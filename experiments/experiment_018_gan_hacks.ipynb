{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 018\n",
    "\n",
    "In this experiment, we will try some common \"GAN hacks\" to try improve the board accuracy of the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError()\n",
    "        with os.scandir(self.path) as it:\n",
    "            entry: os.DirEntry = next(iter(it))\n",
    "            _, self.ext = os.path.splitext(entry.name)\n",
    "            self.highest_index = max((int(Path(file.path).stem) for file in it), default=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.highest_index + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = os.path.join(self.path, f\"{idx}{self.ext}\")\n",
    "        if not os.path.exists(file):\n",
    "            raise IndexError()\n",
    "        boards = np.load(file)\n",
    "\n",
    "        def transform(board):\n",
    "            board = torch.tensor(board, dtype=torch.long)\n",
    "            board = F.one_hot(board, 2) # One-hot encode the cell types\n",
    "            board = board.type(torch.float) # Convert to floating-point\n",
    "            board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "            return board\n",
    "\n",
    "        x = transform(boards[-2]) # Ignore all boards except the last two\n",
    "        y = transform(boards[-1])\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 22, 10]) torch.float32\n",
      "torch.Size([4, 2, 22, 10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisModel(nn.Module):\n",
    "    \"\"\"Predicts the next state of the cells.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        z: Tensor of float32 of shape (batch_size, 4). The entries should be random numbers sampled from a uniform distribution.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, height, width), logits for the new cells. Probabilities close to 0 (negative logits)\n",
    "             correspond to empty cells, and probabilities close to 1 (positive logits) correspond to filled cells.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        z = z[:, :, None, None] # Expand dims to match x\n",
    "        z = z.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        x_glob = self.glob(x)\n",
    "        x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "        x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisDiscriminator(nn.Module):\n",
    "    \"\"\"A discriminator for the cell state predictions. Assesses the output of the generator.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        y: Tensor of float32 of shape (batch_size, channels, height, width), as with x. This should be either the output of the\n",
    "           generator (with exp applied) or the one-hot encoding of the ground truth of the next cell states.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, 1), decisions on whether the data are real or fake. Probabilities close to 0 (negative logits)\n",
    "             correspond to fake data, and probabilities close to 1 (positive logits) correspond to real data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(160, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def check_disc(disc):\n",
    "    gen = TetrisModel().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X, y = next(iter(train_dataloader))\n",
    "        z = torch.rand(batch_size, 4)\n",
    "        y_gen = gen(X, z)\n",
    "        pred_on_real = F.sigmoid(disc(X, y)[0])\n",
    "        pred_on_fake = F.sigmoid(disc(X, y_gen)[0])\n",
    "        print(f\"Number of discriminator parameters: {count_parameters(disc)}\")\n",
    "        print(f\"Predicted label for real data: {pred_on_real}\")\n",
    "        print(f\"Predicted label for fake data: {pred_on_fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_interesting_examples(dataset, num=4):\n",
    "    num_spawns = num // 2\n",
    "    num_normal = num - num_spawns\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "        num_normal_left = num_normal\n",
    "\n",
    "        for x, y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (x.argmax(0)[0] == 0).all() & (y.argmax(0)[0] == 1).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield x, y\n",
    "                else:\n",
    "                    continue\n",
    "            # Yield general examples\n",
    "            if num_normal_left > 0:\n",
    "                num_normal_left -= 1\n",
    "                yield x, y\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prediction(x, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        x: Tensor of shape (height, width), the model input.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the target.\n",
    "    \"\"\"\n",
    "    assert len(x.shape) == 2, f\"Expected tensors of shape (width, height) but got {x.shape}\"\n",
    "    assert x.shape == pred.shape, f\"Shapes do not match: {x.shape} != {pred.shape}\"\n",
    "    assert x.shape == y.shape, f\"Shapes do not match: {x.shape} != {y.shape}\"\n",
    "    height, width = x.shape\n",
    "    with torch.no_grad():\n",
    "        separator = torch.ones(height, 1, dtype=x.dtype)\n",
    "        return torch.cat((x, separator, pred, separator, y), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(X, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        z = torch.rand(batch_size, 4, device=device)\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(X, z)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(X, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(X, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 20 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "    spawn_recall = 0.0\n",
    "    num_spawns = 0.0\n",
    "    spawn_precision = 0.0\n",
    "    num_predicted_spawns = 0.0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for X, y in dataloader:\n",
    "            batch_size = X.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(X, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            z = torch.rand(batch_size, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            output_fake = disc(X, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_X = torch.argmax(X, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy += (classes_y_fake == classes_y).type(torch.float).mean().item()\n",
    "            board_accuracy += (classes_y_fake == classes_y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "            actual_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y[:, 0, :] == 1).any(-1)\n",
    "            predicted_spawns = (classes_y_fake[:, 0, :] == 1).any(-1)\n",
    "            num_true_positives = (actual_spawns & predicted_spawns).type(torch.float).sum().item()\n",
    "            spawn_recall += num_true_positives\n",
    "            num_spawns += actual_spawns.type(torch.float).sum().item()\n",
    "            spawn_precision += num_true_positives\n",
    "            num_predicted_spawns += predicted_spawns.type(torch.float).sum().item()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    spawn_recall /= num_spawns\n",
    "    spawn_precision = np.nan if (num_predicted_spawns == 0.0) else (spawn_precision / num_predicted_spawns)\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(100*cell_accuracy):>0.1f}%, board accuracy: {(100*board_accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(examples):\n",
    "            X, y = X.unsqueeze(0), y.unsqueeze(0)\n",
    "            z = torch.rand(1, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            X, y, y_fake = X.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            X, y, y_fake = X.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(X, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch, dataformats=\"HW\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", disc_cls=TetrisDiscriminator):\n",
    "    learning_rate = 1e-2\n",
    "    epochs = 50\n",
    "\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = disc_cls().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.SGD(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.SGD(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_018\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 5793\n",
      "Predicted label for real data: 0.5493099093437195\n",
      "Predicted label for fake data: 0.5405417680740356\n"
     ]
    }
   ],
   "source": [
    "class DiscWithLeakyReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(160, 16),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.Linear(16, 16),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithLeakyReLU().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4854, G loss: 0.5560\n",
      "[84/1762] D loss: 0.8090, G loss: 1.1255\n",
      "[164/1762] D loss: 0.9261, G loss: 0.6823\n",
      "[244/1762] D loss: 0.6851, G loss: 0.7790\n",
      "[324/1762] D loss: 0.9878, G loss: 0.4966\n",
      "[404/1762] D loss: 0.7942, G loss: 2.0219\n",
      "[484/1762] D loss: 0.9289, G loss: 1.5304\n",
      "[564/1762] D loss: 1.3108, G loss: 0.3322\n",
      "[644/1762] D loss: 0.9893, G loss: 0.6577\n",
      "[724/1762] D loss: 1.1333, G loss: 0.5262\n",
      "[804/1762] D loss: 1.3874, G loss: 1.8283\n",
      "[884/1762] D loss: 1.1802, G loss: 0.9525\n",
      "[964/1762] D loss: 1.1824, G loss: 1.0871\n",
      "[1044/1762] D loss: 1.2453, G loss: 1.1719\n",
      "[1124/1762] D loss: 1.5359, G loss: 1.3899\n",
      "[1204/1762] D loss: 1.3761, G loss: 0.7429\n",
      "[1284/1762] D loss: 1.2421, G loss: 0.9432\n",
      "[1364/1762] D loss: 1.7282, G loss: 1.6486\n",
      "[1444/1762] D loss: 1.3544, G loss: 0.9336\n",
      "[1524/1762] D loss: 1.3495, G loss: 0.7664\n",
      "[1604/1762] D loss: 1.3690, G loss: 0.7975\n",
      "[1684/1762] D loss: 1.4459, G loss: 0.5958\n",
      "[1762/1762] D loss: 1.4248, G loss: 1.3073\n",
      "train error: \n",
      " D loss: 1.407047, G loss: 1.027470, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 82.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400299, G loss: 1.039052, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4724, G loss: 0.7082\n",
      "[84/1762] D loss: 1.5004, G loss: 0.5236\n",
      "[164/1762] D loss: 1.4461, G loss: 1.0477\n",
      "[244/1762] D loss: 1.3976, G loss: 0.7567\n",
      "[324/1762] D loss: 1.3407, G loss: 0.6298\n",
      "[404/1762] D loss: 1.3761, G loss: 0.6806\n",
      "[484/1762] D loss: 1.3651, G loss: 0.6113\n",
      "[564/1762] D loss: 1.2467, G loss: 0.7496\n",
      "[644/1762] D loss: 1.3781, G loss: 0.7026\n",
      "[724/1762] D loss: 1.3052, G loss: 0.8305\n",
      "[804/1762] D loss: 0.9577, G loss: 1.0580\n",
      "[884/1762] D loss: 1.0706, G loss: 0.9122\n",
      "[964/1762] D loss: 1.2076, G loss: 0.9743\n",
      "[1044/1762] D loss: 1.3069, G loss: 0.7359\n",
      "[1124/1762] D loss: 1.4769, G loss: 0.8432\n",
      "[1204/1762] D loss: 1.2398, G loss: 0.9762\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7757\n",
      "[1364/1762] D loss: 1.3775, G loss: 0.6862\n",
      "[1444/1762] D loss: 1.3055, G loss: 0.8008\n",
      "[1524/1762] D loss: 1.4198, G loss: 0.7266\n",
      "[1604/1762] D loss: 1.4653, G loss: 1.0892\n",
      "[1684/1762] D loss: 1.3524, G loss: 0.6087\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.5017\n",
      "train error: \n",
      " D loss: 1.320281, G loss: 0.656214, D accuracy: 58.6%, cell accuracy: 99.7%, board accuracy: 74.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314718, G loss: 0.655919, D accuracy: 57.6%, cell accuracy: 99.6%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3788, G loss: 0.7323\n",
      "[84/1762] D loss: 1.5070, G loss: 0.5568\n",
      "[164/1762] D loss: 1.5105, G loss: 0.9644\n",
      "[244/1762] D loss: 1.4229, G loss: 0.8218\n",
      "[324/1762] D loss: 1.2564, G loss: 0.9154\n",
      "[404/1762] D loss: 1.4175, G loss: 0.6792\n",
      "[484/1762] D loss: 1.3958, G loss: 0.5407\n",
      "[564/1762] D loss: 0.9945, G loss: 0.9967\n",
      "[644/1762] D loss: 1.4096, G loss: 0.6900\n",
      "[724/1762] D loss: 1.3705, G loss: 0.7280\n",
      "[804/1762] D loss: 1.3689, G loss: 0.5672\n",
      "[884/1762] D loss: 1.4037, G loss: 0.7214\n",
      "[964/1762] D loss: 1.4458, G loss: 0.6886\n",
      "[1044/1762] D loss: 1.3826, G loss: 0.6994\n",
      "[1124/1762] D loss: 1.0915, G loss: 1.1586\n",
      "[1204/1762] D loss: 1.2724, G loss: 1.0255\n",
      "[1284/1762] D loss: 1.2621, G loss: 0.8481\n",
      "[1364/1762] D loss: 1.4079, G loss: 0.5836\n",
      "[1444/1762] D loss: 0.9655, G loss: 1.3581\n",
      "[1524/1762] D loss: 1.6692, G loss: 0.6306\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.7343\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.6310\n",
      "[1762/1762] D loss: 1.4137, G loss: 0.7671\n",
      "train error: \n",
      " D loss: 1.325157, G loss: 0.845662, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309170, G loss: 0.857694, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4064, G loss: 0.6358\n",
      "[84/1762] D loss: 1.4282, G loss: 0.8322\n",
      "[164/1762] D loss: 0.8345, G loss: 1.2476\n",
      "[244/1762] D loss: 1.3993, G loss: 0.8049\n",
      "[324/1762] D loss: 1.4400, G loss: 0.5985\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6823\n",
      "[484/1762] D loss: 0.8037, G loss: 1.2838\n",
      "[564/1762] D loss: 1.4045, G loss: 0.8429\n",
      "[644/1762] D loss: 1.4115, G loss: 0.8282\n",
      "[724/1762] D loss: 1.4099, G loss: 0.6344\n",
      "[804/1762] D loss: 1.4457, G loss: 0.8634\n",
      "[884/1762] D loss: 1.6139, G loss: 1.1331\n",
      "[964/1762] D loss: 1.3982, G loss: 0.6831\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.7359\n",
      "[1124/1762] D loss: 1.5190, G loss: 0.6322\n",
      "[1204/1762] D loss: 1.4302, G loss: 0.7788\n",
      "[1284/1762] D loss: 0.8371, G loss: 1.4475\n",
      "[1364/1762] D loss: 1.2979, G loss: 0.8008\n",
      "[1444/1762] D loss: 1.4279, G loss: 0.6500\n",
      "[1524/1762] D loss: 1.3827, G loss: 0.7185\n",
      "[1604/1762] D loss: 1.3882, G loss: 0.7318\n",
      "[1684/1762] D loss: 0.5724, G loss: 1.4509\n",
      "[1762/1762] D loss: 1.4047, G loss: 0.7608\n",
      "train error: \n",
      " D loss: 1.322023, G loss: 0.734401, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 80.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307247, G loss: 0.739427, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3717, G loss: 0.6976\n",
      "[84/1762] D loss: 0.4303, G loss: 1.6640\n",
      "[164/1762] D loss: 0.6951, G loss: 1.6574\n",
      "[244/1762] D loss: 1.3996, G loss: 0.7428\n",
      "[324/1762] D loss: 1.3991, G loss: 0.7421\n",
      "[404/1762] D loss: 0.3603, G loss: 1.6854\n",
      "[484/1762] D loss: 1.4978, G loss: 0.6479\n",
      "[564/1762] D loss: 0.5321, G loss: 1.5818\n",
      "[644/1762] D loss: 0.4787, G loss: 1.5379\n",
      "[724/1762] D loss: 1.3962, G loss: 0.6998\n",
      "[804/1762] D loss: 1.5357, G loss: 0.7182\n",
      "[884/1762] D loss: 1.6088, G loss: 0.6583\n",
      "[964/1762] D loss: 0.5306, G loss: 1.4819\n",
      "[1044/1762] D loss: 1.4010, G loss: 0.7545\n",
      "[1124/1762] D loss: 0.6387, G loss: 1.4570\n",
      "[1204/1762] D loss: 1.4404, G loss: 0.6851\n",
      "[1284/1762] D loss: 1.4944, G loss: 0.8089\n",
      "[1364/1762] D loss: 1.3727, G loss: 0.7344\n",
      "[1444/1762] D loss: 1.4289, G loss: 0.6693\n",
      "[1524/1762] D loss: 1.4078, G loss: 0.6978\n",
      "[1604/1762] D loss: 1.8335, G loss: 0.8387\n",
      "[1684/1762] D loss: 1.4595, G loss: 0.8628\n",
      "[1762/1762] D loss: 1.3135, G loss: 0.7092\n",
      "train error: \n",
      " D loss: 1.380127, G loss: 0.609497, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378484, G loss: 0.617689, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.7015\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6995\n",
      "[164/1762] D loss: 0.6153, G loss: 1.2675\n",
      "[244/1762] D loss: 1.3896, G loss: 0.7073\n",
      "[324/1762] D loss: 0.5342, G loss: 1.2478\n",
      "[404/1762] D loss: 1.4113, G loss: 0.7193\n",
      "[484/1762] D loss: 0.3156, G loss: 1.6763\n",
      "[564/1762] D loss: 1.3702, G loss: 0.7479\n",
      "[644/1762] D loss: 1.7544, G loss: 0.8455\n",
      "[724/1762] D loss: 1.3835, G loss: 0.6308\n",
      "[804/1762] D loss: 1.4445, G loss: 0.6144\n",
      "[884/1762] D loss: 0.4305, G loss: 1.5135\n",
      "[964/1762] D loss: 1.4085, G loss: 0.6930\n",
      "[1044/1762] D loss: 1.3843, G loss: 0.7312\n",
      "[1124/1762] D loss: 1.4273, G loss: 0.7489\n",
      "[1204/1762] D loss: 1.3894, G loss: 0.6990\n",
      "[1284/1762] D loss: 1.3832, G loss: 0.6924\n",
      "[1364/1762] D loss: 1.4627, G loss: 0.8167\n",
      "[1444/1762] D loss: 0.4078, G loss: 1.5324\n",
      "[1524/1762] D loss: 1.3857, G loss: 0.7204\n",
      "[1604/1762] D loss: 1.3308, G loss: 0.7380\n",
      "[1684/1762] D loss: 0.5841, G loss: 1.2107\n",
      "[1762/1762] D loss: 1.6459, G loss: 1.6627\n",
      "train error: \n",
      " D loss: 2.376406, G loss: 2.605352, D accuracy: 50.5%, cell accuracy: 99.1%, board accuracy: 44.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.366212, G loss: 2.626459, D accuracy: 50.8%, cell accuracy: 99.0%, board accuracy: 43.2% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0915, G loss: 0.3793\n",
      "[84/1762] D loss: 1.4007, G loss: 0.7166\n",
      "[164/1762] D loss: 1.4458, G loss: 0.5401\n",
      "[244/1762] D loss: 1.4068, G loss: 0.7050\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7058\n",
      "[404/1762] D loss: 1.3817, G loss: 0.6962\n",
      "[484/1762] D loss: 1.3997, G loss: 0.8391\n",
      "[564/1762] D loss: 0.8855, G loss: 0.9332\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6926\n",
      "[724/1762] D loss: 1.3920, G loss: 0.6978\n",
      "[804/1762] D loss: 1.3821, G loss: 0.7770\n",
      "[884/1762] D loss: 1.3885, G loss: 0.6784\n",
      "[964/1762] D loss: 1.3466, G loss: 0.7532\n",
      "[1044/1762] D loss: 1.4171, G loss: 0.7321\n",
      "[1124/1762] D loss: 1.3842, G loss: 0.6925\n",
      "[1204/1762] D loss: 1.3834, G loss: 0.6908\n",
      "[1284/1762] D loss: 1.4674, G loss: 0.7482\n",
      "[1364/1762] D loss: 1.4726, G loss: 0.6739\n",
      "[1444/1762] D loss: 0.7009, G loss: 1.4594\n",
      "[1524/1762] D loss: 1.3493, G loss: 0.7441\n",
      "[1604/1762] D loss: 1.3836, G loss: 0.7323\n",
      "[1684/1762] D loss: 1.3856, G loss: 0.7037\n",
      "[1762/1762] D loss: 1.3954, G loss: 0.6795\n",
      "train error: \n",
      " D loss: 1.322609, G loss: 0.679544, D accuracy: 56.3%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306728, G loss: 0.680545, D accuracy: 57.4%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.7009\n",
      "[84/1762] D loss: 1.3966, G loss: 0.7085\n",
      "[164/1762] D loss: 1.4378, G loss: 0.7502\n",
      "[244/1762] D loss: 1.3476, G loss: 0.6339\n",
      "[324/1762] D loss: 1.3315, G loss: 0.6867\n",
      "[404/1762] D loss: 1.5208, G loss: 0.7284\n",
      "[484/1762] D loss: 0.4800, G loss: 1.5186\n",
      "[564/1762] D loss: 1.3947, G loss: 0.7161\n",
      "[644/1762] D loss: 0.3257, G loss: 1.6566\n",
      "[724/1762] D loss: 1.4603, G loss: 0.7190\n",
      "[804/1762] D loss: 0.5107, G loss: 1.3572\n",
      "[884/1762] D loss: 1.3964, G loss: 0.6952\n",
      "[964/1762] D loss: 0.2943, G loss: 1.6459\n",
      "[1044/1762] D loss: 1.3931, G loss: 0.7145\n",
      "[1124/1762] D loss: 1.3806, G loss: 0.6858\n",
      "[1204/1762] D loss: 1.3951, G loss: 0.7161\n",
      "[1284/1762] D loss: 0.3847, G loss: 1.3978\n",
      "[1364/1762] D loss: 0.5265, G loss: 1.1486\n",
      "[1444/1762] D loss: 1.7421, G loss: 1.0873\n",
      "[1524/1762] D loss: 0.8694, G loss: 1.0089\n",
      "[1604/1762] D loss: 1.4019, G loss: 0.7051\n",
      "[1684/1762] D loss: 1.3672, G loss: 0.7271\n",
      "[1762/1762] D loss: 1.4040, G loss: 0.6857\n",
      "train error: \n",
      " D loss: 1.328979, G loss: 0.654139, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318186, G loss: 0.652605, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.6941\n",
      "[84/1762] D loss: 1.2997, G loss: 0.7156\n",
      "[164/1762] D loss: 1.5220, G loss: 0.7189\n",
      "[244/1762] D loss: 1.3941, G loss: 0.7208\n",
      "[324/1762] D loss: 0.7091, G loss: 1.2130\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7027\n",
      "[484/1762] D loss: 1.3894, G loss: 0.7333\n",
      "[564/1762] D loss: 1.6186, G loss: 0.8596\n",
      "[644/1762] D loss: 0.4456, G loss: 1.4208\n",
      "[724/1762] D loss: 0.3842, G loss: 1.5761\n",
      "[804/1762] D loss: 1.3881, G loss: 0.6931\n",
      "[884/1762] D loss: 1.5077, G loss: 0.9160\n",
      "[964/1762] D loss: 1.4060, G loss: 0.6863\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7044\n",
      "[1124/1762] D loss: 0.5787, G loss: 1.2305\n",
      "[1204/1762] D loss: 0.5972, G loss: 1.2012\n",
      "[1284/1762] D loss: 1.4176, G loss: 0.6755\n",
      "[1364/1762] D loss: 1.4095, G loss: 0.8035\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.7383\n",
      "[1524/1762] D loss: 1.4260, G loss: 0.7599\n",
      "[1604/1762] D loss: 0.5039, G loss: 1.2949\n",
      "[1684/1762] D loss: 0.3334, G loss: 1.5988\n",
      "[1762/1762] D loss: 1.4250, G loss: 0.7269\n",
      "train error: \n",
      " D loss: 1.319649, G loss: 0.713080, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299014, G loss: 0.728751, D accuracy: 57.5%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4035, G loss: 0.7149\n",
      "[84/1762] D loss: 1.5075, G loss: 0.8889\n",
      "[164/1762] D loss: 0.5861, G loss: 1.1980\n",
      "[244/1762] D loss: 1.4006, G loss: 0.7923\n",
      "[324/1762] D loss: 1.3775, G loss: 0.6768\n",
      "[404/1762] D loss: 1.5505, G loss: 0.8581\n",
      "[484/1762] D loss: 1.4189, G loss: 0.6780\n",
      "[564/1762] D loss: 1.4203, G loss: 0.7180\n",
      "[644/1762] D loss: 0.5111, G loss: 1.3124\n",
      "[724/1762] D loss: 1.4587, G loss: 0.7975\n",
      "[804/1762] D loss: 1.5689, G loss: 0.7324\n",
      "[884/1762] D loss: 1.2764, G loss: 0.9010\n",
      "[964/1762] D loss: 1.1013, G loss: 0.9875\n",
      "[1044/1762] D loss: 1.4040, G loss: 0.6477\n",
      "[1124/1762] D loss: 1.3838, G loss: 0.6913\n",
      "[1204/1762] D loss: 0.5536, G loss: 1.4912\n",
      "[1284/1762] D loss: 1.3953, G loss: 0.7435\n",
      "[1364/1762] D loss: 1.1227, G loss: 0.8957\n",
      "[1444/1762] D loss: 1.1626, G loss: 0.9145\n",
      "[1524/1762] D loss: 1.3679, G loss: 0.7193\n",
      "[1604/1762] D loss: 1.4030, G loss: 0.6718\n",
      "[1684/1762] D loss: 0.8494, G loss: 1.1124\n",
      "[1762/1762] D loss: 0.8759, G loss: 1.1266\n",
      "train error: \n",
      " D loss: 1.376236, G loss: 0.566809, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 83.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360961, G loss: 0.590030, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0944, G loss: 0.9143\n",
      "[84/1762] D loss: 1.3975, G loss: 0.7592\n",
      "[164/1762] D loss: 1.4077, G loss: 0.6791\n",
      "[244/1762] D loss: 1.3840, G loss: 0.7134\n",
      "[324/1762] D loss: 1.1418, G loss: 0.9493\n",
      "[404/1762] D loss: 1.3987, G loss: 0.7584\n",
      "[484/1762] D loss: 1.3824, G loss: 0.7548\n",
      "[564/1762] D loss: 0.6635, G loss: 1.2709\n",
      "[644/1762] D loss: 1.4985, G loss: 0.7339\n",
      "[724/1762] D loss: 1.3892, G loss: 0.6612\n",
      "[804/1762] D loss: 1.5462, G loss: 0.6988\n",
      "[884/1762] D loss: 1.4472, G loss: 0.7424\n",
      "[964/1762] D loss: 0.9585, G loss: 1.0039\n",
      "[1044/1762] D loss: 1.3595, G loss: 0.7182\n",
      "[1124/1762] D loss: 1.3904, G loss: 0.6944\n",
      "[1204/1762] D loss: 1.2369, G loss: 0.8213\n",
      "[1284/1762] D loss: 1.3949, G loss: 0.7155\n",
      "[1364/1762] D loss: 1.3123, G loss: 0.7701\n",
      "[1444/1762] D loss: 1.3989, G loss: 0.6975\n",
      "[1524/1762] D loss: 1.4060, G loss: 0.7046\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7664\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6949\n",
      "[1762/1762] D loss: 1.4200, G loss: 0.8590\n",
      "train error: \n",
      " D loss: 1.358146, G loss: 1.039049, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339234, G loss: 1.060803, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905, G loss: 0.7256\n",
      "[84/1762] D loss: 1.4048, G loss: 0.7008\n",
      "[164/1762] D loss: 1.3559, G loss: 0.6770\n",
      "[244/1762] D loss: 1.3801, G loss: 0.6969\n",
      "[324/1762] D loss: 0.5089, G loss: 1.3548\n",
      "[404/1762] D loss: 0.4935, G loss: 1.2920\n",
      "[484/1762] D loss: 1.4150, G loss: 0.7975\n",
      "[564/1762] D loss: 1.4911, G loss: 0.7241\n",
      "[644/1762] D loss: 1.4537, G loss: 0.7059\n",
      "[724/1762] D loss: 1.3841, G loss: 0.7083\n",
      "[804/1762] D loss: 1.3882, G loss: 0.7102\n",
      "[884/1762] D loss: 0.4133, G loss: 1.4609\n",
      "[964/1762] D loss: 1.4094, G loss: 0.6523\n",
      "[1044/1762] D loss: 1.3925, G loss: 0.6785\n",
      "[1124/1762] D loss: 1.3951, G loss: 0.7049\n",
      "[1204/1762] D loss: 0.5109, G loss: 1.2836\n",
      "[1284/1762] D loss: 1.3796, G loss: 0.8655\n",
      "[1364/1762] D loss: 0.4642, G loss: 1.4401\n",
      "[1444/1762] D loss: 1.1606, G loss: 1.5327\n",
      "[1524/1762] D loss: 1.3827, G loss: 0.9467\n",
      "[1604/1762] D loss: 1.4032, G loss: 0.7565\n",
      "[1684/1762] D loss: 1.3934, G loss: 0.6742\n",
      "[1762/1762] D loss: 1.4258, G loss: 0.7473\n",
      "train error: \n",
      " D loss: 1.284126, G loss: 0.909866, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 75.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270321, G loss: 0.942493, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3822, G loss: 0.7065\n",
      "[84/1762] D loss: 1.3856, G loss: 0.7037\n",
      "[164/1762] D loss: 1.3848, G loss: 0.6918\n",
      "[244/1762] D loss: 1.2262, G loss: 0.8950\n",
      "[324/1762] D loss: 1.2733, G loss: 0.8634\n",
      "[404/1762] D loss: 1.0980, G loss: 1.0676\n",
      "[484/1762] D loss: 0.8815, G loss: 1.1971\n",
      "[564/1762] D loss: 1.3027, G loss: 0.8971\n",
      "[644/1762] D loss: 1.3737, G loss: 0.7351\n",
      "[724/1762] D loss: 1.4006, G loss: 0.7735\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6913\n",
      "[884/1762] D loss: 1.2848, G loss: 1.0654\n",
      "[964/1762] D loss: 1.3168, G loss: 0.7972\n",
      "[1044/1762] D loss: 1.3922, G loss: 0.7022\n",
      "[1124/1762] D loss: 1.4354, G loss: 1.0113\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.7190\n",
      "[1284/1762] D loss: 1.3815, G loss: 0.7603\n",
      "[1364/1762] D loss: 1.4037, G loss: 0.6486\n",
      "[1444/1762] D loss: 1.4041, G loss: 0.7495\n",
      "[1524/1762] D loss: 1.2899, G loss: 0.8880\n",
      "[1604/1762] D loss: 1.4748, G loss: 0.7242\n",
      "[1684/1762] D loss: 1.4979, G loss: 0.8007\n",
      "[1762/1762] D loss: 0.1345, G loss: 2.4853\n",
      "train error: \n",
      " D loss: 1.328138, G loss: 0.779854, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306146, G loss: 0.802472, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6357, G loss: 0.8420\n",
      "[84/1762] D loss: 1.3913, G loss: 0.7344\n",
      "[164/1762] D loss: 0.4411, G loss: 1.5221\n",
      "[244/1762] D loss: 0.2415, G loss: 2.0975\n",
      "[324/1762] D loss: 1.4655, G loss: 0.7758\n",
      "[404/1762] D loss: 2.6042, G loss: 1.1027\n",
      "[484/1762] D loss: 1.4006, G loss: 0.7931\n",
      "[564/1762] D loss: 1.1171, G loss: 1.0186\n",
      "[644/1762] D loss: 0.6540, G loss: 1.4662\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7024\n",
      "[804/1762] D loss: 1.2750, G loss: 0.8400\n",
      "[884/1762] D loss: 1.3857, G loss: 0.6879\n",
      "[964/1762] D loss: 1.2089, G loss: 0.9243\n",
      "[1044/1762] D loss: 1.3005, G loss: 0.7764\n",
      "[1124/1762] D loss: 1.0862, G loss: 1.1063\n",
      "[1204/1762] D loss: 1.3994, G loss: 0.6567\n",
      "[1284/1762] D loss: 1.2618, G loss: 0.8431\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.7040\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.6966\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.6950\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.7055\n",
      "[1684/1762] D loss: 1.3974, G loss: 0.7089\n",
      "[1762/1762] D loss: 0.2837, G loss: 2.3124\n",
      "train error: \n",
      " D loss: 1.291394, G loss: 0.727677, D accuracy: 59.9%, cell accuracy: 99.6%, board accuracy: 70.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275784, G loss: 0.737799, D accuracy: 61.5%, cell accuracy: 99.5%, board accuracy: 65.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4276, G loss: 0.6523\n",
      "[84/1762] D loss: 1.8140, G loss: 2.7138\n",
      "[164/1762] D loss: 1.3915, G loss: 0.7051\n",
      "[244/1762] D loss: 1.4014, G loss: 0.6865\n",
      "[324/1762] D loss: 1.3847, G loss: 0.7061\n",
      "[404/1762] D loss: 1.3615, G loss: 0.6905\n",
      "[484/1762] D loss: 1.0634, G loss: 1.4813\n",
      "[564/1762] D loss: 1.3222, G loss: 0.8586\n",
      "[644/1762] D loss: 0.9906, G loss: 1.2233\n",
      "[724/1762] D loss: 0.1199, G loss: 2.9184\n",
      "[804/1762] D loss: 1.4244, G loss: 0.7370\n",
      "[884/1762] D loss: 1.3936, G loss: 0.7131\n",
      "[964/1762] D loss: 1.3463, G loss: 0.8677\n",
      "[1044/1762] D loss: 1.3608, G loss: 0.8505\n",
      "[1124/1762] D loss: 0.4961, G loss: 1.6663\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.6942\n",
      "[1284/1762] D loss: 1.4129, G loss: 0.6911\n",
      "[1364/1762] D loss: 0.3433, G loss: 2.2978\n",
      "[1444/1762] D loss: 1.4030, G loss: 0.8128\n",
      "[1524/1762] D loss: 1.3978, G loss: 0.6785\n",
      "[1604/1762] D loss: 1.4074, G loss: 0.7092\n",
      "[1684/1762] D loss: 1.5980, G loss: 0.5750\n",
      "[1762/1762] D loss: 1.3995, G loss: 0.7399\n",
      "train error: \n",
      " D loss: 1.308773, G loss: 0.766256, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285860, G loss: 0.777466, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4300, G loss: 0.6710\n",
      "[84/1762] D loss: 1.3966, G loss: 0.7346\n",
      "[164/1762] D loss: 1.0126, G loss: 1.1896\n",
      "[244/1762] D loss: 1.7000, G loss: 1.3942\n",
      "[324/1762] D loss: 1.1709, G loss: 0.8356\n",
      "[404/1762] D loss: 1.4013, G loss: 0.7132\n",
      "[484/1762] D loss: 0.7913, G loss: 1.2952\n",
      "[564/1762] D loss: 0.6671, G loss: 1.3693\n",
      "[644/1762] D loss: 1.3527, G loss: 0.7064\n",
      "[724/1762] D loss: 1.4130, G loss: 0.7019\n",
      "[804/1762] D loss: 1.3660, G loss: 0.7281\n",
      "[884/1762] D loss: 1.3894, G loss: 0.6766\n",
      "[964/1762] D loss: 1.5497, G loss: 0.6816\n",
      "[1044/1762] D loss: 0.2741, G loss: 2.0744\n",
      "[1124/1762] D loss: 1.3989, G loss: 0.6626\n",
      "[1204/1762] D loss: 0.2252, G loss: 2.1125\n",
      "[1284/1762] D loss: 1.3999, G loss: 0.7251\n",
      "[1364/1762] D loss: 1.4057, G loss: 0.7194\n",
      "[1444/1762] D loss: 0.5213, G loss: 1.6190\n",
      "[1524/1762] D loss: 1.2605, G loss: 0.8041\n",
      "[1604/1762] D loss: 1.3893, G loss: 0.7086\n",
      "[1684/1762] D loss: 1.4283, G loss: 0.7815\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.7005\n",
      "train error: \n",
      " D loss: 1.310693, G loss: 0.749316, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287977, G loss: 0.765634, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3955, G loss: 0.7122\n",
      "[84/1762] D loss: 1.3921, G loss: 0.6486\n",
      "[164/1762] D loss: 0.3363, G loss: 1.8387\n",
      "[244/1762] D loss: 1.5084, G loss: 0.6323\n",
      "[324/1762] D loss: 1.1968, G loss: 0.8491\n",
      "[404/1762] D loss: 1.6715, G loss: 0.7321\n",
      "[484/1762] D loss: 1.4035, G loss: 0.6788\n",
      "[564/1762] D loss: 1.3846, G loss: 0.7208\n",
      "[644/1762] D loss: 1.3032, G loss: 0.9545\n",
      "[724/1762] D loss: 0.7676, G loss: 2.5883\n",
      "[804/1762] D loss: 1.4036, G loss: 0.7305\n",
      "[884/1762] D loss: 1.4090, G loss: 0.7798\n",
      "[964/1762] D loss: 1.3834, G loss: 0.7427\n",
      "[1044/1762] D loss: 0.9175, G loss: 0.9375\n",
      "[1124/1762] D loss: 0.8667, G loss: 1.9206\n",
      "[1204/1762] D loss: 1.4005, G loss: 0.7150\n",
      "[1284/1762] D loss: 0.6671, G loss: 1.2078\n",
      "[1364/1762] D loss: 1.5288, G loss: 0.9767\n",
      "[1444/1762] D loss: 0.4450, G loss: 1.5843\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.7248\n",
      "[1604/1762] D loss: 0.4431, G loss: 1.3991\n",
      "[1684/1762] D loss: 0.4075, G loss: 1.6373\n",
      "[1762/1762] D loss: 1.4031, G loss: 0.7367\n",
      "train error: \n",
      " D loss: 1.380523, G loss: 0.548054, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363805, G loss: 0.554656, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.7146\n",
      "[84/1762] D loss: 1.4109, G loss: 0.6608\n",
      "[164/1762] D loss: 1.4018, G loss: 0.8364\n",
      "[244/1762] D loss: 1.3825, G loss: 0.6952\n",
      "[324/1762] D loss: 1.3914, G loss: 0.7045\n",
      "[404/1762] D loss: 1.4010, G loss: 0.7480\n",
      "[484/1762] D loss: 1.2918, G loss: 1.1040\n",
      "[564/1762] D loss: 1.3156, G loss: 0.8982\n",
      "[644/1762] D loss: 1.3921, G loss: 0.7283\n",
      "[724/1762] D loss: 1.3317, G loss: 0.7738\n",
      "[804/1762] D loss: 1.3858, G loss: 0.6798\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6983\n",
      "[964/1762] D loss: 1.3985, G loss: 0.6640\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6694\n",
      "[1124/1762] D loss: 1.3849, G loss: 0.6850\n",
      "[1204/1762] D loss: 1.2595, G loss: 0.6989\n",
      "[1284/1762] D loss: 1.1518, G loss: 0.9550\n",
      "[1364/1762] D loss: 1.3777, G loss: 0.7089\n",
      "[1444/1762] D loss: 0.9075, G loss: 1.4749\n",
      "[1524/1762] D loss: 1.3436, G loss: 0.7768\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.6929\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7119\n",
      "[1762/1762] D loss: 1.1025, G loss: 2.2954\n",
      "train error: \n",
      " D loss: 1.641294, G loss: 1.378407, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.658781, G loss: 1.429249, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4429, G loss: 0.6381\n",
      "[84/1762] D loss: 1.3863, G loss: 0.7505\n",
      "[164/1762] D loss: 1.4223, G loss: 0.6050\n",
      "[244/1762] D loss: 1.3847, G loss: 0.7176\n",
      "[324/1762] D loss: 1.3799, G loss: 0.7137\n",
      "[404/1762] D loss: 1.3881, G loss: 0.6890\n",
      "[484/1762] D loss: 1.3550, G loss: 0.7476\n",
      "[564/1762] D loss: 1.3856, G loss: 0.7123\n",
      "[644/1762] D loss: 1.2155, G loss: 0.9193\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6836\n",
      "[804/1762] D loss: 1.3930, G loss: 0.6656\n",
      "[884/1762] D loss: 1.3118, G loss: 0.7039\n",
      "[964/1762] D loss: 1.7032, G loss: 0.5798\n",
      "[1044/1762] D loss: 1.4139, G loss: 0.6870\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.6873\n",
      "[1204/1762] D loss: 1.3801, G loss: 0.7045\n",
      "[1284/1762] D loss: 1.3950, G loss: 0.7316\n",
      "[1364/1762] D loss: 1.4035, G loss: 0.6939\n",
      "[1444/1762] D loss: 1.5502, G loss: 0.7196\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.6842\n",
      "[1604/1762] D loss: 1.1432, G loss: 1.0537\n",
      "[1684/1762] D loss: 1.2047, G loss: 1.3438\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6987\n",
      "train error: \n",
      " D loss: 1.336322, G loss: 0.744531, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317727, G loss: 0.771146, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6468, G loss: 1.5438\n",
      "[84/1762] D loss: 1.4604, G loss: 0.5780\n",
      "[164/1762] D loss: 1.4460, G loss: 0.6539\n",
      "[244/1762] D loss: 1.4833, G loss: 0.7273\n",
      "[324/1762] D loss: 1.3857, G loss: 0.6963\n",
      "[404/1762] D loss: 1.3845, G loss: 0.6997\n",
      "[484/1762] D loss: 1.3912, G loss: 0.7105\n",
      "[564/1762] D loss: 1.4110, G loss: 0.7256\n",
      "[644/1762] D loss: 1.4080, G loss: 0.7145\n",
      "[724/1762] D loss: 1.3906, G loss: 0.6802\n",
      "[804/1762] D loss: 1.3907, G loss: 0.7055\n",
      "[884/1762] D loss: 1.4385, G loss: 0.6032\n",
      "[964/1762] D loss: 1.3946, G loss: 0.6880\n",
      "[1044/1762] D loss: 1.3984, G loss: 0.7290\n",
      "[1124/1762] D loss: 1.3966, G loss: 0.6946\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.6880\n",
      "[1284/1762] D loss: 0.9717, G loss: 1.1005\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.6884\n",
      "[1444/1762] D loss: 1.4159, G loss: 0.7934\n",
      "[1524/1762] D loss: 1.3944, G loss: 0.8903\n",
      "[1604/1762] D loss: 1.3850, G loss: 0.6599\n",
      "[1684/1762] D loss: 1.3745, G loss: 0.7579\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.6978\n",
      "train error: \n",
      " D loss: 1.337196, G loss: 0.832747, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320740, G loss: 0.846495, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908, G loss: 0.6969\n",
      "[84/1762] D loss: 1.4275, G loss: 0.7444\n",
      "[164/1762] D loss: 1.4810, G loss: 0.7882\n",
      "[244/1762] D loss: 0.5572, G loss: 1.2744\n",
      "[324/1762] D loss: 1.3839, G loss: 0.8128\n",
      "[404/1762] D loss: 1.4125, G loss: 0.7796\n",
      "[484/1762] D loss: 1.3904, G loss: 0.7194\n",
      "[564/1762] D loss: 2.1978, G loss: 1.2568\n",
      "[644/1762] D loss: 1.0642, G loss: 0.9779\n",
      "[724/1762] D loss: 1.1735, G loss: 0.9384\n",
      "[804/1762] D loss: 1.3961, G loss: 0.7050\n",
      "[884/1762] D loss: 1.4400, G loss: 0.6992\n",
      "[964/1762] D loss: 1.3703, G loss: 0.6964\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.6722\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.6744\n",
      "[1204/1762] D loss: 1.3901, G loss: 0.6598\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6879\n",
      "[1364/1762] D loss: 1.4164, G loss: 1.0940\n",
      "[1444/1762] D loss: 1.3838, G loss: 0.6883\n",
      "[1524/1762] D loss: 1.3979, G loss: 0.6472\n",
      "[1604/1762] D loss: 1.3848, G loss: 0.7065\n",
      "[1684/1762] D loss: 1.3940, G loss: 0.7137\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.7170\n",
      "train error: \n",
      " D loss: 1.367910, G loss: 0.669266, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367412, G loss: 0.668480, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6947\n",
      "[84/1762] D loss: 1.3880, G loss: 0.6861\n",
      "[164/1762] D loss: 1.4650, G loss: 0.4498\n",
      "[244/1762] D loss: 1.3875, G loss: 0.6942\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6990\n",
      "[404/1762] D loss: 1.3920, G loss: 0.6974\n",
      "[484/1762] D loss: 1.4029, G loss: 0.6973\n",
      "[564/1762] D loss: 1.4150, G loss: 0.7848\n",
      "[644/1762] D loss: 1.3882, G loss: 0.6578\n",
      "[724/1762] D loss: 1.4164, G loss: 0.7901\n",
      "[804/1762] D loss: 1.4535, G loss: 0.7547\n",
      "[884/1762] D loss: 1.4958, G loss: 0.8142\n",
      "[964/1762] D loss: 1.4133, G loss: 0.6833\n",
      "[1044/1762] D loss: 0.5389, G loss: 1.2402\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.7354\n",
      "[1204/1762] D loss: 1.4060, G loss: 0.7201\n",
      "[1284/1762] D loss: 1.3773, G loss: 0.7059\n",
      "[1364/1762] D loss: 0.7703, G loss: 0.9788\n",
      "[1444/1762] D loss: 0.5631, G loss: 1.4380\n",
      "[1524/1762] D loss: 1.4152, G loss: 0.7286\n",
      "[1604/1762] D loss: 1.4108, G loss: 0.7908\n",
      "[1684/1762] D loss: 0.6335, G loss: 1.1299\n",
      "[1762/1762] D loss: 0.1497, G loss: 2.2962\n",
      "train error: \n",
      " D loss: 1.356482, G loss: 0.575921, D accuracy: 56.3%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338821, G loss: 0.593939, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4317, G loss: 0.7222\n",
      "[84/1762] D loss: 1.3043, G loss: 0.8479\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7007\n",
      "[244/1762] D loss: 1.4211, G loss: 0.7137\n",
      "[324/1762] D loss: 1.3747, G loss: 0.7282\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7046\n",
      "[484/1762] D loss: 1.4082, G loss: 0.7070\n",
      "[564/1762] D loss: 1.3839, G loss: 0.7381\n",
      "[644/1762] D loss: 1.3982, G loss: 0.7167\n",
      "[724/1762] D loss: 1.3909, G loss: 0.6922\n",
      "[804/1762] D loss: 1.4536, G loss: 0.8145\n",
      "[884/1762] D loss: 1.4248, G loss: 0.7838\n",
      "[964/1762] D loss: 1.4059, G loss: 0.7285\n",
      "[1044/1762] D loss: 1.4086, G loss: 0.4195\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.7156\n",
      "[1204/1762] D loss: 1.3929, G loss: 0.7240\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.6149\n",
      "[1364/1762] D loss: 1.3910, G loss: 0.6863\n",
      "[1444/1762] D loss: 1.1491, G loss: 1.0334\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6939\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.7268\n",
      "[1684/1762] D loss: 1.4391, G loss: 0.6952\n",
      "[1762/1762] D loss: 1.8865, G loss: 0.8758\n",
      "train error: \n",
      " D loss: 1.342523, G loss: 0.679086, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321406, G loss: 0.699642, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3971, G loss: 0.7196\n",
      "[84/1762] D loss: 1.4151, G loss: 0.7182\n",
      "[164/1762] D loss: 1.3920, G loss: 0.7118\n",
      "[244/1762] D loss: 1.3222, G loss: 0.8646\n",
      "[324/1762] D loss: 1.7420, G loss: 0.7559\n",
      "[404/1762] D loss: 1.3948, G loss: 0.7200\n",
      "[484/1762] D loss: 1.3913, G loss: 0.7342\n",
      "[564/1762] D loss: 1.3898, G loss: 0.6935\n",
      "[644/1762] D loss: 0.3163, G loss: 2.1849\n",
      "[724/1762] D loss: 1.4020, G loss: 0.7684\n",
      "[804/1762] D loss: 1.3842, G loss: 0.7395\n",
      "[884/1762] D loss: 1.3968, G loss: 0.7256\n",
      "[964/1762] D loss: 0.3400, G loss: 1.9257\n",
      "[1044/1762] D loss: 1.3926, G loss: 0.7248\n",
      "[1124/1762] D loss: 1.5984, G loss: 0.8337\n",
      "[1204/1762] D loss: 0.2913, G loss: 2.6257\n",
      "[1284/1762] D loss: 1.5206, G loss: 0.6544\n",
      "[1364/1762] D loss: 0.4917, G loss: 1.4900\n",
      "[1444/1762] D loss: 1.4029, G loss: 0.6627\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7273\n",
      "[1604/1762] D loss: 0.2380, G loss: 1.9996\n",
      "[1684/1762] D loss: 1.3066, G loss: 0.6262\n",
      "[1762/1762] D loss: 1.2557, G loss: 0.8878\n",
      "train error: \n",
      " D loss: 1.288994, G loss: 0.907864, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259095, G loss: 0.957587, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3949, G loss: 0.6745\n",
      "[84/1762] D loss: 1.3926, G loss: 0.7040\n",
      "[164/1762] D loss: 1.4500, G loss: 0.9489\n",
      "[244/1762] D loss: 1.4409, G loss: 0.7049\n",
      "[324/1762] D loss: 1.3901, G loss: 0.7185\n",
      "[404/1762] D loss: 0.9338, G loss: 1.4763\n",
      "[484/1762] D loss: 1.4148, G loss: 0.7884\n",
      "[564/1762] D loss: 1.4674, G loss: 0.6118\n",
      "[644/1762] D loss: 1.4236, G loss: 0.7147\n",
      "[724/1762] D loss: 1.4280, G loss: 0.7738\n",
      "[804/1762] D loss: 1.3877, G loss: 0.5472\n",
      "[884/1762] D loss: 1.4067, G loss: 0.7003\n",
      "[964/1762] D loss: 1.3945, G loss: 0.7041\n",
      "[1044/1762] D loss: 1.4904, G loss: 0.6508\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.7087\n",
      "[1204/1762] D loss: 1.5214, G loss: 0.7930\n",
      "[1284/1762] D loss: 1.4208, G loss: 0.6784\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.6753\n",
      "[1444/1762] D loss: 0.2509, G loss: 2.1382\n",
      "[1524/1762] D loss: 1.4034, G loss: 0.7426\n",
      "[1604/1762] D loss: 1.4114, G loss: 0.6889\n",
      "[1684/1762] D loss: 0.5911, G loss: 1.6350\n",
      "[1762/1762] D loss: 1.2793, G loss: 1.3181\n",
      "train error: \n",
      " D loss: 1.353451, G loss: 1.239362, D accuracy: 53.6%, cell accuracy: 99.3%, board accuracy: 70.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332481, G loss: 1.266007, D accuracy: 54.5%, cell accuracy: 99.1%, board accuracy: 69.3% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3629, G loss: 0.5140\n",
      "[84/1762] D loss: 0.4413, G loss: 2.1236\n",
      "[164/1762] D loss: 0.4213, G loss: 2.1364\n",
      "[244/1762] D loss: 1.3966, G loss: 0.7016\n",
      "[324/1762] D loss: 1.4515, G loss: 1.1296\n",
      "[404/1762] D loss: 1.4347, G loss: 0.6081\n",
      "[484/1762] D loss: 1.4285, G loss: 0.8515\n",
      "[564/1762] D loss: 1.3942, G loss: 0.6785\n",
      "[644/1762] D loss: 0.4368, G loss: 2.0044\n",
      "[724/1762] D loss: 0.4041, G loss: 2.1187\n",
      "[804/1762] D loss: 1.3738, G loss: 0.8093\n",
      "[884/1762] D loss: 0.6601, G loss: 1.4055\n",
      "[964/1762] D loss: 1.3931, G loss: 0.7024\n",
      "[1044/1762] D loss: 1.3818, G loss: 0.6953\n",
      "[1124/1762] D loss: 1.4026, G loss: 0.6888\n",
      "[1204/1762] D loss: 0.3537, G loss: 2.0580\n",
      "[1284/1762] D loss: 1.4035, G loss: 0.6553\n",
      "[1364/1762] D loss: 1.4149, G loss: 0.6862\n",
      "[1444/1762] D loss: 1.4019, G loss: 0.7089\n",
      "[1524/1762] D loss: 0.6403, G loss: 1.6059\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.6926\n",
      "[1684/1762] D loss: 1.0647, G loss: 1.7085\n",
      "[1762/1762] D loss: 1.3776, G loss: 0.7422\n",
      "train error: \n",
      " D loss: 1.315340, G loss: 0.791278, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306176, G loss: 0.797705, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3656, G loss: 0.6907\n",
      "[84/1762] D loss: 1.3098, G loss: 0.7939\n",
      "[164/1762] D loss: 1.3716, G loss: 0.7838\n",
      "[244/1762] D loss: 1.1352, G loss: 1.4383\n",
      "[324/1762] D loss: 1.4596, G loss: 0.7770\n",
      "[404/1762] D loss: 1.3947, G loss: 0.6580\n",
      "[484/1762] D loss: 1.3560, G loss: 0.7330\n",
      "[564/1762] D loss: 1.3634, G loss: 0.7142\n",
      "[644/1762] D loss: 1.4921, G loss: 0.8080\n",
      "[724/1762] D loss: 1.3855, G loss: 0.6513\n",
      "[804/1762] D loss: 1.4868, G loss: 0.9835\n",
      "[884/1762] D loss: 1.3927, G loss: 0.6674\n",
      "[964/1762] D loss: 1.6217, G loss: 0.8483\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6795\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6904\n",
      "[1204/1762] D loss: 1.0861, G loss: 0.9053\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6854\n",
      "[1364/1762] D loss: 1.2598, G loss: 0.8498\n",
      "[1444/1762] D loss: 0.9056, G loss: 1.0002\n",
      "[1524/1762] D loss: 1.3842, G loss: 0.7236\n",
      "[1604/1762] D loss: 1.3981, G loss: 0.7456\n",
      "[1684/1762] D loss: 1.3770, G loss: 1.0312\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6505\n",
      "train error: \n",
      " D loss: 1.345132, G loss: 0.734957, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335348, G loss: 0.737433, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6869\n",
      "[84/1762] D loss: 1.3841, G loss: 0.6844\n",
      "[164/1762] D loss: 1.3904, G loss: 0.7187\n",
      "[244/1762] D loss: 1.3945, G loss: 0.7403\n",
      "[324/1762] D loss: 1.4124, G loss: 0.9547\n",
      "[404/1762] D loss: 1.3896, G loss: 0.7080\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7038\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6993\n",
      "[644/1762] D loss: 1.3897, G loss: 0.7051\n",
      "[724/1762] D loss: 0.3876, G loss: 1.5226\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7117\n",
      "[884/1762] D loss: 1.3997, G loss: 0.6561\n",
      "[964/1762] D loss: 1.3936, G loss: 0.7317\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.6381\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.6879\n",
      "[1204/1762] D loss: 1.3965, G loss: 0.6457\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.6720\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.7155\n",
      "[1444/1762] D loss: 1.3922, G loss: 0.6466\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6705\n",
      "[1604/1762] D loss: 1.3998, G loss: 0.7618\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.7270\n",
      "[1762/1762] D loss: 1.3853, G loss: 0.7060\n",
      "train error: \n",
      " D loss: 1.379169, G loss: 0.667045, D accuracy: 49.5%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382224, G loss: 0.655707, D accuracy: 49.8%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3946, G loss: 0.7164\n",
      "[84/1762] D loss: 0.5832, G loss: 1.1393\n",
      "[164/1762] D loss: 1.3893, G loss: 0.7065\n",
      "[244/1762] D loss: 1.4006, G loss: 0.6490\n",
      "[324/1762] D loss: 1.3899, G loss: 0.6785\n",
      "[404/1762] D loss: 1.3843, G loss: 0.6948\n",
      "[484/1762] D loss: 1.3927, G loss: 0.7237\n",
      "[564/1762] D loss: 1.0194, G loss: 1.1192\n",
      "[644/1762] D loss: 1.3993, G loss: 0.7150\n",
      "[724/1762] D loss: 1.3862, G loss: 0.7139\n",
      "[804/1762] D loss: 1.3670, G loss: 0.7061\n",
      "[884/1762] D loss: 1.3797, G loss: 0.7462\n",
      "[964/1762] D loss: 1.3838, G loss: 0.7455\n",
      "[1044/1762] D loss: 1.4650, G loss: 0.7044\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.7105\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.7261\n",
      "[1284/1762] D loss: 1.6852, G loss: 0.8630\n",
      "[1364/1762] D loss: 1.3651, G loss: 0.7409\n",
      "[1444/1762] D loss: 1.4190, G loss: 0.6949\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6923\n",
      "[1604/1762] D loss: 1.3810, G loss: 0.7446\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.7216\n",
      "[1762/1762] D loss: 1.6425, G loss: 0.9323\n",
      "train error: \n",
      " D loss: 1.395913, G loss: 1.102777, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368062, G loss: 1.122253, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4393, G loss: 0.6349\n",
      "[84/1762] D loss: 1.4996, G loss: 0.7062\n",
      "[164/1762] D loss: 0.5370, G loss: 1.7528\n",
      "[244/1762] D loss: 1.4930, G loss: 0.7423\n",
      "[324/1762] D loss: 1.3968, G loss: 0.7565\n",
      "[404/1762] D loss: 1.3921, G loss: 0.6857\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6945\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7065\n",
      "[644/1762] D loss: 1.3882, G loss: 0.6977\n",
      "[724/1762] D loss: 1.3939, G loss: 0.6736\n",
      "[804/1762] D loss: 1.0153, G loss: 1.4603\n",
      "[884/1762] D loss: 1.3918, G loss: 0.6730\n",
      "[964/1762] D loss: 1.0353, G loss: 1.3326\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.6847\n",
      "[1124/1762] D loss: 0.5815, G loss: 1.5248\n",
      "[1204/1762] D loss: 1.4319, G loss: 0.5733\n",
      "[1284/1762] D loss: 1.3854, G loss: 0.7018\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.7141\n",
      "[1444/1762] D loss: 1.4021, G loss: 0.7501\n",
      "[1524/1762] D loss: 1.5612, G loss: 0.7142\n",
      "[1604/1762] D loss: 1.3997, G loss: 0.7067\n",
      "[1684/1762] D loss: 1.3914, G loss: 0.7300\n",
      "[1762/1762] D loss: 1.3854, G loss: 0.6986\n",
      "train error: \n",
      " D loss: 1.272766, G loss: 0.854548, D accuracy: 61.1%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.248551, G loss: 0.901722, D accuracy: 61.3%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.7374\n",
      "[84/1762] D loss: 1.3705, G loss: 1.1327\n",
      "[164/1762] D loss: 1.3930, G loss: 0.6870\n",
      "[244/1762] D loss: 0.4830, G loss: 1.5796\n",
      "[324/1762] D loss: 1.3719, G loss: 0.7105\n",
      "[404/1762] D loss: 0.1679, G loss: 2.9496\n",
      "[484/1762] D loss: 0.4373, G loss: 1.7096\n",
      "[564/1762] D loss: 1.4408, G loss: 0.7543\n",
      "[644/1762] D loss: 1.3899, G loss: 0.7023\n",
      "[724/1762] D loss: 1.4428, G loss: 0.6934\n",
      "[804/1762] D loss: 0.6277, G loss: 1.3617\n",
      "[884/1762] D loss: 0.3857, G loss: 1.9809\n",
      "[964/1762] D loss: 1.3888, G loss: 0.6877\n",
      "[1044/1762] D loss: 0.1424, G loss: 2.8402\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.6994\n",
      "[1204/1762] D loss: 0.4574, G loss: 1.8828\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6842\n",
      "[1364/1762] D loss: 1.3353, G loss: 1.0571\n",
      "[1444/1762] D loss: 1.4966, G loss: 0.8338\n",
      "[1524/1762] D loss: 0.2558, G loss: 2.1861\n",
      "[1604/1762] D loss: 0.2223, G loss: 2.3169\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.6706\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6941\n",
      "train error: \n",
      " D loss: 1.340960, G loss: 1.068393, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308216, G loss: 1.115729, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2075, G loss: 2.1101\n",
      "[84/1762] D loss: 1.3016, G loss: 0.8474\n",
      "[164/1762] D loss: 1.3978, G loss: 0.7133\n",
      "[244/1762] D loss: 1.4208, G loss: 0.6869\n",
      "[324/1762] D loss: 1.4029, G loss: 0.6607\n",
      "[404/1762] D loss: 1.4123, G loss: 0.6634\n",
      "[484/1762] D loss: 0.3772, G loss: 2.0377\n",
      "[564/1762] D loss: 0.2737, G loss: 2.1678\n",
      "[644/1762] D loss: 1.3962, G loss: 0.6806\n",
      "[724/1762] D loss: 1.4004, G loss: 0.6615\n",
      "[804/1762] D loss: 1.3925, G loss: 0.7459\n",
      "[884/1762] D loss: 1.3904, G loss: 0.6928\n",
      "[964/1762] D loss: 1.3926, G loss: 0.7474\n",
      "[1044/1762] D loss: 0.0783, G loss: 2.8379\n",
      "[1124/1762] D loss: 1.3988, G loss: 0.6682\n",
      "[1204/1762] D loss: 1.4300, G loss: 0.5878\n",
      "[1284/1762] D loss: 1.4056, G loss: 0.6359\n",
      "[1364/1762] D loss: 1.3857, G loss: 0.7041\n",
      "[1444/1762] D loss: 1.4056, G loss: 0.6909\n",
      "[1524/1762] D loss: 1.3967, G loss: 0.7127\n",
      "[1604/1762] D loss: 0.2711, G loss: 2.4473\n",
      "[1684/1762] D loss: 0.0714, G loss: 3.6686\n",
      "[1762/1762] D loss: 1.4264, G loss: 0.7025\n",
      "train error: \n",
      " D loss: 1.297010, G loss: 1.001373, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272473, G loss: 1.070817, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4214, G loss: 0.7387\n",
      "[84/1762] D loss: 1.4006, G loss: 0.7113\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6950\n",
      "[244/1762] D loss: 1.0787, G loss: 1.4589\n",
      "[324/1762] D loss: 1.4099, G loss: 0.5941\n",
      "[404/1762] D loss: 1.4055, G loss: 0.7259\n",
      "[484/1762] D loss: 1.2217, G loss: 0.9488\n",
      "[564/1762] D loss: 1.3948, G loss: 0.6365\n",
      "[644/1762] D loss: 1.4076, G loss: 0.8259\n",
      "[724/1762] D loss: 1.8496, G loss: 0.5701\n",
      "[804/1762] D loss: 0.2802, G loss: 2.8419\n",
      "[884/1762] D loss: 1.3968, G loss: 0.5559\n",
      "[964/1762] D loss: 1.3992, G loss: 0.7624\n",
      "[1044/1762] D loss: 1.3674, G loss: 0.5889\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.6470\n",
      "[1204/1762] D loss: 1.3956, G loss: 0.6529\n",
      "[1284/1762] D loss: 1.6878, G loss: 0.6207\n",
      "[1364/1762] D loss: 1.3386, G loss: 0.5761\n",
      "[1444/1762] D loss: 1.3931, G loss: 0.6699\n",
      "[1524/1762] D loss: 1.3954, G loss: 0.6260\n",
      "[1604/1762] D loss: 1.5011, G loss: 0.7506\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7061\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.7204\n",
      "train error: \n",
      " D loss: 1.298160, G loss: 0.939505, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266143, G loss: 1.003966, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3328, G loss: 2.2113\n",
      "[84/1762] D loss: 0.3764, G loss: 2.4023\n",
      "[164/1762] D loss: 1.3940, G loss: 0.6764\n",
      "[244/1762] D loss: 1.2037, G loss: 1.0971\n",
      "[324/1762] D loss: 0.0789, G loss: 3.6139\n",
      "[404/1762] D loss: 1.4116, G loss: 0.7118\n",
      "[484/1762] D loss: 1.3997, G loss: 0.7186\n",
      "[564/1762] D loss: 1.3964, G loss: 0.7143\n",
      "[644/1762] D loss: 1.3906, G loss: 0.6791\n",
      "[724/1762] D loss: 0.4070, G loss: 2.0031\n",
      "[804/1762] D loss: 1.3914, G loss: 0.7003\n",
      "[884/1762] D loss: 1.5335, G loss: 0.7210\n",
      "[964/1762] D loss: 1.3985, G loss: 0.6850\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.6890\n",
      "[1124/1762] D loss: 1.4108, G loss: 0.6830\n",
      "[1204/1762] D loss: 1.3964, G loss: 0.6924\n",
      "[1284/1762] D loss: 1.3978, G loss: 0.6892\n",
      "[1364/1762] D loss: 1.3941, G loss: 0.6645\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.7673\n",
      "[1524/1762] D loss: 1.4838, G loss: 0.7350\n",
      "[1604/1762] D loss: 0.0647, G loss: 3.2426\n",
      "[1684/1762] D loss: 1.3945, G loss: 0.6985\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6664\n",
      "train error: \n",
      " D loss: 1.305866, G loss: 0.787830, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293788, G loss: 0.803955, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3956, G loss: 0.6834\n",
      "[84/1762] D loss: 1.3901, G loss: 0.6302\n",
      "[164/1762] D loss: 1.3965, G loss: 0.6548\n",
      "[244/1762] D loss: 0.4043, G loss: 2.7467\n",
      "[324/1762] D loss: 1.3977, G loss: 0.6331\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6999\n",
      "[484/1762] D loss: 1.3947, G loss: 0.6299\n",
      "[564/1762] D loss: 1.4136, G loss: 0.6106\n",
      "[644/1762] D loss: 1.2596, G loss: 0.9056\n",
      "[724/1762] D loss: 1.3859, G loss: 0.6877\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7056\n",
      "[884/1762] D loss: 1.4014, G loss: 0.7499\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7037\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.7134\n",
      "[1124/1762] D loss: 0.1628, G loss: 2.6040\n",
      "[1204/1762] D loss: 1.3951, G loss: 0.6907\n",
      "[1284/1762] D loss: 0.3045, G loss: 2.5719\n",
      "[1364/1762] D loss: 0.1384, G loss: 2.9569\n",
      "[1444/1762] D loss: 1.4510, G loss: 0.6756\n",
      "[1524/1762] D loss: 1.3985, G loss: 0.6717\n",
      "[1604/1762] D loss: 1.4730, G loss: 1.4229\n",
      "[1684/1762] D loss: 0.9677, G loss: 2.0410\n",
      "[1762/1762] D loss: 1.4323, G loss: 0.5267\n",
      "train error: \n",
      " D loss: 1.348685, G loss: 0.901290, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315107, G loss: 1.004427, D accuracy: 55.9%, cell accuracy: 99.4%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4302, G loss: 0.6133\n",
      "[84/1762] D loss: 0.5047, G loss: 1.9061\n",
      "[164/1762] D loss: 0.4460, G loss: 3.5298\n",
      "[244/1762] D loss: 0.3182, G loss: 2.7738\n",
      "[324/1762] D loss: 0.2440, G loss: 2.5183\n",
      "[404/1762] D loss: 0.3506, G loss: 2.4743\n",
      "[484/1762] D loss: 0.2466, G loss: 2.6053\n",
      "[564/1762] D loss: 0.3527, G loss: 2.3177\n",
      "[644/1762] D loss: 1.3911, G loss: 0.6656\n",
      "[724/1762] D loss: 0.3412, G loss: 2.4722\n",
      "[804/1762] D loss: 1.4003, G loss: 0.6323\n",
      "[884/1762] D loss: 1.5021, G loss: 0.5594\n",
      "[964/1762] D loss: 1.3932, G loss: 0.6578\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6642\n",
      "[1124/1762] D loss: 0.0799, G loss: 3.7735\n",
      "[1204/1762] D loss: 0.1570, G loss: 3.1321\n",
      "[1284/1762] D loss: 1.5065, G loss: 0.7020\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.6555\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.7153\n",
      "[1524/1762] D loss: 0.1225, G loss: 3.2144\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.6552\n",
      "[1684/1762] D loss: 1.4063, G loss: 0.6747\n",
      "[1762/1762] D loss: 0.0625, G loss: 4.2398\n",
      "train error: \n",
      " D loss: 2.615171, G loss: 0.235584, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.592640, G loss: 0.300380, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.6748\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6858\n",
      "[164/1762] D loss: 1.4837, G loss: 0.6404\n",
      "[244/1762] D loss: 1.3900, G loss: 0.6658\n",
      "[324/1762] D loss: 1.4483, G loss: 0.6070\n",
      "[404/1762] D loss: 1.3848, G loss: 0.6874\n",
      "[484/1762] D loss: 1.3936, G loss: 0.7612\n",
      "[564/1762] D loss: 1.3935, G loss: 0.6866\n",
      "[644/1762] D loss: 1.4224, G loss: 0.6612\n",
      "[724/1762] D loss: 1.3859, G loss: 0.6739\n",
      "[804/1762] D loss: 1.3985, G loss: 0.6237\n",
      "[884/1762] D loss: 0.2142, G loss: 2.6556\n",
      "[964/1762] D loss: 1.3927, G loss: 0.6367\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7097\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.6419\n",
      "[1204/1762] D loss: 0.2846, G loss: 2.3841\n",
      "[1284/1762] D loss: 1.3971, G loss: 0.6223\n",
      "[1364/1762] D loss: 0.1563, G loss: 3.1120\n",
      "[1444/1762] D loss: 1.3902, G loss: 0.7163\n",
      "[1524/1762] D loss: 1.3955, G loss: 0.6365\n",
      "[1604/1762] D loss: 1.4118, G loss: 0.6188\n",
      "[1684/1762] D loss: 0.0855, G loss: 3.5417\n",
      "[1762/1762] D loss: 0.1276, G loss: 2.9275\n",
      "train error: \n",
      " D loss: 1.342109, G loss: 0.784163, D accuracy: 57.1%, cell accuracy: 99.6%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318797, G loss: 0.824521, D accuracy: 57.0%, cell accuracy: 99.5%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4422, G loss: 1.3495\n",
      "[84/1762] D loss: 1.2899, G loss: 1.0630\n",
      "[164/1762] D loss: 1.4103, G loss: 0.6832\n",
      "[244/1762] D loss: 1.4560, G loss: 0.7789\n",
      "[324/1762] D loss: 1.3937, G loss: 0.6859\n",
      "[404/1762] D loss: 1.4143, G loss: 0.5563\n",
      "[484/1762] D loss: 1.5871, G loss: 0.6107\n",
      "[564/1762] D loss: 0.2868, G loss: 2.5819\n",
      "[644/1762] D loss: 1.4397, G loss: 0.7475\n",
      "[724/1762] D loss: 0.0792, G loss: 3.8865\n",
      "[804/1762] D loss: 0.1392, G loss: 3.1348\n",
      "[884/1762] D loss: 1.6001, G loss: 0.4991\n",
      "[964/1762] D loss: 0.1817, G loss: 3.6988\n",
      "[1044/1762] D loss: 0.1505, G loss: 3.2739\n",
      "[1124/1762] D loss: 1.4397, G loss: 0.5163\n",
      "[1204/1762] D loss: 1.4036, G loss: 0.6529\n",
      "[1284/1762] D loss: 1.1859, G loss: 1.0701\n",
      "[1364/1762] D loss: 1.4164, G loss: 0.6395\n",
      "[1444/1762] D loss: 1.4068, G loss: 0.6509\n",
      "[1524/1762] D loss: 1.4194, G loss: 0.7258\n",
      "[1604/1762] D loss: 1.4340, G loss: 0.5100\n",
      "[1684/1762] D loss: 1.4105, G loss: 0.5564\n",
      "[1762/1762] D loss: 1.4019, G loss: 0.5883\n",
      "train error: \n",
      " D loss: 1.291404, G loss: 0.912413, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264714, G loss: 1.002510, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8413, G loss: 2.5991\n",
      "[84/1762] D loss: 1.4445, G loss: 0.5213\n",
      "[164/1762] D loss: 0.4384, G loss: 2.2427\n",
      "[244/1762] D loss: 1.4112, G loss: 0.5737\n",
      "[324/1762] D loss: 0.0701, G loss: 4.0770\n",
      "[404/1762] D loss: 1.4308, G loss: 0.5865\n",
      "[484/1762] D loss: 1.3949, G loss: 0.6276\n",
      "[564/1762] D loss: 1.3889, G loss: 0.7047\n",
      "[644/1762] D loss: 1.3956, G loss: 0.6210\n",
      "[724/1762] D loss: 1.4253, G loss: 0.5244\n",
      "[804/1762] D loss: 1.3887, G loss: 0.6512\n",
      "[884/1762] D loss: 1.4178, G loss: 0.7097\n",
      "[964/1762] D loss: 0.2363, G loss: 3.1205\n",
      "[1044/1762] D loss: 1.3900, G loss: 0.7053\n",
      "[1124/1762] D loss: 0.1209, G loss: 3.4085\n",
      "[1204/1762] D loss: 1.3922, G loss: 0.6655\n",
      "[1284/1762] D loss: 0.3250, G loss: 2.4758\n",
      "[1364/1762] D loss: 0.1034, G loss: 3.4639\n",
      "[1444/1762] D loss: 0.1398, G loss: 3.3964\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6860\n",
      "[1604/1762] D loss: 1.3665, G loss: 0.6649\n",
      "[1684/1762] D loss: 0.2279, G loss: 3.1053\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6828\n",
      "train error: \n",
      " D loss: 1.289631, G loss: 1.013821, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261223, G loss: 1.131122, D accuracy: 56.4%, cell accuracy: 99.6%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.6420\n",
      "[84/1762] D loss: 1.3946, G loss: 0.6287\n",
      "[164/1762] D loss: 0.2730, G loss: 3.1872\n",
      "[244/1762] D loss: 1.3924, G loss: 0.6510\n",
      "[324/1762] D loss: 0.1157, G loss: 3.5233\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6605\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7236\n",
      "[564/1762] D loss: 1.3891, G loss: 0.7125\n",
      "[644/1762] D loss: 0.0967, G loss: 3.7871\n",
      "[724/1762] D loss: 0.0896, G loss: 3.5495\n",
      "[804/1762] D loss: 0.0659, G loss: 3.8605\n",
      "[884/1762] D loss: 1.3887, G loss: 0.6752\n",
      "[964/1762] D loss: 1.3918, G loss: 0.6578\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.7005\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.6734\n",
      "[1204/1762] D loss: 1.3916, G loss: 0.6619\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.7084\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.7178\n",
      "[1444/1762] D loss: 1.3964, G loss: 0.6511\n",
      "[1524/1762] D loss: 1.4054, G loss: 0.6541\n",
      "[1604/1762] D loss: 0.1523, G loss: 3.1218\n",
      "[1684/1762] D loss: 0.9315, G loss: 2.6884\n",
      "[1762/1762] D loss: 0.0155, G loss: 4.8486\n",
      "train error: \n",
      " D loss: 2.261298, G loss: 0.292420, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 79.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.204398, G loss: 0.399934, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4029, G loss: 0.6056\n",
      "[84/1762] D loss: 1.0184, G loss: 1.6226\n",
      "[164/1762] D loss: 1.4057, G loss: 0.6198\n",
      "[244/1762] D loss: 1.7117, G loss: 0.5471\n",
      "[324/1762] D loss: 1.2337, G loss: 1.0332\n",
      "[404/1762] D loss: 1.2001, G loss: 0.8493\n",
      "[484/1762] D loss: 1.3377, G loss: 0.7462\n",
      "[564/1762] D loss: 1.4683, G loss: 0.4832\n",
      "[644/1762] D loss: 1.4101, G loss: 0.6343\n",
      "[724/1762] D loss: 0.0746, G loss: 3.7360\n",
      "[804/1762] D loss: 1.3915, G loss: 0.6264\n",
      "[884/1762] D loss: 0.1048, G loss: 3.1517\n",
      "[964/1762] D loss: 1.3965, G loss: 0.6227\n",
      "[1044/1762] D loss: 0.1521, G loss: 3.2940\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6682\n",
      "[1204/1762] D loss: 1.3841, G loss: 0.6851\n",
      "[1284/1762] D loss: 0.1851, G loss: 3.6264\n",
      "[1364/1762] D loss: 1.4901, G loss: 0.6015\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6930\n",
      "[1524/1762] D loss: 1.3928, G loss: 0.7145\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.6555\n",
      "[1684/1762] D loss: 0.2985, G loss: 2.3921\n",
      "[1762/1762] D loss: 1.4635, G loss: 0.6842\n",
      "train error: \n",
      " D loss: 1.298441, G loss: 0.925646, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269070, G loss: 1.005039, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4361, G loss: 0.6035\n",
      "[84/1762] D loss: 1.5210, G loss: 0.6682\n",
      "[164/1762] D loss: 1.3893, G loss: 0.6513\n",
      "[244/1762] D loss: 1.3850, G loss: 0.6832\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6808\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7007\n",
      "[484/1762] D loss: 0.1336, G loss: 3.3820\n",
      "[564/1762] D loss: 1.3944, G loss: 0.6382\n",
      "[644/1762] D loss: 0.6208, G loss: 1.5099\n",
      "[724/1762] D loss: 1.2660, G loss: 0.9639\n",
      "[804/1762] D loss: 1.3898, G loss: 0.6809\n",
      "[884/1762] D loss: 1.3863, G loss: 0.7114\n",
      "[964/1762] D loss: 1.3947, G loss: 0.6632\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6948\n",
      "[1124/1762] D loss: 1.3973, G loss: 0.7527\n",
      "[1204/1762] D loss: 0.0556, G loss: 3.2319\n",
      "[1284/1762] D loss: 0.0064, G loss: 6.0375\n",
      "[1364/1762] D loss: 1.0428, G loss: 2.0905\n",
      "[1444/1762] D loss: 1.4477, G loss: 0.6563\n",
      "[1524/1762] D loss: 1.3955, G loss: 0.6610\n",
      "[1604/1762] D loss: 1.4096, G loss: 0.6101\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.5620\n",
      "[1762/1762] D loss: 1.3978, G loss: 0.6227\n",
      "train error: \n",
      " D loss: 1.296911, G loss: 0.837562, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268745, G loss: 0.935301, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.6447\n",
      "[84/1762] D loss: 1.3888, G loss: 0.7138\n",
      "[164/1762] D loss: 1.3972, G loss: 0.6669\n",
      "[244/1762] D loss: 0.2330, G loss: 2.9731\n",
      "[324/1762] D loss: 0.1985, G loss: 3.1885\n",
      "[404/1762] D loss: 1.3842, G loss: 0.8445\n",
      "[484/1762] D loss: 1.3822, G loss: 0.8222\n",
      "[564/1762] D loss: 1.3860, G loss: 0.6758\n",
      "[644/1762] D loss: 1.4022, G loss: 0.7009\n",
      "[724/1762] D loss: 0.0227, G loss: 4.4037\n",
      "[804/1762] D loss: 0.1813, G loss: 3.2367\n",
      "[884/1762] D loss: 0.0550, G loss: 4.2399\n",
      "[964/1762] D loss: 0.1507, G loss: 3.6066\n",
      "[1044/1762] D loss: 1.3973, G loss: 0.6443\n",
      "[1124/1762] D loss: 1.3976, G loss: 0.6331\n",
      "[1204/1762] D loss: 1.3994, G loss: 0.6304\n",
      "[1284/1762] D loss: 1.2500, G loss: 1.0425\n",
      "[1364/1762] D loss: 1.4255, G loss: 0.5909\n",
      "[1444/1762] D loss: 1.5153, G loss: 0.7427\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.6812\n",
      "[1604/1762] D loss: 1.3249, G loss: 0.9222\n",
      "[1684/1762] D loss: 0.1383, G loss: 3.7232\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6703\n",
      "train error: \n",
      " D loss: 1.305077, G loss: 1.094008, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276245, G loss: 1.196788, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.6825\n",
      "[84/1762] D loss: 1.3905, G loss: 0.6513\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6531\n",
      "[244/1762] D loss: 1.4095, G loss: 0.6629\n",
      "[324/1762] D loss: 1.4210, G loss: 0.6834\n",
      "[404/1762] D loss: 1.4242, G loss: 0.6870\n",
      "[484/1762] D loss: 1.3881, G loss: 0.6690\n",
      "[564/1762] D loss: 1.3897, G loss: 0.6803\n",
      "[644/1762] D loss: 1.3984, G loss: 0.7532\n",
      "[724/1762] D loss: 1.4327, G loss: 0.6745\n",
      "[804/1762] D loss: 0.0751, G loss: 3.6068\n",
      "[884/1762] D loss: 0.0320, G loss: 4.0394\n",
      "[964/1762] D loss: 1.3510, G loss: 1.1251\n",
      "[1044/1762] D loss: 1.1732, G loss: 1.2644\n",
      "[1124/1762] D loss: 1.3242, G loss: 0.6974\n",
      "[1204/1762] D loss: 1.7368, G loss: 0.6550\n",
      "[1284/1762] D loss: 1.3986, G loss: 0.7028\n",
      "[1364/1762] D loss: 1.4322, G loss: 0.6122\n",
      "[1444/1762] D loss: 0.6880, G loss: 3.6314\n",
      "[1524/1762] D loss: 0.0162, G loss: 4.6534\n",
      "[1604/1762] D loss: 1.3926, G loss: 0.6530\n",
      "[1684/1762] D loss: 1.2636, G loss: 0.7378\n",
      "[1762/1762] D loss: 1.3851, G loss: 0.6882\n",
      "train error: \n",
      " D loss: 1.307012, G loss: 1.071463, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274885, G loss: 1.178222, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3906, G loss: 0.7601\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6862\n",
      "[164/1762] D loss: 1.3944, G loss: 0.6502\n",
      "[244/1762] D loss: 0.1664, G loss: 3.5362\n",
      "[324/1762] D loss: 1.3963, G loss: 0.6509\n",
      "[404/1762] D loss: 1.3987, G loss: 0.6160\n",
      "[484/1762] D loss: 1.3886, G loss: 0.7274\n",
      "[564/1762] D loss: 0.3926, G loss: 2.2756\n",
      "[644/1762] D loss: 1.5404, G loss: 0.7668\n",
      "[724/1762] D loss: 1.3561, G loss: 0.7695\n",
      "[804/1762] D loss: 1.4245, G loss: 0.7575\n",
      "[884/1762] D loss: 0.4264, G loss: 2.0052\n",
      "[964/1762] D loss: 0.4226, G loss: 1.9584\n",
      "[1044/1762] D loss: 1.5070, G loss: 0.5946\n",
      "[1124/1762] D loss: 1.4028, G loss: 0.6604\n",
      "[1204/1762] D loss: 0.0995, G loss: 3.6110\n",
      "[1284/1762] D loss: 1.3888, G loss: 0.6814\n",
      "[1364/1762] D loss: 1.4139, G loss: 0.5892\n",
      "[1444/1762] D loss: 1.3966, G loss: 0.7217\n",
      "[1524/1762] D loss: 0.1731, G loss: 3.3053\n",
      "[1604/1762] D loss: 1.3330, G loss: 0.8558\n",
      "[1684/1762] D loss: 1.3610, G loss: 0.7746\n",
      "[1762/1762] D loss: 0.0072, G loss: 5.8356\n",
      "train error: \n",
      " D loss: 1.372243, G loss: 0.789926, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333016, G loss: 0.902605, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3153, G loss: 1.0071\n",
      "[84/1762] D loss: 1.3898, G loss: 0.7164\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6713\n",
      "[244/1762] D loss: 1.4587, G loss: 0.6603\n",
      "[324/1762] D loss: 0.0375, G loss: 3.6892\n",
      "[404/1762] D loss: 0.3283, G loss: 3.4322\n",
      "[484/1762] D loss: 0.0328, G loss: 4.3295\n",
      "[564/1762] D loss: 1.3945, G loss: 0.6216\n",
      "[644/1762] D loss: 1.3851, G loss: 0.6806\n",
      "[724/1762] D loss: 1.3930, G loss: 0.7424\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6987\n",
      "[884/1762] D loss: 1.3810, G loss: 0.6812\n",
      "[964/1762] D loss: 1.4019, G loss: 0.6792\n",
      "[1044/1762] D loss: 1.3639, G loss: 0.8130\n",
      "[1124/1762] D loss: 1.4531, G loss: 0.6341\n",
      "[1204/1762] D loss: 0.1043, G loss: 3.2306\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.6623\n",
      "[1364/1762] D loss: 1.3830, G loss: 0.6691\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6628\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7105\n",
      "[1604/1762] D loss: 1.4852, G loss: 0.6376\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6787\n",
      "[1762/1762] D loss: 0.0021, G loss: 6.7429\n",
      "train error: \n",
      " D loss: 1.434005, G loss: 0.888416, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.429238, G loss: 0.951372, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3907, G loss: 0.7389\n",
      "[84/1762] D loss: 0.0656, G loss: 4.4884\n",
      "[164/1762] D loss: 1.5347, G loss: 0.6058\n",
      "[244/1762] D loss: 1.3811, G loss: 0.6779\n",
      "[324/1762] D loss: 0.1484, G loss: 3.7649\n",
      "[404/1762] D loss: 0.0343, G loss: 4.2508\n",
      "[484/1762] D loss: 1.3951, G loss: 0.6318\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6611\n",
      "[644/1762] D loss: 1.3918, G loss: 0.6446\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6809\n",
      "[804/1762] D loss: 1.4533, G loss: 0.7033\n",
      "[884/1762] D loss: 0.0952, G loss: 3.8173\n",
      "[964/1762] D loss: 1.4189, G loss: 0.6804\n",
      "[1044/1762] D loss: 1.3924, G loss: 0.6455\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6781\n",
      "[1204/1762] D loss: 0.0957, G loss: 3.8643\n",
      "[1284/1762] D loss: 1.8250, G loss: 0.5999\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.6938\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7062\n",
      "[1524/1762] D loss: 0.0358, G loss: 4.2911\n",
      "[1604/1762] D loss: 1.3951, G loss: 0.6536\n",
      "[1684/1762] D loss: 0.0026, G loss: 6.4010\n",
      "[1762/1762] D loss: 0.6383, G loss: 4.3130\n",
      "train error: \n",
      " D loss: 1.426650, G loss: 2.942628, D accuracy: 53.3%, cell accuracy: 98.7%, board accuracy: 14.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.437397, G loss: 2.959734, D accuracy: 53.9%, cell accuracy: 98.8%, board accuracy: 18.6% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6356, G loss: 4.0778\n",
      "[84/1762] D loss: 1.4128, G loss: 0.5181\n",
      "[164/1762] D loss: 1.3924, G loss: 0.7551\n",
      "[244/1762] D loss: 1.3783, G loss: 0.7008\n",
      "[324/1762] D loss: 1.3977, G loss: 0.6089\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6669\n",
      "[484/1762] D loss: 0.1480, G loss: 3.6190\n",
      "[564/1762] D loss: 1.3859, G loss: 0.6818\n",
      "[644/1762] D loss: 1.2094, G loss: 3.2492\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6780\n",
      "[804/1762] D loss: 1.3620, G loss: 0.6820\n",
      "[884/1762] D loss: 0.2360, G loss: 4.4119\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6460\n",
      "[1044/1762] D loss: 1.3700, G loss: 0.6911\n",
      "[1124/1762] D loss: 1.1995, G loss: 1.6379\n",
      "[1204/1762] D loss: 1.3802, G loss: 0.6953\n",
      "[1284/1762] D loss: 0.9458, G loss: 3.9373\n",
      "[1364/1762] D loss: 0.0307, G loss: 4.6810\n",
      "[1444/1762] D loss: 1.3773, G loss: 0.6861\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.7127\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6609\n",
      "[1684/1762] D loss: 1.3909, G loss: 0.7184\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.6534\n",
      "train error: \n",
      " D loss: 1.287640, G loss: 1.014820, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255460, G loss: 1.187316, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3948, G loss: 0.7054\n",
      "[84/1762] D loss: 0.2212, G loss: 4.1340\n",
      "[164/1762] D loss: 1.3861, G loss: 0.7096\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7274\n",
      "[324/1762] D loss: 1.4132, G loss: 0.7375\n",
      "[404/1762] D loss: 1.3952, G loss: 0.6393\n",
      "[484/1762] D loss: 0.1284, G loss: 5.1825\n",
      "[564/1762] D loss: 0.2303, G loss: 2.9566\n",
      "[644/1762] D loss: 1.3632, G loss: 0.8628\n",
      "[724/1762] D loss: 1.3999, G loss: 0.7153\n",
      "[804/1762] D loss: 1.4007, G loss: 0.6539\n",
      "[884/1762] D loss: 1.4137, G loss: 0.6922\n",
      "[964/1762] D loss: 0.4507, G loss: 3.1828\n",
      "[1044/1762] D loss: 0.6393, G loss: 1.2434\n",
      "[1124/1762] D loss: 0.2356, G loss: 3.3454\n",
      "[1204/1762] D loss: 1.3939, G loss: 0.7120\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.7423\n",
      "[1364/1762] D loss: 1.4780, G loss: 0.6495\n",
      "[1444/1762] D loss: 1.3944, G loss: 0.6393\n",
      "[1524/1762] D loss: 1.4390, G loss: 0.5681\n",
      "[1604/1762] D loss: 1.3923, G loss: 0.6782\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6888\n",
      "[1762/1762] D loss: 1.3849, G loss: 0.6959\n",
      "train error: \n",
      " D loss: 1.293975, G loss: 1.039846, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267315, G loss: 1.186859, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.6548\n",
      "[84/1762] D loss: 1.4819, G loss: 0.6470\n",
      "[164/1762] D loss: 0.0843, G loss: 3.7735\n",
      "[244/1762] D loss: 0.0255, G loss: 4.8731\n",
      "[324/1762] D loss: 1.4825, G loss: 0.6872\n",
      "[404/1762] D loss: 1.5878, G loss: 0.5571\n",
      "[484/1762] D loss: 0.1025, G loss: 3.3769\n",
      "[564/1762] D loss: 1.3910, G loss: 0.6490\n",
      "[644/1762] D loss: 1.3853, G loss: 0.6758\n",
      "[724/1762] D loss: 0.0197, G loss: 4.6435\n",
      "[804/1762] D loss: 1.3745, G loss: 0.7026\n",
      "[884/1762] D loss: 1.4464, G loss: 0.7232\n",
      "[964/1762] D loss: 1.3995, G loss: 0.7267\n",
      "[1044/1762] D loss: 1.3354, G loss: 0.8260\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.6912\n",
      "[1204/1762] D loss: 0.2083, G loss: 3.6010\n",
      "[1284/1762] D loss: 1.3855, G loss: 0.6879\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6502\n",
      "[1444/1762] D loss: 1.4427, G loss: 0.6563\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.6868\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6870\n",
      "[1684/1762] D loss: 1.3859, G loss: 0.6941\n",
      "[1762/1762] D loss: 1.4531, G loss: 0.6434\n",
      "train error: \n",
      " D loss: 1.350662, G loss: 1.215966, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321407, G loss: 1.365988, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4163, G loss: 0.7563\n",
      "[84/1762] D loss: 1.3402, G loss: 0.7652\n",
      "[164/1762] D loss: 1.1926, G loss: 0.8158\n",
      "[244/1762] D loss: 0.8755, G loss: 1.0046\n",
      "[324/1762] D loss: 0.4232, G loss: 1.5918\n",
      "[404/1762] D loss: 0.3033, G loss: 1.9723\n",
      "[484/1762] D loss: 0.6635, G loss: 2.2198\n",
      "[564/1762] D loss: 1.3317, G loss: 2.1912\n",
      "[644/1762] D loss: 0.6205, G loss: 1.1755\n",
      "[724/1762] D loss: 0.9431, G loss: 1.8360\n",
      "[804/1762] D loss: 0.8653, G loss: 1.4281\n",
      "[884/1762] D loss: 1.7473, G loss: 1.6683\n",
      "[964/1762] D loss: 1.0614, G loss: 1.2866\n",
      "[1044/1762] D loss: 1.2790, G loss: 2.3597\n",
      "[1124/1762] D loss: 1.2840, G loss: 0.9915\n",
      "[1204/1762] D loss: 1.4009, G loss: 0.9885\n",
      "[1284/1762] D loss: 1.3565, G loss: 1.0606\n",
      "[1364/1762] D loss: 1.2828, G loss: 0.9217\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.6836\n",
      "[1524/1762] D loss: 1.3627, G loss: 0.7249\n",
      "[1604/1762] D loss: 1.2036, G loss: 0.8238\n",
      "[1684/1762] D loss: 1.2038, G loss: 0.8221\n",
      "[1762/1762] D loss: 1.2316, G loss: 0.6636\n",
      "train error: \n",
      " D loss: 1.347041, G loss: 0.578990, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 77.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341911, G loss: 0.594406, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 73.4% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2229, G loss: 0.8854\n",
      "[84/1762] D loss: 1.3234, G loss: 0.8112\n",
      "[164/1762] D loss: 1.2033, G loss: 1.0064\n",
      "[244/1762] D loss: 1.3216, G loss: 0.7590\n",
      "[324/1762] D loss: 1.3816, G loss: 0.8304\n",
      "[404/1762] D loss: 1.4397, G loss: 0.8827\n",
      "[484/1762] D loss: 1.1157, G loss: 1.0286\n",
      "[564/1762] D loss: 1.3613, G loss: 0.7987\n",
      "[644/1762] D loss: 1.2780, G loss: 0.6870\n",
      "[724/1762] D loss: 1.3991, G loss: 0.4703\n",
      "[804/1762] D loss: 1.3784, G loss: 0.8153\n",
      "[884/1762] D loss: 1.0596, G loss: 0.9130\n",
      "[964/1762] D loss: 1.3732, G loss: 0.6108\n",
      "[1044/1762] D loss: 1.3986, G loss: 0.6318\n",
      "[1124/1762] D loss: 1.3725, G loss: 0.6809\n",
      "[1204/1762] D loss: 1.3774, G loss: 0.6061\n",
      "[1284/1762] D loss: 1.1339, G loss: 1.1933\n",
      "[1364/1762] D loss: 1.4266, G loss: 0.6919\n",
      "[1444/1762] D loss: 1.5235, G loss: 0.3990\n",
      "[1524/1762] D loss: 1.3975, G loss: 0.6593\n",
      "[1604/1762] D loss: 1.4147, G loss: 0.6352\n",
      "[1684/1762] D loss: 1.4388, G loss: 0.6991\n",
      "[1762/1762] D loss: 1.3822, G loss: 0.3956\n",
      "train error: \n",
      " D loss: 1.345753, G loss: 0.724315, D accuracy: 50.3%, cell accuracy: 99.6%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331582, G loss: 0.736733, D accuracy: 51.9%, cell accuracy: 99.5%, board accuracy: 58.6% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9986, G loss: 1.2375\n",
      "[84/1762] D loss: 1.4803, G loss: 1.0509\n",
      "[164/1762] D loss: 1.7743, G loss: 0.7491\n",
      "[244/1762] D loss: 1.2022, G loss: 0.9699\n",
      "[324/1762] D loss: 1.4130, G loss: 0.7023\n",
      "[404/1762] D loss: 1.4465, G loss: 0.7760\n",
      "[484/1762] D loss: 0.8595, G loss: 1.2836\n",
      "[564/1762] D loss: 1.3791, G loss: 0.7405\n",
      "[644/1762] D loss: 1.5500, G loss: 0.9333\n",
      "[724/1762] D loss: 1.3835, G loss: 0.7342\n",
      "[804/1762] D loss: 1.3885, G loss: 0.7087\n",
      "[884/1762] D loss: 1.4124, G loss: 0.7027\n",
      "[964/1762] D loss: 1.3880, G loss: 0.7286\n",
      "[1044/1762] D loss: 1.4093, G loss: 0.7945\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7006\n",
      "[1204/1762] D loss: 1.3792, G loss: 0.7027\n",
      "[1284/1762] D loss: 1.1434, G loss: 0.8674\n",
      "[1364/1762] D loss: 1.0657, G loss: 1.4057\n",
      "[1444/1762] D loss: 1.5342, G loss: 0.7084\n",
      "[1524/1762] D loss: 0.8625, G loss: 1.1869\n",
      "[1604/1762] D loss: 2.3860, G loss: 0.9048\n",
      "[1684/1762] D loss: 1.3705, G loss: 0.9097\n",
      "[1762/1762] D loss: 1.4123, G loss: 0.5488\n",
      "train error: \n",
      " D loss: 1.351320, G loss: 0.682868, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348347, G loss: 0.692139, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3557, G loss: 0.8105\n",
      "[84/1762] D loss: 1.0511, G loss: 0.9668\n",
      "[164/1762] D loss: 1.3819, G loss: 0.7168\n",
      "[244/1762] D loss: 0.9017, G loss: 1.1527\n",
      "[324/1762] D loss: 1.3600, G loss: 0.7085\n",
      "[404/1762] D loss: 1.4043, G loss: 0.6887\n",
      "[484/1762] D loss: 1.4785, G loss: 0.6651\n",
      "[564/1762] D loss: 1.3681, G loss: 0.6830\n",
      "[644/1762] D loss: 1.2611, G loss: 0.7067\n",
      "[724/1762] D loss: 1.1238, G loss: 0.9250\n",
      "[804/1762] D loss: 1.3763, G loss: 0.7132\n",
      "[884/1762] D loss: 1.3984, G loss: 0.6826\n",
      "[964/1762] D loss: 1.1618, G loss: 0.9351\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7075\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6793\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.6508\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7010\n",
      "[1364/1762] D loss: 1.0299, G loss: 0.9694\n",
      "[1444/1762] D loss: 0.6510, G loss: 1.2885\n",
      "[1524/1762] D loss: 1.3261, G loss: 0.7805\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.6624\n",
      "[1684/1762] D loss: 1.3025, G loss: 0.6282\n",
      "[1762/1762] D loss: 1.3825, G loss: 0.5868\n",
      "train error: \n",
      " D loss: 1.204584, G loss: 0.855820, D accuracy: 69.4%, cell accuracy: 98.9%, board accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.208364, G loss: 0.872089, D accuracy: 68.4%, cell accuracy: 98.8%, board accuracy: 45.7% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2963, G loss: 0.8125\n",
      "[84/1762] D loss: 1.3981, G loss: 0.7368\n",
      "[164/1762] D loss: 1.0661, G loss: 0.7952\n",
      "[244/1762] D loss: 0.8217, G loss: 1.1520\n",
      "[324/1762] D loss: 1.3525, G loss: 0.7552\n",
      "[404/1762] D loss: 1.3733, G loss: 0.7101\n",
      "[484/1762] D loss: 1.3842, G loss: 0.6815\n",
      "[564/1762] D loss: 1.4041, G loss: 0.7102\n",
      "[644/1762] D loss: 1.4175, G loss: 0.6534\n",
      "[724/1762] D loss: 1.4299, G loss: 0.6705\n",
      "[804/1762] D loss: 1.4038, G loss: 0.8278\n",
      "[884/1762] D loss: 0.8650, G loss: 1.5120\n",
      "[964/1762] D loss: 1.4858, G loss: 0.5552\n",
      "[1044/1762] D loss: 0.8498, G loss: 1.1695\n",
      "[1124/1762] D loss: 0.8963, G loss: 1.0390\n",
      "[1204/1762] D loss: 0.9203, G loss: 1.1331\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.7361\n",
      "[1364/1762] D loss: 1.4083, G loss: 0.7012\n",
      "[1444/1762] D loss: 0.5612, G loss: 1.3608\n",
      "[1524/1762] D loss: 0.8284, G loss: 1.2111\n",
      "[1604/1762] D loss: 1.3507, G loss: 0.6792\n",
      "[1684/1762] D loss: 1.3334, G loss: 0.9106\n",
      "[1762/1762] D loss: 1.8502, G loss: 1.0855\n",
      "train error: \n",
      " D loss: 1.335356, G loss: 0.886003, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 77.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320550, G loss: 0.902862, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4669, G loss: 0.7450\n",
      "[84/1762] D loss: 1.6055, G loss: 0.8101\n",
      "[164/1762] D loss: 1.4225, G loss: 0.7542\n",
      "[244/1762] D loss: 1.4875, G loss: 0.8754\n",
      "[324/1762] D loss: 0.7112, G loss: 1.1662\n",
      "[404/1762] D loss: 1.5348, G loss: 0.6948\n",
      "[484/1762] D loss: 1.3900, G loss: 0.7056\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6913\n",
      "[644/1762] D loss: 1.3979, G loss: 0.6572\n",
      "[724/1762] D loss: 1.2625, G loss: 0.8317\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6994\n",
      "[884/1762] D loss: 1.3798, G loss: 0.6998\n",
      "[964/1762] D loss: 1.5202, G loss: 0.8556\n",
      "[1044/1762] D loss: 1.3860, G loss: 0.6384\n",
      "[1124/1762] D loss: 0.6039, G loss: 1.2526\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6840\n",
      "[1284/1762] D loss: 0.5869, G loss: 1.4324\n",
      "[1364/1762] D loss: 1.4916, G loss: 0.5913\n",
      "[1444/1762] D loss: 1.3855, G loss: 0.7020\n",
      "[1524/1762] D loss: 1.3949, G loss: 0.7162\n",
      "[1604/1762] D loss: 1.4090, G loss: 0.7622\n",
      "[1684/1762] D loss: 1.4380, G loss: 0.7035\n",
      "[1762/1762] D loss: 1.4094, G loss: 0.7253\n",
      "train error: \n",
      " D loss: 1.450996, G loss: 0.449152, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.436754, G loss: 0.460048, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.6961\n",
      "[84/1762] D loss: 1.4304, G loss: 0.7843\n",
      "[164/1762] D loss: 1.3989, G loss: 0.7176\n",
      "[244/1762] D loss: 1.4171, G loss: 0.7369\n",
      "[324/1762] D loss: 1.3984, G loss: 0.7205\n",
      "[404/1762] D loss: 1.4317, G loss: 0.8375\n",
      "[484/1762] D loss: 1.3958, G loss: 0.7388\n",
      "[564/1762] D loss: 1.3941, G loss: 0.7358\n",
      "[644/1762] D loss: 1.5104, G loss: 0.9384\n",
      "[724/1762] D loss: 0.4998, G loss: 1.1849\n",
      "[804/1762] D loss: 1.3980, G loss: 0.8865\n",
      "[884/1762] D loss: 1.4004, G loss: 0.7815\n",
      "[964/1762] D loss: 1.3956, G loss: 0.7615\n",
      "[1044/1762] D loss: 1.3981, G loss: 0.7445\n",
      "[1124/1762] D loss: 0.6038, G loss: 1.0296\n",
      "[1204/1762] D loss: 1.3974, G loss: 0.7437\n",
      "[1284/1762] D loss: 1.4310, G loss: 0.8527\n",
      "[1364/1762] D loss: 1.4856, G loss: 0.8983\n",
      "[1444/1762] D loss: 0.3798, G loss: 1.3346\n",
      "[1524/1762] D loss: 1.4273, G loss: 0.8376\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.6444\n",
      "[1684/1762] D loss: 1.3953, G loss: 0.7681\n",
      "[1762/1762] D loss: 1.4095, G loss: 0.7798\n",
      "train error: \n",
      " D loss: 1.339439, G loss: 0.626737, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318058, G loss: 0.649564, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4073, G loss: 0.8408\n",
      "[84/1762] D loss: 1.4111, G loss: 0.7737\n",
      "[164/1762] D loss: 1.4249, G loss: 0.8405\n",
      "[244/1762] D loss: 0.4455, G loss: 1.1953\n",
      "[324/1762] D loss: 1.4089, G loss: 0.8099\n",
      "[404/1762] D loss: 1.1372, G loss: 1.5342\n",
      "[484/1762] D loss: 1.3921, G loss: 0.7631\n",
      "[564/1762] D loss: 1.4241, G loss: 0.8318\n",
      "[644/1762] D loss: 1.4849, G loss: 0.9697\n",
      "[724/1762] D loss: 0.7481, G loss: 0.8835\n",
      "[804/1762] D loss: 0.6706, G loss: 0.8642\n",
      "[884/1762] D loss: 1.3757, G loss: 0.8772\n",
      "[964/1762] D loss: 0.4560, G loss: 1.2547\n",
      "[1044/1762] D loss: 1.3903, G loss: 0.7386\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.7487\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.7015\n",
      "[1284/1762] D loss: 1.4549, G loss: 0.8814\n",
      "[1364/1762] D loss: 1.4294, G loss: 0.8152\n",
      "[1444/1762] D loss: 1.4156, G loss: 0.8043\n",
      "[1524/1762] D loss: 0.4825, G loss: 1.1304\n",
      "[1604/1762] D loss: 1.3922, G loss: 0.7765\n",
      "[1684/1762] D loss: 0.4535, G loss: 1.3461\n",
      "[1762/1762] D loss: 1.3831, G loss: 0.7010\n",
      "train error: \n",
      " D loss: 1.321364, G loss: 0.753803, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301794, G loss: 0.768238, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3810, G loss: 0.7524\n",
      "[84/1762] D loss: 0.6085, G loss: 0.9876\n",
      "[164/1762] D loss: 1.3822, G loss: 0.7210\n",
      "[244/1762] D loss: 0.5259, G loss: 1.1015\n",
      "[324/1762] D loss: 0.5746, G loss: 0.9844\n",
      "[404/1762] D loss: 0.6022, G loss: 0.9513\n",
      "[484/1762] D loss: 1.3972, G loss: 0.7500\n",
      "[564/1762] D loss: 1.3888, G loss: 0.7149\n",
      "[644/1762] D loss: 1.3979, G loss: 0.7703\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7334\n",
      "[804/1762] D loss: 0.8579, G loss: 0.8832\n",
      "[884/1762] D loss: 0.9382, G loss: 0.7053\n",
      "[964/1762] D loss: 1.3965, G loss: 0.7093\n",
      "[1044/1762] D loss: 0.8598, G loss: 0.9127\n",
      "[1124/1762] D loss: 1.3922, G loss: 0.7307\n",
      "[1204/1762] D loss: 1.3590, G loss: 0.5024\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.7290\n",
      "[1364/1762] D loss: 1.4145, G loss: 0.8081\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.8657\n",
      "[1524/1762] D loss: 1.4066, G loss: 0.7608\n",
      "[1604/1762] D loss: 1.3950, G loss: 0.7986\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.7621\n",
      "[1762/1762] D loss: 1.3986, G loss: 0.7399\n",
      "train error: \n",
      " D loss: 1.319474, G loss: 0.750239, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300633, G loss: 0.766212, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4839, G loss: 1.2009\n",
      "[84/1762] D loss: 1.3979, G loss: 0.7545\n",
      "[164/1762] D loss: 0.5391, G loss: 1.2039\n",
      "[244/1762] D loss: 1.4099, G loss: 0.7854\n",
      "[324/1762] D loss: 1.3782, G loss: 0.7566\n",
      "[404/1762] D loss: 1.3888, G loss: 0.7315\n",
      "[484/1762] D loss: 0.5772, G loss: 0.9674\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7226\n",
      "[644/1762] D loss: 1.3971, G loss: 0.7713\n",
      "[724/1762] D loss: 0.4002, G loss: 1.3184\n",
      "[804/1762] D loss: 0.5710, G loss: 1.0181\n",
      "[884/1762] D loss: 1.5548, G loss: 0.9679\n",
      "[964/1762] D loss: 1.4666, G loss: 0.8841\n",
      "[1044/1762] D loss: 1.4418, G loss: 0.8564\n",
      "[1124/1762] D loss: 1.5644, G loss: 0.9456\n",
      "[1204/1762] D loss: 1.4354, G loss: 0.9253\n",
      "[1284/1762] D loss: 1.4330, G loss: 0.8410\n",
      "[1364/1762] D loss: 1.3999, G loss: 0.7847\n",
      "[1444/1762] D loss: 0.5172, G loss: 1.1029\n",
      "[1524/1762] D loss: 1.3949, G loss: 0.6864\n",
      "[1604/1762] D loss: 1.4028, G loss: 0.7977\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.7478\n",
      "[1762/1762] D loss: 1.4071, G loss: 0.7952\n",
      "train error: \n",
      " D loss: 1.333283, G loss: 0.688679, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319592, G loss: 0.702303, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.7505\n",
      "[84/1762] D loss: 1.3411, G loss: 0.8536\n",
      "[164/1762] D loss: 1.3944, G loss: 0.6598\n",
      "[244/1762] D loss: 1.3974, G loss: 0.7435\n",
      "[324/1762] D loss: 1.4678, G loss: 0.8896\n",
      "[404/1762] D loss: 0.5671, G loss: 1.0424\n",
      "[484/1762] D loss: 1.4111, G loss: 0.8132\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7859\n",
      "[644/1762] D loss: 0.9799, G loss: 0.5687\n",
      "[724/1762] D loss: 0.5458, G loss: 1.1439\n",
      "[804/1762] D loss: 0.6346, G loss: 1.0642\n",
      "[884/1762] D loss: 1.3911, G loss: 0.7241\n",
      "[964/1762] D loss: 1.4271, G loss: 0.8066\n",
      "[1044/1762] D loss: 0.5862, G loss: 1.0844\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7567\n",
      "[1204/1762] D loss: 1.4500, G loss: 0.8416\n",
      "[1284/1762] D loss: 0.5032, G loss: 1.2624\n",
      "[1364/1762] D loss: 1.3967, G loss: 0.7522\n",
      "[1444/1762] D loss: 1.4973, G loss: 0.8998\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6869\n",
      "[1604/1762] D loss: 0.5193, G loss: 1.0678\n",
      "[1684/1762] D loss: 0.4691, G loss: 1.2536\n",
      "[1762/1762] D loss: 1.2833, G loss: 0.8259\n",
      "train error: \n",
      " D loss: 1.278354, G loss: 0.672942, D accuracy: 65.4%, cell accuracy: 99.4%, board accuracy: 48.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256401, G loss: 0.703143, D accuracy: 67.5%, cell accuracy: 99.3%, board accuracy: 40.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3159, G loss: 0.8957\n",
      "[84/1762] D loss: 1.4079, G loss: 0.7800\n",
      "[164/1762] D loss: 1.4024, G loss: 0.7671\n",
      "[244/1762] D loss: 1.3848, G loss: 0.7138\n",
      "[324/1762] D loss: 1.3916, G loss: 0.7218\n",
      "[404/1762] D loss: 0.5039, G loss: 1.2007\n",
      "[484/1762] D loss: 1.5271, G loss: 1.0440\n",
      "[564/1762] D loss: 1.4515, G loss: 0.8746\n",
      "[644/1762] D loss: 1.3951, G loss: 0.7306\n",
      "[724/1762] D loss: 1.4369, G loss: 0.9192\n",
      "[804/1762] D loss: 0.3583, G loss: 1.7849\n",
      "[884/1762] D loss: 0.4701, G loss: 1.2545\n",
      "[964/1762] D loss: 1.5694, G loss: 0.8910\n",
      "[1044/1762] D loss: 1.3803, G loss: 0.7939\n",
      "[1124/1762] D loss: 0.8372, G loss: 0.8121\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.6911\n",
      "[1284/1762] D loss: 0.5188, G loss: 1.0820\n",
      "[1364/1762] D loss: 1.3625, G loss: 0.7669\n",
      "[1444/1762] D loss: 1.4074, G loss: 0.7822\n",
      "[1524/1762] D loss: 1.3736, G loss: 0.8122\n",
      "[1604/1762] D loss: 1.3950, G loss: 0.7233\n",
      "[1684/1762] D loss: 0.5090, G loss: 1.1446\n",
      "[1762/1762] D loss: 1.5017, G loss: 0.8349\n",
      "train error: \n",
      " D loss: 1.327306, G loss: 0.729223, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312258, G loss: 0.741363, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4036, G loss: 0.7849\n",
      "[84/1762] D loss: 0.4646, G loss: 1.2321\n",
      "[164/1762] D loss: 1.4013, G loss: 0.7896\n",
      "[244/1762] D loss: 0.4235, G loss: 1.3360\n",
      "[324/1762] D loss: 1.4027, G loss: 0.7920\n",
      "[404/1762] D loss: 1.3918, G loss: 0.7008\n",
      "[484/1762] D loss: 1.3945, G loss: 0.7797\n",
      "[564/1762] D loss: 0.5038, G loss: 1.1279\n",
      "[644/1762] D loss: 0.3757, G loss: 1.3726\n",
      "[724/1762] D loss: 0.3325, G loss: 1.5999\n",
      "[804/1762] D loss: 1.3912, G loss: 0.7152\n",
      "[884/1762] D loss: 1.3656, G loss: 0.7480\n",
      "[964/1762] D loss: 1.4068, G loss: 0.7019\n",
      "[1044/1762] D loss: 0.3700, G loss: 1.4587\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.7450\n",
      "[1204/1762] D loss: 1.4048, G loss: 0.7875\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7152\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.6880\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7037\n",
      "[1524/1762] D loss: 1.4470, G loss: 0.8616\n",
      "[1604/1762] D loss: 1.3520, G loss: 0.8611\n",
      "[1684/1762] D loss: 0.4157, G loss: 1.3423\n",
      "[1762/1762] D loss: 1.3998, G loss: 0.7742\n",
      "train error: \n",
      " D loss: 1.319170, G loss: 0.764277, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301389, G loss: 0.780729, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4033, G loss: 0.7796\n",
      "[84/1762] D loss: 1.3873, G loss: 0.7009\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7125\n",
      "[244/1762] D loss: 1.5206, G loss: 0.7405\n",
      "[324/1762] D loss: 1.5130, G loss: 0.9134\n",
      "[404/1762] D loss: 1.3872, G loss: 0.7126\n",
      "[484/1762] D loss: 1.4629, G loss: 0.8802\n",
      "[564/1762] D loss: 0.5306, G loss: 1.1211\n",
      "[644/1762] D loss: 1.5169, G loss: 0.9065\n",
      "[724/1762] D loss: 1.4231, G loss: 0.8264\n",
      "[804/1762] D loss: 1.3899, G loss: 0.7219\n",
      "[884/1762] D loss: 1.3878, G loss: 0.7142\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6759\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.7190\n",
      "[1124/1762] D loss: 0.3986, G loss: 1.4233\n",
      "[1204/1762] D loss: 3.2201, G loss: 1.8799\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6964\n",
      "[1364/1762] D loss: 0.8222, G loss: 0.8798\n",
      "[1444/1762] D loss: 1.2907, G loss: 0.8654\n",
      "[1524/1762] D loss: 1.2986, G loss: 0.7896\n",
      "[1604/1762] D loss: 1.3299, G loss: 0.8596\n",
      "[1684/1762] D loss: 1.0512, G loss: 1.0061\n",
      "[1762/1762] D loss: 1.3685, G loss: 0.7750\n",
      "train error: \n",
      " D loss: 1.326980, G loss: 0.817116, D accuracy: 52.1%, cell accuracy: 99.6%, board accuracy: 75.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323672, G loss: 0.815824, D accuracy: 52.7%, cell accuracy: 99.5%, board accuracy: 68.4% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.6678\n",
      "[84/1762] D loss: 1.4088, G loss: 0.6897\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6848\n",
      "[244/1762] D loss: 1.3160, G loss: 0.8005\n",
      "[324/1762] D loss: 1.3910, G loss: 0.6848\n",
      "[404/1762] D loss: 1.0801, G loss: 1.0166\n",
      "[484/1762] D loss: 1.1244, G loss: 0.7496\n",
      "[564/1762] D loss: 1.0195, G loss: 0.9834\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6941\n",
      "[724/1762] D loss: 1.3861, G loss: 0.7029\n",
      "[804/1762] D loss: 1.3895, G loss: 0.7366\n",
      "[884/1762] D loss: 1.3456, G loss: 0.7874\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7093\n",
      "[1044/1762] D loss: 1.3535, G loss: 0.7659\n",
      "[1124/1762] D loss: 1.3841, G loss: 0.6737\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.7066\n",
      "[1284/1762] D loss: 1.3950, G loss: 0.7357\n",
      "[1364/1762] D loss: 1.4504, G loss: 0.7574\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.7443\n",
      "[1524/1762] D loss: 1.4126, G loss: 0.7777\n",
      "[1604/1762] D loss: 0.4853, G loss: 1.5147\n",
      "[1684/1762] D loss: 1.3828, G loss: 0.7011\n",
      "[1762/1762] D loss: 1.4309, G loss: 0.8760\n",
      "train error: \n",
      " D loss: 1.345525, G loss: 0.725511, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338737, G loss: 0.743392, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4071, G loss: 0.7838\n",
      "[84/1762] D loss: 1.3977, G loss: 0.7634\n",
      "[164/1762] D loss: 1.4125, G loss: 0.7857\n",
      "[244/1762] D loss: 1.3932, G loss: 0.7254\n",
      "[324/1762] D loss: 1.3845, G loss: 0.7013\n",
      "[404/1762] D loss: 1.3910, G loss: 0.6980\n",
      "[484/1762] D loss: 1.4078, G loss: 0.7136\n",
      "[564/1762] D loss: 0.3527, G loss: 1.7235\n",
      "[644/1762] D loss: 0.3074, G loss: 1.7623\n",
      "[724/1762] D loss: 1.3897, G loss: 0.7102\n",
      "[804/1762] D loss: 0.2015, G loss: 2.2429\n",
      "[884/1762] D loss: 1.4921, G loss: 0.9772\n",
      "[964/1762] D loss: 1.3969, G loss: 0.6872\n",
      "[1044/1762] D loss: 1.4058, G loss: 0.7580\n",
      "[1124/1762] D loss: 0.5202, G loss: 1.2344\n",
      "[1204/1762] D loss: 1.6534, G loss: 1.0501\n",
      "[1284/1762] D loss: 1.4094, G loss: 0.6877\n",
      "[1364/1762] D loss: 1.2286, G loss: 1.0022\n",
      "[1444/1762] D loss: 1.3913, G loss: 0.7416\n",
      "[1524/1762] D loss: 1.3842, G loss: 0.7088\n",
      "[1604/1762] D loss: 1.2985, G loss: 0.9149\n",
      "[1684/1762] D loss: 1.3799, G loss: 0.6840\n",
      "[1762/1762] D loss: 1.2937, G loss: 0.8367\n",
      "train error: \n",
      " D loss: 1.328530, G loss: 0.747739, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319081, G loss: 0.770061, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4876, G loss: 1.3339\n",
      "[84/1762] D loss: 1.4068, G loss: 0.9267\n",
      "[164/1762] D loss: 1.3993, G loss: 0.7466\n",
      "[244/1762] D loss: 1.4026, G loss: 0.8028\n",
      "[324/1762] D loss: 0.3234, G loss: 1.7761\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6903\n",
      "[484/1762] D loss: 1.3964, G loss: 0.6758\n",
      "[564/1762] D loss: 1.5133, G loss: 0.8725\n",
      "[644/1762] D loss: 0.2453, G loss: 1.9004\n",
      "[724/1762] D loss: 1.4004, G loss: 0.6771\n",
      "[804/1762] D loss: 1.4312, G loss: 0.7179\n",
      "[884/1762] D loss: 1.3388, G loss: 0.8298\n",
      "[964/1762] D loss: 1.3936, G loss: 0.6451\n",
      "[1044/1762] D loss: 1.4029, G loss: 0.7568\n",
      "[1124/1762] D loss: 1.3964, G loss: 0.7095\n",
      "[1204/1762] D loss: 1.4644, G loss: 0.8068\n",
      "[1284/1762] D loss: 0.5019, G loss: 1.3136\n",
      "[1364/1762] D loss: 0.2955, G loss: 1.7547\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.7451\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.7102\n",
      "[1604/1762] D loss: 0.3752, G loss: 1.5857\n",
      "[1684/1762] D loss: 1.3268, G loss: 0.9570\n",
      "[1762/1762] D loss: 1.3935, G loss: 0.7644\n",
      "train error: \n",
      " D loss: 1.322199, G loss: 0.748467, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309354, G loss: 0.764322, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5300, G loss: 0.9177\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7124\n",
      "[164/1762] D loss: 1.6052, G loss: 0.8113\n",
      "[244/1762] D loss: 1.5739, G loss: 0.9158\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7078\n",
      "[404/1762] D loss: 1.3960, G loss: 0.7482\n",
      "[484/1762] D loss: 0.6039, G loss: 1.7371\n",
      "[564/1762] D loss: 1.3899, G loss: 0.6672\n",
      "[644/1762] D loss: 1.3896, G loss: 0.6863\n",
      "[724/1762] D loss: 1.4940, G loss: 0.7635\n",
      "[804/1762] D loss: 1.4586, G loss: 0.9351\n",
      "[884/1762] D loss: 1.4987, G loss: 0.9516\n",
      "[964/1762] D loss: 1.5781, G loss: 0.8061\n",
      "[1044/1762] D loss: 0.3504, G loss: 1.7159\n",
      "[1124/1762] D loss: 1.3926, G loss: 0.6948\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.6952\n",
      "[1284/1762] D loss: 1.4171, G loss: 0.7812\n",
      "[1364/1762] D loss: 1.4149, G loss: 0.9309\n",
      "[1444/1762] D loss: 1.3951, G loss: 0.7216\n",
      "[1524/1762] D loss: 1.4231, G loss: 0.7841\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.7014\n",
      "[1684/1762] D loss: 1.3982, G loss: 0.7003\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6647\n",
      "train error: \n",
      " D loss: 1.356913, G loss: 0.765062, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347947, G loss: 0.798544, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2609, G loss: 1.9206\n",
      "[84/1762] D loss: 1.4342, G loss: 0.8255\n",
      "[164/1762] D loss: 1.4198, G loss: 0.7895\n",
      "[244/1762] D loss: 1.4147, G loss: 0.7733\n",
      "[324/1762] D loss: 1.4212, G loss: 0.7203\n",
      "[404/1762] D loss: 1.4151, G loss: 0.6289\n",
      "[484/1762] D loss: 1.3964, G loss: 0.7253\n",
      "[564/1762] D loss: 1.4153, G loss: 0.8170\n",
      "[644/1762] D loss: 0.3473, G loss: 1.6348\n",
      "[724/1762] D loss: 1.4311, G loss: 0.8155\n",
      "[804/1762] D loss: 1.3609, G loss: 0.7705\n",
      "[884/1762] D loss: 1.3674, G loss: 0.7335\n",
      "[964/1762] D loss: 0.4585, G loss: 1.5011\n",
      "[1044/1762] D loss: 0.4679, G loss: 1.4930\n",
      "[1124/1762] D loss: 0.3783, G loss: 2.0282\n",
      "[1204/1762] D loss: 1.3974, G loss: 0.7487\n",
      "[1284/1762] D loss: 0.3929, G loss: 1.7895\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.7166\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.6866\n",
      "[1524/1762] D loss: 1.4235, G loss: 0.7737\n",
      "[1604/1762] D loss: 1.3842, G loss: 0.6943\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.7115\n",
      "[1762/1762] D loss: 1.3802, G loss: 0.7270\n",
      "train error: \n",
      " D loss: 1.343125, G loss: 0.776017, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331614, G loss: 0.814216, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3888, G loss: 0.6889\n",
      "[84/1762] D loss: 1.3970, G loss: 0.7329\n",
      "[164/1762] D loss: 1.6730, G loss: 0.6385\n",
      "[244/1762] D loss: 1.4153, G loss: 0.7659\n",
      "[324/1762] D loss: 0.0798, G loss: 3.0020\n",
      "[404/1762] D loss: 1.5732, G loss: 1.0872\n",
      "[484/1762] D loss: 1.3982, G loss: 0.7229\n",
      "[564/1762] D loss: 1.3984, G loss: 0.7343\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6888\n",
      "[724/1762] D loss: 1.3899, G loss: 0.6762\n",
      "[804/1762] D loss: 1.4285, G loss: 0.7901\n",
      "[884/1762] D loss: 1.3882, G loss: 0.7232\n",
      "[964/1762] D loss: 1.0978, G loss: 1.2650\n",
      "[1044/1762] D loss: 1.4983, G loss: 0.7703\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.7190\n",
      "[1204/1762] D loss: 1.4668, G loss: 0.7437\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.7204\n",
      "[1364/1762] D loss: 0.4464, G loss: 1.9157\n",
      "[1444/1762] D loss: 0.3243, G loss: 1.8682\n",
      "[1524/1762] D loss: 1.4235, G loss: 0.7663\n",
      "[1604/1762] D loss: 1.4001, G loss: 0.6743\n",
      "[1684/1762] D loss: 0.5579, G loss: 1.4421\n",
      "[1762/1762] D loss: 1.5708, G loss: 0.7660\n",
      "train error: \n",
      " D loss: 1.327436, G loss: 0.722145, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312298, G loss: 0.748774, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4490, G loss: 0.7978\n",
      "[84/1762] D loss: 1.3889, G loss: 0.8006\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7922\n",
      "[244/1762] D loss: 1.3806, G loss: 0.7011\n",
      "[324/1762] D loss: 0.4415, G loss: 1.9429\n",
      "[404/1762] D loss: 0.3904, G loss: 1.6134\n",
      "[484/1762] D loss: 1.5466, G loss: 0.7452\n",
      "[564/1762] D loss: 1.3777, G loss: 0.7432\n",
      "[644/1762] D loss: 1.2787, G loss: 0.5230\n",
      "[724/1762] D loss: 1.3533, G loss: 0.7319\n",
      "[804/1762] D loss: 1.3969, G loss: 0.7166\n",
      "[884/1762] D loss: 1.3765, G loss: 0.7154\n",
      "[964/1762] D loss: 1.3955, G loss: 0.7245\n",
      "[1044/1762] D loss: 1.4676, G loss: 0.7717\n",
      "[1124/1762] D loss: 1.4227, G loss: 0.7479\n",
      "[1204/1762] D loss: 1.3775, G loss: 0.7021\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.6550\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6637\n",
      "[1444/1762] D loss: 0.3300, G loss: 1.7543\n",
      "[1524/1762] D loss: 1.6515, G loss: 0.7701\n",
      "[1604/1762] D loss: 1.3969, G loss: 0.7411\n",
      "[1684/1762] D loss: 1.4103, G loss: 0.7230\n",
      "[1762/1762] D loss: 1.3985, G loss: 0.6880\n",
      "train error: \n",
      " D loss: 1.348059, G loss: 0.653191, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335788, G loss: 0.661138, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4002, G loss: 0.6335\n",
      "[84/1762] D loss: 1.3936, G loss: 0.7265\n",
      "[164/1762] D loss: 0.3744, G loss: 1.6178\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7116\n",
      "[324/1762] D loss: 1.4103, G loss: 0.7381\n",
      "[404/1762] D loss: 0.3393, G loss: 1.8367\n",
      "[484/1762] D loss: 1.3917, G loss: 0.6472\n",
      "[564/1762] D loss: 1.4058, G loss: 0.6811\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6971\n",
      "[724/1762] D loss: 1.4150, G loss: 0.7776\n",
      "[804/1762] D loss: 1.3940, G loss: 0.7428\n",
      "[884/1762] D loss: 1.4969, G loss: 0.6716\n",
      "[964/1762] D loss: 0.4279, G loss: 1.7323\n",
      "[1044/1762] D loss: 1.3143, G loss: 0.7585\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.7329\n",
      "[1204/1762] D loss: 1.4639, G loss: 0.7298\n",
      "[1284/1762] D loss: 0.2812, G loss: 2.1166\n",
      "[1364/1762] D loss: 0.3974, G loss: 2.0967\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.7288\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6790\n",
      "[1604/1762] D loss: 1.3810, G loss: 0.6886\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6809\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6727\n",
      "train error: \n",
      " D loss: 1.325650, G loss: 0.653394, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 85.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314219, G loss: 0.672056, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3422, G loss: 0.7858\n",
      "[84/1762] D loss: 1.3239, G loss: 0.7464\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6975\n",
      "[244/1762] D loss: 0.3002, G loss: 2.0334\n",
      "[324/1762] D loss: 0.3141, G loss: 2.0635\n",
      "[404/1762] D loss: 1.4217, G loss: 0.7122\n",
      "[484/1762] D loss: 1.4042, G loss: 0.6994\n",
      "[564/1762] D loss: 1.2641, G loss: 0.5861\n",
      "[644/1762] D loss: 1.4448, G loss: 0.6839\n",
      "[724/1762] D loss: 0.4510, G loss: 2.0208\n",
      "[804/1762] D loss: 0.3962, G loss: 1.8790\n",
      "[884/1762] D loss: 1.3887, G loss: 0.7474\n",
      "[964/1762] D loss: 1.4223, G loss: 0.8083\n",
      "[1044/1762] D loss: 1.3316, G loss: 0.7562\n",
      "[1124/1762] D loss: 1.3954, G loss: 0.7236\n",
      "[1204/1762] D loss: 1.3690, G loss: 0.7863\n",
      "[1284/1762] D loss: 1.3638, G loss: 0.7856\n",
      "[1364/1762] D loss: 2.0691, G loss: 0.5200\n",
      "[1444/1762] D loss: 0.7308, G loss: 1.7329\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6945\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.6800\n",
      "[1684/1762] D loss: 0.3583, G loss: 1.9199\n",
      "[1762/1762] D loss: 0.7357, G loss: 2.6357\n",
      "train error: \n",
      " D loss: 1.807550, G loss: 0.454930, D accuracy: 53.1%, cell accuracy: 98.7%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.916089, G loss: 0.470586, D accuracy: 53.4%, cell accuracy: 98.5%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4263, G loss: 0.6030\n",
      "[84/1762] D loss: 0.6710, G loss: 1.5639\n",
      "[164/1762] D loss: 1.1737, G loss: 1.3792\n",
      "[244/1762] D loss: 1.4141, G loss: 0.7686\n",
      "[324/1762] D loss: 1.4159, G loss: 0.7133\n",
      "[404/1762] D loss: 1.3978, G loss: 0.7218\n",
      "[484/1762] D loss: 1.3476, G loss: 0.7802\n",
      "[564/1762] D loss: 1.3860, G loss: 0.6852\n",
      "[644/1762] D loss: 1.4360, G loss: 0.8877\n",
      "[724/1762] D loss: 1.4101, G loss: 0.6535\n",
      "[804/1762] D loss: 1.3155, G loss: 0.8558\n",
      "[884/1762] D loss: 0.3733, G loss: 1.8003\n",
      "[964/1762] D loss: 0.4276, G loss: 1.6225\n",
      "[1044/1762] D loss: 1.4174, G loss: 0.6106\n",
      "[1124/1762] D loss: 1.3505, G loss: 0.7340\n",
      "[1204/1762] D loss: 0.3501, G loss: 2.0455\n",
      "[1284/1762] D loss: 1.3827, G loss: 0.6807\n",
      "[1364/1762] D loss: 1.3591, G loss: 0.7629\n",
      "[1444/1762] D loss: 1.5391, G loss: 0.7208\n",
      "[1524/1762] D loss: 1.4170, G loss: 0.7185\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.6970\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.7049\n",
      "[1762/1762] D loss: 1.4663, G loss: 0.6583\n",
      "train error: \n",
      " D loss: 1.347148, G loss: 0.681386, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332795, G loss: 0.694395, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3617, G loss: 0.5249\n",
      "[84/1762] D loss: 1.3981, G loss: 0.7030\n",
      "[164/1762] D loss: 1.3910, G loss: 0.6734\n",
      "[244/1762] D loss: 1.4947, G loss: 0.7498\n",
      "[324/1762] D loss: 1.3988, G loss: 0.7290\n",
      "[404/1762] D loss: 1.3899, G loss: 0.6891\n",
      "[484/1762] D loss: 0.0646, G loss: 3.4023\n",
      "[564/1762] D loss: 1.2805, G loss: 0.7630\n",
      "[644/1762] D loss: 0.0594, G loss: 3.3765\n",
      "[724/1762] D loss: 1.4816, G loss: 0.6805\n",
      "[804/1762] D loss: 1.3950, G loss: 0.6873\n",
      "[884/1762] D loss: 1.3918, G loss: 0.6758\n",
      "[964/1762] D loss: 0.3077, G loss: 2.2684\n",
      "[1044/1762] D loss: 1.3955, G loss: 0.6843\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.6560\n",
      "[1204/1762] D loss: 0.1712, G loss: 2.6301\n",
      "[1284/1762] D loss: 1.0708, G loss: 1.0723\n",
      "[1364/1762] D loss: 0.1707, G loss: 2.6937\n",
      "[1444/1762] D loss: 1.7098, G loss: 4.1194\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.6616\n",
      "[1604/1762] D loss: 1.4039, G loss: 0.6287\n",
      "[1684/1762] D loss: 1.4223, G loss: 0.7010\n",
      "[1762/1762] D loss: 1.4114, G loss: 0.6825\n",
      "train error: \n",
      " D loss: 1.325842, G loss: 0.812731, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300868, G loss: 0.868330, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4094, G loss: 0.7005\n",
      "[84/1762] D loss: 1.3972, G loss: 0.7016\n",
      "[164/1762] D loss: 1.3914, G loss: 0.8045\n",
      "[244/1762] D loss: 0.5904, G loss: 1.7028\n",
      "[324/1762] D loss: 1.2655, G loss: 1.1898\n",
      "[404/1762] D loss: 1.4084, G loss: 0.7320\n",
      "[484/1762] D loss: 1.3494, G loss: 0.8816\n",
      "[564/1762] D loss: 1.4210, G loss: 0.6103\n",
      "[644/1762] D loss: 1.3962, G loss: 0.6885\n",
      "[724/1762] D loss: 1.3902, G loss: 0.7195\n",
      "[804/1762] D loss: 1.4157, G loss: 0.7216\n",
      "[884/1762] D loss: 1.3905, G loss: 0.6669\n",
      "[964/1762] D loss: 1.1619, G loss: 2.9544\n",
      "[1044/1762] D loss: 1.1267, G loss: 1.2453\n",
      "[1124/1762] D loss: 1.3821, G loss: 0.6965\n",
      "[1204/1762] D loss: 1.4025, G loss: 0.6722\n",
      "[1284/1762] D loss: 1.1302, G loss: 1.2498\n",
      "[1364/1762] D loss: 1.0671, G loss: 2.0684\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.6412\n",
      "[1524/1762] D loss: 0.5063, G loss: 2.0797\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.6581\n",
      "[1684/1762] D loss: 1.8424, G loss: 0.5514\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6711\n",
      "train error: \n",
      " D loss: 1.418748, G loss: 0.980195, D accuracy: 51.2%, cell accuracy: 99.9%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.406307, G loss: 0.987884, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3966, G loss: 0.7001\n",
      "[84/1762] D loss: 1.0534, G loss: 1.6453\n",
      "[164/1762] D loss: 1.0498, G loss: 1.3938\n",
      "[244/1762] D loss: 0.9943, G loss: 1.1653\n",
      "[324/1762] D loss: 1.3927, G loss: 0.6966\n",
      "[404/1762] D loss: 1.5784, G loss: 0.4288\n",
      "[484/1762] D loss: 0.9272, G loss: 1.2488\n",
      "[564/1762] D loss: 1.3898, G loss: 0.6829\n",
      "[644/1762] D loss: 1.5047, G loss: 0.8516\n",
      "[724/1762] D loss: 1.4193, G loss: 0.5632\n",
      "[804/1762] D loss: 1.3699, G loss: 0.6811\n",
      "[884/1762] D loss: 1.1920, G loss: 1.1543\n",
      "[964/1762] D loss: 1.3852, G loss: 0.6756\n",
      "[1044/1762] D loss: 1.3924, G loss: 0.6486\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.6789\n",
      "[1204/1762] D loss: 1.0207, G loss: 0.8727\n",
      "[1284/1762] D loss: 1.4065, G loss: 0.6536\n",
      "[1364/1762] D loss: 0.4694, G loss: 2.4747\n",
      "[1444/1762] D loss: 1.3947, G loss: 0.6985\n",
      "[1524/1762] D loss: 0.9930, G loss: 2.1490\n",
      "[1604/1762] D loss: 1.3773, G loss: 0.6224\n",
      "[1684/1762] D loss: 1.3184, G loss: 0.7775\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.6970\n",
      "train error: \n",
      " D loss: 1.335953, G loss: 0.889751, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320111, G loss: 0.943164, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3119, G loss: 0.8169\n",
      "[84/1762] D loss: 1.3914, G loss: 0.7079\n",
      "[164/1762] D loss: 0.9958, G loss: 1.4831\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6921\n",
      "[324/1762] D loss: 1.3622, G loss: 0.7917\n",
      "[404/1762] D loss: 1.4184, G loss: 0.6486\n",
      "[484/1762] D loss: 1.4141, G loss: 0.5976\n",
      "[564/1762] D loss: 1.4562, G loss: 0.7241\n",
      "[644/1762] D loss: 1.4059, G loss: 0.8799\n",
      "[724/1762] D loss: 1.4215, G loss: 0.6243\n",
      "[804/1762] D loss: 1.4051, G loss: 0.7103\n",
      "[884/1762] D loss: 1.4259, G loss: 0.6585\n",
      "[964/1762] D loss: 1.3837, G loss: 0.7173\n",
      "[1044/1762] D loss: 1.5264, G loss: 0.7818\n",
      "[1124/1762] D loss: 1.0612, G loss: 1.3264\n",
      "[1204/1762] D loss: 0.9244, G loss: 0.9475\n",
      "[1284/1762] D loss: 1.3478, G loss: 0.8772\n",
      "[1364/1762] D loss: 0.6323, G loss: 1.5603\n",
      "[1444/1762] D loss: 1.4032, G loss: 0.7941\n",
      "[1524/1762] D loss: 1.4543, G loss: 0.8275\n",
      "[1604/1762] D loss: 1.3419, G loss: 0.9556\n",
      "[1684/1762] D loss: 1.3922, G loss: 0.6993\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6098\n",
      "train error: \n",
      " D loss: 1.345528, G loss: 0.830169, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322087, G loss: 0.904848, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6447, G loss: 1.4588\n",
      "[84/1762] D loss: 0.4430, G loss: 1.9455\n",
      "[164/1762] D loss: 1.3942, G loss: 0.7317\n",
      "[244/1762] D loss: 1.3903, G loss: 0.6572\n",
      "[324/1762] D loss: 1.4035, G loss: 0.6387\n",
      "[404/1762] D loss: 1.3926, G loss: 0.7470\n",
      "[484/1762] D loss: 1.3981, G loss: 0.7180\n",
      "[564/1762] D loss: 0.3002, G loss: 1.7939\n",
      "[644/1762] D loss: 1.4275, G loss: 0.6898\n",
      "[724/1762] D loss: 0.7144, G loss: 1.7954\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6296\n",
      "[884/1762] D loss: 1.3928, G loss: 0.6592\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6958\n",
      "[1044/1762] D loss: 1.3544, G loss: 0.7588\n",
      "[1124/1762] D loss: 1.4246, G loss: 0.6976\n",
      "[1204/1762] D loss: 1.3383, G loss: 0.9323\n",
      "[1284/1762] D loss: 0.1711, G loss: 2.6003\n",
      "[1364/1762] D loss: 0.6222, G loss: 1.2822\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.6255\n",
      "[1524/1762] D loss: 0.4848, G loss: 1.9794\n",
      "[1604/1762] D loss: 0.3222, G loss: 2.5116\n",
      "[1684/1762] D loss: 1.4369, G loss: 0.7073\n",
      "[1762/1762] D loss: 1.3987, G loss: 0.6566\n",
      "train error: \n",
      " D loss: 1.383690, G loss: 1.139981, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357415, G loss: 1.177025, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3987, G loss: 0.6616\n",
      "[84/1762] D loss: 1.3848, G loss: 0.6888\n",
      "[164/1762] D loss: 1.4238, G loss: 0.7391\n",
      "[244/1762] D loss: 0.2689, G loss: 2.6310\n",
      "[324/1762] D loss: 1.3441, G loss: 0.8600\n",
      "[404/1762] D loss: 1.3506, G loss: 0.7292\n",
      "[484/1762] D loss: 1.3966, G loss: 0.7229\n",
      "[564/1762] D loss: 1.4105, G loss: 0.5848\n",
      "[644/1762] D loss: 1.4197, G loss: 0.7736\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6593\n",
      "[804/1762] D loss: 3.4854, G loss: 0.9961\n",
      "[884/1762] D loss: 1.4050, G loss: 0.5479\n",
      "[964/1762] D loss: 1.3928, G loss: 0.6562\n",
      "[1044/1762] D loss: 1.3942, G loss: 0.6989\n",
      "[1124/1762] D loss: 1.4073, G loss: 0.7570\n",
      "[1204/1762] D loss: 0.3292, G loss: 1.9973\n",
      "[1284/1762] D loss: 0.3514, G loss: 2.0354\n",
      "[1364/1762] D loss: 0.3863, G loss: 2.4853\n",
      "[1444/1762] D loss: 1.3811, G loss: 0.6895\n",
      "[1524/1762] D loss: 1.4816, G loss: 1.0592\n",
      "[1604/1762] D loss: 1.6881, G loss: 0.7228\n",
      "[1684/1762] D loss: 0.9657, G loss: 1.7936\n",
      "[1762/1762] D loss: 1.0171, G loss: 1.3559\n",
      "train error: \n",
      " D loss: 1.340045, G loss: 0.796060, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333239, G loss: 0.806476, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2353, G loss: 0.6315\n",
      "[84/1762] D loss: 0.3104, G loss: 2.2702\n",
      "[164/1762] D loss: 1.3927, G loss: 0.7140\n",
      "[244/1762] D loss: 1.4008, G loss: 0.7182\n",
      "[324/1762] D loss: 1.3856, G loss: 0.7179\n",
      "[404/1762] D loss: 1.4041, G loss: 0.6348\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6750\n",
      "[564/1762] D loss: 0.2312, G loss: 2.3989\n",
      "[644/1762] D loss: 1.3989, G loss: 0.6375\n",
      "[724/1762] D loss: 0.2919, G loss: 2.2357\n",
      "[804/1762] D loss: 1.3890, G loss: 0.7070\n",
      "[884/1762] D loss: 1.3918, G loss: 0.6549\n",
      "[964/1762] D loss: 1.4012, G loss: 0.6711\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7081\n",
      "[1124/1762] D loss: 0.2956, G loss: 2.5270\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.7095\n",
      "[1284/1762] D loss: 1.3897, G loss: 0.7255\n",
      "[1364/1762] D loss: 1.3923, G loss: 0.6417\n",
      "[1444/1762] D loss: 0.2949, G loss: 2.7506\n",
      "[1524/1762] D loss: 0.0290, G loss: 4.2244\n",
      "[1604/1762] D loss: 0.2209, G loss: 2.9793\n",
      "[1684/1762] D loss: 1.3909, G loss: 0.6906\n",
      "[1762/1762] D loss: 1.4346, G loss: 0.7225\n",
      "train error: \n",
      " D loss: 1.301529, G loss: 0.860787, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275255, G loss: 0.923273, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4897, G loss: 0.6663\n",
      "[84/1762] D loss: 1.3902, G loss: 0.6572\n",
      "[164/1762] D loss: 1.4018, G loss: 0.6925\n",
      "[244/1762] D loss: 1.4027, G loss: 0.6430\n",
      "[324/1762] D loss: 1.3961, G loss: 0.6987\n",
      "[404/1762] D loss: 1.3997, G loss: 0.6276\n",
      "[484/1762] D loss: 1.4052, G loss: 0.6773\n",
      "[564/1762] D loss: 0.1881, G loss: 2.7448\n",
      "[644/1762] D loss: 0.0547, G loss: 3.7293\n",
      "[724/1762] D loss: 1.3747, G loss: 0.7056\n",
      "[804/1762] D loss: 1.3857, G loss: 0.7083\n",
      "[884/1762] D loss: 1.3997, G loss: 0.6385\n",
      "[964/1762] D loss: 1.0848, G loss: 1.6158\n",
      "[1044/1762] D loss: 1.3805, G loss: 0.7013\n",
      "[1124/1762] D loss: 1.3909, G loss: 0.6533\n",
      "[1204/1762] D loss: 0.1052, G loss: 3.1551\n",
      "[1284/1762] D loss: 1.4097, G loss: 0.6632\n",
      "[1364/1762] D loss: 1.3918, G loss: 0.6678\n",
      "[1444/1762] D loss: 1.3954, G loss: 0.6456\n",
      "[1524/1762] D loss: 1.5567, G loss: 0.6242\n",
      "[1604/1762] D loss: 1.4028, G loss: 0.6635\n",
      "[1684/1762] D loss: 0.2633, G loss: 3.1203\n",
      "[1762/1762] D loss: 1.2538, G loss: 1.2872\n",
      "train error: \n",
      " D loss: 8.131157, G loss: 0.001100, D accuracy: 50.0%, cell accuracy: 99.6%, board accuracy: 79.8% \n",
      "\n",
      "test error: \n",
      " D loss: 8.029059, G loss: 0.001095, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5281, G loss: 0.5485\n",
      "[84/1762] D loss: 1.5125, G loss: 0.7329\n",
      "[164/1762] D loss: 0.3402, G loss: 2.4215\n",
      "[244/1762] D loss: 1.4956, G loss: 0.6979\n",
      "[324/1762] D loss: 0.2265, G loss: 2.6722\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6885\n",
      "[484/1762] D loss: 1.2560, G loss: 0.8418\n",
      "[564/1762] D loss: 1.3949, G loss: 0.6359\n",
      "[644/1762] D loss: 1.2705, G loss: 1.3341\n",
      "[724/1762] D loss: 0.3769, G loss: 2.6076\n",
      "[804/1762] D loss: 1.3862, G loss: 0.7292\n",
      "[884/1762] D loss: 0.3567, G loss: 2.2175\n",
      "[964/1762] D loss: 1.3931, G loss: 0.6570\n",
      "[1044/1762] D loss: 1.7351, G loss: 0.6025\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.7258\n",
      "[1204/1762] D loss: 0.0978, G loss: 3.0431\n",
      "[1284/1762] D loss: 0.3532, G loss: 2.7242\n",
      "[1364/1762] D loss: 0.0823, G loss: 3.3924\n",
      "[1444/1762] D loss: 1.3905, G loss: 0.6558\n",
      "[1524/1762] D loss: 0.3358, G loss: 2.8637\n",
      "[1604/1762] D loss: 1.3916, G loss: 0.7506\n",
      "[1684/1762] D loss: 1.7320, G loss: 0.5369\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.7176\n",
      "train error: \n",
      " D loss: 1.306232, G loss: 0.857595, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290889, G loss: 0.897104, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4016, G loss: 0.7424\n",
      "[84/1762] D loss: 1.3846, G loss: 0.6823\n",
      "[164/1762] D loss: 1.3607, G loss: 0.7256\n",
      "[244/1762] D loss: 0.1518, G loss: 3.2188\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6752\n",
      "[404/1762] D loss: 1.4127, G loss: 0.6440\n",
      "[484/1762] D loss: 1.5673, G loss: 0.7223\n",
      "[564/1762] D loss: 0.2722, G loss: 3.4332\n",
      "[644/1762] D loss: 1.3892, G loss: 0.6717\n",
      "[724/1762] D loss: 1.3913, G loss: 0.6947\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6728\n",
      "[884/1762] D loss: 1.4319, G loss: 0.6364\n",
      "[964/1762] D loss: 0.1591, G loss: 3.3629\n",
      "[1044/1762] D loss: 1.3261, G loss: 0.9484\n",
      "[1124/1762] D loss: 0.3340, G loss: 2.6277\n",
      "[1204/1762] D loss: 1.3978, G loss: 0.6290\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7171\n",
      "[1364/1762] D loss: 1.3986, G loss: 0.7010\n",
      "[1444/1762] D loss: 0.8833, G loss: 2.8538\n",
      "[1524/1762] D loss: 1.4299, G loss: 0.5643\n",
      "[1604/1762] D loss: 0.4230, G loss: 1.7196\n",
      "[1684/1762] D loss: 1.5070, G loss: 0.6563\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7038\n",
      "train error: \n",
      " D loss: 1.343824, G loss: 0.727588, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328512, G loss: 0.773785, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6638\n",
      "[84/1762] D loss: 1.2703, G loss: 0.9803\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6638\n",
      "[244/1762] D loss: 1.3842, G loss: 0.6646\n",
      "[324/1762] D loss: 0.0282, G loss: 3.8063\n",
      "[404/1762] D loss: 1.3928, G loss: 0.7262\n",
      "[484/1762] D loss: 1.3957, G loss: 0.6387\n",
      "[564/1762] D loss: 1.1803, G loss: 1.4197\n",
      "[644/1762] D loss: 0.0372, G loss: 4.2336\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6371\n",
      "[804/1762] D loss: 1.3961, G loss: 0.6231\n",
      "[884/1762] D loss: 1.3903, G loss: 0.6670\n",
      "[964/1762] D loss: 0.2576, G loss: 2.7359\n",
      "[1044/1762] D loss: 0.3738, G loss: 2.5940\n",
      "[1124/1762] D loss: 0.4593, G loss: 1.8200\n",
      "[1204/1762] D loss: 1.3941, G loss: 0.6497\n",
      "[1284/1762] D loss: 1.1532, G loss: 1.5762\n",
      "[1364/1762] D loss: 1.3975, G loss: 0.6480\n",
      "[1444/1762] D loss: 1.3185, G loss: 0.8154\n",
      "[1524/1762] D loss: 1.4607, G loss: 0.6449\n",
      "[1604/1762] D loss: 1.4031, G loss: 0.7481\n",
      "[1684/1762] D loss: 1.3963, G loss: 0.6997\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.7266\n",
      "train error: \n",
      " D loss: 1.542876, G loss: 1.173117, D accuracy: 49.0%, cell accuracy: 99.7%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.550825, G loss: 1.257618, D accuracy: 49.1%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6792\n",
      "[84/1762] D loss: 1.3886, G loss: 0.7233\n",
      "[164/1762] D loss: 1.3462, G loss: 1.3278\n",
      "[244/1762] D loss: 0.2397, G loss: 3.0289\n",
      "[324/1762] D loss: 0.2633, G loss: 2.9170\n",
      "[404/1762] D loss: 1.3488, G loss: 0.8306\n",
      "[484/1762] D loss: 1.3856, G loss: 0.8557\n",
      "[564/1762] D loss: 0.1581, G loss: 4.4919\n",
      "[644/1762] D loss: 1.4035, G loss: 0.6265\n",
      "[724/1762] D loss: 1.4426, G loss: 0.5862\n",
      "[804/1762] D loss: 1.3924, G loss: 0.6507\n",
      "[884/1762] D loss: 0.2446, G loss: 4.9494\n",
      "[964/1762] D loss: 2.9730, G loss: 0.7449\n",
      "[1044/1762] D loss: 1.3915, G loss: 0.7064\n",
      "[1124/1762] D loss: 1.4038, G loss: 0.6256\n",
      "[1204/1762] D loss: 1.2492, G loss: 1.1176\n",
      "[1284/1762] D loss: 0.0664, G loss: 3.3311\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7062\n",
      "[1444/1762] D loss: 1.4153, G loss: 0.6435\n",
      "[1524/1762] D loss: 1.3638, G loss: 0.8149\n",
      "[1604/1762] D loss: 1.4165, G loss: 0.6340\n",
      "[1684/1762] D loss: 1.2931, G loss: 1.0864\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.6851\n",
      "train error: \n",
      " D loss: 1.333208, G loss: 0.947593, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309636, G loss: 1.004284, D accuracy: 53.4%, cell accuracy: 99.5%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4039, G loss: 0.6176\n",
      "[84/1762] D loss: 0.0329, G loss: 4.1590\n",
      "[164/1762] D loss: 1.3965, G loss: 0.6280\n",
      "[244/1762] D loss: 1.3974, G loss: 0.6250\n",
      "[324/1762] D loss: 0.0284, G loss: 4.2233\n",
      "[404/1762] D loss: 1.3932, G loss: 0.7405\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6655\n",
      "[564/1762] D loss: 1.3896, G loss: 0.6892\n",
      "[644/1762] D loss: 0.2644, G loss: 3.7088\n",
      "[724/1762] D loss: 1.3994, G loss: 0.6254\n",
      "[804/1762] D loss: 0.1089, G loss: 3.9715\n",
      "[884/1762] D loss: 1.3843, G loss: 0.6400\n",
      "[964/1762] D loss: 0.1697, G loss: 3.3934\n",
      "[1044/1762] D loss: 1.4988, G loss: 0.6393\n",
      "[1124/1762] D loss: 1.4628, G loss: 0.6957\n",
      "[1204/1762] D loss: 0.4552, G loss: 2.0345\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6952\n",
      "[1364/1762] D loss: 1.5413, G loss: 0.6251\n",
      "[1444/1762] D loss: 0.2222, G loss: 3.6988\n",
      "[1524/1762] D loss: 1.3991, G loss: 0.7149\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.7135\n",
      "[1684/1762] D loss: 1.3918, G loss: 0.7281\n",
      "[1762/1762] D loss: 1.4101, G loss: 0.6607\n",
      "train error: \n",
      " D loss: 1.330268, G loss: 0.813207, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309828, G loss: 0.880450, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4053, G loss: 0.5995\n",
      "[84/1762] D loss: 1.4079, G loss: 0.6025\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6638\n",
      "[244/1762] D loss: 1.3898, G loss: 0.6795\n",
      "[324/1762] D loss: 1.3901, G loss: 0.7146\n",
      "[404/1762] D loss: 1.3874, G loss: 0.7658\n",
      "[484/1762] D loss: 1.0496, G loss: 1.3373\n",
      "[564/1762] D loss: 0.0831, G loss: 3.8208\n",
      "[644/1762] D loss: 1.3853, G loss: 0.7056\n",
      "[724/1762] D loss: 0.1447, G loss: 3.2863\n",
      "[804/1762] D loss: 0.1148, G loss: 3.1895\n",
      "[884/1762] D loss: 1.3862, G loss: 0.7005\n",
      "[964/1762] D loss: 0.0134, G loss: 5.6928\n",
      "[1044/1762] D loss: 1.4088, G loss: 0.6548\n",
      "[1124/1762] D loss: 1.3336, G loss: 0.7995\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.7027\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.6278\n",
      "[1364/1762] D loss: 0.8296, G loss: 2.6048\n",
      "[1444/1762] D loss: 1.3926, G loss: 0.6407\n",
      "[1524/1762] D loss: 1.0818, G loss: 5.3756\n",
      "[1604/1762] D loss: 0.1609, G loss: 3.3230\n",
      "[1684/1762] D loss: 0.0694, G loss: 4.2070\n",
      "[1762/1762] D loss: 1.4189, G loss: 0.7316\n",
      "train error: \n",
      " D loss: 1.319967, G loss: 1.015221, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311840, G loss: 1.097324, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.6812\n",
      "[84/1762] D loss: 1.3680, G loss: 1.0760\n",
      "[164/1762] D loss: 1.4141, G loss: 0.6478\n",
      "[244/1762] D loss: 1.4074, G loss: 0.6739\n",
      "[324/1762] D loss: 1.3859, G loss: 0.7029\n",
      "[404/1762] D loss: 1.3491, G loss: 0.7022\n",
      "[484/1762] D loss: 1.3907, G loss: 0.7197\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7212\n",
      "[644/1762] D loss: 1.3877, G loss: 0.6678\n",
      "[724/1762] D loss: 1.3956, G loss: 0.6271\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6675\n",
      "[884/1762] D loss: 1.5257, G loss: 0.6657\n",
      "[964/1762] D loss: 0.1150, G loss: 3.6049\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.6880\n",
      "[1124/1762] D loss: 0.4458, G loss: 3.0544\n",
      "[1204/1762] D loss: 1.3801, G loss: 0.6446\n",
      "[1284/1762] D loss: 1.4018, G loss: 0.6153\n",
      "[1364/1762] D loss: 0.0033, G loss: 5.8922\n",
      "[1444/1762] D loss: 1.2785, G loss: 0.7548\n",
      "[1524/1762] D loss: 1.6231, G loss: 0.5411\n",
      "[1604/1762] D loss: 1.4498, G loss: 0.6829\n",
      "[1684/1762] D loss: 0.6085, G loss: 4.6752\n",
      "[1762/1762] D loss: 1.3985, G loss: 0.6790\n",
      "train error: \n",
      " D loss: 1.340130, G loss: 0.862861, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340413, G loss: 0.928393, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4420, G loss: 0.6264\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6579\n",
      "[164/1762] D loss: 1.3982, G loss: 0.6287\n",
      "[244/1762] D loss: 1.3910, G loss: 0.6423\n",
      "[324/1762] D loss: 0.3576, G loss: 2.6443\n",
      "[404/1762] D loss: 1.3664, G loss: 0.7251\n",
      "[484/1762] D loss: 1.3828, G loss: 0.7888\n",
      "[564/1762] D loss: 1.4245, G loss: 0.7394\n",
      "[644/1762] D loss: 1.3945, G loss: 0.7411\n",
      "[724/1762] D loss: 1.1491, G loss: 2.9297\n",
      "[804/1762] D loss: 1.4025, G loss: 0.6020\n",
      "[884/1762] D loss: 0.3768, G loss: 4.6477\n",
      "[964/1762] D loss: 0.0982, G loss: 4.1013\n",
      "[1044/1762] D loss: 1.2526, G loss: 1.1079\n",
      "[1124/1762] D loss: 1.4032, G loss: 0.6843\n",
      "[1204/1762] D loss: 1.4372, G loss: 0.6538\n",
      "[1284/1762] D loss: 1.7658, G loss: 0.5909\n",
      "[1364/1762] D loss: 0.2238, G loss: 4.0232\n",
      "[1444/1762] D loss: 0.1241, G loss: 4.1501\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.6596\n",
      "[1604/1762] D loss: 0.1400, G loss: 3.2592\n",
      "[1684/1762] D loss: 0.1532, G loss: 3.8403\n",
      "[1762/1762] D loss: 0.0015, G loss: 6.7343\n",
      "train error: \n",
      " D loss: 1.410152, G loss: 0.623971, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393347, G loss: 0.648317, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0147, G loss: 4.6534\n",
      "[84/1762] D loss: 1.2311, G loss: 1.1244\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6695\n",
      "[244/1762] D loss: 0.0030, G loss: 7.4242\n",
      "[324/1762] D loss: 0.0162, G loss: 5.3109\n",
      "[404/1762] D loss: 1.3943, G loss: 0.6481\n",
      "[484/1762] D loss: 0.0071, G loss: 5.6453\n",
      "[564/1762] D loss: 1.5589, G loss: 0.6280\n",
      "[644/1762] D loss: 0.0630, G loss: 3.6786\n",
      "[724/1762] D loss: 1.3998, G loss: 0.6306\n",
      "[804/1762] D loss: 1.3968, G loss: 0.6699\n",
      "[884/1762] D loss: 1.3999, G loss: 0.7274\n",
      "[964/1762] D loss: 1.3930, G loss: 0.6592\n",
      "[1044/1762] D loss: 1.3946, G loss: 0.6234\n",
      "[1124/1762] D loss: 0.0457, G loss: 3.9528\n",
      "[1204/1762] D loss: 1.4291, G loss: 0.5476\n",
      "[1284/1762] D loss: 0.1728, G loss: 4.2775\n",
      "[1364/1762] D loss: 0.0024, G loss: 6.2539\n",
      "[1444/1762] D loss: 0.0362, G loss: 4.6401\n",
      "[1524/1762] D loss: 1.3495, G loss: 0.7202\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6711\n",
      "[1684/1762] D loss: 1.5615, G loss: 0.5600\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.6922\n",
      "train error: \n",
      " D loss: 1.321352, G loss: 0.769025, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312033, G loss: 0.794976, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.6472\n",
      "[84/1762] D loss: 1.4335, G loss: 0.5302\n",
      "[164/1762] D loss: 1.3757, G loss: 0.6983\n",
      "[244/1762] D loss: 1.3097, G loss: 0.7233\n",
      "[324/1762] D loss: 1.4110, G loss: 0.6434\n",
      "[404/1762] D loss: 1.3834, G loss: 0.6830\n",
      "[484/1762] D loss: 1.3895, G loss: 0.6501\n",
      "[564/1762] D loss: 1.3958, G loss: 0.7549\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6966\n",
      "[724/1762] D loss: 1.3911, G loss: 0.7233\n",
      "[804/1762] D loss: 0.0944, G loss: 3.9160\n",
      "[884/1762] D loss: 0.0698, G loss: 4.1517\n",
      "[964/1762] D loss: 0.1667, G loss: 4.7793\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.6686\n",
      "[1124/1762] D loss: 1.3940, G loss: 0.7125\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6681\n",
      "[1284/1762] D loss: 1.5147, G loss: 0.6048\n",
      "[1364/1762] D loss: 0.9819, G loss: 1.2421\n",
      "[1444/1762] D loss: 1.4156, G loss: 0.5669\n",
      "[1524/1762] D loss: 0.2454, G loss: 4.8322\n",
      "[1604/1762] D loss: 0.9675, G loss: 2.2322\n",
      "[1684/1762] D loss: 0.1057, G loss: 4.4081\n",
      "[1762/1762] D loss: 0.0078, G loss: 5.2142\n",
      "train error: \n",
      " D loss: 1.465518, G loss: 0.533464, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.467881, G loss: 0.546019, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3919, G loss: 0.6546\n",
      "[84/1762] D loss: 0.0026, G loss: 6.6697\n",
      "[164/1762] D loss: 1.3975, G loss: 0.6409\n",
      "[244/1762] D loss: 0.0432, G loss: 5.3496\n",
      "[324/1762] D loss: 1.4121, G loss: 0.7392\n",
      "[404/1762] D loss: 1.3889, G loss: 0.6870\n",
      "[484/1762] D loss: 1.3261, G loss: 0.7691\n",
      "[564/1762] D loss: 1.3891, G loss: 0.6718\n",
      "[644/1762] D loss: 1.3717, G loss: 0.7744\n",
      "[724/1762] D loss: 1.7364, G loss: 0.4331\n",
      "[804/1762] D loss: 1.2795, G loss: 0.9362\n",
      "[884/1762] D loss: 1.4503, G loss: 0.6944\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6890\n",
      "[1044/1762] D loss: 0.0620, G loss: 4.1926\n",
      "[1124/1762] D loss: 1.3936, G loss: 0.6497\n",
      "[1204/1762] D loss: 1.7062, G loss: 0.5718\n",
      "[1284/1762] D loss: 1.7863, G loss: 0.6269\n",
      "[1364/1762] D loss: 0.0387, G loss: 4.7106\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6968\n",
      "[1524/1762] D loss: 0.0970, G loss: 3.5820\n",
      "[1604/1762] D loss: 1.4179, G loss: 0.7534\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6823\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6768\n",
      "train error: \n",
      " D loss: 1.305453, G loss: 0.893735, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282916, G loss: 0.992590, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3920, G loss: 0.6781\n",
      "[84/1762] D loss: 0.0033, G loss: 6.5867\n",
      "[164/1762] D loss: 0.0802, G loss: 4.4903\n",
      "[244/1762] D loss: 1.3895, G loss: 0.6856\n",
      "[324/1762] D loss: 0.0249, G loss: 4.5281\n",
      "[404/1762] D loss: 1.0971, G loss: 1.5535\n",
      "[484/1762] D loss: 1.2461, G loss: 0.6895\n",
      "[564/1762] D loss: 1.3622, G loss: 0.6341\n",
      "[644/1762] D loss: 1.1496, G loss: 1.1856\n",
      "[724/1762] D loss: 1.4131, G loss: 0.5723\n",
      "[804/1762] D loss: 1.0530, G loss: 0.6908\n",
      "[884/1762] D loss: 1.3926, G loss: 0.6762\n",
      "[964/1762] D loss: 1.3818, G loss: 0.6955\n",
      "[1044/1762] D loss: 0.5478, G loss: 2.3450\n",
      "[1124/1762] D loss: 1.4457, G loss: 0.7144\n",
      "[1204/1762] D loss: 1.3923, G loss: 0.7109\n",
      "[1284/1762] D loss: 1.3939, G loss: 0.6934\n",
      "[1364/1762] D loss: 1.3995, G loss: 0.6289\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.7061\n",
      "[1524/1762] D loss: 1.3849, G loss: 0.6969\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.6602\n",
      "[1684/1762] D loss: 1.3915, G loss: 0.7285\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.6903\n",
      "train error: \n",
      " D loss: 1.330937, G loss: 0.772621, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310266, G loss: 0.842032, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3823, G loss: 0.6667\n",
      "[84/1762] D loss: 1.3934, G loss: 0.6587\n",
      "[164/1762] D loss: 0.0311, G loss: 4.3024\n",
      "[244/1762] D loss: 1.3896, G loss: 0.7087\n",
      "[324/1762] D loss: 1.3892, G loss: 0.6782\n",
      "[404/1762] D loss: 0.2037, G loss: 3.8018\n",
      "[484/1762] D loss: 1.3953, G loss: 0.6738\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6931\n",
      "[644/1762] D loss: 1.3957, G loss: 0.7316\n",
      "[724/1762] D loss: 0.5960, G loss: 2.9393\n",
      "[804/1762] D loss: 1.3915, G loss: 0.6617\n",
      "[884/1762] D loss: 0.8974, G loss: 3.0981\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6627\n",
      "[1044/1762] D loss: 1.3380, G loss: 0.7898\n",
      "[1124/1762] D loss: 1.3717, G loss: 0.7569\n",
      "[1204/1762] D loss: 1.3941, G loss: 0.6278\n",
      "[1284/1762] D loss: 0.7353, G loss: 2.4256\n",
      "[1364/1762] D loss: 1.3922, G loss: 0.6311\n",
      "[1444/1762] D loss: 0.8840, G loss: 2.1573\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.6065\n",
      "[1604/1762] D loss: 1.3007, G loss: 1.4050\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.6404\n",
      "[1762/1762] D loss: 1.6749, G loss: 0.4787\n",
      "train error: \n",
      " D loss: 1.925396, G loss: 0.314910, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.899735, G loss: 0.347098, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0234, G loss: 4.3221\n",
      "[84/1762] D loss: 1.2543, G loss: 0.9792\n",
      "[164/1762] D loss: 1.3964, G loss: 0.6436\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6956\n",
      "[324/1762] D loss: 0.1685, G loss: 4.9259\n",
      "[404/1762] D loss: 1.4064, G loss: 0.6311\n",
      "[484/1762] D loss: 1.3949, G loss: 0.6281\n",
      "[564/1762] D loss: 1.3900, G loss: 0.6843\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6802\n",
      "[724/1762] D loss: 0.0408, G loss: 4.1380\n",
      "[804/1762] D loss: 0.0426, G loss: 4.0985\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6924\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6794\n",
      "[1044/1762] D loss: 1.3949, G loss: 0.6567\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6755\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6673\n",
      "[1284/1762] D loss: 0.0733, G loss: 3.8574\n",
      "[1364/1762] D loss: 0.1070, G loss: 4.7703\n",
      "[1444/1762] D loss: 0.5870, G loss: 1.1683\n",
      "[1524/1762] D loss: 1.3354, G loss: 0.7030\n",
      "[1604/1762] D loss: 0.3028, G loss: 3.0315\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.6801\n",
      "[1762/1762] D loss: 1.4119, G loss: 0.6984\n",
      "train error: \n",
      " D loss: 1.310474, G loss: 0.921057, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287071, G loss: 1.002873, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5030, G loss: 0.5397\n",
      "[84/1762] D loss: 0.0975, G loss: 3.4617\n",
      "[164/1762] D loss: 1.4503, G loss: 0.6343\n",
      "[244/1762] D loss: 1.3898, G loss: 0.6693\n",
      "[324/1762] D loss: 0.0735, G loss: 3.5935\n",
      "[404/1762] D loss: 0.5130, G loss: 2.3733\n",
      "[484/1762] D loss: 0.0248, G loss: 4.5568\n",
      "[564/1762] D loss: 0.0020, G loss: 8.8116\n",
      "[644/1762] D loss: 1.3930, G loss: 0.6660\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6804\n",
      "[804/1762] D loss: 1.4770, G loss: 0.6188\n",
      "[884/1762] D loss: 1.3938, G loss: 0.6293\n",
      "[964/1762] D loss: 1.3890, G loss: 0.7090\n",
      "[1044/1762] D loss: 0.2426, G loss: 3.4371\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.6494\n",
      "[1204/1762] D loss: 0.0809, G loss: 4.1430\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.6481\n",
      "[1364/1762] D loss: 1.3972, G loss: 0.6543\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6790\n",
      "[1524/1762] D loss: 1.2503, G loss: 1.5549\n",
      "[1604/1762] D loss: 0.0052, G loss: 5.8937\n",
      "[1684/1762] D loss: 1.4008, G loss: 0.7209\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6484\n",
      "train error: \n",
      " D loss: 1.305614, G loss: 0.858535, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283804, G loss: 0.952004, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.6325\n",
      "[84/1762] D loss: 1.3880, G loss: 0.6718\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6552\n",
      "[244/1762] D loss: 1.3875, G loss: 0.6821\n",
      "[324/1762] D loss: 0.6935, G loss: 1.1656\n",
      "[404/1762] D loss: 1.4215, G loss: 0.7231\n",
      "[484/1762] D loss: 0.3823, G loss: 2.6920\n",
      "[564/1762] D loss: 1.3974, G loss: 0.6084\n",
      "[644/1762] D loss: 1.3502, G loss: 1.1118\n",
      "[724/1762] D loss: 1.4066, G loss: 0.6930\n",
      "[804/1762] D loss: 1.3985, G loss: 0.7247\n",
      "[884/1762] D loss: 1.4381, G loss: 0.6581\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7001\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.6801\n",
      "[1124/1762] D loss: 0.1181, G loss: 4.1312\n",
      "[1204/1762] D loss: 1.4052, G loss: 0.6031\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6720\n",
      "[1364/1762] D loss: 1.3645, G loss: 0.8610\n",
      "[1444/1762] D loss: 0.0564, G loss: 5.4470\n",
      "[1524/1762] D loss: 1.3969, G loss: 0.6079\n",
      "[1604/1762] D loss: 0.4513, G loss: 2.0163\n",
      "[1684/1762] D loss: 0.1342, G loss: 8.7935\n",
      "[1762/1762] D loss: 1.3313, G loss: 0.8087\n",
      "train error: \n",
      " D loss: 1.362550, G loss: 1.078030, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345077, G loss: 1.249254, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1192, G loss: 4.1829\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7112\n",
      "[164/1762] D loss: 1.1611, G loss: 4.2435\n",
      "[244/1762] D loss: 1.3963, G loss: 0.6163\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7080\n",
      "[404/1762] D loss: 1.3936, G loss: 0.7784\n",
      "[484/1762] D loss: 1.3681, G loss: 0.7657\n",
      "[564/1762] D loss: 1.5324, G loss: 0.7149\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6930\n",
      "[724/1762] D loss: 1.3928, G loss: 0.6458\n",
      "[804/1762] D loss: 1.3936, G loss: 0.6024\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7163\n",
      "[964/1762] D loss: 1.4030, G loss: 0.6764\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7042\n",
      "[1124/1762] D loss: 1.3350, G loss: 0.8078\n",
      "[1204/1762] D loss: 0.4717, G loss: 2.7599\n",
      "[1284/1762] D loss: 1.4582, G loss: 0.8416\n",
      "[1364/1762] D loss: 1.4033, G loss: 0.6484\n",
      "[1444/1762] D loss: 1.4518, G loss: 0.6762\n",
      "[1524/1762] D loss: 0.4149, G loss: 2.1301\n",
      "[1604/1762] D loss: 0.0945, G loss: 4.4707\n",
      "[1684/1762] D loss: 1.5798, G loss: 0.6486\n",
      "[1762/1762] D loss: 1.5500, G loss: 0.5595\n",
      "train error: \n",
      " D loss: 1.322620, G loss: 0.705229, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301258, G loss: 0.731210, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3431, G loss: 3.8121\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7023\n",
      "[164/1762] D loss: 0.0308, G loss: 4.1489\n",
      "[244/1762] D loss: 1.4106, G loss: 0.5754\n",
      "[324/1762] D loss: 1.3933, G loss: 0.6339\n",
      "[404/1762] D loss: 0.0605, G loss: 4.6842\n",
      "[484/1762] D loss: 1.3890, G loss: 0.7301\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6523\n",
      "[644/1762] D loss: 1.3962, G loss: 0.6355\n",
      "[724/1762] D loss: 0.0458, G loss: 4.4878\n",
      "[804/1762] D loss: 1.3717, G loss: 0.6842\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6990\n",
      "[964/1762] D loss: 1.3901, G loss: 0.6837\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6888\n",
      "[1124/1762] D loss: 1.4036, G loss: 0.5997\n",
      "[1204/1762] D loss: 1.3794, G loss: 0.7196\n",
      "[1284/1762] D loss: 0.0011, G loss: 8.7703\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6841\n",
      "[1444/1762] D loss: 0.0048, G loss: 5.8892\n",
      "[1524/1762] D loss: 1.2966, G loss: 1.2754\n",
      "[1604/1762] D loss: 0.0401, G loss: 4.5935\n",
      "[1684/1762] D loss: 1.3902, G loss: 0.7392\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7226\n",
      "train error: \n",
      " D loss: 1.305408, G loss: 0.921260, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286082, G loss: 1.008912, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for cls in [TetrisDiscriminator, DiscWithLeakyReLU]:\n",
    "    train(run_name=cls.__name__, disc_cls=cls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leaky ReLU doesn't seem to improve anything."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Adam\n",
    "\n",
    "What??? Apparently we've been using SGD instead of Adam this whole time! Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", disc_cls=TetrisDiscriminator, learning_rate=1e-2, beta1=0.9, batch_size=4):\n",
    "    epochs = 50\n",
    "\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = disc_cls().to(device)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate, betas=(beta1, 0.999))\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_018\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3761, G loss: 0.8881\n",
      "[84/1762] D loss: 0.0480, G loss: 9.0529\n",
      "[164/1762] D loss: 0.7109, G loss: 1.9697\n",
      "[244/1762] D loss: 0.0792, G loss: 7.8136\n",
      "[324/1762] D loss: 0.1144, G loss: 8.3762\n",
      "[404/1762] D loss: 1.4968, G loss: 1.7351\n",
      "[484/1762] D loss: 0.4892, G loss: 4.0273\n",
      "[564/1762] D loss: 0.8031, G loss: 1.2203\n",
      "[644/1762] D loss: 0.1756, G loss: 3.2178\n",
      "[724/1762] D loss: 0.6650, G loss: 4.5854\n",
      "[804/1762] D loss: 0.0932, G loss: 8.4619\n",
      "[884/1762] D loss: 0.1161, G loss: 4.6898\n",
      "[964/1762] D loss: 0.2300, G loss: 2.9076\n",
      "[1044/1762] D loss: 0.5348, G loss: 2.9772\n",
      "[1124/1762] D loss: 1.1148, G loss: 6.1005\n",
      "[1204/1762] D loss: 0.2612, G loss: 3.7832\n",
      "[1284/1762] D loss: 0.1535, G loss: 4.6657\n",
      "[1364/1762] D loss: 0.0946, G loss: 5.2144\n",
      "[1444/1762] D loss: 0.2621, G loss: 2.9920\n",
      "[1524/1762] D loss: 0.3452, G loss: 3.1620\n",
      "[1604/1762] D loss: 1.0174, G loss: 1.4952\n",
      "[1684/1762] D loss: 0.2567, G loss: 3.9271\n",
      "[1762/1762] D loss: 0.2069, G loss: 3.4867\n",
      "train error: \n",
      " D loss: 1.011386, G loss: 4.388000, D accuracy: 81.2%, cell accuracy: 95.1%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.139037, G loss: 4.529456, D accuracy: 79.7%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0923, G loss: 6.0722\n",
      "[84/1762] D loss: 0.5385, G loss: 2.9577\n",
      "[164/1762] D loss: 0.5859, G loss: 1.6239\n",
      "[244/1762] D loss: 0.9142, G loss: 3.3703\n",
      "[324/1762] D loss: 1.7278, G loss: 2.0341\n",
      "[404/1762] D loss: 1.2682, G loss: 0.6333\n",
      "[484/1762] D loss: 1.2172, G loss: 0.7907\n",
      "[564/1762] D loss: 1.2671, G loss: 1.1049\n",
      "[644/1762] D loss: 1.2844, G loss: 0.6733\n",
      "[724/1762] D loss: 1.0012, G loss: 1.1455\n",
      "[804/1762] D loss: 1.3100, G loss: 1.0437\n",
      "[884/1762] D loss: 0.9961, G loss: 1.2218\n",
      "[964/1762] D loss: 1.1377, G loss: 0.6190\n",
      "[1044/1762] D loss: 1.1532, G loss: 0.7573\n",
      "[1124/1762] D loss: 0.9789, G loss: 1.7442\n",
      "[1204/1762] D loss: 1.2497, G loss: 2.0853\n",
      "[1284/1762] D loss: 1.3945, G loss: 1.8826\n",
      "[1364/1762] D loss: 0.4254, G loss: 2.5207\n",
      "[1444/1762] D loss: 0.4151, G loss: 2.5191\n",
      "[1524/1762] D loss: 0.8341, G loss: 1.6445\n",
      "[1604/1762] D loss: 1.2615, G loss: 1.2887\n",
      "[1684/1762] D loss: 1.3375, G loss: 0.7299\n",
      "[1762/1762] D loss: 1.3551, G loss: 0.7134\n",
      "train error: \n",
      " D loss: 1.285184, G loss: 1.160139, D accuracy: 58.4%, cell accuracy: 99.5%, board accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.241948, G loss: 1.189896, D accuracy: 60.5%, cell accuracy: 99.5%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4215, G loss: 0.6851\n",
      "[84/1762] D loss: 0.9864, G loss: 1.0805\n",
      "[164/1762] D loss: 0.9243, G loss: 1.1428\n",
      "[244/1762] D loss: 1.4113, G loss: 0.8080\n",
      "[324/1762] D loss: 1.4746, G loss: 0.6055\n",
      "[404/1762] D loss: 0.7653, G loss: 3.5756\n",
      "[484/1762] D loss: 0.8842, G loss: 1.7769\n",
      "[564/1762] D loss: 0.9033, G loss: 1.5749\n",
      "[644/1762] D loss: 1.8583, G loss: 1.8486\n",
      "[724/1762] D loss: 1.2865, G loss: 1.1419\n",
      "[804/1762] D loss: 0.6328, G loss: 1.6646\n",
      "[884/1762] D loss: 0.4951, G loss: 1.4661\n",
      "[964/1762] D loss: 1.5413, G loss: 0.9482\n",
      "[1044/1762] D loss: 1.4662, G loss: 0.9933\n",
      "[1124/1762] D loss: 1.3802, G loss: 0.6562\n",
      "[1204/1762] D loss: 1.4032, G loss: 0.8185\n",
      "[1284/1762] D loss: 1.4505, G loss: 0.6054\n",
      "[1364/1762] D loss: 1.0177, G loss: 0.9701\n",
      "[1444/1762] D loss: 0.9558, G loss: 1.0299\n",
      "[1524/1762] D loss: 0.4617, G loss: 2.2089\n",
      "[1604/1762] D loss: 0.1106, G loss: 4.8606\n",
      "[1684/1762] D loss: 0.7515, G loss: 1.0928\n",
      "[1762/1762] D loss: 1.5746, G loss: 0.9991\n",
      "train error: \n",
      " D loss: 1.524532, G loss: 1.329316, D accuracy: 51.8%, cell accuracy: 99.6%, board accuracy: 62.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.491550, G loss: 1.323479, D accuracy: 53.6%, cell accuracy: 99.5%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5672, G loss: 0.7923\n",
      "[84/1762] D loss: 1.1765, G loss: 1.3241\n",
      "[164/1762] D loss: 0.7013, G loss: 1.3047\n",
      "[244/1762] D loss: 1.1868, G loss: 0.8659\n",
      "[324/1762] D loss: 1.4113, G loss: 0.6272\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6386\n",
      "[484/1762] D loss: 1.5504, G loss: 0.3936\n",
      "[564/1762] D loss: 0.1066, G loss: 2.6413\n",
      "[644/1762] D loss: 0.3002, G loss: 2.8919\n",
      "[724/1762] D loss: 0.7836, G loss: 1.1547\n",
      "[804/1762] D loss: 1.4067, G loss: 0.7401\n",
      "[884/1762] D loss: 1.5668, G loss: 0.7050\n",
      "[964/1762] D loss: 1.7154, G loss: 1.2823\n",
      "[1044/1762] D loss: 1.2110, G loss: 1.3943\n",
      "[1124/1762] D loss: 1.5906, G loss: 0.7856\n",
      "[1204/1762] D loss: 1.3075, G loss: 0.5979\n",
      "[1284/1762] D loss: 1.3968, G loss: 0.5978\n",
      "[1364/1762] D loss: 0.9460, G loss: 1.8235\n",
      "[1444/1762] D loss: 0.9810, G loss: 1.6766\n",
      "[1524/1762] D loss: 1.2008, G loss: 0.9034\n",
      "[1604/1762] D loss: 0.9472, G loss: 1.5452\n",
      "[1684/1762] D loss: 0.8523, G loss: 2.0018\n",
      "[1762/1762] D loss: 1.4707, G loss: 0.6029\n",
      "train error: \n",
      " D loss: 1.371811, G loss: 0.918511, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350927, G loss: 0.966920, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6555, G loss: 0.4930\n",
      "[84/1762] D loss: 1.6817, G loss: 1.3706\n",
      "[164/1762] D loss: 0.4237, G loss: 4.9005\n",
      "[244/1762] D loss: 0.7111, G loss: 2.1638\n",
      "[324/1762] D loss: 1.8150, G loss: 0.6202\n",
      "[404/1762] D loss: 1.6947, G loss: 0.3940\n",
      "[484/1762] D loss: 1.1947, G loss: 2.0142\n",
      "[564/1762] D loss: 1.5394, G loss: 0.6655\n",
      "[644/1762] D loss: 1.4078, G loss: 0.6282\n",
      "[724/1762] D loss: 1.1139, G loss: 0.8989\n",
      "[804/1762] D loss: 0.8062, G loss: 1.4530\n",
      "[884/1762] D loss: 0.3266, G loss: 2.4068\n",
      "[964/1762] D loss: 1.4916, G loss: 0.7861\n",
      "[1044/1762] D loss: 1.8158, G loss: 0.3499\n",
      "[1124/1762] D loss: 1.5216, G loss: 1.1312\n",
      "[1204/1762] D loss: 1.2995, G loss: 0.5043\n",
      "[1284/1762] D loss: 0.3085, G loss: 1.9451\n",
      "[1364/1762] D loss: 1.8518, G loss: 1.1010\n",
      "[1444/1762] D loss: 1.4524, G loss: 0.7205\n",
      "[1524/1762] D loss: 1.3897, G loss: 0.7659\n",
      "[1604/1762] D loss: 0.2245, G loss: 2.9251\n",
      "[1684/1762] D loss: 1.2237, G loss: 0.5599\n",
      "[1762/1762] D loss: 1.4488, G loss: 0.4530\n",
      "train error: \n",
      " D loss: 1.384266, G loss: 0.866510, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375671, G loss: 0.972710, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6269, G loss: 0.3993\n",
      "[84/1762] D loss: 0.3614, G loss: 2.3034\n",
      "[164/1762] D loss: 1.6736, G loss: 0.9648\n",
      "[244/1762] D loss: 1.4285, G loss: 0.8460\n",
      "[324/1762] D loss: 1.5142, G loss: 0.6868\n",
      "[404/1762] D loss: 1.4655, G loss: 0.5299\n",
      "[484/1762] D loss: 1.4589, G loss: 0.5096\n",
      "[564/1762] D loss: 1.4145, G loss: 0.5206\n",
      "[644/1762] D loss: 0.2877, G loss: 2.3590\n",
      "[724/1762] D loss: 1.2985, G loss: 0.7056\n",
      "[804/1762] D loss: 0.3810, G loss: 1.8532\n",
      "[884/1762] D loss: 0.3197, G loss: 2.5577\n",
      "[964/1762] D loss: 1.5239, G loss: 0.5906\n",
      "[1044/1762] D loss: 0.9651, G loss: 1.4189\n",
      "[1124/1762] D loss: 0.5271, G loss: 1.3539\n",
      "[1204/1762] D loss: 1.1397, G loss: 1.0013\n",
      "[1284/1762] D loss: 0.3375, G loss: 1.9568\n",
      "[1364/1762] D loss: 1.4446, G loss: 0.5846\n",
      "[1444/1762] D loss: 0.1666, G loss: 4.2774\n",
      "[1524/1762] D loss: 1.1120, G loss: 1.2718\n",
      "[1604/1762] D loss: 1.4550, G loss: 0.6532\n",
      "[1684/1762] D loss: 0.3411, G loss: 3.5888\n",
      "[1762/1762] D loss: 1.4975, G loss: 0.8428\n",
      "train error: \n",
      " D loss: 1.542561, G loss: 1.576265, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.539512, G loss: 1.681853, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4030, G loss: 0.7737\n",
      "[84/1762] D loss: 1.0937, G loss: 1.5196\n",
      "[164/1762] D loss: 1.6045, G loss: 0.4271\n",
      "[244/1762] D loss: 1.4873, G loss: 0.5937\n",
      "[324/1762] D loss: 1.3965, G loss: 0.5773\n",
      "[404/1762] D loss: 1.4395, G loss: 0.8610\n",
      "[484/1762] D loss: 1.3972, G loss: 0.7027\n",
      "[564/1762] D loss: 1.3909, G loss: 0.7106\n",
      "[644/1762] D loss: 0.1300, G loss: 3.9900\n",
      "[724/1762] D loss: 0.4882, G loss: 2.7585\n",
      "[804/1762] D loss: 1.7505, G loss: 1.1448\n",
      "[884/1762] D loss: 1.7952, G loss: 0.6618\n",
      "[964/1762] D loss: 0.2271, G loss: 2.3328\n",
      "[1044/1762] D loss: 1.4012, G loss: 0.4551\n",
      "[1124/1762] D loss: 1.1040, G loss: 1.0171\n",
      "[1204/1762] D loss: 1.6005, G loss: 0.4736\n",
      "[1284/1762] D loss: 1.7351, G loss: 0.9365\n",
      "[1364/1762] D loss: 0.4408, G loss: 2.0305\n",
      "[1444/1762] D loss: 1.4834, G loss: 0.8488\n",
      "[1524/1762] D loss: 0.1691, G loss: 2.8932\n",
      "[1604/1762] D loss: 1.4938, G loss: 0.8617\n",
      "[1684/1762] D loss: 0.3432, G loss: 2.8949\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6783\n",
      "train error: \n",
      " D loss: 1.409884, G loss: 0.929218, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398778, G loss: 1.034509, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4099, G loss: 0.5636\n",
      "[84/1762] D loss: 1.4051, G loss: 0.5907\n",
      "[164/1762] D loss: 1.3603, G loss: 0.6160\n",
      "[244/1762] D loss: 1.6449, G loss: 0.2993\n",
      "[324/1762] D loss: 1.4187, G loss: 0.7943\n",
      "[404/1762] D loss: 1.4116, G loss: 0.6243\n",
      "[484/1762] D loss: 0.3995, G loss: 4.0625\n",
      "[564/1762] D loss: 1.3729, G loss: 1.0596\n",
      "[644/1762] D loss: 1.5762, G loss: 0.4029\n",
      "[724/1762] D loss: 1.3914, G loss: 0.7269\n",
      "[804/1762] D loss: 1.4043, G loss: 0.6226\n",
      "[884/1762] D loss: 0.5171, G loss: 2.2820\n",
      "[964/1762] D loss: 1.0220, G loss: 1.4110\n",
      "[1044/1762] D loss: 0.2484, G loss: 2.0935\n",
      "[1124/1762] D loss: 0.0569, G loss: 5.2413\n",
      "[1204/1762] D loss: 1.9304, G loss: 0.6763\n",
      "[1284/1762] D loss: 0.9944, G loss: 1.2355\n",
      "[1364/1762] D loss: 1.6465, G loss: 1.2144\n",
      "[1444/1762] D loss: 0.5486, G loss: 3.3984\n",
      "[1524/1762] D loss: 0.1745, G loss: 3.3746\n",
      "[1604/1762] D loss: 0.0261, G loss: 5.1063\n",
      "[1684/1762] D loss: 0.0065, G loss: 6.7003\n",
      "[1762/1762] D loss: 0.0076, G loss: 6.6682\n",
      "train error: \n",
      " D loss: 1.631937, G loss: 11.258885, D accuracy: 57.7%, cell accuracy: 86.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.686763, G loss: 10.961722, D accuracy: 56.6%, cell accuracy: 87.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0115, G loss: 6.5512\n",
      "[84/1762] D loss: 0.0025, G loss: 8.9317\n",
      "[164/1762] D loss: 0.0023, G loss: 8.6699\n",
      "[244/1762] D loss: 0.0039, G loss: 7.2073\n",
      "[324/1762] D loss: 0.0164, G loss: 4.5476\n",
      "[404/1762] D loss: 0.0081, G loss: 6.1670\n",
      "[484/1762] D loss: 0.0082, G loss: 6.6256\n",
      "[564/1762] D loss: 0.0015, G loss: 9.3606\n",
      "[644/1762] D loss: 0.0042, G loss: 9.4830\n",
      "[724/1762] D loss: 0.0015, G loss: 8.7913\n",
      "[804/1762] D loss: 0.0009, G loss: 9.5626\n",
      "[884/1762] D loss: 0.0015, G loss: 9.4184\n",
      "[964/1762] D loss: 0.0074, G loss: 8.6718\n",
      "[1044/1762] D loss: 0.0021, G loss: 7.2357\n",
      "[1124/1762] D loss: 0.0047, G loss: 6.2549\n",
      "[1204/1762] D loss: 0.0011, G loss: 7.9377\n",
      "[1284/1762] D loss: 0.0019, G loss: 8.9093\n",
      "[1364/1762] D loss: 0.0010, G loss: 8.0284\n",
      "[1444/1762] D loss: 0.0030, G loss: 8.2052\n",
      "[1524/1762] D loss: 0.0017, G loss: 10.0951\n",
      "[1604/1762] D loss: 0.0015, G loss: 12.0151\n",
      "[1684/1762] D loss: 0.0010, G loss: 10.9003\n",
      "[1762/1762] D loss: 0.0008, G loss: 10.3344\n",
      "train error: \n",
      " D loss: 1.910919, G loss: 10.407607, D accuracy: 55.8%, cell accuracy: 92.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.920909, G loss: 10.606258, D accuracy: 55.9%, cell accuracy: 91.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0012, G loss: 8.6015\n",
      "[84/1762] D loss: 0.0303, G loss: 10.1082\n",
      "[164/1762] D loss: 0.0059, G loss: 8.8698\n",
      "[244/1762] D loss: 0.0010, G loss: 17.4645\n",
      "[324/1762] D loss: 0.1871, G loss: 3.8121\n",
      "[404/1762] D loss: 0.6751, G loss: 5.7158\n",
      "[484/1762] D loss: 0.1028, G loss: 6.3114\n",
      "[564/1762] D loss: 1.1776, G loss: 3.8353\n",
      "[644/1762] D loss: 0.5618, G loss: 1.6324\n",
      "[724/1762] D loss: 0.1381, G loss: 3.6866\n",
      "[804/1762] D loss: 0.2134, G loss: 6.0279\n",
      "[884/1762] D loss: 0.5650, G loss: 2.8811\n",
      "[964/1762] D loss: 1.7355, G loss: 1.2695\n",
      "[1044/1762] D loss: 1.0964, G loss: 1.6620\n",
      "[1124/1762] D loss: 0.4151, G loss: 2.1612\n",
      "[1204/1762] D loss: 1.4010, G loss: 0.6057\n",
      "[1284/1762] D loss: 1.4032, G loss: 0.6741\n",
      "[1364/1762] D loss: 0.3694, G loss: 2.0434\n",
      "[1444/1762] D loss: 1.5034, G loss: 0.9578\n",
      "[1524/1762] D loss: 0.3806, G loss: 3.1813\n",
      "[1604/1762] D loss: 1.1150, G loss: 1.5131\n",
      "[1684/1762] D loss: 1.6849, G loss: 1.0063\n",
      "[1762/1762] D loss: 0.1684, G loss: 2.6249\n",
      "train error: \n",
      " D loss: 1.342410, G loss: 0.872048, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302237, G loss: 0.955427, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6159, G loss: 0.3495\n",
      "[84/1762] D loss: 1.3033, G loss: 0.9083\n",
      "[164/1762] D loss: 0.2658, G loss: 2.7477\n",
      "[244/1762] D loss: 1.4445, G loss: 0.8939\n",
      "[324/1762] D loss: 1.1199, G loss: 2.5926\n",
      "[404/1762] D loss: 1.4958, G loss: 0.6557\n",
      "[484/1762] D loss: 0.2053, G loss: 2.2374\n",
      "[564/1762] D loss: 1.4048, G loss: 0.5729\n",
      "[644/1762] D loss: 0.2424, G loss: 2.9875\n",
      "[724/1762] D loss: 0.1656, G loss: 2.9330\n",
      "[804/1762] D loss: 1.5529, G loss: 0.9282\n",
      "[884/1762] D loss: 1.4306, G loss: 0.7423\n",
      "[964/1762] D loss: 1.4983, G loss: 0.9880\n",
      "[1044/1762] D loss: 0.3032, G loss: 2.6496\n",
      "[1124/1762] D loss: 0.2648, G loss: 2.8424\n",
      "[1204/1762] D loss: 0.1554, G loss: 3.9390\n",
      "[1284/1762] D loss: 1.5276, G loss: 1.1047\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.6412\n",
      "[1444/1762] D loss: 1.3510, G loss: 0.6171\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7076\n",
      "[1604/1762] D loss: 1.4112, G loss: 0.5462\n",
      "[1684/1762] D loss: 1.4315, G loss: 0.6057\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6783\n",
      "train error: \n",
      " D loss: 1.252128, G loss: 1.978179, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.227407, G loss: 2.260190, D accuracy: 57.4%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4288, G loss: 0.8657\n",
      "[84/1762] D loss: 1.4247, G loss: 0.6838\n",
      "[164/1762] D loss: 1.1311, G loss: 1.3337\n",
      "[244/1762] D loss: 1.3927, G loss: 0.5926\n",
      "[324/1762] D loss: 0.2403, G loss: 3.8142\n",
      "[404/1762] D loss: 0.2216, G loss: 3.7670\n",
      "[484/1762] D loss: 0.1568, G loss: 3.9833\n",
      "[564/1762] D loss: 0.2779, G loss: 3.0757\n",
      "[644/1762] D loss: 0.1853, G loss: 3.6433\n",
      "[724/1762] D loss: 1.5207, G loss: 0.9975\n",
      "[804/1762] D loss: 1.6121, G loss: 0.9349\n",
      "[884/1762] D loss: 1.2080, G loss: 1.0760\n",
      "[964/1762] D loss: 1.4989, G loss: 0.5750\n",
      "[1044/1762] D loss: 0.1383, G loss: 3.5780\n",
      "[1124/1762] D loss: 0.9162, G loss: 2.3998\n",
      "[1204/1762] D loss: 1.3717, G loss: 0.9037\n",
      "[1284/1762] D loss: 0.0788, G loss: 4.3735\n",
      "[1364/1762] D loss: 1.4842, G loss: 0.9102\n",
      "[1444/1762] D loss: 0.2045, G loss: 2.5061\n",
      "[1524/1762] D loss: 0.0794, G loss: 3.8828\n",
      "[1604/1762] D loss: 1.4994, G loss: 0.4624\n",
      "[1684/1762] D loss: 0.0485, G loss: 4.3977\n",
      "[1762/1762] D loss: 0.5572, G loss: 3.2489\n",
      "train error: \n",
      " D loss: 1.321957, G loss: 0.931885, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289352, G loss: 1.037478, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0304, G loss: 4.5500\n",
      "[84/1762] D loss: 0.4473, G loss: 2.7825\n",
      "[164/1762] D loss: 1.2975, G loss: 0.6299\n",
      "[244/1762] D loss: 1.4147, G loss: 0.7873\n",
      "[324/1762] D loss: 1.4034, G loss: 0.7727\n",
      "[404/1762] D loss: 0.4840, G loss: 4.9490\n",
      "[484/1762] D loss: 0.2165, G loss: 3.0851\n",
      "[564/1762] D loss: 0.0755, G loss: 3.5870\n",
      "[644/1762] D loss: 0.0955, G loss: 3.6379\n",
      "[724/1762] D loss: 1.4360, G loss: 0.5926\n",
      "[804/1762] D loss: 0.0740, G loss: 4.2170\n",
      "[884/1762] D loss: 1.4884, G loss: 0.8151\n",
      "[964/1762] D loss: 1.4341, G loss: 1.0474\n",
      "[1044/1762] D loss: 1.5605, G loss: 0.4255\n",
      "[1124/1762] D loss: 1.4200, G loss: 0.8350\n",
      "[1204/1762] D loss: 1.2707, G loss: 0.9906\n",
      "[1284/1762] D loss: 1.3602, G loss: 0.8529\n",
      "[1364/1762] D loss: 1.4060, G loss: 0.6061\n",
      "[1444/1762] D loss: 0.7657, G loss: 4.4975\n",
      "[1524/1762] D loss: 1.5100, G loss: 0.4188\n",
      "[1604/1762] D loss: 1.1859, G loss: 1.3493\n",
      "[1684/1762] D loss: 0.2985, G loss: 2.5442\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6829\n",
      "train error: \n",
      " D loss: 1.460659, G loss: 0.914321, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.431533, G loss: 1.042036, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0902, G loss: 3.3176\n",
      "[84/1762] D loss: 1.4628, G loss: 0.6400\n",
      "[164/1762] D loss: 1.4323, G loss: 0.9190\n",
      "[244/1762] D loss: 1.4087, G loss: 0.8651\n",
      "[324/1762] D loss: 0.2027, G loss: 3.0108\n",
      "[404/1762] D loss: 1.3993, G loss: 0.7863\n",
      "[484/1762] D loss: 1.4985, G loss: 0.8111\n",
      "[564/1762] D loss: 1.4461, G loss: 0.8712\n",
      "[644/1762] D loss: 0.2077, G loss: 2.8707\n",
      "[724/1762] D loss: 1.4718, G loss: 0.9267\n",
      "[804/1762] D loss: 0.3118, G loss: 2.5956\n",
      "[884/1762] D loss: 1.0948, G loss: 1.6307\n",
      "[964/1762] D loss: 1.4411, G loss: 0.5973\n",
      "[1044/1762] D loss: 0.2441, G loss: 4.3944\n",
      "[1124/1762] D loss: 1.4368, G loss: 0.5063\n",
      "[1204/1762] D loss: 0.1504, G loss: 3.4742\n",
      "[1284/1762] D loss: 0.1855, G loss: 3.5072\n",
      "[1364/1762] D loss: 1.4021, G loss: 0.8659\n",
      "[1444/1762] D loss: 1.6425, G loss: 1.1905\n",
      "[1524/1762] D loss: 1.4129, G loss: 0.7679\n",
      "[1604/1762] D loss: 1.1432, G loss: 1.1106\n",
      "[1684/1762] D loss: 1.4393, G loss: 0.6574\n",
      "[1762/1762] D loss: 1.5201, G loss: 0.4325\n",
      "train error: \n",
      " D loss: 1.582295, G loss: 0.981856, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.581389, G loss: 1.180617, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921, G loss: 0.6729\n",
      "[84/1762] D loss: 0.1769, G loss: 3.2477\n",
      "[164/1762] D loss: 0.1542, G loss: 2.9608\n",
      "[244/1762] D loss: 0.1970, G loss: 2.8178\n",
      "[324/1762] D loss: 0.2589, G loss: 2.6506\n",
      "[404/1762] D loss: 1.4874, G loss: 0.5246\n",
      "[484/1762] D loss: 1.4652, G loss: 0.6956\n",
      "[564/1762] D loss: 1.5377, G loss: 0.8900\n",
      "[644/1762] D loss: 1.4102, G loss: 0.7218\n",
      "[724/1762] D loss: 1.3851, G loss: 0.6674\n",
      "[804/1762] D loss: 1.6272, G loss: 0.3762\n",
      "[884/1762] D loss: 1.4082, G loss: 0.7999\n",
      "[964/1762] D loss: 0.7973, G loss: 2.9289\n",
      "[1044/1762] D loss: 0.0808, G loss: 4.0048\n",
      "[1124/1762] D loss: 1.4554, G loss: 0.7305\n",
      "[1204/1762] D loss: 1.4373, G loss: 0.7831\n",
      "[1284/1762] D loss: 1.4391, G loss: 0.5302\n",
      "[1364/1762] D loss: 0.0606, G loss: 3.8246\n",
      "[1444/1762] D loss: 1.4062, G loss: 0.6482\n",
      "[1524/1762] D loss: 1.4629, G loss: 0.4747\n",
      "[1604/1762] D loss: 1.8421, G loss: 0.8539\n",
      "[1684/1762] D loss: 1.4361, G loss: 0.8709\n",
      "[1762/1762] D loss: 1.4005, G loss: 0.7739\n",
      "train error: \n",
      " D loss: 1.403322, G loss: 1.098779, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365448, G loss: 1.258581, D accuracy: 56.8%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4039, G loss: 0.6943\n",
      "[84/1762] D loss: 1.4041, G loss: 0.8026\n",
      "[164/1762] D loss: 0.0899, G loss: 3.9857\n",
      "[244/1762] D loss: 1.4637, G loss: 1.0172\n",
      "[324/1762] D loss: 0.6689, G loss: 1.1111\n",
      "[404/1762] D loss: 1.4095, G loss: 0.8490\n",
      "[484/1762] D loss: 0.1481, G loss: 3.1928\n",
      "[564/1762] D loss: 0.3062, G loss: 2.4374\n",
      "[644/1762] D loss: 0.1127, G loss: 3.3897\n",
      "[724/1762] D loss: 0.5541, G loss: 1.6903\n",
      "[804/1762] D loss: 0.8706, G loss: 1.1982\n",
      "[884/1762] D loss: 0.6455, G loss: 2.1031\n",
      "[964/1762] D loss: 0.1400, G loss: 3.9586\n",
      "[1044/1762] D loss: 1.4352, G loss: 0.5186\n",
      "[1124/1762] D loss: 0.0694, G loss: 3.5392\n",
      "[1204/1762] D loss: 0.6117, G loss: 1.9985\n",
      "[1284/1762] D loss: 0.2519, G loss: 2.4149\n",
      "[1364/1762] D loss: 0.9693, G loss: 1.3174\n",
      "[1444/1762] D loss: 1.9542, G loss: 2.6059\n",
      "[1524/1762] D loss: 1.3037, G loss: 0.8506\n",
      "[1604/1762] D loss: 1.3356, G loss: 0.7647\n",
      "[1684/1762] D loss: 1.3971, G loss: 0.6789\n",
      "[1762/1762] D loss: 1.4251, G loss: 0.5154\n",
      "train error: \n",
      " D loss: 1.379027, G loss: 0.989577, D accuracy: 55.6%, cell accuracy: 99.6%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360527, G loss: 1.131180, D accuracy: 56.0%, cell accuracy: 99.5%, board accuracy: 53.9% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4320, G loss: 0.5089\n",
      "[84/1762] D loss: 1.2784, G loss: 1.2732\n",
      "[164/1762] D loss: 0.8165, G loss: 1.9252\n",
      "[244/1762] D loss: 1.4329, G loss: 3.4367\n",
      "[324/1762] D loss: 0.1747, G loss: 5.8585\n",
      "[404/1762] D loss: 0.0164, G loss: 8.4399\n",
      "[484/1762] D loss: 0.0105, G loss: 12.0482\n",
      "[564/1762] D loss: 0.0090, G loss: 14.2599\n",
      "[644/1762] D loss: 1.3070, G loss: 7.7694\n",
      "[724/1762] D loss: 0.3526, G loss: 5.1253\n",
      "[804/1762] D loss: 0.0183, G loss: 12.5182\n",
      "[884/1762] D loss: 0.0030, G loss: 12.1281\n",
      "[964/1762] D loss: 0.6053, G loss: 11.4119\n",
      "[1044/1762] D loss: 0.0260, G loss: 5.5396\n",
      "[1124/1762] D loss: 0.0109, G loss: 18.2997\n",
      "[1204/1762] D loss: 0.0069, G loss: 13.5373\n",
      "[1284/1762] D loss: 0.0195, G loss: 14.6587\n",
      "[1364/1762] D loss: 1.7252, G loss: 2.1822\n",
      "[1444/1762] D loss: 2.2030, G loss: 0.2262\n",
      "[1524/1762] D loss: 0.6905, G loss: 1.4397\n",
      "[1604/1762] D loss: 0.4148, G loss: 2.0453\n",
      "[1684/1762] D loss: 0.1370, G loss: 2.8239\n",
      "[1762/1762] D loss: 1.4077, G loss: 0.8137\n",
      "train error: \n",
      " D loss: 1.355155, G loss: 1.385882, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317623, G loss: 1.540147, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3141, G loss: 1.3439\n",
      "[84/1762] D loss: 1.4071, G loss: 0.7771\n",
      "[164/1762] D loss: 1.2396, G loss: 1.3465\n",
      "[244/1762] D loss: 1.4142, G loss: 0.8488\n",
      "[324/1762] D loss: 0.2927, G loss: 2.2727\n",
      "[404/1762] D loss: 1.4167, G loss: 0.4964\n",
      "[484/1762] D loss: 1.4813, G loss: 0.8647\n",
      "[564/1762] D loss: 1.4003, G loss: 0.7421\n",
      "[644/1762] D loss: 1.3427, G loss: 2.1502\n",
      "[724/1762] D loss: 0.0893, G loss: 3.6169\n",
      "[804/1762] D loss: 1.3895, G loss: 0.7311\n",
      "[884/1762] D loss: 1.4357, G loss: 0.7785\n",
      "[964/1762] D loss: 1.4001, G loss: 0.7908\n",
      "[1044/1762] D loss: 1.5184, G loss: 0.8660\n",
      "[1124/1762] D loss: 1.3987, G loss: 0.6049\n",
      "[1204/1762] D loss: 1.2097, G loss: 0.8381\n",
      "[1284/1762] D loss: 0.1932, G loss: 2.6695\n",
      "[1364/1762] D loss: 1.4157, G loss: 0.7225\n",
      "[1444/1762] D loss: 0.1548, G loss: 2.6858\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.8031\n",
      "[1604/1762] D loss: 1.4071, G loss: 0.6962\n",
      "[1684/1762] D loss: 0.3163, G loss: 2.1452\n",
      "[1762/1762] D loss: 1.3938, G loss: 0.7117\n",
      "train error: \n",
      " D loss: 1.332965, G loss: 0.848827, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301790, G loss: 0.937952, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4073, G loss: 0.7139\n",
      "[84/1762] D loss: 1.4027, G loss: 0.7475\n",
      "[164/1762] D loss: 1.4221, G loss: 0.5901\n",
      "[244/1762] D loss: 1.3935, G loss: 0.6486\n",
      "[324/1762] D loss: 1.4316, G loss: 0.5573\n",
      "[404/1762] D loss: 1.4170, G loss: 0.5755\n",
      "[484/1762] D loss: 1.4030, G loss: 0.5692\n",
      "[564/1762] D loss: 0.0909, G loss: 3.5542\n",
      "[644/1762] D loss: 1.3904, G loss: 0.7481\n",
      "[724/1762] D loss: 0.0926, G loss: 3.2792\n",
      "[804/1762] D loss: 1.4192, G loss: 0.5503\n",
      "[884/1762] D loss: 1.4159, G loss: 0.8880\n",
      "[964/1762] D loss: 1.4106, G loss: 0.5598\n",
      "[1044/1762] D loss: 0.0988, G loss: 3.3485\n",
      "[1124/1762] D loss: 0.1241, G loss: 3.0665\n",
      "[1204/1762] D loss: 1.4112, G loss: 0.8527\n",
      "[1284/1762] D loss: 0.1270, G loss: 2.9134\n",
      "[1364/1762] D loss: 0.2366, G loss: 2.5726\n",
      "[1444/1762] D loss: 1.4093, G loss: 0.5487\n",
      "[1524/1762] D loss: 0.1950, G loss: 3.0249\n",
      "[1604/1762] D loss: 1.4473, G loss: 0.4973\n",
      "[1684/1762] D loss: 0.1845, G loss: 3.4618\n",
      "[1762/1762] D loss: 1.4681, G loss: 0.8994\n",
      "train error: \n",
      " D loss: 1.527481, G loss: 0.900411, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.540435, G loss: 1.071709, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3739, G loss: 0.7341\n",
      "[84/1762] D loss: 1.5801, G loss: 0.3624\n",
      "[164/1762] D loss: 1.3991, G loss: 0.6631\n",
      "[244/1762] D loss: 1.3867, G loss: 0.7087\n",
      "[324/1762] D loss: 1.3901, G loss: 0.6952\n",
      "[404/1762] D loss: 0.1892, G loss: 3.0041\n",
      "[484/1762] D loss: 1.4295, G loss: 0.8637\n",
      "[564/1762] D loss: 1.4046, G loss: 0.6245\n",
      "[644/1762] D loss: 0.1432, G loss: 2.9230\n",
      "[724/1762] D loss: 1.3903, G loss: 0.7625\n",
      "[804/1762] D loss: 1.2316, G loss: 2.6527\n",
      "[884/1762] D loss: 1.4331, G loss: 0.5916\n",
      "[964/1762] D loss: 1.4290, G loss: 0.8564\n",
      "[1044/1762] D loss: 0.2342, G loss: 2.4483\n",
      "[1124/1762] D loss: 1.5284, G loss: 0.9776\n",
      "[1204/1762] D loss: 0.1534, G loss: 2.8814\n",
      "[1284/1762] D loss: 0.2544, G loss: 2.8189\n",
      "[1364/1762] D loss: 1.4325, G loss: 0.8515\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.6134\n",
      "[1524/1762] D loss: 1.4065, G loss: 0.6735\n",
      "[1604/1762] D loss: 0.1026, G loss: 3.4349\n",
      "[1684/1762] D loss: 0.1744, G loss: 3.0644\n",
      "[1762/1762] D loss: 1.3821, G loss: 0.8558\n",
      "train error: \n",
      " D loss: 1.247118, G loss: 2.052142, D accuracy: 59.0%, cell accuracy: 99.7%, board accuracy: 70.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.219726, G loss: 2.528292, D accuracy: 60.3%, cell accuracy: 99.6%, board accuracy: 67.7% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2230, G loss: 1.5811\n",
      "[84/1762] D loss: 1.2228, G loss: 1.4853\n",
      "[164/1762] D loss: 0.1542, G loss: 3.2076\n",
      "[244/1762] D loss: 1.4005, G loss: 0.6530\n",
      "[324/1762] D loss: 0.4799, G loss: 5.2857\n",
      "[404/1762] D loss: 0.2845, G loss: 4.8039\n",
      "[484/1762] D loss: 0.8180, G loss: 5.6288\n",
      "[564/1762] D loss: 1.4050, G loss: 0.7120\n",
      "[644/1762] D loss: 1.4136, G loss: 0.7824\n",
      "[724/1762] D loss: 1.4478, G loss: 0.9509\n",
      "[804/1762] D loss: 1.4217, G loss: 0.7511\n",
      "[884/1762] D loss: 1.3983, G loss: 0.5767\n",
      "[964/1762] D loss: 1.4688, G loss: 1.0793\n",
      "[1044/1762] D loss: 0.1515, G loss: 3.5271\n",
      "[1124/1762] D loss: 1.3964, G loss: 0.7146\n",
      "[1204/1762] D loss: 1.4016, G loss: 0.7869\n",
      "[1284/1762] D loss: 1.0786, G loss: 1.1414\n",
      "[1364/1762] D loss: 0.1488, G loss: 3.4755\n",
      "[1444/1762] D loss: 1.1829, G loss: 0.8189\n",
      "[1524/1762] D loss: 1.4153, G loss: 0.6678\n",
      "[1604/1762] D loss: 0.1778, G loss: 3.2838\n",
      "[1684/1762] D loss: 1.4120, G loss: 0.8694\n",
      "[1762/1762] D loss: 1.4104, G loss: 0.7471\n",
      "train error: \n",
      " D loss: 1.312302, G loss: 1.406407, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272614, G loss: 1.643788, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4475, G loss: 0.9172\n",
      "[84/1762] D loss: 1.4034, G loss: 0.6616\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6472\n",
      "[244/1762] D loss: 1.4430, G loss: 0.8679\n",
      "[324/1762] D loss: 1.4678, G loss: 0.8185\n",
      "[404/1762] D loss: 0.1854, G loss: 2.9462\n",
      "[484/1762] D loss: 0.2379, G loss: 4.5336\n",
      "[564/1762] D loss: 1.4619, G loss: 0.8818\n",
      "[644/1762] D loss: 1.4658, G loss: 0.9079\n",
      "[724/1762] D loss: 1.4083, G loss: 0.7197\n",
      "[804/1762] D loss: 1.2176, G loss: 0.8554\n",
      "[884/1762] D loss: 1.3974, G loss: 0.6807\n",
      "[964/1762] D loss: 0.2249, G loss: 3.3084\n",
      "[1044/1762] D loss: 0.2178, G loss: 5.2015\n",
      "[1124/1762] D loss: 0.9172, G loss: 2.2752\n",
      "[1204/1762] D loss: 1.4137, G loss: 0.6054\n",
      "[1284/1762] D loss: 1.5018, G loss: 0.5371\n",
      "[1364/1762] D loss: 1.1622, G loss: 1.3802\n",
      "[1444/1762] D loss: 1.4690, G loss: 1.0928\n",
      "[1524/1762] D loss: 1.4570, G loss: 0.5707\n",
      "[1604/1762] D loss: 1.5957, G loss: 1.2118\n",
      "[1684/1762] D loss: 1.4446, G loss: 0.5642\n",
      "[1762/1762] D loss: 1.4507, G loss: 0.4771\n",
      "train error: \n",
      " D loss: 1.359689, G loss: 0.802200, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324098, G loss: 0.905108, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4182, G loss: 0.5497\n",
      "[84/1762] D loss: 1.4100, G loss: 0.7251\n",
      "[164/1762] D loss: 0.1186, G loss: 2.8342\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7089\n",
      "[324/1762] D loss: 1.3955, G loss: 0.6898\n",
      "[404/1762] D loss: 0.1310, G loss: 2.7339\n",
      "[484/1762] D loss: 1.3951, G loss: 0.6636\n",
      "[564/1762] D loss: 0.1249, G loss: 2.6582\n",
      "[644/1762] D loss: 1.4353, G loss: 0.8334\n",
      "[724/1762] D loss: 1.4135, G loss: 0.8741\n",
      "[804/1762] D loss: 1.4301, G loss: 0.5099\n",
      "[884/1762] D loss: 1.4041, G loss: 0.5235\n",
      "[964/1762] D loss: 1.3974, G loss: 0.7504\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.7627\n",
      "[1124/1762] D loss: 1.4182, G loss: 0.6662\n",
      "[1204/1762] D loss: 0.6205, G loss: 2.9489\n",
      "[1284/1762] D loss: 1.4215, G loss: 0.6119\n",
      "[1364/1762] D loss: 1.4619, G loss: 0.9659\n",
      "[1444/1762] D loss: 0.0902, G loss: 3.3113\n",
      "[1524/1762] D loss: 0.0727, G loss: 3.4965\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.7047\n",
      "[1684/1762] D loss: 1.4025, G loss: 0.7824\n",
      "[1762/1762] D loss: 1.4559, G loss: 0.5727\n",
      "train error: \n",
      " D loss: 2.062255, G loss: 0.574947, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.022180, G loss: 0.698423, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1205, G loss: 3.2590\n",
      "[84/1762] D loss: 1.4020, G loss: 0.7813\n",
      "[164/1762] D loss: 1.4268, G loss: 0.5183\n",
      "[244/1762] D loss: 0.0045, G loss: 5.9007\n",
      "[324/1762] D loss: 1.4621, G loss: 0.5847\n",
      "[404/1762] D loss: 0.0372, G loss: 3.9238\n",
      "[484/1762] D loss: 1.3816, G loss: 0.7192\n",
      "[564/1762] D loss: 0.0721, G loss: 3.3930\n",
      "[644/1762] D loss: 1.4133, G loss: 0.8552\n",
      "[724/1762] D loss: 1.4366, G loss: 0.8676\n",
      "[804/1762] D loss: 1.4237, G loss: 0.8484\n",
      "[884/1762] D loss: 1.3930, G loss: 0.9736\n",
      "[964/1762] D loss: 1.4852, G loss: 0.9839\n",
      "[1044/1762] D loss: 0.1200, G loss: 3.1619\n",
      "[1124/1762] D loss: 1.5560, G loss: 1.0840\n",
      "[1204/1762] D loss: 1.4176, G loss: 0.8025\n",
      "[1284/1762] D loss: 1.4466, G loss: 0.8806\n",
      "[1364/1762] D loss: 0.1106, G loss: 3.3310\n",
      "[1444/1762] D loss: 0.0783, G loss: 3.6117\n",
      "[1524/1762] D loss: 1.4076, G loss: 0.7688\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.7451\n",
      "[1684/1762] D loss: 1.4174, G loss: 0.7927\n",
      "[1762/1762] D loss: 0.0032, G loss: 6.4891\n",
      "train error: \n",
      " D loss: 2.463308, G loss: 0.481950, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.411705, G loss: 0.602409, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3947, G loss: 0.7618\n",
      "[84/1762] D loss: 1.4231, G loss: 0.4594\n",
      "[164/1762] D loss: 0.0656, G loss: 3.6005\n",
      "[244/1762] D loss: 1.4301, G loss: 0.8466\n",
      "[324/1762] D loss: 1.4034, G loss: 0.6428\n",
      "[404/1762] D loss: 1.3898, G loss: 0.6963\n",
      "[484/1762] D loss: 0.0037, G loss: 6.4040\n",
      "[564/1762] D loss: 1.4448, G loss: 0.8178\n",
      "[644/1762] D loss: 0.0541, G loss: 3.7506\n",
      "[724/1762] D loss: 1.4066, G loss: 0.7511\n",
      "[804/1762] D loss: 0.0563, G loss: 3.7924\n",
      "[884/1762] D loss: 1.4974, G loss: 0.8817\n",
      "[964/1762] D loss: 1.3940, G loss: 0.6735\n",
      "[1044/1762] D loss: 1.5102, G loss: 1.0391\n",
      "[1124/1762] D loss: 1.4243, G loss: 0.5546\n",
      "[1204/1762] D loss: 1.4524, G loss: 1.0368\n",
      "[1284/1762] D loss: 1.4030, G loss: 0.5374\n",
      "[1364/1762] D loss: 1.4181, G loss: 0.8242\n",
      "[1444/1762] D loss: 1.4124, G loss: 0.6829\n",
      "[1524/1762] D loss: 1.4046, G loss: 0.7009\n",
      "[1604/1762] D loss: 1.3990, G loss: 0.8530\n",
      "[1684/1762] D loss: 0.0549, G loss: 4.1952\n",
      "[1762/1762] D loss: 1.3938, G loss: 0.7308\n",
      "train error: \n",
      " D loss: 1.434034, G loss: 0.962597, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398561, G loss: 1.147715, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4059, G loss: 0.7300\n",
      "[84/1762] D loss: 1.3947, G loss: 0.6920\n",
      "[164/1762] D loss: 0.0664, G loss: 3.9116\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7488\n",
      "[324/1762] D loss: 1.3967, G loss: 0.5739\n",
      "[404/1762] D loss: 0.0391, G loss: 4.5405\n",
      "[484/1762] D loss: 1.4020, G loss: 0.7506\n",
      "[564/1762] D loss: 1.4113, G loss: 0.7012\n",
      "[644/1762] D loss: 1.3889, G loss: 0.7154\n",
      "[724/1762] D loss: 1.3897, G loss: 0.6661\n",
      "[804/1762] D loss: 1.4105, G loss: 0.7642\n",
      "[884/1762] D loss: 0.7980, G loss: 4.0670\n",
      "[964/1762] D loss: 0.0771, G loss: 3.8169\n",
      "[1044/1762] D loss: 1.3919, G loss: 0.7028\n",
      "[1124/1762] D loss: 0.0020, G loss: 7.9770\n",
      "[1204/1762] D loss: 1.3998, G loss: 0.6858\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.6980\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.7326\n",
      "[1444/1762] D loss: 0.0011, G loss: 7.9509\n",
      "[1524/1762] D loss: 1.3977, G loss: 0.7330\n",
      "[1604/1762] D loss: 1.3955, G loss: 0.7363\n",
      "[1684/1762] D loss: 1.4043, G loss: 0.7421\n",
      "[1762/1762] D loss: 0.0009, G loss: 7.2268\n",
      "train error: \n",
      " D loss: 5.008840, G loss: 0.499255, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 4.878348, G loss: 0.655600, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0661, G loss: 3.6842\n",
      "[84/1762] D loss: 0.0450, G loss: 4.2083\n",
      "[164/1762] D loss: 1.3908, G loss: 0.6879\n",
      "[244/1762] D loss: 1.3974, G loss: 0.7794\n",
      "[324/1762] D loss: 1.3639, G loss: 0.6361\n",
      "[404/1762] D loss: 1.5122, G loss: 0.9818\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7289\n",
      "[564/1762] D loss: 1.4518, G loss: 0.8221\n",
      "[644/1762] D loss: 0.0695, G loss: 4.0333\n",
      "[724/1762] D loss: 1.4502, G loss: 1.0143\n",
      "[804/1762] D loss: 1.4005, G loss: 0.7256\n",
      "[884/1762] D loss: 1.3992, G loss: 0.6228\n",
      "[964/1762] D loss: 1.4175, G loss: 0.6936\n",
      "[1044/1762] D loss: 1.4193, G loss: 0.6994\n",
      "[1124/1762] D loss: 1.4453, G loss: 0.7063\n",
      "[1204/1762] D loss: 1.4042, G loss: 0.7246\n",
      "[1284/1762] D loss: 1.4008, G loss: 0.6282\n",
      "[1364/1762] D loss: 1.3922, G loss: 0.7276\n",
      "[1444/1762] D loss: 1.3729, G loss: 0.6573\n",
      "[1524/1762] D loss: 0.0167, G loss: 5.5933\n",
      "[1604/1762] D loss: 1.6639, G loss: 1.1131\n",
      "[1684/1762] D loss: 0.0363, G loss: 6.1726\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6467\n",
      "train error: \n",
      " D loss: 1.323087, G loss: 1.263015, D accuracy: 53.3%, cell accuracy: 99.6%, board accuracy: 46.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290487, G loss: 1.481604, D accuracy: 54.4%, cell accuracy: 99.5%, board accuracy: 47.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.5684\n",
      "[84/1762] D loss: 0.1765, G loss: 3.2618\n",
      "[164/1762] D loss: 0.2418, G loss: 2.9303\n",
      "[244/1762] D loss: 1.4071, G loss: 0.5812\n",
      "[324/1762] D loss: 1.3681, G loss: 0.6355\n",
      "[404/1762] D loss: 1.1550, G loss: 0.9251\n",
      "[484/1762] D loss: 1.4607, G loss: 0.9250\n",
      "[564/1762] D loss: 1.4016, G loss: 0.6383\n",
      "[644/1762] D loss: 1.4065, G loss: 0.6062\n",
      "[724/1762] D loss: 1.3915, G loss: 0.6485\n",
      "[804/1762] D loss: 1.4354, G loss: 0.5920\n",
      "[884/1762] D loss: 1.4316, G loss: 0.7764\n",
      "[964/1762] D loss: 1.4282, G loss: 0.7488\n",
      "[1044/1762] D loss: 1.4399, G loss: 0.7828\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.6632\n",
      "[1204/1762] D loss: 1.4386, G loss: 0.6360\n",
      "[1284/1762] D loss: 1.4839, G loss: 0.6854\n",
      "[1364/1762] D loss: 1.4075, G loss: 0.7511\n",
      "[1444/1762] D loss: 1.4929, G loss: 1.3921\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.7378\n",
      "[1604/1762] D loss: 1.4116, G loss: 0.5169\n",
      "[1684/1762] D loss: 0.2570, G loss: 2.2904\n",
      "[1762/1762] D loss: 1.5993, G loss: 0.7315\n",
      "train error: \n",
      " D loss: 1.419041, G loss: 0.806636, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386270, G loss: 0.818317, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5282, G loss: 0.6759\n",
      "[84/1762] D loss: 1.3885, G loss: 0.6976\n",
      "[164/1762] D loss: 1.4643, G loss: 0.4936\n",
      "[244/1762] D loss: 0.2614, G loss: 2.5516\n",
      "[324/1762] D loss: 1.4072, G loss: 0.7311\n",
      "[404/1762] D loss: 1.4359, G loss: 0.8357\n",
      "[484/1762] D loss: 1.3934, G loss: 0.6360\n",
      "[564/1762] D loss: 1.4080, G loss: 0.6378\n",
      "[644/1762] D loss: 1.3916, G loss: 0.7259\n",
      "[724/1762] D loss: 1.4249, G loss: 0.8254\n",
      "[804/1762] D loss: 0.1297, G loss: 2.9864\n",
      "[884/1762] D loss: 1.3918, G loss: 0.7926\n",
      "[964/1762] D loss: 1.4032, G loss: 0.7055\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.7341\n",
      "[1124/1762] D loss: 1.3945, G loss: 0.6174\n",
      "[1204/1762] D loss: 1.3978, G loss: 0.7698\n",
      "[1284/1762] D loss: 1.4071, G loss: 0.6840\n",
      "[1364/1762] D loss: 1.3928, G loss: 0.7568\n",
      "[1444/1762] D loss: 1.4135, G loss: 0.6358\n",
      "[1524/1762] D loss: 1.3937, G loss: 0.6358\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6731\n",
      "[1684/1762] D loss: 1.4451, G loss: 0.5490\n",
      "[1762/1762] D loss: 1.4130, G loss: 0.6451\n",
      "train error: \n",
      " D loss: 1.379454, G loss: 1.322414, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343005, G loss: 1.628567, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.7029\n",
      "[84/1762] D loss: 1.3241, G loss: 0.7546\n",
      "[164/1762] D loss: 0.6165, G loss: 3.1984\n",
      "[244/1762] D loss: 0.4723, G loss: 2.9739\n",
      "[324/1762] D loss: 0.2786, G loss: 2.4121\n",
      "[404/1762] D loss: 0.2109, G loss: 3.1423\n",
      "[484/1762] D loss: 1.3968, G loss: 0.7743\n",
      "[564/1762] D loss: 0.7276, G loss: 2.2697\n",
      "[644/1762] D loss: 1.3978, G loss: 0.5658\n",
      "[724/1762] D loss: 0.6031, G loss: 5.6703\n",
      "[804/1762] D loss: 0.6234, G loss: 5.2318\n",
      "[884/1762] D loss: 1.7460, G loss: 9.9166\n",
      "[964/1762] D loss: 0.7227, G loss: 2.6181\n",
      "[1044/1762] D loss: 0.0002, G loss: 21.6351\n",
      "[1124/1762] D loss: 1.1370, G loss: 7.2198\n",
      "[1204/1762] D loss: 0.1696, G loss: 2.4712\n",
      "[1284/1762] D loss: 0.4719, G loss: 3.5024\n",
      "[1364/1762] D loss: 0.5646, G loss: 2.7286\n",
      "[1444/1762] D loss: 0.9351, G loss: 3.1811\n",
      "[1524/1762] D loss: 0.0175, G loss: 9.3788\n",
      "[1604/1762] D loss: 0.0020, G loss: 23.4170\n",
      "[1684/1762] D loss: 1.7423, G loss: 3.8091\n",
      "[1762/1762] D loss: 1.7026, G loss: 0.4463\n",
      "train error: \n",
      " D loss: 1.528884, G loss: 1.010798, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.493651, G loss: 1.205479, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4172, G loss: 14.2958\n",
      "[84/1762] D loss: 1.4190, G loss: 0.5492\n",
      "[164/1762] D loss: 1.4218, G loss: 0.6234\n",
      "[244/1762] D loss: 0.9185, G loss: 5.9287\n",
      "[324/1762] D loss: 1.0774, G loss: 1.8514\n",
      "[404/1762] D loss: 1.4344, G loss: 0.7775\n",
      "[484/1762] D loss: 1.0704, G loss: 0.8125\n",
      "[564/1762] D loss: 0.1548, G loss: 3.8464\n",
      "[644/1762] D loss: 0.2348, G loss: 3.1223\n",
      "[724/1762] D loss: 1.3849, G loss: 0.9345\n",
      "[804/1762] D loss: 1.3915, G loss: 0.7013\n",
      "[884/1762] D loss: 0.2586, G loss: 2.9072\n",
      "[964/1762] D loss: 1.4038, G loss: 0.5737\n",
      "[1044/1762] D loss: 1.4315, G loss: 0.5003\n",
      "[1124/1762] D loss: 1.2872, G loss: 1.6565\n",
      "[1204/1762] D loss: 0.1339, G loss: 4.1076\n",
      "[1284/1762] D loss: 1.3811, G loss: 0.6179\n",
      "[1364/1762] D loss: 1.4074, G loss: 0.7747\n",
      "[1444/1762] D loss: 1.4119, G loss: 0.8305\n",
      "[1524/1762] D loss: 1.3946, G loss: 0.5979\n",
      "[1604/1762] D loss: 1.2559, G loss: 1.5563\n",
      "[1684/1762] D loss: 1.4029, G loss: 0.7909\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.6833\n",
      "train error: \n",
      " D loss: 1.288433, G loss: 1.347755, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260899, G loss: 1.550518, D accuracy: 56.8%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3934, G loss: 0.6462\n",
      "[84/1762] D loss: 1.2766, G loss: 1.7097\n",
      "[164/1762] D loss: 1.2616, G loss: 1.6014\n",
      "[244/1762] D loss: 0.0010, G loss: 9.4719\n",
      "[324/1762] D loss: 1.3970, G loss: 0.5865\n",
      "[404/1762] D loss: 1.4013, G loss: 0.7802\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7242\n",
      "[564/1762] D loss: 1.3970, G loss: 0.7817\n",
      "[644/1762] D loss: 1.3272, G loss: 0.9839\n",
      "[724/1762] D loss: 0.4103, G loss: 4.4228\n",
      "[804/1762] D loss: 0.1498, G loss: 4.0083\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6816\n",
      "[964/1762] D loss: 0.0626, G loss: 5.0841\n",
      "[1044/1762] D loss: 1.3935, G loss: 0.6461\n",
      "[1124/1762] D loss: 1.4169, G loss: 0.5619\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6610\n",
      "[1284/1762] D loss: 0.0781, G loss: 6.3365\n",
      "[1364/1762] D loss: 0.1864, G loss: 2.5675\n",
      "[1444/1762] D loss: 1.7775, G loss: 1.0052\n",
      "[1524/1762] D loss: 0.1522, G loss: 5.0391\n",
      "[1604/1762] D loss: 0.2123, G loss: 4.2867\n",
      "[1684/1762] D loss: 1.4089, G loss: 0.6578\n",
      "[1762/1762] D loss: 1.4452, G loss: 0.4998\n",
      "train error: \n",
      " D loss: 1.576105, G loss: 0.810356, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.569616, G loss: 0.958851, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2438, G loss: 3.2883\n",
      "[84/1762] D loss: 1.4145, G loss: 0.6329\n",
      "[164/1762] D loss: 1.3914, G loss: 0.7162\n",
      "[244/1762] D loss: 1.4118, G loss: 0.5839\n",
      "[324/1762] D loss: 1.4095, G loss: 0.8382\n",
      "[404/1762] D loss: 1.4017, G loss: 0.7990\n",
      "[484/1762] D loss: 1.3953, G loss: 0.7329\n",
      "[564/1762] D loss: 0.1167, G loss: 4.3005\n",
      "[644/1762] D loss: 1.3836, G loss: 0.7937\n",
      "[724/1762] D loss: 1.2324, G loss: 1.4904\n",
      "[804/1762] D loss: 1.4243, G loss: 0.5940\n",
      "[884/1762] D loss: 0.6389, G loss: 4.7349\n",
      "[964/1762] D loss: 0.1749, G loss: 3.1260\n",
      "[1044/1762] D loss: 0.2068, G loss: 3.2248\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.7758\n",
      "[1204/1762] D loss: 1.3979, G loss: 0.6436\n",
      "[1284/1762] D loss: 1.3618, G loss: 0.7023\n",
      "[1364/1762] D loss: 0.7997, G loss: 6.9000\n",
      "[1444/1762] D loss: 1.4002, G loss: 0.6530\n",
      "[1524/1762] D loss: 0.2790, G loss: 2.9756\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.7304\n",
      "[1684/1762] D loss: 1.3969, G loss: 0.6219\n",
      "[1762/1762] D loss: 1.2294, G loss: 1.0033\n",
      "train error: \n",
      " D loss: 1.680812, G loss: 0.740831, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.661580, G loss: 0.876022, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3994, G loss: 0.7156\n",
      "[84/1762] D loss: 1.3889, G loss: 0.6233\n",
      "[164/1762] D loss: 1.3894, G loss: 0.6414\n",
      "[244/1762] D loss: 1.4488, G loss: 0.9236\n",
      "[324/1762] D loss: 1.4024, G loss: 0.7974\n",
      "[404/1762] D loss: 1.4241, G loss: 0.5571\n",
      "[484/1762] D loss: 1.3879, G loss: 0.6791\n",
      "[564/1762] D loss: 0.0741, G loss: 3.9336\n",
      "[644/1762] D loss: 0.0534, G loss: 5.0815\n",
      "[724/1762] D loss: 0.0165, G loss: 5.5967\n",
      "[804/1762] D loss: 0.0191, G loss: 5.2223\n",
      "[884/1762] D loss: 1.3908, G loss: 0.7527\n",
      "[964/1762] D loss: 0.0115, G loss: 5.9882\n",
      "[1044/1762] D loss: 0.0191, G loss: 4.9601\n",
      "[1124/1762] D loss: 0.0164, G loss: 5.2885\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.6356\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6902\n",
      "[1364/1762] D loss: 0.0493, G loss: 5.1920\n",
      "[1444/1762] D loss: 1.4742, G loss: 0.4977\n",
      "[1524/1762] D loss: 1.4026, G loss: 0.7337\n",
      "[1604/1762] D loss: 1.4104, G loss: 0.8280\n",
      "[1684/1762] D loss: 1.4134, G loss: 0.5886\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.6774\n",
      "train error: \n",
      " D loss: 1.287198, G loss: 1.540889, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262885, G loss: 1.749635, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.6347\n",
      "[84/1762] D loss: 1.4570, G loss: 0.8831\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6622\n",
      "[244/1762] D loss: 0.1603, G loss: 2.7938\n",
      "[324/1762] D loss: 1.4140, G loss: 0.8785\n",
      "[404/1762] D loss: 1.4071, G loss: 0.8410\n",
      "[484/1762] D loss: 0.0451, G loss: 7.2574\n",
      "[564/1762] D loss: 0.9347, G loss: 1.7571\n",
      "[644/1762] D loss: 1.5547, G loss: 0.4375\n",
      "[724/1762] D loss: 0.0683, G loss: 3.9476\n",
      "[804/1762] D loss: 0.1072, G loss: 3.2145\n",
      "[884/1762] D loss: 1.3939, G loss: 0.6937\n",
      "[964/1762] D loss: 1.4219, G loss: 0.7631\n",
      "[1044/1762] D loss: 1.3974, G loss: 0.6948\n",
      "[1124/1762] D loss: 1.3997, G loss: 0.6305\n",
      "[1204/1762] D loss: 1.4872, G loss: 0.5242\n",
      "[1284/1762] D loss: 0.0531, G loss: 4.9247\n",
      "[1364/1762] D loss: 1.4623, G loss: 0.9556\n",
      "[1444/1762] D loss: 1.4223, G loss: 0.5835\n",
      "[1524/1762] D loss: 1.3966, G loss: 0.6432\n",
      "[1604/1762] D loss: 1.4091, G loss: 0.6500\n",
      "[1684/1762] D loss: 1.3990, G loss: 0.5770\n",
      "[1762/1762] D loss: 0.9631, G loss: 2.3802\n",
      "train error: \n",
      " D loss: 1.308536, G loss: 1.815649, D accuracy: 58.2%, cell accuracy: 99.6%, board accuracy: 77.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310541, G loss: 2.091460, D accuracy: 58.0%, cell accuracy: 99.6%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1468, G loss: 1.2952\n",
      "[84/1762] D loss: 1.5055, G loss: 0.4602\n",
      "[164/1762] D loss: 1.4559, G loss: 0.5359\n",
      "[244/1762] D loss: 1.3836, G loss: 0.7494\n",
      "[324/1762] D loss: 1.3884, G loss: 0.7015\n",
      "[404/1762] D loss: 0.0003, G loss: 10.9635\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7083\n",
      "[564/1762] D loss: 1.4106, G loss: 0.8166\n",
      "[644/1762] D loss: 1.3888, G loss: 0.7306\n",
      "[724/1762] D loss: 1.4563, G loss: 0.9073\n",
      "[804/1762] D loss: 0.0315, G loss: 6.5782\n",
      "[884/1762] D loss: 1.3996, G loss: 0.7292\n",
      "[964/1762] D loss: 1.4688, G loss: 0.4481\n",
      "[1044/1762] D loss: 1.4839, G loss: 0.4745\n",
      "[1124/1762] D loss: 0.0420, G loss: 5.8761\n",
      "[1204/1762] D loss: 0.0104, G loss: 7.1104\n",
      "[1284/1762] D loss: 1.4088, G loss: 0.6446\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.7483\n",
      "[1444/1762] D loss: 0.0042, G loss: 8.0912\n",
      "[1524/1762] D loss: 0.9551, G loss: 1.6507\n",
      "[1604/1762] D loss: 1.4875, G loss: 0.7634\n",
      "[1684/1762] D loss: 1.4094, G loss: 0.6838\n",
      "[1762/1762] D loss: 0.0026, G loss: 9.5834\n",
      "train error: \n",
      " D loss: 2.822813, G loss: 0.650318, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.796823, G loss: 0.801047, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4212, G loss: 0.8552\n",
      "[84/1762] D loss: 1.4107, G loss: 0.8786\n",
      "[164/1762] D loss: 1.3940, G loss: 0.6684\n",
      "[244/1762] D loss: 1.3996, G loss: 0.7660\n",
      "[324/1762] D loss: 0.0009, G loss: 10.4109\n",
      "[404/1762] D loss: 1.4219, G loss: 0.5317\n",
      "[484/1762] D loss: 1.3882, G loss: 0.7472\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6453\n",
      "[644/1762] D loss: 0.0816, G loss: 4.5052\n",
      "[724/1762] D loss: 1.4236, G loss: 0.5382\n",
      "[804/1762] D loss: 1.3906, G loss: 0.7614\n",
      "[884/1762] D loss: 1.3924, G loss: 0.6327\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6204\n",
      "[1044/1762] D loss: 0.0647, G loss: 5.2262\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.5584\n",
      "[1204/1762] D loss: 1.4431, G loss: 0.4794\n",
      "[1284/1762] D loss: 1.4043, G loss: 0.5824\n",
      "[1364/1762] D loss: 0.7671, G loss: 5.5258\n",
      "[1444/1762] D loss: 1.3900, G loss: 0.7732\n",
      "[1524/1762] D loss: 1.4121, G loss: 0.5576\n",
      "[1604/1762] D loss: 1.4148, G loss: 0.6395\n",
      "[1684/1762] D loss: 1.4009, G loss: 0.8012\n",
      "[1762/1762] D loss: 1.3974, G loss: 0.6117\n",
      "train error: \n",
      " D loss: 1.382293, G loss: 1.100812, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352276, G loss: 1.294671, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7101\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6331\n",
      "[164/1762] D loss: 1.3952, G loss: 0.6762\n",
      "[244/1762] D loss: 1.3916, G loss: 0.7047\n",
      "[324/1762] D loss: 1.3928, G loss: 0.6428\n",
      "[404/1762] D loss: 0.0438, G loss: 5.1427\n",
      "[484/1762] D loss: 0.0588, G loss: 5.4194\n",
      "[564/1762] D loss: 1.3955, G loss: 0.6815\n",
      "[644/1762] D loss: 1.4030, G loss: 0.5814\n",
      "[724/1762] D loss: 0.0003, G loss: 10.6321\n",
      "[804/1762] D loss: 0.0609, G loss: 5.1430\n",
      "[884/1762] D loss: 1.3931, G loss: 0.6128\n",
      "[964/1762] D loss: 0.0233, G loss: 5.9023\n",
      "[1044/1762] D loss: 1.5133, G loss: 0.5163\n",
      "[1124/1762] D loss: 1.0739, G loss: 5.6713\n",
      "[1204/1762] D loss: 1.4034, G loss: 0.8032\n",
      "[1284/1762] D loss: 1.3976, G loss: 0.6187\n",
      "[1364/1762] D loss: 1.4734, G loss: 0.4449\n",
      "[1444/1762] D loss: 1.4049, G loss: 0.7358\n",
      "[1524/1762] D loss: 0.0959, G loss: 5.1536\n",
      "[1604/1762] D loss: 1.3970, G loss: 0.7321\n",
      "[1684/1762] D loss: 0.0604, G loss: 5.3437\n",
      "[1762/1762] D loss: 1.4033, G loss: 0.7910\n",
      "train error: \n",
      " D loss: 1.318841, G loss: 1.333062, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289175, G loss: 1.571600, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3922, G loss: 0.7116\n",
      "[84/1762] D loss: 0.0647, G loss: 5.2896\n",
      "[164/1762] D loss: 1.3911, G loss: 0.6677\n",
      "[244/1762] D loss: 1.4318, G loss: 0.5979\n",
      "[324/1762] D loss: 1.4738, G loss: 0.8860\n",
      "[404/1762] D loss: 1.3949, G loss: 0.6654\n",
      "[484/1762] D loss: 1.3966, G loss: 0.7167\n",
      "[564/1762] D loss: 1.4037, G loss: 0.8120\n",
      "[644/1762] D loss: 1.4084, G loss: 0.7456\n",
      "[724/1762] D loss: 1.3959, G loss: 0.7330\n",
      "[804/1762] D loss: 1.4394, G loss: 0.8477\n",
      "[884/1762] D loss: 1.4205, G loss: 0.7619\n",
      "[964/1762] D loss: 1.3904, G loss: 0.7120\n",
      "[1044/1762] D loss: 1.3950, G loss: 0.5978\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.7148\n",
      "[1204/1762] D loss: 0.0321, G loss: 5.5893\n",
      "[1284/1762] D loss: 1.3970, G loss: 0.7585\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6925\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6771\n",
      "[1524/1762] D loss: 1.3996, G loss: 0.7714\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.6285\n",
      "[1684/1762] D loss: 0.0328, G loss: 5.8393\n",
      "[1762/1762] D loss: 1.4098, G loss: 0.7290\n",
      "train error: \n",
      " D loss: 1.319584, G loss: 1.370472, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289587, G loss: 1.617835, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4265, G loss: 0.8433\n",
      "[84/1762] D loss: 1.3943, G loss: 0.8317\n",
      "[164/1762] D loss: 1.3893, G loss: 0.7302\n",
      "[244/1762] D loss: 1.4578, G loss: 0.4831\n",
      "[324/1762] D loss: 1.4086, G loss: 0.7686\n",
      "[404/1762] D loss: 0.1275, G loss: 4.8788\n",
      "[484/1762] D loss: 0.0752, G loss: 4.8957\n",
      "[564/1762] D loss: 1.3934, G loss: 0.7680\n",
      "[644/1762] D loss: 1.4082, G loss: 0.7537\n",
      "[724/1762] D loss: 1.4029, G loss: 0.6748\n",
      "[804/1762] D loss: 1.3893, G loss: 0.6966\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7093\n",
      "[964/1762] D loss: 0.0003, G loss: 10.7133\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.6866\n",
      "[1124/1762] D loss: 1.4390, G loss: 0.8840\n",
      "[1204/1762] D loss: 1.4416, G loss: 0.6461\n",
      "[1284/1762] D loss: 1.4577, G loss: 0.4445\n",
      "[1364/1762] D loss: 1.3981, G loss: 0.7484\n",
      "[1444/1762] D loss: 0.0856, G loss: 3.3163\n",
      "[1524/1762] D loss: 1.4114, G loss: 0.8171\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.6292\n",
      "[1684/1762] D loss: 1.3997, G loss: 0.7538\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.6526\n",
      "train error: \n",
      " D loss: 1.305416, G loss: 1.042151, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276595, G loss: 1.173124, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.7524\n",
      "[84/1762] D loss: 1.4264, G loss: 0.5750\n",
      "[164/1762] D loss: 0.2507, G loss: 3.5606\n",
      "[244/1762] D loss: 1.3941, G loss: 0.6549\n",
      "[324/1762] D loss: 1.3736, G loss: 0.6080\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6553\n",
      "[484/1762] D loss: 1.3978, G loss: 0.7516\n",
      "[564/1762] D loss: 1.4048, G loss: 0.6167\n",
      "[644/1762] D loss: 1.3556, G loss: 0.6600\n",
      "[724/1762] D loss: 1.7552, G loss: 0.3139\n",
      "[804/1762] D loss: 0.0489, G loss: 5.3338\n",
      "[884/1762] D loss: 1.4388, G loss: 0.9427\n",
      "[964/1762] D loss: 0.1721, G loss: 3.4945\n",
      "[1044/1762] D loss: 1.4591, G loss: 0.5379\n",
      "[1124/1762] D loss: 0.0943, G loss: 4.0538\n",
      "[1204/1762] D loss: 0.8833, G loss: 2.4238\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.6689\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.7257\n",
      "[1444/1762] D loss: 0.1146, G loss: 3.2295\n",
      "[1524/1762] D loss: 1.3945, G loss: 0.7300\n",
      "[1604/1762] D loss: 1.4136, G loss: 0.8654\n",
      "[1684/1762] D loss: 1.4020, G loss: 0.7875\n",
      "[1762/1762] D loss: 0.0006, G loss: 10.5305\n",
      "train error: \n",
      " D loss: 7.339636, G loss: 0.356766, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 7.297022, G loss: 0.462117, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0769, G loss: 3.7749\n",
      "[84/1762] D loss: 1.3962, G loss: 0.8124\n",
      "[164/1762] D loss: 1.4016, G loss: 0.6572\n",
      "[244/1762] D loss: 1.3913, G loss: 0.6877\n",
      "[324/1762] D loss: 1.3871, G loss: 0.7287\n",
      "[404/1762] D loss: 0.0444, G loss: 5.7065\n",
      "[484/1762] D loss: 0.0288, G loss: 5.8497\n",
      "[564/1762] D loss: 1.3892, G loss: 0.6472\n",
      "[644/1762] D loss: 1.4186, G loss: 0.9016\n",
      "[724/1762] D loss: 1.4049, G loss: 0.7361\n",
      "[804/1762] D loss: 0.0638, G loss: 5.1406\n",
      "[884/1762] D loss: 1.4003, G loss: 0.7215\n",
      "[964/1762] D loss: 1.4203, G loss: 0.8219\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.6746\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.7037\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.6801\n",
      "[1284/1762] D loss: 1.4670, G loss: 0.8428\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.7709\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6427\n",
      "[1524/1762] D loss: 1.4249, G loss: 0.8343\n",
      "[1604/1762] D loss: 0.0548, G loss: 5.2941\n",
      "[1684/1762] D loss: 1.3933, G loss: 0.7149\n",
      "[1762/1762] D loss: 1.4152, G loss: 0.6821\n",
      "train error: \n",
      " D loss: 1.307059, G loss: 1.718219, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281286, G loss: 1.991349, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0670, G loss: 5.3565\n",
      "[84/1762] D loss: 0.1177, G loss: 4.8833\n",
      "[164/1762] D loss: 1.3899, G loss: 0.6807\n",
      "[244/1762] D loss: 1.3983, G loss: 0.7920\n",
      "[324/1762] D loss: 0.0585, G loss: 5.1458\n",
      "[404/1762] D loss: 0.0451, G loss: 5.2294\n",
      "[484/1762] D loss: 1.4129, G loss: 0.5868\n",
      "[564/1762] D loss: 1.3891, G loss: 0.7281\n",
      "[644/1762] D loss: 1.3914, G loss: 0.7110\n",
      "[724/1762] D loss: 1.3932, G loss: 0.6575\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6801\n",
      "[884/1762] D loss: 1.3952, G loss: 0.7986\n",
      "[964/1762] D loss: 0.0247, G loss: 5.5380\n",
      "[1044/1762] D loss: 0.0562, G loss: 5.3435\n",
      "[1124/1762] D loss: 1.4043, G loss: 0.5951\n",
      "[1204/1762] D loss: 1.3946, G loss: 0.6408\n",
      "[1284/1762] D loss: 1.4355, G loss: 0.6637\n",
      "[1364/1762] D loss: 1.4696, G loss: 0.6512\n",
      "[1444/1762] D loss: 1.4195, G loss: 0.8115\n",
      "[1524/1762] D loss: 0.0531, G loss: 5.0606\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.6826\n",
      "[1684/1762] D loss: 0.9156, G loss: 3.3859\n",
      "[1762/1762] D loss: 0.0889, G loss: 4.4860\n",
      "train error: \n",
      " D loss: 1.475370, G loss: 0.483944, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.443469, G loss: 0.520101, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4098, G loss: 0.5795\n",
      "[84/1762] D loss: 0.1060, G loss: 3.3742\n",
      "[164/1762] D loss: 0.0390, G loss: 4.5843\n",
      "[244/1762] D loss: 1.3960, G loss: 0.6561\n",
      "[324/1762] D loss: 1.4116, G loss: 0.5728\n",
      "[404/1762] D loss: 0.0025, G loss: 7.2549\n",
      "[484/1762] D loss: 1.4720, G loss: 0.5527\n",
      "[564/1762] D loss: 1.5161, G loss: 0.8601\n",
      "[644/1762] D loss: 1.3976, G loss: 0.6230\n",
      "[724/1762] D loss: 1.4271, G loss: 0.8812\n",
      "[804/1762] D loss: 1.4229, G loss: 0.8686\n",
      "[884/1762] D loss: 1.3928, G loss: 0.7302\n",
      "[964/1762] D loss: 1.4030, G loss: 0.7681\n",
      "[1044/1762] D loss: 0.9137, G loss: 2.5903\n",
      "[1124/1762] D loss: 1.4404, G loss: 0.8306\n",
      "[1204/1762] D loss: 1.3889, G loss: 0.6541\n",
      "[1284/1762] D loss: 1.3929, G loss: 0.5981\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6858\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.6883\n",
      "[1524/1762] D loss: 0.2295, G loss: 2.8935\n",
      "[1604/1762] D loss: 1.3974, G loss: 0.8011\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.7927\n",
      "[1762/1762] D loss: 0.0014, G loss: 6.6246\n",
      "train error: \n",
      " D loss: 3.140628, G loss: 0.613315, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.076173, G loss: 0.776608, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7366\n",
      "[84/1762] D loss: 1.3986, G loss: 0.7571\n",
      "[164/1762] D loss: 1.4022, G loss: 0.8692\n",
      "[244/1762] D loss: 1.4030, G loss: 0.7270\n",
      "[324/1762] D loss: 1.3905, G loss: 0.6684\n",
      "[404/1762] D loss: 1.4106, G loss: 0.5709\n",
      "[484/1762] D loss: 0.0587, G loss: 4.1946\n",
      "[564/1762] D loss: 1.3924, G loss: 0.6321\n",
      "[644/1762] D loss: 1.3899, G loss: 0.6994\n",
      "[724/1762] D loss: 1.3925, G loss: 0.5864\n",
      "[804/1762] D loss: 1.3875, G loss: 0.7104\n",
      "[884/1762] D loss: 0.0519, G loss: 3.6622\n",
      "[964/1762] D loss: 1.4185, G loss: 0.6264\n",
      "[1044/1762] D loss: 1.3986, G loss: 0.6945\n",
      "[1124/1762] D loss: 1.4021, G loss: 0.7352\n",
      "[1204/1762] D loss: 0.0006, G loss: 7.7224\n",
      "[1284/1762] D loss: 1.4218, G loss: 0.7582\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.6803\n",
      "[1444/1762] D loss: 1.3930, G loss: 0.7944\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6907\n",
      "[1604/1762] D loss: 1.5286, G loss: 0.7339\n",
      "[1684/1762] D loss: 1.3943, G loss: 0.6466\n",
      "[1762/1762] D loss: 1.4070, G loss: 0.8483\n",
      "train error: \n",
      " D loss: 1.785980, G loss: 0.734500, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.741609, G loss: 0.864306, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0336, G loss: 4.3151\n",
      "[84/1762] D loss: 0.0392, G loss: 4.1080\n",
      "[164/1762] D loss: 0.0195, G loss: 4.7539\n",
      "[244/1762] D loss: 1.3906, G loss: 0.6912\n",
      "[324/1762] D loss: 1.4071, G loss: 0.7675\n",
      "[404/1762] D loss: 0.0512, G loss: 4.6591\n",
      "[484/1762] D loss: 1.4093, G loss: 0.5978\n",
      "[564/1762] D loss: 0.0006, G loss: 8.5779\n",
      "[644/1762] D loss: 1.3969, G loss: 0.7521\n",
      "[724/1762] D loss: 1.3891, G loss: 0.7665\n",
      "[804/1762] D loss: 1.5115, G loss: 1.0398\n",
      "[884/1762] D loss: 0.8478, G loss: 3.6969\n",
      "[964/1762] D loss: 0.1205, G loss: 3.3087\n",
      "[1044/1762] D loss: 0.1138, G loss: 4.5085\n",
      "[1124/1762] D loss: 0.7140, G loss: 4.9105\n",
      "[1204/1762] D loss: 2.1946, G loss: 0.6840\n",
      "[1284/1762] D loss: 1.4034, G loss: 0.6838\n",
      "[1364/1762] D loss: 0.1058, G loss: 2.7114\n",
      "[1444/1762] D loss: 1.2262, G loss: 0.8592\n",
      "[1524/1762] D loss: 1.2148, G loss: 0.8357\n",
      "[1604/1762] D loss: 1.4324, G loss: 0.5997\n",
      "[1684/1762] D loss: 0.0684, G loss: 3.5577\n",
      "[1762/1762] D loss: 1.4075, G loss: 0.8008\n",
      "train error: \n",
      " D loss: 1.308865, G loss: 1.057150, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281213, G loss: 1.144173, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9687, G loss: 3.3473\n",
      "[84/1762] D loss: 1.4210, G loss: 0.5306\n",
      "[164/1762] D loss: 0.1116, G loss: 3.1391\n",
      "[244/1762] D loss: 0.0506, G loss: 3.6400\n",
      "[324/1762] D loss: 1.3908, G loss: 0.6238\n",
      "[404/1762] D loss: 1.4066, G loss: 0.7535\n",
      "[484/1762] D loss: 0.0803, G loss: 3.4284\n",
      "[564/1762] D loss: 1.3904, G loss: 0.7483\n",
      "[644/1762] D loss: 0.0006, G loss: 8.2487\n",
      "[724/1762] D loss: 1.4105, G loss: 0.8164\n",
      "[804/1762] D loss: 1.4044, G loss: 0.5956\n",
      "[884/1762] D loss: 1.3900, G loss: 0.6969\n",
      "[964/1762] D loss: 1.4186, G loss: 0.8091\n",
      "[1044/1762] D loss: 0.0229, G loss: 4.4146\n",
      "[1124/1762] D loss: 1.4276, G loss: 0.5605\n",
      "[1204/1762] D loss: 1.4337, G loss: 0.8785\n",
      "[1284/1762] D loss: 0.0602, G loss: 4.1381\n",
      "[1364/1762] D loss: 0.0538, G loss: 4.3069\n",
      "[1444/1762] D loss: 1.4489, G loss: 0.8557\n",
      "[1524/1762] D loss: 0.0630, G loss: 4.0519\n",
      "[1604/1762] D loss: 1.0105, G loss: 4.8134\n",
      "[1684/1762] D loss: 0.3621, G loss: 6.6005\n",
      "[1762/1762] D loss: 0.6825, G loss: 1.7817\n",
      "train error: \n",
      " D loss: 1.517054, G loss: 5.630849, D accuracy: 51.7%, cell accuracy: 96.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.526048, G loss: 5.849270, D accuracy: 51.5%, cell accuracy: 96.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2991, G loss: 5.5575\n",
      "[84/1762] D loss: 0.3841, G loss: 2.7100\n",
      "[164/1762] D loss: 0.7405, G loss: 3.0196\n",
      "[244/1762] D loss: 0.5820, G loss: 4.9072\n",
      "[324/1762] D loss: 1.4102, G loss: 0.8526\n",
      "[404/1762] D loss: 0.4918, G loss: 3.8881\n",
      "[484/1762] D loss: 0.7745, G loss: 2.4599\n",
      "[564/1762] D loss: 1.8196, G loss: 0.2330\n",
      "[644/1762] D loss: 0.2454, G loss: 6.0431\n",
      "[724/1762] D loss: 1.4530, G loss: 0.5790\n",
      "[804/1762] D loss: 1.6226, G loss: 1.9323\n",
      "[884/1762] D loss: 0.7476, G loss: 2.9380\n",
      "[964/1762] D loss: 1.4061, G loss: 0.6029\n",
      "[1044/1762] D loss: 0.2899, G loss: 7.0963\n",
      "[1124/1762] D loss: 1.4067, G loss: 0.6525\n",
      "[1204/1762] D loss: 1.4070, G loss: 0.5578\n",
      "[1284/1762] D loss: 0.3236, G loss: 3.9796\n",
      "[1364/1762] D loss: 1.4829, G loss: 0.9213\n",
      "[1444/1762] D loss: 0.3184, G loss: 2.9808\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.6919\n",
      "[1604/1762] D loss: 1.4062, G loss: 0.7777\n",
      "[1684/1762] D loss: 1.4448, G loss: 0.5527\n",
      "[1762/1762] D loss: 1.3986, G loss: 0.6761\n",
      "train error: \n",
      " D loss: 1.535629, G loss: 1.065855, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 86.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.502015, G loss: 1.087972, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2364, G loss: 3.4725\n",
      "[84/1762] D loss: 1.4539, G loss: 0.9520\n",
      "[164/1762] D loss: 1.3856, G loss: 0.5916\n",
      "[244/1762] D loss: 1.4378, G loss: 0.5162\n",
      "[324/1762] D loss: 1.4398, G loss: 0.6901\n",
      "[404/1762] D loss: 1.4079, G loss: 0.8175\n",
      "[484/1762] D loss: 1.0392, G loss: 0.9584\n",
      "[564/1762] D loss: 0.8259, G loss: 2.0013\n",
      "[644/1762] D loss: 1.3357, G loss: 0.4480\n",
      "[724/1762] D loss: 1.3977, G loss: 0.6103\n",
      "[804/1762] D loss: 0.9833, G loss: 1.3093\n",
      "[884/1762] D loss: 0.1594, G loss: 6.5122\n",
      "[964/1762] D loss: 1.4259, G loss: 0.8227\n",
      "[1044/1762] D loss: 0.4435, G loss: 13.3339\n",
      "[1124/1762] D loss: 0.1276, G loss: 11.3487\n",
      "[1204/1762] D loss: 1.4677, G loss: 0.9083\n",
      "[1284/1762] D loss: 1.4017, G loss: 0.7905\n",
      "[1364/1762] D loss: 0.1728, G loss: 4.4553\n",
      "[1444/1762] D loss: 1.4373, G loss: 0.9460\n",
      "[1524/1762] D loss: 1.5902, G loss: 1.1974\n",
      "[1604/1762] D loss: 1.4225, G loss: 0.6512\n",
      "[1684/1762] D loss: 1.5045, G loss: 0.9756\n",
      "[1762/1762] D loss: 1.4403, G loss: 0.8561\n",
      "train error: \n",
      " D loss: 1.392237, G loss: 1.374267, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367536, G loss: 1.576800, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3939, G loss: 0.5940\n",
      "[84/1762] D loss: 0.0940, G loss: 7.8471\n",
      "[164/1762] D loss: 1.3904, G loss: 0.6758\n",
      "[244/1762] D loss: 1.4086, G loss: 0.5892\n",
      "[324/1762] D loss: 1.3944, G loss: 0.6391\n",
      "[404/1762] D loss: 1.3883, G loss: 0.6930\n",
      "[484/1762] D loss: 0.1188, G loss: 5.6605\n",
      "[564/1762] D loss: 1.3900, G loss: 0.6826\n",
      "[644/1762] D loss: 1.3981, G loss: 0.7960\n",
      "[724/1762] D loss: 0.1443, G loss: 5.6539\n",
      "[804/1762] D loss: 1.1059, G loss: 1.3206\n",
      "[884/1762] D loss: 1.6640, G loss: 1.0649\n",
      "[964/1762] D loss: 1.4302, G loss: 0.7966\n",
      "[1044/1762] D loss: 0.7978, G loss: 1.5369\n",
      "[1124/1762] D loss: 1.3957, G loss: 0.8420\n",
      "[1204/1762] D loss: 0.1714, G loss: 4.5606\n",
      "[1284/1762] D loss: 0.2363, G loss: 4.9782\n",
      "[1364/1762] D loss: 1.4091, G loss: 0.5980\n",
      "[1444/1762] D loss: 1.4221, G loss: 0.5858\n",
      "[1524/1762] D loss: 0.1154, G loss: 5.3700\n",
      "[1604/1762] D loss: 1.4010, G loss: 0.5962\n",
      "[1684/1762] D loss: 0.0854, G loss: 6.0610\n",
      "[1762/1762] D loss: 1.2076, G loss: 0.9952\n",
      "train error: \n",
      " D loss: 1.459413, G loss: 1.016632, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.433925, G loss: 1.144997, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4289, G loss: 0.6880\n",
      "[84/1762] D loss: 0.0131, G loss: 6.7731\n",
      "[164/1762] D loss: 0.1075, G loss: 2.3805\n",
      "[244/1762] D loss: 0.7319, G loss: 1.3554\n",
      "[324/1762] D loss: 0.4038, G loss: 3.8001\n",
      "[404/1762] D loss: 0.2099, G loss: 5.1750\n",
      "[484/1762] D loss: 0.0151, G loss: 8.0161\n",
      "[564/1762] D loss: 1.5922, G loss: 0.5598\n",
      "[644/1762] D loss: 0.0714, G loss: 9.7707\n",
      "[724/1762] D loss: 0.1648, G loss: 6.3567\n",
      "[804/1762] D loss: 0.4600, G loss: 5.6181\n",
      "[884/1762] D loss: 0.0560, G loss: 5.9510\n",
      "[964/1762] D loss: 0.1789, G loss: 3.8722\n",
      "[1044/1762] D loss: 0.0874, G loss: 2.7998\n",
      "[1124/1762] D loss: 0.0997, G loss: 2.3414\n",
      "[1204/1762] D loss: 0.4253, G loss: 4.8817\n",
      "[1284/1762] D loss: 0.1161, G loss: 6.1695\n",
      "[1364/1762] D loss: 1.4084, G loss: 6.0284\n",
      "[1444/1762] D loss: 0.1815, G loss: 3.1853\n",
      "[1524/1762] D loss: 0.5593, G loss: 3.7755\n",
      "[1604/1762] D loss: 0.7053, G loss: 3.6609\n",
      "[1684/1762] D loss: 0.0575, G loss: 3.5866\n",
      "[1762/1762] D loss: 0.6653, G loss: 3.8178\n",
      "train error: \n",
      " D loss: 0.754683, G loss: 4.268031, D accuracy: 85.2%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.860001, G loss: 4.267890, D accuracy: 83.3%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.6502, G loss: 7.3723\n",
      "[84/1762] D loss: 0.2496, G loss: 3.3688\n",
      "[164/1762] D loss: 0.0478, G loss: 4.2982\n",
      "[244/1762] D loss: 1.3822, G loss: 2.3802\n",
      "[324/1762] D loss: 0.1933, G loss: 2.5227\n",
      "[404/1762] D loss: 1.2412, G loss: 1.9269\n",
      "[484/1762] D loss: 0.6547, G loss: 3.5313\n",
      "[564/1762] D loss: 0.9034, G loss: 2.6456\n",
      "[644/1762] D loss: 1.4151, G loss: 0.6065\n",
      "[724/1762] D loss: 1.3303, G loss: 0.7144\n",
      "[804/1762] D loss: 1.2206, G loss: 1.5756\n",
      "[884/1762] D loss: 1.3954, G loss: 0.6890\n",
      "[964/1762] D loss: 1.2671, G loss: 1.0157\n",
      "[1044/1762] D loss: 1.0936, G loss: 1.3045\n",
      "[1124/1762] D loss: 1.1700, G loss: 0.9136\n",
      "[1204/1762] D loss: 1.4540, G loss: 0.7841\n",
      "[1284/1762] D loss: 1.4203, G loss: 0.7321\n",
      "[1364/1762] D loss: 1.4363, G loss: 0.7210\n",
      "[1444/1762] D loss: 1.3951, G loss: 0.8108\n",
      "[1524/1762] D loss: 1.4322, G loss: 0.5275\n",
      "[1604/1762] D loss: 1.3568, G loss: 0.6939\n",
      "[1684/1762] D loss: 1.3989, G loss: 0.6648\n",
      "[1762/1762] D loss: 1.4073, G loss: 0.7144\n",
      "train error: \n",
      " D loss: 1.278360, G loss: 0.946089, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261174, G loss: 0.978215, D accuracy: 57.6%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3960, G loss: 0.7301\n",
      "[84/1762] D loss: 1.2443, G loss: 0.9164\n",
      "[164/1762] D loss: 1.1894, G loss: 1.1582\n",
      "[244/1762] D loss: 1.3573, G loss: 0.8097\n",
      "[324/1762] D loss: 1.4419, G loss: 0.6606\n",
      "[404/1762] D loss: 1.2139, G loss: 1.0356\n",
      "[484/1762] D loss: 1.3861, G loss: 0.6295\n",
      "[564/1762] D loss: 0.7244, G loss: 2.9093\n",
      "[644/1762] D loss: 0.5991, G loss: 3.3403\n",
      "[724/1762] D loss: 0.8647, G loss: 1.2484\n",
      "[804/1762] D loss: 1.3074, G loss: 0.6558\n",
      "[884/1762] D loss: 1.3801, G loss: 0.5543\n",
      "[964/1762] D loss: 1.1905, G loss: 1.0042\n",
      "[1044/1762] D loss: 0.9901, G loss: 1.4756\n",
      "[1124/1762] D loss: 1.3075, G loss: 0.8713\n",
      "[1204/1762] D loss: 0.3365, G loss: 2.9865\n",
      "[1284/1762] D loss: 1.2529, G loss: 0.8219\n",
      "[1364/1762] D loss: 1.4155, G loss: 0.7531\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.6395\n",
      "[1524/1762] D loss: 1.4074, G loss: 0.6368\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.6447\n",
      "[1684/1762] D loss: 0.7744, G loss: 1.6773\n",
      "[1762/1762] D loss: 0.7073, G loss: 2.9676\n",
      "train error: \n",
      " D loss: 0.899505, G loss: 3.733821, D accuracy: 74.2%, cell accuracy: 98.8%, board accuracy: 20.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.884300, G loss: 3.840147, D accuracy: 75.1%, cell accuracy: 98.8%, board accuracy: 19.1% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7201, G loss: 0.8877\n",
      "[84/1762] D loss: 0.7609, G loss: 8.9297\n",
      "[164/1762] D loss: 1.5572, G loss: 0.4250\n",
      "[244/1762] D loss: 1.3547, G loss: 0.8254\n",
      "[324/1762] D loss: 1.3936, G loss: 0.7257\n",
      "[404/1762] D loss: 1.2476, G loss: 0.7939\n",
      "[484/1762] D loss: 1.3883, G loss: 0.5361\n",
      "[564/1762] D loss: 1.4260, G loss: 0.8775\n",
      "[644/1762] D loss: 1.0399, G loss: 0.9212\n",
      "[724/1762] D loss: 1.2678, G loss: 0.9033\n",
      "[804/1762] D loss: 1.4059, G loss: 0.6215\n",
      "[884/1762] D loss: 1.4277, G loss: 0.7908\n",
      "[964/1762] D loss: 0.9333, G loss: 1.0368\n",
      "[1044/1762] D loss: 0.9344, G loss: 0.9707\n",
      "[1124/1762] D loss: 1.3672, G loss: 0.8300\n",
      "[1204/1762] D loss: 1.1910, G loss: 1.1816\n",
      "[1284/1762] D loss: 0.5207, G loss: 2.4149\n",
      "[1364/1762] D loss: 1.6182, G loss: 0.4064\n",
      "[1444/1762] D loss: 1.4312, G loss: 0.6599\n",
      "[1524/1762] D loss: 0.8624, G loss: 0.8587\n",
      "[1604/1762] D loss: 0.5695, G loss: 1.5749\n",
      "[1684/1762] D loss: 1.4852, G loss: 0.7137\n",
      "[1762/1762] D loss: 1.6207, G loss: 0.6577\n",
      "train error: \n",
      " D loss: 1.332578, G loss: 1.061135, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301197, G loss: 1.111304, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4337, G loss: 0.7505\n",
      "[84/1762] D loss: 1.3931, G loss: 0.7690\n",
      "[164/1762] D loss: 1.4975, G loss: 0.9484\n",
      "[244/1762] D loss: 1.4370, G loss: 0.6859\n",
      "[324/1762] D loss: 1.3956, G loss: 0.6032\n",
      "[404/1762] D loss: 0.7284, G loss: 0.8734\n",
      "[484/1762] D loss: 1.4081, G loss: 0.7147\n",
      "[564/1762] D loss: 1.4240, G loss: 0.5222\n",
      "[644/1762] D loss: 1.6292, G loss: 1.0611\n",
      "[724/1762] D loss: 1.2818, G loss: 0.6066\n",
      "[804/1762] D loss: 1.4977, G loss: 0.9277\n",
      "[884/1762] D loss: 1.3129, G loss: 1.8000\n",
      "[964/1762] D loss: 0.5686, G loss: 1.5129\n",
      "[1044/1762] D loss: 1.4239, G loss: 0.8146\n",
      "[1124/1762] D loss: 1.5016, G loss: 0.9814\n",
      "[1204/1762] D loss: 0.2872, G loss: 3.3083\n",
      "[1284/1762] D loss: 1.4533, G loss: 0.5822\n",
      "[1364/1762] D loss: 0.2001, G loss: 3.1486\n",
      "[1444/1762] D loss: 1.7110, G loss: 1.1627\n",
      "[1524/1762] D loss: 1.4162, G loss: 0.7359\n",
      "[1604/1762] D loss: 0.3031, G loss: 2.3849\n",
      "[1684/1762] D loss: 0.4035, G loss: 3.3957\n",
      "[1762/1762] D loss: 1.6626, G loss: 0.7139\n",
      "train error: \n",
      " D loss: 1.493270, G loss: 1.408005, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 70.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.436447, G loss: 1.419354, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8655, G loss: 1.5611\n",
      "[84/1762] D loss: 1.4017, G loss: 0.8093\n",
      "[164/1762] D loss: 1.3985, G loss: 0.8484\n",
      "[244/1762] D loss: 1.3812, G loss: 0.9217\n",
      "[324/1762] D loss: 1.2198, G loss: 0.9353\n",
      "[404/1762] D loss: 1.3651, G loss: 0.7367\n",
      "[484/1762] D loss: 1.4237, G loss: 0.6736\n",
      "[564/1762] D loss: 1.0404, G loss: 2.1921\n",
      "[644/1762] D loss: 1.8037, G loss: 1.3811\n",
      "[724/1762] D loss: 1.3370, G loss: 1.0175\n",
      "[804/1762] D loss: 1.4213, G loss: 0.6813\n",
      "[884/1762] D loss: 1.1654, G loss: 1.0010\n",
      "[964/1762] D loss: 1.5005, G loss: 1.1535\n",
      "[1044/1762] D loss: 1.4247, G loss: 0.5812\n",
      "[1124/1762] D loss: 0.6308, G loss: 1.8417\n",
      "[1204/1762] D loss: 1.4193, G loss: 0.7901\n",
      "[1284/1762] D loss: 0.4256, G loss: 1.8716\n",
      "[1364/1762] D loss: 1.4025, G loss: 0.7917\n",
      "[1444/1762] D loss: 1.3943, G loss: 0.7123\n",
      "[1524/1762] D loss: 1.4858, G loss: 1.0348\n",
      "[1604/1762] D loss: 1.7225, G loss: 0.6975\n",
      "[1684/1762] D loss: 1.3239, G loss: 1.1758\n",
      "[1762/1762] D loss: 0.8730, G loss: 1.0209\n",
      "train error: \n",
      " D loss: 1.210914, G loss: 0.931936, D accuracy: 68.5%, cell accuracy: 97.3%, board accuracy: 20.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.157511, G loss: 0.947547, D accuracy: 69.9%, cell accuracy: 97.2%, board accuracy: 17.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2604, G loss: 2.1148\n",
      "[84/1762] D loss: 1.6182, G loss: 0.4356\n",
      "[164/1762] D loss: 1.3298, G loss: 0.9613\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6712\n",
      "[324/1762] D loss: 1.3882, G loss: 0.6535\n",
      "[404/1762] D loss: 1.3896, G loss: 0.6585\n",
      "[484/1762] D loss: 1.3878, G loss: 0.6736\n",
      "[564/1762] D loss: 1.3848, G loss: 0.6318\n",
      "[644/1762] D loss: 1.3888, G loss: 0.6542\n",
      "[724/1762] D loss: 1.3773, G loss: 0.6625\n",
      "[804/1762] D loss: 1.3848, G loss: 0.6575\n",
      "[884/1762] D loss: 0.9690, G loss: 1.1259\n",
      "[964/1762] D loss: 0.7627, G loss: 2.0364\n",
      "[1044/1762] D loss: 1.4110, G loss: 0.7529\n",
      "[1124/1762] D loss: 0.6938, G loss: 3.1759\n",
      "[1204/1762] D loss: 1.3992, G loss: 0.7442\n",
      "[1284/1762] D loss: 1.4112, G loss: 0.6744\n",
      "[1364/1762] D loss: 0.5205, G loss: 2.7909\n",
      "[1444/1762] D loss: 1.3017, G loss: 0.9812\n",
      "[1524/1762] D loss: 1.4556, G loss: 0.8710\n",
      "[1604/1762] D loss: 1.4090, G loss: 0.8091\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7450\n",
      "[1762/1762] D loss: 1.4156, G loss: 0.6564\n",
      "train error: \n",
      " D loss: 1.423044, G loss: 0.684644, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412280, G loss: 0.766322, D accuracy: 58.2%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4590, G loss: 0.5351\n",
      "[84/1762] D loss: 0.6751, G loss: 2.0114\n",
      "[164/1762] D loss: 1.2513, G loss: 1.0762\n",
      "[244/1762] D loss: 1.3340, G loss: 0.9564\n",
      "[324/1762] D loss: 2.3051, G loss: 1.9648\n",
      "[404/1762] D loss: 0.5186, G loss: 2.1373\n",
      "[484/1762] D loss: 0.7383, G loss: 0.8595\n",
      "[564/1762] D loss: 1.4115, G loss: 0.8255\n",
      "[644/1762] D loss: 1.1514, G loss: 1.2270\n",
      "[724/1762] D loss: 0.6357, G loss: 2.0624\n",
      "[804/1762] D loss: 1.3009, G loss: 0.8231\n",
      "[884/1762] D loss: 1.3368, G loss: 0.9615\n",
      "[964/1762] D loss: 1.3715, G loss: 0.7790\n",
      "[1044/1762] D loss: 1.4055, G loss: 0.7324\n",
      "[1124/1762] D loss: 0.3801, G loss: 2.5557\n",
      "[1204/1762] D loss: 0.6735, G loss: 2.9778\n",
      "[1284/1762] D loss: 0.7509, G loss: 2.1950\n",
      "[1364/1762] D loss: 0.7759, G loss: 2.9521\n",
      "[1444/1762] D loss: 2.9943, G loss: 0.4544\n",
      "[1524/1762] D loss: 1.2371, G loss: 0.7285\n",
      "[1604/1762] D loss: 1.3564, G loss: 0.5890\n",
      "[1684/1762] D loss: 1.2090, G loss: 1.3905\n",
      "[1762/1762] D loss: 1.4538, G loss: 0.8842\n",
      "train error: \n",
      " D loss: 1.399662, G loss: 0.678658, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.405974, G loss: 0.690362, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5789, G loss: 1.0203\n",
      "[84/1762] D loss: 1.3523, G loss: 0.7880\n",
      "[164/1762] D loss: 1.4120, G loss: 0.6163\n",
      "[244/1762] D loss: 1.1712, G loss: 0.8730\n",
      "[324/1762] D loss: 1.4171, G loss: 0.7001\n",
      "[404/1762] D loss: 1.4196, G loss: 0.5620\n",
      "[484/1762] D loss: 1.0436, G loss: 1.6719\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6669\n",
      "[644/1762] D loss: 1.2266, G loss: 0.9425\n",
      "[724/1762] D loss: 1.5294, G loss: 0.8768\n",
      "[804/1762] D loss: 1.4082, G loss: 0.7421\n",
      "[884/1762] D loss: 1.4032, G loss: 0.6384\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7240\n",
      "[1044/1762] D loss: 1.1916, G loss: 1.4523\n",
      "[1124/1762] D loss: 1.0341, G loss: 2.2374\n",
      "[1204/1762] D loss: 0.4816, G loss: 4.0073\n",
      "[1284/1762] D loss: 0.4121, G loss: 3.6549\n",
      "[1364/1762] D loss: 1.2402, G loss: 0.9335\n",
      "[1444/1762] D loss: 1.5444, G loss: 1.3828\n",
      "[1524/1762] D loss: 1.4331, G loss: 0.5202\n",
      "[1604/1762] D loss: 1.2757, G loss: 0.7662\n",
      "[1684/1762] D loss: 0.4752, G loss: 2.5060\n",
      "[1762/1762] D loss: 0.5923, G loss: 2.1850\n",
      "train error: \n",
      " D loss: 1.316471, G loss: 0.841081, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286394, G loss: 0.888931, D accuracy: 57.2%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6604, G loss: 1.7766\n",
      "[84/1762] D loss: 1.3846, G loss: 0.6003\n",
      "[164/1762] D loss: 1.3939, G loss: 0.6698\n",
      "[244/1762] D loss: 0.2382, G loss: 2.1321\n",
      "[324/1762] D loss: 0.4561, G loss: 2.6752\n",
      "[404/1762] D loss: 1.3711, G loss: 0.6959\n",
      "[484/1762] D loss: 1.3142, G loss: 0.7936\n",
      "[564/1762] D loss: 1.4249, G loss: 0.6637\n",
      "[644/1762] D loss: 1.3941, G loss: 0.7162\n",
      "[724/1762] D loss: 1.3976, G loss: 0.9447\n",
      "[804/1762] D loss: 1.3883, G loss: 0.9022\n",
      "[884/1762] D loss: 1.4392, G loss: 0.8629\n",
      "[964/1762] D loss: 0.4703, G loss: 2.0349\n",
      "[1044/1762] D loss: 0.6313, G loss: 1.6643\n",
      "[1124/1762] D loss: 0.6341, G loss: 1.5427\n",
      "[1204/1762] D loss: 0.2023, G loss: 2.5515\n",
      "[1284/1762] D loss: 1.4059, G loss: 0.8102\n",
      "[1364/1762] D loss: 1.4032, G loss: 0.6838\n",
      "[1444/1762] D loss: 1.9289, G loss: 3.4799\n",
      "[1524/1762] D loss: 1.6295, G loss: 1.8131\n",
      "[1604/1762] D loss: 1.4516, G loss: 0.4680\n",
      "[1684/1762] D loss: 1.4039, G loss: 0.5732\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.6433\n",
      "train error: \n",
      " D loss: 1.330190, G loss: 0.665225, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304097, G loss: 0.680490, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.6469\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7226\n",
      "[164/1762] D loss: 1.3909, G loss: 0.7652\n",
      "[244/1762] D loss: 1.3930, G loss: 0.7779\n",
      "[324/1762] D loss: 1.2721, G loss: 1.1826\n",
      "[404/1762] D loss: 1.3933, G loss: 0.7785\n",
      "[484/1762] D loss: 1.0539, G loss: 2.0914\n",
      "[564/1762] D loss: 1.4208, G loss: 0.7341\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6604\n",
      "[724/1762] D loss: 1.2141, G loss: 1.3729\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[884/1762] D loss: 0.6867, G loss: 1.5936\n",
      "[964/1762] D loss: 0.4728, G loss: 1.8367\n",
      "[1044/1762] D loss: 1.3956, G loss: 0.7953\n",
      "[1124/1762] D loss: 1.0414, G loss: 1.9562\n",
      "[1204/1762] D loss: 1.3977, G loss: 1.9252\n",
      "[1284/1762] D loss: 1.0880, G loss: 1.2858\n",
      "[1364/1762] D loss: 0.4259, G loss: 3.3131\n",
      "[1444/1762] D loss: 0.8358, G loss: 1.5193\n",
      "[1524/1762] D loss: 1.1961, G loss: 1.1357\n",
      "[1604/1762] D loss: 1.4152, G loss: 0.6069\n",
      "[1684/1762] D loss: 1.4112, G loss: 0.6501\n",
      "[1762/1762] D loss: 1.3853, G loss: 0.7060\n",
      "train error: \n",
      " D loss: 1.304554, G loss: 0.884448, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278220, G loss: 0.922808, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5147, G loss: 1.7311\n",
      "[84/1762] D loss: 1.4084, G loss: 0.8253\n",
      "[164/1762] D loss: 1.2707, G loss: 0.8868\n",
      "[244/1762] D loss: 0.5420, G loss: 2.3769\n",
      "[324/1762] D loss: 0.3701, G loss: 2.1278\n",
      "[404/1762] D loss: 1.3957, G loss: 0.7548\n",
      "[484/1762] D loss: 1.4178, G loss: 0.8411\n",
      "[564/1762] D loss: 1.4507, G loss: 0.8793\n",
      "[644/1762] D loss: 1.3934, G loss: 0.7053\n",
      "[724/1762] D loss: 0.3125, G loss: 2.3317\n",
      "[804/1762] D loss: 0.4848, G loss: 2.2768\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6994\n",
      "[964/1762] D loss: 0.0580, G loss: 3.5152\n",
      "[1044/1762] D loss: 1.3825, G loss: 0.6975\n",
      "[1124/1762] D loss: 0.0233, G loss: 5.7659\n",
      "[1204/1762] D loss: 0.4419, G loss: 2.7778\n",
      "[1284/1762] D loss: 1.4602, G loss: 0.9253\n",
      "[1364/1762] D loss: 1.3900, G loss: 0.7200\n",
      "[1444/1762] D loss: 0.3932, G loss: 2.0964\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7101\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.7197\n",
      "[1684/1762] D loss: 0.4228, G loss: 3.1182\n",
      "[1762/1762] D loss: 1.3923, G loss: 0.7753\n",
      "train error: \n",
      " D loss: 1.345241, G loss: 0.976563, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316069, G loss: 1.107082, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909, G loss: 0.7508\n",
      "[84/1762] D loss: 0.4141, G loss: 1.9518\n",
      "[164/1762] D loss: 0.2895, G loss: 2.0662\n",
      "[244/1762] D loss: 1.4449, G loss: 0.8375\n",
      "[324/1762] D loss: 1.3895, G loss: 0.7522\n",
      "[404/1762] D loss: 1.3888, G loss: 0.7444\n",
      "[484/1762] D loss: 0.4194, G loss: 2.2923\n",
      "[564/1762] D loss: 1.3886, G loss: 0.7266\n",
      "[644/1762] D loss: 0.4841, G loss: 1.8741\n",
      "[724/1762] D loss: 2.1358, G loss: 0.9969\n",
      "[804/1762] D loss: 0.2233, G loss: 2.4553\n",
      "[884/1762] D loss: 1.3913, G loss: 0.7281\n",
      "[964/1762] D loss: 1.3586, G loss: 0.7788\n",
      "[1044/1762] D loss: 1.3971, G loss: 0.7574\n",
      "[1124/1762] D loss: 1.3904, G loss: 0.7619\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7684\n",
      "[1284/1762] D loss: 1.3935, G loss: 0.7779\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.7890\n",
      "[1444/1762] D loss: 0.2896, G loss: 2.2738\n",
      "[1524/1762] D loss: 1.3912, G loss: 0.7491\n",
      "[1604/1762] D loss: 1.2266, G loss: 1.8506\n",
      "[1684/1762] D loss: 1.3902, G loss: 0.7600\n",
      "[1762/1762] D loss: 1.1145, G loss: 1.6383\n",
      "train error: \n",
      " D loss: 1.149140, G loss: 1.800318, D accuracy: 53.5%, cell accuracy: 98.8%, board accuracy: 42.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.129468, G loss: 1.983667, D accuracy: 54.5%, cell accuracy: 98.6%, board accuracy: 41.6% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1129, G loss: 1.7760\n",
      "[84/1762] D loss: 0.2106, G loss: 4.2467\n",
      "[164/1762] D loss: 1.3744, G loss: 1.1235\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6619\n",
      "[324/1762] D loss: 1.4482, G loss: 0.6792\n",
      "[404/1762] D loss: 0.5288, G loss: 2.7998\n",
      "[484/1762] D loss: 1.3092, G loss: 0.9079\n",
      "[564/1762] D loss: 1.4748, G loss: 1.0256\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7315\n",
      "[724/1762] D loss: 1.6065, G loss: 0.9777\n",
      "[804/1762] D loss: 0.2174, G loss: 4.5652\n",
      "[884/1762] D loss: 0.2991, G loss: 1.5825\n",
      "[964/1762] D loss: 1.2786, G loss: 0.9228\n",
      "[1044/1762] D loss: 1.1325, G loss: 1.1842\n",
      "[1124/1762] D loss: 1.5494, G loss: 0.8339\n",
      "[1204/1762] D loss: 1.2872, G loss: 0.8535\n",
      "[1284/1762] D loss: 1.3984, G loss: 0.8129\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6817\n",
      "[1444/1762] D loss: 1.2913, G loss: 0.9348\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6813\n",
      "[1604/1762] D loss: 1.3225, G loss: 0.8433\n",
      "[1684/1762] D loss: 0.8433, G loss: 2.9017\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.6653\n",
      "train error: \n",
      " D loss: 1.339209, G loss: 1.479110, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332162, G loss: 1.639914, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2658, G loss: 1.0606\n",
      "[84/1762] D loss: 1.4169, G loss: 0.5283\n",
      "[164/1762] D loss: 1.4188, G loss: 0.5310\n",
      "[244/1762] D loss: 1.5383, G loss: 0.9106\n",
      "[324/1762] D loss: 1.4014, G loss: 0.5795\n",
      "[404/1762] D loss: 1.1995, G loss: 2.2407\n",
      "[484/1762] D loss: 1.3894, G loss: 0.6393\n",
      "[564/1762] D loss: 1.3892, G loss: 0.6595\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6422\n",
      "[724/1762] D loss: 1.6562, G loss: 0.7174\n",
      "[804/1762] D loss: 1.3971, G loss: 0.5947\n",
      "[884/1762] D loss: 1.3934, G loss: 0.6135\n",
      "[964/1762] D loss: 1.3955, G loss: 0.6014\n",
      "[1044/1762] D loss: 1.3426, G loss: 0.9840\n",
      "[1124/1762] D loss: 1.1961, G loss: 1.7781\n",
      "[1204/1762] D loss: 1.4029, G loss: 0.5727\n",
      "[1284/1762] D loss: 1.3335, G loss: 0.5739\n",
      "[1364/1762] D loss: 1.3656, G loss: 0.6390\n",
      "[1444/1762] D loss: 1.3503, G loss: 0.6715\n",
      "[1524/1762] D loss: 1.4162, G loss: 0.7084\n",
      "[1604/1762] D loss: 1.4333, G loss: 0.4984\n",
      "[1684/1762] D loss: 1.4524, G loss: 0.7179\n",
      "[1762/1762] D loss: 1.5143, G loss: 0.7343\n",
      "train error: \n",
      " D loss: 1.388118, G loss: 1.339216, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369840, G loss: 1.493777, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5788, G loss: 0.7277\n",
      "[84/1762] D loss: 1.7310, G loss: 1.0758\n",
      "[164/1762] D loss: 1.4189, G loss: 0.5311\n",
      "[244/1762] D loss: 1.4105, G loss: 0.5503\n",
      "[324/1762] D loss: 1.4148, G loss: 0.5380\n",
      "[404/1762] D loss: 1.4145, G loss: 0.5394\n",
      "[484/1762] D loss: 0.6468, G loss: 4.0871\n",
      "[564/1762] D loss: 1.4496, G loss: 0.4776\n",
      "[644/1762] D loss: 0.8595, G loss: 3.6240\n",
      "[724/1762] D loss: 1.4282, G loss: 0.5116\n",
      "[804/1762] D loss: 0.8253, G loss: 3.2900\n",
      "[884/1762] D loss: 0.6171, G loss: 4.6068\n",
      "[964/1762] D loss: 0.9441, G loss: 1.7111\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6189\n",
      "[1124/1762] D loss: 1.4044, G loss: 0.7026\n",
      "[1204/1762] D loss: 1.4239, G loss: 0.5290\n",
      "[1284/1762] D loss: 0.6094, G loss: 3.5511\n",
      "[1364/1762] D loss: 0.6063, G loss: 4.3685\n",
      "[1444/1762] D loss: 0.8299, G loss: 3.3441\n",
      "[1524/1762] D loss: 0.7362, G loss: 3.4882\n",
      "[1604/1762] D loss: 1.4107, G loss: 0.5771\n",
      "[1684/1762] D loss: 0.5859, G loss: 3.7310\n",
      "[1762/1762] D loss: 1.4443, G loss: 0.5758\n",
      "train error: \n",
      " D loss: 1.376074, G loss: 1.071587, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347776, G loss: 1.271052, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4820, G loss: 0.6678\n",
      "[84/1762] D loss: 1.4214, G loss: 0.5994\n",
      "[164/1762] D loss: 1.4433, G loss: 0.4902\n",
      "[244/1762] D loss: 0.4821, G loss: 5.2238\n",
      "[324/1762] D loss: 1.4540, G loss: 0.4605\n",
      "[404/1762] D loss: 1.4600, G loss: 0.4750\n",
      "[484/1762] D loss: 0.8703, G loss: 1.8538\n",
      "[564/1762] D loss: 0.9534, G loss: 3.5455\n",
      "[644/1762] D loss: 1.4277, G loss: 0.6859\n",
      "[724/1762] D loss: 1.4133, G loss: 0.6311\n",
      "[804/1762] D loss: 1.3923, G loss: 0.6081\n",
      "[884/1762] D loss: 1.3940, G loss: 0.6158\n",
      "[964/1762] D loss: 1.2732, G loss: 0.8493\n",
      "[1044/1762] D loss: 1.4124, G loss: 0.5635\n",
      "[1124/1762] D loss: 0.7929, G loss: 2.8798\n",
      "[1204/1762] D loss: 1.3676, G loss: 0.7698\n",
      "[1284/1762] D loss: 1.4098, G loss: 0.8553\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.6619\n",
      "[1444/1762] D loss: 1.3839, G loss: 0.6378\n",
      "[1524/1762] D loss: 0.3122, G loss: 8.9873\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.7283\n",
      "[1684/1762] D loss: 1.3996, G loss: 0.7761\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6773\n",
      "train error: \n",
      " D loss: 1.321000, G loss: 1.382421, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302459, G loss: 1.615177, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.7804\n",
      "[84/1762] D loss: 0.3244, G loss: 5.0859\n",
      "[164/1762] D loss: 1.3928, G loss: 0.6085\n",
      "[244/1762] D loss: 1.4244, G loss: 0.5578\n",
      "[324/1762] D loss: 1.3820, G loss: 1.2150\n",
      "[404/1762] D loss: 1.5944, G loss: 0.9995\n",
      "[484/1762] D loss: 0.2906, G loss: 4.7842\n",
      "[564/1762] D loss: 1.3997, G loss: 0.6288\n",
      "[644/1762] D loss: 1.3988, G loss: 0.7819\n",
      "[724/1762] D loss: 1.3877, G loss: 0.7347\n",
      "[804/1762] D loss: 1.4796, G loss: 0.5035\n",
      "[884/1762] D loss: 1.3946, G loss: 0.7524\n",
      "[964/1762] D loss: 0.2972, G loss: 3.8585\n",
      "[1044/1762] D loss: 0.3266, G loss: 5.5282\n",
      "[1124/1762] D loss: 1.3242, G loss: 0.9429\n",
      "[1204/1762] D loss: 1.4105, G loss: 0.5541\n",
      "[1284/1762] D loss: 0.2889, G loss: 4.3216\n",
      "[1364/1762] D loss: 1.4942, G loss: 0.9560\n",
      "[1444/1762] D loss: 0.1843, G loss: 5.9902\n",
      "[1524/1762] D loss: 0.2292, G loss: 4.7887\n",
      "[1604/1762] D loss: 0.1534, G loss: 7.1130\n",
      "[1684/1762] D loss: 1.1740, G loss: 1.6984\n",
      "[1762/1762] D loss: 1.2401, G loss: 0.9528\n",
      "train error: \n",
      " D loss: 1.837231, G loss: 2.264460, D accuracy: 51.7%, cell accuracy: 99.6%, board accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.775853, G loss: 2.131001, D accuracy: 51.0%, cell accuracy: 99.6%, board accuracy: 52.7% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3580, G loss: 0.8893\n",
      "[84/1762] D loss: 1.6338, G loss: 1.0358\n",
      "[164/1762] D loss: 0.5294, G loss: 5.5024\n",
      "[244/1762] D loss: 0.4705, G loss: 5.7959\n",
      "[324/1762] D loss: 0.4100, G loss: 4.5164\n",
      "[404/1762] D loss: 0.9056, G loss: 4.9892\n",
      "[484/1762] D loss: 1.6427, G loss: 1.0418\n",
      "[564/1762] D loss: 1.7115, G loss: 0.9334\n",
      "[644/1762] D loss: 1.3924, G loss: 0.7616\n",
      "[724/1762] D loss: 1.3952, G loss: 0.6480\n",
      "[804/1762] D loss: 1.5415, G loss: 0.9529\n",
      "[884/1762] D loss: 0.4983, G loss: 3.0881\n",
      "[964/1762] D loss: 1.4910, G loss: 1.0127\n",
      "[1044/1762] D loss: 0.2290, G loss: 4.6405\n",
      "[1124/1762] D loss: 0.0807, G loss: 9.9105\n",
      "[1204/1762] D loss: 1.4078, G loss: 0.7761\n",
      "[1284/1762] D loss: 1.3646, G loss: 0.7847\n",
      "[1364/1762] D loss: 1.4014, G loss: 0.6632\n",
      "[1444/1762] D loss: 0.1310, G loss: 4.0014\n",
      "[1524/1762] D loss: 0.2835, G loss: 3.4916\n",
      "[1604/1762] D loss: 1.4901, G loss: 0.4843\n",
      "[1684/1762] D loss: 0.5094, G loss: 2.5057\n",
      "[1762/1762] D loss: 1.5787, G loss: 1.1327\n",
      "train error: \n",
      " D loss: 1.295032, G loss: 1.237343, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268778, G loss: 1.400383, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4374, G loss: 0.8498\n",
      "[84/1762] D loss: 0.3039, G loss: 3.2361\n",
      "[164/1762] D loss: 1.4310, G loss: 0.8861\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6729\n",
      "[324/1762] D loss: 0.3516, G loss: 2.2587\n",
      "[404/1762] D loss: 1.5270, G loss: 3.6520\n",
      "[484/1762] D loss: 0.7174, G loss: 3.4891\n",
      "[564/1762] D loss: 0.4143, G loss: 3.9313\n",
      "[644/1762] D loss: 0.2306, G loss: 3.1358\n",
      "[724/1762] D loss: 0.1920, G loss: 4.2411\n",
      "[804/1762] D loss: 1.4436, G loss: 0.5265\n",
      "[884/1762] D loss: 0.6421, G loss: 2.3080\n",
      "[964/1762] D loss: 1.4069, G loss: 0.6595\n",
      "[1044/1762] D loss: 1.4380, G loss: 0.9004\n",
      "[1124/1762] D loss: 1.3130, G loss: 1.2772\n",
      "[1204/1762] D loss: 1.3902, G loss: 0.6616\n",
      "[1284/1762] D loss: 0.1292, G loss: 10.4288\n",
      "[1364/1762] D loss: 1.1542, G loss: 1.2127\n",
      "[1444/1762] D loss: 0.1605, G loss: 5.2932\n",
      "[1524/1762] D loss: 1.3928, G loss: 0.6346\n",
      "[1604/1762] D loss: 0.3687, G loss: 4.0717\n",
      "[1684/1762] D loss: 0.4070, G loss: 3.9619\n",
      "[1762/1762] D loss: 1.3996, G loss: 0.6106\n",
      "train error: \n",
      " D loss: 1.307179, G loss: 1.557225, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288301, G loss: 1.842779, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.6804\n",
      "[84/1762] D loss: 0.6097, G loss: 1.4166\n",
      "[164/1762] D loss: 1.3852, G loss: 0.6706\n",
      "[244/1762] D loss: 1.4361, G loss: 4.1569\n",
      "[324/1762] D loss: 1.4226, G loss: 0.8236\n",
      "[404/1762] D loss: 1.4049, G loss: 0.6829\n",
      "[484/1762] D loss: 1.4289, G loss: 0.8656\n",
      "[564/1762] D loss: 1.3559, G loss: 0.7541\n",
      "[644/1762] D loss: 0.4000, G loss: 2.4270\n",
      "[724/1762] D loss: 1.3961, G loss: 0.5912\n",
      "[804/1762] D loss: 1.4594, G loss: 0.8311\n",
      "[884/1762] D loss: 1.4111, G loss: 0.7474\n",
      "[964/1762] D loss: 0.0955, G loss: 5.7404\n",
      "[1044/1762] D loss: 1.4076, G loss: 0.5732\n",
      "[1124/1762] D loss: 1.1225, G loss: 6.2578\n",
      "[1204/1762] D loss: 1.2619, G loss: 0.5464\n",
      "[1284/1762] D loss: 1.4330, G loss: 0.7226\n",
      "[1364/1762] D loss: 0.1052, G loss: 6.3042\n",
      "[1444/1762] D loss: 1.4509, G loss: 0.9697\n",
      "[1524/1762] D loss: 0.0822, G loss: 16.5523\n",
      "[1604/1762] D loss: 1.4416, G loss: 0.7587\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.6250\n",
      "[1762/1762] D loss: 1.4338, G loss: 0.8953\n",
      "train error: \n",
      " D loss: 1.361390, G loss: 1.435486, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338598, G loss: 1.705242, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0823, G loss: 7.2124\n",
      "[84/1762] D loss: 0.2183, G loss: 4.3136\n",
      "[164/1762] D loss: 1.3995, G loss: 0.7873\n",
      "[244/1762] D loss: 1.3937, G loss: 0.8073\n",
      "[324/1762] D loss: 0.4950, G loss: 1.4351\n",
      "[404/1762] D loss: 1.3741, G loss: 0.7380\n",
      "[484/1762] D loss: 1.3876, G loss: 0.7051\n",
      "[564/1762] D loss: 1.3733, G loss: 0.6186\n",
      "[644/1762] D loss: 1.4184, G loss: 0.6242\n",
      "[724/1762] D loss: 1.3934, G loss: 0.7265\n",
      "[804/1762] D loss: 0.0791, G loss: 7.8877\n",
      "[884/1762] D loss: 0.1359, G loss: 5.4484\n",
      "[964/1762] D loss: 1.3952, G loss: 0.7266\n",
      "[1044/1762] D loss: 1.6099, G loss: 1.2215\n",
      "[1124/1762] D loss: 1.4267, G loss: 0.9502\n",
      "[1204/1762] D loss: 1.5415, G loss: 0.4310\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.7750\n",
      "[1364/1762] D loss: 1.4719, G loss: 0.9588\n",
      "[1444/1762] D loss: 1.4510, G loss: 0.7778\n",
      "[1524/1762] D loss: 1.4033, G loss: 0.6242\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.7024\n",
      "[1684/1762] D loss: 1.4014, G loss: 0.6241\n",
      "[1762/1762] D loss: 0.0442, G loss: 14.4000\n",
      "train error: \n",
      " D loss: 1.916682, G loss: 1.043060, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.842162, G loss: 1.355737, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3567, G loss: 0.5517\n",
      "[84/1762] D loss: 0.0710, G loss: 7.6163\n",
      "[164/1762] D loss: 0.8908, G loss: 1.4506\n",
      "[244/1762] D loss: 1.0884, G loss: 2.0445\n",
      "[324/1762] D loss: 0.2944, G loss: 4.1171\n",
      "[404/1762] D loss: 0.0767, G loss: 8.0945\n",
      "[484/1762] D loss: 0.2233, G loss: 5.6772\n",
      "[564/1762] D loss: 0.2934, G loss: 5.5206\n",
      "[644/1762] D loss: 0.1536, G loss: 5.0268\n",
      "[724/1762] D loss: 1.3907, G loss: 0.7803\n",
      "[804/1762] D loss: 0.0759, G loss: 6.9250\n",
      "[884/1762] D loss: 1.3884, G loss: 0.7055\n",
      "[964/1762] D loss: 0.0906, G loss: 8.5026\n",
      "[1044/1762] D loss: 1.3900, G loss: 0.6520\n",
      "[1124/1762] D loss: 1.4922, G loss: 0.4930\n",
      "[1204/1762] D loss: 1.3632, G loss: 0.6873\n",
      "[1284/1762] D loss: 1.4275, G loss: 0.5701\n",
      "[1364/1762] D loss: 0.0562, G loss: 5.0992\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.7514\n",
      "[1524/1762] D loss: 1.4264, G loss: 0.8459\n",
      "[1604/1762] D loss: 0.1736, G loss: 2.8106\n",
      "[1684/1762] D loss: 2.5201, G loss: 0.6251\n",
      "[1762/1762] D loss: 1.4296, G loss: 0.8004\n",
      "train error: \n",
      " D loss: 1.350584, G loss: 1.151928, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315049, G loss: 1.302783, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4029, G loss: 0.7183\n",
      "[84/1762] D loss: 1.6621, G loss: 0.3198\n",
      "[164/1762] D loss: 1.1784, G loss: 2.9334\n",
      "[244/1762] D loss: 1.4293, G loss: 0.8552\n",
      "[324/1762] D loss: 1.3946, G loss: 0.7091\n",
      "[404/1762] D loss: 1.4035, G loss: 0.7828\n",
      "[484/1762] D loss: 1.3910, G loss: 0.7054\n",
      "[564/1762] D loss: 1.4021, G loss: 0.5912\n",
      "[644/1762] D loss: 1.2067, G loss: 1.4203\n",
      "[724/1762] D loss: 1.3975, G loss: 0.8014\n",
      "[804/1762] D loss: 0.7527, G loss: 4.7435\n",
      "[884/1762] D loss: 1.4332, G loss: 0.5581\n",
      "[964/1762] D loss: 1.7386, G loss: 1.2569\n",
      "[1044/1762] D loss: 0.0692, G loss: 9.1628\n",
      "[1124/1762] D loss: 1.4100, G loss: 0.6016\n",
      "[1204/1762] D loss: 1.3935, G loss: 0.6595\n",
      "[1284/1762] D loss: 1.3123, G loss: 0.8243\n",
      "[1364/1762] D loss: 0.1037, G loss: 9.2996\n",
      "[1444/1762] D loss: 0.1235, G loss: 15.3566\n",
      "[1524/1762] D loss: 0.0983, G loss: 3.8942\n",
      "[1604/1762] D loss: 1.4245, G loss: 0.7948\n",
      "[1684/1762] D loss: 0.9701, G loss: 0.6250\n",
      "[1762/1762] D loss: 1.4579, G loss: 0.8948\n",
      "train error: \n",
      " D loss: 1.340407, G loss: 1.036379, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302127, G loss: 1.246055, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2115, G loss: 4.0194\n",
      "[84/1762] D loss: 1.3974, G loss: 0.7509\n",
      "[164/1762] D loss: 1.2637, G loss: 0.9980\n",
      "[244/1762] D loss: 1.4368, G loss: 1.0961\n",
      "[324/1762] D loss: 1.4533, G loss: 0.9310\n",
      "[404/1762] D loss: 1.4214, G loss: 0.5263\n",
      "[484/1762] D loss: 0.0289, G loss: 9.8420\n",
      "[564/1762] D loss: 1.4080, G loss: 0.8562\n",
      "[644/1762] D loss: 1.4110, G loss: 0.6147\n",
      "[724/1762] D loss: 0.0267, G loss: 8.3098\n",
      "[804/1762] D loss: 1.5479, G loss: 1.2150\n",
      "[884/1762] D loss: 1.4401, G loss: 1.4363\n",
      "[964/1762] D loss: 1.4044, G loss: 0.5871\n",
      "[1044/1762] D loss: 1.5385, G loss: 0.9855\n",
      "[1124/1762] D loss: 1.4136, G loss: 0.4804\n",
      "[1204/1762] D loss: 1.4207, G loss: 0.5472\n",
      "[1284/1762] D loss: 1.4349, G loss: 0.5237\n",
      "[1364/1762] D loss: 1.4007, G loss: 0.6320\n",
      "[1444/1762] D loss: 1.4239, G loss: 1.1278\n",
      "[1524/1762] D loss: 0.0487, G loss: 4.9167\n",
      "[1604/1762] D loss: 1.5021, G loss: 0.9953\n",
      "[1684/1762] D loss: 1.3992, G loss: 0.7876\n",
      "[1762/1762] D loss: 1.4379, G loss: 0.8906\n",
      "train error: \n",
      " D loss: 1.347990, G loss: 1.005691, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319024, G loss: 1.103595, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4541, G loss: 0.8307\n",
      "[84/1762] D loss: 0.0231, G loss: 5.8949\n",
      "[164/1762] D loss: 1.4157, G loss: 0.5982\n",
      "[244/1762] D loss: 1.4053, G loss: 0.7237\n",
      "[324/1762] D loss: 1.4168, G loss: 0.8815\n",
      "[404/1762] D loss: 0.0685, G loss: 4.2897\n",
      "[484/1762] D loss: 1.3966, G loss: 0.7655\n",
      "[564/1762] D loss: 1.7052, G loss: 0.8635\n",
      "[644/1762] D loss: 1.1782, G loss: 0.7915\n",
      "[724/1762] D loss: 1.0757, G loss: 1.3272\n",
      "[804/1762] D loss: 0.9049, G loss: 3.5782\n",
      "[884/1762] D loss: 1.4151, G loss: 0.6028\n",
      "[964/1762] D loss: 1.4336, G loss: 0.4981\n",
      "[1044/1762] D loss: 1.3964, G loss: 0.8307\n",
      "[1124/1762] D loss: 1.3086, G loss: 1.1404\n",
      "[1204/1762] D loss: 0.3817, G loss: 2.6099\n",
      "[1284/1762] D loss: 1.4082, G loss: 0.6279\n",
      "[1364/1762] D loss: 1.4154, G loss: 0.7870\n",
      "[1444/1762] D loss: 1.5922, G loss: 1.0563\n",
      "[1524/1762] D loss: 1.4045, G loss: 0.7228\n",
      "[1604/1762] D loss: 1.4484, G loss: 0.8603\n",
      "[1684/1762] D loss: 1.4253, G loss: 0.8145\n",
      "[1762/1762] D loss: 1.4194, G loss: 0.7687\n",
      "train error: \n",
      " D loss: 1.580301, G loss: 0.810809, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.528797, G loss: 1.000643, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4414, G loss: 2.7486\n",
      "[84/1762] D loss: 1.4537, G loss: 0.4621\n",
      "[164/1762] D loss: 1.4150, G loss: 0.7695\n",
      "[244/1762] D loss: 0.3355, G loss: 2.6165\n",
      "[324/1762] D loss: 0.1295, G loss: 3.3254\n",
      "[404/1762] D loss: 0.2642, G loss: 2.0368\n",
      "[484/1762] D loss: 1.3992, G loss: 0.8244\n",
      "[564/1762] D loss: 1.4086, G loss: 0.7973\n",
      "[644/1762] D loss: 0.6300, G loss: 0.9688\n",
      "[724/1762] D loss: 0.3665, G loss: 1.3971\n",
      "[804/1762] D loss: 0.3050, G loss: 2.4744\n",
      "[884/1762] D loss: 1.3919, G loss: 0.6829\n",
      "[964/1762] D loss: 1.3886, G loss: 0.6884\n",
      "[1044/1762] D loss: 1.3934, G loss: 0.7385\n",
      "[1124/1762] D loss: 0.2152, G loss: 3.3853\n",
      "[1204/1762] D loss: 0.1598, G loss: 3.2270\n",
      "[1284/1762] D loss: 1.4151, G loss: 0.8777\n",
      "[1364/1762] D loss: 1.4138, G loss: 0.7687\n",
      "[1444/1762] D loss: 0.3218, G loss: 1.7317\n",
      "[1524/1762] D loss: 1.4161, G loss: 0.7239\n",
      "[1604/1762] D loss: 1.4483, G loss: 0.4672\n",
      "[1684/1762] D loss: 0.2401, G loss: 2.6224\n",
      "[1762/1762] D loss: 1.4005, G loss: 0.6656\n",
      "train error: \n",
      " D loss: 1.316525, G loss: 1.031935, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288436, G loss: 1.209632, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3900, G loss: 0.7139\n",
      "[84/1762] D loss: 1.3938, G loss: 0.7672\n",
      "[164/1762] D loss: 1.3838, G loss: 0.8010\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6434\n",
      "[324/1762] D loss: 1.3943, G loss: 0.6132\n",
      "[404/1762] D loss: 0.1712, G loss: 3.6317\n",
      "[484/1762] D loss: 1.4216, G loss: 0.9010\n",
      "[564/1762] D loss: 1.5312, G loss: 0.9403\n",
      "[644/1762] D loss: 0.4703, G loss: 1.1197\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7171\n",
      "[804/1762] D loss: 1.5380, G loss: 1.3094\n",
      "[884/1762] D loss: 1.4265, G loss: 0.5648\n",
      "[964/1762] D loss: 1.3087, G loss: 0.9014\n",
      "[1044/1762] D loss: 0.2393, G loss: 3.9820\n",
      "[1124/1762] D loss: 1.1410, G loss: 2.4796\n",
      "[1204/1762] D loss: 1.4291, G loss: 0.7039\n",
      "[1284/1762] D loss: 1.4344, G loss: 0.7683\n",
      "[1364/1762] D loss: 1.4148, G loss: 0.5880\n",
      "[1444/1762] D loss: 1.4431, G loss: 0.5894\n",
      "[1524/1762] D loss: 1.4007, G loss: 0.6911\n",
      "[1604/1762] D loss: 0.5481, G loss: 1.1418\n",
      "[1684/1762] D loss: 1.4526, G loss: 0.9371\n",
      "[1762/1762] D loss: 1.2051, G loss: 0.8545\n",
      "train error: \n",
      " D loss: 1.488710, G loss: 0.832823, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.443638, G loss: 0.806017, D accuracy: 56.5%, cell accuracy: 99.4%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4182, G loss: 0.5542\n",
      "[84/1762] D loss: 1.4144, G loss: 0.7596\n",
      "[164/1762] D loss: 1.4134, G loss: 0.8993\n",
      "[244/1762] D loss: 0.4923, G loss: 1.5899\n",
      "[324/1762] D loss: 1.1612, G loss: 0.8647\n",
      "[404/1762] D loss: 1.4456, G loss: 0.9094\n",
      "[484/1762] D loss: 1.4067, G loss: 0.8420\n",
      "[564/1762] D loss: 1.4508, G loss: 0.8670\n",
      "[644/1762] D loss: 1.3888, G loss: 0.5868\n",
      "[724/1762] D loss: 1.2935, G loss: 0.9414\n",
      "[804/1762] D loss: 1.4194, G loss: 0.8750\n",
      "[884/1762] D loss: 1.3959, G loss: 0.6756\n",
      "[964/1762] D loss: 1.4055, G loss: 0.7555\n",
      "[1044/1762] D loss: 1.4148, G loss: 0.8957\n",
      "[1124/1762] D loss: 1.4028, G loss: 0.7407\n",
      "[1204/1762] D loss: 1.4639, G loss: 0.8669\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6791\n",
      "[1364/1762] D loss: 1.4238, G loss: 0.8686\n",
      "[1444/1762] D loss: 1.4035, G loss: 0.7812\n",
      "[1524/1762] D loss: 1.4989, G loss: 1.0107\n",
      "[1604/1762] D loss: 1.4107, G loss: 0.8577\n",
      "[1684/1762] D loss: 0.0790, G loss: 5.7893\n",
      "[1762/1762] D loss: 1.4884, G loss: 1.0559\n",
      "train error: \n",
      " D loss: 1.476097, G loss: 1.000831, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.453282, G loss: 1.242525, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1525, G loss: 6.0228\n",
      "[84/1762] D loss: 0.0144, G loss: 13.3989\n",
      "[164/1762] D loss: 1.4759, G loss: 0.9096\n",
      "[244/1762] D loss: 1.3969, G loss: 0.6318\n",
      "[324/1762] D loss: 1.4061, G loss: 0.7457\n",
      "[404/1762] D loss: 1.3993, G loss: 0.7585\n",
      "[484/1762] D loss: 1.4133, G loss: 0.6373\n",
      "[564/1762] D loss: 1.4083, G loss: 0.6139\n",
      "[644/1762] D loss: 1.4000, G loss: 0.6903\n",
      "[724/1762] D loss: 1.4237, G loss: 0.8613\n",
      "[804/1762] D loss: 0.0516, G loss: 4.4502\n",
      "[884/1762] D loss: 1.4382, G loss: 0.5562\n",
      "[964/1762] D loss: 0.1821, G loss: 4.8814\n",
      "[1044/1762] D loss: 1.4073, G loss: 0.6630\n",
      "[1124/1762] D loss: 0.0431, G loss: 7.9340\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.6906\n",
      "[1284/1762] D loss: 1.4098, G loss: 0.5917\n",
      "[1364/1762] D loss: 1.4878, G loss: 0.4463\n",
      "[1444/1762] D loss: 1.5259, G loss: 0.4825\n",
      "[1524/1762] D loss: 1.4062, G loss: 0.6692\n",
      "[1604/1762] D loss: 1.4177, G loss: 0.7763\n",
      "[1684/1762] D loss: 0.0124, G loss: 6.0336\n",
      "[1762/1762] D loss: 1.4259, G loss: 0.8947\n",
      "train error: \n",
      " D loss: 1.638593, G loss: 0.835726, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.600679, G loss: 1.018655, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8648, G loss: 0.9337\n",
      "[84/1762] D loss: 1.4249, G loss: 0.8835\n",
      "[164/1762] D loss: 1.4045, G loss: 0.8109\n",
      "[244/1762] D loss: 0.1605, G loss: 4.8245\n",
      "[324/1762] D loss: 1.4170, G loss: 0.6709\n",
      "[404/1762] D loss: 0.2832, G loss: 4.2508\n",
      "[484/1762] D loss: 1.6093, G loss: 1.0170\n",
      "[564/1762] D loss: 0.1672, G loss: 2.4569\n",
      "[644/1762] D loss: 1.2931, G loss: 0.8011\n",
      "[724/1762] D loss: 1.3947, G loss: 0.5696\n",
      "[804/1762] D loss: 1.4348, G loss: 0.6142\n",
      "[884/1762] D loss: 1.4087, G loss: 0.6418\n",
      "[964/1762] D loss: 1.4092, G loss: 0.6256\n",
      "[1044/1762] D loss: 1.4208, G loss: 0.9232\n",
      "[1124/1762] D loss: 1.4142, G loss: 0.6206\n",
      "[1204/1762] D loss: 0.3259, G loss: 3.7559\n",
      "[1284/1762] D loss: 0.1950, G loss: 4.0642\n",
      "[1364/1762] D loss: 1.3955, G loss: 0.7611\n",
      "[1444/1762] D loss: 0.2266, G loss: 4.1422\n",
      "[1524/1762] D loss: 1.4148, G loss: 0.8630\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.6028\n",
      "[1684/1762] D loss: 0.2351, G loss: 3.1878\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7050\n",
      "train error: \n",
      " D loss: 1.320339, G loss: 1.330031, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291012, G loss: 1.569797, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2189, G loss: 2.7770\n",
      "[84/1762] D loss: 1.3963, G loss: 0.7233\n",
      "[164/1762] D loss: 1.4025, G loss: 0.7284\n",
      "[244/1762] D loss: 0.1460, G loss: 3.8257\n",
      "[324/1762] D loss: 1.4724, G loss: 0.9321\n",
      "[404/1762] D loss: 1.3968, G loss: 0.6362\n",
      "[484/1762] D loss: 1.4119, G loss: 0.5523\n",
      "[564/1762] D loss: 1.4003, G loss: 0.7489\n",
      "[644/1762] D loss: 1.4271, G loss: 0.9011\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6431\n",
      "[804/1762] D loss: 1.4610, G loss: 0.9577\n",
      "[884/1762] D loss: 0.0090, G loss: 6.9093\n",
      "[964/1762] D loss: 1.4085, G loss: 0.9274\n",
      "[1044/1762] D loss: 1.4089, G loss: 0.8939\n",
      "[1124/1762] D loss: 1.3581, G loss: 0.8691\n",
      "[1204/1762] D loss: 1.3967, G loss: 0.6605\n",
      "[1284/1762] D loss: 1.4020, G loss: 0.7777\n",
      "[1364/1762] D loss: 1.3918, G loss: 0.6969\n",
      "[1444/1762] D loss: 1.4217, G loss: 0.9481\n",
      "[1524/1762] D loss: 1.4705, G loss: 0.8964\n",
      "[1604/1762] D loss: 0.2502, G loss: 2.8121\n",
      "[1684/1762] D loss: 1.4011, G loss: 0.7470\n",
      "[1762/1762] D loss: 1.4033, G loss: 0.8596\n",
      "train error: \n",
      " D loss: 1.375363, G loss: 1.047647, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352501, G loss: 1.192810, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3727, G loss: 1.3599\n",
      "[84/1762] D loss: 1.4194, G loss: 0.7429\n",
      "[164/1762] D loss: 1.4047, G loss: 0.5566\n",
      "[244/1762] D loss: 0.2455, G loss: 4.6203\n",
      "[324/1762] D loss: 0.1740, G loss: 4.3058\n",
      "[404/1762] D loss: 1.3891, G loss: 0.6834\n",
      "[484/1762] D loss: 1.4286, G loss: 0.5376\n",
      "[564/1762] D loss: 1.4778, G loss: 0.9266\n",
      "[644/1762] D loss: 1.4626, G loss: 0.4066\n",
      "[724/1762] D loss: 1.0032, G loss: 2.8231\n",
      "[804/1762] D loss: 1.5817, G loss: 0.5639\n",
      "[884/1762] D loss: 1.5863, G loss: 1.0379\n",
      "[964/1762] D loss: 1.5745, G loss: 0.8950\n",
      "[1044/1762] D loss: 0.5223, G loss: 1.2032\n",
      "[1124/1762] D loss: 1.5310, G loss: 1.2176\n",
      "[1204/1762] D loss: 1.3918, G loss: 0.7232\n",
      "[1284/1762] D loss: 1.4038, G loss: 0.7583\n",
      "[1364/1762] D loss: 0.5630, G loss: 0.9313\n",
      "[1444/1762] D loss: 1.4435, G loss: 0.8753\n",
      "[1524/1762] D loss: 0.1598, G loss: 3.0255\n",
      "[1604/1762] D loss: 1.4027, G loss: 0.7685\n",
      "[1684/1762] D loss: 1.4410, G loss: 0.9262\n",
      "[1762/1762] D loss: 1.3935, G loss: 0.7381\n",
      "train error: \n",
      " D loss: 1.320439, G loss: 0.850109, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293989, G loss: 0.899795, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4099, G loss: 0.5943\n",
      "[84/1762] D loss: 0.2064, G loss: 2.4865\n",
      "[164/1762] D loss: 1.4388, G loss: 0.9232\n",
      "[244/1762] D loss: 1.3964, G loss: 0.5772\n",
      "[324/1762] D loss: 1.4002, G loss: 0.6280\n",
      "[404/1762] D loss: 1.4085, G loss: 0.8073\n",
      "[484/1762] D loss: 1.4578, G loss: 0.5028\n",
      "[564/1762] D loss: 1.4078, G loss: 0.7935\n",
      "[644/1762] D loss: 1.4279, G loss: 0.8794\n",
      "[724/1762] D loss: 0.0934, G loss: 4.0192\n",
      "[804/1762] D loss: 1.4228, G loss: 0.8327\n",
      "[884/1762] D loss: 0.0996, G loss: 4.2109\n",
      "[964/1762] D loss: 1.4252, G loss: 0.7217\n",
      "[1044/1762] D loss: 1.3906, G loss: 0.6537\n",
      "[1124/1762] D loss: 1.4653, G loss: 0.9229\n",
      "[1204/1762] D loss: 1.2425, G loss: 3.3984\n",
      "[1284/1762] D loss: 0.8006, G loss: 2.8771\n",
      "[1364/1762] D loss: 1.4711, G loss: 0.5340\n",
      "[1444/1762] D loss: 1.4095, G loss: 0.8048\n",
      "[1524/1762] D loss: 0.1293, G loss: 6.7818\n",
      "[1604/1762] D loss: 1.2137, G loss: 0.7186\n",
      "[1684/1762] D loss: 0.2193, G loss: 2.1568\n",
      "[1762/1762] D loss: 0.0106, G loss: 6.0822\n",
      "train error: \n",
      " D loss: 1.514502, G loss: 0.678212, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.469880, G loss: 0.750408, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2458, G loss: 2.1612\n",
      "[84/1762] D loss: 1.3884, G loss: 0.7126\n",
      "[164/1762] D loss: 1.4098, G loss: 0.7374\n",
      "[244/1762] D loss: 0.1333, G loss: 3.6806\n",
      "[324/1762] D loss: 0.0272, G loss: 4.7084\n",
      "[404/1762] D loss: 1.3436, G loss: 1.5196\n",
      "[484/1762] D loss: 1.3976, G loss: 0.7077\n",
      "[564/1762] D loss: 1.4074, G loss: 0.7741\n",
      "[644/1762] D loss: 1.4090, G loss: 0.6705\n",
      "[724/1762] D loss: 1.3922, G loss: 3.5859\n",
      "[804/1762] D loss: 1.4322, G loss: 1.6914\n",
      "[884/1762] D loss: 0.6083, G loss: 2.8095\n",
      "[964/1762] D loss: 1.0944, G loss: 1.0239\n",
      "[1044/1762] D loss: 0.0005, G loss: 13.4252\n",
      "[1124/1762] D loss: 1.0092, G loss: 1.0078\n",
      "[1204/1762] D loss: 0.2959, G loss: 5.4741\n",
      "[1284/1762] D loss: 0.5758, G loss: 3.3568\n",
      "[1364/1762] D loss: 1.5065, G loss: 0.7580\n",
      "[1444/1762] D loss: 1.4110, G loss: 0.6797\n",
      "[1524/1762] D loss: 1.3794, G loss: 0.7162\n",
      "[1604/1762] D loss: 1.4437, G loss: 1.0799\n",
      "[1684/1762] D loss: 1.4151, G loss: 0.7638\n",
      "[1762/1762] D loss: 1.4700, G loss: 0.4463\n",
      "train error: \n",
      " D loss: 1.320761, G loss: 0.826860, D accuracy: 59.0%, cell accuracy: 99.6%, board accuracy: 72.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283760, G loss: 0.936431, D accuracy: 60.6%, cell accuracy: 99.6%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3666, G loss: 2.6697\n",
      "[84/1762] D loss: 1.4013, G loss: 0.6747\n",
      "[164/1762] D loss: 1.4018, G loss: 0.7110\n",
      "[244/1762] D loss: 1.4233, G loss: 0.6140\n",
      "[324/1762] D loss: 1.3923, G loss: 0.7039\n",
      "[404/1762] D loss: 0.1380, G loss: 4.1561\n",
      "[484/1762] D loss: 0.0495, G loss: 3.2858\n",
      "[564/1762] D loss: 0.2675, G loss: 3.1168\n",
      "[644/1762] D loss: 1.4406, G loss: 0.5687\n",
      "[724/1762] D loss: 1.4062, G loss: 0.5580\n",
      "[804/1762] D loss: 0.1008, G loss: 4.8919\n",
      "[884/1762] D loss: 1.4247, G loss: 0.8992\n",
      "[964/1762] D loss: 1.4987, G loss: 0.9097\n",
      "[1044/1762] D loss: 1.5302, G loss: 0.6829\n",
      "[1124/1762] D loss: 1.2421, G loss: 1.6619\n",
      "[1204/1762] D loss: 1.4150, G loss: 0.5399\n",
      "[1284/1762] D loss: 1.4101, G loss: 0.7900\n",
      "[1364/1762] D loss: 0.2234, G loss: 2.0502\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.6985\n",
      "[1524/1762] D loss: 0.0272, G loss: 4.8976\n",
      "[1604/1762] D loss: 1.4215, G loss: 0.8481\n",
      "[1684/1762] D loss: 1.3931, G loss: 0.7499\n",
      "[1762/1762] D loss: 0.0019, G loss: 12.1967\n",
      "train error: \n",
      " D loss: 3.216437, G loss: 0.247617, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.133124, G loss: 0.343002, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4149, G loss: 0.5551\n",
      "[84/1762] D loss: 1.3973, G loss: 0.6621\n",
      "[164/1762] D loss: 1.4107, G loss: 0.5995\n",
      "[244/1762] D loss: 1.3910, G loss: 0.7464\n",
      "[324/1762] D loss: 1.4046, G loss: 0.7617\n",
      "[404/1762] D loss: 1.4609, G loss: 0.9299\n",
      "[484/1762] D loss: 1.5739, G loss: 0.8906\n",
      "[564/1762] D loss: 1.4220, G loss: 0.5838\n",
      "[644/1762] D loss: 0.1467, G loss: 4.5794\n",
      "[724/1762] D loss: 0.2448, G loss: 3.3527\n",
      "[804/1762] D loss: 0.3920, G loss: 2.6792\n",
      "[884/1762] D loss: 1.3777, G loss: 0.6433\n",
      "[964/1762] D loss: 1.3911, G loss: 0.7641\n",
      "[1044/1762] D loss: 1.3407, G loss: 0.7176\n",
      "[1124/1762] D loss: 0.6069, G loss: 0.8966\n",
      "[1204/1762] D loss: 1.4214, G loss: 0.8851\n",
      "[1284/1762] D loss: 1.3727, G loss: 0.6508\n",
      "[1364/1762] D loss: 1.3804, G loss: 0.8442\n",
      "[1444/1762] D loss: 1.3819, G loss: 0.5627\n",
      "[1524/1762] D loss: 0.2459, G loss: 2.9064\n",
      "[1604/1762] D loss: 0.1160, G loss: 5.7394\n",
      "[1684/1762] D loss: 1.4114, G loss: 0.6171\n",
      "[1762/1762] D loss: 1.3906, G loss: 0.7465\n",
      "train error: \n",
      " D loss: 1.812417, G loss: 0.932684, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.933628, G loss: 1.019319, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1858, G loss: 2.9248\n",
      "[84/1762] D loss: 1.3946, G loss: 0.7410\n",
      "[164/1762] D loss: 1.3917, G loss: 0.6991\n",
      "[244/1762] D loss: 0.0043, G loss: 8.2018\n",
      "[324/1762] D loss: 0.1057, G loss: 2.8988\n",
      "[404/1762] D loss: 0.0662, G loss: 5.1855\n",
      "[484/1762] D loss: 1.3980, G loss: 0.6611\n",
      "[564/1762] D loss: 1.3943, G loss: 0.6523\n",
      "[644/1762] D loss: 1.4040, G loss: 0.7506\n",
      "[724/1762] D loss: 1.4283, G loss: 0.7025\n",
      "[804/1762] D loss: 1.4035, G loss: 0.6325\n",
      "[884/1762] D loss: 1.4995, G loss: 0.9723\n",
      "[964/1762] D loss: 1.3921, G loss: 0.6941\n",
      "[1044/1762] D loss: 1.4074, G loss: 0.5992\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.6678\n",
      "[1204/1762] D loss: 1.5626, G loss: 0.9476\n",
      "[1284/1762] D loss: 1.4143, G loss: 0.6119\n",
      "[1364/1762] D loss: 1.4103, G loss: 0.8130\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.6727\n",
      "[1524/1762] D loss: 1.3982, G loss: 0.7537\n",
      "[1604/1762] D loss: 0.2239, G loss: 3.1590\n",
      "[1684/1762] D loss: 1.3306, G loss: 0.9207\n",
      "[1762/1762] D loss: 0.0022, G loss: 7.1200\n",
      "train error: \n",
      " D loss: 5.995848, G loss: 0.171247, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 5.862503, G loss: 0.243499, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0836, G loss: 5.0406\n",
      "[84/1762] D loss: 1.2685, G loss: 1.0304\n",
      "[164/1762] D loss: 1.4374, G loss: 0.9394\n",
      "[244/1762] D loss: 1.2673, G loss: 0.7888\n",
      "[324/1762] D loss: 1.3778, G loss: 0.5770\n",
      "[404/1762] D loss: 1.2633, G loss: 0.7990\n",
      "[484/1762] D loss: 1.3899, G loss: 0.7182\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6591\n",
      "[644/1762] D loss: 1.4201, G loss: 0.7141\n",
      "[724/1762] D loss: 1.3899, G loss: 0.7579\n",
      "[804/1762] D loss: 1.3924, G loss: 0.6712\n",
      "[884/1762] D loss: 1.0472, G loss: 1.5571\n",
      "[964/1762] D loss: 1.4182, G loss: 0.5291\n",
      "[1044/1762] D loss: 1.1767, G loss: 0.6901\n",
      "[1124/1762] D loss: 1.4925, G loss: 0.8932\n",
      "[1204/1762] D loss: 0.2727, G loss: 3.6695\n",
      "[1284/1762] D loss: 0.7715, G loss: 2.0935\n",
      "[1364/1762] D loss: 0.0045, G loss: 6.1848\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.7782\n",
      "[1524/1762] D loss: 1.1822, G loss: 1.0142\n",
      "[1604/1762] D loss: 0.7128, G loss: 7.3752\n",
      "[1684/1762] D loss: 1.3844, G loss: 0.5598\n",
      "[1762/1762] D loss: 1.6811, G loss: 0.3169\n",
      "train error: \n",
      " D loss: 2.835445, G loss: 2.806354, D accuracy: 47.5%, cell accuracy: 98.8%, board accuracy: 70.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.915118, G loss: 2.936542, D accuracy: 47.7%, cell accuracy: 98.9%, board accuracy: 67.7% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5887, G loss: 0.3797\n",
      "[84/1762] D loss: 1.4921, G loss: 0.4487\n",
      "[164/1762] D loss: 0.0024, G loss: 7.7640\n",
      "[244/1762] D loss: 1.4178, G loss: 0.5783\n",
      "[324/1762] D loss: 0.0109, G loss: 5.7469\n",
      "[404/1762] D loss: 1.5998, G loss: 0.3665\n",
      "[484/1762] D loss: 1.3981, G loss: 0.7095\n",
      "[564/1762] D loss: 1.3938, G loss: 0.5800\n",
      "[644/1762] D loss: 0.1940, G loss: 2.5611\n",
      "[724/1762] D loss: 0.2398, G loss: 3.8266\n",
      "[804/1762] D loss: 0.0694, G loss: 4.5433\n",
      "[884/1762] D loss: 1.2842, G loss: 0.8512\n",
      "[964/1762] D loss: 1.3221, G loss: 0.7011\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.7157\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.5934\n",
      "[1204/1762] D loss: 1.4014, G loss: 0.6184\n",
      "[1284/1762] D loss: 0.0566, G loss: 7.1166\n",
      "[1364/1762] D loss: 0.1755, G loss: 3.7371\n",
      "[1444/1762] D loss: 1.3290, G loss: 0.5369\n",
      "[1524/1762] D loss: 0.1786, G loss: 4.0425\n",
      "[1604/1762] D loss: 0.0567, G loss: 5.6816\n",
      "[1684/1762] D loss: 0.3754, G loss: 3.4023\n",
      "[1762/1762] D loss: 0.0201, G loss: 11.1901\n",
      "train error: \n",
      " D loss: 1.962078, G loss: 0.390097, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.005004, G loss: 0.438211, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4614, G loss: 1.0668\n",
      "[84/1762] D loss: 1.3792, G loss: 0.6375\n",
      "[164/1762] D loss: 1.4020, G loss: 0.6212\n",
      "[244/1762] D loss: 0.0854, G loss: 3.3580\n",
      "[324/1762] D loss: 0.0008, G loss: 9.4289\n",
      "[404/1762] D loss: 0.1749, G loss: 3.5585\n",
      "[484/1762] D loss: 1.3904, G loss: 0.7776\n",
      "[564/1762] D loss: 1.0728, G loss: 3.6673\n",
      "[644/1762] D loss: 1.4019, G loss: 0.5747\n",
      "[724/1762] D loss: 1.4116, G loss: 0.6657\n",
      "[804/1762] D loss: 1.4002, G loss: 0.6950\n",
      "[884/1762] D loss: 1.3972, G loss: 0.7211\n",
      "[964/1762] D loss: 1.3372, G loss: 0.6671\n",
      "[1044/1762] D loss: 1.3964, G loss: 0.6202\n",
      "[1124/1762] D loss: 0.0052, G loss: 6.3559\n",
      "[1204/1762] D loss: 1.0536, G loss: 1.2508\n",
      "[1284/1762] D loss: 1.4032, G loss: 0.7948\n",
      "[1364/1762] D loss: 0.0021, G loss: 6.7725\n",
      "[1444/1762] D loss: 1.4178, G loss: 0.5365\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.7338\n",
      "[1604/1762] D loss: 0.4185, G loss: 1.2752\n",
      "[1684/1762] D loss: 0.0980, G loss: 7.1113\n",
      "[1762/1762] D loss: 0.0012, G loss: 11.3944\n",
      "train error: \n",
      " D loss: 3.187750, G loss: 0.580232, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 3.242585, G loss: 0.693385, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0126, G loss: 6.3722\n",
      "[84/1762] D loss: 1.4695, G loss: 0.4239\n",
      "[164/1762] D loss: 1.3265, G loss: 0.7867\n",
      "[244/1762] D loss: 0.1374, G loss: 4.0407\n",
      "[324/1762] D loss: 0.9694, G loss: 1.2868\n",
      "[404/1762] D loss: 0.0299, G loss: 4.7658\n",
      "[484/1762] D loss: 1.4111, G loss: 0.5815\n",
      "[564/1762] D loss: 1.4092, G loss: 0.5543\n",
      "[644/1762] D loss: 0.0027, G loss: 8.4918\n",
      "[724/1762] D loss: 0.2037, G loss: 2.4314\n",
      "[804/1762] D loss: 1.3899, G loss: 0.6706\n",
      "[884/1762] D loss: 1.4050, G loss: 0.8531\n",
      "[964/1762] D loss: 1.3954, G loss: 0.8416\n",
      "[1044/1762] D loss: 1.4762, G loss: 1.0250\n",
      "[1124/1762] D loss: 0.1918, G loss: 3.5367\n",
      "[1204/1762] D loss: 1.3811, G loss: 0.7018\n",
      "[1284/1762] D loss: 0.1003, G loss: 3.3557\n",
      "[1364/1762] D loss: 1.3948, G loss: 0.6607\n",
      "[1444/1762] D loss: 1.4077, G loss: 0.7936\n",
      "[1524/1762] D loss: 1.3643, G loss: 0.5325\n",
      "[1604/1762] D loss: 0.1187, G loss: 4.0095\n",
      "[1684/1762] D loss: 1.4447, G loss: 0.8666\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7068\n",
      "train error: \n",
      " D loss: 1.652395, G loss: 0.779326, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.627055, G loss: 0.957434, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7068\n",
      "[84/1762] D loss: 0.0516, G loss: 4.9181\n",
      "[164/1762] D loss: 1.4302, G loss: 0.8468\n",
      "[244/1762] D loss: 1.3352, G loss: 0.5226\n",
      "[324/1762] D loss: 1.1664, G loss: 0.8129\n",
      "[404/1762] D loss: 1.4392, G loss: 0.8609\n",
      "[484/1762] D loss: 1.4109, G loss: 0.6144\n",
      "[564/1762] D loss: 1.3733, G loss: 0.8859\n",
      "[644/1762] D loss: 1.5128, G loss: 1.0380\n",
      "[724/1762] D loss: 1.3924, G loss: 0.6253\n",
      "[804/1762] D loss: 1.3874, G loss: 0.7062\n",
      "[884/1762] D loss: 1.4219, G loss: 0.8580\n",
      "[964/1762] D loss: 1.3931, G loss: 0.7373\n",
      "[1044/1762] D loss: 1.4052, G loss: 0.7862\n",
      "[1124/1762] D loss: 1.4164, G loss: 0.5666\n",
      "[1204/1762] D loss: 1.3555, G loss: 1.4144\n",
      "[1284/1762] D loss: 1.4241, G loss: 0.8149\n",
      "[1364/1762] D loss: 0.0014, G loss: 13.0270\n",
      "[1444/1762] D loss: 1.3937, G loss: 0.7617\n",
      "[1524/1762] D loss: 1.4756, G loss: 0.8066\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.6482\n",
      "[1684/1762] D loss: 1.4067, G loss: 0.9018\n",
      "[1762/1762] D loss: 1.3899, G loss: 0.6599\n",
      "train error: \n",
      " D loss: 2.036951, G loss: 1.580284, D accuracy: 50.4%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.250279, G loss: 1.720513, D accuracy: 50.7%, cell accuracy: 99.6%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.6902\n",
      "[84/1762] D loss: 0.0697, G loss: 5.1540\n",
      "[164/1762] D loss: 0.0029, G loss: 8.9294\n",
      "[244/1762] D loss: 0.0924, G loss: 6.1767\n",
      "[324/1762] D loss: 1.4219, G loss: 0.5805\n",
      "[404/1762] D loss: 1.4599, G loss: 0.4962\n",
      "[484/1762] D loss: 0.2501, G loss: 3.5264\n",
      "[564/1762] D loss: 1.4013, G loss: 0.5961\n",
      "[644/1762] D loss: 1.3995, G loss: 0.6216\n",
      "[724/1762] D loss: 1.2241, G loss: 0.6874\n",
      "[804/1762] D loss: 1.3919, G loss: 0.6382\n",
      "[884/1762] D loss: 0.0003, G loss: 13.1331\n",
      "[964/1762] D loss: 1.3929, G loss: 0.6963\n",
      "[1044/1762] D loss: 0.0043, G loss: 6.8800\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.7271\n",
      "[1204/1762] D loss: 1.4186, G loss: 0.5541\n",
      "[1284/1762] D loss: 1.3974, G loss: 0.8883\n",
      "[1364/1762] D loss: 1.6445, G loss: 0.9642\n",
      "[1444/1762] D loss: 1.3949, G loss: 0.7145\n",
      "[1524/1762] D loss: 1.4364, G loss: 0.9165\n",
      "[1604/1762] D loss: 1.4290, G loss: 0.8545\n",
      "[1684/1762] D loss: 0.1508, G loss: 2.4564\n",
      "[1762/1762] D loss: 0.0003, G loss: 11.9178\n",
      "train error: \n",
      " D loss: 1.448033, G loss: 0.752130, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.430155, G loss: 0.860938, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4616, G loss: 1.2054\n",
      "[84/1762] D loss: 0.0532, G loss: 5.2593\n",
      "[164/1762] D loss: 1.4246, G loss: 0.5312\n",
      "[244/1762] D loss: 1.5097, G loss: 0.6254\n",
      "[324/1762] D loss: 0.0339, G loss: 9.3976\n",
      "[404/1762] D loss: 0.1293, G loss: 2.6318\n",
      "[484/1762] D loss: 1.4318, G loss: 0.5569\n",
      "[564/1762] D loss: 1.3907, G loss: 0.6809\n",
      "[644/1762] D loss: 1.4394, G loss: 0.4615\n",
      "[724/1762] D loss: 1.4175, G loss: 0.5765\n",
      "[804/1762] D loss: 1.3954, G loss: 0.6780\n",
      "[884/1762] D loss: 0.0018, G loss: 14.6312\n",
      "[964/1762] D loss: 1.3973, G loss: 0.6409\n",
      "[1044/1762] D loss: 1.3999, G loss: 0.6672\n",
      "[1124/1762] D loss: 1.3933, G loss: 0.7260\n",
      "[1204/1762] D loss: 1.3816, G loss: 0.8812\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.6811\n",
      "[1364/1762] D loss: 1.4129, G loss: 0.5624\n",
      "[1444/1762] D loss: 0.0170, G loss: 5.4995\n",
      "[1524/1762] D loss: 5.6873, G loss: 0.5130\n",
      "[1604/1762] D loss: 1.5048, G loss: 0.4905\n",
      "[1684/1762] D loss: 1.4222, G loss: 0.5672\n",
      "[1762/1762] D loss: 1.3912, G loss: 0.7327\n",
      "train error: \n",
      " D loss: 1.328928, G loss: 0.747293, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305935, G loss: 0.785311, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4012, G loss: 0.6425\n",
      "[84/1762] D loss: 1.3944, G loss: 0.6175\n",
      "[164/1762] D loss: 1.3991, G loss: 0.7296\n",
      "[244/1762] D loss: 0.4813, G loss: 1.8106\n",
      "[324/1762] D loss: 1.3893, G loss: 0.6814\n",
      "[404/1762] D loss: 0.2106, G loss: 4.0560\n",
      "[484/1762] D loss: 1.3898, G loss: 0.7686\n",
      "[564/1762] D loss: 1.5774, G loss: 1.0788\n",
      "[644/1762] D loss: 1.4355, G loss: 0.9093\n",
      "[724/1762] D loss: 1.4373, G loss: 0.9779\n",
      "[804/1762] D loss: 0.1110, G loss: 5.1892\n",
      "[884/1762] D loss: 1.3974, G loss: 0.7787\n",
      "[964/1762] D loss: 0.0397, G loss: 9.7410\n",
      "[1044/1762] D loss: 0.2327, G loss: 2.9210\n",
      "[1124/1762] D loss: 1.4687, G loss: 0.8383\n",
      "[1204/1762] D loss: 1.4069, G loss: 0.5825\n",
      "[1284/1762] D loss: 1.4339, G loss: 0.5422\n",
      "[1364/1762] D loss: 1.3942, G loss: 0.6570\n",
      "[1444/1762] D loss: 1.3954, G loss: 0.7061\n",
      "[1524/1762] D loss: 1.4109, G loss: 0.6205\n",
      "[1604/1762] D loss: 0.1701, G loss: 4.4611\n",
      "[1684/1762] D loss: 1.4074, G loss: 0.6263\n",
      "[1762/1762] D loss: 1.3956, G loss: 0.5937\n",
      "train error: \n",
      " D loss: 1.331711, G loss: 0.949040, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302647, G loss: 1.095572, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2295, G loss: 3.2279\n",
      "[84/1762] D loss: 1.3929, G loss: 0.6297\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6922\n",
      "[244/1762] D loss: 0.1537, G loss: 3.3355\n",
      "[324/1762] D loss: 0.0025, G loss: 10.8084\n",
      "[404/1762] D loss: 1.3935, G loss: 0.5887\n",
      "[484/1762] D loss: 1.3948, G loss: 0.7425\n",
      "[564/1762] D loss: 1.3916, G loss: 0.8215\n",
      "[644/1762] D loss: 1.4404, G loss: 0.8440\n",
      "[724/1762] D loss: 1.1641, G loss: 1.4234\n",
      "[804/1762] D loss: 0.2495, G loss: 4.7522\n",
      "[884/1762] D loss: 0.0722, G loss: 2.9778\n",
      "[964/1762] D loss: 1.4135, G loss: 0.7922\n",
      "[1044/1762] D loss: 1.4651, G loss: 1.0048\n",
      "[1124/1762] D loss: 1.3943, G loss: 0.6706\n",
      "[1204/1762] D loss: 1.3935, G loss: 0.6558\n",
      "[1284/1762] D loss: 1.3932, G loss: 0.6997\n",
      "[1364/1762] D loss: 1.3968, G loss: 0.7665\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.5901\n",
      "[1524/1762] D loss: 0.1312, G loss: 3.9929\n",
      "[1604/1762] D loss: 0.1388, G loss: 4.4679\n",
      "[1684/1762] D loss: 1.1524, G loss: 2.0330\n",
      "[1762/1762] D loss: 1.4381, G loss: 0.4752\n",
      "train error: \n",
      " D loss: 1.472093, G loss: 1.312326, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.477592, G loss: 1.476220, D accuracy: 57.2%, cell accuracy: 99.5%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0200, G loss: 9.7255\n",
      "[84/1762] D loss: 1.4098, G loss: 0.5928\n",
      "[164/1762] D loss: 1.4014, G loss: 0.6654\n",
      "[244/1762] D loss: 1.4191, G loss: 0.5780\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6856\n",
      "[404/1762] D loss: 1.3800, G loss: 0.6790\n",
      "[484/1762] D loss: 1.4141, G loss: 0.5400\n",
      "[564/1762] D loss: 0.1488, G loss: 3.8641\n",
      "[644/1762] D loss: 1.4071, G loss: 0.8760\n",
      "[724/1762] D loss: 2.0019, G loss: 1.0405\n",
      "[804/1762] D loss: 0.1083, G loss: 3.7057\n",
      "[884/1762] D loss: 0.2018, G loss: 3.7984\n",
      "[964/1762] D loss: 1.4259, G loss: 0.5978\n",
      "[1044/1762] D loss: 1.4098, G loss: 0.8405\n",
      "[1124/1762] D loss: 0.0017, G loss: 12.8640\n",
      "[1204/1762] D loss: 1.2578, G loss: 0.8966\n",
      "[1284/1762] D loss: 1.4579, G loss: 0.5491\n",
      "[1364/1762] D loss: 1.4038, G loss: 0.6548\n",
      "[1444/1762] D loss: 0.1976, G loss: 3.4865\n",
      "[1524/1762] D loss: 1.2108, G loss: 1.7375\n",
      "[1604/1762] D loss: 1.1272, G loss: 0.8177\n",
      "[1684/1762] D loss: 1.4388, G loss: 0.4971\n",
      "[1762/1762] D loss: 1.4491, G loss: 0.5340\n",
      "train error: \n",
      " D loss: 1.626446, G loss: 0.799706, D accuracy: 54.5%, cell accuracy: 99.5%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.580082, G loss: 0.965721, D accuracy: 55.6%, cell accuracy: 99.4%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3982, G loss: 0.6283\n",
      "[84/1762] D loss: 1.4085, G loss: 0.7039\n",
      "[164/1762] D loss: 1.4282, G loss: 0.5603\n",
      "[244/1762] D loss: 1.4334, G loss: 0.5962\n",
      "[324/1762] D loss: 1.6539, G loss: 1.0095\n",
      "[404/1762] D loss: 1.3895, G loss: 0.7712\n",
      "[484/1762] D loss: 0.1588, G loss: 3.2033\n",
      "[564/1762] D loss: 1.4143, G loss: 0.8206\n",
      "[644/1762] D loss: 1.0588, G loss: 1.9252\n",
      "[724/1762] D loss: 0.0515, G loss: 3.7157\n",
      "[804/1762] D loss: 1.4192, G loss: 0.8538\n",
      "[884/1762] D loss: 1.4119, G loss: 0.5161\n",
      "[964/1762] D loss: 0.1802, G loss: 3.3323\n",
      "[1044/1762] D loss: 1.4179, G loss: 0.8004\n",
      "[1124/1762] D loss: 1.4129, G loss: 0.8342\n",
      "[1204/1762] D loss: 1.3958, G loss: 0.6732\n",
      "[1284/1762] D loss: 1.4353, G loss: 0.9312\n",
      "[1364/1762] D loss: 1.4231, G loss: 0.5372\n",
      "[1444/1762] D loss: 1.3971, G loss: 0.5914\n",
      "[1524/1762] D loss: 1.4012, G loss: 0.5777\n",
      "[1604/1762] D loss: 1.4179, G loss: 0.5287\n",
      "[1684/1762] D loss: 1.4091, G loss: 0.5758\n",
      "[1762/1762] D loss: 1.3959, G loss: 0.6314\n",
      "train error: \n",
      " D loss: 3.228375, G loss: 0.607199, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 3.263475, G loss: 0.793194, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3523, G loss: 0.9089\n",
      "[84/1762] D loss: 1.4048, G loss: 0.7666\n",
      "[164/1762] D loss: 0.1189, G loss: 4.5317\n",
      "[244/1762] D loss: 0.0195, G loss: 5.3407\n",
      "[324/1762] D loss: 1.3905, G loss: 0.7494\n",
      "[404/1762] D loss: 0.2782, G loss: 2.9300\n",
      "[484/1762] D loss: 0.0250, G loss: 4.4217\n",
      "[564/1762] D loss: 0.1429, G loss: 4.0334\n",
      "[644/1762] D loss: 1.4283, G loss: 0.8603\n",
      "[724/1762] D loss: 1.3275, G loss: 0.8005\n",
      "[804/1762] D loss: 1.3656, G loss: 0.8008\n",
      "[884/1762] D loss: 0.0030, G loss: 7.0338\n",
      "[964/1762] D loss: 1.6927, G loss: 0.8175\n",
      "[1044/1762] D loss: 0.3712, G loss: 3.6728\n",
      "[1124/1762] D loss: 1.4195, G loss: 0.5828\n",
      "[1204/1762] D loss: 1.0463, G loss: 1.8607\n",
      "[1284/1762] D loss: 1.4089, G loss: 0.8954\n",
      "[1364/1762] D loss: 1.4465, G loss: 0.9647\n",
      "[1444/1762] D loss: 0.0690, G loss: 4.4788\n",
      "[1524/1762] D loss: 1.3607, G loss: 0.7249\n",
      "[1604/1762] D loss: 1.4277, G loss: 0.9092\n",
      "[1684/1762] D loss: 0.1501, G loss: 3.7333\n",
      "[1762/1762] D loss: 1.3970, G loss: 0.6492\n",
      "train error: \n",
      " D loss: 1.362191, G loss: 1.086459, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327237, G loss: 1.336788, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    train(run_name=\"adam\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam seems to have some significant instability; let's try reducing the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3816, G loss: 0.6912\n",
      "[84/1762] D loss: 1.0127, G loss: 0.9967\n",
      "[164/1762] D loss: 0.6188, G loss: 1.5769\n",
      "[244/1762] D loss: 0.1177, G loss: 3.6155\n",
      "[324/1762] D loss: 0.1746, G loss: 3.0600\n",
      "[404/1762] D loss: 0.1901, G loss: 2.9943\n",
      "[484/1762] D loss: 0.3561, G loss: 3.5213\n",
      "[564/1762] D loss: 0.2798, G loss: 2.6448\n",
      "[644/1762] D loss: 0.1786, G loss: 3.7024\n",
      "[724/1762] D loss: 0.6618, G loss: 1.5532\n",
      "[804/1762] D loss: 1.2984, G loss: 2.0507\n",
      "[884/1762] D loss: 0.7367, G loss: 1.3706\n",
      "[964/1762] D loss: 1.0316, G loss: 1.0764\n",
      "[1044/1762] D loss: 0.6845, G loss: 0.7339\n",
      "[1124/1762] D loss: 1.2141, G loss: 0.5853\n",
      "[1204/1762] D loss: 1.6664, G loss: 1.2998\n",
      "[1284/1762] D loss: 1.2940, G loss: 0.8930\n",
      "[1364/1762] D loss: 1.3494, G loss: 1.6234\n",
      "[1444/1762] D loss: 1.1270, G loss: 0.8822\n",
      "[1524/1762] D loss: 1.0956, G loss: 1.1624\n",
      "[1604/1762] D loss: 1.0677, G loss: 0.6873\n",
      "[1684/1762] D loss: 1.3318, G loss: 0.7817\n",
      "[1762/1762] D loss: 0.2863, G loss: 1.6939\n",
      "train error: \n",
      " D loss: 1.302836, G loss: 0.682379, D accuracy: 58.8%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298974, G loss: 0.707420, D accuracy: 58.9%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0965, G loss: 0.8055\n",
      "[84/1762] D loss: 0.7355, G loss: 1.2520\n",
      "[164/1762] D loss: 1.3448, G loss: 0.7861\n",
      "[244/1762] D loss: 1.3815, G loss: 0.8951\n",
      "[324/1762] D loss: 1.1027, G loss: 1.0910\n",
      "[404/1762] D loss: 1.3669, G loss: 0.7600\n",
      "[484/1762] D loss: 1.4342, G loss: 0.9377\n",
      "[564/1762] D loss: 1.3076, G loss: 0.8720\n",
      "[644/1762] D loss: 0.8307, G loss: 0.9683\n",
      "[724/1762] D loss: 1.1610, G loss: 1.4417\n",
      "[804/1762] D loss: 0.4800, G loss: 1.6541\n",
      "[884/1762] D loss: 0.8219, G loss: 0.9211\n",
      "[964/1762] D loss: 1.4365, G loss: 0.6493\n",
      "[1044/1762] D loss: 1.4145, G loss: 0.5879\n",
      "[1124/1762] D loss: 1.1299, G loss: 1.1092\n",
      "[1204/1762] D loss: 1.3729, G loss: 0.6308\n",
      "[1284/1762] D loss: 1.2635, G loss: 0.7946\n",
      "[1364/1762] D loss: 0.8726, G loss: 2.3336\n",
      "[1444/1762] D loss: 1.5381, G loss: 0.4523\n",
      "[1524/1762] D loss: 1.5154, G loss: 1.1499\n",
      "[1604/1762] D loss: 1.5410, G loss: 0.4464\n",
      "[1684/1762] D loss: 1.4216, G loss: 0.7478\n",
      "[1762/1762] D loss: 1.0014, G loss: 0.9341\n",
      "train error: \n",
      " D loss: 1.333977, G loss: 0.640352, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320704, G loss: 0.645270, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8161, G loss: 0.9059\n",
      "[84/1762] D loss: 1.3951, G loss: 0.8124\n",
      "[164/1762] D loss: 1.4484, G loss: 0.6185\n",
      "[244/1762] D loss: 1.4633, G loss: 0.5036\n",
      "[324/1762] D loss: 0.6790, G loss: 1.7558\n",
      "[404/1762] D loss: 0.7934, G loss: 0.9960\n",
      "[484/1762] D loss: 0.7641, G loss: 1.3530\n",
      "[564/1762] D loss: 0.4948, G loss: 1.2940\n",
      "[644/1762] D loss: 0.8672, G loss: 1.2096\n",
      "[724/1762] D loss: 1.5845, G loss: 1.4697\n",
      "[804/1762] D loss: 1.3262, G loss: 0.6757\n",
      "[884/1762] D loss: 1.3994, G loss: 0.5379\n",
      "[964/1762] D loss: 1.4041, G loss: 0.7967\n",
      "[1044/1762] D loss: 0.6740, G loss: 0.9449\n",
      "[1124/1762] D loss: 1.4500, G loss: 0.8334\n",
      "[1204/1762] D loss: 1.4095, G loss: 0.6886\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.5336\n",
      "[1364/1762] D loss: 1.4601, G loss: 0.6130\n",
      "[1444/1762] D loss: 0.6425, G loss: 1.5398\n",
      "[1524/1762] D loss: 1.5015, G loss: 0.9271\n",
      "[1604/1762] D loss: 1.3977, G loss: 0.7314\n",
      "[1684/1762] D loss: 1.3813, G loss: 0.8409\n",
      "[1762/1762] D loss: 0.2829, G loss: 2.0004\n",
      "train error: \n",
      " D loss: 1.370168, G loss: 0.984394, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352763, G loss: 0.992837, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5670, G loss: 1.5355\n",
      "[84/1762] D loss: 1.4553, G loss: 0.7221\n",
      "[164/1762] D loss: 1.1114, G loss: 1.4307\n",
      "[244/1762] D loss: 1.2103, G loss: 0.5415\n",
      "[324/1762] D loss: 1.4565, G loss: 1.0958\n",
      "[404/1762] D loss: 0.8955, G loss: 0.9796\n",
      "[484/1762] D loss: 1.3015, G loss: 0.6906\n",
      "[564/1762] D loss: 1.5443, G loss: 1.3423\n",
      "[644/1762] D loss: 1.3637, G loss: 0.6246\n",
      "[724/1762] D loss: 1.3896, G loss: 0.7157\n",
      "[804/1762] D loss: 1.3224, G loss: 0.8002\n",
      "[884/1762] D loss: 1.4839, G loss: 1.0268\n",
      "[964/1762] D loss: 0.6943, G loss: 0.8921\n",
      "[1044/1762] D loss: 1.4215, G loss: 0.6901\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.7147\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.6415\n",
      "[1284/1762] D loss: 0.6482, G loss: 1.3311\n",
      "[1364/1762] D loss: 0.5441, G loss: 1.3516\n",
      "[1444/1762] D loss: 1.4027, G loss: 0.6533\n",
      "[1524/1762] D loss: 1.4935, G loss: 0.7079\n",
      "[1604/1762] D loss: 1.3470, G loss: 0.9540\n",
      "[1684/1762] D loss: 0.7708, G loss: 0.9445\n",
      "[1762/1762] D loss: 1.3814, G loss: 0.5868\n",
      "train error: \n",
      " D loss: 1.353887, G loss: 0.843756, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337326, G loss: 0.862987, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4052, G loss: 0.5712\n",
      "[84/1762] D loss: 1.4231, G loss: 0.8933\n",
      "[164/1762] D loss: 1.4884, G loss: 1.2273\n",
      "[244/1762] D loss: 1.5579, G loss: 0.4936\n",
      "[324/1762] D loss: 0.1401, G loss: 2.5682\n",
      "[404/1762] D loss: 1.3420, G loss: 0.8191\n",
      "[484/1762] D loss: 0.4806, G loss: 1.3564\n",
      "[564/1762] D loss: 1.4720, G loss: 0.3950\n",
      "[644/1762] D loss: 1.5303, G loss: 0.8375\n",
      "[724/1762] D loss: 0.7273, G loss: 0.9023\n",
      "[804/1762] D loss: 0.1794, G loss: 1.9770\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6374\n",
      "[964/1762] D loss: 1.4849, G loss: 0.9989\n",
      "[1044/1762] D loss: 1.4525, G loss: 1.2980\n",
      "[1124/1762] D loss: 1.4980, G loss: 0.7790\n",
      "[1204/1762] D loss: 1.2996, G loss: 0.9484\n",
      "[1284/1762] D loss: 0.4989, G loss: 1.2512\n",
      "[1364/1762] D loss: 1.2402, G loss: 1.1248\n",
      "[1444/1762] D loss: 1.0439, G loss: 1.3273\n",
      "[1524/1762] D loss: 1.4235, G loss: 0.7617\n",
      "[1604/1762] D loss: 1.4816, G loss: 0.4405\n",
      "[1684/1762] D loss: 1.2169, G loss: 0.6512\n",
      "[1762/1762] D loss: 1.5046, G loss: 0.7943\n",
      "train error: \n",
      " D loss: 1.340242, G loss: 0.733517, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326229, G loss: 0.744235, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4916, G loss: 0.4328\n",
      "[84/1762] D loss: 1.1745, G loss: 0.7287\n",
      "[164/1762] D loss: 1.4526, G loss: 0.8679\n",
      "[244/1762] D loss: 1.5815, G loss: 0.9485\n",
      "[324/1762] D loss: 1.3880, G loss: 0.8517\n",
      "[404/1762] D loss: 1.4227, G loss: 0.6650\n",
      "[484/1762] D loss: 0.2712, G loss: 2.0954\n",
      "[564/1762] D loss: 1.3395, G loss: 0.8203\n",
      "[644/1762] D loss: 0.6227, G loss: 1.3888\n",
      "[724/1762] D loss: 1.3998, G loss: 0.8255\n",
      "[804/1762] D loss: 0.4347, G loss: 1.4302\n",
      "[884/1762] D loss: 1.2472, G loss: 0.9618\n",
      "[964/1762] D loss: 1.4447, G loss: 0.7933\n",
      "[1044/1762] D loss: 1.4960, G loss: 0.3901\n",
      "[1124/1762] D loss: 1.4158, G loss: 0.8091\n",
      "[1204/1762] D loss: 1.4014, G loss: 0.6985\n",
      "[1284/1762] D loss: 1.4046, G loss: 0.7513\n",
      "[1364/1762] D loss: 0.7051, G loss: 1.0644\n",
      "[1444/1762] D loss: 1.9621, G loss: 1.5460\n",
      "[1524/1762] D loss: 0.2340, G loss: 1.9548\n",
      "[1604/1762] D loss: 0.4242, G loss: 1.2186\n",
      "[1684/1762] D loss: 1.4473, G loss: 1.0392\n",
      "[1762/1762] D loss: 1.5358, G loss: 0.4768\n",
      "train error: \n",
      " D loss: 1.344614, G loss: 0.648764, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329026, G loss: 0.656524, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4360, G loss: 0.9479\n",
      "[84/1762] D loss: 1.5247, G loss: 0.9081\n",
      "[164/1762] D loss: 0.3827, G loss: 1.7140\n",
      "[244/1762] D loss: 0.4208, G loss: 1.1777\n",
      "[324/1762] D loss: 1.3619, G loss: 1.0551\n",
      "[404/1762] D loss: 1.6147, G loss: 0.4241\n",
      "[484/1762] D loss: 1.3117, G loss: 0.9045\n",
      "[564/1762] D loss: 1.3321, G loss: 0.6076\n",
      "[644/1762] D loss: 1.8502, G loss: 1.3683\n",
      "[724/1762] D loss: 1.4143, G loss: 0.6033\n",
      "[804/1762] D loss: 1.4148, G loss: 1.0148\n",
      "[884/1762] D loss: 1.4052, G loss: 0.7572\n",
      "[964/1762] D loss: 0.1379, G loss: 2.4026\n",
      "[1044/1762] D loss: 1.4094, G loss: 0.5062\n",
      "[1124/1762] D loss: 0.3187, G loss: 1.5354\n",
      "[1204/1762] D loss: 1.3950, G loss: 0.7013\n",
      "[1284/1762] D loss: 1.4553, G loss: 0.5324\n",
      "[1364/1762] D loss: 1.3998, G loss: 0.7526\n",
      "[1444/1762] D loss: 1.4192, G loss: 0.4980\n",
      "[1524/1762] D loss: 1.4027, G loss: 0.7682\n",
      "[1604/1762] D loss: 0.3335, G loss: 2.1235\n",
      "[1684/1762] D loss: 1.5986, G loss: 1.1144\n",
      "[1762/1762] D loss: 1.1875, G loss: 1.2634\n",
      "train error: \n",
      " D loss: 1.322910, G loss: 0.713401, D accuracy: 56.0%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309443, G loss: 0.719997, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3539, G loss: 1.3929\n",
      "[84/1762] D loss: 1.0952, G loss: 1.2300\n",
      "[164/1762] D loss: 1.4411, G loss: 0.5653\n",
      "[244/1762] D loss: 1.4694, G loss: 1.0825\n",
      "[324/1762] D loss: 1.3013, G loss: 0.7197\n",
      "[404/1762] D loss: 1.4237, G loss: 0.6489\n",
      "[484/1762] D loss: 1.4090, G loss: 0.5825\n",
      "[564/1762] D loss: 0.2964, G loss: 1.5340\n",
      "[644/1762] D loss: 1.4260, G loss: 0.7789\n",
      "[724/1762] D loss: 0.4186, G loss: 1.2430\n",
      "[804/1762] D loss: 0.2624, G loss: 1.6739\n",
      "[884/1762] D loss: 1.4063, G loss: 0.6218\n",
      "[964/1762] D loss: 1.3946, G loss: 0.7265\n",
      "[1044/1762] D loss: 0.3797, G loss: 1.1608\n",
      "[1124/1762] D loss: 1.4720, G loss: 0.9835\n",
      "[1204/1762] D loss: 1.4646, G loss: 0.8226\n",
      "[1284/1762] D loss: 1.5488, G loss: 0.9520\n",
      "[1364/1762] D loss: 1.3938, G loss: 0.7645\n",
      "[1444/1762] D loss: 0.2798, G loss: 1.6491\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.6191\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.7716\n",
      "[1684/1762] D loss: 0.2743, G loss: 1.6810\n",
      "[1762/1762] D loss: 1.3966, G loss: 0.6327\n",
      "train error: \n",
      " D loss: 1.351592, G loss: 0.621564, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339198, G loss: 0.625553, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4438, G loss: 0.4607\n",
      "[84/1762] D loss: 0.4127, G loss: 1.3021\n",
      "[164/1762] D loss: 0.1901, G loss: 2.1959\n",
      "[244/1762] D loss: 1.4839, G loss: 0.8209\n",
      "[324/1762] D loss: 1.4881, G loss: 0.4542\n",
      "[404/1762] D loss: 1.4263, G loss: 0.8611\n",
      "[484/1762] D loss: 1.4483, G loss: 0.7676\n",
      "[564/1762] D loss: 1.8333, G loss: 1.3018\n",
      "[644/1762] D loss: 1.4609, G loss: 0.7704\n",
      "[724/1762] D loss: 1.5726, G loss: 0.4374\n",
      "[804/1762] D loss: 1.4691, G loss: 1.0274\n",
      "[884/1762] D loss: 1.5047, G loss: 1.1175\n",
      "[964/1762] D loss: 1.4521, G loss: 0.6828\n",
      "[1044/1762] D loss: 1.3964, G loss: 0.5783\n",
      "[1124/1762] D loss: 1.3967, G loss: 0.7596\n",
      "[1204/1762] D loss: 2.3315, G loss: 0.3975\n",
      "[1284/1762] D loss: 0.6269, G loss: 1.6084\n",
      "[1364/1762] D loss: 1.4846, G loss: 0.5330\n",
      "[1444/1762] D loss: 1.5199, G loss: 0.5920\n",
      "[1524/1762] D loss: 0.9438, G loss: 1.1398\n",
      "[1604/1762] D loss: 1.4041, G loss: 0.7351\n",
      "[1684/1762] D loss: 1.3939, G loss: 0.6722\n",
      "[1762/1762] D loss: 1.3058, G loss: 0.8506\n",
      "train error: \n",
      " D loss: 1.352866, G loss: 0.893268, D accuracy: 53.2%, cell accuracy: 99.6%, board accuracy: 47.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342694, G loss: 0.895770, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 41.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7926, G loss: 1.1694\n",
      "[84/1762] D loss: 1.4151, G loss: 0.5741\n",
      "[164/1762] D loss: 0.5724, G loss: 1.3883\n",
      "[244/1762] D loss: 0.6837, G loss: 1.0561\n",
      "[324/1762] D loss: 0.5822, G loss: 1.2856\n",
      "[404/1762] D loss: 0.6268, G loss: 1.0142\n",
      "[484/1762] D loss: 1.4500, G loss: 0.4753\n",
      "[564/1762] D loss: 1.4022, G loss: 0.7254\n",
      "[644/1762] D loss: 1.4113, G loss: 0.6506\n",
      "[724/1762] D loss: 1.2335, G loss: 1.0535\n",
      "[804/1762] D loss: 1.2833, G loss: 0.8901\n",
      "[884/1762] D loss: 1.5791, G loss: 1.8200\n",
      "[964/1762] D loss: 1.4919, G loss: 1.0771\n",
      "[1044/1762] D loss: 0.4737, G loss: 1.3326\n",
      "[1124/1762] D loss: 1.5243, G loss: 1.1068\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.5952\n",
      "[1284/1762] D loss: 0.2315, G loss: 1.8150\n",
      "[1364/1762] D loss: 1.4257, G loss: 0.9219\n",
      "[1444/1762] D loss: 1.4476, G loss: 1.1973\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.8677\n",
      "[1604/1762] D loss: 0.5876, G loss: 0.9589\n",
      "[1684/1762] D loss: 1.6877, G loss: 1.3033\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.6945\n",
      "train error: \n",
      " D loss: 1.335847, G loss: 0.853976, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315221, G loss: 0.860331, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3994, G loss: 1.3185\n",
      "[84/1762] D loss: 0.3710, G loss: 1.3499\n",
      "[164/1762] D loss: 1.3986, G loss: 0.6115\n",
      "[244/1762] D loss: 1.4014, G loss: 0.6747\n",
      "[324/1762] D loss: 0.4629, G loss: 1.1242\n",
      "[404/1762] D loss: 1.3374, G loss: 1.3607\n",
      "[484/1762] D loss: 1.4268, G loss: 0.4920\n",
      "[564/1762] D loss: 0.5610, G loss: 0.9738\n",
      "[644/1762] D loss: 1.4812, G loss: 1.0060\n",
      "[724/1762] D loss: 0.3724, G loss: 1.3903\n",
      "[804/1762] D loss: 1.4334, G loss: 0.8751\n",
      "[884/1762] D loss: 0.3027, G loss: 1.5367\n",
      "[964/1762] D loss: 1.4016, G loss: 0.5847\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6815\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.7172\n",
      "[1204/1762] D loss: 0.8602, G loss: 1.6841\n",
      "[1284/1762] D loss: 1.5827, G loss: 0.4160\n",
      "[1364/1762] D loss: 1.4963, G loss: 0.7735\n",
      "[1444/1762] D loss: 0.6049, G loss: 0.9001\n",
      "[1524/1762] D loss: 1.4062, G loss: 0.6858\n",
      "[1604/1762] D loss: 1.4549, G loss: 0.9199\n",
      "[1684/1762] D loss: 1.4124, G loss: 0.5574\n",
      "[1762/1762] D loss: 1.3591, G loss: 0.7161\n",
      "train error: \n",
      " D loss: 1.418587, G loss: 0.519721, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.406938, G loss: 0.519183, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4523, G loss: 0.6129\n",
      "[84/1762] D loss: 1.4311, G loss: 0.8725\n",
      "[164/1762] D loss: 1.4310, G loss: 0.8401\n",
      "[244/1762] D loss: 1.3950, G loss: 0.6383\n",
      "[324/1762] D loss: 0.2851, G loss: 1.8709\n",
      "[404/1762] D loss: 1.4360, G loss: 0.6101\n",
      "[484/1762] D loss: 1.4569, G loss: 0.5136\n",
      "[564/1762] D loss: 0.2691, G loss: 1.7986\n",
      "[644/1762] D loss: 1.4268, G loss: 0.8770\n",
      "[724/1762] D loss: 1.3841, G loss: 0.7030\n",
      "[804/1762] D loss: 1.4806, G loss: 0.8475\n",
      "[884/1762] D loss: 1.0575, G loss: 1.0470\n",
      "[964/1762] D loss: 0.6037, G loss: 1.0348\n",
      "[1044/1762] D loss: 0.5394, G loss: 1.5447\n",
      "[1124/1762] D loss: 1.4051, G loss: 0.7334\n",
      "[1204/1762] D loss: 0.2021, G loss: 2.4427\n",
      "[1284/1762] D loss: 1.4324, G loss: 0.9015\n",
      "[1364/1762] D loss: 0.4296, G loss: 1.3046\n",
      "[1444/1762] D loss: 1.4183, G loss: 0.8380\n",
      "[1524/1762] D loss: 1.4399, G loss: 0.8858\n",
      "[1604/1762] D loss: 0.3142, G loss: 1.6846\n",
      "[1684/1762] D loss: 1.4349, G loss: 0.8952\n",
      "[1762/1762] D loss: 1.4058, G loss: 0.5290\n",
      "train error: \n",
      " D loss: 1.507077, G loss: 0.401598, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.507590, G loss: 0.398320, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4794, G loss: 0.4238\n",
      "[84/1762] D loss: 0.5088, G loss: 1.2818\n",
      "[164/1762] D loss: 1.5316, G loss: 0.9452\n",
      "[244/1762] D loss: 1.4014, G loss: 0.6235\n",
      "[324/1762] D loss: 1.4902, G loss: 0.9465\n",
      "[404/1762] D loss: 1.4292, G loss: 0.6178\n",
      "[484/1762] D loss: 1.3938, G loss: 0.7513\n",
      "[564/1762] D loss: 1.4691, G loss: 0.5240\n",
      "[644/1762] D loss: 1.4474, G loss: 0.4930\n",
      "[724/1762] D loss: 0.6687, G loss: 0.9264\n",
      "[804/1762] D loss: 1.5269, G loss: 1.1307\n",
      "[884/1762] D loss: 1.3958, G loss: 0.6785\n",
      "[964/1762] D loss: 1.4104, G loss: 0.8141\n",
      "[1044/1762] D loss: 1.4713, G loss: 0.4845\n",
      "[1124/1762] D loss: 1.4032, G loss: 0.6670\n",
      "[1204/1762] D loss: 1.4252, G loss: 0.7590\n",
      "[1284/1762] D loss: 1.4790, G loss: 0.9287\n",
      "[1364/1762] D loss: 0.7915, G loss: 1.0320\n",
      "[1444/1762] D loss: 1.5088, G loss: 1.0941\n",
      "[1524/1762] D loss: 1.3694, G loss: 0.9530\n",
      "[1604/1762] D loss: 1.4441, G loss: 1.2326\n",
      "[1684/1762] D loss: 1.2691, G loss: 0.7840\n",
      "[1762/1762] D loss: 0.3413, G loss: 1.5271\n",
      "train error: \n",
      " D loss: 1.359895, G loss: 0.682196, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349442, G loss: 0.705833, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3732, G loss: 1.0306\n",
      "[84/1762] D loss: 1.4309, G loss: 0.6456\n",
      "[164/1762] D loss: 1.7821, G loss: 1.4162\n",
      "[244/1762] D loss: 1.4954, G loss: 0.9534\n",
      "[324/1762] D loss: 0.4573, G loss: 1.0705\n",
      "[404/1762] D loss: 1.4078, G loss: 0.6896\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7574\n",
      "[564/1762] D loss: 1.5969, G loss: 1.2508\n",
      "[644/1762] D loss: 0.3623, G loss: 1.7075\n",
      "[724/1762] D loss: 1.4141, G loss: 0.7634\n",
      "[804/1762] D loss: 1.5169, G loss: 0.4473\n",
      "[884/1762] D loss: 0.4358, G loss: 1.3369\n",
      "[964/1762] D loss: 1.4262, G loss: 0.9964\n",
      "[1044/1762] D loss: 0.3447, G loss: 1.4065\n",
      "[1124/1762] D loss: 1.3943, G loss: 0.6937\n",
      "[1204/1762] D loss: 1.4040, G loss: 0.7870\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.8214\n",
      "[1364/1762] D loss: 1.5806, G loss: 1.2173\n",
      "[1444/1762] D loss: 1.6651, G loss: 1.2516\n",
      "[1524/1762] D loss: 1.4080, G loss: 0.5283\n",
      "[1604/1762] D loss: 1.5686, G loss: 0.4232\n",
      "[1684/1762] D loss: 0.5306, G loss: 1.0508\n",
      "[1762/1762] D loss: 1.3968, G loss: 0.6152\n",
      "train error: \n",
      " D loss: 1.443209, G loss: 0.469111, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.439708, G loss: 0.463342, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6237, G loss: 0.9973\n",
      "[84/1762] D loss: 1.4833, G loss: 0.5234\n",
      "[164/1762] D loss: 1.4474, G loss: 0.7062\n",
      "[244/1762] D loss: 1.4286, G loss: 0.6098\n",
      "[324/1762] D loss: 0.3640, G loss: 1.4490\n",
      "[404/1762] D loss: 1.3758, G loss: 0.7213\n",
      "[484/1762] D loss: 1.1532, G loss: 1.0357\n",
      "[564/1762] D loss: 1.4326, G loss: 0.8675\n",
      "[644/1762] D loss: 1.4157, G loss: 0.6706\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6663\n",
      "[804/1762] D loss: 1.4216, G loss: 0.7902\n",
      "[884/1762] D loss: 1.4962, G loss: 0.9483\n",
      "[964/1762] D loss: 1.4806, G loss: 0.8867\n",
      "[1044/1762] D loss: 1.4141, G loss: 0.5845\n",
      "[1124/1762] D loss: 1.4330, G loss: 1.0047\n",
      "[1204/1762] D loss: 1.3980, G loss: 0.6266\n",
      "[1284/1762] D loss: 1.4464, G loss: 0.8284\n",
      "[1364/1762] D loss: 0.1697, G loss: 2.1100\n",
      "[1444/1762] D loss: 1.3918, G loss: 0.8202\n",
      "[1524/1762] D loss: 1.4367, G loss: 0.5803\n",
      "[1604/1762] D loss: 0.5952, G loss: 1.0218\n",
      "[1684/1762] D loss: 1.3735, G loss: 0.8859\n",
      "[1762/1762] D loss: 1.4170, G loss: 0.7886\n",
      "train error: \n",
      " D loss: 1.344796, G loss: 0.640333, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326298, G loss: 0.651953, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.7341\n",
      "[84/1762] D loss: 1.4092, G loss: 0.6075\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6205\n",
      "[244/1762] D loss: 1.5217, G loss: 0.4770\n",
      "[324/1762] D loss: 1.5058, G loss: 0.4991\n",
      "[404/1762] D loss: 0.2884, G loss: 1.6287\n",
      "[484/1762] D loss: 1.2912, G loss: 0.8170\n",
      "[564/1762] D loss: 1.3667, G loss: 0.8063\n",
      "[644/1762] D loss: 1.4113, G loss: 0.5320\n",
      "[724/1762] D loss: 1.3935, G loss: 0.7419\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6722\n",
      "[884/1762] D loss: 1.3310, G loss: 0.8758\n",
      "[964/1762] D loss: 1.4228, G loss: 0.8370\n",
      "[1044/1762] D loss: 0.3482, G loss: 1.3742\n",
      "[1124/1762] D loss: 1.4177, G loss: 0.7246\n",
      "[1204/1762] D loss: 1.5153, G loss: 1.1433\n",
      "[1284/1762] D loss: 1.4735, G loss: 0.9612\n",
      "[1364/1762] D loss: 1.4189, G loss: 0.5772\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.7602\n",
      "[1524/1762] D loss: 0.4367, G loss: 1.1128\n",
      "[1604/1762] D loss: 1.2958, G loss: 0.9875\n",
      "[1684/1762] D loss: 0.2903, G loss: 1.6447\n",
      "[1762/1762] D loss: 1.5663, G loss: 1.0418\n",
      "train error: \n",
      " D loss: 1.561142, G loss: 1.383305, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.540730, G loss: 1.391462, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5510, G loss: 0.9297\n",
      "[84/1762] D loss: 1.3794, G loss: 0.6071\n",
      "[164/1762] D loss: 1.3926, G loss: 0.6669\n",
      "[244/1762] D loss: 1.4414, G loss: 0.9099\n",
      "[324/1762] D loss: 1.7626, G loss: 1.4020\n",
      "[404/1762] D loss: 1.6037, G loss: 1.1506\n",
      "[484/1762] D loss: 1.4228, G loss: 0.9272\n",
      "[564/1762] D loss: 1.4307, G loss: 0.7996\n",
      "[644/1762] D loss: 1.4223, G loss: 0.5697\n",
      "[724/1762] D loss: 1.4000, G loss: 0.6456\n",
      "[804/1762] D loss: 0.1667, G loss: 1.8592\n",
      "[884/1762] D loss: 0.3387, G loss: 1.6314\n",
      "[964/1762] D loss: 1.3967, G loss: 0.8386\n",
      "[1044/1762] D loss: 0.1945, G loss: 2.1895\n",
      "[1124/1762] D loss: 1.5415, G loss: 1.0474\n",
      "[1204/1762] D loss: 0.1395, G loss: 2.5090\n",
      "[1284/1762] D loss: 1.2815, G loss: 0.8217\n",
      "[1364/1762] D loss: 1.4158, G loss: 0.8280\n",
      "[1444/1762] D loss: 1.2625, G loss: 0.8561\n",
      "[1524/1762] D loss: 1.4197, G loss: 0.5646\n",
      "[1604/1762] D loss: 1.3860, G loss: 0.5479\n",
      "[1684/1762] D loss: 1.1584, G loss: 0.9816\n",
      "[1762/1762] D loss: 1.4075, G loss: 0.6953\n",
      "train error: \n",
      " D loss: 1.376092, G loss: 0.532328, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354892, G loss: 0.545517, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4153, G loss: 0.5338\n",
      "[84/1762] D loss: 1.3910, G loss: 0.6216\n",
      "[164/1762] D loss: 1.3853, G loss: 0.4901\n",
      "[244/1762] D loss: 0.2276, G loss: 1.8791\n",
      "[324/1762] D loss: 1.4076, G loss: 0.5611\n",
      "[404/1762] D loss: 1.4176, G loss: 0.6649\n",
      "[484/1762] D loss: 0.2438, G loss: 1.7168\n",
      "[564/1762] D loss: 0.3615, G loss: 1.3238\n",
      "[644/1762] D loss: 1.4507, G loss: 0.4974\n",
      "[724/1762] D loss: 1.4125, G loss: 0.7948\n",
      "[804/1762] D loss: 1.4034, G loss: 0.7186\n",
      "[884/1762] D loss: 1.3711, G loss: 0.7989\n",
      "[964/1762] D loss: 1.3954, G loss: 0.7791\n",
      "[1044/1762] D loss: 1.4318, G loss: 0.7917\n",
      "[1124/1762] D loss: 1.5348, G loss: 0.3583\n",
      "[1204/1762] D loss: 1.4344, G loss: 0.4605\n",
      "[1284/1762] D loss: 1.4569, G loss: 0.9414\n",
      "[1364/1762] D loss: 0.3225, G loss: 1.5438\n",
      "[1444/1762] D loss: 1.1269, G loss: 0.7007\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.9752\n",
      "[1604/1762] D loss: 1.5576, G loss: 1.0609\n",
      "[1684/1762] D loss: 0.1953, G loss: 1.7887\n",
      "[1762/1762] D loss: 1.4565, G loss: 0.7884\n",
      "train error: \n",
      " D loss: 1.353952, G loss: 0.638437, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339216, G loss: 0.652696, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4604, G loss: 0.8422\n",
      "[84/1762] D loss: 0.0461, G loss: 3.4211\n",
      "[164/1762] D loss: 1.7653, G loss: 1.1154\n",
      "[244/1762] D loss: 1.4266, G loss: 0.5511\n",
      "[324/1762] D loss: 1.2969, G loss: 0.9348\n",
      "[404/1762] D loss: 1.4114, G loss: 0.7474\n",
      "[484/1762] D loss: 0.3209, G loss: 1.4034\n",
      "[564/1762] D loss: 1.4728, G loss: 1.0350\n",
      "[644/1762] D loss: 1.3853, G loss: 0.7689\n",
      "[724/1762] D loss: 0.2005, G loss: 1.9009\n",
      "[804/1762] D loss: 1.4103, G loss: 0.7883\n",
      "[884/1762] D loss: 0.2298, G loss: 1.5687\n",
      "[964/1762] D loss: 1.3158, G loss: 0.7701\n",
      "[1044/1762] D loss: 1.3175, G loss: 0.8107\n",
      "[1124/1762] D loss: 1.4019, G loss: 0.6684\n",
      "[1204/1762] D loss: 0.3300, G loss: 1.6909\n",
      "[1284/1762] D loss: 0.1736, G loss: 2.1013\n",
      "[1364/1762] D loss: 1.5398, G loss: 1.2056\n",
      "[1444/1762] D loss: 1.4110, G loss: 0.6831\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.6628\n",
      "[1604/1762] D loss: 1.4552, G loss: 0.8370\n",
      "[1684/1762] D loss: 1.4124, G loss: 0.7115\n",
      "[1762/1762] D loss: 1.4124, G loss: 0.6690\n",
      "train error: \n",
      " D loss: 1.344090, G loss: 0.629130, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325556, G loss: 0.642477, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4300, G loss: 0.6847\n",
      "[84/1762] D loss: 1.4016, G loss: 0.7095\n",
      "[164/1762] D loss: 0.3836, G loss: 1.3009\n",
      "[244/1762] D loss: 0.3824, G loss: 1.4324\n",
      "[324/1762] D loss: 1.6382, G loss: 1.1671\n",
      "[404/1762] D loss: 0.3116, G loss: 1.3464\n",
      "[484/1762] D loss: 1.4059, G loss: 0.8853\n",
      "[564/1762] D loss: 1.3924, G loss: 0.8646\n",
      "[644/1762] D loss: 1.3925, G loss: 0.6492\n",
      "[724/1762] D loss: 1.4348, G loss: 0.9802\n",
      "[804/1762] D loss: 1.5276, G loss: 1.0397\n",
      "[884/1762] D loss: 1.4048, G loss: 0.5312\n",
      "[964/1762] D loss: 1.4350, G loss: 0.6352\n",
      "[1044/1762] D loss: 1.4186, G loss: 0.9123\n",
      "[1124/1762] D loss: 1.4942, G loss: 0.9762\n",
      "[1204/1762] D loss: 1.4829, G loss: 0.8918\n",
      "[1284/1762] D loss: 1.4343, G loss: 0.7923\n",
      "[1364/1762] D loss: 1.5018, G loss: 1.0464\n",
      "[1444/1762] D loss: 0.1716, G loss: 2.0615\n",
      "[1524/1762] D loss: 1.3954, G loss: 0.6385\n",
      "[1604/1762] D loss: 1.3962, G loss: 0.7260\n",
      "[1684/1762] D loss: 1.4003, G loss: 0.7473\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.6388\n",
      "train error: \n",
      " D loss: 1.423462, G loss: 0.472094, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403555, G loss: 0.485619, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4175, G loss: 0.6513\n",
      "[84/1762] D loss: 1.4056, G loss: 0.7959\n",
      "[164/1762] D loss: 1.4068, G loss: 0.7003\n",
      "[244/1762] D loss: 1.3954, G loss: 0.6422\n",
      "[324/1762] D loss: 0.2120, G loss: 1.7682\n",
      "[404/1762] D loss: 1.4392, G loss: 0.6378\n",
      "[484/1762] D loss: 0.1876, G loss: 2.2297\n",
      "[564/1762] D loss: 1.1667, G loss: 0.8612\n",
      "[644/1762] D loss: 0.2346, G loss: 1.8952\n",
      "[724/1762] D loss: 0.3396, G loss: 1.7373\n",
      "[804/1762] D loss: 1.4834, G loss: 0.4142\n",
      "[884/1762] D loss: 0.3328, G loss: 1.4767\n",
      "[964/1762] D loss: 1.4115, G loss: 0.6155\n",
      "[1044/1762] D loss: 1.4080, G loss: 0.7964\n",
      "[1124/1762] D loss: 0.1060, G loss: 2.5983\n",
      "[1204/1762] D loss: 1.6625, G loss: 1.2618\n",
      "[1284/1762] D loss: 0.3763, G loss: 1.1356\n",
      "[1364/1762] D loss: 1.5578, G loss: 1.2044\n",
      "[1444/1762] D loss: 1.3944, G loss: 0.6369\n",
      "[1524/1762] D loss: 1.4851, G loss: 1.0594\n",
      "[1604/1762] D loss: 1.5337, G loss: 0.8777\n",
      "[1684/1762] D loss: 1.3720, G loss: 0.5503\n",
      "[1762/1762] D loss: 1.3793, G loss: 0.7147\n",
      "train error: \n",
      " D loss: 1.305394, G loss: 0.845796, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294318, G loss: 0.839251, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5891, G loss: 1.0942\n",
      "[84/1762] D loss: 0.1416, G loss: 2.2091\n",
      "[164/1762] D loss: 1.4942, G loss: 0.4270\n",
      "[244/1762] D loss: 0.2749, G loss: 1.4962\n",
      "[324/1762] D loss: 0.9056, G loss: 1.0590\n",
      "[404/1762] D loss: 1.9433, G loss: 1.7763\n",
      "[484/1762] D loss: 1.4059, G loss: 0.7970\n",
      "[564/1762] D loss: 0.5338, G loss: 1.0555\n",
      "[644/1762] D loss: 1.4001, G loss: 0.6916\n",
      "[724/1762] D loss: 1.4236, G loss: 0.8770\n",
      "[804/1762] D loss: 1.3898, G loss: 0.7548\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7790\n",
      "[964/1762] D loss: 1.4542, G loss: 0.8979\n",
      "[1044/1762] D loss: 0.3646, G loss: 1.4264\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.7468\n",
      "[1204/1762] D loss: 1.4260, G loss: 0.8745\n",
      "[1284/1762] D loss: 0.3894, G loss: 1.0849\n",
      "[1364/1762] D loss: 1.5673, G loss: 1.1194\n",
      "[1444/1762] D loss: 0.0180, G loss: 4.5705\n",
      "[1524/1762] D loss: 1.4169, G loss: 0.7526\n",
      "[1604/1762] D loss: 0.0876, G loss: 3.5517\n",
      "[1684/1762] D loss: 1.4036, G loss: 0.7056\n",
      "[1762/1762] D loss: 1.5427, G loss: 0.3702\n",
      "train error: \n",
      " D loss: 1.412671, G loss: 0.501115, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400120, G loss: 0.503937, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4908, G loss: 0.4947\n",
      "[84/1762] D loss: 1.4011, G loss: 0.8591\n",
      "[164/1762] D loss: 1.4481, G loss: 0.8326\n",
      "[244/1762] D loss: 1.3937, G loss: 0.6794\n",
      "[324/1762] D loss: 1.3565, G loss: 0.8175\n",
      "[404/1762] D loss: 0.3150, G loss: 1.4736\n",
      "[484/1762] D loss: 1.4293, G loss: 0.8300\n",
      "[564/1762] D loss: 0.2812, G loss: 1.3017\n",
      "[644/1762] D loss: 1.4137, G loss: 0.6453\n",
      "[724/1762] D loss: 1.4046, G loss: 0.8683\n",
      "[804/1762] D loss: 1.4740, G loss: 0.8868\n",
      "[884/1762] D loss: 1.4024, G loss: 0.6972\n",
      "[964/1762] D loss: 1.4482, G loss: 0.8089\n",
      "[1044/1762] D loss: 1.4141, G loss: 0.7710\n",
      "[1124/1762] D loss: 1.4311, G loss: 0.6577\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.8905\n",
      "[1284/1762] D loss: 1.4517, G loss: 0.9236\n",
      "[1364/1762] D loss: 1.4074, G loss: 0.7679\n",
      "[1444/1762] D loss: 1.4327, G loss: 0.5877\n",
      "[1524/1762] D loss: 0.0195, G loss: 4.9285\n",
      "[1604/1762] D loss: 1.6090, G loss: 1.2314\n",
      "[1684/1762] D loss: 1.5106, G loss: 0.8946\n",
      "[1762/1762] D loss: 1.5038, G loss: 0.5322\n",
      "train error: \n",
      " D loss: 1.337581, G loss: 0.631249, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322448, G loss: 0.632777, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4159, G loss: 0.6439\n",
      "[84/1762] D loss: 1.4378, G loss: 0.6903\n",
      "[164/1762] D loss: 1.4713, G loss: 1.0662\n",
      "[244/1762] D loss: 0.0607, G loss: 3.1028\n",
      "[324/1762] D loss: 1.4135, G loss: 0.6107\n",
      "[404/1762] D loss: 1.4214, G loss: 0.6129\n",
      "[484/1762] D loss: 1.4210, G loss: 0.5238\n",
      "[564/1762] D loss: 1.5308, G loss: 1.0076\n",
      "[644/1762] D loss: 1.4289, G loss: 0.5079\n",
      "[724/1762] D loss: 1.4152, G loss: 0.7704\n",
      "[804/1762] D loss: 0.3439, G loss: 1.6008\n",
      "[884/1762] D loss: 0.2336, G loss: 1.7151\n",
      "[964/1762] D loss: 1.4462, G loss: 0.8751\n",
      "[1044/1762] D loss: 1.5139, G loss: 1.1031\n",
      "[1124/1762] D loss: 1.5472, G loss: 0.4586\n",
      "[1204/1762] D loss: 0.0509, G loss: 3.9343\n",
      "[1284/1762] D loss: 0.2846, G loss: 1.3214\n",
      "[1364/1762] D loss: 1.4093, G loss: 0.8716\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.8524\n",
      "[1524/1762] D loss: 1.7554, G loss: 1.3338\n",
      "[1604/1762] D loss: 1.4671, G loss: 0.4991\n",
      "[1684/1762] D loss: 1.4127, G loss: 0.5922\n",
      "[1762/1762] D loss: 0.0618, G loss: 2.9548\n",
      "train error: \n",
      " D loss: 1.707541, G loss: 0.274148, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.688551, G loss: 0.281565, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0522, G loss: 3.2634\n",
      "[84/1762] D loss: 0.2644, G loss: 1.7606\n",
      "[164/1762] D loss: 1.4122, G loss: 0.7402\n",
      "[244/1762] D loss: 1.4080, G loss: 0.6264\n",
      "[324/1762] D loss: 1.3925, G loss: 0.7555\n",
      "[404/1762] D loss: 1.7715, G loss: 1.3704\n",
      "[484/1762] D loss: 1.2742, G loss: 0.7379\n",
      "[564/1762] D loss: 0.2047, G loss: 1.7846\n",
      "[644/1762] D loss: 1.2403, G loss: 0.9449\n",
      "[724/1762] D loss: 1.3970, G loss: 0.7059\n",
      "[804/1762] D loss: 0.2235, G loss: 1.6827\n",
      "[884/1762] D loss: 1.2425, G loss: 0.9151\n",
      "[964/1762] D loss: 1.3944, G loss: 0.6172\n",
      "[1044/1762] D loss: 1.3596, G loss: 0.6931\n",
      "[1124/1762] D loss: 1.4345, G loss: 0.7195\n",
      "[1204/1762] D loss: 1.7861, G loss: 0.2831\n",
      "[1284/1762] D loss: 0.2145, G loss: 1.8305\n",
      "[1364/1762] D loss: 1.5264, G loss: 1.1659\n",
      "[1444/1762] D loss: 1.4031, G loss: 0.7650\n",
      "[1524/1762] D loss: 0.1874, G loss: 1.9767\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.7745\n",
      "[1684/1762] D loss: 0.1562, G loss: 2.1094\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6267\n",
      "train error: \n",
      " D loss: 1.330849, G loss: 0.642273, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311788, G loss: 0.653647, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0393, G loss: 3.3563\n",
      "[84/1762] D loss: 1.4199, G loss: 0.9246\n",
      "[164/1762] D loss: 0.2188, G loss: 1.8474\n",
      "[244/1762] D loss: 0.1403, G loss: 2.3305\n",
      "[324/1762] D loss: 1.3964, G loss: 0.7640\n",
      "[404/1762] D loss: 0.2400, G loss: 1.8855\n",
      "[484/1762] D loss: 1.5299, G loss: 1.7706\n",
      "[564/1762] D loss: 0.3679, G loss: 1.3510\n",
      "[644/1762] D loss: 1.4150, G loss: 0.5406\n",
      "[724/1762] D loss: 1.4071, G loss: 0.8014\n",
      "[804/1762] D loss: 1.5205, G loss: 0.8811\n",
      "[884/1762] D loss: 1.4205, G loss: 0.7646\n",
      "[964/1762] D loss: 0.2684, G loss: 1.8336\n",
      "[1044/1762] D loss: 1.4041, G loss: 0.7156\n",
      "[1124/1762] D loss: 1.6848, G loss: 1.1850\n",
      "[1204/1762] D loss: 1.3832, G loss: 0.7165\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.6827\n",
      "[1364/1762] D loss: 1.3951, G loss: 0.6640\n",
      "[1444/1762] D loss: 1.4266, G loss: 0.4778\n",
      "[1524/1762] D loss: 1.4638, G loss: 0.8123\n",
      "[1604/1762] D loss: 1.4063, G loss: 0.5237\n",
      "[1684/1762] D loss: 1.4076, G loss: 0.7903\n",
      "[1762/1762] D loss: 1.4038, G loss: 0.6453\n",
      "train error: \n",
      " D loss: 1.492488, G loss: 0.405367, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.468693, G loss: 0.418863, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3817, G loss: 0.7777\n",
      "[84/1762] D loss: 1.4801, G loss: 0.8840\n",
      "[164/1762] D loss: 0.2821, G loss: 1.8312\n",
      "[244/1762] D loss: 1.4001, G loss: 0.7229\n",
      "[324/1762] D loss: 0.1693, G loss: 2.1175\n",
      "[404/1762] D loss: 1.3880, G loss: 0.6782\n",
      "[484/1762] D loss: 0.3299, G loss: 1.3082\n",
      "[564/1762] D loss: 0.1945, G loss: 1.9859\n",
      "[644/1762] D loss: 1.4440, G loss: 0.8678\n",
      "[724/1762] D loss: 1.3987, G loss: 0.5864\n",
      "[804/1762] D loss: 1.4573, G loss: 0.9604\n",
      "[884/1762] D loss: 1.3929, G loss: 0.7265\n",
      "[964/1762] D loss: 1.3878, G loss: 0.6774\n",
      "[1044/1762] D loss: 1.4215, G loss: 0.5336\n",
      "[1124/1762] D loss: 0.0622, G loss: 3.0437\n",
      "[1204/1762] D loss: 0.1462, G loss: 2.3213\n",
      "[1284/1762] D loss: 1.3934, G loss: 0.7427\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6833\n",
      "[1444/1762] D loss: 1.4052, G loss: 0.6110\n",
      "[1524/1762] D loss: 1.4009, G loss: 0.8590\n",
      "[1604/1762] D loss: 0.1874, G loss: 2.0345\n",
      "[1684/1762] D loss: 0.0332, G loss: 3.5208\n",
      "[1762/1762] D loss: 1.4021, G loss: 0.5975\n",
      "train error: \n",
      " D loss: 1.668360, G loss: 0.294438, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 82.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.668088, G loss: 0.293560, D accuracy: 51.1%, cell accuracy: 99.6%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4592, G loss: 0.5406\n",
      "[84/1762] D loss: 1.3895, G loss: 0.7409\n",
      "[164/1762] D loss: 1.4076, G loss: 0.6331\n",
      "[244/1762] D loss: 1.4018, G loss: 0.7586\n",
      "[324/1762] D loss: 0.1555, G loss: 2.3201\n",
      "[404/1762] D loss: 1.4514, G loss: 0.4024\n",
      "[484/1762] D loss: 1.4999, G loss: 1.0538\n",
      "[564/1762] D loss: 1.3907, G loss: 0.6343\n",
      "[644/1762] D loss: 1.4182, G loss: 0.6762\n",
      "[724/1762] D loss: 1.4598, G loss: 0.9982\n",
      "[804/1762] D loss: 1.3899, G loss: 0.6076\n",
      "[884/1762] D loss: 1.6249, G loss: 0.6220\n",
      "[964/1762] D loss: 0.1345, G loss: 2.2124\n",
      "[1044/1762] D loss: 1.4686, G loss: 0.9474\n",
      "[1124/1762] D loss: 1.4936, G loss: 0.5124\n",
      "[1204/1762] D loss: 1.5276, G loss: 0.9471\n",
      "[1284/1762] D loss: 1.3969, G loss: 0.6307\n",
      "[1364/1762] D loss: 1.4253, G loss: 0.9283\n",
      "[1444/1762] D loss: 0.0808, G loss: 2.5034\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.8540\n",
      "[1604/1762] D loss: 0.2309, G loss: 1.7368\n",
      "[1684/1762] D loss: 1.3969, G loss: 0.8144\n",
      "[1762/1762] D loss: 1.4389, G loss: 0.7612\n",
      "train error: \n",
      " D loss: 1.348291, G loss: 0.613996, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327593, G loss: 0.624016, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2653, G loss: 0.8185\n",
      "[84/1762] D loss: 1.3926, G loss: 0.7467\n",
      "[164/1762] D loss: 1.4046, G loss: 0.7660\n",
      "[244/1762] D loss: 1.4154, G loss: 0.8547\n",
      "[324/1762] D loss: 1.3966, G loss: 0.7906\n",
      "[404/1762] D loss: 1.4556, G loss: 0.8694\n",
      "[484/1762] D loss: 1.3953, G loss: 0.6103\n",
      "[564/1762] D loss: 1.4297, G loss: 0.8400\n",
      "[644/1762] D loss: 1.3912, G loss: 0.6788\n",
      "[724/1762] D loss: 0.2214, G loss: 1.8207\n",
      "[804/1762] D loss: 1.4310, G loss: 0.9514\n",
      "[884/1762] D loss: 1.4346, G loss: 0.8957\n",
      "[964/1762] D loss: 0.2933, G loss: 1.5163\n",
      "[1044/1762] D loss: 1.3539, G loss: 0.8732\n",
      "[1124/1762] D loss: 0.2461, G loss: 1.9172\n",
      "[1204/1762] D loss: 1.4733, G loss: 0.9682\n",
      "[1284/1762] D loss: 1.4211, G loss: 0.5177\n",
      "[1364/1762] D loss: 0.0788, G loss: 2.9385\n",
      "[1444/1762] D loss: 1.3993, G loss: 0.6981\n",
      "[1524/1762] D loss: 1.4617, G loss: 0.8038\n",
      "[1604/1762] D loss: 1.4200, G loss: 0.9971\n",
      "[1684/1762] D loss: 1.4014, G loss: 0.6815\n",
      "[1762/1762] D loss: 1.4810, G loss: 0.4459\n",
      "train error: \n",
      " D loss: 1.527165, G loss: 0.371093, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.516661, G loss: 0.375478, D accuracy: 51.4%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6224, G loss: 0.3954\n",
      "[84/1762] D loss: 1.4761, G loss: 1.0394\n",
      "[164/1762] D loss: 0.2543, G loss: 1.7413\n",
      "[244/1762] D loss: 1.4608, G loss: 0.5012\n",
      "[324/1762] D loss: 1.4175, G loss: 0.8832\n",
      "[404/1762] D loss: 0.3252, G loss: 1.5225\n",
      "[484/1762] D loss: 1.4563, G loss: 0.7967\n",
      "[564/1762] D loss: 1.4899, G loss: 0.5308\n",
      "[644/1762] D loss: 1.4006, G loss: 0.7054\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6478\n",
      "[804/1762] D loss: 1.3900, G loss: 0.6889\n",
      "[884/1762] D loss: 0.1588, G loss: 2.2513\n",
      "[964/1762] D loss: 0.1476, G loss: 2.1732\n",
      "[1044/1762] D loss: 1.3832, G loss: 0.7200\n",
      "[1124/1762] D loss: 1.4022, G loss: 0.6939\n",
      "[1204/1762] D loss: 1.4156, G loss: 0.8037\n",
      "[1284/1762] D loss: 1.5200, G loss: 0.4817\n",
      "[1364/1762] D loss: 1.4060, G loss: 0.6694\n",
      "[1444/1762] D loss: 1.4020, G loss: 0.6609\n",
      "[1524/1762] D loss: 1.3993, G loss: 0.8466\n",
      "[1604/1762] D loss: 1.4831, G loss: 0.5056\n",
      "[1684/1762] D loss: 0.0755, G loss: 2.8302\n",
      "[1762/1762] D loss: 1.4757, G loss: 0.9164\n",
      "train error: \n",
      " D loss: 1.417989, G loss: 0.477622, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399569, G loss: 0.489048, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4162, G loss: 0.7466\n",
      "[84/1762] D loss: 0.1437, G loss: 2.1555\n",
      "[164/1762] D loss: 1.3909, G loss: 0.7591\n",
      "[244/1762] D loss: 0.1052, G loss: 2.5480\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6521\n",
      "[404/1762] D loss: 1.3939, G loss: 0.8421\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7008\n",
      "[564/1762] D loss: 1.3913, G loss: 0.6642\n",
      "[644/1762] D loss: 0.8916, G loss: 1.5596\n",
      "[724/1762] D loss: 1.3970, G loss: 0.8704\n",
      "[804/1762] D loss: 1.4070, G loss: 0.6482\n",
      "[884/1762] D loss: 1.3936, G loss: 0.7374\n",
      "[964/1762] D loss: 1.4266, G loss: 0.9754\n",
      "[1044/1762] D loss: 1.4066, G loss: 0.6493\n",
      "[1124/1762] D loss: 0.1008, G loss: 2.5870\n",
      "[1204/1762] D loss: 0.0416, G loss: 3.5892\n",
      "[1284/1762] D loss: 1.4514, G loss: 0.5114\n",
      "[1364/1762] D loss: 1.3998, G loss: 0.6867\n",
      "[1444/1762] D loss: 1.4600, G loss: 0.9595\n",
      "[1524/1762] D loss: 1.4099, G loss: 0.7873\n",
      "[1604/1762] D loss: 1.4056, G loss: 0.6266\n",
      "[1684/1762] D loss: 1.4370, G loss: 0.9141\n",
      "[1762/1762] D loss: 1.3954, G loss: 0.7562\n",
      "train error: \n",
      " D loss: 1.319926, G loss: 0.741750, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298736, G loss: 0.750050, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4064, G loss: 0.6967\n",
      "[84/1762] D loss: 0.0963, G loss: 2.5783\n",
      "[164/1762] D loss: 0.1188, G loss: 2.4033\n",
      "[244/1762] D loss: 1.4080, G loss: 0.6554\n",
      "[324/1762] D loss: 1.4648, G loss: 0.5199\n",
      "[404/1762] D loss: 1.4142, G loss: 0.8396\n",
      "[484/1762] D loss: 1.4622, G loss: 0.8871\n",
      "[564/1762] D loss: 1.4079, G loss: 0.5961\n",
      "[644/1762] D loss: 0.1264, G loss: 2.1936\n",
      "[724/1762] D loss: 1.4858, G loss: 0.4806\n",
      "[804/1762] D loss: 1.3952, G loss: 0.7560\n",
      "[884/1762] D loss: 1.3928, G loss: 0.9027\n",
      "[964/1762] D loss: 0.0996, G loss: 2.4205\n",
      "[1044/1762] D loss: 1.3985, G loss: 0.6787\n",
      "[1124/1762] D loss: 1.3963, G loss: 0.6850\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.6558\n",
      "[1284/1762] D loss: 1.4109, G loss: 0.8516\n",
      "[1364/1762] D loss: 1.5178, G loss: 1.0012\n",
      "[1444/1762] D loss: 1.4296, G loss: 0.8046\n",
      "[1524/1762] D loss: 1.4227, G loss: 0.9200\n",
      "[1604/1762] D loss: 1.3987, G loss: 0.7166\n",
      "[1684/1762] D loss: 1.4348, G loss: 0.5094\n",
      "[1762/1762] D loss: 1.6791, G loss: 1.2353\n",
      "train error: \n",
      " D loss: 1.345996, G loss: 0.955385, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323528, G loss: 0.965237, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4125, G loss: 0.7359\n",
      "[84/1762] D loss: 1.4233, G loss: 0.7116\n",
      "[164/1762] D loss: 1.3913, G loss: 0.8007\n",
      "[244/1762] D loss: 0.0365, G loss: 4.1870\n",
      "[324/1762] D loss: 1.4083, G loss: 0.3436\n",
      "[404/1762] D loss: 1.4541, G loss: 0.5057\n",
      "[484/1762] D loss: 0.0632, G loss: 3.3414\n",
      "[564/1762] D loss: 1.5296, G loss: 0.8676\n",
      "[644/1762] D loss: 1.3893, G loss: 0.5782\n",
      "[724/1762] D loss: 1.4443, G loss: 0.4879\n",
      "[804/1762] D loss: 1.4959, G loss: 0.9508\n",
      "[884/1762] D loss: 1.4003, G loss: 0.8213\n",
      "[964/1762] D loss: 1.2443, G loss: 1.0823\n",
      "[1044/1762] D loss: 1.4076, G loss: 0.8206\n",
      "[1124/1762] D loss: 1.4022, G loss: 0.5508\n",
      "[1204/1762] D loss: 1.4864, G loss: 0.4405\n",
      "[1284/1762] D loss: 0.2777, G loss: 1.5169\n",
      "[1364/1762] D loss: 1.4376, G loss: 0.8603\n",
      "[1444/1762] D loss: 0.1428, G loss: 2.1502\n",
      "[1524/1762] D loss: 0.0880, G loss: 2.7010\n",
      "[1604/1762] D loss: 1.5204, G loss: 1.0124\n",
      "[1684/1762] D loss: 0.1641, G loss: 1.8117\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6941\n",
      "train error: \n",
      " D loss: 1.811084, G loss: 0.236873, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.795591, G loss: 0.246033, D accuracy: 51.0%, cell accuracy: 99.7%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2769, G loss: 0.7129\n",
      "[84/1762] D loss: 1.3998, G loss: 0.7416\n",
      "[164/1762] D loss: 1.3923, G loss: 0.7761\n",
      "[244/1762] D loss: 1.3945, G loss: 0.6018\n",
      "[324/1762] D loss: 1.4146, G loss: 0.8127\n",
      "[404/1762] D loss: 0.2831, G loss: 1.4912\n",
      "[484/1762] D loss: 1.1749, G loss: 0.9510\n",
      "[564/1762] D loss: 1.3930, G loss: 0.8108\n",
      "[644/1762] D loss: 0.8219, G loss: 1.3664\n",
      "[724/1762] D loss: 1.5666, G loss: 1.1455\n",
      "[804/1762] D loss: 1.4293, G loss: 0.9432\n",
      "[884/1762] D loss: 1.3976, G loss: 0.6770\n",
      "[964/1762] D loss: 1.4102, G loss: 0.6841\n",
      "[1044/1762] D loss: 0.1744, G loss: 2.3688\n",
      "[1124/1762] D loss: 1.7092, G loss: 1.1523\n",
      "[1204/1762] D loss: 1.4032, G loss: 0.6360\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.8100\n",
      "[1364/1762] D loss: 1.4272, G loss: 0.8911\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.6045\n",
      "[1524/1762] D loss: 1.4838, G loss: 0.9997\n",
      "[1604/1762] D loss: 0.1436, G loss: 2.2354\n",
      "[1684/1762] D loss: 1.4878, G loss: 0.9862\n",
      "[1762/1762] D loss: 1.3956, G loss: 0.7316\n",
      "train error: \n",
      " D loss: 1.384689, G loss: 0.527572, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367936, G loss: 0.533578, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3896, G loss: 0.6411\n",
      "[84/1762] D loss: 1.7106, G loss: 1.3540\n",
      "[164/1762] D loss: 1.4006, G loss: 0.6605\n",
      "[244/1762] D loss: 1.3967, G loss: 0.5976\n",
      "[324/1762] D loss: 1.3920, G loss: 0.7991\n",
      "[404/1762] D loss: 1.4639, G loss: 0.8444\n",
      "[484/1762] D loss: 0.1038, G loss: 2.9019\n",
      "[564/1762] D loss: 1.3254, G loss: 0.6047\n",
      "[644/1762] D loss: 1.3101, G loss: 0.7037\n",
      "[724/1762] D loss: 1.3882, G loss: 0.6554\n",
      "[804/1762] D loss: 1.3965, G loss: 0.8037\n",
      "[884/1762] D loss: 1.4106, G loss: 0.7500\n",
      "[964/1762] D loss: 0.0137, G loss: 4.6105\n",
      "[1044/1762] D loss: 1.4101, G loss: 0.8110\n",
      "[1124/1762] D loss: 1.4839, G loss: 0.9431\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.7369\n",
      "[1284/1762] D loss: 1.4277, G loss: 0.7912\n",
      "[1364/1762] D loss: 1.3981, G loss: 0.6941\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6518\n",
      "[1524/1762] D loss: 1.4072, G loss: 0.7947\n",
      "[1604/1762] D loss: 1.4197, G loss: 0.7666\n",
      "[1684/1762] D loss: 1.3960, G loss: 0.7880\n",
      "[1762/1762] D loss: 1.4131, G loss: 0.7704\n",
      "train error: \n",
      " D loss: 1.555644, G loss: 0.359312, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.534596, G loss: 0.376530, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.6404\n",
      "[84/1762] D loss: 1.4782, G loss: 1.0322\n",
      "[164/1762] D loss: 1.4132, G loss: 0.7111\n",
      "[244/1762] D loss: 1.5539, G loss: 0.9672\n",
      "[324/1762] D loss: 0.0137, G loss: 4.5562\n",
      "[404/1762] D loss: 1.3935, G loss: 0.7312\n",
      "[484/1762] D loss: 1.4049, G loss: 0.5920\n",
      "[564/1762] D loss: 1.4857, G loss: 0.4608\n",
      "[644/1762] D loss: 0.1283, G loss: 2.3391\n",
      "[724/1762] D loss: 1.4256, G loss: 0.7800\n",
      "[804/1762] D loss: 1.4048, G loss: 0.6845\n",
      "[884/1762] D loss: 1.7297, G loss: 1.3865\n",
      "[964/1762] D loss: 0.0883, G loss: 2.5464\n",
      "[1044/1762] D loss: 0.1276, G loss: 2.4907\n",
      "[1124/1762] D loss: 0.1686, G loss: 1.9680\n",
      "[1204/1762] D loss: 1.3924, G loss: 0.7529\n",
      "[1284/1762] D loss: 1.4002, G loss: 0.6432\n",
      "[1364/1762] D loss: 1.4136, G loss: 0.6889\n",
      "[1444/1762] D loss: 1.4278, G loss: 0.6651\n",
      "[1524/1762] D loss: 0.1025, G loss: 2.7060\n",
      "[1604/1762] D loss: 0.9119, G loss: 2.1675\n",
      "[1684/1762] D loss: 0.1566, G loss: 2.1493\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.6143\n",
      "train error: \n",
      " D loss: 1.931331, G loss: 0.200098, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.912991, G loss: 0.203140, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6693\n",
      "[84/1762] D loss: 1.4037, G loss: 0.8192\n",
      "[164/1762] D loss: 1.4415, G loss: 0.8183\n",
      "[244/1762] D loss: 1.3987, G loss: 0.8764\n",
      "[324/1762] D loss: 1.4492, G loss: 0.7054\n",
      "[404/1762] D loss: 1.4429, G loss: 0.6802\n",
      "[484/1762] D loss: 0.0258, G loss: 3.9121\n",
      "[564/1762] D loss: 1.4094, G loss: 0.6226\n",
      "[644/1762] D loss: 1.3725, G loss: 0.7674\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7297\n",
      "[804/1762] D loss: 1.4479, G loss: 0.8315\n",
      "[884/1762] D loss: 0.0719, G loss: 3.4668\n",
      "[964/1762] D loss: 1.4105, G loss: 0.5975\n",
      "[1044/1762] D loss: 1.4669, G loss: 0.5561\n",
      "[1124/1762] D loss: 0.0863, G loss: 2.3728\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.7654\n",
      "[1284/1762] D loss: 0.1291, G loss: 2.1479\n",
      "[1364/1762] D loss: 0.0784, G loss: 2.7664\n",
      "[1444/1762] D loss: 0.1497, G loss: 2.2081\n",
      "[1524/1762] D loss: 0.0067, G loss: 5.0973\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.7670\n",
      "[1684/1762] D loss: 1.3972, G loss: 0.7234\n",
      "[1762/1762] D loss: 1.4280, G loss: 0.8031\n",
      "train error: \n",
      " D loss: 1.363469, G loss: 0.561380, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346776, G loss: 0.572618, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.6177\n",
      "[84/1762] D loss: 0.0103, G loss: 4.8974\n",
      "[164/1762] D loss: 1.3929, G loss: 0.8194\n",
      "[244/1762] D loss: 1.5174, G loss: 1.0132\n",
      "[324/1762] D loss: 0.0560, G loss: 3.3221\n",
      "[404/1762] D loss: 1.5118, G loss: 0.5655\n",
      "[484/1762] D loss: 1.4367, G loss: 0.7673\n",
      "[564/1762] D loss: 1.4040, G loss: 0.6245\n",
      "[644/1762] D loss: 1.4422, G loss: 0.9210\n",
      "[724/1762] D loss: 1.4012, G loss: 0.8149\n",
      "[804/1762] D loss: 1.4122, G loss: 0.6327\n",
      "[884/1762] D loss: 0.1933, G loss: 1.9315\n",
      "[964/1762] D loss: 1.4234, G loss: 0.8202\n",
      "[1044/1762] D loss: 0.1267, G loss: 2.3715\n",
      "[1124/1762] D loss: 0.0934, G loss: 2.5970\n",
      "[1204/1762] D loss: 1.3972, G loss: 0.6187\n",
      "[1284/1762] D loss: 1.4126, G loss: 0.6200\n",
      "[1364/1762] D loss: 0.0716, G loss: 2.6769\n",
      "[1444/1762] D loss: 1.3977, G loss: 0.6916\n",
      "[1524/1762] D loss: 0.0010, G loss: 8.3471\n",
      "[1604/1762] D loss: 1.4145, G loss: 0.6344\n",
      "[1684/1762] D loss: 1.3955, G loss: 0.6654\n",
      "[1762/1762] D loss: 1.4073, G loss: 0.5996\n",
      "train error: \n",
      " D loss: 1.284832, G loss: 0.912556, D accuracy: 54.4%, cell accuracy: 99.5%, board accuracy: 77.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270325, G loss: 0.908130, D accuracy: 56.0%, cell accuracy: 99.4%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5289, G loss: 0.6756\n",
      "[84/1762] D loss: 1.7070, G loss: 0.4612\n",
      "[164/1762] D loss: 1.4206, G loss: 0.6211\n",
      "[244/1762] D loss: 1.3144, G loss: 0.8315\n",
      "[324/1762] D loss: 1.4317, G loss: 0.7252\n",
      "[404/1762] D loss: 1.3928, G loss: 0.7245\n",
      "[484/1762] D loss: 1.5141, G loss: 0.9485\n",
      "[564/1762] D loss: 1.3961, G loss: 0.6335\n",
      "[644/1762] D loss: 0.3307, G loss: 1.4359\n",
      "[724/1762] D loss: 1.3992, G loss: 0.8356\n",
      "[804/1762] D loss: 1.3125, G loss: 0.7064\n",
      "[884/1762] D loss: 1.3887, G loss: 0.7471\n",
      "[964/1762] D loss: 1.3966, G loss: 0.6101\n",
      "[1044/1762] D loss: 1.3958, G loss: 0.5215\n",
      "[1124/1762] D loss: 1.4204, G loss: 0.6289\n",
      "[1204/1762] D loss: 1.4509, G loss: 0.9532\n",
      "[1284/1762] D loss: 0.1077, G loss: 2.4555\n",
      "[1364/1762] D loss: 1.4121, G loss: 0.6983\n",
      "[1444/1762] D loss: 1.5037, G loss: 0.4781\n",
      "[1524/1762] D loss: 1.3898, G loss: 0.8095\n",
      "[1604/1762] D loss: 1.4147, G loss: 0.6423\n",
      "[1684/1762] D loss: 1.4354, G loss: 0.9518\n",
      "[1762/1762] D loss: 1.4014, G loss: 0.7555\n",
      "train error: \n",
      " D loss: 1.553608, G loss: 0.355283, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.549809, G loss: 0.356361, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1495, G loss: 2.1697\n",
      "[84/1762] D loss: 0.0725, G loss: 2.8444\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6353\n",
      "[244/1762] D loss: 0.0728, G loss: 2.9302\n",
      "[324/1762] D loss: 1.4222, G loss: 0.8179\n",
      "[404/1762] D loss: 1.3951, G loss: 0.6907\n",
      "[484/1762] D loss: 0.1162, G loss: 2.4208\n",
      "[564/1762] D loss: 0.0556, G loss: 3.1035\n",
      "[644/1762] D loss: 1.4037, G loss: 0.8407\n",
      "[724/1762] D loss: 0.1195, G loss: 2.2535\n",
      "[804/1762] D loss: 0.0579, G loss: 3.1889\n",
      "[884/1762] D loss: 0.0916, G loss: 2.6965\n",
      "[964/1762] D loss: 1.4064, G loss: 0.8688\n",
      "[1044/1762] D loss: 1.4291, G loss: 0.8018\n",
      "[1124/1762] D loss: 1.4252, G loss: 0.8028\n",
      "[1204/1762] D loss: 1.4058, G loss: 0.7025\n",
      "[1284/1762] D loss: 0.0999, G loss: 2.6007\n",
      "[1364/1762] D loss: 1.4007, G loss: 0.7044\n",
      "[1444/1762] D loss: 0.1058, G loss: 2.4699\n",
      "[1524/1762] D loss: 1.3937, G loss: 0.7154\n",
      "[1604/1762] D loss: 1.4116, G loss: 0.8378\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6931\n",
      "[1762/1762] D loss: 1.4434, G loss: 0.8373\n",
      "train error: \n",
      " D loss: 1.346033, G loss: 0.602682, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328843, G loss: 0.615320, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4218, G loss: 0.8002\n",
      "[84/1762] D loss: 1.3876, G loss: 0.8090\n",
      "[164/1762] D loss: 0.0987, G loss: 2.4295\n",
      "[244/1762] D loss: 0.0766, G loss: 2.8243\n",
      "[324/1762] D loss: 1.4347, G loss: 0.8197\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6659\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6731\n",
      "[564/1762] D loss: 1.3933, G loss: 0.7205\n",
      "[644/1762] D loss: 0.2945, G loss: 1.5554\n",
      "[724/1762] D loss: 1.4138, G loss: 0.6132\n",
      "[804/1762] D loss: 0.9277, G loss: 1.7871\n",
      "[884/1762] D loss: 1.6351, G loss: 0.6196\n",
      "[964/1762] D loss: 0.1090, G loss: 2.9294\n",
      "[1044/1762] D loss: 1.5895, G loss: 0.9273\n",
      "[1124/1762] D loss: 1.4779, G loss: 1.1901\n",
      "[1204/1762] D loss: 1.4549, G loss: 0.7380\n",
      "[1284/1762] D loss: 1.4914, G loss: 0.9163\n",
      "[1364/1762] D loss: 1.3971, G loss: 0.7430\n",
      "[1444/1762] D loss: 1.4145, G loss: 0.8534\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.8062\n",
      "[1604/1762] D loss: 1.3828, G loss: 0.6023\n",
      "[1684/1762] D loss: 1.3848, G loss: 0.7479\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7029\n",
      "train error: \n",
      " D loss: 1.347301, G loss: 0.765212, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342873, G loss: 0.781974, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4511, G loss: 0.9247\n",
      "[84/1762] D loss: 0.0927, G loss: 2.5663\n",
      "[164/1762] D loss: 1.4429, G loss: 0.9160\n",
      "[244/1762] D loss: 0.0343, G loss: 3.4512\n",
      "[324/1762] D loss: 1.5650, G loss: 1.2362\n",
      "[404/1762] D loss: 1.3993, G loss: 0.8051\n",
      "[484/1762] D loss: 1.4155, G loss: 0.7391\n",
      "[564/1762] D loss: 0.0815, G loss: 2.3703\n",
      "[644/1762] D loss: 0.2465, G loss: 1.6847\n",
      "[724/1762] D loss: 1.4127, G loss: 0.7144\n",
      "[804/1762] D loss: 1.4234, G loss: 0.7422\n",
      "[884/1762] D loss: 0.0871, G loss: 2.6385\n",
      "[964/1762] D loss: 0.0121, G loss: 4.4186\n",
      "[1044/1762] D loss: 0.0800, G loss: 2.7755\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.6741\n",
      "[1204/1762] D loss: 1.4168, G loss: 0.7741\n",
      "[1284/1762] D loss: 1.4031, G loss: 0.6124\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.8486\n",
      "[1444/1762] D loss: 0.1093, G loss: 2.4298\n",
      "[1524/1762] D loss: 1.3229, G loss: 0.8513\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7180\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6378\n",
      "[1762/1762] D loss: 1.3921, G loss: 0.6987\n",
      "train error: \n",
      " D loss: 1.373529, G loss: 1.023783, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347372, G loss: 1.019348, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4884, G loss: 0.9895\n",
      "[84/1762] D loss: 1.4799, G loss: 0.5469\n",
      "[164/1762] D loss: 1.3918, G loss: 0.7124\n",
      "[244/1762] D loss: 1.3916, G loss: 0.7759\n",
      "[324/1762] D loss: 1.4175, G loss: 0.8244\n",
      "[404/1762] D loss: 1.4173, G loss: 0.8494\n",
      "[484/1762] D loss: 1.3938, G loss: 0.6111\n",
      "[564/1762] D loss: 1.4908, G loss: 0.9283\n",
      "[644/1762] D loss: 0.0865, G loss: 2.6490\n",
      "[724/1762] D loss: 1.3908, G loss: 0.7822\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6312\n",
      "[884/1762] D loss: 0.0887, G loss: 2.8272\n",
      "[964/1762] D loss: 0.1249, G loss: 2.1596\n",
      "[1044/1762] D loss: 1.3968, G loss: 0.8516\n",
      "[1124/1762] D loss: 1.4199, G loss: 0.5992\n",
      "[1204/1762] D loss: 1.3813, G loss: 0.7285\n",
      "[1284/1762] D loss: 1.4574, G loss: 0.5035\n",
      "[1364/1762] D loss: 1.4509, G loss: 0.8526\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7260\n",
      "[1524/1762] D loss: 0.1817, G loss: 2.1545\n",
      "[1604/1762] D loss: 1.4117, G loss: 0.7937\n",
      "[1684/1762] D loss: 0.0919, G loss: 2.4515\n",
      "[1762/1762] D loss: 1.4267, G loss: 0.6876\n",
      "train error: \n",
      " D loss: 2.529224, G loss: 0.105912, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.498854, G loss: 0.109624, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.8394\n",
      "[84/1762] D loss: 0.0901, G loss: 2.7380\n",
      "[164/1762] D loss: 0.1215, G loss: 2.1270\n",
      "[244/1762] D loss: 1.4821, G loss: 0.9456\n",
      "[324/1762] D loss: 1.3948, G loss: 0.7962\n",
      "[404/1762] D loss: 1.8131, G loss: 0.5248\n",
      "[484/1762] D loss: 1.3954, G loss: 0.6141\n",
      "[564/1762] D loss: 1.5023, G loss: 0.4523\n",
      "[644/1762] D loss: 1.4641, G loss: 0.9574\n",
      "[724/1762] D loss: 1.5140, G loss: 0.5764\n",
      "[804/1762] D loss: 1.5719, G loss: 1.1058\n",
      "[884/1762] D loss: 1.4536, G loss: 0.5809\n",
      "[964/1762] D loss: 0.1429, G loss: 2.1476\n",
      "[1044/1762] D loss: 1.5704, G loss: 0.9990\n",
      "[1124/1762] D loss: 1.4169, G loss: 0.6630\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.7584\n",
      "[1284/1762] D loss: 1.4111, G loss: 0.8100\n",
      "[1364/1762] D loss: 1.4774, G loss: 0.5377\n",
      "[1444/1762] D loss: 0.2039, G loss: 2.1263\n",
      "[1524/1762] D loss: 0.0094, G loss: 4.8307\n",
      "[1604/1762] D loss: 0.1211, G loss: 2.2882\n",
      "[1684/1762] D loss: 1.4174, G loss: 0.5794\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.6308\n",
      "train error: \n",
      " D loss: 1.339499, G loss: 0.740162, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332115, G loss: 0.735299, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4020, G loss: 0.6239\n",
      "[84/1762] D loss: 1.3995, G loss: 0.7044\n",
      "[164/1762] D loss: 0.1869, G loss: 2.0012\n",
      "[244/1762] D loss: 1.5247, G loss: 1.1101\n",
      "[324/1762] D loss: 1.4075, G loss: 0.7638\n",
      "[404/1762] D loss: 1.4087, G loss: 0.6864\n",
      "[484/1762] D loss: 1.3798, G loss: 0.8063\n",
      "[564/1762] D loss: 1.3941, G loss: 0.5792\n",
      "[644/1762] D loss: 1.5172, G loss: 0.9362\n",
      "[724/1762] D loss: 1.4206, G loss: 0.8258\n",
      "[804/1762] D loss: 1.3895, G loss: 0.6619\n",
      "[884/1762] D loss: 1.3985, G loss: 0.7790\n",
      "[964/1762] D loss: 1.3964, G loss: 0.7877\n",
      "[1044/1762] D loss: 1.4091, G loss: 0.6897\n",
      "[1124/1762] D loss: 0.0841, G loss: 2.7244\n",
      "[1204/1762] D loss: 1.4005, G loss: 0.7803\n",
      "[1284/1762] D loss: 0.1669, G loss: 2.0167\n",
      "[1364/1762] D loss: 0.0073, G loss: 5.2864\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7402\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.7169\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.7094\n",
      "[1684/1762] D loss: 0.0742, G loss: 2.8997\n",
      "[1762/1762] D loss: 0.0191, G loss: 4.2161\n",
      "train error: \n",
      " D loss: 2.823492, G loss: 0.082909, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.792024, G loss: 0.090313, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.5781\n",
      "[84/1762] D loss: 0.0866, G loss: 2.9860\n",
      "[164/1762] D loss: 1.4470, G loss: 0.4563\n",
      "[244/1762] D loss: 1.3878, G loss: 0.7882\n",
      "[324/1762] D loss: 1.4034, G loss: 0.7682\n",
      "[404/1762] D loss: 0.1190, G loss: 2.2455\n",
      "[484/1762] D loss: 1.3925, G loss: 0.6983\n",
      "[564/1762] D loss: 0.0971, G loss: 2.4503\n",
      "[644/1762] D loss: 0.2344, G loss: 1.7930\n",
      "[724/1762] D loss: 0.1065, G loss: 2.3721\n",
      "[804/1762] D loss: 0.0800, G loss: 2.5949\n",
      "[884/1762] D loss: 1.3905, G loss: 0.7354\n",
      "[964/1762] D loss: 1.3915, G loss: 0.6972\n",
      "[1044/1762] D loss: 1.3944, G loss: 0.7046\n",
      "[1124/1762] D loss: 1.4201, G loss: 0.7100\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.6544\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.5913\n",
      "[1364/1762] D loss: 1.3975, G loss: 0.7791\n",
      "[1444/1762] D loss: 1.4062, G loss: 0.5778\n",
      "[1524/1762] D loss: 0.0922, G loss: 2.6658\n",
      "[1604/1762] D loss: 0.1114, G loss: 2.3311\n",
      "[1684/1762] D loss: 1.4045, G loss: 0.7505\n",
      "[1762/1762] D loss: 0.0060, G loss: 5.4188\n",
      "train error: \n",
      " D loss: 2.956803, G loss: 0.071604, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.926383, G loss: 0.076411, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1140, G loss: 2.3203\n",
      "[84/1762] D loss: 1.4047, G loss: 0.7976\n",
      "[164/1762] D loss: 1.3889, G loss: 0.7729\n",
      "[244/1762] D loss: 1.4021, G loss: 0.6946\n",
      "[324/1762] D loss: 0.1207, G loss: 2.2972\n",
      "[404/1762] D loss: 0.1079, G loss: 2.3232\n",
      "[484/1762] D loss: 1.3891, G loss: 0.8359\n",
      "[564/1762] D loss: 1.7864, G loss: 0.3201\n",
      "[644/1762] D loss: 1.4502, G loss: 0.7543\n",
      "[724/1762] D loss: 1.4495, G loss: 0.5350\n",
      "[804/1762] D loss: 1.4145, G loss: 0.7656\n",
      "[884/1762] D loss: 1.3890, G loss: 0.6882\n",
      "[964/1762] D loss: 0.1322, G loss: 2.2513\n",
      "[1044/1762] D loss: 0.0888, G loss: 2.4978\n",
      "[1124/1762] D loss: 1.3941, G loss: 0.6068\n",
      "[1204/1762] D loss: 1.4058, G loss: 0.7159\n",
      "[1284/1762] D loss: 1.3334, G loss: 0.5481\n",
      "[1364/1762] D loss: 1.4056, G loss: 0.7814\n",
      "[1444/1762] D loss: 1.3888, G loss: 0.7399\n",
      "[1524/1762] D loss: 0.1555, G loss: 2.0115\n",
      "[1604/1762] D loss: 0.0762, G loss: 2.8058\n",
      "[1684/1762] D loss: 1.3933, G loss: 0.6406\n",
      "[1762/1762] D loss: 1.5967, G loss: 1.0523\n",
      "train error: \n",
      " D loss: 1.772143, G loss: 0.261564, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.747086, G loss: 0.278767, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0859, G loss: 2.4413\n",
      "[84/1762] D loss: 1.4133, G loss: 0.6106\n",
      "[164/1762] D loss: 1.3930, G loss: 0.6009\n",
      "[244/1762] D loss: 1.4057, G loss: 0.7736\n",
      "[324/1762] D loss: 1.3944, G loss: 0.6916\n",
      "[404/1762] D loss: 0.1235, G loss: 2.2609\n",
      "[484/1762] D loss: 1.4147, G loss: 0.8684\n",
      "[564/1762] D loss: 0.0637, G loss: 2.9872\n",
      "[644/1762] D loss: 0.0620, G loss: 2.9990\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6743\n",
      "[804/1762] D loss: 0.1190, G loss: 2.1067\n",
      "[884/1762] D loss: 1.3912, G loss: 0.7551\n",
      "[964/1762] D loss: 1.4125, G loss: 0.5842\n",
      "[1044/1762] D loss: 1.3982, G loss: 0.9265\n",
      "[1124/1762] D loss: 1.0520, G loss: 1.0255\n",
      "[1204/1762] D loss: 1.4332, G loss: 0.7087\n",
      "[1284/1762] D loss: 0.1483, G loss: 2.2755\n",
      "[1364/1762] D loss: 1.4086, G loss: 0.6070\n",
      "[1444/1762] D loss: 1.4095, G loss: 0.6146\n",
      "[1524/1762] D loss: 1.3963, G loss: 0.7289\n",
      "[1604/1762] D loss: 1.4023, G loss: 0.9168\n",
      "[1684/1762] D loss: 1.4851, G loss: 0.4712\n",
      "[1762/1762] D loss: 1.3971, G loss: 0.8466\n",
      "train error: \n",
      " D loss: 1.528723, G loss: 0.377274, D accuracy: 51.8%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.507794, G loss: 0.384510, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4498, G loss: 0.9424\n",
      "[84/1762] D loss: 1.4522, G loss: 0.4965\n",
      "[164/1762] D loss: 0.0335, G loss: 3.7956\n",
      "[244/1762] D loss: 1.4235, G loss: 0.9665\n",
      "[324/1762] D loss: 1.3977, G loss: 0.7378\n",
      "[404/1762] D loss: 1.3893, G loss: 0.7078\n",
      "[484/1762] D loss: 0.0867, G loss: 3.0578\n",
      "[564/1762] D loss: 0.0879, G loss: 2.6415\n",
      "[644/1762] D loss: 0.1014, G loss: 2.4134\n",
      "[724/1762] D loss: 1.3892, G loss: 0.7322\n",
      "[804/1762] D loss: 0.1366, G loss: 2.2113\n",
      "[884/1762] D loss: 1.3915, G loss: 0.7642\n",
      "[964/1762] D loss: 1.3944, G loss: 0.5980\n",
      "[1044/1762] D loss: 0.0968, G loss: 2.7068\n",
      "[1124/1762] D loss: 0.0054, G loss: 5.6212\n",
      "[1204/1762] D loss: 1.4104, G loss: 0.6807\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.8000\n",
      "[1364/1762] D loss: 0.0710, G loss: 2.7270\n",
      "[1444/1762] D loss: 0.1777, G loss: 1.9999\n",
      "[1524/1762] D loss: 1.3680, G loss: 0.7340\n",
      "[1604/1762] D loss: 0.0890, G loss: 2.6021\n",
      "[1684/1762] D loss: 0.0713, G loss: 2.8309\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6418\n",
      "train error: \n",
      " D loss: 1.412664, G loss: 0.474766, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395176, G loss: 0.485314, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3950, G loss: 0.6586\n",
      "[84/1762] D loss: 0.0662, G loss: 2.7785\n",
      "[164/1762] D loss: 1.3887, G loss: 0.7196\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6831\n",
      "[324/1762] D loss: 1.3918, G loss: 0.7201\n",
      "[404/1762] D loss: 1.4585, G loss: 0.9567\n",
      "[484/1762] D loss: 1.4292, G loss: 0.9053\n",
      "[564/1762] D loss: 1.3996, G loss: 0.6990\n",
      "[644/1762] D loss: 1.4143, G loss: 0.6540\n",
      "[724/1762] D loss: 1.3909, G loss: 0.6515\n",
      "[804/1762] D loss: 1.3976, G loss: 0.7867\n",
      "[884/1762] D loss: 1.3922, G loss: 0.7616\n",
      "[964/1762] D loss: 1.4417, G loss: 0.8588\n",
      "[1044/1762] D loss: 1.4806, G loss: 0.4566\n",
      "[1124/1762] D loss: 1.5593, G loss: 0.5138\n",
      "[1204/1762] D loss: 1.5330, G loss: 0.9264\n",
      "[1284/1762] D loss: 1.5043, G loss: 0.3717\n",
      "[1364/1762] D loss: 1.4802, G loss: 0.9513\n",
      "[1444/1762] D loss: 0.1785, G loss: 2.1875\n",
      "[1524/1762] D loss: 1.3976, G loss: 0.7616\n",
      "[1604/1762] D loss: 0.0594, G loss: 2.9758\n",
      "[1684/1762] D loss: 1.3708, G loss: 0.6311\n",
      "[1762/1762] D loss: 1.5373, G loss: 0.4552\n",
      "train error: \n",
      " D loss: 2.068419, G loss: 0.179423, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.049584, G loss: 0.187214, D accuracy: 50.6%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4235, G loss: 0.8385\n",
      "[84/1762] D loss: 1.3576, G loss: 0.8308\n",
      "[164/1762] D loss: 1.2223, G loss: 0.9341\n",
      "[244/1762] D loss: 1.1816, G loss: 1.0210\n",
      "[324/1762] D loss: 1.0281, G loss: 1.1059\n",
      "[404/1762] D loss: 0.8973, G loss: 1.2429\n",
      "[484/1762] D loss: 0.7920, G loss: 1.2966\n",
      "[564/1762] D loss: 0.7057, G loss: 1.4153\n",
      "[644/1762] D loss: 0.5971, G loss: 1.6654\n",
      "[724/1762] D loss: 0.5378, G loss: 1.5775\n",
      "[804/1762] D loss: 0.4509, G loss: 1.9101\n",
      "[884/1762] D loss: 0.3522, G loss: 2.2555\n",
      "[964/1762] D loss: 0.2725, G loss: 2.3982\n",
      "[1044/1762] D loss: 0.3387, G loss: 2.3871\n",
      "[1124/1762] D loss: 0.2378, G loss: 2.4809\n",
      "[1204/1762] D loss: 0.2273, G loss: 2.6234\n",
      "[1284/1762] D loss: 0.1689, G loss: 3.0102\n",
      "[1364/1762] D loss: 0.1399, G loss: 2.8165\n",
      "[1444/1762] D loss: 0.1625, G loss: 3.0989\n",
      "[1524/1762] D loss: 0.1116, G loss: 3.1176\n",
      "[1604/1762] D loss: 0.1267, G loss: 2.9687\n",
      "[1684/1762] D loss: 0.0928, G loss: 3.4204\n",
      "[1762/1762] D loss: 0.0744, G loss: 3.6821\n",
      "train error: \n",
      " D loss: 0.233417, G loss: 3.460571, D accuracy: 100.0%, cell accuracy: 57.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.234507, G loss: 3.448826, D accuracy: 100.0%, cell accuracy: 59.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0931, G loss: 3.3711\n",
      "[84/1762] D loss: 0.0881, G loss: 3.3382\n",
      "[164/1762] D loss: 0.0641, G loss: 3.7453\n",
      "[244/1762] D loss: 0.0902, G loss: 3.1699\n",
      "[324/1762] D loss: 0.0477, G loss: 3.9323\n",
      "[404/1762] D loss: 0.0576, G loss: 3.8678\n",
      "[484/1762] D loss: 0.0449, G loss: 4.0046\n",
      "[564/1762] D loss: 0.0629, G loss: 3.4914\n",
      "[644/1762] D loss: 0.0481, G loss: 3.7433\n",
      "[724/1762] D loss: 0.0449, G loss: 4.0197\n",
      "[804/1762] D loss: 0.0422, G loss: 4.0964\n",
      "[884/1762] D loss: 0.0487, G loss: 3.9527\n",
      "[964/1762] D loss: 0.0366, G loss: 4.4735\n",
      "[1044/1762] D loss: 0.0354, G loss: 4.4540\n",
      "[1124/1762] D loss: 0.0418, G loss: 4.1544\n",
      "[1204/1762] D loss: 0.0320, G loss: 4.2600\n",
      "[1284/1762] D loss: 0.0263, G loss: 4.5886\n",
      "[1364/1762] D loss: 0.0250, G loss: 4.4301\n",
      "[1444/1762] D loss: 0.0265, G loss: 4.5835\n",
      "[1524/1762] D loss: 0.0349, G loss: 4.5247\n",
      "[1604/1762] D loss: 0.0323, G loss: 4.8892\n",
      "[1684/1762] D loss: 0.0244, G loss: 4.8354\n",
      "[1762/1762] D loss: 0.0295, G loss: 4.1625\n",
      "train error: \n",
      " D loss: 0.569338, G loss: 4.338695, D accuracy: 92.9%, cell accuracy: 65.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.577458, G loss: 4.312892, D accuracy: 93.1%, cell accuracy: 66.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0293, G loss: 4.6224\n",
      "[84/1762] D loss: 0.0263, G loss: 4.5309\n",
      "[164/1762] D loss: 0.0206, G loss: 4.8474\n",
      "[244/1762] D loss: 0.0156, G loss: 4.9526\n",
      "[324/1762] D loss: 0.0253, G loss: 4.7711\n",
      "[404/1762] D loss: 0.0205, G loss: 4.9363\n",
      "[484/1762] D loss: 0.0177, G loss: 4.8251\n",
      "[564/1762] D loss: 0.0188, G loss: 4.9878\n",
      "[644/1762] D loss: 0.0122, G loss: 5.1130\n",
      "[724/1762] D loss: 0.0185, G loss: 4.6630\n",
      "[804/1762] D loss: 0.0207, G loss: 4.6248\n",
      "[884/1762] D loss: 0.0173, G loss: 4.8739\n",
      "[964/1762] D loss: 0.0113, G loss: 5.3284\n",
      "[1044/1762] D loss: 0.0106, G loss: 5.2892\n",
      "[1124/1762] D loss: 0.0213, G loss: 4.6749\n",
      "[1204/1762] D loss: 0.0161, G loss: 5.4691\n",
      "[1284/1762] D loss: 0.0134, G loss: 5.3004\n",
      "[1364/1762] D loss: 0.0320, G loss: 4.0439\n",
      "[1444/1762] D loss: 0.0156, G loss: 5.0704\n",
      "[1524/1762] D loss: 0.0218, G loss: 4.8001\n",
      "[1604/1762] D loss: 0.0154, G loss: 5.4147\n",
      "[1684/1762] D loss: 0.0203, G loss: 4.8488\n",
      "[1762/1762] D loss: 0.0111, G loss: 5.4457\n",
      "train error: \n",
      " D loss: 0.900265, G loss: 4.153852, D accuracy: 59.6%, cell accuracy: 87.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.907010, G loss: 4.229626, D accuracy: 60.8%, cell accuracy: 86.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0176, G loss: 5.2035\n",
      "[84/1762] D loss: 0.0245, G loss: 5.1023\n",
      "[164/1762] D loss: 0.0187, G loss: 4.9378\n",
      "[244/1762] D loss: 0.0234, G loss: 6.0280\n",
      "[324/1762] D loss: 0.0221, G loss: 4.8444\n",
      "[404/1762] D loss: 0.0135, G loss: 5.5837\n",
      "[484/1762] D loss: 0.0211, G loss: 5.1094\n",
      "[564/1762] D loss: 0.0133, G loss: 5.5001\n",
      "[644/1762] D loss: 0.0128, G loss: 5.3330\n",
      "[724/1762] D loss: 0.0069, G loss: 5.8669\n",
      "[804/1762] D loss: 0.0168, G loss: 6.7942\n",
      "[884/1762] D loss: 0.0049, G loss: 6.1447\n",
      "[964/1762] D loss: 0.0152, G loss: 5.1430\n",
      "[1044/1762] D loss: 0.0062, G loss: 6.1362\n",
      "[1124/1762] D loss: 0.0256, G loss: 5.1515\n",
      "[1204/1762] D loss: 0.0074, G loss: 6.0234\n",
      "[1284/1762] D loss: 0.0071, G loss: 5.8441\n",
      "[1364/1762] D loss: 0.0096, G loss: 5.2421\n",
      "[1444/1762] D loss: 0.0148, G loss: 5.4117\n",
      "[1524/1762] D loss: 0.0137, G loss: 5.5351\n",
      "[1604/1762] D loss: 0.0756, G loss: 4.1385\n",
      "[1684/1762] D loss: 0.0146, G loss: 4.8439\n",
      "[1762/1762] D loss: 0.0221, G loss: 4.4075\n",
      "train error: \n",
      " D loss: 0.653576, G loss: 3.991922, D accuracy: 84.2%, cell accuracy: 96.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.662534, G loss: 3.941717, D accuracy: 82.3%, cell accuracy: 96.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0213, G loss: 5.5244\n",
      "[84/1762] D loss: 0.0838, G loss: 3.7931\n",
      "[164/1762] D loss: 0.0304, G loss: 6.9113\n",
      "[244/1762] D loss: 0.0083, G loss: 5.8470\n",
      "[324/1762] D loss: 0.0106, G loss: 6.3788\n",
      "[404/1762] D loss: 0.0249, G loss: 4.4314\n",
      "[484/1762] D loss: 0.1829, G loss: 4.0644\n",
      "[564/1762] D loss: 0.0154, G loss: 5.1354\n",
      "[644/1762] D loss: 0.0422, G loss: 6.9012\n",
      "[724/1762] D loss: 0.1234, G loss: 6.3392\n",
      "[804/1762] D loss: 0.1014, G loss: 3.3746\n",
      "[884/1762] D loss: 0.0276, G loss: 4.6081\n",
      "[964/1762] D loss: 0.1185, G loss: 3.1351\n",
      "[1044/1762] D loss: 0.1749, G loss: 2.6912\n",
      "[1124/1762] D loss: 0.1355, G loss: 2.8037\n",
      "[1204/1762] D loss: 0.0173, G loss: 5.4282\n",
      "[1284/1762] D loss: 0.1404, G loss: 3.6867\n",
      "[1364/1762] D loss: 0.0852, G loss: 6.3673\n",
      "[1444/1762] D loss: 0.1092, G loss: 3.2644\n",
      "[1524/1762] D loss: 0.1374, G loss: 2.7954\n",
      "[1604/1762] D loss: 0.1641, G loss: 3.9304\n",
      "[1684/1762] D loss: 0.1496, G loss: 3.6476\n",
      "[1762/1762] D loss: 0.3792, G loss: 1.4815\n",
      "train error: \n",
      " D loss: 0.737733, G loss: 3.317259, D accuracy: 80.3%, cell accuracy: 98.2%, board accuracy: 7.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.701441, G loss: 3.417597, D accuracy: 80.0%, cell accuracy: 98.2%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1083, G loss: 4.0490\n",
      "[84/1762] D loss: 0.5487, G loss: 2.0157\n",
      "[164/1762] D loss: 0.1282, G loss: 2.6899\n",
      "[244/1762] D loss: 0.3212, G loss: 2.1941\n",
      "[324/1762] D loss: 0.2539, G loss: 3.1838\n",
      "[404/1762] D loss: 0.3112, G loss: 1.7852\n",
      "[484/1762] D loss: 0.2095, G loss: 1.7942\n",
      "[564/1762] D loss: 0.4116, G loss: 1.8160\n",
      "[644/1762] D loss: 0.2918, G loss: 1.6776\n",
      "[724/1762] D loss: 0.2852, G loss: 2.2960\n",
      "[804/1762] D loss: 0.2426, G loss: 3.1780\n",
      "[884/1762] D loss: 0.4013, G loss: 1.9386\n",
      "[964/1762] D loss: 0.5078, G loss: 1.7073\n",
      "[1044/1762] D loss: 0.4774, G loss: 0.7338\n",
      "[1124/1762] D loss: 0.2934, G loss: 2.7821\n",
      "[1204/1762] D loss: 0.3427, G loss: 2.6596\n",
      "[1284/1762] D loss: 0.3035, G loss: 3.3438\n",
      "[1364/1762] D loss: 0.4674, G loss: 2.9744\n",
      "[1444/1762] D loss: 0.3920, G loss: 2.6625\n",
      "[1524/1762] D loss: 0.4512, G loss: 1.8278\n",
      "[1604/1762] D loss: 0.4239, G loss: 3.3747\n",
      "[1684/1762] D loss: 0.4346, G loss: 2.7790\n",
      "[1762/1762] D loss: 0.6017, G loss: 1.5398\n",
      "train error: \n",
      " D loss: 0.815316, G loss: 1.484361, D accuracy: 85.4%, cell accuracy: 99.6%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.828186, G loss: 1.407058, D accuracy: 83.5%, cell accuracy: 99.5%, board accuracy: 57.3% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2958, G loss: 3.4465\n",
      "[84/1762] D loss: 0.5692, G loss: 2.2882\n",
      "[164/1762] D loss: 0.4648, G loss: 2.3763\n",
      "[244/1762] D loss: 0.3707, G loss: 1.2511\n",
      "[324/1762] D loss: 0.5860, G loss: 1.3797\n",
      "[404/1762] D loss: 0.6058, G loss: 1.7418\n",
      "[484/1762] D loss: 0.5197, G loss: 1.6163\n",
      "[564/1762] D loss: 0.5525, G loss: 1.6668\n",
      "[644/1762] D loss: 0.7831, G loss: 2.9283\n",
      "[724/1762] D loss: 0.4596, G loss: 2.6312\n",
      "[804/1762] D loss: 0.8643, G loss: 2.9264\n",
      "[884/1762] D loss: 0.5241, G loss: 1.8105\n",
      "[964/1762] D loss: 0.7361, G loss: 1.5445\n",
      "[1044/1762] D loss: 0.5614, G loss: 1.2172\n",
      "[1124/1762] D loss: 1.2680, G loss: 1.0421\n",
      "[1204/1762] D loss: 0.6351, G loss: 1.8580\n",
      "[1284/1762] D loss: 0.7154, G loss: 0.9367\n",
      "[1364/1762] D loss: 0.6634, G loss: 1.9431\n",
      "[1444/1762] D loss: 1.0687, G loss: 0.7163\n",
      "[1524/1762] D loss: 0.7999, G loss: 1.6687\n",
      "[1604/1762] D loss: 0.5162, G loss: 0.9728\n",
      "[1684/1762] D loss: 0.8415, G loss: 1.1272\n",
      "[1762/1762] D loss: 0.7896, G loss: 0.8893\n",
      "train error: \n",
      " D loss: 0.974559, G loss: 1.043123, D accuracy: 82.1%, cell accuracy: 99.6%, board accuracy: 67.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.985497, G loss: 1.032771, D accuracy: 80.2%, cell accuracy: 99.6%, board accuracy: 65.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4537, G loss: 1.6243\n",
      "[84/1762] D loss: 1.1248, G loss: 1.9142\n",
      "[164/1762] D loss: 0.6763, G loss: 1.3797\n",
      "[244/1762] D loss: 1.5250, G loss: 2.8277\n",
      "[324/1762] D loss: 0.8791, G loss: 2.7287\n",
      "[404/1762] D loss: 0.6573, G loss: 2.1233\n",
      "[484/1762] D loss: 0.6106, G loss: 1.7593\n",
      "[564/1762] D loss: 0.7186, G loss: 2.2171\n",
      "[644/1762] D loss: 0.9560, G loss: 0.8354\n",
      "[724/1762] D loss: 0.8891, G loss: 0.4720\n",
      "[804/1762] D loss: 0.7000, G loss: 1.5105\n",
      "[884/1762] D loss: 0.4400, G loss: 1.9039\n",
      "[964/1762] D loss: 1.0506, G loss: 0.6109\n",
      "[1044/1762] D loss: 0.7201, G loss: 1.4959\n",
      "[1124/1762] D loss: 0.8948, G loss: 0.8883\n",
      "[1204/1762] D loss: 1.3577, G loss: 2.3386\n",
      "[1284/1762] D loss: 1.0441, G loss: 1.2487\n",
      "[1364/1762] D loss: 0.7844, G loss: 0.9694\n",
      "[1444/1762] D loss: 0.8584, G loss: 2.8093\n",
      "[1524/1762] D loss: 0.7296, G loss: 1.6871\n",
      "[1604/1762] D loss: 0.9421, G loss: 1.3926\n",
      "[1684/1762] D loss: 0.9743, G loss: 1.6374\n",
      "[1762/1762] D loss: 1.0504, G loss: 1.2561\n",
      "train error: \n",
      " D loss: 1.076065, G loss: 0.876511, D accuracy: 75.3%, cell accuracy: 99.7%, board accuracy: 73.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.096908, G loss: 0.866106, D accuracy: 71.0%, cell accuracy: 99.6%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8634, G loss: 0.9925\n",
      "[84/1762] D loss: 1.3845, G loss: 0.4029\n",
      "[164/1762] D loss: 0.7720, G loss: 1.0902\n",
      "[244/1762] D loss: 1.2165, G loss: 1.2530\n",
      "[324/1762] D loss: 1.0280, G loss: 1.3261\n",
      "[404/1762] D loss: 0.3941, G loss: 2.2248\n",
      "[484/1762] D loss: 1.1951, G loss: 0.8120\n",
      "[564/1762] D loss: 0.5681, G loss: 1.4131\n",
      "[644/1762] D loss: 0.4718, G loss: 1.9377\n",
      "[724/1762] D loss: 1.1566, G loss: 1.0284\n",
      "[804/1762] D loss: 0.9345, G loss: 1.3382\n",
      "[884/1762] D loss: 0.8905, G loss: 1.3846\n",
      "[964/1762] D loss: 1.1515, G loss: 1.1986\n",
      "[1044/1762] D loss: 0.9933, G loss: 1.6988\n",
      "[1124/1762] D loss: 0.8366, G loss: 1.1309\n",
      "[1204/1762] D loss: 1.2501, G loss: 0.6951\n",
      "[1284/1762] D loss: 1.2266, G loss: 0.5374\n",
      "[1364/1762] D loss: 0.6945, G loss: 1.1389\n",
      "[1444/1762] D loss: 1.2257, G loss: 0.3545\n",
      "[1524/1762] D loss: 0.5857, G loss: 1.1340\n",
      "[1604/1762] D loss: 0.6644, G loss: 1.2628\n",
      "[1684/1762] D loss: 1.0512, G loss: 1.2117\n",
      "[1762/1762] D loss: 1.6576, G loss: 2.9496\n",
      "train error: \n",
      " D loss: 1.201582, G loss: 1.375051, D accuracy: 63.2%, cell accuracy: 99.7%, board accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.203725, G loss: 1.403295, D accuracy: 65.7%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0502, G loss: 0.8744\n",
      "[84/1762] D loss: 0.9782, G loss: 0.9460\n",
      "[164/1762] D loss: 1.0012, G loss: 0.5788\n",
      "[244/1762] D loss: 0.8743, G loss: 1.0451\n",
      "[324/1762] D loss: 0.5581, G loss: 1.5521\n",
      "[404/1762] D loss: 1.2152, G loss: 1.4831\n",
      "[484/1762] D loss: 1.0892, G loss: 1.2718\n",
      "[564/1762] D loss: 0.5818, G loss: 1.7058\n",
      "[644/1762] D loss: 1.1000, G loss: 1.0516\n",
      "[724/1762] D loss: 1.2100, G loss: 1.0291\n",
      "[804/1762] D loss: 1.0140, G loss: 1.0828\n",
      "[884/1762] D loss: 0.7913, G loss: 1.1813\n",
      "[964/1762] D loss: 0.8923, G loss: 0.8295\n",
      "[1044/1762] D loss: 1.0062, G loss: 0.8827\n",
      "[1124/1762] D loss: 0.7005, G loss: 1.2489\n",
      "[1204/1762] D loss: 1.1868, G loss: 0.8703\n",
      "[1284/1762] D loss: 0.9987, G loss: 1.3029\n",
      "[1364/1762] D loss: 1.2083, G loss: 0.6966\n",
      "[1444/1762] D loss: 1.2293, G loss: 0.8367\n",
      "[1524/1762] D loss: 0.9916, G loss: 1.3169\n",
      "[1604/1762] D loss: 0.8876, G loss: 1.2295\n",
      "[1684/1762] D loss: 1.1347, G loss: 0.9108\n",
      "[1762/1762] D loss: 1.0805, G loss: 0.6145\n",
      "train error: \n",
      " D loss: 1.185797, G loss: 0.978008, D accuracy: 68.3%, cell accuracy: 99.7%, board accuracy: 71.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.195797, G loss: 0.998245, D accuracy: 66.4%, cell accuracy: 99.6%, board accuracy: 71.1% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1682, G loss: 0.6600\n",
      "[84/1762] D loss: 0.9246, G loss: 1.0155\n",
      "[164/1762] D loss: 1.1526, G loss: 0.6181\n",
      "[244/1762] D loss: 0.8277, G loss: 1.2734\n",
      "[324/1762] D loss: 1.4345, G loss: 0.3950\n",
      "[404/1762] D loss: 1.2007, G loss: 0.5477\n",
      "[484/1762] D loss: 1.2432, G loss: 0.6250\n",
      "[564/1762] D loss: 1.0587, G loss: 0.8768\n",
      "[644/1762] D loss: 0.9585, G loss: 1.1554\n",
      "[724/1762] D loss: 0.9582, G loss: 2.2847\n",
      "[804/1762] D loss: 1.1116, G loss: 0.8439\n",
      "[884/1762] D loss: 1.2597, G loss: 1.0366\n",
      "[964/1762] D loss: 0.8490, G loss: 1.2610\n",
      "[1044/1762] D loss: 1.2240, G loss: 1.0577\n",
      "[1124/1762] D loss: 1.2053, G loss: 1.1959\n",
      "[1204/1762] D loss: 1.2074, G loss: 0.8387\n",
      "[1284/1762] D loss: 1.0346, G loss: 0.7491\n",
      "[1364/1762] D loss: 1.3208, G loss: 0.4848\n",
      "[1444/1762] D loss: 0.3204, G loss: 2.1157\n",
      "[1524/1762] D loss: 1.2965, G loss: 0.9243\n",
      "[1604/1762] D loss: 1.3939, G loss: 0.4783\n",
      "[1684/1762] D loss: 1.3124, G loss: 0.9395\n",
      "[1762/1762] D loss: 1.0697, G loss: 1.0270\n",
      "train error: \n",
      " D loss: 1.292797, G loss: 1.293029, D accuracy: 61.8%, cell accuracy: 99.7%, board accuracy: 79.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296964, G loss: 1.296594, D accuracy: 64.7%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4322, G loss: 1.4152\n",
      "[84/1762] D loss: 0.6480, G loss: 1.3202\n",
      "[164/1762] D loss: 1.2751, G loss: 0.5375\n",
      "[244/1762] D loss: 1.2033, G loss: 1.0950\n",
      "[324/1762] D loss: 1.2666, G loss: 0.5237\n",
      "[404/1762] D loss: 0.7200, G loss: 1.3178\n",
      "[484/1762] D loss: 0.9613, G loss: 2.0770\n",
      "[564/1762] D loss: 1.1449, G loss: 0.6490\n",
      "[644/1762] D loss: 1.2454, G loss: 0.7336\n",
      "[724/1762] D loss: 1.8695, G loss: 0.3273\n",
      "[804/1762] D loss: 1.2422, G loss: 0.6470\n",
      "[884/1762] D loss: 0.8005, G loss: 1.2320\n",
      "[964/1762] D loss: 1.2314, G loss: 0.6505\n",
      "[1044/1762] D loss: 1.1071, G loss: 0.7740\n",
      "[1124/1762] D loss: 0.8263, G loss: 0.8743\n",
      "[1204/1762] D loss: 0.7896, G loss: 1.2863\n",
      "[1284/1762] D loss: 0.9718, G loss: 0.8557\n",
      "[1364/1762] D loss: 1.1223, G loss: 1.2422\n",
      "[1444/1762] D loss: 1.4416, G loss: 1.1368\n",
      "[1524/1762] D loss: 0.9445, G loss: 0.8787\n",
      "[1604/1762] D loss: 1.2345, G loss: 0.8690\n",
      "[1684/1762] D loss: 0.9694, G loss: 1.5259\n",
      "[1762/1762] D loss: 1.4581, G loss: 0.3461\n",
      "train error: \n",
      " D loss: 1.251627, G loss: 0.731474, D accuracy: 62.2%, cell accuracy: 99.7%, board accuracy: 79.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262014, G loss: 0.746131, D accuracy: 61.7%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8902, G loss: 0.8310\n",
      "[84/1762] D loss: 1.3462, G loss: 1.2459\n",
      "[164/1762] D loss: 0.7250, G loss: 1.0503\n",
      "[244/1762] D loss: 1.1890, G loss: 0.8293\n",
      "[324/1762] D loss: 1.2194, G loss: 1.0872\n",
      "[404/1762] D loss: 1.1903, G loss: 0.8000\n",
      "[484/1762] D loss: 0.8567, G loss: 0.7179\n",
      "[564/1762] D loss: 0.7582, G loss: 1.0493\n",
      "[644/1762] D loss: 1.2719, G loss: 2.0469\n",
      "[724/1762] D loss: 0.4951, G loss: 2.3959\n",
      "[804/1762] D loss: 1.2498, G loss: 0.8657\n",
      "[884/1762] D loss: 0.8063, G loss: 1.1537\n",
      "[964/1762] D loss: 1.2191, G loss: 0.7702\n",
      "[1044/1762] D loss: 1.2577, G loss: 0.4417\n",
      "[1124/1762] D loss: 0.7757, G loss: 0.8507\n",
      "[1204/1762] D loss: 1.2990, G loss: 0.7078\n",
      "[1284/1762] D loss: 1.8418, G loss: 1.5401\n",
      "[1364/1762] D loss: 0.7422, G loss: 1.0507\n",
      "[1444/1762] D loss: 1.4162, G loss: 1.0588\n",
      "[1524/1762] D loss: 1.2664, G loss: 0.7587\n",
      "[1604/1762] D loss: 1.2466, G loss: 0.8839\n",
      "[1684/1762] D loss: 1.3665, G loss: 1.0428\n",
      "[1762/1762] D loss: 1.0965, G loss: 1.1424\n",
      "train error: \n",
      " D loss: 1.303940, G loss: 1.076119, D accuracy: 58.3%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299703, G loss: 1.086412, D accuracy: 59.3%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8042, G loss: 1.8264\n",
      "[84/1762] D loss: 1.3743, G loss: 0.7438\n",
      "[164/1762] D loss: 1.4883, G loss: 0.4364\n",
      "[244/1762] D loss: 0.3890, G loss: 1.8627\n",
      "[324/1762] D loss: 0.5500, G loss: 1.4045\n",
      "[404/1762] D loss: 1.1495, G loss: 1.5625\n",
      "[484/1762] D loss: 0.4920, G loss: 1.5139\n",
      "[564/1762] D loss: 1.7581, G loss: 1.5374\n",
      "[644/1762] D loss: 1.6072, G loss: 0.3242\n",
      "[724/1762] D loss: 0.6219, G loss: 1.8680\n",
      "[804/1762] D loss: 1.3465, G loss: 0.9693\n",
      "[884/1762] D loss: 1.9086, G loss: 0.2159\n",
      "[964/1762] D loss: 1.4257, G loss: 1.1867\n",
      "[1044/1762] D loss: 0.7694, G loss: 0.9796\n",
      "[1124/1762] D loss: 1.4014, G loss: 1.1254\n",
      "[1204/1762] D loss: 0.6261, G loss: 0.8984\n",
      "[1284/1762] D loss: 1.3137, G loss: 1.1007\n",
      "[1364/1762] D loss: 1.4364, G loss: 1.0773\n",
      "[1444/1762] D loss: 0.5309, G loss: 1.2638\n",
      "[1524/1762] D loss: 1.5422, G loss: 0.6390\n",
      "[1604/1762] D loss: 1.4988, G loss: 0.3562\n",
      "[1684/1762] D loss: 1.1106, G loss: 2.3336\n",
      "[1762/1762] D loss: 1.3494, G loss: 1.1668\n",
      "train error: \n",
      " D loss: 1.291977, G loss: 0.901675, D accuracy: 59.5%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292262, G loss: 0.919461, D accuracy: 59.7%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3783, G loss: 1.6237\n",
      "[84/1762] D loss: 1.2595, G loss: 0.8534\n",
      "[164/1762] D loss: 1.4592, G loss: 1.1767\n",
      "[244/1762] D loss: 0.5944, G loss: 1.6995\n",
      "[324/1762] D loss: 0.8977, G loss: 1.3564\n",
      "[404/1762] D loss: 1.2423, G loss: 0.9856\n",
      "[484/1762] D loss: 1.2864, G loss: 0.7754\n",
      "[564/1762] D loss: 1.3917, G loss: 0.5107\n",
      "[644/1762] D loss: 1.3261, G loss: 0.7792\n",
      "[724/1762] D loss: 1.6365, G loss: 1.5089\n",
      "[804/1762] D loss: 0.9588, G loss: 1.4860\n",
      "[884/1762] D loss: 1.3472, G loss: 0.6211\n",
      "[964/1762] D loss: 1.7656, G loss: 1.3163\n",
      "[1044/1762] D loss: 1.3924, G loss: 0.4855\n",
      "[1124/1762] D loss: 1.2676, G loss: 0.7393\n",
      "[1204/1762] D loss: 1.3323, G loss: 0.4436\n",
      "[1284/1762] D loss: 1.5721, G loss: 1.0465\n",
      "[1364/1762] D loss: 1.3179, G loss: 1.5594\n",
      "[1444/1762] D loss: 1.4027, G loss: 0.5925\n",
      "[1524/1762] D loss: 0.4578, G loss: 1.9845\n",
      "[1604/1762] D loss: 1.6161, G loss: 0.3697\n",
      "[1684/1762] D loss: 1.3307, G loss: 0.6959\n",
      "[1762/1762] D loss: 1.3392, G loss: 0.6136\n",
      "train error: \n",
      " D loss: 1.322130, G loss: 0.685653, D accuracy: 57.4%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315730, G loss: 0.702077, D accuracy: 59.0%, cell accuracy: 99.8%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4261, G loss: 0.5946\n",
      "[84/1762] D loss: 0.6296, G loss: 1.1829\n",
      "[164/1762] D loss: 1.3497, G loss: 0.8339\n",
      "[244/1762] D loss: 0.7853, G loss: 0.8773\n",
      "[324/1762] D loss: 1.3484, G loss: 0.7766\n",
      "[404/1762] D loss: 1.2677, G loss: 0.8795\n",
      "[484/1762] D loss: 0.6115, G loss: 1.3075\n",
      "[564/1762] D loss: 1.3697, G loss: 0.5336\n",
      "[644/1762] D loss: 1.4282, G loss: 1.1794\n",
      "[724/1762] D loss: 0.2463, G loss: 2.4087\n",
      "[804/1762] D loss: 1.3842, G loss: 0.5707\n",
      "[884/1762] D loss: 1.3417, G loss: 0.4949\n",
      "[964/1762] D loss: 1.5705, G loss: 0.9690\n",
      "[1044/1762] D loss: 1.1501, G loss: 1.1153\n",
      "[1124/1762] D loss: 0.8417, G loss: 1.7291\n",
      "[1204/1762] D loss: 0.6542, G loss: 2.0544\n",
      "[1284/1762] D loss: 2.3054, G loss: 0.1749\n",
      "[1364/1762] D loss: 1.5268, G loss: 1.4479\n",
      "[1444/1762] D loss: 1.3926, G loss: 1.1807\n",
      "[1524/1762] D loss: 1.4031, G loss: 0.5456\n",
      "[1604/1762] D loss: 1.2427, G loss: 1.0474\n",
      "[1684/1762] D loss: 0.8580, G loss: 1.8927\n",
      "[1762/1762] D loss: 0.2361, G loss: 2.3339\n",
      "train error: \n",
      " D loss: 1.234320, G loss: 0.810681, D accuracy: 65.2%, cell accuracy: 99.7%, board accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.229014, G loss: 0.825726, D accuracy: 64.7%, cell accuracy: 99.6%, board accuracy: 65.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4249, G loss: 0.6596\n",
      "[84/1762] D loss: 1.0991, G loss: 0.6460\n",
      "[164/1762] D loss: 1.5610, G loss: 0.6706\n",
      "[244/1762] D loss: 0.6442, G loss: 0.9898\n",
      "[324/1762] D loss: 2.7457, G loss: 0.1166\n",
      "[404/1762] D loss: 1.4702, G loss: 0.6477\n",
      "[484/1762] D loss: 1.4820, G loss: 0.4880\n",
      "[564/1762] D loss: 1.5283, G loss: 1.2706\n",
      "[644/1762] D loss: 1.5079, G loss: 0.9028\n",
      "[724/1762] D loss: 1.7345, G loss: 2.3013\n",
      "[804/1762] D loss: 1.3983, G loss: 0.8643\n",
      "[884/1762] D loss: 1.3317, G loss: 0.4588\n",
      "[964/1762] D loss: 1.4031, G loss: 1.0010\n",
      "[1044/1762] D loss: 0.5827, G loss: 1.1392\n",
      "[1124/1762] D loss: 1.4572, G loss: 0.4928\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.6710\n",
      "[1284/1762] D loss: 0.6452, G loss: 1.2919\n",
      "[1364/1762] D loss: 1.3721, G loss: 0.8502\n",
      "[1444/1762] D loss: 1.3449, G loss: 0.7064\n",
      "[1524/1762] D loss: 0.6337, G loss: 1.5118\n",
      "[1604/1762] D loss: 1.3800, G loss: 0.6840\n",
      "[1684/1762] D loss: 1.3208, G loss: 0.5081\n",
      "[1762/1762] D loss: 1.8145, G loss: 0.3004\n",
      "train error: \n",
      " D loss: 1.432688, G loss: 0.477724, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 80.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.421239, G loss: 0.497463, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2721, G loss: 0.9537\n",
      "[84/1762] D loss: 0.5612, G loss: 1.6761\n",
      "[164/1762] D loss: 1.3340, G loss: 0.7980\n",
      "[244/1762] D loss: 0.5299, G loss: 1.6569\n",
      "[324/1762] D loss: 0.7166, G loss: 1.2735\n",
      "[404/1762] D loss: 1.4565, G loss: 0.6738\n",
      "[484/1762] D loss: 1.4013, G loss: 0.6325\n",
      "[564/1762] D loss: 0.8442, G loss: 0.7748\n",
      "[644/1762] D loss: 1.4983, G loss: 0.6039\n",
      "[724/1762] D loss: 1.2708, G loss: 0.8093\n",
      "[804/1762] D loss: 1.3708, G loss: 0.6778\n",
      "[884/1762] D loss: 1.4914, G loss: 0.9237\n",
      "[964/1762] D loss: 1.2384, G loss: 0.8565\n",
      "[1044/1762] D loss: 1.4274, G loss: 0.9872\n",
      "[1124/1762] D loss: 0.6233, G loss: 1.7006\n",
      "[1204/1762] D loss: 1.2876, G loss: 0.7450\n",
      "[1284/1762] D loss: 1.3474, G loss: 0.6400\n",
      "[1364/1762] D loss: 1.1987, G loss: 1.0517\n",
      "[1444/1762] D loss: 0.5450, G loss: 1.8453\n",
      "[1524/1762] D loss: 1.3946, G loss: 0.6564\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7607\n",
      "[1684/1762] D loss: 0.5793, G loss: 1.2690\n",
      "[1762/1762] D loss: 1.4932, G loss: 0.4200\n",
      "train error: \n",
      " D loss: 1.368663, G loss: 0.592092, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370349, G loss: 0.615195, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8046, G loss: 0.9451\n",
      "[84/1762] D loss: 0.4948, G loss: 1.4954\n",
      "[164/1762] D loss: 1.3660, G loss: 0.9126\n",
      "[244/1762] D loss: 1.4687, G loss: 0.9637\n",
      "[324/1762] D loss: 1.1911, G loss: 1.2153\n",
      "[404/1762] D loss: 0.5835, G loss: 1.3385\n",
      "[484/1762] D loss: 1.3843, G loss: 0.8169\n",
      "[564/1762] D loss: 1.4454, G loss: 0.9991\n",
      "[644/1762] D loss: 1.3576, G loss: 0.6796\n",
      "[724/1762] D loss: 1.3760, G loss: 0.8250\n",
      "[804/1762] D loss: 1.6132, G loss: 0.8287\n",
      "[884/1762] D loss: 1.4322, G loss: 1.0684\n",
      "[964/1762] D loss: 0.5758, G loss: 1.8518\n",
      "[1044/1762] D loss: 1.5074, G loss: 0.4904\n",
      "[1124/1762] D loss: 1.4184, G loss: 1.2665\n",
      "[1204/1762] D loss: 1.4157, G loss: 0.7172\n",
      "[1284/1762] D loss: 1.3779, G loss: 0.5058\n",
      "[1364/1762] D loss: 1.4150, G loss: 1.1151\n",
      "[1444/1762] D loss: 1.9728, G loss: 0.2979\n",
      "[1524/1762] D loss: 0.2397, G loss: 3.0689\n",
      "[1604/1762] D loss: 1.4331, G loss: 0.6663\n",
      "[1684/1762] D loss: 1.5165, G loss: 0.7955\n",
      "[1762/1762] D loss: 1.2877, G loss: 0.7074\n",
      "train error: \n",
      " D loss: 1.335380, G loss: 0.755686, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331990, G loss: 0.776351, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.8876\n",
      "[84/1762] D loss: 1.5149, G loss: 0.6404\n",
      "[164/1762] D loss: 1.4112, G loss: 0.5425\n",
      "[244/1762] D loss: 1.3550, G loss: 0.8186\n",
      "[324/1762] D loss: 1.4995, G loss: 0.9791\n",
      "[404/1762] D loss: 1.4799, G loss: 1.0078\n",
      "[484/1762] D loss: 1.5508, G loss: 0.3573\n",
      "[564/1762] D loss: 1.4312, G loss: 1.0398\n",
      "[644/1762] D loss: 1.6140, G loss: 1.0487\n",
      "[724/1762] D loss: 1.4394, G loss: 0.8241\n",
      "[804/1762] D loss: 0.9057, G loss: 1.4654\n",
      "[884/1762] D loss: 1.3972, G loss: 0.5480\n",
      "[964/1762] D loss: 1.3864, G loss: 0.8410\n",
      "[1044/1762] D loss: 1.4467, G loss: 0.5235\n",
      "[1124/1762] D loss: 1.4193, G loss: 0.5645\n",
      "[1204/1762] D loss: 0.6104, G loss: 1.4296\n",
      "[1284/1762] D loss: 1.3440, G loss: 0.7929\n",
      "[1364/1762] D loss: 1.4221, G loss: 0.6877\n",
      "[1444/1762] D loss: 1.4076, G loss: 0.8588\n",
      "[1524/1762] D loss: 1.3454, G loss: 0.8356\n",
      "[1604/1762] D loss: 1.4964, G loss: 0.5407\n",
      "[1684/1762] D loss: 1.3771, G loss: 0.5591\n",
      "[1762/1762] D loss: 1.1982, G loss: 0.6907\n",
      "train error: \n",
      " D loss: 1.341516, G loss: 0.971224, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338790, G loss: 1.005804, D accuracy: 57.6%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5390, G loss: 1.9294\n",
      "[84/1762] D loss: 0.4984, G loss: 1.2432\n",
      "[164/1762] D loss: 1.4740, G loss: 0.4038\n",
      "[244/1762] D loss: 0.6233, G loss: 1.1040\n",
      "[324/1762] D loss: 1.1154, G loss: 1.0688\n",
      "[404/1762] D loss: 1.4019, G loss: 0.7503\n",
      "[484/1762] D loss: 1.3968, G loss: 0.5889\n",
      "[564/1762] D loss: 1.3840, G loss: 0.7826\n",
      "[644/1762] D loss: 1.7335, G loss: 1.2408\n",
      "[724/1762] D loss: 0.5837, G loss: 1.6266\n",
      "[804/1762] D loss: 0.4409, G loss: 1.6978\n",
      "[884/1762] D loss: 1.3671, G loss: 0.5799\n",
      "[964/1762] D loss: 0.2071, G loss: 2.5109\n",
      "[1044/1762] D loss: 1.4665, G loss: 0.7614\n",
      "[1124/1762] D loss: 1.2658, G loss: 0.9198\n",
      "[1204/1762] D loss: 1.4253, G loss: 0.8147\n",
      "[1284/1762] D loss: 1.4388, G loss: 0.5844\n",
      "[1364/1762] D loss: 1.5044, G loss: 0.8869\n",
      "[1444/1762] D loss: 0.5343, G loss: 1.3799\n",
      "[1524/1762] D loss: 1.4445, G loss: 0.9540\n",
      "[1604/1762] D loss: 1.4911, G loss: 0.9549\n",
      "[1684/1762] D loss: 1.4673, G loss: 1.2824\n",
      "[1762/1762] D loss: 1.3940, G loss: 0.8047\n",
      "train error: \n",
      " D loss: 1.334089, G loss: 0.945938, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332855, G loss: 0.957351, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4061, G loss: 0.7835\n",
      "[84/1762] D loss: 1.3490, G loss: 0.7155\n",
      "[164/1762] D loss: 1.3388, G loss: 0.6645\n",
      "[244/1762] D loss: 1.4675, G loss: 0.8843\n",
      "[324/1762] D loss: 1.2232, G loss: 1.1636\n",
      "[404/1762] D loss: 1.4081, G loss: 0.7668\n",
      "[484/1762] D loss: 1.4069, G loss: 0.8286\n",
      "[564/1762] D loss: 1.3627, G loss: 0.8243\n",
      "[644/1762] D loss: 1.5880, G loss: 1.2021\n",
      "[724/1762] D loss: 0.6486, G loss: 1.8494\n",
      "[804/1762] D loss: 1.3162, G loss: 1.1755\n",
      "[884/1762] D loss: 1.4732, G loss: 0.5427\n",
      "[964/1762] D loss: 1.3690, G loss: 0.8726\n",
      "[1044/1762] D loss: 1.4695, G loss: 0.8643\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.6897\n",
      "[1204/1762] D loss: 1.5694, G loss: 0.4637\n",
      "[1284/1762] D loss: 1.4318, G loss: 0.9184\n",
      "[1364/1762] D loss: 1.4042, G loss: 0.4752\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.6592\n",
      "[1524/1762] D loss: 1.4162, G loss: 0.9360\n",
      "[1604/1762] D loss: 1.3783, G loss: 0.5982\n",
      "[1684/1762] D loss: 1.4990, G loss: 0.7807\n",
      "[1762/1762] D loss: 0.1439, G loss: 2.7612\n",
      "train error: \n",
      " D loss: 1.383292, G loss: 1.042640, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373512, G loss: 1.064542, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4526, G loss: 1.0229\n",
      "[84/1762] D loss: 1.6255, G loss: 1.6943\n",
      "[164/1762] D loss: 1.5238, G loss: 0.4741\n",
      "[244/1762] D loss: 1.3723, G loss: 0.7444\n",
      "[324/1762] D loss: 1.4519, G loss: 0.9727\n",
      "[404/1762] D loss: 1.4336, G loss: 0.6764\n",
      "[484/1762] D loss: 0.5288, G loss: 1.3668\n",
      "[564/1762] D loss: 1.4157, G loss: 0.7839\n",
      "[644/1762] D loss: 1.3799, G loss: 0.6931\n",
      "[724/1762] D loss: 1.4106, G loss: 0.7256\n",
      "[804/1762] D loss: 0.5336, G loss: 1.2771\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6112\n",
      "[964/1762] D loss: 1.4298, G loss: 0.9660\n",
      "[1044/1762] D loss: 1.3617, G loss: 0.6584\n",
      "[1124/1762] D loss: 1.4252, G loss: 0.7944\n",
      "[1204/1762] D loss: 1.4721, G loss: 0.6055\n",
      "[1284/1762] D loss: 1.4480, G loss: 0.9771\n",
      "[1364/1762] D loss: 0.6850, G loss: 1.0286\n",
      "[1444/1762] D loss: 0.4992, G loss: 1.9850\n",
      "[1524/1762] D loss: 1.5023, G loss: 0.8616\n",
      "[1604/1762] D loss: 1.4192, G loss: 0.6287\n",
      "[1684/1762] D loss: 1.5041, G loss: 0.4591\n",
      "[1762/1762] D loss: 1.4084, G loss: 0.5962\n",
      "train error: \n",
      " D loss: 1.370392, G loss: 0.577643, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371381, G loss: 0.595734, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4536, G loss: 1.6699\n",
      "[84/1762] D loss: 1.4830, G loss: 0.8893\n",
      "[164/1762] D loss: 1.5126, G loss: 0.3890\n",
      "[244/1762] D loss: 1.3493, G loss: 1.0388\n",
      "[324/1762] D loss: 1.5403, G loss: 1.2823\n",
      "[404/1762] D loss: 1.4734, G loss: 0.5910\n",
      "[484/1762] D loss: 1.4055, G loss: 0.6393\n",
      "[564/1762] D loss: 0.4816, G loss: 1.2142\n",
      "[644/1762] D loss: 0.3538, G loss: 2.0909\n",
      "[724/1762] D loss: 1.4189, G loss: 0.6907\n",
      "[804/1762] D loss: 1.4030, G loss: 0.5727\n",
      "[884/1762] D loss: 0.4361, G loss: 1.6789\n",
      "[964/1762] D loss: 1.5604, G loss: 0.4760\n",
      "[1044/1762] D loss: 1.4086, G loss: 0.7030\n",
      "[1124/1762] D loss: 0.5127, G loss: 1.2402\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.7494\n",
      "[1284/1762] D loss: 1.3306, G loss: 0.6671\n",
      "[1364/1762] D loss: 1.4447, G loss: 0.9066\n",
      "[1444/1762] D loss: 0.4981, G loss: 1.4397\n",
      "[1524/1762] D loss: 1.3670, G loss: 0.4891\n",
      "[1604/1762] D loss: 1.4312, G loss: 0.9298\n",
      "[1684/1762] D loss: 1.4707, G loss: 0.7746\n",
      "[1762/1762] D loss: 0.2980, G loss: 1.6039\n",
      "train error: \n",
      " D loss: 1.307977, G loss: 0.823348, D accuracy: 57.8%, cell accuracy: 99.8%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302163, G loss: 0.820011, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4594, G loss: 1.5305\n",
      "[84/1762] D loss: 0.5918, G loss: 1.1844\n",
      "[164/1762] D loss: 1.3285, G loss: 0.9569\n",
      "[244/1762] D loss: 1.4325, G loss: 0.7028\n",
      "[324/1762] D loss: 0.4077, G loss: 1.9787\n",
      "[404/1762] D loss: 4.2798, G loss: 0.8867\n",
      "[484/1762] D loss: 1.1746, G loss: 2.5010\n",
      "[564/1762] D loss: 0.0965, G loss: 3.1888\n",
      "[644/1762] D loss: 0.6339, G loss: 2.7344\n",
      "[724/1762] D loss: 1.1618, G loss: 0.4736\n",
      "[804/1762] D loss: 1.4466, G loss: 0.7096\n",
      "[884/1762] D loss: 1.4284, G loss: 0.7815\n",
      "[964/1762] D loss: 1.4009, G loss: 0.7203\n",
      "[1044/1762] D loss: 0.9445, G loss: 1.1812\n",
      "[1124/1762] D loss: 1.4890, G loss: 1.0082\n",
      "[1204/1762] D loss: 1.4168, G loss: 0.8435\n",
      "[1284/1762] D loss: 1.2538, G loss: 1.3290\n",
      "[1364/1762] D loss: 0.8670, G loss: 1.1037\n",
      "[1444/1762] D loss: 1.3123, G loss: 0.9870\n",
      "[1524/1762] D loss: 1.3797, G loss: 0.9401\n",
      "[1604/1762] D loss: 0.3215, G loss: 1.8670\n",
      "[1684/1762] D loss: 1.4213, G loss: 0.7106\n",
      "[1762/1762] D loss: 1.4129, G loss: 0.8247\n",
      "train error: \n",
      " D loss: 1.430724, G loss: 1.017919, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.440615, G loss: 1.003695, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6979, G loss: 1.6750\n",
      "[84/1762] D loss: 1.2662, G loss: 0.7648\n",
      "[164/1762] D loss: 1.4950, G loss: 0.5544\n",
      "[244/1762] D loss: 0.5909, G loss: 1.7774\n",
      "[324/1762] D loss: 1.4047, G loss: 0.7227\n",
      "[404/1762] D loss: 1.3902, G loss: 0.7109\n",
      "[484/1762] D loss: 1.3930, G loss: 0.5539\n",
      "[564/1762] D loss: 1.3307, G loss: 0.7628\n",
      "[644/1762] D loss: 1.3900, G loss: 0.6885\n",
      "[724/1762] D loss: 0.7613, G loss: 1.2751\n",
      "[804/1762] D loss: 1.3986, G loss: 0.8306\n",
      "[884/1762] D loss: 1.3939, G loss: 0.8026\n",
      "[964/1762] D loss: 1.2211, G loss: 1.6897\n",
      "[1044/1762] D loss: 1.2764, G loss: 0.9149\n",
      "[1124/1762] D loss: 1.4495, G loss: 0.5525\n",
      "[1204/1762] D loss: 1.3057, G loss: 0.7596\n",
      "[1284/1762] D loss: 1.3999, G loss: 0.9302\n",
      "[1364/1762] D loss: 1.5054, G loss: 1.0511\n",
      "[1444/1762] D loss: 0.6711, G loss: 1.0725\n",
      "[1524/1762] D loss: 0.6817, G loss: 1.0729\n",
      "[1604/1762] D loss: 0.6219, G loss: 1.3229\n",
      "[1684/1762] D loss: 1.4243, G loss: 0.5534\n",
      "[1762/1762] D loss: 1.1282, G loss: 0.8612\n",
      "train error: \n",
      " D loss: 1.339108, G loss: 0.930887, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 77.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344696, G loss: 0.927511, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 73.4% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4150, G loss: 1.6715\n",
      "[84/1762] D loss: 0.5552, G loss: 1.2815\n",
      "[164/1762] D loss: 1.3936, G loss: 0.5884\n",
      "[244/1762] D loss: 1.5150, G loss: 0.9997\n",
      "[324/1762] D loss: 1.7253, G loss: 0.5368\n",
      "[404/1762] D loss: 1.3850, G loss: 0.6529\n",
      "[484/1762] D loss: 1.4767, G loss: 0.5992\n",
      "[564/1762] D loss: 1.4405, G loss: 0.9603\n",
      "[644/1762] D loss: 1.3095, G loss: 0.5863\n",
      "[724/1762] D loss: 1.3989, G loss: 0.8651\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7831\n",
      "[884/1762] D loss: 1.4053, G loss: 0.6021\n",
      "[964/1762] D loss: 1.3897, G loss: 0.6700\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6245\n",
      "[1124/1762] D loss: 1.4419, G loss: 0.5741\n",
      "[1204/1762] D loss: 1.6522, G loss: 1.3221\n",
      "[1284/1762] D loss: 1.4461, G loss: 0.8945\n",
      "[1364/1762] D loss: 0.5223, G loss: 1.2660\n",
      "[1444/1762] D loss: 1.4304, G loss: 0.5785\n",
      "[1524/1762] D loss: 0.4598, G loss: 1.6056\n",
      "[1604/1762] D loss: 1.3970, G loss: 0.7425\n",
      "[1684/1762] D loss: 1.4245, G loss: 0.7297\n",
      "[1762/1762] D loss: 1.3054, G loss: 0.6620\n",
      "train error: \n",
      " D loss: 1.340661, G loss: 0.792051, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341820, G loss: 0.804374, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4348, G loss: 0.5430\n",
      "[84/1762] D loss: 0.6296, G loss: 1.1770\n",
      "[164/1762] D loss: 1.4645, G loss: 1.0410\n",
      "[244/1762] D loss: 1.2595, G loss: 1.5172\n",
      "[324/1762] D loss: 1.3817, G loss: 0.5843\n",
      "[404/1762] D loss: 0.4203, G loss: 1.4928\n",
      "[484/1762] D loss: 0.6715, G loss: 0.8448\n",
      "[564/1762] D loss: 0.5514, G loss: 1.1559\n",
      "[644/1762] D loss: 1.4826, G loss: 0.8900\n",
      "[724/1762] D loss: 1.3655, G loss: 0.7238\n",
      "[804/1762] D loss: 1.5339, G loss: 1.6839\n",
      "[884/1762] D loss: 1.4317, G loss: 0.5785\n",
      "[964/1762] D loss: 0.6163, G loss: 0.9896\n",
      "[1044/1762] D loss: 0.8088, G loss: 0.7063\n",
      "[1124/1762] D loss: 1.3331, G loss: 0.7353\n",
      "[1204/1762] D loss: 1.4006, G loss: 0.7839\n",
      "[1284/1762] D loss: 0.4663, G loss: 1.6435\n",
      "[1364/1762] D loss: 1.4478, G loss: 0.5219\n",
      "[1444/1762] D loss: 1.4544, G loss: 0.8719\n",
      "[1524/1762] D loss: 0.5154, G loss: 1.2767\n",
      "[1604/1762] D loss: 1.4144, G loss: 0.7375\n",
      "[1684/1762] D loss: 1.4300, G loss: 0.9196\n",
      "[1762/1762] D loss: 1.4164, G loss: 0.9493\n",
      "train error: \n",
      " D loss: 1.368693, G loss: 1.028227, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365525, G loss: 1.031088, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4525, G loss: 0.9694\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6377\n",
      "[164/1762] D loss: 1.4646, G loss: 0.7158\n",
      "[244/1762] D loss: 0.4224, G loss: 1.9293\n",
      "[324/1762] D loss: 1.4596, G loss: 0.9501\n",
      "[404/1762] D loss: 1.4033, G loss: 0.5504\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7275\n",
      "[564/1762] D loss: 1.6159, G loss: 0.9988\n",
      "[644/1762] D loss: 1.2829, G loss: 0.8377\n",
      "[724/1762] D loss: 0.1905, G loss: 1.8661\n",
      "[804/1762] D loss: 1.4712, G loss: 0.5087\n",
      "[884/1762] D loss: 1.5334, G loss: 0.9758\n",
      "[964/1762] D loss: 1.4013, G loss: 0.5867\n",
      "[1044/1762] D loss: 0.5100, G loss: 1.2999\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.7328\n",
      "[1204/1762] D loss: 1.4558, G loss: 0.8017\n",
      "[1284/1762] D loss: 1.3982, G loss: 0.6315\n",
      "[1364/1762] D loss: 0.4392, G loss: 1.5549\n",
      "[1444/1762] D loss: 1.4332, G loss: 0.9677\n",
      "[1524/1762] D loss: 1.4197, G loss: 0.6244\n",
      "[1604/1762] D loss: 1.4270, G loss: 0.6195\n",
      "[1684/1762] D loss: 1.4168, G loss: 0.9159\n",
      "[1762/1762] D loss: 1.5025, G loss: 0.4312\n",
      "train error: \n",
      " D loss: 1.384555, G loss: 0.556096, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386638, G loss: 0.563356, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4171, G loss: 0.5916\n",
      "[84/1762] D loss: 1.4268, G loss: 0.4947\n",
      "[164/1762] D loss: 1.2772, G loss: 1.1607\n",
      "[244/1762] D loss: 1.4707, G loss: 0.5825\n",
      "[324/1762] D loss: 1.3585, G loss: 0.6123\n",
      "[404/1762] D loss: 1.4508, G loss: 0.5538\n",
      "[484/1762] D loss: 0.4336, G loss: 1.5211\n",
      "[564/1762] D loss: 0.5370, G loss: 1.5585\n",
      "[644/1762] D loss: 1.3929, G loss: 0.8406\n",
      "[724/1762] D loss: 0.6806, G loss: 0.9446\n",
      "[804/1762] D loss: 1.4835, G loss: 0.5781\n",
      "[884/1762] D loss: 1.3516, G loss: 0.7805\n",
      "[964/1762] D loss: 1.4888, G loss: 0.5939\n",
      "[1044/1762] D loss: 1.4037, G loss: 0.6916\n",
      "[1124/1762] D loss: 0.1822, G loss: 2.6960\n",
      "[1204/1762] D loss: 0.4033, G loss: 1.4756\n",
      "[1284/1762] D loss: 1.3902, G loss: 0.9567\n",
      "[1364/1762] D loss: 1.4047, G loss: 0.8104\n",
      "[1444/1762] D loss: 0.4917, G loss: 1.2029\n",
      "[1524/1762] D loss: 1.4152, G loss: 0.8241\n",
      "[1604/1762] D loss: 1.4419, G loss: 0.8056\n",
      "[1684/1762] D loss: 1.4307, G loss: 0.9001\n",
      "[1762/1762] D loss: 1.4631, G loss: 0.5351\n",
      "train error: \n",
      " D loss: 1.328723, G loss: 0.738657, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331577, G loss: 0.742171, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5497, G loss: 1.3721\n",
      "[84/1762] D loss: 1.3282, G loss: 0.8408\n",
      "[164/1762] D loss: 0.4293, G loss: 1.4062\n",
      "[244/1762] D loss: 1.4292, G loss: 0.7721\n",
      "[324/1762] D loss: 1.4533, G loss: 0.7556\n",
      "[404/1762] D loss: 1.4048, G loss: 0.6713\n",
      "[484/1762] D loss: 1.4029, G loss: 0.6359\n",
      "[564/1762] D loss: 1.4016, G loss: 0.7120\n",
      "[644/1762] D loss: 1.5430, G loss: 0.6359\n",
      "[724/1762] D loss: 1.4400, G loss: 0.5538\n",
      "[804/1762] D loss: 1.4721, G loss: 0.5491\n",
      "[884/1762] D loss: 1.4194, G loss: 0.8885\n",
      "[964/1762] D loss: 1.6729, G loss: 1.6775\n",
      "[1044/1762] D loss: 0.5459, G loss: 1.2935\n",
      "[1124/1762] D loss: 0.4640, G loss: 1.7168\n",
      "[1204/1762] D loss: 1.4361, G loss: 0.6712\n",
      "[1284/1762] D loss: 1.2747, G loss: 0.7279\n",
      "[1364/1762] D loss: 1.5789, G loss: 0.6175\n",
      "[1444/1762] D loss: 1.4140, G loss: 0.8086\n",
      "[1524/1762] D loss: 0.5637, G loss: 1.1238\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.8298\n",
      "[1684/1762] D loss: 1.3992, G loss: 0.8608\n",
      "[1762/1762] D loss: 1.3735, G loss: 1.0776\n",
      "train error: \n",
      " D loss: 1.323828, G loss: 0.681841, D accuracy: 57.9%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309867, G loss: 0.699199, D accuracy: 59.9%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7450, G loss: 0.7888\n",
      "[84/1762] D loss: 1.4614, G loss: 0.4934\n",
      "[164/1762] D loss: 1.4230, G loss: 0.9383\n",
      "[244/1762] D loss: 1.5277, G loss: 1.0105\n",
      "[324/1762] D loss: 1.3198, G loss: 0.7497\n",
      "[404/1762] D loss: 1.4597, G loss: 0.5380\n",
      "[484/1762] D loss: 1.4184, G loss: 0.5322\n",
      "[564/1762] D loss: 0.3146, G loss: 2.5659\n",
      "[644/1762] D loss: 0.6993, G loss: 0.9880\n",
      "[724/1762] D loss: 1.3378, G loss: 1.0115\n",
      "[804/1762] D loss: 1.4316, G loss: 0.5562\n",
      "[884/1762] D loss: 1.4507, G loss: 0.8601\n",
      "[964/1762] D loss: 1.4481, G loss: 0.5953\n",
      "[1044/1762] D loss: 1.3236, G loss: 0.8605\n",
      "[1124/1762] D loss: 1.5068, G loss: 1.0189\n",
      "[1204/1762] D loss: 0.2039, G loss: 2.0277\n",
      "[1284/1762] D loss: 0.9964, G loss: 0.7144\n",
      "[1364/1762] D loss: 1.0316, G loss: 0.9208\n",
      "[1444/1762] D loss: 1.4582, G loss: 0.6272\n",
      "[1524/1762] D loss: 1.3812, G loss: 1.0034\n",
      "[1604/1762] D loss: 1.4976, G loss: 1.1478\n",
      "[1684/1762] D loss: 1.6115, G loss: 1.0091\n",
      "[1762/1762] D loss: 1.4197, G loss: 0.6339\n",
      "train error: \n",
      " D loss: 1.413167, G loss: 0.537878, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.419599, G loss: 0.526266, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5649, G loss: 0.5032\n",
      "[84/1762] D loss: 0.6393, G loss: 1.2719\n",
      "[164/1762] D loss: 1.4445, G loss: 0.9301\n",
      "[244/1762] D loss: 1.4027, G loss: 0.7798\n",
      "[324/1762] D loss: 1.4087, G loss: 0.9055\n",
      "[404/1762] D loss: 1.4688, G loss: 0.9657\n",
      "[484/1762] D loss: 1.4015, G loss: 0.6962\n",
      "[564/1762] D loss: 1.4285, G loss: 0.5936\n",
      "[644/1762] D loss: 0.2126, G loss: 2.0884\n",
      "[724/1762] D loss: 0.5648, G loss: 1.7895\n",
      "[804/1762] D loss: 1.4525, G loss: 0.9538\n",
      "[884/1762] D loss: 1.4093, G loss: 0.9214\n",
      "[964/1762] D loss: 0.5662, G loss: 1.2894\n",
      "[1044/1762] D loss: 1.5014, G loss: 0.9565\n",
      "[1124/1762] D loss: 1.3646, G loss: 0.8362\n",
      "[1204/1762] D loss: 1.3167, G loss: 0.7734\n",
      "[1284/1762] D loss: 0.4001, G loss: 1.2193\n",
      "[1364/1762] D loss: 1.4322, G loss: 0.6916\n",
      "[1444/1762] D loss: 1.8911, G loss: 1.7068\n",
      "[1524/1762] D loss: 0.4048, G loss: 1.4767\n",
      "[1604/1762] D loss: 1.5056, G loss: 1.1028\n",
      "[1684/1762] D loss: 1.3940, G loss: 0.6308\n",
      "[1762/1762] D loss: 1.5203, G loss: 1.0200\n",
      "train error: \n",
      " D loss: 1.383864, G loss: 0.963044, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379043, G loss: 0.965800, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7035, G loss: 0.6697\n",
      "[84/1762] D loss: 1.4068, G loss: 0.6799\n",
      "[164/1762] D loss: 0.4427, G loss: 1.1707\n",
      "[244/1762] D loss: 0.5000, G loss: 1.1771\n",
      "[324/1762] D loss: 1.4158, G loss: 0.6150\n",
      "[404/1762] D loss: 1.5146, G loss: 0.9325\n",
      "[484/1762] D loss: 1.4567, G loss: 0.9396\n",
      "[564/1762] D loss: 0.2936, G loss: 1.9411\n",
      "[644/1762] D loss: 1.4817, G loss: 1.1515\n",
      "[724/1762] D loss: 1.3714, G loss: 0.8185\n",
      "[804/1762] D loss: 1.4620, G loss: 0.6847\n",
      "[884/1762] D loss: 1.4443, G loss: 0.7490\n",
      "[964/1762] D loss: 0.5271, G loss: 1.0560\n",
      "[1044/1762] D loss: 1.5549, G loss: 0.4360\n",
      "[1124/1762] D loss: 1.3653, G loss: 0.7473\n",
      "[1204/1762] D loss: 1.4277, G loss: 0.8861\n",
      "[1284/1762] D loss: 1.4824, G loss: 0.4948\n",
      "[1364/1762] D loss: 1.4191, G loss: 0.4976\n",
      "[1444/1762] D loss: 1.3827, G loss: 0.7595\n",
      "[1524/1762] D loss: 0.1647, G loss: 2.1409\n",
      "[1604/1762] D loss: 0.5614, G loss: 1.1149\n",
      "[1684/1762] D loss: 1.4623, G loss: 0.9702\n",
      "[1762/1762] D loss: 1.4424, G loss: 0.6814\n",
      "train error: \n",
      " D loss: 1.358369, G loss: 0.651146, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362530, G loss: 0.645578, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4048, G loss: 0.6846\n",
      "[84/1762] D loss: 0.3752, G loss: 1.4434\n",
      "[164/1762] D loss: 1.3623, G loss: 0.7912\n",
      "[244/1762] D loss: 1.4675, G loss: 0.8118\n",
      "[324/1762] D loss: 0.4306, G loss: 1.3487\n",
      "[404/1762] D loss: 1.4001, G loss: 0.8054\n",
      "[484/1762] D loss: 0.4132, G loss: 1.4830\n",
      "[564/1762] D loss: 1.4134, G loss: 0.8061\n",
      "[644/1762] D loss: 1.6105, G loss: 0.4315\n",
      "[724/1762] D loss: 0.4185, G loss: 1.4814\n",
      "[804/1762] D loss: 0.4193, G loss: 1.8002\n",
      "[884/1762] D loss: 0.3792, G loss: 1.6600\n",
      "[964/1762] D loss: 1.4065, G loss: 0.5985\n",
      "[1044/1762] D loss: 1.3788, G loss: 0.7697\n",
      "[1124/1762] D loss: 0.3765, G loss: 2.0478\n",
      "[1204/1762] D loss: 0.7500, G loss: 0.8480\n",
      "[1284/1762] D loss: 1.4347, G loss: 0.7388\n",
      "[1364/1762] D loss: 1.4080, G loss: 0.7119\n",
      "[1444/1762] D loss: 1.4515, G loss: 0.8480\n",
      "[1524/1762] D loss: 1.4294, G loss: 0.9978\n",
      "[1604/1762] D loss: 0.1830, G loss: 1.9480\n",
      "[1684/1762] D loss: 1.3752, G loss: 0.7217\n",
      "[1762/1762] D loss: 1.1781, G loss: 0.9199\n",
      "train error: \n",
      " D loss: 1.336655, G loss: 0.768610, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326759, G loss: 0.784632, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3970, G loss: 0.7280\n",
      "[84/1762] D loss: 0.4417, G loss: 1.3066\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6206\n",
      "[244/1762] D loss: 1.4622, G loss: 0.9389\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6175\n",
      "[404/1762] D loss: 1.3930, G loss: 0.5787\n",
      "[484/1762] D loss: 1.3587, G loss: 0.6448\n",
      "[564/1762] D loss: 1.2749, G loss: 0.8186\n",
      "[644/1762] D loss: 0.5155, G loss: 1.1979\n",
      "[724/1762] D loss: 1.4168, G loss: 0.7607\n",
      "[804/1762] D loss: 0.3899, G loss: 1.1930\n",
      "[884/1762] D loss: 1.5209, G loss: 0.4453\n",
      "[964/1762] D loss: 1.4100, G loss: 0.8718\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.7381\n",
      "[1124/1762] D loss: 1.4090, G loss: 0.8020\n",
      "[1204/1762] D loss: 3.7701, G loss: 0.4620\n",
      "[1284/1762] D loss: 0.7943, G loss: 1.3466\n",
      "[1364/1762] D loss: 1.2603, G loss: 1.1705\n",
      "[1444/1762] D loss: 1.2943, G loss: 1.6374\n",
      "[1524/1762] D loss: 1.4420, G loss: 0.4952\n",
      "[1604/1762] D loss: 1.4722, G loss: 1.0782\n",
      "[1684/1762] D loss: 1.4833, G loss: 1.0471\n",
      "[1762/1762] D loss: 1.4594, G loss: 0.7025\n",
      "train error: \n",
      " D loss: 1.382608, G loss: 0.844634, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376450, G loss: 0.832676, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5435, G loss: 1.1987\n",
      "[84/1762] D loss: 0.3707, G loss: 1.5710\n",
      "[164/1762] D loss: 1.4668, G loss: 1.0195\n",
      "[244/1762] D loss: 1.3684, G loss: 0.9031\n",
      "[324/1762] D loss: 1.4394, G loss: 0.9354\n",
      "[404/1762] D loss: 1.4790, G loss: 0.4947\n",
      "[484/1762] D loss: 0.6116, G loss: 1.1542\n",
      "[564/1762] D loss: 1.4066, G loss: 0.8297\n",
      "[644/1762] D loss: 1.4189, G loss: 0.5829\n",
      "[724/1762] D loss: 0.1232, G loss: 2.7384\n",
      "[804/1762] D loss: 1.4922, G loss: 0.8542\n",
      "[884/1762] D loss: 1.3982, G loss: 0.7196\n",
      "[964/1762] D loss: 0.3873, G loss: 1.4649\n",
      "[1044/1762] D loss: 1.4061, G loss: 0.7763\n",
      "[1124/1762] D loss: 1.4842, G loss: 0.4833\n",
      "[1204/1762] D loss: 1.4336, G loss: 0.5099\n",
      "[1284/1762] D loss: 1.4009, G loss: 0.6919\n",
      "[1364/1762] D loss: 0.4592, G loss: 1.2865\n",
      "[1444/1762] D loss: 1.4421, G loss: 0.9178\n",
      "[1524/1762] D loss: 1.4002, G loss: 0.7807\n",
      "[1604/1762] D loss: 1.4014, G loss: 0.7697\n",
      "[1684/1762] D loss: 1.5216, G loss: 0.5088\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7063\n",
      "train error: \n",
      " D loss: 1.348507, G loss: 0.732114, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355156, G loss: 0.744696, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4115, G loss: 0.7434\n",
      "[84/1762] D loss: 1.4716, G loss: 0.9617\n",
      "[164/1762] D loss: 1.5444, G loss: 1.0354\n",
      "[244/1762] D loss: 1.4493, G loss: 0.8450\n",
      "[324/1762] D loss: 0.6244, G loss: 1.0656\n",
      "[404/1762] D loss: 1.7928, G loss: 0.8026\n",
      "[484/1762] D loss: 1.2767, G loss: 1.5004\n",
      "[564/1762] D loss: 0.2988, G loss: 1.6969\n",
      "[644/1762] D loss: 1.8751, G loss: 1.5371\n",
      "[724/1762] D loss: 1.6837, G loss: 0.9347\n",
      "[804/1762] D loss: 1.1397, G loss: 0.6443\n",
      "[884/1762] D loss: 1.3727, G loss: 0.8908\n",
      "[964/1762] D loss: 0.6644, G loss: 0.9735\n",
      "[1044/1762] D loss: 0.8284, G loss: 0.9288\n",
      "[1124/1762] D loss: 0.5029, G loss: 1.3358\n",
      "[1204/1762] D loss: 1.4128, G loss: 0.8367\n",
      "[1284/1762] D loss: 1.4592, G loss: 0.5296\n",
      "[1364/1762] D loss: 0.7725, G loss: 0.9663\n",
      "[1444/1762] D loss: 1.4249, G loss: 0.5725\n",
      "[1524/1762] D loss: 0.7044, G loss: 1.1239\n",
      "[1604/1762] D loss: 1.3753, G loss: 0.7245\n",
      "[1684/1762] D loss: 1.4035, G loss: 0.6000\n",
      "[1762/1762] D loss: 1.5352, G loss: 1.0772\n",
      "train error: \n",
      " D loss: 1.470434, G loss: 1.142648, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.465849, G loss: 1.147425, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5034, G loss: 1.0401\n",
      "[84/1762] D loss: 1.2588, G loss: 0.9684\n",
      "[164/1762] D loss: 1.3874, G loss: 0.7376\n",
      "[244/1762] D loss: 1.4364, G loss: 0.5481\n",
      "[324/1762] D loss: 1.3979, G loss: 0.6471\n",
      "[404/1762] D loss: 0.4518, G loss: 1.3684\n",
      "[484/1762] D loss: 0.3560, G loss: 1.8078\n",
      "[564/1762] D loss: 1.4792, G loss: 0.5066\n",
      "[644/1762] D loss: 1.4189, G loss: 0.5755\n",
      "[724/1762] D loss: 1.3490, G loss: 0.6123\n",
      "[804/1762] D loss: 0.3801, G loss: 1.5474\n",
      "[884/1762] D loss: 1.3910, G loss: 0.6295\n",
      "[964/1762] D loss: 1.4155, G loss: 0.7411\n",
      "[1044/1762] D loss: 1.3975, G loss: 0.8340\n",
      "[1124/1762] D loss: 1.4020, G loss: 0.8294\n",
      "[1204/1762] D loss: 0.2917, G loss: 1.8046\n",
      "[1284/1762] D loss: 0.3182, G loss: 1.7332\n",
      "[1364/1762] D loss: 1.4003, G loss: 0.9632\n",
      "[1444/1762] D loss: 1.4441, G loss: 0.9968\n",
      "[1524/1762] D loss: 1.2475, G loss: 0.8014\n",
      "[1604/1762] D loss: 1.4260, G loss: 0.6712\n",
      "[1684/1762] D loss: 0.4914, G loss: 2.0994\n",
      "[1762/1762] D loss: 1.4608, G loss: 0.9340\n",
      "train error: \n",
      " D loss: 1.355444, G loss: 0.861987, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350949, G loss: 0.872899, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5881, G loss: 1.1015\n",
      "[84/1762] D loss: 0.5227, G loss: 1.2124\n",
      "[164/1762] D loss: 1.4297, G loss: 0.7284\n",
      "[244/1762] D loss: 0.4537, G loss: 1.1946\n",
      "[324/1762] D loss: 1.4174, G loss: 0.7372\n",
      "[404/1762] D loss: 1.4260, G loss: 0.6144\n",
      "[484/1762] D loss: 1.4428, G loss: 0.9441\n",
      "[564/1762] D loss: 2.1036, G loss: 0.3141\n",
      "[644/1762] D loss: 3.8537, G loss: 0.1331\n",
      "[724/1762] D loss: 0.6371, G loss: 2.4014\n",
      "[804/1762] D loss: 0.7321, G loss: 2.6246\n",
      "[884/1762] D loss: 1.4299, G loss: 0.8536\n",
      "[964/1762] D loss: 1.3833, G loss: 0.8041\n",
      "[1044/1762] D loss: 1.4390, G loss: 0.8799\n",
      "[1124/1762] D loss: 1.3684, G loss: 0.7650\n",
      "[1204/1762] D loss: 1.4362, G loss: 0.5892\n",
      "[1284/1762] D loss: 1.4590, G loss: 0.8160\n",
      "[1364/1762] D loss: 1.4051, G loss: 0.7618\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.6433\n",
      "[1524/1762] D loss: 1.4586, G loss: 0.7976\n",
      "[1604/1762] D loss: 1.4674, G loss: 0.8709\n",
      "[1684/1762] D loss: 1.4411, G loss: 0.6556\n",
      "[1762/1762] D loss: 1.4603, G loss: 0.5643\n",
      "train error: \n",
      " D loss: 1.397502, G loss: 0.838381, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408811, G loss: 0.830365, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4788, G loss: 0.9525\n",
      "[84/1762] D loss: 1.4192, G loss: 0.8202\n",
      "[164/1762] D loss: 1.4466, G loss: 0.8796\n",
      "[244/1762] D loss: 1.4096, G loss: 0.6886\n",
      "[324/1762] D loss: 0.7886, G loss: 0.9750\n",
      "[404/1762] D loss: 1.4293, G loss: 0.8797\n",
      "[484/1762] D loss: 1.4128, G loss: 0.8190\n",
      "[564/1762] D loss: 1.4528, G loss: 0.8983\n",
      "[644/1762] D loss: 0.5802, G loss: 1.3257\n",
      "[724/1762] D loss: 1.4390, G loss: 0.7708\n",
      "[804/1762] D loss: 0.6052, G loss: 1.1263\n",
      "[884/1762] D loss: 1.4448, G loss: 0.5924\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6793\n",
      "[1044/1762] D loss: 1.9319, G loss: 0.6298\n",
      "[1124/1762] D loss: 1.1908, G loss: 1.1486\n",
      "[1204/1762] D loss: 0.8395, G loss: 1.5199\n",
      "[1284/1762] D loss: 0.6069, G loss: 1.1364\n",
      "[1364/1762] D loss: 1.5165, G loss: 0.4606\n",
      "[1444/1762] D loss: 1.4440, G loss: 0.9461\n",
      "[1524/1762] D loss: 1.4133, G loss: 0.8049\n",
      "[1604/1762] D loss: 0.6752, G loss: 1.1812\n",
      "[1684/1762] D loss: 1.3966, G loss: 0.6185\n",
      "[1762/1762] D loss: 1.4062, G loss: 0.8347\n",
      "train error: \n",
      " D loss: 1.374334, G loss: 0.753813, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379178, G loss: 0.745518, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4435, G loss: 0.8587\n",
      "[84/1762] D loss: 1.4127, G loss: 0.6414\n",
      "[164/1762] D loss: 1.3992, G loss: 0.6443\n",
      "[244/1762] D loss: 1.4342, G loss: 0.7529\n",
      "[324/1762] D loss: 0.6602, G loss: 1.0336\n",
      "[404/1762] D loss: 1.3912, G loss: 0.7313\n",
      "[484/1762] D loss: 1.4299, G loss: 0.8871\n",
      "[564/1762] D loss: 1.3701, G loss: 1.0597\n",
      "[644/1762] D loss: 0.6710, G loss: 1.0794\n",
      "[724/1762] D loss: 0.4776, G loss: 1.6631\n",
      "[804/1762] D loss: 1.3476, G loss: 0.7546\n",
      "[884/1762] D loss: 0.2031, G loss: 2.5764\n",
      "[964/1762] D loss: 1.3551, G loss: 1.0333\n",
      "[1044/1762] D loss: 1.5171, G loss: 1.0502\n",
      "[1124/1762] D loss: 0.4132, G loss: 1.6452\n",
      "[1204/1762] D loss: 0.3915, G loss: 1.9612\n",
      "[1284/1762] D loss: 1.4193, G loss: 0.5759\n",
      "[1364/1762] D loss: 1.4183, G loss: 0.5385\n",
      "[1444/1762] D loss: 1.3787, G loss: 0.7304\n",
      "[1524/1762] D loss: 1.3991, G loss: 0.6965\n",
      "[1604/1762] D loss: 1.3972, G loss: 0.6016\n",
      "[1684/1762] D loss: 0.3872, G loss: 1.4770\n",
      "[1762/1762] D loss: 1.3911, G loss: 0.6152\n",
      "train error: \n",
      " D loss: 1.356279, G loss: 0.668446, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359051, G loss: 0.671297, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2116, G loss: 2.2848\n",
      "[84/1762] D loss: 1.3889, G loss: 0.6191\n",
      "[164/1762] D loss: 0.6475, G loss: 1.0277\n",
      "[244/1762] D loss: 0.7137, G loss: 0.9014\n",
      "[324/1762] D loss: 1.4135, G loss: 0.6988\n",
      "[404/1762] D loss: 1.4154, G loss: 0.5436\n",
      "[484/1762] D loss: 0.5196, G loss: 1.3452\n",
      "[564/1762] D loss: 1.3917, G loss: 0.7500\n",
      "[644/1762] D loss: 1.4092, G loss: 0.7504\n",
      "[724/1762] D loss: 1.3967, G loss: 0.5454\n",
      "[804/1762] D loss: 0.5326, G loss: 1.3372\n",
      "[884/1762] D loss: 1.4469, G loss: 0.9625\n",
      "[964/1762] D loss: 1.3972, G loss: 0.6709\n",
      "[1044/1762] D loss: 1.4270, G loss: 0.8304\n",
      "[1124/1762] D loss: 1.5001, G loss: 0.9388\n",
      "[1204/1762] D loss: 1.3644, G loss: 0.6781\n",
      "[1284/1762] D loss: 1.4295, G loss: 0.7491\n",
      "[1364/1762] D loss: 1.4619, G loss: 1.0062\n",
      "[1444/1762] D loss: 1.4747, G loss: 0.5817\n",
      "[1524/1762] D loss: 1.4066, G loss: 0.5510\n",
      "[1604/1762] D loss: 1.4032, G loss: 0.8624\n",
      "[1684/1762] D loss: 1.4531, G loss: 0.9783\n",
      "[1762/1762] D loss: 1.3953, G loss: 0.7850\n",
      "train error: \n",
      " D loss: 1.347233, G loss: 0.837392, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350865, G loss: 0.841649, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3049, G loss: 1.7102\n",
      "[84/1762] D loss: 1.4852, G loss: 0.5318\n",
      "[164/1762] D loss: 1.3185, G loss: 0.9446\n",
      "[244/1762] D loss: 1.6708, G loss: 1.3085\n",
      "[324/1762] D loss: 1.6353, G loss: 0.4856\n",
      "[404/1762] D loss: 1.3912, G loss: 0.6530\n",
      "[484/1762] D loss: 0.2970, G loss: 1.6798\n",
      "[564/1762] D loss: 1.4141, G loss: 0.8627\n",
      "[644/1762] D loss: 0.3775, G loss: 1.3933\n",
      "[724/1762] D loss: 1.6187, G loss: 1.2686\n",
      "[804/1762] D loss: 0.5273, G loss: 0.9426\n",
      "[884/1762] D loss: 1.4424, G loss: 0.9722\n",
      "[964/1762] D loss: 1.3475, G loss: 0.7584\n",
      "[1044/1762] D loss: 0.1115, G loss: 2.5868\n",
      "[1124/1762] D loss: 1.4227, G loss: 0.5986\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.6625\n",
      "[1284/1762] D loss: 1.4715, G loss: 0.6838\n",
      "[1364/1762] D loss: 0.3570, G loss: 1.3771\n",
      "[1444/1762] D loss: 0.2265, G loss: 2.0291\n",
      "[1524/1762] D loss: 1.4306, G loss: 0.7527\n",
      "[1604/1762] D loss: 1.4153, G loss: 0.8726\n",
      "[1684/1762] D loss: 1.4004, G loss: 0.8147\n",
      "[1762/1762] D loss: 1.5316, G loss: 0.9738\n",
      "train error: \n",
      " D loss: 1.381153, G loss: 0.563334, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387327, G loss: 0.561153, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2939, G loss: 0.7819\n",
      "[84/1762] D loss: 1.5032, G loss: 0.5822\n",
      "[164/1762] D loss: 0.4394, G loss: 1.3687\n",
      "[244/1762] D loss: 1.4374, G loss: 0.9273\n",
      "[324/1762] D loss: 1.1993, G loss: 1.0538\n",
      "[404/1762] D loss: 1.5107, G loss: 0.7320\n",
      "[484/1762] D loss: 1.5444, G loss: 1.1473\n",
      "[564/1762] D loss: 1.4296, G loss: 0.8075\n",
      "[644/1762] D loss: 1.4915, G loss: 1.1016\n",
      "[724/1762] D loss: 1.4211, G loss: 0.5325\n",
      "[804/1762] D loss: 1.3933, G loss: 0.7363\n",
      "[884/1762] D loss: 0.4430, G loss: 1.2936\n",
      "[964/1762] D loss: 1.4434, G loss: 0.7852\n",
      "[1044/1762] D loss: 1.3529, G loss: 1.0574\n",
      "[1124/1762] D loss: 0.3169, G loss: 1.5293\n",
      "[1204/1762] D loss: 1.4156, G loss: 0.5265\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.6737\n",
      "[1364/1762] D loss: 1.4111, G loss: 0.5508\n",
      "[1444/1762] D loss: 0.4774, G loss: 1.1206\n",
      "[1524/1762] D loss: 1.4767, G loss: 0.4990\n",
      "[1604/1762] D loss: 1.4308, G loss: 0.9749\n",
      "[1684/1762] D loss: 0.3619, G loss: 1.5342\n",
      "[1762/1762] D loss: 1.4005, G loss: 0.7500\n",
      "train error: \n",
      " D loss: 1.349241, G loss: 0.694304, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352837, G loss: 0.696814, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3954, G loss: 0.7038\n",
      "[84/1762] D loss: 0.3791, G loss: 1.7963\n",
      "[164/1762] D loss: 1.5496, G loss: 1.1322\n",
      "[244/1762] D loss: 1.4268, G loss: 0.8189\n",
      "[324/1762] D loss: 1.6100, G loss: 1.2712\n",
      "[404/1762] D loss: 1.3980, G loss: 0.9292\n",
      "[484/1762] D loss: 1.4269, G loss: 0.9188\n",
      "[564/1762] D loss: 1.4466, G loss: 0.9263\n",
      "[644/1762] D loss: 1.4653, G loss: 0.9977\n",
      "[724/1762] D loss: 1.4174, G loss: 0.8470\n",
      "[804/1762] D loss: 1.4121, G loss: 0.7158\n",
      "[884/1762] D loss: 1.4511, G loss: 0.7710\n",
      "[964/1762] D loss: 1.4230, G loss: 0.9275\n",
      "[1044/1762] D loss: 0.3122, G loss: 1.5794\n",
      "[1124/1762] D loss: 1.3939, G loss: 0.6581\n",
      "[1204/1762] D loss: 0.3395, G loss: 1.4578\n",
      "[1284/1762] D loss: 0.5658, G loss: 1.1249\n",
      "[1364/1762] D loss: 0.3942, G loss: 1.3483\n",
      "[1444/1762] D loss: 1.3954, G loss: 0.7689\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.6965\n",
      "[1604/1762] D loss: 1.5263, G loss: 1.1714\n",
      "[1684/1762] D loss: 1.5751, G loss: 1.1423\n",
      "[1762/1762] D loss: 1.3685, G loss: 0.6076\n",
      "train error: \n",
      " D loss: 1.329978, G loss: 0.723249, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321333, G loss: 0.741372, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5273, G loss: 0.9200\n",
      "[84/1762] D loss: 1.4608, G loss: 1.0357\n",
      "[164/1762] D loss: 1.4446, G loss: 0.8660\n",
      "[244/1762] D loss: 1.4102, G loss: 0.5967\n",
      "[324/1762] D loss: 0.3299, G loss: 1.6369\n",
      "[404/1762] D loss: 0.3114, G loss: 1.4835\n",
      "[484/1762] D loss: 0.4073, G loss: 1.2865\n",
      "[564/1762] D loss: 0.3962, G loss: 1.2696\n",
      "[644/1762] D loss: 0.3614, G loss: 1.5818\n",
      "[724/1762] D loss: 1.3944, G loss: 0.7700\n",
      "[804/1762] D loss: 1.4019, G loss: 0.7934\n",
      "[884/1762] D loss: 0.3765, G loss: 1.5670\n",
      "[964/1762] D loss: 1.5607, G loss: 0.3987\n",
      "[1044/1762] D loss: 0.3569, G loss: 1.4241\n",
      "[1124/1762] D loss: 1.4397, G loss: 0.5324\n",
      "[1204/1762] D loss: 1.4361, G loss: 0.6853\n",
      "[1284/1762] D loss: 1.4798, G loss: 0.5779\n",
      "[1364/1762] D loss: 1.5078, G loss: 1.0249\n",
      "[1444/1762] D loss: 1.3819, G loss: 0.6080\n",
      "[1524/1762] D loss: 1.2083, G loss: 1.4197\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.6757\n",
      "[1684/1762] D loss: 0.4808, G loss: 1.1032\n",
      "[1762/1762] D loss: 1.3965, G loss: 0.7156\n",
      "train error: \n",
      " D loss: 1.342695, G loss: 0.768820, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341091, G loss: 0.788237, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4959, G loss: 0.6033\n",
      "[84/1762] D loss: 0.3773, G loss: 1.4500\n",
      "[164/1762] D loss: 1.3925, G loss: 0.7261\n",
      "[244/1762] D loss: 1.3906, G loss: 0.6364\n",
      "[324/1762] D loss: 1.5272, G loss: 1.1653\n",
      "[404/1762] D loss: 1.3179, G loss: 0.8088\n",
      "[484/1762] D loss: 1.2638, G loss: 0.7653\n",
      "[564/1762] D loss: 1.5677, G loss: 1.0324\n",
      "[644/1762] D loss: 1.4479, G loss: 0.6212\n",
      "[724/1762] D loss: 1.4514, G loss: 0.8163\n",
      "[804/1762] D loss: 1.5711, G loss: 1.1854\n",
      "[884/1762] D loss: 1.4386, G loss: 0.8248\n",
      "[964/1762] D loss: 1.4311, G loss: 0.5925\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.6625\n",
      "[1124/1762] D loss: 1.4816, G loss: 0.5083\n",
      "[1204/1762] D loss: 0.6258, G loss: 0.8933\n",
      "[1284/1762] D loss: 0.3042, G loss: 1.7199\n",
      "[1364/1762] D loss: 1.4072, G loss: 0.7998\n",
      "[1444/1762] D loss: 1.3996, G loss: 0.7789\n",
      "[1524/1762] D loss: 0.0621, G loss: 2.9937\n",
      "[1604/1762] D loss: 1.4426, G loss: 0.9945\n",
      "[1684/1762] D loss: 0.1774, G loss: 2.1379\n",
      "[1762/1762] D loss: 1.4181, G loss: 0.8281\n",
      "train error: \n",
      " D loss: 1.362506, G loss: 0.614881, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366099, G loss: 0.629741, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4548, G loss: 0.4905\n",
      "[84/1762] D loss: 1.4384, G loss: 0.9573\n",
      "[164/1762] D loss: 1.3964, G loss: 0.6507\n",
      "[244/1762] D loss: 1.4191, G loss: 0.5684\n",
      "[324/1762] D loss: 1.1032, G loss: 0.8913\n",
      "[404/1762] D loss: 1.2735, G loss: 1.1170\n",
      "[484/1762] D loss: 1.4020, G loss: 0.7176\n",
      "[564/1762] D loss: 1.4070, G loss: 0.6692\n",
      "[644/1762] D loss: 1.4023, G loss: 0.6226\n",
      "[724/1762] D loss: 1.4317, G loss: 0.9646\n",
      "[804/1762] D loss: 1.3973, G loss: 0.5989\n",
      "[884/1762] D loss: 1.4636, G loss: 0.9026\n",
      "[964/1762] D loss: 0.3159, G loss: 1.6562\n",
      "[1044/1762] D loss: 0.3280, G loss: 1.6081\n",
      "[1124/1762] D loss: 1.4884, G loss: 0.9675\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.7726\n",
      "[1284/1762] D loss: 1.2078, G loss: 1.4044\n",
      "[1364/1762] D loss: 1.4755, G loss: 0.9308\n",
      "[1444/1762] D loss: 0.0817, G loss: 2.6893\n",
      "[1524/1762] D loss: 1.4436, G loss: 0.7248\n",
      "[1604/1762] D loss: 1.2508, G loss: 0.9658\n",
      "[1684/1762] D loss: 1.6727, G loss: 0.4332\n",
      "[1762/1762] D loss: 1.3942, G loss: 0.6369\n",
      "train error: \n",
      " D loss: 1.345243, G loss: 0.750169, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345524, G loss: 0.758301, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2991, G loss: 0.7607\n",
      "[84/1762] D loss: 0.3320, G loss: 1.6925\n",
      "[164/1762] D loss: 1.4170, G loss: 0.6123\n",
      "[244/1762] D loss: 1.4603, G loss: 0.9111\n",
      "[324/1762] D loss: 0.2365, G loss: 2.3040\n",
      "[404/1762] D loss: 1.4191, G loss: 0.7744\n",
      "[484/1762] D loss: 1.4133, G loss: 0.7787\n",
      "[564/1762] D loss: 1.3998, G loss: 0.5336\n",
      "[644/1762] D loss: 1.4097, G loss: 0.8350\n",
      "[724/1762] D loss: 1.4547, G loss: 0.8935\n",
      "[804/1762] D loss: 1.2499, G loss: 0.6384\n",
      "[884/1762] D loss: 1.4292, G loss: 0.7236\n",
      "[964/1762] D loss: 0.3993, G loss: 1.1858\n",
      "[1044/1762] D loss: 1.4249, G loss: 0.7702\n",
      "[1124/1762] D loss: 1.4209, G loss: 0.7228\n",
      "[1204/1762] D loss: 0.5112, G loss: 0.9555\n",
      "[1284/1762] D loss: 1.4438, G loss: 0.8133\n",
      "[1364/1762] D loss: 0.2808, G loss: 1.5344\n",
      "[1444/1762] D loss: 0.0655, G loss: 3.1245\n",
      "[1524/1762] D loss: 1.4423, G loss: 0.9281\n",
      "[1604/1762] D loss: 1.4039, G loss: 0.7518\n",
      "[1684/1762] D loss: 1.4191, G loss: 0.5251\n",
      "[1762/1762] D loss: 1.7818, G loss: 0.2636\n",
      "train error: \n",
      " D loss: 1.392093, G loss: 0.529336, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402310, G loss: 0.527601, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4096, G loss: 0.7133\n",
      "[84/1762] D loss: 1.3833, G loss: 0.7110\n",
      "[164/1762] D loss: 1.3762, G loss: 0.6849\n",
      "[244/1762] D loss: 1.3415, G loss: 0.7209\n",
      "[324/1762] D loss: 1.3714, G loss: 0.7491\n",
      "[404/1762] D loss: 1.4037, G loss: 0.6704\n",
      "[484/1762] D loss: 1.3798, G loss: 0.7379\n",
      "[564/1762] D loss: 1.3243, G loss: 0.7599\n",
      "[644/1762] D loss: 1.3336, G loss: 0.6989\n",
      "[724/1762] D loss: 1.3001, G loss: 0.7470\n",
      "[804/1762] D loss: 1.3695, G loss: 0.7668\n",
      "[884/1762] D loss: 1.3722, G loss: 0.7228\n",
      "[964/1762] D loss: 1.3260, G loss: 0.7497\n",
      "[1044/1762] D loss: 1.3383, G loss: 0.7685\n",
      "[1124/1762] D loss: 1.3141, G loss: 0.6906\n",
      "[1204/1762] D loss: 1.3360, G loss: 0.7420\n",
      "[1284/1762] D loss: 1.3090, G loss: 0.7417\n",
      "[1364/1762] D loss: 1.3277, G loss: 0.7555\n",
      "[1444/1762] D loss: 1.3073, G loss: 0.7404\n",
      "[1524/1762] D loss: 1.3279, G loss: 0.7725\n",
      "[1604/1762] D loss: 1.2915, G loss: 0.7540\n",
      "[1684/1762] D loss: 1.3071, G loss: 0.7329\n",
      "[1762/1762] D loss: 1.3203, G loss: 0.6915\n",
      "train error: \n",
      " D loss: 1.294507, G loss: 0.735358, D accuracy: 81.4%, cell accuracy: 45.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289144, G loss: 0.737504, D accuracy: 83.3%, cell accuracy: 43.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3016, G loss: 0.8067\n",
      "[84/1762] D loss: 1.2997, G loss: 0.7729\n",
      "[164/1762] D loss: 1.2918, G loss: 0.7393\n",
      "[244/1762] D loss: 1.2722, G loss: 0.7217\n",
      "[324/1762] D loss: 1.2571, G loss: 0.7662\n",
      "[404/1762] D loss: 1.2526, G loss: 0.7797\n",
      "[484/1762] D loss: 1.1974, G loss: 0.7680\n",
      "[564/1762] D loss: 1.2743, G loss: 0.7404\n",
      "[644/1762] D loss: 1.2557, G loss: 0.7997\n",
      "[724/1762] D loss: 1.2063, G loss: 0.8041\n",
      "[804/1762] D loss: 1.2473, G loss: 0.7046\n",
      "[884/1762] D loss: 1.2079, G loss: 0.7849\n",
      "[964/1762] D loss: 1.2356, G loss: 0.8330\n",
      "[1044/1762] D loss: 1.1797, G loss: 0.7881\n",
      "[1124/1762] D loss: 1.2129, G loss: 0.8377\n",
      "[1204/1762] D loss: 1.2334, G loss: 0.7945\n",
      "[1284/1762] D loss: 1.1420, G loss: 0.7756\n",
      "[1364/1762] D loss: 1.1762, G loss: 0.8042\n",
      "[1444/1762] D loss: 1.2029, G loss: 0.8774\n",
      "[1524/1762] D loss: 1.1759, G loss: 0.7752\n",
      "[1604/1762] D loss: 1.1122, G loss: 0.8310\n",
      "[1684/1762] D loss: 1.0920, G loss: 0.7806\n",
      "[1762/1762] D loss: 1.1281, G loss: 0.7887\n",
      "train error: \n",
      " D loss: 1.127787, G loss: 0.837785, D accuracy: 97.1%, cell accuracy: 54.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.129190, G loss: 0.834094, D accuracy: 97.3%, cell accuracy: 54.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1059, G loss: 0.8568\n",
      "[84/1762] D loss: 1.1128, G loss: 0.8035\n",
      "[164/1762] D loss: 1.1190, G loss: 0.8725\n",
      "[244/1762] D loss: 1.1410, G loss: 0.7684\n",
      "[324/1762] D loss: 1.0355, G loss: 0.8882\n",
      "[404/1762] D loss: 1.0797, G loss: 0.8307\n",
      "[484/1762] D loss: 0.9819, G loss: 0.9192\n",
      "[564/1762] D loss: 1.0811, G loss: 0.8857\n",
      "[644/1762] D loss: 1.0296, G loss: 0.8633\n",
      "[724/1762] D loss: 0.9520, G loss: 0.9705\n",
      "[804/1762] D loss: 1.0306, G loss: 0.9147\n",
      "[884/1762] D loss: 0.9858, G loss: 0.8913\n",
      "[964/1762] D loss: 0.9731, G loss: 0.9325\n",
      "[1044/1762] D loss: 0.9514, G loss: 1.0186\n",
      "[1124/1762] D loss: 0.9783, G loss: 1.0280\n",
      "[1204/1762] D loss: 0.9721, G loss: 0.9115\n",
      "[1284/1762] D loss: 0.8784, G loss: 1.0673\n",
      "[1364/1762] D loss: 0.8753, G loss: 0.9980\n",
      "[1444/1762] D loss: 0.8518, G loss: 1.0668\n",
      "[1524/1762] D loss: 0.8645, G loss: 1.1169\n",
      "[1604/1762] D loss: 0.8343, G loss: 1.0372\n",
      "[1684/1762] D loss: 0.8427, G loss: 0.9990\n",
      "[1762/1762] D loss: 0.7874, G loss: 1.1994\n",
      "train error: \n",
      " D loss: 0.820851, G loss: 1.170966, D accuracy: 99.9%, cell accuracy: 67.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.826924, G loss: 1.161032, D accuracy: 100.0%, cell accuracy: 67.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8220, G loss: 1.1549\n",
      "[84/1762] D loss: 0.8114, G loss: 1.1195\n",
      "[164/1762] D loss: 0.7912, G loss: 1.1154\n",
      "[244/1762] D loss: 0.7990, G loss: 1.1370\n",
      "[324/1762] D loss: 0.7233, G loss: 1.1413\n",
      "[404/1762] D loss: 0.7484, G loss: 1.2822\n",
      "[484/1762] D loss: 0.7144, G loss: 1.2041\n",
      "[564/1762] D loss: 0.8224, G loss: 0.9761\n",
      "[644/1762] D loss: 0.7490, G loss: 1.2263\n",
      "[724/1762] D loss: 0.7435, G loss: 1.1280\n",
      "[804/1762] D loss: 0.7177, G loss: 1.1880\n",
      "[884/1762] D loss: 0.6322, G loss: 1.3097\n",
      "[964/1762] D loss: 0.6521, G loss: 1.3168\n",
      "[1044/1762] D loss: 0.5825, G loss: 1.2736\n",
      "[1124/1762] D loss: 0.6582, G loss: 1.2285\n",
      "[1204/1762] D loss: 0.6433, G loss: 1.3005\n",
      "[1284/1762] D loss: 0.6810, G loss: 1.2661\n",
      "[1364/1762] D loss: 0.5280, G loss: 1.5005\n",
      "[1444/1762] D loss: 0.5848, G loss: 1.3537\n",
      "[1524/1762] D loss: 0.5811, G loss: 1.3304\n",
      "[1604/1762] D loss: 0.5345, G loss: 1.4602\n",
      "[1684/1762] D loss: 0.5005, G loss: 1.4641\n",
      "[1762/1762] D loss: 0.6000, G loss: 1.3580\n",
      "train error: \n",
      " D loss: 0.597625, G loss: 1.530874, D accuracy: 99.9%, cell accuracy: 67.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.600760, G loss: 1.533634, D accuracy: 99.9%, cell accuracy: 66.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5857, G loss: 1.3647\n",
      "[84/1762] D loss: 0.5662, G loss: 1.3999\n",
      "[164/1762] D loss: 0.5139, G loss: 1.4596\n",
      "[244/1762] D loss: 0.4794, G loss: 1.5260\n",
      "[324/1762] D loss: 0.5026, G loss: 1.5074\n",
      "[404/1762] D loss: 0.5684, G loss: 1.4341\n",
      "[484/1762] D loss: 0.4300, G loss: 1.6019\n",
      "[564/1762] D loss: 0.4829, G loss: 1.5591\n",
      "[644/1762] D loss: 0.4834, G loss: 1.5604\n",
      "[724/1762] D loss: 0.5014, G loss: 1.4786\n",
      "[804/1762] D loss: 0.5402, G loss: 1.5509\n",
      "[884/1762] D loss: 0.4886, G loss: 1.5557\n",
      "[964/1762] D loss: 0.4567, G loss: 1.7289\n",
      "[1044/1762] D loss: 0.5388, G loss: 1.4470\n",
      "[1124/1762] D loss: 0.4909, G loss: 1.6481\n",
      "[1204/1762] D loss: 0.5065, G loss: 1.5979\n",
      "[1284/1762] D loss: 0.4880, G loss: 1.6508\n",
      "[1364/1762] D loss: 0.4649, G loss: 1.6748\n",
      "[1444/1762] D loss: 0.3957, G loss: 1.8536\n",
      "[1524/1762] D loss: 0.4451, G loss: 1.7675\n",
      "[1604/1762] D loss: 0.4237, G loss: 1.6799\n",
      "[1684/1762] D loss: 0.4909, G loss: 1.5853\n",
      "[1762/1762] D loss: 0.3685, G loss: 1.7491\n",
      "train error: \n",
      " D loss: 0.634514, G loss: 1.843778, D accuracy: 99.7%, cell accuracy: 60.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.653988, G loss: 1.798677, D accuracy: 99.5%, cell accuracy: 61.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3984, G loss: 1.8676\n",
      "[84/1762] D loss: 0.4393, G loss: 1.7349\n",
      "[164/1762] D loss: 0.4175, G loss: 1.7917\n",
      "[244/1762] D loss: 0.4154, G loss: 1.7305\n",
      "[324/1762] D loss: 0.3625, G loss: 1.9033\n",
      "[404/1762] D loss: 0.3919, G loss: 1.7510\n",
      "[484/1762] D loss: 0.3604, G loss: 1.8790\n",
      "[564/1762] D loss: 0.3619, G loss: 1.8956\n",
      "[644/1762] D loss: 0.3717, G loss: 1.8711\n",
      "[724/1762] D loss: 0.3409, G loss: 1.8941\n",
      "[804/1762] D loss: 0.3366, G loss: 1.8599\n",
      "[884/1762] D loss: 0.3374, G loss: 1.7636\n",
      "[964/1762] D loss: 0.3336, G loss: 1.8872\n",
      "[1044/1762] D loss: 0.2925, G loss: 2.0473\n",
      "[1124/1762] D loss: 0.3147, G loss: 1.9089\n",
      "[1204/1762] D loss: 0.3473, G loss: 1.8861\n",
      "[1284/1762] D loss: 0.2781, G loss: 2.1771\n",
      "[1364/1762] D loss: 0.2878, G loss: 2.0363\n",
      "[1444/1762] D loss: 0.3075, G loss: 2.0136\n",
      "[1524/1762] D loss: 0.3226, G loss: 1.8370\n",
      "[1604/1762] D loss: 0.4111, G loss: 1.7147\n",
      "[1684/1762] D loss: 0.2879, G loss: 2.1076\n",
      "[1762/1762] D loss: 0.2724, G loss: 2.0506\n",
      "train error: \n",
      " D loss: 0.653873, G loss: 1.955767, D accuracy: 98.4%, cell accuracy: 65.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.661822, G loss: 1.924962, D accuracy: 98.5%, cell accuracy: 67.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3303, G loss: 1.8161\n",
      "[84/1762] D loss: 0.3142, G loss: 1.9899\n",
      "[164/1762] D loss: 0.2757, G loss: 1.9475\n",
      "[244/1762] D loss: 0.2389, G loss: 2.1990\n",
      "[324/1762] D loss: 0.3064, G loss: 2.0045\n",
      "[404/1762] D loss: 0.2645, G loss: 2.0426\n",
      "[484/1762] D loss: 0.2949, G loss: 1.9535\n",
      "[564/1762] D loss: 0.2597, G loss: 2.1527\n",
      "[644/1762] D loss: 0.2861, G loss: 2.1434\n",
      "[724/1762] D loss: 0.2411, G loss: 2.0503\n",
      "[804/1762] D loss: 0.2135, G loss: 2.4292\n",
      "[884/1762] D loss: 0.2425, G loss: 2.2782\n",
      "[964/1762] D loss: 0.2231, G loss: 2.2863\n",
      "[1044/1762] D loss: 0.2578, G loss: 2.0961\n",
      "[1124/1762] D loss: 0.2395, G loss: 2.2482\n",
      "[1204/1762] D loss: 0.2484, G loss: 2.0812\n",
      "[1284/1762] D loss: 0.2132, G loss: 2.3141\n",
      "[1364/1762] D loss: 0.2448, G loss: 2.1446\n",
      "[1444/1762] D loss: 0.2222, G loss: 2.1895\n",
      "[1524/1762] D loss: 0.2478, G loss: 2.2818\n",
      "[1604/1762] D loss: 0.2228, G loss: 2.2276\n",
      "[1684/1762] D loss: 0.1881, G loss: 2.4262\n",
      "[1762/1762] D loss: 0.1900, G loss: 2.2827\n",
      "train error: \n",
      " D loss: 0.765120, G loss: 2.102320, D accuracy: 89.4%, cell accuracy: 71.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.774250, G loss: 2.072688, D accuracy: 87.3%, cell accuracy: 71.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2108, G loss: 2.3041\n",
      "[84/1762] D loss: 0.1979, G loss: 2.4451\n",
      "[164/1762] D loss: 0.1821, G loss: 2.3703\n",
      "[244/1762] D loss: 0.1858, G loss: 2.3804\n",
      "[324/1762] D loss: 0.1908, G loss: 2.3176\n",
      "[404/1762] D loss: 0.1688, G loss: 2.5281\n",
      "[484/1762] D loss: 0.2083, G loss: 2.4925\n",
      "[564/1762] D loss: 0.1898, G loss: 2.4682\n",
      "[644/1762] D loss: 0.1871, G loss: 2.4642\n",
      "[724/1762] D loss: 0.1760, G loss: 2.5299\n",
      "[804/1762] D loss: 0.1947, G loss: 2.3429\n",
      "[884/1762] D loss: 0.1560, G loss: 2.6525\n",
      "[964/1762] D loss: 0.1846, G loss: 2.3119\n",
      "[1044/1762] D loss: 0.1780, G loss: 2.4142\n",
      "[1124/1762] D loss: 0.1397, G loss: 2.6822\n",
      "[1204/1762] D loss: 0.1627, G loss: 2.5323\n",
      "[1284/1762] D loss: 0.1569, G loss: 2.4426\n",
      "[1364/1762] D loss: 0.1957, G loss: 2.4077\n",
      "[1444/1762] D loss: 0.1736, G loss: 2.5175\n",
      "[1524/1762] D loss: 0.1472, G loss: 2.6094\n",
      "[1604/1762] D loss: 0.1419, G loss: 2.6669\n",
      "[1684/1762] D loss: 0.1666, G loss: 2.4410\n",
      "[1762/1762] D loss: 0.1714, G loss: 2.4059\n",
      "train error: \n",
      " D loss: 0.818019, G loss: 2.367812, D accuracy: 76.6%, cell accuracy: 72.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.826584, G loss: 2.347422, D accuracy: 74.4%, cell accuracy: 72.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1649, G loss: 2.7113\n",
      "[84/1762] D loss: 0.1652, G loss: 2.5381\n",
      "[164/1762] D loss: 0.1514, G loss: 2.5413\n",
      "[244/1762] D loss: 0.1404, G loss: 2.7109\n",
      "[324/1762] D loss: 0.1604, G loss: 2.5045\n",
      "[404/1762] D loss: 0.1424, G loss: 2.6202\n",
      "[484/1762] D loss: 0.1407, G loss: 2.5218\n",
      "[564/1762] D loss: 0.1247, G loss: 2.8360\n",
      "[644/1762] D loss: 0.1312, G loss: 2.6661\n",
      "[724/1762] D loss: 0.1345, G loss: 2.8379\n",
      "[804/1762] D loss: 0.1243, G loss: 2.8547\n",
      "[884/1762] D loss: 0.1430, G loss: 2.6478\n",
      "[964/1762] D loss: 0.1250, G loss: 2.9965\n",
      "[1044/1762] D loss: 0.1173, G loss: 2.7827\n",
      "[1124/1762] D loss: 0.1291, G loss: 2.6325\n",
      "[1204/1762] D loss: 0.1289, G loss: 2.8843\n",
      "[1284/1762] D loss: 0.1938, G loss: 2.8020\n",
      "[1364/1762] D loss: 0.1342, G loss: 2.8939\n",
      "[1444/1762] D loss: 0.1394, G loss: 2.5609\n",
      "[1524/1762] D loss: 0.1150, G loss: 2.9545\n",
      "[1604/1762] D loss: 0.1121, G loss: 2.8756\n",
      "[1684/1762] D loss: 0.1226, G loss: 2.6453\n",
      "[1762/1762] D loss: 0.0992, G loss: 2.8491\n",
      "train error: \n",
      " D loss: 0.769280, G loss: 2.776459, D accuracy: 79.9%, cell accuracy: 65.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.776556, G loss: 2.761858, D accuracy: 78.1%, cell accuracy: 66.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1097, G loss: 2.9049\n",
      "[84/1762] D loss: 0.1556, G loss: 2.6033\n",
      "[164/1762] D loss: 0.1181, G loss: 2.7773\n",
      "[244/1762] D loss: 0.1064, G loss: 2.8266\n",
      "[324/1762] D loss: 0.1135, G loss: 2.9529\n",
      "[404/1762] D loss: 0.1064, G loss: 2.9407\n",
      "[484/1762] D loss: 0.1180, G loss: 2.9807\n",
      "[564/1762] D loss: 0.1107, G loss: 2.9955\n",
      "[644/1762] D loss: 0.0901, G loss: 3.1013\n",
      "[724/1762] D loss: 0.1143, G loss: 2.9254\n",
      "[804/1762] D loss: 0.0898, G loss: 3.2056\n",
      "[884/1762] D loss: 0.0867, G loss: 3.2160\n",
      "[964/1762] D loss: 0.0926, G loss: 3.0371\n",
      "[1044/1762] D loss: 0.0831, G loss: 3.1119\n",
      "[1124/1762] D loss: 0.0878, G loss: 3.3748\n",
      "[1204/1762] D loss: 0.1177, G loss: 2.8868\n",
      "[1284/1762] D loss: 0.0839, G loss: 3.0498\n",
      "[1364/1762] D loss: 0.1260, G loss: 2.9168\n",
      "[1444/1762] D loss: 0.1042, G loss: 2.9987\n",
      "[1524/1762] D loss: 0.0857, G loss: 3.2247\n",
      "[1604/1762] D loss: 0.1162, G loss: 3.1268\n",
      "[1684/1762] D loss: 0.0914, G loss: 3.1044\n",
      "[1762/1762] D loss: 0.0704, G loss: 3.3368\n",
      "train error: \n",
      " D loss: 0.843462, G loss: 3.007071, D accuracy: 68.6%, cell accuracy: 72.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.856070, G loss: 2.987824, D accuracy: 68.9%, cell accuracy: 72.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0914, G loss: 2.8870\n",
      "[84/1762] D loss: 0.0759, G loss: 3.2383\n",
      "[164/1762] D loss: 0.0775, G loss: 3.2508\n",
      "[244/1762] D loss: 0.0801, G loss: 3.3170\n",
      "[324/1762] D loss: 0.1170, G loss: 3.0832\n",
      "[404/1762] D loss: 0.1034, G loss: 3.0158\n",
      "[484/1762] D loss: 0.0936, G loss: 3.1955\n",
      "[564/1762] D loss: 0.1301, G loss: 2.9020\n",
      "[644/1762] D loss: 0.0704, G loss: 3.3317\n",
      "[724/1762] D loss: 0.0673, G loss: 3.3394\n",
      "[804/1762] D loss: 0.0893, G loss: 3.2567\n",
      "[884/1762] D loss: 0.0865, G loss: 3.3387\n",
      "[964/1762] D loss: 0.0636, G loss: 3.5745\n",
      "[1044/1762] D loss: 0.0654, G loss: 3.3270\n",
      "[1124/1762] D loss: 0.0719, G loss: 3.4933\n",
      "[1204/1762] D loss: 0.0737, G loss: 3.1776\n",
      "[1284/1762] D loss: 0.0859, G loss: 3.2240\n",
      "[1364/1762] D loss: 0.0602, G loss: 3.6149\n",
      "[1444/1762] D loss: 0.0673, G loss: 3.3527\n",
      "[1524/1762] D loss: 0.0602, G loss: 3.7377\n",
      "[1604/1762] D loss: 0.0692, G loss: 3.4070\n",
      "[1684/1762] D loss: 0.0610, G loss: 3.5592\n",
      "[1762/1762] D loss: 0.1059, G loss: 3.1408\n",
      "train error: \n",
      " D loss: 0.780881, G loss: 3.171253, D accuracy: 75.5%, cell accuracy: 71.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.792743, G loss: 3.153114, D accuracy: 74.9%, cell accuracy: 72.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0645, G loss: 3.4853\n",
      "[84/1762] D loss: 0.0612, G loss: 3.6220\n",
      "[164/1762] D loss: 0.0701, G loss: 3.5115\n",
      "[244/1762] D loss: 0.0709, G loss: 3.4349\n",
      "[324/1762] D loss: 0.0613, G loss: 3.6003\n",
      "[404/1762] D loss: 0.0664, G loss: 3.7506\n",
      "[484/1762] D loss: 0.0620, G loss: 3.4753\n",
      "[564/1762] D loss: 0.0637, G loss: 3.5230\n",
      "[644/1762] D loss: 0.0690, G loss: 3.4938\n",
      "[724/1762] D loss: 0.0488, G loss: 3.9916\n",
      "[804/1762] D loss: 0.0603, G loss: 3.7176\n",
      "[884/1762] D loss: 0.0778, G loss: 3.3882\n",
      "[964/1762] D loss: 0.0524, G loss: 3.5456\n",
      "[1044/1762] D loss: 0.0588, G loss: 3.4814\n",
      "[1124/1762] D loss: 0.0546, G loss: 3.5815\n",
      "[1204/1762] D loss: 0.0705, G loss: 3.4567\n",
      "[1284/1762] D loss: 0.0484, G loss: 3.5837\n",
      "[1364/1762] D loss: 0.0488, G loss: 3.7352\n",
      "[1444/1762] D loss: 0.0445, G loss: 3.8104\n",
      "[1524/1762] D loss: 0.0392, G loss: 3.8266\n",
      "[1604/1762] D loss: 0.0581, G loss: 3.4873\n",
      "[1684/1762] D loss: 0.0657, G loss: 3.6730\n",
      "[1762/1762] D loss: 0.0561, G loss: 3.7287\n",
      "train error: \n",
      " D loss: 1.074383, G loss: 3.438210, D accuracy: 54.1%, cell accuracy: 77.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.094496, G loss: 3.411251, D accuracy: 55.2%, cell accuracy: 77.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0526, G loss: 3.7441\n",
      "[84/1762] D loss: 0.0446, G loss: 3.9105\n",
      "[164/1762] D loss: 0.0640, G loss: 3.5699\n",
      "[244/1762] D loss: 0.0529, G loss: 3.7237\n",
      "[324/1762] D loss: 0.0738, G loss: 3.4584\n",
      "[404/1762] D loss: 0.0793, G loss: 3.4473\n",
      "[484/1762] D loss: 0.0459, G loss: 3.8738\n",
      "[564/1762] D loss: 0.0616, G loss: 3.7064\n",
      "[644/1762] D loss: 0.0599, G loss: 3.6444\n",
      "[724/1762] D loss: 0.0420, G loss: 3.8397\n",
      "[804/1762] D loss: 0.0528, G loss: 3.9327\n",
      "[884/1762] D loss: 0.0413, G loss: 3.7167\n",
      "[964/1762] D loss: 0.0364, G loss: 4.1346\n",
      "[1044/1762] D loss: 0.0414, G loss: 3.8676\n",
      "[1124/1762] D loss: 0.0472, G loss: 3.9783\n",
      "[1204/1762] D loss: 0.0488, G loss: 3.7497\n",
      "[1284/1762] D loss: 0.0387, G loss: 3.9397\n",
      "[1364/1762] D loss: 0.0362, G loss: 4.1728\n",
      "[1444/1762] D loss: 0.0638, G loss: 3.6146\n",
      "[1524/1762] D loss: 0.0449, G loss: 3.9915\n",
      "[1604/1762] D loss: 0.0418, G loss: 3.9631\n",
      "[1684/1762] D loss: 0.0319, G loss: 4.1739\n",
      "[1762/1762] D loss: 0.0490, G loss: 4.1348\n",
      "train error: \n",
      " D loss: 0.997927, G loss: 3.342090, D accuracy: 57.1%, cell accuracy: 76.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.018075, G loss: 3.314515, D accuracy: 57.7%, cell accuracy: 77.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0496, G loss: 4.0331\n",
      "[84/1762] D loss: 0.0426, G loss: 4.0048\n",
      "[164/1762] D loss: 0.0381, G loss: 4.1598\n",
      "[244/1762] D loss: 0.0486, G loss: 3.7908\n",
      "[324/1762] D loss: 0.0420, G loss: 3.7865\n",
      "[404/1762] D loss: 0.0377, G loss: 3.9563\n",
      "[484/1762] D loss: 0.0456, G loss: 3.8796\n",
      "[564/1762] D loss: 0.0596, G loss: 3.6020\n",
      "[644/1762] D loss: 0.0518, G loss: 3.6902\n",
      "[724/1762] D loss: 0.0471, G loss: 3.7972\n",
      "[804/1762] D loss: 0.0320, G loss: 4.1727\n",
      "[884/1762] D loss: 0.0420, G loss: 3.9160\n",
      "[964/1762] D loss: 0.0560, G loss: 4.0415\n",
      "[1044/1762] D loss: 0.0292, G loss: 4.1135\n",
      "[1124/1762] D loss: 0.0367, G loss: 4.1722\n",
      "[1204/1762] D loss: 0.0353, G loss: 4.0342\n",
      "[1284/1762] D loss: 0.0334, G loss: 4.2109\n",
      "[1364/1762] D loss: 0.0519, G loss: 3.7983\n",
      "[1444/1762] D loss: 0.0655, G loss: 3.6778\n",
      "[1524/1762] D loss: 0.0282, G loss: 4.0389\n",
      "[1604/1762] D loss: 0.0371, G loss: 4.3156\n",
      "[1684/1762] D loss: 0.0478, G loss: 3.6827\n",
      "[1762/1762] D loss: 0.0169, G loss: 5.1068\n",
      "train error: \n",
      " D loss: 1.088588, G loss: 3.816385, D accuracy: 53.0%, cell accuracy: 74.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.110551, G loss: 3.808010, D accuracy: 54.1%, cell accuracy: 75.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0520, G loss: 3.7984\n",
      "[84/1762] D loss: 0.0313, G loss: 4.0017\n",
      "[164/1762] D loss: 0.0360, G loss: 4.0464\n",
      "[244/1762] D loss: 0.0283, G loss: 4.3968\n",
      "[324/1762] D loss: 0.0251, G loss: 4.3167\n",
      "[404/1762] D loss: 0.0339, G loss: 4.1428\n",
      "[484/1762] D loss: 0.0238, G loss: 4.3624\n",
      "[564/1762] D loss: 0.0293, G loss: 4.0091\n",
      "[644/1762] D loss: 0.0439, G loss: 4.1228\n",
      "[724/1762] D loss: 0.0388, G loss: 4.0088\n",
      "[804/1762] D loss: 0.0214, G loss: 4.3949\n",
      "[884/1762] D loss: 0.0347, G loss: 4.1240\n",
      "[964/1762] D loss: 0.0259, G loss: 4.3650\n",
      "[1044/1762] D loss: 0.0274, G loss: 4.5093\n",
      "[1124/1762] D loss: 0.0255, G loss: 4.2826\n",
      "[1204/1762] D loss: 0.0320, G loss: 4.1115\n",
      "[1284/1762] D loss: 0.0210, G loss: 4.3695\n",
      "[1364/1762] D loss: 0.0195, G loss: 4.6955\n",
      "[1444/1762] D loss: 0.0251, G loss: 4.4154\n",
      "[1524/1762] D loss: 0.0238, G loss: 4.4553\n",
      "[1604/1762] D loss: 0.0329, G loss: 4.3648\n",
      "[1684/1762] D loss: 0.0318, G loss: 4.0091\n",
      "[1762/1762] D loss: 0.0186, G loss: 4.5975\n",
      "train error: \n",
      " D loss: 1.322318, G loss: 3.860904, D accuracy: 50.0%, cell accuracy: 76.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347465, G loss: 3.852534, D accuracy: 50.0%, cell accuracy: 77.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0276, G loss: 4.4225\n",
      "[84/1762] D loss: 0.0252, G loss: 4.6268\n",
      "[164/1762] D loss: 0.0340, G loss: 3.9099\n",
      "[244/1762] D loss: 0.0216, G loss: 4.4985\n",
      "[324/1762] D loss: 0.0175, G loss: 4.6969\n",
      "[404/1762] D loss: 0.0173, G loss: 4.4523\n",
      "[484/1762] D loss: 0.0274, G loss: 4.3756\n",
      "[564/1762] D loss: 0.0185, G loss: 4.6540\n",
      "[644/1762] D loss: 0.0448, G loss: 4.2678\n",
      "[724/1762] D loss: 0.0175, G loss: 4.7216\n",
      "[804/1762] D loss: 0.0237, G loss: 4.3758\n",
      "[884/1762] D loss: 0.0168, G loss: 4.6730\n",
      "[964/1762] D loss: 0.0252, G loss: 4.3537\n",
      "[1044/1762] D loss: 0.0244, G loss: 4.4875\n",
      "[1124/1762] D loss: 0.0220, G loss: 4.2597\n",
      "[1204/1762] D loss: 0.0244, G loss: 4.3890\n",
      "[1284/1762] D loss: 0.0453, G loss: 4.2722\n",
      "[1364/1762] D loss: 0.0136, G loss: 4.8701\n",
      "[1444/1762] D loss: 0.0352, G loss: 4.3357\n",
      "[1524/1762] D loss: 0.0135, G loss: 5.0021\n",
      "[1604/1762] D loss: 0.0172, G loss: 4.7795\n",
      "[1684/1762] D loss: 0.0215, G loss: 4.4635\n",
      "[1762/1762] D loss: 0.0168, G loss: 4.8522\n",
      "train error: \n",
      " D loss: 1.502038, G loss: 4.176348, D accuracy: 50.0%, cell accuracy: 79.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.529138, G loss: 4.231497, D accuracy: 50.0%, cell accuracy: 78.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0244, G loss: 4.2611\n",
      "[84/1762] D loss: 0.0162, G loss: 4.7397\n",
      "[164/1762] D loss: 0.0336, G loss: 4.3986\n",
      "[244/1762] D loss: 0.0182, G loss: 4.6029\n",
      "[324/1762] D loss: 0.0209, G loss: 4.8253\n",
      "[404/1762] D loss: 0.0186, G loss: 4.6412\n",
      "[484/1762] D loss: 0.0234, G loss: 4.5863\n",
      "[564/1762] D loss: 0.0226, G loss: 5.0580\n",
      "[644/1762] D loss: 0.0192, G loss: 4.5448\n",
      "[724/1762] D loss: 0.0137, G loss: 5.1078\n",
      "[804/1762] D loss: 0.0312, G loss: 4.3468\n",
      "[884/1762] D loss: 0.0217, G loss: 4.8331\n",
      "[964/1762] D loss: 0.0184, G loss: 4.7728\n",
      "[1044/1762] D loss: 0.0185, G loss: 4.7218\n",
      "[1124/1762] D loss: 0.0231, G loss: 4.7417\n",
      "[1204/1762] D loss: 0.0127, G loss: 4.8682\n",
      "[1284/1762] D loss: 0.0154, G loss: 4.9819\n",
      "[1364/1762] D loss: 0.0151, G loss: 4.9158\n",
      "[1444/1762] D loss: 0.0183, G loss: 4.8001\n",
      "[1524/1762] D loss: 0.0157, G loss: 4.7931\n",
      "[1604/1762] D loss: 0.0112, G loss: 4.9912\n",
      "[1684/1762] D loss: 0.0206, G loss: 4.7459\n",
      "[1762/1762] D loss: 0.0302, G loss: 4.2909\n",
      "train error: \n",
      " D loss: 1.243775, G loss: 4.296451, D accuracy: 50.3%, cell accuracy: 80.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268513, G loss: 4.303341, D accuracy: 51.0%, cell accuracy: 80.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0117, G loss: 5.2019\n",
      "[84/1762] D loss: 0.0216, G loss: 4.7333\n",
      "[164/1762] D loss: 0.0154, G loss: 4.8149\n",
      "[244/1762] D loss: 0.0248, G loss: 4.6681\n",
      "[324/1762] D loss: 0.0100, G loss: 5.2476\n",
      "[404/1762] D loss: 0.0312, G loss: 3.9283\n",
      "[484/1762] D loss: 0.0122, G loss: 5.2016\n",
      "[564/1762] D loss: 0.0129, G loss: 5.0199\n",
      "[644/1762] D loss: 0.0203, G loss: 4.5703\n",
      "[724/1762] D loss: 0.0110, G loss: 5.1778\n",
      "[804/1762] D loss: 0.0208, G loss: 5.1304\n",
      "[884/1762] D loss: 0.0100, G loss: 5.2023\n",
      "[964/1762] D loss: 0.0112, G loss: 5.1429\n",
      "[1044/1762] D loss: 0.0136, G loss: 5.1150\n",
      "[1124/1762] D loss: 0.0190, G loss: 4.7904\n",
      "[1204/1762] D loss: 0.0171, G loss: 5.0494\n",
      "[1284/1762] D loss: 0.0118, G loss: 5.0324\n",
      "[1364/1762] D loss: 0.0138, G loss: 5.0009\n",
      "[1444/1762] D loss: 0.0153, G loss: 5.0816\n",
      "[1524/1762] D loss: 0.0136, G loss: 5.0194\n",
      "[1604/1762] D loss: 0.0132, G loss: 4.9549\n",
      "[1684/1762] D loss: 0.0106, G loss: 5.1888\n",
      "[1762/1762] D loss: 0.0186, G loss: 4.8921\n",
      "train error: \n",
      " D loss: 1.263858, G loss: 4.224654, D accuracy: 50.2%, cell accuracy: 82.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287916, G loss: 4.257587, D accuracy: 50.7%, cell accuracy: 81.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0143, G loss: 4.9546\n",
      "[84/1762] D loss: 0.0097, G loss: 5.2863\n",
      "[164/1762] D loss: 0.0127, G loss: 5.0844\n",
      "[244/1762] D loss: 0.0152, G loss: 5.1535\n",
      "[324/1762] D loss: 0.0108, G loss: 5.2614\n",
      "[404/1762] D loss: 0.0322, G loss: 3.9644\n",
      "[484/1762] D loss: 0.0180, G loss: 4.8583\n",
      "[564/1762] D loss: 0.0190, G loss: 4.8714\n",
      "[644/1762] D loss: 0.0360, G loss: 4.1528\n",
      "[724/1762] D loss: 0.0173, G loss: 4.8977\n",
      "[804/1762] D loss: 0.0110, G loss: 5.1122\n",
      "[884/1762] D loss: 0.0143, G loss: 5.0102\n",
      "[964/1762] D loss: 0.0080, G loss: 5.3362\n",
      "[1044/1762] D loss: 0.0103, G loss: 5.1353\n",
      "[1124/1762] D loss: 0.0099, G loss: 5.5301\n",
      "[1204/1762] D loss: 0.0084, G loss: 5.2696\n",
      "[1284/1762] D loss: 0.0101, G loss: 5.1872\n",
      "[1364/1762] D loss: 0.0109, G loss: 5.1876\n",
      "[1444/1762] D loss: 0.0116, G loss: 5.2261\n",
      "[1524/1762] D loss: 0.0142, G loss: 5.2506\n",
      "[1604/1762] D loss: 0.0101, G loss: 5.4459\n",
      "[1684/1762] D loss: 0.0069, G loss: 5.5919\n",
      "[1762/1762] D loss: 0.0098, G loss: 5.0567\n",
      "train error: \n",
      " D loss: 1.377420, G loss: 4.943564, D accuracy: 50.1%, cell accuracy: 82.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403624, G loss: 4.880395, D accuracy: 50.5%, cell accuracy: 82.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0109, G loss: 5.4929\n",
      "[84/1762] D loss: 0.0077, G loss: 5.4934\n",
      "[164/1762] D loss: 0.0209, G loss: 4.7636\n",
      "[244/1762] D loss: 0.0080, G loss: 5.5159\n",
      "[324/1762] D loss: 0.0118, G loss: 4.9094\n",
      "[404/1762] D loss: 0.0115, G loss: 5.3472\n",
      "[484/1762] D loss: 0.0079, G loss: 5.4252\n",
      "[564/1762] D loss: 0.0134, G loss: 5.1839\n",
      "[644/1762] D loss: 0.0064, G loss: 6.0277\n",
      "[724/1762] D loss: 0.0051, G loss: 6.3118\n",
      "[804/1762] D loss: 0.0104, G loss: 5.5138\n",
      "[884/1762] D loss: 0.0150, G loss: 5.4300\n",
      "[964/1762] D loss: 0.0069, G loss: 5.6562\n",
      "[1044/1762] D loss: 0.0093, G loss: 5.6346\n",
      "[1124/1762] D loss: 0.0094, G loss: 5.5888\n",
      "[1204/1762] D loss: 0.0069, G loss: 5.8119\n",
      "[1284/1762] D loss: 0.0267, G loss: 3.9349\n",
      "[1364/1762] D loss: 0.0048, G loss: 6.1800\n",
      "[1444/1762] D loss: 0.0063, G loss: 6.6207\n",
      "[1524/1762] D loss: 0.0110, G loss: 5.1721\n",
      "[1604/1762] D loss: 0.0078, G loss: 5.5572\n",
      "[1684/1762] D loss: 0.0088, G loss: 5.6028\n",
      "[1762/1762] D loss: 0.0136, G loss: 5.2273\n",
      "train error: \n",
      " D loss: 0.987730, G loss: 5.001485, D accuracy: 59.6%, cell accuracy: 81.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.010316, G loss: 5.028528, D accuracy: 59.7%, cell accuracy: 81.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0067, G loss: 5.7764\n",
      "[84/1762] D loss: 0.0134, G loss: 5.2549\n",
      "[164/1762] D loss: 0.0104, G loss: 5.1913\n",
      "[244/1762] D loss: 0.0111, G loss: 5.3359\n",
      "[324/1762] D loss: 0.0048, G loss: 5.9660\n",
      "[404/1762] D loss: 0.0108, G loss: 5.9616\n",
      "[484/1762] D loss: 0.0181, G loss: 5.4326\n",
      "[564/1762] D loss: 0.0071, G loss: 5.8722\n",
      "[644/1762] D loss: 0.0065, G loss: 5.8264\n",
      "[724/1762] D loss: 0.0187, G loss: 4.4488\n",
      "[804/1762] D loss: 0.0057, G loss: 6.0799\n",
      "[884/1762] D loss: 0.0094, G loss: 5.5612\n",
      "[964/1762] D loss: 0.0307, G loss: 3.8184\n",
      "[1044/1762] D loss: 0.0072, G loss: 5.8276\n",
      "[1124/1762] D loss: 0.0074, G loss: 5.7634\n",
      "[1204/1762] D loss: 0.0065, G loss: 5.7593\n",
      "[1284/1762] D loss: 0.0147, G loss: 5.4402\n",
      "[1364/1762] D loss: 0.0039, G loss: 6.4504\n",
      "[1444/1762] D loss: 0.0214, G loss: 4.3131\n",
      "[1524/1762] D loss: 0.0083, G loss: 5.7420\n",
      "[1604/1762] D loss: 0.0078, G loss: 5.6463\n",
      "[1684/1762] D loss: 0.0112, G loss: 5.6193\n",
      "[1762/1762] D loss: 0.0043, G loss: 6.8066\n",
      "train error: \n",
      " D loss: 1.551829, G loss: 5.178424, D accuracy: 50.0%, cell accuracy: 82.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.578980, G loss: 5.223089, D accuracy: 50.0%, cell accuracy: 82.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0091, G loss: 5.6073\n",
      "[84/1762] D loss: 0.0102, G loss: 6.0089\n",
      "[164/1762] D loss: 0.0201, G loss: 4.9978\n",
      "[244/1762] D loss: 0.0048, G loss: 5.9875\n",
      "[324/1762] D loss: 0.0097, G loss: 5.9383\n",
      "[404/1762] D loss: 0.0147, G loss: 4.7616\n",
      "[484/1762] D loss: 0.0144, G loss: 5.2234\n",
      "[564/1762] D loss: 0.0317, G loss: 3.7492\n",
      "[644/1762] D loss: 0.0074, G loss: 5.7810\n",
      "[724/1762] D loss: 0.0059, G loss: 6.0056\n",
      "[804/1762] D loss: 0.0064, G loss: 5.8399\n",
      "[884/1762] D loss: 0.0088, G loss: 6.0075\n",
      "[964/1762] D loss: 0.0075, G loss: 5.8664\n",
      "[1044/1762] D loss: 0.0082, G loss: 5.3751\n",
      "[1124/1762] D loss: 0.0049, G loss: 5.9664\n",
      "[1204/1762] D loss: 0.0134, G loss: 4.7926\n",
      "[1284/1762] D loss: 0.0083, G loss: 5.9570\n",
      "[1364/1762] D loss: 0.0071, G loss: 5.6281\n",
      "[1444/1762] D loss: 0.0061, G loss: 5.7748\n",
      "[1524/1762] D loss: 0.0060, G loss: 5.9382\n",
      "[1604/1762] D loss: 0.0057, G loss: 6.0189\n",
      "[1684/1762] D loss: 0.0095, G loss: 5.6165\n",
      "[1762/1762] D loss: 0.0043, G loss: 6.1713\n",
      "train error: \n",
      " D loss: 1.486175, G loss: 5.379804, D accuracy: 50.2%, cell accuracy: 84.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.513366, G loss: 5.407962, D accuracy: 50.3%, cell accuracy: 84.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0044, G loss: 5.8749\n",
      "[84/1762] D loss: 0.0070, G loss: 5.7400\n",
      "[164/1762] D loss: 0.0145, G loss: 4.9089\n",
      "[244/1762] D loss: 0.0123, G loss: 4.8040\n",
      "[324/1762] D loss: 0.0062, G loss: 5.8080\n",
      "[404/1762] D loss: 0.0092, G loss: 5.8082\n",
      "[484/1762] D loss: 0.0045, G loss: 6.0756\n",
      "[564/1762] D loss: 0.0140, G loss: 4.5863\n",
      "[644/1762] D loss: 0.0042, G loss: 6.1386\n",
      "[724/1762] D loss: 0.0132, G loss: 5.4727\n",
      "[804/1762] D loss: 0.0072, G loss: 5.7089\n",
      "[884/1762] D loss: 0.0042, G loss: 6.2244\n",
      "[964/1762] D loss: 0.0054, G loss: 6.3265\n",
      "[1044/1762] D loss: 0.0049, G loss: 6.2856\n",
      "[1124/1762] D loss: 0.0159, G loss: 4.6138\n",
      "[1204/1762] D loss: 0.0052, G loss: 6.1695\n",
      "[1284/1762] D loss: 0.0057, G loss: 6.0168\n",
      "[1364/1762] D loss: 0.0064, G loss: 6.0291\n",
      "[1444/1762] D loss: 0.0084, G loss: 5.6606\n",
      "[1524/1762] D loss: 0.0113, G loss: 4.9795\n",
      "[1604/1762] D loss: 0.0147, G loss: 4.6225\n",
      "[1684/1762] D loss: 0.0052, G loss: 6.3504\n",
      "[1762/1762] D loss: 0.0036, G loss: 6.5390\n",
      "train error: \n",
      " D loss: 1.742553, G loss: 5.535538, D accuracy: 50.0%, cell accuracy: 84.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.768898, G loss: 5.541480, D accuracy: 50.0%, cell accuracy: 84.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0046, G loss: 6.2103\n",
      "[84/1762] D loss: 0.0060, G loss: 6.0016\n",
      "[164/1762] D loss: 0.0201, G loss: 5.1815\n",
      "[244/1762] D loss: 0.0072, G loss: 5.4820\n",
      "[324/1762] D loss: 0.0074, G loss: 5.7433\n",
      "[404/1762] D loss: 0.0049, G loss: 6.0755\n",
      "[484/1762] D loss: 0.0027, G loss: 6.6208\n",
      "[564/1762] D loss: 0.0112, G loss: 4.8593\n",
      "[644/1762] D loss: 0.0050, G loss: 6.0762\n",
      "[724/1762] D loss: 0.0051, G loss: 6.2584\n",
      "[804/1762] D loss: 0.0028, G loss: 6.7884\n",
      "[884/1762] D loss: 0.0059, G loss: 6.2703\n",
      "[964/1762] D loss: 0.0063, G loss: 6.2118\n",
      "[1044/1762] D loss: 0.0053, G loss: 6.0323\n",
      "[1124/1762] D loss: 0.0025, G loss: 6.5879\n",
      "[1204/1762] D loss: 0.0185, G loss: 4.3992\n",
      "[1284/1762] D loss: 0.0039, G loss: 6.3098\n",
      "[1364/1762] D loss: 0.0056, G loss: 5.8260\n",
      "[1444/1762] D loss: 0.0043, G loss: 6.5570\n",
      "[1524/1762] D loss: 0.0056, G loss: 6.0411\n",
      "[1604/1762] D loss: 0.0100, G loss: 5.7844\n",
      "[1684/1762] D loss: 0.0034, G loss: 6.4229\n",
      "[1762/1762] D loss: 0.0034, G loss: 6.2606\n",
      "train error: \n",
      " D loss: 1.680281, G loss: 5.734509, D accuracy: 50.0%, cell accuracy: 85.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.705392, G loss: 5.787164, D accuracy: 50.1%, cell accuracy: 84.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0087, G loss: 5.5794\n",
      "[84/1762] D loss: 0.0528, G loss: 3.1871\n",
      "[164/1762] D loss: 0.0086, G loss: 6.2081\n",
      "[244/1762] D loss: 0.0122, G loss: 5.3442\n",
      "[324/1762] D loss: 0.0050, G loss: 5.8956\n",
      "[404/1762] D loss: 0.0068, G loss: 6.5302\n",
      "[484/1762] D loss: 0.0040, G loss: 6.4905\n",
      "[564/1762] D loss: 0.0045, G loss: 6.2014\n",
      "[644/1762] D loss: 0.0036, G loss: 6.4268\n",
      "[724/1762] D loss: 0.0072, G loss: 5.8829\n",
      "[804/1762] D loss: 0.0043, G loss: 6.0597\n",
      "[884/1762] D loss: 0.0052, G loss: 6.4114\n",
      "[964/1762] D loss: 0.0059, G loss: 6.2467\n",
      "[1044/1762] D loss: 0.0055, G loss: 6.1759\n",
      "[1124/1762] D loss: 0.0293, G loss: 4.3611\n",
      "[1204/1762] D loss: 0.0214, G loss: 4.3857\n",
      "[1284/1762] D loss: 0.0057, G loss: 5.5489\n",
      "[1364/1762] D loss: 0.0025, G loss: 7.5829\n",
      "[1444/1762] D loss: 0.0063, G loss: 6.1057\n",
      "[1524/1762] D loss: 0.0035, G loss: 6.4495\n",
      "[1604/1762] D loss: 0.0047, G loss: 6.0886\n",
      "[1684/1762] D loss: 0.0048, G loss: 6.3653\n",
      "[1762/1762] D loss: 0.0100, G loss: 5.6994\n",
      "train error: \n",
      " D loss: 2.050600, G loss: 5.796668, D accuracy: 50.0%, cell accuracy: 85.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.077996, G loss: 5.826861, D accuracy: 50.0%, cell accuracy: 85.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0039, G loss: 6.5989\n",
      "[84/1762] D loss: 0.0033, G loss: 6.4678\n",
      "[164/1762] D loss: 0.0055, G loss: 6.2358\n",
      "[244/1762] D loss: 0.0070, G loss: 6.4570\n",
      "[324/1762] D loss: 0.0072, G loss: 6.3422\n",
      "[404/1762] D loss: 0.0049, G loss: 6.3522\n",
      "[484/1762] D loss: 0.0049, G loss: 6.2140\n",
      "[564/1762] D loss: 0.0055, G loss: 6.2054\n",
      "[644/1762] D loss: 0.0169, G loss: 4.6033\n",
      "[724/1762] D loss: 0.0034, G loss: 6.4488\n",
      "[804/1762] D loss: 0.0080, G loss: 6.4556\n",
      "[884/1762] D loss: 0.0105, G loss: 6.2788\n",
      "[964/1762] D loss: 0.0060, G loss: 6.1542\n",
      "[1044/1762] D loss: 0.0034, G loss: 6.9567\n",
      "[1124/1762] D loss: 0.0437, G loss: 3.5133\n",
      "[1204/1762] D loss: 0.0043, G loss: 6.4270\n",
      "[1284/1762] D loss: 0.0043, G loss: 6.6628\n",
      "[1364/1762] D loss: 0.0082, G loss: 6.2398\n",
      "[1444/1762] D loss: 0.0073, G loss: 6.6913\n",
      "[1524/1762] D loss: 0.0038, G loss: 6.4530\n",
      "[1604/1762] D loss: 0.0053, G loss: 6.5600\n",
      "[1684/1762] D loss: 0.0040, G loss: 6.4739\n",
      "[1762/1762] D loss: 0.0610, G loss: 3.9235\n",
      "train error: \n",
      " D loss: 0.814494, G loss: 5.120561, D accuracy: 70.8%, cell accuracy: 85.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.831176, G loss: 5.209618, D accuracy: 72.4%, cell accuracy: 84.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0033, G loss: 6.5247\n",
      "[84/1762] D loss: 0.0051, G loss: 6.1737\n",
      "[164/1762] D loss: 0.0032, G loss: 6.4702\n",
      "[244/1762] D loss: 0.0082, G loss: 5.9081\n",
      "[324/1762] D loss: 0.0058, G loss: 5.5980\n",
      "[404/1762] D loss: 0.0070, G loss: 5.5756\n",
      "[484/1762] D loss: 0.0036, G loss: 6.5846\n",
      "[564/1762] D loss: 0.0062, G loss: 6.3761\n",
      "[644/1762] D loss: 0.0062, G loss: 6.1634\n",
      "[724/1762] D loss: 0.0030, G loss: 7.0886\n",
      "[804/1762] D loss: 0.0049, G loss: 6.3476\n",
      "[884/1762] D loss: 0.0041, G loss: 6.8627\n",
      "[964/1762] D loss: 0.0049, G loss: 6.5974\n",
      "[1044/1762] D loss: 0.0040, G loss: 6.9455\n",
      "[1124/1762] D loss: 0.0072, G loss: 5.5917\n",
      "[1204/1762] D loss: 0.0064, G loss: 5.4634\n",
      "[1284/1762] D loss: 0.0156, G loss: 4.9150\n",
      "[1364/1762] D loss: 0.0044, G loss: 7.0128\n",
      "[1444/1762] D loss: 0.0267, G loss: 5.7659\n",
      "[1524/1762] D loss: 0.0037, G loss: 6.4105\n",
      "[1604/1762] D loss: 0.0098, G loss: 6.7581\n",
      "[1684/1762] D loss: 0.0048, G loss: 6.7277\n",
      "[1762/1762] D loss: 0.0013, G loss: 7.2910\n",
      "train error: \n",
      " D loss: 1.896792, G loss: 6.504182, D accuracy: 50.0%, cell accuracy: 84.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.924050, G loss: 6.515024, D accuracy: 50.0%, cell accuracy: 84.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0065, G loss: 5.9994\n",
      "[84/1762] D loss: 0.0055, G loss: 6.0062\n",
      "[164/1762] D loss: 0.0134, G loss: 5.4703\n",
      "[244/1762] D loss: 0.0030, G loss: 7.1398\n",
      "[324/1762] D loss: 0.0045, G loss: 6.3658\n",
      "[404/1762] D loss: 0.0153, G loss: 4.5140\n",
      "[484/1762] D loss: 0.0125, G loss: 5.5942\n",
      "[564/1762] D loss: 0.0048, G loss: 6.1961\n",
      "[644/1762] D loss: 0.0090, G loss: 5.0339\n",
      "[724/1762] D loss: 0.0027, G loss: 6.7446\n",
      "[804/1762] D loss: 0.0041, G loss: 6.7453\n",
      "[884/1762] D loss: 0.0084, G loss: 7.4910\n",
      "[964/1762] D loss: 0.0024, G loss: 6.7623\n",
      "[1044/1762] D loss: 0.0030, G loss: 6.6542\n",
      "[1124/1762] D loss: 0.0039, G loss: 6.3766\n",
      "[1204/1762] D loss: 0.0049, G loss: 6.9722\n",
      "[1284/1762] D loss: 0.0118, G loss: 4.8774\n",
      "[1364/1762] D loss: 0.0025, G loss: 6.9379\n",
      "[1444/1762] D loss: 0.0035, G loss: 6.4935\n",
      "[1524/1762] D loss: 0.0058, G loss: 6.5401\n",
      "[1604/1762] D loss: 0.0029, G loss: 6.7021\n",
      "[1684/1762] D loss: 0.0029, G loss: 6.7408\n",
      "[1762/1762] D loss: 0.0028, G loss: 7.0911\n",
      "train error: \n",
      " D loss: 2.005274, G loss: 6.260990, D accuracy: 50.0%, cell accuracy: 86.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.032450, G loss: 6.304534, D accuracy: 50.0%, cell accuracy: 86.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0075, G loss: 6.3921\n",
      "[84/1762] D loss: 0.0086, G loss: 6.4022\n",
      "[164/1762] D loss: 0.0044, G loss: 6.5496\n",
      "[244/1762] D loss: 0.0078, G loss: 5.6948\n",
      "[324/1762] D loss: 0.0038, G loss: 6.6262\n",
      "[404/1762] D loss: 0.0096, G loss: 5.1535\n",
      "[484/1762] D loss: 0.0054, G loss: 6.1035\n",
      "[564/1762] D loss: 0.0079, G loss: 5.4011\n",
      "[644/1762] D loss: 0.0030, G loss: 6.7355\n",
      "[724/1762] D loss: 0.0026, G loss: 6.8414\n",
      "[804/1762] D loss: 0.0022, G loss: 7.0035\n",
      "[884/1762] D loss: 0.0128, G loss: 4.8184\n",
      "[964/1762] D loss: 0.0029, G loss: 6.9025\n",
      "[1044/1762] D loss: 0.0035, G loss: 6.2339\n",
      "[1124/1762] D loss: 0.0068, G loss: 6.3232\n",
      "[1204/1762] D loss: 0.0059, G loss: 5.6863\n",
      "[1284/1762] D loss: 0.0035, G loss: 6.5795\n",
      "[1364/1762] D loss: 0.0022, G loss: 6.8314\n",
      "[1444/1762] D loss: 0.0032, G loss: 6.9251\n",
      "[1524/1762] D loss: 0.0020, G loss: 7.0710\n",
      "[1604/1762] D loss: 0.0035, G loss: 7.2067\n",
      "[1684/1762] D loss: 0.0019, G loss: 6.7493\n",
      "[1762/1762] D loss: 0.0034, G loss: 7.0603\n",
      "train error: \n",
      " D loss: 1.615540, G loss: 5.800589, D accuracy: 50.3%, cell accuracy: 88.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.641098, G loss: 5.798493, D accuracy: 50.3%, cell accuracy: 88.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0045, G loss: 6.5176\n",
      "[84/1762] D loss: 0.0020, G loss: 6.6300\n",
      "[164/1762] D loss: 0.0039, G loss: 6.8647\n",
      "[244/1762] D loss: 0.0034, G loss: 7.0106\n",
      "[324/1762] D loss: 0.0027, G loss: 6.8359\n",
      "[404/1762] D loss: 0.0119, G loss: 5.5822\n",
      "[484/1762] D loss: 0.0107, G loss: 5.3221\n",
      "[564/1762] D loss: 0.0043, G loss: 6.3064\n",
      "[644/1762] D loss: 0.0032, G loss: 6.6088\n",
      "[724/1762] D loss: 0.0042, G loss: 6.5031\n",
      "[804/1762] D loss: 0.0040, G loss: 6.6494\n",
      "[884/1762] D loss: 0.0088, G loss: 5.4654\n",
      "[964/1762] D loss: 0.0067, G loss: 5.7282\n",
      "[1044/1762] D loss: 0.0032, G loss: 6.8182\n",
      "[1124/1762] D loss: 0.0077, G loss: 5.8748\n",
      "[1204/1762] D loss: 0.0023, G loss: 7.7358\n",
      "[1284/1762] D loss: 0.0030, G loss: 7.1734\n",
      "[1364/1762] D loss: 0.0087, G loss: 6.9920\n",
      "[1444/1762] D loss: 0.0031, G loss: 6.6698\n",
      "[1524/1762] D loss: 0.0022, G loss: 6.9080\n",
      "[1604/1762] D loss: 0.0061, G loss: 5.9968\n",
      "[1684/1762] D loss: 0.0026, G loss: 7.1090\n",
      "[1762/1762] D loss: 0.0014, G loss: 7.9475\n",
      "train error: \n",
      " D loss: 2.051350, G loss: 6.528254, D accuracy: 50.0%, cell accuracy: 90.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.077806, G loss: 6.573394, D accuracy: 50.0%, cell accuracy: 89.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0073, G loss: 5.3621\n",
      "[84/1762] D loss: 0.0035, G loss: 6.3515\n",
      "[164/1762] D loss: 0.0127, G loss: 5.1735\n",
      "[244/1762] D loss: 0.0074, G loss: 7.3057\n",
      "[324/1762] D loss: 0.0087, G loss: 7.3469\n",
      "[404/1762] D loss: 0.0020, G loss: 6.9066\n",
      "[484/1762] D loss: 0.0024, G loss: 7.1060\n",
      "[564/1762] D loss: 0.0020, G loss: 7.2124\n",
      "[644/1762] D loss: 0.0021, G loss: 7.2213\n",
      "[724/1762] D loss: 0.0030, G loss: 6.9601\n",
      "[804/1762] D loss: 0.0026, G loss: 6.9224\n",
      "[884/1762] D loss: 0.0031, G loss: 6.4282\n",
      "[964/1762] D loss: 0.0136, G loss: 5.9884\n",
      "[1044/1762] D loss: 0.0049, G loss: 6.6958\n",
      "[1124/1762] D loss: 0.0045, G loss: 6.5171\n",
      "[1204/1762] D loss: 0.0069, G loss: 5.9317\n",
      "[1284/1762] D loss: 0.0048, G loss: 7.0263\n",
      "[1364/1762] D loss: 0.0049, G loss: 6.9464\n",
      "[1444/1762] D loss: 0.0039, G loss: 6.6866\n",
      "[1524/1762] D loss: 0.0017, G loss: 7.6707\n",
      "[1604/1762] D loss: 0.0057, G loss: 5.9505\n",
      "[1684/1762] D loss: 0.0017, G loss: 7.1741\n",
      "[1762/1762] D loss: 0.0117, G loss: 5.9101\n",
      "train error: \n",
      " D loss: 0.867630, G loss: 6.091310, D accuracy: 70.5%, cell accuracy: 89.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.886438, G loss: 6.102171, D accuracy: 71.0%, cell accuracy: 88.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0069, G loss: 7.7103\n",
      "[84/1762] D loss: 0.0044, G loss: 5.9561\n",
      "[164/1762] D loss: 0.0166, G loss: 4.7493\n",
      "[244/1762] D loss: 0.0102, G loss: 5.0595\n",
      "[324/1762] D loss: 0.0053, G loss: 6.9238\n",
      "[404/1762] D loss: 0.0165, G loss: 6.6935\n",
      "[484/1762] D loss: 0.0115, G loss: 4.9083\n",
      "[564/1762] D loss: 0.0038, G loss: 6.5352\n",
      "[644/1762] D loss: 0.0114, G loss: 5.2602\n",
      "[724/1762] D loss: 0.0047, G loss: 5.8537\n",
      "[804/1762] D loss: 0.0026, G loss: 7.3640\n",
      "[884/1762] D loss: 0.0110, G loss: 5.6420\n",
      "[964/1762] D loss: 0.0051, G loss: 5.9295\n",
      "[1044/1762] D loss: 0.0043, G loss: 7.4024\n",
      "[1124/1762] D loss: 0.0069, G loss: 5.1016\n",
      "[1204/1762] D loss: 0.0113, G loss: 5.4625\n",
      "[1284/1762] D loss: 0.0081, G loss: 5.6342\n",
      "[1364/1762] D loss: 0.0205, G loss: 5.8123\n",
      "[1444/1762] D loss: 0.0052, G loss: 5.7520\n",
      "[1524/1762] D loss: 0.0012, G loss: 7.9336\n",
      "[1604/1762] D loss: 0.0165, G loss: 4.7758\n",
      "[1684/1762] D loss: 0.0024, G loss: 6.8318\n",
      "[1762/1762] D loss: 0.0083, G loss: 4.9578\n",
      "train error: \n",
      " D loss: 1.323680, G loss: 5.789902, D accuracy: 54.6%, cell accuracy: 93.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345551, G loss: 5.770879, D accuracy: 54.8%, cell accuracy: 93.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0013, G loss: 7.7834\n",
      "[84/1762] D loss: 0.0123, G loss: 4.6684\n",
      "[164/1762] D loss: 0.0040, G loss: 6.3265\n",
      "[244/1762] D loss: 0.0049, G loss: 6.2335\n",
      "[324/1762] D loss: 0.0039, G loss: 6.7943\n",
      "[404/1762] D loss: 0.0021, G loss: 7.4478\n",
      "[484/1762] D loss: 0.0053, G loss: 7.0549\n",
      "[564/1762] D loss: 0.0114, G loss: 6.1364\n",
      "[644/1762] D loss: 0.0063, G loss: 5.4820\n",
      "[724/1762] D loss: 0.0321, G loss: 3.9387\n",
      "[804/1762] D loss: 0.0038, G loss: 6.9766\n",
      "[884/1762] D loss: 0.0116, G loss: 5.1482\n",
      "[964/1762] D loss: 0.0019, G loss: 6.9407\n",
      "[1044/1762] D loss: 0.0031, G loss: 6.4189\n",
      "[1124/1762] D loss: 0.0021, G loss: 8.0888\n",
      "[1204/1762] D loss: 0.0156, G loss: 4.9576\n",
      "[1284/1762] D loss: 0.0025, G loss: 7.2742\n",
      "[1364/1762] D loss: 0.0022, G loss: 6.6624\n",
      "[1444/1762] D loss: 0.0031, G loss: 7.7276\n",
      "[1524/1762] D loss: 0.0090, G loss: 6.0456\n",
      "[1604/1762] D loss: 0.0027, G loss: 6.8873\n",
      "[1684/1762] D loss: 0.0053, G loss: 7.0364\n",
      "[1762/1762] D loss: 0.0127, G loss: 4.6429\n",
      "train error: \n",
      " D loss: 0.194804, G loss: 4.716161, D accuracy: 99.4%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.197894, G loss: 4.649391, D accuracy: 99.1%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0049, G loss: 6.9515\n",
      "[84/1762] D loss: 0.0055, G loss: 5.6675\n",
      "[164/1762] D loss: 0.0054, G loss: 5.9888\n",
      "[244/1762] D loss: 0.0145, G loss: 5.2287\n",
      "[324/1762] D loss: 0.0028, G loss: 7.7457\n",
      "[404/1762] D loss: 0.0017, G loss: 7.1332\n",
      "[484/1762] D loss: 0.0099, G loss: 6.1385\n",
      "[564/1762] D loss: 0.0016, G loss: 6.9941\n",
      "[644/1762] D loss: 0.0091, G loss: 6.0826\n",
      "[724/1762] D loss: 0.0179, G loss: 5.1234\n",
      "[804/1762] D loss: 0.0043, G loss: 6.3648\n",
      "[884/1762] D loss: 0.0058, G loss: 6.3031\n",
      "[964/1762] D loss: 0.0120, G loss: 6.1753\n",
      "[1044/1762] D loss: 0.0029, G loss: 6.5902\n",
      "[1124/1762] D loss: 0.0033, G loss: 6.8674\n",
      "[1204/1762] D loss: 0.0106, G loss: 5.7758\n",
      "[1284/1762] D loss: 0.0049, G loss: 7.7534\n",
      "[1364/1762] D loss: 0.0013, G loss: 8.2602\n",
      "[1444/1762] D loss: 0.0026, G loss: 7.2881\n",
      "[1524/1762] D loss: 0.0018, G loss: 7.5232\n",
      "[1604/1762] D loss: 0.0041, G loss: 7.3740\n",
      "[1684/1762] D loss: 0.0044, G loss: 5.8160\n",
      "[1762/1762] D loss: 0.0035, G loss: 8.3830\n",
      "train error: \n",
      " D loss: 0.555103, G loss: 5.588630, D accuracy: 86.1%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.565618, G loss: 5.559912, D accuracy: 86.7%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0123, G loss: 5.2765\n",
      "[84/1762] D loss: 0.0028, G loss: 7.7522\n",
      "[164/1762] D loss: 0.0068, G loss: 6.7712\n",
      "[244/1762] D loss: 0.0240, G loss: 7.2433\n",
      "[324/1762] D loss: 0.0036, G loss: 6.8463\n",
      "[404/1762] D loss: 0.0031, G loss: 7.6245\n",
      "[484/1762] D loss: 0.0051, G loss: 7.1060\n",
      "[564/1762] D loss: 0.0096, G loss: 5.9217\n",
      "[644/1762] D loss: 0.0026, G loss: 7.3589\n",
      "[724/1762] D loss: 0.0032, G loss: 6.7685\n",
      "[804/1762] D loss: 0.0038, G loss: 6.5416\n",
      "[884/1762] D loss: 0.0141, G loss: 7.8880\n",
      "[964/1762] D loss: 0.0040, G loss: 6.8917\n",
      "[1044/1762] D loss: 0.0225, G loss: 4.6013\n",
      "[1124/1762] D loss: 0.0048, G loss: 6.1616\n",
      "[1204/1762] D loss: 0.0169, G loss: 5.3335\n",
      "[1284/1762] D loss: 0.0069, G loss: 5.9739\n",
      "[1364/1762] D loss: 0.0099, G loss: 5.8595\n",
      "[1444/1762] D loss: 0.0093, G loss: 5.6968\n",
      "[1524/1762] D loss: 0.0033, G loss: 6.9496\n",
      "[1604/1762] D loss: 0.0078, G loss: 6.5863\n",
      "[1684/1762] D loss: 0.0061, G loss: 5.7482\n",
      "[1762/1762] D loss: 0.0027, G loss: 6.6214\n",
      "train error: \n",
      " D loss: 0.220405, G loss: 4.822765, D accuracy: 98.7%, cell accuracy: 96.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.223845, G loss: 4.950974, D accuracy: 98.1%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0315, G loss: 4.0726\n",
      "[84/1762] D loss: 0.0073, G loss: 6.3963\n",
      "[164/1762] D loss: 0.0168, G loss: 6.4970\n",
      "[244/1762] D loss: 0.0069, G loss: 5.6683\n",
      "[324/1762] D loss: 0.0087, G loss: 6.0238\n",
      "[404/1762] D loss: 0.0054, G loss: 5.8645\n",
      "[484/1762] D loss: 0.0041, G loss: 6.0259\n",
      "[564/1762] D loss: 0.0106, G loss: 5.9666\n",
      "[644/1762] D loss: 0.0100, G loss: 7.4915\n",
      "[724/1762] D loss: 0.0085, G loss: 5.3951\n",
      "[804/1762] D loss: 0.0159, G loss: 4.8162\n",
      "[884/1762] D loss: 0.0045, G loss: 6.4575\n",
      "[964/1762] D loss: 0.0070, G loss: 6.9633\n",
      "[1044/1762] D loss: 0.0045, G loss: 7.3601\n",
      "[1124/1762] D loss: 0.0156, G loss: 7.9371\n",
      "[1204/1762] D loss: 0.0126, G loss: 6.5772\n",
      "[1284/1762] D loss: 0.0056, G loss: 7.9152\n",
      "[1364/1762] D loss: 0.0203, G loss: 4.3563\n",
      "[1444/1762] D loss: 0.0119, G loss: 5.9110\n",
      "[1524/1762] D loss: 0.1569, G loss: 2.7630\n",
      "[1604/1762] D loss: 0.0051, G loss: 6.1163\n",
      "[1684/1762] D loss: 0.0022, G loss: 7.7444\n",
      "[1762/1762] D loss: 0.0017, G loss: 7.6076\n",
      "train error: \n",
      " D loss: 0.338882, G loss: 5.135795, D accuracy: 95.1%, cell accuracy: 96.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.344780, G loss: 5.201773, D accuracy: 93.9%, cell accuracy: 96.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0200, G loss: 6.4357\n",
      "[84/1762] D loss: 0.0299, G loss: 4.7885\n",
      "[164/1762] D loss: 0.0023, G loss: 7.2601\n",
      "[244/1762] D loss: 0.0205, G loss: 5.8047\n",
      "[324/1762] D loss: 0.0115, G loss: 5.2818\n",
      "[404/1762] D loss: 0.0335, G loss: 4.1304\n",
      "[484/1762] D loss: 0.0009, G loss: 7.9994\n",
      "[564/1762] D loss: 0.0020, G loss: 7.4049\n",
      "[644/1762] D loss: 0.0108, G loss: 5.8777\n",
      "[724/1762] D loss: 0.0046, G loss: 6.5865\n",
      "[804/1762] D loss: 0.0047, G loss: 6.3822\n",
      "[884/1762] D loss: 0.0055, G loss: 6.4783\n",
      "[964/1762] D loss: 0.0102, G loss: 6.8321\n",
      "[1044/1762] D loss: 0.0042, G loss: 7.2208\n",
      "[1124/1762] D loss: 0.0075, G loss: 5.9419\n",
      "[1204/1762] D loss: 0.0066, G loss: 6.5182\n",
      "[1284/1762] D loss: 0.0088, G loss: 5.4649\n",
      "[1364/1762] D loss: 0.0079, G loss: 5.9322\n",
      "[1444/1762] D loss: 0.0087, G loss: 7.1999\n",
      "[1524/1762] D loss: 0.0111, G loss: 5.4114\n",
      "[1604/1762] D loss: 0.0027, G loss: 6.9896\n",
      "[1684/1762] D loss: 0.0054, G loss: 8.3416\n",
      "[1762/1762] D loss: 0.0206, G loss: 4.4394\n",
      "train error: \n",
      " D loss: 0.170134, G loss: 4.415262, D accuracy: 99.5%, cell accuracy: 97.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.172752, G loss: 4.470311, D accuracy: 99.7%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0135, G loss: 5.2931\n",
      "[84/1762] D loss: 0.0056, G loss: 5.9355\n",
      "[164/1762] D loss: 0.0095, G loss: 6.0870\n",
      "[244/1762] D loss: 0.0082, G loss: 5.1196\n",
      "[324/1762] D loss: 0.0320, G loss: 4.5687\n",
      "[404/1762] D loss: 0.0058, G loss: 6.6239\n",
      "[484/1762] D loss: 0.0069, G loss: 6.0223\n",
      "[564/1762] D loss: 0.0221, G loss: 5.4106\n",
      "[644/1762] D loss: 0.0078, G loss: 5.5873\n",
      "[724/1762] D loss: 0.0055, G loss: 8.1672\n",
      "[804/1762] D loss: 0.0061, G loss: 6.3744\n",
      "[884/1762] D loss: 0.0080, G loss: 5.1314\n",
      "[964/1762] D loss: 0.0134, G loss: 4.8063\n",
      "[1044/1762] D loss: 0.0137, G loss: 7.7633\n",
      "[1124/1762] D loss: 0.0179, G loss: 4.5633\n",
      "[1204/1762] D loss: 0.0299, G loss: 4.5695\n",
      "[1284/1762] D loss: 0.0170, G loss: 4.8597\n",
      "[1364/1762] D loss: 0.0084, G loss: 6.7111\n",
      "[1444/1762] D loss: 0.0046, G loss: 7.0409\n",
      "[1524/1762] D loss: 0.0155, G loss: 4.7602\n",
      "[1604/1762] D loss: 0.0209, G loss: 4.5397\n",
      "[1684/1762] D loss: 0.0127, G loss: 7.1916\n",
      "[1762/1762] D loss: 0.0033, G loss: 7.1862\n",
      "train error: \n",
      " D loss: 0.381332, G loss: 5.020484, D accuracy: 93.6%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.389800, G loss: 5.051097, D accuracy: 93.3%, cell accuracy: 96.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0024, G loss: 7.0442\n",
      "[84/1762] D loss: 0.0049, G loss: 7.5286\n",
      "[164/1762] D loss: 0.0037, G loss: 6.3867\n",
      "[244/1762] D loss: 0.0037, G loss: 6.9136\n",
      "[324/1762] D loss: 0.0021, G loss: 8.6950\n",
      "[404/1762] D loss: 0.0085, G loss: 5.9306\n",
      "[484/1762] D loss: 0.0028, G loss: 6.7014\n",
      "[564/1762] D loss: 0.0142, G loss: 5.5388\n",
      "[644/1762] D loss: 0.0184, G loss: 5.8336\n",
      "[724/1762] D loss: 0.0084, G loss: 5.3325\n",
      "[804/1762] D loss: 0.0257, G loss: 5.6632\n",
      "[884/1762] D loss: 0.0063, G loss: 6.0825\n",
      "[964/1762] D loss: 0.0133, G loss: 5.3263\n",
      "[1044/1762] D loss: 0.0035, G loss: 6.5489\n",
      "[1124/1762] D loss: 0.0158, G loss: 5.6808\n",
      "[1204/1762] D loss: 0.0313, G loss: 4.9687\n",
      "[1284/1762] D loss: 0.0147, G loss: 5.3698\n",
      "[1364/1762] D loss: 0.0148, G loss: 4.6272\n",
      "[1444/1762] D loss: 0.0026, G loss: 6.6469\n",
      "[1524/1762] D loss: 0.0096, G loss: 5.8518\n",
      "[1604/1762] D loss: 0.0292, G loss: 4.1798\n",
      "[1684/1762] D loss: 0.0028, G loss: 7.6937\n",
      "[1762/1762] D loss: 0.0074, G loss: 5.9800\n",
      "train error: \n",
      " D loss: 0.178312, G loss: 4.260082, D accuracy: 99.5%, cell accuracy: 97.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.182014, G loss: 4.298561, D accuracy: 99.3%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0175, G loss: 5.0103\n",
      "[84/1762] D loss: 0.0099, G loss: 4.9273\n",
      "[164/1762] D loss: 0.0049, G loss: 6.8557\n",
      "[244/1762] D loss: 0.0375, G loss: 6.3380\n",
      "[324/1762] D loss: 0.0030, G loss: 6.8482\n",
      "[404/1762] D loss: 0.0316, G loss: 3.6762\n",
      "[484/1762] D loss: 0.0237, G loss: 6.6278\n",
      "[564/1762] D loss: 0.0181, G loss: 6.4719\n",
      "[644/1762] D loss: 0.0046, G loss: 7.6803\n",
      "[724/1762] D loss: 0.0039, G loss: 6.4527\n",
      "[804/1762] D loss: 0.0470, G loss: 4.5026\n",
      "[884/1762] D loss: 0.0098, G loss: 6.0258\n",
      "[964/1762] D loss: 0.0184, G loss: 8.4702\n",
      "[1044/1762] D loss: 0.0121, G loss: 5.9462\n",
      "[1124/1762] D loss: 0.0091, G loss: 6.5324\n",
      "[1204/1762] D loss: 0.0093, G loss: 6.0429\n",
      "[1284/1762] D loss: 0.0262, G loss: 5.0580\n",
      "[1364/1762] D loss: 0.0117, G loss: 6.7437\n",
      "[1444/1762] D loss: 0.0175, G loss: 4.3188\n",
      "[1524/1762] D loss: 0.0077, G loss: 6.0732\n",
      "[1604/1762] D loss: 0.0173, G loss: 5.3271\n",
      "[1684/1762] D loss: 0.0152, G loss: 5.0956\n",
      "[1762/1762] D loss: 0.0026, G loss: 7.6982\n",
      "train error: \n",
      " D loss: 0.524081, G loss: 4.958671, D accuracy: 88.2%, cell accuracy: 97.9%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.534177, G loss: 4.917040, D accuracy: 88.4%, cell accuracy: 97.8%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0204, G loss: 5.1335\n",
      "[84/1762] D loss: 0.0034, G loss: 6.3634\n",
      "[164/1762] D loss: 0.0106, G loss: 6.3617\n",
      "[244/1762] D loss: 0.0383, G loss: 6.4483\n",
      "[324/1762] D loss: 0.0228, G loss: 4.6361\n",
      "[404/1762] D loss: 0.0352, G loss: 4.6655\n",
      "[484/1762] D loss: 0.0142, G loss: 4.5857\n",
      "[564/1762] D loss: 0.0187, G loss: 5.5665\n",
      "[644/1762] D loss: 0.0219, G loss: 5.2476\n",
      "[724/1762] D loss: 0.0194, G loss: 4.4617\n",
      "[804/1762] D loss: 0.0360, G loss: 4.2268\n",
      "[884/1762] D loss: 0.0140, G loss: 5.1223\n",
      "[964/1762] D loss: 0.0201, G loss: 4.4525\n",
      "[1044/1762] D loss: 0.0098, G loss: 6.5141\n",
      "[1124/1762] D loss: 0.0332, G loss: 4.2824\n",
      "[1204/1762] D loss: 0.0021, G loss: 7.7121\n",
      "[1284/1762] D loss: 0.0168, G loss: 5.0251\n",
      "[1364/1762] D loss: 0.0155, G loss: 4.7461\n",
      "[1444/1762] D loss: 0.0488, G loss: 3.8391\n",
      "[1524/1762] D loss: 0.0486, G loss: 3.4988\n",
      "[1604/1762] D loss: 0.0191, G loss: 5.6883\n",
      "[1684/1762] D loss: 0.0208, G loss: 6.1605\n",
      "[1762/1762] D loss: 0.0049, G loss: 7.4374\n",
      "train error: \n",
      " D loss: 0.336090, G loss: 4.315433, D accuracy: 95.7%, cell accuracy: 98.2%, board accuracy: 4.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.340731, G loss: 4.379204, D accuracy: 95.1%, cell accuracy: 98.1%, board accuracy: 3.9% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0103, G loss: 6.3588\n",
      "[84/1762] D loss: 0.0192, G loss: 5.7231\n",
      "[164/1762] D loss: 0.0491, G loss: 4.5377\n",
      "[244/1762] D loss: 0.0397, G loss: 4.4130\n",
      "[324/1762] D loss: 0.0113, G loss: 6.1321\n",
      "[404/1762] D loss: 0.0417, G loss: 4.2413\n",
      "[484/1762] D loss: 0.0173, G loss: 4.4221\n",
      "[564/1762] D loss: 0.0198, G loss: 6.4408\n",
      "[644/1762] D loss: 0.0569, G loss: 3.4531\n",
      "[724/1762] D loss: 0.0521, G loss: 3.5244\n",
      "[804/1762] D loss: 0.0175, G loss: 5.6073\n",
      "[884/1762] D loss: 0.0183, G loss: 4.6080\n",
      "[964/1762] D loss: 0.0412, G loss: 4.7797\n",
      "[1044/1762] D loss: 0.0554, G loss: 4.4603\n",
      "[1124/1762] D loss: 0.0299, G loss: 4.2950\n",
      "[1204/1762] D loss: 0.0358, G loss: 4.1587\n",
      "[1284/1762] D loss: 0.0146, G loss: 4.6508\n",
      "[1364/1762] D loss: 0.0874, G loss: 3.7422\n",
      "[1444/1762] D loss: 0.0072, G loss: 6.1516\n",
      "[1524/1762] D loss: 0.1151, G loss: 4.1913\n",
      "[1604/1762] D loss: 0.0070, G loss: 6.9709\n",
      "[1684/1762] D loss: 0.0290, G loss: 3.8941\n",
      "[1762/1762] D loss: 0.0197, G loss: 8.0659\n",
      "train error: \n",
      " D loss: 0.584986, G loss: 4.771510, D accuracy: 85.3%, cell accuracy: 98.5%, board accuracy: 7.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592699, G loss: 4.788819, D accuracy: 85.2%, cell accuracy: 98.4%, board accuracy: 6.1% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0233, G loss: 4.3549\n",
      "[84/1762] D loss: 0.0374, G loss: 3.8510\n",
      "[164/1762] D loss: 0.0350, G loss: 4.2748\n",
      "[244/1762] D loss: 0.0054, G loss: 6.2720\n",
      "[324/1762] D loss: 0.0080, G loss: 6.6704\n",
      "[404/1762] D loss: 0.0092, G loss: 6.8769\n",
      "[484/1762] D loss: 0.0502, G loss: 4.2048\n",
      "[564/1762] D loss: 0.0352, G loss: 4.8513\n",
      "[644/1762] D loss: 0.0727, G loss: 3.3776\n",
      "[724/1762] D loss: 0.0266, G loss: 4.1313\n",
      "[804/1762] D loss: 0.0050, G loss: 7.1705\n",
      "[884/1762] D loss: 0.0669, G loss: 3.5108\n",
      "[964/1762] D loss: 0.0107, G loss: 5.0268\n",
      "[1044/1762] D loss: 0.0573, G loss: 4.3227\n",
      "[1124/1762] D loss: 0.0438, G loss: 5.3017\n",
      "[1204/1762] D loss: 0.0200, G loss: 6.4432\n",
      "[1284/1762] D loss: 0.0126, G loss: 5.8697\n",
      "[1364/1762] D loss: 0.0386, G loss: 4.7733\n",
      "[1444/1762] D loss: 0.0089, G loss: 5.9901\n",
      "[1524/1762] D loss: 0.0418, G loss: 4.0518\n",
      "[1604/1762] D loss: 0.0558, G loss: 4.9460\n",
      "[1684/1762] D loss: 0.0085, G loss: 7.7935\n",
      "[1762/1762] D loss: 0.0399, G loss: 3.8310\n",
      "train error: \n",
      " D loss: 0.248844, G loss: 3.911321, D accuracy: 98.6%, cell accuracy: 98.7%, board accuracy: 12.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.251775, G loss: 3.926076, D accuracy: 98.1%, cell accuracy: 98.6%, board accuracy: 10.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0085, G loss: 6.2806\n",
      "[84/1762] D loss: 0.0072, G loss: 6.1796\n",
      "[164/1762] D loss: 0.0068, G loss: 7.6560\n",
      "[244/1762] D loss: 0.0106, G loss: 5.4554\n",
      "[324/1762] D loss: 0.0295, G loss: 5.3402\n",
      "[404/1762] D loss: 0.0086, G loss: 5.4114\n",
      "[484/1762] D loss: 0.0523, G loss: 5.8310\n",
      "[564/1762] D loss: 0.1076, G loss: 4.8149\n",
      "[644/1762] D loss: 0.0821, G loss: 4.6098\n",
      "[724/1762] D loss: 0.0161, G loss: 6.5330\n",
      "[804/1762] D loss: 0.0324, G loss: 5.0354\n",
      "[884/1762] D loss: 0.1300, G loss: 4.9621\n",
      "[964/1762] D loss: 0.0291, G loss: 4.8488\n",
      "[1044/1762] D loss: 0.0498, G loss: 6.8049\n",
      "[1124/1762] D loss: 0.0139, G loss: 5.3611\n",
      "[1204/1762] D loss: 0.0257, G loss: 4.8708\n",
      "[1284/1762] D loss: 0.0498, G loss: 4.0361\n",
      "[1364/1762] D loss: 0.0263, G loss: 4.4973\n",
      "[1444/1762] D loss: 0.0719, G loss: 4.0250\n",
      "[1524/1762] D loss: 0.0264, G loss: 4.5748\n",
      "[1604/1762] D loss: 0.0850, G loss: 4.6474\n",
      "[1684/1762] D loss: 0.0415, G loss: 4.2872\n",
      "[1762/1762] D loss: 0.0331, G loss: 4.5107\n",
      "train error: \n",
      " D loss: 0.315114, G loss: 3.832604, D accuracy: 96.9%, cell accuracy: 98.9%, board accuracy: 15.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.317180, G loss: 3.885415, D accuracy: 96.7%, cell accuracy: 98.8%, board accuracy: 13.9% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0327, G loss: 4.9252\n",
      "[84/1762] D loss: 0.0168, G loss: 5.1480\n",
      "[164/1762] D loss: 0.0532, G loss: 3.6424\n",
      "[244/1762] D loss: 0.1195, G loss: 3.8547\n",
      "[324/1762] D loss: 0.0531, G loss: 3.8858\n",
      "[404/1762] D loss: 0.0117, G loss: 5.2685\n",
      "[484/1762] D loss: 0.0742, G loss: 3.5423\n",
      "[564/1762] D loss: 0.0596, G loss: 4.3878\n",
      "[644/1762] D loss: 0.0350, G loss: 4.0785\n",
      "[724/1762] D loss: 0.0449, G loss: 6.4411\n",
      "[804/1762] D loss: 0.0071, G loss: 6.3648\n",
      "[884/1762] D loss: 0.0748, G loss: 4.8786\n",
      "[964/1762] D loss: 0.0119, G loss: 5.8100\n",
      "[1044/1762] D loss: 0.0527, G loss: 4.2844\n",
      "[1124/1762] D loss: 0.0068, G loss: 5.9837\n",
      "[1204/1762] D loss: 0.0609, G loss: 3.4509\n",
      "[1284/1762] D loss: 0.0146, G loss: 5.3622\n",
      "[1364/1762] D loss: 0.0560, G loss: 3.9002\n",
      "[1444/1762] D loss: 0.0519, G loss: 5.6756\n",
      "[1524/1762] D loss: 0.0727, G loss: 4.9798\n",
      "[1604/1762] D loss: 0.0967, G loss: 3.6122\n",
      "[1684/1762] D loss: 0.0090, G loss: 8.1940\n",
      "[1762/1762] D loss: 0.0080, G loss: 7.3766\n",
      "train error: \n",
      " D loss: 0.390881, G loss: 4.087374, D accuracy: 94.0%, cell accuracy: 99.0%, board accuracy: 19.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.396115, G loss: 4.129332, D accuracy: 93.1%, cell accuracy: 99.0%, board accuracy: 14.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0239, G loss: 4.8524\n",
      "[84/1762] D loss: 0.0412, G loss: 4.0767\n",
      "[164/1762] D loss: 0.0271, G loss: 4.8176\n",
      "[244/1762] D loss: 0.0382, G loss: 4.5194\n",
      "[324/1762] D loss: 0.0467, G loss: 4.5552\n",
      "[404/1762] D loss: 0.1462, G loss: 2.1576\n",
      "[484/1762] D loss: 0.0678, G loss: 3.4389\n",
      "[564/1762] D loss: 0.0882, G loss: 4.5623\n",
      "[644/1762] D loss: 0.0630, G loss: 3.1582\n",
      "[724/1762] D loss: 0.0286, G loss: 7.9972\n",
      "[804/1762] D loss: 0.0297, G loss: 4.8596\n",
      "[884/1762] D loss: 0.1947, G loss: 3.0867\n",
      "[964/1762] D loss: 0.0423, G loss: 4.7801\n",
      "[1044/1762] D loss: 0.0339, G loss: 4.1486\n",
      "[1124/1762] D loss: 0.0522, G loss: 3.4463\n",
      "[1204/1762] D loss: 0.0345, G loss: 4.3296\n",
      "[1284/1762] D loss: 0.0650, G loss: 4.0078\n",
      "[1364/1762] D loss: 0.0449, G loss: 3.8953\n",
      "[1444/1762] D loss: 0.0933, G loss: 3.7158\n",
      "[1524/1762] D loss: 0.3061, G loss: 4.8807\n",
      "[1604/1762] D loss: 0.1144, G loss: 3.5237\n",
      "[1684/1762] D loss: 0.0771, G loss: 4.1781\n",
      "[1762/1762] D loss: 0.0166, G loss: 4.7810\n",
      "train error: \n",
      " D loss: 0.231454, G loss: 2.695866, D accuracy: 99.5%, cell accuracy: 99.2%, board accuracy: 24.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.227718, G loss: 2.775656, D accuracy: 99.8%, cell accuracy: 99.1%, board accuracy: 21.4% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0321, G loss: 4.5838\n",
      "[84/1762] D loss: 0.0606, G loss: 3.5741\n",
      "[164/1762] D loss: 0.1134, G loss: 4.0482\n",
      "[244/1762] D loss: 0.0655, G loss: 5.9508\n",
      "[324/1762] D loss: 0.1039, G loss: 4.4760\n",
      "[404/1762] D loss: 0.0515, G loss: 3.5639\n",
      "[484/1762] D loss: 0.0470, G loss: 4.1905\n",
      "[564/1762] D loss: 0.1038, G loss: 7.1129\n",
      "[644/1762] D loss: 0.0641, G loss: 3.7639\n",
      "[724/1762] D loss: 0.0718, G loss: 6.1377\n",
      "[804/1762] D loss: 0.0553, G loss: 3.4738\n",
      "[884/1762] D loss: 0.1471, G loss: 2.3611\n",
      "[964/1762] D loss: 0.0714, G loss: 3.7594\n",
      "[1044/1762] D loss: 0.0850, G loss: 3.2655\n",
      "[1124/1762] D loss: 0.0342, G loss: 4.1767\n",
      "[1204/1762] D loss: 0.0362, G loss: 4.2104\n",
      "[1284/1762] D loss: 0.0602, G loss: 5.5745\n",
      "[1364/1762] D loss: 0.0462, G loss: 4.8140\n",
      "[1444/1762] D loss: 0.1515, G loss: 3.4086\n",
      "[1524/1762] D loss: 0.1110, G loss: 3.2780\n",
      "[1604/1762] D loss: 0.1060, G loss: 3.8681\n",
      "[1684/1762] D loss: 0.0590, G loss: 3.2675\n",
      "[1762/1762] D loss: 0.0657, G loss: 3.0822\n",
      "train error: \n",
      " D loss: 0.286000, G loss: 3.171644, D accuracy: 98.0%, cell accuracy: 99.3%, board accuracy: 34.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.290214, G loss: 3.241308, D accuracy: 97.5%, cell accuracy: 99.2%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0558, G loss: 3.7446\n",
      "[84/1762] D loss: 0.0819, G loss: 4.1944\n",
      "[164/1762] D loss: 0.0948, G loss: 3.3658\n",
      "[244/1762] D loss: 0.0765, G loss: 3.5431\n",
      "[324/1762] D loss: 0.1203, G loss: 3.6745\n",
      "[404/1762] D loss: 0.0632, G loss: 3.9125\n",
      "[484/1762] D loss: 0.1241, G loss: 4.6021\n",
      "[564/1762] D loss: 0.0506, G loss: 6.0174\n",
      "[644/1762] D loss: 0.0491, G loss: 4.8181\n",
      "[724/1762] D loss: 0.0926, G loss: 5.8111\n",
      "[804/1762] D loss: 0.0301, G loss: 4.2930\n",
      "[884/1762] D loss: 0.0472, G loss: 4.5136\n",
      "[964/1762] D loss: 0.1501, G loss: 3.9835\n",
      "[1044/1762] D loss: 0.1686, G loss: 4.5524\n",
      "[1124/1762] D loss: 0.0860, G loss: 3.4710\n",
      "[1204/1762] D loss: 0.0140, G loss: 6.8117\n",
      "[1284/1762] D loss: 0.1237, G loss: 3.6997\n",
      "[1364/1762] D loss: 0.1008, G loss: 3.3491\n",
      "[1444/1762] D loss: 0.0260, G loss: 5.8626\n",
      "[1524/1762] D loss: 0.0655, G loss: 4.0879\n",
      "[1604/1762] D loss: 0.0688, G loss: 4.3648\n",
      "[1684/1762] D loss: 0.0562, G loss: 3.6306\n",
      "[1762/1762] D loss: 0.2048, G loss: 2.6542\n",
      "train error: \n",
      " D loss: 0.345971, G loss: 3.147081, D accuracy: 96.8%, cell accuracy: 99.4%, board accuracy: 48.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.348860, G loss: 3.193335, D accuracy: 96.1%, cell accuracy: 99.3%, board accuracy: 43.6% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1134, G loss: 4.3116\n",
      "[84/1762] D loss: 0.0958, G loss: 3.7599\n",
      "[164/1762] D loss: 0.1639, G loss: 4.2458\n",
      "[244/1762] D loss: 0.0436, G loss: 4.9528\n",
      "[324/1762] D loss: 0.0687, G loss: 3.4786\n",
      "[404/1762] D loss: 0.0868, G loss: 4.3645\n",
      "[484/1762] D loss: 0.2422, G loss: 4.2015\n",
      "[564/1762] D loss: 0.0925, G loss: 5.4169\n",
      "[644/1762] D loss: 0.0634, G loss: 4.9306\n",
      "[724/1762] D loss: 0.0616, G loss: 4.7476\n",
      "[804/1762] D loss: 0.1325, G loss: 2.9274\n",
      "[884/1762] D loss: 0.0900, G loss: 3.1558\n",
      "[964/1762] D loss: 0.0372, G loss: 4.8618\n",
      "[1044/1762] D loss: 0.0615, G loss: 6.4908\n",
      "[1124/1762] D loss: 0.1643, G loss: 2.4126\n",
      "[1204/1762] D loss: 0.1167, G loss: 2.6587\n",
      "[1284/1762] D loss: 0.1157, G loss: 3.7166\n",
      "[1364/1762] D loss: 0.0540, G loss: 3.9122\n",
      "[1444/1762] D loss: 0.0728, G loss: 4.1460\n",
      "[1524/1762] D loss: 0.1166, G loss: 2.9373\n",
      "[1604/1762] D loss: 0.0438, G loss: 5.0656\n",
      "[1684/1762] D loss: 0.1442, G loss: 2.6535\n",
      "[1762/1762] D loss: 0.2724, G loss: 2.0256\n",
      "train error: \n",
      " D loss: 0.353595, G loss: 2.438487, D accuracy: 98.2%, cell accuracy: 99.5%, board accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.355501, G loss: 2.503435, D accuracy: 97.8%, cell accuracy: 99.4%, board accuracy: 50.2% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0793, G loss: 3.6852\n",
      "[84/1762] D loss: 0.0901, G loss: 3.6427\n",
      "[164/1762] D loss: 0.2114, G loss: 2.0677\n",
      "[244/1762] D loss: 0.1920, G loss: 2.4703\n",
      "[324/1762] D loss: 0.2425, G loss: 3.8323\n",
      "[404/1762] D loss: 0.2832, G loss: 4.4770\n",
      "[484/1762] D loss: 0.0741, G loss: 4.1295\n",
      "[564/1762] D loss: 0.0218, G loss: 4.8634\n",
      "[644/1762] D loss: 0.1223, G loss: 3.2320\n",
      "[724/1762] D loss: 0.1370, G loss: 2.8180\n",
      "[804/1762] D loss: 0.2618, G loss: 2.6819\n",
      "[884/1762] D loss: 0.1761, G loss: 2.9773\n",
      "[964/1762] D loss: 0.0445, G loss: 4.1269\n",
      "[1044/1762] D loss: 0.1352, G loss: 4.0926\n",
      "[1124/1762] D loss: 0.1866, G loss: 3.3757\n",
      "[1204/1762] D loss: 0.0666, G loss: 3.9410\n",
      "[1284/1762] D loss: 0.1551, G loss: 4.3134\n",
      "[1364/1762] D loss: 0.0595, G loss: 6.2957\n",
      "[1444/1762] D loss: 0.0763, G loss: 3.8069\n",
      "[1524/1762] D loss: 0.1985, G loss: 4.3432\n",
      "[1604/1762] D loss: 0.0895, G loss: 3.5327\n",
      "[1684/1762] D loss: 0.0476, G loss: 6.1723\n",
      "[1762/1762] D loss: 0.0961, G loss: 2.8793\n",
      "train error: \n",
      " D loss: 0.339632, G loss: 2.475455, D accuracy: 98.0%, cell accuracy: 99.5%, board accuracy: 55.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.339260, G loss: 2.530138, D accuracy: 97.6%, cell accuracy: 99.4%, board accuracy: 50.2% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in [1e-3, 1e-4, 1e-5]:\n",
    "    run_name = \"adam_lr_\" + f\"{learning_rate:.0e}\".replace(\"-\", \"m\")\n",
    "    train(run_name=run_name, learning_rate=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, Adam doesn't seem to be helping much. Let's try setting beta1 to 0.5 as per the DCGAN paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4119, G loss: 0.8702\n",
      "[84/1762] D loss: 0.6370, G loss: 1.4336\n",
      "[164/1762] D loss: 0.1705, G loss: 2.9810\n",
      "[244/1762] D loss: 0.0605, G loss: 3.9275\n",
      "[324/1762] D loss: 0.4647, G loss: 1.7480\n",
      "[404/1762] D loss: 2.5029, G loss: 0.1242\n",
      "[484/1762] D loss: 0.4363, G loss: 1.2609\n",
      "[564/1762] D loss: 0.4308, G loss: 3.0727\n",
      "[644/1762] D loss: 0.9062, G loss: 0.5194\n",
      "[724/1762] D loss: 0.6781, G loss: 1.5322\n",
      "[804/1762] D loss: 1.4525, G loss: 1.5776\n",
      "[884/1762] D loss: 1.3220, G loss: 3.1353\n",
      "[964/1762] D loss: 1.5245, G loss: 1.3114\n",
      "[1044/1762] D loss: 0.9586, G loss: 1.3693\n",
      "[1124/1762] D loss: 1.4398, G loss: 1.6562\n",
      "[1204/1762] D loss: 1.2565, G loss: 0.4819\n",
      "[1284/1762] D loss: 1.0660, G loss: 0.7753\n",
      "[1364/1762] D loss: 1.1739, G loss: 1.1530\n",
      "[1444/1762] D loss: 1.0411, G loss: 0.5582\n",
      "[1524/1762] D loss: 1.2335, G loss: 0.7985\n",
      "[1604/1762] D loss: 1.3291, G loss: 0.5242\n",
      "[1684/1762] D loss: 1.0776, G loss: 1.0718\n",
      "[1762/1762] D loss: 1.4934, G loss: 1.5375\n",
      "train error: \n",
      " D loss: 1.592936, G loss: 1.786505, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 73.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.561175, G loss: 1.792262, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6126, G loss: 0.5233\n",
      "[84/1762] D loss: 1.1712, G loss: 0.7197\n",
      "[164/1762] D loss: 0.9986, G loss: 1.3813\n",
      "[244/1762] D loss: 1.1795, G loss: 0.6131\n",
      "[324/1762] D loss: 1.1970, G loss: 0.8686\n",
      "[404/1762] D loss: 1.2947, G loss: 0.6448\n",
      "[484/1762] D loss: 1.1491, G loss: 1.4451\n",
      "[564/1762] D loss: 1.3165, G loss: 0.6003\n",
      "[644/1762] D loss: 1.2680, G loss: 2.0059\n",
      "[724/1762] D loss: 1.3993, G loss: 0.9070\n",
      "[804/1762] D loss: 1.3340, G loss: 1.0623\n",
      "[884/1762] D loss: 1.3758, G loss: 0.8739\n",
      "[964/1762] D loss: 1.2459, G loss: 0.6333\n",
      "[1044/1762] D loss: 1.4003, G loss: 0.4694\n",
      "[1124/1762] D loss: 1.0994, G loss: 1.0741\n",
      "[1204/1762] D loss: 1.3782, G loss: 0.4396\n",
      "[1284/1762] D loss: 1.0592, G loss: 1.0392\n",
      "[1364/1762] D loss: 1.3536, G loss: 0.8980\n",
      "[1444/1762] D loss: 1.2363, G loss: 0.8035\n",
      "[1524/1762] D loss: 1.2266, G loss: 0.7452\n",
      "[1604/1762] D loss: 1.5402, G loss: 0.5047\n",
      "[1684/1762] D loss: 1.3641, G loss: 0.8347\n",
      "[1762/1762] D loss: 1.3334, G loss: 0.6216\n",
      "train error: \n",
      " D loss: 1.509133, G loss: 0.381214, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.500854, G loss: 0.384856, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7029, G loss: 1.0857\n",
      "[84/1762] D loss: 1.3634, G loss: 0.7176\n",
      "[164/1762] D loss: 1.0328, G loss: 1.2497\n",
      "[244/1762] D loss: 0.7469, G loss: 1.3802\n",
      "[324/1762] D loss: 1.0626, G loss: 2.2136\n",
      "[404/1762] D loss: 1.4122, G loss: 0.6422\n",
      "[484/1762] D loss: 1.2064, G loss: 0.9790\n",
      "[564/1762] D loss: 1.4460, G loss: 0.7043\n",
      "[644/1762] D loss: 1.3770, G loss: 0.7466\n",
      "[724/1762] D loss: 1.4391, G loss: 0.7543\n",
      "[804/1762] D loss: 1.3722, G loss: 0.7862\n",
      "[884/1762] D loss: 1.0179, G loss: 0.9852\n",
      "[964/1762] D loss: 0.8553, G loss: 1.2147\n",
      "[1044/1762] D loss: 1.5417, G loss: 0.8348\n",
      "[1124/1762] D loss: 1.3855, G loss: 0.8102\n",
      "[1204/1762] D loss: 1.4866, G loss: 0.8003\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.8537\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.8111\n",
      "[1444/1762] D loss: 1.4049, G loss: 0.6392\n",
      "[1524/1762] D loss: 1.4081, G loss: 0.7352\n",
      "[1604/1762] D loss: 0.8375, G loss: 1.3366\n",
      "[1684/1762] D loss: 1.4311, G loss: 0.7600\n",
      "[1762/1762] D loss: 1.2036, G loss: 1.1771\n",
      "train error: \n",
      " D loss: 0.958035, G loss: 0.910227, D accuracy: 80.8%, cell accuracy: 99.2%, board accuracy: 25.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.965927, G loss: 0.938456, D accuracy: 80.5%, cell accuracy: 99.1%, board accuracy: 25.7% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8280, G loss: 1.3174\n",
      "[84/1762] D loss: 1.3493, G loss: 0.6912\n",
      "[164/1762] D loss: 1.3962, G loss: 0.6257\n",
      "[244/1762] D loss: 1.4314, G loss: 0.5098\n",
      "[324/1762] D loss: 1.4503, G loss: 0.6309\n",
      "[404/1762] D loss: 1.4127, G loss: 0.7411\n",
      "[484/1762] D loss: 1.4108, G loss: 0.7324\n",
      "[564/1762] D loss: 0.5610, G loss: 1.7894\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6496\n",
      "[724/1762] D loss: 1.4110, G loss: 0.7101\n",
      "[804/1762] D loss: 1.5094, G loss: 0.8205\n",
      "[884/1762] D loss: 1.3798, G loss: 0.5971\n",
      "[964/1762] D loss: 0.7298, G loss: 1.2383\n",
      "[1044/1762] D loss: 0.7712, G loss: 1.5933\n",
      "[1124/1762] D loss: 1.6395, G loss: 0.5577\n",
      "[1204/1762] D loss: 0.5755, G loss: 1.7327\n",
      "[1284/1762] D loss: 1.2898, G loss: 0.9706\n",
      "[1364/1762] D loss: 1.3694, G loss: 0.6170\n",
      "[1444/1762] D loss: 1.0964, G loss: 1.1542\n",
      "[1524/1762] D loss: 1.3489, G loss: 0.7989\n",
      "[1604/1762] D loss: 1.4000, G loss: 0.6787\n",
      "[1684/1762] D loss: 0.6875, G loss: 2.0639\n",
      "[1762/1762] D loss: 1.4171, G loss: 0.5371\n",
      "train error: \n",
      " D loss: 1.379707, G loss: 0.563225, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 80.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376764, G loss: 0.558354, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4539, G loss: 0.5861\n",
      "[84/1762] D loss: 1.2607, G loss: 0.6516\n",
      "[164/1762] D loss: 1.4276, G loss: 0.7299\n",
      "[244/1762] D loss: 1.4435, G loss: 0.8108\n",
      "[324/1762] D loss: 1.4853, G loss: 0.6220\n",
      "[404/1762] D loss: 1.4236, G loss: 0.6245\n",
      "[484/1762] D loss: 1.4421, G loss: 0.8314\n",
      "[564/1762] D loss: 1.4567, G loss: 0.7630\n",
      "[644/1762] D loss: 1.3560, G loss: 0.7329\n",
      "[724/1762] D loss: 1.3731, G loss: 0.6985\n",
      "[804/1762] D loss: 1.5637, G loss: 0.7392\n",
      "[884/1762] D loss: 1.3249, G loss: 0.8258\n",
      "[964/1762] D loss: 1.4560, G loss: 0.8109\n",
      "[1044/1762] D loss: 1.3948, G loss: 0.7851\n",
      "[1124/1762] D loss: 1.5079, G loss: 0.6512\n",
      "[1204/1762] D loss: 0.5357, G loss: 1.4434\n",
      "[1284/1762] D loss: 1.2424, G loss: 0.6603\n",
      "[1364/1762] D loss: 1.1637, G loss: 0.7458\n",
      "[1444/1762] D loss: 1.3273, G loss: 0.8330\n",
      "[1524/1762] D loss: 0.3580, G loss: 1.6367\n",
      "[1604/1762] D loss: 1.5062, G loss: 0.8636\n",
      "[1684/1762] D loss: 1.2477, G loss: 0.9096\n",
      "[1762/1762] D loss: 1.4222, G loss: 0.7540\n",
      "train error: \n",
      " D loss: 1.391017, G loss: 1.005021, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399463, G loss: 1.029003, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4261, G loss: 0.6946\n",
      "[84/1762] D loss: 1.3971, G loss: 0.7172\n",
      "[164/1762] D loss: 0.6359, G loss: 1.5219\n",
      "[244/1762] D loss: 0.8472, G loss: 0.8796\n",
      "[324/1762] D loss: 1.4885, G loss: 0.9142\n",
      "[404/1762] D loss: 1.3909, G loss: 0.7420\n",
      "[484/1762] D loss: 1.4210, G loss: 0.6575\n",
      "[564/1762] D loss: 1.4362, G loss: 0.8263\n",
      "[644/1762] D loss: 1.4280, G loss: 0.7157\n",
      "[724/1762] D loss: 1.2701, G loss: 0.7202\n",
      "[804/1762] D loss: 2.5185, G loss: 0.3571\n",
      "[884/1762] D loss: 0.8330, G loss: 1.2231\n",
      "[964/1762] D loss: 0.3935, G loss: 1.8555\n",
      "[1044/1762] D loss: 1.3280, G loss: 0.9418\n",
      "[1124/1762] D loss: 0.5125, G loss: 1.3999\n",
      "[1204/1762] D loss: 1.4373, G loss: 0.7429\n",
      "[1284/1762] D loss: 1.6072, G loss: 0.6888\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.6372\n",
      "[1444/1762] D loss: 1.4172, G loss: 0.7064\n",
      "[1524/1762] D loss: 1.4789, G loss: 0.4657\n",
      "[1604/1762] D loss: 1.4171, G loss: 0.5220\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6012\n",
      "[1762/1762] D loss: 1.4173, G loss: 0.8181\n",
      "train error: \n",
      " D loss: 1.370611, G loss: 0.590597, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360489, G loss: 0.603419, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2641, G loss: 1.8901\n",
      "[84/1762] D loss: 1.4942, G loss: 0.8173\n",
      "[164/1762] D loss: 0.3284, G loss: 1.8686\n",
      "[244/1762] D loss: 1.1668, G loss: 0.8775\n",
      "[324/1762] D loss: 0.5619, G loss: 1.5294\n",
      "[404/1762] D loss: 1.3938, G loss: 0.5797\n",
      "[484/1762] D loss: 1.3157, G loss: 0.9197\n",
      "[564/1762] D loss: 1.3587, G loss: 0.9125\n",
      "[644/1762] D loss: 1.4006, G loss: 0.6192\n",
      "[724/1762] D loss: 1.2988, G loss: 0.7243\n",
      "[804/1762] D loss: 0.2176, G loss: 2.0743\n",
      "[884/1762] D loss: 1.3935, G loss: 0.5256\n",
      "[964/1762] D loss: 1.4383, G loss: 0.6411\n",
      "[1044/1762] D loss: 1.4226, G loss: 0.8359\n",
      "[1124/1762] D loss: 0.4600, G loss: 1.5373\n",
      "[1204/1762] D loss: 1.3988, G loss: 0.5986\n",
      "[1284/1762] D loss: 1.3257, G loss: 0.5869\n",
      "[1364/1762] D loss: 1.6325, G loss: 1.0180\n",
      "[1444/1762] D loss: 1.4196, G loss: 0.6441\n",
      "[1524/1762] D loss: 1.4789, G loss: 0.7550\n",
      "[1604/1762] D loss: 1.4189, G loss: 0.7423\n",
      "[1684/1762] D loss: 1.4067, G loss: 0.7251\n",
      "[1762/1762] D loss: 1.4089, G loss: 0.6744\n",
      "train error: \n",
      " D loss: 1.395541, G loss: 0.515566, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383618, G loss: 0.519826, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5792, G loss: 1.2218\n",
      "[84/1762] D loss: 0.5267, G loss: 1.4398\n",
      "[164/1762] D loss: 1.3943, G loss: 0.7339\n",
      "[244/1762] D loss: 0.4111, G loss: 1.8300\n",
      "[324/1762] D loss: 1.4595, G loss: 0.5983\n",
      "[404/1762] D loss: 1.2587, G loss: 0.8389\n",
      "[484/1762] D loss: 1.3244, G loss: 1.0271\n",
      "[564/1762] D loss: 1.4081, G loss: 0.6885\n",
      "[644/1762] D loss: 1.4077, G loss: 0.7288\n",
      "[724/1762] D loss: 1.4085, G loss: 0.7452\n",
      "[804/1762] D loss: 1.4849, G loss: 0.5897\n",
      "[884/1762] D loss: 0.1050, G loss: 2.8311\n",
      "[964/1762] D loss: 1.1588, G loss: 1.3006\n",
      "[1044/1762] D loss: 1.7063, G loss: 0.8975\n",
      "[1124/1762] D loss: 1.1351, G loss: 1.0708\n",
      "[1204/1762] D loss: 0.1712, G loss: 2.5846\n",
      "[1284/1762] D loss: 1.3993, G loss: 0.7524\n",
      "[1364/1762] D loss: 1.4643, G loss: 0.3190\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.6251\n",
      "[1524/1762] D loss: 0.5213, G loss: 1.7174\n",
      "[1604/1762] D loss: 0.5765, G loss: 1.2879\n",
      "[1684/1762] D loss: 1.7618, G loss: 0.9105\n",
      "[1762/1762] D loss: 0.1954, G loss: 2.4586\n",
      "train error: \n",
      " D loss: 1.411475, G loss: 0.503633, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394591, G loss: 0.512116, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4470, G loss: 0.8334\n",
      "[84/1762] D loss: 1.4482, G loss: 0.9595\n",
      "[164/1762] D loss: 1.3738, G loss: 0.7959\n",
      "[244/1762] D loss: 1.3424, G loss: 0.7391\n",
      "[324/1762] D loss: 1.4179, G loss: 0.7927\n",
      "[404/1762] D loss: 0.3255, G loss: 2.4512\n",
      "[484/1762] D loss: 1.3468, G loss: 0.7545\n",
      "[564/1762] D loss: 1.2602, G loss: 0.9438\n",
      "[644/1762] D loss: 1.4756, G loss: 0.6935\n",
      "[724/1762] D loss: 0.3648, G loss: 1.4114\n",
      "[804/1762] D loss: 0.1723, G loss: 2.3730\n",
      "[884/1762] D loss: 1.4083, G loss: 0.7040\n",
      "[964/1762] D loss: 1.4332, G loss: 0.6389\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.6974\n",
      "[1124/1762] D loss: 1.4097, G loss: 0.8298\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.7052\n",
      "[1284/1762] D loss: 0.3727, G loss: 1.7317\n",
      "[1364/1762] D loss: 1.4153, G loss: 0.4795\n",
      "[1444/1762] D loss: 1.3329, G loss: 0.7121\n",
      "[1524/1762] D loss: 1.3285, G loss: 0.7999\n",
      "[1604/1762] D loss: 1.2486, G loss: 0.9369\n",
      "[1684/1762] D loss: 1.3943, G loss: 0.7079\n",
      "[1762/1762] D loss: 1.4777, G loss: 0.6562\n",
      "train error: \n",
      " D loss: 1.346659, G loss: 0.671114, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334846, G loss: 0.687695, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3594, G loss: 1.5964\n",
      "[84/1762] D loss: 0.3518, G loss: 1.7548\n",
      "[164/1762] D loss: 1.4005, G loss: 0.8155\n",
      "[244/1762] D loss: 1.4516, G loss: 0.8805\n",
      "[324/1762] D loss: 0.3646, G loss: 1.9123\n",
      "[404/1762] D loss: 0.3392, G loss: 1.9488\n",
      "[484/1762] D loss: 0.2097, G loss: 2.4001\n",
      "[564/1762] D loss: 0.0589, G loss: 3.7759\n",
      "[644/1762] D loss: 1.4243, G loss: 0.7702\n",
      "[724/1762] D loss: 1.4196, G loss: 0.7262\n",
      "[804/1762] D loss: 1.0700, G loss: 1.4477\n",
      "[884/1762] D loss: 0.2859, G loss: 2.1378\n",
      "[964/1762] D loss: 1.4322, G loss: 0.5904\n",
      "[1044/1762] D loss: 0.6330, G loss: 1.2035\n",
      "[1124/1762] D loss: 1.4089, G loss: 0.6521\n",
      "[1204/1762] D loss: 1.5222, G loss: 0.9757\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.7156\n",
      "[1364/1762] D loss: 1.5091, G loss: 0.6746\n",
      "[1444/1762] D loss: 1.3949, G loss: 0.7088\n",
      "[1524/1762] D loss: 1.4404, G loss: 0.8299\n",
      "[1604/1762] D loss: 1.4404, G loss: 0.5789\n",
      "[1684/1762] D loss: 1.4868, G loss: 0.8015\n",
      "[1762/1762] D loss: 1.3466, G loss: 0.8275\n",
      "train error: \n",
      " D loss: 1.354488, G loss: 0.615360, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327126, G loss: 0.663719, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3358, G loss: 0.7764\n",
      "[84/1762] D loss: 0.3497, G loss: 1.9512\n",
      "[164/1762] D loss: 1.3711, G loss: 0.5271\n",
      "[244/1762] D loss: 0.1127, G loss: 2.6611\n",
      "[324/1762] D loss: 1.4302, G loss: 0.6384\n",
      "[404/1762] D loss: 0.1257, G loss: 2.6818\n",
      "[484/1762] D loss: 1.4041, G loss: 0.6774\n",
      "[564/1762] D loss: 1.4171, G loss: 0.6509\n",
      "[644/1762] D loss: 1.4305, G loss: 0.5624\n",
      "[724/1762] D loss: 0.9631, G loss: 1.4475\n",
      "[804/1762] D loss: 1.4533, G loss: 0.6734\n",
      "[884/1762] D loss: 1.6494, G loss: 0.6375\n",
      "[964/1762] D loss: 1.5013, G loss: 0.7261\n",
      "[1044/1762] D loss: 0.1881, G loss: 2.5710\n",
      "[1124/1762] D loss: 1.6517, G loss: 0.8560\n",
      "[1204/1762] D loss: 1.4241, G loss: 0.6341\n",
      "[1284/1762] D loss: 1.3475, G loss: 0.7002\n",
      "[1364/1762] D loss: 1.4175, G loss: 0.6649\n",
      "[1444/1762] D loss: 1.4169, G loss: 0.8658\n",
      "[1524/1762] D loss: 1.4023, G loss: 0.6673\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.6888\n",
      "[1684/1762] D loss: 0.0904, G loss: 3.5034\n",
      "[1762/1762] D loss: 0.8700, G loss: 1.6150\n",
      "train error: \n",
      " D loss: 1.350971, G loss: 0.613346, D accuracy: 57.7%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341599, G loss: 0.638007, D accuracy: 57.8%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4102, G loss: 0.6373\n",
      "[84/1762] D loss: 0.2312, G loss: 2.3248\n",
      "[164/1762] D loss: 1.4386, G loss: 0.6983\n",
      "[244/1762] D loss: 1.4020, G loss: 0.7103\n",
      "[324/1762] D loss: 1.1692, G loss: 1.0898\n",
      "[404/1762] D loss: 1.4471, G loss: 0.7053\n",
      "[484/1762] D loss: 1.4219, G loss: 0.6328\n",
      "[564/1762] D loss: 1.3249, G loss: 0.7785\n",
      "[644/1762] D loss: 1.4005, G loss: 0.6963\n",
      "[724/1762] D loss: 0.2389, G loss: 2.3597\n",
      "[804/1762] D loss: 1.4529, G loss: 0.6175\n",
      "[884/1762] D loss: 1.4099, G loss: 0.5817\n",
      "[964/1762] D loss: 1.3992, G loss: 0.6548\n",
      "[1044/1762] D loss: 1.4007, G loss: 0.7220\n",
      "[1124/1762] D loss: 1.4266, G loss: 0.8004\n",
      "[1204/1762] D loss: 1.3979, G loss: 0.7579\n",
      "[1284/1762] D loss: 0.1647, G loss: 2.5401\n",
      "[1364/1762] D loss: 1.4545, G loss: 0.7568\n",
      "[1444/1762] D loss: 1.4013, G loss: 0.7947\n",
      "[1524/1762] D loss: 0.2381, G loss: 2.5850\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.6982\n",
      "[1684/1762] D loss: 1.3977, G loss: 0.7458\n",
      "[1762/1762] D loss: 0.3802, G loss: 2.9380\n",
      "train error: \n",
      " D loss: 1.421290, G loss: 0.556626, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404314, G loss: 0.598470, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5335, G loss: 0.8705\n",
      "[84/1762] D loss: 0.4374, G loss: 1.7202\n",
      "[164/1762] D loss: 1.4109, G loss: 0.7733\n",
      "[244/1762] D loss: 1.4587, G loss: 0.8791\n",
      "[324/1762] D loss: 1.4051, G loss: 0.7186\n",
      "[404/1762] D loss: 1.4084, G loss: 0.5752\n",
      "[484/1762] D loss: 1.3165, G loss: 0.6690\n",
      "[564/1762] D loss: 1.4337, G loss: 0.6290\n",
      "[644/1762] D loss: 1.3923, G loss: 0.6678\n",
      "[724/1762] D loss: 1.4142, G loss: 0.7749\n",
      "[804/1762] D loss: 1.4017, G loss: 0.7461\n",
      "[884/1762] D loss: 1.3972, G loss: 0.7180\n",
      "[964/1762] D loss: 1.4514, G loss: 0.7212\n",
      "[1044/1762] D loss: 0.2242, G loss: 2.0388\n",
      "[1124/1762] D loss: 1.4473, G loss: 0.7624\n",
      "[1204/1762] D loss: 1.4045, G loss: 0.6824\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6490\n",
      "[1364/1762] D loss: 1.4120, G loss: 0.7567\n",
      "[1444/1762] D loss: 1.4081, G loss: 0.8650\n",
      "[1524/1762] D loss: 1.4214, G loss: 0.7084\n",
      "[1604/1762] D loss: 1.1332, G loss: 1.4038\n",
      "[1684/1762] D loss: 1.4294, G loss: 0.6828\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.7319\n",
      "train error: \n",
      " D loss: 1.381668, G loss: 0.722037, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382521, G loss: 0.764518, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4129, G loss: 0.6777\n",
      "[84/1762] D loss: 1.3612, G loss: 0.8259\n",
      "[164/1762] D loss: 1.4438, G loss: 0.7786\n",
      "[244/1762] D loss: 1.3488, G loss: 0.6633\n",
      "[324/1762] D loss: 0.2427, G loss: 1.6090\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7780\n",
      "[484/1762] D loss: 1.3843, G loss: 1.0016\n",
      "[564/1762] D loss: 0.2419, G loss: 1.9885\n",
      "[644/1762] D loss: 1.4085, G loss: 0.6667\n",
      "[724/1762] D loss: 1.3978, G loss: 0.6974\n",
      "[804/1762] D loss: 1.3909, G loss: 0.7720\n",
      "[884/1762] D loss: 1.2476, G loss: 0.8157\n",
      "[964/1762] D loss: 1.6024, G loss: 1.0202\n",
      "[1044/1762] D loss: 0.0488, G loss: 3.7423\n",
      "[1124/1762] D loss: 0.2474, G loss: 2.1508\n",
      "[1204/1762] D loss: 1.4107, G loss: 0.7211\n",
      "[1284/1762] D loss: 1.4739, G loss: 0.5743\n",
      "[1364/1762] D loss: 1.4040, G loss: 0.7183\n",
      "[1444/1762] D loss: 1.5093, G loss: 0.8248\n",
      "[1524/1762] D loss: 1.4079, G loss: 0.7013\n",
      "[1604/1762] D loss: 0.0764, G loss: 3.1134\n",
      "[1684/1762] D loss: 1.4044, G loss: 0.7663\n",
      "[1762/1762] D loss: 1.4370, G loss: 0.7131\n",
      "train error: \n",
      " D loss: 1.440532, G loss: 0.718291, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.446244, G loss: 0.750623, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4041, G loss: 0.7669\n",
      "[84/1762] D loss: 1.4045, G loss: 0.7388\n",
      "[164/1762] D loss: 1.4726, G loss: 0.7456\n",
      "[244/1762] D loss: 1.4254, G loss: 0.6902\n",
      "[324/1762] D loss: 1.3938, G loss: 0.7559\n",
      "[404/1762] D loss: 1.3916, G loss: 0.7071\n",
      "[484/1762] D loss: 1.4821, G loss: 0.6456\n",
      "[564/1762] D loss: 1.4570, G loss: 0.6478\n",
      "[644/1762] D loss: 1.4109, G loss: 0.7589\n",
      "[724/1762] D loss: 1.3924, G loss: 0.7419\n",
      "[804/1762] D loss: 1.6628, G loss: 0.7120\n",
      "[884/1762] D loss: 1.4065, G loss: 0.8590\n",
      "[964/1762] D loss: 1.3332, G loss: 0.9503\n",
      "[1044/1762] D loss: 2.0504, G loss: 0.8419\n",
      "[1124/1762] D loss: 0.4038, G loss: 2.2129\n",
      "[1204/1762] D loss: 1.2594, G loss: 0.8708\n",
      "[1284/1762] D loss: 0.1618, G loss: 2.6130\n",
      "[1364/1762] D loss: 0.3564, G loss: 1.7766\n",
      "[1444/1762] D loss: 1.4107, G loss: 0.7549\n",
      "[1524/1762] D loss: 1.3966, G loss: 0.8024\n",
      "[1604/1762] D loss: 1.3928, G loss: 0.6693\n",
      "[1684/1762] D loss: 0.0239, G loss: 4.2565\n",
      "[1762/1762] D loss: 0.0059, G loss: 12.1213\n",
      "train error: \n",
      " D loss: 2.110845, G loss: 0.241561, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.054459, G loss: 0.293318, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904, G loss: 0.6768\n",
      "[84/1762] D loss: 1.4010, G loss: 0.7680\n",
      "[164/1762] D loss: 1.4042, G loss: 0.6245\n",
      "[244/1762] D loss: 1.3817, G loss: 0.7527\n",
      "[324/1762] D loss: 0.0753, G loss: 3.3232\n",
      "[404/1762] D loss: 0.1300, G loss: 3.2497\n",
      "[484/1762] D loss: 0.1877, G loss: 2.0820\n",
      "[564/1762] D loss: 1.4167, G loss: 0.7676\n",
      "[644/1762] D loss: 1.4162, G loss: 0.8304\n",
      "[724/1762] D loss: 1.4237, G loss: 0.6452\n",
      "[804/1762] D loss: 0.1145, G loss: 3.3470\n",
      "[884/1762] D loss: 1.2146, G loss: 1.3118\n",
      "[964/1762] D loss: 1.3025, G loss: 0.7225\n",
      "[1044/1762] D loss: 1.4117, G loss: 0.7688\n",
      "[1124/1762] D loss: 0.1670, G loss: 2.1729\n",
      "[1204/1762] D loss: 1.3986, G loss: 0.5907\n",
      "[1284/1762] D loss: 1.4039, G loss: 0.7011\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.5734\n",
      "[1444/1762] D loss: 1.4971, G loss: 0.7904\n",
      "[1524/1762] D loss: 1.3946, G loss: 0.6597\n",
      "[1604/1762] D loss: 0.0394, G loss: 3.4165\n",
      "[1684/1762] D loss: 1.4191, G loss: 0.6794\n",
      "[1762/1762] D loss: 1.3989, G loss: 0.7087\n",
      "train error: \n",
      " D loss: 1.475663, G loss: 0.595334, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.464016, G loss: 0.644188, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4205, G loss: 0.6847\n",
      "[84/1762] D loss: 1.3952, G loss: 0.5915\n",
      "[164/1762] D loss: 1.3887, G loss: 0.7287\n",
      "[244/1762] D loss: 0.1587, G loss: 2.6397\n",
      "[324/1762] D loss: 0.1585, G loss: 2.8223\n",
      "[404/1762] D loss: 0.1240, G loss: 2.8156\n",
      "[484/1762] D loss: 1.4314, G loss: 0.6549\n",
      "[564/1762] D loss: 1.4216, G loss: 0.6492\n",
      "[644/1762] D loss: 0.3002, G loss: 2.5101\n",
      "[724/1762] D loss: 1.4068, G loss: 0.7004\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6722\n",
      "[884/1762] D loss: 1.3879, G loss: 0.8163\n",
      "[964/1762] D loss: 1.4892, G loss: 0.8720\n",
      "[1044/1762] D loss: 1.4130, G loss: 0.8052\n",
      "[1124/1762] D loss: 1.4870, G loss: 0.6175\n",
      "[1204/1762] D loss: 0.1795, G loss: 2.2117\n",
      "[1284/1762] D loss: 0.0843, G loss: 2.9353\n",
      "[1364/1762] D loss: 0.2731, G loss: 1.8748\n",
      "[1444/1762] D loss: 1.3931, G loss: 0.7847\n",
      "[1524/1762] D loss: 1.4013, G loss: 0.6490\n",
      "[1604/1762] D loss: 1.4029, G loss: 0.7386\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.6364\n",
      "[1762/1762] D loss: 1.3592, G loss: 0.7577\n",
      "train error: \n",
      " D loss: 1.729172, G loss: 0.478498, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.746740, G loss: 0.529541, D accuracy: 51.0%, cell accuracy: 99.7%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4192, G loss: 0.6849\n",
      "[84/1762] D loss: 1.5586, G loss: 0.4984\n",
      "[164/1762] D loss: 0.1320, G loss: 2.4877\n",
      "[244/1762] D loss: 1.4071, G loss: 0.6974\n",
      "[324/1762] D loss: 1.3201, G loss: 0.7904\n",
      "[404/1762] D loss: 0.9742, G loss: 1.9983\n",
      "[484/1762] D loss: 1.3893, G loss: 0.6918\n",
      "[564/1762] D loss: 1.4027, G loss: 0.6978\n",
      "[644/1762] D loss: 1.5422, G loss: 0.5926\n",
      "[724/1762] D loss: 1.4609, G loss: 0.5786\n",
      "[804/1762] D loss: 0.1112, G loss: 2.8207\n",
      "[884/1762] D loss: 1.5082, G loss: 0.6449\n",
      "[964/1762] D loss: 0.2482, G loss: 2.5580\n",
      "[1044/1762] D loss: 0.0177, G loss: 4.9823\n",
      "[1124/1762] D loss: 0.1981, G loss: 2.5425\n",
      "[1204/1762] D loss: 1.4156, G loss: 0.7814\n",
      "[1284/1762] D loss: 1.4606, G loss: 0.7654\n",
      "[1364/1762] D loss: 0.0174, G loss: 4.6120\n",
      "[1444/1762] D loss: 1.4258, G loss: 0.6693\n",
      "[1524/1762] D loss: 1.4146, G loss: 0.6986\n",
      "[1604/1762] D loss: 1.0997, G loss: 1.1741\n",
      "[1684/1762] D loss: 1.4154, G loss: 0.6370\n",
      "[1762/1762] D loss: 1.4211, G loss: 0.4898\n",
      "train error: \n",
      " D loss: 1.832645, G loss: 0.377694, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.822551, G loss: 0.420418, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4247, G loss: 0.5595\n",
      "[84/1762] D loss: 0.1597, G loss: 2.8164\n",
      "[164/1762] D loss: 1.4033, G loss: 0.7613\n",
      "[244/1762] D loss: 1.3877, G loss: 0.8098\n",
      "[324/1762] D loss: 1.4053, G loss: 0.6315\n",
      "[404/1762] D loss: 1.3880, G loss: 0.7083\n",
      "[484/1762] D loss: 0.1382, G loss: 2.6192\n",
      "[564/1762] D loss: 0.0125, G loss: 5.3439\n",
      "[644/1762] D loss: 1.4175, G loss: 0.7759\n",
      "[724/1762] D loss: 1.4164, G loss: 0.7219\n",
      "[804/1762] D loss: 1.3925, G loss: 0.6796\n",
      "[884/1762] D loss: 1.3946, G loss: 0.6978\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6298\n",
      "[1044/1762] D loss: 1.3961, G loss: 0.6806\n",
      "[1124/1762] D loss: 1.4698, G loss: 0.7475\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.6550\n",
      "[1284/1762] D loss: 1.3953, G loss: 0.5811\n",
      "[1364/1762] D loss: 0.1052, G loss: 3.4622\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6513\n",
      "[1524/1762] D loss: 1.3851, G loss: 0.6983\n",
      "[1604/1762] D loss: 1.4123, G loss: 0.7169\n",
      "[1684/1762] D loss: 1.5165, G loss: 0.8599\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.7134\n",
      "train error: \n",
      " D loss: 1.661103, G loss: 0.397371, D accuracy: 50.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.675602, G loss: 0.426736, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3971, G loss: 0.6952\n",
      "[84/1762] D loss: 1.3988, G loss: 0.6227\n",
      "[164/1762] D loss: 1.4008, G loss: 0.6631\n",
      "[244/1762] D loss: 0.1205, G loss: 3.5571\n",
      "[324/1762] D loss: 0.2196, G loss: 2.1508\n",
      "[404/1762] D loss: 1.3906, G loss: 0.7528\n",
      "[484/1762] D loss: 1.4347, G loss: 0.7143\n",
      "[564/1762] D loss: 1.4950, G loss: 0.5589\n",
      "[644/1762] D loss: 0.1315, G loss: 2.6117\n",
      "[724/1762] D loss: 0.1266, G loss: 3.0213\n",
      "[804/1762] D loss: 0.1731, G loss: 2.5052\n",
      "[884/1762] D loss: 0.1220, G loss: 3.0994\n",
      "[964/1762] D loss: 1.4375, G loss: 0.6855\n",
      "[1044/1762] D loss: 1.4261, G loss: 0.6392\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.7309\n",
      "[1204/1762] D loss: 1.4032, G loss: 0.7590\n",
      "[1284/1762] D loss: 1.4142, G loss: 0.7252\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.6951\n",
      "[1444/1762] D loss: 0.1543, G loss: 2.9014\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6776\n",
      "[1604/1762] D loss: 1.3991, G loss: 0.6599\n",
      "[1684/1762] D loss: 1.3932, G loss: 0.6225\n",
      "[1762/1762] D loss: 1.4655, G loss: 0.7307\n",
      "train error: \n",
      " D loss: 1.861336, G loss: 0.364768, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.849330, G loss: 0.412377, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4259, G loss: 0.6380\n",
      "[84/1762] D loss: 1.3990, G loss: 0.7520\n",
      "[164/1762] D loss: 1.3945, G loss: 0.8309\n",
      "[244/1762] D loss: 1.4868, G loss: 0.7325\n",
      "[324/1762] D loss: 1.7118, G loss: 1.6363\n",
      "[404/1762] D loss: 1.3962, G loss: 0.6169\n",
      "[484/1762] D loss: 1.4569, G loss: 0.7097\n",
      "[564/1762] D loss: 0.0750, G loss: 3.5529\n",
      "[644/1762] D loss: 1.4201, G loss: 0.6589\n",
      "[724/1762] D loss: 0.1076, G loss: 3.3819\n",
      "[804/1762] D loss: 0.0676, G loss: 3.2031\n",
      "[884/1762] D loss: 1.4173, G loss: 0.6234\n",
      "[964/1762] D loss: 1.4247, G loss: 0.6339\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.6586\n",
      "[1124/1762] D loss: 0.1187, G loss: 3.0970\n",
      "[1204/1762] D loss: 1.4071, G loss: 0.6897\n",
      "[1284/1762] D loss: 1.3934, G loss: 0.7350\n",
      "[1364/1762] D loss: 0.1589, G loss: 2.9967\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.6914\n",
      "[1524/1762] D loss: 0.1256, G loss: 2.6876\n",
      "[1604/1762] D loss: 1.3943, G loss: 0.5658\n",
      "[1684/1762] D loss: 1.4024, G loss: 0.7431\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7011\n",
      "train error: \n",
      " D loss: 1.764864, G loss: 0.468947, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.797886, G loss: 0.510733, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3947, G loss: 0.7054\n",
      "[84/1762] D loss: 1.3988, G loss: 0.6622\n",
      "[164/1762] D loss: 1.4018, G loss: 0.7054\n",
      "[244/1762] D loss: 1.4251, G loss: 0.7373\n",
      "[324/1762] D loss: 1.3949, G loss: 0.7720\n",
      "[404/1762] D loss: 0.0791, G loss: 3.4012\n",
      "[484/1762] D loss: 0.0883, G loss: 3.1886\n",
      "[564/1762] D loss: 0.0707, G loss: 3.7920\n",
      "[644/1762] D loss: 0.1676, G loss: 2.7623\n",
      "[724/1762] D loss: 0.0814, G loss: 3.2951\n",
      "[804/1762] D loss: 0.1008, G loss: 2.8356\n",
      "[884/1762] D loss: 1.5725, G loss: 0.6671\n",
      "[964/1762] D loss: 0.1074, G loss: 3.0515\n",
      "[1044/1762] D loss: 1.4279, G loss: 0.6990\n",
      "[1124/1762] D loss: 1.4082, G loss: 0.7329\n",
      "[1204/1762] D loss: 1.4479, G loss: 0.7262\n",
      "[1284/1762] D loss: 0.0084, G loss: 5.3671\n",
      "[1364/1762] D loss: 1.3949, G loss: 0.7336\n",
      "[1444/1762] D loss: 1.3996, G loss: 0.5563\n",
      "[1524/1762] D loss: 1.4183, G loss: 0.7871\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.6977\n",
      "[1684/1762] D loss: 0.8240, G loss: 2.0671\n",
      "[1762/1762] D loss: 1.4592, G loss: 0.7617\n",
      "train error: \n",
      " D loss: 2.381326, G loss: 0.368350, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.347957, G loss: 0.446264, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4197, G loss: 0.7766\n",
      "[84/1762] D loss: 1.4119, G loss: 0.6336\n",
      "[164/1762] D loss: 1.2832, G loss: 0.7834\n",
      "[244/1762] D loss: 1.4273, G loss: 0.5601\n",
      "[324/1762] D loss: 0.0369, G loss: 4.2275\n",
      "[404/1762] D loss: 1.4028, G loss: 0.8073\n",
      "[484/1762] D loss: 0.0864, G loss: 3.2297\n",
      "[564/1762] D loss: 1.4431, G loss: 0.6334\n",
      "[644/1762] D loss: 1.3370, G loss: 0.8312\n",
      "[724/1762] D loss: 0.1120, G loss: 3.6207\n",
      "[804/1762] D loss: 1.4153, G loss: 0.7118\n",
      "[884/1762] D loss: 1.3881, G loss: 0.7038\n",
      "[964/1762] D loss: 0.1251, G loss: 3.6948\n",
      "[1044/1762] D loss: 1.4354, G loss: 0.7464\n",
      "[1124/1762] D loss: 0.1418, G loss: 2.8841\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.7405\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.6906\n",
      "[1364/1762] D loss: 1.3826, G loss: 0.6813\n",
      "[1444/1762] D loss: 1.6421, G loss: 0.7462\n",
      "[1524/1762] D loss: 1.4011, G loss: 0.5733\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.7133\n",
      "[1684/1762] D loss: 0.0957, G loss: 3.3747\n",
      "[1762/1762] D loss: 1.4053, G loss: 0.7064\n",
      "train error: \n",
      " D loss: 1.717097, G loss: 0.568420, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.744971, G loss: 0.640137, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3973, G loss: 0.6781\n",
      "[84/1762] D loss: 1.4616, G loss: 0.6704\n",
      "[164/1762] D loss: 0.0191, G loss: 4.6715\n",
      "[244/1762] D loss: 1.4139, G loss: 0.6983\n",
      "[324/1762] D loss: 1.3884, G loss: 0.7151\n",
      "[404/1762] D loss: 1.3904, G loss: 0.6952\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6687\n",
      "[564/1762] D loss: 0.0907, G loss: 3.4439\n",
      "[644/1762] D loss: 1.4293, G loss: 0.6151\n",
      "[724/1762] D loss: 1.3964, G loss: 0.6837\n",
      "[804/1762] D loss: 1.3952, G loss: 0.6581\n",
      "[884/1762] D loss: 1.4781, G loss: 0.5880\n",
      "[964/1762] D loss: 1.3384, G loss: 0.8805\n",
      "[1044/1762] D loss: 1.3915, G loss: 0.6724\n",
      "[1124/1762] D loss: 1.4051, G loss: 0.6332\n",
      "[1204/1762] D loss: 1.3956, G loss: 0.6012\n",
      "[1284/1762] D loss: 1.4493, G loss: 0.7492\n",
      "[1364/1762] D loss: 1.4464, G loss: 0.8800\n",
      "[1444/1762] D loss: 1.1706, G loss: 1.2356\n",
      "[1524/1762] D loss: 1.3920, G loss: 0.7380\n",
      "[1604/1762] D loss: 1.4069, G loss: 0.6490\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.7604\n",
      "[1762/1762] D loss: 1.4616, G loss: 0.8304\n",
      "train error: \n",
      " D loss: 1.860732, G loss: 1.072508, D accuracy: 53.2%, cell accuracy: 99.5%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.870252, G loss: 0.731124, D accuracy: 52.8%, cell accuracy: 99.5%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4733, G loss: 0.6970\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6660\n",
      "[164/1762] D loss: 0.1005, G loss: 3.2828\n",
      "[244/1762] D loss: 1.4175, G loss: 0.8201\n",
      "[324/1762] D loss: 1.4119, G loss: 0.7244\n",
      "[404/1762] D loss: 1.3950, G loss: 0.7436\n",
      "[484/1762] D loss: 0.1239, G loss: 2.7347\n",
      "[564/1762] D loss: 1.3904, G loss: 0.7117\n",
      "[644/1762] D loss: 1.5675, G loss: 0.5893\n",
      "[724/1762] D loss: 0.2405, G loss: 3.2433\n",
      "[804/1762] D loss: 0.6696, G loss: 2.5508\n",
      "[884/1762] D loss: 1.4207, G loss: 0.5848\n",
      "[964/1762] D loss: 1.3950, G loss: 0.7068\n",
      "[1044/1762] D loss: 1.4109, G loss: 0.6970\n",
      "[1124/1762] D loss: 1.3410, G loss: 0.7420\n",
      "[1204/1762] D loss: 1.3606, G loss: 0.7142\n",
      "[1284/1762] D loss: 1.3916, G loss: 0.7222\n",
      "[1364/1762] D loss: 1.4045, G loss: 0.6471\n",
      "[1444/1762] D loss: 0.0546, G loss: 3.7622\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.6858\n",
      "[1604/1762] D loss: 0.0576, G loss: 3.3080\n",
      "[1684/1762] D loss: 0.0874, G loss: 2.9769\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7236\n",
      "train error: \n",
      " D loss: 1.901752, G loss: 0.549306, D accuracy: 51.9%, cell accuracy: 99.6%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.885562, G loss: 0.712180, D accuracy: 52.5%, cell accuracy: 99.5%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3047, G loss: 0.8424\n",
      "[84/1762] D loss: 0.0332, G loss: 4.6929\n",
      "[164/1762] D loss: 1.5004, G loss: 0.7778\n",
      "[244/1762] D loss: 0.0833, G loss: 3.5560\n",
      "[324/1762] D loss: 0.1839, G loss: 2.9178\n",
      "[404/1762] D loss: 1.3892, G loss: 0.7088\n",
      "[484/1762] D loss: 0.1137, G loss: 2.8760\n",
      "[564/1762] D loss: 0.0976, G loss: 3.0849\n",
      "[644/1762] D loss: 1.4005, G loss: 0.7417\n",
      "[724/1762] D loss: 1.3859, G loss: 0.7105\n",
      "[804/1762] D loss: 0.9061, G loss: 1.9852\n",
      "[884/1762] D loss: 1.3889, G loss: 0.6983\n",
      "[964/1762] D loss: 0.1422, G loss: 3.7125\n",
      "[1044/1762] D loss: 1.5593, G loss: 0.6107\n",
      "[1124/1762] D loss: 0.0096, G loss: 6.4631\n",
      "[1204/1762] D loss: 1.4884, G loss: 0.6006\n",
      "[1284/1762] D loss: 1.4312, G loss: 0.6852\n",
      "[1364/1762] D loss: 1.4220, G loss: 0.6429\n",
      "[1444/1762] D loss: 1.4005, G loss: 0.7357\n",
      "[1524/1762] D loss: 1.3898, G loss: 0.6774\n",
      "[1604/1762] D loss: 1.4535, G loss: 0.5734\n",
      "[1684/1762] D loss: 1.4095, G loss: 0.5671\n",
      "[1762/1762] D loss: 1.4297, G loss: 0.7108\n",
      "train error: \n",
      " D loss: 1.730526, G loss: 0.515410, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.710124, G loss: 0.600461, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0986, G loss: 3.2134\n",
      "[84/1762] D loss: 0.1174, G loss: 3.1478\n",
      "[164/1762] D loss: 0.0580, G loss: 3.9271\n",
      "[244/1762] D loss: 1.4065, G loss: 0.6026\n",
      "[324/1762] D loss: 1.3985, G loss: 0.7347\n",
      "[404/1762] D loss: 1.3947, G loss: 0.6974\n",
      "[484/1762] D loss: 1.3895, G loss: 0.6657\n",
      "[564/1762] D loss: 1.4163, G loss: 0.7763\n",
      "[644/1762] D loss: 1.3935, G loss: 0.6330\n",
      "[724/1762] D loss: 0.0907, G loss: 3.3317\n",
      "[804/1762] D loss: 1.3930, G loss: 0.6885\n",
      "[884/1762] D loss: 1.4221, G loss: 0.6722\n",
      "[964/1762] D loss: 1.3825, G loss: 0.7120\n",
      "[1044/1762] D loss: 0.9442, G loss: 1.6240\n",
      "[1124/1762] D loss: 1.4107, G loss: 0.7418\n",
      "[1204/1762] D loss: 0.1011, G loss: 3.3131\n",
      "[1284/1762] D loss: 1.3998, G loss: 0.6899\n",
      "[1364/1762] D loss: 0.0864, G loss: 3.1930\n",
      "[1444/1762] D loss: 1.4608, G loss: 0.5700\n",
      "[1524/1762] D loss: 1.3991, G loss: 0.6416\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.7392\n",
      "[1684/1762] D loss: 1.5043, G loss: 0.5520\n",
      "[1762/1762] D loss: 1.4430, G loss: 0.5623\n",
      "train error: \n",
      " D loss: 2.035943, G loss: 0.428092, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.012256, G loss: 0.516646, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4067, G loss: 0.6072\n",
      "[84/1762] D loss: 0.0094, G loss: 5.5847\n",
      "[164/1762] D loss: 0.0974, G loss: 3.1542\n",
      "[244/1762] D loss: 0.0919, G loss: 3.3404\n",
      "[324/1762] D loss: 1.4552, G loss: 0.6512\n",
      "[404/1762] D loss: 1.4191, G loss: 0.6519\n",
      "[484/1762] D loss: 1.1191, G loss: 0.9595\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6624\n",
      "[644/1762] D loss: 1.4046, G loss: 0.6690\n",
      "[724/1762] D loss: 0.0754, G loss: 3.6547\n",
      "[804/1762] D loss: 0.0991, G loss: 3.2266\n",
      "[884/1762] D loss: 1.3909, G loss: 0.6690\n",
      "[964/1762] D loss: 1.4501, G loss: 0.6446\n",
      "[1044/1762] D loss: 0.0774, G loss: 3.3169\n",
      "[1124/1762] D loss: 1.3906, G loss: 0.6915\n",
      "[1204/1762] D loss: 1.3987, G loss: 0.6794\n",
      "[1284/1762] D loss: 1.4157, G loss: 0.6772\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.7247\n",
      "[1444/1762] D loss: 1.5046, G loss: 0.5718\n",
      "[1524/1762] D loss: 1.4460, G loss: 0.7146\n",
      "[1604/1762] D loss: 1.3277, G loss: 0.7389\n",
      "[1684/1762] D loss: 1.4829, G loss: 0.6153\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6667\n",
      "train error: \n",
      " D loss: 2.125882, G loss: 0.424863, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.165699, G loss: 0.519108, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3996, G loss: 0.6802\n",
      "[84/1762] D loss: 1.3958, G loss: 0.6653\n",
      "[164/1762] D loss: 1.3967, G loss: 0.7341\n",
      "[244/1762] D loss: 1.4652, G loss: 0.4703\n",
      "[324/1762] D loss: 1.4362, G loss: 0.6491\n",
      "[404/1762] D loss: 1.4734, G loss: 0.6452\n",
      "[484/1762] D loss: 1.4042, G loss: 0.6770\n",
      "[564/1762] D loss: 1.4663, G loss: 0.7023\n",
      "[644/1762] D loss: 1.4061, G loss: 0.7701\n",
      "[724/1762] D loss: 1.3911, G loss: 0.6890\n",
      "[804/1762] D loss: 1.4432, G loss: 0.7150\n",
      "[884/1762] D loss: 0.0918, G loss: 3.8676\n",
      "[964/1762] D loss: 1.4510, G loss: 0.4793\n",
      "[1044/1762] D loss: 0.0968, G loss: 3.2439\n",
      "[1124/1762] D loss: 0.0663, G loss: 4.1729\n",
      "[1204/1762] D loss: 1.4097, G loss: 0.7029\n",
      "[1284/1762] D loss: 1.4028, G loss: 0.6852\n",
      "[1364/1762] D loss: 0.0810, G loss: 3.5254\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.6977\n",
      "[1524/1762] D loss: 0.7853, G loss: 2.7579\n",
      "[1604/1762] D loss: 0.2338, G loss: 1.9845\n",
      "[1684/1762] D loss: 1.5224, G loss: 0.7717\n",
      "[1762/1762] D loss: 1.3836, G loss: 0.6850\n",
      "train error: \n",
      " D loss: 1.926144, G loss: 0.441233, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.951770, G loss: 0.512505, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4030, G loss: 0.6678\n",
      "[84/1762] D loss: 1.4613, G loss: 0.7704\n",
      "[164/1762] D loss: 0.4077, G loss: 2.1083\n",
      "[244/1762] D loss: 1.3999, G loss: 0.7065\n",
      "[324/1762] D loss: 1.3919, G loss: 0.7060\n",
      "[404/1762] D loss: 1.3927, G loss: 0.6826\n",
      "[484/1762] D loss: 0.1010, G loss: 3.0668\n",
      "[564/1762] D loss: 1.4034, G loss: 0.6911\n",
      "[644/1762] D loss: 0.0755, G loss: 3.4071\n",
      "[724/1762] D loss: 0.0547, G loss: 4.1441\n",
      "[804/1762] D loss: 1.3931, G loss: 0.7379\n",
      "[884/1762] D loss: 1.4760, G loss: 0.7762\n",
      "[964/1762] D loss: 0.1052, G loss: 2.9728\n",
      "[1044/1762] D loss: 0.0779, G loss: 3.3641\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.7178\n",
      "[1204/1762] D loss: 1.4276, G loss: 0.7205\n",
      "[1284/1762] D loss: 1.3997, G loss: 0.6886\n",
      "[1364/1762] D loss: 1.4952, G loss: 0.5673\n",
      "[1444/1762] D loss: 1.4117, G loss: 0.7264\n",
      "[1524/1762] D loss: 1.4247, G loss: 0.6899\n",
      "[1604/1762] D loss: 1.4196, G loss: 0.6796\n",
      "[1684/1762] D loss: 1.3996, G loss: 0.7278\n",
      "[1762/1762] D loss: 1.3984, G loss: 0.5200\n",
      "train error: \n",
      " D loss: 2.420890, G loss: 0.422178, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.397540, G loss: 0.545599, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4388, G loss: 0.6322\n",
      "[84/1762] D loss: 1.3900, G loss: 0.6897\n",
      "[164/1762] D loss: 1.4041, G loss: 0.7539\n",
      "[244/1762] D loss: 0.1113, G loss: 3.0888\n",
      "[324/1762] D loss: 1.4034, G loss: 0.6660\n",
      "[404/1762] D loss: 0.0294, G loss: 4.0576\n",
      "[484/1762] D loss: 1.5597, G loss: 0.5607\n",
      "[564/1762] D loss: 0.0522, G loss: 3.8670\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6337\n",
      "[724/1762] D loss: 0.1734, G loss: 2.8469\n",
      "[804/1762] D loss: 1.4567, G loss: 0.6681\n",
      "[884/1762] D loss: 1.4010, G loss: 0.7370\n",
      "[964/1762] D loss: 1.4751, G loss: 0.6069\n",
      "[1044/1762] D loss: 1.4106, G loss: 0.7276\n",
      "[1124/1762] D loss: 1.2547, G loss: 0.8241\n",
      "[1204/1762] D loss: 1.3930, G loss: 0.6475\n",
      "[1284/1762] D loss: 1.4186, G loss: 0.7215\n",
      "[1364/1762] D loss: 1.4058, G loss: 0.6741\n",
      "[1444/1762] D loss: 1.0782, G loss: 1.7513\n",
      "[1524/1762] D loss: 1.3843, G loss: 0.7088\n",
      "[1604/1762] D loss: 1.4133, G loss: 0.6826\n",
      "[1684/1762] D loss: 0.0363, G loss: 4.6505\n",
      "[1762/1762] D loss: 1.4010, G loss: 0.7511\n",
      "train error: \n",
      " D loss: 1.960371, G loss: 0.771633, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.054885, G loss: 0.930395, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0535, G loss: 4.3468\n",
      "[84/1762] D loss: 1.3970, G loss: 0.6955\n",
      "[164/1762] D loss: 1.3848, G loss: 0.6629\n",
      "[244/1762] D loss: 0.0699, G loss: 3.4670\n",
      "[324/1762] D loss: 0.0536, G loss: 3.5477\n",
      "[404/1762] D loss: 1.3626, G loss: 0.7125\n",
      "[484/1762] D loss: 1.4431, G loss: 0.6484\n",
      "[564/1762] D loss: 1.3704, G loss: 1.9926\n",
      "[644/1762] D loss: 1.3438, G loss: 0.6745\n",
      "[724/1762] D loss: 0.0576, G loss: 3.9614\n",
      "[804/1762] D loss: 0.0439, G loss: 4.2223\n",
      "[884/1762] D loss: 1.5684, G loss: 0.6753\n",
      "[964/1762] D loss: 1.3799, G loss: 0.7330\n",
      "[1044/1762] D loss: 1.3923, G loss: 0.7259\n",
      "[1124/1762] D loss: 0.0929, G loss: 3.5020\n",
      "[1204/1762] D loss: 1.4028, G loss: 0.6536\n",
      "[1284/1762] D loss: 1.3978, G loss: 0.7706\n",
      "[1364/1762] D loss: 1.3996, G loss: 0.6627\n",
      "[1444/1762] D loss: 0.0120, G loss: 6.8400\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.6820\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7089\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.6853\n",
      "[1762/1762] D loss: 1.4272, G loss: 0.7068\n",
      "train error: \n",
      " D loss: 1.878908, G loss: 1.627912, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.881421, G loss: 1.685802, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4724, G loss: 0.8568\n",
      "[84/1762] D loss: 0.0696, G loss: 3.7365\n",
      "[164/1762] D loss: 1.4216, G loss: 0.8631\n",
      "[244/1762] D loss: 1.4658, G loss: 0.7829\n",
      "[324/1762] D loss: 1.3925, G loss: 0.7564\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6229\n",
      "[484/1762] D loss: 1.3520, G loss: 1.4442\n",
      "[564/1762] D loss: 1.4829, G loss: 0.5455\n",
      "[644/1762] D loss: 1.4010, G loss: 0.7149\n",
      "[724/1762] D loss: 1.4013, G loss: 0.8196\n",
      "[804/1762] D loss: 1.5149, G loss: 0.4228\n",
      "[884/1762] D loss: 0.0617, G loss: 4.1211\n",
      "[964/1762] D loss: 1.4156, G loss: 0.7392\n",
      "[1044/1762] D loss: 1.3783, G loss: 0.6826\n",
      "[1124/1762] D loss: 1.4095, G loss: 0.7285\n",
      "[1204/1762] D loss: 0.0351, G loss: 4.3544\n",
      "[1284/1762] D loss: 1.4031, G loss: 0.6753\n",
      "[1364/1762] D loss: 1.4264, G loss: 0.6741\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.7026\n",
      "[1524/1762] D loss: 1.3932, G loss: 0.6688\n",
      "[1604/1762] D loss: 1.3999, G loss: 0.7227\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.7063\n",
      "[1762/1762] D loss: 1.3945, G loss: 0.6914\n",
      "train error: \n",
      " D loss: 1.978569, G loss: 0.647748, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.109548, G loss: 0.718858, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4106, G loss: 0.6594\n",
      "[84/1762] D loss: 1.3787, G loss: 0.6784\n",
      "[164/1762] D loss: 1.4130, G loss: 0.7118\n",
      "[244/1762] D loss: 1.4253, G loss: 0.8859\n",
      "[324/1762] D loss: 1.4271, G loss: 0.7172\n",
      "[404/1762] D loss: 0.1192, G loss: 4.5260\n",
      "[484/1762] D loss: 1.4165, G loss: 0.6619\n",
      "[564/1762] D loss: 1.3954, G loss: 0.6749\n",
      "[644/1762] D loss: 1.4886, G loss: 0.8341\n",
      "[724/1762] D loss: 0.0501, G loss: 4.0548\n",
      "[804/1762] D loss: 1.0707, G loss: 1.0095\n",
      "[884/1762] D loss: 0.0592, G loss: 3.9278\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6786\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.7623\n",
      "[1124/1762] D loss: 1.4271, G loss: 0.6958\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6959\n",
      "[1284/1762] D loss: 0.0020, G loss: 7.6603\n",
      "[1364/1762] D loss: 1.4087, G loss: 0.6430\n",
      "[1444/1762] D loss: 0.0535, G loss: 3.3622\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.6945\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.7194\n",
      "[1684/1762] D loss: 1.3589, G loss: 0.9776\n",
      "[1762/1762] D loss: 1.3820, G loss: 0.6845\n",
      "train error: \n",
      " D loss: 1.882770, G loss: 0.860248, D accuracy: 50.3%, cell accuracy: 99.7%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.960362, G loss: 0.944174, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0351, G loss: 4.3970\n",
      "[84/1762] D loss: 1.4177, G loss: 0.8704\n",
      "[164/1762] D loss: 1.4032, G loss: 0.7174\n",
      "[244/1762] D loss: 1.3570, G loss: 0.7641\n",
      "[324/1762] D loss: 0.0933, G loss: 3.5842\n",
      "[404/1762] D loss: 1.4024, G loss: 0.6336\n",
      "[484/1762] D loss: 1.4180, G loss: 0.7506\n",
      "[564/1762] D loss: 1.3905, G loss: 0.7316\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6840\n",
      "[724/1762] D loss: 0.0465, G loss: 5.0592\n",
      "[804/1762] D loss: 0.0681, G loss: 3.9972\n",
      "[884/1762] D loss: 1.3454, G loss: 0.6416\n",
      "[964/1762] D loss: 1.4199, G loss: 0.5608\n",
      "[1044/1762] D loss: 0.0138, G loss: 6.9758\n",
      "[1124/1762] D loss: 0.0806, G loss: 4.0931\n",
      "[1204/1762] D loss: 1.3955, G loss: 0.6989\n",
      "[1284/1762] D loss: 1.3548, G loss: 0.6663\n",
      "[1364/1762] D loss: 1.3189, G loss: 0.9303\n",
      "[1444/1762] D loss: 1.7663, G loss: 0.4343\n",
      "[1524/1762] D loss: 0.2320, G loss: 4.0617\n",
      "[1604/1762] D loss: 1.3951, G loss: 0.6342\n",
      "[1684/1762] D loss: 1.4159, G loss: 0.6824\n",
      "[1762/1762] D loss: 1.4965, G loss: 0.9542\n",
      "train error: \n",
      " D loss: 1.637459, G loss: 0.660785, D accuracy: 49.4%, cell accuracy: 99.7%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.631348, G loss: 0.718149, D accuracy: 48.8%, cell accuracy: 99.7%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1741, G loss: 2.6853\n",
      "[84/1762] D loss: 1.4293, G loss: 0.5549\n",
      "[164/1762] D loss: 0.1867, G loss: 2.7562\n",
      "[244/1762] D loss: 0.1815, G loss: 3.4180\n",
      "[324/1762] D loss: 1.4311, G loss: 0.7440\n",
      "[404/1762] D loss: 1.3925, G loss: 0.8000\n",
      "[484/1762] D loss: 0.0966, G loss: 2.8836\n",
      "[564/1762] D loss: 1.4556, G loss: 0.7682\n",
      "[644/1762] D loss: 1.3889, G loss: 0.7216\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6699\n",
      "[804/1762] D loss: 0.1616, G loss: 2.9553\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6230\n",
      "[964/1762] D loss: 1.3957, G loss: 0.6783\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.7193\n",
      "[1124/1762] D loss: 1.4036, G loss: 0.6749\n",
      "[1204/1762] D loss: 1.4093, G loss: 0.7091\n",
      "[1284/1762] D loss: 0.0754, G loss: 3.9852\n",
      "[1364/1762] D loss: 0.0716, G loss: 3.9765\n",
      "[1444/1762] D loss: 1.3815, G loss: 0.7036\n",
      "[1524/1762] D loss: 0.0805, G loss: 4.0198\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.7156\n",
      "[1684/1762] D loss: 1.4668, G loss: 0.5923\n",
      "[1762/1762] D loss: 1.3804, G loss: 0.6699\n",
      "train error: \n",
      " D loss: 2.126936, G loss: 0.654129, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.251581, G loss: 0.760479, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.6807\n",
      "[84/1762] D loss: 1.3984, G loss: 0.6837\n",
      "[164/1762] D loss: 1.3764, G loss: 0.6909\n",
      "[244/1762] D loss: 0.0266, G loss: 4.8372\n",
      "[324/1762] D loss: 1.4782, G loss: 0.6589\n",
      "[404/1762] D loss: 0.0683, G loss: 3.6530\n",
      "[484/1762] D loss: 1.3901, G loss: 0.6691\n",
      "[564/1762] D loss: 1.4054, G loss: 0.6993\n",
      "[644/1762] D loss: 1.4092, G loss: 0.7763\n",
      "[724/1762] D loss: 1.3847, G loss: 0.6664\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6904\n",
      "[884/1762] D loss: 0.0687, G loss: 3.8632\n",
      "[964/1762] D loss: 1.3962, G loss: 0.6752\n",
      "[1044/1762] D loss: 0.0660, G loss: 4.1735\n",
      "[1124/1762] D loss: 1.4248, G loss: 0.7459\n",
      "[1204/1762] D loss: 1.3992, G loss: 0.7071\n",
      "[1284/1762] D loss: 1.3797, G loss: 0.7556\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.7441\n",
      "[1444/1762] D loss: 0.0568, G loss: 3.9597\n",
      "[1524/1762] D loss: 1.3848, G loss: 0.6686\n",
      "[1604/1762] D loss: 0.1633, G loss: 2.9814\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6674\n",
      "[1762/1762] D loss: 0.0022, G loss: 7.0614\n",
      "train error: \n",
      " D loss: 2.945746, G loss: 0.368035, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.877928, G loss: 0.475921, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4017, G loss: 0.7278\n",
      "[84/1762] D loss: 0.1527, G loss: 2.9204\n",
      "[164/1762] D loss: 1.3901, G loss: 0.7193\n",
      "[244/1762] D loss: 1.3897, G loss: 0.5848\n",
      "[324/1762] D loss: 0.0302, G loss: 4.3667\n",
      "[404/1762] D loss: 1.4035, G loss: 0.7761\n",
      "[484/1762] D loss: 1.3977, G loss: 0.6659\n",
      "[564/1762] D loss: 0.0677, G loss: 3.7888\n",
      "[644/1762] D loss: 1.3939, G loss: 0.8170\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6898\n",
      "[804/1762] D loss: 1.3891, G loss: 0.6831\n",
      "[884/1762] D loss: 1.3805, G loss: 0.6807\n",
      "[964/1762] D loss: 1.4126, G loss: 0.6571\n",
      "[1044/1762] D loss: 1.4747, G loss: 0.7719\n",
      "[1124/1762] D loss: 1.3890, G loss: 0.8989\n",
      "[1204/1762] D loss: 1.3242, G loss: 0.7903\n",
      "[1284/1762] D loss: 1.5878, G loss: 0.6739\n",
      "[1364/1762] D loss: 1.3753, G loss: 0.6226\n",
      "[1444/1762] D loss: 0.0840, G loss: 3.8618\n",
      "[1524/1762] D loss: 1.4858, G loss: 0.6565\n",
      "[1604/1762] D loss: 0.0042, G loss: 6.6427\n",
      "[1684/1762] D loss: 1.4154, G loss: 0.7627\n",
      "[1762/1762] D loss: 1.4059, G loss: 0.7066\n",
      "train error: \n",
      " D loss: 2.211133, G loss: 0.650268, D accuracy: 50.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.322609, G loss: 0.741180, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4065, G loss: 0.7787\n",
      "[84/1762] D loss: 1.3981, G loss: 0.6488\n",
      "[164/1762] D loss: 0.0460, G loss: 3.7728\n",
      "[244/1762] D loss: 1.4017, G loss: 0.7125\n",
      "[324/1762] D loss: 1.4052, G loss: 0.6115\n",
      "[404/1762] D loss: 1.4139, G loss: 0.7499\n",
      "[484/1762] D loss: 1.4575, G loss: 0.6034\n",
      "[564/1762] D loss: 1.4203, G loss: 0.6790\n",
      "[644/1762] D loss: 0.0701, G loss: 3.5928\n",
      "[724/1762] D loss: 0.1644, G loss: 3.3610\n",
      "[804/1762] D loss: 1.3964, G loss: 0.6479\n",
      "[884/1762] D loss: 1.4258, G loss: 0.6665\n",
      "[964/1762] D loss: 1.4165, G loss: 0.7696\n",
      "[1044/1762] D loss: 0.0425, G loss: 3.8436\n",
      "[1124/1762] D loss: 1.3772, G loss: 0.7520\n",
      "[1204/1762] D loss: 1.3998, G loss: 0.6732\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7255\n",
      "[1364/1762] D loss: 1.3935, G loss: 0.6933\n",
      "[1444/1762] D loss: 1.4385, G loss: 0.6951\n",
      "[1524/1762] D loss: 1.3790, G loss: 0.7546\n",
      "[1604/1762] D loss: 1.3596, G loss: 0.8513\n",
      "[1684/1762] D loss: 1.3725, G loss: 0.8070\n",
      "[1762/1762] D loss: 1.4140, G loss: 0.6155\n",
      "train error: \n",
      " D loss: 2.144666, G loss: 0.538101, D accuracy: 50.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.241777, G loss: 0.636279, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8921, G loss: 2.4284\n",
      "[84/1762] D loss: 1.3734, G loss: 0.7593\n",
      "[164/1762] D loss: 0.0444, G loss: 3.7990\n",
      "[244/1762] D loss: 1.4583, G loss: 0.7978\n",
      "[324/1762] D loss: 0.0940, G loss: 2.7385\n",
      "[404/1762] D loss: 1.4422, G loss: 0.8383\n",
      "[484/1762] D loss: 1.4035, G loss: 0.7164\n",
      "[564/1762] D loss: 0.0341, G loss: 3.7243\n",
      "[644/1762] D loss: 1.3839, G loss: 0.6673\n",
      "[724/1762] D loss: 0.0354, G loss: 3.7693\n",
      "[804/1762] D loss: 1.4676, G loss: 0.6479\n",
      "[884/1762] D loss: 1.4005, G loss: 0.6763\n",
      "[964/1762] D loss: 1.4137, G loss: 0.5676\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.7052\n",
      "[1124/1762] D loss: 0.0460, G loss: 4.8500\n",
      "[1204/1762] D loss: 1.3857, G loss: 0.6983\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.7562\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.7160\n",
      "[1444/1762] D loss: 1.3991, G loss: 0.6665\n",
      "[1524/1762] D loss: 1.4229, G loss: 0.6442\n",
      "[1604/1762] D loss: 1.3833, G loss: 0.6761\n",
      "[1684/1762] D loss: 1.3898, G loss: 0.6995\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.6758\n",
      "train error: \n",
      " D loss: 2.580434, G loss: 0.521993, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.692396, G loss: 0.652205, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3767, G loss: 0.6526\n",
      "[84/1762] D loss: 0.0570, G loss: 3.6892\n",
      "[164/1762] D loss: 1.6158, G loss: 0.4747\n",
      "[244/1762] D loss: 0.1092, G loss: 3.5103\n",
      "[324/1762] D loss: 1.4045, G loss: 0.6912\n",
      "[404/1762] D loss: 1.3907, G loss: 0.7178\n",
      "[484/1762] D loss: 1.4101, G loss: 0.6201\n",
      "[564/1762] D loss: 0.0924, G loss: 3.7357\n",
      "[644/1762] D loss: 1.4127, G loss: 0.6578\n",
      "[724/1762] D loss: 0.0256, G loss: 6.4052\n",
      "[804/1762] D loss: 1.3949, G loss: 0.6898\n",
      "[884/1762] D loss: 1.3556, G loss: 0.7501\n",
      "[964/1762] D loss: 1.4314, G loss: 0.6192\n",
      "[1044/1762] D loss: 1.3801, G loss: 0.7104\n",
      "[1124/1762] D loss: 1.3909, G loss: 0.6918\n",
      "[1204/1762] D loss: 0.0217, G loss: 4.5574\n",
      "[1284/1762] D loss: 1.3888, G loss: 0.7287\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.7199\n",
      "[1444/1762] D loss: 0.0219, G loss: 4.6308\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6905\n",
      "[1604/1762] D loss: 1.3957, G loss: 0.6576\n",
      "[1684/1762] D loss: 0.0078, G loss: 6.6635\n",
      "[1762/1762] D loss: 1.4065, G loss: 0.7738\n",
      "train error: \n",
      " D loss: 2.367269, G loss: 0.560671, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.456825, G loss: 0.666184, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0743, G loss: 4.8726\n",
      "[84/1762] D loss: 1.0369, G loss: 1.4470\n",
      "[164/1762] D loss: 1.3861, G loss: 0.6966\n",
      "[244/1762] D loss: 0.0060, G loss: 6.5206\n",
      "[324/1762] D loss: 1.3787, G loss: 0.7264\n",
      "[404/1762] D loss: 1.3817, G loss: 0.7429\n",
      "[484/1762] D loss: 1.4726, G loss: 0.7357\n",
      "[564/1762] D loss: 0.0023, G loss: 7.9380\n",
      "[644/1762] D loss: 1.1134, G loss: 1.1970\n",
      "[724/1762] D loss: 1.3774, G loss: 0.7018\n",
      "[804/1762] D loss: 1.3862, G loss: 0.7075\n",
      "[884/1762] D loss: 1.3861, G loss: 0.7117\n",
      "[964/1762] D loss: 1.4873, G loss: 0.7148\n",
      "[1044/1762] D loss: 0.0339, G loss: 4.3519\n",
      "[1124/1762] D loss: 0.0574, G loss: 3.8632\n",
      "[1204/1762] D loss: 0.0392, G loss: 3.7877\n",
      "[1284/1762] D loss: 1.3942, G loss: 0.6576\n",
      "[1364/1762] D loss: 1.3857, G loss: 0.7503\n",
      "[1444/1762] D loss: 1.3345, G loss: 1.0399\n",
      "[1524/1762] D loss: 1.4003, G loss: 0.6675\n",
      "[1604/1762] D loss: 1.3741, G loss: 0.7295\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7259\n",
      "[1762/1762] D loss: 0.0030, G loss: 7.6779\n",
      "train error: \n",
      " D loss: 2.613266, G loss: 0.317261, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.671169, G loss: 0.396190, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6846\n",
      "[84/1762] D loss: 1.3792, G loss: 0.7023\n",
      "[164/1762] D loss: 1.4192, G loss: 0.6601\n",
      "[244/1762] D loss: 0.0338, G loss: 4.5763\n",
      "[324/1762] D loss: 0.0190, G loss: 5.6635\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6862\n",
      "[484/1762] D loss: 1.3835, G loss: 0.6360\n",
      "[564/1762] D loss: 0.0310, G loss: 4.3618\n",
      "[644/1762] D loss: 1.3892, G loss: 0.7010\n",
      "[724/1762] D loss: 1.4371, G loss: 0.7076\n",
      "[804/1762] D loss: 1.3832, G loss: 0.6888\n",
      "[884/1762] D loss: 0.0446, G loss: 3.9777\n",
      "[964/1762] D loss: 0.0478, G loss: 3.8569\n",
      "[1044/1762] D loss: 0.0268, G loss: 4.6452\n",
      "[1124/1762] D loss: 1.3156, G loss: 0.7717\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.7576\n",
      "[1284/1762] D loss: 1.4107, G loss: 0.7628\n",
      "[1364/1762] D loss: 1.3794, G loss: 0.7060\n",
      "[1444/1762] D loss: 0.0126, G loss: 5.3735\n",
      "[1524/1762] D loss: 1.3325, G loss: 0.8051\n",
      "[1604/1762] D loss: 1.3931, G loss: 0.6916\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.7070\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.6305\n",
      "train error: \n",
      " D loss: 3.020877, G loss: 0.675556, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.400986, G loss: 0.798062, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.6263\n",
      "[84/1762] D loss: 1.3775, G loss: 0.6943\n",
      "[164/1762] D loss: 0.0407, G loss: 4.1793\n",
      "[244/1762] D loss: 1.3782, G loss: 0.6476\n",
      "[324/1762] D loss: 1.4553, G loss: 0.6169\n",
      "[404/1762] D loss: 1.3807, G loss: 0.7719\n",
      "[484/1762] D loss: 1.3943, G loss: 0.7101\n",
      "[564/1762] D loss: 1.3816, G loss: 0.7206\n",
      "[644/1762] D loss: 0.0074, G loss: 6.3370\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6613\n",
      "[804/1762] D loss: 1.3906, G loss: 0.7240\n",
      "[884/1762] D loss: 0.0188, G loss: 4.8131\n",
      "[964/1762] D loss: 1.3736, G loss: 0.7241\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7189\n",
      "[1124/1762] D loss: 1.4095, G loss: 0.5558\n",
      "[1204/1762] D loss: 0.0126, G loss: 5.9366\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.7318\n",
      "[1364/1762] D loss: 1.3929, G loss: 0.7420\n",
      "[1444/1762] D loss: 1.3803, G loss: 0.6701\n",
      "[1524/1762] D loss: 1.4336, G loss: 0.7309\n",
      "[1604/1762] D loss: 1.4159, G loss: 0.6592\n",
      "[1684/1762] D loss: 0.0052, G loss: 8.3494\n",
      "[1762/1762] D loss: 1.3991, G loss: 0.7865\n",
      "train error: \n",
      " D loss: 2.892473, G loss: 0.547782, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.038516, G loss: 0.691590, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0765, G loss: 4.2851\n",
      "[84/1762] D loss: 0.0321, G loss: 4.1656\n",
      "[164/1762] D loss: 1.3891, G loss: 0.7246\n",
      "[244/1762] D loss: 0.0143, G loss: 5.5596\n",
      "[324/1762] D loss: 1.4834, G loss: 0.4630\n",
      "[404/1762] D loss: 1.3880, G loss: 0.7407\n",
      "[484/1762] D loss: 1.3851, G loss: 0.6894\n",
      "[564/1762] D loss: 1.3878, G loss: 0.6793\n",
      "[644/1762] D loss: 1.3827, G loss: 0.6717\n",
      "[724/1762] D loss: 1.3897, G loss: 0.6983\n",
      "[804/1762] D loss: 1.3893, G loss: 0.6834\n",
      "[884/1762] D loss: 0.0118, G loss: 5.3697\n",
      "[964/1762] D loss: 1.4399, G loss: 0.6527\n",
      "[1044/1762] D loss: 1.2392, G loss: 1.8917\n",
      "[1124/1762] D loss: 1.4086, G loss: 0.7163\n",
      "[1204/1762] D loss: 1.3783, G loss: 0.7124\n",
      "[1284/1762] D loss: 1.5757, G loss: 0.4985\n",
      "[1364/1762] D loss: 1.3421, G loss: 0.7256\n",
      "[1444/1762] D loss: 1.3732, G loss: 0.7026\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.6464\n",
      "[1604/1762] D loss: 0.0137, G loss: 5.4183\n",
      "[1684/1762] D loss: 0.0057, G loss: 7.0643\n",
      "[1762/1762] D loss: 0.0013, G loss: 13.8180\n",
      "train error: \n",
      " D loss: 3.415874, G loss: 0.303024, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.329690, G loss: 0.410429, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4035, G loss: 0.7054\n",
      "[84/1762] D loss: 1.4196, G loss: 1.0320\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7316\n",
      "[244/1762] D loss: 1.3887, G loss: 0.6630\n",
      "[324/1762] D loss: 1.3773, G loss: 0.6529\n",
      "[404/1762] D loss: 1.3773, G loss: 0.7116\n",
      "[484/1762] D loss: 1.3936, G loss: 0.6354\n",
      "[564/1762] D loss: 1.3822, G loss: 0.6699\n",
      "[644/1762] D loss: 1.3843, G loss: 0.6952\n",
      "[724/1762] D loss: 1.3806, G loss: 0.6707\n",
      "[804/1762] D loss: 0.0115, G loss: 5.4969\n",
      "[884/1762] D loss: 1.3823, G loss: 0.6867\n",
      "[964/1762] D loss: 0.0368, G loss: 4.6854\n",
      "[1044/1762] D loss: 1.3931, G loss: 0.6755\n",
      "[1124/1762] D loss: 1.4684, G loss: 0.2851\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.7226\n",
      "[1284/1762] D loss: 1.3855, G loss: 0.7198\n",
      "[1364/1762] D loss: 1.3953, G loss: 0.6853\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.6454\n",
      "[1524/1762] D loss: 0.0926, G loss: 4.2773\n",
      "[1604/1762] D loss: 1.4026, G loss: 0.6318\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.6400\n",
      "[1762/1762] D loss: 1.4111, G loss: 0.7066\n",
      "train error: \n",
      " D loss: 3.041552, G loss: 0.844151, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 3.373692, G loss: 1.021163, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0323, G loss: 4.8739\n",
      "[84/1762] D loss: 0.0317, G loss: 5.0817\n",
      "[164/1762] D loss: 0.0445, G loss: 4.8656\n",
      "[244/1762] D loss: 0.0505, G loss: 5.4751\n",
      "[324/1762] D loss: 1.3958, G loss: 0.7181\n",
      "[404/1762] D loss: 1.3559, G loss: 0.7372\n",
      "[484/1762] D loss: 0.0294, G loss: 6.1490\n",
      "[564/1762] D loss: 1.3776, G loss: 0.7002\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7243\n",
      "[724/1762] D loss: 1.3764, G loss: 0.7290\n",
      "[804/1762] D loss: 0.0026, G loss: 10.5993\n",
      "[884/1762] D loss: 1.3856, G loss: 0.7290\n",
      "[964/1762] D loss: 1.3984, G loss: 0.6878\n",
      "[1044/1762] D loss: 1.3834, G loss: 0.6574\n",
      "[1124/1762] D loss: 1.3853, G loss: 0.6945\n",
      "[1204/1762] D loss: 1.3848, G loss: 0.6939\n",
      "[1284/1762] D loss: 1.3998, G loss: 0.7050\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.7255\n",
      "[1444/1762] D loss: 1.4039, G loss: 0.6760\n",
      "[1524/1762] D loss: 0.1075, G loss: 5.1189\n",
      "[1604/1762] D loss: 1.3577, G loss: 0.6844\n",
      "[1684/1762] D loss: 1.3782, G loss: 0.6499\n",
      "[1762/1762] D loss: 1.3978, G loss: 0.6185\n",
      "train error: \n",
      " D loss: 3.177454, G loss: 1.098858, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 3.664110, G loss: 1.231298, D accuracy: 49.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3721, G loss: 0.6642\n",
      "[84/1762] D loss: 0.0649, G loss: 4.5771\n",
      "[164/1762] D loss: 0.0073, G loss: 6.0832\n",
      "[244/1762] D loss: 1.3850, G loss: 0.7067\n",
      "[324/1762] D loss: 1.4245, G loss: 0.6088\n",
      "[404/1762] D loss: 1.3902, G loss: 0.6921\n",
      "[484/1762] D loss: 1.3977, G loss: 0.7052\n",
      "[564/1762] D loss: 1.3808, G loss: 0.6658\n",
      "[644/1762] D loss: 1.3807, G loss: 0.7576\n",
      "[724/1762] D loss: 1.3942, G loss: 0.6478\n",
      "[804/1762] D loss: 1.3879, G loss: 0.6208\n",
      "[884/1762] D loss: 1.3185, G loss: 0.7847\n",
      "[964/1762] D loss: 1.3912, G loss: 0.7111\n",
      "[1044/1762] D loss: 0.0101, G loss: 5.7590\n",
      "[1124/1762] D loss: 0.0083, G loss: 6.0668\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6942\n",
      "[1284/1762] D loss: 1.4114, G loss: 0.7205\n",
      "[1364/1762] D loss: 1.4147, G loss: 0.7604\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.7204\n",
      "[1524/1762] D loss: 1.4037, G loss: 0.6688\n",
      "[1604/1762] D loss: 1.4104, G loss: 0.6751\n",
      "[1684/1762] D loss: 1.4058, G loss: 0.6508\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.6011\n",
      "train error: \n",
      " D loss: 2.615857, G loss: 1.034942, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.926629, G loss: 1.225085, D accuracy: 49.3%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4237, G loss: 0.6371\n",
      "[84/1762] D loss: 0.0032, G loss: 10.0482\n",
      "[164/1762] D loss: 0.2481, G loss: 2.6000\n",
      "[244/1762] D loss: 1.4143, G loss: 0.7302\n",
      "[324/1762] D loss: 0.0670, G loss: 4.7428\n",
      "[404/1762] D loss: 1.4093, G loss: 0.6739\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6842\n",
      "[564/1762] D loss: 0.0123, G loss: 4.1579\n",
      "[644/1762] D loss: 1.4104, G loss: 0.8070\n",
      "[724/1762] D loss: 1.3971, G loss: 0.6824\n",
      "[804/1762] D loss: 1.3822, G loss: 0.6990\n",
      "[884/1762] D loss: 1.3839, G loss: 0.6746\n",
      "[964/1762] D loss: 1.3839, G loss: 0.7141\n",
      "[1044/1762] D loss: 0.0065, G loss: 7.0342\n",
      "[1124/1762] D loss: 0.0166, G loss: 5.6217\n",
      "[1204/1762] D loss: 1.3831, G loss: 0.7123\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.7366\n",
      "[1364/1762] D loss: 1.3991, G loss: 0.4881\n",
      "[1444/1762] D loss: 1.4061, G loss: 0.7136\n",
      "[1524/1762] D loss: 1.3827, G loss: 0.7052\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.7154\n",
      "[1684/1762] D loss: 0.0044, G loss: 8.7128\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6802\n",
      "train error: \n",
      " D loss: 2.599591, G loss: 0.850071, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.911402, G loss: 0.965971, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4039, G loss: 0.7028\n",
      "[84/1762] D loss: 1.4179, G loss: 0.5793\n",
      "[164/1762] D loss: 1.4073, G loss: 0.6098\n",
      "[244/1762] D loss: 0.0581, G loss: 3.8836\n",
      "[324/1762] D loss: 1.3690, G loss: 0.6568\n",
      "[404/1762] D loss: 1.3859, G loss: 0.7705\n",
      "[484/1762] D loss: 1.4025, G loss: 0.6343\n",
      "[564/1762] D loss: 0.0649, G loss: 4.2988\n",
      "[644/1762] D loss: 1.3732, G loss: 0.5993\n",
      "[724/1762] D loss: 1.3780, G loss: 0.7324\n",
      "[804/1762] D loss: 1.3923, G loss: 0.6506\n",
      "[884/1762] D loss: 1.4655, G loss: 0.6922\n",
      "[964/1762] D loss: 1.3881, G loss: 0.7014\n",
      "[1044/1762] D loss: 1.3837, G loss: 0.7471\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.6764\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.7486\n",
      "[1284/1762] D loss: 1.3935, G loss: 0.6717\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6553\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6948\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.5474\n",
      "[1604/1762] D loss: 0.0076, G loss: 7.8974\n",
      "[1684/1762] D loss: 1.4400, G loss: 0.5819\n",
      "[1762/1762] D loss: 1.3991, G loss: 0.7327\n",
      "train error: \n",
      " D loss: 2.924895, G loss: 0.458445, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 3.158192, G loss: 0.598578, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#for learning_rate in [1e-3, 1e-4, 1e-5]:\n",
    "for learning_rate in [1e-3]:\n",
    "    run_name = \"adam_lr_\" + f\"{learning_rate:.0e}\".replace(\"-\", \"m\") + \"_beta1_0p5\"\n",
    "    train(run_name=run_name, learning_rate=learning_rate, beta1=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The change to beta1 seems not to make too much difference.\n",
    "\n",
    "Let's keep using Adam as it's supposed to be less sensitive to the exact choice of learning rate than SGD."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove linear layer\n",
    "\n",
    "One GAN hack suggested not having linear layers at the end of the discriminator, or at least not having multiple. Let's try removing one of the linear layers from the top of the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscWithLessLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(160, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6167, G loss: 1.1186\n",
      "[84/1762] D loss: 0.8856, G loss: 1.2471\n",
      "[164/1762] D loss: 0.5144, G loss: 1.5778\n",
      "[244/1762] D loss: 0.2832, G loss: 2.2208\n",
      "[324/1762] D loss: 0.1694, G loss: 2.9587\n",
      "[404/1762] D loss: 0.1285, G loss: 2.7698\n",
      "[484/1762] D loss: 0.1271, G loss: 3.2402\n",
      "[564/1762] D loss: 0.2399, G loss: 1.8456\n",
      "[644/1762] D loss: 0.3772, G loss: 2.6360\n",
      "[724/1762] D loss: 0.5194, G loss: 2.0709\n",
      "[804/1762] D loss: 1.0834, G loss: 1.9496\n",
      "[884/1762] D loss: 0.3965, G loss: 1.4100\n",
      "[964/1762] D loss: 0.7231, G loss: 1.6464\n",
      "[1044/1762] D loss: 0.2092, G loss: 1.9423\n",
      "[1124/1762] D loss: 1.5056, G loss: 2.5327\n",
      "[1204/1762] D loss: 1.4458, G loss: 1.6801\n",
      "[1284/1762] D loss: 0.9211, G loss: 1.3423\n",
      "[1364/1762] D loss: 1.2521, G loss: 0.9912\n",
      "[1444/1762] D loss: 1.1146, G loss: 0.8716\n",
      "[1524/1762] D loss: 1.3431, G loss: 0.6098\n",
      "[1604/1762] D loss: 1.0341, G loss: 1.3978\n",
      "[1684/1762] D loss: 1.5701, G loss: 1.2832\n",
      "[1762/1762] D loss: 1.2502, G loss: 0.7228\n",
      "train error: \n",
      " D loss: 1.345100, G loss: 0.607619, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317069, G loss: 0.651560, D accuracy: 59.1%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3975, G loss: 0.5418\n",
      "[84/1762] D loss: 1.4542, G loss: 0.7930\n",
      "[164/1762] D loss: 1.4648, G loss: 1.0022\n",
      "[244/1762] D loss: 1.3493, G loss: 0.7674\n",
      "[324/1762] D loss: 1.0152, G loss: 1.0243\n",
      "[404/1762] D loss: 1.3117, G loss: 0.7434\n",
      "[484/1762] D loss: 1.1321, G loss: 0.9139\n",
      "[564/1762] D loss: 1.2964, G loss: 0.7194\n",
      "[644/1762] D loss: 1.3591, G loss: 0.7648\n",
      "[724/1762] D loss: 1.4121, G loss: 0.8681\n",
      "[804/1762] D loss: 1.3348, G loss: 0.7735\n",
      "[884/1762] D loss: 0.9728, G loss: 1.0521\n",
      "[964/1762] D loss: 1.4116, G loss: 0.5785\n",
      "[1044/1762] D loss: 1.0087, G loss: 1.1341\n",
      "[1124/1762] D loss: 0.7618, G loss: 1.5833\n",
      "[1204/1762] D loss: 1.0144, G loss: 0.7602\n",
      "[1284/1762] D loss: 1.2153, G loss: 0.7638\n",
      "[1364/1762] D loss: 1.2452, G loss: 0.6576\n",
      "[1444/1762] D loss: 1.4341, G loss: 0.9800\n",
      "[1524/1762] D loss: 1.4433, G loss: 0.8966\n",
      "[1604/1762] D loss: 0.5597, G loss: 1.7386\n",
      "[1684/1762] D loss: 1.4031, G loss: 0.7888\n",
      "[1762/1762] D loss: 1.4167, G loss: 0.5584\n",
      "train error: \n",
      " D loss: 1.309246, G loss: 0.783392, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292120, G loss: 0.801182, D accuracy: 58.1%, cell accuracy: 99.7%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8461, G loss: 0.9963\n",
      "[84/1762] D loss: 0.7944, G loss: 1.3689\n",
      "[164/1762] D loss: 0.7854, G loss: 0.8940\n",
      "[244/1762] D loss: 0.7879, G loss: 1.0659\n",
      "[324/1762] D loss: 1.3653, G loss: 0.7080\n",
      "[404/1762] D loss: 2.1713, G loss: 0.5693\n",
      "[484/1762] D loss: 1.5864, G loss: 1.0233\n",
      "[564/1762] D loss: 1.2768, G loss: 0.7385\n",
      "[644/1762] D loss: 1.2266, G loss: 0.8651\n",
      "[724/1762] D loss: 1.4077, G loss: 0.7798\n",
      "[804/1762] D loss: 1.4204, G loss: 0.6615\n",
      "[884/1762] D loss: 1.3718, G loss: 0.7717\n",
      "[964/1762] D loss: 1.4296, G loss: 0.5491\n",
      "[1044/1762] D loss: 1.6875, G loss: 0.8852\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.6453\n",
      "[1204/1762] D loss: 1.3237, G loss: 0.7618\n",
      "[1284/1762] D loss: 1.3338, G loss: 0.5839\n",
      "[1364/1762] D loss: 1.1321, G loss: 0.8938\n",
      "[1444/1762] D loss: 1.3965, G loss: 0.7354\n",
      "[1524/1762] D loss: 1.3942, G loss: 0.7627\n",
      "[1604/1762] D loss: 0.9100, G loss: 0.8880\n",
      "[1684/1762] D loss: 1.4372, G loss: 0.5807\n",
      "[1762/1762] D loss: 1.5759, G loss: 1.0103\n",
      "train error: \n",
      " D loss: 1.327990, G loss: 0.801427, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319586, G loss: 0.806847, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4150, G loss: 0.6917\n",
      "[84/1762] D loss: 1.2881, G loss: 0.9085\n",
      "[164/1762] D loss: 1.2686, G loss: 1.0453\n",
      "[244/1762] D loss: 1.5830, G loss: 0.4513\n",
      "[324/1762] D loss: 0.9688, G loss: 2.2472\n",
      "[404/1762] D loss: 0.4274, G loss: 1.5632\n",
      "[484/1762] D loss: 1.0098, G loss: 1.2353\n",
      "[564/1762] D loss: 0.6623, G loss: 1.7186\n",
      "[644/1762] D loss: 0.5819, G loss: 1.7003\n",
      "[724/1762] D loss: 1.4929, G loss: 0.7699\n",
      "[804/1762] D loss: 1.2883, G loss: 0.7144\n",
      "[884/1762] D loss: 1.2157, G loss: 1.2137\n",
      "[964/1762] D loss: 1.4455, G loss: 0.6179\n",
      "[1044/1762] D loss: 0.9619, G loss: 0.8652\n",
      "[1124/1762] D loss: 0.6083, G loss: 1.2959\n",
      "[1204/1762] D loss: 1.4947, G loss: 0.9732\n",
      "[1284/1762] D loss: 1.4481, G loss: 0.5649\n",
      "[1364/1762] D loss: 0.7355, G loss: 1.0444\n",
      "[1444/1762] D loss: 1.4016, G loss: 0.6019\n",
      "[1524/1762] D loss: 1.4060, G loss: 0.7511\n",
      "[1604/1762] D loss: 1.4227, G loss: 0.6259\n",
      "[1684/1762] D loss: 0.4294, G loss: 1.6138\n",
      "[1762/1762] D loss: 1.4073, G loss: 0.7834\n",
      "train error: \n",
      " D loss: 1.356301, G loss: 0.603812, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342523, G loss: 0.611506, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3610, G loss: 0.6251\n",
      "[84/1762] D loss: 1.2729, G loss: 0.8121\n",
      "[164/1762] D loss: 0.9311, G loss: 1.1458\n",
      "[244/1762] D loss: 1.4820, G loss: 0.5200\n",
      "[324/1762] D loss: 1.3760, G loss: 0.7090\n",
      "[404/1762] D loss: 1.4446, G loss: 0.9328\n",
      "[484/1762] D loss: 1.5389, G loss: 1.0643\n",
      "[564/1762] D loss: 1.4083, G loss: 0.6460\n",
      "[644/1762] D loss: 1.4576, G loss: 0.4079\n",
      "[724/1762] D loss: 1.3969, G loss: 0.8772\n",
      "[804/1762] D loss: 0.5350, G loss: 1.2035\n",
      "[884/1762] D loss: 1.3971, G loss: 0.5968\n",
      "[964/1762] D loss: 0.4700, G loss: 1.3158\n",
      "[1044/1762] D loss: 0.5343, G loss: 1.1047\n",
      "[1124/1762] D loss: 1.5400, G loss: 0.5000\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.7917\n",
      "[1284/1762] D loss: 1.3404, G loss: 0.7426\n",
      "[1364/1762] D loss: 1.7037, G loss: 0.3478\n",
      "[1444/1762] D loss: 1.5208, G loss: 0.4970\n",
      "[1524/1762] D loss: 1.5345, G loss: 1.2068\n",
      "[1604/1762] D loss: 0.4122, G loss: 1.4022\n",
      "[1684/1762] D loss: 1.1378, G loss: 1.3086\n",
      "[1762/1762] D loss: 1.5555, G loss: 1.1607\n",
      "train error: \n",
      " D loss: 1.381988, G loss: 0.955680, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373381, G loss: 0.963155, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4778, G loss: 0.9581\n",
      "[84/1762] D loss: 1.3907, G loss: 0.6619\n",
      "[164/1762] D loss: 1.4910, G loss: 0.9871\n",
      "[244/1762] D loss: 1.4100, G loss: 0.7956\n",
      "[324/1762] D loss: 1.4309, G loss: 0.8065\n",
      "[404/1762] D loss: 1.4336, G loss: 0.4891\n",
      "[484/1762] D loss: 1.4123, G loss: 0.8765\n",
      "[564/1762] D loss: 1.4287, G loss: 0.8840\n",
      "[644/1762] D loss: 1.4888, G loss: 1.5067\n",
      "[724/1762] D loss: 1.3921, G loss: 0.6720\n",
      "[804/1762] D loss: 0.5737, G loss: 1.0929\n",
      "[884/1762] D loss: 1.4434, G loss: 0.6825\n",
      "[964/1762] D loss: 0.4049, G loss: 1.2393\n",
      "[1044/1762] D loss: 1.4264, G loss: 0.5529\n",
      "[1124/1762] D loss: 0.3687, G loss: 1.4245\n",
      "[1204/1762] D loss: 0.6340, G loss: 0.8425\n",
      "[1284/1762] D loss: 0.2760, G loss: 1.7280\n",
      "[1364/1762] D loss: 1.4107, G loss: 0.9331\n",
      "[1444/1762] D loss: 1.3694, G loss: 0.7724\n",
      "[1524/1762] D loss: 1.4724, G loss: 0.6795\n",
      "[1604/1762] D loss: 1.4545, G loss: 1.0090\n",
      "[1684/1762] D loss: 0.1055, G loss: 3.0744\n",
      "[1762/1762] D loss: 1.4334, G loss: 1.1691\n",
      "train error: \n",
      " D loss: 1.380586, G loss: 1.137857, D accuracy: 53.0%, cell accuracy: 99.6%, board accuracy: 65.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370027, G loss: 1.158552, D accuracy: 53.8%, cell accuracy: 99.5%, board accuracy: 61.4% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3683, G loss: 0.7818\n",
      "[84/1762] D loss: 0.4731, G loss: 1.2209\n",
      "[164/1762] D loss: 1.3574, G loss: 0.8581\n",
      "[244/1762] D loss: 1.5342, G loss: 1.0486\n",
      "[324/1762] D loss: 1.4000, G loss: 0.7894\n",
      "[404/1762] D loss: 1.6550, G loss: 1.1561\n",
      "[484/1762] D loss: 1.4123, G loss: 1.0703\n",
      "[564/1762] D loss: 0.4549, G loss: 1.2902\n",
      "[644/1762] D loss: 1.4211, G loss: 0.7816\n",
      "[724/1762] D loss: 1.3980, G loss: 0.6939\n",
      "[804/1762] D loss: 1.4395, G loss: 0.8521\n",
      "[884/1762] D loss: 0.3698, G loss: 1.3036\n",
      "[964/1762] D loss: 1.3935, G loss: 0.6640\n",
      "[1044/1762] D loss: 0.3532, G loss: 1.3616\n",
      "[1124/1762] D loss: 1.5762, G loss: 0.3657\n",
      "[1204/1762] D loss: 1.4615, G loss: 0.6725\n",
      "[1284/1762] D loss: 1.4115, G loss: 0.7290\n",
      "[1364/1762] D loss: 0.3086, G loss: 1.6225\n",
      "[1444/1762] D loss: 1.3840, G loss: 0.6793\n",
      "[1524/1762] D loss: 1.4067, G loss: 0.6656\n",
      "[1604/1762] D loss: 1.4076, G loss: 0.7968\n",
      "[1684/1762] D loss: 1.4378, G loss: 0.6293\n",
      "[1762/1762] D loss: 1.6130, G loss: 0.4104\n",
      "train error: \n",
      " D loss: 1.459066, G loss: 0.458408, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.452818, G loss: 0.469706, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6687, G loss: 0.7731\n",
      "[84/1762] D loss: 1.1060, G loss: 0.8573\n",
      "[164/1762] D loss: 1.3879, G loss: 0.6736\n",
      "[244/1762] D loss: 1.4918, G loss: 1.0533\n",
      "[324/1762] D loss: 0.1858, G loss: 1.9956\n",
      "[404/1762] D loss: 0.2935, G loss: 1.7995\n",
      "[484/1762] D loss: 1.5289, G loss: 1.0824\n",
      "[564/1762] D loss: 1.4587, G loss: 1.0335\n",
      "[644/1762] D loss: 1.5962, G loss: 1.1793\n",
      "[724/1762] D loss: 3.2784, G loss: 0.3122\n",
      "[804/1762] D loss: 0.5999, G loss: 1.4770\n",
      "[884/1762] D loss: 1.3970, G loss: 0.7165\n",
      "[964/1762] D loss: 1.1605, G loss: 0.9866\n",
      "[1044/1762] D loss: 0.7284, G loss: 1.2549\n",
      "[1124/1762] D loss: 0.8556, G loss: 0.9144\n",
      "[1204/1762] D loss: 1.4234, G loss: 0.6669\n",
      "[1284/1762] D loss: 1.3485, G loss: 1.2046\n",
      "[1364/1762] D loss: 1.4049, G loss: 0.7022\n",
      "[1444/1762] D loss: 1.3981, G loss: 0.8407\n",
      "[1524/1762] D loss: 1.4347, G loss: 0.9682\n",
      "[1604/1762] D loss: 0.4466, G loss: 1.2214\n",
      "[1684/1762] D loss: 1.4568, G loss: 0.8208\n",
      "[1762/1762] D loss: 1.5281, G loss: 0.4702\n",
      "train error: \n",
      " D loss: 1.389050, G loss: 0.854271, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404250, G loss: 0.864180, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3989, G loss: 0.6842\n",
      "[84/1762] D loss: 1.3769, G loss: 0.7013\n",
      "[164/1762] D loss: 1.4030, G loss: 0.8234\n",
      "[244/1762] D loss: 1.4206, G loss: 0.9225\n",
      "[324/1762] D loss: 1.3907, G loss: 0.8952\n",
      "[404/1762] D loss: 1.4103, G loss: 0.7027\n",
      "[484/1762] D loss: 1.5042, G loss: 1.0292\n",
      "[564/1762] D loss: 1.4840, G loss: 0.4749\n",
      "[644/1762] D loss: 1.2292, G loss: 1.2496\n",
      "[724/1762] D loss: 0.7204, G loss: 1.0405\n",
      "[804/1762] D loss: 1.2896, G loss: 0.7926\n",
      "[884/1762] D loss: 1.3947, G loss: 0.5917\n",
      "[964/1762] D loss: 0.5419, G loss: 1.2258\n",
      "[1044/1762] D loss: 1.4046, G loss: 0.9484\n",
      "[1124/1762] D loss: 0.3569, G loss: 1.3218\n",
      "[1204/1762] D loss: 1.4092, G loss: 0.6105\n",
      "[1284/1762] D loss: 0.5219, G loss: 1.0284\n",
      "[1364/1762] D loss: 1.4075, G loss: 0.6269\n",
      "[1444/1762] D loss: 1.4220, G loss: 0.8136\n",
      "[1524/1762] D loss: 1.4029, G loss: 0.6615\n",
      "[1604/1762] D loss: 1.4135, G loss: 0.7822\n",
      "[1684/1762] D loss: 1.4262, G loss: 0.8554\n",
      "[1762/1762] D loss: 1.4489, G loss: 0.8298\n",
      "train error: \n",
      " D loss: 1.410455, G loss: 0.583168, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404379, G loss: 0.606371, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3945, G loss: 1.2757\n",
      "[84/1762] D loss: 1.7047, G loss: 1.3861\n",
      "[164/1762] D loss: 0.1728, G loss: 2.3305\n",
      "[244/1762] D loss: 0.3604, G loss: 1.4280\n",
      "[324/1762] D loss: 1.4229, G loss: 0.8602\n",
      "[404/1762] D loss: 1.3937, G loss: 0.7435\n",
      "[484/1762] D loss: 1.4731, G loss: 0.9966\n",
      "[564/1762] D loss: 0.2159, G loss: 1.9554\n",
      "[644/1762] D loss: 1.4192, G loss: 0.7978\n",
      "[724/1762] D loss: 1.5138, G loss: 0.9634\n",
      "[804/1762] D loss: 1.4085, G loss: 0.7036\n",
      "[884/1762] D loss: 0.1496, G loss: 2.5999\n",
      "[964/1762] D loss: 1.4386, G loss: 0.9304\n",
      "[1044/1762] D loss: 1.4960, G loss: 1.0505\n",
      "[1124/1762] D loss: 1.4527, G loss: 1.0467\n",
      "[1204/1762] D loss: 1.4457, G loss: 0.9874\n",
      "[1284/1762] D loss: 1.4224, G loss: 0.6995\n",
      "[1364/1762] D loss: 1.6866, G loss: 1.2098\n",
      "[1444/1762] D loss: 1.4233, G loss: 0.7351\n",
      "[1524/1762] D loss: 1.3715, G loss: 0.8844\n",
      "[1604/1762] D loss: 1.3975, G loss: 0.7499\n",
      "[1684/1762] D loss: 1.4081, G loss: 0.7230\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6395\n",
      "train error: \n",
      " D loss: 1.324427, G loss: 0.707260, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322524, G loss: 0.711218, D accuracy: 57.5%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4006, G loss: 0.5274\n",
      "[84/1762] D loss: 1.4481, G loss: 0.4959\n",
      "[164/1762] D loss: 1.4119, G loss: 0.8036\n",
      "[244/1762] D loss: 1.3491, G loss: 0.5091\n",
      "[324/1762] D loss: 0.3324, G loss: 1.4914\n",
      "[404/1762] D loss: 1.5086, G loss: 1.8494\n",
      "[484/1762] D loss: 1.4810, G loss: 0.9469\n",
      "[564/1762] D loss: 1.3742, G loss: 0.8657\n",
      "[644/1762] D loss: 1.4228, G loss: 0.8121\n",
      "[724/1762] D loss: 1.3906, G loss: 0.8102\n",
      "[804/1762] D loss: 1.4246, G loss: 0.9172\n",
      "[884/1762] D loss: 1.5125, G loss: 1.1499\n",
      "[964/1762] D loss: 1.6153, G loss: 1.2474\n",
      "[1044/1762] D loss: 1.4213, G loss: 0.7783\n",
      "[1124/1762] D loss: 1.4081, G loss: 0.6074\n",
      "[1204/1762] D loss: 1.4404, G loss: 0.5524\n",
      "[1284/1762] D loss: 1.4463, G loss: 0.7528\n",
      "[1364/1762] D loss: 1.3659, G loss: 0.5191\n",
      "[1444/1762] D loss: 0.4326, G loss: 1.2008\n",
      "[1524/1762] D loss: 1.4828, G loss: 0.4901\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7375\n",
      "[1684/1762] D loss: 0.2355, G loss: 1.8511\n",
      "[1762/1762] D loss: 0.0113, G loss: 4.7573\n",
      "train error: \n",
      " D loss: 1.875540, G loss: 0.227648, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.856000, G loss: 0.234916, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3766, G loss: 1.3190\n",
      "[84/1762] D loss: 1.4719, G loss: 0.9697\n",
      "[164/1762] D loss: 1.4594, G loss: 0.9820\n",
      "[244/1762] D loss: 1.4236, G loss: 0.5982\n",
      "[324/1762] D loss: 1.4178, G loss: 0.8381\n",
      "[404/1762] D loss: 0.4239, G loss: 1.2798\n",
      "[484/1762] D loss: 1.4207, G loss: 0.8946\n",
      "[564/1762] D loss: 1.4425, G loss: 0.9064\n",
      "[644/1762] D loss: 1.4056, G loss: 0.6190\n",
      "[724/1762] D loss: 1.5181, G loss: 1.0587\n",
      "[804/1762] D loss: 1.4070, G loss: 0.7236\n",
      "[884/1762] D loss: 1.4033, G loss: 0.6569\n",
      "[964/1762] D loss: 1.4090, G loss: 0.7507\n",
      "[1044/1762] D loss: 0.4779, G loss: 1.2310\n",
      "[1124/1762] D loss: 1.5497, G loss: 0.8479\n",
      "[1204/1762] D loss: 1.2811, G loss: 0.8073\n",
      "[1284/1762] D loss: 0.5363, G loss: 1.0531\n",
      "[1364/1762] D loss: 1.3960, G loss: 0.7494\n",
      "[1444/1762] D loss: 0.6453, G loss: 0.9467\n",
      "[1524/1762] D loss: 1.4238, G loss: 0.8969\n",
      "[1604/1762] D loss: 1.4617, G loss: 0.9249\n",
      "[1684/1762] D loss: 1.5573, G loss: 0.9994\n",
      "[1762/1762] D loss: 0.1238, G loss: 2.3396\n",
      "train error: \n",
      " D loss: 1.550229, G loss: 0.373130, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.532177, G loss: 0.390128, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3982, G loss: 0.6824\n",
      "[84/1762] D loss: 0.3792, G loss: 1.6092\n",
      "[164/1762] D loss: 1.4290, G loss: 0.9430\n",
      "[244/1762] D loss: 1.4829, G loss: 0.4433\n",
      "[324/1762] D loss: 1.4511, G loss: 0.7715\n",
      "[404/1762] D loss: 1.4942, G loss: 1.0530\n",
      "[484/1762] D loss: 1.4729, G loss: 1.0040\n",
      "[564/1762] D loss: 1.4325, G loss: 0.6835\n",
      "[644/1762] D loss: 1.2419, G loss: 1.4555\n",
      "[724/1762] D loss: 1.4579, G loss: 1.6578\n",
      "[804/1762] D loss: 1.3989, G loss: 0.6705\n",
      "[884/1762] D loss: 1.3939, G loss: 0.6877\n",
      "[964/1762] D loss: 1.4562, G loss: 0.4831\n",
      "[1044/1762] D loss: 1.4288, G loss: 0.8895\n",
      "[1124/1762] D loss: 1.4474, G loss: 0.7943\n",
      "[1204/1762] D loss: 1.1231, G loss: 1.1808\n",
      "[1284/1762] D loss: 1.4490, G loss: 0.8916\n",
      "[1364/1762] D loss: 1.6007, G loss: 1.9859\n",
      "[1444/1762] D loss: 0.0923, G loss: 2.9584\n",
      "[1524/1762] D loss: 1.4059, G loss: 0.8352\n",
      "[1604/1762] D loss: 1.4250, G loss: 0.7604\n",
      "[1684/1762] D loss: 0.3957, G loss: 1.2799\n",
      "[1762/1762] D loss: 1.4502, G loss: 0.4767\n",
      "train error: \n",
      " D loss: 1.420004, G loss: 0.516359, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.415857, G loss: 0.529344, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3934, G loss: 0.6423\n",
      "[84/1762] D loss: 1.3897, G loss: 0.6245\n",
      "[164/1762] D loss: 1.4249, G loss: 0.8897\n",
      "[244/1762] D loss: 1.4785, G loss: 0.9640\n",
      "[324/1762] D loss: 0.3344, G loss: 1.6119\n",
      "[404/1762] D loss: 1.3886, G loss: 0.8335\n",
      "[484/1762] D loss: 1.4104, G loss: 0.5391\n",
      "[564/1762] D loss: 1.3189, G loss: 0.8758\n",
      "[644/1762] D loss: 0.3791, G loss: 1.2443\n",
      "[724/1762] D loss: 1.3991, G loss: 0.8575\n",
      "[804/1762] D loss: 1.4439, G loss: 0.9939\n",
      "[884/1762] D loss: 1.4153, G loss: 0.8962\n",
      "[964/1762] D loss: 0.3043, G loss: 1.5045\n",
      "[1044/1762] D loss: 1.4941, G loss: 0.5503\n",
      "[1124/1762] D loss: 1.4158, G loss: 0.6037\n",
      "[1204/1762] D loss: 0.3047, G loss: 1.5733\n",
      "[1284/1762] D loss: 0.2973, G loss: 1.9133\n",
      "[1364/1762] D loss: 1.4270, G loss: 0.5888\n",
      "[1444/1762] D loss: 0.3059, G loss: 1.6022\n",
      "[1524/1762] D loss: 1.4181, G loss: 0.8409\n",
      "[1604/1762] D loss: 0.4555, G loss: 1.1928\n",
      "[1684/1762] D loss: 0.1777, G loss: 1.9871\n",
      "[1762/1762] D loss: 1.5341, G loss: 1.0660\n",
      "train error: \n",
      " D loss: 1.391640, G loss: 0.760828, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410592, G loss: 0.779876, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5263, G loss: 0.9864\n",
      "[84/1762] D loss: 1.4301, G loss: 0.7791\n",
      "[164/1762] D loss: 1.4295, G loss: 0.5907\n",
      "[244/1762] D loss: 1.4344, G loss: 0.9096\n",
      "[324/1762] D loss: 1.4319, G loss: 0.6280\n",
      "[404/1762] D loss: 0.3442, G loss: 1.4481\n",
      "[484/1762] D loss: 0.2672, G loss: 1.5945\n",
      "[564/1762] D loss: 1.3914, G loss: 0.6894\n",
      "[644/1762] D loss: 1.4518, G loss: 0.9281\n",
      "[724/1762] D loss: 1.3886, G loss: 0.7641\n",
      "[804/1762] D loss: 0.2047, G loss: 2.0120\n",
      "[884/1762] D loss: 1.4091, G loss: 0.6625\n",
      "[964/1762] D loss: 1.2725, G loss: 1.3571\n",
      "[1044/1762] D loss: 0.4840, G loss: 1.2786\n",
      "[1124/1762] D loss: 1.1100, G loss: 1.2463\n",
      "[1204/1762] D loss: 1.4042, G loss: 0.6463\n",
      "[1284/1762] D loss: 1.3949, G loss: 0.7255\n",
      "[1364/1762] D loss: 1.4552, G loss: 0.8909\n",
      "[1444/1762] D loss: 1.4921, G loss: 1.1068\n",
      "[1524/1762] D loss: 1.4031, G loss: 0.7951\n",
      "[1604/1762] D loss: 0.5405, G loss: 0.9382\n",
      "[1684/1762] D loss: 1.4423, G loss: 0.5019\n",
      "[1762/1762] D loss: 0.3737, G loss: 1.4688\n",
      "train error: \n",
      " D loss: 1.733678, G loss: 0.292143, D accuracy: 52.6%, cell accuracy: 99.4%, board accuracy: 63.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.741227, G loss: 0.286619, D accuracy: 52.3%, cell accuracy: 99.3%, board accuracy: 61.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2762, G loss: 0.7598\n",
      "[84/1762] D loss: 0.5104, G loss: 1.2090\n",
      "[164/1762] D loss: 1.4264, G loss: 0.9393\n",
      "[244/1762] D loss: 1.4339, G loss: 0.8011\n",
      "[324/1762] D loss: 1.4896, G loss: 0.9021\n",
      "[404/1762] D loss: 1.3957, G loss: 0.6689\n",
      "[484/1762] D loss: 0.3616, G loss: 1.3754\n",
      "[564/1762] D loss: 0.1625, G loss: 2.0579\n",
      "[644/1762] D loss: 0.3696, G loss: 1.5353\n",
      "[724/1762] D loss: 0.3796, G loss: 1.3908\n",
      "[804/1762] D loss: 0.3170, G loss: 1.5249\n",
      "[884/1762] D loss: 1.3964, G loss: 0.6597\n",
      "[964/1762] D loss: 1.4045, G loss: 0.7911\n",
      "[1044/1762] D loss: 1.3109, G loss: 0.8750\n",
      "[1124/1762] D loss: 1.4311, G loss: 0.5149\n",
      "[1204/1762] D loss: 1.5169, G loss: 0.9939\n",
      "[1284/1762] D loss: 0.2002, G loss: 1.7814\n",
      "[1364/1762] D loss: 1.4580, G loss: 0.8051\n",
      "[1444/1762] D loss: 0.2370, G loss: 1.7387\n",
      "[1524/1762] D loss: 0.0763, G loss: 2.8514\n",
      "[1604/1762] D loss: 1.5269, G loss: 1.0960\n",
      "[1684/1762] D loss: 1.4421, G loss: 0.8714\n",
      "[1762/1762] D loss: 1.4722, G loss: 0.9651\n",
      "train error: \n",
      " D loss: 1.393040, G loss: 0.865614, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 83.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403686, G loss: 0.887111, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4938, G loss: 1.0024\n",
      "[84/1762] D loss: 0.3238, G loss: 1.6472\n",
      "[164/1762] D loss: 0.3716, G loss: 1.8925\n",
      "[244/1762] D loss: 1.6413, G loss: 1.2160\n",
      "[324/1762] D loss: 1.4010, G loss: 0.7538\n",
      "[404/1762] D loss: 1.3957, G loss: 0.7526\n",
      "[484/1762] D loss: 0.2478, G loss: 1.7459\n",
      "[564/1762] D loss: 1.4516, G loss: 0.9771\n",
      "[644/1762] D loss: 1.3946, G loss: 0.7373\n",
      "[724/1762] D loss: 1.4461, G loss: 0.9064\n",
      "[804/1762] D loss: 0.3048, G loss: 1.6396\n",
      "[884/1762] D loss: 0.2887, G loss: 1.5546\n",
      "[964/1762] D loss: 1.3914, G loss: 0.8030\n",
      "[1044/1762] D loss: 1.4301, G loss: 0.5591\n",
      "[1124/1762] D loss: 1.4051, G loss: 0.6114\n",
      "[1204/1762] D loss: 1.4314, G loss: 0.5104\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6291\n",
      "[1364/1762] D loss: 1.3977, G loss: 0.6524\n",
      "[1444/1762] D loss: 1.4196, G loss: 0.5703\n",
      "[1524/1762] D loss: 1.4530, G loss: 0.5682\n",
      "[1604/1762] D loss: 1.4403, G loss: 0.9752\n",
      "[1684/1762] D loss: 1.4204, G loss: 0.6109\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6460\n",
      "train error: \n",
      " D loss: 1.429226, G loss: 0.556515, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.438264, G loss: 0.577676, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4336, G loss: 1.1411\n",
      "[84/1762] D loss: 0.8649, G loss: 1.1319\n",
      "[164/1762] D loss: 1.4103, G loss: 0.6209\n",
      "[244/1762] D loss: 1.4048, G loss: 0.5800\n",
      "[324/1762] D loss: 1.4615, G loss: 0.9265\n",
      "[404/1762] D loss: 1.4070, G loss: 0.7439\n",
      "[484/1762] D loss: 1.4054, G loss: 0.7010\n",
      "[564/1762] D loss: 1.3997, G loss: 0.6787\n",
      "[644/1762] D loss: 0.2581, G loss: 1.6270\n",
      "[724/1762] D loss: 0.2835, G loss: 1.5455\n",
      "[804/1762] D loss: 1.4640, G loss: 1.0352\n",
      "[884/1762] D loss: 0.1655, G loss: 2.1748\n",
      "[964/1762] D loss: 1.4572, G loss: 0.9297\n",
      "[1044/1762] D loss: 1.9857, G loss: 1.3747\n",
      "[1124/1762] D loss: 1.4205, G loss: 1.0461\n",
      "[1204/1762] D loss: 1.4042, G loss: 0.8077\n",
      "[1284/1762] D loss: 1.3405, G loss: 0.6762\n",
      "[1364/1762] D loss: 0.3932, G loss: 1.4338\n",
      "[1444/1762] D loss: 0.3776, G loss: 1.1742\n",
      "[1524/1762] D loss: 1.0925, G loss: 1.0497\n",
      "[1604/1762] D loss: 1.4896, G loss: 0.4197\n",
      "[1684/1762] D loss: 0.3114, G loss: 1.4842\n",
      "[1762/1762] D loss: 1.3919, G loss: 0.8565\n",
      "train error: \n",
      " D loss: 1.383514, G loss: 0.587144, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367149, G loss: 0.605099, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7908\n",
      "[84/1762] D loss: 1.4008, G loss: 0.7237\n",
      "[164/1762] D loss: 1.4745, G loss: 0.9722\n",
      "[244/1762] D loss: 1.4792, G loss: 0.8918\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6324\n",
      "[404/1762] D loss: 1.4160, G loss: 0.5254\n",
      "[484/1762] D loss: 1.4066, G loss: 0.6720\n",
      "[564/1762] D loss: 1.4566, G loss: 0.9422\n",
      "[644/1762] D loss: 1.4265, G loss: 0.4998\n",
      "[724/1762] D loss: 1.3985, G loss: 0.7953\n",
      "[804/1762] D loss: 1.3884, G loss: 0.7112\n",
      "[884/1762] D loss: 1.4178, G loss: 0.7482\n",
      "[964/1762] D loss: 1.4545, G loss: 0.9686\n",
      "[1044/1762] D loss: 1.4241, G loss: 0.6044\n",
      "[1124/1762] D loss: 0.3801, G loss: 1.2820\n",
      "[1204/1762] D loss: 0.2214, G loss: 1.8486\n",
      "[1284/1762] D loss: 1.4045, G loss: 0.6164\n",
      "[1364/1762] D loss: 0.2634, G loss: 1.6295\n",
      "[1444/1762] D loss: 1.4638, G loss: 0.5367\n",
      "[1524/1762] D loss: 0.3804, G loss: 1.2453\n",
      "[1604/1762] D loss: 1.0923, G loss: 1.2352\n",
      "[1684/1762] D loss: 1.4040, G loss: 0.6659\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6022\n",
      "train error: \n",
      " D loss: 1.390341, G loss: 0.683269, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403705, G loss: 0.690138, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4073, G loss: 0.6889\n",
      "[84/1762] D loss: 1.3983, G loss: 0.7587\n",
      "[164/1762] D loss: 1.4312, G loss: 0.8674\n",
      "[244/1762] D loss: 1.4108, G loss: 0.8178\n",
      "[324/1762] D loss: 1.4674, G loss: 0.5438\n",
      "[404/1762] D loss: 1.4843, G loss: 0.5213\n",
      "[484/1762] D loss: 0.5027, G loss: 0.9867\n",
      "[564/1762] D loss: 1.4194, G loss: 0.7833\n",
      "[644/1762] D loss: 1.4219, G loss: 0.8395\n",
      "[724/1762] D loss: 1.4160, G loss: 0.8397\n",
      "[804/1762] D loss: 0.1928, G loss: 1.9330\n",
      "[884/1762] D loss: 0.1700, G loss: 2.0141\n",
      "[964/1762] D loss: 1.4491, G loss: 0.9379\n",
      "[1044/1762] D loss: 0.1621, G loss: 2.1392\n",
      "[1124/1762] D loss: 1.4054, G loss: 0.8006\n",
      "[1204/1762] D loss: 1.4260, G loss: 0.8799\n",
      "[1284/1762] D loss: 1.4100, G loss: 0.6500\n",
      "[1364/1762] D loss: 0.5512, G loss: 1.0895\n",
      "[1444/1762] D loss: 0.2641, G loss: 1.7309\n",
      "[1524/1762] D loss: 1.4087, G loss: 0.8484\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.7212\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.7516\n",
      "[1762/1762] D loss: 0.7270, G loss: 2.6932\n",
      "train error: \n",
      " D loss: 1.391325, G loss: 0.650454, D accuracy: 61.5%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409791, G loss: 0.671850, D accuracy: 61.5%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4293, G loss: 0.5292\n",
      "[84/1762] D loss: 1.4187, G loss: 0.5097\n",
      "[164/1762] D loss: 1.4554, G loss: 0.8832\n",
      "[244/1762] D loss: 1.4066, G loss: 0.7413\n",
      "[324/1762] D loss: 1.4135, G loss: 0.5707\n",
      "[404/1762] D loss: 0.4366, G loss: 1.2127\n",
      "[484/1762] D loss: 1.3973, G loss: 0.7570\n",
      "[564/1762] D loss: 1.4135, G loss: 0.8383\n",
      "[644/1762] D loss: 1.5336, G loss: 0.4929\n",
      "[724/1762] D loss: 1.4887, G loss: 0.9434\n",
      "[804/1762] D loss: 1.3940, G loss: 0.7009\n",
      "[884/1762] D loss: 1.4460, G loss: 1.0921\n",
      "[964/1762] D loss: 1.4239, G loss: 0.9964\n",
      "[1044/1762] D loss: 1.7577, G loss: 1.3093\n",
      "[1124/1762] D loss: 1.3204, G loss: 0.9313\n",
      "[1204/1762] D loss: 1.4041, G loss: 0.7774\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.7465\n",
      "[1364/1762] D loss: 1.4192, G loss: 0.7213\n",
      "[1444/1762] D loss: 1.4933, G loss: 0.9225\n",
      "[1524/1762] D loss: 1.3125, G loss: 0.8111\n",
      "[1604/1762] D loss: 0.3552, G loss: 1.3113\n",
      "[1684/1762] D loss: 1.3041, G loss: 0.7774\n",
      "[1762/1762] D loss: 1.4215, G loss: 0.5486\n",
      "train error: \n",
      " D loss: 1.507321, G loss: 0.451937, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.495254, G loss: 0.470364, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3026, G loss: 1.5062\n",
      "[84/1762] D loss: 1.2893, G loss: 1.0066\n",
      "[164/1762] D loss: 0.1065, G loss: 2.4702\n",
      "[244/1762] D loss: 0.2489, G loss: 1.7112\n",
      "[324/1762] D loss: 0.2173, G loss: 1.8935\n",
      "[404/1762] D loss: 1.4021, G loss: 0.9411\n",
      "[484/1762] D loss: 1.4002, G loss: 0.7497\n",
      "[564/1762] D loss: 1.3919, G loss: 0.8915\n",
      "[644/1762] D loss: 1.6900, G loss: 1.2477\n",
      "[724/1762] D loss: 0.2679, G loss: 1.4424\n",
      "[804/1762] D loss: 0.3244, G loss: 1.4491\n",
      "[884/1762] D loss: 0.2171, G loss: 1.8091\n",
      "[964/1762] D loss: 0.1962, G loss: 1.8414\n",
      "[1044/1762] D loss: 1.4062, G loss: 0.7520\n",
      "[1124/1762] D loss: 1.3821, G loss: 0.6231\n",
      "[1204/1762] D loss: 0.3764, G loss: 1.2566\n",
      "[1284/1762] D loss: 0.1855, G loss: 2.4030\n",
      "[1364/1762] D loss: 1.3417, G loss: 1.3943\n",
      "[1444/1762] D loss: 1.4479, G loss: 1.0679\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.6527\n",
      "[1604/1762] D loss: 1.4699, G loss: 0.5092\n",
      "[1684/1762] D loss: 1.4394, G loss: 0.5197\n",
      "[1762/1762] D loss: 1.3990, G loss: 0.6666\n",
      "train error: \n",
      " D loss: 1.448625, G loss: 0.522941, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.446907, G loss: 0.529517, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3993, G loss: 0.6572\n",
      "[84/1762] D loss: 1.3990, G loss: 0.7539\n",
      "[164/1762] D loss: 1.3688, G loss: 0.6407\n",
      "[244/1762] D loss: 1.4010, G loss: 0.7255\n",
      "[324/1762] D loss: 1.4177, G loss: 0.6409\n",
      "[404/1762] D loss: 1.5456, G loss: 0.4229\n",
      "[484/1762] D loss: 1.8214, G loss: 1.3864\n",
      "[564/1762] D loss: 1.4700, G loss: 0.9386\n",
      "[644/1762] D loss: 1.3949, G loss: 0.6693\n",
      "[724/1762] D loss: 1.3986, G loss: 0.7854\n",
      "[804/1762] D loss: 0.2506, G loss: 1.8313\n",
      "[884/1762] D loss: 1.3912, G loss: 0.7785\n",
      "[964/1762] D loss: 1.4263, G loss: 0.8696\n",
      "[1044/1762] D loss: 1.4057, G loss: 0.8861\n",
      "[1124/1762] D loss: 1.4434, G loss: 0.8341\n",
      "[1204/1762] D loss: 1.4206, G loss: 0.5802\n",
      "[1284/1762] D loss: 1.3968, G loss: 0.7328\n",
      "[1364/1762] D loss: 1.4555, G loss: 0.9995\n",
      "[1444/1762] D loss: 1.4456, G loss: 0.8814\n",
      "[1524/1762] D loss: 0.0885, G loss: 2.5021\n",
      "[1604/1762] D loss: 1.4198, G loss: 0.5228\n",
      "[1684/1762] D loss: 0.1989, G loss: 1.8165\n",
      "[1762/1762] D loss: 1.5097, G loss: 0.9916\n",
      "train error: \n",
      " D loss: 1.446810, G loss: 0.494612, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.437518, G loss: 0.511436, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4423, G loss: 0.9108\n",
      "[84/1762] D loss: 1.4054, G loss: 0.7933\n",
      "[164/1762] D loss: 1.4122, G loss: 0.7794\n",
      "[244/1762] D loss: 1.3962, G loss: 0.7135\n",
      "[324/1762] D loss: 1.3977, G loss: 0.7007\n",
      "[404/1762] D loss: 1.4565, G loss: 0.9067\n",
      "[484/1762] D loss: 1.4278, G loss: 0.6049\n",
      "[564/1762] D loss: 1.3983, G loss: 0.7575\n",
      "[644/1762] D loss: 1.3975, G loss: 0.7166\n",
      "[724/1762] D loss: 1.3889, G loss: 0.6265\n",
      "[804/1762] D loss: 1.4533, G loss: 0.4921\n",
      "[884/1762] D loss: 0.2389, G loss: 1.7127\n",
      "[964/1762] D loss: 1.4444, G loss: 0.9142\n",
      "[1044/1762] D loss: 0.3140, G loss: 1.5883\n",
      "[1124/1762] D loss: 1.3418, G loss: 1.0385\n",
      "[1204/1762] D loss: 1.4030, G loss: 0.6398\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.7292\n",
      "[1364/1762] D loss: 1.4360, G loss: 0.7256\n",
      "[1444/1762] D loss: 1.3945, G loss: 0.5094\n",
      "[1524/1762] D loss: 1.3988, G loss: 0.6157\n",
      "[1604/1762] D loss: 0.2102, G loss: 1.8425\n",
      "[1684/1762] D loss: 1.4001, G loss: 0.6627\n",
      "[1762/1762] D loss: 1.4074, G loss: 0.7919\n",
      "train error: \n",
      " D loss: 1.455272, G loss: 0.558040, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.462054, G loss: 0.563535, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.6447\n",
      "[84/1762] D loss: 1.4476, G loss: 0.5211\n",
      "[164/1762] D loss: 1.2159, G loss: 1.8068\n",
      "[244/1762] D loss: 0.3878, G loss: 1.2780\n",
      "[324/1762] D loss: 1.4105, G loss: 0.8474\n",
      "[404/1762] D loss: 1.3989, G loss: 0.8583\n",
      "[484/1762] D loss: 0.2036, G loss: 1.8331\n",
      "[564/1762] D loss: 1.4087, G loss: 0.7411\n",
      "[644/1762] D loss: 1.3987, G loss: 0.6463\n",
      "[724/1762] D loss: 1.4002, G loss: 0.6391\n",
      "[804/1762] D loss: 0.2187, G loss: 1.8155\n",
      "[884/1762] D loss: 0.1757, G loss: 2.2815\n",
      "[964/1762] D loss: 1.4058, G loss: 0.7752\n",
      "[1044/1762] D loss: 0.1939, G loss: 1.8599\n",
      "[1124/1762] D loss: 1.4014, G loss: 0.6791\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.6288\n",
      "[1284/1762] D loss: 1.4132, G loss: 0.5957\n",
      "[1364/1762] D loss: 1.4662, G loss: 0.9811\n",
      "[1444/1762] D loss: 1.3900, G loss: 0.6788\n",
      "[1524/1762] D loss: 0.2192, G loss: 1.7186\n",
      "[1604/1762] D loss: 1.4642, G loss: 0.4409\n",
      "[1684/1762] D loss: 1.4080, G loss: 0.7859\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.7675\n",
      "train error: \n",
      " D loss: 1.470717, G loss: 0.496800, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.472914, G loss: 0.509375, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4061, G loss: 0.8034\n",
      "[84/1762] D loss: 1.4102, G loss: 0.8704\n",
      "[164/1762] D loss: 0.2073, G loss: 1.7937\n",
      "[244/1762] D loss: 0.2900, G loss: 1.5257\n",
      "[324/1762] D loss: 1.3913, G loss: 0.6660\n",
      "[404/1762] D loss: 1.4609, G loss: 0.5474\n",
      "[484/1762] D loss: 1.6272, G loss: 1.2122\n",
      "[564/1762] D loss: 0.2489, G loss: 1.6535\n",
      "[644/1762] D loss: 1.3934, G loss: 0.7089\n",
      "[724/1762] D loss: 1.3961, G loss: 0.6897\n",
      "[804/1762] D loss: 1.4122, G loss: 0.7289\n",
      "[884/1762] D loss: 1.4812, G loss: 0.8465\n",
      "[964/1762] D loss: 1.4706, G loss: 0.9602\n",
      "[1044/1762] D loss: 1.5462, G loss: 2.1168\n",
      "[1124/1762] D loss: 1.4276, G loss: 0.8594\n",
      "[1204/1762] D loss: 1.5362, G loss: 1.0011\n",
      "[1284/1762] D loss: 0.1862, G loss: 1.8683\n",
      "[1364/1762] D loss: 1.3970, G loss: 0.6571\n",
      "[1444/1762] D loss: 1.4599, G loss: 0.4579\n",
      "[1524/1762] D loss: 1.4288, G loss: 0.5068\n",
      "[1604/1762] D loss: 1.3927, G loss: 0.6959\n",
      "[1684/1762] D loss: 1.2946, G loss: 0.7486\n",
      "[1762/1762] D loss: 1.4192, G loss: 0.5524\n",
      "train error: \n",
      " D loss: 2.068818, G loss: 0.173783, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.064940, G loss: 0.178557, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3907, G loss: 0.6725\n",
      "[84/1762] D loss: 0.2669, G loss: 1.6422\n",
      "[164/1762] D loss: 1.4163, G loss: 0.8956\n",
      "[244/1762] D loss: 0.1993, G loss: 1.7776\n",
      "[324/1762] D loss: 1.4762, G loss: 0.9982\n",
      "[404/1762] D loss: 1.4395, G loss: 0.9479\n",
      "[484/1762] D loss: 1.3890, G loss: 0.7274\n",
      "[564/1762] D loss: 0.2011, G loss: 1.6972\n",
      "[644/1762] D loss: 1.3876, G loss: 0.7835\n",
      "[724/1762] D loss: 1.5885, G loss: 1.1563\n",
      "[804/1762] D loss: 1.4233, G loss: 0.7691\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6378\n",
      "[964/1762] D loss: 1.4288, G loss: 0.8025\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6208\n",
      "[1124/1762] D loss: 0.2912, G loss: 1.5312\n",
      "[1204/1762] D loss: 1.4092, G loss: 0.8057\n",
      "[1284/1762] D loss: 1.5098, G loss: 0.9783\n",
      "[1364/1762] D loss: 1.3488, G loss: 0.6800\n",
      "[1444/1762] D loss: 1.4407, G loss: 0.5356\n",
      "[1524/1762] D loss: 1.4147, G loss: 0.5863\n",
      "[1604/1762] D loss: 1.4372, G loss: 0.5757\n",
      "[1684/1762] D loss: 0.2724, G loss: 1.8136\n",
      "[1762/1762] D loss: 1.4067, G loss: 0.6462\n",
      "train error: \n",
      " D loss: 1.423738, G loss: 0.491349, D accuracy: 56.9%, cell accuracy: 99.5%, board accuracy: 75.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404486, G loss: 0.528056, D accuracy: 58.0%, cell accuracy: 99.5%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2254, G loss: 2.4356\n",
      "[84/1762] D loss: 1.3307, G loss: 0.8910\n",
      "[164/1762] D loss: 1.3818, G loss: 0.8053\n",
      "[244/1762] D loss: 1.3999, G loss: 0.6904\n",
      "[324/1762] D loss: 1.3537, G loss: 1.1656\n",
      "[404/1762] D loss: 0.1084, G loss: 2.3457\n",
      "[484/1762] D loss: 0.0640, G loss: 4.0431\n",
      "[564/1762] D loss: 1.4552, G loss: 0.9951\n",
      "[644/1762] D loss: 1.4148, G loss: 0.6154\n",
      "[724/1762] D loss: 1.4113, G loss: 0.5546\n",
      "[804/1762] D loss: 1.4291, G loss: 0.6255\n",
      "[884/1762] D loss: 0.3332, G loss: 1.4780\n",
      "[964/1762] D loss: 1.2831, G loss: 0.8101\n",
      "[1044/1762] D loss: 0.3202, G loss: 1.7190\n",
      "[1124/1762] D loss: 1.4781, G loss: 0.8964\n",
      "[1204/1762] D loss: 1.4035, G loss: 0.6619\n",
      "[1284/1762] D loss: 1.4045, G loss: 0.7656\n",
      "[1364/1762] D loss: 0.3448, G loss: 1.3112\n",
      "[1444/1762] D loss: 0.3345, G loss: 1.3063\n",
      "[1524/1762] D loss: 1.4065, G loss: 0.7256\n",
      "[1604/1762] D loss: 1.4511, G loss: 0.9235\n",
      "[1684/1762] D loss: 0.3863, G loss: 1.2670\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.7235\n",
      "train error: \n",
      " D loss: 1.472694, G loss: 0.488411, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.478526, G loss: 0.496217, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3918, G loss: 0.6984\n",
      "[84/1762] D loss: 0.3294, G loss: 1.3449\n",
      "[164/1762] D loss: 1.4003, G loss: 0.6871\n",
      "[244/1762] D loss: 0.3599, G loss: 1.3655\n",
      "[324/1762] D loss: 1.3682, G loss: 1.1987\n",
      "[404/1762] D loss: 1.4031, G loss: 0.7857\n",
      "[484/1762] D loss: 1.3918, G loss: 0.6515\n",
      "[564/1762] D loss: 0.2786, G loss: 1.8942\n",
      "[644/1762] D loss: 0.1846, G loss: 2.0660\n",
      "[724/1762] D loss: 0.0817, G loss: 2.8635\n",
      "[804/1762] D loss: 1.3950, G loss: 0.8706\n",
      "[884/1762] D loss: 1.3968, G loss: 0.7135\n",
      "[964/1762] D loss: 0.2656, G loss: 1.6307\n",
      "[1044/1762] D loss: 0.2730, G loss: 1.6749\n",
      "[1124/1762] D loss: 0.0716, G loss: 2.6969\n",
      "[1204/1762] D loss: 1.4291, G loss: 0.5778\n",
      "[1284/1762] D loss: 1.3770, G loss: 0.7061\n",
      "[1364/1762] D loss: 1.5176, G loss: 1.0214\n",
      "[1444/1762] D loss: 1.3900, G loss: 0.7267\n",
      "[1524/1762] D loss: 0.1531, G loss: 2.1144\n",
      "[1604/1762] D loss: 1.3936, G loss: 0.6993\n",
      "[1684/1762] D loss: 1.4255, G loss: 0.5552\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6769\n",
      "train error: \n",
      " D loss: 1.715843, G loss: 0.292223, D accuracy: 49.0%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.721882, G loss: 0.297266, D accuracy: 48.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3977, G loss: 0.6963\n",
      "[84/1762] D loss: 1.4402, G loss: 0.9127\n",
      "[164/1762] D loss: 1.3943, G loss: 0.7962\n",
      "[244/1762] D loss: 1.4430, G loss: 0.9652\n",
      "[324/1762] D loss: 1.5204, G loss: 1.0647\n",
      "[404/1762] D loss: 0.1807, G loss: 2.1442\n",
      "[484/1762] D loss: 0.0776, G loss: 3.0266\n",
      "[564/1762] D loss: 1.4203, G loss: 0.7951\n",
      "[644/1762] D loss: 1.4076, G loss: 0.5970\n",
      "[724/1762] D loss: 0.2810, G loss: 1.4541\n",
      "[804/1762] D loss: 1.4027, G loss: 0.5686\n",
      "[884/1762] D loss: 1.4402, G loss: 0.5068\n",
      "[964/1762] D loss: 0.2590, G loss: 1.5475\n",
      "[1044/1762] D loss: 1.4210, G loss: 0.5105\n",
      "[1124/1762] D loss: 0.2916, G loss: 1.3927\n",
      "[1204/1762] D loss: 0.2874, G loss: 1.5899\n",
      "[1284/1762] D loss: 1.4550, G loss: 0.9530\n",
      "[1364/1762] D loss: 1.4137, G loss: 0.7622\n",
      "[1444/1762] D loss: 0.4144, G loss: 1.0952\n",
      "[1524/1762] D loss: 0.1245, G loss: 2.2168\n",
      "[1604/1762] D loss: 1.4024, G loss: 0.6851\n",
      "[1684/1762] D loss: 1.4171, G loss: 0.7906\n",
      "[1762/1762] D loss: 1.3844, G loss: 0.6785\n",
      "train error: \n",
      " D loss: 1.789973, G loss: 0.275893, D accuracy: 49.1%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.789769, G loss: 0.289472, D accuracy: 48.4%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5484, G loss: 0.5881\n",
      "[84/1762] D loss: 0.3271, G loss: 1.5182\n",
      "[164/1762] D loss: 1.3327, G loss: 0.8698\n",
      "[244/1762] D loss: 1.4518, G loss: 0.8786\n",
      "[324/1762] D loss: 0.1872, G loss: 1.7500\n",
      "[404/1762] D loss: 1.4100, G loss: 0.5667\n",
      "[484/1762] D loss: 1.3986, G loss: 0.6276\n",
      "[564/1762] D loss: 1.4098, G loss: 0.8626\n",
      "[644/1762] D loss: 1.4990, G loss: 0.9615\n",
      "[724/1762] D loss: 1.4236, G loss: 0.8321\n",
      "[804/1762] D loss: 1.3978, G loss: 0.5735\n",
      "[884/1762] D loss: 1.3897, G loss: 0.7134\n",
      "[964/1762] D loss: 1.3931, G loss: 0.7429\n",
      "[1044/1762] D loss: 1.3847, G loss: 0.7649\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.6515\n",
      "[1204/1762] D loss: 0.1660, G loss: 1.9631\n",
      "[1284/1762] D loss: 1.3935, G loss: 0.6099\n",
      "[1364/1762] D loss: 0.2213, G loss: 1.7912\n",
      "[1444/1762] D loss: 1.4179, G loss: 0.7518\n",
      "[1524/1762] D loss: 1.4478, G loss: 0.9303\n",
      "[1604/1762] D loss: 1.5147, G loss: 1.0059\n",
      "[1684/1762] D loss: 1.4282, G loss: 0.8159\n",
      "[1762/1762] D loss: 1.3387, G loss: 0.7442\n",
      "train error: \n",
      " D loss: 1.721133, G loss: 0.330163, D accuracy: 51.1%, cell accuracy: 99.5%, board accuracy: 75.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.701611, G loss: 0.370339, D accuracy: 51.0%, cell accuracy: 99.3%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4468, G loss: 0.7310\n",
      "[84/1762] D loss: 1.2613, G loss: 1.0327\n",
      "[164/1762] D loss: 1.4244, G loss: 0.7418\n",
      "[244/1762] D loss: 1.3976, G loss: 0.6979\n",
      "[324/1762] D loss: 1.4050, G loss: 0.7335\n",
      "[404/1762] D loss: 1.3929, G loss: 0.9158\n",
      "[484/1762] D loss: 1.4338, G loss: 0.7807\n",
      "[564/1762] D loss: 1.3997, G loss: 0.6162\n",
      "[644/1762] D loss: 1.3978, G loss: 0.7115\n",
      "[724/1762] D loss: 1.3968, G loss: 0.6445\n",
      "[804/1762] D loss: 1.5543, G loss: 1.1831\n",
      "[884/1762] D loss: 1.9488, G loss: 0.6935\n",
      "[964/1762] D loss: 2.2036, G loss: 0.8557\n",
      "[1044/1762] D loss: 2.1238, G loss: 0.8385\n",
      "[1124/1762] D loss: 1.6679, G loss: 0.3950\n",
      "[1204/1762] D loss: 1.4571, G loss: 0.7606\n",
      "[1284/1762] D loss: 1.3696, G loss: 0.7635\n",
      "[1364/1762] D loss: 1.4040, G loss: 0.8006\n",
      "[1444/1762] D loss: 1.2109, G loss: 0.8865\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.8100\n",
      "[1604/1762] D loss: 1.3982, G loss: 0.7490\n",
      "[1684/1762] D loss: 1.2563, G loss: 1.0077\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6547\n",
      "train error: \n",
      " D loss: 1.324377, G loss: 0.696664, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303906, G loss: 0.712491, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0677, G loss: 0.9078\n",
      "[84/1762] D loss: 1.0019, G loss: 1.1243\n",
      "[164/1762] D loss: 1.3908, G loss: 0.7490\n",
      "[244/1762] D loss: 0.8875, G loss: 1.3011\n",
      "[324/1762] D loss: 1.6304, G loss: 0.6853\n",
      "[404/1762] D loss: 1.4107, G loss: 0.8526\n",
      "[484/1762] D loss: 1.3866, G loss: 0.5596\n",
      "[564/1762] D loss: 1.4875, G loss: 1.0529\n",
      "[644/1762] D loss: 1.3921, G loss: 0.7075\n",
      "[724/1762] D loss: 1.4400, G loss: 0.5449\n",
      "[804/1762] D loss: 1.3949, G loss: 0.7802\n",
      "[884/1762] D loss: 0.5942, G loss: 1.4834\n",
      "[964/1762] D loss: 1.3965, G loss: 0.5905\n",
      "[1044/1762] D loss: 1.3542, G loss: 0.8364\n",
      "[1124/1762] D loss: 1.4060, G loss: 0.6432\n",
      "[1204/1762] D loss: 1.4139, G loss: 0.7697\n",
      "[1284/1762] D loss: 1.4435, G loss: 0.8811\n",
      "[1364/1762] D loss: 1.4194, G loss: 0.7905\n",
      "[1444/1762] D loss: 0.2912, G loss: 1.7797\n",
      "[1524/1762] D loss: 1.4049, G loss: 0.5840\n",
      "[1604/1762] D loss: 0.3776, G loss: 1.3399\n",
      "[1684/1762] D loss: 1.4428, G loss: 0.6748\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.7757\n",
      "train error: \n",
      " D loss: 1.333855, G loss: 0.901304, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316261, G loss: 0.917117, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4191, G loss: 0.8655\n",
      "[84/1762] D loss: 1.4053, G loss: 0.5947\n",
      "[164/1762] D loss: 1.4252, G loss: 0.8307\n",
      "[244/1762] D loss: 1.4465, G loss: 0.7895\n",
      "[324/1762] D loss: 1.4151, G loss: 0.8933\n",
      "[404/1762] D loss: 1.4020, G loss: 0.7319\n",
      "[484/1762] D loss: 1.6562, G loss: 1.2740\n",
      "[564/1762] D loss: 1.6102, G loss: 1.3151\n",
      "[644/1762] D loss: 0.2669, G loss: 1.8706\n",
      "[724/1762] D loss: 1.3886, G loss: 0.6714\n",
      "[804/1762] D loss: 0.2643, G loss: 1.8517\n",
      "[884/1762] D loss: 1.5918, G loss: 1.1077\n",
      "[964/1762] D loss: 1.4169, G loss: 0.8100\n",
      "[1044/1762] D loss: 1.4125, G loss: 0.8147\n",
      "[1124/1762] D loss: 0.2250, G loss: 1.9007\n",
      "[1204/1762] D loss: 0.0770, G loss: 3.2628\n",
      "[1284/1762] D loss: 1.4118, G loss: 0.9120\n",
      "[1364/1762] D loss: 0.0727, G loss: 3.1534\n",
      "[1444/1762] D loss: 1.4880, G loss: 0.9974\n",
      "[1524/1762] D loss: 1.4069, G loss: 0.8034\n",
      "[1604/1762] D loss: 1.4301, G loss: 0.7169\n",
      "[1684/1762] D loss: 1.4117, G loss: 0.5459\n",
      "[1762/1762] D loss: 0.0567, G loss: 3.2823\n",
      "train error: \n",
      " D loss: 1.347589, G loss: 0.641110, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333919, G loss: 0.646769, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3955, G loss: 0.8686\n",
      "[84/1762] D loss: 1.3973, G loss: 0.8225\n",
      "[164/1762] D loss: 0.2335, G loss: 1.9673\n",
      "[244/1762] D loss: 0.2359, G loss: 1.6544\n",
      "[324/1762] D loss: 1.4305, G loss: 0.5008\n",
      "[404/1762] D loss: 1.3521, G loss: 0.7583\n",
      "[484/1762] D loss: 1.4214, G loss: 0.8455\n",
      "[564/1762] D loss: 0.2112, G loss: 2.2102\n",
      "[644/1762] D loss: 1.4095, G loss: 0.8400\n",
      "[724/1762] D loss: 1.4078, G loss: 0.8766\n",
      "[804/1762] D loss: 1.4151, G loss: 0.7722\n",
      "[884/1762] D loss: 0.0039, G loss: 6.4755\n",
      "[964/1762] D loss: 0.1863, G loss: 1.7258\n",
      "[1044/1762] D loss: 0.0446, G loss: 3.2623\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6891\n",
      "[1204/1762] D loss: 1.3994, G loss: 0.7594\n",
      "[1284/1762] D loss: 1.4135, G loss: 0.7989\n",
      "[1364/1762] D loss: 1.4544, G loss: 0.5171\n",
      "[1444/1762] D loss: 1.4114, G loss: 0.8527\n",
      "[1524/1762] D loss: 1.3954, G loss: 0.7202\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.7540\n",
      "[1684/1762] D loss: 0.0029, G loss: 6.1208\n",
      "[1762/1762] D loss: 0.0212, G loss: 3.9946\n",
      "train error: \n",
      " D loss: 1.477349, G loss: 0.425932, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.453255, G loss: 0.445219, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4658, G loss: 0.9495\n",
      "[84/1762] D loss: 1.4198, G loss: 0.5407\n",
      "[164/1762] D loss: 1.3896, G loss: 0.8216\n",
      "[244/1762] D loss: 1.3995, G loss: 0.7660\n",
      "[324/1762] D loss: 0.1882, G loss: 2.0270\n",
      "[404/1762] D loss: 1.3946, G loss: 0.7128\n",
      "[484/1762] D loss: 1.4252, G loss: 0.5306\n",
      "[564/1762] D loss: 1.4085, G loss: 1.0032\n",
      "[644/1762] D loss: 1.3890, G loss: 0.8062\n",
      "[724/1762] D loss: 1.4041, G loss: 0.5462\n",
      "[804/1762] D loss: 1.4655, G loss: 0.5313\n",
      "[884/1762] D loss: 1.4207, G loss: 0.5369\n",
      "[964/1762] D loss: 1.3999, G loss: 0.5642\n",
      "[1044/1762] D loss: 1.4431, G loss: 0.9672\n",
      "[1124/1762] D loss: 1.3913, G loss: 0.7792\n",
      "[1204/1762] D loss: 1.4430, G loss: 0.9491\n",
      "[1284/1762] D loss: 0.0581, G loss: 3.3073\n",
      "[1364/1762] D loss: 1.3048, G loss: 0.9197\n",
      "[1444/1762] D loss: 1.4000, G loss: 0.8717\n",
      "[1524/1762] D loss: 1.4065, G loss: 0.8753\n",
      "[1604/1762] D loss: 1.5363, G loss: 1.2696\n",
      "[1684/1762] D loss: 1.4081, G loss: 0.8151\n",
      "[1762/1762] D loss: 1.4640, G loss: 0.4470\n",
      "train error: \n",
      " D loss: 1.348233, G loss: 0.639581, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331341, G loss: 0.659107, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2361, G loss: 1.6244\n",
      "[84/1762] D loss: 1.4114, G loss: 0.8217\n",
      "[164/1762] D loss: 1.3971, G loss: 0.7031\n",
      "[244/1762] D loss: 1.3186, G loss: 0.7996\n",
      "[324/1762] D loss: 1.3902, G loss: 0.9173\n",
      "[404/1762] D loss: 1.4225, G loss: 0.7679\n",
      "[484/1762] D loss: 1.3923, G loss: 0.7218\n",
      "[564/1762] D loss: 1.4829, G loss: 0.4384\n",
      "[644/1762] D loss: 1.4442, G loss: 0.5273\n",
      "[724/1762] D loss: 1.3925, G loss: 0.7081\n",
      "[804/1762] D loss: 0.1704, G loss: 1.9159\n",
      "[884/1762] D loss: 1.4215, G loss: 0.5091\n",
      "[964/1762] D loss: 0.2381, G loss: 1.7776\n",
      "[1044/1762] D loss: 0.2419, G loss: 1.5360\n",
      "[1124/1762] D loss: 1.3999, G loss: 0.6017\n",
      "[1204/1762] D loss: 1.3916, G loss: 0.6526\n",
      "[1284/1762] D loss: 1.4131, G loss: 0.8617\n",
      "[1364/1762] D loss: 1.4021, G loss: 0.6226\n",
      "[1444/1762] D loss: 1.4058, G loss: 0.6879\n",
      "[1524/1762] D loss: 0.1616, G loss: 1.9747\n",
      "[1604/1762] D loss: 1.4011, G loss: 0.6497\n",
      "[1684/1762] D loss: 1.3931, G loss: 0.7322\n",
      "[1762/1762] D loss: 0.0372, G loss: 3.5416\n",
      "train error: \n",
      " D loss: 1.423851, G loss: 0.487009, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394588, G loss: 0.511696, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4226, G loss: 0.8561\n",
      "[84/1762] D loss: 2.1081, G loss: 1.0799\n",
      "[164/1762] D loss: 1.0020, G loss: 0.6157\n",
      "[244/1762] D loss: 1.5282, G loss: 0.6405\n",
      "[324/1762] D loss: 1.4412, G loss: 0.7905\n",
      "[404/1762] D loss: 1.2957, G loss: 1.0469\n",
      "[484/1762] D loss: 1.0137, G loss: 1.4437\n",
      "[564/1762] D loss: 1.4198, G loss: 0.5325\n",
      "[644/1762] D loss: 0.9859, G loss: 0.9398\n",
      "[724/1762] D loss: 0.7075, G loss: 1.1713\n",
      "[804/1762] D loss: 0.8392, G loss: 0.9889\n",
      "[884/1762] D loss: 0.9640, G loss: 1.2330\n",
      "[964/1762] D loss: 1.4162, G loss: 0.8309\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6944\n",
      "[1124/1762] D loss: 0.7773, G loss: 1.0351\n",
      "[1204/1762] D loss: 1.4303, G loss: 0.8675\n",
      "[1284/1762] D loss: 1.4654, G loss: 0.8579\n",
      "[1364/1762] D loss: 1.3959, G loss: 0.7167\n",
      "[1444/1762] D loss: 0.5620, G loss: 1.1957\n",
      "[1524/1762] D loss: 0.6678, G loss: 0.9904\n",
      "[1604/1762] D loss: 1.4182, G loss: 0.8411\n",
      "[1684/1762] D loss: 0.4712, G loss: 1.2006\n",
      "[1762/1762] D loss: 1.4603, G loss: 0.4451\n",
      "train error: \n",
      " D loss: 1.461420, G loss: 0.431442, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.442008, G loss: 0.440544, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4869, G loss: 0.4746\n",
      "[84/1762] D loss: 1.3982, G loss: 0.7693\n",
      "[164/1762] D loss: 1.4060, G loss: 0.6461\n",
      "[244/1762] D loss: 1.4051, G loss: 0.7145\n",
      "[324/1762] D loss: 0.4762, G loss: 1.2143\n",
      "[404/1762] D loss: 1.4353, G loss: 0.9489\n",
      "[484/1762] D loss: 1.5088, G loss: 0.9210\n",
      "[564/1762] D loss: 1.4257, G loss: 0.5271\n",
      "[644/1762] D loss: 0.3656, G loss: 1.5175\n",
      "[724/1762] D loss: 1.4009, G loss: 0.7632\n",
      "[804/1762] D loss: 1.4099, G loss: 0.8479\n",
      "[884/1762] D loss: 1.4029, G loss: 0.7504\n",
      "[964/1762] D loss: 1.4476, G loss: 0.4790\n",
      "[1044/1762] D loss: 0.7307, G loss: 0.8861\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.7272\n",
      "[1204/1762] D loss: 1.5186, G loss: 0.9634\n",
      "[1284/1762] D loss: 1.4321, G loss: 0.9788\n",
      "[1364/1762] D loss: 0.1304, G loss: 2.2965\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.7253\n",
      "[1524/1762] D loss: 1.4713, G loss: 0.5427\n",
      "[1604/1762] D loss: 1.4958, G loss: 0.4652\n",
      "[1684/1762] D loss: 1.4264, G loss: 0.6082\n",
      "[1762/1762] D loss: 1.3944, G loss: 1.1193\n",
      "train error: \n",
      " D loss: 0.486042, G loss: 2.123499, D accuracy: 97.3%, cell accuracy: 98.4%, board accuracy: 1.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.501650, G loss: 2.062572, D accuracy: 97.2%, cell accuracy: 98.4%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1989, G loss: 2.7404\n",
      "[84/1762] D loss: 0.9444, G loss: 1.9160\n",
      "[164/1762] D loss: 0.4654, G loss: 3.4677\n",
      "[244/1762] D loss: 1.6568, G loss: 1.2372\n",
      "[324/1762] D loss: 1.5688, G loss: 1.0748\n",
      "[404/1762] D loss: 1.3545, G loss: 1.1636\n",
      "[484/1762] D loss: 1.4248, G loss: 0.9969\n",
      "[564/1762] D loss: 1.4372, G loss: 0.5515\n",
      "[644/1762] D loss: 1.4964, G loss: 0.5092\n",
      "[724/1762] D loss: 1.4277, G loss: 0.7332\n",
      "[804/1762] D loss: 1.3898, G loss: 0.7504\n",
      "[884/1762] D loss: 1.5375, G loss: 1.0755\n",
      "[964/1762] D loss: 0.0769, G loss: 2.9332\n",
      "[1044/1762] D loss: 1.4429, G loss: 0.5231\n",
      "[1124/1762] D loss: 0.3365, G loss: 1.7107\n",
      "[1204/1762] D loss: 1.4075, G loss: 0.6003\n",
      "[1284/1762] D loss: 1.4137, G loss: 0.8302\n",
      "[1364/1762] D loss: 1.4070, G loss: 0.6561\n",
      "[1444/1762] D loss: 1.1617, G loss: 1.5041\n",
      "[1524/1762] D loss: 1.4685, G loss: 1.3130\n",
      "[1604/1762] D loss: 1.4698, G loss: 0.6610\n",
      "[1684/1762] D loss: 0.4959, G loss: 1.5912\n",
      "[1762/1762] D loss: 1.5217, G loss: 0.4405\n",
      "train error: \n",
      " D loss: 1.373463, G loss: 0.635467, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 83.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358435, G loss: 0.655417, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6791, G loss: 1.2073\n",
      "[84/1762] D loss: 1.3904, G loss: 0.7468\n",
      "[164/1762] D loss: 1.1860, G loss: 2.1136\n",
      "[244/1762] D loss: 1.4968, G loss: 0.9275\n",
      "[324/1762] D loss: 0.6153, G loss: 1.8687\n",
      "[404/1762] D loss: 1.4204, G loss: 0.5917\n",
      "[484/1762] D loss: 1.4049, G loss: 0.7980\n",
      "[564/1762] D loss: 1.3927, G loss: 0.7158\n",
      "[644/1762] D loss: 0.2029, G loss: 2.1913\n",
      "[724/1762] D loss: 1.3949, G loss: 0.6952\n",
      "[804/1762] D loss: 1.4261, G loss: 0.8086\n",
      "[884/1762] D loss: 1.4551, G loss: 0.9147\n",
      "[964/1762] D loss: 0.4115, G loss: 1.5755\n",
      "[1044/1762] D loss: 1.3995, G loss: 0.7350\n",
      "[1124/1762] D loss: 0.4668, G loss: 1.3597\n",
      "[1204/1762] D loss: 1.4133, G loss: 0.5387\n",
      "[1284/1762] D loss: 1.4073, G loss: 0.5751\n",
      "[1364/1762] D loss: 0.3267, G loss: 1.4409\n",
      "[1444/1762] D loss: 1.4322, G loss: 0.8767\n",
      "[1524/1762] D loss: 1.4685, G loss: 0.9254\n",
      "[1604/1762] D loss: 1.4234, G loss: 0.8924\n",
      "[1684/1762] D loss: 1.4394, G loss: 0.9664\n",
      "[1762/1762] D loss: 1.4058, G loss: 0.7953\n",
      "train error: \n",
      " D loss: 1.321046, G loss: 0.783411, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303072, G loss: 0.798957, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4312, G loss: 0.7397\n",
      "[84/1762] D loss: 1.4055, G loss: 0.7665\n",
      "[164/1762] D loss: 0.2779, G loss: 1.6110\n",
      "[244/1762] D loss: 1.3990, G loss: 0.7575\n",
      "[324/1762] D loss: 1.3958, G loss: 0.7495\n",
      "[404/1762] D loss: 1.3955, G loss: 0.7551\n",
      "[484/1762] D loss: 0.3224, G loss: 1.4215\n",
      "[564/1762] D loss: 0.2338, G loss: 1.7175\n",
      "[644/1762] D loss: 1.3808, G loss: 0.7053\n",
      "[724/1762] D loss: 1.3880, G loss: 0.7031\n",
      "[804/1762] D loss: 1.4138, G loss: 0.6152\n",
      "[884/1762] D loss: 0.2869, G loss: 1.7126\n",
      "[964/1762] D loss: 1.4055, G loss: 0.8171\n",
      "[1044/1762] D loss: 1.3527, G loss: 0.7325\n",
      "[1124/1762] D loss: 1.4138, G loss: 0.7322\n",
      "[1204/1762] D loss: 1.4304, G loss: 0.5704\n",
      "[1284/1762] D loss: 0.2742, G loss: 1.7384\n",
      "[1364/1762] D loss: 1.5751, G loss: 1.0046\n",
      "[1444/1762] D loss: 1.5545, G loss: 0.3814\n",
      "[1524/1762] D loss: 1.4054, G loss: 0.8194\n",
      "[1604/1762] D loss: 1.4085, G loss: 0.6106\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.6686\n",
      "[1762/1762] D loss: 1.5199, G loss: 0.4629\n",
      "train error: \n",
      " D loss: 1.859183, G loss: 0.223064, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.839689, G loss: 0.228956, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4449, G loss: 0.5842\n",
      "[84/1762] D loss: 1.4040, G loss: 0.7640\n",
      "[164/1762] D loss: 1.3895, G loss: 0.6693\n",
      "[244/1762] D loss: 0.2373, G loss: 1.6739\n",
      "[324/1762] D loss: 1.4351, G loss: 0.8034\n",
      "[404/1762] D loss: 1.3430, G loss: 0.8395\n",
      "[484/1762] D loss: 1.4013, G loss: 0.7755\n",
      "[564/1762] D loss: 1.3914, G loss: 0.7289\n",
      "[644/1762] D loss: 1.4515, G loss: 0.9452\n",
      "[724/1762] D loss: 1.3953, G loss: 0.8154\n",
      "[804/1762] D loss: 0.2685, G loss: 1.5310\n",
      "[884/1762] D loss: 0.2341, G loss: 1.7102\n",
      "[964/1762] D loss: 1.4763, G loss: 0.9279\n",
      "[1044/1762] D loss: 1.3946, G loss: 0.6699\n",
      "[1124/1762] D loss: 1.4209, G loss: 0.9173\n",
      "[1204/1762] D loss: 1.7694, G loss: 1.2560\n",
      "[1284/1762] D loss: 1.4065, G loss: 0.6753\n",
      "[1364/1762] D loss: 1.3990, G loss: 0.6899\n",
      "[1444/1762] D loss: 0.2225, G loss: 1.6999\n",
      "[1524/1762] D loss: 1.4353, G loss: 0.5543\n",
      "[1604/1762] D loss: 1.4058, G loss: 0.8913\n",
      "[1684/1762] D loss: 1.4116, G loss: 0.8103\n",
      "[1762/1762] D loss: 1.5153, G loss: 0.8703\n",
      "train error: \n",
      " D loss: 1.370426, G loss: 0.584350, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349166, G loss: 0.627474, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2762, G loss: 1.5518\n",
      "[84/1762] D loss: 1.3775, G loss: 0.9501\n",
      "[164/1762] D loss: 1.3252, G loss: 0.6172\n",
      "[244/1762] D loss: 1.4795, G loss: 0.9613\n",
      "[324/1762] D loss: 0.1419, G loss: 2.0621\n",
      "[404/1762] D loss: 1.4115, G loss: 0.7794\n",
      "[484/1762] D loss: 1.5478, G loss: 1.0849\n",
      "[564/1762] D loss: 1.4082, G loss: 0.6801\n",
      "[644/1762] D loss: 1.2203, G loss: 0.6226\n",
      "[724/1762] D loss: 1.2386, G loss: 0.9549\n",
      "[804/1762] D loss: 0.0973, G loss: 2.7127\n",
      "[884/1762] D loss: 1.4035, G loss: 0.6985\n",
      "[964/1762] D loss: 1.3912, G loss: 0.6593\n",
      "[1044/1762] D loss: 1.3962, G loss: 0.7418\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.7354\n",
      "[1204/1762] D loss: 1.3916, G loss: 0.7741\n",
      "[1284/1762] D loss: 1.6624, G loss: 1.2182\n",
      "[1364/1762] D loss: 1.4146, G loss: 0.8830\n",
      "[1444/1762] D loss: 1.4067, G loss: 0.8343\n",
      "[1524/1762] D loss: 1.4019, G loss: 0.6512\n",
      "[1604/1762] D loss: 1.4018, G loss: 0.5774\n",
      "[1684/1762] D loss: 1.4422, G loss: 0.9315\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.5819\n",
      "train error: \n",
      " D loss: 1.382314, G loss: 0.540411, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374313, G loss: 0.557230, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3994, G loss: 0.5682\n",
      "[84/1762] D loss: 0.2065, G loss: 1.8308\n",
      "[164/1762] D loss: 0.3159, G loss: 1.4490\n",
      "[244/1762] D loss: 1.3857, G loss: 0.7110\n",
      "[324/1762] D loss: 1.3936, G loss: 0.6524\n",
      "[404/1762] D loss: 1.4168, G loss: 0.5409\n",
      "[484/1762] D loss: 1.3886, G loss: 0.7199\n",
      "[564/1762] D loss: 0.1438, G loss: 2.1567\n",
      "[644/1762] D loss: 1.3887, G loss: 0.6779\n",
      "[724/1762] D loss: 1.3937, G loss: 0.7489\n",
      "[804/1762] D loss: 1.3243, G loss: 0.9631\n",
      "[884/1762] D loss: 1.4063, G loss: 0.6797\n",
      "[964/1762] D loss: 1.3960, G loss: 0.7381\n",
      "[1044/1762] D loss: 0.1280, G loss: 2.2410\n",
      "[1124/1762] D loss: 1.4190, G loss: 0.7818\n",
      "[1204/1762] D loss: 1.3983, G loss: 0.7854\n",
      "[1284/1762] D loss: 0.2099, G loss: 1.6753\n",
      "[1364/1762] D loss: 1.4104, G loss: 0.6145\n",
      "[1444/1762] D loss: 1.4573, G loss: 1.0216\n",
      "[1524/1762] D loss: 0.0167, G loss: 4.2062\n",
      "[1604/1762] D loss: 1.4525, G loss: 0.8472\n",
      "[1684/1762] D loss: 0.1787, G loss: 2.1960\n",
      "[1762/1762] D loss: 0.0263, G loss: 4.2715\n",
      "train error: \n",
      " D loss: 2.329739, G loss: 0.142765, D accuracy: 51.0%, cell accuracy: 99.7%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.285217, G loss: 0.155130, D accuracy: 51.5%, cell accuracy: 99.6%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3841, G loss: 1.0432\n",
      "[84/1762] D loss: 1.4034, G loss: 0.7304\n",
      "[164/1762] D loss: 1.3998, G loss: 0.5639\n",
      "[244/1762] D loss: 1.3971, G loss: 0.7031\n",
      "[324/1762] D loss: 1.3929, G loss: 0.6667\n",
      "[404/1762] D loss: 1.3996, G loss: 0.8544\n",
      "[484/1762] D loss: 1.4066, G loss: 0.7131\n",
      "[564/1762] D loss: 1.4352, G loss: 0.6393\n",
      "[644/1762] D loss: 1.5633, G loss: 1.1005\n",
      "[724/1762] D loss: 0.1531, G loss: 2.0956\n",
      "[804/1762] D loss: 1.5235, G loss: 0.3714\n",
      "[884/1762] D loss: 1.3651, G loss: 0.6626\n",
      "[964/1762] D loss: 1.3922, G loss: 0.7079\n",
      "[1044/1762] D loss: 1.4055, G loss: 0.6053\n",
      "[1124/1762] D loss: 0.2808, G loss: 1.5390\n",
      "[1204/1762] D loss: 0.0636, G loss: 3.1175\n",
      "[1284/1762] D loss: 1.4467, G loss: 0.7338\n",
      "[1364/1762] D loss: 1.4116, G loss: 0.6944\n",
      "[1444/1762] D loss: 0.1314, G loss: 2.2778\n",
      "[1524/1762] D loss: 0.1211, G loss: 2.6125\n",
      "[1604/1762] D loss: 1.4466, G loss: 0.9074\n",
      "[1684/1762] D loss: 1.4351, G loss: 0.5643\n",
      "[1762/1762] D loss: 1.4003, G loss: 0.8144\n",
      "train error: \n",
      " D loss: 1.354963, G loss: 0.768208, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355737, G loss: 0.773431, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3996, G loss: 0.7242\n",
      "[84/1762] D loss: 1.3977, G loss: 0.7529\n",
      "[164/1762] D loss: 0.0737, G loss: 2.7459\n",
      "[244/1762] D loss: 1.4008, G loss: 0.5878\n",
      "[324/1762] D loss: 1.4168, G loss: 0.6563\n",
      "[404/1762] D loss: 1.3964, G loss: 0.8219\n",
      "[484/1762] D loss: 1.4278, G loss: 0.5486\n",
      "[564/1762] D loss: 0.0857, G loss: 2.6581\n",
      "[644/1762] D loss: 1.4032, G loss: 0.7947\n",
      "[724/1762] D loss: 0.1818, G loss: 2.0677\n",
      "[804/1762] D loss: 1.4279, G loss: 0.5572\n",
      "[884/1762] D loss: 1.4090, G loss: 0.8801\n",
      "[964/1762] D loss: 0.1017, G loss: 2.5926\n",
      "[1044/1762] D loss: 1.4518, G loss: 0.8303\n",
      "[1124/1762] D loss: 1.4871, G loss: 0.5014\n",
      "[1204/1762] D loss: 0.1204, G loss: 2.2185\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.6226\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.6707\n",
      "[1444/1762] D loss: 1.4019, G loss: 0.8443\n",
      "[1524/1762] D loss: 1.3955, G loss: 0.7180\n",
      "[1604/1762] D loss: 0.1430, G loss: 1.9768\n",
      "[1684/1762] D loss: 1.4293, G loss: 0.4822\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.7105\n",
      "train error: \n",
      " D loss: 1.576909, G loss: 0.358835, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.566220, G loss: 0.368773, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2456, G loss: 1.6206\n",
      "[84/1762] D loss: 1.4046, G loss: 0.7384\n",
      "[164/1762] D loss: 1.4038, G loss: 0.8449\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6097\n",
      "[324/1762] D loss: 1.3982, G loss: 0.6350\n",
      "[404/1762] D loss: 1.3910, G loss: 0.7758\n",
      "[484/1762] D loss: 1.3991, G loss: 0.8282\n",
      "[564/1762] D loss: 0.1465, G loss: 2.1308\n",
      "[644/1762] D loss: 0.1148, G loss: 2.4766\n",
      "[724/1762] D loss: 1.4185, G loss: 0.8042\n",
      "[804/1762] D loss: 1.4122, G loss: 0.7440\n",
      "[884/1762] D loss: 1.4285, G loss: 0.5661\n",
      "[964/1762] D loss: 1.3201, G loss: 0.8673\n",
      "[1044/1762] D loss: 0.1324, G loss: 2.2880\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.8469\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.7743\n",
      "[1284/1762] D loss: 0.1506, G loss: 2.1452\n",
      "[1364/1762] D loss: 0.1055, G loss: 2.4058\n",
      "[1444/1762] D loss: 0.1285, G loss: 2.2479\n",
      "[1524/1762] D loss: 1.3924, G loss: 0.7084\n",
      "[1604/1762] D loss: 0.1366, G loss: 2.1133\n",
      "[1684/1762] D loss: 0.0100, G loss: 4.6724\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.6346\n",
      "train error: \n",
      " D loss: 1.385743, G loss: 0.560014, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383137, G loss: 0.574200, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1692, G loss: 1.9767\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7108\n",
      "[164/1762] D loss: 0.1378, G loss: 2.2107\n",
      "[244/1762] D loss: 1.3997, G loss: 0.7355\n",
      "[324/1762] D loss: 0.0910, G loss: 2.5822\n",
      "[404/1762] D loss: 1.3901, G loss: 0.6957\n",
      "[484/1762] D loss: 0.1373, G loss: 2.2340\n",
      "[564/1762] D loss: 1.4040, G loss: 0.7664\n",
      "[644/1762] D loss: 1.4470, G loss: 0.4844\n",
      "[724/1762] D loss: 1.3935, G loss: 0.7035\n",
      "[804/1762] D loss: 1.3932, G loss: 0.6377\n",
      "[884/1762] D loss: 1.3983, G loss: 0.6318\n",
      "[964/1762] D loss: 1.4060, G loss: 0.7055\n",
      "[1044/1762] D loss: 1.4008, G loss: 0.5737\n",
      "[1124/1762] D loss: 1.4016, G loss: 0.9009\n",
      "[1204/1762] D loss: 1.4158, G loss: 0.7695\n",
      "[1284/1762] D loss: 0.1773, G loss: 1.9630\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.7893\n",
      "[1444/1762] D loss: 1.7963, G loss: 1.0289\n",
      "[1524/1762] D loss: 1.4008, G loss: 0.7212\n",
      "[1604/1762] D loss: 1.4537, G loss: 0.9195\n",
      "[1684/1762] D loss: 1.4057, G loss: 0.5865\n",
      "[1762/1762] D loss: 1.4017, G loss: 0.7493\n",
      "train error: \n",
      " D loss: 1.372947, G loss: 0.662832, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376241, G loss: 0.665250, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4021, G loss: 0.7430\n",
      "[84/1762] D loss: 1.4095, G loss: 0.8412\n",
      "[164/1762] D loss: 1.4045, G loss: 0.6875\n",
      "[244/1762] D loss: 1.5278, G loss: 0.4335\n",
      "[324/1762] D loss: 1.4852, G loss: 0.9340\n",
      "[404/1762] D loss: 1.4212, G loss: 0.6754\n",
      "[484/1762] D loss: 1.4363, G loss: 0.8445\n",
      "[564/1762] D loss: 1.3945, G loss: 0.7583\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6976\n",
      "[724/1762] D loss: 1.4629, G loss: 0.8532\n",
      "[804/1762] D loss: 0.1985, G loss: 1.7548\n",
      "[884/1762] D loss: 0.0595, G loss: 3.2656\n",
      "[964/1762] D loss: 1.4364, G loss: 0.8800\n",
      "[1044/1762] D loss: 1.6187, G loss: 0.9745\n",
      "[1124/1762] D loss: 0.1126, G loss: 2.9221\n",
      "[1204/1762] D loss: 1.4418, G loss: 0.9409\n",
      "[1284/1762] D loss: 1.4278, G loss: 0.6466\n",
      "[1364/1762] D loss: 0.1217, G loss: 2.1645\n",
      "[1444/1762] D loss: 1.3966, G loss: 0.6724\n",
      "[1524/1762] D loss: 1.4014, G loss: 0.7958\n",
      "[1604/1762] D loss: 1.1896, G loss: 0.9812\n",
      "[1684/1762] D loss: 0.4081, G loss: 2.0347\n",
      "[1762/1762] D loss: 1.3975, G loss: 0.7435\n",
      "train error: \n",
      " D loss: 1.366426, G loss: 0.830257, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356203, G loss: 0.829248, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for cls in [DiscWithLessLinear]:\n",
    "    train(run_name=cls.__name__ + \"_lr_1em03\", learning_rate=1e-3, disc_cls=cls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, no difference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch size\n",
    "\n",
    "Just in case it makes a difference, let's try using a larger batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4096, G loss: 0.8376\n",
      "[164/1762] D loss: 0.9216, G loss: 0.9966\n",
      "[324/1762] D loss: 0.4052, G loss: 1.7929\n",
      "[484/1762] D loss: 0.0583, G loss: 3.3663\n",
      "[644/1762] D loss: 0.1307, G loss: 4.0234\n",
      "[804/1762] D loss: 0.0342, G loss: 4.1476\n",
      "[964/1762] D loss: 0.0555, G loss: 3.8795\n",
      "[1124/1762] D loss: 0.0362, G loss: 4.2559\n",
      "[1284/1762] D loss: 1.7508, G loss: 0.8830\n",
      "[1444/1762] D loss: 0.4192, G loss: 2.6205\n",
      "[1604/1762] D loss: 0.1526, G loss: 4.0958\n",
      "[1764/1762] D loss: 0.4872, G loss: 2.8617\n",
      "[1924/1762] D loss: 0.3653, G loss: 1.5350\n",
      "[2084/1762] D loss: 0.8694, G loss: 1.4778\n",
      "[2244/1762] D loss: 0.2608, G loss: 3.4962\n",
      "[2404/1762] D loss: 0.2585, G loss: 1.6643\n",
      "[2564/1762] D loss: 0.7230, G loss: 1.7321\n",
      "[2724/1762] D loss: 1.5001, G loss: 2.3424\n",
      "[2884/1762] D loss: 0.7781, G loss: 1.7318\n",
      "[3044/1762] D loss: 0.9170, G loss: 2.0009\n",
      "[3204/1762] D loss: 1.3824, G loss: 1.0525\n",
      "[3364/1762] D loss: 1.3952, G loss: 0.6370\n",
      "[3522/1762] D loss: 0.8220, G loss: 1.3182\n",
      "train error: \n",
      " D loss: 1.423000, G loss: 0.571927, D accuracy: 56.1%, cell accuracy: 99.6%, board accuracy: 70.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409352, G loss: 0.588235, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3591, G loss: 0.8651\n",
      "[164/1762] D loss: 1.4574, G loss: 0.7324\n",
      "[324/1762] D loss: 1.3441, G loss: 0.7484\n",
      "[484/1762] D loss: 1.1958, G loss: 1.5753\n",
      "[644/1762] D loss: 1.1634, G loss: 1.1065\n",
      "[804/1762] D loss: 1.2497, G loss: 0.7311\n",
      "[964/1762] D loss: 1.3112, G loss: 0.9933\n",
      "[1124/1762] D loss: 1.4886, G loss: 1.4183\n",
      "[1284/1762] D loss: 1.3079, G loss: 0.7398\n",
      "[1444/1762] D loss: 1.1362, G loss: 0.6998\n",
      "[1604/1762] D loss: 1.2328, G loss: 0.8179\n",
      "[1764/1762] D loss: 1.4069, G loss: 0.6221\n",
      "[1924/1762] D loss: 0.8483, G loss: 2.0960\n",
      "[2084/1762] D loss: 1.8200, G loss: 1.0334\n",
      "[2244/1762] D loss: 1.5269, G loss: 0.5038\n",
      "[2404/1762] D loss: 1.3823, G loss: 0.5372\n",
      "[2564/1762] D loss: 1.4079, G loss: 0.9617\n",
      "[2724/1762] D loss: 1.4506, G loss: 0.5686\n",
      "[2884/1762] D loss: 1.2986, G loss: 0.7945\n",
      "[3044/1762] D loss: 1.4508, G loss: 0.6437\n",
      "[3204/1762] D loss: 1.2795, G loss: 0.6649\n",
      "[3364/1762] D loss: 1.2923, G loss: 1.0923\n",
      "[3522/1762] D loss: 1.4884, G loss: 0.6040\n",
      "train error: \n",
      " D loss: 1.379197, G loss: 0.694012, D accuracy: 54.1%, cell accuracy: 99.5%, board accuracy: 61.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363142, G loss: 0.704776, D accuracy: 54.0%, cell accuracy: 99.4%, board accuracy: 56.4% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2569, G loss: 0.6717\n",
      "[164/1762] D loss: 1.2399, G loss: 1.3317\n",
      "[324/1762] D loss: 1.3123, G loss: 1.3024\n",
      "[484/1762] D loss: 1.1398, G loss: 0.8673\n",
      "[644/1762] D loss: 1.4039, G loss: 0.8973\n",
      "[804/1762] D loss: 1.0281, G loss: 1.0605\n",
      "[964/1762] D loss: 1.3703, G loss: 0.6782\n",
      "[1124/1762] D loss: 0.8793, G loss: 1.2321\n",
      "[1284/1762] D loss: 1.3183, G loss: 0.8760\n",
      "[1444/1762] D loss: 1.0489, G loss: 0.8044\n",
      "[1604/1762] D loss: 1.4144, G loss: 0.5567\n",
      "[1764/1762] D loss: 1.2845, G loss: 0.6893\n",
      "[1924/1762] D loss: 1.4625, G loss: 0.7140\n",
      "[2084/1762] D loss: 0.8555, G loss: 1.4475\n",
      "[2244/1762] D loss: 1.3906, G loss: 0.9054\n",
      "[2404/1762] D loss: 1.1972, G loss: 1.0190\n",
      "[2564/1762] D loss: 1.3364, G loss: 0.7689\n",
      "[2724/1762] D loss: 1.3045, G loss: 0.8136\n",
      "[2884/1762] D loss: 1.3740, G loss: 0.6022\n",
      "[3044/1762] D loss: 0.9620, G loss: 0.8503\n",
      "[3204/1762] D loss: 1.0162, G loss: 0.8594\n",
      "[3364/1762] D loss: 1.3838, G loss: 0.7804\n",
      "[3522/1762] D loss: 1.3760, G loss: 0.7727\n",
      "train error: \n",
      " D loss: 1.350294, G loss: 0.616860, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344884, G loss: 0.621122, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.6389\n",
      "[164/1762] D loss: 1.4703, G loss: 0.8243\n",
      "[324/1762] D loss: 1.3620, G loss: 0.8086\n",
      "[484/1762] D loss: 1.6649, G loss: 0.4185\n",
      "[644/1762] D loss: 1.4539, G loss: 0.8779\n",
      "[804/1762] D loss: 1.0992, G loss: 0.6609\n",
      "[964/1762] D loss: 1.3997, G loss: 0.9477\n",
      "[1124/1762] D loss: 1.4345, G loss: 0.8938\n",
      "[1284/1762] D loss: 1.2905, G loss: 0.8754\n",
      "[1444/1762] D loss: 1.4280, G loss: 0.7007\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6599\n",
      "[1764/1762] D loss: 1.4182, G loss: 0.6062\n",
      "[1924/1762] D loss: 1.3649, G loss: 0.9238\n",
      "[2084/1762] D loss: 1.2794, G loss: 0.8316\n",
      "[2244/1762] D loss: 1.3844, G loss: 0.7246\n",
      "[2404/1762] D loss: 1.4282, G loss: 0.5038\n",
      "[2564/1762] D loss: 0.4129, G loss: 1.6754\n",
      "[2724/1762] D loss: 0.4212, G loss: 1.4306\n",
      "[2884/1762] D loss: 1.3935, G loss: 0.8334\n",
      "[3044/1762] D loss: 1.3998, G loss: 0.5560\n",
      "[3204/1762] D loss: 1.2841, G loss: 0.5125\n",
      "[3364/1762] D loss: 1.5441, G loss: 1.1096\n",
      "[3522/1762] D loss: 1.1024, G loss: 1.3446\n",
      "train error: \n",
      " D loss: 1.372121, G loss: 0.576257, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368455, G loss: 0.574704, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4064, G loss: 0.7371\n",
      "[164/1762] D loss: 1.4444, G loss: 0.8471\n",
      "[324/1762] D loss: 1.3813, G loss: 0.7160\n",
      "[484/1762] D loss: 0.9458, G loss: 1.1625\n",
      "[644/1762] D loss: 1.4490, G loss: 0.8701\n",
      "[804/1762] D loss: 1.4248, G loss: 0.8392\n",
      "[964/1762] D loss: 1.3161, G loss: 0.8109\n",
      "[1124/1762] D loss: 1.3968, G loss: 0.7688\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.7701\n",
      "[1444/1762] D loss: 1.4052, G loss: 0.6672\n",
      "[1604/1762] D loss: 1.1961, G loss: 0.8168\n",
      "[1764/1762] D loss: 1.3898, G loss: 0.6314\n",
      "[1924/1762] D loss: 1.3795, G loss: 0.6656\n",
      "[2084/1762] D loss: 1.3203, G loss: 0.7241\n",
      "[2244/1762] D loss: 1.4080, G loss: 0.8275\n",
      "[2404/1762] D loss: 1.1187, G loss: 0.7797\n",
      "[2564/1762] D loss: 1.3571, G loss: 0.8156\n",
      "[2724/1762] D loss: 1.3913, G loss: 0.7182\n",
      "[2884/1762] D loss: 1.4272, G loss: 0.8569\n",
      "[3044/1762] D loss: 1.3945, G loss: 0.6131\n",
      "[3204/1762] D loss: 1.3908, G loss: 0.6279\n",
      "[3364/1762] D loss: 1.3613, G loss: 0.8204\n",
      "[3522/1762] D loss: 1.4309, G loss: 0.8911\n",
      "train error: \n",
      " D loss: 1.332210, G loss: 0.808761, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317903, G loss: 0.816728, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7181\n",
      "[164/1762] D loss: 1.3715, G loss: 0.7105\n",
      "[324/1762] D loss: 1.3879, G loss: 0.7608\n",
      "[484/1762] D loss: 0.9966, G loss: 1.0170\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6771\n",
      "[804/1762] D loss: 1.2642, G loss: 0.9581\n",
      "[964/1762] D loss: 1.4515, G loss: 0.8411\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7651\n",
      "[1284/1762] D loss: 1.3532, G loss: 0.7523\n",
      "[1444/1762] D loss: 1.3628, G loss: 0.9814\n",
      "[1604/1762] D loss: 1.6758, G loss: 1.2452\n",
      "[1764/1762] D loss: 2.1992, G loss: 0.6427\n",
      "[1924/1762] D loss: 1.6373, G loss: 0.9767\n",
      "[2084/1762] D loss: 1.4043, G loss: 0.9263\n",
      "[2244/1762] D loss: 1.2427, G loss: 0.7549\n",
      "[2404/1762] D loss: 1.4119, G loss: 0.9130\n",
      "[2564/1762] D loss: 1.1346, G loss: 0.8072\n",
      "[2724/1762] D loss: 1.4032, G loss: 0.6116\n",
      "[2884/1762] D loss: 1.0387, G loss: 1.0063\n",
      "[3044/1762] D loss: 1.2569, G loss: 0.7559\n",
      "[3204/1762] D loss: 0.9667, G loss: 0.8691\n",
      "[3364/1762] D loss: 1.5202, G loss: 0.5905\n",
      "[3522/1762] D loss: 1.3395, G loss: 0.9107\n",
      "train error: \n",
      " D loss: 1.330765, G loss: 0.692784, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326841, G loss: 0.692828, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4264, G loss: 0.6070\n",
      "[164/1762] D loss: 1.4546, G loss: 0.5821\n",
      "[324/1762] D loss: 1.3988, G loss: 0.6788\n",
      "[484/1762] D loss: 1.3949, G loss: 0.7206\n",
      "[644/1762] D loss: 1.3824, G loss: 0.7962\n",
      "[804/1762] D loss: 1.4858, G loss: 0.9366\n",
      "[964/1762] D loss: 1.4568, G loss: 0.6026\n",
      "[1124/1762] D loss: 0.6422, G loss: 1.2322\n",
      "[1284/1762] D loss: 1.4972, G loss: 0.4788\n",
      "[1444/1762] D loss: 1.4518, G loss: 0.8959\n",
      "[1604/1762] D loss: 1.3964, G loss: 0.6619\n",
      "[1764/1762] D loss: 1.3960, G loss: 0.6570\n",
      "[1924/1762] D loss: 1.4146, G loss: 0.9031\n",
      "[2084/1762] D loss: 1.6224, G loss: 1.2631\n",
      "[2244/1762] D loss: 1.3909, G loss: 0.7595\n",
      "[2404/1762] D loss: 0.5033, G loss: 1.2599\n",
      "[2564/1762] D loss: 1.1517, G loss: 1.2332\n",
      "[2724/1762] D loss: 0.5903, G loss: 0.9901\n",
      "[2884/1762] D loss: 0.4204, G loss: 1.7944\n",
      "[3044/1762] D loss: 0.3304, G loss: 2.0677\n",
      "[3204/1762] D loss: 1.1142, G loss: 0.8914\n",
      "[3364/1762] D loss: 1.3142, G loss: 0.6623\n",
      "[3522/1762] D loss: 1.3923, G loss: 0.6323\n",
      "train error: \n",
      " D loss: 1.393978, G loss: 0.573275, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398510, G loss: 0.576962, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4036, G loss: 0.8011\n",
      "[164/1762] D loss: 1.3905, G loss: 0.8412\n",
      "[324/1762] D loss: 0.7034, G loss: 0.8842\n",
      "[484/1762] D loss: 0.6920, G loss: 1.2025\n",
      "[644/1762] D loss: 1.3989, G loss: 0.8869\n",
      "[804/1762] D loss: 1.3854, G loss: 0.7129\n",
      "[964/1762] D loss: 1.3341, G loss: 1.0490\n",
      "[1124/1762] D loss: 1.4689, G loss: 0.7729\n",
      "[1284/1762] D loss: 1.4275, G loss: 0.6357\n",
      "[1444/1762] D loss: 1.4643, G loss: 1.0673\n",
      "[1604/1762] D loss: 1.4069, G loss: 0.7322\n",
      "[1764/1762] D loss: 0.2348, G loss: 1.9345\n",
      "[1924/1762] D loss: 1.4897, G loss: 0.4477\n",
      "[2084/1762] D loss: 1.1854, G loss: 0.8991\n",
      "[2244/1762] D loss: 1.2182, G loss: 0.8171\n",
      "[2404/1762] D loss: 1.6221, G loss: 0.8908\n",
      "[2564/1762] D loss: 1.4577, G loss: 0.4882\n",
      "[2724/1762] D loss: 0.6705, G loss: 0.9249\n",
      "[2884/1762] D loss: 2.1807, G loss: 0.5614\n",
      "[3044/1762] D loss: 1.3994, G loss: 0.7163\n",
      "[3204/1762] D loss: 1.3459, G loss: 0.7966\n",
      "[3364/1762] D loss: 1.2779, G loss: 0.7524\n",
      "[3522/1762] D loss: 1.1885, G loss: 0.9276\n",
      "train error: \n",
      " D loss: 1.369032, G loss: 0.820231, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364888, G loss: 0.833823, D accuracy: 55.3%, cell accuracy: 99.5%, board accuracy: 53.4% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3490, G loss: 0.8478\n",
      "[164/1762] D loss: 1.3903, G loss: 0.6523\n",
      "[324/1762] D loss: 1.3934, G loss: 0.7050\n",
      "[484/1762] D loss: 1.4176, G loss: 0.8192\n",
      "[644/1762] D loss: 1.3976, G loss: 0.8692\n",
      "[804/1762] D loss: 1.3858, G loss: 0.7048\n",
      "[964/1762] D loss: 1.0708, G loss: 0.7985\n",
      "[1124/1762] D loss: 1.0457, G loss: 0.7852\n",
      "[1284/1762] D loss: 1.3665, G loss: 0.6100\n",
      "[1444/1762] D loss: 1.4084, G loss: 0.5921\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.7903\n",
      "[1764/1762] D loss: 1.3930, G loss: 0.7589\n",
      "[1924/1762] D loss: 1.4064, G loss: 0.5780\n",
      "[2084/1762] D loss: 1.4347, G loss: 0.5788\n",
      "[2244/1762] D loss: 1.4005, G loss: 0.7695\n",
      "[2404/1762] D loss: 0.8791, G loss: 0.8093\n",
      "[2564/1762] D loss: 1.7728, G loss: 0.7131\n",
      "[2724/1762] D loss: 1.4242, G loss: 0.9337\n",
      "[2884/1762] D loss: 1.3144, G loss: 0.8815\n",
      "[3044/1762] D loss: 1.3322, G loss: 0.6596\n",
      "[3204/1762] D loss: 0.6852, G loss: 1.1134\n",
      "[3364/1762] D loss: 1.4556, G loss: 0.8898\n",
      "[3522/1762] D loss: 1.3704, G loss: 0.7104\n",
      "train error: \n",
      " D loss: 1.340555, G loss: 0.660854, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327225, G loss: 0.672530, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4518, G loss: 0.5546\n",
      "[164/1762] D loss: 1.3894, G loss: 0.6230\n",
      "[324/1762] D loss: 1.3932, G loss: 0.7221\n",
      "[484/1762] D loss: 0.3883, G loss: 1.4926\n",
      "[644/1762] D loss: 1.4382, G loss: 0.8072\n",
      "[804/1762] D loss: 1.4107, G loss: 0.7280\n",
      "[964/1762] D loss: 1.6923, G loss: 1.0876\n",
      "[1124/1762] D loss: 0.5978, G loss: 1.7949\n",
      "[1284/1762] D loss: 1.4541, G loss: 0.7349\n",
      "[1444/1762] D loss: 1.4032, G loss: 0.5915\n",
      "[1604/1762] D loss: 1.3916, G loss: 0.7668\n",
      "[1764/1762] D loss: 1.4341, G loss: 0.7041\n",
      "[1924/1762] D loss: 0.2265, G loss: 1.9850\n",
      "[2084/1762] D loss: 1.3963, G loss: 0.7499\n",
      "[2244/1762] D loss: 1.1769, G loss: 1.7391\n",
      "[2404/1762] D loss: 1.2506, G loss: 1.0680\n",
      "[2564/1762] D loss: 0.4584, G loss: 1.3479\n",
      "[2724/1762] D loss: 1.4129, G loss: 0.8958\n",
      "[2884/1762] D loss: 0.6607, G loss: 0.7871\n",
      "[3044/1762] D loss: 1.4584, G loss: 0.8422\n",
      "[3204/1762] D loss: 1.5784, G loss: 0.3648\n",
      "[3364/1762] D loss: 1.5142, G loss: 0.5808\n",
      "[3522/1762] D loss: 1.5423, G loss: 0.9210\n",
      "train error: \n",
      " D loss: 1.336973, G loss: 0.858805, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312043, G loss: 0.863165, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4118, G loss: 0.5791\n",
      "[164/1762] D loss: 1.2297, G loss: 0.7849\n",
      "[324/1762] D loss: 1.4094, G loss: 0.6385\n",
      "[484/1762] D loss: 1.4310, G loss: 0.8986\n",
      "[644/1762] D loss: 1.5010, G loss: 0.9964\n",
      "[804/1762] D loss: 1.4373, G loss: 0.9123\n",
      "[964/1762] D loss: 1.5705, G loss: 1.0599\n",
      "[1124/1762] D loss: 1.5150, G loss: 0.4300\n",
      "[1284/1762] D loss: 0.1668, G loss: 2.4603\n",
      "[1444/1762] D loss: 1.4070, G loss: 0.7092\n",
      "[1604/1762] D loss: 1.6878, G loss: 1.1727\n",
      "[1764/1762] D loss: 0.6206, G loss: 1.6305\n",
      "[1924/1762] D loss: 1.4250, G loss: 0.5663\n",
      "[2084/1762] D loss: 1.4235, G loss: 0.8003\n",
      "[2244/1762] D loss: 1.4294, G loss: 0.9454\n",
      "[2404/1762] D loss: 1.5140, G loss: 0.9792\n",
      "[2564/1762] D loss: 1.4241, G loss: 0.5110\n",
      "[2724/1762] D loss: 1.6679, G loss: 0.3926\n",
      "[2884/1762] D loss: 1.4234, G loss: 0.5917\n",
      "[3044/1762] D loss: 1.3680, G loss: 0.6604\n",
      "[3204/1762] D loss: 1.4139, G loss: 0.7992\n",
      "[3364/1762] D loss: 1.4011, G loss: 0.9375\n",
      "[3522/1762] D loss: 1.3878, G loss: 0.6058\n",
      "train error: \n",
      " D loss: 1.340853, G loss: 0.628876, D accuracy: 58.0%, cell accuracy: 99.8%, board accuracy: 71.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326491, G loss: 0.636157, D accuracy: 59.5%, cell accuracy: 99.7%, board accuracy: 68.4% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4531, G loss: 0.6280\n",
      "[164/1762] D loss: 1.0697, G loss: 1.1584\n",
      "[324/1762] D loss: 1.4469, G loss: 0.9723\n",
      "[484/1762] D loss: 0.6337, G loss: 0.9238\n",
      "[644/1762] D loss: 0.4396, G loss: 1.3499\n",
      "[804/1762] D loss: 0.2780, G loss: 1.6112\n",
      "[964/1762] D loss: 1.6209, G loss: 1.4067\n",
      "[1124/1762] D loss: 1.4760, G loss: 0.9026\n",
      "[1284/1762] D loss: 0.4133, G loss: 1.2330\n",
      "[1444/1762] D loss: 1.4156, G loss: 0.5345\n",
      "[1604/1762] D loss: 1.4460, G loss: 0.8241\n",
      "[1764/1762] D loss: 1.3969, G loss: 0.7407\n",
      "[1924/1762] D loss: 1.4038, G loss: 0.6995\n",
      "[2084/1762] D loss: 3.7212, G loss: 0.1295\n",
      "[2244/1762] D loss: 0.8179, G loss: 0.9677\n",
      "[2404/1762] D loss: 1.3336, G loss: 0.6093\n",
      "[2564/1762] D loss: 1.6354, G loss: 0.7744\n",
      "[2724/1762] D loss: 1.4145, G loss: 0.8010\n",
      "[2884/1762] D loss: 1.3855, G loss: 0.6982\n",
      "[3044/1762] D loss: 1.3100, G loss: 0.8237\n",
      "[3204/1762] D loss: 1.3037, G loss: 0.8685\n",
      "[3364/1762] D loss: 1.3495, G loss: 0.6950\n",
      "[3522/1762] D loss: 1.3918, G loss: 0.7309\n",
      "train error: \n",
      " D loss: 1.383979, G loss: 0.672842, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382510, G loss: 0.673784, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9656, G loss: 0.8219\n",
      "[164/1762] D loss: 1.3547, G loss: 0.8723\n",
      "[324/1762] D loss: 1.3429, G loss: 0.8797\n",
      "[484/1762] D loss: 0.8947, G loss: 0.7563\n",
      "[644/1762] D loss: 1.4003, G loss: 0.6060\n",
      "[804/1762] D loss: 1.4112, G loss: 0.8072\n",
      "[964/1762] D loss: 1.4491, G loss: 0.8987\n",
      "[1124/1762] D loss: 0.6825, G loss: 0.8663\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7770\n",
      "[1444/1762] D loss: 1.4169, G loss: 0.8525\n",
      "[1604/1762] D loss: 0.4396, G loss: 1.3255\n",
      "[1764/1762] D loss: 1.4234, G loss: 0.7608\n",
      "[1924/1762] D loss: 1.3828, G loss: 0.9511\n",
      "[2084/1762] D loss: 1.3810, G loss: 0.7653\n",
      "[2244/1762] D loss: 1.3953, G loss: 0.6869\n",
      "[2404/1762] D loss: 0.1176, G loss: 2.4660\n",
      "[2564/1762] D loss: 0.8698, G loss: 0.7541\n",
      "[2724/1762] D loss: 0.2921, G loss: 1.5954\n",
      "[2884/1762] D loss: 1.5069, G loss: 1.1282\n",
      "[3044/1762] D loss: 1.4859, G loss: 0.9899\n",
      "[3204/1762] D loss: 1.3954, G loss: 0.6774\n",
      "[3364/1762] D loss: 1.4119, G loss: 0.7919\n",
      "[3522/1762] D loss: 1.4008, G loss: 0.5618\n",
      "train error: \n",
      " D loss: 1.457414, G loss: 0.470318, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.457721, G loss: 0.476254, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3815, G loss: 1.2940\n",
      "[164/1762] D loss: 1.3950, G loss: 0.7339\n",
      "[324/1762] D loss: 1.6079, G loss: 1.2811\n",
      "[484/1762] D loss: 1.2625, G loss: 0.8718\n",
      "[644/1762] D loss: 1.3859, G loss: 0.8158\n",
      "[804/1762] D loss: 1.3957, G loss: 0.7279\n",
      "[964/1762] D loss: 1.4997, G loss: 1.0230\n",
      "[1124/1762] D loss: 1.4070, G loss: 0.7647\n",
      "[1284/1762] D loss: 1.4312, G loss: 0.7487\n",
      "[1444/1762] D loss: 1.4908, G loss: 0.9996\n",
      "[1604/1762] D loss: 1.3931, G loss: 0.6415\n",
      "[1764/1762] D loss: 0.3333, G loss: 1.7264\n",
      "[1924/1762] D loss: 1.6009, G loss: 1.2089\n",
      "[2084/1762] D loss: 1.4662, G loss: 0.9228\n",
      "[2244/1762] D loss: 0.3628, G loss: 1.3014\n",
      "[2404/1762] D loss: 1.3182, G loss: 0.7745\n",
      "[2564/1762] D loss: 0.4854, G loss: 1.1400\n",
      "[2724/1762] D loss: 0.3921, G loss: 1.3183\n",
      "[2884/1762] D loss: 1.3745, G loss: 0.9478\n",
      "[3044/1762] D loss: 0.9760, G loss: 1.0127\n",
      "[3204/1762] D loss: 1.4824, G loss: 0.5665\n",
      "[3364/1762] D loss: 0.4093, G loss: 1.1660\n",
      "[3522/1762] D loss: 0.1014, G loss: 2.9472\n",
      "train error: \n",
      " D loss: 1.413464, G loss: 0.508682, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402898, G loss: 0.518669, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1948, G loss: 1.0873\n",
      "[164/1762] D loss: 0.5291, G loss: 1.0006\n",
      "[324/1762] D loss: 1.3348, G loss: 0.8550\n",
      "[484/1762] D loss: 0.2932, G loss: 1.5954\n",
      "[644/1762] D loss: 1.3959, G loss: 0.7078\n",
      "[804/1762] D loss: 1.4094, G loss: 0.6078\n",
      "[964/1762] D loss: 0.2575, G loss: 1.8757\n",
      "[1124/1762] D loss: 1.5044, G loss: 1.1067\n",
      "[1284/1762] D loss: 1.4021, G loss: 0.6982\n",
      "[1444/1762] D loss: 1.4068, G loss: 0.8935\n",
      "[1604/1762] D loss: 0.2043, G loss: 1.9974\n",
      "[1764/1762] D loss: 1.3891, G loss: 0.5632\n",
      "[1924/1762] D loss: 0.5231, G loss: 1.0275\n",
      "[2084/1762] D loss: 1.4070, G loss: 1.2849\n",
      "[2244/1762] D loss: 0.9781, G loss: 1.3169\n",
      "[2404/1762] D loss: 1.3494, G loss: 0.8271\n",
      "[2564/1762] D loss: 0.7350, G loss: 1.0427\n",
      "[2724/1762] D loss: 0.5953, G loss: 1.2883\n",
      "[2884/1762] D loss: 1.4982, G loss: 0.9147\n",
      "[3044/1762] D loss: 0.5655, G loss: 0.9374\n",
      "[3204/1762] D loss: 1.5086, G loss: 1.0406\n",
      "[3364/1762] D loss: 1.3874, G loss: 0.6896\n",
      "[3522/1762] D loss: 1.4094, G loss: 0.5339\n",
      "train error: \n",
      " D loss: 1.394663, G loss: 0.510477, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393268, G loss: 0.506547, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 72.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5554, G loss: 0.5403\n",
      "[164/1762] D loss: 1.4065, G loss: 0.7864\n",
      "[324/1762] D loss: 1.3990, G loss: 0.5570\n",
      "[484/1762] D loss: 0.5150, G loss: 1.0853\n",
      "[644/1762] D loss: 0.5788, G loss: 1.1377\n",
      "[804/1762] D loss: 1.5966, G loss: 1.2017\n",
      "[964/1762] D loss: 0.4493, G loss: 1.0892\n",
      "[1124/1762] D loss: 1.4304, G loss: 0.7772\n",
      "[1284/1762] D loss: 1.4360, G loss: 0.9000\n",
      "[1444/1762] D loss: 1.3478, G loss: 0.6068\n",
      "[1604/1762] D loss: 1.3999, G loss: 0.8342\n",
      "[1764/1762] D loss: 1.5076, G loss: 1.0351\n",
      "[1924/1762] D loss: 1.4046, G loss: 0.6285\n",
      "[2084/1762] D loss: 1.5314, G loss: 0.4143\n",
      "[2244/1762] D loss: 0.1781, G loss: 2.0942\n",
      "[2404/1762] D loss: 0.3955, G loss: 1.2466\n",
      "[2564/1762] D loss: 1.4134, G loss: 0.8542\n",
      "[2724/1762] D loss: 1.4021, G loss: 0.7496\n",
      "[2884/1762] D loss: 1.4183, G loss: 0.8214\n",
      "[3044/1762] D loss: 1.3995, G loss: 0.6802\n",
      "[3204/1762] D loss: 1.3904, G loss: 0.7001\n",
      "[3364/1762] D loss: 1.4376, G loss: 0.9186\n",
      "[3522/1762] D loss: 0.0808, G loss: 2.8543\n",
      "train error: \n",
      " D loss: 1.536551, G loss: 0.386981, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.528259, G loss: 0.393248, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4198, G loss: 0.8888\n",
      "[164/1762] D loss: 1.0774, G loss: 1.1115\n",
      "[324/1762] D loss: 1.4276, G loss: 0.9039\n",
      "[484/1762] D loss: 1.2972, G loss: 0.7201\n",
      "[644/1762] D loss: 0.1203, G loss: 2.5081\n",
      "[804/1762] D loss: 1.3897, G loss: 0.6797\n",
      "[964/1762] D loss: 1.4128, G loss: 0.7866\n",
      "[1124/1762] D loss: 1.4069, G loss: 0.7102\n",
      "[1284/1762] D loss: 1.4053, G loss: 0.7028\n",
      "[1444/1762] D loss: 1.4132, G loss: 0.8675\n",
      "[1604/1762] D loss: 1.3990, G loss: 0.9595\n",
      "[1764/1762] D loss: 1.4125, G loss: 0.5727\n",
      "[1924/1762] D loss: 1.3698, G loss: 0.6675\n",
      "[2084/1762] D loss: 0.0951, G loss: 2.5654\n",
      "[2244/1762] D loss: 1.4436, G loss: 1.0086\n",
      "[2404/1762] D loss: 1.4635, G loss: 1.0230\n",
      "[2564/1762] D loss: 1.2656, G loss: 0.7862\n",
      "[2724/1762] D loss: 1.2801, G loss: 0.6420\n",
      "[2884/1762] D loss: 1.5122, G loss: 0.5105\n",
      "[3044/1762] D loss: 1.4086, G loss: 0.8548\n",
      "[3204/1762] D loss: 1.1515, G loss: 1.1126\n",
      "[3364/1762] D loss: 0.2837, G loss: 1.5199\n",
      "[3522/1762] D loss: 1.3920, G loss: 0.7012\n",
      "train error: \n",
      " D loss: 1.424089, G loss: 0.486314, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409855, G loss: 0.494562, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2716, G loss: 1.6172\n",
      "[164/1762] D loss: 1.3964, G loss: 0.7098\n",
      "[324/1762] D loss: 1.4468, G loss: 0.9498\n",
      "[484/1762] D loss: 0.0175, G loss: 4.0685\n",
      "[644/1762] D loss: 1.4309, G loss: 0.7647\n",
      "[804/1762] D loss: 1.4041, G loss: 0.8047\n",
      "[964/1762] D loss: 1.3203, G loss: 0.7043\n",
      "[1124/1762] D loss: 1.4695, G loss: 0.5205\n",
      "[1284/1762] D loss: 1.4504, G loss: 0.8911\n",
      "[1444/1762] D loss: 0.2541, G loss: 1.8196\n",
      "[1604/1762] D loss: 1.3960, G loss: 0.7950\n",
      "[1764/1762] D loss: 1.4049, G loss: 0.6299\n",
      "[1924/1762] D loss: 0.2871, G loss: 1.7909\n",
      "[2084/1762] D loss: 1.7844, G loss: 1.3364\n",
      "[2244/1762] D loss: 0.3113, G loss: 1.4096\n",
      "[2404/1762] D loss: 1.3582, G loss: 0.9347\n",
      "[2564/1762] D loss: 1.4343, G loss: 0.8710\n",
      "[2724/1762] D loss: 1.4459, G loss: 0.5172\n",
      "[2884/1762] D loss: 1.3991, G loss: 0.8432\n",
      "[3044/1762] D loss: 1.4428, G loss: 0.8807\n",
      "[3204/1762] D loss: 0.9584, G loss: 0.8967\n",
      "[3364/1762] D loss: 1.4366, G loss: 0.9199\n",
      "[3522/1762] D loss: 1.4190, G loss: 0.7269\n",
      "train error: \n",
      " D loss: 1.367175, G loss: 0.635239, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366015, G loss: 0.640438, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0792, G loss: 1.2042\n",
      "[164/1762] D loss: 1.4065, G loss: 0.6299\n",
      "[324/1762] D loss: 1.3966, G loss: 0.7643\n",
      "[484/1762] D loss: 0.1307, G loss: 2.3097\n",
      "[644/1762] D loss: 1.4318, G loss: 0.8130\n",
      "[804/1762] D loss: 0.2591, G loss: 1.7662\n",
      "[964/1762] D loss: 1.4020, G loss: 0.7574\n",
      "[1124/1762] D loss: 1.2981, G loss: 0.7933\n",
      "[1284/1762] D loss: 1.4267, G loss: 0.7600\n",
      "[1444/1762] D loss: 1.4133, G loss: 0.6682\n",
      "[1604/1762] D loss: 0.2409, G loss: 1.8032\n",
      "[1764/1762] D loss: 1.3906, G loss: 0.6360\n",
      "[1924/1762] D loss: 1.3449, G loss: 0.7657\n",
      "[2084/1762] D loss: 1.5014, G loss: 0.9211\n",
      "[2244/1762] D loss: 1.4085, G loss: 0.7364\n",
      "[2404/1762] D loss: 0.5634, G loss: 1.0142\n",
      "[2564/1762] D loss: 1.4013, G loss: 0.7072\n",
      "[2724/1762] D loss: 1.4016, G loss: 0.5677\n",
      "[2884/1762] D loss: 1.3871, G loss: 0.7517\n",
      "[3044/1762] D loss: 1.2384, G loss: 0.9585\n",
      "[3204/1762] D loss: 1.4754, G loss: 0.8267\n",
      "[3364/1762] D loss: 1.3912, G loss: 0.6803\n",
      "[3522/1762] D loss: 0.1354, G loss: 2.1608\n",
      "train error: \n",
      " D loss: 2.150146, G loss: 0.162385, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.126787, G loss: 0.170036, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.5836\n",
      "[164/1762] D loss: 1.4000, G loss: 0.6433\n",
      "[324/1762] D loss: 0.4100, G loss: 1.3020\n",
      "[484/1762] D loss: 1.3978, G loss: 0.6579\n",
      "[644/1762] D loss: 1.1038, G loss: 0.9440\n",
      "[804/1762] D loss: 0.3029, G loss: 1.4395\n",
      "[964/1762] D loss: 0.2559, G loss: 1.6735\n",
      "[1124/1762] D loss: 0.2300, G loss: 1.8925\n",
      "[1284/1762] D loss: 0.2177, G loss: 1.7428\n",
      "[1444/1762] D loss: 1.2751, G loss: 1.3484\n",
      "[1604/1762] D loss: 1.3668, G loss: 1.0875\n",
      "[1764/1762] D loss: 0.3123, G loss: 1.3130\n",
      "[1924/1762] D loss: 0.2506, G loss: 1.7067\n",
      "[2084/1762] D loss: 1.4136, G loss: 0.5328\n",
      "[2244/1762] D loss: 1.3966, G loss: 0.5688\n",
      "[2404/1762] D loss: 0.2337, G loss: 1.6982\n",
      "[2564/1762] D loss: 1.4168, G loss: 0.7878\n",
      "[2724/1762] D loss: 1.3991, G loss: 0.7111\n",
      "[2884/1762] D loss: 0.2873, G loss: 1.4523\n",
      "[3044/1762] D loss: 1.4239, G loss: 0.8616\n",
      "[3204/1762] D loss: 1.4076, G loss: 0.6891\n",
      "[3364/1762] D loss: 0.2766, G loss: 1.4453\n",
      "[3522/1762] D loss: 1.3873, G loss: 0.6703\n",
      "train error: \n",
      " D loss: 1.435544, G loss: 0.507355, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.440513, G loss: 0.522663, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2341, G loss: 1.7259\n",
      "[164/1762] D loss: 1.3591, G loss: 0.6995\n",
      "[324/1762] D loss: 1.4868, G loss: 0.5139\n",
      "[484/1762] D loss: 0.2514, G loss: 1.6501\n",
      "[644/1762] D loss: 1.4036, G loss: 0.6674\n",
      "[804/1762] D loss: 1.4293, G loss: 0.6689\n",
      "[964/1762] D loss: 1.4407, G loss: 0.7841\n",
      "[1124/1762] D loss: 1.4108, G loss: 0.8112\n",
      "[1284/1762] D loss: 1.4496, G loss: 0.5256\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6772\n",
      "[1604/1762] D loss: 0.2327, G loss: 1.6999\n",
      "[1764/1762] D loss: 1.5287, G loss: 0.9431\n",
      "[1924/1762] D loss: 0.1727, G loss: 1.8575\n",
      "[2084/1762] D loss: 1.4374, G loss: 0.8759\n",
      "[2244/1762] D loss: 1.4726, G loss: 0.9026\n",
      "[2404/1762] D loss: 1.5020, G loss: 0.4297\n",
      "[2564/1762] D loss: 1.3652, G loss: 0.8034\n",
      "[2724/1762] D loss: 0.8810, G loss: 1.2265\n",
      "[2884/1762] D loss: 1.3943, G loss: 0.6322\n",
      "[3044/1762] D loss: 1.3893, G loss: 0.7635\n",
      "[3204/1762] D loss: 1.5041, G loss: 1.0398\n",
      "[3364/1762] D loss: 1.4168, G loss: 0.7654\n",
      "[3522/1762] D loss: 1.4210, G loss: 0.8174\n",
      "train error: \n",
      " D loss: 1.728947, G loss: 0.274407, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.712371, G loss: 0.284763, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5174, G loss: 0.9413\n",
      "[164/1762] D loss: 1.4044, G loss: 0.7981\n",
      "[324/1762] D loss: 1.3158, G loss: 0.7378\n",
      "[484/1762] D loss: 1.2672, G loss: 0.9380\n",
      "[644/1762] D loss: 1.3997, G loss: 1.0593\n",
      "[804/1762] D loss: 1.5077, G loss: 0.4362\n",
      "[964/1762] D loss: 1.4455, G loss: 0.8206\n",
      "[1124/1762] D loss: 1.4612, G loss: 0.9795\n",
      "[1284/1762] D loss: 0.4516, G loss: 1.0957\n",
      "[1444/1762] D loss: 1.4395, G loss: 1.0145\n",
      "[1604/1762] D loss: 1.5492, G loss: 1.2157\n",
      "[1764/1762] D loss: 0.1663, G loss: 2.1478\n",
      "[1924/1762] D loss: 1.4898, G loss: 0.9424\n",
      "[2084/1762] D loss: 0.2236, G loss: 1.7677\n",
      "[2244/1762] D loss: 1.4096, G loss: 0.6842\n",
      "[2404/1762] D loss: 0.3410, G loss: 1.5859\n",
      "[2564/1762] D loss: 1.4158, G loss: 0.5287\n",
      "[2724/1762] D loss: 0.0615, G loss: 2.9545\n",
      "[2884/1762] D loss: 1.4028, G loss: 0.6648\n",
      "[3044/1762] D loss: 1.4529, G loss: 0.5500\n",
      "[3204/1762] D loss: 1.4660, G loss: 0.8176\n",
      "[3364/1762] D loss: 1.4181, G loss: 0.9184\n",
      "[3522/1762] D loss: 0.0211, G loss: 3.9964\n",
      "train error: \n",
      " D loss: 1.980519, G loss: 0.198024, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.961646, G loss: 0.206787, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3978, G loss: 0.7800\n",
      "[164/1762] D loss: 1.4052, G loss: 0.6696\n",
      "[324/1762] D loss: 1.3976, G loss: 0.7899\n",
      "[484/1762] D loss: 1.4326, G loss: 0.7610\n",
      "[644/1762] D loss: 1.4082, G loss: 0.8376\n",
      "[804/1762] D loss: 1.4467, G loss: 0.4948\n",
      "[964/1762] D loss: 1.4539, G loss: 0.8790\n",
      "[1124/1762] D loss: 0.1025, G loss: 2.3884\n",
      "[1284/1762] D loss: 1.5875, G loss: 1.0752\n",
      "[1444/1762] D loss: 1.4159, G loss: 0.5336\n",
      "[1604/1762] D loss: 1.3612, G loss: 0.7269\n",
      "[1764/1762] D loss: 1.4151, G loss: 0.9045\n",
      "[1924/1762] D loss: 1.4015, G loss: 0.6701\n",
      "[2084/1762] D loss: 1.4196, G loss: 0.7483\n",
      "[2244/1762] D loss: 1.4129, G loss: 0.5475\n",
      "[2404/1762] D loss: 0.1791, G loss: 2.0691\n",
      "[2564/1762] D loss: 0.0482, G loss: 3.3788\n",
      "[2724/1762] D loss: 0.2056, G loss: 1.9025\n",
      "[2884/1762] D loss: 1.3941, G loss: 0.6325\n",
      "[3044/1762] D loss: 1.6031, G loss: 1.1157\n",
      "[3204/1762] D loss: 1.4436, G loss: 0.5512\n",
      "[3364/1762] D loss: 1.3987, G loss: 0.8383\n",
      "[3522/1762] D loss: 0.0420, G loss: 3.3198\n",
      "train error: \n",
      " D loss: 2.384521, G loss: 0.127193, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.351698, G loss: 0.137376, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3993, G loss: 0.7626\n",
      "[164/1762] D loss: 0.1249, G loss: 2.3248\n",
      "[324/1762] D loss: 1.4470, G loss: 0.8903\n",
      "[484/1762] D loss: 1.3945, G loss: 0.7256\n",
      "[644/1762] D loss: 0.0636, G loss: 2.9520\n",
      "[804/1762] D loss: 1.4091, G loss: 0.7151\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6797\n",
      "[1124/1762] D loss: 1.3084, G loss: 0.7060\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.7034\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6746\n",
      "[1604/1762] D loss: 1.4013, G loss: 0.7112\n",
      "[1764/1762] D loss: 1.4987, G loss: 1.0187\n",
      "[1924/1762] D loss: 1.3857, G loss: 0.4503\n",
      "[2084/1762] D loss: 1.4278, G loss: 0.5767\n",
      "[2244/1762] D loss: 1.3985, G loss: 0.7197\n",
      "[2404/1762] D loss: 1.4210, G loss: 0.6553\n",
      "[2564/1762] D loss: 1.4220, G loss: 0.8592\n",
      "[2724/1762] D loss: 1.3987, G loss: 0.8034\n",
      "[2884/1762] D loss: 1.4572, G loss: 1.2749\n",
      "[3044/1762] D loss: 1.4007, G loss: 0.7197\n",
      "[3204/1762] D loss: 1.3918, G loss: 0.8727\n",
      "[3364/1762] D loss: 1.3963, G loss: 0.7571\n",
      "[3522/1762] D loss: 0.0311, G loss: 3.5210\n",
      "train error: \n",
      " D loss: 2.427148, G loss: 0.120340, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.395466, G loss: 0.125640, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1849, G loss: 1.9493\n",
      "[164/1762] D loss: 0.1631, G loss: 2.1751\n",
      "[324/1762] D loss: 1.4082, G loss: 0.5992\n",
      "[484/1762] D loss: 1.3974, G loss: 0.5721\n",
      "[644/1762] D loss: 1.4296, G loss: 0.7139\n",
      "[804/1762] D loss: 1.4108, G loss: 0.7717\n",
      "[964/1762] D loss: 1.4223, G loss: 0.8421\n",
      "[1124/1762] D loss: 1.3950, G loss: 0.8201\n",
      "[1284/1762] D loss: 1.5067, G loss: 0.5085\n",
      "[1444/1762] D loss: 1.4860, G loss: 0.9689\n",
      "[1604/1762] D loss: 1.2076, G loss: 1.3159\n",
      "[1764/1762] D loss: 0.1290, G loss: 2.2960\n",
      "[1924/1762] D loss: 0.1970, G loss: 1.9221\n",
      "[2084/1762] D loss: 0.1530, G loss: 2.1485\n",
      "[2244/1762] D loss: 1.3917, G loss: 0.5509\n",
      "[2404/1762] D loss: 1.5446, G loss: 1.0376\n",
      "[2564/1762] D loss: 1.4008, G loss: 0.8131\n",
      "[2724/1762] D loss: 0.0193, G loss: 4.1275\n",
      "[2884/1762] D loss: 1.4034, G loss: 0.6346\n",
      "[3044/1762] D loss: 1.3996, G loss: 0.6554\n",
      "[3204/1762] D loss: 0.1030, G loss: 2.3650\n",
      "[3364/1762] D loss: 1.3774, G loss: 0.5660\n",
      "[3522/1762] D loss: 1.4101, G loss: 0.8980\n",
      "train error: \n",
      " D loss: 1.409810, G loss: 0.969501, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416445, G loss: 0.953863, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1418, G loss: 2.1814\n",
      "[164/1762] D loss: 1.4476, G loss: 0.5772\n",
      "[324/1762] D loss: 0.2067, G loss: 1.8657\n",
      "[484/1762] D loss: 1.4049, G loss: 0.7561\n",
      "[644/1762] D loss: 0.1847, G loss: 1.9103\n",
      "[804/1762] D loss: 1.4772, G loss: 0.5160\n",
      "[964/1762] D loss: 1.4423, G loss: 1.0055\n",
      "[1124/1762] D loss: 0.2683, G loss: 1.5383\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.7282\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.5596\n",
      "[1604/1762] D loss: 0.1869, G loss: 2.1393\n",
      "[1764/1762] D loss: 1.4054, G loss: 0.8605\n",
      "[1924/1762] D loss: 1.4085, G loss: 0.5675\n",
      "[2084/1762] D loss: 1.4046, G loss: 0.8188\n",
      "[2244/1762] D loss: 1.4536, G loss: 0.5173\n",
      "[2404/1762] D loss: 1.4212, G loss: 0.8704\n",
      "[2564/1762] D loss: 1.4037, G loss: 0.6050\n",
      "[2724/1762] D loss: 1.4026, G loss: 0.6299\n",
      "[2884/1762] D loss: 0.2972, G loss: 1.6139\n",
      "[3044/1762] D loss: 0.0270, G loss: 3.6979\n",
      "[3204/1762] D loss: 1.3526, G loss: 0.6783\n",
      "[3364/1762] D loss: 1.3991, G loss: 0.6891\n",
      "[3522/1762] D loss: 1.3969, G loss: 0.5956\n",
      "train error: \n",
      " D loss: 1.373060, G loss: 0.557394, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349798, G loss: 0.593192, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.6929\n",
      "[164/1762] D loss: 1.4624, G loss: 0.8753\n",
      "[324/1762] D loss: 1.3811, G loss: 0.6371\n",
      "[484/1762] D loss: 1.4042, G loss: 0.7825\n",
      "[644/1762] D loss: 0.0160, G loss: 4.1644\n",
      "[804/1762] D loss: 0.0254, G loss: 3.7466\n",
      "[964/1762] D loss: 1.4090, G loss: 0.6004\n",
      "[1124/1762] D loss: 0.1192, G loss: 2.3640\n",
      "[1284/1762] D loss: 1.4208, G loss: 0.7154\n",
      "[1444/1762] D loss: 1.4332, G loss: 0.9933\n",
      "[1604/1762] D loss: 0.0977, G loss: 2.4158\n",
      "[1764/1762] D loss: 1.4637, G loss: 0.8580\n",
      "[1924/1762] D loss: 0.1402, G loss: 2.3140\n",
      "[2084/1762] D loss: 1.4094, G loss: 0.6680\n",
      "[2244/1762] D loss: 1.3963, G loss: 0.5678\n",
      "[2404/1762] D loss: 1.4159, G loss: 0.6725\n",
      "[2564/1762] D loss: 1.5216, G loss: 1.1102\n",
      "[2724/1762] D loss: 1.5249, G loss: 0.4585\n",
      "[2884/1762] D loss: 1.4648, G loss: 0.5164\n",
      "[3044/1762] D loss: 1.3818, G loss: 0.7538\n",
      "[3204/1762] D loss: 1.3929, G loss: 0.6760\n",
      "[3364/1762] D loss: 1.4530, G loss: 1.0027\n",
      "[3522/1762] D loss: 1.4287, G loss: 0.8180\n",
      "train error: \n",
      " D loss: 1.814212, G loss: 0.281828, D accuracy: 51.4%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.801768, G loss: 0.283991, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4041, G loss: 0.5988\n",
      "[164/1762] D loss: 1.3690, G loss: 0.6831\n",
      "[324/1762] D loss: 0.2669, G loss: 1.5944\n",
      "[484/1762] D loss: 1.4209, G loss: 0.6159\n",
      "[644/1762] D loss: 1.4445, G loss: 0.6905\n",
      "[804/1762] D loss: 1.3944, G loss: 0.6275\n",
      "[964/1762] D loss: 1.3969, G loss: 0.6613\n",
      "[1124/1762] D loss: 1.4761, G loss: 0.9731\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.6742\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.6419\n",
      "[1604/1762] D loss: 0.1234, G loss: 2.2243\n",
      "[1764/1762] D loss: 0.0568, G loss: 3.2880\n",
      "[1924/1762] D loss: 0.3990, G loss: 1.2098\n",
      "[2084/1762] D loss: 0.0151, G loss: 4.2943\n",
      "[2244/1762] D loss: 1.3968, G loss: 0.7410\n",
      "[2404/1762] D loss: 1.4771, G loss: 0.5121\n",
      "[2564/1762] D loss: 1.3552, G loss: 1.1127\n",
      "[2724/1762] D loss: 1.5526, G loss: 1.0428\n",
      "[2884/1762] D loss: 1.4298, G loss: 0.9140\n",
      "[3044/1762] D loss: 0.2496, G loss: 1.5567\n",
      "[3204/1762] D loss: 0.2672, G loss: 1.5236\n",
      "[3364/1762] D loss: 1.3959, G loss: 0.5887\n",
      "[3522/1762] D loss: 1.4420, G loss: 0.9320\n",
      "train error: \n",
      " D loss: 1.429848, G loss: 0.667952, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.448289, G loss: 0.684522, D accuracy: 52.2%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2600, G loss: 1.0667\n",
      "[164/1762] D loss: 0.3656, G loss: 1.2350\n",
      "[324/1762] D loss: 1.4273, G loss: 0.6774\n",
      "[484/1762] D loss: 0.1126, G loss: 2.4576\n",
      "[644/1762] D loss: 1.4043, G loss: 0.5698\n",
      "[804/1762] D loss: 1.4111, G loss: 0.6153\n",
      "[964/1762] D loss: 0.1952, G loss: 2.0217\n",
      "[1124/1762] D loss: 1.3969, G loss: 0.7318\n",
      "[1284/1762] D loss: 1.4066, G loss: 0.8153\n",
      "[1444/1762] D loss: 1.4648, G loss: 0.7710\n",
      "[1604/1762] D loss: 1.2745, G loss: 0.9590\n",
      "[1764/1762] D loss: 0.0818, G loss: 3.1089\n",
      "[1924/1762] D loss: 1.4602, G loss: 0.8972\n",
      "[2084/1762] D loss: 1.4236, G loss: 0.6140\n",
      "[2244/1762] D loss: 1.3984, G loss: 0.7447\n",
      "[2404/1762] D loss: 1.3878, G loss: 0.8458\n",
      "[2564/1762] D loss: 1.3938, G loss: 0.7287\n",
      "[2724/1762] D loss: 1.3986, G loss: 0.6865\n",
      "[2884/1762] D loss: 0.9954, G loss: 1.4105\n",
      "[3044/1762] D loss: 1.5156, G loss: 0.8741\n",
      "[3204/1762] D loss: 1.4171, G loss: 0.5932\n",
      "[3364/1762] D loss: 1.3895, G loss: 0.6805\n",
      "[3522/1762] D loss: 1.3965, G loss: 0.7266\n",
      "train error: \n",
      " D loss: 2.014914, G loss: 0.193093, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.004213, G loss: 0.193982, D accuracy: 50.6%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3961, G loss: 0.7713\n",
      "[164/1762] D loss: 1.4409, G loss: 0.8700\n",
      "[324/1762] D loss: 1.4264, G loss: 0.5522\n",
      "[484/1762] D loss: 1.4804, G loss: 0.9681\n",
      "[644/1762] D loss: 1.4277, G loss: 0.7482\n",
      "[804/1762] D loss: 0.0999, G loss: 2.3216\n",
      "[964/1762] D loss: 1.4374, G loss: 0.8747\n",
      "[1124/1762] D loss: 1.4214, G loss: 0.5309\n",
      "[1284/1762] D loss: 1.5194, G loss: 0.3757\n",
      "[1444/1762] D loss: 1.4656, G loss: 1.0031\n",
      "[1604/1762] D loss: 0.1086, G loss: 2.2877\n",
      "[1764/1762] D loss: 1.3936, G loss: 0.6541\n",
      "[1924/1762] D loss: 1.4046, G loss: 0.6346\n",
      "[2084/1762] D loss: 1.4092, G loss: 0.7511\n",
      "[2244/1762] D loss: 0.1363, G loss: 2.1461\n",
      "[2404/1762] D loss: 1.4302, G loss: 0.5091\n",
      "[2564/1762] D loss: 1.4036, G loss: 0.8306\n",
      "[2724/1762] D loss: 1.4061, G loss: 0.7903\n",
      "[2884/1762] D loss: 1.3968, G loss: 0.7098\n",
      "[3044/1762] D loss: 1.3894, G loss: 0.6955\n",
      "[3204/1762] D loss: 0.2556, G loss: 1.8011\n",
      "[3364/1762] D loss: 1.3920, G loss: 0.6406\n",
      "[3522/1762] D loss: 1.3905, G loss: 0.6786\n",
      "train error: \n",
      " D loss: 1.619311, G loss: 0.346402, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.614575, G loss: 0.361513, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4012, G loss: 0.6153\n",
      "[164/1762] D loss: 1.4260, G loss: 0.6099\n",
      "[324/1762] D loss: 1.2853, G loss: 1.2877\n",
      "[484/1762] D loss: 1.5045, G loss: 0.7232\n",
      "[644/1762] D loss: 1.4963, G loss: 0.4037\n",
      "[804/1762] D loss: 1.4999, G loss: 1.2000\n",
      "[964/1762] D loss: 1.4002, G loss: 0.5183\n",
      "[1124/1762] D loss: 1.4632, G loss: 0.5032\n",
      "[1284/1762] D loss: 0.1777, G loss: 2.2350\n",
      "[1444/1762] D loss: 1.4272, G loss: 0.8418\n",
      "[1604/1762] D loss: 0.1109, G loss: 2.2771\n",
      "[1764/1762] D loss: 1.3926, G loss: 0.6590\n",
      "[1924/1762] D loss: 1.2670, G loss: 1.1755\n",
      "[2084/1762] D loss: 0.0298, G loss: 3.6659\n",
      "[2244/1762] D loss: 1.4023, G loss: 0.6473\n",
      "[2404/1762] D loss: 1.1801, G loss: 0.7059\n",
      "[2564/1762] D loss: 0.2310, G loss: 1.6535\n",
      "[2724/1762] D loss: 1.4063, G loss: 0.8452\n",
      "[2884/1762] D loss: 1.3957, G loss: 0.7764\n",
      "[3044/1762] D loss: 1.3996, G loss: 0.7916\n",
      "[3204/1762] D loss: 1.4268, G loss: 0.8521\n",
      "[3364/1762] D loss: 1.3892, G loss: 0.6948\n",
      "[3522/1762] D loss: 1.4139, G loss: 0.9205\n",
      "train error: \n",
      " D loss: 1.558708, G loss: 0.366343, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.548132, G loss: 0.377998, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3906, G loss: 0.6125\n",
      "[164/1762] D loss: 0.1160, G loss: 2.4280\n",
      "[324/1762] D loss: 1.5033, G loss: 0.9110\n",
      "[484/1762] D loss: 0.2103, G loss: 1.7915\n",
      "[644/1762] D loss: 1.4074, G loss: 0.7751\n",
      "[804/1762] D loss: 1.4001, G loss: 0.6696\n",
      "[964/1762] D loss: 1.4955, G loss: 0.9775\n",
      "[1124/1762] D loss: 1.4197, G loss: 0.6093\n",
      "[1284/1762] D loss: 0.1823, G loss: 2.0622\n",
      "[1444/1762] D loss: 0.1373, G loss: 2.1166\n",
      "[1604/1762] D loss: 1.4046, G loss: 0.8198\n",
      "[1764/1762] D loss: 1.4139, G loss: 0.5671\n",
      "[1924/1762] D loss: 1.3926, G loss: 0.7399\n",
      "[2084/1762] D loss: 1.3351, G loss: 0.7737\n",
      "[2244/1762] D loss: 1.7936, G loss: 0.8944\n",
      "[2404/1762] D loss: 1.3904, G loss: 0.7167\n",
      "[2564/1762] D loss: 1.4176, G loss: 0.6229\n",
      "[2724/1762] D loss: 1.4295, G loss: 0.8477\n",
      "[2884/1762] D loss: 1.3918, G loss: 0.7051\n",
      "[3044/1762] D loss: 1.3984, G loss: 0.7679\n",
      "[3204/1762] D loss: 1.4189, G loss: 0.8819\n",
      "[3364/1762] D loss: 1.3974, G loss: 0.5984\n",
      "[3522/1762] D loss: 0.0455, G loss: 3.5152\n",
      "train error: \n",
      " D loss: 3.500030, G loss: 0.040004, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 3.469873, G loss: 0.042958, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.6950\n",
      "[164/1762] D loss: 1.4067, G loss: 0.7502\n",
      "[324/1762] D loss: 1.3954, G loss: 0.7864\n",
      "[484/1762] D loss: 1.4012, G loss: 0.7378\n",
      "[644/1762] D loss: 1.5205, G loss: 0.4649\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6554\n",
      "[964/1762] D loss: 1.4522, G loss: 1.0795\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.7300\n",
      "[1284/1762] D loss: 1.4191, G loss: 0.5133\n",
      "[1444/1762] D loss: 0.0080, G loss: 5.0295\n",
      "[1604/1762] D loss: 0.1221, G loss: 2.0008\n",
      "[1764/1762] D loss: 1.4622, G loss: 0.7885\n",
      "[1924/1762] D loss: 0.2017, G loss: 1.6659\n",
      "[2084/1762] D loss: 1.4186, G loss: 0.8238\n",
      "[2244/1762] D loss: 1.4232, G loss: 0.9068\n",
      "[2404/1762] D loss: 1.4249, G loss: 0.7741\n",
      "[2564/1762] D loss: 1.4302, G loss: 0.7638\n",
      "[2724/1762] D loss: 0.1545, G loss: 1.9952\n",
      "[2884/1762] D loss: 1.0837, G loss: 2.1981\n",
      "[3044/1762] D loss: 0.2135, G loss: 2.1815\n",
      "[3204/1762] D loss: 1.3927, G loss: 0.6607\n",
      "[3364/1762] D loss: 0.2265, G loss: 1.6508\n",
      "[3522/1762] D loss: 1.6367, G loss: 0.9874\n",
      "train error: \n",
      " D loss: 2.126660, G loss: 0.167078, D accuracy: 49.5%, cell accuracy: 99.7%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.108880, G loss: 0.177486, D accuracy: 49.2%, cell accuracy: 99.7%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4803, G loss: 0.7162\n",
      "[164/1762] D loss: 1.3897, G loss: 0.7298\n",
      "[324/1762] D loss: 0.1434, G loss: 2.2010\n",
      "[484/1762] D loss: 0.1674, G loss: 2.0385\n",
      "[644/1762] D loss: 1.4513, G loss: 0.4605\n",
      "[804/1762] D loss: 1.3995, G loss: 0.6337\n",
      "[964/1762] D loss: 1.4819, G loss: 0.5468\n",
      "[1124/1762] D loss: 1.4073, G loss: 0.8870\n",
      "[1284/1762] D loss: 1.5035, G loss: 0.9540\n",
      "[1444/1762] D loss: 1.3972, G loss: 0.7428\n",
      "[1604/1762] D loss: 1.3897, G loss: 0.8433\n",
      "[1764/1762] D loss: 1.7373, G loss: 1.1373\n",
      "[1924/1762] D loss: 0.2655, G loss: 1.7610\n",
      "[2084/1762] D loss: 0.2456, G loss: 2.0781\n",
      "[2244/1762] D loss: 1.4011, G loss: 0.7564\n",
      "[2404/1762] D loss: 1.4414, G loss: 0.8426\n",
      "[2564/1762] D loss: 1.4293, G loss: 0.5992\n",
      "[2724/1762] D loss: 1.4544, G loss: 0.9513\n",
      "[2884/1762] D loss: 1.4127, G loss: 0.5512\n",
      "[3044/1762] D loss: 1.3901, G loss: 0.6914\n",
      "[3204/1762] D loss: 0.1558, G loss: 1.8806\n",
      "[3364/1762] D loss: 0.2062, G loss: 1.9092\n",
      "[3522/1762] D loss: 1.4646, G loss: 0.8907\n",
      "train error: \n",
      " D loss: 1.534875, G loss: 0.427157, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.556992, G loss: 0.441321, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1437, G loss: 2.0355\n",
      "[164/1762] D loss: 1.4373, G loss: 0.8076\n",
      "[324/1762] D loss: 1.4628, G loss: 0.4981\n",
      "[484/1762] D loss: 1.4620, G loss: 0.5227\n",
      "[644/1762] D loss: 1.4002, G loss: 0.8069\n",
      "[804/1762] D loss: 1.4032, G loss: 0.7603\n",
      "[964/1762] D loss: 0.1919, G loss: 1.8092\n",
      "[1124/1762] D loss: 1.3958, G loss: 0.6382\n",
      "[1284/1762] D loss: 0.1970, G loss: 1.9837\n",
      "[1444/1762] D loss: 1.4403, G loss: 0.9634\n",
      "[1604/1762] D loss: 0.0813, G loss: 2.5668\n",
      "[1764/1762] D loss: 0.1558, G loss: 2.0071\n",
      "[1924/1762] D loss: 0.1782, G loss: 1.7559\n",
      "[2084/1762] D loss: 1.1777, G loss: 0.9001\n",
      "[2244/1762] D loss: 0.8579, G loss: 2.7542\n",
      "[2404/1762] D loss: 1.3655, G loss: 0.6045\n",
      "[2564/1762] D loss: 0.2060, G loss: 1.9606\n",
      "[2724/1762] D loss: 0.2524, G loss: 1.5853\n",
      "[2884/1762] D loss: 1.3912, G loss: 0.9321\n",
      "[3044/1762] D loss: 1.5269, G loss: 0.5126\n",
      "[3204/1762] D loss: 0.5320, G loss: 1.0475\n",
      "[3364/1762] D loss: 1.5152, G loss: 0.9145\n",
      "[3522/1762] D loss: 0.0103, G loss: 4.7215\n",
      "train error: \n",
      " D loss: 3.220862, G loss: 0.070633, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 3.156881, G loss: 0.091893, D accuracy: 51.0%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0056, G loss: 5.5993\n",
      "[164/1762] D loss: 1.3959, G loss: 0.5538\n",
      "[324/1762] D loss: 0.1938, G loss: 1.9195\n",
      "[484/1762] D loss: 1.3930, G loss: 0.6723\n",
      "[644/1762] D loss: 0.0263, G loss: 3.9195\n",
      "[804/1762] D loss: 1.4093, G loss: 0.6881\n",
      "[964/1762] D loss: 0.1350, G loss: 2.2209\n",
      "[1124/1762] D loss: 1.3969, G loss: 0.7544\n",
      "[1284/1762] D loss: 1.3983, G loss: 0.8283\n",
      "[1444/1762] D loss: 1.4711, G loss: 0.9940\n",
      "[1604/1762] D loss: 1.4285, G loss: 0.8481\n",
      "[1764/1762] D loss: 1.4269, G loss: 0.5898\n",
      "[1924/1762] D loss: 1.4271, G loss: 0.8852\n",
      "[2084/1762] D loss: 0.0984, G loss: 2.5298\n",
      "[2244/1762] D loss: 1.4022, G loss: 0.8565\n",
      "[2404/1762] D loss: 0.1162, G loss: 2.3247\n",
      "[2564/1762] D loss: 1.3914, G loss: 0.8254\n",
      "[2724/1762] D loss: 0.1521, G loss: 2.1976\n",
      "[2884/1762] D loss: 1.5375, G loss: 0.8055\n",
      "[3044/1762] D loss: 0.2692, G loss: 1.6444\n",
      "[3204/1762] D loss: 1.4179, G loss: 0.8778\n",
      "[3364/1762] D loss: 1.4018, G loss: 0.6080\n",
      "[3522/1762] D loss: 1.4021, G loss: 0.8920\n",
      "train error: \n",
      " D loss: 1.381749, G loss: 0.716397, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378745, G loss: 0.720845, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4906, G loss: 1.0376\n",
      "[164/1762] D loss: 1.4138, G loss: 0.5395\n",
      "[324/1762] D loss: 0.2045, G loss: 1.8422\n",
      "[484/1762] D loss: 1.4246, G loss: 0.8817\n",
      "[644/1762] D loss: 1.3970, G loss: 0.8659\n",
      "[804/1762] D loss: 0.0907, G loss: 2.7760\n",
      "[964/1762] D loss: 1.3998, G loss: 0.8149\n",
      "[1124/1762] D loss: 1.3954, G loss: 0.9249\n",
      "[1284/1762] D loss: 0.0803, G loss: 2.5739\n",
      "[1444/1762] D loss: 1.6151, G loss: 0.4711\n",
      "[1604/1762] D loss: 0.0195, G loss: 4.3144\n",
      "[1764/1762] D loss: 1.3984, G loss: 0.6355\n",
      "[1924/1762] D loss: 0.2318, G loss: 1.9058\n",
      "[2084/1762] D loss: 1.4052, G loss: 0.5256\n",
      "[2244/1762] D loss: 1.3902, G loss: 0.6029\n",
      "[2404/1762] D loss: 0.1829, G loss: 1.9207\n",
      "[2564/1762] D loss: 1.4050, G loss: 0.7734\n",
      "[2724/1762] D loss: 0.1679, G loss: 2.0158\n",
      "[2884/1762] D loss: 1.3943, G loss: 0.6874\n",
      "[3044/1762] D loss: 1.4231, G loss: 0.5572\n",
      "[3204/1762] D loss: 0.1299, G loss: 2.1018\n",
      "[3364/1762] D loss: 1.5287, G loss: 0.4250\n",
      "[3522/1762] D loss: 1.4241, G loss: 0.5006\n",
      "train error: \n",
      " D loss: 1.529288, G loss: 0.407416, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.532191, G loss: 0.409817, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2084, G loss: 1.6804\n",
      "[164/1762] D loss: 1.4092, G loss: 0.6666\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6997\n",
      "[484/1762] D loss: 1.3903, G loss: 0.7122\n",
      "[644/1762] D loss: 1.4514, G loss: 0.8767\n",
      "[804/1762] D loss: 1.4029, G loss: 0.5370\n",
      "[964/1762] D loss: 0.0142, G loss: 4.3605\n",
      "[1124/1762] D loss: 1.7858, G loss: 1.4257\n",
      "[1284/1762] D loss: 1.3943, G loss: 0.5792\n",
      "[1444/1762] D loss: 0.1806, G loss: 2.1404\n",
      "[1604/1762] D loss: 1.4484, G loss: 0.9026\n",
      "[1764/1762] D loss: 1.3990, G loss: 0.7142\n",
      "[1924/1762] D loss: 1.4181, G loss: 0.8793\n",
      "[2084/1762] D loss: 1.5083, G loss: 0.8704\n",
      "[2244/1762] D loss: 1.4438, G loss: 0.5395\n",
      "[2404/1762] D loss: 1.4134, G loss: 0.8850\n",
      "[2564/1762] D loss: 1.3961, G loss: 0.6772\n",
      "[2724/1762] D loss: 1.4245, G loss: 0.8800\n",
      "[2884/1762] D loss: 1.3880, G loss: 0.7256\n",
      "[3044/1762] D loss: 1.4338, G loss: 0.7678\n",
      "[3204/1762] D loss: 1.4659, G loss: 0.5990\n",
      "[3364/1762] D loss: 1.3957, G loss: 0.7399\n",
      "[3522/1762] D loss: 1.4289, G loss: 0.5699\n",
      "train error: \n",
      " D loss: 1.603739, G loss: 0.395639, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.597392, G loss: 0.422030, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.8287\n",
      "[164/1762] D loss: 1.4502, G loss: 0.5781\n",
      "[324/1762] D loss: 0.1769, G loss: 2.1880\n",
      "[484/1762] D loss: 0.0226, G loss: 3.8117\n",
      "[644/1762] D loss: 1.4399, G loss: 0.4892\n",
      "[804/1762] D loss: 0.1155, G loss: 2.4073\n",
      "[964/1762] D loss: 1.4061, G loss: 0.7737\n",
      "[1124/1762] D loss: 1.3859, G loss: 0.7157\n",
      "[1284/1762] D loss: 1.4329, G loss: 0.9061\n",
      "[1444/1762] D loss: 1.3931, G loss: 0.6176\n",
      "[1604/1762] D loss: 1.4373, G loss: 0.9919\n",
      "[1764/1762] D loss: 0.2550, G loss: 1.4275\n",
      "[1924/1762] D loss: 0.0176, G loss: 4.0168\n",
      "[2084/1762] D loss: 1.3900, G loss: 0.8196\n",
      "[2244/1762] D loss: 1.3893, G loss: 0.7679\n",
      "[2404/1762] D loss: 1.5001, G loss: 0.9592\n",
      "[2564/1762] D loss: 1.4512, G loss: 0.5439\n",
      "[2724/1762] D loss: 0.8342, G loss: 2.2977\n",
      "[2884/1762] D loss: 0.1278, G loss: 2.5216\n",
      "[3044/1762] D loss: 1.3930, G loss: 0.7500\n",
      "[3204/1762] D loss: 1.4180, G loss: 0.7998\n",
      "[3364/1762] D loss: 1.3833, G loss: 0.7019\n",
      "[3522/1762] D loss: 1.3796, G loss: 0.6577\n",
      "train error: \n",
      " D loss: 1.399743, G loss: 0.788649, D accuracy: 50.5%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397954, G loss: 0.788359, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3932, G loss: 0.6188\n",
      "[164/1762] D loss: 3.5284, G loss: 0.4136\n",
      "[324/1762] D loss: 1.8565, G loss: 1.4641\n",
      "[484/1762] D loss: 0.7897, G loss: 1.6309\n",
      "[644/1762] D loss: 1.4903, G loss: 0.6615\n",
      "[804/1762] D loss: 0.7628, G loss: 1.0961\n",
      "[964/1762] D loss: 0.4649, G loss: 1.4842\n",
      "[1124/1762] D loss: 1.4242, G loss: 0.6035\n",
      "[1284/1762] D loss: 1.4024, G loss: 0.7579\n",
      "[1444/1762] D loss: 1.4788, G loss: 1.0508\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.6688\n",
      "[1764/1762] D loss: 1.3925, G loss: 0.7080\n",
      "[1924/1762] D loss: 1.4978, G loss: 0.8891\n",
      "[2084/1762] D loss: 0.4506, G loss: 1.5743\n",
      "[2244/1762] D loss: 1.3982, G loss: 0.6891\n",
      "[2404/1762] D loss: 1.3913, G loss: 0.6739\n",
      "[2564/1762] D loss: 1.4951, G loss: 1.1658\n",
      "[2724/1762] D loss: 1.6881, G loss: 0.8377\n",
      "[2884/1762] D loss: 1.3915, G loss: 0.6288\n",
      "[3044/1762] D loss: 1.0646, G loss: 0.9375\n",
      "[3204/1762] D loss: 1.7124, G loss: 1.3480\n",
      "[3364/1762] D loss: 0.3046, G loss: 1.6357\n",
      "[3522/1762] D loss: 1.4088, G loss: 0.6554\n",
      "train error: \n",
      " D loss: 1.382776, G loss: 0.598256, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374500, G loss: 0.604047, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5253, G loss: 1.0768\n",
      "[164/1762] D loss: 0.1992, G loss: 1.9921\n",
      "[324/1762] D loss: 1.4545, G loss: 0.8871\n",
      "[484/1762] D loss: 0.0708, G loss: 2.7470\n",
      "[644/1762] D loss: 1.4683, G loss: 0.7468\n",
      "[804/1762] D loss: 1.3967, G loss: 0.6167\n",
      "[964/1762] D loss: 1.4346, G loss: 0.9606\n",
      "[1124/1762] D loss: 0.1911, G loss: 2.3729\n",
      "[1284/1762] D loss: 0.1709, G loss: 2.1766\n",
      "[1444/1762] D loss: 1.2450, G loss: 1.1332\n",
      "[1604/1762] D loss: 1.2615, G loss: 1.3830\n",
      "[1764/1762] D loss: 1.4106, G loss: 0.7130\n",
      "[1924/1762] D loss: 1.1878, G loss: 0.9386\n",
      "[2084/1762] D loss: 0.2202, G loss: 1.7618\n",
      "[2244/1762] D loss: 1.5229, G loss: 0.4933\n",
      "[2404/1762] D loss: 1.4697, G loss: 1.1955\n",
      "[2564/1762] D loss: 1.3906, G loss: 0.6161\n",
      "[2724/1762] D loss: 1.4212, G loss: 0.6482\n",
      "[2884/1762] D loss: 1.4137, G loss: 0.6651\n",
      "[3044/1762] D loss: 0.3647, G loss: 1.4470\n",
      "[3204/1762] D loss: 0.2920, G loss: 1.5813\n",
      "[3364/1762] D loss: 0.2616, G loss: 1.6761\n",
      "[3522/1762] D loss: 1.3892, G loss: 0.6753\n",
      "train error: \n",
      " D loss: 1.418714, G loss: 0.497848, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402921, G loss: 0.506526, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4506, G loss: 0.8576\n",
      "[164/1762] D loss: 1.4258, G loss: 0.7398\n",
      "[324/1762] D loss: 1.4002, G loss: 0.6356\n",
      "[484/1762] D loss: 1.3926, G loss: 0.6640\n",
      "[644/1762] D loss: 0.2149, G loss: 1.7299\n",
      "[804/1762] D loss: 1.3968, G loss: 0.7670\n",
      "[964/1762] D loss: 1.3900, G loss: 0.7229\n",
      "[1124/1762] D loss: 1.3936, G loss: 0.7206\n",
      "[1284/1762] D loss: 0.0311, G loss: 3.5421\n",
      "[1444/1762] D loss: 0.2811, G loss: 1.5856\n",
      "[1604/1762] D loss: 1.4089, G loss: 0.7519\n",
      "[1764/1762] D loss: 1.4065, G loss: 0.7624\n",
      "[1924/1762] D loss: 0.1908, G loss: 2.2000\n",
      "[2084/1762] D loss: 1.3993, G loss: 0.7798\n",
      "[2244/1762] D loss: 1.4102, G loss: 0.7984\n",
      "[2404/1762] D loss: 1.4722, G loss: 0.8732\n",
      "[2564/1762] D loss: 0.3539, G loss: 1.5342\n",
      "[2724/1762] D loss: 1.4283, G loss: 0.8838\n",
      "[2884/1762] D loss: 0.0943, G loss: 2.6013\n",
      "[3044/1762] D loss: 0.1423, G loss: 2.2849\n",
      "[3204/1762] D loss: 1.3888, G loss: 1.0083\n",
      "[3364/1762] D loss: 0.1954, G loss: 1.9700\n",
      "[3522/1762] D loss: 1.4581, G loss: 0.5114\n",
      "train error: \n",
      " D loss: 1.272664, G loss: 0.986760, D accuracy: 57.9%, cell accuracy: 99.6%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252519, G loss: 1.003029, D accuracy: 58.6%, cell accuracy: 99.5%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1783, G loss: 1.0690\n",
      "[164/1762] D loss: 1.3820, G loss: 0.6417\n",
      "[324/1762] D loss: 0.0784, G loss: 3.0625\n",
      "[484/1762] D loss: 1.3409, G loss: 0.6066\n",
      "[644/1762] D loss: 0.2466, G loss: 1.7741\n",
      "[804/1762] D loss: 0.1692, G loss: 1.9825\n",
      "[964/1762] D loss: 1.4131, G loss: 0.7850\n",
      "[1124/1762] D loss: 0.1658, G loss: 1.9820\n",
      "[1284/1762] D loss: 1.4109, G loss: 0.6070\n",
      "[1444/1762] D loss: 3.6781, G loss: 0.0534\n",
      "[1604/1762] D loss: 1.3941, G loss: 0.7475\n",
      "[1764/1762] D loss: 1.3929, G loss: 0.7017\n",
      "[1924/1762] D loss: 1.3912, G loss: 0.6452\n",
      "[2084/1762] D loss: 1.4254, G loss: 0.9840\n",
      "[2244/1762] D loss: 1.4029, G loss: 0.7915\n",
      "[2404/1762] D loss: 0.1715, G loss: 2.1448\n",
      "[2564/1762] D loss: 1.3945, G loss: 0.6440\n",
      "[2724/1762] D loss: 0.4270, G loss: 1.3949\n",
      "[2884/1762] D loss: 1.4579, G loss: 1.0921\n",
      "[3044/1762] D loss: 0.0792, G loss: 3.2279\n",
      "[3204/1762] D loss: 1.4169, G loss: 0.7012\n",
      "[3364/1762] D loss: 1.4275, G loss: 0.6542\n",
      "[3522/1762] D loss: 1.4361, G loss: 0.5599\n",
      "train error: \n",
      " D loss: 1.461031, G loss: 0.494964, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.434526, G loss: 0.532696, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4012, G loss: 0.7518\n",
      "[164/1762] D loss: 1.1514, G loss: 1.1150\n",
      "[324/1762] D loss: 1.4087, G loss: 0.7771\n",
      "[484/1762] D loss: 0.1093, G loss: 2.5145\n",
      "[644/1762] D loss: 1.4715, G loss: 0.5963\n",
      "[804/1762] D loss: 1.4547, G loss: 1.0209\n",
      "[964/1762] D loss: 1.4017, G loss: 0.7211\n",
      "[1124/1762] D loss: 1.4200, G loss: 0.5269\n",
      "[1284/1762] D loss: 1.4364, G loss: 0.8929\n",
      "[1444/1762] D loss: 1.4269, G loss: 0.8180\n",
      "[1604/1762] D loss: 1.3924, G loss: 0.7052\n",
      "[1764/1762] D loss: 0.0278, G loss: 3.7674\n",
      "[1924/1762] D loss: 1.4212, G loss: 0.9181\n",
      "[2084/1762] D loss: 0.1567, G loss: 1.9388\n",
      "[2244/1762] D loss: 1.3908, G loss: 0.7871\n",
      "[2404/1762] D loss: 1.3949, G loss: 0.6782\n",
      "[2564/1762] D loss: 0.1667, G loss: 2.2203\n",
      "[2724/1762] D loss: 1.4049, G loss: 0.5902\n",
      "[2884/1762] D loss: 1.4024, G loss: 0.8572\n",
      "[3044/1762] D loss: 1.3869, G loss: 0.6783\n",
      "[3204/1762] D loss: 1.4157, G loss: 0.5586\n",
      "[3364/1762] D loss: 1.3961, G loss: 0.6120\n",
      "[3522/1762] D loss: 1.4252, G loss: 0.5615\n",
      "train error: \n",
      " D loss: 1.408640, G loss: 0.541648, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401413, G loss: 0.554223, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4001, G loss: 0.7266\n",
      "[164/1762] D loss: 1.4170, G loss: 0.7596\n",
      "[324/1762] D loss: 1.4819, G loss: 0.4779\n",
      "[484/1762] D loss: 0.2527, G loss: 1.8933\n",
      "[644/1762] D loss: 0.1577, G loss: 2.5867\n",
      "[804/1762] D loss: 0.2206, G loss: 1.9326\n",
      "[964/1762] D loss: 1.4534, G loss: 0.7935\n",
      "[1124/1762] D loss: 0.0985, G loss: 2.5864\n",
      "[1284/1762] D loss: 1.4496, G loss: 0.8505\n",
      "[1444/1762] D loss: 1.5386, G loss: 0.9203\n",
      "[1604/1762] D loss: 1.4094, G loss: 0.6664\n",
      "[1764/1762] D loss: 0.3638, G loss: 1.7636\n",
      "[1924/1762] D loss: 1.4809, G loss: 1.1956\n",
      "[2084/1762] D loss: 1.5093, G loss: 0.4784\n",
      "[2244/1762] D loss: 1.4033, G loss: 0.7253\n",
      "[2404/1762] D loss: 1.4184, G loss: 0.8431\n",
      "[2564/1762] D loss: 1.4089, G loss: 0.8530\n",
      "[2724/1762] D loss: 1.4301, G loss: 0.8699\n",
      "[2884/1762] D loss: 1.4275, G loss: 0.8127\n",
      "[3044/1762] D loss: 1.3961, G loss: 0.6669\n",
      "[3204/1762] D loss: 0.0959, G loss: 2.8860\n",
      "[3364/1762] D loss: 1.4158, G loss: 0.7737\n",
      "[3522/1762] D loss: 1.4324, G loss: 0.7802\n",
      "train error: \n",
      " D loss: 1.464174, G loss: 0.786181, D accuracy: 49.3%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.475493, G loss: 0.793323, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2161, G loss: 1.8295\n",
      "[164/1762] D loss: 1.4119, G loss: 0.7751\n",
      "[324/1762] D loss: 1.4320, G loss: 0.8256\n",
      "[484/1762] D loss: 1.0274, G loss: 1.0849\n",
      "[644/1762] D loss: 0.0442, G loss: 3.2852\n",
      "[804/1762] D loss: 0.0848, G loss: 2.6636\n",
      "[964/1762] D loss: 1.4074, G loss: 0.7888\n",
      "[1124/1762] D loss: 1.4163, G loss: 0.7038\n",
      "[1284/1762] D loss: 1.4117, G loss: 0.6707\n",
      "[1444/1762] D loss: 1.3926, G loss: 0.6876\n",
      "[1604/1762] D loss: 1.4097, G loss: 0.6322\n",
      "[1764/1762] D loss: 1.4241, G loss: 0.5652\n",
      "[1924/1762] D loss: 0.1695, G loss: 2.1448\n",
      "[2084/1762] D loss: 1.4459, G loss: 0.8136\n",
      "[2244/1762] D loss: 1.4048, G loss: 0.8502\n",
      "[2404/1762] D loss: 1.4056, G loss: 0.7032\n",
      "[2564/1762] D loss: 0.1613, G loss: 2.3799\n",
      "[2724/1762] D loss: 1.4388, G loss: 0.8749\n",
      "[2884/1762] D loss: 1.4003, G loss: 0.7505\n",
      "[3044/1762] D loss: 1.3959, G loss: 0.7226\n",
      "[3204/1762] D loss: 1.3898, G loss: 0.6587\n",
      "[3364/1762] D loss: 1.3888, G loss: 0.7042\n",
      "[3522/1762] D loss: 1.4191, G loss: 0.6599\n",
      "train error: \n",
      " D loss: 1.424905, G loss: 1.012770, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416342, G loss: 1.026084, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4553, G loss: 0.8322\n",
      "[164/1762] D loss: 1.3937, G loss: 0.7712\n",
      "[324/1762] D loss: 1.4251, G loss: 1.1379\n",
      "[484/1762] D loss: 1.3968, G loss: 0.7681\n",
      "[644/1762] D loss: 1.4046, G loss: 0.7202\n",
      "[804/1762] D loss: 0.1510, G loss: 2.5946\n",
      "[964/1762] D loss: 1.3921, G loss: 0.6482\n",
      "[1124/1762] D loss: 1.3938, G loss: 0.8806\n",
      "[1284/1762] D loss: 1.3920, G loss: 0.6549\n",
      "[1444/1762] D loss: 1.3938, G loss: 0.6771\n",
      "[1604/1762] D loss: 0.0831, G loss: 2.8427\n",
      "[1764/1762] D loss: 0.1419, G loss: 2.2111\n",
      "[1924/1762] D loss: 1.3932, G loss: 0.6679\n",
      "[2084/1762] D loss: 0.0857, G loss: 2.5747\n",
      "[2244/1762] D loss: 1.3902, G loss: 0.7237\n",
      "[2404/1762] D loss: 1.3990, G loss: 0.5898\n",
      "[2564/1762] D loss: 1.3989, G loss: 0.6984\n",
      "[2724/1762] D loss: 1.3965, G loss: 0.6242\n",
      "[2884/1762] D loss: 1.4163, G loss: 0.8979\n",
      "[3044/1762] D loss: 0.1290, G loss: 2.4872\n",
      "[3204/1762] D loss: 1.3860, G loss: 0.6908\n",
      "[3364/1762] D loss: 1.3998, G loss: 0.6876\n",
      "[3522/1762] D loss: 1.3875, G loss: 0.7100\n",
      "train error: \n",
      " D loss: 1.384856, G loss: 0.702286, D accuracy: 51.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380477, G loss: 0.715867, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3972, G loss: 0.7390\n",
      "[164/1762] D loss: 1.4539, G loss: 0.5937\n",
      "[324/1762] D loss: 1.1649, G loss: 1.7993\n",
      "[484/1762] D loss: 0.0973, G loss: 2.6813\n",
      "[644/1762] D loss: 1.4107, G loss: 0.4637\n",
      "[804/1762] D loss: 1.4202, G loss: 0.9088\n",
      "[964/1762] D loss: 0.0768, G loss: 2.9855\n",
      "[1124/1762] D loss: 1.4529, G loss: 0.4773\n",
      "[1284/1762] D loss: 1.4081, G loss: 0.6991\n",
      "[1444/1762] D loss: 1.7309, G loss: 1.3304\n",
      "[1604/1762] D loss: 0.1161, G loss: 2.0422\n",
      "[1764/1762] D loss: 1.5910, G loss: 0.3681\n",
      "[1924/1762] D loss: 1.4277, G loss: 0.7030\n",
      "[2084/1762] D loss: 1.4087, G loss: 0.6639\n",
      "[2244/1762] D loss: 1.4149, G loss: 0.6097\n",
      "[2404/1762] D loss: 0.0785, G loss: 2.8353\n",
      "[2564/1762] D loss: 0.1599, G loss: 2.1942\n",
      "[2724/1762] D loss: 1.4414, G loss: 0.8030\n",
      "[2884/1762] D loss: 1.3887, G loss: 0.6172\n",
      "[3044/1762] D loss: 1.3936, G loss: 0.8060\n",
      "[3204/1762] D loss: 1.3877, G loss: 0.7413\n",
      "[3364/1762] D loss: 1.3964, G loss: 0.7198\n",
      "[3522/1762] D loss: 1.4016, G loss: 0.5890\n",
      "train error: \n",
      " D loss: 1.618928, G loss: 0.338083, D accuracy: 51.3%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.603429, G loss: 0.352248, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4386, G loss: 0.5585\n",
      "[164/1762] D loss: 1.0213, G loss: 1.2286\n",
      "[324/1762] D loss: 1.4056, G loss: 0.7184\n",
      "[484/1762] D loss: 1.4113, G loss: 0.6202\n",
      "[644/1762] D loss: 0.1600, G loss: 2.3133\n",
      "[804/1762] D loss: 0.0757, G loss: 2.9525\n",
      "[964/1762] D loss: 1.4042, G loss: 0.7014\n",
      "[1124/1762] D loss: 1.5867, G loss: 0.9995\n",
      "[1284/1762] D loss: 1.4135, G loss: 0.5597\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.6538\n",
      "[1604/1762] D loss: 0.0902, G loss: 2.6628\n",
      "[1764/1762] D loss: 0.1720, G loss: 2.2864\n",
      "[1924/1762] D loss: 0.0867, G loss: 2.7157\n",
      "[2084/1762] D loss: 0.0996, G loss: 2.6619\n",
      "[2244/1762] D loss: 1.3968, G loss: 0.5749\n",
      "[2404/1762] D loss: 0.2652, G loss: 1.6102\n",
      "[2564/1762] D loss: 1.4262, G loss: 0.8748\n",
      "[2724/1762] D loss: 1.4481, G loss: 0.5334\n",
      "[2884/1762] D loss: 0.1097, G loss: 2.5374\n",
      "[3044/1762] D loss: 1.4814, G loss: 0.9125\n",
      "[3204/1762] D loss: 1.4168, G loss: 0.7208\n",
      "[3364/1762] D loss: 1.3947, G loss: 0.6747\n",
      "[3522/1762] D loss: 1.3866, G loss: 0.6518\n",
      "train error: \n",
      " D loss: 1.525100, G loss: 0.478873, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.527592, G loss: 0.481290, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1485, G loss: 2.1390\n",
      "[164/1762] D loss: 1.3945, G loss: 0.6867\n",
      "[324/1762] D loss: 1.4650, G loss: 0.8881\n",
      "[484/1762] D loss: 1.4182, G loss: 0.6318\n",
      "[644/1762] D loss: 1.4177, G loss: 0.9739\n",
      "[804/1762] D loss: 1.3946, G loss: 0.7027\n",
      "[964/1762] D loss: 1.4006, G loss: 0.6331\n",
      "[1124/1762] D loss: 1.4442, G loss: 0.9371\n",
      "[1284/1762] D loss: 1.3967, G loss: 0.6609\n",
      "[1444/1762] D loss: 1.3084, G loss: 0.8045\n",
      "[1604/1762] D loss: 0.0757, G loss: 2.8860\n",
      "[1764/1762] D loss: 1.4275, G loss: 0.7542\n",
      "[1924/1762] D loss: 1.4079, G loss: 0.6704\n",
      "[2084/1762] D loss: 1.4231, G loss: 0.8308\n",
      "[2244/1762] D loss: 1.4461, G loss: 0.8763\n",
      "[2404/1762] D loss: 1.3901, G loss: 0.7658\n",
      "[2564/1762] D loss: 0.1470, G loss: 2.2530\n",
      "[2724/1762] D loss: 1.3975, G loss: 0.8052\n",
      "[2884/1762] D loss: 1.3877, G loss: 0.6274\n",
      "[3044/1762] D loss: 1.4010, G loss: 0.7209\n",
      "[3204/1762] D loss: 1.3957, G loss: 0.6761\n",
      "[3364/1762] D loss: 1.4251, G loss: 0.5719\n",
      "[3522/1762] D loss: 0.0089, G loss: 4.9310\n",
      "train error: \n",
      " D loss: 1.796426, G loss: 0.270798, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.777054, G loss: 0.274959, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3177, G loss: 0.7145\n",
      "[324/1762] D loss: 0.5826, G loss: 1.4610\n",
      "[644/1762] D loss: 0.1618, G loss: 2.6178\n",
      "[964/1762] D loss: 0.0899, G loss: 3.9930\n",
      "[1284/1762] D loss: 0.0255, G loss: 4.8226\n",
      "[1604/1762] D loss: 0.0624, G loss: 3.4724\n",
      "[1924/1762] D loss: 0.0367, G loss: 4.0233\n",
      "[2244/1762] D loss: 0.0466, G loss: 5.5128\n",
      "[2564/1762] D loss: 0.1202, G loss: 4.7062\n",
      "[2884/1762] D loss: 0.7457, G loss: 2.7220\n",
      "[3204/1762] D loss: 0.2611, G loss: 2.5983\n",
      "[3524/1762] D loss: 0.5919, G loss: 1.2437\n",
      "[3844/1762] D loss: 0.4723, G loss: 2.8593\n",
      "[4164/1762] D loss: 0.0865, G loss: 3.8425\n",
      "[4484/1762] D loss: 0.5049, G loss: 2.0773\n",
      "[4804/1762] D loss: 0.3571, G loss: 2.0860\n",
      "[5124/1762] D loss: 0.3146, G loss: 2.6876\n",
      "[5444/1762] D loss: 1.3641, G loss: 1.6036\n",
      "[5764/1762] D loss: 0.5282, G loss: 5.3425\n",
      "[6084/1762] D loss: 0.5732, G loss: 1.2883\n",
      "[6404/1762] D loss: 0.5472, G loss: 2.3966\n",
      "[6724/1762] D loss: 0.9032, G loss: 1.3358\n",
      "[7042/1762] D loss: 1.2261, G loss: 1.2532\n",
      "train error: \n",
      " D loss: 1.350210, G loss: 0.913843, D accuracy: 66.5%, cell accuracy: 99.2%, board accuracy: 40.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397781, G loss: 0.902383, D accuracy: 65.3%, cell accuracy: 99.1%, board accuracy: 41.5% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6294, G loss: 2.9675\n",
      "[324/1762] D loss: 0.9120, G loss: 1.6490\n",
      "[644/1762] D loss: 1.1976, G loss: 1.4252\n",
      "[964/1762] D loss: 1.0420, G loss: 1.3090\n",
      "[1284/1762] D loss: 1.4975, G loss: 0.5581\n",
      "[1604/1762] D loss: 1.5876, G loss: 0.4919\n",
      "[1924/1762] D loss: 1.2235, G loss: 1.4444\n",
      "[2244/1762] D loss: 0.6731, G loss: 1.8541\n",
      "[2564/1762] D loss: 1.4976, G loss: 0.6767\n",
      "[2884/1762] D loss: 1.1855, G loss: 0.8777\n",
      "[3204/1762] D loss: 1.4828, G loss: 0.8735\n",
      "[3524/1762] D loss: 1.3550, G loss: 0.9113\n",
      "[3844/1762] D loss: 0.7972, G loss: 1.2016\n",
      "[4164/1762] D loss: 1.0234, G loss: 1.5816\n",
      "[4484/1762] D loss: 1.3550, G loss: 1.1912\n",
      "[4804/1762] D loss: 1.3667, G loss: 0.7956\n",
      "[5124/1762] D loss: 0.9496, G loss: 0.8755\n",
      "[5444/1762] D loss: 0.8320, G loss: 0.8312\n",
      "[5764/1762] D loss: 1.4630, G loss: 0.6303\n",
      "[6084/1762] D loss: 1.2894, G loss: 0.6159\n",
      "[6404/1762] D loss: 1.0789, G loss: 1.0369\n",
      "[6724/1762] D loss: 1.4224, G loss: 0.5263\n",
      "[7042/1762] D loss: 1.2952, G loss: 0.4744\n",
      "train error: \n",
      " D loss: 1.308352, G loss: 0.725670, D accuracy: 58.9%, cell accuracy: 99.6%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285881, G loss: 0.761956, D accuracy: 60.2%, cell accuracy: 99.6%, board accuracy: 69.2% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8630, G loss: 0.9314\n",
      "[324/1762] D loss: 0.7282, G loss: 1.5384\n",
      "[644/1762] D loss: 0.7143, G loss: 1.2943\n",
      "[964/1762] D loss: 1.5123, G loss: 1.0241\n",
      "[1284/1762] D loss: 0.8227, G loss: 0.9809\n",
      "[1604/1762] D loss: 1.4224, G loss: 0.6799\n",
      "[1924/1762] D loss: 1.5802, G loss: 0.4611\n",
      "[2244/1762] D loss: 1.3573, G loss: 0.6338\n",
      "[2564/1762] D loss: 1.4129, G loss: 0.6157\n",
      "[2884/1762] D loss: 1.5914, G loss: 0.9942\n",
      "[3204/1762] D loss: 1.5753, G loss: 0.4770\n",
      "[3524/1762] D loss: 1.6260, G loss: 1.2665\n",
      "[3844/1762] D loss: 1.4698, G loss: 0.7291\n",
      "[4164/1762] D loss: 1.4896, G loss: 0.4959\n",
      "[4484/1762] D loss: 1.3914, G loss: 0.7600\n",
      "[4804/1762] D loss: 1.3363, G loss: 0.3969\n",
      "[5124/1762] D loss: 1.3621, G loss: 0.6365\n",
      "[5444/1762] D loss: 1.5524, G loss: 1.0740\n",
      "[5764/1762] D loss: 1.4707, G loss: 0.6828\n",
      "[6084/1762] D loss: 1.4049, G loss: 0.7354\n",
      "[6404/1762] D loss: 1.4339, G loss: 0.8535\n",
      "[6724/1762] D loss: 1.2788, G loss: 0.6450\n",
      "[7042/1762] D loss: 1.4270, G loss: 0.8115\n",
      "train error: \n",
      " D loss: 1.430500, G loss: 1.346312, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394458, G loss: 1.371548, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5010, G loss: 0.8851\n",
      "[324/1762] D loss: 0.6912, G loss: 1.0875\n",
      "[644/1762] D loss: 1.5142, G loss: 0.6356\n",
      "[964/1762] D loss: 0.4438, G loss: 1.6115\n",
      "[1284/1762] D loss: 1.3295, G loss: 1.3256\n",
      "[1604/1762] D loss: 1.4140, G loss: 0.6698\n",
      "[1924/1762] D loss: 0.6139, G loss: 1.3636\n",
      "[2244/1762] D loss: 1.5073, G loss: 1.2038\n",
      "[2564/1762] D loss: 0.8671, G loss: 0.7305\n",
      "[2884/1762] D loss: 0.7896, G loss: 1.4563\n",
      "[3204/1762] D loss: 1.4085, G loss: 0.8713\n",
      "[3524/1762] D loss: 1.3710, G loss: 0.6617\n",
      "[3844/1762] D loss: 0.5858, G loss: 1.2055\n",
      "[4164/1762] D loss: 1.4369, G loss: 0.6394\n",
      "[4484/1762] D loss: 1.5485, G loss: 1.0236\n",
      "[4804/1762] D loss: 1.2804, G loss: 0.6791\n",
      "[5124/1762] D loss: 1.1586, G loss: 1.4744\n",
      "[5444/1762] D loss: 0.1954, G loss: 2.3323\n",
      "[5764/1762] D loss: 1.1365, G loss: 1.0687\n",
      "[6084/1762] D loss: 0.5370, G loss: 1.2530\n",
      "[6404/1762] D loss: 1.5397, G loss: 0.4443\n",
      "[6724/1762] D loss: 1.5023, G loss: 0.4668\n",
      "[7042/1762] D loss: 1.4483, G loss: 0.4131\n",
      "train error: \n",
      " D loss: 1.403751, G loss: 0.499160, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398158, G loss: 0.511955, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 79.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7183, G loss: 0.8823\n",
      "[324/1762] D loss: 0.4338, G loss: 1.6382\n",
      "[644/1762] D loss: 0.5694, G loss: 1.7402\n",
      "[964/1762] D loss: 1.3997, G loss: 0.6927\n",
      "[1284/1762] D loss: 1.3508, G loss: 0.6852\n",
      "[1604/1762] D loss: 1.4201, G loss: 0.8473\n",
      "[1924/1762] D loss: 0.4499, G loss: 1.3769\n",
      "[2244/1762] D loss: 1.3961, G loss: 0.6368\n",
      "[2564/1762] D loss: 1.4463, G loss: 0.7441\n",
      "[2884/1762] D loss: 1.1042, G loss: 1.0061\n",
      "[3204/1762] D loss: 1.4850, G loss: 0.4140\n",
      "[3524/1762] D loss: 1.5043, G loss: 0.8777\n",
      "[3844/1762] D loss: 1.3116, G loss: 0.5149\n",
      "[4164/1762] D loss: 1.4374, G loss: 0.7211\n",
      "[4484/1762] D loss: 1.4869, G loss: 0.7057\n",
      "[4804/1762] D loss: 0.4453, G loss: 1.7445\n",
      "[5124/1762] D loss: 1.3634, G loss: 0.7261\n",
      "[5444/1762] D loss: 1.3985, G loss: 0.7971\n",
      "[5764/1762] D loss: 0.5301, G loss: 1.1312\n",
      "[6084/1762] D loss: 1.2605, G loss: 1.1916\n",
      "[6404/1762] D loss: 1.2643, G loss: 0.6510\n",
      "[6724/1762] D loss: 0.5959, G loss: 1.4240\n",
      "[7042/1762] D loss: 1.0239, G loss: 1.0255\n",
      "train error: \n",
      " D loss: 1.381277, G loss: 0.580270, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368348, G loss: 0.592184, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5937, G loss: 1.0731\n",
      "[324/1762] D loss: 0.1405, G loss: 2.4604\n",
      "[644/1762] D loss: 0.1427, G loss: 2.7484\n",
      "[964/1762] D loss: 1.4291, G loss: 0.7234\n",
      "[1284/1762] D loss: 0.4377, G loss: 1.4407\n",
      "[1604/1762] D loss: 1.3600, G loss: 0.7599\n",
      "[1924/1762] D loss: 1.3634, G loss: 0.7291\n",
      "[2244/1762] D loss: 1.2976, G loss: 0.8938\n",
      "[2564/1762] D loss: 1.2380, G loss: 0.7507\n",
      "[2884/1762] D loss: 1.3571, G loss: 0.6974\n",
      "[3204/1762] D loss: 1.5262, G loss: 0.9519\n",
      "[3524/1762] D loss: 0.9338, G loss: 0.6941\n",
      "[3844/1762] D loss: 1.4428, G loss: 0.7666\n",
      "[4164/1762] D loss: 1.2147, G loss: 1.3920\n",
      "[4484/1762] D loss: 0.3963, G loss: 1.4630\n",
      "[4804/1762] D loss: 1.3993, G loss: 0.6936\n",
      "[5124/1762] D loss: 1.3861, G loss: 0.8236\n",
      "[5444/1762] D loss: 1.4646, G loss: 0.5628\n",
      "[5764/1762] D loss: 1.4446, G loss: 0.7928\n",
      "[6084/1762] D loss: 1.4248, G loss: 0.7457\n",
      "[6404/1762] D loss: 0.3891, G loss: 1.4112\n",
      "[6724/1762] D loss: 1.5276, G loss: 0.4067\n",
      "[7042/1762] D loss: 0.1339, G loss: 2.6653\n",
      "train error: \n",
      " D loss: 1.338104, G loss: 0.832395, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325057, G loss: 0.848528, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3537, G loss: 1.9896\n",
      "[324/1762] D loss: 1.6541, G loss: 1.0773\n",
      "[644/1762] D loss: 1.4120, G loss: 0.5623\n",
      "[964/1762] D loss: 1.3984, G loss: 0.8354\n",
      "[1284/1762] D loss: 1.4735, G loss: 0.6202\n",
      "[1604/1762] D loss: 1.4576, G loss: 0.9144\n",
      "[1924/1762] D loss: 1.4063, G loss: 0.7087\n",
      "[2244/1762] D loss: 1.4839, G loss: 0.5635\n",
      "[2564/1762] D loss: 0.2824, G loss: 1.9697\n",
      "[2884/1762] D loss: 0.4267, G loss: 1.1103\n",
      "[3204/1762] D loss: 1.3631, G loss: 0.5611\n",
      "[3524/1762] D loss: 0.5369, G loss: 1.1404\n",
      "[3844/1762] D loss: 0.4556, G loss: 1.0938\n",
      "[4164/1762] D loss: 1.4137, G loss: 0.5576\n",
      "[4484/1762] D loss: 1.4823, G loss: 0.9307\n",
      "[4804/1762] D loss: 0.5160, G loss: 0.9717\n",
      "[5124/1762] D loss: 1.3941, G loss: 0.5589\n",
      "[5444/1762] D loss: 1.4308, G loss: 0.6764\n",
      "[5764/1762] D loss: 2.6745, G loss: 0.6563\n",
      "[6084/1762] D loss: 1.6519, G loss: 1.5132\n",
      "[6404/1762] D loss: 0.8353, G loss: 1.3412\n",
      "[6724/1762] D loss: 0.8512, G loss: 1.2996\n",
      "[7042/1762] D loss: 0.5102, G loss: 1.2838\n",
      "train error: \n",
      " D loss: 1.346709, G loss: 0.740368, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333528, G loss: 0.744464, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4290, G loss: 0.8063\n",
      "[324/1762] D loss: 1.4032, G loss: 0.7837\n",
      "[644/1762] D loss: 1.4096, G loss: 0.8633\n",
      "[964/1762] D loss: 1.3971, G loss: 0.7378\n",
      "[1284/1762] D loss: 1.3216, G loss: 0.9744\n",
      "[1604/1762] D loss: 0.6799, G loss: 0.9676\n",
      "[1924/1762] D loss: 1.4102, G loss: 0.8592\n",
      "[2244/1762] D loss: 1.3989, G loss: 0.6200\n",
      "[2564/1762] D loss: 1.3864, G loss: 0.7396\n",
      "[2884/1762] D loss: 1.5104, G loss: 1.0396\n",
      "[3204/1762] D loss: 1.4337, G loss: 0.6457\n",
      "[3524/1762] D loss: 1.4014, G loss: 0.7052\n",
      "[3844/1762] D loss: 1.5291, G loss: 0.4163\n",
      "[4164/1762] D loss: 1.3921, G loss: 0.7982\n",
      "[4484/1762] D loss: 1.5162, G loss: 0.7574\n",
      "[4804/1762] D loss: 1.1264, G loss: 1.2389\n",
      "[5124/1762] D loss: 1.4781, G loss: 0.9724\n",
      "[5444/1762] D loss: 0.6456, G loss: 1.0403\n",
      "[5764/1762] D loss: 0.4663, G loss: 1.6278\n",
      "[6084/1762] D loss: 1.4060, G loss: 0.7797\n",
      "[6404/1762] D loss: 1.3944, G loss: 0.8166\n",
      "[6724/1762] D loss: 1.4957, G loss: 0.9233\n",
      "[7042/1762] D loss: 0.0255, G loss: 3.9520\n",
      "train error: \n",
      " D loss: 1.540790, G loss: 0.370933, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.512785, G loss: 0.385292, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4389, G loss: 0.5375\n",
      "[324/1762] D loss: 1.3913, G loss: 0.5658\n",
      "[644/1762] D loss: 0.5066, G loss: 1.2408\n",
      "[964/1762] D loss: 1.4236, G loss: 0.8425\n",
      "[1284/1762] D loss: 1.6628, G loss: 0.3306\n",
      "[1604/1762] D loss: 1.7721, G loss: 1.3306\n",
      "[1924/1762] D loss: 1.3432, G loss: 0.6578\n",
      "[2244/1762] D loss: 1.4205, G loss: 0.9215\n",
      "[2564/1762] D loss: 1.4213, G loss: 0.5939\n",
      "[2884/1762] D loss: 1.5130, G loss: 1.0124\n",
      "[3204/1762] D loss: 1.4694, G loss: 0.4662\n",
      "[3524/1762] D loss: 1.4063, G loss: 0.7316\n",
      "[3844/1762] D loss: 1.3051, G loss: 0.9547\n",
      "[4164/1762] D loss: 0.5391, G loss: 1.0736\n",
      "[4484/1762] D loss: 0.4264, G loss: 1.6110\n",
      "[4804/1762] D loss: 0.1784, G loss: 2.3037\n",
      "[5124/1762] D loss: 1.4048, G loss: 0.5475\n",
      "[5444/1762] D loss: 1.4209, G loss: 0.5945\n",
      "[5764/1762] D loss: 1.3912, G loss: 0.8898\n",
      "[6084/1762] D loss: 1.1277, G loss: 0.7722\n",
      "[6404/1762] D loss: 1.2705, G loss: 1.0564\n",
      "[6724/1762] D loss: 1.5152, G loss: 1.0513\n",
      "[7042/1762] D loss: 1.4919, G loss: 0.8879\n",
      "train error: \n",
      " D loss: 1.376106, G loss: 0.538268, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371389, G loss: 0.540716, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4985, G loss: 0.4295\n",
      "[324/1762] D loss: 1.4066, G loss: 0.6932\n",
      "[644/1762] D loss: 1.5335, G loss: 1.0887\n",
      "[964/1762] D loss: 1.6165, G loss: 1.2416\n",
      "[1284/1762] D loss: 1.4050, G loss: 0.7157\n",
      "[1604/1762] D loss: 1.4307, G loss: 0.8071\n",
      "[1924/1762] D loss: 1.3947, G loss: 0.6572\n",
      "[2244/1762] D loss: 1.4030, G loss: 0.7979\n",
      "[2564/1762] D loss: 1.4120, G loss: 1.6910\n",
      "[2884/1762] D loss: 0.1670, G loss: 2.3245\n",
      "[3204/1762] D loss: 1.4985, G loss: 0.8505\n",
      "[3524/1762] D loss: 0.1932, G loss: 2.3083\n",
      "[3844/1762] D loss: 0.2056, G loss: 1.8519\n",
      "[4164/1762] D loss: 1.3826, G loss: 0.9797\n",
      "[4484/1762] D loss: 1.2805, G loss: 0.9353\n",
      "[4804/1762] D loss: 1.4187, G loss: 0.5767\n",
      "[5124/1762] D loss: 1.4427, G loss: 1.0197\n",
      "[5444/1762] D loss: 1.4413, G loss: 0.6450\n",
      "[5764/1762] D loss: 1.3983, G loss: 0.6471\n",
      "[6084/1762] D loss: 0.2364, G loss: 1.8609\n",
      "[6404/1762] D loss: 1.4159, G loss: 0.7206\n",
      "[6724/1762] D loss: 1.4845, G loss: 1.0530\n",
      "[7042/1762] D loss: 1.4037, G loss: 0.8133\n",
      "train error: \n",
      " D loss: 1.314116, G loss: 0.758384, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296589, G loss: 0.775138, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4292, G loss: 0.6290\n",
      "[324/1762] D loss: 1.4333, G loss: 0.8337\n",
      "[644/1762] D loss: 0.2089, G loss: 2.1047\n",
      "[964/1762] D loss: 1.5309, G loss: 1.1789\n",
      "[1284/1762] D loss: 0.0795, G loss: 2.9337\n",
      "[1604/1762] D loss: 1.4321, G loss: 0.9717\n",
      "[1924/1762] D loss: 1.4622, G loss: 0.8323\n",
      "[2244/1762] D loss: 0.4585, G loss: 1.1478\n",
      "[2564/1762] D loss: 1.5324, G loss: 0.4328\n",
      "[2884/1762] D loss: 1.3661, G loss: 0.7485\n",
      "[3204/1762] D loss: 1.4909, G loss: 1.0447\n",
      "[3524/1762] D loss: 1.3978, G loss: 0.7859\n",
      "[3844/1762] D loss: 1.3754, G loss: 1.5398\n",
      "[4164/1762] D loss: 1.4194, G loss: 0.6858\n",
      "[4484/1762] D loss: 0.3984, G loss: 1.3224\n",
      "[4804/1762] D loss: 1.4285, G loss: 0.7482\n",
      "[5124/1762] D loss: 1.6740, G loss: 1.3930\n",
      "[5444/1762] D loss: 0.4598, G loss: 1.2647\n",
      "[5764/1762] D loss: 1.3785, G loss: 0.8991\n",
      "[6084/1762] D loss: 0.2677, G loss: 1.7300\n",
      "[6404/1762] D loss: 0.2726, G loss: 1.5441\n",
      "[6724/1762] D loss: 0.0684, G loss: 2.8695\n",
      "[7042/1762] D loss: 1.1087, G loss: 1.0006\n",
      "train error: \n",
      " D loss: 1.269689, G loss: 0.675138, D accuracy: 61.9%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255377, G loss: 0.688870, D accuracy: 62.5%, cell accuracy: 99.6%, board accuracy: 72.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4054, G loss: 0.6466\n",
      "[324/1762] D loss: 0.8675, G loss: 1.9287\n",
      "[644/1762] D loss: 2.5693, G loss: 0.7356\n",
      "[964/1762] D loss: 1.4240, G loss: 0.8664\n",
      "[1284/1762] D loss: 1.2762, G loss: 0.7889\n",
      "[1604/1762] D loss: 1.3800, G loss: 0.6082\n",
      "[1924/1762] D loss: 1.4173, G loss: 0.7832\n",
      "[2244/1762] D loss: 1.3892, G loss: 0.7736\n",
      "[2564/1762] D loss: 1.1070, G loss: 0.9170\n",
      "[2884/1762] D loss: 1.4239, G loss: 0.5586\n",
      "[3204/1762] D loss: 1.4083, G loss: 0.8144\n",
      "[3524/1762] D loss: 1.3996, G loss: 0.7581\n",
      "[3844/1762] D loss: 1.4011, G loss: 0.6834\n",
      "[4164/1762] D loss: 1.3196, G loss: 0.8080\n",
      "[4484/1762] D loss: 1.3922, G loss: 0.6847\n",
      "[4804/1762] D loss: 1.0307, G loss: 1.0409\n",
      "[5124/1762] D loss: 1.0176, G loss: 0.7831\n",
      "[5444/1762] D loss: 1.3681, G loss: 0.8062\n",
      "[5764/1762] D loss: 1.4334, G loss: 0.9255\n",
      "[6084/1762] D loss: 1.4210, G loss: 0.7995\n",
      "[6404/1762] D loss: 0.7168, G loss: 1.1203\n",
      "[6724/1762] D loss: 1.4214, G loss: 0.7414\n",
      "[7042/1762] D loss: 0.5929, G loss: 1.7343\n",
      "train error: \n",
      " D loss: 1.371757, G loss: 0.657768, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375591, G loss: 0.670284, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 83.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2962, G loss: 1.1416\n",
      "[324/1762] D loss: 0.6164, G loss: 1.5377\n",
      "[644/1762] D loss: 1.3908, G loss: 0.5646\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6865\n",
      "[1284/1762] D loss: 1.4139, G loss: 0.6802\n",
      "[1604/1762] D loss: 1.3850, G loss: 0.6993\n",
      "[1924/1762] D loss: 1.5062, G loss: 0.6849\n",
      "[2244/1762] D loss: 1.6154, G loss: 1.1924\n",
      "[2564/1762] D loss: 1.4750, G loss: 1.0705\n",
      "[2884/1762] D loss: 0.6884, G loss: 1.8527\n",
      "[3204/1762] D loss: 0.7958, G loss: 0.8068\n",
      "[3524/1762] D loss: 0.6299, G loss: 1.0611\n",
      "[3844/1762] D loss: 1.4595, G loss: 1.0044\n",
      "[4164/1762] D loss: 1.3748, G loss: 0.8677\n",
      "[4484/1762] D loss: 1.3935, G loss: 0.6315\n",
      "[4804/1762] D loss: 1.1893, G loss: 1.1333\n",
      "[5124/1762] D loss: 0.3739, G loss: 1.6867\n",
      "[5444/1762] D loss: 1.4645, G loss: 0.7692\n",
      "[5764/1762] D loss: 1.4061, G loss: 0.7651\n",
      "[6084/1762] D loss: 0.4717, G loss: 1.6924\n",
      "[6404/1762] D loss: 1.4147, G loss: 0.8210\n",
      "[6724/1762] D loss: 1.3991, G loss: 0.5793\n",
      "[7042/1762] D loss: 1.8232, G loss: 0.2630\n",
      "train error: \n",
      " D loss: 1.863508, G loss: 0.232000, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.824363, G loss: 0.241095, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6372, G loss: 0.4187\n",
      "[324/1762] D loss: 1.3947, G loss: 0.8004\n",
      "[644/1762] D loss: 0.5005, G loss: 1.1352\n",
      "[964/1762] D loss: 1.4277, G loss: 0.8863\n",
      "[1284/1762] D loss: 0.5233, G loss: 0.9351\n",
      "[1604/1762] D loss: 0.4663, G loss: 1.1304\n",
      "[1924/1762] D loss: 0.3986, G loss: 1.3267\n",
      "[2244/1762] D loss: 0.2181, G loss: 1.9386\n",
      "[2564/1762] D loss: 0.2041, G loss: 2.0731\n",
      "[2884/1762] D loss: 1.4453, G loss: 0.8364\n",
      "[3204/1762] D loss: 0.4665, G loss: 1.3287\n",
      "[3524/1762] D loss: 0.1219, G loss: 2.7329\n",
      "[3844/1762] D loss: 1.4096, G loss: 0.7990\n",
      "[4164/1762] D loss: 0.2958, G loss: 1.4363\n",
      "[4484/1762] D loss: 0.2882, G loss: 1.8284\n",
      "[4804/1762] D loss: 1.4248, G loss: 0.7879\n",
      "[5124/1762] D loss: 2.2510, G loss: 0.6809\n",
      "[5444/1762] D loss: 0.9377, G loss: 2.0173\n",
      "[5764/1762] D loss: 1.2329, G loss: 0.7070\n",
      "[6084/1762] D loss: 1.4478, G loss: 0.7179\n",
      "[6404/1762] D loss: 1.4010, G loss: 0.7745\n",
      "[6724/1762] D loss: 0.8846, G loss: 1.0541\n",
      "[7042/1762] D loss: 0.5474, G loss: 1.2886\n",
      "train error: \n",
      " D loss: 1.369445, G loss: 0.589967, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356692, G loss: 0.608504, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4081, G loss: 0.5865\n",
      "[324/1762] D loss: 0.7495, G loss: 1.1602\n",
      "[644/1762] D loss: 1.4302, G loss: 0.6549\n",
      "[964/1762] D loss: 0.5887, G loss: 1.2628\n",
      "[1284/1762] D loss: 0.6794, G loss: 0.9553\n",
      "[1604/1762] D loss: 1.4459, G loss: 0.5186\n",
      "[1924/1762] D loss: 1.3949, G loss: 0.7989\n",
      "[2244/1762] D loss: 0.4835, G loss: 1.3807\n",
      "[2564/1762] D loss: 1.4217, G loss: 0.8269\n",
      "[2884/1762] D loss: 0.7948, G loss: 0.8811\n",
      "[3204/1762] D loss: 0.7102, G loss: 1.0889\n",
      "[3524/1762] D loss: 1.6657, G loss: 0.4954\n",
      "[3844/1762] D loss: 1.5262, G loss: 0.4812\n",
      "[4164/1762] D loss: 0.6912, G loss: 1.1009\n",
      "[4484/1762] D loss: 0.4615, G loss: 1.4074\n",
      "[4804/1762] D loss: 1.5753, G loss: 0.4705\n",
      "[5124/1762] D loss: 0.3499, G loss: 1.7173\n",
      "[5444/1762] D loss: 1.4869, G loss: 0.9259\n",
      "[5764/1762] D loss: 1.3971, G loss: 0.7391\n",
      "[6084/1762] D loss: 1.3941, G loss: 0.7277\n",
      "[6404/1762] D loss: 0.2879, G loss: 1.6622\n",
      "[6724/1762] D loss: 1.0936, G loss: 0.9605\n",
      "[7042/1762] D loss: 1.4891, G loss: 0.5073\n",
      "train error: \n",
      " D loss: 1.328018, G loss: 0.687304, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305209, G loss: 0.704036, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4470, G loss: 1.3354\n",
      "[324/1762] D loss: 1.4014, G loss: 0.8637\n",
      "[644/1762] D loss: 1.4763, G loss: 0.9664\n",
      "[964/1762] D loss: 1.4121, G loss: 0.6034\n",
      "[1284/1762] D loss: 1.4081, G loss: 0.5091\n",
      "[1604/1762] D loss: 1.4534, G loss: 0.4532\n",
      "[1924/1762] D loss: 1.4690, G loss: 0.5220\n",
      "[2244/1762] D loss: 1.3994, G loss: 0.7286\n",
      "[2564/1762] D loss: 0.2243, G loss: 1.9527\n",
      "[2884/1762] D loss: 1.4164, G loss: 0.8256\n",
      "[3204/1762] D loss: 1.0545, G loss: 1.0020\n",
      "[3524/1762] D loss: 0.5657, G loss: 1.1237\n",
      "[3844/1762] D loss: 1.4621, G loss: 0.5064\n",
      "[4164/1762] D loss: 1.1326, G loss: 1.0455\n",
      "[4484/1762] D loss: 1.4507, G loss: 0.9696\n",
      "[4804/1762] D loss: 1.4319, G loss: 0.7795\n",
      "[5124/1762] D loss: 1.4353, G loss: 0.9320\n",
      "[5444/1762] D loss: 0.5132, G loss: 1.7685\n",
      "[5764/1762] D loss: 1.4743, G loss: 0.6026\n",
      "[6084/1762] D loss: 1.4725, G loss: 0.5449\n",
      "[6404/1762] D loss: 1.3815, G loss: 0.8170\n",
      "[6724/1762] D loss: 0.3684, G loss: 1.6021\n",
      "[7042/1762] D loss: 0.8911, G loss: 1.5214\n",
      "train error: \n",
      " D loss: 1.258726, G loss: 0.918090, D accuracy: 58.1%, cell accuracy: 99.7%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.223858, G loss: 0.997635, D accuracy: 59.9%, cell accuracy: 99.6%, board accuracy: 80.6% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4106, G loss: 0.6790\n",
      "[324/1762] D loss: 1.4393, G loss: 2.1370\n",
      "[644/1762] D loss: 0.5567, G loss: 1.2738\n",
      "[964/1762] D loss: 1.4395, G loss: 0.4786\n",
      "[1284/1762] D loss: 1.4586, G loss: 0.7974\n",
      "[1604/1762] D loss: 1.2445, G loss: 0.7350\n",
      "[1924/1762] D loss: 1.3929, G loss: 0.6928\n",
      "[2244/1762] D loss: 1.4200, G loss: 0.5850\n",
      "[2564/1762] D loss: 1.2538, G loss: 0.7980\n",
      "[2884/1762] D loss: 1.2499, G loss: 0.8604\n",
      "[3204/1762] D loss: 1.3984, G loss: 0.7972\n",
      "[3524/1762] D loss: 1.4507, G loss: 0.9781\n",
      "[3844/1762] D loss: 1.4381, G loss: 0.9727\n",
      "[4164/1762] D loss: 1.3910, G loss: 0.7223\n",
      "[4484/1762] D loss: 1.4160, G loss: 0.8115\n",
      "[4804/1762] D loss: 0.2568, G loss: 1.9473\n",
      "[5124/1762] D loss: 1.4641, G loss: 0.9180\n",
      "[5444/1762] D loss: 1.3760, G loss: 0.6923\n",
      "[5764/1762] D loss: 0.5004, G loss: 1.2636\n",
      "[6084/1762] D loss: 0.2565, G loss: 2.1993\n",
      "[6404/1762] D loss: 1.4615, G loss: 0.7544\n",
      "[6724/1762] D loss: 1.5249, G loss: 0.9033\n",
      "[7042/1762] D loss: 0.0470, G loss: 3.3432\n",
      "train error: \n",
      " D loss: 1.461185, G loss: 0.451699, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.436193, G loss: 0.472406, D accuracy: 57.0%, cell accuracy: 99.6%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3937, G loss: 0.5195\n",
      "[324/1762] D loss: 1.4177, G loss: 0.7381\n",
      "[644/1762] D loss: 0.1421, G loss: 2.7395\n",
      "[964/1762] D loss: 1.4104, G loss: 0.7739\n",
      "[1284/1762] D loss: 1.4064, G loss: 0.5796\n",
      "[1604/1762] D loss: 1.3618, G loss: 0.7519\n",
      "[1924/1762] D loss: 0.2541, G loss: 1.8870\n",
      "[2244/1762] D loss: 1.4262, G loss: 0.6512\n",
      "[2564/1762] D loss: 1.4518, G loss: 0.5937\n",
      "[2884/1762] D loss: 1.4134, G loss: 0.7229\n",
      "[3204/1762] D loss: 1.5870, G loss: 1.1885\n",
      "[3524/1762] D loss: 0.2627, G loss: 2.0373\n",
      "[3844/1762] D loss: 0.6766, G loss: 1.8417\n",
      "[4164/1762] D loss: 1.4879, G loss: 0.5355\n",
      "[4484/1762] D loss: 0.7962, G loss: 1.3355\n",
      "[4804/1762] D loss: 1.4528, G loss: 0.9319\n",
      "[5124/1762] D loss: 1.3900, G loss: 0.7018\n",
      "[5444/1762] D loss: 1.4449, G loss: 0.8393\n",
      "[5764/1762] D loss: 1.3215, G loss: 0.9136\n",
      "[6084/1762] D loss: 1.4018, G loss: 0.6256\n",
      "[6404/1762] D loss: 1.4109, G loss: 0.8380\n",
      "[6724/1762] D loss: 0.2245, G loss: 2.0937\n",
      "[7042/1762] D loss: 0.1383, G loss: 2.6551\n",
      "train error: \n",
      " D loss: 1.262772, G loss: 0.766034, D accuracy: 63.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.235536, G loss: 0.802179, D accuracy: 64.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2929, G loss: 2.0746\n",
      "[324/1762] D loss: 0.4984, G loss: 1.0929\n",
      "[644/1762] D loss: 1.4835, G loss: 1.0507\n",
      "[964/1762] D loss: 1.4039, G loss: 0.6563\n",
      "[1284/1762] D loss: 1.4531, G loss: 0.6427\n",
      "[1604/1762] D loss: 1.4086, G loss: 0.8672\n",
      "[1924/1762] D loss: 0.2005, G loss: 2.2084\n",
      "[2244/1762] D loss: 1.3849, G loss: 0.6694\n",
      "[2564/1762] D loss: 0.2724, G loss: 1.8280\n",
      "[2884/1762] D loss: 1.4411, G loss: 0.8779\n",
      "[3204/1762] D loss: 0.3354, G loss: 1.7632\n",
      "[3524/1762] D loss: 1.3712, G loss: 0.6601\n",
      "[3844/1762] D loss: 1.3989, G loss: 0.6533\n",
      "[4164/1762] D loss: 0.0204, G loss: 6.1980\n",
      "[4484/1762] D loss: 1.4255, G loss: 0.4652\n",
      "[4804/1762] D loss: 0.2400, G loss: 1.8871\n",
      "[5124/1762] D loss: 1.4160, G loss: 0.8593\n",
      "[5444/1762] D loss: 1.1987, G loss: 1.5340\n",
      "[5764/1762] D loss: 1.4685, G loss: 0.8554\n",
      "[6084/1762] D loss: 0.1680, G loss: 2.1970\n",
      "[6404/1762] D loss: 0.2647, G loss: 1.9037\n",
      "[6724/1762] D loss: 1.4275, G loss: 0.9027\n",
      "[7042/1762] D loss: 1.4225, G loss: 0.5042\n",
      "train error: \n",
      " D loss: 1.315217, G loss: 0.721332, D accuracy: 55.0%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285026, G loss: 0.739073, D accuracy: 56.8%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3178, G loss: 1.4758\n",
      "[324/1762] D loss: 1.4162, G loss: 0.5992\n",
      "[644/1762] D loss: 0.1503, G loss: 2.3222\n",
      "[964/1762] D loss: 1.3901, G loss: 0.6952\n",
      "[1284/1762] D loss: 0.0328, G loss: 4.2838\n",
      "[1604/1762] D loss: 0.1936, G loss: 2.3576\n",
      "[1924/1762] D loss: 1.5235, G loss: 1.0572\n",
      "[2244/1762] D loss: 1.4836, G loss: 0.8230\n",
      "[2564/1762] D loss: 1.4304, G loss: 0.8485\n",
      "[2884/1762] D loss: 1.4439, G loss: 0.9286\n",
      "[3204/1762] D loss: 1.3849, G loss: 0.6119\n",
      "[3524/1762] D loss: 1.4370, G loss: 0.7222\n",
      "[3844/1762] D loss: 1.9993, G loss: 1.6374\n",
      "[4164/1762] D loss: 1.4023, G loss: 0.6974\n",
      "[4484/1762] D loss: 1.4043, G loss: 0.6991\n",
      "[4804/1762] D loss: 1.4216, G loss: 0.9127\n",
      "[5124/1762] D loss: 1.3968, G loss: 0.7449\n",
      "[5444/1762] D loss: 1.4090, G loss: 0.6627\n",
      "[5764/1762] D loss: 0.0422, G loss: 3.8543\n",
      "[6084/1762] D loss: 1.4730, G loss: 0.7999\n",
      "[6404/1762] D loss: 1.4238, G loss: 0.9189\n",
      "[6724/1762] D loss: 1.3292, G loss: 1.0148\n",
      "[7042/1762] D loss: 1.4401, G loss: 0.5614\n",
      "train error: \n",
      " D loss: 1.392318, G loss: 0.528159, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354847, G loss: 0.579845, D accuracy: 57.6%, cell accuracy: 99.8%, board accuracy: 81.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0503, G loss: 4.0138\n",
      "[324/1762] D loss: 0.0332, G loss: 4.3649\n",
      "[644/1762] D loss: 1.4038, G loss: 0.8439\n",
      "[964/1762] D loss: 0.1367, G loss: 2.3088\n",
      "[1284/1762] D loss: 1.3972, G loss: 0.8109\n",
      "[1604/1762] D loss: 0.1709, G loss: 2.1433\n",
      "[1924/1762] D loss: 1.3459, G loss: 0.7769\n",
      "[2244/1762] D loss: 0.0193, G loss: 5.0162\n",
      "[2564/1762] D loss: 1.4042, G loss: 0.6040\n",
      "[2884/1762] D loss: 1.4075, G loss: 0.7411\n",
      "[3204/1762] D loss: 1.4865, G loss: 1.0548\n",
      "[3524/1762] D loss: 1.4423, G loss: 0.6087\n",
      "[3844/1762] D loss: 1.4445, G loss: 0.8921\n",
      "[4164/1762] D loss: 1.4169, G loss: 0.8327\n",
      "[4484/1762] D loss: 1.3921, G loss: 0.7307\n",
      "[4804/1762] D loss: 0.1033, G loss: 2.9997\n",
      "[5124/1762] D loss: 0.1649, G loss: 2.3789\n",
      "[5444/1762] D loss: 0.0232, G loss: 5.8161\n",
      "[5764/1762] D loss: 1.3986, G loss: 0.5574\n",
      "[6084/1762] D loss: 1.3751, G loss: 0.7725\n",
      "[6404/1762] D loss: 1.4338, G loss: 0.7133\n",
      "[6724/1762] D loss: 1.5148, G loss: 1.0765\n",
      "[7042/1762] D loss: 1.5401, G loss: 0.5532\n",
      "train error: \n",
      " D loss: 1.227702, G loss: 0.978773, D accuracy: 59.9%, cell accuracy: 99.7%, board accuracy: 79.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.203159, G loss: 0.987097, D accuracy: 61.8%, cell accuracy: 99.7%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3742, G loss: 0.9539\n",
      "[324/1762] D loss: 1.4935, G loss: 1.0155\n",
      "[644/1762] D loss: 1.2392, G loss: 0.7305\n",
      "[964/1762] D loss: 1.4462, G loss: 0.9270\n",
      "[1284/1762] D loss: 1.4033, G loss: 0.6164\n",
      "[1604/1762] D loss: 1.4313, G loss: 0.9525\n",
      "[1924/1762] D loss: 1.4872, G loss: 1.0208\n",
      "[2244/1762] D loss: 0.1750, G loss: 1.9743\n",
      "[2564/1762] D loss: 0.1413, G loss: 2.4658\n",
      "[2884/1762] D loss: 0.1445, G loss: 2.7743\n",
      "[3204/1762] D loss: 0.1250, G loss: 2.8695\n",
      "[3524/1762] D loss: 0.1029, G loss: 2.7873\n",
      "[3844/1762] D loss: 1.4021, G loss: 0.7782\n",
      "[4164/1762] D loss: 1.6401, G loss: 1.0331\n",
      "[4484/1762] D loss: 0.3345, G loss: 1.7021\n",
      "[4804/1762] D loss: 0.2078, G loss: 1.9776\n",
      "[5124/1762] D loss: 1.4383, G loss: 0.8718\n",
      "[5444/1762] D loss: 1.3875, G loss: 0.6938\n",
      "[5764/1762] D loss: 0.2335, G loss: 2.2525\n",
      "[6084/1762] D loss: 1.3847, G loss: 0.7053\n",
      "[6404/1762] D loss: 1.3908, G loss: 0.7487\n",
      "[6724/1762] D loss: 1.2707, G loss: 0.5961\n",
      "[7042/1762] D loss: 1.3895, G loss: 0.7614\n",
      "train error: \n",
      " D loss: 1.310010, G loss: 0.841158, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285996, G loss: 0.896613, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4225, G loss: 0.7956\n",
      "[324/1762] D loss: 1.3842, G loss: 0.7960\n",
      "[644/1762] D loss: 1.4290, G loss: 0.7929\n",
      "[964/1762] D loss: 1.4044, G loss: 0.7274\n",
      "[1284/1762] D loss: 1.4555, G loss: 0.5411\n",
      "[1604/1762] D loss: 1.4023, G loss: 0.8635\n",
      "[1924/1762] D loss: 1.0939, G loss: 2.3807\n",
      "[2244/1762] D loss: 0.2373, G loss: 1.6105\n",
      "[2564/1762] D loss: 1.4500, G loss: 0.5145\n",
      "[2884/1762] D loss: 1.3872, G loss: 0.8007\n",
      "[3204/1762] D loss: 1.2839, G loss: 0.8163\n",
      "[3524/1762] D loss: 1.3958, G loss: 0.7025\n",
      "[3844/1762] D loss: 1.4343, G loss: 0.8320\n",
      "[4164/1762] D loss: 1.4672, G loss: 0.4850\n",
      "[4484/1762] D loss: 1.3843, G loss: 0.6426\n",
      "[4804/1762] D loss: 1.4233, G loss: 0.7892\n",
      "[5124/1762] D loss: 0.0829, G loss: 3.2058\n",
      "[5444/1762] D loss: 1.4081, G loss: 0.7285\n",
      "[5764/1762] D loss: 1.1886, G loss: 1.2562\n",
      "[6084/1762] D loss: 0.7441, G loss: 1.4863\n",
      "[6404/1762] D loss: 1.4809, G loss: 0.9696\n",
      "[6724/1762] D loss: 1.5206, G loss: 0.7506\n",
      "[7042/1762] D loss: 1.4466, G loss: 0.6622\n",
      "train error: \n",
      " D loss: 1.436681, G loss: 1.312142, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404661, G loss: 1.385811, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4318, G loss: 0.9122\n",
      "[324/1762] D loss: 1.4207, G loss: 0.7787\n",
      "[644/1762] D loss: 0.4754, G loss: 1.3206\n",
      "[964/1762] D loss: 0.5658, G loss: 1.1900\n",
      "[1284/1762] D loss: 1.4194, G loss: 0.6208\n",
      "[1604/1762] D loss: 1.2201, G loss: 0.8170\n",
      "[1924/1762] D loss: 1.3884, G loss: 0.7229\n",
      "[2244/1762] D loss: 1.3063, G loss: 0.9760\n",
      "[2564/1762] D loss: 1.4159, G loss: 0.6943\n",
      "[2884/1762] D loss: 1.4535, G loss: 0.5465\n",
      "[3204/1762] D loss: 0.1526, G loss: 2.5944\n",
      "[3524/1762] D loss: 1.4553, G loss: 0.6306\n",
      "[3844/1762] D loss: 1.5688, G loss: 1.0597\n",
      "[4164/1762] D loss: 0.2019, G loss: 2.2164\n",
      "[4484/1762] D loss: 1.2576, G loss: 0.8220\n",
      "[4804/1762] D loss: 0.1990, G loss: 2.3158\n",
      "[5124/1762] D loss: 1.4027, G loss: 0.5836\n",
      "[5444/1762] D loss: 1.3958, G loss: 0.7477\n",
      "[5764/1762] D loss: 0.0019, G loss: 7.9697\n",
      "[6084/1762] D loss: 1.3825, G loss: 0.7249\n",
      "[6404/1762] D loss: 1.4138, G loss: 0.6361\n",
      "[6724/1762] D loss: 1.4014, G loss: 0.5856\n",
      "[7042/1762] D loss: 1.4595, G loss: 0.8546\n",
      "train error: \n",
      " D loss: 1.342870, G loss: 0.698299, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306177, G loss: 0.764230, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4504, G loss: 0.5834\n",
      "[324/1762] D loss: 1.1447, G loss: 0.9783\n",
      "[644/1762] D loss: 1.4597, G loss: 0.8772\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7983\n",
      "[1284/1762] D loss: 1.4301, G loss: 0.8072\n",
      "[1604/1762] D loss: 1.4374, G loss: 0.7312\n",
      "[1924/1762] D loss: 1.3945, G loss: 0.6676\n",
      "[2244/1762] D loss: 0.0131, G loss: 5.5450\n",
      "[2564/1762] D loss: 1.3068, G loss: 0.9658\n",
      "[2884/1762] D loss: 1.3785, G loss: 0.8799\n",
      "[3204/1762] D loss: 0.1513, G loss: 2.6101\n",
      "[3524/1762] D loss: 2.3154, G loss: 1.4066\n",
      "[3844/1762] D loss: 1.3357, G loss: 0.9235\n",
      "[4164/1762] D loss: 1.4413, G loss: 0.8619\n",
      "[4484/1762] D loss: 1.3977, G loss: 0.5653\n",
      "[4804/1762] D loss: 1.3931, G loss: 0.6490\n",
      "[5124/1762] D loss: 0.2262, G loss: 1.9948\n",
      "[5444/1762] D loss: 1.4154, G loss: 0.7953\n",
      "[5764/1762] D loss: 0.0241, G loss: 4.7029\n",
      "[6084/1762] D loss: 1.4435, G loss: 1.0598\n",
      "[6404/1762] D loss: 1.4196, G loss: 0.4866\n",
      "[6724/1762] D loss: 0.2827, G loss: 1.8653\n",
      "[7042/1762] D loss: 1.2000, G loss: 2.1432\n",
      "train error: \n",
      " D loss: 1.159520, G loss: 1.649773, D accuracy: 64.2%, cell accuracy: 99.5%, board accuracy: 75.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.135430, G loss: 1.681652, D accuracy: 65.0%, cell accuracy: 99.4%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3754, G loss: 0.5738\n",
      "[324/1762] D loss: 1.3909, G loss: 0.5842\n",
      "[644/1762] D loss: 1.3939, G loss: 0.7698\n",
      "[964/1762] D loss: 0.0915, G loss: 4.2302\n",
      "[1284/1762] D loss: 0.2029, G loss: 2.0922\n",
      "[1604/1762] D loss: 1.4325, G loss: 0.5070\n",
      "[1924/1762] D loss: 1.4033, G loss: 0.6412\n",
      "[2244/1762] D loss: 1.4046, G loss: 0.7396\n",
      "[2564/1762] D loss: 1.3604, G loss: 0.8166\n",
      "[2884/1762] D loss: 1.4627, G loss: 0.5193\n",
      "[3204/1762] D loss: 1.3805, G loss: 0.6871\n",
      "[3524/1762] D loss: 1.3879, G loss: 0.6102\n",
      "[3844/1762] D loss: 1.4050, G loss: 0.7791\n",
      "[4164/1762] D loss: 1.4199, G loss: 0.7206\n",
      "[4484/1762] D loss: 1.4272, G loss: 0.5312\n",
      "[4804/1762] D loss: 1.4162, G loss: 0.8419\n",
      "[5124/1762] D loss: 1.3910, G loss: 0.6154\n",
      "[5444/1762] D loss: 0.2270, G loss: 2.4551\n",
      "[5764/1762] D loss: 0.0784, G loss: 3.1345\n",
      "[6084/1762] D loss: 0.1733, G loss: 2.5401\n",
      "[6404/1762] D loss: 1.4191, G loss: 0.7494\n",
      "[6724/1762] D loss: 1.4368, G loss: 0.9418\n",
      "[7042/1762] D loss: 0.4540, G loss: 3.9991\n",
      "train error: \n",
      " D loss: 1.362903, G loss: 1.219198, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334886, G loss: 1.342631, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4084, G loss: 0.7128\n",
      "[324/1762] D loss: 1.4196, G loss: 0.6692\n",
      "[644/1762] D loss: 1.3975, G loss: 0.6155\n",
      "[964/1762] D loss: 1.2821, G loss: 0.8525\n",
      "[1284/1762] D loss: 0.3764, G loss: 1.5106\n",
      "[1604/1762] D loss: 0.2369, G loss: 2.7911\n",
      "[1924/1762] D loss: 1.4426, G loss: 0.7378\n",
      "[2244/1762] D loss: 1.4409, G loss: 0.9352\n",
      "[2564/1762] D loss: 0.9550, G loss: 1.2655\n",
      "[2884/1762] D loss: 1.3977, G loss: 0.5519\n",
      "[3204/1762] D loss: 1.4038, G loss: 0.7556\n",
      "[3524/1762] D loss: 1.5569, G loss: 1.2107\n",
      "[3844/1762] D loss: 1.4376, G loss: 0.6865\n",
      "[4164/1762] D loss: 1.4829, G loss: 0.8432\n",
      "[4484/1762] D loss: 1.4162, G loss: 0.8659\n",
      "[4804/1762] D loss: 1.3924, G loss: 0.6953\n",
      "[5124/1762] D loss: 1.4973, G loss: 0.6721\n",
      "[5444/1762] D loss: 1.4668, G loss: 0.4971\n",
      "[5764/1762] D loss: 1.4087, G loss: 0.8557\n",
      "[6084/1762] D loss: 1.4208, G loss: 0.8611\n",
      "[6404/1762] D loss: 1.3999, G loss: 0.7466\n",
      "[6724/1762] D loss: 1.4065, G loss: 0.7729\n",
      "[7042/1762] D loss: 1.3935, G loss: 0.6738\n",
      "train error: \n",
      " D loss: 1.361074, G loss: 0.727901, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339387, G loss: 0.795051, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4414, G loss: 0.4994\n",
      "[324/1762] D loss: 1.3939, G loss: 0.7930\n",
      "[644/1762] D loss: 1.3967, G loss: 0.7825\n",
      "[964/1762] D loss: 1.4227, G loss: 0.8611\n",
      "[1284/1762] D loss: 0.2563, G loss: 1.7394\n",
      "[1604/1762] D loss: 1.4187, G loss: 0.9052\n",
      "[1924/1762] D loss: 1.4212, G loss: 0.9413\n",
      "[2244/1762] D loss: 1.3994, G loss: 0.6350\n",
      "[2564/1762] D loss: 1.4139, G loss: 0.6609\n",
      "[2884/1762] D loss: 1.4157, G loss: 0.6768\n",
      "[3204/1762] D loss: 1.4690, G loss: 0.9229\n",
      "[3524/1762] D loss: 0.0664, G loss: 3.3446\n",
      "[3844/1762] D loss: 1.3945, G loss: 0.9162\n",
      "[4164/1762] D loss: 1.3942, G loss: 0.6808\n",
      "[4484/1762] D loss: 1.4171, G loss: 0.6785\n",
      "[4804/1762] D loss: 1.3910, G loss: 0.6156\n",
      "[5124/1762] D loss: 1.3878, G loss: 0.7671\n",
      "[5444/1762] D loss: 1.3879, G loss: 0.6524\n",
      "[5764/1762] D loss: 1.4355, G loss: 0.8731\n",
      "[6084/1762] D loss: 1.3976, G loss: 0.5899\n",
      "[6404/1762] D loss: 1.4055, G loss: 0.6930\n",
      "[6724/1762] D loss: 1.4368, G loss: 0.8460\n",
      "[7042/1762] D loss: 1.4226, G loss: 0.6479\n",
      "train error: \n",
      " D loss: 1.433231, G loss: 0.708626, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404052, G loss: 0.822942, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0427, G loss: 4.2713\n",
      "[324/1762] D loss: 1.4445, G loss: 0.5737\n",
      "[644/1762] D loss: 1.4108, G loss: 0.8083\n",
      "[964/1762] D loss: 0.1413, G loss: 2.1528\n",
      "[1284/1762] D loss: 1.4056, G loss: 0.6879\n",
      "[1604/1762] D loss: 1.4021, G loss: 0.7445\n",
      "[1924/1762] D loss: 1.4153, G loss: 0.5541\n",
      "[2244/1762] D loss: 1.4047, G loss: 0.6914\n",
      "[2564/1762] D loss: 1.3992, G loss: 0.7095\n",
      "[2884/1762] D loss: 1.4012, G loss: 0.7170\n",
      "[3204/1762] D loss: 1.3999, G loss: 0.5793\n",
      "[3524/1762] D loss: 1.0826, G loss: 1.0462\n",
      "[3844/1762] D loss: 1.5030, G loss: 1.0568\n",
      "[4164/1762] D loss: 0.3401, G loss: 1.6425\n",
      "[4484/1762] D loss: 1.3865, G loss: 0.6797\n",
      "[4804/1762] D loss: 1.3679, G loss: 0.6929\n",
      "[5124/1762] D loss: 1.9010, G loss: 1.3232\n",
      "[5444/1762] D loss: 1.4495, G loss: 0.9158\n",
      "[5764/1762] D loss: 1.4359, G loss: 0.5234\n",
      "[6084/1762] D loss: 0.3081, G loss: 1.4905\n",
      "[6404/1762] D loss: 0.1111, G loss: 2.9233\n",
      "[6724/1762] D loss: 1.4190, G loss: 0.9184\n",
      "[7042/1762] D loss: 1.4717, G loss: 0.7644\n",
      "train error: \n",
      " D loss: 1.313831, G loss: 0.817741, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292010, G loss: 0.906386, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1185, G loss: 2.7050\n",
      "[324/1762] D loss: 0.9678, G loss: 1.1967\n",
      "[644/1762] D loss: 0.1805, G loss: 2.5849\n",
      "[964/1762] D loss: 0.9305, G loss: 1.1568\n",
      "[1284/1762] D loss: 1.2921, G loss: 1.6344\n",
      "[1604/1762] D loss: 0.0156, G loss: 4.2799\n",
      "[1924/1762] D loss: 1.4926, G loss: 0.5030\n",
      "[2244/1762] D loss: 1.4634, G loss: 0.9945\n",
      "[2564/1762] D loss: 1.3927, G loss: 0.7222\n",
      "[2884/1762] D loss: 1.3891, G loss: 0.7421\n",
      "[3204/1762] D loss: 1.3889, G loss: 0.7635\n",
      "[3524/1762] D loss: 1.3884, G loss: 0.7244\n",
      "[3844/1762] D loss: 1.4110, G loss: 0.8259\n",
      "[4164/1762] D loss: 0.1746, G loss: 2.3981\n",
      "[4484/1762] D loss: 1.4057, G loss: 0.7951\n",
      "[4804/1762] D loss: 1.3472, G loss: 0.7481\n",
      "[5124/1762] D loss: 1.4331, G loss: 0.5662\n",
      "[5444/1762] D loss: 0.2605, G loss: 2.2073\n",
      "[5764/1762] D loss: 1.7288, G loss: 1.1445\n",
      "[6084/1762] D loss: 1.4455, G loss: 0.5243\n",
      "[6404/1762] D loss: 0.3268, G loss: 3.2968\n",
      "[6724/1762] D loss: 1.4550, G loss: 1.1168\n",
      "[7042/1762] D loss: 1.3875, G loss: 0.7394\n",
      "train error: \n",
      " D loss: 1.384273, G loss: 0.647671, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379657, G loss: 0.659289, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4047, G loss: 0.7466\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6810\n",
      "[644/1762] D loss: 1.4162, G loss: 0.8180\n",
      "[964/1762] D loss: 1.2528, G loss: 0.8784\n",
      "[1284/1762] D loss: 1.3991, G loss: 0.7816\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.7055\n",
      "[1924/1762] D loss: 1.3993, G loss: 0.6159\n",
      "[2244/1762] D loss: 1.3945, G loss: 0.7057\n",
      "[2564/1762] D loss: 1.3973, G loss: 0.6438\n",
      "[2884/1762] D loss: 1.4061, G loss: 0.7415\n",
      "[3204/1762] D loss: 1.3974, G loss: 0.7587\n",
      "[3524/1762] D loss: 1.4310, G loss: 0.7948\n",
      "[3844/1762] D loss: 1.4043, G loss: 0.6358\n",
      "[4164/1762] D loss: 1.4217, G loss: 0.8183\n",
      "[4484/1762] D loss: 1.4095, G loss: 0.6394\n",
      "[4804/1762] D loss: 1.3876, G loss: 0.8485\n",
      "[5124/1762] D loss: 1.4065, G loss: 0.6558\n",
      "[5444/1762] D loss: 1.4187, G loss: 0.7609\n",
      "[5764/1762] D loss: 1.4243, G loss: 0.8678\n",
      "[6084/1762] D loss: 1.3241, G loss: 0.8467\n",
      "[6404/1762] D loss: 1.4053, G loss: 0.8024\n",
      "[6724/1762] D loss: 1.4096, G loss: 0.8511\n",
      "[7042/1762] D loss: 1.4002, G loss: 0.7215\n",
      "train error: \n",
      " D loss: 1.575780, G loss: 0.542918, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.543378, G loss: 0.614604, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1263, G loss: 2.8046\n",
      "[324/1762] D loss: 0.0734, G loss: 3.2702\n",
      "[644/1762] D loss: 1.4041, G loss: 0.7291\n",
      "[964/1762] D loss: 1.4049, G loss: 0.5759\n",
      "[1284/1762] D loss: 1.4063, G loss: 0.7976\n",
      "[1604/1762] D loss: 1.4095, G loss: 0.8127\n",
      "[1924/1762] D loss: 1.4184, G loss: 0.8087\n",
      "[2244/1762] D loss: 1.4512, G loss: 0.7416\n",
      "[2564/1762] D loss: 0.0664, G loss: 3.6278\n",
      "[2884/1762] D loss: 1.5078, G loss: 0.9494\n",
      "[3204/1762] D loss: 1.4028, G loss: 0.8061\n",
      "[3524/1762] D loss: 0.0806, G loss: 3.3409\n",
      "[3844/1762] D loss: 1.4099, G loss: 0.8588\n",
      "[4164/1762] D loss: 1.4009, G loss: 0.8027\n",
      "[4484/1762] D loss: 0.0806, G loss: 3.0178\n",
      "[4804/1762] D loss: 0.6671, G loss: 2.7219\n",
      "[5124/1762] D loss: 1.4135, G loss: 0.6457\n",
      "[5444/1762] D loss: 1.4061, G loss: 0.5978\n",
      "[5764/1762] D loss: 0.0955, G loss: 2.9681\n",
      "[6084/1762] D loss: 1.4183, G loss: 0.8449\n",
      "[6404/1762] D loss: 0.0566, G loss: 3.4924\n",
      "[6724/1762] D loss: 1.4185, G loss: 0.5892\n",
      "[7042/1762] D loss: 1.3945, G loss: 0.6461\n",
      "train error: \n",
      " D loss: 2.032008, G loss: 0.396535, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.989209, G loss: 0.474229, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3990, G loss: 0.7789\n",
      "[324/1762] D loss: 1.3894, G loss: 0.7141\n",
      "[644/1762] D loss: 0.0724, G loss: 3.2867\n",
      "[964/1762] D loss: 0.0827, G loss: 3.0857\n",
      "[1284/1762] D loss: 1.4022, G loss: 0.8017\n",
      "[1604/1762] D loss: 1.3928, G loss: 0.7156\n",
      "[1924/1762] D loss: 1.3879, G loss: 0.7161\n",
      "[2244/1762] D loss: 1.3929, G loss: 0.7910\n",
      "[2564/1762] D loss: 1.3924, G loss: 0.7019\n",
      "[2884/1762] D loss: 1.3908, G loss: 0.7006\n",
      "[3204/1762] D loss: 1.3773, G loss: 0.8680\n",
      "[3524/1762] D loss: 1.0196, G loss: 1.0208\n",
      "[3844/1762] D loss: 1.4306, G loss: 0.4858\n",
      "[4164/1762] D loss: 1.5829, G loss: 1.1320\n",
      "[4484/1762] D loss: 1.3885, G loss: 0.7241\n",
      "[4804/1762] D loss: 1.4482, G loss: 0.5725\n",
      "[5124/1762] D loss: 1.3894, G loss: 0.7301\n",
      "[5444/1762] D loss: 1.3956, G loss: 0.6893\n",
      "[5764/1762] D loss: 1.4301, G loss: 0.6709\n",
      "[6084/1762] D loss: 1.4065, G loss: 0.7528\n",
      "[6404/1762] D loss: 0.1249, G loss: 2.6004\n",
      "[6724/1762] D loss: 0.0498, G loss: 3.4969\n",
      "[7042/1762] D loss: 1.3887, G loss: 0.6646\n",
      "train error: \n",
      " D loss: 1.342992, G loss: 0.748391, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311139, G loss: 0.837198, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0754, G loss: 3.0432\n",
      "[324/1762] D loss: 1.4023, G loss: 0.7670\n",
      "[644/1762] D loss: 1.3962, G loss: 0.6925\n",
      "[964/1762] D loss: 1.4524, G loss: 0.5027\n",
      "[1284/1762] D loss: 1.5077, G loss: 0.4334\n",
      "[1604/1762] D loss: 1.5395, G loss: 0.4522\n",
      "[1924/1762] D loss: 1.3991, G loss: 0.7132\n",
      "[2244/1762] D loss: 1.3957, G loss: 0.6788\n",
      "[2564/1762] D loss: 0.0458, G loss: 4.2259\n",
      "[2884/1762] D loss: 1.4154, G loss: 0.6301\n",
      "[3204/1762] D loss: 1.3895, G loss: 0.7129\n",
      "[3524/1762] D loss: 1.3994, G loss: 0.7362\n",
      "[3844/1762] D loss: 1.4369, G loss: 0.8889\n",
      "[4164/1762] D loss: 1.4065, G loss: 0.5794\n",
      "[4484/1762] D loss: 0.0608, G loss: 3.8072\n",
      "[4804/1762] D loss: 1.4862, G loss: 0.4802\n",
      "[5124/1762] D loss: 1.5764, G loss: 0.9767\n",
      "[5444/1762] D loss: 1.4768, G loss: 0.8378\n",
      "[5764/1762] D loss: 1.5089, G loss: 0.8713\n",
      "[6084/1762] D loss: 1.3974, G loss: 0.9298\n",
      "[6404/1762] D loss: 1.3877, G loss: 0.7558\n",
      "[6724/1762] D loss: 1.4059, G loss: 0.5561\n",
      "[7042/1762] D loss: 0.0223, G loss: 4.6273\n",
      "train error: \n",
      " D loss: 1.626630, G loss: 0.335523, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.598718, G loss: 0.360170, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1131, G loss: 2.3275\n",
      "[324/1762] D loss: 0.0737, G loss: 3.0775\n",
      "[644/1762] D loss: 1.3416, G loss: 2.7196\n",
      "[964/1762] D loss: 0.1336, G loss: 3.2639\n",
      "[1284/1762] D loss: 1.4429, G loss: 0.5325\n",
      "[1604/1762] D loss: 1.3948, G loss: 0.7640\n",
      "[1924/1762] D loss: 1.4055, G loss: 0.7616\n",
      "[2244/1762] D loss: 0.3996, G loss: 1.4272\n",
      "[2564/1762] D loss: 1.4730, G loss: 0.9462\n",
      "[2884/1762] D loss: 0.0805, G loss: 2.8024\n",
      "[3204/1762] D loss: 1.4003, G loss: 0.7063\n",
      "[3524/1762] D loss: 1.3998, G loss: 0.6937\n",
      "[3844/1762] D loss: 1.4048, G loss: 0.5638\n",
      "[4164/1762] D loss: 1.3777, G loss: 0.6910\n",
      "[4484/1762] D loss: 1.4018, G loss: 0.7626\n",
      "[4804/1762] D loss: 1.4113, G loss: 0.8858\n",
      "[5124/1762] D loss: 1.4033, G loss: 0.8183\n",
      "[5444/1762] D loss: 1.5011, G loss: 0.9984\n",
      "[5764/1762] D loss: 1.3917, G loss: 0.6487\n",
      "[6084/1762] D loss: 0.1833, G loss: 2.6369\n",
      "[6404/1762] D loss: 0.9256, G loss: 1.8354\n",
      "[6724/1762] D loss: 1.4169, G loss: 0.7959\n",
      "[7042/1762] D loss: 1.4014, G loss: 0.7639\n",
      "train error: \n",
      " D loss: 1.470249, G loss: 0.641167, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.445536, G loss: 0.719981, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4478, G loss: 0.8787\n",
      "[324/1762] D loss: 0.0026, G loss: 7.6055\n",
      "[644/1762] D loss: 1.3927, G loss: 0.7654\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6473\n",
      "[1284/1762] D loss: 1.1078, G loss: 1.1804\n",
      "[1604/1762] D loss: 0.0422, G loss: 4.0647\n",
      "[1924/1762] D loss: 1.4243, G loss: 0.8118\n",
      "[2244/1762] D loss: 1.3326, G loss: 0.7433\n",
      "[2564/1762] D loss: 1.3952, G loss: 0.7302\n",
      "[2884/1762] D loss: 1.4021, G loss: 0.7343\n",
      "[3204/1762] D loss: 0.0797, G loss: 3.0705\n",
      "[3524/1762] D loss: 0.1085, G loss: 2.7672\n",
      "[3844/1762] D loss: 0.0762, G loss: 3.1938\n",
      "[4164/1762] D loss: 0.0811, G loss: 3.0731\n",
      "[4484/1762] D loss: 0.1064, G loss: 2.9713\n",
      "[4804/1762] D loss: 0.0045, G loss: 5.6871\n",
      "[5124/1762] D loss: 1.4033, G loss: 0.7533\n",
      "[5444/1762] D loss: 1.4162, G loss: 0.8336\n",
      "[5764/1762] D loss: 1.3534, G loss: 0.7659\n",
      "[6084/1762] D loss: 1.5855, G loss: 0.8959\n",
      "[6404/1762] D loss: 1.4654, G loss: 1.0188\n",
      "[6724/1762] D loss: 1.3878, G loss: 0.5459\n",
      "[7042/1762] D loss: 1.5598, G loss: 0.4721\n",
      "train error: \n",
      " D loss: 1.769657, G loss: 0.460555, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.730883, G loss: 0.518915, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0923, G loss: 3.3341\n",
      "[324/1762] D loss: 1.5400, G loss: 0.9744\n",
      "[644/1762] D loss: 1.3974, G loss: 0.6635\n",
      "[964/1762] D loss: 0.0690, G loss: 3.2541\n",
      "[1284/1762] D loss: 1.3956, G loss: 0.7538\n",
      "[1604/1762] D loss: 1.3761, G loss: 0.7352\n",
      "[1924/1762] D loss: 1.3915, G loss: 0.7726\n",
      "[2244/1762] D loss: 1.4137, G loss: 0.7768\n",
      "[2564/1762] D loss: 1.3912, G loss: 0.6670\n",
      "[2884/1762] D loss: 1.3915, G loss: 0.7478\n",
      "[3204/1762] D loss: 1.3980, G loss: 0.6647\n",
      "[3524/1762] D loss: 0.1352, G loss: 3.0435\n",
      "[3844/1762] D loss: 1.3931, G loss: 0.7405\n",
      "[4164/1762] D loss: 1.3876, G loss: 0.7030\n",
      "[4484/1762] D loss: 1.3869, G loss: 0.7175\n",
      "[4804/1762] D loss: 1.4029, G loss: 0.7580\n",
      "[5124/1762] D loss: 1.4300, G loss: 0.9088\n",
      "[5444/1762] D loss: 1.3961, G loss: 0.7609\n",
      "[5764/1762] D loss: 1.3925, G loss: 0.7297\n",
      "[6084/1762] D loss: 1.3889, G loss: 0.7747\n",
      "[6404/1762] D loss: 1.4812, G loss: 0.9624\n",
      "[6724/1762] D loss: 1.3959, G loss: 0.7216\n",
      "[7042/1762] D loss: 1.3912, G loss: 0.7078\n",
      "train error: \n",
      " D loss: 1.559114, G loss: 0.559430, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.536689, G loss: 0.626698, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 90.8% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1603, G loss: 1.0175\n",
      "[324/1762] D loss: 1.3811, G loss: 0.6823\n",
      "[644/1762] D loss: 1.4158, G loss: 0.8481\n",
      "[964/1762] D loss: 1.4110, G loss: 0.7763\n",
      "[1284/1762] D loss: 1.4181, G loss: 0.6539\n",
      "[1604/1762] D loss: 1.4290, G loss: 0.5276\n",
      "[1924/1762] D loss: 1.2866, G loss: 0.7992\n",
      "[2244/1762] D loss: 1.4244, G loss: 0.6397\n",
      "[2564/1762] D loss: 1.3967, G loss: 0.6237\n",
      "[2884/1762] D loss: 0.0749, G loss: 3.5818\n",
      "[3204/1762] D loss: 0.0870, G loss: 3.5790\n",
      "[3524/1762] D loss: 1.2956, G loss: 0.9848\n",
      "[3844/1762] D loss: 1.3981, G loss: 0.6814\n",
      "[4164/1762] D loss: 0.9326, G loss: 1.9940\n",
      "[4484/1762] D loss: 0.0691, G loss: 3.7188\n",
      "[4804/1762] D loss: 1.3879, G loss: 0.7122\n",
      "[5124/1762] D loss: 1.3906, G loss: 0.5996\n",
      "[5444/1762] D loss: 1.3887, G loss: 0.7098\n",
      "[5764/1762] D loss: 1.3991, G loss: 0.6149\n",
      "[6084/1762] D loss: 1.4257, G loss: 0.5218\n",
      "[6404/1762] D loss: 1.4390, G loss: 0.5703\n",
      "[6724/1762] D loss: 1.4259, G loss: 0.5545\n",
      "[7042/1762] D loss: 1.4178, G loss: 0.7688\n",
      "train error: \n",
      " D loss: 2.167871, G loss: 0.454015, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.112318, G loss: 0.580879, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4163, G loss: 0.6036\n",
      "[324/1762] D loss: 1.4069, G loss: 0.6450\n",
      "[644/1762] D loss: 1.4302, G loss: 0.8500\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6792\n",
      "[1284/1762] D loss: 1.4459, G loss: 0.8166\n",
      "[1604/1762] D loss: 0.0691, G loss: 3.3957\n",
      "[1924/1762] D loss: 1.4070, G loss: 0.6266\n",
      "[2244/1762] D loss: 0.0752, G loss: 3.6620\n",
      "[2564/1762] D loss: 1.4270, G loss: 0.8432\n",
      "[2884/1762] D loss: 1.3872, G loss: 0.6844\n",
      "[3204/1762] D loss: 1.4052, G loss: 0.6769\n",
      "[3524/1762] D loss: 1.4007, G loss: 0.7644\n",
      "[3844/1762] D loss: 1.4248, G loss: 0.7911\n",
      "[4164/1762] D loss: 1.3896, G loss: 0.6709\n",
      "[4484/1762] D loss: 0.1054, G loss: 2.9115\n",
      "[4804/1762] D loss: 1.3904, G loss: 0.7290\n",
      "[5124/1762] D loss: 1.4191, G loss: 0.6686\n",
      "[5444/1762] D loss: 1.4037, G loss: 0.7239\n",
      "[5764/1762] D loss: 1.3989, G loss: 0.7534\n",
      "[6084/1762] D loss: 1.4072, G loss: 0.8519\n",
      "[6404/1762] D loss: 0.0513, G loss: 3.7858\n",
      "[6724/1762] D loss: 1.4090, G loss: 0.5563\n",
      "[7042/1762] D loss: 1.3923, G loss: 0.7610\n",
      "train error: \n",
      " D loss: 1.325931, G loss: 1.333775, D accuracy: 53.8%, cell accuracy: 99.5%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294864, G loss: 1.473721, D accuracy: 54.8%, cell accuracy: 99.3%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3928, G loss: 0.7266\n",
      "[324/1762] D loss: 1.4283, G loss: 0.6811\n",
      "[644/1762] D loss: 1.3988, G loss: 0.7436\n",
      "[964/1762] D loss: 1.3958, G loss: 0.7111\n",
      "[1284/1762] D loss: 1.3902, G loss: 0.6923\n",
      "[1604/1762] D loss: 1.3956, G loss: 0.6141\n",
      "[1924/1762] D loss: 0.0450, G loss: 3.8495\n",
      "[2244/1762] D loss: 1.3929, G loss: 0.6667\n",
      "[2564/1762] D loss: 0.0771, G loss: 3.8042\n",
      "[2884/1762] D loss: 1.3928, G loss: 0.6202\n",
      "[3204/1762] D loss: 1.4100, G loss: 0.7495\n",
      "[3524/1762] D loss: 1.4024, G loss: 0.7216\n",
      "[3844/1762] D loss: 1.4009, G loss: 0.7856\n",
      "[4164/1762] D loss: 1.3965, G loss: 0.6762\n",
      "[4484/1762] D loss: 1.5610, G loss: 1.0964\n",
      "[4804/1762] D loss: 1.3924, G loss: 0.6433\n",
      "[5124/1762] D loss: 1.4376, G loss: 0.8941\n",
      "[5444/1762] D loss: 1.3691, G loss: 0.8621\n",
      "[5764/1762] D loss: 1.3908, G loss: 0.7817\n",
      "[6084/1762] D loss: 1.4380, G loss: 0.7761\n",
      "[6404/1762] D loss: 1.4874, G loss: 0.8697\n",
      "[6724/1762] D loss: 1.4644, G loss: 1.0077\n",
      "[7042/1762] D loss: 0.0058, G loss: 5.8034\n",
      "train error: \n",
      " D loss: 2.270929, G loss: 0.382151, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.236583, G loss: 0.497947, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0804, G loss: 3.1443\n",
      "[324/1762] D loss: 1.4302, G loss: 0.5547\n",
      "[644/1762] D loss: 1.2133, G loss: 0.6846\n",
      "[964/1762] D loss: 1.4278, G loss: 0.8358\n",
      "[1284/1762] D loss: 1.4009, G loss: 0.9041\n",
      "[1604/1762] D loss: 0.1411, G loss: 2.7767\n",
      "[1924/1762] D loss: 1.4063, G loss: 0.7618\n",
      "[2244/1762] D loss: 1.4196, G loss: 0.7082\n",
      "[2564/1762] D loss: 1.3843, G loss: 0.5644\n",
      "[2884/1762] D loss: 1.1566, G loss: 1.8553\n",
      "[3204/1762] D loss: 0.0179, G loss: 5.0252\n",
      "[3524/1762] D loss: 1.2285, G loss: 1.1542\n",
      "[3844/1762] D loss: 1.3918, G loss: 0.7628\n",
      "[4164/1762] D loss: 1.4099, G loss: 0.7210\n",
      "[4484/1762] D loss: 1.3953, G loss: 0.6640\n",
      "[4804/1762] D loss: 0.0688, G loss: 3.2292\n",
      "[5124/1762] D loss: 1.4613, G loss: 0.9352\n",
      "[5444/1762] D loss: 1.4159, G loss: 0.5411\n",
      "[5764/1762] D loss: 1.3942, G loss: 0.7863\n",
      "[6084/1762] D loss: 0.0599, G loss: 3.7660\n",
      "[6404/1762] D loss: 1.3918, G loss: 0.7322\n",
      "[6724/1762] D loss: 0.0911, G loss: 2.9995\n",
      "[7042/1762] D loss: 1.4034, G loss: 0.6812\n",
      "train error: \n",
      " D loss: 1.649113, G loss: 0.508726, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.616277, G loss: 0.578978, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 90.8% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0030, G loss: 6.1062\n",
      "[324/1762] D loss: 1.4020, G loss: 0.7335\n",
      "[644/1762] D loss: 0.0482, G loss: 3.8798\n",
      "[964/1762] D loss: 0.0333, G loss: 5.1291\n",
      "[1284/1762] D loss: 0.0892, G loss: 2.9543\n",
      "[1604/1762] D loss: 1.4123, G loss: 0.6339\n",
      "[1924/1762] D loss: 1.3951, G loss: 0.8010\n",
      "[2244/1762] D loss: 0.0827, G loss: 3.4071\n",
      "[2564/1762] D loss: 1.3991, G loss: 0.7210\n",
      "[2884/1762] D loss: 1.4114, G loss: 0.8070\n",
      "[3204/1762] D loss: 1.4160, G loss: 0.5915\n",
      "[3524/1762] D loss: 0.0734, G loss: 3.4508\n",
      "[3844/1762] D loss: 1.3986, G loss: 0.6528\n",
      "[4164/1762] D loss: 0.0578, G loss: 3.5491\n",
      "[4484/1762] D loss: 1.4303, G loss: 0.5869\n",
      "[4804/1762] D loss: 1.4013, G loss: 0.6414\n",
      "[5124/1762] D loss: 1.4132, G loss: 0.7925\n",
      "[5444/1762] D loss: 1.3940, G loss: 0.6588\n",
      "[5764/1762] D loss: 0.1376, G loss: 2.4142\n",
      "[6084/1762] D loss: 1.3941, G loss: 0.6600\n",
      "[6404/1762] D loss: 1.3877, G loss: 0.7399\n",
      "[6724/1762] D loss: 1.4129, G loss: 0.7957\n",
      "[7042/1762] D loss: 0.0017, G loss: 6.9640\n",
      "train error: \n",
      " D loss: 3.166451, G loss: 0.408285, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 3.114583, G loss: 0.501484, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7726, G loss: 2.5848\n",
      "[324/1762] D loss: 0.1166, G loss: 3.1207\n",
      "[644/1762] D loss: 1.3971, G loss: 0.6934\n",
      "[964/1762] D loss: 0.0591, G loss: 3.4488\n",
      "[1284/1762] D loss: 1.4034, G loss: 0.7200\n",
      "[1604/1762] D loss: 0.0558, G loss: 3.5929\n",
      "[1924/1762] D loss: 1.3838, G loss: 0.6927\n",
      "[2244/1762] D loss: 1.4060, G loss: 0.8077\n",
      "[2564/1762] D loss: 1.4172, G loss: 0.6873\n",
      "[2884/1762] D loss: 1.3979, G loss: 0.7181\n",
      "[3204/1762] D loss: 1.4079, G loss: 0.7689\n",
      "[3524/1762] D loss: 1.4496, G loss: 0.7343\n",
      "[3844/1762] D loss: 1.4170, G loss: 0.5714\n",
      "[4164/1762] D loss: 1.4331, G loss: 0.8948\n",
      "[4484/1762] D loss: 1.4076, G loss: 0.5760\n",
      "[4804/1762] D loss: 0.0725, G loss: 3.7341\n",
      "[5124/1762] D loss: 1.3855, G loss: 0.7378\n",
      "[5444/1762] D loss: 1.4149, G loss: 0.8453\n",
      "[5764/1762] D loss: 0.0240, G loss: 4.7941\n",
      "[6084/1762] D loss: 0.0268, G loss: 5.2940\n",
      "[6404/1762] D loss: 1.2366, G loss: 1.4053\n",
      "[6724/1762] D loss: 1.4043, G loss: 0.7929\n",
      "[7042/1762] D loss: 1.4908, G loss: 0.8775\n",
      "train error: \n",
      " D loss: 1.383934, G loss: 0.912408, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338850, G loss: 1.130980, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0846, G loss: 3.4988\n",
      "[324/1762] D loss: 0.0755, G loss: 3.8941\n",
      "[644/1762] D loss: 1.4171, G loss: 0.7845\n",
      "[964/1762] D loss: 0.2121, G loss: 1.8872\n",
      "[1284/1762] D loss: 1.4261, G loss: 0.6514\n",
      "[1604/1762] D loss: 1.4074, G loss: 0.5876\n",
      "[1924/1762] D loss: 1.4214, G loss: 0.6269\n",
      "[2244/1762] D loss: 1.4239, G loss: 0.8821\n",
      "[2564/1762] D loss: 0.1118, G loss: 3.0966\n",
      "[2884/1762] D loss: 0.0976, G loss: 3.3692\n",
      "[3204/1762] D loss: 1.4081, G loss: 0.6649\n",
      "[3524/1762] D loss: 0.1579, G loss: 4.2163\n",
      "[3844/1762] D loss: 1.0193, G loss: 1.4804\n",
      "[4164/1762] D loss: 1.3918, G loss: 0.6379\n",
      "[4484/1762] D loss: 1.4050, G loss: 0.7237\n",
      "[4804/1762] D loss: 1.4169, G loss: 0.6359\n",
      "[5124/1762] D loss: 1.3886, G loss: 0.6782\n",
      "[5444/1762] D loss: 1.3924, G loss: 0.6719\n",
      "[5764/1762] D loss: 1.3892, G loss: 0.7190\n",
      "[6084/1762] D loss: 1.4020, G loss: 0.8009\n",
      "[6404/1762] D loss: 0.0152, G loss: 5.3563\n",
      "[6724/1762] D loss: 1.4357, G loss: 0.7790\n",
      "[7042/1762] D loss: 1.3990, G loss: 0.7394\n",
      "train error: \n",
      " D loss: 2.218732, G loss: 0.430625, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.178539, G loss: 0.551991, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2414, G loss: 1.9365\n",
      "[324/1762] D loss: 1.4019, G loss: 0.6087\n",
      "[644/1762] D loss: 1.4064, G loss: 0.7945\n",
      "[964/1762] D loss: 1.5081, G loss: 0.9406\n",
      "[1284/1762] D loss: 1.3972, G loss: 0.5955\n",
      "[1604/1762] D loss: 1.4173, G loss: 0.5316\n",
      "[1924/1762] D loss: 1.4517, G loss: 0.5892\n",
      "[2244/1762] D loss: 0.1361, G loss: 2.3187\n",
      "[2564/1762] D loss: 1.3889, G loss: 0.7178\n",
      "[2884/1762] D loss: 1.3900, G loss: 0.6633\n",
      "[3204/1762] D loss: 1.4668, G loss: 0.9053\n",
      "[3524/1762] D loss: 1.4142, G loss: 0.7063\n",
      "[3844/1762] D loss: 1.4025, G loss: 0.6263\n",
      "[4164/1762] D loss: 1.3873, G loss: 0.6631\n",
      "[4484/1762] D loss: 1.4070, G loss: 0.8200\n",
      "[4804/1762] D loss: 1.4389, G loss: 0.7855\n",
      "[5124/1762] D loss: 0.1025, G loss: 3.5612\n",
      "[5444/1762] D loss: 1.3912, G loss: 0.6915\n",
      "[5764/1762] D loss: 0.0011, G loss: 7.2747\n",
      "[6084/1762] D loss: 1.4121, G loss: 0.7636\n",
      "[6404/1762] D loss: 1.4387, G loss: 0.5489\n",
      "[6724/1762] D loss: 1.4071, G loss: 0.7955\n",
      "[7042/1762] D loss: 0.0018, G loss: 7.6656\n",
      "train error: \n",
      " D loss: 2.617590, G loss: 0.507867, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.572630, G loss: 0.641778, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.7220\n",
      "[324/1762] D loss: 0.0607, G loss: 3.9466\n",
      "[644/1762] D loss: 0.0697, G loss: 3.8420\n",
      "[964/1762] D loss: 1.4045, G loss: 0.7018\n",
      "[1284/1762] D loss: 1.4011, G loss: 0.8207\n",
      "[1604/1762] D loss: 0.0418, G loss: 4.2665\n",
      "[1924/1762] D loss: 0.9994, G loss: 2.8262\n",
      "[2244/1762] D loss: 1.4007, G loss: 0.5730\n",
      "[2564/1762] D loss: 1.3990, G loss: 0.7913\n",
      "[2884/1762] D loss: 1.3962, G loss: 0.6386\n",
      "[3204/1762] D loss: 0.0510, G loss: 3.8564\n",
      "[3524/1762] D loss: 0.1536, G loss: 2.8872\n",
      "[3844/1762] D loss: 1.3353, G loss: 0.7967\n",
      "[4164/1762] D loss: 0.0649, G loss: 4.8618\n",
      "[4484/1762] D loss: 1.5408, G loss: 0.5266\n",
      "[4804/1762] D loss: 0.0401, G loss: 5.2285\n",
      "[5124/1762] D loss: 1.3715, G loss: 0.7618\n",
      "[5444/1762] D loss: 1.4215, G loss: 0.6796\n",
      "[5764/1762] D loss: 1.3935, G loss: 0.7469\n",
      "[6084/1762] D loss: 1.3925, G loss: 0.7760\n",
      "[6404/1762] D loss: 0.0024, G loss: 8.4976\n",
      "[6724/1762] D loss: 0.0840, G loss: 3.8963\n",
      "[7042/1762] D loss: 1.3877, G loss: 0.6392\n",
      "train error: \n",
      " D loss: 2.021468, G loss: 0.625200, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.986730, G loss: 0.747158, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0016, G loss: 7.7832\n",
      "[324/1762] D loss: 1.4285, G loss: 0.5247\n",
      "[644/1762] D loss: 1.3910, G loss: 0.6849\n",
      "[964/1762] D loss: 1.4181, G loss: 0.5925\n",
      "[1284/1762] D loss: 1.3946, G loss: 0.7600\n",
      "[1604/1762] D loss: 0.0894, G loss: 3.7659\n",
      "[1924/1762] D loss: 0.0014, G loss: 8.2388\n",
      "[2244/1762] D loss: 1.4034, G loss: 0.6420\n",
      "[2564/1762] D loss: 1.4130, G loss: 0.8021\n",
      "[2884/1762] D loss: 1.2147, G loss: 2.2409\n",
      "[3204/1762] D loss: 1.3902, G loss: 0.8137\n",
      "[3524/1762] D loss: 1.2522, G loss: 0.6781\n",
      "[3844/1762] D loss: 1.4861, G loss: 0.7830\n",
      "[4164/1762] D loss: 1.4572, G loss: 0.6336\n",
      "[4484/1762] D loss: 1.4294, G loss: 0.8477\n",
      "[4804/1762] D loss: 1.5007, G loss: 0.9100\n",
      "[5124/1762] D loss: 0.0675, G loss: 3.6338\n",
      "[5444/1762] D loss: 1.4111, G loss: 0.7727\n",
      "[5764/1762] D loss: 1.3996, G loss: 0.5745\n",
      "[6084/1762] D loss: 1.3979, G loss: 0.7801\n",
      "[6404/1762] D loss: 1.4275, G loss: 0.8930\n",
      "[6724/1762] D loss: 0.0021, G loss: 7.7011\n",
      "[7042/1762] D loss: 1.3891, G loss: 0.7738\n",
      "train error: \n",
      " D loss: 1.379744, G loss: 1.047262, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351091, G loss: 1.210475, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0016, G loss: 8.9070\n",
      "[324/1762] D loss: 1.3837, G loss: 0.8523\n",
      "[644/1762] D loss: 1.4023, G loss: 0.8413\n",
      "[964/1762] D loss: 0.0922, G loss: 3.7567\n",
      "[1284/1762] D loss: 1.4091, G loss: 0.5815\n",
      "[1604/1762] D loss: 1.3979, G loss: 0.7477\n",
      "[1924/1762] D loss: 1.4001, G loss: 0.7688\n",
      "[2244/1762] D loss: 1.3980, G loss: 0.6677\n",
      "[2564/1762] D loss: 1.3908, G loss: 0.7088\n",
      "[2884/1762] D loss: 1.3893, G loss: 0.7361\n",
      "[3204/1762] D loss: 1.4171, G loss: 0.9276\n",
      "[3524/1762] D loss: 1.4457, G loss: 0.7163\n",
      "[3844/1762] D loss: 0.0467, G loss: 4.0433\n",
      "[4164/1762] D loss: 1.3888, G loss: 0.6465\n",
      "[4484/1762] D loss: 1.3956, G loss: 0.6947\n",
      "[4804/1762] D loss: 1.3774, G loss: 0.7970\n",
      "[5124/1762] D loss: 1.4194, G loss: 0.6261\n",
      "[5444/1762] D loss: 1.3924, G loss: 0.6263\n",
      "[5764/1762] D loss: 1.4356, G loss: 0.6181\n",
      "[6084/1762] D loss: 1.4336, G loss: 0.7585\n",
      "[6404/1762] D loss: 1.4853, G loss: 0.4504\n",
      "[6724/1762] D loss: 1.3950, G loss: 0.7775\n",
      "[7042/1762] D loss: 0.0024, G loss: 8.6318\n",
      "train error: \n",
      " D loss: 3.442550, G loss: 0.459342, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 3.358063, G loss: 0.615383, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6998\n",
      "[324/1762] D loss: 1.3981, G loss: 0.5865\n",
      "[644/1762] D loss: 1.3334, G loss: 1.4662\n",
      "[964/1762] D loss: 0.0462, G loss: 3.3890\n",
      "[1284/1762] D loss: 0.0714, G loss: 3.6347\n",
      "[1604/1762] D loss: 1.4051, G loss: 0.8210\n",
      "[1924/1762] D loss: 1.3408, G loss: 1.0360\n",
      "[2244/1762] D loss: 0.0370, G loss: 4.3902\n",
      "[2564/1762] D loss: 0.0010, G loss: 7.9906\n",
      "[2884/1762] D loss: 1.4352, G loss: 0.8483\n",
      "[3204/1762] D loss: 0.1480, G loss: 2.5084\n",
      "[3524/1762] D loss: 1.3988, G loss: 0.7387\n",
      "[3844/1762] D loss: 1.4400, G loss: 0.7889\n",
      "[4164/1762] D loss: 1.3918, G loss: 0.6130\n",
      "[4484/1762] D loss: 0.0467, G loss: 4.2272\n",
      "[4804/1762] D loss: 1.4055, G loss: 0.6345\n",
      "[5124/1762] D loss: 1.4477, G loss: 0.8746\n",
      "[5444/1762] D loss: 1.2640, G loss: 0.7304\n",
      "[5764/1762] D loss: 1.4450, G loss: 0.5634\n",
      "[6084/1762] D loss: 1.4183, G loss: 0.5768\n",
      "[6404/1762] D loss: 1.4107, G loss: 0.6646\n",
      "[6724/1762] D loss: 0.0317, G loss: 5.2216\n",
      "[7042/1762] D loss: 1.3918, G loss: 0.7061\n",
      "train error: \n",
      " D loss: 1.499683, G loss: 0.812859, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.462096, G loss: 0.951828, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4456, G loss: 0.7785\n",
      "[324/1762] D loss: 1.3874, G loss: 0.7553\n",
      "[644/1762] D loss: 1.3771, G loss: 0.6546\n",
      "[964/1762] D loss: 1.3903, G loss: 0.7264\n",
      "[1284/1762] D loss: 0.0536, G loss: 4.1074\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.7542\n",
      "[1924/1762] D loss: 1.3871, G loss: 0.6594\n",
      "[2244/1762] D loss: 1.3985, G loss: 0.7179\n",
      "[2564/1762] D loss: 0.0464, G loss: 4.1455\n",
      "[2884/1762] D loss: 1.3580, G loss: 1.6095\n",
      "[3204/1762] D loss: 1.3965, G loss: 0.8058\n",
      "[3524/1762] D loss: 1.4237, G loss: 0.8535\n",
      "[3844/1762] D loss: 1.4008, G loss: 0.7638\n",
      "[4164/1762] D loss: 1.3921, G loss: 0.6843\n",
      "[4484/1762] D loss: 1.4170, G loss: 0.5268\n",
      "[4804/1762] D loss: 1.4495, G loss: 0.5520\n",
      "[5124/1762] D loss: 1.3932, G loss: 0.7223\n",
      "[5444/1762] D loss: 1.4056, G loss: 0.7477\n",
      "[5764/1762] D loss: 1.3945, G loss: 0.6395\n",
      "[6084/1762] D loss: 0.0569, G loss: 3.2008\n",
      "[6404/1762] D loss: 1.3933, G loss: 0.6876\n",
      "[6724/1762] D loss: 1.4096, G loss: 0.5651\n",
      "[7042/1762] D loss: 1.3942, G loss: 0.7112\n",
      "train error: \n",
      " D loss: 1.501027, G loss: 0.758632, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.475742, G loss: 0.876403, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3714, G loss: 0.7842\n",
      "[164/1762] D loss: 0.9263, G loss: 0.9910\n",
      "[324/1762] D loss: 0.3251, G loss: 2.6052\n",
      "[484/1762] D loss: 0.0645, G loss: 3.4062\n",
      "[644/1762] D loss: 0.1706, G loss: 4.3161\n",
      "[804/1762] D loss: 0.1431, G loss: 4.0561\n",
      "[964/1762] D loss: 0.0946, G loss: 3.0923\n",
      "[1124/1762] D loss: 0.3207, G loss: 4.0315\n",
      "[1284/1762] D loss: 0.1194, G loss: 5.2193\n",
      "[1444/1762] D loss: 0.5831, G loss: 2.5840\n",
      "[1604/1762] D loss: 0.5349, G loss: 2.3341\n",
      "[1764/1762] D loss: 0.7591, G loss: 1.1148\n",
      "[1924/1762] D loss: 0.8704, G loss: 2.9720\n",
      "[2084/1762] D loss: 1.6139, G loss: 2.6181\n",
      "[2244/1762] D loss: 0.9723, G loss: 0.6406\n",
      "[2404/1762] D loss: 1.0225, G loss: 1.1482\n",
      "[2564/1762] D loss: 1.3814, G loss: 1.6934\n",
      "[2724/1762] D loss: 1.6720, G loss: 0.4871\n",
      "[2884/1762] D loss: 1.2418, G loss: 0.8798\n",
      "[3044/1762] D loss: 1.3875, G loss: 1.4012\n",
      "[3204/1762] D loss: 1.6171, G loss: 1.7608\n",
      "[3364/1762] D loss: 1.4333, G loss: 0.6615\n",
      "[3522/1762] D loss: 1.3126, G loss: 0.8412\n",
      "train error: \n",
      " D loss: 1.302986, G loss: 0.750258, D accuracy: 59.7%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288679, G loss: 0.782220, D accuracy: 60.0%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3641, G loss: 0.9167\n",
      "[164/1762] D loss: 1.1504, G loss: 0.6606\n",
      "[324/1762] D loss: 0.9805, G loss: 1.0070\n",
      "[484/1762] D loss: 1.3693, G loss: 0.9432\n",
      "[644/1762] D loss: 1.0246, G loss: 0.9687\n",
      "[804/1762] D loss: 1.5320, G loss: 1.3326\n",
      "[964/1762] D loss: 1.4014, G loss: 0.6668\n",
      "[1124/1762] D loss: 1.0867, G loss: 0.6080\n",
      "[1284/1762] D loss: 1.4160, G loss: 0.6005\n",
      "[1444/1762] D loss: 1.3752, G loss: 0.8474\n",
      "[1604/1762] D loss: 0.5295, G loss: 1.6007\n",
      "[1764/1762] D loss: 1.5495, G loss: 1.3097\n",
      "[1924/1762] D loss: 1.4006, G loss: 0.9123\n",
      "[2084/1762] D loss: 1.4237, G loss: 0.8236\n",
      "[2244/1762] D loss: 0.7061, G loss: 1.2045\n",
      "[2404/1762] D loss: 1.3894, G loss: 0.7522\n",
      "[2564/1762] D loss: 0.5865, G loss: 1.6892\n",
      "[2724/1762] D loss: 0.6874, G loss: 1.0391\n",
      "[2884/1762] D loss: 1.3106, G loss: 1.4994\n",
      "[3044/1762] D loss: 1.5124, G loss: 1.3215\n",
      "[3204/1762] D loss: 1.2449, G loss: 1.0374\n",
      "[3364/1762] D loss: 0.6476, G loss: 1.3992\n",
      "[3522/1762] D loss: 1.7467, G loss: 0.4676\n",
      "train error: \n",
      " D loss: 1.309193, G loss: 0.711955, D accuracy: 57.8%, cell accuracy: 99.7%, board accuracy: 84.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301568, G loss: 0.721128, D accuracy: 59.0%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4495, G loss: 0.7731\n",
      "[164/1762] D loss: 1.5065, G loss: 0.3808\n",
      "[324/1762] D loss: 1.6575, G loss: 0.9658\n",
      "[484/1762] D loss: 1.5118, G loss: 0.6174\n",
      "[644/1762] D loss: 1.4665, G loss: 0.4582\n",
      "[804/1762] D loss: 0.5373, G loss: 1.8482\n",
      "[964/1762] D loss: 0.4796, G loss: 2.0752\n",
      "[1124/1762] D loss: 2.0996, G loss: 2.2853\n",
      "[1284/1762] D loss: 1.2730, G loss: 0.7192\n",
      "[1444/1762] D loss: 1.5083, G loss: 0.9743\n",
      "[1604/1762] D loss: 1.3950, G loss: 0.5312\n",
      "[1764/1762] D loss: 1.5112, G loss: 0.9864\n",
      "[1924/1762] D loss: 1.2967, G loss: 0.9590\n",
      "[2084/1762] D loss: 1.4415, G loss: 0.7571\n",
      "[2244/1762] D loss: 1.2666, G loss: 1.3499\n",
      "[2404/1762] D loss: 0.5469, G loss: 1.1591\n",
      "[2564/1762] D loss: 1.4584, G loss: 0.8210\n",
      "[2724/1762] D loss: 1.2584, G loss: 0.7899\n",
      "[2884/1762] D loss: 1.3915, G loss: 0.5306\n",
      "[3044/1762] D loss: 1.4184, G loss: 0.7552\n",
      "[3204/1762] D loss: 1.2562, G loss: 0.8609\n",
      "[3364/1762] D loss: 1.3965, G loss: 0.7100\n",
      "[3522/1762] D loss: 1.3143, G loss: 0.8185\n",
      "train error: \n",
      " D loss: 1.353281, G loss: 0.993783, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341494, G loss: 1.014952, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7890, G loss: 1.4635\n",
      "[164/1762] D loss: 1.3928, G loss: 0.7125\n",
      "[324/1762] D loss: 1.5465, G loss: 1.1315\n",
      "[484/1762] D loss: 0.6582, G loss: 1.2370\n",
      "[644/1762] D loss: 1.3936, G loss: 0.6851\n",
      "[804/1762] D loss: 1.4307, G loss: 0.9043\n",
      "[964/1762] D loss: 1.4137, G loss: 0.5598\n",
      "[1124/1762] D loss: 1.4222, G loss: 0.8688\n",
      "[1284/1762] D loss: 1.4162, G loss: 0.7823\n",
      "[1444/1762] D loss: 1.5800, G loss: 1.0215\n",
      "[1604/1762] D loss: 0.3851, G loss: 2.1785\n",
      "[1764/1762] D loss: 0.4477, G loss: 1.6496\n",
      "[1924/1762] D loss: 1.0391, G loss: 0.7770\n",
      "[2084/1762] D loss: 1.5380, G loss: 0.4121\n",
      "[2244/1762] D loss: 1.8052, G loss: 0.2047\n",
      "[2404/1762] D loss: 0.5801, G loss: 1.0837\n",
      "[2564/1762] D loss: 0.5855, G loss: 1.0276\n",
      "[2724/1762] D loss: 1.3685, G loss: 0.6578\n",
      "[2884/1762] D loss: 1.5044, G loss: 0.9225\n",
      "[3044/1762] D loss: 1.4090, G loss: 0.5809\n",
      "[3204/1762] D loss: 1.5726, G loss: 0.9169\n",
      "[3364/1762] D loss: 1.3932, G loss: 0.6088\n",
      "[3522/1762] D loss: 0.3366, G loss: 1.4289\n",
      "train error: \n",
      " D loss: 1.757829, G loss: 0.255276, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.739765, G loss: 0.261866, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3557, G loss: 0.8424\n",
      "[164/1762] D loss: 1.3917, G loss: 0.8106\n",
      "[324/1762] D loss: 0.2842, G loss: 1.7175\n",
      "[484/1762] D loss: 1.6009, G loss: 0.4278\n",
      "[644/1762] D loss: 1.4316, G loss: 0.5964\n",
      "[804/1762] D loss: 1.4047, G loss: 0.7919\n",
      "[964/1762] D loss: 1.4464, G loss: 0.4791\n",
      "[1124/1762] D loss: 1.4391, G loss: 1.0112\n",
      "[1284/1762] D loss: 1.4982, G loss: 0.8883\n",
      "[1444/1762] D loss: 1.3914, G loss: 1.6176\n",
      "[1604/1762] D loss: 0.9459, G loss: 0.6076\n",
      "[1764/1762] D loss: 2.0740, G loss: 1.6690\n",
      "[1924/1762] D loss: 0.5326, G loss: 1.2037\n",
      "[2084/1762] D loss: 1.4236, G loss: 0.8075\n",
      "[2244/1762] D loss: 1.2232, G loss: 1.3423\n",
      "[2404/1762] D loss: 0.2470, G loss: 1.6914\n",
      "[2564/1762] D loss: 3.3471, G loss: 0.2866\n",
      "[2724/1762] D loss: 0.1805, G loss: 2.6886\n",
      "[2884/1762] D loss: 1.5446, G loss: 1.0041\n",
      "[3044/1762] D loss: 1.2440, G loss: 0.7775\n",
      "[3204/1762] D loss: 1.2249, G loss: 1.2273\n",
      "[3364/1762] D loss: 1.4343, G loss: 0.5515\n",
      "[3522/1762] D loss: 1.4060, G loss: 0.6228\n",
      "train error: \n",
      " D loss: 1.352366, G loss: 0.696547, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350136, G loss: 0.701813, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4354, G loss: 0.5885\n",
      "[164/1762] D loss: 1.4124, G loss: 0.7892\n",
      "[324/1762] D loss: 0.7865, G loss: 1.0060\n",
      "[484/1762] D loss: 1.4268, G loss: 0.8225\n",
      "[644/1762] D loss: 0.6081, G loss: 1.3543\n",
      "[804/1762] D loss: 1.3995, G loss: 0.7722\n",
      "[964/1762] D loss: 0.7147, G loss: 0.8326\n",
      "[1124/1762] D loss: 1.4228, G loss: 1.1907\n",
      "[1284/1762] D loss: 1.5262, G loss: 0.5558\n",
      "[1444/1762] D loss: 1.4031, G loss: 0.7815\n",
      "[1604/1762] D loss: 1.3839, G loss: 0.6916\n",
      "[1764/1762] D loss: 1.2533, G loss: 0.6191\n",
      "[1924/1762] D loss: 1.4171, G loss: 0.8260\n",
      "[2084/1762] D loss: 1.4778, G loss: 1.0564\n",
      "[2244/1762] D loss: 0.3907, G loss: 1.3145\n",
      "[2404/1762] D loss: 0.3088, G loss: 1.7969\n",
      "[2564/1762] D loss: 1.4900, G loss: 0.9165\n",
      "[2724/1762] D loss: 0.5048, G loss: 1.0989\n",
      "[2884/1762] D loss: 1.3480, G loss: 0.9078\n",
      "[3044/1762] D loss: 1.5202, G loss: 1.0442\n",
      "[3204/1762] D loss: 0.4557, G loss: 1.3109\n",
      "[3364/1762] D loss: 1.4023, G loss: 0.6170\n",
      "[3522/1762] D loss: 1.5315, G loss: 1.1178\n",
      "train error: \n",
      " D loss: 1.362614, G loss: 0.797785, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356939, G loss: 0.839205, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5168, G loss: 1.0277\n",
      "[164/1762] D loss: 1.4831, G loss: 0.6209\n",
      "[324/1762] D loss: 1.4545, G loss: 0.8774\n",
      "[484/1762] D loss: 1.5691, G loss: 0.8795\n",
      "[644/1762] D loss: 0.4238, G loss: 1.0880\n",
      "[804/1762] D loss: 1.3359, G loss: 0.6205\n",
      "[964/1762] D loss: 1.2263, G loss: 0.8870\n",
      "[1124/1762] D loss: 0.4789, G loss: 1.5086\n",
      "[1284/1762] D loss: 1.3974, G loss: 0.6286\n",
      "[1444/1762] D loss: 1.4723, G loss: 0.5783\n",
      "[1604/1762] D loss: 1.4569, G loss: 1.0578\n",
      "[1764/1762] D loss: 1.4047, G loss: 0.7368\n",
      "[1924/1762] D loss: 0.2540, G loss: 1.8677\n",
      "[2084/1762] D loss: 0.5798, G loss: 1.6493\n",
      "[2244/1762] D loss: 1.2425, G loss: 1.0900\n",
      "[2404/1762] D loss: 1.4415, G loss: 0.8993\n",
      "[2564/1762] D loss: 1.4205, G loss: 0.5386\n",
      "[2724/1762] D loss: 1.4009, G loss: 0.5834\n",
      "[2884/1762] D loss: 0.4863, G loss: 1.1289\n",
      "[3044/1762] D loss: 1.4913, G loss: 0.9310\n",
      "[3204/1762] D loss: 1.3853, G loss: 0.7434\n",
      "[3364/1762] D loss: 1.1623, G loss: 1.0303\n",
      "[3522/1762] D loss: 0.1295, G loss: 2.5524\n",
      "train error: \n",
      " D loss: 1.366947, G loss: 0.825869, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372010, G loss: 0.876722, D accuracy: 51.9%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5281, G loss: 1.6097\n",
      "[164/1762] D loss: 1.4552, G loss: 0.8345\n",
      "[324/1762] D loss: 1.6199, G loss: 1.6577\n",
      "[484/1762] D loss: 1.1565, G loss: 1.3349\n",
      "[644/1762] D loss: 0.2821, G loss: 2.1338\n",
      "[804/1762] D loss: 1.4037, G loss: 0.6158\n",
      "[964/1762] D loss: 1.5215, G loss: 1.0658\n",
      "[1124/1762] D loss: 1.5896, G loss: 1.0912\n",
      "[1284/1762] D loss: 0.2699, G loss: 1.6225\n",
      "[1444/1762] D loss: 1.6500, G loss: 1.2380\n",
      "[1604/1762] D loss: 1.4061, G loss: 0.5904\n",
      "[1764/1762] D loss: 0.4969, G loss: 1.0417\n",
      "[1924/1762] D loss: 0.2266, G loss: 1.8409\n",
      "[2084/1762] D loss: 1.4000, G loss: 0.6515\n",
      "[2244/1762] D loss: 0.5037, G loss: 0.9998\n",
      "[2404/1762] D loss: 0.2849, G loss: 1.7013\n",
      "[2564/1762] D loss: 0.2683, G loss: 1.7670\n",
      "[2724/1762] D loss: 0.4216, G loss: 1.2179\n",
      "[2884/1762] D loss: 1.5253, G loss: 0.8831\n",
      "[3044/1762] D loss: 1.8409, G loss: 1.4351\n",
      "[3204/1762] D loss: 1.4477, G loss: 0.5243\n",
      "[3364/1762] D loss: 0.3451, G loss: 1.4912\n",
      "[3522/1762] D loss: 1.3773, G loss: 0.8449\n",
      "train error: \n",
      " D loss: 1.284633, G loss: 0.799170, D accuracy: 60.9%, cell accuracy: 98.6%, board accuracy: 42.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283295, G loss: 0.815643, D accuracy: 62.4%, cell accuracy: 98.4%, board accuracy: 41.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2032, G loss: 1.9417\n",
      "[164/1762] D loss: 1.4828, G loss: 0.8070\n",
      "[324/1762] D loss: 0.2943, G loss: 1.6295\n",
      "[484/1762] D loss: 0.3911, G loss: 1.1131\n",
      "[644/1762] D loss: 0.2864, G loss: 1.5290\n",
      "[804/1762] D loss: 1.3937, G loss: 0.5945\n",
      "[964/1762] D loss: 1.4124, G loss: 0.6321\n",
      "[1124/1762] D loss: 0.1891, G loss: 1.9096\n",
      "[1284/1762] D loss: 1.4123, G loss: 0.7970\n",
      "[1444/1762] D loss: 1.4551, G loss: 0.4874\n",
      "[1604/1762] D loss: 1.5234, G loss: 0.8687\n",
      "[1764/1762] D loss: 1.4181, G loss: 0.7512\n",
      "[1924/1762] D loss: 1.4493, G loss: 1.0256\n",
      "[2084/1762] D loss: 0.3419, G loss: 1.3799\n",
      "[2244/1762] D loss: 0.0686, G loss: 2.7816\n",
      "[2404/1762] D loss: 0.3366, G loss: 1.3276\n",
      "[2564/1762] D loss: 0.2877, G loss: 1.5765\n",
      "[2724/1762] D loss: 1.5191, G loss: 1.0460\n",
      "[2884/1762] D loss: 0.4084, G loss: 1.2829\n",
      "[3044/1762] D loss: 1.4088, G loss: 0.8002\n",
      "[3204/1762] D loss: 1.4661, G loss: 0.5439\n",
      "[3364/1762] D loss: 1.4686, G loss: 0.9052\n",
      "[3522/1762] D loss: 1.4005, G loss: 0.4399\n",
      "train error: \n",
      " D loss: 1.373412, G loss: 0.687369, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377466, G loss: 0.715980, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3769, G loss: 0.4384\n",
      "[164/1762] D loss: 0.4526, G loss: 1.2518\n",
      "[324/1762] D loss: 0.4728, G loss: 1.0412\n",
      "[484/1762] D loss: 1.4062, G loss: 0.7600\n",
      "[644/1762] D loss: 1.4055, G loss: 0.6506\n",
      "[804/1762] D loss: 1.4132, G loss: 0.5298\n",
      "[964/1762] D loss: 1.4146, G loss: 0.5941\n",
      "[1124/1762] D loss: 1.4459, G loss: 0.8260\n",
      "[1284/1762] D loss: 1.4352, G loss: 0.8585\n",
      "[1444/1762] D loss: 1.4004, G loss: 0.8443\n",
      "[1604/1762] D loss: 1.4156, G loss: 0.6810\n",
      "[1764/1762] D loss: 1.3853, G loss: 0.7705\n",
      "[1924/1762] D loss: 0.4190, G loss: 1.4796\n",
      "[2084/1762] D loss: 1.4367, G loss: 0.5203\n",
      "[2244/1762] D loss: 0.0585, G loss: 3.1154\n",
      "[2404/1762] D loss: 1.3899, G loss: 0.7404\n",
      "[2564/1762] D loss: 1.2678, G loss: 0.6807\n",
      "[2724/1762] D loss: 1.2414, G loss: 0.9472\n",
      "[2884/1762] D loss: 0.2846, G loss: 1.4666\n",
      "[3044/1762] D loss: 1.5645, G loss: 1.3014\n",
      "[3204/1762] D loss: 1.3752, G loss: 0.8565\n",
      "[3364/1762] D loss: 0.3515, G loss: 1.5853\n",
      "[3522/1762] D loss: 1.4582, G loss: 0.9748\n",
      "train error: \n",
      " D loss: 1.370059, G loss: 0.756344, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368585, G loss: 0.774767, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1267, G loss: 2.5415\n",
      "[164/1762] D loss: 1.3937, G loss: 0.7118\n",
      "[324/1762] D loss: 1.4055, G loss: 0.8419\n",
      "[484/1762] D loss: 1.4180, G loss: 0.6883\n",
      "[644/1762] D loss: 1.4072, G loss: 0.7254\n",
      "[804/1762] D loss: 0.3064, G loss: 1.4292\n",
      "[964/1762] D loss: 0.1345, G loss: 2.2809\n",
      "[1124/1762] D loss: 1.4219, G loss: 0.5562\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.6235\n",
      "[1444/1762] D loss: 1.3914, G loss: 0.6610\n",
      "[1604/1762] D loss: 0.2118, G loss: 1.9552\n",
      "[1764/1762] D loss: 1.4077, G loss: 0.8457\n",
      "[1924/1762] D loss: 1.4462, G loss: 0.9429\n",
      "[2084/1762] D loss: 0.9489, G loss: 1.4759\n",
      "[2244/1762] D loss: 0.0528, G loss: 4.0773\n",
      "[2404/1762] D loss: 0.1939, G loss: 2.0904\n",
      "[2564/1762] D loss: 1.4377, G loss: 0.5043\n",
      "[2724/1762] D loss: 0.5802, G loss: 1.0002\n",
      "[2884/1762] D loss: 0.2563, G loss: 1.9197\n",
      "[3044/1762] D loss: 0.1662, G loss: 2.2120\n",
      "[3204/1762] D loss: 1.4353, G loss: 0.8442\n",
      "[3364/1762] D loss: 0.2966, G loss: 1.6733\n",
      "[3522/1762] D loss: 1.2024, G loss: 1.0493\n",
      "train error: \n",
      " D loss: 1.387983, G loss: 0.777975, D accuracy: 52.3%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390330, G loss: 0.789011, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3854, G loss: 1.3109\n",
      "[164/1762] D loss: 1.4307, G loss: 0.9219\n",
      "[324/1762] D loss: 1.4345, G loss: 0.7666\n",
      "[484/1762] D loss: 1.3920, G loss: 0.7305\n",
      "[644/1762] D loss: 1.4203, G loss: 0.8668\n",
      "[804/1762] D loss: 0.3815, G loss: 1.3656\n",
      "[964/1762] D loss: 1.3940, G loss: 0.6563\n",
      "[1124/1762] D loss: 1.5535, G loss: 1.3001\n",
      "[1284/1762] D loss: 1.4014, G loss: 0.7582\n",
      "[1444/1762] D loss: 1.3328, G loss: 0.6099\n",
      "[1604/1762] D loss: 1.3944, G loss: 0.6400\n",
      "[1764/1762] D loss: 1.4085, G loss: 0.6602\n",
      "[1924/1762] D loss: 1.3387, G loss: 0.7461\n",
      "[2084/1762] D loss: 0.2539, G loss: 1.6629\n",
      "[2244/1762] D loss: 1.4558, G loss: 0.8616\n",
      "[2404/1762] D loss: 1.4535, G loss: 0.4829\n",
      "[2564/1762] D loss: 1.4283, G loss: 1.0030\n",
      "[2724/1762] D loss: 1.4045, G loss: 1.3569\n",
      "[2884/1762] D loss: 0.1829, G loss: 1.9012\n",
      "[3044/1762] D loss: 1.4847, G loss: 0.7980\n",
      "[3204/1762] D loss: 1.4077, G loss: 0.6560\n",
      "[3364/1762] D loss: 1.3096, G loss: 0.7178\n",
      "[3522/1762] D loss: 1.4426, G loss: 0.8458\n",
      "train error: \n",
      " D loss: 1.498571, G loss: 0.440969, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.504275, G loss: 0.447654, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4835, G loss: 1.0555\n",
      "[164/1762] D loss: 1.3947, G loss: 0.6429\n",
      "[324/1762] D loss: 1.4042, G loss: 0.7068\n",
      "[484/1762] D loss: 0.1402, G loss: 2.3592\n",
      "[644/1762] D loss: 0.2626, G loss: 1.4946\n",
      "[804/1762] D loss: 1.4723, G loss: 0.5150\n",
      "[964/1762] D loss: 1.4171, G loss: 0.8341\n",
      "[1124/1762] D loss: 1.4412, G loss: 0.9478\n",
      "[1284/1762] D loss: 1.4053, G loss: 0.6725\n",
      "[1444/1762] D loss: 1.4872, G loss: 1.2868\n",
      "[1604/1762] D loss: 0.3187, G loss: 1.5443\n",
      "[1764/1762] D loss: 1.7890, G loss: 1.0044\n",
      "[1924/1762] D loss: 1.3949, G loss: 0.6437\n",
      "[2084/1762] D loss: 0.0877, G loss: 2.6551\n",
      "[2244/1762] D loss: 1.4313, G loss: 0.8573\n",
      "[2404/1762] D loss: 0.2844, G loss: 1.4903\n",
      "[2564/1762] D loss: 1.4026, G loss: 0.7798\n",
      "[2724/1762] D loss: 0.6033, G loss: 0.8646\n",
      "[2884/1762] D loss: 1.3981, G loss: 0.9148\n",
      "[3044/1762] D loss: 1.0287, G loss: 1.5222\n",
      "[3204/1762] D loss: 1.4225, G loss: 0.6494\n",
      "[3364/1762] D loss: 1.3957, G loss: 0.7108\n",
      "[3522/1762] D loss: 1.5669, G loss: 1.1546\n",
      "train error: \n",
      " D loss: 1.424019, G loss: 0.512226, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417007, G loss: 0.532332, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4052, G loss: 0.6953\n",
      "[164/1762] D loss: 1.4097, G loss: 0.4592\n",
      "[324/1762] D loss: 1.4494, G loss: 0.5156\n",
      "[484/1762] D loss: 0.3897, G loss: 1.5276\n",
      "[644/1762] D loss: 1.5740, G loss: 1.0554\n",
      "[804/1762] D loss: 1.3687, G loss: 0.6419\n",
      "[964/1762] D loss: 0.3010, G loss: 1.5557\n",
      "[1124/1762] D loss: 1.4141, G loss: 0.5653\n",
      "[1284/1762] D loss: 1.2835, G loss: 1.5750\n",
      "[1444/1762] D loss: 1.3984, G loss: 0.6532\n",
      "[1604/1762] D loss: 1.4611, G loss: 0.9148\n",
      "[1764/1762] D loss: 1.4000, G loss: 0.6856\n",
      "[1924/1762] D loss: 0.4823, G loss: 1.0010\n",
      "[2084/1762] D loss: 1.6447, G loss: 0.3691\n",
      "[2244/1762] D loss: 0.1347, G loss: 2.4565\n",
      "[2404/1762] D loss: 1.4142, G loss: 0.7845\n",
      "[2564/1762] D loss: 1.3920, G loss: 0.7140\n",
      "[2724/1762] D loss: 1.3919, G loss: 0.7407\n",
      "[2884/1762] D loss: 1.4014, G loss: 0.6980\n",
      "[3044/1762] D loss: 0.2932, G loss: 1.5521\n",
      "[3204/1762] D loss: 0.4252, G loss: 1.2715\n",
      "[3364/1762] D loss: 1.4028, G loss: 0.7386\n",
      "[3522/1762] D loss: 1.4287, G loss: 0.7852\n",
      "train error: \n",
      " D loss: 2.087524, G loss: 0.174064, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.091485, G loss: 0.173594, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4011, G loss: 0.8112\n",
      "[164/1762] D loss: 0.1113, G loss: 2.3614\n",
      "[324/1762] D loss: 1.4762, G loss: 0.4731\n",
      "[484/1762] D loss: 1.4144, G loss: 0.7768\n",
      "[644/1762] D loss: 1.2347, G loss: 1.1032\n",
      "[804/1762] D loss: 1.3931, G loss: 0.6669\n",
      "[964/1762] D loss: 1.4362, G loss: 0.6063\n",
      "[1124/1762] D loss: 1.4080, G loss: 0.7473\n",
      "[1284/1762] D loss: 1.4699, G loss: 0.7941\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.7717\n",
      "[1604/1762] D loss: 0.5579, G loss: 1.2695\n",
      "[1764/1762] D loss: 1.4140, G loss: 1.0705\n",
      "[1924/1762] D loss: 0.4491, G loss: 1.1024\n",
      "[2084/1762] D loss: 1.4285, G loss: 1.0097\n",
      "[2244/1762] D loss: 1.5949, G loss: 1.1682\n",
      "[2404/1762] D loss: 1.3986, G loss: 0.8147\n",
      "[2564/1762] D loss: 1.5736, G loss: 1.0116\n",
      "[2724/1762] D loss: 1.4152, G loss: 0.7967\n",
      "[2884/1762] D loss: 0.9894, G loss: 0.9954\n",
      "[3044/1762] D loss: 0.2763, G loss: 1.6980\n",
      "[3204/1762] D loss: 1.7873, G loss: 1.2365\n",
      "[3364/1762] D loss: 1.2774, G loss: 0.9750\n",
      "[3522/1762] D loss: 1.4495, G loss: 0.8711\n",
      "train error: \n",
      " D loss: 1.548261, G loss: 0.400936, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.541648, G loss: 0.415236, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5177, G loss: 0.8784\n",
      "[164/1762] D loss: 1.4308, G loss: 0.4744\n",
      "[324/1762] D loss: 1.4681, G loss: 0.5728\n",
      "[484/1762] D loss: 1.4872, G loss: 0.5422\n",
      "[644/1762] D loss: 0.9440, G loss: 1.1579\n",
      "[804/1762] D loss: 0.2230, G loss: 1.8101\n",
      "[964/1762] D loss: 0.3465, G loss: 1.3288\n",
      "[1124/1762] D loss: 1.1546, G loss: 0.8903\n",
      "[1284/1762] D loss: 1.4472, G loss: 0.5519\n",
      "[1444/1762] D loss: 1.4085, G loss: 0.7547\n",
      "[1604/1762] D loss: 1.3337, G loss: 1.0801\n",
      "[1764/1762] D loss: 1.4006, G loss: 0.7692\n",
      "[1924/1762] D loss: 1.4016, G loss: 0.9199\n",
      "[2084/1762] D loss: 0.2625, G loss: 1.6727\n",
      "[2244/1762] D loss: 1.3987, G loss: 0.7275\n",
      "[2404/1762] D loss: 1.4100, G loss: 0.8519\n",
      "[2564/1762] D loss: 1.4545, G loss: 0.9175\n",
      "[2724/1762] D loss: 0.0949, G loss: 2.9327\n",
      "[2884/1762] D loss: 1.4806, G loss: 0.4763\n",
      "[3044/1762] D loss: 1.4260, G loss: 0.7359\n",
      "[3204/1762] D loss: 1.6252, G loss: 1.4027\n",
      "[3364/1762] D loss: 1.6379, G loss: 0.3625\n",
      "[3522/1762] D loss: 0.1104, G loss: 2.4477\n",
      "train error: \n",
      " D loss: 1.641220, G loss: 0.351931, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.651484, G loss: 0.368747, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4047, G loss: 0.6885\n",
      "[164/1762] D loss: 1.5148, G loss: 1.4390\n",
      "[324/1762] D loss: 1.4459, G loss: 0.9894\n",
      "[484/1762] D loss: 1.4582, G loss: 0.8934\n",
      "[644/1762] D loss: 1.5674, G loss: 0.3792\n",
      "[804/1762] D loss: 0.5848, G loss: 0.9551\n",
      "[964/1762] D loss: 1.4113, G loss: 0.6500\n",
      "[1124/1762] D loss: 1.3956, G loss: 0.6626\n",
      "[1284/1762] D loss: 1.4887, G loss: 0.5226\n",
      "[1444/1762] D loss: 1.7024, G loss: 1.3844\n",
      "[1604/1762] D loss: 1.4849, G loss: 1.3615\n",
      "[1764/1762] D loss: 1.4050, G loss: 0.8573\n",
      "[1924/1762] D loss: 1.4568, G loss: 0.9853\n",
      "[2084/1762] D loss: 1.4247, G loss: 0.8510\n",
      "[2244/1762] D loss: 0.1877, G loss: 1.8605\n",
      "[2404/1762] D loss: 1.6163, G loss: 1.1843\n",
      "[2564/1762] D loss: 0.2660, G loss: 1.5616\n",
      "[2724/1762] D loss: 1.4005, G loss: 0.8265\n",
      "[2884/1762] D loss: 1.4755, G loss: 0.8431\n",
      "[3044/1762] D loss: 1.4143, G loss: 0.5693\n",
      "[3204/1762] D loss: 1.4157, G loss: 0.6699\n",
      "[3364/1762] D loss: 1.4787, G loss: 0.9623\n",
      "[3522/1762] D loss: 1.4729, G loss: 0.4521\n",
      "train error: \n",
      " D loss: 1.470590, G loss: 0.436157, D accuracy: 51.4%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.461867, G loss: 0.445185, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4017, G loss: 0.5818\n",
      "[164/1762] D loss: 1.5108, G loss: 0.4686\n",
      "[324/1762] D loss: 0.2086, G loss: 2.0164\n",
      "[484/1762] D loss: 1.4356, G loss: 0.7919\n",
      "[644/1762] D loss: 1.3987, G loss: 0.7393\n",
      "[804/1762] D loss: 0.0835, G loss: 2.7529\n",
      "[964/1762] D loss: 0.2070, G loss: 1.7823\n",
      "[1124/1762] D loss: 1.4055, G loss: 0.8161\n",
      "[1284/1762] D loss: 1.4668, G loss: 0.9110\n",
      "[1444/1762] D loss: 1.4404, G loss: 0.5885\n",
      "[1604/1762] D loss: 0.1938, G loss: 1.8296\n",
      "[1764/1762] D loss: 1.4000, G loss: 0.7816\n",
      "[1924/1762] D loss: 1.4349, G loss: 0.7267\n",
      "[2084/1762] D loss: 0.2840, G loss: 1.5772\n",
      "[2244/1762] D loss: 1.3986, G loss: 0.7195\n",
      "[2404/1762] D loss: 1.3843, G loss: 0.8647\n",
      "[2564/1762] D loss: 1.6684, G loss: 1.4162\n",
      "[2724/1762] D loss: 1.4165, G loss: 0.5853\n",
      "[2884/1762] D loss: 0.1461, G loss: 2.2469\n",
      "[3044/1762] D loss: 1.4299, G loss: 0.7631\n",
      "[3204/1762] D loss: 1.4221, G loss: 0.7969\n",
      "[3364/1762] D loss: 0.2772, G loss: 1.6076\n",
      "[3522/1762] D loss: 1.3867, G loss: 0.7466\n",
      "train error: \n",
      " D loss: 1.496003, G loss: 0.408854, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.495337, G loss: 0.413614, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3846, G loss: 0.7571\n",
      "[164/1762] D loss: 0.2028, G loss: 1.7292\n",
      "[324/1762] D loss: 1.5091, G loss: 1.0335\n",
      "[484/1762] D loss: 1.4464, G loss: 0.5797\n",
      "[644/1762] D loss: 1.4462, G loss: 0.8745\n",
      "[804/1762] D loss: 1.1348, G loss: 0.8981\n",
      "[964/1762] D loss: 0.2345, G loss: 1.7892\n",
      "[1124/1762] D loss: 1.4527, G loss: 0.4339\n",
      "[1284/1762] D loss: 0.3039, G loss: 2.1978\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.6379\n",
      "[1604/1762] D loss: 1.2469, G loss: 0.7745\n",
      "[1764/1762] D loss: 0.4248, G loss: 1.2120\n",
      "[1924/1762] D loss: 1.3975, G loss: 0.6584\n",
      "[2084/1762] D loss: 0.2683, G loss: 1.6027\n",
      "[2244/1762] D loss: 1.4256, G loss: 0.5921\n",
      "[2404/1762] D loss: 1.3817, G loss: 0.6262\n",
      "[2564/1762] D loss: 0.3321, G loss: 1.5783\n",
      "[2724/1762] D loss: 1.3701, G loss: 0.7907\n",
      "[2884/1762] D loss: 1.4174, G loss: 0.7372\n",
      "[3044/1762] D loss: 1.5027, G loss: 0.4601\n",
      "[3204/1762] D loss: 1.5313, G loss: 1.1159\n",
      "[3364/1762] D loss: 1.4076, G loss: 0.6147\n",
      "[3522/1762] D loss: 1.5488, G loss: 0.4548\n",
      "train error: \n",
      " D loss: 1.891105, G loss: 0.223484, D accuracy: 49.3%, cell accuracy: 99.9%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.883492, G loss: 0.228714, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4083, G loss: 0.8185\n",
      "[164/1762] D loss: 0.2364, G loss: 1.8840\n",
      "[324/1762] D loss: 1.4302, G loss: 0.7601\n",
      "[484/1762] D loss: 1.3894, G loss: 0.6792\n",
      "[644/1762] D loss: 1.4954, G loss: 0.4409\n",
      "[804/1762] D loss: 1.3921, G loss: 0.6288\n",
      "[964/1762] D loss: 0.1988, G loss: 1.9252\n",
      "[1124/1762] D loss: 1.4403, G loss: 0.8494\n",
      "[1284/1762] D loss: 1.2944, G loss: 0.6761\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7689\n",
      "[1604/1762] D loss: 1.4924, G loss: 1.0019\n",
      "[1764/1762] D loss: 1.3978, G loss: 0.8366\n",
      "[1924/1762] D loss: 1.4554, G loss: 0.8406\n",
      "[2084/1762] D loss: 1.4041, G loss: 0.8033\n",
      "[2244/1762] D loss: 1.3895, G loss: 0.6147\n",
      "[2404/1762] D loss: 1.4480, G loss: 0.8957\n",
      "[2564/1762] D loss: 1.4579, G loss: 0.4036\n",
      "[2724/1762] D loss: 0.1757, G loss: 1.9159\n",
      "[2884/1762] D loss: 0.0441, G loss: 3.5591\n",
      "[3044/1762] D loss: 1.1510, G loss: 0.9615\n",
      "[3204/1762] D loss: 1.5597, G loss: 1.0459\n",
      "[3364/1762] D loss: 1.5205, G loss: 0.3695\n",
      "[3522/1762] D loss: 1.3912, G loss: 0.7819\n",
      "train error: \n",
      " D loss: 1.897970, G loss: 0.214767, D accuracy: 49.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.888107, G loss: 0.221708, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4065, G loss: 0.8241\n",
      "[164/1762] D loss: 0.1723, G loss: 2.0332\n",
      "[324/1762] D loss: 1.4766, G loss: 0.5384\n",
      "[484/1762] D loss: 1.3935, G loss: 0.6535\n",
      "[644/1762] D loss: 1.4052, G loss: 0.8133\n",
      "[804/1762] D loss: 1.3951, G loss: 0.7981\n",
      "[964/1762] D loss: 1.4027, G loss: 0.7920\n",
      "[1124/1762] D loss: 1.4000, G loss: 0.9001\n",
      "[1284/1762] D loss: 1.3927, G loss: 0.7939\n",
      "[1444/1762] D loss: 0.1743, G loss: 2.1344\n",
      "[1604/1762] D loss: 1.3944, G loss: 0.6724\n",
      "[1764/1762] D loss: 0.2130, G loss: 1.8210\n",
      "[1924/1762] D loss: 1.5071, G loss: 1.0407\n",
      "[2084/1762] D loss: 1.5030, G loss: 0.6952\n",
      "[2244/1762] D loss: 1.4201, G loss: 0.6370\n",
      "[2404/1762] D loss: 0.0590, G loss: 2.9313\n",
      "[2564/1762] D loss: 1.4807, G loss: 0.6484\n",
      "[2724/1762] D loss: 0.9821, G loss: 2.2531\n",
      "[2884/1762] D loss: 0.0937, G loss: 4.5131\n",
      "[3044/1762] D loss: 1.5589, G loss: 0.6013\n",
      "[3204/1762] D loss: 0.1402, G loss: 2.7105\n",
      "[3364/1762] D loss: 1.6138, G loss: 1.0605\n",
      "[3522/1762] D loss: 1.4632, G loss: 0.4352\n",
      "train error: \n",
      " D loss: 1.483022, G loss: 0.530069, D accuracy: 49.1%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.491580, G loss: 0.542163, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4172, G loss: 0.6513\n",
      "[164/1762] D loss: 0.3988, G loss: 1.1916\n",
      "[324/1762] D loss: 1.4699, G loss: 0.7445\n",
      "[484/1762] D loss: 1.3904, G loss: 0.6243\n",
      "[644/1762] D loss: 0.3736, G loss: 1.2968\n",
      "[804/1762] D loss: 1.4318, G loss: 0.8367\n",
      "[964/1762] D loss: 1.3956, G loss: 0.7345\n",
      "[1124/1762] D loss: 1.4869, G loss: 1.0490\n",
      "[1284/1762] D loss: 0.3724, G loss: 1.2190\n",
      "[1444/1762] D loss: 0.4258, G loss: 1.2265\n",
      "[1604/1762] D loss: 1.4251, G loss: 0.6014\n",
      "[1764/1762] D loss: 0.2077, G loss: 1.7490\n",
      "[1924/1762] D loss: 0.3414, G loss: 1.5175\n",
      "[2084/1762] D loss: 0.2992, G loss: 1.5357\n",
      "[2244/1762] D loss: 0.2698, G loss: 1.6202\n",
      "[2404/1762] D loss: 1.5370, G loss: 1.1948\n",
      "[2564/1762] D loss: 1.4281, G loss: 0.9411\n",
      "[2724/1762] D loss: 1.4257, G loss: 0.8398\n",
      "[2884/1762] D loss: 1.1422, G loss: 0.6509\n",
      "[3044/1762] D loss: 1.3932, G loss: 0.6567\n",
      "[3204/1762] D loss: 0.2909, G loss: 1.5482\n",
      "[3364/1762] D loss: 0.3003, G loss: 1.5829\n",
      "[3522/1762] D loss: 1.4506, G loss: 0.8162\n",
      "train error: \n",
      " D loss: 1.530045, G loss: 0.386272, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.523578, G loss: 0.388363, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4665, G loss: 0.8437\n",
      "[164/1762] D loss: 1.3371, G loss: 0.7250\n",
      "[324/1762] D loss: 1.4647, G loss: 1.0914\n",
      "[484/1762] D loss: 1.6316, G loss: 1.0644\n",
      "[644/1762] D loss: 0.2388, G loss: 1.6380\n",
      "[804/1762] D loss: 0.2489, G loss: 1.7448\n",
      "[964/1762] D loss: 1.4092, G loss: 0.9243\n",
      "[1124/1762] D loss: 1.4317, G loss: 0.9148\n",
      "[1284/1762] D loss: 1.4092, G loss: 0.8200\n",
      "[1444/1762] D loss: 1.4347, G loss: 0.8460\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.6858\n",
      "[1764/1762] D loss: 1.3385, G loss: 0.7797\n",
      "[1924/1762] D loss: 0.3033, G loss: 1.4962\n",
      "[2084/1762] D loss: 1.5773, G loss: 1.0517\n",
      "[2244/1762] D loss: 1.1892, G loss: 0.7646\n",
      "[2404/1762] D loss: 0.1875, G loss: 1.8515\n",
      "[2564/1762] D loss: 0.2748, G loss: 1.5068\n",
      "[2724/1762] D loss: 1.3675, G loss: 0.7253\n",
      "[2884/1762] D loss: 1.4072, G loss: 0.7476\n",
      "[3044/1762] D loss: 1.4190, G loss: 0.8737\n",
      "[3204/1762] D loss: 1.4486, G loss: 1.0225\n",
      "[3364/1762] D loss: 1.4066, G loss: 0.6182\n",
      "[3522/1762] D loss: 1.4160, G loss: 0.8168\n",
      "train error: \n",
      " D loss: 1.496550, G loss: 0.551544, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.521269, G loss: 0.555856, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1283, G loss: 2.3817\n",
      "[164/1762] D loss: 0.1757, G loss: 1.7371\n",
      "[324/1762] D loss: 1.3983, G loss: 0.7793\n",
      "[484/1762] D loss: 1.4128, G loss: 0.8682\n",
      "[644/1762] D loss: 1.4013, G loss: 0.6331\n",
      "[804/1762] D loss: 1.4230, G loss: 0.5799\n",
      "[964/1762] D loss: 1.5307, G loss: 0.9164\n",
      "[1124/1762] D loss: 1.4227, G loss: 0.5075\n",
      "[1284/1762] D loss: 0.1938, G loss: 1.8506\n",
      "[1444/1762] D loss: 0.3028, G loss: 1.3331\n",
      "[1604/1762] D loss: 1.4110, G loss: 0.7445\n",
      "[1764/1762] D loss: 1.4571, G loss: 0.8449\n",
      "[1924/1762] D loss: 1.4069, G loss: 0.9620\n",
      "[2084/1762] D loss: 0.1428, G loss: 2.7495\n",
      "[2244/1762] D loss: 0.7045, G loss: 3.3663\n",
      "[2404/1762] D loss: 1.4850, G loss: 0.7284\n",
      "[2564/1762] D loss: 1.3954, G loss: 0.8373\n",
      "[2724/1762] D loss: 1.4611, G loss: 0.3889\n",
      "[2884/1762] D loss: 1.4010, G loss: 0.8015\n",
      "[3044/1762] D loss: 1.3948, G loss: 0.6726\n",
      "[3204/1762] D loss: 0.3224, G loss: 1.3987\n",
      "[3364/1762] D loss: 1.3906, G loss: 0.7148\n",
      "[3522/1762] D loss: 1.4334, G loss: 0.5327\n",
      "train error: \n",
      " D loss: 1.487725, G loss: 0.447024, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.492565, G loss: 0.450176, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2639, G loss: 0.9781\n",
      "[164/1762] D loss: 1.4108, G loss: 0.6556\n",
      "[324/1762] D loss: 0.0356, G loss: 3.5179\n",
      "[484/1762] D loss: 1.3506, G loss: 0.8110\n",
      "[644/1762] D loss: 0.3225, G loss: 1.4799\n",
      "[804/1762] D loss: 0.9830, G loss: 1.2925\n",
      "[964/1762] D loss: 1.4568, G loss: 0.4949\n",
      "[1124/1762] D loss: 0.0551, G loss: 3.4532\n",
      "[1284/1762] D loss: 1.7556, G loss: 1.2507\n",
      "[1444/1762] D loss: 1.3939, G loss: 0.7350\n",
      "[1604/1762] D loss: 1.3974, G loss: 0.6279\n",
      "[1764/1762] D loss: 1.5224, G loss: 0.4284\n",
      "[1924/1762] D loss: 1.4151, G loss: 0.6577\n",
      "[2084/1762] D loss: 1.4073, G loss: 0.6136\n",
      "[2244/1762] D loss: 1.3891, G loss: 0.7289\n",
      "[2404/1762] D loss: 1.4300, G loss: 0.7883\n",
      "[2564/1762] D loss: 0.3243, G loss: 1.4235\n",
      "[2724/1762] D loss: 1.4342, G loss: 0.6597\n",
      "[2884/1762] D loss: 1.5456, G loss: 1.0396\n",
      "[3044/1762] D loss: 1.1797, G loss: 0.7313\n",
      "[3204/1762] D loss: 1.5482, G loss: 1.1491\n",
      "[3364/1762] D loss: 1.4648, G loss: 0.5198\n",
      "[3522/1762] D loss: 1.3485, G loss: 0.7104\n",
      "train error: \n",
      " D loss: 1.929913, G loss: 0.219817, D accuracy: 48.5%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.939037, G loss: 0.219984, D accuracy: 48.0%, cell accuracy: 99.7%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4303, G loss: 0.6031\n",
      "[164/1762] D loss: 0.1838, G loss: 2.0069\n",
      "[324/1762] D loss: 1.4368, G loss: 0.9256\n",
      "[484/1762] D loss: 1.4045, G loss: 0.6444\n",
      "[644/1762] D loss: 1.4343, G loss: 0.4990\n",
      "[804/1762] D loss: 1.3857, G loss: 0.8097\n",
      "[964/1762] D loss: 1.4099, G loss: 0.8266\n",
      "[1124/1762] D loss: 0.2077, G loss: 1.8917\n",
      "[1284/1762] D loss: 0.1429, G loss: 2.2536\n",
      "[1444/1762] D loss: 1.3303, G loss: 0.8157\n",
      "[1604/1762] D loss: 0.1854, G loss: 1.9500\n",
      "[1764/1762] D loss: 1.4640, G loss: 0.6397\n",
      "[1924/1762] D loss: 1.5735, G loss: 1.0445\n",
      "[2084/1762] D loss: 1.3869, G loss: 0.7880\n",
      "[2244/1762] D loss: 0.2340, G loss: 1.6773\n",
      "[2404/1762] D loss: 0.1335, G loss: 2.2274\n",
      "[2564/1762] D loss: 1.4295, G loss: 0.5171\n",
      "[2724/1762] D loss: 1.4283, G loss: 0.5969\n",
      "[2884/1762] D loss: 1.3964, G loss: 0.7673\n",
      "[3044/1762] D loss: 1.4343, G loss: 0.8318\n",
      "[3204/1762] D loss: 1.3665, G loss: 1.0058\n",
      "[3364/1762] D loss: 1.4039, G loss: 0.7186\n",
      "[3522/1762] D loss: 1.3530, G loss: 0.7953\n",
      "train error: \n",
      " D loss: 1.741463, G loss: 0.294443, D accuracy: 48.9%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.744719, G loss: 0.302858, D accuracy: 48.4%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4451, G loss: 0.5661\n",
      "[164/1762] D loss: 0.1158, G loss: 2.4885\n",
      "[324/1762] D loss: 1.4111, G loss: 0.5792\n",
      "[484/1762] D loss: 1.3995, G loss: 0.8531\n",
      "[644/1762] D loss: 0.0278, G loss: 3.8289\n",
      "[804/1762] D loss: 0.2621, G loss: 1.5976\n",
      "[964/1762] D loss: 1.3762, G loss: 0.6452\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.8124\n",
      "[1284/1762] D loss: 1.4076, G loss: 0.6113\n",
      "[1444/1762] D loss: 0.0184, G loss: 4.3626\n",
      "[1604/1762] D loss: 1.5640, G loss: 1.0667\n",
      "[1764/1762] D loss: 1.3730, G loss: 0.7484\n",
      "[1924/1762] D loss: 0.1410, G loss: 2.2904\n",
      "[2084/1762] D loss: 1.4073, G loss: 0.6634\n",
      "[2244/1762] D loss: 0.1734, G loss: 1.9340\n",
      "[2404/1762] D loss: 1.4145, G loss: 1.0105\n",
      "[2564/1762] D loss: 1.4671, G loss: 1.0702\n",
      "[2724/1762] D loss: 0.6578, G loss: 1.5878\n",
      "[2884/1762] D loss: 1.5800, G loss: 0.4353\n",
      "[3044/1762] D loss: 1.5630, G loss: 0.3954\n",
      "[3204/1762] D loss: 1.3172, G loss: 0.7383\n",
      "[3364/1762] D loss: 1.4456, G loss: 0.7791\n",
      "[3522/1762] D loss: 1.4451, G loss: 0.5660\n",
      "train error: \n",
      " D loss: 1.757962, G loss: 0.265680, D accuracy: 48.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.744820, G loss: 0.278286, D accuracy: 48.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4714, G loss: 0.4991\n",
      "[164/1762] D loss: 1.4091, G loss: 0.7972\n",
      "[324/1762] D loss: 0.1556, G loss: 2.0233\n",
      "[484/1762] D loss: 1.2526, G loss: 0.9803\n",
      "[644/1762] D loss: 1.4384, G loss: 0.5329\n",
      "[804/1762] D loss: 1.4107, G loss: 0.7035\n",
      "[964/1762] D loss: 0.2075, G loss: 1.6612\n",
      "[1124/1762] D loss: 1.4070, G loss: 0.7067\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.6153\n",
      "[1444/1762] D loss: 1.4101, G loss: 0.5895\n",
      "[1604/1762] D loss: 1.4099, G loss: 0.6596\n",
      "[1764/1762] D loss: 1.4132, G loss: 0.8158\n",
      "[1924/1762] D loss: 1.3044, G loss: 0.7392\n",
      "[2084/1762] D loss: 1.3740, G loss: 0.8237\n",
      "[2244/1762] D loss: 0.2828, G loss: 1.6375\n",
      "[2404/1762] D loss: 0.2231, G loss: 1.8194\n",
      "[2564/1762] D loss: 1.4977, G loss: 0.9635\n",
      "[2724/1762] D loss: 1.5412, G loss: 0.8784\n",
      "[2884/1762] D loss: 1.5186, G loss: 0.4186\n",
      "[3044/1762] D loss: 1.4276, G loss: 0.8641\n",
      "[3204/1762] D loss: 1.4011, G loss: 0.6593\n",
      "[3364/1762] D loss: 1.3919, G loss: 0.7558\n",
      "[3522/1762] D loss: 1.4083, G loss: 0.7759\n",
      "train error: \n",
      " D loss: 1.619754, G loss: 0.332916, D accuracy: 49.2%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.623420, G loss: 0.336104, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3934, G loss: 0.6304\n",
      "[164/1762] D loss: 1.4865, G loss: 1.0169\n",
      "[324/1762] D loss: 0.1447, G loss: 2.0946\n",
      "[484/1762] D loss: 1.5507, G loss: 1.0181\n",
      "[644/1762] D loss: 1.4935, G loss: 0.9922\n",
      "[804/1762] D loss: 1.4108, G loss: 0.6053\n",
      "[964/1762] D loss: 1.4513, G loss: 0.9646\n",
      "[1124/1762] D loss: 1.4596, G loss: 0.7212\n",
      "[1284/1762] D loss: 1.4105, G loss: 0.5895\n",
      "[1444/1762] D loss: 1.4356, G loss: 0.9337\n",
      "[1604/1762] D loss: 1.4332, G loss: 1.0205\n",
      "[1764/1762] D loss: 1.4296, G loss: 0.8518\n",
      "[1924/1762] D loss: 1.3972, G loss: 0.5996\n",
      "[2084/1762] D loss: 1.4089, G loss: 0.8265\n",
      "[2244/1762] D loss: 0.1592, G loss: 1.9487\n",
      "[2404/1762] D loss: 1.4038, G loss: 0.5963\n",
      "[2564/1762] D loss: 1.3993, G loss: 0.7828\n",
      "[2724/1762] D loss: 0.2306, G loss: 1.6768\n",
      "[2884/1762] D loss: 1.4044, G loss: 0.7612\n",
      "[3044/1762] D loss: 1.1575, G loss: 0.8129\n",
      "[3204/1762] D loss: 1.4013, G loss: 0.8443\n",
      "[3364/1762] D loss: 1.4198, G loss: 0.6091\n",
      "[3522/1762] D loss: 1.4645, G loss: 0.9412\n",
      "train error: \n",
      " D loss: 1.406113, G loss: 0.629254, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416095, G loss: 0.637397, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1802, G loss: 1.9307\n",
      "[164/1762] D loss: 1.4533, G loss: 0.4951\n",
      "[324/1762] D loss: 1.3907, G loss: 0.7058\n",
      "[484/1762] D loss: 1.3967, G loss: 0.6975\n",
      "[644/1762] D loss: 1.3886, G loss: 0.6590\n",
      "[804/1762] D loss: 1.3987, G loss: 0.6553\n",
      "[964/1762] D loss: 1.4445, G loss: 0.8645\n",
      "[1124/1762] D loss: 0.1539, G loss: 2.2678\n",
      "[1284/1762] D loss: 0.0132, G loss: 4.4785\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.6911\n",
      "[1604/1762] D loss: 0.2121, G loss: 1.8675\n",
      "[1764/1762] D loss: 1.4066, G loss: 0.6448\n",
      "[1924/1762] D loss: 1.4212, G loss: 0.7935\n",
      "[2084/1762] D loss: 1.4047, G loss: 0.6048\n",
      "[2244/1762] D loss: 1.3897, G loss: 0.6213\n",
      "[2404/1762] D loss: 1.3972, G loss: 0.7298\n",
      "[2564/1762] D loss: 1.3973, G loss: 0.7564\n",
      "[2724/1762] D loss: 1.3938, G loss: 0.7613\n",
      "[2884/1762] D loss: 1.1622, G loss: 1.5258\n",
      "[3044/1762] D loss: 0.0791, G loss: 2.7193\n",
      "[3204/1762] D loss: 1.4031, G loss: 0.6232\n",
      "[3364/1762] D loss: 1.4156, G loss: 0.9307\n",
      "[3522/1762] D loss: 1.4861, G loss: 0.9241\n",
      "train error: \n",
      " D loss: 1.590286, G loss: 0.405036, D accuracy: 48.1%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.601543, G loss: 0.408246, D accuracy: 47.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4529, G loss: 0.7303\n",
      "[164/1762] D loss: 1.4192, G loss: 0.6912\n",
      "[324/1762] D loss: 1.4476, G loss: 0.5289\n",
      "[484/1762] D loss: 0.0162, G loss: 4.3941\n",
      "[644/1762] D loss: 0.2394, G loss: 1.6540\n",
      "[804/1762] D loss: 1.4049, G loss: 0.7354\n",
      "[964/1762] D loss: 1.3968, G loss: 0.5918\n",
      "[1124/1762] D loss: 0.1160, G loss: 2.4333\n",
      "[1284/1762] D loss: 1.3840, G loss: 0.7548\n",
      "[1444/1762] D loss: 1.4296, G loss: 0.7458\n",
      "[1604/1762] D loss: 1.0202, G loss: 1.2215\n",
      "[1764/1762] D loss: 1.4168, G loss: 0.8430\n",
      "[1924/1762] D loss: 1.4636, G loss: 0.7118\n",
      "[2084/1762] D loss: 1.5020, G loss: 0.9949\n",
      "[2244/1762] D loss: 1.4240, G loss: 0.8421\n",
      "[2404/1762] D loss: 1.4190, G loss: 0.5622\n",
      "[2564/1762] D loss: 1.4180, G loss: 0.6316\n",
      "[2724/1762] D loss: 0.0218, G loss: 4.0931\n",
      "[2884/1762] D loss: 1.3885, G loss: 0.7738\n",
      "[3044/1762] D loss: 1.4693, G loss: 0.5115\n",
      "[3204/1762] D loss: 1.3990, G loss: 0.6444\n",
      "[3364/1762] D loss: 1.4437, G loss: 0.9543\n",
      "[3522/1762] D loss: 1.3954, G loss: 0.6910\n",
      "train error: \n",
      " D loss: 1.614668, G loss: 0.335138, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.613460, G loss: 0.340429, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4047, G loss: 0.8767\n",
      "[164/1762] D loss: 1.4168, G loss: 0.8100\n",
      "[324/1762] D loss: 1.3876, G loss: 0.7256\n",
      "[484/1762] D loss: 1.3733, G loss: 0.8319\n",
      "[644/1762] D loss: 0.6854, G loss: 1.4614\n",
      "[804/1762] D loss: 0.0338, G loss: 3.9556\n",
      "[964/1762] D loss: 1.4024, G loss: 0.6866\n",
      "[1124/1762] D loss: 1.4069, G loss: 0.5963\n",
      "[1284/1762] D loss: 1.4960, G loss: 0.9443\n",
      "[1444/1762] D loss: 1.4425, G loss: 0.7390\n",
      "[1604/1762] D loss: 1.4285, G loss: 0.9216\n",
      "[1764/1762] D loss: 0.1726, G loss: 1.9125\n",
      "[1924/1762] D loss: 1.3893, G loss: 0.7647\n",
      "[2084/1762] D loss: 0.1518, G loss: 2.0201\n",
      "[2244/1762] D loss: 1.4092, G loss: 0.7656\n",
      "[2404/1762] D loss: 0.1598, G loss: 1.9969\n",
      "[2564/1762] D loss: 1.3603, G loss: 0.7657\n",
      "[2724/1762] D loss: 0.0122, G loss: 4.5562\n",
      "[2884/1762] D loss: 1.4158, G loss: 0.5110\n",
      "[3044/1762] D loss: 1.3773, G loss: 0.8655\n",
      "[3204/1762] D loss: 1.4036, G loss: 0.6278\n",
      "[3364/1762] D loss: 0.2067, G loss: 2.0478\n",
      "[3522/1762] D loss: 1.4311, G loss: 0.7151\n",
      "train error: \n",
      " D loss: 1.514005, G loss: 0.453591, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.528183, G loss: 0.454589, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3791, G loss: 0.6111\n",
      "[164/1762] D loss: 0.3802, G loss: 1.2463\n",
      "[324/1762] D loss: 0.2362, G loss: 1.7811\n",
      "[484/1762] D loss: 1.3887, G loss: 0.8868\n",
      "[644/1762] D loss: 1.3986, G loss: 0.7499\n",
      "[804/1762] D loss: 0.1102, G loss: 2.3923\n",
      "[964/1762] D loss: 1.4041, G loss: 0.5533\n",
      "[1124/1762] D loss: 1.4976, G loss: 0.9144\n",
      "[1284/1762] D loss: 1.1937, G loss: 0.9341\n",
      "[1444/1762] D loss: 0.9928, G loss: 2.0175\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.8803\n",
      "[1764/1762] D loss: 0.0715, G loss: 2.7674\n",
      "[1924/1762] D loss: 0.1263, G loss: 2.5228\n",
      "[2084/1762] D loss: 1.3803, G loss: 0.6080\n",
      "[2244/1762] D loss: 1.4148, G loss: 0.7034\n",
      "[2404/1762] D loss: 1.3927, G loss: 0.5979\n",
      "[2564/1762] D loss: 1.3998, G loss: 0.7647\n",
      "[2724/1762] D loss: 1.3847, G loss: 0.6653\n",
      "[2884/1762] D loss: 1.4012, G loss: 0.6315\n",
      "[3044/1762] D loss: 1.4004, G loss: 0.6673\n",
      "[3204/1762] D loss: 1.2788, G loss: 0.9485\n",
      "[3364/1762] D loss: 0.1707, G loss: 2.0989\n",
      "[3522/1762] D loss: 1.4184, G loss: 0.5086\n",
      "train error: \n",
      " D loss: 1.515625, G loss: 0.460503, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.521270, G loss: 0.464998, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4280, G loss: 0.5281\n",
      "[164/1762] D loss: 1.4115, G loss: 0.8224\n",
      "[324/1762] D loss: 1.4242, G loss: 0.6151\n",
      "[484/1762] D loss: 1.3920, G loss: 0.7300\n",
      "[644/1762] D loss: 1.3989, G loss: 0.7775\n",
      "[804/1762] D loss: 0.0143, G loss: 4.4564\n",
      "[964/1762] D loss: 1.2308, G loss: 1.0133\n",
      "[1124/1762] D loss: 1.4580, G loss: 0.5623\n",
      "[1284/1762] D loss: 1.4083, G loss: 0.5366\n",
      "[1444/1762] D loss: 0.1284, G loss: 2.1862\n",
      "[1604/1762] D loss: 1.4286, G loss: 0.8011\n",
      "[1764/1762] D loss: 1.4022, G loss: 0.8065\n",
      "[1924/1762] D loss: 1.5740, G loss: 1.0317\n",
      "[2084/1762] D loss: 0.1724, G loss: 1.9164\n",
      "[2244/1762] D loss: 1.3991, G loss: 0.7680\n",
      "[2404/1762] D loss: 1.1820, G loss: 0.6616\n",
      "[2564/1762] D loss: 1.3977, G loss: 0.8219\n",
      "[2724/1762] D loss: 0.0837, G loss: 2.6831\n",
      "[2884/1762] D loss: 1.4098, G loss: 0.7803\n",
      "[3044/1762] D loss: 1.3904, G loss: 0.7020\n",
      "[3204/1762] D loss: 1.6428, G loss: 1.1779\n",
      "[3364/1762] D loss: 0.1587, G loss: 1.9993\n",
      "[3522/1762] D loss: 1.4424, G loss: 0.5798\n",
      "train error: \n",
      " D loss: 1.538146, G loss: 0.437125, D accuracy: 49.3%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.548601, G loss: 0.438936, D accuracy: 49.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4461, G loss: 0.6768\n",
      "[164/1762] D loss: 1.6199, G loss: 1.1633\n",
      "[324/1762] D loss: 0.0980, G loss: 2.4860\n",
      "[484/1762] D loss: 0.1334, G loss: 2.1412\n",
      "[644/1762] D loss: 1.4046, G loss: 0.7749\n",
      "[804/1762] D loss: 1.3955, G loss: 0.6688\n",
      "[964/1762] D loss: 1.3960, G loss: 0.6703\n",
      "[1124/1762] D loss: 1.3851, G loss: 0.6540\n",
      "[1284/1762] D loss: 1.3828, G loss: 0.6198\n",
      "[1444/1762] D loss: 1.4126, G loss: 0.8056\n",
      "[1604/1762] D loss: 1.4119, G loss: 0.6089\n",
      "[1764/1762] D loss: 1.3958, G loss: 0.6635\n",
      "[1924/1762] D loss: 1.3894, G loss: 0.6566\n",
      "[2084/1762] D loss: 0.0183, G loss: 4.1128\n",
      "[2244/1762] D loss: 1.4418, G loss: 0.7650\n",
      "[2404/1762] D loss: 1.3911, G loss: 0.5776\n",
      "[2564/1762] D loss: 1.4000, G loss: 0.5725\n",
      "[2724/1762] D loss: 1.4448, G loss: 0.7363\n",
      "[2884/1762] D loss: 1.4144, G loss: 0.6004\n",
      "[3044/1762] D loss: 0.0683, G loss: 2.5653\n",
      "[3204/1762] D loss: 1.4007, G loss: 0.7877\n",
      "[3364/1762] D loss: 1.4721, G loss: 0.7392\n",
      "[3522/1762] D loss: 1.7093, G loss: 1.1858\n",
      "train error: \n",
      " D loss: 1.511227, G loss: 0.767184, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.551866, G loss: 0.761665, D accuracy: 51.8%, cell accuracy: 99.7%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4669, G loss: 0.9073\n",
      "[164/1762] D loss: 1.4383, G loss: 0.5794\n",
      "[324/1762] D loss: 1.4718, G loss: 1.1343\n",
      "[484/1762] D loss: 0.8807, G loss: 1.5969\n",
      "[644/1762] D loss: 1.4043, G loss: 0.7020\n",
      "[804/1762] D loss: 1.4127, G loss: 0.9355\n",
      "[964/1762] D loss: 0.1523, G loss: 2.0518\n",
      "[1124/1762] D loss: 1.4197, G loss: 0.8614\n",
      "[1284/1762] D loss: 1.4116, G loss: 0.6748\n",
      "[1444/1762] D loss: 1.4286, G loss: 0.6097\n",
      "[1604/1762] D loss: 0.0892, G loss: 2.4597\n",
      "[1764/1762] D loss: 1.3959, G loss: 0.7324\n",
      "[1924/1762] D loss: 0.0942, G loss: 2.5363\n",
      "[2084/1762] D loss: 1.4215, G loss: 0.6563\n",
      "[2244/1762] D loss: 1.3884, G loss: 0.6775\n",
      "[2404/1762] D loss: 1.4617, G loss: 0.8946\n",
      "[2564/1762] D loss: 0.1415, G loss: 2.2987\n",
      "[2724/1762] D loss: 0.1318, G loss: 2.2139\n",
      "[2884/1762] D loss: 0.0962, G loss: 2.5156\n",
      "[3044/1762] D loss: 0.1274, G loss: 2.2813\n",
      "[3204/1762] D loss: 0.0791, G loss: 2.6767\n",
      "[3364/1762] D loss: 0.1191, G loss: 2.5323\n",
      "[3522/1762] D loss: 0.0087, G loss: 4.7883\n",
      "train error: \n",
      " D loss: 2.588913, G loss: 0.096202, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.570493, G loss: 0.098183, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0106, G loss: 4.6156\n",
      "[164/1762] D loss: 1.3974, G loss: 0.8197\n",
      "[324/1762] D loss: 1.4004, G loss: 0.6600\n",
      "[484/1762] D loss: 1.5089, G loss: 0.8319\n",
      "[644/1762] D loss: 1.4110, G loss: 0.7162\n",
      "[804/1762] D loss: 1.4041, G loss: 0.6871\n",
      "[964/1762] D loss: 0.0941, G loss: 2.4663\n",
      "[1124/1762] D loss: 1.6145, G loss: 0.7564\n",
      "[1284/1762] D loss: 0.0978, G loss: 2.5672\n",
      "[1444/1762] D loss: 1.4200, G loss: 0.8551\n",
      "[1604/1762] D loss: 1.4105, G loss: 0.5221\n",
      "[1764/1762] D loss: 1.3983, G loss: 0.8139\n",
      "[1924/1762] D loss: 1.4591, G loss: 0.4675\n",
      "[2084/1762] D loss: 0.0559, G loss: 2.9980\n",
      "[2244/1762] D loss: 1.4099, G loss: 0.6842\n",
      "[2404/1762] D loss: 1.3814, G loss: 0.7452\n",
      "[2564/1762] D loss: 0.1931, G loss: 2.4196\n",
      "[2724/1762] D loss: 1.5429, G loss: 1.0798\n",
      "[2884/1762] D loss: 1.5032, G loss: 0.4535\n",
      "[3044/1762] D loss: 1.4434, G loss: 0.8484\n",
      "[3204/1762] D loss: 1.4020, G loss: 0.6221\n",
      "[3364/1762] D loss: 1.4193, G loss: 0.6743\n",
      "[3522/1762] D loss: 1.4105, G loss: 0.8646\n",
      "train error: \n",
      " D loss: 1.808766, G loss: 0.276196, D accuracy: 47.3%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.810002, G loss: 0.284519, D accuracy: 46.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4393, G loss: 1.3708\n",
      "[164/1762] D loss: 1.4237, G loss: 0.8450\n",
      "[324/1762] D loss: 0.1456, G loss: 2.0895\n",
      "[484/1762] D loss: 1.5334, G loss: 0.5097\n",
      "[644/1762] D loss: 1.4289, G loss: 0.5179\n",
      "[804/1762] D loss: 1.4052, G loss: 0.5443\n",
      "[964/1762] D loss: 1.3986, G loss: 0.7268\n",
      "[1124/1762] D loss: 1.3993, G loss: 0.7813\n",
      "[1284/1762] D loss: 1.3841, G loss: 0.6533\n",
      "[1444/1762] D loss: 1.4010, G loss: 0.7238\n",
      "[1604/1762] D loss: 0.0899, G loss: 2.5730\n",
      "[1764/1762] D loss: 1.4198, G loss: 0.5675\n",
      "[1924/1762] D loss: 0.0996, G loss: 2.4665\n",
      "[2084/1762] D loss: 1.4084, G loss: 0.6484\n",
      "[2244/1762] D loss: 1.3939, G loss: 0.7437\n",
      "[2404/1762] D loss: 1.3871, G loss: 0.6434\n",
      "[2564/1762] D loss: 0.0109, G loss: 4.5718\n",
      "[2724/1762] D loss: 1.3940, G loss: 0.7924\n",
      "[2884/1762] D loss: 1.4016, G loss: 0.6672\n",
      "[3044/1762] D loss: 1.4299, G loss: 0.8519\n",
      "[3204/1762] D loss: 1.3915, G loss: 0.7381\n",
      "[3364/1762] D loss: 1.3987, G loss: 0.6947\n",
      "[3522/1762] D loss: 1.4813, G loss: 0.8096\n",
      "train error: \n",
      " D loss: 1.561551, G loss: 0.533797, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.584890, G loss: 0.545408, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0826, G loss: 2.5273\n",
      "[164/1762] D loss: 1.4601, G loss: 0.9261\n",
      "[324/1762] D loss: 1.3887, G loss: 0.7618\n",
      "[484/1762] D loss: 1.3998, G loss: 0.6406\n",
      "[644/1762] D loss: 1.5347, G loss: 1.0114\n",
      "[804/1762] D loss: 1.4144, G loss: 0.7382\n",
      "[964/1762] D loss: 0.0057, G loss: 5.2829\n",
      "[1124/1762] D loss: 1.4205, G loss: 0.7997\n",
      "[1284/1762] D loss: 0.0672, G loss: 2.7929\n",
      "[1444/1762] D loss: 0.0663, G loss: 2.8974\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.7082\n",
      "[1764/1762] D loss: 0.0648, G loss: 2.7432\n",
      "[1924/1762] D loss: 0.0724, G loss: 3.0793\n",
      "[2084/1762] D loss: 1.4037, G loss: 0.6217\n",
      "[2244/1762] D loss: 1.4033, G loss: 0.7594\n",
      "[2404/1762] D loss: 1.4078, G loss: 0.6242\n",
      "[2564/1762] D loss: 1.4169, G loss: 0.6061\n",
      "[2724/1762] D loss: 0.0564, G loss: 2.9995\n",
      "[2884/1762] D loss: 1.4086, G loss: 0.7423\n",
      "[3044/1762] D loss: 1.5656, G loss: 0.8659\n",
      "[3204/1762] D loss: 0.1109, G loss: 2.6134\n",
      "[3364/1762] D loss: 0.1044, G loss: 2.3497\n",
      "[3522/1762] D loss: 1.4886, G loss: 0.9086\n",
      "train error: \n",
      " D loss: 2.118615, G loss: 0.169438, D accuracy: 48.3%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.115222, G loss: 0.173830, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4143, G loss: 0.7054\n",
      "[164/1762] D loss: 0.0868, G loss: 2.7003\n",
      "[324/1762] D loss: 1.4069, G loss: 0.7723\n",
      "[484/1762] D loss: 0.0827, G loss: 2.7551\n",
      "[644/1762] D loss: 1.4075, G loss: 0.7393\n",
      "[804/1762] D loss: 0.1376, G loss: 1.9870\n",
      "[964/1762] D loss: 1.3926, G loss: 0.6472\n",
      "[1124/1762] D loss: 1.4076, G loss: 0.7821\n",
      "[1284/1762] D loss: 0.0378, G loss: 3.4719\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.7341\n",
      "[1604/1762] D loss: 1.4247, G loss: 0.5380\n",
      "[1764/1762] D loss: 1.4010, G loss: 0.8123\n",
      "[1924/1762] D loss: 1.4419, G loss: 0.8949\n",
      "[2084/1762] D loss: 1.3996, G loss: 0.8280\n",
      "[2244/1762] D loss: 0.0292, G loss: 3.6644\n",
      "[2404/1762] D loss: 0.0541, G loss: 2.8487\n",
      "[2564/1762] D loss: 1.3789, G loss: 0.8129\n",
      "[2724/1762] D loss: 1.4566, G loss: 0.5017\n",
      "[2884/1762] D loss: 1.4498, G loss: 0.9199\n",
      "[3044/1762] D loss: 1.3803, G loss: 0.7010\n",
      "[3204/1762] D loss: 1.4738, G loss: 0.8033\n",
      "[3364/1762] D loss: 0.3498, G loss: 1.4832\n",
      "[3522/1762] D loss: 1.4081, G loss: 0.7032\n",
      "train error: \n",
      " D loss: 1.541734, G loss: 0.520862, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.563617, G loss: 0.517449, D accuracy: 49.5%, cell accuracy: 99.7%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2263, G loss: 1.8137\n",
      "[164/1762] D loss: 1.4415, G loss: 0.7881\n",
      "[324/1762] D loss: 0.1422, G loss: 2.1200\n",
      "[484/1762] D loss: 1.0030, G loss: 1.1174\n",
      "[644/1762] D loss: 1.4092, G loss: 0.7265\n",
      "[804/1762] D loss: 0.1776, G loss: 1.8844\n",
      "[964/1762] D loss: 1.4003, G loss: 0.7648\n",
      "[1124/1762] D loss: 0.1377, G loss: 2.2502\n",
      "[1284/1762] D loss: 1.4907, G loss: 0.9442\n",
      "[1444/1762] D loss: 1.4056, G loss: 0.7643\n",
      "[1604/1762] D loss: 0.1323, G loss: 2.1424\n",
      "[1764/1762] D loss: 1.4117, G loss: 0.7696\n",
      "[1924/1762] D loss: 1.3971, G loss: 0.7606\n",
      "[2084/1762] D loss: 1.3962, G loss: 0.6654\n",
      "[2244/1762] D loss: 1.4038, G loss: 0.6631\n",
      "[2404/1762] D loss: 1.4046, G loss: 0.7819\n",
      "[2564/1762] D loss: 1.4185, G loss: 0.6186\n",
      "[2724/1762] D loss: 1.4107, G loss: 1.3980\n",
      "[2884/1762] D loss: 1.4090, G loss: 0.6211\n",
      "[3044/1762] D loss: 1.4215, G loss: 0.8893\n",
      "[3204/1762] D loss: 0.1319, G loss: 2.2657\n",
      "[3364/1762] D loss: 1.4083, G loss: 0.6508\n",
      "[3522/1762] D loss: 1.4035, G loss: 0.6121\n",
      "train error: \n",
      " D loss: 1.749348, G loss: 0.323609, D accuracy: 47.3%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.762956, G loss: 0.331296, D accuracy: 46.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4012, G loss: 0.5981\n",
      "[164/1762] D loss: 1.3972, G loss: 0.6621\n",
      "[324/1762] D loss: 1.4323, G loss: 0.8012\n",
      "[484/1762] D loss: 0.0803, G loss: 2.6878\n",
      "[644/1762] D loss: 0.0944, G loss: 2.5757\n",
      "[804/1762] D loss: 1.4008, G loss: 0.7403\n",
      "[964/1762] D loss: 1.4013, G loss: 0.7591\n",
      "[1124/1762] D loss: 1.4353, G loss: 0.5949\n",
      "[1284/1762] D loss: 1.3856, G loss: 0.6587\n",
      "[1444/1762] D loss: 0.1127, G loss: 2.3498\n",
      "[1604/1762] D loss: 1.3944, G loss: 0.5945\n",
      "[1764/1762] D loss: 0.9237, G loss: 3.3799\n",
      "[1924/1762] D loss: 1.3937, G loss: 0.7557\n",
      "[2084/1762] D loss: 1.4018, G loss: 0.7894\n",
      "[2244/1762] D loss: 1.4136, G loss: 0.7713\n",
      "[2404/1762] D loss: 1.4252, G loss: 0.8537\n",
      "[2564/1762] D loss: 1.3885, G loss: 0.6573\n",
      "[2724/1762] D loss: 1.3876, G loss: 0.6832\n",
      "[2884/1762] D loss: 1.3971, G loss: 0.5775\n",
      "[3044/1762] D loss: 0.1284, G loss: 2.3928\n",
      "[3204/1762] D loss: 1.4019, G loss: 0.5407\n",
      "[3364/1762] D loss: 0.1246, G loss: 2.4009\n",
      "[3522/1762] D loss: 1.4105, G loss: 0.5607\n",
      "train error: \n",
      " D loss: 1.648239, G loss: 0.507370, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.696768, G loss: 0.509761, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3968, G loss: 0.7108\n",
      "[164/1762] D loss: 1.4108, G loss: 0.7367\n",
      "[324/1762] D loss: 1.3045, G loss: 1.1558\n",
      "[484/1762] D loss: 0.0754, G loss: 2.9942\n",
      "[644/1762] D loss: 1.4449, G loss: 0.9570\n",
      "[804/1762] D loss: 1.4024, G loss: 1.1953\n",
      "[964/1762] D loss: 0.0621, G loss: 3.0562\n",
      "[1124/1762] D loss: 1.4864, G loss: 0.5264\n",
      "[1284/1762] D loss: 0.1344, G loss: 2.3151\n",
      "[1444/1762] D loss: 1.4143, G loss: 0.5815\n",
      "[1604/1762] D loss: 1.3844, G loss: 0.8090\n",
      "[1764/1762] D loss: 0.0762, G loss: 2.9777\n",
      "[1924/1762] D loss: 0.8832, G loss: 1.5057\n",
      "[2084/1762] D loss: 1.5059, G loss: 0.9249\n",
      "[2244/1762] D loss: 0.1010, G loss: 2.6618\n",
      "[2404/1762] D loss: 0.1481, G loss: 2.2878\n",
      "[2564/1762] D loss: 1.4052, G loss: 0.6312\n",
      "[2724/1762] D loss: 1.5006, G loss: 0.5268\n",
      "[2884/1762] D loss: 0.1556, G loss: 1.9773\n",
      "[3044/1762] D loss: 1.4943, G loss: 0.9501\n",
      "[3204/1762] D loss: 1.3947, G loss: 0.6242\n",
      "[3364/1762] D loss: 1.3906, G loss: 0.7444\n",
      "[3522/1762] D loss: 1.3768, G loss: 0.7068\n",
      "train error: \n",
      " D loss: 1.716295, G loss: 0.452474, D accuracy: 47.7%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.764748, G loss: 0.458962, D accuracy: 47.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1826, G loss: 1.8776\n",
      "[164/1762] D loss: 1.4372, G loss: 0.9234\n",
      "[324/1762] D loss: 0.1051, G loss: 2.3965\n",
      "[484/1762] D loss: 1.3936, G loss: 0.6703\n",
      "[644/1762] D loss: 1.3926, G loss: 0.6677\n",
      "[804/1762] D loss: 0.0981, G loss: 2.7213\n",
      "[964/1762] D loss: 1.2380, G loss: 0.8199\n",
      "[1124/1762] D loss: 1.4198, G loss: 0.9144\n",
      "[1284/1762] D loss: 0.1018, G loss: 3.0893\n",
      "[1444/1762] D loss: 0.1217, G loss: 2.3716\n",
      "[1604/1762] D loss: 1.3931, G loss: 0.5836\n",
      "[1764/1762] D loss: 1.2605, G loss: 0.7620\n",
      "[1924/1762] D loss: 0.1564, G loss: 1.9790\n",
      "[2084/1762] D loss: 1.4285, G loss: 0.8307\n",
      "[2244/1762] D loss: 0.0892, G loss: 2.7180\n",
      "[2404/1762] D loss: 1.3908, G loss: 0.6400\n",
      "[2564/1762] D loss: 1.4063, G loss: 0.7032\n",
      "[2724/1762] D loss: 1.4167, G loss: 0.4983\n",
      "[2884/1762] D loss: 1.3903, G loss: 0.7161\n",
      "[3044/1762] D loss: 0.1474, G loss: 2.1297\n",
      "[3204/1762] D loss: 1.3909, G loss: 0.7432\n",
      "[3364/1762] D loss: 1.4691, G loss: 0.9199\n",
      "[3522/1762] D loss: 1.4544, G loss: 0.4965\n",
      "train error: \n",
      " D loss: 1.983414, G loss: 0.232035, D accuracy: 47.1%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.017784, G loss: 0.233364, D accuracy: 46.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4019, G loss: 0.6456\n",
      "[164/1762] D loss: 1.4375, G loss: 0.8736\n",
      "[324/1762] D loss: 0.1616, G loss: 2.0954\n",
      "[484/1762] D loss: 1.4318, G loss: 0.5033\n",
      "[644/1762] D loss: 1.5065, G loss: 0.9770\n",
      "[804/1762] D loss: 0.0760, G loss: 2.6565\n",
      "[964/1762] D loss: 0.0067, G loss: 5.1466\n",
      "[1124/1762] D loss: 1.4618, G loss: 0.6052\n",
      "[1284/1762] D loss: 0.1137, G loss: 2.2896\n",
      "[1444/1762] D loss: 1.3637, G loss: 0.7483\n",
      "[1604/1762] D loss: 0.1540, G loss: 1.9978\n",
      "[1764/1762] D loss: 0.1222, G loss: 2.2552\n",
      "[1924/1762] D loss: 0.0842, G loss: 2.6217\n",
      "[2084/1762] D loss: 1.4434, G loss: 0.6162\n",
      "[2244/1762] D loss: 0.1237, G loss: 2.5360\n",
      "[2404/1762] D loss: 1.3884, G loss: 0.6826\n",
      "[2564/1762] D loss: 1.3888, G loss: 0.7367\n",
      "[2724/1762] D loss: 0.1091, G loss: 2.4119\n",
      "[2884/1762] D loss: 1.3902, G loss: 0.7553\n",
      "[3044/1762] D loss: 1.3909, G loss: 0.6368\n",
      "[3204/1762] D loss: 1.4116, G loss: 0.7649\n",
      "[3364/1762] D loss: 1.3977, G loss: 0.6851\n",
      "[3522/1762] D loss: 1.4040, G loss: 0.5559\n",
      "train error: \n",
      " D loss: 1.908812, G loss: 0.258950, D accuracy: 47.2%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.940368, G loss: 0.265649, D accuracy: 46.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4210, G loss: 0.7291\n",
      "[164/1762] D loss: 1.3985, G loss: 0.8279\n",
      "[324/1762] D loss: 1.4022, G loss: 0.7081\n",
      "[484/1762] D loss: 1.5266, G loss: 0.4563\n",
      "[644/1762] D loss: 1.3992, G loss: 0.8064\n",
      "[804/1762] D loss: 1.3966, G loss: 0.5788\n",
      "[964/1762] D loss: 1.4438, G loss: 0.8682\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7095\n",
      "[1284/1762] D loss: 0.1001, G loss: 2.4033\n",
      "[1444/1762] D loss: 1.4284, G loss: 0.9065\n",
      "[1604/1762] D loss: 1.3913, G loss: 0.5807\n",
      "[1764/1762] D loss: 1.4147, G loss: 0.8573\n",
      "[1924/1762] D loss: 1.3932, G loss: 0.6762\n",
      "[2084/1762] D loss: 0.8281, G loss: 2.1074\n",
      "[2244/1762] D loss: 1.4104, G loss: 0.8337\n",
      "[2404/1762] D loss: 1.4584, G loss: 0.5300\n",
      "[2564/1762] D loss: 1.3974, G loss: 0.6019\n",
      "[2724/1762] D loss: 1.3918, G loss: 0.7411\n",
      "[2884/1762] D loss: 1.3924, G loss: 0.7789\n",
      "[3044/1762] D loss: 1.3994, G loss: 0.6561\n",
      "[3204/1762] D loss: 1.4253, G loss: 0.7460\n",
      "[3364/1762] D loss: 1.3969, G loss: 0.8587\n",
      "[3522/1762] D loss: 1.3910, G loss: 0.6090\n",
      "train error: \n",
      " D loss: 2.292264, G loss: 0.168996, D accuracy: 47.9%, cell accuracy: 99.6%, board accuracy: 71.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.311480, G loss: 0.175245, D accuracy: 47.0%, cell accuracy: 99.5%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9247, G loss: 1.2867\n",
      "[164/1762] D loss: 1.0119, G loss: 1.3832\n",
      "[324/1762] D loss: 1.9446, G loss: 1.2117\n",
      "[484/1762] D loss: 1.5131, G loss: 1.2006\n",
      "[644/1762] D loss: 1.3371, G loss: 0.9758\n",
      "[804/1762] D loss: 1.4084, G loss: 0.6684\n",
      "[964/1762] D loss: 0.0865, G loss: 3.3307\n",
      "[1124/1762] D loss: 1.3989, G loss: 0.7999\n",
      "[1284/1762] D loss: 1.4548, G loss: 0.7377\n",
      "[1444/1762] D loss: 1.4684, G loss: 0.9389\n",
      "[1604/1762] D loss: 1.4282, G loss: 0.5488\n",
      "[1764/1762] D loss: 0.1008, G loss: 2.3601\n",
      "[1924/1762] D loss: 1.4591, G loss: 0.8922\n",
      "[2084/1762] D loss: 1.3956, G loss: 0.5688\n",
      "[2244/1762] D loss: 1.3437, G loss: 0.9571\n",
      "[2404/1762] D loss: 1.4527, G loss: 0.8546\n",
      "[2564/1762] D loss: 0.0795, G loss: 2.7658\n",
      "[2724/1762] D loss: 1.4278, G loss: 0.8381\n",
      "[2884/1762] D loss: 1.4691, G loss: 0.9320\n",
      "[3044/1762] D loss: 0.0485, G loss: 3.2499\n",
      "[3204/1762] D loss: 1.5131, G loss: 0.9892\n",
      "[3364/1762] D loss: 1.4501, G loss: 0.6353\n",
      "[3522/1762] D loss: 1.3919, G loss: 0.5865\n",
      "train error: \n",
      " D loss: 2.629689, G loss: 0.097893, D accuracy: 47.4%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.632024, G loss: 0.101523, D accuracy: 46.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1418, G loss: 1.8771\n",
      "[164/1762] D loss: 1.3878, G loss: 0.7721\n",
      "[324/1762] D loss: 0.1313, G loss: 2.1614\n",
      "[484/1762] D loss: 1.4624, G loss: 1.0137\n",
      "[644/1762] D loss: 1.3920, G loss: 0.6122\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6848\n",
      "[964/1762] D loss: 0.2376, G loss: 1.7208\n",
      "[1124/1762] D loss: 1.3954, G loss: 0.7329\n",
      "[1284/1762] D loss: 1.4140, G loss: 0.8569\n",
      "[1444/1762] D loss: 1.3977, G loss: 0.5278\n",
      "[1604/1762] D loss: 1.4130, G loss: 0.7831\n",
      "[1764/1762] D loss: 1.4011, G loss: 0.6585\n",
      "[1924/1762] D loss: 1.3901, G loss: 0.7859\n",
      "[2084/1762] D loss: 0.0644, G loss: 2.8473\n",
      "[2244/1762] D loss: 1.4043, G loss: 0.5373\n",
      "[2404/1762] D loss: 1.4550, G loss: 0.5087\n",
      "[2564/1762] D loss: 0.0854, G loss: 2.4735\n",
      "[2724/1762] D loss: 0.0609, G loss: 3.0979\n",
      "[2884/1762] D loss: 0.0042, G loss: 5.3522\n",
      "[3044/1762] D loss: 1.3935, G loss: 0.7446\n",
      "[3204/1762] D loss: 1.4067, G loss: 0.7856\n",
      "[3364/1762] D loss: 1.3938, G loss: 0.7367\n",
      "[3522/1762] D loss: 1.4565, G loss: 0.8304\n",
      "train error: \n",
      " D loss: 2.720133, G loss: 0.093817, D accuracy: 47.1%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.727770, G loss: 0.097244, D accuracy: 46.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4257, G loss: 0.7144\n",
      "[164/1762] D loss: 1.4080, G loss: 0.6600\n",
      "[324/1762] D loss: 0.0713, G loss: 2.7469\n",
      "[484/1762] D loss: 1.3969, G loss: 0.7539\n",
      "[644/1762] D loss: 0.0870, G loss: 2.7489\n",
      "[804/1762] D loss: 0.0738, G loss: 2.6332\n",
      "[964/1762] D loss: 1.2769, G loss: 1.1358\n",
      "[1124/1762] D loss: 1.4340, G loss: 0.6686\n",
      "[1284/1762] D loss: 0.0512, G loss: 3.0740\n",
      "[1444/1762] D loss: 0.0498, G loss: 3.3245\n",
      "[1604/1762] D loss: 0.0813, G loss: 2.8793\n",
      "[1764/1762] D loss: 1.4140, G loss: 0.5283\n",
      "[1924/1762] D loss: 1.5003, G loss: 0.9976\n",
      "[2084/1762] D loss: 1.4067, G loss: 0.6375\n",
      "[2244/1762] D loss: 0.0785, G loss: 2.8716\n",
      "[2404/1762] D loss: 1.4276, G loss: 0.5187\n",
      "[2564/1762] D loss: 1.3978, G loss: 0.7654\n",
      "[2724/1762] D loss: 0.2219, G loss: 1.7859\n",
      "[2884/1762] D loss: 1.4406, G loss: 0.5189\n",
      "[3044/1762] D loss: 1.3997, G loss: 0.7277\n",
      "[3204/1762] D loss: 1.4387, G loss: 0.8538\n",
      "[3364/1762] D loss: 0.0335, G loss: 3.7661\n",
      "[3522/1762] D loss: 1.4093, G loss: 0.6171\n",
      "train error: \n",
      " D loss: 2.015461, G loss: 0.230316, D accuracy: 47.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.033625, G loss: 0.243593, D accuracy: 46.8%, cell accuracy: 99.7%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.6871\n",
      "[164/1762] D loss: 1.3661, G loss: 0.5595\n",
      "[324/1762] D loss: 1.3920, G loss: 0.6885\n",
      "[484/1762] D loss: 0.8641, G loss: 1.2952\n",
      "[644/1762] D loss: 0.0923, G loss: 2.7334\n",
      "[804/1762] D loss: 0.0676, G loss: 3.0173\n",
      "[964/1762] D loss: 0.1556, G loss: 1.9652\n",
      "[1124/1762] D loss: 0.0850, G loss: 2.4968\n",
      "[1284/1762] D loss: 1.6738, G loss: 0.4520\n",
      "[1444/1762] D loss: 1.4086, G loss: 0.5822\n",
      "[1604/1762] D loss: 0.0812, G loss: 2.7726\n",
      "[1764/1762] D loss: 1.4121, G loss: 0.7323\n",
      "[1924/1762] D loss: 0.1190, G loss: 2.3710\n",
      "[2084/1762] D loss: 0.0333, G loss: 3.6487\n",
      "[2244/1762] D loss: 1.4601, G loss: 0.5500\n",
      "[2404/1762] D loss: 1.3767, G loss: 0.8735\n",
      "[2564/1762] D loss: 1.3908, G loss: 0.7322\n",
      "[2724/1762] D loss: 1.4112, G loss: 0.7323\n",
      "[2884/1762] D loss: 1.4692, G loss: 0.9336\n",
      "[3044/1762] D loss: 1.4009, G loss: 0.6843\n",
      "[3204/1762] D loss: 1.4092, G loss: 0.7545\n",
      "[3364/1762] D loss: 1.3896, G loss: 0.7021\n",
      "[3522/1762] D loss: 1.4042, G loss: 0.6019\n",
      "train error: \n",
      " D loss: 2.040995, G loss: 0.270085, D accuracy: 47.6%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.117415, G loss: 0.275602, D accuracy: 46.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4701, G loss: 0.9389\n",
      "[324/1762] D loss: 0.8750, G loss: 1.1188\n",
      "[644/1762] D loss: 0.3248, G loss: 2.0017\n",
      "[964/1762] D loss: 0.1137, G loss: 3.1585\n",
      "[1284/1762] D loss: 0.0357, G loss: 4.5907\n",
      "[1604/1762] D loss: 0.0569, G loss: 4.0541\n",
      "[1924/1762] D loss: 0.0422, G loss: 3.5902\n",
      "[2244/1762] D loss: 0.0173, G loss: 5.1912\n",
      "[2564/1762] D loss: 0.0254, G loss: 6.1303\n",
      "[2884/1762] D loss: 0.6491, G loss: 3.7876\n",
      "[3204/1762] D loss: 1.7636, G loss: 0.9744\n",
      "[3524/1762] D loss: 0.4967, G loss: 1.7052\n",
      "[3844/1762] D loss: 0.3373, G loss: 2.2487\n",
      "[4164/1762] D loss: 0.4231, G loss: 2.1485\n",
      "[4484/1762] D loss: 0.4767, G loss: 2.9822\n",
      "[4804/1762] D loss: 1.5557, G loss: 0.7811\n",
      "[5124/1762] D loss: 1.3741, G loss: 2.1324\n",
      "[5444/1762] D loss: 1.2216, G loss: 1.8801\n",
      "[5764/1762] D loss: 1.1348, G loss: 0.6961\n",
      "[6084/1762] D loss: 1.3552, G loss: 0.6619\n",
      "[6404/1762] D loss: 1.2752, G loss: 1.7127\n",
      "[6724/1762] D loss: 1.2877, G loss: 0.7379\n",
      "[7042/1762] D loss: 1.0458, G loss: 1.0379\n",
      "train error: \n",
      " D loss: 1.306478, G loss: 0.790823, D accuracy: 59.7%, cell accuracy: 99.6%, board accuracy: 73.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294033, G loss: 0.811595, D accuracy: 61.0%, cell accuracy: 99.6%, board accuracy: 72.5% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0605, G loss: 1.1683\n",
      "[324/1762] D loss: 1.4748, G loss: 0.5755\n",
      "[644/1762] D loss: 1.3718, G loss: 0.6725\n",
      "[964/1762] D loss: 1.3730, G loss: 0.8255\n",
      "[1284/1762] D loss: 1.1866, G loss: 1.2510\n",
      "[1604/1762] D loss: 1.5101, G loss: 1.0387\n",
      "[1924/1762] D loss: 1.2316, G loss: 0.6922\n",
      "[2244/1762] D loss: 1.3966, G loss: 0.8297\n",
      "[2564/1762] D loss: 1.3724, G loss: 0.9936\n",
      "[2884/1762] D loss: 1.4742, G loss: 0.9167\n",
      "[3204/1762] D loss: 1.0186, G loss: 1.0288\n",
      "[3524/1762] D loss: 1.0199, G loss: 0.9943\n",
      "[3844/1762] D loss: 1.2666, G loss: 0.6875\n",
      "[4164/1762] D loss: 0.7074, G loss: 1.7996\n",
      "[4484/1762] D loss: 1.4122, G loss: 1.0122\n",
      "[4804/1762] D loss: 1.4340, G loss: 0.9755\n",
      "[5124/1762] D loss: 1.3508, G loss: 1.3879\n",
      "[5444/1762] D loss: 1.3988, G loss: 0.7702\n",
      "[5764/1762] D loss: 1.4266, G loss: 0.7875\n",
      "[6084/1762] D loss: 1.3487, G loss: 0.6285\n",
      "[6404/1762] D loss: 1.7205, G loss: 1.1276\n",
      "[6724/1762] D loss: 0.5292, G loss: 2.7121\n",
      "[7042/1762] D loss: 1.4835, G loss: 0.6855\n",
      "train error: \n",
      " D loss: 1.402532, G loss: 1.207446, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389747, G loss: 1.221838, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4434, G loss: 0.9760\n",
      "[324/1762] D loss: 1.3771, G loss: 0.6695\n",
      "[644/1762] D loss: 1.2438, G loss: 1.1231\n",
      "[964/1762] D loss: 1.2957, G loss: 0.8339\n",
      "[1284/1762] D loss: 1.3091, G loss: 1.1192\n",
      "[1604/1762] D loss: 1.1108, G loss: 1.8320\n",
      "[1924/1762] D loss: 0.8417, G loss: 1.4603\n",
      "[2244/1762] D loss: 1.4885, G loss: 0.4819\n",
      "[2564/1762] D loss: 1.2128, G loss: 0.8671\n",
      "[2884/1762] D loss: 1.3815, G loss: 0.6056\n",
      "[3204/1762] D loss: 1.3919, G loss: 0.7532\n",
      "[3524/1762] D loss: 1.3102, G loss: 1.1994\n",
      "[3844/1762] D loss: 1.3754, G loss: 0.7021\n",
      "[4164/1762] D loss: 1.3703, G loss: 0.8246\n",
      "[4484/1762] D loss: 1.3840, G loss: 0.7170\n",
      "[4804/1762] D loss: 1.3872, G loss: 0.7212\n",
      "[5124/1762] D loss: 1.1623, G loss: 1.0453\n",
      "[5444/1762] D loss: 1.4368, G loss: 0.5912\n",
      "[5764/1762] D loss: 0.8914, G loss: 1.0695\n",
      "[6084/1762] D loss: 1.1774, G loss: 1.2643\n",
      "[6404/1762] D loss: 1.3720, G loss: 1.0229\n",
      "[6724/1762] D loss: 1.3263, G loss: 0.9166\n",
      "[7042/1762] D loss: 0.1406, G loss: 3.3014\n",
      "train error: \n",
      " D loss: 1.363343, G loss: 1.087319, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344858, G loss: 1.102197, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 81.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4049, G loss: 0.7192\n",
      "[324/1762] D loss: 1.5413, G loss: 0.7078\n",
      "[644/1762] D loss: 1.5756, G loss: 0.4331\n",
      "[964/1762] D loss: 1.4428, G loss: 0.6371\n",
      "[1284/1762] D loss: 0.3398, G loss: 2.2535\n",
      "[1604/1762] D loss: 1.7768, G loss: 1.2157\n",
      "[1924/1762] D loss: 1.0459, G loss: 1.0456\n",
      "[2244/1762] D loss: 0.8840, G loss: 1.3708\n",
      "[2564/1762] D loss: 2.3736, G loss: 0.3530\n",
      "[2884/1762] D loss: 1.5973, G loss: 0.7551\n",
      "[3204/1762] D loss: 1.4161, G loss: 0.6398\n",
      "[3524/1762] D loss: 1.5615, G loss: 0.9594\n",
      "[3844/1762] D loss: 1.3554, G loss: 0.6968\n",
      "[4164/1762] D loss: 0.8245, G loss: 0.9473\n",
      "[4484/1762] D loss: 1.4007, G loss: 0.6201\n",
      "[4804/1762] D loss: 1.4122, G loss: 0.5651\n",
      "[5124/1762] D loss: 0.6941, G loss: 1.2019\n",
      "[5444/1762] D loss: 1.3922, G loss: 0.7263\n",
      "[5764/1762] D loss: 1.3848, G loss: 0.6667\n",
      "[6084/1762] D loss: 1.3880, G loss: 0.7621\n",
      "[6404/1762] D loss: 1.2859, G loss: 0.7381\n",
      "[6724/1762] D loss: 0.7704, G loss: 1.0004\n",
      "[7042/1762] D loss: 0.9571, G loss: 1.5541\n",
      "train error: \n",
      " D loss: 0.689887, G loss: 1.603932, D accuracy: 88.0%, cell accuracy: 98.3%, board accuracy: 12.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.704631, G loss: 1.562197, D accuracy: 87.7%, cell accuracy: 98.3%, board accuracy: 12.1% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0483, G loss: 1.5601\n",
      "[324/1762] D loss: 1.4208, G loss: 0.6562\n",
      "[644/1762] D loss: 1.4939, G loss: 0.4853\n",
      "[964/1762] D loss: 0.8864, G loss: 1.2526\n",
      "[1284/1762] D loss: 1.0409, G loss: 0.8785\n",
      "[1604/1762] D loss: 1.3971, G loss: 0.7890\n",
      "[1924/1762] D loss: 1.3911, G loss: 0.6273\n",
      "[2244/1762] D loss: 1.4484, G loss: 0.8572\n",
      "[2564/1762] D loss: 1.3522, G loss: 0.7149\n",
      "[2884/1762] D loss: 1.4034, G loss: 0.8579\n",
      "[3204/1762] D loss: 1.4025, G loss: 0.8072\n",
      "[3524/1762] D loss: 1.4444, G loss: 0.4987\n",
      "[3844/1762] D loss: 0.8131, G loss: 1.1937\n",
      "[4164/1762] D loss: 1.3839, G loss: 0.6615\n",
      "[4484/1762] D loss: 1.3804, G loss: 0.6764\n",
      "[4804/1762] D loss: 1.5395, G loss: 0.7708\n",
      "[5124/1762] D loss: 1.1963, G loss: 0.8011\n",
      "[5444/1762] D loss: 1.6348, G loss: 0.6232\n",
      "[5764/1762] D loss: 1.0385, G loss: 0.7103\n",
      "[6084/1762] D loss: 0.9159, G loss: 1.1759\n",
      "[6404/1762] D loss: 0.8472, G loss: 1.0940\n",
      "[6724/1762] D loss: 0.7913, G loss: 0.9203\n",
      "[7042/1762] D loss: 1.4097, G loss: 0.7394\n",
      "train error: \n",
      " D loss: 1.323636, G loss: 0.769924, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304858, G loss: 0.793484, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3900, G loss: 0.6831\n",
      "[324/1762] D loss: 0.7051, G loss: 1.1591\n",
      "[644/1762] D loss: 1.3944, G loss: 0.7935\n",
      "[964/1762] D loss: 0.8659, G loss: 0.9871\n",
      "[1284/1762] D loss: 1.2853, G loss: 0.8054\n",
      "[1604/1762] D loss: 1.0691, G loss: 0.8007\n",
      "[1924/1762] D loss: 0.7658, G loss: 0.9296\n",
      "[2244/1762] D loss: 0.5852, G loss: 1.7639\n",
      "[2564/1762] D loss: 1.3978, G loss: 0.4742\n",
      "[2884/1762] D loss: 1.4216, G loss: 0.8188\n",
      "[3204/1762] D loss: 1.3913, G loss: 0.6328\n",
      "[3524/1762] D loss: 1.4021, G loss: 0.6886\n",
      "[3844/1762] D loss: 0.5535, G loss: 1.6229\n",
      "[4164/1762] D loss: 1.6845, G loss: 1.1994\n",
      "[4484/1762] D loss: 1.4006, G loss: 0.6190\n",
      "[4804/1762] D loss: 1.4055, G loss: 0.6297\n",
      "[5124/1762] D loss: 0.4559, G loss: 1.3663\n",
      "[5444/1762] D loss: 1.4411, G loss: 0.4984\n",
      "[5764/1762] D loss: 1.4280, G loss: 0.8324\n",
      "[6084/1762] D loss: 1.3916, G loss: 0.7732\n",
      "[6404/1762] D loss: 1.5848, G loss: 1.0775\n",
      "[6724/1762] D loss: 0.6489, G loss: 1.0532\n",
      "[7042/1762] D loss: 1.3901, G loss: 0.7699\n",
      "train error: \n",
      " D loss: 1.340935, G loss: 0.627420, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323635, G loss: 0.650609, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.6480\n",
      "[324/1762] D loss: 1.4192, G loss: 0.8931\n",
      "[644/1762] D loss: 1.4324, G loss: 0.8438\n",
      "[964/1762] D loss: 1.4038, G loss: 0.7739\n",
      "[1284/1762] D loss: 1.4958, G loss: 0.9359\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.6905\n",
      "[1924/1762] D loss: 1.4487, G loss: 0.6318\n",
      "[2244/1762] D loss: 1.3909, G loss: 0.7992\n",
      "[2564/1762] D loss: 0.5715, G loss: 0.9979\n",
      "[2884/1762] D loss: 1.4661, G loss: 0.9134\n",
      "[3204/1762] D loss: 1.3101, G loss: 0.6940\n",
      "[3524/1762] D loss: 1.3324, G loss: 0.7520\n",
      "[3844/1762] D loss: 0.3673, G loss: 1.3629\n",
      "[4164/1762] D loss: 1.4300, G loss: 0.8423\n",
      "[4484/1762] D loss: 0.4266, G loss: 1.2660\n",
      "[4804/1762] D loss: 1.4972, G loss: 1.0100\n",
      "[5124/1762] D loss: 1.4185, G loss: 0.8018\n",
      "[5444/1762] D loss: 1.5233, G loss: 0.8735\n",
      "[5764/1762] D loss: 1.4033, G loss: 0.5806\n",
      "[6084/1762] D loss: 3.4343, G loss: 0.1465\n",
      "[6404/1762] D loss: 1.4561, G loss: 0.8164\n",
      "[6724/1762] D loss: 1.5519, G loss: 1.1787\n",
      "[7042/1762] D loss: 0.7331, G loss: 1.6173\n",
      "train error: \n",
      " D loss: 1.384297, G loss: 0.906386, D accuracy: 52.2%, cell accuracy: 99.6%, board accuracy: 47.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388963, G loss: 0.919215, D accuracy: 52.6%, cell accuracy: 99.5%, board accuracy: 49.8% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2039, G loss: 0.8117\n",
      "[324/1762] D loss: 0.9357, G loss: 1.3083\n",
      "[644/1762] D loss: 1.4118, G loss: 0.7097\n",
      "[964/1762] D loss: 1.4092, G loss: 0.5315\n",
      "[1284/1762] D loss: 1.1283, G loss: 0.6483\n",
      "[1604/1762] D loss: 1.4052, G loss: 0.7271\n",
      "[1924/1762] D loss: 0.7642, G loss: 1.1572\n",
      "[2244/1762] D loss: 1.3913, G loss: 0.7856\n",
      "[2564/1762] D loss: 1.4031, G loss: 0.8131\n",
      "[2884/1762] D loss: 1.4085, G loss: 0.7658\n",
      "[3204/1762] D loss: 1.4143, G loss: 0.6140\n",
      "[3524/1762] D loss: 0.5382, G loss: 1.4060\n",
      "[3844/1762] D loss: 1.3965, G loss: 0.7643\n",
      "[4164/1762] D loss: 1.4971, G loss: 1.1706\n",
      "[4484/1762] D loss: 0.6684, G loss: 0.8969\n",
      "[4804/1762] D loss: 1.4372, G loss: 0.8742\n",
      "[5124/1762] D loss: 1.5788, G loss: 1.1636\n",
      "[5444/1762] D loss: 1.4278, G loss: 0.7603\n",
      "[5764/1762] D loss: 1.4398, G loss: 0.8119\n",
      "[6084/1762] D loss: 0.3521, G loss: 1.5358\n",
      "[6404/1762] D loss: 1.2305, G loss: 0.7533\n",
      "[6724/1762] D loss: 1.4488, G loss: 0.7475\n",
      "[7042/1762] D loss: 0.3020, G loss: 1.5271\n",
      "train error: \n",
      " D loss: 1.415690, G loss: 0.496761, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392057, G loss: 0.519095, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5472, G loss: 1.1636\n",
      "[324/1762] D loss: 1.3727, G loss: 0.9313\n",
      "[644/1762] D loss: 1.4215, G loss: 0.5650\n",
      "[964/1762] D loss: 1.4020, G loss: 0.7774\n",
      "[1284/1762] D loss: 1.4238, G loss: 0.5070\n",
      "[1604/1762] D loss: 1.4403, G loss: 0.9661\n",
      "[1924/1762] D loss: 0.3198, G loss: 1.5572\n",
      "[2244/1762] D loss: 1.4324, G loss: 0.5554\n",
      "[2564/1762] D loss: 1.4191, G loss: 0.8250\n",
      "[2884/1762] D loss: 1.4034, G loss: 0.7484\n",
      "[3204/1762] D loss: 0.4060, G loss: 1.3316\n",
      "[3524/1762] D loss: 0.2634, G loss: 1.6917\n",
      "[3844/1762] D loss: 1.3985, G loss: 0.7018\n",
      "[4164/1762] D loss: 1.3834, G loss: 0.7264\n",
      "[4484/1762] D loss: 1.4944, G loss: 0.5347\n",
      "[4804/1762] D loss: 0.3106, G loss: 1.6157\n",
      "[5124/1762] D loss: 1.3979, G loss: 0.6558\n",
      "[5444/1762] D loss: 1.4612, G loss: 0.3873\n",
      "[5764/1762] D loss: 1.0850, G loss: 1.0680\n",
      "[6084/1762] D loss: 1.0652, G loss: 0.9425\n",
      "[6404/1762] D loss: 0.1639, G loss: 2.6483\n",
      "[6724/1762] D loss: 1.4542, G loss: 1.8109\n",
      "[7042/1762] D loss: 1.4554, G loss: 0.5693\n",
      "train error: \n",
      " D loss: 1.431490, G loss: 0.530711, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411269, G loss: 0.543333, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4885, G loss: 0.5204\n",
      "[324/1762] D loss: 1.4138, G loss: 0.5817\n",
      "[644/1762] D loss: 1.3993, G loss: 0.7520\n",
      "[964/1762] D loss: 0.6111, G loss: 1.1228\n",
      "[1284/1762] D loss: 1.4309, G loss: 0.7721\n",
      "[1604/1762] D loss: 0.3340, G loss: 1.5024\n",
      "[1924/1762] D loss: 0.2626, G loss: 2.5404\n",
      "[2244/1762] D loss: 1.3916, G loss: 0.7556\n",
      "[2564/1762] D loss: 1.4775, G loss: 0.8880\n",
      "[2884/1762] D loss: 0.3574, G loss: 1.5241\n",
      "[3204/1762] D loss: 1.4112, G loss: 0.6051\n",
      "[3524/1762] D loss: 0.1968, G loss: 2.5129\n",
      "[3844/1762] D loss: 1.3891, G loss: 0.6943\n",
      "[4164/1762] D loss: 1.4279, G loss: 0.8425\n",
      "[4484/1762] D loss: 1.4290, G loss: 0.5714\n",
      "[4804/1762] D loss: 1.5530, G loss: 1.0704\n",
      "[5124/1762] D loss: 1.3937, G loss: 0.6734\n",
      "[5444/1762] D loss: 1.4508, G loss: 0.9846\n",
      "[5764/1762] D loss: 1.3098, G loss: 0.8974\n",
      "[6084/1762] D loss: 0.3332, G loss: 1.4474\n",
      "[6404/1762] D loss: 1.5621, G loss: 1.1530\n",
      "[6724/1762] D loss: 0.4040, G loss: 1.2851\n",
      "[7042/1762] D loss: 1.4510, G loss: 0.9010\n",
      "train error: \n",
      " D loss: 1.368008, G loss: 0.783984, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367918, G loss: 0.805822, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4327, G loss: 0.7995\n",
      "[324/1762] D loss: 0.3197, G loss: 1.5623\n",
      "[644/1762] D loss: 0.4455, G loss: 1.0952\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6183\n",
      "[1284/1762] D loss: 1.4208, G loss: 0.9065\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.7184\n",
      "[1924/1762] D loss: 0.3134, G loss: 1.5651\n",
      "[2244/1762] D loss: 1.5224, G loss: 1.0235\n",
      "[2564/1762] D loss: 0.2813, G loss: 1.5598\n",
      "[2884/1762] D loss: 0.3163, G loss: 1.4881\n",
      "[3204/1762] D loss: 1.3918, G loss: 0.8483\n",
      "[3524/1762] D loss: 1.4884, G loss: 0.8501\n",
      "[3844/1762] D loss: 1.3977, G loss: 0.6924\n",
      "[4164/1762] D loss: 1.3941, G loss: 0.7690\n",
      "[4484/1762] D loss: 1.6619, G loss: 0.4876\n",
      "[4804/1762] D loss: 1.1168, G loss: 0.9066\n",
      "[5124/1762] D loss: 1.7563, G loss: 0.3996\n",
      "[5444/1762] D loss: 0.1378, G loss: 2.4723\n",
      "[5764/1762] D loss: 0.3867, G loss: 1.2279\n",
      "[6084/1762] D loss: 1.4603, G loss: 0.9205\n",
      "[6404/1762] D loss: 0.3539, G loss: 1.5602\n",
      "[6724/1762] D loss: 1.3691, G loss: 0.7305\n",
      "[7042/1762] D loss: 1.5328, G loss: 0.8786\n",
      "train error: \n",
      " D loss: 1.352649, G loss: 0.607675, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343017, G loss: 0.616588, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2750, G loss: 0.7116\n",
      "[324/1762] D loss: 0.0890, G loss: 2.6653\n",
      "[644/1762] D loss: 1.4512, G loss: 0.9225\n",
      "[964/1762] D loss: 1.4613, G loss: 0.7921\n",
      "[1284/1762] D loss: 0.0831, G loss: 2.7434\n",
      "[1604/1762] D loss: 0.3572, G loss: 1.3276\n",
      "[1924/1762] D loss: 0.7501, G loss: 1.0850\n",
      "[2244/1762] D loss: 0.3349, G loss: 1.7615\n",
      "[2564/1762] D loss: 1.3457, G loss: 0.4412\n",
      "[2884/1762] D loss: 1.1548, G loss: 0.7533\n",
      "[3204/1762] D loss: 1.8718, G loss: 0.7883\n",
      "[3524/1762] D loss: 0.1897, G loss: 2.2574\n",
      "[3844/1762] D loss: 1.7371, G loss: 1.1542\n",
      "[4164/1762] D loss: 1.5463, G loss: 1.1896\n",
      "[4484/1762] D loss: 1.4133, G loss: 0.6739\n",
      "[4804/1762] D loss: 1.0942, G loss: 0.9025\n",
      "[5124/1762] D loss: 1.3979, G loss: 0.6926\n",
      "[5444/1762] D loss: 1.0015, G loss: 0.7993\n",
      "[5764/1762] D loss: 1.4404, G loss: 0.6481\n",
      "[6084/1762] D loss: 1.1094, G loss: 0.8322\n",
      "[6404/1762] D loss: 1.2101, G loss: 0.7891\n",
      "[6724/1762] D loss: 0.5907, G loss: 1.3411\n",
      "[7042/1762] D loss: 1.3923, G loss: 0.8277\n",
      "train error: \n",
      " D loss: 1.363845, G loss: 0.679999, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353416, G loss: 0.680002, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6682, G loss: 1.2197\n",
      "[324/1762] D loss: 1.4568, G loss: 0.9336\n",
      "[644/1762] D loss: 1.4509, G loss: 0.9038\n",
      "[964/1762] D loss: 1.4063, G loss: 0.6202\n",
      "[1284/1762] D loss: 1.4275, G loss: 0.9371\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.6114\n",
      "[1924/1762] D loss: 1.4360, G loss: 0.5809\n",
      "[2244/1762] D loss: 0.7662, G loss: 1.0384\n",
      "[2564/1762] D loss: 1.4012, G loss: 0.7617\n",
      "[2884/1762] D loss: 1.3829, G loss: 0.9179\n",
      "[3204/1762] D loss: 2.1135, G loss: 0.6396\n",
      "[3524/1762] D loss: 0.8845, G loss: 1.4398\n",
      "[3844/1762] D loss: 1.4100, G loss: 0.7772\n",
      "[4164/1762] D loss: 1.3734, G loss: 0.6818\n",
      "[4484/1762] D loss: 1.4770, G loss: 0.9911\n",
      "[4804/1762] D loss: 1.2651, G loss: 0.7877\n",
      "[5124/1762] D loss: 1.4540, G loss: 0.7913\n",
      "[5444/1762] D loss: 1.4415, G loss: 0.5239\n",
      "[5764/1762] D loss: 1.4003, G loss: 0.7212\n",
      "[6084/1762] D loss: 0.3578, G loss: 1.5555\n",
      "[6404/1762] D loss: 1.4010, G loss: 0.6605\n",
      "[6724/1762] D loss: 1.4257, G loss: 0.6568\n",
      "[7042/1762] D loss: 1.4491, G loss: 0.9720\n",
      "train error: \n",
      " D loss: 1.338443, G loss: 0.805594, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324408, G loss: 0.817221, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4589, G loss: 0.9579\n",
      "[324/1762] D loss: 1.4611, G loss: 0.8892\n",
      "[644/1762] D loss: 1.5206, G loss: 1.0857\n",
      "[964/1762] D loss: 1.4005, G loss: 0.7967\n",
      "[1284/1762] D loss: 1.3928, G loss: 0.8545\n",
      "[1604/1762] D loss: 0.3321, G loss: 1.4815\n",
      "[1924/1762] D loss: 1.4383, G loss: 0.7710\n",
      "[2244/1762] D loss: 1.4203, G loss: 0.6899\n",
      "[2564/1762] D loss: 1.4744, G loss: 1.0474\n",
      "[2884/1762] D loss: 0.3902, G loss: 1.1379\n",
      "[3204/1762] D loss: 0.3407, G loss: 1.4205\n",
      "[3524/1762] D loss: 0.2529, G loss: 1.8589\n",
      "[3844/1762] D loss: 1.4350, G loss: 0.6045\n",
      "[4164/1762] D loss: 1.3384, G loss: 1.0112\n",
      "[4484/1762] D loss: 1.3970, G loss: 0.8022\n",
      "[4804/1762] D loss: 1.4191, G loss: 0.7813\n",
      "[5124/1762] D loss: 1.4346, G loss: 0.6106\n",
      "[5444/1762] D loss: 1.4463, G loss: 0.5237\n",
      "[5764/1762] D loss: 1.3864, G loss: 0.7045\n",
      "[6084/1762] D loss: 1.1030, G loss: 1.2805\n",
      "[6404/1762] D loss: 1.4190, G loss: 0.5908\n",
      "[6724/1762] D loss: 1.6211, G loss: 1.3995\n",
      "[7042/1762] D loss: 1.3987, G loss: 0.8392\n",
      "train error: \n",
      " D loss: 1.345782, G loss: 0.670070, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340400, G loss: 0.654333, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4152, G loss: 0.6910\n",
      "[324/1762] D loss: 0.2918, G loss: 1.6003\n",
      "[644/1762] D loss: 0.3380, G loss: 1.5300\n",
      "[964/1762] D loss: 1.6096, G loss: 1.1777\n",
      "[1284/1762] D loss: 1.4915, G loss: 0.8326\n",
      "[1604/1762] D loss: 1.3820, G loss: 0.7935\n",
      "[1924/1762] D loss: 0.1898, G loss: 1.9093\n",
      "[2244/1762] D loss: 1.3929, G loss: 0.7227\n",
      "[2564/1762] D loss: 0.3094, G loss: 1.5014\n",
      "[2884/1762] D loss: 1.2938, G loss: 0.9740\n",
      "[3204/1762] D loss: 1.4039, G loss: 0.8923\n",
      "[3524/1762] D loss: 0.1962, G loss: 2.0899\n",
      "[3844/1762] D loss: 1.5619, G loss: 1.1660\n",
      "[4164/1762] D loss: 0.4737, G loss: 1.8355\n",
      "[4484/1762] D loss: 1.4346, G loss: 0.6845\n",
      "[4804/1762] D loss: 1.5061, G loss: 0.9010\n",
      "[5124/1762] D loss: 1.4515, G loss: 0.8554\n",
      "[5444/1762] D loss: 1.3961, G loss: 0.5773\n",
      "[5764/1762] D loss: 0.3856, G loss: 1.4042\n",
      "[6084/1762] D loss: 1.1795, G loss: 1.1792\n",
      "[6404/1762] D loss: 1.4295, G loss: 0.9076\n",
      "[6724/1762] D loss: 0.2342, G loss: 1.9333\n",
      "[7042/1762] D loss: 1.4112, G loss: 0.7258\n",
      "train error: \n",
      " D loss: 1.342154, G loss: 0.676727, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326720, G loss: 0.680385, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4304, G loss: 0.5059\n",
      "[324/1762] D loss: 1.4972, G loss: 0.9904\n",
      "[644/1762] D loss: 1.3982, G loss: 0.6769\n",
      "[964/1762] D loss: 0.1091, G loss: 3.3663\n",
      "[1284/1762] D loss: 1.4110, G loss: 0.5673\n",
      "[1604/1762] D loss: 1.4132, G loss: 0.6643\n",
      "[1924/1762] D loss: 0.2942, G loss: 1.6294\n",
      "[2244/1762] D loss: 0.2510, G loss: 1.7888\n",
      "[2564/1762] D loss: 0.2164, G loss: 1.8531\n",
      "[2884/1762] D loss: 0.2507, G loss: 1.9163\n",
      "[3204/1762] D loss: 1.4263, G loss: 0.7804\n",
      "[3524/1762] D loss: 1.5007, G loss: 0.4357\n",
      "[3844/1762] D loss: 1.3697, G loss: 0.7031\n",
      "[4164/1762] D loss: 1.4296, G loss: 0.6087\n",
      "[4484/1762] D loss: 1.1848, G loss: 0.7385\n",
      "[4804/1762] D loss: 1.0627, G loss: 1.2792\n",
      "[5124/1762] D loss: 1.3752, G loss: 0.6665\n",
      "[5444/1762] D loss: 0.0581, G loss: 3.1611\n",
      "[5764/1762] D loss: 1.6181, G loss: 1.0723\n",
      "[6084/1762] D loss: 1.5478, G loss: 1.1565\n",
      "[6404/1762] D loss: 1.4184, G loss: 0.8146\n",
      "[6724/1762] D loss: 1.3980, G loss: 0.8198\n",
      "[7042/1762] D loss: 1.4883, G loss: 0.4361\n",
      "train error: \n",
      " D loss: 1.818429, G loss: 0.239888, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.795667, G loss: 0.249417, D accuracy: 51.3%, cell accuracy: 99.8%, board accuracy: 82.8% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9975, G loss: 1.1907\n",
      "[324/1762] D loss: 1.3966, G loss: 0.6321\n",
      "[644/1762] D loss: 1.2225, G loss: 0.9051\n",
      "[964/1762] D loss: 0.1186, G loss: 2.4184\n",
      "[1284/1762] D loss: 1.4214, G loss: 0.6322\n",
      "[1604/1762] D loss: 1.2957, G loss: 1.3149\n",
      "[1924/1762] D loss: 1.3961, G loss: 0.5721\n",
      "[2244/1762] D loss: 1.4330, G loss: 0.6364\n",
      "[2564/1762] D loss: 1.5403, G loss: 1.3386\n",
      "[2884/1762] D loss: 1.4433, G loss: 0.8057\n",
      "[3204/1762] D loss: 1.4075, G loss: 0.5614\n",
      "[3524/1762] D loss: 1.4074, G loss: 0.5623\n",
      "[3844/1762] D loss: 1.4036, G loss: 0.6192\n",
      "[4164/1762] D loss: 0.1622, G loss: 2.3249\n",
      "[4484/1762] D loss: 1.5118, G loss: 1.0276\n",
      "[4804/1762] D loss: 1.4118, G loss: 0.6436\n",
      "[5124/1762] D loss: 0.2135, G loss: 1.6873\n",
      "[5444/1762] D loss: 0.2437, G loss: 1.6923\n",
      "[5764/1762] D loss: 1.5149, G loss: 0.3986\n",
      "[6084/1762] D loss: 1.4158, G loss: 0.5508\n",
      "[6404/1762] D loss: 1.3944, G loss: 0.8116\n",
      "[6724/1762] D loss: 1.4234, G loss: 0.8123\n",
      "[7042/1762] D loss: 1.4910, G loss: 0.4707\n",
      "train error: \n",
      " D loss: 1.595283, G loss: 0.344619, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.571718, G loss: 0.361498, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3965, G loss: 0.6671\n",
      "[324/1762] D loss: 1.4002, G loss: 0.7553\n",
      "[644/1762] D loss: 0.2668, G loss: 1.6667\n",
      "[964/1762] D loss: 1.3978, G loss: 0.7214\n",
      "[1284/1762] D loss: 1.4087, G loss: 0.8819\n",
      "[1604/1762] D loss: 1.4076, G loss: 0.7446\n",
      "[1924/1762] D loss: 1.4802, G loss: 0.5129\n",
      "[2244/1762] D loss: 0.3375, G loss: 1.4080\n",
      "[2564/1762] D loss: 1.0909, G loss: 1.2447\n",
      "[2884/1762] D loss: 1.3972, G loss: 0.8922\n",
      "[3204/1762] D loss: 1.4313, G loss: 0.7969\n",
      "[3524/1762] D loss: 1.4389, G loss: 0.7024\n",
      "[3844/1762] D loss: 1.3938, G loss: 0.8117\n",
      "[4164/1762] D loss: 1.4931, G loss: 0.9879\n",
      "[4484/1762] D loss: 0.0387, G loss: 3.4543\n",
      "[4804/1762] D loss: 1.4404, G loss: 0.5166\n",
      "[5124/1762] D loss: 1.3919, G loss: 0.7404\n",
      "[5444/1762] D loss: 1.4063, G loss: 0.8103\n",
      "[5764/1762] D loss: 1.3889, G loss: 0.6539\n",
      "[6084/1762] D loss: 1.3987, G loss: 0.7957\n",
      "[6404/1762] D loss: 1.4117, G loss: 0.7942\n",
      "[6724/1762] D loss: 1.3925, G loss: 0.6655\n",
      "[7042/1762] D loss: 0.0417, G loss: 3.5798\n",
      "train error: \n",
      " D loss: 2.098145, G loss: 0.178172, D accuracy: 51.4%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.085233, G loss: 0.186493, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4336, G loss: 0.5748\n",
      "[324/1762] D loss: 1.3925, G loss: 0.6780\n",
      "[644/1762] D loss: 1.4065, G loss: 0.7859\n",
      "[964/1762] D loss: 1.3215, G loss: 0.7836\n",
      "[1284/1762] D loss: 0.3870, G loss: 1.4131\n",
      "[1604/1762] D loss: 1.4476, G loss: 0.6689\n",
      "[1924/1762] D loss: 1.5565, G loss: 0.4680\n",
      "[2244/1762] D loss: 0.2664, G loss: 2.8861\n",
      "[2564/1762] D loss: 0.0595, G loss: 4.2800\n",
      "[2884/1762] D loss: 1.6847, G loss: 1.5852\n",
      "[3204/1762] D loss: 0.4014, G loss: 1.2677\n",
      "[3524/1762] D loss: 1.3989, G loss: 0.6578\n",
      "[3844/1762] D loss: 1.4865, G loss: 0.9320\n",
      "[4164/1762] D loss: 1.5210, G loss: 1.0746\n",
      "[4484/1762] D loss: 0.1570, G loss: 2.1574\n",
      "[4804/1762] D loss: 1.3343, G loss: 1.0085\n",
      "[5124/1762] D loss: 0.0861, G loss: 2.5068\n",
      "[5444/1762] D loss: 1.2583, G loss: 0.7981\n",
      "[5764/1762] D loss: 1.4014, G loss: 0.6021\n",
      "[6084/1762] D loss: 1.3881, G loss: 0.6633\n",
      "[6404/1762] D loss: 0.2399, G loss: 1.7725\n",
      "[6724/1762] D loss: 0.1702, G loss: 2.2118\n",
      "[7042/1762] D loss: 1.2239, G loss: 0.8375\n",
      "train error: \n",
      " D loss: 1.344009, G loss: 0.607050, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316936, G loss: 0.638658, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 84.2% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3945, G loss: 0.6900\n",
      "[324/1762] D loss: 1.3425, G loss: 0.8393\n",
      "[644/1762] D loss: 1.3990, G loss: 0.7380\n",
      "[964/1762] D loss: 1.3966, G loss: 0.6837\n",
      "[1284/1762] D loss: 1.3615, G loss: 0.6036\n",
      "[1604/1762] D loss: 0.2850, G loss: 1.7116\n",
      "[1924/1762] D loss: 1.4011, G loss: 0.8720\n",
      "[2244/1762] D loss: 1.4007, G loss: 0.7598\n",
      "[2564/1762] D loss: 1.3856, G loss: 0.6447\n",
      "[2884/1762] D loss: 1.4164, G loss: 0.6648\n",
      "[3204/1762] D loss: 1.3580, G loss: 0.7751\n",
      "[3524/1762] D loss: 1.4915, G loss: 0.9977\n",
      "[3844/1762] D loss: 1.4448, G loss: 0.9071\n",
      "[4164/1762] D loss: 1.4041, G loss: 0.7205\n",
      "[4484/1762] D loss: 0.1071, G loss: 2.6940\n",
      "[4804/1762] D loss: 1.3596, G loss: 1.5804\n",
      "[5124/1762] D loss: 1.4068, G loss: 0.7567\n",
      "[5444/1762] D loss: 1.5752, G loss: 1.0162\n",
      "[5764/1762] D loss: 0.1609, G loss: 2.0341\n",
      "[6084/1762] D loss: 1.3717, G loss: 0.8109\n",
      "[6404/1762] D loss: 1.4396, G loss: 0.9210\n",
      "[6724/1762] D loss: 1.8129, G loss: 1.6242\n",
      "[7042/1762] D loss: 0.0194, G loss: 4.4330\n",
      "train error: \n",
      " D loss: 2.445145, G loss: 0.131880, D accuracy: 51.4%, cell accuracy: 99.7%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.391579, G loss: 0.152053, D accuracy: 52.2%, cell accuracy: 99.6%, board accuracy: 83.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4369, G loss: 0.8367\n",
      "[324/1762] D loss: 1.4043, G loss: 0.7478\n",
      "[644/1762] D loss: 1.4427, G loss: 0.9398\n",
      "[964/1762] D loss: 0.0324, G loss: 4.0559\n",
      "[1284/1762] D loss: 1.4048, G loss: 0.5424\n",
      "[1604/1762] D loss: 1.4335, G loss: 0.6902\n",
      "[1924/1762] D loss: 0.1636, G loss: 2.0702\n",
      "[2244/1762] D loss: 1.3885, G loss: 0.7252\n",
      "[2564/1762] D loss: 0.1050, G loss: 2.5969\n",
      "[2884/1762] D loss: 0.1136, G loss: 3.0130\n",
      "[3204/1762] D loss: 0.1088, G loss: 2.8900\n",
      "[3524/1762] D loss: 1.4260, G loss: 0.5614\n",
      "[3844/1762] D loss: 1.4258, G loss: 0.8810\n",
      "[4164/1762] D loss: 1.4028, G loss: 0.7236\n",
      "[4484/1762] D loss: 0.1056, G loss: 2.8364\n",
      "[4804/1762] D loss: 0.3196, G loss: 1.8349\n",
      "[5124/1762] D loss: 0.1439, G loss: 2.2711\n",
      "[5444/1762] D loss: 1.5974, G loss: 0.7999\n",
      "[5764/1762] D loss: 1.2372, G loss: 0.8479\n",
      "[6084/1762] D loss: 1.4234, G loss: 0.5288\n",
      "[6404/1762] D loss: 1.5335, G loss: 0.4039\n",
      "[6724/1762] D loss: 0.1712, G loss: 2.1124\n",
      "[7042/1762] D loss: 0.0137, G loss: 4.9612\n",
      "train error: \n",
      " D loss: 2.178353, G loss: 0.186262, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.142717, G loss: 0.209415, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4110, G loss: 0.5893\n",
      "[324/1762] D loss: 1.5528, G loss: 0.4025\n",
      "[644/1762] D loss: 1.4104, G loss: 0.5831\n",
      "[964/1762] D loss: 0.1815, G loss: 2.2903\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.6951\n",
      "[1604/1762] D loss: 1.4164, G loss: 0.8224\n",
      "[1924/1762] D loss: 1.4252, G loss: 0.9458\n",
      "[2244/1762] D loss: 1.4053, G loss: 0.7036\n",
      "[2564/1762] D loss: 0.1168, G loss: 2.8454\n",
      "[2884/1762] D loss: 0.3328, G loss: 1.4702\n",
      "[3204/1762] D loss: 0.0089, G loss: 5.8483\n",
      "[3524/1762] D loss: 1.4160, G loss: 0.8485\n",
      "[3844/1762] D loss: 1.4070, G loss: 0.5472\n",
      "[4164/1762] D loss: 1.3288, G loss: 0.8057\n",
      "[4484/1762] D loss: 0.2645, G loss: 1.5799\n",
      "[4804/1762] D loss: 1.5663, G loss: 0.3988\n",
      "[5124/1762] D loss: 1.4238, G loss: 0.8756\n",
      "[5444/1762] D loss: 1.4276, G loss: 0.8341\n",
      "[5764/1762] D loss: 1.5279, G loss: 1.0213\n",
      "[6084/1762] D loss: 0.2106, G loss: 1.9013\n",
      "[6404/1762] D loss: 0.0938, G loss: 2.7390\n",
      "[6724/1762] D loss: 0.2616, G loss: 1.5622\n",
      "[7042/1762] D loss: 1.3833, G loss: 0.6863\n",
      "train error: \n",
      " D loss: 1.325515, G loss: 0.661146, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297063, G loss: 0.692991, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.7288\n",
      "[324/1762] D loss: 0.0937, G loss: 2.7996\n",
      "[644/1762] D loss: 1.4124, G loss: 0.6737\n",
      "[964/1762] D loss: 0.1490, G loss: 2.4018\n",
      "[1284/1762] D loss: 0.0217, G loss: 4.5814\n",
      "[1604/1762] D loss: 3.1870, G loss: 0.3532\n",
      "[1924/1762] D loss: 1.5918, G loss: 1.0745\n",
      "[2244/1762] D loss: 0.2770, G loss: 1.9251\n",
      "[2564/1762] D loss: 1.7203, G loss: 0.5882\n",
      "[2884/1762] D loss: 1.4714, G loss: 0.5392\n",
      "[3204/1762] D loss: 1.5027, G loss: 1.0747\n",
      "[3524/1762] D loss: 1.3933, G loss: 0.6044\n",
      "[3844/1762] D loss: 1.3087, G loss: 0.8331\n",
      "[4164/1762] D loss: 1.4285, G loss: 0.4949\n",
      "[4484/1762] D loss: 0.8115, G loss: 1.6650\n",
      "[4804/1762] D loss: 0.4124, G loss: 1.7033\n",
      "[5124/1762] D loss: 1.4295, G loss: 0.5236\n",
      "[5444/1762] D loss: 1.4613, G loss: 0.4867\n",
      "[5764/1762] D loss: 1.8562, G loss: 0.6709\n",
      "[6084/1762] D loss: 1.3907, G loss: 0.5356\n",
      "[6404/1762] D loss: 1.3134, G loss: 0.8227\n",
      "[6724/1762] D loss: 1.4165, G loss: 0.6557\n",
      "[7042/1762] D loss: 1.3711, G loss: 0.8945\n",
      "train error: \n",
      " D loss: 1.605186, G loss: 0.372598, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.584750, G loss: 0.410866, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3690, G loss: 0.8899\n",
      "[324/1762] D loss: 1.4186, G loss: 0.5384\n",
      "[644/1762] D loss: 1.4084, G loss: 0.6215\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6938\n",
      "[1284/1762] D loss: 1.3969, G loss: 0.7611\n",
      "[1604/1762] D loss: 0.8567, G loss: 1.3241\n",
      "[1924/1762] D loss: 1.3637, G loss: 0.7545\n",
      "[2244/1762] D loss: 1.3892, G loss: 0.7283\n",
      "[2564/1762] D loss: 1.3943, G loss: 0.6767\n",
      "[2884/1762] D loss: 0.4609, G loss: 1.5980\n",
      "[3204/1762] D loss: 0.3303, G loss: 1.9071\n",
      "[3524/1762] D loss: 1.4314, G loss: 0.8584\n",
      "[3844/1762] D loss: 1.3890, G loss: 0.7521\n",
      "[4164/1762] D loss: 1.4135, G loss: 0.9010\n",
      "[4484/1762] D loss: 0.3041, G loss: 2.1358\n",
      "[4804/1762] D loss: 1.5575, G loss: 1.0775\n",
      "[5124/1762] D loss: 1.3984, G loss: 0.6585\n",
      "[5444/1762] D loss: 0.5597, G loss: 1.0595\n",
      "[5764/1762] D loss: 1.3941, G loss: 0.9117\n",
      "[6084/1762] D loss: 1.4088, G loss: 0.6095\n",
      "[6404/1762] D loss: 1.4275, G loss: 0.8527\n",
      "[6724/1762] D loss: 1.5010, G loss: 1.1119\n",
      "[7042/1762] D loss: 1.5844, G loss: 1.0562\n",
      "train error: \n",
      " D loss: 1.350288, G loss: 0.686402, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331013, G loss: 0.705077, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4618, G loss: 0.8292\n",
      "[324/1762] D loss: 0.4667, G loss: 1.6122\n",
      "[644/1762] D loss: 1.4348, G loss: 0.9012\n",
      "[964/1762] D loss: 0.2225, G loss: 2.0761\n",
      "[1284/1762] D loss: 1.4278, G loss: 0.6111\n",
      "[1604/1762] D loss: 1.4478, G loss: 0.9296\n",
      "[1924/1762] D loss: 0.2763, G loss: 2.0215\n",
      "[2244/1762] D loss: 1.4263, G loss: 1.0495\n",
      "[2564/1762] D loss: 1.4258, G loss: 0.9007\n",
      "[2884/1762] D loss: 1.4939, G loss: 1.0481\n",
      "[3204/1762] D loss: 1.9886, G loss: 0.2446\n",
      "[3524/1762] D loss: 1.2547, G loss: 1.3121\n",
      "[3844/1762] D loss: 1.6300, G loss: 0.9815\n",
      "[4164/1762] D loss: 1.4101, G loss: 0.7007\n",
      "[4484/1762] D loss: 1.3872, G loss: 0.6544\n",
      "[4804/1762] D loss: 1.4291, G loss: 0.6081\n",
      "[5124/1762] D loss: 1.4203, G loss: 0.6120\n",
      "[5444/1762] D loss: 1.2239, G loss: 0.9251\n",
      "[5764/1762] D loss: 1.4945, G loss: 0.5004\n",
      "[6084/1762] D loss: 1.4169, G loss: 0.5950\n",
      "[6404/1762] D loss: 1.3913, G loss: 0.7206\n",
      "[6724/1762] D loss: 1.3847, G loss: 0.6308\n",
      "[7042/1762] D loss: 1.4726, G loss: 0.5072\n",
      "train error: \n",
      " D loss: 1.353338, G loss: 0.794535, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337898, G loss: 0.819249, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4014, G loss: 0.6654\n",
      "[324/1762] D loss: 1.4001, G loss: 0.7867\n",
      "[644/1762] D loss: 1.3973, G loss: 0.6051\n",
      "[964/1762] D loss: 1.3831, G loss: 0.7052\n",
      "[1284/1762] D loss: 1.3997, G loss: 0.7413\n",
      "[1604/1762] D loss: 1.4106, G loss: 0.7783\n",
      "[1924/1762] D loss: 1.3997, G loss: 0.5783\n",
      "[2244/1762] D loss: 1.4057, G loss: 0.6133\n",
      "[2564/1762] D loss: 1.4028, G loss: 0.7883\n",
      "[2884/1762] D loss: 1.2942, G loss: 0.8405\n",
      "[3204/1762] D loss: 1.3806, G loss: 0.6920\n",
      "[3524/1762] D loss: 1.2987, G loss: 0.8131\n",
      "[3844/1762] D loss: 1.4304, G loss: 0.5229\n",
      "[4164/1762] D loss: 1.1611, G loss: 0.8138\n",
      "[4484/1762] D loss: 1.3500, G loss: 0.7065\n",
      "[4804/1762] D loss: 1.3858, G loss: 0.6672\n",
      "[5124/1762] D loss: 1.3999, G loss: 0.5773\n",
      "[5444/1762] D loss: 1.3931, G loss: 0.7532\n",
      "[5764/1762] D loss: 1.3983, G loss: 0.7984\n",
      "[6084/1762] D loss: 1.3941, G loss: 0.7624\n",
      "[6404/1762] D loss: 1.2081, G loss: 0.8544\n",
      "[6724/1762] D loss: 1.3897, G loss: 0.6452\n",
      "[7042/1762] D loss: 1.3888, G loss: 0.7093\n",
      "train error: \n",
      " D loss: 1.353667, G loss: 0.713595, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341727, G loss: 0.723891, D accuracy: 54.7%, cell accuracy: 99.9%, board accuracy: 88.8% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4030, G loss: 0.6194\n",
      "[324/1762] D loss: 1.3916, G loss: 0.6286\n",
      "[644/1762] D loss: 1.4258, G loss: 0.5433\n",
      "[964/1762] D loss: 1.4006, G loss: 0.7625\n",
      "[1284/1762] D loss: 1.0673, G loss: 1.4636\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.6812\n",
      "[1924/1762] D loss: 1.3959, G loss: 0.6877\n",
      "[2244/1762] D loss: 1.2995, G loss: 0.7087\n",
      "[2564/1762] D loss: 1.4180, G loss: 0.6844\n",
      "[2884/1762] D loss: 1.2844, G loss: 0.8196\n",
      "[3204/1762] D loss: 1.4036, G loss: 0.5957\n",
      "[3524/1762] D loss: 1.3897, G loss: 0.7160\n",
      "[3844/1762] D loss: 1.3989, G loss: 0.7284\n",
      "[4164/1762] D loss: 1.3973, G loss: 0.6431\n",
      "[4484/1762] D loss: 1.3971, G loss: 0.6166\n",
      "[4804/1762] D loss: 1.3492, G loss: 0.6893\n",
      "[5124/1762] D loss: 1.3976, G loss: 0.6682\n",
      "[5444/1762] D loss: 1.3879, G loss: 0.6403\n",
      "[5764/1762] D loss: 1.3691, G loss: 0.6551\n",
      "[6084/1762] D loss: 1.3631, G loss: 0.6502\n",
      "[6404/1762] D loss: 1.4581, G loss: 1.2433\n",
      "[6724/1762] D loss: 1.4053, G loss: 0.7830\n",
      "[7042/1762] D loss: 0.9643, G loss: 1.1812\n",
      "train error: \n",
      " D loss: 1.374439, G loss: 0.763074, D accuracy: 49.7%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369670, G loss: 0.759645, D accuracy: 49.3%, cell accuracy: 99.9%, board accuracy: 88.8% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3131, G loss: 0.7222\n",
      "[324/1762] D loss: 1.2078, G loss: 0.8256\n",
      "[644/1762] D loss: 1.3321, G loss: 0.7534\n",
      "[964/1762] D loss: 1.2240, G loss: 0.7343\n",
      "[1284/1762] D loss: 1.3929, G loss: 0.8027\n",
      "[1604/1762] D loss: 1.4216, G loss: 0.8234\n",
      "[1924/1762] D loss: 1.4102, G loss: 0.8256\n",
      "[2244/1762] D loss: 1.3862, G loss: 0.7512\n",
      "[2564/1762] D loss: 1.4199, G loss: 0.8291\n",
      "[2884/1762] D loss: 1.4052, G loss: 0.8019\n",
      "[3204/1762] D loss: 1.0967, G loss: 0.8939\n",
      "[3524/1762] D loss: 1.3555, G loss: 0.7670\n",
      "[3844/1762] D loss: 1.3958, G loss: 0.6731\n",
      "[4164/1762] D loss: 1.4004, G loss: 0.7208\n",
      "[4484/1762] D loss: 1.4278, G loss: 0.6948\n",
      "[4804/1762] D loss: 1.3987, G loss: 0.7767\n",
      "[5124/1762] D loss: 1.1071, G loss: 1.5954\n",
      "[5444/1762] D loss: 1.3903, G loss: 0.6847\n",
      "[5764/1762] D loss: 1.3975, G loss: 0.7394\n",
      "[6084/1762] D loss: 1.3921, G loss: 0.6559\n",
      "[6404/1762] D loss: 1.7789, G loss: 1.1328\n",
      "[6724/1762] D loss: 1.4031, G loss: 0.6537\n",
      "[7042/1762] D loss: 1.4054, G loss: 0.7714\n",
      "train error: \n",
      " D loss: 1.361886, G loss: 0.723788, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353924, G loss: 0.723505, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4029, G loss: 0.7235\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6979\n",
      "[644/1762] D loss: 0.9429, G loss: 1.0320\n",
      "[964/1762] D loss: 1.3893, G loss: 0.6274\n",
      "[1284/1762] D loss: 1.4169, G loss: 0.6058\n",
      "[1604/1762] D loss: 0.9610, G loss: 0.8830\n",
      "[1924/1762] D loss: 1.3927, G loss: 0.6844\n",
      "[2244/1762] D loss: 1.0230, G loss: 0.7531\n",
      "[2564/1762] D loss: 0.7558, G loss: 1.3288\n",
      "[2884/1762] D loss: 1.3982, G loss: 0.6678\n",
      "[3204/1762] D loss: 1.4179, G loss: 0.6520\n",
      "[3524/1762] D loss: 1.1710, G loss: 0.6097\n",
      "[3844/1762] D loss: 1.4821, G loss: 0.8879\n",
      "[4164/1762] D loss: 1.4379, G loss: 0.5256\n",
      "[4484/1762] D loss: 1.0583, G loss: 1.2037\n",
      "[4804/1762] D loss: 1.5047, G loss: 0.4170\n",
      "[5124/1762] D loss: 0.9721, G loss: 1.1979\n",
      "[5444/1762] D loss: 0.9881, G loss: 1.1119\n",
      "[5764/1762] D loss: 1.3996, G loss: 0.8093\n",
      "[6084/1762] D loss: 1.3907, G loss: 0.7122\n",
      "[6404/1762] D loss: 1.4121, G loss: 0.6362\n",
      "[6724/1762] D loss: 1.1905, G loss: 0.8412\n",
      "[7042/1762] D loss: 1.4697, G loss: 0.6639\n",
      "train error: \n",
      " D loss: 1.345698, G loss: 0.709128, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333269, G loss: 0.713869, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0965, G loss: 1.1351\n",
      "[324/1762] D loss: 1.1853, G loss: 0.9622\n",
      "[644/1762] D loss: 1.3899, G loss: 0.7164\n",
      "[964/1762] D loss: 1.3925, G loss: 0.7361\n",
      "[1284/1762] D loss: 1.3919, G loss: 0.6896\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.7093\n",
      "[1924/1762] D loss: 1.4027, G loss: 0.7677\n",
      "[2244/1762] D loss: 0.5483, G loss: 1.2980\n",
      "[2564/1762] D loss: 1.4042, G loss: 0.7514\n",
      "[2884/1762] D loss: 1.9403, G loss: 1.1369\n",
      "[3204/1762] D loss: 0.9597, G loss: 1.1903\n",
      "[3524/1762] D loss: 1.4126, G loss: 0.8555\n",
      "[3844/1762] D loss: 1.5008, G loss: 0.7646\n",
      "[4164/1762] D loss: 1.4137, G loss: 0.7582\n",
      "[4484/1762] D loss: 1.3522, G loss: 0.4387\n",
      "[4804/1762] D loss: 1.3894, G loss: 0.7278\n",
      "[5124/1762] D loss: 1.3960, G loss: 0.7222\n",
      "[5444/1762] D loss: 0.8297, G loss: 0.9135\n",
      "[5764/1762] D loss: 1.1625, G loss: 1.0483\n",
      "[6084/1762] D loss: 1.3991, G loss: 0.6362\n",
      "[6404/1762] D loss: 1.4182, G loss: 0.7597\n",
      "[6724/1762] D loss: 1.3846, G loss: 0.6672\n",
      "[7042/1762] D loss: 1.4175, G loss: 0.8507\n",
      "train error: \n",
      " D loss: 1.317675, G loss: 0.874267, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297869, G loss: 0.915968, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3997, G loss: 0.6717\n",
      "[324/1762] D loss: 1.3888, G loss: 0.6899\n",
      "[644/1762] D loss: 0.7776, G loss: 0.9219\n",
      "[964/1762] D loss: 1.1766, G loss: 1.0843\n",
      "[1284/1762] D loss: 1.4235, G loss: 0.6132\n",
      "[1604/1762] D loss: 0.9974, G loss: 1.0303\n",
      "[1924/1762] D loss: 1.4181, G loss: 0.8140\n",
      "[2244/1762] D loss: 1.3904, G loss: 0.6677\n",
      "[2564/1762] D loss: 1.4030, G loss: 0.6675\n",
      "[2884/1762] D loss: 1.7353, G loss: 0.3994\n",
      "[3204/1762] D loss: 1.4043, G loss: 0.6091\n",
      "[3524/1762] D loss: 1.4001, G loss: 0.6060\n",
      "[3844/1762] D loss: 1.1058, G loss: 1.1772\n",
      "[4164/1762] D loss: 1.3931, G loss: 0.6272\n",
      "[4484/1762] D loss: 1.4235, G loss: 0.5421\n",
      "[4804/1762] D loss: 0.7782, G loss: 1.1485\n",
      "[5124/1762] D loss: 1.4400, G loss: 0.5540\n",
      "[5444/1762] D loss: 1.4167, G loss: 0.7367\n",
      "[5764/1762] D loss: 1.4836, G loss: 0.5560\n",
      "[6084/1762] D loss: 1.3923, G loss: 0.7624\n",
      "[6404/1762] D loss: 0.5344, G loss: 1.7597\n",
      "[6724/1762] D loss: 1.4267, G loss: 0.5256\n",
      "[7042/1762] D loss: 0.5645, G loss: 2.3677\n",
      "train error: \n",
      " D loss: 1.538847, G loss: 1.325072, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.516806, G loss: 1.348820, D accuracy: 53.7%, cell accuracy: 99.6%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4259, G loss: 0.5422\n",
      "[324/1762] D loss: 1.4341, G loss: 0.9348\n",
      "[644/1762] D loss: 1.4646, G loss: 0.4673\n",
      "[964/1762] D loss: 1.3137, G loss: 0.7250\n",
      "[1284/1762] D loss: 1.2752, G loss: 0.6322\n",
      "[1604/1762] D loss: 1.3997, G loss: 0.8008\n",
      "[1924/1762] D loss: 1.0461, G loss: 0.7966\n",
      "[2244/1762] D loss: 1.3945, G loss: 0.7328\n",
      "[2564/1762] D loss: 1.3908, G loss: 0.7234\n",
      "[2884/1762] D loss: 1.4212, G loss: 0.8876\n",
      "[3204/1762] D loss: 1.3947, G loss: 0.7200\n",
      "[3524/1762] D loss: 1.4090, G loss: 0.6263\n",
      "[3844/1762] D loss: 1.4099, G loss: 0.6163\n",
      "[4164/1762] D loss: 0.9142, G loss: 1.0854\n",
      "[4484/1762] D loss: 1.0690, G loss: 0.7357\n",
      "[4804/1762] D loss: 1.4611, G loss: 0.4957\n",
      "[5124/1762] D loss: 1.3174, G loss: 0.6087\n",
      "[5444/1762] D loss: 1.3925, G loss: 0.7203\n",
      "[5764/1762] D loss: 1.4071, G loss: 0.6560\n",
      "[6084/1762] D loss: 1.4098, G loss: 0.7318\n",
      "[6404/1762] D loss: 0.8339, G loss: 0.8389\n",
      "[6724/1762] D loss: 1.3934, G loss: 0.6585\n",
      "[7042/1762] D loss: 1.5099, G loss: 1.0199\n",
      "train error: \n",
      " D loss: 1.366314, G loss: 0.900898, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348980, G loss: 0.911659, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4234, G loss: 0.8339\n",
      "[324/1762] D loss: 1.2057, G loss: 0.5209\n",
      "[644/1762] D loss: 2.4615, G loss: 1.1760\n",
      "[964/1762] D loss: 1.4165, G loss: 0.8057\n",
      "[1284/1762] D loss: 1.4191, G loss: 0.6958\n",
      "[1604/1762] D loss: 1.4061, G loss: 0.7322\n",
      "[1924/1762] D loss: 1.3827, G loss: 0.6641\n",
      "[2244/1762] D loss: 1.4428, G loss: 0.7856\n",
      "[2564/1762] D loss: 1.4015, G loss: 0.5995\n",
      "[2884/1762] D loss: 0.7766, G loss: 1.1795\n",
      "[3204/1762] D loss: 0.6216, G loss: 1.3739\n",
      "[3524/1762] D loss: 1.4207, G loss: 0.7375\n",
      "[3844/1762] D loss: 1.3950, G loss: 0.7283\n",
      "[4164/1762] D loss: 1.4367, G loss: 0.4935\n",
      "[4484/1762] D loss: 1.4370, G loss: 0.6081\n",
      "[4804/1762] D loss: 1.3537, G loss: 0.7451\n",
      "[5124/1762] D loss: 0.2561, G loss: 2.0488\n",
      "[5444/1762] D loss: 1.2025, G loss: 1.0081\n",
      "[5764/1762] D loss: 1.4245, G loss: 0.6283\n",
      "[6084/1762] D loss: 1.4497, G loss: 0.9541\n",
      "[6404/1762] D loss: 0.5539, G loss: 1.0653\n",
      "[6724/1762] D loss: 0.3966, G loss: 2.3518\n",
      "[7042/1762] D loss: 1.3916, G loss: 0.6390\n",
      "train error: \n",
      " D loss: 1.363937, G loss: 0.655291, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339441, G loss: 0.677477, D accuracy: 54.6%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4089, G loss: 0.5745\n",
      "[324/1762] D loss: 1.4294, G loss: 0.8121\n",
      "[644/1762] D loss: 0.3997, G loss: 2.0338\n",
      "[964/1762] D loss: 1.4712, G loss: 1.0086\n",
      "[1284/1762] D loss: 1.4326, G loss: 0.8455\n",
      "[1604/1762] D loss: 0.1406, G loss: 2.8267\n",
      "[1924/1762] D loss: 1.3958, G loss: 0.5576\n",
      "[2244/1762] D loss: 1.2375, G loss: 1.1357\n",
      "[2564/1762] D loss: 1.4279, G loss: 0.8545\n",
      "[2884/1762] D loss: 1.3954, G loss: 0.6659\n",
      "[3204/1762] D loss: 1.4220, G loss: 0.8510\n",
      "[3524/1762] D loss: 1.4167, G loss: 0.8038\n",
      "[3844/1762] D loss: 1.3967, G loss: 0.7840\n",
      "[4164/1762] D loss: 0.3063, G loss: 2.0135\n",
      "[4484/1762] D loss: 1.4114, G loss: 0.7119\n",
      "[4804/1762] D loss: 1.4210, G loss: 0.8111\n",
      "[5124/1762] D loss: 1.4579, G loss: 0.8313\n",
      "[5444/1762] D loss: 1.4031, G loss: 0.7481\n",
      "[5764/1762] D loss: 1.4451, G loss: 0.5187\n",
      "[6084/1762] D loss: 1.4415, G loss: 0.5801\n",
      "[6404/1762] D loss: 1.4449, G loss: 0.8469\n",
      "[6724/1762] D loss: 1.3966, G loss: 0.6860\n",
      "[7042/1762] D loss: 1.3998, G loss: 0.6094\n",
      "train error: \n",
      " D loss: 1.450361, G loss: 0.482315, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.424327, G loss: 0.515794, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.6786\n",
      "[324/1762] D loss: 1.3897, G loss: 0.7081\n",
      "[644/1762] D loss: 0.1514, G loss: 2.1145\n",
      "[964/1762] D loss: 0.1995, G loss: 2.4874\n",
      "[1284/1762] D loss: 1.4173, G loss: 0.5221\n",
      "[1604/1762] D loss: 0.3335, G loss: 1.5275\n",
      "[1924/1762] D loss: 0.3052, G loss: 1.4330\n",
      "[2244/1762] D loss: 1.4467, G loss: 0.9709\n",
      "[2564/1762] D loss: 1.3914, G loss: 0.7353\n",
      "[2884/1762] D loss: 1.4240, G loss: 0.7686\n",
      "[3204/1762] D loss: 0.5587, G loss: 1.9119\n",
      "[3524/1762] D loss: 1.8676, G loss: 1.1535\n",
      "[3844/1762] D loss: 0.7894, G loss: 1.1630\n",
      "[4164/1762] D loss: 1.3706, G loss: 0.7468\n",
      "[4484/1762] D loss: 1.3997, G loss: 0.7125\n",
      "[4804/1762] D loss: 0.3059, G loss: 2.3947\n",
      "[5124/1762] D loss: 1.3630, G loss: 0.7241\n",
      "[5444/1762] D loss: 1.3915, G loss: 0.5981\n",
      "[5764/1762] D loss: 1.4422, G loss: 0.7021\n",
      "[6084/1762] D loss: 1.4791, G loss: 0.9859\n",
      "[6404/1762] D loss: 1.3901, G loss: 0.5567\n",
      "[6724/1762] D loss: 1.5516, G loss: 0.3975\n",
      "[7042/1762] D loss: 1.5258, G loss: 0.4806\n",
      "train error: \n",
      " D loss: 1.328910, G loss: 0.846879, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317460, G loss: 0.869052, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4516, G loss: 0.5370\n",
      "[324/1762] D loss: 1.3480, G loss: 0.7839\n",
      "[644/1762] D loss: 1.4096, G loss: 0.7038\n",
      "[964/1762] D loss: 0.6042, G loss: 1.2320\n",
      "[1284/1762] D loss: 1.3972, G loss: 0.6567\n",
      "[1604/1762] D loss: 1.3945, G loss: 0.6649\n",
      "[1924/1762] D loss: 1.4466, G loss: 0.5026\n",
      "[2244/1762] D loss: 1.4024, G loss: 0.7883\n",
      "[2564/1762] D loss: 0.4338, G loss: 1.6358\n",
      "[2884/1762] D loss: 1.3900, G loss: 0.6509\n",
      "[3204/1762] D loss: 1.4563, G loss: 0.8347\n",
      "[3524/1762] D loss: 1.5109, G loss: 0.5565\n",
      "[3844/1762] D loss: 1.4249, G loss: 0.5232\n",
      "[4164/1762] D loss: 1.4406, G loss: 0.5753\n",
      "[4484/1762] D loss: 1.3230, G loss: 0.8710\n",
      "[4804/1762] D loss: 0.2820, G loss: 2.1928\n",
      "[5124/1762] D loss: 1.4496, G loss: 0.5434\n",
      "[5444/1762] D loss: 1.4673, G loss: 0.6014\n",
      "[5764/1762] D loss: 1.4638, G loss: 0.9022\n",
      "[6084/1762] D loss: 1.4425, G loss: 0.7976\n",
      "[6404/1762] D loss: 1.4175, G loss: 0.8460\n",
      "[6724/1762] D loss: 1.4205, G loss: 0.5853\n",
      "[7042/1762] D loss: 1.3590, G loss: 0.8220\n",
      "train error: \n",
      " D loss: 1.312587, G loss: 0.909957, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283664, G loss: 0.976027, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4095, G loss: 0.8266\n",
      "[324/1762] D loss: 1.3971, G loss: 0.8781\n",
      "[644/1762] D loss: 1.0484, G loss: 1.9388\n",
      "[964/1762] D loss: 1.2816, G loss: 0.9555\n",
      "[1284/1762] D loss: 0.1360, G loss: 3.9882\n",
      "[1604/1762] D loss: 1.4107, G loss: 0.6572\n",
      "[1924/1762] D loss: 1.3900, G loss: 0.7285\n",
      "[2244/1762] D loss: 1.3978, G loss: 0.6599\n",
      "[2564/1762] D loss: 1.3984, G loss: 0.5777\n",
      "[2884/1762] D loss: 1.4133, G loss: 0.5029\n",
      "[3204/1762] D loss: 1.4297, G loss: 0.5347\n",
      "[3524/1762] D loss: 1.4114, G loss: 0.6227\n",
      "[3844/1762] D loss: 1.4148, G loss: 0.6051\n",
      "[4164/1762] D loss: 0.8901, G loss: 0.8990\n",
      "[4484/1762] D loss: 1.3975, G loss: 0.6648\n",
      "[4804/1762] D loss: 1.1707, G loss: 0.9819\n",
      "[5124/1762] D loss: 1.3961, G loss: 0.7470\n",
      "[5444/1762] D loss: 0.7571, G loss: 1.1614\n",
      "[5764/1762] D loss: 1.3886, G loss: 0.7446\n",
      "[6084/1762] D loss: 0.9478, G loss: 1.4524\n",
      "[6404/1762] D loss: 0.5963, G loss: 1.5543\n",
      "[6724/1762] D loss: 0.4273, G loss: 1.5585\n",
      "[7042/1762] D loss: 1.4219, G loss: 0.6190\n",
      "train error: \n",
      " D loss: 1.374186, G loss: 0.706128, D accuracy: 51.1%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374755, G loss: 0.699091, D accuracy: 51.1%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3981, G loss: 0.6893\n",
      "[324/1762] D loss: 1.3887, G loss: 0.7094\n",
      "[644/1762] D loss: 1.3895, G loss: 0.6372\n",
      "[964/1762] D loss: 1.4111, G loss: 0.6051\n",
      "[1284/1762] D loss: 1.4042, G loss: 0.7508\n",
      "[1604/1762] D loss: 1.5071, G loss: 0.9666\n",
      "[1924/1762] D loss: 0.5820, G loss: 1.2736\n",
      "[2244/1762] D loss: 1.3976, G loss: 0.6690\n",
      "[2564/1762] D loss: 1.4231, G loss: 0.6291\n",
      "[2884/1762] D loss: 1.4820, G loss: 0.4536\n",
      "[3204/1762] D loss: 1.4104, G loss: 0.5916\n",
      "[3524/1762] D loss: 1.4168, G loss: 0.6187\n",
      "[3844/1762] D loss: 0.4643, G loss: 1.1591\n",
      "[4164/1762] D loss: 1.3973, G loss: 0.7216\n",
      "[4484/1762] D loss: 1.4630, G loss: 0.4844\n",
      "[4804/1762] D loss: 0.1815, G loss: 2.7281\n",
      "[5124/1762] D loss: 1.3913, G loss: 0.6703\n",
      "[5444/1762] D loss: 0.5644, G loss: 1.5027\n",
      "[5764/1762] D loss: 1.0361, G loss: 1.2604\n",
      "[6084/1762] D loss: 1.4034, G loss: 0.6422\n",
      "[6404/1762] D loss: 0.8880, G loss: 1.8981\n",
      "[6724/1762] D loss: 1.4113, G loss: 0.6909\n",
      "[7042/1762] D loss: 1.3901, G loss: 0.6471\n",
      "train error: \n",
      " D loss: 1.380202, G loss: 0.622772, D accuracy: 52.2%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356373, G loss: 0.667331, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.7016\n",
      "[324/1762] D loss: 1.3142, G loss: 0.9597\n",
      "[644/1762] D loss: 1.2782, G loss: 1.8109\n",
      "[964/1762] D loss: 1.3970, G loss: 0.7266\n",
      "[1284/1762] D loss: 1.4609, G loss: 0.8934\n",
      "[1604/1762] D loss: 0.7696, G loss: 0.9577\n",
      "[1924/1762] D loss: 1.4294, G loss: 0.5320\n",
      "[2244/1762] D loss: 1.4123, G loss: 0.7194\n",
      "[2564/1762] D loss: 1.3867, G loss: 0.6950\n",
      "[2884/1762] D loss: 1.4210, G loss: 0.8072\n",
      "[3204/1762] D loss: 1.4170, G loss: 0.6958\n",
      "[3524/1762] D loss: 1.3847, G loss: 0.5850\n",
      "[3844/1762] D loss: 1.4561, G loss: 0.4499\n",
      "[4164/1762] D loss: 1.5283, G loss: 0.4348\n",
      "[4484/1762] D loss: 1.4257, G loss: 0.5463\n",
      "[4804/1762] D loss: 1.4022, G loss: 0.7512\n",
      "[5124/1762] D loss: 0.6277, G loss: 1.7275\n",
      "[5444/1762] D loss: 0.5137, G loss: 2.1875\n",
      "[5764/1762] D loss: 0.5710, G loss: 1.8022\n",
      "[6084/1762] D loss: 0.3239, G loss: 2.0195\n",
      "[6404/1762] D loss: 0.1717, G loss: 2.4523\n",
      "[6724/1762] D loss: 1.0735, G loss: 0.9047\n",
      "[7042/1762] D loss: 0.8603, G loss: 1.0966\n",
      "train error: \n",
      " D loss: 1.434907, G loss: 0.799399, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.429302, G loss: 0.779347, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5540, G loss: 1.1482\n",
      "[324/1762] D loss: 1.3948, G loss: 0.6658\n",
      "[644/1762] D loss: 1.4663, G loss: 0.9053\n",
      "[964/1762] D loss: 1.5464, G loss: 1.0426\n",
      "[1284/1762] D loss: 1.4189, G loss: 0.8508\n",
      "[1604/1762] D loss: 1.3945, G loss: 0.6358\n",
      "[1924/1762] D loss: 0.4567, G loss: 1.1090\n",
      "[2244/1762] D loss: 0.3372, G loss: 1.7494\n",
      "[2564/1762] D loss: 1.4017, G loss: 0.6385\n",
      "[2884/1762] D loss: 1.4198, G loss: 0.5857\n",
      "[3204/1762] D loss: 1.4520, G loss: 0.4950\n",
      "[3524/1762] D loss: 0.4195, G loss: 1.1508\n",
      "[3844/1762] D loss: 1.4153, G loss: 0.5652\n",
      "[4164/1762] D loss: 1.4197, G loss: 0.8825\n",
      "[4484/1762] D loss: 0.3876, G loss: 1.2512\n",
      "[4804/1762] D loss: 1.4278, G loss: 0.8058\n",
      "[5124/1762] D loss: 0.2387, G loss: 1.9915\n",
      "[5444/1762] D loss: 0.9098, G loss: 1.3977\n",
      "[5764/1762] D loss: 1.3839, G loss: 0.7403\n",
      "[6084/1762] D loss: 1.4119, G loss: 0.5784\n",
      "[6404/1762] D loss: 1.3967, G loss: 0.7648\n",
      "[6724/1762] D loss: 1.4115, G loss: 0.8961\n",
      "[7042/1762] D loss: 1.4851, G loss: 0.5082\n",
      "train error: \n",
      " D loss: 1.418483, G loss: 0.509940, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403185, G loss: 0.508338, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4187, G loss: 0.6117\n",
      "[324/1762] D loss: 1.4263, G loss: 0.5657\n",
      "[644/1762] D loss: 1.4858, G loss: 0.9672\n",
      "[964/1762] D loss: 1.4306, G loss: 0.9211\n",
      "[1284/1762] D loss: 1.4270, G loss: 0.5542\n",
      "[1604/1762] D loss: 1.3968, G loss: 0.6577\n",
      "[1924/1762] D loss: 1.7448, G loss: 1.5722\n",
      "[2244/1762] D loss: 1.3997, G loss: 0.6127\n",
      "[2564/1762] D loss: 1.3910, G loss: 0.6595\n",
      "[2884/1762] D loss: 1.4105, G loss: 0.8230\n",
      "[3204/1762] D loss: 0.5019, G loss: 1.6859\n",
      "[3524/1762] D loss: 1.4157, G loss: 0.8441\n",
      "[3844/1762] D loss: 1.4331, G loss: 0.8602\n",
      "[4164/1762] D loss: 0.0653, G loss: 4.2335\n",
      "[4484/1762] D loss: 0.2435, G loss: 2.4827\n",
      "[4804/1762] D loss: 0.2098, G loss: 2.4205\n",
      "[5124/1762] D loss: 1.4178, G loss: 0.8737\n",
      "[5444/1762] D loss: 1.3991, G loss: 0.7519\n",
      "[5764/1762] D loss: 1.3968, G loss: 0.6803\n",
      "[6084/1762] D loss: 1.4267, G loss: 0.8275\n",
      "[6404/1762] D loss: 1.4100, G loss: 0.5582\n",
      "[6724/1762] D loss: 1.4485, G loss: 0.5066\n",
      "[7042/1762] D loss: 1.4195, G loss: 0.7093\n",
      "train error: \n",
      " D loss: 1.511138, G loss: 0.591076, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.473989, G loss: 0.680402, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3699, G loss: 1.0227\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6468\n",
      "[644/1762] D loss: 0.3448, G loss: 1.8758\n",
      "[964/1762] D loss: 1.4264, G loss: 0.7266\n",
      "[1284/1762] D loss: 1.3982, G loss: 0.7373\n",
      "[1604/1762] D loss: 1.4051, G loss: 0.7548\n",
      "[1924/1762] D loss: 1.3909, G loss: 0.6999\n",
      "[2244/1762] D loss: 1.4071, G loss: 0.7695\n",
      "[2564/1762] D loss: 1.3915, G loss: 0.6619\n",
      "[2884/1762] D loss: 0.2093, G loss: 2.4742\n",
      "[3204/1762] D loss: 0.1090, G loss: 2.9034\n",
      "[3524/1762] D loss: 1.4612, G loss: 0.5192\n",
      "[3844/1762] D loss: 1.3992, G loss: 0.8152\n",
      "[4164/1762] D loss: 1.3927, G loss: 0.7279\n",
      "[4484/1762] D loss: 0.2044, G loss: 2.1190\n",
      "[4804/1762] D loss: 1.4180, G loss: 0.5085\n",
      "[5124/1762] D loss: 0.1811, G loss: 2.2584\n",
      "[5444/1762] D loss: 0.1522, G loss: 2.3132\n",
      "[5764/1762] D loss: 1.3945, G loss: 0.6978\n",
      "[6084/1762] D loss: 1.4097, G loss: 0.7937\n",
      "[6404/1762] D loss: 1.4023, G loss: 0.6429\n",
      "[6724/1762] D loss: 1.3892, G loss: 0.7193\n",
      "[7042/1762] D loss: 1.3982, G loss: 0.8093\n",
      "train error: \n",
      " D loss: 2.062636, G loss: 0.381545, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.004696, G loss: 0.456300, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3896, G loss: 0.7054\n",
      "[324/1762] D loss: 1.4022, G loss: 0.6839\n",
      "[644/1762] D loss: 1.4573, G loss: 0.8025\n",
      "[964/1762] D loss: 1.4199, G loss: 0.5286\n",
      "[1284/1762] D loss: 0.1678, G loss: 2.3821\n",
      "[1604/1762] D loss: 1.4178, G loss: 0.8380\n",
      "[1924/1762] D loss: 0.2375, G loss: 2.7309\n",
      "[2244/1762] D loss: 0.2339, G loss: 2.1008\n",
      "[2564/1762] D loss: 1.4038, G loss: 0.6076\n",
      "[2884/1762] D loss: 1.4198, G loss: 0.6622\n",
      "[3204/1762] D loss: 1.4085, G loss: 0.8742\n",
      "[3524/1762] D loss: 1.4432, G loss: 1.0420\n",
      "[3844/1762] D loss: 1.2685, G loss: 0.7663\n",
      "[4164/1762] D loss: 0.9911, G loss: 2.1746\n",
      "[4484/1762] D loss: 1.4175, G loss: 0.8310\n",
      "[4804/1762] D loss: 1.4262, G loss: 0.9184\n",
      "[5124/1762] D loss: 1.4607, G loss: 0.8901\n",
      "[5444/1762] D loss: 1.3895, G loss: 0.7901\n",
      "[5764/1762] D loss: 1.4443, G loss: 0.8758\n",
      "[6084/1762] D loss: 1.3928, G loss: 0.5719\n",
      "[6404/1762] D loss: 1.4246, G loss: 0.6197\n",
      "[6724/1762] D loss: 1.4150, G loss: 0.8754\n",
      "[7042/1762] D loss: 1.5846, G loss: 0.3658\n",
      "train error: \n",
      " D loss: 1.356879, G loss: 0.925635, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340688, G loss: 0.993090, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 89.7% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4472, G loss: 0.5931\n",
      "[324/1762] D loss: 1.4143, G loss: 0.6292\n",
      "[644/1762] D loss: 1.4073, G loss: 0.8599\n",
      "[964/1762] D loss: 2.2928, G loss: 0.8987\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.6544\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7174\n",
      "[1924/1762] D loss: 1.4035, G loss: 0.5601\n",
      "[2244/1762] D loss: 0.5318, G loss: 1.4355\n",
      "[2564/1762] D loss: 0.3302, G loss: 1.8936\n",
      "[2884/1762] D loss: 1.3503, G loss: 0.6740\n",
      "[3204/1762] D loss: 1.3994, G loss: 0.6406\n",
      "[3524/1762] D loss: 1.4167, G loss: 0.5551\n",
      "[3844/1762] D loss: 1.4280, G loss: 0.7946\n",
      "[4164/1762] D loss: 1.4176, G loss: 0.8096\n",
      "[4484/1762] D loss: 0.2137, G loss: 1.7351\n",
      "[4804/1762] D loss: 1.4186, G loss: 0.8220\n",
      "[5124/1762] D loss: 1.3939, G loss: 0.6976\n",
      "[5444/1762] D loss: 1.3947, G loss: 0.7650\n",
      "[5764/1762] D loss: 1.4065, G loss: 0.5789\n",
      "[6084/1762] D loss: 1.4015, G loss: 0.7384\n",
      "[6404/1762] D loss: 1.3896, G loss: 0.7424\n",
      "[6724/1762] D loss: 1.3995, G loss: 0.6205\n",
      "[7042/1762] D loss: 1.4033, G loss: 0.6572\n",
      "train error: \n",
      " D loss: 1.360645, G loss: 0.744827, D accuracy: 51.9%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351263, G loss: 0.749064, D accuracy: 52.3%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4062, G loss: 0.8300\n",
      "[324/1762] D loss: 1.1451, G loss: 1.2313\n",
      "[644/1762] D loss: 0.2414, G loss: 1.8157\n",
      "[964/1762] D loss: 1.4063, G loss: 0.5880\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.7156\n",
      "[1604/1762] D loss: 1.4086, G loss: 0.8605\n",
      "[1924/1762] D loss: 0.2871, G loss: 1.5538\n",
      "[2244/1762] D loss: 1.4370, G loss: 0.8790\n",
      "[2564/1762] D loss: 1.3983, G loss: 0.7822\n",
      "[2884/1762] D loss: 0.2347, G loss: 1.6458\n",
      "[3204/1762] D loss: 1.3863, G loss: 0.6811\n",
      "[3524/1762] D loss: 1.3937, G loss: 0.6508\n",
      "[3844/1762] D loss: 0.6014, G loss: 1.1839\n",
      "[4164/1762] D loss: 1.4602, G loss: 0.9681\n",
      "[4484/1762] D loss: 1.3920, G loss: 0.6260\n",
      "[4804/1762] D loss: 1.4004, G loss: 0.6998\n",
      "[5124/1762] D loss: 1.3899, G loss: 0.6721\n",
      "[5444/1762] D loss: 1.3955, G loss: 0.7084\n",
      "[5764/1762] D loss: 1.4353, G loss: 0.5642\n",
      "[6084/1762] D loss: 1.3889, G loss: 0.6759\n",
      "[6404/1762] D loss: 1.3910, G loss: 0.6912\n",
      "[6724/1762] D loss: 1.3956, G loss: 0.7679\n",
      "[7042/1762] D loss: 1.3868, G loss: 0.6935\n",
      "train error: \n",
      " D loss: 1.364617, G loss: 0.724595, D accuracy: 52.1%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351154, G loss: 0.746834, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 90.4% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.6660\n",
      "[324/1762] D loss: 1.4138, G loss: 0.8031\n",
      "[644/1762] D loss: 1.3932, G loss: 0.7608\n",
      "[964/1762] D loss: 1.3930, G loss: 0.6771\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7059\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.6690\n",
      "[1924/1762] D loss: 0.7477, G loss: 1.1188\n",
      "[2244/1762] D loss: 1.4059, G loss: 0.5860\n",
      "[2564/1762] D loss: 0.3384, G loss: 1.4020\n",
      "[2884/1762] D loss: 1.4039, G loss: 0.8373\n",
      "[3204/1762] D loss: 1.3889, G loss: 0.6859\n",
      "[3524/1762] D loss: 1.4051, G loss: 0.7126\n",
      "[3844/1762] D loss: 1.4820, G loss: 0.5551\n",
      "[4164/1762] D loss: 1.4010, G loss: 0.7504\n",
      "[4484/1762] D loss: 1.3978, G loss: 0.6393\n",
      "[4804/1762] D loss: 1.4060, G loss: 0.7385\n",
      "[5124/1762] D loss: 0.6657, G loss: 1.9815\n",
      "[5444/1762] D loss: 1.4363, G loss: 0.8193\n",
      "[5764/1762] D loss: 1.3963, G loss: 0.7488\n",
      "[6084/1762] D loss: 0.2448, G loss: 2.1685\n",
      "[6404/1762] D loss: 0.5500, G loss: 1.9722\n",
      "[6724/1762] D loss: 1.3919, G loss: 0.6722\n",
      "[7042/1762] D loss: 1.1422, G loss: 1.3998\n",
      "train error: \n",
      " D loss: 1.315252, G loss: 0.874802, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312125, G loss: 0.873136, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1589, G loss: 2.2937\n",
      "[324/1762] D loss: 1.3923, G loss: 0.5936\n",
      "[644/1762] D loss: 0.9561, G loss: 2.6195\n",
      "[964/1762] D loss: 1.3919, G loss: 0.7071\n",
      "[1284/1762] D loss: 1.4056, G loss: 0.6054\n",
      "[1604/1762] D loss: 0.4349, G loss: 2.7937\n",
      "[1924/1762] D loss: 1.3921, G loss: 0.6134\n",
      "[2244/1762] D loss: 0.1126, G loss: 4.3181\n",
      "[2564/1762] D loss: 1.3929, G loss: 0.6803\n",
      "[2884/1762] D loss: 0.2539, G loss: 3.9428\n",
      "[3204/1762] D loss: 1.3953, G loss: 0.6488\n",
      "[3524/1762] D loss: 1.3956, G loss: 0.7067\n",
      "[3844/1762] D loss: 1.3885, G loss: 0.6343\n",
      "[4164/1762] D loss: 1.3943, G loss: 0.6550\n",
      "[4484/1762] D loss: 1.3346, G loss: 0.7154\n",
      "[4804/1762] D loss: 1.3787, G loss: 0.6611\n",
      "[5124/1762] D loss: 0.1211, G loss: 2.9984\n",
      "[5444/1762] D loss: 1.3990, G loss: 0.6009\n",
      "[5764/1762] D loss: 1.4233, G loss: 0.7189\n",
      "[6084/1762] D loss: 1.4035, G loss: 0.7677\n",
      "[6404/1762] D loss: 0.0238, G loss: 5.3274\n",
      "[6724/1762] D loss: 0.0772, G loss: 3.6540\n",
      "[7042/1762] D loss: 1.4021, G loss: 0.5973\n",
      "train error: \n",
      " D loss: 2.067392, G loss: 1.537543, D accuracy: 50.0%, cell accuracy: 99.3%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.101409, G loss: 1.525915, D accuracy: 50.3%, cell accuracy: 99.1%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6640\n",
      "[324/1762] D loss: 1.3804, G loss: 0.5983\n",
      "[644/1762] D loss: 1.4019, G loss: 0.7542\n",
      "[964/1762] D loss: 1.3978, G loss: 0.7336\n",
      "[1284/1762] D loss: 0.0631, G loss: 3.3641\n",
      "[1604/1762] D loss: 0.0507, G loss: 3.4012\n",
      "[1924/1762] D loss: 1.4366, G loss: 0.8921\n",
      "[2244/1762] D loss: 0.0469, G loss: 3.7080\n",
      "[2564/1762] D loss: 0.3874, G loss: 1.2380\n",
      "[2884/1762] D loss: 1.3923, G loss: 0.6638\n",
      "[3204/1762] D loss: 1.3955, G loss: 0.6979\n",
      "[3524/1762] D loss: 1.4044, G loss: 0.7482\n",
      "[3844/1762] D loss: 1.3888, G loss: 0.6729\n",
      "[4164/1762] D loss: 1.4022, G loss: 0.7947\n",
      "[4484/1762] D loss: 1.4235, G loss: 0.8519\n",
      "[4804/1762] D loss: 1.4659, G loss: 0.5530\n",
      "[5124/1762] D loss: 0.3214, G loss: 1.9395\n",
      "[5444/1762] D loss: 1.3920, G loss: 0.7865\n",
      "[5764/1762] D loss: 1.3685, G loss: 0.7414\n",
      "[6084/1762] D loss: 1.4175, G loss: 0.8527\n",
      "[6404/1762] D loss: 1.3872, G loss: 0.6800\n",
      "[6724/1762] D loss: 0.0220, G loss: 4.6422\n",
      "[7042/1762] D loss: 1.4219, G loss: 0.8712\n",
      "train error: \n",
      " D loss: 1.290115, G loss: 0.966839, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 85.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265744, G loss: 1.083859, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 83.7% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2039, G loss: 2.8185\n",
      "[324/1762] D loss: 1.4092, G loss: 0.8322\n",
      "[644/1762] D loss: 1.4042, G loss: 0.6715\n",
      "[964/1762] D loss: 0.1471, G loss: 2.5837\n",
      "[1284/1762] D loss: 1.3377, G loss: 0.6991\n",
      "[1604/1762] D loss: 0.2267, G loss: 2.2086\n",
      "[1924/1762] D loss: 1.4125, G loss: 0.6466\n",
      "[2244/1762] D loss: 1.3907, G loss: 0.6566\n",
      "[2564/1762] D loss: 0.8223, G loss: 3.2123\n",
      "[2884/1762] D loss: 0.9135, G loss: 1.3115\n",
      "[3204/1762] D loss: 1.4067, G loss: 0.6902\n",
      "[3524/1762] D loss: 1.4118, G loss: 1.2875\n",
      "[3844/1762] D loss: 1.4579, G loss: 0.4804\n",
      "[4164/1762] D loss: 0.4781, G loss: 1.5154\n",
      "[4484/1762] D loss: 1.5155, G loss: 0.9223\n",
      "[4804/1762] D loss: 1.4293, G loss: 0.6109\n",
      "[5124/1762] D loss: 1.4013, G loss: 0.6251\n",
      "[5444/1762] D loss: 0.4623, G loss: 1.8928\n",
      "[5764/1762] D loss: 1.8102, G loss: 1.2467\n",
      "[6084/1762] D loss: 1.4220, G loss: 0.8761\n",
      "[6404/1762] D loss: 1.3905, G loss: 0.6569\n",
      "[6724/1762] D loss: 1.4148, G loss: 0.8201\n",
      "[7042/1762] D loss: 1.4447, G loss: 0.6698\n",
      "train error: \n",
      " D loss: 1.319269, G loss: 0.790373, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288394, G loss: 0.822149, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8314, G loss: 1.4256\n",
      "[324/1762] D loss: 0.3161, G loss: 2.3286\n",
      "[644/1762] D loss: 0.3026, G loss: 2.1295\n",
      "[964/1762] D loss: 1.3976, G loss: 0.6026\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.6706\n",
      "[1604/1762] D loss: 1.4291, G loss: 0.8455\n",
      "[1924/1762] D loss: 1.4097, G loss: 0.5828\n",
      "[2244/1762] D loss: 0.3128, G loss: 2.1278\n",
      "[2564/1762] D loss: 1.4075, G loss: 0.6287\n",
      "[2884/1762] D loss: 1.3978, G loss: 0.6240\n",
      "[3204/1762] D loss: 1.4058, G loss: 0.8204\n",
      "[3524/1762] D loss: 0.4115, G loss: 1.2538\n",
      "[3844/1762] D loss: 1.3958, G loss: 0.6860\n",
      "[4164/1762] D loss: 1.5951, G loss: 1.2535\n",
      "[4484/1762] D loss: 0.1633, G loss: 1.9915\n",
      "[4804/1762] D loss: 1.3940, G loss: 0.7337\n",
      "[5124/1762] D loss: 1.4292, G loss: 0.5609\n",
      "[5444/1762] D loss: 0.1553, G loss: 3.2908\n",
      "[5764/1762] D loss: 0.2984, G loss: 1.4682\n",
      "[6084/1762] D loss: 1.3388, G loss: 0.5745\n",
      "[6404/1762] D loss: 1.4028, G loss: 0.7959\n",
      "[6724/1762] D loss: 1.3944, G loss: 0.7173\n",
      "[7042/1762] D loss: 1.3853, G loss: 0.7191\n",
      "train error: \n",
      " D loss: 1.385248, G loss: 0.719305, D accuracy: 51.2%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377023, G loss: 0.702057, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for bs in [8, 16]:\n",
    "        train(run_name=f\"bs_{bs}\", learning_rate=1e-3, batch_size=bs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the batch size doesn't help."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "None of the \"GAN hacks\" seem to work. We'll have to find another approach of improving the models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
