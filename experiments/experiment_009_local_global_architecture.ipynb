{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 009\n",
    "\n",
    "In this experiment, we try out a new architecture for the Tetris emulator model which incorporates global information as well as local information into the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError()\n",
    "        with os.scandir(self.path) as it:\n",
    "            entry: os.DirEntry = next(iter(it))\n",
    "            _, self.ext = os.path.splitext(entry.name)\n",
    "            self.highest_index = max((int(Path(file.path).stem) for file in it), default=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.highest_index + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = os.path.join(self.path, f\"{idx}{self.ext}\")\n",
    "        if not os.path.exists(file):\n",
    "            raise IndexError()\n",
    "        boards = np.load(file)\n",
    "        x = torch.tensor(boards[-2]) # Ignore all boards except the last two\n",
    "        y = torch.tensor(boards[-1], dtype=torch.long)\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 22, 10]) torch.int32\n",
      "torch.Size([4, 22, 10]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisModel(nn.Module):\n",
    "    \"\"\"Predicts the next state of the cells.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of int32 of shape (batch_size, height, width). height = 22 and width = 10 are the dimensions of the game\n",
    "           board. The entries should be 0 for empty cells and 1 for blocks.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, height, width), logits for the new cells. Probabilities close to 0 (negative logits)\n",
    "             correspond to empty cells, and probabilities close to 1 (positive logits) correspond to blocks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(2, 10, 3, padding=1)\n",
    "        self.conv1 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 10, 1)\n",
    "        self.conv3 = nn.Conv2d(10, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((0, 3, 1, 2)) # Move channels/classes to dimension 1\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        logits = F.log_softmax(self.conv3(x), dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalGlobalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 5, 3),               # (26, 14) -> (24, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),      # (24, 12) -> (12,  6)\n",
    "            nn.Conv2d(5, 10, 3),              # (12,  6) -> (10,  4)\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(6, 3)), # ( 6,  3) -> ( 1,  1)\n",
    "        )\n",
    "        self.local_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 5, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(5, 10, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv0 = nn.Conv2d(20, 10, 1)\n",
    "        self.conv1 = nn.Conv2d(10, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((0, 3, 1, 2)) # Move channels/classes to dimension 1\n",
    "        x = F.pad(x, (2, 2, 2, 2)) # Zero-pad 2 cells on each side\n",
    "        x_local = self.local_module(x) # Extract local information\n",
    "        x_global = self.global_module(x) # Extract global information\n",
    "        x_global = x_global.repeat(1, 1, 22, 10) # Broadcast global information to image dimensions\n",
    "        x = torch.cat((x_local, x_global), dim=1) # Combine local and global information\n",
    "        x = F.relu(self.conv0(x))\n",
    "        logits = F.log_softmax(self.conv1(x), dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalGlobalModel(\n",
      "  (global_module): Sequential(\n",
      "    (0): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): AvgPool2d(kernel_size=(6, 3), stride=(6, 3), padding=0)\n",
      "  )\n",
      "  (local_module): Sequential(\n",
      "    (0): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (conv0): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (conv1): Conv2d(10, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "Predicted states: tensor([[[0.2740, 0.2753, 0.2754, 0.2754, 0.2754, 0.2754, 0.2754, 0.2754,\n",
      "          0.2753, 0.2752],\n",
      "         [0.2734, 0.2739, 0.2734, 0.2734, 0.2734, 0.2734, 0.2734, 0.2734,\n",
      "          0.2736, 0.2743],\n",
      "         [0.2739, 0.2745, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2745, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2745, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2745, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2745, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2745, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2747, 0.2735, 0.2727, 0.2754, 0.2740, 0.2741, 0.2741,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2744, 0.2729, 0.2705, 0.2763, 0.2750, 0.2750, 0.2740,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2743, 0.2720, 0.2747, 0.2709, 0.2753, 0.2751, 0.2743,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2745, 0.2733, 0.2749, 0.2753, 0.2758, 0.2711, 0.2748,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2743, 0.2738, 0.2742, 0.2732, 0.2744, 0.2743, 0.2733,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2744, 0.2742, 0.2743, 0.2736, 0.2737, 0.2736, 0.2746,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2745, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2745, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741, 0.2741,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2745, 0.2741, 0.2743, 0.2735, 0.2727, 0.2754, 0.2740,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2747, 0.2737, 0.2718, 0.2744, 0.2737, 0.2759, 0.2742,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2744, 0.2726, 0.2705, 0.2751, 0.2771, 0.2753, 0.2744,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2739, 0.2743, 0.2720, 0.2745, 0.2726, 0.2782, 0.2710, 0.2751,\n",
      "          0.2742, 0.2746],\n",
      "         [0.2738, 0.2750, 0.2747, 0.2748, 0.2755, 0.2746, 0.2724, 0.2737,\n",
      "          0.2750, 0.2744],\n",
      "         [0.2723, 0.2725, 0.2723, 0.2724, 0.2748, 0.2713, 0.2711, 0.2720,\n",
      "          0.2729, 0.2732]],\n",
      "\n",
      "        [[0.3837, 0.3828, 0.3827, 0.3827, 0.3827, 0.3827, 0.3827, 0.3827,\n",
      "          0.3828, 0.3828],\n",
      "         [0.3841, 0.3838, 0.3841, 0.3841, 0.3841, 0.3841, 0.3841, 0.3841,\n",
      "          0.3840, 0.3835],\n",
      "         [0.3838, 0.3833, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3833, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3833, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3833, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3833, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3833, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3832, 0.3840, 0.3846, 0.3827, 0.3837, 0.3836, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3834, 0.3845, 0.3862, 0.3821, 0.3829, 0.3830, 0.3837,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3835, 0.3851, 0.3832, 0.3859, 0.3828, 0.3829, 0.3835,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3834, 0.3842, 0.3830, 0.3828, 0.3824, 0.3858, 0.3831,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3835, 0.3838, 0.3836, 0.3843, 0.3834, 0.3835, 0.3842,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3834, 0.3835, 0.3835, 0.3840, 0.3839, 0.3840, 0.3833,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3833, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3833, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3833, 0.3836, 0.3835, 0.3840, 0.3846, 0.3827, 0.3837,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3832, 0.3839, 0.3852, 0.3834, 0.3839, 0.3824, 0.3836,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3834, 0.3847, 0.3862, 0.3829, 0.3815, 0.3828, 0.3834,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3835, 0.3851, 0.3833, 0.3847, 0.3806, 0.3858, 0.3829,\n",
      "          0.3836, 0.3833],\n",
      "         [0.3838, 0.3830, 0.3832, 0.3831, 0.3826, 0.3833, 0.3848, 0.3839,\n",
      "          0.3830, 0.3834],\n",
      "         [0.3849, 0.3848, 0.3849, 0.3849, 0.3831, 0.3856, 0.3858, 0.3851,\n",
      "          0.3845, 0.3843]]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = LocalGlobalModel().to(device)\n",
    "print(model)\n",
    "\n",
    "X, y = next(iter(train_dataloader))\n",
    "logits = model(X)[0]\n",
    "preds = F.sigmoid(logits)\n",
    "print(f\"Predicted states: {preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        classes = torch.argmax(pred, dim=1)\n",
    "        cell_accuracy += (classes == y).type(torch.float).mean().item()\n",
    "        board_accuracy += (classes == y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    epoch_loss /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    return {\n",
    "        \"loss\": epoch_loss,\n",
    "        \"acc\": cell_accuracy,\n",
    "        \"acc_board\": board_accuracy\n",
    "    }\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            epoch_loss += loss_fn(pred, y).item()\n",
    "            classes = torch.argmax(pred, dim=1)\n",
    "            cell_accuracy += (classes == y).type(torch.float).mean().item()\n",
    "            board_accuracy += (classes == y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "    epoch_loss /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*cell_accuracy):>0.1f}%, Board accuracy: {(100*board_accuracy):>0.1f}%, Avg loss: {epoch_loss:>8f} \\n\")\n",
    "    return {\n",
    "        \"loss\": epoch_loss,\n",
    "        \"acc\": cell_accuracy,\n",
    "        \"acc_board\": board_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'baseline' has 1232 parameters.\n",
      "Model 'local_global' has 1342 parameters.\n",
      "Training model baseline...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.595740  [    4/  237]\n",
      "loss: 0.293449  [   84/  237]\n",
      "loss: 0.288356  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.4%, Board accuracy: 0.0%, Avg loss: 0.288916 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.260252  [    4/  237]\n",
      "loss: 0.260029  [   84/  237]\n",
      "loss: 0.272077  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.218866 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.242478  [    4/  237]\n",
      "loss: 0.118317  [   84/  237]\n",
      "loss: 0.092602  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Board accuracy: 0.0%, Avg loss: 0.106572 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.106475  [    4/  237]\n",
      "loss: 0.101227  [   84/  237]\n",
      "loss: 0.132749  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Board accuracy: 0.0%, Avg loss: 0.081486 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.071601  [    4/  237]\n",
      "loss: 0.058002  [   84/  237]\n",
      "loss: 0.074533  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Board accuracy: 0.0%, Avg loss: 0.072829 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.093624  [    4/  237]\n",
      "loss: 0.102935  [   84/  237]\n",
      "loss: 0.064427  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 0.0%, Avg loss: 0.065898 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.037339  [    4/  237]\n",
      "loss: 0.035213  [   84/  237]\n",
      "loss: 0.067655  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 0.0%, Avg loss: 0.061007 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.075470  [    4/  237]\n",
      "loss: 0.077311  [   84/  237]\n",
      "loss: 0.078078  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.054692 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.040290  [    4/  237]\n",
      "loss: 0.043787  [   84/  237]\n",
      "loss: 0.035808  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 0.0%, Avg loss: 0.050322 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.038226  [    4/  237]\n",
      "loss: 0.043528  [   84/  237]\n",
      "loss: 0.045989  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.045368 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.038919  [    4/  237]\n",
      "loss: 0.039856  [   84/  237]\n",
      "loss: 0.032126  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 21.1%, Avg loss: 0.037801 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.027121  [    4/  237]\n",
      "loss: 0.071864  [   84/  237]\n",
      "loss: 0.022638  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 21.7%, Avg loss: 0.034221 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.048988  [    4/  237]\n",
      "loss: 0.021560  [   84/  237]\n",
      "loss: 0.013836  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Board accuracy: 22.2%, Avg loss: 0.030342 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.026283  [    4/  237]\n",
      "loss: 0.042522  [   84/  237]\n",
      "loss: 0.020967  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Board accuracy: 34.4%, Avg loss: 0.026549 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.019713  [    4/  237]\n",
      "loss: 0.014873  [   84/  237]\n",
      "loss: 0.028144  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Board accuracy: 33.3%, Avg loss: 0.025069 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.033724  [    4/  237]\n",
      "loss: 0.019806  [   84/  237]\n",
      "loss: 0.028634  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 47.8%, Avg loss: 0.023885 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.020504  [    4/  237]\n",
      "loss: 0.024833  [   84/  237]\n",
      "loss: 0.049502  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 51.1%, Avg loss: 0.021485 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.019436  [    4/  237]\n",
      "loss: 0.016548  [   84/  237]\n",
      "loss: 0.018334  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 40.6%, Avg loss: 0.019689 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.019641  [    4/  237]\n",
      "loss: 0.033124  [   84/  237]\n",
      "loss: 0.020009  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 41.1%, Avg loss: 0.018193 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.032579  [    4/  237]\n",
      "loss: 0.036578  [   84/  237]\n",
      "loss: 0.023019  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 61.1%, Avg loss: 0.017794 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.008899  [    4/  237]\n",
      "loss: 0.013885  [   84/  237]\n",
      "loss: 0.010058  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 61.7%, Avg loss: 0.017270 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.021638  [    4/  237]\n",
      "loss: 0.012099  [   84/  237]\n",
      "loss: 0.030785  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 42.2%, Avg loss: 0.017159 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.044107  [    4/  237]\n",
      "loss: 0.011610  [   84/  237]\n",
      "loss: 0.017623  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 43.9%, Avg loss: 0.019093 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.027594  [    4/  237]\n",
      "loss: 0.041723  [   84/  237]\n",
      "loss: 0.007416  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 65.0%, Avg loss: 0.016839 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.011747  [    4/  237]\n",
      "loss: 0.013369  [   84/  237]\n",
      "loss: 0.014900  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 62.8%, Avg loss: 0.015518 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.022444  [    4/  237]\n",
      "loss: 0.012594  [   84/  237]\n",
      "loss: 0.014786  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 63.3%, Avg loss: 0.014787 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.007035  [    4/  237]\n",
      "loss: 0.042122  [   84/  237]\n",
      "loss: 0.044601  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 68.9%, Avg loss: 0.015203 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.039191  [    4/  237]\n",
      "loss: 0.012975  [   84/  237]\n",
      "loss: 0.009694  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 50.6%, Avg loss: 0.017784 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.005144  [    4/  237]\n",
      "loss: 0.006160  [   84/  237]\n",
      "loss: 0.042564  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 61.7%, Avg loss: 0.014818 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.009989  [    4/  237]\n",
      "loss: 0.009886  [   84/  237]\n",
      "loss: 0.007838  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 65.6%, Avg loss: 0.013974 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.036709  [    4/  237]\n",
      "loss: 0.004138  [   84/  237]\n",
      "loss: 0.006302  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 66.7%, Avg loss: 0.013820 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.005739  [    4/  237]\n",
      "loss: 0.016344  [   84/  237]\n",
      "loss: 0.005317  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 66.1%, Avg loss: 0.014058 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.011062  [    4/  237]\n",
      "loss: 0.010706  [   84/  237]\n",
      "loss: 0.011913  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.012357 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.005352  [    4/  237]\n",
      "loss: 0.005907  [   84/  237]\n",
      "loss: 0.007175  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 0.0%, Avg loss: 0.039538 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.036433  [    4/  237]\n",
      "loss: 0.003256  [   84/  237]\n",
      "loss: 0.009007  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 63.3%, Avg loss: 0.013665 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.060169  [    4/  237]\n",
      "loss: 0.014448  [   84/  237]\n",
      "loss: 0.008378  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.012218 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.003605  [    4/  237]\n",
      "loss: 0.004974  [   84/  237]\n",
      "loss: 0.029361  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 64.4%, Avg loss: 0.013799 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.006538  [    4/  237]\n",
      "loss: 0.003023  [   84/  237]\n",
      "loss: 0.004837  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.011828 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.006128  [    4/  237]\n",
      "loss: 0.009903  [   84/  237]\n",
      "loss: 0.005245  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.011279 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.027596  [    4/  237]\n",
      "loss: 0.007448  [   84/  237]\n",
      "loss: 0.002812  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 31.7%, Avg loss: 0.017837 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.015966  [    4/  237]\n",
      "loss: 0.003695  [   84/  237]\n",
      "loss: 0.006014  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.011297 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.004456  [    4/  237]\n",
      "loss: 0.005656  [   84/  237]\n",
      "loss: 0.011800  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 71.1%, Avg loss: 0.011642 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.008196  [    4/  237]\n",
      "loss: 0.004056  [   84/  237]\n",
      "loss: 0.010061  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 69.4%, Avg loss: 0.012562 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.024758  [    4/  237]\n",
      "loss: 0.004930  [   84/  237]\n",
      "loss: 0.005124  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.010695 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.003053  [    4/  237]\n",
      "loss: 0.006192  [   84/  237]\n",
      "loss: 0.010076  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.010649 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.033795  [    4/  237]\n",
      "loss: 0.015635  [   84/  237]\n",
      "loss: 0.003010  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.010909 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.030650  [    4/  237]\n",
      "loss: 0.005165  [   84/  237]\n",
      "loss: 0.003942  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.011732 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.002855  [    4/  237]\n",
      "loss: 0.005367  [   84/  237]\n",
      "loss: 0.003919  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 73.9%, Avg loss: 0.013508 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.012317  [    4/  237]\n",
      "loss: 0.004987  [   84/  237]\n",
      "loss: 0.023080  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.011629 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.001583  [    4/  237]\n",
      "loss: 0.002600  [   84/  237]\n",
      "loss: 0.003723  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.010099 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.003947  [    4/  237]\n",
      "loss: 0.002501  [   84/  237]\n",
      "loss: 0.006618  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.010372 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.003315  [    4/  237]\n",
      "loss: 0.002414  [   84/  237]\n",
      "loss: 0.003091  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Board accuracy: 27.2%, Avg loss: 0.019180 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.013479  [    4/  237]\n",
      "loss: 0.005341  [   84/  237]\n",
      "loss: 0.002430  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.010163 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.004089  [    4/  237]\n",
      "loss: 0.002590  [   84/  237]\n",
      "loss: 0.026263  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.7%, Avg loss: 0.011324 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.032207  [    4/  237]\n",
      "loss: 0.004991  [   84/  237]\n",
      "loss: 0.001508  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.2%, Avg loss: 0.012133 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.005951  [    4/  237]\n",
      "loss: 0.006329  [   84/  237]\n",
      "loss: 0.003369  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.010238 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.001413  [    4/  237]\n",
      "loss: 0.003246  [   84/  237]\n",
      "loss: 0.001933  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.010062 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.004150  [    4/  237]\n",
      "loss: 0.025622  [   84/  237]\n",
      "loss: 0.008436  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 73.9%, Avg loss: 0.011514 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.001950  [    4/  237]\n",
      "loss: 0.003829  [   84/  237]\n",
      "loss: 0.005391  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Board accuracy: 0.0%, Avg loss: 0.123806 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.150788  [    4/  237]\n",
      "loss: 0.004734  [   84/  237]\n",
      "loss: 0.029416  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 74.4%, Avg loss: 0.011490 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.002204  [    4/  237]\n",
      "loss: 0.002475  [   84/  237]\n",
      "loss: 0.007112  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.011009 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.002379  [    4/  237]\n",
      "loss: 0.021164  [   84/  237]\n",
      "loss: 0.002228  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.010447 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.002805  [    4/  237]\n",
      "loss: 0.003308  [   84/  237]\n",
      "loss: 0.007538  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.010934 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.007984  [    4/  237]\n",
      "loss: 0.005633  [   84/  237]\n",
      "loss: 0.001051  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.010139 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.003381  [    4/  237]\n",
      "loss: 0.001587  [   84/  237]\n",
      "loss: 0.004302  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.070710 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.066464  [    4/  237]\n",
      "loss: 0.005093  [   84/  237]\n",
      "loss: 0.023809  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.010404 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.023012  [    4/  237]\n",
      "loss: 0.010532  [   84/  237]\n",
      "loss: 0.022193  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.010816 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.002493  [    4/  237]\n",
      "loss: 0.001628  [   84/  237]\n",
      "loss: 0.001274  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.010233 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.001354  [    4/  237]\n",
      "loss: 0.001836  [   84/  237]\n",
      "loss: 0.000485  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.012125 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.002700  [    4/  237]\n",
      "loss: 0.026472  [   84/  237]\n",
      "loss: 0.002161  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.010725 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.001201  [    4/  237]\n",
      "loss: 0.020808  [   84/  237]\n",
      "loss: 0.002379  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.6%, Avg loss: 0.011241 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.001543  [    4/  237]\n",
      "loss: 0.020793  [   84/  237]\n",
      "loss: 0.001223  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.009163 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.001314  [    4/  237]\n",
      "loss: 0.002633  [   84/  237]\n",
      "loss: 0.002055  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.008937 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.003163  [    4/  237]\n",
      "loss: 0.023159  [   84/  237]\n",
      "loss: 0.002348  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009738 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.018305  [    4/  237]\n",
      "loss: 0.000926  [   84/  237]\n",
      "loss: 0.004212  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.009591 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.004137  [    4/  237]\n",
      "loss: 0.009121  [   84/  237]\n",
      "loss: 0.003767  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.009786 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.002657  [    4/  237]\n",
      "loss: 0.003934  [   84/  237]\n",
      "loss: 0.001770  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009979 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.001134  [    4/  237]\n",
      "loss: 0.002439  [   84/  237]\n",
      "loss: 0.002265  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009726 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.001045  [    4/  237]\n",
      "loss: 0.002271  [   84/  237]\n",
      "loss: 0.001407  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009500 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.001925  [    4/  237]\n",
      "loss: 0.001177  [   84/  237]\n",
      "loss: 0.000941  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.009403 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.001598  [    4/  237]\n",
      "loss: 0.001691  [   84/  237]\n",
      "loss: 0.001139  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009725 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.000817  [    4/  237]\n",
      "loss: 0.005242  [   84/  237]\n",
      "loss: 0.001659  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.010062 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.033129  [    4/  237]\n",
      "loss: 0.002390  [   84/  237]\n",
      "loss: 0.001729  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.009892 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.001119  [    4/  237]\n",
      "loss: 0.003162  [   84/  237]\n",
      "loss: 0.001464  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009249 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.001513  [    4/  237]\n",
      "loss: 0.025809  [   84/  237]\n",
      "loss: 0.001070  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009944 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.000788  [    4/  237]\n",
      "loss: 0.003510  [   84/  237]\n",
      "loss: 0.000771  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.008864 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.001231  [    4/  237]\n",
      "loss: 0.000922  [   84/  237]\n",
      "loss: 0.002386  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.009422 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.003249  [    4/  237]\n",
      "loss: 0.004534  [   84/  237]\n",
      "loss: 0.000974  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.010879 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.005567  [    4/  237]\n",
      "loss: 0.000746  [   84/  237]\n",
      "loss: 0.000528  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009575 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.000512  [    4/  237]\n",
      "loss: 0.006069  [   84/  237]\n",
      "loss: 0.049287  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.010703 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.000388  [    4/  237]\n",
      "loss: 0.001172  [   84/  237]\n",
      "loss: 0.014616  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009544 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.001564  [    4/  237]\n",
      "loss: 0.001247  [   84/  237]\n",
      "loss: 0.028405  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 94.6%, Board accuracy: 0.0%, Avg loss: 0.123086 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.137760  [    4/  237]\n",
      "loss: 0.000806  [   84/  237]\n",
      "loss: 0.002211  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.8%, Avg loss: 0.009783 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.002590  [    4/  237]\n",
      "loss: 0.001815  [   84/  237]\n",
      "loss: 0.020382  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.6%, Avg loss: 0.010078 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.003009  [    4/  237]\n",
      "loss: 0.003164  [   84/  237]\n",
      "loss: 0.000664  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.009108 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.001934  [    4/  237]\n",
      "loss: 0.001315  [   84/  237]\n",
      "loss: 0.005113  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.008672 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.039697  [    4/  237]\n",
      "loss: 0.001336  [   84/  237]\n",
      "loss: 0.002526  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.8%, Avg loss: 0.009500 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.002514  [    4/  237]\n",
      "loss: 0.001912  [   84/  237]\n",
      "loss: 0.001206  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.008400 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.000933  [    4/  237]\n",
      "loss: 0.000680  [   84/  237]\n",
      "loss: 0.024121  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.008939 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.002838  [    4/  237]\n",
      "loss: 0.003307  [   84/  237]\n",
      "loss: 0.001906  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.9%, Avg loss: 0.010722 \n",
      "\n",
      "Done!\n",
      "Training model local_global...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.697639  [    4/  237]\n",
      "loss: 0.332743  [   84/  237]\n",
      "loss: 0.296485  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.296814 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.388763  [    4/  237]\n",
      "loss: 0.262773  [   84/  237]\n",
      "loss: 0.400102  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.295533 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.248062  [    4/  237]\n",
      "loss: 0.353822  [   84/  237]\n",
      "loss: 0.248580  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.293298 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.223793  [    4/  237]\n",
      "loss: 0.255898  [   84/  237]\n",
      "loss: 0.365626  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.278899 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.256743  [    4/  237]\n",
      "loss: 0.323390  [   84/  237]\n",
      "loss: 0.237373  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.210446 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.179395  [    4/  237]\n",
      "loss: 0.172279  [   84/  237]\n",
      "loss: 0.134170  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.123594 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.130596  [    4/  237]\n",
      "loss: 0.072713  [   84/  237]\n",
      "loss: 0.101841  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Board accuracy: 0.0%, Avg loss: 0.084077 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.119276  [    4/  237]\n",
      "loss: 0.073990  [   84/  237]\n",
      "loss: 0.081624  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Board accuracy: 0.0%, Avg loss: 0.077386 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.040281  [    4/  237]\n",
      "loss: 0.033671  [   84/  237]\n",
      "loss: 0.037819  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Board accuracy: 0.0%, Avg loss: 0.071671 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.046974  [    4/  237]\n",
      "loss: 0.081281  [   84/  237]\n",
      "loss: 0.086843  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 0.0%, Avg loss: 0.069047 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.030987  [    4/  237]\n",
      "loss: 0.026623  [   84/  237]\n",
      "loss: 0.045186  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 0.0%, Avg loss: 0.066605 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.058549  [    4/  237]\n",
      "loss: 0.112950  [   84/  237]\n",
      "loss: 0.035118  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 0.0%, Avg loss: 0.062940 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.032766  [    4/  237]\n",
      "loss: 0.040861  [   84/  237]\n",
      "loss: 0.091332  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 0.0%, Avg loss: 0.054909 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.045020  [    4/  237]\n",
      "loss: 0.053517  [   84/  237]\n",
      "loss: 0.066100  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 18.9%, Avg loss: 0.047059 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.026185  [    4/  237]\n",
      "loss: 0.029913  [   84/  237]\n",
      "loss: 0.040548  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 13.3%, Avg loss: 0.043754 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.029339  [    4/  237]\n",
      "loss: 0.032593  [   84/  237]\n",
      "loss: 0.063103  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 30.6%, Avg loss: 0.037214 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.035847  [    4/  237]\n",
      "loss: 0.030627  [   84/  237]\n",
      "loss: 0.026432  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 5.0%, Avg loss: 0.038736 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.034261  [    4/  237]\n",
      "loss: 0.034514  [   84/  237]\n",
      "loss: 0.020403  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 53.9%, Avg loss: 0.029580 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.049586  [    4/  237]\n",
      "loss: 0.018537  [   84/  237]\n",
      "loss: 0.055969  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 57.8%, Avg loss: 0.027832 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.011438  [    4/  237]\n",
      "loss: 0.020532  [   84/  237]\n",
      "loss: 0.031553  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 57.8%, Avg loss: 0.024836 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.012552  [    4/  237]\n",
      "loss: 0.011784  [   84/  237]\n",
      "loss: 0.007278  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 61.1%, Avg loss: 0.023475 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.008464  [    4/  237]\n",
      "loss: 0.007303  [   84/  237]\n",
      "loss: 0.008116  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 63.3%, Avg loss: 0.022019 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.014900  [    4/  237]\n",
      "loss: 0.048088  [   84/  237]\n",
      "loss: 0.016292  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 60.6%, Avg loss: 0.021797 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.022342  [    4/  237]\n",
      "loss: 0.008016  [   84/  237]\n",
      "loss: 0.014309  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 65.0%, Avg loss: 0.020398 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.003750  [    4/  237]\n",
      "loss: 0.006990  [   84/  237]\n",
      "loss: 0.017283  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 71.1%, Avg loss: 0.019460 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.011437  [    4/  237]\n",
      "loss: 0.050633  [   84/  237]\n",
      "loss: 0.024940  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.019366 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.013995  [    4/  237]\n",
      "loss: 0.006981  [   84/  237]\n",
      "loss: 0.005274  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 43.3%, Avg loss: 0.021421 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.013094  [    4/  237]\n",
      "loss: 0.019345  [   84/  237]\n",
      "loss: 0.051151  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.018542 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.035300  [    4/  237]\n",
      "loss: 0.007781  [   84/  237]\n",
      "loss: 0.006564  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 74.4%, Avg loss: 0.018158 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.044779  [    4/  237]\n",
      "loss: 0.009153  [   84/  237]\n",
      "loss: 0.012701  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.016978 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.006007  [    4/  237]\n",
      "loss: 0.012237  [   84/  237]\n",
      "loss: 0.005999  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 68.3%, Avg loss: 0.016609 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.013109  [    4/  237]\n",
      "loss: 0.007408  [   84/  237]\n",
      "loss: 0.004753  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.7%, Avg loss: 0.017090 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.012826  [    4/  237]\n",
      "loss: 0.013309  [   84/  237]\n",
      "loss: 0.006010  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 75.6%, Avg loss: 0.015976 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.005294  [    4/  237]\n",
      "loss: 0.003998  [   84/  237]\n",
      "loss: 0.068246  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.015352 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.013334  [    4/  237]\n",
      "loss: 0.006711  [   84/  237]\n",
      "loss: 0.006505  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.1%, Avg loss: 0.016265 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.007323  [    4/  237]\n",
      "loss: 0.005291  [   84/  237]\n",
      "loss: 0.010745  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.016306 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.003199  [    4/  237]\n",
      "loss: 0.040270  [   84/  237]\n",
      "loss: 0.006204  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.7%, Avg loss: 0.015335 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.003285  [    4/  237]\n",
      "loss: 0.006007  [   84/  237]\n",
      "loss: 0.039830  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.014644 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.007864  [    4/  237]\n",
      "loss: 0.005327  [   84/  237]\n",
      "loss: 0.002069  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.015164 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.008101  [    4/  237]\n",
      "loss: 0.006586  [   84/  237]\n",
      "loss: 0.038840  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.014798 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.006684  [    4/  237]\n",
      "loss: 0.003048  [   84/  237]\n",
      "loss: 0.003307  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.015089 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.003431  [    4/  237]\n",
      "loss: 0.023856  [   84/  237]\n",
      "loss: 0.002211  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.014766 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.005847  [    4/  237]\n",
      "loss: 0.003929  [   84/  237]\n",
      "loss: 0.003666  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.014220 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.002948  [    4/  237]\n",
      "loss: 0.006043  [   84/  237]\n",
      "loss: 0.005644  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.015039 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.004195  [    4/  237]\n",
      "loss: 0.004167  [   84/  237]\n",
      "loss: 0.004698  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.015059 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.002350  [    4/  237]\n",
      "loss: 0.001949  [   84/  237]\n",
      "loss: 0.004248  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.2%, Avg loss: 0.014741 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.002717  [    4/  237]\n",
      "loss: 0.004584  [   84/  237]\n",
      "loss: 0.005184  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.013213 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.035330  [    4/  237]\n",
      "loss: 0.007231  [   84/  237]\n",
      "loss: 0.003337  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 71.7%, Avg loss: 0.015275 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.003590  [    4/  237]\n",
      "loss: 0.012919  [   84/  237]\n",
      "loss: 0.038468  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.013200 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.004346  [    4/  237]\n",
      "loss: 0.001856  [   84/  237]\n",
      "loss: 0.032966  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.013230 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.007539  [    4/  237]\n",
      "loss: 0.004538  [   84/  237]\n",
      "loss: 0.035835  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.013037 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.019502  [    4/  237]\n",
      "loss: 0.005451  [   84/  237]\n",
      "loss: 0.002098  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.013723 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.003268  [    4/  237]\n",
      "loss: 0.002992  [   84/  237]\n",
      "loss: 0.003011  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.013078 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.003702  [    4/  237]\n",
      "loss: 0.001902  [   84/  237]\n",
      "loss: 0.013917  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.013411 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.003451  [    4/  237]\n",
      "loss: 0.023560  [   84/  237]\n",
      "loss: 0.002514  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.013144 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.027937  [    4/  237]\n",
      "loss: 0.012695  [   84/  237]\n",
      "loss: 0.003594  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.013073 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.002152  [    4/  237]\n",
      "loss: 0.004556  [   84/  237]\n",
      "loss: 0.005690  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.013052 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.004804  [    4/  237]\n",
      "loss: 0.004227  [   84/  237]\n",
      "loss: 0.007531  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.012138 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.001557  [    4/  237]\n",
      "loss: 0.002288  [   84/  237]\n",
      "loss: 0.001058  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.6%, Avg loss: 0.013078 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.004156  [    4/  237]\n",
      "loss: 0.002379  [   84/  237]\n",
      "loss: 0.006922  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.012432 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.032859  [    4/  237]\n",
      "loss: 0.040350  [   84/  237]\n",
      "loss: 0.004776  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.012983 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.001736  [    4/  237]\n",
      "loss: 0.001914  [   84/  237]\n",
      "loss: 0.004444  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.012576 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.001362  [    4/  237]\n",
      "loss: 0.035942  [   84/  237]\n",
      "loss: 0.003910  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.012820 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.002159  [    4/  237]\n",
      "loss: 0.026193  [   84/  237]\n",
      "loss: 0.003852  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.011181 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.002246  [    4/  237]\n",
      "loss: 0.026092  [   84/  237]\n",
      "loss: 0.019953  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.012361 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.003034  [    4/  237]\n",
      "loss: 0.009647  [   84/  237]\n",
      "loss: 0.041973  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.013388 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.032795  [    4/  237]\n",
      "loss: 0.002937  [   84/  237]\n",
      "loss: 0.003280  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.011894 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.006428  [    4/  237]\n",
      "loss: 0.004914  [   84/  237]\n",
      "loss: 0.002580  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 62.8%, Avg loss: 0.015412 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.011520  [    4/  237]\n",
      "loss: 0.005273  [   84/  237]\n",
      "loss: 0.001835  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011172 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.006742  [    4/  237]\n",
      "loss: 0.003679  [   84/  237]\n",
      "loss: 0.006147  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011163 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.008002  [    4/  237]\n",
      "loss: 0.002637  [   84/  237]\n",
      "loss: 0.001652  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.011064 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.004595  [    4/  237]\n",
      "loss: 0.006764  [   84/  237]\n",
      "loss: 0.001976  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011836 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.000843  [    4/  237]\n",
      "loss: 0.035090  [   84/  237]\n",
      "loss: 0.023522  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.011566 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.001240  [    4/  237]\n",
      "loss: 0.001678  [   84/  237]\n",
      "loss: 0.005175  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011220 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.001015  [    4/  237]\n",
      "loss: 0.001152  [   84/  237]\n",
      "loss: 0.025196  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.010064 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.002439  [    4/  237]\n",
      "loss: 0.001739  [   84/  237]\n",
      "loss: 0.005455  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.010465 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.028957  [    4/  237]\n",
      "loss: 0.021095  [   84/  237]\n",
      "loss: 0.002077  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.011912 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.060437  [    4/  237]\n",
      "loss: 0.003750  [   84/  237]\n",
      "loss: 0.002221  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.010704 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.003875  [    4/  237]\n",
      "loss: 0.001965  [   84/  237]\n",
      "loss: 0.001060  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.9%, Avg loss: 0.011329 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.003437  [    4/  237]\n",
      "loss: 0.031685  [   84/  237]\n",
      "loss: 0.001516  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 17.2%, Avg loss: 0.039082 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.043801  [    4/  237]\n",
      "loss: 0.002701  [   84/  237]\n",
      "loss: 0.002101  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010591 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.002553  [    4/  237]\n",
      "loss: 0.003081  [   84/  237]\n",
      "loss: 0.001693  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.010804 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.018666  [    4/  237]\n",
      "loss: 0.002085  [   84/  237]\n",
      "loss: 0.019949  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010585 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.001644  [    4/  237]\n",
      "loss: 0.032958  [   84/  237]\n",
      "loss: 0.004410  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009987 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.001499  [    4/  237]\n",
      "loss: 0.006123  [   84/  237]\n",
      "loss: 0.002314  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.011366 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.000830  [    4/  237]\n",
      "loss: 0.004868  [   84/  237]\n",
      "loss: 0.002100  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010497 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.005115  [    4/  237]\n",
      "loss: 0.002126  [   84/  237]\n",
      "loss: 0.002883  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.009951 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.002336  [    4/  237]\n",
      "loss: 0.009609  [   84/  237]\n",
      "loss: 0.023123  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011515 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.000928  [    4/  237]\n",
      "loss: 0.011287  [   84/  237]\n",
      "loss: 0.005318  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010052 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.000933  [    4/  237]\n",
      "loss: 0.001238  [   84/  237]\n",
      "loss: 0.001200  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009514 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.001680  [    4/  237]\n",
      "loss: 0.000969  [   84/  237]\n",
      "loss: 0.020485  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.010326 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.001029  [    4/  237]\n",
      "loss: 0.000533  [   84/  237]\n",
      "loss: 0.001900  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009660 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.002036  [    4/  237]\n",
      "loss: 0.005435  [   84/  237]\n",
      "loss: 0.001918  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.010643 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.002206  [    4/  237]\n",
      "loss: 0.019429  [   84/  237]\n",
      "loss: 0.001513  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.009948 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.005830  [    4/  237]\n",
      "loss: 0.002858  [   84/  237]\n",
      "loss: 0.002845  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.035980 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.049232  [    4/  237]\n",
      "loss: 0.002593  [   84/  237]\n",
      "loss: 0.001212  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.010931 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.001199  [    4/  237]\n",
      "loss: 0.002860  [   84/  237]\n",
      "loss: 0.018884  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.009010 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.002320  [    4/  237]\n",
      "loss: 0.003583  [   84/  237]\n",
      "loss: 0.002233  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.010780 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.001915  [    4/  237]\n",
      "loss: 0.001086  [   84/  237]\n",
      "loss: 0.002334  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.010959 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.001216  [    4/  237]\n",
      "loss: 0.002400  [   84/  237]\n",
      "loss: 0.003373  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.009836 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-1\n",
    "epochs = 100\n",
    "\n",
    "models = {\n",
    "    \"baseline\": TetrisModel().to(device),\n",
    "    \"local_global\": LocalGlobalModel().to(device)\n",
    "}\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Model '{name}' has {count_parameters(model)} parameters.\")\n",
    "\n",
    "log_dir = os.path.join(\"runs\", \"experiment_009\")\n",
    "# shutil.rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "for name, model in models.items():\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_subdir = os.path.join(log_dir, name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb = SummaryWriter(log_subdir)\n",
    "\n",
    "    print(f\"Training model {name}...\")\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        train_metrics = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_metrics = test_loop(test_dataloader, model, loss_fn)\n",
    "        tb.add_scalar(\"Loss/train\", train_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Cell accuracy/train\", train_metrics[\"acc\"], t)\n",
    "        tb.add_scalar(\"Board accuracy/train\", train_metrics[\"acc_board\"], t)\n",
    "        tb.add_scalar(\"Loss/test\", test_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Cell accuracy/test\", test_metrics[\"acc\"], t)\n",
    "        tb.add_scalar(\"Board accuracy/test\", test_metrics[\"acc_board\"], t)\n",
    "        for name, weight in model.named_parameters():\n",
    "            tb.add_histogram(f\"Weights/{name}\", weight, t)\n",
    "            tb.add_histogram(f\"Gradients/{name}\", weight.grad, t)\n",
    "\n",
    "    tb.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(example):\n",
    "    x, y = example\n",
    "    with torch.no_grad():\n",
    "        pred_baseline = models[\"baseline\"](x.unsqueeze(0)).argmax(dim=1).squeeze(0)\n",
    "        pred_local_global = models[\"local_global\"](x.unsqueeze(0)).argmax(dim=1).squeeze(0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4)\n",
    "    fig.suptitle(\"Prediction vs reality\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].set_title(\"Reality\")\n",
    "    axs[2].set_title(\"baseline\")\n",
    "    axs[3].set_title(\"local_global\")\n",
    "\n",
    "    axs[0].imshow(x)\n",
    "    axs[1].imshow(y)\n",
    "    axs[2].imshow(pred_baseline)\n",
    "    axs[3].imshow(pred_local_global)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 167\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAFzCAYAAABBzRFyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnFklEQVR4nO3de3xNZ6L/8e/O/YqEHYI0N1Wty9GJQSskKoQgE+NSUy3htM2gbh016jUzRDv10lGiaKqmDa3UED1VHB2VGc4hbbSdosXQlDBIB3GJa6JJnt8fTtbPliDRkCY+79fL62U/e631PGuvZ6393Ws9a8VmjDECAAD3NKeabgAAAKh5BAIAAEAgAAAABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCIBKCQkJUWJiovV6y5Ytstls2rJlS7XVYbPZNGPGjGpb3r0oOjpa0dHR1utDhw7JZrNp6dKlNdYmoLYgEOAnb+nSpbLZbNY/Dw8PtWzZUs8995yOHz9e082rkg0bNvClX8PYBkDFXGq6AUBlzZw5U6GhoSosLNS2bduUmpqqDRs2aPfu3fLy8rqrbenWrZsuX74sNze3Ks23YcMGLVq0qMIvpMuXL8vFhV2yOgUHB+vy5ctydXW1ym62DYB7GUcf1Bp9+vRRhw4dJElPP/20GjZsqLlz5+qjjz7Sr371qwrnuXjxory9vau9LU5OTvLw8KjWZVb38n7KLl26dFdCXNkZJQC3xiUD1FqPPfaYJCk3N1eSlJiYKB8fHx04cEBxcXHy9fXVsGHDJEmlpaVKSUlR69at5eHhocaNGyspKUlnzpxxWKYxRi+//LKaN28uLy8vde/eXXv27ClX943GEGzfvl1xcXHy8/OTt7e32rVrp/nz51vtW7RokSQ5XAIpU9EYgh07dqhPnz6qV6+efHx81KNHD2VnZztMU3ZJJSsrS88//7zsdru8vb01YMAAnTx58qaf4Zw5c2Sz2XT48OFy77344otyc3OzPqOcnBwNHDhQTZo0kYeHh5o3b66hQ4eqoKDgpnVER0erTZs2+sc//qFu3brJy8tL06ZNkyQVFRVp+vTpatGihdzd3RUUFKQpU6aoqKjIYRlpaWl67LHHFBAQIHd3dz300ENKTU29ab1S+TEEN9oGxhiFhIToF7/4RbllFBYWqn79+kpKSrplfUBtxhkC1FoHDhyQJDVs2NAqKy4uVmxsrCIjIzVnzhzrV2hSUpKWLl2qkSNHavz48crNzdXChQu1Y8cOZWVlWaeU//CHP+jll19WXFyc4uLi9NVXX6lXr166cuXKLduzadMm9evXT4GBgZowYYKaNGmif/7zn1q/fr0mTJigpKQk5eXladOmTXrvvfduubw9e/aoa9euqlevnqZMmSJXV1ctXrxY0dHR+p//+R916tTJYfpx48bJz89P06dP16FDh5SSkqLnnntOK1euvGEdQ4YM0ZQpU7Rq1Sq98MILDu+tWrVKvXr1kp+fn65cuaLY2FgVFRVp3LhxatKkiY4dO6b169fr7Nmzql+//k3X5dSpU+rTp4+GDh2qJ598Uo0bN1Zpaani4+O1bds2Pfvss3rwwQf1zTffaN68efr222+1Zs0aa/7U1FS1bt1a8fHxcnFx0bp16zRmzBiVlpZq7Nixt/wsy9xoG9hsNj355JN69dVXdfr0afn7+1vvrVu3TufOndOTTz5Z6XqAWskAP3FpaWlGksnMzDQnT540R44cMX/5y19Mw4YNjaenpzl69KgxxpgRI0YYSWbq1KkO82/dutVIMunp6Q7lf/3rXx3KT5w4Ydzc3Ezfvn1NaWmpNd20adOMJDNixAirbPPmzUaS2bx5szHGmOLiYhMaGmqCg4PNmTNnHOq5dlljx441N9rtJJnp06dbrxMSEoybm5s5cOCAVZaXl2d8fX1Nt27dyn0+MTExDnVNmjTJODs7m7Nnz1ZYX5lHHnnEREREOJR9/vnnRpJ59913jTHG7Nixw0gyGRkZN11WRaKioowk8+abbzqUv/fee8bJycls3brVofzNN980kkxWVpZVdunSpXLLjY2NNWFhYeXqioqKsl7n5uYaSSYtLc0qu9E22L9/v5FkUlNTHcrj4+NNSEiIw2cL1EVcMkCtERMTI7vdrqCgIA0dOlQ+Pj768MMP1axZM4fpRo8e7fA6IyND9evXV8+ePZWfn2/9i4iIkI+PjzZv3ixJyszM1JUrVzRu3DiHU/kTJ068Zdt27Nih3NxcTZw4UQ0aNHB479plVVZJSYk++eQTJSQkKCwszCoPDAzUE088oW3btuncuXMO8zz77LMOdXXt2lUlJSUVXg641uOPP65//OMf1hkXSVq5cqXc3d2tU+hlZwA2btyoS5cuVXl93N3dNXLkSIeyjIwMPfjgg2rVqpXDdim7FFS2XSTJ09PT+n9BQYHy8/MVFRWlgwcP3vKSRWW1bNlSnTp1Unp6ulV2+vRpffzxxxo2bNhtbUegNiEQoNZYtGiRNm3apM2bN2vv3r06ePCgYmNjHaZxcXFR8+bNHcpycnJUUFCggIAA2e12h38XLlzQiRMnJMn64rz//vsd5rfb7fLz87tp28q+TNu0afOj1rHMyZMndenSJT3wwAPl3nvwwQdVWlqqI0eOOJTfd999Dq/L2nz9OInrDR48WE5OTtalBWOMMjIyrLELkhQaGqrnn39ef/7zn9WoUSPFxsZq0aJFlf4ybtasWbk7MnJycrRnz55y26Rly5aSZG0XScrKylJMTIy8vb3VoEED2e12axxCdQUCSRo+fLiysrKsvpCRkaEffvhBTz31VLXVAfxUMYYAtUbHjh2tuwxuxN3dXU5Ojjm3tLRUAQEBDr/8rmW326utjTXJ2dm5wnJjzE3na9q0qbp27apVq1Zp2rRpys7O1r/+9S/Nnj3bYbrXXntNiYmJ+uijj/TJJ59o/PjxmjVrlrKzs8uFsOtd+wu/TGlpqdq2bau5c+dWOE9QUJCkq2GrR48eatWqlebOnaugoCC5ublpw4YNmjdvnkpLS29ad1UMHTpUkyZNUnp6uqZNm6bly5erQ4cOFQYzoK4hEKDOCw8PV2Zmprp06VLhF1OZ4OBgSVd/uV57mv7kyZO3/JUdHh4uSdq9e7diYmJuOF1lTzvb7XZ5eXlp//795d7bt2+fnJycrC/M6vD4449rzJgx2r9/v1auXCkvLy/179+/3HRt27ZV27Zt9bvf/U6ffvqpunTpojfffFMvv/xylesMDw/Xrl271KNHj5t+LuvWrVNRUZHWrl3rcBbk2ksKVXGzuvz9/dW3b1+lp6dr2LBhysrKUkpKym3VA9Q2XDJAnTdkyBCVlJTopZdeKvdecXGxzp49K+nqGAVXV1ctWLDA4Vd1Zb4Qfvaznyk0NFQpKSnW8spcu6yyZyJcP831nJ2d1atXL3300Uc6dOiQVX78+HG9//77ioyMtE7nV4eBAwfK2dlZK1asUEZGhvr16+fw/IZz586puLjYYZ62bdvKycmp3C2ClTVkyBAdO3ZMS5YsKffe5cuXdfHiRUn//8zHtZ9jQUGB0tLSbqveW22Dp556Snv37tULL7wgZ2dnDR069LbqAWobzhCgzouKilJSUpJmzZqlnTt3qlevXnJ1dVVOTo4yMjI0f/58DRo0SHa7XZMnT9asWbPUr18/xcXFaceOHfr444/VqFGjm9bh5OSk1NRU9e/fX+3bt9fIkSMVGBioffv2ac+ePdq4caMkKSIiQpI0fvx4xcbG3vQL5+WXX9amTZsUGRmpMWPGyMXFRYsXL1ZRUZFeffXVav2MAgIC1L17d82dO1fnz5/X448/7vD+3//+dz333HMaPHiwWrZsqeLiYr333ntydnbWwIEDb6vOp556SqtWrdKvf/1rbd68WV26dFFJSYn27dunVatWaePGjerQoYN69eolNzc39e/fX0lJSbpw4YKWLFmigIAAff/991Wu91bboG/fvmrYsKE1jiIgIOC21g+odWr0HgegEspuq/viiy9uOt2IESOMt7f3Dd9/6623TEREhPH09DS+vr6mbdu2ZsqUKSYvL8+apqSkxCQnJ5vAwEDj6elpoqOjze7du01wcPBNbzsss23bNtOzZ0/j6+trvL29Tbt27cyCBQus94uLi824ceOM3W43NpvN4fY3XXfboTHGfPXVVyY2Ntb4+PgYLy8v0717d/Ppp59W6vO5URtvZMmSJUaS8fX1NZcvX3Z47+DBg2bUqFEmPDzceHh4GH9/f9O9e3eTmZl5y+VGRUWZ1q1bV/jelStXzOzZs03r1q2Nu7u78fPzMxERESY5OdkUFBRY061du9a0a9fOeHh4mJCQEDN79mzzzjvvGEkmNzfXoa5b3XZ4s21QZsyYMUaSef/992+5fkBdYTPmFiOOAOAeM2nSJL399tv697//fdf/TgZQUxhDAADXKCws1PLlyzVw4EDCAO4pjCEAAF197kFmZqZWr16tU6dOacKECTXdJOCuIhAAgKS9e/dq2LBhCggI0Ouvv6727dvXdJOAu4oxBAAAgDEEAACAQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAA4OHTokGw2m5YuXWqVzZgxQzabreYaVceVfb75+fk13ZRyoqOjFR0dbb2uqH/A0dKlS2Wz2XTo0KE624aQkBAlJiZWeb4tW7bIZrNp9erV1daW6jw+1bpAULahv/zyy5puii5duqQZM2Zoy5YtNd2UOqdsO5f9c3FxUbNmzZSYmKhjx47VdPP0yiuvaM2aNTXdDACoNi413YDa7NKlS0pOTpYkh18RqD4zZ85UaGioCgsLlZ2draVLl2rbtm3avXu3PDw87kobfve732nq1KkOZa+88ooGDRqkhISEu9IG/DQEBwfr8uXLcnV1remmANWOQICftD59+qhDhw6SpKefflqNGjXS7NmztXbtWg0ZMuSutMHFxUUuLuwqkGw2210LosDdVusuGVwvMTFRPj4+OnbsmBISEuTj4yO73a7JkyerpKTEmq7s2t+cOXM0b948BQcHy9PTU1FRUdq9e7fDMq+/bnhtXSEhIdby7Ha7JCk5Odk6tT1jxow7taqQ1LVrV0nSgQMHrLJ9+/Zp0KBB8vf3l4eHhzp06KC1a9c6zHf69GlNnjxZbdu2lY+Pj+rVq6c+ffpo165dt6zz+mt0NptNFy9e1LJly6ztnpiYqM2bN8tms+nDDz8st4z3339fNptNn3322e2uep2Xn5+vIUOGqF69emrYsKEmTJigwsJC6/20tDQ99thjCggIkLu7ux566CGlpqaWW86XX36p2NhYNWrUSJ6engoNDdWoUaMcpiktLVVKSopat24tDw8PNW7cWElJSTpz5sxN21jRGILKHoN+TL213RtvvKHWrVvL3d1dTZs21dixY3X27Nly023fvl1xcXHy8/OTt7e32rVrp/nz51vvf/3110pMTFRYWJg8PDzUpEkTjRo1SqdOnaqWdm7ZskUdOnSQh4eHwsPDtXjx4kpfoz948KAGDx4sf39/eXl5qXPnzvrv//7vCqctKSnRtGnT1KRJE3l7eys+Pl5HjhxxmGbr1q0aPHiw7rvvPrm7uysoKEiTJk3S5cuXq2VdK1InfvaUlJQoNjZWnTp10pw5c5SZmanXXntN4eHhGj16tMO07777rs6fP6+xY8eqsLBQ8+fP12OPPaZvvvlGjRs3rnSddrtdqampGj16tAYMGKBf/vKXkqR27dpV67rBUdkgIT8/P0nSnj171KVLFzVr1kxTp06Vt7e3Vq1apYSEBH3wwQcaMGCApKs765o1azR48GCFhobq+PHjWrx4saKiorR37141bdq00m1477339PTTT6tjx4569tlnJUnh4eHq3LmzgoKClJ6ebtVbJj09XeHh4XrkkUeq4VOom4YMGaKQkBDNmjVL2dnZev3113XmzBm9++67kqTU1FS1bt1a8fHxcnFx0bp16zRmzBiVlpZq7NixkqQTJ06oV69estvtmjp1qho0aKBDhw7pv/7rvxzqSkpK0tKlSzVy5EiNHz9eubm5WrhwoXbs2KGsrKwqXxKo7DGouuutDWbMmKHk5GTFxMRo9OjR2r9/v1JTU/XFF184rPOmTZvUr18/BQYGasKECWrSpIn++c9/av369ZowYYI1zcGDBzVy5Eg1adJEe/bs0VtvvaU9e/YoOzv7Rw2u27Fjh3r37q3AwEAlJyerpKREM2fOtH743czx48f16KOP6tKlSxo/frwaNmyoZcuWKT4+XqtXry53PPjjH/8om82m3/72tzpx4oRSUlIUExOjnTt3ytPTU5KUkZGhS5cuafTo0WrYsKE+//xzLViwQEePHlVGRsZtr+dNmVomLS3NSDJffPGFMcaYESNGGElm5syZDtM9/PDDJiIiwnqdm5trJBlPT09z9OhRq3z79u1Gkpk0aZJVFhUVZaKiosrVPWLECBMcHGy9PnnypJFkpk+fXj0rB0vZds7MzDQnT540R44cMatXrzZ2u924u7ubI0eOGGOM6dGjh2nbtq0pLCy05i0tLTWPPvqouf/++62ywsJCU1JS4lBHbm6ucXd3d+g7Zf0kLS3NKps+fbq5flfx9vY2I0aMKNfuF1980bi7u5uzZ89aZSdOnDAuLi70kxso+3zj4+MdyseMGWMkmV27dhljjLl06VK5eWNjY01YWJj1+sMPP3Q4PlRk69atRpJJT093KP/rX/9arvz6Y0FF/aOyx6Cq1Fuble27ubm55sSJE8bNzc306tXLYf9buHChkWTeeecdY4wxxcXFJjQ01AQHB5szZ844LK+0tNT6f0V9YMWKFUaS+d///d8K21BZ/fv3N15eXubYsWNWWU5OjnFxcSm3/wcHBzvs/xMnTjSSzNatW62y8+fPm9DQUBMSEmKt++bNm40k06xZM3Pu3Dlr2lWrVhlJZv78+Tdd11mzZhmbzWYOHz5slVV0fLpdtf6SQZlf//rXDq+7du2qgwcPlpsuISFBzZo1s1537NhRnTp10oYNG+54G1F1MTExstvtCgoK0qBBg+Tt7a21a9eqefPmOn36tP7+979ryJAhOn/+vPLz85Wfn69Tp04pNjZWOTk51h0J7u7ucnK62t1LSkp06tQp+fj46IEHHtBXX31Vbe0dPny4ioqKHG4rWrlypYqLi/Xkk09WWz11Udmv/DLjxo2TJGvfLPvlJEkFBQXKz89XVFSUDh48qIKCAklSgwYNJEnr16/XDz/8UGE9GRkZql+/vnr27Gn1mfz8fEVERMjHx0ebN2++rfbf6hh0p+r9KcvMzNSVK1c0ceJEa/+TpGeeeUb16tWzTqnv2LFDubm5mjhxorUNy1z7q//aPlBYWKj8/Hx17txZkn7UflxSUqLMzEwlJCQ4nC1s0aKF+vTpc8v5N2zYoI4dOyoyMtIq8/Hx0bPPPqtDhw5p7969DtMPHz5cvr6+1utBgwYpMDDQ4Xvo2nW9ePGi8vPz9eijj8oYox07dtzWet5KnQgEHh4e5U7r+Pn5VXhd7v777y9X1rJlyxq9ZxY3tmjRIm3atEmrV69WXFyc8vPz5e7uLkn67rvvZIzR73//e9ntdod/06dPl3T1FLJ09drtvHnzdP/998vd3V2NGjWS3W7X119/bX2ZVIdWrVrp5z//udLT062y9PR0de7cWS1atKi2euqi6/fN8PBwOTk5WftmVlaWYmJi5O3trQYNGshut2vatGmSZG3DqKgoDRw4UMnJyWrUqJF+8YtfKC0tTUVFRdZyc3JyVFBQoICAgHL95sKFC1afqYrKHIPuRL0/dYcPH5YkPfDAAw7lbm5uCgsLs94vGxPUpk2bmy7v9OnTmjBhgho3bixPT0/Z7XaFhoZK0o/aj0+cOKHLly9XuI9WZr89fPhwuXWUpAcffNB6/1rX93WbzaYWLVo4fA/961//UmJiovz9/a1xKVFRUZJ+3LreTJ0YQ+Ds7Fyty7PZbDLGlCu/foAQ7ryOHTtadxkkJCQoMjJSTzzxhPbv36/S0lJJ0uTJkxUbG1vh/GU78yuvvKLf//73GjVqlF566SX5+/vLyclJEydOtJZTXYYPH64JEybo6NGjKioqUnZ2thYuXFitddwLrv1leODAAfXo0UOtWrXS3LlzFRQUJDc3N23YsEHz5s2ztmHZQ1+ys7O1bt06bdy4UaNGjdJrr72m7Oxs+fj4qLS0VAEBAQ6h7VqVuWZ8vcocg+5EvfeaIUOG6NNPP9ULL7yg9u3bW9uzd+/e1b4f16SSkhL17NlTp0+f1m9/+1u1atVK3t7eOnbsmBITE+/YutaJQFAVOTk55cq+/fZb6+4B6Wqyr+hyw/Upj6fX3V3Ozs6aNWuWunfvroULF1ojx11dXRUTE3PTeVevXq3u3bvr7bffdig/e/asGjVqVOW23GzbDx06VM8//7xWrFhh3bP++OOPV7mOe01OTo71a0+6egaotLRUISEhWrdunYqKirR27Vrdd9991jQ3Os3euXNnde7cWX/84x/1/vvva9iwYfrLX/6ip59+WuHh4crMzFSXLl0cTsveaTVVb00KDg6WJO3fv19hYWFW+ZUrV5Sbm2vtt+Hh4ZKk3bt333BfPnPmjP72t78pOTlZf/jDH6zyio7pVRUQECAPDw9999135d6rqOx6wcHB2r9/f7nyffv2We9f6/o2G2P03XffWYPSv/nmG3377bdatmyZhg8fbk23adOmW6/Mj1AnLhlUxZo1axyedPf5559r+/btDteJwsPDtW/fPp08edIq27Vrl7KyshyW5eXlJUkV3j6DOyM6OlodO3ZUSkqK6tWrp+joaC1evFjff/99uWmv3X7Ozs7lzvpkZGTc9lMPvb29b7jdGzVqpD59+mj58uVKT09X7969byt03GsWLVrk8HrBggWSrj6LouwX+LXbsKCgQGlpaQ7znDlzptx2bt++vSRZlw2GDBmikpISvfTSS+XaUFxcfMf255qqtybFxMTIzc1Nr7/+usN2efvtt1VQUKC+fftKkn72s58pNDRUKSkp5T6Hsvkq6gOSlJKS8qPb6ezsrJiYGK1Zs0Z5eXlW+XfffaePP/74lvPHxcXp888/d7it+OLFi3rrrbcUEhKihx56yGH6srvdyqxevVrff/+99T1U0boaYxxuwbwT7rkzBC1atFBkZKRGjx6toqIipaSkqGHDhpoyZYo1zahRozR37lzFxsbqP//zP3XixAm9+eabat26tc6dO2dN5+npqYceekgrV65Uy5Yt5e/vrzZt2tzyOhh+nBdeeEGDBw/W0qVLtWjRIkVGRqpt27Z65plnFBYWpuPHj+uzzz7T0aNHrecM9OvXTzNnztTIkSP16KOP6ptvvlF6errDr5aqiIiIUGZmpubOnaumTZsqNDRUnTp1st4fPny4Bg0aJEkVfgGgvNzcXMXHx6t379767LPPtHz5cj3xxBP6j//4D3l4eMjNzU39+/dXUlKSLly4oCVLliggIMAhDC5btkxvvPGGBgwYoPDwcJ0/f15LlixRvXr1FBcXJ+nqOIOkpCTNmjVLO3fuVK9eveTq6qqcnBxlZGRo/vz51rarTjVVb02y2+168cUXlZycrN69eys+Pl779+/XG2+8oZ///OfWQFsnJyelpqaqf//+at++vUaOHKnAwEDt27dPe/bs0caNG1WvXj1169ZNr776qn744Qc1a9ZMn3zyiXJzc6ulrTNmzNAnn3yiLl26aPTo0SopKdHChQvVpk0b7dy586bzTp06VStWrFCfPn00fvx4+fv7a9myZcrNzdUHH3zgMKBSkvz9/RUZGamRI0fq+PHjSklJUYsWLfTMM89IujoWKTw8XJMnT9axY8dUr149ffDBB3f+eRXVcq/CXVTRbYfe3t7lprv+Voyy24X+9Kc/mddee80EBQUZd3d307VrV+u2pmstX77chIWFGTc3N9O+fXuzcePGcrcdGmPMp59+aiIiIoybmxu3IFaj67fztUpKSkx4eLgJDw83xcXF5sCBA2b48OGmSZMmxtXV1TRr1sz069fPrF692pqnsLDQ/OY3vzGBgYHG09PTdOnSxXz22WeVuq2sott69u3bZ7p162Y8PT2NpHK3IBYVFRk/Pz9Tv359c/ny5Wr5TOqqss937969ZtCgQcbX19f4+fmZ5557zuGzW7t2rWnXrp3x8PAwISEhZvbs2eadd95xuL3sq6++Mr/61a/MfffdZ9zd3U1AQIDp16+f+fLLL8vV+9Zbb5mIiAjj6elpfH19Tdu2bc2UKVNMXl6eNU1lbzuszDGoKvXWZhXd8rdw4ULTqlUr4+rqaho3bmxGjx5d7vZCY4zZtm2b6dmzp/H19TXe3t6mXbt2ZsGCBdb7R48eNQMGDDANGjQw9evXN4MHDzZ5eXnljr23c9uhMcb87W9/Mw8//LBxc3Mz4eHh5s9//rP5zW9+Yzw8PBymu/62Q2OMOXDggBk0aJBp0KCB8fDwMB07djTr1693mKbstsMVK1aYF1980QQEBBhPT0/Tt29fh1sJjTFm7969JiYmxvj4+JhGjRqZZ555xuzatatSx6fbZTOmgtFzddChQ4cUGhqqP/3pT5o8eXJNNwd1XHFxsZo2bar+/fuXG7cAoPZISEjQnj17qmWswk/dPTeGALgb1qxZo5MnTzoMCALw03b9Y4FzcnK0YcOGe+aP191zYwiAO2n79u36+uuv9dJLL+nhhx+27hsGUDMuXLigCxcu3HQau90uZ2dnhYWFWX8r4fDhw0pNTZWbm5vDGLO6jEAAVKPU1FQtX75c7du3d/gDOABqxpw5c6w/U38jubm5CgkJUe/evbVixQr9+9//lru7ux555BG98sorFT7Qri66Z8YQAADuPQcPHqzwuTLXioyM5M9ai0AAAADEoEIAAKBKjiEoLS1VXl6efH19eVxvLWCM0fnz59W0adNyD8S4XfSB2uVO9AGJflDbcCxAVfpApQJBXl6egoKCqqVxuHuOHDmi5s2bV8uy6AO1U3X2AYl+UFtxLEBl+kClAkHZ322OVJxc5PrjW4Y7qlg/aJs2OPy97R+LPlC73Ik+INEPahuOBahKH6hUICg7LeQiV7nY6AA/ef83TLQ6T+fRB2qZO9AHrl0e/aCW4FiAKvQBBhUCAAACAQAAIBAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACDJpaYbUFkb83bWdBOqJLZp+5puAgAAlcYZAgAAQCAAAAAEAgAAIAIBAAAQgQAAAIhAAAAARCAAAAAiEAAAABEIAACACAQAAEC16NHFPAoYPL4aEv0A9IE7hTMEAACAQAAAAAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAADVoicVArXlaV+4s+gHoA/cGZwhAAAABAIAAEAgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAIhAAAAARCAAAgAgEAABAkktNN6CmbczbWelpY5u2v2PtQM2hD0CiH4A+wBkCAABAIAAAAAQCAAAgAgEAABCBAAAAiEAAAABEIAAAACIQAAAAEQgAAIBq0ZMKq/IEKdRN9AFI9APQB+4UzhAAAAACAQAAIBAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAEQgAAAAqkWPLv4pqMrjMmObtr9j7UDNoQ9Aoh+gbvYBzhAAAAACAQAAIBAAAAARCAAAgAgEAABABAIAACACAQAAEIEAAACIQAAAAFTJJxUaYyRJxfpBMne0PTd07nxpzVR8m4rNDzVXt67WXbbdqgN9oOrqWh+4dnn0g8qra/2APlB1taUP2Ewlpjp69KiCgoJ+fMtwVx05ckTNmzevlmXRB2qn6uwDEv2gtuJYgMr0gUoFgtLSUuXl5cnX11c2m63aGog7wxij8+fPq2nTpnJyqp6rQvSB2uVO9AGJflDbcCxAVfpApQIBAACo2xhUCAAACAQAAIBAAAAARCAAAAAiEAAAABEIAACACAQAAEDS/wN/+zDeHv60IAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random training predictions vs reality\n",
    "import random\n",
    "\n",
    "idx = random.randrange(len(train_dataset))\n",
    "print(f\"Showing prediction for training example {idx}\")\n",
    "show_prediction(train_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for test example 45\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random test predictions vs reality\n",
    "idx = random.randrange(len(test_dataset))\n",
    "print(f\"Showing prediction for test example {idx}\")\n",
    "show_prediction(test_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 96\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random training prediction where the baseline model failed\n",
    "success = True\n",
    "while success:\n",
    "    idx = random.randrange(len(train_dataset))\n",
    "    example = train_dataset[idx]\n",
    "    x, y = example\n",
    "    with torch.no_grad():\n",
    "        pred = models[\"baseline\"](x.unsqueeze(0)).squeeze(0).argmax(0)\n",
    "        success = (pred == y).all(-1).all(-1).item()\n",
    "print(f\"Showing prediction for training example {idx}\")\n",
    "show_prediction(train_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 31\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random training prediction where the local_global model failed\n",
    "success = True\n",
    "while success:\n",
    "    idx = random.randrange(len(train_dataset))\n",
    "    example = train_dataset[idx]\n",
    "    x, y = example\n",
    "    with torch.no_grad():\n",
    "        pred = models[\"local_global\"](x.unsqueeze(0)).squeeze(0).argmax(0)\n",
    "        success = (pred == y).all(-1).all(-1).item()\n",
    "print(f\"Showing prediction for training example {idx}\")\n",
    "show_prediction(train_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "237 examples in total.\n",
      "206 examples where both succeeded.\n",
      "18 examples where both failed.\n",
      "10 examples where baseline succeeded and local_global failed.\n",
      "3 examples where local_global succeeded and baseline failed.\n",
      "\n",
      "Test data:\n",
      "59 examples in total.\n",
      "50 examples where both succeeded.\n",
      "6 examples where both failed.\n",
      "3 examples where baseline succeeded and local_global failed.\n",
      "0 examples where local_global succeeded and baseline failed.\n"
     ]
    }
   ],
   "source": [
    "# Count the number of examples where each model failed\n",
    "train_total = len(train_dataset)\n",
    "train_bf_lf = 0\n",
    "train_bf_ls = 0\n",
    "train_bs_lf = 0\n",
    "train_bs_ls = 0\n",
    "for x, y in train_dataset:\n",
    "    success_baseline = (models[\"baseline\"](x.unsqueeze(0)).squeeze(0).argmax(0) == y).all(-1).all(-1).item()\n",
    "    success_local_global = (models[\"local_global\"](x.unsqueeze(0)).squeeze(0).argmax(0) == y).all(-1).all(-1).item()\n",
    "    if success_baseline:\n",
    "        if success_local_global:\n",
    "            train_bs_ls += 1\n",
    "        else:\n",
    "            train_bs_lf += 1\n",
    "    else:\n",
    "        if success_local_global:\n",
    "            train_bf_ls += 1\n",
    "        else:\n",
    "            train_bf_lf += 1\n",
    "\n",
    "print(\"Training data:\")\n",
    "print(f\"{train_total} examples in total.\")\n",
    "print(f\"{train_bs_ls} examples where both succeeded.\")\n",
    "print(f\"{train_bf_lf} examples where both failed.\")\n",
    "print(f\"{train_bs_lf} examples where baseline succeeded and local_global failed.\")\n",
    "print(f\"{train_bf_ls} examples where local_global succeeded and baseline failed.\")\n",
    "print()\n",
    "\n",
    "test_total = len(test_dataset)\n",
    "test_bf_lf = 0\n",
    "test_bf_ls = 0\n",
    "test_bs_lf = 0\n",
    "test_bs_ls = 0\n",
    "for x, y in test_dataset:\n",
    "    success_baseline = (models[\"baseline\"](x.unsqueeze(0)).squeeze(0).argmax(0) == y).all(-1).all(-1).item()\n",
    "    success_local_global = (models[\"local_global\"](x.unsqueeze(0)).squeeze(0).argmax(0) == y).all(-1).all(-1).item()\n",
    "    if success_baseline:\n",
    "        if success_local_global:\n",
    "            test_bs_ls += 1\n",
    "        else:\n",
    "            test_bs_lf += 1\n",
    "    else:\n",
    "        if success_local_global:\n",
    "            test_bf_ls += 1\n",
    "        else:\n",
    "            test_bf_lf += 1\n",
    "\n",
    "print(\"Test data:\")\n",
    "print(f\"{test_total} examples in total.\")\n",
    "print(f\"{test_bs_ls} examples where both succeeded.\")\n",
    "print(f\"{test_bf_lf} examples where both failed.\")\n",
    "print(f\"{test_bs_lf} examples where baseline succeeded and local_global failed.\")\n",
    "print(f\"{test_bf_ls} examples where local_global succeeded and baseline failed.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The local_global model reaches about the same test board accuracy and slightly worse training board accuracy than the baseline model. In terms of loss, the test loss occasionally spikes up drastically in the baseline model during training, but only jumps up slightly in the local_global model.\n",
    "\n",
    "By looking at a few random predictions, it seems both models do a fairly good job at prediction. The baseline model never manages to spawn a new block, but it makes few \"local\" mistakes. The local_global model makes some silly \"local\" mistakes, but does manage to spawn blocks occasionally. However, it tends to do so when an existing block is still falling.\n",
    "\n",
    "One realisation I had during this experiment was that, to accurately simulate Tetris, we cannot just predict cell states based on thresholds, because that makes the predictions deterministic based on the state of the board, but we know that the choice of which block will drop next is nondeterministic. We'll have to figure out how to handle this.\n",
    "\n",
    "Another observation is that we haven't really experienced overfitting in terms of the test loss going up, so we could try using a larger model and see if this improves the performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increasing capacity\n",
    "\n",
    "Let's try using variants of the two models with much larger capacity to see if we can get better performance before they start overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_process(model_class, learning_rate, epochs):\n",
    "    model = model_class().to(device)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_009\")\n",
    "\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_subdir = os.path.join(log_dir, f\"{model_class.__name__}_lr_{str(learning_rate).replace('.', '_')}_ep_{epochs}_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb = SummaryWriter(log_subdir)\n",
    "\n",
    "    print(f\"Training...\")\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        train_metrics = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_metrics = test_loop(test_dataloader, model, loss_fn)\n",
    "        tb.add_scalar(\"Loss/train\", train_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Cell accuracy/train\", train_metrics[\"acc\"], t)\n",
    "        tb.add_scalar(\"Board accuracy/train\", train_metrics[\"acc_board\"], t)\n",
    "        tb.add_scalar(\"Loss/test\", test_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Cell accuracy/test\", test_metrics[\"acc\"], t)\n",
    "        tb.add_scalar(\"Board accuracy/test\", test_metrics[\"acc_board\"], t)\n",
    "        for name, weight in model.named_parameters():\n",
    "            tb.add_histogram(f\"Weights/{name}\", weight, t)\n",
    "            tb.add_histogram(f\"Gradients/{name}\", weight.grad, t)\n",
    "\n",
    "    tb.close()\n",
    "    print(\"Done!\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LG2(nn.Module):\n",
    "    \"\"\"Added extra 1x1 convs at the end, increasing the number of channels.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 5, 3),               # (26, 14) -> (24, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),      # (24, 12) -> (12,  6)\n",
    "            nn.Conv2d(5, 10, 3),              # (12,  6) -> (10,  4)\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(6, 3)), # ( 6,  3) -> ( 1,  1)\n",
    "        )\n",
    "        self.local_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 5, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(5, 10, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv0 = nn.Conv2d(20, 40, 1)\n",
    "        self.conv1 = nn.Conv2d(40, 20, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 10, 1)\n",
    "        self.conv3 = nn.Conv2d(10, 5, 1)\n",
    "        self.conv4 = nn.Conv2d(5, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((0, 3, 1, 2)) # Move channels/classes to dimension 1\n",
    "        x = F.pad(x, (2, 2, 2, 2)) # Zero-pad 2 cells on each side\n",
    "        x_local = self.local_module(x) # Extract local information\n",
    "        x_global = self.global_module(x) # Extract global information\n",
    "        x_global = x_global.repeat(1, 1, 22, 10) # Broadcast global information to image dimensions\n",
    "        x = torch.cat((x_local, x_global), dim=1) # Combine local and global information\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        logits = F.log_softmax(self.conv4(x), dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.650481  [    4/  237]\n",
      "loss: 0.379707  [   84/  237]\n",
      "loss: 0.269441  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.297920 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.286257  [    4/  237]\n",
      "loss: 0.294141  [   84/  237]\n",
      "loss: 0.315266  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295024 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.262535  [    4/  237]\n",
      "loss: 0.294042  [   84/  237]\n",
      "loss: 0.262086  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296148 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.293988  [    4/  237]\n",
      "loss: 0.194941  [   84/  237]\n",
      "loss: 0.240317  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297352 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.315023  [    4/  237]\n",
      "loss: 0.294207  [   84/  237]\n",
      "loss: 0.229125  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295123 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.357911  [    4/  237]\n",
      "loss: 0.210425  [   84/  237]\n",
      "loss: 0.228354  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297221 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.283232  [    4/  237]\n",
      "loss: 0.262139  [   84/  237]\n",
      "loss: 0.326876  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295040 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.346950  [    4/  237]\n",
      "loss: 0.146558  [   84/  237]\n",
      "loss: 0.359322  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.298641 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.424042  [    4/  237]\n",
      "loss: 0.282938  [   84/  237]\n",
      "loss: 0.368780  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297246 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.177301  [    4/  237]\n",
      "loss: 0.304501  [   84/  237]\n",
      "loss: 0.177235  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.296905 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.220118  [    4/  237]\n",
      "loss: 0.241135  [   84/  237]\n",
      "loss: 0.389092  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295780 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.336432  [    4/  237]\n",
      "loss: 0.282628  [   84/  237]\n",
      "loss: 0.430075  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.296521 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.271484  [    4/  237]\n",
      "loss: 0.325339  [   84/  237]\n",
      "loss: 0.282180  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295046 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.355504  [    4/  237]\n",
      "loss: 0.376834  [   84/  237]\n",
      "loss: 0.260781  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.293568 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.313567  [    4/  237]\n",
      "loss: 0.388026  [   84/  237]\n",
      "loss: 0.395583  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.291830 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.216829  [    4/  237]\n",
      "loss: 0.330972  [   84/  237]\n",
      "loss: 0.307578  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.285313 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.294555  [    4/  237]\n",
      "loss: 0.209133  [   84/  237]\n",
      "loss: 0.241982  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.255882 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.227388  [    4/  237]\n",
      "loss: 0.240904  [   84/  237]\n",
      "loss: 0.199917  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.192507 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.189558  [    4/  237]\n",
      "loss: 0.162698  [   84/  237]\n",
      "loss: 0.147640  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.140343 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.171915  [    4/  237]\n",
      "loss: 0.176742  [   84/  237]\n",
      "loss: 0.116486  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Board accuracy: 0.0%, Avg loss: 0.085448 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.113517  [    4/  237]\n",
      "loss: 0.066713  [   84/  237]\n",
      "loss: 0.100198  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 7.2%, Avg loss: 0.070656 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.073604  [    4/  237]\n",
      "loss: 0.090943  [   84/  237]\n",
      "loss: 0.097733  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 0.0%, Avg loss: 0.064678 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.047881  [    4/  237]\n",
      "loss: 0.034549  [   84/  237]\n",
      "loss: 0.034018  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 13.3%, Avg loss: 0.043142 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.043184  [    4/  237]\n",
      "loss: 0.039785  [   84/  237]\n",
      "loss: 0.027801  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 27.2%, Avg loss: 0.031280 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.053903  [    4/  237]\n",
      "loss: 0.021192  [   84/  237]\n",
      "loss: 0.042216  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Board accuracy: 29.4%, Avg loss: 0.029739 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.027917  [    4/  237]\n",
      "loss: 0.013237  [   84/  237]\n",
      "loss: 0.047934  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Board accuracy: 37.2%, Avg loss: 0.024210 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.011545  [    4/  237]\n",
      "loss: 0.044799  [   84/  237]\n",
      "loss: 0.023765  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 58.9%, Avg loss: 0.018786 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.007854  [    4/  237]\n",
      "loss: 0.023904  [   84/  237]\n",
      "loss: 0.007128  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 37.2%, Avg loss: 0.022425 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.009107  [    4/  237]\n",
      "loss: 0.011438  [   84/  237]\n",
      "loss: 0.021977  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 61.1%, Avg loss: 0.017460 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.049348  [    4/  237]\n",
      "loss: 0.006138  [   84/  237]\n",
      "loss: 0.053628  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 59.4%, Avg loss: 0.015665 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.025173  [    4/  237]\n",
      "loss: 0.010051  [   84/  237]\n",
      "loss: 0.005158  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 65.6%, Avg loss: 0.015319 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.010355  [    4/  237]\n",
      "loss: 0.003280  [   84/  237]\n",
      "loss: 0.035814  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 20.6%, Avg loss: 0.032113 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.029015  [    4/  237]\n",
      "loss: 0.005669  [   84/  237]\n",
      "loss: 0.036320  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 68.9%, Avg loss: 0.015933 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.005977  [    4/  237]\n",
      "loss: 0.043257  [   84/  237]\n",
      "loss: 0.003605  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 70.0%, Avg loss: 0.013776 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.023184  [    4/  237]\n",
      "loss: 0.006475  [   84/  237]\n",
      "loss: 0.033437  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Board accuracy: 32.2%, Avg loss: 0.022720 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.022841  [    4/  237]\n",
      "loss: 0.003434  [   84/  237]\n",
      "loss: 0.006070  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 60.6%, Avg loss: 0.014727 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.044696  [    4/  237]\n",
      "loss: 0.008073  [   84/  237]\n",
      "loss: 0.005456  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 73.3%, Avg loss: 0.012903 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.004139  [    4/  237]\n",
      "loss: 0.002135  [   84/  237]\n",
      "loss: 0.008273  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 68.9%, Avg loss: 0.013043 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.002929  [    4/  237]\n",
      "loss: 0.014556  [   84/  237]\n",
      "loss: 0.004233  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 62.8%, Avg loss: 0.014292 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.006013  [    4/  237]\n",
      "loss: 0.006065  [   84/  237]\n",
      "loss: 0.022371  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 67.8%, Avg loss: 0.013099 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.042464  [    4/  237]\n",
      "loss: 0.005066  [   84/  237]\n",
      "loss: 0.003613  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 66.7%, Avg loss: 0.013554 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.004594  [    4/  237]\n",
      "loss: 0.003676  [   84/  237]\n",
      "loss: 0.006717  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 70.0%, Avg loss: 0.012733 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.004559  [    4/  237]\n",
      "loss: 0.003944  [   84/  237]\n",
      "loss: 0.037724  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 66.1%, Avg loss: 0.013436 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.005916  [    4/  237]\n",
      "loss: 0.018769  [   84/  237]\n",
      "loss: 0.042945  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 66.1%, Avg loss: 0.014149 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.004646  [    4/  237]\n",
      "loss: 0.004538  [   84/  237]\n",
      "loss: 0.009898  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Board accuracy: 1.7%, Avg loss: 0.065975 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.069542  [    4/  237]\n",
      "loss: 0.008660  [   84/  237]\n",
      "loss: 0.004554  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 40.0%, Avg loss: 0.013673 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.016901  [    4/  237]\n",
      "loss: 0.002462  [   84/  237]\n",
      "loss: 0.002468  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 72.8%, Avg loss: 0.012248 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.004621  [    4/  237]\n",
      "loss: 0.003485  [   84/  237]\n",
      "loss: 0.037259  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.012172 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.004304  [    4/  237]\n",
      "loss: 0.012828  [   84/  237]\n",
      "loss: 0.002063  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 35.6%, Avg loss: 0.017406 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.007554  [    4/  237]\n",
      "loss: 0.003232  [   84/  237]\n",
      "loss: 0.003765  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 70.0%, Avg loss: 0.012411 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.004795  [    4/  237]\n",
      "loss: 0.005146  [   84/  237]\n",
      "loss: 0.059122  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010642 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.002470  [    4/  237]\n",
      "loss: 0.024011  [   84/  237]\n",
      "loss: 0.012419  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 70.0%, Avg loss: 0.012365 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.014780  [    4/  237]\n",
      "loss: 0.006587  [   84/  237]\n",
      "loss: 0.000503  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 21.7%, Avg loss: 0.032882 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.040472  [    4/  237]\n",
      "loss: 0.003494  [   84/  237]\n",
      "loss: 0.002760  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 58.9%, Avg loss: 0.016367 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.011808  [    4/  237]\n",
      "loss: 0.006811  [   84/  237]\n",
      "loss: 0.005250  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.011215 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.006964  [    4/  237]\n",
      "loss: 0.007025  [   84/  237]\n",
      "loss: 0.004368  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.012427 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.008504  [    4/  237]\n",
      "loss: 0.001524  [   84/  237]\n",
      "loss: 0.002268  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.011191 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.002536  [    4/  237]\n",
      "loss: 0.004101  [   84/  237]\n",
      "loss: 0.005120  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 74.4%, Avg loss: 0.012463 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.010415  [    4/  237]\n",
      "loss: 0.004380  [   84/  237]\n",
      "loss: 0.006869  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.011785 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.016396  [    4/  237]\n",
      "loss: 0.004393  [   84/  237]\n",
      "loss: 0.006756  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.010805 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.002029  [    4/  237]\n",
      "loss: 0.003157  [   84/  237]\n",
      "loss: 0.029314  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 71.7%, Avg loss: 0.012414 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.004030  [    4/  237]\n",
      "loss: 0.011435  [   84/  237]\n",
      "loss: 0.003189  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 53.9%, Avg loss: 0.013414 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.005398  [    4/  237]\n",
      "loss: 0.005245  [   84/  237]\n",
      "loss: 0.002735  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.010431 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.040224  [    4/  237]\n",
      "loss: 0.001761  [   84/  237]\n",
      "loss: 0.004356  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.010794 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.001859  [    4/  237]\n",
      "loss: 0.003521  [   84/  237]\n",
      "loss: 0.003121  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.9%, Avg loss: 0.011516 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.002528  [    4/  237]\n",
      "loss: 0.001937  [   84/  237]\n",
      "loss: 0.006524  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.6%, Avg loss: 0.012468 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.003055  [    4/  237]\n",
      "loss: 0.003567  [   84/  237]\n",
      "loss: 0.001810  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.011442 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.006435  [    4/  237]\n",
      "loss: 0.004439  [   84/  237]\n",
      "loss: 0.006618  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 74.4%, Avg loss: 0.012449 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.034965  [    4/  237]\n",
      "loss: 0.021413  [   84/  237]\n",
      "loss: 0.004059  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010694 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.006173  [    4/  237]\n",
      "loss: 0.032516  [   84/  237]\n",
      "loss: 0.001098  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.013737 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.002115  [    4/  237]\n",
      "loss: 0.030591  [   84/  237]\n",
      "loss: 0.006292  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.012172 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.001310  [    4/  237]\n",
      "loss: 0.008269  [   84/  237]\n",
      "loss: 0.000808  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.010233 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.029234  [    4/  237]\n",
      "loss: 0.002224  [   84/  237]\n",
      "loss: 0.008451  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010923 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.002803  [    4/  237]\n",
      "loss: 0.037024  [   84/  237]\n",
      "loss: 0.013169  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.2%, Avg loss: 0.012568 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.005175  [    4/  237]\n",
      "loss: 0.001602  [   84/  237]\n",
      "loss: 0.007894  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.010189 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.011666  [    4/  237]\n",
      "loss: 0.024565  [   84/  237]\n",
      "loss: 0.004602  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010635 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.003469  [    4/  237]\n",
      "loss: 0.003629  [   84/  237]\n",
      "loss: 0.005698  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.011434 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.002065  [    4/  237]\n",
      "loss: 0.001924  [   84/  237]\n",
      "loss: 0.038474  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.012309 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.000810  [    4/  237]\n",
      "loss: 0.061539  [   84/  237]\n",
      "loss: 0.033481  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.010185 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.001277  [    4/  237]\n",
      "loss: 0.003194  [   84/  237]\n",
      "loss: 0.003279  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.011095 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.001118  [    4/  237]\n",
      "loss: 0.019355  [   84/  237]\n",
      "loss: 0.001208  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.9%, Avg loss: 0.012595 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.004213  [    4/  237]\n",
      "loss: 0.004879  [   84/  237]\n",
      "loss: 0.027815  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.7%, Avg loss: 0.011090 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.028097  [    4/  237]\n",
      "loss: 0.037566  [   84/  237]\n",
      "loss: 0.023170  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 66.1%, Avg loss: 0.013692 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.044524  [    4/  237]\n",
      "loss: 0.031577  [   84/  237]\n",
      "loss: 0.012120  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.012621 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.000814  [    4/  237]\n",
      "loss: 0.007165  [   84/  237]\n",
      "loss: 0.000953  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011040 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.004320  [    4/  237]\n",
      "loss: 0.001098  [   84/  237]\n",
      "loss: 0.001066  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.010464 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.001105  [    4/  237]\n",
      "loss: 0.001714  [   84/  237]\n",
      "loss: 0.004469  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 62.2%, Avg loss: 0.015054 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.002296  [    4/  237]\n",
      "loss: 0.002016  [   84/  237]\n",
      "loss: 0.000828  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.1%, Avg loss: 0.011532 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.002503  [    4/  237]\n",
      "loss: 0.041989  [   84/  237]\n",
      "loss: 0.007138  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.011269 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.001855  [    4/  237]\n",
      "loss: 0.032028  [   84/  237]\n",
      "loss: 0.013197  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.6%, Avg loss: 0.011130 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.000821  [    4/  237]\n",
      "loss: 0.001605  [   84/  237]\n",
      "loss: 0.023277  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.011243 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.005159  [    4/  237]\n",
      "loss: 0.003350  [   84/  237]\n",
      "loss: 0.000679  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.010911 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.000640  [    4/  237]\n",
      "loss: 0.004809  [   84/  237]\n",
      "loss: 0.008572  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009978 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.000783  [    4/  237]\n",
      "loss: 0.000748  [   84/  237]\n",
      "loss: 0.027847  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.011650 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.001648  [    4/  237]\n",
      "loss: 0.000447  [   84/  237]\n",
      "loss: 0.038482  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.009738 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.027111  [    4/  237]\n",
      "loss: 0.001793  [   84/  237]\n",
      "loss: 0.000945  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 71.7%, Avg loss: 0.013312 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.005370  [    4/  237]\n",
      "loss: 0.002512  [   84/  237]\n",
      "loss: 0.001030  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Board accuracy: 38.3%, Avg loss: 0.021629 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.009083  [    4/  237]\n",
      "loss: 0.001892  [   84/  237]\n",
      "loss: 0.004122  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010641 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.001272  [    4/  237]\n",
      "loss: 0.000527  [   84/  237]\n",
      "loss: 0.001116  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.010356 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.003163  [    4/  237]\n",
      "loss: 0.003461  [   84/  237]\n",
      "loss: 0.031562  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010286 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LG2(\n",
       "  (global_module): Sequential(\n",
       "    (0): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): AvgPool2d(kernel_size=(6, 3), stride=(6, 3), padding=0)\n",
       "  )\n",
       "  (local_module): Sequential(\n",
       "    (0): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv0): Conv2d(20, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv1): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv3): Conv2d(10, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv4): Conv2d(5, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_process(LG2, 1e-1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.721277  [    4/  237]\n",
      "loss: 0.401280  [   84/  237]\n",
      "loss: 0.331926  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.306555 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.271901  [    4/  237]\n",
      "loss: 0.255345  [   84/  237]\n",
      "loss: 0.259120  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.298143 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.284993  [    4/  237]\n",
      "loss: 0.223141  [   84/  237]\n",
      "loss: 0.232225  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297696 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.273324  [    4/  237]\n",
      "loss: 0.231532  [   84/  237]\n",
      "loss: 0.262571  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294780 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.283393  [    4/  237]\n",
      "loss: 0.250893  [   84/  237]\n",
      "loss: 0.272659  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297858 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.240831  [    4/  237]\n",
      "loss: 0.325906  [   84/  237]\n",
      "loss: 0.197109  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297621 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.357727  [    4/  237]\n",
      "loss: 0.283544  [   84/  237]\n",
      "loss: 0.346751  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295013 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.379970  [    4/  237]\n",
      "loss: 0.283309  [   84/  237]\n",
      "loss: 0.261905  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296443 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.175948  [    4/  237]\n",
      "loss: 0.272636  [   84/  237]\n",
      "loss: 0.315601  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297153 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.347689  [    4/  237]\n",
      "loss: 0.251243  [   84/  237]\n",
      "loss: 0.228983  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294555 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.219947  [    4/  237]\n",
      "loss: 0.198444  [   84/  237]\n",
      "loss: 0.240654  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.298562 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.240662  [    4/  237]\n",
      "loss: 0.357800  [   84/  237]\n",
      "loss: 0.230990  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.299112 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.413031  [    4/  237]\n",
      "loss: 0.272529  [   84/  237]\n",
      "loss: 0.196828  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297134 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.251509  [    4/  237]\n",
      "loss: 0.156901  [   84/  237]\n",
      "loss: 0.294058  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295950 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.357921  [    4/  237]\n",
      "loss: 0.304667  [   84/  237]\n",
      "loss: 0.262974  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.296934 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.412802  [    4/  237]\n",
      "loss: 0.401524  [   84/  237]\n",
      "loss: 0.294050  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297131 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.347239  [    4/  237]\n",
      "loss: 0.283247  [   84/  237]\n",
      "loss: 0.326372  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295777 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.189216  [    4/  237]\n",
      "loss: 0.347718  [   84/  237]\n",
      "loss: 0.240803  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295727 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.230605  [    4/  237]\n",
      "loss: 0.304673  [   84/  237]\n",
      "loss: 0.219419  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297837 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.294058  [    4/  237]\n",
      "loss: 0.315360  [   84/  237]\n",
      "loss: 0.411791  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296184 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.358366  [    4/  237]\n",
      "loss: 0.359019  [   84/  237]\n",
      "loss: 0.283362  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.298331 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.336958  [    4/  237]\n",
      "loss: 0.336909  [   84/  237]\n",
      "loss: 0.347585  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295465 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.368915  [    4/  237]\n",
      "loss: 0.304638  [   84/  237]\n",
      "loss: 0.262100  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296705 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.218259  [    4/  237]\n",
      "loss: 0.283312  [   84/  237]\n",
      "loss: 0.294037  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295751 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.304909  [    4/  237]\n",
      "loss: 0.326650  [   84/  237]\n",
      "loss: 0.434912  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296659 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.358444  [    4/  237]\n",
      "loss: 0.336889  [   84/  237]\n",
      "loss: 0.443736  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297134 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.294035  [    4/  237]\n",
      "loss: 0.241028  [   84/  237]\n",
      "loss: 0.304716  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295959 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.218516  [    4/  237]\n",
      "loss: 0.294068  [   84/  237]\n",
      "loss: 0.358654  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297135 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.337011  [    4/  237]\n",
      "loss: 0.187184  [   84/  237]\n",
      "loss: 0.241025  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.296916 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.229291  [    4/  237]\n",
      "loss: 0.423205  [   84/  237]\n",
      "loss: 0.251352  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297404 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.337270  [    4/  237]\n",
      "loss: 0.219472  [   84/  237]\n",
      "loss: 0.272459  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294752 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.304814  [    4/  237]\n",
      "loss: 0.294029  [   84/  237]\n",
      "loss: 0.326352  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297119 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.283314  [    4/  237]\n",
      "loss: 0.218336  [   84/  237]\n",
      "loss: 0.476147  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.296881 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.240422  [    4/  237]\n",
      "loss: 0.229533  [   84/  237]\n",
      "loss: 0.272626  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.298309 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.261856  [    4/  237]\n",
      "loss: 0.358346  [   84/  237]\n",
      "loss: 0.336723  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296641 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.261839  [    4/  237]\n",
      "loss: 0.326163  [   84/  237]\n",
      "loss: 0.315427  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297603 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.337028  [    4/  237]\n",
      "loss: 0.413032  [   84/  237]\n",
      "loss: 0.315563  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295682 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.272740  [    4/  237]\n",
      "loss: 0.251562  [   84/  237]\n",
      "loss: 0.164649  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295938 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.315185  [    4/  237]\n",
      "loss: 0.304680  [   84/  237]\n",
      "loss: 0.315321  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295939 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.452369  [    4/  237]\n",
      "loss: 0.283617  [   84/  237]\n",
      "loss: 0.241318  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.298512 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.240745  [    4/  237]\n",
      "loss: 0.272797  [   84/  237]\n",
      "loss: 0.240802  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295688 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.283220  [    4/  237]\n",
      "loss: 0.336674  [   84/  237]\n",
      "loss: 0.326312  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296163 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.261650  [    4/  237]\n",
      "loss: 0.272521  [   84/  237]\n",
      "loss: 0.336920  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296635 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.283218  [    4/  237]\n",
      "loss: 0.230071  [   84/  237]\n",
      "loss: 0.186008  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Board accuracy: 0.0%, Avg loss: 0.299287 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.391266  [    4/  237]\n",
      "loss: 0.251015  [   84/  237]\n",
      "loss: 0.326296  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295662 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.240153  [    4/  237]\n",
      "loss: 0.304706  [   84/  237]\n",
      "loss: 0.229233  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297536 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.453497  [    4/  237]\n",
      "loss: 0.187985  [   84/  237]\n",
      "loss: 0.347482  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.296826 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.315387  [    4/  237]\n",
      "loss: 0.346734  [   84/  237]\n",
      "loss: 0.272509  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296581 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.208289  [    4/  237]\n",
      "loss: 0.347594  [   84/  237]\n",
      "loss: 0.251170  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.298014 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.218744  [    4/  237]\n",
      "loss: 0.347556  [   84/  237]\n",
      "loss: 0.315384  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Board accuracy: 0.0%, Avg loss: 0.299874 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.389923  [    4/  237]\n",
      "loss: 0.272479  [   84/  237]\n",
      "loss: 0.229934  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296314 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.218892  [    4/  237]\n",
      "loss: 0.315764  [   84/  237]\n",
      "loss: 0.261451  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297476 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.368463  [    4/  237]\n",
      "loss: 0.272652  [   84/  237]\n",
      "loss: 0.369059  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295340 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.336332  [    4/  237]\n",
      "loss: 0.304577  [   84/  237]\n",
      "loss: 0.336264  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294604 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.198203  [    4/  237]\n",
      "loss: 0.283182  [   84/  237]\n",
      "loss: 0.218443  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.298834 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.347057  [    4/  237]\n",
      "loss: 0.220336  [   84/  237]\n",
      "loss: 0.251391  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295752 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.239961  [    4/  237]\n",
      "loss: 0.357922  [   84/  237]\n",
      "loss: 0.186360  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295465 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.229412  [    4/  237]\n",
      "loss: 0.410909  [   84/  237]\n",
      "loss: 0.325886  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.296363 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.154824  [    4/  237]\n",
      "loss: 0.272471  [   84/  237]\n",
      "loss: 0.346983  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297265 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.357989  [    4/  237]\n",
      "loss: 0.272392  [   84/  237]\n",
      "loss: 0.336240  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295280 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.282917  [    4/  237]\n",
      "loss: 0.335700  [   84/  237]\n",
      "loss: 0.336373  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297536 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.272300  [    4/  237]\n",
      "loss: 0.293484  [   84/  237]\n",
      "loss: 0.346307  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.296455 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.346745  [    4/  237]\n",
      "loss: 0.304136  [   84/  237]\n",
      "loss: 0.293236  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294138 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.261630  [    4/  237]\n",
      "loss: 0.314106  [   84/  237]\n",
      "loss: 0.240575  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297808 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.282124  [    4/  237]\n",
      "loss: 0.356199  [   84/  237]\n",
      "loss: 0.239579  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297079 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.260055  [    4/  237]\n",
      "loss: 0.517887  [   84/  237]\n",
      "loss: 0.333916  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.293296 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.195894  [    4/  237]\n",
      "loss: 0.323329  [   84/  237]\n",
      "loss: 0.215863  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.290801 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.195724  [    4/  237]\n",
      "loss: 0.185232  [   84/  237]\n",
      "loss: 0.288005  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.287595 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.265560  [    4/  237]\n",
      "loss: 0.170001  [   84/  237]\n",
      "loss: 0.282357  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.280549 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.330451  [    4/  237]\n",
      "loss: 0.213837  [   84/  237]\n",
      "loss: 0.370693  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Board accuracy: 0.0%, Avg loss: 0.269065 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.294182  [    4/  237]\n",
      "loss: 0.316144  [   84/  237]\n",
      "loss: 0.200413  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.239367 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.217786  [    4/  237]\n",
      "loss: 0.207938  [   84/  237]\n",
      "loss: 0.322806  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.202955 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.258625  [    4/  237]\n",
      "loss: 0.193769  [   84/  237]\n",
      "loss: 0.177859  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Board accuracy: 0.0%, Avg loss: 0.164513 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.184993  [    4/  237]\n",
      "loss: 0.138173  [   84/  237]\n",
      "loss: 0.126217  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.128523 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.112187  [    4/  237]\n",
      "loss: 0.100874  [   84/  237]\n",
      "loss: 0.116034  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.100537 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.085173  [    4/  237]\n",
      "loss: 0.081885  [   84/  237]\n",
      "loss: 0.073039  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 0.0%, Avg loss: 0.081031 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.061917  [    4/  237]\n",
      "loss: 0.054660  [   84/  237]\n",
      "loss: 0.075994  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 0.0%, Avg loss: 0.073290 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.117898  [    4/  237]\n",
      "loss: 0.055442  [   84/  237]\n",
      "loss: 0.042087  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 0.0%, Avg loss: 0.071934 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.056377  [    4/  237]\n",
      "loss: 0.078726  [   84/  237]\n",
      "loss: 0.052768  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Board accuracy: 0.0%, Avg loss: 0.071622 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.069433  [    4/  237]\n",
      "loss: 0.041418  [   84/  237]\n",
      "loss: 0.044863  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Board accuracy: 0.0%, Avg loss: 0.070235 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.071778  [    4/  237]\n",
      "loss: 0.074514  [   84/  237]\n",
      "loss: 0.090115  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.066249 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.043625  [    4/  237]\n",
      "loss: 0.053336  [   84/  237]\n",
      "loss: 0.054558  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.062539 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.045012  [    4/  237]\n",
      "loss: 0.045350  [   84/  237]\n",
      "loss: 0.050560  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.059240 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.082189  [    4/  237]\n",
      "loss: 0.036038  [   84/  237]\n",
      "loss: 0.044644  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Board accuracy: 0.0%, Avg loss: 0.057238 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.051660  [    4/  237]\n",
      "loss: 0.032950  [   84/  237]\n",
      "loss: 0.038876  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Board accuracy: 0.0%, Avg loss: 0.110536 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.112387  [    4/  237]\n",
      "loss: 0.064497  [   84/  237]\n",
      "loss: 0.069286  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 0.0%, Avg loss: 0.048789 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.046601  [    4/  237]\n",
      "loss: 0.036320  [   84/  237]\n",
      "loss: 0.043803  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 0.0%, Avg loss: 0.047805 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.044396  [    4/  237]\n",
      "loss: 0.034920  [   84/  237]\n",
      "loss: 0.033066  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 0.0%, Avg loss: 0.045689 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.070165  [    4/  237]\n",
      "loss: 0.039852  [   84/  237]\n",
      "loss: 0.029917  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Board accuracy: 0.0%, Avg loss: 0.061783 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.057422  [    4/  237]\n",
      "loss: 0.034491  [   84/  237]\n",
      "loss: 0.035009  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.048845 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.033339  [    4/  237]\n",
      "loss: 0.030596  [   84/  237]\n",
      "loss: 0.027141  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 16.7%, Avg loss: 0.040812 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.026505  [    4/  237]\n",
      "loss: 0.045340  [   84/  237]\n",
      "loss: 0.032612  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 0.0%, Avg loss: 0.038135 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.028338  [    4/  237]\n",
      "loss: 0.031866  [   84/  237]\n",
      "loss: 0.023147  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 1.7%, Avg loss: 0.051355 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.032425  [    4/  237]\n",
      "loss: 0.025975  [   84/  237]\n",
      "loss: 0.015206  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 12.2%, Avg loss: 0.033634 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.062527  [    4/  237]\n",
      "loss: 0.015705  [   84/  237]\n",
      "loss: 0.072062  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 51.1%, Avg loss: 0.023434 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.017269  [    4/  237]\n",
      "loss: 0.049175  [   84/  237]\n",
      "loss: 0.023312  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 43.3%, Avg loss: 0.024212 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.057580  [    4/  237]\n",
      "loss: 0.011630  [   84/  237]\n",
      "loss: 0.011770  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 51.1%, Avg loss: 0.020293 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.010361  [    4/  237]\n",
      "loss: 0.011986  [   84/  237]\n",
      "loss: 0.009898  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 67.8%, Avg loss: 0.018089 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.007528  [    4/  237]\n",
      "loss: 0.038562  [   84/  237]\n",
      "loss: 0.006794  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 45.0%, Avg loss: 0.017386 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.010559  [    4/  237]\n",
      "loss: 0.006563  [   84/  237]\n",
      "loss: 0.002041  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 76.1%, Avg loss: 0.015783 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.033235  [    4/  237]\n",
      "loss: 0.003546  [   84/  237]\n",
      "loss: 0.006755  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.014949 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.004309  [    4/  237]\n",
      "loss: 0.002483  [   84/  237]\n",
      "loss: 0.003692  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 74.4%, Avg loss: 0.015627 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.028777  [    4/  237]\n",
      "loss: 0.002867  [   84/  237]\n",
      "loss: 0.013784  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 73.3%, Avg loss: 0.013875 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.005003  [    4/  237]\n",
      "loss: 0.005004  [   84/  237]\n",
      "loss: 0.003911  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 34.4%, Avg loss: 0.015834 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.005564  [    4/  237]\n",
      "loss: 0.041410  [   84/  237]\n",
      "loss: 0.006929  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 75.0%, Avg loss: 0.014868 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.007871  [    4/  237]\n",
      "loss: 0.002820  [   84/  237]\n",
      "loss: 0.013769  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.012964 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.035069  [    4/  237]\n",
      "loss: 0.002912  [   84/  237]\n",
      "loss: 0.001564  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.012724 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.002568  [    4/  237]\n",
      "loss: 0.001874  [   84/  237]\n",
      "loss: 0.004190  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 53.9%, Avg loss: 0.014231 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.009265  [    4/  237]\n",
      "loss: 0.002567  [   84/  237]\n",
      "loss: 0.002636  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Board accuracy: 30.0%, Avg loss: 0.026637 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.012299  [    4/  237]\n",
      "loss: 0.028026  [   84/  237]\n",
      "loss: 0.001036  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011880 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.002273  [    4/  237]\n",
      "loss: 0.000814  [   84/  237]\n",
      "loss: 0.002786  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 74.4%, Avg loss: 0.012114 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.003427  [    4/  237]\n",
      "loss: 0.006701  [   84/  237]\n",
      "loss: 0.002806  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.013094 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.001849  [    4/  237]\n",
      "loss: 0.034214  [   84/  237]\n",
      "loss: 0.035941  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.012488 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.001633  [    4/  237]\n",
      "loss: 0.002089  [   84/  237]\n",
      "loss: 0.023714  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 75.6%, Avg loss: 0.014354 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.002769  [    4/  237]\n",
      "loss: 0.002347  [   84/  237]\n",
      "loss: 0.001740  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.012666 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.003051  [    4/  237]\n",
      "loss: 0.000988  [   84/  237]\n",
      "loss: 0.001401  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 52.8%, Avg loss: 0.015711 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.030780  [    4/  237]\n",
      "loss: 0.007650  [   84/  237]\n",
      "loss: 0.000926  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 43.3%, Avg loss: 0.038543 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.035776  [    4/  237]\n",
      "loss: 0.001139  [   84/  237]\n",
      "loss: 0.001804  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 73.3%, Avg loss: 0.014313 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.001229  [    4/  237]\n",
      "loss: 0.050488  [   84/  237]\n",
      "loss: 0.031963  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.014499 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.008592  [    4/  237]\n",
      "loss: 0.007292  [   84/  237]\n",
      "loss: 0.002216  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 59.4%, Avg loss: 0.012584 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.023039  [    4/  237]\n",
      "loss: 0.003718  [   84/  237]\n",
      "loss: 0.001513  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.011920 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.001980  [    4/  237]\n",
      "loss: 0.004467  [   84/  237]\n",
      "loss: 0.001213  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.010856 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.004426  [    4/  237]\n",
      "loss: 0.001935  [   84/  237]\n",
      "loss: 0.004733  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.011912 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.004250  [    4/  237]\n",
      "loss: 0.033331  [   84/  237]\n",
      "loss: 0.001744  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011273 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.001258  [    4/  237]\n",
      "loss: 0.001710  [   84/  237]\n",
      "loss: 0.029216  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.011200 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.000806  [    4/  237]\n",
      "loss: 0.029752  [   84/  237]\n",
      "loss: 0.049237  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.012727 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.004289  [    4/  237]\n",
      "loss: 0.032836  [   84/  237]\n",
      "loss: 0.001085  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.012731 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.001689  [    4/  237]\n",
      "loss: 0.032358  [   84/  237]\n",
      "loss: 0.004503  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.1%, Avg loss: 0.012170 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.032877  [    4/  237]\n",
      "loss: 0.025985  [   84/  237]\n",
      "loss: 0.003281  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.010471 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.002652  [    4/  237]\n",
      "loss: 0.000943  [   84/  237]\n",
      "loss: 0.007736  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.011641 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.001059  [    4/  237]\n",
      "loss: 0.001199  [   84/  237]\n",
      "loss: 0.002269  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.011233 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.000580  [    4/  237]\n",
      "loss: 0.000717  [   84/  237]\n",
      "loss: 0.010079  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.011839 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.001093  [    4/  237]\n",
      "loss: 0.032304  [   84/  237]\n",
      "loss: 0.002984  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.010902 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.030640  [    4/  237]\n",
      "loss: 0.003109  [   84/  237]\n",
      "loss: 0.058602  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 32.2%, Avg loss: 0.026089 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.017493  [    4/  237]\n",
      "loss: 0.034806  [   84/  237]\n",
      "loss: 0.001482  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.091122 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.100647  [    4/  237]\n",
      "loss: 0.001241  [   84/  237]\n",
      "loss: 0.001302  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010856 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.001519  [    4/  237]\n",
      "loss: 0.047814  [   84/  237]\n",
      "loss: 0.001140  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010588 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.005097  [    4/  237]\n",
      "loss: 0.001257  [   84/  237]\n",
      "loss: 0.001471  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010926 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.000728  [    4/  237]\n",
      "loss: 0.002202  [   84/  237]\n",
      "loss: 0.001699  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010810 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.001222  [    4/  237]\n",
      "loss: 0.001030  [   84/  237]\n",
      "loss: 0.001481  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.010868 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.030630  [    4/  237]\n",
      "loss: 0.000841  [   84/  237]\n",
      "loss: 0.001409  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009644 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.028378  [    4/  237]\n",
      "loss: 0.003542  [   84/  237]\n",
      "loss: 0.028090  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 65.6%, Avg loss: 0.010945 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.026002  [    4/  237]\n",
      "loss: 0.001460  [   84/  237]\n",
      "loss: 0.002249  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.010385 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.030214  [    4/  237]\n",
      "loss: 0.000771  [   84/  237]\n",
      "loss: 0.004496  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 52.2%, Avg loss: 0.014052 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.011958  [    4/  237]\n",
      "loss: 0.002082  [   84/  237]\n",
      "loss: 0.001127  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009860 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.002284  [    4/  237]\n",
      "loss: 0.000886  [   84/  237]\n",
      "loss: 0.000526  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010262 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.031621  [    4/  237]\n",
      "loss: 0.000636  [   84/  237]\n",
      "loss: 0.028278  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010164 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.000622  [    4/  237]\n",
      "loss: 0.002723  [   84/  237]\n",
      "loss: 0.000751  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.029291 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.026469  [    4/  237]\n",
      "loss: 0.001446  [   84/  237]\n",
      "loss: 0.002406  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Board accuracy: 23.3%, Avg loss: 0.029275 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.063670  [    4/  237]\n",
      "loss: 0.003816  [   84/  237]\n",
      "loss: 0.001844  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009455 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.012123  [    4/  237]\n",
      "loss: 0.028861  [   84/  237]\n",
      "loss: 0.033458  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009980 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.000630  [    4/  237]\n",
      "loss: 0.003228  [   84/  237]\n",
      "loss: 0.001978  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.010082 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.000850  [    4/  237]\n",
      "loss: 0.007469  [   84/  237]\n",
      "loss: 0.001056  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.010159 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.003783  [    4/  237]\n",
      "loss: 0.000820  [   84/  237]\n",
      "loss: 0.000963  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 6.7%, Avg loss: 0.059774 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.079103  [    4/  237]\n",
      "loss: 0.000916  [   84/  237]\n",
      "loss: 0.001624  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.010588 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.030157  [    4/  237]\n",
      "loss: 0.002246  [   84/  237]\n",
      "loss: 0.000867  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009526 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.001973  [    4/  237]\n",
      "loss: 0.000714  [   84/  237]\n",
      "loss: 0.000877  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010416 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.002412  [    4/  237]\n",
      "loss: 0.000807  [   84/  237]\n",
      "loss: 0.001275  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009571 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.002304  [    4/  237]\n",
      "loss: 0.001697  [   84/  237]\n",
      "loss: 0.000994  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.010127 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.002514  [    4/  237]\n",
      "loss: 0.001262  [   84/  237]\n",
      "loss: 0.000744  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.010674 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.028392  [    4/  237]\n",
      "loss: 0.000761  [   84/  237]\n",
      "loss: 0.000792  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010507 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.000849  [    4/  237]\n",
      "loss: 0.001825  [   84/  237]\n",
      "loss: 0.000783  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.010004 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.023454  [    4/  237]\n",
      "loss: 0.000508  [   84/  237]\n",
      "loss: 0.006619  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.9%, Avg loss: 0.010703 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.001313  [    4/  237]\n",
      "loss: 0.001228  [   84/  237]\n",
      "loss: 0.001408  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009245 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.000676  [    4/  237]\n",
      "loss: 0.000811  [   84/  237]\n",
      "loss: 0.002356  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009259 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.000665  [    4/  237]\n",
      "loss: 0.000559  [   84/  237]\n",
      "loss: 0.002840  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.010079 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.001060  [    4/  237]\n",
      "loss: 0.017109  [   84/  237]\n",
      "loss: 0.002874  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.009585 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.026230  [    4/  237]\n",
      "loss: 0.000384  [   84/  237]\n",
      "loss: 0.001508  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.010182 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.029976  [    4/  237]\n",
      "loss: 0.004174  [   84/  237]\n",
      "loss: 0.011241  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009454 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.023784  [    4/  237]\n",
      "loss: 0.013335  [   84/  237]\n",
      "loss: 0.001278  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009580 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.000796  [    4/  237]\n",
      "loss: 0.000934  [   84/  237]\n",
      "loss: 0.000853  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.8%, Avg loss: 0.008898 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.001199  [    4/  237]\n",
      "loss: 0.000538  [   84/  237]\n",
      "loss: 0.001024  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009539 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.000532  [    4/  237]\n",
      "loss: 0.003156  [   84/  237]\n",
      "loss: 0.000383  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.008981 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.001315  [    4/  237]\n",
      "loss: 0.018221  [   84/  237]\n",
      "loss: 0.002064  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009729 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.000487  [    4/  237]\n",
      "loss: 0.027148  [   84/  237]\n",
      "loss: 0.001578  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.010261 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.008953  [    4/  237]\n",
      "loss: 0.000426  [   84/  237]\n",
      "loss: 0.001867  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 40.0%, Avg loss: 0.012870 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.008525  [    4/  237]\n",
      "loss: 0.000427  [   84/  237]\n",
      "loss: 0.023916  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008629 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.017690  [    4/  237]\n",
      "loss: 0.000943  [   84/  237]\n",
      "loss: 0.006029  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008840 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.000642  [    4/  237]\n",
      "loss: 0.000963  [   84/  237]\n",
      "loss: 0.000954  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008844 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.002201  [    4/  237]\n",
      "loss: 0.002316  [   84/  237]\n",
      "loss: 0.000797  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010082 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.033435  [    4/  237]\n",
      "loss: 0.001246  [   84/  237]\n",
      "loss: 0.001193  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009522 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.001512  [    4/  237]\n",
      "loss: 0.001347  [   84/  237]\n",
      "loss: 0.010527  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009417 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.000450  [    4/  237]\n",
      "loss: 0.000617  [   84/  237]\n",
      "loss: 0.012931  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.008625 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.006514  [    4/  237]\n",
      "loss: 0.000577  [   84/  237]\n",
      "loss: 0.002341  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.009306 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.001206  [    4/  237]\n",
      "loss: 0.001045  [   84/  237]\n",
      "loss: 0.001162  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.008948 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.002118  [    4/  237]\n",
      "loss: 0.000824  [   84/  237]\n",
      "loss: 0.003895  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.010506 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.001770  [    4/  237]\n",
      "loss: 0.000865  [   84/  237]\n",
      "loss: 0.000664  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.9%, Avg loss: 0.010003 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.000767  [    4/  237]\n",
      "loss: 0.005688  [   84/  237]\n",
      "loss: 0.002914  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.010505 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.012322  [    4/  237]\n",
      "loss: 0.001734  [   84/  237]\n",
      "loss: 0.011545  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009895 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.000962  [    4/  237]\n",
      "loss: 0.001825  [   84/  237]\n",
      "loss: 0.000720  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.008918 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.002550  [    4/  237]\n",
      "loss: 0.001648  [   84/  237]\n",
      "loss: 0.000793  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008584 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.000312  [    4/  237]\n",
      "loss: 0.023622  [   84/  237]\n",
      "loss: 0.000725  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009123 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.000760  [    4/  237]\n",
      "loss: 0.014380  [   84/  237]\n",
      "loss: 0.000960  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008049 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.026585  [    4/  237]\n",
      "loss: 0.000862  [   84/  237]\n",
      "loss: 0.000495  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008458 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.017463  [    4/  237]\n",
      "loss: 0.000985  [   84/  237]\n",
      "loss: 0.001507  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008204 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.000601  [    4/  237]\n",
      "loss: 0.004874  [   84/  237]\n",
      "loss: 0.004006  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.010249 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.005752  [    4/  237]\n",
      "loss: 0.009953  [   84/  237]\n",
      "loss: 0.004983  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007629 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.000568  [    4/  237]\n",
      "loss: 0.000859  [   84/  237]\n",
      "loss: 0.002239  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008528 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.000476  [    4/  237]\n",
      "loss: 0.002032  [   84/  237]\n",
      "loss: 0.000565  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.007239 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.001715  [    4/  237]\n",
      "loss: 0.000468  [   84/  237]\n",
      "loss: 0.000551  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.007017 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.000939  [    4/  237]\n",
      "loss: 0.002014  [   84/  237]\n",
      "loss: 0.006522  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008545 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.000461  [    4/  237]\n",
      "loss: 0.003167  [   84/  237]\n",
      "loss: 0.000954  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008819 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.025639  [    4/  237]\n",
      "loss: 0.000593  [   84/  237]\n",
      "loss: 0.000397  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.007068 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.001985  [    4/  237]\n",
      "loss: 0.002637  [   84/  237]\n",
      "loss: 0.000488  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006762 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.002858  [    4/  237]\n",
      "loss: 0.003143  [   84/  237]\n",
      "loss: 0.001658  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007329 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.002402  [    4/  237]\n",
      "loss: 0.020745  [   84/  237]\n",
      "loss: 0.000288  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007006 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.001001  [    4/  237]\n",
      "loss: 0.018259  [   84/  237]\n",
      "loss: 0.000615  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007461 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.000515  [    4/  237]\n",
      "loss: 0.000277  [   84/  237]\n",
      "loss: 0.003526  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006265 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.003514  [    4/  237]\n",
      "loss: 0.001760  [   84/  237]\n",
      "loss: 0.000696  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007211 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.000536  [    4/  237]\n",
      "loss: 0.000402  [   84/  237]\n",
      "loss: 0.001040  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.6%, Avg loss: 0.007080 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.001513  [    4/  237]\n",
      "loss: 0.000454  [   84/  237]\n",
      "loss: 0.000530  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006472 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.000550  [    4/  237]\n",
      "loss: 0.000643  [   84/  237]\n",
      "loss: 0.000456  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.006946 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.000753  [    4/  237]\n",
      "loss: 0.007313  [   84/  237]\n",
      "loss: 0.001494  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006967 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.000273  [    4/  237]\n",
      "loss: 0.000746  [   84/  237]\n",
      "loss: 0.001369  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.006583 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.001094  [    4/  237]\n",
      "loss: 0.000218  [   84/  237]\n",
      "loss: 0.000298  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 30.0%, Avg loss: 0.048842 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.095907  [    4/  237]\n",
      "loss: 0.011781  [   84/  237]\n",
      "loss: 0.000302  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006392 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.002654  [    4/  237]\n",
      "loss: 0.000496  [   84/  237]\n",
      "loss: 0.001799  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.006582 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.002692  [    4/  237]\n",
      "loss: 0.000784  [   84/  237]\n",
      "loss: 0.000910  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.006767 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.005801  [    4/  237]\n",
      "loss: 0.000316  [   84/  237]\n",
      "loss: 0.000276  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006525 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.009208  [    4/  237]\n",
      "loss: 0.000414  [   84/  237]\n",
      "loss: 0.000513  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.006368 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.001994  [    4/  237]\n",
      "loss: 0.018280  [   84/  237]\n",
      "loss: 0.000454  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007662 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.017637  [    4/  237]\n",
      "loss: 0.000634  [   84/  237]\n",
      "loss: 0.001194  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008262 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.000534  [    4/  237]\n",
      "loss: 0.000216  [   84/  237]\n",
      "loss: 0.000496  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006845 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.000239  [    4/  237]\n",
      "loss: 0.003615  [   84/  237]\n",
      "loss: 0.000492  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007632 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.009758  [    4/  237]\n",
      "loss: 0.008333  [   84/  237]\n",
      "loss: 0.000224  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006822 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.014824  [    4/  237]\n",
      "loss: 0.001255  [   84/  237]\n",
      "loss: 0.000625  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006030 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.020859  [    4/  237]\n",
      "loss: 0.000289  [   84/  237]\n",
      "loss: 0.000257  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006447 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.000373  [    4/  237]\n",
      "loss: 0.007381  [   84/  237]\n",
      "loss: 0.000521  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006334 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.003544  [    4/  237]\n",
      "loss: 0.007860  [   84/  237]\n",
      "loss: 0.003127  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006791 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.000419  [    4/  237]\n",
      "loss: 0.000410  [   84/  237]\n",
      "loss: 0.013305  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005828 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.000811  [    4/  237]\n",
      "loss: 0.001379  [   84/  237]\n",
      "loss: 0.000536  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 20.6%, Avg loss: 0.052739 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.038689  [    4/  237]\n",
      "loss: 0.001156  [   84/  237]\n",
      "loss: 0.004244  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005933 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.014241  [    4/  237]\n",
      "loss: 0.002672  [   84/  237]\n",
      "loss: 0.000360  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006623 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.001546  [    4/  237]\n",
      "loss: 0.000341  [   84/  237]\n",
      "loss: 0.000222  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005752 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.000251  [    4/  237]\n",
      "loss: 0.000622  [   84/  237]\n",
      "loss: 0.000897  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007383 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.000518  [    4/  237]\n",
      "loss: 0.001241  [   84/  237]\n",
      "loss: 0.016315  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006382 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.000179  [    4/  237]\n",
      "loss: 0.000328  [   84/  237]\n",
      "loss: 0.001324  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006982 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.011233  [    4/  237]\n",
      "loss: 0.025741  [   84/  237]\n",
      "loss: 0.005543  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007238 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.003129  [    4/  237]\n",
      "loss: 0.000122  [   84/  237]\n",
      "loss: 0.011689  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 61.1%, Avg loss: 0.009202 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.019927  [    4/  237]\n",
      "loss: 0.000316  [   84/  237]\n",
      "loss: 0.002318  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007537 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.000483  [    4/  237]\n",
      "loss: 0.000529  [   84/  237]\n",
      "loss: 0.004695  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006621 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.000137  [    4/  237]\n",
      "loss: 0.009830  [   84/  237]\n",
      "loss: 0.000616  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005888 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.001407  [    4/  237]\n",
      "loss: 0.005734  [   84/  237]\n",
      "loss: 0.001226  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007087 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.000601  [    4/  237]\n",
      "loss: 0.000533  [   84/  237]\n",
      "loss: 0.028277  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006456 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.001487  [    4/  237]\n",
      "loss: 0.010968  [   84/  237]\n",
      "loss: 0.013527  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006139 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.000508  [    4/  237]\n",
      "loss: 0.010053  [   84/  237]\n",
      "loss: 0.014628  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006152 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.000283  [    4/  237]\n",
      "loss: 0.000113  [   84/  237]\n",
      "loss: 0.001143  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005657 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.000347  [    4/  237]\n",
      "loss: 0.000604  [   84/  237]\n",
      "loss: 0.002716  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007036 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.000232  [    4/  237]\n",
      "loss: 0.000810  [   84/  237]\n",
      "loss: 0.001735  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006244 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.000309  [    4/  237]\n",
      "loss: 0.002200  [   84/  237]\n",
      "loss: 0.000089  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006481 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.000141  [    4/  237]\n",
      "loss: 0.009798  [   84/  237]\n",
      "loss: 0.000087  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.006584 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.000938  [    4/  237]\n",
      "loss: 0.000353  [   84/  237]\n",
      "loss: 0.011417  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006724 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.000597  [    4/  237]\n",
      "loss: 0.000167  [   84/  237]\n",
      "loss: 0.000116  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.006781 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.014566  [    4/  237]\n",
      "loss: 0.000081  [   84/  237]\n",
      "loss: 0.002560  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006624 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.000462  [    4/  237]\n",
      "loss: 0.000815  [   84/  237]\n",
      "loss: 0.000227  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005894 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.012177  [    4/  237]\n",
      "loss: 0.000601  [   84/  237]\n",
      "loss: 0.000305  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007074 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.013721  [    4/  237]\n",
      "loss: 0.000929  [   84/  237]\n",
      "loss: 0.000147  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006675 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.000081  [    4/  237]\n",
      "loss: 0.000207  [   84/  237]\n",
      "loss: 0.002885  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007022 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.000165  [    4/  237]\n",
      "loss: 0.000795  [   84/  237]\n",
      "loss: 0.001418  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.005949 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.007698  [    4/  237]\n",
      "loss: 0.001132  [   84/  237]\n",
      "loss: 0.000203  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005922 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.000241  [    4/  237]\n",
      "loss: 0.002906  [   84/  237]\n",
      "loss: 0.000159  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007356 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.001714  [    4/  237]\n",
      "loss: 0.001467  [   84/  237]\n",
      "loss: 0.000131  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005638 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.000142  [    4/  237]\n",
      "loss: 0.002611  [   84/  237]\n",
      "loss: 0.000484  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 45.6%, Avg loss: 0.019263 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.014324  [    4/  237]\n",
      "loss: 0.000254  [   84/  237]\n",
      "loss: 0.000106  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.006791 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.000348  [    4/  237]\n",
      "loss: 0.000235  [   84/  237]\n",
      "loss: 0.000071  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.005696 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.011639  [    4/  237]\n",
      "loss: 0.000802  [   84/  237]\n",
      "loss: 0.010040  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006965 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.015119  [    4/  237]\n",
      "loss: 0.010956  [   84/  237]\n",
      "loss: 0.000089  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006857 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.008942  [    4/  237]\n",
      "loss: 0.019108  [   84/  237]\n",
      "loss: 0.000117  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006476 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.000212  [    4/  237]\n",
      "loss: 0.014100  [   84/  237]\n",
      "loss: 0.001114  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005617 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.000177  [    4/  237]\n",
      "loss: 0.001964  [   84/  237]\n",
      "loss: 0.000593  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 63.9%, Avg loss: 0.010573 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.016002  [    4/  237]\n",
      "loss: 0.000200  [   84/  237]\n",
      "loss: 0.000143  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006297 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.000152  [    4/  237]\n",
      "loss: 0.000195  [   84/  237]\n",
      "loss: 0.000482  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005535 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.013171  [    4/  237]\n",
      "loss: 0.010753  [   84/  237]\n",
      "loss: 0.000108  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005667 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.000153  [    4/  237]\n",
      "loss: 0.000148  [   84/  237]\n",
      "loss: 0.000540  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006653 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.000456  [    4/  237]\n",
      "loss: 0.001221  [   84/  237]\n",
      "loss: 0.000577  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.005477 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.000807  [    4/  237]\n",
      "loss: 0.000482  [   84/  237]\n",
      "loss: 0.004136  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005312 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.003451  [    4/  237]\n",
      "loss: 0.000346  [   84/  237]\n",
      "loss: 0.001574  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006355 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.001109  [    4/  237]\n",
      "loss: 0.000171  [   84/  237]\n",
      "loss: 0.000063  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006002 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.000557  [    4/  237]\n",
      "loss: 0.002321  [   84/  237]\n",
      "loss: 0.000264  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006352 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.000063  [    4/  237]\n",
      "loss: 0.005667  [   84/  237]\n",
      "loss: 0.002362  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006154 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.000237  [    4/  237]\n",
      "loss: 0.004027  [   84/  237]\n",
      "loss: 0.016866  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007745 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.000037  [    4/  237]\n",
      "loss: 0.000374  [   84/  237]\n",
      "loss: 0.000277  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006731 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.000047  [    4/  237]\n",
      "loss: 0.000642  [   84/  237]\n",
      "loss: 0.000138  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005298 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.000483  [    4/  237]\n",
      "loss: 0.000373  [   84/  237]\n",
      "loss: 0.000121  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006942 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.000142  [    4/  237]\n",
      "loss: 0.000181  [   84/  237]\n",
      "loss: 0.001057  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 83.3%, Avg loss: 0.011195 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.013033  [    4/  237]\n",
      "loss: 0.000633  [   84/  237]\n",
      "loss: 0.000115  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005296 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.000821  [    4/  237]\n",
      "loss: 0.001660  [   84/  237]\n",
      "loss: 0.000186  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005701 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.005346  [    4/  237]\n",
      "loss: 0.000602  [   84/  237]\n",
      "loss: 0.000190  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005646 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.002702  [    4/  237]\n",
      "loss: 0.000152  [   84/  237]\n",
      "loss: 0.000123  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005744 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.012044  [    4/  237]\n",
      "loss: 0.000650  [   84/  237]\n",
      "loss: 0.000197  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005657 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.000269  [    4/  237]\n",
      "loss: 0.000374  [   84/  237]\n",
      "loss: 0.001081  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005410 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.010367  [    4/  237]\n",
      "loss: 0.000227  [   84/  237]\n",
      "loss: 0.000506  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Board accuracy: 0.0%, Avg loss: 0.174199 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.182055  [    4/  237]\n",
      "loss: 0.000114  [   84/  237]\n",
      "loss: 0.000649  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005316 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.004129  [    4/  237]\n",
      "loss: 0.010671  [   84/  237]\n",
      "loss: 0.000248  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Board accuracy: 67.8%, Avg loss: 0.022629 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.045481  [    4/  237]\n",
      "loss: 0.001637  [   84/  237]\n",
      "loss: 0.000103  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005270 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.001020  [    4/  237]\n",
      "loss: 0.000082  [   84/  237]\n",
      "loss: 0.000165  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005086 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.000506  [    4/  237]\n",
      "loss: 0.000075  [   84/  237]\n",
      "loss: 0.011828  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005960 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.000247  [    4/  237]\n",
      "loss: 0.000127  [   84/  237]\n",
      "loss: 0.000146  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006180 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.012193  [    4/  237]\n",
      "loss: 0.002759  [   84/  237]\n",
      "loss: 0.007143  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006454 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.001748  [    4/  237]\n",
      "loss: 0.000052  [   84/  237]\n",
      "loss: 0.012492  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005961 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LG2(\n",
       "  (global_module): Sequential(\n",
       "    (0): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): AvgPool2d(kernel_size=(6, 3), stride=(6, 3), padding=0)\n",
       "  )\n",
       "  (local_module): Sequential(\n",
       "    (0): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(5, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (conv0): Conv2d(20, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv1): Conv2d(40, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv3): Conv2d(10, 5, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv4): Conv2d(5, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = training_process(LG2, 1e-1, 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the larger model has a lot more loss and accuracy spikes during training, but seems to achieving a higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_prediction(model):\n",
    "    idx = random.randrange(len(train_dataset))\n",
    "    print(f\"Showing prediction for training example {idx}\")\n",
    "    example = train_dataset[idx]\n",
    "\n",
    "    x, y = example\n",
    "    with torch.no_grad():\n",
    "        pred = model(x.unsqueeze(0)).argmax(dim=1).squeeze(0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    fig.suptitle(\"Prediction vs reality\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].set_title(\"Reality\")\n",
    "    axs[2].set_title(\"Predicted\")\n",
    "\n",
    "    axs[0].imshow(x)\n",
    "    axs[1].imshow(y)\n",
    "    axs[2].imshow(pred)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 34\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_failed_prediction(model):\n",
    "    success = True\n",
    "    with torch.no_grad():\n",
    "        while success:\n",
    "            idx = random.randrange(len(train_dataset))\n",
    "            x, y = train_dataset[idx]\n",
    "            pred = model(x.unsqueeze(0)).squeeze(0).argmax(0)\n",
    "            success = (pred == y).all(-1).all(-1).item()\n",
    "\n",
    "    print(f\"Showing prediction for training example {idx}\")\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    fig.suptitle(\"Prediction vs reality\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].set_title(\"Reality\")\n",
    "    axs[2].set_title(\"Predicted\")\n",
    "\n",
    "    axs[0].imshow(x)\n",
    "    axs[1].imshow(y)\n",
    "    axs[2].imshow(pred)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 234\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_failed_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LG3(nn.Module):\n",
    "    \"\"\"Like LG2, but with more channels in the local and global modules.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 20, 3),               # (26, 14) -> (24, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),      # (24, 12) -> (12,  6)\n",
    "            nn.Conv2d(20, 40, 3),              # (12,  6) -> (10,  4)\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(kernel_size=(6, 3)), # ( 6,  3) -> ( 1,  1)\n",
    "        )\n",
    "        self.local_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 20, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(20, 40, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv0 = nn.Conv2d(80, 80, 1)\n",
    "        self.conv1 = nn.Conv2d(80, 40, 1)\n",
    "        self.conv2 = nn.Conv2d(40, 20, 1)\n",
    "        self.conv3 = nn.Conv2d(20, 10, 1)\n",
    "        self.conv4 = nn.Conv2d(10, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((0, 3, 1, 2)) # Move channels/classes to dimension 1\n",
    "        x = F.pad(x, (2, 2, 2, 2)) # Zero-pad 2 cells on each side\n",
    "        x_local = self.local_module(x) # Extract local information\n",
    "        x_global = self.global_module(x) # Extract global information\n",
    "        x_global = x_global.repeat(1, 1, 22, 10) # Broadcast global information to image dimensions\n",
    "        x = torch.cat((x_local, x_global), dim=1) # Combine local and global information\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        logits = F.log_softmax(self.conv4(x), dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.783855  [    4/  237]\n",
      "loss: 0.313248  [   84/  237]\n",
      "loss: 0.226637  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297671 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.314827  [    4/  237]\n",
      "loss: 0.325039  [   84/  237]\n",
      "loss: 0.314699  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294697 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.315461  [    4/  237]\n",
      "loss: 0.304429  [   84/  237]\n",
      "loss: 0.293592  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294746 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.293543  [    4/  237]\n",
      "loss: 0.261682  [   84/  237]\n",
      "loss: 0.239204  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294718 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.198530  [    4/  237]\n",
      "loss: 0.271698  [   84/  237]\n",
      "loss: 0.368152  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294918 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.345605  [    4/  237]\n",
      "loss: 0.260531  [   84/  237]\n",
      "loss: 0.196040  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.296169 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.250089  [    4/  237]\n",
      "loss: 0.312506  [   84/  237]\n",
      "loss: 0.333978  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.292782 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.259371  [    4/  237]\n",
      "loss: 0.228538  [   84/  237]\n",
      "loss: 0.171984  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.289078 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.338187  [    4/  237]\n",
      "loss: 0.385563  [   84/  237]\n",
      "loss: 0.222690  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.263245 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.328704  [    4/  237]\n",
      "loss: 0.282418  [   84/  237]\n",
      "loss: 0.169617  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.166814 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.209386  [    4/  237]\n",
      "loss: 0.104653  [   84/  237]\n",
      "loss: 0.073247  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.1%, Board accuracy: 0.0%, Avg loss: 0.106674 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.089854  [    4/  237]\n",
      "loss: 0.094538  [   84/  237]\n",
      "loss: 0.096695  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 0.0%, Avg loss: 0.080384 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.062882  [    4/  237]\n",
      "loss: 0.084416  [   84/  237]\n",
      "loss: 0.054390  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 8.3%, Avg loss: 0.071426 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.126418  [    4/  237]\n",
      "loss: 0.093144  [   84/  237]\n",
      "loss: 0.049239  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 11.7%, Avg loss: 0.069496 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.090496  [    4/  237]\n",
      "loss: 0.065866  [   84/  237]\n",
      "loss: 0.081864  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Board accuracy: 20.0%, Avg loss: 0.066718 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.086576  [    4/  237]\n",
      "loss: 0.059037  [   84/  237]\n",
      "loss: 0.047912  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 17.2%, Avg loss: 0.064357 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.049259  [    4/  237]\n",
      "loss: 0.089929  [   84/  237]\n",
      "loss: 0.085623  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 22.2%, Avg loss: 0.061617 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.070482  [    4/  237]\n",
      "loss: 0.020964  [   84/  237]\n",
      "loss: 0.025327  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.048892 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.049538  [    4/  237]\n",
      "loss: 0.025372  [   84/  237]\n",
      "loss: 0.017872  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 0.0%, Avg loss: 0.034431 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.026296  [    4/  237]\n",
      "loss: 0.020265  [   84/  237]\n",
      "loss: 0.016619  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 68.3%, Avg loss: 0.022647 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.009190  [    4/  237]\n",
      "loss: 0.042256  [   84/  237]\n",
      "loss: 0.019048  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 64.4%, Avg loss: 0.020482 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.012710  [    4/  237]\n",
      "loss: 0.007944  [   84/  237]\n",
      "loss: 0.045302  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 65.0%, Avg loss: 0.017195 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.017518  [    4/  237]\n",
      "loss: 0.010150  [   84/  237]\n",
      "loss: 0.003321  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 67.8%, Avg loss: 0.017332 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.010469  [    4/  237]\n",
      "loss: 0.012662  [   84/  237]\n",
      "loss: 0.014873  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.014163 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.008694  [    4/  237]\n",
      "loss: 0.004922  [   84/  237]\n",
      "loss: 0.006824  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.014090 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.003735  [    4/  237]\n",
      "loss: 0.036810  [   84/  237]\n",
      "loss: 0.015031  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.013592 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.041526  [    4/  237]\n",
      "loss: 0.038653  [   84/  237]\n",
      "loss: 0.040312  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.013185 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.003075  [    4/  237]\n",
      "loss: 0.003979  [   84/  237]\n",
      "loss: 0.002992  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 58.9%, Avg loss: 0.014038 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.008948  [    4/  237]\n",
      "loss: 0.002283  [   84/  237]\n",
      "loss: 0.001713  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.012835 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.005156  [    4/  237]\n",
      "loss: 0.003826  [   84/  237]\n",
      "loss: 0.017914  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.011734 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.002464  [    4/  237]\n",
      "loss: 0.005086  [   84/  237]\n",
      "loss: 0.006397  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.011408 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.002515  [    4/  237]\n",
      "loss: 0.040308  [   84/  237]\n",
      "loss: 0.002262  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.012813 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.001224  [    4/  237]\n",
      "loss: 0.001016  [   84/  237]\n",
      "loss: 0.001017  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.011745 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.002139  [    4/  237]\n",
      "loss: 0.001108  [   84/  237]\n",
      "loss: 0.003602  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.011551 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.001173  [    4/  237]\n",
      "loss: 0.002078  [   84/  237]\n",
      "loss: 0.019619  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.010549 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.023926  [    4/  237]\n",
      "loss: 0.024042  [   84/  237]\n",
      "loss: 0.003324  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.010422 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.001813  [    4/  237]\n",
      "loss: 0.021628  [   84/  237]\n",
      "loss: 0.003784  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.011937 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.004783  [    4/  237]\n",
      "loss: 0.001152  [   84/  237]\n",
      "loss: 0.001000  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.010870 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.002995  [    4/  237]\n",
      "loss: 0.028300  [   84/  237]\n",
      "loss: 0.001540  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 47.2%, Avg loss: 0.020792 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.003041  [    4/  237]\n",
      "loss: 0.001109  [   84/  237]\n",
      "loss: 0.009702  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.2%, Avg loss: 0.010953 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.001206  [    4/  237]\n",
      "loss: 0.003343  [   84/  237]\n",
      "loss: 0.029188  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010094 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.000753  [    4/  237]\n",
      "loss: 0.000963  [   84/  237]\n",
      "loss: 0.003481  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.010268 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.000720  [    4/  237]\n",
      "loss: 0.002026  [   84/  237]\n",
      "loss: 0.051497  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.010869 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.000579  [    4/  237]\n",
      "loss: 0.001220  [   84/  237]\n",
      "loss: 0.001078  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009174 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.027314  [    4/  237]\n",
      "loss: 0.019355  [   84/  237]\n",
      "loss: 0.031844  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009077 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.000740  [    4/  237]\n",
      "loss: 0.017570  [   84/  237]\n",
      "loss: 0.002651  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.8%, Avg loss: 0.011168 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.001529  [    4/  237]\n",
      "loss: 0.000486  [   84/  237]\n",
      "loss: 0.003792  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.011002 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.005038  [    4/  237]\n",
      "loss: 0.000686  [   84/  237]\n",
      "loss: 0.000601  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.009451 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.001063  [    4/  237]\n",
      "loss: 0.011934  [   84/  237]\n",
      "loss: 0.001911  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008796 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.000766  [    4/  237]\n",
      "loss: 0.003708  [   84/  237]\n",
      "loss: 0.001212  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009183 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.000758  [    4/  237]\n",
      "loss: 0.000779  [   84/  237]\n",
      "loss: 0.020811  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.009310 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.001377  [    4/  237]\n",
      "loss: 0.000531  [   84/  237]\n",
      "loss: 0.000548  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009163 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.000684  [    4/  237]\n",
      "loss: 0.020206  [   84/  237]\n",
      "loss: 0.002204  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.6%, Avg loss: 0.009934 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.000795  [    4/  237]\n",
      "loss: 0.001228  [   84/  237]\n",
      "loss: 0.002805  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008597 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.017021  [    4/  237]\n",
      "loss: 0.000535  [   84/  237]\n",
      "loss: 0.000716  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.007874 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.000750  [    4/  237]\n",
      "loss: 0.002153  [   84/  237]\n",
      "loss: 0.002494  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.009853 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.009322  [    4/  237]\n",
      "loss: 0.000759  [   84/  237]\n",
      "loss: 0.000706  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.009940 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.000620  [    4/  237]\n",
      "loss: 0.002047  [   84/  237]\n",
      "loss: 0.001491  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.010113 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.000425  [    4/  237]\n",
      "loss: 0.000961  [   84/  237]\n",
      "loss: 0.000411  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008926 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.025388  [    4/  237]\n",
      "loss: 0.035568  [   84/  237]\n",
      "loss: 0.004060  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.009597 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.000759  [    4/  237]\n",
      "loss: 0.007186  [   84/  237]\n",
      "loss: 0.022658  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008280 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.001684  [    4/  237]\n",
      "loss: 0.000568  [   84/  237]\n",
      "loss: 0.002980  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.007037 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.000784  [    4/  237]\n",
      "loss: 0.000485  [   84/  237]\n",
      "loss: 0.000568  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007784 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.002534  [    4/  237]\n",
      "loss: 0.001448  [   84/  237]\n",
      "loss: 0.001344  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.007149 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.002328  [    4/  237]\n",
      "loss: 0.001241  [   84/  237]\n",
      "loss: 0.002216  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008645 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.028918  [    4/  237]\n",
      "loss: 0.002065  [   84/  237]\n",
      "loss: 0.000981  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.009656 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.024245  [    4/  237]\n",
      "loss: 0.001153  [   84/  237]\n",
      "loss: 0.000525  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.008015 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.009528  [    4/  237]\n",
      "loss: 0.004425  [   84/  237]\n",
      "loss: 0.001883  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.008324 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.000271  [    4/  237]\n",
      "loss: 0.000654  [   84/  237]\n",
      "loss: 0.001519  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006786 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.000507  [    4/  237]\n",
      "loss: 0.000639  [   84/  237]\n",
      "loss: 0.000451  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.006938 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.000590  [    4/  237]\n",
      "loss: 0.013988  [   84/  237]\n",
      "loss: 0.001025  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.007782 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.000751  [    4/  237]\n",
      "loss: 0.013057  [   84/  237]\n",
      "loss: 0.000981  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 57.2%, Avg loss: 0.017739 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.002761  [    4/  237]\n",
      "loss: 0.011325  [   84/  237]\n",
      "loss: 0.000343  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006372 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.001806  [    4/  237]\n",
      "loss: 0.002748  [   84/  237]\n",
      "loss: 0.000539  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.007691 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.000335  [    4/  237]\n",
      "loss: 0.000729  [   84/  237]\n",
      "loss: 0.010604  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.006753 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.000456  [    4/  237]\n",
      "loss: 0.000524  [   84/  237]\n",
      "loss: 0.003147  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.007265 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.000170  [    4/  237]\n",
      "loss: 0.000479  [   84/  237]\n",
      "loss: 0.002417  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009104 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.000459  [    4/  237]\n",
      "loss: 0.000411  [   84/  237]\n",
      "loss: 0.006773  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006369 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.000580  [    4/  237]\n",
      "loss: 0.000618  [   84/  237]\n",
      "loss: 0.005012  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006299 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.000720  [    4/  237]\n",
      "loss: 0.000096  [   84/  237]\n",
      "loss: 0.000450  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005611 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.002777  [    4/  237]\n",
      "loss: 0.002765  [   84/  237]\n",
      "loss: 0.000211  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007449 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.002043  [    4/  237]\n",
      "loss: 0.000621  [   84/  237]\n",
      "loss: 0.000444  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008103 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.000609  [    4/  237]\n",
      "loss: 0.026598  [   84/  237]\n",
      "loss: 0.000643  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008794 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.002199  [    4/  237]\n",
      "loss: 0.002733  [   84/  237]\n",
      "loss: 0.010492  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006508 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.000210  [    4/  237]\n",
      "loss: 0.000888  [   84/  237]\n",
      "loss: 0.000180  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007665 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.003699  [    4/  237]\n",
      "loss: 0.003647  [   84/  237]\n",
      "loss: 0.000225  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006015 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.003412  [    4/  237]\n",
      "loss: 0.019759  [   84/  237]\n",
      "loss: 0.000529  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.005981 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.002924  [    4/  237]\n",
      "loss: 0.000648  [   84/  237]\n",
      "loss: 0.005525  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005713 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.001002  [    4/  237]\n",
      "loss: 0.015564  [   84/  237]\n",
      "loss: 0.001217  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006198 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.004536  [    4/  237]\n",
      "loss: 0.000581  [   84/  237]\n",
      "loss: 0.000373  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006273 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.000521  [    4/  237]\n",
      "loss: 0.000569  [   84/  237]\n",
      "loss: 0.000816  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.006969 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.000229  [    4/  237]\n",
      "loss: 0.003303  [   84/  237]\n",
      "loss: 0.000215  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005366 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.000212  [    4/  237]\n",
      "loss: 0.003281  [   84/  237]\n",
      "loss: 0.000804  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006804 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.000231  [    4/  237]\n",
      "loss: 0.000410  [   84/  237]\n",
      "loss: 0.000284  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006317 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.000356  [    4/  237]\n",
      "loss: 0.000801  [   84/  237]\n",
      "loss: 0.000449  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006096 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.013712  [    4/  237]\n",
      "loss: 0.000600  [   84/  237]\n",
      "loss: 0.000405  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006566 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.000457  [    4/  237]\n",
      "loss: 0.000287  [   84/  237]\n",
      "loss: 0.000073  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.006153 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.000742  [    4/  237]\n",
      "loss: 0.000123  [   84/  237]\n",
      "loss: 0.000243  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005246 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.004823  [    4/  237]\n",
      "loss: 0.001579  [   84/  237]\n",
      "loss: 0.000193  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005118 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.000479  [    4/  237]\n",
      "loss: 0.000439  [   84/  237]\n",
      "loss: 0.009668  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.005866 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.001849  [    4/  237]\n",
      "loss: 0.000085  [   84/  237]\n",
      "loss: 0.000167  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005864 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.000632  [    4/  237]\n",
      "loss: 0.001928  [   84/  237]\n",
      "loss: 0.000067  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.005964 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.000608  [    4/  237]\n",
      "loss: 0.018138  [   84/  237]\n",
      "loss: 0.001975  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005235 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.000396  [    4/  237]\n",
      "loss: 0.000121  [   84/  237]\n",
      "loss: 0.000168  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 94.5%, Board accuracy: 0.0%, Avg loss: 0.194513 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.127706  [    4/  237]\n",
      "loss: 0.000787  [   84/  237]\n",
      "loss: 0.000570  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005346 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.000702  [    4/  237]\n",
      "loss: 0.000185  [   84/  237]\n",
      "loss: 0.006464  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.005993 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.005628  [    4/  237]\n",
      "loss: 0.001601  [   84/  237]\n",
      "loss: 0.000475  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005820 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.000501  [    4/  237]\n",
      "loss: 0.000314  [   84/  237]\n",
      "loss: 0.000290  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007031 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.000943  [    4/  237]\n",
      "loss: 0.000505  [   84/  237]\n",
      "loss: 0.000785  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.005467 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.000680  [    4/  237]\n",
      "loss: 0.000198  [   84/  237]\n",
      "loss: 0.000212  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.005231 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.009552  [    4/  237]\n",
      "loss: 0.000461  [   84/  237]\n",
      "loss: 0.005546  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006951 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.022752  [    4/  237]\n",
      "loss: 0.000162  [   84/  237]\n",
      "loss: 0.000899  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005092 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.000292  [    4/  237]\n",
      "loss: 0.001040  [   84/  237]\n",
      "loss: 0.000176  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005601 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.002286  [    4/  237]\n",
      "loss: 0.011222  [   84/  237]\n",
      "loss: 0.001721  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006796 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.000181  [    4/  237]\n",
      "loss: 0.000213  [   84/  237]\n",
      "loss: 0.000565  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006630 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.000869  [    4/  237]\n",
      "loss: 0.002627  [   84/  237]\n",
      "loss: 0.000218  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005774 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.000109  [    4/  237]\n",
      "loss: 0.000149  [   84/  237]\n",
      "loss: 0.004490  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005677 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.002122  [    4/  237]\n",
      "loss: 0.000088  [   84/  237]\n",
      "loss: 0.000270  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006392 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.021323  [    4/  237]\n",
      "loss: 0.000251  [   84/  237]\n",
      "loss: 0.000371  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005545 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.000247  [    4/  237]\n",
      "loss: 0.000422  [   84/  237]\n",
      "loss: 0.000128  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006359 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.000698  [    4/  237]\n",
      "loss: 0.000170  [   84/  237]\n",
      "loss: 0.000287  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.005801 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.000500  [    4/  237]\n",
      "loss: 0.000297  [   84/  237]\n",
      "loss: 0.003244  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 15.0%, Avg loss: 0.052795 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.039137  [    4/  237]\n",
      "loss: 0.000275  [   84/  237]\n",
      "loss: 0.000378  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006164 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.000085  [    4/  237]\n",
      "loss: 0.000604  [   84/  237]\n",
      "loss: 0.000137  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005673 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.001808  [    4/  237]\n",
      "loss: 0.000368  [   84/  237]\n",
      "loss: 0.031216  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005607 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.000847  [    4/  237]\n",
      "loss: 0.000161  [   84/  237]\n",
      "loss: 0.007558  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006013 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.010159  [    4/  237]\n",
      "loss: 0.000465  [   84/  237]\n",
      "loss: 0.000623  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007730 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.000139  [    4/  237]\n",
      "loss: 0.013927  [   84/  237]\n",
      "loss: 0.000089  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005169 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.000316  [    4/  237]\n",
      "loss: 0.001457  [   84/  237]\n",
      "loss: 0.000082  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005522 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.000514  [    4/  237]\n",
      "loss: 0.000273  [   84/  237]\n",
      "loss: 0.000313  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005942 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.000175  [    4/  237]\n",
      "loss: 0.000505  [   84/  237]\n",
      "loss: 0.000704  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005450 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.000441  [    4/  237]\n",
      "loss: 0.000112  [   84/  237]\n",
      "loss: 0.000122  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005004 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.000249  [    4/  237]\n",
      "loss: 0.000203  [   84/  237]\n",
      "loss: 0.000212  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Board accuracy: 6.7%, Avg loss: 0.085248 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.135665  [    4/  237]\n",
      "loss: 0.000052  [   84/  237]\n",
      "loss: 0.002675  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006136 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.001715  [    4/  237]\n",
      "loss: 0.000319  [   84/  237]\n",
      "loss: 0.000686  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006100 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.001792  [    4/  237]\n",
      "loss: 0.000657  [   84/  237]\n",
      "loss: 0.000083  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006343 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.000098  [    4/  237]\n",
      "loss: 0.010140  [   84/  237]\n",
      "loss: 0.000147  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005326 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.000575  [    4/  237]\n",
      "loss: 0.014110  [   84/  237]\n",
      "loss: 0.000108  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005739 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.000308  [    4/  237]\n",
      "loss: 0.000120  [   84/  237]\n",
      "loss: 0.000138  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009739 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.000207  [    4/  237]\n",
      "loss: 0.000228  [   84/  237]\n",
      "loss: 0.000189  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006586 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.000216  [    4/  237]\n",
      "loss: 0.000555  [   84/  237]\n",
      "loss: 0.000805  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006113 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.001151  [    4/  237]\n",
      "loss: 0.000365  [   84/  237]\n",
      "loss: 0.000287  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005176 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.000325  [    4/  237]\n",
      "loss: 0.005031  [   84/  237]\n",
      "loss: 0.000145  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005394 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.000102  [    4/  237]\n",
      "loss: 0.001931  [   84/  237]\n",
      "loss: 0.000055  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005537 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.010720  [    4/  237]\n",
      "loss: 0.000117  [   84/  237]\n",
      "loss: 0.000169  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006380 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.014157  [    4/  237]\n",
      "loss: 0.000190  [   84/  237]\n",
      "loss: 0.016651  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005965 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.000300  [    4/  237]\n",
      "loss: 0.007835  [   84/  237]\n",
      "loss: 0.010425  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005460 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.000076  [    4/  237]\n",
      "loss: 0.000139  [   84/  237]\n",
      "loss: 0.001808  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005239 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.000255  [    4/  237]\n",
      "loss: 0.000111  [   84/  237]\n",
      "loss: 0.000212  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006496 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.006405  [    4/  237]\n",
      "loss: 0.009664  [   84/  237]\n",
      "loss: 0.000143  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005326 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.001455  [    4/  237]\n",
      "loss: 0.000114  [   84/  237]\n",
      "loss: 0.000078  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005764 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.000381  [    4/  237]\n",
      "loss: 0.000592  [   84/  237]\n",
      "loss: 0.004367  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005909 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.000303  [    4/  237]\n",
      "loss: 0.000095  [   84/  237]\n",
      "loss: 0.000590  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006005 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.000055  [    4/  237]\n",
      "loss: 0.000434  [   84/  237]\n",
      "loss: 0.000143  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005090 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.000430  [    4/  237]\n",
      "loss: 0.000124  [   84/  237]\n",
      "loss: 0.000355  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004850 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.000302  [    4/  237]\n",
      "loss: 0.000516  [   84/  237]\n",
      "loss: 0.000062  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005244 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.000428  [    4/  237]\n",
      "loss: 0.000085  [   84/  237]\n",
      "loss: 0.000051  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005791 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.041822  [    4/  237]\n",
      "loss: 0.001224  [   84/  237]\n",
      "loss: 0.011430  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005665 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.000057  [    4/  237]\n",
      "loss: 0.000153  [   84/  237]\n",
      "loss: 0.000336  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005036 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.000508  [    4/  237]\n",
      "loss: 0.000082  [   84/  237]\n",
      "loss: 0.011622  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006452 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.000608  [    4/  237]\n",
      "loss: 0.000080  [   84/  237]\n",
      "loss: 0.000053  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005566 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.001837  [    4/  237]\n",
      "loss: 0.000859  [   84/  237]\n",
      "loss: 0.000102  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005410 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.000280  [    4/  237]\n",
      "loss: 0.000073  [   84/  237]\n",
      "loss: 0.000364  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004889 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.000304  [    4/  237]\n",
      "loss: 0.018218  [   84/  237]\n",
      "loss: 0.009917  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006705 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.000273  [    4/  237]\n",
      "loss: 0.000060  [   84/  237]\n",
      "loss: 0.000080  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Board accuracy: 5.0%, Avg loss: 0.100246 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.120944  [    4/  237]\n",
      "loss: 0.000165  [   84/  237]\n",
      "loss: 0.000206  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004961 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.001327  [    4/  237]\n",
      "loss: 0.000167  [   84/  237]\n",
      "loss: 0.001334  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004830 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.001123  [    4/  237]\n",
      "loss: 0.006222  [   84/  237]\n",
      "loss: 0.000407  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004786 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.000236  [    4/  237]\n",
      "loss: 0.000228  [   84/  237]\n",
      "loss: 0.000067  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005330 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.000167  [    4/  237]\n",
      "loss: 0.003461  [   84/  237]\n",
      "loss: 0.000146  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005549 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.000092  [    4/  237]\n",
      "loss: 0.000093  [   84/  237]\n",
      "loss: 0.017506  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004943 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.000150  [    4/  237]\n",
      "loss: 0.002143  [   84/  237]\n",
      "loss: 0.000127  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005893 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.002013  [    4/  237]\n",
      "loss: 0.000242  [   84/  237]\n",
      "loss: 0.000238  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004796 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.000223  [    4/  237]\n",
      "loss: 0.000748  [   84/  237]\n",
      "loss: 0.000110  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006428 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.001066  [    4/  237]\n",
      "loss: 0.011869  [   84/  237]\n",
      "loss: 0.000173  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004894 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.021331  [    4/  237]\n",
      "loss: 0.000196  [   84/  237]\n",
      "loss: 0.000113  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005805 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.000146  [    4/  237]\n",
      "loss: 0.000323  [   84/  237]\n",
      "loss: 0.000167  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004835 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.000143  [    4/  237]\n",
      "loss: 0.000196  [   84/  237]\n",
      "loss: 0.000386  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006685 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.013073  [    4/  237]\n",
      "loss: 0.000235  [   84/  237]\n",
      "loss: 0.000466  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005384 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.000082  [    4/  237]\n",
      "loss: 0.000113  [   84/  237]\n",
      "loss: 0.000232  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005176 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.003334  [    4/  237]\n",
      "loss: 0.000081  [   84/  237]\n",
      "loss: 0.001868  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004944 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.000209  [    4/  237]\n",
      "loss: 0.000070  [   84/  237]\n",
      "loss: 0.001273  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005178 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.000500  [    4/  237]\n",
      "loss: 0.014039  [   84/  237]\n",
      "loss: 0.000083  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005330 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.000114  [    4/  237]\n",
      "loss: 0.003103  [   84/  237]\n",
      "loss: 0.015848  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006457 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.000041  [    4/  237]\n",
      "loss: 0.023849  [   84/  237]\n",
      "loss: 0.000063  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004917 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.000763  [    4/  237]\n",
      "loss: 0.000062  [   84/  237]\n",
      "loss: 0.001920  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006494 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.000053  [    4/  237]\n",
      "loss: 0.021485  [   84/  237]\n",
      "loss: 0.000245  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004945 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.000516  [    4/  237]\n",
      "loss: 0.001194  [   84/  237]\n",
      "loss: 0.000089  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.005696 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.000093  [    4/  237]\n",
      "loss: 0.000062  [   84/  237]\n",
      "loss: 0.000148  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005083 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.000459  [    4/  237]\n",
      "loss: 0.000231  [   84/  237]\n",
      "loss: 0.000115  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004753 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.000461  [    4/  237]\n",
      "loss: 0.003198  [   84/  237]\n",
      "loss: 0.000126  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005006 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.000557  [    4/  237]\n",
      "loss: 0.000157  [   84/  237]\n",
      "loss: 0.024378  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005684 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.000376  [    4/  237]\n",
      "loss: 0.000422  [   84/  237]\n",
      "loss: 0.000209  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005484 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.000117  [    4/  237]\n",
      "loss: 0.002152  [   84/  237]\n",
      "loss: 0.000175  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004759 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.000335  [    4/  237]\n",
      "loss: 0.000581  [   84/  237]\n",
      "loss: 0.000038  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004872 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.000185  [    4/  237]\n",
      "loss: 0.000110  [   84/  237]\n",
      "loss: 0.003265  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005869 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.000045  [    4/  237]\n",
      "loss: 0.000163  [   84/  237]\n",
      "loss: 0.000404  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005753 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.000117  [    4/  237]\n",
      "loss: 0.000459  [   84/  237]\n",
      "loss: 0.000071  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 10.0%, Avg loss: 0.071491 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.055525  [    4/  237]\n",
      "loss: 0.002197  [   84/  237]\n",
      "loss: 0.000518  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004940 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.000254  [    4/  237]\n",
      "loss: 0.003100  [   84/  237]\n",
      "loss: 0.009794  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004968 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.000168  [    4/  237]\n",
      "loss: 0.000553  [   84/  237]\n",
      "loss: 0.000783  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004798 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.000581  [    4/  237]\n",
      "loss: 0.000196  [   84/  237]\n",
      "loss: 0.000110  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005028 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.000105  [    4/  237]\n",
      "loss: 0.000196  [   84/  237]\n",
      "loss: 0.001638  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004768 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.012458  [    4/  237]\n",
      "loss: 0.000450  [   84/  237]\n",
      "loss: 0.000094  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005007 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.000177  [    4/  237]\n",
      "loss: 0.001489  [   84/  237]\n",
      "loss: 0.002938  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005372 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.000622  [    4/  237]\n",
      "loss: 0.000122  [   84/  237]\n",
      "loss: 0.000145  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004842 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.009604  [    4/  237]\n",
      "loss: 0.000767  [   84/  237]\n",
      "loss: 0.000325  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.005733 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.000153  [    4/  237]\n",
      "loss: 0.000529  [   84/  237]\n",
      "loss: 0.000104  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006343 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.000110  [    4/  237]\n",
      "loss: 0.001170  [   84/  237]\n",
      "loss: 0.000058  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004749 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.000144  [    4/  237]\n",
      "loss: 0.000157  [   84/  237]\n",
      "loss: 0.002189  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005202 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.000062  [    4/  237]\n",
      "loss: 0.000053  [   84/  237]\n",
      "loss: 0.000041  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006559 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.019539  [    4/  237]\n",
      "loss: 0.008774  [   84/  237]\n",
      "loss: 0.003076  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005881 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.017578  [    4/  237]\n",
      "loss: 0.000454  [   84/  237]\n",
      "loss: 0.000093  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005337 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.000116  [    4/  237]\n",
      "loss: 0.000150  [   84/  237]\n",
      "loss: 0.000274  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005470 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.000069  [    4/  237]\n",
      "loss: 0.002372  [   84/  237]\n",
      "loss: 0.000181  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005236 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.002673  [    4/  237]\n",
      "loss: 0.000227  [   84/  237]\n",
      "loss: 0.000189  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004984 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.009203  [    4/  237]\n",
      "loss: 0.000069  [   84/  237]\n",
      "loss: 0.000065  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005197 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.000227  [    4/  237]\n",
      "loss: 0.017762  [   84/  237]\n",
      "loss: 0.000214  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005703 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.000155  [    4/  237]\n",
      "loss: 0.000152  [   84/  237]\n",
      "loss: 0.001371  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005400 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.001224  [    4/  237]\n",
      "loss: 0.000973  [   84/  237]\n",
      "loss: 0.000426  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005125 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.000178  [    4/  237]\n",
      "loss: 0.000052  [   84/  237]\n",
      "loss: 0.008909  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004717 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.000844  [    4/  237]\n",
      "loss: 0.000072  [   84/  237]\n",
      "loss: 0.000070  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005111 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.000064  [    4/  237]\n",
      "loss: 0.000137  [   84/  237]\n",
      "loss: 0.000486  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005908 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.000167  [    4/  237]\n",
      "loss: 0.000431  [   84/  237]\n",
      "loss: 0.000096  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005223 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.001843  [    4/  237]\n",
      "loss: 0.000097  [   84/  237]\n",
      "loss: 0.000352  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005508 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.000062  [    4/  237]\n",
      "loss: 0.017026  [   84/  237]\n",
      "loss: 0.000174  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006119 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.000055  [    4/  237]\n",
      "loss: 0.000039  [   84/  237]\n",
      "loss: 0.000073  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005709 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.000033  [    4/  237]\n",
      "loss: 0.000460  [   84/  237]\n",
      "loss: 0.000062  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005050 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.000228  [    4/  237]\n",
      "loss: 0.000108  [   84/  237]\n",
      "loss: 0.002216  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004989 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.000249  [    4/  237]\n",
      "loss: 0.000060  [   84/  237]\n",
      "loss: 0.000152  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004871 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.001233  [    4/  237]\n",
      "loss: 0.002524  [   84/  237]\n",
      "loss: 0.000256  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005296 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.000088  [    4/  237]\n",
      "loss: 0.000180  [   84/  237]\n",
      "loss: 0.000103  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005797 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.017779  [    4/  237]\n",
      "loss: 0.000135  [   84/  237]\n",
      "loss: 0.000065  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005678 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.012142  [    4/  237]\n",
      "loss: 0.003890  [   84/  237]\n",
      "loss: 0.002706  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.004995 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.000202  [    4/  237]\n",
      "loss: 0.000314  [   84/  237]\n",
      "loss: 0.000390  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005634 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.000040  [    4/  237]\n",
      "loss: 0.000087  [   84/  237]\n",
      "loss: 0.000936  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004736 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.000078  [    4/  237]\n",
      "loss: 0.008854  [   84/  237]\n",
      "loss: 0.000148  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004704 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.010988  [    4/  237]\n",
      "loss: 0.002480  [   84/  237]\n",
      "loss: 0.000130  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005773 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.000031  [    4/  237]\n",
      "loss: 0.000071  [   84/  237]\n",
      "loss: 0.000276  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005767 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.000027  [    4/  237]\n",
      "loss: 0.002192  [   84/  237]\n",
      "loss: 0.000041  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005138 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.000080  [    4/  237]\n",
      "loss: 0.000761  [   84/  237]\n",
      "loss: 0.000043  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005888 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.000120  [    4/  237]\n",
      "loss: 0.018770  [   84/  237]\n",
      "loss: 0.000295  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 86.7%, Avg loss: 0.011847 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.010522  [    4/  237]\n",
      "loss: 0.000100  [   84/  237]\n",
      "loss: 0.000075  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006234 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.001364  [    4/  237]\n",
      "loss: 0.000051  [   84/  237]\n",
      "loss: 0.000391  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.005243 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.000659  [    4/  237]\n",
      "loss: 0.000647  [   84/  237]\n",
      "loss: 0.000490  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005598 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.000058  [    4/  237]\n",
      "loss: 0.001727  [   84/  237]\n",
      "loss: 0.000153  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005271 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.001174  [    4/  237]\n",
      "loss: 0.000211  [   84/  237]\n",
      "loss: 0.000417  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.004924 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.001762  [    4/  237]\n",
      "loss: 0.000291  [   84/  237]\n",
      "loss: 0.000332  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004874 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.000229  [    4/  237]\n",
      "loss: 0.000187  [   84/  237]\n",
      "loss: 0.000075  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005230 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.015187  [    4/  237]\n",
      "loss: 0.007980  [   84/  237]\n",
      "loss: 0.000083  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004989 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.000080  [    4/  237]\n",
      "loss: 0.000324  [   84/  237]\n",
      "loss: 0.000476  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005092 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.000485  [    4/  237]\n",
      "loss: 0.000385  [   84/  237]\n",
      "loss: 0.014393  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.004833 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.000326  [    4/  237]\n",
      "loss: 0.000452  [   84/  237]\n",
      "loss: 0.000121  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005093 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.000070  [    4/  237]\n",
      "loss: 0.000246  [   84/  237]\n",
      "loss: 0.000063  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004699 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.000117  [    4/  237]\n",
      "loss: 0.000159  [   84/  237]\n",
      "loss: 0.000456  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006310 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.012088  [    4/  237]\n",
      "loss: 0.000174  [   84/  237]\n",
      "loss: 0.000319  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004880 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.000138  [    4/  237]\n",
      "loss: 0.000062  [   84/  237]\n",
      "loss: 0.000645  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005065 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.000083  [    4/  237]\n",
      "loss: 0.000154  [   84/  237]\n",
      "loss: 0.024134  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005161 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.000064  [    4/  237]\n",
      "loss: 0.009743  [   84/  237]\n",
      "loss: 0.000098  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004636 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.010154  [    4/  237]\n",
      "loss: 0.000175  [   84/  237]\n",
      "loss: 0.000038  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005031 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.005247  [    4/  237]\n",
      "loss: 0.000142  [   84/  237]\n",
      "loss: 0.000114  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005296 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.000125  [    4/  237]\n",
      "loss: 0.000065  [   84/  237]\n",
      "loss: 0.011324  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.004937 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.005408  [    4/  237]\n",
      "loss: 0.000044  [   84/  237]\n",
      "loss: 0.000535  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004712 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.000081  [    4/  237]\n",
      "loss: 0.000083  [   84/  237]\n",
      "loss: 0.001283  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004875 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.000067  [    4/  237]\n",
      "loss: 0.000111  [   84/  237]\n",
      "loss: 0.000245  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004680 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.000514  [    4/  237]\n",
      "loss: 0.000193  [   84/  237]\n",
      "loss: 0.000040  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005163 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.000062  [    4/  237]\n",
      "loss: 0.000171  [   84/  237]\n",
      "loss: 0.002050  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005353 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.000098  [    4/  237]\n",
      "loss: 0.000300  [   84/  237]\n",
      "loss: 0.000114  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005147 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.000062  [    4/  237]\n",
      "loss: 0.000131  [   84/  237]\n",
      "loss: 0.000137  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005515 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.006117  [    4/  237]\n",
      "loss: 0.010459  [   84/  237]\n",
      "loss: 0.002814  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004930 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.000119  [    4/  237]\n",
      "loss: 0.000107  [   84/  237]\n",
      "loss: 0.000060  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005051 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.000063  [    4/  237]\n",
      "loss: 0.000350  [   84/  237]\n",
      "loss: 0.000094  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005553 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.000094  [    4/  237]\n",
      "loss: 0.010521  [   84/  237]\n",
      "loss: 0.000444  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.004788 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.001086  [    4/  237]\n",
      "loss: 0.000412  [   84/  237]\n",
      "loss: 0.000032  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004985 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.000231  [    4/  237]\n",
      "loss: 0.002541  [   84/  237]\n",
      "loss: 0.000624  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004605 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.020043  [    4/  237]\n",
      "loss: 0.001225  [   84/  237]\n",
      "loss: 0.000122  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004624 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.002353  [    4/  237]\n",
      "loss: 0.000155  [   84/  237]\n",
      "loss: 0.002077  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005183 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.000041  [    4/  237]\n",
      "loss: 0.000208  [   84/  237]\n",
      "loss: 0.000711  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004897 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.000323  [    4/  237]\n",
      "loss: 0.012390  [   84/  237]\n",
      "loss: 0.000037  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005130 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.000060  [    4/  237]\n",
      "loss: 0.000034  [   84/  237]\n",
      "loss: 0.000196  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004710 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.000076  [    4/  237]\n",
      "loss: 0.000042  [   84/  237]\n",
      "loss: 0.008976  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004859 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.000086  [    4/  237]\n",
      "loss: 0.000042  [   84/  237]\n",
      "loss: 0.000969  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005244 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.000099  [    4/  237]\n",
      "loss: 0.000300  [   84/  237]\n",
      "loss: 0.000055  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005587 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.000177  [    4/  237]\n",
      "loss: 0.012566  [   84/  237]\n",
      "loss: 0.000111  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004724 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.000116  [    4/  237]\n",
      "loss: 0.000068  [   84/  237]\n",
      "loss: 0.000249  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004601 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.000470  [    4/  237]\n",
      "loss: 0.000448  [   84/  237]\n",
      "loss: 0.000081  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004514 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.000109  [    4/  237]\n",
      "loss: 0.000038  [   84/  237]\n",
      "loss: 0.000600  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004812 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.000099  [    4/  237]\n",
      "loss: 0.009179  [   84/  237]\n",
      "loss: 0.012791  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005589 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.000159  [    4/  237]\n",
      "loss: 0.001099  [   84/  237]\n",
      "loss: 0.000619  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004507 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.000154  [    4/  237]\n",
      "loss: 0.000404  [   84/  237]\n",
      "loss: 0.000052  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004571 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.000244  [    4/  237]\n",
      "loss: 0.000066  [   84/  237]\n",
      "loss: 0.000072  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004487 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.000432  [    4/  237]\n",
      "loss: 0.000164  [   84/  237]\n",
      "loss: 0.000137  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005536 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.000135  [    4/  237]\n",
      "loss: 0.001058  [   84/  237]\n",
      "loss: 0.000222  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004730 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.000195  [    4/  237]\n",
      "loss: 0.000070  [   84/  237]\n",
      "loss: 0.009176  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005263 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.000101  [    4/  237]\n",
      "loss: 0.000148  [   84/  237]\n",
      "loss: 0.000036  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004556 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.000252  [    4/  237]\n",
      "loss: 0.000415  [   84/  237]\n",
      "loss: 0.000108  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005134 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.000123  [    4/  237]\n",
      "loss: 0.000056  [   84/  237]\n",
      "loss: 0.000209  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004492 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.000348  [    4/  237]\n",
      "loss: 0.000093  [   84/  237]\n",
      "loss: 0.000577  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005517 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.000090  [    4/  237]\n",
      "loss: 0.000219  [   84/  237]\n",
      "loss: 0.000783  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009046 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.000052  [    4/  237]\n",
      "loss: 0.000039  [   84/  237]\n",
      "loss: 0.000127  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004708 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = training_process(LG3, 1e-1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 24\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 217\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_failed_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LG4(nn.Module):\n",
    "    \"\"\"Like LG3, but with global max pool instead of average pool.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 20, 3),               # (26, 14) -> (24, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),      # (24, 12) -> (12,  6)\n",
    "            nn.Conv2d(20, 40, 3),              # (12,  6) -> (10,  4)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(6, 3)), # ( 6,  3) -> ( 1,  1)\n",
    "        )\n",
    "        self.local_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 20, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(20, 40, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv0 = nn.Conv2d(80, 80, 1)\n",
    "        self.conv1 = nn.Conv2d(80, 40, 1)\n",
    "        self.conv2 = nn.Conv2d(40, 20, 1)\n",
    "        self.conv3 = nn.Conv2d(20, 10, 1)\n",
    "        self.conv4 = nn.Conv2d(10, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((0, 3, 1, 2)) # Move channels/classes to dimension 1\n",
    "        x = F.pad(x, (2, 2, 2, 2)) # Zero-pad 2 cells on each side\n",
    "        x_local = self.local_module(x) # Extract local information\n",
    "        x_global = self.global_module(x) # Extract global information\n",
    "        x_global = x_global.repeat(1, 1, 22, 10) # Broadcast global information to image dimensions\n",
    "        x = torch.cat((x_local, x_global), dim=1) # Combine local and global information\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        logits = F.log_softmax(self.conv4(x), dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.696731  [    4/  237]\n",
      "loss: 0.358483  [   84/  237]\n",
      "loss: 0.250700  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.306244 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.337233  [    4/  237]\n",
      "loss: 0.278220  [   84/  237]\n",
      "loss: 0.224228  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297443 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.190770  [    4/  237]\n",
      "loss: 0.230958  [   84/  237]\n",
      "loss: 0.272729  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295333 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.293928  [    4/  237]\n",
      "loss: 0.325800  [   84/  237]\n",
      "loss: 0.272490  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.298131 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.272494  [    4/  237]\n",
      "loss: 0.208709  [   84/  237]\n",
      "loss: 0.315250  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297592 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.262029  [    4/  237]\n",
      "loss: 0.369441  [   84/  237]\n",
      "loss: 0.442296  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295874 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.325856  [    4/  237]\n",
      "loss: 0.250787  [   84/  237]\n",
      "loss: 0.208413  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.295818 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.347626  [    4/  237]\n",
      "loss: 0.261221  [   84/  237]\n",
      "loss: 0.304225  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297162 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.390801  [    4/  237]\n",
      "loss: 0.187098  [   84/  237]\n",
      "loss: 0.219117  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297307 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.358515  [    4/  237]\n",
      "loss: 0.390645  [   84/  237]\n",
      "loss: 0.228283  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294148 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.421703  [    4/  237]\n",
      "loss: 0.325318  [   84/  237]\n",
      "loss: 0.293107  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.297401 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.292880  [    4/  237]\n",
      "loss: 0.346011  [   84/  237]\n",
      "loss: 0.303332  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.294922 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.218735  [    4/  237]\n",
      "loss: 0.271191  [   84/  237]\n",
      "loss: 0.249205  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.293816 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.365177  [    4/  237]\n",
      "loss: 0.343225  [   84/  237]\n",
      "loss: 0.331768  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.293441 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.404208  [    4/  237]\n",
      "loss: 0.369621  [   84/  237]\n",
      "loss: 0.314935  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.282941 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.249869  [    4/  237]\n",
      "loss: 0.224290  [   84/  237]\n",
      "loss: 0.188239  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.247000 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.218150  [    4/  237]\n",
      "loss: 0.292875  [   84/  237]\n",
      "loss: 0.212118  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.3%, Board accuracy: 0.0%, Avg loss: 0.166673 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.156748  [    4/  237]\n",
      "loss: 0.165771  [   84/  237]\n",
      "loss: 0.051338  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Board accuracy: 0.0%, Avg loss: 0.076704 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.055132  [    4/  237]\n",
      "loss: 0.038966  [   84/  237]\n",
      "loss: 0.053104  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 0.0%, Avg loss: 0.066322 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.037690  [    4/  237]\n",
      "loss: 0.076525  [   84/  237]\n",
      "loss: 0.055211  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Board accuracy: 0.0%, Avg loss: 0.058668 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.048522  [    4/  237]\n",
      "loss: 0.047503  [   84/  237]\n",
      "loss: 0.058079  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.047880 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.045324  [    4/  237]\n",
      "loss: 0.060552  [   84/  237]\n",
      "loss: 0.065392  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.039176 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.036655  [    4/  237]\n",
      "loss: 0.035568  [   84/  237]\n",
      "loss: 0.029358  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 1.7%, Avg loss: 0.038814 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.037940  [    4/  237]\n",
      "loss: 0.015526  [   84/  237]\n",
      "loss: 0.041711  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 25.0%, Avg loss: 0.029084 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.026862  [    4/  237]\n",
      "loss: 0.010861  [   84/  237]\n",
      "loss: 0.023830  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 36.1%, Avg loss: 0.022964 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.012182  [    4/  237]\n",
      "loss: 0.008993  [   84/  237]\n",
      "loss: 0.012956  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Board accuracy: 12.2%, Avg loss: 0.024980 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.016071  [    4/  237]\n",
      "loss: 0.010559  [   84/  237]\n",
      "loss: 0.010266  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 38.9%, Avg loss: 0.021072 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.018271  [    4/  237]\n",
      "loss: 0.003291  [   84/  237]\n",
      "loss: 0.007034  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.014849 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.010517  [    4/  237]\n",
      "loss: 0.007339  [   84/  237]\n",
      "loss: 0.042029  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Board accuracy: 0.0%, Avg loss: 0.262018 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.274418  [    4/  237]\n",
      "loss: 0.040387  [   84/  237]\n",
      "loss: 0.013312  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 68.3%, Avg loss: 0.019350 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.010761  [    4/  237]\n",
      "loss: 0.011244  [   84/  237]\n",
      "loss: 0.022927  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 73.3%, Avg loss: 0.016158 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.008079  [    4/  237]\n",
      "loss: 0.009302  [   84/  237]\n",
      "loss: 0.005885  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.015160 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.012678  [    4/  237]\n",
      "loss: 0.007821  [   84/  237]\n",
      "loss: 0.004738  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.014474 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.044597  [    4/  237]\n",
      "loss: 0.003310  [   84/  237]\n",
      "loss: 0.006546  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.1%, Avg loss: 0.014785 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.008652  [    4/  237]\n",
      "loss: 0.037431  [   84/  237]\n",
      "loss: 0.004251  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 56.1%, Avg loss: 0.015915 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.007323  [    4/  237]\n",
      "loss: 0.036917  [   84/  237]\n",
      "loss: 0.003146  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 62.2%, Avg loss: 0.016906 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.004311  [    4/  237]\n",
      "loss: 0.003447  [   84/  237]\n",
      "loss: 0.002113  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.013366 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.004445  [    4/  237]\n",
      "loss: 0.002120  [   84/  237]\n",
      "loss: 0.002131  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 63.9%, Avg loss: 0.015595 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.006281  [    4/  237]\n",
      "loss: 0.004910  [   84/  237]\n",
      "loss: 0.002086  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.012615 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.004442  [    4/  237]\n",
      "loss: 0.004067  [   84/  237]\n",
      "loss: 0.034830  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.012246 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.002916  [    4/  237]\n",
      "loss: 0.003128  [   84/  237]\n",
      "loss: 0.001716  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.6%, Avg loss: 0.011745 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.007167  [    4/  237]\n",
      "loss: 0.004712  [   84/  237]\n",
      "loss: 0.001403  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.012090 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.030971  [    4/  237]\n",
      "loss: 0.022054  [   84/  237]\n",
      "loss: 0.024015  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011337 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.001251  [    4/  237]\n",
      "loss: 0.001650  [   84/  237]\n",
      "loss: 0.001828  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.010077 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.021358  [    4/  237]\n",
      "loss: 0.001498  [   84/  237]\n",
      "loss: 0.001291  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.011485 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.044732  [    4/  237]\n",
      "loss: 0.029968  [   84/  237]\n",
      "loss: 0.001085  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.010853 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.001466  [    4/  237]\n",
      "loss: 0.001283  [   84/  237]\n",
      "loss: 0.005006  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.010490 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.000730  [    4/  237]\n",
      "loss: 0.001280  [   84/  237]\n",
      "loss: 0.039545  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.6%, Avg loss: 0.010752 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.001249  [    4/  237]\n",
      "loss: 0.001418  [   84/  237]\n",
      "loss: 0.000892  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 48.9%, Avg loss: 0.020911 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.019763  [    4/  237]\n",
      "loss: 0.004296  [   84/  237]\n",
      "loss: 0.004659  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 66.1%, Avg loss: 0.010171 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.004333  [    4/  237]\n",
      "loss: 0.001230  [   84/  237]\n",
      "loss: 0.022373  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 57.8%, Avg loss: 0.013834 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.005168  [    4/  237]\n",
      "loss: 0.000983  [   84/  237]\n",
      "loss: 0.039875  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009858 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.002295  [    4/  237]\n",
      "loss: 0.001796  [   84/  237]\n",
      "loss: 0.022420  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009087 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.001625  [    4/  237]\n",
      "loss: 0.004819  [   84/  237]\n",
      "loss: 0.002370  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.010574 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.000682  [    4/  237]\n",
      "loss: 0.033744  [   84/  237]\n",
      "loss: 0.000672  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009027 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.001069  [    4/  237]\n",
      "loss: 0.000602  [   84/  237]\n",
      "loss: 0.038202  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009197 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.018048  [    4/  237]\n",
      "loss: 0.001089  [   84/  237]\n",
      "loss: 0.000612  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.009701 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.000899  [    4/  237]\n",
      "loss: 0.001553  [   84/  237]\n",
      "loss: 0.000964  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.6%, Avg loss: 0.009683 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.001226  [    4/  237]\n",
      "loss: 0.015653  [   84/  237]\n",
      "loss: 0.002024  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 27.8%, Avg loss: 0.052396 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.095105  [    4/  237]\n",
      "loss: 0.002438  [   84/  237]\n",
      "loss: 0.000592  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.2%, Avg loss: 0.010450 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.001232  [    4/  237]\n",
      "loss: 0.032120  [   84/  237]\n",
      "loss: 0.002581  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008423 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.000715  [    4/  237]\n",
      "loss: 0.002146  [   84/  237]\n",
      "loss: 0.001689  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.012162 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.000580  [    4/  237]\n",
      "loss: 0.000636  [   84/  237]\n",
      "loss: 0.002166  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009283 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.000952  [    4/  237]\n",
      "loss: 0.004980  [   84/  237]\n",
      "loss: 0.001113  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.009126 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.034459  [    4/  237]\n",
      "loss: 0.000855  [   84/  237]\n",
      "loss: 0.006104  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.009449 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.001099  [    4/  237]\n",
      "loss: 0.001369  [   84/  237]\n",
      "loss: 0.000676  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008952 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.000814  [    4/  237]\n",
      "loss: 0.000409  [   84/  237]\n",
      "loss: 0.001124  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.009704 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.002952  [    4/  237]\n",
      "loss: 0.003868  [   84/  237]\n",
      "loss: 0.011609  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009129 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.000360  [    4/  237]\n",
      "loss: 0.003732  [   84/  237]\n",
      "loss: 0.031286  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.011326 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.034817  [    4/  237]\n",
      "loss: 0.000347  [   84/  237]\n",
      "loss: 0.000550  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.009085 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.003090  [    4/  237]\n",
      "loss: 0.002665  [   84/  237]\n",
      "loss: 0.001452  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.010862 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.000801  [    4/  237]\n",
      "loss: 0.004011  [   84/  237]\n",
      "loss: 0.001203  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.008548 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.000430  [    4/  237]\n",
      "loss: 0.000593  [   84/  237]\n",
      "loss: 0.000639  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.008511 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.000476  [    4/  237]\n",
      "loss: 0.001023  [   84/  237]\n",
      "loss: 0.000874  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.008095 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.000862  [    4/  237]\n",
      "loss: 0.000900  [   84/  237]\n",
      "loss: 0.028664  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008449 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.000738  [    4/  237]\n",
      "loss: 0.001086  [   84/  237]\n",
      "loss: 0.005563  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008027 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.001089  [    4/  237]\n",
      "loss: 0.001087  [   84/  237]\n",
      "loss: 0.000565  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.008368 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.000545  [    4/  237]\n",
      "loss: 0.000811  [   84/  237]\n",
      "loss: 0.012764  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008683 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.000559  [    4/  237]\n",
      "loss: 0.000711  [   84/  237]\n",
      "loss: 0.000385  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008588 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.003849  [    4/  237]\n",
      "loss: 0.000677  [   84/  237]\n",
      "loss: 0.000372  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008343 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.031432  [    4/  237]\n",
      "loss: 0.001710  [   84/  237]\n",
      "loss: 0.000898  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008274 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.000378  [    4/  237]\n",
      "loss: 0.000689  [   84/  237]\n",
      "loss: 0.003298  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007958 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.001832  [    4/  237]\n",
      "loss: 0.001449  [   84/  237]\n",
      "loss: 0.000842  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007913 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.011579  [    4/  237]\n",
      "loss: 0.000382  [   84/  237]\n",
      "loss: 0.002812  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.010131 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.000488  [    4/  237]\n",
      "loss: 0.016299  [   84/  237]\n",
      "loss: 0.000727  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008210 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.000534  [    4/  237]\n",
      "loss: 0.000821  [   84/  237]\n",
      "loss: 0.030444  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007842 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.000456  [    4/  237]\n",
      "loss: 0.000916  [   84/  237]\n",
      "loss: 0.000356  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007964 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.000884  [    4/  237]\n",
      "loss: 0.000417  [   84/  237]\n",
      "loss: 0.000275  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.008324 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.000675  [    4/  237]\n",
      "loss: 0.002663  [   84/  237]\n",
      "loss: 0.000409  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007752 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.001491  [    4/  237]\n",
      "loss: 0.000562  [   84/  237]\n",
      "loss: 0.000664  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008304 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.000280  [    4/  237]\n",
      "loss: 0.023815  [   84/  237]\n",
      "loss: 0.000720  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007595 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.004463  [    4/  237]\n",
      "loss: 0.004893  [   84/  237]\n",
      "loss: 0.001114  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007610 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.001012  [    4/  237]\n",
      "loss: 0.001263  [   84/  237]\n",
      "loss: 0.000815  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007519 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.000616  [    4/  237]\n",
      "loss: 0.000500  [   84/  237]\n",
      "loss: 0.000903  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007242 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.001059  [    4/  237]\n",
      "loss: 0.030854  [   84/  237]\n",
      "loss: 0.000348  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008220 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.000918  [    4/  237]\n",
      "loss: 0.000447  [   84/  237]\n",
      "loss: 0.000633  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008468 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.000482  [    4/  237]\n",
      "loss: 0.000563  [   84/  237]\n",
      "loss: 0.000606  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007189 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.001172  [    4/  237]\n",
      "loss: 0.022587  [   84/  237]\n",
      "loss: 0.007706  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007647 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.004063  [    4/  237]\n",
      "loss: 0.000335  [   84/  237]\n",
      "loss: 0.001115  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008556 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.000413  [    4/  237]\n",
      "loss: 0.000594  [   84/  237]\n",
      "loss: 0.025562  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.007625 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.023572  [    4/  237]\n",
      "loss: 0.000479  [   84/  237]\n",
      "loss: 0.002459  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007257 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.000458  [    4/  237]\n",
      "loss: 0.001743  [   84/  237]\n",
      "loss: 0.000476  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007477 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.000356  [    4/  237]\n",
      "loss: 0.005240  [   84/  237]\n",
      "loss: 0.003292  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007264 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.003274  [    4/  237]\n",
      "loss: 0.001818  [   84/  237]\n",
      "loss: 0.000460  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007212 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.000424  [    4/  237]\n",
      "loss: 0.001718  [   84/  237]\n",
      "loss: 0.005216  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008106 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.000457  [    4/  237]\n",
      "loss: 0.000415  [   84/  237]\n",
      "loss: 0.005409  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007130 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.000480  [    4/  237]\n",
      "loss: 0.000356  [   84/  237]\n",
      "loss: 0.000391  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007432 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.000294  [    4/  237]\n",
      "loss: 0.012458  [   84/  237]\n",
      "loss: 0.000466  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007773 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.000838  [    4/  237]\n",
      "loss: 0.000555  [   84/  237]\n",
      "loss: 0.000251  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006957 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.000554  [    4/  237]\n",
      "loss: 0.001031  [   84/  237]\n",
      "loss: 0.000952  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007852 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.000809  [    4/  237]\n",
      "loss: 0.029342  [   84/  237]\n",
      "loss: 0.000325  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007916 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.000342  [    4/  237]\n",
      "loss: 0.000351  [   84/  237]\n",
      "loss: 0.000370  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Board accuracy: 10.0%, Avg loss: 0.128065 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.106486  [    4/  237]\n",
      "loss: 0.000252  [   84/  237]\n",
      "loss: 0.000296  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 67.8%, Avg loss: 0.016598 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.005223  [    4/  237]\n",
      "loss: 0.000389  [   84/  237]\n",
      "loss: 0.001069  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007476 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.000434  [    4/  237]\n",
      "loss: 0.000457  [   84/  237]\n",
      "loss: 0.000324  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006917 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.000301  [    4/  237]\n",
      "loss: 0.001062  [   84/  237]\n",
      "loss: 0.000695  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007018 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.000355  [    4/  237]\n",
      "loss: 0.001687  [   84/  237]\n",
      "loss: 0.000259  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007192 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.000393  [    4/  237]\n",
      "loss: 0.000228  [   84/  237]\n",
      "loss: 0.000242  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007421 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.001127  [    4/  237]\n",
      "loss: 0.000222  [   84/  237]\n",
      "loss: 0.000438  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006918 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.000332  [    4/  237]\n",
      "loss: 0.000645  [   84/  237]\n",
      "loss: 0.000448  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007110 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.000243  [    4/  237]\n",
      "loss: 0.000269  [   84/  237]\n",
      "loss: 0.000339  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008977 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.000625  [    4/  237]\n",
      "loss: 0.000397  [   84/  237]\n",
      "loss: 0.000238  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007639 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.000512  [    4/  237]\n",
      "loss: 0.000240  [   84/  237]\n",
      "loss: 0.000392  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007147 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.000701  [    4/  237]\n",
      "loss: 0.021317  [   84/  237]\n",
      "loss: 0.000274  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007592 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.000302  [    4/  237]\n",
      "loss: 0.023540  [   84/  237]\n",
      "loss: 0.000972  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007259 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.000433  [    4/  237]\n",
      "loss: 0.000263  [   84/  237]\n",
      "loss: 0.000261  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 5.0%, Avg loss: 0.101907 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.108043  [    4/  237]\n",
      "loss: 0.000487  [   84/  237]\n",
      "loss: 0.000806  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.007880 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.005683  [    4/  237]\n",
      "loss: 0.000286  [   84/  237]\n",
      "loss: 0.000270  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006970 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.002890  [    4/  237]\n",
      "loss: 0.000473  [   84/  237]\n",
      "loss: 0.001222  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007002 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.020775  [    4/  237]\n",
      "loss: 0.021442  [   84/  237]\n",
      "loss: 0.000249  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007436 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.018408  [    4/  237]\n",
      "loss: 0.005942  [   84/  237]\n",
      "loss: 0.002015  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.008387 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.001285  [    4/  237]\n",
      "loss: 0.000220  [   84/  237]\n",
      "loss: 0.000259  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007327 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.000232  [    4/  237]\n",
      "loss: 0.000350  [   84/  237]\n",
      "loss: 0.000268  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007185 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.000278  [    4/  237]\n",
      "loss: 0.000246  [   84/  237]\n",
      "loss: 0.010954  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007198 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.000385  [    4/  237]\n",
      "loss: 0.000425  [   84/  237]\n",
      "loss: 0.005276  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006892 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.000256  [    4/  237]\n",
      "loss: 0.000352  [   84/  237]\n",
      "loss: 0.000252  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007063 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.005887  [    4/  237]\n",
      "loss: 0.000348  [   84/  237]\n",
      "loss: 0.000234  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006823 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.027850  [    4/  237]\n",
      "loss: 0.002553  [   84/  237]\n",
      "loss: 0.007938  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007116 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.000409  [    4/  237]\n",
      "loss: 0.000287  [   84/  237]\n",
      "loss: 0.000651  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007189 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.000812  [    4/  237]\n",
      "loss: 0.000406  [   84/  237]\n",
      "loss: 0.000394  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.008094 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.005533  [    4/  237]\n",
      "loss: 0.000351  [   84/  237]\n",
      "loss: 0.001345  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007697 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.001704  [    4/  237]\n",
      "loss: 0.000288  [   84/  237]\n",
      "loss: 0.000239  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.007457 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.027475  [    4/  237]\n",
      "loss: 0.005399  [   84/  237]\n",
      "loss: 0.001168  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007123 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.000358  [    4/  237]\n",
      "loss: 0.000523  [   84/  237]\n",
      "loss: 0.000311  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007293 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.000269  [    4/  237]\n",
      "loss: 0.000262  [   84/  237]\n",
      "loss: 0.000213  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007144 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.000292  [    4/  237]\n",
      "loss: 0.006583  [   84/  237]\n",
      "loss: 0.000193  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 18.9%, Avg loss: 0.048768 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.030745  [    4/  237]\n",
      "loss: 0.000286  [   84/  237]\n",
      "loss: 0.000266  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005294 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.000295  [    4/  237]\n",
      "loss: 0.000854  [   84/  237]\n",
      "loss: 0.000510  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005662 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.000867  [    4/  237]\n",
      "loss: 0.000280  [   84/  237]\n",
      "loss: 0.000177  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005152 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.000632  [    4/  237]\n",
      "loss: 0.000255  [   84/  237]\n",
      "loss: 0.012937  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004915 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.000238  [    4/  237]\n",
      "loss: 0.000552  [   84/  237]\n",
      "loss: 0.008403  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004780 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.000153  [    4/  237]\n",
      "loss: 0.002042  [   84/  237]\n",
      "loss: 0.000147  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004784 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.000673  [    4/  237]\n",
      "loss: 0.007830  [   84/  237]\n",
      "loss: 0.000189  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005067 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.000449  [    4/  237]\n",
      "loss: 0.000116  [   84/  237]\n",
      "loss: 0.000119  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005225 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.000288  [    4/  237]\n",
      "loss: 0.000312  [   84/  237]\n",
      "loss: 0.000258  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005678 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.012485  [    4/  237]\n",
      "loss: 0.000156  [   84/  237]\n",
      "loss: 0.000313  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005698 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.000669  [    4/  237]\n",
      "loss: 0.010096  [   84/  237]\n",
      "loss: 0.000180  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004806 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.007880  [    4/  237]\n",
      "loss: 0.000135  [   84/  237]\n",
      "loss: 0.000096  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.005061 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.000892  [    4/  237]\n",
      "loss: 0.000130  [   84/  237]\n",
      "loss: 0.001393  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006556 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.000066  [    4/  237]\n",
      "loss: 0.000302  [   84/  237]\n",
      "loss: 0.000100  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004913 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.000116  [    4/  237]\n",
      "loss: 0.000092  [   84/  237]\n",
      "loss: 0.000358  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004733 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.010510  [    4/  237]\n",
      "loss: 0.000203  [   84/  237]\n",
      "loss: 0.000095  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004766 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.002508  [    4/  237]\n",
      "loss: 0.000526  [   84/  237]\n",
      "loss: 0.000128  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005001 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.000065  [    4/  237]\n",
      "loss: 0.000431  [   84/  237]\n",
      "loss: 0.000145  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004849 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.000073  [    4/  237]\n",
      "loss: 0.000159  [   84/  237]\n",
      "loss: 0.000085  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004990 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.000180  [    4/  237]\n",
      "loss: 0.000047  [   84/  237]\n",
      "loss: 0.000156  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005481 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.000057  [    4/  237]\n",
      "loss: 0.000059  [   84/  237]\n",
      "loss: 0.000041  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004893 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.000047  [    4/  237]\n",
      "loss: 0.000178  [   84/  237]\n",
      "loss: 0.000216  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004817 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.000097  [    4/  237]\n",
      "loss: 0.000116  [   84/  237]\n",
      "loss: 0.003179  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004793 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.000099  [    4/  237]\n",
      "loss: 0.000264  [   84/  237]\n",
      "loss: 0.001010  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005177 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.000058  [    4/  237]\n",
      "loss: 0.010059  [   84/  237]\n",
      "loss: 0.007805  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006819 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.000262  [    4/  237]\n",
      "loss: 0.000150  [   84/  237]\n",
      "loss: 0.007300  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005798 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.000040  [    4/  237]\n",
      "loss: 0.000140  [   84/  237]\n",
      "loss: 0.000046  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005580 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.000141  [    4/  237]\n",
      "loss: 0.000206  [   84/  237]\n",
      "loss: 0.004158  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004830 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.000047  [    4/  237]\n",
      "loss: 0.000460  [   84/  237]\n",
      "loss: 0.000057  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005367 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.009831  [    4/  237]\n",
      "loss: 0.000048  [   84/  237]\n",
      "loss: 0.002037  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.004963 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.000139  [    4/  237]\n",
      "loss: 0.002647  [   84/  237]\n",
      "loss: 0.000230  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005138 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.003001  [    4/  237]\n",
      "loss: 0.000062  [   84/  237]\n",
      "loss: 0.000067  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005426 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.000039  [    4/  237]\n",
      "loss: 0.012442  [   84/  237]\n",
      "loss: 0.000163  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004867 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.000525  [    4/  237]\n",
      "loss: 0.000043  [   84/  237]\n",
      "loss: 0.000344  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.004941 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.000039  [    4/  237]\n",
      "loss: 0.000038  [   84/  237]\n",
      "loss: 0.001035  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004811 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.000137  [    4/  237]\n",
      "loss: 0.000132  [   84/  237]\n",
      "loss: 0.003190  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004960 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.000887  [    4/  237]\n",
      "loss: 0.000105  [   84/  237]\n",
      "loss: 0.000060  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005470 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.000067  [    4/  237]\n",
      "loss: 0.009046  [   84/  237]\n",
      "loss: 0.000173  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005210 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.000032  [    4/  237]\n",
      "loss: 0.000433  [   84/  237]\n",
      "loss: 0.000051  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007528 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.000035  [    4/  237]\n",
      "loss: 0.000025  [   84/  237]\n",
      "loss: 0.002638  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005165 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.000045  [    4/  237]\n",
      "loss: 0.000405  [   84/  237]\n",
      "loss: 0.001574  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004860 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.009152  [    4/  237]\n",
      "loss: 0.000042  [   84/  237]\n",
      "loss: 0.000081  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004950 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.000167  [    4/  237]\n",
      "loss: 0.000047  [   84/  237]\n",
      "loss: 0.000436  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004926 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.000102  [    4/  237]\n",
      "loss: 0.000098  [   84/  237]\n",
      "loss: 0.000067  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004906 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.000028  [    4/  237]\n",
      "loss: 0.000074  [   84/  237]\n",
      "loss: 0.000030  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004945 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.000033  [    4/  237]\n",
      "loss: 0.000043  [   84/  237]\n",
      "loss: 0.000154  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008428 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.000974  [    4/  237]\n",
      "loss: 0.000022  [   84/  237]\n",
      "loss: 0.000118  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005279 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.000066  [    4/  237]\n",
      "loss: 0.004847  [   84/  237]\n",
      "loss: 0.000054  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004843 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.001089  [    4/  237]\n",
      "loss: 0.010225  [   84/  237]\n",
      "loss: 0.000130  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004868 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.000034  [    4/  237]\n",
      "loss: 0.000025  [   84/  237]\n",
      "loss: 0.013313  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006206 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.002564  [    4/  237]\n",
      "loss: 0.000090  [   84/  237]\n",
      "loss: 0.000200  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006430 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.000191  [    4/  237]\n",
      "loss: 0.000435  [   84/  237]\n",
      "loss: 0.000025  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005001 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.000049  [    4/  237]\n",
      "loss: 0.000025  [   84/  237]\n",
      "loss: 0.006495  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004919 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.002365  [    4/  237]\n",
      "loss: 0.000105  [   84/  237]\n",
      "loss: 0.000118  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004931 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.000159  [    4/  237]\n",
      "loss: 0.000213  [   84/  237]\n",
      "loss: 0.000026  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005038 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.010403  [    4/  237]\n",
      "loss: 0.000319  [   84/  237]\n",
      "loss: 0.000157  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007576 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.000081  [    4/  237]\n",
      "loss: 0.000046  [   84/  237]\n",
      "loss: 0.000128  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004948 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.000020  [    4/  237]\n",
      "loss: 0.000093  [   84/  237]\n",
      "loss: 0.000063  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005010 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.000095  [    4/  237]\n",
      "loss: 0.000017  [   84/  237]\n",
      "loss: 0.000056  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005238 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.000065  [    4/  237]\n",
      "loss: 0.000049  [   84/  237]\n",
      "loss: 0.000131  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004959 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.000082  [    4/  237]\n",
      "loss: 0.007705  [   84/  237]\n",
      "loss: 0.000039  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005203 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.000078  [    4/  237]\n",
      "loss: 0.000021  [   84/  237]\n",
      "loss: 0.000187  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005065 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.000044  [    4/  237]\n",
      "loss: 0.000073  [   84/  237]\n",
      "loss: 0.003599  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005116 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.000880  [    4/  237]\n",
      "loss: 0.000018  [   84/  237]\n",
      "loss: 0.009007  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.012581 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.000977  [    4/  237]\n",
      "loss: 0.010076  [   84/  237]\n",
      "loss: 0.000128  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005062 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.001639  [    4/  237]\n",
      "loss: 0.000177  [   84/  237]\n",
      "loss: 0.000029  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006864 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.000019  [    4/  237]\n",
      "loss: 0.000016  [   84/  237]\n",
      "loss: 0.007596  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006402 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.009660  [    4/  237]\n",
      "loss: 0.000560  [   84/  237]\n",
      "loss: 0.000877  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004978 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.000021  [    4/  237]\n",
      "loss: 0.000194  [   84/  237]\n",
      "loss: 0.000039  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005108 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.000020  [    4/  237]\n",
      "loss: 0.000063  [   84/  237]\n",
      "loss: 0.012632  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.004953 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.000024  [    4/  237]\n",
      "loss: 0.000258  [   84/  237]\n",
      "loss: 0.000070  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006273 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.000122  [    4/  237]\n",
      "loss: 0.000280  [   84/  237]\n",
      "loss: 0.000131  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 3.9%, Avg loss: 0.091176 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.076272  [    4/  237]\n",
      "loss: 0.169784  [   84/  237]\n",
      "loss: 0.263672  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 91.2%, Board accuracy: 0.0%, Avg loss: 0.206504 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.161062  [    4/  237]\n",
      "loss: 0.186443  [   84/  237]\n",
      "loss: 0.133587  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Board accuracy: 0.0%, Avg loss: 0.117080 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.132260  [    4/  237]\n",
      "loss: 0.122226  [   84/  237]\n",
      "loss: 0.117647  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Board accuracy: 0.0%, Avg loss: 0.094642 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.065447  [    4/  237]\n",
      "loss: 0.141755  [   84/  237]\n",
      "loss: 0.068205  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Board accuracy: 0.0%, Avg loss: 0.074737 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.063649  [    4/  237]\n",
      "loss: 0.052136  [   84/  237]\n",
      "loss: 0.085393  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.049044 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.063318  [    4/  237]\n",
      "loss: 0.028328  [   84/  237]\n",
      "loss: 0.025721  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Board accuracy: 36.7%, Avg loss: 0.031296 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.021402  [    4/  237]\n",
      "loss: 0.024458  [   84/  237]\n",
      "loss: 0.042425  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 45.6%, Avg loss: 0.022738 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.012860  [    4/  237]\n",
      "loss: 0.019981  [   84/  237]\n",
      "loss: 0.008108  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 51.7%, Avg loss: 0.019217 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.010144  [    4/  237]\n",
      "loss: 0.029924  [   84/  237]\n",
      "loss: 0.025630  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 73.9%, Avg loss: 0.016734 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.006552  [    4/  237]\n",
      "loss: 0.006218  [   84/  237]\n",
      "loss: 0.015249  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 63.3%, Avg loss: 0.015280 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.013031  [    4/  237]\n",
      "loss: 0.011331  [   84/  237]\n",
      "loss: 0.002744  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 71.1%, Avg loss: 0.015157 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.008720  [    4/  237]\n",
      "loss: 0.004191  [   84/  237]\n",
      "loss: 0.004574  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.013804 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.007644  [    4/  237]\n",
      "loss: 0.003541  [   84/  237]\n",
      "loss: 0.023773  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 75.0%, Avg loss: 0.013107 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.002862  [    4/  237]\n",
      "loss: 0.010779  [   84/  237]\n",
      "loss: 0.040676  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 74.4%, Avg loss: 0.013510 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.033631  [    4/  237]\n",
      "loss: 0.001931  [   84/  237]\n",
      "loss: 0.006636  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.014072 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.004587  [    4/  237]\n",
      "loss: 0.068698  [   84/  237]\n",
      "loss: 0.026046  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.1%, Avg loss: 0.012608 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.031269  [    4/  237]\n",
      "loss: 0.002312  [   84/  237]\n",
      "loss: 0.003129  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.013016 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.002420  [    4/  237]\n",
      "loss: 0.003397  [   84/  237]\n",
      "loss: 0.004001  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 31.7%, Avg loss: 0.017482 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.019175  [    4/  237]\n",
      "loss: 0.004004  [   84/  237]\n",
      "loss: 0.001980  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.011388 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.001798  [    4/  237]\n",
      "loss: 0.001077  [   84/  237]\n",
      "loss: 0.005846  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.2%, Avg loss: 0.012721 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.007091  [    4/  237]\n",
      "loss: 0.001546  [   84/  237]\n",
      "loss: 0.006439  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.012031 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.005749  [    4/  237]\n",
      "loss: 0.001924  [   84/  237]\n",
      "loss: 0.003149  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.7%, Avg loss: 0.011074 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.001513  [    4/  237]\n",
      "loss: 0.003524  [   84/  237]\n",
      "loss: 0.002949  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.011309 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.001006  [    4/  237]\n",
      "loss: 0.005981  [   84/  237]\n",
      "loss: 0.002575  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.010781 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.003234  [    4/  237]\n",
      "loss: 0.003606  [   84/  237]\n",
      "loss: 0.030167  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 73.3%, Avg loss: 0.012669 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.001052  [    4/  237]\n",
      "loss: 0.030454  [   84/  237]\n",
      "loss: 0.001437  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.010556 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.023973  [    4/  237]\n",
      "loss: 0.000834  [   84/  237]\n",
      "loss: 0.029527  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.010372 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.001064  [    4/  237]\n",
      "loss: 0.036618  [   84/  237]\n",
      "loss: 0.001423  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.012098 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.000813  [    4/  237]\n",
      "loss: 0.000872  [   84/  237]\n",
      "loss: 0.003171  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010332 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.003358  [    4/  237]\n",
      "loss: 0.003284  [   84/  237]\n",
      "loss: 0.036509  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.8%, Avg loss: 0.010105 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.001043  [    4/  237]\n",
      "loss: 0.000836  [   84/  237]\n",
      "loss: 0.002693  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.010250 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.001640  [    4/  237]\n",
      "loss: 0.001710  [   84/  237]\n",
      "loss: 0.002290  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.010312 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.030130  [    4/  237]\n",
      "loss: 0.001207  [   84/  237]\n",
      "loss: 0.004089  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.011161 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.027849  [    4/  237]\n",
      "loss: 0.024554  [   84/  237]\n",
      "loss: 0.001146  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009982 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.004443  [    4/  237]\n",
      "loss: 0.001066  [   84/  237]\n",
      "loss: 0.001108  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.010141 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.001707  [    4/  237]\n",
      "loss: 0.001491  [   84/  237]\n",
      "loss: 0.002713  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009243 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.005088  [    4/  237]\n",
      "loss: 0.001056  [   84/  237]\n",
      "loss: 0.002213  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.009728 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.000709  [    4/  237]\n",
      "loss: 0.001005  [   84/  237]\n",
      "loss: 0.001466  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.009408 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.025454  [    4/  237]\n",
      "loss: 0.001716  [   84/  237]\n",
      "loss: 0.000971  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009857 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.000974  [    4/  237]\n",
      "loss: 0.006956  [   84/  237]\n",
      "loss: 0.002222  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.009940 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.000761  [    4/  237]\n",
      "loss: 0.001301  [   84/  237]\n",
      "loss: 0.001325  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 74.4%, Avg loss: 0.011577 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.029795  [    4/  237]\n",
      "loss: 0.001430  [   84/  237]\n",
      "loss: 0.001615  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.6%, Avg loss: 0.010077 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.002526  [    4/  237]\n",
      "loss: 0.006964  [   84/  237]\n",
      "loss: 0.001225  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009276 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.001713  [    4/  237]\n",
      "loss: 0.001151  [   84/  237]\n",
      "loss: 0.022843  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.009979 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.001217  [    4/  237]\n",
      "loss: 0.001375  [   84/  237]\n",
      "loss: 0.000740  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.8%, Avg loss: 0.009525 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.025745  [    4/  237]\n",
      "loss: 0.036558  [   84/  237]\n",
      "loss: 0.001475  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.010797 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.029142  [    4/  237]\n",
      "loss: 0.000977  [   84/  237]\n",
      "loss: 0.001121  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.010142 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.002677  [    4/  237]\n",
      "loss: 0.001082  [   84/  237]\n",
      "loss: 0.000791  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.008878 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.021404  [    4/  237]\n",
      "loss: 0.001220  [   84/  237]\n",
      "loss: 0.000925  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.009222 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.002897  [    4/  237]\n",
      "loss: 0.000641  [   84/  237]\n",
      "loss: 0.001949  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009201 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.000645  [    4/  237]\n",
      "loss: 0.000657  [   84/  237]\n",
      "loss: 0.001054  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008650 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.000928  [    4/  237]\n",
      "loss: 0.000676  [   84/  237]\n",
      "loss: 0.000599  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009770 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.000882  [    4/  237]\n",
      "loss: 0.001284  [   84/  237]\n",
      "loss: 0.027818  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.009353 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.000732  [    4/  237]\n",
      "loss: 0.002611  [   84/  237]\n",
      "loss: 0.000675  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009282 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.001399  [    4/  237]\n",
      "loss: 0.025181  [   84/  237]\n",
      "loss: 0.003342  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.8%, Avg loss: 0.008931 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.001427  [    4/  237]\n",
      "loss: 0.002518  [   84/  237]\n",
      "loss: 0.000777  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.010359 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.001592  [    4/  237]\n",
      "loss: 0.001401  [   84/  237]\n",
      "loss: 0.000872  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.009053 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.000594  [    4/  237]\n",
      "loss: 0.000933  [   84/  237]\n",
      "loss: 0.002816  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.010497 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.030795  [    4/  237]\n",
      "loss: 0.000497  [   84/  237]\n",
      "loss: 0.000583  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.1%, Avg loss: 0.008535 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.006359  [    4/  237]\n",
      "loss: 0.000936  [   84/  237]\n",
      "loss: 0.001404  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.008778 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.001353  [    4/  237]\n",
      "loss: 0.001003  [   84/  237]\n",
      "loss: 0.001740  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.009131 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.000857  [    4/  237]\n",
      "loss: 0.003127  [   84/  237]\n",
      "loss: 0.003090  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009136 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.000946  [    4/  237]\n",
      "loss: 0.000512  [   84/  237]\n",
      "loss: 0.014237  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008391 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.000495  [    4/  237]\n",
      "loss: 0.002356  [   84/  237]\n",
      "loss: 0.000512  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008108 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.001307  [    4/  237]\n",
      "loss: 0.000766  [   84/  237]\n",
      "loss: 0.000388  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009831 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.000307  [    4/  237]\n",
      "loss: 0.000306  [   84/  237]\n",
      "loss: 0.000494  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008339 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.000828  [    4/  237]\n",
      "loss: 0.001027  [   84/  237]\n",
      "loss: 0.003140  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.011521 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.001349  [    4/  237]\n",
      "loss: 0.001431  [   84/  237]\n",
      "loss: 0.001327  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.010749 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.000779  [    4/  237]\n",
      "loss: 0.001267  [   84/  237]\n",
      "loss: 0.001185  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009659 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.001065  [    4/  237]\n",
      "loss: 0.001307  [   84/  237]\n",
      "loss: 0.001932  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.009135 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.000941  [    4/  237]\n",
      "loss: 0.001752  [   84/  237]\n",
      "loss: 0.001002  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.009733 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.001078  [    4/  237]\n",
      "loss: 0.000786  [   84/  237]\n",
      "loss: 0.001012  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008543 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.000650  [    4/  237]\n",
      "loss: 0.000853  [   84/  237]\n",
      "loss: 0.001921  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.009887 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.001619  [    4/  237]\n",
      "loss: 0.001105  [   84/  237]\n",
      "loss: 0.018576  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.007438 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.002116  [    4/  237]\n",
      "loss: 0.008744  [   84/  237]\n",
      "loss: 0.003315  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007915 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.001312  [    4/  237]\n",
      "loss: 0.000981  [   84/  237]\n",
      "loss: 0.000604  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008004 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.003023  [    4/  237]\n",
      "loss: 0.000694  [   84/  237]\n",
      "loss: 0.037761  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008113 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.000911  [    4/  237]\n",
      "loss: 0.000772  [   84/  237]\n",
      "loss: 0.001066  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007280 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.020202  [    4/  237]\n",
      "loss: 0.000609  [   84/  237]\n",
      "loss: 0.001903  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006839 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.000791  [    4/  237]\n",
      "loss: 0.000587  [   84/  237]\n",
      "loss: 0.000697  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006993 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.002729  [    4/  237]\n",
      "loss: 0.001346  [   84/  237]\n",
      "loss: 0.001305  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005950 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.000759  [    4/  237]\n",
      "loss: 0.000686  [   84/  237]\n",
      "loss: 0.000714  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 63.9%, Avg loss: 0.014452 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = training_process(LG4, 1e-1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 54\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGdCAYAAACPX3D5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh8UlEQVR4nO3de1TUdeL/8ddwv2qog1cWkaKL4rFwtfICXllRW1tvlOatNvKurXnKU2teTh7LDFddtLZ0UyrFPal1LJMT7ialtUluahqr2Kq0indTwGDe3z/8MT9HENElEd/PxzmdE5/5zOfzhnk7PPnM5zPjMMYYAQAAa3nV9AAAAEDNIgYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGgCpo3ry5RowY4f568+bNcjgc2rx5c7Xtw+Fw6MUXX6y27dkoISFBCQkJ7q8PHDggh8Oh5cuX19iYgNqAGMBNb/ny5XI4HO7/AgICFBMTo3HjxunIkSM1PbxrsmHDBn7h1zAeA6A8n5oeAFBVM2fOVFRUlIqKirRlyxalpaVpw4YN2rlzp4KCgm7oWDp37qzCwkL5+fld0/02bNigxYsXV/jLqLCwUD4+/JOsTpGRkSosLJSvr697WWWPAWArnnlQa/Tq1Utt27aVJD3xxBOqX7++5s+fr3Xr1umRRx6p8D7nzp1TcHBwtY/Fy8tLAQEB1brN6t7ezez8+fM3JODKjiQBqBwvE6DW6tq1qyQpLy9PkjRixAiFhIRo3759SkpKUmhoqIYMGSJJcrlcSk1NVcuWLRUQEKCGDRsqJSVFJ0+e9NimMUazZ89Ws2bNFBQUpC5dumjXrl3l9n2lcwa2bdumpKQkhYWFKTg4WK1bt9aCBQvc41u8eLEkebzsUaaicwZycnLUq1cv1alTRyEhIerWrZu2bt3qsU7ZyyjZ2dl6+umn5XQ6FRwcrIcfflgFBQWV/gznzZsnh8OhH374odxtzz33nPz8/Nw/o9zcXPXv31+NGjVSQECAmjVrpuTkZJ0+fbrSfSQkJKhVq1b6+uuv1blzZwUFBWnatGmSpOLiYk2fPl233367/P39FRERoalTp6q4uNhjG8uWLVPXrl0VHh4uf39/3XPPPUpLS6t0v1L5cwau9BgYY9S8eXP99re/LbeNoqIi1a1bVykpKVfdH1BbcWQAtda+ffskSfXr13cvKykpUWJiojp27Kh58+a5//pMSUnR8uXLNXLkSE2YMEF5eXlatGiRcnJylJ2d7T6M/Mc//lGzZ89WUlKSkpKStH37dvXs2VMXLly46ng2bdqkPn36qHHjxpo4caIaNWqk7777Th9++KEmTpyolJQU5efna9OmTVqxYsVVt7dr1y516tRJderU0dSpU+Xr66ulS5cqISFBf//739W+fXuP9cePH6+wsDBNnz5dBw4cUGpqqsaNG6dVq1ZdcR+DBg3S1KlTtXr1aj3zzDMet61evVo9e/ZUWFiYLly4oMTERBUXF2v8+PFq1KiRDh8+rA8//FCnTp1S3bp1K/1ejh8/rl69eik5OVlDhw5Vw4YN5XK59NBDD2nLli168skndffdd+vbb7/Va6+9pu+//15r16513z8tLU0tW7bUQw89JB8fH33wwQcaM2aMXC6Xxo4de9WfZZkrPQYOh0NDhw7Vyy+/rBMnTqhevXru2z744AOdOXNGQ4cOrfJ+gFrHADe5ZcuWGUkmMzPTFBQUmIMHD5r33nvP1K9f3wQGBppDhw4ZY4wZPny4kWSeffZZj/t/9tlnRpJJT0/3WP7xxx97LD969Kjx8/MzvXv3Ni6Xy73etGnTjCQzfPhw97KsrCwjyWRlZRljjCkpKTFRUVEmMjLSnDx50mM/l25r7Nix5kr/7CSZ6dOnu7/u16+f8fPzM/v27XMvy8/PN6GhoaZz587lfj7du3f32NfkyZONt7e3OXXqVIX7K/PAAw+YuLg4j2VffvmlkWTefvttY4wxOTk5RpLJyMiodFsViY+PN5LMkiVLPJavWLHCeHl5mc8++8xj+ZIlS4wkk52d7V52/vz5cttNTEw0LVq0KLev+Ph499d5eXlGklm2bJl72ZUeg7179xpJJi0tzWP5Qw89ZJo3b+7xswVuNbxMgFqje/fucjqdioiIUHJyskJCQvT++++radOmHuuNHj3a4+uMjAzVrVtXPXr00LFjx9z/xcXFKSQkRFlZWZKkzMxMXbhwQePHj/c4fD9p0qSrji0nJ0d5eXmaNGmSbrvtNo/bLt1WVZWWluqTTz5Rv3791KJFC/fyxo0b69FHH9WWLVt05swZj/s8+eSTHvvq1KmTSktLK3wJ4FKDBw/W119/7T7SIkmrVq2Sv7+/+7B52V/+Gzdu1Pnz56/5+/H399fIkSM9lmVkZOjuu+/WXXfd5fG4lL38U/a4SFJgYKD7/0+fPq1jx44pPj5e+/fvv+rLFFUVExOj9u3bKz093b3sxIkT+uijjzRkyJDrehyB2oIYQK2xePFibdq0SVlZWdq9e7f279+vxMREj3V8fHzUrFkzj2W5ubk6ffq0wsPD5XQ6Pf776aefdPToUUly/9K84447PO7vdDoVFhZW6djKfpG2atXqf/oeyxQUFOj8+fO68847y9129913y+Vy6eDBgx7Lf/WrX3l8XTbmy8+LuNzAgQPl5eXlfjnBGKOMjAz3uQqSFBUVpaefflp/+ctf1KBBAyUmJmrx4sVV/kXctGnTclde5ObmateuXeUek5iYGElyPy6SlJ2dre7duys4OFi33XabnE6n+7yD6ooBSRo2bJiys7PdcyEjI0M///yzHnvssWrbB3Az4pwB1Brt2rVzX01wJf7+/vLy8mxcl8ul8PBwj7/4LuV0OqttjDXJ29u7wuXGmErv16RJE3Xq1EmrV6/WtGnTtHXrVv3nP//R3LlzPdZ79dVXNWLECK1bt06ffPKJJkyYoDlz5mjr1q3lAuxyl/5lX8blcik2Nlbz58+v8D4RERGSLoZWt27ddNddd2n+/PmKiIiQn5+fNmzYoNdee00ul6vSfV+L5ORkTZ48Wenp6Zo2bZpWrlyptm3bVhhlwK2EGMAtLzo6WpmZmerQoUOFv5TKREZGSrr4F+ulh+YLCgqu+td1dHS0JGnnzp3q3r37Fder6qFmp9OpoKAg7d27t9xte/bskZeXl/uXZXUYPHiwxowZo71792rVqlUKCgpS3759y60XGxur2NhYPf/88/r888/VoUMHLVmyRLNnz77mfUZHR2vHjh3q1q1bpT+XDz74QMXFxVq/fr3H0Y9LX0a4FpXtq169eurdu7fS09M1ZMgQZWdnKzU19br2A9QmvEyAW96gQYNUWlqqWbNmlbutpKREp06dknTxnARfX18tXLjQ46/pqvwyuO+++xQVFaXU1FT39spcuq2y9zy4fJ3LeXt7q2fPnlq3bp0OHDjgXn7kyBG988476tixo/sQfnXo37+/vL299e677yojI0N9+vTxeH+GM2fOqKSkxOM+sbGx8vLyKncZYFUNGjRIhw8f1htvvFHutsLCQp07d07S/z/icenP8fTp01q2bNl17fdqj8Fjjz2m3bt365lnnpG3t7eSk5Ovaz9AbcKRAdzy4uPjlZKSojlz5uibb75Rz5495evrq9zcXGVkZGjBggUaMGCAnE6npkyZojlz5qhPnz5KSkpSTk6OPvroIzVo0KDSfXh5eSktLU19+/ZVmzZtNHLkSDVu3Fh79uzRrl27tHHjRklSXFycJGnChAlKTEys9JfN7NmztWnTJnXs2FFjxoyRj4+Pli5dquLiYr388svV+jMKDw9Xly5dNH/+fJ09e1aDBw/2uP3TTz/VuHHjNHDgQMXExKikpEQrVqyQt7e3+vfvf137fOyxx7R69Wo99dRTysrKUocOHVRaWqo9e/Zo9erV2rhxo9q2bauePXvKz89Pffv2VUpKin766Se98cYbCg8P148//njN+73aY9C7d2/Vr1/ffd5EeHj4dX1/QK1So9cyAFVQduncV199Vel6w4cPN8HBwVe8/fXXXzdxcXEmMDDQhIaGmtjYWDN16lSTn5/vXqe0tNTMmDHDNG7c2AQGBpqEhASzc+dOExkZWemlhWW2bNlievToYUJDQ01wcLBp3bq1Wbhwofv2kpISM378eON0Oo3D4fC4xE2XXVpojDHbt283iYmJJiQkxAQFBZkuXbqYzz//vEo/nyuN8UreeOMNI8mEhoaawsJCj9v2799vRo0aZaKjo01AQICpV6+e6dKli8nMzLzqduPj403Lli0rvO3ChQtm7ty5pmXLlsbf39+EhYWZuLg4M2PGDHP69Gn3euvXrzetW7c2AQEBpnnz5mbu3LnmrbfeMpJMXl6ex76udmlhZY9BmTFjxhhJ5p133rnq9wfcChzGXOXsIgCwzOTJk/Xmm2/qv//97w3/3AugJnDOAABcoqioSCtXrlT//v0JAViDcwYAQBff1yAzM1Nr1qzR8ePHNXHixJoeEnDDEAMAIGn37t0aMmSIwsPD9ac//Ult2rSp6SEBNwznDAAAYDnOGQAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDADwcOHBADodDy5cvdy978cUX5XA4am5QgKTmzZtrxIgR7q83b94sh8OhzZs319iYLnf5GGsLq2Ng+fLlcjgc+uc//1nTQ9H58+f14osv3lSTGjWrbH6W/efj46OmTZtqxIgROnz4cE0PTy+99JLWrl1b08PADXT5nAwICFBMTIzGjRunI0eO1PTwqmzDhg168cUXa3oYNxWrY+Bmcv78ec2YMYMYQDkzZ87UihUrtGTJEvXq1UsrV65UfHy8ioqKbtgYnn/+eRUWFnosIwbsVTYnFy1apAcffFBpaWl64IEHdP78+Rs6js6dO6uwsFCdO3e+pvtt2LBBM2bM+IVGVTv51PQAAFSuV69eatu2rSTpiSeeUIMGDTR37lytX79egwYNuiFj8PHxkY8PTxe46PI5Wb9+fc2fP1/r1q3TI488Um79c+fOKTg4uNrH4eXlpYCAgGrfro04MnCJESNGKCQkRIcPH1a/fv0UEhIip9OpKVOmqLS01L1e2Wuq8+bN02uvvabIyEgFBgYqPj5eO3fu9NhmQkKCEhISKtxX8+bN3dtzOp2SpBkzZrgPwXEYCxXp1KmTJGnfvn3uZXv27NGAAQNUr149BQQEqG3btlq/fr3H/U6cOKEpU6YoNjZWISEhqlOnjnr16qUdO3ZcdZ+XnzPgcDh07tw5/fWvf3XP1xEjRigrK0sOh0Pvv/9+uW288847cjgc+uKLL673W8dNqmvXrpKkvLw89/Povn37lJSUpNDQUA0ZMkSS5HK5lJqaqpYtWyogIEANGzZUSkqKTp486bE9Y4xmz56tZs2aKSgoSF26dNGuXbvK7fdK5wxs27ZNSUlJCgsLU3BwsFq3bq0FCxZIuvjcu3jxYknyeMmjTHWPsbYg9S9TWlqqxMREtW/fXvPmzVNmZqZeffVVRUdHa/To0R7rvv322zp79qzGjh2roqIiLViwQF27dtW3336rhg0bVnmfTqdTaWlpGj16tB5++GH97ne/kyS1bt26Wr833BoOHDggSQoLC5Mk7dq1Sx06dFDTpk317LPPKjg4WKtXr1a/fv30t7/9TQ8//LAkaf/+/Vq7dq0GDhyoqKgoHTlyREuXLlV8fLx2796tJk2aVHkMK1as0BNPPKF27drpySeflCRFR0fr/vvvV0REhNLT0937LZOenq7o6Gg98MAD1fBTwM2kLEzr168vSSopKVFiYqI6duyoefPmKSgoSJKUkpKi5cuXa+TIkZowYYLy8vK0aNEi5eTkKDs7W76+vpKkP/7xj5o9e7aSkpKUlJSk7du3q2fPnrpw4cJVx7Jp0yb16dNHjRs31sSJE9WoUSN99913+vDDDzVx4kSlpKQoPz9fmzZt0ooVK8rd/0aM8aZkLLZs2TIjyXz11VfGGGOGDx9uJJmZM2d6rHfvvfeauLg499d5eXlGkgkMDDSHDh1yL9+2bZuRZCZPnuxeFh8fb+Lj48vte/jw4SYyMtL9dUFBgZFkpk+fXj3fHGq9svmZmZlpCgoKzMGDB82aNWuM0+k0/v7+5uDBg8YYY7p162ZiY2NNUVGR+74ul8s8+OCD5o477nAvKyoqMqWlpR77yMvLM/7+/h5zvmx+L1u2zL1s+vTp5vKni+DgYDN8+PBy437uueeMv7+/OXXqlHvZ0aNHjY+PD/O7lqtoTr733numfv367ufDsufRZ5991uO+n332mZFk0tPTPZZ//PHHHsuPHj1q/Pz8TO/evY3L5XKvN23aNCPJY85lZWUZSSYrK8sYY0xJSYmJiooykZGR5uTJkx77uXRbY8eOLTeff6kx1ha8TFCBp556yuPrTp06af/+/eXW69evn5o2ber+ul27dmrfvr02bNjwi48R9ujevbucTqciIiI0YMAABQcHa/369WrWrJlOnDihTz/9VIMGDdLZs2d17NgxHTt2TMePH1diYqJyc3PdVx74+/vLy+viP/nS0lIdP35cISEhuvPOO7V9+/ZqG++wYcNUXFysNWvWuJetWrVKJSUlGjp0aLXtBzXn0jmZnJyskJAQvf/++x7Ph5cfSc3IyFDdunXVo0cP9zw9duyY4uLiFBISoqysLElSZmamLly4oPHjx3scvp80adJVx5WTk6O8vDxNmjRJt912m8dtVbk09kaM8WbFywSXCQgIcL9+XyYsLKzc60WSdMcdd5RbFhMTo9WrV/9i44N9Fi9erJiYGJ0+fVpvvfWW/vGPf8jf31+S9O9//1vGGL3wwgt64YUXKrz/0aNH1bRpU7lcLi1YsEB//vOflZeX53EeTNnh3epw11136de//rXS09P1+OOPS7r4EsH999+v22+/vdr2g5pTNid9fHzUsGFD3Xnnne7QlC6ecNqsWTOP++Tm5ur06dMKDw+vcJtHjx6VJP3www+Syj+/Op1O90tjV1L2ckWrVq2u7Ru6gWO8WREDl/H29q7W7TkcDhljyi2/9IkYqEy7du3cZ27369dPHTt21KOPPqq9e/fK5XJJkqZMmaLExMQK71/2C/ill17SCy+8oFGjRmnWrFmqV6+evLy8NGnSJPd2qsuwYcM0ceJEHTp0SMXFxdq6dasWLVpUrftAzbl0Tlbk0qNQZVwul8LDw5Wenl7hfS7/I6wm1IYx/lKIgf9Bbm5uuWXff/+9+yoB6eJRhYpeYigryzK8uxuqwtvbW3PmzFGXLl20aNEijRo1SpLk6+ur7t27V3rfNWvWqEuXLnrzzTc9lp86dUoNGjS45rFUNmeTk5P19NNP691331VhYaF8fX01ePDga94Hbh3R0dHKzMxUhw4dFBgYeMX1IiMjJV18fm3RooV7eUFBQYVHaC/fhyTt3Lmz0n8PV5q7N2KMNyvOGfgfrF271uOd4L788ktt27ZNvXr1ci+Ljo7Wnj17VFBQ4F62Y8cOZWdne2yr7GzbU6dO/bKDRq2XkJCgdu3aKTU1VXXq1FFCQoKWLl2qH3/8sdy6l847b2/vckepMjIyrvvdDIODg684Xxs0aOB+g6T09HT95je/ua7gwK1j0KBBKi0t1axZs8rdVlJS4p5L3bt3l6+vrxYuXOgxX1NTU6+6j/vuu09RUVFKTU0tNzcv3VbZex5cvs6NGOPNiiMD/4Pbb79dHTt21OjRo1VcXKzU1FTVr19fU6dOda8zatQozZ8/X4mJiXr88cd19OhRLVmyRC1bttSZM2fc6wUGBuqee+7RqlWrFBMTo3r16qlVq1bX/doXbm3PPPOMBg4cqOXLl2vx4sXq2LGjYmNj9fvf/14tWrTQkSNH9MUXX+jQoUPu9xHo06ePZs6cqZEjR+rBBx/Ut99+q/T0dI+/bK5FXFycMjMzNX/+fDVp0kRRUVFq3769+/Zhw4ZpwIABklThkyvsEh8fr5SUFM2ZM0fffPONevbsKV9fX+Xm5iojI0MLFizQgAED3O/tMmfOHPXp00dJSUnKycnRRx99dNWg9PLyUlpamvr27as2bdpo5MiRaty4sfbs2aNdu3Zp48aNki7OXUmaMGGCEhMT5e3treTk5BsyxptWTV7KUNMqurQwODi43HqXX1ZVdunVK6+8Yl599VUTERFh/P39TadOncyOHTvK3X/lypWmRYsWxs/Pz7Rp08Zs3Lix3KWFxhjz+eefm7i4OOPn58dlhig3Py9VWlpqoqOjTXR0tCkpKTH79u0zw4YNM40aNTK+vr6madOmpk+fPmbNmjXu+xQVFZk//OEPpnHjxiYwMNB06NDBfPHFF+Uuf63qpYV79uwxnTt3NoGBgRVeTlVcXGzCwsJM3bp1TWFhYbX8TFCzKpuTZa70PFrm9ddfN3FxcSYwMNCEhoaa2NhYM3XqVJOfn+9ep7S01MyYMcM9VxMSEszOnTtNZGRkpZcWltmyZYvp0aOHCQ0NNcHBwaZ169Zm4cKF7ttLSkrM+PHjjdPpNA6Ho9zcrs4x1hYOYyo4uw2VOnDggKKiovTKK69oypQpNT0c4KZUUlKiJk2aqG/fvuXOUwBwc+GcAQC/iLVr16qgoEDDhg2r6aEAuArOGQBQrbZt26Z//etfmjVrlu69917Fx8fX9JAAXAVHBgBUq7LP2QgPD9fbb79d08MBUAWcMwAAgOU4MgAAgOWIAQAALFelEwhdLpfy8/MVGhrK2+biuhljdPbsWTVp0qTc+5b/Upi7qA7MXdRWVZ27VYqB/Px8RUREVNvgYLeDBw+W+0SzXwpzF9WJuYva6mpzt0oxEBoaKknqqCT5yLd6RgbrlOhnbdEG93y6EZi7qA7MXdRWVZ27VYqBskNUPvKVj4NJiev0/65buZGHPJm7qBbMXdRWVZy7nEAIAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALOdT0wO42WzM/6ZG9pvYpE2N7BcAAI4MAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJa7ZT+1sCY+fZBPHkRN4hM3UVsxd2seRwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABY7pb9CGM+mhK1FR+/jdqKuVt7cWQAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsNwt+6mFQG3Fp7ChtmLu1l4cGQAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHI+NT2AX8rG/G9qegg3RGKTNjU9BFQz5i5qK+Zu7cWRAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByVfrUQmOMJKlEP0vmFx1PtTlz1lXTQ7ghSszPNT2EKivRxbGWzacbgbl782LuVo65e/O6Feeuw1Rhdh86dEgRERHVMzJY7+DBg2rWrNkN2RdzF9WJuYva6mpzt0ox4HK5lJ+fr9DQUDkcjmodIOxhjNHZs2fVpEkTeXndmFeomLuoDsxd1FZVnbtVigEAAHDr4gRCAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALDc/wEhim/4NmGiqAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 94\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGdCAYAAACPX3D5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAiSElEQVR4nO3de1TUdeL/8ddwv2qI4JVFpOiieCxcrbyAV1bU1tYbpXmrjbxra57y1Ho9eSwzXHXR2tJNqRT3pNaxTE64m5TWJrmpaaxiq9Iq3k0Bg3n//vDHfB1BRBdFfD8f53RO85nPfD5vZt4OTz7zmRmHMcYIAABYy6OmBwAAAGoWMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAVEGzZs00fPhw1+XNmzfL4XBo8+bN1bYPh8Oh6dOnV9v2bJSQkKCEhATX5QMHDsjhcGj58uU1NiagNiAGcMtbvny5HA6H6z8/Pz/FxMRo7NixOnLkSE0P75ps2LCBX/g1jMcAKM+rpgcAVNXMmTMVFRWloqIibdmyRWlpadqwYYN27typgICAmzqWTp06qbCwUD4+Ptd0uw0bNmjx4sUV/jIqLCyUlxf/JKtTZGSkCgsL5e3t7VpW2WMA2IpnHtQaPXv2VJs2bSRJTz31lEJDQzV//nytW7dOjz32WIW3OXfunAIDA6t9LB4eHvLz86vWbVb39m5l58+fvykBV3YkCUDleJkAtVaXLl0kSXl5eZKk4cOHKygoSPv27VNSUpKCg4M1ePBgSZLT6VRqaqpatGghPz8/NWjQQCkpKTp58qTbNo0xmj17tpo2baqAgAB17txZu3btKrfvK50zsG3bNiUlJSkkJESBgYFq1aqVFixY4Brf4sWLJcntZY8yFZ0zkJOTo549e6pOnToKCgpS165dtXXrVrd1yl5Gyc7O1rPPPquwsDAFBgbq0UcfVUFBQaX34bx58+RwOPTjjz+Wu+6FF16Qj4+P6z7Kzc1Vv3791LBhQ/n5+alp06ZKTk7W6dOnK91HQkKCWrZsqW+++UadOnVSQECApk6dKkkqLi7WtGnTdOedd8rX11cRERGaMmWKiouL3baxbNkydenSReHh4fL19dV9992ntLS0SvcrlT9n4EqPgTFGzZo1029/+9ty2ygqKlLdunWVkpJy1f0BtRVHBlBr7du3T5IUGhrqWlZSUqLExER16NBB8+bNc/31mZKSouXLl2vEiBEaP3688vLytGjRIuXk5Cg7O9t1GPmPf/yjZs+eraSkJCUlJWn79u3q0aOHLly4cNXxbNq0Sb1791ajRo00YcIENWzYUN9//70++ugjTZgwQSkpKcrPz9emTZu0YsWKq25v165d6tixo+rUqaMpU6bI29tbS5cuVUJCgv7+97+rXbt2buuPGzdOISEhmjZtmg4cOKDU1FSNHTtWq1atuuI+Bg4cqClTpmj16tV67rnn3K5bvXq1evTooZCQEF24cEGJiYkqLi7WuHHj1LBhQx0+fFgfffSRTp06pbp161b6sxw/flw9e/ZUcnKyhgwZogYNGsjpdOqRRx7Rli1b9PTTT+vee+/Vd999p9dff10//PCD1q5d67p9WlqaWrRooUceeUReXl768MMPNXr0aDmdTo0ZM+aq92WZKz0GDodDQ4YM0SuvvKITJ06oXr16rus+/PBDnTlzRkOGDKnyfoBaxwC3uGXLlhlJJjMz0xQUFJiDBw+a999/34SGhhp/f39z6NAhY4wxw4YNM5LM888/73b7zz//3Egy6enpbss/+eQTt+VHjx41Pj4+plevXsbpdLrWmzp1qpFkhg0b5lqWlZVlJJmsrCxjjDElJSUmKirKREZGmpMnT7rt59JtjRkzxlzpn50kM23aNNflvn37Gh8fH7Nv3z7Xsvz8fBMcHGw6depU7v7p1q2b274mTZpkPD09zalTpyrcX5mHHnrIxMXFuS376quvjCTzzjvvGGOMycnJMZJMRkZGpduqSHx8vJFklixZ4rZ8xYoVxsPDw3z++eduy5csWWIkmezsbNey8+fPl9tuYmKiad68ebl9xcfHuy7n5eUZSWbZsmWuZVd6DPbu3WskmbS0NLfljzzyiGnWrJnbfQvcbniZALVGt27dFBYWpoiICCUnJysoKEgffPCBmjRp4rbeqFGj3C5nZGSobt266t69u44dO+b6Ly4uTkFBQcrKypIkZWZm6sKFCxo3bpzb4fuJEydedWw5OTnKy8vTxIkTdccdd7hdd+m2qqq0tFSffvqp+vbtq+bNm7uWN2rUSI8//ri2bNmiM2fOuN3m6aefdttXx44dVVpaWuFLAJcaNGiQvvnmG9eRFklatWqVfH19XYfNy/7y37hxo86fP3/NP4+vr69GjBjhtiwjI0P33nuv7rnnHrfHpezln7LHRZL8/f1d/3/69GkdO3ZM8fHx2r9//1VfpqiqmJgYtWvXTunp6a5lJ06c0Mcff6zBgwdf1+MI1BbEAGqNxYsXa9OmTcrKytLu3bu1f/9+JSYmuq3j5eWlpk2bui3Lzc3V6dOnFR4errCwMLf/fv75Zx09elSSXL8077rrLrfbh4WFKSQkpNKxlf0ibdmy5f/0M5YpKCjQ+fPndffdd5e77t5775XT6dTBgwfdlv/qV79yu1w25svPi7jcgAED5OHh4Xo5wRijjIwM17kKkhQVFaVnn31Wf/nLX1S/fn0lJiZq8eLFVf5F3KRJk3LvvMjNzdWuXbvKPSYxMTGS5HpcJCk7O1vdunVTYGCg7rjjDoWFhbnOO6iuGJCkoUOHKjs72zUXMjIy9Msvv+iJJ56otn0AtyLOGUCt0bZtW9e7Ca7E19dXHh7ujet0OhUeHu72F9+lwsLCqm2MNcnT07PC5caYSm/XuHFjdezYUatXr9bUqVO1detW/ec//9HcuXPd1nvttdc0fPhwrVu3Tp9++qnGjx+vOXPmaOvWreUC7HKX/mVfxul0KjY2VvPnz6/wNhEREZIuhlbXrl11zz33aP78+YqIiJCPj482bNig119/XU6ns9J9X4vk5GRNmjRJ6enpmjp1qlauXKk2bdpUGGXA7YQYwG0vOjpamZmZat++fYW/lMpERkZKuvgX66WH5gsKCq7613V0dLQkaefOnerWrdsV16vqoeawsDAFBARo79695a7bs2ePPDw8XL8sq8OgQYM0evRo7d27V6tWrVJAQID69OlTbr3Y2FjFxsbqxRdf1BdffKH27dtryZIlmj179jXvMzo6Wjt27FDXrl0rvV8+/PBDFRcXa/369W5HPy59GeFaVLavevXqqVevXkpPT9fgwYOVnZ2t1NTU69oPUJvwMgFuewMHDlRpaalmzZpV7rqSkhKdOnVK0sVzEry9vbVw4UK3v6ar8svggQceUFRUlFJTU13bK3Pptso+8+DydS7n6empHj16aN26dTpw4IBr+ZEjR/Tuu++qQ4cOrkP41aFfv37y9PTUe++9p4yMDPXu3dvt8xnOnDmjkpISt9vExsbKw8Oj3NsAq2rgwIE6fPiw3nzzzXLXFRYW6ty5c5L+74jHpffj6dOntWzZsuva79UegyeeeEK7d+/Wc889J09PTyUnJ1/XfoDahCMDuO3Fx8crJSVFc+bM0bfffqsePXrI29tbubm5ysjI0IIFC9S/f3+FhYVp8uTJmjNnjnr37q2kpCTl5OTo448/Vv369Svdh4eHh9LS0tSnTx+1bt1aI0aMUKNGjbRnzx7t2rVLGzdulCTFxcVJksaPH6/ExMRKf9nMnj1bmzZtUocOHTR69Gh5eXlp6dKlKi4u1iuvvFKt91F4eLg6d+6s+fPn6+zZsxo0aJDb9Z999pnGjh2rAQMGKCYmRiUlJVqxYoU8PT3Vr1+/69rnE088odWrV+uZZ55RVlaW2rdvr9LSUu3Zs0erV6/Wxo0b1aZNG/Xo0UM+Pj7q06ePUlJS9PPPP+vNN99UeHi4fvrpp2ve79Ueg169eik0NNR13kR4ePh1/XxArVKj72UAqqDsrXNff/11pesNGzbMBAYGXvH6N954w8TFxRl/f38THBxsYmNjzZQpU0x+fr5rndLSUjNjxgzTqFEj4+/vbxISEszOnTtNZGRkpW8tLLNlyxbTvXt3ExwcbAIDA02rVq3MwoULXdeXlJSYcePGmbCwMONwONze4qbL3lpojDHbt283iYmJJigoyAQEBJjOnTubL774okr3z5XGeCVvvvmmkWSCg4NNYWGh23X79+83I0eONNHR0cbPz8/Uq1fPdO7c2WRmZl51u/Hx8aZFixYVXnfhwgUzd+5c06JFC+Pr62tCQkJMXFycmTFjhjl9+rRrvfXr15tWrVoZPz8/06xZMzN37lzz9ttvG0kmLy/PbV9Xe2thZY9BmdGjRxtJ5t13373qzwfcDhzGXOXsIgCwzKRJk/TWW2/pv//9703/3gugJnDOAABcoqioSCtXrlS/fv0IAViDcwYAQBc/1yAzM1Nr1qzR8ePHNWHChJoeEnDTEAMAIGn37t0aPHiwwsPD9ac//UmtW7eu6SEBNw3nDAAAYDnOGQAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDANwcOHBADodDy5cvdy2bPn26HA5HzQ0KkNSsWTMNHz7cdXnz5s1yOBzavHlzjY3pcpePsbawOgaWL18uh8Ohf/7znzU9FJ0/f17Tp0+/pSY1albZ/Cz7z8vLS02aNNHw4cN1+PDhmh6eXn75Za1du7amh4Gb6PI56efnp5iYGI0dO1ZHjhyp6eFV2YYNGzR9+vSaHsYtxeoYuJWcP39eM2bMIAZQzsyZM7VixQotWbJEPXv21MqVKxUfH6+ioqKbNoYXX3xRhYWFbsuIAXuVzclFixbp4YcfVlpamh566CGdP3/+po6jU6dOKiwsVKdOna7pdhs2bNCMGTNu0KhqJ6+aHgCAyvXs2VNt2rSRJD311FOqX7++5s6dq/Xr12vgwIE3ZQxeXl7y8uLpAhddPidDQ0M1f/58rVu3To899li59c+dO6fAwMBqH4eHh4f8/Pyqfbs24sjAJYYPH66goCAdPnxYffv2VVBQkMLCwjR58mSVlpa61it7TXXevHl6/fXXFRkZKX9/f8XHx2vnzp1u20xISFBCQkKF+2rWrJlre2FhYZKkGTNmuA7BcRgLFenYsaMkad++fa5le/bsUf/+/VWvXj35+fmpTZs2Wr9+vdvtTpw4ocmTJys2NlZBQUGqU6eOevbsqR07dlx1n5efM+BwOHTu3Dn99a9/dc3X4cOHKysrSw6HQx988EG5bbz77rtyOBz68ssvr/dHxy2qS5cukqS8vDzX8+i+ffuUlJSk4OBgDR48WJLkdDqVmpqqFi1ayM/PTw0aNFBKSopOnjzptj1jjGbPnq2mTZsqICBAnTt31q5du8rt90rnDGzbtk1JSUkKCQlRYGCgWrVqpQULFki6+Ny7ePFiSXJ7yaNMdY+xtiD1L1NaWqrExES1a9dO8+bNU2Zmpl577TVFR0dr1KhRbuu+8847Onv2rMaMGaOioiItWLBAXbp00XfffacGDRpUeZ9hYWFKS0vTqFGj9Oijj+p3v/udJKlVq1bV+rPh9nDgwAFJUkhIiCRp165dat++vZo0aaLnn39egYGBWr16tfr27au//e1vevTRRyVJ+/fv19q1azVgwABFRUXpyJEjWrp0qeLj47V79241bty4ymNYsWKFnnrqKbVt21ZPP/20JCk6OloPPvigIiIilJ6e7tpvmfT0dEVHR+uhhx6qhnsBt5KyMA0NDZUklZSUKDExUR06dNC8efMUEBAgSUpJSdHy5cs1YsQIjR8/Xnl5eVq0aJFycnKUnZ0tb29vSdIf//hHzZ49W0lJSUpKStL27dvVo0cPXbhw4apj2bRpk3r37q1GjRppwoQJatiwob7//nt99NFHmjBhglJSUpSfn69NmzZpxYoV5W5/M8Z4SzIWW7ZsmZFkvv76a2OMMcOGDTOSzMyZM93Wu//++01cXJzrcl5enpFk/P39zaFDh1zLt23bZiSZSZMmuZbFx8eb+Pj4cvseNmyYiYyMdF0uKCgwksy0adOq54dDrVc2PzMzM01BQYE5ePCgWbNmjQkLCzO+vr7m4MGDxhhjunbtamJjY01RUZHrtk6n0zz88MPmrrvuci0rKioypaWlbvvIy8szvr6+bnO+bH4vW7bMtWzatGnm8qeLwMBAM2zYsHLjfuGFF4yvr685deqUa9nRo0eNl5cX87uWq2hOvv/++yY0NNT1fFj2PPr888+73fbzzz83kkx6errb8k8++cRt+dGjR42Pj4/p1auXcTqdrvWmTp1qJLnNuaysLCPJZGVlGWOMKSkpMVFRUSYyMtKcPHnSbT+XbmvMmDHl5vONGmNtwcsEFXjmmWfcLnfs2FH79+8vt17fvn3VpEkT1+W2bduqXbt22rBhww0fI+zRrVs3hYWFKSIiQv3791dgYKDWr1+vpk2b6sSJE/rss880cOBAnT17VseOHdOxY8d0/PhxJSYmKjc31/XOA19fX3l4XPwnX1paquPHjysoKEh33323tm/fXm3jHTp0qIqLi7VmzRrXslWrVqmkpERDhgyptv2g5lw6J5OTkxUUFKQPPvjA7fnw8iOpGRkZqlu3rrp37+6ap8eOHVNcXJyCgoKUlZUlScrMzNSFCxc0btw4t8P3EydOvOq4cnJylJeXp4kTJ+qOO+5wu64qb429GWO8VfEywWX8/Pxcr9+XCQkJKfd6kSTddddd5ZbFxMRo9erVN2x8sM/ixYsVExOj06dP6+2339Y//vEP+fr6SpL+/e9/yxijl156SS+99FKFtz969KiaNGkip9OpBQsW6M9//rPy8vLczoMpO7xbHe655x79+te/Vnp6up588klJF18iePDBB3XnnXdW235Qc8rmpJeXlxo0aKC7777bFZrSxRNOmzZt6nab3NxcnT59WuHh4RVu8+jRo5KkH3/8UVL559ewsDDXS2NXUvZyRcuWLa/tB7qJY7xVEQOX8fT0rNbtORwOGWPKLb/0iRioTNu2bV1nbvft21cdOnTQ448/rr1798rpdEqSJk+erMTExApvX/YL+OWXX9ZLL72kkSNHatasWapXr548PDw0ceJE13aqy9ChQzVhwgQdOnRIxcXF2rp1qxYtWlSt+0DNuXROVuTSo1BlnE6nwsPDlZ6eXuFtLv8jrCbUhjHeKMTA/yA3N7fcsh9++MH1LgHp4lGFil5iKCvLMny6G6rC09NTc+bMUefOnbVo0SKNHDlSkuTt7a1u3bpVets1a9aoc+fOeuutt9yWnzp1SvXr17/msVQ2Z5OTk/Xss8/qvffeU2Fhoby9vTVo0KBr3gduH9HR0crMzFT79u3l7+9/xfUiIyMlXXx+bd68uWt5QUFBhUdoL9+HJO3cubPSfw9Xmrs3Y4y3Ks4Z+B+sXbvW7ZPgvvrqK23btk09e/Z0LYuOjtaePXtUUFDgWrZjxw5lZ2e7bavsbNtTp07d2EGj1ktISFDbtm2VmpqqOnXqKCEhQUuXLtVPP/1Ubt1L552np2e5o1QZGRnX/WmGgYGBV5yv9evXd31AUnp6un7zm99cV3Dg9jFw4ECVlpZq1qxZ5a4rKSlxzaVu3brJ29tbCxcudJuvqampV93HAw88oKioKKWmppabm5duq+wzDy5f52aM8VbFkYH/wZ133qkOHTpo1KhRKi4uVmpqqkJDQzVlyhTXOiNHjtT8+fOVmJioJ598UkePHtWSJUvUokULnTlzxrWev7+/7rvvPq1atUoxMTGqV6+eWrZsed2vfeH29txzz2nAgAFavny5Fi9erA4dOig2Nla///3v1bx5cx05ckRffvmlDh065Pocgd69e2vmzJkaMWKEHn74YX333XdKT093+8vmWsTFxSkzM1Pz589X48aNFRUVpXbt2rmuHzp0qPr37y9JFT65wi7x8fFKSUnRnDlz9O2336pHjx7y9vZWbm6uMjIytGDBAvXv39/12S5z5sxR7969lZSUpJycHH388cdXDUoPDw+lpaWpT58+at26tUaMGKFGjRppz5492rVrlzZu3Cjp4tyVpPHjxysxMVGenp5KTk6+KWO8ZdXkWxlqWkVvLQwMDCy33uVvqyp769Wrr75qXnvtNRMREWF8fX1Nx44dzY4dO8rdfuXKlaZ58+bGx8fHtG7d2mzcuLHcWwuNMeaLL74wcXFxxsfHh7cZotz8vFRpaamJjo420dHRpqSkxOzbt88MHTrUNGzY0Hh7e5smTZqY3r17mzVr1rhuU1RUZP7whz+YRo0aGX9/f9O+fXvz5Zdflnv7a1XfWrhnzx7TqVMn4+/vX+HbqYqLi01ISIipW7euKSwsrJb7BDWrsjlZ5krPo2XeeOMNExcXZ/z9/U1wcLCJjY01U6ZMMfn5+a51SktLzYwZM1xzNSEhwezcudNERkZW+tbCMlu2bDHdu3c3wcHBJjAw0LRq1cosXLjQdX1JSYkZN26cCQsLMw6Ho9zcrs4x1hYOYyo4uw2VOnDggKKiovTqq69q8uTJNT0c4JZUUlKixo0bq0+fPuXOUwBwa+GcAQA3xNq1a1VQUKChQ4fW9FAAXAXnDACoVtu2bdO//vUvzZo1S/fff7/i4+NrekgAroIjAwCqVdn3bISHh+udd96p6eEAqALOGQAAwHIcGQAAwHLEAAAAlqvSCYROp1P5+fkKDg7mY3Nx3YwxOnv2rBo3blzuc8tvFOYuqgNzF7VVVedulWIgPz9fERER1TY42O3gwYPlvtHsRmHuojoxd1FbXW3uVikGgoODJUkdlCQveVfPyGCdEv2iLdrgmk83A3MX1YG5i9qqqnO3SjFQdojKS97ycjApcZ3+//tWbuYhT+YuqgVzF7VVFecuJxACAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5bxqegA3ysb8b2t6CDdFYuPWNT0EAEAtx5EBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHK37bcW8m1+qK34xk3UVszd2osjAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACx3236FMVBb3Y5fjwo7MHdrL44MAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHJeNT2AG2Vj/rc1PYSbIrFx65oeAqoZcxe1VW2bu8zB/8ORAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJa7bb/CGACAylzvVy7fjl99zJEBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHJ8a+Flbsdvo4IdmLuorZi7NY8jAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACzHVxhfZmP+tzWyX77CE/8r5i5qK+ZuzePIAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMvdtl9hXBNfTVlTX8OJ2wtzF7UVc7f24sgAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYLnb9lsL+SYr1FbMXdRWzN3aiyMDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5YgBAAAsRwwAAGA5YgAAAMsRAwAAWI4YAADAcsQAAACWIwYAALAcMQAAgOWIAQAALEcMAABgOWIAAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsJxXTQ/gRkls3Pq6brcx/9ubvk/gUsxd1FbM3dqLIwMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACxHDAAAYDliAAAAyxEDAABYjhgAAMByxAAAAJYjBgAAsBwxAACA5ar0rYXGGElSiX6RzA0dT407c9Z53bctMb9U40huPyW6eP+UzaebgblbNczdyjF3byzm7o1T1bnrMFWY3YcOHVJERET1jAzWO3jwoJo2bXpT9sXcRXVi7qK2utrcrVIMOJ1O5efnKzg4WA6Ho1oHCHsYY3T27Fk1btxYHh435xUq5i6qA3MXtVVV526VYgAAANy+OIEQAADLEQMAAFiOGAAAwHLEAAAAliMGAACwHDEAAIDliAEAACz3/wD/uY+16htB3QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_failed_prediction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCModel(nn.Module):\n",
    "    \"\"\"What if instead of separating local and global at the start, we just fully connect the cells?\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin0 = nn.Linear(220, 1000)\n",
    "        self.lin1 = nn.Linear(1000, 1000)\n",
    "        self.lin2 = nn.Linear(1000, 440)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.type(torch.float)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.lin0(x))\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        x = torch.reshape(x, (-1, 2, 22, 10))\n",
    "        logits = F.log_softmax(x, dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.691422  [    4/  237]\n",
      "loss: 0.676783  [   84/  237]\n",
      "loss: 0.656854  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 90.6%, Board accuracy: 0.0%, Avg loss: 0.637670 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.644383  [    4/  237]\n",
      "loss: 0.579736  [   84/  237]\n",
      "loss: 0.516426  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Board accuracy: 0.0%, Avg loss: 0.462079 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.471453  [    4/  237]\n",
      "loss: 0.313942  [   84/  237]\n",
      "loss: 0.279169  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.3%, Board accuracy: 0.0%, Avg loss: 0.273585 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.362968  [    4/  237]\n",
      "loss: 0.298757  [   84/  237]\n",
      "loss: 0.199109  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Board accuracy: 0.0%, Avg loss: 0.227303 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.173378  [    4/  237]\n",
      "loss: 0.156239  [   84/  237]\n",
      "loss: 0.193567  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Board accuracy: 0.0%, Avg loss: 0.208113 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.173883  [    4/  237]\n",
      "loss: 0.167882  [   84/  237]\n",
      "loss: 0.209840  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.2%, Board accuracy: 0.0%, Avg loss: 0.202729 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.234999  [    4/  237]\n",
      "loss: 0.166841  [   84/  237]\n",
      "loss: 0.242841  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.5%, Board accuracy: 0.0%, Avg loss: 0.193677 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.149740  [    4/  237]\n",
      "loss: 0.158558  [   84/  237]\n",
      "loss: 0.147645  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.6%, Board accuracy: 0.0%, Avg loss: 0.189984 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.169793  [    4/  237]\n",
      "loss: 0.215658  [   84/  237]\n",
      "loss: 0.207196  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.8%, Board accuracy: 0.0%, Avg loss: 0.185993 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.190597  [    4/  237]\n",
      "loss: 0.245667  [   84/  237]\n",
      "loss: 0.182441  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 92.9%, Board accuracy: 0.0%, Avg loss: 0.182626 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.177616  [    4/  237]\n",
      "loss: 0.132452  [   84/  237]\n",
      "loss: 0.216842  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Board accuracy: 0.0%, Avg loss: 0.180060 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.169438  [    4/  237]\n",
      "loss: 0.204033  [   84/  237]\n",
      "loss: 0.201242  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Board accuracy: 0.0%, Avg loss: 0.178251 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.141701  [    4/  237]\n",
      "loss: 0.168188  [   84/  237]\n",
      "loss: 0.153139  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 93.1%, Board accuracy: 0.0%, Avg loss: 0.174524 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.170070  [    4/  237]\n",
      "loss: 0.142979  [   84/  237]\n",
      "loss: 0.171671  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Board accuracy: 0.0%, Avg loss: 0.171336 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.149328  [    4/  237]\n",
      "loss: 0.160059  [   84/  237]\n",
      "loss: 0.167773  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 93.3%, Board accuracy: 0.0%, Avg loss: 0.169651 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.145586  [    4/  237]\n",
      "loss: 0.144767  [   84/  237]\n",
      "loss: 0.169277  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 93.7%, Board accuracy: 0.0%, Avg loss: 0.165260 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.191554  [    4/  237]\n",
      "loss: 0.220047  [   84/  237]\n",
      "loss: 0.217349  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 94.2%, Board accuracy: 0.0%, Avg loss: 0.161211 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.171353  [    4/  237]\n",
      "loss: 0.163915  [   84/  237]\n",
      "loss: 0.150609  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Board accuracy: 0.0%, Avg loss: 0.158487 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.167903  [    4/  237]\n",
      "loss: 0.130622  [   84/  237]\n",
      "loss: 0.146534  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Board accuracy: 0.0%, Avg loss: 0.153979 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.109594  [    4/  237]\n",
      "loss: 0.126082  [   84/  237]\n",
      "loss: 0.141591  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Board accuracy: 0.0%, Avg loss: 0.151162 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.131439  [    4/  237]\n",
      "loss: 0.143247  [   84/  237]\n",
      "loss: 0.133755  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 94.1%, Board accuracy: 0.0%, Avg loss: 0.149577 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.119346  [    4/  237]\n",
      "loss: 0.137810  [   84/  237]\n",
      "loss: 0.135250  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Board accuracy: 0.0%, Avg loss: 0.143162 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.162340  [    4/  237]\n",
      "loss: 0.216410  [   84/  237]\n",
      "loss: 0.128360  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Board accuracy: 0.0%, Avg loss: 0.139758 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.138916  [    4/  237]\n",
      "loss: 0.145048  [   84/  237]\n",
      "loss: 0.125578  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Board accuracy: 0.0%, Avg loss: 0.137952 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.115769  [    4/  237]\n",
      "loss: 0.158565  [   84/  237]\n",
      "loss: 0.114863  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 94.9%, Board accuracy: 0.0%, Avg loss: 0.134576 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.135884  [    4/  237]\n",
      "loss: 0.137530  [   84/  237]\n",
      "loss: 0.158973  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.2%, Board accuracy: 0.0%, Avg loss: 0.131221 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.129209  [    4/  237]\n",
      "loss: 0.120960  [   84/  237]\n",
      "loss: 0.123498  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Board accuracy: 0.0%, Avg loss: 0.131134 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.107031  [    4/  237]\n",
      "loss: 0.135887  [   84/  237]\n",
      "loss: 0.129421  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.1%, Board accuracy: 0.0%, Avg loss: 0.130239 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.109626  [    4/  237]\n",
      "loss: 0.119336  [   84/  237]\n",
      "loss: 0.132374  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.4%, Board accuracy: 0.0%, Avg loss: 0.128073 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.117782  [    4/  237]\n",
      "loss: 0.141850  [   84/  237]\n",
      "loss: 0.122047  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Board accuracy: 0.0%, Avg loss: 0.124893 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.156076  [    4/  237]\n",
      "loss: 0.105131  [   84/  237]\n",
      "loss: 0.092153  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Board accuracy: 0.0%, Avg loss: 0.123985 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.158908  [    4/  237]\n",
      "loss: 0.120185  [   84/  237]\n",
      "loss: 0.126533  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.7%, Board accuracy: 0.0%, Avg loss: 0.122293 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.100258  [    4/  237]\n",
      "loss: 0.108558  [   84/  237]\n",
      "loss: 0.136498  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Board accuracy: 0.0%, Avg loss: 0.121238 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.125907  [    4/  237]\n",
      "loss: 0.106016  [   84/  237]\n",
      "loss: 0.122510  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Board accuracy: 0.0%, Avg loss: 0.119672 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.107185  [    4/  237]\n",
      "loss: 0.102967  [   84/  237]\n",
      "loss: 0.092683  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.8%, Board accuracy: 0.0%, Avg loss: 0.120849 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.130016  [    4/  237]\n",
      "loss: 0.094906  [   84/  237]\n",
      "loss: 0.121278  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Board accuracy: 0.0%, Avg loss: 0.117759 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.112718  [    4/  237]\n",
      "loss: 0.096542  [   84/  237]\n",
      "loss: 0.102889  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Board accuracy: 0.0%, Avg loss: 0.117210 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.103890  [    4/  237]\n",
      "loss: 0.099481  [   84/  237]\n",
      "loss: 0.148363  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.9%, Board accuracy: 0.0%, Avg loss: 0.118034 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.101448  [    4/  237]\n",
      "loss: 0.089031  [   84/  237]\n",
      "loss: 0.128419  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Board accuracy: 0.0%, Avg loss: 0.115112 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.105029  [    4/  237]\n",
      "loss: 0.126030  [   84/  237]\n",
      "loss: 0.090567  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Board accuracy: 0.0%, Avg loss: 0.115725 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.105964  [    4/  237]\n",
      "loss: 0.137303  [   84/  237]\n",
      "loss: 0.100418  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Board accuracy: 0.0%, Avg loss: 0.113443 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.109206  [    4/  237]\n",
      "loss: 0.083646  [   84/  237]\n",
      "loss: 0.135625  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Board accuracy: 0.0%, Avg loss: 0.113941 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.133407  [    4/  237]\n",
      "loss: 0.132348  [   84/  237]\n",
      "loss: 0.098742  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Board accuracy: 0.0%, Avg loss: 0.112759 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.128363  [    4/  237]\n",
      "loss: 0.108446  [   84/  237]\n",
      "loss: 0.099421  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Board accuracy: 0.0%, Avg loss: 0.111553 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.084907  [    4/  237]\n",
      "loss: 0.112440  [   84/  237]\n",
      "loss: 0.102344  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Board accuracy: 0.0%, Avg loss: 0.109981 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.090267  [    4/  237]\n",
      "loss: 0.130189  [   84/  237]\n",
      "loss: 0.082615  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Board accuracy: 0.0%, Avg loss: 0.109167 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.091175  [    4/  237]\n",
      "loss: 0.115939  [   84/  237]\n",
      "loss: 0.090524  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Board accuracy: 0.0%, Avg loss: 0.108897 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.095366  [    4/  237]\n",
      "loss: 0.098875  [   84/  237]\n",
      "loss: 0.099104  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Board accuracy: 0.0%, Avg loss: 0.108315 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.110961  [    4/  237]\n",
      "loss: 0.087324  [   84/  237]\n",
      "loss: 0.092232  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Board accuracy: 0.0%, Avg loss: 0.107160 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.089301  [    4/  237]\n",
      "loss: 0.117722  [   84/  237]\n",
      "loss: 0.086935  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.1%, Board accuracy: 0.0%, Avg loss: 0.107917 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.098431  [    4/  237]\n",
      "loss: 0.084717  [   84/  237]\n",
      "loss: 0.106759  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Board accuracy: 0.0%, Avg loss: 0.107125 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.093234  [    4/  237]\n",
      "loss: 0.076651  [   84/  237]\n",
      "loss: 0.072331  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Board accuracy: 0.0%, Avg loss: 0.105797 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.115815  [    4/  237]\n",
      "loss: 0.103476  [   84/  237]\n",
      "loss: 0.117595  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.2%, Board accuracy: 0.0%, Avg loss: 0.105268 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.097729  [    4/  237]\n",
      "loss: 0.087311  [   84/  237]\n",
      "loss: 0.101984  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.3%, Board accuracy: 0.0%, Avg loss: 0.104627 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.097710  [    4/  237]\n",
      "loss: 0.103063  [   84/  237]\n",
      "loss: 0.110493  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Board accuracy: 0.0%, Avg loss: 0.104452 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.076213  [    4/  237]\n",
      "loss: 0.078348  [   84/  237]\n",
      "loss: 0.091486  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Board accuracy: 0.0%, Avg loss: 0.103174 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.104804  [    4/  237]\n",
      "loss: 0.106272  [   84/  237]\n",
      "loss: 0.082417  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Board accuracy: 0.0%, Avg loss: 0.102077 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.078245  [    4/  237]\n",
      "loss: 0.070790  [   84/  237]\n",
      "loss: 0.087092  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Board accuracy: 0.0%, Avg loss: 0.101071 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.076284  [    4/  237]\n",
      "loss: 0.074607  [   84/  237]\n",
      "loss: 0.079512  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.4%, Board accuracy: 0.0%, Avg loss: 0.101377 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.094991  [    4/  237]\n",
      "loss: 0.071964  [   84/  237]\n",
      "loss: 0.124863  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Board accuracy: 0.0%, Avg loss: 0.100384 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.106510  [    4/  237]\n",
      "loss: 0.095889  [   84/  237]\n",
      "loss: 0.093781  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Board accuracy: 0.0%, Avg loss: 0.100241 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.089669  [    4/  237]\n",
      "loss: 0.083314  [   84/  237]\n",
      "loss: 0.059889  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Board accuracy: 0.0%, Avg loss: 0.098979 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.109267  [    4/  237]\n",
      "loss: 0.084082  [   84/  237]\n",
      "loss: 0.097206  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Board accuracy: 0.0%, Avg loss: 0.098268 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.090692  [    4/  237]\n",
      "loss: 0.091492  [   84/  237]\n",
      "loss: 0.102552  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Board accuracy: 0.0%, Avg loss: 0.097971 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.099010  [    4/  237]\n",
      "loss: 0.076179  [   84/  237]\n",
      "loss: 0.071480  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Board accuracy: 0.0%, Avg loss: 0.096832 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.076320  [    4/  237]\n",
      "loss: 0.071695  [   84/  237]\n",
      "loss: 0.084549  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Board accuracy: 0.0%, Avg loss: 0.095853 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.077401  [    4/  237]\n",
      "loss: 0.091813  [   84/  237]\n",
      "loss: 0.085742  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Board accuracy: 0.0%, Avg loss: 0.095809 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.082866  [    4/  237]\n",
      "loss: 0.082115  [   84/  237]\n",
      "loss: 0.098476  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Board accuracy: 0.0%, Avg loss: 0.096897 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.095416  [    4/  237]\n",
      "loss: 0.087681  [   84/  237]\n",
      "loss: 0.077982  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Board accuracy: 0.0%, Avg loss: 0.095271 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.071507  [    4/  237]\n",
      "loss: 0.087684  [   84/  237]\n",
      "loss: 0.093418  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 0.0%, Avg loss: 0.093675 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.079958  [    4/  237]\n",
      "loss: 0.082757  [   84/  237]\n",
      "loss: 0.093956  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Board accuracy: 0.0%, Avg loss: 0.093434 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.064901  [    4/  237]\n",
      "loss: 0.076439  [   84/  237]\n",
      "loss: 0.082267  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 0.0%, Avg loss: 0.091807 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.069935  [    4/  237]\n",
      "loss: 0.082108  [   84/  237]\n",
      "loss: 0.099000  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.6%, Board accuracy: 0.0%, Avg loss: 0.092247 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.089496  [    4/  237]\n",
      "loss: 0.078439  [   84/  237]\n",
      "loss: 0.081049  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Board accuracy: 0.0%, Avg loss: 0.092618 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.093104  [    4/  237]\n",
      "loss: 0.087246  [   84/  237]\n",
      "loss: 0.079373  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 0.0%, Avg loss: 0.090866 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.073756  [    4/  237]\n",
      "loss: 0.068189  [   84/  237]\n",
      "loss: 0.092503  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.8%, Board accuracy: 0.0%, Avg loss: 0.091045 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.084263  [    4/  237]\n",
      "loss: 0.069552  [   84/  237]\n",
      "loss: 0.087969  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Board accuracy: 0.0%, Avg loss: 0.088824 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.096283  [    4/  237]\n",
      "loss: 0.076924  [   84/  237]\n",
      "loss: 0.079082  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Board accuracy: 0.0%, Avg loss: 0.088834 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.079100  [    4/  237]\n",
      "loss: 0.086823  [   84/  237]\n",
      "loss: 0.083155  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 0.0%, Avg loss: 0.088224 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.090481  [    4/  237]\n",
      "loss: 0.092781  [   84/  237]\n",
      "loss: 0.079897  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 0.0%, Avg loss: 0.087609 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.072770  [    4/  237]\n",
      "loss: 0.075023  [   84/  237]\n",
      "loss: 0.075466  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Board accuracy: 0.0%, Avg loss: 0.086479 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.070444  [    4/  237]\n",
      "loss: 0.070221  [   84/  237]\n",
      "loss: 0.062189  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.9%, Board accuracy: 0.0%, Avg loss: 0.086406 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.069237  [    4/  237]\n",
      "loss: 0.066416  [   84/  237]\n",
      "loss: 0.077469  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.084188 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.069320  [    4/  237]\n",
      "loss: 0.077785  [   84/  237]\n",
      "loss: 0.065605  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.084367 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.067687  [    4/  237]\n",
      "loss: 0.075243  [   84/  237]\n",
      "loss: 0.061743  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.085490 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.088804  [    4/  237]\n",
      "loss: 0.069552  [   84/  237]\n",
      "loss: 0.077017  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.083595 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.060124  [    4/  237]\n",
      "loss: 0.061339  [   84/  237]\n",
      "loss: 0.037325  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Board accuracy: 0.0%, Avg loss: 0.083186 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.078920  [    4/  237]\n",
      "loss: 0.083447  [   84/  237]\n",
      "loss: 0.085511  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Board accuracy: 0.0%, Avg loss: 0.081249 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.074436  [    4/  237]\n",
      "loss: 0.068098  [   84/  237]\n",
      "loss: 0.080918  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Board accuracy: 0.0%, Avg loss: 0.081031 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.053989  [    4/  237]\n",
      "loss: 0.079256  [   84/  237]\n",
      "loss: 0.079685  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.081872 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.066420  [    4/  237]\n",
      "loss: 0.058534  [   84/  237]\n",
      "loss: 0.065526  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.2%, Board accuracy: 0.0%, Avg loss: 0.079754 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.058923  [    4/  237]\n",
      "loss: 0.069250  [   84/  237]\n",
      "loss: 0.065651  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.081579 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.074532  [    4/  237]\n",
      "loss: 0.074916  [   84/  237]\n",
      "loss: 0.064187  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Board accuracy: 0.0%, Avg loss: 0.079699 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.075687  [    4/  237]\n",
      "loss: 0.059902  [   84/  237]\n",
      "loss: 0.080260  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Board accuracy: 0.0%, Avg loss: 0.077929 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.094597  [    4/  237]\n",
      "loss: 0.069446  [   84/  237]\n",
      "loss: 0.045251  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Board accuracy: 0.0%, Avg loss: 0.077092 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.068015  [    4/  237]\n",
      "loss: 0.069329  [   84/  237]\n",
      "loss: 0.064520  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Board accuracy: 0.0%, Avg loss: 0.077564 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.072365  [    4/  237]\n",
      "loss: 0.062483  [   84/  237]\n",
      "loss: 0.066231  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.076507 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.071768  [    4/  237]\n",
      "loss: 0.053742  [   84/  237]\n",
      "loss: 0.059849  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.076272 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.070676  [    4/  237]\n",
      "loss: 0.066904  [   84/  237]\n",
      "loss: 0.059552  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.3%, Board accuracy: 0.0%, Avg loss: 0.075033 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.070128  [    4/  237]\n",
      "loss: 0.064510  [   84/  237]\n",
      "loss: 0.062145  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.074806 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.056206  [    4/  237]\n",
      "loss: 0.058015  [   84/  237]\n",
      "loss: 0.058695  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.074224 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.064606  [    4/  237]\n",
      "loss: 0.074275  [   84/  237]\n",
      "loss: 0.044980  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.073884 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.064466  [    4/  237]\n",
      "loss: 0.072387  [   84/  237]\n",
      "loss: 0.053066  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Board accuracy: 0.0%, Avg loss: 0.073303 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.065039  [    4/  237]\n",
      "loss: 0.065956  [   84/  237]\n",
      "loss: 0.053876  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Board accuracy: 0.0%, Avg loss: 0.073282 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.070723  [    4/  237]\n",
      "loss: 0.070238  [   84/  237]\n",
      "loss: 0.048240  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Board accuracy: 0.0%, Avg loss: 0.071386 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.062845  [    4/  237]\n",
      "loss: 0.065595  [   84/  237]\n",
      "loss: 0.052369  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Board accuracy: 0.0%, Avg loss: 0.071595 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.054588  [    4/  237]\n",
      "loss: 0.057879  [   84/  237]\n",
      "loss: 0.051257  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.071602 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.054437  [    4/  237]\n",
      "loss: 0.042603  [   84/  237]\n",
      "loss: 0.049564  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.070887 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.046300  [    4/  237]\n",
      "loss: 0.052835  [   84/  237]\n",
      "loss: 0.045488  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Board accuracy: 0.0%, Avg loss: 0.069528 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.045814  [    4/  237]\n",
      "loss: 0.046505  [   84/  237]\n",
      "loss: 0.048667  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 0.0%, Avg loss: 0.069310 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.071352  [    4/  237]\n",
      "loss: 0.051802  [   84/  237]\n",
      "loss: 0.046391  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Board accuracy: 0.0%, Avg loss: 0.069642 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.070691  [    4/  237]\n",
      "loss: 0.067650  [   84/  237]\n",
      "loss: 0.059343  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Board accuracy: 0.0%, Avg loss: 0.069327 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.060206  [    4/  237]\n",
      "loss: 0.060679  [   84/  237]\n",
      "loss: 0.063531  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 0.0%, Avg loss: 0.067944 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.054939  [    4/  237]\n",
      "loss: 0.050719  [   84/  237]\n",
      "loss: 0.039616  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 0.0%, Avg loss: 0.068061 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.044671  [    4/  237]\n",
      "loss: 0.051231  [   84/  237]\n",
      "loss: 0.057348  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 0.0%, Avg loss: 0.067676 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.047185  [    4/  237]\n",
      "loss: 0.068391  [   84/  237]\n",
      "loss: 0.046470  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.5%, Board accuracy: 0.0%, Avg loss: 0.067644 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.071664  [    4/  237]\n",
      "loss: 0.049590  [   84/  237]\n",
      "loss: 0.052954  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 0.0%, Avg loss: 0.066679 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.054144  [    4/  237]\n",
      "loss: 0.054403  [   84/  237]\n",
      "loss: 0.049171  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 0.0%, Avg loss: 0.065743 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.046452  [    4/  237]\n",
      "loss: 0.051788  [   84/  237]\n",
      "loss: 0.062042  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 0.0%, Avg loss: 0.065601 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.048356  [    4/  237]\n",
      "loss: 0.055165  [   84/  237]\n",
      "loss: 0.035617  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 0.0%, Avg loss: 0.065505 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.056476  [    4/  237]\n",
      "loss: 0.054651  [   84/  237]\n",
      "loss: 0.063450  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Board accuracy: 0.0%, Avg loss: 0.065526 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.046691  [    4/  237]\n",
      "loss: 0.032077  [   84/  237]\n",
      "loss: 0.056259  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 0.0%, Avg loss: 0.064837 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.049928  [    4/  237]\n",
      "loss: 0.065939  [   84/  237]\n",
      "loss: 0.041541  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Board accuracy: 0.0%, Avg loss: 0.063654 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.051378  [    4/  237]\n",
      "loss: 0.055692  [   84/  237]\n",
      "loss: 0.064542  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 0.0%, Avg loss: 0.063916 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.044237  [    4/  237]\n",
      "loss: 0.056744  [   84/  237]\n",
      "loss: 0.053653  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 0.0%, Avg loss: 0.062337 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.047536  [    4/  237]\n",
      "loss: 0.051215  [   84/  237]\n",
      "loss: 0.077329  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Board accuracy: 0.0%, Avg loss: 0.062603 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.049644  [    4/  237]\n",
      "loss: 0.060863  [   84/  237]\n",
      "loss: 0.043301  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Board accuracy: 0.0%, Avg loss: 0.062756 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.038493  [    4/  237]\n",
      "loss: 0.048959  [   84/  237]\n",
      "loss: 0.048540  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.061658 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.047665  [    4/  237]\n",
      "loss: 0.050197  [   84/  237]\n",
      "loss: 0.045094  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.061363 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.054299  [    4/  237]\n",
      "loss: 0.056533  [   84/  237]\n",
      "loss: 0.045375  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 0.0%, Avg loss: 0.062600 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.050300  [    4/  237]\n",
      "loss: 0.061604  [   84/  237]\n",
      "loss: 0.068027  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.060621 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.063765  [    4/  237]\n",
      "loss: 0.055057  [   84/  237]\n",
      "loss: 0.056259  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.060819 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.040415  [    4/  237]\n",
      "loss: 0.040798  [   84/  237]\n",
      "loss: 0.038883  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.059895 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.045749  [    4/  237]\n",
      "loss: 0.055770  [   84/  237]\n",
      "loss: 0.042513  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.059204 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.043483  [    4/  237]\n",
      "loss: 0.036031  [   84/  237]\n",
      "loss: 0.038575  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.059023 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.054881  [    4/  237]\n",
      "loss: 0.038422  [   84/  237]\n",
      "loss: 0.042122  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.058976 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.039669  [    4/  237]\n",
      "loss: 0.032403  [   84/  237]\n",
      "loss: 0.064782  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.058181 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.053068  [    4/  237]\n",
      "loss: 0.029172  [   84/  237]\n",
      "loss: 0.051572  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.058697 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.050083  [    4/  237]\n",
      "loss: 0.051539  [   84/  237]\n",
      "loss: 0.046885  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.058233 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.036190  [    4/  237]\n",
      "loss: 0.060087  [   84/  237]\n",
      "loss: 0.029676  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.057292 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.064320  [    4/  237]\n",
      "loss: 0.036559  [   84/  237]\n",
      "loss: 0.046136  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.057998 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.047164  [    4/  237]\n",
      "loss: 0.053308  [   84/  237]\n",
      "loss: 0.067037  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.056730 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.047650  [    4/  237]\n",
      "loss: 0.035134  [   84/  237]\n",
      "loss: 0.028840  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 0.0%, Avg loss: 0.057371 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.043264  [    4/  237]\n",
      "loss: 0.059521  [   84/  237]\n",
      "loss: 0.049404  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.057090 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.037436  [    4/  237]\n",
      "loss: 0.030257  [   84/  237]\n",
      "loss: 0.023902  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.056172 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.031932  [    4/  237]\n",
      "loss: 0.027929  [   84/  237]\n",
      "loss: 0.036340  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.056197 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.055585  [    4/  237]\n",
      "loss: 0.044394  [   84/  237]\n",
      "loss: 0.042897  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.056060 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.042294  [    4/  237]\n",
      "loss: 0.039741  [   84/  237]\n",
      "loss: 0.048460  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.0%, Board accuracy: 0.0%, Avg loss: 0.056133 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.046546  [    4/  237]\n",
      "loss: 0.035385  [   84/  237]\n",
      "loss: 0.041060  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.055256 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.029437  [    4/  237]\n",
      "loss: 0.054670  [   84/  237]\n",
      "loss: 0.055427  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.054128 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.041853  [    4/  237]\n",
      "loss: 0.041479  [   84/  237]\n",
      "loss: 0.036817  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.054774 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.048691  [    4/  237]\n",
      "loss: 0.042530  [   84/  237]\n",
      "loss: 0.044735  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.054574 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.030373  [    4/  237]\n",
      "loss: 0.029220  [   84/  237]\n",
      "loss: 0.044117  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.054271 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.047988  [    4/  237]\n",
      "loss: 0.027339  [   84/  237]\n",
      "loss: 0.055662  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 0.0%, Avg loss: 0.054150 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.026177  [    4/  237]\n",
      "loss: 0.026298  [   84/  237]\n",
      "loss: 0.021785  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 0.0%, Avg loss: 0.052898 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.035294  [    4/  237]\n",
      "loss: 0.033605  [   84/  237]\n",
      "loss: 0.029921  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.054946 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.045685  [    4/  237]\n",
      "loss: 0.035447  [   84/  237]\n",
      "loss: 0.043689  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 3.9%, Avg loss: 0.053108 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.023934  [    4/  237]\n",
      "loss: 0.035818  [   84/  237]\n",
      "loss: 0.056857  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 3.9%, Avg loss: 0.053378 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.038096  [    4/  237]\n",
      "loss: 0.032595  [   84/  237]\n",
      "loss: 0.030782  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 0.0%, Avg loss: 0.053785 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.038037  [    4/  237]\n",
      "loss: 0.026194  [   84/  237]\n",
      "loss: 0.029563  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 1.7%, Avg loss: 0.052633 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.034001  [    4/  237]\n",
      "loss: 0.040593  [   84/  237]\n",
      "loss: 0.032277  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 0.0%, Avg loss: 0.052848 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.022645  [    4/  237]\n",
      "loss: 0.045166  [   84/  237]\n",
      "loss: 0.033531  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 3.3%, Avg loss: 0.052940 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.030087  [    4/  237]\n",
      "loss: 0.050308  [   84/  237]\n",
      "loss: 0.027498  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 3.3%, Avg loss: 0.052771 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.030141  [    4/  237]\n",
      "loss: 0.035609  [   84/  237]\n",
      "loss: 0.036051  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 1.7%, Avg loss: 0.052035 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.031901  [    4/  237]\n",
      "loss: 0.038844  [   84/  237]\n",
      "loss: 0.029220  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 1.7%, Avg loss: 0.051207 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.030238  [    4/  237]\n",
      "loss: 0.055967  [   84/  237]\n",
      "loss: 0.028750  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 5.0%, Avg loss: 0.052059 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.028514  [    4/  237]\n",
      "loss: 0.039865  [   84/  237]\n",
      "loss: 0.036153  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 5.0%, Avg loss: 0.050660 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.040195  [    4/  237]\n",
      "loss: 0.033032  [   84/  237]\n",
      "loss: 0.036496  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 3.9%, Avg loss: 0.051376 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.034205  [    4/  237]\n",
      "loss: 0.028441  [   84/  237]\n",
      "loss: 0.046206  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 5.0%, Avg loss: 0.050876 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.025968  [    4/  237]\n",
      "loss: 0.037590  [   84/  237]\n",
      "loss: 0.024577  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 1.7%, Avg loss: 0.050541 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.035891  [    4/  237]\n",
      "loss: 0.059271  [   84/  237]\n",
      "loss: 0.032363  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 1.7%, Avg loss: 0.050867 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.020301  [    4/  237]\n",
      "loss: 0.029076  [   84/  237]\n",
      "loss: 0.033129  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 1.7%, Avg loss: 0.050364 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.027975  [    4/  237]\n",
      "loss: 0.028605  [   84/  237]\n",
      "loss: 0.029013  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 3.3%, Avg loss: 0.050351 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.037114  [    4/  237]\n",
      "loss: 0.044382  [   84/  237]\n",
      "loss: 0.025053  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 3.3%, Avg loss: 0.050038 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.027040  [    4/  237]\n",
      "loss: 0.039383  [   84/  237]\n",
      "loss: 0.031430  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 3.3%, Avg loss: 0.049633 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.032448  [    4/  237]\n",
      "loss: 0.032375  [   84/  237]\n",
      "loss: 0.029467  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 1.7%, Avg loss: 0.050303 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.037627  [    4/  237]\n",
      "loss: 0.029703  [   84/  237]\n",
      "loss: 0.029171  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 5.0%, Avg loss: 0.049777 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.037482  [    4/  237]\n",
      "loss: 0.043080  [   84/  237]\n",
      "loss: 0.033567  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 5.0%, Avg loss: 0.050023 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.036037  [    4/  237]\n",
      "loss: 0.026899  [   84/  237]\n",
      "loss: 0.021975  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 5.0%, Avg loss: 0.049228 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.029989  [    4/  237]\n",
      "loss: 0.033967  [   84/  237]\n",
      "loss: 0.036233  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 5.0%, Avg loss: 0.049442 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.028156  [    4/  237]\n",
      "loss: 0.029317  [   84/  237]\n",
      "loss: 0.030896  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 5.0%, Avg loss: 0.049142 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.022834  [    4/  237]\n",
      "loss: 0.036874  [   84/  237]\n",
      "loss: 0.047321  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 5.0%, Avg loss: 0.048078 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.027583  [    4/  237]\n",
      "loss: 0.039578  [   84/  237]\n",
      "loss: 0.026011  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.3%, Board accuracy: 5.6%, Avg loss: 0.049128 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.045269  [    4/  237]\n",
      "loss: 0.028160  [   84/  237]\n",
      "loss: 0.036755  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.048576 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.021092  [    4/  237]\n",
      "loss: 0.032473  [   84/  237]\n",
      "loss: 0.039051  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.048301 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.029350  [    4/  237]\n",
      "loss: 0.040441  [   84/  237]\n",
      "loss: 0.030648  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 3.3%, Avg loss: 0.048386 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.029563  [    4/  237]\n",
      "loss: 0.036218  [   84/  237]\n",
      "loss: 0.051190  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.047842 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.027324  [    4/  237]\n",
      "loss: 0.024997  [   84/  237]\n",
      "loss: 0.028855  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.047782 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.038867  [    4/  237]\n",
      "loss: 0.040102  [   84/  237]\n",
      "loss: 0.031428  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.048121 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.035090  [    4/  237]\n",
      "loss: 0.027560  [   84/  237]\n",
      "loss: 0.042139  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.048144 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.028270  [    4/  237]\n",
      "loss: 0.023670  [   84/  237]\n",
      "loss: 0.021176  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.048136 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.033073  [    4/  237]\n",
      "loss: 0.026604  [   84/  237]\n",
      "loss: 0.029131  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.6%, Avg loss: 0.046807 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.042970  [    4/  237]\n",
      "loss: 0.022836  [   84/  237]\n",
      "loss: 0.043230  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.6%, Avg loss: 0.047450 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.032382  [    4/  237]\n",
      "loss: 0.032472  [   84/  237]\n",
      "loss: 0.031240  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.047743 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.028772  [    4/  237]\n",
      "loss: 0.020784  [   84/  237]\n",
      "loss: 0.031210  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.046772 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.033821  [    4/  237]\n",
      "loss: 0.023833  [   84/  237]\n",
      "loss: 0.046837  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.047893 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.023253  [    4/  237]\n",
      "loss: 0.026834  [   84/  237]\n",
      "loss: 0.045896  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.047013 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.023816  [    4/  237]\n",
      "loss: 0.021668  [   84/  237]\n",
      "loss: 0.035969  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.046330 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.033920  [    4/  237]\n",
      "loss: 0.042728  [   84/  237]\n",
      "loss: 0.026667  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.046888 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.033190  [    4/  237]\n",
      "loss: 0.024029  [   84/  237]\n",
      "loss: 0.032843  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.046731 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.021908  [    4/  237]\n",
      "loss: 0.029035  [   84/  237]\n",
      "loss: 0.034594  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.6%, Avg loss: 0.046250 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.025146  [    4/  237]\n",
      "loss: 0.030956  [   84/  237]\n",
      "loss: 0.016271  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.046820 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.038078  [    4/  237]\n",
      "loss: 0.027672  [   84/  237]\n",
      "loss: 0.028527  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.046371 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.034679  [    4/  237]\n",
      "loss: 0.025085  [   84/  237]\n",
      "loss: 0.027034  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.046122 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.031271  [    4/  237]\n",
      "loss: 0.020494  [   84/  237]\n",
      "loss: 0.031232  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 5.0%, Avg loss: 0.045855 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.021324  [    4/  237]\n",
      "loss: 0.024252  [   84/  237]\n",
      "loss: 0.029159  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 5.0%, Avg loss: 0.046070 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.035182  [    4/  237]\n",
      "loss: 0.018712  [   84/  237]\n",
      "loss: 0.029337  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.046635 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.030149  [    4/  237]\n",
      "loss: 0.019837  [   84/  237]\n",
      "loss: 0.031104  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.6%, Avg loss: 0.045713 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.035638  [    4/  237]\n",
      "loss: 0.020684  [   84/  237]\n",
      "loss: 0.029255  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 8.3%, Avg loss: 0.045823 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.023936  [    4/  237]\n",
      "loss: 0.026944  [   84/  237]\n",
      "loss: 0.033017  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 5.0%, Avg loss: 0.045388 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.017971  [    4/  237]\n",
      "loss: 0.019563  [   84/  237]\n",
      "loss: 0.027335  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.045707 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.033746  [    4/  237]\n",
      "loss: 0.021755  [   84/  237]\n",
      "loss: 0.020859  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 8.3%, Avg loss: 0.045874 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.021605  [    4/  237]\n",
      "loss: 0.022180  [   84/  237]\n",
      "loss: 0.027201  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.9%, Avg loss: 0.045217 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.023345  [    4/  237]\n",
      "loss: 0.031427  [   84/  237]\n",
      "loss: 0.033373  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 6.7%, Avg loss: 0.045176 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.021525  [    4/  237]\n",
      "loss: 0.043881  [   84/  237]\n",
      "loss: 0.021218  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.045999 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.027628  [    4/  237]\n",
      "loss: 0.032005  [   84/  237]\n",
      "loss: 0.023621  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 5.6%, Avg loss: 0.044615 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.025976  [    4/  237]\n",
      "loss: 0.025120  [   84/  237]\n",
      "loss: 0.038128  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.045070 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.026017  [    4/  237]\n",
      "loss: 0.027122  [   84/  237]\n",
      "loss: 0.030124  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.044373 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.035732  [    4/  237]\n",
      "loss: 0.029921  [   84/  237]\n",
      "loss: 0.024922  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.045217 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.025949  [    4/  237]\n",
      "loss: 0.021225  [   84/  237]\n",
      "loss: 0.024206  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 7.2%, Avg loss: 0.044238 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.031485  [    4/  237]\n",
      "loss: 0.038930  [   84/  237]\n",
      "loss: 0.014597  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.9%, Avg loss: 0.044811 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.019350  [    4/  237]\n",
      "loss: 0.021391  [   84/  237]\n",
      "loss: 0.043034  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 3.3%, Avg loss: 0.044225 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.037231  [    4/  237]\n",
      "loss: 0.031381  [   84/  237]\n",
      "loss: 0.021358  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.4%, Board accuracy: 8.3%, Avg loss: 0.044340 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.025496  [    4/  237]\n",
      "loss: 0.034495  [   84/  237]\n",
      "loss: 0.017439  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.044393 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.024789  [    4/  237]\n",
      "loss: 0.033866  [   84/  237]\n",
      "loss: 0.038052  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 5.0%, Avg loss: 0.044222 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.039803  [    4/  237]\n",
      "loss: 0.024673  [   84/  237]\n",
      "loss: 0.014577  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.9%, Avg loss: 0.044176 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.024239  [    4/  237]\n",
      "loss: 0.025730  [   84/  237]\n",
      "loss: 0.022821  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 9.4%, Avg loss: 0.044531 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.020366  [    4/  237]\n",
      "loss: 0.014599  [   84/  237]\n",
      "loss: 0.020192  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 10.0%, Avg loss: 0.043805 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.019713  [    4/  237]\n",
      "loss: 0.020670  [   84/  237]\n",
      "loss: 0.026310  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.043919 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.031431  [    4/  237]\n",
      "loss: 0.019165  [   84/  237]\n",
      "loss: 0.024827  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.043761 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.034974  [    4/  237]\n",
      "loss: 0.017354  [   84/  237]\n",
      "loss: 0.016251  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.043693 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.017476  [    4/  237]\n",
      "loss: 0.030571  [   84/  237]\n",
      "loss: 0.016094  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.043779 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.020025  [    4/  237]\n",
      "loss: 0.026108  [   84/  237]\n",
      "loss: 0.016768  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.043161 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.039814  [    4/  237]\n",
      "loss: 0.025601  [   84/  237]\n",
      "loss: 0.026842  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.043446 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.039135  [    4/  237]\n",
      "loss: 0.028200  [   84/  237]\n",
      "loss: 0.024386  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.043455 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.010864  [    4/  237]\n",
      "loss: 0.025638  [   84/  237]\n",
      "loss: 0.017003  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.043023 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.024029  [    4/  237]\n",
      "loss: 0.021877  [   84/  237]\n",
      "loss: 0.033065  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 6.7%, Avg loss: 0.042882 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.028654  [    4/  237]\n",
      "loss: 0.013311  [   84/  237]\n",
      "loss: 0.030534  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.042670 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.015675  [    4/  237]\n",
      "loss: 0.023090  [   84/  237]\n",
      "loss: 0.036650  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.9%, Avg loss: 0.042633 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.024536  [    4/  237]\n",
      "loss: 0.032093  [   84/  237]\n",
      "loss: 0.029498  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.043109 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.018958  [    4/  237]\n",
      "loss: 0.016398  [   84/  237]\n",
      "loss: 0.025291  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.042962 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.029006  [    4/  237]\n",
      "loss: 0.036950  [   84/  237]\n",
      "loss: 0.026855  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.9%, Avg loss: 0.042586 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.035862  [    4/  237]\n",
      "loss: 0.029000  [   84/  237]\n",
      "loss: 0.026772  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 6.7%, Avg loss: 0.043428 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.019003  [    4/  237]\n",
      "loss: 0.028879  [   84/  237]\n",
      "loss: 0.027791  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.042369 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.028620  [    4/  237]\n",
      "loss: 0.030286  [   84/  237]\n",
      "loss: 0.038244  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.042853 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.028224  [    4/  237]\n",
      "loss: 0.020454  [   84/  237]\n",
      "loss: 0.029510  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.9%, Avg loss: 0.043131 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.027405  [    4/  237]\n",
      "loss: 0.033243  [   84/  237]\n",
      "loss: 0.019549  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041935 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.028392  [    4/  237]\n",
      "loss: 0.028187  [   84/  237]\n",
      "loss: 0.035332  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.042013 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.018163  [    4/  237]\n",
      "loss: 0.017060  [   84/  237]\n",
      "loss: 0.020896  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.042938 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.020994  [    4/  237]\n",
      "loss: 0.015202  [   84/  237]\n",
      "loss: 0.024483  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.041611 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.022038  [    4/  237]\n",
      "loss: 0.015931  [   84/  237]\n",
      "loss: 0.015766  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 12.2%, Avg loss: 0.041964 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.014617  [    4/  237]\n",
      "loss: 0.033403  [   84/  237]\n",
      "loss: 0.022201  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 10.0%, Avg loss: 0.041652 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.016591  [    4/  237]\n",
      "loss: 0.024110  [   84/  237]\n",
      "loss: 0.032293  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.9%, Avg loss: 0.041902 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.021965  [    4/  237]\n",
      "loss: 0.026823  [   84/  237]\n",
      "loss: 0.020472  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.9%, Avg loss: 0.042111 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.032674  [    4/  237]\n",
      "loss: 0.015400  [   84/  237]\n",
      "loss: 0.015125  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041994 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.018544  [    4/  237]\n",
      "loss: 0.023460  [   84/  237]\n",
      "loss: 0.022568  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.042322 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.013142  [    4/  237]\n",
      "loss: 0.018398  [   84/  237]\n",
      "loss: 0.018786  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041441 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.017174  [    4/  237]\n",
      "loss: 0.017296  [   84/  237]\n",
      "loss: 0.016364  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 6.7%, Avg loss: 0.041924 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.021133  [    4/  237]\n",
      "loss: 0.021849  [   84/  237]\n",
      "loss: 0.016335  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 8.3%, Avg loss: 0.041667 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.015897  [    4/  237]\n",
      "loss: 0.020705  [   84/  237]\n",
      "loss: 0.021190  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 10.6%, Avg loss: 0.041602 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.018205  [    4/  237]\n",
      "loss: 0.027048  [   84/  237]\n",
      "loss: 0.024763  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.9%, Avg loss: 0.041406 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.021436  [    4/  237]\n",
      "loss: 0.044956  [   84/  237]\n",
      "loss: 0.012919  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.5%, Board accuracy: 6.7%, Avg loss: 0.041461 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.010642  [    4/  237]\n",
      "loss: 0.019761  [   84/  237]\n",
      "loss: 0.018318  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041198 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.024314  [    4/  237]\n",
      "loss: 0.021024  [   84/  237]\n",
      "loss: 0.015596  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041175 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.029427  [    4/  237]\n",
      "loss: 0.019666  [   84/  237]\n",
      "loss: 0.027948  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041002 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.014575  [    4/  237]\n",
      "loss: 0.016224  [   84/  237]\n",
      "loss: 0.015907  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041353 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.020218  [    4/  237]\n",
      "loss: 0.019288  [   84/  237]\n",
      "loss: 0.016171  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041412 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.019913  [    4/  237]\n",
      "loss: 0.024236  [   84/  237]\n",
      "loss: 0.025437  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041503 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.016231  [    4/  237]\n",
      "loss: 0.025568  [   84/  237]\n",
      "loss: 0.027487  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.041062 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.011707  [    4/  237]\n",
      "loss: 0.022058  [   84/  237]\n",
      "loss: 0.033183  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 10.6%, Avg loss: 0.040389 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.021654  [    4/  237]\n",
      "loss: 0.028560  [   84/  237]\n",
      "loss: 0.019414  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.040849 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.013566  [    4/  237]\n",
      "loss: 0.017556  [   84/  237]\n",
      "loss: 0.020949  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 10.6%, Avg loss: 0.041207 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.017341  [    4/  237]\n",
      "loss: 0.032316  [   84/  237]\n",
      "loss: 0.012531  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 10.6%, Avg loss: 0.040347 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.018035  [    4/  237]\n",
      "loss: 0.019559  [   84/  237]\n",
      "loss: 0.022247  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 6.7%, Avg loss: 0.041442 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.015402  [    4/  237]\n",
      "loss: 0.017220  [   84/  237]\n",
      "loss: 0.022426  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.040069 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.032810  [    4/  237]\n",
      "loss: 0.025469  [   84/  237]\n",
      "loss: 0.025242  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 11.7%, Avg loss: 0.040751 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.022886  [    4/  237]\n",
      "loss: 0.017960  [   84/  237]\n",
      "loss: 0.018684  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 9.4%, Avg loss: 0.039949 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.020516  [    4/  237]\n",
      "loss: 0.030898  [   84/  237]\n",
      "loss: 0.013497  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 8.3%, Avg loss: 0.040278 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.013831  [    4/  237]\n",
      "loss: 0.018850  [   84/  237]\n",
      "loss: 0.030686  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 6.7%, Avg loss: 0.040305 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.014965  [    4/  237]\n",
      "loss: 0.028626  [   84/  237]\n",
      "loss: 0.012122  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.040315 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.023481  [    4/  237]\n",
      "loss: 0.023129  [   84/  237]\n",
      "loss: 0.016434  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.040126 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.013941  [    4/  237]\n",
      "loss: 0.014331  [   84/  237]\n",
      "loss: 0.024117  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.9%, Avg loss: 0.040665 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.025446  [    4/  237]\n",
      "loss: 0.017700  [   84/  237]\n",
      "loss: 0.024583  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 6.7%, Avg loss: 0.040214 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.030723  [    4/  237]\n",
      "loss: 0.030953  [   84/  237]\n",
      "loss: 0.017785  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.040584 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.023002  [    4/  237]\n",
      "loss: 0.014895  [   84/  237]\n",
      "loss: 0.016212  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.040058 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.016009  [    4/  237]\n",
      "loss: 0.033815  [   84/  237]\n",
      "loss: 0.018285  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 12.2%, Avg loss: 0.039798 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.024443  [    4/  237]\n",
      "loss: 0.021026  [   84/  237]\n",
      "loss: 0.028234  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 10.0%, Avg loss: 0.039654 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.015480  [    4/  237]\n",
      "loss: 0.011308  [   84/  237]\n",
      "loss: 0.027062  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 7.2%, Avg loss: 0.039538 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.011198  [    4/  237]\n",
      "loss: 0.031211  [   84/  237]\n",
      "loss: 0.012561  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.039755 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.018813  [    4/  237]\n",
      "loss: 0.014688  [   84/  237]\n",
      "loss: 0.014948  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.039095 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.012709  [    4/  237]\n",
      "loss: 0.015694  [   84/  237]\n",
      "loss: 0.027719  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 8.3%, Avg loss: 0.039900 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.013187  [    4/  237]\n",
      "loss: 0.017409  [   84/  237]\n",
      "loss: 0.021354  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 6.7%, Avg loss: 0.039462 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.019391  [    4/  237]\n",
      "loss: 0.014659  [   84/  237]\n",
      "loss: 0.009088  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.039588 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.023584  [    4/  237]\n",
      "loss: 0.019919  [   84/  237]\n",
      "loss: 0.023896  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 8.3%, Avg loss: 0.039353 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.014992  [    4/  237]\n",
      "loss: 0.018019  [   84/  237]\n",
      "loss: 0.011742  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.039737 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.019674  [    4/  237]\n",
      "loss: 0.025014  [   84/  237]\n",
      "loss: 0.018361  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.039520 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.016395  [    4/  237]\n",
      "loss: 0.012021  [   84/  237]\n",
      "loss: 0.018380  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 10.0%, Avg loss: 0.039640 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.013611  [    4/  237]\n",
      "loss: 0.015447  [   84/  237]\n",
      "loss: 0.017491  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 8.9%, Avg loss: 0.039396 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.011549  [    4/  237]\n",
      "loss: 0.020143  [   84/  237]\n",
      "loss: 0.025339  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.039562 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.009088  [    4/  237]\n",
      "loss: 0.022074  [   84/  237]\n",
      "loss: 0.017641  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.039530 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "loss: 0.024178  [    4/  237]\n",
      "loss: 0.010884  [   84/  237]\n",
      "loss: 0.018328  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.039002 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "loss: 0.011392  [    4/  237]\n",
      "loss: 0.019342  [   84/  237]\n",
      "loss: 0.018573  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.038669 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "loss: 0.023936  [    4/  237]\n",
      "loss: 0.013786  [   84/  237]\n",
      "loss: 0.016793  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 9.4%, Avg loss: 0.038711 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "loss: 0.011129  [    4/  237]\n",
      "loss: 0.012535  [   84/  237]\n",
      "loss: 0.011119  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.6%, Board accuracy: 6.7%, Avg loss: 0.039196 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "loss: 0.014514  [    4/  237]\n",
      "loss: 0.011158  [   84/  237]\n",
      "loss: 0.015528  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.038676 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "loss: 0.016911  [    4/  237]\n",
      "loss: 0.016096  [   84/  237]\n",
      "loss: 0.038061  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.038780 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "loss: 0.021267  [    4/  237]\n",
      "loss: 0.018994  [   84/  237]\n",
      "loss: 0.018888  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.038142 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "loss: 0.011434  [    4/  237]\n",
      "loss: 0.012912  [   84/  237]\n",
      "loss: 0.011924  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.039185 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "loss: 0.020692  [    4/  237]\n",
      "loss: 0.014838  [   84/  237]\n",
      "loss: 0.015680  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.039012 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "loss: 0.012609  [    4/  237]\n",
      "loss: 0.010897  [   84/  237]\n",
      "loss: 0.023333  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 8.3%, Avg loss: 0.038257 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "loss: 0.014627  [    4/  237]\n",
      "loss: 0.020062  [   84/  237]\n",
      "loss: 0.013927  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 13.9%, Avg loss: 0.038990 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "loss: 0.013192  [    4/  237]\n",
      "loss: 0.026144  [   84/  237]\n",
      "loss: 0.015286  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 13.9%, Avg loss: 0.038751 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "loss: 0.010993  [    4/  237]\n",
      "loss: 0.028168  [   84/  237]\n",
      "loss: 0.012783  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.038208 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "loss: 0.012154  [    4/  237]\n",
      "loss: 0.017357  [   84/  237]\n",
      "loss: 0.015308  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 13.3%, Avg loss: 0.038977 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "loss: 0.016578  [    4/  237]\n",
      "loss: 0.006578  [   84/  237]\n",
      "loss: 0.026272  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 13.3%, Avg loss: 0.038614 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "loss: 0.013449  [    4/  237]\n",
      "loss: 0.016184  [   84/  237]\n",
      "loss: 0.020116  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.038821 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "loss: 0.019058  [    4/  237]\n",
      "loss: 0.013291  [   84/  237]\n",
      "loss: 0.016067  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.038611 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "loss: 0.017850  [    4/  237]\n",
      "loss: 0.012031  [   84/  237]\n",
      "loss: 0.024994  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.038740 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "loss: 0.023730  [    4/  237]\n",
      "loss: 0.017137  [   84/  237]\n",
      "loss: 0.014066  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.038393 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "loss: 0.021341  [    4/  237]\n",
      "loss: 0.009588  [   84/  237]\n",
      "loss: 0.011123  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.038295 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "loss: 0.015606  [    4/  237]\n",
      "loss: 0.015118  [   84/  237]\n",
      "loss: 0.011343  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.038079 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "loss: 0.017596  [    4/  237]\n",
      "loss: 0.018792  [   84/  237]\n",
      "loss: 0.019608  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.038335 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "loss: 0.021776  [    4/  237]\n",
      "loss: 0.015580  [   84/  237]\n",
      "loss: 0.012312  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.038289 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "loss: 0.008987  [    4/  237]\n",
      "loss: 0.014801  [   84/  237]\n",
      "loss: 0.017764  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.037643 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "loss: 0.012488  [    4/  237]\n",
      "loss: 0.015079  [   84/  237]\n",
      "loss: 0.014110  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 12.2%, Avg loss: 0.038033 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "loss: 0.026544  [    4/  237]\n",
      "loss: 0.014303  [   84/  237]\n",
      "loss: 0.031649  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.038574 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "loss: 0.021695  [    4/  237]\n",
      "loss: 0.015094  [   84/  237]\n",
      "loss: 0.023929  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 12.2%, Avg loss: 0.038281 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "loss: 0.022595  [    4/  237]\n",
      "loss: 0.011548  [   84/  237]\n",
      "loss: 0.014065  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.038019 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "loss: 0.012493  [    4/  237]\n",
      "loss: 0.017289  [   84/  237]\n",
      "loss: 0.010955  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 13.3%, Avg loss: 0.038004 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "loss: 0.015184  [    4/  237]\n",
      "loss: 0.022452  [   84/  237]\n",
      "loss: 0.026426  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 13.3%, Avg loss: 0.038268 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "loss: 0.023303  [    4/  237]\n",
      "loss: 0.009619  [   84/  237]\n",
      "loss: 0.029976  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.037777 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "loss: 0.015672  [    4/  237]\n",
      "loss: 0.017948  [   84/  237]\n",
      "loss: 0.025619  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 12.2%, Avg loss: 0.038170 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "loss: 0.025155  [    4/  237]\n",
      "loss: 0.009367  [   84/  237]\n",
      "loss: 0.013802  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.037721 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "loss: 0.018391  [    4/  237]\n",
      "loss: 0.010945  [   84/  237]\n",
      "loss: 0.022863  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.037574 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "loss: 0.013897  [    4/  237]\n",
      "loss: 0.017837  [   84/  237]\n",
      "loss: 0.022865  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.037086 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "loss: 0.016501  [    4/  237]\n",
      "loss: 0.014078  [   84/  237]\n",
      "loss: 0.021793  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.037828 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "loss: 0.016146  [    4/  237]\n",
      "loss: 0.011146  [   84/  237]\n",
      "loss: 0.013199  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 12.2%, Avg loss: 0.037404 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "loss: 0.018388  [    4/  237]\n",
      "loss: 0.013514  [   84/  237]\n",
      "loss: 0.021343  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.037506 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "loss: 0.013042  [    4/  237]\n",
      "loss: 0.022513  [   84/  237]\n",
      "loss: 0.019567  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.1%, Avg loss: 0.037077 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "loss: 0.013708  [    4/  237]\n",
      "loss: 0.019090  [   84/  237]\n",
      "loss: 0.013005  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.037662 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "loss: 0.015633  [    4/  237]\n",
      "loss: 0.015619  [   84/  237]\n",
      "loss: 0.013624  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 12.2%, Avg loss: 0.038225 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "loss: 0.009661  [    4/  237]\n",
      "loss: 0.016465  [   84/  237]\n",
      "loss: 0.017504  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.037884 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "loss: 0.016942  [    4/  237]\n",
      "loss: 0.016136  [   84/  237]\n",
      "loss: 0.013659  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.037866 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "loss: 0.008606  [    4/  237]\n",
      "loss: 0.020480  [   84/  237]\n",
      "loss: 0.011330  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.037786 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "loss: 0.016258  [    4/  237]\n",
      "loss: 0.014006  [   84/  237]\n",
      "loss: 0.012430  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.037783 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "loss: 0.017128  [    4/  237]\n",
      "loss: 0.021214  [   84/  237]\n",
      "loss: 0.009019  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.036986 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "loss: 0.014437  [    4/  237]\n",
      "loss: 0.033795  [   84/  237]\n",
      "loss: 0.021356  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.037175 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "loss: 0.012690  [    4/  237]\n",
      "loss: 0.020524  [   84/  237]\n",
      "loss: 0.013773  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 13.3%, Avg loss: 0.037734 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "loss: 0.013079  [    4/  237]\n",
      "loss: 0.010375  [   84/  237]\n",
      "loss: 0.013175  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.037528 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "loss: 0.021344  [    4/  237]\n",
      "loss: 0.019944  [   84/  237]\n",
      "loss: 0.012993  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.037438 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "loss: 0.013470  [    4/  237]\n",
      "loss: 0.009885  [   84/  237]\n",
      "loss: 0.014114  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.037065 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "loss: 0.019361  [    4/  237]\n",
      "loss: 0.030085  [   84/  237]\n",
      "loss: 0.018258  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.037176 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "loss: 0.019531  [    4/  237]\n",
      "loss: 0.015598  [   84/  237]\n",
      "loss: 0.019691  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 12.2%, Avg loss: 0.037029 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "loss: 0.012821  [    4/  237]\n",
      "loss: 0.016270  [   84/  237]\n",
      "loss: 0.019141  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.037502 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "loss: 0.030400  [    4/  237]\n",
      "loss: 0.009978  [   84/  237]\n",
      "loss: 0.010809  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.036800 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "loss: 0.015268  [    4/  237]\n",
      "loss: 0.031921  [   84/  237]\n",
      "loss: 0.023401  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.037259 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "loss: 0.027068  [    4/  237]\n",
      "loss: 0.027586  [   84/  237]\n",
      "loss: 0.019227  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.036983 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "loss: 0.018404  [    4/  237]\n",
      "loss: 0.011368  [   84/  237]\n",
      "loss: 0.016277  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.036453 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "loss: 0.009157  [    4/  237]\n",
      "loss: 0.011462  [   84/  237]\n",
      "loss: 0.011194  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.037586 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "loss: 0.010088  [    4/  237]\n",
      "loss: 0.012961  [   84/  237]\n",
      "loss: 0.020293  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.037400 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "loss: 0.008672  [    4/  237]\n",
      "loss: 0.012565  [   84/  237]\n",
      "loss: 0.013700  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.036520 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "loss: 0.014691  [    4/  237]\n",
      "loss: 0.013576  [   84/  237]\n",
      "loss: 0.013553  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 12.2%, Avg loss: 0.036706 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "loss: 0.015289  [    4/  237]\n",
      "loss: 0.023902  [   84/  237]\n",
      "loss: 0.009270  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 8.3%, Avg loss: 0.037079 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "loss: 0.017566  [    4/  237]\n",
      "loss: 0.010578  [   84/  237]\n",
      "loss: 0.013680  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.036750 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "loss: 0.009685  [    4/  237]\n",
      "loss: 0.013210  [   84/  237]\n",
      "loss: 0.015426  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.036808 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "loss: 0.006714  [    4/  237]\n",
      "loss: 0.019842  [   84/  237]\n",
      "loss: 0.022605  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.1%, Avg loss: 0.036401 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "loss: 0.015730  [    4/  237]\n",
      "loss: 0.014593  [   84/  237]\n",
      "loss: 0.020225  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.6%, Avg loss: 0.036274 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "loss: 0.012040  [    4/  237]\n",
      "loss: 0.011190  [   84/  237]\n",
      "loss: 0.009728  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.036385 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "loss: 0.016823  [    4/  237]\n",
      "loss: 0.010723  [   84/  237]\n",
      "loss: 0.014830  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.036496 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "loss: 0.018614  [    4/  237]\n",
      "loss: 0.010597  [   84/  237]\n",
      "loss: 0.024255  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.036823 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "loss: 0.016871  [    4/  237]\n",
      "loss: 0.014996  [   84/  237]\n",
      "loss: 0.016223  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.036147 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "loss: 0.017102  [    4/  237]\n",
      "loss: 0.011486  [   84/  237]\n",
      "loss: 0.010104  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 13.3%, Avg loss: 0.036420 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "loss: 0.010414  [    4/  237]\n",
      "loss: 0.017629  [   84/  237]\n",
      "loss: 0.017015  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 14.4%, Avg loss: 0.036187 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "loss: 0.016385  [    4/  237]\n",
      "loss: 0.015022  [   84/  237]\n",
      "loss: 0.011092  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.035773 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "loss: 0.017833  [    4/  237]\n",
      "loss: 0.020150  [   84/  237]\n",
      "loss: 0.016716  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.036503 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "loss: 0.016399  [    4/  237]\n",
      "loss: 0.014272  [   84/  237]\n",
      "loss: 0.019123  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.036076 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "loss: 0.008025  [    4/  237]\n",
      "loss: 0.015848  [   84/  237]\n",
      "loss: 0.018348  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 12.8%, Avg loss: 0.036249 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "loss: 0.026540  [    4/  237]\n",
      "loss: 0.009176  [   84/  237]\n",
      "loss: 0.008905  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.036103 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "loss: 0.014758  [    4/  237]\n",
      "loss: 0.009914  [   84/  237]\n",
      "loss: 0.010202  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.036526 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "loss: 0.009335  [    4/  237]\n",
      "loss: 0.018293  [   84/  237]\n",
      "loss: 0.013827  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.035754 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "loss: 0.013372  [    4/  237]\n",
      "loss: 0.019890  [   84/  237]\n",
      "loss: 0.019991  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 10.0%, Avg loss: 0.036203 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "loss: 0.016061  [    4/  237]\n",
      "loss: 0.011973  [   84/  237]\n",
      "loss: 0.015749  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.036115 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "loss: 0.014818  [    4/  237]\n",
      "loss: 0.012070  [   84/  237]\n",
      "loss: 0.011889  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 11.7%, Avg loss: 0.036396 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "loss: 0.014946  [    4/  237]\n",
      "loss: 0.012031  [   84/  237]\n",
      "loss: 0.021659  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 12.2%, Avg loss: 0.036575 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "loss: 0.019542  [    4/  237]\n",
      "loss: 0.011439  [   84/  237]\n",
      "loss: 0.013209  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.035894 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "loss: 0.016046  [    4/  237]\n",
      "loss: 0.012029  [   84/  237]\n",
      "loss: 0.008538  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.035434 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "loss: 0.014536  [    4/  237]\n",
      "loss: 0.015168  [   84/  237]\n",
      "loss: 0.021324  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.036243 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "loss: 0.010482  [    4/  237]\n",
      "loss: 0.013116  [   84/  237]\n",
      "loss: 0.019496  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.035369 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "loss: 0.013229  [    4/  237]\n",
      "loss: 0.012247  [   84/  237]\n",
      "loss: 0.010131  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.036137 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "loss: 0.012849  [    4/  237]\n",
      "loss: 0.018713  [   84/  237]\n",
      "loss: 0.012708  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.036007 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "loss: 0.011679  [    4/  237]\n",
      "loss: 0.011731  [   84/  237]\n",
      "loss: 0.019141  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.6%, Avg loss: 0.035732 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "loss: 0.011504  [    4/  237]\n",
      "loss: 0.021404  [   84/  237]\n",
      "loss: 0.012540  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.036302 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "loss: 0.012316  [    4/  237]\n",
      "loss: 0.026055  [   84/  237]\n",
      "loss: 0.013992  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.1%, Avg loss: 0.036387 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "loss: 0.014558  [    4/  237]\n",
      "loss: 0.012419  [   84/  237]\n",
      "loss: 0.007513  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.035893 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "loss: 0.011067  [    4/  237]\n",
      "loss: 0.009429  [   84/  237]\n",
      "loss: 0.021752  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.035328 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "loss: 0.015338  [    4/  237]\n",
      "loss: 0.013254  [   84/  237]\n",
      "loss: 0.007253  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.035968 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "loss: 0.017471  [    4/  237]\n",
      "loss: 0.010860  [   84/  237]\n",
      "loss: 0.015474  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.036136 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "loss: 0.018310  [    4/  237]\n",
      "loss: 0.017823  [   84/  237]\n",
      "loss: 0.011643  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.036104 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "loss: 0.017451  [    4/  237]\n",
      "loss: 0.019054  [   84/  237]\n",
      "loss: 0.016996  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.035787 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "loss: 0.011524  [    4/  237]\n",
      "loss: 0.007550  [   84/  237]\n",
      "loss: 0.018062  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.035531 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "loss: 0.022533  [    4/  237]\n",
      "loss: 0.010124  [   84/  237]\n",
      "loss: 0.010089  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.6%, Avg loss: 0.035742 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "loss: 0.013626  [    4/  237]\n",
      "loss: 0.014853  [   84/  237]\n",
      "loss: 0.008689  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.035513 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "loss: 0.006894  [    4/  237]\n",
      "loss: 0.011485  [   84/  237]\n",
      "loss: 0.026165  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.035632 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "loss: 0.008843  [    4/  237]\n",
      "loss: 0.008696  [   84/  237]\n",
      "loss: 0.020604  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.036228 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "loss: 0.009809  [    4/  237]\n",
      "loss: 0.014604  [   84/  237]\n",
      "loss: 0.023607  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 11.7%, Avg loss: 0.035815 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "loss: 0.015855  [    4/  237]\n",
      "loss: 0.012193  [   84/  237]\n",
      "loss: 0.024136  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 12.2%, Avg loss: 0.035540 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "loss: 0.017742  [    4/  237]\n",
      "loss: 0.011397  [   84/  237]\n",
      "loss: 0.013970  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.035957 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "loss: 0.009884  [    4/  237]\n",
      "loss: 0.015098  [   84/  237]\n",
      "loss: 0.009176  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.035607 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "loss: 0.007602  [    4/  237]\n",
      "loss: 0.006949  [   84/  237]\n",
      "loss: 0.015071  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.035697 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "loss: 0.008968  [    4/  237]\n",
      "loss: 0.011346  [   84/  237]\n",
      "loss: 0.013085  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 10.0%, Avg loss: 0.035814 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "loss: 0.024909  [    4/  237]\n",
      "loss: 0.007671  [   84/  237]\n",
      "loss: 0.010228  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 11.7%, Avg loss: 0.035482 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "loss: 0.014345  [    4/  237]\n",
      "loss: 0.007736  [   84/  237]\n",
      "loss: 0.009772  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.035590 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "loss: 0.017546  [    4/  237]\n",
      "loss: 0.008524  [   84/  237]\n",
      "loss: 0.010909  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.035542 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "loss: 0.013537  [    4/  237]\n",
      "loss: 0.009503  [   84/  237]\n",
      "loss: 0.011588  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.036106 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "loss: 0.014355  [    4/  237]\n",
      "loss: 0.013917  [   84/  237]\n",
      "loss: 0.021539  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034980 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "loss: 0.018013  [    4/  237]\n",
      "loss: 0.008203  [   84/  237]\n",
      "loss: 0.018568  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.035195 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "loss: 0.014687  [    4/  237]\n",
      "loss: 0.011074  [   84/  237]\n",
      "loss: 0.013012  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 12.2%, Avg loss: 0.035342 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "loss: 0.016766  [    4/  237]\n",
      "loss: 0.008822  [   84/  237]\n",
      "loss: 0.010742  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 12.8%, Avg loss: 0.034800 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "loss: 0.006852  [    4/  237]\n",
      "loss: 0.007824  [   84/  237]\n",
      "loss: 0.008569  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.035179 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "loss: 0.018374  [    4/  237]\n",
      "loss: 0.021187  [   84/  237]\n",
      "loss: 0.019154  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.035389 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "loss: 0.020896  [    4/  237]\n",
      "loss: 0.006747  [   84/  237]\n",
      "loss: 0.019560  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.035561 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "loss: 0.020524  [    4/  237]\n",
      "loss: 0.007890  [   84/  237]\n",
      "loss: 0.013045  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.035467 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "loss: 0.015139  [    4/  237]\n",
      "loss: 0.027121  [   84/  237]\n",
      "loss: 0.013114  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034941 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "loss: 0.014094  [    4/  237]\n",
      "loss: 0.010277  [   84/  237]\n",
      "loss: 0.014548  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.034933 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "loss: 0.014490  [    4/  237]\n",
      "loss: 0.005957  [   84/  237]\n",
      "loss: 0.008825  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.035684 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "loss: 0.006685  [    4/  237]\n",
      "loss: 0.013221  [   84/  237]\n",
      "loss: 0.009240  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.035014 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "loss: 0.006706  [    4/  237]\n",
      "loss: 0.009796  [   84/  237]\n",
      "loss: 0.011664  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034556 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "loss: 0.016789  [    4/  237]\n",
      "loss: 0.010480  [   84/  237]\n",
      "loss: 0.006935  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.035156 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "loss: 0.018665  [    4/  237]\n",
      "loss: 0.012336  [   84/  237]\n",
      "loss: 0.008673  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.035367 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "loss: 0.008906  [    4/  237]\n",
      "loss: 0.013229  [   84/  237]\n",
      "loss: 0.016405  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034878 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "loss: 0.007068  [    4/  237]\n",
      "loss: 0.013994  [   84/  237]\n",
      "loss: 0.011567  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.035088 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "loss: 0.011652  [    4/  237]\n",
      "loss: 0.012123  [   84/  237]\n",
      "loss: 0.007603  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.035370 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "loss: 0.006583  [    4/  237]\n",
      "loss: 0.010433  [   84/  237]\n",
      "loss: 0.007912  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 12.2%, Avg loss: 0.035143 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "loss: 0.010507  [    4/  237]\n",
      "loss: 0.015955  [   84/  237]\n",
      "loss: 0.009488  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.035202 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "loss: 0.015600  [    4/  237]\n",
      "loss: 0.016582  [   84/  237]\n",
      "loss: 0.018363  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.034950 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "loss: 0.011806  [    4/  237]\n",
      "loss: 0.007136  [   84/  237]\n",
      "loss: 0.011960  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.3%, Avg loss: 0.035142 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "loss: 0.013247  [    4/  237]\n",
      "loss: 0.007263  [   84/  237]\n",
      "loss: 0.015533  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.035554 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "loss: 0.010192  [    4/  237]\n",
      "loss: 0.007307  [   84/  237]\n",
      "loss: 0.015858  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.035461 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "loss: 0.010279  [    4/  237]\n",
      "loss: 0.008650  [   84/  237]\n",
      "loss: 0.013732  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034853 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "loss: 0.017247  [    4/  237]\n",
      "loss: 0.007510  [   84/  237]\n",
      "loss: 0.013490  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.035352 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "loss: 0.015223  [    4/  237]\n",
      "loss: 0.014720  [   84/  237]\n",
      "loss: 0.012592  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.035118 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "loss: 0.019071  [    4/  237]\n",
      "loss: 0.007197  [   84/  237]\n",
      "loss: 0.008082  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034436 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "loss: 0.006381  [    4/  237]\n",
      "loss: 0.010980  [   84/  237]\n",
      "loss: 0.009595  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.035337 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "loss: 0.007084  [    4/  237]\n",
      "loss: 0.013485  [   84/  237]\n",
      "loss: 0.016016  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 11.7%, Avg loss: 0.035203 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "loss: 0.010835  [    4/  237]\n",
      "loss: 0.012570  [   84/  237]\n",
      "loss: 0.010903  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 11.7%, Avg loss: 0.034906 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "loss: 0.013206  [    4/  237]\n",
      "loss: 0.009086  [   84/  237]\n",
      "loss: 0.013379  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.034641 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "loss: 0.014289  [    4/  237]\n",
      "loss: 0.009750  [   84/  237]\n",
      "loss: 0.019240  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034722 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "loss: 0.013998  [    4/  237]\n",
      "loss: 0.006475  [   84/  237]\n",
      "loss: 0.005998  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 11.7%, Avg loss: 0.035185 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "loss: 0.010899  [    4/  237]\n",
      "loss: 0.016632  [   84/  237]\n",
      "loss: 0.011003  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034878 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "loss: 0.018785  [    4/  237]\n",
      "loss: 0.012202  [   84/  237]\n",
      "loss: 0.007655  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.035104 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "loss: 0.008862  [    4/  237]\n",
      "loss: 0.017814  [   84/  237]\n",
      "loss: 0.004520  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.034364 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "loss: 0.009794  [    4/  237]\n",
      "loss: 0.005863  [   84/  237]\n",
      "loss: 0.006479  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.035019 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "loss: 0.008088  [    4/  237]\n",
      "loss: 0.009204  [   84/  237]\n",
      "loss: 0.012849  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.035212 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "loss: 0.010648  [    4/  237]\n",
      "loss: 0.008217  [   84/  237]\n",
      "loss: 0.009789  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034958 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "loss: 0.011534  [    4/  237]\n",
      "loss: 0.015960  [   84/  237]\n",
      "loss: 0.007892  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034712 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "loss: 0.011780  [    4/  237]\n",
      "loss: 0.009321  [   84/  237]\n",
      "loss: 0.011824  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 12.8%, Avg loss: 0.035032 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "loss: 0.006560  [    4/  237]\n",
      "loss: 0.007354  [   84/  237]\n",
      "loss: 0.010586  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 11.7%, Avg loss: 0.034082 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "loss: 0.012873  [    4/  237]\n",
      "loss: 0.011867  [   84/  237]\n",
      "loss: 0.008642  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034781 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "loss: 0.008085  [    4/  237]\n",
      "loss: 0.009969  [   84/  237]\n",
      "loss: 0.010446  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.035182 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "loss: 0.011387  [    4/  237]\n",
      "loss: 0.006768  [   84/  237]\n",
      "loss: 0.012587  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.034465 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "loss: 0.007271  [    4/  237]\n",
      "loss: 0.007987  [   84/  237]\n",
      "loss: 0.012436  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034125 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "loss: 0.010920  [    4/  237]\n",
      "loss: 0.008980  [   84/  237]\n",
      "loss: 0.014165  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.034037 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "loss: 0.009222  [    4/  237]\n",
      "loss: 0.007628  [   84/  237]\n",
      "loss: 0.006492  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.035186 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "loss: 0.014560  [    4/  237]\n",
      "loss: 0.009075  [   84/  237]\n",
      "loss: 0.016017  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 13.9%, Avg loss: 0.034763 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "loss: 0.014463  [    4/  237]\n",
      "loss: 0.009227  [   84/  237]\n",
      "loss: 0.013848  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034881 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "loss: 0.013133  [    4/  237]\n",
      "loss: 0.008242  [   84/  237]\n",
      "loss: 0.008089  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.034514 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "loss: 0.005517  [    4/  237]\n",
      "loss: 0.014530  [   84/  237]\n",
      "loss: 0.010584  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034657 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "loss: 0.008385  [    4/  237]\n",
      "loss: 0.010872  [   84/  237]\n",
      "loss: 0.012054  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.8%, Board accuracy: 15.0%, Avg loss: 0.034894 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "loss: 0.016823  [    4/  237]\n",
      "loss: 0.006068  [   84/  237]\n",
      "loss: 0.005063  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.034684 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "loss: 0.007825  [    4/  237]\n",
      "loss: 0.004112  [   84/  237]\n",
      "loss: 0.015954  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.035455 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "loss: 0.012129  [    4/  237]\n",
      "loss: 0.006610  [   84/  237]\n",
      "loss: 0.005644  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034231 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "loss: 0.016171  [    4/  237]\n",
      "loss: 0.007703  [   84/  237]\n",
      "loss: 0.005303  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034696 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "loss: 0.018995  [    4/  237]\n",
      "loss: 0.009967  [   84/  237]\n",
      "loss: 0.009606  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034296 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "loss: 0.014864  [    4/  237]\n",
      "loss: 0.008608  [   84/  237]\n",
      "loss: 0.006185  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034257 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "loss: 0.010695  [    4/  237]\n",
      "loss: 0.009972  [   84/  237]\n",
      "loss: 0.013103  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034572 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "loss: 0.019784  [    4/  237]\n",
      "loss: 0.008490  [   84/  237]\n",
      "loss: 0.016005  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.034409 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "loss: 0.020585  [    4/  237]\n",
      "loss: 0.015271  [   84/  237]\n",
      "loss: 0.010773  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033912 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "loss: 0.003435  [    4/  237]\n",
      "loss: 0.012871  [   84/  237]\n",
      "loss: 0.005680  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033795 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "loss: 0.006894  [    4/  237]\n",
      "loss: 0.016226  [   84/  237]\n",
      "loss: 0.009625  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034301 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "loss: 0.010481  [    4/  237]\n",
      "loss: 0.008669  [   84/  237]\n",
      "loss: 0.012157  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.034454 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "loss: 0.005193  [    4/  237]\n",
      "loss: 0.012242  [   84/  237]\n",
      "loss: 0.014186  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.034268 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "loss: 0.010726  [    4/  237]\n",
      "loss: 0.006120  [   84/  237]\n",
      "loss: 0.009608  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033577 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "loss: 0.008507  [    4/  237]\n",
      "loss: 0.009219  [   84/  237]\n",
      "loss: 0.009723  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033870 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "loss: 0.006690  [    4/  237]\n",
      "loss: 0.006392  [   84/  237]\n",
      "loss: 0.009598  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034128 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "loss: 0.014038  [    4/  237]\n",
      "loss: 0.015436  [   84/  237]\n",
      "loss: 0.009583  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034443 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "loss: 0.010593  [    4/  237]\n",
      "loss: 0.010440  [   84/  237]\n",
      "loss: 0.014800  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033969 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "loss: 0.006433  [    4/  237]\n",
      "loss: 0.013713  [   84/  237]\n",
      "loss: 0.007544  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 11.7%, Avg loss: 0.033691 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "loss: 0.005358  [    4/  237]\n",
      "loss: 0.014748  [   84/  237]\n",
      "loss: 0.012039  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.033913 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "loss: 0.012739  [    4/  237]\n",
      "loss: 0.008947  [   84/  237]\n",
      "loss: 0.008860  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033843 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "loss: 0.013295  [    4/  237]\n",
      "loss: 0.013838  [   84/  237]\n",
      "loss: 0.009822  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 17.2%, Avg loss: 0.033689 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "loss: 0.011001  [    4/  237]\n",
      "loss: 0.006009  [   84/  237]\n",
      "loss: 0.008039  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033920 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "loss: 0.010715  [    4/  237]\n",
      "loss: 0.018781  [   84/  237]\n",
      "loss: 0.010640  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034038 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "loss: 0.011459  [    4/  237]\n",
      "loss: 0.012354  [   84/  237]\n",
      "loss: 0.005649  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034647 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "loss: 0.008590  [    4/  237]\n",
      "loss: 0.006306  [   84/  237]\n",
      "loss: 0.013550  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034137 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "loss: 0.011058  [    4/  237]\n",
      "loss: 0.014786  [   84/  237]\n",
      "loss: 0.006183  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034124 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "loss: 0.008024  [    4/  237]\n",
      "loss: 0.012154  [   84/  237]\n",
      "loss: 0.006399  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034146 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "loss: 0.009194  [    4/  237]\n",
      "loss: 0.008528  [   84/  237]\n",
      "loss: 0.004955  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033810 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "loss: 0.010025  [    4/  237]\n",
      "loss: 0.012767  [   84/  237]\n",
      "loss: 0.008714  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.034015 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "loss: 0.006813  [    4/  237]\n",
      "loss: 0.007234  [   84/  237]\n",
      "loss: 0.008043  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034340 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "loss: 0.005693  [    4/  237]\n",
      "loss: 0.013484  [   84/  237]\n",
      "loss: 0.009455  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034688 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.021776  [    4/  237]\n",
      "loss: 0.006698  [   84/  237]\n",
      "loss: 0.012351  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034175 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "loss: 0.007249  [    4/  237]\n",
      "loss: 0.007630  [   84/  237]\n",
      "loss: 0.008588  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033772 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "loss: 0.007751  [    4/  237]\n",
      "loss: 0.008338  [   84/  237]\n",
      "loss: 0.007641  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.1%, Avg loss: 0.033465 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "loss: 0.004658  [    4/  237]\n",
      "loss: 0.018679  [   84/  237]\n",
      "loss: 0.009131  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034051 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "loss: 0.013834  [    4/  237]\n",
      "loss: 0.008983  [   84/  237]\n",
      "loss: 0.006720  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.033473 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "loss: 0.008810  [    4/  237]\n",
      "loss: 0.016936  [   84/  237]\n",
      "loss: 0.007330  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034148 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "loss: 0.006337  [    4/  237]\n",
      "loss: 0.007722  [   84/  237]\n",
      "loss: 0.004607  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033976 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "loss: 0.007178  [    4/  237]\n",
      "loss: 0.006182  [   84/  237]\n",
      "loss: 0.010238  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.034032 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "loss: 0.006576  [    4/  237]\n",
      "loss: 0.009799  [   84/  237]\n",
      "loss: 0.005335  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033894 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "loss: 0.005881  [    4/  237]\n",
      "loss: 0.009454  [   84/  237]\n",
      "loss: 0.006377  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 11.7%, Avg loss: 0.034221 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "loss: 0.005547  [    4/  237]\n",
      "loss: 0.007086  [   84/  237]\n",
      "loss: 0.011451  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033417 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "loss: 0.008250  [    4/  237]\n",
      "loss: 0.009451  [   84/  237]\n",
      "loss: 0.008550  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.034097 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "loss: 0.006994  [    4/  237]\n",
      "loss: 0.005362  [   84/  237]\n",
      "loss: 0.010510  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033435 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "loss: 0.010011  [    4/  237]\n",
      "loss: 0.008768  [   84/  237]\n",
      "loss: 0.013459  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034367 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "loss: 0.005378  [    4/  237]\n",
      "loss: 0.014751  [   84/  237]\n",
      "loss: 0.012020  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034182 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "loss: 0.012415  [    4/  237]\n",
      "loss: 0.008238  [   84/  237]\n",
      "loss: 0.007068  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033613 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "loss: 0.007744  [    4/  237]\n",
      "loss: 0.013056  [   84/  237]\n",
      "loss: 0.012214  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.034176 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "loss: 0.005762  [    4/  237]\n",
      "loss: 0.008431  [   84/  237]\n",
      "loss: 0.008660  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033801 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "loss: 0.012908  [    4/  237]\n",
      "loss: 0.009325  [   84/  237]\n",
      "loss: 0.005284  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033832 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "loss: 0.004660  [    4/  237]\n",
      "loss: 0.011769  [   84/  237]\n",
      "loss: 0.016122  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034240 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "loss: 0.014028  [    4/  237]\n",
      "loss: 0.011506  [   84/  237]\n",
      "loss: 0.011087  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.034014 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "loss: 0.007897  [    4/  237]\n",
      "loss: 0.008855  [   84/  237]\n",
      "loss: 0.008564  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033620 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "loss: 0.011234  [    4/  237]\n",
      "loss: 0.014797  [   84/  237]\n",
      "loss: 0.017404  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.1%, Avg loss: 0.033548 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "loss: 0.005516  [    4/  237]\n",
      "loss: 0.005792  [   84/  237]\n",
      "loss: 0.004249  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.033604 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "loss: 0.008753  [    4/  237]\n",
      "loss: 0.006337  [   84/  237]\n",
      "loss: 0.010303  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033808 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "loss: 0.005955  [    4/  237]\n",
      "loss: 0.009699  [   84/  237]\n",
      "loss: 0.010361  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033505 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "loss: 0.005814  [    4/  237]\n",
      "loss: 0.008040  [   84/  237]\n",
      "loss: 0.006114  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033630 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "loss: 0.005979  [    4/  237]\n",
      "loss: 0.007595  [   84/  237]\n",
      "loss: 0.015391  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.034014 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "loss: 0.006904  [    4/  237]\n",
      "loss: 0.007627  [   84/  237]\n",
      "loss: 0.012529  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.1%, Avg loss: 0.034193 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "loss: 0.008552  [    4/  237]\n",
      "loss: 0.003481  [   84/  237]\n",
      "loss: 0.005741  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033532 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "loss: 0.005726  [    4/  237]\n",
      "loss: 0.005481  [   84/  237]\n",
      "loss: 0.007074  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.033818 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "loss: 0.008603  [    4/  237]\n",
      "loss: 0.010633  [   84/  237]\n",
      "loss: 0.008995  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033826 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "loss: 0.018506  [    4/  237]\n",
      "loss: 0.007988  [   84/  237]\n",
      "loss: 0.007760  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.034178 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "loss: 0.005077  [    4/  237]\n",
      "loss: 0.008058  [   84/  237]\n",
      "loss: 0.011931  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033608 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "loss: 0.007058  [    4/  237]\n",
      "loss: 0.009453  [   84/  237]\n",
      "loss: 0.005803  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.6%, Avg loss: 0.033713 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "loss: 0.009130  [    4/  237]\n",
      "loss: 0.006704  [   84/  237]\n",
      "loss: 0.004106  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033941 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "loss: 0.007516  [    4/  237]\n",
      "loss: 0.003644  [   84/  237]\n",
      "loss: 0.012664  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.034537 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "loss: 0.014960  [    4/  237]\n",
      "loss: 0.007379  [   84/  237]\n",
      "loss: 0.010502  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.033798 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "loss: 0.007824  [    4/  237]\n",
      "loss: 0.014189  [   84/  237]\n",
      "loss: 0.011307  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.6%, Avg loss: 0.033508 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "loss: 0.008577  [    4/  237]\n",
      "loss: 0.020224  [   84/  237]\n",
      "loss: 0.004281  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033584 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "loss: 0.014826  [    4/  237]\n",
      "loss: 0.006138  [   84/  237]\n",
      "loss: 0.012285  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 17.2%, Avg loss: 0.033950 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "loss: 0.005962  [    4/  237]\n",
      "loss: 0.006855  [   84/  237]\n",
      "loss: 0.012665  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.9%, Avg loss: 0.033861 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "loss: 0.009838  [    4/  237]\n",
      "loss: 0.006175  [   84/  237]\n",
      "loss: 0.008316  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033885 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "loss: 0.006237  [    4/  237]\n",
      "loss: 0.008177  [   84/  237]\n",
      "loss: 0.009219  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.6%, Avg loss: 0.033601 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "loss: 0.009359  [    4/  237]\n",
      "loss: 0.007898  [   84/  237]\n",
      "loss: 0.009126  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.034389 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "loss: 0.007202  [    4/  237]\n",
      "loss: 0.010305  [   84/  237]\n",
      "loss: 0.010866  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.033483 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "loss: 0.012258  [    4/  237]\n",
      "loss: 0.010372  [   84/  237]\n",
      "loss: 0.004687  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033507 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "loss: 0.006864  [    4/  237]\n",
      "loss: 0.009874  [   84/  237]\n",
      "loss: 0.007854  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033439 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "loss: 0.006040  [    4/  237]\n",
      "loss: 0.008670  [   84/  237]\n",
      "loss: 0.010417  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033259 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "loss: 0.007751  [    4/  237]\n",
      "loss: 0.008062  [   84/  237]\n",
      "loss: 0.013645  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033304 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "loss: 0.004329  [    4/  237]\n",
      "loss: 0.006004  [   84/  237]\n",
      "loss: 0.005684  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.1%, Avg loss: 0.033323 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "loss: 0.011178  [    4/  237]\n",
      "loss: 0.011650  [   84/  237]\n",
      "loss: 0.005247  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.2%, Avg loss: 0.033653 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "loss: 0.005391  [    4/  237]\n",
      "loss: 0.011533  [   84/  237]\n",
      "loss: 0.005561  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033564 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "loss: 0.009287  [    4/  237]\n",
      "loss: 0.014194  [   84/  237]\n",
      "loss: 0.011992  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.033143 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "loss: 0.007010  [    4/  237]\n",
      "loss: 0.005995  [   84/  237]\n",
      "loss: 0.005083  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.0%, Avg loss: 0.033551 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "loss: 0.004303  [    4/  237]\n",
      "loss: 0.010262  [   84/  237]\n",
      "loss: 0.008611  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.033749 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "loss: 0.005854  [    4/  237]\n",
      "loss: 0.010363  [   84/  237]\n",
      "loss: 0.006138  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033334 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "loss: 0.007446  [    4/  237]\n",
      "loss: 0.005727  [   84/  237]\n",
      "loss: 0.011478  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.034326 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "loss: 0.006248  [    4/  237]\n",
      "loss: 0.007223  [   84/  237]\n",
      "loss: 0.009902  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033714 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "loss: 0.016160  [    4/  237]\n",
      "loss: 0.008071  [   84/  237]\n",
      "loss: 0.009853  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.6%, Avg loss: 0.033252 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "loss: 0.006956  [    4/  237]\n",
      "loss: 0.003950  [   84/  237]\n",
      "loss: 0.013545  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 13.3%, Avg loss: 0.034491 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "loss: 0.003900  [    4/  237]\n",
      "loss: 0.006491  [   84/  237]\n",
      "loss: 0.006891  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.6%, Avg loss: 0.033731 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "loss: 0.011843  [    4/  237]\n",
      "loss: 0.005221  [   84/  237]\n",
      "loss: 0.005467  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033366 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "loss: 0.010669  [    4/  237]\n",
      "loss: 0.009888  [   84/  237]\n",
      "loss: 0.010121  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.033020 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "loss: 0.006113  [    4/  237]\n",
      "loss: 0.008815  [   84/  237]\n",
      "loss: 0.005559  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.033761 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "loss: 0.006124  [    4/  237]\n",
      "loss: 0.013730  [   84/  237]\n",
      "loss: 0.012418  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.6%, Avg loss: 0.033382 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "loss: 0.005557  [    4/  237]\n",
      "loss: 0.004617  [   84/  237]\n",
      "loss: 0.008471  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033258 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "loss: 0.005688  [    4/  237]\n",
      "loss: 0.014759  [   84/  237]\n",
      "loss: 0.009395  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 18.3%, Avg loss: 0.033583 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "loss: 0.005045  [    4/  237]\n",
      "loss: 0.003843  [   84/  237]\n",
      "loss: 0.008004  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.8%, Avg loss: 0.033531 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "loss: 0.009594  [    4/  237]\n",
      "loss: 0.009302  [   84/  237]\n",
      "loss: 0.007012  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.0%, Avg loss: 0.033659 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "loss: 0.005094  [    4/  237]\n",
      "loss: 0.007391  [   84/  237]\n",
      "loss: 0.009353  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033380 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "loss: 0.010331  [    4/  237]\n",
      "loss: 0.010570  [   84/  237]\n",
      "loss: 0.007917  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033867 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "loss: 0.004702  [    4/  237]\n",
      "loss: 0.008313  [   84/  237]\n",
      "loss: 0.006549  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033461 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "loss: 0.004175  [    4/  237]\n",
      "loss: 0.009946  [   84/  237]\n",
      "loss: 0.006547  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033769 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "loss: 0.009080  [    4/  237]\n",
      "loss: 0.006756  [   84/  237]\n",
      "loss: 0.014241  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033260 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "loss: 0.008467  [    4/  237]\n",
      "loss: 0.011166  [   84/  237]\n",
      "loss: 0.006948  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.034036 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "loss: 0.007806  [    4/  237]\n",
      "loss: 0.010711  [   84/  237]\n",
      "loss: 0.006941  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033766 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "loss: 0.008138  [    4/  237]\n",
      "loss: 0.009896  [   84/  237]\n",
      "loss: 0.006715  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.033917 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "loss: 0.007692  [    4/  237]\n",
      "loss: 0.003796  [   84/  237]\n",
      "loss: 0.009714  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.8%, Avg loss: 0.033435 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "loss: 0.008709  [    4/  237]\n",
      "loss: 0.006824  [   84/  237]\n",
      "loss: 0.008296  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.033636 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "loss: 0.005574  [    4/  237]\n",
      "loss: 0.009276  [   84/  237]\n",
      "loss: 0.005884  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 13.3%, Avg loss: 0.033259 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "loss: 0.004754  [    4/  237]\n",
      "loss: 0.008130  [   84/  237]\n",
      "loss: 0.005361  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.034361 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "loss: 0.005659  [    4/  237]\n",
      "loss: 0.006128  [   84/  237]\n",
      "loss: 0.009999  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033189 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "loss: 0.005246  [    4/  237]\n",
      "loss: 0.013102  [   84/  237]\n",
      "loss: 0.010050  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033666 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "loss: 0.007593  [    4/  237]\n",
      "loss: 0.008477  [   84/  237]\n",
      "loss: 0.005911  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033106 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "loss: 0.010179  [    4/  237]\n",
      "loss: 0.003897  [   84/  237]\n",
      "loss: 0.007790  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033260 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "loss: 0.005737  [    4/  237]\n",
      "loss: 0.009707  [   84/  237]\n",
      "loss: 0.010462  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033988 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "loss: 0.012075  [    4/  237]\n",
      "loss: 0.007183  [   84/  237]\n",
      "loss: 0.005717  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033224 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "loss: 0.008474  [    4/  237]\n",
      "loss: 0.007418  [   84/  237]\n",
      "loss: 0.004742  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033408 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "loss: 0.011543  [    4/  237]\n",
      "loss: 0.010894  [   84/  237]\n",
      "loss: 0.005310  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.2%, Avg loss: 0.033252 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "loss: 0.007025  [    4/  237]\n",
      "loss: 0.005158  [   84/  237]\n",
      "loss: 0.006218  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033533 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "loss: 0.005669  [    4/  237]\n",
      "loss: 0.008165  [   84/  237]\n",
      "loss: 0.011726  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.6%, Avg loss: 0.033219 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "loss: 0.003739  [    4/  237]\n",
      "loss: 0.006614  [   84/  237]\n",
      "loss: 0.008394  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.6%, Avg loss: 0.033666 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "loss: 0.006235  [    4/  237]\n",
      "loss: 0.007601  [   84/  237]\n",
      "loss: 0.006921  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 15.0%, Avg loss: 0.033350 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "loss: 0.010737  [    4/  237]\n",
      "loss: 0.007230  [   84/  237]\n",
      "loss: 0.004461  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033263 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "loss: 0.010113  [    4/  237]\n",
      "loss: 0.004743  [   84/  237]\n",
      "loss: 0.006251  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.2%, Avg loss: 0.033404 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "loss: 0.004685  [    4/  237]\n",
      "loss: 0.005015  [   84/  237]\n",
      "loss: 0.007923  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033685 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "loss: 0.006703  [    4/  237]\n",
      "loss: 0.007020  [   84/  237]\n",
      "loss: 0.005709  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.2%, Avg loss: 0.033292 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "loss: 0.011771  [    4/  237]\n",
      "loss: 0.005928  [   84/  237]\n",
      "loss: 0.008608  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.033530 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "loss: 0.008244  [    4/  237]\n",
      "loss: 0.006131  [   84/  237]\n",
      "loss: 0.004685  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033676 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "loss: 0.009328  [    4/  237]\n",
      "loss: 0.007672  [   84/  237]\n",
      "loss: 0.009547  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033286 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "loss: 0.006461  [    4/  237]\n",
      "loss: 0.004394  [   84/  237]\n",
      "loss: 0.014247  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 16.7%, Avg loss: 0.033472 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "loss: 0.007745  [    4/  237]\n",
      "loss: 0.004193  [   84/  237]\n",
      "loss: 0.007217  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.2%, Avg loss: 0.033579 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "loss: 0.006018  [    4/  237]\n",
      "loss: 0.010293  [   84/  237]\n",
      "loss: 0.011632  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.2%, Avg loss: 0.033047 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "loss: 0.007739  [    4/  237]\n",
      "loss: 0.005467  [   84/  237]\n",
      "loss: 0.004936  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033272 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "loss: 0.007514  [    4/  237]\n",
      "loss: 0.008266  [   84/  237]\n",
      "loss: 0.005100  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033494 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "loss: 0.005201  [    4/  237]\n",
      "loss: 0.004291  [   84/  237]\n",
      "loss: 0.010714  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.8%, Avg loss: 0.032930 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "loss: 0.006988  [    4/  237]\n",
      "loss: 0.007506  [   84/  237]\n",
      "loss: 0.004506  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033168 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "loss: 0.004049  [    4/  237]\n",
      "loss: 0.005191  [   84/  237]\n",
      "loss: 0.011270  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 15.0%, Avg loss: 0.033258 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "loss: 0.006572  [    4/  237]\n",
      "loss: 0.005491  [   84/  237]\n",
      "loss: 0.008389  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.8%, Avg loss: 0.033524 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "loss: 0.012114  [    4/  237]\n",
      "loss: 0.011805  [   84/  237]\n",
      "loss: 0.006035  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.1%, Avg loss: 0.033113 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "loss: 0.005019  [    4/  237]\n",
      "loss: 0.009268  [   84/  237]\n",
      "loss: 0.005222  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.6%, Avg loss: 0.033308 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "loss: 0.013144  [    4/  237]\n",
      "loss: 0.009660  [   84/  237]\n",
      "loss: 0.007864  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033410 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "loss: 0.005184  [    4/  237]\n",
      "loss: 0.006729  [   84/  237]\n",
      "loss: 0.009022  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033432 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "loss: 0.004912  [    4/  237]\n",
      "loss: 0.006866  [   84/  237]\n",
      "loss: 0.006418  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.6%, Avg loss: 0.033462 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "loss: 0.003830  [    4/  237]\n",
      "loss: 0.005731  [   84/  237]\n",
      "loss: 0.007131  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.9%, Board accuracy: 18.3%, Avg loss: 0.033639 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "loss: 0.006718  [    4/  237]\n",
      "loss: 0.006430  [   84/  237]\n",
      "loss: 0.011858  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033601 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "loss: 0.004873  [    4/  237]\n",
      "loss: 0.004661  [   84/  237]\n",
      "loss: 0.008305  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033680 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "loss: 0.004626  [    4/  237]\n",
      "loss: 0.006796  [   84/  237]\n",
      "loss: 0.003614  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033163 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "loss: 0.005072  [    4/  237]\n",
      "loss: 0.004098  [   84/  237]\n",
      "loss: 0.011148  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033815 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "loss: 0.012598  [    4/  237]\n",
      "loss: 0.008397  [   84/  237]\n",
      "loss: 0.004270  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.0%, Avg loss: 0.033401 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "loss: 0.007007  [    4/  237]\n",
      "loss: 0.009359  [   84/  237]\n",
      "loss: 0.010883  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.032952 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "loss: 0.004249  [    4/  237]\n",
      "loss: 0.003441  [   84/  237]\n",
      "loss: 0.004700  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.032954 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "loss: 0.004756  [    4/  237]\n",
      "loss: 0.008410  [   84/  237]\n",
      "loss: 0.007579  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.2%, Avg loss: 0.033571 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "loss: 0.009078  [    4/  237]\n",
      "loss: 0.007176  [   84/  237]\n",
      "loss: 0.006023  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033230 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "loss: 0.005812  [    4/  237]\n",
      "loss: 0.007350  [   84/  237]\n",
      "loss: 0.003817  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.032768 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "loss: 0.005360  [    4/  237]\n",
      "loss: 0.008779  [   84/  237]\n",
      "loss: 0.005376  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.8%, Avg loss: 0.032853 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "loss: 0.007267  [    4/  237]\n",
      "loss: 0.005451  [   84/  237]\n",
      "loss: 0.009125  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033665 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "loss: 0.007373  [    4/  237]\n",
      "loss: 0.008195  [   84/  237]\n",
      "loss: 0.003376  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033023 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "loss: 0.003197  [    4/  237]\n",
      "loss: 0.004428  [   84/  237]\n",
      "loss: 0.008224  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033562 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "loss: 0.007145  [    4/  237]\n",
      "loss: 0.007740  [   84/  237]\n",
      "loss: 0.004805  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 17.2%, Avg loss: 0.033151 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "loss: 0.010898  [    4/  237]\n",
      "loss: 0.006885  [   84/  237]\n",
      "loss: 0.005670  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.6%, Avg loss: 0.033308 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "loss: 0.006428  [    4/  237]\n",
      "loss: 0.006564  [   84/  237]\n",
      "loss: 0.014434  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033400 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "loss: 0.006530  [    4/  237]\n",
      "loss: 0.007942  [   84/  237]\n",
      "loss: 0.006270  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.0%, Avg loss: 0.033153 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "loss: 0.004837  [    4/  237]\n",
      "loss: 0.004839  [   84/  237]\n",
      "loss: 0.006686  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 19.4%, Avg loss: 0.033228 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "loss: 0.007874  [    4/  237]\n",
      "loss: 0.006175  [   84/  237]\n",
      "loss: 0.006202  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033228 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "loss: 0.005129  [    4/  237]\n",
      "loss: 0.012601  [   84/  237]\n",
      "loss: 0.010039  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.032965 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "loss: 0.005622  [    4/  237]\n",
      "loss: 0.004160  [   84/  237]\n",
      "loss: 0.007943  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033523 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "loss: 0.008453  [    4/  237]\n",
      "loss: 0.015539  [   84/  237]\n",
      "loss: 0.010918  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033438 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "loss: 0.005552  [    4/  237]\n",
      "loss: 0.006973  [   84/  237]\n",
      "loss: 0.007472  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033516 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "loss: 0.010399  [    4/  237]\n",
      "loss: 0.005911  [   84/  237]\n",
      "loss: 0.006354  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033258 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "loss: 0.003440  [    4/  237]\n",
      "loss: 0.006028  [   84/  237]\n",
      "loss: 0.005872  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033965 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "loss: 0.004988  [    4/  237]\n",
      "loss: 0.003077  [   84/  237]\n",
      "loss: 0.004538  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.0%, Avg loss: 0.033910 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "loss: 0.005884  [    4/  237]\n",
      "loss: 0.004834  [   84/  237]\n",
      "loss: 0.004294  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033146 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "loss: 0.004294  [    4/  237]\n",
      "loss: 0.005952  [   84/  237]\n",
      "loss: 0.005295  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.0%, Avg loss: 0.033314 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "loss: 0.006347  [    4/  237]\n",
      "loss: 0.004304  [   84/  237]\n",
      "loss: 0.007513  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.033091 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "loss: 0.004843  [    4/  237]\n",
      "loss: 0.006514  [   84/  237]\n",
      "loss: 0.005492  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033385 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "loss: 0.003464  [    4/  237]\n",
      "loss: 0.006890  [   84/  237]\n",
      "loss: 0.006537  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033876 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "loss: 0.007421  [    4/  237]\n",
      "loss: 0.007411  [   84/  237]\n",
      "loss: 0.003597  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033706 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "loss: 0.004114  [    4/  237]\n",
      "loss: 0.008360  [   84/  237]\n",
      "loss: 0.003900  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.0%, Avg loss: 0.033265 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "loss: 0.006280  [    4/  237]\n",
      "loss: 0.003264  [   84/  237]\n",
      "loss: 0.005041  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033501 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "loss: 0.006632  [    4/  237]\n",
      "loss: 0.006203  [   84/  237]\n",
      "loss: 0.011587  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033203 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "loss: 0.005800  [    4/  237]\n",
      "loss: 0.006529  [   84/  237]\n",
      "loss: 0.004529  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.033281 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "loss: 0.006054  [    4/  237]\n",
      "loss: 0.006403  [   84/  237]\n",
      "loss: 0.006916  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033070 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "loss: 0.003842  [    4/  237]\n",
      "loss: 0.010865  [   84/  237]\n",
      "loss: 0.005119  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033291 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "loss: 0.003665  [    4/  237]\n",
      "loss: 0.003621  [   84/  237]\n",
      "loss: 0.002142  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.0%, Avg loss: 0.033090 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "loss: 0.004885  [    4/  237]\n",
      "loss: 0.003815  [   84/  237]\n",
      "loss: 0.006785  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.9%, Avg loss: 0.033334 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "loss: 0.005435  [    4/  237]\n",
      "loss: 0.006615  [   84/  237]\n",
      "loss: 0.005287  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033446 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "loss: 0.009654  [    4/  237]\n",
      "loss: 0.004121  [   84/  237]\n",
      "loss: 0.011949  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 16.7%, Avg loss: 0.033508 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "loss: 0.006265  [    4/  237]\n",
      "loss: 0.008265  [   84/  237]\n",
      "loss: 0.006616  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 18.3%, Avg loss: 0.033299 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "loss: 0.004561  [    4/  237]\n",
      "loss: 0.005831  [   84/  237]\n",
      "loss: 0.004700  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.032926 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "loss: 0.004564  [    4/  237]\n",
      "loss: 0.003225  [   84/  237]\n",
      "loss: 0.010855  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.032844 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "loss: 0.006670  [    4/  237]\n",
      "loss: 0.006068  [   84/  237]\n",
      "loss: 0.004148  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034078 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "loss: 0.004899  [    4/  237]\n",
      "loss: 0.005177  [   84/  237]\n",
      "loss: 0.005208  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033350 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "loss: 0.011756  [    4/  237]\n",
      "loss: 0.006136  [   84/  237]\n",
      "loss: 0.005947  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.033805 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "loss: 0.009794  [    4/  237]\n",
      "loss: 0.004949  [   84/  237]\n",
      "loss: 0.004749  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.033370 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "loss: 0.005502  [    4/  237]\n",
      "loss: 0.003539  [   84/  237]\n",
      "loss: 0.007157  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.032895 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "loss: 0.006420  [    4/  237]\n",
      "loss: 0.003393  [   84/  237]\n",
      "loss: 0.008979  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.0%, Avg loss: 0.033675 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "loss: 0.007196  [    4/  237]\n",
      "loss: 0.003840  [   84/  237]\n",
      "loss: 0.006809  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.0%, Avg loss: 0.032856 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "loss: 0.002860  [    4/  237]\n",
      "loss: 0.004976  [   84/  237]\n",
      "loss: 0.008003  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.033501 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "loss: 0.005933  [    4/  237]\n",
      "loss: 0.007098  [   84/  237]\n",
      "loss: 0.008096  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 20.0%, Avg loss: 0.033183 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "loss: 0.003847  [    4/  237]\n",
      "loss: 0.007119  [   84/  237]\n",
      "loss: 0.005265  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033292 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "loss: 0.004297  [    4/  237]\n",
      "loss: 0.005424  [   84/  237]\n",
      "loss: 0.003307  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 24.4%, Avg loss: 0.033129 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "loss: 0.006767  [    4/  237]\n",
      "loss: 0.005442  [   84/  237]\n",
      "loss: 0.004228  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033668 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "loss: 0.006429  [    4/  237]\n",
      "loss: 0.004335  [   84/  237]\n",
      "loss: 0.004647  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033842 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "loss: 0.006733  [    4/  237]\n",
      "loss: 0.003122  [   84/  237]\n",
      "loss: 0.004901  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033616 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "loss: 0.005710  [    4/  237]\n",
      "loss: 0.003644  [   84/  237]\n",
      "loss: 0.003620  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033679 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "loss: 0.004567  [    4/  237]\n",
      "loss: 0.003554  [   84/  237]\n",
      "loss: 0.004672  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.033101 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "loss: 0.004448  [    4/  237]\n",
      "loss: 0.008247  [   84/  237]\n",
      "loss: 0.002343  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033645 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "loss: 0.005922  [    4/  237]\n",
      "loss: 0.005537  [   84/  237]\n",
      "loss: 0.004661  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.032977 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "loss: 0.002255  [    4/  237]\n",
      "loss: 0.003851  [   84/  237]\n",
      "loss: 0.006759  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.033847 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "loss: 0.006394  [    4/  237]\n",
      "loss: 0.005482  [   84/  237]\n",
      "loss: 0.005408  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033254 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "loss: 0.006175  [    4/  237]\n",
      "loss: 0.005964  [   84/  237]\n",
      "loss: 0.003571  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033543 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "loss: 0.002931  [    4/  237]\n",
      "loss: 0.005824  [   84/  237]\n",
      "loss: 0.006643  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033157 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "loss: 0.006171  [    4/  237]\n",
      "loss: 0.010021  [   84/  237]\n",
      "loss: 0.004088  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033084 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "loss: 0.005624  [    4/  237]\n",
      "loss: 0.004941  [   84/  237]\n",
      "loss: 0.006246  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.032775 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "loss: 0.004788  [    4/  237]\n",
      "loss: 0.004829  [   84/  237]\n",
      "loss: 0.003261  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.032971 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "loss: 0.003261  [    4/  237]\n",
      "loss: 0.004440  [   84/  237]\n",
      "loss: 0.007712  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033570 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "loss: 0.011159  [    4/  237]\n",
      "loss: 0.012346  [   84/  237]\n",
      "loss: 0.004885  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033236 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "loss: 0.003964  [    4/  237]\n",
      "loss: 0.003932  [   84/  237]\n",
      "loss: 0.005925  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.033212 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "loss: 0.011514  [    4/  237]\n",
      "loss: 0.012166  [   84/  237]\n",
      "loss: 0.003813  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033505 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "loss: 0.007260  [    4/  237]\n",
      "loss: 0.004343  [   84/  237]\n",
      "loss: 0.008511  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033050 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "loss: 0.003346  [    4/  237]\n",
      "loss: 0.007970  [   84/  237]\n",
      "loss: 0.006578  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.1%, Avg loss: 0.032688 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "loss: 0.006140  [    4/  237]\n",
      "loss: 0.004522  [   84/  237]\n",
      "loss: 0.005106  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033131 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "loss: 0.006506  [    4/  237]\n",
      "loss: 0.005969  [   84/  237]\n",
      "loss: 0.009058  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033569 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "loss: 0.006370  [    4/  237]\n",
      "loss: 0.002331  [   84/  237]\n",
      "loss: 0.005390  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.033412 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "loss: 0.003922  [    4/  237]\n",
      "loss: 0.003726  [   84/  237]\n",
      "loss: 0.008238  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033555 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "loss: 0.005423  [    4/  237]\n",
      "loss: 0.003220  [   84/  237]\n",
      "loss: 0.004317  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 25.6%, Avg loss: 0.033369 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "loss: 0.006540  [    4/  237]\n",
      "loss: 0.005693  [   84/  237]\n",
      "loss: 0.004479  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033255 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "loss: 0.008470  [    4/  237]\n",
      "loss: 0.004605  [   84/  237]\n",
      "loss: 0.004824  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.033464 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "loss: 0.008365  [    4/  237]\n",
      "loss: 0.007078  [   84/  237]\n",
      "loss: 0.008498  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033143 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "loss: 0.005678  [    4/  237]\n",
      "loss: 0.004719  [   84/  237]\n",
      "loss: 0.006775  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033207 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "loss: 0.004257  [    4/  237]\n",
      "loss: 0.003553  [   84/  237]\n",
      "loss: 0.007250  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033434 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "loss: 0.003382  [    4/  237]\n",
      "loss: 0.006565  [   84/  237]\n",
      "loss: 0.003122  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033406 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "loss: 0.004815  [    4/  237]\n",
      "loss: 0.007982  [   84/  237]\n",
      "loss: 0.009614  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.1%, Avg loss: 0.033262 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "loss: 0.005615  [    4/  237]\n",
      "loss: 0.007791  [   84/  237]\n",
      "loss: 0.006136  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.033307 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "loss: 0.003861  [    4/  237]\n",
      "loss: 0.003972  [   84/  237]\n",
      "loss: 0.003085  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033666 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "loss: 0.003624  [    4/  237]\n",
      "loss: 0.003107  [   84/  237]\n",
      "loss: 0.002074  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033358 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "loss: 0.004759  [    4/  237]\n",
      "loss: 0.009554  [   84/  237]\n",
      "loss: 0.008629  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033080 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "loss: 0.003372  [    4/  237]\n",
      "loss: 0.005314  [   84/  237]\n",
      "loss: 0.004883  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033150 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "loss: 0.002766  [    4/  237]\n",
      "loss: 0.008186  [   84/  237]\n",
      "loss: 0.007206  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033327 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "loss: 0.007727  [    4/  237]\n",
      "loss: 0.002509  [   84/  237]\n",
      "loss: 0.009316  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033003 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "loss: 0.006412  [    4/  237]\n",
      "loss: 0.004314  [   84/  237]\n",
      "loss: 0.003821  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034168 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "loss: 0.007911  [    4/  237]\n",
      "loss: 0.010501  [   84/  237]\n",
      "loss: 0.004311  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033148 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "loss: 0.003028  [    4/  237]\n",
      "loss: 0.005814  [   84/  237]\n",
      "loss: 0.006515  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.032854 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "loss: 0.005682  [    4/  237]\n",
      "loss: 0.005798  [   84/  237]\n",
      "loss: 0.004967  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.033432 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "loss: 0.003714  [    4/  237]\n",
      "loss: 0.005034  [   84/  237]\n",
      "loss: 0.006132  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033051 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "loss: 0.004500  [    4/  237]\n",
      "loss: 0.001491  [   84/  237]\n",
      "loss: 0.004617  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033618 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "loss: 0.007534  [    4/  237]\n",
      "loss: 0.007518  [   84/  237]\n",
      "loss: 0.004416  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.033476 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "loss: 0.008455  [    4/  237]\n",
      "loss: 0.003575  [   84/  237]\n",
      "loss: 0.003813  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033449 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "loss: 0.004550  [    4/  237]\n",
      "loss: 0.008135  [   84/  237]\n",
      "loss: 0.005692  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033486 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "loss: 0.003776  [    4/  237]\n",
      "loss: 0.003814  [   84/  237]\n",
      "loss: 0.004573  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.032816 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "loss: 0.005936  [    4/  237]\n",
      "loss: 0.004874  [   84/  237]\n",
      "loss: 0.007765  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033559 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "loss: 0.005034  [    4/  237]\n",
      "loss: 0.009946  [   84/  237]\n",
      "loss: 0.004321  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033346 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "loss: 0.006805  [    4/  237]\n",
      "loss: 0.004381  [   84/  237]\n",
      "loss: 0.006272  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.033365 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "loss: 0.006538  [    4/  237]\n",
      "loss: 0.003069  [   84/  237]\n",
      "loss: 0.004926  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034069 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "loss: 0.007287  [    4/  237]\n",
      "loss: 0.004911  [   84/  237]\n",
      "loss: 0.006400  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033121 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "loss: 0.004694  [    4/  237]\n",
      "loss: 0.003019  [   84/  237]\n",
      "loss: 0.003189  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033923 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "loss: 0.002801  [    4/  237]\n",
      "loss: 0.006124  [   84/  237]\n",
      "loss: 0.004782  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034014 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "loss: 0.007284  [    4/  237]\n",
      "loss: 0.008619  [   84/  237]\n",
      "loss: 0.003954  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.8%, Avg loss: 0.033131 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "loss: 0.004745  [    4/  237]\n",
      "loss: 0.004835  [   84/  237]\n",
      "loss: 0.008080  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033680 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "loss: 0.004523  [    4/  237]\n",
      "loss: 0.004103  [   84/  237]\n",
      "loss: 0.005588  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033118 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "loss: 0.002598  [    4/  237]\n",
      "loss: 0.004442  [   84/  237]\n",
      "loss: 0.004554  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033039 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "loss: 0.002303  [    4/  237]\n",
      "loss: 0.007716  [   84/  237]\n",
      "loss: 0.004830  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033299 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "loss: 0.003498  [    4/  237]\n",
      "loss: 0.006826  [   84/  237]\n",
      "loss: 0.007260  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033536 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "loss: 0.005155  [    4/  237]\n",
      "loss: 0.004299  [   84/  237]\n",
      "loss: 0.010632  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033640 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "loss: 0.003856  [    4/  237]\n",
      "loss: 0.003213  [   84/  237]\n",
      "loss: 0.008120  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033124 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "loss: 0.003890  [    4/  237]\n",
      "loss: 0.005132  [   84/  237]\n",
      "loss: 0.002797  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033304 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "loss: 0.005233  [    4/  237]\n",
      "loss: 0.006818  [   84/  237]\n",
      "loss: 0.004683  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.033399 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "loss: 0.003298  [    4/  237]\n",
      "loss: 0.005451  [   84/  237]\n",
      "loss: 0.004228  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033636 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "loss: 0.004142  [    4/  237]\n",
      "loss: 0.005079  [   84/  237]\n",
      "loss: 0.004020  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033827 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "loss: 0.006963  [    4/  237]\n",
      "loss: 0.010202  [   84/  237]\n",
      "loss: 0.008841  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033684 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "loss: 0.003489  [    4/  237]\n",
      "loss: 0.007419  [   84/  237]\n",
      "loss: 0.007121  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033171 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "loss: 0.003638  [    4/  237]\n",
      "loss: 0.002700  [   84/  237]\n",
      "loss: 0.005456  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033487 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "loss: 0.004278  [    4/  237]\n",
      "loss: 0.002587  [   84/  237]\n",
      "loss: 0.007358  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.032951 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "loss: 0.006562  [    4/  237]\n",
      "loss: 0.006509  [   84/  237]\n",
      "loss: 0.003368  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.8%, Avg loss: 0.033351 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "loss: 0.003712  [    4/  237]\n",
      "loss: 0.005386  [   84/  237]\n",
      "loss: 0.001712  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033211 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "loss: 0.005315  [    4/  237]\n",
      "loss: 0.004272  [   84/  237]\n",
      "loss: 0.005224  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033487 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "loss: 0.009396  [    4/  237]\n",
      "loss: 0.002798  [   84/  237]\n",
      "loss: 0.006580  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033298 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "loss: 0.002932  [    4/  237]\n",
      "loss: 0.004139  [   84/  237]\n",
      "loss: 0.003790  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.033328 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "loss: 0.003451  [    4/  237]\n",
      "loss: 0.005971  [   84/  237]\n",
      "loss: 0.004927  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033637 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "loss: 0.005167  [    4/  237]\n",
      "loss: 0.003144  [   84/  237]\n",
      "loss: 0.003891  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033182 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "loss: 0.004215  [    4/  237]\n",
      "loss: 0.003669  [   84/  237]\n",
      "loss: 0.002987  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033846 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "loss: 0.004152  [    4/  237]\n",
      "loss: 0.004182  [   84/  237]\n",
      "loss: 0.003958  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034034 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "loss: 0.003079  [    4/  237]\n",
      "loss: 0.004063  [   84/  237]\n",
      "loss: 0.003896  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034113 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "loss: 0.004584  [    4/  237]\n",
      "loss: 0.009776  [   84/  237]\n",
      "loss: 0.004176  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.032981 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "loss: 0.002761  [    4/  237]\n",
      "loss: 0.005024  [   84/  237]\n",
      "loss: 0.005072  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033092 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "loss: 0.003544  [    4/  237]\n",
      "loss: 0.004193  [   84/  237]\n",
      "loss: 0.007970  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034130 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "loss: 0.005766  [    4/  237]\n",
      "loss: 0.005741  [   84/  237]\n",
      "loss: 0.003671  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033718 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "loss: 0.004026  [    4/  237]\n",
      "loss: 0.004784  [   84/  237]\n",
      "loss: 0.003178  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.033474 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "loss: 0.004386  [    4/  237]\n",
      "loss: 0.004160  [   84/  237]\n",
      "loss: 0.003340  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033752 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "loss: 0.005906  [    4/  237]\n",
      "loss: 0.003666  [   84/  237]\n",
      "loss: 0.004656  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034186 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "loss: 0.004055  [    4/  237]\n",
      "loss: 0.004143  [   84/  237]\n",
      "loss: 0.007019  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033941 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "loss: 0.004551  [    4/  237]\n",
      "loss: 0.004897  [   84/  237]\n",
      "loss: 0.004202  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033377 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "loss: 0.002239  [    4/  237]\n",
      "loss: 0.006426  [   84/  237]\n",
      "loss: 0.003758  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033542 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "loss: 0.004450  [    4/  237]\n",
      "loss: 0.004436  [   84/  237]\n",
      "loss: 0.002605  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033243 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "loss: 0.006611  [    4/  237]\n",
      "loss: 0.007400  [   84/  237]\n",
      "loss: 0.008978  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033196 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "loss: 0.004133  [    4/  237]\n",
      "loss: 0.004350  [   84/  237]\n",
      "loss: 0.005588  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.033253 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "loss: 0.008925  [    4/  237]\n",
      "loss: 0.004449  [   84/  237]\n",
      "loss: 0.003854  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033452 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "loss: 0.003872  [    4/  237]\n",
      "loss: 0.003594  [   84/  237]\n",
      "loss: 0.004961  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033865 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "loss: 0.002114  [    4/  237]\n",
      "loss: 0.003724  [   84/  237]\n",
      "loss: 0.002537  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033233 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "loss: 0.007677  [    4/  237]\n",
      "loss: 0.003129  [   84/  237]\n",
      "loss: 0.004071  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033587 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "loss: 0.006672  [    4/  237]\n",
      "loss: 0.004679  [   84/  237]\n",
      "loss: 0.004700  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034129 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "loss: 0.005063  [    4/  237]\n",
      "loss: 0.007024  [   84/  237]\n",
      "loss: 0.008743  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034016 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "loss: 0.003380  [    4/  237]\n",
      "loss: 0.003636  [   84/  237]\n",
      "loss: 0.002760  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033842 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "loss: 0.004855  [    4/  237]\n",
      "loss: 0.002904  [   84/  237]\n",
      "loss: 0.002571  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033359 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "loss: 0.003794  [    4/  237]\n",
      "loss: 0.003059  [   84/  237]\n",
      "loss: 0.012805  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033253 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "loss: 0.002970  [    4/  237]\n",
      "loss: 0.004154  [   84/  237]\n",
      "loss: 0.005161  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034140 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "loss: 0.004183  [    4/  237]\n",
      "loss: 0.004194  [   84/  237]\n",
      "loss: 0.003745  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033932 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "loss: 0.002453  [    4/  237]\n",
      "loss: 0.005318  [   84/  237]\n",
      "loss: 0.003641  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033256 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "loss: 0.007301  [    4/  237]\n",
      "loss: 0.005156  [   84/  237]\n",
      "loss: 0.002108  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033330 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "loss: 0.006149  [    4/  237]\n",
      "loss: 0.003527  [   84/  237]\n",
      "loss: 0.003416  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.8%, Avg loss: 0.033515 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "loss: 0.003296  [    4/  237]\n",
      "loss: 0.002510  [   84/  237]\n",
      "loss: 0.004811  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033800 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "loss: 0.004732  [    4/  237]\n",
      "loss: 0.005935  [   84/  237]\n",
      "loss: 0.003717  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033559 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "loss: 0.005193  [    4/  237]\n",
      "loss: 0.004323  [   84/  237]\n",
      "loss: 0.003280  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.033990 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "loss: 0.003957  [    4/  237]\n",
      "loss: 0.003303  [   84/  237]\n",
      "loss: 0.005839  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033191 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "loss: 0.004285  [    4/  237]\n",
      "loss: 0.003307  [   84/  237]\n",
      "loss: 0.004049  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033825 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "loss: 0.006633  [    4/  237]\n",
      "loss: 0.004377  [   84/  237]\n",
      "loss: 0.003066  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033730 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "loss: 0.003301  [    4/  237]\n",
      "loss: 0.004582  [   84/  237]\n",
      "loss: 0.002620  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.033739 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "loss: 0.002022  [    4/  237]\n",
      "loss: 0.007750  [   84/  237]\n",
      "loss: 0.012905  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033412 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "loss: 0.004048  [    4/  237]\n",
      "loss: 0.002827  [   84/  237]\n",
      "loss: 0.007675  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.033921 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "loss: 0.004480  [    4/  237]\n",
      "loss: 0.005571  [   84/  237]\n",
      "loss: 0.004174  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033849 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "loss: 0.004522  [    4/  237]\n",
      "loss: 0.005030  [   84/  237]\n",
      "loss: 0.002909  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.033248 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "loss: 0.005356  [    4/  237]\n",
      "loss: 0.009432  [   84/  237]\n",
      "loss: 0.002156  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033273 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "loss: 0.002871  [    4/  237]\n",
      "loss: 0.002092  [   84/  237]\n",
      "loss: 0.002516  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034016 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "loss: 0.003281  [    4/  237]\n",
      "loss: 0.007831  [   84/  237]\n",
      "loss: 0.003745  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033623 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "loss: 0.006211  [    4/  237]\n",
      "loss: 0.002972  [   84/  237]\n",
      "loss: 0.004778  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033705 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "loss: 0.008880  [    4/  237]\n",
      "loss: 0.002104  [   84/  237]\n",
      "loss: 0.004405  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034058 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "loss: 0.002931  [    4/  237]\n",
      "loss: 0.002681  [   84/  237]\n",
      "loss: 0.003618  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033613 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "loss: 0.003353  [    4/  237]\n",
      "loss: 0.004536  [   84/  237]\n",
      "loss: 0.003277  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033863 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "loss: 0.004111  [    4/  237]\n",
      "loss: 0.003244  [   84/  237]\n",
      "loss: 0.002763  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033495 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "loss: 0.003287  [    4/  237]\n",
      "loss: 0.004185  [   84/  237]\n",
      "loss: 0.002375  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033853 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "loss: 0.005502  [    4/  237]\n",
      "loss: 0.006945  [   84/  237]\n",
      "loss: 0.004166  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.033102 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "loss: 0.003827  [    4/  237]\n",
      "loss: 0.002848  [   84/  237]\n",
      "loss: 0.006413  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033768 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "loss: 0.003299  [    4/  237]\n",
      "loss: 0.002908  [   84/  237]\n",
      "loss: 0.005869  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.034011 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "loss: 0.005248  [    4/  237]\n",
      "loss: 0.004238  [   84/  237]\n",
      "loss: 0.007580  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034164 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "loss: 0.003676  [    4/  237]\n",
      "loss: 0.002987  [   84/  237]\n",
      "loss: 0.004567  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034197 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "loss: 0.002660  [    4/  237]\n",
      "loss: 0.004921  [   84/  237]\n",
      "loss: 0.007450  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033484 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "loss: 0.003131  [    4/  237]\n",
      "loss: 0.005589  [   84/  237]\n",
      "loss: 0.002752  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033304 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "loss: 0.005026  [    4/  237]\n",
      "loss: 0.003557  [   84/  237]\n",
      "loss: 0.002892  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033652 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "loss: 0.003400  [    4/  237]\n",
      "loss: 0.008132  [   84/  237]\n",
      "loss: 0.002077  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033739 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "loss: 0.003369  [    4/  237]\n",
      "loss: 0.002903  [   84/  237]\n",
      "loss: 0.006635  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033828 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "loss: 0.002580  [    4/  237]\n",
      "loss: 0.003521  [   84/  237]\n",
      "loss: 0.004138  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033552 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "loss: 0.004362  [    4/  237]\n",
      "loss: 0.003838  [   84/  237]\n",
      "loss: 0.002994  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.033974 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "loss: 0.006751  [    4/  237]\n",
      "loss: 0.004818  [   84/  237]\n",
      "loss: 0.006538  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033505 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "loss: 0.004662  [    4/  237]\n",
      "loss: 0.003090  [   84/  237]\n",
      "loss: 0.006024  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033624 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "loss: 0.003111  [    4/  237]\n",
      "loss: 0.005457  [   84/  237]\n",
      "loss: 0.001551  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033689 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "loss: 0.006426  [    4/  237]\n",
      "loss: 0.001474  [   84/  237]\n",
      "loss: 0.002881  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033926 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "loss: 0.003701  [    4/  237]\n",
      "loss: 0.003861  [   84/  237]\n",
      "loss: 0.005311  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033689 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "loss: 0.004630  [    4/  237]\n",
      "loss: 0.008208  [   84/  237]\n",
      "loss: 0.004593  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033510 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "loss: 0.004689  [    4/  237]\n",
      "loss: 0.003119  [   84/  237]\n",
      "loss: 0.003065  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033545 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "loss: 0.005223  [    4/  237]\n",
      "loss: 0.005829  [   84/  237]\n",
      "loss: 0.003040  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.033437 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "loss: 0.002489  [    4/  237]\n",
      "loss: 0.005173  [   84/  237]\n",
      "loss: 0.003117  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.033623 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "loss: 0.003288  [    4/  237]\n",
      "loss: 0.006830  [   84/  237]\n",
      "loss: 0.006224  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033737 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "loss: 0.001968  [    4/  237]\n",
      "loss: 0.005345  [   84/  237]\n",
      "loss: 0.003224  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033384 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "loss: 0.003494  [    4/  237]\n",
      "loss: 0.003295  [   84/  237]\n",
      "loss: 0.004060  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034161 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "loss: 0.005976  [    4/  237]\n",
      "loss: 0.002862  [   84/  237]\n",
      "loss: 0.003789  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.8%, Avg loss: 0.034035 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "loss: 0.002913  [    4/  237]\n",
      "loss: 0.002885  [   84/  237]\n",
      "loss: 0.004186  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033857 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "loss: 0.002879  [    4/  237]\n",
      "loss: 0.004703  [   84/  237]\n",
      "loss: 0.002709  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034036 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "loss: 0.006966  [    4/  237]\n",
      "loss: 0.003093  [   84/  237]\n",
      "loss: 0.004801  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033720 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "loss: 0.004287  [    4/  237]\n",
      "loss: 0.003878  [   84/  237]\n",
      "loss: 0.001953  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033489 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "loss: 0.003430  [    4/  237]\n",
      "loss: 0.001898  [   84/  237]\n",
      "loss: 0.002350  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.033428 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "loss: 0.003138  [    4/  237]\n",
      "loss: 0.002453  [   84/  237]\n",
      "loss: 0.003718  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034276 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "loss: 0.003233  [    4/  237]\n",
      "loss: 0.001634  [   84/  237]\n",
      "loss: 0.005912  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033875 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "loss: 0.004765  [    4/  237]\n",
      "loss: 0.009160  [   84/  237]\n",
      "loss: 0.007401  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034009 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "loss: 0.006981  [    4/  237]\n",
      "loss: 0.004050  [   84/  237]\n",
      "loss: 0.003765  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033828 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "loss: 0.003627  [    4/  237]\n",
      "loss: 0.002675  [   84/  237]\n",
      "loss: 0.005808  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.034236 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "loss: 0.006347  [    4/  237]\n",
      "loss: 0.004102  [   84/  237]\n",
      "loss: 0.004763  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033449 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "loss: 0.004862  [    4/  237]\n",
      "loss: 0.002292  [   84/  237]\n",
      "loss: 0.004459  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034122 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "loss: 0.005403  [    4/  237]\n",
      "loss: 0.003873  [   84/  237]\n",
      "loss: 0.005393  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034285 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "loss: 0.002806  [    4/  237]\n",
      "loss: 0.003025  [   84/  237]\n",
      "loss: 0.003924  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033892 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "loss: 0.002568  [    4/  237]\n",
      "loss: 0.005316  [   84/  237]\n",
      "loss: 0.004868  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033704 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "loss: 0.003937  [    4/  237]\n",
      "loss: 0.004356  [   84/  237]\n",
      "loss: 0.006715  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034043 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "loss: 0.006928  [    4/  237]\n",
      "loss: 0.002395  [   84/  237]\n",
      "loss: 0.006397  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.033685 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "loss: 0.003053  [    4/  237]\n",
      "loss: 0.002531  [   84/  237]\n",
      "loss: 0.005602  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033739 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "loss: 0.004597  [    4/  237]\n",
      "loss: 0.005172  [   84/  237]\n",
      "loss: 0.006750  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033737 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "loss: 0.002536  [    4/  237]\n",
      "loss: 0.001897  [   84/  237]\n",
      "loss: 0.004225  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034605 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "loss: 0.003689  [    4/  237]\n",
      "loss: 0.003936  [   84/  237]\n",
      "loss: 0.004625  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.033777 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "loss: 0.002932  [    4/  237]\n",
      "loss: 0.003806  [   84/  237]\n",
      "loss: 0.003227  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034033 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "loss: 0.005527  [    4/  237]\n",
      "loss: 0.006290  [   84/  237]\n",
      "loss: 0.004508  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033844 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "loss: 0.006973  [    4/  237]\n",
      "loss: 0.002827  [   84/  237]\n",
      "loss: 0.003236  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033814 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "loss: 0.004870  [    4/  237]\n",
      "loss: 0.003896  [   84/  237]\n",
      "loss: 0.003773  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034474 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "loss: 0.003203  [    4/  237]\n",
      "loss: 0.004373  [   84/  237]\n",
      "loss: 0.002588  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.034801 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "loss: 0.004094  [    4/  237]\n",
      "loss: 0.003319  [   84/  237]\n",
      "loss: 0.001727  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.033845 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "loss: 0.003215  [    4/  237]\n",
      "loss: 0.003276  [   84/  237]\n",
      "loss: 0.002207  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033802 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "loss: 0.004525  [    4/  237]\n",
      "loss: 0.003337  [   84/  237]\n",
      "loss: 0.001776  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034062 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "loss: 0.003815  [    4/  237]\n",
      "loss: 0.004231  [   84/  237]\n",
      "loss: 0.004886  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033267 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "loss: 0.003938  [    4/  237]\n",
      "loss: 0.003188  [   84/  237]\n",
      "loss: 0.002402  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.034606 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "loss: 0.003836  [    4/  237]\n",
      "loss: 0.005272  [   84/  237]\n",
      "loss: 0.003020  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033989 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "loss: 0.002165  [    4/  237]\n",
      "loss: 0.003524  [   84/  237]\n",
      "loss: 0.003029  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.8%, Avg loss: 0.033468 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "loss: 0.003450  [    4/  237]\n",
      "loss: 0.002461  [   84/  237]\n",
      "loss: 0.002545  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033970 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "loss: 0.003652  [    4/  237]\n",
      "loss: 0.004993  [   84/  237]\n",
      "loss: 0.002808  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.034075 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "loss: 0.003129  [    4/  237]\n",
      "loss: 0.003241  [   84/  237]\n",
      "loss: 0.006468  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.033883 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "loss: 0.004499  [    4/  237]\n",
      "loss: 0.003403  [   84/  237]\n",
      "loss: 0.004275  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034398 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "loss: 0.003234  [    4/  237]\n",
      "loss: 0.005405  [   84/  237]\n",
      "loss: 0.002720  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034443 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "loss: 0.002692  [    4/  237]\n",
      "loss: 0.003056  [   84/  237]\n",
      "loss: 0.004549  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034046 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "loss: 0.004207  [    4/  237]\n",
      "loss: 0.003661  [   84/  237]\n",
      "loss: 0.002796  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034355 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "loss: 0.004064  [    4/  237]\n",
      "loss: 0.004495  [   84/  237]\n",
      "loss: 0.003226  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.8%, Avg loss: 0.033820 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "loss: 0.004382  [    4/  237]\n",
      "loss: 0.003293  [   84/  237]\n",
      "loss: 0.004829  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034472 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "loss: 0.002590  [    4/  237]\n",
      "loss: 0.003951  [   84/  237]\n",
      "loss: 0.004308  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034131 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "loss: 0.002111  [    4/  237]\n",
      "loss: 0.003088  [   84/  237]\n",
      "loss: 0.003207  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.033979 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "loss: 0.003459  [    4/  237]\n",
      "loss: 0.002970  [   84/  237]\n",
      "loss: 0.002105  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034206 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "loss: 0.003216  [    4/  237]\n",
      "loss: 0.002911  [   84/  237]\n",
      "loss: 0.002418  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033973 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "loss: 0.002784  [    4/  237]\n",
      "loss: 0.003525  [   84/  237]\n",
      "loss: 0.001877  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034127 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "loss: 0.002065  [    4/  237]\n",
      "loss: 0.003499  [   84/  237]\n",
      "loss: 0.006042  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033755 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "loss: 0.003387  [    4/  237]\n",
      "loss: 0.002604  [   84/  237]\n",
      "loss: 0.003257  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034160 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "loss: 0.003884  [    4/  237]\n",
      "loss: 0.005812  [   84/  237]\n",
      "loss: 0.001672  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034072 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "loss: 0.002951  [    4/  237]\n",
      "loss: 0.002600  [   84/  237]\n",
      "loss: 0.002806  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.033933 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "loss: 0.003148  [    4/  237]\n",
      "loss: 0.005976  [   84/  237]\n",
      "loss: 0.004564  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034458 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "loss: 0.001236  [    4/  237]\n",
      "loss: 0.003820  [   84/  237]\n",
      "loss: 0.005997  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034208 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "loss: 0.004254  [    4/  237]\n",
      "loss: 0.002782  [   84/  237]\n",
      "loss: 0.002731  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.034535 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "loss: 0.005309  [    4/  237]\n",
      "loss: 0.003099  [   84/  237]\n",
      "loss: 0.003330  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034898 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "loss: 0.002887  [    4/  237]\n",
      "loss: 0.005797  [   84/  237]\n",
      "loss: 0.005354  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034081 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "loss: 0.002427  [    4/  237]\n",
      "loss: 0.003038  [   84/  237]\n",
      "loss: 0.002154  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034254 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "loss: 0.003582  [    4/  237]\n",
      "loss: 0.003022  [   84/  237]\n",
      "loss: 0.003901  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034413 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "loss: 0.006503  [    4/  237]\n",
      "loss: 0.002352  [   84/  237]\n",
      "loss: 0.002064  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034195 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "loss: 0.005081  [    4/  237]\n",
      "loss: 0.002529  [   84/  237]\n",
      "loss: 0.004798  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034604 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "loss: 0.004049  [    4/  237]\n",
      "loss: 0.003175  [   84/  237]\n",
      "loss: 0.003469  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034659 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "loss: 0.002557  [    4/  237]\n",
      "loss: 0.003026  [   84/  237]\n",
      "loss: 0.005666  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034155 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "loss: 0.006535  [    4/  237]\n",
      "loss: 0.002454  [   84/  237]\n",
      "loss: 0.005393  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035438 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "loss: 0.008403  [    4/  237]\n",
      "loss: 0.001980  [   84/  237]\n",
      "loss: 0.002764  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034110 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "loss: 0.003326  [    4/  237]\n",
      "loss: 0.002468  [   84/  237]\n",
      "loss: 0.003526  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034063 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "loss: 0.005008  [    4/  237]\n",
      "loss: 0.003428  [   84/  237]\n",
      "loss: 0.003308  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.8%, Avg loss: 0.034056 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "loss: 0.003707  [    4/  237]\n",
      "loss: 0.001652  [   84/  237]\n",
      "loss: 0.003105  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034469 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "loss: 0.003643  [    4/  237]\n",
      "loss: 0.002955  [   84/  237]\n",
      "loss: 0.001754  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034353 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "loss: 0.001739  [    4/  237]\n",
      "loss: 0.006037  [   84/  237]\n",
      "loss: 0.004053  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034461 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "loss: 0.003536  [    4/  237]\n",
      "loss: 0.003149  [   84/  237]\n",
      "loss: 0.003850  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034622 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "loss: 0.003098  [    4/  237]\n",
      "loss: 0.004428  [   84/  237]\n",
      "loss: 0.004455  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034156 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "loss: 0.003175  [    4/  237]\n",
      "loss: 0.002953  [   84/  237]\n",
      "loss: 0.003723  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034575 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "loss: 0.002152  [    4/  237]\n",
      "loss: 0.003952  [   84/  237]\n",
      "loss: 0.003266  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034435 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "loss: 0.004738  [    4/  237]\n",
      "loss: 0.005334  [   84/  237]\n",
      "loss: 0.001904  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034844 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "loss: 0.002284  [    4/  237]\n",
      "loss: 0.004654  [   84/  237]\n",
      "loss: 0.005281  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.8%, Avg loss: 0.034096 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "loss: 0.001920  [    4/  237]\n",
      "loss: 0.005133  [   84/  237]\n",
      "loss: 0.002755  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034105 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "loss: 0.001772  [    4/  237]\n",
      "loss: 0.005819  [   84/  237]\n",
      "loss: 0.002648  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034225 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "loss: 0.004479  [    4/  237]\n",
      "loss: 0.003210  [   84/  237]\n",
      "loss: 0.002514  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034027 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "loss: 0.004031  [    4/  237]\n",
      "loss: 0.004748  [   84/  237]\n",
      "loss: 0.002886  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034644 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "loss: 0.004190  [    4/  237]\n",
      "loss: 0.001511  [   84/  237]\n",
      "loss: 0.002408  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034333 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "loss: 0.001977  [    4/  237]\n",
      "loss: 0.007372  [   84/  237]\n",
      "loss: 0.003995  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034081 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "loss: 0.002254  [    4/  237]\n",
      "loss: 0.005735  [   84/  237]\n",
      "loss: 0.001829  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.034630 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "loss: 0.003304  [    4/  237]\n",
      "loss: 0.001987  [   84/  237]\n",
      "loss: 0.002704  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034551 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "loss: 0.003878  [    4/  237]\n",
      "loss: 0.004719  [   84/  237]\n",
      "loss: 0.001730  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.8%, Avg loss: 0.033824 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "loss: 0.002198  [    4/  237]\n",
      "loss: 0.002127  [   84/  237]\n",
      "loss: 0.002298  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034726 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "loss: 0.004087  [    4/  237]\n",
      "loss: 0.004152  [   84/  237]\n",
      "loss: 0.003420  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034891 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "loss: 0.003121  [    4/  237]\n",
      "loss: 0.002359  [   84/  237]\n",
      "loss: 0.003668  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034597 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "loss: 0.006371  [    4/  237]\n",
      "loss: 0.003883  [   84/  237]\n",
      "loss: 0.003613  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034573 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "loss: 0.003391  [    4/  237]\n",
      "loss: 0.002204  [   84/  237]\n",
      "loss: 0.004535  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.8%, Avg loss: 0.033881 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "loss: 0.005720  [    4/  237]\n",
      "loss: 0.002093  [   84/  237]\n",
      "loss: 0.001872  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.033475 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "loss: 0.002066  [    4/  237]\n",
      "loss: 0.001840  [   84/  237]\n",
      "loss: 0.001763  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034121 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "loss: 0.003286  [    4/  237]\n",
      "loss: 0.002463  [   84/  237]\n",
      "loss: 0.002684  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034121 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "loss: 0.003093  [    4/  237]\n",
      "loss: 0.002608  [   84/  237]\n",
      "loss: 0.002965  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.035444 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "loss: 0.002086  [    4/  237]\n",
      "loss: 0.002858  [   84/  237]\n",
      "loss: 0.003140  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034545 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "loss: 0.006047  [    4/  237]\n",
      "loss: 0.005568  [   84/  237]\n",
      "loss: 0.003889  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034254 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "loss: 0.003398  [    4/  237]\n",
      "loss: 0.004268  [   84/  237]\n",
      "loss: 0.001663  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034263 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "loss: 0.003215  [    4/  237]\n",
      "loss: 0.002234  [   84/  237]\n",
      "loss: 0.002211  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034585 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "loss: 0.001313  [    4/  237]\n",
      "loss: 0.002203  [   84/  237]\n",
      "loss: 0.002241  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034810 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "loss: 0.002333  [    4/  237]\n",
      "loss: 0.002230  [   84/  237]\n",
      "loss: 0.002970  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034195 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "loss: 0.003059  [    4/  237]\n",
      "loss: 0.003996  [   84/  237]\n",
      "loss: 0.003521  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034412 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "loss: 0.003783  [    4/  237]\n",
      "loss: 0.005028  [   84/  237]\n",
      "loss: 0.002916  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.035282 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "loss: 0.002908  [    4/  237]\n",
      "loss: 0.003422  [   84/  237]\n",
      "loss: 0.002798  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 25.0%, Avg loss: 0.034699 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "loss: 0.003532  [    4/  237]\n",
      "loss: 0.004137  [   84/  237]\n",
      "loss: 0.004792  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.034459 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "loss: 0.001889  [    4/  237]\n",
      "loss: 0.003334  [   84/  237]\n",
      "loss: 0.002355  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034013 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "loss: 0.002281  [    4/  237]\n",
      "loss: 0.002665  [   84/  237]\n",
      "loss: 0.002552  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.033857 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "loss: 0.003090  [    4/  237]\n",
      "loss: 0.003031  [   84/  237]\n",
      "loss: 0.001709  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034571 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "loss: 0.004025  [    4/  237]\n",
      "loss: 0.003714  [   84/  237]\n",
      "loss: 0.005104  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034995 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "loss: 0.002551  [    4/  237]\n",
      "loss: 0.002347  [   84/  237]\n",
      "loss: 0.003058  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035017 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "loss: 0.005372  [    4/  237]\n",
      "loss: 0.002919  [   84/  237]\n",
      "loss: 0.002599  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034734 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "loss: 0.002204  [    4/  237]\n",
      "loss: 0.004838  [   84/  237]\n",
      "loss: 0.003066  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 22.2%, Avg loss: 0.034398 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "loss: 0.003435  [    4/  237]\n",
      "loss: 0.002915  [   84/  237]\n",
      "loss: 0.001729  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.034329 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "loss: 0.001902  [    4/  237]\n",
      "loss: 0.004375  [   84/  237]\n",
      "loss: 0.002818  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.034748 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "loss: 0.005653  [    4/  237]\n",
      "loss: 0.003189  [   84/  237]\n",
      "loss: 0.003247  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035264 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "loss: 0.002244  [    4/  237]\n",
      "loss: 0.004845  [   84/  237]\n",
      "loss: 0.004248  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034971 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "loss: 0.004684  [    4/  237]\n",
      "loss: 0.003171  [   84/  237]\n",
      "loss: 0.002979  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.034230 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "loss: 0.001563  [    4/  237]\n",
      "loss: 0.001639  [   84/  237]\n",
      "loss: 0.004315  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034616 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "loss: 0.001009  [    4/  237]\n",
      "loss: 0.003741  [   84/  237]\n",
      "loss: 0.003631  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034890 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "loss: 0.002819  [    4/  237]\n",
      "loss: 0.002921  [   84/  237]\n",
      "loss: 0.002015  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.035721 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "loss: 0.001447  [    4/  237]\n",
      "loss: 0.002160  [   84/  237]\n",
      "loss: 0.001934  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.034573 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "loss: 0.003208  [    4/  237]\n",
      "loss: 0.003657  [   84/  237]\n",
      "loss: 0.002168  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034304 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "loss: 0.003173  [    4/  237]\n",
      "loss: 0.005178  [   84/  237]\n",
      "loss: 0.003694  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034271 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "loss: 0.003026  [    4/  237]\n",
      "loss: 0.002774  [   84/  237]\n",
      "loss: 0.003031  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.035019 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "loss: 0.002222  [    4/  237]\n",
      "loss: 0.002452  [   84/  237]\n",
      "loss: 0.003239  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034136 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "loss: 0.003379  [    4/  237]\n",
      "loss: 0.002958  [   84/  237]\n",
      "loss: 0.001750  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034302 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "loss: 0.004304  [    4/  237]\n",
      "loss: 0.002211  [   84/  237]\n",
      "loss: 0.005818  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034894 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "loss: 0.006342  [    4/  237]\n",
      "loss: 0.002347  [   84/  237]\n",
      "loss: 0.004245  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034315 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "loss: 0.004250  [    4/  237]\n",
      "loss: 0.002791  [   84/  237]\n",
      "loss: 0.002569  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034494 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "loss: 0.002130  [    4/  237]\n",
      "loss: 0.001829  [   84/  237]\n",
      "loss: 0.002568  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034938 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "loss: 0.003197  [    4/  237]\n",
      "loss: 0.004001  [   84/  237]\n",
      "loss: 0.002314  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.034664 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "loss: 0.001894  [    4/  237]\n",
      "loss: 0.004809  [   84/  237]\n",
      "loss: 0.003279  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034846 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "loss: 0.003225  [    4/  237]\n",
      "loss: 0.002749  [   84/  237]\n",
      "loss: 0.001524  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034246 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "loss: 0.002818  [    4/  237]\n",
      "loss: 0.001876  [   84/  237]\n",
      "loss: 0.002177  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034355 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "loss: 0.002369  [    4/  237]\n",
      "loss: 0.004341  [   84/  237]\n",
      "loss: 0.002671  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 21.7%, Avg loss: 0.034726 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "loss: 0.001961  [    4/  237]\n",
      "loss: 0.002051  [   84/  237]\n",
      "loss: 0.001905  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034389 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "loss: 0.004202  [    4/  237]\n",
      "loss: 0.001764  [   84/  237]\n",
      "loss: 0.002738  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035399 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "loss: 0.003140  [    4/  237]\n",
      "loss: 0.002553  [   84/  237]\n",
      "loss: 0.004069  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034762 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "loss: 0.001780  [    4/  237]\n",
      "loss: 0.002432  [   84/  237]\n",
      "loss: 0.002982  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 21.7%, Avg loss: 0.034809 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "loss: 0.003196  [    4/  237]\n",
      "loss: 0.003098  [   84/  237]\n",
      "loss: 0.002269  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034717 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "loss: 0.003276  [    4/  237]\n",
      "loss: 0.001777  [   84/  237]\n",
      "loss: 0.001944  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035007 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "loss: 0.004781  [    4/  237]\n",
      "loss: 0.002014  [   84/  237]\n",
      "loss: 0.001670  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034607 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "loss: 0.003186  [    4/  237]\n",
      "loss: 0.004933  [   84/  237]\n",
      "loss: 0.002736  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035027 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "loss: 0.001286  [    4/  237]\n",
      "loss: 0.004238  [   84/  237]\n",
      "loss: 0.003544  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.3%, Avg loss: 0.035187 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "loss: 0.006214  [    4/  237]\n",
      "loss: 0.002075  [   84/  237]\n",
      "loss: 0.003395  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035413 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "loss: 0.001957  [    4/  237]\n",
      "loss: 0.002537  [   84/  237]\n",
      "loss: 0.002202  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034705 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "loss: 0.003413  [    4/  237]\n",
      "loss: 0.003290  [   84/  237]\n",
      "loss: 0.005107  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.035315 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "loss: 0.005959  [    4/  237]\n",
      "loss: 0.002963  [   84/  237]\n",
      "loss: 0.003650  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034588 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "loss: 0.001222  [    4/  237]\n",
      "loss: 0.002990  [   84/  237]\n",
      "loss: 0.003962  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034913 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "loss: 0.002006  [    4/  237]\n",
      "loss: 0.000884  [   84/  237]\n",
      "loss: 0.008037  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034998 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "loss: 0.002754  [    4/  237]\n",
      "loss: 0.002871  [   84/  237]\n",
      "loss: 0.002741  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034767 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "loss: 0.002410  [    4/  237]\n",
      "loss: 0.002655  [   84/  237]\n",
      "loss: 0.003548  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.035058 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "loss: 0.002390  [    4/  237]\n",
      "loss: 0.002042  [   84/  237]\n",
      "loss: 0.003494  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034731 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "loss: 0.002053  [    4/  237]\n",
      "loss: 0.002447  [   84/  237]\n",
      "loss: 0.003093  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 22.2%, Avg loss: 0.034575 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "loss: 0.004548  [    4/  237]\n",
      "loss: 0.004002  [   84/  237]\n",
      "loss: 0.002927  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034856 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "loss: 0.003434  [    4/  237]\n",
      "loss: 0.002880  [   84/  237]\n",
      "loss: 0.003452  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035052 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "loss: 0.001843  [    4/  237]\n",
      "loss: 0.002086  [   84/  237]\n",
      "loss: 0.002908  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034913 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "loss: 0.001901  [    4/  237]\n",
      "loss: 0.002650  [   84/  237]\n",
      "loss: 0.002412  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.035192 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "loss: 0.001935  [    4/  237]\n",
      "loss: 0.001750  [   84/  237]\n",
      "loss: 0.003078  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035104 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "loss: 0.002868  [    4/  237]\n",
      "loss: 0.001839  [   84/  237]\n",
      "loss: 0.001915  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034692 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "loss: 0.001693  [    4/  237]\n",
      "loss: 0.002457  [   84/  237]\n",
      "loss: 0.003308  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034733 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "loss: 0.001825  [    4/  237]\n",
      "loss: 0.001554  [   84/  237]\n",
      "loss: 0.002006  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 25.0%, Avg loss: 0.034376 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "loss: 0.002531  [    4/  237]\n",
      "loss: 0.004958  [   84/  237]\n",
      "loss: 0.002297  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.034567 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "loss: 0.002691  [    4/  237]\n",
      "loss: 0.003594  [   84/  237]\n",
      "loss: 0.002435  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034952 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "loss: 0.001522  [    4/  237]\n",
      "loss: 0.004970  [   84/  237]\n",
      "loss: 0.002153  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035165 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "loss: 0.002023  [    4/  237]\n",
      "loss: 0.002171  [   84/  237]\n",
      "loss: 0.004261  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034946 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "loss: 0.002609  [    4/  237]\n",
      "loss: 0.001872  [   84/  237]\n",
      "loss: 0.002767  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034847 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "loss: 0.002733  [    4/  237]\n",
      "loss: 0.002097  [   84/  237]\n",
      "loss: 0.001182  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035304 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "loss: 0.002787  [    4/  237]\n",
      "loss: 0.001613  [   84/  237]\n",
      "loss: 0.002908  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.034979 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "loss: 0.003534  [    4/  237]\n",
      "loss: 0.002582  [   84/  237]\n",
      "loss: 0.001730  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.3%, Avg loss: 0.035259 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "loss: 0.001524  [    4/  237]\n",
      "loss: 0.001032  [   84/  237]\n",
      "loss: 0.003094  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034644 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "loss: 0.004700  [    4/  237]\n",
      "loss: 0.003151  [   84/  237]\n",
      "loss: 0.004321  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034727 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "loss: 0.002208  [    4/  237]\n",
      "loss: 0.002711  [   84/  237]\n",
      "loss: 0.001788  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034638 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "loss: 0.003649  [    4/  237]\n",
      "loss: 0.001278  [   84/  237]\n",
      "loss: 0.003298  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 23.9%, Avg loss: 0.034719 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "loss: 0.002118  [    4/  237]\n",
      "loss: 0.002021  [   84/  237]\n",
      "loss: 0.003331  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 24.4%, Avg loss: 0.035129 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = training_process(FCModel, 1e-1, 1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, using a fully connected model was a bit mad, but it does learn. The board accuracy increases much more like a straight line, where the convolution-based models' curves shoot up at the start and then level off quickly. Unfortunately, the fully connected model's test accuracy increases much more slowly than its training accuracy. After 1000 iterations, the fully connected model's training accuracy is 97%, higher than any of the convolution-based models' training accuracy, but its test accuracy levels off at 22% at 700 iterations and doesn't increase between 700 and 1000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 90\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_failed_prediction(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The failed predictions of this model show it is clearly lacking some geometric intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnectionModel(nn.Module):\n",
    "    \"\"\"Like the baseline, but with a skip connection from the input to the output, because we expect most cells not to change from one frame to the next.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(2, 10, 3, padding=1)\n",
    "        self.conv1 = nn.Conv2d(10, 10, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(10, 10, 1)\n",
    "        self.conv3 = nn.Conv2d(10, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((0, 3, 1, 2)) # Move channels/classes to dimension 1\n",
    "        x_skip = x # Store value of x for skip connection\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = x + (x_skip - 0.5) * 20.0 # Add skip connection value that moves log_softmax close to the correct values\n",
    "        logits = F.log_softmax(x, dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.545671  [    4/  237]\n",
      "loss: 0.545582  [   84/  237]\n",
      "loss: 0.590647  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575548 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.499696  [    4/  237]\n",
      "loss: 0.499477  [   84/  237]\n",
      "loss: 0.589608  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.572819 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.544238  [    4/  237]\n",
      "loss: 0.498709  [   84/  237]\n",
      "loss: 0.589145  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.573064 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.453277  [    4/  237]\n",
      "loss: 0.498149  [   84/  237]\n",
      "loss: 0.587910  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.573135 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.497340  [    4/  237]\n",
      "loss: 0.498768  [   84/  237]\n",
      "loss: 0.542357  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.571816 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.496589  [    4/  237]\n",
      "loss: 0.496020  [   84/  237]\n",
      "loss: 0.540163  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.569403 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.539411  [    4/  237]\n",
      "loss: 0.583191  [   84/  237]\n",
      "loss: 0.536205  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.566301 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.622477  [    4/  237]\n",
      "loss: 0.489645  [   84/  237]\n",
      "loss: 0.530681  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.556084 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.611919  [    4/  237]\n",
      "loss: 0.479514  [   84/  237]\n",
      "loss: 0.473948  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.536490 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.546637  [    4/  237]\n",
      "loss: 0.494587  [   84/  237]\n",
      "loss: 0.475663  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.445979 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.477003  [    4/  237]\n",
      "loss: 0.321779  [   84/  237]\n",
      "loss: 0.206181  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.9%, Board accuracy: 14.4%, Avg loss: 0.104241 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.070933  [    4/  237]\n",
      "loss: 0.044439  [   84/  237]\n",
      "loss: 0.043173  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 22.2%, Avg loss: 0.069204 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.043044  [    4/  237]\n",
      "loss: 0.023626  [   84/  237]\n",
      "loss: 0.041157  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.0%, Board accuracy: 23.9%, Avg loss: 0.056488 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.023167  [    4/  237]\n",
      "loss: 0.020183  [   84/  237]\n",
      "loss: 0.018000  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.1%, Board accuracy: 28.3%, Avg loss: 0.047999 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.009102  [    4/  237]\n",
      "loss: 0.020767  [   84/  237]\n",
      "loss: 0.013140  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.3%, Board accuracy: 33.9%, Avg loss: 0.042278 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.016866  [    4/  237]\n",
      "loss: 0.019272  [   84/  237]\n",
      "loss: 0.019018  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.4%, Board accuracy: 39.4%, Avg loss: 0.039615 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.004173  [    4/  237]\n",
      "loss: 0.117639  [   84/  237]\n",
      "loss: 0.093714  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 45.0%, Avg loss: 0.033162 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.010895  [    4/  237]\n",
      "loss: 0.006365  [   84/  237]\n",
      "loss: 0.011254  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 42.8%, Avg loss: 0.030908 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.015051  [    4/  237]\n",
      "loss: 0.004929  [   84/  237]\n",
      "loss: 0.004355  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 55.0%, Avg loss: 0.028026 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.010573  [    4/  237]\n",
      "loss: 0.006797  [   84/  237]\n",
      "loss: 0.008641  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 61.7%, Avg loss: 0.026213 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.022492  [    4/  237]\n",
      "loss: 0.006027  [   84/  237]\n",
      "loss: 0.004175  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 63.9%, Avg loss: 0.024917 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.002866  [    4/  237]\n",
      "loss: 0.009052  [   84/  237]\n",
      "loss: 0.004083  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 66.7%, Avg loss: 0.022733 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.009981  [    4/  237]\n",
      "loss: 0.007978  [   84/  237]\n",
      "loss: 0.015148  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 65.6%, Avg loss: 0.021632 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.009017  [    4/  237]\n",
      "loss: 0.010711  [   84/  237]\n",
      "loss: 0.005868  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 66.1%, Avg loss: 0.020087 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.018080  [    4/  237]\n",
      "loss: 0.003606  [   84/  237]\n",
      "loss: 0.008331  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 68.3%, Avg loss: 0.018352 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.082406  [    4/  237]\n",
      "loss: 0.011044  [   84/  237]\n",
      "loss: 0.046445  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.017452 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.002433  [    4/  237]\n",
      "loss: 0.001490  [   84/  237]\n",
      "loss: 0.003691  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 72.8%, Avg loss: 0.015121 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.006854  [    4/  237]\n",
      "loss: 0.033438  [   84/  237]\n",
      "loss: 0.005490  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 69.4%, Avg loss: 0.013982 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.028100  [    4/  237]\n",
      "loss: 0.008316  [   84/  237]\n",
      "loss: 0.004777  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 76.7%, Avg loss: 0.013252 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.006966  [    4/  237]\n",
      "loss: 0.004213  [   84/  237]\n",
      "loss: 0.002617  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.012660 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.054584  [    4/  237]\n",
      "loss: 0.003041  [   84/  237]\n",
      "loss: 0.002144  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 75.0%, Avg loss: 0.011781 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.007347  [    4/  237]\n",
      "loss: 0.005265  [   84/  237]\n",
      "loss: 0.002159  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 63.3%, Avg loss: 0.014785 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.009346  [    4/  237]\n",
      "loss: 0.028209  [   84/  237]\n",
      "loss: 0.002501  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.010659 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.002871  [    4/  237]\n",
      "loss: 0.027339  [   84/  237]\n",
      "loss: 0.002000  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.010399 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.002723  [    4/  237]\n",
      "loss: 0.005275  [   84/  237]\n",
      "loss: 0.008026  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.010721 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.002863  [    4/  237]\n",
      "loss: 0.009887  [   84/  237]\n",
      "loss: 0.002119  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.010847 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.002532  [    4/  237]\n",
      "loss: 0.003936  [   84/  237]\n",
      "loss: 0.001649  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009483 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.004975  [    4/  237]\n",
      "loss: 0.001515  [   84/  237]\n",
      "loss: 0.001488  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009524 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.003737  [    4/  237]\n",
      "loss: 0.034146  [   84/  237]\n",
      "loss: 0.004604  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009623 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.001568  [    4/  237]\n",
      "loss: 0.001982  [   84/  237]\n",
      "loss: 0.002396  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.009476 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.021894  [    4/  237]\n",
      "loss: 0.005762  [   84/  237]\n",
      "loss: 0.001379  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009077 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.002499  [    4/  237]\n",
      "loss: 0.003823  [   84/  237]\n",
      "loss: 0.005048  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.2%, Avg loss: 0.009815 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.004706  [    4/  237]\n",
      "loss: 0.002785  [   84/  237]\n",
      "loss: 0.022227  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.008960 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.004738  [    4/  237]\n",
      "loss: 0.001990  [   84/  237]\n",
      "loss: 0.009637  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.009188 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.004771  [    4/  237]\n",
      "loss: 0.002056  [   84/  237]\n",
      "loss: 0.020456  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.009054 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.033738  [    4/  237]\n",
      "loss: 0.002588  [   84/  237]\n",
      "loss: 0.001894  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008759 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.027628  [    4/  237]\n",
      "loss: 0.004180  [   84/  237]\n",
      "loss: 0.002655  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009148 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.003892  [    4/  237]\n",
      "loss: 0.003154  [   84/  237]\n",
      "loss: 0.001442  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008442 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.018566  [    4/  237]\n",
      "loss: 0.004799  [   84/  237]\n",
      "loss: 0.006082  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.009613 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.001634  [    4/  237]\n",
      "loss: 0.002721  [   84/  237]\n",
      "loss: 0.005419  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008568 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.022996  [    4/  237]\n",
      "loss: 0.002312  [   84/  237]\n",
      "loss: 0.002038  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008852 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.001990  [    4/  237]\n",
      "loss: 0.001424  [   84/  237]\n",
      "loss: 0.003951  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.008792 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.001401  [    4/  237]\n",
      "loss: 0.003003  [   84/  237]\n",
      "loss: 0.037995  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008381 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.001791  [    4/  237]\n",
      "loss: 0.001286  [   84/  237]\n",
      "loss: 0.021664  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009322 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.002655  [    4/  237]\n",
      "loss: 0.001364  [   84/  237]\n",
      "loss: 0.001132  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008622 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.025892  [    4/  237]\n",
      "loss: 0.003205  [   84/  237]\n",
      "loss: 0.004046  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008627 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.001470  [    4/  237]\n",
      "loss: 0.024074  [   84/  237]\n",
      "loss: 0.037472  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.008798 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.005119  [    4/  237]\n",
      "loss: 0.002083  [   84/  237]\n",
      "loss: 0.001454  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.008992 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.001303  [    4/  237]\n",
      "loss: 0.002451  [   84/  237]\n",
      "loss: 0.001899  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008186 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.002580  [    4/  237]\n",
      "loss: 0.001229  [   84/  237]\n",
      "loss: 0.041338  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007866 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.004021  [    4/  237]\n",
      "loss: 0.000995  [   84/  237]\n",
      "loss: 0.003115  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008507 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.001259  [    4/  237]\n",
      "loss: 0.005527  [   84/  237]\n",
      "loss: 0.001834  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008144 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.020931  [    4/  237]\n",
      "loss: 0.002061  [   84/  237]\n",
      "loss: 0.002827  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008461 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.002593  [    4/  237]\n",
      "loss: 0.001031  [   84/  237]\n",
      "loss: 0.001798  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008636 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.003552  [    4/  237]\n",
      "loss: 0.002098  [   84/  237]\n",
      "loss: 0.004841  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008305 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.001690  [    4/  237]\n",
      "loss: 0.001443  [   84/  237]\n",
      "loss: 0.000856  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008094 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.002624  [    4/  237]\n",
      "loss: 0.001753  [   84/  237]\n",
      "loss: 0.001105  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008230 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.003433  [    4/  237]\n",
      "loss: 0.023760  [   84/  237]\n",
      "loss: 0.001553  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008196 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.020485  [    4/  237]\n",
      "loss: 0.000733  [   84/  237]\n",
      "loss: 0.000993  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008132 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.001584  [    4/  237]\n",
      "loss: 0.001082  [   84/  237]\n",
      "loss: 0.001333  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007725 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.002435  [    4/  237]\n",
      "loss: 0.000860  [   84/  237]\n",
      "loss: 0.000647  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.015936 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.019157  [    4/  237]\n",
      "loss: 0.001360  [   84/  237]\n",
      "loss: 0.001105  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008188 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.003138  [    4/  237]\n",
      "loss: 0.034657  [   84/  237]\n",
      "loss: 0.023652  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.008806 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.004948  [    4/  237]\n",
      "loss: 0.001014  [   84/  237]\n",
      "loss: 0.002567  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008099 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.003808  [    4/  237]\n",
      "loss: 0.023420  [   84/  237]\n",
      "loss: 0.002186  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008767 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.001763  [    4/  237]\n",
      "loss: 0.004168  [   84/  237]\n",
      "loss: 0.003510  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008176 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.001824  [    4/  237]\n",
      "loss: 0.002997  [   84/  237]\n",
      "loss: 0.002447  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008845 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.032448  [    4/  237]\n",
      "loss: 0.000778  [   84/  237]\n",
      "loss: 0.002298  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008550 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.000902  [    4/  237]\n",
      "loss: 0.019139  [   84/  237]\n",
      "loss: 0.002202  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008263 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.031743  [    4/  237]\n",
      "loss: 0.002800  [   84/  237]\n",
      "loss: 0.000860  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008212 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.001052  [    4/  237]\n",
      "loss: 0.001206  [   84/  237]\n",
      "loss: 0.003003  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008211 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.000797  [    4/  237]\n",
      "loss: 0.001205  [   84/  237]\n",
      "loss: 0.000601  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008312 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.001085  [    4/  237]\n",
      "loss: 0.001815  [   84/  237]\n",
      "loss: 0.022947  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007441 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.001812  [    4/  237]\n",
      "loss: 0.002262  [   84/  237]\n",
      "loss: 0.002157  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008449 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.000852  [    4/  237]\n",
      "loss: 0.024268  [   84/  237]\n",
      "loss: 0.003274  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007748 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.001064  [    4/  237]\n",
      "loss: 0.000796  [   84/  237]\n",
      "loss: 0.002051  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007824 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.001089  [    4/  237]\n",
      "loss: 0.003337  [   84/  237]\n",
      "loss: 0.023993  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008425 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.002155  [    4/  237]\n",
      "loss: 0.002300  [   84/  237]\n",
      "loss: 0.000787  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007469 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.001850  [    4/  237]\n",
      "loss: 0.001811  [   84/  237]\n",
      "loss: 0.001586  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008638 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.000765  [    4/  237]\n",
      "loss: 0.001801  [   84/  237]\n",
      "loss: 0.000835  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008098 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.000880  [    4/  237]\n",
      "loss: 0.001100  [   84/  237]\n",
      "loss: 0.000664  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.008331 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.001563  [    4/  237]\n",
      "loss: 0.001505  [   84/  237]\n",
      "loss: 0.029212  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008383 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.000849  [    4/  237]\n",
      "loss: 0.000996  [   84/  237]\n",
      "loss: 0.000701  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008729 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.002668  [    4/  237]\n",
      "loss: 0.002140  [   84/  237]\n",
      "loss: 0.001024  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008477 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.023032  [    4/  237]\n",
      "loss: 0.000944  [   84/  237]\n",
      "loss: 0.027247  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007495 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.001499  [    4/  237]\n",
      "loss: 0.001423  [   84/  237]\n",
      "loss: 0.001368  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007572 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.001246  [    4/  237]\n",
      "loss: 0.001178  [   84/  237]\n",
      "loss: 0.001096  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008060 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.000784  [    4/  237]\n",
      "loss: 0.001903  [   84/  237]\n",
      "loss: 0.000536  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007854 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.002020  [    4/  237]\n",
      "loss: 0.024224  [   84/  237]\n",
      "loss: 0.001536  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007612 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.001121  [    4/  237]\n",
      "loss: 0.000759  [   84/  237]\n",
      "loss: 0.000873  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008382 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.026198  [    4/  237]\n",
      "loss: 0.001023  [   84/  237]\n",
      "loss: 0.001062  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008293 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.000621  [    4/  237]\n",
      "loss: 0.001505  [   84/  237]\n",
      "loss: 0.000716  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007423 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.002435  [    4/  237]\n",
      "loss: 0.000753  [   84/  237]\n",
      "loss: 0.019243  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008079 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.001153  [    4/  237]\n",
      "loss: 0.001113  [   84/  237]\n",
      "loss: 0.019557  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.009474 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.017523  [    4/  237]\n",
      "loss: 0.019810  [   84/  237]\n",
      "loss: 0.002592  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007544 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.001696  [    4/  237]\n",
      "loss: 0.001983  [   84/  237]\n",
      "loss: 0.001631  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007574 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.001418  [    4/  237]\n",
      "loss: 0.004270  [   84/  237]\n",
      "loss: 0.001724  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007425 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.000989  [    4/  237]\n",
      "loss: 0.001421  [   84/  237]\n",
      "loss: 0.001162  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007756 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.001042  [    4/  237]\n",
      "loss: 0.000539  [   84/  237]\n",
      "loss: 0.005086  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007730 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.000772  [    4/  237]\n",
      "loss: 0.003077  [   84/  237]\n",
      "loss: 0.026355  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007899 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.005450  [    4/  237]\n",
      "loss: 0.001853  [   84/  237]\n",
      "loss: 0.000954  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008159 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.001540  [    4/  237]\n",
      "loss: 0.023553  [   84/  237]\n",
      "loss: 0.000871  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008013 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.001006  [    4/  237]\n",
      "loss: 0.000834  [   84/  237]\n",
      "loss: 0.001292  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007685 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.001931  [    4/  237]\n",
      "loss: 0.001362  [   84/  237]\n",
      "loss: 0.000676  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007959 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.000789  [    4/  237]\n",
      "loss: 0.000952  [   84/  237]\n",
      "loss: 0.000764  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007660 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.036359  [    4/  237]\n",
      "loss: 0.000974  [   84/  237]\n",
      "loss: 0.002087  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008087 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.001092  [    4/  237]\n",
      "loss: 0.017790  [   84/  237]\n",
      "loss: 0.001002  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007589 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.000760  [    4/  237]\n",
      "loss: 0.002043  [   84/  237]\n",
      "loss: 0.001261  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.010205 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.000580  [    4/  237]\n",
      "loss: 0.000430  [   84/  237]\n",
      "loss: 0.001352  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007328 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.002105  [    4/  237]\n",
      "loss: 0.001936  [   84/  237]\n",
      "loss: 0.000820  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008130 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.002420  [    4/  237]\n",
      "loss: 0.000679  [   84/  237]\n",
      "loss: 0.002597  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007658 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.000874  [    4/  237]\n",
      "loss: 0.020710  [   84/  237]\n",
      "loss: 0.001634  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007957 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.000587  [    4/  237]\n",
      "loss: 0.019497  [   84/  237]\n",
      "loss: 0.001125  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008531 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.025776  [    4/  237]\n",
      "loss: 0.000767  [   84/  237]\n",
      "loss: 0.021923  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008482 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.000324  [    4/  237]\n",
      "loss: 0.000772  [   84/  237]\n",
      "loss: 0.001144  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008402 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.005181  [    4/  237]\n",
      "loss: 0.000587  [   84/  237]\n",
      "loss: 0.018962  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008058 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.001098  [    4/  237]\n",
      "loss: 0.000598  [   84/  237]\n",
      "loss: 0.000926  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007994 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.001865  [    4/  237]\n",
      "loss: 0.000368  [   84/  237]\n",
      "loss: 0.000835  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007236 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.001284  [    4/  237]\n",
      "loss: 0.004050  [   84/  237]\n",
      "loss: 0.000923  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007753 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.001476  [    4/  237]\n",
      "loss: 0.001504  [   84/  237]\n",
      "loss: 0.001112  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007621 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.000926  [    4/  237]\n",
      "loss: 0.000584  [   84/  237]\n",
      "loss: 0.001197  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008447 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.022182  [    4/  237]\n",
      "loss: 0.001101  [   84/  237]\n",
      "loss: 0.000628  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007515 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.003800  [    4/  237]\n",
      "loss: 0.000962  [   84/  237]\n",
      "loss: 0.001875  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007772 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.001333  [    4/  237]\n",
      "loss: 0.026608  [   84/  237]\n",
      "loss: 0.001077  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008120 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.021008  [    4/  237]\n",
      "loss: 0.020120  [   84/  237]\n",
      "loss: 0.001800  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008165 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.001977  [    4/  237]\n",
      "loss: 0.000770  [   84/  237]\n",
      "loss: 0.001329  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007688 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.000957  [    4/  237]\n",
      "loss: 0.045424  [   84/  237]\n",
      "loss: 0.001177  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008325 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.000692  [    4/  237]\n",
      "loss: 0.001532  [   84/  237]\n",
      "loss: 0.000760  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008577 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.001432  [    4/  237]\n",
      "loss: 0.000928  [   84/  237]\n",
      "loss: 0.001883  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008039 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.022798  [    4/  237]\n",
      "loss: 0.000767  [   84/  237]\n",
      "loss: 0.000787  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008144 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.001272  [    4/  237]\n",
      "loss: 0.000819  [   84/  237]\n",
      "loss: 0.002566  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007236 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.001264  [    4/  237]\n",
      "loss: 0.001495  [   84/  237]\n",
      "loss: 0.002564  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008296 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.000453  [    4/  237]\n",
      "loss: 0.005032  [   84/  237]\n",
      "loss: 0.000997  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008193 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.021839  [    4/  237]\n",
      "loss: 0.000794  [   84/  237]\n",
      "loss: 0.002257  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008384 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.000644  [    4/  237]\n",
      "loss: 0.001247  [   84/  237]\n",
      "loss: 0.000863  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008344 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.000693  [    4/  237]\n",
      "loss: 0.000573  [   84/  237]\n",
      "loss: 0.001767  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008747 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.000524  [    4/  237]\n",
      "loss: 0.001110  [   84/  237]\n",
      "loss: 0.001547  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008008 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.000905  [    4/  237]\n",
      "loss: 0.001118  [   84/  237]\n",
      "loss: 0.022989  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007739 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.000330  [    4/  237]\n",
      "loss: 0.001561  [   84/  237]\n",
      "loss: 0.002260  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008084 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.001411  [    4/  237]\n",
      "loss: 0.000683  [   84/  237]\n",
      "loss: 0.001623  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007832 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.000732  [    4/  237]\n",
      "loss: 0.001148  [   84/  237]\n",
      "loss: 0.000558  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007628 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.001241  [    4/  237]\n",
      "loss: 0.019952  [   84/  237]\n",
      "loss: 0.025311  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008471 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.000519  [    4/  237]\n",
      "loss: 0.003821  [   84/  237]\n",
      "loss: 0.021255  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007675 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.001256  [    4/  237]\n",
      "loss: 0.003662  [   84/  237]\n",
      "loss: 0.023227  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007563 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.001138  [    4/  237]\n",
      "loss: 0.000608  [   84/  237]\n",
      "loss: 0.000621  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008142 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.000623  [    4/  237]\n",
      "loss: 0.001071  [   84/  237]\n",
      "loss: 0.000593  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007794 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.001237  [    4/  237]\n",
      "loss: 0.000661  [   84/  237]\n",
      "loss: 0.000467  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008010 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.000618  [    4/  237]\n",
      "loss: 0.001691  [   84/  237]\n",
      "loss: 0.001301  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007841 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.000767  [    4/  237]\n",
      "loss: 0.001244  [   84/  237]\n",
      "loss: 0.020240  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007765 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.023260  [    4/  237]\n",
      "loss: 0.000528  [   84/  237]\n",
      "loss: 0.001965  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008395 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.021877  [    4/  237]\n",
      "loss: 0.001181  [   84/  237]\n",
      "loss: 0.001595  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008788 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.000480  [    4/  237]\n",
      "loss: 0.001121  [   84/  237]\n",
      "loss: 0.025187  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007590 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.000776  [    4/  237]\n",
      "loss: 0.001155  [   84/  237]\n",
      "loss: 0.001227  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007687 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.020956  [    4/  237]\n",
      "loss: 0.022917  [   84/  237]\n",
      "loss: 0.025642  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008146 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.003247  [    4/  237]\n",
      "loss: 0.003635  [   84/  237]\n",
      "loss: 0.001746  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008338 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.000440  [    4/  237]\n",
      "loss: 0.000421  [   84/  237]\n",
      "loss: 0.001457  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007826 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.001080  [    4/  237]\n",
      "loss: 0.002180  [   84/  237]\n",
      "loss: 0.000823  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007804 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.043842  [    4/  237]\n",
      "loss: 0.014528  [   84/  237]\n",
      "loss: 0.000663  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007834 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.000461  [    4/  237]\n",
      "loss: 0.000513  [   84/  237]\n",
      "loss: 0.020512  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007250 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.001199  [    4/  237]\n",
      "loss: 0.001089  [   84/  237]\n",
      "loss: 0.000277  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008007 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.000785  [    4/  237]\n",
      "loss: 0.000742  [   84/  237]\n",
      "loss: 0.001665  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008814 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.001661  [    4/  237]\n",
      "loss: 0.000436  [   84/  237]\n",
      "loss: 0.000826  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008235 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.002143  [    4/  237]\n",
      "loss: 0.022659  [   84/  237]\n",
      "loss: 0.000690  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007505 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.000849  [    4/  237]\n",
      "loss: 0.002389  [   84/  237]\n",
      "loss: 0.000786  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007736 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.001562  [    4/  237]\n",
      "loss: 0.001545  [   84/  237]\n",
      "loss: 0.019961  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.008297 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.000936  [    4/  237]\n",
      "loss: 0.000896  [   84/  237]\n",
      "loss: 0.018761  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007797 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.000992  [    4/  237]\n",
      "loss: 0.000610  [   84/  237]\n",
      "loss: 0.001626  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008213 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.001319  [    4/  237]\n",
      "loss: 0.000582  [   84/  237]\n",
      "loss: 0.002030  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007492 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.000630  [    4/  237]\n",
      "loss: 0.000546  [   84/  237]\n",
      "loss: 0.001711  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007530 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.000676  [    4/  237]\n",
      "loss: 0.021516  [   84/  237]\n",
      "loss: 0.000658  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008442 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.025330  [    4/  237]\n",
      "loss: 0.001609  [   84/  237]\n",
      "loss: 0.000499  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007777 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.000690  [    4/  237]\n",
      "loss: 0.000606  [   84/  237]\n",
      "loss: 0.020739  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007215 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.001133  [    4/  237]\n",
      "loss: 0.001005  [   84/  237]\n",
      "loss: 0.000835  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008057 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.023753  [    4/  237]\n",
      "loss: 0.001298  [   84/  237]\n",
      "loss: 0.000375  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.008185 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.002084  [    4/  237]\n",
      "loss: 0.002613  [   84/  237]\n",
      "loss: 0.000922  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008418 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.000927  [    4/  237]\n",
      "loss: 0.001016  [   84/  237]\n",
      "loss: 0.001317  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007212 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.001402  [    4/  237]\n",
      "loss: 0.000514  [   84/  237]\n",
      "loss: 0.001027  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.012610 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.011855  [    4/  237]\n",
      "loss: 0.002209  [   84/  237]\n",
      "loss: 0.001118  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007724 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.000954  [    4/  237]\n",
      "loss: 0.003656  [   84/  237]\n",
      "loss: 0.000603  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008064 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.023647  [    4/  237]\n",
      "loss: 0.000315  [   84/  237]\n",
      "loss: 0.002182  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007808 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.001518  [    4/  237]\n",
      "loss: 0.014407  [   84/  237]\n",
      "loss: 0.000985  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.009108 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.000410  [    4/  237]\n",
      "loss: 0.024331  [   84/  237]\n",
      "loss: 0.000684  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007565 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.017878  [    4/  237]\n",
      "loss: 0.000397  [   84/  237]\n",
      "loss: 0.024716  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008717 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.022140  [    4/  237]\n",
      "loss: 0.001315  [   84/  237]\n",
      "loss: 0.000486  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007175 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.000805  [    4/  237]\n",
      "loss: 0.000583  [   84/  237]\n",
      "loss: 0.000715  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007462 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.000794  [    4/  237]\n",
      "loss: 0.000784  [   84/  237]\n",
      "loss: 0.019947  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007619 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.001530  [    4/  237]\n",
      "loss: 0.000695  [   84/  237]\n",
      "loss: 0.000727  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.010120 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.008638  [    4/  237]\n",
      "loss: 0.001129  [   84/  237]\n",
      "loss: 0.020068  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008331 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.020499  [    4/  237]\n",
      "loss: 0.000583  [   84/  237]\n",
      "loss: 0.000565  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.007561 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.003512  [    4/  237]\n",
      "loss: 0.020912  [   84/  237]\n",
      "loss: 0.001298  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007458 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.000819  [    4/  237]\n",
      "loss: 0.001136  [   84/  237]\n",
      "loss: 0.000461  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007151 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.002225  [    4/  237]\n",
      "loss: 0.019934  [   84/  237]\n",
      "loss: 0.000973  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007662 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.001011  [    4/  237]\n",
      "loss: 0.003219  [   84/  237]\n",
      "loss: 0.001309  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007190 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.001144  [    4/  237]\n",
      "loss: 0.001141  [   84/  237]\n",
      "loss: 0.001809  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007219 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.002807  [    4/  237]\n",
      "loss: 0.000694  [   84/  237]\n",
      "loss: 0.004813  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007728 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.000574  [    4/  237]\n",
      "loss: 0.000750  [   84/  237]\n",
      "loss: 0.001156  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008259 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.000622  [    4/  237]\n",
      "loss: 0.000524  [   84/  237]\n",
      "loss: 0.000760  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008043 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.000766  [    4/  237]\n",
      "loss: 0.000715  [   84/  237]\n",
      "loss: 0.000406  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008267 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.000771  [    4/  237]\n",
      "loss: 0.000498  [   84/  237]\n",
      "loss: 0.021094  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007538 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.000488  [    4/  237]\n",
      "loss: 0.019124  [   84/  237]\n",
      "loss: 0.000355  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007785 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.000507  [    4/  237]\n",
      "loss: 0.000565  [   84/  237]\n",
      "loss: 0.000637  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007660 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.000760  [    4/  237]\n",
      "loss: 0.000754  [   84/  237]\n",
      "loss: 0.001282  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007737 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.000711  [    4/  237]\n",
      "loss: 0.001610  [   84/  237]\n",
      "loss: 0.000601  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007348 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.000980  [    4/  237]\n",
      "loss: 0.000755  [   84/  237]\n",
      "loss: 0.001930  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008198 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.000585  [    4/  237]\n",
      "loss: 0.000527  [   84/  237]\n",
      "loss: 0.000896  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007872 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.014787  [    4/  237]\n",
      "loss: 0.000598  [   84/  237]\n",
      "loss: 0.000614  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007970 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.000378  [    4/  237]\n",
      "loss: 0.000980  [   84/  237]\n",
      "loss: 0.002071  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008120 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.000471  [    4/  237]\n",
      "loss: 0.001708  [   84/  237]\n",
      "loss: 0.000736  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008422 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.000512  [    4/  237]\n",
      "loss: 0.001210  [   84/  237]\n",
      "loss: 0.000843  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008237 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.000709  [    4/  237]\n",
      "loss: 0.001851  [   84/  237]\n",
      "loss: 0.003767  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008250 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.018240  [    4/  237]\n",
      "loss: 0.000602  [   84/  237]\n",
      "loss: 0.001541  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008108 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.025561  [    4/  237]\n",
      "loss: 0.001069  [   84/  237]\n",
      "loss: 0.003770  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007458 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.000963  [    4/  237]\n",
      "loss: 0.000913  [   84/  237]\n",
      "loss: 0.000908  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007097 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.013537  [    4/  237]\n",
      "loss: 0.000725  [   84/  237]\n",
      "loss: 0.001114  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008215 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.000535  [    4/  237]\n",
      "loss: 0.015699  [   84/  237]\n",
      "loss: 0.000508  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008206 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.000553  [    4/  237]\n",
      "loss: 0.000729  [   84/  237]\n",
      "loss: 0.001076  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007341 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.000940  [    4/  237]\n",
      "loss: 0.000858  [   84/  237]\n",
      "loss: 0.001167  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007811 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.000724  [    4/  237]\n",
      "loss: 0.046409  [   84/  237]\n",
      "loss: 0.000567  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008087 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.000696  [    4/  237]\n",
      "loss: 0.000694  [   84/  237]\n",
      "loss: 0.000599  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007332 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.000874  [    4/  237]\n",
      "loss: 0.001021  [   84/  237]\n",
      "loss: 0.000857  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006946 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.001519  [    4/  237]\n",
      "loss: 0.000823  [   84/  237]\n",
      "loss: 0.022175  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007952 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.000834  [    4/  237]\n",
      "loss: 0.000389  [   84/  237]\n",
      "loss: 0.004435  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007134 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.001471  [    4/  237]\n",
      "loss: 0.001164  [   84/  237]\n",
      "loss: 0.001281  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007599 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.000729  [    4/  237]\n",
      "loss: 0.001013  [   84/  237]\n",
      "loss: 0.001033  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007371 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.000628  [    4/  237]\n",
      "loss: 0.001276  [   84/  237]\n",
      "loss: 0.001785  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007421 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.000767  [    4/  237]\n",
      "loss: 0.025888  [   84/  237]\n",
      "loss: 0.001422  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007345 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.003460  [    4/  237]\n",
      "loss: 0.000973  [   84/  237]\n",
      "loss: 0.000340  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008052 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.003120  [    4/  237]\n",
      "loss: 0.011663  [   84/  237]\n",
      "loss: 0.000342  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008456 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.026479  [    4/  237]\n",
      "loss: 0.000966  [   84/  237]\n",
      "loss: 0.000543  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007584 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.000514  [    4/  237]\n",
      "loss: 0.000244  [   84/  237]\n",
      "loss: 0.000816  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007617 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.000611  [    4/  237]\n",
      "loss: 0.000716  [   84/  237]\n",
      "loss: 0.000885  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007992 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.000446  [    4/  237]\n",
      "loss: 0.022861  [   84/  237]\n",
      "loss: 0.000532  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007584 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.022456  [    4/  237]\n",
      "loss: 0.000472  [   84/  237]\n",
      "loss: 0.001085  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007658 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.000410  [    4/  237]\n",
      "loss: 0.000810  [   84/  237]\n",
      "loss: 0.001720  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007611 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.001544  [    4/  237]\n",
      "loss: 0.019764  [   84/  237]\n",
      "loss: 0.001514  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008249 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.026165  [    4/  237]\n",
      "loss: 0.000401  [   84/  237]\n",
      "loss: 0.019288  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007906 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.000566  [    4/  237]\n",
      "loss: 0.000551  [   84/  237]\n",
      "loss: 0.001391  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007238 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.001253  [    4/  237]\n",
      "loss: 0.002889  [   84/  237]\n",
      "loss: 0.000673  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008129 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.000332  [    4/  237]\n",
      "loss: 0.000412  [   84/  237]\n",
      "loss: 0.001603  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007216 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.001358  [    4/  237]\n",
      "loss: 0.019584  [   84/  237]\n",
      "loss: 0.001549  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008416 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.001136  [    4/  237]\n",
      "loss: 0.000859  [   84/  237]\n",
      "loss: 0.000749  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008565 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.000683  [    4/  237]\n",
      "loss: 0.001603  [   84/  237]\n",
      "loss: 0.000333  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.009016 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.005325  [    4/  237]\n",
      "loss: 0.002754  [   84/  237]\n",
      "loss: 0.000474  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007113 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.012892  [    4/  237]\n",
      "loss: 0.045756  [   84/  237]\n",
      "loss: 0.001085  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008440 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.023603  [    4/  237]\n",
      "loss: 0.000489  [   84/  237]\n",
      "loss: 0.000626  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007138 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.000964  [    4/  237]\n",
      "loss: 0.001391  [   84/  237]\n",
      "loss: 0.000369  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007411 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.000775  [    4/  237]\n",
      "loss: 0.000968  [   84/  237]\n",
      "loss: 0.000947  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007719 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.000530  [    4/  237]\n",
      "loss: 0.001497  [   84/  237]\n",
      "loss: 0.000973  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007825 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.000442  [    4/  237]\n",
      "loss: 0.023982  [   84/  237]\n",
      "loss: 0.001308  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007724 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.000613  [    4/  237]\n",
      "loss: 0.001014  [   84/  237]\n",
      "loss: 0.001214  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007138 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.000946  [    4/  237]\n",
      "loss: 0.019690  [   84/  237]\n",
      "loss: 0.000826  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008067 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.000272  [    4/  237]\n",
      "loss: 0.000553  [   84/  237]\n",
      "loss: 0.001115  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.008737 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.000449  [    4/  237]\n",
      "loss: 0.001562  [   84/  237]\n",
      "loss: 0.001267  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008380 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.001376  [    4/  237]\n",
      "loss: 0.000984  [   84/  237]\n",
      "loss: 0.000856  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007190 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.000891  [    4/  237]\n",
      "loss: 0.001291  [   84/  237]\n",
      "loss: 0.000718  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008022 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.000355  [    4/  237]\n",
      "loss: 0.000612  [   84/  237]\n",
      "loss: 0.000714  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008023 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.000957  [    4/  237]\n",
      "loss: 0.000309  [   84/  237]\n",
      "loss: 0.000910  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007274 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.000885  [    4/  237]\n",
      "loss: 0.000353  [   84/  237]\n",
      "loss: 0.000709  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006924 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.010950  [    4/  237]\n",
      "loss: 0.000442  [   84/  237]\n",
      "loss: 0.001607  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007963 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.001618  [    4/  237]\n",
      "loss: 0.016809  [   84/  237]\n",
      "loss: 0.004401  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007603 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.001502  [    4/  237]\n",
      "loss: 0.000566  [   84/  237]\n",
      "loss: 0.001366  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008435 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.000583  [    4/  237]\n",
      "loss: 0.000599  [   84/  237]\n",
      "loss: 0.000886  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007537 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.000522  [    4/  237]\n",
      "loss: 0.000899  [   84/  237]\n",
      "loss: 0.000919  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008142 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.000426  [    4/  237]\n",
      "loss: 0.001077  [   84/  237]\n",
      "loss: 0.000707  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007940 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.018926  [    4/  237]\n",
      "loss: 0.000988  [   84/  237]\n",
      "loss: 0.000540  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007653 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.000511  [    4/  237]\n",
      "loss: 0.000845  [   84/  237]\n",
      "loss: 0.005188  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.008213 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.000269  [    4/  237]\n",
      "loss: 0.000672  [   84/  237]\n",
      "loss: 0.001032  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007794 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.020525  [    4/  237]\n",
      "loss: 0.000455  [   84/  237]\n",
      "loss: 0.001923  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007475 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.019458  [    4/  237]\n",
      "loss: 0.000315  [   84/  237]\n",
      "loss: 0.000641  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007405 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.000665  [    4/  237]\n",
      "loss: 0.001394  [   84/  237]\n",
      "loss: 0.000672  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007510 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.000612  [    4/  237]\n",
      "loss: 0.004198  [   84/  237]\n",
      "loss: 0.002058  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007264 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.000753  [    4/  237]\n",
      "loss: 0.000784  [   84/  237]\n",
      "loss: 0.000769  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007250 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.001414  [    4/  237]\n",
      "loss: 0.000839  [   84/  237]\n",
      "loss: 0.001372  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008523 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.000662  [    4/  237]\n",
      "loss: 0.000946  [   84/  237]\n",
      "loss: 0.023090  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007156 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.001024  [    4/  237]\n",
      "loss: 0.001781  [   84/  237]\n",
      "loss: 0.001643  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007985 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.000408  [    4/  237]\n",
      "loss: 0.000514  [   84/  237]\n",
      "loss: 0.001725  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007678 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.000859  [    4/  237]\n",
      "loss: 0.023678  [   84/  237]\n",
      "loss: 0.001336  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007234 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.000669  [    4/  237]\n",
      "loss: 0.018927  [   84/  237]\n",
      "loss: 0.000959  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007914 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.000596  [    4/  237]\n",
      "loss: 0.001250  [   84/  237]\n",
      "loss: 0.000595  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.007446 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.004202  [    4/  237]\n",
      "loss: 0.000891  [   84/  237]\n",
      "loss: 0.000552  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007682 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.001047  [    4/  237]\n",
      "loss: 0.004226  [   84/  237]\n",
      "loss: 0.022027  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007749 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.000437  [    4/  237]\n",
      "loss: 0.000573  [   84/  237]\n",
      "loss: 0.001804  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007239 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.000852  [    4/  237]\n",
      "loss: 0.000504  [   84/  237]\n",
      "loss: 0.000715  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007807 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.017094  [    4/  237]\n",
      "loss: 0.000934  [   84/  237]\n",
      "loss: 0.000966  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008069 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.000310  [    4/  237]\n",
      "loss: 0.000989  [   84/  237]\n",
      "loss: 0.000711  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008435 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.000435  [    4/  237]\n",
      "loss: 0.000468  [   84/  237]\n",
      "loss: 0.001835  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007466 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.001444  [    4/  237]\n",
      "loss: 0.020909  [   84/  237]\n",
      "loss: 0.061825  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007263 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.000653  [    4/  237]\n",
      "loss: 0.001749  [   84/  237]\n",
      "loss: 0.001029  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007049 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.001701  [    4/  237]\n",
      "loss: 0.001128  [   84/  237]\n",
      "loss: 0.001447  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008044 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.000470  [    4/  237]\n",
      "loss: 0.000864  [   84/  237]\n",
      "loss: 0.000842  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008349 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = training_process(SkipConnectionModel, 1e-1, 300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's unclear whether this skip connection helps a lot. On one of two tries, one train/test board accuracy curve was worse than the baseline and the test curve was very spiky; on the other try, the curves were better in that they shot up more steeply, but they still attained the same eventual upper bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LG4WithSkip(nn.Module):\n",
    "    \"\"\"Like LG4, but with skip connection.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 20, 3),               # (26, 14) -> (24, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),      # (24, 12) -> (12,  6)\n",
    "            nn.Conv2d(20, 40, 3),              # (12,  6) -> (10,  4)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(6, 3)), # ( 6,  3) -> ( 1,  1)\n",
    "        )\n",
    "        self.local_module = nn.Sequential(\n",
    "            nn.Conv2d(2, 20, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(20, 40, 3),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv0 = nn.Conv2d(80, 80, 1)\n",
    "        self.conv1 = nn.Conv2d(80, 40, 1)\n",
    "        self.conv2 = nn.Conv2d(40, 20, 1)\n",
    "        self.conv3 = nn.Conv2d(20, 10, 1)\n",
    "        self.conv4 = nn.Conv2d(10, 2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((0, 3, 1, 2)) # Move channels/classes to dimension 1\n",
    "        x_skip = x\n",
    "        x = F.pad(x, (2, 2, 2, 2)) # Zero-pad 2 cells on each side\n",
    "        x_local = self.local_module(x) # Extract local information\n",
    "        x_global = self.global_module(x) # Extract global information\n",
    "        x_global = x_global.repeat(1, 1, 22, 10) # Broadcast global information to image dimensions\n",
    "        x = torch.cat((x_local, x_global), dim=1) # Combine local and global information\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = x + (x_skip - 0.5) * 20.0\n",
    "        logits = F.log_softmax(x, dim=1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.500000  [    4/  237]\n",
      "loss: 0.456132  [   84/  237]\n",
      "loss: 0.590907  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575300 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.500000  [    4/  237]\n",
      "loss: 0.590906  [   84/  237]\n",
      "loss: 0.636362  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576260 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.590907  [    4/  237]\n",
      "loss: 0.499996  [   84/  237]\n",
      "loss: 0.545455  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.578265 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.499997  [    4/  237]\n",
      "loss: 0.545451  [   84/  237]\n",
      "loss: 0.499997  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576229 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.545452  [    4/  237]\n",
      "loss: 0.545451  [   84/  237]\n",
      "loss: 0.499999  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.578234 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.590905  [    4/  237]\n",
      "loss: 0.636356  [   84/  237]\n",
      "loss: 0.636358  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575218 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.545448  [    4/  237]\n",
      "loss: 0.545448  [   84/  237]\n",
      "loss: 0.545449  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577193 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.499995  [    4/  237]\n",
      "loss: 0.501276  [   84/  237]\n",
      "loss: 0.590901  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575185 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.681809  [    4/  237]\n",
      "loss: 0.454540  [   84/  237]\n",
      "loss: 0.636355  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575169 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.545447  [    4/  237]\n",
      "loss: 0.545447  [   84/  237]\n",
      "loss: 0.501167  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577172 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.545446  [    4/  237]\n",
      "loss: 0.499994  [   84/  237]\n",
      "loss: 0.499994  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575136 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.545445  [    4/  237]\n",
      "loss: 0.456744  [   84/  237]\n",
      "loss: 0.590898  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.578126 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.499992  [    4/  237]\n",
      "loss: 0.590899  [   84/  237]\n",
      "loss: 0.499989  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577101 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.501021  [    4/  237]\n",
      "loss: 0.501003  [   84/  237]\n",
      "loss: 0.545443  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576075 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.590896  [    4/  237]\n",
      "loss: 0.545443  [   84/  237]\n",
      "loss: 0.590898  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576060 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.455477  [    4/  237]\n",
      "loss: 0.681802  [   84/  237]\n",
      "loss: 0.636348  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577055 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.636347  [    4/  237]\n",
      "loss: 0.545440  [   84/  237]\n",
      "loss: 0.545442  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577040 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.636348  [    4/  237]\n",
      "loss: 0.545442  [   84/  237]\n",
      "loss: 0.545441  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577024 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.500799  [    4/  237]\n",
      "loss: 0.590893  [   84/  237]\n",
      "loss: 0.546225  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577026 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.499984  [    4/  237]\n",
      "loss: 0.545438  [   84/  237]\n",
      "loss: 0.409830  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576994 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.590891  [    4/  237]\n",
      "loss: 0.590890  [   84/  237]\n",
      "loss: 0.545436  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.573963 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.499984  [    4/  237]\n",
      "loss: 0.636341  [   84/  237]\n",
      "loss: 0.681794  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576963 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.545443  [    4/  237]\n",
      "loss: 0.636340  [   84/  237]\n",
      "loss: 0.499986  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574927 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.455128  [    4/  237]\n",
      "loss: 0.499983  [   84/  237]\n",
      "loss: 0.499979  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575921 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.590886  [    4/  237]\n",
      "loss: 0.590890  [   84/  237]\n",
      "loss: 0.499982  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577926 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.590884  [    4/  237]\n",
      "loss: 0.500477  [   84/  237]\n",
      "loss: 0.636338  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575901 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.545431  [    4/  237]\n",
      "loss: 0.545432  [   84/  237]\n",
      "loss: 0.545432  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575875 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.590885  [    4/  237]\n",
      "loss: 0.590883  [   84/  237]\n",
      "loss: 0.545431  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574849 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.590885  [    4/  237]\n",
      "loss: 0.636333  [   84/  237]\n",
      "loss: 0.409427  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574833 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.590883  [    4/  237]\n",
      "loss: 0.409396  [   84/  237]\n",
      "loss: 0.636330  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575834 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.636334  [    4/  237]\n",
      "loss: 0.590880  [   84/  237]\n",
      "loss: 0.636335  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577832 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.500226  [    4/  237]\n",
      "loss: 0.545426  [   84/  237]\n",
      "loss: 0.590878  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576811 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.545424  [    4/  237]\n",
      "loss: 0.590878  [   84/  237]\n",
      "loss: 0.500159  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577801 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.545422  [    4/  237]\n",
      "loss: 0.499975  [   84/  237]\n",
      "loss: 0.545568  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575765 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.545422  [    4/  237]\n",
      "loss: 0.636324  [   84/  237]\n",
      "loss: 0.454611  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577769 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.545426  [    4/  237]\n",
      "loss: 0.545418  [   84/  237]\n",
      "loss: 0.590878  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576744 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.545452  [    4/  237]\n",
      "loss: 0.545431  [   84/  237]\n",
      "loss: 0.545427  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575718 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.454518  [    4/  237]\n",
      "loss: 0.590870  [   84/  237]\n",
      "loss: 0.499923  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574691 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.590872  [    4/  237]\n",
      "loss: 0.590872  [   84/  237]\n",
      "loss: 0.499967  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577706 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.545417  [    4/  237]\n",
      "loss: 0.545422  [   84/  237]\n",
      "loss: 0.545290  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575670 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.590870  [    4/  237]\n",
      "loss: 0.545279  [   84/  237]\n",
      "loss: 0.636319  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577674 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.409060  [    4/  237]\n",
      "loss: 0.636312  [   84/  237]\n",
      "loss: 0.545409  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.578668 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.590864  [    4/  237]\n",
      "loss: 0.499716  [   84/  237]\n",
      "loss: 0.545416  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576631 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.545411  [    4/  237]\n",
      "loss: 0.590862  [   84/  237]\n",
      "loss: 0.590856  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.578635 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.408741  [    4/  237]\n",
      "loss: 0.545407  [   84/  237]\n",
      "loss: 0.454159  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576598 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.636307  [    4/  237]\n",
      "loss: 0.636301  [   84/  237]\n",
      "loss: 0.499959  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577592 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.545404  [    4/  237]\n",
      "loss: 0.590864  [   84/  237]\n",
      "loss: 0.590852  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576565 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.545409  [    4/  237]\n",
      "loss: 0.636300  [   84/  237]\n",
      "loss: 0.454027  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.578568 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.499956  [    4/  237]\n",
      "loss: 0.499453  [   84/  237]\n",
      "loss: 0.545394  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575504 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.499942  [    4/  237]\n",
      "loss: 0.590847  [   84/  237]\n",
      "loss: 0.636290  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574476 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.590843  [    4/  237]\n",
      "loss: 0.590843  [   84/  237]\n",
      "loss: 0.681734  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575482 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.545405  [    4/  237]\n",
      "loss: 0.636294  [   84/  237]\n",
      "loss: 0.499304  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576470 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.499248  [    4/  237]\n",
      "loss: 0.590843  [   84/  237]\n",
      "loss: 0.545387  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574416 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.681731  [    4/  237]\n",
      "loss: 0.545396  [   84/  237]\n",
      "loss: 0.636283  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576435 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.499142  [    4/  237]\n",
      "loss: 0.636275  [   84/  237]\n",
      "loss: 0.545395  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576417 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.499930  [    4/  237]\n",
      "loss: 0.590827  [   84/  237]\n",
      "loss: 0.499062  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576399 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.499931  [    4/  237]\n",
      "loss: 0.545374  [   84/  237]\n",
      "loss: 0.545381  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575366 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.727162  [    4/  237]\n",
      "loss: 0.545378  [   84/  237]\n",
      "loss: 0.590817  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576357 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.499937  [    4/  237]\n",
      "loss: 0.454481  [   84/  237]\n",
      "loss: 0.544352  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574318 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.545372  [    4/  237]\n",
      "loss: 0.545364  [   84/  237]\n",
      "loss: 0.545374  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576319 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.636253  [    4/  237]\n",
      "loss: 0.590804  [   84/  237]\n",
      "loss: 0.590813  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576299 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.636256  [    4/  237]\n",
      "loss: 0.498788  [   84/  237]\n",
      "loss: 0.454470  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574260 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.590804  [    4/  237]\n",
      "loss: 0.499922  [   84/  237]\n",
      "loss: 0.681682  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576260 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.636238  [    4/  237]\n",
      "loss: 0.544175  [   84/  237]\n",
      "loss: 0.681676  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575201 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.590792  [    4/  237]\n",
      "loss: 0.499908  [   84/  237]\n",
      "loss: 0.590794  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576218 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.499929  [    4/  237]\n",
      "loss: 0.499891  [   84/  237]\n",
      "loss: 0.590776  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575187 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.545345  [    4/  237]\n",
      "loss: 0.545341  [   84/  237]\n",
      "loss: 0.590781  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575165 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.590778  [    4/  237]\n",
      "loss: 0.590773  [   84/  237]\n",
      "loss: 0.499889  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577162 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.499896  [    4/  237]\n",
      "loss: 0.590753  [   84/  237]\n",
      "loss: 0.498423  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576130 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.590765  [    4/  237]\n",
      "loss: 0.543830  [   84/  237]\n",
      "loss: 0.636182  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576105 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.681609  [    4/  237]\n",
      "loss: 0.590747  [   84/  237]\n",
      "loss: 0.499861  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576081 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.452880  [    4/  237]\n",
      "loss: 0.545295  [   84/  237]\n",
      "loss: 0.499851  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575045 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.498258  [    4/  237]\n",
      "loss: 0.499840  [   84/  237]\n",
      "loss: 0.636148  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.577038 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.590730  [    4/  237]\n",
      "loss: 0.499827  [   84/  237]\n",
      "loss: 0.499850  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576000 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.590702  [    4/  237]\n",
      "loss: 0.499867  [   84/  237]\n",
      "loss: 0.545255  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574961 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.590687  [    4/  237]\n",
      "loss: 0.588935  [   84/  237]\n",
      "loss: 0.545242  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574885 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.545229  [    4/  237]\n",
      "loss: 0.636119  [   84/  237]\n",
      "loss: 0.545252  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576912 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.499792  [    4/  237]\n",
      "loss: 0.499785  [   84/  237]\n",
      "loss: 0.497882  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574859 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.590655  [    4/  237]\n",
      "loss: 0.499798  [   84/  237]\n",
      "loss: 0.499759  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576841 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.543282  [    4/  237]\n",
      "loss: 0.499775  [   84/  237]\n",
      "loss: 0.497797  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575779 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.545147  [    4/  237]\n",
      "loss: 0.635960  [   84/  237]\n",
      "loss: 0.497706  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575720 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.635932  [    4/  237]\n",
      "loss: 0.590474  [   84/  237]\n",
      "loss: 0.590488  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576677 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.454219  [    4/  237]\n",
      "loss: 0.495482  [   84/  237]\n",
      "loss: 0.590489  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574604 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.545003  [    4/  237]\n",
      "loss: 0.542948  [   84/  237]\n",
      "loss: 0.499533  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.573533 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.544970  [    4/  237]\n",
      "loss: 0.635777  [   84/  237]\n",
      "loss: 0.545013  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574425 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.454138  [    4/  237]\n",
      "loss: 0.635670  [   84/  237]\n",
      "loss: 0.454069  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574392 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.590301  [    4/  237]\n",
      "loss: 0.590202  [   84/  237]\n",
      "loss: 0.451786  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575311 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.590221  [    4/  237]\n",
      "loss: 0.499347  [   84/  237]\n",
      "loss: 0.499385  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574199 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.408590  [    4/  237]\n",
      "loss: 0.635462  [   84/  237]\n",
      "loss: 0.499272  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.576093 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.589987  [    4/  237]\n",
      "loss: 0.499221  [   84/  237]\n",
      "loss: 0.499170  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.572870 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.544548  [    4/  237]\n",
      "loss: 0.499071  [   84/  237]\n",
      "loss: 0.634963  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.574757 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.634930  [    4/  237]\n",
      "loss: 0.634873  [   84/  237]\n",
      "loss: 0.544167  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.575541 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.498708  [    4/  237]\n",
      "loss: 0.589392  [   84/  237]\n",
      "loss: 0.544011  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.573241 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.541559  [    4/  237]\n",
      "loss: 0.588874  [   84/  237]\n",
      "loss: 0.498346  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.571811 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.543405  [    4/  237]\n",
      "loss: 0.588728  [   84/  237]\n",
      "loss: 0.588347  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.572369 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.542995  [    4/  237]\n",
      "loss: 0.587902  [   84/  237]\n",
      "loss: 0.587678  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.572657 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.587422  [    4/  237]\n",
      "loss: 0.541990  [   84/  237]\n",
      "loss: 0.586517  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.570416 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.541408  [    4/  237]\n",
      "loss: 0.538638  [   84/  237]\n",
      "loss: 0.495369  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.568397 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.584142  [    4/  237]\n",
      "loss: 0.582955  [   84/  237]\n",
      "loss: 0.582076  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.566233 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.491531  [    4/  237]\n",
      "loss: 0.534069  [   84/  237]\n",
      "loss: 0.532603  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.559926 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.531568  [    4/  237]\n",
      "loss: 0.440360  [   84/  237]\n",
      "loss: 0.569229  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.549924 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: 0.475641  [    4/  237]\n",
      "loss: 0.514490  [   84/  237]\n",
      "loss: 0.499557  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Board accuracy: 0.0%, Avg loss: 0.500585 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: 0.507042  [    4/  237]\n",
      "loss: 0.395913  [   84/  237]\n",
      "loss: 0.282040  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 0.0%, Avg loss: 0.303673 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: 0.295179  [    4/  237]\n",
      "loss: 0.260233  [   84/  237]\n",
      "loss: 0.216474  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 0.0%, Avg loss: 0.294281 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: 0.235818  [    4/  237]\n",
      "loss: 0.202652  [   84/  237]\n",
      "loss: 0.266237  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.1%, Board accuracy: 0.0%, Avg loss: 0.268842 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: 0.278651  [    4/  237]\n",
      "loss: 0.290566  [   84/  237]\n",
      "loss: 0.207651  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.2%, Board accuracy: 0.0%, Avg loss: 0.242774 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: 0.203392  [    4/  237]\n",
      "loss: 0.197157  [   84/  237]\n",
      "loss: 0.128156  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.2%, Board accuracy: 28.9%, Avg loss: 0.029450 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: 0.025679  [    4/  237]\n",
      "loss: 0.022249  [   84/  237]\n",
      "loss: 0.017137  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 55.0%, Avg loss: 0.019646 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: 0.004225  [    4/  237]\n",
      "loss: 0.012048  [   84/  237]\n",
      "loss: 0.007083  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 63.9%, Avg loss: 0.016600 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: 0.021937  [    4/  237]\n",
      "loss: 0.008859  [   84/  237]\n",
      "loss: 0.003804  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 56.1%, Avg loss: 0.015780 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: 0.006979  [    4/  237]\n",
      "loss: 0.018818  [   84/  237]\n",
      "loss: 0.007626  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 77.8%, Avg loss: 0.012994 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "loss: 0.009821  [    4/  237]\n",
      "loss: 0.008587  [   84/  237]\n",
      "loss: 0.010390  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.011854 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "loss: 0.005932  [    4/  237]\n",
      "loss: 0.036545  [   84/  237]\n",
      "loss: 0.013583  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 75.6%, Avg loss: 0.012216 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "loss: 0.010746  [    4/  237]\n",
      "loss: 0.028836  [   84/  237]\n",
      "loss: 0.002723  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 78.3%, Avg loss: 0.012162 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "loss: 0.002540  [    4/  237]\n",
      "loss: 0.005215  [   84/  237]\n",
      "loss: 0.004572  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.010813 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "loss: 0.007335  [    4/  237]\n",
      "loss: 0.002953  [   84/  237]\n",
      "loss: 0.008573  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.011957 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "loss: 0.005217  [    4/  237]\n",
      "loss: 0.010072  [   84/  237]\n",
      "loss: 0.002320  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 52.2%, Avg loss: 0.012210 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "loss: 0.008340  [    4/  237]\n",
      "loss: 0.031459  [   84/  237]\n",
      "loss: 0.002929  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.010658 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "loss: 0.005193  [    4/  237]\n",
      "loss: 0.004615  [   84/  237]\n",
      "loss: 0.001298  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.009664 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "loss: 0.030118  [    4/  237]\n",
      "loss: 0.002896  [   84/  237]\n",
      "loss: 0.012337  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 80.0%, Avg loss: 0.009987 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "loss: 0.002735  [    4/  237]\n",
      "loss: 0.003887  [   84/  237]\n",
      "loss: 0.002489  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.010638 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "loss: 0.003258  [    4/  237]\n",
      "loss: 0.002014  [   84/  237]\n",
      "loss: 0.004076  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.009857 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "loss: 0.001026  [    4/  237]\n",
      "loss: 0.003271  [   84/  237]\n",
      "loss: 0.008951  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.009325 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "loss: 0.005053  [    4/  237]\n",
      "loss: 0.002063  [   84/  237]\n",
      "loss: 0.003751  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.9%, Avg loss: 0.008394 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "loss: 0.001971  [    4/  237]\n",
      "loss: 0.003964  [   84/  237]\n",
      "loss: 0.001479  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.009198 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "loss: 0.001289  [    4/  237]\n",
      "loss: 0.004477  [   84/  237]\n",
      "loss: 0.025113  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 98.7%, Board accuracy: 20.0%, Avg loss: 0.046262 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "loss: 0.095059  [    4/  237]\n",
      "loss: 0.003425  [   84/  237]\n",
      "loss: 0.007565  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.009227 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "loss: 0.001167  [    4/  237]\n",
      "loss: 0.001883  [   84/  237]\n",
      "loss: 0.005076  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 68.9%, Avg loss: 0.010088 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "loss: 0.032830  [    4/  237]\n",
      "loss: 0.006931  [   84/  237]\n",
      "loss: 0.001696  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.9%, Avg loss: 0.009116 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "loss: 0.001266  [    4/  237]\n",
      "loss: 0.000854  [   84/  237]\n",
      "loss: 0.002325  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.007831 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "loss: 0.003098  [    4/  237]\n",
      "loss: 0.001614  [   84/  237]\n",
      "loss: 0.010375  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 90.0%, Board accuracy: 0.0%, Avg loss: 0.372838 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "loss: 0.292498  [    4/  237]\n",
      "loss: 0.029921  [   84/  237]\n",
      "loss: 0.006896  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.013640 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "loss: 0.006828  [    4/  237]\n",
      "loss: 0.004581  [   84/  237]\n",
      "loss: 0.001974  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.010171 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "loss: 0.007315  [    4/  237]\n",
      "loss: 0.019170  [   84/  237]\n",
      "loss: 0.027188  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 79.4%, Avg loss: 0.009600 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "loss: 0.005893  [    4/  237]\n",
      "loss: 0.007463  [   84/  237]\n",
      "loss: 0.005367  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.3%, Avg loss: 0.009798 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "loss: 0.002714  [    4/  237]\n",
      "loss: 0.001987  [   84/  237]\n",
      "loss: 0.003753  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.008302 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "loss: 0.001487  [    4/  237]\n",
      "loss: 0.000739  [   84/  237]\n",
      "loss: 0.000951  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.008082 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "loss: 0.001986  [    4/  237]\n",
      "loss: 0.001891  [   84/  237]\n",
      "loss: 0.004960  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.007889 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "loss: 0.001321  [    4/  237]\n",
      "loss: 0.002462  [   84/  237]\n",
      "loss: 0.025430  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.007638 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "loss: 0.013900  [    4/  237]\n",
      "loss: 0.001514  [   84/  237]\n",
      "loss: 0.003433  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 83.9%, Avg loss: 0.009283 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "loss: 0.001408  [    4/  237]\n",
      "loss: 0.004003  [   84/  237]\n",
      "loss: 0.000835  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.7%, Avg loss: 0.008097 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "loss: 0.003721  [    4/  237]\n",
      "loss: 0.001214  [   84/  237]\n",
      "loss: 0.019069  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.007818 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "loss: 0.002629  [    4/  237]\n",
      "loss: 0.000517  [   84/  237]\n",
      "loss: 0.000850  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.6%, Board accuracy: 10.0%, Avg loss: 0.045506 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "loss: 0.041178  [    4/  237]\n",
      "loss: 0.000856  [   84/  237]\n",
      "loss: 0.000458  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.007149 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "loss: 0.004276  [    4/  237]\n",
      "loss: 0.013831  [   84/  237]\n",
      "loss: 0.004770  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.007490 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "loss: 0.002024  [    4/  237]\n",
      "loss: 0.000605  [   84/  237]\n",
      "loss: 0.002447  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 81.1%, Avg loss: 0.006755 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "loss: 0.001562  [    4/  237]\n",
      "loss: 0.000421  [   84/  237]\n",
      "loss: 0.007876  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 87.8%, Avg loss: 0.006452 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "loss: 0.001754  [    4/  237]\n",
      "loss: 0.011534  [   84/  237]\n",
      "loss: 0.002233  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 84.4%, Avg loss: 0.009402 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "loss: 0.000828  [    4/  237]\n",
      "loss: 0.008688  [   84/  237]\n",
      "loss: 0.001117  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 85.0%, Avg loss: 0.008639 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "loss: 0.012486  [    4/  237]\n",
      "loss: 0.017292  [   84/  237]\n",
      "loss: 0.000817  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.010170 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "loss: 0.000619  [    4/  237]\n",
      "loss: 0.001079  [   84/  237]\n",
      "loss: 0.000455  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.006923 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "loss: 0.001055  [    4/  237]\n",
      "loss: 0.001059  [   84/  237]\n",
      "loss: 0.000657  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.007923 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "loss: 0.000766  [    4/  237]\n",
      "loss: 0.001037  [   84/  237]\n",
      "loss: 0.001350  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.008567 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "loss: 0.000847  [    4/  237]\n",
      "loss: 0.001546  [   84/  237]\n",
      "loss: 0.001551  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.006645 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "loss: 0.000369  [    4/  237]\n",
      "loss: 0.000911  [   84/  237]\n",
      "loss: 0.001647  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.008498 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "loss: 0.004320  [    4/  237]\n",
      "loss: 0.002115  [   84/  237]\n",
      "loss: 0.000218  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.007469 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "loss: 0.000289  [    4/  237]\n",
      "loss: 0.000172  [   84/  237]\n",
      "loss: 0.001181  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.005537 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "loss: 0.003502  [    4/  237]\n",
      "loss: 0.000538  [   84/  237]\n",
      "loss: 0.000419  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 82.8%, Avg loss: 0.006159 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "loss: 0.006185  [    4/  237]\n",
      "loss: 0.012326  [   84/  237]\n",
      "loss: 0.008481  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.007190 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "loss: 0.013619  [    4/  237]\n",
      "loss: 0.002320  [   84/  237]\n",
      "loss: 0.000733  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.006086 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "loss: 0.000145  [    4/  237]\n",
      "loss: 0.000437  [   84/  237]\n",
      "loss: 0.000755  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.007861 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "loss: 0.000098  [    4/  237]\n",
      "loss: 0.001934  [   84/  237]\n",
      "loss: 0.018040  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.007231 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "loss: 0.000133  [    4/  237]\n",
      "loss: 0.001834  [   84/  237]\n",
      "loss: 0.000882  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.006391 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "loss: 0.016656  [    4/  237]\n",
      "loss: 0.000251  [   84/  237]\n",
      "loss: 0.001694  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.007893 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "loss: 0.000326  [    4/  237]\n",
      "loss: 0.000908  [   84/  237]\n",
      "loss: 0.001568  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.005636 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "loss: 0.000871  [    4/  237]\n",
      "loss: 0.000339  [   84/  237]\n",
      "loss: 0.000094  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.006119 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "loss: 0.000935  [    4/  237]\n",
      "loss: 0.013041  [   84/  237]\n",
      "loss: 0.001717  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.007286 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "loss: 0.000276  [    4/  237]\n",
      "loss: 0.000655  [   84/  237]\n",
      "loss: 0.000114  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.005215 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "loss: 0.012190  [    4/  237]\n",
      "loss: 0.004234  [   84/  237]\n",
      "loss: 0.005235  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.008165 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "loss: 0.004941  [    4/  237]\n",
      "loss: 0.012489  [   84/  237]\n",
      "loss: 0.000309  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.006029 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "loss: 0.011203  [    4/  237]\n",
      "loss: 0.000958  [   84/  237]\n",
      "loss: 0.001385  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.005183 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "loss: 0.000220  [    4/  237]\n",
      "loss: 0.004522  [   84/  237]\n",
      "loss: 0.000267  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006726 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "loss: 0.000368  [    4/  237]\n",
      "loss: 0.014351  [   84/  237]\n",
      "loss: 0.001155  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.005112 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "loss: 0.001942  [    4/  237]\n",
      "loss: 0.016326  [   84/  237]\n",
      "loss: 0.000212  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.005258 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "loss: 0.000168  [    4/  237]\n",
      "loss: 0.000161  [   84/  237]\n",
      "loss: 0.004647  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 88.3%, Avg loss: 0.005111 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "loss: 0.004024  [    4/  237]\n",
      "loss: 0.000091  [   84/  237]\n",
      "loss: 0.000279  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 96.5%, Board accuracy: 8.3%, Avg loss: 0.065542 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "loss: 0.046855  [    4/  237]\n",
      "loss: 0.000219  [   84/  237]\n",
      "loss: 0.001887  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.005980 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "loss: 0.000542  [    4/  237]\n",
      "loss: 0.000094  [   84/  237]\n",
      "loss: 0.001058  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006497 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "loss: 0.000166  [    4/  237]\n",
      "loss: 0.000082  [   84/  237]\n",
      "loss: 0.001408  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.005548 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "loss: 0.000300  [    4/  237]\n",
      "loss: 0.000065  [   84/  237]\n",
      "loss: 0.007864  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005640 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "loss: 0.000160  [    4/  237]\n",
      "loss: 0.000245  [   84/  237]\n",
      "loss: 0.013971  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005593 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "loss: 0.000131  [    4/  237]\n",
      "loss: 0.001068  [   84/  237]\n",
      "loss: 0.001216  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.006508 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "loss: 0.000113  [    4/  237]\n",
      "loss: 0.000351  [   84/  237]\n",
      "loss: 0.000349  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.012201 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "loss: 0.022080  [    4/  237]\n",
      "loss: 0.000247  [   84/  237]\n",
      "loss: 0.000063  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.006833 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "loss: 0.000082  [    4/  237]\n",
      "loss: 0.000536  [   84/  237]\n",
      "loss: 0.000167  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.7%, Board accuracy: 86.7%, Avg loss: 0.009288 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "loss: 0.001992  [    4/  237]\n",
      "loss: 0.000072  [   84/  237]\n",
      "loss: 0.000225  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 97.8%, Board accuracy: 21.7%, Avg loss: 0.041426 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "loss: 0.069377  [    4/  237]\n",
      "loss: 0.014573  [   84/  237]\n",
      "loss: 0.001892  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005533 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "loss: 0.001808  [    4/  237]\n",
      "loss: 0.001067  [   84/  237]\n",
      "loss: 0.000293  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005369 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "loss: 0.011209  [    4/  237]\n",
      "loss: 0.000075  [   84/  237]\n",
      "loss: 0.000374  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005188 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "loss: 0.000538  [    4/  237]\n",
      "loss: 0.000310  [   84/  237]\n",
      "loss: 0.001968  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.007037 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "loss: 0.000472  [    4/  237]\n",
      "loss: 0.000196  [   84/  237]\n",
      "loss: 0.000059  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.005245 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "loss: 0.000220  [    4/  237]\n",
      "loss: 0.000261  [   84/  237]\n",
      "loss: 0.000162  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005273 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "loss: 0.000116  [    4/  237]\n",
      "loss: 0.000388  [   84/  237]\n",
      "loss: 0.003063  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005520 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "loss: 0.000185  [    4/  237]\n",
      "loss: 0.003429  [   84/  237]\n",
      "loss: 0.000083  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005907 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "loss: 0.000294  [    4/  237]\n",
      "loss: 0.000096  [   84/  237]\n",
      "loss: 0.007877  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007621 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "loss: 0.000167  [    4/  237]\n",
      "loss: 0.000943  [   84/  237]\n",
      "loss: 0.000742  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005825 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "loss: 0.000067  [    4/  237]\n",
      "loss: 0.000038  [   84/  237]\n",
      "loss: 0.000288  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005610 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "loss: 0.001374  [    4/  237]\n",
      "loss: 0.013562  [   84/  237]\n",
      "loss: 0.000374  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005159 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "loss: 0.000420  [    4/  237]\n",
      "loss: 0.000394  [   84/  237]\n",
      "loss: 0.000145  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005827 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "loss: 0.000283  [    4/  237]\n",
      "loss: 0.000287  [   84/  237]\n",
      "loss: 0.000016  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.007246 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "loss: 0.000360  [    4/  237]\n",
      "loss: 0.000461  [   84/  237]\n",
      "loss: 0.001065  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005607 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "loss: 0.001689  [    4/  237]\n",
      "loss: 0.000564  [   84/  237]\n",
      "loss: 0.007638  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.7%, Avg loss: 0.012683 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "loss: 0.000732  [    4/  237]\n",
      "loss: 0.000103  [   84/  237]\n",
      "loss: 0.000543  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006115 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "loss: 0.000170  [    4/  237]\n",
      "loss: 0.000274  [   84/  237]\n",
      "loss: 0.006105  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005937 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "loss: 0.013515  [    4/  237]\n",
      "loss: 0.009945  [   84/  237]\n",
      "loss: 0.000678  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005614 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "loss: 0.000230  [    4/  237]\n",
      "loss: 0.001726  [   84/  237]\n",
      "loss: 0.000117  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.007003 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "loss: 0.000210  [    4/  237]\n",
      "loss: 0.000117  [   84/  237]\n",
      "loss: 0.001183  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.007374 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "loss: 0.000526  [    4/  237]\n",
      "loss: 0.012062  [   84/  237]\n",
      "loss: 0.007028  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005385 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "loss: 0.000067  [    4/  237]\n",
      "loss: 0.000398  [   84/  237]\n",
      "loss: 0.000143  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 86.1%, Avg loss: 0.008791 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "loss: 0.019338  [    4/  237]\n",
      "loss: 0.000075  [   84/  237]\n",
      "loss: 0.009423  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005955 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "loss: 0.000041  [    4/  237]\n",
      "loss: 0.000043  [   84/  237]\n",
      "loss: 0.000204  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006033 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "loss: 0.000064  [    4/  237]\n",
      "loss: 0.000141  [   84/  237]\n",
      "loss: 0.000769  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005582 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "loss: 0.000035  [    4/  237]\n",
      "loss: 0.000177  [   84/  237]\n",
      "loss: 0.006336  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005510 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "loss: 0.000221  [    4/  237]\n",
      "loss: 0.008424  [   84/  237]\n",
      "loss: 0.018975  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005170 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "loss: 0.000063  [    4/  237]\n",
      "loss: 0.000995  [   84/  237]\n",
      "loss: 0.010594  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005779 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "loss: 0.000284  [    4/  237]\n",
      "loss: 0.000137  [   84/  237]\n",
      "loss: 0.000618  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005332 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "loss: 0.000163  [    4/  237]\n",
      "loss: 0.000141  [   84/  237]\n",
      "loss: 0.000126  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005085 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "loss: 0.011050  [    4/  237]\n",
      "loss: 0.000599  [   84/  237]\n",
      "loss: 0.000078  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 86.1%, Avg loss: 0.005348 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "loss: 0.000095  [    4/  237]\n",
      "loss: 0.000170  [   84/  237]\n",
      "loss: 0.000867  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006542 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "loss: 0.000887  [    4/  237]\n",
      "loss: 0.000942  [   84/  237]\n",
      "loss: 0.000059  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005951 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "loss: 0.010094  [    4/  237]\n",
      "loss: 0.000132  [   84/  237]\n",
      "loss: 0.000064  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007050 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "loss: 0.000041  [    4/  237]\n",
      "loss: 0.000195  [   84/  237]\n",
      "loss: 0.000041  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.006926 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "loss: 0.010192  [    4/  237]\n",
      "loss: 0.000199  [   84/  237]\n",
      "loss: 0.000330  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005412 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "loss: 0.002157  [    4/  237]\n",
      "loss: 0.000032  [   84/  237]\n",
      "loss: 0.000055  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.004903 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "loss: 0.000031  [    4/  237]\n",
      "loss: 0.000035  [   84/  237]\n",
      "loss: 0.001836  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005253 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "loss: 0.000160  [    4/  237]\n",
      "loss: 0.000199  [   84/  237]\n",
      "loss: 0.000290  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005267 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "loss: 0.000292  [    4/  237]\n",
      "loss: 0.000295  [   84/  237]\n",
      "loss: 0.010928  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006765 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "loss: 0.001454  [    4/  237]\n",
      "loss: 0.001516  [   84/  237]\n",
      "loss: 0.000121  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 95.6%, Board accuracy: 0.0%, Avg loss: 0.147783 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "loss: 0.109379  [    4/  237]\n",
      "loss: 0.010274  [   84/  237]\n",
      "loss: 0.000055  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005032 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "loss: 0.000149  [    4/  237]\n",
      "loss: 0.000422  [   84/  237]\n",
      "loss: 0.000168  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005247 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "loss: 0.000037  [    4/  237]\n",
      "loss: 0.006583  [   84/  237]\n",
      "loss: 0.000053  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005592 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "loss: 0.000196  [    4/  237]\n",
      "loss: 0.001483  [   84/  237]\n",
      "loss: 0.010868  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006592 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "loss: 0.009380  [    4/  237]\n",
      "loss: 0.000706  [   84/  237]\n",
      "loss: 0.000099  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006533 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "loss: 0.000097  [    4/  237]\n",
      "loss: 0.000057  [   84/  237]\n",
      "loss: 0.000018  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005455 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "loss: 0.001634  [    4/  237]\n",
      "loss: 0.000092  [   84/  237]\n",
      "loss: 0.009593  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005272 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "loss: 0.000164  [    4/  237]\n",
      "loss: 0.000167  [   84/  237]\n",
      "loss: 0.007970  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005943 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "loss: 0.000445  [    4/  237]\n",
      "loss: 0.000041  [   84/  237]\n",
      "loss: 0.000029  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005459 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "loss: 0.000128  [    4/  237]\n",
      "loss: 0.000199  [   84/  237]\n",
      "loss: 0.010592  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005294 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "loss: 0.000170  [    4/  237]\n",
      "loss: 0.000027  [   84/  237]\n",
      "loss: 0.001390  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005613 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "loss: 0.015570  [    4/  237]\n",
      "loss: 0.000714  [   84/  237]\n",
      "loss: 0.000047  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007023 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "loss: 0.000087  [    4/  237]\n",
      "loss: 0.000082  [   84/  237]\n",
      "loss: 0.004858  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005795 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "loss: 0.000147  [    4/  237]\n",
      "loss: 0.007228  [   84/  237]\n",
      "loss: 0.000159  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005524 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "loss: 0.001699  [    4/  237]\n",
      "loss: 0.000264  [   84/  237]\n",
      "loss: 0.000086  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.010257 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "loss: 0.000117  [    4/  237]\n",
      "loss: 0.000020  [   84/  237]\n",
      "loss: 0.000013  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005077 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "loss: 0.000114  [    4/  237]\n",
      "loss: 0.000110  [   84/  237]\n",
      "loss: 0.001449  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005820 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "loss: 0.000158  [    4/  237]\n",
      "loss: 0.000005  [   84/  237]\n",
      "loss: 0.000019  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.007824 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "loss: 0.000106  [    4/  237]\n",
      "loss: 0.000012  [   84/  237]\n",
      "loss: 0.000095  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.012983 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "loss: 0.000108  [    4/  237]\n",
      "loss: 0.015986  [   84/  237]\n",
      "loss: 0.001084  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.007209 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "loss: 0.000019  [    4/  237]\n",
      "loss: 0.000803  [   84/  237]\n",
      "loss: 0.000078  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006368 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "loss: 0.000180  [    4/  237]\n",
      "loss: 0.000072  [   84/  237]\n",
      "loss: 0.000088  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005089 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "loss: 0.000124  [    4/  237]\n",
      "loss: 0.000058  [   84/  237]\n",
      "loss: 0.000178  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005084 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "loss: 0.000124  [    4/  237]\n",
      "loss: 0.000032  [   84/  237]\n",
      "loss: 0.001816  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.6%, Board accuracy: 85.0%, Avg loss: 0.010713 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "loss: 0.013840  [    4/  237]\n",
      "loss: 0.000149  [   84/  237]\n",
      "loss: 0.003781  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 89.4%, Avg loss: 0.005790 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "loss: 0.000028  [    4/  237]\n",
      "loss: 0.000039  [   84/  237]\n",
      "loss: 0.000059  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005892 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "loss: 0.000050  [    4/  237]\n",
      "loss: 0.000036  [   84/  237]\n",
      "loss: 0.000150  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005230 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "loss: 0.000021  [    4/  237]\n",
      "loss: 0.000036  [   84/  237]\n",
      "loss: 0.000220  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005881 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "loss: 0.000189  [    4/  237]\n",
      "loss: 0.000132  [   84/  237]\n",
      "loss: 0.000028  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005612 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "loss: 0.004885  [    4/  237]\n",
      "loss: 0.000595  [   84/  237]\n",
      "loss: 0.000054  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.007086 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "loss: 0.010615  [    4/  237]\n",
      "loss: 0.001444  [   84/  237]\n",
      "loss: 0.000166  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.008961 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "loss: 0.000062  [    4/  237]\n",
      "loss: 0.005118  [   84/  237]\n",
      "loss: 0.000024  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005613 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "loss: 0.010220  [    4/  237]\n",
      "loss: 0.000018  [   84/  237]\n",
      "loss: 0.000090  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005241 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "loss: 0.000142  [    4/  237]\n",
      "loss: 0.000030  [   84/  237]\n",
      "loss: 0.000545  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.008533 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "loss: 0.000102  [    4/  237]\n",
      "loss: 0.009628  [   84/  237]\n",
      "loss: 0.000072  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005301 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "loss: 0.000451  [    4/  237]\n",
      "loss: 0.000019  [   84/  237]\n",
      "loss: 0.000078  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006927 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "loss: 0.000026  [    4/  237]\n",
      "loss: 0.000006  [   84/  237]\n",
      "loss: 0.000732  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006903 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "loss: 0.000085  [    4/  237]\n",
      "loss: 0.000022  [   84/  237]\n",
      "loss: 0.000281  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005612 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "loss: 0.000026  [    4/  237]\n",
      "loss: 0.000449  [   84/  237]\n",
      "loss: 0.000782  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005285 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "loss: 0.000093  [    4/  237]\n",
      "loss: 0.000018  [   84/  237]\n",
      "loss: 0.000106  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006784 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "loss: 0.000014  [    4/  237]\n",
      "loss: 0.000404  [   84/  237]\n",
      "loss: 0.000029  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005782 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "loss: 0.000964  [    4/  237]\n",
      "loss: 0.010905  [   84/  237]\n",
      "loss: 0.000058  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005766 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "loss: 0.000161  [    4/  237]\n",
      "loss: 0.000142  [   84/  237]\n",
      "loss: 0.010600  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005569 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "loss: 0.000026  [    4/  237]\n",
      "loss: 0.001469  [   84/  237]\n",
      "loss: 0.009112  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005850 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "loss: 0.000043  [    4/  237]\n",
      "loss: 0.000375  [   84/  237]\n",
      "loss: 0.006718  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.009494 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "loss: 0.000013  [    4/  237]\n",
      "loss: 0.000131  [   84/  237]\n",
      "loss: 0.009261  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005506 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "loss: 0.000007  [    4/  237]\n",
      "loss: 0.000082  [   84/  237]\n",
      "loss: 0.000068  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005883 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "loss: 0.000005  [    4/  237]\n",
      "loss: 0.000114  [   84/  237]\n",
      "loss: 0.000229  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006371 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "loss: 0.000218  [    4/  237]\n",
      "loss: 0.000013  [   84/  237]\n",
      "loss: 0.000165  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006510 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "loss: 0.000404  [    4/  237]\n",
      "loss: 0.000023  [   84/  237]\n",
      "loss: 0.009514  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005719 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "loss: 0.000034  [    4/  237]\n",
      "loss: 0.000199  [   84/  237]\n",
      "loss: 0.000025  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005304 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "loss: 0.000037  [    4/  237]\n",
      "loss: 0.000045  [   84/  237]\n",
      "loss: 0.000342  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005247 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "loss: 0.005480  [    4/  237]\n",
      "loss: 0.000072  [   84/  237]\n",
      "loss: 0.006886  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005757 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "loss: 0.007044  [    4/  237]\n",
      "loss: 0.000051  [   84/  237]\n",
      "loss: 0.007517  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006010 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "loss: 0.004037  [    4/  237]\n",
      "loss: 0.000026  [   84/  237]\n",
      "loss: 0.000012  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005898 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "loss: 0.000035  [    4/  237]\n",
      "loss: 0.000219  [   84/  237]\n",
      "loss: 0.000038  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005650 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "loss: 0.001328  [    4/  237]\n",
      "loss: 0.000058  [   84/  237]\n",
      "loss: 0.001226  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005732 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "loss: 0.010406  [    4/  237]\n",
      "loss: 0.000026  [   84/  237]\n",
      "loss: 0.001387  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005703 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "loss: 0.009427  [    4/  237]\n",
      "loss: 0.000009  [   84/  237]\n",
      "loss: 0.001560  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.5%, Board accuracy: 82.8%, Avg loss: 0.014828 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "loss: 0.051874  [    4/  237]\n",
      "loss: 0.000068  [   84/  237]\n",
      "loss: 0.000033  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005689 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "loss: 0.000116  [    4/  237]\n",
      "loss: 0.000301  [   84/  237]\n",
      "loss: 0.000052  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005391 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "loss: 0.000023  [    4/  237]\n",
      "loss: 0.000065  [   84/  237]\n",
      "loss: 0.000031  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.0%, Avg loss: 0.005403 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "loss: 0.000245  [    4/  237]\n",
      "loss: 0.000350  [   84/  237]\n",
      "loss: 0.000878  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005497 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "loss: 0.000049  [    4/  237]\n",
      "loss: 0.000142  [   84/  237]\n",
      "loss: 0.000039  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.006478 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "loss: 0.000031  [    4/  237]\n",
      "loss: 0.000025  [   84/  237]\n",
      "loss: 0.000016  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005807 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "loss: 0.009114  [    4/  237]\n",
      "loss: 0.003676  [   84/  237]\n",
      "loss: 0.000477  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006092 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "loss: 0.000389  [    4/  237]\n",
      "loss: 0.000063  [   84/  237]\n",
      "loss: 0.000013  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 90.6%, Avg loss: 0.006460 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "loss: 0.000477  [    4/  237]\n",
      "loss: 0.000150  [   84/  237]\n",
      "loss: 0.004060  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.1%, Avg loss: 0.005796 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "loss: 0.000068  [    4/  237]\n",
      "loss: 0.000108  [   84/  237]\n",
      "loss: 0.000017  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.006025 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "loss: 0.000112  [    4/  237]\n",
      "loss: 0.000000  [   84/  237]\n",
      "loss: 0.000101  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005440 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "loss: 0.000013  [    4/  237]\n",
      "loss: 0.000158  [   84/  237]\n",
      "loss: 0.010527  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005639 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "loss: 0.000009  [    4/  237]\n",
      "loss: 0.000044  [   84/  237]\n",
      "loss: 0.000217  [  164/  237]\n",
      "Test Error: \n",
      " Accuracy: 99.8%, Board accuracy: 91.7%, Avg loss: 0.005846 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model = training_process(LG4WithSkip, 1e-1, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
