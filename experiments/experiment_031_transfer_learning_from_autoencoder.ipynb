{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 031\n",
    "\n",
    "In this experiment, we will train the GameGAN model but using transfer learning from the autoencoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from models import TetrisModel, TetrisDiscriminator, GameganAutoencoder\n",
    "import metrics\n",
    "from recording import FileBasedDatabaseWithEvents\n",
    "from engines import EVENT_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CELL_TYPES = 8\n",
    "NUM_EVENT_TYPES = 5\n",
    "\n",
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self._db = FileBasedDatabaseWithEvents(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._db)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        boards, events = self._db[idx]\n",
    "        b = self._transform_board(boards[-2]) # Ignore all boards except the last two\n",
    "        e = self._transform_event(events[-1])\n",
    "        x = (b, e)\n",
    "        y = self._transform_board(boards[-1])\n",
    "        return x, y\n",
    "    \n",
    "    def _transform_board(self, board):\n",
    "        board = torch.tensor(board, dtype=torch.long)\n",
    "        board = F.one_hot(board, NUM_CELL_TYPES) # One-hot encode the cell types\n",
    "        board = board.type(torch.float) # Convert to floating-point\n",
    "        board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "        return board\n",
    "    \n",
    "    def _transform_event(self, event):\n",
    "        event = torch.tensor(event, dtype=torch.long)\n",
    "        event = F.one_hot(event, NUM_EVENT_TYPES) # One-hot encode the event\n",
    "        event = event.type(torch.float) # Convert to floating-point\n",
    "        return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: shape torch.Size([12, 8, 22, 10]), dtype torch.float32\n",
      "e: shape torch.Size([12, 5]), dtype torch.float32\n",
      "y: shape torch.Size([12, 8, 22, 10]), dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Put datasets in memory for faster training\n",
    "train_dataset = list(RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\")))\n",
    "test_dataset = list(RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\")))\n",
    "batch_size = 12\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "(b, e), y = next(iter(train_dataloader))\n",
    "print(f\"x: shape {b.shape}, dtype {b.dtype}\")\n",
    "print(f\"e: shape {e.shape}, dtype {e.dtype}\")\n",
    "print(f\"y: shape {y.shape}, dtype {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_by_event(metric_cls, dataloader):\n",
    "    metrics = [metric_cls() for _ in range(NUM_EVENT_TYPES)]\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        for ((b, e), y) in dataloader:\n",
    "            b = b.to(device)\n",
    "            e = e.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            batch_size = b.size(0)\n",
    "\n",
    "            y_fake = gen(b, e)\n",
    "            \n",
    "            classes_b = torch.argmax(b, dim=1)\n",
    "            classes_e = torch.argmax(e, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "\n",
    "            for idx in range(batch_size):\n",
    "                class_e = classes_e[idx]\n",
    "                metric = metrics[class_e]\n",
    "                metric.update_state(classes_x=classes_b[idx:idx+1], classes_y_pred=classes_y_fake[idx:idx+1], classes_y=classes_y[idx:idx+1])\n",
    "\n",
    "    return [metric.result() for metric in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.10.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from engines import EventTypes\n",
    "\n",
    "def find_interesting_examples(dataset, num=3):\n",
    "    num_spawns = num\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "\n",
    "        for (b, e), y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (e.argmax(0).item() == EventTypes.DROP) & (b.argmax(0)[0] == 0).all() & (y.argmax(0)[0] > 0).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield (b, e), y\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))\n",
    "from tetris import CELL_COLORS\n",
    "\n",
    "def render_board(board):\n",
    "    height, width = board.shape\n",
    "    img = np.zeros((3, height, width))\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            img[:, row, col] = CELL_COLORS[board[row, col]]\n",
    "    img /= 255.0\n",
    "    return img\n",
    "def render_prediction(b, e, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        b: Tensor of shape (height, width), the initial board state.\n",
    "        e: Tensor of shape (1,), the event type.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the next board state.\n",
    "    \"\"\"\n",
    "    assert len(b.shape) == 2, f\"Expected tensors of shape (width, height) but got {b.shape}\"\n",
    "    assert b.shape == pred.shape, f\"Shapes do not match: {b.shape} != {pred.shape}\"\n",
    "    assert b.shape == y.shape, f\"Shapes do not match: {b.shape} != {y.shape}\"\n",
    "    assert len(e.shape) == 0, f\"Expected e of shape () but got {e.shape}\"\n",
    "    height, width = b.shape\n",
    "    with torch.no_grad():\n",
    "        b = render_board(b)\n",
    "        pred = render_board(pred)\n",
    "        y = render_board(y)\n",
    "        separator = np.ones((3, height, 1))\n",
    "        return np.concatenate((b, separator, pred, separator, y), axis=-1)\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, ((b, e), y) in enumerate(dataloader):\n",
    "        b = b.to(device)\n",
    "        e = e.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        batch_size = b.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(b, e, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(b, e)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(b, e, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(b, e, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 30 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = metrics.CellAccuracy()\n",
    "    board_accuracy = metrics.BoardAccuracy()\n",
    "    spawn_recall = metrics.SpawnRecall()\n",
    "    scores_real = np.zeros(len(dataloader.dataset))\n",
    "    scores_fake = np.zeros(len(dataloader.dataset))\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for batch, ((b, e), y) in enumerate(dataloader):\n",
    "            b = b.to(device)\n",
    "            e = e.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            batch_size = b.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(b, e, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            y_fake = gen(b, e)\n",
    "            output_fake = disc(b, e, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_b = torch.argmax(b, dim=1)\n",
    "            classes_e = torch.argmax(e, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy.update_state(classes_y_fake, classes_y)\n",
    "            board_accuracy.update_state(classes_y_fake, classes_y)\n",
    "\n",
    "            spawn_recall.update_state(classes_b, classes_y_fake, classes_y)\n",
    "\n",
    "            start_index = dataloader.batch_size * batch\n",
    "            end_index = start_index + batch_size\n",
    "            scores_real[start_index:end_index] = torch.sigmoid(output_real).cpu().numpy()\n",
    "            scores_fake[start_index:end_index] = torch.sigmoid(output_fake).cpu().numpy()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(cell_accuracy.result()):>0.1%}, board accuracy: {(board_accuracy.result()):>0.1%} \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall.result(), epoch)\n",
    "\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/real\", scores_real, epoch)\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/fake\", scores_fake, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name, gen_factory, disc_factory, epochs):\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    gen = gen_factory()\n",
    "    disc = disc_factory()\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_031\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "            train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "            test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch)\n",
    "            test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch)\n",
    "            gen_zero_grads = 0\n",
    "            for name, weight in gen.named_parameters():\n",
    "                tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "                if weight.grad is not None:\n",
    "                    tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "                    gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "            tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "            disc_zero_grads = 0\n",
    "            for name, weight in disc.named_parameters():\n",
    "                tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "                if weight.grad is not None:\n",
    "                    tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "                    disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "            tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "    finally:\n",
    "        tb_writer.close()\n",
    "        \n",
    "    print(\"Done!\")\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 590280\n",
      "Baseline: 19682\n"
     ]
    }
   ],
   "source": [
    "NUM_RANDOM_INPUTS = 4\n",
    "\n",
    "\n",
    "from models import Conv2dLeakyReLU, ConvTranspose2dLeakyReLU, LinearLeakyReLU\n",
    "\n",
    "\n",
    "class AltGenerator(nn.Module):\n",
    "    def __init__(self, autoencoder, use_batch_norm=False, leak=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.leak = leak\n",
    "\n",
    "        self.board_encoder = autoencoder.board_encoder\n",
    "\n",
    "        self.event_encoder = nn.Sequential(\n",
    "            LinearLeakyReLU(NUM_EVENT_TYPES + NUM_RANDOM_INPUTS, 32, negative_slope=leak),\n",
    "            LinearLeakyReLU(32, 32, negative_slope=leak),\n",
    "            LinearLeakyReLU(32, 32, negative_slope=leak),\n",
    "        )\n",
    "\n",
    "        self.dynamics = nn.Sequential(\n",
    "            LinearLeakyReLU(256 + 32, 256, negative_slope=leak),\n",
    "            LinearLeakyReLU(256, 256, negative_slope=leak),\n",
    "            LinearLeakyReLU(256, 256, negative_slope=leak),\n",
    "        )\n",
    "\n",
    "        self.renderer = autoencoder.renderer\n",
    "\n",
    "    def forward(self, b, e):\n",
    "        batch_size, cell_channels, height, width = b.shape\n",
    "\n",
    "        # Encode board state\n",
    "        s = self.board_encoder(b)\n",
    "\n",
    "        # Generate random inputs\n",
    "        z = torch.rand(batch_size, NUM_RANDOM_INPUTS, device=device)\n",
    "\n",
    "        # Encode events and random inputs\n",
    "        v = self.event_encoder(torch.cat((e, z), dim=1))\n",
    "\n",
    "        # Combine encodings\n",
    "        h = torch.cat((s, v), dim=1)\n",
    "\n",
    "        # Apply game dynamics\n",
    "        h = self.dynamics(h)\n",
    "\n",
    "        # Render new board\n",
    "        y = self.renderer(h)\n",
    "        return y\n",
    "\n",
    "\n",
    "autoencoder = GameganAutoencoder()\n",
    "autoencoder.load_state_dict(torch.load(\"gamegan_autoencoder.pth\"))\n",
    "# autoencoder.requires_grad_(False)\n",
    "\n",
    "print(f\"Parameters: {count_parameters(AltGenerator(autoencoder))}\")\n",
    "print(f\"Baseline: {count_parameters(TetrisModel())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 51329\n",
      "Baseline: 9505\n"
     ]
    }
   ],
   "source": [
    "class AltDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            Conv2dLeakyReLU(2 * NUM_CELL_TYPES + NUM_EVENT_TYPES, 32, kernel_size=3),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            LinearLeakyReLU(416, 32),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Flatten(start_dim=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, b, e, y):\n",
    "        batch_size, cell_channels, height, width = b.shape\n",
    "\n",
    "        # Upscale events to board size\n",
    "        e = e[:, :, None, None].repeat(1, 1, height, width)\n",
    "\n",
    "        # Combine cells, events and random inputs\n",
    "        x = torch.cat((b, e, y), dim=1)\n",
    "\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "print(f\"Parameters: {count_parameters(AltDiscriminator())}\")\n",
    "print(f\"Baseline: {count_parameters(TetrisDiscriminator())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.4174, G loss: 0.8463\n",
      "[372/8000] D loss: 1.3894, G loss: 0.6684\n",
      "[732/8000] D loss: 1.3681, G loss: 0.7081\n",
      "[1092/8000] D loss: 1.3533, G loss: 0.7253\n",
      "[1452/8000] D loss: 1.3232, G loss: 0.7464\n",
      "[1812/8000] D loss: 1.2600, G loss: 0.7991\n",
      "[2172/8000] D loss: 1.1501, G loss: 0.8412\n",
      "[2532/8000] D loss: 1.3346, G loss: 0.6841\n",
      "[2892/8000] D loss: 1.0843, G loss: 0.8938\n",
      "[3252/8000] D loss: 1.2829, G loss: 0.8342\n",
      "[3612/8000] D loss: 1.0379, G loss: 0.9606\n",
      "[3972/8000] D loss: 1.1591, G loss: 1.2135\n",
      "[4332/8000] D loss: 1.0818, G loss: 1.0494\n",
      "[4692/8000] D loss: 1.1271, G loss: 1.2460\n",
      "[5052/8000] D loss: 1.3187, G loss: 0.8285\n",
      "[5412/8000] D loss: 0.9409, G loss: 1.2325\n",
      "[5772/8000] D loss: 0.7630, G loss: 1.2513\n",
      "[6132/8000] D loss: 1.4690, G loss: 1.3789\n",
      "[6492/8000] D loss: 0.6416, G loss: 1.9375\n",
      "[6852/8000] D loss: 1.1616, G loss: 1.5263\n",
      "[7212/8000] D loss: 1.0568, G loss: 0.8177\n",
      "[7572/8000] D loss: 1.2470, G loss: 1.2133\n",
      "[7932/8000] D loss: 1.0914, G loss: 1.5400\n",
      "train error: \n",
      " D loss: 0.846447, G loss: 1.429321, D accuracy: 79.5%, cell accuracy: 71.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.861570, G loss: 1.399041, D accuracy: 79.0%, cell accuracy: 72.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0227, G loss: 1.7180\n",
      "[372/8000] D loss: 0.8507, G loss: 1.3103\n",
      "[732/8000] D loss: 0.7510, G loss: 1.5873\n",
      "[1092/8000] D loss: 0.5525, G loss: 2.0275\n",
      "[1452/8000] D loss: 0.5866, G loss: 2.3663\n",
      "[1812/8000] D loss: 0.6780, G loss: 1.4506\n",
      "[2172/8000] D loss: 0.2372, G loss: 2.3833\n",
      "[2532/8000] D loss: 0.4025, G loss: 2.1501\n",
      "[2892/8000] D loss: 0.4821, G loss: 2.4441\n",
      "[3252/8000] D loss: 0.8284, G loss: 2.3438\n",
      "[3612/8000] D loss: 0.6258, G loss: 2.1060\n",
      "[3972/8000] D loss: 0.4216, G loss: 2.2429\n",
      "[4332/8000] D loss: 0.3485, G loss: 2.8945\n",
      "[4692/8000] D loss: 0.8468, G loss: 1.9412\n",
      "[5052/8000] D loss: 0.7145, G loss: 1.7685\n",
      "[5412/8000] D loss: 0.2663, G loss: 3.4093\n",
      "[5772/8000] D loss: 0.2249, G loss: 3.6764\n",
      "[6132/8000] D loss: 0.4329, G loss: 1.9636\n",
      "[6492/8000] D loss: 0.1799, G loss: 3.5362\n",
      "[6852/8000] D loss: 0.4403, G loss: 2.7910\n",
      "[7212/8000] D loss: 0.6283, G loss: 2.3538\n",
      "[7572/8000] D loss: 0.2649, G loss: 4.5188\n",
      "[7932/8000] D loss: 0.5645, G loss: 2.7943\n",
      "train error: \n",
      " D loss: 0.511713, G loss: 3.875789, D accuracy: 87.6%, cell accuracy: 75.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.533142, G loss: 3.822828, D accuracy: 87.2%, cell accuracy: 75.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6252, G loss: 3.3441\n",
      "[372/8000] D loss: 0.2702, G loss: 4.0468\n",
      "[732/8000] D loss: 0.1721, G loss: 4.1772\n",
      "[1092/8000] D loss: 0.2826, G loss: 3.2456\n",
      "[1452/8000] D loss: 0.3668, G loss: 4.1163\n",
      "[1812/8000] D loss: 0.3992, G loss: 2.2704\n",
      "[2172/8000] D loss: 0.2794, G loss: 3.4881\n",
      "[2532/8000] D loss: 0.3600, G loss: 3.3519\n",
      "[2892/8000] D loss: 0.3466, G loss: 2.8437\n",
      "[3252/8000] D loss: 0.1231, G loss: 4.3760\n",
      "[3612/8000] D loss: 0.3390, G loss: 4.4215\n",
      "[3972/8000] D loss: 0.6936, G loss: 2.9889\n",
      "[4332/8000] D loss: 0.3760, G loss: 3.8270\n",
      "[4692/8000] D loss: 0.5625, G loss: 3.4010\n",
      "[5052/8000] D loss: 0.5990, G loss: 3.2135\n",
      "[5412/8000] D loss: 0.8492, G loss: 2.3841\n",
      "[5772/8000] D loss: 0.4144, G loss: 2.7529\n",
      "[6132/8000] D loss: 0.3446, G loss: 4.2679\n",
      "[6492/8000] D loss: 0.5530, G loss: 2.3743\n",
      "[6852/8000] D loss: 0.5989, G loss: 2.1173\n",
      "[7212/8000] D loss: 0.4763, G loss: 2.3762\n",
      "[7572/8000] D loss: 0.8834, G loss: 1.9541\n",
      "[7932/8000] D loss: 0.4736, G loss: 2.0639\n",
      "train error: \n",
      " D loss: 0.636304, G loss: 2.111193, D accuracy: 86.6%, cell accuracy: 85.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658802, G loss: 2.194511, D accuracy: 86.1%, cell accuracy: 85.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5878, G loss: 2.2474\n",
      "[372/8000] D loss: 0.9414, G loss: 1.3325\n",
      "[732/8000] D loss: 0.5795, G loss: 3.3858\n",
      "[1092/8000] D loss: 1.5288, G loss: 3.1861\n",
      "[1452/8000] D loss: 0.6484, G loss: 2.3630\n",
      "[1812/8000] D loss: 0.5910, G loss: 3.3185\n",
      "[2172/8000] D loss: 0.4243, G loss: 4.2804\n",
      "[2532/8000] D loss: 0.3904, G loss: 2.3310\n",
      "[2892/8000] D loss: 0.6936, G loss: 2.9570\n",
      "[3252/8000] D loss: 0.4363, G loss: 2.6712\n",
      "[3612/8000] D loss: 0.7055, G loss: 1.9742\n",
      "[3972/8000] D loss: 0.6170, G loss: 2.4379\n",
      "[4332/8000] D loss: 0.2980, G loss: 3.4017\n",
      "[4692/8000] D loss: 0.7052, G loss: 2.3948\n",
      "[5052/8000] D loss: 1.0373, G loss: 3.8510\n",
      "[5412/8000] D loss: 0.8342, G loss: 1.9437\n",
      "[5772/8000] D loss: 0.5644, G loss: 2.9530\n",
      "[6132/8000] D loss: 0.6317, G loss: 2.6868\n",
      "[6492/8000] D loss: 0.6200, G loss: 2.2233\n",
      "[6852/8000] D loss: 0.8407, G loss: 1.7129\n",
      "[7212/8000] D loss: 0.6529, G loss: 2.4546\n",
      "[7572/8000] D loss: 0.6192, G loss: 1.9625\n",
      "[7932/8000] D loss: 0.3834, G loss: 2.6114\n",
      "train error: \n",
      " D loss: 0.654915, G loss: 2.260771, D accuracy: 88.4%, cell accuracy: 88.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.671966, G loss: 2.336553, D accuracy: 88.2%, cell accuracy: 87.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7728, G loss: 2.1600\n",
      "[372/8000] D loss: 0.6308, G loss: 3.4316\n",
      "[732/8000] D loss: 0.5026, G loss: 2.6587\n",
      "[1092/8000] D loss: 0.7646, G loss: 1.4418\n",
      "[1452/8000] D loss: 1.1139, G loss: 1.4810\n",
      "[1812/8000] D loss: 1.0502, G loss: 1.5154\n",
      "[2172/8000] D loss: 0.4426, G loss: 2.2648\n",
      "[2532/8000] D loss: 0.6831, G loss: 2.4585\n",
      "[2892/8000] D loss: 0.6583, G loss: 1.5395\n",
      "[3252/8000] D loss: 0.5166, G loss: 2.2035\n",
      "[3612/8000] D loss: 0.5088, G loss: 2.1377\n",
      "[3972/8000] D loss: 0.7447, G loss: 2.0553\n",
      "[4332/8000] D loss: 0.5325, G loss: 2.0072\n",
      "[4692/8000] D loss: 0.5869, G loss: 1.8606\n",
      "[5052/8000] D loss: 0.7005, G loss: 1.3571\n",
      "[5412/8000] D loss: 0.6917, G loss: 1.3819\n",
      "[5772/8000] D loss: 0.4969, G loss: 2.3536\n",
      "[6132/8000] D loss: 0.5889, G loss: 1.8578\n",
      "[6492/8000] D loss: 0.5107, G loss: 2.5686\n",
      "[6852/8000] D loss: 0.3488, G loss: 2.4302\n",
      "[7212/8000] D loss: 0.7684, G loss: 1.9128\n",
      "[7572/8000] D loss: 0.7384, G loss: 2.1571\n",
      "[7932/8000] D loss: 0.9021, G loss: 2.3559\n",
      "train error: \n",
      " D loss: 0.702670, G loss: 1.964830, D accuracy: 86.8%, cell accuracy: 90.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.722551, G loss: 2.023602, D accuracy: 86.7%, cell accuracy: 90.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5626, G loss: 3.1220\n",
      "[372/8000] D loss: 0.8770, G loss: 2.3193\n",
      "[732/8000] D loss: 0.8228, G loss: 1.7954\n",
      "[1092/8000] D loss: 0.6964, G loss: 1.7620\n",
      "[1452/8000] D loss: 0.6303, G loss: 1.9271\n",
      "[1812/8000] D loss: 0.6845, G loss: 2.3822\n",
      "[2172/8000] D loss: 0.6980, G loss: 1.4824\n",
      "[2532/8000] D loss: 1.1110, G loss: 2.2490\n",
      "[2892/8000] D loss: 0.8759, G loss: 2.4206\n",
      "[3252/8000] D loss: 0.8899, G loss: 1.3714\n",
      "[3612/8000] D loss: 0.7561, G loss: 1.7833\n",
      "[3972/8000] D loss: 0.5092, G loss: 1.7955\n",
      "[4332/8000] D loss: 0.6155, G loss: 1.8618\n",
      "[4692/8000] D loss: 0.8888, G loss: 1.5560\n",
      "[5052/8000] D loss: 0.5546, G loss: 2.9560\n",
      "[5412/8000] D loss: 0.5803, G loss: 2.2573\n",
      "[5772/8000] D loss: 1.3828, G loss: 2.0495\n",
      "[6132/8000] D loss: 0.5468, G loss: 1.8203\n",
      "[6492/8000] D loss: 0.7735, G loss: 1.9599\n",
      "[6852/8000] D loss: 1.1573, G loss: 1.7015\n",
      "[7212/8000] D loss: 1.0423, G loss: 2.0309\n",
      "[7572/8000] D loss: 0.8442, G loss: 1.9078\n",
      "[7932/8000] D loss: 0.6398, G loss: 1.7322\n",
      "train error: \n",
      " D loss: 0.878550, G loss: 1.411752, D accuracy: 79.7%, cell accuracy: 91.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.865572, G loss: 1.505916, D accuracy: 80.7%, cell accuracy: 91.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6833, G loss: 1.1043\n",
      "[372/8000] D loss: 0.8259, G loss: 1.6470\n",
      "[732/8000] D loss: 0.8032, G loss: 1.7782\n",
      "[1092/8000] D loss: 0.5484, G loss: 1.7154\n",
      "[1452/8000] D loss: 0.8054, G loss: 1.7435\n",
      "[1812/8000] D loss: 0.8576, G loss: 1.3832\n",
      "[2172/8000] D loss: 1.1091, G loss: 1.2380\n",
      "[2532/8000] D loss: 0.6986, G loss: 1.9786\n",
      "[2892/8000] D loss: 0.8261, G loss: 2.7913\n",
      "[3252/8000] D loss: 0.8066, G loss: 1.9044\n",
      "[3612/8000] D loss: 0.8753, G loss: 1.9633\n",
      "[3972/8000] D loss: 0.7833, G loss: 1.5459\n",
      "[4332/8000] D loss: 0.9938, G loss: 2.0730\n",
      "[4692/8000] D loss: 1.1786, G loss: 2.0737\n",
      "[5052/8000] D loss: 0.9312, G loss: 1.5918\n",
      "[5412/8000] D loss: 1.4549, G loss: 0.9860\n",
      "[5772/8000] D loss: 0.8767, G loss: 1.0628\n",
      "[6132/8000] D loss: 1.1453, G loss: 1.9264\n",
      "[6492/8000] D loss: 0.8944, G loss: 1.7505\n",
      "[6852/8000] D loss: 0.6391, G loss: 1.7000\n",
      "[7212/8000] D loss: 1.1424, G loss: 2.0590\n",
      "[7572/8000] D loss: 0.9085, G loss: 1.8335\n",
      "[7932/8000] D loss: 0.7941, G loss: 1.4804\n",
      "train error: \n",
      " D loss: 0.878778, G loss: 1.564882, D accuracy: 81.9%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.885990, G loss: 1.666748, D accuracy: 81.1%, cell accuracy: 93.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7349, G loss: 1.3978\n",
      "[372/8000] D loss: 1.0418, G loss: 1.7036\n",
      "[732/8000] D loss: 0.9626, G loss: 1.7682\n",
      "[1092/8000] D loss: 0.6111, G loss: 1.4244\n",
      "[1452/8000] D loss: 1.1768, G loss: 2.5200\n",
      "[1812/8000] D loss: 0.5256, G loss: 1.5328\n",
      "[2172/8000] D loss: 0.8023, G loss: 1.4855\n",
      "[2532/8000] D loss: 0.9741, G loss: 1.3523\n",
      "[2892/8000] D loss: 1.1063, G loss: 1.3010\n",
      "[3252/8000] D loss: 0.8781, G loss: 1.7008\n",
      "[3612/8000] D loss: 0.7274, G loss: 2.0724\n",
      "[3972/8000] D loss: 1.1973, G loss: 2.0296\n",
      "[4332/8000] D loss: 0.7885, G loss: 1.4759\n",
      "[4692/8000] D loss: 0.9089, G loss: 1.5759\n",
      "[5052/8000] D loss: 1.1428, G loss: 1.5100\n",
      "[5412/8000] D loss: 0.8572, G loss: 1.9133\n",
      "[5772/8000] D loss: 0.6924, G loss: 1.2087\n",
      "[6132/8000] D loss: 0.6588, G loss: 1.6086\n",
      "[6492/8000] D loss: 0.9110, G loss: 1.6649\n",
      "[6852/8000] D loss: 0.8572, G loss: 1.2719\n",
      "[7212/8000] D loss: 1.0748, G loss: 1.5620\n",
      "[7572/8000] D loss: 1.1008, G loss: 1.0749\n",
      "[7932/8000] D loss: 1.2277, G loss: 1.2130\n",
      "train error: \n",
      " D loss: 0.873095, G loss: 1.381936, D accuracy: 81.3%, cell accuracy: 93.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.871645, G loss: 1.491623, D accuracy: 81.0%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6466, G loss: 1.8572\n",
      "[372/8000] D loss: 0.7724, G loss: 1.7289\n",
      "[732/8000] D loss: 0.7030, G loss: 1.3015\n",
      "[1092/8000] D loss: 0.8296, G loss: 1.3454\n",
      "[1452/8000] D loss: 0.5942, G loss: 1.8821\n",
      "[1812/8000] D loss: 0.5341, G loss: 1.9007\n",
      "[2172/8000] D loss: 0.7988, G loss: 2.2529\n",
      "[2532/8000] D loss: 1.0143, G loss: 1.6807\n",
      "[2892/8000] D loss: 1.0258, G loss: 1.9342\n",
      "[3252/8000] D loss: 1.1584, G loss: 1.1854\n",
      "[3612/8000] D loss: 0.6307, G loss: 2.0404\n",
      "[3972/8000] D loss: 1.3203, G loss: 0.9195\n",
      "[4332/8000] D loss: 1.0201, G loss: 1.2194\n",
      "[4692/8000] D loss: 0.9882, G loss: 1.2570\n",
      "[5052/8000] D loss: 0.9432, G loss: 0.7418\n",
      "[5412/8000] D loss: 0.9368, G loss: 2.4233\n",
      "[5772/8000] D loss: 1.2689, G loss: 0.8724\n",
      "[6132/8000] D loss: 0.9578, G loss: 1.6234\n",
      "[6492/8000] D loss: 0.7334, G loss: 2.0125\n",
      "[6852/8000] D loss: 1.5189, G loss: 1.8977\n",
      "[7212/8000] D loss: 0.8177, G loss: 2.0080\n",
      "[7572/8000] D loss: 0.7700, G loss: 1.5603\n",
      "[7932/8000] D loss: 0.5777, G loss: 2.1220\n",
      "train error: \n",
      " D loss: 0.875414, G loss: 1.899796, D accuracy: 79.5%, cell accuracy: 94.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.875443, G loss: 2.015897, D accuracy: 79.2%, cell accuracy: 94.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7494, G loss: 2.4934\n",
      "[372/8000] D loss: 0.7000, G loss: 1.4181\n",
      "[732/8000] D loss: 0.9690, G loss: 2.0228\n",
      "[1092/8000] D loss: 1.1608, G loss: 1.0549\n",
      "[1452/8000] D loss: 0.8278, G loss: 1.3961\n",
      "[1812/8000] D loss: 0.9294, G loss: 1.5312\n",
      "[2172/8000] D loss: 0.9068, G loss: 1.0208\n",
      "[2532/8000] D loss: 1.0159, G loss: 1.6130\n",
      "[2892/8000] D loss: 0.8099, G loss: 1.3391\n",
      "[3252/8000] D loss: 0.8381, G loss: 1.9009\n",
      "[3612/8000] D loss: 0.7198, G loss: 1.6221\n",
      "[3972/8000] D loss: 0.7383, G loss: 1.9985\n",
      "[4332/8000] D loss: 0.8526, G loss: 1.5035\n",
      "[4692/8000] D loss: 0.6878, G loss: 1.5101\n",
      "[5052/8000] D loss: 0.8853, G loss: 1.6395\n",
      "[5412/8000] D loss: 1.2175, G loss: 2.3131\n",
      "[5772/8000] D loss: 0.6591, G loss: 1.7463\n",
      "[6132/8000] D loss: 1.0695, G loss: 1.5899\n",
      "[6492/8000] D loss: 0.8818, G loss: 1.5560\n",
      "[6852/8000] D loss: 0.7410, G loss: 2.1940\n",
      "[7212/8000] D loss: 0.7876, G loss: 1.7495\n",
      "[7572/8000] D loss: 0.7777, G loss: 1.9224\n",
      "[7932/8000] D loss: 0.7285, G loss: 2.2213\n",
      "train error: \n",
      " D loss: 0.827264, G loss: 1.457853, D accuracy: 81.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.789570, G loss: 1.605341, D accuracy: 82.4%, cell accuracy: 94.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6663, G loss: 1.8704\n",
      "[372/8000] D loss: 0.7338, G loss: 2.1280\n",
      "[732/8000] D loss: 0.8109, G loss: 1.4196\n",
      "[1092/8000] D loss: 0.6599, G loss: 1.3239\n",
      "[1452/8000] D loss: 0.7718, G loss: 2.0047\n",
      "[1812/8000] D loss: 0.5966, G loss: 1.6142\n",
      "[2172/8000] D loss: 1.1299, G loss: 1.9265\n",
      "[2532/8000] D loss: 0.9562, G loss: 2.4970\n",
      "[2892/8000] D loss: 0.5760, G loss: 2.5629\n",
      "[3252/8000] D loss: 0.7308, G loss: 2.1341\n",
      "[3612/8000] D loss: 0.8366, G loss: 1.7149\n",
      "[3972/8000] D loss: 0.8776, G loss: 2.6654\n",
      "[4332/8000] D loss: 0.9930, G loss: 2.0269\n",
      "[4692/8000] D loss: 0.7713, G loss: 1.3586\n",
      "[5052/8000] D loss: 0.5514, G loss: 2.6026\n",
      "[5412/8000] D loss: 1.1255, G loss: 1.5693\n",
      "[5772/8000] D loss: 0.8212, G loss: 2.0171\n",
      "[6132/8000] D loss: 0.8038, G loss: 2.1619\n",
      "[6492/8000] D loss: 1.0805, G loss: 1.1131\n",
      "[6852/8000] D loss: 0.5070, G loss: 1.3259\n",
      "[7212/8000] D loss: 0.6277, G loss: 2.7389\n",
      "[7572/8000] D loss: 0.9857, G loss: 1.5448\n",
      "[7932/8000] D loss: 0.6370, G loss: 1.7963\n",
      "train error: \n",
      " D loss: 0.892416, G loss: 2.122868, D accuracy: 76.8%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.879564, G loss: 2.282736, D accuracy: 77.2%, cell accuracy: 94.9%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0114, G loss: 1.9421\n",
      "[372/8000] D loss: 1.2356, G loss: 2.0396\n",
      "[732/8000] D loss: 0.6934, G loss: 1.9582\n",
      "[1092/8000] D loss: 0.7677, G loss: 1.1141\n",
      "[1452/8000] D loss: 0.6452, G loss: 2.0973\n",
      "[1812/8000] D loss: 0.7117, G loss: 1.1809\n",
      "[2172/8000] D loss: 1.0663, G loss: 1.6791\n",
      "[2532/8000] D loss: 0.9001, G loss: 1.9010\n",
      "[2892/8000] D loss: 0.7900, G loss: 2.7035\n",
      "[3252/8000] D loss: 1.2655, G loss: 1.1593\n",
      "[3612/8000] D loss: 0.5356, G loss: 2.3955\n",
      "[3972/8000] D loss: 0.7373, G loss: 2.1842\n",
      "[4332/8000] D loss: 0.9251, G loss: 2.3865\n",
      "[4692/8000] D loss: 0.6855, G loss: 2.3764\n",
      "[5052/8000] D loss: 0.6518, G loss: 2.7396\n",
      "[5412/8000] D loss: 1.0164, G loss: 2.9389\n",
      "[5772/8000] D loss: 1.1632, G loss: 1.1910\n",
      "[6132/8000] D loss: 1.1883, G loss: 2.3167\n",
      "[6492/8000] D loss: 0.8275, G loss: 1.6386\n",
      "[6852/8000] D loss: 1.2623, G loss: 1.4778\n",
      "[7212/8000] D loss: 0.6732, G loss: 2.2456\n",
      "[7572/8000] D loss: 0.6521, G loss: 1.8578\n",
      "[7932/8000] D loss: 0.8725, G loss: 2.2505\n",
      "train error: \n",
      " D loss: 0.859354, G loss: 1.620652, D accuracy: 80.4%, cell accuracy: 95.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.802223, G loss: 1.829694, D accuracy: 82.5%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7165, G loss: 1.7975\n",
      "[372/8000] D loss: 1.0934, G loss: 1.2992\n",
      "[732/8000] D loss: 0.8909, G loss: 1.2955\n",
      "[1092/8000] D loss: 0.5539, G loss: 2.9443\n",
      "[1452/8000] D loss: 1.3543, G loss: 2.3191\n",
      "[1812/8000] D loss: 1.0244, G loss: 0.9895\n",
      "[2172/8000] D loss: 0.7761, G loss: 1.8283\n",
      "[2532/8000] D loss: 0.5887, G loss: 2.6438\n",
      "[2892/8000] D loss: 0.8856, G loss: 1.7226\n",
      "[3252/8000] D loss: 0.5615, G loss: 1.8527\n",
      "[3612/8000] D loss: 0.9768, G loss: 3.2153\n",
      "[3972/8000] D loss: 1.2725, G loss: 0.8588\n",
      "[4332/8000] D loss: 0.7170, G loss: 1.5172\n",
      "[4692/8000] D loss: 0.8832, G loss: 1.6552\n",
      "[5052/8000] D loss: 1.1079, G loss: 1.9417\n",
      "[5412/8000] D loss: 0.7932, G loss: 1.6743\n",
      "[5772/8000] D loss: 1.1035, G loss: 1.0385\n",
      "[6132/8000] D loss: 0.7891, G loss: 2.3215\n",
      "[6492/8000] D loss: 0.8998, G loss: 1.6167\n",
      "[6852/8000] D loss: 0.8311, G loss: 2.6527\n",
      "[7212/8000] D loss: 0.6715, G loss: 2.2883\n",
      "[7572/8000] D loss: 0.7824, G loss: 1.7301\n",
      "[7932/8000] D loss: 0.7190, G loss: 2.8625\n",
      "train error: \n",
      " D loss: 0.970429, G loss: 1.225406, D accuracy: 76.2%, cell accuracy: 95.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.868982, G loss: 1.444546, D accuracy: 79.6%, cell accuracy: 95.3%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2092, G loss: 1.3947\n",
      "[372/8000] D loss: 1.2299, G loss: 1.6121\n",
      "[732/8000] D loss: 1.0666, G loss: 1.0665\n",
      "[1092/8000] D loss: 0.7098, G loss: 2.3962\n",
      "[1452/8000] D loss: 0.7744, G loss: 1.7256\n",
      "[1812/8000] D loss: 1.0219, G loss: 1.1759\n",
      "[2172/8000] D loss: 0.6147, G loss: 2.3389\n",
      "[2532/8000] D loss: 0.6548, G loss: 1.8745\n",
      "[2892/8000] D loss: 0.9552, G loss: 1.2756\n",
      "[3252/8000] D loss: 0.7371, G loss: 2.4253\n",
      "[3612/8000] D loss: 1.1074, G loss: 1.3950\n",
      "[3972/8000] D loss: 0.6216, G loss: 2.5620\n",
      "[4332/8000] D loss: 0.8273, G loss: 1.0588\n",
      "[4692/8000] D loss: 0.8860, G loss: 1.0555\n",
      "[5052/8000] D loss: 0.7352, G loss: 2.5840\n",
      "[5412/8000] D loss: 0.6367, G loss: 1.8154\n",
      "[5772/8000] D loss: 0.7952, G loss: 2.1002\n",
      "[6132/8000] D loss: 0.6599, G loss: 2.2398\n",
      "[6492/8000] D loss: 0.7407, G loss: 1.5695\n",
      "[6852/8000] D loss: 0.7580, G loss: 1.3822\n",
      "[7212/8000] D loss: 0.7071, G loss: 2.7951\n",
      "[7572/8000] D loss: 0.8302, G loss: 2.1783\n",
      "[7932/8000] D loss: 0.6635, G loss: 2.0262\n",
      "train error: \n",
      " D loss: 0.928025, G loss: 1.331565, D accuracy: 76.6%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.847635, G loss: 1.546260, D accuracy: 79.4%, cell accuracy: 95.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8383, G loss: 1.9426\n",
      "[372/8000] D loss: 0.7892, G loss: 1.8071\n",
      "[732/8000] D loss: 0.6427, G loss: 1.8965\n",
      "[1092/8000] D loss: 0.5431, G loss: 2.0179\n",
      "[1452/8000] D loss: 0.8912, G loss: 2.1493\n",
      "[1812/8000] D loss: 0.7260, G loss: 1.9076\n",
      "[2172/8000] D loss: 0.7594, G loss: 2.0572\n",
      "[2532/8000] D loss: 0.8074, G loss: 1.7891\n",
      "[2892/8000] D loss: 0.8431, G loss: 1.9367\n",
      "[3252/8000] D loss: 0.8992, G loss: 1.4905\n",
      "[3612/8000] D loss: 1.0443, G loss: 1.5649\n",
      "[3972/8000] D loss: 0.6214, G loss: 1.8863\n",
      "[4332/8000] D loss: 0.8051, G loss: 1.6161\n",
      "[4692/8000] D loss: 0.7614, G loss: 1.8117\n",
      "[5052/8000] D loss: 0.9964, G loss: 1.8967\n",
      "[5412/8000] D loss: 0.9459, G loss: 1.8949\n",
      "[5772/8000] D loss: 1.3420, G loss: 1.0286\n",
      "[6132/8000] D loss: 0.4975, G loss: 2.6446\n",
      "[6492/8000] D loss: 0.5828, G loss: 1.8163\n",
      "[6852/8000] D loss: 0.7931, G loss: 1.7824\n",
      "[7212/8000] D loss: 0.6236, G loss: 1.4671\n",
      "[7572/8000] D loss: 0.8664, G loss: 1.7886\n",
      "[7932/8000] D loss: 0.8182, G loss: 1.8547\n",
      "train error: \n",
      " D loss: 0.954135, G loss: 1.236643, D accuracy: 76.0%, cell accuracy: 95.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.862052, G loss: 1.491776, D accuracy: 80.2%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9106, G loss: 1.1434\n",
      "[372/8000] D loss: 0.7359, G loss: 1.6647\n",
      "[732/8000] D loss: 0.9786, G loss: 2.2007\n",
      "[1092/8000] D loss: 0.9328, G loss: 0.9376\n",
      "[1452/8000] D loss: 0.8244, G loss: 1.4727\n",
      "[1812/8000] D loss: 0.9766, G loss: 1.3778\n",
      "[2172/8000] D loss: 1.0489, G loss: 1.0573\n",
      "[2532/8000] D loss: 0.8126, G loss: 2.6831\n",
      "[2892/8000] D loss: 0.8790, G loss: 2.4334\n",
      "[3252/8000] D loss: 0.7709, G loss: 1.7046\n",
      "[3612/8000] D loss: 0.8726, G loss: 1.4868\n",
      "[3972/8000] D loss: 0.7250, G loss: 2.0558\n",
      "[4332/8000] D loss: 1.1143, G loss: 1.0150\n",
      "[4692/8000] D loss: 1.2497, G loss: 1.2749\n",
      "[5052/8000] D loss: 0.6916, G loss: 1.5133\n",
      "[5412/8000] D loss: 0.7513, G loss: 1.6995\n",
      "[5772/8000] D loss: 0.5253, G loss: 1.8383\n",
      "[6132/8000] D loss: 0.8290, G loss: 1.8717\n",
      "[6492/8000] D loss: 0.8402, G loss: 1.6830\n",
      "[6852/8000] D loss: 0.9414, G loss: 2.0155\n",
      "[7212/8000] D loss: 0.8358, G loss: 2.2373\n",
      "[7572/8000] D loss: 0.6638, G loss: 1.8889\n",
      "[7932/8000] D loss: 0.7417, G loss: 2.1035\n",
      "train error: \n",
      " D loss: 0.815570, G loss: 2.040008, D accuracy: 81.6%, cell accuracy: 95.9%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.793604, G loss: 2.333113, D accuracy: 82.3%, cell accuracy: 95.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9021, G loss: 1.8155\n",
      "[372/8000] D loss: 0.7417, G loss: 2.3311\n",
      "[732/8000] D loss: 0.7657, G loss: 2.6596\n",
      "[1092/8000] D loss: 1.1166, G loss: 1.7614\n",
      "[1452/8000] D loss: 0.6388, G loss: 2.3061\n",
      "[1812/8000] D loss: 0.8584, G loss: 1.5923\n",
      "[2172/8000] D loss: 0.6410, G loss: 2.2758\n",
      "[2532/8000] D loss: 0.7459, G loss: 2.0588\n",
      "[2892/8000] D loss: 0.7954, G loss: 2.2255\n",
      "[3252/8000] D loss: 0.6798, G loss: 2.2121\n",
      "[3612/8000] D loss: 0.6582, G loss: 2.7436\n",
      "[3972/8000] D loss: 0.8417, G loss: 1.7149\n",
      "[4332/8000] D loss: 0.8726, G loss: 1.7846\n",
      "[4692/8000] D loss: 0.7154, G loss: 2.2292\n",
      "[5052/8000] D loss: 0.9305, G loss: 2.0208\n",
      "[5412/8000] D loss: 0.7500, G loss: 1.4121\n",
      "[5772/8000] D loss: 0.6190, G loss: 1.6529\n",
      "[6132/8000] D loss: 0.8646, G loss: 1.5936\n",
      "[6492/8000] D loss: 0.8418, G loss: 2.7653\n",
      "[6852/8000] D loss: 0.6498, G loss: 2.6456\n",
      "[7212/8000] D loss: 0.7596, G loss: 1.4115\n",
      "[7572/8000] D loss: 0.5373, G loss: 1.5989\n",
      "[7932/8000] D loss: 0.5791, G loss: 2.3212\n",
      "train error: \n",
      " D loss: 0.784745, G loss: 1.637858, D accuracy: 82.4%, cell accuracy: 96.1%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.713648, G loss: 1.968468, D accuracy: 84.7%, cell accuracy: 95.8%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9056, G loss: 1.6173\n",
      "[372/8000] D loss: 0.8896, G loss: 1.8147\n",
      "[732/8000] D loss: 0.8791, G loss: 1.2811\n",
      "[1092/8000] D loss: 0.7309, G loss: 1.9375\n",
      "[1452/8000] D loss: 1.0069, G loss: 1.8059\n",
      "[1812/8000] D loss: 0.6217, G loss: 2.1347\n",
      "[2172/8000] D loss: 0.6999, G loss: 2.6505\n",
      "[2532/8000] D loss: 0.7207, G loss: 1.8236\n",
      "[2892/8000] D loss: 0.9292, G loss: 1.7707\n",
      "[3252/8000] D loss: 0.8991, G loss: 1.6223\n",
      "[3612/8000] D loss: 0.6564, G loss: 1.8473\n",
      "[3972/8000] D loss: 0.5867, G loss: 1.9651\n",
      "[4332/8000] D loss: 0.7453, G loss: 2.0260\n",
      "[4692/8000] D loss: 0.9282, G loss: 2.4496\n",
      "[5052/8000] D loss: 0.7399, G loss: 2.8017\n",
      "[5412/8000] D loss: 1.0812, G loss: 1.0627\n",
      "[5772/8000] D loss: 0.4574, G loss: 2.2344\n",
      "[6132/8000] D loss: 0.8861, G loss: 2.0380\n",
      "[6492/8000] D loss: 0.7217, G loss: 2.6192\n",
      "[6852/8000] D loss: 0.3324, G loss: 2.9204\n",
      "[7212/8000] D loss: 0.5572, G loss: 2.4094\n",
      "[7572/8000] D loss: 0.5572, G loss: 2.1501\n",
      "[7932/8000] D loss: 0.4220, G loss: 2.3612\n",
      "train error: \n",
      " D loss: 0.771153, G loss: 1.795996, D accuracy: 82.5%, cell accuracy: 96.2%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.689493, G loss: 2.202152, D accuracy: 85.6%, cell accuracy: 95.9%, board accuracy: 0.3% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8854, G loss: 1.2467\n",
      "[372/8000] D loss: 0.8291, G loss: 3.3025\n",
      "[732/8000] D loss: 0.7934, G loss: 2.0776\n",
      "[1092/8000] D loss: 0.8307, G loss: 1.8284\n",
      "[1452/8000] D loss: 0.4775, G loss: 2.7581\n",
      "[1812/8000] D loss: 0.6943, G loss: 1.4109\n",
      "[2172/8000] D loss: 1.3832, G loss: 1.1302\n",
      "[2532/8000] D loss: 0.5865, G loss: 2.2700\n",
      "[2892/8000] D loss: 0.6405, G loss: 4.3903\n",
      "[3252/8000] D loss: 0.6389, G loss: 2.0006\n",
      "[3612/8000] D loss: 0.9923, G loss: 1.7715\n",
      "[3972/8000] D loss: 0.6518, G loss: 2.1531\n",
      "[4332/8000] D loss: 1.2229, G loss: 1.3838\n",
      "[4692/8000] D loss: 1.1487, G loss: 1.5052\n",
      "[5052/8000] D loss: 0.5928, G loss: 2.7897\n",
      "[5412/8000] D loss: 0.5920, G loss: 2.5234\n",
      "[5772/8000] D loss: 0.8259, G loss: 1.3057\n",
      "[6132/8000] D loss: 0.8821, G loss: 2.0408\n",
      "[6492/8000] D loss: 0.7378, G loss: 2.0815\n",
      "[6852/8000] D loss: 0.9179, G loss: 2.3208\n",
      "[7212/8000] D loss: 0.7449, G loss: 2.3576\n",
      "[7572/8000] D loss: 0.7075, G loss: 3.4452\n",
      "[7932/8000] D loss: 0.7559, G loss: 2.4063\n",
      "train error: \n",
      " D loss: 0.842755, G loss: 3.035321, D accuracy: 78.8%, cell accuracy: 96.1%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.836222, G loss: 3.464584, D accuracy: 79.2%, cell accuracy: 95.8%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9749, G loss: 2.6472\n",
      "[372/8000] D loss: 0.9293, G loss: 1.1194\n",
      "[732/8000] D loss: 0.4519, G loss: 2.8967\n",
      "[1092/8000] D loss: 1.1658, G loss: 1.7787\n",
      "[1452/8000] D loss: 0.8059, G loss: 2.3829\n",
      "[1812/8000] D loss: 0.6163, G loss: 2.2840\n",
      "[2172/8000] D loss: 0.7111, G loss: 1.8180\n",
      "[2532/8000] D loss: 0.6218, G loss: 2.0980\n",
      "[2892/8000] D loss: 0.6654, G loss: 1.9645\n",
      "[3252/8000] D loss: 1.1261, G loss: 3.5026\n",
      "[3612/8000] D loss: 0.4334, G loss: 1.8432\n",
      "[3972/8000] D loss: 0.8501, G loss: 2.5158\n",
      "[4332/8000] D loss: 0.7697, G loss: 2.1355\n",
      "[4692/8000] D loss: 0.6849, G loss: 1.5255\n",
      "[5052/8000] D loss: 0.5789, G loss: 2.0630\n",
      "[5412/8000] D loss: 0.4354, G loss: 2.4610\n",
      "[5772/8000] D loss: 0.3911, G loss: 2.4788\n",
      "[6132/8000] D loss: 1.2097, G loss: 1.5477\n",
      "[6492/8000] D loss: 0.8184, G loss: 3.2866\n",
      "[6852/8000] D loss: 0.9410, G loss: 1.4760\n",
      "[7212/8000] D loss: 0.4511, G loss: 3.3608\n",
      "[7572/8000] D loss: 0.6525, G loss: 2.6587\n",
      "[7932/8000] D loss: 0.7640, G loss: 2.7645\n",
      "train error: \n",
      " D loss: 0.706627, G loss: 2.550512, D accuracy: 84.9%, cell accuracy: 96.3%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.685929, G loss: 2.982418, D accuracy: 85.7%, cell accuracy: 95.9%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5325, G loss: 2.3087\n",
      "[372/8000] D loss: 0.3667, G loss: 2.3066\n",
      "[732/8000] D loss: 0.8449, G loss: 1.9485\n",
      "[1092/8000] D loss: 0.7254, G loss: 1.6546\n",
      "[1452/8000] D loss: 0.5592, G loss: 1.9545\n",
      "[1812/8000] D loss: 0.5585, G loss: 2.3701\n",
      "[2172/8000] D loss: 0.7049, G loss: 2.3357\n",
      "[2532/8000] D loss: 0.3920, G loss: 3.1586\n",
      "[2892/8000] D loss: 0.9807, G loss: 2.3220\n",
      "[3252/8000] D loss: 0.4615, G loss: 2.9278\n",
      "[3612/8000] D loss: 0.4469, G loss: 3.1243\n",
      "[3972/8000] D loss: 0.8216, G loss: 2.3790\n",
      "[4332/8000] D loss: 0.4311, G loss: 3.2371\n",
      "[4692/8000] D loss: 0.5177, G loss: 4.2844\n",
      "[5052/8000] D loss: 0.6931, G loss: 2.9234\n",
      "[5412/8000] D loss: 0.5488, G loss: 3.0786\n",
      "[5772/8000] D loss: 0.9326, G loss: 3.4201\n",
      "[6132/8000] D loss: 0.3802, G loss: 3.9471\n",
      "[6492/8000] D loss: 0.9374, G loss: 2.1052\n",
      "[6852/8000] D loss: 0.8317, G loss: 3.2746\n",
      "[7212/8000] D loss: 0.7224, G loss: 1.5338\n",
      "[7572/8000] D loss: 0.7499, G loss: 1.7549\n",
      "[7932/8000] D loss: 0.7121, G loss: 2.4780\n",
      "train error: \n",
      " D loss: 0.812667, G loss: 1.732806, D accuracy: 80.4%, cell accuracy: 96.5%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.722664, G loss: 2.149301, D accuracy: 83.8%, cell accuracy: 96.1%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8105, G loss: 1.1452\n",
      "[372/8000] D loss: 0.9464, G loss: 2.1368\n",
      "[732/8000] D loss: 0.4829, G loss: 2.5811\n",
      "[1092/8000] D loss: 1.1580, G loss: 1.4532\n",
      "[1452/8000] D loss: 0.8142, G loss: 2.0387\n",
      "[1812/8000] D loss: 0.5857, G loss: 2.2577\n",
      "[2172/8000] D loss: 0.8329, G loss: 2.9034\n",
      "[2532/8000] D loss: 0.5926, G loss: 1.8546\n",
      "[2892/8000] D loss: 0.5494, G loss: 1.8927\n",
      "[3252/8000] D loss: 0.5187, G loss: 2.5483\n",
      "[3612/8000] D loss: 0.7165, G loss: 2.9962\n",
      "[3972/8000] D loss: 0.8533, G loss: 4.2474\n",
      "[4332/8000] D loss: 0.4890, G loss: 2.7989\n",
      "[4692/8000] D loss: 0.7662, G loss: 3.3907\n",
      "[5052/8000] D loss: 0.7651, G loss: 2.3611\n",
      "[5412/8000] D loss: 0.6904, G loss: 3.4345\n",
      "[5772/8000] D loss: 0.7030, G loss: 2.7680\n",
      "[6132/8000] D loss: 0.6258, G loss: 2.0065\n",
      "[6492/8000] D loss: 0.6663, G loss: 3.3137\n",
      "[6852/8000] D loss: 0.4837, G loss: 3.2435\n",
      "[7212/8000] D loss: 0.7124, G loss: 2.1258\n",
      "[7572/8000] D loss: 0.3623, G loss: 3.1231\n",
      "[7932/8000] D loss: 0.7035, G loss: 4.6965\n",
      "train error: \n",
      " D loss: 0.707079, G loss: 2.768891, D accuracy: 84.0%, cell accuracy: 96.5%, board accuracy: 1.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.660497, G loss: 3.325536, D accuracy: 84.4%, cell accuracy: 96.1%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0196, G loss: 2.1452\n",
      "[372/8000] D loss: 0.6268, G loss: 2.5153\n",
      "[732/8000] D loss: 0.5272, G loss: 3.1073\n",
      "[1092/8000] D loss: 0.6087, G loss: 3.2679\n",
      "[1452/8000] D loss: 0.7096, G loss: 3.1565\n",
      "[1812/8000] D loss: 0.4383, G loss: 3.0273\n",
      "[2172/8000] D loss: 0.8539, G loss: 3.2789\n",
      "[2532/8000] D loss: 0.7771, G loss: 2.7657\n",
      "[2892/8000] D loss: 1.0576, G loss: 2.1551\n",
      "[3252/8000] D loss: 0.4795, G loss: 2.9326\n",
      "[3612/8000] D loss: 0.4486, G loss: 2.6108\n",
      "[3972/8000] D loss: 0.6425, G loss: 1.9236\n",
      "[4332/8000] D loss: 0.5605, G loss: 3.3431\n",
      "[4692/8000] D loss: 0.4935, G loss: 2.2344\n",
      "[5052/8000] D loss: 0.7050, G loss: 2.3300\n",
      "[5412/8000] D loss: 0.6653, G loss: 3.5777\n",
      "[5772/8000] D loss: 0.6831, G loss: 2.7688\n",
      "[6132/8000] D loss: 0.3564, G loss: 1.8344\n",
      "[6492/8000] D loss: 0.7214, G loss: 2.7552\n",
      "[6852/8000] D loss: 0.8362, G loss: 2.4582\n",
      "[7212/8000] D loss: 0.9186, G loss: 2.8050\n",
      "[7572/8000] D loss: 0.7651, G loss: 2.7081\n",
      "[7932/8000] D loss: 0.6739, G loss: 2.9565\n",
      "train error: \n",
      " D loss: 0.671789, G loss: 2.535001, D accuracy: 85.1%, cell accuracy: 96.6%, board accuracy: 1.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608158, G loss: 3.064754, D accuracy: 86.7%, cell accuracy: 96.3%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6897, G loss: 2.8559\n",
      "[372/8000] D loss: 0.8439, G loss: 3.4772\n",
      "[732/8000] D loss: 0.4239, G loss: 2.5140\n",
      "[1092/8000] D loss: 0.3908, G loss: 2.8976\n",
      "[1452/8000] D loss: 0.6778, G loss: 2.0951\n",
      "[1812/8000] D loss: 0.4869, G loss: 3.1453\n",
      "[2172/8000] D loss: 0.9156, G loss: 2.1719\n",
      "[2532/8000] D loss: 0.5732, G loss: 2.1780\n",
      "[2892/8000] D loss: 0.5516, G loss: 3.3014\n",
      "[3252/8000] D loss: 0.4763, G loss: 2.4539\n",
      "[3612/8000] D loss: 0.8634, G loss: 1.8095\n",
      "[3972/8000] D loss: 0.5241, G loss: 3.6656\n",
      "[4332/8000] D loss: 0.7230, G loss: 2.8255\n",
      "[4692/8000] D loss: 0.6238, G loss: 3.5379\n",
      "[5052/8000] D loss: 0.5561, G loss: 3.5488\n",
      "[5412/8000] D loss: 0.7348, G loss: 3.0349\n",
      "[5772/8000] D loss: 1.1391, G loss: 2.9203\n",
      "[6132/8000] D loss: 0.8808, G loss: 4.2362\n",
      "[6492/8000] D loss: 0.2842, G loss: 4.4203\n",
      "[6852/8000] D loss: 0.6834, G loss: 2.9773\n",
      "[7212/8000] D loss: 0.6487, G loss: 3.3566\n",
      "[7572/8000] D loss: 1.1746, G loss: 3.7066\n",
      "[7932/8000] D loss: 0.7632, G loss: 4.3083\n",
      "train error: \n",
      " D loss: 0.847681, G loss: 1.777807, D accuracy: 80.7%, cell accuracy: 96.5%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.692484, G loss: 2.314548, D accuracy: 85.0%, cell accuracy: 96.2%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5708, G loss: 2.4149\n",
      "[372/8000] D loss: 0.3504, G loss: 2.9593\n",
      "[732/8000] D loss: 0.5379, G loss: 2.6903\n",
      "[1092/8000] D loss: 0.4101, G loss: 3.4600\n",
      "[1452/8000] D loss: 0.7448, G loss: 2.0806\n",
      "[1812/8000] D loss: 0.6826, G loss: 2.4786\n",
      "[2172/8000] D loss: 0.6839, G loss: 2.8277\n",
      "[2532/8000] D loss: 0.6227, G loss: 4.1625\n",
      "[2892/8000] D loss: 0.8022, G loss: 1.5931\n",
      "[3252/8000] D loss: 0.6062, G loss: 3.2806\n",
      "[3612/8000] D loss: 0.7115, G loss: 3.1071\n",
      "[3972/8000] D loss: 0.2794, G loss: 4.2092\n",
      "[4332/8000] D loss: 0.7602, G loss: 3.0721\n",
      "[4692/8000] D loss: 0.8597, G loss: 3.3277\n",
      "[5052/8000] D loss: 0.3332, G loss: 3.9110\n",
      "[5412/8000] D loss: 0.9428, G loss: 3.2609\n",
      "[5772/8000] D loss: 0.6222, G loss: 2.3564\n",
      "[6132/8000] D loss: 0.4874, G loss: 3.1152\n",
      "[6492/8000] D loss: 0.5562, G loss: 2.4605\n",
      "[6852/8000] D loss: 0.5080, G loss: 2.9707\n",
      "[7212/8000] D loss: 0.6813, G loss: 3.0342\n",
      "[7572/8000] D loss: 0.6637, G loss: 2.9965\n",
      "[7932/8000] D loss: 0.5822, G loss: 2.9850\n",
      "train error: \n",
      " D loss: 0.797336, G loss: 2.033263, D accuracy: 81.7%, cell accuracy: 96.6%, board accuracy: 1.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.660151, G loss: 2.646760, D accuracy: 85.2%, cell accuracy: 96.2%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5581, G loss: 2.6495\n",
      "[372/8000] D loss: 0.6925, G loss: 3.0940\n",
      "[732/8000] D loss: 0.7199, G loss: 2.6147\n",
      "[1092/8000] D loss: 0.8657, G loss: 3.4959\n",
      "[1452/8000] D loss: 0.6976, G loss: 3.7753\n",
      "[1812/8000] D loss: 0.8152, G loss: 1.7870\n",
      "[2172/8000] D loss: 0.9558, G loss: 1.7718\n",
      "[2532/8000] D loss: 0.4613, G loss: 2.6751\n",
      "[2892/8000] D loss: 0.4775, G loss: 3.3551\n",
      "[3252/8000] D loss: 0.4745, G loss: 4.1081\n",
      "[3612/8000] D loss: 0.6190, G loss: 2.1629\n",
      "[3972/8000] D loss: 0.5403, G loss: 3.5094\n",
      "[4332/8000] D loss: 1.1085, G loss: 2.3410\n",
      "[4692/8000] D loss: 0.4767, G loss: 2.9947\n",
      "[5052/8000] D loss: 0.7915, G loss: 1.5599\n",
      "[5412/8000] D loss: 0.7327, G loss: 2.0509\n",
      "[5772/8000] D loss: 0.7153, G loss: 2.8162\n",
      "[6132/8000] D loss: 1.1410, G loss: 3.6961\n",
      "[6492/8000] D loss: 0.5790, G loss: 3.8030\n",
      "[6852/8000] D loss: 0.8377, G loss: 2.8855\n",
      "[7212/8000] D loss: 0.5586, G loss: 3.7514\n",
      "[7572/8000] D loss: 0.7405, G loss: 2.9807\n",
      "[7932/8000] D loss: 0.8085, G loss: 1.6521\n",
      "train error: \n",
      " D loss: 0.742651, G loss: 3.378097, D accuracy: 83.2%, cell accuracy: 96.7%, board accuracy: 1.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.731417, G loss: 4.024641, D accuracy: 83.5%, cell accuracy: 96.2%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6061, G loss: 3.0420\n",
      "[372/8000] D loss: 0.6860, G loss: 2.9804\n",
      "[732/8000] D loss: 1.0948, G loss: 1.9383\n",
      "[1092/8000] D loss: 0.7192, G loss: 2.0012\n",
      "[1452/8000] D loss: 0.6109, G loss: 1.5664\n",
      "[1812/8000] D loss: 0.7229, G loss: 2.2244\n",
      "[2172/8000] D loss: 0.7288, G loss: 2.8518\n",
      "[2532/8000] D loss: 0.6209, G loss: 2.8562\n",
      "[2892/8000] D loss: 0.4995, G loss: 3.5214\n",
      "[3252/8000] D loss: 0.4370, G loss: 3.0661\n",
      "[3612/8000] D loss: 0.4883, G loss: 2.1728\n",
      "[3972/8000] D loss: 0.8572, G loss: 1.8777\n",
      "[4332/8000] D loss: 0.3102, G loss: 3.6089\n",
      "[4692/8000] D loss: 0.7926, G loss: 2.6743\n",
      "[5052/8000] D loss: 0.6213, G loss: 1.5669\n",
      "[5412/8000] D loss: 1.1600, G loss: 1.6122\n",
      "[5772/8000] D loss: 0.7399, G loss: 3.4796\n",
      "[6132/8000] D loss: 0.4222, G loss: 3.4303\n",
      "[6492/8000] D loss: 0.9454, G loss: 2.5888\n",
      "[6852/8000] D loss: 0.4672, G loss: 4.1707\n",
      "[7212/8000] D loss: 0.5700, G loss: 3.9626\n",
      "[7572/8000] D loss: 0.7527, G loss: 3.7697\n",
      "[7932/8000] D loss: 0.3549, G loss: 4.4599\n",
      "train error: \n",
      " D loss: 0.651973, G loss: 2.930755, D accuracy: 85.0%, cell accuracy: 96.7%, board accuracy: 1.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.605803, G loss: 3.643878, D accuracy: 86.4%, cell accuracy: 96.3%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7471, G loss: 3.8462\n",
      "[372/8000] D loss: 0.4501, G loss: 2.1299\n",
      "[732/8000] D loss: 0.6195, G loss: 2.5027\n",
      "[1092/8000] D loss: 0.7839, G loss: 2.6819\n",
      "[1452/8000] D loss: 0.4267, G loss: 2.7210\n",
      "[1812/8000] D loss: 0.7742, G loss: 2.4422\n",
      "[2172/8000] D loss: 0.4702, G loss: 4.0676\n",
      "[2532/8000] D loss: 0.9277, G loss: 1.6992\n",
      "[2892/8000] D loss: 0.8322, G loss: 1.9955\n",
      "[3252/8000] D loss: 0.4462, G loss: 4.4364\n",
      "[3612/8000] D loss: 0.5586, G loss: 1.9067\n",
      "[3972/8000] D loss: 0.5620, G loss: 3.8773\n",
      "[4332/8000] D loss: 0.6146, G loss: 3.2188\n",
      "[4692/8000] D loss: 0.4756, G loss: 2.6243\n",
      "[5052/8000] D loss: 0.5458, G loss: 3.1051\n",
      "[5412/8000] D loss: 0.6627, G loss: 2.4182\n",
      "[5772/8000] D loss: 0.6101, G loss: 3.1870\n",
      "[6132/8000] D loss: 0.5085, G loss: 3.2553\n",
      "[6492/8000] D loss: 1.0978, G loss: 2.0913\n",
      "[6852/8000] D loss: 0.8604, G loss: 1.2584\n",
      "[7212/8000] D loss: 0.6506, G loss: 1.9219\n",
      "[7572/8000] D loss: 0.8746, G loss: 2.7416\n",
      "[7932/8000] D loss: 0.3995, G loss: 3.9293\n",
      "train error: \n",
      " D loss: 0.667058, G loss: 2.467527, D accuracy: 84.5%, cell accuracy: 96.7%, board accuracy: 1.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.588678, G loss: 3.193532, D accuracy: 86.5%, cell accuracy: 96.3%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6158, G loss: 3.1208\n",
      "[372/8000] D loss: 0.7134, G loss: 3.3525\n",
      "[732/8000] D loss: 0.5614, G loss: 2.2354\n",
      "[1092/8000] D loss: 0.8162, G loss: 1.9120\n",
      "[1452/8000] D loss: 0.4469, G loss: 4.2700\n",
      "[1812/8000] D loss: 0.4929, G loss: 5.0303\n",
      "[2172/8000] D loss: 0.7497, G loss: 2.5393\n",
      "[2532/8000] D loss: 0.3118, G loss: 4.7048\n",
      "[2892/8000] D loss: 0.4099, G loss: 3.3436\n",
      "[3252/8000] D loss: 0.7444, G loss: 3.1729\n",
      "[3612/8000] D loss: 0.7246, G loss: 2.8080\n",
      "[3972/8000] D loss: 0.7344, G loss: 3.5018\n",
      "[4332/8000] D loss: 1.0756, G loss: 3.7485\n",
      "[4692/8000] D loss: 0.8057, G loss: 3.6663\n",
      "[5052/8000] D loss: 0.7537, G loss: 3.3879\n",
      "[5412/8000] D loss: 0.9097, G loss: 2.2258\n",
      "[5772/8000] D loss: 0.6224, G loss: 2.9337\n",
      "[6132/8000] D loss: 0.6752, G loss: 3.1108\n",
      "[6492/8000] D loss: 0.6648, G loss: 2.7284\n",
      "[6852/8000] D loss: 0.4031, G loss: 3.5271\n",
      "[7212/8000] D loss: 0.4141, G loss: 3.3947\n",
      "[7572/8000] D loss: 0.5571, G loss: 3.2669\n",
      "[7932/8000] D loss: 0.5474, G loss: 3.7917\n",
      "train error: \n",
      " D loss: 0.682039, G loss: 2.622465, D accuracy: 83.9%, cell accuracy: 96.8%, board accuracy: 1.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.598625, G loss: 3.461682, D accuracy: 86.2%, cell accuracy: 96.3%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9031, G loss: 1.9246\n",
      "[372/8000] D loss: 0.6687, G loss: 3.5410\n",
      "[732/8000] D loss: 0.7640, G loss: 3.5978\n",
      "[1092/8000] D loss: 0.6415, G loss: 2.7986\n",
      "[1452/8000] D loss: 0.5697, G loss: 2.4863\n",
      "[1812/8000] D loss: 0.4540, G loss: 3.5030\n",
      "[2172/8000] D loss: 0.7446, G loss: 2.5784\n",
      "[2532/8000] D loss: 1.0815, G loss: 1.6280\n",
      "[2892/8000] D loss: 0.7246, G loss: 2.8684\n",
      "[3252/8000] D loss: 0.4910, G loss: 2.9828\n",
      "[3612/8000] D loss: 0.5639, G loss: 3.1021\n",
      "[3972/8000] D loss: 0.7453, G loss: 1.6900\n",
      "[4332/8000] D loss: 0.7887, G loss: 2.6187\n",
      "[4692/8000] D loss: 0.8277, G loss: 1.8418\n",
      "[5052/8000] D loss: 0.7392, G loss: 2.3415\n",
      "[5412/8000] D loss: 0.6451, G loss: 3.1983\n",
      "[5772/8000] D loss: 0.7664, G loss: 2.9483\n",
      "[6132/8000] D loss: 0.4846, G loss: 3.3992\n",
      "[6492/8000] D loss: 1.3517, G loss: 1.7196\n",
      "[6852/8000] D loss: 1.0549, G loss: 1.9011\n",
      "[7212/8000] D loss: 0.6696, G loss: 2.5194\n",
      "[7572/8000] D loss: 0.5538, G loss: 2.4082\n",
      "[7932/8000] D loss: 0.6522, G loss: 3.3113\n",
      "train error: \n",
      " D loss: 0.664969, G loss: 2.639624, D accuracy: 84.3%, cell accuracy: 96.8%, board accuracy: 1.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.596270, G loss: 3.382528, D accuracy: 86.3%, cell accuracy: 96.5%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4963, G loss: 3.5849\n",
      "[372/8000] D loss: 0.6912, G loss: 2.1198\n",
      "[732/8000] D loss: 0.6428, G loss: 1.6708\n",
      "[1092/8000] D loss: 0.6604, G loss: 2.4809\n",
      "[1452/8000] D loss: 0.6427, G loss: 3.9012\n",
      "[1812/8000] D loss: 0.5743, G loss: 2.9430\n",
      "[2172/8000] D loss: 0.7152, G loss: 2.8195\n",
      "[2532/8000] D loss: 0.9286, G loss: 2.3050\n",
      "[2892/8000] D loss: 0.5813, G loss: 2.2116\n",
      "[3252/8000] D loss: 0.8209, G loss: 3.1707\n",
      "[3612/8000] D loss: 0.8842, G loss: 2.9064\n",
      "[3972/8000] D loss: 0.6148, G loss: 2.3339\n",
      "[4332/8000] D loss: 0.9736, G loss: 2.9265\n",
      "[4692/8000] D loss: 1.0518, G loss: 2.2617\n",
      "[5052/8000] D loss: 0.7396, G loss: 2.0456\n",
      "[5412/8000] D loss: 1.1263, G loss: 1.4946\n",
      "[5772/8000] D loss: 0.5671, G loss: 3.0321\n",
      "[6132/8000] D loss: 0.7277, G loss: 2.7370\n",
      "[6492/8000] D loss: 0.8257, G loss: 3.5332\n",
      "[6852/8000] D loss: 0.6040, G loss: 2.8993\n",
      "[7212/8000] D loss: 0.5451, G loss: 2.7277\n",
      "[7572/8000] D loss: 0.7565, G loss: 3.3891\n",
      "[7932/8000] D loss: 0.6783, G loss: 1.6845\n",
      "train error: \n",
      " D loss: 0.750801, G loss: 2.220830, D accuracy: 81.8%, cell accuracy: 96.9%, board accuracy: 2.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.614033, G loss: 3.047034, D accuracy: 85.5%, cell accuracy: 96.5%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9938, G loss: 1.1490\n",
      "[372/8000] D loss: 1.0004, G loss: 2.1555\n",
      "[732/8000] D loss: 0.9964, G loss: 2.2719\n",
      "[1092/8000] D loss: 0.2179, G loss: 3.9916\n",
      "[1452/8000] D loss: 0.9889, G loss: 3.3377\n",
      "[1812/8000] D loss: 0.4458, G loss: 2.9053\n",
      "[2172/8000] D loss: 0.6850, G loss: 3.1655\n",
      "[2532/8000] D loss: 0.5563, G loss: 3.0304\n",
      "[2892/8000] D loss: 0.4908, G loss: 3.1715\n",
      "[3252/8000] D loss: 0.5989, G loss: 3.1925\n",
      "[3612/8000] D loss: 0.6067, G loss: 2.9442\n",
      "[3972/8000] D loss: 0.8106, G loss: 2.3560\n",
      "[4332/8000] D loss: 0.7261, G loss: 2.3651\n",
      "[4692/8000] D loss: 1.0906, G loss: 2.0508\n",
      "[5052/8000] D loss: 0.7474, G loss: 3.3411\n",
      "[5412/8000] D loss: 0.6658, G loss: 5.0045\n",
      "[5772/8000] D loss: 0.7214, G loss: 2.9191\n",
      "[6132/8000] D loss: 0.5571, G loss: 3.2378\n",
      "[6492/8000] D loss: 0.6739, G loss: 4.0733\n",
      "[6852/8000] D loss: 1.2546, G loss: 1.5004\n",
      "[7212/8000] D loss: 0.5857, G loss: 1.8138\n",
      "[7572/8000] D loss: 0.3195, G loss: 3.4800\n",
      "[7932/8000] D loss: 0.6909, G loss: 2.2562\n",
      "train error: \n",
      " D loss: 0.655906, G loss: 3.149523, D accuracy: 84.0%, cell accuracy: 96.9%, board accuracy: 1.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.604830, G loss: 4.033712, D accuracy: 85.5%, cell accuracy: 96.5%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6025, G loss: 3.3857\n",
      "[372/8000] D loss: 0.5008, G loss: 3.0573\n",
      "[732/8000] D loss: 0.7811, G loss: 2.4377\n",
      "[1092/8000] D loss: 0.8283, G loss: 3.1229\n",
      "[1452/8000] D loss: 0.7060, G loss: 2.1741\n",
      "[1812/8000] D loss: 0.7957, G loss: 3.4946\n",
      "[2172/8000] D loss: 0.6097, G loss: 3.1663\n",
      "[2532/8000] D loss: 0.4819, G loss: 3.2271\n",
      "[2892/8000] D loss: 0.4588, G loss: 3.8795\n",
      "[3252/8000] D loss: 0.4018, G loss: 2.7150\n",
      "[3612/8000] D loss: 0.7431, G loss: 2.6601\n",
      "[3972/8000] D loss: 0.7379, G loss: 3.2696\n",
      "[4332/8000] D loss: 0.4864, G loss: 2.9182\n",
      "[4692/8000] D loss: 0.6943, G loss: 2.6158\n",
      "[5052/8000] D loss: 0.9048, G loss: 2.0139\n",
      "[5412/8000] D loss: 0.7922, G loss: 4.6467\n",
      "[5772/8000] D loss: 1.0588, G loss: 1.4714\n",
      "[6132/8000] D loss: 0.9291, G loss: 1.8005\n",
      "[6492/8000] D loss: 0.7556, G loss: 2.5841\n",
      "[6852/8000] D loss: 1.1129, G loss: 1.3288\n",
      "[7212/8000] D loss: 0.4364, G loss: 2.8829\n",
      "[7572/8000] D loss: 1.0247, G loss: 2.9885\n",
      "[7932/8000] D loss: 0.8332, G loss: 2.7177\n",
      "train error: \n",
      " D loss: 0.763984, G loss: 2.270552, D accuracy: 82.2%, cell accuracy: 97.0%, board accuracy: 2.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626779, G loss: 3.150445, D accuracy: 85.5%, cell accuracy: 96.6%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3566, G loss: 2.5179\n",
      "[372/8000] D loss: 0.7740, G loss: 2.5227\n",
      "[732/8000] D loss: 0.7527, G loss: 1.8314\n",
      "[1092/8000] D loss: 0.2399, G loss: 3.4254\n",
      "[1452/8000] D loss: 0.8251, G loss: 1.8158\n",
      "[1812/8000] D loss: 0.3968, G loss: 3.6225\n",
      "[2172/8000] D loss: 0.5621, G loss: 2.7847\n",
      "[2532/8000] D loss: 0.4790, G loss: 2.5176\n",
      "[2892/8000] D loss: 0.3413, G loss: 3.0099\n",
      "[3252/8000] D loss: 0.7960, G loss: 2.6279\n",
      "[3612/8000] D loss: 1.1016, G loss: 1.4920\n",
      "[3972/8000] D loss: 0.8168, G loss: 3.0141\n",
      "[4332/8000] D loss: 0.3741, G loss: 2.7415\n",
      "[4692/8000] D loss: 0.6214, G loss: 3.3220\n",
      "[5052/8000] D loss: 0.5924, G loss: 3.5522\n",
      "[5412/8000] D loss: 0.5687, G loss: 3.9105\n",
      "[5772/8000] D loss: 0.6886, G loss: 2.4089\n",
      "[6132/8000] D loss: 0.7574, G loss: 2.4619\n",
      "[6492/8000] D loss: 0.8309, G loss: 3.5295\n",
      "[6852/8000] D loss: 0.4884, G loss: 2.8899\n",
      "[7212/8000] D loss: 0.5263, G loss: 3.1388\n",
      "[7572/8000] D loss: 1.0243, G loss: 1.2800\n",
      "[7932/8000] D loss: 0.5567, G loss: 2.4839\n",
      "train error: \n",
      " D loss: 0.703820, G loss: 2.587645, D accuracy: 82.9%, cell accuracy: 96.9%, board accuracy: 2.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.598089, G loss: 3.452398, D accuracy: 86.3%, cell accuracy: 96.5%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3961, G loss: 3.9481\n",
      "[372/8000] D loss: 0.6614, G loss: 3.2754\n",
      "[732/8000] D loss: 0.6280, G loss: 4.1012\n",
      "[1092/8000] D loss: 0.5929, G loss: 3.6417\n",
      "[1452/8000] D loss: 0.9784, G loss: 2.5965\n",
      "[1812/8000] D loss: 0.9138, G loss: 2.6600\n",
      "[2172/8000] D loss: 0.6571, G loss: 2.6502\n",
      "[2532/8000] D loss: 0.6611, G loss: 4.7760\n",
      "[2892/8000] D loss: 0.6508, G loss: 2.1702\n",
      "[3252/8000] D loss: 1.1962, G loss: 2.1659\n",
      "[3612/8000] D loss: 0.6665, G loss: 3.9485\n",
      "[3972/8000] D loss: 0.6018, G loss: 2.7492\n",
      "[4332/8000] D loss: 0.5391, G loss: 3.7619\n",
      "[4692/8000] D loss: 0.3662, G loss: 3.9282\n",
      "[5052/8000] D loss: 0.8152, G loss: 2.3388\n",
      "[5412/8000] D loss: 0.5475, G loss: 2.3789\n",
      "[5772/8000] D loss: 0.5708, G loss: 5.8995\n",
      "[6132/8000] D loss: 0.6580, G loss: 2.5405\n",
      "[6492/8000] D loss: 1.4495, G loss: 2.1997\n",
      "[6852/8000] D loss: 0.4814, G loss: 3.8725\n",
      "[7212/8000] D loss: 0.4788, G loss: 3.3265\n",
      "[7572/8000] D loss: 0.4977, G loss: 4.2885\n",
      "[7932/8000] D loss: 0.6347, G loss: 2.6212\n",
      "train error: \n",
      " D loss: 0.691185, G loss: 2.852908, D accuracy: 83.0%, cell accuracy: 97.1%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.595533, G loss: 3.785483, D accuracy: 86.1%, cell accuracy: 96.7%, board accuracy: 2.1% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7392, G loss: 2.8503\n",
      "[372/8000] D loss: 0.7628, G loss: 2.6771\n",
      "[732/8000] D loss: 0.7696, G loss: 3.6786\n",
      "[1092/8000] D loss: 0.7709, G loss: 3.0510\n",
      "[1452/8000] D loss: 0.9638, G loss: 3.9403\n",
      "[1812/8000] D loss: 0.6445, G loss: 2.6372\n",
      "[2172/8000] D loss: 0.9391, G loss: 1.7883\n",
      "[2532/8000] D loss: 0.7178, G loss: 3.7250\n",
      "[2892/8000] D loss: 0.3977, G loss: 3.8469\n",
      "[3252/8000] D loss: 0.4540, G loss: 5.0512\n",
      "[3612/8000] D loss: 0.7407, G loss: 3.7860\n",
      "[3972/8000] D loss: 0.7650, G loss: 2.8326\n",
      "[4332/8000] D loss: 0.7475, G loss: 3.1613\n",
      "[4692/8000] D loss: 0.4429, G loss: 3.5794\n",
      "[5052/8000] D loss: 0.5160, G loss: 3.7947\n",
      "[5412/8000] D loss: 0.8818, G loss: 2.5968\n",
      "[5772/8000] D loss: 0.7111, G loss: 3.8248\n",
      "[6132/8000] D loss: 1.0677, G loss: 2.2200\n",
      "[6492/8000] D loss: 0.6025, G loss: 2.5102\n",
      "[6852/8000] D loss: 0.8641, G loss: 2.6215\n",
      "[7212/8000] D loss: 0.5934, G loss: 3.2202\n",
      "[7572/8000] D loss: 0.4887, G loss: 3.0346\n",
      "[7932/8000] D loss: 0.3755, G loss: 4.4905\n",
      "train error: \n",
      " D loss: 0.656276, G loss: 3.131871, D accuracy: 84.3%, cell accuracy: 97.1%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608951, G loss: 4.072062, D accuracy: 85.5%, cell accuracy: 96.7%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4163, G loss: 3.2737\n",
      "[372/8000] D loss: 1.0178, G loss: 2.6864\n",
      "[732/8000] D loss: 0.5012, G loss: 3.2180\n",
      "[1092/8000] D loss: 0.5225, G loss: 3.0147\n",
      "[1452/8000] D loss: 0.8215, G loss: 3.4307\n",
      "[1812/8000] D loss: 0.5565, G loss: 3.6685\n",
      "[2172/8000] D loss: 0.9127, G loss: 3.7025\n",
      "[2532/8000] D loss: 0.7198, G loss: 4.1915\n",
      "[2892/8000] D loss: 0.2363, G loss: 3.9264\n",
      "[3252/8000] D loss: 0.6053, G loss: 3.3630\n",
      "[3612/8000] D loss: 0.7604, G loss: 2.2730\n",
      "[3972/8000] D loss: 0.4198, G loss: 2.7519\n",
      "[4332/8000] D loss: 0.7058, G loss: 1.8053\n",
      "[4692/8000] D loss: 0.7828, G loss: 3.2547\n",
      "[5052/8000] D loss: 0.9477, G loss: 3.4581\n",
      "[5412/8000] D loss: 0.7551, G loss: 2.5836\n",
      "[5772/8000] D loss: 0.7848, G loss: 2.7455\n",
      "[6132/8000] D loss: 1.0506, G loss: 2.3250\n",
      "[6492/8000] D loss: 1.0272, G loss: 2.8366\n",
      "[6852/8000] D loss: 0.5435, G loss: 3.0258\n",
      "[7212/8000] D loss: 1.0842, G loss: 3.7822\n",
      "[7572/8000] D loss: 0.5578, G loss: 3.0120\n",
      "[7932/8000] D loss: 0.8279, G loss: 2.0302\n",
      "train error: \n",
      " D loss: 0.755538, G loss: 3.423854, D accuracy: 81.6%, cell accuracy: 97.1%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.714308, G loss: 4.377317, D accuracy: 83.2%, cell accuracy: 96.7%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5633, G loss: 3.3649\n",
      "[372/8000] D loss: 0.9324, G loss: 3.4017\n",
      "[732/8000] D loss: 0.6535, G loss: 1.9825\n",
      "[1092/8000] D loss: 0.2865, G loss: 2.8412\n",
      "[1452/8000] D loss: 0.8733, G loss: 2.7095\n",
      "[1812/8000] D loss: 0.6890, G loss: 2.1624\n",
      "[2172/8000] D loss: 0.5486, G loss: 2.4718\n",
      "[2532/8000] D loss: 0.5814, G loss: 4.3366\n",
      "[2892/8000] D loss: 0.5809, G loss: 3.7820\n",
      "[3252/8000] D loss: 0.2697, G loss: 5.1526\n",
      "[3612/8000] D loss: 1.0713, G loss: 2.8780\n",
      "[3972/8000] D loss: 0.6856, G loss: 2.5953\n",
      "[4332/8000] D loss: 0.3207, G loss: 2.4850\n",
      "[4692/8000] D loss: 0.8922, G loss: 2.0477\n",
      "[5052/8000] D loss: 0.7699, G loss: 3.7239\n",
      "[5412/8000] D loss: 0.5902, G loss: 2.8829\n",
      "[5772/8000] D loss: 0.6992, G loss: 3.3349\n",
      "[6132/8000] D loss: 0.7775, G loss: 3.7819\n",
      "[6492/8000] D loss: 0.7274, G loss: 3.1963\n",
      "[6852/8000] D loss: 1.1091, G loss: 2.2539\n",
      "[7212/8000] D loss: 1.0293, G loss: 1.6393\n",
      "[7572/8000] D loss: 0.4926, G loss: 2.8426\n",
      "[7932/8000] D loss: 0.4492, G loss: 4.4475\n",
      "train error: \n",
      " D loss: 0.823946, G loss: 3.728364, D accuracy: 79.5%, cell accuracy: 97.2%, board accuracy: 3.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.778292, G loss: 4.683222, D accuracy: 81.0%, cell accuracy: 96.8%, board accuracy: 2.3% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4404, G loss: 5.1177\n",
      "[372/8000] D loss: 0.6100, G loss: 4.3910\n",
      "[732/8000] D loss: 1.2850, G loss: 1.6033\n",
      "[1092/8000] D loss: 0.4620, G loss: 3.2661\n",
      "[1452/8000] D loss: 0.2005, G loss: 3.6140\n",
      "[1812/8000] D loss: 0.7242, G loss: 2.3130\n",
      "[2172/8000] D loss: 0.7710, G loss: 2.2160\n",
      "[2532/8000] D loss: 0.7591, G loss: 2.0541\n",
      "[2892/8000] D loss: 0.2466, G loss: 4.9327\n",
      "[3252/8000] D loss: 0.7081, G loss: 2.2203\n",
      "[3612/8000] D loss: 0.6241, G loss: 3.0053\n",
      "[3972/8000] D loss: 0.4898, G loss: 2.6500\n",
      "[4332/8000] D loss: 0.5582, G loss: 3.2334\n",
      "[4692/8000] D loss: 1.0402, G loss: 2.1544\n",
      "[5052/8000] D loss: 0.4752, G loss: 3.2567\n",
      "[5412/8000] D loss: 0.7880, G loss: 3.0956\n",
      "[5772/8000] D loss: 0.4845, G loss: 3.8270\n",
      "[6132/8000] D loss: 0.8965, G loss: 1.9113\n",
      "[6492/8000] D loss: 0.5680, G loss: 2.9967\n",
      "[6852/8000] D loss: 0.7404, G loss: 3.9333\n",
      "[7212/8000] D loss: 0.8477, G loss: 2.5562\n",
      "[7572/8000] D loss: 0.6493, G loss: 3.7758\n",
      "[7932/8000] D loss: 0.8160, G loss: 3.1264\n",
      "train error: \n",
      " D loss: 0.712124, G loss: 3.007987, D accuracy: 82.2%, cell accuracy: 97.2%, board accuracy: 3.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.637911, G loss: 3.939286, D accuracy: 84.3%, cell accuracy: 96.8%, board accuracy: 2.3% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9764, G loss: 1.8058\n",
      "[372/8000] D loss: 0.7493, G loss: 4.3781\n",
      "[732/8000] D loss: 0.6099, G loss: 2.4103\n",
      "[1092/8000] D loss: 0.5506, G loss: 3.8223\n",
      "[1452/8000] D loss: 0.7686, G loss: 2.9596\n",
      "[1812/8000] D loss: 0.5004, G loss: 2.9088\n",
      "[2172/8000] D loss: 1.1892, G loss: 2.3433\n",
      "[2532/8000] D loss: 0.7834, G loss: 2.0079\n",
      "[2892/8000] D loss: 0.7374, G loss: 2.8846\n",
      "[3252/8000] D loss: 0.5278, G loss: 3.2094\n",
      "[3612/8000] D loss: 0.6954, G loss: 2.4140\n",
      "[3972/8000] D loss: 0.8669, G loss: 2.7810\n",
      "[4332/8000] D loss: 0.7846, G loss: 3.0804\n",
      "[4692/8000] D loss: 0.6295, G loss: 4.5728\n",
      "[5052/8000] D loss: 0.6275, G loss: 4.2399\n",
      "[5412/8000] D loss: 0.9692, G loss: 3.9033\n",
      "[5772/8000] D loss: 0.7115, G loss: 2.4442\n",
      "[6132/8000] D loss: 0.7432, G loss: 2.3538\n",
      "[6492/8000] D loss: 0.6021, G loss: 4.8854\n",
      "[6852/8000] D loss: 0.9214, G loss: 2.7035\n",
      "[7212/8000] D loss: 1.1855, G loss: 1.3530\n",
      "[7572/8000] D loss: 0.2854, G loss: 4.4626\n",
      "[7932/8000] D loss: 0.9687, G loss: 3.0427\n",
      "train error: \n",
      " D loss: 0.829671, G loss: 2.245651, D accuracy: 80.1%, cell accuracy: 97.3%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.644737, G loss: 3.158042, D accuracy: 84.7%, cell accuracy: 96.8%, board accuracy: 2.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6741, G loss: 1.9958\n",
      "[372/8000] D loss: 0.6235, G loss: 3.1828\n",
      "[732/8000] D loss: 0.5558, G loss: 2.5192\n",
      "[1092/8000] D loss: 0.6917, G loss: 3.2513\n",
      "[1452/8000] D loss: 0.4613, G loss: 4.4153\n",
      "[1812/8000] D loss: 0.7538, G loss: 2.9680\n",
      "[2172/8000] D loss: 0.7237, G loss: 2.2800\n",
      "[2532/8000] D loss: 0.6004, G loss: 2.9237\n",
      "[2892/8000] D loss: 0.7938, G loss: 2.4876\n",
      "[3252/8000] D loss: 0.9452, G loss: 2.1992\n",
      "[3612/8000] D loss: 0.4368, G loss: 3.8949\n",
      "[3972/8000] D loss: 0.7164, G loss: 2.0772\n",
      "[4332/8000] D loss: 0.4140, G loss: 3.1165\n",
      "[4692/8000] D loss: 0.6022, G loss: 3.4659\n",
      "[5052/8000] D loss: 0.7119, G loss: 2.8794\n",
      "[5412/8000] D loss: 0.7133, G loss: 4.2346\n",
      "[5772/8000] D loss: 0.5710, G loss: 3.2682\n",
      "[6132/8000] D loss: 0.6909, G loss: 3.1225\n",
      "[6492/8000] D loss: 0.3038, G loss: 3.5602\n",
      "[6852/8000] D loss: 0.7558, G loss: 3.2814\n",
      "[7212/8000] D loss: 1.0052, G loss: 1.8224\n",
      "[7572/8000] D loss: 0.7770, G loss: 3.0535\n",
      "[7932/8000] D loss: 0.7994, G loss: 3.0109\n",
      "train error: \n",
      " D loss: 0.677648, G loss: 3.066273, D accuracy: 83.6%, cell accuracy: 97.3%, board accuracy: 4.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.598855, G loss: 4.115436, D accuracy: 85.7%, cell accuracy: 96.9%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9784, G loss: 3.2366\n",
      "[372/8000] D loss: 1.1365, G loss: 3.0646\n",
      "[732/8000] D loss: 0.4648, G loss: 5.1697\n",
      "[1092/8000] D loss: 0.7094, G loss: 3.0336\n",
      "[1452/8000] D loss: 0.9602, G loss: 2.9592\n",
      "[1812/8000] D loss: 0.9208, G loss: 3.6538\n",
      "[2172/8000] D loss: 0.8609, G loss: 2.8556\n",
      "[2532/8000] D loss: 0.8287, G loss: 3.7106\n",
      "[2892/8000] D loss: 0.4922, G loss: 4.0584\n",
      "[3252/8000] D loss: 0.3372, G loss: 3.9306\n",
      "[3612/8000] D loss: 0.5778, G loss: 2.0886\n",
      "[3972/8000] D loss: 0.8452, G loss: 2.2710\n",
      "[4332/8000] D loss: 0.6524, G loss: 3.1011\n",
      "[4692/8000] D loss: 0.9379, G loss: 2.3979\n",
      "[5052/8000] D loss: 0.9028, G loss: 2.7916\n",
      "[5412/8000] D loss: 0.7360, G loss: 3.5277\n",
      "[5772/8000] D loss: 0.8083, G loss: 3.1908\n",
      "[6132/8000] D loss: 0.7284, G loss: 2.5801\n",
      "[6492/8000] D loss: 0.6687, G loss: 2.6404\n",
      "[6852/8000] D loss: 0.6349, G loss: 3.2217\n",
      "[7212/8000] D loss: 0.9425, G loss: 3.4801\n",
      "[7572/8000] D loss: 0.7436, G loss: 3.1152\n",
      "[7932/8000] D loss: 0.5396, G loss: 3.7440\n",
      "train error: \n",
      " D loss: 0.722120, G loss: 2.573491, D accuracy: 82.2%, cell accuracy: 97.3%, board accuracy: 3.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.575471, G loss: 3.591248, D accuracy: 86.4%, cell accuracy: 96.9%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6758, G loss: 4.4458\n",
      "[372/8000] D loss: 0.7938, G loss: 4.9644\n",
      "[732/8000] D loss: 0.9095, G loss: 1.8860\n",
      "[1092/8000] D loss: 0.4577, G loss: 5.0127\n",
      "[1452/8000] D loss: 0.7515, G loss: 5.1883\n",
      "[1812/8000] D loss: 0.7321, G loss: 4.0403\n",
      "[2172/8000] D loss: 0.7033, G loss: 2.3928\n",
      "[2532/8000] D loss: 0.8387, G loss: 2.6969\n",
      "[2892/8000] D loss: 0.6365, G loss: 1.8441\n",
      "[3252/8000] D loss: 0.5609, G loss: 3.2423\n",
      "[3612/8000] D loss: 1.0682, G loss: 1.7350\n",
      "[3972/8000] D loss: 0.4575, G loss: 3.7990\n",
      "[4332/8000] D loss: 0.7496, G loss: 1.9491\n",
      "[4692/8000] D loss: 0.4692, G loss: 3.5140\n",
      "[5052/8000] D loss: 0.5743, G loss: 3.1468\n",
      "[5412/8000] D loss: 1.0116, G loss: 3.8786\n",
      "[5772/8000] D loss: 0.5035, G loss: 4.9603\n",
      "[6132/8000] D loss: 0.5004, G loss: 1.8609\n",
      "[6492/8000] D loss: 0.5279, G loss: 3.8321\n",
      "[6852/8000] D loss: 0.7496, G loss: 2.7682\n",
      "[7212/8000] D loss: 0.5590, G loss: 4.0857\n",
      "[7572/8000] D loss: 0.8473, G loss: 2.5247\n",
      "[7932/8000] D loss: 0.6163, G loss: 2.9627\n",
      "train error: \n",
      " D loss: 0.684533, G loss: 3.113356, D accuracy: 83.0%, cell accuracy: 97.4%, board accuracy: 4.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.611822, G loss: 4.185095, D accuracy: 85.3%, cell accuracy: 96.9%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6843, G loss: 4.8378\n",
      "[372/8000] D loss: 0.4357, G loss: 3.2862\n",
      "[732/8000] D loss: 1.3782, G loss: 2.0612\n",
      "[1092/8000] D loss: 0.6598, G loss: 2.2968\n",
      "[1452/8000] D loss: 0.6609, G loss: 3.6120\n",
      "[1812/8000] D loss: 0.5533, G loss: 3.4268\n",
      "[2172/8000] D loss: 0.6246, G loss: 4.2565\n",
      "[2532/8000] D loss: 0.7925, G loss: 2.2463\n",
      "[2892/8000] D loss: 0.5574, G loss: 3.1735\n",
      "[3252/8000] D loss: 0.7852, G loss: 4.3890\n",
      "[3612/8000] D loss: 0.9916, G loss: 2.1256\n",
      "[3972/8000] D loss: 1.0817, G loss: 3.0265\n",
      "[4332/8000] D loss: 0.6189, G loss: 2.1280\n",
      "[4692/8000] D loss: 0.8562, G loss: 3.3885\n",
      "[5052/8000] D loss: 1.0973, G loss: 2.1883\n",
      "[5412/8000] D loss: 0.6315, G loss: 3.5272\n",
      "[5772/8000] D loss: 0.6971, G loss: 3.3071\n",
      "[6132/8000] D loss: 0.8971, G loss: 2.0923\n",
      "[6492/8000] D loss: 0.8421, G loss: 3.0562\n",
      "[6852/8000] D loss: 0.8009, G loss: 2.5603\n",
      "[7212/8000] D loss: 0.7484, G loss: 4.5041\n",
      "[7572/8000] D loss: 0.9280, G loss: 2.3324\n",
      "[7932/8000] D loss: 0.6013, G loss: 2.6082\n",
      "train error: \n",
      " D loss: 0.757089, G loss: 3.587100, D accuracy: 80.0%, cell accuracy: 97.3%, board accuracy: 4.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.728094, G loss: 4.695769, D accuracy: 80.4%, cell accuracy: 97.0%, board accuracy: 3.3% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4638, G loss: 3.4965\n",
      "[372/8000] D loss: 0.6783, G loss: 3.9268\n",
      "[732/8000] D loss: 0.6945, G loss: 3.4861\n",
      "[1092/8000] D loss: 0.5608, G loss: 3.1458\n",
      "[1452/8000] D loss: 0.7138, G loss: 3.7986\n",
      "[1812/8000] D loss: 0.8312, G loss: 2.4939\n",
      "[2172/8000] D loss: 0.6534, G loss: 3.0854\n",
      "[2532/8000] D loss: 0.6909, G loss: 2.2410\n",
      "[2892/8000] D loss: 0.8764, G loss: 2.2616\n",
      "[3252/8000] D loss: 0.9245, G loss: 2.4847\n",
      "[3612/8000] D loss: 0.5772, G loss: 3.3135\n",
      "[3972/8000] D loss: 0.5993, G loss: 2.6823\n",
      "[4332/8000] D loss: 0.6537, G loss: 4.3121\n",
      "[4692/8000] D loss: 0.5079, G loss: 3.4058\n",
      "[5052/8000] D loss: 1.0446, G loss: 2.9003\n",
      "[5412/8000] D loss: 0.7852, G loss: 3.7931\n",
      "[5772/8000] D loss: 0.8502, G loss: 1.8687\n",
      "[6132/8000] D loss: 0.6281, G loss: 2.3422\n",
      "[6492/8000] D loss: 0.5963, G loss: 2.8025\n",
      "[6852/8000] D loss: 0.6063, G loss: 3.8257\n",
      "[7212/8000] D loss: 0.9980, G loss: 2.8875\n",
      "[7572/8000] D loss: 0.8817, G loss: 1.8522\n",
      "[7932/8000] D loss: 0.5151, G loss: 3.7332\n",
      "train error: \n",
      " D loss: 0.760364, G loss: 2.634792, D accuracy: 81.4%, cell accuracy: 97.4%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.622538, G loss: 3.740960, D accuracy: 84.9%, cell accuracy: 97.0%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4214, G loss: 4.9081\n",
      "[372/8000] D loss: 0.5712, G loss: 3.4228\n",
      "[732/8000] D loss: 0.8269, G loss: 1.6827\n",
      "[1092/8000] D loss: 0.7638, G loss: 3.1072\n",
      "[1452/8000] D loss: 0.4415, G loss: 4.3925\n",
      "[1812/8000] D loss: 0.6130, G loss: 3.0511\n",
      "[2172/8000] D loss: 0.6147, G loss: 2.9567\n",
      "[2532/8000] D loss: 0.7610, G loss: 4.2034\n",
      "[2892/8000] D loss: 0.5090, G loss: 3.2524\n",
      "[3252/8000] D loss: 1.0620, G loss: 1.8716\n",
      "[3612/8000] D loss: 0.8756, G loss: 2.7752\n",
      "[3972/8000] D loss: 1.0336, G loss: 2.2149\n",
      "[4332/8000] D loss: 1.1257, G loss: 2.4160\n",
      "[4692/8000] D loss: 0.9992, G loss: 2.0486\n",
      "[5052/8000] D loss: 0.9523, G loss: 2.3537\n",
      "[5412/8000] D loss: 0.6464, G loss: 2.2205\n",
      "[5772/8000] D loss: 0.6285, G loss: 3.3479\n",
      "[6132/8000] D loss: 0.5267, G loss: 3.3670\n",
      "[6492/8000] D loss: 0.4883, G loss: 3.1155\n",
      "[6852/8000] D loss: 0.9237, G loss: 2.1725\n",
      "[7212/8000] D loss: 1.1280, G loss: 3.5420\n",
      "[7572/8000] D loss: 0.9810, G loss: 2.6054\n",
      "[7932/8000] D loss: 0.8402, G loss: 2.5790\n",
      "train error: \n",
      " D loss: 0.700548, G loss: 3.105379, D accuracy: 82.3%, cell accuracy: 97.5%, board accuracy: 5.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.625576, G loss: 4.275826, D accuracy: 84.8%, cell accuracy: 97.1%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7241, G loss: 2.4278\n",
      "[372/8000] D loss: 0.4835, G loss: 3.7236\n",
      "[732/8000] D loss: 0.7823, G loss: 2.5233\n",
      "[1092/8000] D loss: 0.6676, G loss: 2.8689\n",
      "[1452/8000] D loss: 0.9175, G loss: 1.7126\n",
      "[1812/8000] D loss: 0.7599, G loss: 3.5091\n",
      "[2172/8000] D loss: 0.6638, G loss: 2.3054\n",
      "[2532/8000] D loss: 0.8150, G loss: 2.6511\n",
      "[2892/8000] D loss: 0.3910, G loss: 4.3056\n",
      "[3252/8000] D loss: 0.7062, G loss: 3.7725\n",
      "[3612/8000] D loss: 0.8949, G loss: 2.3801\n",
      "[3972/8000] D loss: 0.6443, G loss: 3.2071\n",
      "[4332/8000] D loss: 0.4238, G loss: 3.4984\n",
      "[4692/8000] D loss: 0.6727, G loss: 5.6352\n",
      "[5052/8000] D loss: 0.5046, G loss: 2.6364\n",
      "[5412/8000] D loss: 0.5639, G loss: 2.9752\n",
      "[5772/8000] D loss: 0.9334, G loss: 2.3485\n",
      "[6132/8000] D loss: 0.6305, G loss: 4.2060\n",
      "[6492/8000] D loss: 0.7726, G loss: 2.7391\n",
      "[6852/8000] D loss: 0.5089, G loss: 3.8939\n",
      "[7212/8000] D loss: 0.8589, G loss: 3.2588\n",
      "[7572/8000] D loss: 0.8609, G loss: 3.4361\n",
      "[7932/8000] D loss: 1.1298, G loss: 2.3236\n",
      "train error: \n",
      " D loss: 0.952171, G loss: 4.235659, D accuracy: 75.4%, cell accuracy: 97.5%, board accuracy: 5.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.964581, G loss: 5.477224, D accuracy: 75.9%, cell accuracy: 97.1%, board accuracy: 3.3% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0423, G loss: 3.5095\n",
      "[372/8000] D loss: 0.8690, G loss: 2.9160\n",
      "[732/8000] D loss: 0.6867, G loss: 2.2166\n",
      "[1092/8000] D loss: 0.8359, G loss: 1.9078\n",
      "[1452/8000] D loss: 0.8417, G loss: 1.9536\n",
      "[1812/8000] D loss: 0.9165, G loss: 3.2621\n",
      "[2172/8000] D loss: 0.7763, G loss: 4.2166\n",
      "[2532/8000] D loss: 0.5137, G loss: 3.2091\n",
      "[2892/8000] D loss: 0.5046, G loss: 3.3830\n",
      "[3252/8000] D loss: 0.2865, G loss: 3.8763\n",
      "[3612/8000] D loss: 0.8325, G loss: 2.6364\n",
      "[3972/8000] D loss: 0.6165, G loss: 2.3949\n",
      "[4332/8000] D loss: 0.5381, G loss: 4.7348\n",
      "[4692/8000] D loss: 0.8566, G loss: 2.7905\n",
      "[5052/8000] D loss: 0.7187, G loss: 3.9810\n",
      "[5412/8000] D loss: 0.6727, G loss: 2.0225\n",
      "[5772/8000] D loss: 0.7030, G loss: 3.8227\n",
      "[6132/8000] D loss: 0.5116, G loss: 3.8373\n",
      "[6492/8000] D loss: 0.6374, G loss: 3.5797\n",
      "[6852/8000] D loss: 0.6178, G loss: 4.7667\n",
      "[7212/8000] D loss: 0.7058, G loss: 2.2788\n",
      "[7572/8000] D loss: 0.7800, G loss: 1.9143\n",
      "[7932/8000] D loss: 0.6816, G loss: 2.9561\n",
      "train error: \n",
      " D loss: 0.687470, G loss: 3.352884, D accuracy: 82.6%, cell accuracy: 97.5%, board accuracy: 5.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609704, G loss: 4.576257, D accuracy: 85.0%, cell accuracy: 97.1%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8123, G loss: 3.0346\n",
      "[372/8000] D loss: 0.7406, G loss: 2.4773\n",
      "[732/8000] D loss: 0.7795, G loss: 2.0367\n",
      "[1092/8000] D loss: 0.7089, G loss: 2.8959\n",
      "[1452/8000] D loss: 0.8573, G loss: 1.7761\n",
      "[1812/8000] D loss: 0.5536, G loss: 3.0975\n",
      "[2172/8000] D loss: 0.6214, G loss: 5.7579\n",
      "[2532/8000] D loss: 1.1120, G loss: 2.0642\n",
      "[2892/8000] D loss: 0.6754, G loss: 1.7256\n",
      "[3252/8000] D loss: 0.8256, G loss: 2.2565\n",
      "[3612/8000] D loss: 0.8333, G loss: 2.3036\n",
      "[3972/8000] D loss: 0.8699, G loss: 2.7301\n",
      "[4332/8000] D loss: 0.7833, G loss: 2.6025\n",
      "[4692/8000] D loss: 0.5167, G loss: 4.1805\n",
      "[5052/8000] D loss: 0.9681, G loss: 1.8330\n",
      "[5412/8000] D loss: 0.6631, G loss: 2.1007\n",
      "[5772/8000] D loss: 0.4293, G loss: 3.5509\n",
      "[6132/8000] D loss: 0.6371, G loss: 3.7090\n",
      "[6492/8000] D loss: 0.8041, G loss: 4.1388\n",
      "[6852/8000] D loss: 0.5652, G loss: 2.6064\n",
      "[7212/8000] D loss: 0.5868, G loss: 3.1577\n",
      "[7572/8000] D loss: 1.1411, G loss: 1.6665\n",
      "[7932/8000] D loss: 0.4685, G loss: 4.0527\n",
      "train error: \n",
      " D loss: 0.734174, G loss: 2.999157, D accuracy: 80.6%, cell accuracy: 97.5%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.649446, G loss: 4.120605, D accuracy: 83.7%, cell accuracy: 97.1%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7433, G loss: 2.4005\n",
      "[372/8000] D loss: 0.3297, G loss: 3.9751\n",
      "[732/8000] D loss: 0.8623, G loss: 2.8691\n",
      "[1092/8000] D loss: 0.8764, G loss: 1.9957\n",
      "[1452/8000] D loss: 0.6035, G loss: 3.4955\n",
      "[1812/8000] D loss: 0.4541, G loss: 3.5687\n",
      "[2172/8000] D loss: 0.7838, G loss: 1.8013\n",
      "[2532/8000] D loss: 0.7011, G loss: 3.3898\n",
      "[2892/8000] D loss: 0.5287, G loss: 4.1648\n",
      "[3252/8000] D loss: 0.4975, G loss: 2.4795\n",
      "[3612/8000] D loss: 0.3247, G loss: 4.5701\n",
      "[3972/8000] D loss: 0.8169, G loss: 2.7902\n",
      "[4332/8000] D loss: 0.7709, G loss: 2.1631\n",
      "[4692/8000] D loss: 0.8228, G loss: 1.5189\n",
      "[5052/8000] D loss: 0.9983, G loss: 2.3950\n",
      "[5412/8000] D loss: 0.6219, G loss: 2.5087\n",
      "[5772/8000] D loss: 0.9562, G loss: 2.5681\n",
      "[6132/8000] D loss: 0.3015, G loss: 5.5205\n",
      "[6492/8000] D loss: 0.6133, G loss: 3.1411\n",
      "[6852/8000] D loss: 0.4566, G loss: 4.7782\n",
      "[7212/8000] D loss: 0.3604, G loss: 4.3643\n",
      "[7572/8000] D loss: 0.7794, G loss: 2.2957\n",
      "[7932/8000] D loss: 0.5102, G loss: 4.4376\n",
      "train error: \n",
      " D loss: 0.692601, G loss: 3.156563, D accuracy: 82.1%, cell accuracy: 97.6%, board accuracy: 5.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.630149, G loss: 4.331703, D accuracy: 84.5%, cell accuracy: 97.1%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7998, G loss: 2.6342\n",
      "[372/8000] D loss: 0.6567, G loss: 2.3707\n",
      "[732/8000] D loss: 1.0063, G loss: 1.9167\n",
      "[1092/8000] D loss: 0.6789, G loss: 2.8803\n",
      "[1452/8000] D loss: 0.5818, G loss: 2.4959\n",
      "[1812/8000] D loss: 0.8219, G loss: 1.7108\n",
      "[2172/8000] D loss: 0.5621, G loss: 4.1050\n",
      "[2532/8000] D loss: 0.7614, G loss: 3.4265\n",
      "[2892/8000] D loss: 0.4226, G loss: 3.6251\n",
      "[3252/8000] D loss: 0.6359, G loss: 2.6127\n",
      "[3612/8000] D loss: 1.0900, G loss: 2.1530\n",
      "[3972/8000] D loss: 0.6675, G loss: 3.3394\n",
      "[4332/8000] D loss: 0.8335, G loss: 2.3497\n",
      "[4692/8000] D loss: 0.8877, G loss: 3.2672\n",
      "[5052/8000] D loss: 0.5419, G loss: 2.8424\n",
      "[5412/8000] D loss: 0.6280, G loss: 2.4149\n",
      "[5772/8000] D loss: 0.4606, G loss: 3.6743\n",
      "[6132/8000] D loss: 0.4970, G loss: 2.3510\n",
      "[6492/8000] D loss: 0.9074, G loss: 3.0355\n",
      "[6852/8000] D loss: 0.5630, G loss: 3.5475\n",
      "[7212/8000] D loss: 0.7047, G loss: 2.6504\n",
      "[7572/8000] D loss: 0.5275, G loss: 3.0121\n",
      "[7932/8000] D loss: 0.7459, G loss: 2.5873\n",
      "train error: \n",
      " D loss: 0.712918, G loss: 2.848290, D accuracy: 82.3%, cell accuracy: 97.5%, board accuracy: 6.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.607700, G loss: 4.127020, D accuracy: 84.8%, cell accuracy: 97.1%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8839, G loss: 2.4161\n",
      "[372/8000] D loss: 0.5158, G loss: 2.9865\n",
      "[732/8000] D loss: 0.2683, G loss: 4.2572\n",
      "[1092/8000] D loss: 0.6831, G loss: 2.7477\n",
      "[1452/8000] D loss: 1.0146, G loss: 2.6636\n",
      "[1812/8000] D loss: 0.5805, G loss: 4.4693\n",
      "[2172/8000] D loss: 0.3696, G loss: 5.0005\n",
      "[2532/8000] D loss: 0.7201, G loss: 3.0552\n",
      "[2892/8000] D loss: 0.7720, G loss: 3.2083\n",
      "[3252/8000] D loss: 0.6482, G loss: 2.8069\n",
      "[3612/8000] D loss: 0.3820, G loss: 4.9151\n",
      "[3972/8000] D loss: 0.5890, G loss: 4.3107\n",
      "[4332/8000] D loss: 0.7143, G loss: 3.5006\n",
      "[4692/8000] D loss: 1.0620, G loss: 2.4686\n",
      "[5052/8000] D loss: 0.9843, G loss: 2.5290\n",
      "[5412/8000] D loss: 0.7435, G loss: 3.3960\n",
      "[5772/8000] D loss: 0.5791, G loss: 3.6123\n",
      "[6132/8000] D loss: 1.1992, G loss: 2.4331\n",
      "[6492/8000] D loss: 0.6209, G loss: 5.5347\n",
      "[6852/8000] D loss: 0.6836, G loss: 2.1742\n",
      "[7212/8000] D loss: 0.6896, G loss: 4.2394\n",
      "[7572/8000] D loss: 0.8808, G loss: 2.5161\n",
      "[7932/8000] D loss: 0.7892, G loss: 1.5932\n",
      "train error: \n",
      " D loss: 0.746987, G loss: 2.643833, D accuracy: 81.6%, cell accuracy: 97.6%, board accuracy: 6.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.607307, G loss: 3.956440, D accuracy: 85.6%, cell accuracy: 97.2%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8940, G loss: 2.4662\n",
      "[372/8000] D loss: 0.6760, G loss: 2.4297\n",
      "[732/8000] D loss: 0.5847, G loss: 2.1219\n",
      "[1092/8000] D loss: 0.3462, G loss: 2.9794\n",
      "[1452/8000] D loss: 0.7915, G loss: 3.2005\n",
      "[1812/8000] D loss: 1.0751, G loss: 1.7946\n",
      "[2172/8000] D loss: 0.5487, G loss: 2.8831\n",
      "[2532/8000] D loss: 0.4835, G loss: 4.0590\n",
      "[2892/8000] D loss: 0.4400, G loss: 4.3944\n",
      "[3252/8000] D loss: 0.3362, G loss: 3.7483\n",
      "[3612/8000] D loss: 0.5203, G loss: 3.2562\n",
      "[3972/8000] D loss: 0.6795, G loss: 3.1024\n",
      "[4332/8000] D loss: 0.7568, G loss: 3.3627\n",
      "[4692/8000] D loss: 0.6091, G loss: 3.2371\n",
      "[5052/8000] D loss: 0.6623, G loss: 1.7587\n",
      "[5412/8000] D loss: 0.6792, G loss: 3.2139\n",
      "[5772/8000] D loss: 0.6719, G loss: 3.2210\n",
      "[6132/8000] D loss: 1.1228, G loss: 1.1528\n",
      "[6492/8000] D loss: 0.6049, G loss: 3.9275\n",
      "[6852/8000] D loss: 0.7821, G loss: 3.0259\n",
      "[7212/8000] D loss: 0.7035, G loss: 2.4964\n",
      "[7572/8000] D loss: 0.7399, G loss: 4.1239\n",
      "[7932/8000] D loss: 0.7636, G loss: 3.1635\n",
      "train error: \n",
      " D loss: 0.772624, G loss: 2.496475, D accuracy: 81.0%, cell accuracy: 97.6%, board accuracy: 6.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603936, G loss: 3.689516, D accuracy: 85.3%, cell accuracy: 97.1%, board accuracy: 3.7% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5072, G loss: 3.6858\n",
      "[372/8000] D loss: 0.9377, G loss: 1.9935\n",
      "[732/8000] D loss: 1.0898, G loss: 1.7961\n",
      "[1092/8000] D loss: 1.0537, G loss: 2.1256\n",
      "[1452/8000] D loss: 0.5590, G loss: 3.8203\n",
      "[1812/8000] D loss: 0.9577, G loss: 3.6046\n",
      "[2172/8000] D loss: 0.5423, G loss: 4.9321\n",
      "[2532/8000] D loss: 0.6085, G loss: 2.9757\n",
      "[2892/8000] D loss: 1.1035, G loss: 2.0054\n",
      "[3252/8000] D loss: 0.6902, G loss: 2.7854\n",
      "[3612/8000] D loss: 0.5976, G loss: 3.4893\n",
      "[3972/8000] D loss: 0.7314, G loss: 4.7346\n",
      "[4332/8000] D loss: 0.4596, G loss: 2.7888\n",
      "[4692/8000] D loss: 0.8981, G loss: 4.5561\n",
      "[5052/8000] D loss: 0.9481, G loss: 3.1245\n",
      "[5412/8000] D loss: 0.7318, G loss: 2.5077\n",
      "[5772/8000] D loss: 0.7307, G loss: 2.9330\n",
      "[6132/8000] D loss: 1.2715, G loss: 2.9436\n",
      "[6492/8000] D loss: 0.1651, G loss: 4.7504\n",
      "[6852/8000] D loss: 0.5846, G loss: 2.7949\n",
      "[7212/8000] D loss: 0.4725, G loss: 3.4758\n",
      "[7572/8000] D loss: 1.2036, G loss: 2.9002\n",
      "[7932/8000] D loss: 0.9320, G loss: 3.7114\n",
      "train error: \n",
      " D loss: 0.889832, G loss: 2.447973, D accuracy: 78.5%, cell accuracy: 97.6%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.654467, G loss: 3.816602, D accuracy: 84.6%, cell accuracy: 97.2%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6451, G loss: 3.3411\n",
      "[372/8000] D loss: 0.7809, G loss: 2.3517\n",
      "[732/8000] D loss: 0.5849, G loss: 4.8073\n",
      "[1092/8000] D loss: 0.9462, G loss: 3.7868\n",
      "[1452/8000] D loss: 0.9553, G loss: 2.2734\n",
      "[1812/8000] D loss: 1.0415, G loss: 2.6826\n",
      "[2172/8000] D loss: 0.8008, G loss: 2.9793\n",
      "[2532/8000] D loss: 0.6098, G loss: 3.1195\n",
      "[2892/8000] D loss: 0.6561, G loss: 3.5029\n",
      "[3252/8000] D loss: 1.0002, G loss: 1.8252\n",
      "[3612/8000] D loss: 0.5958, G loss: 3.9422\n",
      "[3972/8000] D loss: 0.4999, G loss: 2.7161\n",
      "[4332/8000] D loss: 0.6057, G loss: 3.5249\n",
      "[4692/8000] D loss: 0.3890, G loss: 4.1647\n",
      "[5052/8000] D loss: 1.1156, G loss: 1.8816\n",
      "[5412/8000] D loss: 0.8912, G loss: 3.3254\n",
      "[5772/8000] D loss: 0.9052, G loss: 2.4996\n",
      "[6132/8000] D loss: 0.4398, G loss: 4.8445\n",
      "[6492/8000] D loss: 0.8909, G loss: 2.4209\n",
      "[6852/8000] D loss: 0.6128, G loss: 2.8181\n",
      "[7212/8000] D loss: 0.4119, G loss: 4.2255\n",
      "[7572/8000] D loss: 0.3960, G loss: 2.7932\n",
      "[7932/8000] D loss: 1.0286, G loss: 1.9614\n",
      "train error: \n",
      " D loss: 0.749600, G loss: 3.483655, D accuracy: 80.1%, cell accuracy: 97.7%, board accuracy: 8.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.700338, G loss: 4.926414, D accuracy: 81.8%, cell accuracy: 97.2%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5756, G loss: 3.5098\n",
      "[372/8000] D loss: 0.7024, G loss: 2.8306\n",
      "[732/8000] D loss: 0.7251, G loss: 3.0152\n",
      "[1092/8000] D loss: 0.8187, G loss: 3.0246\n",
      "[1452/8000] D loss: 0.7912, G loss: 3.0267\n",
      "[1812/8000] D loss: 1.0158, G loss: 2.6793\n",
      "[2172/8000] D loss: 0.5563, G loss: 2.7519\n",
      "[2532/8000] D loss: 0.7988, G loss: 2.8072\n",
      "[2892/8000] D loss: 0.6547, G loss: 2.2606\n",
      "[3252/8000] D loss: 0.6901, G loss: 3.1840\n",
      "[3612/8000] D loss: 0.8270, G loss: 3.7451\n",
      "[3972/8000] D loss: 1.3631, G loss: 1.7899\n",
      "[4332/8000] D loss: 0.5318, G loss: 3.2015\n",
      "[4692/8000] D loss: 0.7377, G loss: 2.9866\n",
      "[5052/8000] D loss: 0.7317, G loss: 3.1655\n",
      "[5412/8000] D loss: 0.9192, G loss: 2.8766\n",
      "[5772/8000] D loss: 0.7465, G loss: 2.9751\n",
      "[6132/8000] D loss: 0.5351, G loss: 3.2514\n",
      "[6492/8000] D loss: 0.7523, G loss: 3.4237\n",
      "[6852/8000] D loss: 0.6552, G loss: 4.7617\n",
      "[7212/8000] D loss: 0.4445, G loss: 3.1067\n",
      "[7572/8000] D loss: 1.0319, G loss: 1.4402\n",
      "[7932/8000] D loss: 0.8698, G loss: 2.4976\n",
      "train error: \n",
      " D loss: 0.713336, G loss: 3.163152, D accuracy: 81.3%, cell accuracy: 97.7%, board accuracy: 8.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.645556, G loss: 4.498385, D accuracy: 84.0%, cell accuracy: 97.2%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5906, G loss: 3.4733\n",
      "[372/8000] D loss: 0.5921, G loss: 3.0223\n",
      "[732/8000] D loss: 0.7306, G loss: 2.7861\n",
      "[1092/8000] D loss: 0.3971, G loss: 4.9315\n",
      "[1452/8000] D loss: 0.6124, G loss: 3.2696\n",
      "[1812/8000] D loss: 1.0524, G loss: 3.4549\n",
      "[2172/8000] D loss: 0.8012, G loss: 2.6180\n",
      "[2532/8000] D loss: 0.6643, G loss: 3.8482\n",
      "[2892/8000] D loss: 0.8951, G loss: 2.7250\n",
      "[3252/8000] D loss: 0.8335, G loss: 2.5311\n",
      "[3612/8000] D loss: 0.8312, G loss: 2.4919\n",
      "[3972/8000] D loss: 0.7485, G loss: 4.7270\n",
      "[4332/8000] D loss: 0.8208, G loss: 2.5237\n",
      "[4692/8000] D loss: 0.6744, G loss: 5.1113\n",
      "[5052/8000] D loss: 0.5093, G loss: 3.2807\n",
      "[5412/8000] D loss: 0.5160, G loss: 3.4664\n",
      "[5772/8000] D loss: 0.8442, G loss: 3.0261\n",
      "[6132/8000] D loss: 0.7273, G loss: 2.9587\n",
      "[6492/8000] D loss: 0.5803, G loss: 4.3285\n",
      "[6852/8000] D loss: 0.6908, G loss: 3.7137\n",
      "[7212/8000] D loss: 0.7462, G loss: 4.4490\n",
      "[7572/8000] D loss: 0.5868, G loss: 3.4136\n",
      "[7932/8000] D loss: 0.9978, G loss: 3.0119\n",
      "train error: \n",
      " D loss: 0.953054, G loss: 3.746149, D accuracy: 74.6%, cell accuracy: 97.7%, board accuracy: 7.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.923608, G loss: 4.955805, D accuracy: 75.5%, cell accuracy: 97.2%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.3132, G loss: 1.7026\n",
      "[372/8000] D loss: 0.3530, G loss: 3.7501\n",
      "[732/8000] D loss: 0.7067, G loss: 3.7774\n",
      "[1092/8000] D loss: 0.9793, G loss: 0.9631\n",
      "[1452/8000] D loss: 0.5881, G loss: 2.4404\n",
      "[1812/8000] D loss: 0.4719, G loss: 3.9193\n",
      "[2172/8000] D loss: 0.8432, G loss: 2.2189\n",
      "[2532/8000] D loss: 0.6783, G loss: 2.4703\n",
      "[2892/8000] D loss: 0.6864, G loss: 2.9529\n",
      "[3252/8000] D loss: 0.6957, G loss: 2.4698\n",
      "[3612/8000] D loss: 0.6722, G loss: 5.2715\n",
      "[3972/8000] D loss: 0.8897, G loss: 2.3192\n",
      "[4332/8000] D loss: 0.6770, G loss: 2.2014\n",
      "[4692/8000] D loss: 0.8943, G loss: 2.6749\n",
      "[5052/8000] D loss: 0.7811, G loss: 1.9151\n",
      "[5412/8000] D loss: 0.5491, G loss: 2.9593\n",
      "[5772/8000] D loss: 0.9397, G loss: 2.6863\n",
      "[6132/8000] D loss: 0.7799, G loss: 2.8502\n",
      "[6492/8000] D loss: 0.9231, G loss: 1.3027\n",
      "[6852/8000] D loss: 0.7312, G loss: 2.4716\n",
      "[7212/8000] D loss: 0.3080, G loss: 4.9829\n",
      "[7572/8000] D loss: 0.5033, G loss: 4.4584\n",
      "[7932/8000] D loss: 0.4000, G loss: 3.5875\n",
      "train error: \n",
      " D loss: 0.707753, G loss: 2.974486, D accuracy: 82.3%, cell accuracy: 97.8%, board accuracy: 8.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.617583, G loss: 4.295941, D accuracy: 85.6%, cell accuracy: 97.3%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7484, G loss: 3.1923\n",
      "[372/8000] D loss: 0.9362, G loss: 3.9460\n",
      "[732/8000] D loss: 0.4773, G loss: 3.3655\n",
      "[1092/8000] D loss: 0.8350, G loss: 3.8732\n",
      "[1452/8000] D loss: 0.8433, G loss: 2.5981\n",
      "[1812/8000] D loss: 0.9107, G loss: 3.3013\n",
      "[2172/8000] D loss: 0.6663, G loss: 2.9545\n",
      "[2532/8000] D loss: 0.5736, G loss: 3.8801\n",
      "[2892/8000] D loss: 0.8281, G loss: 1.7565\n",
      "[3252/8000] D loss: 0.8257, G loss: 3.0546\n",
      "[3612/8000] D loss: 0.7320, G loss: 3.8230\n",
      "[3972/8000] D loss: 0.5385, G loss: 1.9786\n",
      "[4332/8000] D loss: 0.6467, G loss: 2.0442\n",
      "[4692/8000] D loss: 1.1143, G loss: 2.6128\n",
      "[5052/8000] D loss: 0.4489, G loss: 4.1994\n",
      "[5412/8000] D loss: 0.4273, G loss: 4.2120\n",
      "[5772/8000] D loss: 0.7886, G loss: 1.7358\n",
      "[6132/8000] D loss: 0.8467, G loss: 2.2123\n",
      "[6492/8000] D loss: 0.2462, G loss: 4.5845\n",
      "[6852/8000] D loss: 0.6000, G loss: 2.6425\n",
      "[7212/8000] D loss: 0.8028, G loss: 3.8375\n",
      "[7572/8000] D loss: 0.6892, G loss: 3.2938\n",
      "[7932/8000] D loss: 1.0003, G loss: 1.7358\n",
      "train error: \n",
      " D loss: 0.752329, G loss: 3.325836, D accuracy: 80.2%, cell accuracy: 97.7%, board accuracy: 8.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.680013, G loss: 4.694674, D accuracy: 82.3%, cell accuracy: 97.3%, board accuracy: 4.3% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9437, G loss: 3.1373\n",
      "[372/8000] D loss: 1.0011, G loss: 3.4469\n",
      "[732/8000] D loss: 0.6859, G loss: 3.8257\n",
      "[1092/8000] D loss: 0.3372, G loss: 4.2032\n",
      "[1452/8000] D loss: 0.6780, G loss: 2.5921\n",
      "[1812/8000] D loss: 0.7280, G loss: 2.4370\n",
      "[2172/8000] D loss: 0.9208, G loss: 4.3028\n",
      "[2532/8000] D loss: 0.7392, G loss: 4.3914\n",
      "[2892/8000] D loss: 0.4427, G loss: 2.9406\n",
      "[3252/8000] D loss: 0.7691, G loss: 3.1662\n",
      "[3612/8000] D loss: 0.8851, G loss: 2.1970\n",
      "[3972/8000] D loss: 0.9868, G loss: 2.3723\n",
      "[4332/8000] D loss: 0.6065, G loss: 3.5018\n",
      "[4692/8000] D loss: 1.1335, G loss: 2.8637\n",
      "[5052/8000] D loss: 0.7771, G loss: 3.9658\n",
      "[5412/8000] D loss: 0.9517, G loss: 1.9959\n",
      "[5772/8000] D loss: 1.2942, G loss: 1.6324\n",
      "[6132/8000] D loss: 0.8448, G loss: 1.4244\n",
      "[6492/8000] D loss: 0.6161, G loss: 2.7676\n",
      "[6852/8000] D loss: 0.6833, G loss: 4.0143\n",
      "[7212/8000] D loss: 0.7078, G loss: 2.6208\n",
      "[7572/8000] D loss: 0.5311, G loss: 3.1634\n",
      "[7932/8000] D loss: 0.6067, G loss: 3.2509\n",
      "train error: \n",
      " D loss: 0.721318, G loss: 3.135358, D accuracy: 81.1%, cell accuracy: 97.7%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.638341, G loss: 4.558890, D accuracy: 84.0%, cell accuracy: 97.3%, board accuracy: 4.9% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7336, G loss: 3.5663\n",
      "[372/8000] D loss: 0.6762, G loss: 3.6236\n",
      "[732/8000] D loss: 0.8385, G loss: 1.9687\n",
      "[1092/8000] D loss: 0.8501, G loss: 2.2342\n",
      "[1452/8000] D loss: 0.7055, G loss: 3.1341\n",
      "[1812/8000] D loss: 0.4381, G loss: 4.7662\n",
      "[2172/8000] D loss: 0.7515, G loss: 5.5064\n",
      "[2532/8000] D loss: 0.6973, G loss: 4.9129\n",
      "[2892/8000] D loss: 1.0312, G loss: 2.2082\n",
      "[3252/8000] D loss: 0.9987, G loss: 2.3688\n",
      "[3612/8000] D loss: 0.8182, G loss: 3.4990\n",
      "[3972/8000] D loss: 0.9565, G loss: 2.1237\n",
      "[4332/8000] D loss: 0.3722, G loss: 4.8711\n",
      "[4692/8000] D loss: 0.6170, G loss: 4.7016\n",
      "[5052/8000] D loss: 0.5804, G loss: 2.5959\n",
      "[5412/8000] D loss: 0.6022, G loss: 5.0328\n",
      "[5772/8000] D loss: 0.6022, G loss: 2.4945\n",
      "[6132/8000] D loss: 0.6737, G loss: 2.8598\n",
      "[6492/8000] D loss: 0.8958, G loss: 3.9719\n",
      "[6852/8000] D loss: 0.4613, G loss: 3.5084\n",
      "[7212/8000] D loss: 0.5373, G loss: 2.9062\n",
      "[7572/8000] D loss: 0.7018, G loss: 4.6470\n",
      "[7932/8000] D loss: 1.0276, G loss: 1.9720\n",
      "train error: \n",
      " D loss: 0.742178, G loss: 2.959050, D accuracy: 80.7%, cell accuracy: 97.8%, board accuracy: 9.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609873, G loss: 4.553926, D accuracy: 85.8%, cell accuracy: 97.3%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7821, G loss: 3.1812\n",
      "[372/8000] D loss: 0.4417, G loss: 4.3687\n",
      "[732/8000] D loss: 0.7908, G loss: 3.4958\n",
      "[1092/8000] D loss: 0.9930, G loss: 1.8500\n",
      "[1452/8000] D loss: 0.8316, G loss: 1.1614\n",
      "[1812/8000] D loss: 0.5607, G loss: 3.5900\n",
      "[2172/8000] D loss: 0.8278, G loss: 3.7749\n",
      "[2532/8000] D loss: 0.9442, G loss: 3.3896\n",
      "[2892/8000] D loss: 0.6681, G loss: 2.7766\n",
      "[3252/8000] D loss: 0.7187, G loss: 4.0676\n",
      "[3612/8000] D loss: 0.4640, G loss: 4.0832\n",
      "[3972/8000] D loss: 0.8062, G loss: 2.4983\n",
      "[4332/8000] D loss: 0.5732, G loss: 2.8365\n",
      "[4692/8000] D loss: 0.3291, G loss: 4.1320\n",
      "[5052/8000] D loss: 0.6466, G loss: 4.1737\n",
      "[5412/8000] D loss: 0.9930, G loss: 1.7147\n",
      "[5772/8000] D loss: 0.7563, G loss: 2.6414\n",
      "[6132/8000] D loss: 0.5794, G loss: 2.8713\n",
      "[6492/8000] D loss: 1.0075, G loss: 1.9715\n",
      "[6852/8000] D loss: 0.9399, G loss: 2.4485\n",
      "[7212/8000] D loss: 0.7057, G loss: 5.3734\n",
      "[7572/8000] D loss: 0.8765, G loss: 2.8361\n",
      "[7932/8000] D loss: 0.9045, G loss: 2.4624\n",
      "train error: \n",
      " D loss: 0.745260, G loss: 3.173217, D accuracy: 81.1%, cell accuracy: 97.8%, board accuracy: 10.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.657978, G loss: 4.662928, D accuracy: 84.4%, cell accuracy: 97.4%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6028, G loss: 3.0448\n",
      "[372/8000] D loss: 0.7522, G loss: 1.4487\n",
      "[732/8000] D loss: 0.9965, G loss: 3.2662\n",
      "[1092/8000] D loss: 0.6080, G loss: 2.9457\n",
      "[1452/8000] D loss: 0.7724, G loss: 3.7402\n",
      "[1812/8000] D loss: 0.6452, G loss: 2.6403\n",
      "[2172/8000] D loss: 1.0245, G loss: 3.5086\n",
      "[2532/8000] D loss: 0.6163, G loss: 3.5791\n",
      "[2892/8000] D loss: 0.5363, G loss: 3.4134\n",
      "[3252/8000] D loss: 0.5047, G loss: 3.8933\n",
      "[3612/8000] D loss: 0.9450, G loss: 1.8776\n",
      "[3972/8000] D loss: 0.6561, G loss: 2.8358\n",
      "[4332/8000] D loss: 0.5097, G loss: 3.4154\n",
      "[4692/8000] D loss: 0.7688, G loss: 2.9429\n",
      "[5052/8000] D loss: 0.7208, G loss: 3.8749\n",
      "[5412/8000] D loss: 0.7712, G loss: 2.2229\n",
      "[5772/8000] D loss: 1.0193, G loss: 5.0657\n",
      "[6132/8000] D loss: 0.5177, G loss: 2.9651\n",
      "[6492/8000] D loss: 0.6020, G loss: 3.5550\n",
      "[6852/8000] D loss: 0.9276, G loss: 1.9965\n",
      "[7212/8000] D loss: 0.7971, G loss: 3.0962\n",
      "[7572/8000] D loss: 0.6709, G loss: 3.2007\n",
      "[7932/8000] D loss: 0.9184, G loss: 1.7765\n",
      "train error: \n",
      " D loss: 0.725823, G loss: 2.842557, D accuracy: 81.6%, cell accuracy: 97.8%, board accuracy: 10.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.601243, G loss: 4.303830, D accuracy: 85.5%, cell accuracy: 97.4%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5590, G loss: 2.3398\n",
      "[372/8000] D loss: 0.6899, G loss: 2.5755\n",
      "[732/8000] D loss: 0.5941, G loss: 3.8621\n",
      "[1092/8000] D loss: 1.0765, G loss: 2.9055\n",
      "[1452/8000] D loss: 1.3765, G loss: 1.6401\n",
      "[1812/8000] D loss: 0.5748, G loss: 4.2511\n",
      "[2172/8000] D loss: 0.5057, G loss: 3.6363\n",
      "[2532/8000] D loss: 0.5990, G loss: 3.4674\n",
      "[2892/8000] D loss: 0.5023, G loss: 3.5893\n",
      "[3252/8000] D loss: 0.9426, G loss: 3.7932\n",
      "[3612/8000] D loss: 0.9393, G loss: 2.4588\n",
      "[3972/8000] D loss: 0.6909, G loss: 4.1798\n",
      "[4332/8000] D loss: 0.8370, G loss: 3.1632\n",
      "[4692/8000] D loss: 0.7402, G loss: 2.3170\n",
      "[5052/8000] D loss: 0.5880, G loss: 2.9415\n",
      "[5412/8000] D loss: 0.9466, G loss: 2.5478\n",
      "[5772/8000] D loss: 0.8621, G loss: 2.3457\n",
      "[6132/8000] D loss: 1.0492, G loss: 3.5580\n",
      "[6492/8000] D loss: 0.9249, G loss: 0.9350\n",
      "[6852/8000] D loss: 0.6041, G loss: 3.5453\n",
      "[7212/8000] D loss: 0.9056, G loss: 2.2359\n",
      "[7572/8000] D loss: 0.5647, G loss: 4.6242\n",
      "[7932/8000] D loss: 0.7208, G loss: 2.8132\n",
      "train error: \n",
      " D loss: 0.712572, G loss: 3.012494, D accuracy: 82.0%, cell accuracy: 97.8%, board accuracy: 10.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.618438, G loss: 4.551601, D accuracy: 85.5%, cell accuracy: 97.4%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0342, G loss: 2.5240\n",
      "[372/8000] D loss: 0.6054, G loss: 1.8769\n",
      "[732/8000] D loss: 0.5336, G loss: 3.5037\n",
      "[1092/8000] D loss: 0.7295, G loss: 2.5331\n",
      "[1452/8000] D loss: 0.7841, G loss: 3.6977\n",
      "[1812/8000] D loss: 0.5660, G loss: 4.1295\n",
      "[2172/8000] D loss: 0.6293, G loss: 4.6705\n",
      "[2532/8000] D loss: 0.7104, G loss: 2.9979\n",
      "[2892/8000] D loss: 0.4738, G loss: 4.1198\n",
      "[3252/8000] D loss: 0.3570, G loss: 4.3406\n",
      "[3612/8000] D loss: 0.8458, G loss: 3.8194\n",
      "[3972/8000] D loss: 0.6934, G loss: 4.6967\n",
      "[4332/8000] D loss: 0.5339, G loss: 4.2627\n",
      "[4692/8000] D loss: 0.6173, G loss: 2.8748\n",
      "[5052/8000] D loss: 0.4846, G loss: 4.4948\n",
      "[5412/8000] D loss: 0.7814, G loss: 5.7374\n",
      "[5772/8000] D loss: 0.4845, G loss: 4.8458\n",
      "[6132/8000] D loss: 1.3264, G loss: 0.6773\n",
      "[6492/8000] D loss: 0.9055, G loss: 2.1429\n",
      "[6852/8000] D loss: 1.0123, G loss: 2.2634\n",
      "[7212/8000] D loss: 0.5099, G loss: 4.9746\n",
      "[7572/8000] D loss: 0.4774, G loss: 3.4797\n",
      "[7932/8000] D loss: 0.7178, G loss: 2.7505\n",
      "train error: \n",
      " D loss: 0.787076, G loss: 2.425505, D accuracy: 79.7%, cell accuracy: 97.8%, board accuracy: 11.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.628083, G loss: 3.866245, D accuracy: 85.4%, cell accuracy: 97.4%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9637, G loss: 1.5293\n",
      "[372/8000] D loss: 0.7306, G loss: 3.0346\n",
      "[732/8000] D loss: 0.3174, G loss: 3.7250\n",
      "[1092/8000] D loss: 0.8133, G loss: 4.7537\n",
      "[1452/8000] D loss: 0.6357, G loss: 2.7630\n",
      "[1812/8000] D loss: 0.6701, G loss: 2.7614\n",
      "[2172/8000] D loss: 0.9187, G loss: 3.0692\n",
      "[2532/8000] D loss: 0.7813, G loss: 3.5200\n",
      "[2892/8000] D loss: 0.6225, G loss: 3.8790\n",
      "[3252/8000] D loss: 0.7326, G loss: 2.7275\n",
      "[3612/8000] D loss: 0.6459, G loss: 2.5542\n",
      "[3972/8000] D loss: 0.9577, G loss: 2.6634\n",
      "[4332/8000] D loss: 0.6945, G loss: 2.4601\n",
      "[4692/8000] D loss: 1.1642, G loss: 1.2208\n",
      "[5052/8000] D loss: 0.8570, G loss: 2.8898\n",
      "[5412/8000] D loss: 0.6806, G loss: 2.5465\n",
      "[5772/8000] D loss: 0.6546, G loss: 2.4420\n",
      "[6132/8000] D loss: 1.0641, G loss: 2.1640\n",
      "[6492/8000] D loss: 0.5005, G loss: 4.3470\n",
      "[6852/8000] D loss: 0.6870, G loss: 3.0777\n",
      "[7212/8000] D loss: 1.0157, G loss: 2.8855\n",
      "[7572/8000] D loss: 0.5298, G loss: 4.2379\n",
      "[7932/8000] D loss: 0.6258, G loss: 3.0961\n",
      "train error: \n",
      " D loss: 0.753457, G loss: 2.902238, D accuracy: 80.8%, cell accuracy: 97.8%, board accuracy: 10.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608459, G loss: 4.589601, D accuracy: 85.2%, cell accuracy: 97.4%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5554, G loss: 3.8884\n",
      "[372/8000] D loss: 0.7514, G loss: 2.2491\n",
      "[732/8000] D loss: 0.8630, G loss: 2.3821\n",
      "[1092/8000] D loss: 0.5748, G loss: 3.2158\n",
      "[1452/8000] D loss: 0.4202, G loss: 2.0698\n",
      "[1812/8000] D loss: 1.0526, G loss: 2.1562\n",
      "[2172/8000] D loss: 0.4078, G loss: 2.4104\n",
      "[2532/8000] D loss: 0.8751, G loss: 1.4982\n",
      "[2892/8000] D loss: 0.5241, G loss: 2.3418\n",
      "[3252/8000] D loss: 0.7345, G loss: 3.3284\n",
      "[3612/8000] D loss: 0.6680, G loss: 2.3176\n",
      "[3972/8000] D loss: 0.2471, G loss: 3.9495\n",
      "[4332/8000] D loss: 0.4281, G loss: 3.7091\n",
      "[4692/8000] D loss: 0.6183, G loss: 4.8263\n",
      "[5052/8000] D loss: 0.5897, G loss: 2.6625\n",
      "[5412/8000] D loss: 1.0013, G loss: 4.5298\n",
      "[5772/8000] D loss: 0.9706, G loss: 2.9301\n",
      "[6132/8000] D loss: 0.5966, G loss: 4.0357\n",
      "[6492/8000] D loss: 0.6925, G loss: 2.6894\n",
      "[6852/8000] D loss: 0.6021, G loss: 3.7419\n",
      "[7212/8000] D loss: 1.1026, G loss: 2.3046\n",
      "[7572/8000] D loss: 0.5987, G loss: 4.7294\n",
      "[7932/8000] D loss: 0.9853, G loss: 1.6790\n",
      "train error: \n",
      " D loss: 0.798304, G loss: 3.612061, D accuracy: 78.2%, cell accuracy: 97.9%, board accuracy: 11.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.770676, G loss: 5.208660, D accuracy: 78.9%, cell accuracy: 97.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7974, G loss: 3.3880\n",
      "[372/8000] D loss: 0.8446, G loss: 2.5970\n",
      "[732/8000] D loss: 0.6460, G loss: 3.0883\n",
      "[1092/8000] D loss: 0.7726, G loss: 2.7388\n",
      "[1452/8000] D loss: 0.7105, G loss: 2.4998\n",
      "[1812/8000] D loss: 0.9943, G loss: 2.3600\n",
      "[2172/8000] D loss: 0.5978, G loss: 5.3011\n",
      "[2532/8000] D loss: 0.8784, G loss: 2.9290\n",
      "[2892/8000] D loss: 0.5998, G loss: 4.1687\n",
      "[3252/8000] D loss: 0.5631, G loss: 3.3476\n",
      "[3612/8000] D loss: 0.8298, G loss: 2.4592\n",
      "[3972/8000] D loss: 0.6551, G loss: 2.9647\n",
      "[4332/8000] D loss: 0.6995, G loss: 3.9196\n",
      "[4692/8000] D loss: 0.8355, G loss: 4.2650\n",
      "[5052/8000] D loss: 0.4083, G loss: 4.1060\n",
      "[5412/8000] D loss: 0.8681, G loss: 1.6538\n",
      "[5772/8000] D loss: 1.0478, G loss: 4.0954\n",
      "[6132/8000] D loss: 0.8133, G loss: 3.6312\n",
      "[6492/8000] D loss: 0.6642, G loss: 3.7403\n",
      "[6852/8000] D loss: 0.2769, G loss: 5.0494\n",
      "[7212/8000] D loss: 0.5768, G loss: 4.7650\n",
      "[7572/8000] D loss: 0.8465, G loss: 2.2622\n",
      "[7932/8000] D loss: 1.0066, G loss: 2.2669\n",
      "train error: \n",
      " D loss: 0.807188, G loss: 2.693225, D accuracy: 79.8%, cell accuracy: 97.9%, board accuracy: 11.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609610, G loss: 4.283522, D accuracy: 85.4%, cell accuracy: 97.4%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6896, G loss: 3.1184\n",
      "[372/8000] D loss: 0.8210, G loss: 3.3908\n",
      "[732/8000] D loss: 0.6828, G loss: 3.9521\n",
      "[1092/8000] D loss: 0.7632, G loss: 1.7328\n",
      "[1452/8000] D loss: 0.8480, G loss: 1.8082\n",
      "[1812/8000] D loss: 1.1421, G loss: 3.5700\n",
      "[2172/8000] D loss: 0.6645, G loss: 2.8431\n",
      "[2532/8000] D loss: 0.9073, G loss: 3.2537\n",
      "[2892/8000] D loss: 0.9150, G loss: 1.8176\n",
      "[3252/8000] D loss: 0.6990, G loss: 1.8673\n",
      "[3612/8000] D loss: 0.6254, G loss: 2.7452\n",
      "[3972/8000] D loss: 1.0363, G loss: 1.6925\n",
      "[4332/8000] D loss: 0.5096, G loss: 4.3828\n",
      "[4692/8000] D loss: 0.7718, G loss: 4.1729\n",
      "[5052/8000] D loss: 0.6655, G loss: 5.5291\n",
      "[5412/8000] D loss: 1.0078, G loss: 2.6479\n",
      "[5772/8000] D loss: 0.5824, G loss: 3.8084\n",
      "[6132/8000] D loss: 1.1218, G loss: 3.4985\n",
      "[6492/8000] D loss: 0.5264, G loss: 6.1253\n",
      "[6852/8000] D loss: 0.9004, G loss: 1.8191\n",
      "[7212/8000] D loss: 0.9588, G loss: 2.1730\n",
      "[7572/8000] D loss: 0.4963, G loss: 2.8194\n",
      "[7932/8000] D loss: 0.4888, G loss: 3.8122\n",
      "train error: \n",
      " D loss: 0.741630, G loss: 2.991752, D accuracy: 80.8%, cell accuracy: 97.9%, board accuracy: 11.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.623662, G loss: 4.716149, D accuracy: 85.0%, cell accuracy: 97.5%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9229, G loss: 3.6204\n",
      "[372/8000] D loss: 0.5994, G loss: 2.8483\n",
      "[732/8000] D loss: 0.7946, G loss: 2.1696\n",
      "[1092/8000] D loss: 0.7569, G loss: 2.6474\n",
      "[1452/8000] D loss: 0.3966, G loss: 2.8143\n",
      "[1812/8000] D loss: 0.6278, G loss: 3.2879\n",
      "[2172/8000] D loss: 0.7472, G loss: 4.5508\n",
      "[2532/8000] D loss: 0.7630, G loss: 3.4268\n",
      "[2892/8000] D loss: 0.3109, G loss: 4.5628\n",
      "[3252/8000] D loss: 0.9087, G loss: 2.4860\n",
      "[3612/8000] D loss: 0.5981, G loss: 3.4536\n",
      "[3972/8000] D loss: 0.6666, G loss: 2.5851\n",
      "[4332/8000] D loss: 0.8750, G loss: 2.4198\n",
      "[4692/8000] D loss: 0.7860, G loss: 2.8749\n",
      "[5052/8000] D loss: 0.7705, G loss: 2.2190\n",
      "[5412/8000] D loss: 0.4076, G loss: 4.1057\n",
      "[5772/8000] D loss: 1.3301, G loss: 0.8565\n",
      "[6132/8000] D loss: 0.7923, G loss: 3.3044\n",
      "[6492/8000] D loss: 0.8565, G loss: 2.6733\n",
      "[6852/8000] D loss: 0.7373, G loss: 3.6303\n",
      "[7212/8000] D loss: 0.7927, G loss: 3.1158\n",
      "[7572/8000] D loss: 0.4393, G loss: 3.4792\n",
      "[7932/8000] D loss: 0.5887, G loss: 4.8452\n",
      "train error: \n",
      " D loss: 0.766990, G loss: 2.733703, D accuracy: 80.6%, cell accuracy: 97.9%, board accuracy: 11.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603675, G loss: 4.310576, D accuracy: 86.0%, cell accuracy: 97.5%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7305, G loss: 4.7065\n",
      "[372/8000] D loss: 0.4125, G loss: 3.7526\n",
      "[732/8000] D loss: 0.6602, G loss: 2.7772\n",
      "[1092/8000] D loss: 0.8647, G loss: 4.3402\n",
      "[1452/8000] D loss: 0.5198, G loss: 3.9910\n",
      "[1812/8000] D loss: 0.5285, G loss: 2.4310\n",
      "[2172/8000] D loss: 1.0084, G loss: 3.0727\n",
      "[2532/8000] D loss: 0.6316, G loss: 4.1733\n",
      "[2892/8000] D loss: 0.7108, G loss: 4.0390\n",
      "[3252/8000] D loss: 0.7942, G loss: 3.5608\n",
      "[3612/8000] D loss: 0.8056, G loss: 3.6037\n",
      "[3972/8000] D loss: 1.0224, G loss: 2.4812\n",
      "[4332/8000] D loss: 0.5726, G loss: 3.3904\n",
      "[4692/8000] D loss: 0.6908, G loss: 2.6677\n",
      "[5052/8000] D loss: 0.6738, G loss: 3.7773\n",
      "[5412/8000] D loss: 0.8265, G loss: 2.3487\n",
      "[5772/8000] D loss: 0.6981, G loss: 4.3597\n",
      "[6132/8000] D loss: 0.8165, G loss: 4.2610\n",
      "[6492/8000] D loss: 0.5655, G loss: 3.2801\n",
      "[6852/8000] D loss: 0.5636, G loss: 3.4471\n",
      "[7212/8000] D loss: 0.5174, G loss: 5.9842\n",
      "[7572/8000] D loss: 0.9035, G loss: 1.8532\n",
      "[7932/8000] D loss: 0.5134, G loss: 4.6057\n",
      "train error: \n",
      " D loss: 0.745638, G loss: 3.212896, D accuracy: 80.1%, cell accuracy: 97.9%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.662034, G loss: 4.872156, D accuracy: 82.9%, cell accuracy: 97.5%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7635, G loss: 2.1991\n",
      "[372/8000] D loss: 0.6473, G loss: 3.4219\n",
      "[732/8000] D loss: 0.8536, G loss: 2.0790\n",
      "[1092/8000] D loss: 0.3489, G loss: 5.9270\n",
      "[1452/8000] D loss: 0.8376, G loss: 2.4263\n",
      "[1812/8000] D loss: 0.7357, G loss: 2.7450\n",
      "[2172/8000] D loss: 0.8590, G loss: 2.8996\n",
      "[2532/8000] D loss: 1.2280, G loss: 1.5027\n",
      "[2892/8000] D loss: 0.7048, G loss: 2.4904\n",
      "[3252/8000] D loss: 0.9006, G loss: 3.8472\n",
      "[3612/8000] D loss: 0.4772, G loss: 3.7155\n",
      "[3972/8000] D loss: 0.7134, G loss: 3.1722\n",
      "[4332/8000] D loss: 0.6222, G loss: 4.1165\n",
      "[4692/8000] D loss: 0.8491, G loss: 2.7751\n",
      "[5052/8000] D loss: 0.6307, G loss: 3.2783\n",
      "[5412/8000] D loss: 0.9284, G loss: 2.2317\n",
      "[5772/8000] D loss: 0.9483, G loss: 1.4872\n",
      "[6132/8000] D loss: 1.2689, G loss: 1.1652\n",
      "[6492/8000] D loss: 0.9310, G loss: 3.5025\n",
      "[6852/8000] D loss: 0.4316, G loss: 4.9461\n",
      "[7212/8000] D loss: 1.0173, G loss: 2.9539\n",
      "[7572/8000] D loss: 0.9278, G loss: 3.2977\n",
      "[7932/8000] D loss: 0.6816, G loss: 2.4148\n",
      "train error: \n",
      " D loss: 0.722655, G loss: 3.248326, D accuracy: 81.3%, cell accuracy: 97.9%, board accuracy: 12.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626470, G loss: 5.106574, D accuracy: 84.2%, cell accuracy: 97.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9478, G loss: 3.1032\n",
      "[372/8000] D loss: 0.6371, G loss: 3.9887\n",
      "[732/8000] D loss: 0.7313, G loss: 2.9286\n",
      "[1092/8000] D loss: 0.2671, G loss: 5.2713\n",
      "[1452/8000] D loss: 0.5423, G loss: 3.1272\n",
      "[1812/8000] D loss: 0.7852, G loss: 3.0979\n",
      "[2172/8000] D loss: 0.8111, G loss: 2.0196\n",
      "[2532/8000] D loss: 0.6430, G loss: 5.0252\n",
      "[2892/8000] D loss: 0.4630, G loss: 4.4155\n",
      "[3252/8000] D loss: 0.5635, G loss: 4.0930\n",
      "[3612/8000] D loss: 1.3218, G loss: 3.0562\n",
      "[3972/8000] D loss: 0.8479, G loss: 2.6559\n",
      "[4332/8000] D loss: 0.7134, G loss: 2.6935\n",
      "[4692/8000] D loss: 0.6789, G loss: 3.4462\n",
      "[5052/8000] D loss: 1.0178, G loss: 2.5455\n",
      "[5412/8000] D loss: 0.9833, G loss: 2.1018\n",
      "[5772/8000] D loss: 0.9865, G loss: 2.2419\n",
      "[6132/8000] D loss: 0.6301, G loss: 2.6951\n",
      "[6492/8000] D loss: 0.4366, G loss: 3.9286\n",
      "[6852/8000] D loss: 0.6403, G loss: 2.9310\n",
      "[7212/8000] D loss: 0.7603, G loss: 2.5092\n",
      "[7572/8000] D loss: 0.6309, G loss: 3.2996\n",
      "[7932/8000] D loss: 0.7665, G loss: 2.3040\n",
      "train error: \n",
      " D loss: 0.761318, G loss: 3.051085, D accuracy: 80.3%, cell accuracy: 98.0%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609658, G loss: 4.896757, D accuracy: 84.6%, cell accuracy: 97.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8604, G loss: 3.0013\n",
      "[372/8000] D loss: 0.9179, G loss: 1.5872\n",
      "[732/8000] D loss: 0.7143, G loss: 3.4153\n",
      "[1092/8000] D loss: 1.1018, G loss: 1.5796\n",
      "[1452/8000] D loss: 0.3497, G loss: 4.1106\n",
      "[1812/8000] D loss: 0.8096, G loss: 3.9044\n",
      "[2172/8000] D loss: 0.6626, G loss: 2.4384\n",
      "[2532/8000] D loss: 0.9793, G loss: 1.4335\n",
      "[2892/8000] D loss: 0.8493, G loss: 1.6854\n",
      "[3252/8000] D loss: 0.8653, G loss: 2.6084\n",
      "[3612/8000] D loss: 0.6534, G loss: 3.0336\n",
      "[3972/8000] D loss: 0.5531, G loss: 4.5150\n",
      "[4332/8000] D loss: 1.1513, G loss: 2.1319\n",
      "[4692/8000] D loss: 0.6198, G loss: 2.7429\n",
      "[5052/8000] D loss: 1.1344, G loss: 1.9290\n",
      "[5412/8000] D loss: 0.9211, G loss: 1.8726\n",
      "[5772/8000] D loss: 0.8850, G loss: 3.4793\n",
      "[6132/8000] D loss: 1.0163, G loss: 1.8765\n",
      "[6492/8000] D loss: 0.7123, G loss: 4.2446\n",
      "[6852/8000] D loss: 0.6622, G loss: 2.4657\n",
      "[7212/8000] D loss: 0.9305, G loss: 2.2561\n",
      "[7572/8000] D loss: 0.7824, G loss: 1.9213\n",
      "[7932/8000] D loss: 0.9627, G loss: 2.6670\n",
      "train error: \n",
      " D loss: 0.788232, G loss: 2.699164, D accuracy: 79.8%, cell accuracy: 98.0%, board accuracy: 13.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.597526, G loss: 4.571164, D accuracy: 85.7%, cell accuracy: 97.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0083, G loss: 2.3309\n",
      "[372/8000] D loss: 1.0362, G loss: 2.2541\n",
      "[732/8000] D loss: 0.8934, G loss: 2.3269\n",
      "[1092/8000] D loss: 0.6669, G loss: 2.7082\n",
      "[1452/8000] D loss: 0.7627, G loss: 3.5508\n",
      "[1812/8000] D loss: 0.7064, G loss: 4.2950\n",
      "[2172/8000] D loss: 0.6292, G loss: 4.2708\n",
      "[2532/8000] D loss: 0.7726, G loss: 3.1442\n",
      "[2892/8000] D loss: 0.5566, G loss: 3.5122\n",
      "[3252/8000] D loss: 0.8051, G loss: 5.0495\n",
      "[3612/8000] D loss: 0.7807, G loss: 3.3441\n",
      "[3972/8000] D loss: 0.5432, G loss: 1.7166\n",
      "[4332/8000] D loss: 0.6286, G loss: 5.2589\n",
      "[4692/8000] D loss: 1.0215, G loss: 1.4247\n",
      "[5052/8000] D loss: 0.7848, G loss: 4.7612\n",
      "[5412/8000] D loss: 0.5669, G loss: 4.5013\n",
      "[5772/8000] D loss: 0.7914, G loss: 2.3457\n",
      "[6132/8000] D loss: 0.7686, G loss: 3.6608\n",
      "[6492/8000] D loss: 0.6066, G loss: 2.7200\n",
      "[6852/8000] D loss: 0.9209, G loss: 3.1596\n",
      "[7212/8000] D loss: 0.5059, G loss: 2.5764\n",
      "[7572/8000] D loss: 0.8266, G loss: 1.9422\n",
      "[7932/8000] D loss: 0.8448, G loss: 2.5812\n",
      "train error: \n",
      " D loss: 0.755457, G loss: 3.626884, D accuracy: 79.4%, cell accuracy: 97.9%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.699293, G loss: 5.458130, D accuracy: 81.3%, cell accuracy: 97.5%, board accuracy: 7.6% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7066, G loss: 3.1193\n",
      "[372/8000] D loss: 0.4268, G loss: 4.0245\n",
      "[732/8000] D loss: 0.9592, G loss: 1.9988\n",
      "[1092/8000] D loss: 0.6897, G loss: 2.3800\n",
      "[1452/8000] D loss: 0.3419, G loss: 4.3677\n",
      "[1812/8000] D loss: 0.6218, G loss: 3.1344\n",
      "[2172/8000] D loss: 0.6427, G loss: 3.9945\n",
      "[2532/8000] D loss: 0.5412, G loss: 3.9787\n",
      "[2892/8000] D loss: 0.6212, G loss: 3.4072\n",
      "[3252/8000] D loss: 1.2074, G loss: 2.8844\n",
      "[3612/8000] D loss: 0.5066, G loss: 3.6242\n",
      "[3972/8000] D loss: 0.5435, G loss: 2.7849\n",
      "[4332/8000] D loss: 0.7751, G loss: 4.4706\n",
      "[4692/8000] D loss: 0.6664, G loss: 3.3769\n",
      "[5052/8000] D loss: 0.7649, G loss: 2.1971\n",
      "[5412/8000] D loss: 0.6234, G loss: 3.0032\n",
      "[5772/8000] D loss: 0.5862, G loss: 3.9613\n",
      "[6132/8000] D loss: 0.6686, G loss: 2.1678\n",
      "[6492/8000] D loss: 1.0892, G loss: 1.1333\n",
      "[6852/8000] D loss: 0.5098, G loss: 3.7660\n",
      "[7212/8000] D loss: 0.8603, G loss: 3.5679\n",
      "[7572/8000] D loss: 0.6934, G loss: 4.3145\n",
      "[7932/8000] D loss: 0.5863, G loss: 3.5301\n",
      "train error: \n",
      " D loss: 0.770291, G loss: 2.688792, D accuracy: 80.0%, cell accuracy: 98.0%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.607230, G loss: 4.441208, D accuracy: 86.2%, cell accuracy: 97.5%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8919, G loss: 2.5001\n",
      "[372/8000] D loss: 0.7121, G loss: 2.6056\n",
      "[732/8000] D loss: 0.7323, G loss: 2.2855\n",
      "[1092/8000] D loss: 0.7034, G loss: 4.9224\n",
      "[1452/8000] D loss: 0.5734, G loss: 2.8851\n",
      "[1812/8000] D loss: 0.8183, G loss: 2.3409\n",
      "[2172/8000] D loss: 0.8685, G loss: 2.3710\n",
      "[2532/8000] D loss: 0.8046, G loss: 3.3976\n",
      "[2892/8000] D loss: 0.8335, G loss: 4.3876\n",
      "[3252/8000] D loss: 0.8268, G loss: 2.6913\n",
      "[3612/8000] D loss: 0.9764, G loss: 2.4669\n",
      "[3972/8000] D loss: 0.8718, G loss: 2.5352\n",
      "[4332/8000] D loss: 0.9849, G loss: 3.2239\n",
      "[4692/8000] D loss: 0.4114, G loss: 6.2180\n",
      "[5052/8000] D loss: 0.5142, G loss: 4.3656\n",
      "[5412/8000] D loss: 0.9184, G loss: 2.9639\n",
      "[5772/8000] D loss: 0.6986, G loss: 3.1593\n",
      "[6132/8000] D loss: 0.7827, G loss: 3.3408\n",
      "[6492/8000] D loss: 0.6914, G loss: 2.5207\n",
      "[6852/8000] D loss: 0.8264, G loss: 2.4349\n",
      "[7212/8000] D loss: 0.5266, G loss: 3.3554\n",
      "[7572/8000] D loss: 0.7901, G loss: 2.8866\n",
      "[7932/8000] D loss: 0.8717, G loss: 3.5201\n",
      "train error: \n",
      " D loss: 0.809065, G loss: 3.738813, D accuracy: 76.8%, cell accuracy: 98.0%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.768337, G loss: 5.609850, D accuracy: 78.5%, cell accuracy: 97.5%, board accuracy: 8.2% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7660, G loss: 2.8917\n",
      "[372/8000] D loss: 0.9700, G loss: 1.8665\n",
      "[732/8000] D loss: 0.6266, G loss: 3.1729\n",
      "[1092/8000] D loss: 0.7180, G loss: 4.4542\n",
      "[1452/8000] D loss: 0.7435, G loss: 1.9532\n",
      "[1812/8000] D loss: 0.7055, G loss: 2.2601\n",
      "[2172/8000] D loss: 0.6973, G loss: 3.3735\n",
      "[2532/8000] D loss: 0.4998, G loss: 3.9377\n",
      "[2892/8000] D loss: 0.8344, G loss: 3.8145\n",
      "[3252/8000] D loss: 0.9024, G loss: 2.7973\n",
      "[3612/8000] D loss: 0.4460, G loss: 3.8777\n",
      "[3972/8000] D loss: 1.1158, G loss: 2.5216\n",
      "[4332/8000] D loss: 1.0667, G loss: 2.7865\n",
      "[4692/8000] D loss: 0.8244, G loss: 2.8565\n",
      "[5052/8000] D loss: 0.7676, G loss: 3.4630\n",
      "[5412/8000] D loss: 0.9197, G loss: 3.8747\n",
      "[5772/8000] D loss: 0.8037, G loss: 3.6914\n",
      "[6132/8000] D loss: 0.7171, G loss: 2.4978\n",
      "[6492/8000] D loss: 0.7787, G loss: 2.0451\n",
      "[6852/8000] D loss: 0.6375, G loss: 4.1753\n",
      "[7212/8000] D loss: 0.6965, G loss: 3.7696\n",
      "[7572/8000] D loss: 0.6037, G loss: 3.5074\n",
      "[7932/8000] D loss: 0.7989, G loss: 1.7140\n",
      "train error: \n",
      " D loss: 0.755029, G loss: 3.232091, D accuracy: 79.5%, cell accuracy: 98.0%, board accuracy: 14.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.671495, G loss: 5.195278, D accuracy: 82.5%, cell accuracy: 97.6%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8673, G loss: 3.0003\n",
      "[372/8000] D loss: 0.6745, G loss: 4.0759\n",
      "[732/8000] D loss: 0.5944, G loss: 4.2237\n",
      "[1092/8000] D loss: 0.7665, G loss: 3.0724\n",
      "[1452/8000] D loss: 0.3907, G loss: 4.5380\n",
      "[1812/8000] D loss: 1.0273, G loss: 1.9111\n",
      "[2172/8000] D loss: 1.0026, G loss: 2.3407\n",
      "[2532/8000] D loss: 0.9709, G loss: 1.6114\n",
      "[2892/8000] D loss: 0.9230, G loss: 2.2247\n",
      "[3252/8000] D loss: 0.7695, G loss: 3.1219\n",
      "[3612/8000] D loss: 0.6844, G loss: 3.6277\n",
      "[3972/8000] D loss: 0.7296, G loss: 1.9065\n",
      "[4332/8000] D loss: 0.7145, G loss: 3.8811\n",
      "[4692/8000] D loss: 0.5014, G loss: 3.9286\n",
      "[5052/8000] D loss: 0.4793, G loss: 4.3489\n",
      "[5412/8000] D loss: 0.7524, G loss: 2.9238\n",
      "[5772/8000] D loss: 0.7418, G loss: 2.9651\n",
      "[6132/8000] D loss: 0.7218, G loss: 3.1765\n",
      "[6492/8000] D loss: 0.3857, G loss: 4.9391\n",
      "[6852/8000] D loss: 0.6933, G loss: 2.8393\n",
      "[7212/8000] D loss: 0.6254, G loss: 3.2565\n",
      "[7572/8000] D loss: 0.5913, G loss: 2.1465\n",
      "[7932/8000] D loss: 0.8530, G loss: 2.8371\n",
      "train error: \n",
      " D loss: 0.792872, G loss: 2.655207, D accuracy: 79.1%, cell accuracy: 98.0%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.594956, G loss: 4.500211, D accuracy: 85.5%, cell accuracy: 97.6%, board accuracy: 8.7% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0468, G loss: 2.4200\n",
      "[372/8000] D loss: 0.5794, G loss: 4.3081\n",
      "[732/8000] D loss: 0.5261, G loss: 4.8468\n",
      "[1092/8000] D loss: 0.5443, G loss: 4.4096\n",
      "[1452/8000] D loss: 1.0766, G loss: 2.9797\n",
      "[1812/8000] D loss: 0.6127, G loss: 4.7666\n",
      "[2172/8000] D loss: 1.0118, G loss: 2.4851\n",
      "[2532/8000] D loss: 0.7924, G loss: 3.7576\n",
      "[2892/8000] D loss: 0.7336, G loss: 3.1417\n",
      "[3252/8000] D loss: 0.4613, G loss: 4.2227\n",
      "[3612/8000] D loss: 0.9711, G loss: 2.2197\n",
      "[3972/8000] D loss: 0.5758, G loss: 4.6602\n",
      "[4332/8000] D loss: 0.9606, G loss: 3.7716\n",
      "[4692/8000] D loss: 0.8525, G loss: 4.2954\n",
      "[5052/8000] D loss: 0.4798, G loss: 4.3470\n",
      "[5412/8000] D loss: 0.9463, G loss: 2.0782\n",
      "[5772/8000] D loss: 0.9167, G loss: 1.7287\n",
      "[6132/8000] D loss: 0.6066, G loss: 2.2115\n",
      "[6492/8000] D loss: 0.6137, G loss: 3.7453\n",
      "[6852/8000] D loss: 0.9898, G loss: 2.3340\n",
      "[7212/8000] D loss: 0.8815, G loss: 2.9624\n",
      "[7572/8000] D loss: 0.5327, G loss: 4.4710\n",
      "[7932/8000] D loss: 0.8480, G loss: 1.8135\n",
      "train error: \n",
      " D loss: 0.765296, G loss: 2.760676, D accuracy: 80.7%, cell accuracy: 98.0%, board accuracy: 13.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.588791, G loss: 4.781862, D accuracy: 86.7%, cell accuracy: 97.6%, board accuracy: 7.6% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8335, G loss: 3.2313\n",
      "[372/8000] D loss: 1.0152, G loss: 2.5001\n",
      "[732/8000] D loss: 0.7002, G loss: 2.6358\n",
      "[1092/8000] D loss: 0.5390, G loss: 3.9136\n",
      "[1452/8000] D loss: 1.2137, G loss: 2.2771\n",
      "[1812/8000] D loss: 0.5703, G loss: 5.2281\n",
      "[2172/8000] D loss: 0.9048, G loss: 2.5091\n",
      "[2532/8000] D loss: 0.5425, G loss: 3.7707\n",
      "[2892/8000] D loss: 0.8633, G loss: 2.8185\n",
      "[3252/8000] D loss: 0.9030, G loss: 2.0563\n",
      "[3612/8000] D loss: 0.5483, G loss: 4.0599\n",
      "[3972/8000] D loss: 0.4056, G loss: 4.7620\n",
      "[4332/8000] D loss: 0.7278, G loss: 3.4041\n",
      "[4692/8000] D loss: 0.4627, G loss: 4.1159\n",
      "[5052/8000] D loss: 1.0934, G loss: 1.9042\n",
      "[5412/8000] D loss: 0.4474, G loss: 4.6745\n",
      "[5772/8000] D loss: 0.5317, G loss: 4.0428\n",
      "[6132/8000] D loss: 1.0256, G loss: 1.3821\n",
      "[6492/8000] D loss: 0.7183, G loss: 3.1808\n",
      "[6852/8000] D loss: 0.8762, G loss: 3.4139\n",
      "[7212/8000] D loss: 0.6110, G loss: 3.9193\n",
      "[7572/8000] D loss: 0.6126, G loss: 3.7628\n",
      "[7932/8000] D loss: 0.7462, G loss: 2.8209\n",
      "train error: \n",
      " D loss: 0.767414, G loss: 3.315681, D accuracy: 79.8%, cell accuracy: 98.0%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.691295, G loss: 5.306094, D accuracy: 82.1%, cell accuracy: 97.6%, board accuracy: 8.7% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9265, G loss: 2.9583\n",
      "[372/8000] D loss: 1.0997, G loss: 1.4176\n",
      "[732/8000] D loss: 0.5712, G loss: 5.6895\n",
      "[1092/8000] D loss: 0.8475, G loss: 2.8033\n",
      "[1452/8000] D loss: 0.7030, G loss: 3.2162\n",
      "[1812/8000] D loss: 1.1031, G loss: 2.1315\n",
      "[2172/8000] D loss: 0.6437, G loss: 5.2397\n",
      "[2532/8000] D loss: 0.7151, G loss: 4.3448\n",
      "[2892/8000] D loss: 0.5622, G loss: 4.2179\n",
      "[3252/8000] D loss: 0.8324, G loss: 1.8842\n",
      "[3612/8000] D loss: 0.4066, G loss: 6.8452\n",
      "[3972/8000] D loss: 0.6648, G loss: 3.2656\n",
      "[4332/8000] D loss: 0.6546, G loss: 3.7019\n",
      "[4692/8000] D loss: 0.6888, G loss: 2.8231\n",
      "[5052/8000] D loss: 0.7804, G loss: 5.3991\n",
      "[5412/8000] D loss: 0.7143, G loss: 3.5224\n",
      "[5772/8000] D loss: 0.5840, G loss: 4.9771\n",
      "[6132/8000] D loss: 0.8297, G loss: 2.6085\n",
      "[6492/8000] D loss: 0.9108, G loss: 1.7557\n",
      "[6852/8000] D loss: 0.7713, G loss: 2.4225\n",
      "[7212/8000] D loss: 0.6231, G loss: 5.1842\n",
      "[7572/8000] D loss: 0.5306, G loss: 3.9706\n",
      "[7932/8000] D loss: 0.6605, G loss: 4.5293\n",
      "train error: \n",
      " D loss: 0.847281, G loss: 2.440456, D accuracy: 78.6%, cell accuracy: 98.1%, board accuracy: 15.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.641834, G loss: 4.350305, D accuracy: 84.5%, cell accuracy: 97.6%, board accuracy: 9.8% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8359, G loss: 2.4427\n",
      "[372/8000] D loss: 1.1540, G loss: 1.2675\n",
      "[732/8000] D loss: 0.5088, G loss: 4.4625\n",
      "[1092/8000] D loss: 0.9329, G loss: 2.7806\n",
      "[1452/8000] D loss: 0.8599, G loss: 2.0750\n",
      "[1812/8000] D loss: 0.6800, G loss: 2.8567\n",
      "[2172/8000] D loss: 0.7546, G loss: 2.3225\n",
      "[2532/8000] D loss: 0.6827, G loss: 2.7045\n",
      "[2892/8000] D loss: 0.7924, G loss: 2.4564\n",
      "[3252/8000] D loss: 0.6705, G loss: 3.5542\n",
      "[3612/8000] D loss: 0.9476, G loss: 1.9004\n",
      "[3972/8000] D loss: 0.7515, G loss: 2.5040\n",
      "[4332/8000] D loss: 0.3478, G loss: 6.2614\n",
      "[4692/8000] D loss: 0.7146, G loss: 2.6145\n",
      "[5052/8000] D loss: 0.9508, G loss: 2.8351\n",
      "[5412/8000] D loss: 0.6419, G loss: 4.5929\n",
      "[5772/8000] D loss: 0.7099, G loss: 2.7301\n",
      "[6132/8000] D loss: 0.5440, G loss: 3.9292\n",
      "[6492/8000] D loss: 0.5315, G loss: 3.3998\n",
      "[6852/8000] D loss: 0.6909, G loss: 3.1103\n",
      "[7212/8000] D loss: 0.8540, G loss: 2.9240\n",
      "[7572/8000] D loss: 0.7537, G loss: 4.2198\n",
      "[7932/8000] D loss: 0.5255, G loss: 4.4367\n",
      "train error: \n",
      " D loss: 0.773841, G loss: 3.214265, D accuracy: 79.0%, cell accuracy: 98.1%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.709246, G loss: 5.214599, D accuracy: 81.3%, cell accuracy: 97.7%, board accuracy: 9.7% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9932, G loss: 2.5728\n",
      "[372/8000] D loss: 0.7166, G loss: 3.5431\n",
      "[732/8000] D loss: 0.5217, G loss: 4.3693\n",
      "[1092/8000] D loss: 0.7668, G loss: 3.6712\n",
      "[1452/8000] D loss: 1.0220, G loss: 1.3698\n",
      "[1812/8000] D loss: 0.4899, G loss: 3.4156\n",
      "[2172/8000] D loss: 0.4586, G loss: 3.7673\n",
      "[2532/8000] D loss: 0.6847, G loss: 3.1371\n",
      "[2892/8000] D loss: 0.8403, G loss: 3.4652\n",
      "[3252/8000] D loss: 0.3146, G loss: 4.4021\n",
      "[3612/8000] D loss: 0.4688, G loss: 3.8561\n",
      "[3972/8000] D loss: 0.8228, G loss: 2.3023\n",
      "[4332/8000] D loss: 0.8082, G loss: 3.8512\n",
      "[4692/8000] D loss: 0.7065, G loss: 2.3746\n",
      "[5052/8000] D loss: 0.7707, G loss: 2.9143\n",
      "[5412/8000] D loss: 0.9831, G loss: 3.7142\n",
      "[5772/8000] D loss: 0.3871, G loss: 4.2395\n",
      "[6132/8000] D loss: 0.7951, G loss: 3.2615\n",
      "[6492/8000] D loss: 0.6745, G loss: 2.0557\n",
      "[6852/8000] D loss: 0.5739, G loss: 3.2006\n",
      "[7212/8000] D loss: 1.2002, G loss: 2.9295\n",
      "[7572/8000] D loss: 0.9850, G loss: 4.1552\n",
      "[7932/8000] D loss: 0.5212, G loss: 4.5602\n",
      "train error: \n",
      " D loss: 0.784556, G loss: 2.904605, D accuracy: 79.5%, cell accuracy: 98.0%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.623814, G loss: 4.943553, D accuracy: 85.0%, cell accuracy: 97.6%, board accuracy: 9.6% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0022, G loss: 2.7911\n",
      "[372/8000] D loss: 0.4315, G loss: 3.6086\n",
      "[732/8000] D loss: 0.7725, G loss: 3.1526\n",
      "[1092/8000] D loss: 0.7207, G loss: 3.4966\n",
      "[1452/8000] D loss: 0.7467, G loss: 2.1247\n",
      "[1812/8000] D loss: 0.8704, G loss: 2.6257\n",
      "[2172/8000] D loss: 0.9461, G loss: 2.8044\n",
      "[2532/8000] D loss: 1.1706, G loss: 2.6336\n",
      "[2892/8000] D loss: 0.8373, G loss: 2.8383\n",
      "[3252/8000] D loss: 1.0370, G loss: 2.1721\n",
      "[3612/8000] D loss: 0.9089, G loss: 2.7789\n",
      "[3972/8000] D loss: 0.8455, G loss: 3.5212\n",
      "[4332/8000] D loss: 0.5368, G loss: 3.4756\n",
      "[4692/8000] D loss: 0.8282, G loss: 4.2444\n",
      "[5052/8000] D loss: 0.8158, G loss: 2.0258\n",
      "[5412/8000] D loss: 0.8672, G loss: 2.1660\n",
      "[5772/8000] D loss: 0.9857, G loss: 3.2935\n",
      "[6132/8000] D loss: 0.5809, G loss: 3.1259\n",
      "[6492/8000] D loss: 0.5839, G loss: 3.7274\n",
      "[6852/8000] D loss: 0.9996, G loss: 1.8708\n",
      "[7212/8000] D loss: 0.5866, G loss: 3.2762\n",
      "[7572/8000] D loss: 0.5797, G loss: 4.2862\n",
      "[7932/8000] D loss: 0.5850, G loss: 4.5630\n",
      "train error: \n",
      " D loss: 0.739235, G loss: 3.294806, D accuracy: 80.0%, cell accuracy: 98.1%, board accuracy: 17.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.657197, G loss: 5.393872, D accuracy: 83.6%, cell accuracy: 97.7%, board accuracy: 9.6% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8010, G loss: 2.4591\n",
      "[372/8000] D loss: 1.2784, G loss: 1.7596\n",
      "[732/8000] D loss: 0.9443, G loss: 2.7165\n",
      "[1092/8000] D loss: 0.6640, G loss: 2.9681\n",
      "[1452/8000] D loss: 0.6189, G loss: 2.7625\n",
      "[1812/8000] D loss: 0.6485, G loss: 2.3937\n",
      "[2172/8000] D loss: 0.6322, G loss: 2.9194\n",
      "[2532/8000] D loss: 0.4205, G loss: 5.1842\n",
      "[2892/8000] D loss: 0.9130, G loss: 2.1681\n",
      "[3252/8000] D loss: 0.5774, G loss: 3.4926\n",
      "[3612/8000] D loss: 0.8654, G loss: 2.9325\n",
      "[3972/8000] D loss: 0.9891, G loss: 1.5902\n",
      "[4332/8000] D loss: 0.6009, G loss: 4.1525\n",
      "[4692/8000] D loss: 0.7118, G loss: 3.7344\n",
      "[5052/8000] D loss: 0.7542, G loss: 2.9025\n",
      "[5412/8000] D loss: 0.5956, G loss: 3.0223\n",
      "[5772/8000] D loss: 0.5900, G loss: 3.8011\n",
      "[6132/8000] D loss: 0.3720, G loss: 3.5453\n",
      "[6492/8000] D loss: 0.5122, G loss: 4.0032\n",
      "[6852/8000] D loss: 1.1221, G loss: 3.0148\n",
      "[7212/8000] D loss: 0.7885, G loss: 4.2153\n",
      "[7572/8000] D loss: 0.7211, G loss: 2.6517\n",
      "[7932/8000] D loss: 0.5258, G loss: 4.5772\n",
      "train error: \n",
      " D loss: 0.756722, G loss: 2.981435, D accuracy: 80.3%, cell accuracy: 98.1%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.606477, G loss: 5.146782, D accuracy: 85.3%, cell accuracy: 97.7%, board accuracy: 9.6% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9198, G loss: 1.5682\n",
      "[372/8000] D loss: 0.6294, G loss: 3.0043\n",
      "[732/8000] D loss: 0.6758, G loss: 4.8810\n",
      "[1092/8000] D loss: 0.5586, G loss: 2.9664\n",
      "[1452/8000] D loss: 0.7060, G loss: 2.0584\n",
      "[1812/8000] D loss: 0.6476, G loss: 3.5043\n",
      "[2172/8000] D loss: 0.9748, G loss: 2.9996\n",
      "[2532/8000] D loss: 1.3146, G loss: 1.9261\n",
      "[2892/8000] D loss: 0.6232, G loss: 2.7119\n",
      "[3252/8000] D loss: 0.8154, G loss: 3.4601\n",
      "[3612/8000] D loss: 0.6215, G loss: 5.2209\n",
      "[3972/8000] D loss: 0.7860, G loss: 3.8882\n",
      "[4332/8000] D loss: 0.6198, G loss: 4.6481\n",
      "[4692/8000] D loss: 0.7263, G loss: 2.5928\n",
      "[5052/8000] D loss: 0.8273, G loss: 3.1119\n",
      "[5412/8000] D loss: 0.6468, G loss: 4.4773\n",
      "[5772/8000] D loss: 0.7668, G loss: 2.5728\n",
      "[6132/8000] D loss: 0.7790, G loss: 3.0384\n",
      "[6492/8000] D loss: 0.5927, G loss: 4.6216\n",
      "[6852/8000] D loss: 0.7684, G loss: 2.4550\n",
      "[7212/8000] D loss: 0.5884, G loss: 3.6945\n",
      "[7572/8000] D loss: 0.5201, G loss: 5.0866\n",
      "[7932/8000] D loss: 0.7127, G loss: 4.4844\n",
      "train error: \n",
      " D loss: 0.960578, G loss: 2.164611, D accuracy: 76.3%, cell accuracy: 98.1%, board accuracy: 18.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.652607, G loss: 4.174889, D accuracy: 84.3%, cell accuracy: 97.7%, board accuracy: 10.3% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8593, G loss: 1.9717\n",
      "[372/8000] D loss: 0.7184, G loss: 3.7049\n",
      "[732/8000] D loss: 0.9663, G loss: 1.9237\n",
      "[1092/8000] D loss: 0.6590, G loss: 3.8645\n",
      "[1452/8000] D loss: 0.9549, G loss: 2.3659\n",
      "[1812/8000] D loss: 0.4728, G loss: 3.5985\n",
      "[2172/8000] D loss: 1.0509, G loss: 2.7535\n",
      "[2532/8000] D loss: 0.9581, G loss: 1.6883\n",
      "[2892/8000] D loss: 0.6636, G loss: 4.0016\n",
      "[3252/8000] D loss: 0.4626, G loss: 2.7052\n",
      "[3612/8000] D loss: 0.7323, G loss: 4.1891\n",
      "[3972/8000] D loss: 0.6859, G loss: 4.2182\n",
      "[4332/8000] D loss: 0.6404, G loss: 3.1611\n",
      "[4692/8000] D loss: 0.5902, G loss: 4.3493\n",
      "[5052/8000] D loss: 1.1147, G loss: 3.2404\n",
      "[5412/8000] D loss: 0.8392, G loss: 3.0685\n",
      "[5772/8000] D loss: 0.4800, G loss: 4.3730\n",
      "[6132/8000] D loss: 0.6506, G loss: 4.0238\n",
      "[6492/8000] D loss: 0.5815, G loss: 2.9009\n",
      "[6852/8000] D loss: 0.6122, G loss: 3.1196\n",
      "[7212/8000] D loss: 0.8511, G loss: 4.1328\n",
      "[7572/8000] D loss: 0.7928, G loss: 2.6737\n",
      "[7932/8000] D loss: 0.6631, G loss: 4.6168\n",
      "train error: \n",
      " D loss: 0.746524, G loss: 3.489214, D accuracy: 80.2%, cell accuracy: 98.1%, board accuracy: 17.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.656353, G loss: 5.771305, D accuracy: 83.5%, cell accuracy: 97.6%, board accuracy: 9.3% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5322, G loss: 4.1123\n",
      "[372/8000] D loss: 1.0331, G loss: 1.3822\n",
      "[732/8000] D loss: 0.9412, G loss: 2.4446\n",
      "[1092/8000] D loss: 0.5064, G loss: 2.8758\n",
      "[1452/8000] D loss: 0.9870, G loss: 1.3914\n",
      "[1812/8000] D loss: 0.9775, G loss: 2.2576\n",
      "[2172/8000] D loss: 0.4362, G loss: 4.9168\n",
      "[2532/8000] D loss: 0.3482, G loss: 3.3828\n",
      "[2892/8000] D loss: 0.6476, G loss: 3.5183\n",
      "[3252/8000] D loss: 0.7341, G loss: 3.4577\n",
      "[3612/8000] D loss: 0.7225, G loss: 3.5821\n",
      "[3972/8000] D loss: 0.8188, G loss: 4.8913\n",
      "[4332/8000] D loss: 0.6817, G loss: 4.6137\n",
      "[4692/8000] D loss: 0.7835, G loss: 3.2436\n",
      "[5052/8000] D loss: 0.4726, G loss: 2.7335\n",
      "[5412/8000] D loss: 0.9479, G loss: 3.1039\n",
      "[5772/8000] D loss: 0.6457, G loss: 3.6350\n",
      "[6132/8000] D loss: 0.4958, G loss: 5.0235\n",
      "[6492/8000] D loss: 0.9406, G loss: 1.7505\n",
      "[6852/8000] D loss: 0.8311, G loss: 3.6718\n",
      "[7212/8000] D loss: 0.8716, G loss: 2.2647\n",
      "[7572/8000] D loss: 0.6704, G loss: 2.2600\n",
      "[7932/8000] D loss: 0.6197, G loss: 2.8802\n",
      "train error: \n",
      " D loss: 0.917273, G loss: 4.549292, D accuracy: 75.4%, cell accuracy: 98.1%, board accuracy: 17.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.921629, G loss: 6.837817, D accuracy: 75.9%, cell accuracy: 97.7%, board accuracy: 10.2% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8291, G loss: 3.3358\n",
      "[372/8000] D loss: 1.0905, G loss: 2.4955\n",
      "[732/8000] D loss: 0.5767, G loss: 2.4445\n",
      "[1092/8000] D loss: 0.6652, G loss: 5.1949\n",
      "[1452/8000] D loss: 0.4091, G loss: 4.2247\n",
      "[1812/8000] D loss: 0.8206, G loss: 1.5129\n",
      "[2172/8000] D loss: 0.5163, G loss: 4.3643\n",
      "[2532/8000] D loss: 0.7066, G loss: 3.1714\n",
      "[2892/8000] D loss: 0.7921, G loss: 4.0933\n",
      "[3252/8000] D loss: 0.6793, G loss: 2.7823\n",
      "[3612/8000] D loss: 0.6575, G loss: 3.3067\n",
      "[3972/8000] D loss: 0.8916, G loss: 1.7746\n",
      "[4332/8000] D loss: 0.7856, G loss: 3.5379\n",
      "[4692/8000] D loss: 0.7806, G loss: 3.7009\n",
      "[5052/8000] D loss: 0.9133, G loss: 1.8305\n",
      "[5412/8000] D loss: 0.9346, G loss: 1.7628\n",
      "[5772/8000] D loss: 0.5099, G loss: 2.7566\n",
      "[6132/8000] D loss: 0.5677, G loss: 4.1596\n",
      "[6492/8000] D loss: 1.0175, G loss: 3.2678\n",
      "[6852/8000] D loss: 0.5057, G loss: 3.2198\n",
      "[7212/8000] D loss: 1.0472, G loss: 1.5984\n",
      "[7572/8000] D loss: 1.0260, G loss: 1.5626\n",
      "[7932/8000] D loss: 0.6161, G loss: 2.0414\n",
      "train error: \n",
      " D loss: 0.791846, G loss: 3.507302, D accuracy: 78.0%, cell accuracy: 98.2%, board accuracy: 18.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.731212, G loss: 5.572108, D accuracy: 80.5%, cell accuracy: 97.8%, board accuracy: 10.7% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6099, G loss: 2.8558\n",
      "[372/8000] D loss: 0.7330, G loss: 2.8992\n",
      "[732/8000] D loss: 0.6106, G loss: 4.2649\n",
      "[1092/8000] D loss: 0.6089, G loss: 3.2392\n",
      "[1452/8000] D loss: 0.5280, G loss: 7.4603\n",
      "[1812/8000] D loss: 0.4550, G loss: 3.7927\n",
      "[2172/8000] D loss: 0.5565, G loss: 5.1340\n",
      "[2532/8000] D loss: 0.9788, G loss: 2.2622\n",
      "[2892/8000] D loss: 0.7490, G loss: 3.4661\n",
      "[3252/8000] D loss: 0.9456, G loss: 2.4900\n",
      "[3612/8000] D loss: 0.2816, G loss: 4.4583\n",
      "[3972/8000] D loss: 0.6411, G loss: 5.4323\n",
      "[4332/8000] D loss: 0.6235, G loss: 5.1746\n",
      "[4692/8000] D loss: 0.8060, G loss: 4.1379\n",
      "[5052/8000] D loss: 0.3973, G loss: 4.8364\n",
      "[5412/8000] D loss: 0.8604, G loss: 7.1503\n",
      "[5772/8000] D loss: 0.5350, G loss: 4.6196\n",
      "[6132/8000] D loss: 1.1570, G loss: 1.5129\n",
      "[6492/8000] D loss: 0.6342, G loss: 3.1701\n",
      "[6852/8000] D loss: 0.8360, G loss: 3.7729\n",
      "[7212/8000] D loss: 0.7684, G loss: 4.2455\n",
      "[7572/8000] D loss: 0.7365, G loss: 4.4583\n",
      "[7932/8000] D loss: 0.7572, G loss: 3.3052\n",
      "train error: \n",
      " D loss: 0.778580, G loss: 2.797204, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 19.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.604713, G loss: 4.937114, D accuracy: 86.0%, cell accuracy: 97.8%, board accuracy: 11.3% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7445, G loss: 3.4814\n",
      "[372/8000] D loss: 0.6220, G loss: 3.6835\n",
      "[732/8000] D loss: 0.6034, G loss: 5.3703\n",
      "[1092/8000] D loss: 0.4066, G loss: 4.1270\n",
      "[1452/8000] D loss: 0.9341, G loss: 3.4499\n",
      "[1812/8000] D loss: 0.6765, G loss: 2.6702\n",
      "[2172/8000] D loss: 0.7066, G loss: 3.0497\n",
      "[2532/8000] D loss: 1.1139, G loss: 1.8345\n",
      "[2892/8000] D loss: 1.3110, G loss: 1.6436\n",
      "[3252/8000] D loss: 0.7993, G loss: 2.8850\n",
      "[3612/8000] D loss: 0.7289, G loss: 2.6693\n",
      "[3972/8000] D loss: 0.6280, G loss: 4.9735\n",
      "[4332/8000] D loss: 1.3299, G loss: 2.2077\n",
      "[4692/8000] D loss: 0.9285, G loss: 3.0272\n",
      "[5052/8000] D loss: 0.7207, G loss: 2.6600\n",
      "[5412/8000] D loss: 0.5130, G loss: 3.8842\n",
      "[5772/8000] D loss: 1.1068, G loss: 1.1563\n",
      "[6132/8000] D loss: 0.8601, G loss: 4.5338\n",
      "[6492/8000] D loss: 0.6995, G loss: 3.9341\n",
      "[6852/8000] D loss: 0.7166, G loss: 2.3016\n",
      "[7212/8000] D loss: 0.6848, G loss: 4.7500\n",
      "[7572/8000] D loss: 0.6553, G loss: 4.9920\n",
      "[7932/8000] D loss: 0.8687, G loss: 3.9849\n",
      "train error: \n",
      " D loss: 0.838723, G loss: 2.460126, D accuracy: 78.7%, cell accuracy: 98.1%, board accuracy: 18.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.601254, G loss: 4.571811, D accuracy: 86.2%, cell accuracy: 97.7%, board accuracy: 10.9% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8771, G loss: 3.3354\n",
      "[372/8000] D loss: 1.0257, G loss: 3.1696\n",
      "[732/8000] D loss: 0.7280, G loss: 3.4385\n",
      "[1092/8000] D loss: 0.5291, G loss: 3.6502\n",
      "[1452/8000] D loss: 0.9340, G loss: 3.4952\n",
      "[1812/8000] D loss: 0.8800, G loss: 3.2354\n",
      "[2172/8000] D loss: 0.7408, G loss: 3.7232\n",
      "[2532/8000] D loss: 0.5061, G loss: 3.0658\n",
      "[2892/8000] D loss: 0.7792, G loss: 1.8369\n",
      "[3252/8000] D loss: 0.9718, G loss: 2.3891\n",
      "[3612/8000] D loss: 0.5914, G loss: 5.4707\n",
      "[3972/8000] D loss: 0.4195, G loss: 5.0633\n",
      "[4332/8000] D loss: 1.1836, G loss: 3.1869\n",
      "[4692/8000] D loss: 0.7708, G loss: 2.9471\n",
      "[5052/8000] D loss: 0.7909, G loss: 2.3159\n",
      "[5412/8000] D loss: 0.8553, G loss: 2.2060\n",
      "[5772/8000] D loss: 0.7191, G loss: 2.7427\n",
      "[6132/8000] D loss: 1.1159, G loss: 2.5791\n",
      "[6492/8000] D loss: 0.5457, G loss: 1.8465\n",
      "[6852/8000] D loss: 0.9143, G loss: 1.5708\n",
      "[7212/8000] D loss: 0.4732, G loss: 4.4411\n",
      "[7572/8000] D loss: 0.8163, G loss: 2.4033\n",
      "[7932/8000] D loss: 0.5751, G loss: 2.4133\n",
      "train error: \n",
      " D loss: 0.767464, G loss: 3.685202, D accuracy: 79.5%, cell accuracy: 98.1%, board accuracy: 18.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.692012, G loss: 5.998663, D accuracy: 82.9%, cell accuracy: 97.7%, board accuracy: 10.2% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6965, G loss: 4.6683\n",
      "[372/8000] D loss: 0.4903, G loss: 5.2357\n",
      "[732/8000] D loss: 1.0223, G loss: 3.3645\n",
      "[1092/8000] D loss: 0.5814, G loss: 3.9224\n",
      "[1452/8000] D loss: 0.8827, G loss: 4.2438\n",
      "[1812/8000] D loss: 0.5915, G loss: 5.9229\n",
      "[2172/8000] D loss: 0.5247, G loss: 2.9320\n",
      "[2532/8000] D loss: 1.0058, G loss: 1.4453\n",
      "[2892/8000] D loss: 0.7824, G loss: 3.2854\n",
      "[3252/8000] D loss: 0.9159, G loss: 2.5620\n",
      "[3612/8000] D loss: 0.5776, G loss: 3.3106\n",
      "[3972/8000] D loss: 0.5768, G loss: 3.0017\n",
      "[4332/8000] D loss: 0.5487, G loss: 4.2445\n",
      "[4692/8000] D loss: 0.9231, G loss: 2.3373\n",
      "[5052/8000] D loss: 0.6642, G loss: 5.0499\n",
      "[5412/8000] D loss: 1.1374, G loss: 3.0301\n",
      "[5772/8000] D loss: 0.7068, G loss: 4.7376\n",
      "[6132/8000] D loss: 0.7335, G loss: 3.1075\n",
      "[6492/8000] D loss: 1.0174, G loss: 3.3818\n",
      "[6852/8000] D loss: 0.8185, G loss: 3.1147\n",
      "[7212/8000] D loss: 0.7617, G loss: 4.0496\n",
      "[7572/8000] D loss: 0.5297, G loss: 4.6146\n",
      "[7932/8000] D loss: 0.6691, G loss: 2.7525\n",
      "train error: \n",
      " D loss: 0.765861, G loss: 3.599776, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 18.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.704443, G loss: 5.827793, D accuracy: 81.2%, cell accuracy: 97.7%, board accuracy: 11.1% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2087, G loss: 1.4825\n",
      "[372/8000] D loss: 0.8640, G loss: 3.0810\n",
      "[732/8000] D loss: 0.8392, G loss: 2.0757\n",
      "[1092/8000] D loss: 0.5530, G loss: 5.2848\n",
      "[1452/8000] D loss: 0.5215, G loss: 5.1408\n",
      "[1812/8000] D loss: 0.9166, G loss: 2.5430\n",
      "[2172/8000] D loss: 0.6995, G loss: 3.1222\n",
      "[2532/8000] D loss: 0.8649, G loss: 4.1814\n",
      "[2892/8000] D loss: 0.6901, G loss: 2.9087\n",
      "[3252/8000] D loss: 0.4914, G loss: 2.6737\n",
      "[3612/8000] D loss: 0.4195, G loss: 5.4299\n",
      "[3972/8000] D loss: 0.5080, G loss: 3.0699\n",
      "[4332/8000] D loss: 1.0083, G loss: 4.5953\n",
      "[4692/8000] D loss: 0.9525, G loss: 1.3518\n",
      "[5052/8000] D loss: 0.7403, G loss: 2.1878\n",
      "[5412/8000] D loss: 0.3906, G loss: 3.7646\n",
      "[5772/8000] D loss: 0.6924, G loss: 4.4938\n",
      "[6132/8000] D loss: 0.8417, G loss: 2.8434\n",
      "[6492/8000] D loss: 0.6219, G loss: 4.1121\n",
      "[6852/8000] D loss: 0.7211, G loss: 2.4302\n",
      "[7212/8000] D loss: 0.5776, G loss: 5.2507\n",
      "[7572/8000] D loss: 0.5465, G loss: 3.6324\n",
      "[7932/8000] D loss: 0.9848, G loss: 2.0877\n",
      "train error: \n",
      " D loss: 0.766043, G loss: 3.713570, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 20.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.703184, G loss: 6.112641, D accuracy: 81.7%, cell accuracy: 97.8%, board accuracy: 12.3% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6363, G loss: 4.7877\n",
      "[372/8000] D loss: 1.1235, G loss: 2.6072\n",
      "[732/8000] D loss: 0.6635, G loss: 3.8133\n",
      "[1092/8000] D loss: 0.5448, G loss: 4.8677\n",
      "[1452/8000] D loss: 0.5576, G loss: 4.4706\n",
      "[1812/8000] D loss: 1.0589, G loss: 2.1875\n",
      "[2172/8000] D loss: 0.7050, G loss: 2.7860\n",
      "[2532/8000] D loss: 0.9550, G loss: 1.9262\n",
      "[2892/8000] D loss: 0.6306, G loss: 3.1038\n",
      "[3252/8000] D loss: 0.7950, G loss: 4.2727\n",
      "[3612/8000] D loss: 0.7202, G loss: 4.5649\n",
      "[3972/8000] D loss: 0.7202, G loss: 3.6105\n",
      "[4332/8000] D loss: 0.4509, G loss: 5.0391\n",
      "[4692/8000] D loss: 1.1615, G loss: 1.0233\n",
      "[5052/8000] D loss: 0.4991, G loss: 3.2087\n",
      "[5412/8000] D loss: 1.0023, G loss: 3.5666\n",
      "[5772/8000] D loss: 0.8585, G loss: 1.8635\n",
      "[6132/8000] D loss: 0.8780, G loss: 1.8208\n",
      "[6492/8000] D loss: 0.5739, G loss: 4.4391\n",
      "[6852/8000] D loss: 0.6234, G loss: 4.4251\n",
      "[7212/8000] D loss: 0.4825, G loss: 3.8541\n",
      "[7572/8000] D loss: 1.0077, G loss: 1.9489\n",
      "[7932/8000] D loss: 0.5694, G loss: 3.5556\n",
      "train error: \n",
      " D loss: 0.781330, G loss: 3.981540, D accuracy: 78.5%, cell accuracy: 98.2%, board accuracy: 20.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.743520, G loss: 6.581090, D accuracy: 80.5%, cell accuracy: 97.8%, board accuracy: 11.9% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7240, G loss: 3.3789\n",
      "[372/8000] D loss: 0.7798, G loss: 2.4126\n",
      "[732/8000] D loss: 1.0319, G loss: 3.5313\n",
      "[1092/8000] D loss: 0.9682, G loss: 2.0348\n",
      "[1452/8000] D loss: 0.6056, G loss: 4.2371\n",
      "[1812/8000] D loss: 0.8722, G loss: 2.7966\n",
      "[2172/8000] D loss: 0.8449, G loss: 2.4682\n",
      "[2532/8000] D loss: 0.5701, G loss: 2.9480\n",
      "[2892/8000] D loss: 0.8408, G loss: 3.6386\n",
      "[3252/8000] D loss: 0.8412, G loss: 3.1218\n",
      "[3612/8000] D loss: 0.7126, G loss: 3.3176\n",
      "[3972/8000] D loss: 0.8653, G loss: 2.6784\n",
      "[4332/8000] D loss: 0.6246, G loss: 3.2627\n",
      "[4692/8000] D loss: 1.2055, G loss: 2.5504\n",
      "[5052/8000] D loss: 1.0888, G loss: 2.0573\n",
      "[5412/8000] D loss: 0.7904, G loss: 1.8374\n",
      "[5772/8000] D loss: 1.3722, G loss: 0.8443\n",
      "[6132/8000] D loss: 0.9922, G loss: 3.9260\n",
      "[6492/8000] D loss: 0.8182, G loss: 2.9548\n",
      "[6852/8000] D loss: 1.0601, G loss: 2.0623\n",
      "[7212/8000] D loss: 0.5187, G loss: 3.8920\n",
      "[7572/8000] D loss: 0.7152, G loss: 3.8409\n",
      "[7932/8000] D loss: 0.7476, G loss: 2.6193\n",
      "train error: \n",
      " D loss: 0.764992, G loss: 3.390673, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 20.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.695822, G loss: 5.671603, D accuracy: 81.7%, cell accuracy: 97.8%, board accuracy: 11.2% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4565, G loss: 5.5558\n",
      "[372/8000] D loss: 0.9278, G loss: 2.2347\n",
      "[732/8000] D loss: 0.4978, G loss: 3.8792\n",
      "[1092/8000] D loss: 0.4582, G loss: 5.5046\n",
      "[1452/8000] D loss: 1.4278, G loss: 3.5362\n",
      "[1812/8000] D loss: 0.6486, G loss: 2.8883\n",
      "[2172/8000] D loss: 0.7022, G loss: 2.9648\n",
      "[2532/8000] D loss: 0.7902, G loss: 2.9385\n",
      "[2892/8000] D loss: 0.7017, G loss: 2.7345\n",
      "[3252/8000] D loss: 0.8091, G loss: 2.0594\n",
      "[3612/8000] D loss: 0.9241, G loss: 2.8601\n",
      "[3972/8000] D loss: 0.8846, G loss: 1.6265\n",
      "[4332/8000] D loss: 0.7128, G loss: 4.2148\n",
      "[4692/8000] D loss: 0.6701, G loss: 3.4993\n",
      "[5052/8000] D loss: 0.3652, G loss: 4.6164\n",
      "[5412/8000] D loss: 0.8130, G loss: 4.0689\n",
      "[5772/8000] D loss: 1.0158, G loss: 1.7372\n",
      "[6132/8000] D loss: 0.7300, G loss: 4.9291\n",
      "[6492/8000] D loss: 0.7368, G loss: 2.9174\n",
      "[6852/8000] D loss: 0.6021, G loss: 4.4271\n",
      "[7212/8000] D loss: 0.8074, G loss: 2.1857\n",
      "[7572/8000] D loss: 0.6291, G loss: 4.2691\n",
      "[7932/8000] D loss: 0.4191, G loss: 5.5366\n",
      "train error: \n",
      " D loss: 0.759319, G loss: 3.651214, D accuracy: 79.5%, cell accuracy: 98.2%, board accuracy: 21.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.682410, G loss: 6.093440, D accuracy: 82.1%, cell accuracy: 97.8%, board accuracy: 11.8% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7157, G loss: 4.1475\n",
      "[372/8000] D loss: 0.7975, G loss: 2.6961\n",
      "[732/8000] D loss: 0.8783, G loss: 2.9301\n",
      "[1092/8000] D loss: 0.6216, G loss: 4.4482\n",
      "[1452/8000] D loss: 0.7086, G loss: 2.8656\n",
      "[1812/8000] D loss: 0.7687, G loss: 3.3874\n",
      "[2172/8000] D loss: 1.0398, G loss: 3.2948\n",
      "[2532/8000] D loss: 0.7648, G loss: 2.8185\n",
      "[2892/8000] D loss: 0.7252, G loss: 4.4340\n",
      "[3252/8000] D loss: 0.3462, G loss: 6.1973\n",
      "[3612/8000] D loss: 0.7791, G loss: 2.1422\n",
      "[3972/8000] D loss: 0.8527, G loss: 3.2444\n",
      "[4332/8000] D loss: 0.7080, G loss: 2.2571\n",
      "[4692/8000] D loss: 1.0089, G loss: 2.3250\n",
      "[5052/8000] D loss: 0.9711, G loss: 1.2431\n",
      "[5412/8000] D loss: 1.2732, G loss: 1.6243\n",
      "[5772/8000] D loss: 0.2624, G loss: 4.9896\n",
      "[6132/8000] D loss: 0.4868, G loss: 3.3565\n",
      "[6492/8000] D loss: 0.6978, G loss: 4.7541\n",
      "[6852/8000] D loss: 0.9437, G loss: 2.4255\n",
      "[7212/8000] D loss: 0.6518, G loss: 4.0109\n",
      "[7572/8000] D loss: 0.8621, G loss: 1.7920\n",
      "[7932/8000] D loss: 0.8337, G loss: 3.2298\n",
      "train error: \n",
      " D loss: 0.813922, G loss: 2.736736, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 21.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.620733, G loss: 4.925797, D accuracy: 85.2%, cell accuracy: 97.8%, board accuracy: 11.9% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5523, G loss: 3.5391\n",
      "[372/8000] D loss: 0.9208, G loss: 3.7032\n",
      "[732/8000] D loss: 0.7116, G loss: 2.3895\n",
      "[1092/8000] D loss: 0.9967, G loss: 2.7908\n",
      "[1452/8000] D loss: 0.6531, G loss: 3.1335\n",
      "[1812/8000] D loss: 0.6048, G loss: 3.6429\n",
      "[2172/8000] D loss: 0.6566, G loss: 2.5324\n",
      "[2532/8000] D loss: 0.5339, G loss: 4.5574\n",
      "[2892/8000] D loss: 1.3833, G loss: 1.7653\n",
      "[3252/8000] D loss: 0.6892, G loss: 3.6216\n",
      "[3612/8000] D loss: 0.3424, G loss: 3.8220\n",
      "[3972/8000] D loss: 0.9845, G loss: 2.6353\n",
      "[4332/8000] D loss: 0.5276, G loss: 4.2325\n",
      "[4692/8000] D loss: 1.0007, G loss: 3.6192\n",
      "[5052/8000] D loss: 0.8686, G loss: 2.5006\n",
      "[5412/8000] D loss: 0.3131, G loss: 4.9729\n",
      "[5772/8000] D loss: 0.7240, G loss: 2.0902\n",
      "[6132/8000] D loss: 0.7458, G loss: 2.2193\n",
      "[6492/8000] D loss: 0.8747, G loss: 2.6207\n",
      "[6852/8000] D loss: 0.4145, G loss: 3.3342\n",
      "[7212/8000] D loss: 1.0440, G loss: 2.6491\n",
      "[7572/8000] D loss: 0.7546, G loss: 2.8888\n",
      "[7932/8000] D loss: 0.4726, G loss: 3.9788\n",
      "train error: \n",
      " D loss: 0.782261, G loss: 2.922935, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 22.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.622005, G loss: 5.132570, D accuracy: 84.9%, cell accuracy: 97.8%, board accuracy: 13.1% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4123, G loss: 2.7577\n",
      "[372/8000] D loss: 0.4008, G loss: 4.4881\n",
      "[732/8000] D loss: 0.9113, G loss: 2.1435\n",
      "[1092/8000] D loss: 0.9809, G loss: 3.2247\n",
      "[1452/8000] D loss: 0.2329, G loss: 6.8640\n",
      "[1812/8000] D loss: 0.7818, G loss: 3.8767\n",
      "[2172/8000] D loss: 0.6666, G loss: 4.7152\n",
      "[2532/8000] D loss: 0.8725, G loss: 2.8141\n",
      "[2892/8000] D loss: 0.9894, G loss: 2.8554\n",
      "[3252/8000] D loss: 0.6447, G loss: 3.1502\n",
      "[3612/8000] D loss: 0.6022, G loss: 3.2396\n",
      "[3972/8000] D loss: 0.4904, G loss: 3.7953\n",
      "[4332/8000] D loss: 0.5792, G loss: 4.0039\n",
      "[4692/8000] D loss: 0.9033, G loss: 3.8406\n",
      "[5052/8000] D loss: 0.6463, G loss: 4.2431\n",
      "[5412/8000] D loss: 0.5323, G loss: 3.2568\n",
      "[5772/8000] D loss: 1.0385, G loss: 1.2696\n",
      "[6132/8000] D loss: 1.1345, G loss: 1.8130\n",
      "[6492/8000] D loss: 1.1621, G loss: 2.3514\n",
      "[6852/8000] D loss: 0.5994, G loss: 5.2777\n",
      "[7212/8000] D loss: 0.9319, G loss: 1.9430\n",
      "[7572/8000] D loss: 0.7003, G loss: 3.2304\n",
      "[7932/8000] D loss: 0.7522, G loss: 2.3782\n",
      "train error: \n",
      " D loss: 0.714756, G loss: 3.511974, D accuracy: 81.0%, cell accuracy: 98.2%, board accuracy: 20.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.633451, G loss: 6.024667, D accuracy: 84.0%, cell accuracy: 97.8%, board accuracy: 11.2% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5730, G loss: 3.4044\n",
      "[372/8000] D loss: 0.3041, G loss: 5.8098\n",
      "[732/8000] D loss: 0.7902, G loss: 5.7222\n",
      "[1092/8000] D loss: 0.8288, G loss: 4.7668\n",
      "[1452/8000] D loss: 0.7631, G loss: 2.3093\n",
      "[1812/8000] D loss: 0.7909, G loss: 4.6349\n",
      "[2172/8000] D loss: 0.4889, G loss: 4.5642\n",
      "[2532/8000] D loss: 1.2458, G loss: 2.0413\n",
      "[2892/8000] D loss: 0.5893, G loss: 2.6340\n",
      "[3252/8000] D loss: 0.7203, G loss: 3.2041\n",
      "[3612/8000] D loss: 0.9187, G loss: 4.0589\n",
      "[3972/8000] D loss: 1.0254, G loss: 2.5886\n",
      "[4332/8000] D loss: 0.6261, G loss: 4.2683\n",
      "[4692/8000] D loss: 0.6497, G loss: 2.0783\n",
      "[5052/8000] D loss: 0.7515, G loss: 2.4162\n",
      "[5412/8000] D loss: 1.1221, G loss: 2.0634\n",
      "[5772/8000] D loss: 0.9858, G loss: 5.2581\n",
      "[6132/8000] D loss: 0.5757, G loss: 3.4995\n",
      "[6492/8000] D loss: 0.4346, G loss: 3.3788\n",
      "[6852/8000] D loss: 0.4533, G loss: 3.6131\n",
      "[7212/8000] D loss: 0.7008, G loss: 3.7532\n",
      "[7572/8000] D loss: 1.0714, G loss: 2.3043\n",
      "[7932/8000] D loss: 0.6801, G loss: 3.1229\n",
      "train error: \n",
      " D loss: 0.741069, G loss: 3.606789, D accuracy: 80.2%, cell accuracy: 98.2%, board accuracy: 20.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.666718, G loss: 6.130925, D accuracy: 82.7%, cell accuracy: 97.8%, board accuracy: 11.3% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7333, G loss: 3.5918\n",
      "[372/8000] D loss: 0.8686, G loss: 2.6829\n",
      "[732/8000] D loss: 0.9400, G loss: 1.8326\n",
      "[1092/8000] D loss: 0.6113, G loss: 3.6714\n",
      "[1452/8000] D loss: 0.7305, G loss: 4.1136\n",
      "[1812/8000] D loss: 1.0092, G loss: 1.8059\n",
      "[2172/8000] D loss: 0.7996, G loss: 3.8988\n",
      "[2532/8000] D loss: 0.7230, G loss: 3.8677\n",
      "[2892/8000] D loss: 0.8325, G loss: 4.3194\n",
      "[3252/8000] D loss: 0.6392, G loss: 3.1554\n",
      "[3612/8000] D loss: 0.3423, G loss: 4.5589\n",
      "[3972/8000] D loss: 0.4744, G loss: 6.4194\n",
      "[4332/8000] D loss: 0.6886, G loss: 2.7043\n",
      "[4692/8000] D loss: 0.7301, G loss: 4.3810\n",
      "[5052/8000] D loss: 0.9090, G loss: 1.9818\n",
      "[5412/8000] D loss: 0.9481, G loss: 1.7531\n",
      "[5772/8000] D loss: 0.6058, G loss: 4.6638\n",
      "[6132/8000] D loss: 0.6523, G loss: 3.7415\n",
      "[6492/8000] D loss: 0.4565, G loss: 3.6288\n",
      "[6852/8000] D loss: 0.6912, G loss: 3.5068\n",
      "[7212/8000] D loss: 0.6459, G loss: 3.0202\n",
      "[7572/8000] D loss: 0.8601, G loss: 3.5357\n",
      "[7932/8000] D loss: 0.6043, G loss: 4.5339\n",
      "train error: \n",
      " D loss: 0.753024, G loss: 3.624978, D accuracy: 79.2%, cell accuracy: 98.3%, board accuracy: 23.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.682060, G loss: 6.062450, D accuracy: 82.0%, cell accuracy: 97.9%, board accuracy: 12.4% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4664, G loss: 3.2038\n",
      "[372/8000] D loss: 0.8337, G loss: 2.9604\n",
      "[732/8000] D loss: 0.5649, G loss: 3.6886\n",
      "[1092/8000] D loss: 0.9455, G loss: 3.0579\n",
      "[1452/8000] D loss: 0.7221, G loss: 3.0716\n",
      "[1812/8000] D loss: 0.6783, G loss: 4.2808\n",
      "[2172/8000] D loss: 0.7898, G loss: 3.9533\n",
      "[2532/8000] D loss: 1.0777, G loss: 1.9383\n",
      "[2892/8000] D loss: 1.2859, G loss: 2.7281\n",
      "[3252/8000] D loss: 1.1566, G loss: 1.6801\n",
      "[3612/8000] D loss: 0.9938, G loss: 2.2888\n",
      "[3972/8000] D loss: 0.8215, G loss: 3.8434\n",
      "[4332/8000] D loss: 0.6149, G loss: 4.4411\n",
      "[4692/8000] D loss: 0.8772, G loss: 2.1776\n",
      "[5052/8000] D loss: 0.2990, G loss: 5.0161\n",
      "[5412/8000] D loss: 0.5595, G loss: 4.2870\n",
      "[5772/8000] D loss: 0.6226, G loss: 3.4857\n",
      "[6132/8000] D loss: 0.6236, G loss: 4.8453\n",
      "[6492/8000] D loss: 0.7910, G loss: 3.6142\n",
      "[6852/8000] D loss: 0.5579, G loss: 4.0860\n",
      "[7212/8000] D loss: 0.4292, G loss: 5.2589\n",
      "[7572/8000] D loss: 0.6496, G loss: 4.7934\n",
      "[7932/8000] D loss: 0.7951, G loss: 2.1948\n",
      "train error: \n",
      " D loss: 0.782658, G loss: 3.724943, D accuracy: 78.1%, cell accuracy: 98.2%, board accuracy: 23.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.722848, G loss: 6.350324, D accuracy: 81.2%, cell accuracy: 97.8%, board accuracy: 12.2% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6150, G loss: 4.9835\n",
      "[372/8000] D loss: 0.9204, G loss: 2.7296\n",
      "[732/8000] D loss: 0.9671, G loss: 4.2945\n",
      "[1092/8000] D loss: 0.6680, G loss: 5.8510\n",
      "[1452/8000] D loss: 0.4384, G loss: 5.5848\n",
      "[1812/8000] D loss: 0.6851, G loss: 2.9537\n",
      "[2172/8000] D loss: 0.4899, G loss: 3.9891\n",
      "[2532/8000] D loss: 0.5376, G loss: 3.4102\n",
      "[2892/8000] D loss: 0.7294, G loss: 3.7891\n",
      "[3252/8000] D loss: 0.9037, G loss: 2.7383\n",
      "[3612/8000] D loss: 0.6315, G loss: 4.6844\n",
      "[3972/8000] D loss: 0.6893, G loss: 6.1676\n",
      "[4332/8000] D loss: 0.6445, G loss: 3.6591\n",
      "[4692/8000] D loss: 0.8513, G loss: 3.9444\n",
      "[5052/8000] D loss: 0.8560, G loss: 2.5769\n",
      "[5412/8000] D loss: 0.8916, G loss: 4.0745\n",
      "[5772/8000] D loss: 0.7273, G loss: 3.6224\n",
      "[6132/8000] D loss: 0.8762, G loss: 1.8761\n",
      "[6492/8000] D loss: 0.8916, G loss: 1.5712\n",
      "[6852/8000] D loss: 1.2155, G loss: 2.0114\n",
      "[7212/8000] D loss: 0.7661, G loss: 3.8939\n",
      "[7572/8000] D loss: 0.4924, G loss: 4.9336\n",
      "[7932/8000] D loss: 1.2143, G loss: 1.8133\n",
      "train error: \n",
      " D loss: 0.826561, G loss: 2.629674, D accuracy: 78.4%, cell accuracy: 98.3%, board accuracy: 23.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.586906, G loss: 5.075125, D accuracy: 86.1%, cell accuracy: 97.8%, board accuracy: 13.2% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5038, G loss: 4.6819\n",
      "[372/8000] D loss: 0.5300, G loss: 2.9682\n",
      "[732/8000] D loss: 1.1451, G loss: 2.5207\n",
      "[1092/8000] D loss: 0.9438, G loss: 4.4653\n",
      "[1452/8000] D loss: 0.2999, G loss: 7.5804\n",
      "[1812/8000] D loss: 0.5643, G loss: 3.4286\n",
      "[2172/8000] D loss: 0.9295, G loss: 1.9106\n",
      "[2532/8000] D loss: 0.7510, G loss: 2.3946\n",
      "[2892/8000] D loss: 0.5700, G loss: 5.0012\n",
      "[3252/8000] D loss: 0.9059, G loss: 3.1521\n",
      "[3612/8000] D loss: 0.7312, G loss: 4.8398\n",
      "[3972/8000] D loss: 1.2110, G loss: 2.7446\n",
      "[4332/8000] D loss: 1.0122, G loss: 4.3564\n",
      "[4692/8000] D loss: 0.9244, G loss: 1.4855\n",
      "[5052/8000] D loss: 0.5525, G loss: 3.9737\n",
      "[5412/8000] D loss: 0.7298, G loss: 2.9656\n",
      "[5772/8000] D loss: 1.1668, G loss: 1.1707\n",
      "[6132/8000] D loss: 0.6458, G loss: 2.9889\n",
      "[6492/8000] D loss: 0.6375, G loss: 3.3955\n",
      "[6852/8000] D loss: 0.5089, G loss: 5.0664\n",
      "[7212/8000] D loss: 0.6490, G loss: 3.1045\n",
      "[7572/8000] D loss: 0.8011, G loss: 4.2370\n",
      "[7932/8000] D loss: 0.4252, G loss: 5.8755\n",
      "train error: \n",
      " D loss: 0.747521, G loss: 3.427943, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 21.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.578580, G loss: 6.205028, D accuracy: 86.3%, cell accuracy: 97.8%, board accuracy: 12.3% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8410, G loss: 2.9831\n",
      "[372/8000] D loss: 0.4296, G loss: 4.4360\n",
      "[732/8000] D loss: 0.7016, G loss: 3.7014\n",
      "[1092/8000] D loss: 0.5169, G loss: 4.2360\n",
      "[1452/8000] D loss: 0.8896, G loss: 2.1445\n",
      "[1812/8000] D loss: 0.5924, G loss: 3.4278\n",
      "[2172/8000] D loss: 0.6938, G loss: 4.6398\n",
      "[2532/8000] D loss: 0.8318, G loss: 2.6455\n",
      "[2892/8000] D loss: 0.6329, G loss: 3.6296\n",
      "[3252/8000] D loss: 0.8290, G loss: 3.5770\n",
      "[3612/8000] D loss: 0.5493, G loss: 6.1770\n",
      "[3972/8000] D loss: 0.6974, G loss: 3.3796\n",
      "[4332/8000] D loss: 0.5070, G loss: 3.6297\n",
      "[4692/8000] D loss: 0.3306, G loss: 4.7753\n",
      "[5052/8000] D loss: 0.5968, G loss: 3.4579\n",
      "[5412/8000] D loss: 0.6535, G loss: 2.8865\n",
      "[5772/8000] D loss: 0.6542, G loss: 5.6006\n",
      "[6132/8000] D loss: 0.7488, G loss: 3.6237\n",
      "[6492/8000] D loss: 0.5645, G loss: 3.5332\n",
      "[6852/8000] D loss: 0.1871, G loss: 6.1071\n",
      "[7212/8000] D loss: 0.5441, G loss: 4.6681\n",
      "[7572/8000] D loss: 0.7191, G loss: 3.6617\n",
      "[7932/8000] D loss: 0.9732, G loss: 5.0183\n",
      "train error: \n",
      " D loss: 0.878333, G loss: 2.661757, D accuracy: 77.3%, cell accuracy: 98.3%, board accuracy: 24.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.654719, G loss: 5.220206, D accuracy: 84.0%, cell accuracy: 97.9%, board accuracy: 13.4% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0516, G loss: 1.3405\n",
      "[372/8000] D loss: 0.7119, G loss: 3.3588\n",
      "[732/8000] D loss: 0.4212, G loss: 5.0699\n",
      "[1092/8000] D loss: 0.9383, G loss: 3.8945\n",
      "[1452/8000] D loss: 1.0795, G loss: 1.9322\n",
      "[1812/8000] D loss: 0.8907, G loss: 3.1957\n",
      "[2172/8000] D loss: 0.7796, G loss: 2.7560\n",
      "[2532/8000] D loss: 0.7448, G loss: 3.2893\n",
      "[2892/8000] D loss: 0.9200, G loss: 2.4121\n",
      "[3252/8000] D loss: 0.7599, G loss: 2.2201\n",
      "[3612/8000] D loss: 0.7891, G loss: 3.0059\n",
      "[3972/8000] D loss: 1.1838, G loss: 3.0567\n",
      "[4332/8000] D loss: 0.6377, G loss: 3.2703\n",
      "[4692/8000] D loss: 0.9642, G loss: 3.6017\n",
      "[5052/8000] D loss: 0.5268, G loss: 4.6919\n",
      "[5412/8000] D loss: 0.6136, G loss: 5.2461\n",
      "[5772/8000] D loss: 0.5743, G loss: 3.1198\n",
      "[6132/8000] D loss: 0.8510, G loss: 2.7196\n",
      "[6492/8000] D loss: 0.5786, G loss: 3.0332\n",
      "[6852/8000] D loss: 0.8377, G loss: 2.5282\n",
      "[7212/8000] D loss: 0.7698, G loss: 4.0855\n",
      "[7572/8000] D loss: 0.9739, G loss: 3.6532\n",
      "[7932/8000] D loss: 1.0254, G loss: 1.4927\n",
      "train error: \n",
      " D loss: 0.805123, G loss: 2.991263, D accuracy: 78.8%, cell accuracy: 98.3%, board accuracy: 25.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.610601, G loss: 5.790620, D accuracy: 85.1%, cell accuracy: 97.9%, board accuracy: 14.3% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4885, G loss: 6.6948\n",
      "[372/8000] D loss: 0.4777, G loss: 3.6445\n",
      "[732/8000] D loss: 0.6973, G loss: 3.6407\n",
      "[1092/8000] D loss: 1.0072, G loss: 2.5249\n",
      "[1452/8000] D loss: 0.5416, G loss: 3.7505\n",
      "[1812/8000] D loss: 0.9139, G loss: 1.9557\n",
      "[2172/8000] D loss: 0.7081, G loss: 3.9867\n",
      "[2532/8000] D loss: 1.0633, G loss: 2.7602\n",
      "[2892/8000] D loss: 0.8348, G loss: 1.9522\n",
      "[3252/8000] D loss: 0.8308, G loss: 2.7685\n",
      "[3612/8000] D loss: 0.5278, G loss: 3.6481\n",
      "[3972/8000] D loss: 0.5863, G loss: 5.2788\n",
      "[4332/8000] D loss: 0.7692, G loss: 3.6874\n",
      "[4692/8000] D loss: 0.4715, G loss: 6.6723\n",
      "[5052/8000] D loss: 0.6623, G loss: 2.8304\n",
      "[5412/8000] D loss: 0.4724, G loss: 4.7112\n",
      "[5772/8000] D loss: 0.7330, G loss: 4.5646\n",
      "[6132/8000] D loss: 0.5931, G loss: 3.1773\n",
      "[6492/8000] D loss: 0.7827, G loss: 2.3239\n",
      "[6852/8000] D loss: 0.6090, G loss: 2.9517\n",
      "[7212/8000] D loss: 0.8484, G loss: 1.8456\n",
      "[7572/8000] D loss: 0.5006, G loss: 3.6027\n",
      "[7932/8000] D loss: 0.7936, G loss: 4.1399\n",
      "train error: \n",
      " D loss: 0.921978, G loss: 2.341207, D accuracy: 76.1%, cell accuracy: 98.3%, board accuracy: 25.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.659517, G loss: 4.762580, D accuracy: 83.8%, cell accuracy: 97.9%, board accuracy: 14.1% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6730, G loss: 2.5326\n",
      "[372/8000] D loss: 0.8993, G loss: 1.8711\n",
      "[732/8000] D loss: 0.8591, G loss: 1.6586\n",
      "[1092/8000] D loss: 0.9618, G loss: 2.2507\n",
      "[1452/8000] D loss: 1.0300, G loss: 2.3758\n",
      "[1812/8000] D loss: 0.6255, G loss: 5.4558\n",
      "[2172/8000] D loss: 0.7961, G loss: 2.9480\n",
      "[2532/8000] D loss: 0.4865, G loss: 5.6525\n",
      "[2892/8000] D loss: 0.5080, G loss: 4.2768\n",
      "[3252/8000] D loss: 0.3966, G loss: 9.6674\n",
      "[3612/8000] D loss: 0.7171, G loss: 5.6732\n",
      "[3972/8000] D loss: 0.7002, G loss: 2.4153\n",
      "[4332/8000] D loss: 0.8615, G loss: 2.6150\n",
      "[4692/8000] D loss: 1.2849, G loss: 1.7628\n",
      "[5052/8000] D loss: 0.7967, G loss: 4.1241\n",
      "[5412/8000] D loss: 0.5679, G loss: 4.3856\n",
      "[5772/8000] D loss: 0.7903, G loss: 3.8488\n",
      "[6132/8000] D loss: 0.6522, G loss: 6.3066\n",
      "[6492/8000] D loss: 0.4297, G loss: 6.1325\n",
      "[6852/8000] D loss: 0.8126, G loss: 5.2539\n",
      "[7212/8000] D loss: 0.8134, G loss: 3.3670\n",
      "[7572/8000] D loss: 0.5433, G loss: 3.3173\n",
      "[7932/8000] D loss: 0.9581, G loss: 2.4274\n",
      "train error: \n",
      " D loss: 0.750906, G loss: 3.657108, D accuracy: 79.3%, cell accuracy: 98.3%, board accuracy: 25.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.689876, G loss: 6.466517, D accuracy: 81.5%, cell accuracy: 97.9%, board accuracy: 14.1% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8431, G loss: 3.3931\n",
      "[372/8000] D loss: 0.7914, G loss: 3.6109\n",
      "[732/8000] D loss: 0.7876, G loss: 2.8595\n",
      "[1092/8000] D loss: 1.0633, G loss: 2.7871\n",
      "[1452/8000] D loss: 0.7573, G loss: 3.5733\n",
      "[1812/8000] D loss: 0.9263, G loss: 2.7905\n",
      "[2172/8000] D loss: 0.6082, G loss: 4.8366\n",
      "[2532/8000] D loss: 0.6176, G loss: 3.2333\n",
      "[2892/8000] D loss: 0.5533, G loss: 3.3983\n",
      "[3252/8000] D loss: 1.1144, G loss: 2.4905\n",
      "[3612/8000] D loss: 0.8794, G loss: 2.8811\n",
      "[3972/8000] D loss: 0.8134, G loss: 3.3214\n",
      "[4332/8000] D loss: 0.5496, G loss: 6.3789\n",
      "[4692/8000] D loss: 0.5596, G loss: 4.9354\n",
      "[5052/8000] D loss: 0.6935, G loss: 2.6336\n",
      "[5412/8000] D loss: 0.8737, G loss: 3.3734\n",
      "[5772/8000] D loss: 0.5452, G loss: 2.5394\n",
      "[6132/8000] D loss: 0.8105, G loss: 3.9895\n",
      "[6492/8000] D loss: 0.6061, G loss: 2.9767\n",
      "[6852/8000] D loss: 0.9837, G loss: 3.7807\n",
      "[7212/8000] D loss: 0.6778, G loss: 3.1837\n",
      "[7572/8000] D loss: 0.6031, G loss: 4.2106\n",
      "[7932/8000] D loss: 0.4930, G loss: 4.9446\n",
      "train error: \n",
      " D loss: 0.758597, G loss: 3.273176, D accuracy: 80.1%, cell accuracy: 98.3%, board accuracy: 25.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.606926, G loss: 6.268037, D accuracy: 85.9%, cell accuracy: 97.9%, board accuracy: 14.2% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6668, G loss: 3.5948\n",
      "[372/8000] D loss: 0.7829, G loss: 3.2417\n",
      "[732/8000] D loss: 0.7574, G loss: 3.7580\n",
      "[1092/8000] D loss: 0.8505, G loss: 2.0133\n",
      "[1452/8000] D loss: 0.6701, G loss: 3.2660\n",
      "[1812/8000] D loss: 0.7779, G loss: 1.9984\n",
      "[2172/8000] D loss: 0.8476, G loss: 2.2928\n",
      "[2532/8000] D loss: 0.4919, G loss: 4.4628\n",
      "[2892/8000] D loss: 0.6973, G loss: 4.0922\n",
      "[3252/8000] D loss: 0.8535, G loss: 3.1295\n",
      "[3612/8000] D loss: 0.5647, G loss: 4.5402\n",
      "[3972/8000] D loss: 0.9241, G loss: 1.7545\n",
      "[4332/8000] D loss: 0.6736, G loss: 4.9986\n",
      "[4692/8000] D loss: 0.6193, G loss: 5.0448\n",
      "[5052/8000] D loss: 0.5816, G loss: 2.8026\n",
      "[5412/8000] D loss: 1.0099, G loss: 2.4452\n",
      "[5772/8000] D loss: 0.7930, G loss: 4.0532\n",
      "[6132/8000] D loss: 1.0861, G loss: 1.9669\n",
      "[6492/8000] D loss: 0.6601, G loss: 4.5758\n",
      "[6852/8000] D loss: 0.8976, G loss: 4.4296\n",
      "[7212/8000] D loss: 0.6921, G loss: 2.6819\n",
      "[7572/8000] D loss: 0.7330, G loss: 3.7182\n",
      "[7932/8000] D loss: 0.5805, G loss: 3.0934\n",
      "train error: \n",
      " D loss: 0.785984, G loss: 3.506867, D accuracy: 78.7%, cell accuracy: 98.3%, board accuracy: 27.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.684386, G loss: 6.325562, D accuracy: 82.5%, cell accuracy: 97.9%, board accuracy: 14.3% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5090, G loss: 4.0774\n",
      "[372/8000] D loss: 0.4175, G loss: 3.5924\n",
      "[732/8000] D loss: 0.7879, G loss: 2.9916\n",
      "[1092/8000] D loss: 0.5354, G loss: 3.4879\n",
      "[1452/8000] D loss: 0.8113, G loss: 3.0744\n",
      "[1812/8000] D loss: 0.5010, G loss: 3.8465\n",
      "[2172/8000] D loss: 1.2493, G loss: 1.3729\n",
      "[2532/8000] D loss: 0.7782, G loss: 2.3145\n",
      "[2892/8000] D loss: 0.9759, G loss: 2.1449\n",
      "[3252/8000] D loss: 0.5623, G loss: 4.1145\n",
      "[3612/8000] D loss: 0.5023, G loss: 3.8927\n",
      "[3972/8000] D loss: 0.6501, G loss: 2.5677\n",
      "[4332/8000] D loss: 0.8482, G loss: 2.6127\n",
      "[4692/8000] D loss: 0.8812, G loss: 3.2808\n",
      "[5052/8000] D loss: 0.3865, G loss: 4.6311\n",
      "[5412/8000] D loss: 0.3156, G loss: 4.8018\n",
      "[5772/8000] D loss: 0.4227, G loss: 4.7870\n",
      "[6132/8000] D loss: 1.0194, G loss: 4.3792\n",
      "[6492/8000] D loss: 1.1206, G loss: 1.7580\n",
      "[6852/8000] D loss: 0.7241, G loss: 4.6646\n",
      "[7212/8000] D loss: 0.7923, G loss: 3.3102\n",
      "[7572/8000] D loss: 1.0755, G loss: 3.2040\n",
      "[7932/8000] D loss: 0.4065, G loss: 6.4927\n",
      "train error: \n",
      " D loss: 0.749094, G loss: 3.499013, D accuracy: 79.6%, cell accuracy: 98.3%, board accuracy: 25.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609476, G loss: 6.344346, D accuracy: 85.3%, cell accuracy: 97.9%, board accuracy: 13.9% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6872, G loss: 3.3637\n",
      "[372/8000] D loss: 1.0642, G loss: 1.9688\n",
      "[732/8000] D loss: 0.7772, G loss: 3.3390\n",
      "[1092/8000] D loss: 0.8224, G loss: 3.8279\n",
      "[1452/8000] D loss: 0.9088, G loss: 2.4847\n",
      "[1812/8000] D loss: 0.3975, G loss: 3.8390\n",
      "[2172/8000] D loss: 0.5221, G loss: 5.2735\n",
      "[2532/8000] D loss: 0.5690, G loss: 5.3274\n",
      "[2892/8000] D loss: 0.6783, G loss: 3.2568\n",
      "[3252/8000] D loss: 0.6336, G loss: 2.9590\n",
      "[3612/8000] D loss: 1.1242, G loss: 2.1859\n",
      "[3972/8000] D loss: 1.2052, G loss: 1.9745\n",
      "[4332/8000] D loss: 0.6872, G loss: 3.8320\n",
      "[4692/8000] D loss: 1.0147, G loss: 2.8524\n",
      "[5052/8000] D loss: 0.6790, G loss: 4.4417\n",
      "[5412/8000] D loss: 0.6029, G loss: 2.5083\n",
      "[5772/8000] D loss: 0.8576, G loss: 2.9925\n",
      "[6132/8000] D loss: 0.4924, G loss: 7.1351\n",
      "[6492/8000] D loss: 0.8019, G loss: 3.7035\n",
      "[6852/8000] D loss: 0.8268, G loss: 2.9624\n",
      "[7212/8000] D loss: 0.9404, G loss: 5.5342\n",
      "[7572/8000] D loss: 0.6517, G loss: 3.0836\n",
      "[7932/8000] D loss: 0.6716, G loss: 2.4331\n",
      "train error: \n",
      " D loss: 0.751985, G loss: 3.701620, D accuracy: 78.9%, cell accuracy: 98.3%, board accuracy: 26.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.690511, G loss: 6.541565, D accuracy: 81.6%, cell accuracy: 97.9%, board accuracy: 14.8% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6766, G loss: 5.8385\n",
      "[372/8000] D loss: 0.9103, G loss: 2.1204\n",
      "[732/8000] D loss: 0.9615, G loss: 2.4481\n",
      "[1092/8000] D loss: 1.1312, G loss: 2.3775\n",
      "[1452/8000] D loss: 0.8810, G loss: 2.8746\n",
      "[1812/8000] D loss: 0.7055, G loss: 3.4059\n",
      "[2172/8000] D loss: 0.8018, G loss: 3.8124\n",
      "[2532/8000] D loss: 0.8237, G loss: 2.1822\n",
      "[2892/8000] D loss: 0.7532, G loss: 2.8801\n",
      "[3252/8000] D loss: 0.9896, G loss: 1.9760\n",
      "[3612/8000] D loss: 0.7018, G loss: 2.6569\n",
      "[3972/8000] D loss: 0.8324, G loss: 4.3299\n",
      "[4332/8000] D loss: 0.6957, G loss: 4.1678\n",
      "[4692/8000] D loss: 0.8001, G loss: 2.9906\n",
      "[5052/8000] D loss: 0.4410, G loss: 5.2566\n",
      "[5412/8000] D loss: 1.0195, G loss: 2.6827\n",
      "[5772/8000] D loss: 0.9024, G loss: 3.2894\n",
      "[6132/8000] D loss: 1.0578, G loss: 2.0758\n",
      "[6492/8000] D loss: 0.8578, G loss: 3.5438\n",
      "[6852/8000] D loss: 0.8557, G loss: 2.0134\n",
      "[7212/8000] D loss: 1.1196, G loss: 1.9493\n",
      "[7572/8000] D loss: 0.6740, G loss: 4.3082\n",
      "[7932/8000] D loss: 0.8403, G loss: 2.5579\n",
      "train error: \n",
      " D loss: 0.802418, G loss: 3.513546, D accuracy: 78.2%, cell accuracy: 98.4%, board accuracy: 28.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.690050, G loss: 6.550506, D accuracy: 83.0%, cell accuracy: 98.0%, board accuracy: 15.6% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8385, G loss: 4.8072\n",
      "[372/8000] D loss: 0.7532, G loss: 5.1203\n",
      "[732/8000] D loss: 0.6772, G loss: 4.0228\n",
      "[1092/8000] D loss: 0.9322, G loss: 2.0569\n",
      "[1452/8000] D loss: 0.5999, G loss: 5.5354\n",
      "[1812/8000] D loss: 1.0657, G loss: 2.4651\n",
      "[2172/8000] D loss: 0.4146, G loss: 5.4129\n",
      "[2532/8000] D loss: 0.6144, G loss: 4.7355\n",
      "[2892/8000] D loss: 1.0077, G loss: 2.7111\n",
      "[3252/8000] D loss: 0.8498, G loss: 3.1674\n",
      "[3612/8000] D loss: 1.0035, G loss: 1.5352\n",
      "[3972/8000] D loss: 0.6881, G loss: 4.2646\n",
      "[4332/8000] D loss: 1.1156, G loss: 3.5178\n",
      "[4692/8000] D loss: 0.9510, G loss: 2.8137\n",
      "[5052/8000] D loss: 0.7293, G loss: 5.3987\n",
      "[5412/8000] D loss: 0.8464, G loss: 3.0375\n",
      "[5772/8000] D loss: 0.5842, G loss: 3.2486\n",
      "[6132/8000] D loss: 0.7245, G loss: 2.0312\n",
      "[6492/8000] D loss: 0.7546, G loss: 4.2155\n",
      "[6852/8000] D loss: 0.9004, G loss: 3.3516\n",
      "[7212/8000] D loss: 0.9990, G loss: 2.3944\n",
      "[7572/8000] D loss: 0.7529, G loss: 3.7156\n",
      "[7932/8000] D loss: 0.5452, G loss: 4.4871\n",
      "train error: \n",
      " D loss: 0.781009, G loss: 3.903296, D accuracy: 77.5%, cell accuracy: 98.3%, board accuracy: 27.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.760094, G loss: 6.961471, D accuracy: 80.3%, cell accuracy: 98.0%, board accuracy: 13.9% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7830, G loss: 3.1185\n",
      "[372/8000] D loss: 0.7953, G loss: 2.8683\n",
      "[732/8000] D loss: 0.7777, G loss: 3.9490\n",
      "[1092/8000] D loss: 0.4832, G loss: 3.4688\n",
      "[1452/8000] D loss: 0.6924, G loss: 2.7779\n",
      "[1812/8000] D loss: 0.4718, G loss: 4.4841\n",
      "[2172/8000] D loss: 0.8327, G loss: 3.5838\n",
      "[2532/8000] D loss: 0.8190, G loss: 3.0775\n",
      "[2892/8000] D loss: 0.4003, G loss: 6.9757\n",
      "[3252/8000] D loss: 0.3699, G loss: 6.0972\n",
      "[3612/8000] D loss: 0.7249, G loss: 3.4734\n",
      "[3972/8000] D loss: 0.8697, G loss: 3.4903\n",
      "[4332/8000] D loss: 0.7680, G loss: 2.3655\n",
      "[4692/8000] D loss: 0.7521, G loss: 4.0424\n",
      "[5052/8000] D loss: 0.8329, G loss: 2.5464\n",
      "[5412/8000] D loss: 0.7712, G loss: 3.3920\n",
      "[5772/8000] D loss: 0.9132, G loss: 2.9321\n",
      "[6132/8000] D loss: 0.9353, G loss: 4.4103\n",
      "[6492/8000] D loss: 0.8505, G loss: 2.0664\n",
      "[6852/8000] D loss: 0.6949, G loss: 1.8487\n",
      "[7212/8000] D loss: 0.8400, G loss: 2.5686\n",
      "[7572/8000] D loss: 0.8115, G loss: 3.4254\n",
      "[7932/8000] D loss: 0.5411, G loss: 4.7799\n",
      "train error: \n",
      " D loss: 0.754759, G loss: 3.904481, D accuracy: 78.9%, cell accuracy: 98.4%, board accuracy: 27.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.711781, G loss: 7.026913, D accuracy: 81.6%, cell accuracy: 98.0%, board accuracy: 15.0% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8505, G loss: 2.3023\n",
      "[372/8000] D loss: 0.7700, G loss: 2.7905\n",
      "[732/8000] D loss: 0.9222, G loss: 1.5360\n",
      "[1092/8000] D loss: 0.6784, G loss: 4.9252\n",
      "[1452/8000] D loss: 0.8710, G loss: 2.9098\n",
      "[1812/8000] D loss: 0.6096, G loss: 4.5657\n",
      "[2172/8000] D loss: 1.1448, G loss: 3.4854\n",
      "[2532/8000] D loss: 0.4432, G loss: 4.5685\n",
      "[2892/8000] D loss: 0.7970, G loss: 2.4126\n",
      "[3252/8000] D loss: 0.7810, G loss: 3.4145\n",
      "[3612/8000] D loss: 0.8315, G loss: 3.6842\n",
      "[3972/8000] D loss: 0.4105, G loss: 7.3162\n",
      "[4332/8000] D loss: 0.4439, G loss: 6.6533\n",
      "[4692/8000] D loss: 0.7201, G loss: 4.5258\n",
      "[5052/8000] D loss: 0.5556, G loss: 4.4081\n",
      "[5412/8000] D loss: 0.6149, G loss: 2.8081\n",
      "[5772/8000] D loss: 0.9140, G loss: 1.9363\n",
      "[6132/8000] D loss: 0.9915, G loss: 2.5985\n",
      "[6492/8000] D loss: 0.6450, G loss: 2.4125\n",
      "[6852/8000] D loss: 1.1406, G loss: 2.4069\n",
      "[7212/8000] D loss: 0.8008, G loss: 3.3505\n",
      "[7572/8000] D loss: 0.7802, G loss: 3.4211\n",
      "[7932/8000] D loss: 0.5885, G loss: 4.2779\n",
      "train error: \n",
      " D loss: 0.760578, G loss: 3.775264, D accuracy: 79.1%, cell accuracy: 98.4%, board accuracy: 28.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.648139, G loss: 7.032611, D accuracy: 83.7%, cell accuracy: 98.0%, board accuracy: 15.7% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4965, G loss: 5.8609\n",
      "[372/8000] D loss: 0.5864, G loss: 4.7112\n",
      "[732/8000] D loss: 0.7798, G loss: 4.2716\n",
      "[1092/8000] D loss: 0.5514, G loss: 3.0096\n",
      "[1452/8000] D loss: 0.9326, G loss: 2.0725\n",
      "[1812/8000] D loss: 0.7346, G loss: 3.8185\n",
      "[2172/8000] D loss: 0.9212, G loss: 2.6911\n",
      "[2532/8000] D loss: 0.9469, G loss: 2.3923\n",
      "[2892/8000] D loss: 0.3849, G loss: 3.9910\n",
      "[3252/8000] D loss: 0.7594, G loss: 4.4590\n",
      "[3612/8000] D loss: 0.7887, G loss: 2.1801\n",
      "[3972/8000] D loss: 0.9618, G loss: 1.8518\n",
      "[4332/8000] D loss: 0.7878, G loss: 3.8249\n",
      "[4692/8000] D loss: 0.6777, G loss: 1.9954\n",
      "[5052/8000] D loss: 0.7648, G loss: 4.4557\n",
      "[5412/8000] D loss: 0.3078, G loss: 6.6088\n",
      "[5772/8000] D loss: 0.7122, G loss: 5.1315\n",
      "[6132/8000] D loss: 0.8255, G loss: 3.2781\n",
      "[6492/8000] D loss: 0.7088, G loss: 3.3088\n",
      "[6852/8000] D loss: 1.1304, G loss: 2.0558\n",
      "[7212/8000] D loss: 0.7421, G loss: 6.0063\n",
      "[7572/8000] D loss: 0.3827, G loss: 6.2203\n",
      "[7932/8000] D loss: 0.6224, G loss: 4.9177\n",
      "train error: \n",
      " D loss: 0.753776, G loss: 3.747638, D accuracy: 79.4%, cell accuracy: 98.4%, board accuracy: 28.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.688775, G loss: 6.920277, D accuracy: 82.3%, cell accuracy: 98.0%, board accuracy: 16.0% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8061, G loss: 5.0922\n",
      "[372/8000] D loss: 0.7109, G loss: 2.8212\n",
      "[732/8000] D loss: 0.8846, G loss: 4.3201\n",
      "[1092/8000] D loss: 0.6807, G loss: 3.0667\n",
      "[1452/8000] D loss: 0.7837, G loss: 2.1466\n",
      "[1812/8000] D loss: 1.1130, G loss: 2.9290\n",
      "[2172/8000] D loss: 0.7646, G loss: 4.5610\n",
      "[2532/8000] D loss: 1.2567, G loss: 1.2886\n",
      "[2892/8000] D loss: 0.9097, G loss: 2.0662\n",
      "[3252/8000] D loss: 0.6232, G loss: 4.9696\n",
      "[3612/8000] D loss: 0.7039, G loss: 2.4649\n",
      "[3972/8000] D loss: 0.6448, G loss: 4.1031\n",
      "[4332/8000] D loss: 0.9055, G loss: 1.6321\n",
      "[4692/8000] D loss: 0.8303, G loss: 2.7823\n",
      "[5052/8000] D loss: 1.0845, G loss: 3.6898\n",
      "[5412/8000] D loss: 0.5715, G loss: 4.3399\n",
      "[5772/8000] D loss: 0.8299, G loss: 2.7607\n",
      "[6132/8000] D loss: 0.5027, G loss: 6.2628\n",
      "[6492/8000] D loss: 0.8495, G loss: 3.4887\n",
      "[6852/8000] D loss: 0.7779, G loss: 4.2313\n",
      "[7212/8000] D loss: 0.6506, G loss: 5.0739\n",
      "[7572/8000] D loss: 0.7435, G loss: 3.7894\n",
      "[7932/8000] D loss: 1.0288, G loss: 2.0054\n",
      "train error: \n",
      " D loss: 0.770809, G loss: 3.487004, D accuracy: 78.6%, cell accuracy: 98.4%, board accuracy: 30.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.655044, G loss: 6.593009, D accuracy: 83.3%, cell accuracy: 98.0%, board accuracy: 16.9% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9324, G loss: 3.0561\n",
      "[372/8000] D loss: 0.7987, G loss: 2.6689\n",
      "[732/8000] D loss: 0.5683, G loss: 3.0975\n",
      "[1092/8000] D loss: 0.8150, G loss: 4.1717\n",
      "[1452/8000] D loss: 0.7350, G loss: 6.3548\n",
      "[1812/8000] D loss: 0.9601, G loss: 2.2442\n",
      "[2172/8000] D loss: 0.6748, G loss: 4.6235\n",
      "[2532/8000] D loss: 0.7348, G loss: 3.9949\n",
      "[2892/8000] D loss: 0.8542, G loss: 4.4276\n",
      "[3252/8000] D loss: 0.7109, G loss: 2.8599\n",
      "[3612/8000] D loss: 0.7385, G loss: 3.3342\n",
      "[3972/8000] D loss: 0.8632, G loss: 3.9864\n",
      "[4332/8000] D loss: 0.6406, G loss: 4.2672\n",
      "[4692/8000] D loss: 0.8475, G loss: 5.4028\n",
      "[5052/8000] D loss: 0.9854, G loss: 2.2560\n",
      "[5412/8000] D loss: 0.4172, G loss: 4.9978\n",
      "[5772/8000] D loss: 1.1882, G loss: 1.5993\n",
      "[6132/8000] D loss: 0.8460, G loss: 2.5535\n",
      "[6492/8000] D loss: 0.4679, G loss: 3.6533\n",
      "[6852/8000] D loss: 0.6334, G loss: 3.6546\n",
      "[7212/8000] D loss: 0.7488, G loss: 4.5200\n",
      "[7572/8000] D loss: 0.4348, G loss: 6.7470\n",
      "[7932/8000] D loss: 1.0184, G loss: 3.1118\n",
      "train error: \n",
      " D loss: 0.767346, G loss: 3.437764, D accuracy: 78.8%, cell accuracy: 98.4%, board accuracy: 29.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.624471, G loss: 6.629434, D accuracy: 84.5%, cell accuracy: 98.0%, board accuracy: 16.4% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5117, G loss: 5.0693\n",
      "[372/8000] D loss: 0.7737, G loss: 4.8116\n",
      "[732/8000] D loss: 0.7186, G loss: 2.8255\n",
      "[1092/8000] D loss: 0.6372, G loss: 4.6092\n",
      "[1452/8000] D loss: 0.3569, G loss: 4.8601\n",
      "[1812/8000] D loss: 0.6574, G loss: 5.8427\n",
      "[2172/8000] D loss: 1.1229, G loss: 2.7131\n",
      "[2532/8000] D loss: 0.8938, G loss: 3.6145\n",
      "[2892/8000] D loss: 0.6464, G loss: 3.5132\n",
      "[3252/8000] D loss: 1.0887, G loss: 2.0596\n",
      "[3612/8000] D loss: 0.7697, G loss: 2.1912\n",
      "[3972/8000] D loss: 0.8852, G loss: 3.8182\n",
      "[4332/8000] D loss: 0.7658, G loss: 4.0926\n",
      "[4692/8000] D loss: 0.7980, G loss: 2.0758\n",
      "[5052/8000] D loss: 0.6581, G loss: 2.7518\n",
      "[5412/8000] D loss: 0.6975, G loss: 4.5509\n",
      "[5772/8000] D loss: 0.7381, G loss: 3.0091\n",
      "[6132/8000] D loss: 0.3636, G loss: 4.5013\n",
      "[6492/8000] D loss: 0.6044, G loss: 4.7666\n",
      "[6852/8000] D loss: 0.7536, G loss: 3.1878\n",
      "[7212/8000] D loss: 0.7547, G loss: 2.7203\n",
      "[7572/8000] D loss: 0.5898, G loss: 3.6081\n",
      "[7932/8000] D loss: 1.5713, G loss: 1.2523\n",
      "train error: \n",
      " D loss: 0.835354, G loss: 2.854266, D accuracy: 77.2%, cell accuracy: 98.4%, board accuracy: 30.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.622003, G loss: 5.733990, D accuracy: 84.3%, cell accuracy: 98.0%, board accuracy: 17.0% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5114, G loss: 4.8882\n",
      "[372/8000] D loss: 0.8750, G loss: 4.0339\n",
      "[732/8000] D loss: 0.6574, G loss: 4.9335\n",
      "[1092/8000] D loss: 0.8214, G loss: 5.0493\n",
      "[1452/8000] D loss: 0.6563, G loss: 4.4535\n",
      "[1812/8000] D loss: 0.8401, G loss: 5.0205\n",
      "[2172/8000] D loss: 0.7238, G loss: 3.8545\n",
      "[2532/8000] D loss: 0.8517, G loss: 2.7808\n",
      "[2892/8000] D loss: 1.1990, G loss: 2.4337\n",
      "[3252/8000] D loss: 0.5440, G loss: 5.6333\n",
      "[3612/8000] D loss: 0.7382, G loss: 5.9578\n",
      "[3972/8000] D loss: 0.7299, G loss: 4.2007\n",
      "[4332/8000] D loss: 0.7998, G loss: 3.8237\n",
      "[4692/8000] D loss: 0.7141, G loss: 2.5340\n",
      "[5052/8000] D loss: 1.0371, G loss: 3.6856\n",
      "[5412/8000] D loss: 0.7697, G loss: 2.5115\n",
      "[5772/8000] D loss: 0.5052, G loss: 3.1432\n",
      "[6132/8000] D loss: 0.8983, G loss: 4.2929\n",
      "[6492/8000] D loss: 1.0382, G loss: 1.7677\n",
      "[6852/8000] D loss: 0.9980, G loss: 2.7628\n",
      "[7212/8000] D loss: 0.8366, G loss: 3.8967\n",
      "[7572/8000] D loss: 1.0713, G loss: 4.8169\n",
      "[7932/8000] D loss: 0.7313, G loss: 3.2271\n",
      "train error: \n",
      " D loss: 0.784753, G loss: 2.979671, D accuracy: 78.7%, cell accuracy: 98.4%, board accuracy: 29.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.621343, G loss: 6.084031, D accuracy: 85.1%, cell accuracy: 98.0%, board accuracy: 15.6% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6945, G loss: 2.9315\n",
      "[372/8000] D loss: 0.5959, G loss: 7.3216\n",
      "[732/8000] D loss: 0.8193, G loss: 3.0560\n",
      "[1092/8000] D loss: 0.9343, G loss: 2.2914\n",
      "[1452/8000] D loss: 1.1119, G loss: 2.4401\n",
      "[1812/8000] D loss: 1.2409, G loss: 3.8564\n",
      "[2172/8000] D loss: 0.6364, G loss: 4.3993\n",
      "[2532/8000] D loss: 0.5031, G loss: 3.5490\n",
      "[2892/8000] D loss: 1.1976, G loss: 0.8918\n",
      "[3252/8000] D loss: 0.4963, G loss: 2.0174\n",
      "[3612/8000] D loss: 0.7931, G loss: 4.2040\n",
      "[3972/8000] D loss: 0.7436, G loss: 3.6418\n",
      "[4332/8000] D loss: 0.9032, G loss: 1.3745\n",
      "[4692/8000] D loss: 0.7868, G loss: 3.1359\n",
      "[5052/8000] D loss: 1.0955, G loss: 1.8422\n",
      "[5412/8000] D loss: 0.7645, G loss: 5.1155\n",
      "[5772/8000] D loss: 1.0853, G loss: 1.5179\n",
      "[6132/8000] D loss: 0.7787, G loss: 5.2882\n",
      "[6492/8000] D loss: 0.7219, G loss: 2.9788\n",
      "[6852/8000] D loss: 0.7268, G loss: 4.0535\n",
      "[7212/8000] D loss: 0.9544, G loss: 4.0056\n",
      "[7572/8000] D loss: 0.6682, G loss: 5.8896\n",
      "[7932/8000] D loss: 0.8708, G loss: 1.7148\n",
      "train error: \n",
      " D loss: 0.816030, G loss: 3.806470, D accuracy: 76.6%, cell accuracy: 98.4%, board accuracy: 31.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.768699, G loss: 7.046773, D accuracy: 79.9%, cell accuracy: 98.0%, board accuracy: 16.6% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8951, G loss: 3.5502\n",
      "[372/8000] D loss: 0.7861, G loss: 3.9656\n",
      "[732/8000] D loss: 0.7421, G loss: 3.4778\n",
      "[1092/8000] D loss: 0.7036, G loss: 3.6264\n",
      "[1452/8000] D loss: 0.7170, G loss: 2.8107\n",
      "[1812/8000] D loss: 0.6869, G loss: 3.6946\n",
      "[2172/8000] D loss: 0.9074, G loss: 4.5944\n",
      "[2532/8000] D loss: 0.6961, G loss: 3.0520\n",
      "[2892/8000] D loss: 0.5533, G loss: 4.4141\n",
      "[3252/8000] D loss: 0.9599, G loss: 4.0354\n",
      "[3612/8000] D loss: 0.5777, G loss: 3.7236\n",
      "[3972/8000] D loss: 1.0576, G loss: 1.0752\n",
      "[4332/8000] D loss: 0.9451, G loss: 3.2163\n",
      "[4692/8000] D loss: 0.8005, G loss: 2.9725\n",
      "[5052/8000] D loss: 0.7202, G loss: 2.5674\n",
      "[5412/8000] D loss: 0.7121, G loss: 4.8148\n",
      "[5772/8000] D loss: 0.6269, G loss: 2.2433\n",
      "[6132/8000] D loss: 0.9473, G loss: 3.5780\n",
      "[6492/8000] D loss: 0.5570, G loss: 6.2690\n",
      "[6852/8000] D loss: 0.5437, G loss: 4.5965\n",
      "[7212/8000] D loss: 0.7114, G loss: 3.3431\n",
      "[7572/8000] D loss: 0.9791, G loss: 2.2631\n",
      "[7932/8000] D loss: 1.0887, G loss: 1.6280\n",
      "train error: \n",
      " D loss: 0.788957, G loss: 4.022940, D accuracy: 77.7%, cell accuracy: 98.4%, board accuracy: 31.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.754900, G loss: 7.507346, D accuracy: 80.2%, cell accuracy: 98.0%, board accuracy: 16.4% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6071, G loss: 6.2622\n",
      "[372/8000] D loss: 1.0372, G loss: 1.5582\n",
      "[732/8000] D loss: 0.5486, G loss: 6.3435\n",
      "[1092/8000] D loss: 1.0602, G loss: 1.0276\n",
      "[1452/8000] D loss: 0.7709, G loss: 5.1378\n",
      "[1812/8000] D loss: 0.7213, G loss: 2.3803\n",
      "[2172/8000] D loss: 1.0275, G loss: 3.5998\n",
      "[2532/8000] D loss: 0.6842, G loss: 4.2216\n",
      "[2892/8000] D loss: 0.6482, G loss: 3.1456\n",
      "[3252/8000] D loss: 1.1028, G loss: 1.1509\n",
      "[3612/8000] D loss: 1.1607, G loss: 3.6409\n",
      "[3972/8000] D loss: 0.6991, G loss: 3.7361\n",
      "[4332/8000] D loss: 0.6686, G loss: 3.1119\n",
      "[4692/8000] D loss: 0.8023, G loss: 3.3774\n",
      "[5052/8000] D loss: 0.6656, G loss: 4.8700\n",
      "[5412/8000] D loss: 0.7184, G loss: 6.3924\n",
      "[5772/8000] D loss: 0.6973, G loss: 4.3547\n",
      "[6132/8000] D loss: 0.4468, G loss: 3.4415\n",
      "[6492/8000] D loss: 0.6544, G loss: 5.2016\n",
      "[6852/8000] D loss: 0.7550, G loss: 4.5925\n",
      "[7212/8000] D loss: 0.4967, G loss: 3.8342\n",
      "[7572/8000] D loss: 0.7812, G loss: 3.6989\n",
      "[7932/8000] D loss: 0.5125, G loss: 3.8910\n",
      "train error: \n",
      " D loss: 0.774232, G loss: 3.908774, D accuracy: 78.8%, cell accuracy: 98.4%, board accuracy: 30.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.667891, G loss: 7.388919, D accuracy: 82.4%, cell accuracy: 98.0%, board accuracy: 16.0% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6190, G loss: 3.5728\n",
      "[372/8000] D loss: 0.7493, G loss: 3.3811\n",
      "[732/8000] D loss: 0.9105, G loss: 3.3470\n",
      "[1092/8000] D loss: 0.8973, G loss: 3.7880\n",
      "[1452/8000] D loss: 0.7052, G loss: 4.0252\n",
      "[1812/8000] D loss: 0.7633, G loss: 2.5737\n",
      "[2172/8000] D loss: 1.0280, G loss: 2.6844\n",
      "[2532/8000] D loss: 0.7409, G loss: 5.7210\n",
      "[2892/8000] D loss: 0.8952, G loss: 4.8415\n",
      "[3252/8000] D loss: 0.9565, G loss: 2.4187\n",
      "[3612/8000] D loss: 0.6132, G loss: 2.7124\n",
      "[3972/8000] D loss: 0.6934, G loss: 5.9972\n",
      "[4332/8000] D loss: 0.5498, G loss: 3.0124\n",
      "[4692/8000] D loss: 0.6632, G loss: 4.4071\n",
      "[5052/8000] D loss: 0.7252, G loss: 4.0756\n",
      "[5412/8000] D loss: 0.8184, G loss: 2.9330\n",
      "[5772/8000] D loss: 0.6317, G loss: 3.4848\n",
      "[6132/8000] D loss: 0.7128, G loss: 3.6996\n",
      "[6492/8000] D loss: 1.1107, G loss: 2.2410\n",
      "[6852/8000] D loss: 0.6257, G loss: 3.6788\n",
      "[7212/8000] D loss: 0.5694, G loss: 3.8536\n",
      "[7572/8000] D loss: 1.1336, G loss: 2.1547\n",
      "[7932/8000] D loss: 1.0551, G loss: 2.9107\n",
      "train error: \n",
      " D loss: 0.766781, G loss: 3.411318, D accuracy: 78.9%, cell accuracy: 98.4%, board accuracy: 30.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.650157, G loss: 6.551090, D accuracy: 83.6%, cell accuracy: 98.0%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6000, G loss: 3.5556\n",
      "[372/8000] D loss: 0.8798, G loss: 3.6927\n",
      "[732/8000] D loss: 0.6898, G loss: 3.6245\n",
      "[1092/8000] D loss: 0.9709, G loss: 2.4568\n",
      "[1452/8000] D loss: 0.5162, G loss: 5.1871\n",
      "[1812/8000] D loss: 0.4776, G loss: 3.9501\n",
      "[2172/8000] D loss: 0.9842, G loss: 2.4546\n",
      "[2532/8000] D loss: 1.0855, G loss: 2.7675\n",
      "[2892/8000] D loss: 0.6374, G loss: 4.5576\n",
      "[3252/8000] D loss: 0.8723, G loss: 5.2423\n",
      "[3612/8000] D loss: 0.7633, G loss: 3.6007\n",
      "[3972/8000] D loss: 0.9635, G loss: 2.3296\n",
      "[4332/8000] D loss: 1.0994, G loss: 2.1244\n",
      "[4692/8000] D loss: 0.9318, G loss: 3.1203\n",
      "[5052/8000] D loss: 0.8001, G loss: 2.2464\n",
      "[5412/8000] D loss: 0.4284, G loss: 8.0249\n",
      "[5772/8000] D loss: 0.7487, G loss: 2.8990\n",
      "[6132/8000] D loss: 0.8779, G loss: 4.8784\n",
      "[6492/8000] D loss: 0.5045, G loss: 4.8501\n",
      "[6852/8000] D loss: 0.6776, G loss: 2.0441\n",
      "[7212/8000] D loss: 0.6230, G loss: 2.0375\n",
      "[7572/8000] D loss: 0.4992, G loss: 5.2751\n",
      "[7932/8000] D loss: 0.9790, G loss: 3.5130\n",
      "train error: \n",
      " D loss: 0.777944, G loss: 3.214879, D accuracy: 79.1%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.628392, G loss: 6.434276, D accuracy: 84.5%, cell accuracy: 98.0%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6249, G loss: 2.8591\n",
      "[372/8000] D loss: 1.0273, G loss: 4.3345\n",
      "[732/8000] D loss: 1.0431, G loss: 3.4440\n",
      "[1092/8000] D loss: 0.5453, G loss: 2.7815\n",
      "[1452/8000] D loss: 0.7873, G loss: 3.0987\n",
      "[1812/8000] D loss: 0.8500, G loss: 3.0711\n",
      "[2172/8000] D loss: 0.8488, G loss: 2.9560\n",
      "[2532/8000] D loss: 0.9592, G loss: 1.8323\n",
      "[2892/8000] D loss: 0.9897, G loss: 2.3557\n",
      "[3252/8000] D loss: 1.0460, G loss: 2.0439\n",
      "[3612/8000] D loss: 0.6095, G loss: 4.7977\n",
      "[3972/8000] D loss: 0.7492, G loss: 3.9904\n",
      "[4332/8000] D loss: 0.7580, G loss: 3.9011\n",
      "[4692/8000] D loss: 0.8493, G loss: 3.5702\n",
      "[5052/8000] D loss: 0.7976, G loss: 2.5196\n",
      "[5412/8000] D loss: 0.6772, G loss: 2.9899\n",
      "[5772/8000] D loss: 1.2180, G loss: 2.9198\n",
      "[6132/8000] D loss: 0.7727, G loss: 4.8275\n",
      "[6492/8000] D loss: 0.6237, G loss: 4.4789\n",
      "[6852/8000] D loss: 0.8460, G loss: 3.9874\n",
      "[7212/8000] D loss: 0.9260, G loss: 4.0551\n",
      "[7572/8000] D loss: 0.7053, G loss: 3.6519\n",
      "[7932/8000] D loss: 0.5581, G loss: 3.3477\n",
      "train error: \n",
      " D loss: 0.757152, G loss: 3.692561, D accuracy: 79.0%, cell accuracy: 98.4%, board accuracy: 30.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.667344, G loss: 6.989436, D accuracy: 82.5%, cell accuracy: 98.0%, board accuracy: 16.9% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7080, G loss: 3.3254\n",
      "[372/8000] D loss: 0.9217, G loss: 3.8603\n",
      "[732/8000] D loss: 0.8352, G loss: 1.7324\n",
      "[1092/8000] D loss: 0.7699, G loss: 2.6418\n",
      "[1452/8000] D loss: 1.0703, G loss: 2.9784\n",
      "[1812/8000] D loss: 0.7003, G loss: 3.0547\n",
      "[2172/8000] D loss: 0.5132, G loss: 4.9008\n",
      "[2532/8000] D loss: 0.8133, G loss: 2.5434\n",
      "[2892/8000] D loss: 0.9736, G loss: 3.5113\n",
      "[3252/8000] D loss: 0.5276, G loss: 5.0837\n",
      "[3612/8000] D loss: 0.5795, G loss: 4.4202\n",
      "[3972/8000] D loss: 1.1387, G loss: 1.1338\n",
      "[4332/8000] D loss: 0.6865, G loss: 3.8510\n",
      "[4692/8000] D loss: 0.5840, G loss: 4.6617\n",
      "[5052/8000] D loss: 1.0078, G loss: 2.7101\n",
      "[5412/8000] D loss: 0.5736, G loss: 4.4319\n",
      "[5772/8000] D loss: 0.6113, G loss: 3.9837\n",
      "[6132/8000] D loss: 0.9973, G loss: 3.6865\n",
      "[6492/8000] D loss: 0.9555, G loss: 2.2551\n",
      "[6852/8000] D loss: 0.5879, G loss: 4.5129\n",
      "[7212/8000] D loss: 0.6517, G loss: 3.0655\n",
      "[7572/8000] D loss: 0.5922, G loss: 3.0552\n",
      "[7932/8000] D loss: 1.0309, G loss: 1.7781\n",
      "train error: \n",
      " D loss: 0.754870, G loss: 3.771121, D accuracy: 78.6%, cell accuracy: 98.4%, board accuracy: 30.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.695938, G loss: 7.267187, D accuracy: 82.1%, cell accuracy: 98.0%, board accuracy: 16.3% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9352, G loss: 3.9170\n",
      "[372/8000] D loss: 1.0817, G loss: 4.3112\n",
      "[732/8000] D loss: 0.9718, G loss: 2.7221\n",
      "[1092/8000] D loss: 0.5069, G loss: 5.3398\n",
      "[1452/8000] D loss: 0.5938, G loss: 4.2614\n",
      "[1812/8000] D loss: 0.5501, G loss: 5.9394\n",
      "[2172/8000] D loss: 0.3567, G loss: 5.3812\n",
      "[2532/8000] D loss: 0.8829, G loss: 2.1252\n",
      "[2892/8000] D loss: 0.9652, G loss: 4.0762\n",
      "[3252/8000] D loss: 0.7346, G loss: 3.5986\n",
      "[3612/8000] D loss: 0.7040, G loss: 2.6822\n",
      "[3972/8000] D loss: 0.4992, G loss: 6.5689\n",
      "[4332/8000] D loss: 0.7660, G loss: 3.7300\n",
      "[4692/8000] D loss: 0.5148, G loss: 4.6688\n",
      "[5052/8000] D loss: 0.7564, G loss: 4.8531\n",
      "[5412/8000] D loss: 0.7185, G loss: 4.4581\n",
      "[5772/8000] D loss: 0.7663, G loss: 2.7608\n",
      "[6132/8000] D loss: 0.7152, G loss: 2.2252\n",
      "[6492/8000] D loss: 0.7865, G loss: 2.9438\n",
      "[6852/8000] D loss: 0.5783, G loss: 6.0938\n",
      "[7212/8000] D loss: 0.7949, G loss: 2.7554\n",
      "[7572/8000] D loss: 0.6975, G loss: 6.5888\n",
      "[7932/8000] D loss: 0.6102, G loss: 5.1162\n",
      "train error: \n",
      " D loss: 0.758537, G loss: 3.774279, D accuracy: 78.9%, cell accuracy: 98.4%, board accuracy: 30.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.664189, G loss: 7.321621, D accuracy: 83.6%, cell accuracy: 98.0%, board accuracy: 16.3% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8739, G loss: 2.2854\n",
      "[372/8000] D loss: 0.5126, G loss: 7.3742\n",
      "[732/8000] D loss: 0.5350, G loss: 3.1673\n",
      "[1092/8000] D loss: 0.6713, G loss: 4.6244\n",
      "[1452/8000] D loss: 0.4173, G loss: 5.4512\n",
      "[1812/8000] D loss: 0.8370, G loss: 2.6339\n",
      "[2172/8000] D loss: 0.7854, G loss: 3.6553\n",
      "[2532/8000] D loss: 0.9367, G loss: 3.2504\n",
      "[2892/8000] D loss: 0.5533, G loss: 2.2405\n",
      "[3252/8000] D loss: 0.6023, G loss: 3.1887\n",
      "[3612/8000] D loss: 0.5474, G loss: 3.0043\n",
      "[3972/8000] D loss: 0.9361, G loss: 2.9745\n",
      "[4332/8000] D loss: 0.6725, G loss: 3.8365\n",
      "[4692/8000] D loss: 0.7441, G loss: 2.4964\n",
      "[5052/8000] D loss: 0.8976, G loss: 4.0238\n",
      "[5412/8000] D loss: 0.4552, G loss: 4.6455\n",
      "[5772/8000] D loss: 0.7299, G loss: 4.9389\n",
      "[6132/8000] D loss: 0.9102, G loss: 2.2946\n",
      "[6492/8000] D loss: 0.9552, G loss: 3.1276\n",
      "[6852/8000] D loss: 0.6436, G loss: 4.1599\n",
      "[7212/8000] D loss: 1.0629, G loss: 2.5020\n",
      "[7572/8000] D loss: 0.7060, G loss: 3.8541\n",
      "[7932/8000] D loss: 1.0835, G loss: 1.6120\n",
      "train error: \n",
      " D loss: 0.799083, G loss: 3.654344, D accuracy: 77.3%, cell accuracy: 98.4%, board accuracy: 32.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.745265, G loss: 7.080455, D accuracy: 80.0%, cell accuracy: 98.0%, board accuracy: 17.2% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9125, G loss: 4.6578\n",
      "[372/8000] D loss: 0.9885, G loss: 2.9764\n",
      "[732/8000] D loss: 0.8019, G loss: 3.5424\n",
      "[1092/8000] D loss: 1.4577, G loss: 2.3557\n",
      "[1452/8000] D loss: 0.8192, G loss: 3.2015\n",
      "[1812/8000] D loss: 0.8211, G loss: 3.1824\n",
      "[2172/8000] D loss: 0.6574, G loss: 3.3871\n",
      "[2532/8000] D loss: 1.1775, G loss: 1.8414\n",
      "[2892/8000] D loss: 0.7017, G loss: 3.4029\n",
      "[3252/8000] D loss: 0.8619, G loss: 3.7330\n",
      "[3612/8000] D loss: 0.7985, G loss: 4.1599\n",
      "[3972/8000] D loss: 0.6591, G loss: 2.4173\n",
      "[4332/8000] D loss: 0.7677, G loss: 3.5301\n",
      "[4692/8000] D loss: 0.5338, G loss: 5.8165\n",
      "[5052/8000] D loss: 0.7668, G loss: 3.5700\n",
      "[5412/8000] D loss: 0.5571, G loss: 3.6693\n",
      "[5772/8000] D loss: 1.3820, G loss: 2.6597\n",
      "[6132/8000] D loss: 0.9968, G loss: 2.5693\n",
      "[6492/8000] D loss: 0.9305, G loss: 1.9392\n",
      "[6852/8000] D loss: 0.9472, G loss: 2.1955\n",
      "[7212/8000] D loss: 0.8643, G loss: 3.3607\n",
      "[7572/8000] D loss: 0.7538, G loss: 3.0496\n",
      "[7932/8000] D loss: 0.6216, G loss: 4.1905\n",
      "train error: \n",
      " D loss: 0.830359, G loss: 2.790592, D accuracy: 77.8%, cell accuracy: 98.4%, board accuracy: 31.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.616457, G loss: 6.054291, D accuracy: 85.2%, cell accuracy: 98.0%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9422, G loss: 3.1131\n",
      "[372/8000] D loss: 0.7628, G loss: 2.7083\n",
      "[732/8000] D loss: 1.0152, G loss: 3.4295\n",
      "[1092/8000] D loss: 1.2011, G loss: 2.9800\n",
      "[1452/8000] D loss: 1.0878, G loss: 1.2743\n",
      "[1812/8000] D loss: 0.5265, G loss: 4.2478\n",
      "[2172/8000] D loss: 0.6647, G loss: 5.3913\n",
      "[2532/8000] D loss: 0.5513, G loss: 5.5905\n",
      "[2892/8000] D loss: 0.9145, G loss: 3.1802\n",
      "[3252/8000] D loss: 0.5112, G loss: 4.3135\n",
      "[3612/8000] D loss: 0.6002, G loss: 5.3968\n",
      "[3972/8000] D loss: 0.3874, G loss: 4.4981\n",
      "[4332/8000] D loss: 0.8209, G loss: 2.3323\n",
      "[4692/8000] D loss: 0.5249, G loss: 4.1314\n",
      "[5052/8000] D loss: 0.5379, G loss: 5.9348\n",
      "[5412/8000] D loss: 0.7145, G loss: 2.8964\n",
      "[5772/8000] D loss: 0.7816, G loss: 1.9940\n",
      "[6132/8000] D loss: 0.6899, G loss: 3.2329\n",
      "[6492/8000] D loss: 0.7272, G loss: 3.2785\n",
      "[6852/8000] D loss: 0.7196, G loss: 3.9592\n",
      "[7212/8000] D loss: 0.3244, G loss: 4.9279\n",
      "[7572/8000] D loss: 0.4902, G loss: 4.4466\n",
      "[7932/8000] D loss: 0.5952, G loss: 3.7415\n",
      "train error: \n",
      " D loss: 0.804883, G loss: 3.018158, D accuracy: 77.0%, cell accuracy: 98.4%, board accuracy: 32.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.691714, G loss: 6.049175, D accuracy: 82.4%, cell accuracy: 98.0%, board accuracy: 17.8% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9657, G loss: 2.1438\n",
      "[372/8000] D loss: 1.0246, G loss: 2.1547\n",
      "[732/8000] D loss: 0.7065, G loss: 1.8898\n",
      "[1092/8000] D loss: 1.0684, G loss: 2.3149\n",
      "[1452/8000] D loss: 0.8637, G loss: 3.3827\n",
      "[1812/8000] D loss: 0.4217, G loss: 4.8500\n",
      "[2172/8000] D loss: 0.9221, G loss: 2.8233\n",
      "[2532/8000] D loss: 0.6185, G loss: 5.5167\n",
      "[2892/8000] D loss: 0.8145, G loss: 2.1554\n",
      "[3252/8000] D loss: 0.4584, G loss: 3.3557\n",
      "[3612/8000] D loss: 0.7821, G loss: 3.9601\n",
      "[3972/8000] D loss: 0.6830, G loss: 4.1653\n",
      "[4332/8000] D loss: 0.7040, G loss: 3.4084\n",
      "[4692/8000] D loss: 0.6993, G loss: 2.8572\n",
      "[5052/8000] D loss: 1.0201, G loss: 2.8914\n",
      "[5412/8000] D loss: 0.5598, G loss: 3.7760\n",
      "[5772/8000] D loss: 0.6930, G loss: 3.9636\n",
      "[6132/8000] D loss: 1.0376, G loss: 1.9379\n",
      "[6492/8000] D loss: 0.7018, G loss: 3.6291\n",
      "[6852/8000] D loss: 0.5903, G loss: 5.1471\n",
      "[7212/8000] D loss: 0.7713, G loss: 2.1657\n",
      "[7572/8000] D loss: 0.6495, G loss: 5.2115\n",
      "[7932/8000] D loss: 0.6102, G loss: 3.1872\n",
      "train error: \n",
      " D loss: 0.803347, G loss: 3.814752, D accuracy: 76.8%, cell accuracy: 98.4%, board accuracy: 32.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.781186, G loss: 7.260275, D accuracy: 79.1%, cell accuracy: 98.0%, board accuracy: 17.2% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5702, G loss: 3.5071\n",
      "[372/8000] D loss: 0.6382, G loss: 6.2082\n",
      "[732/8000] D loss: 0.9314, G loss: 3.0619\n",
      "[1092/8000] D loss: 0.6276, G loss: 5.8410\n",
      "[1452/8000] D loss: 0.6590, G loss: 7.4355\n",
      "[1812/8000] D loss: 0.5624, G loss: 5.6027\n",
      "[2172/8000] D loss: 0.9559, G loss: 1.7448\n",
      "[2532/8000] D loss: 0.8706, G loss: 2.5236\n",
      "[2892/8000] D loss: 0.8742, G loss: 2.9044\n",
      "[3252/8000] D loss: 0.6172, G loss: 4.8460\n",
      "[3612/8000] D loss: 0.7181, G loss: 4.6929\n",
      "[3972/8000] D loss: 0.4251, G loss: 4.6832\n",
      "[4332/8000] D loss: 0.7927, G loss: 3.2241\n",
      "[4692/8000] D loss: 0.6491, G loss: 6.2401\n",
      "[5052/8000] D loss: 0.6946, G loss: 4.6179\n",
      "[5412/8000] D loss: 0.5529, G loss: 3.9840\n",
      "[5772/8000] D loss: 1.0665, G loss: 2.7511\n",
      "[6132/8000] D loss: 0.8872, G loss: 2.8552\n",
      "[6492/8000] D loss: 0.7488, G loss: 3.7969\n",
      "[6852/8000] D loss: 0.6491, G loss: 2.1794\n",
      "[7212/8000] D loss: 0.5730, G loss: 5.5733\n",
      "[7572/8000] D loss: 0.7268, G loss: 5.1516\n",
      "[7932/8000] D loss: 1.1035, G loss: 2.6372\n",
      "train error: \n",
      " D loss: 0.740381, G loss: 3.833147, D accuracy: 79.1%, cell accuracy: 98.4%, board accuracy: 32.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.674292, G loss: 7.686833, D accuracy: 82.7%, cell accuracy: 98.0%, board accuracy: 16.2% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5974, G loss: 4.4649\n",
      "[372/8000] D loss: 0.6974, G loss: 4.6360\n",
      "[732/8000] D loss: 0.6916, G loss: 3.3059\n",
      "[1092/8000] D loss: 0.5965, G loss: 5.5252\n",
      "[1452/8000] D loss: 0.9429, G loss: 1.5550\n",
      "[1812/8000] D loss: 0.7390, G loss: 3.5332\n",
      "[2172/8000] D loss: 0.5507, G loss: 7.5640\n",
      "[2532/8000] D loss: 0.8719, G loss: 2.6355\n",
      "[2892/8000] D loss: 0.6241, G loss: 6.6591\n",
      "[3252/8000] D loss: 1.0298, G loss: 3.7866\n",
      "[3612/8000] D loss: 0.8850, G loss: 3.8190\n",
      "[3972/8000] D loss: 0.7969, G loss: 2.6900\n",
      "[4332/8000] D loss: 0.8039, G loss: 2.6949\n",
      "[4692/8000] D loss: 0.8996, G loss: 3.8060\n",
      "[5052/8000] D loss: 0.6203, G loss: 4.0589\n",
      "[5412/8000] D loss: 0.7087, G loss: 4.1321\n",
      "[5772/8000] D loss: 0.7628, G loss: 2.6845\n",
      "[6132/8000] D loss: 0.7700, G loss: 2.3581\n",
      "[6492/8000] D loss: 0.9196, G loss: 2.9354\n",
      "[6852/8000] D loss: 0.2331, G loss: 5.9380\n",
      "[7212/8000] D loss: 0.8563, G loss: 3.3684\n",
      "[7572/8000] D loss: 0.9709, G loss: 2.5753\n",
      "[7932/8000] D loss: 0.6668, G loss: 2.5913\n",
      "train error: \n",
      " D loss: 0.763949, G loss: 3.775728, D accuracy: 78.4%, cell accuracy: 98.4%, board accuracy: 32.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.668451, G loss: 7.551049, D accuracy: 83.3%, cell accuracy: 98.0%, board accuracy: 18.4% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3888, G loss: 4.9739\n",
      "[372/8000] D loss: 0.9530, G loss: 3.8441\n",
      "[732/8000] D loss: 0.6701, G loss: 4.1643\n",
      "[1092/8000] D loss: 0.5623, G loss: 5.6120\n",
      "[1452/8000] D loss: 0.6576, G loss: 5.4397\n",
      "[1812/8000] D loss: 0.7350, G loss: 2.9180\n",
      "[2172/8000] D loss: 0.4790, G loss: 3.9721\n",
      "[2532/8000] D loss: 0.9924, G loss: 1.8631\n",
      "[2892/8000] D loss: 0.7630, G loss: 2.7591\n",
      "[3252/8000] D loss: 0.3671, G loss: 8.6471\n",
      "[3612/8000] D loss: 0.8678, G loss: 4.1211\n",
      "[3972/8000] D loss: 0.8156, G loss: 4.4292\n",
      "[4332/8000] D loss: 0.6765, G loss: 3.4802\n",
      "[4692/8000] D loss: 0.8058, G loss: 2.7978\n",
      "[5052/8000] D loss: 1.0420, G loss: 3.0518\n",
      "[5412/8000] D loss: 0.6438, G loss: 2.3065\n",
      "[5772/8000] D loss: 1.1684, G loss: 1.2479\n",
      "[6132/8000] D loss: 0.7717, G loss: 3.4370\n",
      "[6492/8000] D loss: 0.6119, G loss: 5.8453\n",
      "[6852/8000] D loss: 0.7912, G loss: 2.8388\n",
      "[7212/8000] D loss: 0.9461, G loss: 1.5618\n",
      "[7572/8000] D loss: 1.0356, G loss: 2.9889\n",
      "[7932/8000] D loss: 0.8292, G loss: 3.8647\n",
      "train error: \n",
      " D loss: 0.825376, G loss: 3.119477, D accuracy: 77.4%, cell accuracy: 98.5%, board accuracy: 33.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626421, G loss: 6.667136, D accuracy: 84.6%, cell accuracy: 98.1%, board accuracy: 17.0% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6626, G loss: 3.9724\n",
      "[372/8000] D loss: 0.9018, G loss: 3.6785\n",
      "[732/8000] D loss: 0.4742, G loss: 3.2789\n",
      "[1092/8000] D loss: 0.8286, G loss: 2.4611\n",
      "[1452/8000] D loss: 0.6035, G loss: 4.3055\n",
      "[1812/8000] D loss: 0.6285, G loss: 2.7792\n",
      "[2172/8000] D loss: 0.7492, G loss: 4.2261\n",
      "[2532/8000] D loss: 0.9007, G loss: 3.8957\n",
      "[2892/8000] D loss: 0.6643, G loss: 3.2318\n",
      "[3252/8000] D loss: 0.4064, G loss: 4.9756\n",
      "[3612/8000] D loss: 0.8985, G loss: 2.4990\n",
      "[3972/8000] D loss: 1.0561, G loss: 1.1770\n",
      "[4332/8000] D loss: 0.7707, G loss: 3.4835\n",
      "[4692/8000] D loss: 0.8835, G loss: 3.2518\n",
      "[5052/8000] D loss: 0.4336, G loss: 4.3872\n",
      "[5412/8000] D loss: 0.8756, G loss: 4.4448\n",
      "[5772/8000] D loss: 0.4706, G loss: 4.5811\n",
      "[6132/8000] D loss: 1.1401, G loss: 1.6082\n",
      "[6492/8000] D loss: 0.8434, G loss: 4.5122\n",
      "[6852/8000] D loss: 0.4874, G loss: 4.3645\n",
      "[7212/8000] D loss: 0.9055, G loss: 3.1353\n",
      "[7572/8000] D loss: 0.6644, G loss: 3.1716\n",
      "[7932/8000] D loss: 0.4063, G loss: 4.5411\n",
      "train error: \n",
      " D loss: 0.783952, G loss: 3.882614, D accuracy: 77.9%, cell accuracy: 98.5%, board accuracy: 32.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.718430, G loss: 7.665978, D accuracy: 81.8%, cell accuracy: 98.0%, board accuracy: 17.5% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7805, G loss: 5.7658\n",
      "[372/8000] D loss: 0.8840, G loss: 3.2635\n",
      "[732/8000] D loss: 0.7421, G loss: 2.9930\n",
      "[1092/8000] D loss: 0.4403, G loss: 4.6003\n",
      "[1452/8000] D loss: 0.3646, G loss: 5.6098\n",
      "[1812/8000] D loss: 0.7909, G loss: 4.1636\n",
      "[2172/8000] D loss: 0.3186, G loss: 5.9930\n",
      "[2532/8000] D loss: 0.3962, G loss: 6.1946\n",
      "[2892/8000] D loss: 0.8108, G loss: 4.0488\n",
      "[3252/8000] D loss: 0.7635, G loss: 3.9386\n",
      "[3612/8000] D loss: 0.6258, G loss: 4.6513\n",
      "[3972/8000] D loss: 0.6207, G loss: 6.2885\n",
      "[4332/8000] D loss: 0.9327, G loss: 2.2355\n",
      "[4692/8000] D loss: 1.0136, G loss: 3.5507\n",
      "[5052/8000] D loss: 0.7810, G loss: 3.2262\n",
      "[5412/8000] D loss: 0.7638, G loss: 3.0807\n",
      "[5772/8000] D loss: 0.8395, G loss: 2.7910\n",
      "[6132/8000] D loss: 0.9533, G loss: 2.9361\n",
      "[6492/8000] D loss: 0.8834, G loss: 2.4236\n",
      "[6852/8000] D loss: 0.9965, G loss: 1.7662\n",
      "[7212/8000] D loss: 0.9094, G loss: 5.1685\n",
      "[7572/8000] D loss: 0.7082, G loss: 1.9889\n",
      "[7932/8000] D loss: 1.1157, G loss: 1.9765\n",
      "train error: \n",
      " D loss: 0.813322, G loss: 3.910936, D accuracy: 76.7%, cell accuracy: 98.5%, board accuracy: 34.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.788051, G loss: 7.507877, D accuracy: 78.5%, cell accuracy: 98.1%, board accuracy: 17.9% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7133, G loss: 4.1526\n",
      "[372/8000] D loss: 0.6544, G loss: 5.6075\n",
      "[732/8000] D loss: 0.6642, G loss: 6.1127\n",
      "[1092/8000] D loss: 0.4368, G loss: 5.0159\n",
      "[1452/8000] D loss: 0.6778, G loss: 5.2836\n",
      "[1812/8000] D loss: 1.2191, G loss: 1.8055\n",
      "[2172/8000] D loss: 1.0932, G loss: 2.4924\n",
      "[2532/8000] D loss: 0.7990, G loss: 2.5543\n",
      "[2892/8000] D loss: 1.2168, G loss: 2.4031\n",
      "[3252/8000] D loss: 0.7775, G loss: 2.9294\n",
      "[3612/8000] D loss: 0.9223, G loss: 2.4287\n",
      "[3972/8000] D loss: 0.9438, G loss: 2.5159\n",
      "[4332/8000] D loss: 0.8602, G loss: 2.9680\n",
      "[4692/8000] D loss: 0.8527, G loss: 4.8273\n",
      "[5052/8000] D loss: 0.8814, G loss: 2.5082\n",
      "[5412/8000] D loss: 0.6912, G loss: 3.0011\n",
      "[5772/8000] D loss: 0.6655, G loss: 3.4581\n",
      "[6132/8000] D loss: 0.8058, G loss: 2.1171\n",
      "[6492/8000] D loss: 0.7565, G loss: 3.0251\n",
      "[6852/8000] D loss: 0.8914, G loss: 4.0524\n",
      "[7212/8000] D loss: 0.7365, G loss: 4.1824\n",
      "[7572/8000] D loss: 0.8059, G loss: 4.1004\n",
      "[7932/8000] D loss: 0.9357, G loss: 3.6239\n",
      "train error: \n",
      " D loss: 0.800867, G loss: 3.212739, D accuracy: 77.9%, cell accuracy: 98.5%, board accuracy: 33.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.629601, G loss: 6.855040, D accuracy: 84.8%, cell accuracy: 98.0%, board accuracy: 18.1% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1853, G loss: 2.7310\n",
      "[372/8000] D loss: 0.4789, G loss: 4.5132\n",
      "[732/8000] D loss: 0.6817, G loss: 4.3069\n",
      "[1092/8000] D loss: 0.9737, G loss: 3.9941\n",
      "[1452/8000] D loss: 0.3518, G loss: 4.8935\n",
      "[1812/8000] D loss: 1.0328, G loss: 2.3498\n",
      "[2172/8000] D loss: 1.1155, G loss: 1.5571\n",
      "[2532/8000] D loss: 0.6851, G loss: 3.5071\n",
      "[2892/8000] D loss: 0.5871, G loss: 4.0914\n",
      "[3252/8000] D loss: 0.7611, G loss: 2.9952\n",
      "[3612/8000] D loss: 0.6040, G loss: 4.5635\n",
      "[3972/8000] D loss: 0.8639, G loss: 2.2526\n",
      "[4332/8000] D loss: 0.6412, G loss: 8.4655\n",
      "[4692/8000] D loss: 1.0360, G loss: 1.9063\n",
      "[5052/8000] D loss: 0.8364, G loss: 2.1450\n",
      "[5412/8000] D loss: 1.0572, G loss: 2.2216\n",
      "[5772/8000] D loss: 0.7276, G loss: 3.4989\n",
      "[6132/8000] D loss: 0.9748, G loss: 2.2440\n",
      "[6492/8000] D loss: 0.8161, G loss: 4.3078\n",
      "[6852/8000] D loss: 0.7443, G loss: 4.4648\n",
      "[7212/8000] D loss: 0.8353, G loss: 2.8327\n",
      "[7572/8000] D loss: 0.5378, G loss: 5.8671\n",
      "[7932/8000] D loss: 0.6883, G loss: 4.2604\n",
      "train error: \n",
      " D loss: 0.791934, G loss: 3.673519, D accuracy: 77.3%, cell accuracy: 98.5%, board accuracy: 34.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.729597, G loss: 7.525153, D accuracy: 82.3%, cell accuracy: 98.0%, board accuracy: 18.6% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4710, G loss: 4.9248\n",
      "[372/8000] D loss: 1.1247, G loss: 1.7555\n",
      "[732/8000] D loss: 0.6730, G loss: 3.9855\n",
      "[1092/8000] D loss: 0.5419, G loss: 4.4832\n",
      "[1452/8000] D loss: 0.6214, G loss: 4.5954\n",
      "[1812/8000] D loss: 0.9746, G loss: 2.7545\n",
      "[2172/8000] D loss: 0.6741, G loss: 3.8820\n",
      "[2532/8000] D loss: 0.5225, G loss: 4.3680\n",
      "[2892/8000] D loss: 0.7706, G loss: 2.7190\n",
      "[3252/8000] D loss: 0.8838, G loss: 2.0897\n",
      "[3612/8000] D loss: 0.7364, G loss: 3.7999\n",
      "[3972/8000] D loss: 0.8560, G loss: 2.1805\n",
      "[4332/8000] D loss: 0.6927, G loss: 2.2587\n",
      "[4692/8000] D loss: 0.9453, G loss: 3.4884\n",
      "[5052/8000] D loss: 1.1164, G loss: 3.5235\n",
      "[5412/8000] D loss: 0.9704, G loss: 1.8241\n",
      "[5772/8000] D loss: 0.5379, G loss: 4.5459\n",
      "[6132/8000] D loss: 0.9507, G loss: 1.8474\n",
      "[6492/8000] D loss: 0.8844, G loss: 2.7154\n",
      "[6852/8000] D loss: 0.7298, G loss: 2.1424\n",
      "[7212/8000] D loss: 0.8008, G loss: 2.4615\n",
      "[7572/8000] D loss: 0.8087, G loss: 2.7304\n",
      "[7932/8000] D loss: 0.7966, G loss: 2.8304\n",
      "train error: \n",
      " D loss: 0.798000, G loss: 3.946431, D accuracy: 76.7%, cell accuracy: 98.5%, board accuracy: 34.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.744696, G loss: 7.667728, D accuracy: 80.4%, cell accuracy: 98.0%, board accuracy: 18.2% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9871, G loss: 2.7177\n",
      "[372/8000] D loss: 0.7723, G loss: 4.8398\n",
      "[732/8000] D loss: 1.2108, G loss: 1.4088\n",
      "[1092/8000] D loss: 0.7777, G loss: 3.8934\n",
      "[1452/8000] D loss: 0.7064, G loss: 5.2440\n",
      "[1812/8000] D loss: 0.8737, G loss: 2.7538\n",
      "[2172/8000] D loss: 0.6558, G loss: 3.7171\n",
      "[2532/8000] D loss: 0.9307, G loss: 3.1112\n",
      "[2892/8000] D loss: 0.9494, G loss: 2.8091\n",
      "[3252/8000] D loss: 0.9717, G loss: 3.0557\n",
      "[3612/8000] D loss: 0.9191, G loss: 2.7771\n",
      "[3972/8000] D loss: 0.6342, G loss: 4.8174\n",
      "[4332/8000] D loss: 1.0775, G loss: 2.2160\n",
      "[4692/8000] D loss: 0.8705, G loss: 2.8329\n",
      "[5052/8000] D loss: 0.8153, G loss: 5.4534\n",
      "[5412/8000] D loss: 0.8098, G loss: 2.7285\n",
      "[5772/8000] D loss: 0.9184, G loss: 2.6333\n",
      "[6132/8000] D loss: 0.7726, G loss: 2.4905\n",
      "[6492/8000] D loss: 0.6034, G loss: 3.6854\n",
      "[6852/8000] D loss: 0.7686, G loss: 3.2479\n",
      "[7212/8000] D loss: 0.7924, G loss: 1.7491\n",
      "[7572/8000] D loss: 0.8451, G loss: 4.7544\n",
      "[7932/8000] D loss: 1.0993, G loss: 2.0336\n",
      "train error: \n",
      " D loss: 0.852419, G loss: 4.074568, D accuracy: 75.7%, cell accuracy: 98.5%, board accuracy: 35.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.822393, G loss: 7.911686, D accuracy: 78.2%, cell accuracy: 98.1%, board accuracy: 18.4% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1648, G loss: 2.3789\n",
      "[372/8000] D loss: 1.2653, G loss: 1.3359\n",
      "[732/8000] D loss: 0.6877, G loss: 3.3458\n",
      "[1092/8000] D loss: 0.7045, G loss: 3.9151\n",
      "[1452/8000] D loss: 0.9761, G loss: 2.4964\n",
      "[1812/8000] D loss: 0.5890, G loss: 3.0775\n",
      "[2172/8000] D loss: 0.8346, G loss: 1.9142\n",
      "[2532/8000] D loss: 1.1314, G loss: 2.9385\n",
      "[2892/8000] D loss: 0.7124, G loss: 5.0687\n",
      "[3252/8000] D loss: 0.7958, G loss: 4.5596\n",
      "[3612/8000] D loss: 0.6446, G loss: 4.7565\n",
      "[3972/8000] D loss: 0.6973, G loss: 3.8618\n",
      "[4332/8000] D loss: 0.8046, G loss: 3.5275\n",
      "[4692/8000] D loss: 0.9573, G loss: 1.8316\n",
      "[5052/8000] D loss: 1.2673, G loss: 2.4680\n",
      "[5412/8000] D loss: 0.7577, G loss: 6.2876\n",
      "[5772/8000] D loss: 0.7180, G loss: 3.6358\n",
      "[6132/8000] D loss: 0.8105, G loss: 3.9212\n",
      "[6492/8000] D loss: 0.5076, G loss: 6.3508\n",
      "[6852/8000] D loss: 0.7144, G loss: 3.5050\n",
      "[7212/8000] D loss: 0.7166, G loss: 5.2379\n",
      "[7572/8000] D loss: 0.7844, G loss: 2.9468\n",
      "[7932/8000] D loss: 0.7234, G loss: 2.6182\n",
      "train error: \n",
      " D loss: 0.786636, G loss: 3.922472, D accuracy: 76.9%, cell accuracy: 98.5%, board accuracy: 33.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.762097, G loss: 7.636714, D accuracy: 80.0%, cell accuracy: 98.1%, board accuracy: 18.1% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6820, G loss: 4.9728\n",
      "[372/8000] D loss: 0.6607, G loss: 5.5272\n",
      "[732/8000] D loss: 0.7905, G loss: 4.0385\n",
      "[1092/8000] D loss: 0.5804, G loss: 6.5238\n",
      "[1452/8000] D loss: 0.8172, G loss: 3.3069\n",
      "[1812/8000] D loss: 0.5504, G loss: 2.5729\n",
      "[2172/8000] D loss: 0.4745, G loss: 4.2050\n",
      "[2532/8000] D loss: 0.6155, G loss: 3.5003\n",
      "[2892/8000] D loss: 0.5352, G loss: 6.9029\n",
      "[3252/8000] D loss: 0.6569, G loss: 3.5988\n",
      "[3612/8000] D loss: 0.7468, G loss: 2.1567\n",
      "[3972/8000] D loss: 0.7998, G loss: 6.6083\n",
      "[4332/8000] D loss: 0.6322, G loss: 3.9813\n",
      "[4692/8000] D loss: 0.7646, G loss: 3.8091\n",
      "[5052/8000] D loss: 0.7002, G loss: 2.8568\n",
      "[5412/8000] D loss: 0.5382, G loss: 3.2946\n",
      "[5772/8000] D loss: 0.6996, G loss: 3.5866\n",
      "[6132/8000] D loss: 0.6914, G loss: 5.7129\n",
      "[6492/8000] D loss: 0.8606, G loss: 2.4863\n",
      "[6852/8000] D loss: 0.8893, G loss: 2.5000\n",
      "[7212/8000] D loss: 0.9185, G loss: 3.0030\n",
      "[7572/8000] D loss: 0.7860, G loss: 2.6682\n",
      "[7932/8000] D loss: 0.6064, G loss: 4.4688\n",
      "train error: \n",
      " D loss: 0.830167, G loss: 3.370402, D accuracy: 75.7%, cell accuracy: 98.4%, board accuracy: 34.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.775710, G loss: 6.791391, D accuracy: 80.3%, cell accuracy: 98.0%, board accuracy: 18.1% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5328, G loss: 3.9168\n",
      "[372/8000] D loss: 1.0159, G loss: 1.8953\n",
      "[732/8000] D loss: 1.1769, G loss: 1.5337\n",
      "[1092/8000] D loss: 0.9139, G loss: 3.6150\n",
      "[1452/8000] D loss: 0.6779, G loss: 4.6252\n",
      "[1812/8000] D loss: 0.7754, G loss: 3.2637\n",
      "[2172/8000] D loss: 0.7524, G loss: 3.7429\n",
      "[2532/8000] D loss: 0.5254, G loss: 4.7020\n",
      "[2892/8000] D loss: 0.6313, G loss: 6.7314\n",
      "[3252/8000] D loss: 1.0720, G loss: 1.5423\n",
      "[3612/8000] D loss: 0.8145, G loss: 3.3272\n",
      "[3972/8000] D loss: 0.7399, G loss: 2.8951\n",
      "[4332/8000] D loss: 0.6823, G loss: 4.2709\n",
      "[4692/8000] D loss: 0.7885, G loss: 2.9950\n",
      "[5052/8000] D loss: 1.0376, G loss: 3.9374\n",
      "[5412/8000] D loss: 0.9490, G loss: 2.6420\n",
      "[5772/8000] D loss: 0.6072, G loss: 5.4590\n",
      "[6132/8000] D loss: 0.6958, G loss: 5.4028\n",
      "[6492/8000] D loss: 0.6737, G loss: 5.2649\n",
      "[6852/8000] D loss: 0.9230, G loss: 1.6022\n",
      "[7212/8000] D loss: 0.8314, G loss: 4.6170\n",
      "[7572/8000] D loss: 0.5453, G loss: 4.7519\n",
      "[7932/8000] D loss: 0.4801, G loss: 3.5652\n",
      "train error: \n",
      " D loss: 0.812104, G loss: 4.042254, D accuracy: 76.6%, cell accuracy: 98.5%, board accuracy: 34.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.823692, G loss: 7.931145, D accuracy: 77.4%, cell accuracy: 98.0%, board accuracy: 19.1% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8583, G loss: 5.2165\n",
      "[372/8000] D loss: 0.7416, G loss: 3.4990\n",
      "[732/8000] D loss: 1.1318, G loss: 3.1901\n",
      "[1092/8000] D loss: 0.7153, G loss: 2.3301\n",
      "[1452/8000] D loss: 0.8169, G loss: 3.0859\n",
      "[1812/8000] D loss: 0.9818, G loss: 1.7544\n",
      "[2172/8000] D loss: 0.7309, G loss: 6.2310\n",
      "[2532/8000] D loss: 0.9272, G loss: 2.6150\n",
      "[2892/8000] D loss: 0.8807, G loss: 5.6688\n",
      "[3252/8000] D loss: 1.0165, G loss: 3.1138\n",
      "[3612/8000] D loss: 0.7219, G loss: 2.9974\n",
      "[3972/8000] D loss: 0.7728, G loss: 2.7764\n",
      "[4332/8000] D loss: 0.7035, G loss: 5.2659\n",
      "[4692/8000] D loss: 0.5064, G loss: 5.8165\n",
      "[5052/8000] D loss: 0.6070, G loss: 3.1311\n",
      "[5412/8000] D loss: 0.3010, G loss: 5.2604\n",
      "[5772/8000] D loss: 0.9126, G loss: 3.6097\n",
      "[6132/8000] D loss: 0.8405, G loss: 4.1613\n",
      "[6492/8000] D loss: 0.5053, G loss: 5.4461\n",
      "[6852/8000] D loss: 0.6954, G loss: 2.8941\n",
      "[7212/8000] D loss: 0.4310, G loss: 3.9540\n",
      "[7572/8000] D loss: 0.8295, G loss: 2.7906\n",
      "[7932/8000] D loss: 0.5597, G loss: 4.5273\n",
      "train error: \n",
      " D loss: 0.815785, G loss: 4.281707, D accuracy: 77.0%, cell accuracy: 98.5%, board accuracy: 34.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.799475, G loss: 8.392188, D accuracy: 79.6%, cell accuracy: 98.1%, board accuracy: 18.0% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8492, G loss: 5.2692\n",
      "[372/8000] D loss: 0.6705, G loss: 2.6461\n",
      "[732/8000] D loss: 0.6006, G loss: 6.3134\n",
      "[1092/8000] D loss: 0.7077, G loss: 3.7853\n",
      "[1452/8000] D loss: 0.5560, G loss: 5.3929\n",
      "[1812/8000] D loss: 0.5952, G loss: 3.5393\n",
      "[2172/8000] D loss: 0.6814, G loss: 3.4202\n",
      "[2532/8000] D loss: 0.6531, G loss: 3.3204\n",
      "[2892/8000] D loss: 0.9058, G loss: 4.0510\n",
      "[3252/8000] D loss: 0.7989, G loss: 4.3471\n",
      "[3612/8000] D loss: 0.9889, G loss: 2.3265\n",
      "[3972/8000] D loss: 0.7927, G loss: 3.0929\n",
      "[4332/8000] D loss: 0.6069, G loss: 3.4559\n",
      "[4692/8000] D loss: 0.8694, G loss: 1.8177\n",
      "[5052/8000] D loss: 1.1285, G loss: 3.9033\n",
      "[5412/8000] D loss: 0.7344, G loss: 5.9932\n",
      "[5772/8000] D loss: 0.8752, G loss: 3.9630\n",
      "[6132/8000] D loss: 0.6923, G loss: 4.0630\n",
      "[6492/8000] D loss: 0.9555, G loss: 3.6203\n",
      "[6852/8000] D loss: 0.6621, G loss: 4.5829\n",
      "[7212/8000] D loss: 0.5357, G loss: 3.4846\n",
      "[7572/8000] D loss: 0.7005, G loss: 3.1388\n",
      "[7932/8000] D loss: 0.7191, G loss: 1.9069\n",
      "train error: \n",
      " D loss: 0.781683, G loss: 4.146689, D accuracy: 77.5%, cell accuracy: 98.5%, board accuracy: 32.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.765158, G loss: 7.950842, D accuracy: 79.9%, cell accuracy: 98.0%, board accuracy: 18.1% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7010, G loss: 6.8557\n",
      "[372/8000] D loss: 1.1960, G loss: 2.9470\n",
      "[732/8000] D loss: 1.2891, G loss: 1.3526\n",
      "[1092/8000] D loss: 0.4598, G loss: 4.5440\n",
      "[1452/8000] D loss: 0.4000, G loss: 3.4306\n",
      "[1812/8000] D loss: 0.5510, G loss: 4.4971\n",
      "[2172/8000] D loss: 0.9612, G loss: 2.0006\n",
      "[2532/8000] D loss: 0.5836, G loss: 7.3941\n",
      "[2892/8000] D loss: 0.5953, G loss: 4.8125\n",
      "[3252/8000] D loss: 0.8293, G loss: 2.7591\n",
      "[3612/8000] D loss: 0.9190, G loss: 4.0205\n",
      "[3972/8000] D loss: 0.6100, G loss: 3.0904\n",
      "[4332/8000] D loss: 0.7074, G loss: 5.6873\n",
      "[4692/8000] D loss: 0.7516, G loss: 2.5393\n",
      "[5052/8000] D loss: 0.2846, G loss: 4.5869\n",
      "[5412/8000] D loss: 0.7519, G loss: 3.8803\n",
      "[5772/8000] D loss: 0.8628, G loss: 4.3161\n",
      "[6132/8000] D loss: 0.4843, G loss: 3.1110\n",
      "[6492/8000] D loss: 0.6980, G loss: 2.7272\n",
      "[6852/8000] D loss: 0.7689, G loss: 2.9390\n",
      "[7212/8000] D loss: 0.7224, G loss: 3.0099\n",
      "[7572/8000] D loss: 0.6862, G loss: 4.0939\n",
      "[7932/8000] D loss: 0.7036, G loss: 7.1691\n",
      "train error: \n",
      " D loss: 0.809572, G loss: 3.493565, D accuracy: 77.6%, cell accuracy: 98.5%, board accuracy: 34.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.621326, G loss: 7.437089, D accuracy: 85.9%, cell accuracy: 98.1%, board accuracy: 17.8% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8554, G loss: 1.7816\n",
      "[372/8000] D loss: 0.7281, G loss: 5.4492\n",
      "[732/8000] D loss: 0.9635, G loss: 4.4181\n",
      "[1092/8000] D loss: 0.5714, G loss: 4.6493\n",
      "[1452/8000] D loss: 0.7972, G loss: 2.4017\n",
      "[1812/8000] D loss: 0.7684, G loss: 4.8226\n",
      "[2172/8000] D loss: 0.8390, G loss: 3.3015\n",
      "[2532/8000] D loss: 0.5299, G loss: 5.5542\n",
      "[2892/8000] D loss: 0.6753, G loss: 6.5190\n",
      "[3252/8000] D loss: 0.6908, G loss: 6.5627\n",
      "[3612/8000] D loss: 0.7176, G loss: 3.1755\n",
      "[3972/8000] D loss: 0.8322, G loss: 2.2828\n",
      "[4332/8000] D loss: 0.7534, G loss: 4.7964\n",
      "[4692/8000] D loss: 0.6481, G loss: 3.6678\n",
      "[5052/8000] D loss: 0.6949, G loss: 3.3793\n",
      "[5412/8000] D loss: 0.7121, G loss: 6.5060\n",
      "[5772/8000] D loss: 0.6901, G loss: 5.7588\n",
      "[6132/8000] D loss: 0.8523, G loss: 2.8194\n",
      "[6492/8000] D loss: 0.9254, G loss: 2.1565\n",
      "[6852/8000] D loss: 0.5762, G loss: 5.9529\n",
      "[7212/8000] D loss: 1.3203, G loss: 1.1882\n",
      "[7572/8000] D loss: 0.5035, G loss: 5.3853\n",
      "[7932/8000] D loss: 0.8254, G loss: 4.1309\n",
      "train error: \n",
      " D loss: 0.826148, G loss: 3.048573, D accuracy: 76.7%, cell accuracy: 98.5%, board accuracy: 35.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.681954, G loss: 6.674531, D accuracy: 82.8%, cell accuracy: 98.1%, board accuracy: 19.4% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8010, G loss: 2.9587\n",
      "[372/8000] D loss: 0.7075, G loss: 3.6473\n",
      "[732/8000] D loss: 1.0247, G loss: 2.1138\n",
      "[1092/8000] D loss: 0.7523, G loss: 2.9178\n",
      "[1452/8000] D loss: 0.9537, G loss: 6.1531\n",
      "[1812/8000] D loss: 1.0220, G loss: 2.5654\n",
      "[2172/8000] D loss: 0.4590, G loss: 6.4918\n",
      "[2532/8000] D loss: 0.7291, G loss: 3.7744\n",
      "[2892/8000] D loss: 0.6602, G loss: 2.4940\n",
      "[3252/8000] D loss: 0.8446, G loss: 2.3483\n",
      "[3612/8000] D loss: 0.5274, G loss: 7.3740\n",
      "[3972/8000] D loss: 1.0735, G loss: 2.7633\n",
      "[4332/8000] D loss: 0.7132, G loss: 3.7276\n",
      "[4692/8000] D loss: 0.7875, G loss: 4.0007\n",
      "[5052/8000] D loss: 0.7275, G loss: 4.9639\n",
      "[5412/8000] D loss: 1.1961, G loss: 2.5916\n",
      "[5772/8000] D loss: 0.9436, G loss: 6.0867\n",
      "[6132/8000] D loss: 0.7751, G loss: 3.2812\n",
      "[6492/8000] D loss: 0.5755, G loss: 5.2161\n",
      "[6852/8000] D loss: 0.5318, G loss: 4.5748\n",
      "[7212/8000] D loss: 0.7220, G loss: 2.8022\n",
      "[7572/8000] D loss: 1.0371, G loss: 2.1331\n",
      "[7932/8000] D loss: 1.0095, G loss: 3.6011\n",
      "train error: \n",
      " D loss: 0.757590, G loss: 3.827143, D accuracy: 78.4%, cell accuracy: 98.5%, board accuracy: 34.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.700316, G loss: 7.749936, D accuracy: 82.3%, cell accuracy: 98.0%, board accuracy: 18.2% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9244, G loss: 3.0033\n",
      "[372/8000] D loss: 0.6335, G loss: 3.4377\n",
      "[732/8000] D loss: 0.7373, G loss: 2.4880\n",
      "[1092/8000] D loss: 0.6862, G loss: 4.5710\n",
      "[1452/8000] D loss: 0.8593, G loss: 3.6634\n",
      "[1812/8000] D loss: 0.9793, G loss: 2.4063\n",
      "[2172/8000] D loss: 1.3294, G loss: 1.5649\n",
      "[2532/8000] D loss: 0.7589, G loss: 2.7281\n",
      "[2892/8000] D loss: 0.9142, G loss: 2.5280\n",
      "[3252/8000] D loss: 0.5444, G loss: 3.0274\n",
      "[3612/8000] D loss: 1.1041, G loss: 1.6450\n",
      "[3972/8000] D loss: 0.9000, G loss: 5.9329\n",
      "[4332/8000] D loss: 0.5979, G loss: 5.1425\n",
      "[4692/8000] D loss: 0.7251, G loss: 3.6574\n",
      "[5052/8000] D loss: 0.8719, G loss: 4.5692\n",
      "[5412/8000] D loss: 0.6273, G loss: 5.0637\n",
      "[5772/8000] D loss: 0.9216, G loss: 1.9734\n",
      "[6132/8000] D loss: 0.6107, G loss: 4.0473\n",
      "[6492/8000] D loss: 0.6541, G loss: 6.0426\n",
      "[6852/8000] D loss: 0.7871, G loss: 5.7189\n",
      "[7212/8000] D loss: 1.2588, G loss: 1.8957\n",
      "[7572/8000] D loss: 0.8644, G loss: 3.8325\n",
      "[7932/8000] D loss: 0.5351, G loss: 4.1710\n",
      "train error: \n",
      " D loss: 0.815308, G loss: 3.313556, D accuracy: 77.1%, cell accuracy: 98.5%, board accuracy: 36.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.649718, G loss: 7.299712, D accuracy: 85.0%, cell accuracy: 98.1%, board accuracy: 18.4% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6000, G loss: 5.1534\n",
      "[372/8000] D loss: 1.0593, G loss: 3.5733\n",
      "[732/8000] D loss: 1.0619, G loss: 1.3952\n",
      "[1092/8000] D loss: 0.7036, G loss: 4.4367\n",
      "[1452/8000] D loss: 0.5588, G loss: 5.0663\n",
      "[1812/8000] D loss: 0.5012, G loss: 4.7571\n",
      "[2172/8000] D loss: 0.6437, G loss: 3.8201\n",
      "[2532/8000] D loss: 0.7878, G loss: 2.1364\n",
      "[2892/8000] D loss: 0.8124, G loss: 3.4520\n",
      "[3252/8000] D loss: 0.5978, G loss: 3.9581\n",
      "[3612/8000] D loss: 0.8120, G loss: 3.0546\n",
      "[3972/8000] D loss: 1.1727, G loss: 3.8929\n",
      "[4332/8000] D loss: 0.8005, G loss: 1.9964\n",
      "[4692/8000] D loss: 0.8084, G loss: 3.3264\n",
      "[5052/8000] D loss: 0.7907, G loss: 3.5029\n",
      "[5412/8000] D loss: 0.7477, G loss: 4.8513\n",
      "[5772/8000] D loss: 0.7507, G loss: 6.4492\n",
      "[6132/8000] D loss: 0.5743, G loss: 4.0222\n",
      "[6492/8000] D loss: 0.6120, G loss: 2.5719\n",
      "[6852/8000] D loss: 0.5137, G loss: 5.1223\n",
      "[7212/8000] D loss: 0.8868, G loss: 2.5730\n",
      "[7572/8000] D loss: 0.8963, G loss: 2.1378\n",
      "[7932/8000] D loss: 0.7384, G loss: 2.5602\n",
      "train error: \n",
      " D loss: 0.833063, G loss: 3.387882, D accuracy: 76.4%, cell accuracy: 98.5%, board accuracy: 35.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.768098, G loss: 7.231586, D accuracy: 80.0%, cell accuracy: 98.1%, board accuracy: 17.9% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8412, G loss: 3.6705\n",
      "[372/8000] D loss: 0.9023, G loss: 4.0975\n",
      "[732/8000] D loss: 0.9852, G loss: 2.6751\n",
      "[1092/8000] D loss: 0.4928, G loss: 6.0039\n",
      "[1452/8000] D loss: 1.2077, G loss: 1.1056\n",
      "[1812/8000] D loss: 0.5718, G loss: 5.6230\n",
      "[2172/8000] D loss: 0.7034, G loss: 4.5135\n",
      "[2532/8000] D loss: 0.5771, G loss: 4.1315\n",
      "[2892/8000] D loss: 0.9777, G loss: 1.6283\n",
      "[3252/8000] D loss: 0.8943, G loss: 1.6462\n",
      "[3612/8000] D loss: 0.5989, G loss: 3.7093\n",
      "[3972/8000] D loss: 0.7645, G loss: 2.5777\n",
      "[4332/8000] D loss: 0.8598, G loss: 2.0249\n",
      "[4692/8000] D loss: 0.9371, G loss: 3.6341\n",
      "[5052/8000] D loss: 0.6120, G loss: 4.1737\n",
      "[5412/8000] D loss: 0.5115, G loss: 4.8860\n",
      "[5772/8000] D loss: 0.6155, G loss: 6.2899\n",
      "[6132/8000] D loss: 0.6261, G loss: 3.0929\n",
      "[6492/8000] D loss: 0.7326, G loss: 3.8786\n",
      "[6852/8000] D loss: 0.8887, G loss: 3.7974\n",
      "[7212/8000] D loss: 0.9154, G loss: 2.9129\n",
      "[7572/8000] D loss: 0.5405, G loss: 7.1443\n",
      "[7932/8000] D loss: 0.8926, G loss: 4.1561\n",
      "train error: \n",
      " D loss: 0.798212, G loss: 3.483136, D accuracy: 77.3%, cell accuracy: 98.5%, board accuracy: 34.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.731837, G loss: 7.145455, D accuracy: 81.3%, cell accuracy: 98.0%, board accuracy: 17.9% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5925, G loss: 3.7511\n",
      "[372/8000] D loss: 0.7767, G loss: 3.0795\n",
      "[732/8000] D loss: 0.8515, G loss: 3.6062\n",
      "[1092/8000] D loss: 0.5826, G loss: 5.1924\n",
      "[1452/8000] D loss: 0.8883, G loss: 1.6817\n",
      "[1812/8000] D loss: 0.7067, G loss: 4.1751\n",
      "[2172/8000] D loss: 0.7576, G loss: 4.3594\n",
      "[2532/8000] D loss: 1.1905, G loss: 3.4375\n",
      "[2892/8000] D loss: 0.7574, G loss: 2.6174\n",
      "[3252/8000] D loss: 1.5224, G loss: 2.0522\n",
      "[3612/8000] D loss: 0.7807, G loss: 4.7000\n",
      "[3972/8000] D loss: 0.7325, G loss: 3.1063\n",
      "[4332/8000] D loss: 0.7045, G loss: 5.2546\n",
      "[4692/8000] D loss: 1.1268, G loss: 1.8022\n",
      "[5052/8000] D loss: 0.7891, G loss: 4.8818\n",
      "[5412/8000] D loss: 0.5684, G loss: 3.7682\n",
      "[5772/8000] D loss: 0.6020, G loss: 3.2894\n",
      "[6132/8000] D loss: 0.7767, G loss: 3.9202\n",
      "[6492/8000] D loss: 0.7948, G loss: 3.0389\n",
      "[6852/8000] D loss: 0.6947, G loss: 4.8616\n",
      "[7212/8000] D loss: 0.9325, G loss: 4.6633\n",
      "[7572/8000] D loss: 0.7733, G loss: 4.3826\n",
      "[7932/8000] D loss: 0.7548, G loss: 4.7330\n",
      "train error: \n",
      " D loss: 0.768686, G loss: 3.682516, D accuracy: 78.0%, cell accuracy: 98.5%, board accuracy: 35.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.674161, G loss: 7.855916, D accuracy: 83.7%, cell accuracy: 98.1%, board accuracy: 18.8% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8291, G loss: 3.0246\n",
      "[372/8000] D loss: 0.5730, G loss: 4.9341\n",
      "[732/8000] D loss: 0.6949, G loss: 5.0865\n",
      "[1092/8000] D loss: 0.8627, G loss: 3.3479\n",
      "[1452/8000] D loss: 0.6752, G loss: 4.2436\n",
      "[1812/8000] D loss: 0.9931, G loss: 4.6023\n",
      "[2172/8000] D loss: 0.8325, G loss: 5.1671\n",
      "[2532/8000] D loss: 0.5652, G loss: 4.3959\n",
      "[2892/8000] D loss: 0.5410, G loss: 4.9414\n",
      "[3252/8000] D loss: 0.8442, G loss: 2.4117\n",
      "[3612/8000] D loss: 0.4833, G loss: 5.1152\n",
      "[3972/8000] D loss: 0.6088, G loss: 4.9335\n",
      "[4332/8000] D loss: 0.8235, G loss: 2.8227\n",
      "[4692/8000] D loss: 0.8320, G loss: 5.7938\n",
      "[5052/8000] D loss: 0.9867, G loss: 1.7362\n",
      "[5412/8000] D loss: 1.0356, G loss: 1.8512\n",
      "[5772/8000] D loss: 0.6251, G loss: 4.3354\n",
      "[6132/8000] D loss: 0.7993, G loss: 4.1303\n",
      "[6492/8000] D loss: 0.8631, G loss: 2.7462\n",
      "[6852/8000] D loss: 1.0808, G loss: 2.4474\n",
      "[7212/8000] D loss: 0.8887, G loss: 1.6112\n",
      "[7572/8000] D loss: 0.7688, G loss: 3.6681\n",
      "[7932/8000] D loss: 0.8468, G loss: 4.0589\n",
      "train error: \n",
      " D loss: 0.794910, G loss: 3.994829, D accuracy: 77.0%, cell accuracy: 98.5%, board accuracy: 36.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.747842, G loss: 8.243460, D accuracy: 80.5%, cell accuracy: 98.1%, board accuracy: 18.6% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4756, G loss: 4.5401\n",
      "[372/8000] D loss: 0.9282, G loss: 3.4515\n",
      "[732/8000] D loss: 1.1410, G loss: 1.0653\n",
      "[1092/8000] D loss: 0.7978, G loss: 2.4319\n",
      "[1452/8000] D loss: 0.8813, G loss: 3.1892\n",
      "[1812/8000] D loss: 0.7163, G loss: 4.9407\n",
      "[2172/8000] D loss: 0.8905, G loss: 2.8392\n",
      "[2532/8000] D loss: 0.4786, G loss: 4.1126\n",
      "[2892/8000] D loss: 0.7740, G loss: 4.1629\n",
      "[3252/8000] D loss: 1.0482, G loss: 1.5809\n",
      "[3612/8000] D loss: 0.8416, G loss: 3.7028\n",
      "[3972/8000] D loss: 0.8886, G loss: 3.1524\n",
      "[4332/8000] D loss: 0.9140, G loss: 2.5555\n",
      "[4692/8000] D loss: 0.7120, G loss: 4.1811\n",
      "[5052/8000] D loss: 0.7924, G loss: 3.6860\n",
      "[5412/8000] D loss: 0.5126, G loss: 8.1637\n",
      "[5772/8000] D loss: 0.7881, G loss: 2.7712\n",
      "[6132/8000] D loss: 0.9274, G loss: 2.6759\n",
      "[6492/8000] D loss: 0.8542, G loss: 2.7032\n",
      "[6852/8000] D loss: 0.7484, G loss: 5.8259\n",
      "[7212/8000] D loss: 0.7032, G loss: 5.7358\n",
      "[7572/8000] D loss: 0.6401, G loss: 2.8909\n",
      "[7932/8000] D loss: 0.5848, G loss: 3.0538\n",
      "train error: \n",
      " D loss: 0.829294, G loss: 3.351006, D accuracy: 77.1%, cell accuracy: 98.5%, board accuracy: 36.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.675726, G loss: 7.538542, D accuracy: 84.2%, cell accuracy: 98.1%, board accuracy: 19.1% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8509, G loss: 3.4012\n",
      "[372/8000] D loss: 0.7523, G loss: 5.7556\n",
      "[732/8000] D loss: 1.0186, G loss: 3.4478\n",
      "[1092/8000] D loss: 0.8259, G loss: 2.4234\n",
      "[1452/8000] D loss: 0.7672, G loss: 3.7598\n",
      "[1812/8000] D loss: 0.6580, G loss: 4.3066\n",
      "[2172/8000] D loss: 0.7080, G loss: 3.5082\n",
      "[2532/8000] D loss: 0.5746, G loss: 7.2501\n",
      "[2892/8000] D loss: 0.8267, G loss: 3.0679\n",
      "[3252/8000] D loss: 0.4875, G loss: 4.2921\n",
      "[3612/8000] D loss: 0.6379, G loss: 3.7042\n",
      "[3972/8000] D loss: 0.6492, G loss: 5.8987\n",
      "[4332/8000] D loss: 0.4226, G loss: 3.8417\n",
      "[4692/8000] D loss: 0.7133, G loss: 3.3942\n",
      "[5052/8000] D loss: 0.4763, G loss: 5.4033\n",
      "[5412/8000] D loss: 0.8244, G loss: 4.3965\n",
      "[5772/8000] D loss: 1.0411, G loss: 2.4535\n",
      "[6132/8000] D loss: 0.7166, G loss: 4.1265\n",
      "[6492/8000] D loss: 0.8936, G loss: 2.6540\n",
      "[6852/8000] D loss: 0.6057, G loss: 4.0990\n",
      "[7212/8000] D loss: 0.8379, G loss: 5.9566\n",
      "[7572/8000] D loss: 0.3925, G loss: 5.4909\n",
      "[7932/8000] D loss: 0.8696, G loss: 2.3812\n",
      "train error: \n",
      " D loss: 0.822162, G loss: 4.400864, D accuracy: 76.9%, cell accuracy: 98.5%, board accuracy: 36.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.780923, G loss: 8.945311, D accuracy: 81.6%, cell accuracy: 98.1%, board accuracy: 18.3% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8149, G loss: 3.3070\n",
      "[372/8000] D loss: 0.5941, G loss: 4.4463\n",
      "[732/8000] D loss: 1.1270, G loss: 1.8019\n",
      "[1092/8000] D loss: 0.5763, G loss: 4.2882\n",
      "[1452/8000] D loss: 1.0785, G loss: 2.1501\n",
      "[1812/8000] D loss: 0.6414, G loss: 4.7799\n",
      "[2172/8000] D loss: 0.7823, G loss: 4.1370\n",
      "[2532/8000] D loss: 1.0597, G loss: 2.0421\n",
      "[2892/8000] D loss: 0.8327, G loss: 3.3380\n",
      "[3252/8000] D loss: 0.4728, G loss: 4.2075\n",
      "[3612/8000] D loss: 0.8208, G loss: 3.1282\n",
      "[3972/8000] D loss: 0.6729, G loss: 5.0640\n",
      "[4332/8000] D loss: 0.8683, G loss: 1.8955\n",
      "[4692/8000] D loss: 0.7386, G loss: 3.4452\n",
      "[5052/8000] D loss: 0.4791, G loss: 4.5839\n",
      "[5412/8000] D loss: 0.6657, G loss: 6.2194\n",
      "[5772/8000] D loss: 0.7313, G loss: 3.9403\n",
      "[6132/8000] D loss: 0.8554, G loss: 2.0551\n",
      "[6492/8000] D loss: 0.3951, G loss: 7.6624\n",
      "[6852/8000] D loss: 0.7523, G loss: 3.9065\n",
      "[7212/8000] D loss: 0.6677, G loss: 4.1002\n",
      "[7572/8000] D loss: 0.5595, G loss: 5.2184\n",
      "[7932/8000] D loss: 0.8532, G loss: 3.0534\n",
      "train error: \n",
      " D loss: 0.818584, G loss: 3.574465, D accuracy: 77.3%, cell accuracy: 98.5%, board accuracy: 36.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.653091, G loss: 8.141338, D accuracy: 85.3%, cell accuracy: 98.1%, board accuracy: 19.1% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7039, G loss: 1.7313\n",
      "[372/8000] D loss: 0.6896, G loss: 3.2524\n",
      "[732/8000] D loss: 0.8930, G loss: 4.5375\n",
      "[1092/8000] D loss: 0.8427, G loss: 5.6433\n",
      "[1452/8000] D loss: 0.7377, G loss: 3.0013\n",
      "[1812/8000] D loss: 1.0168, G loss: 3.1738\n",
      "[2172/8000] D loss: 0.6419, G loss: 2.9327\n",
      "[2532/8000] D loss: 0.8794, G loss: 5.9224\n",
      "[2892/8000] D loss: 0.8140, G loss: 3.0053\n",
      "[3252/8000] D loss: 0.5836, G loss: 4.3017\n",
      "[3612/8000] D loss: 0.5313, G loss: 6.4818\n",
      "[3972/8000] D loss: 1.0027, G loss: 2.9285\n",
      "[4332/8000] D loss: 0.8109, G loss: 3.8113\n",
      "[4692/8000] D loss: 0.8604, G loss: 3.6310\n",
      "[5052/8000] D loss: 0.9579, G loss: 3.6778\n",
      "[5412/8000] D loss: 0.5196, G loss: 5.1300\n",
      "[5772/8000] D loss: 0.9043, G loss: 4.4806\n",
      "[6132/8000] D loss: 0.7034, G loss: 4.0292\n",
      "[6492/8000] D loss: 0.5013, G loss: 4.1429\n",
      "[6852/8000] D loss: 0.5804, G loss: 5.8636\n",
      "[7212/8000] D loss: 0.9315, G loss: 3.9109\n",
      "[7572/8000] D loss: 0.6844, G loss: 5.6442\n",
      "[7932/8000] D loss: 0.5849, G loss: 4.0118\n",
      "train error: \n",
      " D loss: 0.745595, G loss: 4.421465, D accuracy: 78.5%, cell accuracy: 98.5%, board accuracy: 34.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.767976, G loss: 8.940645, D accuracy: 80.4%, cell accuracy: 98.1%, board accuracy: 18.1% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4128, G loss: 7.1218\n",
      "[372/8000] D loss: 0.7415, G loss: 3.3541\n",
      "[732/8000] D loss: 1.1210, G loss: 2.2713\n",
      "[1092/8000] D loss: 0.7937, G loss: 3.8987\n",
      "[1452/8000] D loss: 0.7256, G loss: 3.1757\n",
      "[1812/8000] D loss: 1.2967, G loss: 0.9734\n",
      "[2172/8000] D loss: 0.9294, G loss: 2.9654\n",
      "[2532/8000] D loss: 0.5604, G loss: 3.8602\n",
      "[2892/8000] D loss: 0.6259, G loss: 6.0492\n",
      "[3252/8000] D loss: 0.6722, G loss: 3.6478\n",
      "[3612/8000] D loss: 0.6574, G loss: 4.0547\n",
      "[3972/8000] D loss: 0.8492, G loss: 3.0461\n",
      "[4332/8000] D loss: 0.6125, G loss: 4.4255\n",
      "[4692/8000] D loss: 1.2188, G loss: 0.7721\n",
      "[5052/8000] D loss: 0.9336, G loss: 2.0315\n",
      "[5412/8000] D loss: 0.3374, G loss: 10.5959\n",
      "[5772/8000] D loss: 0.8057, G loss: 5.1503\n",
      "[6132/8000] D loss: 0.8161, G loss: 3.4947\n",
      "[6492/8000] D loss: 0.5836, G loss: 5.3233\n",
      "[6852/8000] D loss: 0.9060, G loss: 2.1720\n",
      "[7212/8000] D loss: 0.6313, G loss: 4.0614\n",
      "[7572/8000] D loss: 0.7086, G loss: 6.0830\n",
      "[7932/8000] D loss: 0.5113, G loss: 4.8407\n",
      "train error: \n",
      " D loss: 0.792628, G loss: 3.517024, D accuracy: 77.3%, cell accuracy: 98.5%, board accuracy: 37.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.672054, G loss: 7.811632, D accuracy: 83.7%, cell accuracy: 98.1%, board accuracy: 19.2% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0845, G loss: 1.5492\n",
      "[372/8000] D loss: 0.9825, G loss: 3.2124\n",
      "[732/8000] D loss: 0.6213, G loss: 5.7818\n",
      "[1092/8000] D loss: 0.5401, G loss: 4.8091\n",
      "[1452/8000] D loss: 0.8943, G loss: 3.3725\n",
      "[1812/8000] D loss: 0.8387, G loss: 2.3250\n",
      "[2172/8000] D loss: 0.8496, G loss: 1.6200\n",
      "[2532/8000] D loss: 0.7999, G loss: 2.5608\n",
      "[2892/8000] D loss: 0.8269, G loss: 3.3422\n",
      "[3252/8000] D loss: 0.6441, G loss: 3.7829\n",
      "[3612/8000] D loss: 1.1067, G loss: 2.6460\n",
      "[3972/8000] D loss: 0.8529, G loss: 2.4165\n",
      "[4332/8000] D loss: 0.3448, G loss: 5.1116\n",
      "[4692/8000] D loss: 0.5709, G loss: 4.1640\n",
      "[5052/8000] D loss: 0.7414, G loss: 5.1943\n",
      "[5412/8000] D loss: 0.5233, G loss: 4.6951\n",
      "[5772/8000] D loss: 1.1236, G loss: 1.2044\n",
      "[6132/8000] D loss: 0.7725, G loss: 2.2494\n",
      "[6492/8000] D loss: 1.0373, G loss: 2.2398\n",
      "[6852/8000] D loss: 0.7817, G loss: 5.3272\n",
      "[7212/8000] D loss: 0.4867, G loss: 6.0380\n",
      "[7572/8000] D loss: 0.9946, G loss: 2.4538\n",
      "[7932/8000] D loss: 0.8989, G loss: 4.5811\n",
      "train error: \n",
      " D loss: 0.796588, G loss: 3.250054, D accuracy: 77.1%, cell accuracy: 98.5%, board accuracy: 37.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.718370, G loss: 7.092365, D accuracy: 82.3%, cell accuracy: 98.1%, board accuracy: 18.4% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6507, G loss: 4.7851\n",
      "[372/8000] D loss: 1.2427, G loss: 1.1524\n",
      "[732/8000] D loss: 0.7798, G loss: 3.2088\n",
      "[1092/8000] D loss: 0.8280, G loss: 3.6843\n",
      "[1452/8000] D loss: 1.4667, G loss: 3.9588\n",
      "[1812/8000] D loss: 1.1201, G loss: 2.0719\n",
      "[2172/8000] D loss: 0.4080, G loss: 4.0903\n",
      "[2532/8000] D loss: 0.7845, G loss: 2.8432\n",
      "[2892/8000] D loss: 1.1050, G loss: 1.9595\n",
      "[3252/8000] D loss: 0.7883, G loss: 6.5678\n",
      "[3612/8000] D loss: 0.6959, G loss: 5.8300\n",
      "[3972/8000] D loss: 0.8757, G loss: 3.7554\n",
      "[4332/8000] D loss: 0.5011, G loss: 7.2292\n",
      "[4692/8000] D loss: 0.9656, G loss: 2.2242\n",
      "[5052/8000] D loss: 0.6642, G loss: 4.4916\n",
      "[5412/8000] D loss: 0.4313, G loss: 4.7305\n",
      "[5772/8000] D loss: 0.7403, G loss: 4.3628\n",
      "[6132/8000] D loss: 0.6035, G loss: 5.9244\n",
      "[6492/8000] D loss: 1.0213, G loss: 3.2132\n",
      "[6852/8000] D loss: 0.6047, G loss: 3.9831\n",
      "[7212/8000] D loss: 0.9461, G loss: 4.6928\n",
      "[7572/8000] D loss: 0.7582, G loss: 3.1853\n",
      "[7932/8000] D loss: 0.6401, G loss: 3.1970\n",
      "train error: \n",
      " D loss: 0.823914, G loss: 3.196540, D accuracy: 76.8%, cell accuracy: 98.5%, board accuracy: 36.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.657914, G loss: 7.199661, D accuracy: 84.1%, cell accuracy: 98.1%, board accuracy: 19.1% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7163, G loss: 3.7692\n",
      "[372/8000] D loss: 0.9265, G loss: 2.4996\n",
      "[732/8000] D loss: 0.4710, G loss: 6.0932\n",
      "[1092/8000] D loss: 0.7188, G loss: 6.1677\n",
      "[1452/8000] D loss: 0.8872, G loss: 5.2396\n",
      "[1812/8000] D loss: 0.9154, G loss: 4.5143\n",
      "[2172/8000] D loss: 0.6240, G loss: 6.1896\n",
      "[2532/8000] D loss: 0.9226, G loss: 1.6394\n",
      "[2892/8000] D loss: 0.5333, G loss: 3.0559\n",
      "[3252/8000] D loss: 0.8341, G loss: 2.9794\n",
      "[3612/8000] D loss: 0.9735, G loss: 2.4410\n",
      "[3972/8000] D loss: 1.0730, G loss: 1.8026\n",
      "[4332/8000] D loss: 0.8368, G loss: 3.6651\n",
      "[4692/8000] D loss: 0.9372, G loss: 6.8471\n",
      "[5052/8000] D loss: 0.5624, G loss: 5.6411\n",
      "[5412/8000] D loss: 0.5787, G loss: 6.8561\n",
      "[5772/8000] D loss: 0.5765, G loss: 3.5889\n",
      "[6132/8000] D loss: 1.1273, G loss: 2.7291\n",
      "[6492/8000] D loss: 0.7912, G loss: 1.7634\n",
      "[6852/8000] D loss: 0.5885, G loss: 3.9762\n",
      "[7212/8000] D loss: 0.7267, G loss: 4.6454\n",
      "[7572/8000] D loss: 0.5761, G loss: 7.0395\n",
      "[7932/8000] D loss: 0.4544, G loss: 3.7063\n",
      "train error: \n",
      " D loss: 0.774102, G loss: 3.887633, D accuracy: 77.7%, cell accuracy: 98.5%, board accuracy: 37.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.731053, G loss: 8.193564, D accuracy: 81.7%, cell accuracy: 98.1%, board accuracy: 18.9% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6189, G loss: 6.4812\n",
      "[372/8000] D loss: 0.7615, G loss: 5.0675\n",
      "[732/8000] D loss: 0.7001, G loss: 3.4193\n",
      "[1092/8000] D loss: 0.9837, G loss: 3.2100\n",
      "[1452/8000] D loss: 1.0502, G loss: 2.3138\n",
      "[1812/8000] D loss: 0.8093, G loss: 4.8149\n",
      "[2172/8000] D loss: 0.7323, G loss: 3.4804\n",
      "[2532/8000] D loss: 0.5948, G loss: 4.6728\n",
      "[2892/8000] D loss: 0.8162, G loss: 2.7308\n",
      "[3252/8000] D loss: 0.7890, G loss: 2.2511\n",
      "[3612/8000] D loss: 0.2965, G loss: 5.8988\n",
      "[3972/8000] D loss: 0.6838, G loss: 3.1011\n",
      "[4332/8000] D loss: 0.8396, G loss: 2.3553\n",
      "[4692/8000] D loss: 0.5732, G loss: 7.2303\n",
      "[5052/8000] D loss: 0.5850, G loss: 3.1494\n",
      "[5412/8000] D loss: 0.9732, G loss: 1.8053\n",
      "[5772/8000] D loss: 0.8049, G loss: 3.3585\n",
      "[6132/8000] D loss: 0.5345, G loss: 4.8506\n",
      "[6492/8000] D loss: 0.6518, G loss: 3.4474\n",
      "[6852/8000] D loss: 0.9149, G loss: 2.3950\n",
      "[7212/8000] D loss: 0.8937, G loss: 2.7317\n",
      "[7572/8000] D loss: 0.6248, G loss: 4.5593\n",
      "[7932/8000] D loss: 0.8475, G loss: 3.5352\n",
      "train error: \n",
      " D loss: 0.814542, G loss: 3.093922, D accuracy: 77.3%, cell accuracy: 98.5%, board accuracy: 36.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.633872, G loss: 7.054481, D accuracy: 85.2%, cell accuracy: 98.1%, board accuracy: 18.5% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7460, G loss: 3.0464\n",
      "[372/8000] D loss: 0.5185, G loss: 7.2081\n",
      "[732/8000] D loss: 0.7633, G loss: 2.9793\n",
      "[1092/8000] D loss: 1.0384, G loss: 2.0215\n",
      "[1452/8000] D loss: 0.5627, G loss: 4.8389\n",
      "[1812/8000] D loss: 0.3415, G loss: 5.4754\n",
      "[2172/8000] D loss: 0.5938, G loss: 6.8684\n",
      "[2532/8000] D loss: 0.8051, G loss: 3.9146\n",
      "[2892/8000] D loss: 0.8738, G loss: 2.7000\n",
      "[3252/8000] D loss: 1.0212, G loss: 4.7890\n",
      "[3612/8000] D loss: 0.4954, G loss: 3.8979\n",
      "[3972/8000] D loss: 0.7064, G loss: 4.3064\n",
      "[4332/8000] D loss: 0.8092, G loss: 3.6140\n",
      "[4692/8000] D loss: 1.1058, G loss: 2.9674\n",
      "[5052/8000] D loss: 0.5938, G loss: 3.4568\n",
      "[5412/8000] D loss: 0.3806, G loss: 5.4687\n",
      "[5772/8000] D loss: 0.5670, G loss: 4.2861\n",
      "[6132/8000] D loss: 0.7464, G loss: 5.3400\n",
      "[6492/8000] D loss: 0.7886, G loss: 4.8411\n",
      "[6852/8000] D loss: 0.8667, G loss: 4.0015\n",
      "[7212/8000] D loss: 1.0007, G loss: 3.7849\n",
      "[7572/8000] D loss: 0.5626, G loss: 3.6494\n",
      "[7932/8000] D loss: 0.7263, G loss: 2.4280\n",
      "train error: \n",
      " D loss: 0.806389, G loss: 4.389237, D accuracy: 76.5%, cell accuracy: 98.5%, board accuracy: 37.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.836494, G loss: 8.840045, D accuracy: 78.0%, cell accuracy: 98.1%, board accuracy: 18.7% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7273, G loss: 4.4500\n",
      "[372/8000] D loss: 0.4073, G loss: 4.7531\n",
      "[732/8000] D loss: 0.7104, G loss: 7.3066\n",
      "[1092/8000] D loss: 0.8591, G loss: 3.0320\n",
      "[1452/8000] D loss: 0.7964, G loss: 3.5466\n",
      "[1812/8000] D loss: 1.1616, G loss: 3.6086\n",
      "[2172/8000] D loss: 0.7848, G loss: 5.2722\n",
      "[2532/8000] D loss: 1.2008, G loss: 1.1974\n",
      "[2892/8000] D loss: 0.8623, G loss: 2.8491\n",
      "[3252/8000] D loss: 0.6497, G loss: 3.1983\n",
      "[3612/8000] D loss: 0.6102, G loss: 6.7108\n",
      "[3972/8000] D loss: 0.8931, G loss: 3.0933\n",
      "[4332/8000] D loss: 0.6536, G loss: 5.2558\n",
      "[4692/8000] D loss: 0.8952, G loss: 3.8418\n",
      "[5052/8000] D loss: 0.7604, G loss: 3.5363\n",
      "[5412/8000] D loss: 0.7610, G loss: 4.9468\n",
      "[5772/8000] D loss: 0.7288, G loss: 3.9076\n",
      "[6132/8000] D loss: 0.6070, G loss: 5.0608\n",
      "[6492/8000] D loss: 0.7389, G loss: 4.3898\n",
      "[6852/8000] D loss: 0.7870, G loss: 4.9004\n",
      "[7212/8000] D loss: 0.7615, G loss: 3.7171\n",
      "[7572/8000] D loss: 1.0838, G loss: 1.2631\n",
      "[7932/8000] D loss: 0.7144, G loss: 4.5346\n",
      "train error: \n",
      " D loss: 0.799316, G loss: 4.143443, D accuracy: 76.4%, cell accuracy: 98.5%, board accuracy: 37.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.818668, G loss: 8.566617, D accuracy: 80.5%, cell accuracy: 98.1%, board accuracy: 19.5% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4748, G loss: 7.1958\n",
      "[372/8000] D loss: 1.0147, G loss: 3.3924\n",
      "[732/8000] D loss: 0.6750, G loss: 3.3874\n",
      "[1092/8000] D loss: 0.5297, G loss: 4.9857\n",
      "[1452/8000] D loss: 0.7903, G loss: 4.1694\n",
      "[1812/8000] D loss: 0.8642, G loss: 5.9950\n",
      "[2172/8000] D loss: 0.6522, G loss: 4.5947\n",
      "[2532/8000] D loss: 0.9068, G loss: 5.1948\n",
      "[2892/8000] D loss: 0.6874, G loss: 4.7719\n",
      "[3252/8000] D loss: 0.7116, G loss: 4.8086\n",
      "[3612/8000] D loss: 1.1167, G loss: 2.8914\n",
      "[3972/8000] D loss: 0.7421, G loss: 5.4107\n",
      "[4332/8000] D loss: 1.2277, G loss: 2.5719\n",
      "[4692/8000] D loss: 0.9149, G loss: 2.0799\n",
      "[5052/8000] D loss: 1.1340, G loss: 1.7330\n",
      "[5412/8000] D loss: 0.6831, G loss: 4.9684\n",
      "[5772/8000] D loss: 0.3628, G loss: 4.4044\n",
      "[6132/8000] D loss: 0.8748, G loss: 1.7533\n",
      "[6492/8000] D loss: 1.1261, G loss: 1.3718\n",
      "[6852/8000] D loss: 1.0549, G loss: 1.3538\n",
      "[7212/8000] D loss: 1.0393, G loss: 2.3728\n",
      "[7572/8000] D loss: 0.5471, G loss: 3.8143\n",
      "[7932/8000] D loss: 1.0858, G loss: 2.0531\n",
      "train error: \n",
      " D loss: 0.869319, G loss: 5.113997, D accuracy: 74.8%, cell accuracy: 98.5%, board accuracy: 36.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.961059, G loss: 10.142651, D accuracy: 74.9%, cell accuracy: 98.0%, board accuracy: 18.1% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4711, G loss: 10.2859\n",
      "[372/8000] D loss: 0.8111, G loss: 2.7007\n",
      "[732/8000] D loss: 0.7313, G loss: 3.6179\n",
      "[1092/8000] D loss: 0.8793, G loss: 3.8189\n",
      "[1452/8000] D loss: 0.8532, G loss: 3.6373\n",
      "[1812/8000] D loss: 0.7293, G loss: 4.7191\n",
      "[2172/8000] D loss: 1.1566, G loss: 1.1680\n",
      "[2532/8000] D loss: 0.7170, G loss: 4.5765\n",
      "[2892/8000] D loss: 0.8260, G loss: 3.4717\n",
      "[3252/8000] D loss: 0.7502, G loss: 4.0033\n",
      "[3612/8000] D loss: 0.5164, G loss: 5.2035\n",
      "[3972/8000] D loss: 1.1062, G loss: 2.9134\n",
      "[4332/8000] D loss: 0.8289, G loss: 2.8029\n",
      "[4692/8000] D loss: 1.0113, G loss: 4.4471\n",
      "[5052/8000] D loss: 0.9512, G loss: 3.6087\n",
      "[5412/8000] D loss: 0.5419, G loss: 4.4858\n",
      "[5772/8000] D loss: 0.5292, G loss: 5.7931\n",
      "[6132/8000] D loss: 0.7477, G loss: 3.7290\n",
      "[6492/8000] D loss: 1.0966, G loss: 5.2332\n",
      "[6852/8000] D loss: 0.8944, G loss: 2.1366\n",
      "[7212/8000] D loss: 0.6919, G loss: 3.0984\n",
      "[7572/8000] D loss: 0.6637, G loss: 3.5518\n",
      "[7932/8000] D loss: 0.7402, G loss: 4.8336\n",
      "train error: \n",
      " D loss: 0.790276, G loss: 3.579202, D accuracy: 77.1%, cell accuracy: 98.5%, board accuracy: 38.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.719922, G loss: 7.863619, D accuracy: 81.6%, cell accuracy: 98.1%, board accuracy: 20.1% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7133, G loss: 2.9607\n",
      "[372/8000] D loss: 0.7478, G loss: 2.6952\n",
      "[732/8000] D loss: 1.3932, G loss: 1.2072\n",
      "[1092/8000] D loss: 0.6394, G loss: 4.5186\n",
      "[1452/8000] D loss: 0.7734, G loss: 6.4105\n",
      "[1812/8000] D loss: 0.7492, G loss: 3.0971\n",
      "[2172/8000] D loss: 1.0915, G loss: 1.9862\n",
      "[2532/8000] D loss: 1.2350, G loss: 2.2442\n",
      "[2892/8000] D loss: 0.8154, G loss: 3.4007\n",
      "[3252/8000] D loss: 0.7875, G loss: 4.8125\n",
      "[3612/8000] D loss: 0.6913, G loss: 6.5362\n",
      "[3972/8000] D loss: 0.8099, G loss: 3.2274\n",
      "[4332/8000] D loss: 0.5793, G loss: 4.5080\n",
      "[4692/8000] D loss: 0.8721, G loss: 3.1118\n",
      "[5052/8000] D loss: 0.9345, G loss: 2.7719\n",
      "[5412/8000] D loss: 0.8717, G loss: 2.2140\n",
      "[5772/8000] D loss: 1.1270, G loss: 1.0176\n",
      "[6132/8000] D loss: 1.0108, G loss: 3.5706\n",
      "[6492/8000] D loss: 0.7075, G loss: 5.9126\n",
      "[6852/8000] D loss: 1.1384, G loss: 2.8771\n",
      "[7212/8000] D loss: 0.7759, G loss: 3.8739\n",
      "[7572/8000] D loss: 0.6015, G loss: 3.4104\n",
      "[7932/8000] D loss: 0.4738, G loss: 5.6798\n",
      "train error: \n",
      " D loss: 0.832701, G loss: 4.594835, D accuracy: 75.7%, cell accuracy: 98.5%, board accuracy: 38.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.882720, G loss: 9.453995, D accuracy: 77.4%, cell accuracy: 98.1%, board accuracy: 19.6% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7446, G loss: 8.0301\n",
      "[372/8000] D loss: 0.5637, G loss: 3.9474\n",
      "[732/8000] D loss: 1.0098, G loss: 1.0108\n",
      "[1092/8000] D loss: 0.9892, G loss: 2.3128\n",
      "[1452/8000] D loss: 0.7081, G loss: 4.8777\n",
      "[1812/8000] D loss: 0.8255, G loss: 3.7324\n",
      "[2172/8000] D loss: 0.3212, G loss: 8.6552\n",
      "[2532/8000] D loss: 0.5956, G loss: 3.9747\n",
      "[2892/8000] D loss: 0.9982, G loss: 3.6558\n",
      "[3252/8000] D loss: 0.8769, G loss: 3.8379\n",
      "[3612/8000] D loss: 0.7883, G loss: 3.8659\n",
      "[3972/8000] D loss: 0.9676, G loss: 3.4025\n",
      "[4332/8000] D loss: 1.0809, G loss: 3.4960\n",
      "[4692/8000] D loss: 0.8328, G loss: 6.5468\n",
      "[5052/8000] D loss: 1.0305, G loss: 4.1056\n",
      "[5412/8000] D loss: 1.1270, G loss: 1.4410\n",
      "[5772/8000] D loss: 1.0336, G loss: 1.6331\n",
      "[6132/8000] D loss: 0.8910, G loss: 4.2236\n",
      "[6492/8000] D loss: 0.6346, G loss: 4.9067\n",
      "[6852/8000] D loss: 0.2655, G loss: 8.0835\n",
      "[7212/8000] D loss: 0.7230, G loss: 4.0153\n",
      "[7572/8000] D loss: 0.8100, G loss: 5.2856\n",
      "[7932/8000] D loss: 0.3885, G loss: 3.5729\n",
      "train error: \n",
      " D loss: 0.776389, G loss: 3.733509, D accuracy: 77.3%, cell accuracy: 98.5%, board accuracy: 38.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.741863, G loss: 8.234111, D accuracy: 81.1%, cell accuracy: 98.1%, board accuracy: 19.8% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2816, G loss: 6.3815\n",
      "[372/8000] D loss: 0.7157, G loss: 6.2839\n",
      "[732/8000] D loss: 0.7483, G loss: 3.1133\n",
      "[1092/8000] D loss: 0.3769, G loss: 6.9918\n",
      "[1452/8000] D loss: 0.6813, G loss: 2.2045\n",
      "[1812/8000] D loss: 0.5826, G loss: 4.4031\n",
      "[2172/8000] D loss: 0.5424, G loss: 7.1928\n",
      "[2532/8000] D loss: 0.7227, G loss: 2.3078\n",
      "[2892/8000] D loss: 0.7128, G loss: 3.7904\n",
      "[3252/8000] D loss: 0.4292, G loss: 9.4139\n",
      "[3612/8000] D loss: 0.8261, G loss: 2.0214\n",
      "[3972/8000] D loss: 0.7053, G loss: 2.2903\n",
      "[4332/8000] D loss: 0.7449, G loss: 6.1616\n",
      "[4692/8000] D loss: 0.8974, G loss: 3.4830\n",
      "[5052/8000] D loss: 0.8778, G loss: 2.0912\n",
      "[5412/8000] D loss: 1.0940, G loss: 1.6341\n",
      "[5772/8000] D loss: 1.0665, G loss: 2.0863\n",
      "[6132/8000] D loss: 0.8013, G loss: 3.2465\n",
      "[6492/8000] D loss: 0.9215, G loss: 3.4619\n",
      "[6852/8000] D loss: 0.9914, G loss: 2.5435\n",
      "[7212/8000] D loss: 0.8713, G loss: 3.6728\n",
      "[7572/8000] D loss: 0.6914, G loss: 3.2914\n",
      "[7932/8000] D loss: 0.4965, G loss: 6.7354\n",
      "train error: \n",
      " D loss: 0.804448, G loss: 3.452084, D accuracy: 77.3%, cell accuracy: 98.5%, board accuracy: 37.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.673004, G loss: 7.904435, D accuracy: 83.9%, cell accuracy: 98.1%, board accuracy: 19.8% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4564, G loss: 3.3710\n",
      "[372/8000] D loss: 0.3269, G loss: 10.3223\n",
      "[732/8000] D loss: 1.3002, G loss: 1.2797\n",
      "[1092/8000] D loss: 0.8000, G loss: 2.1041\n",
      "[1452/8000] D loss: 0.4618, G loss: 6.4105\n",
      "[1812/8000] D loss: 0.5886, G loss: 4.6091\n",
      "[2172/8000] D loss: 0.9552, G loss: 2.8503\n",
      "[2532/8000] D loss: 0.7254, G loss: 4.8083\n",
      "[2892/8000] D loss: 0.5806, G loss: 4.2565\n",
      "[3252/8000] D loss: 1.0118, G loss: 2.4388\n",
      "[3612/8000] D loss: 0.6837, G loss: 6.6218\n",
      "[3972/8000] D loss: 1.3067, G loss: 0.8655\n",
      "[4332/8000] D loss: 1.1339, G loss: 2.4418\n",
      "[4692/8000] D loss: 0.4091, G loss: 6.7428\n",
      "[5052/8000] D loss: 1.0880, G loss: 2.3172\n",
      "[5412/8000] D loss: 1.0625, G loss: 1.8208\n",
      "[5772/8000] D loss: 0.9198, G loss: 4.4232\n",
      "[6132/8000] D loss: 0.3391, G loss: 5.7920\n",
      "[6492/8000] D loss: 1.0789, G loss: 3.1636\n",
      "[6852/8000] D loss: 0.6397, G loss: 7.6384\n",
      "[7212/8000] D loss: 0.5446, G loss: 4.0278\n",
      "[7572/8000] D loss: 0.5673, G loss: 5.7224\n",
      "[7932/8000] D loss: 0.7612, G loss: 3.1380\n",
      "train error: \n",
      " D loss: 0.786430, G loss: 4.631487, D accuracy: 76.9%, cell accuracy: 98.5%, board accuracy: 38.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.806839, G loss: 9.645222, D accuracy: 79.3%, cell accuracy: 98.1%, board accuracy: 19.6% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7800, G loss: 4.6388\n",
      "[372/8000] D loss: 0.5845, G loss: 4.7169\n",
      "[732/8000] D loss: 0.4844, G loss: 3.3944\n",
      "[1092/8000] D loss: 0.7322, G loss: 4.0715\n",
      "[1452/8000] D loss: 0.9197, G loss: 5.3491\n",
      "[1812/8000] D loss: 0.4631, G loss: 7.8211\n",
      "[2172/8000] D loss: 0.9806, G loss: 1.0689\n",
      "[2532/8000] D loss: 0.6862, G loss: 3.9106\n",
      "[2892/8000] D loss: 0.8718, G loss: 3.3805\n",
      "[3252/8000] D loss: 0.5601, G loss: 4.1128\n",
      "[3612/8000] D loss: 0.5372, G loss: 4.2968\n",
      "[3972/8000] D loss: 0.9554, G loss: 3.9382\n",
      "[4332/8000] D loss: 0.5270, G loss: 5.2312\n",
      "[4692/8000] D loss: 0.7914, G loss: 2.9503\n",
      "[5052/8000] D loss: 0.7705, G loss: 3.7403\n",
      "[5412/8000] D loss: 0.6604, G loss: 4.5022\n",
      "[5772/8000] D loss: 0.9490, G loss: 4.9558\n",
      "[6132/8000] D loss: 0.6955, G loss: 3.8787\n",
      "[6492/8000] D loss: 0.6897, G loss: 4.9994\n",
      "[6852/8000] D loss: 0.7773, G loss: 3.4204\n",
      "[7212/8000] D loss: 0.6430, G loss: 3.7644\n",
      "[7572/8000] D loss: 0.4996, G loss: 5.4620\n",
      "[7932/8000] D loss: 0.7520, G loss: 2.6281\n",
      "train error: \n",
      " D loss: 0.779161, G loss: 3.900707, D accuracy: 77.8%, cell accuracy: 98.5%, board accuracy: 36.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.660597, G loss: 8.444831, D accuracy: 84.6%, cell accuracy: 98.0%, board accuracy: 19.6% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8356, G loss: 6.0801\n",
      "[372/8000] D loss: 0.7264, G loss: 4.8715\n",
      "[732/8000] D loss: 0.7651, G loss: 5.9998\n",
      "[1092/8000] D loss: 0.7834, G loss: 5.0779\n",
      "[1452/8000] D loss: 0.4975, G loss: 6.4241\n",
      "[1812/8000] D loss: 0.8597, G loss: 2.0790\n",
      "[2172/8000] D loss: 0.6891, G loss: 7.8635\n",
      "[2532/8000] D loss: 0.4398, G loss: 8.3121\n",
      "[2892/8000] D loss: 0.4458, G loss: 4.4524\n",
      "[3252/8000] D loss: 1.0806, G loss: 1.5886\n",
      "[3612/8000] D loss: 0.8013, G loss: 3.7415\n",
      "[3972/8000] D loss: 0.5394, G loss: 6.9966\n",
      "[4332/8000] D loss: 0.9017, G loss: 3.6497\n",
      "[4692/8000] D loss: 0.6540, G loss: 6.8754\n",
      "[5052/8000] D loss: 0.9729, G loss: 3.1912\n",
      "[5412/8000] D loss: 1.0073, G loss: 3.1103\n",
      "[5772/8000] D loss: 0.7012, G loss: 5.6152\n",
      "[6132/8000] D loss: 0.4412, G loss: 5.0408\n",
      "[6492/8000] D loss: 0.9335, G loss: 4.6247\n",
      "[6852/8000] D loss: 0.6735, G loss: 5.7656\n",
      "[7212/8000] D loss: 0.8081, G loss: 4.5382\n",
      "[7572/8000] D loss: 0.5447, G loss: 4.5956\n",
      "[7932/8000] D loss: 0.8295, G loss: 6.4779\n",
      "train error: \n",
      " D loss: 0.809120, G loss: 4.450841, D accuracy: 75.9%, cell accuracy: 98.5%, board accuracy: 38.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.899903, G loss: 9.165542, D accuracy: 77.6%, cell accuracy: 98.1%, board accuracy: 19.9% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8124, G loss: 4.0370\n",
      "[372/8000] D loss: 0.6129, G loss: 3.0781\n",
      "[732/8000] D loss: 0.8079, G loss: 3.8561\n",
      "[1092/8000] D loss: 0.4969, G loss: 4.0169\n",
      "[1452/8000] D loss: 0.5250, G loss: 7.8932\n",
      "[1812/8000] D loss: 0.8395, G loss: 2.5152\n",
      "[2172/8000] D loss: 0.8011, G loss: 3.0240\n",
      "[2532/8000] D loss: 0.5975, G loss: 4.1512\n",
      "[2892/8000] D loss: 0.9927, G loss: 2.0465\n",
      "[3252/8000] D loss: 0.4858, G loss: 5.7586\n",
      "[3612/8000] D loss: 0.4486, G loss: 3.9491\n",
      "[3972/8000] D loss: 1.0265, G loss: 1.9782\n",
      "[4332/8000] D loss: 0.5210, G loss: 5.0513\n",
      "[4692/8000] D loss: 1.0734, G loss: 1.5316\n",
      "[5052/8000] D loss: 0.8462, G loss: 4.6979\n",
      "[5412/8000] D loss: 0.8405, G loss: 3.0897\n",
      "[5772/8000] D loss: 0.8235, G loss: 5.1936\n",
      "[6132/8000] D loss: 0.8341, G loss: 3.0186\n",
      "[6492/8000] D loss: 0.7904, G loss: 3.3658\n",
      "[6852/8000] D loss: 0.6148, G loss: 7.8740\n",
      "[7212/8000] D loss: 0.5107, G loss: 3.8402\n",
      "[7572/8000] D loss: 0.8330, G loss: 1.9896\n",
      "[7932/8000] D loss: 0.5929, G loss: 5.6758\n",
      "train error: \n",
      " D loss: 0.786379, G loss: 3.893868, D accuracy: 77.0%, cell accuracy: 98.5%, board accuracy: 38.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.773030, G loss: 8.548532, D accuracy: 81.3%, cell accuracy: 98.1%, board accuracy: 20.0% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7660, G loss: 4.3262\n",
      "[372/8000] D loss: 0.5959, G loss: 5.0025\n",
      "[732/8000] D loss: 0.7080, G loss: 3.3107\n",
      "[1092/8000] D loss: 0.3105, G loss: 5.7840\n",
      "[1452/8000] D loss: 0.5093, G loss: 5.5063\n",
      "[1812/8000] D loss: 0.4789, G loss: 4.8263\n",
      "[2172/8000] D loss: 0.5943, G loss: 3.3833\n",
      "[2532/8000] D loss: 0.7010, G loss: 4.4871\n",
      "[2892/8000] D loss: 0.6564, G loss: 5.2842\n",
      "[3252/8000] D loss: 0.8667, G loss: 2.2944\n",
      "[3612/8000] D loss: 0.6265, G loss: 2.1468\n",
      "[3972/8000] D loss: 0.7785, G loss: 5.4068\n",
      "[4332/8000] D loss: 0.7640, G loss: 4.1122\n",
      "[4692/8000] D loss: 0.3711, G loss: 7.0856\n",
      "[5052/8000] D loss: 0.6307, G loss: 6.7280\n",
      "[5412/8000] D loss: 1.1156, G loss: 3.4303\n",
      "[5772/8000] D loss: 0.7114, G loss: 5.0787\n",
      "[6132/8000] D loss: 0.9560, G loss: 2.8850\n",
      "[6492/8000] D loss: 0.5653, G loss: 4.0356\n",
      "[6852/8000] D loss: 0.6357, G loss: 3.5110\n",
      "[7212/8000] D loss: 0.8130, G loss: 3.0988\n",
      "[7572/8000] D loss: 0.8316, G loss: 2.5908\n",
      "[7932/8000] D loss: 0.7316, G loss: 3.8938\n",
      "train error: \n",
      " D loss: 0.769699, G loss: 3.873499, D accuracy: 77.4%, cell accuracy: 98.5%, board accuracy: 38.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.735399, G loss: 8.529093, D accuracy: 81.9%, cell accuracy: 98.1%, board accuracy: 19.1% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8295, G loss: 2.6355\n",
      "[372/8000] D loss: 0.9516, G loss: 1.8383\n",
      "[732/8000] D loss: 0.6450, G loss: 7.7992\n",
      "[1092/8000] D loss: 0.8964, G loss: 4.0362\n",
      "[1452/8000] D loss: 0.6559, G loss: 3.6919\n",
      "[1812/8000] D loss: 0.7089, G loss: 3.9905\n",
      "[2172/8000] D loss: 0.9761, G loss: 4.7244\n",
      "[2532/8000] D loss: 0.7513, G loss: 2.3351\n",
      "[2892/8000] D loss: 0.4877, G loss: 7.2137\n",
      "[3252/8000] D loss: 0.5757, G loss: 4.4637\n",
      "[3612/8000] D loss: 0.6143, G loss: 3.3339\n",
      "[3972/8000] D loss: 0.6332, G loss: 3.6487\n",
      "[4332/8000] D loss: 0.6196, G loss: 4.7926\n",
      "[4692/8000] D loss: 0.5880, G loss: 7.3671\n",
      "[5052/8000] D loss: 0.2421, G loss: 6.6235\n",
      "[5412/8000] D loss: 1.0399, G loss: 2.1129\n",
      "[5772/8000] D loss: 0.8694, G loss: 2.6582\n",
      "[6132/8000] D loss: 0.7074, G loss: 4.5352\n",
      "[6492/8000] D loss: 0.9176, G loss: 2.4012\n",
      "[6852/8000] D loss: 0.7723, G loss: 4.7849\n",
      "[7212/8000] D loss: 0.8577, G loss: 2.2615\n",
      "[7572/8000] D loss: 0.9016, G loss: 3.6690\n",
      "[7932/8000] D loss: 0.7175, G loss: 3.7164\n",
      "train error: \n",
      " D loss: 0.771422, G loss: 3.921348, D accuracy: 77.7%, cell accuracy: 98.5%, board accuracy: 38.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.714702, G loss: 8.764742, D accuracy: 82.6%, cell accuracy: 98.1%, board accuracy: 18.9% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6438, G loss: 5.9973\n",
      "[372/8000] D loss: 0.9050, G loss: 3.5126\n",
      "[732/8000] D loss: 0.7199, G loss: 4.3291\n",
      "[1092/8000] D loss: 0.6289, G loss: 4.1363\n",
      "[1452/8000] D loss: 0.7783, G loss: 3.6031\n",
      "[1812/8000] D loss: 0.9165, G loss: 3.4940\n",
      "[2172/8000] D loss: 0.7808, G loss: 5.0252\n",
      "[2532/8000] D loss: 1.1749, G loss: 1.5983\n",
      "[2892/8000] D loss: 0.6883, G loss: 5.2267\n",
      "[3252/8000] D loss: 0.8846, G loss: 5.5191\n",
      "[3612/8000] D loss: 1.4095, G loss: 1.2773\n",
      "[3972/8000] D loss: 0.6767, G loss: 2.2721\n",
      "[4332/8000] D loss: 0.8182, G loss: 3.2561\n",
      "[4692/8000] D loss: 0.9069, G loss: 3.1967\n",
      "[5052/8000] D loss: 0.9908, G loss: 2.1309\n",
      "[5412/8000] D loss: 0.4911, G loss: 2.5167\n",
      "[5772/8000] D loss: 1.0044, G loss: 5.6089\n",
      "[6132/8000] D loss: 0.7838, G loss: 3.3007\n",
      "[6492/8000] D loss: 1.0414, G loss: 3.6988\n",
      "[6852/8000] D loss: 0.4870, G loss: 6.3922\n",
      "[7212/8000] D loss: 0.8361, G loss: 5.6927\n",
      "[7572/8000] D loss: 0.8070, G loss: 8.8743\n",
      "[7932/8000] D loss: 0.7020, G loss: 2.7097\n",
      "train error: \n",
      " D loss: 0.784168, G loss: 3.952349, D accuracy: 77.2%, cell accuracy: 98.5%, board accuracy: 38.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.807600, G loss: 8.562945, D accuracy: 80.2%, cell accuracy: 98.1%, board accuracy: 19.9% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4977, G loss: 4.9066\n",
      "[372/8000] D loss: 0.9293, G loss: 3.5090\n",
      "[732/8000] D loss: 0.7374, G loss: 3.3118\n",
      "[1092/8000] D loss: 1.1660, G loss: 1.4170\n",
      "[1452/8000] D loss: 1.0538, G loss: 5.4728\n",
      "[1812/8000] D loss: 0.6706, G loss: 5.9484\n",
      "[2172/8000] D loss: 0.5992, G loss: 3.1515\n",
      "[2532/8000] D loss: 1.2390, G loss: 1.7255\n",
      "[2892/8000] D loss: 1.1187, G loss: 2.4421\n",
      "[3252/8000] D loss: 0.7828, G loss: 3.7190\n",
      "[3612/8000] D loss: 0.9200, G loss: 3.1721\n",
      "[3972/8000] D loss: 0.7217, G loss: 4.7699\n",
      "[4332/8000] D loss: 0.7912, G loss: 3.0695\n",
      "[4692/8000] D loss: 0.7972, G loss: 2.3547\n",
      "[5052/8000] D loss: 0.9152, G loss: 1.9345\n",
      "[5412/8000] D loss: 0.6664, G loss: 5.2123\n",
      "[5772/8000] D loss: 0.6727, G loss: 4.2488\n",
      "[6132/8000] D loss: 0.6965, G loss: 8.1211\n",
      "[6492/8000] D loss: 0.4648, G loss: 5.2856\n",
      "[6852/8000] D loss: 0.8939, G loss: 2.4000\n",
      "[7212/8000] D loss: 0.5444, G loss: 5.8011\n",
      "[7572/8000] D loss: 0.6105, G loss: 5.8988\n",
      "[7932/8000] D loss: 0.9153, G loss: 2.9820\n",
      "train error: \n",
      " D loss: 0.792839, G loss: 4.179486, D accuracy: 76.7%, cell accuracy: 98.5%, board accuracy: 38.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.733068, G loss: 8.971116, D accuracy: 82.2%, cell accuracy: 98.1%, board accuracy: 20.8% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5093, G loss: 6.1568\n",
      "[372/8000] D loss: 1.0404, G loss: 2.2712\n",
      "[732/8000] D loss: 0.7605, G loss: 3.9405\n",
      "[1092/8000] D loss: 0.8224, G loss: 2.5266\n",
      "[1452/8000] D loss: 0.6673, G loss: 5.6249\n",
      "[1812/8000] D loss: 0.6480, G loss: 4.9770\n",
      "[2172/8000] D loss: 0.8587, G loss: 1.7556\n",
      "[2532/8000] D loss: 0.7016, G loss: 4.0362\n",
      "[2892/8000] D loss: 0.5823, G loss: 5.8706\n",
      "[3252/8000] D loss: 1.0180, G loss: 2.2069\n",
      "[3612/8000] D loss: 0.8187, G loss: 3.6570\n",
      "[3972/8000] D loss: 0.5722, G loss: 6.3792\n",
      "[4332/8000] D loss: 0.8691, G loss: 3.8912\n",
      "[4692/8000] D loss: 0.3908, G loss: 8.1861\n",
      "[5052/8000] D loss: 0.5214, G loss: 6.9439\n",
      "[5412/8000] D loss: 0.7819, G loss: 4.6683\n",
      "[5772/8000] D loss: 0.8503, G loss: 3.0140\n",
      "[6132/8000] D loss: 0.6864, G loss: 2.6064\n",
      "[6492/8000] D loss: 0.4948, G loss: 6.7590\n",
      "[6852/8000] D loss: 0.7644, G loss: 6.0377\n",
      "[7212/8000] D loss: 0.8950, G loss: 3.5424\n",
      "[7572/8000] D loss: 0.3776, G loss: 5.1914\n",
      "[7932/8000] D loss: 0.8020, G loss: 3.5074\n",
      "train error: \n",
      " D loss: 0.795755, G loss: 3.487737, D accuracy: 77.2%, cell accuracy: 98.5%, board accuracy: 39.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.694537, G loss: 7.729818, D accuracy: 83.2%, cell accuracy: 98.1%, board accuracy: 18.7% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7486, G loss: 3.6690\n",
      "[372/8000] D loss: 0.6586, G loss: 4.0955\n",
      "[732/8000] D loss: 0.4955, G loss: 7.7851\n",
      "[1092/8000] D loss: 0.2432, G loss: 9.1573\n",
      "[1452/8000] D loss: 0.8878, G loss: 2.9104\n",
      "[1812/8000] D loss: 0.6072, G loss: 4.7340\n",
      "[2172/8000] D loss: 0.7291, G loss: 4.1774\n",
      "[2532/8000] D loss: 0.6948, G loss: 7.1221\n",
      "[2892/8000] D loss: 0.8284, G loss: 3.4448\n",
      "[3252/8000] D loss: 0.6174, G loss: 5.1963\n",
      "[3612/8000] D loss: 0.7976, G loss: 2.9296\n",
      "[3972/8000] D loss: 0.7762, G loss: 3.5837\n",
      "[4332/8000] D loss: 0.3378, G loss: 4.4502\n",
      "[4692/8000] D loss: 0.7745, G loss: 8.3073\n",
      "[5052/8000] D loss: 0.9584, G loss: 1.6960\n",
      "[5412/8000] D loss: 0.8700, G loss: 3.4920\n",
      "[5772/8000] D loss: 0.8446, G loss: 3.3694\n",
      "[6132/8000] D loss: 0.7684, G loss: 3.3984\n",
      "[6492/8000] D loss: 0.8222, G loss: 3.9720\n",
      "[6852/8000] D loss: 0.6689, G loss: 6.1812\n",
      "[7212/8000] D loss: 0.9007, G loss: 3.4501\n",
      "[7572/8000] D loss: 0.6725, G loss: 5.9692\n",
      "[7932/8000] D loss: 0.6610, G loss: 3.8278\n",
      "train error: \n",
      " D loss: 0.781284, G loss: 4.298659, D accuracy: 77.2%, cell accuracy: 98.5%, board accuracy: 38.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.775631, G loss: 9.269201, D accuracy: 79.9%, cell accuracy: 98.1%, board accuracy: 20.8% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7592, G loss: 4.7448\n",
      "[372/8000] D loss: 0.6794, G loss: 5.8345\n",
      "[732/8000] D loss: 1.0146, G loss: 2.1325\n",
      "[1092/8000] D loss: 0.7351, G loss: 3.3099\n",
      "[1452/8000] D loss: 0.9972, G loss: 3.1333\n",
      "[1812/8000] D loss: 0.4663, G loss: 8.2240\n",
      "[2172/8000] D loss: 0.7657, G loss: 4.5544\n",
      "[2532/8000] D loss: 0.5585, G loss: 7.0596\n",
      "[2892/8000] D loss: 0.8462, G loss: 3.7851\n",
      "[3252/8000] D loss: 1.1072, G loss: 2.7082\n",
      "[3612/8000] D loss: 0.9731, G loss: 1.8348\n",
      "[3972/8000] D loss: 0.9898, G loss: 3.8514\n",
      "[4332/8000] D loss: 0.5452, G loss: 3.4660\n",
      "[4692/8000] D loss: 1.2732, G loss: 3.7069\n",
      "[5052/8000] D loss: 0.2698, G loss: 6.9486\n",
      "[5412/8000] D loss: 0.6428, G loss: 7.8044\n",
      "[5772/8000] D loss: 0.6529, G loss: 6.8013\n",
      "[6132/8000] D loss: 0.5701, G loss: 4.2476\n",
      "[6492/8000] D loss: 1.1250, G loss: 1.4619\n",
      "[6852/8000] D loss: 0.6142, G loss: 3.9145\n",
      "[7212/8000] D loss: 0.7020, G loss: 2.8122\n",
      "[7572/8000] D loss: 0.9524, G loss: 2.5212\n",
      "[7932/8000] D loss: 0.6943, G loss: 4.5751\n",
      "train error: \n",
      " D loss: 0.781309, G loss: 4.044235, D accuracy: 76.8%, cell accuracy: 98.6%, board accuracy: 40.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.755787, G loss: 8.858887, D accuracy: 80.3%, cell accuracy: 98.2%, board accuracy: 20.6% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9371, G loss: 2.4289\n",
      "[372/8000] D loss: 1.3094, G loss: 1.7165\n",
      "[732/8000] D loss: 0.7839, G loss: 2.1662\n",
      "[1092/8000] D loss: 0.9167, G loss: 2.4497\n",
      "[1452/8000] D loss: 0.6772, G loss: 8.3287\n",
      "[1812/8000] D loss: 0.9794, G loss: 4.0496\n",
      "[2172/8000] D loss: 0.7336, G loss: 3.9095\n",
      "[2532/8000] D loss: 0.4867, G loss: 6.3849\n",
      "[2892/8000] D loss: 0.5727, G loss: 4.0210\n",
      "[3252/8000] D loss: 1.1347, G loss: 3.0427\n",
      "[3612/8000] D loss: 0.4215, G loss: 5.5093\n",
      "[3972/8000] D loss: 0.7438, G loss: 3.9541\n",
      "[4332/8000] D loss: 0.4613, G loss: 4.1064\n",
      "[4692/8000] D loss: 0.7484, G loss: 5.0958\n",
      "[5052/8000] D loss: 0.9241, G loss: 4.7047\n",
      "[5412/8000] D loss: 1.1804, G loss: 3.2444\n",
      "[5772/8000] D loss: 0.7786, G loss: 3.2797\n",
      "[6132/8000] D loss: 0.6756, G loss: 6.6891\n",
      "[6492/8000] D loss: 1.0677, G loss: 1.9849\n",
      "[6852/8000] D loss: 1.0604, G loss: 2.2745\n",
      "[7212/8000] D loss: 0.8714, G loss: 3.4044\n",
      "[7572/8000] D loss: 0.7366, G loss: 6.4443\n",
      "[7932/8000] D loss: 0.9200, G loss: 3.0308\n",
      "train error: \n",
      " D loss: 0.812455, G loss: 4.414716, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 40.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.868699, G loss: 9.302880, D accuracy: 76.9%, cell accuracy: 98.1%, board accuracy: 19.4% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7910, G loss: 2.7255\n",
      "[372/8000] D loss: 0.7836, G loss: 5.5525\n",
      "[732/8000] D loss: 1.0263, G loss: 4.1662\n",
      "[1092/8000] D loss: 0.8177, G loss: 4.1434\n",
      "[1452/8000] D loss: 0.8678, G loss: 4.9955\n",
      "[1812/8000] D loss: 0.9219, G loss: 3.6196\n",
      "[2172/8000] D loss: 0.9044, G loss: 3.5095\n",
      "[2532/8000] D loss: 0.5460, G loss: 3.7810\n",
      "[2892/8000] D loss: 1.0561, G loss: 2.2705\n",
      "[3252/8000] D loss: 0.6314, G loss: 4.6174\n",
      "[3612/8000] D loss: 1.1166, G loss: 2.4176\n",
      "[3972/8000] D loss: 0.6797, G loss: 4.2341\n",
      "[4332/8000] D loss: 0.7365, G loss: 4.1320\n",
      "[4692/8000] D loss: 0.8307, G loss: 3.7707\n",
      "[5052/8000] D loss: 0.6609, G loss: 4.0186\n",
      "[5412/8000] D loss: 0.6498, G loss: 5.3288\n",
      "[5772/8000] D loss: 0.6254, G loss: 5.4077\n",
      "[6132/8000] D loss: 0.9446, G loss: 6.5243\n",
      "[6492/8000] D loss: 0.5506, G loss: 5.3436\n",
      "[6852/8000] D loss: 0.7639, G loss: 5.0081\n",
      "[7212/8000] D loss: 1.0218, G loss: 2.7170\n",
      "[7572/8000] D loss: 0.8701, G loss: 4.8763\n",
      "[7932/8000] D loss: 1.1186, G loss: 2.9002\n",
      "train error: \n",
      " D loss: 0.783323, G loss: 4.267042, D accuracy: 77.3%, cell accuracy: 98.5%, board accuracy: 38.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.708162, G loss: 9.385792, D accuracy: 83.5%, cell accuracy: 98.1%, board accuracy: 19.1% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6547, G loss: 3.0011\n",
      "[372/8000] D loss: 0.6563, G loss: 3.2874\n",
      "[732/8000] D loss: 0.8503, G loss: 6.4426\n",
      "[1092/8000] D loss: 0.5856, G loss: 4.1132\n",
      "[1452/8000] D loss: 0.4478, G loss: 4.5017\n",
      "[1812/8000] D loss: 0.9230, G loss: 4.4146\n",
      "[2172/8000] D loss: 0.6286, G loss: 4.1738\n",
      "[2532/8000] D loss: 0.5528, G loss: 4.7750\n",
      "[2892/8000] D loss: 0.7690, G loss: 4.6996\n",
      "[3252/8000] D loss: 0.6843, G loss: 3.4865\n",
      "[3612/8000] D loss: 0.4427, G loss: 6.0124\n",
      "[3972/8000] D loss: 0.9032, G loss: 4.5423\n",
      "[4332/8000] D loss: 0.6050, G loss: 3.7468\n",
      "[4692/8000] D loss: 0.9462, G loss: 3.7401\n",
      "[5052/8000] D loss: 0.8904, G loss: 2.1057\n",
      "[5412/8000] D loss: 1.0314, G loss: 2.8135\n",
      "[5772/8000] D loss: 0.6973, G loss: 4.8540\n",
      "[6132/8000] D loss: 0.7040, G loss: 4.0054\n",
      "[6492/8000] D loss: 0.9140, G loss: 1.7063\n",
      "[6852/8000] D loss: 0.8978, G loss: 2.7819\n",
      "[7212/8000] D loss: 0.8363, G loss: 3.5756\n",
      "[7572/8000] D loss: 0.6055, G loss: 4.4413\n",
      "[7932/8000] D loss: 0.7137, G loss: 5.0919\n",
      "train error: \n",
      " D loss: 0.768779, G loss: 4.141032, D accuracy: 77.7%, cell accuracy: 98.5%, board accuracy: 39.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.757137, G loss: 9.013371, D accuracy: 82.2%, cell accuracy: 98.1%, board accuracy: 19.1% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0698, G loss: 1.8386\n",
      "[372/8000] D loss: 0.7207, G loss: 6.4200\n",
      "[732/8000] D loss: 0.8756, G loss: 3.9866\n",
      "[1092/8000] D loss: 0.5358, G loss: 7.1237\n",
      "[1452/8000] D loss: 0.6893, G loss: 5.1103\n",
      "[1812/8000] D loss: 1.1679, G loss: 3.2124\n",
      "[2172/8000] D loss: 0.7461, G loss: 4.9227\n",
      "[2532/8000] D loss: 0.7059, G loss: 4.5323\n",
      "[2892/8000] D loss: 0.7047, G loss: 3.1645\n",
      "[3252/8000] D loss: 0.8424, G loss: 3.5518\n",
      "[3612/8000] D loss: 0.8255, G loss: 3.3227\n",
      "[3972/8000] D loss: 0.8002, G loss: 3.0461\n",
      "[4332/8000] D loss: 0.8678, G loss: 2.1443\n",
      "[4692/8000] D loss: 0.7859, G loss: 3.9257\n",
      "[5052/8000] D loss: 0.9591, G loss: 2.8811\n",
      "[5412/8000] D loss: 0.4849, G loss: 3.5144\n",
      "[5772/8000] D loss: 0.8016, G loss: 4.9886\n",
      "[6132/8000] D loss: 0.7761, G loss: 2.3320\n",
      "[6492/8000] D loss: 0.6320, G loss: 4.1580\n",
      "[6852/8000] D loss: 0.4362, G loss: 5.2966\n",
      "[7212/8000] D loss: 0.5572, G loss: 5.3410\n",
      "[7572/8000] D loss: 0.9173, G loss: 2.6322\n",
      "[7932/8000] D loss: 0.7557, G loss: 7.8230\n",
      "train error: \n",
      " D loss: 0.801239, G loss: 3.606047, D accuracy: 76.8%, cell accuracy: 98.5%, board accuracy: 40.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.686217, G loss: 8.313301, D accuracy: 83.8%, cell accuracy: 98.1%, board accuracy: 20.2% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2153, G loss: 1.0475\n",
      "[372/8000] D loss: 0.7541, G loss: 7.9765\n",
      "[732/8000] D loss: 0.8302, G loss: 4.3395\n",
      "[1092/8000] D loss: 0.9702, G loss: 6.0211\n",
      "[1452/8000] D loss: 0.6335, G loss: 5.2448\n",
      "[1812/8000] D loss: 0.5429, G loss: 2.9528\n",
      "[2172/8000] D loss: 0.8151, G loss: 3.1880\n",
      "[2532/8000] D loss: 1.0355, G loss: 2.7924\n",
      "[2892/8000] D loss: 1.1286, G loss: 2.7180\n",
      "[3252/8000] D loss: 1.0217, G loss: 3.6995\n",
      "[3612/8000] D loss: 1.0049, G loss: 1.7691\n",
      "[3972/8000] D loss: 1.0220, G loss: 2.5589\n",
      "[4332/8000] D loss: 0.9112, G loss: 5.2745\n",
      "[4692/8000] D loss: 0.4817, G loss: 7.4446\n",
      "[5052/8000] D loss: 0.7435, G loss: 4.6516\n",
      "[5412/8000] D loss: 0.5236, G loss: 4.5742\n",
      "[5772/8000] D loss: 0.6313, G loss: 4.9634\n",
      "[6132/8000] D loss: 0.9409, G loss: 2.7210\n",
      "[6492/8000] D loss: 0.7754, G loss: 2.6367\n",
      "[6852/8000] D loss: 0.9587, G loss: 3.3145\n",
      "[7212/8000] D loss: 0.8678, G loss: 2.4711\n",
      "[7572/8000] D loss: 1.1347, G loss: 6.2355\n",
      "[7932/8000] D loss: 1.0876, G loss: 1.1270\n",
      "train error: \n",
      " D loss: 0.784238, G loss: 3.805955, D accuracy: 77.5%, cell accuracy: 98.5%, board accuracy: 38.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.740693, G loss: 8.614616, D accuracy: 82.0%, cell accuracy: 98.1%, board accuracy: 19.8% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6247, G loss: 4.2731\n",
      "[372/8000] D loss: 0.7319, G loss: 3.5469\n",
      "[732/8000] D loss: 0.8986, G loss: 4.6225\n",
      "[1092/8000] D loss: 0.8193, G loss: 3.4635\n",
      "[1452/8000] D loss: 0.8591, G loss: 5.0427\n",
      "[1812/8000] D loss: 0.7873, G loss: 5.5449\n",
      "[2172/8000] D loss: 1.1911, G loss: 3.5296\n",
      "[2532/8000] D loss: 0.5843, G loss: 2.9054\n",
      "[2892/8000] D loss: 0.8309, G loss: 2.8525\n",
      "[3252/8000] D loss: 0.4436, G loss: 4.7623\n",
      "[3612/8000] D loss: 0.7655, G loss: 5.1616\n",
      "[3972/8000] D loss: 0.9553, G loss: 2.3590\n",
      "[4332/8000] D loss: 0.9423, G loss: 2.9380\n",
      "[4692/8000] D loss: 0.8321, G loss: 5.6301\n",
      "[5052/8000] D loss: 0.8794, G loss: 1.8358\n",
      "[5412/8000] D loss: 0.9407, G loss: 4.0862\n",
      "[5772/8000] D loss: 0.7717, G loss: 4.3711\n",
      "[6132/8000] D loss: 0.3672, G loss: 5.6684\n",
      "[6492/8000] D loss: 1.0358, G loss: 2.5973\n",
      "[6852/8000] D loss: 0.6826, G loss: 3.2000\n",
      "[7212/8000] D loss: 0.5382, G loss: 4.7479\n",
      "[7572/8000] D loss: 0.5391, G loss: 3.9521\n",
      "[7932/8000] D loss: 1.2215, G loss: 3.4762\n",
      "train error: \n",
      " D loss: 0.790974, G loss: 3.890567, D accuracy: 76.6%, cell accuracy: 98.5%, board accuracy: 39.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.766979, G loss: 8.705748, D accuracy: 79.9%, cell accuracy: 98.1%, board accuracy: 20.9% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7180, G loss: 2.3070\n",
      "[372/8000] D loss: 0.8194, G loss: 3.5288\n",
      "[732/8000] D loss: 0.5730, G loss: 4.4562\n",
      "[1092/8000] D loss: 1.2154, G loss: 3.4923\n",
      "[1452/8000] D loss: 0.7196, G loss: 6.6005\n",
      "[1812/8000] D loss: 0.9027, G loss: 1.8768\n",
      "[2172/8000] D loss: 0.6079, G loss: 5.8660\n",
      "[2532/8000] D loss: 0.7464, G loss: 2.2897\n",
      "[2892/8000] D loss: 0.8821, G loss: 2.2768\n",
      "[3252/8000] D loss: 1.0237, G loss: 1.2369\n",
      "[3612/8000] D loss: 0.7266, G loss: 3.2595\n",
      "[3972/8000] D loss: 0.7333, G loss: 3.3889\n",
      "[4332/8000] D loss: 0.4717, G loss: 5.8442\n",
      "[4692/8000] D loss: 0.6228, G loss: 5.0646\n",
      "[5052/8000] D loss: 0.5877, G loss: 5.1177\n",
      "[5412/8000] D loss: 0.7509, G loss: 6.6132\n",
      "[5772/8000] D loss: 1.0195, G loss: 2.8996\n",
      "[6132/8000] D loss: 0.7660, G loss: 4.0255\n",
      "[6492/8000] D loss: 0.8286, G loss: 3.0388\n",
      "[6852/8000] D loss: 0.8998, G loss: 3.7969\n",
      "[7212/8000] D loss: 0.5930, G loss: 8.4949\n",
      "[7572/8000] D loss: 0.6469, G loss: 5.7622\n",
      "[7932/8000] D loss: 1.0064, G loss: 2.7010\n",
      "train error: \n",
      " D loss: 0.803495, G loss: 4.278899, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 40.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.785375, G loss: 9.475867, D accuracy: 81.8%, cell accuracy: 98.1%, board accuracy: 20.8% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5338, G loss: 3.6283\n",
      "[372/8000] D loss: 0.9848, G loss: 3.6165\n",
      "[732/8000] D loss: 0.9249, G loss: 4.4501\n",
      "[1092/8000] D loss: 0.7601, G loss: 3.2889\n",
      "[1452/8000] D loss: 0.7836, G loss: 5.8830\n",
      "[1812/8000] D loss: 1.0807, G loss: 1.5673\n",
      "[2172/8000] D loss: 0.8502, G loss: 3.2928\n",
      "[2532/8000] D loss: 0.8639, G loss: 2.9955\n",
      "[2892/8000] D loss: 0.9837, G loss: 3.3344\n",
      "[3252/8000] D loss: 0.5187, G loss: 4.7349\n",
      "[3612/8000] D loss: 0.7981, G loss: 3.4187\n",
      "[3972/8000] D loss: 0.7365, G loss: 5.4047\n",
      "[4332/8000] D loss: 0.6782, G loss: 2.8490\n",
      "[4692/8000] D loss: 0.4521, G loss: 5.3158\n",
      "[5052/8000] D loss: 0.7037, G loss: 5.4740\n",
      "[5412/8000] D loss: 0.4404, G loss: 5.0626\n",
      "[5772/8000] D loss: 1.1779, G loss: 4.0920\n",
      "[6132/8000] D loss: 0.2689, G loss: 5.8591\n",
      "[6492/8000] D loss: 0.8403, G loss: 2.8827\n",
      "[6852/8000] D loss: 0.2977, G loss: 5.9035\n",
      "[7212/8000] D loss: 0.8486, G loss: 3.7460\n",
      "[7572/8000] D loss: 0.8278, G loss: 4.1749\n",
      "[7932/8000] D loss: 0.7763, G loss: 4.9715\n",
      "train error: \n",
      " D loss: 0.781988, G loss: 3.730766, D accuracy: 77.2%, cell accuracy: 98.5%, board accuracy: 39.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.734193, G loss: 8.440120, D accuracy: 82.2%, cell accuracy: 98.1%, board accuracy: 19.2% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8541, G loss: 3.1021\n",
      "[372/8000] D loss: 0.5912, G loss: 4.1744\n",
      "[732/8000] D loss: 0.4687, G loss: 3.2144\n",
      "[1092/8000] D loss: 0.7905, G loss: 3.0650\n",
      "[1452/8000] D loss: 0.7078, G loss: 5.4125\n",
      "[1812/8000] D loss: 1.0080, G loss: 2.3208\n",
      "[2172/8000] D loss: 0.7712, G loss: 4.7290\n",
      "[2532/8000] D loss: 0.6623, G loss: 4.9070\n",
      "[2892/8000] D loss: 0.6767, G loss: 3.7151\n",
      "[3252/8000] D loss: 0.7417, G loss: 6.0402\n",
      "[3612/8000] D loss: 0.5833, G loss: 3.9385\n",
      "[3972/8000] D loss: 0.7053, G loss: 4.2233\n",
      "[4332/8000] D loss: 0.6574, G loss: 4.8823\n",
      "[4692/8000] D loss: 0.7814, G loss: 3.7747\n",
      "[5052/8000] D loss: 0.6385, G loss: 7.9882\n",
      "[5412/8000] D loss: 0.4239, G loss: 4.6710\n",
      "[5772/8000] D loss: 0.7361, G loss: 3.2317\n",
      "[6132/8000] D loss: 1.0770, G loss: 1.5623\n",
      "[6492/8000] D loss: 0.7762, G loss: 4.8481\n",
      "[6852/8000] D loss: 0.8754, G loss: 3.6096\n",
      "[7212/8000] D loss: 0.5810, G loss: 3.9788\n",
      "[7572/8000] D loss: 0.9618, G loss: 2.0546\n",
      "[7932/8000] D loss: 0.6216, G loss: 2.9000\n",
      "train error: \n",
      " D loss: 0.791377, G loss: 3.516632, D accuracy: 76.9%, cell accuracy: 98.5%, board accuracy: 38.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.783063, G loss: 7.937896, D accuracy: 80.2%, cell accuracy: 98.1%, board accuracy: 19.7% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4647, G loss: 4.7969\n",
      "[372/8000] D loss: 0.9466, G loss: 3.9270\n",
      "[732/8000] D loss: 0.9617, G loss: 4.2326\n",
      "[1092/8000] D loss: 0.6919, G loss: 3.7417\n",
      "[1452/8000] D loss: 0.6948, G loss: 3.0782\n",
      "[1812/8000] D loss: 0.9258, G loss: 1.6103\n",
      "[2172/8000] D loss: 0.7150, G loss: 3.6580\n",
      "[2532/8000] D loss: 1.0095, G loss: 2.9557\n",
      "[2892/8000] D loss: 0.4856, G loss: 7.6341\n",
      "[3252/8000] D loss: 0.8413, G loss: 3.5033\n",
      "[3612/8000] D loss: 0.5786, G loss: 3.6363\n",
      "[3972/8000] D loss: 0.9547, G loss: 2.2752\n",
      "[4332/8000] D loss: 0.6381, G loss: 4.0469\n",
      "[4692/8000] D loss: 0.3751, G loss: 4.5987\n",
      "[5052/8000] D loss: 0.4042, G loss: 6.6225\n",
      "[5412/8000] D loss: 0.9423, G loss: 3.0616\n",
      "[5772/8000] D loss: 1.3531, G loss: 1.0506\n",
      "[6132/8000] D loss: 0.6751, G loss: 6.5023\n",
      "[6492/8000] D loss: 0.7867, G loss: 5.8632\n",
      "[6852/8000] D loss: 0.6961, G loss: 2.4897\n",
      "[7212/8000] D loss: 0.7992, G loss: 5.3243\n",
      "[7572/8000] D loss: 0.8245, G loss: 2.7209\n",
      "[7932/8000] D loss: 0.6766, G loss: 4.5086\n",
      "train error: \n",
      " D loss: 0.775061, G loss: 4.080048, D accuracy: 77.1%, cell accuracy: 98.5%, board accuracy: 40.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.770732, G loss: 9.376953, D accuracy: 80.6%, cell accuracy: 98.1%, board accuracy: 20.1% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6949, G loss: 6.8471\n",
      "[372/8000] D loss: 0.7775, G loss: 2.8587\n",
      "[732/8000] D loss: 1.1104, G loss: 3.0989\n",
      "[1092/8000] D loss: 0.8344, G loss: 3.8074\n",
      "[1452/8000] D loss: 0.9976, G loss: 2.4193\n",
      "[1812/8000] D loss: 1.1039, G loss: 1.2316\n",
      "[2172/8000] D loss: 0.7967, G loss: 5.8965\n",
      "[2532/8000] D loss: 0.5568, G loss: 4.6344\n",
      "[2892/8000] D loss: 1.0218, G loss: 2.5821\n",
      "[3252/8000] D loss: 0.7391, G loss: 5.8499\n",
      "[3612/8000] D loss: 0.9751, G loss: 3.5983\n",
      "[3972/8000] D loss: 0.2916, G loss: 3.9400\n",
      "[4332/8000] D loss: 0.8836, G loss: 2.0176\n",
      "[4692/8000] D loss: 0.9157, G loss: 2.1944\n",
      "[5052/8000] D loss: 0.9434, G loss: 2.8118\n",
      "[5412/8000] D loss: 0.6961, G loss: 8.1981\n",
      "[5772/8000] D loss: 1.1168, G loss: 1.7729\n",
      "[6132/8000] D loss: 0.9948, G loss: 2.9263\n",
      "[6492/8000] D loss: 0.7735, G loss: 2.7897\n",
      "[6852/8000] D loss: 0.5096, G loss: 4.3405\n",
      "[7212/8000] D loss: 0.7978, G loss: 4.0922\n",
      "[7572/8000] D loss: 0.9279, G loss: 2.8149\n",
      "[7932/8000] D loss: 0.8870, G loss: 3.5124\n",
      "train error: \n",
      " D loss: 0.816065, G loss: 3.728964, D accuracy: 76.6%, cell accuracy: 98.5%, board accuracy: 39.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.676475, G loss: 8.873369, D accuracy: 84.4%, cell accuracy: 98.1%, board accuracy: 20.3% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0743, G loss: 1.4699\n",
      "[372/8000] D loss: 0.7275, G loss: 3.4501\n",
      "[732/8000] D loss: 0.9133, G loss: 3.0952\n",
      "[1092/8000] D loss: 0.6141, G loss: 5.4175\n",
      "[1452/8000] D loss: 0.8596, G loss: 4.3948\n",
      "[1812/8000] D loss: 0.8447, G loss: 4.6678\n",
      "[2172/8000] D loss: 0.6712, G loss: 4.5166\n",
      "[2532/8000] D loss: 0.9213, G loss: 1.7239\n",
      "[2892/8000] D loss: 0.7715, G loss: 3.1646\n",
      "[3252/8000] D loss: 0.3676, G loss: 7.1927\n",
      "[3612/8000] D loss: 0.6600, G loss: 3.4826\n",
      "[3972/8000] D loss: 0.8639, G loss: 2.3385\n",
      "[4332/8000] D loss: 0.7510, G loss: 5.2365\n",
      "[4692/8000] D loss: 0.9326, G loss: 4.0185\n",
      "[5052/8000] D loss: 0.8001, G loss: 5.6433\n",
      "[5412/8000] D loss: 0.8735, G loss: 2.6935\n",
      "[5772/8000] D loss: 0.9593, G loss: 3.6542\n",
      "[6132/8000] D loss: 0.6604, G loss: 4.6221\n",
      "[6492/8000] D loss: 1.0577, G loss: 2.2033\n",
      "[6852/8000] D loss: 0.6986, G loss: 4.4954\n",
      "[7212/8000] D loss: 0.8014, G loss: 3.8970\n",
      "[7572/8000] D loss: 1.0797, G loss: 2.5705\n",
      "[7932/8000] D loss: 0.7731, G loss: 2.3381\n",
      "train error: \n",
      " D loss: 0.786497, G loss: 4.369916, D accuracy: 77.2%, cell accuracy: 98.6%, board accuracy: 40.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.812829, G loss: 9.578417, D accuracy: 80.9%, cell accuracy: 98.1%, board accuracy: 20.2% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4067, G loss: 8.2763\n",
      "[372/8000] D loss: 0.7778, G loss: 3.7098\n",
      "[732/8000] D loss: 0.6968, G loss: 8.6263\n",
      "[1092/8000] D loss: 0.5209, G loss: 5.0360\n",
      "[1452/8000] D loss: 0.7767, G loss: 3.9505\n",
      "[1812/8000] D loss: 0.4695, G loss: 5.3059\n",
      "[2172/8000] D loss: 0.6855, G loss: 2.9064\n",
      "[2532/8000] D loss: 0.5108, G loss: 3.7540\n",
      "[2892/8000] D loss: 0.4059, G loss: 4.3070\n",
      "[3252/8000] D loss: 0.8958, G loss: 3.6550\n",
      "[3612/8000] D loss: 1.1676, G loss: 1.5885\n",
      "[3972/8000] D loss: 0.5176, G loss: 5.5673\n",
      "[4332/8000] D loss: 0.6793, G loss: 3.9273\n",
      "[4692/8000] D loss: 0.5105, G loss: 3.7639\n",
      "[5052/8000] D loss: 0.7331, G loss: 4.0192\n",
      "[5412/8000] D loss: 0.7506, G loss: 4.3818\n",
      "[5772/8000] D loss: 1.0920, G loss: 2.3643\n",
      "[6132/8000] D loss: 0.5452, G loss: 4.4262\n",
      "[6492/8000] D loss: 1.0292, G loss: 2.3133\n",
      "[6852/8000] D loss: 0.6971, G loss: 4.3214\n",
      "[7212/8000] D loss: 0.8463, G loss: 3.5121\n",
      "[7572/8000] D loss: 0.9946, G loss: 2.9638\n",
      "[7932/8000] D loss: 0.5536, G loss: 4.5469\n",
      "train error: \n",
      " D loss: 0.781631, G loss: 4.469012, D accuracy: 76.7%, cell accuracy: 98.6%, board accuracy: 40.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.830805, G loss: 9.980653, D accuracy: 78.8%, cell accuracy: 98.1%, board accuracy: 19.9% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6046, G loss: 6.9212\n",
      "[372/8000] D loss: 1.0717, G loss: 1.1856\n",
      "[732/8000] D loss: 1.0123, G loss: 3.8808\n",
      "[1092/8000] D loss: 0.7570, G loss: 7.4991\n",
      "[1452/8000] D loss: 0.6585, G loss: 5.2950\n",
      "[1812/8000] D loss: 0.4782, G loss: 6.2267\n",
      "[2172/8000] D loss: 0.4067, G loss: 4.9940\n",
      "[2532/8000] D loss: 0.7230, G loss: 5.2604\n",
      "[2892/8000] D loss: 0.9635, G loss: 1.9173\n",
      "[3252/8000] D loss: 0.8400, G loss: 3.1176\n",
      "[3612/8000] D loss: 0.6188, G loss: 3.8548\n",
      "[3972/8000] D loss: 0.7751, G loss: 3.9047\n",
      "[4332/8000] D loss: 0.9938, G loss: 3.8238\n",
      "[4692/8000] D loss: 0.7821, G loss: 4.2267\n",
      "[5052/8000] D loss: 0.8744, G loss: 2.4450\n",
      "[5412/8000] D loss: 0.9579, G loss: 2.8044\n",
      "[5772/8000] D loss: 0.7486, G loss: 2.0776\n",
      "[6132/8000] D loss: 0.9321, G loss: 3.0187\n",
      "[6492/8000] D loss: 0.9921, G loss: 3.0751\n",
      "[6852/8000] D loss: 1.0165, G loss: 2.7259\n",
      "[7212/8000] D loss: 0.6281, G loss: 6.5321\n",
      "[7572/8000] D loss: 0.9273, G loss: 2.6068\n",
      "[7932/8000] D loss: 0.7093, G loss: 4.2670\n",
      "train error: \n",
      " D loss: 0.777227, G loss: 4.074755, D accuracy: 76.9%, cell accuracy: 98.6%, board accuracy: 40.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.783576, G loss: 9.325317, D accuracy: 80.7%, cell accuracy: 98.1%, board accuracy: 21.3% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7520, G loss: 7.9534\n",
      "[372/8000] D loss: 0.9054, G loss: 3.3181\n",
      "[732/8000] D loss: 0.5236, G loss: 6.1623\n",
      "[1092/8000] D loss: 1.0969, G loss: 3.0387\n",
      "[1452/8000] D loss: 0.4641, G loss: 7.9115\n",
      "[1812/8000] D loss: 0.7925, G loss: 3.9208\n",
      "[2172/8000] D loss: 0.2703, G loss: 5.3478\n",
      "[2532/8000] D loss: 0.8312, G loss: 4.2923\n",
      "[2892/8000] D loss: 0.7615, G loss: 4.6696\n",
      "[3252/8000] D loss: 0.9395, G loss: 4.2029\n",
      "[3612/8000] D loss: 0.7889, G loss: 3.3182\n",
      "[3972/8000] D loss: 0.9568, G loss: 3.5656\n",
      "[4332/8000] D loss: 0.5577, G loss: 6.0126\n",
      "[4692/8000] D loss: 0.6583, G loss: 6.7392\n",
      "[5052/8000] D loss: 0.9920, G loss: 2.1995\n",
      "[5412/8000] D loss: 0.8737, G loss: 2.2770\n",
      "[5772/8000] D loss: 0.5335, G loss: 3.6398\n",
      "[6132/8000] D loss: 0.7623, G loss: 3.9529\n",
      "[6492/8000] D loss: 0.4271, G loss: 8.8895\n",
      "[6852/8000] D loss: 0.4277, G loss: 6.3957\n",
      "[7212/8000] D loss: 0.9300, G loss: 2.2645\n",
      "[7572/8000] D loss: 1.3044, G loss: 2.2591\n",
      "[7932/8000] D loss: 0.4544, G loss: 3.9730\n",
      "train error: \n",
      " D loss: 0.808911, G loss: 4.392789, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 41.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.794341, G loss: 9.621187, D accuracy: 78.7%, cell accuracy: 98.1%, board accuracy: 20.8% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7424, G loss: 5.2503\n",
      "[372/8000] D loss: 0.8187, G loss: 4.8790\n",
      "[732/8000] D loss: 0.8433, G loss: 2.8559\n",
      "[1092/8000] D loss: 0.5615, G loss: 5.8280\n",
      "[1452/8000] D loss: 0.4908, G loss: 5.7990\n",
      "[1812/8000] D loss: 0.5196, G loss: 5.6524\n",
      "[2172/8000] D loss: 0.7876, G loss: 2.4403\n",
      "[2532/8000] D loss: 0.3764, G loss: 5.9746\n",
      "[2892/8000] D loss: 0.5103, G loss: 6.1860\n",
      "[3252/8000] D loss: 0.6078, G loss: 4.6157\n",
      "[3612/8000] D loss: 0.9536, G loss: 3.4879\n",
      "[3972/8000] D loss: 0.6481, G loss: 4.3046\n",
      "[4332/8000] D loss: 0.6933, G loss: 4.5104\n",
      "[4692/8000] D loss: 0.4442, G loss: 4.7899\n",
      "[5052/8000] D loss: 0.6708, G loss: 3.4154\n",
      "[5412/8000] D loss: 0.9966, G loss: 3.1255\n",
      "[5772/8000] D loss: 0.8838, G loss: 4.0725\n",
      "[6132/8000] D loss: 0.9171, G loss: 3.5259\n",
      "[6492/8000] D loss: 1.1132, G loss: 2.5077\n",
      "[6852/8000] D loss: 0.7271, G loss: 3.5690\n",
      "[7212/8000] D loss: 0.7211, G loss: 3.1908\n",
      "[7572/8000] D loss: 0.3595, G loss: 8.0810\n",
      "[7932/8000] D loss: 1.1017, G loss: 2.8952\n",
      "train error: \n",
      " D loss: 0.804182, G loss: 3.739114, D accuracy: 76.3%, cell accuracy: 98.6%, board accuracy: 41.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.746972, G loss: 8.388642, D accuracy: 81.9%, cell accuracy: 98.1%, board accuracy: 20.3% \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5410, G loss: 5.6765\n",
      "[372/8000] D loss: 1.0585, G loss: 2.4694\n",
      "[732/8000] D loss: 0.9633, G loss: 2.0461\n",
      "[1092/8000] D loss: 0.6699, G loss: 4.4979\n",
      "[1452/8000] D loss: 0.4121, G loss: 4.2821\n",
      "[1812/8000] D loss: 1.0550, G loss: 3.3003\n",
      "[2172/8000] D loss: 0.9346, G loss: 2.1946\n",
      "[2532/8000] D loss: 0.5919, G loss: 5.0837\n",
      "[2892/8000] D loss: 0.8056, G loss: 2.1197\n",
      "[3252/8000] D loss: 0.9462, G loss: 2.9846\n",
      "[3612/8000] D loss: 0.8378, G loss: 4.7915\n",
      "[3972/8000] D loss: 1.0478, G loss: 2.4479\n",
      "[4332/8000] D loss: 1.0026, G loss: 8.9104\n",
      "[4692/8000] D loss: 0.7365, G loss: 3.2542\n",
      "[5052/8000] D loss: 0.5915, G loss: 3.1513\n",
      "[5412/8000] D loss: 0.7291, G loss: 4.9526\n",
      "[5772/8000] D loss: 0.7342, G loss: 4.5661\n",
      "[6132/8000] D loss: 0.9057, G loss: 3.5013\n",
      "[6492/8000] D loss: 0.8459, G loss: 4.1413\n",
      "[6852/8000] D loss: 0.7318, G loss: 4.4462\n",
      "[7212/8000] D loss: 0.5355, G loss: 6.4398\n",
      "[7572/8000] D loss: 0.7953, G loss: 3.2297\n",
      "[7932/8000] D loss: 0.5862, G loss: 7.1987\n",
      "train error: \n",
      " D loss: 0.784171, G loss: 3.791507, D accuracy: 77.1%, cell accuracy: 98.6%, board accuracy: 40.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.748694, G loss: 8.703738, D accuracy: 82.5%, cell accuracy: 98.1%, board accuracy: 20.6% \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7153, G loss: 5.2867\n",
      "[372/8000] D loss: 0.9258, G loss: 5.4338\n",
      "[732/8000] D loss: 0.6389, G loss: 3.0318\n",
      "[1092/8000] D loss: 1.0089, G loss: 3.9985\n",
      "[1452/8000] D loss: 0.7004, G loss: 5.1130\n",
      "[1812/8000] D loss: 0.8007, G loss: 4.5843\n",
      "[2172/8000] D loss: 0.7121, G loss: 5.8936\n",
      "[2532/8000] D loss: 0.8880, G loss: 7.0322\n",
      "[2892/8000] D loss: 0.6256, G loss: 4.2425\n",
      "[3252/8000] D loss: 0.9240, G loss: 4.1107\n",
      "[3612/8000] D loss: 0.7522, G loss: 5.2889\n",
      "[3972/8000] D loss: 0.7407, G loss: 4.3692\n",
      "[4332/8000] D loss: 0.5933, G loss: 2.4434\n",
      "[4692/8000] D loss: 0.8017, G loss: 4.7185\n",
      "[5052/8000] D loss: 0.7666, G loss: 4.4576\n",
      "[5412/8000] D loss: 0.7644, G loss: 3.2135\n",
      "[5772/8000] D loss: 0.8432, G loss: 2.8887\n",
      "[6132/8000] D loss: 0.8333, G loss: 5.5538\n",
      "[6492/8000] D loss: 0.7669, G loss: 3.7886\n",
      "[6852/8000] D loss: 0.6861, G loss: 6.3525\n",
      "[7212/8000] D loss: 0.7390, G loss: 4.8566\n",
      "[7572/8000] D loss: 0.9289, G loss: 2.2518\n",
      "[7932/8000] D loss: 0.7213, G loss: 5.9784\n",
      "train error: \n",
      " D loss: 0.785937, G loss: 4.247686, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 40.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.813784, G loss: 9.546288, D accuracy: 80.0%, cell accuracy: 98.1%, board accuracy: 21.2% \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7513, G loss: 2.8775\n",
      "[372/8000] D loss: 0.6347, G loss: 4.5048\n",
      "[732/8000] D loss: 1.0446, G loss: 2.3490\n",
      "[1092/8000] D loss: 0.5026, G loss: 2.7927\n",
      "[1452/8000] D loss: 0.4422, G loss: 5.3062\n",
      "[1812/8000] D loss: 0.9712, G loss: 3.6020\n",
      "[2172/8000] D loss: 0.8773, G loss: 2.5641\n",
      "[2532/8000] D loss: 0.9002, G loss: 3.4097\n",
      "[2892/8000] D loss: 0.7087, G loss: 3.4453\n",
      "[3252/8000] D loss: 0.6286, G loss: 6.8216\n",
      "[3612/8000] D loss: 0.7093, G loss: 4.2727\n",
      "[3972/8000] D loss: 0.5438, G loss: 3.4200\n",
      "[4332/8000] D loss: 0.5808, G loss: 4.3571\n",
      "[4692/8000] D loss: 0.5968, G loss: 4.1848\n",
      "[5052/8000] D loss: 0.5246, G loss: 5.3668\n",
      "[5412/8000] D loss: 0.8693, G loss: 3.3895\n",
      "[5772/8000] D loss: 0.4697, G loss: 5.2222\n",
      "[6132/8000] D loss: 0.4924, G loss: 5.9929\n",
      "[6492/8000] D loss: 0.8873, G loss: 4.3205\n",
      "[6852/8000] D loss: 0.7957, G loss: 5.2564\n",
      "[7212/8000] D loss: 0.4225, G loss: 7.6653\n",
      "[7572/8000] D loss: 0.7178, G loss: 3.2686\n",
      "[7932/8000] D loss: 0.9670, G loss: 3.4185\n",
      "train error: \n",
      " D loss: 0.784172, G loss: 4.565025, D accuracy: 76.6%, cell accuracy: 98.6%, board accuracy: 41.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.870256, G loss: 9.759662, D accuracy: 78.9%, cell accuracy: 98.1%, board accuracy: 20.9% \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9278, G loss: 5.3903\n",
      "[372/8000] D loss: 0.8507, G loss: 5.5269\n",
      "[732/8000] D loss: 0.9738, G loss: 2.9866\n",
      "[1092/8000] D loss: 0.9835, G loss: 4.2638\n",
      "[1452/8000] D loss: 0.7141, G loss: 2.5002\n",
      "[1812/8000] D loss: 0.6427, G loss: 3.5399\n",
      "[2172/8000] D loss: 0.8587, G loss: 5.9177\n",
      "[2532/8000] D loss: 0.6091, G loss: 5.5427\n",
      "[2892/8000] D loss: 0.7269, G loss: 4.6078\n",
      "[3252/8000] D loss: 0.7697, G loss: 4.7523\n",
      "[3612/8000] D loss: 0.5354, G loss: 4.8926\n",
      "[3972/8000] D loss: 0.6958, G loss: 5.8690\n",
      "[4332/8000] D loss: 0.8785, G loss: 3.4377\n",
      "[4692/8000] D loss: 0.7073, G loss: 4.8583\n",
      "[5052/8000] D loss: 0.7445, G loss: 4.5868\n",
      "[5412/8000] D loss: 0.7302, G loss: 4.2695\n",
      "[5772/8000] D loss: 0.8977, G loss: 4.8660\n",
      "[6132/8000] D loss: 0.7427, G loss: 3.8814\n",
      "[6492/8000] D loss: 0.8496, G loss: 3.8877\n",
      "[6852/8000] D loss: 1.1121, G loss: 3.9214\n",
      "[7212/8000] D loss: 0.8388, G loss: 2.7103\n",
      "[7572/8000] D loss: 0.4807, G loss: 4.0933\n",
      "[7932/8000] D loss: 0.8109, G loss: 3.9933\n",
      "train error: \n",
      " D loss: 0.801462, G loss: 3.920750, D accuracy: 76.5%, cell accuracy: 98.5%, board accuracy: 41.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.680305, G loss: 9.265450, D accuracy: 83.6%, cell accuracy: 98.1%, board accuracy: 20.3% \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9167, G loss: 2.8922\n",
      "[372/8000] D loss: 1.0681, G loss: 3.1692\n",
      "[732/8000] D loss: 0.8040, G loss: 5.2174\n",
      "[1092/8000] D loss: 0.6749, G loss: 4.5068\n",
      "[1452/8000] D loss: 0.5745, G loss: 3.9845\n",
      "[1812/8000] D loss: 1.0813, G loss: 3.5983\n",
      "[2172/8000] D loss: 0.4152, G loss: 5.7132\n",
      "[2532/8000] D loss: 0.8645, G loss: 1.5656\n",
      "[2892/8000] D loss: 0.6897, G loss: 7.1994\n",
      "[3252/8000] D loss: 1.0491, G loss: 2.2255\n",
      "[3612/8000] D loss: 0.7042, G loss: 2.4077\n",
      "[3972/8000] D loss: 0.8599, G loss: 3.8853\n",
      "[4332/8000] D loss: 0.7569, G loss: 4.7817\n",
      "[4692/8000] D loss: 0.9378, G loss: 2.7768\n",
      "[5052/8000] D loss: 0.5991, G loss: 5.0638\n",
      "[5412/8000] D loss: 0.6324, G loss: 5.1184\n",
      "[5772/8000] D loss: 0.7275, G loss: 5.1802\n",
      "[6132/8000] D loss: 0.6635, G loss: 4.6544\n",
      "[6492/8000] D loss: 0.5730, G loss: 6.0068\n",
      "[6852/8000] D loss: 0.7828, G loss: 4.6069\n",
      "[7212/8000] D loss: 0.5120, G loss: 6.5504\n",
      "[7572/8000] D loss: 0.8652, G loss: 4.3000\n",
      "[7932/8000] D loss: 0.6554, G loss: 3.7581\n",
      "train error: \n",
      " D loss: 0.827999, G loss: 3.621317, D accuracy: 76.2%, cell accuracy: 98.6%, board accuracy: 41.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.668061, G loss: 8.397936, D accuracy: 84.9%, cell accuracy: 98.1%, board accuracy: 21.1% \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7328, G loss: 2.2398\n",
      "[372/8000] D loss: 0.5509, G loss: 8.8669\n",
      "[732/8000] D loss: 0.4282, G loss: 5.2517\n",
      "[1092/8000] D loss: 0.9913, G loss: 3.7318\n",
      "[1452/8000] D loss: 0.8383, G loss: 3.1892\n",
      "[1812/8000] D loss: 0.7225, G loss: 4.6824\n",
      "[2172/8000] D loss: 0.8805, G loss: 3.4527\n",
      "[2532/8000] D loss: 1.0920, G loss: 2.6292\n",
      "[2892/8000] D loss: 0.7781, G loss: 3.6475\n",
      "[3252/8000] D loss: 0.8442, G loss: 5.4975\n",
      "[3612/8000] D loss: 0.7843, G loss: 7.0905\n",
      "[3972/8000] D loss: 1.0282, G loss: 5.6521\n",
      "[4332/8000] D loss: 0.7600, G loss: 3.3967\n",
      "[4692/8000] D loss: 0.8486, G loss: 3.6347\n",
      "[5052/8000] D loss: 0.5986, G loss: 4.7760\n",
      "[5412/8000] D loss: 0.4521, G loss: 5.7744\n",
      "[5772/8000] D loss: 1.0737, G loss: 4.0736\n",
      "[6132/8000] D loss: 0.9722, G loss: 3.9125\n",
      "[6492/8000] D loss: 0.6320, G loss: 7.2904\n",
      "[6852/8000] D loss: 0.7413, G loss: 5.0378\n",
      "[7212/8000] D loss: 0.8567, G loss: 3.0429\n",
      "[7572/8000] D loss: 0.7242, G loss: 2.7864\n",
      "[7932/8000] D loss: 1.0545, G loss: 2.2372\n",
      "train error: \n",
      " D loss: 0.824302, G loss: 4.120777, D accuracy: 75.7%, cell accuracy: 98.6%, board accuracy: 41.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.748735, G loss: 9.320939, D accuracy: 81.0%, cell accuracy: 98.1%, board accuracy: 21.1% \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4795, G loss: 4.6614\n",
      "[372/8000] D loss: 0.7369, G loss: 3.2530\n",
      "[732/8000] D loss: 0.6604, G loss: 4.4360\n",
      "[1092/8000] D loss: 1.1329, G loss: 1.2850\n",
      "[1452/8000] D loss: 0.7166, G loss: 3.5448\n",
      "[1812/8000] D loss: 0.7449, G loss: 5.2116\n",
      "[2172/8000] D loss: 0.8302, G loss: 3.2153\n",
      "[2532/8000] D loss: 0.9669, G loss: 2.7798\n",
      "[2892/8000] D loss: 0.8033, G loss: 3.0612\n",
      "[3252/8000] D loss: 0.7605, G loss: 3.7348\n",
      "[3612/8000] D loss: 0.5835, G loss: 4.7502\n",
      "[3972/8000] D loss: 1.0789, G loss: 1.6605\n",
      "[4332/8000] D loss: 0.9587, G loss: 2.4902\n",
      "[4692/8000] D loss: 0.9285, G loss: 2.9705\n",
      "[5052/8000] D loss: 0.8643, G loss: 2.9363\n",
      "[5412/8000] D loss: 1.1239, G loss: 2.3896\n",
      "[5772/8000] D loss: 0.5337, G loss: 5.3537\n",
      "[6132/8000] D loss: 0.9874, G loss: 1.6009\n",
      "[6492/8000] D loss: 0.6434, G loss: 5.4020\n",
      "[6852/8000] D loss: 0.8346, G loss: 3.8572\n",
      "[7212/8000] D loss: 1.0393, G loss: 2.2029\n",
      "[7572/8000] D loss: 0.9136, G loss: 1.7919\n",
      "[7932/8000] D loss: 0.9142, G loss: 2.6609\n",
      "train error: \n",
      " D loss: 0.785076, G loss: 3.912098, D accuracy: 76.5%, cell accuracy: 98.6%, board accuracy: 42.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.746168, G loss: 9.117483, D accuracy: 82.1%, cell accuracy: 98.2%, board accuracy: 21.3% \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8013, G loss: 5.8740\n",
      "[372/8000] D loss: 0.8174, G loss: 2.3981\n",
      "[732/8000] D loss: 0.7170, G loss: 5.2076\n",
      "[1092/8000] D loss: 0.7762, G loss: 5.7200\n",
      "[1452/8000] D loss: 0.6669, G loss: 5.8804\n",
      "[1812/8000] D loss: 0.9134, G loss: 3.4531\n",
      "[2172/8000] D loss: 0.7431, G loss: 2.1931\n",
      "[2532/8000] D loss: 1.0275, G loss: 2.2403\n",
      "[2892/8000] D loss: 0.6933, G loss: 1.9558\n",
      "[3252/8000] D loss: 0.7531, G loss: 4.2480\n",
      "[3612/8000] D loss: 0.7248, G loss: 4.9752\n",
      "[3972/8000] D loss: 1.0096, G loss: 3.6217\n",
      "[4332/8000] D loss: 0.7936, G loss: 7.3386\n",
      "[4692/8000] D loss: 0.9163, G loss: 3.3426\n",
      "[5052/8000] D loss: 1.1749, G loss: 1.9417\n",
      "[5412/8000] D loss: 0.7378, G loss: 3.1739\n",
      "[5772/8000] D loss: 0.4758, G loss: 5.0678\n",
      "[6132/8000] D loss: 0.8186, G loss: 4.4622\n",
      "[6492/8000] D loss: 0.7122, G loss: 6.4671\n",
      "[6852/8000] D loss: 0.6671, G loss: 7.3103\n",
      "[7212/8000] D loss: 0.4541, G loss: 6.0767\n",
      "[7572/8000] D loss: 0.8779, G loss: 2.3094\n",
      "[7932/8000] D loss: 0.8262, G loss: 4.4491\n",
      "train error: \n",
      " D loss: 0.804446, G loss: 3.292785, D accuracy: 76.2%, cell accuracy: 98.6%, board accuracy: 41.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.716055, G loss: 8.218980, D accuracy: 82.4%, cell accuracy: 98.1%, board accuracy: 20.5% \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9743, G loss: 2.6521\n",
      "[372/8000] D loss: 0.7158, G loss: 4.4248\n",
      "[732/8000] D loss: 0.8537, G loss: 3.6712\n",
      "[1092/8000] D loss: 1.1117, G loss: 2.0415\n",
      "[1452/8000] D loss: 0.7773, G loss: 4.5847\n",
      "[1812/8000] D loss: 0.9214, G loss: 3.0721\n",
      "[2172/8000] D loss: 0.4465, G loss: 4.1200\n",
      "[2532/8000] D loss: 0.9714, G loss: 2.9628\n",
      "[2892/8000] D loss: 0.8006, G loss: 2.5467\n",
      "[3252/8000] D loss: 0.6774, G loss: 4.2871\n",
      "[3612/8000] D loss: 0.8608, G loss: 6.2796\n",
      "[3972/8000] D loss: 0.4285, G loss: 7.3313\n",
      "[4332/8000] D loss: 0.4105, G loss: 6.6628\n",
      "[4692/8000] D loss: 0.8391, G loss: 3.3947\n",
      "[5052/8000] D loss: 0.7679, G loss: 2.7626\n",
      "[5412/8000] D loss: 0.6621, G loss: 7.7593\n",
      "[5772/8000] D loss: 0.4426, G loss: 6.0873\n",
      "[6132/8000] D loss: 0.4984, G loss: 7.6978\n",
      "[6492/8000] D loss: 0.4373, G loss: 6.5943\n",
      "[6852/8000] D loss: 0.5211, G loss: 6.8992\n",
      "[7212/8000] D loss: 0.9766, G loss: 3.5836\n",
      "[7572/8000] D loss: 0.7554, G loss: 6.0483\n",
      "[7932/8000] D loss: 0.4525, G loss: 4.0944\n",
      "train error: \n",
      " D loss: 0.769297, G loss: 4.676364, D accuracy: 77.3%, cell accuracy: 98.5%, board accuracy: 40.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.839438, G loss: 10.053822, D accuracy: 80.4%, cell accuracy: 98.1%, board accuracy: 19.4% \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7114, G loss: 5.6455\n",
      "[372/8000] D loss: 0.9482, G loss: 2.8029\n",
      "[732/8000] D loss: 1.0290, G loss: 2.4423\n",
      "[1092/8000] D loss: 0.5895, G loss: 3.7784\n",
      "[1452/8000] D loss: 0.7820, G loss: 3.0831\n",
      "[1812/8000] D loss: 0.7177, G loss: 3.7100\n",
      "[2172/8000] D loss: 1.1923, G loss: 2.6063\n",
      "[2532/8000] D loss: 0.9136, G loss: 1.9106\n",
      "[2892/8000] D loss: 1.0068, G loss: 2.7840\n",
      "[3252/8000] D loss: 1.2501, G loss: 2.4334\n",
      "[3612/8000] D loss: 0.8097, G loss: 8.1373\n",
      "[3972/8000] D loss: 0.6013, G loss: 5.1703\n",
      "[4332/8000] D loss: 0.2740, G loss: 6.1773\n",
      "[4692/8000] D loss: 0.5579, G loss: 3.5243\n",
      "[5052/8000] D loss: 0.5594, G loss: 6.6815\n",
      "[5412/8000] D loss: 0.8214, G loss: 5.2320\n",
      "[5772/8000] D loss: 0.7815, G loss: 4.8340\n",
      "[6132/8000] D loss: 0.7645, G loss: 6.8498\n",
      "[6492/8000] D loss: 0.9816, G loss: 5.0040\n",
      "[6852/8000] D loss: 0.5956, G loss: 5.0052\n",
      "[7212/8000] D loss: 0.8891, G loss: 4.0591\n",
      "[7572/8000] D loss: 0.4780, G loss: 7.6660\n",
      "[7932/8000] D loss: 0.9272, G loss: 1.6918\n",
      "train error: \n",
      " D loss: 0.782559, G loss: 4.236910, D accuracy: 76.7%, cell accuracy: 98.6%, board accuracy: 42.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.763018, G loss: 9.617077, D accuracy: 83.4%, cell accuracy: 98.2%, board accuracy: 20.1% \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5150, G loss: 5.2561\n",
      "[372/8000] D loss: 0.7643, G loss: 6.4786\n",
      "[732/8000] D loss: 0.7928, G loss: 3.5753\n",
      "[1092/8000] D loss: 0.5634, G loss: 5.8593\n",
      "[1452/8000] D loss: 0.8556, G loss: 4.0938\n",
      "[1812/8000] D loss: 0.8190, G loss: 2.8501\n",
      "[2172/8000] D loss: 0.7111, G loss: 4.2329\n",
      "[2532/8000] D loss: 0.8569, G loss: 3.3693\n",
      "[2892/8000] D loss: 0.7959, G loss: 2.1536\n",
      "[3252/8000] D loss: 0.6988, G loss: 8.2748\n",
      "[3612/8000] D loss: 0.7855, G loss: 4.6281\n",
      "[3972/8000] D loss: 0.8277, G loss: 4.2121\n",
      "[4332/8000] D loss: 0.8398, G loss: 3.8837\n",
      "[4692/8000] D loss: 0.8621, G loss: 3.6861\n",
      "[5052/8000] D loss: 0.8556, G loss: 5.0345\n",
      "[5412/8000] D loss: 0.5505, G loss: 4.9886\n",
      "[5772/8000] D loss: 0.6277, G loss: 4.4900\n",
      "[6132/8000] D loss: 0.5572, G loss: 4.4205\n",
      "[6492/8000] D loss: 0.8590, G loss: 3.5179\n",
      "[6852/8000] D loss: 0.3848, G loss: 5.5003\n",
      "[7212/8000] D loss: 1.0246, G loss: 2.6695\n",
      "[7572/8000] D loss: 0.9157, G loss: 2.6373\n",
      "[7932/8000] D loss: 0.7493, G loss: 5.4554\n",
      "train error: \n",
      " D loss: 0.826115, G loss: 3.421165, D accuracy: 75.7%, cell accuracy: 98.6%, board accuracy: 42.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.746295, G loss: 8.496492, D accuracy: 83.0%, cell accuracy: 98.2%, board accuracy: 21.7% \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6730, G loss: 3.7693\n",
      "[372/8000] D loss: 0.8974, G loss: 4.6038\n",
      "[732/8000] D loss: 0.9005, G loss: 3.0111\n",
      "[1092/8000] D loss: 0.5809, G loss: 6.5517\n",
      "[1452/8000] D loss: 0.7507, G loss: 4.9014\n",
      "[1812/8000] D loss: 0.6366, G loss: 3.6284\n",
      "[2172/8000] D loss: 0.7745, G loss: 2.9305\n",
      "[2532/8000] D loss: 0.8442, G loss: 6.3602\n",
      "[2892/8000] D loss: 0.5537, G loss: 5.8493\n",
      "[3252/8000] D loss: 0.6552, G loss: 4.1027\n",
      "[3612/8000] D loss: 0.7606, G loss: 4.8093\n",
      "[3972/8000] D loss: 0.4581, G loss: 4.5119\n",
      "[4332/8000] D loss: 0.8640, G loss: 3.2084\n",
      "[4692/8000] D loss: 0.7604, G loss: 5.7551\n",
      "[5052/8000] D loss: 0.8431, G loss: 3.2528\n",
      "[5412/8000] D loss: 0.6811, G loss: 4.0965\n",
      "[5772/8000] D loss: 0.8425, G loss: 3.8057\n",
      "[6132/8000] D loss: 0.9007, G loss: 3.8431\n",
      "[6492/8000] D loss: 0.8617, G loss: 4.0331\n",
      "[6852/8000] D loss: 0.7821, G loss: 4.0529\n",
      "[7212/8000] D loss: 0.4961, G loss: 5.2088\n",
      "[7572/8000] D loss: 0.7346, G loss: 7.3232\n",
      "[7932/8000] D loss: 0.8316, G loss: 2.9530\n",
      "train error: \n",
      " D loss: 0.805118, G loss: 3.405990, D accuracy: 76.3%, cell accuracy: 98.6%, board accuracy: 42.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.729891, G loss: 8.348222, D accuracy: 82.5%, cell accuracy: 98.1%, board accuracy: 22.1% \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8724, G loss: 2.3588\n",
      "[372/8000] D loss: 1.0173, G loss: 3.8555\n",
      "[732/8000] D loss: 0.5839, G loss: 4.6618\n",
      "[1092/8000] D loss: 1.1038, G loss: 3.6221\n",
      "[1452/8000] D loss: 0.8548, G loss: 5.4604\n",
      "[1812/8000] D loss: 0.7536, G loss: 4.3928\n",
      "[2172/8000] D loss: 0.6718, G loss: 6.4377\n",
      "[2532/8000] D loss: 0.5224, G loss: 8.3567\n",
      "[2892/8000] D loss: 0.7508, G loss: 4.2194\n",
      "[3252/8000] D loss: 0.9484, G loss: 1.7756\n",
      "[3612/8000] D loss: 0.6316, G loss: 5.2135\n",
      "[3972/8000] D loss: 0.9005, G loss: 2.8063\n",
      "[4332/8000] D loss: 0.9049, G loss: 3.9793\n",
      "[4692/8000] D loss: 0.6828, G loss: 3.2661\n",
      "[5052/8000] D loss: 0.5724, G loss: 6.6560\n",
      "[5412/8000] D loss: 0.5640, G loss: 4.9921\n",
      "[5772/8000] D loss: 0.6758, G loss: 5.0214\n",
      "[6132/8000] D loss: 0.6606, G loss: 5.9546\n",
      "[6492/8000] D loss: 0.6534, G loss: 5.5824\n",
      "[6852/8000] D loss: 0.6633, G loss: 4.5651\n",
      "[7212/8000] D loss: 0.3873, G loss: 6.2329\n",
      "[7572/8000] D loss: 0.8101, G loss: 2.6062\n",
      "[7932/8000] D loss: 1.1276, G loss: 1.6552\n",
      "train error: \n",
      " D loss: 0.742635, G loss: 4.402233, D accuracy: 78.2%, cell accuracy: 98.6%, board accuracy: 40.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.752592, G loss: 10.109859, D accuracy: 82.5%, cell accuracy: 98.1%, board accuracy: 18.6% \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8541, G loss: 3.3640\n",
      "[372/8000] D loss: 0.6290, G loss: 3.6087\n",
      "[732/8000] D loss: 0.7209, G loss: 3.8197\n",
      "[1092/8000] D loss: 0.7384, G loss: 5.2346\n",
      "[1452/8000] D loss: 0.8111, G loss: 6.8135\n",
      "[1812/8000] D loss: 0.7515, G loss: 4.6354\n",
      "[2172/8000] D loss: 0.6556, G loss: 2.9943\n",
      "[2532/8000] D loss: 0.6401, G loss: 5.4830\n",
      "[2892/8000] D loss: 0.5813, G loss: 7.6131\n",
      "[3252/8000] D loss: 1.2177, G loss: 2.3973\n",
      "[3612/8000] D loss: 0.6243, G loss: 5.6146\n",
      "[3972/8000] D loss: 0.6249, G loss: 5.9934\n",
      "[4332/8000] D loss: 0.5296, G loss: 6.6790\n",
      "[4692/8000] D loss: 1.0739, G loss: 2.4146\n",
      "[5052/8000] D loss: 0.7913, G loss: 3.4314\n",
      "[5412/8000] D loss: 0.8508, G loss: 2.9738\n",
      "[5772/8000] D loss: 0.4905, G loss: 3.4840\n",
      "[6132/8000] D loss: 0.6701, G loss: 2.9945\n",
      "[6492/8000] D loss: 0.5904, G loss: 5.7687\n",
      "[6852/8000] D loss: 1.1333, G loss: 2.4649\n",
      "[7212/8000] D loss: 1.0028, G loss: 4.3096\n",
      "[7572/8000] D loss: 0.9548, G loss: 2.5489\n",
      "[7932/8000] D loss: 0.7964, G loss: 1.7307\n",
      "train error: \n",
      " D loss: 0.763539, G loss: 4.734575, D accuracy: 78.0%, cell accuracy: 98.5%, board accuracy: 39.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.776324, G loss: 11.018268, D accuracy: 81.8%, cell accuracy: 98.1%, board accuracy: 19.2% \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7845, G loss: 4.1554\n",
      "[372/8000] D loss: 0.9832, G loss: 2.4707\n",
      "[732/8000] D loss: 0.9430, G loss: 2.7334\n",
      "[1092/8000] D loss: 0.7543, G loss: 3.4912\n",
      "[1452/8000] D loss: 0.5372, G loss: 4.8965\n",
      "[1812/8000] D loss: 0.7240, G loss: 3.3072\n",
      "[2172/8000] D loss: 0.7245, G loss: 3.8989\n",
      "[2532/8000] D loss: 0.5662, G loss: 6.4850\n",
      "[2892/8000] D loss: 0.9901, G loss: 2.1965\n",
      "[3252/8000] D loss: 0.6742, G loss: 2.5799\n",
      "[3612/8000] D loss: 0.4802, G loss: 4.7853\n",
      "[3972/8000] D loss: 0.5982, G loss: 3.6408\n",
      "[4332/8000] D loss: 0.7795, G loss: 5.3531\n",
      "[4692/8000] D loss: 0.8249, G loss: 4.9441\n",
      "[5052/8000] D loss: 0.8177, G loss: 5.0694\n",
      "[5412/8000] D loss: 0.8177, G loss: 4.3563\n",
      "[5772/8000] D loss: 0.9331, G loss: 7.0654\n",
      "[6132/8000] D loss: 0.7658, G loss: 6.7245\n",
      "[6492/8000] D loss: 0.6463, G loss: 4.3139\n",
      "[6852/8000] D loss: 0.8064, G loss: 2.4264\n",
      "[7212/8000] D loss: 0.7305, G loss: 4.4865\n",
      "[7572/8000] D loss: 0.6986, G loss: 7.9453\n",
      "[7932/8000] D loss: 0.5239, G loss: 5.5064\n",
      "train error: \n",
      " D loss: 0.786175, G loss: 3.692560, D accuracy: 76.8%, cell accuracy: 98.6%, board accuracy: 41.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.737120, G loss: 8.689496, D accuracy: 81.9%, cell accuracy: 98.2%, board accuracy: 21.2% \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7618, G loss: 4.6937\n",
      "[372/8000] D loss: 0.5850, G loss: 9.4785\n",
      "[732/8000] D loss: 0.7731, G loss: 3.3125\n",
      "[1092/8000] D loss: 0.7115, G loss: 3.3350\n",
      "[1452/8000] D loss: 0.5113, G loss: 6.7309\n",
      "[1812/8000] D loss: 0.7498, G loss: 4.5056\n",
      "[2172/8000] D loss: 0.7549, G loss: 6.4376\n",
      "[2532/8000] D loss: 0.7739, G loss: 5.3123\n",
      "[2892/8000] D loss: 0.6375, G loss: 4.0737\n",
      "[3252/8000] D loss: 0.8730, G loss: 2.8795\n",
      "[3612/8000] D loss: 0.7183, G loss: 5.3717\n",
      "[3972/8000] D loss: 0.5818, G loss: 7.9089\n",
      "[4332/8000] D loss: 0.9833, G loss: 4.0286\n",
      "[4692/8000] D loss: 0.9911, G loss: 3.9602\n",
      "[5052/8000] D loss: 0.8185, G loss: 4.3594\n",
      "[5412/8000] D loss: 0.3482, G loss: 8.8470\n",
      "[5772/8000] D loss: 0.7030, G loss: 5.7664\n",
      "[6132/8000] D loss: 0.7821, G loss: 4.2221\n",
      "[6492/8000] D loss: 0.8087, G loss: 4.1529\n",
      "[6852/8000] D loss: 0.8968, G loss: 4.8071\n",
      "[7212/8000] D loss: 1.0936, G loss: 2.8115\n",
      "[7572/8000] D loss: 0.6758, G loss: 5.0522\n",
      "[7932/8000] D loss: 0.8415, G loss: 5.4209\n",
      "train error: \n",
      " D loss: 0.777415, G loss: 4.127528, D accuracy: 76.8%, cell accuracy: 98.6%, board accuracy: 41.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.774974, G loss: 9.545074, D accuracy: 80.8%, cell accuracy: 98.1%, board accuracy: 20.4% \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5426, G loss: 3.9951\n",
      "[372/8000] D loss: 0.6543, G loss: 4.1370\n",
      "[732/8000] D loss: 0.6512, G loss: 3.2055\n",
      "[1092/8000] D loss: 0.6507, G loss: 4.5880\n",
      "[1452/8000] D loss: 1.0936, G loss: 1.9890\n",
      "[1812/8000] D loss: 0.9408, G loss: 4.4882\n",
      "[2172/8000] D loss: 0.8727, G loss: 1.7982\n",
      "[2532/8000] D loss: 0.7924, G loss: 3.9285\n",
      "[2892/8000] D loss: 0.8217, G loss: 3.5619\n",
      "[3252/8000] D loss: 0.5761, G loss: 5.8767\n",
      "[3612/8000] D loss: 0.8613, G loss: 3.0539\n",
      "[3972/8000] D loss: 1.1388, G loss: 1.1116\n",
      "[4332/8000] D loss: 0.5149, G loss: 5.8461\n",
      "[4692/8000] D loss: 0.7115, G loss: 6.6379\n",
      "[5052/8000] D loss: 0.9531, G loss: 3.0652\n",
      "[5412/8000] D loss: 1.3429, G loss: 2.4665\n",
      "[5772/8000] D loss: 0.8997, G loss: 2.0470\n",
      "[6132/8000] D loss: 0.8272, G loss: 3.1757\n",
      "[6492/8000] D loss: 0.3095, G loss: 7.1020\n",
      "[6852/8000] D loss: 0.9529, G loss: 4.3620\n",
      "[7212/8000] D loss: 0.7666, G loss: 4.2514\n",
      "[7572/8000] D loss: 0.4771, G loss: 5.2834\n",
      "[7932/8000] D loss: 0.6916, G loss: 3.9357\n",
      "train error: \n",
      " D loss: 0.843582, G loss: 4.308045, D accuracy: 74.3%, cell accuracy: 98.6%, board accuracy: 43.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.930663, G loss: 9.257456, D accuracy: 76.5%, cell accuracy: 98.2%, board accuracy: 21.8% \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6256, G loss: 3.4977\n",
      "[372/8000] D loss: 0.5319, G loss: 7.7198\n",
      "[732/8000] D loss: 0.7086, G loss: 3.4831\n",
      "[1092/8000] D loss: 0.8943, G loss: 2.1411\n",
      "[1452/8000] D loss: 0.8859, G loss: 2.5584\n",
      "[1812/8000] D loss: 0.6942, G loss: 3.4910\n",
      "[2172/8000] D loss: 0.7709, G loss: 2.9390\n",
      "[2532/8000] D loss: 1.0445, G loss: 2.0860\n",
      "[2892/8000] D loss: 0.9008, G loss: 3.4461\n",
      "[3252/8000] D loss: 0.5698, G loss: 6.7015\n",
      "[3612/8000] D loss: 0.9908, G loss: 2.4960\n",
      "[3972/8000] D loss: 0.5447, G loss: 6.3116\n",
      "[4332/8000] D loss: 0.7378, G loss: 3.6345\n",
      "[4692/8000] D loss: 0.8851, G loss: 4.1608\n",
      "[5052/8000] D loss: 0.7232, G loss: 5.6230\n",
      "[5412/8000] D loss: 0.7950, G loss: 4.8798\n",
      "[5772/8000] D loss: 0.8303, G loss: 5.0416\n",
      "[6132/8000] D loss: 0.7560, G loss: 4.9843\n",
      "[6492/8000] D loss: 0.9653, G loss: 3.4217\n",
      "[6852/8000] D loss: 0.8531, G loss: 5.4371\n",
      "[7212/8000] D loss: 0.7576, G loss: 2.2786\n",
      "[7572/8000] D loss: 0.6367, G loss: 4.9350\n",
      "[7932/8000] D loss: 0.3421, G loss: 6.3533\n",
      "train error: \n",
      " D loss: 0.784529, G loss: 4.719299, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 42.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.842615, G loss: 10.471382, D accuracy: 79.8%, cell accuracy: 98.1%, board accuracy: 21.1% \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8664, G loss: 3.6984\n",
      "[372/8000] D loss: 0.8099, G loss: 4.3513\n",
      "[732/8000] D loss: 0.6315, G loss: 6.3818\n",
      "[1092/8000] D loss: 0.5671, G loss: 5.1852\n",
      "[1452/8000] D loss: 0.5415, G loss: 5.2729\n",
      "[1812/8000] D loss: 0.8184, G loss: 4.7059\n",
      "[2172/8000] D loss: 0.7497, G loss: 3.1609\n",
      "[2532/8000] D loss: 0.5286, G loss: 3.9585\n",
      "[2892/8000] D loss: 0.8680, G loss: 6.5580\n",
      "[3252/8000] D loss: 0.8078, G loss: 3.8376\n",
      "[3612/8000] D loss: 0.4043, G loss: 5.1147\n",
      "[3972/8000] D loss: 0.8299, G loss: 4.6306\n",
      "[4332/8000] D loss: 0.6041, G loss: 3.0173\n",
      "[4692/8000] D loss: 0.8165, G loss: 3.5257\n",
      "[5052/8000] D loss: 0.9327, G loss: 4.0881\n",
      "[5412/8000] D loss: 1.1093, G loss: 1.0341\n",
      "[5772/8000] D loss: 1.0717, G loss: 2.7398\n",
      "[6132/8000] D loss: 0.6475, G loss: 3.5196\n",
      "[6492/8000] D loss: 0.6560, G loss: 6.6835\n",
      "[6852/8000] D loss: 1.1873, G loss: 1.7925\n",
      "[7212/8000] D loss: 0.8843, G loss: 4.6030\n",
      "[7572/8000] D loss: 0.5334, G loss: 4.2835\n",
      "[7932/8000] D loss: 0.8373, G loss: 3.0720\n",
      "train error: \n",
      " D loss: 0.863330, G loss: 3.654858, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 42.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.663422, G loss: 8.844168, D accuracy: 84.8%, cell accuracy: 98.2%, board accuracy: 21.7% \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4149, G loss: 5.5384\n",
      "[372/8000] D loss: 0.4089, G loss: 9.0458\n",
      "[732/8000] D loss: 0.9158, G loss: 3.3092\n",
      "[1092/8000] D loss: 0.8158, G loss: 3.3308\n",
      "[1452/8000] D loss: 0.8853, G loss: 3.0700\n",
      "[1812/8000] D loss: 0.4867, G loss: 9.2469\n",
      "[2172/8000] D loss: 0.9149, G loss: 2.7853\n",
      "[2532/8000] D loss: 1.0774, G loss: 3.1310\n",
      "[2892/8000] D loss: 0.7440, G loss: 4.0725\n",
      "[3252/8000] D loss: 1.0401, G loss: 2.5857\n",
      "[3612/8000] D loss: 0.9084, G loss: 3.4986\n",
      "[3972/8000] D loss: 0.6460, G loss: 5.8759\n",
      "[4332/8000] D loss: 0.6213, G loss: 5.5667\n",
      "[4692/8000] D loss: 0.7508, G loss: 3.4853\n",
      "[5052/8000] D loss: 0.7158, G loss: 4.5080\n",
      "[5412/8000] D loss: 0.7553, G loss: 6.1737\n",
      "[5772/8000] D loss: 0.7940, G loss: 6.1104\n",
      "[6132/8000] D loss: 0.5887, G loss: 4.9696\n",
      "[6492/8000] D loss: 0.6803, G loss: 3.2600\n",
      "[6852/8000] D loss: 0.7867, G loss: 6.0744\n",
      "[7212/8000] D loss: 0.6513, G loss: 3.8538\n",
      "[7572/8000] D loss: 0.8236, G loss: 5.0331\n",
      "[7932/8000] D loss: 0.7246, G loss: 3.1668\n",
      "train error: \n",
      " D loss: 0.788039, G loss: 4.353257, D accuracy: 76.3%, cell accuracy: 98.6%, board accuracy: 43.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.807796, G loss: 9.923419, D accuracy: 79.9%, cell accuracy: 98.2%, board accuracy: 22.1% \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9323, G loss: 2.5456\n",
      "[372/8000] D loss: 0.6971, G loss: 3.6982\n",
      "[732/8000] D loss: 1.0150, G loss: 2.5259\n",
      "[1092/8000] D loss: 0.7146, G loss: 6.1823\n",
      "[1452/8000] D loss: 0.6909, G loss: 3.2588\n",
      "[1812/8000] D loss: 0.6269, G loss: 6.8895\n",
      "[2172/8000] D loss: 0.6479, G loss: 3.1459\n",
      "[2532/8000] D loss: 0.8205, G loss: 3.3762\n",
      "[2892/8000] D loss: 0.4616, G loss: 5.2246\n",
      "[3252/8000] D loss: 1.2540, G loss: 1.6941\n",
      "[3612/8000] D loss: 0.9809, G loss: 2.6253\n",
      "[3972/8000] D loss: 0.9870, G loss: 2.8170\n",
      "[4332/8000] D loss: 0.6754, G loss: 4.1570\n",
      "[4692/8000] D loss: 1.0929, G loss: 3.3702\n",
      "[5052/8000] D loss: 0.3061, G loss: 5.9979\n",
      "[5412/8000] D loss: 0.5754, G loss: 4.6530\n",
      "[5772/8000] D loss: 0.7930, G loss: 2.5745\n",
      "[6132/8000] D loss: 0.6180, G loss: 4.7559\n",
      "[6492/8000] D loss: 0.7255, G loss: 2.6642\n",
      "[6852/8000] D loss: 0.6359, G loss: 2.7290\n",
      "[7212/8000] D loss: 0.4922, G loss: 4.7237\n",
      "[7572/8000] D loss: 0.6328, G loss: 6.2711\n",
      "[7932/8000] D loss: 0.5590, G loss: 6.9251\n",
      "train error: \n",
      " D loss: 0.823647, G loss: 3.614912, D accuracy: 76.0%, cell accuracy: 98.5%, board accuracy: 42.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.748092, G loss: 9.065389, D accuracy: 83.6%, cell accuracy: 98.1%, board accuracy: 21.1% \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2011, G loss: 8.3509\n",
      "[372/8000] D loss: 0.6820, G loss: 2.4014\n",
      "[732/8000] D loss: 0.5666, G loss: 6.8272\n",
      "[1092/8000] D loss: 0.7993, G loss: 3.2243\n",
      "[1452/8000] D loss: 0.6881, G loss: 4.8485\n",
      "[1812/8000] D loss: 0.7609, G loss: 3.2906\n",
      "[2172/8000] D loss: 0.4616, G loss: 5.9138\n",
      "[2532/8000] D loss: 0.4535, G loss: 6.8163\n",
      "[2892/8000] D loss: 0.3534, G loss: 5.0575\n",
      "[3252/8000] D loss: 0.8507, G loss: 3.4142\n",
      "[3612/8000] D loss: 0.8463, G loss: 8.6073\n",
      "[3972/8000] D loss: 0.7443, G loss: 6.0163\n",
      "[4332/8000] D loss: 0.6844, G loss: 6.0666\n",
      "[4692/8000] D loss: 0.9194, G loss: 4.3309\n",
      "[5052/8000] D loss: 0.9862, G loss: 3.6900\n",
      "[5412/8000] D loss: 0.8172, G loss: 2.6931\n",
      "[5772/8000] D loss: 1.1742, G loss: 2.7425\n",
      "[6132/8000] D loss: 1.0329, G loss: 4.1794\n",
      "[6492/8000] D loss: 0.8923, G loss: 5.4117\n",
      "[6852/8000] D loss: 0.8294, G loss: 2.9954\n",
      "[7212/8000] D loss: 0.8330, G loss: 3.2842\n",
      "[7572/8000] D loss: 0.6461, G loss: 8.4964\n",
      "[7932/8000] D loss: 1.0449, G loss: 3.6019\n",
      "train error: \n",
      " D loss: 0.802466, G loss: 3.926593, D accuracy: 76.5%, cell accuracy: 98.6%, board accuracy: 41.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.710125, G loss: 9.686915, D accuracy: 83.9%, cell accuracy: 98.1%, board accuracy: 21.1% \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8262, G loss: 3.4233\n",
      "[372/8000] D loss: 0.7457, G loss: 2.2864\n",
      "[732/8000] D loss: 0.5245, G loss: 6.8459\n",
      "[1092/8000] D loss: 0.8845, G loss: 8.5887\n",
      "[1452/8000] D loss: 0.6488, G loss: 6.7713\n",
      "[1812/8000] D loss: 0.5648, G loss: 2.0188\n",
      "[2172/8000] D loss: 0.7218, G loss: 3.9881\n",
      "[2532/8000] D loss: 0.6668, G loss: 3.6558\n",
      "[2892/8000] D loss: 0.3433, G loss: 9.5123\n",
      "[3252/8000] D loss: 0.8019, G loss: 3.9100\n",
      "[3612/8000] D loss: 0.6524, G loss: 5.2129\n",
      "[3972/8000] D loss: 0.5748, G loss: 4.9303\n",
      "[4332/8000] D loss: 1.0331, G loss: 2.2681\n",
      "[4692/8000] D loss: 1.1148, G loss: 2.1985\n",
      "[5052/8000] D loss: 0.6228, G loss: 3.8883\n",
      "[5412/8000] D loss: 0.6801, G loss: 4.9030\n",
      "[5772/8000] D loss: 0.9223, G loss: 4.2162\n",
      "[6132/8000] D loss: 0.8902, G loss: 2.7843\n",
      "[6492/8000] D loss: 0.6898, G loss: 6.4896\n",
      "[6852/8000] D loss: 0.6710, G loss: 3.3495\n",
      "[7212/8000] D loss: 0.7593, G loss: 2.5232\n",
      "[7572/8000] D loss: 0.4659, G loss: 4.1710\n",
      "[7932/8000] D loss: 0.9909, G loss: 2.2808\n",
      "train error: \n",
      " D loss: 0.773435, G loss: 4.679060, D accuracy: 76.9%, cell accuracy: 98.5%, board accuracy: 42.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.858533, G loss: 10.524571, D accuracy: 79.8%, cell accuracy: 98.1%, board accuracy: 21.7% \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7988, G loss: 5.1235\n",
      "[372/8000] D loss: 1.1262, G loss: 1.7567\n",
      "[732/8000] D loss: 0.5325, G loss: 8.7689\n",
      "[1092/8000] D loss: 0.2874, G loss: 6.8860\n",
      "[1452/8000] D loss: 0.7031, G loss: 4.4241\n",
      "[1812/8000] D loss: 1.0061, G loss: 3.8617\n",
      "[2172/8000] D loss: 0.7746, G loss: 2.8957\n",
      "[2532/8000] D loss: 0.7259, G loss: 3.2705\n",
      "[2892/8000] D loss: 0.6895, G loss: 2.3749\n",
      "[3252/8000] D loss: 0.7076, G loss: 4.8915\n",
      "[3612/8000] D loss: 1.0197, G loss: 2.0892\n",
      "[3972/8000] D loss: 0.9684, G loss: 3.4207\n",
      "[4332/8000] D loss: 1.2026, G loss: 4.9922\n",
      "[4692/8000] D loss: 0.6236, G loss: 5.7262\n",
      "[5052/8000] D loss: 1.0908, G loss: 4.5634\n",
      "[5412/8000] D loss: 0.8667, G loss: 2.7344\n",
      "[5772/8000] D loss: 0.9098, G loss: 2.8297\n",
      "[6132/8000] D loss: 0.6939, G loss: 2.7962\n",
      "[6492/8000] D loss: 0.9963, G loss: 6.6124\n",
      "[6852/8000] D loss: 0.7762, G loss: 4.9013\n",
      "[7212/8000] D loss: 0.6057, G loss: 2.8195\n",
      "[7572/8000] D loss: 0.6790, G loss: 7.2057\n",
      "[7932/8000] D loss: 0.7292, G loss: 2.9573\n",
      "train error: \n",
      " D loss: 0.791846, G loss: 4.365519, D accuracy: 76.8%, cell accuracy: 98.6%, board accuracy: 41.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.836152, G loss: 10.050967, D accuracy: 80.5%, cell accuracy: 98.1%, board accuracy: 20.8% \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0635, G loss: 3.3657\n",
      "[372/8000] D loss: 0.9793, G loss: 3.5498\n",
      "[732/8000] D loss: 0.7100, G loss: 5.9579\n",
      "[1092/8000] D loss: 0.8045, G loss: 5.8207\n",
      "[1452/8000] D loss: 0.7391, G loss: 5.2566\n",
      "[1812/8000] D loss: 0.9084, G loss: 4.5966\n",
      "[2172/8000] D loss: 1.2698, G loss: 1.0067\n",
      "[2532/8000] D loss: 0.9802, G loss: 4.1925\n",
      "[2892/8000] D loss: 0.9427, G loss: 3.8259\n",
      "[3252/8000] D loss: 0.9893, G loss: 4.4440\n",
      "[3612/8000] D loss: 0.8605, G loss: 1.8993\n",
      "[3972/8000] D loss: 0.5519, G loss: 6.2326\n",
      "[4332/8000] D loss: 0.5952, G loss: 6.4528\n",
      "[4692/8000] D loss: 0.8686, G loss: 4.9234\n",
      "[5052/8000] D loss: 1.2905, G loss: 1.0689\n",
      "[5412/8000] D loss: 1.1657, G loss: 1.3036\n",
      "[5772/8000] D loss: 1.0956, G loss: 5.5026\n",
      "[6132/8000] D loss: 0.6474, G loss: 4.4826\n",
      "[6492/8000] D loss: 0.6108, G loss: 5.7354\n",
      "[6852/8000] D loss: 0.9330, G loss: 1.6461\n",
      "[7212/8000] D loss: 0.8696, G loss: 3.3206\n",
      "[7572/8000] D loss: 0.8775, G loss: 6.2178\n",
      "[7932/8000] D loss: 0.6950, G loss: 4.9997\n",
      "train error: \n",
      " D loss: 0.820771, G loss: 4.081888, D accuracy: 75.5%, cell accuracy: 98.6%, board accuracy: 43.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.861833, G loss: 9.473694, D accuracy: 81.3%, cell accuracy: 98.1%, board accuracy: 21.3% \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9884, G loss: 2.6020\n",
      "[372/8000] D loss: 0.6607, G loss: 3.9126\n",
      "[732/8000] D loss: 0.9099, G loss: 2.8371\n",
      "[1092/8000] D loss: 0.6583, G loss: 4.4826\n",
      "[1452/8000] D loss: 0.5526, G loss: 3.6480\n",
      "[1812/8000] D loss: 0.9951, G loss: 1.9421\n",
      "[2172/8000] D loss: 0.8900, G loss: 3.6540\n",
      "[2532/8000] D loss: 0.9208, G loss: 2.3151\n",
      "[2892/8000] D loss: 0.6900, G loss: 5.4053\n",
      "[3252/8000] D loss: 1.1735, G loss: 1.8587\n",
      "[3612/8000] D loss: 0.8043, G loss: 2.7269\n",
      "[3972/8000] D loss: 0.6954, G loss: 3.4807\n",
      "[4332/8000] D loss: 0.8271, G loss: 4.1507\n",
      "[4692/8000] D loss: 0.5530, G loss: 5.3816\n",
      "[5052/8000] D loss: 0.6384, G loss: 6.6808\n",
      "[5412/8000] D loss: 0.6568, G loss: 3.5619\n",
      "[5772/8000] D loss: 1.2831, G loss: 2.8321\n",
      "[6132/8000] D loss: 0.8287, G loss: 4.9363\n",
      "[6492/8000] D loss: 0.8870, G loss: 2.9251\n",
      "[6852/8000] D loss: 0.9638, G loss: 2.9847\n",
      "[7212/8000] D loss: 0.6347, G loss: 4.2149\n",
      "[7572/8000] D loss: 0.6607, G loss: 7.8214\n",
      "[7932/8000] D loss: 0.8574, G loss: 2.5158\n",
      "train error: \n",
      " D loss: 0.787753, G loss: 4.151947, D accuracy: 76.6%, cell accuracy: 98.6%, board accuracy: 44.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.802334, G loss: 9.795153, D accuracy: 81.1%, cell accuracy: 98.1%, board accuracy: 23.4% \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7477, G loss: 2.6546\n",
      "[372/8000] D loss: 1.0651, G loss: 3.3743\n",
      "[732/8000] D loss: 0.5431, G loss: 6.9703\n",
      "[1092/8000] D loss: 0.7311, G loss: 4.9801\n",
      "[1452/8000] D loss: 0.9551, G loss: 1.8020\n",
      "[1812/8000] D loss: 0.7526, G loss: 4.4003\n",
      "[2172/8000] D loss: 1.0628, G loss: 2.0509\n",
      "[2532/8000] D loss: 0.4029, G loss: 7.9601\n",
      "[2892/8000] D loss: 1.0384, G loss: 1.7513\n",
      "[3252/8000] D loss: 0.4811, G loss: 6.9968\n",
      "[3612/8000] D loss: 0.6570, G loss: 4.8171\n",
      "[3972/8000] D loss: 0.4652, G loss: 6.7467\n",
      "[4332/8000] D loss: 0.8007, G loss: 3.0424\n",
      "[4692/8000] D loss: 0.7610, G loss: 3.6578\n",
      "[5052/8000] D loss: 0.8974, G loss: 6.4211\n",
      "[5412/8000] D loss: 0.6649, G loss: 3.6505\n",
      "[5772/8000] D loss: 0.9254, G loss: 2.3736\n",
      "[6132/8000] D loss: 0.9890, G loss: 3.1603\n",
      "[6492/8000] D loss: 0.8068, G loss: 7.9602\n",
      "[6852/8000] D loss: 1.1558, G loss: 3.6235\n",
      "[7212/8000] D loss: 0.6424, G loss: 4.3895\n",
      "[7572/8000] D loss: 0.3548, G loss: 7.2570\n",
      "[7932/8000] D loss: 1.1307, G loss: 2.0197\n",
      "train error: \n",
      " D loss: 0.798144, G loss: 4.844623, D accuracy: 75.4%, cell accuracy: 98.6%, board accuracy: 44.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.939212, G loss: 10.698476, D accuracy: 77.1%, cell accuracy: 98.1%, board accuracy: 21.4% \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5859, G loss: 6.1558\n",
      "[372/8000] D loss: 0.8715, G loss: 4.9489\n",
      "[732/8000] D loss: 0.7747, G loss: 4.4062\n",
      "[1092/8000] D loss: 0.6752, G loss: 5.1357\n",
      "[1452/8000] D loss: 0.7755, G loss: 2.0279\n",
      "[1812/8000] D loss: 0.9169, G loss: 2.0744\n",
      "[2172/8000] D loss: 1.1501, G loss: 3.1071\n",
      "[2532/8000] D loss: 0.3645, G loss: 7.3238\n",
      "[2892/8000] D loss: 0.4950, G loss: 4.6170\n",
      "[3252/8000] D loss: 0.5840, G loss: 5.8724\n",
      "[3612/8000] D loss: 0.7705, G loss: 3.6390\n",
      "[3972/8000] D loss: 0.8908, G loss: 2.9021\n",
      "[4332/8000] D loss: 0.6201, G loss: 5.6848\n",
      "[4692/8000] D loss: 0.8983, G loss: 1.9214\n",
      "[5052/8000] D loss: 0.7305, G loss: 5.1348\n",
      "[5412/8000] D loss: 0.7493, G loss: 3.2647\n",
      "[5772/8000] D loss: 0.7995, G loss: 4.0994\n",
      "[6132/8000] D loss: 1.0082, G loss: 2.9225\n",
      "[6492/8000] D loss: 0.3170, G loss: 7.5779\n",
      "[6852/8000] D loss: 0.8477, G loss: 3.1851\n",
      "[7212/8000] D loss: 0.8986, G loss: 2.2482\n",
      "[7572/8000] D loss: 0.6743, G loss: 6.4530\n",
      "[7932/8000] D loss: 0.6735, G loss: 5.0334\n",
      "train error: \n",
      " D loss: 0.804429, G loss: 4.705567, D accuracy: 75.8%, cell accuracy: 98.6%, board accuracy: 44.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.802689, G loss: 10.839120, D accuracy: 80.6%, cell accuracy: 98.1%, board accuracy: 22.5% \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8735, G loss: 5.4526\n",
      "[372/8000] D loss: 0.7682, G loss: 3.4370\n",
      "[732/8000] D loss: 1.1060, G loss: 1.9710\n",
      "[1092/8000] D loss: 0.5079, G loss: 6.4510\n",
      "[1452/8000] D loss: 0.8945, G loss: 2.4916\n",
      "[1812/8000] D loss: 0.9637, G loss: 1.1643\n",
      "[2172/8000] D loss: 0.8500, G loss: 3.1488\n",
      "[2532/8000] D loss: 0.8330, G loss: 2.9623\n",
      "[2892/8000] D loss: 0.6237, G loss: 3.2415\n",
      "[3252/8000] D loss: 1.0462, G loss: 2.0427\n",
      "[3612/8000] D loss: 0.9528, G loss: 3.5874\n",
      "[3972/8000] D loss: 0.5304, G loss: 3.8283\n",
      "[4332/8000] D loss: 0.5018, G loss: 7.7215\n",
      "[4692/8000] D loss: 0.7044, G loss: 5.6776\n",
      "[5052/8000] D loss: 0.6194, G loss: 6.1746\n",
      "[5412/8000] D loss: 0.7558, G loss: 4.4510\n",
      "[5772/8000] D loss: 0.6769, G loss: 4.4235\n",
      "[6132/8000] D loss: 0.6962, G loss: 4.9603\n",
      "[6492/8000] D loss: 1.0256, G loss: 3.6788\n",
      "[6852/8000] D loss: 0.9216, G loss: 2.8634\n",
      "[7212/8000] D loss: 0.5801, G loss: 2.6260\n",
      "[7572/8000] D loss: 0.8412, G loss: 3.9954\n",
      "[7932/8000] D loss: 0.8693, G loss: 3.6176\n",
      "train error: \n",
      " D loss: 0.796310, G loss: 3.879577, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 43.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.831635, G loss: 9.207781, D accuracy: 78.9%, cell accuracy: 98.1%, board accuracy: 21.5% \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4287, G loss: 4.9771\n",
      "[372/8000] D loss: 0.5802, G loss: 8.7818\n",
      "[732/8000] D loss: 0.8425, G loss: 2.7958\n",
      "[1092/8000] D loss: 1.4764, G loss: 2.6683\n",
      "[1452/8000] D loss: 0.8370, G loss: 5.7045\n",
      "[1812/8000] D loss: 0.9599, G loss: 2.6977\n",
      "[2172/8000] D loss: 0.3641, G loss: 4.2637\n",
      "[2532/8000] D loss: 0.6978, G loss: 3.7811\n",
      "[2892/8000] D loss: 0.7132, G loss: 4.6916\n",
      "[3252/8000] D loss: 0.9323, G loss: 4.6033\n",
      "[3612/8000] D loss: 0.5951, G loss: 3.7180\n",
      "[3972/8000] D loss: 0.8580, G loss: 3.2172\n",
      "[4332/8000] D loss: 0.4444, G loss: 9.6904\n",
      "[4692/8000] D loss: 0.6463, G loss: 4.4703\n",
      "[5052/8000] D loss: 0.7563, G loss: 4.2172\n",
      "[5412/8000] D loss: 0.8904, G loss: 2.1390\n",
      "[5772/8000] D loss: 0.5785, G loss: 5.3381\n",
      "[6132/8000] D loss: 0.5660, G loss: 6.5139\n",
      "[6492/8000] D loss: 0.4740, G loss: 6.1320\n",
      "[6852/8000] D loss: 0.5858, G loss: 5.9680\n",
      "[7212/8000] D loss: 0.8604, G loss: 3.7995\n",
      "[7572/8000] D loss: 0.6469, G loss: 5.8586\n",
      "[7932/8000] D loss: 0.6561, G loss: 3.0160\n",
      "train error: \n",
      " D loss: 0.888525, G loss: 4.829814, D accuracy: 73.9%, cell accuracy: 98.5%, board accuracy: 43.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.980806, G loss: 10.138820, D accuracy: 75.1%, cell accuracy: 98.1%, board accuracy: 22.1% \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6968, G loss: 8.4456\n",
      "[372/8000] D loss: 0.8658, G loss: 4.0654\n",
      "[732/8000] D loss: 0.9886, G loss: 2.5403\n",
      "[1092/8000] D loss: 0.3326, G loss: 6.7710\n",
      "[1452/8000] D loss: 0.4614, G loss: 5.5857\n",
      "[1812/8000] D loss: 1.0216, G loss: 3.0390\n",
      "[2172/8000] D loss: 0.5479, G loss: 4.4778\n",
      "[2532/8000] D loss: 0.9763, G loss: 2.6604\n",
      "[2892/8000] D loss: 0.6193, G loss: 4.8012\n",
      "[3252/8000] D loss: 1.0314, G loss: 1.9128\n",
      "[3612/8000] D loss: 0.8665, G loss: 4.0894\n",
      "[3972/8000] D loss: 1.0202, G loss: 3.0221\n",
      "[4332/8000] D loss: 0.8464, G loss: 5.8952\n",
      "[4692/8000] D loss: 0.5445, G loss: 4.5591\n",
      "[5052/8000] D loss: 1.0763, G loss: 2.1422\n",
      "[5412/8000] D loss: 0.8841, G loss: 4.0272\n",
      "[5772/8000] D loss: 0.9547, G loss: 2.7945\n",
      "[6132/8000] D loss: 0.7453, G loss: 3.8380\n",
      "[6492/8000] D loss: 0.5545, G loss: 5.6672\n",
      "[6852/8000] D loss: 0.7664, G loss: 2.7434\n",
      "[7212/8000] D loss: 0.7789, G loss: 8.5323\n",
      "[7572/8000] D loss: 0.9539, G loss: 7.1331\n",
      "[7932/8000] D loss: 0.5420, G loss: 5.6070\n",
      "train error: \n",
      " D loss: 0.792880, G loss: 4.041541, D accuracy: 77.0%, cell accuracy: 98.5%, board accuracy: 41.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.726861, G loss: 9.534472, D accuracy: 84.4%, cell accuracy: 98.0%, board accuracy: 19.8% \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6959, G loss: 4.8759\n",
      "[372/8000] D loss: 0.8600, G loss: 4.4501\n",
      "[732/8000] D loss: 0.9091, G loss: 3.2216\n",
      "[1092/8000] D loss: 0.9923, G loss: 3.8299\n",
      "[1452/8000] D loss: 0.3964, G loss: 6.7356\n",
      "[1812/8000] D loss: 0.5928, G loss: 6.3742\n",
      "[2172/8000] D loss: 0.9794, G loss: 1.9774\n",
      "[2532/8000] D loss: 0.5106, G loss: 7.9843\n",
      "[2892/8000] D loss: 0.5135, G loss: 6.1094\n",
      "[3252/8000] D loss: 0.6173, G loss: 2.7456\n",
      "[3612/8000] D loss: 0.8452, G loss: 3.4568\n",
      "[3972/8000] D loss: 0.9246, G loss: 4.1385\n",
      "[4332/8000] D loss: 0.9028, G loss: 3.8384\n",
      "[4692/8000] D loss: 0.6504, G loss: 3.7011\n",
      "[5052/8000] D loss: 0.6851, G loss: 4.8351\n",
      "[5412/8000] D loss: 0.6014, G loss: 6.1260\n",
      "[5772/8000] D loss: 0.7495, G loss: 3.5984\n",
      "[6132/8000] D loss: 0.9240, G loss: 4.4967\n",
      "[6492/8000] D loss: 0.7417, G loss: 4.9413\n",
      "[6852/8000] D loss: 0.8632, G loss: 3.2125\n",
      "[7212/8000] D loss: 0.9692, G loss: 4.3710\n",
      "[7572/8000] D loss: 0.5238, G loss: 5.8895\n",
      "[7932/8000] D loss: 0.9689, G loss: 2.9200\n",
      "train error: \n",
      " D loss: 0.810931, G loss: 3.805649, D accuracy: 76.2%, cell accuracy: 98.6%, board accuracy: 44.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.762791, G loss: 9.223395, D accuracy: 82.6%, cell accuracy: 98.1%, board accuracy: 21.1% \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6403, G loss: 2.9287\n",
      "[372/8000] D loss: 1.0292, G loss: 3.8962\n",
      "[732/8000] D loss: 0.7613, G loss: 3.1512\n",
      "[1092/8000] D loss: 0.5299, G loss: 7.3488\n",
      "[1452/8000] D loss: 0.4741, G loss: 5.5530\n",
      "[1812/8000] D loss: 0.6854, G loss: 5.2672\n",
      "[2172/8000] D loss: 0.4028, G loss: 8.0834\n",
      "[2532/8000] D loss: 0.9049, G loss: 4.1693\n",
      "[2892/8000] D loss: 0.8907, G loss: 2.4771\n",
      "[3252/8000] D loss: 0.5845, G loss: 4.2914\n",
      "[3612/8000] D loss: 0.7651, G loss: 4.7118\n",
      "[3972/8000] D loss: 0.6637, G loss: 4.1964\n",
      "[4332/8000] D loss: 0.7602, G loss: 3.9564\n",
      "[4692/8000] D loss: 0.4407, G loss: 6.8781\n",
      "[5052/8000] D loss: 0.6282, G loss: 5.3097\n",
      "[5412/8000] D loss: 1.1907, G loss: 3.6713\n",
      "[5772/8000] D loss: 0.7809, G loss: 3.4829\n",
      "[6132/8000] D loss: 0.8950, G loss: 4.0080\n",
      "[6492/8000] D loss: 0.9772, G loss: 2.8905\n",
      "[6852/8000] D loss: 0.3444, G loss: 6.9365\n",
      "[7212/8000] D loss: 1.0584, G loss: 4.3830\n",
      "[7572/8000] D loss: 0.8066, G loss: 4.1681\n",
      "[7932/8000] D loss: 0.7745, G loss: 3.2700\n",
      "train error: \n",
      " D loss: 0.837982, G loss: 4.249000, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 44.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.960867, G loss: 9.959635, D accuracy: 78.7%, cell accuracy: 98.1%, board accuracy: 21.7% \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1161, G loss: 3.8009\n",
      "[372/8000] D loss: 1.1492, G loss: 1.5463\n",
      "[732/8000] D loss: 0.5312, G loss: 7.6700\n",
      "[1092/8000] D loss: 0.8538, G loss: 3.3024\n",
      "[1452/8000] D loss: 1.1159, G loss: 4.4268\n",
      "[1812/8000] D loss: 0.8140, G loss: 3.3948\n",
      "[2172/8000] D loss: 0.9195, G loss: 6.0640\n",
      "[2532/8000] D loss: 0.8565, G loss: 5.2147\n",
      "[2892/8000] D loss: 1.0314, G loss: 2.2892\n",
      "[3252/8000] D loss: 1.0584, G loss: 2.9211\n",
      "[3612/8000] D loss: 0.7357, G loss: 5.6965\n",
      "[3972/8000] D loss: 0.9841, G loss: 7.3091\n",
      "[4332/8000] D loss: 0.8095, G loss: 3.1470\n",
      "[4692/8000] D loss: 0.9685, G loss: 4.4600\n",
      "[5052/8000] D loss: 0.7305, G loss: 6.7944\n",
      "[5412/8000] D loss: 0.9647, G loss: 2.5900\n",
      "[5772/8000] D loss: 0.6134, G loss: 6.3612\n",
      "[6132/8000] D loss: 0.8098, G loss: 5.8253\n",
      "[6492/8000] D loss: 0.6897, G loss: 5.9059\n",
      "[6852/8000] D loss: 0.9118, G loss: 3.4131\n",
      "[7212/8000] D loss: 0.6470, G loss: 3.1955\n",
      "[7572/8000] D loss: 0.5232, G loss: 7.3815\n",
      "[7932/8000] D loss: 0.8398, G loss: 5.2224\n",
      "train error: \n",
      " D loss: 0.816400, G loss: 4.619469, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 45.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.892186, G loss: 10.356737, D accuracy: 76.5%, cell accuracy: 98.2%, board accuracy: 22.9% \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6894, G loss: 4.7222\n",
      "[372/8000] D loss: 0.7262, G loss: 5.1864\n",
      "[732/8000] D loss: 0.8304, G loss: 3.0808\n",
      "[1092/8000] D loss: 0.6798, G loss: 4.2565\n",
      "[1452/8000] D loss: 0.5186, G loss: 4.2963\n",
      "[1812/8000] D loss: 1.0159, G loss: 2.7477\n",
      "[2172/8000] D loss: 0.3900, G loss: 7.4645\n",
      "[2532/8000] D loss: 0.7624, G loss: 3.6808\n",
      "[2892/8000] D loss: 0.8303, G loss: 7.7399\n",
      "[3252/8000] D loss: 1.0036, G loss: 2.0245\n",
      "[3612/8000] D loss: 0.6423, G loss: 5.0443\n",
      "[3972/8000] D loss: 0.5647, G loss: 4.9293\n",
      "[4332/8000] D loss: 0.9830, G loss: 5.6721\n",
      "[4692/8000] D loss: 0.5941, G loss: 5.6406\n",
      "[5052/8000] D loss: 0.5684, G loss: 4.8091\n",
      "[5412/8000] D loss: 0.6482, G loss: 3.2308\n",
      "[5772/8000] D loss: 0.6532, G loss: 4.8810\n",
      "[6132/8000] D loss: 0.5605, G loss: 6.6060\n",
      "[6492/8000] D loss: 0.4986, G loss: 5.7269\n",
      "[6852/8000] D loss: 0.9452, G loss: 3.0520\n",
      "[7212/8000] D loss: 0.5986, G loss: 6.2663\n",
      "[7572/8000] D loss: 0.7524, G loss: 3.5419\n",
      "[7932/8000] D loss: 1.1519, G loss: 2.4944\n",
      "train error: \n",
      " D loss: 0.797393, G loss: 4.298836, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 44.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.875601, G loss: 10.143932, D accuracy: 82.5%, cell accuracy: 98.1%, board accuracy: 22.0% \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6418, G loss: 5.0667\n",
      "[372/8000] D loss: 0.9468, G loss: 2.9807\n",
      "[732/8000] D loss: 0.2558, G loss: 7.5611\n",
      "[1092/8000] D loss: 0.8052, G loss: 3.7528\n",
      "[1452/8000] D loss: 0.7361, G loss: 2.8827\n",
      "[1812/8000] D loss: 0.4681, G loss: 8.2789\n",
      "[2172/8000] D loss: 0.8732, G loss: 4.6073\n",
      "[2532/8000] D loss: 0.6856, G loss: 4.7423\n",
      "[2892/8000] D loss: 0.6406, G loss: 3.3389\n",
      "[3252/8000] D loss: 1.3203, G loss: 2.4727\n",
      "[3612/8000] D loss: 0.6202, G loss: 5.2964\n",
      "[3972/8000] D loss: 0.9119, G loss: 6.1455\n",
      "[4332/8000] D loss: 1.0324, G loss: 3.1411\n",
      "[4692/8000] D loss: 0.7779, G loss: 7.3136\n",
      "[5052/8000] D loss: 1.0239, G loss: 2.5972\n",
      "[5412/8000] D loss: 0.9989, G loss: 2.6788\n",
      "[5772/8000] D loss: 0.8046, G loss: 2.9161\n",
      "[6132/8000] D loss: 0.7444, G loss: 4.6594\n",
      "[6492/8000] D loss: 0.6867, G loss: 5.5340\n",
      "[6852/8000] D loss: 0.8829, G loss: 3.2058\n",
      "[7212/8000] D loss: 0.7138, G loss: 4.8591\n",
      "[7572/8000] D loss: 1.0760, G loss: 4.1229\n",
      "[7932/8000] D loss: 0.9599, G loss: 4.1954\n",
      "train error: \n",
      " D loss: 0.806854, G loss: 3.587484, D accuracy: 75.8%, cell accuracy: 98.6%, board accuracy: 45.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.772478, G loss: 9.111071, D accuracy: 82.7%, cell accuracy: 98.1%, board accuracy: 21.4% \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7087, G loss: 3.7525\n",
      "[372/8000] D loss: 0.5857, G loss: 3.3210\n",
      "[732/8000] D loss: 0.7423, G loss: 5.8282\n",
      "[1092/8000] D loss: 0.8088, G loss: 4.7115\n",
      "[1452/8000] D loss: 0.5712, G loss: 5.0765\n",
      "[1812/8000] D loss: 0.8401, G loss: 4.0433\n",
      "[2172/8000] D loss: 0.7485, G loss: 4.3213\n",
      "[2532/8000] D loss: 0.8524, G loss: 4.3809\n",
      "[2892/8000] D loss: 0.6611, G loss: 4.4454\n",
      "[3252/8000] D loss: 1.0393, G loss: 4.5405\n",
      "[3612/8000] D loss: 0.6745, G loss: 4.1439\n",
      "[3972/8000] D loss: 1.0210, G loss: 2.9999\n",
      "[4332/8000] D loss: 0.8845, G loss: 5.5998\n",
      "[4692/8000] D loss: 0.4406, G loss: 4.5769\n",
      "[5052/8000] D loss: 0.7023, G loss: 5.7758\n",
      "[5412/8000] D loss: 0.3088, G loss: 9.9673\n",
      "[5772/8000] D loss: 0.8396, G loss: 4.3604\n",
      "[6132/8000] D loss: 0.9337, G loss: 2.9231\n",
      "[6492/8000] D loss: 0.7029, G loss: 3.9682\n",
      "[6852/8000] D loss: 0.7897, G loss: 3.1003\n",
      "[7212/8000] D loss: 0.8940, G loss: 7.3588\n",
      "[7572/8000] D loss: 0.9691, G loss: 3.4379\n",
      "[7932/8000] D loss: 0.6463, G loss: 5.2783\n",
      "train error: \n",
      " D loss: 0.795263, G loss: 4.352058, D accuracy: 76.1%, cell accuracy: 98.6%, board accuracy: 43.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.788812, G loss: 10.264887, D accuracy: 80.7%, cell accuracy: 98.1%, board accuracy: 22.7% \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6829, G loss: 5.2653\n",
      "[372/8000] D loss: 0.3472, G loss: 6.9550\n",
      "[732/8000] D loss: 0.8444, G loss: 3.4113\n",
      "[1092/8000] D loss: 0.7177, G loss: 3.4756\n",
      "[1452/8000] D loss: 0.4879, G loss: 6.2683\n",
      "[1812/8000] D loss: 0.8033, G loss: 3.4651\n",
      "[2172/8000] D loss: 0.4232, G loss: 5.7355\n",
      "[2532/8000] D loss: 0.9611, G loss: 2.3765\n",
      "[2892/8000] D loss: 1.1004, G loss: 2.4598\n",
      "[3252/8000] D loss: 0.3304, G loss: 7.4993\n",
      "[3612/8000] D loss: 0.6146, G loss: 3.9838\n",
      "[3972/8000] D loss: 0.5783, G loss: 3.8452\n",
      "[4332/8000] D loss: 0.8800, G loss: 2.3690\n",
      "[4692/8000] D loss: 0.6331, G loss: 8.4850\n",
      "[5052/8000] D loss: 1.0543, G loss: 4.8912\n",
      "[5412/8000] D loss: 0.8434, G loss: 2.0277\n",
      "[5772/8000] D loss: 1.2509, G loss: 4.5866\n",
      "[6132/8000] D loss: 0.8651, G loss: 3.3933\n",
      "[6492/8000] D loss: 0.8915, G loss: 3.6995\n",
      "[6852/8000] D loss: 0.8596, G loss: 2.2169\n",
      "[7212/8000] D loss: 0.9176, G loss: 4.3480\n",
      "[7572/8000] D loss: 0.8536, G loss: 2.9358\n",
      "[7932/8000] D loss: 0.8970, G loss: 3.4651\n",
      "train error: \n",
      " D loss: 0.781301, G loss: 3.869499, D accuracy: 76.5%, cell accuracy: 98.6%, board accuracy: 45.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.774536, G loss: 9.693844, D accuracy: 82.6%, cell accuracy: 98.2%, board accuracy: 22.9% \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6533, G loss: 4.1700\n",
      "[372/8000] D loss: 0.6656, G loss: 4.0383\n",
      "[732/8000] D loss: 0.6496, G loss: 6.0610\n",
      "[1092/8000] D loss: 0.4910, G loss: 6.4276\n",
      "[1452/8000] D loss: 0.5046, G loss: 6.7784\n",
      "[1812/8000] D loss: 0.7150, G loss: 5.2542\n",
      "[2172/8000] D loss: 0.8770, G loss: 2.7952\n",
      "[2532/8000] D loss: 0.5864, G loss: 6.6367\n",
      "[2892/8000] D loss: 0.9163, G loss: 4.1538\n",
      "[3252/8000] D loss: 0.6725, G loss: 5.2147\n",
      "[3612/8000] D loss: 1.0922, G loss: 4.9250\n",
      "[3972/8000] D loss: 0.7055, G loss: 5.2201\n",
      "[4332/8000] D loss: 0.7645, G loss: 5.2792\n",
      "[4692/8000] D loss: 1.1782, G loss: 1.4984\n",
      "[5052/8000] D loss: 1.2677, G loss: 1.0579\n",
      "[5412/8000] D loss: 0.7318, G loss: 5.9430\n",
      "[5772/8000] D loss: 1.0918, G loss: 3.1772\n",
      "[6132/8000] D loss: 0.9548, G loss: 4.5150\n",
      "[6492/8000] D loss: 0.6586, G loss: 6.1268\n",
      "[6852/8000] D loss: 1.0099, G loss: 3.1958\n",
      "[7212/8000] D loss: 0.6794, G loss: 5.0509\n",
      "[7572/8000] D loss: 0.8155, G loss: 6.1080\n",
      "[7932/8000] D loss: 0.3992, G loss: 5.7804\n",
      "train error: \n",
      " D loss: 0.783672, G loss: 4.071878, D accuracy: 77.5%, cell accuracy: 98.6%, board accuracy: 42.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.751927, G loss: 10.015966, D accuracy: 83.3%, cell accuracy: 98.1%, board accuracy: 20.5% \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3856, G loss: 7.2000\n",
      "[372/8000] D loss: 0.9658, G loss: 3.5261\n",
      "[732/8000] D loss: 0.4498, G loss: 5.6521\n",
      "[1092/8000] D loss: 0.6247, G loss: 4.9317\n",
      "[1452/8000] D loss: 0.8855, G loss: 2.2266\n",
      "[1812/8000] D loss: 0.9223, G loss: 5.3581\n",
      "[2172/8000] D loss: 0.6747, G loss: 4.1136\n",
      "[2532/8000] D loss: 0.5455, G loss: 7.4702\n",
      "[2892/8000] D loss: 0.9785, G loss: 4.2265\n",
      "[3252/8000] D loss: 0.7075, G loss: 4.8548\n",
      "[3612/8000] D loss: 0.8009, G loss: 3.2134\n",
      "[3972/8000] D loss: 0.6665, G loss: 7.5160\n",
      "[4332/8000] D loss: 0.6277, G loss: 4.1269\n",
      "[4692/8000] D loss: 0.4080, G loss: 7.4978\n",
      "[5052/8000] D loss: 1.0098, G loss: 5.0525\n",
      "[5412/8000] D loss: 0.5578, G loss: 5.5904\n",
      "[5772/8000] D loss: 0.5660, G loss: 6.1910\n",
      "[6132/8000] D loss: 0.6006, G loss: 7.0640\n",
      "[6492/8000] D loss: 0.7634, G loss: 5.9953\n",
      "[6852/8000] D loss: 1.0537, G loss: 3.1968\n",
      "[7212/8000] D loss: 0.7357, G loss: 3.2166\n",
      "[7572/8000] D loss: 0.4413, G loss: 7.2685\n",
      "[7932/8000] D loss: 1.1414, G loss: 1.1643\n",
      "train error: \n",
      " D loss: 0.816272, G loss: 3.910707, D accuracy: 75.5%, cell accuracy: 98.6%, board accuracy: 43.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.745787, G loss: 9.645771, D accuracy: 81.0%, cell accuracy: 98.1%, board accuracy: 22.2% \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7071, G loss: 4.0278\n",
      "[372/8000] D loss: 0.6921, G loss: 3.8220\n",
      "[732/8000] D loss: 0.6633, G loss: 6.8248\n",
      "[1092/8000] D loss: 0.8931, G loss: 3.0613\n",
      "[1452/8000] D loss: 0.6421, G loss: 4.4974\n",
      "[1812/8000] D loss: 0.9044, G loss: 6.5109\n",
      "[2172/8000] D loss: 1.1273, G loss: 2.7844\n",
      "[2532/8000] D loss: 0.8493, G loss: 1.9763\n",
      "[2892/8000] D loss: 0.7658, G loss: 4.3430\n",
      "[3252/8000] D loss: 0.9250, G loss: 4.8503\n",
      "[3612/8000] D loss: 1.1412, G loss: 4.3721\n",
      "[3972/8000] D loss: 0.8516, G loss: 5.7006\n",
      "[4332/8000] D loss: 0.8334, G loss: 4.4502\n",
      "[4692/8000] D loss: 0.4734, G loss: 4.4796\n",
      "[5052/8000] D loss: 0.8250, G loss: 3.0993\n",
      "[5412/8000] D loss: 0.9034, G loss: 3.6991\n",
      "[5772/8000] D loss: 0.2941, G loss: 7.8047\n",
      "[6132/8000] D loss: 0.9622, G loss: 1.7048\n",
      "[6492/8000] D loss: 0.8313, G loss: 2.6732\n",
      "[6852/8000] D loss: 0.7419, G loss: 2.9876\n",
      "[7212/8000] D loss: 0.9056, G loss: 2.5397\n",
      "[7572/8000] D loss: 0.6227, G loss: 3.9312\n",
      "[7932/8000] D loss: 0.5737, G loss: 3.5354\n",
      "train error: \n",
      " D loss: 0.839503, G loss: 4.702479, D accuracy: 74.9%, cell accuracy: 98.6%, board accuracy: 44.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.994529, G loss: 10.675721, D accuracy: 79.0%, cell accuracy: 98.1%, board accuracy: 22.8% \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5980, G loss: 6.0610\n",
      "[372/8000] D loss: 0.6653, G loss: 4.0836\n",
      "[732/8000] D loss: 0.8306, G loss: 2.5619\n",
      "[1092/8000] D loss: 0.9240, G loss: 1.5122\n",
      "[1452/8000] D loss: 0.7196, G loss: 3.7497\n",
      "[1812/8000] D loss: 0.8698, G loss: 2.6820\n",
      "[2172/8000] D loss: 1.0266, G loss: 1.2337\n",
      "[2532/8000] D loss: 0.7758, G loss: 3.9451\n",
      "[2892/8000] D loss: 0.7228, G loss: 4.0523\n",
      "[3252/8000] D loss: 0.9447, G loss: 5.6234\n",
      "[3612/8000] D loss: 0.8797, G loss: 6.2776\n",
      "[3972/8000] D loss: 1.1828, G loss: 2.2320\n",
      "[4332/8000] D loss: 1.0455, G loss: 2.4213\n",
      "[4692/8000] D loss: 0.5689, G loss: 4.9123\n",
      "[5052/8000] D loss: 0.8169, G loss: 3.4955\n",
      "[5412/8000] D loss: 0.9443, G loss: 3.8457\n",
      "[5772/8000] D loss: 0.9369, G loss: 2.3645\n",
      "[6132/8000] D loss: 0.7301, G loss: 5.7012\n",
      "[6492/8000] D loss: 0.9498, G loss: 2.3571\n",
      "[6852/8000] D loss: 0.8442, G loss: 4.2312\n",
      "[7212/8000] D loss: 0.7948, G loss: 1.6809\n",
      "[7572/8000] D loss: 0.9966, G loss: 5.3268\n",
      "[7932/8000] D loss: 0.7717, G loss: 5.2938\n",
      "train error: \n",
      " D loss: 0.798024, G loss: 4.271215, D accuracy: 76.9%, cell accuracy: 98.6%, board accuracy: 42.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.766337, G loss: 9.972516, D accuracy: 82.3%, cell accuracy: 98.1%, board accuracy: 21.5% \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6847, G loss: 5.7712\n",
      "[372/8000] D loss: 0.6293, G loss: 4.9125\n",
      "[732/8000] D loss: 0.6911, G loss: 4.7395\n",
      "[1092/8000] D loss: 0.6951, G loss: 4.6705\n",
      "[1452/8000] D loss: 0.6063, G loss: 4.6819\n",
      "[1812/8000] D loss: 0.5867, G loss: 7.1313\n",
      "[2172/8000] D loss: 0.4780, G loss: 6.7943\n",
      "[2532/8000] D loss: 0.9119, G loss: 4.8139\n",
      "[2892/8000] D loss: 0.8040, G loss: 3.4515\n",
      "[3252/8000] D loss: 0.8704, G loss: 5.3936\n",
      "[3612/8000] D loss: 0.3636, G loss: 5.2488\n",
      "[3972/8000] D loss: 0.6938, G loss: 4.8856\n",
      "[4332/8000] D loss: 0.5790, G loss: 7.0081\n",
      "[4692/8000] D loss: 0.6718, G loss: 4.1812\n",
      "[5052/8000] D loss: 0.8700, G loss: 2.6831\n",
      "[5412/8000] D loss: 1.1115, G loss: 1.4617\n",
      "[5772/8000] D loss: 0.7262, G loss: 6.4725\n",
      "[6132/8000] D loss: 0.9455, G loss: 3.5682\n",
      "[6492/8000] D loss: 1.1391, G loss: 2.4622\n",
      "[6852/8000] D loss: 0.7847, G loss: 5.7385\n",
      "[7212/8000] D loss: 1.0634, G loss: 4.0343\n",
      "[7572/8000] D loss: 0.5551, G loss: 6.3304\n",
      "[7932/8000] D loss: 0.6732, G loss: 3.4124\n",
      "train error: \n",
      " D loss: 0.786048, G loss: 4.579389, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 44.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.885284, G loss: 10.726385, D accuracy: 79.4%, cell accuracy: 98.1%, board accuracy: 22.6% \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7888, G loss: 5.8527\n",
      "[372/8000] D loss: 0.7867, G loss: 3.3733\n",
      "[732/8000] D loss: 0.7284, G loss: 6.2600\n",
      "[1092/8000] D loss: 0.8369, G loss: 2.5567\n",
      "[1452/8000] D loss: 0.9043, G loss: 5.3562\n",
      "[1812/8000] D loss: 1.1674, G loss: 2.3670\n",
      "[2172/8000] D loss: 1.0284, G loss: 2.4371\n",
      "[2532/8000] D loss: 0.7472, G loss: 3.5119\n",
      "[2892/8000] D loss: 0.5993, G loss: 7.3942\n",
      "[3252/8000] D loss: 0.6592, G loss: 6.2123\n",
      "[3612/8000] D loss: 0.8188, G loss: 2.3790\n",
      "[3972/8000] D loss: 0.5028, G loss: 6.2633\n",
      "[4332/8000] D loss: 0.7408, G loss: 3.9106\n",
      "[4692/8000] D loss: 0.6275, G loss: 5.7038\n",
      "[5052/8000] D loss: 0.8907, G loss: 2.4595\n",
      "[5412/8000] D loss: 0.6229, G loss: 8.9442\n",
      "[5772/8000] D loss: 0.5537, G loss: 10.1625\n",
      "[6132/8000] D loss: 0.9543, G loss: 3.0905\n",
      "[6492/8000] D loss: 0.4871, G loss: 4.6267\n",
      "[6852/8000] D loss: 0.6591, G loss: 3.9153\n",
      "[7212/8000] D loss: 0.9058, G loss: 2.7751\n",
      "[7572/8000] D loss: 0.8673, G loss: 4.0034\n",
      "[7932/8000] D loss: 0.2971, G loss: 5.3789\n",
      "train error: \n",
      " D loss: 0.777603, G loss: 4.342660, D accuracy: 76.8%, cell accuracy: 98.6%, board accuracy: 44.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.799536, G loss: 10.379025, D accuracy: 80.8%, cell accuracy: 98.1%, board accuracy: 21.6% \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5716, G loss: 6.2258\n",
      "[372/8000] D loss: 0.7328, G loss: 4.3793\n",
      "[732/8000] D loss: 0.7727, G loss: 6.0797\n",
      "[1092/8000] D loss: 0.8951, G loss: 3.0706\n",
      "[1452/8000] D loss: 0.6037, G loss: 3.0903\n",
      "[1812/8000] D loss: 0.8641, G loss: 4.2608\n",
      "[2172/8000] D loss: 0.8858, G loss: 2.5181\n",
      "[2532/8000] D loss: 0.5528, G loss: 5.1818\n",
      "[2892/8000] D loss: 0.8279, G loss: 3.3718\n",
      "[3252/8000] D loss: 0.6642, G loss: 3.5912\n",
      "[3612/8000] D loss: 0.6337, G loss: 5.3430\n",
      "[3972/8000] D loss: 0.2140, G loss: 6.7276\n",
      "[4332/8000] D loss: 0.7315, G loss: 3.6681\n",
      "[4692/8000] D loss: 0.6245, G loss: 5.3278\n",
      "[5052/8000] D loss: 0.8265, G loss: 3.6832\n",
      "[5412/8000] D loss: 0.7866, G loss: 5.2413\n",
      "[5772/8000] D loss: 0.7267, G loss: 5.6331\n",
      "[6132/8000] D loss: 0.8505, G loss: 4.6505\n",
      "[6492/8000] D loss: 1.0592, G loss: 2.8535\n",
      "[6852/8000] D loss: 0.7267, G loss: 7.0377\n",
      "[7212/8000] D loss: 0.8635, G loss: 3.2840\n",
      "[7572/8000] D loss: 0.8405, G loss: 4.6044\n",
      "[7932/8000] D loss: 0.8448, G loss: 4.8944\n",
      "train error: \n",
      " D loss: 0.782614, G loss: 3.777970, D accuracy: 77.0%, cell accuracy: 98.6%, board accuracy: 43.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.774673, G loss: 9.299323, D accuracy: 81.9%, cell accuracy: 98.1%, board accuracy: 21.1% \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1502, G loss: 2.9000\n",
      "[372/8000] D loss: 0.5177, G loss: 6.4768\n",
      "[732/8000] D loss: 0.9648, G loss: 2.2266\n",
      "[1092/8000] D loss: 0.6739, G loss: 3.6154\n",
      "[1452/8000] D loss: 0.7667, G loss: 4.2649\n",
      "[1812/8000] D loss: 0.7564, G loss: 2.5897\n",
      "[2172/8000] D loss: 0.8638, G loss: 4.5273\n",
      "[2532/8000] D loss: 0.7385, G loss: 4.7332\n",
      "[2892/8000] D loss: 0.6572, G loss: 4.7082\n",
      "[3252/8000] D loss: 1.0283, G loss: 2.5785\n",
      "[3612/8000] D loss: 0.6032, G loss: 4.9764\n",
      "[3972/8000] D loss: 0.9601, G loss: 1.7456\n",
      "[4332/8000] D loss: 0.5265, G loss: 5.7784\n",
      "[4692/8000] D loss: 0.8135, G loss: 2.3909\n",
      "[5052/8000] D loss: 0.3785, G loss: 7.7293\n",
      "[5412/8000] D loss: 0.5939, G loss: 7.6344\n",
      "[5772/8000] D loss: 0.3327, G loss: 8.6194\n",
      "[6132/8000] D loss: 0.8464, G loss: 3.9564\n",
      "[6492/8000] D loss: 0.5320, G loss: 6.8729\n",
      "[6852/8000] D loss: 0.8549, G loss: 4.9702\n",
      "[7212/8000] D loss: 0.7308, G loss: 3.5563\n",
      "[7572/8000] D loss: 0.9609, G loss: 2.3382\n",
      "[7932/8000] D loss: 0.6576, G loss: 5.2932\n",
      "train error: \n",
      " D loss: 0.782926, G loss: 4.794215, D accuracy: 76.1%, cell accuracy: 98.6%, board accuracy: 44.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.922254, G loss: 11.403183, D accuracy: 78.6%, cell accuracy: 98.1%, board accuracy: 21.4% \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8696, G loss: 2.8466\n",
      "[372/8000] D loss: 0.6433, G loss: 4.5594\n",
      "[732/8000] D loss: 0.8764, G loss: 3.8710\n",
      "[1092/8000] D loss: 0.6287, G loss: 3.5335\n",
      "[1452/8000] D loss: 0.6653, G loss: 6.1379\n",
      "[1812/8000] D loss: 0.5071, G loss: 5.7658\n",
      "[2172/8000] D loss: 0.2940, G loss: 7.8121\n",
      "[2532/8000] D loss: 0.8480, G loss: 5.2959\n",
      "[2892/8000] D loss: 0.7663, G loss: 5.8040\n",
      "[3252/8000] D loss: 0.6020, G loss: 4.9493\n",
      "[3612/8000] D loss: 0.9959, G loss: 3.8317\n",
      "[3972/8000] D loss: 0.7856, G loss: 7.0689\n",
      "[4332/8000] D loss: 0.5691, G loss: 5.0062\n",
      "[4692/8000] D loss: 0.6453, G loss: 3.6299\n",
      "[5052/8000] D loss: 0.5238, G loss: 4.6542\n",
      "[5412/8000] D loss: 0.5983, G loss: 4.6735\n",
      "[5772/8000] D loss: 0.8015, G loss: 5.1107\n",
      "[6132/8000] D loss: 0.5305, G loss: 5.2799\n",
      "[6492/8000] D loss: 0.7326, G loss: 6.3070\n",
      "[6852/8000] D loss: 0.5685, G loss: 7.4873\n",
      "[7212/8000] D loss: 0.5781, G loss: 3.5831\n",
      "[7572/8000] D loss: 0.6708, G loss: 7.7678\n",
      "[7932/8000] D loss: 0.4830, G loss: 7.9365\n",
      "train error: \n",
      " D loss: 0.798360, G loss: 3.746603, D accuracy: 75.8%, cell accuracy: 98.6%, board accuracy: 45.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.793266, G loss: 9.539493, D accuracy: 81.6%, cell accuracy: 98.1%, board accuracy: 22.3% \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2755, G loss: 5.1134\n",
      "[372/8000] D loss: 0.9265, G loss: 3.2467\n",
      "[732/8000] D loss: 0.5628, G loss: 3.8443\n",
      "[1092/8000] D loss: 0.9388, G loss: 3.3674\n",
      "[1452/8000] D loss: 0.7846, G loss: 5.4872\n",
      "[1812/8000] D loss: 0.7505, G loss: 4.0163\n",
      "[2172/8000] D loss: 0.4435, G loss: 4.1115\n",
      "[2532/8000] D loss: 0.6237, G loss: 6.2603\n",
      "[2892/8000] D loss: 0.5563, G loss: 4.0187\n",
      "[3252/8000] D loss: 0.9730, G loss: 4.5838\n",
      "[3612/8000] D loss: 0.7295, G loss: 3.7925\n",
      "[3972/8000] D loss: 0.5947, G loss: 6.4818\n",
      "[4332/8000] D loss: 0.7952, G loss: 2.2734\n",
      "[4692/8000] D loss: 0.8574, G loss: 3.9292\n",
      "[5052/8000] D loss: 0.7962, G loss: 7.3306\n",
      "[5412/8000] D loss: 0.7065, G loss: 5.2811\n",
      "[5772/8000] D loss: 0.9702, G loss: 2.9576\n",
      "[6132/8000] D loss: 0.6596, G loss: 5.3016\n",
      "[6492/8000] D loss: 0.9207, G loss: 3.3388\n",
      "[6852/8000] D loss: 0.4078, G loss: 5.7944\n",
      "[7212/8000] D loss: 0.9987, G loss: 1.7780\n",
      "[7572/8000] D loss: 0.8234, G loss: 4.3938\n",
      "[7932/8000] D loss: 0.5224, G loss: 3.0854\n",
      "train error: \n",
      " D loss: 0.816818, G loss: 3.553106, D accuracy: 75.7%, cell accuracy: 98.6%, board accuracy: 45.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.784544, G loss: 9.368421, D accuracy: 82.7%, cell accuracy: 98.1%, board accuracy: 22.2% \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9484, G loss: 3.6914\n",
      "[372/8000] D loss: 0.9242, G loss: 3.0692\n",
      "[732/8000] D loss: 0.5491, G loss: 3.8452\n",
      "[1092/8000] D loss: 0.4643, G loss: 4.5537\n",
      "[1452/8000] D loss: 0.5608, G loss: 6.5143\n",
      "[1812/8000] D loss: 0.7956, G loss: 4.5804\n",
      "[2172/8000] D loss: 0.8037, G loss: 3.0214\n",
      "[2532/8000] D loss: 0.8866, G loss: 3.7731\n",
      "[2892/8000] D loss: 0.4970, G loss: 7.5613\n",
      "[3252/8000] D loss: 1.1115, G loss: 2.5589\n",
      "[3612/8000] D loss: 0.7521, G loss: 4.8976\n",
      "[3972/8000] D loss: 0.5370, G loss: 6.5575\n",
      "[4332/8000] D loss: 0.7932, G loss: 2.0848\n",
      "[4692/8000] D loss: 0.5142, G loss: 4.2869\n",
      "[5052/8000] D loss: 0.8194, G loss: 6.6914\n",
      "[5412/8000] D loss: 0.6620, G loss: 5.0881\n",
      "[5772/8000] D loss: 0.6352, G loss: 6.1488\n",
      "[6132/8000] D loss: 1.1869, G loss: 1.3875\n",
      "[6492/8000] D loss: 0.9429, G loss: 4.1548\n",
      "[6852/8000] D loss: 0.8754, G loss: 3.0001\n",
      "[7212/8000] D loss: 0.6968, G loss: 6.8825\n",
      "[7572/8000] D loss: 0.7243, G loss: 5.4303\n",
      "[7932/8000] D loss: 0.7887, G loss: 7.4158\n",
      "train error: \n",
      " D loss: 0.832050, G loss: 3.654606, D accuracy: 75.5%, cell accuracy: 98.6%, board accuracy: 45.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.699325, G loss: 9.703809, D accuracy: 84.4%, cell accuracy: 98.1%, board accuracy: 22.8% \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0414, G loss: 3.8486\n",
      "[372/8000] D loss: 0.7008, G loss: 5.1899\n",
      "[732/8000] D loss: 0.7885, G loss: 3.9810\n",
      "[1092/8000] D loss: 0.9233, G loss: 3.7009\n",
      "[1452/8000] D loss: 0.8760, G loss: 5.5920\n",
      "[1812/8000] D loss: 0.9146, G loss: 6.6804\n",
      "[2172/8000] D loss: 0.6596, G loss: 5.5060\n",
      "[2532/8000] D loss: 0.5898, G loss: 8.2026\n",
      "[2892/8000] D loss: 0.5019, G loss: 9.4326\n",
      "[3252/8000] D loss: 0.5840, G loss: 5.0183\n",
      "[3612/8000] D loss: 0.9272, G loss: 2.9743\n",
      "[3972/8000] D loss: 0.7321, G loss: 5.4511\n",
      "[4332/8000] D loss: 0.5134, G loss: 4.9429\n",
      "[4692/8000] D loss: 1.0304, G loss: 2.9363\n",
      "[5052/8000] D loss: 0.7785, G loss: 4.5105\n",
      "[5412/8000] D loss: 0.9851, G loss: 7.4983\n",
      "[5772/8000] D loss: 1.0878, G loss: 3.2475\n",
      "[6132/8000] D loss: 1.0460, G loss: 2.0174\n",
      "[6492/8000] D loss: 0.8054, G loss: 3.2747\n",
      "[6852/8000] D loss: 1.0474, G loss: 2.3640\n",
      "[7212/8000] D loss: 0.9376, G loss: 1.7970\n",
      "[7572/8000] D loss: 0.8071, G loss: 2.9734\n",
      "[7932/8000] D loss: 0.6624, G loss: 6.2166\n",
      "train error: \n",
      " D loss: 0.798956, G loss: 4.739736, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 45.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.911875, G loss: 11.025007, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 23.1% \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3463, G loss: 4.6577\n",
      "[372/8000] D loss: 0.4730, G loss: 6.0518\n",
      "[732/8000] D loss: 0.4192, G loss: 6.1512\n",
      "[1092/8000] D loss: 1.0647, G loss: 4.2873\n",
      "[1452/8000] D loss: 0.8973, G loss: 2.4222\n",
      "[1812/8000] D loss: 0.7907, G loss: 5.4073\n",
      "[2172/8000] D loss: 0.5986, G loss: 6.0100\n",
      "[2532/8000] D loss: 0.8207, G loss: 3.8530\n",
      "[2892/8000] D loss: 0.7506, G loss: 6.2562\n",
      "[3252/8000] D loss: 0.9000, G loss: 3.6523\n",
      "[3612/8000] D loss: 0.3471, G loss: 8.2449\n",
      "[3972/8000] D loss: 0.9730, G loss: 3.8788\n",
      "[4332/8000] D loss: 1.0508, G loss: 2.3650\n",
      "[4692/8000] D loss: 0.9752, G loss: 3.3815\n",
      "[5052/8000] D loss: 0.6992, G loss: 2.9104\n",
      "[5412/8000] D loss: 0.5933, G loss: 6.3703\n",
      "[5772/8000] D loss: 0.6461, G loss: 4.8597\n",
      "[6132/8000] D loss: 0.5332, G loss: 4.6983\n",
      "[6492/8000] D loss: 0.6666, G loss: 4.5257\n",
      "[6852/8000] D loss: 0.9329, G loss: 2.7274\n",
      "[7212/8000] D loss: 0.8673, G loss: 2.7732\n",
      "[7572/8000] D loss: 0.9652, G loss: 4.5099\n",
      "[7932/8000] D loss: 0.6953, G loss: 5.8229\n",
      "train error: \n",
      " D loss: 0.819402, G loss: 3.798276, D accuracy: 75.3%, cell accuracy: 98.6%, board accuracy: 46.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.730369, G loss: 9.644057, D accuracy: 82.4%, cell accuracy: 98.2%, board accuracy: 22.8% \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7480, G loss: 3.0373\n",
      "[372/8000] D loss: 0.6879, G loss: 6.9336\n",
      "[732/8000] D loss: 0.7669, G loss: 6.2195\n",
      "[1092/8000] D loss: 0.5926, G loss: 4.6988\n",
      "[1452/8000] D loss: 0.7013, G loss: 5.7083\n",
      "[1812/8000] D loss: 0.7615, G loss: 3.6201\n",
      "[2172/8000] D loss: 1.0071, G loss: 2.5932\n",
      "[2532/8000] D loss: 0.8433, G loss: 4.6335\n",
      "[2892/8000] D loss: 0.9520, G loss: 3.8432\n",
      "[3252/8000] D loss: 0.8981, G loss: 2.5122\n",
      "[3612/8000] D loss: 0.8884, G loss: 3.3879\n",
      "[3972/8000] D loss: 1.0044, G loss: 3.5128\n",
      "[4332/8000] D loss: 0.8762, G loss: 4.6188\n",
      "[4692/8000] D loss: 1.0290, G loss: 4.2138\n",
      "[5052/8000] D loss: 0.6755, G loss: 5.0144\n",
      "[5412/8000] D loss: 1.0753, G loss: 2.4071\n",
      "[5772/8000] D loss: 0.8611, G loss: 2.3214\n",
      "[6132/8000] D loss: 0.9581, G loss: 4.7220\n",
      "[6492/8000] D loss: 0.8450, G loss: 2.5436\n",
      "[6852/8000] D loss: 0.4933, G loss: 7.9432\n",
      "[7212/8000] D loss: 0.7801, G loss: 5.1135\n",
      "[7572/8000] D loss: 0.6052, G loss: 4.9019\n",
      "[7932/8000] D loss: 0.8029, G loss: 3.8235\n",
      "train error: \n",
      " D loss: 0.804671, G loss: 3.927961, D accuracy: 75.9%, cell accuracy: 98.6%, board accuracy: 45.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.780433, G loss: 10.126152, D accuracy: 83.0%, cell accuracy: 98.1%, board accuracy: 22.6% \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8371, G loss: 3.9470\n",
      "[372/8000] D loss: 0.6162, G loss: 5.5704\n",
      "[732/8000] D loss: 0.7944, G loss: 2.3016\n",
      "[1092/8000] D loss: 1.1488, G loss: 1.6979\n",
      "[1452/8000] D loss: 0.9592, G loss: 5.0502\n",
      "[1812/8000] D loss: 0.6797, G loss: 4.4782\n",
      "[2172/8000] D loss: 0.6562, G loss: 8.1596\n",
      "[2532/8000] D loss: 0.4234, G loss: 5.1307\n",
      "[2892/8000] D loss: 0.9326, G loss: 4.2693\n",
      "[3252/8000] D loss: 0.4110, G loss: 7.7702\n",
      "[3612/8000] D loss: 0.9339, G loss: 4.3396\n",
      "[3972/8000] D loss: 0.6981, G loss: 4.5359\n",
      "[4332/8000] D loss: 0.8596, G loss: 5.8002\n",
      "[4692/8000] D loss: 0.8619, G loss: 4.4875\n",
      "[5052/8000] D loss: 0.5703, G loss: 4.7472\n",
      "[5412/8000] D loss: 0.9420, G loss: 3.4374\n",
      "[5772/8000] D loss: 0.6602, G loss: 7.4646\n",
      "[6132/8000] D loss: 0.2084, G loss: 11.5841\n",
      "[6492/8000] D loss: 1.1898, G loss: 6.4044\n",
      "[6852/8000] D loss: 0.8291, G loss: 5.2995\n",
      "[7212/8000] D loss: 0.6224, G loss: 4.6992\n",
      "[7572/8000] D loss: 0.8081, G loss: 2.7936\n",
      "[7932/8000] D loss: 0.7955, G loss: 4.7740\n",
      "train error: \n",
      " D loss: 0.790460, G loss: 3.693747, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 44.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.727174, G loss: 9.614147, D accuracy: 83.4%, cell accuracy: 98.1%, board accuracy: 22.1% \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9406, G loss: 1.6775\n",
      "[372/8000] D loss: 0.5454, G loss: 8.4575\n",
      "[732/8000] D loss: 0.9211, G loss: 8.3235\n",
      "[1092/8000] D loss: 0.9619, G loss: 1.6934\n",
      "[1452/8000] D loss: 0.3763, G loss: 4.6197\n",
      "[1812/8000] D loss: 0.6184, G loss: 6.4674\n",
      "[2172/8000] D loss: 0.7901, G loss: 5.1294\n",
      "[2532/8000] D loss: 1.0692, G loss: 4.8104\n",
      "[2892/8000] D loss: 0.9594, G loss: 3.2993\n",
      "[3252/8000] D loss: 0.8652, G loss: 2.5777\n",
      "[3612/8000] D loss: 0.6264, G loss: 5.7815\n",
      "[3972/8000] D loss: 0.6617, G loss: 4.7489\n",
      "[4332/8000] D loss: 0.6371, G loss: 4.8317\n",
      "[4692/8000] D loss: 0.9148, G loss: 4.0777\n",
      "[5052/8000] D loss: 0.6914, G loss: 3.9102\n",
      "[5412/8000] D loss: 0.8709, G loss: 3.8953\n",
      "[5772/8000] D loss: 0.5663, G loss: 7.6936\n",
      "[6132/8000] D loss: 0.7453, G loss: 5.2852\n",
      "[6492/8000] D loss: 0.8681, G loss: 5.0907\n",
      "[6852/8000] D loss: 0.8004, G loss: 4.1175\n",
      "[7212/8000] D loss: 0.9095, G loss: 4.5347\n",
      "[7572/8000] D loss: 0.6384, G loss: 5.0108\n",
      "[7932/8000] D loss: 0.8662, G loss: 1.8296\n",
      "train error: \n",
      " D loss: 0.826089, G loss: 4.063325, D accuracy: 75.5%, cell accuracy: 98.6%, board accuracy: 45.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.737692, G loss: 10.076001, D accuracy: 83.7%, cell accuracy: 98.1%, board accuracy: 21.7% \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0818, G loss: 1.2378\n",
      "[372/8000] D loss: 0.9893, G loss: 3.2481\n",
      "[732/8000] D loss: 0.6857, G loss: 3.9391\n",
      "[1092/8000] D loss: 0.9509, G loss: 2.4942\n",
      "[1452/8000] D loss: 0.8545, G loss: 4.0168\n",
      "[1812/8000] D loss: 0.7115, G loss: 3.7517\n",
      "[2172/8000] D loss: 0.4622, G loss: 6.6375\n",
      "[2532/8000] D loss: 0.8558, G loss: 5.3155\n",
      "[2892/8000] D loss: 0.9062, G loss: 4.3430\n",
      "[3252/8000] D loss: 0.5995, G loss: 6.6518\n",
      "[3612/8000] D loss: 0.4993, G loss: 6.1351\n",
      "[3972/8000] D loss: 0.5820, G loss: 4.6375\n",
      "[4332/8000] D loss: 1.1067, G loss: 1.9329\n",
      "[4692/8000] D loss: 1.0153, G loss: 3.6847\n",
      "[5052/8000] D loss: 0.7674, G loss: 5.2717\n",
      "[5412/8000] D loss: 0.8674, G loss: 2.9494\n",
      "[5772/8000] D loss: 0.4505, G loss: 6.6993\n",
      "[6132/8000] D loss: 0.9439, G loss: 2.3405\n",
      "[6492/8000] D loss: 0.9602, G loss: 2.9025\n",
      "[6852/8000] D loss: 0.7183, G loss: 6.4282\n",
      "[7212/8000] D loss: 0.8214, G loss: 2.7305\n",
      "[7572/8000] D loss: 0.7630, G loss: 3.1942\n",
      "[7932/8000] D loss: 0.7393, G loss: 3.3123\n",
      "train error: \n",
      " D loss: 0.786129, G loss: 3.526581, D accuracy: 76.9%, cell accuracy: 98.6%, board accuracy: 43.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.764645, G loss: 9.231061, D accuracy: 81.8%, cell accuracy: 98.1%, board accuracy: 21.6% \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3859, G loss: 4.2374\n",
      "[372/8000] D loss: 0.9836, G loss: 2.1057\n",
      "[732/8000] D loss: 0.8117, G loss: 5.5713\n",
      "[1092/8000] D loss: 0.6322, G loss: 5.6286\n",
      "[1452/8000] D loss: 0.9737, G loss: 2.3851\n",
      "[1812/8000] D loss: 0.7545, G loss: 3.7693\n",
      "[2172/8000] D loss: 0.8550, G loss: 3.4893\n",
      "[2532/8000] D loss: 0.7227, G loss: 3.2904\n",
      "[2892/8000] D loss: 1.1022, G loss: 2.8181\n",
      "[3252/8000] D loss: 1.0304, G loss: 1.9976\n",
      "[3612/8000] D loss: 0.7829, G loss: 3.7521\n",
      "[3972/8000] D loss: 0.7178, G loss: 6.9247\n",
      "[4332/8000] D loss: 0.7314, G loss: 5.1103\n",
      "[4692/8000] D loss: 0.9173, G loss: 4.9038\n",
      "[5052/8000] D loss: 0.7385, G loss: 4.6010\n",
      "[5412/8000] D loss: 0.8146, G loss: 2.4601\n",
      "[5772/8000] D loss: 0.3157, G loss: 6.0391\n",
      "[6132/8000] D loss: 0.8873, G loss: 3.1759\n",
      "[6492/8000] D loss: 0.8644, G loss: 4.1866\n",
      "[6852/8000] D loss: 0.8060, G loss: 4.2530\n",
      "[7212/8000] D loss: 1.0004, G loss: 3.5574\n",
      "[7572/8000] D loss: 0.4917, G loss: 7.2265\n",
      "[7932/8000] D loss: 0.7165, G loss: 3.8493\n",
      "train error: \n",
      " D loss: 0.798702, G loss: 3.909958, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 45.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.737306, G loss: 10.227346, D accuracy: 83.6%, cell accuracy: 98.1%, board accuracy: 22.6% \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5999, G loss: 4.2612\n",
      "[372/8000] D loss: 0.9569, G loss: 2.8878\n",
      "[732/8000] D loss: 0.8265, G loss: 4.1909\n",
      "[1092/8000] D loss: 0.5689, G loss: 6.0137\n",
      "[1452/8000] D loss: 0.5061, G loss: 5.2457\n",
      "[1812/8000] D loss: 0.7752, G loss: 4.2047\n",
      "[2172/8000] D loss: 1.0193, G loss: 2.0419\n",
      "[2532/8000] D loss: 0.8277, G loss: 2.4521\n",
      "[2892/8000] D loss: 0.6804, G loss: 4.3729\n",
      "[3252/8000] D loss: 0.7765, G loss: 4.4325\n",
      "[3612/8000] D loss: 1.0957, G loss: 4.1222\n",
      "[3972/8000] D loss: 0.2488, G loss: 11.0562\n",
      "[4332/8000] D loss: 0.5276, G loss: 5.4144\n",
      "[4692/8000] D loss: 0.5302, G loss: 6.7110\n",
      "[5052/8000] D loss: 0.8361, G loss: 3.3773\n",
      "[5412/8000] D loss: 0.5173, G loss: 5.9283\n",
      "[5772/8000] D loss: 0.9044, G loss: 1.7355\n",
      "[6132/8000] D loss: 0.4272, G loss: 4.3444\n",
      "[6492/8000] D loss: 0.5969, G loss: 8.3720\n",
      "[6852/8000] D loss: 0.9432, G loss: 3.3766\n",
      "[7212/8000] D loss: 0.6862, G loss: 5.8497\n",
      "[7572/8000] D loss: 0.7075, G loss: 6.2347\n",
      "[7932/8000] D loss: 0.8576, G loss: 3.0956\n",
      "train error: \n",
      " D loss: 0.794452, G loss: 4.439286, D accuracy: 76.6%, cell accuracy: 98.6%, board accuracy: 45.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.764734, G loss: 10.997640, D accuracy: 84.0%, cell accuracy: 98.1%, board accuracy: 21.6% \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7891, G loss: 4.0560\n",
      "[372/8000] D loss: 0.5284, G loss: 7.3555\n",
      "[732/8000] D loss: 0.7367, G loss: 3.2091\n",
      "[1092/8000] D loss: 0.6509, G loss: 8.9411\n",
      "[1452/8000] D loss: 0.4751, G loss: 4.6259\n",
      "[1812/8000] D loss: 0.5862, G loss: 7.6425\n",
      "[2172/8000] D loss: 0.9746, G loss: 5.3983\n",
      "[2532/8000] D loss: 0.7457, G loss: 6.2256\n",
      "[2892/8000] D loss: 0.8380, G loss: 3.7722\n",
      "[3252/8000] D loss: 0.5187, G loss: 8.3528\n",
      "[3612/8000] D loss: 0.9621, G loss: 3.0007\n",
      "[3972/8000] D loss: 0.9154, G loss: 6.8888\n",
      "[4332/8000] D loss: 0.5485, G loss: 5.8531\n",
      "[4692/8000] D loss: 0.7337, G loss: 6.7903\n",
      "[5052/8000] D loss: 0.6979, G loss: 8.0165\n",
      "[5412/8000] D loss: 0.7020, G loss: 3.5496\n",
      "[5772/8000] D loss: 1.0699, G loss: 2.1682\n",
      "[6132/8000] D loss: 0.8007, G loss: 7.0750\n",
      "[6492/8000] D loss: 0.4515, G loss: 9.2922\n",
      "[6852/8000] D loss: 0.6141, G loss: 10.1368\n",
      "[7212/8000] D loss: 0.8755, G loss: 4.9570\n",
      "[7572/8000] D loss: 0.6628, G loss: 5.3143\n",
      "[7932/8000] D loss: 0.8756, G loss: 2.9620\n",
      "train error: \n",
      " D loss: 0.801396, G loss: 3.812768, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 45.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.749151, G loss: 9.833293, D accuracy: 82.8%, cell accuracy: 98.1%, board accuracy: 22.4% \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1104, G loss: 1.8832\n",
      "[372/8000] D loss: 0.8739, G loss: 6.5535\n",
      "[732/8000] D loss: 0.7484, G loss: 5.3613\n",
      "[1092/8000] D loss: 0.9220, G loss: 4.0478\n",
      "[1452/8000] D loss: 1.0300, G loss: 5.7374\n",
      "[1812/8000] D loss: 0.9196, G loss: 4.7561\n",
      "[2172/8000] D loss: 0.7320, G loss: 4.2794\n",
      "[2532/8000] D loss: 0.8378, G loss: 4.7879\n",
      "[2892/8000] D loss: 0.8185, G loss: 3.3582\n",
      "[3252/8000] D loss: 0.8075, G loss: 4.5572\n",
      "[3612/8000] D loss: 0.8518, G loss: 4.5366\n",
      "[3972/8000] D loss: 0.4732, G loss: 4.5487\n",
      "[4332/8000] D loss: 0.8602, G loss: 3.4226\n",
      "[4692/8000] D loss: 0.7029, G loss: 4.3933\n",
      "[5052/8000] D loss: 0.8729, G loss: 1.9804\n",
      "[5412/8000] D loss: 1.2046, G loss: 2.0497\n",
      "[5772/8000] D loss: 0.6444, G loss: 3.8986\n",
      "[6132/8000] D loss: 1.0192, G loss: 5.2654\n",
      "[6492/8000] D loss: 0.7245, G loss: 4.9942\n",
      "[6852/8000] D loss: 0.6494, G loss: 4.8844\n",
      "[7212/8000] D loss: 0.6100, G loss: 3.0981\n",
      "[7572/8000] D loss: 0.7222, G loss: 5.6064\n",
      "[7932/8000] D loss: 0.3639, G loss: 7.4039\n",
      "train error: \n",
      " D loss: 0.782920, G loss: 4.511707, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 46.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.835533, G loss: 11.098511, D accuracy: 79.3%, cell accuracy: 98.2%, board accuracy: 22.7% \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2811, G loss: 8.3291\n",
      "[372/8000] D loss: 0.8310, G loss: 2.5056\n",
      "[732/8000] D loss: 0.8847, G loss: 4.7717\n",
      "[1092/8000] D loss: 0.7158, G loss: 5.4481\n",
      "[1452/8000] D loss: 0.7814, G loss: 3.1910\n",
      "[1812/8000] D loss: 0.7843, G loss: 5.7974\n",
      "[2172/8000] D loss: 0.6956, G loss: 5.5432\n",
      "[2532/8000] D loss: 0.4957, G loss: 6.7702\n",
      "[2892/8000] D loss: 0.6814, G loss: 3.0710\n",
      "[3252/8000] D loss: 0.6293, G loss: 7.1859\n",
      "[3612/8000] D loss: 0.5099, G loss: 5.8308\n",
      "[3972/8000] D loss: 0.3380, G loss: 7.6717\n",
      "[4332/8000] D loss: 0.7189, G loss: 7.1840\n",
      "[4692/8000] D loss: 0.5810, G loss: 6.5152\n",
      "[5052/8000] D loss: 0.9848, G loss: 3.2260\n",
      "[5412/8000] D loss: 0.7719, G loss: 3.8867\n",
      "[5772/8000] D loss: 0.8037, G loss: 4.5344\n",
      "[6132/8000] D loss: 1.0933, G loss: 3.5047\n",
      "[6492/8000] D loss: 0.9499, G loss: 3.2616\n",
      "[6852/8000] D loss: 0.9914, G loss: 2.1142\n",
      "[7212/8000] D loss: 0.7529, G loss: 6.2292\n",
      "[7572/8000] D loss: 0.4834, G loss: 8.7868\n",
      "[7932/8000] D loss: 1.0403, G loss: 3.3820\n",
      "train error: \n",
      " D loss: 0.820442, G loss: 4.091132, D accuracy: 75.7%, cell accuracy: 98.6%, board accuracy: 46.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.748581, G loss: 10.100683, D accuracy: 84.2%, cell accuracy: 98.1%, board accuracy: 22.5% \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6982, G loss: 3.9390\n",
      "[372/8000] D loss: 0.7347, G loss: 3.4813\n",
      "[732/8000] D loss: 1.1544, G loss: 3.9874\n",
      "[1092/8000] D loss: 0.8684, G loss: 5.1187\n",
      "[1452/8000] D loss: 0.8815, G loss: 2.9726\n",
      "[1812/8000] D loss: 0.8301, G loss: 7.4529\n",
      "[2172/8000] D loss: 0.8051, G loss: 4.4269\n",
      "[2532/8000] D loss: 1.0804, G loss: 2.7374\n",
      "[2892/8000] D loss: 0.4540, G loss: 5.3384\n",
      "[3252/8000] D loss: 1.0454, G loss: 2.9155\n",
      "[3612/8000] D loss: 0.8422, G loss: 2.8302\n",
      "[3972/8000] D loss: 1.0618, G loss: 3.7096\n",
      "[4332/8000] D loss: 0.7457, G loss: 7.6053\n",
      "[4692/8000] D loss: 0.6035, G loss: 6.0313\n",
      "[5052/8000] D loss: 0.8611, G loss: 3.5684\n",
      "[5412/8000] D loss: 0.4214, G loss: 5.0102\n",
      "[5772/8000] D loss: 0.8629, G loss: 5.7241\n",
      "[6132/8000] D loss: 0.6486, G loss: 3.7340\n",
      "[6492/8000] D loss: 0.8247, G loss: 4.2653\n",
      "[6852/8000] D loss: 0.5155, G loss: 5.2995\n",
      "[7212/8000] D loss: 0.9490, G loss: 4.8574\n",
      "[7572/8000] D loss: 0.6949, G loss: 6.4943\n",
      "[7932/8000] D loss: 0.6648, G loss: 4.3147\n",
      "train error: \n",
      " D loss: 0.821393, G loss: 4.964511, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 46.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.976307, G loss: 11.679445, D accuracy: 76.9%, cell accuracy: 98.1%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7631, G loss: 3.9480\n",
      "[372/8000] D loss: 0.4602, G loss: 6.8315\n",
      "[732/8000] D loss: 0.8151, G loss: 4.1632\n",
      "[1092/8000] D loss: 1.0509, G loss: 2.1358\n",
      "[1452/8000] D loss: 0.9946, G loss: 1.6206\n",
      "[1812/8000] D loss: 0.3492, G loss: 6.4981\n",
      "[2172/8000] D loss: 0.3268, G loss: 4.3120\n",
      "[2532/8000] D loss: 0.5204, G loss: 6.5124\n",
      "[2892/8000] D loss: 1.0511, G loss: 3.2040\n",
      "[3252/8000] D loss: 0.2224, G loss: 10.2278\n",
      "[3612/8000] D loss: 0.9157, G loss: 4.1218\n",
      "[3972/8000] D loss: 1.0590, G loss: 4.4397\n",
      "[4332/8000] D loss: 1.0780, G loss: 1.9978\n",
      "[4692/8000] D loss: 0.7747, G loss: 3.8806\n",
      "[5052/8000] D loss: 0.7198, G loss: 6.2459\n",
      "[5412/8000] D loss: 0.4385, G loss: 6.0600\n",
      "[5772/8000] D loss: 1.1827, G loss: 2.9928\n",
      "[6132/8000] D loss: 0.8310, G loss: 4.3409\n",
      "[6492/8000] D loss: 0.8193, G loss: 2.4990\n",
      "[6852/8000] D loss: 0.7593, G loss: 3.3482\n",
      "[7212/8000] D loss: 0.7320, G loss: 4.0424\n",
      "[7572/8000] D loss: 0.7973, G loss: 3.1992\n",
      "[7932/8000] D loss: 0.5386, G loss: 6.6753\n",
      "train error: \n",
      " D loss: 0.802949, G loss: 4.508899, D accuracy: 75.5%, cell accuracy: 98.6%, board accuracy: 46.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.891155, G loss: 10.525104, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 23.4% \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8630, G loss: 2.5515\n",
      "[372/8000] D loss: 0.4597, G loss: 8.5273\n",
      "[732/8000] D loss: 0.8087, G loss: 3.0762\n",
      "[1092/8000] D loss: 0.9291, G loss: 3.2705\n",
      "[1452/8000] D loss: 0.7835, G loss: 7.3038\n",
      "[1812/8000] D loss: 0.5870, G loss: 8.7561\n",
      "[2172/8000] D loss: 0.8608, G loss: 2.9509\n",
      "[2532/8000] D loss: 0.6288, G loss: 6.2511\n",
      "[2892/8000] D loss: 0.4882, G loss: 7.2648\n",
      "[3252/8000] D loss: 0.7694, G loss: 4.8716\n",
      "[3612/8000] D loss: 0.6360, G loss: 8.0371\n",
      "[3972/8000] D loss: 0.8394, G loss: 2.1910\n",
      "[4332/8000] D loss: 0.7936, G loss: 2.6060\n",
      "[4692/8000] D loss: 0.9528, G loss: 1.3488\n",
      "[5052/8000] D loss: 0.8499, G loss: 3.0751\n",
      "[5412/8000] D loss: 0.7461, G loss: 6.8856\n",
      "[5772/8000] D loss: 0.6568, G loss: 9.6007\n",
      "[6132/8000] D loss: 0.6225, G loss: 5.6179\n",
      "[6492/8000] D loss: 0.9578, G loss: 4.6049\n",
      "[6852/8000] D loss: 0.9741, G loss: 3.7590\n",
      "[7212/8000] D loss: 0.8456, G loss: 4.2192\n",
      "[7572/8000] D loss: 1.1342, G loss: 0.9519\n",
      "[7932/8000] D loss: 0.7083, G loss: 4.7534\n",
      "train error: \n",
      " D loss: 0.804811, G loss: 4.440835, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 46.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.912124, G loss: 10.705336, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 23.5% \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7818, G loss: 2.4120\n",
      "[372/8000] D loss: 0.9167, G loss: 3.3862\n",
      "[732/8000] D loss: 0.5933, G loss: 3.6894\n",
      "[1092/8000] D loss: 0.6588, G loss: 5.0003\n",
      "[1452/8000] D loss: 0.2788, G loss: 6.2043\n",
      "[1812/8000] D loss: 0.9396, G loss: 2.4534\n",
      "[2172/8000] D loss: 0.7094, G loss: 7.7214\n",
      "[2532/8000] D loss: 0.7135, G loss: 3.2371\n",
      "[2892/8000] D loss: 0.7655, G loss: 5.0144\n",
      "[3252/8000] D loss: 0.9922, G loss: 4.7327\n",
      "[3612/8000] D loss: 0.4469, G loss: 4.5752\n",
      "[3972/8000] D loss: 0.8699, G loss: 3.1199\n",
      "[4332/8000] D loss: 1.0429, G loss: 2.9089\n",
      "[4692/8000] D loss: 0.7273, G loss: 3.1169\n",
      "[5052/8000] D loss: 1.1515, G loss: 5.6806\n",
      "[5412/8000] D loss: 0.6122, G loss: 7.9482\n",
      "[5772/8000] D loss: 0.6547, G loss: 5.2346\n",
      "[6132/8000] D loss: 0.4953, G loss: 5.9080\n",
      "[6492/8000] D loss: 0.6850, G loss: 6.1141\n",
      "[6852/8000] D loss: 0.9049, G loss: 4.0962\n",
      "[7212/8000] D loss: 0.7257, G loss: 5.2819\n",
      "[7572/8000] D loss: 0.8848, G loss: 3.4835\n",
      "[7932/8000] D loss: 0.6127, G loss: 5.8250\n",
      "train error: \n",
      " D loss: 0.799832, G loss: 4.022044, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 46.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.787417, G loss: 10.049421, D accuracy: 82.1%, cell accuracy: 98.1%, board accuracy: 22.4% \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3751, G loss: 6.0303\n",
      "[372/8000] D loss: 0.7536, G loss: 3.0079\n",
      "[732/8000] D loss: 0.8285, G loss: 3.1896\n",
      "[1092/8000] D loss: 0.5333, G loss: 5.6852\n",
      "[1452/8000] D loss: 0.5006, G loss: 8.0708\n",
      "[1812/8000] D loss: 0.7930, G loss: 7.5952\n",
      "[2172/8000] D loss: 0.7297, G loss: 4.5270\n",
      "[2532/8000] D loss: 0.6367, G loss: 5.5893\n",
      "[2892/8000] D loss: 1.0061, G loss: 4.6106\n",
      "[3252/8000] D loss: 0.7137, G loss: 3.9040\n",
      "[3612/8000] D loss: 0.7974, G loss: 4.6372\n",
      "[3972/8000] D loss: 0.7406, G loss: 4.6265\n",
      "[4332/8000] D loss: 0.7154, G loss: 3.9863\n",
      "[4692/8000] D loss: 0.3016, G loss: 5.5183\n",
      "[5052/8000] D loss: 0.7199, G loss: 6.6011\n",
      "[5412/8000] D loss: 0.7426, G loss: 3.9252\n",
      "[5772/8000] D loss: 0.3943, G loss: 6.0666\n",
      "[6132/8000] D loss: 0.6537, G loss: 6.5762\n",
      "[6492/8000] D loss: 1.0966, G loss: 2.6891\n",
      "[6852/8000] D loss: 0.7681, G loss: 5.3691\n",
      "[7212/8000] D loss: 0.6841, G loss: 5.2826\n",
      "[7572/8000] D loss: 0.7741, G loss: 4.1004\n",
      "[7932/8000] D loss: 0.8325, G loss: 3.0462\n",
      "train error: \n",
      " D loss: 0.818270, G loss: 4.235288, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 44.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.717779, G loss: 11.120321, D accuracy: 85.4%, cell accuracy: 98.1%, board accuracy: 20.4% \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4472, G loss: 6.1282\n",
      "[372/8000] D loss: 1.0930, G loss: 6.0823\n",
      "[732/8000] D loss: 0.6212, G loss: 8.5392\n",
      "[1092/8000] D loss: 0.8740, G loss: 2.4428\n",
      "[1452/8000] D loss: 0.5285, G loss: 6.3462\n",
      "[1812/8000] D loss: 0.9056, G loss: 4.2602\n",
      "[2172/8000] D loss: 0.8972, G loss: 2.7522\n",
      "[2532/8000] D loss: 0.4538, G loss: 3.6092\n",
      "[2892/8000] D loss: 0.9338, G loss: 3.9022\n",
      "[3252/8000] D loss: 0.9394, G loss: 5.7843\n",
      "[3612/8000] D loss: 0.7728, G loss: 4.8979\n",
      "[3972/8000] D loss: 0.8045, G loss: 5.3060\n",
      "[4332/8000] D loss: 0.8357, G loss: 3.3069\n",
      "[4692/8000] D loss: 0.8253, G loss: 6.2174\n",
      "[5052/8000] D loss: 0.7595, G loss: 7.2421\n",
      "[5412/8000] D loss: 0.8577, G loss: 3.5712\n",
      "[5772/8000] D loss: 0.9268, G loss: 2.7203\n",
      "[6132/8000] D loss: 0.8974, G loss: 2.4445\n",
      "[6492/8000] D loss: 0.6830, G loss: 4.1971\n",
      "[6852/8000] D loss: 0.8948, G loss: 4.1638\n",
      "[7212/8000] D loss: 0.9189, G loss: 5.2923\n",
      "[7572/8000] D loss: 0.7289, G loss: 3.2611\n",
      "[7932/8000] D loss: 0.6645, G loss: 6.8969\n",
      "train error: \n",
      " D loss: 0.817229, G loss: 3.934998, D accuracy: 75.6%, cell accuracy: 98.6%, board accuracy: 46.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.768301, G loss: 10.138439, D accuracy: 83.8%, cell accuracy: 98.1%, board accuracy: 22.7% \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6689, G loss: 2.9386\n",
      "[372/8000] D loss: 0.5716, G loss: 4.9604\n",
      "[732/8000] D loss: 0.7370, G loss: 5.0429\n",
      "[1092/8000] D loss: 1.0210, G loss: 2.1970\n",
      "[1452/8000] D loss: 0.7364, G loss: 6.3177\n",
      "[1812/8000] D loss: 0.6674, G loss: 6.2975\n",
      "[2172/8000] D loss: 0.4654, G loss: 10.4603\n",
      "[2532/8000] D loss: 0.8752, G loss: 5.8359\n",
      "[2892/8000] D loss: 0.6557, G loss: 3.7000\n",
      "[3252/8000] D loss: 0.9515, G loss: 3.4757\n",
      "[3612/8000] D loss: 0.9460, G loss: 7.6015\n",
      "[3972/8000] D loss: 0.7372, G loss: 4.0801\n",
      "[4332/8000] D loss: 0.8148, G loss: 3.0348\n",
      "[4692/8000] D loss: 0.9195, G loss: 3.5408\n",
      "[5052/8000] D loss: 0.9617, G loss: 4.9110\n",
      "[5412/8000] D loss: 0.7541, G loss: 5.2658\n",
      "[5772/8000] D loss: 1.0848, G loss: 1.9524\n",
      "[6132/8000] D loss: 0.9590, G loss: 3.5963\n",
      "[6492/8000] D loss: 0.7710, G loss: 3.2161\n",
      "[6852/8000] D loss: 0.7427, G loss: 7.1150\n",
      "[7212/8000] D loss: 0.6467, G loss: 5.5581\n",
      "[7572/8000] D loss: 0.4553, G loss: 6.8626\n",
      "[7932/8000] D loss: 0.8537, G loss: 2.3416\n",
      "train error: \n",
      " D loss: 0.845616, G loss: 4.289784, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 46.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.980097, G loss: 10.250103, D accuracy: 75.6%, cell accuracy: 98.2%, board accuracy: 22.7% \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9946, G loss: 5.3549\n",
      "[372/8000] D loss: 1.1077, G loss: 2.2588\n",
      "[732/8000] D loss: 0.9178, G loss: 6.2842\n",
      "[1092/8000] D loss: 0.8726, G loss: 3.7195\n",
      "[1452/8000] D loss: 0.9509, G loss: 3.3614\n",
      "[1812/8000] D loss: 0.9200, G loss: 1.8472\n",
      "[2172/8000] D loss: 0.8602, G loss: 2.9509\n",
      "[2532/8000] D loss: 0.8116, G loss: 2.3490\n",
      "[2892/8000] D loss: 0.8123, G loss: 2.8164\n",
      "[3252/8000] D loss: 1.1422, G loss: 1.5056\n",
      "[3612/8000] D loss: 0.7477, G loss: 5.6197\n",
      "[3972/8000] D loss: 0.6543, G loss: 3.1555\n",
      "[4332/8000] D loss: 1.0634, G loss: 2.5407\n",
      "[4692/8000] D loss: 0.6264, G loss: 3.4548\n",
      "[5052/8000] D loss: 0.7682, G loss: 7.6698\n",
      "[5412/8000] D loss: 0.8019, G loss: 6.3581\n",
      "[5772/8000] D loss: 0.7322, G loss: 6.0784\n",
      "[6132/8000] D loss: 0.6881, G loss: 3.3332\n",
      "[6492/8000] D loss: 0.6782, G loss: 4.1840\n",
      "[6852/8000] D loss: 1.0916, G loss: 2.2741\n",
      "[7212/8000] D loss: 0.5977, G loss: 4.7547\n",
      "[7572/8000] D loss: 0.2518, G loss: 10.1881\n",
      "[7932/8000] D loss: 0.7964, G loss: 6.5735\n",
      "train error: \n",
      " D loss: 0.820735, G loss: 5.169343, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 46.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999034, G loss: 12.088226, D accuracy: 75.3%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7062, G loss: 5.0396\n",
      "[372/8000] D loss: 0.8363, G loss: 2.7065\n",
      "[732/8000] D loss: 0.7849, G loss: 2.9389\n",
      "[1092/8000] D loss: 0.7957, G loss: 2.6665\n",
      "[1452/8000] D loss: 1.0596, G loss: 3.1011\n",
      "[1812/8000] D loss: 0.5365, G loss: 6.6899\n",
      "[2172/8000] D loss: 0.7724, G loss: 4.0074\n",
      "[2532/8000] D loss: 0.6946, G loss: 4.7788\n",
      "[2892/8000] D loss: 0.7526, G loss: 5.6119\n",
      "[3252/8000] D loss: 0.5112, G loss: 4.0912\n",
      "[3612/8000] D loss: 0.8385, G loss: 2.8856\n",
      "[3972/8000] D loss: 0.6954, G loss: 5.7371\n",
      "[4332/8000] D loss: 0.9023, G loss: 4.0086\n",
      "[4692/8000] D loss: 0.7529, G loss: 4.0158\n",
      "[5052/8000] D loss: 1.0160, G loss: 5.0758\n",
      "[5412/8000] D loss: 0.9015, G loss: 5.6590\n",
      "[5772/8000] D loss: 0.6269, G loss: 4.9553\n",
      "[6132/8000] D loss: 0.6153, G loss: 6.4603\n",
      "[6492/8000] D loss: 0.8990, G loss: 2.5389\n",
      "[6852/8000] D loss: 0.9199, G loss: 4.1054\n",
      "[7212/8000] D loss: 0.7360, G loss: 6.9138\n",
      "[7572/8000] D loss: 0.7093, G loss: 4.4398\n",
      "[7932/8000] D loss: 0.8106, G loss: 7.6420\n",
      "train error: \n",
      " D loss: 0.807276, G loss: 4.014472, D accuracy: 75.7%, cell accuracy: 98.6%, board accuracy: 46.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.767151, G loss: 10.661378, D accuracy: 82.1%, cell accuracy: 98.2%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9333, G loss: 4.4077\n",
      "[372/8000] D loss: 0.4742, G loss: 5.9536\n",
      "[732/8000] D loss: 0.7884, G loss: 3.6785\n",
      "[1092/8000] D loss: 0.7550, G loss: 5.2688\n",
      "[1452/8000] D loss: 0.4112, G loss: 5.4024\n",
      "[1812/8000] D loss: 0.9887, G loss: 2.1094\n",
      "[2172/8000] D loss: 0.6409, G loss: 5.6328\n",
      "[2532/8000] D loss: 0.9775, G loss: 2.6315\n",
      "[2892/8000] D loss: 0.8104, G loss: 5.0140\n",
      "[3252/8000] D loss: 0.8997, G loss: 4.6118\n",
      "[3612/8000] D loss: 0.9266, G loss: 3.3501\n",
      "[3972/8000] D loss: 0.7919, G loss: 6.9613\n",
      "[4332/8000] D loss: 0.8305, G loss: 4.8232\n",
      "[4692/8000] D loss: 0.8096, G loss: 4.3621\n",
      "[5052/8000] D loss: 0.7048, G loss: 7.5220\n",
      "[5412/8000] D loss: 1.2297, G loss: 1.5188\n",
      "[5772/8000] D loss: 0.4139, G loss: 6.2733\n",
      "[6132/8000] D loss: 0.8723, G loss: 3.8036\n",
      "[6492/8000] D loss: 0.9534, G loss: 3.5291\n",
      "[6852/8000] D loss: 0.6612, G loss: 7.7992\n",
      "[7212/8000] D loss: 0.6267, G loss: 9.2957\n",
      "[7572/8000] D loss: 0.5673, G loss: 7.1380\n",
      "[7932/8000] D loss: 0.7765, G loss: 5.9135\n",
      "train error: \n",
      " D loss: 0.801978, G loss: 4.123640, D accuracy: 75.9%, cell accuracy: 98.6%, board accuracy: 47.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.798279, G loss: 10.928643, D accuracy: 82.6%, cell accuracy: 98.1%, board accuracy: 22.8% \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0441, G loss: 2.0409\n",
      "[372/8000] D loss: 0.8935, G loss: 7.5555\n",
      "[732/8000] D loss: 0.6306, G loss: 3.3153\n",
      "[1092/8000] D loss: 0.8045, G loss: 6.2724\n",
      "[1452/8000] D loss: 0.8758, G loss: 5.3914\n",
      "[1812/8000] D loss: 0.5424, G loss: 5.7669\n",
      "[2172/8000] D loss: 0.5244, G loss: 7.2439\n",
      "[2532/8000] D loss: 0.9492, G loss: 2.2371\n",
      "[2892/8000] D loss: 0.0483, G loss: 9.8146\n",
      "[3252/8000] D loss: 1.1130, G loss: 3.8601\n",
      "[3612/8000] D loss: 0.9035, G loss: 7.4508\n",
      "[3972/8000] D loss: 0.6821, G loss: 3.7420\n",
      "[4332/8000] D loss: 1.0539, G loss: 1.8832\n",
      "[4692/8000] D loss: 0.7943, G loss: 4.3719\n",
      "[5052/8000] D loss: 0.8699, G loss: 3.7456\n",
      "[5412/8000] D loss: 0.7331, G loss: 7.0872\n",
      "[5772/8000] D loss: 0.9093, G loss: 3.5299\n",
      "[6132/8000] D loss: 0.7925, G loss: 2.7784\n",
      "[6492/8000] D loss: 0.8597, G loss: 3.3790\n",
      "[6852/8000] D loss: 1.1002, G loss: 5.2615\n",
      "[7212/8000] D loss: 0.5726, G loss: 5.1111\n",
      "[7572/8000] D loss: 0.5044, G loss: 5.7219\n",
      "[7932/8000] D loss: 0.6718, G loss: 4.7814\n",
      "train error: \n",
      " D loss: 0.772028, G loss: 4.584977, D accuracy: 76.5%, cell accuracy: 98.6%, board accuracy: 46.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.811657, G loss: 11.326703, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 23.3% \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7856, G loss: 5.0410\n",
      "[372/8000] D loss: 0.6074, G loss: 10.9615\n",
      "[732/8000] D loss: 0.6769, G loss: 7.3152\n",
      "[1092/8000] D loss: 0.5212, G loss: 5.8597\n",
      "[1452/8000] D loss: 0.6350, G loss: 8.5834\n",
      "[1812/8000] D loss: 0.8301, G loss: 3.4243\n",
      "[2172/8000] D loss: 0.7356, G loss: 8.8145\n",
      "[2532/8000] D loss: 0.8347, G loss: 4.6663\n",
      "[2892/8000] D loss: 0.7097, G loss: 5.6634\n",
      "[3252/8000] D loss: 0.8284, G loss: 6.0277\n",
      "[3612/8000] D loss: 0.7380, G loss: 4.1562\n",
      "[3972/8000] D loss: 0.6346, G loss: 3.1091\n",
      "[4332/8000] D loss: 0.7094, G loss: 7.3737\n",
      "[4692/8000] D loss: 0.8181, G loss: 3.4468\n",
      "[5052/8000] D loss: 0.8256, G loss: 3.3554\n",
      "[5412/8000] D loss: 0.6508, G loss: 7.5977\n",
      "[5772/8000] D loss: 0.6668, G loss: 3.8520\n",
      "[6132/8000] D loss: 0.6397, G loss: 7.1426\n",
      "[6492/8000] D loss: 0.6946, G loss: 7.3980\n",
      "[6852/8000] D loss: 0.8453, G loss: 8.1922\n",
      "[7212/8000] D loss: 0.4991, G loss: 7.7903\n",
      "[7572/8000] D loss: 0.6534, G loss: 4.7881\n",
      "[7932/8000] D loss: 0.3763, G loss: 8.3358\n",
      "train error: \n",
      " D loss: 0.832858, G loss: 3.664297, D accuracy: 75.3%, cell accuracy: 98.6%, board accuracy: 46.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.762677, G loss: 9.786313, D accuracy: 83.9%, cell accuracy: 98.1%, board accuracy: 23.1% \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5190, G loss: 4.5398\n",
      "[372/8000] D loss: 0.6756, G loss: 3.1130\n",
      "[732/8000] D loss: 0.9673, G loss: 2.5184\n",
      "[1092/8000] D loss: 0.7831, G loss: 4.3102\n",
      "[1452/8000] D loss: 0.9234, G loss: 4.1104\n",
      "[1812/8000] D loss: 1.1633, G loss: 1.8902\n",
      "[2172/8000] D loss: 0.4267, G loss: 8.8601\n",
      "[2532/8000] D loss: 0.9899, G loss: 4.2621\n",
      "[2892/8000] D loss: 0.6611, G loss: 6.5031\n",
      "[3252/8000] D loss: 0.8964, G loss: 4.0766\n",
      "[3612/8000] D loss: 1.1026, G loss: 2.7707\n",
      "[3972/8000] D loss: 0.5859, G loss: 2.8279\n",
      "[4332/8000] D loss: 0.5565, G loss: 9.3555\n",
      "[4692/8000] D loss: 0.9197, G loss: 2.5313\n",
      "[5052/8000] D loss: 0.7640, G loss: 3.4642\n",
      "[5412/8000] D loss: 0.8703, G loss: 3.3011\n",
      "[5772/8000] D loss: 0.7112, G loss: 5.3054\n",
      "[6132/8000] D loss: 0.9860, G loss: 3.8956\n",
      "[6492/8000] D loss: 0.7537, G loss: 5.3258\n",
      "[6852/8000] D loss: 0.8829, G loss: 3.1171\n",
      "[7212/8000] D loss: 0.4741, G loss: 8.3615\n",
      "[7572/8000] D loss: 1.1644, G loss: 2.3205\n",
      "[7932/8000] D loss: 0.6289, G loss: 3.9980\n",
      "train error: \n",
      " D loss: 0.785445, G loss: 5.366200, D accuracy: 76.7%, cell accuracy: 98.6%, board accuracy: 45.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.905870, G loss: 12.428147, D accuracy: 81.0%, cell accuracy: 98.1%, board accuracy: 22.1% \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8203, G loss: 8.0722\n",
      "[372/8000] D loss: 1.0247, G loss: 2.3143\n",
      "[732/8000] D loss: 0.9858, G loss: 7.0859\n",
      "[1092/8000] D loss: 0.4987, G loss: 6.0111\n",
      "[1452/8000] D loss: 0.5234, G loss: 5.7014\n",
      "[1812/8000] D loss: 0.9148, G loss: 1.5790\n",
      "[2172/8000] D loss: 0.7196, G loss: 6.5641\n",
      "[2532/8000] D loss: 0.9748, G loss: 4.6133\n",
      "[2892/8000] D loss: 1.1342, G loss: 2.1993\n",
      "[3252/8000] D loss: 0.7788, G loss: 4.3960\n",
      "[3612/8000] D loss: 0.9150, G loss: 5.6596\n",
      "[3972/8000] D loss: 1.0692, G loss: 1.5258\n",
      "[4332/8000] D loss: 0.8346, G loss: 4.0150\n",
      "[4692/8000] D loss: 0.6591, G loss: 6.9567\n",
      "[5052/8000] D loss: 0.5836, G loss: 5.6470\n",
      "[5412/8000] D loss: 0.3486, G loss: 9.3217\n",
      "[5772/8000] D loss: 0.6274, G loss: 6.4770\n",
      "[6132/8000] D loss: 0.6610, G loss: 6.5053\n",
      "[6492/8000] D loss: 0.8140, G loss: 3.8515\n",
      "[6852/8000] D loss: 0.8359, G loss: 2.9703\n",
      "[7212/8000] D loss: 0.7743, G loss: 2.9610\n",
      "[7572/8000] D loss: 0.7597, G loss: 6.3137\n",
      "[7932/8000] D loss: 0.4728, G loss: 6.9757\n",
      "train error: \n",
      " D loss: 0.780994, G loss: 5.127715, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 46.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.928618, G loss: 12.418442, D accuracy: 78.4%, cell accuracy: 98.1%, board accuracy: 22.9% \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1829, G loss: 2.3865\n",
      "[372/8000] D loss: 0.6385, G loss: 3.6253\n",
      "[732/8000] D loss: 0.5737, G loss: 4.9607\n",
      "[1092/8000] D loss: 0.8462, G loss: 6.0606\n",
      "[1452/8000] D loss: 0.7558, G loss: 5.0645\n",
      "[1812/8000] D loss: 0.5794, G loss: 6.1174\n",
      "[2172/8000] D loss: 0.6865, G loss: 5.7561\n",
      "[2532/8000] D loss: 0.9919, G loss: 5.0422\n",
      "[2892/8000] D loss: 0.7133, G loss: 6.5135\n",
      "[3252/8000] D loss: 0.7122, G loss: 4.3582\n",
      "[3612/8000] D loss: 0.5394, G loss: 5.0139\n",
      "[3972/8000] D loss: 0.6301, G loss: 4.9384\n",
      "[4332/8000] D loss: 0.9554, G loss: 3.3081\n",
      "[4692/8000] D loss: 0.8498, G loss: 3.9532\n",
      "[5052/8000] D loss: 0.6322, G loss: 4.8059\n",
      "[5412/8000] D loss: 0.8277, G loss: 5.3449\n",
      "[5772/8000] D loss: 0.5487, G loss: 4.0895\n",
      "[6132/8000] D loss: 0.4352, G loss: 7.2755\n",
      "[6492/8000] D loss: 0.7088, G loss: 5.9907\n",
      "[6852/8000] D loss: 0.5516, G loss: 6.4569\n",
      "[7212/8000] D loss: 1.0252, G loss: 3.1185\n",
      "[7572/8000] D loss: 0.8188, G loss: 3.9003\n",
      "[7932/8000] D loss: 0.9195, G loss: 5.5379\n",
      "train error: \n",
      " D loss: 0.792456, G loss: 4.942506, D accuracy: 75.3%, cell accuracy: 98.6%, board accuracy: 47.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.963781, G loss: 11.824305, D accuracy: 77.3%, cell accuracy: 98.2%, board accuracy: 24.7% \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6634, G loss: 5.9343\n",
      "[372/8000] D loss: 0.9742, G loss: 2.9850\n",
      "[732/8000] D loss: 0.8552, G loss: 5.6585\n",
      "[1092/8000] D loss: 1.0247, G loss: 3.6424\n",
      "[1452/8000] D loss: 1.1194, G loss: 5.4106\n",
      "[1812/8000] D loss: 1.0582, G loss: 2.1189\n",
      "[2172/8000] D loss: 0.9315, G loss: 5.9899\n",
      "[2532/8000] D loss: 0.5716, G loss: 7.5554\n",
      "[2892/8000] D loss: 0.7491, G loss: 3.6153\n",
      "[3252/8000] D loss: 0.5917, G loss: 5.5395\n",
      "[3612/8000] D loss: 1.2716, G loss: 2.9524\n",
      "[3972/8000] D loss: 0.6551, G loss: 2.4974\n",
      "[4332/8000] D loss: 0.6873, G loss: 3.7137\n",
      "[4692/8000] D loss: 0.6760, G loss: 4.1636\n",
      "[5052/8000] D loss: 1.0212, G loss: 2.0390\n",
      "[5412/8000] D loss: 0.6293, G loss: 4.5967\n",
      "[5772/8000] D loss: 0.4949, G loss: 4.6127\n",
      "[6132/8000] D loss: 0.5618, G loss: 6.2468\n",
      "[6492/8000] D loss: 0.7882, G loss: 3.8311\n",
      "[6852/8000] D loss: 0.9119, G loss: 3.8626\n",
      "[7212/8000] D loss: 0.9970, G loss: 4.4838\n",
      "[7572/8000] D loss: 0.9973, G loss: 2.1946\n",
      "[7932/8000] D loss: 0.7705, G loss: 2.6420\n",
      "train error: \n",
      " D loss: 0.785948, G loss: 4.907296, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 44.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.855998, G loss: 11.704595, D accuracy: 79.1%, cell accuracy: 98.1%, board accuracy: 22.2% \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9295, G loss: 5.2970\n",
      "[372/8000] D loss: 0.9331, G loss: 3.7134\n",
      "[732/8000] D loss: 0.4993, G loss: 9.6711\n",
      "[1092/8000] D loss: 0.5410, G loss: 5.7034\n",
      "[1452/8000] D loss: 0.5502, G loss: 5.3633\n",
      "[1812/8000] D loss: 1.0733, G loss: 2.6689\n",
      "[2172/8000] D loss: 0.6028, G loss: 6.4980\n",
      "[2532/8000] D loss: 0.8394, G loss: 4.4701\n",
      "[2892/8000] D loss: 0.7386, G loss: 4.1523\n",
      "[3252/8000] D loss: 0.5121, G loss: 4.4132\n",
      "[3612/8000] D loss: 0.8531, G loss: 4.3635\n",
      "[3972/8000] D loss: 1.0157, G loss: 2.3683\n",
      "[4332/8000] D loss: 1.1565, G loss: 5.8831\n",
      "[4692/8000] D loss: 0.7476, G loss: 2.9738\n",
      "[5052/8000] D loss: 0.7726, G loss: 7.2633\n",
      "[5412/8000] D loss: 0.4906, G loss: 5.7824\n",
      "[5772/8000] D loss: 0.7654, G loss: 4.1393\n",
      "[6132/8000] D loss: 0.5408, G loss: 4.6814\n",
      "[6492/8000] D loss: 1.0659, G loss: 3.4964\n",
      "[6852/8000] D loss: 0.7452, G loss: 5.2429\n",
      "[7212/8000] D loss: 0.9855, G loss: 4.4522\n",
      "[7572/8000] D loss: 1.1475, G loss: 3.6478\n",
      "[7932/8000] D loss: 0.4836, G loss: 3.5724\n",
      "train error: \n",
      " D loss: 0.824067, G loss: 5.454814, D accuracy: 74.9%, cell accuracy: 98.6%, board accuracy: 46.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.958206, G loss: 12.899062, D accuracy: 78.5%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6631, G loss: 7.3099\n",
      "[372/8000] D loss: 0.6438, G loss: 4.5247\n",
      "[732/8000] D loss: 1.0037, G loss: 2.0552\n",
      "[1092/8000] D loss: 1.0886, G loss: 2.4612\n",
      "[1452/8000] D loss: 0.6919, G loss: 7.8192\n",
      "[1812/8000] D loss: 0.8901, G loss: 2.3611\n",
      "[2172/8000] D loss: 0.8246, G loss: 5.4999\n",
      "[2532/8000] D loss: 0.7800, G loss: 5.2780\n",
      "[2892/8000] D loss: 0.9835, G loss: 2.3043\n",
      "[3252/8000] D loss: 0.6414, G loss: 5.0018\n",
      "[3612/8000] D loss: 0.6310, G loss: 3.5720\n",
      "[3972/8000] D loss: 1.1177, G loss: 2.3867\n",
      "[4332/8000] D loss: 0.9287, G loss: 3.9954\n",
      "[4692/8000] D loss: 0.5791, G loss: 5.4635\n",
      "[5052/8000] D loss: 0.7458, G loss: 2.9238\n",
      "[5412/8000] D loss: 0.5546, G loss: 4.3081\n",
      "[5772/8000] D loss: 0.6972, G loss: 3.2166\n",
      "[6132/8000] D loss: 0.9272, G loss: 3.0774\n",
      "[6492/8000] D loss: 0.7219, G loss: 5.4395\n",
      "[6852/8000] D loss: 0.4546, G loss: 5.9558\n",
      "[7212/8000] D loss: 0.9117, G loss: 5.1529\n",
      "[7572/8000] D loss: 0.4771, G loss: 7.0597\n",
      "[7932/8000] D loss: 0.9631, G loss: 3.3974\n",
      "train error: \n",
      " D loss: 0.834356, G loss: 5.714693, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 46.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.063517, G loss: 13.222409, D accuracy: 74.0%, cell accuracy: 98.1%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7499, G loss: 5.5897\n",
      "[372/8000] D loss: 0.7026, G loss: 5.6816\n",
      "[732/8000] D loss: 0.6883, G loss: 6.1349\n",
      "[1092/8000] D loss: 0.5673, G loss: 7.7808\n",
      "[1452/8000] D loss: 0.6757, G loss: 5.2161\n",
      "[1812/8000] D loss: 0.8849, G loss: 2.7011\n",
      "[2172/8000] D loss: 0.9511, G loss: 4.5987\n",
      "[2532/8000] D loss: 0.7840, G loss: 5.9639\n",
      "[2892/8000] D loss: 0.8133, G loss: 2.8505\n",
      "[3252/8000] D loss: 0.8762, G loss: 7.1285\n",
      "[3612/8000] D loss: 0.8570, G loss: 4.9854\n",
      "[3972/8000] D loss: 0.9700, G loss: 1.9052\n",
      "[4332/8000] D loss: 0.4506, G loss: 4.6460\n",
      "[4692/8000] D loss: 0.7046, G loss: 6.1956\n",
      "[5052/8000] D loss: 0.5710, G loss: 4.7022\n",
      "[5412/8000] D loss: 0.8671, G loss: 7.0724\n",
      "[5772/8000] D loss: 0.5223, G loss: 4.0073\n",
      "[6132/8000] D loss: 0.8675, G loss: 8.3101\n",
      "[6492/8000] D loss: 0.8470, G loss: 2.7066\n",
      "[6852/8000] D loss: 0.8214, G loss: 2.0463\n",
      "[7212/8000] D loss: 0.9024, G loss: 3.8852\n",
      "[7572/8000] D loss: 0.6999, G loss: 5.1004\n",
      "[7932/8000] D loss: 0.9470, G loss: 5.9946\n",
      "train error: \n",
      " D loss: 0.797032, G loss: 5.072256, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 46.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.785193, G loss: 12.419636, D accuracy: 83.0%, cell accuracy: 98.2%, board accuracy: 23.5% \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8732, G loss: 2.6458\n",
      "[372/8000] D loss: 0.7352, G loss: 5.7514\n",
      "[732/8000] D loss: 0.9037, G loss: 2.1997\n",
      "[1092/8000] D loss: 0.8866, G loss: 5.3058\n",
      "[1452/8000] D loss: 0.6575, G loss: 6.4891\n",
      "[1812/8000] D loss: 1.1864, G loss: 1.7122\n",
      "[2172/8000] D loss: 0.7090, G loss: 5.9105\n",
      "[2532/8000] D loss: 0.7298, G loss: 4.3143\n",
      "[2892/8000] D loss: 1.0766, G loss: 2.7806\n",
      "[3252/8000] D loss: 0.3279, G loss: 6.4577\n",
      "[3612/8000] D loss: 0.5746, G loss: 10.1479\n",
      "[3972/8000] D loss: 1.0221, G loss: 1.6258\n",
      "[4332/8000] D loss: 0.6797, G loss: 9.5400\n",
      "[4692/8000] D loss: 1.0510, G loss: 1.1052\n",
      "[5052/8000] D loss: 0.8708, G loss: 3.9252\n",
      "[5412/8000] D loss: 1.0460, G loss: 2.3729\n",
      "[5772/8000] D loss: 0.9769, G loss: 2.5307\n",
      "[6132/8000] D loss: 0.8576, G loss: 2.6676\n",
      "[6492/8000] D loss: 0.6568, G loss: 5.6575\n",
      "[6852/8000] D loss: 0.7848, G loss: 4.5965\n",
      "[7212/8000] D loss: 0.9451, G loss: 2.3130\n",
      "[7572/8000] D loss: 0.7522, G loss: 3.7371\n",
      "[7932/8000] D loss: 0.6428, G loss: 5.3123\n",
      "train error: \n",
      " D loss: 0.798020, G loss: 4.160385, D accuracy: 75.7%, cell accuracy: 98.6%, board accuracy: 47.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.798798, G loss: 10.952023, D accuracy: 82.8%, cell accuracy: 98.1%, board accuracy: 22.7% \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6278, G loss: 6.1263\n",
      "[372/8000] D loss: 0.6096, G loss: 4.9123\n",
      "[732/8000] D loss: 1.0390, G loss: 4.8877\n",
      "[1092/8000] D loss: 0.6552, G loss: 10.2626\n",
      "[1452/8000] D loss: 0.9475, G loss: 7.8883\n",
      "[1812/8000] D loss: 0.7718, G loss: 2.7694\n",
      "[2172/8000] D loss: 0.5241, G loss: 7.9016\n",
      "[2532/8000] D loss: 0.7704, G loss: 5.6390\n",
      "[2892/8000] D loss: 0.5166, G loss: 7.5091\n",
      "[3252/8000] D loss: 0.6512, G loss: 6.5095\n",
      "[3612/8000] D loss: 0.9659, G loss: 2.3056\n",
      "[3972/8000] D loss: 0.7427, G loss: 5.6154\n",
      "[4332/8000] D loss: 0.5586, G loss: 6.5750\n",
      "[4692/8000] D loss: 0.7734, G loss: 6.6925\n",
      "[5052/8000] D loss: 0.5477, G loss: 5.1134\n",
      "[5412/8000] D loss: 0.9458, G loss: 3.8043\n",
      "[5772/8000] D loss: 0.6456, G loss: 5.5974\n",
      "[6132/8000] D loss: 0.6606, G loss: 2.8057\n",
      "[6492/8000] D loss: 0.4474, G loss: 4.8713\n",
      "[6852/8000] D loss: 0.9377, G loss: 1.4833\n",
      "[7212/8000] D loss: 0.8700, G loss: 3.7976\n",
      "[7572/8000] D loss: 0.9153, G loss: 5.7187\n",
      "[7932/8000] D loss: 1.0123, G loss: 1.8310\n",
      "train error: \n",
      " D loss: 0.791402, G loss: 4.889093, D accuracy: 75.6%, cell accuracy: 98.6%, board accuracy: 47.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.920864, G loss: 12.198783, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 23.4% \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9017, G loss: 4.8905\n",
      "[372/8000] D loss: 0.6583, G loss: 7.4673\n",
      "[732/8000] D loss: 0.7276, G loss: 5.1777\n",
      "[1092/8000] D loss: 0.4463, G loss: 4.8508\n",
      "[1452/8000] D loss: 0.8457, G loss: 3.3838\n",
      "[1812/8000] D loss: 0.8423, G loss: 5.6857\n",
      "[2172/8000] D loss: 0.6767, G loss: 4.6610\n",
      "[2532/8000] D loss: 0.9351, G loss: 3.1372\n",
      "[2892/8000] D loss: 0.6871, G loss: 4.8514\n",
      "[3252/8000] D loss: 0.9265, G loss: 3.3561\n",
      "[3612/8000] D loss: 0.7355, G loss: 4.5536\n",
      "[3972/8000] D loss: 1.2805, G loss: 2.2578\n",
      "[4332/8000] D loss: 0.9845, G loss: 7.5389\n",
      "[4692/8000] D loss: 0.8054, G loss: 3.6098\n",
      "[5052/8000] D loss: 0.7480, G loss: 5.7225\n",
      "[5412/8000] D loss: 0.8153, G loss: 3.2565\n",
      "[5772/8000] D loss: 0.6143, G loss: 5.6910\n",
      "[6132/8000] D loss: 0.4547, G loss: 6.4697\n",
      "[6492/8000] D loss: 0.7282, G loss: 3.8430\n",
      "[6852/8000] D loss: 0.7853, G loss: 3.8544\n",
      "[7212/8000] D loss: 0.7984, G loss: 4.4135\n",
      "[7572/8000] D loss: 0.7672, G loss: 4.1108\n",
      "[7932/8000] D loss: 0.6974, G loss: 6.4879\n",
      "train error: \n",
      " D loss: 0.796777, G loss: 4.677015, D accuracy: 75.9%, cell accuracy: 98.6%, board accuracy: 46.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.840183, G loss: 12.086507, D accuracy: 82.1%, cell accuracy: 98.1%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7851, G loss: 6.6271\n",
      "[372/8000] D loss: 0.6669, G loss: 5.3791\n",
      "[732/8000] D loss: 0.3673, G loss: 16.4275\n",
      "[1092/8000] D loss: 0.5962, G loss: 3.8388\n",
      "[1452/8000] D loss: 0.4272, G loss: 5.7272\n",
      "[1812/8000] D loss: 0.6871, G loss: 7.4227\n",
      "[2172/8000] D loss: 0.7317, G loss: 4.3066\n",
      "[2532/8000] D loss: 0.8673, G loss: 4.6571\n",
      "[2892/8000] D loss: 0.3720, G loss: 6.9612\n",
      "[3252/8000] D loss: 0.6110, G loss: 9.4661\n",
      "[3612/8000] D loss: 0.6254, G loss: 3.7087\n",
      "[3972/8000] D loss: 0.8811, G loss: 4.0836\n",
      "[4332/8000] D loss: 1.1415, G loss: 3.7670\n",
      "[4692/8000] D loss: 0.9205, G loss: 4.9926\n",
      "[5052/8000] D loss: 0.6350, G loss: 5.2544\n",
      "[5412/8000] D loss: 0.7652, G loss: 3.3629\n",
      "[5772/8000] D loss: 0.8377, G loss: 2.8603\n",
      "[6132/8000] D loss: 1.1202, G loss: 1.9227\n",
      "[6492/8000] D loss: 0.8770, G loss: 8.2087\n",
      "[6852/8000] D loss: 0.4451, G loss: 3.9817\n",
      "[7212/8000] D loss: 0.9863, G loss: 3.7601\n",
      "[7572/8000] D loss: 0.7857, G loss: 6.2699\n",
      "[7932/8000] D loss: 0.8571, G loss: 4.0752\n",
      "train error: \n",
      " D loss: 0.822511, G loss: 4.206441, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 46.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.966425, G loss: 10.535340, D accuracy: 77.9%, cell accuracy: 98.1%, board accuracy: 23.6% \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8974, G loss: 3.3643\n",
      "[372/8000] D loss: 1.2819, G loss: 2.4208\n",
      "[732/8000] D loss: 0.9154, G loss: 4.4573\n",
      "[1092/8000] D loss: 0.6205, G loss: 7.6294\n",
      "[1452/8000] D loss: 0.6609, G loss: 4.2542\n",
      "[1812/8000] D loss: 0.7441, G loss: 6.9448\n",
      "[2172/8000] D loss: 0.7567, G loss: 4.6755\n",
      "[2532/8000] D loss: 0.9510, G loss: 4.7472\n",
      "[2892/8000] D loss: 0.4469, G loss: 8.8047\n",
      "[3252/8000] D loss: 0.5071, G loss: 6.7083\n",
      "[3612/8000] D loss: 0.6192, G loss: 5.8932\n",
      "[3972/8000] D loss: 1.1112, G loss: 2.0922\n",
      "[4332/8000] D loss: 0.5567, G loss: 4.1027\n",
      "[4692/8000] D loss: 0.2683, G loss: 8.8237\n",
      "[5052/8000] D loss: 0.6608, G loss: 4.8919\n",
      "[5412/8000] D loss: 0.7489, G loss: 3.3278\n",
      "[5772/8000] D loss: 0.7125, G loss: 4.4246\n",
      "[6132/8000] D loss: 0.5813, G loss: 4.2335\n",
      "[6492/8000] D loss: 0.8004, G loss: 4.0717\n",
      "[6852/8000] D loss: 0.8539, G loss: 3.2394\n",
      "[7212/8000] D loss: 0.9446, G loss: 2.4516\n",
      "[7572/8000] D loss: 0.5308, G loss: 3.6686\n",
      "[7932/8000] D loss: 0.8220, G loss: 5.0839\n",
      "train error: \n",
      " D loss: 0.768653, G loss: 5.277689, D accuracy: 76.2%, cell accuracy: 98.6%, board accuracy: 46.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.890464, G loss: 12.645683, D accuracy: 78.6%, cell accuracy: 98.1%, board accuracy: 23.1% \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8003, G loss: 3.0211\n",
      "[372/8000] D loss: 0.4990, G loss: 6.1314\n",
      "[732/8000] D loss: 0.9538, G loss: 3.9253\n",
      "[1092/8000] D loss: 0.6285, G loss: 4.4844\n",
      "[1452/8000] D loss: 0.9542, G loss: 4.3021\n",
      "[1812/8000] D loss: 0.4418, G loss: 8.4259\n",
      "[2172/8000] D loss: 0.9935, G loss: 4.2426\n",
      "[2532/8000] D loss: 0.9838, G loss: 1.9966\n",
      "[2892/8000] D loss: 0.3907, G loss: 16.5050\n",
      "[3252/8000] D loss: 0.4609, G loss: 11.9512\n",
      "[3612/8000] D loss: 0.8807, G loss: 9.4861\n",
      "[3972/8000] D loss: 0.2299, G loss: 5.4744\n",
      "[4332/8000] D loss: 0.8350, G loss: 5.1743\n",
      "[4692/8000] D loss: 0.7398, G loss: 4.0284\n",
      "[5052/8000] D loss: 0.7738, G loss: 3.3956\n",
      "[5412/8000] D loss: 0.9931, G loss: 4.2241\n",
      "[5772/8000] D loss: 0.5487, G loss: 4.7955\n",
      "[6132/8000] D loss: 0.7770, G loss: 5.8647\n",
      "[6492/8000] D loss: 0.5722, G loss: 8.8462\n",
      "[6852/8000] D loss: 0.7318, G loss: 6.9780\n",
      "[7212/8000] D loss: 0.8325, G loss: 5.8618\n",
      "[7572/8000] D loss: 0.9059, G loss: 4.3515\n",
      "[7932/8000] D loss: 0.8318, G loss: 4.8359\n",
      "train error: \n",
      " D loss: 0.763986, G loss: 4.827929, D accuracy: 76.9%, cell accuracy: 98.6%, board accuracy: 45.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.834065, G loss: 12.043681, D accuracy: 82.6%, cell accuracy: 98.1%, board accuracy: 22.3% \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8610, G loss: 6.2023\n",
      "[372/8000] D loss: 0.6854, G loss: 7.6103\n",
      "[732/8000] D loss: 0.8211, G loss: 4.7446\n",
      "[1092/8000] D loss: 0.5929, G loss: 3.9134\n",
      "[1452/8000] D loss: 0.9117, G loss: 6.4066\n",
      "[1812/8000] D loss: 0.5214, G loss: 8.1606\n",
      "[2172/8000] D loss: 1.1414, G loss: 1.8203\n",
      "[2532/8000] D loss: 0.8907, G loss: 3.7436\n",
      "[2892/8000] D loss: 0.6843, G loss: 4.2514\n",
      "[3252/8000] D loss: 0.9790, G loss: 3.1787\n",
      "[3612/8000] D loss: 0.8771, G loss: 3.4977\n",
      "[3972/8000] D loss: 0.7252, G loss: 4.4919\n",
      "[4332/8000] D loss: 0.7270, G loss: 3.9937\n",
      "[4692/8000] D loss: 0.7961, G loss: 4.1315\n",
      "[5052/8000] D loss: 0.6989, G loss: 6.8600\n",
      "[5412/8000] D loss: 0.8718, G loss: 6.2324\n",
      "[5772/8000] D loss: 0.9362, G loss: 2.6860\n",
      "[6132/8000] D loss: 1.1631, G loss: 1.7385\n",
      "[6492/8000] D loss: 0.9166, G loss: 5.3172\n",
      "[6852/8000] D loss: 0.3958, G loss: 7.8069\n",
      "[7212/8000] D loss: 0.9754, G loss: 3.9025\n",
      "[7572/8000] D loss: 0.7119, G loss: 8.5651\n",
      "[7932/8000] D loss: 0.4962, G loss: 8.3929\n",
      "train error: \n",
      " D loss: 0.774115, G loss: 5.355969, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 46.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.917480, G loss: 12.829061, D accuracy: 79.8%, cell accuracy: 98.1%, board accuracy: 22.4% \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5611, G loss: 7.5753\n",
      "[372/8000] D loss: 0.8795, G loss: 3.1668\n",
      "[732/8000] D loss: 0.9790, G loss: 4.3232\n",
      "[1092/8000] D loss: 0.8245, G loss: 4.0394\n",
      "[1452/8000] D loss: 0.9681, G loss: 3.5881\n",
      "[1812/8000] D loss: 0.6777, G loss: 5.1907\n",
      "[2172/8000] D loss: 0.8254, G loss: 4.4923\n",
      "[2532/8000] D loss: 0.6966, G loss: 5.1165\n",
      "[2892/8000] D loss: 0.6403, G loss: 5.8008\n",
      "[3252/8000] D loss: 0.8642, G loss: 2.8580\n",
      "[3612/8000] D loss: 0.6222, G loss: 6.3066\n",
      "[3972/8000] D loss: 0.8518, G loss: 4.0942\n",
      "[4332/8000] D loss: 0.6194, G loss: 4.9165\n",
      "[4692/8000] D loss: 0.7930, G loss: 5.0715\n",
      "[5052/8000] D loss: 0.4100, G loss: 7.7933\n",
      "[5412/8000] D loss: 0.3550, G loss: 11.6206\n",
      "[5772/8000] D loss: 0.7628, G loss: 3.8714\n",
      "[6132/8000] D loss: 0.8152, G loss: 3.8967\n",
      "[6492/8000] D loss: 0.6800, G loss: 4.0298\n",
      "[6852/8000] D loss: 0.7135, G loss: 3.3753\n",
      "[7212/8000] D loss: 0.8499, G loss: 2.4172\n",
      "[7572/8000] D loss: 0.8521, G loss: 3.9539\n",
      "[7932/8000] D loss: 0.6259, G loss: 5.3114\n",
      "train error: \n",
      " D loss: 0.808302, G loss: 4.375464, D accuracy: 75.4%, cell accuracy: 98.6%, board accuracy: 47.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.814171, G loss: 11.506214, D accuracy: 81.9%, cell accuracy: 98.2%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7696, G loss: 4.6250\n",
      "[372/8000] D loss: 0.9237, G loss: 4.3387\n",
      "[732/8000] D loss: 0.7924, G loss: 6.1268\n",
      "[1092/8000] D loss: 0.9040, G loss: 4.8004\n",
      "[1452/8000] D loss: 0.7197, G loss: 7.5746\n",
      "[1812/8000] D loss: 0.8397, G loss: 7.0320\n",
      "[2172/8000] D loss: 0.4776, G loss: 6.5389\n",
      "[2532/8000] D loss: 0.8985, G loss: 2.9789\n",
      "[2892/8000] D loss: 1.2594, G loss: 2.1279\n",
      "[3252/8000] D loss: 0.6850, G loss: 5.1220\n",
      "[3612/8000] D loss: 1.2060, G loss: 3.0021\n",
      "[3972/8000] D loss: 0.8462, G loss: 2.4020\n",
      "[4332/8000] D loss: 1.2090, G loss: 2.5360\n",
      "[4692/8000] D loss: 0.7386, G loss: 3.1423\n",
      "[5052/8000] D loss: 0.6995, G loss: 4.3179\n",
      "[5412/8000] D loss: 0.8276, G loss: 3.3628\n",
      "[5772/8000] D loss: 0.6487, G loss: 8.7853\n",
      "[6132/8000] D loss: 0.6516, G loss: 8.0958\n",
      "[6492/8000] D loss: 0.8155, G loss: 8.1293\n",
      "[6852/8000] D loss: 0.8534, G loss: 3.9310\n",
      "[7212/8000] D loss: 0.7520, G loss: 4.2808\n",
      "[7572/8000] D loss: 0.7613, G loss: 4.4449\n",
      "[7932/8000] D loss: 0.7581, G loss: 1.8507\n",
      "train error: \n",
      " D loss: 0.774425, G loss: 4.696970, D accuracy: 76.6%, cell accuracy: 98.6%, board accuracy: 46.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.852275, G loss: 11.638305, D accuracy: 81.0%, cell accuracy: 98.1%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6297, G loss: 7.3456\n",
      "[372/8000] D loss: 0.5976, G loss: 4.7257\n",
      "[732/8000] D loss: 0.7873, G loss: 7.0273\n",
      "[1092/8000] D loss: 1.0625, G loss: 3.1003\n",
      "[1452/8000] D loss: 0.7612, G loss: 6.8544\n",
      "[1812/8000] D loss: 0.6809, G loss: 4.7321\n",
      "[2172/8000] D loss: 1.2051, G loss: 2.6947\n",
      "[2532/8000] D loss: 0.4100, G loss: 7.8899\n",
      "[2892/8000] D loss: 0.8452, G loss: 4.3902\n",
      "[3252/8000] D loss: 0.8194, G loss: 5.9166\n",
      "[3612/8000] D loss: 0.3652, G loss: 8.8541\n",
      "[3972/8000] D loss: 0.5241, G loss: 8.6284\n",
      "[4332/8000] D loss: 0.8361, G loss: 3.4494\n",
      "[4692/8000] D loss: 0.7099, G loss: 5.7085\n",
      "[5052/8000] D loss: 0.8310, G loss: 3.3084\n",
      "[5412/8000] D loss: 0.5074, G loss: 6.5151\n",
      "[5772/8000] D loss: 0.6971, G loss: 5.8750\n",
      "[6132/8000] D loss: 0.8220, G loss: 3.4798\n",
      "[6492/8000] D loss: 0.7890, G loss: 5.2585\n",
      "[6852/8000] D loss: 0.7208, G loss: 6.7113\n",
      "[7212/8000] D loss: 0.8911, G loss: 3.7959\n",
      "[7572/8000] D loss: 0.8780, G loss: 2.7558\n",
      "[7932/8000] D loss: 0.5381, G loss: 9.5199\n",
      "train error: \n",
      " D loss: 0.789274, G loss: 4.981060, D accuracy: 75.6%, cell accuracy: 98.6%, board accuracy: 47.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.911054, G loss: 12.312642, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7635, G loss: 5.8704\n",
      "[372/8000] D loss: 0.8623, G loss: 3.4302\n",
      "[732/8000] D loss: 0.7449, G loss: 3.5938\n",
      "[1092/8000] D loss: 0.6912, G loss: 3.9021\n",
      "[1452/8000] D loss: 0.6230, G loss: 5.9085\n",
      "[1812/8000] D loss: 0.5794, G loss: 3.4555\n",
      "[2172/8000] D loss: 0.8033, G loss: 5.8889\n",
      "[2532/8000] D loss: 0.8567, G loss: 2.2252\n",
      "[2892/8000] D loss: 0.9086, G loss: 1.9568\n",
      "[3252/8000] D loss: 0.8387, G loss: 6.6151\n",
      "[3612/8000] D loss: 0.6212, G loss: 7.4986\n",
      "[3972/8000] D loss: 1.0546, G loss: 2.5362\n",
      "[4332/8000] D loss: 0.5925, G loss: 3.6599\n",
      "[4692/8000] D loss: 0.8309, G loss: 4.1900\n",
      "[5052/8000] D loss: 0.6256, G loss: 6.6770\n",
      "[5412/8000] D loss: 0.3885, G loss: 7.1848\n",
      "[5772/8000] D loss: 0.2576, G loss: 5.2726\n",
      "[6132/8000] D loss: 0.9784, G loss: 2.3585\n",
      "[6492/8000] D loss: 0.7172, G loss: 5.0203\n",
      "[6852/8000] D loss: 0.9063, G loss: 3.3564\n",
      "[7212/8000] D loss: 0.7532, G loss: 3.5713\n",
      "[7572/8000] D loss: 0.8473, G loss: 3.6444\n",
      "[7932/8000] D loss: 0.5919, G loss: 4.5194\n",
      "train error: \n",
      " D loss: 0.789591, G loss: 5.043351, D accuracy: 75.9%, cell accuracy: 98.6%, board accuracy: 48.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.812278, G loss: 12.301374, D accuracy: 81.3%, cell accuracy: 98.2%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7304, G loss: 4.7577\n",
      "[372/8000] D loss: 0.8495, G loss: 5.4713\n",
      "[732/8000] D loss: 0.7185, G loss: 5.8390\n",
      "[1092/8000] D loss: 0.8689, G loss: 6.0941\n",
      "[1452/8000] D loss: 0.7045, G loss: 8.0213\n",
      "[1812/8000] D loss: 0.8825, G loss: 5.4431\n",
      "[2172/8000] D loss: 0.6852, G loss: 3.8726\n",
      "[2532/8000] D loss: 0.8221, G loss: 2.7722\n",
      "[2892/8000] D loss: 0.6673, G loss: 7.2527\n",
      "[3252/8000] D loss: 1.0627, G loss: 5.6516\n",
      "[3612/8000] D loss: 0.7012, G loss: 5.2576\n",
      "[3972/8000] D loss: 0.8269, G loss: 3.8314\n",
      "[4332/8000] D loss: 0.9812, G loss: 5.3452\n",
      "[4692/8000] D loss: 0.6297, G loss: 6.6746\n",
      "[5052/8000] D loss: 0.9490, G loss: 2.8459\n",
      "[5412/8000] D loss: 1.0565, G loss: 4.6164\n",
      "[5772/8000] D loss: 0.6231, G loss: 6.8733\n",
      "[6132/8000] D loss: 0.7981, G loss: 2.9987\n",
      "[6492/8000] D loss: 0.7370, G loss: 5.1581\n",
      "[6852/8000] D loss: 1.2657, G loss: 2.4483\n",
      "[7212/8000] D loss: 0.7301, G loss: 2.6457\n",
      "[7572/8000] D loss: 0.9427, G loss: 2.6428\n",
      "[7932/8000] D loss: 0.7814, G loss: 8.4892\n",
      "train error: \n",
      " D loss: 0.805977, G loss: 4.816709, D accuracy: 75.5%, cell accuracy: 98.6%, board accuracy: 47.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.877471, G loss: 12.083489, D accuracy: 81.4%, cell accuracy: 98.1%, board accuracy: 24.4% \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6881, G loss: 4.5108\n",
      "[372/8000] D loss: 0.9169, G loss: 3.5763\n",
      "[732/8000] D loss: 0.9482, G loss: 2.3546\n",
      "[1092/8000] D loss: 0.8714, G loss: 4.9601\n",
      "[1452/8000] D loss: 0.8332, G loss: 4.8707\n",
      "[1812/8000] D loss: 0.3693, G loss: 6.3837\n",
      "[2172/8000] D loss: 1.0261, G loss: 1.8260\n",
      "[2532/8000] D loss: 0.7742, G loss: 5.4036\n",
      "[2892/8000] D loss: 0.8688, G loss: 5.0479\n",
      "[3252/8000] D loss: 0.9303, G loss: 2.5075\n",
      "[3612/8000] D loss: 0.7866, G loss: 2.6706\n",
      "[3972/8000] D loss: 0.8718, G loss: 5.8641\n",
      "[4332/8000] D loss: 1.0435, G loss: 4.5636\n",
      "[4692/8000] D loss: 0.6525, G loss: 7.6487\n",
      "[5052/8000] D loss: 0.7455, G loss: 8.3464\n",
      "[5412/8000] D loss: 0.8984, G loss: 4.8708\n",
      "[5772/8000] D loss: 0.7709, G loss: 6.9905\n",
      "[6132/8000] D loss: 0.7222, G loss: 4.6252\n",
      "[6492/8000] D loss: 1.0531, G loss: 3.2659\n",
      "[6852/8000] D loss: 0.7911, G loss: 4.7235\n",
      "[7212/8000] D loss: 0.7349, G loss: 3.9097\n",
      "[7572/8000] D loss: 0.7351, G loss: 6.0985\n",
      "[7932/8000] D loss: 0.9973, G loss: 1.8639\n",
      "train error: \n",
      " D loss: 0.802325, G loss: 4.500964, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 47.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.872359, G loss: 11.434342, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6751, G loss: 5.0548\n",
      "[372/8000] D loss: 0.6831, G loss: 3.8339\n",
      "[732/8000] D loss: 0.7670, G loss: 5.9261\n",
      "[1092/8000] D loss: 0.7039, G loss: 5.4007\n",
      "[1452/8000] D loss: 0.7666, G loss: 5.9652\n",
      "[1812/8000] D loss: 1.1006, G loss: 3.4550\n",
      "[2172/8000] D loss: 0.9176, G loss: 2.1317\n",
      "[2532/8000] D loss: 0.7361, G loss: 4.7191\n",
      "[2892/8000] D loss: 0.7872, G loss: 5.9346\n",
      "[3252/8000] D loss: 0.5228, G loss: 5.4929\n",
      "[3612/8000] D loss: 0.7200, G loss: 4.7524\n",
      "[3972/8000] D loss: 0.4478, G loss: 7.2707\n",
      "[4332/8000] D loss: 0.6369, G loss: 5.9007\n",
      "[4692/8000] D loss: 0.7704, G loss: 4.5429\n",
      "[5052/8000] D loss: 0.7866, G loss: 4.3078\n",
      "[5412/8000] D loss: 0.8612, G loss: 5.9050\n",
      "[5772/8000] D loss: 0.9612, G loss: 2.6189\n",
      "[6132/8000] D loss: 0.7328, G loss: 4.9774\n",
      "[6492/8000] D loss: 0.6598, G loss: 8.0138\n",
      "[6852/8000] D loss: 0.5519, G loss: 5.1503\n",
      "[7212/8000] D loss: 1.0298, G loss: 4.8520\n",
      "[7572/8000] D loss: 0.4992, G loss: 6.1745\n",
      "[7932/8000] D loss: 0.8335, G loss: 2.0760\n",
      "train error: \n",
      " D loss: 0.788614, G loss: 4.612240, D accuracy: 76.5%, cell accuracy: 98.6%, board accuracy: 46.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.853270, G loss: 11.837270, D accuracy: 82.8%, cell accuracy: 98.1%, board accuracy: 22.1% \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2113, G loss: 2.6117\n",
      "[372/8000] D loss: 1.0226, G loss: 3.6032\n",
      "[732/8000] D loss: 0.8502, G loss: 3.0323\n",
      "[1092/8000] D loss: 0.6753, G loss: 4.1813\n",
      "[1452/8000] D loss: 1.0700, G loss: 1.1248\n",
      "[1812/8000] D loss: 0.7369, G loss: 5.1624\n",
      "[2172/8000] D loss: 0.4552, G loss: 4.5368\n",
      "[2532/8000] D loss: 0.7765, G loss: 6.3143\n",
      "[2892/8000] D loss: 0.7211, G loss: 7.2770\n",
      "[3252/8000] D loss: 1.0601, G loss: 2.1400\n",
      "[3612/8000] D loss: 0.5204, G loss: 7.1228\n",
      "[3972/8000] D loss: 0.7658, G loss: 3.7742\n",
      "[4332/8000] D loss: 0.8422, G loss: 3.5049\n",
      "[4692/8000] D loss: 0.6996, G loss: 8.5421\n",
      "[5052/8000] D loss: 0.7090, G loss: 2.8808\n",
      "[5412/8000] D loss: 0.5565, G loss: 9.7213\n",
      "[5772/8000] D loss: 0.7247, G loss: 2.9838\n",
      "[6132/8000] D loss: 0.7435, G loss: 3.2785\n",
      "[6492/8000] D loss: 0.5425, G loss: 4.1502\n",
      "[6852/8000] D loss: 0.6241, G loss: 5.6025\n",
      "[7212/8000] D loss: 0.5562, G loss: 8.7876\n",
      "[7572/8000] D loss: 0.8234, G loss: 2.7489\n",
      "[7932/8000] D loss: 0.8998, G loss: 4.9887\n",
      "train error: \n",
      " D loss: 0.795945, G loss: 4.920959, D accuracy: 75.3%, cell accuracy: 98.6%, board accuracy: 47.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.952229, G loss: 11.900087, D accuracy: 78.4%, cell accuracy: 98.1%, board accuracy: 22.1% \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0023, G loss: 2.1739\n",
      "[372/8000] D loss: 0.8871, G loss: 6.1191\n",
      "[732/8000] D loss: 0.4351, G loss: 7.3577\n",
      "[1092/8000] D loss: 0.9453, G loss: 1.9671\n",
      "[1452/8000] D loss: 1.0574, G loss: 3.3799\n",
      "[1812/8000] D loss: 0.8691, G loss: 2.2813\n",
      "[2172/8000] D loss: 0.5696, G loss: 8.4977\n",
      "[2532/8000] D loss: 0.7431, G loss: 3.3915\n",
      "[2892/8000] D loss: 0.6971, G loss: 6.7248\n",
      "[3252/8000] D loss: 0.8652, G loss: 4.8330\n",
      "[3612/8000] D loss: 1.0641, G loss: 2.9899\n",
      "[3972/8000] D loss: 0.8976, G loss: 3.6889\n",
      "[4332/8000] D loss: 1.0066, G loss: 4.7468\n",
      "[4692/8000] D loss: 0.4875, G loss: 6.9471\n",
      "[5052/8000] D loss: 0.7125, G loss: 5.1984\n",
      "[5412/8000] D loss: 0.5661, G loss: 4.0681\n",
      "[5772/8000] D loss: 0.6255, G loss: 5.9420\n",
      "[6132/8000] D loss: 0.6857, G loss: 5.5560\n",
      "[6492/8000] D loss: 1.0771, G loss: 4.4107\n",
      "[6852/8000] D loss: 1.1683, G loss: 1.4461\n",
      "[7212/8000] D loss: 0.8640, G loss: 3.0669\n",
      "[7572/8000] D loss: 0.9080, G loss: 4.9325\n",
      "[7932/8000] D loss: 1.1790, G loss: 1.5431\n",
      "train error: \n",
      " D loss: 0.802858, G loss: 4.890513, D accuracy: 75.4%, cell accuracy: 98.6%, board accuracy: 47.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.918995, G loss: 12.458067, D accuracy: 80.1%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6619, G loss: 4.1450\n",
      "[372/8000] D loss: 0.9531, G loss: 5.9443\n",
      "[732/8000] D loss: 1.2469, G loss: 2.7240\n",
      "[1092/8000] D loss: 0.6351, G loss: 4.2864\n",
      "[1452/8000] D loss: 0.4313, G loss: 5.2771\n",
      "[1812/8000] D loss: 1.2778, G loss: 4.8457\n",
      "[2172/8000] D loss: 0.4846, G loss: 6.0140\n",
      "[2532/8000] D loss: 0.7760, G loss: 2.8554\n",
      "[2892/8000] D loss: 0.9275, G loss: 3.9091\n",
      "[3252/8000] D loss: 1.0013, G loss: 2.4309\n",
      "[3612/8000] D loss: 0.9176, G loss: 2.8901\n",
      "[3972/8000] D loss: 0.6566, G loss: 5.5301\n",
      "[4332/8000] D loss: 0.7653, G loss: 4.3899\n",
      "[4692/8000] D loss: 1.1558, G loss: 2.8681\n",
      "[5052/8000] D loss: 0.9693, G loss: 6.9827\n",
      "[5412/8000] D loss: 0.8264, G loss: 4.5733\n",
      "[5772/8000] D loss: 0.8998, G loss: 2.7081\n",
      "[6132/8000] D loss: 1.0131, G loss: 4.3602\n",
      "[6492/8000] D loss: 0.9283, G loss: 2.7642\n",
      "[6852/8000] D loss: 0.9237, G loss: 3.0341\n",
      "[7212/8000] D loss: 0.8213, G loss: 5.5224\n",
      "[7572/8000] D loss: 0.5092, G loss: 7.0034\n",
      "[7932/8000] D loss: 1.1306, G loss: 1.3473\n",
      "train error: \n",
      " D loss: 0.803285, G loss: 4.735746, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 48.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.930403, G loss: 11.899507, D accuracy: 78.0%, cell accuracy: 98.2%, board accuracy: 24.9% \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6086, G loss: 7.3630\n",
      "[372/8000] D loss: 0.4758, G loss: 9.9869\n",
      "[732/8000] D loss: 0.5481, G loss: 5.0443\n",
      "[1092/8000] D loss: 0.5264, G loss: 8.5861\n",
      "[1452/8000] D loss: 0.6479, G loss: 3.7786\n",
      "[1812/8000] D loss: 0.5430, G loss: 10.2876\n",
      "[2172/8000] D loss: 0.7144, G loss: 3.9560\n",
      "[2532/8000] D loss: 0.9909, G loss: 2.4143\n",
      "[2892/8000] D loss: 0.9913, G loss: 3.5251\n",
      "[3252/8000] D loss: 0.9016, G loss: 2.9089\n",
      "[3612/8000] D loss: 1.1224, G loss: 3.6071\n",
      "[3972/8000] D loss: 0.7158, G loss: 4.2922\n",
      "[4332/8000] D loss: 0.6403, G loss: 6.1812\n",
      "[4692/8000] D loss: 0.9290, G loss: 3.5729\n",
      "[5052/8000] D loss: 0.5826, G loss: 9.3237\n",
      "[5412/8000] D loss: 0.4674, G loss: 5.8260\n",
      "[5772/8000] D loss: 1.0012, G loss: 1.9956\n",
      "[6132/8000] D loss: 0.8437, G loss: 5.3127\n",
      "[6492/8000] D loss: 1.0071, G loss: 3.4998\n",
      "[6852/8000] D loss: 0.8823, G loss: 2.0831\n",
      "[7212/8000] D loss: 1.0733, G loss: 1.8345\n",
      "[7572/8000] D loss: 0.9621, G loss: 8.0353\n",
      "[7932/8000] D loss: 0.6205, G loss: 7.0986\n",
      "train error: \n",
      " D loss: 0.800965, G loss: 4.716608, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 47.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.838362, G loss: 12.001215, D accuracy: 80.3%, cell accuracy: 98.1%, board accuracy: 22.8% \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8167, G loss: 6.2513\n",
      "[372/8000] D loss: 0.6307, G loss: 7.1211\n",
      "[732/8000] D loss: 0.7389, G loss: 5.3692\n",
      "[1092/8000] D loss: 1.1174, G loss: 2.5033\n",
      "[1452/8000] D loss: 0.6790, G loss: 3.2424\n",
      "[1812/8000] D loss: 0.7011, G loss: 3.7881\n",
      "[2172/8000] D loss: 0.7227, G loss: 4.6718\n",
      "[2532/8000] D loss: 0.6479, G loss: 4.8177\n",
      "[2892/8000] D loss: 0.6998, G loss: 6.1509\n",
      "[3252/8000] D loss: 0.8123, G loss: 4.7761\n",
      "[3612/8000] D loss: 0.9495, G loss: 4.7321\n",
      "[3972/8000] D loss: 0.9148, G loss: 3.7141\n",
      "[4332/8000] D loss: 0.9662, G loss: 5.2327\n",
      "[4692/8000] D loss: 0.2520, G loss: 10.0436\n",
      "[5052/8000] D loss: 0.6827, G loss: 2.9660\n",
      "[5412/8000] D loss: 0.8264, G loss: 5.2730\n",
      "[5772/8000] D loss: 0.7374, G loss: 4.4280\n",
      "[6132/8000] D loss: 0.4916, G loss: 4.2450\n",
      "[6492/8000] D loss: 0.9805, G loss: 5.8694\n",
      "[6852/8000] D loss: 0.6471, G loss: 7.0809\n",
      "[7212/8000] D loss: 0.7093, G loss: 3.4967\n",
      "[7572/8000] D loss: 1.0414, G loss: 2.0848\n",
      "[7932/8000] D loss: 0.7424, G loss: 4.2548\n",
      "train error: \n",
      " D loss: 0.808305, G loss: 4.241328, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 47.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.920137, G loss: 10.776612, D accuracy: 80.2%, cell accuracy: 98.1%, board accuracy: 24.8% \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7431, G loss: 6.2209\n",
      "[372/8000] D loss: 0.5677, G loss: 9.1441\n",
      "[732/8000] D loss: 0.9680, G loss: 2.0113\n",
      "[1092/8000] D loss: 1.1016, G loss: 2.8612\n",
      "[1452/8000] D loss: 0.8399, G loss: 2.4847\n",
      "[1812/8000] D loss: 0.9980, G loss: 2.5538\n",
      "[2172/8000] D loss: 0.8980, G loss: 2.3552\n",
      "[2532/8000] D loss: 0.7833, G loss: 3.4000\n",
      "[2892/8000] D loss: 0.5433, G loss: 5.6384\n",
      "[3252/8000] D loss: 0.7590, G loss: 7.0275\n",
      "[3612/8000] D loss: 1.1626, G loss: 3.4858\n",
      "[3972/8000] D loss: 0.9384, G loss: 3.5362\n",
      "[4332/8000] D loss: 0.9087, G loss: 4.8999\n",
      "[4692/8000] D loss: 0.8417, G loss: 4.0962\n",
      "[5052/8000] D loss: 0.6822, G loss: 5.4930\n",
      "[5412/8000] D loss: 0.6917, G loss: 5.3689\n",
      "[5772/8000] D loss: 0.8373, G loss: 3.4088\n",
      "[6132/8000] D loss: 0.5566, G loss: 3.5429\n",
      "[6492/8000] D loss: 0.6171, G loss: 4.2477\n",
      "[6852/8000] D loss: 0.9762, G loss: 3.6898\n",
      "[7212/8000] D loss: 0.9152, G loss: 6.4152\n",
      "[7572/8000] D loss: 0.8161, G loss: 3.1095\n",
      "[7932/8000] D loss: 0.5557, G loss: 4.3576\n",
      "train error: \n",
      " D loss: 0.849151, G loss: 5.570475, D accuracy: 73.8%, cell accuracy: 98.6%, board accuracy: 47.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.118776, G loss: 12.875975, D accuracy: 74.2%, cell accuracy: 98.2%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6546, G loss: 5.1305\n",
      "[372/8000] D loss: 0.8612, G loss: 4.8140\n",
      "[732/8000] D loss: 0.4941, G loss: 7.2590\n",
      "[1092/8000] D loss: 0.6250, G loss: 4.3733\n",
      "[1452/8000] D loss: 0.4605, G loss: 9.9527\n",
      "[1812/8000] D loss: 0.8381, G loss: 5.2029\n",
      "[2172/8000] D loss: 0.9890, G loss: 1.7171\n",
      "[2532/8000] D loss: 0.9744, G loss: 4.2070\n",
      "[2892/8000] D loss: 0.7464, G loss: 6.8978\n",
      "[3252/8000] D loss: 0.6450, G loss: 4.7322\n",
      "[3612/8000] D loss: 1.0464, G loss: 1.9931\n",
      "[3972/8000] D loss: 0.7601, G loss: 5.6794\n",
      "[4332/8000] D loss: 0.6927, G loss: 6.5243\n",
      "[4692/8000] D loss: 0.4321, G loss: 5.9954\n",
      "[5052/8000] D loss: 0.8335, G loss: 4.5291\n",
      "[5412/8000] D loss: 1.1648, G loss: 2.3928\n",
      "[5772/8000] D loss: 0.8771, G loss: 3.5031\n",
      "[6132/8000] D loss: 0.5152, G loss: 8.0247\n",
      "[6492/8000] D loss: 0.7346, G loss: 3.0332\n",
      "[6852/8000] D loss: 0.6019, G loss: 3.6243\n",
      "[7212/8000] D loss: 0.9096, G loss: 3.3789\n",
      "[7572/8000] D loss: 1.0910, G loss: 2.9883\n",
      "[7932/8000] D loss: 0.6995, G loss: 6.6876\n",
      "train error: \n",
      " D loss: 0.791589, G loss: 4.321727, D accuracy: 75.6%, cell accuracy: 98.6%, board accuracy: 47.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.870311, G loss: 11.263533, D accuracy: 81.3%, cell accuracy: 98.1%, board accuracy: 23.1% \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8446, G loss: 6.2442\n",
      "[372/8000] D loss: 0.6086, G loss: 7.1983\n",
      "[732/8000] D loss: 0.9436, G loss: 1.7389\n",
      "[1092/8000] D loss: 0.7697, G loss: 3.9409\n",
      "[1452/8000] D loss: 0.9261, G loss: 3.1323\n",
      "[1812/8000] D loss: 0.8601, G loss: 3.0256\n",
      "[2172/8000] D loss: 0.5307, G loss: 6.4773\n",
      "[2532/8000] D loss: 0.8409, G loss: 3.7242\n",
      "[2892/8000] D loss: 0.3709, G loss: 7.0107\n",
      "[3252/8000] D loss: 0.5782, G loss: 3.3909\n",
      "[3612/8000] D loss: 0.4978, G loss: 6.6279\n",
      "[3972/8000] D loss: 0.6428, G loss: 5.7534\n",
      "[4332/8000] D loss: 0.6062, G loss: 5.7049\n",
      "[4692/8000] D loss: 0.8952, G loss: 2.9581\n",
      "[5052/8000] D loss: 0.5259, G loss: 5.9023\n",
      "[5412/8000] D loss: 0.6842, G loss: 4.1783\n",
      "[5772/8000] D loss: 0.6108, G loss: 6.2604\n",
      "[6132/8000] D loss: 0.7983, G loss: 4.1145\n",
      "[6492/8000] D loss: 0.6815, G loss: 6.9414\n",
      "[6852/8000] D loss: 0.7855, G loss: 3.0557\n",
      "[7212/8000] D loss: 1.0109, G loss: 4.5930\n",
      "[7572/8000] D loss: 1.1659, G loss: 2.6465\n",
      "[7932/8000] D loss: 0.7033, G loss: 4.8659\n",
      "train error: \n",
      " D loss: 0.808611, G loss: 4.354768, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 48.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.917319, G loss: 11.228806, D accuracy: 79.8%, cell accuracy: 98.2%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6048, G loss: 6.1400\n",
      "[372/8000] D loss: 0.7292, G loss: 5.1385\n",
      "[732/8000] D loss: 1.1338, G loss: 1.7489\n",
      "[1092/8000] D loss: 0.8586, G loss: 3.8243\n",
      "[1452/8000] D loss: 1.0978, G loss: 1.7647\n",
      "[1812/8000] D loss: 0.9506, G loss: 5.4633\n",
      "[2172/8000] D loss: 0.7523, G loss: 6.5649\n",
      "[2532/8000] D loss: 0.9305, G loss: 7.4750\n",
      "[2892/8000] D loss: 0.6845, G loss: 4.7441\n",
      "[3252/8000] D loss: 0.8843, G loss: 2.6812\n",
      "[3612/8000] D loss: 0.8556, G loss: 7.1079\n",
      "[3972/8000] D loss: 1.2222, G loss: 1.7662\n",
      "[4332/8000] D loss: 0.8481, G loss: 2.7840\n",
      "[4692/8000] D loss: 0.6545, G loss: 6.8171\n",
      "[5052/8000] D loss: 0.9008, G loss: 7.5725\n",
      "[5412/8000] D loss: 0.7824, G loss: 3.5817\n",
      "[5772/8000] D loss: 0.6393, G loss: 5.2948\n",
      "[6132/8000] D loss: 0.6032, G loss: 6.4724\n",
      "[6492/8000] D loss: 1.2014, G loss: 1.2337\n",
      "[6852/8000] D loss: 0.9205, G loss: 3.3933\n",
      "[7212/8000] D loss: 1.0196, G loss: 5.2214\n",
      "[7572/8000] D loss: 0.8792, G loss: 2.1026\n",
      "[7932/8000] D loss: 0.8442, G loss: 3.2526\n",
      "train error: \n",
      " D loss: 0.799825, G loss: 4.864824, D accuracy: 75.3%, cell accuracy: 98.6%, board accuracy: 47.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.895586, G loss: 12.338628, D accuracy: 78.3%, cell accuracy: 98.1%, board accuracy: 22.4% \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7517, G loss: 5.6769\n",
      "[372/8000] D loss: 0.5450, G loss: 6.2427\n",
      "[732/8000] D loss: 0.9824, G loss: 3.9352\n",
      "[1092/8000] D loss: 0.6188, G loss: 4.9655\n",
      "[1452/8000] D loss: 0.9353, G loss: 2.6672\n",
      "[1812/8000] D loss: 0.6476, G loss: 7.3192\n",
      "[2172/8000] D loss: 0.7048, G loss: 6.3054\n",
      "[2532/8000] D loss: 0.7514, G loss: 6.0090\n",
      "[2892/8000] D loss: 0.8432, G loss: 4.9339\n",
      "[3252/8000] D loss: 0.9060, G loss: 3.0172\n",
      "[3612/8000] D loss: 0.5942, G loss: 6.2978\n",
      "[3972/8000] D loss: 0.7169, G loss: 11.6647\n",
      "[4332/8000] D loss: 0.6709, G loss: 6.4080\n",
      "[4692/8000] D loss: 1.0304, G loss: 4.3512\n",
      "[5052/8000] D loss: 0.6073, G loss: 11.0589\n",
      "[5412/8000] D loss: 0.5384, G loss: 7.5549\n",
      "[5772/8000] D loss: 0.7496, G loss: 3.8862\n",
      "[6132/8000] D loss: 0.5228, G loss: 4.1281\n",
      "[6492/8000] D loss: 0.9365, G loss: 2.7661\n",
      "[6852/8000] D loss: 0.7269, G loss: 5.7774\n",
      "[7212/8000] D loss: 0.8046, G loss: 4.2475\n",
      "[7572/8000] D loss: 0.9275, G loss: 5.3848\n",
      "[7932/8000] D loss: 0.7568, G loss: 4.1138\n",
      "train error: \n",
      " D loss: 0.809461, G loss: 4.316763, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 47.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.853287, G loss: 10.986444, D accuracy: 80.9%, cell accuracy: 98.1%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.3889, G loss: 0.7398\n",
      "[372/8000] D loss: 1.0614, G loss: 3.4513\n",
      "[732/8000] D loss: 0.7354, G loss: 6.2710\n",
      "[1092/8000] D loss: 0.5574, G loss: 9.1402\n",
      "[1452/8000] D loss: 0.5463, G loss: 6.3509\n",
      "[1812/8000] D loss: 0.9522, G loss: 6.0319\n",
      "[2172/8000] D loss: 1.0811, G loss: 4.0430\n",
      "[2532/8000] D loss: 0.7759, G loss: 3.2983\n",
      "[2892/8000] D loss: 0.4990, G loss: 4.2755\n",
      "[3252/8000] D loss: 0.8141, G loss: 3.1107\n",
      "[3612/8000] D loss: 1.0897, G loss: 2.6409\n",
      "[3972/8000] D loss: 0.6095, G loss: 7.0802\n",
      "[4332/8000] D loss: 0.5398, G loss: 5.3447\n",
      "[4692/8000] D loss: 0.8523, G loss: 3.4942\n",
      "[5052/8000] D loss: 0.6986, G loss: 4.3713\n",
      "[5412/8000] D loss: 0.9664, G loss: 5.7212\n",
      "[5772/8000] D loss: 0.6802, G loss: 7.0529\n",
      "[6132/8000] D loss: 0.9606, G loss: 4.6614\n",
      "[6492/8000] D loss: 0.7249, G loss: 3.1233\n",
      "[6852/8000] D loss: 0.5675, G loss: 5.6774\n",
      "[7212/8000] D loss: 0.9721, G loss: 2.9762\n",
      "[7572/8000] D loss: 0.6138, G loss: 3.5973\n",
      "[7932/8000] D loss: 0.4335, G loss: 7.2474\n",
      "train error: \n",
      " D loss: 0.819638, G loss: 3.965965, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 47.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.780251, G loss: 10.828920, D accuracy: 83.5%, cell accuracy: 98.1%, board accuracy: 23.0% \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2124, G loss: 3.2730\n",
      "[372/8000] D loss: 0.7563, G loss: 3.9988\n",
      "[732/8000] D loss: 1.0104, G loss: 3.0926\n",
      "[1092/8000] D loss: 1.0604, G loss: 3.5075\n",
      "[1452/8000] D loss: 0.7953, G loss: 3.9750\n",
      "[1812/8000] D loss: 1.1522, G loss: 2.5105\n",
      "[2172/8000] D loss: 1.0062, G loss: 3.2165\n",
      "[2532/8000] D loss: 0.9196, G loss: 2.5929\n",
      "[2892/8000] D loss: 0.7103, G loss: 5.4824\n",
      "[3252/8000] D loss: 0.8910, G loss: 6.1198\n",
      "[3612/8000] D loss: 0.8983, G loss: 5.7218\n",
      "[3972/8000] D loss: 0.6881, G loss: 2.5871\n",
      "[4332/8000] D loss: 1.1715, G loss: 2.3777\n",
      "[4692/8000] D loss: 1.0177, G loss: 2.8809\n",
      "[5052/8000] D loss: 0.7775, G loss: 6.0289\n",
      "[5412/8000] D loss: 0.5584, G loss: 9.1011\n",
      "[5772/8000] D loss: 1.0094, G loss: 1.3597\n",
      "[6132/8000] D loss: 1.0864, G loss: 4.6176\n",
      "[6492/8000] D loss: 0.7185, G loss: 6.0271\n",
      "[6852/8000] D loss: 0.8737, G loss: 3.4944\n",
      "[7212/8000] D loss: 0.7606, G loss: 2.3967\n",
      "[7572/8000] D loss: 0.7768, G loss: 4.3391\n",
      "[7932/8000] D loss: 0.6854, G loss: 5.6222\n",
      "train error: \n",
      " D loss: 0.804324, G loss: 4.309538, D accuracy: 75.5%, cell accuracy: 98.6%, board accuracy: 47.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.783868, G loss: 11.386495, D accuracy: 82.0%, cell accuracy: 98.2%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1905, G loss: 2.0054\n",
      "[372/8000] D loss: 0.7629, G loss: 3.7024\n",
      "[732/8000] D loss: 0.8051, G loss: 2.3377\n",
      "[1092/8000] D loss: 1.3009, G loss: 1.7820\n",
      "[1452/8000] D loss: 0.7474, G loss: 5.9843\n",
      "[1812/8000] D loss: 0.6946, G loss: 3.6418\n",
      "[2172/8000] D loss: 0.8660, G loss: 6.1181\n",
      "[2532/8000] D loss: 0.9516, G loss: 2.9452\n",
      "[2892/8000] D loss: 0.7054, G loss: 5.2214\n",
      "[3252/8000] D loss: 0.9146, G loss: 2.8341\n",
      "[3612/8000] D loss: 0.8041, G loss: 3.0783\n",
      "[3972/8000] D loss: 0.7830, G loss: 3.4560\n",
      "[4332/8000] D loss: 0.7978, G loss: 9.2781\n",
      "[4692/8000] D loss: 0.8939, G loss: 3.1614\n",
      "[5052/8000] D loss: 0.7276, G loss: 3.5181\n",
      "[5412/8000] D loss: 0.8571, G loss: 2.9973\n",
      "[5772/8000] D loss: 0.7890, G loss: 3.8144\n",
      "[6132/8000] D loss: 0.6902, G loss: 5.4431\n",
      "[6492/8000] D loss: 0.8772, G loss: 4.0162\n",
      "[6852/8000] D loss: 0.9477, G loss: 4.1943\n",
      "[7212/8000] D loss: 0.6013, G loss: 7.1072\n",
      "[7572/8000] D loss: 0.8961, G loss: 5.3994\n",
      "[7932/8000] D loss: 1.0482, G loss: 6.6461\n",
      "train error: \n",
      " D loss: 0.847154, G loss: 4.142164, D accuracy: 74.6%, cell accuracy: 98.6%, board accuracy: 48.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.839818, G loss: 11.094639, D accuracy: 83.3%, cell accuracy: 98.1%, board accuracy: 22.5% \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6588, G loss: 7.2549\n",
      "[372/8000] D loss: 0.3747, G loss: 6.1334\n",
      "[732/8000] D loss: 0.1641, G loss: 6.7373\n",
      "[1092/8000] D loss: 0.7084, G loss: 6.9211\n",
      "[1452/8000] D loss: 1.1049, G loss: 4.9741\n",
      "[1812/8000] D loss: 0.5463, G loss: 6.0676\n",
      "[2172/8000] D loss: 0.8086, G loss: 3.2819\n",
      "[2532/8000] D loss: 0.7094, G loss: 6.0255\n",
      "[2892/8000] D loss: 0.6071, G loss: 6.0834\n",
      "[3252/8000] D loss: 0.9690, G loss: 1.5762\n",
      "[3612/8000] D loss: 0.7130, G loss: 3.7488\n",
      "[3972/8000] D loss: 0.7060, G loss: 4.5702\n",
      "[4332/8000] D loss: 0.4792, G loss: 8.1483\n",
      "[4692/8000] D loss: 0.4137, G loss: 6.5188\n",
      "[5052/8000] D loss: 0.6160, G loss: 2.9457\n",
      "[5412/8000] D loss: 0.7205, G loss: 6.8238\n",
      "[5772/8000] D loss: 0.6614, G loss: 4.1303\n",
      "[6132/8000] D loss: 0.9271, G loss: 5.1570\n",
      "[6492/8000] D loss: 0.5757, G loss: 4.8314\n",
      "[6852/8000] D loss: 0.9279, G loss: 2.4957\n",
      "[7212/8000] D loss: 0.5707, G loss: 5.8262\n",
      "[7572/8000] D loss: 0.8566, G loss: 6.5215\n",
      "[7932/8000] D loss: 0.6458, G loss: 8.2164\n",
      "train error: \n",
      " D loss: 0.791039, G loss: 4.791332, D accuracy: 75.8%, cell accuracy: 98.6%, board accuracy: 47.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.836028, G loss: 12.374699, D accuracy: 81.7%, cell accuracy: 98.1%, board accuracy: 23.0% \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6603, G loss: 3.2451\n",
      "[372/8000] D loss: 0.5081, G loss: 5.7629\n",
      "[732/8000] D loss: 0.7776, G loss: 2.2203\n",
      "[1092/8000] D loss: 0.8266, G loss: 5.4825\n",
      "[1452/8000] D loss: 0.8694, G loss: 2.6067\n",
      "[1812/8000] D loss: 0.4176, G loss: 6.5350\n",
      "[2172/8000] D loss: 0.5980, G loss: 5.1837\n",
      "[2532/8000] D loss: 0.8773, G loss: 4.0182\n",
      "[2892/8000] D loss: 0.6683, G loss: 5.0277\n",
      "[3252/8000] D loss: 1.0893, G loss: 3.2474\n",
      "[3612/8000] D loss: 0.6249, G loss: 6.6740\n",
      "[3972/8000] D loss: 1.1083, G loss: 2.0870\n",
      "[4332/8000] D loss: 0.5812, G loss: 4.1277\n",
      "[4692/8000] D loss: 0.8870, G loss: 3.5310\n",
      "[5052/8000] D loss: 0.9848, G loss: 4.3517\n",
      "[5412/8000] D loss: 0.6877, G loss: 6.3915\n",
      "[5772/8000] D loss: 0.9039, G loss: 5.5020\n",
      "[6132/8000] D loss: 1.1446, G loss: 2.6018\n",
      "[6492/8000] D loss: 0.5953, G loss: 5.3096\n",
      "[6852/8000] D loss: 0.8359, G loss: 6.1641\n",
      "[7212/8000] D loss: 0.9612, G loss: 2.9223\n",
      "[7572/8000] D loss: 0.7199, G loss: 7.0299\n",
      "[7932/8000] D loss: 0.8946, G loss: 3.8693\n",
      "train error: \n",
      " D loss: 0.792070, G loss: 4.787261, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 46.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.788211, G loss: 12.344948, D accuracy: 83.8%, cell accuracy: 98.1%, board accuracy: 21.3% \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7040, G loss: 6.9552\n",
      "[372/8000] D loss: 0.6904, G loss: 5.0212\n",
      "[732/8000] D loss: 0.7212, G loss: 4.7591\n",
      "[1092/8000] D loss: 0.7819, G loss: 4.6611\n",
      "[1452/8000] D loss: 0.9854, G loss: 3.0531\n",
      "[1812/8000] D loss: 0.9932, G loss: 2.7994\n",
      "[2172/8000] D loss: 0.7255, G loss: 4.5118\n",
      "[2532/8000] D loss: 0.7157, G loss: 5.3252\n",
      "[2892/8000] D loss: 0.6107, G loss: 5.0500\n",
      "[3252/8000] D loss: 0.7099, G loss: 3.1410\n",
      "[3612/8000] D loss: 1.0111, G loss: 2.3469\n",
      "[3972/8000] D loss: 0.8666, G loss: 3.4554\n",
      "[4332/8000] D loss: 0.7668, G loss: 4.1374\n",
      "[4692/8000] D loss: 0.9624, G loss: 1.9950\n",
      "[5052/8000] D loss: 1.0496, G loss: 2.8295\n",
      "[5412/8000] D loss: 0.6566, G loss: 6.7429\n",
      "[5772/8000] D loss: 0.7257, G loss: 3.9351\n",
      "[6132/8000] D loss: 0.8123, G loss: 7.4870\n",
      "[6492/8000] D loss: 0.8709, G loss: 2.5898\n",
      "[6852/8000] D loss: 0.7794, G loss: 4.9444\n",
      "[7212/8000] D loss: 0.7732, G loss: 6.5785\n",
      "[7572/8000] D loss: 1.0559, G loss: 2.7616\n",
      "[7932/8000] D loss: 0.7338, G loss: 6.9408\n",
      "train error: \n",
      " D loss: 0.806851, G loss: 4.273198, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 49.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.876505, G loss: 11.350175, D accuracy: 80.6%, cell accuracy: 98.2%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5594, G loss: 4.1035\n",
      "[372/8000] D loss: 0.9140, G loss: 2.8464\n",
      "[732/8000] D loss: 0.9585, G loss: 6.4053\n",
      "[1092/8000] D loss: 0.9667, G loss: 2.8006\n",
      "[1452/8000] D loss: 1.1258, G loss: 2.5298\n",
      "[1812/8000] D loss: 0.5234, G loss: 3.9983\n",
      "[2172/8000] D loss: 0.6262, G loss: 6.5680\n",
      "[2532/8000] D loss: 0.2092, G loss: 11.8510\n",
      "[2892/8000] D loss: 0.7307, G loss: 3.8084\n",
      "[3252/8000] D loss: 1.0428, G loss: 3.6825\n",
      "[3612/8000] D loss: 0.8723, G loss: 3.3626\n",
      "[3972/8000] D loss: 1.2245, G loss: 2.4959\n",
      "[4332/8000] D loss: 0.4139, G loss: 9.8927\n",
      "[4692/8000] D loss: 0.8454, G loss: 2.4103\n",
      "[5052/8000] D loss: 0.6950, G loss: 5.5151\n",
      "[5412/8000] D loss: 0.6923, G loss: 4.1313\n",
      "[5772/8000] D loss: 0.7489, G loss: 7.3052\n",
      "[6132/8000] D loss: 0.7881, G loss: 4.2928\n",
      "[6492/8000] D loss: 0.9258, G loss: 3.5008\n",
      "[6852/8000] D loss: 0.8228, G loss: 4.2871\n",
      "[7212/8000] D loss: 0.7444, G loss: 3.3868\n",
      "[7572/8000] D loss: 0.5452, G loss: 11.6945\n",
      "[7932/8000] D loss: 0.9703, G loss: 4.0629\n",
      "train error: \n",
      " D loss: 0.843455, G loss: 3.878094, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 47.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.719987, G loss: 11.043714, D accuracy: 83.7%, cell accuracy: 98.1%, board accuracy: 22.7% \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7668, G loss: 4.9204\n",
      "[372/8000] D loss: 0.9015, G loss: 3.4500\n",
      "[732/8000] D loss: 0.8440, G loss: 3.3218\n",
      "[1092/8000] D loss: 0.5761, G loss: 5.7380\n",
      "[1452/8000] D loss: 0.8492, G loss: 4.4472\n",
      "[1812/8000] D loss: 0.8902, G loss: 2.7545\n",
      "[2172/8000] D loss: 0.7835, G loss: 5.2405\n",
      "[2532/8000] D loss: 0.7822, G loss: 4.4866\n",
      "[2892/8000] D loss: 0.7319, G loss: 4.2726\n",
      "[3252/8000] D loss: 1.1265, G loss: 2.6633\n",
      "[3612/8000] D loss: 0.9851, G loss: 4.2688\n",
      "[3972/8000] D loss: 0.6787, G loss: 5.5866\n",
      "[4332/8000] D loss: 0.9122, G loss: 5.4167\n",
      "[4692/8000] D loss: 0.4432, G loss: 5.1674\n",
      "[5052/8000] D loss: 0.7785, G loss: 8.6337\n",
      "[5412/8000] D loss: 0.8471, G loss: 8.8408\n",
      "[5772/8000] D loss: 0.5091, G loss: 5.1909\n",
      "[6132/8000] D loss: 1.0207, G loss: 5.8367\n",
      "[6492/8000] D loss: 0.8338, G loss: 3.7661\n",
      "[6852/8000] D loss: 0.7623, G loss: 6.2819\n",
      "[7212/8000] D loss: 0.6629, G loss: 5.3388\n",
      "[7572/8000] D loss: 0.7923, G loss: 5.2067\n",
      "[7932/8000] D loss: 0.8424, G loss: 6.1504\n",
      "train error: \n",
      " D loss: 0.784822, G loss: 4.789876, D accuracy: 76.4%, cell accuracy: 98.6%, board accuracy: 46.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.832712, G loss: 12.374194, D accuracy: 83.6%, cell accuracy: 98.1%, board accuracy: 21.9% \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0707, G loss: 2.8396\n",
      "[372/8000] D loss: 0.6807, G loss: 6.8900\n",
      "[732/8000] D loss: 0.6463, G loss: 6.4731\n",
      "[1092/8000] D loss: 0.8162, G loss: 3.3314\n",
      "[1452/8000] D loss: 0.8885, G loss: 5.1170\n",
      "[1812/8000] D loss: 0.7743, G loss: 3.9106\n",
      "[2172/8000] D loss: 1.1324, G loss: 4.6325\n",
      "[2532/8000] D loss: 0.7104, G loss: 4.0644\n",
      "[2892/8000] D loss: 0.7449, G loss: 5.0127\n",
      "[3252/8000] D loss: 0.8116, G loss: 5.0596\n",
      "[3612/8000] D loss: 0.7951, G loss: 3.5260\n",
      "[3972/8000] D loss: 0.9156, G loss: 3.8569\n",
      "[4332/8000] D loss: 0.9173, G loss: 4.7232\n",
      "[4692/8000] D loss: 0.8387, G loss: 5.8954\n",
      "[5052/8000] D loss: 0.6266, G loss: 5.9548\n",
      "[5412/8000] D loss: 0.6613, G loss: 3.4377\n",
      "[5772/8000] D loss: 0.8164, G loss: 4.0003\n",
      "[6132/8000] D loss: 0.9367, G loss: 4.3264\n",
      "[6492/8000] D loss: 0.9461, G loss: 3.1860\n",
      "[6852/8000] D loss: 0.8380, G loss: 4.4616\n",
      "[7212/8000] D loss: 0.8250, G loss: 3.1714\n",
      "[7572/8000] D loss: 0.3499, G loss: 9.6138\n",
      "[7932/8000] D loss: 0.8882, G loss: 4.5172\n",
      "train error: \n",
      " D loss: 0.813155, G loss: 4.241238, D accuracy: 75.3%, cell accuracy: 98.6%, board accuracy: 47.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.811584, G loss: 11.481401, D accuracy: 80.8%, cell accuracy: 98.1%, board accuracy: 23.3% \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7658, G loss: 5.9523\n",
      "[372/8000] D loss: 0.8980, G loss: 4.7765\n",
      "[732/8000] D loss: 0.5259, G loss: 6.8239\n",
      "[1092/8000] D loss: 0.7906, G loss: 6.4938\n",
      "[1452/8000] D loss: 0.7023, G loss: 6.5480\n",
      "[1812/8000] D loss: 0.8528, G loss: 2.7008\n",
      "[2172/8000] D loss: 0.5976, G loss: 8.3825\n",
      "[2532/8000] D loss: 0.5342, G loss: 8.1555\n",
      "[2892/8000] D loss: 0.6937, G loss: 3.6914\n",
      "[3252/8000] D loss: 0.7072, G loss: 5.2192\n",
      "[3612/8000] D loss: 0.9148, G loss: 8.1191\n",
      "[3972/8000] D loss: 0.7291, G loss: 4.2587\n",
      "[4332/8000] D loss: 0.8962, G loss: 2.8770\n",
      "[4692/8000] D loss: 0.8151, G loss: 3.6429\n",
      "[5052/8000] D loss: 0.9177, G loss: 2.8382\n",
      "[5412/8000] D loss: 0.8744, G loss: 6.5478\n",
      "[5772/8000] D loss: 0.6975, G loss: 4.3317\n",
      "[6132/8000] D loss: 0.8063, G loss: 3.4158\n",
      "[6492/8000] D loss: 0.8449, G loss: 4.4212\n",
      "[6852/8000] D loss: 0.8275, G loss: 7.0252\n",
      "[7212/8000] D loss: 0.8761, G loss: 3.7068\n",
      "[7572/8000] D loss: 0.3496, G loss: 11.0299\n",
      "[7932/8000] D loss: 0.6278, G loss: 4.7561\n",
      "train error: \n",
      " D loss: 0.796814, G loss: 5.014058, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 48.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.927806, G loss: 12.487538, D accuracy: 79.8%, cell accuracy: 98.2%, board accuracy: 24.3% \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6513, G loss: 5.5486\n",
      "[372/8000] D loss: 0.6605, G loss: 6.4615\n",
      "[732/8000] D loss: 0.7710, G loss: 4.5776\n",
      "[1092/8000] D loss: 0.9019, G loss: 3.8748\n",
      "[1452/8000] D loss: 0.8592, G loss: 3.4163\n",
      "[1812/8000] D loss: 0.4501, G loss: 6.1363\n",
      "[2172/8000] D loss: 0.8273, G loss: 8.9153\n",
      "[2532/8000] D loss: 0.7827, G loss: 5.3097\n",
      "[2892/8000] D loss: 0.8066, G loss: 2.7308\n",
      "[3252/8000] D loss: 1.0371, G loss: 2.3362\n",
      "[3612/8000] D loss: 0.9147, G loss: 4.5102\n",
      "[3972/8000] D loss: 1.1301, G loss: 1.2819\n",
      "[4332/8000] D loss: 0.9560, G loss: 5.7457\n",
      "[4692/8000] D loss: 0.7376, G loss: 3.8086\n",
      "[5052/8000] D loss: 1.0186, G loss: 1.6660\n",
      "[5412/8000] D loss: 1.0785, G loss: 2.1296\n",
      "[5772/8000] D loss: 0.6701, G loss: 11.0981\n",
      "[6132/8000] D loss: 0.4877, G loss: 5.4711\n",
      "[6492/8000] D loss: 0.8178, G loss: 3.8067\n",
      "[6852/8000] D loss: 0.8254, G loss: 1.9330\n",
      "[7212/8000] D loss: 0.9632, G loss: 2.3524\n",
      "[7572/8000] D loss: 0.6770, G loss: 5.7186\n",
      "[7932/8000] D loss: 0.7781, G loss: 4.0480\n",
      "train error: \n",
      " D loss: 0.794499, G loss: 4.316222, D accuracy: 75.5%, cell accuracy: 98.6%, board accuracy: 48.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.865374, G loss: 11.492726, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 23.3% \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0653, G loss: 2.9294\n",
      "[372/8000] D loss: 0.5062, G loss: 6.6783\n",
      "[732/8000] D loss: 0.9085, G loss: 4.8308\n",
      "[1092/8000] D loss: 0.6000, G loss: 4.3016\n",
      "[1452/8000] D loss: 0.9296, G loss: 2.5456\n",
      "[1812/8000] D loss: 1.1141, G loss: 2.7925\n",
      "[2172/8000] D loss: 0.6308, G loss: 6.1557\n",
      "[2532/8000] D loss: 0.7151, G loss: 3.8711\n",
      "[2892/8000] D loss: 0.6996, G loss: 4.8556\n",
      "[3252/8000] D loss: 0.7713, G loss: 5.8971\n",
      "[3612/8000] D loss: 0.6441, G loss: 5.8444\n",
      "[3972/8000] D loss: 0.7409, G loss: 7.1165\n",
      "[4332/8000] D loss: 0.5190, G loss: 8.6978\n",
      "[4692/8000] D loss: 1.1326, G loss: 2.2594\n",
      "[5052/8000] D loss: 0.6249, G loss: 3.3728\n",
      "[5412/8000] D loss: 1.3352, G loss: 2.2129\n",
      "[5772/8000] D loss: 0.9340, G loss: 1.8920\n",
      "[6132/8000] D loss: 0.7294, G loss: 4.5178\n",
      "[6492/8000] D loss: 0.7820, G loss: 1.7105\n",
      "[6852/8000] D loss: 0.7693, G loss: 5.5759\n",
      "[7212/8000] D loss: 1.0577, G loss: 2.5442\n",
      "[7572/8000] D loss: 0.8045, G loss: 6.5772\n",
      "[7932/8000] D loss: 1.1826, G loss: 3.0570\n",
      "train error: \n",
      " D loss: 0.806974, G loss: 4.513442, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 48.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.967139, G loss: 11.341733, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5518, G loss: 6.5459\n",
      "[372/8000] D loss: 1.0123, G loss: 2.5042\n",
      "[732/8000] D loss: 1.1294, G loss: 3.0946\n",
      "[1092/8000] D loss: 0.8780, G loss: 4.5466\n",
      "[1452/8000] D loss: 0.6763, G loss: 4.0175\n",
      "[1812/8000] D loss: 0.8073, G loss: 3.6485\n",
      "[2172/8000] D loss: 0.7567, G loss: 4.0353\n",
      "[2532/8000] D loss: 0.7242, G loss: 6.2997\n",
      "[2892/8000] D loss: 0.7715, G loss: 3.3353\n",
      "[3252/8000] D loss: 0.4484, G loss: 6.1116\n",
      "[3612/8000] D loss: 1.2388, G loss: 1.4551\n",
      "[3972/8000] D loss: 0.9076, G loss: 2.0005\n",
      "[4332/8000] D loss: 0.9216, G loss: 3.7026\n",
      "[4692/8000] D loss: 0.7501, G loss: 7.2287\n",
      "[5052/8000] D loss: 0.7648, G loss: 5.0949\n",
      "[5412/8000] D loss: 0.9570, G loss: 3.4295\n",
      "[5772/8000] D loss: 0.8588, G loss: 4.7299\n",
      "[6132/8000] D loss: 0.6466, G loss: 8.9346\n",
      "[6492/8000] D loss: 0.6801, G loss: 5.2372\n",
      "[6852/8000] D loss: 0.4138, G loss: 7.6952\n",
      "[7212/8000] D loss: 0.8636, G loss: 4.3990\n",
      "[7572/8000] D loss: 0.9797, G loss: 3.8086\n",
      "[7932/8000] D loss: 1.0467, G loss: 2.2382\n",
      "train error: \n",
      " D loss: 0.798750, G loss: 4.476137, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 49.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.841413, G loss: 11.784253, D accuracy: 81.2%, cell accuracy: 98.1%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7784, G loss: 3.0032\n",
      "[372/8000] D loss: 0.6833, G loss: 5.5599\n",
      "[732/8000] D loss: 0.6612, G loss: 7.4580\n",
      "[1092/8000] D loss: 0.7631, G loss: 4.6306\n",
      "[1452/8000] D loss: 0.7413, G loss: 6.7445\n",
      "[1812/8000] D loss: 0.9883, G loss: 2.8163\n",
      "[2172/8000] D loss: 0.8763, G loss: 6.1194\n",
      "[2532/8000] D loss: 0.6745, G loss: 6.3464\n",
      "[2892/8000] D loss: 0.5188, G loss: 6.2305\n",
      "[3252/8000] D loss: 0.2988, G loss: 8.3707\n",
      "[3612/8000] D loss: 0.9591, G loss: 2.2981\n",
      "[3972/8000] D loss: 0.9647, G loss: 3.3665\n",
      "[4332/8000] D loss: 1.0877, G loss: 3.6931\n",
      "[4692/8000] D loss: 0.6856, G loss: 7.5192\n",
      "[5052/8000] D loss: 0.5052, G loss: 8.5768\n",
      "[5412/8000] D loss: 1.1262, G loss: 1.2820\n",
      "[5772/8000] D loss: 0.7916, G loss: 2.8760\n",
      "[6132/8000] D loss: 0.5355, G loss: 8.9382\n",
      "[6492/8000] D loss: 0.4118, G loss: 10.8792\n",
      "[6852/8000] D loss: 1.0006, G loss: 4.2556\n",
      "[7212/8000] D loss: 0.6583, G loss: 5.0442\n",
      "[7572/8000] D loss: 0.3935, G loss: 10.1392\n",
      "[7932/8000] D loss: 0.8269, G loss: 6.9270\n",
      "train error: \n",
      " D loss: 0.790694, G loss: 4.544786, D accuracy: 76.0%, cell accuracy: 98.6%, board accuracy: 47.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.918027, G loss: 11.987850, D accuracy: 80.8%, cell accuracy: 98.1%, board accuracy: 22.9% \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8702, G loss: 5.1665\n",
      "[372/8000] D loss: 0.7345, G loss: 5.9519\n",
      "[732/8000] D loss: 0.6293, G loss: 5.6975\n",
      "[1092/8000] D loss: 0.7059, G loss: 5.2258\n",
      "[1452/8000] D loss: 0.9280, G loss: 3.8420\n",
      "[1812/8000] D loss: 0.8267, G loss: 4.3059\n",
      "[2172/8000] D loss: 0.7091, G loss: 5.2235\n",
      "[2532/8000] D loss: 0.7956, G loss: 3.8123\n",
      "[2892/8000] D loss: 0.5840, G loss: 9.2376\n",
      "[3252/8000] D loss: 0.9846, G loss: 2.4269\n",
      "[3612/8000] D loss: 0.4436, G loss: 7.0028\n",
      "[3972/8000] D loss: 0.9883, G loss: 2.4977\n",
      "[4332/8000] D loss: 1.1381, G loss: 3.1812\n",
      "[4692/8000] D loss: 0.8451, G loss: 6.0375\n",
      "[5052/8000] D loss: 0.7537, G loss: 2.7948\n",
      "[5412/8000] D loss: 0.6472, G loss: 5.9861\n",
      "[5772/8000] D loss: 1.0262, G loss: 2.5496\n",
      "[6132/8000] D loss: 0.5367, G loss: 5.3881\n",
      "[6492/8000] D loss: 0.7606, G loss: 3.3783\n",
      "[6852/8000] D loss: 0.7981, G loss: 4.0551\n",
      "[7212/8000] D loss: 0.6973, G loss: 8.5532\n",
      "[7572/8000] D loss: 0.5288, G loss: 5.8984\n",
      "[7932/8000] D loss: 0.5564, G loss: 9.5457\n",
      "train error: \n",
      " D loss: 0.787930, G loss: 5.185080, D accuracy: 75.7%, cell accuracy: 98.6%, board accuracy: 48.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.898146, G loss: 12.941458, D accuracy: 80.9%, cell accuracy: 98.2%, board accuracy: 22.9% \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6970, G loss: 8.4930\n",
      "[372/8000] D loss: 1.3116, G loss: 4.6791\n",
      "[732/8000] D loss: 1.1547, G loss: 5.7862\n",
      "[1092/8000] D loss: 0.5512, G loss: 5.0069\n",
      "[1452/8000] D loss: 0.5402, G loss: 7.2392\n",
      "[1812/8000] D loss: 0.9133, G loss: 4.1690\n",
      "[2172/8000] D loss: 0.7097, G loss: 3.1518\n",
      "[2532/8000] D loss: 0.9041, G loss: 4.7922\n",
      "[2892/8000] D loss: 0.7526, G loss: 4.1056\n",
      "[3252/8000] D loss: 0.8076, G loss: 4.2116\n",
      "[3612/8000] D loss: 0.6639, G loss: 7.8337\n",
      "[3972/8000] D loss: 0.6639, G loss: 8.1286\n",
      "[4332/8000] D loss: 0.9820, G loss: 1.9446\n",
      "[4692/8000] D loss: 0.8049, G loss: 4.0246\n",
      "[5052/8000] D loss: 0.5776, G loss: 6.7690\n",
      "[5412/8000] D loss: 0.7665, G loss: 6.0429\n",
      "[5772/8000] D loss: 0.9629, G loss: 3.7647\n",
      "[6132/8000] D loss: 0.9978, G loss: 9.6143\n",
      "[6492/8000] D loss: 0.6798, G loss: 2.7252\n",
      "[6852/8000] D loss: 1.0066, G loss: 1.4577\n",
      "[7212/8000] D loss: 0.8194, G loss: 5.7789\n",
      "[7572/8000] D loss: 0.6545, G loss: 5.5726\n",
      "[7932/8000] D loss: 0.8370, G loss: 2.1819\n",
      "train error: \n",
      " D loss: 0.802829, G loss: 5.534931, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 48.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.004748, G loss: 13.344663, D accuracy: 79.5%, cell accuracy: 98.1%, board accuracy: 23.6% \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7117, G loss: 6.6276\n",
      "[372/8000] D loss: 0.7624, G loss: 8.3616\n",
      "[732/8000] D loss: 0.5752, G loss: 6.6857\n",
      "[1092/8000] D loss: 1.2454, G loss: 3.1118\n",
      "[1452/8000] D loss: 0.8921, G loss: 8.5427\n",
      "[1812/8000] D loss: 1.1551, G loss: 3.9560\n",
      "[2172/8000] D loss: 0.6038, G loss: 4.2423\n",
      "[2532/8000] D loss: 0.8290, G loss: 2.8138\n",
      "[2892/8000] D loss: 1.1195, G loss: 2.3723\n",
      "[3252/8000] D loss: 0.8564, G loss: 5.6799\n",
      "[3612/8000] D loss: 0.6174, G loss: 7.7209\n",
      "[3972/8000] D loss: 0.7761, G loss: 3.4344\n",
      "[4332/8000] D loss: 0.8733, G loss: 5.0303\n",
      "[4692/8000] D loss: 0.9715, G loss: 2.7609\n",
      "[5052/8000] D loss: 0.7515, G loss: 4.5029\n",
      "[5412/8000] D loss: 0.6155, G loss: 3.2453\n",
      "[5772/8000] D loss: 0.9684, G loss: 2.8426\n",
      "[6132/8000] D loss: 0.6048, G loss: 8.4615\n",
      "[6492/8000] D loss: 0.7746, G loss: 5.9324\n",
      "[6852/8000] D loss: 0.6787, G loss: 3.4847\n",
      "[7212/8000] D loss: 0.9473, G loss: 3.8562\n",
      "[7572/8000] D loss: 0.8203, G loss: 3.7095\n",
      "[7932/8000] D loss: 1.0241, G loss: 2.8321\n",
      "train error: \n",
      " D loss: 0.823120, G loss: 3.985051, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 48.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.759457, G loss: 10.828411, D accuracy: 82.6%, cell accuracy: 98.1%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4315, G loss: 7.3307\n",
      "[372/8000] D loss: 1.1487, G loss: 1.7815\n",
      "[732/8000] D loss: 0.6146, G loss: 7.4155\n",
      "[1092/8000] D loss: 0.7418, G loss: 4.7221\n",
      "[1452/8000] D loss: 0.9147, G loss: 3.7342\n",
      "[1812/8000] D loss: 0.5283, G loss: 6.2864\n",
      "[2172/8000] D loss: 1.0691, G loss: 2.6333\n",
      "[2532/8000] D loss: 0.7726, G loss: 4.6319\n",
      "[2892/8000] D loss: 0.8505, G loss: 4.0529\n",
      "[3252/8000] D loss: 0.5575, G loss: 9.4137\n",
      "[3612/8000] D loss: 0.6253, G loss: 6.6205\n",
      "[3972/8000] D loss: 0.7603, G loss: 6.1336\n",
      "[4332/8000] D loss: 0.7049, G loss: 3.4166\n",
      "[4692/8000] D loss: 0.7665, G loss: 2.9187\n",
      "[5052/8000] D loss: 0.8538, G loss: 4.0256\n",
      "[5412/8000] D loss: 0.5629, G loss: 5.2459\n",
      "[5772/8000] D loss: 1.0246, G loss: 1.9018\n",
      "[6132/8000] D loss: 1.2038, G loss: 3.8156\n",
      "[6492/8000] D loss: 1.0099, G loss: 2.0275\n",
      "[6852/8000] D loss: 0.8347, G loss: 3.6930\n",
      "[7212/8000] D loss: 0.7638, G loss: 11.9763\n",
      "[7572/8000] D loss: 0.5562, G loss: 6.0203\n",
      "[7932/8000] D loss: 0.4148, G loss: 5.1648\n",
      "train error: \n",
      " D loss: 0.812785, G loss: 4.497892, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 48.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.859270, G loss: 11.767244, D accuracy: 80.5%, cell accuracy: 98.1%, board accuracy: 23.0% \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8502, G loss: 5.0628\n",
      "[372/8000] D loss: 0.9134, G loss: 3.5128\n",
      "[732/8000] D loss: 0.2864, G loss: 8.6549\n",
      "[1092/8000] D loss: 0.8296, G loss: 3.7270\n",
      "[1452/8000] D loss: 0.9413, G loss: 4.4982\n",
      "[1812/8000] D loss: 0.5734, G loss: 7.9252\n",
      "[2172/8000] D loss: 0.4888, G loss: 6.0866\n",
      "[2532/8000] D loss: 0.8021, G loss: 5.4816\n",
      "[2892/8000] D loss: 0.8112, G loss: 2.8221\n",
      "[3252/8000] D loss: 0.6526, G loss: 4.0038\n",
      "[3612/8000] D loss: 0.8782, G loss: 4.9061\n",
      "[3972/8000] D loss: 0.9266, G loss: 3.1333\n",
      "[4332/8000] D loss: 0.8837, G loss: 4.9736\n",
      "[4692/8000] D loss: 0.8302, G loss: 4.3460\n",
      "[5052/8000] D loss: 0.5040, G loss: 7.1581\n",
      "[5412/8000] D loss: 0.6416, G loss: 9.4203\n",
      "[5772/8000] D loss: 0.8357, G loss: 2.6769\n",
      "[6132/8000] D loss: 0.4814, G loss: 10.0946\n",
      "[6492/8000] D loss: 0.5967, G loss: 5.4087\n",
      "[6852/8000] D loss: 0.6514, G loss: 7.0417\n",
      "[7212/8000] D loss: 0.3522, G loss: 6.2687\n",
      "[7572/8000] D loss: 0.8435, G loss: 6.7808\n",
      "[7932/8000] D loss: 0.8598, G loss: 4.5475\n",
      "train error: \n",
      " D loss: 0.838366, G loss: 4.474536, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 48.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.792026, G loss: 12.348510, D accuracy: 83.2%, cell accuracy: 98.2%, board accuracy: 23.6% \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5959, G loss: 2.6635\n",
      "[372/8000] D loss: 0.9656, G loss: 3.0753\n",
      "[732/8000] D loss: 0.5678, G loss: 5.3480\n",
      "[1092/8000] D loss: 0.5402, G loss: 9.8036\n",
      "[1452/8000] D loss: 0.6819, G loss: 5.4840\n",
      "[1812/8000] D loss: 0.9496, G loss: 4.7580\n",
      "[2172/8000] D loss: 0.8859, G loss: 3.7046\n",
      "[2532/8000] D loss: 0.7991, G loss: 6.9538\n",
      "[2892/8000] D loss: 0.6789, G loss: 2.9822\n",
      "[3252/8000] D loss: 0.9156, G loss: 3.6742\n",
      "[3612/8000] D loss: 0.9756, G loss: 5.2469\n",
      "[3972/8000] D loss: 0.4912, G loss: 6.4957\n",
      "[4332/8000] D loss: 0.7382, G loss: 2.7438\n",
      "[4692/8000] D loss: 1.1359, G loss: 2.1454\n",
      "[5052/8000] D loss: 0.6787, G loss: 4.5706\n",
      "[5412/8000] D loss: 0.7748, G loss: 3.1839\n",
      "[5772/8000] D loss: 0.7713, G loss: 2.6872\n",
      "[6132/8000] D loss: 0.7660, G loss: 2.5900\n",
      "[6492/8000] D loss: 0.7739, G loss: 4.4542\n",
      "[6852/8000] D loss: 0.7453, G loss: 2.7072\n",
      "[7212/8000] D loss: 0.6934, G loss: 4.1388\n",
      "[7572/8000] D loss: 0.6018, G loss: 4.6351\n",
      "[7932/8000] D loss: 0.9042, G loss: 2.9507\n",
      "train error: \n",
      " D loss: 0.834452, G loss: 5.255481, D accuracy: 74.0%, cell accuracy: 98.6%, board accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.024553, G loss: 12.823221, D accuracy: 77.4%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7094, G loss: 6.3731\n",
      "[372/8000] D loss: 0.6994, G loss: 8.2065\n",
      "[732/8000] D loss: 1.1181, G loss: 2.8567\n",
      "[1092/8000] D loss: 0.7989, G loss: 7.4797\n",
      "[1452/8000] D loss: 0.6942, G loss: 5.8090\n",
      "[1812/8000] D loss: 1.2044, G loss: 4.0657\n",
      "[2172/8000] D loss: 0.8956, G loss: 2.9573\n",
      "[2532/8000] D loss: 0.9769, G loss: 4.5256\n",
      "[2892/8000] D loss: 0.9344, G loss: 1.7910\n",
      "[3252/8000] D loss: 0.7124, G loss: 3.2853\n",
      "[3612/8000] D loss: 0.9892, G loss: 4.1819\n",
      "[3972/8000] D loss: 0.6884, G loss: 7.1805\n",
      "[4332/8000] D loss: 0.8693, G loss: 3.9448\n",
      "[4692/8000] D loss: 1.0171, G loss: 3.1996\n",
      "[5052/8000] D loss: 0.8496, G loss: 4.4719\n",
      "[5412/8000] D loss: 0.6253, G loss: 4.9879\n",
      "[5772/8000] D loss: 0.9337, G loss: 2.3142\n",
      "[6132/8000] D loss: 0.7218, G loss: 6.9251\n",
      "[6492/8000] D loss: 0.7446, G loss: 5.4524\n",
      "[6852/8000] D loss: 0.5467, G loss: 7.4444\n",
      "[7212/8000] D loss: 0.7561, G loss: 2.9779\n",
      "[7572/8000] D loss: 0.9059, G loss: 4.1366\n",
      "[7932/8000] D loss: 0.5482, G loss: 7.5854\n",
      "train error: \n",
      " D loss: 0.809864, G loss: 5.097123, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 48.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.936778, G loss: 12.977800, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6308, G loss: 5.5406\n",
      "[372/8000] D loss: 0.6101, G loss: 3.8995\n",
      "[732/8000] D loss: 0.9751, G loss: 2.1550\n",
      "[1092/8000] D loss: 0.7213, G loss: 2.1114\n",
      "[1452/8000] D loss: 0.8034, G loss: 3.1448\n",
      "[1812/8000] D loss: 0.8645, G loss: 3.1087\n",
      "[2172/8000] D loss: 1.1852, G loss: 4.3369\n",
      "[2532/8000] D loss: 0.5109, G loss: 4.6483\n",
      "[2892/8000] D loss: 0.3857, G loss: 8.2802\n",
      "[3252/8000] D loss: 0.8789, G loss: 5.1747\n",
      "[3612/8000] D loss: 0.9931, G loss: 5.8226\n",
      "[3972/8000] D loss: 0.7648, G loss: 4.9457\n",
      "[4332/8000] D loss: 0.6575, G loss: 3.2723\n",
      "[4692/8000] D loss: 0.9407, G loss: 3.7633\n",
      "[5052/8000] D loss: 0.9715, G loss: 2.8096\n",
      "[5412/8000] D loss: 0.5282, G loss: 4.5903\n",
      "[5772/8000] D loss: 0.8713, G loss: 4.5543\n",
      "[6132/8000] D loss: 0.6872, G loss: 5.8160\n",
      "[6492/8000] D loss: 0.9749, G loss: 4.6344\n",
      "[6852/8000] D loss: 1.0937, G loss: 1.8030\n",
      "[7212/8000] D loss: 0.5896, G loss: 4.8836\n",
      "[7572/8000] D loss: 1.0839, G loss: 4.4475\n",
      "[7932/8000] D loss: 0.7760, G loss: 3.9519\n",
      "train error: \n",
      " D loss: 0.807263, G loss: 4.136437, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.861402, G loss: 11.440126, D accuracy: 80.7%, cell accuracy: 98.2%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6974, G loss: 4.3502\n",
      "[372/8000] D loss: 1.1083, G loss: 1.2619\n",
      "[732/8000] D loss: 0.7758, G loss: 4.0473\n",
      "[1092/8000] D loss: 0.7442, G loss: 7.4669\n",
      "[1452/8000] D loss: 0.9537, G loss: 3.5387\n",
      "[1812/8000] D loss: 0.9531, G loss: 1.8055\n",
      "[2172/8000] D loss: 0.4721, G loss: 5.4313\n",
      "[2532/8000] D loss: 0.3189, G loss: 6.3154\n",
      "[2892/8000] D loss: 0.9694, G loss: 2.9650\n",
      "[3252/8000] D loss: 0.3004, G loss: 10.1828\n",
      "[3612/8000] D loss: 0.7373, G loss: 4.3428\n",
      "[3972/8000] D loss: 0.6115, G loss: 3.7347\n",
      "[4332/8000] D loss: 0.8099, G loss: 5.2434\n",
      "[4692/8000] D loss: 0.4943, G loss: 5.6032\n",
      "[5052/8000] D loss: 0.7047, G loss: 4.0632\n",
      "[5412/8000] D loss: 0.8691, G loss: 3.4210\n",
      "[5772/8000] D loss: 0.9583, G loss: 3.8852\n",
      "[6132/8000] D loss: 0.3640, G loss: 7.0107\n",
      "[6492/8000] D loss: 0.7362, G loss: 5.7555\n",
      "[6852/8000] D loss: 0.6399, G loss: 7.7733\n",
      "[7212/8000] D loss: 0.4966, G loss: 7.4845\n",
      "[7572/8000] D loss: 0.9553, G loss: 3.2012\n",
      "[7932/8000] D loss: 0.8400, G loss: 5.3403\n",
      "train error: \n",
      " D loss: 0.825506, G loss: 4.178617, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 49.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.865419, G loss: 11.344659, D accuracy: 83.2%, cell accuracy: 98.1%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5580, G loss: 6.4642\n",
      "[372/8000] D loss: 1.1578, G loss: 1.5114\n",
      "[732/8000] D loss: 0.6298, G loss: 6.2885\n",
      "[1092/8000] D loss: 0.8961, G loss: 4.3434\n",
      "[1452/8000] D loss: 0.9365, G loss: 2.3972\n",
      "[1812/8000] D loss: 0.8653, G loss: 4.4235\n",
      "[2172/8000] D loss: 0.9655, G loss: 3.2220\n",
      "[2532/8000] D loss: 1.0340, G loss: 3.5410\n",
      "[2892/8000] D loss: 0.5664, G loss: 9.2542\n",
      "[3252/8000] D loss: 1.1991, G loss: 1.3388\n",
      "[3612/8000] D loss: 1.0292, G loss: 2.6164\n",
      "[3972/8000] D loss: 0.7379, G loss: 3.2923\n",
      "[4332/8000] D loss: 0.9017, G loss: 4.1650\n",
      "[4692/8000] D loss: 0.5477, G loss: 8.4280\n",
      "[5052/8000] D loss: 0.6818, G loss: 4.9225\n",
      "[5412/8000] D loss: 0.7515, G loss: 3.6865\n",
      "[5772/8000] D loss: 0.9514, G loss: 2.2271\n",
      "[6132/8000] D loss: 1.0171, G loss: 1.8642\n",
      "[6492/8000] D loss: 0.7338, G loss: 3.0584\n",
      "[6852/8000] D loss: 0.5117, G loss: 9.2685\n",
      "[7212/8000] D loss: 0.6358, G loss: 6.0771\n",
      "[7572/8000] D loss: 0.4816, G loss: 5.4048\n",
      "[7932/8000] D loss: 0.8863, G loss: 3.5324\n",
      "train error: \n",
      " D loss: 0.795191, G loss: 5.313885, D accuracy: 75.3%, cell accuracy: 98.6%, board accuracy: 48.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.976477, G loss: 13.379582, D accuracy: 78.2%, cell accuracy: 98.1%, board accuracy: 22.6% \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9349, G loss: 4.6522\n",
      "[372/8000] D loss: 0.8648, G loss: 3.1570\n",
      "[732/8000] D loss: 0.7341, G loss: 3.1195\n",
      "[1092/8000] D loss: 0.6016, G loss: 6.6417\n",
      "[1452/8000] D loss: 0.4085, G loss: 6.3800\n",
      "[1812/8000] D loss: 0.8076, G loss: 4.5193\n",
      "[2172/8000] D loss: 0.8304, G loss: 3.2548\n",
      "[2532/8000] D loss: 0.8085, G loss: 4.1808\n",
      "[2892/8000] D loss: 1.0132, G loss: 3.1380\n",
      "[3252/8000] D loss: 0.7953, G loss: 4.9790\n",
      "[3612/8000] D loss: 0.6871, G loss: 7.0461\n",
      "[3972/8000] D loss: 0.6200, G loss: 4.9830\n",
      "[4332/8000] D loss: 0.4988, G loss: 6.5835\n",
      "[4692/8000] D loss: 0.8410, G loss: 3.9465\n",
      "[5052/8000] D loss: 1.0000, G loss: 2.7955\n",
      "[5412/8000] D loss: 0.7142, G loss: 5.6480\n",
      "[5772/8000] D loss: 0.5142, G loss: 7.2210\n",
      "[6132/8000] D loss: 1.1224, G loss: 1.9456\n",
      "[6492/8000] D loss: 0.8600, G loss: 2.4336\n",
      "[6852/8000] D loss: 0.6012, G loss: 4.3209\n",
      "[7212/8000] D loss: 0.6799, G loss: 5.3386\n",
      "[7572/8000] D loss: 0.6625, G loss: 4.6311\n",
      "[7932/8000] D loss: 0.7579, G loss: 4.0826\n",
      "train error: \n",
      " D loss: 0.895561, G loss: 3.362943, D accuracy: 73.5%, cell accuracy: 98.6%, board accuracy: 49.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.726551, G loss: 9.927521, D accuracy: 84.2%, cell accuracy: 98.2%, board accuracy: 24.8% \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8519, G loss: 4.8683\n",
      "[372/8000] D loss: 0.8415, G loss: 2.8505\n",
      "[732/8000] D loss: 1.1729, G loss: 2.0242\n",
      "[1092/8000] D loss: 0.7528, G loss: 6.3713\n",
      "[1452/8000] D loss: 0.9645, G loss: 3.3025\n",
      "[1812/8000] D loss: 0.8072, G loss: 2.2174\n",
      "[2172/8000] D loss: 0.7082, G loss: 6.9199\n",
      "[2532/8000] D loss: 0.8444, G loss: 7.0015\n",
      "[2892/8000] D loss: 0.5651, G loss: 5.7380\n",
      "[3252/8000] D loss: 0.7458, G loss: 4.4287\n",
      "[3612/8000] D loss: 0.8439, G loss: 4.2847\n",
      "[3972/8000] D loss: 1.1288, G loss: 2.2510\n",
      "[4332/8000] D loss: 0.7990, G loss: 4.4181\n",
      "[4692/8000] D loss: 1.0277, G loss: 3.9698\n",
      "[5052/8000] D loss: 0.4620, G loss: 6.4501\n",
      "[5412/8000] D loss: 1.1228, G loss: 2.4942\n",
      "[5772/8000] D loss: 0.7565, G loss: 4.1779\n",
      "[6132/8000] D loss: 0.7267, G loss: 4.8350\n",
      "[6492/8000] D loss: 0.5947, G loss: 5.6350\n",
      "[6852/8000] D loss: 0.6765, G loss: 6.4456\n",
      "[7212/8000] D loss: 0.6672, G loss: 6.6144\n",
      "[7572/8000] D loss: 0.7444, G loss: 4.5817\n",
      "[7932/8000] D loss: 0.5862, G loss: 5.7353\n",
      "train error: \n",
      " D loss: 0.814041, G loss: 4.485218, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 49.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.829868, G loss: 11.820176, D accuracy: 83.0%, cell accuracy: 98.2%, board accuracy: 23.6% \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9597, G loss: 3.3287\n",
      "[372/8000] D loss: 0.8208, G loss: 3.4372\n",
      "[732/8000] D loss: 0.5510, G loss: 4.9252\n",
      "[1092/8000] D loss: 0.5770, G loss: 8.6773\n",
      "[1452/8000] D loss: 0.9333, G loss: 1.8146\n",
      "[1812/8000] D loss: 1.0646, G loss: 4.4238\n",
      "[2172/8000] D loss: 0.6571, G loss: 7.6582\n",
      "[2532/8000] D loss: 0.8675, G loss: 3.8645\n",
      "[2892/8000] D loss: 0.5344, G loss: 7.7781\n",
      "[3252/8000] D loss: 0.8187, G loss: 5.2716\n",
      "[3612/8000] D loss: 0.6857, G loss: 5.9552\n",
      "[3972/8000] D loss: 0.6129, G loss: 7.5680\n",
      "[4332/8000] D loss: 0.8702, G loss: 4.1483\n",
      "[4692/8000] D loss: 0.8896, G loss: 3.3093\n",
      "[5052/8000] D loss: 0.7365, G loss: 4.5029\n",
      "[5412/8000] D loss: 0.7951, G loss: 5.9690\n",
      "[5772/8000] D loss: 0.8043, G loss: 3.5070\n",
      "[6132/8000] D loss: 0.6782, G loss: 6.3387\n",
      "[6492/8000] D loss: 0.4070, G loss: 13.7195\n",
      "[6852/8000] D loss: 0.9009, G loss: 2.8386\n",
      "[7212/8000] D loss: 0.6258, G loss: 7.3927\n",
      "[7572/8000] D loss: 0.4941, G loss: 5.9847\n",
      "[7932/8000] D loss: 0.7073, G loss: 3.8135\n",
      "train error: \n",
      " D loss: 0.821217, G loss: 6.047335, D accuracy: 74.3%, cell accuracy: 98.6%, board accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.061918, G loss: 14.474830, D accuracy: 75.8%, cell accuracy: 98.2%, board accuracy: 24.8% \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9211, G loss: 4.3257\n",
      "[372/8000] D loss: 0.7029, G loss: 5.0703\n",
      "[732/8000] D loss: 0.6789, G loss: 4.8543\n",
      "[1092/8000] D loss: 0.7496, G loss: 4.5149\n",
      "[1452/8000] D loss: 0.5675, G loss: 9.8391\n",
      "[1812/8000] D loss: 1.0006, G loss: 4.5657\n",
      "[2172/8000] D loss: 0.4391, G loss: 10.0873\n",
      "[2532/8000] D loss: 0.9249, G loss: 3.5270\n",
      "[2892/8000] D loss: 0.7197, G loss: 2.8018\n",
      "[3252/8000] D loss: 1.1921, G loss: 3.3171\n",
      "[3612/8000] D loss: 0.4768, G loss: 9.1446\n",
      "[3972/8000] D loss: 0.8291, G loss: 6.3357\n",
      "[4332/8000] D loss: 1.0858, G loss: 7.3975\n",
      "[4692/8000] D loss: 0.4880, G loss: 5.1836\n",
      "[5052/8000] D loss: 0.9512, G loss: 4.6922\n",
      "[5412/8000] D loss: 0.9288, G loss: 3.7515\n",
      "[5772/8000] D loss: 0.6039, G loss: 8.2989\n",
      "[6132/8000] D loss: 0.3791, G loss: 8.6922\n",
      "[6492/8000] D loss: 1.1255, G loss: 2.5606\n",
      "[6852/8000] D loss: 0.3653, G loss: 7.6345\n",
      "[7212/8000] D loss: 0.7965, G loss: 5.2529\n",
      "[7572/8000] D loss: 0.8565, G loss: 6.7062\n",
      "[7932/8000] D loss: 0.5694, G loss: 4.7816\n",
      "train error: \n",
      " D loss: 0.768622, G loss: 5.176088, D accuracy: 76.3%, cell accuracy: 98.6%, board accuracy: 48.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.876685, G loss: 13.327129, D accuracy: 81.4%, cell accuracy: 98.1%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2672, G loss: 1.4655\n",
      "[372/8000] D loss: 0.8213, G loss: 3.3015\n",
      "[732/8000] D loss: 0.5307, G loss: 7.6750\n",
      "[1092/8000] D loss: 0.9888, G loss: 3.5924\n",
      "[1452/8000] D loss: 0.5620, G loss: 7.6996\n",
      "[1812/8000] D loss: 0.6171, G loss: 5.1455\n",
      "[2172/8000] D loss: 0.9876, G loss: 2.9067\n",
      "[2532/8000] D loss: 0.6385, G loss: 4.0285\n",
      "[2892/8000] D loss: 0.7938, G loss: 3.2892\n",
      "[3252/8000] D loss: 0.6670, G loss: 6.3128\n",
      "[3612/8000] D loss: 0.4201, G loss: 9.3992\n",
      "[3972/8000] D loss: 1.1784, G loss: 2.5763\n",
      "[4332/8000] D loss: 0.7597, G loss: 5.8648\n",
      "[4692/8000] D loss: 0.9426, G loss: 4.7172\n",
      "[5052/8000] D loss: 1.3076, G loss: 4.3928\n",
      "[5412/8000] D loss: 0.8209, G loss: 7.8812\n",
      "[5772/8000] D loss: 0.9424, G loss: 3.7678\n",
      "[6132/8000] D loss: 0.8408, G loss: 4.1451\n",
      "[6492/8000] D loss: 0.9864, G loss: 5.6622\n",
      "[6852/8000] D loss: 1.1439, G loss: 1.7320\n",
      "[7212/8000] D loss: 0.5475, G loss: 5.7704\n",
      "[7572/8000] D loss: 0.9898, G loss: 1.5020\n",
      "[7932/8000] D loss: 0.7858, G loss: 3.5336\n",
      "train error: \n",
      " D loss: 0.815532, G loss: 4.145003, D accuracy: 74.4%, cell accuracy: 98.6%, board accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.917935, G loss: 11.181178, D accuracy: 81.4%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8692, G loss: 2.1919\n",
      "[372/8000] D loss: 1.1014, G loss: 2.7358\n",
      "[732/8000] D loss: 0.9717, G loss: 2.2026\n",
      "[1092/8000] D loss: 0.8666, G loss: 2.8114\n",
      "[1452/8000] D loss: 1.0737, G loss: 4.0817\n",
      "[1812/8000] D loss: 0.6575, G loss: 5.7527\n",
      "[2172/8000] D loss: 0.9152, G loss: 3.7682\n",
      "[2532/8000] D loss: 0.4609, G loss: 5.7599\n",
      "[2892/8000] D loss: 0.9451, G loss: 2.9356\n",
      "[3252/8000] D loss: 0.3448, G loss: 5.0718\n",
      "[3612/8000] D loss: 1.0149, G loss: 3.3202\n",
      "[3972/8000] D loss: 0.5427, G loss: 4.3129\n",
      "[4332/8000] D loss: 0.7811, G loss: 4.2241\n",
      "[4692/8000] D loss: 0.5220, G loss: 6.3309\n",
      "[5052/8000] D loss: 0.6671, G loss: 5.5288\n",
      "[5412/8000] D loss: 1.1694, G loss: 3.0142\n",
      "[5772/8000] D loss: 0.7266, G loss: 4.4189\n",
      "[6132/8000] D loss: 0.6777, G loss: 4.9488\n",
      "[6492/8000] D loss: 0.6190, G loss: 5.4917\n",
      "[6852/8000] D loss: 0.8902, G loss: 4.4574\n",
      "[7212/8000] D loss: 0.9938, G loss: 4.2657\n",
      "[7572/8000] D loss: 0.8697, G loss: 3.3800\n",
      "[7932/8000] D loss: 1.1363, G loss: 3.0471\n",
      "train error: \n",
      " D loss: 0.816281, G loss: 4.336287, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.831501, G loss: 11.913887, D accuracy: 82.6%, cell accuracy: 98.2%, board accuracy: 24.9% \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1451, G loss: 3.6223\n",
      "[372/8000] D loss: 0.9784, G loss: 2.6461\n",
      "[732/8000] D loss: 0.5699, G loss: 4.3691\n",
      "[1092/8000] D loss: 0.7589, G loss: 3.6601\n",
      "[1452/8000] D loss: 1.0731, G loss: 4.8065\n",
      "[1812/8000] D loss: 0.6208, G loss: 9.5235\n",
      "[2172/8000] D loss: 0.5809, G loss: 6.0594\n",
      "[2532/8000] D loss: 0.8136, G loss: 2.9165\n",
      "[2892/8000] D loss: 0.6315, G loss: 9.7905\n",
      "[3252/8000] D loss: 0.4748, G loss: 6.9214\n",
      "[3612/8000] D loss: 0.5702, G loss: 7.7412\n",
      "[3972/8000] D loss: 0.7658, G loss: 3.9933\n",
      "[4332/8000] D loss: 1.0474, G loss: 4.2650\n",
      "[4692/8000] D loss: 1.2409, G loss: 1.1170\n",
      "[5052/8000] D loss: 0.4566, G loss: 9.6011\n",
      "[5412/8000] D loss: 0.9852, G loss: 2.5257\n",
      "[5772/8000] D loss: 0.8143, G loss: 4.1784\n",
      "[6132/8000] D loss: 0.7950, G loss: 6.2980\n",
      "[6492/8000] D loss: 0.6632, G loss: 3.6692\n",
      "[6852/8000] D loss: 1.0260, G loss: 4.5693\n",
      "[7212/8000] D loss: 0.8730, G loss: 2.4712\n",
      "[7572/8000] D loss: 0.7148, G loss: 6.4144\n",
      "[7932/8000] D loss: 0.8447, G loss: 5.6221\n",
      "train error: \n",
      " D loss: 0.844344, G loss: 3.947994, D accuracy: 74.5%, cell accuracy: 98.6%, board accuracy: 49.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.785807, G loss: 10.985146, D accuracy: 83.6%, cell accuracy: 98.1%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7661, G loss: 3.1646\n",
      "[372/8000] D loss: 0.9997, G loss: 2.9576\n",
      "[732/8000] D loss: 0.8171, G loss: 3.7398\n",
      "[1092/8000] D loss: 0.8461, G loss: 5.3614\n",
      "[1452/8000] D loss: 1.0575, G loss: 2.1888\n",
      "[1812/8000] D loss: 0.5275, G loss: 4.0884\n",
      "[2172/8000] D loss: 0.5814, G loss: 6.3817\n",
      "[2532/8000] D loss: 0.5232, G loss: 8.0759\n",
      "[2892/8000] D loss: 0.7281, G loss: 3.3895\n",
      "[3252/8000] D loss: 0.7403, G loss: 4.2581\n",
      "[3612/8000] D loss: 1.0278, G loss: 7.3134\n",
      "[3972/8000] D loss: 0.9083, G loss: 4.2306\n",
      "[4332/8000] D loss: 1.1130, G loss: 1.8440\n",
      "[4692/8000] D loss: 0.7163, G loss: 5.0803\n",
      "[5052/8000] D loss: 0.9667, G loss: 6.4338\n",
      "[5412/8000] D loss: 0.7458, G loss: 7.2579\n",
      "[5772/8000] D loss: 0.7299, G loss: 6.8406\n",
      "[6132/8000] D loss: 0.6345, G loss: 5.0268\n",
      "[6492/8000] D loss: 0.6882, G loss: 4.2994\n",
      "[6852/8000] D loss: 1.0312, G loss: 3.4400\n",
      "[7212/8000] D loss: 1.0870, G loss: 1.7589\n",
      "[7572/8000] D loss: 0.6300, G loss: 9.0673\n",
      "[7932/8000] D loss: 0.8469, G loss: 8.7783\n",
      "train error: \n",
      " D loss: 0.786492, G loss: 4.992773, D accuracy: 75.9%, cell accuracy: 98.6%, board accuracy: 48.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.869272, G loss: 12.839017, D accuracy: 80.4%, cell accuracy: 98.1%, board accuracy: 23.4% \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0877, G loss: 1.7726\n",
      "[372/8000] D loss: 1.0982, G loss: 3.2113\n",
      "[732/8000] D loss: 0.7551, G loss: 4.5446\n",
      "[1092/8000] D loss: 0.8727, G loss: 3.6293\n",
      "[1452/8000] D loss: 0.5553, G loss: 6.2230\n",
      "[1812/8000] D loss: 0.7535, G loss: 7.9077\n",
      "[2172/8000] D loss: 1.0520, G loss: 2.5688\n",
      "[2532/8000] D loss: 0.7305, G loss: 6.0309\n",
      "[2892/8000] D loss: 0.7000, G loss: 7.5868\n",
      "[3252/8000] D loss: 0.7844, G loss: 4.1710\n",
      "[3612/8000] D loss: 1.0572, G loss: 4.8811\n",
      "[3972/8000] D loss: 0.6191, G loss: 6.8661\n",
      "[4332/8000] D loss: 0.5560, G loss: 5.6011\n",
      "[4692/8000] D loss: 0.8060, G loss: 6.5597\n",
      "[5052/8000] D loss: 0.7429, G loss: 4.0085\n",
      "[5412/8000] D loss: 0.8660, G loss: 3.2378\n",
      "[5772/8000] D loss: 0.9987, G loss: 4.8837\n",
      "[6132/8000] D loss: 0.5597, G loss: 7.9820\n",
      "[6492/8000] D loss: 0.6161, G loss: 4.6570\n",
      "[6852/8000] D loss: 0.7194, G loss: 5.4381\n",
      "[7212/8000] D loss: 0.5309, G loss: 3.2927\n",
      "[7572/8000] D loss: 1.1249, G loss: 3.2673\n",
      "[7932/8000] D loss: 0.8496, G loss: 3.4619\n",
      "train error: \n",
      " D loss: 0.906198, G loss: 4.034210, D accuracy: 73.2%, cell accuracy: 98.6%, board accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.759586, G loss: 11.036310, D accuracy: 83.1%, cell accuracy: 98.2%, board accuracy: 24.9% \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4144, G loss: 7.1774\n",
      "[372/8000] D loss: 0.9686, G loss: 3.0933\n",
      "[732/8000] D loss: 1.0343, G loss: 3.7824\n",
      "[1092/8000] D loss: 1.2085, G loss: 4.3874\n",
      "[1452/8000] D loss: 0.9604, G loss: 4.4185\n",
      "[1812/8000] D loss: 1.0335, G loss: 2.4110\n",
      "[2172/8000] D loss: 0.7738, G loss: 3.6162\n",
      "[2532/8000] D loss: 0.8614, G loss: 5.1519\n",
      "[2892/8000] D loss: 0.9468, G loss: 2.8870\n",
      "[3252/8000] D loss: 1.0200, G loss: 2.4475\n",
      "[3612/8000] D loss: 0.7393, G loss: 6.9359\n",
      "[3972/8000] D loss: 0.8034, G loss: 3.2294\n",
      "[4332/8000] D loss: 0.6408, G loss: 3.5029\n",
      "[4692/8000] D loss: 0.2700, G loss: 8.3783\n",
      "[5052/8000] D loss: 1.0816, G loss: 3.1901\n",
      "[5412/8000] D loss: 0.8447, G loss: 4.4129\n",
      "[5772/8000] D loss: 1.2831, G loss: 0.8368\n",
      "[6132/8000] D loss: 1.0358, G loss: 4.3977\n",
      "[6492/8000] D loss: 0.7023, G loss: 5.2648\n",
      "[6852/8000] D loss: 0.3807, G loss: 6.6302\n",
      "[7212/8000] D loss: 0.5613, G loss: 5.7021\n",
      "[7572/8000] D loss: 1.3012, G loss: 1.0013\n",
      "[7932/8000] D loss: 0.3363, G loss: 8.0528\n",
      "train error: \n",
      " D loss: 0.821083, G loss: 4.336827, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.790510, G loss: 11.653581, D accuracy: 82.4%, cell accuracy: 98.1%, board accuracy: 25.4% \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9004, G loss: 4.2019\n",
      "[372/8000] D loss: 1.0305, G loss: 7.3366\n",
      "[732/8000] D loss: 0.6888, G loss: 4.1884\n",
      "[1092/8000] D loss: 0.7153, G loss: 5.5321\n",
      "[1452/8000] D loss: 0.8187, G loss: 4.3328\n",
      "[1812/8000] D loss: 0.7867, G loss: 4.6271\n",
      "[2172/8000] D loss: 0.8644, G loss: 9.2951\n",
      "[2532/8000] D loss: 0.8217, G loss: 3.1596\n",
      "[2892/8000] D loss: 0.8450, G loss: 3.9535\n",
      "[3252/8000] D loss: 1.0068, G loss: 3.1011\n",
      "[3612/8000] D loss: 0.9379, G loss: 2.7950\n",
      "[3972/8000] D loss: 0.8507, G loss: 3.4608\n",
      "[4332/8000] D loss: 0.6657, G loss: 8.4536\n",
      "[4692/8000] D loss: 0.8936, G loss: 6.9400\n",
      "[5052/8000] D loss: 1.0599, G loss: 2.5177\n",
      "[5412/8000] D loss: 0.7163, G loss: 5.0729\n",
      "[5772/8000] D loss: 0.5860, G loss: 3.9795\n",
      "[6132/8000] D loss: 0.8513, G loss: 3.3541\n",
      "[6492/8000] D loss: 0.7498, G loss: 4.2544\n",
      "[6852/8000] D loss: 0.8699, G loss: 1.9739\n",
      "[7212/8000] D loss: 0.7176, G loss: 5.3257\n",
      "[7572/8000] D loss: 0.6177, G loss: 7.1066\n",
      "[7932/8000] D loss: 0.9873, G loss: 4.2035\n",
      "train error: \n",
      " D loss: 0.878148, G loss: 3.280270, D accuracy: 73.5%, cell accuracy: 98.6%, board accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.816243, G loss: 9.663279, D accuracy: 82.8%, cell accuracy: 98.1%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7011, G loss: 4.8625\n",
      "[372/8000] D loss: 1.2004, G loss: 1.4775\n",
      "[732/8000] D loss: 0.8725, G loss: 3.8799\n",
      "[1092/8000] D loss: 0.8594, G loss: 3.0168\n",
      "[1452/8000] D loss: 0.7770, G loss: 4.8522\n",
      "[1812/8000] D loss: 0.9180, G loss: 3.2702\n",
      "[2172/8000] D loss: 0.6758, G loss: 5.1896\n",
      "[2532/8000] D loss: 0.6032, G loss: 4.7016\n",
      "[2892/8000] D loss: 1.0116, G loss: 4.3804\n",
      "[3252/8000] D loss: 0.4040, G loss: 9.2015\n",
      "[3612/8000] D loss: 1.0028, G loss: 6.6773\n",
      "[3972/8000] D loss: 0.4981, G loss: 5.2298\n",
      "[4332/8000] D loss: 0.9528, G loss: 3.3124\n",
      "[4692/8000] D loss: 1.0440, G loss: 2.2921\n",
      "[5052/8000] D loss: 0.8757, G loss: 4.0759\n",
      "[5412/8000] D loss: 0.9134, G loss: 5.0150\n",
      "[5772/8000] D loss: 0.5453, G loss: 6.1458\n",
      "[6132/8000] D loss: 0.9671, G loss: 2.0053\n",
      "[6492/8000] D loss: 0.7411, G loss: 5.1215\n",
      "[6852/8000] D loss: 0.7408, G loss: 5.4545\n",
      "[7212/8000] D loss: 0.7929, G loss: 4.3715\n",
      "[7572/8000] D loss: 0.5484, G loss: 4.3926\n",
      "[7932/8000] D loss: 0.8591, G loss: 9.4371\n",
      "train error: \n",
      " D loss: 0.824092, G loss: 4.237636, D accuracy: 74.3%, cell accuracy: 98.6%, board accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.833017, G loss: 11.563175, D accuracy: 82.9%, cell accuracy: 98.1%, board accuracy: 24.9% \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8891, G loss: 4.7290\n",
      "[372/8000] D loss: 0.6371, G loss: 6.3677\n",
      "[732/8000] D loss: 0.9049, G loss: 3.8301\n",
      "[1092/8000] D loss: 0.6501, G loss: 7.4500\n",
      "[1452/8000] D loss: 0.6894, G loss: 6.2088\n",
      "[1812/8000] D loss: 1.2406, G loss: 4.3100\n",
      "[2172/8000] D loss: 0.6117, G loss: 7.7853\n",
      "[2532/8000] D loss: 0.7377, G loss: 3.9661\n",
      "[2892/8000] D loss: 0.9949, G loss: 6.3761\n",
      "[3252/8000] D loss: 1.1074, G loss: 2.1718\n",
      "[3612/8000] D loss: 1.0349, G loss: 2.0120\n",
      "[3972/8000] D loss: 0.4735, G loss: 9.3779\n",
      "[4332/8000] D loss: 0.9853, G loss: 4.8622\n",
      "[4692/8000] D loss: 0.8630, G loss: 4.5563\n",
      "[5052/8000] D loss: 0.8735, G loss: 5.3358\n",
      "[5412/8000] D loss: 0.5765, G loss: 6.8082\n",
      "[5772/8000] D loss: 0.5867, G loss: 6.4389\n",
      "[6132/8000] D loss: 0.9829, G loss: 3.9874\n",
      "[6492/8000] D loss: 0.7334, G loss: 4.8032\n",
      "[6852/8000] D loss: 0.5742, G loss: 6.1830\n",
      "[7212/8000] D loss: 0.7851, G loss: 6.5901\n",
      "[7572/8000] D loss: 0.8937, G loss: 2.5830\n",
      "[7932/8000] D loss: 0.6698, G loss: 5.7035\n",
      "train error: \n",
      " D loss: 0.825830, G loss: 4.395486, D accuracy: 74.5%, cell accuracy: 98.6%, board accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.939821, G loss: 11.833462, D accuracy: 80.8%, cell accuracy: 98.1%, board accuracy: 24.4% \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8269, G loss: 3.1522\n",
      "[372/8000] D loss: 0.9508, G loss: 5.1036\n",
      "[732/8000] D loss: 1.0893, G loss: 3.4355\n",
      "[1092/8000] D loss: 1.0188, G loss: 5.1160\n",
      "[1452/8000] D loss: 0.8583, G loss: 3.6770\n",
      "[1812/8000] D loss: 0.9495, G loss: 3.2340\n",
      "[2172/8000] D loss: 1.0465, G loss: 2.7097\n",
      "[2532/8000] D loss: 0.7722, G loss: 5.0247\n",
      "[2892/8000] D loss: 0.6913, G loss: 5.7641\n",
      "[3252/8000] D loss: 0.5109, G loss: 5.0673\n",
      "[3612/8000] D loss: 0.7541, G loss: 2.9621\n",
      "[3972/8000] D loss: 1.0094, G loss: 1.9621\n",
      "[4332/8000] D loss: 0.8142, G loss: 4.1864\n",
      "[4692/8000] D loss: 0.9411, G loss: 2.6413\n",
      "[5052/8000] D loss: 0.7972, G loss: 4.3515\n",
      "[5412/8000] D loss: 1.0913, G loss: 3.1355\n",
      "[5772/8000] D loss: 0.7951, G loss: 3.9524\n",
      "[6132/8000] D loss: 0.5706, G loss: 5.6886\n",
      "[6492/8000] D loss: 0.8439, G loss: 1.9621\n",
      "[6852/8000] D loss: 1.0920, G loss: 2.7886\n",
      "[7212/8000] D loss: 0.7731, G loss: 4.3061\n",
      "[7572/8000] D loss: 0.6357, G loss: 2.7715\n",
      "[7932/8000] D loss: 0.8368, G loss: 6.7786\n",
      "train error: \n",
      " D loss: 0.793786, G loss: 5.031010, D accuracy: 75.2%, cell accuracy: 98.6%, board accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.871061, G loss: 13.055640, D accuracy: 82.0%, cell accuracy: 98.1%, board accuracy: 24.2% \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6288, G loss: 3.6543\n",
      "[372/8000] D loss: 0.7683, G loss: 8.3661\n",
      "[732/8000] D loss: 0.6661, G loss: 7.9501\n",
      "[1092/8000] D loss: 0.5230, G loss: 5.0193\n",
      "[1452/8000] D loss: 0.6094, G loss: 5.0607\n",
      "[1812/8000] D loss: 0.5247, G loss: 8.7287\n",
      "[2172/8000] D loss: 0.7495, G loss: 4.0988\n",
      "[2532/8000] D loss: 0.5956, G loss: 6.1805\n",
      "[2892/8000] D loss: 0.6298, G loss: 6.0111\n",
      "[3252/8000] D loss: 0.5358, G loss: 9.5428\n",
      "[3612/8000] D loss: 0.5215, G loss: 8.9611\n",
      "[3972/8000] D loss: 0.6298, G loss: 9.2401\n",
      "[4332/8000] D loss: 0.4933, G loss: 6.4520\n",
      "[4692/8000] D loss: 0.8498, G loss: 3.2136\n",
      "[5052/8000] D loss: 0.6314, G loss: 7.2139\n",
      "[5412/8000] D loss: 1.0862, G loss: 2.3654\n",
      "[5772/8000] D loss: 0.7140, G loss: 6.9629\n",
      "[6132/8000] D loss: 0.9422, G loss: 4.1964\n",
      "[6492/8000] D loss: 1.1279, G loss: 3.8121\n",
      "[6852/8000] D loss: 0.6537, G loss: 4.7312\n",
      "[7212/8000] D loss: 0.3298, G loss: 4.9879\n",
      "[7572/8000] D loss: 0.8705, G loss: 3.7922\n",
      "[7932/8000] D loss: 0.7235, G loss: 5.3285\n",
      "train error: \n",
      " D loss: 0.805624, G loss: 4.519251, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 49.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.874503, G loss: 12.338192, D accuracy: 81.8%, cell accuracy: 98.1%, board accuracy: 25.5% \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8655, G loss: 3.7713\n",
      "[372/8000] D loss: 1.0718, G loss: 3.1194\n",
      "[732/8000] D loss: 0.8969, G loss: 7.6985\n",
      "[1092/8000] D loss: 0.4209, G loss: 6.4556\n",
      "[1452/8000] D loss: 0.9106, G loss: 3.1315\n",
      "[1812/8000] D loss: 0.8480, G loss: 3.5490\n",
      "[2172/8000] D loss: 0.8185, G loss: 6.2960\n",
      "[2532/8000] D loss: 0.8624, G loss: 3.5160\n",
      "[2892/8000] D loss: 0.7524, G loss: 5.0724\n",
      "[3252/8000] D loss: 1.0907, G loss: 5.7298\n",
      "[3612/8000] D loss: 0.9639, G loss: 6.5404\n",
      "[3972/8000] D loss: 1.0793, G loss: 2.3009\n",
      "[4332/8000] D loss: 0.8373, G loss: 5.3811\n",
      "[4692/8000] D loss: 0.5007, G loss: 5.8703\n",
      "[5052/8000] D loss: 0.4479, G loss: 5.8685\n",
      "[5412/8000] D loss: 0.9782, G loss: 5.0518\n",
      "[5772/8000] D loss: 0.9379, G loss: 3.2480\n",
      "[6132/8000] D loss: 0.9801, G loss: 2.1768\n",
      "[6492/8000] D loss: 0.5388, G loss: 3.6497\n",
      "[6852/8000] D loss: 0.7856, G loss: 6.2518\n",
      "[7212/8000] D loss: 1.0034, G loss: 3.7064\n",
      "[7572/8000] D loss: 0.6096, G loss: 7.1685\n",
      "[7932/8000] D loss: 0.5796, G loss: 4.6429\n",
      "train error: \n",
      " D loss: 0.813958, G loss: 4.681831, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.875674, G loss: 12.203066, D accuracy: 82.0%, cell accuracy: 98.1%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7078, G loss: 6.8572\n",
      "[372/8000] D loss: 0.6765, G loss: 3.9019\n",
      "[732/8000] D loss: 1.0298, G loss: 6.2983\n",
      "[1092/8000] D loss: 1.3126, G loss: 1.8023\n",
      "[1452/8000] D loss: 0.8047, G loss: 6.7161\n",
      "[1812/8000] D loss: 0.7955, G loss: 4.9180\n",
      "[2172/8000] D loss: 0.8121, G loss: 7.0853\n",
      "[2532/8000] D loss: 1.2929, G loss: 1.6400\n",
      "[2892/8000] D loss: 0.9193, G loss: 3.5183\n",
      "[3252/8000] D loss: 0.9312, G loss: 5.7395\n",
      "[3612/8000] D loss: 0.9646, G loss: 4.1031\n",
      "[3972/8000] D loss: 0.9196, G loss: 5.2502\n",
      "[4332/8000] D loss: 0.6247, G loss: 6.8170\n",
      "[4692/8000] D loss: 0.6611, G loss: 5.5088\n",
      "[5052/8000] D loss: 0.6701, G loss: 8.0910\n",
      "[5412/8000] D loss: 0.7112, G loss: 5.2648\n",
      "[5772/8000] D loss: 0.5636, G loss: 3.8012\n",
      "[6132/8000] D loss: 0.8554, G loss: 4.9184\n",
      "[6492/8000] D loss: 1.3072, G loss: 1.4895\n",
      "[6852/8000] D loss: 0.9911, G loss: 2.3872\n",
      "[7212/8000] D loss: 0.9928, G loss: 5.7887\n",
      "[7572/8000] D loss: 0.9506, G loss: 4.1472\n",
      "[7932/8000] D loss: 0.7861, G loss: 2.7472\n",
      "train error: \n",
      " D loss: 0.805082, G loss: 4.277067, D accuracy: 74.9%, cell accuracy: 98.6%, board accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.885382, G loss: 11.733516, D accuracy: 81.7%, cell accuracy: 98.1%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6502, G loss: 4.1502\n",
      "[372/8000] D loss: 0.7969, G loss: 4.6004\n",
      "[732/8000] D loss: 0.6937, G loss: 4.4225\n",
      "[1092/8000] D loss: 0.8312, G loss: 3.3282\n",
      "[1452/8000] D loss: 0.7952, G loss: 8.8141\n",
      "[1812/8000] D loss: 0.5804, G loss: 8.1822\n",
      "[2172/8000] D loss: 0.7684, G loss: 4.1383\n",
      "[2532/8000] D loss: 0.8745, G loss: 4.9161\n",
      "[2892/8000] D loss: 0.7183, G loss: 9.7819\n",
      "[3252/8000] D loss: 1.0256, G loss: 3.7279\n",
      "[3612/8000] D loss: 1.2308, G loss: 2.2578\n",
      "[3972/8000] D loss: 0.8061, G loss: 6.8782\n",
      "[4332/8000] D loss: 0.7203, G loss: 4.1577\n",
      "[4692/8000] D loss: 0.8997, G loss: 2.2947\n",
      "[5052/8000] D loss: 0.7266, G loss: 4.4359\n",
      "[5412/8000] D loss: 1.1369, G loss: 2.0147\n",
      "[5772/8000] D loss: 1.0223, G loss: 6.6603\n",
      "[6132/8000] D loss: 0.9008, G loss: 2.9974\n",
      "[6492/8000] D loss: 0.6435, G loss: 3.3071\n",
      "[6852/8000] D loss: 0.6673, G loss: 6.6160\n",
      "[7212/8000] D loss: 0.9450, G loss: 2.4272\n",
      "[7572/8000] D loss: 0.6247, G loss: 6.3461\n",
      "[7932/8000] D loss: 0.3861, G loss: 7.3161\n",
      "train error: \n",
      " D loss: 0.812018, G loss: 4.787976, D accuracy: 74.9%, cell accuracy: 98.6%, board accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.837406, G loss: 12.909974, D accuracy: 81.8%, cell accuracy: 98.1%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3665, G loss: 7.2036\n",
      "[372/8000] D loss: 0.8998, G loss: 3.6924\n",
      "[732/8000] D loss: 0.5961, G loss: 5.4833\n",
      "[1092/8000] D loss: 0.9129, G loss: 5.2037\n",
      "[1452/8000] D loss: 0.8181, G loss: 5.8519\n",
      "[1812/8000] D loss: 0.7920, G loss: 4.1496\n",
      "[2172/8000] D loss: 0.5653, G loss: 5.4441\n",
      "[2532/8000] D loss: 0.7484, G loss: 8.0658\n",
      "[2892/8000] D loss: 0.9832, G loss: 4.2579\n",
      "[3252/8000] D loss: 1.1438, G loss: 2.9393\n",
      "[3612/8000] D loss: 0.2836, G loss: 6.4268\n",
      "[3972/8000] D loss: 0.5594, G loss: 5.1673\n",
      "[4332/8000] D loss: 0.5685, G loss: 7.3107\n",
      "[4692/8000] D loss: 1.0289, G loss: 3.6201\n",
      "[5052/8000] D loss: 0.5807, G loss: 7.4945\n",
      "[5412/8000] D loss: 0.9439, G loss: 2.5701\n",
      "[5772/8000] D loss: 1.0919, G loss: 1.7197\n",
      "[6132/8000] D loss: 0.9022, G loss: 6.2978\n",
      "[6492/8000] D loss: 0.9922, G loss: 4.4699\n",
      "[6852/8000] D loss: 0.7822, G loss: 4.9929\n",
      "[7212/8000] D loss: 0.6997, G loss: 7.1663\n",
      "[7572/8000] D loss: 1.0103, G loss: 2.9616\n",
      "[7932/8000] D loss: 0.6373, G loss: 5.5609\n",
      "train error: \n",
      " D loss: 0.794263, G loss: 4.576758, D accuracy: 75.4%, cell accuracy: 98.6%, board accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.836300, G loss: 12.604621, D accuracy: 82.7%, cell accuracy: 98.1%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4353, G loss: 10.0691\n",
      "[372/8000] D loss: 0.8718, G loss: 3.0989\n",
      "[732/8000] D loss: 0.9144, G loss: 3.5684\n",
      "[1092/8000] D loss: 0.9174, G loss: 3.4709\n",
      "[1452/8000] D loss: 0.6389, G loss: 8.0333\n",
      "[1812/8000] D loss: 0.7133, G loss: 3.4030\n",
      "[2172/8000] D loss: 0.5682, G loss: 3.2049\n",
      "[2532/8000] D loss: 1.0969, G loss: 4.2787\n",
      "[2892/8000] D loss: 1.0560, G loss: 3.8629\n",
      "[3252/8000] D loss: 0.8671, G loss: 2.4627\n",
      "[3612/8000] D loss: 0.8328, G loss: 6.4462\n",
      "[3972/8000] D loss: 0.5173, G loss: 6.1354\n",
      "[4332/8000] D loss: 0.5293, G loss: 8.1815\n",
      "[4692/8000] D loss: 0.8436, G loss: 5.9292\n",
      "[5052/8000] D loss: 1.2125, G loss: 1.0097\n",
      "[5412/8000] D loss: 0.8513, G loss: 2.7923\n",
      "[5772/8000] D loss: 0.6427, G loss: 4.3187\n",
      "[6132/8000] D loss: 0.6231, G loss: 9.0094\n",
      "[6492/8000] D loss: 0.3518, G loss: 6.5045\n",
      "[6852/8000] D loss: 0.8146, G loss: 4.0064\n",
      "[7212/8000] D loss: 0.6943, G loss: 7.3331\n",
      "[7572/8000] D loss: 0.3815, G loss: 6.2865\n",
      "[7932/8000] D loss: 0.9068, G loss: 4.1446\n",
      "train error: \n",
      " D loss: 0.808813, G loss: 5.932050, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.971315, G loss: 14.646170, D accuracy: 78.3%, cell accuracy: 98.1%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8615, G loss: 6.1395\n",
      "[372/8000] D loss: 0.5808, G loss: 4.3272\n",
      "[732/8000] D loss: 0.7909, G loss: 4.9290\n",
      "[1092/8000] D loss: 0.5682, G loss: 8.6237\n",
      "[1452/8000] D loss: 1.0804, G loss: 3.1103\n",
      "[1812/8000] D loss: 1.0730, G loss: 3.1933\n",
      "[2172/8000] D loss: 1.0117, G loss: 4.7342\n",
      "[2532/8000] D loss: 0.6277, G loss: 5.5592\n",
      "[2892/8000] D loss: 0.9471, G loss: 2.6626\n",
      "[3252/8000] D loss: 0.8467, G loss: 8.7068\n",
      "[3612/8000] D loss: 0.8233, G loss: 2.3517\n",
      "[3972/8000] D loss: 0.5965, G loss: 10.2020\n",
      "[4332/8000] D loss: 1.1833, G loss: 5.1208\n",
      "[4692/8000] D loss: 0.7894, G loss: 3.4358\n",
      "[5052/8000] D loss: 0.6610, G loss: 3.1047\n",
      "[5412/8000] D loss: 0.8936, G loss: 6.0202\n",
      "[5772/8000] D loss: 0.3429, G loss: 12.1261\n",
      "[6132/8000] D loss: 1.0939, G loss: 2.3326\n",
      "[6492/8000] D loss: 0.9061, G loss: 4.5073\n",
      "[6852/8000] D loss: 0.8425, G loss: 5.7763\n",
      "[7212/8000] D loss: 0.8944, G loss: 2.9879\n",
      "[7572/8000] D loss: 0.7930, G loss: 5.0444\n",
      "[7932/8000] D loss: 0.8338, G loss: 5.1047\n",
      "train error: \n",
      " D loss: 0.807487, G loss: 4.664691, D accuracy: 74.4%, cell accuracy: 98.6%, board accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.880677, G loss: 12.297935, D accuracy: 80.4%, cell accuracy: 98.1%, board accuracy: 24.9% \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8215, G loss: 2.6521\n",
      "[372/8000] D loss: 0.8604, G loss: 5.5837\n",
      "[732/8000] D loss: 0.5159, G loss: 7.5272\n",
      "[1092/8000] D loss: 1.0645, G loss: 4.2570\n",
      "[1452/8000] D loss: 0.7003, G loss: 5.3360\n",
      "[1812/8000] D loss: 0.7348, G loss: 8.7988\n",
      "[2172/8000] D loss: 0.5307, G loss: 7.4216\n",
      "[2532/8000] D loss: 0.8206, G loss: 6.0873\n",
      "[2892/8000] D loss: 0.8643, G loss: 2.8965\n",
      "[3252/8000] D loss: 0.9951, G loss: 2.4810\n",
      "[3612/8000] D loss: 0.7497, G loss: 5.0694\n",
      "[3972/8000] D loss: 0.7132, G loss: 7.7258\n",
      "[4332/8000] D loss: 0.8098, G loss: 4.3645\n",
      "[4692/8000] D loss: 0.6834, G loss: 4.5404\n",
      "[5052/8000] D loss: 0.8395, G loss: 5.8744\n",
      "[5412/8000] D loss: 0.5281, G loss: 5.9807\n",
      "[5772/8000] D loss: 0.9897, G loss: 2.8974\n",
      "[6132/8000] D loss: 0.6242, G loss: 6.4879\n",
      "[6492/8000] D loss: 0.9265, G loss: 7.0496\n",
      "[6852/8000] D loss: 0.7209, G loss: 5.6129\n",
      "[7212/8000] D loss: 0.4482, G loss: 6.8418\n",
      "[7572/8000] D loss: 0.6163, G loss: 6.4149\n",
      "[7932/8000] D loss: 0.8514, G loss: 3.2043\n",
      "train error: \n",
      " D loss: 0.815841, G loss: 4.383797, D accuracy: 74.4%, cell accuracy: 98.6%, board accuracy: 49.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.928850, G loss: 11.025674, D accuracy: 79.7%, cell accuracy: 98.1%, board accuracy: 25.4% \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8248, G loss: 3.5357\n",
      "[372/8000] D loss: 0.7012, G loss: 6.1226\n",
      "[732/8000] D loss: 0.7126, G loss: 4.1969\n",
      "[1092/8000] D loss: 0.9935, G loss: 3.8642\n",
      "[1452/8000] D loss: 0.9733, G loss: 2.9712\n",
      "[1812/8000] D loss: 0.5094, G loss: 7.9092\n",
      "[2172/8000] D loss: 0.5553, G loss: 5.8936\n",
      "[2532/8000] D loss: 0.7206, G loss: 2.7920\n",
      "[2892/8000] D loss: 0.6937, G loss: 7.7353\n",
      "[3252/8000] D loss: 0.9143, G loss: 2.8815\n",
      "[3612/8000] D loss: 0.6485, G loss: 7.5436\n",
      "[3972/8000] D loss: 1.0329, G loss: 3.0959\n",
      "[4332/8000] D loss: 0.7557, G loss: 5.4593\n",
      "[4692/8000] D loss: 0.7879, G loss: 4.7574\n",
      "[5052/8000] D loss: 0.6710, G loss: 3.8890\n",
      "[5412/8000] D loss: 1.0614, G loss: 3.3213\n",
      "[5772/8000] D loss: 0.8159, G loss: 3.3001\n",
      "[6132/8000] D loss: 1.4470, G loss: 1.1704\n",
      "[6492/8000] D loss: 0.7718, G loss: 2.0373\n",
      "[6852/8000] D loss: 0.9969, G loss: 2.0799\n",
      "[7212/8000] D loss: 1.0842, G loss: 3.9054\n",
      "[7572/8000] D loss: 0.7573, G loss: 4.8517\n",
      "[7932/8000] D loss: 0.8867, G loss: 6.1806\n",
      "train error: \n",
      " D loss: 0.812803, G loss: 4.409574, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.915383, G loss: 11.918150, D accuracy: 82.5%, cell accuracy: 98.1%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8488, G loss: 2.8758\n",
      "[372/8000] D loss: 0.9621, G loss: 5.9457\n",
      "[732/8000] D loss: 0.4758, G loss: 8.4064\n",
      "[1092/8000] D loss: 0.7177, G loss: 5.8153\n",
      "[1452/8000] D loss: 0.5950, G loss: 4.3754\n",
      "[1812/8000] D loss: 1.0628, G loss: 3.1157\n",
      "[2172/8000] D loss: 0.9856, G loss: 3.4441\n",
      "[2532/8000] D loss: 0.9817, G loss: 3.9108\n",
      "[2892/8000] D loss: 0.8519, G loss: 2.8905\n",
      "[3252/8000] D loss: 0.8190, G loss: 7.6964\n",
      "[3612/8000] D loss: 0.4658, G loss: 6.1716\n",
      "[3972/8000] D loss: 0.5805, G loss: 8.0759\n",
      "[4332/8000] D loss: 0.7407, G loss: 9.4490\n",
      "[4692/8000] D loss: 0.6416, G loss: 7.2695\n",
      "[5052/8000] D loss: 0.8043, G loss: 5.0430\n",
      "[5412/8000] D loss: 0.8463, G loss: 4.5848\n",
      "[5772/8000] D loss: 0.7260, G loss: 3.4219\n",
      "[6132/8000] D loss: 0.6224, G loss: 8.7188\n",
      "[6492/8000] D loss: 1.1264, G loss: 2.0649\n",
      "[6852/8000] D loss: 0.6544, G loss: 8.5933\n",
      "[7212/8000] D loss: 0.6768, G loss: 4.5229\n",
      "[7572/8000] D loss: 0.8365, G loss: 5.0132\n",
      "[7932/8000] D loss: 0.7453, G loss: 3.2252\n",
      "train error: \n",
      " D loss: 0.806363, G loss: 4.225151, D accuracy: 75.3%, cell accuracy: 98.6%, board accuracy: 49.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.849972, G loss: 11.445699, D accuracy: 81.9%, cell accuracy: 98.1%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9294, G loss: 4.5556\n",
      "[372/8000] D loss: 0.5458, G loss: 6.6558\n",
      "[732/8000] D loss: 1.0351, G loss: 2.9234\n",
      "[1092/8000] D loss: 0.3019, G loss: 7.7386\n",
      "[1452/8000] D loss: 0.6768, G loss: 4.3616\n",
      "[1812/8000] D loss: 0.9557, G loss: 2.3883\n",
      "[2172/8000] D loss: 0.5253, G loss: 7.7457\n",
      "[2532/8000] D loss: 0.9608, G loss: 2.7958\n",
      "[2892/8000] D loss: 0.7544, G loss: 3.2626\n",
      "[3252/8000] D loss: 0.6649, G loss: 8.3186\n",
      "[3612/8000] D loss: 0.9123, G loss: 4.6768\n",
      "[3972/8000] D loss: 0.9378, G loss: 3.1958\n",
      "[4332/8000] D loss: 0.9311, G loss: 2.8946\n",
      "[4692/8000] D loss: 0.8508, G loss: 2.2426\n",
      "[5052/8000] D loss: 1.0367, G loss: 1.3237\n",
      "[5412/8000] D loss: 0.8321, G loss: 2.8570\n",
      "[5772/8000] D loss: 0.4616, G loss: 9.4350\n",
      "[6132/8000] D loss: 0.7529, G loss: 5.8726\n",
      "[6492/8000] D loss: 0.9064, G loss: 5.0571\n",
      "[6852/8000] D loss: 0.7568, G loss: 4.6425\n",
      "[7212/8000] D loss: 0.7846, G loss: 5.3392\n",
      "[7572/8000] D loss: 0.6458, G loss: 9.2044\n",
      "[7932/8000] D loss: 0.2596, G loss: 6.8878\n",
      "train error: \n",
      " D loss: 0.811771, G loss: 4.644690, D accuracy: 74.4%, cell accuracy: 98.6%, board accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.902602, G loss: 12.550985, D accuracy: 82.0%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0558, G loss: 3.0525\n",
      "[372/8000] D loss: 0.7931, G loss: 2.6192\n",
      "[732/8000] D loss: 0.5058, G loss: 8.2173\n",
      "[1092/8000] D loss: 0.8165, G loss: 6.4271\n",
      "[1452/8000] D loss: 0.6393, G loss: 4.7608\n",
      "[1812/8000] D loss: 0.4478, G loss: 7.1091\n",
      "[2172/8000] D loss: 0.9184, G loss: 3.4363\n",
      "[2532/8000] D loss: 0.8404, G loss: 6.0464\n",
      "[2892/8000] D loss: 0.6773, G loss: 5.3252\n",
      "[3252/8000] D loss: 0.7717, G loss: 2.4440\n",
      "[3612/8000] D loss: 0.9222, G loss: 8.0485\n",
      "[3972/8000] D loss: 0.7865, G loss: 3.9637\n",
      "[4332/8000] D loss: 0.9150, G loss: 3.1819\n",
      "[4692/8000] D loss: 0.7134, G loss: 5.9362\n",
      "[5052/8000] D loss: 0.9411, G loss: 2.3829\n",
      "[5412/8000] D loss: 0.6743, G loss: 4.3777\n",
      "[5772/8000] D loss: 0.8166, G loss: 2.0285\n",
      "[6132/8000] D loss: 1.1070, G loss: 2.2853\n",
      "[6492/8000] D loss: 0.7091, G loss: 6.0069\n",
      "[6852/8000] D loss: 0.8111, G loss: 2.2396\n",
      "[7212/8000] D loss: 0.9650, G loss: 3.8747\n",
      "[7572/8000] D loss: 1.0172, G loss: 1.8012\n",
      "[7932/8000] D loss: 0.7432, G loss: 6.1907\n",
      "train error: \n",
      " D loss: 0.807005, G loss: 4.979301, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 48.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.862851, G loss: 13.093261, D accuracy: 83.2%, cell accuracy: 98.1%, board accuracy: 23.5% \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7629, G loss: 4.7594\n",
      "[372/8000] D loss: 1.1355, G loss: 2.1818\n",
      "[732/8000] D loss: 0.7478, G loss: 6.7158\n",
      "[1092/8000] D loss: 0.7713, G loss: 8.2348\n",
      "[1452/8000] D loss: 0.4730, G loss: 7.6773\n",
      "[1812/8000] D loss: 0.8867, G loss: 3.4830\n",
      "[2172/8000] D loss: 0.6693, G loss: 5.7322\n",
      "[2532/8000] D loss: 0.5620, G loss: 9.0362\n",
      "[2892/8000] D loss: 0.9162, G loss: 5.1290\n",
      "[3252/8000] D loss: 0.9738, G loss: 3.7225\n",
      "[3612/8000] D loss: 0.8827, G loss: 3.2653\n",
      "[3972/8000] D loss: 1.1098, G loss: 4.6734\n",
      "[4332/8000] D loss: 1.1297, G loss: 3.3119\n",
      "[4692/8000] D loss: 1.2969, G loss: 3.8548\n",
      "[5052/8000] D loss: 0.8095, G loss: 6.2551\n",
      "[5412/8000] D loss: 0.4495, G loss: 5.7991\n",
      "[5772/8000] D loss: 0.7468, G loss: 4.6295\n",
      "[6132/8000] D loss: 0.8507, G loss: 6.3334\n",
      "[6492/8000] D loss: 0.6508, G loss: 9.6135\n",
      "[6852/8000] D loss: 0.6371, G loss: 6.5538\n",
      "[7212/8000] D loss: 1.0465, G loss: 1.3951\n",
      "[7572/8000] D loss: 0.6450, G loss: 3.8304\n",
      "[7932/8000] D loss: 0.6912, G loss: 5.0531\n",
      "train error: \n",
      " D loss: 0.806365, G loss: 4.124487, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 49.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.915204, G loss: 11.331038, D accuracy: 80.1%, cell accuracy: 98.1%, board accuracy: 23.6% \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8452, G loss: 4.5153\n",
      "[372/8000] D loss: 0.6122, G loss: 4.0591\n",
      "[732/8000] D loss: 1.0870, G loss: 4.7510\n",
      "[1092/8000] D loss: 0.7647, G loss: 3.6439\n",
      "[1452/8000] D loss: 0.7887, G loss: 4.0468\n",
      "[1812/8000] D loss: 0.7866, G loss: 6.3243\n",
      "[2172/8000] D loss: 0.7287, G loss: 4.5416\n",
      "[2532/8000] D loss: 0.7216, G loss: 4.5476\n",
      "[2892/8000] D loss: 1.1152, G loss: 3.2500\n",
      "[3252/8000] D loss: 0.7299, G loss: 6.7211\n",
      "[3612/8000] D loss: 0.7753, G loss: 8.5171\n",
      "[3972/8000] D loss: 0.8966, G loss: 5.6511\n",
      "[4332/8000] D loss: 0.5965, G loss: 5.6987\n",
      "[4692/8000] D loss: 0.5848, G loss: 5.4160\n",
      "[5052/8000] D loss: 0.8520, G loss: 4.1253\n",
      "[5412/8000] D loss: 0.8335, G loss: 2.0371\n",
      "[5772/8000] D loss: 0.4947, G loss: 10.5738\n",
      "[6132/8000] D loss: 0.9017, G loss: 2.1589\n",
      "[6492/8000] D loss: 0.8981, G loss: 5.5407\n",
      "[6852/8000] D loss: 0.8682, G loss: 8.6069\n",
      "[7212/8000] D loss: 0.9351, G loss: 2.9904\n",
      "[7572/8000] D loss: 0.8216, G loss: 2.9591\n",
      "[7932/8000] D loss: 0.6985, G loss: 13.3164\n",
      "train error: \n",
      " D loss: 0.795024, G loss: 5.484999, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.934206, G loss: 13.868864, D accuracy: 80.6%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7265, G loss: 6.2436\n",
      "[372/8000] D loss: 0.8844, G loss: 2.7348\n",
      "[732/8000] D loss: 0.5923, G loss: 8.8335\n",
      "[1092/8000] D loss: 0.6749, G loss: 6.8228\n",
      "[1452/8000] D loss: 0.8211, G loss: 3.3080\n",
      "[1812/8000] D loss: 0.6565, G loss: 4.4229\n",
      "[2172/8000] D loss: 1.2492, G loss: 1.0261\n",
      "[2532/8000] D loss: 0.8862, G loss: 2.1457\n",
      "[2892/8000] D loss: 0.7324, G loss: 2.9201\n",
      "[3252/8000] D loss: 1.0432, G loss: 4.6161\n",
      "[3612/8000] D loss: 0.5572, G loss: 4.5254\n",
      "[3972/8000] D loss: 0.7299, G loss: 3.0069\n",
      "[4332/8000] D loss: 1.0837, G loss: 1.9623\n",
      "[4692/8000] D loss: 0.8502, G loss: 4.3487\n",
      "[5052/8000] D loss: 0.8804, G loss: 6.9681\n",
      "[5412/8000] D loss: 0.4763, G loss: 7.8566\n",
      "[5772/8000] D loss: 1.1546, G loss: 1.1872\n",
      "[6132/8000] D loss: 1.0223, G loss: 5.7938\n",
      "[6492/8000] D loss: 0.7009, G loss: 9.2648\n",
      "[6852/8000] D loss: 1.1217, G loss: 4.0106\n",
      "[7212/8000] D loss: 0.8369, G loss: 6.3176\n",
      "[7572/8000] D loss: 0.5394, G loss: 6.9459\n",
      "[7932/8000] D loss: 0.9168, G loss: 5.3069\n",
      "train error: \n",
      " D loss: 0.813668, G loss: 5.182608, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.894291, G loss: 13.510982, D accuracy: 80.7%, cell accuracy: 98.1%, board accuracy: 24.2% \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5117, G loss: 4.3633\n",
      "[372/8000] D loss: 0.9261, G loss: 4.6336\n",
      "[732/8000] D loss: 0.4482, G loss: 10.0343\n",
      "[1092/8000] D loss: 0.9054, G loss: 2.9288\n",
      "[1452/8000] D loss: 1.1229, G loss: 2.5153\n",
      "[1812/8000] D loss: 0.6521, G loss: 5.8086\n",
      "[2172/8000] D loss: 0.8984, G loss: 2.9952\n",
      "[2532/8000] D loss: 0.8297, G loss: 3.8647\n",
      "[2892/8000] D loss: 0.6597, G loss: 3.7524\n",
      "[3252/8000] D loss: 0.7820, G loss: 3.9264\n",
      "[3612/8000] D loss: 0.5841, G loss: 8.0539\n",
      "[3972/8000] D loss: 1.1085, G loss: 6.2952\n",
      "[4332/8000] D loss: 0.9366, G loss: 2.6111\n",
      "[4692/8000] D loss: 0.8678, G loss: 3.2301\n",
      "[5052/8000] D loss: 0.7012, G loss: 5.3243\n",
      "[5412/8000] D loss: 0.6179, G loss: 5.5896\n",
      "[5772/8000] D loss: 0.7441, G loss: 8.2850\n",
      "[6132/8000] D loss: 0.6090, G loss: 5.7155\n",
      "[6492/8000] D loss: 0.5674, G loss: 6.4644\n",
      "[6852/8000] D loss: 1.0916, G loss: 2.9278\n",
      "[7212/8000] D loss: 0.7712, G loss: 5.4652\n",
      "[7572/8000] D loss: 0.8026, G loss: 3.1985\n",
      "[7932/8000] D loss: 0.8309, G loss: 4.6221\n",
      "train error: \n",
      " D loss: 0.805346, G loss: 4.659245, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.834627, G loss: 12.564434, D accuracy: 81.2%, cell accuracy: 98.1%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9710, G loss: 2.4859\n",
      "[372/8000] D loss: 0.8306, G loss: 4.1889\n",
      "[732/8000] D loss: 0.8876, G loss: 3.7294\n",
      "[1092/8000] D loss: 0.8298, G loss: 6.9984\n",
      "[1452/8000] D loss: 0.7534, G loss: 9.9358\n",
      "[1812/8000] D loss: 0.5946, G loss: 8.2384\n",
      "[2172/8000] D loss: 0.7258, G loss: 4.4477\n",
      "[2532/8000] D loss: 0.8450, G loss: 7.4911\n",
      "[2892/8000] D loss: 0.6603, G loss: 6.6523\n",
      "[3252/8000] D loss: 0.9778, G loss: 1.4708\n",
      "[3612/8000] D loss: 0.9101, G loss: 4.4468\n",
      "[3972/8000] D loss: 0.5093, G loss: 11.3101\n",
      "[4332/8000] D loss: 0.7191, G loss: 4.5110\n",
      "[4692/8000] D loss: 0.7180, G loss: 4.1819\n",
      "[5052/8000] D loss: 0.4775, G loss: 7.2451\n",
      "[5412/8000] D loss: 1.0240, G loss: 3.6467\n",
      "[5772/8000] D loss: 0.6562, G loss: 6.3175\n",
      "[6132/8000] D loss: 1.3112, G loss: 2.2946\n",
      "[6492/8000] D loss: 0.7774, G loss: 5.1104\n",
      "[6852/8000] D loss: 0.7305, G loss: 4.3076\n",
      "[7212/8000] D loss: 0.6088, G loss: 4.3497\n",
      "[7572/8000] D loss: 0.8950, G loss: 4.5772\n",
      "[7932/8000] D loss: 0.6889, G loss: 7.6564\n",
      "train error: \n",
      " D loss: 0.801424, G loss: 5.279247, D accuracy: 74.6%, cell accuracy: 98.6%, board accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.963199, G loss: 13.850142, D accuracy: 78.0%, cell accuracy: 98.2%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6366, G loss: 5.8275\n",
      "[372/8000] D loss: 1.1097, G loss: 2.6751\n",
      "[732/8000] D loss: 0.8005, G loss: 3.0917\n",
      "[1092/8000] D loss: 0.9674, G loss: 4.1385\n",
      "[1452/8000] D loss: 0.7494, G loss: 7.0634\n",
      "[1812/8000] D loss: 0.9641, G loss: 4.5645\n",
      "[2172/8000] D loss: 0.7159, G loss: 4.7785\n",
      "[2532/8000] D loss: 1.1971, G loss: 3.9904\n",
      "[2892/8000] D loss: 0.7356, G loss: 4.7148\n",
      "[3252/8000] D loss: 1.0733, G loss: 1.8072\n",
      "[3612/8000] D loss: 0.9235, G loss: 6.8721\n",
      "[3972/8000] D loss: 0.7105, G loss: 5.5507\n",
      "[4332/8000] D loss: 0.9487, G loss: 2.8471\n",
      "[4692/8000] D loss: 0.8723, G loss: 2.6173\n",
      "[5052/8000] D loss: 0.7725, G loss: 4.4733\n",
      "[5412/8000] D loss: 1.0202, G loss: 4.9136\n",
      "[5772/8000] D loss: 0.8557, G loss: 4.1562\n",
      "[6132/8000] D loss: 1.0436, G loss: 1.9202\n",
      "[6492/8000] D loss: 1.0025, G loss: 2.9475\n",
      "[6852/8000] D loss: 0.7689, G loss: 4.2364\n",
      "[7212/8000] D loss: 0.4786, G loss: 7.4272\n",
      "[7572/8000] D loss: 0.6216, G loss: 10.6107\n",
      "[7932/8000] D loss: 1.0772, G loss: 3.0142\n",
      "train error: \n",
      " D loss: 0.847938, G loss: 3.964623, D accuracy: 73.9%, cell accuracy: 98.6%, board accuracy: 51.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.807889, G loss: 11.311057, D accuracy: 83.0%, cell accuracy: 98.2%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7301, G loss: 8.1633\n",
      "[372/8000] D loss: 0.7708, G loss: 4.0601\n",
      "[732/8000] D loss: 0.8530, G loss: 4.0712\n",
      "[1092/8000] D loss: 0.9119, G loss: 2.6219\n",
      "[1452/8000] D loss: 0.5404, G loss: 5.7412\n",
      "[1812/8000] D loss: 0.7198, G loss: 6.5905\n",
      "[2172/8000] D loss: 0.5500, G loss: 7.3136\n",
      "[2532/8000] D loss: 0.9195, G loss: 2.5580\n",
      "[2892/8000] D loss: 0.9416, G loss: 4.0726\n",
      "[3252/8000] D loss: 0.8805, G loss: 2.8756\n",
      "[3612/8000] D loss: 0.6353, G loss: 6.5914\n",
      "[3972/8000] D loss: 1.3435, G loss: 1.7954\n",
      "[4332/8000] D loss: 0.9638, G loss: 4.5702\n",
      "[4692/8000] D loss: 0.7719, G loss: 5.8926\n",
      "[5052/8000] D loss: 0.6451, G loss: 5.4308\n",
      "[5412/8000] D loss: 0.6973, G loss: 9.7290\n",
      "[5772/8000] D loss: 0.9649, G loss: 3.4878\n",
      "[6132/8000] D loss: 0.5962, G loss: 4.5535\n",
      "[6492/8000] D loss: 0.7337, G loss: 7.1197\n",
      "[6852/8000] D loss: 0.7565, G loss: 5.5220\n",
      "[7212/8000] D loss: 1.0021, G loss: 4.9974\n",
      "[7572/8000] D loss: 0.6527, G loss: 4.7998\n",
      "[7932/8000] D loss: 1.3368, G loss: 1.2738\n",
      "train error: \n",
      " D loss: 0.795326, G loss: 5.447244, D accuracy: 75.4%, cell accuracy: 98.6%, board accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.952319, G loss: 13.937275, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 24.0% \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8176, G loss: 5.1028\n",
      "[372/8000] D loss: 0.7228, G loss: 3.5771\n",
      "[732/8000] D loss: 0.6445, G loss: 7.6070\n",
      "[1092/8000] D loss: 0.7665, G loss: 3.3261\n",
      "[1452/8000] D loss: 0.9114, G loss: 6.8711\n",
      "[1812/8000] D loss: 0.9124, G loss: 7.5827\n",
      "[2172/8000] D loss: 1.1301, G loss: 2.4907\n",
      "[2532/8000] D loss: 0.5953, G loss: 6.7866\n",
      "[2892/8000] D loss: 0.7279, G loss: 7.1091\n",
      "[3252/8000] D loss: 0.4415, G loss: 6.5984\n",
      "[3612/8000] D loss: 0.7880, G loss: 6.8590\n",
      "[3972/8000] D loss: 0.6597, G loss: 2.9094\n",
      "[4332/8000] D loss: 0.6161, G loss: 4.6783\n",
      "[4692/8000] D loss: 0.7029, G loss: 5.8201\n",
      "[5052/8000] D loss: 0.8509, G loss: 2.6016\n",
      "[5412/8000] D loss: 1.3878, G loss: 0.6319\n",
      "[5772/8000] D loss: 0.7565, G loss: 4.8230\n",
      "[6132/8000] D loss: 0.7795, G loss: 4.9294\n",
      "[6492/8000] D loss: 1.2414, G loss: 1.7733\n",
      "[6852/8000] D loss: 0.7819, G loss: 3.8210\n",
      "[7212/8000] D loss: 0.6347, G loss: 11.0850\n",
      "[7572/8000] D loss: 0.4895, G loss: 5.8646\n",
      "[7932/8000] D loss: 0.8745, G loss: 4.3363\n",
      "train error: \n",
      " D loss: 0.808305, G loss: 4.694760, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.944042, G loss: 12.306352, D accuracy: 80.1%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9094, G loss: 2.7649\n",
      "[372/8000] D loss: 0.6948, G loss: 6.4952\n",
      "[732/8000] D loss: 0.5671, G loss: 6.5059\n",
      "[1092/8000] D loss: 0.6643, G loss: 5.6422\n",
      "[1452/8000] D loss: 0.6050, G loss: 9.4130\n",
      "[1812/8000] D loss: 1.1431, G loss: 5.0330\n",
      "[2172/8000] D loss: 0.5781, G loss: 4.0424\n",
      "[2532/8000] D loss: 1.0645, G loss: 2.6130\n",
      "[2892/8000] D loss: 0.7354, G loss: 6.1929\n",
      "[3252/8000] D loss: 0.8244, G loss: 3.4730\n",
      "[3612/8000] D loss: 0.9142, G loss: 4.3344\n",
      "[3972/8000] D loss: 0.6610, G loss: 4.8211\n",
      "[4332/8000] D loss: 0.4267, G loss: 9.2914\n",
      "[4692/8000] D loss: 0.6421, G loss: 6.2542\n",
      "[5052/8000] D loss: 0.7509, G loss: 7.3298\n",
      "[5412/8000] D loss: 0.8359, G loss: 2.7753\n",
      "[5772/8000] D loss: 0.9666, G loss: 2.7146\n",
      "[6132/8000] D loss: 0.8129, G loss: 2.8932\n",
      "[6492/8000] D loss: 0.6722, G loss: 6.4747\n",
      "[6852/8000] D loss: 0.5252, G loss: 7.2685\n",
      "[7212/8000] D loss: 0.7253, G loss: 3.9730\n",
      "[7572/8000] D loss: 0.8400, G loss: 6.7228\n",
      "[7932/8000] D loss: 0.5317, G loss: 6.2540\n",
      "train error: \n",
      " D loss: 0.829464, G loss: 5.085717, D accuracy: 74.5%, cell accuracy: 98.6%, board accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.992948, G loss: 13.534899, D accuracy: 79.4%, cell accuracy: 98.1%, board accuracy: 24.0% \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8458, G loss: 5.4012\n",
      "[372/8000] D loss: 0.8305, G loss: 2.2173\n",
      "[732/8000] D loss: 0.6616, G loss: 6.0326\n",
      "[1092/8000] D loss: 1.2579, G loss: 4.2378\n",
      "[1452/8000] D loss: 0.8721, G loss: 5.6068\n",
      "[1812/8000] D loss: 0.7263, G loss: 1.9165\n",
      "[2172/8000] D loss: 0.8385, G loss: 3.2929\n",
      "[2532/8000] D loss: 1.0636, G loss: 3.1799\n",
      "[2892/8000] D loss: 0.3690, G loss: 12.1585\n",
      "[3252/8000] D loss: 0.5301, G loss: 4.7709\n",
      "[3612/8000] D loss: 0.8432, G loss: 3.8596\n",
      "[3972/8000] D loss: 1.0496, G loss: 1.6773\n",
      "[4332/8000] D loss: 0.7924, G loss: 6.6971\n",
      "[4692/8000] D loss: 0.9700, G loss: 2.4009\n",
      "[5052/8000] D loss: 1.0684, G loss: 2.0007\n",
      "[5412/8000] D loss: 1.0965, G loss: 2.7710\n",
      "[5772/8000] D loss: 0.7571, G loss: 4.0503\n",
      "[6132/8000] D loss: 0.6001, G loss: 5.4239\n",
      "[6492/8000] D loss: 0.5577, G loss: 4.8644\n",
      "[6852/8000] D loss: 0.6359, G loss: 5.2021\n",
      "[7212/8000] D loss: 0.7345, G loss: 4.9887\n",
      "[7572/8000] D loss: 0.8054, G loss: 5.5692\n",
      "[7932/8000] D loss: 0.9587, G loss: 2.4922\n",
      "train error: \n",
      " D loss: 0.833068, G loss: 6.021237, D accuracy: 74.0%, cell accuracy: 98.6%, board accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.015323, G loss: 15.118891, D accuracy: 77.0%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6776, G loss: 5.1529\n",
      "[372/8000] D loss: 0.8268, G loss: 6.2056\n",
      "[732/8000] D loss: 0.8070, G loss: 6.0004\n",
      "[1092/8000] D loss: 0.7633, G loss: 4.8566\n",
      "[1452/8000] D loss: 0.6844, G loss: 5.4795\n",
      "[1812/8000] D loss: 0.7235, G loss: 3.9044\n",
      "[2172/8000] D loss: 0.6431, G loss: 9.2015\n",
      "[2532/8000] D loss: 0.5822, G loss: 5.3307\n",
      "[2892/8000] D loss: 1.2717, G loss: 2.2297\n",
      "[3252/8000] D loss: 0.7082, G loss: 6.3446\n",
      "[3612/8000] D loss: 0.8241, G loss: 2.0658\n",
      "[3972/8000] D loss: 0.9076, G loss: 4.5155\n",
      "[4332/8000] D loss: 0.9899, G loss: 3.8388\n",
      "[4692/8000] D loss: 0.8877, G loss: 3.3538\n",
      "[5052/8000] D loss: 0.9643, G loss: 2.5167\n",
      "[5412/8000] D loss: 0.9353, G loss: 3.0999\n",
      "[5772/8000] D loss: 0.6497, G loss: 8.1218\n",
      "[6132/8000] D loss: 0.5746, G loss: 7.0595\n",
      "[6492/8000] D loss: 0.8247, G loss: 5.8117\n",
      "[6852/8000] D loss: 0.4061, G loss: 9.6060\n",
      "[7212/8000] D loss: 0.8377, G loss: 1.8547\n",
      "[7572/8000] D loss: 1.0729, G loss: 6.9847\n",
      "[7932/8000] D loss: 0.7878, G loss: 6.7311\n",
      "train error: \n",
      " D loss: 0.816135, G loss: 4.653322, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.923104, G loss: 12.626467, D accuracy: 79.8%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9729, G loss: 3.6425\n",
      "[372/8000] D loss: 0.7267, G loss: 4.6221\n",
      "[732/8000] D loss: 0.9250, G loss: 4.1400\n",
      "[1092/8000] D loss: 0.8958, G loss: 2.7650\n",
      "[1452/8000] D loss: 0.6937, G loss: 7.1498\n",
      "[1812/8000] D loss: 0.8555, G loss: 4.4105\n",
      "[2172/8000] D loss: 1.0005, G loss: 3.6686\n",
      "[2532/8000] D loss: 0.7501, G loss: 5.5023\n",
      "[2892/8000] D loss: 0.7660, G loss: 6.6728\n",
      "[3252/8000] D loss: 0.8308, G loss: 7.4658\n",
      "[3612/8000] D loss: 1.0426, G loss: 5.9675\n",
      "[3972/8000] D loss: 0.9723, G loss: 6.6495\n",
      "[4332/8000] D loss: 0.8831, G loss: 3.1708\n",
      "[4692/8000] D loss: 0.9166, G loss: 2.8558\n",
      "[5052/8000] D loss: 0.4046, G loss: 5.5738\n",
      "[5412/8000] D loss: 0.8192, G loss: 2.7050\n",
      "[5772/8000] D loss: 0.8643, G loss: 4.3953\n",
      "[6132/8000] D loss: 0.5331, G loss: 10.0196\n",
      "[6492/8000] D loss: 1.0131, G loss: 2.5030\n",
      "[6852/8000] D loss: 0.7838, G loss: 7.3993\n",
      "[7212/8000] D loss: 0.8497, G loss: 5.3078\n",
      "[7572/8000] D loss: 1.0218, G loss: 7.5972\n",
      "[7932/8000] D loss: 0.5356, G loss: 4.6196\n",
      "train error: \n",
      " D loss: 0.805922, G loss: 4.721872, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.818547, G loss: 13.121527, D accuracy: 81.9%, cell accuracy: 98.2%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7123, G loss: 7.1689\n",
      "[372/8000] D loss: 0.7338, G loss: 6.2299\n",
      "[732/8000] D loss: 0.6028, G loss: 6.1340\n",
      "[1092/8000] D loss: 0.9817, G loss: 4.0670\n",
      "[1452/8000] D loss: 0.6106, G loss: 7.5729\n",
      "[1812/8000] D loss: 0.8549, G loss: 4.4087\n",
      "[2172/8000] D loss: 1.0989, G loss: 4.8986\n",
      "[2532/8000] D loss: 0.7614, G loss: 4.1606\n",
      "[2892/8000] D loss: 1.0717, G loss: 2.0200\n",
      "[3252/8000] D loss: 1.0301, G loss: 2.8076\n",
      "[3612/8000] D loss: 1.0508, G loss: 2.6528\n",
      "[3972/8000] D loss: 0.5677, G loss: 7.0807\n",
      "[4332/8000] D loss: 0.6077, G loss: 8.3086\n",
      "[4692/8000] D loss: 0.5477, G loss: 8.1685\n",
      "[5052/8000] D loss: 1.2882, G loss: 1.4529\n",
      "[5412/8000] D loss: 0.6067, G loss: 4.7921\n",
      "[5772/8000] D loss: 0.9175, G loss: 7.9953\n",
      "[6132/8000] D loss: 0.6153, G loss: 8.1431\n",
      "[6492/8000] D loss: 0.6132, G loss: 7.3983\n",
      "[6852/8000] D loss: 0.7423, G loss: 4.2814\n",
      "[7212/8000] D loss: 0.5696, G loss: 8.3936\n",
      "[7572/8000] D loss: 1.0965, G loss: 3.1402\n",
      "[7932/8000] D loss: 0.9838, G loss: 5.0920\n",
      "train error: \n",
      " D loss: 0.812620, G loss: 5.035395, D accuracy: 74.3%, cell accuracy: 98.6%, board accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.922696, G loss: 13.087978, D accuracy: 78.9%, cell accuracy: 98.1%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1197, G loss: 4.5244\n",
      "[372/8000] D loss: 0.7219, G loss: 3.9593\n",
      "[732/8000] D loss: 0.7196, G loss: 6.6473\n",
      "[1092/8000] D loss: 0.7286, G loss: 3.0161\n",
      "[1452/8000] D loss: 0.3584, G loss: 7.4994\n",
      "[1812/8000] D loss: 0.8759, G loss: 7.7470\n",
      "[2172/8000] D loss: 1.0132, G loss: 1.9713\n",
      "[2532/8000] D loss: 1.0159, G loss: 3.0719\n",
      "[2892/8000] D loss: 0.7103, G loss: 9.1374\n",
      "[3252/8000] D loss: 0.7356, G loss: 4.9451\n",
      "[3612/8000] D loss: 0.7168, G loss: 7.2043\n",
      "[3972/8000] D loss: 0.8773, G loss: 4.1882\n",
      "[4332/8000] D loss: 0.7465, G loss: 4.0267\n",
      "[4692/8000] D loss: 0.7959, G loss: 8.1991\n",
      "[5052/8000] D loss: 0.9510, G loss: 2.9442\n",
      "[5412/8000] D loss: 0.8201, G loss: 3.7865\n",
      "[5772/8000] D loss: 0.6694, G loss: 6.9058\n",
      "[6132/8000] D loss: 0.5565, G loss: 5.8735\n",
      "[6492/8000] D loss: 0.6905, G loss: 5.9241\n",
      "[6852/8000] D loss: 0.7154, G loss: 5.7306\n",
      "[7212/8000] D loss: 0.7235, G loss: 3.1301\n",
      "[7572/8000] D loss: 1.0144, G loss: 5.8938\n",
      "[7932/8000] D loss: 0.6196, G loss: 6.0745\n",
      "train error: \n",
      " D loss: 0.816130, G loss: 5.684097, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.971128, G loss: 14.412600, D accuracy: 80.5%, cell accuracy: 98.1%, board accuracy: 22.9% \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8084, G loss: 3.6951\n",
      "[372/8000] D loss: 0.7966, G loss: 5.5237\n",
      "[732/8000] D loss: 0.7839, G loss: 7.0272\n",
      "[1092/8000] D loss: 0.9263, G loss: 5.5093\n",
      "[1452/8000] D loss: 1.2264, G loss: 2.7811\n",
      "[1812/8000] D loss: 1.1006, G loss: 2.4083\n",
      "[2172/8000] D loss: 0.8531, G loss: 6.6450\n",
      "[2532/8000] D loss: 0.8455, G loss: 3.8114\n",
      "[2892/8000] D loss: 1.0788, G loss: 4.3006\n",
      "[3252/8000] D loss: 0.8180, G loss: 2.4361\n",
      "[3612/8000] D loss: 0.6689, G loss: 5.5043\n",
      "[3972/8000] D loss: 0.3951, G loss: 6.5061\n",
      "[4332/8000] D loss: 0.7593, G loss: 4.9585\n",
      "[4692/8000] D loss: 0.9372, G loss: 4.2317\n",
      "[5052/8000] D loss: 0.8658, G loss: 3.3120\n",
      "[5412/8000] D loss: 0.7682, G loss: 4.1957\n",
      "[5772/8000] D loss: 0.7657, G loss: 3.7067\n",
      "[6132/8000] D loss: 0.8757, G loss: 5.0141\n",
      "[6492/8000] D loss: 1.0163, G loss: 3.1686\n",
      "[6852/8000] D loss: 1.1372, G loss: 1.8256\n",
      "[7212/8000] D loss: 0.8088, G loss: 4.9885\n",
      "[7572/8000] D loss: 0.7514, G loss: 4.7331\n",
      "[7932/8000] D loss: 0.7341, G loss: 5.3056\n",
      "train error: \n",
      " D loss: 0.803937, G loss: 4.640283, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.911520, G loss: 12.551527, D accuracy: 79.3%, cell accuracy: 98.2%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6319, G loss: 4.7034\n",
      "[372/8000] D loss: 0.5424, G loss: 4.4482\n",
      "[732/8000] D loss: 0.7115, G loss: 4.2968\n",
      "[1092/8000] D loss: 0.5721, G loss: 4.6125\n",
      "[1452/8000] D loss: 0.7515, G loss: 7.0352\n",
      "[1812/8000] D loss: 0.9745, G loss: 4.0588\n",
      "[2172/8000] D loss: 0.4930, G loss: 10.1395\n",
      "[2532/8000] D loss: 0.8808, G loss: 3.8182\n",
      "[2892/8000] D loss: 0.6713, G loss: 4.5175\n",
      "[3252/8000] D loss: 0.8145, G loss: 3.8432\n",
      "[3612/8000] D loss: 0.3997, G loss: 10.4774\n",
      "[3972/8000] D loss: 0.3659, G loss: 5.1073\n",
      "[4332/8000] D loss: 0.7875, G loss: 3.9138\n",
      "[4692/8000] D loss: 0.8169, G loss: 3.0676\n",
      "[5052/8000] D loss: 0.5639, G loss: 6.4855\n",
      "[5412/8000] D loss: 0.7853, G loss: 2.8410\n",
      "[5772/8000] D loss: 0.4258, G loss: 9.6000\n",
      "[6132/8000] D loss: 0.8111, G loss: 5.6382\n",
      "[6492/8000] D loss: 0.5845, G loss: 4.8786\n",
      "[6852/8000] D loss: 1.1239, G loss: 1.3423\n",
      "[7212/8000] D loss: 1.1700, G loss: 1.7797\n",
      "[7572/8000] D loss: 0.7322, G loss: 5.0986\n",
      "[7932/8000] D loss: 0.7267, G loss: 4.0165\n",
      "train error: \n",
      " D loss: 0.813544, G loss: 5.135619, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.815601, G loss: 13.779129, D accuracy: 83.9%, cell accuracy: 98.1%, board accuracy: 23.4% \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8600, G loss: 3.3379\n",
      "[372/8000] D loss: 0.9750, G loss: 5.3321\n",
      "[732/8000] D loss: 0.5356, G loss: 7.4412\n",
      "[1092/8000] D loss: 0.5046, G loss: 9.4228\n",
      "[1452/8000] D loss: 0.7009, G loss: 10.4965\n",
      "[1812/8000] D loss: 0.6622, G loss: 4.1553\n",
      "[2172/8000] D loss: 0.7172, G loss: 6.2320\n",
      "[2532/8000] D loss: 0.5096, G loss: 6.4050\n",
      "[2892/8000] D loss: 0.8199, G loss: 4.1333\n",
      "[3252/8000] D loss: 0.3948, G loss: 13.3961\n",
      "[3612/8000] D loss: 0.9204, G loss: 3.5201\n",
      "[3972/8000] D loss: 1.2099, G loss: 4.2079\n",
      "[4332/8000] D loss: 1.0594, G loss: 2.1181\n",
      "[4692/8000] D loss: 0.9500, G loss: 2.6296\n",
      "[5052/8000] D loss: 0.9454, G loss: 5.8204\n",
      "[5412/8000] D loss: 0.4656, G loss: 5.7988\n",
      "[5772/8000] D loss: 0.7927, G loss: 7.7305\n",
      "[6132/8000] D loss: 0.7608, G loss: 4.0952\n",
      "[6492/8000] D loss: 0.7018, G loss: 3.9124\n",
      "[6852/8000] D loss: 0.6019, G loss: 7.9745\n",
      "[7212/8000] D loss: 0.5531, G loss: 5.8053\n",
      "[7572/8000] D loss: 0.6337, G loss: 5.1364\n",
      "[7932/8000] D loss: 0.6503, G loss: 5.1156\n",
      "train error: \n",
      " D loss: 0.810255, G loss: 4.851873, D accuracy: 74.5%, cell accuracy: 98.6%, board accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.830157, G loss: 13.202052, D accuracy: 81.7%, cell accuracy: 98.2%, board accuracy: 23.6% \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4197, G loss: 6.5294\n",
      "[372/8000] D loss: 0.8266, G loss: 6.0648\n",
      "[732/8000] D loss: 1.1033, G loss: 1.7241\n",
      "[1092/8000] D loss: 0.8016, G loss: 8.7104\n",
      "[1452/8000] D loss: 0.7025, G loss: 3.2485\n",
      "[1812/8000] D loss: 1.0513, G loss: 4.3421\n",
      "[2172/8000] D loss: 0.9285, G loss: 6.6962\n",
      "[2532/8000] D loss: 0.8611, G loss: 4.1135\n",
      "[2892/8000] D loss: 1.0089, G loss: 2.3314\n",
      "[3252/8000] D loss: 0.8929, G loss: 2.9829\n",
      "[3612/8000] D loss: 1.0612, G loss: 4.3598\n",
      "[3972/8000] D loss: 0.5216, G loss: 6.3052\n",
      "[4332/8000] D loss: 0.7012, G loss: 2.9691\n",
      "[4692/8000] D loss: 1.0216, G loss: 5.1815\n",
      "[5052/8000] D loss: 0.8153, G loss: 2.8423\n",
      "[5412/8000] D loss: 1.0531, G loss: 3.4082\n",
      "[5772/8000] D loss: 0.5699, G loss: 6.5639\n",
      "[6132/8000] D loss: 0.6177, G loss: 9.6397\n",
      "[6492/8000] D loss: 0.9791, G loss: 3.4047\n",
      "[6852/8000] D loss: 0.8523, G loss: 1.9993\n",
      "[7212/8000] D loss: 1.0411, G loss: 2.5759\n",
      "[7572/8000] D loss: 0.9238, G loss: 2.8587\n",
      "[7932/8000] D loss: 0.6768, G loss: 9.2827\n",
      "train error: \n",
      " D loss: 0.825494, G loss: 4.809518, D accuracy: 74.1%, cell accuracy: 98.6%, board accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.948474, G loss: 12.691743, D accuracy: 81.2%, cell accuracy: 98.1%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6166, G loss: 5.9111\n",
      "[372/8000] D loss: 0.5558, G loss: 6.2099\n",
      "[732/8000] D loss: 0.6064, G loss: 4.3130\n",
      "[1092/8000] D loss: 0.7067, G loss: 5.7512\n",
      "[1452/8000] D loss: 0.7485, G loss: 8.5565\n",
      "[1812/8000] D loss: 0.8906, G loss: 3.4019\n",
      "[2172/8000] D loss: 1.0549, G loss: 2.4354\n",
      "[2532/8000] D loss: 0.6119, G loss: 8.5968\n",
      "[2892/8000] D loss: 0.9691, G loss: 4.8797\n",
      "[3252/8000] D loss: 0.9234, G loss: 2.1257\n",
      "[3612/8000] D loss: 0.7062, G loss: 3.6446\n",
      "[3972/8000] D loss: 0.7965, G loss: 8.0213\n",
      "[4332/8000] D loss: 0.8558, G loss: 4.7515\n",
      "[4692/8000] D loss: 0.7336, G loss: 5.0692\n",
      "[5052/8000] D loss: 0.9619, G loss: 2.9274\n",
      "[5412/8000] D loss: 0.9732, G loss: 2.5225\n",
      "[5772/8000] D loss: 0.4334, G loss: 7.1048\n",
      "[6132/8000] D loss: 0.8228, G loss: 4.5231\n",
      "[6492/8000] D loss: 0.7092, G loss: 6.2779\n",
      "[6852/8000] D loss: 0.8301, G loss: 3.3356\n",
      "[7212/8000] D loss: 0.4510, G loss: 11.5629\n",
      "[7572/8000] D loss: 0.6444, G loss: 6.6655\n",
      "[7932/8000] D loss: 0.9597, G loss: 4.6112\n",
      "train error: \n",
      " D loss: 0.809014, G loss: 4.482878, D accuracy: 74.9%, cell accuracy: 98.6%, board accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.837645, G loss: 12.301340, D accuracy: 81.7%, cell accuracy: 98.2%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7526, G loss: 3.2717\n",
      "[372/8000] D loss: 0.6269, G loss: 5.1204\n",
      "[732/8000] D loss: 0.7255, G loss: 7.1129\n",
      "[1092/8000] D loss: 0.5923, G loss: 8.1541\n",
      "[1452/8000] D loss: 0.7933, G loss: 8.6587\n",
      "[1812/8000] D loss: 0.8542, G loss: 5.5109\n",
      "[2172/8000] D loss: 0.9027, G loss: 3.9455\n",
      "[2532/8000] D loss: 0.6821, G loss: 7.5804\n",
      "[2892/8000] D loss: 0.5558, G loss: 4.7473\n",
      "[3252/8000] D loss: 0.4893, G loss: 4.7981\n",
      "[3612/8000] D loss: 0.5652, G loss: 4.6556\n",
      "[3972/8000] D loss: 1.0714, G loss: 1.6186\n",
      "[4332/8000] D loss: 0.7837, G loss: 3.7990\n",
      "[4692/8000] D loss: 0.7273, G loss: 5.4030\n",
      "[5052/8000] D loss: 0.5655, G loss: 5.1829\n",
      "[5412/8000] D loss: 0.8525, G loss: 3.7359\n",
      "[5772/8000] D loss: 0.5812, G loss: 6.6885\n",
      "[6132/8000] D loss: 1.0089, G loss: 3.4054\n",
      "[6492/8000] D loss: 0.6100, G loss: 5.0352\n",
      "[6852/8000] D loss: 0.6718, G loss: 7.1339\n",
      "[7212/8000] D loss: 0.6725, G loss: 4.5861\n",
      "[7572/8000] D loss: 0.6347, G loss: 6.3319\n",
      "[7932/8000] D loss: 0.8287, G loss: 3.8802\n",
      "train error: \n",
      " D loss: 0.795888, G loss: 5.122932, D accuracy: 75.4%, cell accuracy: 98.6%, board accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.918364, G loss: 13.391338, D accuracy: 81.4%, cell accuracy: 98.1%, board accuracy: 22.4% \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9291, G loss: 8.6858\n",
      "[372/8000] D loss: 0.6885, G loss: 4.2524\n",
      "[732/8000] D loss: 1.0317, G loss: 5.1279\n",
      "[1092/8000] D loss: 0.7060, G loss: 5.3594\n",
      "[1452/8000] D loss: 0.7324, G loss: 2.5174\n",
      "[1812/8000] D loss: 0.8070, G loss: 2.6239\n",
      "[2172/8000] D loss: 0.5750, G loss: 4.1337\n",
      "[2532/8000] D loss: 0.8232, G loss: 9.0831\n",
      "[2892/8000] D loss: 0.5621, G loss: 3.5138\n",
      "[3252/8000] D loss: 0.7252, G loss: 6.9661\n",
      "[3612/8000] D loss: 0.4732, G loss: 8.1489\n",
      "[3972/8000] D loss: 1.1308, G loss: 1.3916\n",
      "[4332/8000] D loss: 0.6266, G loss: 5.7304\n",
      "[4692/8000] D loss: 0.5880, G loss: 4.8861\n",
      "[5052/8000] D loss: 0.8900, G loss: 5.2502\n",
      "[5412/8000] D loss: 0.8439, G loss: 3.8557\n",
      "[5772/8000] D loss: 0.7924, G loss: 2.8673\n",
      "[6132/8000] D loss: 0.6011, G loss: 6.5431\n",
      "[6492/8000] D loss: 0.6221, G loss: 8.4903\n",
      "[6852/8000] D loss: 0.6226, G loss: 4.4274\n",
      "[7212/8000] D loss: 0.4717, G loss: 5.9456\n",
      "[7572/8000] D loss: 0.6495, G loss: 10.2151\n",
      "[7932/8000] D loss: 0.4081, G loss: 3.1114\n",
      "train error: \n",
      " D loss: 0.810984, G loss: 5.231948, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.982987, G loss: 13.640143, D accuracy: 77.4%, cell accuracy: 98.1%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9098, G loss: 8.0737\n",
      "[372/8000] D loss: 0.7654, G loss: 3.8957\n",
      "[732/8000] D loss: 1.0147, G loss: 2.3623\n",
      "[1092/8000] D loss: 0.8781, G loss: 2.7154\n",
      "[1452/8000] D loss: 0.9747, G loss: 3.4899\n",
      "[1812/8000] D loss: 0.9607, G loss: 3.7817\n",
      "[2172/8000] D loss: 0.8094, G loss: 3.3503\n",
      "[2532/8000] D loss: 0.9903, G loss: 1.5521\n",
      "[2892/8000] D loss: 0.1999, G loss: 12.1084\n",
      "[3252/8000] D loss: 0.9668, G loss: 3.6420\n",
      "[3612/8000] D loss: 0.8980, G loss: 4.1635\n",
      "[3972/8000] D loss: 0.5013, G loss: 3.9246\n",
      "[4332/8000] D loss: 0.3854, G loss: 10.9371\n",
      "[4692/8000] D loss: 0.6783, G loss: 5.8766\n",
      "[5052/8000] D loss: 0.9618, G loss: 5.6821\n",
      "[5412/8000] D loss: 0.6547, G loss: 7.9974\n",
      "[5772/8000] D loss: 1.0580, G loss: 4.9684\n",
      "[6132/8000] D loss: 0.7331, G loss: 7.3663\n",
      "[6492/8000] D loss: 0.6513, G loss: 3.4978\n",
      "[6852/8000] D loss: 0.6894, G loss: 3.0626\n",
      "[7212/8000] D loss: 0.7846, G loss: 4.8440\n",
      "[7572/8000] D loss: 0.7243, G loss: 4.7023\n",
      "[7932/8000] D loss: 1.0510, G loss: 3.1248\n",
      "train error: \n",
      " D loss: 0.813071, G loss: 4.408486, D accuracy: 74.4%, cell accuracy: 98.6%, board accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.807647, G loss: 12.199067, D accuracy: 82.0%, cell accuracy: 98.2%, board accuracy: 24.5% \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8940, G loss: 3.2213\n",
      "[372/8000] D loss: 1.0934, G loss: 2.4047\n",
      "[732/8000] D loss: 1.0796, G loss: 4.2733\n",
      "[1092/8000] D loss: 1.0877, G loss: 2.2309\n",
      "[1452/8000] D loss: 0.7236, G loss: 3.8955\n",
      "[1812/8000] D loss: 0.9099, G loss: 5.3298\n",
      "[2172/8000] D loss: 0.5109, G loss: 8.4640\n",
      "[2532/8000] D loss: 0.8549, G loss: 4.6355\n",
      "[2892/8000] D loss: 0.5461, G loss: 4.6808\n",
      "[3252/8000] D loss: 0.8152, G loss: 4.9894\n",
      "[3612/8000] D loss: 0.9435, G loss: 6.1588\n",
      "[3972/8000] D loss: 0.5192, G loss: 3.4823\n",
      "[4332/8000] D loss: 0.5913, G loss: 5.6468\n",
      "[4692/8000] D loss: 0.7221, G loss: 4.4568\n",
      "[5052/8000] D loss: 0.8529, G loss: 3.8058\n",
      "[5412/8000] D loss: 0.8847, G loss: 5.6390\n",
      "[5772/8000] D loss: 0.7030, G loss: 5.8744\n",
      "[6132/8000] D loss: 0.7977, G loss: 4.5684\n",
      "[6492/8000] D loss: 0.6207, G loss: 4.7866\n",
      "[6852/8000] D loss: 0.8994, G loss: 5.9535\n",
      "[7212/8000] D loss: 1.1136, G loss: 2.9354\n",
      "[7572/8000] D loss: 0.6931, G loss: 5.9124\n",
      "[7932/8000] D loss: 1.0986, G loss: 1.8378\n",
      "train error: \n",
      " D loss: 0.789330, G loss: 4.727392, D accuracy: 75.6%, cell accuracy: 98.6%, board accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.855998, G loss: 12.859468, D accuracy: 81.5%, cell accuracy: 98.1%, board accuracy: 22.4% \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6304, G loss: 5.9230\n",
      "[372/8000] D loss: 0.6578, G loss: 5.3387\n",
      "[732/8000] D loss: 0.5858, G loss: 3.4768\n",
      "[1092/8000] D loss: 0.4396, G loss: 5.0837\n",
      "[1452/8000] D loss: 0.6571, G loss: 4.5894\n",
      "[1812/8000] D loss: 0.9389, G loss: 5.1993\n",
      "[2172/8000] D loss: 0.6410, G loss: 7.1244\n",
      "[2532/8000] D loss: 0.7144, G loss: 6.2862\n",
      "[2892/8000] D loss: 0.9823, G loss: 3.7432\n",
      "[3252/8000] D loss: 0.6397, G loss: 9.4267\n",
      "[3612/8000] D loss: 0.9559, G loss: 3.6851\n",
      "[3972/8000] D loss: 1.0145, G loss: 3.7450\n",
      "[4332/8000] D loss: 1.0449, G loss: 2.0711\n",
      "[4692/8000] D loss: 0.9479, G loss: 2.2676\n",
      "[5052/8000] D loss: 0.7703, G loss: 6.0586\n",
      "[5412/8000] D loss: 1.1093, G loss: 1.4771\n",
      "[5772/8000] D loss: 0.8818, G loss: 5.0748\n",
      "[6132/8000] D loss: 0.7361, G loss: 8.8566\n",
      "[6492/8000] D loss: 0.6710, G loss: 5.4643\n",
      "[6852/8000] D loss: 0.8637, G loss: 3.9573\n",
      "[7212/8000] D loss: 0.7465, G loss: 5.7892\n",
      "[7572/8000] D loss: 0.9404, G loss: 4.3351\n",
      "[7932/8000] D loss: 0.7620, G loss: 4.9896\n",
      "train error: \n",
      " D loss: 0.801724, G loss: 4.873912, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.959546, G loss: 13.069508, D accuracy: 80.6%, cell accuracy: 98.1%, board accuracy: 23.4% \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0583, G loss: 2.4433\n",
      "[372/8000] D loss: 0.3876, G loss: 10.0272\n",
      "[732/8000] D loss: 0.6094, G loss: 9.6005\n",
      "[1092/8000] D loss: 0.2393, G loss: 14.9519\n",
      "[1452/8000] D loss: 0.8061, G loss: 5.0772\n",
      "[1812/8000] D loss: 0.6133, G loss: 7.2087\n",
      "[2172/8000] D loss: 0.5786, G loss: 5.5223\n",
      "[2532/8000] D loss: 0.9206, G loss: 4.8309\n",
      "[2892/8000] D loss: 0.6906, G loss: 6.7933\n",
      "[3252/8000] D loss: 0.6391, G loss: 5.6882\n",
      "[3612/8000] D loss: 0.5579, G loss: 6.2440\n",
      "[3972/8000] D loss: 0.7561, G loss: 3.4042\n",
      "[4332/8000] D loss: 0.6992, G loss: 7.7985\n",
      "[4692/8000] D loss: 0.8050, G loss: 5.4543\n",
      "[5052/8000] D loss: 1.0303, G loss: 4.3538\n",
      "[5412/8000] D loss: 0.6514, G loss: 3.4968\n",
      "[5772/8000] D loss: 0.5645, G loss: 5.2906\n",
      "[6132/8000] D loss: 0.9732, G loss: 3.9651\n",
      "[6492/8000] D loss: 0.8536, G loss: 3.5462\n",
      "[6852/8000] D loss: 0.6241, G loss: 6.2427\n",
      "[7212/8000] D loss: 1.1935, G loss: 0.7909\n",
      "[7572/8000] D loss: 0.5385, G loss: 5.9089\n",
      "[7932/8000] D loss: 0.6630, G loss: 4.0436\n",
      "train error: \n",
      " D loss: 0.798331, G loss: 5.496331, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.027601, G loss: 13.956635, D accuracy: 78.1%, cell accuracy: 98.1%, board accuracy: 23.4% \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0399, G loss: 2.2337\n",
      "[372/8000] D loss: 1.1381, G loss: 2.4140\n",
      "[732/8000] D loss: 0.5668, G loss: 8.5447\n",
      "[1092/8000] D loss: 1.0722, G loss: 2.4820\n",
      "[1452/8000] D loss: 0.9165, G loss: 4.7773\n",
      "[1812/8000] D loss: 1.0609, G loss: 1.6921\n",
      "[2172/8000] D loss: 0.9806, G loss: 3.1105\n",
      "[2532/8000] D loss: 1.0514, G loss: 1.6152\n",
      "[2892/8000] D loss: 0.9348, G loss: 4.3222\n",
      "[3252/8000] D loss: 0.8223, G loss: 8.1576\n",
      "[3612/8000] D loss: 0.7535, G loss: 7.7010\n",
      "[3972/8000] D loss: 0.9121, G loss: 3.7293\n",
      "[4332/8000] D loss: 0.9289, G loss: 5.5655\n",
      "[4692/8000] D loss: 0.8456, G loss: 2.7059\n",
      "[5052/8000] D loss: 1.0520, G loss: 4.6738\n",
      "[5412/8000] D loss: 0.9550, G loss: 2.7239\n",
      "[5772/8000] D loss: 0.8544, G loss: 4.9810\n",
      "[6132/8000] D loss: 0.6544, G loss: 4.4174\n",
      "[6492/8000] D loss: 0.8840, G loss: 4.1124\n",
      "[6852/8000] D loss: 0.9794, G loss: 3.2080\n",
      "[7212/8000] D loss: 0.6506, G loss: 4.5794\n",
      "[7572/8000] D loss: 0.9130, G loss: 5.2209\n",
      "[7932/8000] D loss: 0.5645, G loss: 5.5996\n",
      "train error: \n",
      " D loss: 0.814572, G loss: 5.377537, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.940035, G loss: 14.036831, D accuracy: 77.7%, cell accuracy: 98.1%, board accuracy: 24.2% \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6971, G loss: 5.7831\n",
      "[372/8000] D loss: 0.5055, G loss: 7.0021\n",
      "[732/8000] D loss: 0.7840, G loss: 4.3797\n",
      "[1092/8000] D loss: 0.8441, G loss: 3.1103\n",
      "[1452/8000] D loss: 0.9119, G loss: 2.6161\n",
      "[1812/8000] D loss: 1.0362, G loss: 2.2156\n",
      "[2172/8000] D loss: 0.2089, G loss: 8.7558\n",
      "[2532/8000] D loss: 0.7891, G loss: 5.4648\n",
      "[2892/8000] D loss: 0.9862, G loss: 3.6887\n",
      "[3252/8000] D loss: 0.8976, G loss: 3.9288\n",
      "[3612/8000] D loss: 0.8712, G loss: 5.2144\n",
      "[3972/8000] D loss: 0.7301, G loss: 5.7578\n",
      "[4332/8000] D loss: 0.6482, G loss: 6.3098\n",
      "[4692/8000] D loss: 0.5219, G loss: 9.5730\n",
      "[5052/8000] D loss: 0.5141, G loss: 7.2455\n",
      "[5412/8000] D loss: 0.5561, G loss: 5.3268\n",
      "[5772/8000] D loss: 0.9619, G loss: 6.9733\n",
      "[6132/8000] D loss: 0.5200, G loss: 3.3877\n",
      "[6492/8000] D loss: 1.1230, G loss: 2.0185\n",
      "[6852/8000] D loss: 1.2076, G loss: 1.2065\n",
      "[7212/8000] D loss: 0.8779, G loss: 2.0117\n",
      "[7572/8000] D loss: 0.8045, G loss: 3.1039\n",
      "[7932/8000] D loss: 0.4355, G loss: 4.3536\n",
      "train error: \n",
      " D loss: 0.806531, G loss: 5.394788, D accuracy: 74.3%, cell accuracy: 98.6%, board accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.966228, G loss: 13.675114, D accuracy: 78.1%, cell accuracy: 98.1%, board accuracy: 24.2% \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7492, G loss: 6.1316\n",
      "[372/8000] D loss: 0.5729, G loss: 3.9224\n",
      "[732/8000] D loss: 1.0458, G loss: 3.0446\n",
      "[1092/8000] D loss: 0.7338, G loss: 3.4411\n",
      "[1452/8000] D loss: 1.0174, G loss: 2.4473\n",
      "[1812/8000] D loss: 0.7872, G loss: 4.0453\n",
      "[2172/8000] D loss: 0.4980, G loss: 11.6401\n",
      "[2532/8000] D loss: 0.9626, G loss: 3.4648\n",
      "[2892/8000] D loss: 0.7081, G loss: 6.4149\n",
      "[3252/8000] D loss: 0.9506, G loss: 3.1892\n",
      "[3612/8000] D loss: 0.9970, G loss: 2.1236\n",
      "[3972/8000] D loss: 0.8550, G loss: 5.3159\n",
      "[4332/8000] D loss: 0.7440, G loss: 3.1703\n",
      "[4692/8000] D loss: 0.7317, G loss: 5.2845\n",
      "[5052/8000] D loss: 1.0920, G loss: 1.8226\n",
      "[5412/8000] D loss: 0.7926, G loss: 7.5652\n",
      "[5772/8000] D loss: 0.7509, G loss: 5.0876\n",
      "[6132/8000] D loss: 0.8989, G loss: 3.4653\n",
      "[6492/8000] D loss: 0.5513, G loss: 6.5758\n",
      "[6852/8000] D loss: 0.9161, G loss: 4.9186\n",
      "[7212/8000] D loss: 0.8040, G loss: 3.9022\n",
      "[7572/8000] D loss: 0.6315, G loss: 6.0199\n",
      "[7932/8000] D loss: 0.7759, G loss: 5.8428\n",
      "train error: \n",
      " D loss: 0.797256, G loss: 4.506538, D accuracy: 75.1%, cell accuracy: 98.6%, board accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.864042, G loss: 12.517669, D accuracy: 81.3%, cell accuracy: 98.2%, board accuracy: 24.8% \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8369, G loss: 5.3587\n",
      "[372/8000] D loss: 0.8478, G loss: 7.0244\n",
      "[732/8000] D loss: 0.9720, G loss: 7.3460\n",
      "[1092/8000] D loss: 0.4939, G loss: 6.5493\n",
      "[1452/8000] D loss: 0.8937, G loss: 4.3123\n",
      "[1812/8000] D loss: 1.0266, G loss: 2.1449\n",
      "[2172/8000] D loss: 1.0406, G loss: 2.4860\n",
      "[2532/8000] D loss: 0.7814, G loss: 6.7066\n",
      "[2892/8000] D loss: 0.7207, G loss: 3.4817\n",
      "[3252/8000] D loss: 0.9277, G loss: 4.1808\n",
      "[3612/8000] D loss: 0.8562, G loss: 2.9904\n",
      "[3972/8000] D loss: 0.5808, G loss: 9.9213\n",
      "[4332/8000] D loss: 0.7661, G loss: 6.4027\n",
      "[4692/8000] D loss: 0.6145, G loss: 5.6611\n",
      "[5052/8000] D loss: 0.5445, G loss: 9.4181\n",
      "[5412/8000] D loss: 0.8517, G loss: 6.5343\n",
      "[5772/8000] D loss: 0.8124, G loss: 5.6339\n",
      "[6132/8000] D loss: 0.7874, G loss: 6.9972\n",
      "[6492/8000] D loss: 1.1479, G loss: 1.3558\n",
      "[6852/8000] D loss: 1.0418, G loss: 3.3596\n",
      "[7212/8000] D loss: 1.1860, G loss: 2.6255\n",
      "[7572/8000] D loss: 0.7750, G loss: 4.6791\n",
      "[7932/8000] D loss: 0.9829, G loss: 5.0384\n",
      "train error: \n",
      " D loss: 0.872226, G loss: 3.483093, D accuracy: 73.2%, cell accuracy: 98.6%, board accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.766878, G loss: 10.507783, D accuracy: 83.8%, cell accuracy: 98.1%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8078, G loss: 2.4044\n",
      "[372/8000] D loss: 0.9264, G loss: 3.2443\n",
      "[732/8000] D loss: 1.0343, G loss: 4.1014\n",
      "[1092/8000] D loss: 0.9258, G loss: 2.9946\n",
      "[1452/8000] D loss: 0.8368, G loss: 4.8140\n",
      "[1812/8000] D loss: 0.9064, G loss: 2.9783\n",
      "[2172/8000] D loss: 0.6584, G loss: 5.3568\n",
      "[2532/8000] D loss: 0.6090, G loss: 6.9667\n",
      "[2892/8000] D loss: 0.4656, G loss: 8.1563\n",
      "[3252/8000] D loss: 0.8834, G loss: 6.8005\n",
      "[3612/8000] D loss: 0.7659, G loss: 4.4105\n",
      "[3972/8000] D loss: 0.6686, G loss: 6.1007\n",
      "[4332/8000] D loss: 0.6270, G loss: 10.4514\n",
      "[4692/8000] D loss: 1.0600, G loss: 3.2982\n",
      "[5052/8000] D loss: 0.9071, G loss: 4.2957\n",
      "[5412/8000] D loss: 0.7103, G loss: 3.4028\n",
      "[5772/8000] D loss: 0.6327, G loss: 11.1120\n",
      "[6132/8000] D loss: 0.8731, G loss: 4.4385\n",
      "[6492/8000] D loss: 0.8046, G loss: 2.6559\n",
      "[6852/8000] D loss: 0.5470, G loss: 9.3699\n",
      "[7212/8000] D loss: 0.8643, G loss: 4.2474\n",
      "[7572/8000] D loss: 0.7683, G loss: 5.7916\n",
      "[7932/8000] D loss: 0.8977, G loss: 1.8128\n",
      "train error: \n",
      " D loss: 0.818157, G loss: 4.179355, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.851066, G loss: 12.023548, D accuracy: 80.3%, cell accuracy: 98.2%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7557, G loss: 3.2121\n",
      "[372/8000] D loss: 0.5782, G loss: 7.5068\n",
      "[732/8000] D loss: 0.8942, G loss: 5.7750\n",
      "[1092/8000] D loss: 1.1738, G loss: 1.6029\n",
      "[1452/8000] D loss: 0.8373, G loss: 3.7222\n",
      "[1812/8000] D loss: 0.7955, G loss: 6.5368\n",
      "[2172/8000] D loss: 0.8348, G loss: 3.9421\n",
      "[2532/8000] D loss: 1.0213, G loss: 2.1106\n",
      "[2892/8000] D loss: 1.0256, G loss: 1.6710\n",
      "[3252/8000] D loss: 0.6152, G loss: 9.9975\n",
      "[3612/8000] D loss: 0.5805, G loss: 4.7184\n",
      "[3972/8000] D loss: 0.8272, G loss: 4.3488\n",
      "[4332/8000] D loss: 0.4604, G loss: 8.1030\n",
      "[4692/8000] D loss: 0.6811, G loss: 8.3223\n",
      "[5052/8000] D loss: 1.0670, G loss: 6.6183\n",
      "[5412/8000] D loss: 0.8666, G loss: 4.2614\n",
      "[5772/8000] D loss: 0.8552, G loss: 8.0474\n",
      "[6132/8000] D loss: 0.6329, G loss: 6.8026\n",
      "[6492/8000] D loss: 0.6822, G loss: 6.0146\n",
      "[6852/8000] D loss: 1.0047, G loss: 3.1997\n",
      "[7212/8000] D loss: 0.3004, G loss: 5.8101\n",
      "[7572/8000] D loss: 0.5344, G loss: 8.9973\n",
      "[7932/8000] D loss: 0.7211, G loss: 7.5557\n",
      "train error: \n",
      " D loss: 0.823550, G loss: 5.306622, D accuracy: 73.6%, cell accuracy: 98.6%, board accuracy: 51.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.056258, G loss: 13.680282, D accuracy: 75.9%, cell accuracy: 98.1%, board accuracy: 25.7% \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8528, G loss: 6.4244\n",
      "[372/8000] D loss: 0.8486, G loss: 3.8682\n",
      "[732/8000] D loss: 0.8040, G loss: 6.3687\n",
      "[1092/8000] D loss: 1.0530, G loss: 1.4648\n",
      "[1452/8000] D loss: 1.0600, G loss: 3.5919\n",
      "[1812/8000] D loss: 0.8896, G loss: 2.5243\n",
      "[2172/8000] D loss: 0.7889, G loss: 2.9236\n",
      "[2532/8000] D loss: 0.7853, G loss: 3.9122\n",
      "[2892/8000] D loss: 0.6604, G loss: 6.8588\n",
      "[3252/8000] D loss: 0.7038, G loss: 5.5050\n",
      "[3612/8000] D loss: 0.6827, G loss: 6.2589\n",
      "[3972/8000] D loss: 1.0671, G loss: 4.0116\n",
      "[4332/8000] D loss: 1.1445, G loss: 1.6952\n",
      "[4692/8000] D loss: 0.8643, G loss: 4.4964\n",
      "[5052/8000] D loss: 0.8603, G loss: 5.6609\n",
      "[5412/8000] D loss: 0.7697, G loss: 6.2195\n",
      "[5772/8000] D loss: 0.6074, G loss: 5.6133\n",
      "[6132/8000] D loss: 0.8195, G loss: 8.4047\n",
      "[6492/8000] D loss: 0.5491, G loss: 6.7160\n",
      "[6852/8000] D loss: 0.9349, G loss: 3.9793\n",
      "[7212/8000] D loss: 0.7851, G loss: 3.3930\n",
      "[7572/8000] D loss: 0.9413, G loss: 2.1423\n",
      "[7932/8000] D loss: 0.7837, G loss: 4.4533\n",
      "train error: \n",
      " D loss: 0.801703, G loss: 5.060847, D accuracy: 74.5%, cell accuracy: 98.6%, board accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.970335, G loss: 12.747355, D accuracy: 78.4%, cell accuracy: 98.1%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8102, G loss: 5.2339\n",
      "[372/8000] D loss: 0.6385, G loss: 8.5214\n",
      "[732/8000] D loss: 0.6932, G loss: 7.1296\n",
      "[1092/8000] D loss: 0.8123, G loss: 6.4709\n",
      "[1452/8000] D loss: 0.5660, G loss: 7.4220\n",
      "[1812/8000] D loss: 0.5582, G loss: 4.0677\n",
      "[2172/8000] D loss: 0.8623, G loss: 4.8582\n",
      "[2532/8000] D loss: 0.8297, G loss: 7.8099\n",
      "[2892/8000] D loss: 0.7621, G loss: 3.6424\n",
      "[3252/8000] D loss: 0.9763, G loss: 2.9059\n",
      "[3612/8000] D loss: 0.7187, G loss: 7.8220\n",
      "[3972/8000] D loss: 0.6960, G loss: 8.2282\n",
      "[4332/8000] D loss: 0.7108, G loss: 3.6829\n",
      "[4692/8000] D loss: 0.7738, G loss: 2.0948\n",
      "[5052/8000] D loss: 0.9883, G loss: 8.0541\n",
      "[5412/8000] D loss: 1.0338, G loss: 4.8738\n",
      "[5772/8000] D loss: 0.9606, G loss: 2.8382\n",
      "[6132/8000] D loss: 0.9090, G loss: 8.0069\n",
      "[6492/8000] D loss: 0.6469, G loss: 4.4718\n",
      "[6852/8000] D loss: 0.5419, G loss: 6.4971\n",
      "[7212/8000] D loss: 0.9634, G loss: 1.9880\n",
      "[7572/8000] D loss: 0.6336, G loss: 8.9883\n",
      "[7932/8000] D loss: 0.8694, G loss: 5.6759\n",
      "train error: \n",
      " D loss: 0.822658, G loss: 4.568296, D accuracy: 74.4%, cell accuracy: 98.6%, board accuracy: 51.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.949147, G loss: 12.070775, D accuracy: 80.4%, cell accuracy: 98.2%, board accuracy: 25.7% \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6416, G loss: 7.5259\n",
      "[372/8000] D loss: 0.9406, G loss: 4.6088\n",
      "[732/8000] D loss: 0.8046, G loss: 7.8276\n",
      "[1092/8000] D loss: 0.9285, G loss: 4.1348\n",
      "[1452/8000] D loss: 0.6509, G loss: 6.4539\n",
      "[1812/8000] D loss: 1.4050, G loss: 0.7580\n",
      "[2172/8000] D loss: 0.5590, G loss: 7.0862\n",
      "[2532/8000] D loss: 1.0710, G loss: 3.0059\n",
      "[2892/8000] D loss: 0.5330, G loss: 5.6538\n",
      "[3252/8000] D loss: 0.6315, G loss: 5.0286\n",
      "[3612/8000] D loss: 0.6939, G loss: 7.8548\n",
      "[3972/8000] D loss: 1.0985, G loss: 2.9915\n",
      "[4332/8000] D loss: 1.6703, G loss: 4.3409\n",
      "[4692/8000] D loss: 1.0989, G loss: 1.7545\n",
      "[5052/8000] D loss: 0.8136, G loss: 7.8244\n",
      "[5412/8000] D loss: 0.6146, G loss: 8.6346\n",
      "[5772/8000] D loss: 0.9679, G loss: 2.6536\n",
      "[6132/8000] D loss: 0.5931, G loss: 7.0966\n",
      "[6492/8000] D loss: 0.6233, G loss: 4.1776\n",
      "[6852/8000] D loss: 0.8626, G loss: 4.8006\n",
      "[7212/8000] D loss: 0.9604, G loss: 6.3918\n",
      "[7572/8000] D loss: 0.8239, G loss: 5.3513\n",
      "[7932/8000] D loss: 0.7822, G loss: 5.0615\n",
      "train error: \n",
      " D loss: 0.812675, G loss: 5.365791, D accuracy: 74.3%, cell accuracy: 98.6%, board accuracy: 51.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.007540, G loss: 14.316561, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 24.2% \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7017, G loss: 6.3146\n",
      "[372/8000] D loss: 0.7155, G loss: 8.4022\n",
      "[732/8000] D loss: 0.3781, G loss: 7.2272\n",
      "[1092/8000] D loss: 0.9562, G loss: 1.7281\n",
      "[1452/8000] D loss: 1.0397, G loss: 4.2856\n",
      "[1812/8000] D loss: 0.7355, G loss: 4.4716\n",
      "[2172/8000] D loss: 0.8146, G loss: 3.9759\n",
      "[2532/8000] D loss: 0.6010, G loss: 8.7394\n",
      "[2892/8000] D loss: 0.6623, G loss: 5.1890\n",
      "[3252/8000] D loss: 0.8026, G loss: 4.4779\n",
      "[3612/8000] D loss: 0.8401, G loss: 3.0384\n",
      "[3972/8000] D loss: 0.6977, G loss: 2.8698\n",
      "[4332/8000] D loss: 0.7327, G loss: 4.1287\n",
      "[4692/8000] D loss: 0.7729, G loss: 5.0909\n",
      "[5052/8000] D loss: 0.8157, G loss: 5.4317\n",
      "[5412/8000] D loss: 0.7766, G loss: 3.9780\n",
      "[5772/8000] D loss: 0.8087, G loss: 3.8244\n",
      "[6132/8000] D loss: 1.0126, G loss: 2.9216\n",
      "[6492/8000] D loss: 0.6328, G loss: 5.9830\n",
      "[6852/8000] D loss: 0.6512, G loss: 4.3414\n",
      "[7212/8000] D loss: 0.5421, G loss: 4.3345\n",
      "[7572/8000] D loss: 0.8838, G loss: 4.4351\n",
      "[7932/8000] D loss: 0.5896, G loss: 6.3879\n",
      "train error: \n",
      " D loss: 0.803696, G loss: 4.903391, D accuracy: 74.5%, cell accuracy: 98.6%, board accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.891258, G loss: 13.556003, D accuracy: 79.2%, cell accuracy: 98.1%, board accuracy: 24.2% \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8691, G loss: 5.5454\n",
      "[372/8000] D loss: 0.7047, G loss: 5.9882\n",
      "[732/8000] D loss: 0.7236, G loss: 5.0107\n",
      "[1092/8000] D loss: 0.5953, G loss: 5.9932\n",
      "[1452/8000] D loss: 0.6463, G loss: 7.5543\n",
      "[1812/8000] D loss: 0.8012, G loss: 5.1517\n",
      "[2172/8000] D loss: 0.6916, G loss: 4.0335\n",
      "[2532/8000] D loss: 0.8206, G loss: 4.5839\n",
      "[2892/8000] D loss: 0.8222, G loss: 2.8997\n",
      "[3252/8000] D loss: 0.5368, G loss: 5.5753\n",
      "[3612/8000] D loss: 0.7170, G loss: 6.9837\n",
      "[3972/8000] D loss: 0.7495, G loss: 7.7525\n",
      "[4332/8000] D loss: 0.2712, G loss: 15.3140\n",
      "[4692/8000] D loss: 0.7393, G loss: 6.4680\n",
      "[5052/8000] D loss: 0.9534, G loss: 2.9488\n",
      "[5412/8000] D loss: 0.8527, G loss: 7.3527\n",
      "[5772/8000] D loss: 1.0485, G loss: 2.4622\n",
      "[6132/8000] D loss: 1.1951, G loss: 2.7257\n",
      "[6492/8000] D loss: 0.9650, G loss: 2.8815\n",
      "[6852/8000] D loss: 0.9544, G loss: 8.3566\n",
      "[7212/8000] D loss: 0.9062, G loss: 4.3656\n",
      "[7572/8000] D loss: 1.1816, G loss: 2.1412\n",
      "[7932/8000] D loss: 0.7209, G loss: 6.1670\n",
      "train error: \n",
      " D loss: 0.819758, G loss: 6.042812, D accuracy: 74.5%, cell accuracy: 98.6%, board accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.943614, G loss: 15.319036, D accuracy: 79.9%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9184, G loss: 7.6729\n",
      "[372/8000] D loss: 1.0285, G loss: 3.1604\n",
      "[732/8000] D loss: 0.4783, G loss: 6.3458\n",
      "[1092/8000] D loss: 0.6810, G loss: 4.4134\n",
      "[1452/8000] D loss: 0.7039, G loss: 4.5133\n",
      "[1812/8000] D loss: 0.8995, G loss: 5.9545\n",
      "[2172/8000] D loss: 0.8805, G loss: 6.5996\n",
      "[2532/8000] D loss: 0.8376, G loss: 4.4068\n",
      "[2892/8000] D loss: 0.8081, G loss: 2.8660\n",
      "[3252/8000] D loss: 1.0386, G loss: 2.8105\n",
      "[3612/8000] D loss: 0.9525, G loss: 10.6432\n",
      "[3972/8000] D loss: 0.8289, G loss: 2.6022\n",
      "[4332/8000] D loss: 0.9116, G loss: 5.3185\n",
      "[4692/8000] D loss: 0.9401, G loss: 5.3161\n",
      "[5052/8000] D loss: 0.9112, G loss: 5.2896\n",
      "[5412/8000] D loss: 1.0195, G loss: 4.7582\n",
      "[5772/8000] D loss: 0.9290, G loss: 4.9848\n",
      "[6132/8000] D loss: 0.7925, G loss: 10.5063\n",
      "[6492/8000] D loss: 0.9156, G loss: 2.8756\n",
      "[6852/8000] D loss: 0.5037, G loss: 7.3936\n",
      "[7212/8000] D loss: 0.5583, G loss: 5.1111\n",
      "[7572/8000] D loss: 0.5355, G loss: 6.4188\n",
      "[7932/8000] D loss: 1.4045, G loss: 1.8059\n",
      "train error: \n",
      " D loss: 0.806756, G loss: 5.485224, D accuracy: 74.6%, cell accuracy: 98.6%, board accuracy: 51.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.980541, G loss: 14.407666, D accuracy: 78.8%, cell accuracy: 98.1%, board accuracy: 24.3% \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8233, G loss: 7.7601\n",
      "[372/8000] D loss: 0.5839, G loss: 7.6096\n",
      "[732/8000] D loss: 0.6946, G loss: 7.0090\n",
      "[1092/8000] D loss: 1.0840, G loss: 4.5176\n",
      "[1452/8000] D loss: 0.8275, G loss: 4.4795\n",
      "[1812/8000] D loss: 0.9412, G loss: 3.3262\n",
      "[2172/8000] D loss: 0.6902, G loss: 8.3465\n",
      "[2532/8000] D loss: 0.8559, G loss: 2.0236\n",
      "[2892/8000] D loss: 1.1234, G loss: 4.0005\n",
      "[3252/8000] D loss: 0.8959, G loss: 4.1802\n",
      "[3612/8000] D loss: 0.6753, G loss: 7.3141\n",
      "[3972/8000] D loss: 0.7189, G loss: 3.8634\n",
      "[4332/8000] D loss: 0.5474, G loss: 6.1329\n",
      "[4692/8000] D loss: 0.7811, G loss: 6.6080\n",
      "[5052/8000] D loss: 1.0131, G loss: 3.2715\n",
      "[5412/8000] D loss: 0.8037, G loss: 5.6767\n",
      "[5772/8000] D loss: 0.4435, G loss: 5.6539\n",
      "[6132/8000] D loss: 0.5656, G loss: 3.8849\n",
      "[6492/8000] D loss: 0.8965, G loss: 9.8898\n",
      "[6852/8000] D loss: 0.3726, G loss: 7.1421\n",
      "[7212/8000] D loss: 0.8889, G loss: 3.0498\n",
      "[7572/8000] D loss: 0.8383, G loss: 3.3310\n",
      "[7932/8000] D loss: 0.7231, G loss: 4.0927\n",
      "train error: \n",
      " D loss: 0.826627, G loss: 4.198342, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.840820, G loss: 12.554058, D accuracy: 82.2%, cell accuracy: 98.2%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5924, G loss: 4.6388\n",
      "[372/8000] D loss: 1.3086, G loss: 0.8959\n",
      "[732/8000] D loss: 1.0362, G loss: 4.7416\n",
      "[1092/8000] D loss: 0.9227, G loss: 3.7649\n",
      "[1452/8000] D loss: 0.9561, G loss: 2.1685\n",
      "[1812/8000] D loss: 0.8002, G loss: 4.5938\n",
      "[2172/8000] D loss: 0.6399, G loss: 4.5165\n",
      "[2532/8000] D loss: 0.8616, G loss: 5.1150\n",
      "[2892/8000] D loss: 0.5933, G loss: 5.1541\n",
      "[3252/8000] D loss: 0.9970, G loss: 4.0568\n",
      "[3612/8000] D loss: 0.7407, G loss: 7.7216\n",
      "[3972/8000] D loss: 0.4668, G loss: 7.0201\n",
      "[4332/8000] D loss: 1.2204, G loss: 0.9736\n",
      "[4692/8000] D loss: 0.8178, G loss: 2.7678\n",
      "[5052/8000] D loss: 0.7381, G loss: 4.9773\n",
      "[5412/8000] D loss: 0.9434, G loss: 4.4065\n",
      "[5772/8000] D loss: 0.9174, G loss: 3.1256\n",
      "[6132/8000] D loss: 1.0112, G loss: 3.4499\n",
      "[6492/8000] D loss: 0.7710, G loss: 4.1168\n",
      "[6852/8000] D loss: 1.0805, G loss: 3.8218\n",
      "[7212/8000] D loss: 0.9903, G loss: 6.7876\n",
      "[7572/8000] D loss: 0.8554, G loss: 4.8167\n",
      "[7932/8000] D loss: 0.6528, G loss: 6.3061\n",
      "train error: \n",
      " D loss: 0.820025, G loss: 6.001034, D accuracy: 74.0%, cell accuracy: 98.7%, board accuracy: 51.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.033430, G loss: 15.264951, D accuracy: 78.0%, cell accuracy: 98.2%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9372, G loss: 4.1433\n",
      "[372/8000] D loss: 0.6040, G loss: 5.9709\n",
      "[732/8000] D loss: 0.7826, G loss: 4.0235\n",
      "[1092/8000] D loss: 0.8457, G loss: 7.3128\n",
      "[1452/8000] D loss: 0.8260, G loss: 10.5646\n",
      "[1812/8000] D loss: 0.9838, G loss: 3.5917\n",
      "[2172/8000] D loss: 0.9523, G loss: 3.2146\n",
      "[2532/8000] D loss: 0.8292, G loss: 4.8748\n",
      "[2892/8000] D loss: 0.7625, G loss: 6.2585\n",
      "[3252/8000] D loss: 0.6495, G loss: 2.9378\n",
      "[3612/8000] D loss: 0.7470, G loss: 6.2274\n",
      "[3972/8000] D loss: 0.6071, G loss: 10.8758\n",
      "[4332/8000] D loss: 0.5891, G loss: 6.6144\n",
      "[4692/8000] D loss: 0.6251, G loss: 6.9819\n",
      "[5052/8000] D loss: 0.9595, G loss: 5.7018\n",
      "[5412/8000] D loss: 0.5010, G loss: 6.8395\n",
      "[5772/8000] D loss: 0.9715, G loss: 5.9649\n",
      "[6132/8000] D loss: 0.8700, G loss: 3.3862\n",
      "[6492/8000] D loss: 1.0409, G loss: 2.2487\n",
      "[6852/8000] D loss: 0.7625, G loss: 5.4810\n",
      "[7212/8000] D loss: 1.0181, G loss: 3.2421\n",
      "[7572/8000] D loss: 0.9020, G loss: 4.5232\n",
      "[7932/8000] D loss: 1.0259, G loss: 2.4745\n",
      "train error: \n",
      " D loss: 0.819133, G loss: 4.527199, D accuracy: 74.1%, cell accuracy: 98.7%, board accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.817898, G loss: 12.719988, D accuracy: 82.9%, cell accuracy: 98.2%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6604, G loss: 4.3833\n",
      "[372/8000] D loss: 1.0524, G loss: 3.9570\n",
      "[732/8000] D loss: 1.0542, G loss: 3.5988\n",
      "[1092/8000] D loss: 0.9200, G loss: 4.2591\n",
      "[1452/8000] D loss: 0.9158, G loss: 4.7898\n",
      "[1812/8000] D loss: 0.5995, G loss: 4.7568\n",
      "[2172/8000] D loss: 0.9466, G loss: 5.4458\n",
      "[2532/8000] D loss: 0.7353, G loss: 7.0611\n",
      "[2892/8000] D loss: 0.3148, G loss: 12.0679\n",
      "[3252/8000] D loss: 0.7570, G loss: 2.9299\n",
      "[3612/8000] D loss: 0.7936, G loss: 4.9258\n",
      "[3972/8000] D loss: 0.9147, G loss: 3.6091\n",
      "[4332/8000] D loss: 0.7186, G loss: 3.3441\n",
      "[4692/8000] D loss: 0.6825, G loss: 5.5690\n",
      "[5052/8000] D loss: 0.8140, G loss: 7.8879\n",
      "[5412/8000] D loss: 1.0074, G loss: 3.9702\n",
      "[5772/8000] D loss: 0.5745, G loss: 4.6975\n",
      "[6132/8000] D loss: 0.6676, G loss: 8.8534\n",
      "[6492/8000] D loss: 0.7200, G loss: 11.2595\n",
      "[6852/8000] D loss: 0.8652, G loss: 3.0299\n",
      "[7212/8000] D loss: 0.5191, G loss: 17.6502\n",
      "[7572/8000] D loss: 0.8142, G loss: 2.7413\n",
      "[7932/8000] D loss: 0.7403, G loss: 5.0535\n",
      "train error: \n",
      " D loss: 0.829477, G loss: 4.951594, D accuracy: 74.6%, cell accuracy: 98.6%, board accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.844390, G loss: 13.655584, D accuracy: 82.9%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9417, G loss: 4.5182\n",
      "[372/8000] D loss: 0.8863, G loss: 3.4557\n",
      "[732/8000] D loss: 0.7309, G loss: 3.3902\n",
      "[1092/8000] D loss: 0.8395, G loss: 4.0386\n",
      "[1452/8000] D loss: 1.0402, G loss: 1.5995\n",
      "[1812/8000] D loss: 1.0259, G loss: 3.5749\n",
      "[2172/8000] D loss: 1.2833, G loss: 2.5179\n",
      "[2532/8000] D loss: 0.7578, G loss: 5.9748\n",
      "[2892/8000] D loss: 1.1531, G loss: 5.2883\n",
      "[3252/8000] D loss: 0.8584, G loss: 9.0160\n",
      "[3612/8000] D loss: 0.5454, G loss: 5.3477\n",
      "[3972/8000] D loss: 0.9092, G loss: 2.9121\n",
      "[4332/8000] D loss: 0.3669, G loss: 10.2978\n",
      "[4692/8000] D loss: 0.8927, G loss: 2.6779\n",
      "[5052/8000] D loss: 0.6753, G loss: 6.5021\n",
      "[5412/8000] D loss: 0.6537, G loss: 2.9577\n",
      "[5772/8000] D loss: 0.7544, G loss: 2.4211\n",
      "[6132/8000] D loss: 0.7551, G loss: 4.2479\n",
      "[6492/8000] D loss: 0.5746, G loss: 5.6985\n",
      "[6852/8000] D loss: 0.7179, G loss: 4.0962\n",
      "[7212/8000] D loss: 0.8327, G loss: 4.7667\n",
      "[7572/8000] D loss: 0.7186, G loss: 4.2251\n",
      "[7932/8000] D loss: 0.8968, G loss: 4.6767\n",
      "train error: \n",
      " D loss: 0.809518, G loss: 4.948340, D accuracy: 74.9%, cell accuracy: 98.6%, board accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.821448, G loss: 13.438843, D accuracy: 82.4%, cell accuracy: 98.2%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9554, G loss: 3.8672\n",
      "[372/8000] D loss: 0.6480, G loss: 6.2734\n",
      "[732/8000] D loss: 0.6839, G loss: 6.6913\n",
      "[1092/8000] D loss: 0.9405, G loss: 4.0384\n",
      "[1452/8000] D loss: 0.9629, G loss: 7.3341\n",
      "[1812/8000] D loss: 1.0715, G loss: 2.8261\n",
      "[2172/8000] D loss: 0.7957, G loss: 6.0874\n",
      "[2532/8000] D loss: 0.9159, G loss: 3.6042\n",
      "[2892/8000] D loss: 0.8745, G loss: 4.9733\n",
      "[3252/8000] D loss: 0.8569, G loss: 3.2944\n",
      "[3612/8000] D loss: 0.8774, G loss: 2.9119\n",
      "[3972/8000] D loss: 0.5234, G loss: 5.0961\n",
      "[4332/8000] D loss: 0.5119, G loss: 5.7788\n",
      "[4692/8000] D loss: 0.8504, G loss: 4.2232\n",
      "[5052/8000] D loss: 0.9065, G loss: 2.9756\n",
      "[5412/8000] D loss: 0.8950, G loss: 4.0757\n",
      "[5772/8000] D loss: 0.6186, G loss: 7.1003\n",
      "[6132/8000] D loss: 0.8931, G loss: 2.5913\n",
      "[6492/8000] D loss: 0.5871, G loss: 2.9544\n",
      "[6852/8000] D loss: 0.7158, G loss: 7.4482\n",
      "[7212/8000] D loss: 0.7815, G loss: 4.2668\n",
      "[7572/8000] D loss: 0.8615, G loss: 6.3539\n",
      "[7932/8000] D loss: 0.7429, G loss: 2.3628\n",
      "train error: \n",
      " D loss: 0.832418, G loss: 4.679797, D accuracy: 73.6%, cell accuracy: 98.6%, board accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.976034, G loss: 13.186492, D accuracy: 75.7%, cell accuracy: 98.1%, board accuracy: 25.4% \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7795, G loss: 5.2297\n",
      "[372/8000] D loss: 0.7423, G loss: 6.7327\n",
      "[732/8000] D loss: 1.0524, G loss: 3.1206\n",
      "[1092/8000] D loss: 0.9087, G loss: 3.2621\n",
      "[1452/8000] D loss: 0.5435, G loss: 3.6605\n",
      "[1812/8000] D loss: 1.0043, G loss: 2.8444\n",
      "[2172/8000] D loss: 1.1255, G loss: 2.5404\n",
      "[2532/8000] D loss: 0.9946, G loss: 3.3382\n",
      "[2892/8000] D loss: 0.6527, G loss: 7.3196\n",
      "[3252/8000] D loss: 0.9646, G loss: 3.9006\n",
      "[3612/8000] D loss: 1.0658, G loss: 4.0567\n",
      "[3972/8000] D loss: 0.9785, G loss: 4.4005\n",
      "[4332/8000] D loss: 0.7785, G loss: 3.7094\n",
      "[4692/8000] D loss: 0.7430, G loss: 3.4519\n",
      "[5052/8000] D loss: 1.1894, G loss: 1.9903\n",
      "[5412/8000] D loss: 0.7130, G loss: 4.7300\n",
      "[5772/8000] D loss: 1.1714, G loss: 1.2477\n",
      "[6132/8000] D loss: 1.0697, G loss: 2.2995\n",
      "[6492/8000] D loss: 0.7373, G loss: 3.8968\n",
      "[6852/8000] D loss: 0.5236, G loss: 6.9143\n",
      "[7212/8000] D loss: 0.6684, G loss: 6.3533\n",
      "[7572/8000] D loss: 1.0746, G loss: 4.4238\n",
      "[7932/8000] D loss: 0.8641, G loss: 5.4195\n",
      "train error: \n",
      " D loss: 0.826785, G loss: 4.876533, D accuracy: 73.8%, cell accuracy: 98.7%, board accuracy: 52.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.876521, G loss: 13.289185, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 24.9% \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6246, G loss: 8.3197\n",
      "[372/8000] D loss: 0.7335, G loss: 6.6550\n",
      "[732/8000] D loss: 1.1632, G loss: 2.2539\n",
      "[1092/8000] D loss: 1.0963, G loss: 1.2922\n",
      "[1452/8000] D loss: 0.6602, G loss: 8.1911\n",
      "[1812/8000] D loss: 0.5323, G loss: 4.1536\n",
      "[2172/8000] D loss: 0.9999, G loss: 6.4811\n",
      "[2532/8000] D loss: 0.7309, G loss: 2.8935\n",
      "[2892/8000] D loss: 0.6308, G loss: 10.5810\n",
      "[3252/8000] D loss: 0.8084, G loss: 4.7458\n",
      "[3612/8000] D loss: 0.9264, G loss: 3.6034\n",
      "[3972/8000] D loss: 0.7264, G loss: 5.7272\n",
      "[4332/8000] D loss: 0.7169, G loss: 5.5433\n",
      "[4692/8000] D loss: 0.8105, G loss: 4.4484\n",
      "[5052/8000] D loss: 0.9041, G loss: 3.7386\n",
      "[5412/8000] D loss: 1.0824, G loss: 2.0706\n",
      "[5772/8000] D loss: 0.7068, G loss: 6.7464\n",
      "[6132/8000] D loss: 0.7159, G loss: 4.6518\n",
      "[6492/8000] D loss: 0.6021, G loss: 5.7066\n",
      "[6852/8000] D loss: 0.6927, G loss: 6.0920\n",
      "[7212/8000] D loss: 0.9922, G loss: 5.0643\n",
      "[7572/8000] D loss: 1.1520, G loss: 1.8624\n",
      "[7932/8000] D loss: 0.6771, G loss: 4.9245\n",
      "train error: \n",
      " D loss: 0.822031, G loss: 5.537032, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999798, G loss: 14.590888, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 24.5% \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4567, G loss: 15.0115\n",
      "[372/8000] D loss: 1.1811, G loss: 1.5335\n",
      "[732/8000] D loss: 0.9010, G loss: 3.1117\n",
      "[1092/8000] D loss: 0.6663, G loss: 3.3151\n",
      "[1452/8000] D loss: 0.7828, G loss: 5.5318\n",
      "[1812/8000] D loss: 0.7446, G loss: 8.8031\n",
      "[2172/8000] D loss: 0.8776, G loss: 4.7626\n",
      "[2532/8000] D loss: 0.6438, G loss: 7.6499\n",
      "[2892/8000] D loss: 0.8110, G loss: 6.7983\n",
      "[3252/8000] D loss: 0.9981, G loss: 3.0432\n",
      "[3612/8000] D loss: 0.8380, G loss: 2.7795\n",
      "[3972/8000] D loss: 0.6376, G loss: 5.8611\n",
      "[4332/8000] D loss: 0.6337, G loss: 4.6621\n",
      "[4692/8000] D loss: 0.8607, G loss: 8.2312\n",
      "[5052/8000] D loss: 0.6963, G loss: 7.0384\n",
      "[5412/8000] D loss: 0.8037, G loss: 6.4814\n",
      "[5772/8000] D loss: 0.7111, G loss: 5.4561\n",
      "[6132/8000] D loss: 0.4916, G loss: 7.2843\n",
      "[6492/8000] D loss: 0.7534, G loss: 4.2219\n",
      "[6852/8000] D loss: 0.8043, G loss: 5.4198\n",
      "[7212/8000] D loss: 0.5473, G loss: 9.6632\n",
      "[7572/8000] D loss: 0.8545, G loss: 2.6641\n",
      "[7932/8000] D loss: 0.6440, G loss: 2.8132\n",
      "train error: \n",
      " D loss: 0.813535, G loss: 4.594467, D accuracy: 74.0%, cell accuracy: 98.6%, board accuracy: 51.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.884274, G loss: 12.718353, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 24.8% \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8114, G loss: 3.9732\n",
      "[372/8000] D loss: 0.6394, G loss: 8.4675\n",
      "[732/8000] D loss: 0.8374, G loss: 4.8844\n",
      "[1092/8000] D loss: 0.4956, G loss: 7.0628\n",
      "[1452/8000] D loss: 0.9031, G loss: 4.1368\n",
      "[1812/8000] D loss: 0.6411, G loss: 5.8625\n",
      "[2172/8000] D loss: 0.6117, G loss: 6.7736\n",
      "[2532/8000] D loss: 1.0140, G loss: 3.2736\n",
      "[2892/8000] D loss: 0.6695, G loss: 5.6619\n",
      "[3252/8000] D loss: 0.6806, G loss: 6.2888\n",
      "[3612/8000] D loss: 0.8097, G loss: 2.2874\n",
      "[3972/8000] D loss: 0.6982, G loss: 7.1857\n",
      "[4332/8000] D loss: 0.7481, G loss: 3.1919\n",
      "[4692/8000] D loss: 0.5600, G loss: 8.7913\n",
      "[5052/8000] D loss: 0.9502, G loss: 3.2981\n",
      "[5412/8000] D loss: 0.1749, G loss: 9.9217\n",
      "[5772/8000] D loss: 0.7218, G loss: 3.2439\n",
      "[6132/8000] D loss: 1.3300, G loss: 3.2524\n",
      "[6492/8000] D loss: 0.8748, G loss: 4.8208\n",
      "[6852/8000] D loss: 0.9560, G loss: 6.7244\n",
      "[7212/8000] D loss: 0.9288, G loss: 2.3629\n",
      "[7572/8000] D loss: 0.6985, G loss: 4.6252\n",
      "[7932/8000] D loss: 0.8008, G loss: 2.2216\n",
      "train error: \n",
      " D loss: 0.804875, G loss: 4.972864, D accuracy: 74.9%, cell accuracy: 98.6%, board accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.848953, G loss: 13.562473, D accuracy: 80.9%, cell accuracy: 98.2%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0528, G loss: 3.9739\n",
      "[372/8000] D loss: 0.7068, G loss: 5.4277\n",
      "[732/8000] D loss: 0.8825, G loss: 2.2876\n",
      "[1092/8000] D loss: 0.4932, G loss: 6.6580\n",
      "[1452/8000] D loss: 0.8359, G loss: 6.4300\n",
      "[1812/8000] D loss: 0.9599, G loss: 2.7609\n",
      "[2172/8000] D loss: 0.9775, G loss: 3.0922\n",
      "[2532/8000] D loss: 1.1063, G loss: 4.4440\n",
      "[2892/8000] D loss: 0.6920, G loss: 9.1731\n",
      "[3252/8000] D loss: 0.8937, G loss: 5.2218\n",
      "[3612/8000] D loss: 0.4983, G loss: 7.1448\n",
      "[3972/8000] D loss: 0.9919, G loss: 5.2106\n",
      "[4332/8000] D loss: 1.0359, G loss: 2.8698\n",
      "[4692/8000] D loss: 0.6583, G loss: 4.5250\n",
      "[5052/8000] D loss: 0.7097, G loss: 6.0762\n",
      "[5412/8000] D loss: 0.4622, G loss: 13.4448\n",
      "[5772/8000] D loss: 0.6467, G loss: 9.0758\n",
      "[6132/8000] D loss: 1.0748, G loss: 3.6954\n",
      "[6492/8000] D loss: 0.7670, G loss: 4.2272\n",
      "[6852/8000] D loss: 0.9708, G loss: 4.1349\n",
      "[7212/8000] D loss: 1.1422, G loss: 2.6080\n",
      "[7572/8000] D loss: 0.7188, G loss: 12.6433\n",
      "[7932/8000] D loss: 0.6665, G loss: 4.7128\n",
      "train error: \n",
      " D loss: 0.831715, G loss: 4.507895, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.888863, G loss: 12.848773, D accuracy: 82.0%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7119, G loss: 3.0253\n",
      "[372/8000] D loss: 0.8364, G loss: 6.8625\n",
      "[732/8000] D loss: 1.1650, G loss: 1.5747\n",
      "[1092/8000] D loss: 0.8933, G loss: 3.4162\n",
      "[1452/8000] D loss: 0.6861, G loss: 4.0080\n",
      "[1812/8000] D loss: 0.7860, G loss: 8.6762\n",
      "[2172/8000] D loss: 0.9433, G loss: 4.6552\n",
      "[2532/8000] D loss: 0.7126, G loss: 12.9370\n",
      "[2892/8000] D loss: 0.7200, G loss: 6.2063\n",
      "[3252/8000] D loss: 0.7525, G loss: 7.0314\n",
      "[3612/8000] D loss: 0.7553, G loss: 7.1872\n",
      "[3972/8000] D loss: 0.8485, G loss: 6.0302\n",
      "[4332/8000] D loss: 0.6033, G loss: 7.4036\n",
      "[4692/8000] D loss: 0.9355, G loss: 5.3908\n",
      "[5052/8000] D loss: 0.7649, G loss: 5.7726\n",
      "[5412/8000] D loss: 0.6128, G loss: 7.0357\n",
      "[5772/8000] D loss: 1.0281, G loss: 1.9025\n",
      "[6132/8000] D loss: 0.8476, G loss: 4.4414\n",
      "[6492/8000] D loss: 0.5945, G loss: 8.7638\n",
      "[6852/8000] D loss: 0.5349, G loss: 5.9960\n",
      "[7212/8000] D loss: 0.7252, G loss: 7.6023\n",
      "[7572/8000] D loss: 0.8000, G loss: 5.0244\n",
      "[7932/8000] D loss: 0.6096, G loss: 6.1826\n",
      "train error: \n",
      " D loss: 0.811644, G loss: 4.993306, D accuracy: 74.1%, cell accuracy: 98.6%, board accuracy: 51.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.974234, G loss: 13.194152, D accuracy: 78.5%, cell accuracy: 98.1%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9038, G loss: 6.6309\n",
      "[372/8000] D loss: 0.7911, G loss: 5.4068\n",
      "[732/8000] D loss: 0.7947, G loss: 4.1107\n",
      "[1092/8000] D loss: 0.6745, G loss: 4.8618\n",
      "[1452/8000] D loss: 0.3757, G loss: 7.2811\n",
      "[1812/8000] D loss: 1.0981, G loss: 1.8589\n",
      "[2172/8000] D loss: 0.8984, G loss: 6.2157\n",
      "[2532/8000] D loss: 0.9553, G loss: 2.5155\n",
      "[2892/8000] D loss: 0.3999, G loss: 4.4327\n",
      "[3252/8000] D loss: 0.9122, G loss: 3.6758\n",
      "[3612/8000] D loss: 1.0581, G loss: 1.8340\n",
      "[3972/8000] D loss: 0.8907, G loss: 5.4855\n",
      "[4332/8000] D loss: 0.7067, G loss: 6.2688\n",
      "[4692/8000] D loss: 0.5831, G loss: 7.0971\n",
      "[5052/8000] D loss: 0.9293, G loss: 7.0116\n",
      "[5412/8000] D loss: 0.8313, G loss: 7.4884\n",
      "[5772/8000] D loss: 0.7478, G loss: 4.6153\n",
      "[6132/8000] D loss: 0.5486, G loss: 8.9952\n",
      "[6492/8000] D loss: 1.0688, G loss: 3.3744\n",
      "[6852/8000] D loss: 0.7464, G loss: 3.9067\n",
      "[7212/8000] D loss: 1.0175, G loss: 4.7582\n",
      "[7572/8000] D loss: 1.3036, G loss: 1.3477\n",
      "[7932/8000] D loss: 0.5522, G loss: 6.0712\n",
      "train error: \n",
      " D loss: 0.838679, G loss: 5.261522, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 52.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.966194, G loss: 13.397136, D accuracy: 77.0%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7110, G loss: 9.9703\n",
      "[372/8000] D loss: 0.7836, G loss: 2.3660\n",
      "[732/8000] D loss: 0.7530, G loss: 4.9262\n",
      "[1092/8000] D loss: 0.9536, G loss: 4.9487\n",
      "[1452/8000] D loss: 0.8014, G loss: 7.5574\n",
      "[1812/8000] D loss: 0.8687, G loss: 4.7141\n",
      "[2172/8000] D loss: 0.7396, G loss: 7.0426\n",
      "[2532/8000] D loss: 0.6523, G loss: 4.6414\n",
      "[2892/8000] D loss: 0.7669, G loss: 4.9329\n",
      "[3252/8000] D loss: 0.7886, G loss: 4.1821\n",
      "[3612/8000] D loss: 0.8916, G loss: 6.2237\n",
      "[3972/8000] D loss: 1.2835, G loss: 1.4072\n",
      "[4332/8000] D loss: 0.9215, G loss: 2.5025\n",
      "[4692/8000] D loss: 0.8688, G loss: 5.2930\n",
      "[5052/8000] D loss: 0.7221, G loss: 6.0249\n",
      "[5412/8000] D loss: 0.9144, G loss: 6.4143\n",
      "[5772/8000] D loss: 1.1644, G loss: 3.4092\n",
      "[6132/8000] D loss: 0.8848, G loss: 2.0221\n",
      "[6492/8000] D loss: 1.0243, G loss: 3.1085\n",
      "[6852/8000] D loss: 0.9031, G loss: 2.4372\n",
      "[7212/8000] D loss: 0.6758, G loss: 5.1678\n",
      "[7572/8000] D loss: 0.4165, G loss: 8.3706\n",
      "[7932/8000] D loss: 0.9668, G loss: 3.1968\n",
      "train error: \n",
      " D loss: 0.810546, G loss: 5.162228, D accuracy: 73.9%, cell accuracy: 98.7%, board accuracy: 52.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.904215, G loss: 13.839685, D accuracy: 78.1%, cell accuracy: 98.2%, board accuracy: 25.7% \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1555, G loss: 2.0299\n",
      "[372/8000] D loss: 0.5737, G loss: 9.0997\n",
      "[732/8000] D loss: 0.7324, G loss: 3.8127\n",
      "[1092/8000] D loss: 0.6993, G loss: 5.6457\n",
      "[1452/8000] D loss: 0.5810, G loss: 4.2042\n",
      "[1812/8000] D loss: 0.5858, G loss: 9.2620\n",
      "[2172/8000] D loss: 0.9900, G loss: 6.5750\n",
      "[2532/8000] D loss: 0.5076, G loss: 6.3176\n",
      "[2892/8000] D loss: 1.0971, G loss: 4.7871\n",
      "[3252/8000] D loss: 0.5748, G loss: 6.6652\n",
      "[3612/8000] D loss: 0.8478, G loss: 2.6945\n",
      "[3972/8000] D loss: 1.0971, G loss: 3.0055\n",
      "[4332/8000] D loss: 0.9266, G loss: 2.1903\n",
      "[4692/8000] D loss: 1.0767, G loss: 1.3143\n",
      "[5052/8000] D loss: 0.6782, G loss: 6.4766\n",
      "[5412/8000] D loss: 1.0569, G loss: 3.9234\n",
      "[5772/8000] D loss: 0.7765, G loss: 3.2013\n",
      "[6132/8000] D loss: 0.3978, G loss: 5.7314\n",
      "[6492/8000] D loss: 1.0728, G loss: 4.0953\n",
      "[6852/8000] D loss: 0.3290, G loss: 8.8054\n",
      "[7212/8000] D loss: 0.8583, G loss: 5.1016\n",
      "[7572/8000] D loss: 0.6827, G loss: 5.2807\n",
      "[7932/8000] D loss: 1.1403, G loss: 2.0574\n",
      "train error: \n",
      " D loss: 0.842942, G loss: 3.671504, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 52.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.834108, G loss: 10.704894, D accuracy: 81.1%, cell accuracy: 98.2%, board accuracy: 26.1% \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7842, G loss: 3.4192\n",
      "[372/8000] D loss: 0.9055, G loss: 2.2055\n",
      "[732/8000] D loss: 0.9671, G loss: 8.5642\n",
      "[1092/8000] D loss: 1.0861, G loss: 1.4415\n",
      "[1452/8000] D loss: 0.8576, G loss: 4.6112\n",
      "[1812/8000] D loss: 0.9351, G loss: 4.4581\n",
      "[2172/8000] D loss: 0.6073, G loss: 9.7199\n",
      "[2532/8000] D loss: 0.7498, G loss: 6.0261\n",
      "[2892/8000] D loss: 0.7955, G loss: 4.0106\n",
      "[3252/8000] D loss: 0.4583, G loss: 6.9772\n",
      "[3612/8000] D loss: 1.0083, G loss: 3.2416\n",
      "[3972/8000] D loss: 0.7796, G loss: 5.0764\n",
      "[4332/8000] D loss: 0.9596, G loss: 1.8509\n",
      "[4692/8000] D loss: 1.0642, G loss: 3.5593\n",
      "[5052/8000] D loss: 0.7414, G loss: 6.3453\n",
      "[5412/8000] D loss: 0.6531, G loss: 6.3415\n",
      "[5772/8000] D loss: 0.5392, G loss: 10.4262\n",
      "[6132/8000] D loss: 0.4259, G loss: 9.9163\n",
      "[6492/8000] D loss: 0.9147, G loss: 4.3580\n",
      "[6852/8000] D loss: 0.5098, G loss: 8.7709\n",
      "[7212/8000] D loss: 0.8362, G loss: 2.5043\n",
      "[7572/8000] D loss: 0.9872, G loss: 6.9436\n",
      "[7932/8000] D loss: 0.6527, G loss: 6.1906\n",
      "train error: \n",
      " D loss: 0.810728, G loss: 4.627258, D accuracy: 73.9%, cell accuracy: 98.7%, board accuracy: 51.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.876383, G loss: 12.820273, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5849, G loss: 10.3993\n",
      "[372/8000] D loss: 0.9064, G loss: 3.8246\n",
      "[732/8000] D loss: 0.7859, G loss: 7.4570\n",
      "[1092/8000] D loss: 0.5249, G loss: 5.6255\n",
      "[1452/8000] D loss: 0.8408, G loss: 3.5583\n",
      "[1812/8000] D loss: 0.8502, G loss: 5.8766\n",
      "[2172/8000] D loss: 0.8773, G loss: 5.3377\n",
      "[2532/8000] D loss: 0.9304, G loss: 2.2065\n",
      "[2892/8000] D loss: 0.8329, G loss: 4.2672\n",
      "[3252/8000] D loss: 0.6973, G loss: 5.8274\n",
      "[3612/8000] D loss: 0.8135, G loss: 7.0441\n",
      "[3972/8000] D loss: 0.9032, G loss: 5.1751\n",
      "[4332/8000] D loss: 0.6835, G loss: 3.2352\n",
      "[4692/8000] D loss: 0.7141, G loss: 4.9857\n",
      "[5052/8000] D loss: 0.7441, G loss: 4.6641\n",
      "[5412/8000] D loss: 0.7450, G loss: 5.4274\n",
      "[5772/8000] D loss: 0.7130, G loss: 4.5179\n",
      "[6132/8000] D loss: 0.7581, G loss: 5.9625\n",
      "[6492/8000] D loss: 1.0064, G loss: 3.2294\n",
      "[6852/8000] D loss: 0.8486, G loss: 2.3687\n",
      "[7212/8000] D loss: 0.6615, G loss: 9.6797\n",
      "[7572/8000] D loss: 0.7284, G loss: 5.3038\n",
      "[7932/8000] D loss: 0.8245, G loss: 5.3786\n",
      "train error: \n",
      " D loss: 0.818011, G loss: 4.678691, D accuracy: 74.6%, cell accuracy: 98.6%, board accuracy: 51.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.867776, G loss: 13.057482, D accuracy: 82.3%, cell accuracy: 98.1%, board accuracy: 25.4% \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9990, G loss: 6.0249\n",
      "[372/8000] D loss: 0.5985, G loss: 5.2385\n",
      "[732/8000] D loss: 0.4004, G loss: 5.2784\n",
      "[1092/8000] D loss: 0.6458, G loss: 6.3705\n",
      "[1452/8000] D loss: 0.7081, G loss: 4.7531\n",
      "[1812/8000] D loss: 1.0577, G loss: 4.6665\n",
      "[2172/8000] D loss: 0.4970, G loss: 6.1035\n",
      "[2532/8000] D loss: 0.5674, G loss: 13.6206\n",
      "[2892/8000] D loss: 0.6834, G loss: 6.1549\n",
      "[3252/8000] D loss: 0.8940, G loss: 5.3247\n",
      "[3612/8000] D loss: 0.6479, G loss: 7.2311\n",
      "[3972/8000] D loss: 0.6865, G loss: 10.0686\n",
      "[4332/8000] D loss: 0.6400, G loss: 4.6333\n",
      "[4692/8000] D loss: 0.7921, G loss: 4.2889\n",
      "[5052/8000] D loss: 0.8773, G loss: 5.3567\n",
      "[5412/8000] D loss: 0.6148, G loss: 7.5384\n",
      "[5772/8000] D loss: 0.6478, G loss: 5.8884\n",
      "[6132/8000] D loss: 0.5304, G loss: 8.0161\n",
      "[6492/8000] D loss: 0.3927, G loss: 8.1477\n",
      "[6852/8000] D loss: 0.7000, G loss: 3.4762\n",
      "[7212/8000] D loss: 0.7436, G loss: 2.0934\n",
      "[7572/8000] D loss: 0.7081, G loss: 7.6347\n",
      "[7932/8000] D loss: 0.7873, G loss: 6.0902\n",
      "train error: \n",
      " D loss: 0.835114, G loss: 4.404365, D accuracy: 74.1%, cell accuracy: 98.6%, board accuracy: 51.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.770958, G loss: 12.688873, D accuracy: 83.8%, cell accuracy: 98.1%, board accuracy: 25.6% \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5923, G loss: 5.1983\n",
      "[372/8000] D loss: 0.8213, G loss: 5.0506\n",
      "[732/8000] D loss: 0.7328, G loss: 5.2491\n",
      "[1092/8000] D loss: 0.9385, G loss: 2.6069\n",
      "[1452/8000] D loss: 0.5489, G loss: 8.7613\n",
      "[1812/8000] D loss: 1.1044, G loss: 3.9510\n",
      "[2172/8000] D loss: 0.8778, G loss: 7.8379\n",
      "[2532/8000] D loss: 0.6439, G loss: 5.2907\n",
      "[2892/8000] D loss: 1.0357, G loss: 5.2313\n",
      "[3252/8000] D loss: 1.0000, G loss: 3.3037\n",
      "[3612/8000] D loss: 1.0871, G loss: 1.5642\n",
      "[3972/8000] D loss: 0.5087, G loss: 4.7507\n",
      "[4332/8000] D loss: 0.7983, G loss: 8.8700\n",
      "[4692/8000] D loss: 0.7762, G loss: 3.9671\n",
      "[5052/8000] D loss: 0.9710, G loss: 1.6315\n",
      "[5412/8000] D loss: 0.8212, G loss: 7.2719\n",
      "[5772/8000] D loss: 0.9623, G loss: 4.4536\n",
      "[6132/8000] D loss: 0.4366, G loss: 8.0858\n",
      "[6492/8000] D loss: 0.9473, G loss: 3.2373\n",
      "[6852/8000] D loss: 0.9191, G loss: 5.1455\n",
      "[7212/8000] D loss: 0.7114, G loss: 4.1794\n",
      "[7572/8000] D loss: 0.8041, G loss: 2.6487\n",
      "[7932/8000] D loss: 0.6888, G loss: 3.2981\n",
      "train error: \n",
      " D loss: 0.826656, G loss: 4.509618, D accuracy: 74.1%, cell accuracy: 98.7%, board accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.861869, G loss: 13.317015, D accuracy: 81.4%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6497, G loss: 6.8225\n",
      "[372/8000] D loss: 0.8618, G loss: 7.8777\n",
      "[732/8000] D loss: 1.2335, G loss: 2.1278\n",
      "[1092/8000] D loss: 0.6149, G loss: 6.0129\n",
      "[1452/8000] D loss: 0.9182, G loss: 6.2436\n",
      "[1812/8000] D loss: 0.5810, G loss: 5.5125\n",
      "[2172/8000] D loss: 0.7995, G loss: 4.4167\n",
      "[2532/8000] D loss: 0.9499, G loss: 7.1393\n",
      "[2892/8000] D loss: 0.5766, G loss: 3.8673\n",
      "[3252/8000] D loss: 0.7301, G loss: 7.5364\n",
      "[3612/8000] D loss: 0.8520, G loss: 3.1430\n",
      "[3972/8000] D loss: 0.8921, G loss: 4.1858\n",
      "[4332/8000] D loss: 0.6798, G loss: 8.1001\n",
      "[4692/8000] D loss: 1.0823, G loss: 2.9074\n",
      "[5052/8000] D loss: 0.8370, G loss: 5.5180\n",
      "[5412/8000] D loss: 0.7351, G loss: 4.1163\n",
      "[5772/8000] D loss: 0.7151, G loss: 5.7347\n",
      "[6132/8000] D loss: 0.4849, G loss: 9.7627\n",
      "[6492/8000] D loss: 0.8723, G loss: 3.7941\n",
      "[6852/8000] D loss: 0.7770, G loss: 5.8529\n",
      "[7212/8000] D loss: 0.8128, G loss: 4.6434\n",
      "[7572/8000] D loss: 0.7511, G loss: 5.9709\n",
      "[7932/8000] D loss: 0.6207, G loss: 4.5380\n",
      "train error: \n",
      " D loss: 0.837281, G loss: 5.432745, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.901238, G loss: 14.083057, D accuracy: 79.8%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8192, G loss: 7.5599\n",
      "[372/8000] D loss: 0.9020, G loss: 5.8086\n",
      "[732/8000] D loss: 0.5412, G loss: 6.4507\n",
      "[1092/8000] D loss: 0.8033, G loss: 8.7376\n",
      "[1452/8000] D loss: 0.8387, G loss: 6.0232\n",
      "[1812/8000] D loss: 0.6123, G loss: 7.9328\n",
      "[2172/8000] D loss: 1.1633, G loss: 2.4205\n",
      "[2532/8000] D loss: 0.5896, G loss: 4.5570\n",
      "[2892/8000] D loss: 0.9447, G loss: 1.7760\n",
      "[3252/8000] D loss: 0.2771, G loss: 6.8337\n",
      "[3612/8000] D loss: 0.2781, G loss: 10.8309\n",
      "[3972/8000] D loss: 0.8682, G loss: 3.1921\n",
      "[4332/8000] D loss: 0.6089, G loss: 5.5527\n",
      "[4692/8000] D loss: 1.3139, G loss: 1.2458\n",
      "[5052/8000] D loss: 0.9561, G loss: 2.7796\n",
      "[5412/8000] D loss: 0.8208, G loss: 6.3537\n",
      "[5772/8000] D loss: 1.1047, G loss: 6.1650\n",
      "[6132/8000] D loss: 0.7374, G loss: 5.3234\n",
      "[6492/8000] D loss: 0.6873, G loss: 4.9335\n",
      "[6852/8000] D loss: 0.7525, G loss: 9.5153\n",
      "[7212/8000] D loss: 0.5134, G loss: 6.7762\n",
      "[7572/8000] D loss: 0.6881, G loss: 5.6501\n",
      "[7932/8000] D loss: 0.7201, G loss: 6.9022\n",
      "train error: \n",
      " D loss: 0.803510, G loss: 5.285948, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 51.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.897280, G loss: 14.277822, D accuracy: 79.5%, cell accuracy: 98.1%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6218, G loss: 6.8096\n",
      "[372/8000] D loss: 1.0139, G loss: 3.2054\n",
      "[732/8000] D loss: 0.8477, G loss: 5.6053\n",
      "[1092/8000] D loss: 0.8302, G loss: 7.3845\n",
      "[1452/8000] D loss: 0.8139, G loss: 4.4783\n",
      "[1812/8000] D loss: 0.9663, G loss: 2.8163\n",
      "[2172/8000] D loss: 0.6130, G loss: 6.0937\n",
      "[2532/8000] D loss: 0.5453, G loss: 5.7461\n",
      "[2892/8000] D loss: 0.4927, G loss: 4.9293\n",
      "[3252/8000] D loss: 0.6140, G loss: 7.4647\n",
      "[3612/8000] D loss: 0.7947, G loss: 4.9664\n",
      "[3972/8000] D loss: 0.4711, G loss: 5.2402\n",
      "[4332/8000] D loss: 0.5823, G loss: 6.1852\n",
      "[4692/8000] D loss: 0.8789, G loss: 6.1913\n",
      "[5052/8000] D loss: 0.7078, G loss: 5.7683\n",
      "[5412/8000] D loss: 0.8674, G loss: 8.8835\n",
      "[5772/8000] D loss: 0.4736, G loss: 3.2498\n",
      "[6132/8000] D loss: 0.8322, G loss: 4.2566\n",
      "[6492/8000] D loss: 0.6085, G loss: 11.2552\n",
      "[6852/8000] D loss: 0.4569, G loss: 7.5799\n",
      "[7212/8000] D loss: 1.0565, G loss: 4.2362\n",
      "[7572/8000] D loss: 0.7844, G loss: 6.6565\n",
      "[7932/8000] D loss: 1.0728, G loss: 4.2589\n",
      "train error: \n",
      " D loss: 0.806766, G loss: 5.677744, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 51.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.005732, G loss: 14.671699, D accuracy: 77.8%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9247, G loss: 4.5535\n",
      "[372/8000] D loss: 0.8261, G loss: 7.0647\n",
      "[732/8000] D loss: 0.7118, G loss: 5.1045\n",
      "[1092/8000] D loss: 0.6056, G loss: 9.3087\n",
      "[1452/8000] D loss: 0.4908, G loss: 9.1668\n",
      "[1812/8000] D loss: 0.9578, G loss: 4.7072\n",
      "[2172/8000] D loss: 0.8382, G loss: 5.1496\n",
      "[2532/8000] D loss: 0.7957, G loss: 4.6790\n",
      "[2892/8000] D loss: 0.8369, G loss: 4.8847\n",
      "[3252/8000] D loss: 0.9448, G loss: 2.6176\n",
      "[3612/8000] D loss: 0.6015, G loss: 5.5352\n",
      "[3972/8000] D loss: 0.8075, G loss: 4.5406\n",
      "[4332/8000] D loss: 0.9486, G loss: 4.9072\n",
      "[4692/8000] D loss: 0.8747, G loss: 3.9975\n",
      "[5052/8000] D loss: 0.6422, G loss: 7.0561\n",
      "[5412/8000] D loss: 0.9285, G loss: 2.8340\n",
      "[5772/8000] D loss: 0.6807, G loss: 5.7813\n",
      "[6132/8000] D loss: 0.8357, G loss: 9.0657\n",
      "[6492/8000] D loss: 0.6004, G loss: 12.0956\n",
      "[6852/8000] D loss: 0.6469, G loss: 11.8540\n",
      "[7212/8000] D loss: 0.8279, G loss: 6.1779\n",
      "[7572/8000] D loss: 0.6847, G loss: 5.6784\n",
      "[7932/8000] D loss: 0.8204, G loss: 4.9847\n",
      "train error: \n",
      " D loss: 0.802331, G loss: 5.299150, D accuracy: 74.8%, cell accuracy: 98.7%, board accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.859657, G loss: 14.534557, D accuracy: 81.6%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7578, G loss: 6.3302\n",
      "[372/8000] D loss: 0.7568, G loss: 4.6474\n",
      "[732/8000] D loss: 0.9179, G loss: 7.2941\n",
      "[1092/8000] D loss: 0.9193, G loss: 2.1736\n",
      "[1452/8000] D loss: 0.9279, G loss: 4.7036\n",
      "[1812/8000] D loss: 0.7315, G loss: 8.4302\n",
      "[2172/8000] D loss: 0.6605, G loss: 8.2850\n",
      "[2532/8000] D loss: 0.3816, G loss: 11.9377\n",
      "[2892/8000] D loss: 1.0872, G loss: 6.7930\n",
      "[3252/8000] D loss: 0.4434, G loss: 7.6632\n",
      "[3612/8000] D loss: 0.9272, G loss: 3.9110\n",
      "[3972/8000] D loss: 0.3851, G loss: 9.7951\n",
      "[4332/8000] D loss: 0.9934, G loss: 5.0858\n",
      "[4692/8000] D loss: 1.0135, G loss: 4.4343\n",
      "[5052/8000] D loss: 0.6621, G loss: 8.8188\n",
      "[5412/8000] D loss: 0.8611, G loss: 4.5209\n",
      "[5772/8000] D loss: 0.9769, G loss: 2.0673\n",
      "[6132/8000] D loss: 0.7074, G loss: 6.1455\n",
      "[6492/8000] D loss: 0.8418, G loss: 8.7056\n",
      "[6852/8000] D loss: 0.8278, G loss: 4.4279\n",
      "[7212/8000] D loss: 0.8000, G loss: 7.9640\n",
      "[7572/8000] D loss: 0.6934, G loss: 6.0352\n",
      "[7932/8000] D loss: 1.0674, G loss: 4.6147\n",
      "train error: \n",
      " D loss: 0.805443, G loss: 5.501290, D accuracy: 74.7%, cell accuracy: 98.6%, board accuracy: 51.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.892621, G loss: 15.180455, D accuracy: 81.9%, cell accuracy: 98.1%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6788, G loss: 3.7164\n",
      "[372/8000] D loss: 0.7802, G loss: 3.5164\n",
      "[732/8000] D loss: 0.8641, G loss: 3.8856\n",
      "[1092/8000] D loss: 1.1921, G loss: 1.5674\n",
      "[1452/8000] D loss: 0.5650, G loss: 7.2324\n",
      "[1812/8000] D loss: 0.6654, G loss: 4.7786\n",
      "[2172/8000] D loss: 0.9712, G loss: 3.8616\n",
      "[2532/8000] D loss: 1.0717, G loss: 1.1204\n",
      "[2892/8000] D loss: 1.1056, G loss: 5.4195\n",
      "[3252/8000] D loss: 0.6850, G loss: 5.4159\n",
      "[3612/8000] D loss: 0.7319, G loss: 6.5368\n",
      "[3972/8000] D loss: 0.8986, G loss: 3.8707\n",
      "[4332/8000] D loss: 1.0045, G loss: 2.8058\n",
      "[4692/8000] D loss: 0.9610, G loss: 5.4357\n",
      "[5052/8000] D loss: 0.6053, G loss: 5.8314\n",
      "[5412/8000] D loss: 0.3131, G loss: 15.1732\n",
      "[5772/8000] D loss: 0.7784, G loss: 5.3681\n",
      "[6132/8000] D loss: 0.7203, G loss: 4.7085\n",
      "[6492/8000] D loss: 0.7366, G loss: 3.3485\n",
      "[6852/8000] D loss: 0.7353, G loss: 6.0556\n",
      "[7212/8000] D loss: 0.9340, G loss: 2.6974\n",
      "[7572/8000] D loss: 0.4797, G loss: 7.8191\n",
      "[7932/8000] D loss: 0.5669, G loss: 6.7043\n",
      "train error: \n",
      " D loss: 0.822676, G loss: 4.387812, D accuracy: 73.9%, cell accuracy: 98.7%, board accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.818311, G loss: 12.878008, D accuracy: 82.1%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5771, G loss: 4.8420\n",
      "[372/8000] D loss: 1.2131, G loss: 1.4471\n",
      "[732/8000] D loss: 0.6405, G loss: 5.8276\n",
      "[1092/8000] D loss: 0.9436, G loss: 4.8238\n",
      "[1452/8000] D loss: 0.7312, G loss: 2.6360\n",
      "[1812/8000] D loss: 0.8271, G loss: 3.5453\n",
      "[2172/8000] D loss: 0.7159, G loss: 5.1689\n",
      "[2532/8000] D loss: 0.8175, G loss: 4.9185\n",
      "[2892/8000] D loss: 0.9182, G loss: 3.9022\n",
      "[3252/8000] D loss: 0.8601, G loss: 4.6702\n",
      "[3612/8000] D loss: 0.6843, G loss: 9.2146\n",
      "[3972/8000] D loss: 0.9357, G loss: 3.7035\n",
      "[4332/8000] D loss: 0.6182, G loss: 6.1663\n",
      "[4692/8000] D loss: 0.8278, G loss: 4.1463\n",
      "[5052/8000] D loss: 0.7495, G loss: 6.8685\n",
      "[5412/8000] D loss: 0.8710, G loss: 11.3017\n",
      "[5772/8000] D loss: 0.7332, G loss: 8.3544\n",
      "[6132/8000] D loss: 0.5100, G loss: 7.4101\n",
      "[6492/8000] D loss: 0.7786, G loss: 6.2363\n",
      "[6852/8000] D loss: 0.8325, G loss: 4.2607\n",
      "[7212/8000] D loss: 0.7295, G loss: 9.9923\n",
      "[7572/8000] D loss: 1.1346, G loss: 1.4085\n",
      "[7932/8000] D loss: 1.2415, G loss: 1.8163\n",
      "train error: \n",
      " D loss: 0.877672, G loss: 4.740495, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 51.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.979021, G loss: 12.850848, D accuracy: 75.1%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5086, G loss: 7.1183\n",
      "[372/8000] D loss: 1.0247, G loss: 4.3686\n",
      "[732/8000] D loss: 0.8870, G loss: 5.1686\n",
      "[1092/8000] D loss: 0.6977, G loss: 2.5320\n",
      "[1452/8000] D loss: 0.2063, G loss: 6.4722\n",
      "[1812/8000] D loss: 0.5273, G loss: 10.4288\n",
      "[2172/8000] D loss: 0.6496, G loss: 5.2062\n",
      "[2532/8000] D loss: 0.8948, G loss: 5.1966\n",
      "[2892/8000] D loss: 0.5022, G loss: 9.5244\n",
      "[3252/8000] D loss: 0.5592, G loss: 10.4543\n",
      "[3612/8000] D loss: 0.8043, G loss: 5.1137\n",
      "[3972/8000] D loss: 1.1974, G loss: 1.2840\n",
      "[4332/8000] D loss: 0.9750, G loss: 3.9217\n",
      "[4692/8000] D loss: 0.9846, G loss: 5.2161\n",
      "[5052/8000] D loss: 1.1217, G loss: 5.6727\n",
      "[5412/8000] D loss: 0.9800, G loss: 4.6142\n",
      "[5772/8000] D loss: 0.9483, G loss: 2.8648\n",
      "[6132/8000] D loss: 1.0474, G loss: 3.5055\n",
      "[6492/8000] D loss: 0.6664, G loss: 4.5590\n",
      "[6852/8000] D loss: 0.9246, G loss: 5.3905\n",
      "[7212/8000] D loss: 1.1574, G loss: 1.6014\n",
      "[7572/8000] D loss: 0.9431, G loss: 2.7817\n",
      "[7932/8000] D loss: 0.7632, G loss: 10.4923\n",
      "train error: \n",
      " D loss: 0.805884, G loss: 6.172396, D accuracy: 74.3%, cell accuracy: 98.7%, board accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.995830, G loss: 15.415395, D accuracy: 78.5%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0555, G loss: 3.7766\n",
      "[372/8000] D loss: 0.5281, G loss: 12.9781\n",
      "[732/8000] D loss: 0.7747, G loss: 6.0497\n",
      "[1092/8000] D loss: 0.8846, G loss: 7.7636\n",
      "[1452/8000] D loss: 0.4590, G loss: 5.5605\n",
      "[1812/8000] D loss: 1.1366, G loss: 5.2933\n",
      "[2172/8000] D loss: 0.7396, G loss: 3.7515\n",
      "[2532/8000] D loss: 0.6537, G loss: 7.4540\n",
      "[2892/8000] D loss: 0.9745, G loss: 4.0165\n",
      "[3252/8000] D loss: 0.6026, G loss: 5.0626\n",
      "[3612/8000] D loss: 1.0084, G loss: 4.4299\n",
      "[3972/8000] D loss: 0.3779, G loss: 13.4519\n",
      "[4332/8000] D loss: 0.9564, G loss: 4.3826\n",
      "[4692/8000] D loss: 0.9158, G loss: 5.5522\n",
      "[5052/8000] D loss: 0.5668, G loss: 8.0922\n",
      "[5412/8000] D loss: 1.0499, G loss: 4.6943\n",
      "[5772/8000] D loss: 0.9310, G loss: 3.4323\n",
      "[6132/8000] D loss: 0.9876, G loss: 2.2338\n",
      "[6492/8000] D loss: 0.9525, G loss: 3.7398\n",
      "[6852/8000] D loss: 0.7852, G loss: 8.0119\n",
      "[7212/8000] D loss: 0.6709, G loss: 8.5745\n",
      "[7572/8000] D loss: 0.3072, G loss: 12.4704\n",
      "[7932/8000] D loss: 0.7818, G loss: 2.2815\n",
      "train error: \n",
      " D loss: 0.815309, G loss: 4.655475, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 52.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.883514, G loss: 13.319652, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9907, G loss: 5.0322\n",
      "[372/8000] D loss: 0.5830, G loss: 6.0888\n",
      "[732/8000] D loss: 0.8607, G loss: 3.8428\n",
      "[1092/8000] D loss: 0.4633, G loss: 12.6076\n",
      "[1452/8000] D loss: 1.0046, G loss: 4.2615\n",
      "[1812/8000] D loss: 1.2442, G loss: 1.2730\n",
      "[2172/8000] D loss: 1.0323, G loss: 2.1809\n",
      "[2532/8000] D loss: 0.7748, G loss: 5.2896\n",
      "[2892/8000] D loss: 0.7233, G loss: 5.4265\n",
      "[3252/8000] D loss: 1.0423, G loss: 2.0332\n",
      "[3612/8000] D loss: 0.8310, G loss: 5.1494\n",
      "[3972/8000] D loss: 0.8367, G loss: 6.4326\n",
      "[4332/8000] D loss: 0.7960, G loss: 6.5564\n",
      "[4692/8000] D loss: 0.4470, G loss: 5.9747\n",
      "[5052/8000] D loss: 0.9347, G loss: 6.4491\n",
      "[5412/8000] D loss: 0.8852, G loss: 5.0776\n",
      "[5772/8000] D loss: 0.8258, G loss: 6.1563\n",
      "[6132/8000] D loss: 0.8185, G loss: 4.1352\n",
      "[6492/8000] D loss: 0.7238, G loss: 4.1956\n",
      "[6852/8000] D loss: 0.3713, G loss: 8.8364\n",
      "[7212/8000] D loss: 0.8766, G loss: 6.8203\n",
      "[7572/8000] D loss: 0.4699, G loss: 6.2755\n",
      "[7932/8000] D loss: 0.9184, G loss: 3.8534\n",
      "train error: \n",
      " D loss: 0.809722, G loss: 5.498789, D accuracy: 74.3%, cell accuracy: 98.7%, board accuracy: 51.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.017355, G loss: 14.873697, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7812, G loss: 5.7491\n",
      "[372/8000] D loss: 0.7720, G loss: 5.7306\n",
      "[732/8000] D loss: 0.8642, G loss: 3.5365\n",
      "[1092/8000] D loss: 0.9526, G loss: 5.3440\n",
      "[1452/8000] D loss: 1.0301, G loss: 3.5262\n",
      "[1812/8000] D loss: 0.4735, G loss: 8.7502\n",
      "[2172/8000] D loss: 0.6808, G loss: 3.4153\n",
      "[2532/8000] D loss: 0.7985, G loss: 6.3665\n",
      "[2892/8000] D loss: 0.7723, G loss: 4.2152\n",
      "[3252/8000] D loss: 0.9434, G loss: 6.5539\n",
      "[3612/8000] D loss: 0.9733, G loss: 3.4346\n",
      "[3972/8000] D loss: 0.5799, G loss: 7.6437\n",
      "[4332/8000] D loss: 0.0467, G loss: 13.5285\n",
      "[4692/8000] D loss: 0.2163, G loss: 12.5123\n",
      "[5052/8000] D loss: 0.6756, G loss: 5.6767\n",
      "[5412/8000] D loss: 0.7515, G loss: 3.6075\n",
      "[5772/8000] D loss: 0.9122, G loss: 4.6976\n",
      "[6132/8000] D loss: 0.5981, G loss: 4.9777\n",
      "[6492/8000] D loss: 1.1040, G loss: 2.5033\n",
      "[6852/8000] D loss: 0.5707, G loss: 5.0625\n",
      "[7212/8000] D loss: 0.7454, G loss: 5.4786\n",
      "[7572/8000] D loss: 0.7753, G loss: 3.8722\n",
      "[7932/8000] D loss: 0.6008, G loss: 8.5293\n",
      "train error: \n",
      " D loss: 0.802480, G loss: 5.677022, D accuracy: 74.5%, cell accuracy: 98.6%, board accuracy: 51.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.919335, G loss: 15.783067, D accuracy: 78.2%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6695, G loss: 8.2929\n",
      "[372/8000] D loss: 1.1667, G loss: 3.7360\n",
      "[732/8000] D loss: 0.7620, G loss: 4.4784\n",
      "[1092/8000] D loss: 1.0368, G loss: 4.4790\n",
      "[1452/8000] D loss: 1.0814, G loss: 3.7065\n",
      "[1812/8000] D loss: 0.7020, G loss: 7.1901\n",
      "[2172/8000] D loss: 0.3991, G loss: 6.3520\n",
      "[2532/8000] D loss: 0.5693, G loss: 10.8191\n",
      "[2892/8000] D loss: 1.0329, G loss: 2.4855\n",
      "[3252/8000] D loss: 0.8194, G loss: 3.9161\n",
      "[3612/8000] D loss: 0.9566, G loss: 2.7649\n",
      "[3972/8000] D loss: 0.7927, G loss: 7.1638\n",
      "[4332/8000] D loss: 1.0895, G loss: 1.3318\n",
      "[4692/8000] D loss: 0.4843, G loss: 5.4973\n",
      "[5052/8000] D loss: 0.7352, G loss: 3.7952\n",
      "[5412/8000] D loss: 0.8776, G loss: 4.5774\n",
      "[5772/8000] D loss: 0.8085, G loss: 2.4303\n",
      "[6132/8000] D loss: 1.2719, G loss: 3.1456\n",
      "[6492/8000] D loss: 1.0919, G loss: 8.8110\n",
      "[6852/8000] D loss: 0.9579, G loss: 7.0376\n",
      "[7212/8000] D loss: 0.7004, G loss: 4.8399\n",
      "[7572/8000] D loss: 0.7545, G loss: 6.8377\n",
      "[7932/8000] D loss: 0.8216, G loss: 5.8276\n",
      "train error: \n",
      " D loss: 0.799175, G loss: 5.321251, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.918425, G loss: 14.194457, D accuracy: 79.1%, cell accuracy: 98.1%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6484, G loss: 6.6116\n",
      "[372/8000] D loss: 1.0463, G loss: 3.8381\n",
      "[732/8000] D loss: 0.5617, G loss: 12.1117\n",
      "[1092/8000] D loss: 1.0282, G loss: 3.2257\n",
      "[1452/8000] D loss: 0.6504, G loss: 7.0267\n",
      "[1812/8000] D loss: 0.6862, G loss: 8.0746\n",
      "[2172/8000] D loss: 0.6077, G loss: 6.7730\n",
      "[2532/8000] D loss: 0.9973, G loss: 3.9192\n",
      "[2892/8000] D loss: 0.5166, G loss: 8.3987\n",
      "[3252/8000] D loss: 0.4379, G loss: 11.4820\n",
      "[3612/8000] D loss: 0.7971, G loss: 3.4173\n",
      "[3972/8000] D loss: 0.6783, G loss: 7.2367\n",
      "[4332/8000] D loss: 0.5937, G loss: 7.5932\n",
      "[4692/8000] D loss: 0.7924, G loss: 4.4508\n",
      "[5052/8000] D loss: 0.8310, G loss: 6.2981\n",
      "[5412/8000] D loss: 0.8352, G loss: 2.6599\n",
      "[5772/8000] D loss: 0.6287, G loss: 4.9495\n",
      "[6132/8000] D loss: 1.2014, G loss: 1.7544\n",
      "[6492/8000] D loss: 1.0545, G loss: 4.1222\n",
      "[6852/8000] D loss: 0.4704, G loss: 4.7589\n",
      "[7212/8000] D loss: 0.8450, G loss: 2.1367\n",
      "[7572/8000] D loss: 0.6486, G loss: 9.2441\n",
      "[7932/8000] D loss: 0.8339, G loss: 3.3910\n",
      "train error: \n",
      " D loss: 0.838660, G loss: 5.014524, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.990491, G loss: 13.996261, D accuracy: 78.4%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5208, G loss: 7.8743\n",
      "[372/8000] D loss: 0.9708, G loss: 4.3646\n",
      "[732/8000] D loss: 0.5764, G loss: 3.6608\n",
      "[1092/8000] D loss: 0.7933, G loss: 2.4229\n",
      "[1452/8000] D loss: 0.7187, G loss: 7.5805\n",
      "[1812/8000] D loss: 0.8774, G loss: 3.4271\n",
      "[2172/8000] D loss: 1.2473, G loss: 1.0244\n",
      "[2532/8000] D loss: 0.9153, G loss: 4.0026\n",
      "[2892/8000] D loss: 0.6989, G loss: 7.2415\n",
      "[3252/8000] D loss: 0.7229, G loss: 4.6266\n",
      "[3612/8000] D loss: 1.0927, G loss: 4.8899\n",
      "[3972/8000] D loss: 0.6082, G loss: 13.5130\n",
      "[4332/8000] D loss: 1.0438, G loss: 4.0540\n",
      "[4692/8000] D loss: 0.8999, G loss: 7.0887\n",
      "[5052/8000] D loss: 0.8236, G loss: 6.6877\n",
      "[5412/8000] D loss: 0.5890, G loss: 7.2887\n",
      "[5772/8000] D loss: 0.7053, G loss: 12.1449\n",
      "[6132/8000] D loss: 0.9726, G loss: 5.6802\n",
      "[6492/8000] D loss: 0.6651, G loss: 4.8035\n",
      "[6852/8000] D loss: 0.8319, G loss: 4.0624\n",
      "[7212/8000] D loss: 0.4402, G loss: 7.6649\n",
      "[7572/8000] D loss: 0.7501, G loss: 2.2623\n",
      "[7932/8000] D loss: 0.5951, G loss: 10.7823\n",
      "train error: \n",
      " D loss: 0.803689, G loss: 5.382684, D accuracy: 74.6%, cell accuracy: 98.7%, board accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.856911, G loss: 14.227765, D accuracy: 81.7%, cell accuracy: 98.1%, board accuracy: 24.0% \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0853, G loss: 3.3819\n",
      "[372/8000] D loss: 0.9401, G loss: 3.6797\n",
      "[732/8000] D loss: 0.7560, G loss: 5.3166\n",
      "[1092/8000] D loss: 1.1839, G loss: 4.5688\n",
      "[1452/8000] D loss: 0.5881, G loss: 13.2427\n",
      "[1812/8000] D loss: 1.0119, G loss: 5.3318\n",
      "[2172/8000] D loss: 0.7866, G loss: 3.7996\n",
      "[2532/8000] D loss: 0.6359, G loss: 5.1768\n",
      "[2892/8000] D loss: 0.6072, G loss: 9.9127\n",
      "[3252/8000] D loss: 0.7747, G loss: 3.8641\n",
      "[3612/8000] D loss: 1.0774, G loss: 2.5558\n",
      "[3972/8000] D loss: 0.7755, G loss: 6.2258\n",
      "[4332/8000] D loss: 0.8842, G loss: 5.9954\n",
      "[4692/8000] D loss: 1.0226, G loss: 5.9339\n",
      "[5052/8000] D loss: 0.9243, G loss: 5.6292\n",
      "[5412/8000] D loss: 0.8630, G loss: 6.2421\n",
      "[5772/8000] D loss: 0.5363, G loss: 8.2846\n",
      "[6132/8000] D loss: 0.6391, G loss: 8.1181\n",
      "[6492/8000] D loss: 0.5378, G loss: 4.3696\n",
      "[6852/8000] D loss: 0.5135, G loss: 10.9266\n",
      "[7212/8000] D loss: 0.2861, G loss: 7.8122\n",
      "[7572/8000] D loss: 0.9259, G loss: 3.3022\n",
      "[7932/8000] D loss: 0.4766, G loss: 8.5725\n",
      "train error: \n",
      " D loss: 0.799379, G loss: 5.534284, D accuracy: 74.5%, cell accuracy: 98.7%, board accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.949058, G loss: 14.852593, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 26.0% \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5258, G loss: 7.7185\n",
      "[372/8000] D loss: 0.9365, G loss: 2.8073\n",
      "[732/8000] D loss: 0.7135, G loss: 2.8804\n",
      "[1092/8000] D loss: 0.8702, G loss: 6.4824\n",
      "[1452/8000] D loss: 0.7200, G loss: 6.8698\n",
      "[1812/8000] D loss: 0.7231, G loss: 8.1478\n",
      "[2172/8000] D loss: 0.8415, G loss: 3.7194\n",
      "[2532/8000] D loss: 0.8463, G loss: 4.4354\n",
      "[2892/8000] D loss: 0.7012, G loss: 8.7955\n",
      "[3252/8000] D loss: 0.8106, G loss: 5.9106\n",
      "[3612/8000] D loss: 0.7705, G loss: 8.8192\n",
      "[3972/8000] D loss: 1.0870, G loss: 3.1654\n",
      "[4332/8000] D loss: 0.7517, G loss: 7.0258\n",
      "[4692/8000] D loss: 0.6792, G loss: 5.2582\n",
      "[5052/8000] D loss: 1.0423, G loss: 5.3493\n",
      "[5412/8000] D loss: 0.5934, G loss: 7.7291\n",
      "[5772/8000] D loss: 0.5830, G loss: 2.7306\n",
      "[6132/8000] D loss: 0.7761, G loss: 6.4533\n",
      "[6492/8000] D loss: 1.1004, G loss: 4.0018\n",
      "[6852/8000] D loss: 0.7368, G loss: 5.9582\n",
      "[7212/8000] D loss: 0.8510, G loss: 2.7825\n",
      "[7572/8000] D loss: 0.5743, G loss: 4.1784\n",
      "[7932/8000] D loss: 0.5437, G loss: 4.5548\n",
      "train error: \n",
      " D loss: 0.816552, G loss: 4.988863, D accuracy: 74.0%, cell accuracy: 98.7%, board accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.942750, G loss: 13.561712, D accuracy: 79.3%, cell accuracy: 98.2%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0928, G loss: 3.1295\n",
      "[372/8000] D loss: 1.0783, G loss: 2.9831\n",
      "[732/8000] D loss: 1.0109, G loss: 6.3067\n",
      "[1092/8000] D loss: 0.9037, G loss: 5.6816\n",
      "[1452/8000] D loss: 1.0173, G loss: 6.1225\n",
      "[1812/8000] D loss: 1.1003, G loss: 1.7715\n",
      "[2172/8000] D loss: 0.5003, G loss: 10.9717\n",
      "[2532/8000] D loss: 0.8445, G loss: 5.8385\n",
      "[2892/8000] D loss: 0.8616, G loss: 7.2035\n",
      "[3252/8000] D loss: 1.2442, G loss: 1.2734\n",
      "[3612/8000] D loss: 1.0310, G loss: 3.9718\n",
      "[3972/8000] D loss: 0.6167, G loss: 5.6517\n",
      "[4332/8000] D loss: 0.9366, G loss: 3.3522\n",
      "[4692/8000] D loss: 0.7118, G loss: 7.2744\n",
      "[5052/8000] D loss: 0.6188, G loss: 9.8316\n",
      "[5412/8000] D loss: 0.8015, G loss: 5.7442\n",
      "[5772/8000] D loss: 0.8166, G loss: 5.7884\n",
      "[6132/8000] D loss: 0.6533, G loss: 6.4119\n",
      "[6492/8000] D loss: 1.0661, G loss: 4.6789\n",
      "[6852/8000] D loss: 0.9458, G loss: 4.8591\n",
      "[7212/8000] D loss: 0.8268, G loss: 5.2575\n",
      "[7572/8000] D loss: 1.0036, G loss: 2.5169\n",
      "[7932/8000] D loss: 1.0213, G loss: 4.1934\n",
      "train error: \n",
      " D loss: 0.810889, G loss: 5.319284, D accuracy: 74.1%, cell accuracy: 98.7%, board accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.923289, G loss: 14.715639, D accuracy: 79.1%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8046, G loss: 4.1241\n",
      "[372/8000] D loss: 1.0534, G loss: 2.6378\n",
      "[732/8000] D loss: 0.4955, G loss: 6.9833\n",
      "[1092/8000] D loss: 0.9068, G loss: 4.8229\n",
      "[1452/8000] D loss: 0.9789, G loss: 3.0512\n",
      "[1812/8000] D loss: 0.7821, G loss: 2.9577\n",
      "[2172/8000] D loss: 0.6961, G loss: 6.2895\n",
      "[2532/8000] D loss: 1.2452, G loss: 1.6331\n",
      "[2892/8000] D loss: 0.6740, G loss: 5.4767\n",
      "[3252/8000] D loss: 1.0820, G loss: 2.4609\n",
      "[3612/8000] D loss: 0.8359, G loss: 5.5565\n",
      "[3972/8000] D loss: 0.9868, G loss: 3.8102\n",
      "[4332/8000] D loss: 1.1226, G loss: 3.0325\n",
      "[4692/8000] D loss: 1.1754, G loss: 3.8235\n",
      "[5052/8000] D loss: 0.8525, G loss: 7.8975\n",
      "[5412/8000] D loss: 0.8035, G loss: 6.5530\n",
      "[5772/8000] D loss: 1.0193, G loss: 4.2401\n",
      "[6132/8000] D loss: 0.6827, G loss: 6.5853\n",
      "[6492/8000] D loss: 0.6021, G loss: 4.1677\n",
      "[6852/8000] D loss: 1.0155, G loss: 4.2062\n",
      "[7212/8000] D loss: 0.6665, G loss: 7.9621\n",
      "[7572/8000] D loss: 0.6540, G loss: 6.0777\n",
      "[7932/8000] D loss: 0.4302, G loss: 5.8502\n",
      "train error: \n",
      " D loss: 0.812694, G loss: 5.190977, D accuracy: 74.5%, cell accuracy: 98.7%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.886156, G loss: 14.372801, D accuracy: 81.4%, cell accuracy: 98.2%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6058, G loss: 9.4256\n",
      "[372/8000] D loss: 0.7732, G loss: 5.7774\n",
      "[732/8000] D loss: 0.7494, G loss: 5.1238\n",
      "[1092/8000] D loss: 0.7346, G loss: 6.3008\n",
      "[1452/8000] D loss: 0.7432, G loss: 7.2719\n",
      "[1812/8000] D loss: 0.9302, G loss: 4.1198\n",
      "[2172/8000] D loss: 0.7604, G loss: 4.5920\n",
      "[2532/8000] D loss: 0.5767, G loss: 6.8336\n",
      "[2892/8000] D loss: 0.8073, G loss: 3.8934\n",
      "[3252/8000] D loss: 0.7050, G loss: 8.3784\n",
      "[3612/8000] D loss: 1.0139, G loss: 2.5814\n",
      "[3972/8000] D loss: 0.8959, G loss: 4.1158\n",
      "[4332/8000] D loss: 0.8713, G loss: 7.3184\n",
      "[4692/8000] D loss: 0.6135, G loss: 7.2832\n",
      "[5052/8000] D loss: 1.2657, G loss: 2.2319\n",
      "[5412/8000] D loss: 0.7821, G loss: 6.2388\n",
      "[5772/8000] D loss: 1.0536, G loss: 6.0142\n",
      "[6132/8000] D loss: 0.7004, G loss: 6.2847\n",
      "[6492/8000] D loss: 0.9292, G loss: 6.7197\n",
      "[6852/8000] D loss: 0.6111, G loss: 7.2778\n",
      "[7212/8000] D loss: 0.8540, G loss: 4.0332\n",
      "[7572/8000] D loss: 0.8764, G loss: 3.0299\n",
      "[7932/8000] D loss: 0.7807, G loss: 8.6395\n",
      "train error: \n",
      " D loss: 0.801703, G loss: 5.548030, D accuracy: 74.3%, cell accuracy: 98.7%, board accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.877037, G loss: 14.824566, D accuracy: 80.1%, cell accuracy: 98.2%, board accuracy: 25.7% \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5404, G loss: 8.6800\n",
      "[372/8000] D loss: 0.7460, G loss: 4.3091\n",
      "[732/8000] D loss: 0.9359, G loss: 2.1210\n",
      "[1092/8000] D loss: 0.9426, G loss: 5.7449\n",
      "[1452/8000] D loss: 0.8266, G loss: 2.6006\n",
      "[1812/8000] D loss: 0.6341, G loss: 7.4353\n",
      "[2172/8000] D loss: 0.7585, G loss: 3.7967\n",
      "[2532/8000] D loss: 0.8600, G loss: 9.2439\n",
      "[2892/8000] D loss: 0.9328, G loss: 2.4167\n",
      "[3252/8000] D loss: 0.6246, G loss: 8.5738\n",
      "[3612/8000] D loss: 0.9024, G loss: 3.8665\n",
      "[3972/8000] D loss: 0.9557, G loss: 2.1224\n",
      "[4332/8000] D loss: 1.0416, G loss: 2.6989\n",
      "[4692/8000] D loss: 0.6770, G loss: 4.4821\n",
      "[5052/8000] D loss: 0.7948, G loss: 2.8864\n",
      "[5412/8000] D loss: 1.0549, G loss: 3.1516\n",
      "[5772/8000] D loss: 1.1030, G loss: 1.7348\n",
      "[6132/8000] D loss: 0.8297, G loss: 2.4404\n",
      "[6492/8000] D loss: 0.7419, G loss: 4.2784\n",
      "[6852/8000] D loss: 0.8156, G loss: 4.9872\n",
      "[7212/8000] D loss: 1.1324, G loss: 1.7622\n",
      "[7572/8000] D loss: 0.8860, G loss: 2.3441\n",
      "[7932/8000] D loss: 0.9947, G loss: 2.2094\n",
      "train error: \n",
      " D loss: 0.817966, G loss: 4.732886, D accuracy: 74.1%, cell accuracy: 98.7%, board accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.895005, G loss: 13.624946, D accuracy: 80.8%, cell accuracy: 98.2%, board accuracy: 26.3% \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4047, G loss: 7.5887\n",
      "[372/8000] D loss: 0.8482, G loss: 10.2447\n",
      "[732/8000] D loss: 0.8946, G loss: 3.8789\n",
      "[1092/8000] D loss: 1.0133, G loss: 4.5236\n",
      "[1452/8000] D loss: 0.9692, G loss: 2.9191\n",
      "[1812/8000] D loss: 0.6703, G loss: 5.9518\n",
      "[2172/8000] D loss: 0.8108, G loss: 2.9979\n",
      "[2532/8000] D loss: 0.3704, G loss: 8.8204\n",
      "[2892/8000] D loss: 0.5751, G loss: 5.7783\n",
      "[3252/8000] D loss: 0.8989, G loss: 4.5164\n",
      "[3612/8000] D loss: 1.1185, G loss: 3.5558\n",
      "[3972/8000] D loss: 0.6807, G loss: 7.3378\n",
      "[4332/8000] D loss: 0.8739, G loss: 4.1873\n",
      "[4692/8000] D loss: 0.4863, G loss: 6.9411\n",
      "[5052/8000] D loss: 0.7419, G loss: 3.7473\n",
      "[5412/8000] D loss: 0.6795, G loss: 7.5756\n",
      "[5772/8000] D loss: 1.1459, G loss: 2.0250\n",
      "[6132/8000] D loss: 1.0018, G loss: 2.9403\n",
      "[6492/8000] D loss: 0.7550, G loss: 4.9509\n",
      "[6852/8000] D loss: 0.6445, G loss: 6.4979\n",
      "[7212/8000] D loss: 0.7074, G loss: 4.2666\n",
      "[7572/8000] D loss: 0.5774, G loss: 5.9387\n",
      "[7932/8000] D loss: 0.6432, G loss: 6.2648\n",
      "train error: \n",
      " D loss: 0.877573, G loss: 7.181126, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 52.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.213389, G loss: 17.702881, D accuracy: 72.2%, cell accuracy: 98.2%, board accuracy: 25.6% \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6391, G loss: 10.3638\n",
      "[372/8000] D loss: 0.5657, G loss: 8.7025\n",
      "[732/8000] D loss: 1.0768, G loss: 2.0281\n",
      "[1092/8000] D loss: 0.8431, G loss: 7.1850\n",
      "[1452/8000] D loss: 0.8403, G loss: 4.5693\n",
      "[1812/8000] D loss: 0.9541, G loss: 4.0916\n",
      "[2172/8000] D loss: 1.2088, G loss: 6.1697\n",
      "[2532/8000] D loss: 0.8416, G loss: 4.4222\n",
      "[2892/8000] D loss: 0.8788, G loss: 7.4932\n",
      "[3252/8000] D loss: 0.7306, G loss: 6.0302\n",
      "[3612/8000] D loss: 0.6444, G loss: 14.9535\n",
      "[3972/8000] D loss: 0.9475, G loss: 5.6338\n",
      "[4332/8000] D loss: 1.0631, G loss: 3.0161\n",
      "[4692/8000] D loss: 0.9635, G loss: 4.3621\n",
      "[5052/8000] D loss: 0.6629, G loss: 3.6937\n",
      "[5412/8000] D loss: 0.8322, G loss: 6.1326\n",
      "[5772/8000] D loss: 0.7152, G loss: 5.7032\n",
      "[6132/8000] D loss: 1.0101, G loss: 8.3529\n",
      "[6492/8000] D loss: 0.7915, G loss: 4.9772\n",
      "[6852/8000] D loss: 0.7429, G loss: 6.8574\n",
      "[7212/8000] D loss: 0.7321, G loss: 6.9128\n",
      "[7572/8000] D loss: 0.8429, G loss: 6.1752\n",
      "[7932/8000] D loss: 0.8270, G loss: 5.3904\n",
      "train error: \n",
      " D loss: 0.814581, G loss: 5.187323, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 53.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.935711, G loss: 14.234123, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9916, G loss: 4.6709\n",
      "[372/8000] D loss: 0.8896, G loss: 3.2662\n",
      "[732/8000] D loss: 0.6311, G loss: 4.5371\n",
      "[1092/8000] D loss: 0.8431, G loss: 4.8512\n",
      "[1452/8000] D loss: 0.7337, G loss: 6.0596\n",
      "[1812/8000] D loss: 0.8485, G loss: 4.0822\n",
      "[2172/8000] D loss: 0.6973, G loss: 3.7901\n",
      "[2532/8000] D loss: 0.8991, G loss: 3.0933\n",
      "[2892/8000] D loss: 0.5375, G loss: 5.6203\n",
      "[3252/8000] D loss: 0.9761, G loss: 3.4671\n",
      "[3612/8000] D loss: 1.0214, G loss: 5.9481\n",
      "[3972/8000] D loss: 0.7991, G loss: 4.0124\n",
      "[4332/8000] D loss: 0.8392, G loss: 5.7596\n",
      "[4692/8000] D loss: 0.8693, G loss: 3.5212\n",
      "[5052/8000] D loss: 0.6607, G loss: 5.5592\n",
      "[5412/8000] D loss: 0.7277, G loss: 5.5170\n",
      "[5772/8000] D loss: 0.8159, G loss: 6.9605\n",
      "[6132/8000] D loss: 0.8865, G loss: 2.7540\n",
      "[6492/8000] D loss: 1.1756, G loss: 1.9514\n",
      "[6852/8000] D loss: 0.8668, G loss: 6.3812\n",
      "[7212/8000] D loss: 0.9085, G loss: 4.3469\n",
      "[7572/8000] D loss: 0.9635, G loss: 3.5905\n",
      "[7932/8000] D loss: 0.7533, G loss: 4.4562\n",
      "train error: \n",
      " D loss: 0.798001, G loss: 5.456150, D accuracy: 75.1%, cell accuracy: 98.7%, board accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.847206, G loss: 14.234333, D accuracy: 80.9%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7366, G loss: 6.8170\n",
      "[372/8000] D loss: 0.8900, G loss: 6.7829\n",
      "[732/8000] D loss: 0.7221, G loss: 7.7369\n",
      "[1092/8000] D loss: 0.8421, G loss: 3.3181\n",
      "[1452/8000] D loss: 0.9534, G loss: 2.0443\n",
      "[1812/8000] D loss: 0.7183, G loss: 6.8505\n",
      "[2172/8000] D loss: 0.6962, G loss: 7.1888\n",
      "[2532/8000] D loss: 0.8565, G loss: 6.9635\n",
      "[2892/8000] D loss: 0.2350, G loss: 11.2856\n",
      "[3252/8000] D loss: 1.0943, G loss: 0.9765\n",
      "[3612/8000] D loss: 1.0786, G loss: 3.8336\n",
      "[3972/8000] D loss: 0.7404, G loss: 6.7158\n",
      "[4332/8000] D loss: 0.5900, G loss: 5.7351\n",
      "[4692/8000] D loss: 1.1062, G loss: 2.3147\n",
      "[5052/8000] D loss: 0.7335, G loss: 5.8289\n",
      "[5412/8000] D loss: 1.0815, G loss: 4.5722\n",
      "[5772/8000] D loss: 0.6587, G loss: 11.2496\n",
      "[6132/8000] D loss: 0.6766, G loss: 4.2365\n",
      "[6492/8000] D loss: 0.8942, G loss: 4.6163\n",
      "[6852/8000] D loss: 0.7392, G loss: 3.3790\n",
      "[7212/8000] D loss: 0.4390, G loss: 4.2310\n",
      "[7572/8000] D loss: 1.0762, G loss: 5.0419\n",
      "[7932/8000] D loss: 0.8732, G loss: 3.3921\n",
      "train error: \n",
      " D loss: 0.816395, G loss: 5.489389, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 52.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.006903, G loss: 14.724560, D accuracy: 77.8%, cell accuracy: 98.2%, board accuracy: 25.7% \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0772, G loss: 3.8861\n",
      "[372/8000] D loss: 0.8090, G loss: 4.1567\n",
      "[732/8000] D loss: 1.0300, G loss: 1.6814\n",
      "[1092/8000] D loss: 0.8671, G loss: 3.9174\n",
      "[1452/8000] D loss: 0.7752, G loss: 5.1121\n",
      "[1812/8000] D loss: 0.4987, G loss: 6.6725\n",
      "[2172/8000] D loss: 1.0818, G loss: 2.3797\n",
      "[2532/8000] D loss: 1.1687, G loss: 4.2053\n",
      "[2892/8000] D loss: 0.8944, G loss: 4.4125\n",
      "[3252/8000] D loss: 0.4832, G loss: 6.1451\n",
      "[3612/8000] D loss: 0.4709, G loss: 6.7609\n",
      "[3972/8000] D loss: 0.8899, G loss: 6.3258\n",
      "[4332/8000] D loss: 1.0698, G loss: 3.7687\n",
      "[4692/8000] D loss: 0.6224, G loss: 4.0021\n",
      "[5052/8000] D loss: 0.8756, G loss: 6.4007\n",
      "[5412/8000] D loss: 0.7167, G loss: 7.1422\n",
      "[5772/8000] D loss: 0.8782, G loss: 2.6844\n",
      "[6132/8000] D loss: 0.9544, G loss: 2.6460\n",
      "[6492/8000] D loss: 0.8107, G loss: 11.2203\n",
      "[6852/8000] D loss: 0.9798, G loss: 6.0630\n",
      "[7212/8000] D loss: 0.6909, G loss: 8.7662\n",
      "[7572/8000] D loss: 0.9493, G loss: 4.6821\n",
      "[7932/8000] D loss: 0.5843, G loss: 12.5948\n",
      "train error: \n",
      " D loss: 0.812560, G loss: 5.713085, D accuracy: 73.9%, cell accuracy: 98.7%, board accuracy: 53.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.979353, G loss: 15.622138, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 25.7% \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6046, G loss: 7.4884\n",
      "[372/8000] D loss: 0.8723, G loss: 3.8651\n",
      "[732/8000] D loss: 0.8162, G loss: 6.0975\n",
      "[1092/8000] D loss: 0.8462, G loss: 3.8270\n",
      "[1452/8000] D loss: 0.6833, G loss: 8.1665\n",
      "[1812/8000] D loss: 0.4206, G loss: 10.4092\n",
      "[2172/8000] D loss: 1.0205, G loss: 1.6402\n",
      "[2532/8000] D loss: 0.6161, G loss: 7.9414\n",
      "[2892/8000] D loss: 0.8140, G loss: 8.0267\n",
      "[3252/8000] D loss: 0.4485, G loss: 6.2177\n",
      "[3612/8000] D loss: 0.8312, G loss: 8.3091\n",
      "[3972/8000] D loss: 0.9237, G loss: 5.9954\n",
      "[4332/8000] D loss: 0.5567, G loss: 5.8053\n",
      "[4692/8000] D loss: 0.5100, G loss: 8.7360\n",
      "[5052/8000] D loss: 0.4516, G loss: 9.1712\n",
      "[5412/8000] D loss: 0.7848, G loss: 3.6208\n",
      "[5772/8000] D loss: 0.6892, G loss: 5.5970\n",
      "[6132/8000] D loss: 0.8497, G loss: 1.8642\n",
      "[6492/8000] D loss: 0.9708, G loss: 6.1215\n",
      "[6852/8000] D loss: 1.0318, G loss: 3.0657\n",
      "[7212/8000] D loss: 0.9094, G loss: 5.4106\n",
      "[7572/8000] D loss: 0.9927, G loss: 4.6289\n",
      "[7932/8000] D loss: 1.0143, G loss: 2.2590\n",
      "train error: \n",
      " D loss: 0.814306, G loss: 4.885284, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.909582, G loss: 13.525896, D accuracy: 78.3%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8234, G loss: 4.2576\n",
      "[372/8000] D loss: 0.5543, G loss: 9.8845\n",
      "[732/8000] D loss: 0.9990, G loss: 4.9533\n",
      "[1092/8000] D loss: 0.6172, G loss: 9.4094\n",
      "[1452/8000] D loss: 0.8886, G loss: 2.4215\n",
      "[1812/8000] D loss: 0.7332, G loss: 4.9400\n",
      "[2172/8000] D loss: 0.8459, G loss: 3.7690\n",
      "[2532/8000] D loss: 0.8231, G loss: 5.8650\n",
      "[2892/8000] D loss: 0.9206, G loss: 2.9753\n",
      "[3252/8000] D loss: 0.7627, G loss: 4.7835\n",
      "[3612/8000] D loss: 0.6708, G loss: 10.5654\n",
      "[3972/8000] D loss: 0.8414, G loss: 4.7197\n",
      "[4332/8000] D loss: 0.9344, G loss: 6.4266\n",
      "[4692/8000] D loss: 0.8085, G loss: 3.5736\n",
      "[5052/8000] D loss: 0.6489, G loss: 7.6859\n",
      "[5412/8000] D loss: 0.5115, G loss: 10.3327\n",
      "[5772/8000] D loss: 0.6852, G loss: 5.1012\n",
      "[6132/8000] D loss: 0.5965, G loss: 3.3321\n",
      "[6492/8000] D loss: 0.6124, G loss: 3.6955\n",
      "[6852/8000] D loss: 0.5228, G loss: 8.2529\n",
      "[7212/8000] D loss: 0.9016, G loss: 4.5360\n",
      "[7572/8000] D loss: 0.8109, G loss: 5.1470\n",
      "[7932/8000] D loss: 1.2778, G loss: 0.7717\n",
      "train error: \n",
      " D loss: 0.806153, G loss: 5.317213, D accuracy: 74.7%, cell accuracy: 98.7%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.900268, G loss: 14.932940, D accuracy: 81.5%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9036, G loss: 4.5263\n",
      "[372/8000] D loss: 0.5406, G loss: 5.9035\n",
      "[732/8000] D loss: 0.8331, G loss: 4.3253\n",
      "[1092/8000] D loss: 1.0536, G loss: 3.9546\n",
      "[1452/8000] D loss: 0.7105, G loss: 5.9881\n",
      "[1812/8000] D loss: 0.7121, G loss: 4.3384\n",
      "[2172/8000] D loss: 0.7608, G loss: 7.8170\n",
      "[2532/8000] D loss: 0.8279, G loss: 3.6273\n",
      "[2892/8000] D loss: 0.8626, G loss: 3.3680\n",
      "[3252/8000] D loss: 0.4486, G loss: 8.2947\n",
      "[3612/8000] D loss: 0.8247, G loss: 4.2285\n",
      "[3972/8000] D loss: 0.4969, G loss: 8.4035\n",
      "[4332/8000] D loss: 0.9713, G loss: 3.9530\n",
      "[4692/8000] D loss: 0.7475, G loss: 4.8516\n",
      "[5052/8000] D loss: 0.6538, G loss: 6.1807\n",
      "[5412/8000] D loss: 0.6923, G loss: 6.4204\n",
      "[5772/8000] D loss: 0.9681, G loss: 3.2853\n",
      "[6132/8000] D loss: 1.1302, G loss: 2.7132\n",
      "[6492/8000] D loss: 0.5794, G loss: 4.2523\n",
      "[6852/8000] D loss: 0.8602, G loss: 3.9099\n",
      "[7212/8000] D loss: 0.5970, G loss: 4.3246\n",
      "[7572/8000] D loss: 0.7914, G loss: 4.0062\n",
      "[7932/8000] D loss: 0.9672, G loss: 4.3576\n",
      "train error: \n",
      " D loss: 0.828715, G loss: 4.182681, D accuracy: 73.9%, cell accuracy: 98.7%, board accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.803746, G loss: 12.154689, D accuracy: 81.9%, cell accuracy: 98.2%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7006, G loss: 3.6847\n",
      "[372/8000] D loss: 0.7229, G loss: 8.1968\n",
      "[732/8000] D loss: 0.8852, G loss: 4.5424\n",
      "[1092/8000] D loss: 0.7561, G loss: 7.0418\n",
      "[1452/8000] D loss: 1.0183, G loss: 2.8130\n",
      "[1812/8000] D loss: 1.3366, G loss: 1.3849\n",
      "[2172/8000] D loss: 0.6816, G loss: 5.4477\n",
      "[2532/8000] D loss: 1.0200, G loss: 2.3290\n",
      "[2892/8000] D loss: 0.7363, G loss: 4.8411\n",
      "[3252/8000] D loss: 0.4546, G loss: 14.6783\n",
      "[3612/8000] D loss: 0.5856, G loss: 8.1383\n",
      "[3972/8000] D loss: 1.0420, G loss: 4.3053\n",
      "[4332/8000] D loss: 0.7234, G loss: 4.9675\n",
      "[4692/8000] D loss: 0.6265, G loss: 8.0556\n",
      "[5052/8000] D loss: 0.8567, G loss: 5.8043\n",
      "[5412/8000] D loss: 0.9930, G loss: 2.4621\n",
      "[5772/8000] D loss: 0.5333, G loss: 5.4260\n",
      "[6132/8000] D loss: 0.8891, G loss: 2.7347\n",
      "[6492/8000] D loss: 0.8525, G loss: 4.3252\n",
      "[6852/8000] D loss: 1.0787, G loss: 1.9076\n",
      "[7212/8000] D loss: 0.6061, G loss: 4.0901\n",
      "[7572/8000] D loss: 0.5340, G loss: 7.1562\n",
      "[7932/8000] D loss: 0.7557, G loss: 7.4876\n",
      "train error: \n",
      " D loss: 0.821336, G loss: 5.270833, D accuracy: 73.8%, cell accuracy: 98.7%, board accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.877993, G loss: 14.394103, D accuracy: 80.8%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7964, G loss: 2.4834\n",
      "[372/8000] D loss: 1.0445, G loss: 5.9032\n",
      "[732/8000] D loss: 1.0549, G loss: 4.3869\n",
      "[1092/8000] D loss: 0.5552, G loss: 7.9870\n",
      "[1452/8000] D loss: 1.0661, G loss: 1.5005\n",
      "[1812/8000] D loss: 1.0265, G loss: 3.7497\n",
      "[2172/8000] D loss: 0.9394, G loss: 2.4238\n",
      "[2532/8000] D loss: 0.6419, G loss: 7.2449\n",
      "[2892/8000] D loss: 0.9994, G loss: 3.5728\n",
      "[3252/8000] D loss: 0.8525, G loss: 4.9303\n",
      "[3612/8000] D loss: 1.0725, G loss: 2.3157\n",
      "[3972/8000] D loss: 0.7818, G loss: 3.6619\n",
      "[4332/8000] D loss: 0.8822, G loss: 3.2775\n",
      "[4692/8000] D loss: 0.9035, G loss: 4.2410\n",
      "[5052/8000] D loss: 0.5503, G loss: 8.9379\n",
      "[5412/8000] D loss: 0.9602, G loss: 4.1665\n",
      "[5772/8000] D loss: 0.5449, G loss: 7.9714\n",
      "[6132/8000] D loss: 0.7674, G loss: 5.0041\n",
      "[6492/8000] D loss: 0.8314, G loss: 4.5681\n",
      "[6852/8000] D loss: 0.9991, G loss: 3.3867\n",
      "[7212/8000] D loss: 0.9428, G loss: 2.4181\n",
      "[7572/8000] D loss: 0.5598, G loss: 3.0010\n",
      "[7932/8000] D loss: 0.9413, G loss: 5.1222\n",
      "train error: \n",
      " D loss: 0.829416, G loss: 5.692225, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.005516, G loss: 15.376082, D accuracy: 77.8%, cell accuracy: 98.2%, board accuracy: 26.1% \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2096, G loss: 1.5503\n",
      "[372/8000] D loss: 0.8312, G loss: 4.5635\n",
      "[732/8000] D loss: 1.0251, G loss: 2.5065\n",
      "[1092/8000] D loss: 0.9961, G loss: 2.5782\n",
      "[1452/8000] D loss: 1.0428, G loss: 3.0711\n",
      "[1812/8000] D loss: 1.1998, G loss: 3.3723\n",
      "[2172/8000] D loss: 0.5485, G loss: 11.7101\n",
      "[2532/8000] D loss: 0.8086, G loss: 8.2321\n",
      "[2892/8000] D loss: 1.0420, G loss: 1.4719\n",
      "[3252/8000] D loss: 0.7313, G loss: 5.8541\n",
      "[3612/8000] D loss: 0.9767, G loss: 5.7400\n",
      "[3972/8000] D loss: 1.2009, G loss: 1.4166\n",
      "[4332/8000] D loss: 0.6398, G loss: 4.0080\n",
      "[4692/8000] D loss: 0.8998, G loss: 12.0924\n",
      "[5052/8000] D loss: 0.4281, G loss: 5.8615\n",
      "[5412/8000] D loss: 1.0021, G loss: 1.9730\n",
      "[5772/8000] D loss: 0.8365, G loss: 4.8962\n",
      "[6132/8000] D loss: 1.0826, G loss: 3.0556\n",
      "[6492/8000] D loss: 0.8061, G loss: 5.4835\n",
      "[6852/8000] D loss: 0.5525, G loss: 5.3766\n",
      "[7212/8000] D loss: 0.7852, G loss: 6.3263\n",
      "[7572/8000] D loss: 0.4728, G loss: 5.5261\n",
      "[7932/8000] D loss: 0.6099, G loss: 7.4097\n",
      "train error: \n",
      " D loss: 0.826459, G loss: 5.409673, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 52.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.031859, G loss: 14.481311, D accuracy: 76.1%, cell accuracy: 98.2%, board accuracy: 25.3% \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6723, G loss: 6.1143\n",
      "[372/8000] D loss: 0.6567, G loss: 8.4428\n",
      "[732/8000] D loss: 0.6033, G loss: 7.8981\n",
      "[1092/8000] D loss: 0.9770, G loss: 3.7992\n",
      "[1452/8000] D loss: 0.9958, G loss: 2.2875\n",
      "[1812/8000] D loss: 0.8377, G loss: 6.6103\n",
      "[2172/8000] D loss: 0.7554, G loss: 4.4124\n",
      "[2532/8000] D loss: 0.8209, G loss: 7.0771\n",
      "[2892/8000] D loss: 0.9631, G loss: 1.7846\n",
      "[3252/8000] D loss: 0.6084, G loss: 5.7913\n",
      "[3612/8000] D loss: 0.6462, G loss: 6.4256\n",
      "[3972/8000] D loss: 0.7774, G loss: 5.0835\n",
      "[4332/8000] D loss: 0.3003, G loss: 10.8890\n",
      "[4692/8000] D loss: 0.8045, G loss: 5.5042\n",
      "[5052/8000] D loss: 0.8124, G loss: 3.5200\n",
      "[5412/8000] D loss: 0.8125, G loss: 4.6310\n",
      "[5772/8000] D loss: 0.7399, G loss: 7.4831\n",
      "[6132/8000] D loss: 0.6525, G loss: 8.6877\n",
      "[6492/8000] D loss: 0.8057, G loss: 4.3971\n",
      "[6852/8000] D loss: 0.8308, G loss: 4.5853\n",
      "[7212/8000] D loss: 0.6011, G loss: 4.1357\n",
      "[7572/8000] D loss: 0.7388, G loss: 6.1334\n",
      "[7932/8000] D loss: 0.9325, G loss: 2.8427\n",
      "train error: \n",
      " D loss: 0.812744, G loss: 5.275454, D accuracy: 73.9%, cell accuracy: 98.7%, board accuracy: 53.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.929157, G loss: 15.112100, D accuracy: 80.2%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4571, G loss: 8.4184\n",
      "[372/8000] D loss: 0.9945, G loss: 3.8951\n",
      "[732/8000] D loss: 0.9503, G loss: 4.3082\n",
      "[1092/8000] D loss: 0.9589, G loss: 2.5133\n",
      "[1452/8000] D loss: 1.1202, G loss: 3.4811\n",
      "[1812/8000] D loss: 0.9895, G loss: 2.3297\n",
      "[2172/8000] D loss: 0.8221, G loss: 3.6186\n",
      "[2532/8000] D loss: 0.8815, G loss: 5.6311\n",
      "[2892/8000] D loss: 0.9691, G loss: 2.1855\n",
      "[3252/8000] D loss: 0.8522, G loss: 4.7905\n",
      "[3612/8000] D loss: 0.5605, G loss: 5.0878\n",
      "[3972/8000] D loss: 0.7589, G loss: 5.1891\n",
      "[4332/8000] D loss: 0.5472, G loss: 6.7598\n",
      "[4692/8000] D loss: 0.8794, G loss: 4.6708\n",
      "[5052/8000] D loss: 0.9606, G loss: 4.1106\n",
      "[5412/8000] D loss: 0.9977, G loss: 2.2535\n",
      "[5772/8000] D loss: 0.6083, G loss: 4.5456\n",
      "[6132/8000] D loss: 0.5823, G loss: 10.3741\n",
      "[6492/8000] D loss: 0.9186, G loss: 4.8685\n",
      "[6852/8000] D loss: 1.0997, G loss: 2.2889\n",
      "[7212/8000] D loss: 0.7266, G loss: 3.1784\n",
      "[7572/8000] D loss: 1.4635, G loss: 3.0249\n",
      "[7932/8000] D loss: 0.9136, G loss: 2.1828\n",
      "train error: \n",
      " D loss: 0.810171, G loss: 5.254848, D accuracy: 74.8%, cell accuracy: 98.7%, board accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.818576, G loss: 14.831419, D accuracy: 80.9%, cell accuracy: 98.2%, board accuracy: 24.4% \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3364, G loss: 7.7804\n",
      "[372/8000] D loss: 0.6305, G loss: 5.7995\n",
      "[732/8000] D loss: 0.7451, G loss: 2.8336\n",
      "[1092/8000] D loss: 0.9750, G loss: 3.8928\n",
      "[1452/8000] D loss: 1.1234, G loss: 3.7127\n",
      "[1812/8000] D loss: 0.6947, G loss: 4.2052\n",
      "[2172/8000] D loss: 0.7920, G loss: 5.9870\n",
      "[2532/8000] D loss: 1.1988, G loss: 3.4422\n",
      "[2892/8000] D loss: 0.6691, G loss: 3.5806\n",
      "[3252/8000] D loss: 0.9832, G loss: 3.7844\n",
      "[3612/8000] D loss: 1.0032, G loss: 4.4657\n",
      "[3972/8000] D loss: 0.8685, G loss: 4.4278\n",
      "[4332/8000] D loss: 1.0451, G loss: 2.8460\n",
      "[4692/8000] D loss: 0.6376, G loss: 4.2941\n",
      "[5052/8000] D loss: 0.9177, G loss: 2.3357\n",
      "[5412/8000] D loss: 0.8035, G loss: 3.4508\n",
      "[5772/8000] D loss: 0.4720, G loss: 6.0033\n",
      "[6132/8000] D loss: 0.8069, G loss: 8.4020\n",
      "[6492/8000] D loss: 0.4760, G loss: 6.3958\n",
      "[6852/8000] D loss: 0.9278, G loss: 3.7395\n",
      "[7212/8000] D loss: 1.1644, G loss: 2.1982\n",
      "[7572/8000] D loss: 0.2977, G loss: 13.0587\n",
      "[7932/8000] D loss: 0.5773, G loss: 11.0415\n",
      "train error: \n",
      " D loss: 0.805528, G loss: 5.432483, D accuracy: 74.1%, cell accuracy: 98.7%, board accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.924438, G loss: 14.965881, D accuracy: 78.5%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8791, G loss: 3.7873\n",
      "[372/8000] D loss: 0.6036, G loss: 9.4872\n",
      "[732/8000] D loss: 0.6165, G loss: 9.5569\n",
      "[1092/8000] D loss: 0.7518, G loss: 3.3373\n",
      "[1452/8000] D loss: 0.5903, G loss: 7.7182\n",
      "[1812/8000] D loss: 0.8124, G loss: 4.0180\n",
      "[2172/8000] D loss: 0.8124, G loss: 2.7888\n",
      "[2532/8000] D loss: 0.8405, G loss: 5.4324\n",
      "[2892/8000] D loss: 0.7999, G loss: 4.1989\n",
      "[3252/8000] D loss: 0.8226, G loss: 3.6381\n",
      "[3612/8000] D loss: 0.7403, G loss: 2.5279\n",
      "[3972/8000] D loss: 1.1009, G loss: 3.5826\n",
      "[4332/8000] D loss: 1.0225, G loss: 2.1464\n",
      "[4692/8000] D loss: 0.9330, G loss: 5.1650\n",
      "[5052/8000] D loss: 0.6344, G loss: 5.0907\n",
      "[5412/8000] D loss: 0.8238, G loss: 4.0362\n",
      "[5772/8000] D loss: 0.8481, G loss: 6.6841\n",
      "[6132/8000] D loss: 0.8302, G loss: 4.6005\n",
      "[6492/8000] D loss: 0.6867, G loss: 6.3015\n",
      "[6852/8000] D loss: 0.6185, G loss: 5.5561\n",
      "[7212/8000] D loss: 0.9026, G loss: 4.7551\n",
      "[7572/8000] D loss: 0.6447, G loss: 3.6338\n",
      "[7932/8000] D loss: 0.7403, G loss: 2.6017\n",
      "train error: \n",
      " D loss: 0.826807, G loss: 5.531318, D accuracy: 73.5%, cell accuracy: 98.7%, board accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.003989, G loss: 14.910837, D accuracy: 76.9%, cell accuracy: 98.2%, board accuracy: 26.1% \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8577, G loss: 4.1478\n",
      "[372/8000] D loss: 0.6630, G loss: 6.0588\n",
      "[732/8000] D loss: 0.9428, G loss: 3.4053\n",
      "[1092/8000] D loss: 0.7669, G loss: 6.8423\n",
      "[1452/8000] D loss: 0.9833, G loss: 1.6198\n",
      "[1812/8000] D loss: 0.5922, G loss: 5.3126\n",
      "[2172/8000] D loss: 0.8395, G loss: 3.9102\n",
      "[2532/8000] D loss: 0.8309, G loss: 5.2921\n",
      "[2892/8000] D loss: 0.7132, G loss: 4.4963\n",
      "[3252/8000] D loss: 0.8038, G loss: 3.2297\n",
      "[3612/8000] D loss: 0.9546, G loss: 4.7595\n",
      "[3972/8000] D loss: 0.5641, G loss: 8.2666\n",
      "[4332/8000] D loss: 0.6640, G loss: 11.0492\n",
      "[4692/8000] D loss: 0.9595, G loss: 4.6542\n",
      "[5052/8000] D loss: 0.6355, G loss: 6.1134\n",
      "[5412/8000] D loss: 0.5758, G loss: 8.7501\n",
      "[5772/8000] D loss: 1.1623, G loss: 2.8112\n",
      "[6132/8000] D loss: 0.9915, G loss: 2.4005\n",
      "[6492/8000] D loss: 0.4683, G loss: 7.8727\n",
      "[6852/8000] D loss: 0.9461, G loss: 1.8921\n",
      "[7212/8000] D loss: 0.7514, G loss: 5.6223\n",
      "[7572/8000] D loss: 1.2656, G loss: 1.3177\n",
      "[7932/8000] D loss: 0.5982, G loss: 4.4630\n",
      "train error: \n",
      " D loss: 0.822417, G loss: 4.793285, D accuracy: 73.8%, cell accuracy: 98.7%, board accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.883025, G loss: 13.449803, D accuracy: 81.4%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9225, G loss: 4.0807\n",
      "[372/8000] D loss: 0.7770, G loss: 4.9928\n",
      "[732/8000] D loss: 0.7032, G loss: 8.6627\n",
      "[1092/8000] D loss: 0.5470, G loss: 6.1276\n",
      "[1452/8000] D loss: 0.8239, G loss: 6.3737\n",
      "[1812/8000] D loss: 0.3779, G loss: 8.4686\n",
      "[2172/8000] D loss: 0.3737, G loss: 13.6541\n",
      "[2532/8000] D loss: 0.9796, G loss: 3.6733\n",
      "[2892/8000] D loss: 0.8959, G loss: 6.6895\n",
      "[3252/8000] D loss: 0.7428, G loss: 4.3706\n",
      "[3612/8000] D loss: 0.7479, G loss: 8.2134\n",
      "[3972/8000] D loss: 0.8224, G loss: 7.8400\n",
      "[4332/8000] D loss: 0.9297, G loss: 7.3852\n",
      "[4692/8000] D loss: 0.9911, G loss: 5.4661\n",
      "[5052/8000] D loss: 0.6563, G loss: 5.1348\n",
      "[5412/8000] D loss: 0.8170, G loss: 7.6303\n",
      "[5772/8000] D loss: 0.7771, G loss: 7.5005\n",
      "[6132/8000] D loss: 1.1013, G loss: 4.6104\n",
      "[6492/8000] D loss: 0.2777, G loss: 5.2300\n",
      "[6852/8000] D loss: 0.8241, G loss: 4.5447\n",
      "[7212/8000] D loss: 0.8197, G loss: 4.1168\n",
      "[7572/8000] D loss: 0.7073, G loss: 8.8706\n",
      "[7932/8000] D loss: 0.7591, G loss: 5.4154\n",
      "train error: \n",
      " D loss: 0.845823, G loss: 5.434723, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 53.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.015568, G loss: 14.110077, D accuracy: 75.0%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9038, G loss: 3.9019\n",
      "[372/8000] D loss: 1.0756, G loss: 2.3765\n",
      "[732/8000] D loss: 0.9163, G loss: 6.2086\n",
      "[1092/8000] D loss: 0.7472, G loss: 7.9820\n",
      "[1452/8000] D loss: 0.8657, G loss: 5.9059\n",
      "[1812/8000] D loss: 0.9204, G loss: 4.1975\n",
      "[2172/8000] D loss: 0.7768, G loss: 6.2561\n",
      "[2532/8000] D loss: 0.7686, G loss: 9.6800\n",
      "[2892/8000] D loss: 1.1924, G loss: 4.3306\n",
      "[3252/8000] D loss: 0.5858, G loss: 7.1267\n",
      "[3612/8000] D loss: 0.9270, G loss: 5.2583\n",
      "[3972/8000] D loss: 0.7565, G loss: 3.3065\n",
      "[4332/8000] D loss: 0.7993, G loss: 8.9985\n",
      "[4692/8000] D loss: 1.0135, G loss: 4.8663\n",
      "[5052/8000] D loss: 0.9621, G loss: 2.4732\n",
      "[5412/8000] D loss: 1.2327, G loss: 1.3064\n",
      "[5772/8000] D loss: 0.6486, G loss: 7.1170\n",
      "[6132/8000] D loss: 0.9404, G loss: 5.5499\n",
      "[6492/8000] D loss: 0.8027, G loss: 3.6058\n",
      "[6852/8000] D loss: 0.5821, G loss: 10.7965\n",
      "[7212/8000] D loss: 0.5901, G loss: 4.0627\n",
      "[7572/8000] D loss: 0.7198, G loss: 5.1145\n",
      "[7932/8000] D loss: 1.1712, G loss: 3.4168\n",
      "train error: \n",
      " D loss: 0.807973, G loss: 5.840855, D accuracy: 74.3%, cell accuracy: 98.7%, board accuracy: 52.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.961425, G loss: 15.304821, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7573, G loss: 9.7098\n",
      "[372/8000] D loss: 0.7522, G loss: 3.3625\n",
      "[732/8000] D loss: 0.1032, G loss: 10.9156\n",
      "[1092/8000] D loss: 0.7032, G loss: 4.5007\n",
      "[1452/8000] D loss: 0.8698, G loss: 2.4966\n",
      "[1812/8000] D loss: 0.9491, G loss: 4.2479\n",
      "[2172/8000] D loss: 0.8894, G loss: 5.4780\n",
      "[2532/8000] D loss: 0.8339, G loss: 4.7955\n",
      "[2892/8000] D loss: 0.7684, G loss: 5.8583\n",
      "[3252/8000] D loss: 0.9509, G loss: 3.9179\n",
      "[3612/8000] D loss: 0.6889, G loss: 6.0548\n",
      "[3972/8000] D loss: 1.1659, G loss: 3.1108\n",
      "[4332/8000] D loss: 1.0625, G loss: 3.1703\n",
      "[4692/8000] D loss: 0.9554, G loss: 2.8864\n",
      "[5052/8000] D loss: 0.8136, G loss: 2.2436\n",
      "[5412/8000] D loss: 1.0020, G loss: 2.1446\n",
      "[5772/8000] D loss: 0.6295, G loss: 5.1790\n",
      "[6132/8000] D loss: 0.5293, G loss: 5.5938\n",
      "[6492/8000] D loss: 0.6865, G loss: 15.5987\n",
      "[6852/8000] D loss: 0.7880, G loss: 4.8401\n",
      "[7212/8000] D loss: 0.6111, G loss: 8.2797\n",
      "[7572/8000] D loss: 0.7069, G loss: 5.5077\n",
      "[7932/8000] D loss: 0.9116, G loss: 2.6974\n",
      "train error: \n",
      " D loss: 0.812212, G loss: 5.257999, D accuracy: 74.3%, cell accuracy: 98.7%, board accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.947600, G loss: 13.946143, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 26.1% \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7595, G loss: 6.6116\n",
      "[372/8000] D loss: 0.7642, G loss: 6.2644\n",
      "[732/8000] D loss: 0.7052, G loss: 5.5602\n",
      "[1092/8000] D loss: 0.8129, G loss: 2.6829\n",
      "[1452/8000] D loss: 0.5186, G loss: 5.9160\n",
      "[1812/8000] D loss: 0.6854, G loss: 4.3714\n",
      "[2172/8000] D loss: 0.5041, G loss: 5.7061\n",
      "[2532/8000] D loss: 0.6908, G loss: 6.5144\n",
      "[2892/8000] D loss: 0.5781, G loss: 8.9903\n",
      "[3252/8000] D loss: 0.9472, G loss: 2.5263\n",
      "[3612/8000] D loss: 0.9717, G loss: 7.2082\n",
      "[3972/8000] D loss: 0.5437, G loss: 8.2502\n",
      "[4332/8000] D loss: 0.8214, G loss: 3.8666\n",
      "[4692/8000] D loss: 0.9665, G loss: 5.6705\n",
      "[5052/8000] D loss: 1.2769, G loss: 4.3770\n",
      "[5412/8000] D loss: 0.8214, G loss: 7.0239\n",
      "[5772/8000] D loss: 0.5718, G loss: 7.2664\n",
      "[6132/8000] D loss: 0.3646, G loss: 6.9567\n",
      "[6492/8000] D loss: 0.9384, G loss: 3.8834\n",
      "[6852/8000] D loss: 0.9745, G loss: 2.4102\n",
      "[7212/8000] D loss: 0.6245, G loss: 7.8192\n",
      "[7572/8000] D loss: 1.0156, G loss: 3.6818\n",
      "[7932/8000] D loss: 0.9048, G loss: 5.2069\n",
      "train error: \n",
      " D loss: 0.833730, G loss: 5.507264, D accuracy: 73.8%, cell accuracy: 98.7%, board accuracy: 52.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.922334, G loss: 14.977144, D accuracy: 80.8%, cell accuracy: 98.2%, board accuracy: 26.1% \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8686, G loss: 4.7172\n",
      "[372/8000] D loss: 0.6309, G loss: 7.7943\n",
      "[732/8000] D loss: 0.6428, G loss: 3.4870\n",
      "[1092/8000] D loss: 0.5347, G loss: 5.9964\n",
      "[1452/8000] D loss: 0.6843, G loss: 6.3360\n",
      "[1812/8000] D loss: 0.9537, G loss: 1.5875\n",
      "[2172/8000] D loss: 0.3829, G loss: 9.8296\n",
      "[2532/8000] D loss: 0.7745, G loss: 7.1914\n",
      "[2892/8000] D loss: 0.4726, G loss: 7.4430\n",
      "[3252/8000] D loss: 1.0169, G loss: 2.8042\n",
      "[3612/8000] D loss: 0.8656, G loss: 2.2919\n",
      "[3972/8000] D loss: 0.6872, G loss: 9.7977\n",
      "[4332/8000] D loss: 0.8387, G loss: 4.7521\n",
      "[4692/8000] D loss: 0.6913, G loss: 7.9795\n",
      "[5052/8000] D loss: 0.8311, G loss: 4.9776\n",
      "[5412/8000] D loss: 1.1314, G loss: 3.0422\n",
      "[5772/8000] D loss: 0.8763, G loss: 1.7883\n",
      "[6132/8000] D loss: 0.8503, G loss: 9.6621\n",
      "[6492/8000] D loss: 1.0854, G loss: 4.4158\n",
      "[6852/8000] D loss: 0.9955, G loss: 5.8457\n",
      "[7212/8000] D loss: 0.8458, G loss: 2.7816\n",
      "[7572/8000] D loss: 0.9442, G loss: 4.2699\n",
      "[7932/8000] D loss: 0.8429, G loss: 4.0415\n",
      "train error: \n",
      " D loss: 0.815201, G loss: 5.331669, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 53.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.879498, G loss: 14.431747, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0735, G loss: 3.3085\n",
      "[372/8000] D loss: 0.5033, G loss: 7.7186\n",
      "[732/8000] D loss: 0.8892, G loss: 5.9063\n",
      "[1092/8000] D loss: 0.6646, G loss: 4.3471\n",
      "[1452/8000] D loss: 0.7069, G loss: 3.6767\n",
      "[1812/8000] D loss: 1.0739, G loss: 5.8079\n",
      "[2172/8000] D loss: 0.8556, G loss: 6.6942\n",
      "[2532/8000] D loss: 0.9612, G loss: 5.7785\n",
      "[2892/8000] D loss: 0.7692, G loss: 5.0435\n",
      "[3252/8000] D loss: 0.5674, G loss: 6.8730\n",
      "[3612/8000] D loss: 0.8307, G loss: 6.0919\n",
      "[3972/8000] D loss: 0.9515, G loss: 8.5351\n",
      "[4332/8000] D loss: 0.8576, G loss: 4.1610\n",
      "[4692/8000] D loss: 0.6932, G loss: 6.0358\n",
      "[5052/8000] D loss: 0.9250, G loss: 5.7580\n",
      "[5412/8000] D loss: 0.9050, G loss: 3.4332\n",
      "[5772/8000] D loss: 1.0087, G loss: 4.3260\n",
      "[6132/8000] D loss: 0.6905, G loss: 7.0584\n",
      "[6492/8000] D loss: 1.1229, G loss: 2.5248\n",
      "[6852/8000] D loss: 0.7905, G loss: 4.7501\n",
      "[7212/8000] D loss: 1.0429, G loss: 5.2406\n",
      "[7572/8000] D loss: 0.8318, G loss: 5.6528\n",
      "[7932/8000] D loss: 0.9619, G loss: 7.3072\n",
      "train error: \n",
      " D loss: 0.826100, G loss: 5.390035, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 53.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.055981, G loss: 13.917865, D accuracy: 77.1%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8083, G loss: 3.1035\n",
      "[372/8000] D loss: 0.6819, G loss: 11.8526\n",
      "[732/8000] D loss: 0.8444, G loss: 4.3396\n",
      "[1092/8000] D loss: 0.7043, G loss: 5.8339\n",
      "[1452/8000] D loss: 0.9151, G loss: 6.0209\n",
      "[1812/8000] D loss: 0.9593, G loss: 1.9297\n",
      "[2172/8000] D loss: 0.7560, G loss: 5.7421\n",
      "[2532/8000] D loss: 1.0236, G loss: 2.5610\n",
      "[2892/8000] D loss: 0.5380, G loss: 10.1083\n",
      "[3252/8000] D loss: 0.4956, G loss: 13.2323\n",
      "[3612/8000] D loss: 0.7486, G loss: 5.3085\n",
      "[3972/8000] D loss: 0.9730, G loss: 4.5955\n",
      "[4332/8000] D loss: 1.1549, G loss: 3.3333\n",
      "[4692/8000] D loss: 0.9623, G loss: 5.2626\n",
      "[5052/8000] D loss: 0.7324, G loss: 9.2641\n",
      "[5412/8000] D loss: 0.7410, G loss: 8.5818\n",
      "[5772/8000] D loss: 0.0458, G loss: 9.6790\n",
      "[6132/8000] D loss: 0.7941, G loss: 6.1952\n",
      "[6492/8000] D loss: 0.7528, G loss: 5.1966\n",
      "[6852/8000] D loss: 0.5946, G loss: 5.8484\n",
      "[7212/8000] D loss: 0.6057, G loss: 5.5715\n",
      "[7572/8000] D loss: 0.7636, G loss: 2.8496\n",
      "[7932/8000] D loss: 0.6266, G loss: 5.5829\n",
      "train error: \n",
      " D loss: 0.822431, G loss: 4.721447, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.918612, G loss: 13.435407, D accuracy: 80.1%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9952, G loss: 3.0903\n",
      "[372/8000] D loss: 0.1623, G loss: 11.3822\n",
      "[732/8000] D loss: 0.7939, G loss: 5.8250\n",
      "[1092/8000] D loss: 0.8791, G loss: 5.2175\n",
      "[1452/8000] D loss: 0.9779, G loss: 2.4622\n",
      "[1812/8000] D loss: 0.7962, G loss: 4.5498\n",
      "[2172/8000] D loss: 0.8231, G loss: 7.7475\n",
      "[2532/8000] D loss: 0.5238, G loss: 9.4255\n",
      "[2892/8000] D loss: 0.9284, G loss: 3.2980\n",
      "[3252/8000] D loss: 0.9352, G loss: 6.1519\n",
      "[3612/8000] D loss: 0.6648, G loss: 8.5446\n",
      "[3972/8000] D loss: 0.6754, G loss: 3.2176\n",
      "[4332/8000] D loss: 1.1891, G loss: 3.0366\n",
      "[4692/8000] D loss: 1.1169, G loss: 1.6299\n",
      "[5052/8000] D loss: 0.5533, G loss: 8.5767\n",
      "[5412/8000] D loss: 0.8840, G loss: 5.1341\n",
      "[5772/8000] D loss: 0.8327, G loss: 6.0145\n",
      "[6132/8000] D loss: 0.5002, G loss: 7.5858\n",
      "[6492/8000] D loss: 0.4930, G loss: 12.1967\n",
      "[6852/8000] D loss: 1.2469, G loss: 3.4343\n",
      "[7212/8000] D loss: 0.8331, G loss: 3.9355\n",
      "[7572/8000] D loss: 0.3040, G loss: 12.0534\n",
      "[7932/8000] D loss: 0.7697, G loss: 4.7733\n",
      "train error: \n",
      " D loss: 0.848865, G loss: 6.238086, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 53.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.174182, G loss: 16.223215, D accuracy: 75.4%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9936, G loss: 3.1506\n",
      "[372/8000] D loss: 0.8113, G loss: 5.7773\n",
      "[732/8000] D loss: 1.0084, G loss: 3.1610\n",
      "[1092/8000] D loss: 1.0809, G loss: 5.4689\n",
      "[1452/8000] D loss: 0.6025, G loss: 11.6470\n",
      "[1812/8000] D loss: 0.3048, G loss: 5.0171\n",
      "[2172/8000] D loss: 0.4918, G loss: 8.4202\n",
      "[2532/8000] D loss: 0.9536, G loss: 3.0076\n",
      "[2892/8000] D loss: 1.1090, G loss: 2.1219\n",
      "[3252/8000] D loss: 0.5360, G loss: 7.9689\n",
      "[3612/8000] D loss: 1.0653, G loss: 1.5577\n",
      "[3972/8000] D loss: 0.7961, G loss: 5.9575\n",
      "[4332/8000] D loss: 0.3700, G loss: 8.7070\n",
      "[4692/8000] D loss: 0.7776, G loss: 11.2767\n",
      "[5052/8000] D loss: 0.6916, G loss: 4.7235\n",
      "[5412/8000] D loss: 0.5741, G loss: 8.5057\n",
      "[5772/8000] D loss: 1.0102, G loss: 1.7780\n",
      "[6132/8000] D loss: 0.9881, G loss: 1.7611\n",
      "[6492/8000] D loss: 1.0809, G loss: 3.1632\n",
      "[6852/8000] D loss: 0.9765, G loss: 3.8704\n",
      "[7212/8000] D loss: 0.7125, G loss: 4.0537\n",
      "[7572/8000] D loss: 0.4139, G loss: 11.7497\n",
      "[7932/8000] D loss: 0.6892, G loss: 4.2389\n",
      "train error: \n",
      " D loss: 0.806294, G loss: 5.685929, D accuracy: 74.3%, cell accuracy: 98.7%, board accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.937943, G loss: 15.226025, D accuracy: 79.5%, cell accuracy: 98.2%, board accuracy: 24.9% \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6002, G loss: 9.8734\n",
      "[372/8000] D loss: 0.8173, G loss: 3.0804\n",
      "[732/8000] D loss: 0.9386, G loss: 2.7436\n",
      "[1092/8000] D loss: 0.9529, G loss: 6.7889\n",
      "[1452/8000] D loss: 0.6392, G loss: 7.4105\n",
      "[1812/8000] D loss: 0.5996, G loss: 7.8224\n",
      "[2172/8000] D loss: 0.9420, G loss: 2.1696\n",
      "[2532/8000] D loss: 1.1276, G loss: 2.2088\n",
      "[2892/8000] D loss: 0.7303, G loss: 6.0347\n",
      "[3252/8000] D loss: 1.3470, G loss: 0.7810\n",
      "[3612/8000] D loss: 0.7254, G loss: 4.3262\n",
      "[3972/8000] D loss: 1.0320, G loss: 2.4584\n",
      "[4332/8000] D loss: 0.6247, G loss: 7.9710\n",
      "[4692/8000] D loss: 0.8050, G loss: 8.8425\n",
      "[5052/8000] D loss: 0.9382, G loss: 5.2049\n",
      "[5412/8000] D loss: 0.7886, G loss: 3.2420\n",
      "[5772/8000] D loss: 0.9377, G loss: 3.7121\n",
      "[6132/8000] D loss: 0.9568, G loss: 4.7507\n",
      "[6492/8000] D loss: 0.7925, G loss: 6.1461\n",
      "[6852/8000] D loss: 0.6918, G loss: 10.7822\n",
      "[7212/8000] D loss: 0.6194, G loss: 4.8524\n",
      "[7572/8000] D loss: 0.7251, G loss: 4.8866\n",
      "[7932/8000] D loss: 0.4447, G loss: 7.0551\n",
      "train error: \n",
      " D loss: 0.827746, G loss: 6.450234, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.067722, G loss: 16.198009, D accuracy: 75.4%, cell accuracy: 98.2%, board accuracy: 25.3% \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5382, G loss: 8.3227\n",
      "[372/8000] D loss: 0.5615, G loss: 6.5765\n",
      "[732/8000] D loss: 0.9035, G loss: 5.1311\n",
      "[1092/8000] D loss: 0.7533, G loss: 4.0629\n",
      "[1452/8000] D loss: 0.6620, G loss: 5.1543\n",
      "[1812/8000] D loss: 1.0422, G loss: 3.8429\n",
      "[2172/8000] D loss: 0.6696, G loss: 3.3054\n",
      "[2532/8000] D loss: 0.8292, G loss: 6.9815\n",
      "[2892/8000] D loss: 0.9547, G loss: 5.5267\n",
      "[3252/8000] D loss: 0.9139, G loss: 6.4535\n",
      "[3612/8000] D loss: 1.0352, G loss: 2.0763\n",
      "[3972/8000] D loss: 0.8621, G loss: 4.3493\n",
      "[4332/8000] D loss: 0.6083, G loss: 7.5882\n",
      "[4692/8000] D loss: 0.8851, G loss: 2.9050\n",
      "[5052/8000] D loss: 0.9292, G loss: 6.7739\n",
      "[5412/8000] D loss: 0.4639, G loss: 10.9658\n",
      "[5772/8000] D loss: 0.6174, G loss: 2.9559\n",
      "[6132/8000] D loss: 0.8664, G loss: 6.8645\n",
      "[6492/8000] D loss: 0.9251, G loss: 2.6998\n",
      "[6852/8000] D loss: 0.3978, G loss: 6.3925\n",
      "[7212/8000] D loss: 0.7870, G loss: 3.8828\n",
      "[7572/8000] D loss: 0.5576, G loss: 8.2178\n",
      "[7932/8000] D loss: 0.9793, G loss: 6.4122\n",
      "train error: \n",
      " D loss: 0.818123, G loss: 5.522927, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 52.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.987668, G loss: 14.896605, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 25.5% \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6404, G loss: 6.6679\n",
      "[372/8000] D loss: 0.4316, G loss: 9.1558\n",
      "[732/8000] D loss: 0.5391, G loss: 12.1034\n",
      "[1092/8000] D loss: 1.2238, G loss: 1.4455\n",
      "[1452/8000] D loss: 0.6827, G loss: 4.6541\n",
      "[1812/8000] D loss: 0.9492, G loss: 7.5249\n",
      "[2172/8000] D loss: 0.9199, G loss: 4.9891\n",
      "[2532/8000] D loss: 0.7573, G loss: 4.6816\n",
      "[2892/8000] D loss: 0.6692, G loss: 5.5404\n",
      "[3252/8000] D loss: 1.0551, G loss: 2.9223\n",
      "[3612/8000] D loss: 0.4657, G loss: 6.3633\n",
      "[3972/8000] D loss: 1.0001, G loss: 2.8296\n",
      "[4332/8000] D loss: 0.6431, G loss: 10.0021\n",
      "[4692/8000] D loss: 0.6680, G loss: 7.3628\n",
      "[5052/8000] D loss: 0.5974, G loss: 9.3690\n",
      "[5412/8000] D loss: 0.8248, G loss: 3.7832\n",
      "[5772/8000] D loss: 0.8337, G loss: 7.7084\n",
      "[6132/8000] D loss: 1.0039, G loss: 2.7334\n",
      "[6492/8000] D loss: 0.5289, G loss: 7.7190\n",
      "[6852/8000] D loss: 0.7213, G loss: 3.4435\n",
      "[7212/8000] D loss: 0.7227, G loss: 5.0143\n",
      "[7572/8000] D loss: 0.9430, G loss: 5.3757\n",
      "[7932/8000] D loss: 1.1872, G loss: 1.8349\n",
      "train error: \n",
      " D loss: 0.815095, G loss: 5.500689, D accuracy: 74.2%, cell accuracy: 98.7%, board accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.907892, G loss: 14.947944, D accuracy: 80.2%, cell accuracy: 98.2%, board accuracy: 25.6% \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7812, G loss: 5.5182\n",
      "[372/8000] D loss: 0.6448, G loss: 6.5301\n",
      "[732/8000] D loss: 0.7976, G loss: 3.4601\n",
      "[1092/8000] D loss: 0.8176, G loss: 6.3149\n",
      "[1452/8000] D loss: 0.8651, G loss: 2.9257\n",
      "[1812/8000] D loss: 0.9171, G loss: 2.9533\n",
      "[2172/8000] D loss: 0.6811, G loss: 5.3355\n",
      "[2532/8000] D loss: 1.2233, G loss: 2.2599\n",
      "[2892/8000] D loss: 0.6648, G loss: 8.4855\n",
      "[3252/8000] D loss: 0.4613, G loss: 8.9651\n",
      "[3612/8000] D loss: 0.9954, G loss: 4.2019\n",
      "[3972/8000] D loss: 0.5555, G loss: 4.8065\n",
      "[4332/8000] D loss: 0.6430, G loss: 4.4758\n",
      "[4692/8000] D loss: 0.5583, G loss: 5.9895\n",
      "[5052/8000] D loss: 0.9293, G loss: 3.4336\n",
      "[5412/8000] D loss: 0.8998, G loss: 6.1886\n",
      "[5772/8000] D loss: 0.7728, G loss: 4.2076\n",
      "[6132/8000] D loss: 0.7964, G loss: 5.4056\n",
      "[6492/8000] D loss: 0.9109, G loss: 4.7745\n",
      "[6852/8000] D loss: 0.7386, G loss: 7.5748\n",
      "[7212/8000] D loss: 0.8472, G loss: 3.8017\n",
      "[7572/8000] D loss: 0.3966, G loss: 10.0768\n",
      "[7932/8000] D loss: 0.5226, G loss: 8.9511\n",
      "train error: \n",
      " D loss: 0.830148, G loss: 4.965046, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 53.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.015636, G loss: 13.534752, D accuracy: 77.7%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9186, G loss: 2.7938\n",
      "[372/8000] D loss: 0.7304, G loss: 6.1148\n",
      "[732/8000] D loss: 0.7127, G loss: 7.2112\n",
      "[1092/8000] D loss: 1.0188, G loss: 2.7138\n",
      "[1452/8000] D loss: 0.6104, G loss: 5.1701\n",
      "[1812/8000] D loss: 1.0588, G loss: 4.6021\n",
      "[2172/8000] D loss: 1.5252, G loss: 3.3618\n",
      "[2532/8000] D loss: 0.8271, G loss: 4.4942\n",
      "[2892/8000] D loss: 0.9792, G loss: 9.0594\n",
      "[3252/8000] D loss: 0.6335, G loss: 4.2966\n",
      "[3612/8000] D loss: 0.9079, G loss: 5.1459\n",
      "[3972/8000] D loss: 1.3268, G loss: 0.8641\n",
      "[4332/8000] D loss: 0.5799, G loss: 4.9601\n",
      "[4692/8000] D loss: 1.0158, G loss: 3.6741\n",
      "[5052/8000] D loss: 0.8946, G loss: 4.2729\n",
      "[5412/8000] D loss: 1.0048, G loss: 4.1894\n",
      "[5772/8000] D loss: 0.5590, G loss: 5.8902\n",
      "[6132/8000] D loss: 0.5409, G loss: 10.7684\n",
      "[6492/8000] D loss: 0.5419, G loss: 7.5294\n",
      "[6852/8000] D loss: 1.0530, G loss: 1.6168\n",
      "[7212/8000] D loss: 0.8481, G loss: 10.5310\n",
      "[7572/8000] D loss: 0.9734, G loss: 2.4525\n",
      "[7932/8000] D loss: 0.7340, G loss: 4.7553\n",
      "train error: \n",
      " D loss: 0.815913, G loss: 5.501296, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 53.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.995651, G loss: 14.807977, D accuracy: 77.1%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6549, G loss: 8.2805\n",
      "[372/8000] D loss: 0.6607, G loss: 8.9003\n",
      "[732/8000] D loss: 0.9574, G loss: 4.3621\n",
      "[1092/8000] D loss: 1.0681, G loss: 3.4572\n",
      "[1452/8000] D loss: 0.6145, G loss: 7.2795\n",
      "[1812/8000] D loss: 0.7958, G loss: 7.6308\n",
      "[2172/8000] D loss: 0.6690, G loss: 8.7232\n",
      "[2532/8000] D loss: 0.6066, G loss: 6.1842\n",
      "[2892/8000] D loss: 0.6205, G loss: 9.6747\n",
      "[3252/8000] D loss: 0.6603, G loss: 7.4253\n",
      "[3612/8000] D loss: 0.6170, G loss: 7.1914\n",
      "[3972/8000] D loss: 0.7494, G loss: 3.6601\n",
      "[4332/8000] D loss: 0.5293, G loss: 5.6137\n",
      "[4692/8000] D loss: 0.6843, G loss: 11.9234\n",
      "[5052/8000] D loss: 0.7478, G loss: 7.4021\n",
      "[5412/8000] D loss: 1.0549, G loss: 3.1641\n",
      "[5772/8000] D loss: 0.6035, G loss: 8.3299\n",
      "[6132/8000] D loss: 0.6056, G loss: 4.2481\n",
      "[6492/8000] D loss: 0.5231, G loss: 6.3581\n",
      "[6852/8000] D loss: 0.7513, G loss: 6.8517\n",
      "[7212/8000] D loss: 1.0306, G loss: 8.1967\n",
      "[7572/8000] D loss: 0.6818, G loss: 8.1704\n",
      "[7932/8000] D loss: 0.6074, G loss: 11.2917\n",
      "train error: \n",
      " D loss: 0.838816, G loss: 5.063204, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.897235, G loss: 14.359255, D accuracy: 80.8%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8319, G loss: 5.0180\n",
      "[372/8000] D loss: 1.0521, G loss: 4.0577\n",
      "[732/8000] D loss: 0.8785, G loss: 5.0395\n",
      "[1092/8000] D loss: 1.1658, G loss: 4.1629\n",
      "[1452/8000] D loss: 0.3837, G loss: 11.1158\n",
      "[1812/8000] D loss: 0.8175, G loss: 2.6655\n",
      "[2172/8000] D loss: 0.4759, G loss: 6.9298\n",
      "[2532/8000] D loss: 0.9298, G loss: 6.8290\n",
      "[2892/8000] D loss: 0.9272, G loss: 4.5785\n",
      "[3252/8000] D loss: 1.2458, G loss: 4.3656\n",
      "[3612/8000] D loss: 0.7684, G loss: 8.9561\n",
      "[3972/8000] D loss: 0.6843, G loss: 6.2958\n",
      "[4332/8000] D loss: 1.0033, G loss: 3.5489\n",
      "[4692/8000] D loss: 0.5021, G loss: 11.6100\n",
      "[5052/8000] D loss: 0.9287, G loss: 2.3692\n",
      "[5412/8000] D loss: 0.9173, G loss: 3.7025\n",
      "[5772/8000] D loss: 0.9717, G loss: 5.7196\n",
      "[6132/8000] D loss: 0.8256, G loss: 3.1885\n",
      "[6492/8000] D loss: 0.9149, G loss: 2.8557\n",
      "[6852/8000] D loss: 0.9132, G loss: 3.7090\n",
      "[7212/8000] D loss: 1.0695, G loss: 2.5753\n",
      "[7572/8000] D loss: 0.8736, G loss: 4.9290\n",
      "[7932/8000] D loss: 0.6035, G loss: 7.2053\n",
      "train error: \n",
      " D loss: 0.822803, G loss: 5.125258, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 54.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.952244, G loss: 13.670821, D accuracy: 77.1%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4787, G loss: 7.9665\n",
      "[372/8000] D loss: 0.7190, G loss: 5.3122\n",
      "[732/8000] D loss: 0.7271, G loss: 9.8267\n",
      "[1092/8000] D loss: 0.9686, G loss: 2.5051\n",
      "[1452/8000] D loss: 0.9168, G loss: 3.7156\n",
      "[1812/8000] D loss: 0.7013, G loss: 8.6882\n",
      "[2172/8000] D loss: 0.6704, G loss: 5.3076\n",
      "[2532/8000] D loss: 1.0054, G loss: 3.8193\n",
      "[2892/8000] D loss: 0.8164, G loss: 7.3076\n",
      "[3252/8000] D loss: 0.5683, G loss: 5.6997\n",
      "[3612/8000] D loss: 1.1427, G loss: 1.8589\n",
      "[3972/8000] D loss: 0.4029, G loss: 8.4319\n",
      "[4332/8000] D loss: 0.9863, G loss: 1.4078\n",
      "[4692/8000] D loss: 0.3993, G loss: 4.8525\n",
      "[5052/8000] D loss: 0.5854, G loss: 6.7174\n",
      "[5412/8000] D loss: 0.9692, G loss: 4.4009\n",
      "[5772/8000] D loss: 0.6996, G loss: 5.3770\n",
      "[6132/8000] D loss: 0.9237, G loss: 2.4383\n",
      "[6492/8000] D loss: 0.7300, G loss: 5.4290\n",
      "[6852/8000] D loss: 1.1001, G loss: 2.2231\n",
      "[7212/8000] D loss: 0.7238, G loss: 3.8017\n",
      "[7572/8000] D loss: 0.4964, G loss: 12.2220\n",
      "[7932/8000] D loss: 1.1152, G loss: 1.6441\n",
      "train error: \n",
      " D loss: 0.822506, G loss: 5.271901, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 53.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.870142, G loss: 14.414986, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4666, G loss: 14.1391\n",
      "[372/8000] D loss: 1.0962, G loss: 5.0322\n",
      "[732/8000] D loss: 0.4860, G loss: 15.6266\n",
      "[1092/8000] D loss: 0.6420, G loss: 3.2551\n",
      "[1452/8000] D loss: 0.8266, G loss: 3.5980\n",
      "[1812/8000] D loss: 0.8444, G loss: 4.2252\n",
      "[2172/8000] D loss: 1.0134, G loss: 2.6813\n",
      "[2532/8000] D loss: 1.0541, G loss: 3.5825\n",
      "[2892/8000] D loss: 0.6418, G loss: 5.6016\n",
      "[3252/8000] D loss: 0.7931, G loss: 8.6160\n",
      "[3612/8000] D loss: 0.8011, G loss: 6.8345\n",
      "[3972/8000] D loss: 0.5670, G loss: 6.7507\n",
      "[4332/8000] D loss: 0.9734, G loss: 2.8506\n",
      "[4692/8000] D loss: 0.7202, G loss: 4.0580\n",
      "[5052/8000] D loss: 0.7986, G loss: 10.2381\n",
      "[5412/8000] D loss: 0.9008, G loss: 4.1988\n",
      "[5772/8000] D loss: 0.8849, G loss: 3.3010\n",
      "[6132/8000] D loss: 0.7438, G loss: 6.2599\n",
      "[6492/8000] D loss: 0.9135, G loss: 2.1098\n",
      "[6852/8000] D loss: 1.0187, G loss: 5.2695\n",
      "[7212/8000] D loss: 0.8059, G loss: 3.8582\n",
      "[7572/8000] D loss: 0.8953, G loss: 6.8553\n",
      "[7932/8000] D loss: 0.8040, G loss: 3.3083\n",
      "train error: \n",
      " D loss: 0.837079, G loss: 4.710155, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 53.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.025857, G loss: 13.616025, D accuracy: 77.1%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4147, G loss: 7.8379\n",
      "[372/8000] D loss: 0.9212, G loss: 6.8813\n",
      "[732/8000] D loss: 0.8791, G loss: 5.4231\n",
      "[1092/8000] D loss: 0.8587, G loss: 6.7306\n",
      "[1452/8000] D loss: 0.4908, G loss: 9.6664\n",
      "[1812/8000] D loss: 0.7356, G loss: 8.5249\n",
      "[2172/8000] D loss: 0.8970, G loss: 3.4169\n",
      "[2532/8000] D loss: 0.9508, G loss: 3.0895\n",
      "[2892/8000] D loss: 0.9710, G loss: 3.6941\n",
      "[3252/8000] D loss: 0.7749, G loss: 7.9149\n",
      "[3612/8000] D loss: 1.0817, G loss: 2.3277\n",
      "[3972/8000] D loss: 0.6929, G loss: 3.3367\n",
      "[4332/8000] D loss: 0.6892, G loss: 9.6010\n",
      "[4692/8000] D loss: 1.0302, G loss: 3.0855\n",
      "[5052/8000] D loss: 0.7296, G loss: 3.7929\n",
      "[5412/8000] D loss: 0.8113, G loss: 5.0913\n",
      "[5772/8000] D loss: 1.0734, G loss: 6.1512\n",
      "[6132/8000] D loss: 0.5141, G loss: 5.1669\n",
      "[6492/8000] D loss: 0.7323, G loss: 10.0426\n",
      "[6852/8000] D loss: 1.1226, G loss: 1.5583\n",
      "[7212/8000] D loss: 0.7607, G loss: 5.6584\n",
      "[7572/8000] D loss: 0.6929, G loss: 7.2336\n",
      "[7932/8000] D loss: 0.7265, G loss: 3.2216\n",
      "train error: \n",
      " D loss: 0.823369, G loss: 5.328061, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.944317, G loss: 14.266828, D accuracy: 78.3%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6039, G loss: 8.1676\n",
      "[372/8000] D loss: 0.9125, G loss: 2.6961\n",
      "[732/8000] D loss: 0.8621, G loss: 5.3956\n",
      "[1092/8000] D loss: 1.1651, G loss: 3.6341\n",
      "[1452/8000] D loss: 0.6903, G loss: 5.1446\n",
      "[1812/8000] D loss: 0.5914, G loss: 4.1215\n",
      "[2172/8000] D loss: 0.8083, G loss: 4.7073\n",
      "[2532/8000] D loss: 0.3494, G loss: 7.6327\n",
      "[2892/8000] D loss: 0.8427, G loss: 3.8152\n",
      "[3252/8000] D loss: 1.0447, G loss: 4.8368\n",
      "[3612/8000] D loss: 0.9026, G loss: 2.2915\n",
      "[3972/8000] D loss: 0.7989, G loss: 7.0865\n",
      "[4332/8000] D loss: 0.8896, G loss: 4.8714\n",
      "[4692/8000] D loss: 0.5866, G loss: 6.1403\n",
      "[5052/8000] D loss: 0.8497, G loss: 4.1658\n",
      "[5412/8000] D loss: 0.5231, G loss: 8.0638\n",
      "[5772/8000] D loss: 0.6917, G loss: 4.1036\n",
      "[6132/8000] D loss: 0.5955, G loss: 11.5305\n",
      "[6492/8000] D loss: 0.6336, G loss: 8.4081\n",
      "[6852/8000] D loss: 0.4994, G loss: 5.2121\n",
      "[7212/8000] D loss: 0.9411, G loss: 2.4450\n",
      "[7572/8000] D loss: 0.9682, G loss: 4.7129\n",
      "[7932/8000] D loss: 0.8713, G loss: 4.2116\n",
      "train error: \n",
      " D loss: 0.808776, G loss: 5.645833, D accuracy: 74.1%, cell accuracy: 98.7%, board accuracy: 53.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.978252, G loss: 15.235983, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5854, G loss: 8.3918\n",
      "[372/8000] D loss: 0.9318, G loss: 2.5274\n",
      "[732/8000] D loss: 0.9652, G loss: 8.2636\n",
      "[1092/8000] D loss: 0.4773, G loss: 5.0967\n",
      "[1452/8000] D loss: 0.6586, G loss: 6.7534\n",
      "[1812/8000] D loss: 1.0017, G loss: 2.8840\n",
      "[2172/8000] D loss: 0.8101, G loss: 5.7547\n",
      "[2532/8000] D loss: 1.1248, G loss: 4.6431\n",
      "[2892/8000] D loss: 0.7638, G loss: 6.6504\n",
      "[3252/8000] D loss: 0.9820, G loss: 4.1883\n",
      "[3612/8000] D loss: 0.7730, G loss: 3.8720\n",
      "[3972/8000] D loss: 1.0501, G loss: 1.7400\n",
      "[4332/8000] D loss: 1.0946, G loss: 1.6045\n",
      "[4692/8000] D loss: 0.9066, G loss: 4.3462\n",
      "[5052/8000] D loss: 0.3534, G loss: 7.7452\n",
      "[5412/8000] D loss: 0.7155, G loss: 2.0283\n",
      "[5772/8000] D loss: 0.7188, G loss: 7.0810\n",
      "[6132/8000] D loss: 0.6777, G loss: 4.7730\n",
      "[6492/8000] D loss: 0.6289, G loss: 8.0637\n",
      "[6852/8000] D loss: 0.3218, G loss: 12.3895\n",
      "[7212/8000] D loss: 0.9196, G loss: 4.5792\n",
      "[7572/8000] D loss: 0.9423, G loss: 2.3471\n",
      "[7932/8000] D loss: 0.7442, G loss: 4.1604\n",
      "train error: \n",
      " D loss: 0.822806, G loss: 5.515385, D accuracy: 73.5%, cell accuracy: 98.7%, board accuracy: 53.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.050099, G loss: 15.163058, D accuracy: 76.1%, cell accuracy: 98.2%, board accuracy: 25.6% \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6071, G loss: 7.3545\n",
      "[372/8000] D loss: 0.6358, G loss: 6.7002\n",
      "[732/8000] D loss: 1.0157, G loss: 1.7266\n",
      "[1092/8000] D loss: 0.9797, G loss: 2.7446\n",
      "[1452/8000] D loss: 0.9128, G loss: 3.7710\n",
      "[1812/8000] D loss: 0.7352, G loss: 9.6879\n",
      "[2172/8000] D loss: 1.1806, G loss: 9.1076\n",
      "[2532/8000] D loss: 0.6070, G loss: 7.0208\n",
      "[2892/8000] D loss: 0.7911, G loss: 4.5813\n",
      "[3252/8000] D loss: 0.7048, G loss: 6.7554\n",
      "[3612/8000] D loss: 0.8872, G loss: 3.7725\n",
      "[3972/8000] D loss: 0.5854, G loss: 4.8676\n",
      "[4332/8000] D loss: 0.8305, G loss: 2.2333\n",
      "[4692/8000] D loss: 0.5833, G loss: 4.3785\n",
      "[5052/8000] D loss: 0.8937, G loss: 5.1229\n",
      "[5412/8000] D loss: 0.7775, G loss: 4.2982\n",
      "[5772/8000] D loss: 0.9344, G loss: 3.3242\n",
      "[6132/8000] D loss: 0.5206, G loss: 6.7195\n",
      "[6492/8000] D loss: 0.6554, G loss: 8.3185\n",
      "[6852/8000] D loss: 0.6707, G loss: 9.1227\n",
      "[7212/8000] D loss: 1.0273, G loss: 4.1870\n",
      "[7572/8000] D loss: 1.1800, G loss: 2.4000\n",
      "[7932/8000] D loss: 0.6316, G loss: 5.7828\n",
      "train error: \n",
      " D loss: 0.829347, G loss: 5.398646, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.953129, G loss: 15.423005, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9109, G loss: 3.4594\n",
      "[372/8000] D loss: 0.8073, G loss: 5.0279\n",
      "[732/8000] D loss: 0.7883, G loss: 8.9300\n",
      "[1092/8000] D loss: 0.4883, G loss: 5.0892\n",
      "[1452/8000] D loss: 0.8392, G loss: 3.4330\n",
      "[1812/8000] D loss: 0.7799, G loss: 6.6788\n",
      "[2172/8000] D loss: 0.4645, G loss: 4.4716\n",
      "[2532/8000] D loss: 0.1998, G loss: 7.7014\n",
      "[2892/8000] D loss: 1.2179, G loss: 1.7292\n",
      "[3252/8000] D loss: 1.0465, G loss: 4.5052\n",
      "[3612/8000] D loss: 0.9960, G loss: 4.2951\n",
      "[3972/8000] D loss: 0.8364, G loss: 4.8264\n",
      "[4332/8000] D loss: 0.8684, G loss: 5.2437\n",
      "[4692/8000] D loss: 0.9237, G loss: 7.0052\n",
      "[5052/8000] D loss: 0.9777, G loss: 3.5071\n",
      "[5412/8000] D loss: 1.0213, G loss: 5.3631\n",
      "[5772/8000] D loss: 0.6682, G loss: 5.7166\n",
      "[6132/8000] D loss: 1.0503, G loss: 2.0386\n",
      "[6492/8000] D loss: 1.0803, G loss: 1.4415\n",
      "[6852/8000] D loss: 0.8317, G loss: 4.9091\n",
      "[7212/8000] D loss: 0.7737, G loss: 5.0078\n",
      "[7572/8000] D loss: 0.9354, G loss: 4.2255\n",
      "[7932/8000] D loss: 0.5895, G loss: 5.7267\n",
      "train error: \n",
      " D loss: 0.819088, G loss: 4.867286, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.896473, G loss: 14.024856, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5270, G loss: 3.0845\n",
      "[372/8000] D loss: 0.8290, G loss: 9.3615\n",
      "[732/8000] D loss: 0.6950, G loss: 5.7206\n",
      "[1092/8000] D loss: 1.3209, G loss: 1.0680\n",
      "[1452/8000] D loss: 0.4694, G loss: 12.9463\n",
      "[1812/8000] D loss: 0.7726, G loss: 4.9881\n",
      "[2172/8000] D loss: 0.5436, G loss: 5.4443\n",
      "[2532/8000] D loss: 0.8717, G loss: 6.7650\n",
      "[2892/8000] D loss: 0.7995, G loss: 6.3403\n",
      "[3252/8000] D loss: 0.8607, G loss: 6.9660\n",
      "[3612/8000] D loss: 0.6977, G loss: 3.9444\n",
      "[3972/8000] D loss: 0.5725, G loss: 7.2891\n",
      "[4332/8000] D loss: 0.6999, G loss: 4.3283\n",
      "[4692/8000] D loss: 0.8319, G loss: 6.5912\n",
      "[5052/8000] D loss: 0.8127, G loss: 4.3329\n",
      "[5412/8000] D loss: 0.4759, G loss: 9.1267\n",
      "[5772/8000] D loss: 0.9375, G loss: 5.2353\n",
      "[6132/8000] D loss: 0.8689, G loss: 3.9961\n",
      "[6492/8000] D loss: 1.0566, G loss: 3.2571\n",
      "[6852/8000] D loss: 0.8199, G loss: 7.5981\n",
      "[7212/8000] D loss: 0.8033, G loss: 6.6982\n",
      "[7572/8000] D loss: 0.4708, G loss: 11.0865\n",
      "[7932/8000] D loss: 0.8163, G loss: 3.5766\n",
      "train error: \n",
      " D loss: 0.827559, G loss: 5.440349, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.931372, G loss: 15.456688, D accuracy: 80.0%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9684, G loss: 3.1427\n",
      "[372/8000] D loss: 0.9409, G loss: 4.2742\n",
      "[732/8000] D loss: 1.0748, G loss: 3.3352\n",
      "[1092/8000] D loss: 0.8969, G loss: 4.8983\n",
      "[1452/8000] D loss: 0.6616, G loss: 7.8759\n",
      "[1812/8000] D loss: 0.7015, G loss: 5.7628\n",
      "[2172/8000] D loss: 1.0387, G loss: 2.0212\n",
      "[2532/8000] D loss: 0.5375, G loss: 6.0944\n",
      "[2892/8000] D loss: 0.7424, G loss: 9.1344\n",
      "[3252/8000] D loss: 0.5570, G loss: 7.1065\n",
      "[3612/8000] D loss: 0.9790, G loss: 2.8237\n",
      "[3972/8000] D loss: 0.8126, G loss: 4.0935\n",
      "[4332/8000] D loss: 1.1095, G loss: 2.5037\n",
      "[4692/8000] D loss: 1.1763, G loss: 2.7822\n",
      "[5052/8000] D loss: 0.5756, G loss: 9.9260\n",
      "[5412/8000] D loss: 0.7014, G loss: 3.8573\n",
      "[5772/8000] D loss: 0.9388, G loss: 4.1945\n",
      "[6132/8000] D loss: 0.9501, G loss: 2.2312\n",
      "[6492/8000] D loss: 0.5982, G loss: 11.2954\n",
      "[6852/8000] D loss: 0.7781, G loss: 6.9173\n",
      "[7212/8000] D loss: 0.7520, G loss: 10.5898\n",
      "[7572/8000] D loss: 1.1547, G loss: 5.5682\n",
      "[7932/8000] D loss: 0.9471, G loss: 6.6355\n",
      "train error: \n",
      " D loss: 0.827451, G loss: 4.914503, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 53.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.899402, G loss: 13.892228, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 24.6% \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9739, G loss: 3.8429\n",
      "[372/8000] D loss: 1.2243, G loss: 1.2669\n",
      "[732/8000] D loss: 1.1337, G loss: 1.6695\n",
      "[1092/8000] D loss: 0.9280, G loss: 5.3017\n",
      "[1452/8000] D loss: 0.8874, G loss: 4.7823\n",
      "[1812/8000] D loss: 0.4962, G loss: 8.4507\n",
      "[2172/8000] D loss: 1.0968, G loss: 2.0216\n",
      "[2532/8000] D loss: 0.5284, G loss: 10.1567\n",
      "[2892/8000] D loss: 1.1632, G loss: 1.6366\n",
      "[3252/8000] D loss: 0.8715, G loss: 6.4328\n",
      "[3612/8000] D loss: 0.9011, G loss: 4.2638\n",
      "[3972/8000] D loss: 0.9482, G loss: 7.4029\n",
      "[4332/8000] D loss: 0.6836, G loss: 10.9654\n",
      "[4692/8000] D loss: 0.8650, G loss: 4.7235\n",
      "[5052/8000] D loss: 0.5499, G loss: 6.7563\n",
      "[5412/8000] D loss: 0.7139, G loss: 7.8812\n",
      "[5772/8000] D loss: 1.0350, G loss: 11.2771\n",
      "[6132/8000] D loss: 0.9087, G loss: 5.4803\n",
      "[6492/8000] D loss: 0.6116, G loss: 5.6829\n",
      "[6852/8000] D loss: 1.1090, G loss: 6.2724\n",
      "[7212/8000] D loss: 0.6389, G loss: 8.4335\n",
      "[7572/8000] D loss: 0.4482, G loss: 7.7959\n",
      "[7932/8000] D loss: 0.5225, G loss: 6.1811\n",
      "train error: \n",
      " D loss: 0.824827, G loss: 6.061179, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999026, G loss: 16.198824, D accuracy: 78.3%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6108, G loss: 6.8846\n",
      "[372/8000] D loss: 0.9381, G loss: 4.0696\n",
      "[732/8000] D loss: 0.7017, G loss: 7.7437\n",
      "[1092/8000] D loss: 0.9009, G loss: 4.2316\n",
      "[1452/8000] D loss: 0.9814, G loss: 4.0205\n",
      "[1812/8000] D loss: 0.5954, G loss: 4.8017\n",
      "[2172/8000] D loss: 0.4621, G loss: 7.3907\n",
      "[2532/8000] D loss: 0.7815, G loss: 4.5332\n",
      "[2892/8000] D loss: 1.0632, G loss: 4.9904\n",
      "[3252/8000] D loss: 1.0076, G loss: 6.6114\n",
      "[3612/8000] D loss: 1.3331, G loss: 1.8487\n",
      "[3972/8000] D loss: 0.7384, G loss: 6.4193\n",
      "[4332/8000] D loss: 0.7488, G loss: 5.8486\n",
      "[4692/8000] D loss: 0.5459, G loss: 7.5708\n",
      "[5052/8000] D loss: 0.8716, G loss: 2.6264\n",
      "[5412/8000] D loss: 1.1542, G loss: 1.3385\n",
      "[5772/8000] D loss: 0.7230, G loss: 7.8491\n",
      "[6132/8000] D loss: 0.5977, G loss: 7.2946\n",
      "[6492/8000] D loss: 0.9391, G loss: 5.1654\n",
      "[6852/8000] D loss: 0.2322, G loss: 13.6929\n",
      "[7212/8000] D loss: 1.2405, G loss: 3.8099\n",
      "[7572/8000] D loss: 0.7617, G loss: 5.1038\n",
      "[7932/8000] D loss: 0.6020, G loss: 4.9273\n",
      "train error: \n",
      " D loss: 0.813836, G loss: 5.366697, D accuracy: 73.5%, cell accuracy: 98.7%, board accuracy: 53.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.939646, G loss: 14.440062, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9113, G loss: 4.9440\n",
      "[372/8000] D loss: 0.8251, G loss: 6.4285\n",
      "[732/8000] D loss: 0.9967, G loss: 2.7080\n",
      "[1092/8000] D loss: 0.8989, G loss: 3.6804\n",
      "[1452/8000] D loss: 1.1157, G loss: 3.8400\n",
      "[1812/8000] D loss: 0.8755, G loss: 2.9843\n",
      "[2172/8000] D loss: 0.7431, G loss: 5.5710\n",
      "[2532/8000] D loss: 0.7938, G loss: 5.0280\n",
      "[2892/8000] D loss: 0.8626, G loss: 2.1108\n",
      "[3252/8000] D loss: 0.8833, G loss: 6.8925\n",
      "[3612/8000] D loss: 1.0061, G loss: 4.7410\n",
      "[3972/8000] D loss: 1.2725, G loss: 3.1000\n",
      "[4332/8000] D loss: 0.9093, G loss: 10.4547\n",
      "[4692/8000] D loss: 0.6920, G loss: 6.0098\n",
      "[5052/8000] D loss: 0.6801, G loss: 3.7344\n",
      "[5412/8000] D loss: 0.9931, G loss: 2.3111\n",
      "[5772/8000] D loss: 0.6890, G loss: 7.1043\n",
      "[6132/8000] D loss: 0.6973, G loss: 5.1202\n",
      "[6492/8000] D loss: 0.8302, G loss: 6.4021\n",
      "[6852/8000] D loss: 0.7385, G loss: 6.2543\n",
      "[7212/8000] D loss: 0.6509, G loss: 4.4035\n",
      "[7572/8000] D loss: 0.9032, G loss: 2.0600\n",
      "[7932/8000] D loss: 1.0082, G loss: 3.3352\n",
      "train error: \n",
      " D loss: 0.879072, G loss: 3.216258, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.902494, G loss: 10.747012, D accuracy: 80.3%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1306, G loss: 1.7662\n",
      "[372/8000] D loss: 0.7442, G loss: 7.5858\n",
      "[732/8000] D loss: 1.2228, G loss: 2.9102\n",
      "[1092/8000] D loss: 0.4421, G loss: 9.4121\n",
      "[1452/8000] D loss: 0.7306, G loss: 7.3251\n",
      "[1812/8000] D loss: 0.8796, G loss: 5.9023\n",
      "[2172/8000] D loss: 0.4628, G loss: 9.0711\n",
      "[2532/8000] D loss: 1.0637, G loss: 2.6040\n",
      "[2892/8000] D loss: 0.8369, G loss: 2.5794\n",
      "[3252/8000] D loss: 0.8637, G loss: 4.1247\n",
      "[3612/8000] D loss: 0.9756, G loss: 3.4535\n",
      "[3972/8000] D loss: 0.8611, G loss: 3.2019\n",
      "[4332/8000] D loss: 0.7812, G loss: 8.2017\n",
      "[4692/8000] D loss: 0.8299, G loss: 3.9424\n",
      "[5052/8000] D loss: 0.8904, G loss: 2.5812\n",
      "[5412/8000] D loss: 1.0374, G loss: 2.2973\n",
      "[5772/8000] D loss: 0.7391, G loss: 4.5415\n",
      "[6132/8000] D loss: 0.9701, G loss: 4.0230\n",
      "[6492/8000] D loss: 0.9098, G loss: 8.2241\n",
      "[6852/8000] D loss: 0.6171, G loss: 5.3506\n",
      "[7212/8000] D loss: 0.8584, G loss: 8.1464\n",
      "[7572/8000] D loss: 0.7925, G loss: 4.9963\n",
      "[7932/8000] D loss: 0.4008, G loss: 7.0360\n",
      "train error: \n",
      " D loss: 0.830749, G loss: 4.710741, D accuracy: 73.0%, cell accuracy: 98.7%, board accuracy: 54.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.896938, G loss: 13.560248, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5248, G loss: 6.9956\n",
      "[372/8000] D loss: 0.9413, G loss: 5.8375\n",
      "[732/8000] D loss: 1.0138, G loss: 2.6398\n",
      "[1092/8000] D loss: 0.8289, G loss: 6.6325\n",
      "[1452/8000] D loss: 0.7449, G loss: 12.3346\n",
      "[1812/8000] D loss: 1.0233, G loss: 2.7689\n",
      "[2172/8000] D loss: 0.8558, G loss: 4.6315\n",
      "[2532/8000] D loss: 0.8033, G loss: 5.9429\n",
      "[2892/8000] D loss: 0.7209, G loss: 7.5793\n",
      "[3252/8000] D loss: 0.9793, G loss: 6.4285\n",
      "[3612/8000] D loss: 0.7632, G loss: 5.3264\n",
      "[3972/8000] D loss: 0.6836, G loss: 7.8249\n",
      "[4332/8000] D loss: 0.9889, G loss: 2.5270\n",
      "[4692/8000] D loss: 0.7755, G loss: 6.1588\n",
      "[5052/8000] D loss: 0.7253, G loss: 5.4727\n",
      "[5412/8000] D loss: 0.5001, G loss: 6.2334\n",
      "[5772/8000] D loss: 1.0304, G loss: 2.1144\n",
      "[6132/8000] D loss: 1.0055, G loss: 1.8906\n",
      "[6492/8000] D loss: 0.6468, G loss: 6.4760\n",
      "[6852/8000] D loss: 0.8368, G loss: 6.6309\n",
      "[7212/8000] D loss: 0.8694, G loss: 5.8848\n",
      "[7572/8000] D loss: 0.7029, G loss: 5.2269\n",
      "[7932/8000] D loss: 0.5390, G loss: 9.4048\n",
      "train error: \n",
      " D loss: 0.810663, G loss: 5.362937, D accuracy: 74.1%, cell accuracy: 98.7%, board accuracy: 53.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.882556, G loss: 14.756336, D accuracy: 80.3%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5835, G loss: 8.0174\n",
      "[372/8000] D loss: 0.8530, G loss: 7.9726\n",
      "[732/8000] D loss: 0.6736, G loss: 4.6854\n",
      "[1092/8000] D loss: 1.0394, G loss: 4.1905\n",
      "[1452/8000] D loss: 0.7538, G loss: 7.6277\n",
      "[1812/8000] D loss: 1.2231, G loss: 1.0574\n",
      "[2172/8000] D loss: 0.6362, G loss: 8.5762\n",
      "[2532/8000] D loss: 1.1266, G loss: 2.9067\n",
      "[2892/8000] D loss: 0.6390, G loss: 3.2451\n",
      "[3252/8000] D loss: 0.9147, G loss: 2.7528\n",
      "[3612/8000] D loss: 0.8918, G loss: 4.7746\n",
      "[3972/8000] D loss: 1.0388, G loss: 7.3709\n",
      "[4332/8000] D loss: 0.6530, G loss: 5.8016\n",
      "[4692/8000] D loss: 0.6419, G loss: 5.0731\n",
      "[5052/8000] D loss: 0.8072, G loss: 5.3027\n",
      "[5412/8000] D loss: 0.7985, G loss: 2.9618\n",
      "[5772/8000] D loss: 0.8887, G loss: 5.6307\n",
      "[6132/8000] D loss: 0.3947, G loss: 8.0149\n",
      "[6492/8000] D loss: 0.6070, G loss: 5.4184\n",
      "[6852/8000] D loss: 0.8284, G loss: 4.5904\n",
      "[7212/8000] D loss: 1.1879, G loss: 2.3629\n",
      "[7572/8000] D loss: 0.8252, G loss: 7.3106\n",
      "[7932/8000] D loss: 0.5055, G loss: 8.2392\n",
      "train error: \n",
      " D loss: 0.826009, G loss: 3.999774, D accuracy: 74.5%, cell accuracy: 98.7%, board accuracy: 51.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.818412, G loss: 12.248487, D accuracy: 83.4%, cell accuracy: 98.1%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8359, G loss: 3.5835\n",
      "[372/8000] D loss: 0.8198, G loss: 5.2459\n",
      "[732/8000] D loss: 0.6481, G loss: 5.3786\n",
      "[1092/8000] D loss: 0.7548, G loss: 7.7741\n",
      "[1452/8000] D loss: 0.9945, G loss: 3.0329\n",
      "[1812/8000] D loss: 0.5075, G loss: 6.2410\n",
      "[2172/8000] D loss: 0.6275, G loss: 5.2595\n",
      "[2532/8000] D loss: 0.9573, G loss: 3.9707\n",
      "[2892/8000] D loss: 0.6377, G loss: 7.4448\n",
      "[3252/8000] D loss: 1.0436, G loss: 4.9101\n",
      "[3612/8000] D loss: 0.5850, G loss: 9.7327\n",
      "[3972/8000] D loss: 0.8577, G loss: 3.8187\n",
      "[4332/8000] D loss: 0.7043, G loss: 8.1216\n",
      "[4692/8000] D loss: 0.8604, G loss: 8.0966\n",
      "[5052/8000] D loss: 0.9752, G loss: 5.1167\n",
      "[5412/8000] D loss: 0.6011, G loss: 10.8826\n",
      "[5772/8000] D loss: 0.9712, G loss: 3.8349\n",
      "[6132/8000] D loss: 0.9037, G loss: 2.9176\n",
      "[6492/8000] D loss: 0.8420, G loss: 5.3048\n",
      "[6852/8000] D loss: 1.1264, G loss: 9.1130\n",
      "[7212/8000] D loss: 0.8853, G loss: 2.5072\n",
      "[7572/8000] D loss: 0.9112, G loss: 5.2016\n",
      "[7932/8000] D loss: 0.7588, G loss: 5.5990\n",
      "train error: \n",
      " D loss: 0.816677, G loss: 5.254526, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.944913, G loss: 14.744465, D accuracy: 77.4%, cell accuracy: 98.2%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0314, G loss: 2.1884\n",
      "[372/8000] D loss: 0.8419, G loss: 4.5558\n",
      "[732/8000] D loss: 0.7370, G loss: 6.4747\n",
      "[1092/8000] D loss: 0.8346, G loss: 7.1007\n",
      "[1452/8000] D loss: 0.5403, G loss: 9.4527\n",
      "[1812/8000] D loss: 0.8704, G loss: 9.2076\n",
      "[2172/8000] D loss: 0.9822, G loss: 5.6264\n",
      "[2532/8000] D loss: 1.0713, G loss: 3.0189\n",
      "[2892/8000] D loss: 0.5235, G loss: 6.9181\n",
      "[3252/8000] D loss: 0.4597, G loss: 8.4312\n",
      "[3612/8000] D loss: 0.8869, G loss: 2.6425\n",
      "[3972/8000] D loss: 0.9343, G loss: 9.3758\n",
      "[4332/8000] D loss: 1.0418, G loss: 1.6326\n",
      "[4692/8000] D loss: 0.8569, G loss: 2.1937\n",
      "[5052/8000] D loss: 0.9522, G loss: 3.7280\n",
      "[5412/8000] D loss: 0.7586, G loss: 3.4054\n",
      "[5772/8000] D loss: 0.6240, G loss: 8.0073\n",
      "[6132/8000] D loss: 0.8693, G loss: 5.9781\n",
      "[6492/8000] D loss: 0.7334, G loss: 5.6463\n",
      "[6852/8000] D loss: 0.6564, G loss: 9.0480\n",
      "[7212/8000] D loss: 0.8918, G loss: 7.4535\n",
      "[7572/8000] D loss: 0.7994, G loss: 7.7663\n",
      "[7932/8000] D loss: 1.2396, G loss: 1.2353\n",
      "train error: \n",
      " D loss: 0.831631, G loss: 6.082304, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.038859, G loss: 15.811090, D accuracy: 77.7%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0101, G loss: 5.5356\n",
      "[372/8000] D loss: 1.0417, G loss: 4.4305\n",
      "[732/8000] D loss: 0.7970, G loss: 2.7098\n",
      "[1092/8000] D loss: 0.4003, G loss: 11.8849\n",
      "[1452/8000] D loss: 1.2019, G loss: 4.4977\n",
      "[1812/8000] D loss: 1.1009, G loss: 4.1445\n",
      "[2172/8000] D loss: 0.7636, G loss: 7.1144\n",
      "[2532/8000] D loss: 0.3985, G loss: 11.4670\n",
      "[2892/8000] D loss: 0.7155, G loss: 7.6841\n",
      "[3252/8000] D loss: 0.5333, G loss: 9.3488\n",
      "[3612/8000] D loss: 0.4168, G loss: 8.9198\n",
      "[3972/8000] D loss: 0.6381, G loss: 3.6004\n",
      "[4332/8000] D loss: 0.9042, G loss: 3.0645\n",
      "[4692/8000] D loss: 1.4187, G loss: 3.8983\n",
      "[5052/8000] D loss: 0.7009, G loss: 3.4135\n",
      "[5412/8000] D loss: 0.7923, G loss: 6.3571\n",
      "[5772/8000] D loss: 0.7638, G loss: 5.3501\n",
      "[6132/8000] D loss: 0.9356, G loss: 3.7593\n",
      "[6492/8000] D loss: 0.4899, G loss: 9.7656\n",
      "[6852/8000] D loss: 0.8882, G loss: 3.6954\n",
      "[7212/8000] D loss: 0.5873, G loss: 10.7039\n",
      "[7572/8000] D loss: 0.8540, G loss: 3.3157\n",
      "[7932/8000] D loss: 0.9013, G loss: 3.3648\n",
      "train error: \n",
      " D loss: 0.823267, G loss: 4.985078, D accuracy: 73.8%, cell accuracy: 98.7%, board accuracy: 53.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.865956, G loss: 13.837931, D accuracy: 81.6%, cell accuracy: 98.2%, board accuracy: 26.0% \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7500, G loss: 4.1066\n",
      "[372/8000] D loss: 1.1457, G loss: 4.9112\n",
      "[732/8000] D loss: 0.5688, G loss: 6.1856\n",
      "[1092/8000] D loss: 1.1407, G loss: 2.4553\n",
      "[1452/8000] D loss: 0.5862, G loss: 4.4599\n",
      "[1812/8000] D loss: 0.7537, G loss: 5.5963\n",
      "[2172/8000] D loss: 0.6233, G loss: 14.1725\n",
      "[2532/8000] D loss: 0.9280, G loss: 3.6330\n",
      "[2892/8000] D loss: 0.5894, G loss: 6.8258\n",
      "[3252/8000] D loss: 1.2746, G loss: 3.5167\n",
      "[3612/8000] D loss: 0.7977, G loss: 4.0805\n",
      "[3972/8000] D loss: 0.6459, G loss: 9.7324\n",
      "[4332/8000] D loss: 0.8272, G loss: 6.0426\n",
      "[4692/8000] D loss: 0.7112, G loss: 6.9998\n",
      "[5052/8000] D loss: 0.8987, G loss: 4.8748\n",
      "[5412/8000] D loss: 0.6296, G loss: 6.4721\n",
      "[5772/8000] D loss: 0.8292, G loss: 6.5388\n",
      "[6132/8000] D loss: 0.7250, G loss: 3.7616\n",
      "[6492/8000] D loss: 0.9799, G loss: 3.9109\n",
      "[6852/8000] D loss: 0.6594, G loss: 4.6027\n",
      "[7212/8000] D loss: 0.7630, G loss: 4.7966\n",
      "[7572/8000] D loss: 0.7440, G loss: 6.0982\n",
      "[7932/8000] D loss: 0.5968, G loss: 4.5325\n",
      "train error: \n",
      " D loss: 0.830680, G loss: 4.399632, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.939278, G loss: 12.720563, D accuracy: 78.9%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0430, G loss: 3.5304\n",
      "[372/8000] D loss: 0.4815, G loss: 8.5582\n",
      "[732/8000] D loss: 0.7638, G loss: 3.5155\n",
      "[1092/8000] D loss: 1.1570, G loss: 4.7077\n",
      "[1452/8000] D loss: 0.4244, G loss: 9.2335\n",
      "[1812/8000] D loss: 1.1149, G loss: 2.8341\n",
      "[2172/8000] D loss: 0.3542, G loss: 9.9034\n",
      "[2532/8000] D loss: 0.7934, G loss: 2.7942\n",
      "[2892/8000] D loss: 0.9842, G loss: 3.8866\n",
      "[3252/8000] D loss: 0.7377, G loss: 5.5579\n",
      "[3612/8000] D loss: 0.5090, G loss: 10.9504\n",
      "[3972/8000] D loss: 1.1007, G loss: 6.8057\n",
      "[4332/8000] D loss: 0.7240, G loss: 10.8770\n",
      "[4692/8000] D loss: 0.8362, G loss: 6.9978\n",
      "[5052/8000] D loss: 0.6101, G loss: 6.0471\n",
      "[5412/8000] D loss: 0.7229, G loss: 4.6122\n",
      "[5772/8000] D loss: 0.7651, G loss: 5.4666\n",
      "[6132/8000] D loss: 0.6997, G loss: 4.9621\n",
      "[6492/8000] D loss: 0.8075, G loss: 4.7348\n",
      "[6852/8000] D loss: 0.8234, G loss: 4.3483\n",
      "[7212/8000] D loss: 0.8322, G loss: 3.7103\n",
      "[7572/8000] D loss: 0.9883, G loss: 5.3677\n",
      "[7932/8000] D loss: 0.6145, G loss: 4.1038\n",
      "train error: \n",
      " D loss: 0.825581, G loss: 4.959324, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.975734, G loss: 14.270066, D accuracy: 78.3%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9077, G loss: 5.6185\n",
      "[372/8000] D loss: 0.9987, G loss: 1.8659\n",
      "[732/8000] D loss: 0.7740, G loss: 6.3087\n",
      "[1092/8000] D loss: 0.5437, G loss: 7.0149\n",
      "[1452/8000] D loss: 1.0085, G loss: 4.0789\n",
      "[1812/8000] D loss: 0.6984, G loss: 7.4757\n",
      "[2172/8000] D loss: 0.5293, G loss: 6.0285\n",
      "[2532/8000] D loss: 0.7041, G loss: 6.2372\n",
      "[2892/8000] D loss: 1.0487, G loss: 3.0002\n",
      "[3252/8000] D loss: 0.8330, G loss: 5.6711\n",
      "[3612/8000] D loss: 0.4287, G loss: 7.5832\n",
      "[3972/8000] D loss: 0.5873, G loss: 5.9877\n",
      "[4332/8000] D loss: 0.9769, G loss: 6.3098\n",
      "[4692/8000] D loss: 0.8932, G loss: 7.6309\n",
      "[5052/8000] D loss: 0.8136, G loss: 4.3409\n",
      "[5412/8000] D loss: 0.5999, G loss: 11.1902\n",
      "[5772/8000] D loss: 0.8629, G loss: 3.1942\n",
      "[6132/8000] D loss: 0.5310, G loss: 12.2636\n",
      "[6492/8000] D loss: 1.2514, G loss: 1.1689\n",
      "[6852/8000] D loss: 1.0100, G loss: 2.0362\n",
      "[7212/8000] D loss: 0.9311, G loss: 5.4241\n",
      "[7572/8000] D loss: 0.8170, G loss: 10.8005\n",
      "[7932/8000] D loss: 0.7317, G loss: 5.0980\n",
      "train error: \n",
      " D loss: 0.817970, G loss: 6.079435, D accuracy: 73.9%, cell accuracy: 98.7%, board accuracy: 53.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.998598, G loss: 16.519491, D accuracy: 79.3%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6230, G loss: 6.0249\n",
      "[372/8000] D loss: 1.0372, G loss: 5.1620\n",
      "[732/8000] D loss: 1.0620, G loss: 5.0769\n",
      "[1092/8000] D loss: 0.7039, G loss: 3.4576\n",
      "[1452/8000] D loss: 0.9515, G loss: 4.1420\n",
      "[1812/8000] D loss: 0.6052, G loss: 8.5288\n",
      "[2172/8000] D loss: 0.5305, G loss: 6.4622\n",
      "[2532/8000] D loss: 0.4042, G loss: 7.2836\n",
      "[2892/8000] D loss: 0.8334, G loss: 7.1237\n",
      "[3252/8000] D loss: 0.6693, G loss: 5.3002\n",
      "[3612/8000] D loss: 1.1728, G loss: 1.5321\n",
      "[3972/8000] D loss: 0.8567, G loss: 8.2453\n",
      "[4332/8000] D loss: 0.6334, G loss: 10.6433\n",
      "[4692/8000] D loss: 0.8142, G loss: 3.5135\n",
      "[5052/8000] D loss: 0.9906, G loss: 2.5986\n",
      "[5412/8000] D loss: 0.6751, G loss: 7.4771\n",
      "[5772/8000] D loss: 0.8293, G loss: 4.9859\n",
      "[6132/8000] D loss: 1.2296, G loss: 2.2171\n",
      "[6492/8000] D loss: 0.8515, G loss: 6.4483\n",
      "[6852/8000] D loss: 0.8552, G loss: 7.0655\n",
      "[7212/8000] D loss: 1.0956, G loss: 4.2228\n",
      "[7572/8000] D loss: 0.7522, G loss: 4.4020\n",
      "[7932/8000] D loss: 0.7179, G loss: 7.2938\n",
      "train error: \n",
      " D loss: 0.825273, G loss: 5.626687, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.014082, G loss: 15.417258, D accuracy: 79.3%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6027, G loss: 9.0014\n",
      "[372/8000] D loss: 0.7455, G loss: 8.3635\n",
      "[732/8000] D loss: 0.3945, G loss: 5.9901\n",
      "[1092/8000] D loss: 0.8013, G loss: 2.1615\n",
      "[1452/8000] D loss: 0.4722, G loss: 5.8368\n",
      "[1812/8000] D loss: 0.9644, G loss: 4.9522\n",
      "[2172/8000] D loss: 1.1099, G loss: 2.0286\n",
      "[2532/8000] D loss: 1.0061, G loss: 4.5447\n",
      "[2892/8000] D loss: 0.4986, G loss: 5.4954\n",
      "[3252/8000] D loss: 0.7360, G loss: 4.1720\n",
      "[3612/8000] D loss: 1.0355, G loss: 4.5569\n",
      "[3972/8000] D loss: 0.6997, G loss: 8.4118\n",
      "[4332/8000] D loss: 0.7285, G loss: 3.8417\n",
      "[4692/8000] D loss: 0.6744, G loss: 10.1291\n",
      "[5052/8000] D loss: 1.1557, G loss: 4.6148\n",
      "[5412/8000] D loss: 0.8123, G loss: 4.5479\n",
      "[5772/8000] D loss: 1.0311, G loss: 2.4061\n",
      "[6132/8000] D loss: 0.6591, G loss: 3.1809\n",
      "[6492/8000] D loss: 0.6173, G loss: 7.3685\n",
      "[6852/8000] D loss: 0.8425, G loss: 6.9715\n",
      "[7212/8000] D loss: 0.7450, G loss: 6.1906\n",
      "[7572/8000] D loss: 1.0254, G loss: 5.7022\n",
      "[7932/8000] D loss: 0.5285, G loss: 6.7558\n",
      "train error: \n",
      " D loss: 0.822635, G loss: 5.360947, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 53.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.994718, G loss: 15.046797, D accuracy: 76.4%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7932, G loss: 8.6722\n",
      "[372/8000] D loss: 0.8809, G loss: 4.7731\n",
      "[732/8000] D loss: 1.1281, G loss: 2.9979\n",
      "[1092/8000] D loss: 0.5964, G loss: 4.8528\n",
      "[1452/8000] D loss: 0.7139, G loss: 4.6268\n",
      "[1812/8000] D loss: 0.9215, G loss: 6.0723\n",
      "[2172/8000] D loss: 0.4625, G loss: 6.6877\n",
      "[2532/8000] D loss: 0.6064, G loss: 9.3647\n",
      "[2892/8000] D loss: 0.9248, G loss: 6.4897\n",
      "[3252/8000] D loss: 1.0791, G loss: 1.8188\n",
      "[3612/8000] D loss: 0.7522, G loss: 6.7211\n",
      "[3972/8000] D loss: 0.7160, G loss: 3.4224\n",
      "[4332/8000] D loss: 0.7003, G loss: 4.6429\n",
      "[4692/8000] D loss: 0.8246, G loss: 3.5065\n",
      "[5052/8000] D loss: 0.7974, G loss: 6.3251\n",
      "[5412/8000] D loss: 0.7978, G loss: 5.6344\n",
      "[5772/8000] D loss: 0.7937, G loss: 7.3363\n",
      "[6132/8000] D loss: 0.8231, G loss: 3.5100\n",
      "[6492/8000] D loss: 0.6840, G loss: 6.7876\n",
      "[6852/8000] D loss: 0.7613, G loss: 7.1626\n",
      "[7212/8000] D loss: 0.4859, G loss: 7.7848\n",
      "[7572/8000] D loss: 0.6053, G loss: 5.8490\n",
      "[7932/8000] D loss: 0.8442, G loss: 6.5957\n",
      "train error: \n",
      " D loss: 0.849811, G loss: 5.623132, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.053585, G loss: 15.149946, D accuracy: 75.0%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9951, G loss: 1.7234\n",
      "[372/8000] D loss: 0.5217, G loss: 9.7438\n",
      "[732/8000] D loss: 0.9824, G loss: 2.8055\n",
      "[1092/8000] D loss: 0.9111, G loss: 3.6927\n",
      "[1452/8000] D loss: 0.4521, G loss: 8.6168\n",
      "[1812/8000] D loss: 1.0660, G loss: 4.0511\n",
      "[2172/8000] D loss: 0.7092, G loss: 4.9329\n",
      "[2532/8000] D loss: 0.9535, G loss: 3.1128\n",
      "[2892/8000] D loss: 0.7308, G loss: 3.3658\n",
      "[3252/8000] D loss: 0.8909, G loss: 4.0763\n",
      "[3612/8000] D loss: 0.8344, G loss: 4.1653\n",
      "[3972/8000] D loss: 0.7298, G loss: 6.3344\n",
      "[4332/8000] D loss: 1.0674, G loss: 3.1250\n",
      "[4692/8000] D loss: 0.5311, G loss: 7.2192\n",
      "[5052/8000] D loss: 0.9507, G loss: 5.0099\n",
      "[5412/8000] D loss: 0.9702, G loss: 6.1574\n",
      "[5772/8000] D loss: 0.7912, G loss: 4.8136\n",
      "[6132/8000] D loss: 0.9433, G loss: 6.4914\n",
      "[6492/8000] D loss: 0.5829, G loss: 5.9458\n",
      "[6852/8000] D loss: 0.7396, G loss: 7.0779\n",
      "[7212/8000] D loss: 0.8271, G loss: 4.7389\n",
      "[7572/8000] D loss: 0.5345, G loss: 8.9037\n",
      "[7932/8000] D loss: 0.8675, G loss: 5.0193\n",
      "train error: \n",
      " D loss: 0.818415, G loss: 5.346233, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.919710, G loss: 14.959291, D accuracy: 81.3%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9316, G loss: 6.2697\n",
      "[372/8000] D loss: 0.3576, G loss: 9.0486\n",
      "[732/8000] D loss: 1.0029, G loss: 2.6577\n",
      "[1092/8000] D loss: 1.2332, G loss: 1.3796\n",
      "[1452/8000] D loss: 0.7845, G loss: 7.5875\n",
      "[1812/8000] D loss: 0.7805, G loss: 5.7647\n",
      "[2172/8000] D loss: 0.6166, G loss: 6.8500\n",
      "[2532/8000] D loss: 1.2304, G loss: 2.5728\n",
      "[2892/8000] D loss: 1.1794, G loss: 2.9984\n",
      "[3252/8000] D loss: 0.5857, G loss: 3.9458\n",
      "[3612/8000] D loss: 0.3653, G loss: 14.1267\n",
      "[3972/8000] D loss: 0.8397, G loss: 11.0474\n",
      "[4332/8000] D loss: 0.7264, G loss: 4.4007\n",
      "[4692/8000] D loss: 0.9763, G loss: 4.0235\n",
      "[5052/8000] D loss: 0.8837, G loss: 2.4429\n",
      "[5412/8000] D loss: 0.7308, G loss: 6.0130\n",
      "[5772/8000] D loss: 1.0742, G loss: 4.2264\n",
      "[6132/8000] D loss: 0.8705, G loss: 6.5485\n",
      "[6492/8000] D loss: 0.9254, G loss: 2.2880\n",
      "[6852/8000] D loss: 0.7688, G loss: 5.2661\n",
      "[7212/8000] D loss: 0.5714, G loss: 8.9673\n",
      "[7572/8000] D loss: 0.7545, G loss: 9.1249\n",
      "[7932/8000] D loss: 0.8105, G loss: 4.8549\n",
      "train error: \n",
      " D loss: 0.816413, G loss: 5.736038, D accuracy: 74.2%, cell accuracy: 98.7%, board accuracy: 53.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.854619, G loss: 15.585244, D accuracy: 81.5%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9384, G loss: 1.6730\n",
      "[372/8000] D loss: 0.4916, G loss: 10.4732\n",
      "[732/8000] D loss: 0.8991, G loss: 4.5342\n",
      "[1092/8000] D loss: 0.9832, G loss: 4.4102\n",
      "[1452/8000] D loss: 1.0285, G loss: 3.6756\n",
      "[1812/8000] D loss: 0.9131, G loss: 6.0847\n",
      "[2172/8000] D loss: 0.7222, G loss: 5.7511\n",
      "[2532/8000] D loss: 0.8918, G loss: 3.8176\n",
      "[2892/8000] D loss: 1.1224, G loss: 4.2417\n",
      "[3252/8000] D loss: 0.7962, G loss: 7.3251\n",
      "[3612/8000] D loss: 0.9551, G loss: 7.5074\n",
      "[3972/8000] D loss: 0.6755, G loss: 5.6750\n",
      "[4332/8000] D loss: 0.9974, G loss: 4.2581\n",
      "[4692/8000] D loss: 0.8131, G loss: 3.5547\n",
      "[5052/8000] D loss: 0.7803, G loss: 7.0884\n",
      "[5412/8000] D loss: 0.8751, G loss: 5.4035\n",
      "[5772/8000] D loss: 0.9058, G loss: 7.4401\n",
      "[6132/8000] D loss: 0.9676, G loss: 5.3306\n",
      "[6492/8000] D loss: 0.9185, G loss: 7.6911\n",
      "[6852/8000] D loss: 0.6963, G loss: 8.2751\n",
      "[7212/8000] D loss: 0.6830, G loss: 4.6003\n",
      "[7572/8000] D loss: 1.1267, G loss: 1.5426\n",
      "[7932/8000] D loss: 0.8959, G loss: 5.5841\n",
      "train error: \n",
      " D loss: 0.829680, G loss: 4.751926, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.848880, G loss: 13.682145, D accuracy: 81.2%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7310, G loss: 4.2509\n",
      "[372/8000] D loss: 0.7341, G loss: 4.6927\n",
      "[732/8000] D loss: 1.1246, G loss: 1.5798\n",
      "[1092/8000] D loss: 0.9038, G loss: 9.7942\n",
      "[1452/8000] D loss: 0.6364, G loss: 7.7464\n",
      "[1812/8000] D loss: 0.7045, G loss: 7.1941\n",
      "[2172/8000] D loss: 1.3017, G loss: 0.9532\n",
      "[2532/8000] D loss: 0.8207, G loss: 6.6010\n",
      "[2892/8000] D loss: 0.8128, G loss: 5.5150\n",
      "[3252/8000] D loss: 0.7717, G loss: 6.6317\n",
      "[3612/8000] D loss: 1.0988, G loss: 2.4648\n",
      "[3972/8000] D loss: 0.7422, G loss: 6.3280\n",
      "[4332/8000] D loss: 0.5969, G loss: 4.5694\n",
      "[4692/8000] D loss: 1.1136, G loss: 4.0389\n",
      "[5052/8000] D loss: 0.9974, G loss: 3.8839\n",
      "[5412/8000] D loss: 0.8272, G loss: 4.5685\n",
      "[5772/8000] D loss: 0.6880, G loss: 8.0706\n",
      "[6132/8000] D loss: 0.7529, G loss: 4.1647\n",
      "[6492/8000] D loss: 1.1814, G loss: 1.0932\n",
      "[6852/8000] D loss: 0.8942, G loss: 6.4512\n",
      "[7212/8000] D loss: 0.6660, G loss: 3.1161\n",
      "[7572/8000] D loss: 1.0958, G loss: 1.7251\n",
      "[7932/8000] D loss: 0.8050, G loss: 9.1299\n",
      "train error: \n",
      " D loss: 0.846132, G loss: 4.542920, D accuracy: 73.0%, cell accuracy: 98.7%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.854770, G loss: 13.763324, D accuracy: 81.8%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4847, G loss: 10.6940\n",
      "[372/8000] D loss: 0.8206, G loss: 4.5206\n",
      "[732/8000] D loss: 0.7221, G loss: 5.7710\n",
      "[1092/8000] D loss: 0.5053, G loss: 4.9401\n",
      "[1452/8000] D loss: 0.7385, G loss: 8.6688\n",
      "[1812/8000] D loss: 0.8312, G loss: 6.5333\n",
      "[2172/8000] D loss: 0.6848, G loss: 7.2277\n",
      "[2532/8000] D loss: 0.7308, G loss: 7.7928\n",
      "[2892/8000] D loss: 0.8194, G loss: 4.2413\n",
      "[3252/8000] D loss: 0.8173, G loss: 14.1181\n",
      "[3612/8000] D loss: 0.3943, G loss: 10.5740\n",
      "[3972/8000] D loss: 1.1804, G loss: 3.9393\n",
      "[4332/8000] D loss: 1.1932, G loss: 1.7918\n",
      "[4692/8000] D loss: 0.8813, G loss: 3.0036\n",
      "[5052/8000] D loss: 0.8346, G loss: 4.5388\n",
      "[5412/8000] D loss: 0.7824, G loss: 3.7655\n",
      "[5772/8000] D loss: 0.6663, G loss: 8.1442\n",
      "[6132/8000] D loss: 0.8804, G loss: 7.5852\n",
      "[6492/8000] D loss: 0.8395, G loss: 6.1966\n",
      "[6852/8000] D loss: 0.9064, G loss: 3.9086\n",
      "[7212/8000] D loss: 1.0729, G loss: 8.7245\n",
      "[7572/8000] D loss: 0.6712, G loss: 3.5520\n",
      "[7932/8000] D loss: 0.6085, G loss: 5.5829\n",
      "train error: \n",
      " D loss: 0.808031, G loss: 5.500175, D accuracy: 74.3%, cell accuracy: 98.7%, board accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.886522, G loss: 15.376420, D accuracy: 81.1%, cell accuracy: 98.2%, board accuracy: 25.6% \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7907, G loss: 10.2414\n",
      "[372/8000] D loss: 0.8769, G loss: 3.2491\n",
      "[732/8000] D loss: 0.9597, G loss: 4.5899\n",
      "[1092/8000] D loss: 0.8098, G loss: 4.2550\n",
      "[1452/8000] D loss: 0.7293, G loss: 6.9288\n",
      "[1812/8000] D loss: 0.9470, G loss: 3.9499\n",
      "[2172/8000] D loss: 1.0969, G loss: 3.4326\n",
      "[2532/8000] D loss: 0.6051, G loss: 9.0702\n",
      "[2892/8000] D loss: 0.8004, G loss: 6.3841\n",
      "[3252/8000] D loss: 0.7266, G loss: 4.5588\n",
      "[3612/8000] D loss: 1.2646, G loss: 5.7608\n",
      "[3972/8000] D loss: 0.9619, G loss: 5.6543\n",
      "[4332/8000] D loss: 1.0874, G loss: 4.6321\n",
      "[4692/8000] D loss: 0.8221, G loss: 6.4234\n",
      "[5052/8000] D loss: 0.8010, G loss: 3.0793\n",
      "[5412/8000] D loss: 0.6059, G loss: 7.9838\n",
      "[5772/8000] D loss: 0.7648, G loss: 3.2399\n",
      "[6132/8000] D loss: 0.9580, G loss: 3.5569\n",
      "[6492/8000] D loss: 0.4759, G loss: 6.7622\n",
      "[6852/8000] D loss: 1.2040, G loss: 1.2021\n",
      "[7212/8000] D loss: 0.6300, G loss: 11.4086\n",
      "[7572/8000] D loss: 1.1705, G loss: 1.7375\n",
      "[7932/8000] D loss: 0.6573, G loss: 5.5981\n",
      "train error: \n",
      " D loss: 0.834910, G loss: 4.685380, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.986816, G loss: 14.001832, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0543, G loss: 2.4942\n",
      "[372/8000] D loss: 0.8156, G loss: 3.8656\n",
      "[732/8000] D loss: 0.8309, G loss: 8.3543\n",
      "[1092/8000] D loss: 0.2891, G loss: 11.8116\n",
      "[1452/8000] D loss: 1.0161, G loss: 5.1895\n",
      "[1812/8000] D loss: 0.7455, G loss: 3.3979\n",
      "[2172/8000] D loss: 0.8521, G loss: 2.9743\n",
      "[2532/8000] D loss: 0.8236, G loss: 3.4492\n",
      "[2892/8000] D loss: 0.9063, G loss: 5.6086\n",
      "[3252/8000] D loss: 0.9866, G loss: 3.4171\n",
      "[3612/8000] D loss: 0.6592, G loss: 6.1037\n",
      "[3972/8000] D loss: 0.7129, G loss: 6.4114\n",
      "[4332/8000] D loss: 0.6781, G loss: 4.6241\n",
      "[4692/8000] D loss: 0.9062, G loss: 3.9298\n",
      "[5052/8000] D loss: 1.0120, G loss: 8.9399\n",
      "[5412/8000] D loss: 1.0323, G loss: 7.6039\n",
      "[5772/8000] D loss: 1.1058, G loss: 1.6236\n",
      "[6132/8000] D loss: 0.9749, G loss: 5.1115\n",
      "[6492/8000] D loss: 0.8374, G loss: 4.8532\n",
      "[6852/8000] D loss: 0.6161, G loss: 6.5931\n",
      "[7212/8000] D loss: 0.8881, G loss: 6.8078\n",
      "[7572/8000] D loss: 0.9474, G loss: 2.3275\n",
      "[7932/8000] D loss: 0.7023, G loss: 4.5410\n",
      "train error: \n",
      " D loss: 0.833204, G loss: 4.850537, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.913395, G loss: 13.854487, D accuracy: 79.8%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6025, G loss: 3.5011\n",
      "[372/8000] D loss: 1.0592, G loss: 3.9331\n",
      "[732/8000] D loss: 0.4831, G loss: 7.0679\n",
      "[1092/8000] D loss: 1.0087, G loss: 3.1453\n",
      "[1452/8000] D loss: 0.7727, G loss: 6.0385\n",
      "[1812/8000] D loss: 0.4705, G loss: 8.0565\n",
      "[2172/8000] D loss: 1.1969, G loss: 1.7071\n",
      "[2532/8000] D loss: 0.6204, G loss: 5.9542\n",
      "[2892/8000] D loss: 0.8622, G loss: 7.2045\n",
      "[3252/8000] D loss: 0.7328, G loss: 3.7573\n",
      "[3612/8000] D loss: 0.9693, G loss: 1.9847\n",
      "[3972/8000] D loss: 0.7497, G loss: 4.7415\n",
      "[4332/8000] D loss: 0.8185, G loss: 6.1333\n",
      "[4692/8000] D loss: 0.7920, G loss: 5.0826\n",
      "[5052/8000] D loss: 0.7587, G loss: 3.9982\n",
      "[5412/8000] D loss: 0.6080, G loss: 7.5549\n",
      "[5772/8000] D loss: 0.5474, G loss: 8.2594\n",
      "[6132/8000] D loss: 0.9114, G loss: 4.1869\n",
      "[6492/8000] D loss: 1.0042, G loss: 3.3421\n",
      "[6852/8000] D loss: 0.6270, G loss: 7.1603\n",
      "[7212/8000] D loss: 0.6445, G loss: 9.4669\n",
      "[7572/8000] D loss: 0.8004, G loss: 4.2067\n",
      "[7932/8000] D loss: 0.7880, G loss: 4.2096\n",
      "train error: \n",
      " D loss: 0.830012, G loss: 5.436985, D accuracy: 73.0%, cell accuracy: 98.7%, board accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.947737, G loss: 15.044741, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6138, G loss: 5.6536\n",
      "[372/8000] D loss: 0.9736, G loss: 3.4251\n",
      "[732/8000] D loss: 0.6776, G loss: 5.0618\n",
      "[1092/8000] D loss: 0.7969, G loss: 3.7030\n",
      "[1452/8000] D loss: 0.7688, G loss: 3.5802\n",
      "[1812/8000] D loss: 0.8144, G loss: 6.1240\n",
      "[2172/8000] D loss: 1.0712, G loss: 3.5712\n",
      "[2532/8000] D loss: 0.9426, G loss: 4.5545\n",
      "[2892/8000] D loss: 1.2698, G loss: 1.1527\n",
      "[3252/8000] D loss: 0.8325, G loss: 4.6763\n",
      "[3612/8000] D loss: 1.0675, G loss: 2.6103\n",
      "[3972/8000] D loss: 0.6075, G loss: 5.8567\n",
      "[4332/8000] D loss: 0.8140, G loss: 5.2861\n",
      "[4692/8000] D loss: 0.6953, G loss: 3.9288\n",
      "[5052/8000] D loss: 0.9190, G loss: 6.4392\n",
      "[5412/8000] D loss: 1.0091, G loss: 2.0788\n",
      "[5772/8000] D loss: 0.9286, G loss: 2.9794\n",
      "[6132/8000] D loss: 0.9180, G loss: 5.9512\n",
      "[6492/8000] D loss: 0.9425, G loss: 3.4456\n",
      "[6852/8000] D loss: 0.8409, G loss: 6.7964\n",
      "[7212/8000] D loss: 0.8123, G loss: 5.4629\n",
      "[7572/8000] D loss: 0.9695, G loss: 3.9711\n",
      "[7932/8000] D loss: 0.8994, G loss: 5.0950\n",
      "train error: \n",
      " D loss: 0.826830, G loss: 6.274465, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.998474, G loss: 16.765647, D accuracy: 78.4%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9176, G loss: 1.5941\n",
      "[372/8000] D loss: 0.8780, G loss: 5.2402\n",
      "[732/8000] D loss: 0.7938, G loss: 5.2008\n",
      "[1092/8000] D loss: 0.7634, G loss: 7.8325\n",
      "[1452/8000] D loss: 0.9505, G loss: 5.8556\n",
      "[1812/8000] D loss: 0.7860, G loss: 3.4894\n",
      "[2172/8000] D loss: 1.0870, G loss: 5.4016\n",
      "[2532/8000] D loss: 0.4925, G loss: 10.6267\n",
      "[2892/8000] D loss: 1.0676, G loss: 1.7841\n",
      "[3252/8000] D loss: 0.4982, G loss: 6.6891\n",
      "[3612/8000] D loss: 1.1671, G loss: 5.0575\n",
      "[3972/8000] D loss: 0.7832, G loss: 5.0243\n",
      "[4332/8000] D loss: 0.7819, G loss: 4.6552\n",
      "[4692/8000] D loss: 0.6751, G loss: 7.6218\n",
      "[5052/8000] D loss: 1.2782, G loss: 2.0359\n",
      "[5412/8000] D loss: 0.7435, G loss: 5.5745\n",
      "[5772/8000] D loss: 1.0082, G loss: 3.9297\n",
      "[6132/8000] D loss: 1.1665, G loss: 3.7341\n",
      "[6492/8000] D loss: 0.6546, G loss: 4.8264\n",
      "[6852/8000] D loss: 0.6635, G loss: 8.5944\n",
      "[7212/8000] D loss: 0.8175, G loss: 2.8005\n",
      "[7572/8000] D loss: 0.7429, G loss: 5.1913\n",
      "[7932/8000] D loss: 0.6069, G loss: 8.0500\n",
      "train error: \n",
      " D loss: 0.819322, G loss: 5.664149, D accuracy: 73.8%, cell accuracy: 98.7%, board accuracy: 53.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.943077, G loss: 15.736640, D accuracy: 80.2%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7792, G loss: 5.6946\n",
      "[372/8000] D loss: 0.7851, G loss: 8.3323\n",
      "[732/8000] D loss: 1.0152, G loss: 4.6100\n",
      "[1092/8000] D loss: 0.7163, G loss: 5.1730\n",
      "[1452/8000] D loss: 0.8212, G loss: 3.7057\n",
      "[1812/8000] D loss: 0.8837, G loss: 6.6958\n",
      "[2172/8000] D loss: 0.7777, G loss: 10.2239\n",
      "[2532/8000] D loss: 1.0168, G loss: 5.3704\n",
      "[2892/8000] D loss: 0.5931, G loss: 7.3537\n",
      "[3252/8000] D loss: 0.7443, G loss: 6.3662\n",
      "[3612/8000] D loss: 0.9843, G loss: 2.9875\n",
      "[3972/8000] D loss: 0.9413, G loss: 2.6225\n",
      "[4332/8000] D loss: 0.8396, G loss: 5.4701\n",
      "[4692/8000] D loss: 0.8775, G loss: 4.0077\n",
      "[5052/8000] D loss: 0.3936, G loss: 10.8410\n",
      "[5412/8000] D loss: 0.9020, G loss: 5.0481\n",
      "[5772/8000] D loss: 0.7118, G loss: 5.6733\n",
      "[6132/8000] D loss: 0.8384, G loss: 4.7343\n",
      "[6492/8000] D loss: 0.7033, G loss: 3.8205\n",
      "[6852/8000] D loss: 0.6348, G loss: 7.6061\n",
      "[7212/8000] D loss: 0.5975, G loss: 5.2005\n",
      "[7572/8000] D loss: 0.5873, G loss: 4.8592\n",
      "[7932/8000] D loss: 1.0764, G loss: 2.7463\n",
      "train error: \n",
      " D loss: 0.841603, G loss: 5.100380, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.844920, G loss: 14.319882, D accuracy: 81.5%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7568, G loss: 4.1983\n",
      "[372/8000] D loss: 0.9679, G loss: 2.5768\n",
      "[732/8000] D loss: 0.6537, G loss: 7.4793\n",
      "[1092/8000] D loss: 0.9678, G loss: 2.6972\n",
      "[1452/8000] D loss: 0.9362, G loss: 3.3509\n",
      "[1812/8000] D loss: 0.6244, G loss: 6.0052\n",
      "[2172/8000] D loss: 0.8693, G loss: 5.0905\n",
      "[2532/8000] D loss: 0.8881, G loss: 2.9609\n",
      "[2892/8000] D loss: 0.6631, G loss: 5.1805\n",
      "[3252/8000] D loss: 1.2542, G loss: 4.9253\n",
      "[3612/8000] D loss: 0.5410, G loss: 11.2234\n",
      "[3972/8000] D loss: 0.7964, G loss: 11.6942\n",
      "[4332/8000] D loss: 0.8326, G loss: 6.0046\n",
      "[4692/8000] D loss: 0.8941, G loss: 3.5680\n",
      "[5052/8000] D loss: 0.3010, G loss: 13.1335\n",
      "[5412/8000] D loss: 0.9678, G loss: 6.1428\n",
      "[5772/8000] D loss: 0.9260, G loss: 4.0297\n",
      "[6132/8000] D loss: 0.5604, G loss: 4.3149\n",
      "[6492/8000] D loss: 0.8464, G loss: 3.6946\n",
      "[6852/8000] D loss: 0.7267, G loss: 5.3948\n",
      "[7212/8000] D loss: 0.8057, G loss: 6.2465\n",
      "[7572/8000] D loss: 0.3728, G loss: 10.8446\n",
      "[7932/8000] D loss: 0.7242, G loss: 6.5067\n",
      "train error: \n",
      " D loss: 0.810079, G loss: 6.029587, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 53.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.905457, G loss: 16.216429, D accuracy: 78.2%, cell accuracy: 98.2%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5498, G loss: 6.2301\n",
      "[372/8000] D loss: 0.7714, G loss: 4.7835\n",
      "[732/8000] D loss: 0.8632, G loss: 2.2510\n",
      "[1092/8000] D loss: 0.8171, G loss: 2.8634\n",
      "[1452/8000] D loss: 1.1086, G loss: 2.1239\n",
      "[1812/8000] D loss: 0.7271, G loss: 7.8351\n",
      "[2172/8000] D loss: 0.3711, G loss: 9.7099\n",
      "[2532/8000] D loss: 0.6928, G loss: 7.5101\n",
      "[2892/8000] D loss: 0.9971, G loss: 1.7325\n",
      "[3252/8000] D loss: 1.0482, G loss: 7.4275\n",
      "[3612/8000] D loss: 0.8466, G loss: 3.3553\n",
      "[3972/8000] D loss: 0.7092, G loss: 8.2381\n",
      "[4332/8000] D loss: 0.6290, G loss: 6.5548\n",
      "[4692/8000] D loss: 1.2236, G loss: 2.2624\n",
      "[5052/8000] D loss: 0.3703, G loss: 5.4651\n",
      "[5412/8000] D loss: 1.0114, G loss: 1.6501\n",
      "[5772/8000] D loss: 0.6696, G loss: 9.7562\n",
      "[6132/8000] D loss: 0.9510, G loss: 5.1455\n",
      "[6492/8000] D loss: 0.8017, G loss: 3.2692\n",
      "[6852/8000] D loss: 0.9649, G loss: 6.1164\n",
      "[7212/8000] D loss: 0.7570, G loss: 8.0475\n",
      "[7572/8000] D loss: 0.9575, G loss: 2.8519\n",
      "[7932/8000] D loss: 0.8324, G loss: 5.5248\n",
      "train error: \n",
      " D loss: 0.821213, G loss: 6.201829, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.004120, G loss: 16.433506, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6939, G loss: 5.4508\n",
      "[372/8000] D loss: 0.6748, G loss: 5.3139\n",
      "[732/8000] D loss: 1.0725, G loss: 5.6224\n",
      "[1092/8000] D loss: 0.7191, G loss: 6.4912\n",
      "[1452/8000] D loss: 0.9954, G loss: 5.3027\n",
      "[1812/8000] D loss: 0.4673, G loss: 7.0979\n",
      "[2172/8000] D loss: 0.6210, G loss: 6.0462\n",
      "[2532/8000] D loss: 0.9473, G loss: 4.1291\n",
      "[2892/8000] D loss: 0.8254, G loss: 4.5110\n",
      "[3252/8000] D loss: 1.1247, G loss: 5.1160\n",
      "[3612/8000] D loss: 0.7443, G loss: 5.0658\n",
      "[3972/8000] D loss: 0.6349, G loss: 4.9202\n",
      "[4332/8000] D loss: 0.9160, G loss: 6.0107\n",
      "[4692/8000] D loss: 0.7057, G loss: 6.6539\n",
      "[5052/8000] D loss: 0.8851, G loss: 5.2092\n",
      "[5412/8000] D loss: 1.3170, G loss: 1.7696\n",
      "[5772/8000] D loss: 0.8434, G loss: 6.0064\n",
      "[6132/8000] D loss: 0.8413, G loss: 8.3377\n",
      "[6492/8000] D loss: 0.6893, G loss: 9.0026\n",
      "[6852/8000] D loss: 0.6677, G loss: 10.2643\n",
      "[7212/8000] D loss: 0.7800, G loss: 5.7369\n",
      "[7572/8000] D loss: 0.8152, G loss: 2.3217\n",
      "[7932/8000] D loss: 0.8714, G loss: 3.3023\n",
      "train error: \n",
      " D loss: 0.845575, G loss: 4.266120, D accuracy: 73.0%, cell accuracy: 98.7%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.818348, G loss: 13.375772, D accuracy: 81.9%, cell accuracy: 98.2%, board accuracy: 26.0% \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6970, G loss: 3.7232\n",
      "[372/8000] D loss: 1.0415, G loss: 1.5295\n",
      "[732/8000] D loss: 0.7484, G loss: 4.8970\n",
      "[1092/8000] D loss: 1.0430, G loss: 2.5376\n",
      "[1452/8000] D loss: 0.5966, G loss: 10.5302\n",
      "[1812/8000] D loss: 0.7388, G loss: 4.5394\n",
      "[2172/8000] D loss: 1.2297, G loss: 3.3114\n",
      "[2532/8000] D loss: 0.7106, G loss: 5.0049\n",
      "[2892/8000] D loss: 0.6200, G loss: 6.3374\n",
      "[3252/8000] D loss: 0.6887, G loss: 8.6697\n",
      "[3612/8000] D loss: 0.9926, G loss: 5.2059\n",
      "[3972/8000] D loss: 0.7461, G loss: 6.3697\n",
      "[4332/8000] D loss: 0.8624, G loss: 6.5028\n",
      "[4692/8000] D loss: 0.6856, G loss: 8.9189\n",
      "[5052/8000] D loss: 0.4961, G loss: 7.9848\n",
      "[5412/8000] D loss: 0.4495, G loss: 9.1909\n",
      "[5772/8000] D loss: 0.6094, G loss: 8.9810\n",
      "[6132/8000] D loss: 1.1001, G loss: 3.8485\n",
      "[6492/8000] D loss: 0.4906, G loss: 5.8345\n",
      "[6852/8000] D loss: 0.6901, G loss: 6.2786\n",
      "[7212/8000] D loss: 1.0393, G loss: 3.7032\n",
      "[7572/8000] D loss: 0.4707, G loss: 6.3494\n",
      "[7932/8000] D loss: 0.9831, G loss: 2.3121\n",
      "train error: \n",
      " D loss: 0.854891, G loss: 4.995253, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.077958, G loss: 13.062223, D accuracy: 75.6%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9901, G loss: 3.7805\n",
      "[372/8000] D loss: 0.6905, G loss: 6.3009\n",
      "[732/8000] D loss: 0.7747, G loss: 5.2620\n",
      "[1092/8000] D loss: 0.7121, G loss: 4.0346\n",
      "[1452/8000] D loss: 0.8780, G loss: 4.2811\n",
      "[1812/8000] D loss: 0.5914, G loss: 8.0494\n",
      "[2172/8000] D loss: 0.8618, G loss: 8.2901\n",
      "[2532/8000] D loss: 0.7497, G loss: 9.1761\n",
      "[2892/8000] D loss: 1.0754, G loss: 2.5169\n",
      "[3252/8000] D loss: 0.9396, G loss: 3.9212\n",
      "[3612/8000] D loss: 0.8027, G loss: 5.5261\n",
      "[3972/8000] D loss: 1.0402, G loss: 4.6792\n",
      "[4332/8000] D loss: 0.4381, G loss: 10.2629\n",
      "[4692/8000] D loss: 0.4302, G loss: 10.1438\n",
      "[5052/8000] D loss: 0.9170, G loss: 3.5393\n",
      "[5412/8000] D loss: 0.7437, G loss: 9.8224\n",
      "[5772/8000] D loss: 0.7623, G loss: 4.4879\n",
      "[6132/8000] D loss: 0.6783, G loss: 7.7195\n",
      "[6492/8000] D loss: 0.5506, G loss: 10.4890\n",
      "[6852/8000] D loss: 0.5564, G loss: 5.1329\n",
      "[7212/8000] D loss: 0.6669, G loss: 5.5813\n",
      "[7572/8000] D loss: 0.6708, G loss: 3.7370\n",
      "[7932/8000] D loss: 0.9397, G loss: 7.2108\n",
      "train error: \n",
      " D loss: 0.810705, G loss: 6.264811, D accuracy: 73.9%, cell accuracy: 98.7%, board accuracy: 52.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.941963, G loss: 16.652373, D accuracy: 78.5%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6868, G loss: 11.9705\n",
      "[372/8000] D loss: 0.9522, G loss: 4.2338\n",
      "[732/8000] D loss: 0.6771, G loss: 4.2743\n",
      "[1092/8000] D loss: 1.2770, G loss: 0.8049\n",
      "[1452/8000] D loss: 0.7703, G loss: 4.2140\n",
      "[1812/8000] D loss: 0.7930, G loss: 7.1113\n",
      "[2172/8000] D loss: 0.4729, G loss: 8.8989\n",
      "[2532/8000] D loss: 1.0638, G loss: 5.1374\n",
      "[2892/8000] D loss: 0.6462, G loss: 10.8276\n",
      "[3252/8000] D loss: 0.8322, G loss: 5.1239\n",
      "[3612/8000] D loss: 0.5019, G loss: 14.0057\n",
      "[3972/8000] D loss: 1.0668, G loss: 1.7794\n",
      "[4332/8000] D loss: 0.6101, G loss: 3.3359\n",
      "[4692/8000] D loss: 0.8314, G loss: 7.8647\n",
      "[5052/8000] D loss: 0.9073, G loss: 5.2998\n",
      "[5412/8000] D loss: 0.9420, G loss: 2.4057\n",
      "[5772/8000] D loss: 0.6497, G loss: 5.6369\n",
      "[6132/8000] D loss: 0.9090, G loss: 5.5727\n",
      "[6492/8000] D loss: 0.6130, G loss: 11.0227\n",
      "[6852/8000] D loss: 0.3784, G loss: 6.8658\n",
      "[7212/8000] D loss: 1.1681, G loss: 1.3014\n",
      "[7572/8000] D loss: 0.8245, G loss: 5.3122\n",
      "[7932/8000] D loss: 1.0554, G loss: 2.6822\n",
      "train error: \n",
      " D loss: 0.845679, G loss: 4.494579, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.820019, G loss: 13.454410, D accuracy: 82.0%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8476, G loss: 5.0418\n",
      "[372/8000] D loss: 1.0034, G loss: 4.2579\n",
      "[732/8000] D loss: 0.3282, G loss: 8.4491\n",
      "[1092/8000] D loss: 0.6270, G loss: 7.0855\n",
      "[1452/8000] D loss: 0.9556, G loss: 3.6221\n",
      "[1812/8000] D loss: 1.1109, G loss: 3.3361\n",
      "[2172/8000] D loss: 0.6198, G loss: 5.7536\n",
      "[2532/8000] D loss: 1.2295, G loss: 2.5462\n",
      "[2892/8000] D loss: 1.3847, G loss: 1.2117\n",
      "[3252/8000] D loss: 0.8229, G loss: 7.3717\n",
      "[3612/8000] D loss: 0.7204, G loss: 6.6454\n",
      "[3972/8000] D loss: 0.5918, G loss: 8.5471\n",
      "[4332/8000] D loss: 0.4887, G loss: 6.1477\n",
      "[4692/8000] D loss: 1.0000, G loss: 3.4848\n",
      "[5052/8000] D loss: 1.0467, G loss: 2.5087\n",
      "[5412/8000] D loss: 0.9341, G loss: 4.2028\n",
      "[5772/8000] D loss: 1.0853, G loss: 2.9569\n",
      "[6132/8000] D loss: 0.9152, G loss: 3.3282\n",
      "[6492/8000] D loss: 0.5749, G loss: 12.7405\n",
      "[6852/8000] D loss: 1.1222, G loss: 4.6978\n",
      "[7212/8000] D loss: 1.1947, G loss: 5.0308\n",
      "[7572/8000] D loss: 0.9242, G loss: 3.4211\n",
      "[7932/8000] D loss: 1.1390, G loss: 4.0372\n",
      "train error: \n",
      " D loss: 0.837222, G loss: 6.211588, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.105193, G loss: 16.448157, D accuracy: 74.6%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7433, G loss: 3.8109\n",
      "[372/8000] D loss: 0.7941, G loss: 4.9054\n",
      "[732/8000] D loss: 0.6890, G loss: 6.1104\n",
      "[1092/8000] D loss: 0.8486, G loss: 4.6200\n",
      "[1452/8000] D loss: 1.1576, G loss: 4.8475\n",
      "[1812/8000] D loss: 1.0340, G loss: 6.5072\n",
      "[2172/8000] D loss: 1.0393, G loss: 2.8524\n",
      "[2532/8000] D loss: 0.9690, G loss: 4.0801\n",
      "[2892/8000] D loss: 0.2771, G loss: 7.0808\n",
      "[3252/8000] D loss: 1.2009, G loss: 3.8657\n",
      "[3612/8000] D loss: 1.1918, G loss: 1.9266\n",
      "[3972/8000] D loss: 0.5181, G loss: 11.2828\n",
      "[4332/8000] D loss: 0.7182, G loss: 5.1726\n",
      "[4692/8000] D loss: 1.3257, G loss: 2.4368\n",
      "[5052/8000] D loss: 0.9081, G loss: 1.9526\n",
      "[5412/8000] D loss: 0.7343, G loss: 5.9367\n",
      "[5772/8000] D loss: 0.8751, G loss: 7.0557\n",
      "[6132/8000] D loss: 0.6145, G loss: 6.4409\n",
      "[6492/8000] D loss: 0.5925, G loss: 9.5639\n",
      "[6852/8000] D loss: 0.9089, G loss: 2.4615\n",
      "[7212/8000] D loss: 0.8025, G loss: 5.3305\n",
      "[7572/8000] D loss: 0.9807, G loss: 4.4698\n",
      "[7932/8000] D loss: 0.8708, G loss: 5.1787\n",
      "train error: \n",
      " D loss: 0.815224, G loss: 5.957544, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 53.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.946831, G loss: 16.441656, D accuracy: 78.3%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0385, G loss: 2.8070\n",
      "[372/8000] D loss: 1.1804, G loss: 3.9872\n",
      "[732/8000] D loss: 0.5277, G loss: 5.8043\n",
      "[1092/8000] D loss: 0.6490, G loss: 7.2633\n",
      "[1452/8000] D loss: 0.8265, G loss: 6.0636\n",
      "[1812/8000] D loss: 0.9953, G loss: 3.6787\n",
      "[2172/8000] D loss: 1.0065, G loss: 7.2647\n",
      "[2532/8000] D loss: 0.7684, G loss: 3.3023\n",
      "[2892/8000] D loss: 0.5851, G loss: 5.5224\n",
      "[3252/8000] D loss: 0.9437, G loss: 5.1522\n",
      "[3612/8000] D loss: 0.6515, G loss: 6.9344\n",
      "[3972/8000] D loss: 0.8304, G loss: 6.3305\n",
      "[4332/8000] D loss: 0.7318, G loss: 5.9991\n",
      "[4692/8000] D loss: 0.6600, G loss: 9.3211\n",
      "[5052/8000] D loss: 0.7544, G loss: 3.9060\n",
      "[5412/8000] D loss: 0.9376, G loss: 1.5595\n",
      "[5772/8000] D loss: 0.9296, G loss: 5.5404\n",
      "[6132/8000] D loss: 0.7227, G loss: 8.6191\n",
      "[6492/8000] D loss: 0.8292, G loss: 4.8034\n",
      "[6852/8000] D loss: 0.9436, G loss: 5.3406\n",
      "[7212/8000] D loss: 0.8725, G loss: 6.3932\n",
      "[7572/8000] D loss: 0.8735, G loss: 4.4634\n",
      "[7932/8000] D loss: 0.7482, G loss: 5.1000\n",
      "train error: \n",
      " D loss: 0.815299, G loss: 5.303298, D accuracy: 73.9%, cell accuracy: 98.7%, board accuracy: 54.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.921569, G loss: 15.650478, D accuracy: 81.0%, cell accuracy: 98.2%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7119, G loss: 7.2217\n",
      "[372/8000] D loss: 0.7879, G loss: 6.6144\n",
      "[732/8000] D loss: 1.0759, G loss: 4.6469\n",
      "[1092/8000] D loss: 0.9596, G loss: 3.2506\n",
      "[1452/8000] D loss: 0.7347, G loss: 6.3665\n",
      "[1812/8000] D loss: 1.0221, G loss: 1.9268\n",
      "[2172/8000] D loss: 0.8465, G loss: 4.8657\n",
      "[2532/8000] D loss: 0.5148, G loss: 8.0323\n",
      "[2892/8000] D loss: 1.2378, G loss: 1.9910\n",
      "[3252/8000] D loss: 0.8325, G loss: 8.2481\n",
      "[3612/8000] D loss: 0.9515, G loss: 3.6326\n",
      "[3972/8000] D loss: 0.6462, G loss: 8.2568\n",
      "[4332/8000] D loss: 0.8076, G loss: 4.9093\n",
      "[4692/8000] D loss: 0.7101, G loss: 3.9008\n",
      "[5052/8000] D loss: 0.8876, G loss: 3.3364\n",
      "[5412/8000] D loss: 0.5944, G loss: 5.4135\n",
      "[5772/8000] D loss: 0.7014, G loss: 4.9645\n",
      "[6132/8000] D loss: 0.7960, G loss: 6.2922\n",
      "[6492/8000] D loss: 0.7810, G loss: 4.1434\n",
      "[6852/8000] D loss: 0.8114, G loss: 2.9445\n",
      "[7212/8000] D loss: 0.3456, G loss: 9.5758\n",
      "[7572/8000] D loss: 0.7803, G loss: 4.8254\n",
      "[7932/8000] D loss: 0.7738, G loss: 4.2979\n",
      "train error: \n",
      " D loss: 0.854980, G loss: 6.860568, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.135601, G loss: 17.779147, D accuracy: 74.6%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9938, G loss: 7.3754\n",
      "[372/8000] D loss: 1.3597, G loss: 2.7875\n",
      "[732/8000] D loss: 0.7173, G loss: 6.7635\n",
      "[1092/8000] D loss: 1.0712, G loss: 2.7873\n",
      "[1452/8000] D loss: 0.6399, G loss: 4.3266\n",
      "[1812/8000] D loss: 1.0035, G loss: 3.4254\n",
      "[2172/8000] D loss: 0.8052, G loss: 4.5003\n",
      "[2532/8000] D loss: 1.0949, G loss: 5.7132\n",
      "[2892/8000] D loss: 1.3305, G loss: 0.7308\n",
      "[3252/8000] D loss: 0.7354, G loss: 2.6931\n",
      "[3612/8000] D loss: 0.9594, G loss: 2.8911\n",
      "[3972/8000] D loss: 0.6122, G loss: 8.2010\n",
      "[4332/8000] D loss: 1.0182, G loss: 3.1192\n",
      "[4692/8000] D loss: 0.6423, G loss: 6.8622\n",
      "[5052/8000] D loss: 0.4855, G loss: 5.4532\n",
      "[5412/8000] D loss: 1.0684, G loss: 2.2708\n",
      "[5772/8000] D loss: 0.8173, G loss: 4.1824\n",
      "[6132/8000] D loss: 0.6323, G loss: 5.4725\n",
      "[6492/8000] D loss: 0.7757, G loss: 5.0917\n",
      "[6852/8000] D loss: 0.7404, G loss: 5.4868\n",
      "[7212/8000] D loss: 0.9689, G loss: 7.0600\n",
      "[7572/8000] D loss: 0.9921, G loss: 4.7761\n",
      "[7932/8000] D loss: 0.9608, G loss: 1.9980\n",
      "train error: \n",
      " D loss: 0.820167, G loss: 6.412710, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.005073, G loss: 17.539186, D accuracy: 75.1%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6116, G loss: 6.1878\n",
      "[372/8000] D loss: 0.9105, G loss: 5.2030\n",
      "[732/8000] D loss: 0.4806, G loss: 8.3562\n",
      "[1092/8000] D loss: 0.6116, G loss: 5.9935\n",
      "[1452/8000] D loss: 0.5051, G loss: 9.2490\n",
      "[1812/8000] D loss: 0.8546, G loss: 4.3824\n",
      "[2172/8000] D loss: 0.8546, G loss: 3.4469\n",
      "[2532/8000] D loss: 0.9952, G loss: 2.7437\n",
      "[2892/8000] D loss: 0.9539, G loss: 4.2619\n",
      "[3252/8000] D loss: 0.9438, G loss: 5.3119\n",
      "[3612/8000] D loss: 0.8327, G loss: 7.6005\n",
      "[3972/8000] D loss: 0.6897, G loss: 12.9931\n",
      "[4332/8000] D loss: 0.8922, G loss: 3.6398\n",
      "[4692/8000] D loss: 0.9742, G loss: 3.4171\n",
      "[5052/8000] D loss: 0.8367, G loss: 4.8008\n",
      "[5412/8000] D loss: 0.6217, G loss: 10.8408\n",
      "[5772/8000] D loss: 0.6212, G loss: 12.1755\n",
      "[6132/8000] D loss: 0.6229, G loss: 8.2190\n",
      "[6492/8000] D loss: 0.8331, G loss: 5.3749\n",
      "[6852/8000] D loss: 0.9859, G loss: 3.1652\n",
      "[7212/8000] D loss: 0.9261, G loss: 4.0169\n",
      "[7572/8000] D loss: 0.6208, G loss: 4.1884\n",
      "[7932/8000] D loss: 0.8831, G loss: 4.1635\n",
      "train error: \n",
      " D loss: 0.833414, G loss: 5.110396, D accuracy: 73.8%, cell accuracy: 98.7%, board accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.865277, G loss: 15.172445, D accuracy: 82.2%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7483, G loss: 4.7460\n",
      "[372/8000] D loss: 0.6520, G loss: 5.8755\n",
      "[732/8000] D loss: 0.9369, G loss: 6.0668\n",
      "[1092/8000] D loss: 0.4442, G loss: 6.4147\n",
      "[1452/8000] D loss: 0.9091, G loss: 5.7658\n",
      "[1812/8000] D loss: 0.8079, G loss: 4.1117\n",
      "[2172/8000] D loss: 0.7047, G loss: 4.2565\n",
      "[2532/8000] D loss: 0.9971, G loss: 4.6876\n",
      "[2892/8000] D loss: 0.7999, G loss: 3.1813\n",
      "[3252/8000] D loss: 0.7527, G loss: 2.5512\n",
      "[3612/8000] D loss: 0.4348, G loss: 10.8088\n",
      "[3972/8000] D loss: 0.5797, G loss: 11.3418\n",
      "[4332/8000] D loss: 1.2518, G loss: 4.8239\n",
      "[4692/8000] D loss: 0.7351, G loss: 8.3951\n",
      "[5052/8000] D loss: 0.8732, G loss: 2.9266\n",
      "[5412/8000] D loss: 0.5657, G loss: 10.5974\n",
      "[5772/8000] D loss: 0.8828, G loss: 2.8506\n",
      "[6132/8000] D loss: 0.8877, G loss: 1.9672\n",
      "[6492/8000] D loss: 0.9349, G loss: 3.5770\n",
      "[6852/8000] D loss: 0.9831, G loss: 1.7357\n",
      "[7212/8000] D loss: 0.8273, G loss: 6.4213\n",
      "[7572/8000] D loss: 0.9408, G loss: 2.1844\n",
      "[7932/8000] D loss: 0.7768, G loss: 4.1449\n",
      "train error: \n",
      " D loss: 0.837335, G loss: 4.968975, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.994387, G loss: 13.946936, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7157, G loss: 10.3783\n",
      "[372/8000] D loss: 0.5174, G loss: 6.3592\n",
      "[732/8000] D loss: 0.7401, G loss: 7.3254\n",
      "[1092/8000] D loss: 0.7387, G loss: 2.9822\n",
      "[1452/8000] D loss: 0.6231, G loss: 7.4640\n",
      "[1812/8000] D loss: 1.0153, G loss: 5.5897\n",
      "[2172/8000] D loss: 1.1120, G loss: 2.8447\n",
      "[2532/8000] D loss: 1.1761, G loss: 5.2058\n",
      "[2892/8000] D loss: 0.6426, G loss: 7.1857\n",
      "[3252/8000] D loss: 0.9518, G loss: 1.8049\n",
      "[3612/8000] D loss: 0.6008, G loss: 5.2956\n",
      "[3972/8000] D loss: 1.0649, G loss: 5.6951\n",
      "[4332/8000] D loss: 0.9672, G loss: 5.8622\n",
      "[4692/8000] D loss: 0.8828, G loss: 3.3561\n",
      "[5052/8000] D loss: 0.7718, G loss: 6.4077\n",
      "[5412/8000] D loss: 0.6636, G loss: 5.9283\n",
      "[5772/8000] D loss: 0.6098, G loss: 7.4280\n",
      "[6132/8000] D loss: 0.8616, G loss: 3.6046\n",
      "[6492/8000] D loss: 0.7611, G loss: 4.6131\n",
      "[6852/8000] D loss: 0.9132, G loss: 3.7310\n",
      "[7212/8000] D loss: 0.6932, G loss: 7.4889\n",
      "[7572/8000] D loss: 0.5591, G loss: 5.3261\n",
      "[7932/8000] D loss: 0.7371, G loss: 5.9496\n",
      "train error: \n",
      " D loss: 0.830439, G loss: 6.221962, D accuracy: 73.0%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.048409, G loss: 16.480009, D accuracy: 76.4%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5370, G loss: 10.0100\n",
      "[372/8000] D loss: 0.9420, G loss: 5.7212\n",
      "[732/8000] D loss: 0.5732, G loss: 6.7099\n",
      "[1092/8000] D loss: 0.6414, G loss: 4.8327\n",
      "[1452/8000] D loss: 1.0053, G loss: 5.0612\n",
      "[1812/8000] D loss: 0.8039, G loss: 3.9546\n",
      "[2172/8000] D loss: 1.1480, G loss: 5.4679\n",
      "[2532/8000] D loss: 0.8448, G loss: 8.9471\n",
      "[2892/8000] D loss: 0.6603, G loss: 8.5634\n",
      "[3252/8000] D loss: 0.9973, G loss: 3.3796\n",
      "[3612/8000] D loss: 0.3370, G loss: 9.6632\n",
      "[3972/8000] D loss: 1.1097, G loss: 5.9632\n",
      "[4332/8000] D loss: 1.0897, G loss: 2.6314\n",
      "[4692/8000] D loss: 0.9438, G loss: 4.7098\n",
      "[5052/8000] D loss: 0.9214, G loss: 7.3009\n",
      "[5412/8000] D loss: 0.8904, G loss: 3.1216\n",
      "[5772/8000] D loss: 0.8021, G loss: 3.9556\n",
      "[6132/8000] D loss: 0.7145, G loss: 3.1280\n",
      "[6492/8000] D loss: 0.7980, G loss: 5.6064\n",
      "[6852/8000] D loss: 0.9772, G loss: 2.6818\n",
      "[7212/8000] D loss: 0.7981, G loss: 6.4915\n",
      "[7572/8000] D loss: 0.5348, G loss: 7.2341\n",
      "[7932/8000] D loss: 0.7872, G loss: 3.2236\n",
      "train error: \n",
      " D loss: 0.824731, G loss: 5.093878, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.872402, G loss: 14.492307, D accuracy: 81.4%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9374, G loss: 4.6328\n",
      "[372/8000] D loss: 0.5852, G loss: 5.0357\n",
      "[732/8000] D loss: 0.6606, G loss: 11.8700\n",
      "[1092/8000] D loss: 1.1444, G loss: 3.2120\n",
      "[1452/8000] D loss: 0.9446, G loss: 4.0844\n",
      "[1812/8000] D loss: 0.8546, G loss: 4.9892\n",
      "[2172/8000] D loss: 0.8931, G loss: 4.1634\n",
      "[2532/8000] D loss: 0.6033, G loss: 7.8525\n",
      "[2892/8000] D loss: 1.0255, G loss: 3.5368\n",
      "[3252/8000] D loss: 0.9307, G loss: 4.7836\n",
      "[3612/8000] D loss: 0.8317, G loss: 3.4286\n",
      "[3972/8000] D loss: 0.8057, G loss: 5.6925\n",
      "[4332/8000] D loss: 0.9588, G loss: 4.8744\n",
      "[4692/8000] D loss: 0.6007, G loss: 9.1174\n",
      "[5052/8000] D loss: 0.9216, G loss: 3.6972\n",
      "[5412/8000] D loss: 0.9153, G loss: 6.3952\n",
      "[5772/8000] D loss: 0.8639, G loss: 8.0821\n",
      "[6132/8000] D loss: 0.7683, G loss: 6.8548\n",
      "[6492/8000] D loss: 0.7313, G loss: 5.2631\n",
      "[6852/8000] D loss: 0.7671, G loss: 6.8833\n",
      "[7212/8000] D loss: 1.0309, G loss: 4.6260\n",
      "[7572/8000] D loss: 1.2593, G loss: 2.0099\n",
      "[7932/8000] D loss: 0.6326, G loss: 9.7770\n",
      "train error: \n",
      " D loss: 0.824864, G loss: 5.327962, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.901344, G loss: 14.799435, D accuracy: 81.2%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4860, G loss: 8.6588\n",
      "[372/8000] D loss: 0.7708, G loss: 6.1324\n",
      "[732/8000] D loss: 0.9335, G loss: 2.6259\n",
      "[1092/8000] D loss: 0.9000, G loss: 5.2906\n",
      "[1452/8000] D loss: 0.3819, G loss: 8.2693\n",
      "[1812/8000] D loss: 0.8354, G loss: 7.2449\n",
      "[2172/8000] D loss: 0.6560, G loss: 4.5852\n",
      "[2532/8000] D loss: 1.2673, G loss: 3.8066\n",
      "[2892/8000] D loss: 0.9896, G loss: 6.0440\n",
      "[3252/8000] D loss: 0.8364, G loss: 8.3397\n",
      "[3612/8000] D loss: 0.9445, G loss: 3.5414\n",
      "[3972/8000] D loss: 0.9940, G loss: 1.3485\n",
      "[4332/8000] D loss: 0.7333, G loss: 4.9593\n",
      "[4692/8000] D loss: 0.9419, G loss: 8.9769\n",
      "[5052/8000] D loss: 0.6935, G loss: 3.8897\n",
      "[5412/8000] D loss: 0.7386, G loss: 5.1141\n",
      "[5772/8000] D loss: 0.5630, G loss: 5.2501\n",
      "[6132/8000] D loss: 0.9789, G loss: 3.9601\n",
      "[6492/8000] D loss: 1.1167, G loss: 3.2782\n",
      "[6852/8000] D loss: 0.7038, G loss: 4.4913\n",
      "[7212/8000] D loss: 0.9733, G loss: 3.9074\n",
      "[7572/8000] D loss: 1.0601, G loss: 1.9383\n",
      "[7932/8000] D loss: 0.9332, G loss: 6.0848\n",
      "train error: \n",
      " D loss: 0.828352, G loss: 6.055014, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.967707, G loss: 16.839506, D accuracy: 79.8%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8306, G loss: 7.0593\n",
      "[372/8000] D loss: 1.0255, G loss: 5.1765\n",
      "[732/8000] D loss: 0.8099, G loss: 5.3869\n",
      "[1092/8000] D loss: 0.8742, G loss: 2.2722\n",
      "[1452/8000] D loss: 0.6140, G loss: 9.0705\n",
      "[1812/8000] D loss: 0.4656, G loss: 7.2255\n",
      "[2172/8000] D loss: 0.5974, G loss: 7.7928\n",
      "[2532/8000] D loss: 0.8171, G loss: 3.9531\n",
      "[2892/8000] D loss: 1.0158, G loss: 3.7890\n",
      "[3252/8000] D loss: 0.7451, G loss: 3.3153\n",
      "[3612/8000] D loss: 0.9240, G loss: 6.1101\n",
      "[3972/8000] D loss: 0.8694, G loss: 4.2127\n",
      "[4332/8000] D loss: 0.6071, G loss: 10.4022\n",
      "[4692/8000] D loss: 0.8989, G loss: 4.9356\n",
      "[5052/8000] D loss: 0.8444, G loss: 4.5069\n",
      "[5412/8000] D loss: 0.8672, G loss: 4.7333\n",
      "[5772/8000] D loss: 0.8088, G loss: 2.5859\n",
      "[6132/8000] D loss: 0.7674, G loss: 3.0203\n",
      "[6492/8000] D loss: 0.9634, G loss: 2.7270\n",
      "[6852/8000] D loss: 0.8690, G loss: 4.0905\n",
      "[7212/8000] D loss: 0.9714, G loss: 4.8512\n",
      "[7572/8000] D loss: 0.4934, G loss: 5.9719\n",
      "[7932/8000] D loss: 0.5722, G loss: 5.5530\n",
      "train error: \n",
      " D loss: 0.837292, G loss: 4.995096, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.899534, G loss: 14.852881, D accuracy: 81.6%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5364, G loss: 5.3585\n",
      "[372/8000] D loss: 0.8443, G loss: 6.1784\n",
      "[732/8000] D loss: 0.4783, G loss: 8.6528\n",
      "[1092/8000] D loss: 1.3400, G loss: 0.8598\n",
      "[1452/8000] D loss: 0.7204, G loss: 7.5777\n",
      "[1812/8000] D loss: 0.8757, G loss: 4.6733\n",
      "[2172/8000] D loss: 0.9963, G loss: 4.0495\n",
      "[2532/8000] D loss: 0.5707, G loss: 8.2989\n",
      "[2892/8000] D loss: 0.4198, G loss: 6.8220\n",
      "[3252/8000] D loss: 1.0117, G loss: 3.8954\n",
      "[3612/8000] D loss: 0.7849, G loss: 7.6996\n",
      "[3972/8000] D loss: 0.6287, G loss: 6.6594\n",
      "[4332/8000] D loss: 0.7526, G loss: 3.9104\n",
      "[4692/8000] D loss: 0.6650, G loss: 5.6271\n",
      "[5052/8000] D loss: 1.1599, G loss: 2.8004\n",
      "[5412/8000] D loss: 0.7219, G loss: 3.6034\n",
      "[5772/8000] D loss: 0.4733, G loss: 10.1459\n",
      "[6132/8000] D loss: 0.8361, G loss: 6.9156\n",
      "[6492/8000] D loss: 0.6361, G loss: 4.1395\n",
      "[6852/8000] D loss: 1.1083, G loss: 5.9528\n",
      "[7212/8000] D loss: 0.8314, G loss: 6.2683\n",
      "[7572/8000] D loss: 1.0078, G loss: 2.9874\n",
      "[7932/8000] D loss: 0.7825, G loss: 6.0716\n",
      "train error: \n",
      " D loss: 0.829138, G loss: 5.965203, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 55.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.920384, G loss: 16.758053, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6656, G loss: 7.4022\n",
      "[372/8000] D loss: 0.8724, G loss: 7.2997\n",
      "[732/8000] D loss: 0.7557, G loss: 4.5448\n",
      "[1092/8000] D loss: 0.3695, G loss: 10.7360\n",
      "[1452/8000] D loss: 0.8185, G loss: 5.5805\n",
      "[1812/8000] D loss: 0.4009, G loss: 9.9096\n",
      "[2172/8000] D loss: 0.9105, G loss: 7.0554\n",
      "[2532/8000] D loss: 0.5087, G loss: 13.3421\n",
      "[2892/8000] D loss: 0.9736, G loss: 5.4516\n",
      "[3252/8000] D loss: 1.0336, G loss: 3.3173\n",
      "[3612/8000] D loss: 0.6761, G loss: 5.0233\n",
      "[3972/8000] D loss: 0.6538, G loss: 4.4802\n",
      "[4332/8000] D loss: 0.8404, G loss: 6.1873\n",
      "[4692/8000] D loss: 0.7896, G loss: 4.7868\n",
      "[5052/8000] D loss: 0.5467, G loss: 8.8146\n",
      "[5412/8000] D loss: 0.8592, G loss: 4.7563\n",
      "[5772/8000] D loss: 0.8521, G loss: 4.6328\n",
      "[6132/8000] D loss: 0.4763, G loss: 11.1898\n",
      "[6492/8000] D loss: 0.7360, G loss: 4.2248\n",
      "[6852/8000] D loss: 0.5847, G loss: 4.0730\n",
      "[7212/8000] D loss: 0.4025, G loss: 12.2859\n",
      "[7572/8000] D loss: 0.6731, G loss: 10.2089\n",
      "[7932/8000] D loss: 0.7937, G loss: 6.5693\n",
      "train error: \n",
      " D loss: 0.835541, G loss: 4.797349, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.908669, G loss: 14.524941, D accuracy: 81.6%, cell accuracy: 98.2%, board accuracy: 25.5% \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5669, G loss: 3.9242\n",
      "[372/8000] D loss: 0.5677, G loss: 9.8925\n",
      "[732/8000] D loss: 1.0329, G loss: 6.8868\n",
      "[1092/8000] D loss: 0.6284, G loss: 6.0238\n",
      "[1452/8000] D loss: 0.7745, G loss: 3.9282\n",
      "[1812/8000] D loss: 0.9540, G loss: 5.4762\n",
      "[2172/8000] D loss: 0.9893, G loss: 5.5258\n",
      "[2532/8000] D loss: 0.7836, G loss: 4.5653\n",
      "[2892/8000] D loss: 0.5897, G loss: 9.5682\n",
      "[3252/8000] D loss: 0.6165, G loss: 5.5788\n",
      "[3612/8000] D loss: 0.6379, G loss: 4.9620\n",
      "[3972/8000] D loss: 0.3776, G loss: 8.1841\n",
      "[4332/8000] D loss: 0.5436, G loss: 9.7307\n",
      "[4692/8000] D loss: 1.0233, G loss: 6.8545\n",
      "[5052/8000] D loss: 0.9387, G loss: 3.3418\n",
      "[5412/8000] D loss: 0.9040, G loss: 4.0467\n",
      "[5772/8000] D loss: 1.0448, G loss: 1.7826\n",
      "[6132/8000] D loss: 0.5668, G loss: 8.5282\n",
      "[6492/8000] D loss: 0.6967, G loss: 4.7697\n",
      "[6852/8000] D loss: 1.3722, G loss: 0.6055\n",
      "[7212/8000] D loss: 0.8144, G loss: 4.8482\n",
      "[7572/8000] D loss: 0.5749, G loss: 6.5734\n",
      "[7932/8000] D loss: 0.9594, G loss: 2.7991\n",
      "train error: \n",
      " D loss: 0.819945, G loss: 6.617776, D accuracy: 73.5%, cell accuracy: 98.7%, board accuracy: 53.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.009716, G loss: 17.979681, D accuracy: 77.1%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0017, G loss: 6.3878\n",
      "[372/8000] D loss: 0.5995, G loss: 9.0797\n",
      "[732/8000] D loss: 0.4840, G loss: 10.6934\n",
      "[1092/8000] D loss: 1.1555, G loss: 3.2765\n",
      "[1452/8000] D loss: 0.5999, G loss: 9.2227\n",
      "[1812/8000] D loss: 0.9612, G loss: 1.8834\n",
      "[2172/8000] D loss: 0.4941, G loss: 9.0863\n",
      "[2532/8000] D loss: 0.7979, G loss: 2.9122\n",
      "[2892/8000] D loss: 0.9263, G loss: 3.4086\n",
      "[3252/8000] D loss: 1.1337, G loss: 3.1271\n",
      "[3612/8000] D loss: 0.9359, G loss: 3.7707\n",
      "[3972/8000] D loss: 0.8468, G loss: 3.6554\n",
      "[4332/8000] D loss: 0.8676, G loss: 3.9148\n",
      "[4692/8000] D loss: 1.0551, G loss: 3.2700\n",
      "[5052/8000] D loss: 0.9448, G loss: 3.6735\n",
      "[5412/8000] D loss: 0.7519, G loss: 5.2547\n",
      "[5772/8000] D loss: 1.1582, G loss: 1.1314\n",
      "[6132/8000] D loss: 1.0880, G loss: 2.7832\n",
      "[6492/8000] D loss: 0.5615, G loss: 3.8559\n",
      "[6852/8000] D loss: 0.8781, G loss: 3.9287\n",
      "[7212/8000] D loss: 0.7068, G loss: 5.5314\n",
      "[7572/8000] D loss: 1.0241, G loss: 4.7751\n",
      "[7932/8000] D loss: 0.8632, G loss: 3.2453\n",
      "train error: \n",
      " D loss: 0.834738, G loss: 4.616997, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.878072, G loss: 13.462447, D accuracy: 80.4%, cell accuracy: 98.2%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9765, G loss: 4.5353\n",
      "[372/8000] D loss: 0.8234, G loss: 3.0382\n",
      "[732/8000] D loss: 0.7062, G loss: 7.0053\n",
      "[1092/8000] D loss: 0.8223, G loss: 4.1517\n",
      "[1452/8000] D loss: 0.7575, G loss: 4.8793\n",
      "[1812/8000] D loss: 0.8753, G loss: 6.4700\n",
      "[2172/8000] D loss: 1.2213, G loss: 1.6678\n",
      "[2532/8000] D loss: 1.0538, G loss: 2.3919\n",
      "[2892/8000] D loss: 0.6106, G loss: 7.4075\n",
      "[3252/8000] D loss: 0.8687, G loss: 3.8909\n",
      "[3612/8000] D loss: 0.9899, G loss: 3.5399\n",
      "[3972/8000] D loss: 0.6022, G loss: 7.0542\n",
      "[4332/8000] D loss: 1.1781, G loss: 1.7600\n",
      "[4692/8000] D loss: 0.7180, G loss: 3.9524\n",
      "[5052/8000] D loss: 0.7204, G loss: 6.2088\n",
      "[5412/8000] D loss: 0.5079, G loss: 7.7625\n",
      "[5772/8000] D loss: 1.1133, G loss: 6.3164\n",
      "[6132/8000] D loss: 0.7271, G loss: 8.2650\n",
      "[6492/8000] D loss: 0.8197, G loss: 3.5786\n",
      "[6852/8000] D loss: 0.5614, G loss: 12.4676\n",
      "[7212/8000] D loss: 1.0310, G loss: 4.7913\n",
      "[7572/8000] D loss: 1.1760, G loss: 1.9780\n",
      "[7932/8000] D loss: 1.2051, G loss: 2.8841\n",
      "train error: \n",
      " D loss: 0.831631, G loss: 5.994383, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.089169, G loss: 16.901024, D accuracy: 75.3%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0394, G loss: 6.0834\n",
      "[372/8000] D loss: 0.8569, G loss: 4.2039\n",
      "[732/8000] D loss: 0.5050, G loss: 6.3152\n",
      "[1092/8000] D loss: 0.8298, G loss: 3.2528\n",
      "[1452/8000] D loss: 0.8547, G loss: 6.0592\n",
      "[1812/8000] D loss: 0.8261, G loss: 7.4866\n",
      "[2172/8000] D loss: 0.6698, G loss: 4.7016\n",
      "[2532/8000] D loss: 1.0510, G loss: 4.6663\n",
      "[2892/8000] D loss: 0.4726, G loss: 7.7600\n",
      "[3252/8000] D loss: 0.9157, G loss: 5.5464\n",
      "[3612/8000] D loss: 0.7275, G loss: 9.6501\n",
      "[3972/8000] D loss: 0.8218, G loss: 3.2422\n",
      "[4332/8000] D loss: 0.5219, G loss: 5.0084\n",
      "[4692/8000] D loss: 0.6398, G loss: 7.0921\n",
      "[5052/8000] D loss: 1.0143, G loss: 3.7252\n",
      "[5412/8000] D loss: 0.5172, G loss: 5.1227\n",
      "[5772/8000] D loss: 0.6147, G loss: 8.3755\n",
      "[6132/8000] D loss: 0.5965, G loss: 5.7859\n",
      "[6492/8000] D loss: 0.7585, G loss: 6.9801\n",
      "[6852/8000] D loss: 0.5787, G loss: 11.1424\n",
      "[7212/8000] D loss: 0.8331, G loss: 7.2936\n",
      "[7572/8000] D loss: 0.7497, G loss: 5.5265\n",
      "[7932/8000] D loss: 0.6128, G loss: 6.1473\n",
      "train error: \n",
      " D loss: 0.834112, G loss: 6.330501, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.959094, G loss: 17.189349, D accuracy: 75.9%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8193, G loss: 7.0051\n",
      "[372/8000] D loss: 0.7293, G loss: 4.9184\n",
      "[732/8000] D loss: 0.6969, G loss: 4.9016\n",
      "[1092/8000] D loss: 0.8321, G loss: 6.1507\n",
      "[1452/8000] D loss: 0.5716, G loss: 6.0653\n",
      "[1812/8000] D loss: 0.8524, G loss: 5.1755\n",
      "[2172/8000] D loss: 0.5994, G loss: 10.6174\n",
      "[2532/8000] D loss: 0.9551, G loss: 5.9452\n",
      "[2892/8000] D loss: 0.5438, G loss: 7.3794\n",
      "[3252/8000] D loss: 1.0163, G loss: 5.1689\n",
      "[3612/8000] D loss: 0.9166, G loss: 6.2505\n",
      "[3972/8000] D loss: 0.8446, G loss: 4.7231\n",
      "[4332/8000] D loss: 0.5480, G loss: 12.0867\n",
      "[4692/8000] D loss: 0.8798, G loss: 6.6594\n",
      "[5052/8000] D loss: 0.8132, G loss: 7.8947\n",
      "[5412/8000] D loss: 0.9073, G loss: 3.4315\n",
      "[5772/8000] D loss: 0.6728, G loss: 3.5021\n",
      "[6132/8000] D loss: 1.0320, G loss: 6.6908\n",
      "[6492/8000] D loss: 0.6012, G loss: 10.1259\n",
      "[6852/8000] D loss: 0.8848, G loss: 5.6671\n",
      "[7212/8000] D loss: 0.4950, G loss: 6.0734\n",
      "[7572/8000] D loss: 0.8789, G loss: 5.3460\n",
      "[7932/8000] D loss: 0.8683, G loss: 4.7008\n",
      "train error: \n",
      " D loss: 0.822987, G loss: 5.965102, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.950546, G loss: 16.585608, D accuracy: 79.1%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0348, G loss: 5.2924\n",
      "[372/8000] D loss: 0.5813, G loss: 5.1528\n",
      "[732/8000] D loss: 0.7827, G loss: 4.0115\n",
      "[1092/8000] D loss: 0.6416, G loss: 4.0109\n",
      "[1452/8000] D loss: 0.8359, G loss: 6.5967\n",
      "[1812/8000] D loss: 1.0486, G loss: 4.5047\n",
      "[2172/8000] D loss: 0.6195, G loss: 4.9614\n",
      "[2532/8000] D loss: 0.8897, G loss: 7.4420\n",
      "[2892/8000] D loss: 0.6991, G loss: 6.6876\n",
      "[3252/8000] D loss: 0.7229, G loss: 5.9203\n",
      "[3612/8000] D loss: 0.8624, G loss: 7.5427\n",
      "[3972/8000] D loss: 0.7616, G loss: 10.0356\n",
      "[4332/8000] D loss: 0.6303, G loss: 3.8188\n",
      "[4692/8000] D loss: 1.1345, G loss: 2.5211\n",
      "[5052/8000] D loss: 1.0111, G loss: 2.4722\n",
      "[5412/8000] D loss: 1.0901, G loss: 1.9721\n",
      "[5772/8000] D loss: 0.8933, G loss: 6.1447\n",
      "[6132/8000] D loss: 1.0898, G loss: 1.3042\n",
      "[6492/8000] D loss: 0.7215, G loss: 4.2997\n",
      "[6852/8000] D loss: 0.6965, G loss: 3.0655\n",
      "[7212/8000] D loss: 1.1933, G loss: 3.4991\n",
      "[7572/8000] D loss: 0.4885, G loss: 6.6370\n",
      "[7932/8000] D loss: 1.0872, G loss: 3.9339\n",
      "train error: \n",
      " D loss: 0.830283, G loss: 5.320631, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.895907, G loss: 15.354054, D accuracy: 78.2%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4991, G loss: 8.2490\n",
      "[372/8000] D loss: 0.9454, G loss: 2.3077\n",
      "[732/8000] D loss: 0.8239, G loss: 2.2819\n",
      "[1092/8000] D loss: 0.7892, G loss: 6.8567\n",
      "[1452/8000] D loss: 0.5673, G loss: 8.1888\n",
      "[1812/8000] D loss: 1.0063, G loss: 3.0258\n",
      "[2172/8000] D loss: 0.4061, G loss: 9.3634\n",
      "[2532/8000] D loss: 0.7613, G loss: 5.7399\n",
      "[2892/8000] D loss: 1.0445, G loss: 3.2506\n",
      "[3252/8000] D loss: 0.7279, G loss: 5.8336\n",
      "[3612/8000] D loss: 0.8230, G loss: 3.7488\n",
      "[3972/8000] D loss: 1.1364, G loss: 4.2979\n",
      "[4332/8000] D loss: 1.0187, G loss: 2.3568\n",
      "[4692/8000] D loss: 0.7439, G loss: 3.0193\n",
      "[5052/8000] D loss: 0.9835, G loss: 6.4856\n",
      "[5412/8000] D loss: 0.5655, G loss: 9.8824\n",
      "[5772/8000] D loss: 0.8744, G loss: 2.9142\n",
      "[6132/8000] D loss: 0.9683, G loss: 3.7917\n",
      "[6492/8000] D loss: 1.0925, G loss: 1.5512\n",
      "[6852/8000] D loss: 0.6029, G loss: 8.8103\n",
      "[7212/8000] D loss: 1.0669, G loss: 3.0376\n",
      "[7572/8000] D loss: 0.6935, G loss: 6.4850\n",
      "[7932/8000] D loss: 1.1211, G loss: 2.0021\n",
      "train error: \n",
      " D loss: 0.830048, G loss: 5.319729, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.912422, G loss: 15.925544, D accuracy: 80.8%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0876, G loss: 1.8789\n",
      "[372/8000] D loss: 0.8773, G loss: 5.0364\n",
      "[732/8000] D loss: 0.9782, G loss: 3.7854\n",
      "[1092/8000] D loss: 0.7310, G loss: 7.6764\n",
      "[1452/8000] D loss: 0.6877, G loss: 8.0594\n",
      "[1812/8000] D loss: 0.5242, G loss: 6.3202\n",
      "[2172/8000] D loss: 0.9459, G loss: 4.3439\n",
      "[2532/8000] D loss: 0.8131, G loss: 6.3633\n",
      "[2892/8000] D loss: 0.6129, G loss: 5.4800\n",
      "[3252/8000] D loss: 0.5858, G loss: 5.0707\n",
      "[3612/8000] D loss: 0.6163, G loss: 8.6902\n",
      "[3972/8000] D loss: 0.7446, G loss: 5.5495\n",
      "[4332/8000] D loss: 1.1826, G loss: 3.3626\n",
      "[4692/8000] D loss: 0.9156, G loss: 7.9613\n",
      "[5052/8000] D loss: 0.9387, G loss: 6.2343\n",
      "[5412/8000] D loss: 0.8900, G loss: 6.4084\n",
      "[5772/8000] D loss: 0.7886, G loss: 6.6320\n",
      "[6132/8000] D loss: 0.9391, G loss: 3.8269\n",
      "[6492/8000] D loss: 0.8613, G loss: 2.6828\n",
      "[6852/8000] D loss: 0.9227, G loss: 5.3665\n",
      "[7212/8000] D loss: 1.1743, G loss: 6.0427\n",
      "[7572/8000] D loss: 0.9169, G loss: 3.7261\n",
      "[7932/8000] D loss: 0.8946, G loss: 4.4738\n",
      "train error: \n",
      " D loss: 0.860306, G loss: 4.922053, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.864102, G loss: 14.308071, D accuracy: 80.9%, cell accuracy: 98.2%, board accuracy: 25.6% \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8105, G loss: 2.6639\n",
      "[372/8000] D loss: 0.8538, G loss: 3.0903\n",
      "[732/8000] D loss: 1.1230, G loss: 2.2159\n",
      "[1092/8000] D loss: 0.7016, G loss: 3.8752\n",
      "[1452/8000] D loss: 0.5909, G loss: 7.4246\n",
      "[1812/8000] D loss: 1.1488, G loss: 2.5218\n",
      "[2172/8000] D loss: 0.7131, G loss: 9.6399\n",
      "[2532/8000] D loss: 1.0615, G loss: 3.8372\n",
      "[2892/8000] D loss: 1.2135, G loss: 1.0623\n",
      "[3252/8000] D loss: 0.8442, G loss: 4.2448\n",
      "[3612/8000] D loss: 0.7585, G loss: 4.5476\n",
      "[3972/8000] D loss: 1.0105, G loss: 1.9043\n",
      "[4332/8000] D loss: 0.8316, G loss: 3.2039\n",
      "[4692/8000] D loss: 0.9403, G loss: 4.5587\n",
      "[5052/8000] D loss: 0.9522, G loss: 8.6980\n",
      "[5412/8000] D loss: 0.6932, G loss: 11.0015\n",
      "[5772/8000] D loss: 0.3219, G loss: 8.8691\n",
      "[6132/8000] D loss: 0.8162, G loss: 8.9259\n",
      "[6492/8000] D loss: 0.8567, G loss: 4.3894\n",
      "[6852/8000] D loss: 0.4838, G loss: 10.8840\n",
      "[7212/8000] D loss: 0.8205, G loss: 7.9113\n",
      "[7572/8000] D loss: 0.8204, G loss: 6.5414\n",
      "[7932/8000] D loss: 0.8467, G loss: 2.9193\n",
      "train error: \n",
      " D loss: 0.818475, G loss: 6.349029, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.984515, G loss: 17.317852, D accuracy: 77.6%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2777, G loss: 1.3803\n",
      "[372/8000] D loss: 1.1700, G loss: 1.8154\n",
      "[732/8000] D loss: 0.8607, G loss: 3.5290\n",
      "[1092/8000] D loss: 0.5324, G loss: 6.9140\n",
      "[1452/8000] D loss: 0.7355, G loss: 10.8682\n",
      "[1812/8000] D loss: 1.4400, G loss: 0.6274\n",
      "[2172/8000] D loss: 0.8773, G loss: 17.2305\n",
      "[2532/8000] D loss: 0.9097, G loss: 4.7621\n",
      "[2892/8000] D loss: 0.9606, G loss: 3.4777\n",
      "[3252/8000] D loss: 0.6048, G loss: 4.0886\n",
      "[3612/8000] D loss: 0.9558, G loss: 5.7403\n",
      "[3972/8000] D loss: 0.5632, G loss: 6.4349\n",
      "[4332/8000] D loss: 0.6650, G loss: 6.1931\n",
      "[4692/8000] D loss: 0.4556, G loss: 9.1578\n",
      "[5052/8000] D loss: 0.7828, G loss: 4.6155\n",
      "[5412/8000] D loss: 0.9395, G loss: 4.9723\n",
      "[5772/8000] D loss: 0.6596, G loss: 8.7272\n",
      "[6132/8000] D loss: 0.8218, G loss: 3.2762\n",
      "[6492/8000] D loss: 1.0808, G loss: 3.3295\n",
      "[6852/8000] D loss: 1.0821, G loss: 1.8343\n",
      "[7212/8000] D loss: 0.8570, G loss: 9.5858\n",
      "[7572/8000] D loss: 0.7858, G loss: 7.6524\n",
      "[7932/8000] D loss: 0.8704, G loss: 4.4954\n",
      "train error: \n",
      " D loss: 0.840378, G loss: 5.284569, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.847604, G loss: 15.417559, D accuracy: 80.1%, cell accuracy: 98.2%, board accuracy: 25.4% \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7297, G loss: 6.8319\n",
      "[372/8000] D loss: 0.6615, G loss: 4.7510\n",
      "[732/8000] D loss: 0.6635, G loss: 5.8263\n",
      "[1092/8000] D loss: 1.1227, G loss: 2.3683\n",
      "[1452/8000] D loss: 0.8172, G loss: 6.5368\n",
      "[1812/8000] D loss: 0.8952, G loss: 3.9060\n",
      "[2172/8000] D loss: 1.0475, G loss: 3.8184\n",
      "[2532/8000] D loss: 0.6854, G loss: 5.9311\n",
      "[2892/8000] D loss: 0.7334, G loss: 6.8052\n",
      "[3252/8000] D loss: 0.7352, G loss: 5.8416\n",
      "[3612/8000] D loss: 0.9355, G loss: 4.4808\n",
      "[3972/8000] D loss: 0.6431, G loss: 8.3335\n",
      "[4332/8000] D loss: 0.8271, G loss: 5.0573\n",
      "[4692/8000] D loss: 1.1600, G loss: 2.7653\n",
      "[5052/8000] D loss: 0.8951, G loss: 5.0217\n",
      "[5412/8000] D loss: 0.8603, G loss: 8.1841\n",
      "[5772/8000] D loss: 0.8177, G loss: 5.0269\n",
      "[6132/8000] D loss: 0.7536, G loss: 2.6085\n",
      "[6492/8000] D loss: 1.0431, G loss: 3.4289\n",
      "[6852/8000] D loss: 0.8519, G loss: 5.1544\n",
      "[7212/8000] D loss: 0.7187, G loss: 7.7068\n",
      "[7572/8000] D loss: 0.8274, G loss: 8.2402\n",
      "[7932/8000] D loss: 0.7784, G loss: 9.0848\n",
      "train error: \n",
      " D loss: 0.849696, G loss: 4.787570, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.840921, G loss: 14.852293, D accuracy: 82.2%, cell accuracy: 98.2%, board accuracy: 26.0% \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0327, G loss: 2.8526\n",
      "[372/8000] D loss: 0.6425, G loss: 5.9687\n",
      "[732/8000] D loss: 0.7403, G loss: 9.2931\n",
      "[1092/8000] D loss: 1.0760, G loss: 4.2150\n",
      "[1452/8000] D loss: 0.9123, G loss: 6.4254\n",
      "[1812/8000] D loss: 0.7417, G loss: 5.6445\n",
      "[2172/8000] D loss: 0.8796, G loss: 4.7791\n",
      "[2532/8000] D loss: 1.0104, G loss: 3.5922\n",
      "[2892/8000] D loss: 0.8928, G loss: 5.3809\n",
      "[3252/8000] D loss: 0.5268, G loss: 7.9926\n",
      "[3612/8000] D loss: 0.8359, G loss: 6.1929\n",
      "[3972/8000] D loss: 0.7417, G loss: 7.8339\n",
      "[4332/8000] D loss: 0.7346, G loss: 6.0641\n",
      "[4692/8000] D loss: 1.3577, G loss: 4.9282\n",
      "[5052/8000] D loss: 0.7240, G loss: 7.2184\n",
      "[5412/8000] D loss: 0.6867, G loss: 4.8380\n",
      "[5772/8000] D loss: 0.9650, G loss: 3.5314\n",
      "[6132/8000] D loss: 0.9469, G loss: 3.8863\n",
      "[6492/8000] D loss: 0.6575, G loss: 5.1712\n",
      "[6852/8000] D loss: 1.1933, G loss: 1.7280\n",
      "[7212/8000] D loss: 0.5958, G loss: 9.0303\n",
      "[7572/8000] D loss: 0.6491, G loss: 6.8102\n",
      "[7932/8000] D loss: 0.8643, G loss: 3.3827\n",
      "train error: \n",
      " D loss: 0.830282, G loss: 5.870377, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.960670, G loss: 16.885895, D accuracy: 80.2%, cell accuracy: 98.2%, board accuracy: 25.9% \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2935, G loss: 1.4121\n",
      "[372/8000] D loss: 0.6464, G loss: 7.0404\n",
      "[732/8000] D loss: 0.8406, G loss: 3.0732\n",
      "[1092/8000] D loss: 1.0039, G loss: 2.9781\n",
      "[1452/8000] D loss: 0.6896, G loss: 6.5063\n",
      "[1812/8000] D loss: 0.7155, G loss: 8.7692\n",
      "[2172/8000] D loss: 0.7945, G loss: 5.6493\n",
      "[2532/8000] D loss: 1.0214, G loss: 4.6872\n",
      "[2892/8000] D loss: 0.5756, G loss: 5.9345\n",
      "[3252/8000] D loss: 0.7462, G loss: 6.9402\n",
      "[3612/8000] D loss: 0.8113, G loss: 6.6310\n",
      "[3972/8000] D loss: 0.8750, G loss: 5.1230\n",
      "[4332/8000] D loss: 0.9202, G loss: 6.9854\n",
      "[4692/8000] D loss: 0.7790, G loss: 3.0509\n",
      "[5052/8000] D loss: 0.8830, G loss: 5.1535\n",
      "[5412/8000] D loss: 0.8033, G loss: 3.8209\n",
      "[5772/8000] D loss: 1.1703, G loss: 5.4503\n",
      "[6132/8000] D loss: 1.0670, G loss: 2.6909\n",
      "[6492/8000] D loss: 1.0503, G loss: 2.8802\n",
      "[6852/8000] D loss: 1.1175, G loss: 3.7023\n",
      "[7212/8000] D loss: 0.7424, G loss: 6.4920\n",
      "[7572/8000] D loss: 0.8451, G loss: 3.1283\n",
      "[7932/8000] D loss: 0.6273, G loss: 6.8904\n",
      "train error: \n",
      " D loss: 0.841835, G loss: 6.147375, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.001491, G loss: 16.550705, D accuracy: 75.6%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6765, G loss: 5.8570\n",
      "[372/8000] D loss: 0.5595, G loss: 6.5413\n",
      "[732/8000] D loss: 1.1503, G loss: 1.7942\n",
      "[1092/8000] D loss: 0.6924, G loss: 8.6855\n",
      "[1452/8000] D loss: 0.9062, G loss: 8.4879\n",
      "[1812/8000] D loss: 0.6455, G loss: 10.3094\n",
      "[2172/8000] D loss: 0.7673, G loss: 4.7765\n",
      "[2532/8000] D loss: 1.0393, G loss: 3.0704\n",
      "[2892/8000] D loss: 1.1890, G loss: 6.3181\n",
      "[3252/8000] D loss: 1.2134, G loss: 1.5390\n",
      "[3612/8000] D loss: 1.0030, G loss: 3.9761\n",
      "[3972/8000] D loss: 0.5292, G loss: 4.5275\n",
      "[4332/8000] D loss: 1.0626, G loss: 3.2697\n",
      "[4692/8000] D loss: 0.9191, G loss: 7.7014\n",
      "[5052/8000] D loss: 0.4425, G loss: 10.1087\n",
      "[5412/8000] D loss: 0.4459, G loss: 4.4736\n",
      "[5772/8000] D loss: 0.7338, G loss: 4.0477\n",
      "[6132/8000] D loss: 1.1753, G loss: 2.7805\n",
      "[6492/8000] D loss: 0.6445, G loss: 8.8332\n",
      "[6852/8000] D loss: 0.7718, G loss: 4.0678\n",
      "[7212/8000] D loss: 0.8074, G loss: 4.4439\n",
      "[7572/8000] D loss: 0.9160, G loss: 5.3557\n",
      "[7932/8000] D loss: 0.8397, G loss: 2.5834\n",
      "train error: \n",
      " D loss: 0.844030, G loss: 6.897501, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.092056, G loss: 17.750529, D accuracy: 75.6%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5744, G loss: 8.3598\n",
      "[372/8000] D loss: 0.9429, G loss: 9.8741\n",
      "[732/8000] D loss: 0.4960, G loss: 12.2539\n",
      "[1092/8000] D loss: 0.6084, G loss: 6.3185\n",
      "[1452/8000] D loss: 0.5869, G loss: 6.7297\n",
      "[1812/8000] D loss: 0.8183, G loss: 9.1350\n",
      "[2172/8000] D loss: 0.3901, G loss: 8.8621\n",
      "[2532/8000] D loss: 0.4805, G loss: 9.7422\n",
      "[2892/8000] D loss: 0.7838, G loss: 7.8685\n",
      "[3252/8000] D loss: 0.5278, G loss: 6.5036\n",
      "[3612/8000] D loss: 0.8657, G loss: 4.9138\n",
      "[3972/8000] D loss: 1.1070, G loss: 2.7588\n",
      "[4332/8000] D loss: 1.0384, G loss: 4.4239\n",
      "[4692/8000] D loss: 0.7244, G loss: 3.6036\n",
      "[5052/8000] D loss: 0.7251, G loss: 6.5249\n",
      "[5412/8000] D loss: 1.0521, G loss: 5.3448\n",
      "[5772/8000] D loss: 0.8915, G loss: 2.1821\n",
      "[6132/8000] D loss: 0.1943, G loss: 10.5767\n",
      "[6492/8000] D loss: 0.8257, G loss: 4.9359\n",
      "[6852/8000] D loss: 0.8960, G loss: 5.9493\n",
      "[7212/8000] D loss: 0.3831, G loss: 4.9788\n",
      "[7572/8000] D loss: 0.7160, G loss: 5.5446\n",
      "[7932/8000] D loss: 0.2305, G loss: 13.2694\n",
      "train error: \n",
      " D loss: 0.843658, G loss: 5.179614, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.882301, G loss: 15.159982, D accuracy: 81.7%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7074, G loss: 4.0891\n",
      "[372/8000] D loss: 0.6130, G loss: 5.2939\n",
      "[732/8000] D loss: 0.8339, G loss: 3.9054\n",
      "[1092/8000] D loss: 0.7547, G loss: 7.2055\n",
      "[1452/8000] D loss: 0.6378, G loss: 9.6310\n",
      "[1812/8000] D loss: 0.8201, G loss: 3.6580\n",
      "[2172/8000] D loss: 0.6106, G loss: 4.8809\n",
      "[2532/8000] D loss: 0.6091, G loss: 6.2623\n",
      "[2892/8000] D loss: 1.0564, G loss: 3.9558\n",
      "[3252/8000] D loss: 0.5964, G loss: 6.9865\n",
      "[3612/8000] D loss: 0.9457, G loss: 3.1940\n",
      "[3972/8000] D loss: 0.7656, G loss: 8.5372\n",
      "[4332/8000] D loss: 0.9635, G loss: 10.4689\n",
      "[4692/8000] D loss: 0.6921, G loss: 12.6191\n",
      "[5052/8000] D loss: 0.8567, G loss: 7.3708\n",
      "[5412/8000] D loss: 0.8775, G loss: 6.2019\n",
      "[5772/8000] D loss: 1.1122, G loss: 3.2941\n",
      "[6132/8000] D loss: 1.0068, G loss: 3.8227\n",
      "[6492/8000] D loss: 0.9680, G loss: 1.9493\n",
      "[6852/8000] D loss: 0.8576, G loss: 9.2521\n",
      "[7212/8000] D loss: 1.0223, G loss: 3.1689\n",
      "[7572/8000] D loss: 1.2674, G loss: 1.7132\n",
      "[7932/8000] D loss: 0.9646, G loss: 3.0094\n",
      "train error: \n",
      " D loss: 0.830134, G loss: 6.207795, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.852217, G loss: 16.792413, D accuracy: 80.0%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1439, G loss: 1.9306\n",
      "[372/8000] D loss: 0.9855, G loss: 3.4702\n",
      "[732/8000] D loss: 1.0947, G loss: 1.5547\n",
      "[1092/8000] D loss: 0.9788, G loss: 2.7914\n",
      "[1452/8000] D loss: 0.3891, G loss: 10.1766\n",
      "[1812/8000] D loss: 0.9139, G loss: 5.2829\n",
      "[2172/8000] D loss: 0.8408, G loss: 8.7334\n",
      "[2532/8000] D loss: 0.9100, G loss: 3.4548\n",
      "[2892/8000] D loss: 0.8271, G loss: 5.0382\n",
      "[3252/8000] D loss: 0.8618, G loss: 4.6145\n",
      "[3612/8000] D loss: 0.8120, G loss: 3.9961\n",
      "[3972/8000] D loss: 0.8831, G loss: 7.9412\n",
      "[4332/8000] D loss: 1.4038, G loss: 0.5960\n",
      "[4692/8000] D loss: 0.9073, G loss: 3.1258\n",
      "[5052/8000] D loss: 0.9679, G loss: 3.4600\n",
      "[5412/8000] D loss: 0.7975, G loss: 4.1257\n",
      "[5772/8000] D loss: 0.7537, G loss: 8.3324\n",
      "[6132/8000] D loss: 0.8166, G loss: 5.3982\n",
      "[6492/8000] D loss: 0.5797, G loss: 6.4158\n",
      "[6852/8000] D loss: 0.9295, G loss: 4.8482\n",
      "[7212/8000] D loss: 0.5575, G loss: 10.5185\n",
      "[7572/8000] D loss: 0.5145, G loss: 8.2542\n",
      "[7932/8000] D loss: 0.9597, G loss: 2.8720\n",
      "train error: \n",
      " D loss: 0.827487, G loss: 6.746891, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 54.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.996519, G loss: 18.347622, D accuracy: 77.8%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9441, G loss: 5.2310\n",
      "[372/8000] D loss: 0.7223, G loss: 7.4367\n",
      "[732/8000] D loss: 0.8059, G loss: 5.6763\n",
      "[1092/8000] D loss: 0.5330, G loss: 9.4449\n",
      "[1452/8000] D loss: 0.6145, G loss: 6.5134\n",
      "[1812/8000] D loss: 1.0096, G loss: 1.8237\n",
      "[2172/8000] D loss: 0.6677, G loss: 6.6278\n",
      "[2532/8000] D loss: 0.7875, G loss: 3.1899\n",
      "[2892/8000] D loss: 1.1133, G loss: 3.5956\n",
      "[3252/8000] D loss: 0.9862, G loss: 5.9130\n",
      "[3612/8000] D loss: 0.6223, G loss: 6.0748\n",
      "[3972/8000] D loss: 0.5741, G loss: 12.3857\n",
      "[4332/8000] D loss: 1.0487, G loss: 1.9091\n",
      "[4692/8000] D loss: 0.7984, G loss: 4.6382\n",
      "[5052/8000] D loss: 1.0563, G loss: 1.8543\n",
      "[5412/8000] D loss: 0.6963, G loss: 4.4155\n",
      "[5772/8000] D loss: 0.9320, G loss: 3.2483\n",
      "[6132/8000] D loss: 0.8925, G loss: 2.9173\n",
      "[6492/8000] D loss: 0.7873, G loss: 5.2641\n",
      "[6852/8000] D loss: 0.6991, G loss: 6.6820\n",
      "[7212/8000] D loss: 0.9337, G loss: 5.6261\n",
      "[7572/8000] D loss: 0.8029, G loss: 4.8298\n",
      "[7932/8000] D loss: 0.9936, G loss: 4.7346\n",
      "train error: \n",
      " D loss: 0.846762, G loss: 4.663650, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.845887, G loss: 13.850339, D accuracy: 81.3%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8245, G loss: 3.1630\n",
      "[372/8000] D loss: 1.0990, G loss: 2.7696\n",
      "[732/8000] D loss: 0.6013, G loss: 6.4247\n",
      "[1092/8000] D loss: 0.7287, G loss: 5.2517\n",
      "[1452/8000] D loss: 0.8423, G loss: 4.2732\n",
      "[1812/8000] D loss: 0.8240, G loss: 3.4659\n",
      "[2172/8000] D loss: 0.7792, G loss: 9.7068\n",
      "[2532/8000] D loss: 0.6721, G loss: 4.7917\n",
      "[2892/8000] D loss: 0.6833, G loss: 6.9971\n",
      "[3252/8000] D loss: 0.5368, G loss: 7.7834\n",
      "[3612/8000] D loss: 0.3838, G loss: 8.1032\n",
      "[3972/8000] D loss: 0.7402, G loss: 7.0400\n",
      "[4332/8000] D loss: 0.9562, G loss: 4.2881\n",
      "[4692/8000] D loss: 0.8152, G loss: 6.6054\n",
      "[5052/8000] D loss: 0.8471, G loss: 3.1893\n",
      "[5412/8000] D loss: 0.7795, G loss: 4.5831\n",
      "[5772/8000] D loss: 0.6708, G loss: 4.5196\n",
      "[6132/8000] D loss: 0.9439, G loss: 5.3607\n",
      "[6492/8000] D loss: 0.8207, G loss: 5.1526\n",
      "[6852/8000] D loss: 1.1148, G loss: 2.9042\n",
      "[7212/8000] D loss: 0.5443, G loss: 6.2155\n",
      "[7572/8000] D loss: 0.7960, G loss: 8.8320\n",
      "[7932/8000] D loss: 0.9118, G loss: 2.8934\n",
      "train error: \n",
      " D loss: 0.852053, G loss: 5.439800, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.072474, G loss: 15.634954, D accuracy: 75.6%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6658, G loss: 6.0077\n",
      "[372/8000] D loss: 1.0610, G loss: 2.6737\n",
      "[732/8000] D loss: 0.7012, G loss: 6.5793\n",
      "[1092/8000] D loss: 0.8690, G loss: 5.9827\n",
      "[1452/8000] D loss: 1.0172, G loss: 2.7409\n",
      "[1812/8000] D loss: 0.9749, G loss: 7.3729\n",
      "[2172/8000] D loss: 0.8500, G loss: 3.5554\n",
      "[2532/8000] D loss: 1.0124, G loss: 6.6418\n",
      "[2892/8000] D loss: 0.8643, G loss: 7.4115\n",
      "[3252/8000] D loss: 0.8409, G loss: 4.7222\n",
      "[3612/8000] D loss: 0.4216, G loss: 5.7056\n",
      "[3972/8000] D loss: 1.1229, G loss: 1.8595\n",
      "[4332/8000] D loss: 0.6938, G loss: 3.8541\n",
      "[4692/8000] D loss: 0.3638, G loss: 9.6369\n",
      "[5052/8000] D loss: 0.6426, G loss: 5.3277\n",
      "[5412/8000] D loss: 1.1039, G loss: 3.4945\n",
      "[5772/8000] D loss: 0.6660, G loss: 6.4334\n",
      "[6132/8000] D loss: 0.6310, G loss: 7.7544\n",
      "[6492/8000] D loss: 0.7382, G loss: 8.7066\n",
      "[6852/8000] D loss: 0.8445, G loss: 5.5230\n",
      "[7212/8000] D loss: 0.7628, G loss: 4.6023\n",
      "[7572/8000] D loss: 0.9277, G loss: 3.0369\n",
      "[7932/8000] D loss: 0.7480, G loss: 5.5729\n",
      "train error: \n",
      " D loss: 0.829841, G loss: 4.855586, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.894569, G loss: 14.842020, D accuracy: 78.5%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9257, G loss: 3.1630\n",
      "[372/8000] D loss: 0.7033, G loss: 10.9370\n",
      "[732/8000] D loss: 0.6073, G loss: 7.8483\n",
      "[1092/8000] D loss: 0.7195, G loss: 6.4811\n",
      "[1452/8000] D loss: 1.0217, G loss: 5.7582\n",
      "[1812/8000] D loss: 0.7872, G loss: 4.5276\n",
      "[2172/8000] D loss: 0.8003, G loss: 6.0760\n",
      "[2532/8000] D loss: 0.7335, G loss: 5.7526\n",
      "[2892/8000] D loss: 0.8175, G loss: 6.0575\n",
      "[3252/8000] D loss: 0.9025, G loss: 5.3201\n",
      "[3612/8000] D loss: 0.4368, G loss: 12.0609\n",
      "[3972/8000] D loss: 1.2115, G loss: 2.3813\n",
      "[4332/8000] D loss: 1.1797, G loss: 1.4749\n",
      "[4692/8000] D loss: 0.4275, G loss: 4.8171\n",
      "[5052/8000] D loss: 0.6021, G loss: 12.3558\n",
      "[5412/8000] D loss: 0.6594, G loss: 5.3626\n",
      "[5772/8000] D loss: 0.6374, G loss: 6.4675\n",
      "[6132/8000] D loss: 0.2898, G loss: 13.5339\n",
      "[6492/8000] D loss: 0.7692, G loss: 5.1168\n",
      "[6852/8000] D loss: 1.1552, G loss: 3.5881\n",
      "[7212/8000] D loss: 0.8013, G loss: 9.3227\n",
      "[7572/8000] D loss: 0.9081, G loss: 2.4498\n",
      "[7932/8000] D loss: 0.6516, G loss: 9.6135\n",
      "train error: \n",
      " D loss: 0.820607, G loss: 5.670935, D accuracy: 73.0%, cell accuracy: 98.7%, board accuracy: 55.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.925254, G loss: 16.056581, D accuracy: 79.8%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0019, G loss: 3.0012\n",
      "[372/8000] D loss: 0.7097, G loss: 9.8343\n",
      "[732/8000] D loss: 0.5895, G loss: 7.8153\n",
      "[1092/8000] D loss: 0.8009, G loss: 3.7473\n",
      "[1452/8000] D loss: 1.0287, G loss: 1.6914\n",
      "[1812/8000] D loss: 0.9989, G loss: 5.1039\n",
      "[2172/8000] D loss: 0.8354, G loss: 3.1713\n",
      "[2532/8000] D loss: 1.1872, G loss: 2.9688\n",
      "[2892/8000] D loss: 1.0051, G loss: 4.5457\n",
      "[3252/8000] D loss: 1.2111, G loss: 1.6221\n",
      "[3612/8000] D loss: 0.5260, G loss: 6.6938\n",
      "[3972/8000] D loss: 0.7628, G loss: 6.3140\n",
      "[4332/8000] D loss: 1.0422, G loss: 5.8225\n",
      "[4692/8000] D loss: 0.7080, G loss: 4.9323\n",
      "[5052/8000] D loss: 0.5105, G loss: 6.6265\n",
      "[5412/8000] D loss: 0.7525, G loss: 7.8831\n",
      "[5772/8000] D loss: 0.8700, G loss: 2.9586\n",
      "[6132/8000] D loss: 0.7462, G loss: 8.1725\n",
      "[6492/8000] D loss: 0.7960, G loss: 5.1929\n",
      "[6852/8000] D loss: 1.1162, G loss: 6.4514\n",
      "[7212/8000] D loss: 0.6747, G loss: 10.3570\n",
      "[7572/8000] D loss: 0.5454, G loss: 4.6396\n",
      "[7932/8000] D loss: 0.9078, G loss: 3.1372\n",
      "train error: \n",
      " D loss: 0.848283, G loss: 6.468958, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.932547, G loss: 18.050134, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0178, G loss: 2.7531\n",
      "[372/8000] D loss: 0.9720, G loss: 6.9994\n",
      "[732/8000] D loss: 0.9469, G loss: 5.2549\n",
      "[1092/8000] D loss: 0.6373, G loss: 9.7933\n",
      "[1452/8000] D loss: 1.1515, G loss: 2.2266\n",
      "[1812/8000] D loss: 0.7735, G loss: 5.0145\n",
      "[2172/8000] D loss: 0.5413, G loss: 7.6361\n",
      "[2532/8000] D loss: 1.0501, G loss: 2.0507\n",
      "[2892/8000] D loss: 0.8411, G loss: 6.8630\n",
      "[3252/8000] D loss: 0.6861, G loss: 8.6858\n",
      "[3612/8000] D loss: 0.6315, G loss: 7.8312\n",
      "[3972/8000] D loss: 1.3041, G loss: 3.1803\n",
      "[4332/8000] D loss: 0.9226, G loss: 2.8357\n",
      "[4692/8000] D loss: 0.6685, G loss: 5.3973\n",
      "[5052/8000] D loss: 0.7724, G loss: 4.5146\n",
      "[5412/8000] D loss: 0.3215, G loss: 4.2216\n",
      "[5772/8000] D loss: 0.7696, G loss: 14.4399\n",
      "[6132/8000] D loss: 0.6165, G loss: 7.1624\n",
      "[6492/8000] D loss: 0.8316, G loss: 5.9627\n",
      "[6852/8000] D loss: 1.0285, G loss: 6.6437\n",
      "[7212/8000] D loss: 0.8205, G loss: 5.8684\n",
      "[7572/8000] D loss: 0.4197, G loss: 10.1029\n",
      "[7932/8000] D loss: 0.8375, G loss: 6.4427\n",
      "train error: \n",
      " D loss: 0.828099, G loss: 5.173581, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.863231, G loss: 15.209097, D accuracy: 81.1%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6440, G loss: 6.4405\n",
      "[372/8000] D loss: 1.0963, G loss: 1.3402\n",
      "[732/8000] D loss: 0.3688, G loss: 11.2090\n",
      "[1092/8000] D loss: 0.7295, G loss: 4.7843\n",
      "[1452/8000] D loss: 0.9483, G loss: 4.6173\n",
      "[1812/8000] D loss: 0.5445, G loss: 9.0507\n",
      "[2172/8000] D loss: 0.7308, G loss: 8.7397\n",
      "[2532/8000] D loss: 1.0130, G loss: 2.6626\n",
      "[2892/8000] D loss: 0.9406, G loss: 8.2649\n",
      "[3252/8000] D loss: 0.9294, G loss: 7.5580\n",
      "[3612/8000] D loss: 0.9360, G loss: 7.4992\n",
      "[3972/8000] D loss: 0.7539, G loss: 6.8426\n",
      "[4332/8000] D loss: 0.9662, G loss: 2.3375\n",
      "[4692/8000] D loss: 0.8831, G loss: 3.1582\n",
      "[5052/8000] D loss: 0.8434, G loss: 4.9241\n",
      "[5412/8000] D loss: 0.8376, G loss: 5.5759\n",
      "[5772/8000] D loss: 0.7556, G loss: 4.7825\n",
      "[6132/8000] D loss: 0.6664, G loss: 6.6265\n",
      "[6492/8000] D loss: 0.5179, G loss: 8.6240\n",
      "[6852/8000] D loss: 0.7306, G loss: 8.2786\n",
      "[7212/8000] D loss: 0.8868, G loss: 6.4687\n",
      "[7572/8000] D loss: 0.4587, G loss: 9.6913\n",
      "[7932/8000] D loss: 1.0425, G loss: 5.7055\n",
      "train error: \n",
      " D loss: 0.826752, G loss: 5.467987, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.955850, G loss: 15.714339, D accuracy: 78.2%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9347, G loss: 5.0396\n",
      "[372/8000] D loss: 0.8619, G loss: 11.7471\n",
      "[732/8000] D loss: 0.7941, G loss: 5.8990\n",
      "[1092/8000] D loss: 1.0631, G loss: 7.1418\n",
      "[1452/8000] D loss: 0.8918, G loss: 3.9032\n",
      "[1812/8000] D loss: 1.1363, G loss: 2.1946\n",
      "[2172/8000] D loss: 0.7020, G loss: 4.4225\n",
      "[2532/8000] D loss: 1.0349, G loss: 4.3301\n",
      "[2892/8000] D loss: 0.6273, G loss: 10.7123\n",
      "[3252/8000] D loss: 1.0718, G loss: 6.0088\n",
      "[3612/8000] D loss: 1.0402, G loss: 2.7660\n",
      "[3972/8000] D loss: 0.7816, G loss: 7.5992\n",
      "[4332/8000] D loss: 0.9151, G loss: 4.2892\n",
      "[4692/8000] D loss: 1.0070, G loss: 4.7882\n",
      "[5052/8000] D loss: 0.7620, G loss: 7.6849\n",
      "[5412/8000] D loss: 0.9303, G loss: 4.5408\n",
      "[5772/8000] D loss: 0.6607, G loss: 5.1400\n",
      "[6132/8000] D loss: 0.8044, G loss: 5.8806\n",
      "[6492/8000] D loss: 0.7919, G loss: 7.5581\n",
      "[6852/8000] D loss: 0.4852, G loss: 10.0890\n",
      "[7212/8000] D loss: 0.9656, G loss: 2.2322\n",
      "[7572/8000] D loss: 0.8141, G loss: 5.6114\n",
      "[7932/8000] D loss: 1.0007, G loss: 2.3752\n",
      "train error: \n",
      " D loss: 0.827085, G loss: 5.071516, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.943248, G loss: 14.851092, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6145, G loss: 3.6712\n",
      "[372/8000] D loss: 0.8831, G loss: 2.7534\n",
      "[732/8000] D loss: 0.3404, G loss: 8.8390\n",
      "[1092/8000] D loss: 0.5919, G loss: 17.1373\n",
      "[1452/8000] D loss: 0.7241, G loss: 10.6409\n",
      "[1812/8000] D loss: 0.6572, G loss: 7.3894\n",
      "[2172/8000] D loss: 0.8030, G loss: 3.8380\n",
      "[2532/8000] D loss: 0.6670, G loss: 7.2691\n",
      "[2892/8000] D loss: 0.9511, G loss: 6.3198\n",
      "[3252/8000] D loss: 0.8023, G loss: 3.4643\n",
      "[3612/8000] D loss: 0.9900, G loss: 6.1843\n",
      "[3972/8000] D loss: 0.7354, G loss: 4.8777\n",
      "[4332/8000] D loss: 0.6977, G loss: 4.9213\n",
      "[4692/8000] D loss: 0.7444, G loss: 6.2966\n",
      "[5052/8000] D loss: 0.8224, G loss: 7.3891\n",
      "[5412/8000] D loss: 0.8194, G loss: 2.6132\n",
      "[5772/8000] D loss: 0.9198, G loss: 3.4243\n",
      "[6132/8000] D loss: 0.9269, G loss: 3.5077\n",
      "[6492/8000] D loss: 0.8656, G loss: 12.2932\n",
      "[6852/8000] D loss: 0.5860, G loss: 6.2830\n",
      "[7212/8000] D loss: 1.0867, G loss: 5.1021\n",
      "[7572/8000] D loss: 1.0309, G loss: 1.7982\n",
      "[7932/8000] D loss: 0.6038, G loss: 7.4120\n",
      "train error: \n",
      " D loss: 0.828899, G loss: 6.422236, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.028654, G loss: 17.186954, D accuracy: 77.1%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8772, G loss: 3.6932\n",
      "[372/8000] D loss: 1.0835, G loss: 2.2830\n",
      "[732/8000] D loss: 0.8589, G loss: 4.3327\n",
      "[1092/8000] D loss: 0.9881, G loss: 2.8353\n",
      "[1452/8000] D loss: 0.7155, G loss: 7.4153\n",
      "[1812/8000] D loss: 0.6197, G loss: 7.2436\n",
      "[2172/8000] D loss: 1.0194, G loss: 5.3190\n",
      "[2532/8000] D loss: 0.7594, G loss: 12.9368\n",
      "[2892/8000] D loss: 0.9621, G loss: 4.2832\n",
      "[3252/8000] D loss: 0.8380, G loss: 6.3882\n",
      "[3612/8000] D loss: 0.8135, G loss: 4.1776\n",
      "[3972/8000] D loss: 0.8842, G loss: 6.1816\n",
      "[4332/8000] D loss: 1.1818, G loss: 2.1364\n",
      "[4692/8000] D loss: 1.2554, G loss: 4.0890\n",
      "[5052/8000] D loss: 0.9075, G loss: 4.4773\n",
      "[5412/8000] D loss: 0.5404, G loss: 6.2246\n",
      "[5772/8000] D loss: 0.9977, G loss: 5.9370\n",
      "[6132/8000] D loss: 0.7542, G loss: 4.8165\n",
      "[6492/8000] D loss: 0.7551, G loss: 5.7586\n",
      "[6852/8000] D loss: 0.7824, G loss: 7.6768\n",
      "[7212/8000] D loss: 0.8065, G loss: 6.1498\n",
      "[7572/8000] D loss: 0.8802, G loss: 6.7682\n",
      "[7932/8000] D loss: 0.7108, G loss: 4.8660\n",
      "train error: \n",
      " D loss: 0.857898, G loss: 4.909560, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 54.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.803177, G loss: 15.210572, D accuracy: 82.9%, cell accuracy: 98.2%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9530, G loss: 5.9751\n",
      "[372/8000] D loss: 0.6313, G loss: 9.3840\n",
      "[732/8000] D loss: 0.9001, G loss: 3.5564\n",
      "[1092/8000] D loss: 0.6098, G loss: 7.8241\n",
      "[1452/8000] D loss: 1.1433, G loss: 4.9684\n",
      "[1812/8000] D loss: 0.8221, G loss: 3.8433\n",
      "[2172/8000] D loss: 0.8628, G loss: 9.6128\n",
      "[2532/8000] D loss: 0.5937, G loss: 7.0445\n",
      "[2892/8000] D loss: 0.6408, G loss: 7.6171\n",
      "[3252/8000] D loss: 0.8478, G loss: 5.3236\n",
      "[3612/8000] D loss: 0.7505, G loss: 4.9870\n",
      "[3972/8000] D loss: 0.8921, G loss: 7.0746\n",
      "[4332/8000] D loss: 0.8717, G loss: 1.7638\n",
      "[4692/8000] D loss: 0.8125, G loss: 5.1314\n",
      "[5052/8000] D loss: 0.8512, G loss: 2.9155\n",
      "[5412/8000] D loss: 0.6792, G loss: 6.0461\n",
      "[5772/8000] D loss: 0.5580, G loss: 7.9829\n",
      "[6132/8000] D loss: 0.7563, G loss: 6.3783\n",
      "[6492/8000] D loss: 0.8727, G loss: 4.4917\n",
      "[6852/8000] D loss: 0.8027, G loss: 2.9464\n",
      "[7212/8000] D loss: 0.9930, G loss: 2.8178\n",
      "[7572/8000] D loss: 0.5826, G loss: 6.4186\n",
      "[7932/8000] D loss: 1.1103, G loss: 2.8800\n",
      "train error: \n",
      " D loss: 0.822231, G loss: 5.313010, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.930151, G loss: 15.223569, D accuracy: 80.7%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6778, G loss: 5.4737\n",
      "[372/8000] D loss: 0.9571, G loss: 4.8095\n",
      "[732/8000] D loss: 0.9125, G loss: 5.1778\n",
      "[1092/8000] D loss: 0.5019, G loss: 5.0601\n",
      "[1452/8000] D loss: 0.7834, G loss: 5.2370\n",
      "[1812/8000] D loss: 0.4838, G loss: 6.1186\n",
      "[2172/8000] D loss: 0.5916, G loss: 6.4806\n",
      "[2532/8000] D loss: 1.0420, G loss: 3.7909\n",
      "[2892/8000] D loss: 0.6096, G loss: 7.1275\n",
      "[3252/8000] D loss: 0.7672, G loss: 4.2100\n",
      "[3612/8000] D loss: 0.8203, G loss: 2.7640\n",
      "[3972/8000] D loss: 0.8333, G loss: 8.3430\n",
      "[4332/8000] D loss: 0.8397, G loss: 4.4227\n",
      "[4692/8000] D loss: 1.0100, G loss: 1.6954\n",
      "[5052/8000] D loss: 0.7892, G loss: 3.1236\n",
      "[5412/8000] D loss: 0.8019, G loss: 5.9268\n",
      "[5772/8000] D loss: 0.7224, G loss: 6.9115\n",
      "[6132/8000] D loss: 0.6835, G loss: 16.0223\n",
      "[6492/8000] D loss: 0.8311, G loss: 5.5756\n",
      "[6852/8000] D loss: 0.8621, G loss: 5.8336\n",
      "[7212/8000] D loss: 0.4743, G loss: 7.4132\n",
      "[7572/8000] D loss: 0.9586, G loss: 3.0150\n",
      "[7932/8000] D loss: 1.0314, G loss: 9.0175\n",
      "train error: \n",
      " D loss: 0.866925, G loss: 4.739971, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.798096, G loss: 14.643994, D accuracy: 83.3%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9544, G loss: 3.2693\n",
      "[372/8000] D loss: 0.8707, G loss: 4.3625\n",
      "[732/8000] D loss: 0.8371, G loss: 6.3086\n",
      "[1092/8000] D loss: 0.9827, G loss: 2.8935\n",
      "[1452/8000] D loss: 0.4287, G loss: 3.7984\n",
      "[1812/8000] D loss: 0.7935, G loss: 4.0784\n",
      "[2172/8000] D loss: 0.8256, G loss: 7.5802\n",
      "[2532/8000] D loss: 1.1453, G loss: 1.5100\n",
      "[2892/8000] D loss: 0.8436, G loss: 7.0785\n",
      "[3252/8000] D loss: 0.7668, G loss: 5.1809\n",
      "[3612/8000] D loss: 0.8928, G loss: 9.2545\n",
      "[3972/8000] D loss: 0.7143, G loss: 6.4120\n",
      "[4332/8000] D loss: 0.9354, G loss: 4.1908\n",
      "[4692/8000] D loss: 1.1390, G loss: 2.8601\n",
      "[5052/8000] D loss: 0.6170, G loss: 12.8595\n",
      "[5412/8000] D loss: 1.0422, G loss: 4.8383\n",
      "[5772/8000] D loss: 0.8502, G loss: 2.7532\n",
      "[6132/8000] D loss: 0.9501, G loss: 2.0064\n",
      "[6492/8000] D loss: 0.8861, G loss: 7.7426\n",
      "[6852/8000] D loss: 0.6960, G loss: 5.2303\n",
      "[7212/8000] D loss: 0.5343, G loss: 9.0976\n",
      "[7572/8000] D loss: 0.8925, G loss: 5.4860\n",
      "[7932/8000] D loss: 1.1671, G loss: 2.9446\n",
      "train error: \n",
      " D loss: 0.833560, G loss: 4.917002, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.860489, G loss: 14.329079, D accuracy: 81.8%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8817, G loss: 2.3690\n",
      "[372/8000] D loss: 0.7088, G loss: 6.3916\n",
      "[732/8000] D loss: 0.2607, G loss: 13.8747\n",
      "[1092/8000] D loss: 0.5695, G loss: 8.9837\n",
      "[1452/8000] D loss: 0.5062, G loss: 8.1758\n",
      "[1812/8000] D loss: 0.8528, G loss: 4.0267\n",
      "[2172/8000] D loss: 1.0142, G loss: 3.5491\n",
      "[2532/8000] D loss: 0.7077, G loss: 7.3230\n",
      "[2892/8000] D loss: 0.9092, G loss: 2.4490\n",
      "[3252/8000] D loss: 0.8161, G loss: 4.8790\n",
      "[3612/8000] D loss: 0.8713, G loss: 5.4468\n",
      "[3972/8000] D loss: 0.9244, G loss: 4.0820\n",
      "[4332/8000] D loss: 0.7096, G loss: 7.5593\n",
      "[4692/8000] D loss: 0.6494, G loss: 7.1298\n",
      "[5052/8000] D loss: 0.8271, G loss: 4.6527\n",
      "[5412/8000] D loss: 1.1687, G loss: 2.5888\n",
      "[5772/8000] D loss: 0.9328, G loss: 7.5600\n",
      "[6132/8000] D loss: 0.3880, G loss: 9.7907\n",
      "[6492/8000] D loss: 0.8246, G loss: 7.6499\n",
      "[6852/8000] D loss: 1.0105, G loss: 2.9812\n",
      "[7212/8000] D loss: 0.6460, G loss: 7.4362\n",
      "[7572/8000] D loss: 0.7904, G loss: 6.2876\n",
      "[7932/8000] D loss: 0.4526, G loss: 10.9895\n",
      "train error: \n",
      " D loss: 0.833584, G loss: 5.699661, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.882557, G loss: 16.235995, D accuracy: 81.0%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9632, G loss: 3.5333\n",
      "[372/8000] D loss: 0.8943, G loss: 7.9350\n",
      "[732/8000] D loss: 0.8474, G loss: 3.2907\n",
      "[1092/8000] D loss: 0.5521, G loss: 13.8789\n",
      "[1452/8000] D loss: 0.6962, G loss: 5.1495\n",
      "[1812/8000] D loss: 0.6447, G loss: 4.5032\n",
      "[2172/8000] D loss: 0.8272, G loss: 5.6600\n",
      "[2532/8000] D loss: 0.8476, G loss: 3.8488\n",
      "[2892/8000] D loss: 0.8451, G loss: 6.2873\n",
      "[3252/8000] D loss: 1.0035, G loss: 5.0903\n",
      "[3612/8000] D loss: 1.0111, G loss: 6.5188\n",
      "[3972/8000] D loss: 0.9582, G loss: 5.1872\n",
      "[4332/8000] D loss: 1.0228, G loss: 3.7384\n",
      "[4692/8000] D loss: 0.8497, G loss: 3.8011\n",
      "[5052/8000] D loss: 1.0251, G loss: 5.9008\n",
      "[5412/8000] D loss: 0.6429, G loss: 7.7312\n",
      "[5772/8000] D loss: 0.6767, G loss: 9.8307\n",
      "[6132/8000] D loss: 0.9900, G loss: 3.5746\n",
      "[6492/8000] D loss: 1.1729, G loss: 1.0194\n",
      "[6852/8000] D loss: 0.9378, G loss: 5.5633\n",
      "[7212/8000] D loss: 0.8434, G loss: 3.3128\n",
      "[7572/8000] D loss: 0.8641, G loss: 3.6222\n",
      "[7932/8000] D loss: 1.1941, G loss: 2.9178\n",
      "train error: \n",
      " D loss: 0.827807, G loss: 5.754701, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.007395, G loss: 16.353575, D accuracy: 76.5%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7209, G loss: 7.3848\n",
      "[372/8000] D loss: 0.8258, G loss: 4.7657\n",
      "[732/8000] D loss: 0.6576, G loss: 5.4679\n",
      "[1092/8000] D loss: 0.6718, G loss: 6.7153\n",
      "[1452/8000] D loss: 0.8158, G loss: 3.2889\n",
      "[1812/8000] D loss: 0.6035, G loss: 6.7351\n",
      "[2172/8000] D loss: 0.7417, G loss: 5.3239\n",
      "[2532/8000] D loss: 0.9906, G loss: 4.7917\n",
      "[2892/8000] D loss: 0.9991, G loss: 3.3260\n",
      "[3252/8000] D loss: 1.3079, G loss: 1.4417\n",
      "[3612/8000] D loss: 0.6177, G loss: 7.3490\n",
      "[3972/8000] D loss: 0.9028, G loss: 7.1389\n",
      "[4332/8000] D loss: 0.9087, G loss: 3.4596\n",
      "[4692/8000] D loss: 0.8122, G loss: 4.5845\n",
      "[5052/8000] D loss: 0.8165, G loss: 2.8709\n",
      "[5412/8000] D loss: 0.5109, G loss: 9.1109\n",
      "[5772/8000] D loss: 0.9889, G loss: 4.5076\n",
      "[6132/8000] D loss: 1.1831, G loss: 7.1698\n",
      "[6492/8000] D loss: 0.8224, G loss: 6.0034\n",
      "[6852/8000] D loss: 0.6106, G loss: 6.8680\n",
      "[7212/8000] D loss: 0.7020, G loss: 7.0438\n",
      "[7572/8000] D loss: 1.2327, G loss: 2.5287\n",
      "[7932/8000] D loss: 0.9171, G loss: 3.3916\n",
      "train error: \n",
      " D loss: 0.832111, G loss: 5.389266, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.919639, G loss: 15.734473, D accuracy: 80.9%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7128, G loss: 7.4620\n",
      "[372/8000] D loss: 0.4859, G loss: 8.9170\n",
      "[732/8000] D loss: 0.3260, G loss: 13.3207\n",
      "[1092/8000] D loss: 0.7252, G loss: 5.9456\n",
      "[1452/8000] D loss: 0.9918, G loss: 4.5609\n",
      "[1812/8000] D loss: 0.9234, G loss: 2.8560\n",
      "[2172/8000] D loss: 0.8340, G loss: 4.7553\n",
      "[2532/8000] D loss: 0.6469, G loss: 8.0431\n",
      "[2892/8000] D loss: 1.0651, G loss: 2.6496\n",
      "[3252/8000] D loss: 1.1337, G loss: 1.9805\n",
      "[3612/8000] D loss: 0.8044, G loss: 4.6351\n",
      "[3972/8000] D loss: 0.9003, G loss: 4.2046\n",
      "[4332/8000] D loss: 0.7050, G loss: 8.0020\n",
      "[4692/8000] D loss: 0.8431, G loss: 4.2293\n",
      "[5052/8000] D loss: 1.0599, G loss: 3.2694\n",
      "[5412/8000] D loss: 0.8525, G loss: 3.3813\n",
      "[5772/8000] D loss: 1.0248, G loss: 5.0331\n",
      "[6132/8000] D loss: 0.5142, G loss: 6.9009\n",
      "[6492/8000] D loss: 0.8234, G loss: 2.7337\n",
      "[6852/8000] D loss: 0.4767, G loss: 10.2435\n",
      "[7212/8000] D loss: 0.5254, G loss: 11.2133\n",
      "[7572/8000] D loss: 0.7233, G loss: 8.2198\n",
      "[7932/8000] D loss: 0.8484, G loss: 8.9017\n",
      "train error: \n",
      " D loss: 0.828215, G loss: 5.079026, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.853277, G loss: 15.529688, D accuracy: 81.3%, cell accuracy: 98.2%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5573, G loss: 4.6928\n",
      "[372/8000] D loss: 0.5825, G loss: 8.2378\n",
      "[732/8000] D loss: 0.5948, G loss: 6.3045\n",
      "[1092/8000] D loss: 0.7542, G loss: 9.4339\n",
      "[1452/8000] D loss: 0.9391, G loss: 3.5660\n",
      "[1812/8000] D loss: 1.0122, G loss: 3.7822\n",
      "[2172/8000] D loss: 0.7698, G loss: 5.6803\n",
      "[2532/8000] D loss: 1.3025, G loss: 1.2713\n",
      "[2892/8000] D loss: 0.8941, G loss: 7.0254\n",
      "[3252/8000] D loss: 0.7787, G loss: 4.4589\n",
      "[3612/8000] D loss: 0.5931, G loss: 12.5092\n",
      "[3972/8000] D loss: 0.9451, G loss: 3.1012\n",
      "[4332/8000] D loss: 1.1425, G loss: 4.1205\n",
      "[4692/8000] D loss: 0.8154, G loss: 6.9251\n",
      "[5052/8000] D loss: 0.6516, G loss: 4.5602\n",
      "[5412/8000] D loss: 0.5107, G loss: 9.1691\n",
      "[5772/8000] D loss: 0.8669, G loss: 3.6633\n",
      "[6132/8000] D loss: 0.4756, G loss: 11.2185\n",
      "[6492/8000] D loss: 0.9178, G loss: 1.8255\n",
      "[6852/8000] D loss: 0.4742, G loss: 14.0970\n",
      "[7212/8000] D loss: 0.5637, G loss: 11.9601\n",
      "[7572/8000] D loss: 0.8212, G loss: 4.7392\n",
      "[7932/8000] D loss: 0.6498, G loss: 8.1296\n",
      "train error: \n",
      " D loss: 0.846144, G loss: 6.017004, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.865546, G loss: 17.254147, D accuracy: 82.0%, cell accuracy: 98.2%, board accuracy: 26.3% \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7531, G loss: 7.7343\n",
      "[372/8000] D loss: 0.8152, G loss: 4.9442\n",
      "[732/8000] D loss: 0.8825, G loss: 2.1051\n",
      "[1092/8000] D loss: 1.0041, G loss: 2.0273\n",
      "[1452/8000] D loss: 0.5108, G loss: 13.2564\n",
      "[1812/8000] D loss: 0.8703, G loss: 6.3770\n",
      "[2172/8000] D loss: 0.8533, G loss: 8.2984\n",
      "[2532/8000] D loss: 0.8615, G loss: 6.3551\n",
      "[2892/8000] D loss: 1.0232, G loss: 2.0055\n",
      "[3252/8000] D loss: 0.8171, G loss: 7.1616\n",
      "[3612/8000] D loss: 0.9369, G loss: 3.0875\n",
      "[3972/8000] D loss: 0.3764, G loss: 10.6285\n",
      "[4332/8000] D loss: 0.6682, G loss: 13.4355\n",
      "[4692/8000] D loss: 1.0445, G loss: 4.1670\n",
      "[5052/8000] D loss: 0.4499, G loss: 5.8865\n",
      "[5412/8000] D loss: 0.8164, G loss: 4.0227\n",
      "[5772/8000] D loss: 0.9248, G loss: 5.5540\n",
      "[6132/8000] D loss: 0.9319, G loss: 7.7806\n",
      "[6492/8000] D loss: 1.0788, G loss: 2.8541\n",
      "[6852/8000] D loss: 0.4432, G loss: 9.3906\n",
      "[7212/8000] D loss: 0.9061, G loss: 4.1885\n",
      "[7572/8000] D loss: 0.6908, G loss: 8.7492\n",
      "[7932/8000] D loss: 0.9704, G loss: 4.4174\n",
      "train error: \n",
      " D loss: 0.844358, G loss: 5.466888, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.821552, G loss: 15.847466, D accuracy: 79.5%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7216, G loss: 4.3178\n",
      "[372/8000] D loss: 0.7227, G loss: 3.7760\n",
      "[732/8000] D loss: 0.7908, G loss: 4.6623\n",
      "[1092/8000] D loss: 0.7832, G loss: 11.4366\n",
      "[1452/8000] D loss: 1.0419, G loss: 4.0478\n",
      "[1812/8000] D loss: 0.6919, G loss: 5.7752\n",
      "[2172/8000] D loss: 0.9113, G loss: 3.1840\n",
      "[2532/8000] D loss: 0.5413, G loss: 11.8318\n",
      "[2892/8000] D loss: 0.8229, G loss: 5.4127\n",
      "[3252/8000] D loss: 0.6380, G loss: 9.0616\n",
      "[3612/8000] D loss: 1.1567, G loss: 3.4142\n",
      "[3972/8000] D loss: 0.8380, G loss: 6.2677\n",
      "[4332/8000] D loss: 0.6081, G loss: 8.5099\n",
      "[4692/8000] D loss: 0.8193, G loss: 4.3026\n",
      "[5052/8000] D loss: 1.2583, G loss: 1.6955\n",
      "[5412/8000] D loss: 0.7480, G loss: 9.8031\n",
      "[5772/8000] D loss: 0.9030, G loss: 2.9676\n",
      "[6132/8000] D loss: 0.6473, G loss: 4.1768\n",
      "[6492/8000] D loss: 0.6169, G loss: 6.8619\n",
      "[6852/8000] D loss: 1.0578, G loss: 2.6887\n",
      "[7212/8000] D loss: 0.7990, G loss: 9.4546\n",
      "[7572/8000] D loss: 0.8736, G loss: 6.5581\n",
      "[7932/8000] D loss: 0.8221, G loss: 6.1954\n",
      "train error: \n",
      " D loss: 0.824489, G loss: 5.276359, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.946551, G loss: 15.361804, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1933, G loss: 2.8976\n",
      "[372/8000] D loss: 0.3100, G loss: 13.2310\n",
      "[732/8000] D loss: 0.7816, G loss: 15.4438\n",
      "[1092/8000] D loss: 0.9437, G loss: 6.2233\n",
      "[1452/8000] D loss: 0.4442, G loss: 6.7987\n",
      "[1812/8000] D loss: 0.9392, G loss: 6.4066\n",
      "[2172/8000] D loss: 0.5811, G loss: 5.0881\n",
      "[2532/8000] D loss: 0.5944, G loss: 5.1193\n",
      "[2892/8000] D loss: 0.7855, G loss: 3.2657\n",
      "[3252/8000] D loss: 1.0951, G loss: 3.4396\n",
      "[3612/8000] D loss: 0.8761, G loss: 6.3373\n",
      "[3972/8000] D loss: 0.7001, G loss: 8.7129\n",
      "[4332/8000] D loss: 1.0847, G loss: 2.7094\n",
      "[4692/8000] D loss: 0.8567, G loss: 5.3127\n",
      "[5052/8000] D loss: 1.0646, G loss: 1.7679\n",
      "[5412/8000] D loss: 0.3660, G loss: 7.6331\n",
      "[5772/8000] D loss: 0.5115, G loss: 4.8301\n",
      "[6132/8000] D loss: 1.2236, G loss: 1.2766\n",
      "[6492/8000] D loss: 1.0205, G loss: 2.1901\n",
      "[6852/8000] D loss: 0.5591, G loss: 5.9046\n",
      "[7212/8000] D loss: 0.8399, G loss: 8.7817\n",
      "[7572/8000] D loss: 1.0569, G loss: 3.8071\n",
      "[7932/8000] D loss: 0.7171, G loss: 4.9216\n",
      "train error: \n",
      " D loss: 0.838021, G loss: 4.621267, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.951997, G loss: 14.321013, D accuracy: 79.3%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9176, G loss: 4.0087\n",
      "[372/8000] D loss: 0.7797, G loss: 5.7621\n",
      "[732/8000] D loss: 0.9521, G loss: 4.0730\n",
      "[1092/8000] D loss: 1.0125, G loss: 1.8053\n",
      "[1452/8000] D loss: 0.6259, G loss: 6.1516\n",
      "[1812/8000] D loss: 0.8976, G loss: 3.4839\n",
      "[2172/8000] D loss: 0.8689, G loss: 6.3558\n",
      "[2532/8000] D loss: 1.1011, G loss: 2.6321\n",
      "[2892/8000] D loss: 0.9930, G loss: 3.5068\n",
      "[3252/8000] D loss: 0.9924, G loss: 2.5564\n",
      "[3612/8000] D loss: 0.6693, G loss: 5.1327\n",
      "[3972/8000] D loss: 0.6947, G loss: 5.5332\n",
      "[4332/8000] D loss: 0.5586, G loss: 4.4331\n",
      "[4692/8000] D loss: 0.6982, G loss: 7.3332\n",
      "[5052/8000] D loss: 0.6157, G loss: 7.2888\n",
      "[5412/8000] D loss: 0.6908, G loss: 8.5893\n",
      "[5772/8000] D loss: 0.9903, G loss: 3.0506\n",
      "[6132/8000] D loss: 0.9560, G loss: 4.3546\n",
      "[6492/8000] D loss: 0.4870, G loss: 9.0377\n",
      "[6852/8000] D loss: 0.9158, G loss: 1.8613\n",
      "[7212/8000] D loss: 0.8229, G loss: 10.2133\n",
      "[7572/8000] D loss: 0.8635, G loss: 5.8760\n",
      "[7932/8000] D loss: 1.0313, G loss: 4.4723\n",
      "train error: \n",
      " D loss: 0.819484, G loss: 5.837128, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.936159, G loss: 16.418179, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7699, G loss: 8.2664\n",
      "[372/8000] D loss: 0.6795, G loss: 5.7285\n",
      "[732/8000] D loss: 0.5713, G loss: 5.0942\n",
      "[1092/8000] D loss: 0.8032, G loss: 6.9367\n",
      "[1452/8000] D loss: 0.5052, G loss: 10.0039\n",
      "[1812/8000] D loss: 0.5688, G loss: 6.7488\n",
      "[2172/8000] D loss: 0.9972, G loss: 2.3755\n",
      "[2532/8000] D loss: 0.8109, G loss: 4.9698\n",
      "[2892/8000] D loss: 1.0417, G loss: 3.3679\n",
      "[3252/8000] D loss: 0.6458, G loss: 5.4585\n",
      "[3612/8000] D loss: 0.6065, G loss: 6.4313\n",
      "[3972/8000] D loss: 0.4537, G loss: 10.1933\n",
      "[4332/8000] D loss: 0.7184, G loss: 6.9880\n",
      "[4692/8000] D loss: 0.9064, G loss: 2.4787\n",
      "[5052/8000] D loss: 0.7464, G loss: 5.8737\n",
      "[5412/8000] D loss: 0.8257, G loss: 4.6801\n",
      "[5772/8000] D loss: 0.8990, G loss: 4.2730\n",
      "[6132/8000] D loss: 0.7210, G loss: 6.1118\n",
      "[6492/8000] D loss: 0.5093, G loss: 6.6537\n",
      "[6852/8000] D loss: 0.6404, G loss: 5.3391\n",
      "[7212/8000] D loss: 0.8493, G loss: 5.9622\n",
      "[7572/8000] D loss: 0.9018, G loss: 4.1248\n",
      "[7932/8000] D loss: 0.6270, G loss: 7.1162\n",
      "train error: \n",
      " D loss: 0.818235, G loss: 6.253150, D accuracy: 73.5%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.975620, G loss: 17.817842, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 26.3% \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1110, G loss: 4.0504\n",
      "[372/8000] D loss: 0.8123, G loss: 5.3691\n",
      "[732/8000] D loss: 0.3522, G loss: 15.5442\n",
      "[1092/8000] D loss: 0.8563, G loss: 6.5146\n",
      "[1452/8000] D loss: 0.6593, G loss: 9.8623\n",
      "[1812/8000] D loss: 0.7496, G loss: 5.5603\n",
      "[2172/8000] D loss: 0.9378, G loss: 5.6143\n",
      "[2532/8000] D loss: 0.6746, G loss: 10.2165\n",
      "[2892/8000] D loss: 0.9182, G loss: 1.8367\n",
      "[3252/8000] D loss: 0.6641, G loss: 6.7861\n",
      "[3612/8000] D loss: 0.7954, G loss: 5.6355\n",
      "[3972/8000] D loss: 1.1736, G loss: 1.6085\n",
      "[4332/8000] D loss: 0.9188, G loss: 4.0050\n",
      "[4692/8000] D loss: 0.8389, G loss: 5.4868\n",
      "[5052/8000] D loss: 0.5290, G loss: 8.7325\n",
      "[5412/8000] D loss: 0.8308, G loss: 3.2431\n",
      "[5772/8000] D loss: 0.7626, G loss: 3.4631\n",
      "[6132/8000] D loss: 0.6992, G loss: 8.2495\n",
      "[6492/8000] D loss: 0.8284, G loss: 3.4906\n",
      "[6852/8000] D loss: 0.7277, G loss: 5.7234\n",
      "[7212/8000] D loss: 0.7767, G loss: 8.4846\n",
      "[7572/8000] D loss: 0.6411, G loss: 4.5426\n",
      "[7932/8000] D loss: 0.6466, G loss: 11.4707\n",
      "train error: \n",
      " D loss: 0.852296, G loss: 4.651895, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.844282, G loss: 14.422189, D accuracy: 82.4%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1921, G loss: 1.7419\n",
      "[372/8000] D loss: 0.7668, G loss: 5.5285\n",
      "[732/8000] D loss: 0.7174, G loss: 5.3803\n",
      "[1092/8000] D loss: 0.7566, G loss: 10.0783\n",
      "[1452/8000] D loss: 1.0589, G loss: 3.5147\n",
      "[1812/8000] D loss: 0.7806, G loss: 3.9905\n",
      "[2172/8000] D loss: 0.8942, G loss: 3.7610\n",
      "[2532/8000] D loss: 1.0701, G loss: 1.9974\n",
      "[2892/8000] D loss: 0.9529, G loss: 3.0665\n",
      "[3252/8000] D loss: 0.9493, G loss: 2.9673\n",
      "[3612/8000] D loss: 0.5743, G loss: 9.8736\n",
      "[3972/8000] D loss: 0.6581, G loss: 10.6403\n",
      "[4332/8000] D loss: 0.7029, G loss: 5.9129\n",
      "[4692/8000] D loss: 1.0728, G loss: 2.8792\n",
      "[5052/8000] D loss: 0.8165, G loss: 6.3264\n",
      "[5412/8000] D loss: 1.2533, G loss: 1.1111\n",
      "[5772/8000] D loss: 1.0391, G loss: 2.7315\n",
      "[6132/8000] D loss: 0.9024, G loss: 3.7528\n",
      "[6492/8000] D loss: 0.7067, G loss: 5.4264\n",
      "[6852/8000] D loss: 0.9903, G loss: 1.9671\n",
      "[7212/8000] D loss: 0.9195, G loss: 2.2214\n",
      "[7572/8000] D loss: 0.6335, G loss: 3.9594\n",
      "[7932/8000] D loss: 0.9191, G loss: 5.5050\n",
      "train error: \n",
      " D loss: 0.831615, G loss: 5.865207, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.967845, G loss: 16.739776, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6141, G loss: 8.2165\n",
      "[372/8000] D loss: 0.9048, G loss: 8.7573\n",
      "[732/8000] D loss: 1.1377, G loss: 2.2251\n",
      "[1092/8000] D loss: 0.9368, G loss: 4.5665\n",
      "[1452/8000] D loss: 0.8926, G loss: 4.8283\n",
      "[1812/8000] D loss: 1.0416, G loss: 5.7040\n",
      "[2172/8000] D loss: 1.0381, G loss: 6.5612\n",
      "[2532/8000] D loss: 0.6614, G loss: 7.8451\n",
      "[2892/8000] D loss: 0.7802, G loss: 3.0796\n",
      "[3252/8000] D loss: 0.8050, G loss: 5.3587\n",
      "[3612/8000] D loss: 0.7017, G loss: 5.3384\n",
      "[3972/8000] D loss: 0.8407, G loss: 6.8500\n",
      "[4332/8000] D loss: 0.9416, G loss: 4.1281\n",
      "[4692/8000] D loss: 1.0253, G loss: 2.1810\n",
      "[5052/8000] D loss: 0.6944, G loss: 4.5188\n",
      "[5412/8000] D loss: 0.6595, G loss: 11.1405\n",
      "[5772/8000] D loss: 0.8119, G loss: 4.1622\n",
      "[6132/8000] D loss: 0.4901, G loss: 6.0284\n",
      "[6492/8000] D loss: 0.5707, G loss: 7.5190\n",
      "[6852/8000] D loss: 1.0370, G loss: 2.0490\n",
      "[7212/8000] D loss: 0.3837, G loss: 7.5924\n",
      "[7572/8000] D loss: 0.8316, G loss: 2.9846\n",
      "[7932/8000] D loss: 0.9231, G loss: 6.7636\n",
      "train error: \n",
      " D loss: 0.832051, G loss: 5.764177, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.964652, G loss: 16.316035, D accuracy: 77.8%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2738, G loss: 1.2295\n",
      "[372/8000] D loss: 1.0614, G loss: 3.9178\n",
      "[732/8000] D loss: 0.6517, G loss: 5.3125\n",
      "[1092/8000] D loss: 1.0747, G loss: 2.8396\n",
      "[1452/8000] D loss: 0.8042, G loss: 5.0270\n",
      "[1812/8000] D loss: 0.6373, G loss: 7.9123\n",
      "[2172/8000] D loss: 0.6892, G loss: 7.1924\n",
      "[2532/8000] D loss: 0.7184, G loss: 5.1858\n",
      "[2892/8000] D loss: 0.7158, G loss: 5.4025\n",
      "[3252/8000] D loss: 0.5435, G loss: 8.9072\n",
      "[3612/8000] D loss: 1.0345, G loss: 4.2103\n",
      "[3972/8000] D loss: 0.9776, G loss: 6.9818\n",
      "[4332/8000] D loss: 0.6649, G loss: 5.8949\n",
      "[4692/8000] D loss: 0.9795, G loss: 3.0246\n",
      "[5052/8000] D loss: 0.6210, G loss: 10.9447\n",
      "[5412/8000] D loss: 0.8680, G loss: 4.3339\n",
      "[5772/8000] D loss: 0.7960, G loss: 6.6209\n",
      "[6132/8000] D loss: 0.6379, G loss: 12.1726\n",
      "[6492/8000] D loss: 0.5785, G loss: 7.9672\n",
      "[6852/8000] D loss: 0.8691, G loss: 3.3477\n",
      "[7212/8000] D loss: 0.9090, G loss: 3.1031\n",
      "[7572/8000] D loss: 0.8055, G loss: 4.3811\n",
      "[7932/8000] D loss: 1.0202, G loss: 6.0455\n",
      "train error: \n",
      " D loss: 0.837035, G loss: 5.243534, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.881383, G loss: 15.497759, D accuracy: 81.5%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8643, G loss: 7.2594\n",
      "[372/8000] D loss: 0.8115, G loss: 7.1448\n",
      "[732/8000] D loss: 0.6314, G loss: 4.8480\n",
      "[1092/8000] D loss: 0.7045, G loss: 5.4006\n",
      "[1452/8000] D loss: 1.0400, G loss: 2.3692\n",
      "[1812/8000] D loss: 0.8855, G loss: 6.3699\n",
      "[2172/8000] D loss: 0.3275, G loss: 10.8936\n",
      "[2532/8000] D loss: 0.8401, G loss: 3.3066\n",
      "[2892/8000] D loss: 0.9274, G loss: 3.6257\n",
      "[3252/8000] D loss: 0.8338, G loss: 7.2795\n",
      "[3612/8000] D loss: 0.9191, G loss: 3.5391\n",
      "[3972/8000] D loss: 1.0276, G loss: 5.6300\n",
      "[4332/8000] D loss: 0.7292, G loss: 4.8667\n",
      "[4692/8000] D loss: 0.7944, G loss: 5.4296\n",
      "[5052/8000] D loss: 1.0889, G loss: 6.3155\n",
      "[5412/8000] D loss: 0.8504, G loss: 3.1389\n",
      "[5772/8000] D loss: 0.7081, G loss: 4.5583\n",
      "[6132/8000] D loss: 0.9789, G loss: 4.9839\n",
      "[6492/8000] D loss: 0.6682, G loss: 8.1781\n",
      "[6852/8000] D loss: 0.9665, G loss: 2.8039\n",
      "[7212/8000] D loss: 0.6177, G loss: 9.6006\n",
      "[7572/8000] D loss: 0.7071, G loss: 8.2885\n",
      "[7932/8000] D loss: 0.3377, G loss: 15.5562\n",
      "train error: \n",
      " D loss: 0.829731, G loss: 5.697859, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.959699, G loss: 16.583833, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4845, G loss: 8.9784\n",
      "[372/8000] D loss: 0.8529, G loss: 3.1676\n",
      "[732/8000] D loss: 1.0778, G loss: 2.9691\n",
      "[1092/8000] D loss: 0.8352, G loss: 4.8784\n",
      "[1452/8000] D loss: 0.8051, G loss: 2.4674\n",
      "[1812/8000] D loss: 0.9778, G loss: 5.1143\n",
      "[2172/8000] D loss: 0.6318, G loss: 8.6164\n",
      "[2532/8000] D loss: 0.7419, G loss: 5.9029\n",
      "[2892/8000] D loss: 1.0718, G loss: 3.4971\n",
      "[3252/8000] D loss: 0.9229, G loss: 3.5933\n",
      "[3612/8000] D loss: 0.8045, G loss: 5.2070\n",
      "[3972/8000] D loss: 0.5281, G loss: 7.6932\n",
      "[4332/8000] D loss: 1.1102, G loss: 1.8048\n",
      "[4692/8000] D loss: 0.9187, G loss: 4.7856\n",
      "[5052/8000] D loss: 0.9402, G loss: 2.5102\n",
      "[5412/8000] D loss: 0.3793, G loss: 5.2460\n",
      "[5772/8000] D loss: 0.5181, G loss: 6.8117\n",
      "[6132/8000] D loss: 0.5987, G loss: 6.9243\n",
      "[6492/8000] D loss: 0.6094, G loss: 8.0915\n",
      "[6852/8000] D loss: 0.5158, G loss: 8.9369\n",
      "[7212/8000] D loss: 0.6771, G loss: 6.9456\n",
      "[7572/8000] D loss: 0.8860, G loss: 6.0546\n",
      "[7932/8000] D loss: 0.8158, G loss: 5.4707\n",
      "train error: \n",
      " D loss: 0.851160, G loss: 4.514165, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.955016, G loss: 13.562675, D accuracy: 77.9%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9085, G loss: 2.9516\n",
      "[372/8000] D loss: 0.6634, G loss: 10.8742\n",
      "[732/8000] D loss: 1.3888, G loss: 0.9988\n",
      "[1092/8000] D loss: 1.0114, G loss: 7.3987\n",
      "[1452/8000] D loss: 0.9224, G loss: 3.7345\n",
      "[1812/8000] D loss: 0.7863, G loss: 7.6557\n",
      "[2172/8000] D loss: 0.6584, G loss: 6.2685\n",
      "[2532/8000] D loss: 0.6435, G loss: 8.2015\n",
      "[2892/8000] D loss: 0.7550, G loss: 4.7971\n",
      "[3252/8000] D loss: 0.9215, G loss: 7.3661\n",
      "[3612/8000] D loss: 0.9192, G loss: 3.3853\n",
      "[3972/8000] D loss: 0.8887, G loss: 2.9126\n",
      "[4332/8000] D loss: 0.7661, G loss: 5.3739\n",
      "[4692/8000] D loss: 0.6110, G loss: 8.1544\n",
      "[5052/8000] D loss: 0.7304, G loss: 8.8278\n",
      "[5412/8000] D loss: 0.9095, G loss: 5.6604\n",
      "[5772/8000] D loss: 0.9047, G loss: 10.2316\n",
      "[6132/8000] D loss: 0.6481, G loss: 9.3113\n",
      "[6492/8000] D loss: 0.6858, G loss: 3.3659\n",
      "[6852/8000] D loss: 0.8653, G loss: 3.4512\n",
      "[7212/8000] D loss: 0.6255, G loss: 10.6397\n",
      "[7572/8000] D loss: 0.7718, G loss: 4.6309\n",
      "[7932/8000] D loss: 0.7785, G loss: 6.7075\n",
      "train error: \n",
      " D loss: 0.837212, G loss: 6.212452, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.943927, G loss: 17.196925, D accuracy: 78.1%, cell accuracy: 98.2%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6934, G loss: 6.7500\n",
      "[372/8000] D loss: 1.0169, G loss: 8.3470\n",
      "[732/8000] D loss: 0.9264, G loss: 2.4078\n",
      "[1092/8000] D loss: 0.5920, G loss: 11.3393\n",
      "[1452/8000] D loss: 0.8852, G loss: 2.9909\n",
      "[1812/8000] D loss: 0.7600, G loss: 4.2603\n",
      "[2172/8000] D loss: 0.8080, G loss: 6.6723\n",
      "[2532/8000] D loss: 0.8113, G loss: 3.8295\n",
      "[2892/8000] D loss: 0.8632, G loss: 7.1249\n",
      "[3252/8000] D loss: 0.4891, G loss: 5.0381\n",
      "[3612/8000] D loss: 0.5904, G loss: 3.5951\n",
      "[3972/8000] D loss: 0.6116, G loss: 11.8154\n",
      "[4332/8000] D loss: 0.6134, G loss: 8.5834\n",
      "[4692/8000] D loss: 1.0571, G loss: 2.0159\n",
      "[5052/8000] D loss: 1.1388, G loss: 3.0211\n",
      "[5412/8000] D loss: 0.8814, G loss: 4.8792\n",
      "[5772/8000] D loss: 0.6863, G loss: 5.7638\n",
      "[6132/8000] D loss: 1.0858, G loss: 4.2376\n",
      "[6492/8000] D loss: 0.7439, G loss: 5.8175\n",
      "[6852/8000] D loss: 1.1501, G loss: 3.1080\n",
      "[7212/8000] D loss: 0.6744, G loss: 9.3485\n",
      "[7572/8000] D loss: 0.9937, G loss: 4.6745\n",
      "[7932/8000] D loss: 1.2807, G loss: 1.4295\n",
      "train error: \n",
      " D loss: 0.837394, G loss: 5.448532, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.931627, G loss: 16.302315, D accuracy: 81.1%, cell accuracy: 98.2%, board accuracy: 26.0% \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7607, G loss: 8.4560\n",
      "[372/8000] D loss: 0.8098, G loss: 3.8255\n",
      "[732/8000] D loss: 1.0966, G loss: 3.0907\n",
      "[1092/8000] D loss: 0.9486, G loss: 6.2736\n",
      "[1452/8000] D loss: 0.9173, G loss: 5.8417\n",
      "[1812/8000] D loss: 0.7071, G loss: 7.6320\n",
      "[2172/8000] D loss: 0.8260, G loss: 8.5584\n",
      "[2532/8000] D loss: 0.9436, G loss: 4.8249\n",
      "[2892/8000] D loss: 0.4957, G loss: 11.3772\n",
      "[3252/8000] D loss: 0.6495, G loss: 4.5019\n",
      "[3612/8000] D loss: 1.0541, G loss: 3.0630\n",
      "[3972/8000] D loss: 0.9636, G loss: 3.8771\n",
      "[4332/8000] D loss: 0.7012, G loss: 6.1058\n",
      "[4692/8000] D loss: 0.7357, G loss: 9.2697\n",
      "[5052/8000] D loss: 0.7563, G loss: 4.4049\n",
      "[5412/8000] D loss: 0.7096, G loss: 4.9019\n",
      "[5772/8000] D loss: 0.5776, G loss: 10.2311\n",
      "[6132/8000] D loss: 0.4843, G loss: 11.1703\n",
      "[6492/8000] D loss: 0.6504, G loss: 5.0779\n",
      "[6852/8000] D loss: 1.1410, G loss: 1.7878\n",
      "[7212/8000] D loss: 0.6133, G loss: 4.9847\n",
      "[7572/8000] D loss: 0.9876, G loss: 3.3291\n",
      "[7932/8000] D loss: 0.8812, G loss: 7.5657\n",
      "train error: \n",
      " D loss: 0.821480, G loss: 6.194265, D accuracy: 73.5%, cell accuracy: 98.7%, board accuracy: 55.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.973086, G loss: 17.612741, D accuracy: 79.8%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5840, G loss: 8.8991\n",
      "[372/8000] D loss: 0.7950, G loss: 8.4056\n",
      "[732/8000] D loss: 1.0354, G loss: 3.2161\n",
      "[1092/8000] D loss: 1.1704, G loss: 1.5235\n",
      "[1452/8000] D loss: 1.2196, G loss: 6.8970\n",
      "[1812/8000] D loss: 0.6306, G loss: 3.4862\n",
      "[2172/8000] D loss: 0.8863, G loss: 7.4790\n",
      "[2532/8000] D loss: 0.8858, G loss: 3.1413\n",
      "[2892/8000] D loss: 0.8609, G loss: 4.0209\n",
      "[3252/8000] D loss: 0.7843, G loss: 8.2301\n",
      "[3612/8000] D loss: 0.9410, G loss: 8.8369\n",
      "[3972/8000] D loss: 1.2227, G loss: 1.5705\n",
      "[4332/8000] D loss: 1.0772, G loss: 4.6541\n",
      "[4692/8000] D loss: 0.6722, G loss: 10.0329\n",
      "[5052/8000] D loss: 0.8579, G loss: 4.2247\n",
      "[5412/8000] D loss: 1.0668, G loss: 4.3305\n",
      "[5772/8000] D loss: 0.4704, G loss: 5.9443\n",
      "[6132/8000] D loss: 0.3002, G loss: 12.0954\n",
      "[6492/8000] D loss: 0.6419, G loss: 3.1827\n",
      "[6852/8000] D loss: 0.7061, G loss: 6.7457\n",
      "[7212/8000] D loss: 0.9864, G loss: 5.3724\n",
      "[7572/8000] D loss: 0.7361, G loss: 3.8762\n",
      "[7932/8000] D loss: 1.0266, G loss: 2.6012\n",
      "train error: \n",
      " D loss: 0.819853, G loss: 5.947125, D accuracy: 73.4%, cell accuracy: 98.7%, board accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.928344, G loss: 16.713411, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1328, G loss: 2.2608\n",
      "[372/8000] D loss: 1.0260, G loss: 4.1525\n",
      "[732/8000] D loss: 0.4568, G loss: 11.9479\n",
      "[1092/8000] D loss: 0.5989, G loss: 5.1001\n",
      "[1452/8000] D loss: 1.0720, G loss: 6.1295\n",
      "[1812/8000] D loss: 0.7359, G loss: 10.2579\n",
      "[2172/8000] D loss: 1.0278, G loss: 4.2912\n",
      "[2532/8000] D loss: 1.2172, G loss: 1.2061\n",
      "[2892/8000] D loss: 1.1666, G loss: 1.2885\n",
      "[3252/8000] D loss: 0.8076, G loss: 5.7905\n",
      "[3612/8000] D loss: 0.7757, G loss: 7.6897\n",
      "[3972/8000] D loss: 0.7296, G loss: 4.8462\n",
      "[4332/8000] D loss: 0.8412, G loss: 4.5880\n",
      "[4692/8000] D loss: 0.5439, G loss: 7.5684\n",
      "[5052/8000] D loss: 0.7937, G loss: 5.5364\n",
      "[5412/8000] D loss: 0.9565, G loss: 3.1582\n",
      "[5772/8000] D loss: 0.5036, G loss: 6.3787\n",
      "[6132/8000] D loss: 0.7540, G loss: 8.3501\n",
      "[6492/8000] D loss: 0.9461, G loss: 5.4750\n",
      "[6852/8000] D loss: 0.5301, G loss: 6.3566\n",
      "[7212/8000] D loss: 0.8097, G loss: 5.0271\n",
      "[7572/8000] D loss: 0.8792, G loss: 3.4761\n",
      "[7932/8000] D loss: 0.7363, G loss: 7.7507\n",
      "train error: \n",
      " D loss: 0.865347, G loss: 4.652384, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 55.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.843061, G loss: 14.812455, D accuracy: 82.3%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2981, G loss: 2.9208\n",
      "[372/8000] D loss: 0.4983, G loss: 6.1588\n",
      "[732/8000] D loss: 1.2138, G loss: 1.5495\n",
      "[1092/8000] D loss: 0.8285, G loss: 7.9207\n",
      "[1452/8000] D loss: 0.9380, G loss: 4.7611\n",
      "[1812/8000] D loss: 0.4872, G loss: 9.1866\n",
      "[2172/8000] D loss: 0.9784, G loss: 5.8173\n",
      "[2532/8000] D loss: 0.7031, G loss: 5.2001\n",
      "[2892/8000] D loss: 0.7487, G loss: 6.9642\n",
      "[3252/8000] D loss: 0.7129, G loss: 4.0331\n",
      "[3612/8000] D loss: 0.7204, G loss: 6.2322\n",
      "[3972/8000] D loss: 0.8138, G loss: 4.4023\n",
      "[4332/8000] D loss: 0.5953, G loss: 7.0594\n",
      "[4692/8000] D loss: 0.7593, G loss: 4.2873\n",
      "[5052/8000] D loss: 0.9199, G loss: 4.4933\n",
      "[5412/8000] D loss: 0.8279, G loss: 9.2753\n",
      "[5772/8000] D loss: 0.5555, G loss: 9.4905\n",
      "[6132/8000] D loss: 0.8128, G loss: 8.9725\n",
      "[6492/8000] D loss: 0.8858, G loss: 3.8086\n",
      "[6852/8000] D loss: 0.8247, G loss: 6.3252\n",
      "[7212/8000] D loss: 0.5818, G loss: 9.0869\n",
      "[7572/8000] D loss: 0.7174, G loss: 5.1649\n",
      "[7932/8000] D loss: 0.9584, G loss: 7.9281\n",
      "train error: \n",
      " D loss: 0.835098, G loss: 5.901223, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 55.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.937877, G loss: 16.425806, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3668, G loss: 6.9287\n",
      "[372/8000] D loss: 1.0855, G loss: 1.7038\n",
      "[732/8000] D loss: 0.9495, G loss: 2.7350\n",
      "[1092/8000] D loss: 0.5043, G loss: 5.3233\n",
      "[1452/8000] D loss: 0.7241, G loss: 8.2803\n",
      "[1812/8000] D loss: 0.7122, G loss: 2.7231\n",
      "[2172/8000] D loss: 0.9470, G loss: 5.0337\n",
      "[2532/8000] D loss: 0.7704, G loss: 3.1587\n",
      "[2892/8000] D loss: 0.8606, G loss: 2.7972\n",
      "[3252/8000] D loss: 0.9661, G loss: 6.3251\n",
      "[3612/8000] D loss: 0.5187, G loss: 8.0111\n",
      "[3972/8000] D loss: 0.9750, G loss: 3.0541\n",
      "[4332/8000] D loss: 0.7500, G loss: 8.4254\n",
      "[4692/8000] D loss: 0.7196, G loss: 4.7389\n",
      "[5052/8000] D loss: 0.9071, G loss: 3.9327\n",
      "[5412/8000] D loss: 0.7765, G loss: 5.0299\n",
      "[5772/8000] D loss: 0.8145, G loss: 11.0045\n",
      "[6132/8000] D loss: 0.7526, G loss: 6.3530\n",
      "[6492/8000] D loss: 0.8058, G loss: 6.1019\n",
      "[6852/8000] D loss: 1.1519, G loss: 2.1177\n",
      "[7212/8000] D loss: 0.8392, G loss: 4.6400\n",
      "[7572/8000] D loss: 0.8215, G loss: 2.7608\n",
      "[7932/8000] D loss: 1.0276, G loss: 3.5211\n",
      "train error: \n",
      " D loss: 0.826635, G loss: 5.571780, D accuracy: 73.0%, cell accuracy: 98.7%, board accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.911184, G loss: 16.221340, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8525, G loss: 5.7841\n",
      "[372/8000] D loss: 0.9702, G loss: 4.3308\n",
      "[732/8000] D loss: 0.6797, G loss: 8.8193\n",
      "[1092/8000] D loss: 1.0348, G loss: 6.4851\n",
      "[1452/8000] D loss: 0.9225, G loss: 3.9658\n",
      "[1812/8000] D loss: 1.0903, G loss: 1.6645\n",
      "[2172/8000] D loss: 0.9866, G loss: 4.6111\n",
      "[2532/8000] D loss: 0.4145, G loss: 7.5865\n",
      "[2892/8000] D loss: 0.7334, G loss: 12.4183\n",
      "[3252/8000] D loss: 1.0028, G loss: 2.9155\n",
      "[3612/8000] D loss: 0.8385, G loss: 12.2377\n",
      "[3972/8000] D loss: 1.0675, G loss: 3.3341\n",
      "[4332/8000] D loss: 0.6720, G loss: 6.6246\n",
      "[4692/8000] D loss: 1.0352, G loss: 1.9979\n",
      "[5052/8000] D loss: 0.7315, G loss: 6.3121\n",
      "[5412/8000] D loss: 0.9408, G loss: 3.2993\n",
      "[5772/8000] D loss: 0.5995, G loss: 5.4867\n",
      "[6132/8000] D loss: 0.9272, G loss: 7.1044\n",
      "[6492/8000] D loss: 1.0748, G loss: 4.2450\n",
      "[6852/8000] D loss: 1.1391, G loss: 1.1408\n",
      "[7212/8000] D loss: 0.6126, G loss: 8.9370\n",
      "[7572/8000] D loss: 0.8110, G loss: 5.1147\n",
      "[7932/8000] D loss: 0.4666, G loss: 6.6218\n",
      "train error: \n",
      " D loss: 0.867466, G loss: 3.388942, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 55.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.828231, G loss: 11.927109, D accuracy: 81.8%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8122, G loss: 2.6039\n",
      "[372/8000] D loss: 0.8408, G loss: 8.7066\n",
      "[732/8000] D loss: 0.9860, G loss: 3.7881\n",
      "[1092/8000] D loss: 1.1572, G loss: 1.8553\n",
      "[1452/8000] D loss: 0.6119, G loss: 11.1268\n",
      "[1812/8000] D loss: 0.9713, G loss: 3.4976\n",
      "[2172/8000] D loss: 0.5774, G loss: 9.4257\n",
      "[2532/8000] D loss: 0.3301, G loss: 11.6044\n",
      "[2892/8000] D loss: 0.5733, G loss: 6.5111\n",
      "[3252/8000] D loss: 0.9292, G loss: 6.1758\n",
      "[3612/8000] D loss: 0.7080, G loss: 10.8363\n",
      "[3972/8000] D loss: 0.5811, G loss: 6.3503\n",
      "[4332/8000] D loss: 0.8323, G loss: 6.1264\n",
      "[4692/8000] D loss: 0.3506, G loss: 14.6158\n",
      "[5052/8000] D loss: 0.7038, G loss: 6.7568\n",
      "[5412/8000] D loss: 0.6201, G loss: 6.2230\n",
      "[5772/8000] D loss: 1.0242, G loss: 7.1940\n",
      "[6132/8000] D loss: 0.5929, G loss: 7.0298\n",
      "[6492/8000] D loss: 1.2263, G loss: 1.8919\n",
      "[6852/8000] D loss: 0.5662, G loss: 5.3440\n",
      "[7212/8000] D loss: 0.9546, G loss: 6.8177\n",
      "[7572/8000] D loss: 0.6136, G loss: 5.1527\n",
      "[7932/8000] D loss: 0.8466, G loss: 4.6963\n",
      "train error: \n",
      " D loss: 0.829340, G loss: 6.721806, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.979805, G loss: 18.551181, D accuracy: 78.2%, cell accuracy: 98.2%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9284, G loss: 4.5577\n",
      "[372/8000] D loss: 0.7902, G loss: 4.9647\n",
      "[732/8000] D loss: 0.9225, G loss: 2.0223\n",
      "[1092/8000] D loss: 0.5003, G loss: 11.4448\n",
      "[1452/8000] D loss: 1.2186, G loss: 8.5866\n",
      "[1812/8000] D loss: 1.2057, G loss: 3.9705\n",
      "[2172/8000] D loss: 1.0965, G loss: 2.9760\n",
      "[2532/8000] D loss: 1.0134, G loss: 4.7053\n",
      "[2892/8000] D loss: 0.6586, G loss: 7.6926\n",
      "[3252/8000] D loss: 0.5888, G loss: 9.5473\n",
      "[3612/8000] D loss: 0.9928, G loss: 2.6743\n",
      "[3972/8000] D loss: 0.5837, G loss: 7.3854\n",
      "[4332/8000] D loss: 0.8683, G loss: 4.5762\n",
      "[4692/8000] D loss: 0.8094, G loss: 3.0724\n",
      "[5052/8000] D loss: 0.6859, G loss: 6.9980\n",
      "[5412/8000] D loss: 1.1965, G loss: 1.1938\n",
      "[5772/8000] D loss: 0.7577, G loss: 5.7764\n",
      "[6132/8000] D loss: 0.6917, G loss: 9.4222\n",
      "[6492/8000] D loss: 1.0516, G loss: 3.5474\n",
      "[6852/8000] D loss: 0.8600, G loss: 5.4389\n",
      "[7212/8000] D loss: 0.6746, G loss: 4.5854\n",
      "[7572/8000] D loss: 0.6665, G loss: 7.2848\n",
      "[7932/8000] D loss: 0.7801, G loss: 3.7231\n",
      "train error: \n",
      " D loss: 0.839991, G loss: 5.670390, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.025448, G loss: 16.310790, D accuracy: 78.1%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8214, G loss: 7.8192\n",
      "[372/8000] D loss: 0.7166, G loss: 4.9848\n",
      "[732/8000] D loss: 0.7132, G loss: 8.8194\n",
      "[1092/8000] D loss: 0.6488, G loss: 9.8410\n",
      "[1452/8000] D loss: 1.0473, G loss: 2.3581\n",
      "[1812/8000] D loss: 0.9522, G loss: 4.3663\n",
      "[2172/8000] D loss: 0.4686, G loss: 6.8661\n",
      "[2532/8000] D loss: 0.7909, G loss: 5.1018\n",
      "[2892/8000] D loss: 0.9322, G loss: 4.4478\n",
      "[3252/8000] D loss: 1.1833, G loss: 3.8221\n",
      "[3612/8000] D loss: 0.9428, G loss: 7.8956\n",
      "[3972/8000] D loss: 0.4804, G loss: 15.8265\n",
      "[4332/8000] D loss: 0.9561, G loss: 4.2264\n",
      "[4692/8000] D loss: 0.6014, G loss: 9.2199\n",
      "[5052/8000] D loss: 0.9201, G loss: 3.4932\n",
      "[5412/8000] D loss: 0.5923, G loss: 7.7963\n",
      "[5772/8000] D loss: 0.5272, G loss: 11.1533\n",
      "[6132/8000] D loss: 1.0424, G loss: 3.7897\n",
      "[6492/8000] D loss: 0.8472, G loss: 4.5150\n",
      "[6852/8000] D loss: 0.8137, G loss: 7.0456\n",
      "[7212/8000] D loss: 0.7617, G loss: 7.0693\n",
      "[7572/8000] D loss: 0.7106, G loss: 3.8674\n",
      "[7932/8000] D loss: 0.7413, G loss: 3.2209\n",
      "train error: \n",
      " D loss: 0.835308, G loss: 5.247671, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.969266, G loss: 15.387991, D accuracy: 75.8%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0712, G loss: 2.8225\n",
      "[372/8000] D loss: 0.5797, G loss: 6.6449\n",
      "[732/8000] D loss: 0.7086, G loss: 7.7370\n",
      "[1092/8000] D loss: 0.7436, G loss: 4.8529\n",
      "[1452/8000] D loss: 0.9195, G loss: 2.3911\n",
      "[1812/8000] D loss: 0.8332, G loss: 3.5866\n",
      "[2172/8000] D loss: 0.3969, G loss: 13.7716\n",
      "[2532/8000] D loss: 1.0332, G loss: 2.6812\n",
      "[2892/8000] D loss: 1.1827, G loss: 2.3596\n",
      "[3252/8000] D loss: 0.4691, G loss: 14.4174\n",
      "[3612/8000] D loss: 0.5978, G loss: 8.7363\n",
      "[3972/8000] D loss: 0.9287, G loss: 3.4353\n",
      "[4332/8000] D loss: 1.0634, G loss: 6.8104\n",
      "[4692/8000] D loss: 0.9260, G loss: 5.9689\n",
      "[5052/8000] D loss: 0.5336, G loss: 4.4452\n",
      "[5412/8000] D loss: 0.8757, G loss: 3.4757\n",
      "[5772/8000] D loss: 0.8547, G loss: 6.9307\n",
      "[6132/8000] D loss: 0.5301, G loss: 12.0461\n",
      "[6492/8000] D loss: 1.0282, G loss: 4.5495\n",
      "[6852/8000] D loss: 0.5100, G loss: 11.1263\n",
      "[7212/8000] D loss: 0.8403, G loss: 4.1997\n",
      "[7572/8000] D loss: 0.7839, G loss: 4.1622\n",
      "[7932/8000] D loss: 1.0626, G loss: 4.0676\n",
      "train error: \n",
      " D loss: 0.853556, G loss: 6.466799, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.065305, G loss: 17.667230, D accuracy: 76.7%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6133, G loss: 11.1794\n",
      "[372/8000] D loss: 0.7606, G loss: 8.8330\n",
      "[732/8000] D loss: 0.7549, G loss: 6.7950\n",
      "[1092/8000] D loss: 0.7194, G loss: 7.3599\n",
      "[1452/8000] D loss: 0.9522, G loss: 2.9085\n",
      "[1812/8000] D loss: 0.6149, G loss: 8.1509\n",
      "[2172/8000] D loss: 0.9241, G loss: 2.5189\n",
      "[2532/8000] D loss: 0.9148, G loss: 6.6471\n",
      "[2892/8000] D loss: 1.0183, G loss: 4.2821\n",
      "[3252/8000] D loss: 1.0646, G loss: 4.6023\n",
      "[3612/8000] D loss: 0.8032, G loss: 4.9282\n",
      "[3972/8000] D loss: 0.4825, G loss: 7.4166\n",
      "[4332/8000] D loss: 0.9510, G loss: 4.1903\n",
      "[4692/8000] D loss: 0.8779, G loss: 5.0206\n",
      "[5052/8000] D loss: 0.8373, G loss: 6.8711\n",
      "[5412/8000] D loss: 0.7044, G loss: 6.1705\n",
      "[5772/8000] D loss: 1.0702, G loss: 5.7223\n",
      "[6132/8000] D loss: 1.0416, G loss: 2.2589\n",
      "[6492/8000] D loss: 0.6414, G loss: 7.5422\n",
      "[6852/8000] D loss: 0.4316, G loss: 9.6626\n",
      "[7212/8000] D loss: 0.7874, G loss: 3.8379\n",
      "[7572/8000] D loss: 0.8276, G loss: 6.1906\n",
      "[7932/8000] D loss: 0.9353, G loss: 5.8135\n",
      "train error: \n",
      " D loss: 0.825204, G loss: 6.098405, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.989744, G loss: 16.707418, D accuracy: 77.2%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7791, G loss: 4.4517\n",
      "[372/8000] D loss: 0.9518, G loss: 9.2955\n",
      "[732/8000] D loss: 0.5809, G loss: 4.3931\n",
      "[1092/8000] D loss: 0.7070, G loss: 6.2298\n",
      "[1452/8000] D loss: 0.9804, G loss: 2.1557\n",
      "[1812/8000] D loss: 0.9535, G loss: 2.5478\n",
      "[2172/8000] D loss: 0.7900, G loss: 4.6313\n",
      "[2532/8000] D loss: 0.7325, G loss: 4.2568\n",
      "[2892/8000] D loss: 0.6306, G loss: 7.6723\n",
      "[3252/8000] D loss: 0.6941, G loss: 7.3110\n",
      "[3612/8000] D loss: 0.9194, G loss: 3.1365\n",
      "[3972/8000] D loss: 1.0352, G loss: 4.1477\n",
      "[4332/8000] D loss: 1.0128, G loss: 4.4552\n",
      "[4692/8000] D loss: 0.8698, G loss: 4.8409\n",
      "[5052/8000] D loss: 0.8842, G loss: 1.9873\n",
      "[5412/8000] D loss: 0.7002, G loss: 5.5641\n",
      "[5772/8000] D loss: 0.9320, G loss: 4.0136\n",
      "[6132/8000] D loss: 0.9594, G loss: 3.5975\n",
      "[6492/8000] D loss: 0.9388, G loss: 2.5050\n",
      "[6852/8000] D loss: 0.8859, G loss: 4.7564\n",
      "[7212/8000] D loss: 0.9541, G loss: 2.8833\n",
      "[7572/8000] D loss: 0.1193, G loss: 15.6757\n",
      "[7932/8000] D loss: 0.4312, G loss: 5.8000\n",
      "train error: \n",
      " D loss: 0.850442, G loss: 4.300429, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 55.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.979369, G loss: 12.898961, D accuracy: 77.1%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0287, G loss: 3.6506\n",
      "[372/8000] D loss: 0.7142, G loss: 3.0418\n",
      "[732/8000] D loss: 0.6810, G loss: 6.6651\n",
      "[1092/8000] D loss: 1.1725, G loss: 1.4325\n",
      "[1452/8000] D loss: 0.9265, G loss: 4.2560\n",
      "[1812/8000] D loss: 0.9659, G loss: 2.2219\n",
      "[2172/8000] D loss: 1.0831, G loss: 2.5235\n",
      "[2532/8000] D loss: 0.5214, G loss: 8.6471\n",
      "[2892/8000] D loss: 0.8154, G loss: 7.6349\n",
      "[3252/8000] D loss: 0.8252, G loss: 10.6251\n",
      "[3612/8000] D loss: 0.9011, G loss: 2.9425\n",
      "[3972/8000] D loss: 0.6296, G loss: 6.1450\n",
      "[4332/8000] D loss: 0.5075, G loss: 6.5143\n",
      "[4692/8000] D loss: 0.9099, G loss: 4.4147\n",
      "[5052/8000] D loss: 0.8760, G loss: 6.8019\n",
      "[5412/8000] D loss: 0.4826, G loss: 6.6362\n",
      "[5772/8000] D loss: 1.0165, G loss: 7.1321\n",
      "[6132/8000] D loss: 0.6018, G loss: 6.4912\n",
      "[6492/8000] D loss: 0.8385, G loss: 5.9633\n",
      "[6852/8000] D loss: 0.8122, G loss: 5.1006\n",
      "[7212/8000] D loss: 0.6778, G loss: 7.9254\n",
      "[7572/8000] D loss: 0.9943, G loss: 4.0668\n",
      "[7932/8000] D loss: 0.8595, G loss: 3.5668\n",
      "train error: \n",
      " D loss: 0.854482, G loss: 5.325458, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.806293, G loss: 15.104542, D accuracy: 82.0%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5424, G loss: 7.6771\n",
      "[372/8000] D loss: 0.7317, G loss: 7.2195\n",
      "[732/8000] D loss: 0.9793, G loss: 6.4760\n",
      "[1092/8000] D loss: 0.3959, G loss: 16.4328\n",
      "[1452/8000] D loss: 0.5342, G loss: 8.4418\n",
      "[1812/8000] D loss: 0.8940, G loss: 3.9374\n",
      "[2172/8000] D loss: 0.3303, G loss: 6.2071\n",
      "[2532/8000] D loss: 1.0164, G loss: 2.2632\n",
      "[2892/8000] D loss: 0.7377, G loss: 5.8822\n",
      "[3252/8000] D loss: 0.8061, G loss: 4.7672\n",
      "[3612/8000] D loss: 0.8208, G loss: 4.0092\n",
      "[3972/8000] D loss: 0.9103, G loss: 5.6024\n",
      "[4332/8000] D loss: 0.8854, G loss: 4.7011\n",
      "[4692/8000] D loss: 0.8016, G loss: 8.2943\n",
      "[5052/8000] D loss: 0.7558, G loss: 6.2138\n",
      "[5412/8000] D loss: 0.7724, G loss: 3.8454\n",
      "[5772/8000] D loss: 1.0436, G loss: 1.9794\n",
      "[6132/8000] D loss: 1.0384, G loss: 7.1294\n",
      "[6492/8000] D loss: 0.5864, G loss: 10.1612\n",
      "[6852/8000] D loss: 0.7429, G loss: 4.8362\n",
      "[7212/8000] D loss: 0.7665, G loss: 6.6458\n",
      "[7572/8000] D loss: 0.9284, G loss: 4.3987\n",
      "[7932/8000] D loss: 1.0866, G loss: 1.4737\n",
      "train error: \n",
      " D loss: 0.849617, G loss: 6.372140, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.132832, G loss: 16.733438, D accuracy: 74.1%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4454, G loss: 16.1549\n",
      "[372/8000] D loss: 0.4753, G loss: 5.2498\n",
      "[732/8000] D loss: 1.1142, G loss: 1.4497\n",
      "[1092/8000] D loss: 0.6681, G loss: 9.1264\n",
      "[1452/8000] D loss: 0.8059, G loss: 4.3034\n",
      "[1812/8000] D loss: 0.8283, G loss: 6.5704\n",
      "[2172/8000] D loss: 0.9937, G loss: 5.5584\n",
      "[2532/8000] D loss: 0.8738, G loss: 4.0995\n",
      "[2892/8000] D loss: 0.6332, G loss: 2.7703\n",
      "[3252/8000] D loss: 0.7913, G loss: 4.7717\n",
      "[3612/8000] D loss: 0.4762, G loss: 11.1006\n",
      "[3972/8000] D loss: 0.3685, G loss: 6.3988\n",
      "[4332/8000] D loss: 0.4929, G loss: 13.3642\n",
      "[4692/8000] D loss: 1.1578, G loss: 3.0949\n",
      "[5052/8000] D loss: 0.9694, G loss: 2.6540\n",
      "[5412/8000] D loss: 1.2760, G loss: 3.6144\n",
      "[5772/8000] D loss: 0.9903, G loss: 7.8327\n",
      "[6132/8000] D loss: 0.9849, G loss: 3.6605\n",
      "[6492/8000] D loss: 0.6105, G loss: 14.1715\n",
      "[6852/8000] D loss: 0.8738, G loss: 5.7815\n",
      "[7212/8000] D loss: 0.9785, G loss: 2.7976\n",
      "[7572/8000] D loss: 0.6963, G loss: 6.8290\n",
      "[7932/8000] D loss: 0.9241, G loss: 3.0042\n",
      "train error: \n",
      " D loss: 0.841294, G loss: 5.553593, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.046421, G loss: 15.812153, D accuracy: 75.2%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9413, G loss: 1.8410\n",
      "[372/8000] D loss: 0.8232, G loss: 3.3447\n",
      "[732/8000] D loss: 0.8649, G loss: 5.0407\n",
      "[1092/8000] D loss: 0.5084, G loss: 8.4945\n",
      "[1452/8000] D loss: 0.7573, G loss: 4.3564\n",
      "[1812/8000] D loss: 0.8202, G loss: 7.9300\n",
      "[2172/8000] D loss: 0.5716, G loss: 7.5967\n",
      "[2532/8000] D loss: 0.9884, G loss: 1.6928\n",
      "[2892/8000] D loss: 0.8273, G loss: 3.2446\n",
      "[3252/8000] D loss: 1.2340, G loss: 1.3760\n",
      "[3612/8000] D loss: 0.9035, G loss: 8.3722\n",
      "[3972/8000] D loss: 1.0715, G loss: 2.4671\n",
      "[4332/8000] D loss: 0.9190, G loss: 5.7780\n",
      "[4692/8000] D loss: 0.9241, G loss: 3.9242\n",
      "[5052/8000] D loss: 1.0052, G loss: 3.2746\n",
      "[5412/8000] D loss: 0.7701, G loss: 4.8242\n",
      "[5772/8000] D loss: 1.0309, G loss: 1.8814\n",
      "[6132/8000] D loss: 1.2964, G loss: 1.8819\n",
      "[6492/8000] D loss: 0.8630, G loss: 8.9810\n",
      "[6852/8000] D loss: 0.8664, G loss: 9.5511\n",
      "[7212/8000] D loss: 0.5108, G loss: 7.9516\n",
      "[7572/8000] D loss: 0.8263, G loss: 4.4462\n",
      "[7932/8000] D loss: 0.9442, G loss: 4.7779\n",
      "train error: \n",
      " D loss: 0.849543, G loss: 6.795627, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.111509, G loss: 17.866564, D accuracy: 74.8%, cell accuracy: 98.3%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7824, G loss: 4.8211\n",
      "[372/8000] D loss: 0.3957, G loss: 10.0894\n",
      "[732/8000] D loss: 0.9396, G loss: 4.3511\n",
      "[1092/8000] D loss: 0.9318, G loss: 4.1020\n",
      "[1452/8000] D loss: 0.7265, G loss: 5.4752\n",
      "[1812/8000] D loss: 0.7874, G loss: 5.1377\n",
      "[2172/8000] D loss: 0.3593, G loss: 12.3132\n",
      "[2532/8000] D loss: 0.8263, G loss: 5.9739\n",
      "[2892/8000] D loss: 0.7259, G loss: 5.9433\n",
      "[3252/8000] D loss: 0.7759, G loss: 9.6997\n",
      "[3612/8000] D loss: 0.7240, G loss: 15.3673\n",
      "[3972/8000] D loss: 0.5524, G loss: 5.6678\n",
      "[4332/8000] D loss: 0.6957, G loss: 7.9723\n",
      "[4692/8000] D loss: 0.9403, G loss: 4.1372\n",
      "[5052/8000] D loss: 0.7853, G loss: 8.5404\n",
      "[5412/8000] D loss: 0.8135, G loss: 9.8745\n",
      "[5772/8000] D loss: 0.6608, G loss: 11.0119\n",
      "[6132/8000] D loss: 0.5616, G loss: 10.3629\n",
      "[6492/8000] D loss: 0.7904, G loss: 4.8041\n",
      "[6852/8000] D loss: 0.7109, G loss: 12.1072\n",
      "[7212/8000] D loss: 0.3782, G loss: 9.4543\n",
      "[7572/8000] D loss: 0.6988, G loss: 5.9963\n",
      "[7932/8000] D loss: 0.6832, G loss: 5.4105\n",
      "train error: \n",
      " D loss: 0.847075, G loss: 4.859439, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.997337, G loss: 14.332828, D accuracy: 76.8%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6692, G loss: 4.3748\n",
      "[372/8000] D loss: 0.9756, G loss: 2.3018\n",
      "[732/8000] D loss: 0.4615, G loss: 9.9577\n",
      "[1092/8000] D loss: 0.7450, G loss: 4.3652\n",
      "[1452/8000] D loss: 0.9909, G loss: 5.6634\n",
      "[1812/8000] D loss: 0.8585, G loss: 5.8923\n",
      "[2172/8000] D loss: 1.1057, G loss: 3.9473\n",
      "[2532/8000] D loss: 0.8980, G loss: 4.3462\n",
      "[2892/8000] D loss: 0.6633, G loss: 6.1825\n",
      "[3252/8000] D loss: 0.4795, G loss: 7.1408\n",
      "[3612/8000] D loss: 0.9504, G loss: 4.4911\n",
      "[3972/8000] D loss: 0.8004, G loss: 4.8670\n",
      "[4332/8000] D loss: 0.9376, G loss: 3.0809\n",
      "[4692/8000] D loss: 0.6585, G loss: 7.3644\n",
      "[5052/8000] D loss: 0.5825, G loss: 7.1159\n",
      "[5412/8000] D loss: 0.7639, G loss: 7.3479\n",
      "[5772/8000] D loss: 1.0550, G loss: 2.1810\n",
      "[6132/8000] D loss: 0.9638, G loss: 3.2503\n",
      "[6492/8000] D loss: 0.7707, G loss: 7.2181\n",
      "[6852/8000] D loss: 0.7819, G loss: 7.1200\n",
      "[7212/8000] D loss: 1.1440, G loss: 3.3492\n",
      "[7572/8000] D loss: 0.7176, G loss: 5.2662\n",
      "[7932/8000] D loss: 1.0663, G loss: 3.1369\n",
      "train error: \n",
      " D loss: 0.841211, G loss: 5.490768, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.886566, G loss: 16.127193, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8746, G loss: 2.4205\n",
      "[372/8000] D loss: 0.9365, G loss: 4.0870\n",
      "[732/8000] D loss: 1.0248, G loss: 4.8957\n",
      "[1092/8000] D loss: 0.8819, G loss: 4.6552\n",
      "[1452/8000] D loss: 0.8451, G loss: 2.9585\n",
      "[1812/8000] D loss: 0.5241, G loss: 7.9014\n",
      "[2172/8000] D loss: 0.9127, G loss: 6.2844\n",
      "[2532/8000] D loss: 0.8994, G loss: 8.7468\n",
      "[2892/8000] D loss: 0.8582, G loss: 7.6342\n",
      "[3252/8000] D loss: 0.6153, G loss: 7.3141\n",
      "[3612/8000] D loss: 1.0908, G loss: 2.3446\n",
      "[3972/8000] D loss: 0.9430, G loss: 5.0255\n",
      "[4332/8000] D loss: 0.6881, G loss: 5.6977\n",
      "[4692/8000] D loss: 1.0749, G loss: 6.8525\n",
      "[5052/8000] D loss: 0.6962, G loss: 5.4979\n",
      "[5412/8000] D loss: 0.7173, G loss: 6.6900\n",
      "[5772/8000] D loss: 0.7828, G loss: 5.6023\n",
      "[6132/8000] D loss: 0.9713, G loss: 5.6660\n",
      "[6492/8000] D loss: 1.1059, G loss: 5.6564\n",
      "[6852/8000] D loss: 1.0345, G loss: 4.9466\n",
      "[7212/8000] D loss: 0.7776, G loss: 2.7407\n",
      "[7572/8000] D loss: 0.6781, G loss: 9.4287\n",
      "[7932/8000] D loss: 0.7553, G loss: 8.7242\n",
      "train error: \n",
      " D loss: 0.832183, G loss: 5.780665, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 55.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.006291, G loss: 16.230909, D accuracy: 76.7%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0232, G loss: 3.2552\n",
      "[372/8000] D loss: 0.5080, G loss: 12.2789\n",
      "[732/8000] D loss: 0.5586, G loss: 9.8201\n",
      "[1092/8000] D loss: 1.1163, G loss: 4.1746\n",
      "[1452/8000] D loss: 0.6804, G loss: 4.5065\n",
      "[1812/8000] D loss: 0.6626, G loss: 7.2905\n",
      "[2172/8000] D loss: 0.6337, G loss: 3.6724\n",
      "[2532/8000] D loss: 0.7919, G loss: 5.6522\n",
      "[2892/8000] D loss: 0.9793, G loss: 4.7685\n",
      "[3252/8000] D loss: 0.7631, G loss: 11.6083\n",
      "[3612/8000] D loss: 0.9211, G loss: 4.0485\n",
      "[3972/8000] D loss: 1.1879, G loss: 3.0529\n",
      "[4332/8000] D loss: 1.0586, G loss: 4.8957\n",
      "[4692/8000] D loss: 0.3558, G loss: 11.4680\n",
      "[5052/8000] D loss: 1.1483, G loss: 1.3066\n",
      "[5412/8000] D loss: 0.6551, G loss: 5.4409\n",
      "[5772/8000] D loss: 0.3458, G loss: 22.0217\n",
      "[6132/8000] D loss: 0.5746, G loss: 14.1575\n",
      "[6492/8000] D loss: 0.8077, G loss: 4.0633\n",
      "[6852/8000] D loss: 1.0582, G loss: 4.8414\n",
      "[7212/8000] D loss: 0.7989, G loss: 6.7529\n",
      "[7572/8000] D loss: 0.5898, G loss: 9.5988\n",
      "[7932/8000] D loss: 1.1682, G loss: 1.7027\n",
      "train error: \n",
      " D loss: 0.828934, G loss: 6.456062, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.977167, G loss: 17.537641, D accuracy: 77.8%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8688, G loss: 9.6538\n",
      "[372/8000] D loss: 1.0899, G loss: 3.9050\n",
      "[732/8000] D loss: 0.8115, G loss: 6.8624\n",
      "[1092/8000] D loss: 0.4413, G loss: 4.5597\n",
      "[1452/8000] D loss: 1.0022, G loss: 3.9308\n",
      "[1812/8000] D loss: 0.8720, G loss: 3.7550\n",
      "[2172/8000] D loss: 0.7692, G loss: 4.2409\n",
      "[2532/8000] D loss: 0.7973, G loss: 6.3763\n",
      "[2892/8000] D loss: 0.7945, G loss: 7.7658\n",
      "[3252/8000] D loss: 0.5910, G loss: 9.3087\n",
      "[3612/8000] D loss: 0.7955, G loss: 8.0075\n",
      "[3972/8000] D loss: 1.0549, G loss: 4.1726\n",
      "[4332/8000] D loss: 0.9775, G loss: 6.4920\n",
      "[4692/8000] D loss: 0.5064, G loss: 6.0992\n",
      "[5052/8000] D loss: 0.9435, G loss: 1.6215\n",
      "[5412/8000] D loss: 0.7609, G loss: 3.3522\n",
      "[5772/8000] D loss: 0.8778, G loss: 4.2543\n",
      "[6132/8000] D loss: 0.8335, G loss: 6.7972\n",
      "[6492/8000] D loss: 1.1559, G loss: 3.5028\n",
      "[6852/8000] D loss: 1.1057, G loss: 3.3406\n",
      "[7212/8000] D loss: 0.6935, G loss: 5.7663\n",
      "[7572/8000] D loss: 0.8261, G loss: 3.0689\n",
      "[7932/8000] D loss: 0.9384, G loss: 8.4436\n",
      "train error: \n",
      " D loss: 0.837674, G loss: 5.976124, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.930514, G loss: 16.912220, D accuracy: 79.1%, cell accuracy: 98.2%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0344, G loss: 2.9027\n",
      "[372/8000] D loss: 0.4881, G loss: 9.9840\n",
      "[732/8000] D loss: 0.7110, G loss: 8.9739\n",
      "[1092/8000] D loss: 0.8346, G loss: 7.9092\n",
      "[1452/8000] D loss: 0.6341, G loss: 3.5627\n",
      "[1812/8000] D loss: 1.0402, G loss: 2.7432\n",
      "[2172/8000] D loss: 0.8471, G loss: 6.9055\n",
      "[2532/8000] D loss: 0.9729, G loss: 4.2527\n",
      "[2892/8000] D loss: 0.8579, G loss: 8.0605\n",
      "[3252/8000] D loss: 0.7296, G loss: 2.2800\n",
      "[3612/8000] D loss: 0.6778, G loss: 11.5206\n",
      "[3972/8000] D loss: 0.8909, G loss: 2.9202\n",
      "[4332/8000] D loss: 0.5812, G loss: 7.7584\n",
      "[4692/8000] D loss: 0.7039, G loss: 7.2755\n",
      "[5052/8000] D loss: 0.5249, G loss: 8.3960\n",
      "[5412/8000] D loss: 1.2675, G loss: 1.3313\n",
      "[5772/8000] D loss: 0.6191, G loss: 7.1716\n",
      "[6132/8000] D loss: 1.0975, G loss: 3.6614\n",
      "[6492/8000] D loss: 0.5545, G loss: 9.4481\n",
      "[6852/8000] D loss: 0.8080, G loss: 7.1899\n",
      "[7212/8000] D loss: 0.6923, G loss: 6.4270\n",
      "[7572/8000] D loss: 0.9846, G loss: 4.9130\n",
      "[7932/8000] D loss: 0.8520, G loss: 3.9255\n",
      "train error: \n",
      " D loss: 0.831789, G loss: 6.037313, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.976809, G loss: 17.026880, D accuracy: 76.9%, cell accuracy: 98.2%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3287, G loss: 9.3421\n",
      "[372/8000] D loss: 0.6801, G loss: 7.9651\n",
      "[732/8000] D loss: 0.8875, G loss: 3.9561\n",
      "[1092/8000] D loss: 0.8272, G loss: 7.5795\n",
      "[1452/8000] D loss: 0.7780, G loss: 9.8808\n",
      "[1812/8000] D loss: 0.6187, G loss: 5.1683\n",
      "[2172/8000] D loss: 0.5861, G loss: 8.4380\n",
      "[2532/8000] D loss: 0.7972, G loss: 6.6478\n",
      "[2892/8000] D loss: 0.9956, G loss: 5.9044\n",
      "[3252/8000] D loss: 0.8172, G loss: 4.5013\n",
      "[3612/8000] D loss: 0.9022, G loss: 2.2706\n",
      "[3972/8000] D loss: 0.7159, G loss: 5.0516\n",
      "[4332/8000] D loss: 0.9344, G loss: 4.0437\n",
      "[4692/8000] D loss: 0.8302, G loss: 2.8243\n",
      "[5052/8000] D loss: 0.5985, G loss: 6.2116\n",
      "[5412/8000] D loss: 0.8546, G loss: 8.1175\n",
      "[5772/8000] D loss: 0.5855, G loss: 5.1088\n",
      "[6132/8000] D loss: 0.7647, G loss: 7.1405\n",
      "[6492/8000] D loss: 0.4332, G loss: 9.4705\n",
      "[6852/8000] D loss: 0.8149, G loss: 3.4595\n",
      "[7212/8000] D loss: 0.6877, G loss: 7.8580\n",
      "[7572/8000] D loss: 0.8307, G loss: 5.9262\n",
      "[7932/8000] D loss: 0.3996, G loss: 10.7323\n",
      "train error: \n",
      " D loss: 0.841481, G loss: 5.787179, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.910294, G loss: 17.267231, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7632, G loss: 9.4406\n",
      "[372/8000] D loss: 0.8406, G loss: 6.1173\n",
      "[732/8000] D loss: 0.5278, G loss: 6.7691\n",
      "[1092/8000] D loss: 1.1659, G loss: 3.0135\n",
      "[1452/8000] D loss: 1.0908, G loss: 1.7299\n",
      "[1812/8000] D loss: 0.8226, G loss: 6.8561\n",
      "[2172/8000] D loss: 0.8084, G loss: 4.5636\n",
      "[2532/8000] D loss: 0.8319, G loss: 6.4023\n",
      "[2892/8000] D loss: 0.9448, G loss: 4.2601\n",
      "[3252/8000] D loss: 0.4343, G loss: 7.7729\n",
      "[3612/8000] D loss: 0.8447, G loss: 5.8179\n",
      "[3972/8000] D loss: 1.0652, G loss: 4.3903\n",
      "[4332/8000] D loss: 0.9997, G loss: 4.9653\n",
      "[4692/8000] D loss: 0.9528, G loss: 5.1393\n",
      "[5052/8000] D loss: 0.7857, G loss: 3.3695\n",
      "[5412/8000] D loss: 0.8611, G loss: 7.8924\n",
      "[5772/8000] D loss: 1.2261, G loss: 1.4664\n",
      "[6132/8000] D loss: 0.6411, G loss: 7.8090\n",
      "[6492/8000] D loss: 0.8292, G loss: 3.1628\n",
      "[6852/8000] D loss: 0.5234, G loss: 8.6901\n",
      "[7212/8000] D loss: 0.6818, G loss: 3.1911\n",
      "[7572/8000] D loss: 0.7184, G loss: 13.3739\n",
      "[7932/8000] D loss: 0.8151, G loss: 5.8667\n",
      "train error: \n",
      " D loss: 0.824967, G loss: 6.022604, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.953464, G loss: 17.503039, D accuracy: 79.5%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6501, G loss: 6.6263\n",
      "[372/8000] D loss: 0.9310, G loss: 7.8240\n",
      "[732/8000] D loss: 0.7991, G loss: 7.6413\n",
      "[1092/8000] D loss: 0.8381, G loss: 4.1216\n",
      "[1452/8000] D loss: 0.7557, G loss: 7.4992\n",
      "[1812/8000] D loss: 0.9637, G loss: 2.3273\n",
      "[2172/8000] D loss: 0.9124, G loss: 7.3868\n",
      "[2532/8000] D loss: 0.7974, G loss: 2.5764\n",
      "[2892/8000] D loss: 0.8722, G loss: 8.6885\n",
      "[3252/8000] D loss: 0.8900, G loss: 5.9131\n",
      "[3612/8000] D loss: 0.9164, G loss: 5.2015\n",
      "[3972/8000] D loss: 0.5643, G loss: 13.4747\n",
      "[4332/8000] D loss: 0.7431, G loss: 3.4556\n",
      "[4692/8000] D loss: 0.7594, G loss: 7.8526\n",
      "[5052/8000] D loss: 0.8318, G loss: 5.3391\n",
      "[5412/8000] D loss: 0.8643, G loss: 3.7939\n",
      "[5772/8000] D loss: 1.1815, G loss: 3.0531\n",
      "[6132/8000] D loss: 0.7448, G loss: 5.2831\n",
      "[6492/8000] D loss: 0.9760, G loss: 7.5482\n",
      "[6852/8000] D loss: 0.8667, G loss: 4.5449\n",
      "[7212/8000] D loss: 0.7775, G loss: 4.5092\n",
      "[7572/8000] D loss: 0.8788, G loss: 4.2651\n",
      "[7932/8000] D loss: 1.0006, G loss: 3.7352\n",
      "train error: \n",
      " D loss: 0.841767, G loss: 5.755810, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.007239, G loss: 16.312583, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9783, G loss: 2.8827\n",
      "[372/8000] D loss: 0.7328, G loss: 8.1814\n",
      "[732/8000] D loss: 0.8259, G loss: 5.0894\n",
      "[1092/8000] D loss: 0.7019, G loss: 5.0171\n",
      "[1452/8000] D loss: 1.1070, G loss: 3.1177\n",
      "[1812/8000] D loss: 0.9598, G loss: 9.3918\n",
      "[2172/8000] D loss: 1.1309, G loss: 1.5487\n",
      "[2532/8000] D loss: 0.7373, G loss: 7.2311\n",
      "[2892/8000] D loss: 0.9355, G loss: 4.5051\n",
      "[3252/8000] D loss: 0.6958, G loss: 9.0842\n",
      "[3612/8000] D loss: 1.1705, G loss: 2.1859\n",
      "[3972/8000] D loss: 0.8985, G loss: 1.9240\n",
      "[4332/8000] D loss: 0.3621, G loss: 5.5734\n",
      "[4692/8000] D loss: 0.9875, G loss: 3.1115\n",
      "[5052/8000] D loss: 1.1169, G loss: 3.0724\n",
      "[5412/8000] D loss: 0.8370, G loss: 4.7728\n",
      "[5772/8000] D loss: 0.7144, G loss: 7.3207\n",
      "[6132/8000] D loss: 0.8386, G loss: 6.3398\n",
      "[6492/8000] D loss: 0.8061, G loss: 6.1527\n",
      "[6852/8000] D loss: 1.0586, G loss: 2.2249\n",
      "[7212/8000] D loss: 0.4956, G loss: 11.1537\n",
      "[7572/8000] D loss: 1.0406, G loss: 3.7132\n",
      "[7932/8000] D loss: 1.0230, G loss: 3.9543\n",
      "train error: \n",
      " D loss: 0.842213, G loss: 5.159294, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.905393, G loss: 15.358181, D accuracy: 78.2%, cell accuracy: 98.2%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9902, G loss: 2.4259\n",
      "[372/8000] D loss: 0.9958, G loss: 4.9025\n",
      "[732/8000] D loss: 0.5502, G loss: 8.5852\n",
      "[1092/8000] D loss: 0.3931, G loss: 11.1197\n",
      "[1452/8000] D loss: 0.8870, G loss: 4.0735\n",
      "[1812/8000] D loss: 0.5811, G loss: 6.0885\n",
      "[2172/8000] D loss: 0.5777, G loss: 5.9089\n",
      "[2532/8000] D loss: 0.7931, G loss: 6.8500\n",
      "[2892/8000] D loss: 1.4153, G loss: 0.6622\n",
      "[3252/8000] D loss: 0.7427, G loss: 3.1886\n",
      "[3612/8000] D loss: 0.9041, G loss: 6.0406\n",
      "[3972/8000] D loss: 0.4953, G loss: 11.7991\n",
      "[4332/8000] D loss: 0.7135, G loss: 6.9817\n",
      "[4692/8000] D loss: 0.6894, G loss: 6.2173\n",
      "[5052/8000] D loss: 1.1798, G loss: 1.5850\n",
      "[5412/8000] D loss: 0.8331, G loss: 10.3686\n",
      "[5772/8000] D loss: 0.8347, G loss: 7.6236\n",
      "[6132/8000] D loss: 1.0448, G loss: 3.6504\n",
      "[6492/8000] D loss: 0.5782, G loss: 9.6450\n",
      "[6852/8000] D loss: 1.4889, G loss: 0.6185\n",
      "[7212/8000] D loss: 1.0129, G loss: 2.7845\n",
      "[7572/8000] D loss: 0.9259, G loss: 11.4405\n",
      "[7932/8000] D loss: 0.7607, G loss: 7.8708\n",
      "train error: \n",
      " D loss: 0.872036, G loss: 5.774202, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.879438, G loss: 16.533529, D accuracy: 81.2%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0012, G loss: 5.0685\n",
      "[372/8000] D loss: 0.9374, G loss: 4.5025\n",
      "[732/8000] D loss: 0.7540, G loss: 5.6473\n",
      "[1092/8000] D loss: 0.8410, G loss: 3.3910\n",
      "[1452/8000] D loss: 0.8458, G loss: 5.2706\n",
      "[1812/8000] D loss: 1.0370, G loss: 3.7982\n",
      "[2172/8000] D loss: 0.8217, G loss: 3.8466\n",
      "[2532/8000] D loss: 0.4899, G loss: 8.3391\n",
      "[2892/8000] D loss: 0.7155, G loss: 7.8002\n",
      "[3252/8000] D loss: 0.9972, G loss: 3.0375\n",
      "[3612/8000] D loss: 0.6113, G loss: 7.3175\n",
      "[3972/8000] D loss: 1.0581, G loss: 6.4172\n",
      "[4332/8000] D loss: 0.5912, G loss: 9.9126\n",
      "[4692/8000] D loss: 0.9462, G loss: 2.7305\n",
      "[5052/8000] D loss: 0.6959, G loss: 6.0366\n",
      "[5412/8000] D loss: 1.1001, G loss: 4.1469\n",
      "[5772/8000] D loss: 0.8492, G loss: 4.0900\n",
      "[6132/8000] D loss: 0.7176, G loss: 11.1119\n",
      "[6492/8000] D loss: 0.9256, G loss: 3.6840\n",
      "[6852/8000] D loss: 0.8233, G loss: 4.6867\n",
      "[7212/8000] D loss: 0.7518, G loss: 7.6674\n",
      "[7572/8000] D loss: 1.1033, G loss: 2.6619\n",
      "[7932/8000] D loss: 1.0136, G loss: 2.2653\n",
      "train error: \n",
      " D loss: 0.850144, G loss: 5.067108, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.914394, G loss: 15.142387, D accuracy: 80.2%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8870, G loss: 2.3788\n",
      "[372/8000] D loss: 0.8888, G loss: 2.2070\n",
      "[732/8000] D loss: 1.1583, G loss: 2.5049\n",
      "[1092/8000] D loss: 1.0244, G loss: 7.1284\n",
      "[1452/8000] D loss: 0.5900, G loss: 7.6031\n",
      "[1812/8000] D loss: 0.7348, G loss: 6.5142\n",
      "[2172/8000] D loss: 1.2580, G loss: 1.7664\n",
      "[2532/8000] D loss: 0.5060, G loss: 9.7589\n",
      "[2892/8000] D loss: 0.8236, G loss: 5.2971\n",
      "[3252/8000] D loss: 0.8505, G loss: 2.1612\n",
      "[3612/8000] D loss: 0.5887, G loss: 9.0491\n",
      "[3972/8000] D loss: 1.0062, G loss: 5.3604\n",
      "[4332/8000] D loss: 1.0289, G loss: 2.3150\n",
      "[4692/8000] D loss: 1.2281, G loss: 5.0765\n",
      "[5052/8000] D loss: 0.7182, G loss: 8.2282\n",
      "[5412/8000] D loss: 0.6905, G loss: 5.8751\n",
      "[5772/8000] D loss: 0.6147, G loss: 5.1485\n",
      "[6132/8000] D loss: 0.9638, G loss: 3.3270\n",
      "[6492/8000] D loss: 0.3589, G loss: 10.8683\n",
      "[6852/8000] D loss: 0.9287, G loss: 5.6090\n",
      "[7212/8000] D loss: 1.1587, G loss: 2.6266\n",
      "[7572/8000] D loss: 0.7331, G loss: 5.2253\n",
      "[7932/8000] D loss: 0.8253, G loss: 6.2859\n",
      "train error: \n",
      " D loss: 0.839973, G loss: 5.467323, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.944067, G loss: 16.507137, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5002, G loss: 7.2225\n",
      "[372/8000] D loss: 0.6837, G loss: 10.5955\n",
      "[732/8000] D loss: 0.8605, G loss: 2.6634\n",
      "[1092/8000] D loss: 0.6415, G loss: 4.6302\n",
      "[1452/8000] D loss: 0.8229, G loss: 9.2997\n",
      "[1812/8000] D loss: 0.7922, G loss: 10.2634\n",
      "[2172/8000] D loss: 0.5317, G loss: 11.7757\n",
      "[2532/8000] D loss: 0.8167, G loss: 4.4914\n",
      "[2892/8000] D loss: 0.8939, G loss: 8.3231\n",
      "[3252/8000] D loss: 1.0554, G loss: 4.7500\n",
      "[3612/8000] D loss: 0.8288, G loss: 2.9822\n",
      "[3972/8000] D loss: 0.7053, G loss: 8.6746\n",
      "[4332/8000] D loss: 1.1344, G loss: 2.0216\n",
      "[4692/8000] D loss: 1.0369, G loss: 5.6761\n",
      "[5052/8000] D loss: 0.7165, G loss: 5.2727\n",
      "[5412/8000] D loss: 0.9624, G loss: 4.7391\n",
      "[5772/8000] D loss: 0.4708, G loss: 14.3480\n",
      "[6132/8000] D loss: 1.2079, G loss: 1.4413\n",
      "[6492/8000] D loss: 0.8913, G loss: 7.1029\n",
      "[6852/8000] D loss: 0.8876, G loss: 4.6617\n",
      "[7212/8000] D loss: 0.9066, G loss: 3.3994\n",
      "[7572/8000] D loss: 0.4456, G loss: 7.8128\n",
      "[7932/8000] D loss: 0.4286, G loss: 8.9200\n",
      "train error: \n",
      " D loss: 0.839999, G loss: 5.837852, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.957307, G loss: 16.482303, D accuracy: 78.3%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0648, G loss: 4.6086\n",
      "[372/8000] D loss: 0.8336, G loss: 6.0016\n",
      "[732/8000] D loss: 0.7462, G loss: 3.6194\n",
      "[1092/8000] D loss: 1.0125, G loss: 3.6354\n",
      "[1452/8000] D loss: 0.5683, G loss: 4.7577\n",
      "[1812/8000] D loss: 0.6469, G loss: 5.5068\n",
      "[2172/8000] D loss: 0.6569, G loss: 7.0098\n",
      "[2532/8000] D loss: 0.7417, G loss: 6.9320\n",
      "[2892/8000] D loss: 1.0012, G loss: 6.3192\n",
      "[3252/8000] D loss: 0.4478, G loss: 7.9600\n",
      "[3612/8000] D loss: 0.5788, G loss: 5.2893\n",
      "[3972/8000] D loss: 0.5865, G loss: 10.5419\n",
      "[4332/8000] D loss: 0.6101, G loss: 7.2765\n",
      "[4692/8000] D loss: 0.9975, G loss: 2.7688\n",
      "[5052/8000] D loss: 0.6720, G loss: 5.2610\n",
      "[5412/8000] D loss: 0.3782, G loss: 11.2394\n",
      "[5772/8000] D loss: 0.8097, G loss: 9.7968\n",
      "[6132/8000] D loss: 0.7222, G loss: 4.6316\n",
      "[6492/8000] D loss: 0.9452, G loss: 3.4974\n",
      "[6852/8000] D loss: 0.6740, G loss: 4.9784\n",
      "[7212/8000] D loss: 0.9624, G loss: 3.4263\n",
      "[7572/8000] D loss: 0.7723, G loss: 4.4393\n",
      "[7932/8000] D loss: 0.9588, G loss: 4.7116\n",
      "train error: \n",
      " D loss: 0.830897, G loss: 6.328308, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.996630, G loss: 17.949710, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0150, G loss: 4.5137\n",
      "[372/8000] D loss: 0.6433, G loss: 6.1314\n",
      "[732/8000] D loss: 0.5808, G loss: 3.9496\n",
      "[1092/8000] D loss: 0.7897, G loss: 6.2384\n",
      "[1452/8000] D loss: 1.0310, G loss: 3.1309\n",
      "[1812/8000] D loss: 0.8775, G loss: 7.5743\n",
      "[2172/8000] D loss: 0.8011, G loss: 7.6961\n",
      "[2532/8000] D loss: 0.5257, G loss: 8.1697\n",
      "[2892/8000] D loss: 0.8092, G loss: 5.7434\n",
      "[3252/8000] D loss: 0.5205, G loss: 8.3447\n",
      "[3612/8000] D loss: 0.6959, G loss: 6.2269\n",
      "[3972/8000] D loss: 0.8236, G loss: 6.8604\n",
      "[4332/8000] D loss: 0.6816, G loss: 4.6956\n",
      "[4692/8000] D loss: 0.7407, G loss: 8.6622\n",
      "[5052/8000] D loss: 0.8845, G loss: 4.3360\n",
      "[5412/8000] D loss: 0.9554, G loss: 4.8432\n",
      "[5772/8000] D loss: 0.9152, G loss: 3.2430\n",
      "[6132/8000] D loss: 0.6356, G loss: 7.0998\n",
      "[6492/8000] D loss: 0.6371, G loss: 5.5000\n",
      "[6852/8000] D loss: 1.0217, G loss: 3.4766\n",
      "[7212/8000] D loss: 0.8067, G loss: 7.5625\n",
      "[7572/8000] D loss: 0.7209, G loss: 7.1234\n",
      "[7932/8000] D loss: 1.1079, G loss: 4.3979\n",
      "train error: \n",
      " D loss: 0.846730, G loss: 5.661287, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.902898, G loss: 16.201461, D accuracy: 81.2%, cell accuracy: 98.2%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9760, G loss: 4.2420\n",
      "[372/8000] D loss: 0.9609, G loss: 5.5479\n",
      "[732/8000] D loss: 1.2376, G loss: 1.5764\n",
      "[1092/8000] D loss: 1.1408, G loss: 2.4428\n",
      "[1452/8000] D loss: 1.0595, G loss: 2.1095\n",
      "[1812/8000] D loss: 1.3230, G loss: 0.8623\n",
      "[2172/8000] D loss: 0.8963, G loss: 6.3531\n",
      "[2532/8000] D loss: 0.6204, G loss: 7.8737\n",
      "[2892/8000] D loss: 0.8998, G loss: 5.4670\n",
      "[3252/8000] D loss: 0.9343, G loss: 7.9037\n",
      "[3612/8000] D loss: 1.0537, G loss: 3.9110\n",
      "[3972/8000] D loss: 0.4719, G loss: 12.1139\n",
      "[4332/8000] D loss: 0.8550, G loss: 6.6829\n",
      "[4692/8000] D loss: 0.5681, G loss: 10.0575\n",
      "[5052/8000] D loss: 0.9634, G loss: 2.6883\n",
      "[5412/8000] D loss: 0.7569, G loss: 8.1460\n",
      "[5772/8000] D loss: 0.6211, G loss: 8.9106\n",
      "[6132/8000] D loss: 1.2820, G loss: 1.4951\n",
      "[6492/8000] D loss: 0.7246, G loss: 4.2034\n",
      "[6852/8000] D loss: 0.8547, G loss: 2.5809\n",
      "[7212/8000] D loss: 0.9289, G loss: 3.7725\n",
      "[7572/8000] D loss: 0.9692, G loss: 5.3463\n",
      "[7932/8000] D loss: 0.5716, G loss: 8.0091\n",
      "train error: \n",
      " D loss: 0.850845, G loss: 4.449041, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.996147, G loss: 13.954965, D accuracy: 79.1%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1674, G loss: 6.3981\n",
      "[372/8000] D loss: 0.7123, G loss: 5.1613\n",
      "[732/8000] D loss: 0.9782, G loss: 6.6919\n",
      "[1092/8000] D loss: 0.9287, G loss: 5.7928\n",
      "[1452/8000] D loss: 1.0015, G loss: 4.0908\n",
      "[1812/8000] D loss: 0.8697, G loss: 6.3970\n",
      "[2172/8000] D loss: 1.0889, G loss: 1.3527\n",
      "[2532/8000] D loss: 0.8027, G loss: 5.9123\n",
      "[2892/8000] D loss: 0.7375, G loss: 4.9861\n",
      "[3252/8000] D loss: 0.8870, G loss: 6.2801\n",
      "[3612/8000] D loss: 0.8246, G loss: 3.8253\n",
      "[3972/8000] D loss: 0.6525, G loss: 6.8078\n",
      "[4332/8000] D loss: 1.0128, G loss: 3.9970\n",
      "[4692/8000] D loss: 0.6589, G loss: 9.7613\n",
      "[5052/8000] D loss: 0.5951, G loss: 13.2818\n",
      "[5412/8000] D loss: 1.0064, G loss: 8.7855\n",
      "[5772/8000] D loss: 0.8602, G loss: 3.9409\n",
      "[6132/8000] D loss: 0.9800, G loss: 4.4857\n",
      "[6492/8000] D loss: 0.7492, G loss: 5.8488\n",
      "[6852/8000] D loss: 0.7609, G loss: 5.8811\n",
      "[7212/8000] D loss: 0.6195, G loss: 9.8321\n",
      "[7572/8000] D loss: 0.6926, G loss: 10.3235\n",
      "[7932/8000] D loss: 0.7294, G loss: 6.6173\n",
      "train error: \n",
      " D loss: 0.837024, G loss: 5.623692, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.909608, G loss: 16.109751, D accuracy: 81.6%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0433, G loss: 2.7579\n",
      "[372/8000] D loss: 0.8029, G loss: 7.6928\n",
      "[732/8000] D loss: 0.6112, G loss: 6.2281\n",
      "[1092/8000] D loss: 0.9272, G loss: 7.2869\n",
      "[1452/8000] D loss: 0.9082, G loss: 9.5404\n",
      "[1812/8000] D loss: 0.8641, G loss: 5.3648\n",
      "[2172/8000] D loss: 0.8000, G loss: 11.7271\n",
      "[2532/8000] D loss: 0.6129, G loss: 6.5221\n",
      "[2892/8000] D loss: 0.6495, G loss: 8.8829\n",
      "[3252/8000] D loss: 0.6696, G loss: 4.8657\n",
      "[3612/8000] D loss: 1.0436, G loss: 5.8860\n",
      "[3972/8000] D loss: 0.6629, G loss: 11.0449\n",
      "[4332/8000] D loss: 1.1537, G loss: 2.5125\n",
      "[4692/8000] D loss: 1.0753, G loss: 1.2388\n",
      "[5052/8000] D loss: 0.9855, G loss: 4.5117\n",
      "[5412/8000] D loss: 1.0125, G loss: 7.6697\n",
      "[5772/8000] D loss: 0.9204, G loss: 4.1706\n",
      "[6132/8000] D loss: 0.8733, G loss: 8.9394\n",
      "[6492/8000] D loss: 0.7299, G loss: 9.3310\n",
      "[6852/8000] D loss: 0.9210, G loss: 9.1819\n",
      "[7212/8000] D loss: 0.8942, G loss: 3.4797\n",
      "[7572/8000] D loss: 0.7532, G loss: 8.4412\n",
      "[7932/8000] D loss: 0.7040, G loss: 5.4498\n",
      "train error: \n",
      " D loss: 0.833915, G loss: 5.894426, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 55.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.906648, G loss: 16.222051, D accuracy: 80.7%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7143, G loss: 9.4557\n",
      "[372/8000] D loss: 0.8334, G loss: 4.2652\n",
      "[732/8000] D loss: 0.8355, G loss: 4.0928\n",
      "[1092/8000] D loss: 0.6108, G loss: 8.4072\n",
      "[1452/8000] D loss: 0.6960, G loss: 11.4368\n",
      "[1812/8000] D loss: 1.2168, G loss: 1.5012\n",
      "[2172/8000] D loss: 0.8095, G loss: 5.6211\n",
      "[2532/8000] D loss: 0.7892, G loss: 6.6436\n",
      "[2892/8000] D loss: 0.9025, G loss: 4.9552\n",
      "[3252/8000] D loss: 0.9206, G loss: 9.5861\n",
      "[3612/8000] D loss: 1.1229, G loss: 2.8082\n",
      "[3972/8000] D loss: 0.8612, G loss: 5.4834\n",
      "[4332/8000] D loss: 0.8189, G loss: 7.7604\n",
      "[4692/8000] D loss: 1.0554, G loss: 3.3697\n",
      "[5052/8000] D loss: 0.7722, G loss: 5.0729\n",
      "[5412/8000] D loss: 0.6977, G loss: 4.8211\n",
      "[5772/8000] D loss: 0.8691, G loss: 5.8064\n",
      "[6132/8000] D loss: 0.8256, G loss: 3.2491\n",
      "[6492/8000] D loss: 0.8045, G loss: 2.2589\n",
      "[6852/8000] D loss: 0.9617, G loss: 3.6656\n",
      "[7212/8000] D loss: 0.6183, G loss: 4.8987\n",
      "[7572/8000] D loss: 0.4891, G loss: 11.9255\n",
      "[7932/8000] D loss: 0.8193, G loss: 6.7460\n",
      "train error: \n",
      " D loss: 0.840008, G loss: 6.924216, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.090235, G loss: 18.851007, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9492, G loss: 6.7993\n",
      "[372/8000] D loss: 1.0813, G loss: 1.5395\n",
      "[732/8000] D loss: 0.5913, G loss: 13.2475\n",
      "[1092/8000] D loss: 0.7132, G loss: 8.7887\n",
      "[1452/8000] D loss: 0.9490, G loss: 4.4602\n",
      "[1812/8000] D loss: 0.5152, G loss: 5.5696\n",
      "[2172/8000] D loss: 0.5559, G loss: 9.1336\n",
      "[2532/8000] D loss: 0.9179, G loss: 3.9197\n",
      "[2892/8000] D loss: 1.2534, G loss: 0.8994\n",
      "[3252/8000] D loss: 0.8975, G loss: 5.6760\n",
      "[3612/8000] D loss: 0.6017, G loss: 6.5533\n",
      "[3972/8000] D loss: 0.7059, G loss: 3.8673\n",
      "[4332/8000] D loss: 0.9593, G loss: 4.3073\n",
      "[4692/8000] D loss: 0.7488, G loss: 7.7211\n",
      "[5052/8000] D loss: 1.0485, G loss: 3.8778\n",
      "[5412/8000] D loss: 0.7164, G loss: 7.0767\n",
      "[5772/8000] D loss: 1.0230, G loss: 2.2105\n",
      "[6132/8000] D loss: 0.9664, G loss: 2.2159\n",
      "[6492/8000] D loss: 0.9065, G loss: 3.5530\n",
      "[6852/8000] D loss: 0.9583, G loss: 3.0260\n",
      "[7212/8000] D loss: 0.8022, G loss: 7.4453\n",
      "[7572/8000] D loss: 0.4312, G loss: 9.1899\n",
      "[7932/8000] D loss: 1.2643, G loss: 1.6299\n",
      "train error: \n",
      " D loss: 0.834970, G loss: 5.678729, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.950629, G loss: 16.600119, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7081, G loss: 10.3201\n",
      "[372/8000] D loss: 1.1889, G loss: 4.6608\n",
      "[732/8000] D loss: 0.6568, G loss: 7.2433\n",
      "[1092/8000] D loss: 0.4779, G loss: 7.8684\n",
      "[1452/8000] D loss: 0.6262, G loss: 8.4166\n",
      "[1812/8000] D loss: 0.9715, G loss: 2.8552\n",
      "[2172/8000] D loss: 0.8756, G loss: 5.7256\n",
      "[2532/8000] D loss: 0.7036, G loss: 10.8784\n",
      "[2892/8000] D loss: 0.6740, G loss: 9.8251\n",
      "[3252/8000] D loss: 0.9352, G loss: 3.2794\n",
      "[3612/8000] D loss: 0.4793, G loss: 9.5859\n",
      "[3972/8000] D loss: 1.0335, G loss: 2.3989\n",
      "[4332/8000] D loss: 1.0460, G loss: 5.4420\n",
      "[4692/8000] D loss: 0.6889, G loss: 9.7452\n",
      "[5052/8000] D loss: 0.7729, G loss: 4.6809\n",
      "[5412/8000] D loss: 0.6757, G loss: 4.1698\n",
      "[5772/8000] D loss: 0.8636, G loss: 10.7384\n",
      "[6132/8000] D loss: 1.0592, G loss: 2.2474\n",
      "[6492/8000] D loss: 0.7389, G loss: 5.1002\n",
      "[6852/8000] D loss: 0.8219, G loss: 2.9300\n",
      "[7212/8000] D loss: 0.8227, G loss: 8.1700\n",
      "[7572/8000] D loss: 0.8072, G loss: 4.6639\n",
      "[7932/8000] D loss: 0.5652, G loss: 7.8895\n",
      "train error: \n",
      " D loss: 0.827541, G loss: 5.744537, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.896617, G loss: 16.584398, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7315, G loss: 5.3579\n",
      "[372/8000] D loss: 0.7947, G loss: 4.7386\n",
      "[732/8000] D loss: 0.5840, G loss: 7.0229\n",
      "[1092/8000] D loss: 0.8562, G loss: 5.5479\n",
      "[1452/8000] D loss: 1.1627, G loss: 1.9415\n",
      "[1812/8000] D loss: 0.7322, G loss: 5.9607\n",
      "[2172/8000] D loss: 0.7059, G loss: 4.3091\n",
      "[2532/8000] D loss: 0.7024, G loss: 4.5406\n",
      "[2892/8000] D loss: 0.8337, G loss: 6.0843\n",
      "[3252/8000] D loss: 0.7189, G loss: 3.7879\n",
      "[3612/8000] D loss: 0.8365, G loss: 6.7355\n",
      "[3972/8000] D loss: 0.7730, G loss: 6.6411\n",
      "[4332/8000] D loss: 0.8888, G loss: 3.7748\n",
      "[4692/8000] D loss: 0.7394, G loss: 6.9427\n",
      "[5052/8000] D loss: 0.6977, G loss: 4.3144\n",
      "[5412/8000] D loss: 0.6856, G loss: 6.1158\n",
      "[5772/8000] D loss: 0.6327, G loss: 11.3186\n",
      "[6132/8000] D loss: 1.1941, G loss: 2.2243\n",
      "[6492/8000] D loss: 0.9250, G loss: 3.5243\n",
      "[6852/8000] D loss: 0.8732, G loss: 3.5671\n",
      "[7212/8000] D loss: 0.8191, G loss: 4.4260\n",
      "[7572/8000] D loss: 0.9920, G loss: 7.4860\n",
      "[7932/8000] D loss: 0.6658, G loss: 9.7727\n",
      "train error: \n",
      " D loss: 0.834698, G loss: 5.457864, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.935460, G loss: 15.973986, D accuracy: 80.3%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9746, G loss: 6.0104\n",
      "[372/8000] D loss: 0.8635, G loss: 4.5609\n",
      "[732/8000] D loss: 0.9392, G loss: 4.1171\n",
      "[1092/8000] D loss: 0.8782, G loss: 2.6811\n",
      "[1452/8000] D loss: 0.7046, G loss: 6.3471\n",
      "[1812/8000] D loss: 0.8376, G loss: 4.0796\n",
      "[2172/8000] D loss: 1.0072, G loss: 3.1839\n",
      "[2532/8000] D loss: 0.5791, G loss: 7.4966\n",
      "[2892/8000] D loss: 0.5566, G loss: 16.2576\n",
      "[3252/8000] D loss: 1.2090, G loss: 1.7755\n",
      "[3612/8000] D loss: 0.7804, G loss: 7.0093\n",
      "[3972/8000] D loss: 0.6834, G loss: 10.0808\n",
      "[4332/8000] D loss: 1.0623, G loss: 2.5700\n",
      "[4692/8000] D loss: 1.1287, G loss: 1.8492\n",
      "[5052/8000] D loss: 0.8729, G loss: 4.5145\n",
      "[5412/8000] D loss: 0.9418, G loss: 3.5874\n",
      "[5772/8000] D loss: 0.8018, G loss: 5.8882\n",
      "[6132/8000] D loss: 0.9307, G loss: 5.4564\n",
      "[6492/8000] D loss: 0.5086, G loss: 6.2559\n",
      "[6852/8000] D loss: 0.6884, G loss: 7.5749\n",
      "[7212/8000] D loss: 0.8411, G loss: 9.0351\n",
      "[7572/8000] D loss: 0.7857, G loss: 6.8838\n",
      "[7932/8000] D loss: 0.7328, G loss: 11.2383\n",
      "train error: \n",
      " D loss: 0.824785, G loss: 6.544754, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 55.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.950281, G loss: 18.733421, D accuracy: 78.5%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0010, G loss: 2.1133\n",
      "[372/8000] D loss: 0.8176, G loss: 6.7571\n",
      "[732/8000] D loss: 0.9707, G loss: 3.1407\n",
      "[1092/8000] D loss: 0.6510, G loss: 8.5403\n",
      "[1452/8000] D loss: 0.4445, G loss: 5.5257\n",
      "[1812/8000] D loss: 0.6316, G loss: 8.3111\n",
      "[2172/8000] D loss: 0.6862, G loss: 6.1140\n",
      "[2532/8000] D loss: 0.9586, G loss: 3.8457\n",
      "[2892/8000] D loss: 0.6528, G loss: 5.1435\n",
      "[3252/8000] D loss: 0.9391, G loss: 2.7190\n",
      "[3612/8000] D loss: 0.5319, G loss: 5.6050\n",
      "[3972/8000] D loss: 0.8981, G loss: 7.1518\n",
      "[4332/8000] D loss: 1.1782, G loss: 3.0810\n",
      "[4692/8000] D loss: 0.9887, G loss: 7.3351\n",
      "[5052/8000] D loss: 0.6912, G loss: 4.6868\n",
      "[5412/8000] D loss: 0.8391, G loss: 8.2745\n",
      "[5772/8000] D loss: 0.9325, G loss: 4.1566\n",
      "[6132/8000] D loss: 0.6971, G loss: 5.1611\n",
      "[6492/8000] D loss: 0.8697, G loss: 6.3069\n",
      "[6852/8000] D loss: 0.6925, G loss: 4.3306\n",
      "[7212/8000] D loss: 0.9241, G loss: 5.4337\n",
      "[7572/8000] D loss: 0.6142, G loss: 5.4250\n",
      "[7932/8000] D loss: 0.1299, G loss: 12.7924\n",
      "train error: \n",
      " D loss: 0.842543, G loss: 5.212390, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.862334, G loss: 15.490428, D accuracy: 80.6%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5290, G loss: 9.8049\n",
      "[372/8000] D loss: 0.7153, G loss: 8.6156\n",
      "[732/8000] D loss: 1.0452, G loss: 4.1397\n",
      "[1092/8000] D loss: 0.7069, G loss: 9.4859\n",
      "[1452/8000] D loss: 0.9031, G loss: 6.2768\n",
      "[1812/8000] D loss: 1.0638, G loss: 7.7420\n",
      "[2172/8000] D loss: 1.0797, G loss: 4.4542\n",
      "[2532/8000] D loss: 0.6861, G loss: 6.8712\n",
      "[2892/8000] D loss: 0.6592, G loss: 8.2744\n",
      "[3252/8000] D loss: 1.1778, G loss: 4.2723\n",
      "[3612/8000] D loss: 0.9181, G loss: 8.2118\n",
      "[3972/8000] D loss: 0.7119, G loss: 5.8441\n",
      "[4332/8000] D loss: 0.7116, G loss: 8.3103\n",
      "[4692/8000] D loss: 0.9755, G loss: 6.9029\n",
      "[5052/8000] D loss: 0.7373, G loss: 5.6209\n",
      "[5412/8000] D loss: 0.9379, G loss: 3.8894\n",
      "[5772/8000] D loss: 0.7019, G loss: 6.2547\n",
      "[6132/8000] D loss: 0.6925, G loss: 7.5276\n",
      "[6492/8000] D loss: 0.8497, G loss: 5.6723\n",
      "[6852/8000] D loss: 0.8734, G loss: 6.1122\n",
      "[7212/8000] D loss: 0.7641, G loss: 4.6589\n",
      "[7572/8000] D loss: 0.7722, G loss: 6.0770\n",
      "[7932/8000] D loss: 0.9654, G loss: 4.4949\n",
      "train error: \n",
      " D loss: 0.846168, G loss: 7.068232, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.056403, G loss: 18.894292, D accuracy: 74.6%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0295, G loss: 4.3247\n",
      "[372/8000] D loss: 0.7712, G loss: 3.2354\n",
      "[732/8000] D loss: 1.0652, G loss: 3.0513\n",
      "[1092/8000] D loss: 0.6126, G loss: 5.6128\n",
      "[1452/8000] D loss: 1.1153, G loss: 2.0023\n",
      "[1812/8000] D loss: 0.5868, G loss: 10.0900\n",
      "[2172/8000] D loss: 0.8214, G loss: 3.7922\n",
      "[2532/8000] D loss: 0.9523, G loss: 4.3088\n",
      "[2892/8000] D loss: 0.5911, G loss: 6.2894\n",
      "[3252/8000] D loss: 1.0404, G loss: 3.5034\n",
      "[3612/8000] D loss: 1.1545, G loss: 1.5805\n",
      "[3972/8000] D loss: 0.8842, G loss: 2.7405\n",
      "[4332/8000] D loss: 0.9447, G loss: 4.7540\n",
      "[4692/8000] D loss: 0.6146, G loss: 14.4599\n",
      "[5052/8000] D loss: 0.8255, G loss: 11.0489\n",
      "[5412/8000] D loss: 0.8933, G loss: 4.7835\n",
      "[5772/8000] D loss: 0.9115, G loss: 4.4885\n",
      "[6132/8000] D loss: 0.4846, G loss: 6.5689\n",
      "[6492/8000] D loss: 0.7150, G loss: 8.2668\n",
      "[6852/8000] D loss: 0.5722, G loss: 9.6483\n",
      "[7212/8000] D loss: 0.9177, G loss: 3.6984\n",
      "[7572/8000] D loss: 0.9382, G loss: 5.9434\n",
      "[7932/8000] D loss: 1.1093, G loss: 2.7561\n",
      "train error: \n",
      " D loss: 0.839208, G loss: 6.006429, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.947889, G loss: 16.904033, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8504, G loss: 3.8573\n",
      "[372/8000] D loss: 0.8781, G loss: 3.4801\n",
      "[732/8000] D loss: 0.8443, G loss: 5.8410\n",
      "[1092/8000] D loss: 0.8808, G loss: 5.9350\n",
      "[1452/8000] D loss: 0.8353, G loss: 8.6760\n",
      "[1812/8000] D loss: 0.6422, G loss: 7.5966\n",
      "[2172/8000] D loss: 0.8052, G loss: 2.9903\n",
      "[2532/8000] D loss: 1.0769, G loss: 7.6897\n",
      "[2892/8000] D loss: 0.7364, G loss: 7.6629\n",
      "[3252/8000] D loss: 1.0365, G loss: 2.5711\n",
      "[3612/8000] D loss: 0.6276, G loss: 4.8534\n",
      "[3972/8000] D loss: 0.9585, G loss: 4.4336\n",
      "[4332/8000] D loss: 0.7854, G loss: 4.2075\n",
      "[4692/8000] D loss: 1.0682, G loss: 3.4491\n",
      "[5052/8000] D loss: 0.5820, G loss: 5.5909\n",
      "[5412/8000] D loss: 1.0643, G loss: 2.5611\n",
      "[5772/8000] D loss: 0.4634, G loss: 11.8914\n",
      "[6132/8000] D loss: 0.6144, G loss: 10.2237\n",
      "[6492/8000] D loss: 0.5418, G loss: 7.2244\n",
      "[6852/8000] D loss: 0.9800, G loss: 2.1608\n",
      "[7212/8000] D loss: 0.8981, G loss: 6.0117\n",
      "[7572/8000] D loss: 1.0186, G loss: 2.2367\n",
      "[7932/8000] D loss: 0.9115, G loss: 5.7170\n",
      "train error: \n",
      " D loss: 0.821154, G loss: 6.064201, D accuracy: 73.2%, cell accuracy: 98.7%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.919095, G loss: 16.531015, D accuracy: 80.4%, cell accuracy: 98.2%, board accuracy: 24.9% \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1298, G loss: 1.5699\n",
      "[372/8000] D loss: 0.7002, G loss: 5.0544\n",
      "[732/8000] D loss: 0.9633, G loss: 4.9311\n",
      "[1092/8000] D loss: 0.3757, G loss: 8.0428\n",
      "[1452/8000] D loss: 0.6998, G loss: 7.4917\n",
      "[1812/8000] D loss: 0.9478, G loss: 3.4530\n",
      "[2172/8000] D loss: 0.9280, G loss: 5.6731\n",
      "[2532/8000] D loss: 0.7660, G loss: 6.1384\n",
      "[2892/8000] D loss: 0.6664, G loss: 5.5669\n",
      "[3252/8000] D loss: 0.8187, G loss: 6.4640\n",
      "[3612/8000] D loss: 1.0510, G loss: 2.3571\n",
      "[3972/8000] D loss: 0.8466, G loss: 9.8168\n",
      "[4332/8000] D loss: 0.9988, G loss: 5.0432\n",
      "[4692/8000] D loss: 0.9488, G loss: 3.7475\n",
      "[5052/8000] D loss: 0.8126, G loss: 4.9515\n",
      "[5412/8000] D loss: 0.7322, G loss: 6.5486\n",
      "[5772/8000] D loss: 1.0069, G loss: 3.1723\n",
      "[6132/8000] D loss: 0.7066, G loss: 9.4319\n",
      "[6492/8000] D loss: 1.0277, G loss: 2.5629\n",
      "[6852/8000] D loss: 1.2087, G loss: 4.8758\n",
      "[7212/8000] D loss: 0.9017, G loss: 2.7584\n",
      "[7572/8000] D loss: 0.7154, G loss: 8.2118\n",
      "[7932/8000] D loss: 0.6262, G loss: 8.1761\n",
      "train error: \n",
      " D loss: 0.837675, G loss: 6.582881, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.036476, G loss: 18.078807, D accuracy: 78.7%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7047, G loss: 4.1216\n",
      "[372/8000] D loss: 0.9573, G loss: 4.6003\n",
      "[732/8000] D loss: 0.8975, G loss: 5.1403\n",
      "[1092/8000] D loss: 0.7609, G loss: 7.5752\n",
      "[1452/8000] D loss: 0.5084, G loss: 9.8183\n",
      "[1812/8000] D loss: 0.5267, G loss: 9.3414\n",
      "[2172/8000] D loss: 1.1829, G loss: 2.8700\n",
      "[2532/8000] D loss: 0.5791, G loss: 11.9222\n",
      "[2892/8000] D loss: 0.9627, G loss: 4.4565\n",
      "[3252/8000] D loss: 0.6766, G loss: 9.4426\n",
      "[3612/8000] D loss: 0.4118, G loss: 8.6243\n",
      "[3972/8000] D loss: 0.7647, G loss: 6.7129\n",
      "[4332/8000] D loss: 0.8441, G loss: 7.0198\n",
      "[4692/8000] D loss: 0.8014, G loss: 4.0077\n",
      "[5052/8000] D loss: 0.8759, G loss: 6.2454\n",
      "[5412/8000] D loss: 0.9223, G loss: 5.1545\n",
      "[5772/8000] D loss: 0.8576, G loss: 4.7883\n",
      "[6132/8000] D loss: 0.8111, G loss: 8.6852\n",
      "[6492/8000] D loss: 0.8097, G loss: 3.3149\n",
      "[6852/8000] D loss: 0.8792, G loss: 4.3966\n",
      "[7212/8000] D loss: 0.8195, G loss: 3.9129\n",
      "[7572/8000] D loss: 0.6226, G loss: 7.7531\n",
      "[7932/8000] D loss: 0.5206, G loss: 7.0914\n",
      "train error: \n",
      " D loss: 0.843337, G loss: 4.948513, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.985748, G loss: 15.178546, D accuracy: 78.5%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6722, G loss: 6.2595\n",
      "[372/8000] D loss: 0.9203, G loss: 5.6837\n",
      "[732/8000] D loss: 0.8223, G loss: 4.5067\n",
      "[1092/8000] D loss: 0.5079, G loss: 5.8934\n",
      "[1452/8000] D loss: 0.8364, G loss: 6.1360\n",
      "[1812/8000] D loss: 0.6029, G loss: 7.4784\n",
      "[2172/8000] D loss: 1.1859, G loss: 3.2690\n",
      "[2532/8000] D loss: 1.0284, G loss: 4.7531\n",
      "[2892/8000] D loss: 1.0601, G loss: 4.1101\n",
      "[3252/8000] D loss: 0.7516, G loss: 3.9415\n",
      "[3612/8000] D loss: 0.5824, G loss: 7.0657\n",
      "[3972/8000] D loss: 0.8146, G loss: 8.0456\n",
      "[4332/8000] D loss: 0.7957, G loss: 7.6892\n",
      "[4692/8000] D loss: 0.7643, G loss: 6.4160\n",
      "[5052/8000] D loss: 1.1307, G loss: 1.3897\n",
      "[5412/8000] D loss: 0.5720, G loss: 8.7422\n",
      "[5772/8000] D loss: 0.6131, G loss: 5.0542\n",
      "[6132/8000] D loss: 1.0527, G loss: 2.3100\n",
      "[6492/8000] D loss: 0.8734, G loss: 7.0001\n",
      "[6852/8000] D loss: 0.9496, G loss: 5.5695\n",
      "[7212/8000] D loss: 0.9466, G loss: 3.6378\n",
      "[7572/8000] D loss: 0.9061, G loss: 7.4278\n",
      "[7932/8000] D loss: 0.7887, G loss: 7.8749\n",
      "train error: \n",
      " D loss: 0.843815, G loss: 5.893784, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.835440, G loss: 17.144412, D accuracy: 81.2%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6399, G loss: 3.9402\n",
      "[372/8000] D loss: 0.7220, G loss: 6.9220\n",
      "[732/8000] D loss: 0.6770, G loss: 5.6311\n",
      "[1092/8000] D loss: 0.9902, G loss: 2.3046\n",
      "[1452/8000] D loss: 0.8170, G loss: 6.6729\n",
      "[1812/8000] D loss: 0.7147, G loss: 11.2834\n",
      "[2172/8000] D loss: 0.7173, G loss: 6.8251\n",
      "[2532/8000] D loss: 0.3537, G loss: 9.4993\n",
      "[2892/8000] D loss: 0.7961, G loss: 8.4294\n",
      "[3252/8000] D loss: 0.8149, G loss: 7.2150\n",
      "[3612/8000] D loss: 0.8165, G loss: 2.3039\n",
      "[3972/8000] D loss: 1.2471, G loss: 1.5596\n",
      "[4332/8000] D loss: 0.7254, G loss: 10.7861\n",
      "[4692/8000] D loss: 0.9507, G loss: 3.8753\n",
      "[5052/8000] D loss: 0.5196, G loss: 6.7139\n",
      "[5412/8000] D loss: 1.0978, G loss: 2.8367\n",
      "[5772/8000] D loss: 0.3421, G loss: 5.0832\n",
      "[6132/8000] D loss: 1.1691, G loss: 3.6623\n",
      "[6492/8000] D loss: 0.9565, G loss: 9.2942\n",
      "[6852/8000] D loss: 1.2458, G loss: 2.7656\n",
      "[7212/8000] D loss: 0.6098, G loss: 6.3132\n",
      "[7572/8000] D loss: 0.7830, G loss: 8.4922\n",
      "[7932/8000] D loss: 1.0231, G loss: 2.9029\n",
      "train error: \n",
      " D loss: 0.831046, G loss: 5.582272, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.988451, G loss: 16.664030, D accuracy: 79.3%, cell accuracy: 98.2%, board accuracy: 26.1% \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9469, G loss: 2.5149\n",
      "[372/8000] D loss: 0.8928, G loss: 4.8295\n",
      "[732/8000] D loss: 1.0130, G loss: 2.0134\n",
      "[1092/8000] D loss: 0.6832, G loss: 9.2021\n",
      "[1452/8000] D loss: 0.7231, G loss: 6.0754\n",
      "[1812/8000] D loss: 0.4464, G loss: 5.8916\n",
      "[2172/8000] D loss: 1.0359, G loss: 1.8651\n",
      "[2532/8000] D loss: 0.6438, G loss: 7.4363\n",
      "[2892/8000] D loss: 0.3528, G loss: 10.8070\n",
      "[3252/8000] D loss: 0.4690, G loss: 12.3443\n",
      "[3612/8000] D loss: 1.1209, G loss: 4.5679\n",
      "[3972/8000] D loss: 0.5170, G loss: 6.4697\n",
      "[4332/8000] D loss: 0.7379, G loss: 5.5702\n",
      "[4692/8000] D loss: 0.8301, G loss: 3.7889\n",
      "[5052/8000] D loss: 0.8092, G loss: 10.3910\n",
      "[5412/8000] D loss: 1.2060, G loss: 2.3982\n",
      "[5772/8000] D loss: 0.7242, G loss: 9.2465\n",
      "[6132/8000] D loss: 1.0520, G loss: 3.1944\n",
      "[6492/8000] D loss: 0.8166, G loss: 5.2256\n",
      "[6852/8000] D loss: 0.6327, G loss: 3.8454\n",
      "[7212/8000] D loss: 0.4816, G loss: 8.1835\n",
      "[7572/8000] D loss: 0.6206, G loss: 7.4922\n",
      "[7932/8000] D loss: 1.0653, G loss: 2.3885\n",
      "train error: \n",
      " D loss: 0.872880, G loss: 6.594899, D accuracy: 71.3%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.151398, G loss: 17.495807, D accuracy: 72.4%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8628, G loss: 3.3770\n",
      "[372/8000] D loss: 0.9329, G loss: 6.7448\n",
      "[732/8000] D loss: 0.9279, G loss: 5.2924\n",
      "[1092/8000] D loss: 0.6044, G loss: 6.4996\n",
      "[1452/8000] D loss: 0.9609, G loss: 5.1055\n",
      "[1812/8000] D loss: 0.4501, G loss: 10.2164\n",
      "[2172/8000] D loss: 0.9397, G loss: 5.3937\n",
      "[2532/8000] D loss: 0.6446, G loss: 6.5884\n",
      "[2892/8000] D loss: 0.6726, G loss: 6.4729\n",
      "[3252/8000] D loss: 0.5871, G loss: 5.8850\n",
      "[3612/8000] D loss: 0.3921, G loss: 13.6501\n",
      "[3972/8000] D loss: 0.9179, G loss: 5.1837\n",
      "[4332/8000] D loss: 0.8487, G loss: 6.5503\n",
      "[4692/8000] D loss: 0.6926, G loss: 6.1938\n",
      "[5052/8000] D loss: 0.7922, G loss: 5.3932\n",
      "[5412/8000] D loss: 0.8381, G loss: 5.5644\n",
      "[5772/8000] D loss: 0.4737, G loss: 9.7584\n",
      "[6132/8000] D loss: 1.0532, G loss: 7.3549\n",
      "[6492/8000] D loss: 0.7949, G loss: 6.4392\n",
      "[6852/8000] D loss: 0.7766, G loss: 6.2643\n",
      "[7212/8000] D loss: 0.7478, G loss: 3.5842\n",
      "[7572/8000] D loss: 1.2897, G loss: 1.5531\n",
      "[7932/8000] D loss: 0.9535, G loss: 7.8170\n",
      "train error: \n",
      " D loss: 0.835639, G loss: 6.272508, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.008622, G loss: 17.767890, D accuracy: 74.4%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9599, G loss: 10.5491\n",
      "[372/8000] D loss: 0.6870, G loss: 5.8417\n",
      "[732/8000] D loss: 0.9083, G loss: 4.0790\n",
      "[1092/8000] D loss: 0.7822, G loss: 6.2986\n",
      "[1452/8000] D loss: 1.0507, G loss: 3.1054\n",
      "[1812/8000] D loss: 0.7363, G loss: 4.4801\n",
      "[2172/8000] D loss: 0.7240, G loss: 5.9449\n",
      "[2532/8000] D loss: 0.9995, G loss: 4.8623\n",
      "[2892/8000] D loss: 0.8136, G loss: 9.3392\n",
      "[3252/8000] D loss: 0.8246, G loss: 4.6710\n",
      "[3612/8000] D loss: 0.9520, G loss: 2.2357\n",
      "[3972/8000] D loss: 0.7906, G loss: 9.3233\n",
      "[4332/8000] D loss: 0.7992, G loss: 3.8157\n",
      "[4692/8000] D loss: 0.8272, G loss: 4.1824\n",
      "[5052/8000] D loss: 0.8365, G loss: 5.8871\n",
      "[5412/8000] D loss: 0.7909, G loss: 3.9446\n",
      "[5772/8000] D loss: 0.7071, G loss: 4.9206\n",
      "[6132/8000] D loss: 0.8743, G loss: 2.8648\n",
      "[6492/8000] D loss: 0.7154, G loss: 11.1959\n",
      "[6852/8000] D loss: 0.5187, G loss: 11.5330\n",
      "[7212/8000] D loss: 0.9573, G loss: 4.4379\n",
      "[7572/8000] D loss: 0.3670, G loss: 8.4257\n",
      "[7932/8000] D loss: 0.3763, G loss: 7.1466\n",
      "train error: \n",
      " D loss: 0.844065, G loss: 4.994274, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.846381, G loss: 15.479726, D accuracy: 81.6%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8856, G loss: 5.2131\n",
      "[372/8000] D loss: 0.6001, G loss: 5.3069\n",
      "[732/8000] D loss: 0.5764, G loss: 4.7232\n",
      "[1092/8000] D loss: 0.6831, G loss: 7.5275\n",
      "[1452/8000] D loss: 0.5052, G loss: 12.8854\n",
      "[1812/8000] D loss: 0.9074, G loss: 3.8157\n",
      "[2172/8000] D loss: 0.8345, G loss: 3.4879\n",
      "[2532/8000] D loss: 0.9001, G loss: 2.4783\n",
      "[2892/8000] D loss: 1.2895, G loss: 1.2387\n",
      "[3252/8000] D loss: 0.7700, G loss: 7.3024\n",
      "[3612/8000] D loss: 0.5579, G loss: 7.3255\n",
      "[3972/8000] D loss: 0.8049, G loss: 4.0021\n",
      "[4332/8000] D loss: 0.7625, G loss: 9.1478\n",
      "[4692/8000] D loss: 0.6694, G loss: 3.7305\n",
      "[5052/8000] D loss: 0.7264, G loss: 6.8400\n",
      "[5412/8000] D loss: 0.8680, G loss: 7.0319\n",
      "[5772/8000] D loss: 1.0983, G loss: 2.5742\n",
      "[6132/8000] D loss: 0.7971, G loss: 5.4548\n",
      "[6492/8000] D loss: 1.5324, G loss: 1.1349\n",
      "[6852/8000] D loss: 0.8314, G loss: 6.5718\n",
      "[7212/8000] D loss: 0.7321, G loss: 12.0990\n",
      "[7572/8000] D loss: 0.9021, G loss: 6.3963\n",
      "[7932/8000] D loss: 0.6116, G loss: 8.3356\n",
      "train error: \n",
      " D loss: 0.852668, G loss: 5.803511, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.012889, G loss: 16.904162, D accuracy: 77.2%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1312, G loss: 2.6862\n",
      "[372/8000] D loss: 0.9501, G loss: 3.5934\n",
      "[732/8000] D loss: 1.0568, G loss: 2.4212\n",
      "[1092/8000] D loss: 0.7885, G loss: 5.9069\n",
      "[1452/8000] D loss: 0.5069, G loss: 5.0277\n",
      "[1812/8000] D loss: 0.7252, G loss: 6.1399\n",
      "[2172/8000] D loss: 0.9391, G loss: 5.0112\n",
      "[2532/8000] D loss: 0.8889, G loss: 4.4073\n",
      "[2892/8000] D loss: 0.6744, G loss: 9.0753\n",
      "[3252/8000] D loss: 1.1962, G loss: 1.5689\n",
      "[3612/8000] D loss: 0.9025, G loss: 8.7926\n",
      "[3972/8000] D loss: 1.1106, G loss: 4.7422\n",
      "[4332/8000] D loss: 0.9663, G loss: 7.0350\n",
      "[4692/8000] D loss: 0.8472, G loss: 7.2233\n",
      "[5052/8000] D loss: 0.8498, G loss: 3.0606\n",
      "[5412/8000] D loss: 0.7713, G loss: 5.7717\n",
      "[5772/8000] D loss: 0.9525, G loss: 1.8373\n",
      "[6132/8000] D loss: 0.9937, G loss: 1.4597\n",
      "[6492/8000] D loss: 0.7304, G loss: 4.0007\n",
      "[6852/8000] D loss: 0.8635, G loss: 3.9973\n",
      "[7212/8000] D loss: 0.7092, G loss: 5.5148\n",
      "[7572/8000] D loss: 1.0441, G loss: 4.5011\n",
      "[7932/8000] D loss: 0.6855, G loss: 4.0616\n",
      "train error: \n",
      " D loss: 0.850542, G loss: 5.816087, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.937644, G loss: 16.077073, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5707, G loss: 11.4088\n",
      "[372/8000] D loss: 0.7396, G loss: 6.2184\n",
      "[732/8000] D loss: 1.1966, G loss: 2.5177\n",
      "[1092/8000] D loss: 0.9728, G loss: 2.3965\n",
      "[1452/8000] D loss: 1.0446, G loss: 3.8374\n",
      "[1812/8000] D loss: 0.7187, G loss: 5.3388\n",
      "[2172/8000] D loss: 0.7226, G loss: 6.1020\n",
      "[2532/8000] D loss: 1.1082, G loss: 4.5132\n",
      "[2892/8000] D loss: 0.8267, G loss: 4.8643\n",
      "[3252/8000] D loss: 0.5809, G loss: 5.5937\n",
      "[3612/8000] D loss: 0.4901, G loss: 6.4541\n",
      "[3972/8000] D loss: 0.9526, G loss: 2.3228\n",
      "[4332/8000] D loss: 0.8351, G loss: 3.3250\n",
      "[4692/8000] D loss: 0.7196, G loss: 5.7018\n",
      "[5052/8000] D loss: 0.9406, G loss: 7.8975\n",
      "[5412/8000] D loss: 0.6324, G loss: 4.2046\n",
      "[5772/8000] D loss: 0.8274, G loss: 7.4877\n",
      "[6132/8000] D loss: 1.0023, G loss: 2.8505\n",
      "[6492/8000] D loss: 0.3745, G loss: 18.4843\n",
      "[6852/8000] D loss: 0.6415, G loss: 6.2959\n",
      "[7212/8000] D loss: 0.7535, G loss: 10.0868\n",
      "[7572/8000] D loss: 0.4906, G loss: 12.2991\n",
      "[7932/8000] D loss: 0.3298, G loss: 15.5569\n",
      "train error: \n",
      " D loss: 0.839334, G loss: 6.863893, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.001823, G loss: 19.037330, D accuracy: 78.4%, cell accuracy: 98.2%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6446, G loss: 8.6292\n",
      "[372/8000] D loss: 0.8669, G loss: 14.1149\n",
      "[732/8000] D loss: 1.0251, G loss: 3.1224\n",
      "[1092/8000] D loss: 1.0082, G loss: 2.0709\n",
      "[1452/8000] D loss: 0.6038, G loss: 6.1885\n",
      "[1812/8000] D loss: 0.8357, G loss: 4.2021\n",
      "[2172/8000] D loss: 0.8582, G loss: 4.4609\n",
      "[2532/8000] D loss: 0.7459, G loss: 6.5689\n",
      "[2892/8000] D loss: 1.0533, G loss: 2.4262\n",
      "[3252/8000] D loss: 0.8357, G loss: 3.7185\n",
      "[3612/8000] D loss: 0.8092, G loss: 7.0426\n",
      "[3972/8000] D loss: 0.6927, G loss: 6.1219\n",
      "[4332/8000] D loss: 0.8612, G loss: 6.9018\n",
      "[4692/8000] D loss: 1.3141, G loss: 2.0551\n",
      "[5052/8000] D loss: 1.1562, G loss: 1.5204\n",
      "[5412/8000] D loss: 0.9016, G loss: 2.3834\n",
      "[5772/8000] D loss: 0.8690, G loss: 5.6079\n",
      "[6132/8000] D loss: 1.0406, G loss: 7.4825\n",
      "[6492/8000] D loss: 0.4588, G loss: 10.8931\n",
      "[6852/8000] D loss: 0.8155, G loss: 9.7691\n",
      "[7212/8000] D loss: 1.1537, G loss: 2.9747\n",
      "[7572/8000] D loss: 1.2260, G loss: 3.3315\n",
      "[7932/8000] D loss: 0.5400, G loss: 6.1662\n",
      "train error: \n",
      " D loss: 0.848661, G loss: 5.228514, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.919159, G loss: 16.344186, D accuracy: 79.3%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.4226, G loss: 4.1923\n",
      "[372/8000] D loss: 1.0834, G loss: 4.6125\n",
      "[732/8000] D loss: 0.8172, G loss: 6.4546\n",
      "[1092/8000] D loss: 1.1700, G loss: 4.8525\n",
      "[1452/8000] D loss: 1.0109, G loss: 7.2588\n",
      "[1812/8000] D loss: 0.7579, G loss: 9.2310\n",
      "[2172/8000] D loss: 1.2525, G loss: 2.8381\n",
      "[2532/8000] D loss: 0.5656, G loss: 5.3636\n",
      "[2892/8000] D loss: 0.6388, G loss: 8.2683\n",
      "[3252/8000] D loss: 0.8898, G loss: 6.6983\n",
      "[3612/8000] D loss: 0.7452, G loss: 7.3079\n",
      "[3972/8000] D loss: 1.3382, G loss: 1.6090\n",
      "[4332/8000] D loss: 1.2403, G loss: 1.1137\n",
      "[4692/8000] D loss: 0.7461, G loss: 7.4857\n",
      "[5052/8000] D loss: 1.0733, G loss: 3.8124\n",
      "[5412/8000] D loss: 0.5112, G loss: 6.8340\n",
      "[5772/8000] D loss: 0.9578, G loss: 5.2392\n",
      "[6132/8000] D loss: 0.8146, G loss: 9.0396\n",
      "[6492/8000] D loss: 0.9103, G loss: 5.7815\n",
      "[6852/8000] D loss: 1.3116, G loss: 3.2019\n",
      "[7212/8000] D loss: 0.8164, G loss: 7.6231\n",
      "[7572/8000] D loss: 0.5632, G loss: 9.2956\n",
      "[7932/8000] D loss: 1.1285, G loss: 3.3670\n",
      "train error: \n",
      " D loss: 0.860550, G loss: 6.439168, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.867787, G loss: 18.066700, D accuracy: 81.4%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0587, G loss: 1.8472\n",
      "[372/8000] D loss: 0.9402, G loss: 4.5642\n",
      "[732/8000] D loss: 1.0369, G loss: 2.9826\n",
      "[1092/8000] D loss: 0.6031, G loss: 6.6203\n",
      "[1452/8000] D loss: 1.0520, G loss: 4.1118\n",
      "[1812/8000] D loss: 0.5891, G loss: 12.7186\n",
      "[2172/8000] D loss: 0.4035, G loss: 7.0823\n",
      "[2532/8000] D loss: 0.5938, G loss: 8.4899\n",
      "[2892/8000] D loss: 0.9491, G loss: 3.7467\n",
      "[3252/8000] D loss: 0.6873, G loss: 7.1920\n",
      "[3612/8000] D loss: 0.9642, G loss: 2.5869\n",
      "[3972/8000] D loss: 0.9364, G loss: 6.6403\n",
      "[4332/8000] D loss: 0.5325, G loss: 9.0022\n",
      "[4692/8000] D loss: 0.8467, G loss: 3.5538\n",
      "[5052/8000] D loss: 0.7289, G loss: 4.7152\n",
      "[5412/8000] D loss: 0.6922, G loss: 5.0481\n",
      "[5772/8000] D loss: 1.0283, G loss: 2.9893\n",
      "[6132/8000] D loss: 0.9444, G loss: 4.4801\n",
      "[6492/8000] D loss: 0.8535, G loss: 3.9173\n",
      "[6852/8000] D loss: 0.3651, G loss: 8.8985\n",
      "[7212/8000] D loss: 0.4844, G loss: 9.6316\n",
      "[7572/8000] D loss: 1.0436, G loss: 4.7657\n",
      "[7932/8000] D loss: 0.5986, G loss: 12.0193\n",
      "train error: \n",
      " D loss: 0.834335, G loss: 6.457496, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.973567, G loss: 18.575922, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9403, G loss: 5.0479\n",
      "[372/8000] D loss: 1.2035, G loss: 2.7098\n",
      "[732/8000] D loss: 0.7006, G loss: 3.9632\n",
      "[1092/8000] D loss: 0.9586, G loss: 4.4450\n",
      "[1452/8000] D loss: 1.1249, G loss: 3.4783\n",
      "[1812/8000] D loss: 1.1198, G loss: 2.9686\n",
      "[2172/8000] D loss: 0.8362, G loss: 4.7175\n",
      "[2532/8000] D loss: 1.0534, G loss: 4.5642\n",
      "[2892/8000] D loss: 0.5272, G loss: 9.2142\n",
      "[3252/8000] D loss: 0.4924, G loss: 8.1644\n",
      "[3612/8000] D loss: 0.9393, G loss: 5.7446\n",
      "[3972/8000] D loss: 0.7779, G loss: 10.7225\n",
      "[4332/8000] D loss: 0.8351, G loss: 3.8053\n",
      "[4692/8000] D loss: 0.3766, G loss: 5.7770\n",
      "[5052/8000] D loss: 0.8840, G loss: 3.8849\n",
      "[5412/8000] D loss: 0.7733, G loss: 3.6769\n",
      "[5772/8000] D loss: 1.0735, G loss: 3.5030\n",
      "[6132/8000] D loss: 0.9148, G loss: 8.3007\n",
      "[6492/8000] D loss: 1.0325, G loss: 2.9344\n",
      "[6852/8000] D loss: 1.0295, G loss: 3.9143\n",
      "[7212/8000] D loss: 0.6091, G loss: 5.3247\n",
      "[7572/8000] D loss: 0.6233, G loss: 5.1846\n",
      "[7932/8000] D loss: 0.6002, G loss: 3.3807\n",
      "train error: \n",
      " D loss: 0.849531, G loss: 6.496411, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.122280, G loss: 18.244550, D accuracy: 75.4%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0378, G loss: 5.8804\n",
      "[372/8000] D loss: 0.8837, G loss: 5.0854\n",
      "[732/8000] D loss: 0.7634, G loss: 7.0300\n",
      "[1092/8000] D loss: 0.7679, G loss: 7.0385\n",
      "[1452/8000] D loss: 0.6144, G loss: 6.6804\n",
      "[1812/8000] D loss: 0.5986, G loss: 10.7218\n",
      "[2172/8000] D loss: 0.9267, G loss: 4.5277\n",
      "[2532/8000] D loss: 0.4831, G loss: 8.7939\n",
      "[2892/8000] D loss: 1.0625, G loss: 5.3029\n",
      "[3252/8000] D loss: 1.0675, G loss: 3.9109\n",
      "[3612/8000] D loss: 1.0755, G loss: 2.2594\n",
      "[3972/8000] D loss: 0.4838, G loss: 6.6505\n",
      "[4332/8000] D loss: 0.6866, G loss: 3.7204\n",
      "[4692/8000] D loss: 0.9696, G loss: 6.4351\n",
      "[5052/8000] D loss: 0.9570, G loss: 3.6168\n",
      "[5412/8000] D loss: 0.6009, G loss: 7.8564\n",
      "[5772/8000] D loss: 1.0410, G loss: 2.9861\n",
      "[6132/8000] D loss: 0.3574, G loss: 8.9680\n",
      "[6492/8000] D loss: 0.5716, G loss: 16.9285\n",
      "[6852/8000] D loss: 0.8046, G loss: 10.5627\n",
      "[7212/8000] D loss: 0.7935, G loss: 5.9213\n",
      "[7572/8000] D loss: 0.6690, G loss: 7.8147\n",
      "[7932/8000] D loss: 1.1141, G loss: 6.5785\n",
      "train error: \n",
      " D loss: 0.835193, G loss: 6.304602, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.975158, G loss: 17.401143, D accuracy: 77.0%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7737, G loss: 4.0186\n",
      "[372/8000] D loss: 0.6082, G loss: 3.8486\n",
      "[732/8000] D loss: 0.7457, G loss: 7.1341\n",
      "[1092/8000] D loss: 0.6858, G loss: 4.6439\n",
      "[1452/8000] D loss: 0.9298, G loss: 8.8800\n",
      "[1812/8000] D loss: 1.2483, G loss: 2.0292\n",
      "[2172/8000] D loss: 1.0711, G loss: 2.4476\n",
      "[2532/8000] D loss: 1.0907, G loss: 2.7927\n",
      "[2892/8000] D loss: 0.8693, G loss: 4.6449\n",
      "[3252/8000] D loss: 0.9650, G loss: 7.9371\n",
      "[3612/8000] D loss: 0.7554, G loss: 5.1113\n",
      "[3972/8000] D loss: 0.6315, G loss: 5.6915\n",
      "[4332/8000] D loss: 0.8164, G loss: 4.7055\n",
      "[4692/8000] D loss: 1.1052, G loss: 5.3811\n",
      "[5052/8000] D loss: 0.9618, G loss: 5.5669\n",
      "[5412/8000] D loss: 0.8111, G loss: 5.3813\n",
      "[5772/8000] D loss: 1.0501, G loss: 5.1338\n",
      "[6132/8000] D loss: 0.8727, G loss: 3.7317\n",
      "[6492/8000] D loss: 0.9595, G loss: 4.1762\n",
      "[6852/8000] D loss: 0.9313, G loss: 2.4457\n",
      "[7212/8000] D loss: 0.8164, G loss: 6.1928\n",
      "[7572/8000] D loss: 0.8208, G loss: 6.5262\n",
      "[7932/8000] D loss: 0.8801, G loss: 5.6458\n",
      "train error: \n",
      " D loss: 0.839084, G loss: 6.255626, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.968931, G loss: 18.551359, D accuracy: 78.5%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8215, G loss: 8.9972\n",
      "[372/8000] D loss: 0.5607, G loss: 7.3866\n",
      "[732/8000] D loss: 0.9367, G loss: 2.7177\n",
      "[1092/8000] D loss: 0.4804, G loss: 8.8285\n",
      "[1452/8000] D loss: 0.7011, G loss: 7.2713\n",
      "[1812/8000] D loss: 0.7081, G loss: 5.9671\n",
      "[2172/8000] D loss: 0.7047, G loss: 6.0705\n",
      "[2532/8000] D loss: 1.0339, G loss: 1.6013\n",
      "[2892/8000] D loss: 0.7226, G loss: 4.8966\n",
      "[3252/8000] D loss: 0.8440, G loss: 4.5303\n",
      "[3612/8000] D loss: 0.5904, G loss: 8.6613\n",
      "[3972/8000] D loss: 0.7938, G loss: 13.3532\n",
      "[4332/8000] D loss: 1.1483, G loss: 1.8564\n",
      "[4692/8000] D loss: 0.5205, G loss: 8.8823\n",
      "[5052/8000] D loss: 0.6780, G loss: 4.9384\n",
      "[5412/8000] D loss: 0.9322, G loss: 5.0192\n",
      "[5772/8000] D loss: 0.8253, G loss: 2.8191\n",
      "[6132/8000] D loss: 1.1449, G loss: 3.0778\n",
      "[6492/8000] D loss: 0.8209, G loss: 4.2729\n",
      "[6852/8000] D loss: 0.7069, G loss: 5.1887\n",
      "[7212/8000] D loss: 0.8077, G loss: 4.6753\n",
      "[7572/8000] D loss: 0.8451, G loss: 6.3618\n",
      "[7932/8000] D loss: 0.5174, G loss: 10.0622\n",
      "train error: \n",
      " D loss: 0.835249, G loss: 5.509071, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.960956, G loss: 16.292292, D accuracy: 78.6%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9235, G loss: 4.9870\n",
      "[372/8000] D loss: 1.1992, G loss: 2.5042\n",
      "[732/8000] D loss: 0.9552, G loss: 1.5905\n",
      "[1092/8000] D loss: 1.0605, G loss: 2.1332\n",
      "[1452/8000] D loss: 0.8797, G loss: 3.1469\n",
      "[1812/8000] D loss: 0.8236, G loss: 4.7904\n",
      "[2172/8000] D loss: 0.8160, G loss: 4.4430\n",
      "[2532/8000] D loss: 0.7246, G loss: 5.4572\n",
      "[2892/8000] D loss: 1.2237, G loss: 1.9171\n",
      "[3252/8000] D loss: 0.9520, G loss: 5.5880\n",
      "[3612/8000] D loss: 1.0212, G loss: 7.2527\n",
      "[3972/8000] D loss: 0.7458, G loss: 8.3619\n",
      "[4332/8000] D loss: 0.6044, G loss: 6.8413\n",
      "[4692/8000] D loss: 1.3148, G loss: 3.2130\n",
      "[5052/8000] D loss: 0.6910, G loss: 7.3948\n",
      "[5412/8000] D loss: 0.7202, G loss: 4.5548\n",
      "[5772/8000] D loss: 0.9120, G loss: 2.6654\n",
      "[6132/8000] D loss: 0.4891, G loss: 11.9194\n",
      "[6492/8000] D loss: 0.4547, G loss: 9.8839\n",
      "[6852/8000] D loss: 0.3701, G loss: 13.5414\n",
      "[7212/8000] D loss: 0.9486, G loss: 6.8394\n",
      "[7572/8000] D loss: 0.8055, G loss: 6.7704\n",
      "[7932/8000] D loss: 0.6233, G loss: 5.6101\n",
      "train error: \n",
      " D loss: 0.831831, G loss: 6.170649, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.932609, G loss: 17.772308, D accuracy: 80.7%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1886, G loss: 1.3426\n",
      "[372/8000] D loss: 0.9204, G loss: 5.7620\n",
      "[732/8000] D loss: 1.1121, G loss: 5.1247\n",
      "[1092/8000] D loss: 0.8150, G loss: 7.6984\n",
      "[1452/8000] D loss: 0.8483, G loss: 5.5408\n",
      "[1812/8000] D loss: 0.9420, G loss: 6.6649\n",
      "[2172/8000] D loss: 0.9191, G loss: 2.3007\n",
      "[2532/8000] D loss: 1.0221, G loss: 3.5671\n",
      "[2892/8000] D loss: 0.8099, G loss: 7.7087\n",
      "[3252/8000] D loss: 1.3293, G loss: 1.0596\n",
      "[3612/8000] D loss: 0.9256, G loss: 7.4701\n",
      "[3972/8000] D loss: 0.7509, G loss: 5.4890\n",
      "[4332/8000] D loss: 0.5823, G loss: 10.8922\n",
      "[4692/8000] D loss: 0.5910, G loss: 7.9001\n",
      "[5052/8000] D loss: 0.9252, G loss: 3.9954\n",
      "[5412/8000] D loss: 0.6508, G loss: 14.7080\n",
      "[5772/8000] D loss: 0.9668, G loss: 5.6424\n",
      "[6132/8000] D loss: 0.5851, G loss: 5.8027\n",
      "[6492/8000] D loss: 1.0243, G loss: 3.9386\n",
      "[6852/8000] D loss: 0.5822, G loss: 9.2895\n",
      "[7212/8000] D loss: 0.8459, G loss: 5.7342\n",
      "[7572/8000] D loss: 0.9617, G loss: 3.4246\n",
      "[7932/8000] D loss: 0.7226, G loss: 10.9928\n",
      "train error: \n",
      " D loss: 0.846081, G loss: 5.495391, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.888542, G loss: 16.376374, D accuracy: 80.4%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5353, G loss: 7.6049\n",
      "[372/8000] D loss: 0.4882, G loss: 11.7611\n",
      "[732/8000] D loss: 0.8332, G loss: 3.4829\n",
      "[1092/8000] D loss: 0.6090, G loss: 3.4396\n",
      "[1452/8000] D loss: 1.1864, G loss: 2.3234\n",
      "[1812/8000] D loss: 0.9715, G loss: 5.0011\n",
      "[2172/8000] D loss: 0.6513, G loss: 9.5238\n",
      "[2532/8000] D loss: 0.9934, G loss: 1.9863\n",
      "[2892/8000] D loss: 1.0395, G loss: 3.4060\n",
      "[3252/8000] D loss: 0.8259, G loss: 6.1876\n",
      "[3612/8000] D loss: 0.6665, G loss: 3.2023\n",
      "[3972/8000] D loss: 0.5797, G loss: 7.3618\n",
      "[4332/8000] D loss: 0.8780, G loss: 8.6188\n",
      "[4692/8000] D loss: 0.7729, G loss: 3.7278\n",
      "[5052/8000] D loss: 1.0329, G loss: 7.9650\n",
      "[5412/8000] D loss: 0.8335, G loss: 5.0645\n",
      "[5772/8000] D loss: 1.1217, G loss: 2.2675\n",
      "[6132/8000] D loss: 0.6798, G loss: 6.1634\n",
      "[6492/8000] D loss: 0.6959, G loss: 3.2935\n",
      "[6852/8000] D loss: 0.9001, G loss: 2.2776\n",
      "[7212/8000] D loss: 0.5852, G loss: 8.0746\n",
      "[7572/8000] D loss: 0.6732, G loss: 5.4967\n",
      "[7932/8000] D loss: 1.2192, G loss: 1.3464\n",
      "train error: \n",
      " D loss: 0.856310, G loss: 6.648229, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.976771, G loss: 18.836055, D accuracy: 76.7%, cell accuracy: 98.3%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0472, G loss: 8.6621\n",
      "[372/8000] D loss: 0.6948, G loss: 5.6580\n",
      "[732/8000] D loss: 0.5041, G loss: 7.2654\n",
      "[1092/8000] D loss: 0.9889, G loss: 7.2644\n",
      "[1452/8000] D loss: 0.4026, G loss: 9.5908\n",
      "[1812/8000] D loss: 0.7290, G loss: 5.6416\n",
      "[2172/8000] D loss: 0.8339, G loss: 3.5226\n",
      "[2532/8000] D loss: 0.4979, G loss: 10.4454\n",
      "[2892/8000] D loss: 0.8414, G loss: 6.0303\n",
      "[3252/8000] D loss: 0.5736, G loss: 6.5569\n",
      "[3612/8000] D loss: 0.5488, G loss: 18.4799\n",
      "[3972/8000] D loss: 0.6280, G loss: 7.2386\n",
      "[4332/8000] D loss: 0.9812, G loss: 4.8767\n",
      "[4692/8000] D loss: 0.9853, G loss: 5.9749\n",
      "[5052/8000] D loss: 0.8792, G loss: 11.2831\n",
      "[5412/8000] D loss: 1.0498, G loss: 4.0524\n",
      "[5772/8000] D loss: 0.6754, G loss: 7.1356\n",
      "[6132/8000] D loss: 0.9090, G loss: 6.9021\n",
      "[6492/8000] D loss: 0.5540, G loss: 11.6893\n",
      "[6852/8000] D loss: 0.5309, G loss: 8.6946\n",
      "[7212/8000] D loss: 0.9423, G loss: 6.3472\n",
      "[7572/8000] D loss: 0.4672, G loss: 14.4426\n",
      "[7932/8000] D loss: 0.7313, G loss: 7.4610\n",
      "train error: \n",
      " D loss: 0.836917, G loss: 5.345086, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.959298, G loss: 16.253082, D accuracy: 79.8%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7476, G loss: 6.6465\n",
      "[372/8000] D loss: 1.1575, G loss: 4.9953\n",
      "[732/8000] D loss: 0.7264, G loss: 8.0254\n",
      "[1092/8000] D loss: 0.9316, G loss: 7.0561\n",
      "[1452/8000] D loss: 0.9005, G loss: 6.9957\n",
      "[1812/8000] D loss: 0.7041, G loss: 7.0830\n",
      "[2172/8000] D loss: 0.7661, G loss: 3.6069\n",
      "[2532/8000] D loss: 0.8447, G loss: 5.4990\n",
      "[2892/8000] D loss: 0.4813, G loss: 9.7398\n",
      "[3252/8000] D loss: 0.8011, G loss: 5.0798\n",
      "[3612/8000] D loss: 0.7209, G loss: 8.1060\n",
      "[3972/8000] D loss: 1.1777, G loss: 2.3660\n",
      "[4332/8000] D loss: 1.0191, G loss: 2.0499\n",
      "[4692/8000] D loss: 1.0240, G loss: 2.6110\n",
      "[5052/8000] D loss: 1.0015, G loss: 5.7829\n",
      "[5412/8000] D loss: 0.9399, G loss: 8.3996\n",
      "[5772/8000] D loss: 0.8345, G loss: 7.7989\n",
      "[6132/8000] D loss: 0.8700, G loss: 3.4681\n",
      "[6492/8000] D loss: 1.0291, G loss: 4.7992\n",
      "[6852/8000] D loss: 0.9487, G loss: 5.2346\n",
      "[7212/8000] D loss: 1.2558, G loss: 2.6195\n",
      "[7572/8000] D loss: 0.9098, G loss: 5.6466\n",
      "[7932/8000] D loss: 0.7221, G loss: 8.8646\n",
      "train error: \n",
      " D loss: 0.846226, G loss: 5.488581, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.882562, G loss: 16.680777, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0807, G loss: 3.5897\n",
      "[372/8000] D loss: 0.9359, G loss: 4.6317\n",
      "[732/8000] D loss: 0.6524, G loss: 9.7413\n",
      "[1092/8000] D loss: 0.9804, G loss: 2.9160\n",
      "[1452/8000] D loss: 1.0511, G loss: 2.9545\n",
      "[1812/8000] D loss: 0.8107, G loss: 3.6046\n",
      "[2172/8000] D loss: 0.5929, G loss: 11.8140\n",
      "[2532/8000] D loss: 1.0357, G loss: 2.1944\n",
      "[2892/8000] D loss: 1.2653, G loss: 4.1646\n",
      "[3252/8000] D loss: 0.8350, G loss: 10.3186\n",
      "[3612/8000] D loss: 0.7866, G loss: 8.7658\n",
      "[3972/8000] D loss: 0.7381, G loss: 3.0291\n",
      "[4332/8000] D loss: 1.0041, G loss: 4.6639\n",
      "[4692/8000] D loss: 0.5634, G loss: 6.4718\n",
      "[5052/8000] D loss: 0.7440, G loss: 6.8351\n",
      "[5412/8000] D loss: 0.6123, G loss: 4.3156\n",
      "[5772/8000] D loss: 0.9129, G loss: 7.0022\n",
      "[6132/8000] D loss: 0.9272, G loss: 7.0315\n",
      "[6492/8000] D loss: 1.0329, G loss: 3.0414\n",
      "[6852/8000] D loss: 0.5788, G loss: 5.5527\n",
      "[7212/8000] D loss: 0.4063, G loss: 13.6359\n",
      "[7572/8000] D loss: 0.9513, G loss: 4.8586\n",
      "[7932/8000] D loss: 0.9401, G loss: 5.2433\n",
      "train error: \n",
      " D loss: 0.876696, G loss: 4.201822, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.859724, G loss: 13.337996, D accuracy: 81.1%, cell accuracy: 98.2%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9158, G loss: 4.0934\n",
      "[372/8000] D loss: 0.7165, G loss: 6.3504\n",
      "[732/8000] D loss: 0.8048, G loss: 8.8855\n",
      "[1092/8000] D loss: 0.7110, G loss: 8.3877\n",
      "[1452/8000] D loss: 0.9689, G loss: 5.0187\n",
      "[1812/8000] D loss: 0.5005, G loss: 11.0582\n",
      "[2172/8000] D loss: 0.9007, G loss: 5.5442\n",
      "[2532/8000] D loss: 0.8023, G loss: 7.5070\n",
      "[2892/8000] D loss: 1.0689, G loss: 5.1238\n",
      "[3252/8000] D loss: 0.5425, G loss: 3.9802\n",
      "[3612/8000] D loss: 0.7833, G loss: 3.3799\n",
      "[3972/8000] D loss: 0.7757, G loss: 3.1538\n",
      "[4332/8000] D loss: 0.8745, G loss: 4.5024\n",
      "[4692/8000] D loss: 0.9385, G loss: 4.3446\n",
      "[5052/8000] D loss: 0.8593, G loss: 6.4323\n",
      "[5412/8000] D loss: 0.3935, G loss: 9.6734\n",
      "[5772/8000] D loss: 0.5969, G loss: 6.6069\n",
      "[6132/8000] D loss: 0.8197, G loss: 3.8670\n",
      "[6492/8000] D loss: 1.1974, G loss: 4.1504\n",
      "[6852/8000] D loss: 0.3592, G loss: 7.3919\n",
      "[7212/8000] D loss: 0.9370, G loss: 4.6768\n",
      "[7572/8000] D loss: 0.8218, G loss: 7.1474\n",
      "[7932/8000] D loss: 0.5573, G loss: 3.8046\n",
      "train error: \n",
      " D loss: 0.855540, G loss: 5.924701, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.092623, G loss: 17.318431, D accuracy: 74.6%, cell accuracy: 98.3%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8683, G loss: 6.4197\n",
      "[372/8000] D loss: 0.6919, G loss: 7.5119\n",
      "[732/8000] D loss: 0.8715, G loss: 2.4085\n",
      "[1092/8000] D loss: 1.0380, G loss: 3.6927\n",
      "[1452/8000] D loss: 0.8902, G loss: 8.2585\n",
      "[1812/8000] D loss: 0.8314, G loss: 7.6689\n",
      "[2172/8000] D loss: 0.9417, G loss: 5.5057\n",
      "[2532/8000] D loss: 0.6281, G loss: 13.6988\n",
      "[2892/8000] D loss: 0.6665, G loss: 4.3936\n",
      "[3252/8000] D loss: 0.6857, G loss: 8.6019\n",
      "[3612/8000] D loss: 1.0008, G loss: 2.2260\n",
      "[3972/8000] D loss: 0.7085, G loss: 4.8035\n",
      "[4332/8000] D loss: 0.9415, G loss: 7.9298\n",
      "[4692/8000] D loss: 1.0695, G loss: 3.8241\n",
      "[5052/8000] D loss: 1.0777, G loss: 2.9179\n",
      "[5412/8000] D loss: 0.7717, G loss: 3.2151\n",
      "[5772/8000] D loss: 0.8361, G loss: 9.9358\n",
      "[6132/8000] D loss: 1.1192, G loss: 2.2903\n",
      "[6492/8000] D loss: 0.8527, G loss: 4.8075\n",
      "[6852/8000] D loss: 1.2249, G loss: 1.0787\n",
      "[7212/8000] D loss: 0.8274, G loss: 4.3006\n",
      "[7572/8000] D loss: 0.8776, G loss: 4.0791\n",
      "[7932/8000] D loss: 0.9813, G loss: 5.7156\n",
      "train error: \n",
      " D loss: 0.888724, G loss: 6.445159, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 56.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.081897, G loss: 18.785499, D accuracy: 76.0%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2947, G loss: 1.3543\n",
      "[372/8000] D loss: 0.9082, G loss: 7.1743\n",
      "[732/8000] D loss: 1.0247, G loss: 3.0383\n",
      "[1092/8000] D loss: 0.3589, G loss: 8.4151\n",
      "[1452/8000] D loss: 0.9452, G loss: 2.7872\n",
      "[1812/8000] D loss: 0.9312, G loss: 8.0251\n",
      "[2172/8000] D loss: 0.7241, G loss: 5.4615\n",
      "[2532/8000] D loss: 0.8234, G loss: 7.6442\n",
      "[2892/8000] D loss: 1.2961, G loss: 2.3888\n",
      "[3252/8000] D loss: 1.2416, G loss: 3.2543\n",
      "[3612/8000] D loss: 1.1013, G loss: 2.5147\n",
      "[3972/8000] D loss: 0.6303, G loss: 8.7082\n",
      "[4332/8000] D loss: 1.1663, G loss: 4.4778\n",
      "[4692/8000] D loss: 0.9497, G loss: 4.9461\n",
      "[5052/8000] D loss: 0.7331, G loss: 4.1849\n",
      "[5412/8000] D loss: 0.4219, G loss: 6.3114\n",
      "[5772/8000] D loss: 0.7173, G loss: 11.6455\n",
      "[6132/8000] D loss: 0.5018, G loss: 4.9940\n",
      "[6492/8000] D loss: 0.5659, G loss: 9.9690\n",
      "[6852/8000] D loss: 0.5504, G loss: 5.7887\n",
      "[7212/8000] D loss: 1.1313, G loss: 2.3513\n",
      "[7572/8000] D loss: 0.7070, G loss: 8.4296\n",
      "[7932/8000] D loss: 0.7349, G loss: 6.6632\n",
      "train error: \n",
      " D loss: 0.839757, G loss: 5.860005, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.902878, G loss: 17.504912, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1958, G loss: 3.7282\n",
      "[372/8000] D loss: 0.8654, G loss: 7.4619\n",
      "[732/8000] D loss: 0.7935, G loss: 6.9925\n",
      "[1092/8000] D loss: 0.8826, G loss: 7.6496\n",
      "[1452/8000] D loss: 0.6489, G loss: 4.5761\n",
      "[1812/8000] D loss: 0.5719, G loss: 9.7848\n",
      "[2172/8000] D loss: 1.0867, G loss: 5.1963\n",
      "[2532/8000] D loss: 0.9830, G loss: 7.5460\n",
      "[2892/8000] D loss: 0.6696, G loss: 5.5017\n",
      "[3252/8000] D loss: 0.5851, G loss: 5.2635\n",
      "[3612/8000] D loss: 0.6156, G loss: 7.8857\n",
      "[3972/8000] D loss: 0.8735, G loss: 4.2430\n",
      "[4332/8000] D loss: 0.7911, G loss: 9.6333\n",
      "[4692/8000] D loss: 0.6089, G loss: 16.6771\n",
      "[5052/8000] D loss: 0.7036, G loss: 13.3136\n",
      "[5412/8000] D loss: 0.7984, G loss: 8.9651\n",
      "[5772/8000] D loss: 0.7744, G loss: 5.4437\n",
      "[6132/8000] D loss: 0.7159, G loss: 4.6922\n",
      "[6492/8000] D loss: 0.7344, G loss: 8.4888\n",
      "[6852/8000] D loss: 1.1384, G loss: 1.8055\n",
      "[7212/8000] D loss: 0.8272, G loss: 5.6844\n",
      "[7572/8000] D loss: 1.0502, G loss: 2.0470\n",
      "[7932/8000] D loss: 0.8342, G loss: 5.7504\n",
      "train error: \n",
      " D loss: 0.838748, G loss: 6.052970, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.917049, G loss: 17.914109, D accuracy: 79.1%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8128, G loss: 7.7964\n",
      "[372/8000] D loss: 0.8134, G loss: 2.5927\n",
      "[732/8000] D loss: 0.5741, G loss: 9.5932\n",
      "[1092/8000] D loss: 0.5936, G loss: 5.2172\n",
      "[1452/8000] D loss: 0.8720, G loss: 3.7943\n",
      "[1812/8000] D loss: 0.4986, G loss: 7.8212\n",
      "[2172/8000] D loss: 0.4796, G loss: 8.0253\n",
      "[2532/8000] D loss: 0.7159, G loss: 7.5914\n",
      "[2892/8000] D loss: 0.7325, G loss: 9.6396\n",
      "[3252/8000] D loss: 0.4635, G loss: 12.1955\n",
      "[3612/8000] D loss: 0.8188, G loss: 7.6460\n",
      "[3972/8000] D loss: 0.7053, G loss: 7.2977\n",
      "[4332/8000] D loss: 0.9977, G loss: 2.1745\n",
      "[4692/8000] D loss: 0.8562, G loss: 4.2070\n",
      "[5052/8000] D loss: 0.5880, G loss: 7.3838\n",
      "[5412/8000] D loss: 1.1681, G loss: 2.3156\n",
      "[5772/8000] D loss: 0.8516, G loss: 5.6726\n",
      "[6132/8000] D loss: 0.6691, G loss: 9.1824\n",
      "[6492/8000] D loss: 1.0710, G loss: 2.7372\n",
      "[6852/8000] D loss: 0.7895, G loss: 4.8561\n",
      "[7212/8000] D loss: 0.9213, G loss: 9.0863\n",
      "[7572/8000] D loss: 0.9148, G loss: 2.7753\n",
      "[7932/8000] D loss: 0.9074, G loss: 5.3248\n",
      "train error: \n",
      " D loss: 0.832257, G loss: 5.786813, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 55.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.943408, G loss: 16.976913, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8299, G loss: 2.5741\n",
      "[372/8000] D loss: 1.0009, G loss: 2.7012\n",
      "[732/8000] D loss: 0.7325, G loss: 5.5336\n",
      "[1092/8000] D loss: 0.6906, G loss: 11.2161\n",
      "[1452/8000] D loss: 0.5936, G loss: 7.6276\n",
      "[1812/8000] D loss: 0.7291, G loss: 8.2698\n",
      "[2172/8000] D loss: 0.8795, G loss: 3.9718\n",
      "[2532/8000] D loss: 0.6957, G loss: 6.2048\n",
      "[2892/8000] D loss: 0.7867, G loss: 5.2107\n",
      "[3252/8000] D loss: 1.2160, G loss: 4.7084\n",
      "[3612/8000] D loss: 0.8735, G loss: 7.4871\n",
      "[3972/8000] D loss: 0.9729, G loss: 2.9259\n",
      "[4332/8000] D loss: 0.5732, G loss: 5.3726\n",
      "[4692/8000] D loss: 0.5804, G loss: 7.6983\n",
      "[5052/8000] D loss: 0.7822, G loss: 5.6290\n",
      "[5412/8000] D loss: 0.6012, G loss: 10.5102\n",
      "[5772/8000] D loss: 0.7177, G loss: 10.7049\n",
      "[6132/8000] D loss: 1.0211, G loss: 3.1398\n",
      "[6492/8000] D loss: 0.9205, G loss: 2.6645\n",
      "[6852/8000] D loss: 0.9784, G loss: 6.3372\n",
      "[7212/8000] D loss: 0.7097, G loss: 6.7200\n",
      "[7572/8000] D loss: 0.9425, G loss: 5.2645\n",
      "[7932/8000] D loss: 0.7073, G loss: 7.6593\n",
      "train error: \n",
      " D loss: 0.839726, G loss: 6.196235, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.062588, G loss: 17.940346, D accuracy: 76.9%, cell accuracy: 98.2%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8249, G loss: 4.5979\n",
      "[372/8000] D loss: 0.9905, G loss: 2.8309\n",
      "[732/8000] D loss: 1.0762, G loss: 6.2781\n",
      "[1092/8000] D loss: 0.5601, G loss: 7.9462\n",
      "[1452/8000] D loss: 1.3007, G loss: 1.4252\n",
      "[1812/8000] D loss: 0.8479, G loss: 3.4407\n",
      "[2172/8000] D loss: 0.9399, G loss: 10.3978\n",
      "[2532/8000] D loss: 0.8031, G loss: 3.1645\n",
      "[2892/8000] D loss: 1.1734, G loss: 1.9948\n",
      "[3252/8000] D loss: 0.7578, G loss: 3.1811\n",
      "[3612/8000] D loss: 1.1503, G loss: 3.4159\n",
      "[3972/8000] D loss: 0.5922, G loss: 6.5730\n",
      "[4332/8000] D loss: 0.7259, G loss: 6.2192\n",
      "[4692/8000] D loss: 0.6520, G loss: 4.7124\n",
      "[5052/8000] D loss: 0.7213, G loss: 9.4178\n",
      "[5412/8000] D loss: 0.9441, G loss: 8.3226\n",
      "[5772/8000] D loss: 0.9037, G loss: 4.2241\n",
      "[6132/8000] D loss: 1.0942, G loss: 3.6833\n",
      "[6492/8000] D loss: 1.0663, G loss: 3.7439\n",
      "[6852/8000] D loss: 0.6417, G loss: 8.9945\n",
      "[7212/8000] D loss: 0.9009, G loss: 3.1915\n",
      "[7572/8000] D loss: 1.0867, G loss: 3.3954\n",
      "[7932/8000] D loss: 0.6239, G loss: 6.4231\n",
      "train error: \n",
      " D loss: 0.847671, G loss: 5.278627, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.962229, G loss: 15.920438, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7104, G loss: 7.6461\n",
      "[372/8000] D loss: 1.2504, G loss: 2.0174\n",
      "[732/8000] D loss: 0.4402, G loss: 8.8836\n",
      "[1092/8000] D loss: 0.4741, G loss: 10.9928\n",
      "[1452/8000] D loss: 0.6851, G loss: 5.9303\n",
      "[1812/8000] D loss: 0.8766, G loss: 5.1108\n",
      "[2172/8000] D loss: 0.4939, G loss: 8.0264\n",
      "[2532/8000] D loss: 0.5374, G loss: 6.4538\n",
      "[2892/8000] D loss: 1.2375, G loss: 1.9712\n",
      "[3252/8000] D loss: 0.7089, G loss: 4.0380\n",
      "[3612/8000] D loss: 0.5080, G loss: 11.6436\n",
      "[3972/8000] D loss: 0.3588, G loss: 6.7533\n",
      "[4332/8000] D loss: 1.0161, G loss: 5.3933\n",
      "[4692/8000] D loss: 0.9060, G loss: 3.7237\n",
      "[5052/8000] D loss: 0.7928, G loss: 5.4549\n",
      "[5412/8000] D loss: 1.1110, G loss: 1.8551\n",
      "[5772/8000] D loss: 0.5407, G loss: 16.1661\n",
      "[6132/8000] D loss: 0.8834, G loss: 4.0753\n",
      "[6492/8000] D loss: 0.6589, G loss: 9.3347\n",
      "[6852/8000] D loss: 1.0277, G loss: 4.2697\n",
      "[7212/8000] D loss: 0.9685, G loss: 4.6663\n",
      "[7572/8000] D loss: 1.0212, G loss: 5.5401\n",
      "[7932/8000] D loss: 0.7210, G loss: 9.1339\n",
      "train error: \n",
      " D loss: 0.837094, G loss: 6.679165, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 56.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.043793, G loss: 19.087751, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8879, G loss: 7.9858\n",
      "[372/8000] D loss: 0.5650, G loss: 11.8634\n",
      "[732/8000] D loss: 0.7473, G loss: 5.9215\n",
      "[1092/8000] D loss: 0.9208, G loss: 3.6444\n",
      "[1452/8000] D loss: 1.1386, G loss: 2.7215\n",
      "[1812/8000] D loss: 0.5905, G loss: 7.2953\n",
      "[2172/8000] D loss: 0.9280, G loss: 3.8096\n",
      "[2532/8000] D loss: 0.8401, G loss: 5.1048\n",
      "[2892/8000] D loss: 0.9466, G loss: 3.8437\n",
      "[3252/8000] D loss: 0.9328, G loss: 2.6710\n",
      "[3612/8000] D loss: 1.0371, G loss: 4.2495\n",
      "[3972/8000] D loss: 0.6361, G loss: 6.4993\n",
      "[4332/8000] D loss: 0.7080, G loss: 5.8685\n",
      "[4692/8000] D loss: 0.8236, G loss: 4.5544\n",
      "[5052/8000] D loss: 0.4739, G loss: 12.9535\n",
      "[5412/8000] D loss: 0.4666, G loss: 10.0212\n",
      "[5772/8000] D loss: 0.8193, G loss: 2.8407\n",
      "[6132/8000] D loss: 0.9565, G loss: 2.6584\n",
      "[6492/8000] D loss: 0.4435, G loss: 8.7016\n",
      "[6852/8000] D loss: 0.7379, G loss: 11.0929\n",
      "[7212/8000] D loss: 0.5861, G loss: 7.6477\n",
      "[7572/8000] D loss: 0.7208, G loss: 9.7841\n",
      "[7932/8000] D loss: 0.6295, G loss: 9.9109\n",
      "train error: \n",
      " D loss: 0.833524, G loss: 5.893663, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.907084, G loss: 17.729774, D accuracy: 80.8%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7475, G loss: 8.2787\n",
      "[372/8000] D loss: 0.7475, G loss: 3.4773\n",
      "[732/8000] D loss: 0.9367, G loss: 3.8588\n",
      "[1092/8000] D loss: 0.6843, G loss: 7.1830\n",
      "[1452/8000] D loss: 0.8061, G loss: 3.9979\n",
      "[1812/8000] D loss: 0.4096, G loss: 17.6165\n",
      "[2172/8000] D loss: 0.8522, G loss: 7.3715\n",
      "[2532/8000] D loss: 0.8282, G loss: 4.3511\n",
      "[2892/8000] D loss: 1.1620, G loss: 6.0448\n",
      "[3252/8000] D loss: 0.4981, G loss: 13.6989\n",
      "[3612/8000] D loss: 1.1131, G loss: 3.2802\n",
      "[3972/8000] D loss: 1.0681, G loss: 2.8548\n",
      "[4332/8000] D loss: 0.8694, G loss: 8.7098\n",
      "[4692/8000] D loss: 0.3717, G loss: 10.2198\n",
      "[5052/8000] D loss: 0.5010, G loss: 8.8809\n",
      "[5412/8000] D loss: 0.9726, G loss: 4.1602\n",
      "[5772/8000] D loss: 0.7075, G loss: 7.7007\n",
      "[6132/8000] D loss: 1.3742, G loss: 5.1554\n",
      "[6492/8000] D loss: 0.4628, G loss: 8.3070\n",
      "[6852/8000] D loss: 0.7662, G loss: 7.5829\n",
      "[7212/8000] D loss: 0.8384, G loss: 12.5162\n",
      "[7572/8000] D loss: 0.9387, G loss: 3.6136\n",
      "[7932/8000] D loss: 0.9842, G loss: 4.5841\n",
      "train error: \n",
      " D loss: 0.838484, G loss: 5.525880, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.894046, G loss: 17.431851, D accuracy: 80.6%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0791, G loss: 6.0591\n",
      "[372/8000] D loss: 1.0495, G loss: 4.2751\n",
      "[732/8000] D loss: 0.4932, G loss: 6.4731\n",
      "[1092/8000] D loss: 0.7826, G loss: 5.6273\n",
      "[1452/8000] D loss: 0.8289, G loss: 7.8060\n",
      "[1812/8000] D loss: 0.7200, G loss: 7.9500\n",
      "[2172/8000] D loss: 0.6416, G loss: 9.2322\n",
      "[2532/8000] D loss: 0.6446, G loss: 7.3634\n",
      "[2892/8000] D loss: 0.8346, G loss: 8.5367\n",
      "[3252/8000] D loss: 0.5536, G loss: 8.2904\n",
      "[3612/8000] D loss: 0.5374, G loss: 9.7724\n",
      "[3972/8000] D loss: 0.5084, G loss: 13.0896\n",
      "[4332/8000] D loss: 0.8297, G loss: 2.7629\n",
      "[4692/8000] D loss: 0.9038, G loss: 4.4283\n",
      "[5052/8000] D loss: 0.6409, G loss: 7.4918\n",
      "[5412/8000] D loss: 0.8669, G loss: 10.0240\n",
      "[5772/8000] D loss: 0.7976, G loss: 8.2955\n",
      "[6132/8000] D loss: 0.9289, G loss: 7.9343\n",
      "[6492/8000] D loss: 0.7763, G loss: 7.1322\n",
      "[6852/8000] D loss: 0.7579, G loss: 5.1707\n",
      "[7212/8000] D loss: 0.9032, G loss: 4.3938\n",
      "[7572/8000] D loss: 0.8381, G loss: 10.2216\n",
      "[7932/8000] D loss: 0.9276, G loss: 10.5036\n",
      "train error: \n",
      " D loss: 0.816838, G loss: 6.981341, D accuracy: 73.7%, cell accuracy: 98.7%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.909631, G loss: 19.929591, D accuracy: 80.8%, cell accuracy: 98.2%, board accuracy: 25.1% \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7016, G loss: 6.9016\n",
      "[372/8000] D loss: 1.0323, G loss: 4.3456\n",
      "[732/8000] D loss: 0.9148, G loss: 5.5591\n",
      "[1092/8000] D loss: 0.6306, G loss: 4.6850\n",
      "[1452/8000] D loss: 1.2836, G loss: 0.6658\n",
      "[1812/8000] D loss: 0.9765, G loss: 3.0636\n",
      "[2172/8000] D loss: 0.9758, G loss: 2.6698\n",
      "[2532/8000] D loss: 0.9481, G loss: 3.5963\n",
      "[2892/8000] D loss: 0.7472, G loss: 2.9844\n",
      "[3252/8000] D loss: 0.8234, G loss: 6.5389\n",
      "[3612/8000] D loss: 1.1786, G loss: 3.5111\n",
      "[3972/8000] D loss: 0.7238, G loss: 7.9962\n",
      "[4332/8000] D loss: 0.9611, G loss: 3.6884\n",
      "[4692/8000] D loss: 0.7202, G loss: 7.2598\n",
      "[5052/8000] D loss: 0.7472, G loss: 4.0549\n",
      "[5412/8000] D loss: 1.1812, G loss: 2.1525\n",
      "[5772/8000] D loss: 0.7233, G loss: 4.1503\n",
      "[6132/8000] D loss: 0.9342, G loss: 7.7178\n",
      "[6492/8000] D loss: 0.9251, G loss: 7.7802\n",
      "[6852/8000] D loss: 0.2912, G loss: 11.3142\n",
      "[7212/8000] D loss: 0.7185, G loss: 8.6195\n",
      "[7572/8000] D loss: 1.1935, G loss: 2.0238\n",
      "[7932/8000] D loss: 0.7976, G loss: 5.4695\n",
      "train error: \n",
      " D loss: 0.833995, G loss: 6.639190, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.013209, G loss: 18.241341, D accuracy: 77.4%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7924, G loss: 2.8789\n",
      "[372/8000] D loss: 0.5728, G loss: 7.0269\n",
      "[732/8000] D loss: 0.6152, G loss: 8.0586\n",
      "[1092/8000] D loss: 0.9273, G loss: 7.9029\n",
      "[1452/8000] D loss: 0.8054, G loss: 6.1414\n",
      "[1812/8000] D loss: 0.8283, G loss: 13.3024\n",
      "[2172/8000] D loss: 0.7253, G loss: 5.1149\n",
      "[2532/8000] D loss: 0.9132, G loss: 5.2401\n",
      "[2892/8000] D loss: 0.4499, G loss: 9.8858\n",
      "[3252/8000] D loss: 0.9255, G loss: 5.6718\n",
      "[3612/8000] D loss: 0.7762, G loss: 6.4155\n",
      "[3972/8000] D loss: 0.3878, G loss: 7.9563\n",
      "[4332/8000] D loss: 1.1425, G loss: 2.3431\n",
      "[4692/8000] D loss: 0.7231, G loss: 6.5182\n",
      "[5052/8000] D loss: 0.9256, G loss: 6.3826\n",
      "[5412/8000] D loss: 0.6253, G loss: 6.5658\n",
      "[5772/8000] D loss: 1.1314, G loss: 2.9821\n",
      "[6132/8000] D loss: 0.8839, G loss: 9.7760\n",
      "[6492/8000] D loss: 0.7386, G loss: 4.6066\n",
      "[6852/8000] D loss: 0.8899, G loss: 9.7134\n",
      "[7212/8000] D loss: 0.9346, G loss: 6.6675\n",
      "[7572/8000] D loss: 0.8505, G loss: 2.7066\n",
      "[7932/8000] D loss: 1.0655, G loss: 1.4996\n",
      "train error: \n",
      " D loss: 0.835709, G loss: 5.669561, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.926538, G loss: 17.099477, D accuracy: 80.0%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5724, G loss: 9.3275\n",
      "[372/8000] D loss: 1.1703, G loss: 0.9949\n",
      "[732/8000] D loss: 0.7188, G loss: 11.8112\n",
      "[1092/8000] D loss: 0.6881, G loss: 7.6787\n",
      "[1452/8000] D loss: 0.8096, G loss: 6.0338\n",
      "[1812/8000] D loss: 0.8482, G loss: 4.6803\n",
      "[2172/8000] D loss: 0.5964, G loss: 9.8549\n",
      "[2532/8000] D loss: 0.6911, G loss: 3.6530\n",
      "[2892/8000] D loss: 0.7786, G loss: 9.2694\n",
      "[3252/8000] D loss: 0.6066, G loss: 8.3291\n",
      "[3612/8000] D loss: 0.7565, G loss: 7.2792\n",
      "[3972/8000] D loss: 0.7494, G loss: 4.5566\n",
      "[4332/8000] D loss: 0.7783, G loss: 3.3948\n",
      "[4692/8000] D loss: 1.2875, G loss: 1.1256\n",
      "[5052/8000] D loss: 0.6130, G loss: 10.5865\n",
      "[5412/8000] D loss: 0.7284, G loss: 5.9245\n",
      "[5772/8000] D loss: 0.6146, G loss: 10.8638\n",
      "[6132/8000] D loss: 0.6730, G loss: 11.0528\n",
      "[6492/8000] D loss: 0.5389, G loss: 10.8991\n",
      "[6852/8000] D loss: 0.9467, G loss: 6.4196\n",
      "[7212/8000] D loss: 1.0751, G loss: 1.9438\n",
      "[7572/8000] D loss: 0.9346, G loss: 4.0916\n",
      "[7932/8000] D loss: 1.0706, G loss: 3.7414\n",
      "train error: \n",
      " D loss: 0.832186, G loss: 5.893797, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.909046, G loss: 17.045540, D accuracy: 79.8%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7816, G loss: 4.0580\n",
      "[372/8000] D loss: 0.7720, G loss: 9.0286\n",
      "[732/8000] D loss: 1.1295, G loss: 5.3222\n",
      "[1092/8000] D loss: 0.8955, G loss: 3.4960\n",
      "[1452/8000] D loss: 0.8622, G loss: 5.1021\n",
      "[1812/8000] D loss: 0.6824, G loss: 4.4921\n",
      "[2172/8000] D loss: 0.8968, G loss: 4.8263\n",
      "[2532/8000] D loss: 0.4242, G loss: 10.7133\n",
      "[2892/8000] D loss: 0.7447, G loss: 5.4234\n",
      "[3252/8000] D loss: 0.4832, G loss: 16.8804\n",
      "[3612/8000] D loss: 0.6850, G loss: 7.3734\n",
      "[3972/8000] D loss: 0.4879, G loss: 8.4683\n",
      "[4332/8000] D loss: 1.1848, G loss: 1.9199\n",
      "[4692/8000] D loss: 0.4923, G loss: 12.2710\n",
      "[5052/8000] D loss: 0.7544, G loss: 7.1826\n",
      "[5412/8000] D loss: 0.7131, G loss: 6.0583\n",
      "[5772/8000] D loss: 0.4799, G loss: 7.8725\n",
      "[6132/8000] D loss: 0.9861, G loss: 2.9228\n",
      "[6492/8000] D loss: 0.7030, G loss: 10.7630\n",
      "[6852/8000] D loss: 0.5795, G loss: 7.0930\n",
      "[7212/8000] D loss: 0.8017, G loss: 4.9702\n",
      "[7572/8000] D loss: 0.8644, G loss: 7.0896\n",
      "[7932/8000] D loss: 0.8780, G loss: 4.4138\n",
      "train error: \n",
      " D loss: 0.844154, G loss: 5.814439, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.835254, G loss: 16.817692, D accuracy: 81.9%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8750, G loss: 5.2984\n",
      "[372/8000] D loss: 0.4883, G loss: 14.8326\n",
      "[732/8000] D loss: 0.9523, G loss: 4.3975\n",
      "[1092/8000] D loss: 0.7168, G loss: 5.9008\n",
      "[1452/8000] D loss: 0.9469, G loss: 3.2966\n",
      "[1812/8000] D loss: 0.8211, G loss: 6.4389\n",
      "[2172/8000] D loss: 0.8288, G loss: 6.4955\n",
      "[2532/8000] D loss: 0.8791, G loss: 8.7353\n",
      "[2892/8000] D loss: 0.6818, G loss: 6.0104\n",
      "[3252/8000] D loss: 0.6245, G loss: 7.3262\n",
      "[3612/8000] D loss: 0.6673, G loss: 8.1582\n",
      "[3972/8000] D loss: 0.6637, G loss: 7.3212\n",
      "[4332/8000] D loss: 0.3443, G loss: 5.9261\n",
      "[4692/8000] D loss: 0.6556, G loss: 10.7518\n",
      "[5052/8000] D loss: 0.7588, G loss: 3.7023\n",
      "[5412/8000] D loss: 0.8358, G loss: 4.2817\n",
      "[5772/8000] D loss: 1.0273, G loss: 4.0843\n",
      "[6132/8000] D loss: 0.7474, G loss: 5.9118\n",
      "[6492/8000] D loss: 0.9125, G loss: 4.6284\n",
      "[6852/8000] D loss: 0.9852, G loss: 3.7212\n",
      "[7212/8000] D loss: 0.5279, G loss: 9.1631\n",
      "[7572/8000] D loss: 0.6200, G loss: 9.7257\n",
      "[7932/8000] D loss: 1.0648, G loss: 2.7516\n",
      "train error: \n",
      " D loss: 0.838589, G loss: 6.187996, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.921199, G loss: 17.453665, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0441, G loss: 3.7527\n",
      "[372/8000] D loss: 0.6644, G loss: 7.6878\n",
      "[732/8000] D loss: 1.1263, G loss: 3.8435\n",
      "[1092/8000] D loss: 1.0123, G loss: 2.6178\n",
      "[1452/8000] D loss: 1.1477, G loss: 3.8615\n",
      "[1812/8000] D loss: 0.5517, G loss: 3.9450\n",
      "[2172/8000] D loss: 0.6966, G loss: 7.1738\n",
      "[2532/8000] D loss: 0.5162, G loss: 13.8522\n",
      "[2892/8000] D loss: 0.5602, G loss: 8.7025\n",
      "[3252/8000] D loss: 0.9068, G loss: 4.8396\n",
      "[3612/8000] D loss: 0.8669, G loss: 6.2717\n",
      "[3972/8000] D loss: 0.6586, G loss: 7.0744\n",
      "[4332/8000] D loss: 1.1778, G loss: 1.0690\n",
      "[4692/8000] D loss: 0.8539, G loss: 5.7475\n",
      "[5052/8000] D loss: 0.9836, G loss: 3.1385\n",
      "[5412/8000] D loss: 0.9176, G loss: 5.1540\n",
      "[5772/8000] D loss: 1.2250, G loss: 2.4066\n",
      "[6132/8000] D loss: 0.8340, G loss: 6.4974\n",
      "[6492/8000] D loss: 1.0348, G loss: 4.3333\n",
      "[6852/8000] D loss: 0.7614, G loss: 4.9483\n",
      "[7212/8000] D loss: 1.0773, G loss: 1.8378\n",
      "[7572/8000] D loss: 0.8100, G loss: 4.8299\n",
      "[7932/8000] D loss: 0.6685, G loss: 3.2510\n",
      "train error: \n",
      " D loss: 0.861842, G loss: 4.168288, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.908956, G loss: 13.750382, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7336, G loss: 4.2509\n",
      "[372/8000] D loss: 0.9763, G loss: 3.7920\n",
      "[732/8000] D loss: 0.7686, G loss: 3.7800\n",
      "[1092/8000] D loss: 0.9121, G loss: 4.3974\n",
      "[1452/8000] D loss: 1.0558, G loss: 1.7563\n",
      "[1812/8000] D loss: 0.7886, G loss: 5.6679\n",
      "[2172/8000] D loss: 0.8331, G loss: 5.5251\n",
      "[2532/8000] D loss: 0.9190, G loss: 4.2598\n",
      "[2892/8000] D loss: 0.6985, G loss: 6.3848\n",
      "[3252/8000] D loss: 1.1432, G loss: 3.5321\n",
      "[3612/8000] D loss: 0.9014, G loss: 1.7552\n",
      "[3972/8000] D loss: 0.9796, G loss: 10.3847\n",
      "[4332/8000] D loss: 0.9535, G loss: 3.2912\n",
      "[4692/8000] D loss: 0.9315, G loss: 9.9673\n",
      "[5052/8000] D loss: 0.9229, G loss: 2.9319\n",
      "[5412/8000] D loss: 0.6485, G loss: 11.0471\n",
      "[5772/8000] D loss: 0.4158, G loss: 12.4006\n",
      "[6132/8000] D loss: 0.8674, G loss: 8.4664\n",
      "[6492/8000] D loss: 1.0374, G loss: 2.7376\n",
      "[6852/8000] D loss: 1.1387, G loss: 2.7879\n",
      "[7212/8000] D loss: 0.4502, G loss: 8.3645\n",
      "[7572/8000] D loss: 1.0564, G loss: 2.1865\n",
      "[7932/8000] D loss: 0.9268, G loss: 4.6261\n",
      "train error: \n",
      " D loss: 0.841328, G loss: 5.369499, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.936025, G loss: 16.003967, D accuracy: 79.4%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7202, G loss: 7.7017\n",
      "[372/8000] D loss: 0.5614, G loss: 9.0748\n",
      "[732/8000] D loss: 0.9413, G loss: 4.0092\n",
      "[1092/8000] D loss: 0.8578, G loss: 6.5949\n",
      "[1452/8000] D loss: 0.7225, G loss: 5.3417\n",
      "[1812/8000] D loss: 1.0707, G loss: 4.2767\n",
      "[2172/8000] D loss: 0.5603, G loss: 12.8503\n",
      "[2532/8000] D loss: 0.9028, G loss: 2.5363\n",
      "[2892/8000] D loss: 0.9308, G loss: 2.3716\n",
      "[3252/8000] D loss: 0.5954, G loss: 15.4287\n",
      "[3612/8000] D loss: 0.5765, G loss: 10.5238\n",
      "[3972/8000] D loss: 1.0803, G loss: 4.0139\n",
      "[4332/8000] D loss: 0.9364, G loss: 4.7471\n",
      "[4692/8000] D loss: 0.8563, G loss: 5.8381\n",
      "[5052/8000] D loss: 0.7666, G loss: 4.9751\n",
      "[5412/8000] D loss: 0.4647, G loss: 5.2609\n",
      "[5772/8000] D loss: 0.7152, G loss: 11.2053\n",
      "[6132/8000] D loss: 1.0452, G loss: 3.8668\n",
      "[6492/8000] D loss: 0.7100, G loss: 4.1428\n",
      "[6852/8000] D loss: 0.7460, G loss: 8.1677\n",
      "[7212/8000] D loss: 0.5136, G loss: 6.9593\n",
      "[7572/8000] D loss: 0.8559, G loss: 5.4159\n",
      "[7932/8000] D loss: 0.4603, G loss: 7.2802\n",
      "train error: \n",
      " D loss: 0.849841, G loss: 5.530290, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.984524, G loss: 16.301026, D accuracy: 78.2%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7407, G loss: 5.0905\n",
      "[372/8000] D loss: 0.7806, G loss: 5.4076\n",
      "[732/8000] D loss: 0.7688, G loss: 10.5859\n",
      "[1092/8000] D loss: 0.4787, G loss: 10.4022\n",
      "[1452/8000] D loss: 0.2743, G loss: 15.7303\n",
      "[1812/8000] D loss: 1.2474, G loss: 3.8676\n",
      "[2172/8000] D loss: 0.7129, G loss: 7.5056\n",
      "[2532/8000] D loss: 0.8949, G loss: 6.3973\n",
      "[2892/8000] D loss: 0.8004, G loss: 3.6486\n",
      "[3252/8000] D loss: 1.1784, G loss: 3.9004\n",
      "[3612/8000] D loss: 0.9947, G loss: 3.6422\n",
      "[3972/8000] D loss: 0.6252, G loss: 12.9152\n",
      "[4332/8000] D loss: 0.8401, G loss: 4.5852\n",
      "[4692/8000] D loss: 0.8390, G loss: 6.0422\n",
      "[5052/8000] D loss: 1.0340, G loss: 8.6496\n",
      "[5412/8000] D loss: 0.8645, G loss: 4.0298\n",
      "[5772/8000] D loss: 0.7485, G loss: 3.4035\n",
      "[6132/8000] D loss: 1.0874, G loss: 2.4870\n",
      "[6492/8000] D loss: 0.9533, G loss: 4.0214\n",
      "[6852/8000] D loss: 0.8348, G loss: 8.0765\n",
      "[7212/8000] D loss: 0.6001, G loss: 7.2786\n",
      "[7572/8000] D loss: 0.9758, G loss: 5.8369\n",
      "[7932/8000] D loss: 0.8763, G loss: 5.7792\n",
      "train error: \n",
      " D loss: 0.858377, G loss: 5.065589, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.040623, G loss: 14.863274, D accuracy: 76.4%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8250, G loss: 5.2940\n",
      "[372/8000] D loss: 1.0979, G loss: 3.2741\n",
      "[732/8000] D loss: 1.0056, G loss: 1.8494\n",
      "[1092/8000] D loss: 0.6370, G loss: 4.9677\n",
      "[1452/8000] D loss: 0.9242, G loss: 6.0629\n",
      "[1812/8000] D loss: 0.6243, G loss: 8.6366\n",
      "[2172/8000] D loss: 0.6215, G loss: 6.2329\n",
      "[2532/8000] D loss: 0.5173, G loss: 5.3085\n",
      "[2892/8000] D loss: 0.6977, G loss: 13.8726\n",
      "[3252/8000] D loss: 0.6967, G loss: 7.9839\n",
      "[3612/8000] D loss: 0.6262, G loss: 6.5575\n",
      "[3972/8000] D loss: 1.0926, G loss: 1.8002\n",
      "[4332/8000] D loss: 0.8253, G loss: 11.5716\n",
      "[4692/8000] D loss: 1.1215, G loss: 2.6521\n",
      "[5052/8000] D loss: 1.0900, G loss: 4.6934\n",
      "[5412/8000] D loss: 0.6265, G loss: 14.4269\n",
      "[5772/8000] D loss: 0.6497, G loss: 4.8542\n",
      "[6132/8000] D loss: 0.7223, G loss: 4.7679\n",
      "[6492/8000] D loss: 0.8800, G loss: 4.1494\n",
      "[6852/8000] D loss: 0.2390, G loss: 9.3947\n",
      "[7212/8000] D loss: 0.8341, G loss: 8.2767\n",
      "[7572/8000] D loss: 0.7013, G loss: 6.3178\n",
      "[7932/8000] D loss: 0.5151, G loss: 10.4539\n",
      "train error: \n",
      " D loss: 0.849511, G loss: 5.872823, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 56.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.881644, G loss: 17.497551, D accuracy: 80.8%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1163, G loss: 1.8490\n",
      "[372/8000] D loss: 0.9416, G loss: 4.3391\n",
      "[732/8000] D loss: 0.8918, G loss: 7.3353\n",
      "[1092/8000] D loss: 1.0781, G loss: 2.3532\n",
      "[1452/8000] D loss: 0.9236, G loss: 3.0049\n",
      "[1812/8000] D loss: 0.7256, G loss: 6.6943\n",
      "[2172/8000] D loss: 0.7828, G loss: 3.2777\n",
      "[2532/8000] D loss: 0.7368, G loss: 5.5527\n",
      "[2892/8000] D loss: 0.9975, G loss: 10.7203\n",
      "[3252/8000] D loss: 0.6539, G loss: 7.7160\n",
      "[3612/8000] D loss: 1.0191, G loss: 3.1688\n",
      "[3972/8000] D loss: 0.8468, G loss: 8.2177\n",
      "[4332/8000] D loss: 0.9506, G loss: 3.5730\n",
      "[4692/8000] D loss: 0.6942, G loss: 4.8736\n",
      "[5052/8000] D loss: 0.7431, G loss: 8.7377\n",
      "[5412/8000] D loss: 0.7911, G loss: 11.0757\n",
      "[5772/8000] D loss: 0.9427, G loss: 3.9523\n",
      "[6132/8000] D loss: 1.1361, G loss: 3.8411\n",
      "[6492/8000] D loss: 0.7071, G loss: 10.8679\n",
      "[6852/8000] D loss: 1.0104, G loss: 4.1858\n",
      "[7212/8000] D loss: 0.8595, G loss: 7.2991\n",
      "[7572/8000] D loss: 0.6835, G loss: 3.9656\n",
      "[7932/8000] D loss: 1.1350, G loss: 1.3568\n",
      "train error: \n",
      " D loss: 0.843731, G loss: 6.339905, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.910625, G loss: 18.008381, D accuracy: 80.6%, cell accuracy: 98.2%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7007, G loss: 8.8366\n",
      "[372/8000] D loss: 0.7220, G loss: 8.0434\n",
      "[732/8000] D loss: 0.4581, G loss: 21.4583\n",
      "[1092/8000] D loss: 1.2344, G loss: 4.5597\n",
      "[1452/8000] D loss: 0.4989, G loss: 7.3834\n",
      "[1812/8000] D loss: 0.6390, G loss: 8.6841\n",
      "[2172/8000] D loss: 0.9890, G loss: 3.5760\n",
      "[2532/8000] D loss: 0.9318, G loss: 3.4303\n",
      "[2892/8000] D loss: 0.8849, G loss: 7.8449\n",
      "[3252/8000] D loss: 0.9026, G loss: 6.9837\n",
      "[3612/8000] D loss: 0.3616, G loss: 7.4732\n",
      "[3972/8000] D loss: 0.8601, G loss: 3.8311\n",
      "[4332/8000] D loss: 1.0374, G loss: 3.2749\n",
      "[4692/8000] D loss: 0.9455, G loss: 3.2290\n",
      "[5052/8000] D loss: 0.9453, G loss: 9.0407\n",
      "[5412/8000] D loss: 0.6260, G loss: 8.8412\n",
      "[5772/8000] D loss: 0.7970, G loss: 10.4302\n",
      "[6132/8000] D loss: 1.1139, G loss: 4.9740\n",
      "[6492/8000] D loss: 0.8572, G loss: 3.6830\n",
      "[6852/8000] D loss: 1.0916, G loss: 1.9352\n",
      "[7212/8000] D loss: 0.8366, G loss: 4.8056\n",
      "[7572/8000] D loss: 0.5184, G loss: 8.2440\n",
      "[7932/8000] D loss: 1.1255, G loss: 1.6139\n",
      "train error: \n",
      " D loss: 0.844969, G loss: 7.241849, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.102293, G loss: 19.668625, D accuracy: 75.8%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8031, G loss: 9.5303\n",
      "[372/8000] D loss: 0.9311, G loss: 3.9619\n",
      "[732/8000] D loss: 0.9101, G loss: 10.0073\n",
      "[1092/8000] D loss: 1.1558, G loss: 5.4166\n",
      "[1452/8000] D loss: 0.7869, G loss: 3.4716\n",
      "[1812/8000] D loss: 0.7907, G loss: 5.5422\n",
      "[2172/8000] D loss: 0.7019, G loss: 8.2677\n",
      "[2532/8000] D loss: 0.5877, G loss: 9.8989\n",
      "[2892/8000] D loss: 0.8133, G loss: 3.9837\n",
      "[3252/8000] D loss: 0.9180, G loss: 3.1389\n",
      "[3612/8000] D loss: 0.6110, G loss: 4.5650\n",
      "[3972/8000] D loss: 1.1901, G loss: 5.3582\n",
      "[4332/8000] D loss: 0.8212, G loss: 5.0070\n",
      "[4692/8000] D loss: 0.8029, G loss: 4.8744\n",
      "[5052/8000] D loss: 0.8674, G loss: 4.9759\n",
      "[5412/8000] D loss: 0.7145, G loss: 9.4357\n",
      "[5772/8000] D loss: 0.3783, G loss: 11.3960\n",
      "[6132/8000] D loss: 0.7829, G loss: 7.2159\n",
      "[6492/8000] D loss: 0.6312, G loss: 4.9701\n",
      "[6852/8000] D loss: 0.8068, G loss: 12.0187\n",
      "[7212/8000] D loss: 0.9520, G loss: 6.5572\n",
      "[7572/8000] D loss: 0.5407, G loss: 9.4701\n",
      "[7932/8000] D loss: 0.5632, G loss: 5.7864\n",
      "train error: \n",
      " D loss: 0.844199, G loss: 5.244886, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.892378, G loss: 16.619647, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8909, G loss: 4.4640\n",
      "[372/8000] D loss: 0.8887, G loss: 3.6199\n",
      "[732/8000] D loss: 0.6636, G loss: 8.8207\n",
      "[1092/8000] D loss: 0.7440, G loss: 6.4352\n",
      "[1452/8000] D loss: 0.7735, G loss: 7.2032\n",
      "[1812/8000] D loss: 1.0910, G loss: 2.3570\n",
      "[2172/8000] D loss: 0.7871, G loss: 6.3740\n",
      "[2532/8000] D loss: 0.7956, G loss: 6.2475\n",
      "[2892/8000] D loss: 0.6652, G loss: 8.8461\n",
      "[3252/8000] D loss: 0.7612, G loss: 8.4636\n",
      "[3612/8000] D loss: 0.9183, G loss: 5.6492\n",
      "[3972/8000] D loss: 1.1127, G loss: 3.4090\n",
      "[4332/8000] D loss: 0.7758, G loss: 5.0875\n",
      "[4692/8000] D loss: 0.8860, G loss: 4.2773\n",
      "[5052/8000] D loss: 0.9386, G loss: 5.0493\n",
      "[5412/8000] D loss: 0.3644, G loss: 5.6764\n",
      "[5772/8000] D loss: 0.4887, G loss: 5.7746\n",
      "[6132/8000] D loss: 0.7219, G loss: 9.1772\n",
      "[6492/8000] D loss: 0.7825, G loss: 5.9275\n",
      "[6852/8000] D loss: 0.6426, G loss: 5.5550\n",
      "[7212/8000] D loss: 0.7855, G loss: 3.4884\n",
      "[7572/8000] D loss: 0.8853, G loss: 2.9662\n",
      "[7932/8000] D loss: 1.0824, G loss: 3.7022\n",
      "train error: \n",
      " D loss: 0.832212, G loss: 6.157722, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.013589, G loss: 17.491687, D accuracy: 76.7%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5723, G loss: 9.4590\n",
      "[372/8000] D loss: 0.7297, G loss: 7.3187\n",
      "[732/8000] D loss: 0.8911, G loss: 4.3302\n",
      "[1092/8000] D loss: 0.6460, G loss: 6.2221\n",
      "[1452/8000] D loss: 0.5600, G loss: 9.5464\n",
      "[1812/8000] D loss: 0.6607, G loss: 10.7021\n",
      "[2172/8000] D loss: 0.7932, G loss: 8.1675\n",
      "[2532/8000] D loss: 0.6074, G loss: 11.1600\n",
      "[2892/8000] D loss: 1.0885, G loss: 2.7579\n",
      "[3252/8000] D loss: 0.7019, G loss: 7.8337\n",
      "[3612/8000] D loss: 0.9223, G loss: 5.8486\n",
      "[3972/8000] D loss: 0.2476, G loss: 11.2178\n",
      "[4332/8000] D loss: 0.9130, G loss: 6.6817\n",
      "[4692/8000] D loss: 0.6647, G loss: 3.3123\n",
      "[5052/8000] D loss: 1.1452, G loss: 2.6008\n",
      "[5412/8000] D loss: 0.9366, G loss: 3.0175\n",
      "[5772/8000] D loss: 0.7990, G loss: 6.3613\n",
      "[6132/8000] D loss: 1.0245, G loss: 2.1744\n",
      "[6492/8000] D loss: 0.9378, G loss: 3.5846\n",
      "[6852/8000] D loss: 0.6558, G loss: 8.8563\n",
      "[7212/8000] D loss: 0.8606, G loss: 2.8709\n",
      "[7572/8000] D loss: 0.8663, G loss: 2.3568\n",
      "[7932/8000] D loss: 0.5113, G loss: 12.8257\n",
      "train error: \n",
      " D loss: 0.855219, G loss: 5.485913, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.911387, G loss: 16.798146, D accuracy: 80.7%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0463, G loss: 3.8451\n",
      "[372/8000] D loss: 0.6714, G loss: 6.1633\n",
      "[732/8000] D loss: 0.9281, G loss: 5.4648\n",
      "[1092/8000] D loss: 0.9519, G loss: 2.2352\n",
      "[1452/8000] D loss: 0.8422, G loss: 10.1666\n",
      "[1812/8000] D loss: 0.8080, G loss: 4.0265\n",
      "[2172/8000] D loss: 0.9305, G loss: 5.6390\n",
      "[2532/8000] D loss: 0.9731, G loss: 6.3125\n",
      "[2892/8000] D loss: 0.8105, G loss: 4.1807\n",
      "[3252/8000] D loss: 0.7417, G loss: 3.7383\n",
      "[3612/8000] D loss: 0.8701, G loss: 8.3907\n",
      "[3972/8000] D loss: 0.8378, G loss: 4.8663\n",
      "[4332/8000] D loss: 0.6232, G loss: 5.1001\n",
      "[4692/8000] D loss: 0.6482, G loss: 7.1778\n",
      "[5052/8000] D loss: 0.9589, G loss: 6.1920\n",
      "[5412/8000] D loss: 1.0399, G loss: 4.0324\n",
      "[5772/8000] D loss: 0.9437, G loss: 6.9419\n",
      "[6132/8000] D loss: 0.8646, G loss: 4.1787\n",
      "[6492/8000] D loss: 0.6376, G loss: 6.1430\n",
      "[6852/8000] D loss: 0.7113, G loss: 6.0519\n",
      "[7212/8000] D loss: 0.5242, G loss: 7.3370\n",
      "[7572/8000] D loss: 0.7443, G loss: 8.3627\n",
      "[7932/8000] D loss: 1.0227, G loss: 3.9196\n",
      "train error: \n",
      " D loss: 0.842977, G loss: 6.140383, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.921209, G loss: 17.625199, D accuracy: 81.0%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7174, G loss: 5.7741\n",
      "[372/8000] D loss: 0.6372, G loss: 7.2149\n",
      "[732/8000] D loss: 0.7268, G loss: 8.9050\n",
      "[1092/8000] D loss: 0.8062, G loss: 4.1067\n",
      "[1452/8000] D loss: 1.0178, G loss: 8.7765\n",
      "[1812/8000] D loss: 0.5696, G loss: 8.2229\n",
      "[2172/8000] D loss: 0.4927, G loss: 6.3232\n",
      "[2532/8000] D loss: 0.7015, G loss: 8.1243\n",
      "[2892/8000] D loss: 0.6148, G loss: 8.9294\n",
      "[3252/8000] D loss: 0.8984, G loss: 6.9468\n",
      "[3612/8000] D loss: 0.9652, G loss: 4.5632\n",
      "[3972/8000] D loss: 0.9032, G loss: 2.2551\n",
      "[4332/8000] D loss: 1.1387, G loss: 3.5119\n",
      "[4692/8000] D loss: 0.9647, G loss: 4.3639\n",
      "[5052/8000] D loss: 0.6228, G loss: 4.6752\n",
      "[5412/8000] D loss: 0.3670, G loss: 9.0596\n",
      "[5772/8000] D loss: 0.8145, G loss: 6.9333\n",
      "[6132/8000] D loss: 1.1265, G loss: 2.3279\n",
      "[6492/8000] D loss: 0.6569, G loss: 12.7133\n",
      "[6852/8000] D loss: 0.6963, G loss: 3.5821\n",
      "[7212/8000] D loss: 0.6370, G loss: 5.7025\n",
      "[7572/8000] D loss: 0.7239, G loss: 7.3216\n",
      "[7932/8000] D loss: 0.6917, G loss: 6.0009\n",
      "train error: \n",
      " D loss: 0.824842, G loss: 6.118687, D accuracy: 73.3%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.965975, G loss: 18.292412, D accuracy: 79.1%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8074, G loss: 7.7239\n",
      "[372/8000] D loss: 0.9228, G loss: 3.5240\n",
      "[732/8000] D loss: 0.9122, G loss: 2.9450\n",
      "[1092/8000] D loss: 0.8643, G loss: 9.7354\n",
      "[1452/8000] D loss: 1.1933, G loss: 4.0288\n",
      "[1812/8000] D loss: 1.0869, G loss: 3.6959\n",
      "[2172/8000] D loss: 1.0386, G loss: 2.6870\n",
      "[2532/8000] D loss: 0.9737, G loss: 7.0046\n",
      "[2892/8000] D loss: 0.6169, G loss: 9.2573\n",
      "[3252/8000] D loss: 0.4783, G loss: 16.7152\n",
      "[3612/8000] D loss: 0.7968, G loss: 10.7281\n",
      "[3972/8000] D loss: 1.1826, G loss: 2.5641\n",
      "[4332/8000] D loss: 0.6536, G loss: 7.6100\n",
      "[4692/8000] D loss: 0.8798, G loss: 11.0020\n",
      "[5052/8000] D loss: 0.8959, G loss: 10.4967\n",
      "[5412/8000] D loss: 0.8473, G loss: 4.3016\n",
      "[5772/8000] D loss: 0.7966, G loss: 3.8352\n",
      "[6132/8000] D loss: 0.7216, G loss: 8.8269\n",
      "[6492/8000] D loss: 0.6650, G loss: 3.7457\n",
      "[6852/8000] D loss: 0.5445, G loss: 5.6215\n",
      "[7212/8000] D loss: 0.7210, G loss: 3.8764\n",
      "[7572/8000] D loss: 0.7159, G loss: 5.3957\n",
      "[7932/8000] D loss: 0.4703, G loss: 5.9198\n",
      "train error: \n",
      " D loss: 0.851932, G loss: 6.359557, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.000545, G loss: 18.121004, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7658, G loss: 4.4693\n",
      "[372/8000] D loss: 0.6059, G loss: 7.1335\n",
      "[732/8000] D loss: 0.9604, G loss: 6.3106\n",
      "[1092/8000] D loss: 0.9382, G loss: 1.7898\n",
      "[1452/8000] D loss: 0.6829, G loss: 9.6947\n",
      "[1812/8000] D loss: 0.7035, G loss: 6.3061\n",
      "[2172/8000] D loss: 0.6716, G loss: 5.3134\n",
      "[2532/8000] D loss: 0.8626, G loss: 5.8906\n",
      "[2892/8000] D loss: 0.7046, G loss: 6.8530\n",
      "[3252/8000] D loss: 0.7084, G loss: 5.3621\n",
      "[3612/8000] D loss: 0.9593, G loss: 4.7482\n",
      "[3972/8000] D loss: 0.8228, G loss: 5.9847\n",
      "[4332/8000] D loss: 0.6055, G loss: 7.0609\n",
      "[4692/8000] D loss: 0.4868, G loss: 8.3413\n",
      "[5052/8000] D loss: 0.7095, G loss: 4.7856\n",
      "[5412/8000] D loss: 0.6825, G loss: 5.2398\n",
      "[5772/8000] D loss: 1.1098, G loss: 2.6333\n",
      "[6132/8000] D loss: 0.8225, G loss: 3.7722\n",
      "[6492/8000] D loss: 0.9397, G loss: 4.2291\n",
      "[6852/8000] D loss: 0.8523, G loss: 5.2830\n",
      "[7212/8000] D loss: 1.2067, G loss: 6.1941\n",
      "[7572/8000] D loss: 0.8697, G loss: 7.3567\n",
      "[7932/8000] D loss: 0.8119, G loss: 7.3488\n",
      "train error: \n",
      " D loss: 0.848325, G loss: 5.004027, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.927279, G loss: 16.498579, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5230, G loss: 9.0067\n",
      "[372/8000] D loss: 0.6949, G loss: 8.1120\n",
      "[732/8000] D loss: 0.8247, G loss: 6.9337\n",
      "[1092/8000] D loss: 0.8982, G loss: 6.3415\n",
      "[1452/8000] D loss: 0.7070, G loss: 5.8463\n",
      "[1812/8000] D loss: 0.9750, G loss: 3.1792\n",
      "[2172/8000] D loss: 0.6552, G loss: 14.0909\n",
      "[2532/8000] D loss: 0.7753, G loss: 4.2273\n",
      "[2892/8000] D loss: 1.1099, G loss: 3.0069\n",
      "[3252/8000] D loss: 1.0545, G loss: 5.0693\n",
      "[3612/8000] D loss: 0.8713, G loss: 2.7033\n",
      "[3972/8000] D loss: 0.4474, G loss: 9.6562\n",
      "[4332/8000] D loss: 0.5909, G loss: 5.8936\n",
      "[4692/8000] D loss: 1.1596, G loss: 2.6466\n",
      "[5052/8000] D loss: 0.8804, G loss: 5.4767\n",
      "[5412/8000] D loss: 0.7504, G loss: 3.2931\n",
      "[5772/8000] D loss: 0.7662, G loss: 4.6713\n",
      "[6132/8000] D loss: 0.4130, G loss: 8.8437\n",
      "[6492/8000] D loss: 0.7851, G loss: 12.9596\n",
      "[6852/8000] D loss: 0.9396, G loss: 5.7807\n",
      "[7212/8000] D loss: 0.9823, G loss: 4.9938\n",
      "[7572/8000] D loss: 1.0325, G loss: 2.6331\n",
      "[7932/8000] D loss: 0.6657, G loss: 6.4295\n",
      "train error: \n",
      " D loss: 0.840653, G loss: 5.397496, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.890307, G loss: 16.890559, D accuracy: 81.6%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8511, G loss: 7.3665\n",
      "[372/8000] D loss: 0.8187, G loss: 8.3829\n",
      "[732/8000] D loss: 0.9808, G loss: 4.1970\n",
      "[1092/8000] D loss: 0.7164, G loss: 4.9240\n",
      "[1452/8000] D loss: 0.5075, G loss: 6.7197\n",
      "[1812/8000] D loss: 0.5334, G loss: 11.7759\n",
      "[2172/8000] D loss: 0.8366, G loss: 3.9528\n",
      "[2532/8000] D loss: 0.8635, G loss: 10.3479\n",
      "[2892/8000] D loss: 1.0806, G loss: 1.8196\n",
      "[3252/8000] D loss: 1.0738, G loss: 4.6330\n",
      "[3612/8000] D loss: 0.8185, G loss: 10.2934\n",
      "[3972/8000] D loss: 0.7035, G loss: 6.4730\n",
      "[4332/8000] D loss: 0.4238, G loss: 12.2059\n",
      "[4692/8000] D loss: 0.9054, G loss: 6.8375\n",
      "[5052/8000] D loss: 0.4968, G loss: 5.5639\n",
      "[5412/8000] D loss: 0.8533, G loss: 6.9029\n",
      "[5772/8000] D loss: 0.5911, G loss: 10.2677\n",
      "[6132/8000] D loss: 0.8179, G loss: 10.0311\n",
      "[6492/8000] D loss: 0.9159, G loss: 3.2758\n",
      "[6852/8000] D loss: 0.8809, G loss: 8.9074\n",
      "[7212/8000] D loss: 0.6975, G loss: 6.4485\n",
      "[7572/8000] D loss: 0.7737, G loss: 6.6597\n",
      "[7932/8000] D loss: 0.9561, G loss: 5.7999\n",
      "train error: \n",
      " D loss: 0.852683, G loss: 6.241869, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.116713, G loss: 18.260768, D accuracy: 75.9%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8509, G loss: 3.6131\n",
      "[372/8000] D loss: 0.8048, G loss: 6.7364\n",
      "[732/8000] D loss: 0.8116, G loss: 4.1652\n",
      "[1092/8000] D loss: 0.9144, G loss: 5.3215\n",
      "[1452/8000] D loss: 0.5953, G loss: 6.7851\n",
      "[1812/8000] D loss: 0.5885, G loss: 6.8003\n",
      "[2172/8000] D loss: 0.7374, G loss: 4.1031\n",
      "[2532/8000] D loss: 0.8492, G loss: 2.7546\n",
      "[2892/8000] D loss: 1.0151, G loss: 9.6072\n",
      "[3252/8000] D loss: 0.9426, G loss: 6.0311\n",
      "[3612/8000] D loss: 0.7702, G loss: 7.6042\n",
      "[3972/8000] D loss: 0.7777, G loss: 4.5869\n",
      "[4332/8000] D loss: 0.9217, G loss: 4.6512\n",
      "[4692/8000] D loss: 0.6897, G loss: 6.4366\n",
      "[5052/8000] D loss: 0.9471, G loss: 3.0363\n",
      "[5412/8000] D loss: 0.9860, G loss: 9.5363\n",
      "[5772/8000] D loss: 0.6145, G loss: 3.5704\n",
      "[6132/8000] D loss: 0.8766, G loss: 5.3501\n",
      "[6492/8000] D loss: 0.9176, G loss: 3.8405\n",
      "[6852/8000] D loss: 0.9487, G loss: 8.6189\n",
      "[7212/8000] D loss: 0.6218, G loss: 4.4439\n",
      "[7572/8000] D loss: 0.7991, G loss: 4.9162\n",
      "[7932/8000] D loss: 0.8968, G loss: 6.0782\n",
      "train error: \n",
      " D loss: 0.836873, G loss: 6.519061, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.030964, G loss: 18.103492, D accuracy: 76.5%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6400, G loss: 12.5699\n",
      "[372/8000] D loss: 0.7805, G loss: 3.8091\n",
      "[732/8000] D loss: 0.6292, G loss: 7.1709\n",
      "[1092/8000] D loss: 0.7087, G loss: 4.6114\n",
      "[1452/8000] D loss: 1.0294, G loss: 4.3878\n",
      "[1812/8000] D loss: 0.9361, G loss: 4.3317\n",
      "[2172/8000] D loss: 0.7993, G loss: 5.7566\n",
      "[2532/8000] D loss: 0.6524, G loss: 7.6957\n",
      "[2892/8000] D loss: 0.5892, G loss: 10.2439\n",
      "[3252/8000] D loss: 1.0900, G loss: 2.9808\n",
      "[3612/8000] D loss: 0.8864, G loss: 5.8288\n",
      "[3972/8000] D loss: 0.5527, G loss: 8.4081\n",
      "[4332/8000] D loss: 0.9676, G loss: 6.7503\n",
      "[4692/8000] D loss: 1.3112, G loss: 1.2047\n",
      "[5052/8000] D loss: 0.8076, G loss: 13.5994\n",
      "[5412/8000] D loss: 0.8274, G loss: 4.0558\n",
      "[5772/8000] D loss: 0.5018, G loss: 14.4729\n",
      "[6132/8000] D loss: 0.6067, G loss: 5.3142\n",
      "[6492/8000] D loss: 0.7643, G loss: 8.1305\n",
      "[6852/8000] D loss: 0.7707, G loss: 5.4829\n",
      "[7212/8000] D loss: 0.5837, G loss: 8.7041\n",
      "[7572/8000] D loss: 0.8141, G loss: 3.3165\n",
      "[7932/8000] D loss: 0.9051, G loss: 3.4262\n",
      "train error: \n",
      " D loss: 0.860331, G loss: 6.774201, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.042037, G loss: 18.355654, D accuracy: 75.0%, cell accuracy: 98.2%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7250, G loss: 5.7800\n",
      "[372/8000] D loss: 0.5107, G loss: 6.5060\n",
      "[732/8000] D loss: 0.9643, G loss: 4.3323\n",
      "[1092/8000] D loss: 0.7843, G loss: 6.1218\n",
      "[1452/8000] D loss: 1.0623, G loss: 3.3707\n",
      "[1812/8000] D loss: 0.4814, G loss: 11.6048\n",
      "[2172/8000] D loss: 0.9399, G loss: 3.4216\n",
      "[2532/8000] D loss: 1.1768, G loss: 3.6126\n",
      "[2892/8000] D loss: 0.8466, G loss: 7.8884\n",
      "[3252/8000] D loss: 1.0419, G loss: 2.3709\n",
      "[3612/8000] D loss: 0.7259, G loss: 5.8066\n",
      "[3972/8000] D loss: 0.9102, G loss: 6.7294\n",
      "[4332/8000] D loss: 0.9393, G loss: 6.3903\n",
      "[4692/8000] D loss: 0.8240, G loss: 7.2500\n",
      "[5052/8000] D loss: 0.7146, G loss: 8.5090\n",
      "[5412/8000] D loss: 0.8008, G loss: 4.0125\n",
      "[5772/8000] D loss: 0.8570, G loss: 5.8945\n",
      "[6132/8000] D loss: 0.9211, G loss: 4.5484\n",
      "[6492/8000] D loss: 0.6322, G loss: 9.6900\n",
      "[6852/8000] D loss: 1.0114, G loss: 2.7398\n",
      "[7212/8000] D loss: 0.9329, G loss: 7.0468\n",
      "[7572/8000] D loss: 0.9597, G loss: 2.8958\n",
      "[7932/8000] D loss: 0.9454, G loss: 4.6537\n",
      "train error: \n",
      " D loss: 0.840884, G loss: 6.685098, D accuracy: 71.3%, cell accuracy: 98.7%, board accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.982904, G loss: 18.866490, D accuracy: 75.4%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9783, G loss: 6.8770\n",
      "[372/8000] D loss: 0.6038, G loss: 16.0529\n",
      "[732/8000] D loss: 0.8254, G loss: 7.8930\n",
      "[1092/8000] D loss: 0.9265, G loss: 4.3938\n",
      "[1452/8000] D loss: 0.8199, G loss: 6.3617\n",
      "[1812/8000] D loss: 0.6881, G loss: 8.6771\n",
      "[2172/8000] D loss: 1.0494, G loss: 3.5338\n",
      "[2532/8000] D loss: 1.0181, G loss: 3.0749\n",
      "[2892/8000] D loss: 0.3691, G loss: 9.1453\n",
      "[3252/8000] D loss: 0.5781, G loss: 13.6169\n",
      "[3612/8000] D loss: 0.6767, G loss: 7.5458\n",
      "[3972/8000] D loss: 0.8598, G loss: 7.9704\n",
      "[4332/8000] D loss: 0.8221, G loss: 5.6058\n",
      "[4692/8000] D loss: 0.7182, G loss: 6.3406\n",
      "[5052/8000] D loss: 0.4993, G loss: 5.5102\n",
      "[5412/8000] D loss: 1.0485, G loss: 5.9055\n",
      "[5772/8000] D loss: 0.8115, G loss: 7.9717\n",
      "[6132/8000] D loss: 0.8025, G loss: 5.9612\n",
      "[6492/8000] D loss: 0.7996, G loss: 2.9123\n",
      "[6852/8000] D loss: 0.8871, G loss: 3.1560\n",
      "[7212/8000] D loss: 0.9178, G loss: 7.6329\n",
      "[7572/8000] D loss: 0.9394, G loss: 7.0901\n",
      "[7932/8000] D loss: 0.6103, G loss: 7.1242\n",
      "train error: \n",
      " D loss: 0.848958, G loss: 6.593644, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.057259, G loss: 17.841120, D accuracy: 76.9%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0773, G loss: 4.4869\n",
      "[372/8000] D loss: 0.9707, G loss: 3.3095\n",
      "[732/8000] D loss: 0.5149, G loss: 7.1132\n",
      "[1092/8000] D loss: 0.9083, G loss: 3.0202\n",
      "[1452/8000] D loss: 0.8219, G loss: 5.4067\n",
      "[1812/8000] D loss: 0.6744, G loss: 7.2992\n",
      "[2172/8000] D loss: 1.0650, G loss: 2.7343\n",
      "[2532/8000] D loss: 0.9440, G loss: 3.9488\n",
      "[2892/8000] D loss: 0.8396, G loss: 3.8679\n",
      "[3252/8000] D loss: 0.9170, G loss: 4.8204\n",
      "[3612/8000] D loss: 0.7665, G loss: 10.5269\n",
      "[3972/8000] D loss: 0.6837, G loss: 6.0000\n",
      "[4332/8000] D loss: 0.7606, G loss: 9.9610\n",
      "[4692/8000] D loss: 0.7266, G loss: 7.8658\n",
      "[5052/8000] D loss: 0.5476, G loss: 5.6381\n",
      "[5412/8000] D loss: 0.5197, G loss: 12.5609\n",
      "[5772/8000] D loss: 0.9877, G loss: 5.0839\n",
      "[6132/8000] D loss: 1.2312, G loss: 2.5383\n",
      "[6492/8000] D loss: 0.7022, G loss: 5.1927\n",
      "[6852/8000] D loss: 0.8830, G loss: 8.3280\n",
      "[7212/8000] D loss: 0.6560, G loss: 12.2130\n",
      "[7572/8000] D loss: 0.5099, G loss: 7.9032\n",
      "[7932/8000] D loss: 0.7245, G loss: 4.6141\n",
      "train error: \n",
      " D loss: 0.852807, G loss: 6.563597, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.056828, G loss: 17.948221, D accuracy: 74.8%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9243, G loss: 5.4979\n",
      "[372/8000] D loss: 0.7559, G loss: 6.0783\n",
      "[732/8000] D loss: 0.7382, G loss: 7.2621\n",
      "[1092/8000] D loss: 0.9419, G loss: 7.6689\n",
      "[1452/8000] D loss: 0.7395, G loss: 11.5060\n",
      "[1812/8000] D loss: 0.8099, G loss: 6.5303\n",
      "[2172/8000] D loss: 0.8427, G loss: 4.2469\n",
      "[2532/8000] D loss: 0.8732, G loss: 3.9258\n",
      "[2892/8000] D loss: 1.1686, G loss: 4.7437\n",
      "[3252/8000] D loss: 0.8317, G loss: 2.3410\n",
      "[3612/8000] D loss: 0.8888, G loss: 3.7188\n",
      "[3972/8000] D loss: 0.7489, G loss: 5.3961\n",
      "[4332/8000] D loss: 0.4369, G loss: 9.8605\n",
      "[4692/8000] D loss: 0.7526, G loss: 9.0506\n",
      "[5052/8000] D loss: 0.6486, G loss: 7.0477\n",
      "[5412/8000] D loss: 0.5886, G loss: 7.1980\n",
      "[5772/8000] D loss: 0.5689, G loss: 8.6090\n",
      "[6132/8000] D loss: 1.0588, G loss: 2.6736\n",
      "[6492/8000] D loss: 0.8774, G loss: 4.3116\n",
      "[6852/8000] D loss: 0.7226, G loss: 4.8205\n",
      "[7212/8000] D loss: 1.3281, G loss: 1.9442\n",
      "[7572/8000] D loss: 0.8428, G loss: 4.8563\n",
      "[7932/8000] D loss: 1.2638, G loss: 1.6290\n",
      "train error: \n",
      " D loss: 0.835446, G loss: 6.243077, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.968489, G loss: 18.142230, D accuracy: 79.3%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7470, G loss: 8.0593\n",
      "[372/8000] D loss: 0.6758, G loss: 8.6296\n",
      "[732/8000] D loss: 0.5813, G loss: 10.2893\n",
      "[1092/8000] D loss: 1.1372, G loss: 1.9296\n",
      "[1452/8000] D loss: 1.3773, G loss: 0.9828\n",
      "[1812/8000] D loss: 0.4895, G loss: 7.5031\n",
      "[2172/8000] D loss: 0.8996, G loss: 2.6816\n",
      "[2532/8000] D loss: 1.0541, G loss: 4.5743\n",
      "[2892/8000] D loss: 1.0616, G loss: 2.9672\n",
      "[3252/8000] D loss: 0.7379, G loss: 7.9909\n",
      "[3612/8000] D loss: 0.7108, G loss: 4.6216\n",
      "[3972/8000] D loss: 0.6487, G loss: 8.5491\n",
      "[4332/8000] D loss: 0.7906, G loss: 10.3671\n",
      "[4692/8000] D loss: 0.8583, G loss: 5.5146\n",
      "[5052/8000] D loss: 0.8105, G loss: 5.3084\n",
      "[5412/8000] D loss: 0.7126, G loss: 2.7344\n",
      "[5772/8000] D loss: 0.8332, G loss: 5.2805\n",
      "[6132/8000] D loss: 1.1237, G loss: 2.7605\n",
      "[6492/8000] D loss: 0.5454, G loss: 13.7958\n",
      "[6852/8000] D loss: 0.8476, G loss: 10.7141\n",
      "[7212/8000] D loss: 0.7282, G loss: 5.1798\n",
      "[7572/8000] D loss: 0.6808, G loss: 5.9844\n",
      "[7932/8000] D loss: 0.6453, G loss: 11.0830\n",
      "train error: \n",
      " D loss: 0.838948, G loss: 5.938216, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.008188, G loss: 17.092492, D accuracy: 77.5%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7935, G loss: 3.8769\n",
      "[372/8000] D loss: 0.6013, G loss: 6.9828\n",
      "[732/8000] D loss: 1.2901, G loss: 2.1579\n",
      "[1092/8000] D loss: 0.8960, G loss: 6.3642\n",
      "[1452/8000] D loss: 0.7860, G loss: 5.4324\n",
      "[1812/8000] D loss: 0.7216, G loss: 4.4028\n",
      "[2172/8000] D loss: 0.9672, G loss: 2.2314\n",
      "[2532/8000] D loss: 0.7221, G loss: 11.6259\n",
      "[2892/8000] D loss: 0.2859, G loss: 9.4293\n",
      "[3252/8000] D loss: 0.9478, G loss: 1.8502\n",
      "[3612/8000] D loss: 0.9254, G loss: 5.6642\n",
      "[3972/8000] D loss: 1.0907, G loss: 4.3440\n",
      "[4332/8000] D loss: 1.1820, G loss: 1.5613\n",
      "[4692/8000] D loss: 0.7574, G loss: 8.5928\n",
      "[5052/8000] D loss: 0.6046, G loss: 7.3023\n",
      "[5412/8000] D loss: 0.6961, G loss: 8.6616\n",
      "[5772/8000] D loss: 0.8438, G loss: 5.5891\n",
      "[6132/8000] D loss: 0.8391, G loss: 9.9419\n",
      "[6492/8000] D loss: 0.9233, G loss: 4.6902\n",
      "[6852/8000] D loss: 0.8039, G loss: 6.8193\n",
      "[7212/8000] D loss: 1.0338, G loss: 4.2325\n",
      "[7572/8000] D loss: 0.7948, G loss: 4.2140\n",
      "[7932/8000] D loss: 1.1294, G loss: 2.2026\n",
      "train error: \n",
      " D loss: 0.849014, G loss: 5.169544, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.884672, G loss: 16.040455, D accuracy: 80.7%, cell accuracy: 98.2%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6913, G loss: 9.0383\n",
      "[372/8000] D loss: 0.8899, G loss: 5.7722\n",
      "[732/8000] D loss: 0.6988, G loss: 11.9004\n",
      "[1092/8000] D loss: 0.4343, G loss: 7.3991\n",
      "[1452/8000] D loss: 0.6159, G loss: 11.7451\n",
      "[1812/8000] D loss: 1.1745, G loss: 3.5652\n",
      "[2172/8000] D loss: 0.9767, G loss: 5.1197\n",
      "[2532/8000] D loss: 0.6260, G loss: 8.6879\n",
      "[2892/8000] D loss: 0.6058, G loss: 9.7407\n",
      "[3252/8000] D loss: 0.6312, G loss: 9.8836\n",
      "[3612/8000] D loss: 0.7136, G loss: 8.1925\n",
      "[3972/8000] D loss: 0.8272, G loss: 6.4567\n",
      "[4332/8000] D loss: 0.8676, G loss: 2.7303\n",
      "[4692/8000] D loss: 0.8446, G loss: 4.1518\n",
      "[5052/8000] D loss: 0.8138, G loss: 8.8457\n",
      "[5412/8000] D loss: 0.5838, G loss: 8.0477\n",
      "[5772/8000] D loss: 0.9313, G loss: 2.9246\n",
      "[6132/8000] D loss: 1.1305, G loss: 1.9548\n",
      "[6492/8000] D loss: 0.9675, G loss: 6.8754\n",
      "[6852/8000] D loss: 0.3710, G loss: 11.5694\n",
      "[7212/8000] D loss: 0.8116, G loss: 2.0032\n",
      "[7572/8000] D loss: 0.9141, G loss: 5.2966\n",
      "[7932/8000] D loss: 1.1235, G loss: 2.1056\n",
      "train error: \n",
      " D loss: 0.836648, G loss: 6.725111, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.996540, G loss: 18.759730, D accuracy: 78.9%, cell accuracy: 98.2%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8907, G loss: 7.3167\n",
      "[372/8000] D loss: 0.8274, G loss: 3.5888\n",
      "[732/8000] D loss: 0.8563, G loss: 8.7839\n",
      "[1092/8000] D loss: 0.9664, G loss: 2.9651\n",
      "[1452/8000] D loss: 0.9672, G loss: 3.2780\n",
      "[1812/8000] D loss: 1.0528, G loss: 6.5569\n",
      "[2172/8000] D loss: 0.7590, G loss: 6.1398\n",
      "[2532/8000] D loss: 0.5120, G loss: 6.8613\n",
      "[2892/8000] D loss: 0.8110, G loss: 4.7752\n",
      "[3252/8000] D loss: 1.0317, G loss: 3.5376\n",
      "[3612/8000] D loss: 1.0607, G loss: 2.7490\n",
      "[3972/8000] D loss: 1.1199, G loss: 6.8208\n",
      "[4332/8000] D loss: 0.6896, G loss: 5.1796\n",
      "[4692/8000] D loss: 0.4679, G loss: 10.8545\n",
      "[5052/8000] D loss: 0.8433, G loss: 6.6532\n",
      "[5412/8000] D loss: 0.9577, G loss: 2.5672\n",
      "[5772/8000] D loss: 0.8731, G loss: 12.9234\n",
      "[6132/8000] D loss: 0.9403, G loss: 2.0832\n",
      "[6492/8000] D loss: 0.3528, G loss: 5.6653\n",
      "[6852/8000] D loss: 0.8118, G loss: 5.8783\n",
      "[7212/8000] D loss: 0.4848, G loss: 10.2277\n",
      "[7572/8000] D loss: 0.6104, G loss: 10.0793\n",
      "[7932/8000] D loss: 0.9948, G loss: 6.5076\n",
      "train error: \n",
      " D loss: 0.853438, G loss: 4.991197, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.845044, G loss: 15.970060, D accuracy: 81.4%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8168, G loss: 6.0208\n",
      "[372/8000] D loss: 1.1888, G loss: 1.3263\n",
      "[732/8000] D loss: 0.7018, G loss: 5.2889\n",
      "[1092/8000] D loss: 0.8981, G loss: 5.4784\n",
      "[1452/8000] D loss: 0.7539, G loss: 10.0584\n",
      "[1812/8000] D loss: 0.8586, G loss: 2.8635\n",
      "[2172/8000] D loss: 0.9045, G loss: 3.3256\n",
      "[2532/8000] D loss: 0.7354, G loss: 3.8199\n",
      "[2892/8000] D loss: 1.1198, G loss: 1.6229\n",
      "[3252/8000] D loss: 0.5083, G loss: 5.6081\n",
      "[3612/8000] D loss: 0.9262, G loss: 6.2295\n",
      "[3972/8000] D loss: 0.5799, G loss: 10.5440\n",
      "[4332/8000] D loss: 0.5715, G loss: 6.8372\n",
      "[4692/8000] D loss: 0.6960, G loss: 6.9449\n",
      "[5052/8000] D loss: 0.2020, G loss: 12.2156\n",
      "[5412/8000] D loss: 0.8474, G loss: 6.1411\n",
      "[5772/8000] D loss: 0.5797, G loss: 8.3080\n",
      "[6132/8000] D loss: 0.7081, G loss: 5.9828\n",
      "[6492/8000] D loss: 0.7554, G loss: 9.5887\n",
      "[6852/8000] D loss: 0.6016, G loss: 6.7803\n",
      "[7212/8000] D loss: 0.8586, G loss: 4.3088\n",
      "[7572/8000] D loss: 0.6292, G loss: 5.9487\n",
      "[7932/8000] D loss: 0.7183, G loss: 9.9854\n",
      "train error: \n",
      " D loss: 0.832264, G loss: 6.217010, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 55.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.921621, G loss: 17.890541, D accuracy: 81.3%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7805, G loss: 6.8981\n",
      "[372/8000] D loss: 0.8151, G loss: 7.7814\n",
      "[732/8000] D loss: 0.6255, G loss: 9.5600\n",
      "[1092/8000] D loss: 0.6195, G loss: 5.5888\n",
      "[1452/8000] D loss: 0.6663, G loss: 7.1073\n",
      "[1812/8000] D loss: 0.9970, G loss: 2.1477\n",
      "[2172/8000] D loss: 0.6546, G loss: 6.2420\n",
      "[2532/8000] D loss: 0.9529, G loss: 2.8980\n",
      "[2892/8000] D loss: 0.5543, G loss: 10.4480\n",
      "[3252/8000] D loss: 0.6877, G loss: 4.3895\n",
      "[3612/8000] D loss: 0.8372, G loss: 6.8662\n",
      "[3972/8000] D loss: 0.6845, G loss: 10.0878\n",
      "[4332/8000] D loss: 0.8311, G loss: 11.7637\n",
      "[4692/8000] D loss: 0.6878, G loss: 11.7187\n",
      "[5052/8000] D loss: 0.6437, G loss: 5.2165\n",
      "[5412/8000] D loss: 0.9285, G loss: 6.4613\n",
      "[5772/8000] D loss: 0.9332, G loss: 7.1311\n",
      "[6132/8000] D loss: 0.5459, G loss: 5.5094\n",
      "[6492/8000] D loss: 0.7577, G loss: 5.9359\n",
      "[6852/8000] D loss: 0.7576, G loss: 3.9538\n",
      "[7212/8000] D loss: 0.9106, G loss: 3.3443\n",
      "[7572/8000] D loss: 0.8701, G loss: 5.4250\n",
      "[7932/8000] D loss: 0.8907, G loss: 4.4891\n",
      "train error: \n",
      " D loss: 0.856003, G loss: 4.764819, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.908226, G loss: 15.027127, D accuracy: 78.3%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7533, G loss: 10.0742\n",
      "[372/8000] D loss: 0.9457, G loss: 7.2201\n",
      "[732/8000] D loss: 0.9553, G loss: 2.8282\n",
      "[1092/8000] D loss: 1.0581, G loss: 1.8629\n",
      "[1452/8000] D loss: 0.4050, G loss: 14.3433\n",
      "[1812/8000] D loss: 1.1504, G loss: 1.6061\n",
      "[2172/8000] D loss: 0.6872, G loss: 4.4907\n",
      "[2532/8000] D loss: 0.8206, G loss: 4.7199\n",
      "[2892/8000] D loss: 0.8335, G loss: 7.8417\n",
      "[3252/8000] D loss: 1.1570, G loss: 2.0941\n",
      "[3612/8000] D loss: 0.8851, G loss: 4.9436\n",
      "[3972/8000] D loss: 0.8898, G loss: 7.7095\n",
      "[4332/8000] D loss: 0.9669, G loss: 5.2808\n",
      "[4692/8000] D loss: 0.5968, G loss: 10.3755\n",
      "[5052/8000] D loss: 0.9527, G loss: 7.5585\n",
      "[5412/8000] D loss: 0.6913, G loss: 7.9197\n",
      "[5772/8000] D loss: 0.9040, G loss: 4.6478\n",
      "[6132/8000] D loss: 0.9288, G loss: 3.9204\n",
      "[6492/8000] D loss: 0.8338, G loss: 7.8960\n",
      "[6852/8000] D loss: 1.3134, G loss: 1.7801\n",
      "[7212/8000] D loss: 1.0191, G loss: 4.0694\n",
      "[7572/8000] D loss: 0.8475, G loss: 6.7817\n",
      "[7932/8000] D loss: 0.5309, G loss: 11.8648\n",
      "train error: \n",
      " D loss: 0.854405, G loss: 6.582621, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.002864, G loss: 19.529417, D accuracy: 80.1%, cell accuracy: 98.2%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1230, G loss: 4.1943\n",
      "[372/8000] D loss: 1.1824, G loss: 1.9280\n",
      "[732/8000] D loss: 0.9192, G loss: 5.6793\n",
      "[1092/8000] D loss: 0.8907, G loss: 3.7866\n",
      "[1452/8000] D loss: 0.7104, G loss: 6.9791\n",
      "[1812/8000] D loss: 1.1252, G loss: 3.5587\n",
      "[2172/8000] D loss: 1.1128, G loss: 3.2947\n",
      "[2532/8000] D loss: 0.7556, G loss: 4.2035\n",
      "[2892/8000] D loss: 0.9000, G loss: 5.8228\n",
      "[3252/8000] D loss: 0.8344, G loss: 7.5089\n",
      "[3612/8000] D loss: 1.0725, G loss: 2.3100\n",
      "[3972/8000] D loss: 0.5183, G loss: 7.1137\n",
      "[4332/8000] D loss: 0.9248, G loss: 2.6334\n",
      "[4692/8000] D loss: 0.8770, G loss: 4.6605\n",
      "[5052/8000] D loss: 0.7122, G loss: 5.0601\n",
      "[5412/8000] D loss: 0.5883, G loss: 7.2942\n",
      "[5772/8000] D loss: 0.8074, G loss: 6.5740\n",
      "[6132/8000] D loss: 0.9670, G loss: 4.3583\n",
      "[6492/8000] D loss: 1.2718, G loss: 3.6365\n",
      "[6852/8000] D loss: 0.6994, G loss: 8.6422\n",
      "[7212/8000] D loss: 0.9864, G loss: 5.0448\n",
      "[7572/8000] D loss: 0.8987, G loss: 2.6903\n",
      "[7932/8000] D loss: 0.4279, G loss: 6.3339\n",
      "train error: \n",
      " D loss: 0.851906, G loss: 5.974573, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.985536, G loss: 17.683113, D accuracy: 80.0%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9057, G loss: 5.0626\n",
      "[372/8000] D loss: 1.1290, G loss: 2.2129\n",
      "[732/8000] D loss: 0.5756, G loss: 9.2210\n",
      "[1092/8000] D loss: 0.9843, G loss: 4.4444\n",
      "[1452/8000] D loss: 1.2871, G loss: 1.6427\n",
      "[1812/8000] D loss: 0.8569, G loss: 3.0157\n",
      "[2172/8000] D loss: 0.9461, G loss: 3.6838\n",
      "[2532/8000] D loss: 0.9117, G loss: 2.3852\n",
      "[2892/8000] D loss: 1.0214, G loss: 5.2909\n",
      "[3252/8000] D loss: 0.8483, G loss: 3.4412\n",
      "[3612/8000] D loss: 0.7290, G loss: 6.6088\n",
      "[3972/8000] D loss: 0.9340, G loss: 4.4008\n",
      "[4332/8000] D loss: 0.5899, G loss: 9.5610\n",
      "[4692/8000] D loss: 0.9378, G loss: 6.0025\n",
      "[5052/8000] D loss: 0.7666, G loss: 10.7907\n",
      "[5412/8000] D loss: 0.9565, G loss: 3.6522\n",
      "[5772/8000] D loss: 0.9400, G loss: 6.9147\n",
      "[6132/8000] D loss: 0.8644, G loss: 7.6846\n",
      "[6492/8000] D loss: 0.8199, G loss: 4.9995\n",
      "[6852/8000] D loss: 1.3596, G loss: 0.7375\n",
      "[7212/8000] D loss: 0.8151, G loss: 8.2883\n",
      "[7572/8000] D loss: 0.3684, G loss: 20.3237\n",
      "[7932/8000] D loss: 0.6530, G loss: 9.6914\n",
      "train error: \n",
      " D loss: 0.843489, G loss: 5.528781, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.888886, G loss: 16.770470, D accuracy: 79.9%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0657, G loss: 4.9191\n",
      "[372/8000] D loss: 0.9494, G loss: 6.2807\n",
      "[732/8000] D loss: 1.1387, G loss: 5.0081\n",
      "[1092/8000] D loss: 0.9274, G loss: 7.2006\n",
      "[1452/8000] D loss: 0.8850, G loss: 5.9986\n",
      "[1812/8000] D loss: 0.6394, G loss: 6.0019\n",
      "[2172/8000] D loss: 0.8905, G loss: 6.1465\n",
      "[2532/8000] D loss: 0.8476, G loss: 7.4474\n",
      "[2892/8000] D loss: 0.6742, G loss: 8.2086\n",
      "[3252/8000] D loss: 0.5952, G loss: 7.8194\n",
      "[3612/8000] D loss: 0.9546, G loss: 4.0532\n",
      "[3972/8000] D loss: 0.7014, G loss: 9.9170\n",
      "[4332/8000] D loss: 0.6337, G loss: 9.4840\n",
      "[4692/8000] D loss: 0.5093, G loss: 8.4785\n",
      "[5052/8000] D loss: 1.2947, G loss: 1.2327\n",
      "[5412/8000] D loss: 1.0829, G loss: 4.7224\n",
      "[5772/8000] D loss: 1.0862, G loss: 5.4333\n",
      "[6132/8000] D loss: 0.2615, G loss: 14.0438\n",
      "[6492/8000] D loss: 0.6098, G loss: 3.7990\n",
      "[6852/8000] D loss: 0.8547, G loss: 5.0966\n",
      "[7212/8000] D loss: 0.7509, G loss: 6.9008\n",
      "[7572/8000] D loss: 0.8335, G loss: 5.0979\n",
      "[7932/8000] D loss: 0.5908, G loss: 13.8727\n",
      "train error: \n",
      " D loss: 0.822795, G loss: 6.592507, D accuracy: 72.9%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.986405, G loss: 19.046897, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7278, G loss: 10.3181\n",
      "[372/8000] D loss: 0.6426, G loss: 8.4034\n",
      "[732/8000] D loss: 0.9861, G loss: 3.5339\n",
      "[1092/8000] D loss: 1.0741, G loss: 5.4980\n",
      "[1452/8000] D loss: 0.9836, G loss: 6.9836\n",
      "[1812/8000] D loss: 0.9435, G loss: 3.3795\n",
      "[2172/8000] D loss: 0.7425, G loss: 8.6331\n",
      "[2532/8000] D loss: 0.7800, G loss: 10.6575\n",
      "[2892/8000] D loss: 0.7849, G loss: 9.0381\n",
      "[3252/8000] D loss: 0.6452, G loss: 6.5854\n",
      "[3612/8000] D loss: 1.0399, G loss: 4.5361\n",
      "[3972/8000] D loss: 0.4646, G loss: 5.6704\n",
      "[4332/8000] D loss: 0.5159, G loss: 9.3807\n",
      "[4692/8000] D loss: 0.8220, G loss: 5.9517\n",
      "[5052/8000] D loss: 0.8435, G loss: 4.7511\n",
      "[5412/8000] D loss: 0.9940, G loss: 1.9903\n",
      "[5772/8000] D loss: 0.7926, G loss: 2.3073\n",
      "[6132/8000] D loss: 0.6326, G loss: 8.9588\n",
      "[6492/8000] D loss: 0.8002, G loss: 9.5096\n",
      "[6852/8000] D loss: 1.0809, G loss: 3.9233\n",
      "[7212/8000] D loss: 0.5486, G loss: 8.1734\n",
      "[7572/8000] D loss: 0.6767, G loss: 7.9909\n",
      "[7932/8000] D loss: 1.1052, G loss: 1.7646\n",
      "train error: \n",
      " D loss: 0.837730, G loss: 6.820632, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.981689, G loss: 18.972012, D accuracy: 79.8%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6046, G loss: 18.7368\n",
      "[372/8000] D loss: 1.0633, G loss: 4.6897\n",
      "[732/8000] D loss: 0.5885, G loss: 10.3706\n",
      "[1092/8000] D loss: 0.9685, G loss: 3.0634\n",
      "[1452/8000] D loss: 0.6407, G loss: 8.8000\n",
      "[1812/8000] D loss: 0.5978, G loss: 10.6575\n",
      "[2172/8000] D loss: 0.6718, G loss: 6.5144\n",
      "[2532/8000] D loss: 0.7369, G loss: 6.9503\n",
      "[2892/8000] D loss: 0.5782, G loss: 10.1129\n",
      "[3252/8000] D loss: 1.1375, G loss: 3.2539\n",
      "[3612/8000] D loss: 0.8486, G loss: 6.3532\n",
      "[3972/8000] D loss: 0.7566, G loss: 5.1460\n",
      "[4332/8000] D loss: 1.0896, G loss: 3.0550\n",
      "[4692/8000] D loss: 0.6002, G loss: 4.3422\n",
      "[5052/8000] D loss: 0.7129, G loss: 6.8407\n",
      "[5412/8000] D loss: 0.6987, G loss: 5.4935\n",
      "[5772/8000] D loss: 0.7056, G loss: 10.6479\n",
      "[6132/8000] D loss: 1.0454, G loss: 4.8147\n",
      "[6492/8000] D loss: 1.2547, G loss: 3.2507\n",
      "[6852/8000] D loss: 0.9085, G loss: 5.1850\n",
      "[7212/8000] D loss: 1.1216, G loss: 2.6377\n",
      "[7572/8000] D loss: 0.7808, G loss: 4.4276\n",
      "[7932/8000] D loss: 0.7041, G loss: 4.5835\n",
      "train error: \n",
      " D loss: 0.845527, G loss: 6.576868, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.953275, G loss: 18.916502, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9252, G loss: 2.4057\n",
      "[372/8000] D loss: 0.6059, G loss: 7.7899\n",
      "[732/8000] D loss: 1.0139, G loss: 3.9117\n",
      "[1092/8000] D loss: 0.9659, G loss: 8.4924\n",
      "[1452/8000] D loss: 0.5015, G loss: 10.3927\n",
      "[1812/8000] D loss: 1.1041, G loss: 1.8250\n",
      "[2172/8000] D loss: 0.8860, G loss: 7.5746\n",
      "[2532/8000] D loss: 0.7878, G loss: 2.7507\n",
      "[2892/8000] D loss: 1.2584, G loss: 0.9753\n",
      "[3252/8000] D loss: 0.5528, G loss: 7.1689\n",
      "[3612/8000] D loss: 0.8015, G loss: 3.4991\n",
      "[3972/8000] D loss: 0.8072, G loss: 7.0512\n",
      "[4332/8000] D loss: 0.9459, G loss: 5.4006\n",
      "[4692/8000] D loss: 0.7898, G loss: 4.5350\n",
      "[5052/8000] D loss: 0.7135, G loss: 5.7659\n",
      "[5412/8000] D loss: 0.7264, G loss: 8.0790\n",
      "[5772/8000] D loss: 0.5491, G loss: 6.3976\n",
      "[6132/8000] D loss: 0.5225, G loss: 4.3543\n",
      "[6492/8000] D loss: 1.2064, G loss: 2.3517\n",
      "[6852/8000] D loss: 1.2830, G loss: 6.1077\n",
      "[7212/8000] D loss: 0.5404, G loss: 6.1323\n",
      "[7572/8000] D loss: 1.3964, G loss: 1.0777\n",
      "[7932/8000] D loss: 0.8955, G loss: 5.1197\n",
      "train error: \n",
      " D loss: 0.862648, G loss: 5.882067, D accuracy: 71.0%, cell accuracy: 98.7%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.983667, G loss: 17.037233, D accuracy: 76.0%, cell accuracy: 98.3%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6206, G loss: 9.9865\n",
      "[372/8000] D loss: 0.8141, G loss: 3.7330\n",
      "[732/8000] D loss: 1.0881, G loss: 1.4974\n",
      "[1092/8000] D loss: 0.9315, G loss: 5.9978\n",
      "[1452/8000] D loss: 1.0511, G loss: 7.7387\n",
      "[1812/8000] D loss: 0.9915, G loss: 4.1024\n",
      "[2172/8000] D loss: 0.7321, G loss: 5.3722\n",
      "[2532/8000] D loss: 0.9201, G loss: 4.5510\n",
      "[2892/8000] D loss: 0.8943, G loss: 8.7555\n",
      "[3252/8000] D loss: 1.0645, G loss: 5.7757\n",
      "[3612/8000] D loss: 0.6359, G loss: 7.2540\n",
      "[3972/8000] D loss: 0.9970, G loss: 3.2425\n",
      "[4332/8000] D loss: 0.7309, G loss: 9.9591\n",
      "[4692/8000] D loss: 0.3634, G loss: 7.8414\n",
      "[5052/8000] D loss: 0.8961, G loss: 7.2187\n",
      "[5412/8000] D loss: 0.2781, G loss: 9.6744\n",
      "[5772/8000] D loss: 0.6453, G loss: 8.5024\n",
      "[6132/8000] D loss: 1.1744, G loss: 3.0325\n",
      "[6492/8000] D loss: 0.6863, G loss: 5.4439\n",
      "[6852/8000] D loss: 0.7446, G loss: 5.4488\n",
      "[7212/8000] D loss: 1.0229, G loss: 3.8319\n",
      "[7572/8000] D loss: 1.0447, G loss: 2.1735\n",
      "[7932/8000] D loss: 0.9387, G loss: 7.7073\n",
      "train error: \n",
      " D loss: 0.837921, G loss: 6.112530, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.014388, G loss: 17.941259, D accuracy: 77.2%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0779, G loss: 4.2358\n",
      "[372/8000] D loss: 0.9206, G loss: 5.3661\n",
      "[732/8000] D loss: 0.9584, G loss: 3.0460\n",
      "[1092/8000] D loss: 1.2055, G loss: 2.5849\n",
      "[1452/8000] D loss: 0.8041, G loss: 9.3999\n",
      "[1812/8000] D loss: 0.8692, G loss: 5.6435\n",
      "[2172/8000] D loss: 0.7393, G loss: 8.5526\n",
      "[2532/8000] D loss: 0.6643, G loss: 4.5962\n",
      "[2892/8000] D loss: 0.5958, G loss: 7.5715\n",
      "[3252/8000] D loss: 0.6269, G loss: 8.8676\n",
      "[3612/8000] D loss: 0.7600, G loss: 10.9295\n",
      "[3972/8000] D loss: 1.0882, G loss: 7.6955\n",
      "[4332/8000] D loss: 0.9005, G loss: 4.2224\n",
      "[4692/8000] D loss: 1.0060, G loss: 2.4943\n",
      "[5052/8000] D loss: 0.7065, G loss: 3.9709\n",
      "[5412/8000] D loss: 1.0582, G loss: 4.1870\n",
      "[5772/8000] D loss: 0.9320, G loss: 6.2180\n",
      "[6132/8000] D loss: 0.8950, G loss: 2.5003\n",
      "[6492/8000] D loss: 0.7514, G loss: 4.1366\n",
      "[6852/8000] D loss: 0.7338, G loss: 3.5496\n",
      "[7212/8000] D loss: 1.0208, G loss: 4.7972\n",
      "[7572/8000] D loss: 0.9455, G loss: 5.4158\n",
      "[7932/8000] D loss: 0.9369, G loss: 4.5689\n",
      "train error: \n",
      " D loss: 0.840127, G loss: 5.598686, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.896619, G loss: 17.027430, D accuracy: 80.4%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8179, G loss: 4.9425\n",
      "[372/8000] D loss: 0.7506, G loss: 5.2442\n",
      "[732/8000] D loss: 0.9336, G loss: 1.8726\n",
      "[1092/8000] D loss: 1.0543, G loss: 2.0749\n",
      "[1452/8000] D loss: 0.9554, G loss: 2.7534\n",
      "[1812/8000] D loss: 0.8320, G loss: 3.5232\n",
      "[2172/8000] D loss: 0.7545, G loss: 10.8522\n",
      "[2532/8000] D loss: 0.9883, G loss: 5.3100\n",
      "[2892/8000] D loss: 0.5824, G loss: 9.7621\n",
      "[3252/8000] D loss: 0.6677, G loss: 5.0805\n",
      "[3612/8000] D loss: 0.5929, G loss: 7.6128\n",
      "[3972/8000] D loss: 0.7055, G loss: 6.0240\n",
      "[4332/8000] D loss: 0.6975, G loss: 6.4197\n",
      "[4692/8000] D loss: 1.0353, G loss: 6.3325\n",
      "[5052/8000] D loss: 0.6275, G loss: 10.5048\n",
      "[5412/8000] D loss: 1.0395, G loss: 4.1934\n",
      "[5772/8000] D loss: 1.1387, G loss: 1.5273\n",
      "[6132/8000] D loss: 0.8138, G loss: 7.1696\n",
      "[6492/8000] D loss: 0.6918, G loss: 5.9593\n",
      "[6852/8000] D loss: 1.0482, G loss: 3.5481\n",
      "[7212/8000] D loss: 0.6780, G loss: 5.2759\n",
      "[7572/8000] D loss: 0.6406, G loss: 7.9575\n",
      "[7932/8000] D loss: 0.7494, G loss: 5.0458\n",
      "train error: \n",
      " D loss: 0.838041, G loss: 6.335975, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.964854, G loss: 17.779268, D accuracy: 77.8%, cell accuracy: 98.2%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0527, G loss: 6.8825\n",
      "[372/8000] D loss: 0.7880, G loss: 5.3618\n",
      "[732/8000] D loss: 0.5716, G loss: 11.7802\n",
      "[1092/8000] D loss: 1.1335, G loss: 3.1688\n",
      "[1452/8000] D loss: 0.9260, G loss: 5.4763\n",
      "[1812/8000] D loss: 1.0514, G loss: 2.4715\n",
      "[2172/8000] D loss: 1.0081, G loss: 3.3336\n",
      "[2532/8000] D loss: 0.7490, G loss: 7.2184\n",
      "[2892/8000] D loss: 0.8065, G loss: 6.4029\n",
      "[3252/8000] D loss: 0.7577, G loss: 12.9626\n",
      "[3612/8000] D loss: 1.0157, G loss: 1.8801\n",
      "[3972/8000] D loss: 0.8317, G loss: 5.3413\n",
      "[4332/8000] D loss: 0.6677, G loss: 5.0742\n",
      "[4692/8000] D loss: 1.0064, G loss: 6.5855\n",
      "[5052/8000] D loss: 0.9050, G loss: 6.0589\n",
      "[5412/8000] D loss: 0.9459, G loss: 3.0498\n",
      "[5772/8000] D loss: 0.8297, G loss: 4.0782\n",
      "[6132/8000] D loss: 0.7470, G loss: 5.1154\n",
      "[6492/8000] D loss: 0.8962, G loss: 6.7796\n",
      "[6852/8000] D loss: 0.7999, G loss: 6.1427\n",
      "[7212/8000] D loss: 0.6285, G loss: 7.5880\n",
      "[7572/8000] D loss: 1.0864, G loss: 4.8545\n",
      "[7932/8000] D loss: 0.6382, G loss: 8.9646\n",
      "train error: \n",
      " D loss: 0.838188, G loss: 6.671391, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.987897, G loss: 19.171570, D accuracy: 76.8%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8473, G loss: 5.6272\n",
      "[372/8000] D loss: 0.6950, G loss: 6.5593\n",
      "[732/8000] D loss: 0.8219, G loss: 7.3846\n",
      "[1092/8000] D loss: 1.0787, G loss: 2.5023\n",
      "[1452/8000] D loss: 0.6455, G loss: 9.3979\n",
      "[1812/8000] D loss: 0.5488, G loss: 8.2505\n",
      "[2172/8000] D loss: 0.7540, G loss: 4.3414\n",
      "[2532/8000] D loss: 0.9625, G loss: 6.6163\n",
      "[2892/8000] D loss: 0.9802, G loss: 9.3018\n",
      "[3252/8000] D loss: 0.7372, G loss: 4.7779\n",
      "[3612/8000] D loss: 0.8509, G loss: 4.7003\n",
      "[3972/8000] D loss: 0.8568, G loss: 7.3318\n",
      "[4332/8000] D loss: 0.7046, G loss: 7.2990\n",
      "[4692/8000] D loss: 1.0067, G loss: 5.0772\n",
      "[5052/8000] D loss: 0.7024, G loss: 6.3622\n",
      "[5412/8000] D loss: 1.1269, G loss: 5.8529\n",
      "[5772/8000] D loss: 0.5099, G loss: 9.6959\n",
      "[6132/8000] D loss: 0.5976, G loss: 10.8386\n",
      "[6492/8000] D loss: 0.5789, G loss: 3.5040\n",
      "[6852/8000] D loss: 0.8641, G loss: 4.8951\n",
      "[7212/8000] D loss: 1.0335, G loss: 2.8387\n",
      "[7572/8000] D loss: 0.8853, G loss: 3.6477\n",
      "[7932/8000] D loss: 0.9766, G loss: 2.5150\n",
      "train error: \n",
      " D loss: 0.848793, G loss: 5.858047, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.009585, G loss: 17.336965, D accuracy: 77.1%, cell accuracy: 98.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9237, G loss: 10.7729\n",
      "[372/8000] D loss: 0.7189, G loss: 5.2674\n",
      "[732/8000] D loss: 0.4604, G loss: 16.6282\n",
      "[1092/8000] D loss: 0.3518, G loss: 8.9448\n",
      "[1452/8000] D loss: 0.9377, G loss: 3.8230\n",
      "[1812/8000] D loss: 0.6932, G loss: 5.6331\n",
      "[2172/8000] D loss: 0.8999, G loss: 5.7413\n",
      "[2532/8000] D loss: 0.7708, G loss: 4.1891\n",
      "[2892/8000] D loss: 1.3192, G loss: 0.7357\n",
      "[3252/8000] D loss: 0.6456, G loss: 7.0447\n",
      "[3612/8000] D loss: 0.9377, G loss: 3.1949\n",
      "[3972/8000] D loss: 0.7922, G loss: 8.1070\n",
      "[4332/8000] D loss: 0.7789, G loss: 6.7935\n",
      "[4692/8000] D loss: 1.1597, G loss: 1.3624\n",
      "[5052/8000] D loss: 1.1679, G loss: 1.4407\n",
      "[5412/8000] D loss: 0.7176, G loss: 3.2743\n",
      "[5772/8000] D loss: 1.2714, G loss: 3.3403\n",
      "[6132/8000] D loss: 1.0245, G loss: 4.3178\n",
      "[6492/8000] D loss: 0.9484, G loss: 2.2597\n",
      "[6852/8000] D loss: 0.6976, G loss: 7.4539\n",
      "[7212/8000] D loss: 0.8303, G loss: 6.1144\n",
      "[7572/8000] D loss: 0.8374, G loss: 8.4783\n",
      "[7932/8000] D loss: 0.8433, G loss: 8.7750\n",
      "train error: \n",
      " D loss: 0.827604, G loss: 6.425459, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.009107, G loss: 18.264397, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7930, G loss: 6.2749\n",
      "[372/8000] D loss: 0.5821, G loss: 8.3080\n",
      "[732/8000] D loss: 1.0535, G loss: 2.1087\n",
      "[1092/8000] D loss: 0.5621, G loss: 9.4374\n",
      "[1452/8000] D loss: 1.1037, G loss: 6.1461\n",
      "[1812/8000] D loss: 0.4772, G loss: 11.5278\n",
      "[2172/8000] D loss: 1.0679, G loss: 3.7253\n",
      "[2532/8000] D loss: 0.7950, G loss: 3.6294\n",
      "[2892/8000] D loss: 0.5319, G loss: 9.5651\n",
      "[3252/8000] D loss: 0.9486, G loss: 5.1709\n",
      "[3612/8000] D loss: 0.9902, G loss: 3.8149\n",
      "[3972/8000] D loss: 0.6281, G loss: 9.9852\n",
      "[4332/8000] D loss: 1.0608, G loss: 2.2183\n",
      "[4692/8000] D loss: 0.7120, G loss: 8.2408\n",
      "[5052/8000] D loss: 0.8574, G loss: 4.5982\n",
      "[5412/8000] D loss: 0.5986, G loss: 5.7751\n",
      "[5772/8000] D loss: 1.1988, G loss: 5.4113\n",
      "[6132/8000] D loss: 0.9621, G loss: 2.2636\n",
      "[6492/8000] D loss: 1.1160, G loss: 2.7754\n",
      "[6852/8000] D loss: 1.1893, G loss: 2.8933\n",
      "[7212/8000] D loss: 0.4706, G loss: 13.4035\n",
      "[7572/8000] D loss: 0.8587, G loss: 7.0095\n",
      "[7932/8000] D loss: 1.0061, G loss: 3.4661\n",
      "train error: \n",
      " D loss: 0.844871, G loss: 5.272423, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.908459, G loss: 16.144849, D accuracy: 79.2%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8507, G loss: 5.6119\n",
      "[372/8000] D loss: 0.5970, G loss: 9.6684\n",
      "[732/8000] D loss: 1.0347, G loss: 2.5909\n",
      "[1092/8000] D loss: 0.9482, G loss: 2.5596\n",
      "[1452/8000] D loss: 0.6081, G loss: 10.6333\n",
      "[1812/8000] D loss: 0.9278, G loss: 2.6765\n",
      "[2172/8000] D loss: 0.6957, G loss: 5.7040\n",
      "[2532/8000] D loss: 0.8356, G loss: 8.5128\n",
      "[2892/8000] D loss: 0.9355, G loss: 6.0780\n",
      "[3252/8000] D loss: 0.4746, G loss: 10.3468\n",
      "[3612/8000] D loss: 0.7496, G loss: 7.3271\n",
      "[3972/8000] D loss: 0.8644, G loss: 12.5566\n",
      "[4332/8000] D loss: 0.3545, G loss: 16.8582\n",
      "[4692/8000] D loss: 0.5626, G loss: 5.6272\n",
      "[5052/8000] D loss: 1.0124, G loss: 2.1752\n",
      "[5412/8000] D loss: 1.2830, G loss: 1.0234\n",
      "[5772/8000] D loss: 0.7815, G loss: 3.4512\n",
      "[6132/8000] D loss: 0.7647, G loss: 9.3329\n",
      "[6492/8000] D loss: 0.6992, G loss: 9.8057\n",
      "[6852/8000] D loss: 1.1163, G loss: 4.5814\n",
      "[7212/8000] D loss: 0.6047, G loss: 5.3098\n",
      "[7572/8000] D loss: 0.6938, G loss: 5.8924\n",
      "[7932/8000] D loss: 0.9505, G loss: 5.8781\n",
      "train error: \n",
      " D loss: 0.844363, G loss: 5.973185, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.026016, G loss: 17.289693, D accuracy: 76.8%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8241, G loss: 3.8739\n",
      "[372/8000] D loss: 0.5318, G loss: 11.9924\n",
      "[732/8000] D loss: 1.1656, G loss: 3.5710\n",
      "[1092/8000] D loss: 0.7177, G loss: 2.7842\n",
      "[1452/8000] D loss: 1.0495, G loss: 2.5915\n",
      "[1812/8000] D loss: 1.1924, G loss: 1.2515\n",
      "[2172/8000] D loss: 0.7101, G loss: 5.0831\n",
      "[2532/8000] D loss: 0.7274, G loss: 11.3348\n",
      "[2892/8000] D loss: 0.6134, G loss: 7.7024\n",
      "[3252/8000] D loss: 0.9567, G loss: 9.4073\n",
      "[3612/8000] D loss: 0.5327, G loss: 8.3776\n",
      "[3972/8000] D loss: 0.8895, G loss: 6.8086\n",
      "[4332/8000] D loss: 0.7729, G loss: 7.5738\n",
      "[4692/8000] D loss: 0.8219, G loss: 6.5467\n",
      "[5052/8000] D loss: 1.0918, G loss: 3.4856\n",
      "[5412/8000] D loss: 0.7063, G loss: 5.8091\n",
      "[5772/8000] D loss: 1.2322, G loss: 1.9857\n",
      "[6132/8000] D loss: 0.7210, G loss: 12.1738\n",
      "[6492/8000] D loss: 0.7642, G loss: 6.8323\n",
      "[6852/8000] D loss: 0.9300, G loss: 7.3952\n",
      "[7212/8000] D loss: 0.5801, G loss: 9.0462\n",
      "[7572/8000] D loss: 1.0619, G loss: 4.5497\n",
      "[7932/8000] D loss: 0.8773, G loss: 5.1204\n",
      "train error: \n",
      " D loss: 0.832444, G loss: 6.793581, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.975792, G loss: 19.627808, D accuracy: 78.3%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7169, G loss: 8.3608\n",
      "[372/8000] D loss: 0.6863, G loss: 4.0493\n",
      "[732/8000] D loss: 0.9659, G loss: 3.8861\n",
      "[1092/8000] D loss: 0.6613, G loss: 3.4719\n",
      "[1452/8000] D loss: 1.0308, G loss: 2.5195\n",
      "[1812/8000] D loss: 0.9319, G loss: 3.6093\n",
      "[2172/8000] D loss: 1.2084, G loss: 1.4938\n",
      "[2532/8000] D loss: 0.5497, G loss: 10.3436\n",
      "[2892/8000] D loss: 0.7917, G loss: 3.6460\n",
      "[3252/8000] D loss: 1.0751, G loss: 5.2619\n",
      "[3612/8000] D loss: 0.9465, G loss: 3.1160\n",
      "[3972/8000] D loss: 0.8182, G loss: 5.7783\n",
      "[4332/8000] D loss: 0.4817, G loss: 12.2545\n",
      "[4692/8000] D loss: 0.6433, G loss: 5.1679\n",
      "[5052/8000] D loss: 0.9434, G loss: 9.5866\n",
      "[5412/8000] D loss: 1.0512, G loss: 4.9074\n",
      "[5772/8000] D loss: 1.0409, G loss: 2.5538\n",
      "[6132/8000] D loss: 1.0663, G loss: 2.2426\n",
      "[6492/8000] D loss: 1.0241, G loss: 4.1971\n",
      "[6852/8000] D loss: 0.7852, G loss: 7.0545\n",
      "[7212/8000] D loss: 0.8964, G loss: 7.9531\n",
      "[7572/8000] D loss: 0.8060, G loss: 3.4911\n",
      "[7932/8000] D loss: 1.0206, G loss: 3.9382\n",
      "train error: \n",
      " D loss: 0.848178, G loss: 5.327600, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.922215, G loss: 16.472141, D accuracy: 81.2%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7605, G loss: 5.8541\n",
      "[372/8000] D loss: 1.0898, G loss: 1.8428\n",
      "[732/8000] D loss: 0.7738, G loss: 7.2565\n",
      "[1092/8000] D loss: 0.7380, G loss: 6.6897\n",
      "[1452/8000] D loss: 1.0026, G loss: 4.2016\n",
      "[1812/8000] D loss: 0.9266, G loss: 6.1924\n",
      "[2172/8000] D loss: 1.0557, G loss: 5.1562\n",
      "[2532/8000] D loss: 0.8018, G loss: 6.7632\n",
      "[2892/8000] D loss: 0.5888, G loss: 9.8701\n",
      "[3252/8000] D loss: 0.7176, G loss: 6.4860\n",
      "[3612/8000] D loss: 0.8511, G loss: 7.9926\n",
      "[3972/8000] D loss: 1.0546, G loss: 5.7109\n",
      "[4332/8000] D loss: 0.5897, G loss: 11.3541\n",
      "[4692/8000] D loss: 0.6960, G loss: 5.9091\n",
      "[5052/8000] D loss: 1.1638, G loss: 3.9455\n",
      "[5412/8000] D loss: 0.5473, G loss: 9.1010\n",
      "[5772/8000] D loss: 0.6380, G loss: 9.6955\n",
      "[6132/8000] D loss: 1.0538, G loss: 5.6951\n",
      "[6492/8000] D loss: 0.8298, G loss: 4.8598\n",
      "[6852/8000] D loss: 0.5843, G loss: 7.1982\n",
      "[7212/8000] D loss: 1.1216, G loss: 4.3591\n",
      "[7572/8000] D loss: 0.9702, G loss: 7.1592\n",
      "[7932/8000] D loss: 0.8678, G loss: 4.0167\n",
      "train error: \n",
      " D loss: 0.858051, G loss: 5.456990, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.041867, G loss: 16.768369, D accuracy: 75.8%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0567, G loss: 2.7681\n",
      "[372/8000] D loss: 0.9035, G loss: 4.8443\n",
      "[732/8000] D loss: 1.1221, G loss: 3.5681\n",
      "[1092/8000] D loss: 1.0819, G loss: 3.4776\n",
      "[1452/8000] D loss: 0.8334, G loss: 4.1902\n",
      "[1812/8000] D loss: 1.1227, G loss: 3.3835\n",
      "[2172/8000] D loss: 0.3376, G loss: 8.4068\n",
      "[2532/8000] D loss: 0.9048, G loss: 5.8733\n",
      "[2892/8000] D loss: 0.9350, G loss: 6.6829\n",
      "[3252/8000] D loss: 1.0275, G loss: 6.4571\n",
      "[3612/8000] D loss: 0.8514, G loss: 4.8581\n",
      "[3972/8000] D loss: 0.8477, G loss: 4.1050\n",
      "[4332/8000] D loss: 0.7772, G loss: 5.1378\n",
      "[4692/8000] D loss: 1.0489, G loss: 3.5079\n",
      "[5052/8000] D loss: 1.0080, G loss: 5.3192\n",
      "[5412/8000] D loss: 0.8023, G loss: 4.0544\n",
      "[5772/8000] D loss: 0.9873, G loss: 7.1744\n",
      "[6132/8000] D loss: 0.9012, G loss: 3.5016\n",
      "[6492/8000] D loss: 0.6823, G loss: 5.8040\n",
      "[6852/8000] D loss: 0.5964, G loss: 9.4521\n",
      "[7212/8000] D loss: 0.7878, G loss: 3.6475\n",
      "[7572/8000] D loss: 0.6171, G loss: 8.4667\n",
      "[7932/8000] D loss: 0.9570, G loss: 9.3844\n",
      "train error: \n",
      " D loss: 0.846758, G loss: 6.443730, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.047769, G loss: 18.119639, D accuracy: 75.8%, cell accuracy: 98.3%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7158, G loss: 4.0351\n",
      "[372/8000] D loss: 0.9147, G loss: 7.8350\n",
      "[732/8000] D loss: 0.9689, G loss: 4.5356\n",
      "[1092/8000] D loss: 1.0864, G loss: 8.1788\n",
      "[1452/8000] D loss: 0.8960, G loss: 2.5221\n",
      "[1812/8000] D loss: 0.7127, G loss: 6.7903\n",
      "[2172/8000] D loss: 0.8724, G loss: 3.4387\n",
      "[2532/8000] D loss: 0.8217, G loss: 6.0951\n",
      "[2892/8000] D loss: 0.5681, G loss: 7.6082\n",
      "[3252/8000] D loss: 0.9037, G loss: 5.4659\n",
      "[3612/8000] D loss: 0.8912, G loss: 4.4591\n",
      "[3972/8000] D loss: 0.5608, G loss: 5.6226\n",
      "[4332/8000] D loss: 0.7057, G loss: 5.6788\n",
      "[4692/8000] D loss: 0.8661, G loss: 5.7318\n",
      "[5052/8000] D loss: 0.5958, G loss: 6.9639\n",
      "[5412/8000] D loss: 0.8938, G loss: 7.9618\n",
      "[5772/8000] D loss: 0.5658, G loss: 14.4791\n",
      "[6132/8000] D loss: 1.1866, G loss: 1.4926\n",
      "[6492/8000] D loss: 0.8489, G loss: 5.6429\n",
      "[6852/8000] D loss: 1.0483, G loss: 3.9807\n",
      "[7212/8000] D loss: 0.9549, G loss: 9.9357\n",
      "[7572/8000] D loss: 0.9900, G loss: 4.7839\n",
      "[7932/8000] D loss: 0.5777, G loss: 11.4915\n",
      "train error: \n",
      " D loss: 0.841973, G loss: 5.655485, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.926682, G loss: 16.804229, D accuracy: 79.1%, cell accuracy: 98.3%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1658, G loss: 1.3371\n",
      "[372/8000] D loss: 0.5164, G loss: 10.1506\n",
      "[732/8000] D loss: 0.8086, G loss: 6.5699\n",
      "[1092/8000] D loss: 0.7123, G loss: 6.6306\n",
      "[1452/8000] D loss: 0.6450, G loss: 10.1943\n",
      "[1812/8000] D loss: 0.6859, G loss: 7.9223\n",
      "[2172/8000] D loss: 0.6906, G loss: 6.0641\n",
      "[2532/8000] D loss: 0.9138, G loss: 9.4260\n",
      "[2892/8000] D loss: 0.9127, G loss: 6.5481\n",
      "[3252/8000] D loss: 0.8950, G loss: 5.3809\n",
      "[3612/8000] D loss: 0.5383, G loss: 4.5198\n",
      "[3972/8000] D loss: 0.7088, G loss: 6.7252\n",
      "[4332/8000] D loss: 0.8195, G loss: 4.3030\n",
      "[4692/8000] D loss: 0.8517, G loss: 4.7354\n",
      "[5052/8000] D loss: 0.6979, G loss: 6.3951\n",
      "[5412/8000] D loss: 0.7598, G loss: 7.9606\n",
      "[5772/8000] D loss: 0.9159, G loss: 8.6891\n",
      "[6132/8000] D loss: 0.5364, G loss: 5.7660\n",
      "[6492/8000] D loss: 1.1035, G loss: 8.4639\n",
      "[6852/8000] D loss: 1.0146, G loss: 4.7327\n",
      "[7212/8000] D loss: 0.6217, G loss: 14.2748\n",
      "[7572/8000] D loss: 0.7919, G loss: 5.7058\n",
      "[7932/8000] D loss: 1.0691, G loss: 2.8300\n",
      "train error: \n",
      " D loss: 0.847460, G loss: 5.494818, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.903023, G loss: 16.831007, D accuracy: 77.8%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7030, G loss: 7.7054\n",
      "[372/8000] D loss: 0.9554, G loss: 2.2125\n",
      "[732/8000] D loss: 1.0134, G loss: 7.3870\n",
      "[1092/8000] D loss: 1.0751, G loss: 1.8763\n",
      "[1452/8000] D loss: 0.6898, G loss: 3.8761\n",
      "[1812/8000] D loss: 0.8207, G loss: 6.3250\n",
      "[2172/8000] D loss: 0.8392, G loss: 9.6011\n",
      "[2532/8000] D loss: 0.5156, G loss: 10.5077\n",
      "[2892/8000] D loss: 0.8328, G loss: 7.1404\n",
      "[3252/8000] D loss: 1.1218, G loss: 1.7105\n",
      "[3612/8000] D loss: 0.8479, G loss: 3.0419\n",
      "[3972/8000] D loss: 0.8749, G loss: 10.6248\n",
      "[4332/8000] D loss: 0.7317, G loss: 10.7085\n",
      "[4692/8000] D loss: 0.9598, G loss: 7.8198\n",
      "[5052/8000] D loss: 1.0184, G loss: 2.2302\n",
      "[5412/8000] D loss: 1.0451, G loss: 5.1819\n",
      "[5772/8000] D loss: 0.5859, G loss: 8.0309\n",
      "[6132/8000] D loss: 0.6811, G loss: 5.6883\n",
      "[6492/8000] D loss: 1.0721, G loss: 4.5021\n",
      "[6852/8000] D loss: 0.9268, G loss: 6.6578\n",
      "[7212/8000] D loss: 0.6288, G loss: 8.1235\n",
      "[7572/8000] D loss: 1.1019, G loss: 2.7419\n",
      "[7932/8000] D loss: 0.6456, G loss: 7.7834\n",
      "train error: \n",
      " D loss: 0.839402, G loss: 6.727109, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.083417, G loss: 19.621045, D accuracy: 77.6%, cell accuracy: 98.3%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9591, G loss: 5.2495\n",
      "[372/8000] D loss: 0.8211, G loss: 8.3070\n",
      "[732/8000] D loss: 0.9269, G loss: 6.8146\n",
      "[1092/8000] D loss: 0.9148, G loss: 3.4076\n",
      "[1452/8000] D loss: 0.8872, G loss: 1.8653\n",
      "[1812/8000] D loss: 0.9404, G loss: 2.9787\n",
      "[2172/8000] D loss: 0.8844, G loss: 3.3312\n",
      "[2532/8000] D loss: 0.6439, G loss: 9.2806\n",
      "[2892/8000] D loss: 0.7096, G loss: 5.6039\n",
      "[3252/8000] D loss: 0.9863, G loss: 3.3425\n",
      "[3612/8000] D loss: 0.9985, G loss: 6.2761\n",
      "[3972/8000] D loss: 0.9396, G loss: 6.5119\n",
      "[4332/8000] D loss: 0.6102, G loss: 4.6805\n",
      "[4692/8000] D loss: 1.0948, G loss: 2.1782\n",
      "[5052/8000] D loss: 0.9098, G loss: 5.7372\n",
      "[5412/8000] D loss: 0.9238, G loss: 4.0919\n",
      "[5772/8000] D loss: 0.7895, G loss: 6.2787\n",
      "[6132/8000] D loss: 0.7030, G loss: 4.9178\n",
      "[6492/8000] D loss: 0.6170, G loss: 9.7225\n",
      "[6852/8000] D loss: 1.0491, G loss: 2.3644\n",
      "[7212/8000] D loss: 0.6789, G loss: 9.7166\n",
      "[7572/8000] D loss: 0.4741, G loss: 5.9125\n",
      "[7932/8000] D loss: 0.8510, G loss: 8.5555\n",
      "train error: \n",
      " D loss: 0.853187, G loss: 6.316429, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.947875, G loss: 18.414692, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1362, G loss: 5.3354\n",
      "[372/8000] D loss: 0.7088, G loss: 6.4844\n",
      "[732/8000] D loss: 0.8454, G loss: 2.5543\n",
      "[1092/8000] D loss: 0.6389, G loss: 6.8697\n",
      "[1452/8000] D loss: 1.0775, G loss: 1.7197\n",
      "[1812/8000] D loss: 0.8233, G loss: 9.8370\n",
      "[2172/8000] D loss: 0.8619, G loss: 6.2861\n",
      "[2532/8000] D loss: 1.0466, G loss: 2.3572\n",
      "[2892/8000] D loss: 0.9325, G loss: 2.9639\n",
      "[3252/8000] D loss: 0.8658, G loss: 7.5776\n",
      "[3612/8000] D loss: 0.8573, G loss: 9.2854\n",
      "[3972/8000] D loss: 1.0708, G loss: 4.8482\n",
      "[4332/8000] D loss: 0.8494, G loss: 7.3722\n",
      "[4692/8000] D loss: 0.8317, G loss: 9.2853\n",
      "[5052/8000] D loss: 0.9930, G loss: 3.8129\n",
      "[5412/8000] D loss: 0.8299, G loss: 5.5513\n",
      "[5772/8000] D loss: 0.7171, G loss: 8.2862\n",
      "[6132/8000] D loss: 0.9689, G loss: 4.5889\n",
      "[6492/8000] D loss: 0.8951, G loss: 5.3287\n",
      "[6852/8000] D loss: 0.5593, G loss: 8.2206\n",
      "[7212/8000] D loss: 1.3676, G loss: 0.6639\n",
      "[7572/8000] D loss: 0.8934, G loss: 4.7687\n",
      "[7932/8000] D loss: 0.6070, G loss: 5.2561\n",
      "train error: \n",
      " D loss: 0.835461, G loss: 6.382808, D accuracy: 72.7%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.962837, G loss: 18.148919, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8606, G loss: 5.0063\n",
      "[372/8000] D loss: 0.9230, G loss: 4.4877\n",
      "[732/8000] D loss: 0.8686, G loss: 6.0685\n",
      "[1092/8000] D loss: 0.6929, G loss: 9.1754\n",
      "[1452/8000] D loss: 0.8997, G loss: 6.0538\n",
      "[1812/8000] D loss: 0.6748, G loss: 13.2122\n",
      "[2172/8000] D loss: 1.0286, G loss: 5.0324\n",
      "[2532/8000] D loss: 0.4835, G loss: 6.6580\n",
      "[2892/8000] D loss: 0.8426, G loss: 10.3045\n",
      "[3252/8000] D loss: 0.7222, G loss: 8.8566\n",
      "[3612/8000] D loss: 0.8164, G loss: 5.3615\n",
      "[3972/8000] D loss: 0.9504, G loss: 6.1731\n",
      "[4332/8000] D loss: 1.0425, G loss: 3.1067\n",
      "[4692/8000] D loss: 1.0779, G loss: 5.4446\n",
      "[5052/8000] D loss: 0.9328, G loss: 3.7945\n",
      "[5412/8000] D loss: 0.7583, G loss: 4.1714\n",
      "[5772/8000] D loss: 1.0894, G loss: 4.3507\n",
      "[6132/8000] D loss: 0.4889, G loss: 10.4988\n",
      "[6492/8000] D loss: 0.8556, G loss: 4.5302\n",
      "[6852/8000] D loss: 1.0490, G loss: 4.8872\n",
      "[7212/8000] D loss: 0.9332, G loss: 4.4011\n",
      "[7572/8000] D loss: 0.6049, G loss: 6.6151\n",
      "[7932/8000] D loss: 0.9308, G loss: 5.7124\n",
      "train error: \n",
      " D loss: 0.844123, G loss: 5.426570, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.918869, G loss: 17.001247, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8795, G loss: 2.8033\n",
      "[372/8000] D loss: 1.0622, G loss: 3.8822\n",
      "[732/8000] D loss: 1.2180, G loss: 3.6717\n",
      "[1092/8000] D loss: 0.8465, G loss: 4.0636\n",
      "[1452/8000] D loss: 0.9327, G loss: 3.9001\n",
      "[1812/8000] D loss: 0.6406, G loss: 7.4598\n",
      "[2172/8000] D loss: 0.7807, G loss: 4.3784\n",
      "[2532/8000] D loss: 0.6874, G loss: 7.7397\n",
      "[2892/8000] D loss: 0.7655, G loss: 7.2601\n",
      "[3252/8000] D loss: 1.0224, G loss: 5.9180\n",
      "[3612/8000] D loss: 0.9479, G loss: 3.8561\n",
      "[3972/8000] D loss: 0.9413, G loss: 7.6731\n",
      "[4332/8000] D loss: 1.4009, G loss: 0.6809\n",
      "[4692/8000] D loss: 1.1456, G loss: 1.3838\n",
      "[5052/8000] D loss: 0.7257, G loss: 3.8008\n",
      "[5412/8000] D loss: 0.7745, G loss: 5.0044\n",
      "[5772/8000] D loss: 1.0008, G loss: 4.1830\n",
      "[6132/8000] D loss: 0.8178, G loss: 7.4457\n",
      "[6492/8000] D loss: 0.8065, G loss: 6.8739\n",
      "[6852/8000] D loss: 0.9355, G loss: 4.2592\n",
      "[7212/8000] D loss: 1.1559, G loss: 8.5114\n",
      "[7572/8000] D loss: 0.4555, G loss: 7.8448\n",
      "[7932/8000] D loss: 1.3069, G loss: 1.0859\n",
      "train error: \n",
      " D loss: 0.844914, G loss: 6.137735, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.933641, G loss: 17.587783, D accuracy: 79.7%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7529, G loss: 4.9230\n",
      "[372/8000] D loss: 1.0158, G loss: 4.8822\n",
      "[732/8000] D loss: 1.1717, G loss: 2.4358\n",
      "[1092/8000] D loss: 1.0194, G loss: 6.6435\n",
      "[1452/8000] D loss: 0.7756, G loss: 5.1017\n",
      "[1812/8000] D loss: 0.7876, G loss: 6.4271\n",
      "[2172/8000] D loss: 0.8258, G loss: 4.0359\n",
      "[2532/8000] D loss: 1.2865, G loss: 0.8916\n",
      "[2892/8000] D loss: 0.8662, G loss: 5.6817\n",
      "[3252/8000] D loss: 0.8662, G loss: 7.3000\n",
      "[3612/8000] D loss: 0.7763, G loss: 8.9237\n",
      "[3972/8000] D loss: 0.8676, G loss: 8.5419\n",
      "[4332/8000] D loss: 0.6983, G loss: 4.7757\n",
      "[4692/8000] D loss: 0.9160, G loss: 7.2141\n",
      "[5052/8000] D loss: 1.1158, G loss: 2.2702\n",
      "[5412/8000] D loss: 1.0958, G loss: 7.2810\n",
      "[5772/8000] D loss: 0.8059, G loss: 4.2188\n",
      "[6132/8000] D loss: 0.8193, G loss: 9.6603\n",
      "[6492/8000] D loss: 0.7686, G loss: 4.8142\n",
      "[6852/8000] D loss: 0.6917, G loss: 10.4189\n",
      "[7212/8000] D loss: 0.9814, G loss: 2.6583\n",
      "[7572/8000] D loss: 0.8857, G loss: 9.7114\n",
      "[7932/8000] D loss: 0.5646, G loss: 9.2240\n",
      "train error: \n",
      " D loss: 0.841688, G loss: 6.744516, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.078982, G loss: 19.062834, D accuracy: 77.0%, cell accuracy: 98.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6850, G loss: 5.1108\n",
      "[372/8000] D loss: 0.9549, G loss: 5.5046\n",
      "[732/8000] D loss: 0.8991, G loss: 8.2833\n",
      "[1092/8000] D loss: 0.7880, G loss: 6.0143\n",
      "[1452/8000] D loss: 1.2504, G loss: 1.5888\n",
      "[1812/8000] D loss: 0.7778, G loss: 5.3281\n",
      "[2172/8000] D loss: 0.7527, G loss: 14.2299\n",
      "[2532/8000] D loss: 0.7583, G loss: 10.4799\n",
      "[2892/8000] D loss: 1.1447, G loss: 1.7971\n",
      "[3252/8000] D loss: 1.0494, G loss: 6.4196\n",
      "[3612/8000] D loss: 0.6361, G loss: 6.3854\n",
      "[3972/8000] D loss: 0.8382, G loss: 7.7812\n",
      "[4332/8000] D loss: 0.6836, G loss: 7.3664\n",
      "[4692/8000] D loss: 0.9551, G loss: 2.7462\n",
      "[5052/8000] D loss: 1.0789, G loss: 5.5608\n",
      "[5412/8000] D loss: 0.9792, G loss: 2.6382\n",
      "[5772/8000] D loss: 0.6411, G loss: 6.2368\n",
      "[6132/8000] D loss: 0.7120, G loss: 9.5877\n",
      "[6492/8000] D loss: 0.6700, G loss: 6.2267\n",
      "[6852/8000] D loss: 0.7190, G loss: 7.7264\n",
      "[7212/8000] D loss: 0.3682, G loss: 14.3627\n",
      "[7572/8000] D loss: 0.7904, G loss: 7.7217\n",
      "[7932/8000] D loss: 0.8972, G loss: 9.2543\n",
      "train error: \n",
      " D loss: 0.856490, G loss: 6.470307, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.080540, G loss: 18.838631, D accuracy: 76.0%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7206, G loss: 10.3864\n",
      "[372/8000] D loss: 0.8437, G loss: 7.7717\n",
      "[732/8000] D loss: 0.9301, G loss: 4.4849\n",
      "[1092/8000] D loss: 0.8400, G loss: 3.9467\n",
      "[1452/8000] D loss: 0.8028, G loss: 3.8456\n",
      "[1812/8000] D loss: 1.1009, G loss: 1.7575\n",
      "[2172/8000] D loss: 0.6383, G loss: 8.9634\n",
      "[2532/8000] D loss: 0.8904, G loss: 8.6403\n",
      "[2892/8000] D loss: 0.9978, G loss: 4.4362\n",
      "[3252/8000] D loss: 0.6897, G loss: 5.6778\n",
      "[3612/8000] D loss: 0.6795, G loss: 3.7217\n",
      "[3972/8000] D loss: 0.8753, G loss: 3.8948\n",
      "[4332/8000] D loss: 1.0383, G loss: 4.3175\n",
      "[4692/8000] D loss: 0.5819, G loss: 6.8888\n",
      "[5052/8000] D loss: 0.9485, G loss: 3.2935\n",
      "[5412/8000] D loss: 0.9303, G loss: 4.6375\n",
      "[5772/8000] D loss: 0.6481, G loss: 5.6957\n",
      "[6132/8000] D loss: 0.8963, G loss: 4.4059\n",
      "[6492/8000] D loss: 0.5604, G loss: 7.7293\n",
      "[6852/8000] D loss: 0.9493, G loss: 1.6457\n",
      "[7212/8000] D loss: 0.8484, G loss: 7.6118\n",
      "[7572/8000] D loss: 0.7635, G loss: 7.4112\n",
      "[7932/8000] D loss: 0.8222, G loss: 4.7995\n",
      "train error: \n",
      " D loss: 0.831310, G loss: 6.828040, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.994733, G loss: 19.798583, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0404, G loss: 4.8546\n",
      "[372/8000] D loss: 0.9658, G loss: 3.7039\n",
      "[732/8000] D loss: 0.7113, G loss: 3.2873\n",
      "[1092/8000] D loss: 0.9339, G loss: 2.8028\n",
      "[1452/8000] D loss: 0.9184, G loss: 3.3138\n",
      "[1812/8000] D loss: 0.9998, G loss: 5.2306\n",
      "[2172/8000] D loss: 0.7676, G loss: 3.9115\n",
      "[2532/8000] D loss: 0.9972, G loss: 3.8616\n",
      "[2892/8000] D loss: 0.7032, G loss: 12.6735\n",
      "[3252/8000] D loss: 0.8296, G loss: 5.9625\n",
      "[3612/8000] D loss: 0.9860, G loss: 3.5037\n",
      "[3972/8000] D loss: 1.1267, G loss: 2.3855\n",
      "[4332/8000] D loss: 0.5901, G loss: 7.4981\n",
      "[4692/8000] D loss: 0.8189, G loss: 8.9124\n",
      "[5052/8000] D loss: 0.7063, G loss: 10.5696\n",
      "[5412/8000] D loss: 0.9652, G loss: 2.4851\n",
      "[5772/8000] D loss: 0.9662, G loss: 3.5135\n",
      "[6132/8000] D loss: 0.9860, G loss: 5.2064\n",
      "[6492/8000] D loss: 1.1310, G loss: 5.3259\n",
      "[6852/8000] D loss: 0.6988, G loss: 9.8491\n",
      "[7212/8000] D loss: 0.7354, G loss: 6.5974\n",
      "[7572/8000] D loss: 0.6474, G loss: 5.8389\n",
      "[7932/8000] D loss: 0.6160, G loss: 8.2319\n",
      "train error: \n",
      " D loss: 0.839143, G loss: 6.342622, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.942525, G loss: 18.687491, D accuracy: 78.3%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7924, G loss: 6.0021\n",
      "[372/8000] D loss: 1.0137, G loss: 3.9792\n",
      "[732/8000] D loss: 1.3249, G loss: 0.9171\n",
      "[1092/8000] D loss: 1.0314, G loss: 2.2705\n",
      "[1452/8000] D loss: 1.0383, G loss: 4.4048\n",
      "[1812/8000] D loss: 0.7174, G loss: 8.0309\n",
      "[2172/8000] D loss: 1.1377, G loss: 2.8092\n",
      "[2532/8000] D loss: 0.9723, G loss: 2.8007\n",
      "[2892/8000] D loss: 0.7169, G loss: 6.4968\n",
      "[3252/8000] D loss: 0.9268, G loss: 8.4798\n",
      "[3612/8000] D loss: 0.7311, G loss: 5.9800\n",
      "[3972/8000] D loss: 0.7413, G loss: 5.0435\n",
      "[4332/8000] D loss: 0.9203, G loss: 2.7249\n",
      "[4692/8000] D loss: 0.8028, G loss: 7.3310\n",
      "[5052/8000] D loss: 0.7110, G loss: 7.4446\n",
      "[5412/8000] D loss: 0.9095, G loss: 3.1455\n",
      "[5772/8000] D loss: 1.3101, G loss: 1.0309\n",
      "[6132/8000] D loss: 0.9140, G loss: 3.0799\n",
      "[6492/8000] D loss: 0.9434, G loss: 3.5896\n",
      "[6852/8000] D loss: 0.7579, G loss: 6.4816\n",
      "[7212/8000] D loss: 0.8290, G loss: 6.2401\n",
      "[7572/8000] D loss: 0.9448, G loss: 7.2678\n",
      "[7932/8000] D loss: 0.9914, G loss: 2.5278\n",
      "train error: \n",
      " D loss: 0.881047, G loss: 4.778088, D accuracy: 71.2%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.105099, G loss: 15.293968, D accuracy: 77.0%, cell accuracy: 98.3%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7721, G loss: 4.5577\n",
      "[372/8000] D loss: 1.3036, G loss: 0.8899\n",
      "[732/8000] D loss: 1.1201, G loss: 2.5994\n",
      "[1092/8000] D loss: 1.0501, G loss: 3.1178\n",
      "[1452/8000] D loss: 0.8864, G loss: 3.6455\n",
      "[1812/8000] D loss: 0.9751, G loss: 4.4456\n",
      "[2172/8000] D loss: 0.8228, G loss: 7.8944\n",
      "[2532/8000] D loss: 0.6582, G loss: 4.7897\n",
      "[2892/8000] D loss: 0.9138, G loss: 6.0203\n",
      "[3252/8000] D loss: 0.9517, G loss: 3.3126\n",
      "[3612/8000] D loss: 0.7556, G loss: 5.1534\n",
      "[3972/8000] D loss: 0.9908, G loss: 7.0501\n",
      "[4332/8000] D loss: 0.9800, G loss: 2.3355\n",
      "[4692/8000] D loss: 0.8323, G loss: 7.9922\n",
      "[5052/8000] D loss: 0.9136, G loss: 4.1984\n",
      "[5412/8000] D loss: 0.6404, G loss: 5.6564\n",
      "[5772/8000] D loss: 0.7551, G loss: 4.3071\n",
      "[6132/8000] D loss: 1.0839, G loss: 4.2090\n",
      "[6492/8000] D loss: 0.7113, G loss: 6.5444\n",
      "[6852/8000] D loss: 0.9297, G loss: 9.7080\n",
      "[7212/8000] D loss: 0.3677, G loss: 6.9659\n",
      "[7572/8000] D loss: 0.6249, G loss: 8.6649\n",
      "[7932/8000] D loss: 1.0506, G loss: 3.5022\n",
      "train error: \n",
      " D loss: 0.838867, G loss: 5.784633, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.978314, G loss: 18.121993, D accuracy: 77.4%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9306, G loss: 7.2546\n",
      "[372/8000] D loss: 0.8353, G loss: 4.6808\n",
      "[732/8000] D loss: 0.7440, G loss: 8.8738\n",
      "[1092/8000] D loss: 0.6519, G loss: 4.3824\n",
      "[1452/8000] D loss: 1.2091, G loss: 3.5656\n",
      "[1812/8000] D loss: 0.7908, G loss: 4.5072\n",
      "[2172/8000] D loss: 0.9402, G loss: 4.6952\n",
      "[2532/8000] D loss: 0.6248, G loss: 7.4100\n",
      "[2892/8000] D loss: 0.8529, G loss: 7.4700\n",
      "[3252/8000] D loss: 0.7993, G loss: 6.0135\n",
      "[3612/8000] D loss: 1.1390, G loss: 2.7917\n",
      "[3972/8000] D loss: 0.3754, G loss: 10.3862\n",
      "[4332/8000] D loss: 0.8406, G loss: 5.3863\n",
      "[4692/8000] D loss: 0.8428, G loss: 5.0794\n",
      "[5052/8000] D loss: 0.8089, G loss: 8.4694\n",
      "[5412/8000] D loss: 0.7675, G loss: 8.1606\n",
      "[5772/8000] D loss: 1.0951, G loss: 2.9356\n",
      "[6132/8000] D loss: 0.8918, G loss: 5.4244\n",
      "[6492/8000] D loss: 0.7285, G loss: 5.3858\n",
      "[6852/8000] D loss: 1.0322, G loss: 3.2134\n",
      "[7212/8000] D loss: 0.6569, G loss: 12.6077\n",
      "[7572/8000] D loss: 0.5384, G loss: 5.0623\n",
      "[7932/8000] D loss: 0.5080, G loss: 9.3510\n",
      "train error: \n",
      " D loss: 0.859240, G loss: 4.912777, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.899753, G loss: 15.162464, D accuracy: 79.3%, cell accuracy: 98.3%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0031, G loss: 5.2341\n",
      "[372/8000] D loss: 0.9355, G loss: 9.1998\n",
      "[732/8000] D loss: 0.8565, G loss: 6.6903\n",
      "[1092/8000] D loss: 0.6876, G loss: 5.9552\n",
      "[1452/8000] D loss: 0.7358, G loss: 5.0215\n",
      "[1812/8000] D loss: 1.0574, G loss: 4.4231\n",
      "[2172/8000] D loss: 0.9193, G loss: 2.3181\n",
      "[2532/8000] D loss: 0.6486, G loss: 7.3234\n",
      "[2892/8000] D loss: 1.0520, G loss: 2.8842\n",
      "[3252/8000] D loss: 0.4791, G loss: 9.4203\n",
      "[3612/8000] D loss: 0.7007, G loss: 6.5284\n",
      "[3972/8000] D loss: 1.0089, G loss: 5.7931\n",
      "[4332/8000] D loss: 0.4884, G loss: 17.5037\n",
      "[4692/8000] D loss: 0.9916, G loss: 2.5339\n",
      "[5052/8000] D loss: 0.5840, G loss: 5.1252\n",
      "[5412/8000] D loss: 0.8519, G loss: 9.6123\n",
      "[5772/8000] D loss: 0.6545, G loss: 5.9955\n",
      "[6132/8000] D loss: 0.8113, G loss: 3.4683\n",
      "[6492/8000] D loss: 0.7264, G loss: 5.3540\n",
      "[6852/8000] D loss: 0.7829, G loss: 11.9830\n",
      "[7212/8000] D loss: 0.7589, G loss: 4.4146\n",
      "[7572/8000] D loss: 0.8153, G loss: 4.7470\n",
      "[7932/8000] D loss: 1.1660, G loss: 5.7456\n",
      "train error: \n",
      " D loss: 0.848880, G loss: 6.781786, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.155921, G loss: 19.311567, D accuracy: 75.6%, cell accuracy: 98.2%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7781, G loss: 7.9145\n",
      "[372/8000] D loss: 0.5840, G loss: 11.8382\n",
      "[732/8000] D loss: 1.0493, G loss: 4.2311\n",
      "[1092/8000] D loss: 0.3816, G loss: 18.0114\n",
      "[1452/8000] D loss: 0.5157, G loss: 13.3569\n",
      "[1812/8000] D loss: 0.8159, G loss: 5.8537\n",
      "[2172/8000] D loss: 1.0151, G loss: 2.1587\n",
      "[2532/8000] D loss: 0.9097, G loss: 2.7633\n",
      "[2892/8000] D loss: 0.6670, G loss: 7.7019\n",
      "[3252/8000] D loss: 0.6903, G loss: 8.1186\n",
      "[3612/8000] D loss: 1.1211, G loss: 5.7045\n",
      "[3972/8000] D loss: 0.5643, G loss: 6.5642\n",
      "[4332/8000] D loss: 0.7262, G loss: 4.8272\n",
      "[4692/8000] D loss: 0.5665, G loss: 20.0557\n",
      "[5052/8000] D loss: 0.9067, G loss: 5.6119\n",
      "[5412/8000] D loss: 0.7293, G loss: 12.7434\n",
      "[5772/8000] D loss: 0.9407, G loss: 3.2923\n",
      "[6132/8000] D loss: 0.7368, G loss: 8.0967\n",
      "[6492/8000] D loss: 0.9345, G loss: 4.9521\n",
      "[6852/8000] D loss: 0.7801, G loss: 13.2123\n",
      "[7212/8000] D loss: 0.8780, G loss: 5.4234\n",
      "[7572/8000] D loss: 0.5393, G loss: 9.8297\n",
      "[7932/8000] D loss: 1.0575, G loss: 4.9613\n",
      "train error: \n",
      " D loss: 0.851374, G loss: 6.190095, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.061489, G loss: 17.631948, D accuracy: 75.1%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0119, G loss: 2.4659\n",
      "[372/8000] D loss: 0.9330, G loss: 3.2667\n",
      "[732/8000] D loss: 0.8189, G loss: 6.9831\n",
      "[1092/8000] D loss: 0.6353, G loss: 6.0520\n",
      "[1452/8000] D loss: 1.0336, G loss: 5.3143\n",
      "[1812/8000] D loss: 0.8621, G loss: 4.9435\n",
      "[2172/8000] D loss: 0.5896, G loss: 3.7430\n",
      "[2532/8000] D loss: 0.7966, G loss: 5.9890\n",
      "[2892/8000] D loss: 1.0904, G loss: 5.1695\n",
      "[3252/8000] D loss: 1.0424, G loss: 5.9452\n",
      "[3612/8000] D loss: 0.9007, G loss: 4.0940\n",
      "[3972/8000] D loss: 0.4932, G loss: 8.2829\n",
      "[4332/8000] D loss: 0.8770, G loss: 8.9235\n",
      "[4692/8000] D loss: 0.5969, G loss: 5.7216\n",
      "[5052/8000] D loss: 1.1603, G loss: 6.1557\n",
      "[5412/8000] D loss: 0.6594, G loss: 6.5618\n",
      "[5772/8000] D loss: 1.1711, G loss: 1.6585\n",
      "[6132/8000] D loss: 0.2527, G loss: 7.0658\n",
      "[6492/8000] D loss: 0.9634, G loss: 2.9654\n",
      "[6852/8000] D loss: 1.1367, G loss: 1.5691\n",
      "[7212/8000] D loss: 1.0341, G loss: 3.8449\n",
      "[7572/8000] D loss: 0.8255, G loss: 8.3551\n",
      "[7932/8000] D loss: 1.0094, G loss: 6.1599\n",
      "train error: \n",
      " D loss: 0.842015, G loss: 6.813901, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.116067, G loss: 18.942201, D accuracy: 76.0%, cell accuracy: 98.2%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6668, G loss: 11.0105\n",
      "[372/8000] D loss: 0.9321, G loss: 5.9158\n",
      "[732/8000] D loss: 0.8627, G loss: 5.1752\n",
      "[1092/8000] D loss: 0.9104, G loss: 4.5716\n",
      "[1452/8000] D loss: 0.7263, G loss: 6.7218\n",
      "[1812/8000] D loss: 1.0724, G loss: 3.9156\n",
      "[2172/8000] D loss: 0.6852, G loss: 8.5356\n",
      "[2532/8000] D loss: 0.9318, G loss: 3.2697\n",
      "[2892/8000] D loss: 0.9227, G loss: 3.5279\n",
      "[3252/8000] D loss: 0.8448, G loss: 4.1570\n",
      "[3612/8000] D loss: 0.7568, G loss: 3.8471\n",
      "[3972/8000] D loss: 0.5688, G loss: 7.8074\n",
      "[4332/8000] D loss: 0.8295, G loss: 2.6979\n",
      "[4692/8000] D loss: 1.0583, G loss: 5.2363\n",
      "[5052/8000] D loss: 0.7975, G loss: 5.3235\n",
      "[5412/8000] D loss: 1.1403, G loss: 4.0296\n",
      "[5772/8000] D loss: 0.8073, G loss: 5.3546\n",
      "[6132/8000] D loss: 0.8082, G loss: 6.1546\n",
      "[6492/8000] D loss: 0.6422, G loss: 11.3956\n",
      "[6852/8000] D loss: 0.9478, G loss: 7.1573\n",
      "[7212/8000] D loss: 0.5488, G loss: 17.1601\n",
      "[7572/8000] D loss: 0.9035, G loss: 5.2803\n",
      "[7932/8000] D loss: 0.8423, G loss: 4.2558\n",
      "train error: \n",
      " D loss: 0.842845, G loss: 7.801802, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.068703, G loss: 21.634419, D accuracy: 75.4%, cell accuracy: 98.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7062, G loss: 7.0804\n",
      "[372/8000] D loss: 1.2255, G loss: 0.9689\n",
      "[732/8000] D loss: 0.9666, G loss: 3.5086\n",
      "[1092/8000] D loss: 0.3556, G loss: 10.7377\n",
      "[1452/8000] D loss: 0.7967, G loss: 3.1229\n",
      "[1812/8000] D loss: 0.6926, G loss: 7.0893\n",
      "[2172/8000] D loss: 1.0347, G loss: 2.6858\n",
      "[2532/8000] D loss: 1.0046, G loss: 3.6005\n",
      "[2892/8000] D loss: 0.7102, G loss: 3.6887\n",
      "[3252/8000] D loss: 0.3520, G loss: 11.1624\n",
      "[3612/8000] D loss: 0.8306, G loss: 2.8168\n",
      "[3972/8000] D loss: 1.0435, G loss: 5.5928\n",
      "[4332/8000] D loss: 1.1024, G loss: 2.2446\n",
      "[4692/8000] D loss: 0.9768, G loss: 3.4717\n",
      "[5052/8000] D loss: 0.4519, G loss: 7.0761\n",
      "[5412/8000] D loss: 0.7598, G loss: 6.2125\n",
      "[5772/8000] D loss: 0.5962, G loss: 11.4029\n",
      "[6132/8000] D loss: 0.8749, G loss: 3.5088\n",
      "[6492/8000] D loss: 0.9474, G loss: 2.8642\n",
      "[6852/8000] D loss: 1.5219, G loss: 0.9677\n",
      "[7212/8000] D loss: 0.8690, G loss: 7.4820\n",
      "[7572/8000] D loss: 0.4385, G loss: 8.1909\n",
      "[7932/8000] D loss: 0.7231, G loss: 5.4681\n",
      "train error: \n",
      " D loss: 0.842269, G loss: 6.239154, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.995844, G loss: 18.170219, D accuracy: 77.4%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1220, G loss: 1.5904\n",
      "[372/8000] D loss: 0.7389, G loss: 6.0551\n",
      "[732/8000] D loss: 0.7014, G loss: 4.8607\n",
      "[1092/8000] D loss: 0.8027, G loss: 6.7440\n",
      "[1452/8000] D loss: 0.8268, G loss: 6.9059\n",
      "[1812/8000] D loss: 0.7003, G loss: 3.6767\n",
      "[2172/8000] D loss: 0.7913, G loss: 7.1056\n",
      "[2532/8000] D loss: 0.8530, G loss: 3.8784\n",
      "[2892/8000] D loss: 1.2056, G loss: 2.3755\n",
      "[3252/8000] D loss: 0.6756, G loss: 4.8238\n",
      "[3612/8000] D loss: 0.8155, G loss: 5.3524\n",
      "[3972/8000] D loss: 0.7023, G loss: 4.5682\n",
      "[4332/8000] D loss: 0.5876, G loss: 9.6481\n",
      "[4692/8000] D loss: 0.9044, G loss: 4.6965\n",
      "[5052/8000] D loss: 0.7636, G loss: 11.7034\n",
      "[5412/8000] D loss: 0.8214, G loss: 5.1743\n",
      "[5772/8000] D loss: 0.5872, G loss: 6.5156\n",
      "[6132/8000] D loss: 0.6133, G loss: 7.7837\n",
      "[6492/8000] D loss: 0.8679, G loss: 6.7950\n",
      "[6852/8000] D loss: 1.0554, G loss: 4.0147\n",
      "[7212/8000] D loss: 0.9390, G loss: 3.3950\n",
      "[7572/8000] D loss: 0.8272, G loss: 9.2193\n",
      "[7932/8000] D loss: 0.7921, G loss: 8.4720\n",
      "train error: \n",
      " D loss: 0.841429, G loss: 6.450108, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.952090, G loss: 18.686643, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8170, G loss: 9.0251\n",
      "[372/8000] D loss: 0.9916, G loss: 7.2201\n",
      "[732/8000] D loss: 1.1897, G loss: 1.6651\n",
      "[1092/8000] D loss: 0.7892, G loss: 7.2032\n",
      "[1452/8000] D loss: 1.1459, G loss: 6.5650\n",
      "[1812/8000] D loss: 0.9943, G loss: 5.7417\n",
      "[2172/8000] D loss: 1.0431, G loss: 5.5330\n",
      "[2532/8000] D loss: 1.0543, G loss: 1.9462\n",
      "[2892/8000] D loss: 0.6936, G loss: 7.4049\n",
      "[3252/8000] D loss: 0.5326, G loss: 6.0991\n",
      "[3612/8000] D loss: 0.7197, G loss: 8.7888\n",
      "[3972/8000] D loss: 0.7615, G loss: 6.2653\n",
      "[4332/8000] D loss: 0.4900, G loss: 9.0204\n",
      "[4692/8000] D loss: 0.8228, G loss: 9.0334\n",
      "[5052/8000] D loss: 0.6768, G loss: 9.7322\n",
      "[5412/8000] D loss: 0.7038, G loss: 8.5754\n",
      "[5772/8000] D loss: 1.1761, G loss: 2.5722\n",
      "[6132/8000] D loss: 0.8388, G loss: 7.4511\n",
      "[6492/8000] D loss: 0.9594, G loss: 3.4263\n",
      "[6852/8000] D loss: 0.4413, G loss: 9.7939\n",
      "[7212/8000] D loss: 0.8552, G loss: 7.3762\n",
      "[7572/8000] D loss: 0.6647, G loss: 5.7610\n",
      "[7932/8000] D loss: 1.0127, G loss: 3.2171\n",
      "train error: \n",
      " D loss: 0.850991, G loss: 5.344513, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.852417, G loss: 17.155759, D accuracy: 81.7%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8748, G loss: 5.4328\n",
      "[372/8000] D loss: 0.7530, G loss: 3.6167\n",
      "[732/8000] D loss: 0.7491, G loss: 6.7445\n",
      "[1092/8000] D loss: 0.9599, G loss: 6.1007\n",
      "[1452/8000] D loss: 0.9873, G loss: 4.5236\n",
      "[1812/8000] D loss: 0.7543, G loss: 9.9910\n",
      "[2172/8000] D loss: 0.8403, G loss: 7.9474\n",
      "[2532/8000] D loss: 0.5810, G loss: 7.8633\n",
      "[2892/8000] D loss: 1.0293, G loss: 3.5134\n",
      "[3252/8000] D loss: 0.8213, G loss: 4.7279\n",
      "[3612/8000] D loss: 0.7445, G loss: 7.7039\n",
      "[3972/8000] D loss: 0.6318, G loss: 6.5873\n",
      "[4332/8000] D loss: 0.8642, G loss: 6.6655\n",
      "[4692/8000] D loss: 0.8270, G loss: 3.3326\n",
      "[5052/8000] D loss: 0.6204, G loss: 5.2872\n",
      "[5412/8000] D loss: 0.9609, G loss: 3.3737\n",
      "[5772/8000] D loss: 0.7533, G loss: 7.2462\n",
      "[6132/8000] D loss: 0.6953, G loss: 8.1730\n",
      "[6492/8000] D loss: 0.8128, G loss: 4.7053\n",
      "[6852/8000] D loss: 0.5815, G loss: 5.9709\n",
      "[7212/8000] D loss: 0.8738, G loss: 5.6674\n",
      "[7572/8000] D loss: 1.0443, G loss: 3.3014\n",
      "[7932/8000] D loss: 0.4164, G loss: 8.9302\n",
      "train error: \n",
      " D loss: 0.845954, G loss: 5.566588, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.019165, G loss: 16.938593, D accuracy: 76.7%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2599, G loss: 1.0802\n",
      "[372/8000] D loss: 0.9350, G loss: 3.4355\n",
      "[732/8000] D loss: 0.9199, G loss: 7.7764\n",
      "[1092/8000] D loss: 1.0758, G loss: 2.5023\n",
      "[1452/8000] D loss: 0.7352, G loss: 5.5737\n",
      "[1812/8000] D loss: 0.5535, G loss: 7.8103\n",
      "[2172/8000] D loss: 0.7401, G loss: 11.0825\n",
      "[2532/8000] D loss: 0.7588, G loss: 3.8329\n",
      "[2892/8000] D loss: 0.9264, G loss: 4.4525\n",
      "[3252/8000] D loss: 0.5284, G loss: 3.9831\n",
      "[3612/8000] D loss: 1.0501, G loss: 4.4647\n",
      "[3972/8000] D loss: 0.8218, G loss: 7.6567\n",
      "[4332/8000] D loss: 0.6021, G loss: 12.1001\n",
      "[4692/8000] D loss: 0.9252, G loss: 2.6651\n",
      "[5052/8000] D loss: 1.0792, G loss: 3.3319\n",
      "[5412/8000] D loss: 0.7507, G loss: 6.1460\n",
      "[5772/8000] D loss: 0.8560, G loss: 5.6661\n",
      "[6132/8000] D loss: 0.9919, G loss: 5.1049\n",
      "[6492/8000] D loss: 0.8014, G loss: 4.2025\n",
      "[6852/8000] D loss: 0.8368, G loss: 4.0277\n",
      "[7212/8000] D loss: 1.0602, G loss: 2.7524\n",
      "[7572/8000] D loss: 0.8835, G loss: 5.8527\n",
      "[7932/8000] D loss: 0.8215, G loss: 8.0028\n",
      "train error: \n",
      " D loss: 0.836655, G loss: 6.846916, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.045437, G loss: 20.515405, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 26.9% \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9675, G loss: 2.7455\n",
      "[372/8000] D loss: 0.5809, G loss: 5.6094\n",
      "[732/8000] D loss: 0.7826, G loss: 5.2745\n",
      "[1092/8000] D loss: 0.4760, G loss: 10.3693\n",
      "[1452/8000] D loss: 1.0750, G loss: 2.1567\n",
      "[1812/8000] D loss: 0.6371, G loss: 4.9723\n",
      "[2172/8000] D loss: 0.4883, G loss: 6.7261\n",
      "[2532/8000] D loss: 0.5828, G loss: 4.6817\n",
      "[2892/8000] D loss: 0.8249, G loss: 3.6271\n",
      "[3252/8000] D loss: 0.8855, G loss: 5.6775\n",
      "[3612/8000] D loss: 0.6020, G loss: 12.5865\n",
      "[3972/8000] D loss: 0.7403, G loss: 4.6811\n",
      "[4332/8000] D loss: 0.7125, G loss: 6.7327\n",
      "[4692/8000] D loss: 0.9159, G loss: 8.2412\n",
      "[5052/8000] D loss: 0.9394, G loss: 5.5245\n",
      "[5412/8000] D loss: 0.5877, G loss: 6.2811\n",
      "[5772/8000] D loss: 0.8658, G loss: 8.6294\n",
      "[6132/8000] D loss: 0.8209, G loss: 4.1596\n",
      "[6492/8000] D loss: 0.7191, G loss: 9.5597\n",
      "[6852/8000] D loss: 0.8378, G loss: 7.8148\n",
      "[7212/8000] D loss: 0.7280, G loss: 6.9255\n",
      "[7572/8000] D loss: 0.7322, G loss: 2.6849\n",
      "[7932/8000] D loss: 0.7037, G loss: 6.8182\n",
      "train error: \n",
      " D loss: 0.849728, G loss: 5.286043, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.057667, G loss: 16.581933, D accuracy: 75.8%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1306, G loss: 4.4125\n",
      "[372/8000] D loss: 0.8014, G loss: 6.7787\n",
      "[732/8000] D loss: 0.6599, G loss: 4.7300\n",
      "[1092/8000] D loss: 1.0126, G loss: 2.6001\n",
      "[1452/8000] D loss: 1.0070, G loss: 4.1409\n",
      "[1812/8000] D loss: 0.5957, G loss: 10.3123\n",
      "[2172/8000] D loss: 0.7292, G loss: 5.6607\n",
      "[2532/8000] D loss: 0.7887, G loss: 5.1545\n",
      "[2892/8000] D loss: 0.8301, G loss: 6.8090\n",
      "[3252/8000] D loss: 1.0134, G loss: 3.9903\n",
      "[3612/8000] D loss: 0.3945, G loss: 20.6625\n",
      "[3972/8000] D loss: 0.7255, G loss: 6.1794\n",
      "[4332/8000] D loss: 0.8285, G loss: 4.6514\n",
      "[4692/8000] D loss: 0.6382, G loss: 6.3261\n",
      "[5052/8000] D loss: 0.6365, G loss: 7.4114\n",
      "[5412/8000] D loss: 0.8901, G loss: 3.5861\n",
      "[5772/8000] D loss: 0.8224, G loss: 5.7586\n",
      "[6132/8000] D loss: 0.5872, G loss: 10.4009\n",
      "[6492/8000] D loss: 0.7624, G loss: 4.1918\n",
      "[6852/8000] D loss: 0.8163, G loss: 11.4707\n",
      "[7212/8000] D loss: 0.6641, G loss: 7.5537\n",
      "[7572/8000] D loss: 0.8956, G loss: 7.2243\n",
      "[7932/8000] D loss: 0.8307, G loss: 4.4934\n",
      "train error: \n",
      " D loss: 0.846790, G loss: 6.247832, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.961960, G loss: 18.892317, D accuracy: 78.1%, cell accuracy: 98.2%, board accuracy: 25.6% \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5481, G loss: 6.4663\n",
      "[372/8000] D loss: 0.7905, G loss: 2.7675\n",
      "[732/8000] D loss: 0.4243, G loss: 14.6925\n",
      "[1092/8000] D loss: 0.8076, G loss: 10.8466\n",
      "[1452/8000] D loss: 1.0565, G loss: 1.3666\n",
      "[1812/8000] D loss: 1.1135, G loss: 6.6218\n",
      "[2172/8000] D loss: 0.7520, G loss: 4.2794\n",
      "[2532/8000] D loss: 0.9746, G loss: 2.5206\n",
      "[2892/8000] D loss: 0.8311, G loss: 9.1519\n",
      "[3252/8000] D loss: 0.8138, G loss: 5.6874\n",
      "[3612/8000] D loss: 0.7216, G loss: 3.3534\n",
      "[3972/8000] D loss: 0.9983, G loss: 3.1548\n",
      "[4332/8000] D loss: 0.5509, G loss: 12.6455\n",
      "[4692/8000] D loss: 0.9305, G loss: 5.3364\n",
      "[5052/8000] D loss: 1.2079, G loss: 1.3874\n",
      "[5412/8000] D loss: 1.0522, G loss: 5.5915\n",
      "[5772/8000] D loss: 0.3516, G loss: 9.7414\n",
      "[6132/8000] D loss: 0.9301, G loss: 5.8050\n",
      "[6492/8000] D loss: 0.6501, G loss: 4.4819\n",
      "[6852/8000] D loss: 1.0090, G loss: 6.1073\n",
      "[7212/8000] D loss: 0.8753, G loss: 2.9481\n",
      "[7572/8000] D loss: 0.9471, G loss: 6.0892\n",
      "[7932/8000] D loss: 0.9577, G loss: 9.9346\n",
      "train error: \n",
      " D loss: 0.885572, G loss: 5.894903, D accuracy: 70.9%, cell accuracy: 98.7%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.937528, G loss: 17.490339, D accuracy: 79.8%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7160, G loss: 5.2012\n",
      "[372/8000] D loss: 0.7580, G loss: 3.8285\n",
      "[732/8000] D loss: 0.6120, G loss: 7.6799\n",
      "[1092/8000] D loss: 0.9612, G loss: 4.6351\n",
      "[1452/8000] D loss: 0.5837, G loss: 8.5181\n",
      "[1812/8000] D loss: 0.8374, G loss: 5.9720\n",
      "[2172/8000] D loss: 0.9507, G loss: 2.9678\n",
      "[2532/8000] D loss: 0.8461, G loss: 6.7756\n",
      "[2892/8000] D loss: 0.8392, G loss: 6.4787\n",
      "[3252/8000] D loss: 0.9642, G loss: 8.3489\n",
      "[3612/8000] D loss: 1.0551, G loss: 4.9220\n",
      "[3972/8000] D loss: 0.4371, G loss: 9.0563\n",
      "[4332/8000] D loss: 0.4536, G loss: 18.8266\n",
      "[4692/8000] D loss: 0.7100, G loss: 4.0496\n",
      "[5052/8000] D loss: 0.8674, G loss: 6.4024\n",
      "[5412/8000] D loss: 0.7127, G loss: 5.4614\n",
      "[5772/8000] D loss: 0.9439, G loss: 2.5468\n",
      "[6132/8000] D loss: 0.5675, G loss: 12.1537\n",
      "[6492/8000] D loss: 0.5673, G loss: 16.8470\n",
      "[6852/8000] D loss: 0.7886, G loss: 7.8237\n",
      "[7212/8000] D loss: 0.9508, G loss: 5.9172\n",
      "[7572/8000] D loss: 0.6009, G loss: 10.4191\n",
      "[7932/8000] D loss: 0.8653, G loss: 3.5954\n",
      "train error: \n",
      " D loss: 0.850951, G loss: 5.226723, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.024971, G loss: 16.095513, D accuracy: 75.9%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2360, G loss: 1.1797\n",
      "[372/8000] D loss: 1.0512, G loss: 6.1863\n",
      "[732/8000] D loss: 1.0630, G loss: 3.8948\n",
      "[1092/8000] D loss: 0.8022, G loss: 7.3550\n",
      "[1452/8000] D loss: 0.4804, G loss: 10.0036\n",
      "[1812/8000] D loss: 1.1235, G loss: 6.5625\n",
      "[2172/8000] D loss: 0.4853, G loss: 9.3180\n",
      "[2532/8000] D loss: 0.5834, G loss: 9.2507\n",
      "[2892/8000] D loss: 0.8492, G loss: 10.0750\n",
      "[3252/8000] D loss: 1.0099, G loss: 4.2322\n",
      "[3612/8000] D loss: 0.7169, G loss: 6.4775\n",
      "[3972/8000] D loss: 0.7837, G loss: 3.6344\n",
      "[4332/8000] D loss: 0.9965, G loss: 7.6010\n",
      "[4692/8000] D loss: 0.8561, G loss: 3.2191\n",
      "[5052/8000] D loss: 1.0601, G loss: 5.0407\n",
      "[5412/8000] D loss: 0.6278, G loss: 8.6517\n",
      "[5772/8000] D loss: 0.8340, G loss: 6.7120\n",
      "[6132/8000] D loss: 0.7421, G loss: 7.4592\n",
      "[6492/8000] D loss: 0.6943, G loss: 3.1177\n",
      "[6852/8000] D loss: 0.8645, G loss: 8.5700\n",
      "[7212/8000] D loss: 0.8821, G loss: 2.7972\n",
      "[7572/8000] D loss: 0.4058, G loss: 11.2952\n",
      "[7932/8000] D loss: 0.8181, G loss: 8.2583\n",
      "train error: \n",
      " D loss: 0.841810, G loss: 6.228935, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.007800, G loss: 18.754005, D accuracy: 75.6%, cell accuracy: 98.2%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9227, G loss: 2.5967\n",
      "[372/8000] D loss: 0.5708, G loss: 6.8945\n",
      "[732/8000] D loss: 0.5046, G loss: 7.2268\n",
      "[1092/8000] D loss: 0.3573, G loss: 12.3420\n",
      "[1452/8000] D loss: 0.8744, G loss: 6.8525\n",
      "[1812/8000] D loss: 1.0810, G loss: 2.9232\n",
      "[2172/8000] D loss: 1.0359, G loss: 3.4885\n",
      "[2532/8000] D loss: 0.7079, G loss: 10.3198\n",
      "[2892/8000] D loss: 0.7826, G loss: 3.6682\n",
      "[3252/8000] D loss: 0.8264, G loss: 4.5061\n",
      "[3612/8000] D loss: 0.9307, G loss: 3.7191\n",
      "[3972/8000] D loss: 1.2206, G loss: 1.7713\n",
      "[4332/8000] D loss: 0.8173, G loss: 4.6466\n",
      "[4692/8000] D loss: 0.9251, G loss: 7.5188\n",
      "[5052/8000] D loss: 0.6551, G loss: 4.5809\n",
      "[5412/8000] D loss: 1.0373, G loss: 4.0734\n",
      "[5772/8000] D loss: 0.6115, G loss: 14.2549\n",
      "[6132/8000] D loss: 0.6972, G loss: 12.6869\n",
      "[6492/8000] D loss: 0.9003, G loss: 8.0977\n",
      "[6852/8000] D loss: 0.7501, G loss: 5.1728\n",
      "[7212/8000] D loss: 0.7749, G loss: 8.2502\n",
      "[7572/8000] D loss: 0.8325, G loss: 6.7442\n",
      "[7932/8000] D loss: 0.9474, G loss: 3.8226\n",
      "train error: \n",
      " D loss: 0.830995, G loss: 6.414282, D accuracy: 72.8%, cell accuracy: 98.7%, board accuracy: 56.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.957625, G loss: 19.461884, D accuracy: 82.0%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7695, G loss: 3.3553\n",
      "[372/8000] D loss: 0.8341, G loss: 7.4230\n",
      "[732/8000] D loss: 1.1840, G loss: 1.7322\n",
      "[1092/8000] D loss: 0.6375, G loss: 6.0714\n",
      "[1452/8000] D loss: 1.1756, G loss: 2.0299\n",
      "[1812/8000] D loss: 0.4740, G loss: 11.5781\n",
      "[2172/8000] D loss: 0.9280, G loss: 5.3788\n",
      "[2532/8000] D loss: 0.6085, G loss: 7.0682\n",
      "[2892/8000] D loss: 0.9279, G loss: 3.0766\n",
      "[3252/8000] D loss: 0.8333, G loss: 6.9457\n",
      "[3612/8000] D loss: 0.9998, G loss: 5.3689\n",
      "[3972/8000] D loss: 1.0102, G loss: 3.9321\n",
      "[4332/8000] D loss: 0.7805, G loss: 4.9153\n",
      "[4692/8000] D loss: 0.6624, G loss: 10.1012\n",
      "[5052/8000] D loss: 0.7527, G loss: 9.0100\n",
      "[5412/8000] D loss: 0.7219, G loss: 4.1400\n",
      "[5772/8000] D loss: 1.0392, G loss: 3.3309\n",
      "[6132/8000] D loss: 0.9579, G loss: 4.0052\n",
      "[6492/8000] D loss: 1.0061, G loss: 2.1308\n",
      "[6852/8000] D loss: 1.0305, G loss: 2.3045\n",
      "[7212/8000] D loss: 0.7080, G loss: 3.8601\n",
      "[7572/8000] D loss: 0.9295, G loss: 3.0172\n",
      "[7932/8000] D loss: 0.7572, G loss: 7.6826\n",
      "train error: \n",
      " D loss: 0.846361, G loss: 5.854176, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.930149, G loss: 18.253270, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7056, G loss: 4.0129\n",
      "[372/8000] D loss: 1.2152, G loss: 4.1597\n",
      "[732/8000] D loss: 0.6340, G loss: 8.7116\n",
      "[1092/8000] D loss: 1.0000, G loss: 4.0235\n",
      "[1452/8000] D loss: 1.2656, G loss: 1.1146\n",
      "[1812/8000] D loss: 0.9316, G loss: 6.0714\n",
      "[2172/8000] D loss: 0.4635, G loss: 14.0181\n",
      "[2532/8000] D loss: 0.9175, G loss: 3.0486\n",
      "[2892/8000] D loss: 0.7572, G loss: 4.4131\n",
      "[3252/8000] D loss: 1.0198, G loss: 4.1959\n",
      "[3612/8000] D loss: 0.6502, G loss: 7.8262\n",
      "[3972/8000] D loss: 0.8053, G loss: 5.1623\n",
      "[4332/8000] D loss: 0.9822, G loss: 9.8686\n",
      "[4692/8000] D loss: 0.7212, G loss: 9.4732\n",
      "[5052/8000] D loss: 0.8142, G loss: 7.9726\n",
      "[5412/8000] D loss: 0.8787, G loss: 6.4430\n",
      "[5772/8000] D loss: 0.9193, G loss: 7.3090\n",
      "[6132/8000] D loss: 1.1071, G loss: 3.9731\n",
      "[6492/8000] D loss: 0.8508, G loss: 4.1904\n",
      "[6852/8000] D loss: 0.9492, G loss: 2.3946\n",
      "[7212/8000] D loss: 0.7050, G loss: 5.5572\n",
      "[7572/8000] D loss: 0.6872, G loss: 6.8792\n",
      "[7932/8000] D loss: 0.7082, G loss: 6.8689\n",
      "train error: \n",
      " D loss: 0.842414, G loss: 6.129270, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.916144, G loss: 17.607009, D accuracy: 80.5%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8287, G loss: 2.8185\n",
      "[372/8000] D loss: 0.5061, G loss: 8.9635\n",
      "[732/8000] D loss: 0.9112, G loss: 5.3621\n",
      "[1092/8000] D loss: 1.1340, G loss: 3.5278\n",
      "[1452/8000] D loss: 0.5394, G loss: 6.4297\n",
      "[1812/8000] D loss: 0.7144, G loss: 9.1600\n",
      "[2172/8000] D loss: 0.8117, G loss: 7.3070\n",
      "[2532/8000] D loss: 0.8418, G loss: 5.0811\n",
      "[2892/8000] D loss: 0.8500, G loss: 6.1524\n",
      "[3252/8000] D loss: 0.6013, G loss: 13.1422\n",
      "[3612/8000] D loss: 1.0275, G loss: 2.7333\n",
      "[3972/8000] D loss: 1.0334, G loss: 4.6279\n",
      "[4332/8000] D loss: 0.4116, G loss: 6.9396\n",
      "[4692/8000] D loss: 0.9802, G loss: 7.4959\n",
      "[5052/8000] D loss: 0.8612, G loss: 3.7125\n",
      "[5412/8000] D loss: 0.7007, G loss: 6.0717\n",
      "[5772/8000] D loss: 0.8204, G loss: 3.1791\n",
      "[6132/8000] D loss: 1.0907, G loss: 6.3503\n",
      "[6492/8000] D loss: 0.8686, G loss: 7.2159\n",
      "[6852/8000] D loss: 1.1370, G loss: 1.8030\n",
      "[7212/8000] D loss: 0.9563, G loss: 2.6073\n",
      "[7572/8000] D loss: 1.1176, G loss: 1.4805\n",
      "[7932/8000] D loss: 0.7178, G loss: 7.3755\n",
      "train error: \n",
      " D loss: 0.848945, G loss: 5.622117, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.945632, G loss: 17.147379, D accuracy: 78.6%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4440, G loss: 9.3198\n",
      "[372/8000] D loss: 0.8121, G loss: 4.4676\n",
      "[732/8000] D loss: 0.8513, G loss: 3.5147\n",
      "[1092/8000] D loss: 0.5168, G loss: 7.0149\n",
      "[1452/8000] D loss: 0.7203, G loss: 6.6076\n",
      "[1812/8000] D loss: 0.6970, G loss: 9.3643\n",
      "[2172/8000] D loss: 0.6582, G loss: 8.0732\n",
      "[2532/8000] D loss: 0.5055, G loss: 10.6714\n",
      "[2892/8000] D loss: 0.8902, G loss: 3.6440\n",
      "[3252/8000] D loss: 0.6113, G loss: 17.2576\n",
      "[3612/8000] D loss: 1.1595, G loss: 3.7646\n",
      "[3972/8000] D loss: 0.7395, G loss: 9.6927\n",
      "[4332/8000] D loss: 0.8214, G loss: 4.5812\n",
      "[4692/8000] D loss: 0.4089, G loss: 8.2640\n",
      "[5052/8000] D loss: 0.6779, G loss: 8.4191\n",
      "[5412/8000] D loss: 0.9600, G loss: 7.2657\n",
      "[5772/8000] D loss: 0.5691, G loss: 10.7401\n",
      "[6132/8000] D loss: 0.6094, G loss: 7.6783\n",
      "[6492/8000] D loss: 0.8129, G loss: 8.4281\n",
      "[6852/8000] D loss: 0.6933, G loss: 6.1823\n",
      "[7212/8000] D loss: 0.8254, G loss: 8.2741\n",
      "[7572/8000] D loss: 0.9146, G loss: 6.6263\n",
      "[7932/8000] D loss: 0.9739, G loss: 9.5552\n",
      "train error: \n",
      " D loss: 0.851689, G loss: 6.742890, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.992035, G loss: 19.277435, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7030, G loss: 7.8688\n",
      "[372/8000] D loss: 0.9529, G loss: 3.8649\n",
      "[732/8000] D loss: 0.7690, G loss: 7.6290\n",
      "[1092/8000] D loss: 0.9706, G loss: 2.4283\n",
      "[1452/8000] D loss: 0.9850, G loss: 6.4798\n",
      "[1812/8000] D loss: 0.6009, G loss: 8.0476\n",
      "[2172/8000] D loss: 0.5880, G loss: 4.3412\n",
      "[2532/8000] D loss: 0.9424, G loss: 5.7119\n",
      "[2892/8000] D loss: 1.0975, G loss: 5.8779\n",
      "[3252/8000] D loss: 0.7153, G loss: 13.4160\n",
      "[3612/8000] D loss: 1.0546, G loss: 6.9072\n",
      "[3972/8000] D loss: 1.0717, G loss: 2.9393\n",
      "[4332/8000] D loss: 0.8204, G loss: 7.9737\n",
      "[4692/8000] D loss: 1.1143, G loss: 5.1363\n",
      "[5052/8000] D loss: 1.0024, G loss: 4.6761\n",
      "[5412/8000] D loss: 0.9776, G loss: 2.8403\n",
      "[5772/8000] D loss: 0.7717, G loss: 5.6885\n",
      "[6132/8000] D loss: 0.7760, G loss: 3.9369\n",
      "[6492/8000] D loss: 0.6426, G loss: 7.2224\n",
      "[6852/8000] D loss: 0.9434, G loss: 4.4543\n",
      "[7212/8000] D loss: 0.8054, G loss: 12.3938\n",
      "[7572/8000] D loss: 0.7039, G loss: 10.2684\n",
      "[7932/8000] D loss: 0.9737, G loss: 4.6131\n",
      "train error: \n",
      " D loss: 0.845805, G loss: 6.409436, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.992932, G loss: 19.137811, D accuracy: 77.7%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8177, G loss: 10.5937\n",
      "[372/8000] D loss: 1.1715, G loss: 2.0191\n",
      "[732/8000] D loss: 0.7511, G loss: 6.4388\n",
      "[1092/8000] D loss: 0.5027, G loss: 6.4631\n",
      "[1452/8000] D loss: 0.9019, G loss: 5.6317\n",
      "[1812/8000] D loss: 1.1593, G loss: 1.1645\n",
      "[2172/8000] D loss: 0.4093, G loss: 10.5945\n",
      "[2532/8000] D loss: 0.5143, G loss: 8.7547\n",
      "[2892/8000] D loss: 0.9392, G loss: 6.5997\n",
      "[3252/8000] D loss: 0.8853, G loss: 11.9522\n",
      "[3612/8000] D loss: 0.4967, G loss: 13.3413\n",
      "[3972/8000] D loss: 0.8074, G loss: 6.8214\n",
      "[4332/8000] D loss: 0.9229, G loss: 5.8090\n",
      "[4692/8000] D loss: 0.7633, G loss: 6.4045\n",
      "[5052/8000] D loss: 0.9311, G loss: 8.2116\n",
      "[5412/8000] D loss: 0.3551, G loss: 9.8563\n",
      "[5772/8000] D loss: 0.6580, G loss: 11.2945\n",
      "[6132/8000] D loss: 0.9712, G loss: 5.3257\n",
      "[6492/8000] D loss: 0.8095, G loss: 5.1980\n",
      "[6852/8000] D loss: 0.9378, G loss: 3.3374\n",
      "[7212/8000] D loss: 0.8184, G loss: 6.1984\n",
      "[7572/8000] D loss: 0.7371, G loss: 8.9450\n",
      "[7932/8000] D loss: 1.1662, G loss: 4.0195\n",
      "train error: \n",
      " D loss: 0.843176, G loss: 6.307125, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.942352, G loss: 18.762388, D accuracy: 80.7%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3329, G loss: 10.2566\n",
      "[372/8000] D loss: 0.8165, G loss: 4.5147\n",
      "[732/8000] D loss: 0.5701, G loss: 7.3220\n",
      "[1092/8000] D loss: 0.8227, G loss: 3.7190\n",
      "[1452/8000] D loss: 0.6928, G loss: 4.4134\n",
      "[1812/8000] D loss: 0.9382, G loss: 1.8583\n",
      "[2172/8000] D loss: 1.0850, G loss: 2.1801\n",
      "[2532/8000] D loss: 0.7012, G loss: 8.0152\n",
      "[2892/8000] D loss: 0.5974, G loss: 10.8618\n",
      "[3252/8000] D loss: 0.8532, G loss: 7.6745\n",
      "[3612/8000] D loss: 0.7985, G loss: 6.6408\n",
      "[3972/8000] D loss: 0.9109, G loss: 5.4166\n",
      "[4332/8000] D loss: 1.0362, G loss: 5.5794\n",
      "[4692/8000] D loss: 0.9352, G loss: 5.7264\n",
      "[5052/8000] D loss: 1.0546, G loss: 3.8720\n",
      "[5412/8000] D loss: 0.6802, G loss: 10.0267\n",
      "[5772/8000] D loss: 0.5278, G loss: 13.9257\n",
      "[6132/8000] D loss: 0.8375, G loss: 6.5064\n",
      "[6492/8000] D loss: 0.9502, G loss: 6.3379\n",
      "[6852/8000] D loss: 0.8938, G loss: 6.2779\n",
      "[7212/8000] D loss: 1.1284, G loss: 9.0899\n",
      "[7572/8000] D loss: 0.7884, G loss: 6.9277\n",
      "[7932/8000] D loss: 0.8276, G loss: 7.0798\n",
      "train error: \n",
      " D loss: 0.830786, G loss: 6.708555, D accuracy: 72.6%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.021891, G loss: 19.129718, D accuracy: 79.2%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8104, G loss: 4.4735\n",
      "[372/8000] D loss: 0.7640, G loss: 9.7757\n",
      "[732/8000] D loss: 0.8328, G loss: 5.9408\n",
      "[1092/8000] D loss: 0.6552, G loss: 11.6189\n",
      "[1452/8000] D loss: 0.9374, G loss: 5.2716\n",
      "[1812/8000] D loss: 0.6522, G loss: 5.3784\n",
      "[2172/8000] D loss: 1.1316, G loss: 10.0860\n",
      "[2532/8000] D loss: 1.0253, G loss: 6.2558\n",
      "[2892/8000] D loss: 1.2507, G loss: 1.7284\n",
      "[3252/8000] D loss: 0.7931, G loss: 4.8715\n",
      "[3612/8000] D loss: 0.6700, G loss: 5.5021\n",
      "[3972/8000] D loss: 1.1086, G loss: 4.1960\n",
      "[4332/8000] D loss: 1.3507, G loss: 0.7613\n",
      "[4692/8000] D loss: 0.9394, G loss: 4.8191\n",
      "[5052/8000] D loss: 0.9792, G loss: 4.0288\n",
      "[5412/8000] D loss: 0.7066, G loss: 11.7347\n",
      "[5772/8000] D loss: 0.7128, G loss: 8.6925\n",
      "[6132/8000] D loss: 0.9894, G loss: 2.6268\n",
      "[6492/8000] D loss: 0.3143, G loss: 16.4430\n",
      "[6852/8000] D loss: 0.9491, G loss: 8.8984\n",
      "[7212/8000] D loss: 0.7688, G loss: 5.0680\n",
      "[7572/8000] D loss: 0.8059, G loss: 13.6618\n",
      "[7932/8000] D loss: 0.7884, G loss: 9.2479\n",
      "train error: \n",
      " D loss: 0.846290, G loss: 6.190466, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.997069, G loss: 18.810039, D accuracy: 80.0%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0823, G loss: 3.9131\n",
      "[372/8000] D loss: 0.8199, G loss: 12.0880\n",
      "[732/8000] D loss: 1.3179, G loss: 0.8106\n",
      "[1092/8000] D loss: 0.8822, G loss: 3.6391\n",
      "[1452/8000] D loss: 0.7457, G loss: 4.2647\n",
      "[1812/8000] D loss: 0.7024, G loss: 8.7976\n",
      "[2172/8000] D loss: 0.8512, G loss: 6.3212\n",
      "[2532/8000] D loss: 0.5222, G loss: 5.4642\n",
      "[2892/8000] D loss: 1.0488, G loss: 3.6297\n",
      "[3252/8000] D loss: 0.7169, G loss: 5.7059\n",
      "[3612/8000] D loss: 0.5776, G loss: 8.2176\n",
      "[3972/8000] D loss: 0.6139, G loss: 10.0982\n",
      "[4332/8000] D loss: 0.9272, G loss: 4.1552\n",
      "[4692/8000] D loss: 0.7812, G loss: 4.8245\n",
      "[5052/8000] D loss: 0.8829, G loss: 5.6849\n",
      "[5412/8000] D loss: 0.7100, G loss: 10.7464\n",
      "[5772/8000] D loss: 0.9042, G loss: 7.6305\n",
      "[6132/8000] D loss: 0.6276, G loss: 8.7918\n",
      "[6492/8000] D loss: 0.8972, G loss: 6.0594\n",
      "[6852/8000] D loss: 0.8365, G loss: 8.7328\n",
      "[7212/8000] D loss: 0.7456, G loss: 3.7408\n",
      "[7572/8000] D loss: 0.9035, G loss: 3.5342\n",
      "[7932/8000] D loss: 0.7124, G loss: 6.1635\n",
      "train error: \n",
      " D loss: 0.839521, G loss: 6.037147, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.108190, G loss: 18.077880, D accuracy: 76.1%, cell accuracy: 98.3%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0380, G loss: 2.3453\n",
      "[372/8000] D loss: 0.7150, G loss: 2.5762\n",
      "[732/8000] D loss: 0.4762, G loss: 11.8722\n",
      "[1092/8000] D loss: 0.5626, G loss: 5.9269\n",
      "[1452/8000] D loss: 1.2752, G loss: 3.4603\n",
      "[1812/8000] D loss: 0.8188, G loss: 4.0244\n",
      "[2172/8000] D loss: 0.9389, G loss: 5.8442\n",
      "[2532/8000] D loss: 0.7689, G loss: 14.0415\n",
      "[2892/8000] D loss: 0.4973, G loss: 14.3325\n",
      "[3252/8000] D loss: 0.8628, G loss: 2.0898\n",
      "[3612/8000] D loss: 1.0080, G loss: 5.4800\n",
      "[3972/8000] D loss: 1.0459, G loss: 4.2980\n",
      "[4332/8000] D loss: 1.2521, G loss: 1.1902\n",
      "[4692/8000] D loss: 0.7417, G loss: 4.4846\n",
      "[5052/8000] D loss: 0.7028, G loss: 7.2459\n",
      "[5412/8000] D loss: 0.6720, G loss: 9.8215\n",
      "[5772/8000] D loss: 0.8892, G loss: 5.7830\n",
      "[6132/8000] D loss: 0.7155, G loss: 9.9251\n",
      "[6492/8000] D loss: 0.8288, G loss: 3.8170\n",
      "[6852/8000] D loss: 0.5396, G loss: 11.0745\n",
      "[7212/8000] D loss: 0.9093, G loss: 2.7475\n",
      "[7572/8000] D loss: 1.0127, G loss: 3.2921\n",
      "[7932/8000] D loss: 0.7761, G loss: 10.2236\n",
      "train error: \n",
      " D loss: 0.843352, G loss: 7.199784, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.055793, G loss: 20.397003, D accuracy: 76.5%, cell accuracy: 98.3%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8551, G loss: 10.0018\n",
      "[372/8000] D loss: 0.7465, G loss: 5.1791\n",
      "[732/8000] D loss: 0.6832, G loss: 2.9187\n",
      "[1092/8000] D loss: 1.0844, G loss: 2.1296\n",
      "[1452/8000] D loss: 0.7893, G loss: 8.4762\n",
      "[1812/8000] D loss: 0.5769, G loss: 6.0683\n",
      "[2172/8000] D loss: 0.8563, G loss: 7.5357\n",
      "[2532/8000] D loss: 0.6246, G loss: 7.3651\n",
      "[2892/8000] D loss: 0.9519, G loss: 2.7429\n",
      "[3252/8000] D loss: 0.5787, G loss: 14.4375\n",
      "[3612/8000] D loss: 0.5681, G loss: 11.4144\n",
      "[3972/8000] D loss: 0.7329, G loss: 5.9003\n",
      "[4332/8000] D loss: 0.9369, G loss: 2.7761\n",
      "[4692/8000] D loss: 0.9141, G loss: 3.9176\n",
      "[5052/8000] D loss: 0.7946, G loss: 7.0604\n",
      "[5412/8000] D loss: 0.9375, G loss: 1.8313\n",
      "[5772/8000] D loss: 1.0358, G loss: 2.3415\n",
      "[6132/8000] D loss: 0.7936, G loss: 4.9012\n",
      "[6492/8000] D loss: 0.9804, G loss: 8.0867\n",
      "[6852/8000] D loss: 0.3794, G loss: 6.9274\n",
      "[7212/8000] D loss: 1.0560, G loss: 2.7876\n",
      "[7572/8000] D loss: 0.9959, G loss: 2.3088\n",
      "[7932/8000] D loss: 0.6413, G loss: 7.8617\n",
      "train error: \n",
      " D loss: 0.846368, G loss: 5.811698, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.945852, G loss: 17.700700, D accuracy: 79.2%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0158, G loss: 3.7466\n",
      "[372/8000] D loss: 0.8620, G loss: 10.3000\n",
      "[732/8000] D loss: 0.2806, G loss: 9.5580\n",
      "[1092/8000] D loss: 0.9399, G loss: 7.9831\n",
      "[1452/8000] D loss: 0.5518, G loss: 7.7120\n",
      "[1812/8000] D loss: 0.9520, G loss: 4.8063\n",
      "[2172/8000] D loss: 0.8384, G loss: 2.7446\n",
      "[2532/8000] D loss: 0.9909, G loss: 2.0409\n",
      "[2892/8000] D loss: 1.1242, G loss: 3.9450\n",
      "[3252/8000] D loss: 1.0522, G loss: 3.5767\n",
      "[3612/8000] D loss: 1.2722, G loss: 1.2988\n",
      "[3972/8000] D loss: 0.9303, G loss: 6.4872\n",
      "[4332/8000] D loss: 0.8670, G loss: 7.6714\n",
      "[4692/8000] D loss: 0.9991, G loss: 3.2897\n",
      "[5052/8000] D loss: 1.0419, G loss: 7.3104\n",
      "[5412/8000] D loss: 0.5535, G loss: 10.7099\n",
      "[5772/8000] D loss: 0.6447, G loss: 12.3176\n",
      "[6132/8000] D loss: 0.9976, G loss: 3.0933\n",
      "[6492/8000] D loss: 0.8655, G loss: 6.3752\n",
      "[6852/8000] D loss: 0.8550, G loss: 6.7552\n",
      "[7212/8000] D loss: 0.6829, G loss: 6.2393\n",
      "[7572/8000] D loss: 0.6693, G loss: 13.8992\n",
      "[7932/8000] D loss: 0.9300, G loss: 5.1435\n",
      "train error: \n",
      " D loss: 0.851092, G loss: 5.835030, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.979608, G loss: 17.665522, D accuracy: 77.0%, cell accuracy: 98.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8585, G loss: 8.6130\n",
      "[372/8000] D loss: 0.9395, G loss: 7.0869\n",
      "[732/8000] D loss: 1.1948, G loss: 1.8675\n",
      "[1092/8000] D loss: 1.2708, G loss: 3.8241\n",
      "[1452/8000] D loss: 0.6964, G loss: 11.0968\n",
      "[1812/8000] D loss: 0.5757, G loss: 12.5435\n",
      "[2172/8000] D loss: 0.8470, G loss: 4.6132\n",
      "[2532/8000] D loss: 0.8229, G loss: 3.6266\n",
      "[2892/8000] D loss: 1.0416, G loss: 6.4339\n",
      "[3252/8000] D loss: 0.8121, G loss: 7.7387\n",
      "[3612/8000] D loss: 0.8112, G loss: 6.9201\n",
      "[3972/8000] D loss: 0.7096, G loss: 9.8934\n",
      "[4332/8000] D loss: 0.8030, G loss: 6.9571\n",
      "[4692/8000] D loss: 0.8238, G loss: 7.5737\n",
      "[5052/8000] D loss: 0.6643, G loss: 5.1475\n",
      "[5412/8000] D loss: 0.6158, G loss: 5.1619\n",
      "[5772/8000] D loss: 0.7296, G loss: 3.0478\n",
      "[6132/8000] D loss: 0.7080, G loss: 4.5791\n",
      "[6492/8000] D loss: 0.7270, G loss: 7.1039\n",
      "[6852/8000] D loss: 0.8115, G loss: 5.2525\n",
      "[7212/8000] D loss: 0.6418, G loss: 12.2991\n",
      "[7572/8000] D loss: 0.6906, G loss: 4.3662\n",
      "[7932/8000] D loss: 0.8214, G loss: 4.4752\n",
      "train error: \n",
      " D loss: 0.881019, G loss: 7.095281, D accuracy: 70.8%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.163158, G loss: 20.298682, D accuracy: 72.6%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9802, G loss: 5.5451\n",
      "[372/8000] D loss: 0.9380, G loss: 5.2196\n",
      "[732/8000] D loss: 0.7002, G loss: 6.8245\n",
      "[1092/8000] D loss: 0.8478, G loss: 7.4575\n",
      "[1452/8000] D loss: 0.6520, G loss: 11.6727\n",
      "[1812/8000] D loss: 1.0157, G loss: 2.8117\n",
      "[2172/8000] D loss: 0.6987, G loss: 6.8173\n",
      "[2532/8000] D loss: 1.1187, G loss: 3.4090\n",
      "[2892/8000] D loss: 0.9052, G loss: 1.8402\n",
      "[3252/8000] D loss: 1.1292, G loss: 4.2748\n",
      "[3612/8000] D loss: 0.9045, G loss: 6.4557\n",
      "[3972/8000] D loss: 0.4739, G loss: 6.9050\n",
      "[4332/8000] D loss: 0.6776, G loss: 7.6430\n",
      "[4692/8000] D loss: 0.9660, G loss: 5.5757\n",
      "[5052/8000] D loss: 0.5802, G loss: 19.2620\n",
      "[5412/8000] D loss: 0.5297, G loss: 5.8437\n",
      "[5772/8000] D loss: 1.0886, G loss: 1.4792\n",
      "[6132/8000] D loss: 0.9080, G loss: 5.8288\n",
      "[6492/8000] D loss: 0.9227, G loss: 4.4810\n",
      "[6852/8000] D loss: 0.8201, G loss: 7.3232\n",
      "[7212/8000] D loss: 0.6188, G loss: 7.4041\n",
      "[7572/8000] D loss: 0.9690, G loss: 2.7816\n",
      "[7932/8000] D loss: 0.4933, G loss: 7.4671\n",
      "train error: \n",
      " D loss: 0.840188, G loss: 6.473089, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.960825, G loss: 18.041821, D accuracy: 79.9%, cell accuracy: 98.2%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7349, G loss: 11.8186\n",
      "[372/8000] D loss: 0.8765, G loss: 5.0855\n",
      "[732/8000] D loss: 0.9248, G loss: 6.7688\n",
      "[1092/8000] D loss: 0.9360, G loss: 2.9358\n",
      "[1452/8000] D loss: 0.7544, G loss: 3.1911\n",
      "[1812/8000] D loss: 0.7466, G loss: 5.4941\n",
      "[2172/8000] D loss: 1.0017, G loss: 6.3827\n",
      "[2532/8000] D loss: 0.8647, G loss: 6.3978\n",
      "[2892/8000] D loss: 0.6064, G loss: 8.3923\n",
      "[3252/8000] D loss: 1.0591, G loss: 2.9619\n",
      "[3612/8000] D loss: 1.0420, G loss: 5.1004\n",
      "[3972/8000] D loss: 0.7059, G loss: 7.5301\n",
      "[4332/8000] D loss: 0.5831, G loss: 9.0048\n",
      "[4692/8000] D loss: 0.9058, G loss: 6.8197\n",
      "[5052/8000] D loss: 0.6380, G loss: 7.4779\n",
      "[5412/8000] D loss: 0.7660, G loss: 7.6885\n",
      "[5772/8000] D loss: 1.0269, G loss: 2.5739\n",
      "[6132/8000] D loss: 0.7620, G loss: 5.3727\n",
      "[6492/8000] D loss: 1.0058, G loss: 4.4544\n",
      "[6852/8000] D loss: 1.0079, G loss: 6.1849\n",
      "[7212/8000] D loss: 0.8252, G loss: 5.1185\n",
      "[7572/8000] D loss: 0.7183, G loss: 8.7676\n",
      "[7932/8000] D loss: 0.7224, G loss: 10.7437\n",
      "train error: \n",
      " D loss: 0.841764, G loss: 6.123818, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.909328, G loss: 18.374856, D accuracy: 79.3%, cell accuracy: 98.3%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0266, G loss: 3.3855\n",
      "[372/8000] D loss: 0.7129, G loss: 8.6722\n",
      "[732/8000] D loss: 0.6542, G loss: 3.5908\n",
      "[1092/8000] D loss: 0.8158, G loss: 3.8239\n",
      "[1452/8000] D loss: 0.8994, G loss: 6.4832\n",
      "[1812/8000] D loss: 0.5948, G loss: 10.4089\n",
      "[2172/8000] D loss: 0.6722, G loss: 10.8824\n",
      "[2532/8000] D loss: 0.7894, G loss: 5.7215\n",
      "[2892/8000] D loss: 0.8082, G loss: 8.6803\n",
      "[3252/8000] D loss: 0.9317, G loss: 4.0441\n",
      "[3612/8000] D loss: 1.1637, G loss: 2.0511\n",
      "[3972/8000] D loss: 0.9237, G loss: 3.2307\n",
      "[4332/8000] D loss: 0.8679, G loss: 9.2440\n",
      "[4692/8000] D loss: 0.6134, G loss: 11.0906\n",
      "[5052/8000] D loss: 1.1257, G loss: 1.5085\n",
      "[5412/8000] D loss: 0.9796, G loss: 4.2375\n",
      "[5772/8000] D loss: 0.9586, G loss: 2.3387\n",
      "[6132/8000] D loss: 1.0139, G loss: 4.5607\n",
      "[6492/8000] D loss: 0.8899, G loss: 9.1727\n",
      "[6852/8000] D loss: 0.7511, G loss: 5.6053\n",
      "[7212/8000] D loss: 0.8969, G loss: 2.9558\n",
      "[7572/8000] D loss: 1.0743, G loss: 2.0669\n",
      "[7932/8000] D loss: 0.9821, G loss: 5.1340\n",
      "train error: \n",
      " D loss: 0.839118, G loss: 6.696037, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999722, G loss: 18.844297, D accuracy: 78.8%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9820, G loss: 3.2743\n",
      "[372/8000] D loss: 0.7739, G loss: 6.9186\n",
      "[732/8000] D loss: 0.8849, G loss: 4.5840\n",
      "[1092/8000] D loss: 1.1347, G loss: 4.2041\n",
      "[1452/8000] D loss: 0.7706, G loss: 6.8613\n",
      "[1812/8000] D loss: 0.8206, G loss: 4.9266\n",
      "[2172/8000] D loss: 0.8000, G loss: 6.5442\n",
      "[2532/8000] D loss: 0.7438, G loss: 5.4992\n",
      "[2892/8000] D loss: 0.7968, G loss: 7.1729\n",
      "[3252/8000] D loss: 0.8306, G loss: 4.5485\n",
      "[3612/8000] D loss: 0.5701, G loss: 7.1411\n",
      "[3972/8000] D loss: 0.8149, G loss: 8.3358\n",
      "[4332/8000] D loss: 0.8651, G loss: 10.1072\n",
      "[4692/8000] D loss: 0.7909, G loss: 5.3642\n",
      "[5052/8000] D loss: 1.1317, G loss: 3.2308\n",
      "[5412/8000] D loss: 0.3938, G loss: 7.5782\n",
      "[5772/8000] D loss: 0.8138, G loss: 8.1773\n",
      "[6132/8000] D loss: 0.7267, G loss: 5.8736\n",
      "[6492/8000] D loss: 0.9498, G loss: 3.5653\n",
      "[6852/8000] D loss: 1.0908, G loss: 3.2221\n",
      "[7212/8000] D loss: 0.9192, G loss: 6.9718\n",
      "[7572/8000] D loss: 1.0242, G loss: 6.1075\n",
      "[7932/8000] D loss: 1.2135, G loss: 5.4295\n",
      "train error: \n",
      " D loss: 0.842330, G loss: 7.605651, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.955900, G loss: 21.328553, D accuracy: 77.7%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6989, G loss: 9.6484\n",
      "[372/8000] D loss: 0.7843, G loss: 6.4029\n",
      "[732/8000] D loss: 0.6538, G loss: 4.3667\n",
      "[1092/8000] D loss: 0.6279, G loss: 7.3192\n",
      "[1452/8000] D loss: 0.4921, G loss: 9.6086\n",
      "[1812/8000] D loss: 1.0399, G loss: 2.5368\n",
      "[2172/8000] D loss: 0.6591, G loss: 9.0805\n",
      "[2532/8000] D loss: 0.6411, G loss: 8.7167\n",
      "[2892/8000] D loss: 0.8077, G loss: 2.7580\n",
      "[3252/8000] D loss: 0.9833, G loss: 7.0274\n",
      "[3612/8000] D loss: 0.6073, G loss: 6.8806\n",
      "[3972/8000] D loss: 1.0902, G loss: 3.2362\n",
      "[4332/8000] D loss: 1.0776, G loss: 1.8876\n",
      "[4692/8000] D loss: 0.8013, G loss: 7.2156\n",
      "[5052/8000] D loss: 0.5911, G loss: 9.3495\n",
      "[5412/8000] D loss: 1.1801, G loss: 4.4865\n",
      "[5772/8000] D loss: 1.0420, G loss: 5.3848\n",
      "[6132/8000] D loss: 1.0559, G loss: 9.7875\n",
      "[6492/8000] D loss: 1.1484, G loss: 1.9030\n",
      "[6852/8000] D loss: 0.7627, G loss: 5.6276\n",
      "[7212/8000] D loss: 0.8056, G loss: 3.1353\n",
      "[7572/8000] D loss: 0.6567, G loss: 6.5857\n",
      "[7932/8000] D loss: 0.8611, G loss: 5.8600\n",
      "train error: \n",
      " D loss: 0.850033, G loss: 6.550260, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.961406, G loss: 19.186493, D accuracy: 77.4%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6931, G loss: 5.4627\n",
      "[372/8000] D loss: 1.2264, G loss: 2.7485\n",
      "[732/8000] D loss: 0.5269, G loss: 14.2486\n",
      "[1092/8000] D loss: 0.7758, G loss: 7.7997\n",
      "[1452/8000] D loss: 0.9094, G loss: 6.6671\n",
      "[1812/8000] D loss: 1.0661, G loss: 1.9060\n",
      "[2172/8000] D loss: 0.8169, G loss: 4.5094\n",
      "[2532/8000] D loss: 1.0631, G loss: 8.7817\n",
      "[2892/8000] D loss: 1.0483, G loss: 2.1628\n",
      "[3252/8000] D loss: 0.5883, G loss: 5.7823\n",
      "[3612/8000] D loss: 0.8267, G loss: 5.4747\n",
      "[3972/8000] D loss: 0.4932, G loss: 8.2940\n",
      "[4332/8000] D loss: 0.5937, G loss: 12.3690\n",
      "[4692/8000] D loss: 1.0303, G loss: 2.1712\n",
      "[5052/8000] D loss: 0.6657, G loss: 9.7693\n",
      "[5412/8000] D loss: 0.4534, G loss: 16.2073\n",
      "[5772/8000] D loss: 1.0434, G loss: 3.1800\n",
      "[6132/8000] D loss: 0.6532, G loss: 5.8070\n",
      "[6492/8000] D loss: 0.9260, G loss: 7.4131\n",
      "[6852/8000] D loss: 0.9464, G loss: 4.5454\n",
      "[7212/8000] D loss: 1.0887, G loss: 2.5001\n",
      "[7572/8000] D loss: 0.8592, G loss: 6.2154\n",
      "[7932/8000] D loss: 0.6597, G loss: 7.9023\n",
      "train error: \n",
      " D loss: 0.861178, G loss: 5.101705, D accuracy: 71.2%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.897155, G loss: 16.345030, D accuracy: 80.1%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7028, G loss: 11.5628\n",
      "[372/8000] D loss: 1.0534, G loss: 2.4275\n",
      "[732/8000] D loss: 0.9342, G loss: 7.8005\n",
      "[1092/8000] D loss: 1.1397, G loss: 3.0578\n",
      "[1452/8000] D loss: 0.9130, G loss: 6.8540\n",
      "[1812/8000] D loss: 0.8056, G loss: 4.0455\n",
      "[2172/8000] D loss: 0.7989, G loss: 6.3045\n",
      "[2532/8000] D loss: 0.9240, G loss: 4.0225\n",
      "[2892/8000] D loss: 1.1862, G loss: 3.8142\n",
      "[3252/8000] D loss: 1.0145, G loss: 3.8378\n",
      "[3612/8000] D loss: 0.9043, G loss: 5.5899\n",
      "[3972/8000] D loss: 1.2530, G loss: 1.3382\n",
      "[4332/8000] D loss: 1.1197, G loss: 2.4196\n",
      "[4692/8000] D loss: 0.9321, G loss: 2.5762\n",
      "[5052/8000] D loss: 0.9125, G loss: 5.3560\n",
      "[5412/8000] D loss: 0.7873, G loss: 5.7427\n",
      "[5772/8000] D loss: 0.8220, G loss: 5.0567\n",
      "[6132/8000] D loss: 0.6572, G loss: 5.7663\n",
      "[6492/8000] D loss: 0.5952, G loss: 9.8539\n",
      "[6852/8000] D loss: 0.7853, G loss: 3.2602\n",
      "[7212/8000] D loss: 0.8592, G loss: 10.5926\n",
      "[7572/8000] D loss: 0.7120, G loss: 5.2406\n",
      "[7932/8000] D loss: 0.7260, G loss: 6.0933\n",
      "train error: \n",
      " D loss: 0.850099, G loss: 7.071286, D accuracy: 71.0%, cell accuracy: 98.7%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.082177, G loss: 20.110187, D accuracy: 74.8%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7054, G loss: 8.0224\n",
      "[372/8000] D loss: 0.9832, G loss: 7.6448\n",
      "[732/8000] D loss: 1.0776, G loss: 2.7646\n",
      "[1092/8000] D loss: 0.8335, G loss: 4.8736\n",
      "[1452/8000] D loss: 0.5859, G loss: 6.6557\n",
      "[1812/8000] D loss: 0.9233, G loss: 4.7187\n",
      "[2172/8000] D loss: 0.8795, G loss: 5.3855\n",
      "[2532/8000] D loss: 0.9356, G loss: 2.0730\n",
      "[2892/8000] D loss: 0.7927, G loss: 4.1971\n",
      "[3252/8000] D loss: 0.8086, G loss: 4.1091\n",
      "[3612/8000] D loss: 0.7334, G loss: 5.7892\n",
      "[3972/8000] D loss: 1.1449, G loss: 2.2526\n",
      "[4332/8000] D loss: 0.8202, G loss: 9.3660\n",
      "[4692/8000] D loss: 0.9288, G loss: 8.2169\n",
      "[5052/8000] D loss: 0.7549, G loss: 7.7688\n",
      "[5412/8000] D loss: 0.7039, G loss: 4.1124\n",
      "[5772/8000] D loss: 0.9025, G loss: 3.2242\n",
      "[6132/8000] D loss: 0.8590, G loss: 9.8805\n",
      "[6492/8000] D loss: 0.9981, G loss: 3.5679\n",
      "[6852/8000] D loss: 1.1516, G loss: 3.5622\n",
      "[7212/8000] D loss: 1.0372, G loss: 2.8826\n",
      "[7572/8000] D loss: 0.9993, G loss: 4.3172\n",
      "[7932/8000] D loss: 0.9148, G loss: 2.7035\n",
      "train error: \n",
      " D loss: 0.861058, G loss: 6.455040, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.980932, G loss: 18.971588, D accuracy: 78.1%, cell accuracy: 98.2%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4424, G loss: 10.1677\n",
      "[372/8000] D loss: 0.6989, G loss: 3.2406\n",
      "[732/8000] D loss: 0.8531, G loss: 6.3629\n",
      "[1092/8000] D loss: 0.5008, G loss: 15.3035\n",
      "[1452/8000] D loss: 1.0463, G loss: 4.7069\n",
      "[1812/8000] D loss: 0.8245, G loss: 2.3638\n",
      "[2172/8000] D loss: 0.6776, G loss: 6.4155\n",
      "[2532/8000] D loss: 0.7607, G loss: 6.4950\n",
      "[2892/8000] D loss: 1.0675, G loss: 7.6436\n",
      "[3252/8000] D loss: 0.8295, G loss: 5.3225\n",
      "[3612/8000] D loss: 0.6009, G loss: 6.6711\n",
      "[3972/8000] D loss: 0.8389, G loss: 3.7335\n",
      "[4332/8000] D loss: 0.6377, G loss: 4.9846\n",
      "[4692/8000] D loss: 0.8172, G loss: 6.6792\n",
      "[5052/8000] D loss: 1.1290, G loss: 2.1965\n",
      "[5412/8000] D loss: 0.5773, G loss: 9.3892\n",
      "[5772/8000] D loss: 0.8220, G loss: 8.0319\n",
      "[6132/8000] D loss: 0.8907, G loss: 3.6604\n",
      "[6492/8000] D loss: 0.7090, G loss: 15.5176\n",
      "[6852/8000] D loss: 1.1443, G loss: 1.6894\n",
      "[7212/8000] D loss: 1.0568, G loss: 5.3728\n",
      "[7572/8000] D loss: 0.8244, G loss: 4.5978\n",
      "[7932/8000] D loss: 0.8370, G loss: 6.5748\n",
      "train error: \n",
      " D loss: 0.884377, G loss: 5.044763, D accuracy: 70.5%, cell accuracy: 98.7%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.031198, G loss: 15.003108, D accuracy: 74.0%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8159, G loss: 5.7195\n",
      "[372/8000] D loss: 1.0478, G loss: 2.6892\n",
      "[732/8000] D loss: 0.9423, G loss: 6.6262\n",
      "[1092/8000] D loss: 0.8224, G loss: 7.6759\n",
      "[1452/8000] D loss: 0.9186, G loss: 5.4942\n",
      "[1812/8000] D loss: 0.9373, G loss: 6.7890\n",
      "[2172/8000] D loss: 0.7100, G loss: 4.0402\n",
      "[2532/8000] D loss: 0.8736, G loss: 7.9158\n",
      "[2892/8000] D loss: 0.7077, G loss: 3.6172\n",
      "[3252/8000] D loss: 0.4527, G loss: 17.3477\n",
      "[3612/8000] D loss: 0.9310, G loss: 2.3424\n",
      "[3972/8000] D loss: 0.6338, G loss: 8.6291\n",
      "[4332/8000] D loss: 0.5916, G loss: 15.6921\n",
      "[4692/8000] D loss: 1.0933, G loss: 2.8664\n",
      "[5052/8000] D loss: 1.1905, G loss: 1.7027\n",
      "[5412/8000] D loss: 0.7026, G loss: 5.5541\n",
      "[5772/8000] D loss: 0.7143, G loss: 7.6015\n",
      "[6132/8000] D loss: 0.5807, G loss: 13.3009\n",
      "[6492/8000] D loss: 0.8098, G loss: 4.0376\n",
      "[6852/8000] D loss: 0.8696, G loss: 8.0806\n",
      "[7212/8000] D loss: 0.5835, G loss: 9.1842\n",
      "[7572/8000] D loss: 0.4823, G loss: 12.7405\n",
      "[7932/8000] D loss: 1.3986, G loss: 0.6036\n",
      "train error: \n",
      " D loss: 0.847146, G loss: 6.453482, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.035048, G loss: 18.504929, D accuracy: 76.9%, cell accuracy: 98.2%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5867, G loss: 20.4101\n",
      "[372/8000] D loss: 0.7356, G loss: 11.9957\n",
      "[732/8000] D loss: 0.8783, G loss: 8.9571\n",
      "[1092/8000] D loss: 0.6520, G loss: 7.9264\n",
      "[1452/8000] D loss: 0.9380, G loss: 3.4499\n",
      "[1812/8000] D loss: 0.8715, G loss: 5.6992\n",
      "[2172/8000] D loss: 0.5854, G loss: 11.4033\n",
      "[2532/8000] D loss: 0.8298, G loss: 10.3430\n",
      "[2892/8000] D loss: 0.7154, G loss: 4.1859\n",
      "[3252/8000] D loss: 1.0391, G loss: 7.7194\n",
      "[3612/8000] D loss: 0.9222, G loss: 4.8430\n",
      "[3972/8000] D loss: 0.2402, G loss: 10.5473\n",
      "[4332/8000] D loss: 0.5152, G loss: 8.6456\n",
      "[4692/8000] D loss: 0.6785, G loss: 6.5964\n",
      "[5052/8000] D loss: 0.9492, G loss: 10.4212\n",
      "[5412/8000] D loss: 0.9691, G loss: 6.3989\n",
      "[5772/8000] D loss: 0.3520, G loss: 11.9956\n",
      "[6132/8000] D loss: 0.6723, G loss: 10.3036\n",
      "[6492/8000] D loss: 0.6853, G loss: 6.3880\n",
      "[6852/8000] D loss: 1.0978, G loss: 5.3698\n",
      "[7212/8000] D loss: 0.8523, G loss: 4.7460\n",
      "[7572/8000] D loss: 0.8783, G loss: 5.8710\n",
      "[7932/8000] D loss: 0.9107, G loss: 2.2389\n",
      "train error: \n",
      " D loss: 0.856956, G loss: 7.006335, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.035810, G loss: 20.072089, D accuracy: 77.1%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8254, G loss: 10.6667\n",
      "[372/8000] D loss: 0.8931, G loss: 6.3705\n",
      "[732/8000] D loss: 0.7178, G loss: 6.2146\n",
      "[1092/8000] D loss: 1.2213, G loss: 2.3385\n",
      "[1452/8000] D loss: 0.7251, G loss: 5.6378\n",
      "[1812/8000] D loss: 0.8080, G loss: 3.7197\n",
      "[2172/8000] D loss: 0.9336, G loss: 4.9110\n",
      "[2532/8000] D loss: 0.8622, G loss: 10.8223\n",
      "[2892/8000] D loss: 0.7011, G loss: 9.5402\n",
      "[3252/8000] D loss: 0.5939, G loss: 9.4921\n",
      "[3612/8000] D loss: 0.5013, G loss: 10.4602\n",
      "[3972/8000] D loss: 0.8583, G loss: 4.7092\n",
      "[4332/8000] D loss: 0.7051, G loss: 10.6054\n",
      "[4692/8000] D loss: 1.0365, G loss: 9.8574\n",
      "[5052/8000] D loss: 0.9037, G loss: 6.5370\n",
      "[5412/8000] D loss: 0.6815, G loss: 14.4986\n",
      "[5772/8000] D loss: 0.7492, G loss: 4.6903\n",
      "[6132/8000] D loss: 0.7051, G loss: 5.9316\n",
      "[6492/8000] D loss: 0.8497, G loss: 6.1162\n",
      "[6852/8000] D loss: 0.9525, G loss: 8.2666\n",
      "[7212/8000] D loss: 0.8086, G loss: 8.9993\n",
      "[7572/8000] D loss: 0.9582, G loss: 3.5716\n",
      "[7932/8000] D loss: 0.5716, G loss: 5.5173\n",
      "train error: \n",
      " D loss: 0.840982, G loss: 5.867800, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.050962, G loss: 17.593269, D accuracy: 77.0%, cell accuracy: 98.2%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8181, G loss: 4.7349\n",
      "[372/8000] D loss: 0.7389, G loss: 9.6662\n",
      "[732/8000] D loss: 0.8098, G loss: 3.8379\n",
      "[1092/8000] D loss: 0.8198, G loss: 5.7550\n",
      "[1452/8000] D loss: 1.0465, G loss: 3.5603\n",
      "[1812/8000] D loss: 0.6786, G loss: 9.5813\n",
      "[2172/8000] D loss: 1.1795, G loss: 5.1112\n",
      "[2532/8000] D loss: 0.6922, G loss: 7.8469\n",
      "[2892/8000] D loss: 0.8289, G loss: 4.8373\n",
      "[3252/8000] D loss: 0.7584, G loss: 3.0921\n",
      "[3612/8000] D loss: 0.7122, G loss: 7.0072\n",
      "[3972/8000] D loss: 1.1123, G loss: 7.8154\n",
      "[4332/8000] D loss: 0.8245, G loss: 5.8008\n",
      "[4692/8000] D loss: 0.5961, G loss: 8.5123\n",
      "[5052/8000] D loss: 0.5292, G loss: 6.5756\n",
      "[5412/8000] D loss: 0.8446, G loss: 6.4992\n",
      "[5772/8000] D loss: 1.2449, G loss: 6.0405\n",
      "[6132/8000] D loss: 0.6926, G loss: 6.7112\n",
      "[6492/8000] D loss: 1.0211, G loss: 3.4650\n",
      "[6852/8000] D loss: 0.8621, G loss: 6.4701\n",
      "[7212/8000] D loss: 0.5528, G loss: 9.2725\n",
      "[7572/8000] D loss: 0.8170, G loss: 5.0127\n",
      "[7932/8000] D loss: 0.8205, G loss: 4.5962\n",
      "train error: \n",
      " D loss: 0.838650, G loss: 7.178915, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.986890, G loss: 20.738624, D accuracy: 78.0%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8125, G loss: 10.7130\n",
      "[372/8000] D loss: 0.7815, G loss: 8.8661\n",
      "[732/8000] D loss: 1.0027, G loss: 3.3166\n",
      "[1092/8000] D loss: 1.0184, G loss: 4.7023\n",
      "[1452/8000] D loss: 0.7100, G loss: 5.6544\n",
      "[1812/8000] D loss: 0.5882, G loss: 9.3574\n",
      "[2172/8000] D loss: 0.7212, G loss: 6.7377\n",
      "[2532/8000] D loss: 0.7807, G loss: 5.2598\n",
      "[2892/8000] D loss: 1.2202, G loss: 4.9034\n",
      "[3252/8000] D loss: 0.8062, G loss: 14.8755\n",
      "[3612/8000] D loss: 0.7516, G loss: 6.4499\n",
      "[3972/8000] D loss: 1.0739, G loss: 9.1778\n",
      "[4332/8000] D loss: 0.9434, G loss: 8.2021\n",
      "[4692/8000] D loss: 0.5433, G loss: 5.1792\n",
      "[5052/8000] D loss: 0.9991, G loss: 12.1416\n",
      "[5412/8000] D loss: 0.7436, G loss: 7.2726\n",
      "[5772/8000] D loss: 0.9240, G loss: 8.2670\n",
      "[6132/8000] D loss: 1.1674, G loss: 6.4446\n",
      "[6492/8000] D loss: 0.7088, G loss: 8.4183\n",
      "[6852/8000] D loss: 0.5461, G loss: 8.6946\n",
      "[7212/8000] D loss: 0.5910, G loss: 7.3586\n",
      "[7572/8000] D loss: 0.6468, G loss: 7.5182\n",
      "[7932/8000] D loss: 1.0539, G loss: 2.5594\n",
      "train error: \n",
      " D loss: 0.841384, G loss: 6.711330, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.034944, G loss: 19.434451, D accuracy: 78.2%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8589, G loss: 5.3986\n",
      "[372/8000] D loss: 0.6240, G loss: 6.3469\n",
      "[732/8000] D loss: 0.4233, G loss: 10.1087\n",
      "[1092/8000] D loss: 0.6914, G loss: 8.3325\n",
      "[1452/8000] D loss: 0.9416, G loss: 4.8541\n",
      "[1812/8000] D loss: 1.0578, G loss: 2.5415\n",
      "[2172/8000] D loss: 0.7869, G loss: 9.1897\n",
      "[2532/8000] D loss: 1.0757, G loss: 4.4989\n",
      "[2892/8000] D loss: 0.8076, G loss: 3.3783\n",
      "[3252/8000] D loss: 1.2289, G loss: 2.6609\n",
      "[3612/8000] D loss: 0.8604, G loss: 3.3576\n",
      "[3972/8000] D loss: 0.9267, G loss: 9.7076\n",
      "[4332/8000] D loss: 1.0362, G loss: 1.8794\n",
      "[4692/8000] D loss: 0.5418, G loss: 12.9831\n",
      "[5052/8000] D loss: 0.7594, G loss: 6.2466\n",
      "[5412/8000] D loss: 0.7010, G loss: 6.8355\n",
      "[5772/8000] D loss: 0.6178, G loss: 10.5324\n",
      "[6132/8000] D loss: 0.9057, G loss: 4.7193\n",
      "[6492/8000] D loss: 0.9259, G loss: 5.9408\n",
      "[6852/8000] D loss: 0.7098, G loss: 7.8700\n",
      "[7212/8000] D loss: 1.0991, G loss: 8.0423\n",
      "[7572/8000] D loss: 0.7055, G loss: 12.2259\n",
      "[7932/8000] D loss: 0.9691, G loss: 2.5198\n",
      "train error: \n",
      " D loss: 0.851123, G loss: 6.773282, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.006405, G loss: 20.018603, D accuracy: 79.1%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8965, G loss: 4.0526\n",
      "[372/8000] D loss: 0.8502, G loss: 6.8926\n",
      "[732/8000] D loss: 0.6955, G loss: 5.9142\n",
      "[1092/8000] D loss: 0.8673, G loss: 7.0774\n",
      "[1452/8000] D loss: 0.6349, G loss: 11.2093\n",
      "[1812/8000] D loss: 0.7072, G loss: 4.7147\n",
      "[2172/8000] D loss: 0.7045, G loss: 12.5216\n",
      "[2532/8000] D loss: 0.8114, G loss: 7.9785\n",
      "[2892/8000] D loss: 0.9218, G loss: 6.0773\n",
      "[3252/8000] D loss: 0.8871, G loss: 3.6119\n",
      "[3612/8000] D loss: 1.0534, G loss: 7.9603\n",
      "[3972/8000] D loss: 1.0527, G loss: 4.2598\n",
      "[4332/8000] D loss: 0.6340, G loss: 12.0955\n",
      "[4692/8000] D loss: 0.4155, G loss: 10.9401\n",
      "[5052/8000] D loss: 0.9287, G loss: 7.7001\n",
      "[5412/8000] D loss: 0.7099, G loss: 8.1079\n",
      "[5772/8000] D loss: 0.2438, G loss: 7.1057\n",
      "[6132/8000] D loss: 1.0188, G loss: 2.2314\n",
      "[6492/8000] D loss: 1.1705, G loss: 7.9738\n",
      "[6852/8000] D loss: 0.8124, G loss: 3.4612\n",
      "[7212/8000] D loss: 1.0500, G loss: 5.4299\n",
      "[7572/8000] D loss: 0.5999, G loss: 9.0947\n",
      "[7932/8000] D loss: 0.9588, G loss: 3.0561\n",
      "train error: \n",
      " D loss: 0.843011, G loss: 6.028379, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.986004, G loss: 17.842745, D accuracy: 78.1%, cell accuracy: 98.2%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0342, G loss: 2.9862\n",
      "[372/8000] D loss: 0.4290, G loss: 5.3715\n",
      "[732/8000] D loss: 0.9133, G loss: 8.0337\n",
      "[1092/8000] D loss: 0.7471, G loss: 10.7281\n",
      "[1452/8000] D loss: 0.5874, G loss: 6.0607\n",
      "[1812/8000] D loss: 0.7891, G loss: 11.3485\n",
      "[2172/8000] D loss: 1.0275, G loss: 3.2238\n",
      "[2532/8000] D loss: 0.5720, G loss: 6.8051\n",
      "[2892/8000] D loss: 0.8807, G loss: 3.8826\n",
      "[3252/8000] D loss: 0.4127, G loss: 15.3599\n",
      "[3612/8000] D loss: 0.7939, G loss: 13.1156\n",
      "[3972/8000] D loss: 0.8272, G loss: 10.7400\n",
      "[4332/8000] D loss: 0.9067, G loss: 4.5472\n",
      "[4692/8000] D loss: 1.3118, G loss: 1.0143\n",
      "[5052/8000] D loss: 0.9139, G loss: 7.0098\n",
      "[5412/8000] D loss: 0.9212, G loss: 4.1468\n",
      "[5772/8000] D loss: 0.8276, G loss: 12.2550\n",
      "[6132/8000] D loss: 1.0111, G loss: 4.3727\n",
      "[6492/8000] D loss: 1.0478, G loss: 6.5190\n",
      "[6852/8000] D loss: 1.1067, G loss: 2.5390\n",
      "[7212/8000] D loss: 0.7004, G loss: 8.9438\n",
      "[7572/8000] D loss: 0.9038, G loss: 2.6898\n",
      "[7932/8000] D loss: 0.9154, G loss: 2.7510\n",
      "train error: \n",
      " D loss: 0.849303, G loss: 6.300551, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.961508, G loss: 19.247449, D accuracy: 79.4%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0270, G loss: 3.4017\n",
      "[372/8000] D loss: 0.7005, G loss: 7.9532\n",
      "[732/8000] D loss: 0.7052, G loss: 6.3105\n",
      "[1092/8000] D loss: 1.0583, G loss: 6.2801\n",
      "[1452/8000] D loss: 0.6132, G loss: 9.2459\n",
      "[1812/8000] D loss: 0.5589, G loss: 13.0725\n",
      "[2172/8000] D loss: 1.0838, G loss: 4.1091\n",
      "[2532/8000] D loss: 0.9136, G loss: 9.9459\n",
      "[2892/8000] D loss: 0.3596, G loss: 12.3118\n",
      "[3252/8000] D loss: 0.4131, G loss: 10.8317\n",
      "[3612/8000] D loss: 0.3532, G loss: 12.0786\n",
      "[3972/8000] D loss: 0.7216, G loss: 10.9930\n",
      "[4332/8000] D loss: 1.1888, G loss: 1.5556\n",
      "[4692/8000] D loss: 0.5808, G loss: 6.5102\n",
      "[5052/8000] D loss: 0.8048, G loss: 6.2872\n",
      "[5412/8000] D loss: 0.5039, G loss: 10.9581\n",
      "[5772/8000] D loss: 0.6180, G loss: 9.5483\n",
      "[6132/8000] D loss: 0.7249, G loss: 7.0939\n",
      "[6492/8000] D loss: 0.5320, G loss: 12.5455\n",
      "[6852/8000] D loss: 0.9066, G loss: 2.8866\n",
      "[7212/8000] D loss: 0.8886, G loss: 5.2366\n",
      "[7572/8000] D loss: 0.4514, G loss: 13.4393\n",
      "[7932/8000] D loss: 0.6719, G loss: 4.3715\n",
      "train error: \n",
      " D loss: 0.848629, G loss: 5.290828, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.909015, G loss: 16.571465, D accuracy: 78.4%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7130, G loss: 7.3918\n",
      "[372/8000] D loss: 1.1859, G loss: 2.6447\n",
      "[732/8000] D loss: 0.8116, G loss: 8.3139\n",
      "[1092/8000] D loss: 0.9923, G loss: 6.6853\n",
      "[1452/8000] D loss: 1.1422, G loss: 3.0811\n",
      "[1812/8000] D loss: 1.1059, G loss: 6.9781\n",
      "[2172/8000] D loss: 1.1309, G loss: 7.2941\n",
      "[2532/8000] D loss: 0.6845, G loss: 7.8420\n",
      "[2892/8000] D loss: 0.4923, G loss: 12.7332\n",
      "[3252/8000] D loss: 0.9404, G loss: 4.8379\n",
      "[3612/8000] D loss: 1.0495, G loss: 3.3445\n",
      "[3972/8000] D loss: 0.6040, G loss: 13.8014\n",
      "[4332/8000] D loss: 0.8220, G loss: 7.5873\n",
      "[4692/8000] D loss: 1.0367, G loss: 3.5360\n",
      "[5052/8000] D loss: 0.6080, G loss: 18.2801\n",
      "[5412/8000] D loss: 0.8800, G loss: 7.6554\n",
      "[5772/8000] D loss: 0.6901, G loss: 4.1597\n",
      "[6132/8000] D loss: 0.5452, G loss: 4.8810\n",
      "[6492/8000] D loss: 0.9509, G loss: 4.1963\n",
      "[6852/8000] D loss: 0.9579, G loss: 6.6317\n",
      "[7212/8000] D loss: 0.9563, G loss: 4.4885\n",
      "[7572/8000] D loss: 0.8302, G loss: 8.4339\n",
      "[7932/8000] D loss: 1.0302, G loss: 4.4172\n",
      "train error: \n",
      " D loss: 0.890198, G loss: 4.312347, D accuracy: 71.0%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.806089, G loss: 15.236157, D accuracy: 82.0%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9561, G loss: 3.8591\n",
      "[372/8000] D loss: 0.7600, G loss: 9.2710\n",
      "[732/8000] D loss: 0.7852, G loss: 7.5021\n",
      "[1092/8000] D loss: 0.8192, G loss: 11.8296\n",
      "[1452/8000] D loss: 0.7680, G loss: 12.9316\n",
      "[1812/8000] D loss: 0.5625, G loss: 16.9224\n",
      "[2172/8000] D loss: 0.7851, G loss: 5.9037\n",
      "[2532/8000] D loss: 1.1153, G loss: 4.1823\n",
      "[2892/8000] D loss: 0.9595, G loss: 7.7116\n",
      "[3252/8000] D loss: 0.7280, G loss: 6.3383\n",
      "[3612/8000] D loss: 0.8439, G loss: 13.0356\n",
      "[3972/8000] D loss: 0.4700, G loss: 13.3667\n",
      "[4332/8000] D loss: 0.9511, G loss: 7.0889\n",
      "[4692/8000] D loss: 0.8145, G loss: 5.7145\n",
      "[5052/8000] D loss: 0.7321, G loss: 3.0828\n",
      "[5412/8000] D loss: 0.6642, G loss: 4.2846\n",
      "[5772/8000] D loss: 0.6037, G loss: 6.8166\n",
      "[6132/8000] D loss: 1.0994, G loss: 1.6591\n",
      "[6492/8000] D loss: 0.7850, G loss: 8.2336\n",
      "[6852/8000] D loss: 0.8093, G loss: 4.9629\n",
      "[7212/8000] D loss: 1.0941, G loss: 4.1324\n",
      "[7572/8000] D loss: 0.8327, G loss: 5.5559\n",
      "[7932/8000] D loss: 0.8833, G loss: 9.7771\n",
      "train error: \n",
      " D loss: 0.844222, G loss: 6.200556, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.981835, G loss: 18.953633, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7739, G loss: 4.0653\n",
      "[372/8000] D loss: 0.8066, G loss: 4.8582\n",
      "[732/8000] D loss: 0.9516, G loss: 5.8994\n",
      "[1092/8000] D loss: 0.8648, G loss: 5.6851\n",
      "[1452/8000] D loss: 0.9257, G loss: 3.9907\n",
      "[1812/8000] D loss: 0.8673, G loss: 8.6765\n",
      "[2172/8000] D loss: 1.0641, G loss: 3.9482\n",
      "[2532/8000] D loss: 0.8228, G loss: 12.6865\n",
      "[2892/8000] D loss: 0.8100, G loss: 4.7513\n",
      "[3252/8000] D loss: 1.0368, G loss: 4.6372\n",
      "[3612/8000] D loss: 0.8117, G loss: 5.8314\n",
      "[3972/8000] D loss: 0.3511, G loss: 9.6959\n",
      "[4332/8000] D loss: 0.9877, G loss: 1.6335\n",
      "[4692/8000] D loss: 1.1482, G loss: 2.3045\n",
      "[5052/8000] D loss: 0.9485, G loss: 2.7066\n",
      "[5412/8000] D loss: 0.7265, G loss: 6.3566\n",
      "[5772/8000] D loss: 0.9937, G loss: 2.5994\n",
      "[6132/8000] D loss: 0.9159, G loss: 5.8981\n",
      "[6492/8000] D loss: 0.8406, G loss: 4.1163\n",
      "[6852/8000] D loss: 1.1841, G loss: 10.9902\n",
      "[7212/8000] D loss: 0.7821, G loss: 6.2216\n",
      "[7572/8000] D loss: 0.7218, G loss: 6.3854\n",
      "[7932/8000] D loss: 0.4722, G loss: 5.4938\n",
      "train error: \n",
      " D loss: 0.850316, G loss: 5.938626, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.936115, G loss: 19.137127, D accuracy: 80.6%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7199, G loss: 9.7599\n",
      "[372/8000] D loss: 0.7930, G loss: 7.8660\n",
      "[732/8000] D loss: 1.0674, G loss: 7.7645\n",
      "[1092/8000] D loss: 0.9723, G loss: 2.1957\n",
      "[1452/8000] D loss: 0.8197, G loss: 4.1766\n",
      "[1812/8000] D loss: 0.7326, G loss: 4.0825\n",
      "[2172/8000] D loss: 0.8759, G loss: 7.6401\n",
      "[2532/8000] D loss: 1.0328, G loss: 4.9710\n",
      "[2892/8000] D loss: 0.9558, G loss: 4.6580\n",
      "[3252/8000] D loss: 0.9201, G loss: 6.4738\n",
      "[3612/8000] D loss: 0.9115, G loss: 7.9396\n",
      "[3972/8000] D loss: 0.7017, G loss: 14.9280\n",
      "[4332/8000] D loss: 0.9211, G loss: 2.5663\n",
      "[4692/8000] D loss: 0.9167, G loss: 10.3209\n",
      "[5052/8000] D loss: 0.8120, G loss: 6.8970\n",
      "[5412/8000] D loss: 0.6925, G loss: 5.7066\n",
      "[5772/8000] D loss: 1.0177, G loss: 5.4947\n",
      "[6132/8000] D loss: 1.0449, G loss: 2.0692\n",
      "[6492/8000] D loss: 0.8677, G loss: 7.4445\n",
      "[6852/8000] D loss: 0.2636, G loss: 10.7047\n",
      "[7212/8000] D loss: 0.9234, G loss: 9.3585\n",
      "[7572/8000] D loss: 0.7302, G loss: 11.7656\n",
      "[7932/8000] D loss: 1.3407, G loss: 1.3612\n",
      "train error: \n",
      " D loss: 0.855208, G loss: 5.927468, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.958836, G loss: 17.591541, D accuracy: 78.1%, cell accuracy: 98.2%, board accuracy: 27.1% \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9103, G loss: 5.6432\n",
      "[372/8000] D loss: 0.5958, G loss: 7.5303\n",
      "[732/8000] D loss: 0.6018, G loss: 6.8646\n",
      "[1092/8000] D loss: 0.9566, G loss: 2.8992\n",
      "[1452/8000] D loss: 0.5796, G loss: 9.1607\n",
      "[1812/8000] D loss: 0.6548, G loss: 7.3800\n",
      "[2172/8000] D loss: 0.7364, G loss: 2.6945\n",
      "[2532/8000] D loss: 1.1051, G loss: 5.4696\n",
      "[2892/8000] D loss: 0.9309, G loss: 2.9436\n",
      "[3252/8000] D loss: 0.9372, G loss: 5.0757\n",
      "[3612/8000] D loss: 0.6167, G loss: 11.6542\n",
      "[3972/8000] D loss: 0.9062, G loss: 3.6967\n",
      "[4332/8000] D loss: 0.6552, G loss: 8.2017\n",
      "[4692/8000] D loss: 0.6000, G loss: 8.3304\n",
      "[5052/8000] D loss: 0.6834, G loss: 6.2970\n",
      "[5412/8000] D loss: 1.1876, G loss: 3.3688\n",
      "[5772/8000] D loss: 0.8107, G loss: 4.9162\n",
      "[6132/8000] D loss: 1.1169, G loss: 6.2450\n",
      "[6492/8000] D loss: 0.8146, G loss: 3.9953\n",
      "[6852/8000] D loss: 1.1204, G loss: 3.4083\n",
      "[7212/8000] D loss: 0.8265, G loss: 7.6014\n",
      "[7572/8000] D loss: 0.5954, G loss: 13.1312\n",
      "[7932/8000] D loss: 0.7091, G loss: 8.4961\n",
      "train error: \n",
      " D loss: 0.858565, G loss: 6.087422, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.932000, G loss: 19.345225, D accuracy: 81.3%, cell accuracy: 98.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6267, G loss: 11.5565\n",
      "[372/8000] D loss: 1.0197, G loss: 4.7303\n",
      "[732/8000] D loss: 0.7514, G loss: 6.0018\n",
      "[1092/8000] D loss: 0.5699, G loss: 5.1752\n",
      "[1452/8000] D loss: 0.8485, G loss: 2.8688\n",
      "[1812/8000] D loss: 0.4866, G loss: 10.2425\n",
      "[2172/8000] D loss: 0.9445, G loss: 4.7085\n",
      "[2532/8000] D loss: 0.9449, G loss: 5.8993\n",
      "[2892/8000] D loss: 0.8244, G loss: 4.9139\n",
      "[3252/8000] D loss: 0.6995, G loss: 5.8264\n",
      "[3612/8000] D loss: 0.7737, G loss: 5.9934\n",
      "[3972/8000] D loss: 0.8757, G loss: 2.9552\n",
      "[4332/8000] D loss: 0.8889, G loss: 5.3493\n",
      "[4692/8000] D loss: 1.0361, G loss: 2.0697\n",
      "[5052/8000] D loss: 0.4815, G loss: 6.8782\n",
      "[5412/8000] D loss: 0.5858, G loss: 7.1992\n",
      "[5772/8000] D loss: 0.6935, G loss: 8.5116\n",
      "[6132/8000] D loss: 0.6747, G loss: 10.7175\n",
      "[6492/8000] D loss: 0.4946, G loss: 8.6978\n",
      "[6852/8000] D loss: 1.2221, G loss: 1.4353\n",
      "[7212/8000] D loss: 0.7997, G loss: 5.8027\n",
      "[7572/8000] D loss: 1.0738, G loss: 5.1949\n",
      "[7932/8000] D loss: 0.9006, G loss: 4.8455\n",
      "train error: \n",
      " D loss: 0.859547, G loss: 6.646855, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.023637, G loss: 19.030063, D accuracy: 78.8%, cell accuracy: 98.3%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9416, G loss: 5.0784\n",
      "[372/8000] D loss: 1.0626, G loss: 9.8308\n",
      "[732/8000] D loss: 1.0395, G loss: 4.4378\n",
      "[1092/8000] D loss: 1.0512, G loss: 8.3365\n",
      "[1452/8000] D loss: 0.4224, G loss: 11.6054\n",
      "[1812/8000] D loss: 0.8164, G loss: 5.1870\n",
      "[2172/8000] D loss: 0.9739, G loss: 3.6977\n",
      "[2532/8000] D loss: 0.7276, G loss: 5.1976\n",
      "[2892/8000] D loss: 0.6943, G loss: 6.8637\n",
      "[3252/8000] D loss: 0.9290, G loss: 3.1706\n",
      "[3612/8000] D loss: 0.8198, G loss: 3.2646\n",
      "[3972/8000] D loss: 0.5837, G loss: 9.8359\n",
      "[4332/8000] D loss: 0.8662, G loss: 6.5581\n",
      "[4692/8000] D loss: 1.0426, G loss: 7.0520\n",
      "[5052/8000] D loss: 0.5344, G loss: 13.1242\n",
      "[5412/8000] D loss: 0.8775, G loss: 6.7754\n",
      "[5772/8000] D loss: 0.9328, G loss: 3.4711\n",
      "[6132/8000] D loss: 0.8762, G loss: 3.0707\n",
      "[6492/8000] D loss: 0.8140, G loss: 7.6176\n",
      "[6852/8000] D loss: 0.9128, G loss: 8.3576\n",
      "[7212/8000] D loss: 0.8393, G loss: 3.3325\n",
      "[7572/8000] D loss: 0.8480, G loss: 6.3188\n",
      "[7932/8000] D loss: 0.8765, G loss: 7.7734\n",
      "train error: \n",
      " D loss: 0.851001, G loss: 6.109199, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.969363, G loss: 19.006573, D accuracy: 78.5%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5917, G loss: 15.1077\n",
      "[372/8000] D loss: 0.8186, G loss: 6.2360\n",
      "[732/8000] D loss: 0.8240, G loss: 9.8441\n",
      "[1092/8000] D loss: 0.7074, G loss: 6.2343\n",
      "[1452/8000] D loss: 0.6919, G loss: 14.2506\n",
      "[1812/8000] D loss: 0.8632, G loss: 6.9515\n",
      "[2172/8000] D loss: 0.9035, G loss: 6.0132\n",
      "[2532/8000] D loss: 0.9284, G loss: 5.8320\n",
      "[2892/8000] D loss: 1.1324, G loss: 2.6229\n",
      "[3252/8000] D loss: 1.0925, G loss: 2.6761\n",
      "[3612/8000] D loss: 0.7795, G loss: 3.8242\n",
      "[3972/8000] D loss: 0.8624, G loss: 6.5368\n",
      "[4332/8000] D loss: 1.0358, G loss: 6.0059\n",
      "[4692/8000] D loss: 0.4369, G loss: 12.2892\n",
      "[5052/8000] D loss: 0.8322, G loss: 6.4737\n",
      "[5412/8000] D loss: 0.9461, G loss: 3.6934\n",
      "[5772/8000] D loss: 0.7022, G loss: 5.9544\n",
      "[6132/8000] D loss: 1.1422, G loss: 2.2317\n",
      "[6492/8000] D loss: 1.1113, G loss: 5.5853\n",
      "[6852/8000] D loss: 0.9448, G loss: 11.6026\n",
      "[7212/8000] D loss: 1.1729, G loss: 2.6530\n",
      "[7572/8000] D loss: 0.8381, G loss: 12.4311\n",
      "[7932/8000] D loss: 0.8941, G loss: 4.6744\n",
      "train error: \n",
      " D loss: 0.854045, G loss: 5.788207, D accuracy: 71.3%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.926697, G loss: 17.940927, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8846, G loss: 8.0897\n",
      "[372/8000] D loss: 0.9391, G loss: 3.6092\n",
      "[732/8000] D loss: 0.7281, G loss: 5.8404\n",
      "[1092/8000] D loss: 1.0182, G loss: 6.3849\n",
      "[1452/8000] D loss: 1.0595, G loss: 5.5822\n",
      "[1812/8000] D loss: 0.7448, G loss: 7.5673\n",
      "[2172/8000] D loss: 0.4392, G loss: 16.0502\n",
      "[2532/8000] D loss: 1.2586, G loss: 1.8714\n",
      "[2892/8000] D loss: 1.0712, G loss: 4.9117\n",
      "[3252/8000] D loss: 1.2408, G loss: 4.2655\n",
      "[3612/8000] D loss: 0.7204, G loss: 4.8390\n",
      "[3972/8000] D loss: 0.5828, G loss: 9.1381\n",
      "[4332/8000] D loss: 0.5892, G loss: 9.4690\n",
      "[4692/8000] D loss: 0.5798, G loss: 7.3573\n",
      "[5052/8000] D loss: 0.6597, G loss: 10.2594\n",
      "[5412/8000] D loss: 0.6755, G loss: 13.3232\n",
      "[5772/8000] D loss: 0.6114, G loss: 9.5900\n",
      "[6132/8000] D loss: 0.9218, G loss: 3.0919\n",
      "[6492/8000] D loss: 0.9102, G loss: 5.8159\n",
      "[6852/8000] D loss: 0.6114, G loss: 12.8780\n",
      "[7212/8000] D loss: 0.7038, G loss: 7.5730\n",
      "[7572/8000] D loss: 0.5933, G loss: 6.7619\n",
      "[7932/8000] D loss: 0.6230, G loss: 4.3640\n",
      "train error: \n",
      " D loss: 0.842522, G loss: 5.734291, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.982976, G loss: 17.645360, D accuracy: 79.5%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8235, G loss: 4.1049\n",
      "[372/8000] D loss: 0.8241, G loss: 4.5072\n",
      "[732/8000] D loss: 0.8523, G loss: 7.3593\n",
      "[1092/8000] D loss: 0.5768, G loss: 5.6626\n",
      "[1452/8000] D loss: 0.7920, G loss: 8.8123\n",
      "[1812/8000] D loss: 0.7475, G loss: 8.3277\n",
      "[2172/8000] D loss: 0.7104, G loss: 3.3477\n",
      "[2532/8000] D loss: 0.8191, G loss: 4.1617\n",
      "[2892/8000] D loss: 0.7735, G loss: 6.1218\n",
      "[3252/8000] D loss: 0.8319, G loss: 9.8061\n",
      "[3612/8000] D loss: 0.7033, G loss: 10.1869\n",
      "[3972/8000] D loss: 0.4723, G loss: 6.8575\n",
      "[4332/8000] D loss: 0.9466, G loss: 1.7105\n",
      "[4692/8000] D loss: 1.0049, G loss: 8.5910\n",
      "[5052/8000] D loss: 1.0024, G loss: 5.6302\n",
      "[5412/8000] D loss: 0.7739, G loss: 7.3768\n",
      "[5772/8000] D loss: 0.8542, G loss: 7.4565\n",
      "[6132/8000] D loss: 0.8152, G loss: 3.4319\n",
      "[6492/8000] D loss: 0.8125, G loss: 5.5155\n",
      "[6852/8000] D loss: 1.1003, G loss: 3.4180\n",
      "[7212/8000] D loss: 0.9051, G loss: 5.3679\n",
      "[7572/8000] D loss: 0.9463, G loss: 3.0853\n",
      "[7932/8000] D loss: 1.0727, G loss: 4.9423\n",
      "train error: \n",
      " D loss: 0.914578, G loss: 6.972333, D accuracy: 70.7%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.158153, G loss: 19.370296, D accuracy: 73.5%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7546, G loss: 9.8703\n",
      "[372/8000] D loss: 0.8927, G loss: 2.8176\n",
      "[732/8000] D loss: 0.9781, G loss: 7.1771\n",
      "[1092/8000] D loss: 0.8270, G loss: 5.2257\n",
      "[1452/8000] D loss: 0.9452, G loss: 7.1453\n",
      "[1812/8000] D loss: 0.8139, G loss: 4.6955\n",
      "[2172/8000] D loss: 0.8944, G loss: 7.6363\n",
      "[2532/8000] D loss: 0.3976, G loss: 13.5991\n",
      "[2892/8000] D loss: 0.7417, G loss: 6.0820\n",
      "[3252/8000] D loss: 0.6183, G loss: 7.5518\n",
      "[3612/8000] D loss: 0.8854, G loss: 7.9737\n",
      "[3972/8000] D loss: 0.5373, G loss: 11.9079\n",
      "[4332/8000] D loss: 0.7002, G loss: 7.6141\n",
      "[4692/8000] D loss: 0.7717, G loss: 8.9368\n",
      "[5052/8000] D loss: 1.1681, G loss: 5.7439\n",
      "[5412/8000] D loss: 0.8149, G loss: 9.6603\n",
      "[5772/8000] D loss: 0.9578, G loss: 8.0899\n",
      "[6132/8000] D loss: 1.1316, G loss: 2.0925\n",
      "[6492/8000] D loss: 1.3384, G loss: 2.7886\n",
      "[6852/8000] D loss: 0.9823, G loss: 3.5238\n",
      "[7212/8000] D loss: 0.8602, G loss: 11.4067\n",
      "[7572/8000] D loss: 0.7569, G loss: 9.6255\n",
      "[7932/8000] D loss: 1.1531, G loss: 6.3162\n",
      "train error: \n",
      " D loss: 0.845773, G loss: 5.969880, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.985428, G loss: 18.487178, D accuracy: 79.1%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8173, G loss: 5.3020\n",
      "[372/8000] D loss: 0.8752, G loss: 6.7330\n",
      "[732/8000] D loss: 0.8301, G loss: 4.5566\n",
      "[1092/8000] D loss: 0.5869, G loss: 15.4078\n",
      "[1452/8000] D loss: 0.7355, G loss: 8.8066\n",
      "[1812/8000] D loss: 1.0492, G loss: 2.9904\n",
      "[2172/8000] D loss: 0.8300, G loss: 5.6510\n",
      "[2532/8000] D loss: 0.9004, G loss: 7.1338\n",
      "[2892/8000] D loss: 0.8410, G loss: 3.9947\n",
      "[3252/8000] D loss: 0.5669, G loss: 8.5512\n",
      "[3612/8000] D loss: 0.8298, G loss: 10.7500\n",
      "[3972/8000] D loss: 0.6803, G loss: 7.6557\n",
      "[4332/8000] D loss: 0.7045, G loss: 7.6931\n",
      "[4692/8000] D loss: 0.6247, G loss: 8.3929\n",
      "[5052/8000] D loss: 0.9336, G loss: 2.5225\n",
      "[5412/8000] D loss: 0.7842, G loss: 3.8875\n",
      "[5772/8000] D loss: 0.9596, G loss: 10.1291\n",
      "[6132/8000] D loss: 0.9397, G loss: 9.2341\n",
      "[6492/8000] D loss: 0.6961, G loss: 11.5147\n",
      "[6852/8000] D loss: 0.8280, G loss: 6.4728\n",
      "[7212/8000] D loss: 0.8101, G loss: 2.9645\n",
      "[7572/8000] D loss: 1.1567, G loss: 3.0253\n",
      "[7932/8000] D loss: 0.8670, G loss: 8.7333\n",
      "train error: \n",
      " D loss: 0.863137, G loss: 5.836049, D accuracy: 71.3%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.907032, G loss: 18.091791, D accuracy: 81.5%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8815, G loss: 5.1839\n",
      "[372/8000] D loss: 0.6387, G loss: 13.4628\n",
      "[732/8000] D loss: 1.0580, G loss: 5.2195\n",
      "[1092/8000] D loss: 1.0361, G loss: 4.7001\n",
      "[1452/8000] D loss: 0.6987, G loss: 5.2059\n",
      "[1812/8000] D loss: 0.7128, G loss: 4.8820\n",
      "[2172/8000] D loss: 0.9055, G loss: 3.6378\n",
      "[2532/8000] D loss: 0.9823, G loss: 4.0944\n",
      "[2892/8000] D loss: 0.9179, G loss: 5.3443\n",
      "[3252/8000] D loss: 0.7011, G loss: 8.0101\n",
      "[3612/8000] D loss: 0.9082, G loss: 2.4819\n",
      "[3972/8000] D loss: 0.8351, G loss: 4.5956\n",
      "[4332/8000] D loss: 0.9116, G loss: 3.8458\n",
      "[4692/8000] D loss: 0.5804, G loss: 7.4639\n",
      "[5052/8000] D loss: 1.0007, G loss: 2.6076\n",
      "[5412/8000] D loss: 0.5954, G loss: 4.9577\n",
      "[5772/8000] D loss: 0.8181, G loss: 5.5451\n",
      "[6132/8000] D loss: 0.6522, G loss: 11.6597\n",
      "[6492/8000] D loss: 0.9411, G loss: 3.3324\n",
      "[6852/8000] D loss: 0.5750, G loss: 10.5288\n",
      "[7212/8000] D loss: 0.9193, G loss: 7.2037\n",
      "[7572/8000] D loss: 1.1221, G loss: 3.8343\n",
      "[7932/8000] D loss: 1.1503, G loss: 3.3889\n",
      "train error: \n",
      " D loss: 0.846065, G loss: 5.826907, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.033478, G loss: 17.881512, D accuracy: 78.3%, cell accuracy: 98.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0174, G loss: 4.0140\n",
      "[372/8000] D loss: 1.0538, G loss: 3.9383\n",
      "[732/8000] D loss: 0.6955, G loss: 4.6806\n",
      "[1092/8000] D loss: 0.6375, G loss: 11.4496\n",
      "[1452/8000] D loss: 1.0198, G loss: 7.4428\n",
      "[1812/8000] D loss: 0.5699, G loss: 6.5886\n",
      "[2172/8000] D loss: 1.1021, G loss: 5.8214\n",
      "[2532/8000] D loss: 0.4694, G loss: 7.1226\n",
      "[2892/8000] D loss: 0.9479, G loss: 6.6635\n",
      "[3252/8000] D loss: 1.0538, G loss: 3.4716\n",
      "[3612/8000] D loss: 0.8003, G loss: 6.1745\n",
      "[3972/8000] D loss: 1.0664, G loss: 7.2309\n",
      "[4332/8000] D loss: 1.1527, G loss: 2.5248\n",
      "[4692/8000] D loss: 0.5895, G loss: 12.4886\n",
      "[5052/8000] D loss: 0.5959, G loss: 10.2143\n",
      "[5412/8000] D loss: 0.8060, G loss: 9.0326\n",
      "[5772/8000] D loss: 1.0334, G loss: 3.7216\n",
      "[6132/8000] D loss: 0.9716, G loss: 4.8502\n",
      "[6492/8000] D loss: 0.9918, G loss: 5.5288\n",
      "[6852/8000] D loss: 0.5408, G loss: 10.9066\n",
      "[7212/8000] D loss: 0.6744, G loss: 7.7370\n",
      "[7572/8000] D loss: 0.5712, G loss: 8.3148\n",
      "[7932/8000] D loss: 0.9334, G loss: 3.5325\n",
      "train error: \n",
      " D loss: 0.843870, G loss: 7.533407, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.086941, G loss: 21.370056, D accuracy: 76.2%, cell accuracy: 98.2%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1107, G loss: 3.5004\n",
      "[372/8000] D loss: 0.6243, G loss: 9.6106\n",
      "[732/8000] D loss: 0.8980, G loss: 3.5801\n",
      "[1092/8000] D loss: 0.9291, G loss: 9.4235\n",
      "[1452/8000] D loss: 0.9632, G loss: 3.0992\n",
      "[1812/8000] D loss: 0.8309, G loss: 4.8244\n",
      "[2172/8000] D loss: 0.9961, G loss: 6.2751\n",
      "[2532/8000] D loss: 0.9603, G loss: 5.4549\n",
      "[2892/8000] D loss: 1.0452, G loss: 3.8940\n",
      "[3252/8000] D loss: 0.9933, G loss: 7.7170\n",
      "[3612/8000] D loss: 0.9009, G loss: 7.5485\n",
      "[3972/8000] D loss: 0.8300, G loss: 3.1687\n",
      "[4332/8000] D loss: 0.7731, G loss: 7.1751\n",
      "[4692/8000] D loss: 0.7506, G loss: 6.8088\n",
      "[5052/8000] D loss: 0.5920, G loss: 9.5834\n",
      "[5412/8000] D loss: 0.9460, G loss: 2.2765\n",
      "[5772/8000] D loss: 1.0451, G loss: 3.6923\n",
      "[6132/8000] D loss: 0.5442, G loss: 9.2426\n",
      "[6492/8000] D loss: 0.8774, G loss: 4.6380\n",
      "[6852/8000] D loss: 0.7522, G loss: 7.2488\n",
      "[7212/8000] D loss: 0.7936, G loss: 5.0589\n",
      "[7572/8000] D loss: 1.0464, G loss: 2.2287\n",
      "[7932/8000] D loss: 0.9345, G loss: 2.4070\n",
      "train error: \n",
      " D loss: 0.843904, G loss: 6.259307, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.948833, G loss: 19.531756, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8705, G loss: 5.0891\n",
      "[372/8000] D loss: 0.8634, G loss: 4.4554\n",
      "[732/8000] D loss: 0.7122, G loss: 7.2623\n",
      "[1092/8000] D loss: 0.7220, G loss: 7.1130\n",
      "[1452/8000] D loss: 0.6982, G loss: 7.2977\n",
      "[1812/8000] D loss: 0.7022, G loss: 10.4498\n",
      "[2172/8000] D loss: 0.8245, G loss: 4.7672\n",
      "[2532/8000] D loss: 0.5150, G loss: 9.1461\n",
      "[2892/8000] D loss: 0.6953, G loss: 9.8136\n",
      "[3252/8000] D loss: 0.6529, G loss: 10.3313\n",
      "[3612/8000] D loss: 0.8677, G loss: 5.7493\n",
      "[3972/8000] D loss: 0.3934, G loss: 7.0179\n",
      "[4332/8000] D loss: 0.5212, G loss: 10.9243\n",
      "[4692/8000] D loss: 0.7225, G loss: 8.9513\n",
      "[5052/8000] D loss: 1.0687, G loss: 3.6433\n",
      "[5412/8000] D loss: 0.5538, G loss: 8.9138\n",
      "[5772/8000] D loss: 0.9250, G loss: 3.3476\n",
      "[6132/8000] D loss: 0.9861, G loss: 3.5012\n",
      "[6492/8000] D loss: 0.9538, G loss: 6.4400\n",
      "[6852/8000] D loss: 1.1245, G loss: 4.6977\n",
      "[7212/8000] D loss: 1.3899, G loss: 0.8749\n",
      "[7572/8000] D loss: 0.6300, G loss: 6.8867\n",
      "[7932/8000] D loss: 0.7064, G loss: 11.0737\n",
      "train error: \n",
      " D loss: 0.848323, G loss: 7.119198, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.069694, G loss: 20.606699, D accuracy: 75.9%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6318, G loss: 7.3364\n",
      "[372/8000] D loss: 0.8037, G loss: 5.7942\n",
      "[732/8000] D loss: 0.9368, G loss: 7.8377\n",
      "[1092/8000] D loss: 0.8293, G loss: 10.8843\n",
      "[1452/8000] D loss: 0.9274, G loss: 9.3561\n",
      "[1812/8000] D loss: 0.7233, G loss: 7.7297\n",
      "[2172/8000] D loss: 1.0154, G loss: 2.4032\n",
      "[2532/8000] D loss: 0.8214, G loss: 4.0992\n",
      "[2892/8000] D loss: 0.9459, G loss: 5.8313\n",
      "[3252/8000] D loss: 0.6741, G loss: 8.0200\n",
      "[3612/8000] D loss: 0.9344, G loss: 4.8794\n",
      "[3972/8000] D loss: 0.5243, G loss: 14.1733\n",
      "[4332/8000] D loss: 0.8473, G loss: 4.1485\n",
      "[4692/8000] D loss: 1.0300, G loss: 9.3717\n",
      "[5052/8000] D loss: 1.2184, G loss: 1.6373\n",
      "[5412/8000] D loss: 1.1083, G loss: 3.4680\n",
      "[5772/8000] D loss: 0.7027, G loss: 6.1214\n",
      "[6132/8000] D loss: 0.7701, G loss: 5.9420\n",
      "[6492/8000] D loss: 0.9528, G loss: 4.5341\n",
      "[6852/8000] D loss: 0.8545, G loss: 6.5446\n",
      "[7212/8000] D loss: 0.6875, G loss: 7.8379\n",
      "[7572/8000] D loss: 0.9331, G loss: 5.4484\n",
      "[7932/8000] D loss: 0.6706, G loss: 3.7698\n",
      "train error: \n",
      " D loss: 0.877232, G loss: 5.408188, D accuracy: 71.0%, cell accuracy: 98.7%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.926527, G loss: 16.731942, D accuracy: 76.4%, cell accuracy: 98.2%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7211, G loss: 4.5840\n",
      "[372/8000] D loss: 0.8789, G loss: 4.9705\n",
      "[732/8000] D loss: 1.1419, G loss: 2.4088\n",
      "[1092/8000] D loss: 0.8802, G loss: 6.2874\n",
      "[1452/8000] D loss: 1.1924, G loss: 2.3625\n",
      "[1812/8000] D loss: 0.8288, G loss: 5.3596\n",
      "[2172/8000] D loss: 0.8503, G loss: 2.9733\n",
      "[2532/8000] D loss: 1.1984, G loss: 2.8872\n",
      "[2892/8000] D loss: 0.7966, G loss: 5.0362\n",
      "[3252/8000] D loss: 0.8034, G loss: 4.5464\n",
      "[3612/8000] D loss: 1.3450, G loss: 1.1860\n",
      "[3972/8000] D loss: 0.7189, G loss: 4.9666\n",
      "[4332/8000] D loss: 0.5617, G loss: 7.7525\n",
      "[4692/8000] D loss: 0.6031, G loss: 9.7408\n",
      "[5052/8000] D loss: 0.4435, G loss: 8.1856\n",
      "[5412/8000] D loss: 0.8512, G loss: 3.8292\n",
      "[5772/8000] D loss: 1.1460, G loss: 5.2439\n",
      "[6132/8000] D loss: 0.8732, G loss: 6.2464\n",
      "[6492/8000] D loss: 0.7101, G loss: 6.8236\n",
      "[6852/8000] D loss: 1.0400, G loss: 2.7338\n",
      "[7212/8000] D loss: 0.6972, G loss: 4.8170\n",
      "[7572/8000] D loss: 1.0931, G loss: 2.7385\n",
      "[7932/8000] D loss: 0.8721, G loss: 4.3661\n",
      "train error: \n",
      " D loss: 0.852827, G loss: 6.451564, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.910870, G loss: 19.855538, D accuracy: 78.5%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0407, G loss: 2.1863\n",
      "[372/8000] D loss: 0.8721, G loss: 4.6392\n",
      "[732/8000] D loss: 0.8696, G loss: 5.1846\n",
      "[1092/8000] D loss: 1.0394, G loss: 2.9281\n",
      "[1452/8000] D loss: 0.9203, G loss: 4.9679\n",
      "[1812/8000] D loss: 1.0655, G loss: 2.0263\n",
      "[2172/8000] D loss: 1.0397, G loss: 2.4723\n",
      "[2532/8000] D loss: 0.8887, G loss: 4.5767\n",
      "[2892/8000] D loss: 0.8732, G loss: 3.4346\n",
      "[3252/8000] D loss: 0.9842, G loss: 7.1643\n",
      "[3612/8000] D loss: 1.0398, G loss: 3.5747\n",
      "[3972/8000] D loss: 0.7984, G loss: 4.8027\n",
      "[4332/8000] D loss: 1.2166, G loss: 1.2026\n",
      "[4692/8000] D loss: 0.9571, G loss: 1.9502\n",
      "[5052/8000] D loss: 0.6875, G loss: 4.7586\n",
      "[5412/8000] D loss: 0.9927, G loss: 3.5923\n",
      "[5772/8000] D loss: 0.8491, G loss: 6.0835\n",
      "[6132/8000] D loss: 0.8410, G loss: 5.8531\n",
      "[6492/8000] D loss: 0.7120, G loss: 6.5984\n",
      "[6852/8000] D loss: 0.7547, G loss: 5.0644\n",
      "[7212/8000] D loss: 1.1705, G loss: 3.5402\n",
      "[7572/8000] D loss: 1.0334, G loss: 5.0483\n",
      "[7932/8000] D loss: 0.8231, G loss: 6.1287\n",
      "train error: \n",
      " D loss: 0.847284, G loss: 6.577474, D accuracy: 71.0%, cell accuracy: 98.7%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.003542, G loss: 19.013854, D accuracy: 75.2%, cell accuracy: 98.3%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9305, G loss: 2.6073\n",
      "[372/8000] D loss: 0.8120, G loss: 8.1472\n",
      "[732/8000] D loss: 0.8511, G loss: 7.1871\n",
      "[1092/8000] D loss: 0.7094, G loss: 7.1755\n",
      "[1452/8000] D loss: 1.0513, G loss: 7.2759\n",
      "[1812/8000] D loss: 0.6211, G loss: 4.0569\n",
      "[2172/8000] D loss: 0.8801, G loss: 5.4268\n",
      "[2532/8000] D loss: 0.6622, G loss: 7.9655\n",
      "[2892/8000] D loss: 0.6426, G loss: 7.9376\n",
      "[3252/8000] D loss: 0.8758, G loss: 2.2024\n",
      "[3612/8000] D loss: 1.1582, G loss: 3.7309\n",
      "[3972/8000] D loss: 0.4114, G loss: 7.5414\n",
      "[4332/8000] D loss: 0.9957, G loss: 5.5980\n",
      "[4692/8000] D loss: 0.7965, G loss: 3.0814\n",
      "[5052/8000] D loss: 0.9281, G loss: 5.8252\n",
      "[5412/8000] D loss: 1.1798, G loss: 2.8711\n",
      "[5772/8000] D loss: 0.5971, G loss: 11.7262\n",
      "[6132/8000] D loss: 0.8891, G loss: 3.8081\n",
      "[6492/8000] D loss: 0.6961, G loss: 8.9666\n",
      "[6852/8000] D loss: 1.0569, G loss: 6.2445\n",
      "[7212/8000] D loss: 0.7080, G loss: 7.5966\n",
      "[7572/8000] D loss: 0.7340, G loss: 4.5608\n",
      "[7932/8000] D loss: 0.9329, G loss: 9.0275\n",
      "train error: \n",
      " D loss: 0.868933, G loss: 6.484537, D accuracy: 71.3%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.145723, G loss: 19.025316, D accuracy: 75.6%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8457, G loss: 6.0120\n",
      "[372/8000] D loss: 0.9253, G loss: 5.2251\n",
      "[732/8000] D loss: 1.2907, G loss: 2.0282\n",
      "[1092/8000] D loss: 0.8976, G loss: 4.6876\n",
      "[1452/8000] D loss: 0.8844, G loss: 6.0130\n",
      "[1812/8000] D loss: 0.8799, G loss: 7.0876\n",
      "[2172/8000] D loss: 1.0487, G loss: 4.0387\n",
      "[2532/8000] D loss: 0.8545, G loss: 9.3664\n",
      "[2892/8000] D loss: 0.5981, G loss: 4.8476\n",
      "[3252/8000] D loss: 0.7046, G loss: 6.3087\n",
      "[3612/8000] D loss: 0.9066, G loss: 4.2430\n",
      "[3972/8000] D loss: 0.8780, G loss: 12.2185\n",
      "[4332/8000] D loss: 0.6375, G loss: 9.3001\n",
      "[4692/8000] D loss: 0.5390, G loss: 7.0048\n",
      "[5052/8000] D loss: 0.8920, G loss: 4.8939\n",
      "[5412/8000] D loss: 0.8965, G loss: 11.6566\n",
      "[5772/8000] D loss: 0.6945, G loss: 8.5936\n",
      "[6132/8000] D loss: 0.7989, G loss: 4.0909\n",
      "[6492/8000] D loss: 0.7501, G loss: 4.7258\n",
      "[6852/8000] D loss: 0.7386, G loss: 5.9707\n",
      "[7212/8000] D loss: 0.7415, G loss: 4.8494\n",
      "[7572/8000] D loss: 0.8582, G loss: 4.8469\n",
      "[7932/8000] D loss: 0.2371, G loss: 13.3072\n",
      "train error: \n",
      " D loss: 0.844273, G loss: 6.357853, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.933681, G loss: 19.382835, D accuracy: 80.6%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9792, G loss: 3.4084\n",
      "[372/8000] D loss: 1.2059, G loss: 1.8495\n",
      "[732/8000] D loss: 0.9139, G loss: 4.0800\n",
      "[1092/8000] D loss: 0.5268, G loss: 14.2618\n",
      "[1452/8000] D loss: 0.8161, G loss: 6.0579\n",
      "[1812/8000] D loss: 0.8166, G loss: 10.7833\n",
      "[2172/8000] D loss: 1.0000, G loss: 6.2747\n",
      "[2532/8000] D loss: 0.7811, G loss: 6.5555\n",
      "[2892/8000] D loss: 0.9066, G loss: 4.3429\n",
      "[3252/8000] D loss: 0.7324, G loss: 3.9880\n",
      "[3612/8000] D loss: 0.7884, G loss: 8.1047\n",
      "[3972/8000] D loss: 1.0585, G loss: 2.7496\n",
      "[4332/8000] D loss: 0.9214, G loss: 6.3043\n",
      "[4692/8000] D loss: 0.4735, G loss: 11.8628\n",
      "[5052/8000] D loss: 0.7371, G loss: 14.1528\n",
      "[5412/8000] D loss: 0.9029, G loss: 13.1694\n",
      "[5772/8000] D loss: 0.7461, G loss: 6.5357\n",
      "[6132/8000] D loss: 0.9317, G loss: 5.0279\n",
      "[6492/8000] D loss: 0.9315, G loss: 2.4801\n",
      "[6852/8000] D loss: 0.9176, G loss: 6.4528\n",
      "[7212/8000] D loss: 0.8224, G loss: 5.5553\n",
      "[7572/8000] D loss: 0.6011, G loss: 13.3942\n",
      "[7932/8000] D loss: 0.9342, G loss: 5.3010\n",
      "train error: \n",
      " D loss: 0.848971, G loss: 7.249229, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.042763, G loss: 20.978419, D accuracy: 77.6%, cell accuracy: 98.3%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5865, G loss: 8.3249\n",
      "[372/8000] D loss: 0.6734, G loss: 10.0479\n",
      "[732/8000] D loss: 0.9179, G loss: 6.2761\n",
      "[1092/8000] D loss: 0.8394, G loss: 2.5363\n",
      "[1452/8000] D loss: 0.7325, G loss: 8.0681\n",
      "[1812/8000] D loss: 0.7504, G loss: 5.0651\n",
      "[2172/8000] D loss: 1.1679, G loss: 1.2520\n",
      "[2532/8000] D loss: 1.1730, G loss: 1.5739\n",
      "[2892/8000] D loss: 0.4892, G loss: 8.1220\n",
      "[3252/8000] D loss: 1.2678, G loss: 3.2329\n",
      "[3612/8000] D loss: 0.6157, G loss: 17.3620\n",
      "[3972/8000] D loss: 0.7378, G loss: 6.9748\n",
      "[4332/8000] D loss: 1.2119, G loss: 6.4993\n",
      "[4692/8000] D loss: 0.5452, G loss: 6.1864\n",
      "[5052/8000] D loss: 0.4675, G loss: 12.4892\n",
      "[5412/8000] D loss: 0.9795, G loss: 3.6806\n",
      "[5772/8000] D loss: 0.9362, G loss: 5.3351\n",
      "[6132/8000] D loss: 1.0415, G loss: 2.8478\n",
      "[6492/8000] D loss: 0.7439, G loss: 3.6501\n",
      "[6852/8000] D loss: 0.7480, G loss: 5.4237\n",
      "[7212/8000] D loss: 0.9404, G loss: 3.7100\n",
      "[7572/8000] D loss: 0.9234, G loss: 6.3046\n",
      "[7932/8000] D loss: 1.1479, G loss: 1.3874\n",
      "train error: \n",
      " D loss: 0.847322, G loss: 6.837718, D accuracy: 71.2%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.023345, G loss: 20.749359, D accuracy: 77.2%, cell accuracy: 98.2%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8031, G loss: 4.9905\n",
      "[372/8000] D loss: 0.8993, G loss: 4.5523\n",
      "[732/8000] D loss: 0.8481, G loss: 11.8999\n",
      "[1092/8000] D loss: 0.6861, G loss: 9.7908\n",
      "[1452/8000] D loss: 0.9637, G loss: 5.1480\n",
      "[1812/8000] D loss: 0.9944, G loss: 4.5912\n",
      "[2172/8000] D loss: 0.7582, G loss: 11.5418\n",
      "[2532/8000] D loss: 0.8950, G loss: 4.2038\n",
      "[2892/8000] D loss: 0.5537, G loss: 9.4078\n",
      "[3252/8000] D loss: 0.5576, G loss: 6.8081\n",
      "[3612/8000] D loss: 0.8272, G loss: 9.2236\n",
      "[3972/8000] D loss: 1.0308, G loss: 9.7809\n",
      "[4332/8000] D loss: 1.0544, G loss: 3.0815\n",
      "[4692/8000] D loss: 0.6945, G loss: 7.2053\n",
      "[5052/8000] D loss: 0.8430, G loss: 6.3768\n",
      "[5412/8000] D loss: 0.9482, G loss: 9.8923\n",
      "[5772/8000] D loss: 0.9955, G loss: 4.8377\n",
      "[6132/8000] D loss: 0.8293, G loss: 3.3253\n",
      "[6492/8000] D loss: 1.0984, G loss: 2.3943\n",
      "[6852/8000] D loss: 0.6667, G loss: 7.8157\n",
      "[7212/8000] D loss: 0.9237, G loss: 4.2757\n",
      "[7572/8000] D loss: 0.8687, G loss: 3.1674\n",
      "[7932/8000] D loss: 0.9488, G loss: 8.1094\n",
      "train error: \n",
      " D loss: 0.860518, G loss: 5.387568, D accuracy: 71.2%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.930537, G loss: 16.744947, D accuracy: 80.7%, cell accuracy: 98.2%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7315, G loss: 7.6778\n",
      "[372/8000] D loss: 1.1120, G loss: 9.9743\n",
      "[732/8000] D loss: 0.6579, G loss: 6.9374\n",
      "[1092/8000] D loss: 0.5956, G loss: 8.4203\n",
      "[1452/8000] D loss: 0.9894, G loss: 6.0357\n",
      "[1812/8000] D loss: 0.6802, G loss: 7.0649\n",
      "[2172/8000] D loss: 0.7981, G loss: 4.0913\n",
      "[2532/8000] D loss: 0.6125, G loss: 8.9702\n",
      "[2892/8000] D loss: 0.8140, G loss: 6.8025\n",
      "[3252/8000] D loss: 0.9803, G loss: 9.0009\n",
      "[3612/8000] D loss: 0.7165, G loss: 6.1179\n",
      "[3972/8000] D loss: 0.8455, G loss: 7.1162\n",
      "[4332/8000] D loss: 0.5684, G loss: 5.6803\n",
      "[4692/8000] D loss: 0.6016, G loss: 13.3173\n",
      "[5052/8000] D loss: 0.7004, G loss: 5.1328\n",
      "[5412/8000] D loss: 0.7617, G loss: 8.0661\n",
      "[5772/8000] D loss: 0.8672, G loss: 16.0316\n",
      "[6132/8000] D loss: 0.8849, G loss: 7.0908\n",
      "[6492/8000] D loss: 0.8429, G loss: 7.6123\n",
      "[6852/8000] D loss: 0.5208, G loss: 8.0402\n",
      "[7212/8000] D loss: 1.1725, G loss: 3.8398\n",
      "[7572/8000] D loss: 0.8099, G loss: 4.8061\n",
      "[7932/8000] D loss: 0.9467, G loss: 5.5982\n",
      "train error: \n",
      " D loss: 0.850098, G loss: 6.530698, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.011147, G loss: 19.346144, D accuracy: 79.0%, cell accuracy: 98.2%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9412, G loss: 6.4690\n",
      "[372/8000] D loss: 1.1657, G loss: 3.1779\n",
      "[732/8000] D loss: 1.0419, G loss: 4.2400\n",
      "[1092/8000] D loss: 0.6195, G loss: 8.9344\n",
      "[1452/8000] D loss: 1.0616, G loss: 9.6743\n",
      "[1812/8000] D loss: 0.6671, G loss: 5.3556\n",
      "[2172/8000] D loss: 0.8169, G loss: 5.2221\n",
      "[2532/8000] D loss: 0.8895, G loss: 3.3307\n",
      "[2892/8000] D loss: 0.9635, G loss: 1.8858\n",
      "[3252/8000] D loss: 0.7292, G loss: 6.7203\n",
      "[3612/8000] D loss: 1.1164, G loss: 2.0096\n",
      "[3972/8000] D loss: 1.1744, G loss: 2.0114\n",
      "[4332/8000] D loss: 0.9223, G loss: 6.3668\n",
      "[4692/8000] D loss: 0.9494, G loss: 4.3337\n",
      "[5052/8000] D loss: 0.9802, G loss: 5.2607\n",
      "[5412/8000] D loss: 0.9554, G loss: 2.0116\n",
      "[5772/8000] D loss: 0.9716, G loss: 4.5552\n",
      "[6132/8000] D loss: 0.8116, G loss: 7.2027\n",
      "[6492/8000] D loss: 0.8272, G loss: 6.4484\n",
      "[6852/8000] D loss: 0.6067, G loss: 8.4638\n",
      "[7212/8000] D loss: 0.6051, G loss: 9.0843\n",
      "[7572/8000] D loss: 0.6019, G loss: 9.2545\n",
      "[7932/8000] D loss: 0.8010, G loss: 6.3724\n",
      "train error: \n",
      " D loss: 0.828799, G loss: 7.306415, D accuracy: 72.5%, cell accuracy: 98.7%, board accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.997117, G loss: 21.791265, D accuracy: 78.9%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7244, G loss: 9.1023\n",
      "[372/8000] D loss: 0.8150, G loss: 5.4270\n",
      "[732/8000] D loss: 0.6312, G loss: 5.4680\n",
      "[1092/8000] D loss: 0.5984, G loss: 6.4336\n",
      "[1452/8000] D loss: 0.3704, G loss: 13.9483\n",
      "[1812/8000] D loss: 0.7323, G loss: 7.0168\n",
      "[2172/8000] D loss: 0.5854, G loss: 8.9981\n",
      "[2532/8000] D loss: 0.9401, G loss: 2.5698\n",
      "[2892/8000] D loss: 1.1150, G loss: 3.1960\n",
      "[3252/8000] D loss: 0.9334, G loss: 3.4861\n",
      "[3612/8000] D loss: 0.6408, G loss: 4.7418\n",
      "[3972/8000] D loss: 0.8139, G loss: 8.9803\n",
      "[4332/8000] D loss: 1.0633, G loss: 1.6760\n",
      "[4692/8000] D loss: 0.8092, G loss: 8.2139\n",
      "[5052/8000] D loss: 1.0588, G loss: 6.1722\n",
      "[5412/8000] D loss: 0.9918, G loss: 2.9075\n",
      "[5772/8000] D loss: 0.8401, G loss: 14.7628\n",
      "[6132/8000] D loss: 0.7029, G loss: 7.5813\n",
      "[6492/8000] D loss: 0.9511, G loss: 6.3102\n",
      "[6852/8000] D loss: 0.8465, G loss: 7.0004\n",
      "[7212/8000] D loss: 0.8240, G loss: 9.2742\n",
      "[7572/8000] D loss: 0.6651, G loss: 5.2404\n",
      "[7932/8000] D loss: 1.0163, G loss: 7.4042\n",
      "train error: \n",
      " D loss: 0.841498, G loss: 7.316012, D accuracy: 72.4%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.968133, G loss: 21.240051, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0719, G loss: 4.0770\n",
      "[372/8000] D loss: 0.7632, G loss: 5.4619\n",
      "[732/8000] D loss: 0.9959, G loss: 8.0526\n",
      "[1092/8000] D loss: 0.6935, G loss: 4.5508\n",
      "[1452/8000] D loss: 0.7736, G loss: 12.4985\n",
      "[1812/8000] D loss: 0.8107, G loss: 12.2633\n",
      "[2172/8000] D loss: 1.1452, G loss: 3.8957\n",
      "[2532/8000] D loss: 0.6189, G loss: 8.1196\n",
      "[2892/8000] D loss: 0.6145, G loss: 6.0869\n",
      "[3252/8000] D loss: 0.9870, G loss: 2.4884\n",
      "[3612/8000] D loss: 0.8117, G loss: 6.9120\n",
      "[3972/8000] D loss: 0.4136, G loss: 16.2433\n",
      "[4332/8000] D loss: 1.1660, G loss: 1.3936\n",
      "[4692/8000] D loss: 0.5808, G loss: 8.7815\n",
      "[5052/8000] D loss: 0.5631, G loss: 6.5563\n",
      "[5412/8000] D loss: 0.8526, G loss: 4.2162\n",
      "[5772/8000] D loss: 1.0900, G loss: 1.9944\n",
      "[6132/8000] D loss: 0.7149, G loss: 7.7797\n",
      "[6492/8000] D loss: 0.3724, G loss: 17.1726\n",
      "[6852/8000] D loss: 0.9205, G loss: 4.5659\n",
      "[7212/8000] D loss: 1.0284, G loss: 4.7046\n",
      "[7572/8000] D loss: 1.0091, G loss: 4.8762\n",
      "[7932/8000] D loss: 0.9222, G loss: 5.0712\n",
      "train error: \n",
      " D loss: 0.873424, G loss: 7.189542, D accuracy: 70.9%, cell accuracy: 98.7%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.168385, G loss: 20.504220, D accuracy: 73.9%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6179, G loss: 9.1173\n",
      "[372/8000] D loss: 1.0749, G loss: 6.7826\n",
      "[732/8000] D loss: 0.5394, G loss: 7.6546\n",
      "[1092/8000] D loss: 0.8195, G loss: 7.5529\n",
      "[1452/8000] D loss: 0.8502, G loss: 10.4200\n",
      "[1812/8000] D loss: 0.7796, G loss: 4.2464\n",
      "[2172/8000] D loss: 0.8727, G loss: 2.8767\n",
      "[2532/8000] D loss: 0.6122, G loss: 6.1863\n",
      "[2892/8000] D loss: 0.6955, G loss: 7.7203\n",
      "[3252/8000] D loss: 0.5139, G loss: 11.4861\n",
      "[3612/8000] D loss: 1.2543, G loss: 1.6006\n",
      "[3972/8000] D loss: 0.6016, G loss: 13.5862\n",
      "[4332/8000] D loss: 0.7504, G loss: 5.3408\n",
      "[4692/8000] D loss: 0.9629, G loss: 4.4335\n",
      "[5052/8000] D loss: 0.7690, G loss: 8.8186\n",
      "[5412/8000] D loss: 0.8343, G loss: 5.2903\n",
      "[5772/8000] D loss: 0.8974, G loss: 4.2034\n",
      "[6132/8000] D loss: 1.0424, G loss: 4.8204\n",
      "[6492/8000] D loss: 0.7385, G loss: 7.8321\n",
      "[6852/8000] D loss: 1.0061, G loss: 9.1295\n",
      "[7212/8000] D loss: 0.7412, G loss: 7.6830\n",
      "[7572/8000] D loss: 0.4036, G loss: 11.0317\n",
      "[7932/8000] D loss: 0.8472, G loss: 6.9036\n",
      "train error: \n",
      " D loss: 0.852271, G loss: 5.628863, D accuracy: 71.2%, cell accuracy: 98.7%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.983902, G loss: 17.429796, D accuracy: 78.4%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9690, G loss: 4.6376\n",
      "[372/8000] D loss: 0.9024, G loss: 6.2245\n",
      "[732/8000] D loss: 0.7737, G loss: 7.2393\n",
      "[1092/8000] D loss: 0.6912, G loss: 3.6690\n",
      "[1452/8000] D loss: 1.0886, G loss: 2.0611\n",
      "[1812/8000] D loss: 0.6399, G loss: 5.4798\n",
      "[2172/8000] D loss: 1.0810, G loss: 2.9228\n",
      "[2532/8000] D loss: 0.8859, G loss: 5.4234\n",
      "[2892/8000] D loss: 0.7235, G loss: 9.5825\n",
      "[3252/8000] D loss: 0.8212, G loss: 4.1667\n",
      "[3612/8000] D loss: 1.1798, G loss: 4.5937\n",
      "[3972/8000] D loss: 0.7261, G loss: 5.2399\n",
      "[4332/8000] D loss: 0.6030, G loss: 8.4858\n",
      "[4692/8000] D loss: 0.9928, G loss: 4.6819\n",
      "[5052/8000] D loss: 0.7498, G loss: 3.1171\n",
      "[5412/8000] D loss: 0.6091, G loss: 6.8105\n",
      "[5772/8000] D loss: 0.8265, G loss: 5.6351\n",
      "[6132/8000] D loss: 1.0485, G loss: 2.6464\n",
      "[6492/8000] D loss: 0.4576, G loss: 6.8483\n",
      "[6852/8000] D loss: 0.6369, G loss: 9.0320\n",
      "[7212/8000] D loss: 0.7732, G loss: 5.7526\n",
      "[7572/8000] D loss: 1.1743, G loss: 3.7123\n",
      "[7932/8000] D loss: 1.1169, G loss: 1.8604\n",
      "train error: \n",
      " D loss: 0.854104, G loss: 6.487412, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.942560, G loss: 19.186637, D accuracy: 80.0%, cell accuracy: 98.3%, board accuracy: 29.6% \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0593, G loss: 3.8092\n",
      "[372/8000] D loss: 1.0293, G loss: 3.0763\n",
      "[732/8000] D loss: 0.8481, G loss: 5.7435\n",
      "[1092/8000] D loss: 0.6057, G loss: 10.4071\n",
      "[1452/8000] D loss: 1.0092, G loss: 1.8185\n",
      "[1812/8000] D loss: 0.9331, G loss: 5.4462\n",
      "[2172/8000] D loss: 0.4145, G loss: 13.3021\n",
      "[2532/8000] D loss: 0.7006, G loss: 5.4451\n",
      "[2892/8000] D loss: 0.1689, G loss: 8.5455\n",
      "[3252/8000] D loss: 0.7510, G loss: 5.6561\n",
      "[3612/8000] D loss: 1.0354, G loss: 1.4953\n",
      "[3972/8000] D loss: 1.0536, G loss: 3.6395\n",
      "[4332/8000] D loss: 0.8957, G loss: 7.1123\n",
      "[4692/8000] D loss: 0.8898, G loss: 8.7782\n",
      "[5052/8000] D loss: 1.0498, G loss: 3.7666\n",
      "[5412/8000] D loss: 0.7714, G loss: 7.1233\n",
      "[5772/8000] D loss: 0.8314, G loss: 5.3107\n",
      "[6132/8000] D loss: 1.2333, G loss: 1.8962\n",
      "[6492/8000] D loss: 0.8668, G loss: 2.7298\n",
      "[6852/8000] D loss: 0.4877, G loss: 4.1690\n",
      "[7212/8000] D loss: 0.6747, G loss: 3.1353\n",
      "[7572/8000] D loss: 0.8167, G loss: 6.4664\n",
      "[7932/8000] D loss: 0.9409, G loss: 4.4234\n",
      "train error: \n",
      " D loss: 0.853862, G loss: 5.774262, D accuracy: 71.2%, cell accuracy: 98.7%, board accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.997140, G loss: 17.849288, D accuracy: 79.7%, cell accuracy: 98.2%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4869, G loss: 7.3458\n",
      "[372/8000] D loss: 0.5697, G loss: 7.6482\n",
      "[732/8000] D loss: 0.8531, G loss: 3.0992\n",
      "[1092/8000] D loss: 0.5099, G loss: 6.9457\n",
      "[1452/8000] D loss: 0.9891, G loss: 6.1319\n",
      "[1812/8000] D loss: 0.8011, G loss: 7.1299\n",
      "[2172/8000] D loss: 0.9207, G loss: 2.8117\n",
      "[2532/8000] D loss: 0.8315, G loss: 3.0383\n",
      "[2892/8000] D loss: 0.7174, G loss: 7.8281\n",
      "[3252/8000] D loss: 0.7271, G loss: 3.7714\n",
      "[3612/8000] D loss: 0.8117, G loss: 3.3561\n",
      "[3972/8000] D loss: 0.4725, G loss: 9.5582\n",
      "[4332/8000] D loss: 0.7854, G loss: 7.2692\n",
      "[4692/8000] D loss: 0.6394, G loss: 6.9223\n",
      "[5052/8000] D loss: 0.6973, G loss: 4.9547\n",
      "[5412/8000] D loss: 1.0393, G loss: 8.6437\n",
      "[5772/8000] D loss: 0.8051, G loss: 4.0171\n",
      "[6132/8000] D loss: 1.2815, G loss: 1.6921\n",
      "[6492/8000] D loss: 1.0611, G loss: 3.9911\n",
      "[6852/8000] D loss: 0.9298, G loss: 2.0647\n",
      "[7212/8000] D loss: 0.6974, G loss: 7.7345\n",
      "[7572/8000] D loss: 0.5986, G loss: 9.4948\n",
      "[7932/8000] D loss: 0.9298, G loss: 4.1460\n",
      "train error: \n",
      " D loss: 0.859670, G loss: 6.838669, D accuracy: 71.2%, cell accuracy: 98.7%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.981721, G loss: 19.916834, D accuracy: 80.0%, cell accuracy: 98.3%, board accuracy: 29.3% \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8525, G loss: 6.8651\n",
      "[372/8000] D loss: 1.0172, G loss: 3.3592\n",
      "[732/8000] D loss: 1.0178, G loss: 7.0639\n",
      "[1092/8000] D loss: 0.8834, G loss: 6.0179\n",
      "[1452/8000] D loss: 0.6525, G loss: 10.6298\n",
      "[1812/8000] D loss: 0.9182, G loss: 3.4824\n",
      "[2172/8000] D loss: 0.7118, G loss: 14.5144\n",
      "[2532/8000] D loss: 1.0789, G loss: 1.5486\n",
      "[2892/8000] D loss: 0.7245, G loss: 7.2374\n",
      "[3252/8000] D loss: 0.8020, G loss: 4.7758\n",
      "[3612/8000] D loss: 1.1722, G loss: 1.3414\n",
      "[3972/8000] D loss: 1.0210, G loss: 2.5876\n",
      "[4332/8000] D loss: 0.8136, G loss: 9.3714\n",
      "[4692/8000] D loss: 0.5492, G loss: 9.5906\n",
      "[5052/8000] D loss: 0.9874, G loss: 3.8521\n",
      "[5412/8000] D loss: 1.0518, G loss: 4.4048\n",
      "[5772/8000] D loss: 0.7542, G loss: 5.6150\n",
      "[6132/8000] D loss: 1.0680, G loss: 3.1062\n",
      "[6492/8000] D loss: 0.4733, G loss: 18.3336\n",
      "[6852/8000] D loss: 0.7214, G loss: 9.0963\n",
      "[7212/8000] D loss: 0.6212, G loss: 11.5519\n",
      "[7572/8000] D loss: 0.7153, G loss: 10.6561\n",
      "[7932/8000] D loss: 1.1236, G loss: 3.5935\n",
      "train error: \n",
      " D loss: 0.842639, G loss: 7.165761, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.036320, G loss: 21.166631, D accuracy: 77.4%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9223, G loss: 4.7942\n",
      "[372/8000] D loss: 0.6344, G loss: 7.7990\n",
      "[732/8000] D loss: 0.3664, G loss: 12.1564\n",
      "[1092/8000] D loss: 0.9273, G loss: 4.2086\n",
      "[1452/8000] D loss: 1.0357, G loss: 4.2072\n",
      "[1812/8000] D loss: 0.7737, G loss: 8.3928\n",
      "[2172/8000] D loss: 0.7911, G loss: 4.7693\n",
      "[2532/8000] D loss: 0.8937, G loss: 5.3404\n",
      "[2892/8000] D loss: 0.5967, G loss: 15.3809\n",
      "[3252/8000] D loss: 0.9177, G loss: 4.1682\n",
      "[3612/8000] D loss: 1.1113, G loss: 2.1172\n",
      "[3972/8000] D loss: 0.8095, G loss: 8.7928\n",
      "[4332/8000] D loss: 0.8113, G loss: 10.3336\n",
      "[4692/8000] D loss: 0.8027, G loss: 14.5328\n",
      "[5052/8000] D loss: 0.8695, G loss: 3.7736\n",
      "[5412/8000] D loss: 0.9009, G loss: 14.4013\n",
      "[5772/8000] D loss: 0.7033, G loss: 7.8518\n",
      "[6132/8000] D loss: 1.1375, G loss: 4.3279\n",
      "[6492/8000] D loss: 0.9654, G loss: 2.9525\n",
      "[6852/8000] D loss: 0.6131, G loss: 5.2978\n",
      "[7212/8000] D loss: 0.7151, G loss: 10.7920\n",
      "[7572/8000] D loss: 0.8472, G loss: 6.0602\n",
      "[7932/8000] D loss: 0.7130, G loss: 8.0251\n",
      "train error: \n",
      " D loss: 0.840786, G loss: 6.636298, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.930615, G loss: 19.907164, D accuracy: 80.2%, cell accuracy: 98.3%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9276, G loss: 4.8140\n",
      "[372/8000] D loss: 0.6221, G loss: 18.4771\n",
      "[732/8000] D loss: 0.7002, G loss: 10.0587\n",
      "[1092/8000] D loss: 1.1396, G loss: 3.8139\n",
      "[1452/8000] D loss: 0.7075, G loss: 12.1503\n",
      "[1812/8000] D loss: 0.9849, G loss: 4.4403\n",
      "[2172/8000] D loss: 0.7470, G loss: 7.4949\n",
      "[2532/8000] D loss: 1.0519, G loss: 7.4828\n",
      "[2892/8000] D loss: 0.9325, G loss: 6.1481\n",
      "[3252/8000] D loss: 0.6887, G loss: 5.4574\n",
      "[3612/8000] D loss: 0.4774, G loss: 7.0126\n",
      "[3972/8000] D loss: 1.0908, G loss: 6.6594\n",
      "[4332/8000] D loss: 0.7080, G loss: 10.7398\n",
      "[4692/8000] D loss: 0.5604, G loss: 7.3683\n",
      "[5052/8000] D loss: 0.7004, G loss: 9.5750\n",
      "[5412/8000] D loss: 1.0299, G loss: 3.6532\n",
      "[5772/8000] D loss: 1.1683, G loss: 2.8569\n",
      "[6132/8000] D loss: 0.8539, G loss: 4.2694\n",
      "[6492/8000] D loss: 1.1811, G loss: 3.0778\n",
      "[6852/8000] D loss: 1.1099, G loss: 1.7846\n",
      "[7212/8000] D loss: 1.1449, G loss: 4.1105\n",
      "[7572/8000] D loss: 0.6534, G loss: 3.4741\n",
      "[7932/8000] D loss: 0.8086, G loss: 13.9906\n",
      "train error: \n",
      " D loss: 0.835008, G loss: 6.765646, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.955118, G loss: 20.305946, D accuracy: 78.4%, cell accuracy: 98.3%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8145, G loss: 6.7878\n",
      "[372/8000] D loss: 0.8489, G loss: 9.1092\n",
      "[732/8000] D loss: 0.7238, G loss: 6.5268\n",
      "[1092/8000] D loss: 0.6683, G loss: 10.3996\n",
      "[1452/8000] D loss: 0.7062, G loss: 7.7994\n",
      "[1812/8000] D loss: 0.8255, G loss: 7.3916\n",
      "[2172/8000] D loss: 1.0347, G loss: 5.4977\n",
      "[2532/8000] D loss: 0.5060, G loss: 10.6657\n",
      "[2892/8000] D loss: 0.7011, G loss: 10.8217\n",
      "[3252/8000] D loss: 1.0300, G loss: 3.1113\n",
      "[3612/8000] D loss: 0.6226, G loss: 8.8391\n",
      "[3972/8000] D loss: 0.5263, G loss: 7.7565\n",
      "[4332/8000] D loss: 0.5013, G loss: 7.7091\n",
      "[4692/8000] D loss: 1.3956, G loss: 0.7692\n",
      "[5052/8000] D loss: 0.7561, G loss: 9.0697\n",
      "[5412/8000] D loss: 0.4549, G loss: 9.3212\n",
      "[5772/8000] D loss: 0.9000, G loss: 4.3813\n",
      "[6132/8000] D loss: 0.4086, G loss: 16.8696\n",
      "[6492/8000] D loss: 0.6892, G loss: 11.7337\n",
      "[6852/8000] D loss: 0.6417, G loss: 5.9189\n",
      "[7212/8000] D loss: 0.8735, G loss: 11.4723\n",
      "[7572/8000] D loss: 1.1879, G loss: 2.9933\n",
      "[7932/8000] D loss: 0.8193, G loss: 4.4697\n",
      "train error: \n",
      " D loss: 0.852198, G loss: 5.312228, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.918130, G loss: 16.584120, D accuracy: 78.9%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8238, G loss: 3.9243\n",
      "[372/8000] D loss: 0.8088, G loss: 6.4809\n",
      "[732/8000] D loss: 0.6732, G loss: 3.2758\n",
      "[1092/8000] D loss: 0.9224, G loss: 6.4959\n",
      "[1452/8000] D loss: 0.8741, G loss: 9.6620\n",
      "[1812/8000] D loss: 0.5647, G loss: 15.5496\n",
      "[2172/8000] D loss: 0.9320, G loss: 4.4158\n",
      "[2532/8000] D loss: 1.0316, G loss: 5.2618\n",
      "[2892/8000] D loss: 1.0327, G loss: 4.7437\n",
      "[3252/8000] D loss: 1.0440, G loss: 6.7764\n",
      "[3612/8000] D loss: 0.5120, G loss: 14.0331\n",
      "[3972/8000] D loss: 0.9717, G loss: 5.7708\n",
      "[4332/8000] D loss: 1.1791, G loss: 7.0436\n",
      "[4692/8000] D loss: 0.7831, G loss: 7.4384\n",
      "[5052/8000] D loss: 0.8384, G loss: 4.6488\n",
      "[5412/8000] D loss: 1.0395, G loss: 3.5794\n",
      "[5772/8000] D loss: 0.7508, G loss: 8.2839\n",
      "[6132/8000] D loss: 1.0110, G loss: 8.2952\n",
      "[6492/8000] D loss: 0.8567, G loss: 4.6690\n",
      "[6852/8000] D loss: 0.6971, G loss: 9.6545\n",
      "[7212/8000] D loss: 0.5890, G loss: 6.1278\n",
      "[7572/8000] D loss: 1.0918, G loss: 3.3920\n",
      "[7932/8000] D loss: 0.6959, G loss: 6.5861\n",
      "train error: \n",
      " D loss: 0.844068, G loss: 7.690184, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.129967, G loss: 22.725306, D accuracy: 75.1%, cell accuracy: 98.2%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8763, G loss: 4.2079\n",
      "[372/8000] D loss: 0.6152, G loss: 13.4703\n",
      "[732/8000] D loss: 0.7488, G loss: 5.0100\n",
      "[1092/8000] D loss: 1.0776, G loss: 2.5411\n",
      "[1452/8000] D loss: 0.8677, G loss: 2.7486\n",
      "[1812/8000] D loss: 1.1497, G loss: 3.7787\n",
      "[2172/8000] D loss: 1.1107, G loss: 6.9420\n",
      "[2532/8000] D loss: 0.7459, G loss: 10.6348\n",
      "[2892/8000] D loss: 0.7247, G loss: 7.0644\n",
      "[3252/8000] D loss: 1.1619, G loss: 1.7427\n",
      "[3612/8000] D loss: 0.6942, G loss: 13.4875\n",
      "[3972/8000] D loss: 0.6153, G loss: 9.8407\n",
      "[4332/8000] D loss: 0.9626, G loss: 5.0157\n",
      "[4692/8000] D loss: 1.0186, G loss: 4.8089\n",
      "[5052/8000] D loss: 0.6605, G loss: 8.9784\n",
      "[5412/8000] D loss: 1.0360, G loss: 3.0943\n",
      "[5772/8000] D loss: 0.9017, G loss: 5.8670\n",
      "[6132/8000] D loss: 1.0355, G loss: 3.7461\n",
      "[6492/8000] D loss: 0.8115, G loss: 8.0002\n",
      "[6852/8000] D loss: 0.9005, G loss: 6.2088\n",
      "[7212/8000] D loss: 0.5291, G loss: 13.6662\n",
      "[7572/8000] D loss: 0.8746, G loss: 7.7937\n",
      "[7932/8000] D loss: 0.4677, G loss: 9.5833\n",
      "train error: \n",
      " D loss: 0.848367, G loss: 6.362449, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.054646, G loss: 19.186382, D accuracy: 76.5%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8397, G loss: 4.2686\n",
      "[372/8000] D loss: 0.8532, G loss: 8.5185\n",
      "[732/8000] D loss: 0.9181, G loss: 8.0268\n",
      "[1092/8000] D loss: 1.0452, G loss: 7.0401\n",
      "[1452/8000] D loss: 1.0471, G loss: 3.5470\n",
      "[1812/8000] D loss: 0.9060, G loss: 3.0446\n",
      "[2172/8000] D loss: 1.0186, G loss: 5.8494\n",
      "[2532/8000] D loss: 0.9091, G loss: 8.4642\n",
      "[2892/8000] D loss: 0.7418, G loss: 7.4939\n",
      "[3252/8000] D loss: 0.8169, G loss: 6.1208\n",
      "[3612/8000] D loss: 1.0060, G loss: 2.9056\n",
      "[3972/8000] D loss: 1.0280, G loss: 4.8274\n",
      "[4332/8000] D loss: 0.9418, G loss: 6.8637\n",
      "[4692/8000] D loss: 0.9749, G loss: 4.2601\n",
      "[5052/8000] D loss: 0.7531, G loss: 4.4370\n",
      "[5412/8000] D loss: 0.6937, G loss: 10.0745\n",
      "[5772/8000] D loss: 1.0494, G loss: 4.3828\n",
      "[6132/8000] D loss: 1.0829, G loss: 4.5347\n",
      "[6492/8000] D loss: 0.5874, G loss: 5.0404\n",
      "[6852/8000] D loss: 0.7626, G loss: 10.9763\n",
      "[7212/8000] D loss: 1.1478, G loss: 4.3142\n",
      "[7572/8000] D loss: 1.1776, G loss: 3.8879\n",
      "[7932/8000] D loss: 1.1648, G loss: 1.4720\n",
      "train error: \n",
      " D loss: 0.848991, G loss: 6.770682, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.028319, G loss: 20.325551, D accuracy: 77.0%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5865, G loss: 9.5945\n",
      "[372/8000] D loss: 0.9631, G loss: 5.1588\n",
      "[732/8000] D loss: 0.5805, G loss: 11.7060\n",
      "[1092/8000] D loss: 0.9587, G loss: 4.5776\n",
      "[1452/8000] D loss: 0.9131, G loss: 7.6292\n",
      "[1812/8000] D loss: 0.8211, G loss: 6.3548\n",
      "[2172/8000] D loss: 0.5896, G loss: 8.8754\n",
      "[2532/8000] D loss: 0.8412, G loss: 5.5031\n",
      "[2892/8000] D loss: 0.8145, G loss: 8.7350\n",
      "[3252/8000] D loss: 0.6055, G loss: 9.3200\n",
      "[3612/8000] D loss: 0.5856, G loss: 3.7787\n",
      "[3972/8000] D loss: 0.8056, G loss: 9.3348\n",
      "[4332/8000] D loss: 0.9621, G loss: 2.6258\n",
      "[4692/8000] D loss: 0.9337, G loss: 4.8971\n",
      "[5052/8000] D loss: 0.8289, G loss: 5.1745\n",
      "[5412/8000] D loss: 1.2709, G loss: 1.3777\n",
      "[5772/8000] D loss: 0.7844, G loss: 6.8530\n",
      "[6132/8000] D loss: 1.0720, G loss: 2.5980\n",
      "[6492/8000] D loss: 1.1728, G loss: 1.4959\n",
      "[6852/8000] D loss: 0.9248, G loss: 3.3253\n",
      "[7212/8000] D loss: 0.9328, G loss: 6.7356\n",
      "[7572/8000] D loss: 0.7408, G loss: 10.2173\n",
      "[7932/8000] D loss: 0.8147, G loss: 5.3500\n",
      "train error: \n",
      " D loss: 0.847510, G loss: 6.737860, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999056, G loss: 20.631910, D accuracy: 78.0%, cell accuracy: 98.3%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8178, G loss: 8.5542\n",
      "[372/8000] D loss: 1.0473, G loss: 2.4444\n",
      "[732/8000] D loss: 0.5983, G loss: 7.1557\n",
      "[1092/8000] D loss: 0.9235, G loss: 2.4023\n",
      "[1452/8000] D loss: 0.9242, G loss: 7.6038\n",
      "[1812/8000] D loss: 1.0704, G loss: 2.0637\n",
      "[2172/8000] D loss: 0.9595, G loss: 4.1973\n",
      "[2532/8000] D loss: 0.9955, G loss: 8.1597\n",
      "[2892/8000] D loss: 0.9317, G loss: 5.1760\n",
      "[3252/8000] D loss: 1.0508, G loss: 4.7277\n",
      "[3612/8000] D loss: 0.6764, G loss: 5.6844\n",
      "[3972/8000] D loss: 0.8150, G loss: 7.8065\n",
      "[4332/8000] D loss: 1.0210, G loss: 10.0346\n",
      "[4692/8000] D loss: 1.2350, G loss: 4.2471\n",
      "[5052/8000] D loss: 0.8781, G loss: 7.2238\n",
      "[5412/8000] D loss: 0.5627, G loss: 4.3707\n",
      "[5772/8000] D loss: 0.7912, G loss: 10.8745\n",
      "[6132/8000] D loss: 0.5870, G loss: 14.5937\n",
      "[6492/8000] D loss: 0.6029, G loss: 5.6732\n",
      "[6852/8000] D loss: 0.8751, G loss: 4.6359\n",
      "[7212/8000] D loss: 0.8608, G loss: 7.6363\n",
      "[7572/8000] D loss: 0.8016, G loss: 8.7310\n",
      "[7932/8000] D loss: 0.4819, G loss: 9.4005\n",
      "train error: \n",
      " D loss: 0.845190, G loss: 6.452391, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.953720, G loss: 19.907755, D accuracy: 78.7%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0161, G loss: 4.5163\n",
      "[372/8000] D loss: 0.6886, G loss: 6.6843\n",
      "[732/8000] D loss: 0.7901, G loss: 5.2377\n",
      "[1092/8000] D loss: 0.5248, G loss: 13.5740\n",
      "[1452/8000] D loss: 0.7851, G loss: 8.3155\n",
      "[1812/8000] D loss: 0.9438, G loss: 10.2604\n",
      "[2172/8000] D loss: 1.0802, G loss: 2.7008\n",
      "[2532/8000] D loss: 0.8269, G loss: 11.5087\n",
      "[2892/8000] D loss: 0.6008, G loss: 14.1369\n",
      "[3252/8000] D loss: 0.7067, G loss: 10.2677\n",
      "[3612/8000] D loss: 1.0254, G loss: 1.7971\n",
      "[3972/8000] D loss: 0.9204, G loss: 2.7789\n",
      "[4332/8000] D loss: 0.5600, G loss: 11.9855\n",
      "[4692/8000] D loss: 0.7566, G loss: 3.1558\n",
      "[5052/8000] D loss: 0.6374, G loss: 5.0334\n",
      "[5412/8000] D loss: 1.0985, G loss: 3.0285\n",
      "[5772/8000] D loss: 1.0696, G loss: 4.1101\n",
      "[6132/8000] D loss: 0.7765, G loss: 4.1436\n",
      "[6492/8000] D loss: 0.6491, G loss: 5.2083\n",
      "[6852/8000] D loss: 1.0508, G loss: 10.1518\n",
      "[7212/8000] D loss: 0.8674, G loss: 9.3945\n",
      "[7572/8000] D loss: 0.8738, G loss: 4.4950\n",
      "[7932/8000] D loss: 0.6927, G loss: 4.9123\n",
      "train error: \n",
      " D loss: 0.848571, G loss: 6.458916, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.996748, G loss: 19.664655, D accuracy: 78.4%, cell accuracy: 98.2%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7011, G loss: 4.9720\n",
      "[372/8000] D loss: 0.8577, G loss: 7.9467\n",
      "[732/8000] D loss: 1.0028, G loss: 2.1720\n",
      "[1092/8000] D loss: 0.8870, G loss: 5.6633\n",
      "[1452/8000] D loss: 0.5512, G loss: 8.6363\n",
      "[1812/8000] D loss: 1.0356, G loss: 3.4451\n",
      "[2172/8000] D loss: 0.7374, G loss: 7.3932\n",
      "[2532/8000] D loss: 0.8065, G loss: 6.8256\n",
      "[2892/8000] D loss: 0.7731, G loss: 7.7886\n",
      "[3252/8000] D loss: 1.0623, G loss: 5.2682\n",
      "[3612/8000] D loss: 0.8193, G loss: 4.3772\n",
      "[3972/8000] D loss: 0.9989, G loss: 5.1496\n",
      "[4332/8000] D loss: 0.8734, G loss: 3.3408\n",
      "[4692/8000] D loss: 0.6587, G loss: 11.2129\n",
      "[5052/8000] D loss: 0.9198, G loss: 6.0455\n",
      "[5412/8000] D loss: 0.9540, G loss: 8.6000\n",
      "[5772/8000] D loss: 0.6964, G loss: 7.0831\n",
      "[6132/8000] D loss: 0.9423, G loss: 9.1774\n",
      "[6492/8000] D loss: 0.7729, G loss: 3.3766\n",
      "[6852/8000] D loss: 0.5805, G loss: 8.4720\n",
      "[7212/8000] D loss: 0.7706, G loss: 7.3766\n",
      "[7572/8000] D loss: 1.0737, G loss: 3.6250\n",
      "[7932/8000] D loss: 0.8223, G loss: 8.2966\n",
      "train error: \n",
      " D loss: 0.863990, G loss: 5.906026, D accuracy: 70.7%, cell accuracy: 98.7%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.090927, G loss: 18.181722, D accuracy: 73.9%, cell accuracy: 98.2%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9943, G loss: 6.8392\n",
      "[372/8000] D loss: 1.0706, G loss: 4.2612\n",
      "[732/8000] D loss: 0.7004, G loss: 5.7727\n",
      "[1092/8000] D loss: 0.9440, G loss: 6.5183\n",
      "[1452/8000] D loss: 0.8193, G loss: 9.0047\n",
      "[1812/8000] D loss: 0.7132, G loss: 3.1936\n",
      "[2172/8000] D loss: 0.9833, G loss: 4.6076\n",
      "[2532/8000] D loss: 0.8088, G loss: 6.7982\n",
      "[2892/8000] D loss: 0.6897, G loss: 9.4403\n",
      "[3252/8000] D loss: 1.1386, G loss: 2.7520\n",
      "[3612/8000] D loss: 0.8747, G loss: 8.6115\n",
      "[3972/8000] D loss: 0.9596, G loss: 6.6282\n",
      "[4332/8000] D loss: 0.8615, G loss: 6.3225\n",
      "[4692/8000] D loss: 0.9556, G loss: 3.1942\n",
      "[5052/8000] D loss: 0.6574, G loss: 6.4384\n",
      "[5412/8000] D loss: 0.9545, G loss: 3.4854\n",
      "[5772/8000] D loss: 0.7684, G loss: 4.6598\n",
      "[6132/8000] D loss: 0.4676, G loss: 8.8210\n",
      "[6492/8000] D loss: 0.9298, G loss: 6.0341\n",
      "[6852/8000] D loss: 1.0148, G loss: 8.9310\n",
      "[7212/8000] D loss: 1.0004, G loss: 6.0975\n",
      "[7572/8000] D loss: 0.8930, G loss: 10.3658\n",
      "[7932/8000] D loss: 0.7084, G loss: 5.0388\n",
      "train error: \n",
      " D loss: 0.849079, G loss: 6.530505, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.935562, G loss: 19.693283, D accuracy: 80.1%, cell accuracy: 98.2%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5797, G loss: 4.5316\n",
      "[372/8000] D loss: 0.7196, G loss: 2.9567\n",
      "[732/8000] D loss: 0.6852, G loss: 8.3813\n",
      "[1092/8000] D loss: 0.7350, G loss: 5.1680\n",
      "[1452/8000] D loss: 0.7754, G loss: 7.1828\n",
      "[1812/8000] D loss: 0.8923, G loss: 5.8907\n",
      "[2172/8000] D loss: 0.4871, G loss: 10.0018\n",
      "[2532/8000] D loss: 0.8700, G loss: 7.6319\n",
      "[2892/8000] D loss: 0.8591, G loss: 8.2222\n",
      "[3252/8000] D loss: 0.7037, G loss: 6.1604\n",
      "[3612/8000] D loss: 0.5446, G loss: 4.7272\n",
      "[3972/8000] D loss: 0.4734, G loss: 12.6876\n",
      "[4332/8000] D loss: 0.6964, G loss: 8.8310\n",
      "[4692/8000] D loss: 0.8480, G loss: 4.6736\n",
      "[5052/8000] D loss: 0.8587, G loss: 14.3131\n",
      "[5412/8000] D loss: 0.7145, G loss: 4.0155\n",
      "[5772/8000] D loss: 1.0650, G loss: 3.8381\n",
      "[6132/8000] D loss: 0.8888, G loss: 6.5715\n",
      "[6492/8000] D loss: 0.6798, G loss: 5.2225\n",
      "[6852/8000] D loss: 0.7021, G loss: 7.3892\n",
      "[7212/8000] D loss: 0.9238, G loss: 5.6149\n",
      "[7572/8000] D loss: 0.8075, G loss: 7.6467\n",
      "[7932/8000] D loss: 0.7851, G loss: 7.5561\n",
      "train error: \n",
      " D loss: 0.855308, G loss: 6.031658, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.906990, G loss: 19.330955, D accuracy: 81.2%, cell accuracy: 98.2%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7075, G loss: 7.3645\n",
      "[372/8000] D loss: 0.8363, G loss: 4.7642\n",
      "[732/8000] D loss: 0.9500, G loss: 5.4393\n",
      "[1092/8000] D loss: 0.2589, G loss: 9.0700\n",
      "[1452/8000] D loss: 0.9316, G loss: 5.7688\n",
      "[1812/8000] D loss: 0.6055, G loss: 5.3510\n",
      "[2172/8000] D loss: 0.8193, G loss: 5.3446\n",
      "[2532/8000] D loss: 0.6836, G loss: 6.4395\n",
      "[2892/8000] D loss: 0.4545, G loss: 5.5851\n",
      "[3252/8000] D loss: 0.7222, G loss: 5.5942\n",
      "[3612/8000] D loss: 0.7260, G loss: 3.0768\n",
      "[3972/8000] D loss: 0.5773, G loss: 13.3377\n",
      "[4332/8000] D loss: 0.7632, G loss: 4.2542\n",
      "[4692/8000] D loss: 0.9253, G loss: 5.2380\n",
      "[5052/8000] D loss: 0.4838, G loss: 6.1400\n",
      "[5412/8000] D loss: 0.7734, G loss: 6.4547\n",
      "[5772/8000] D loss: 0.2935, G loss: 8.4291\n",
      "[6132/8000] D loss: 0.9605, G loss: 6.5019\n",
      "[6492/8000] D loss: 0.8572, G loss: 4.0782\n",
      "[6852/8000] D loss: 0.5857, G loss: 5.6387\n",
      "[7212/8000] D loss: 1.1411, G loss: 2.1972\n",
      "[7572/8000] D loss: 0.9595, G loss: 11.0156\n",
      "[7932/8000] D loss: 0.5949, G loss: 10.1020\n",
      "train error: \n",
      " D loss: 0.843534, G loss: 7.119643, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.974148, G loss: 21.276357, D accuracy: 77.6%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0503, G loss: 3.4250\n",
      "[372/8000] D loss: 0.9154, G loss: 6.3126\n",
      "[732/8000] D loss: 0.9743, G loss: 2.8981\n",
      "[1092/8000] D loss: 0.8497, G loss: 6.2069\n",
      "[1452/8000] D loss: 0.7491, G loss: 6.4377\n",
      "[1812/8000] D loss: 0.5777, G loss: 7.7352\n",
      "[2172/8000] D loss: 0.6366, G loss: 13.2237\n",
      "[2532/8000] D loss: 0.8135, G loss: 4.6560\n",
      "[2892/8000] D loss: 0.8195, G loss: 8.1145\n",
      "[3252/8000] D loss: 0.8204, G loss: 7.6228\n",
      "[3612/8000] D loss: 0.6574, G loss: 5.4487\n",
      "[3972/8000] D loss: 0.4762, G loss: 7.4018\n",
      "[4332/8000] D loss: 0.9681, G loss: 4.6763\n",
      "[4692/8000] D loss: 0.4733, G loss: 11.5637\n",
      "[5052/8000] D loss: 1.1663, G loss: 4.6666\n",
      "[5412/8000] D loss: 0.8561, G loss: 4.9055\n",
      "[5772/8000] D loss: 0.7563, G loss: 6.8473\n",
      "[6132/8000] D loss: 0.3584, G loss: 9.6045\n",
      "[6492/8000] D loss: 1.1607, G loss: 2.8217\n",
      "[6852/8000] D loss: 0.6649, G loss: 7.0880\n",
      "[7212/8000] D loss: 0.9436, G loss: 5.8213\n",
      "[7572/8000] D loss: 0.8323, G loss: 6.0899\n",
      "[7932/8000] D loss: 0.6731, G loss: 9.2956\n",
      "train error: \n",
      " D loss: 0.860116, G loss: 5.600286, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.016097, G loss: 17.372780, D accuracy: 74.7%, cell accuracy: 98.3%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7854, G loss: 6.2049\n",
      "[372/8000] D loss: 0.7039, G loss: 10.3612\n",
      "[732/8000] D loss: 0.9352, G loss: 3.7112\n",
      "[1092/8000] D loss: 0.8111, G loss: 10.3027\n",
      "[1452/8000] D loss: 0.8645, G loss: 5.1058\n",
      "[1812/8000] D loss: 1.3611, G loss: 1.2350\n",
      "[2172/8000] D loss: 0.9096, G loss: 3.5007\n",
      "[2532/8000] D loss: 0.4950, G loss: 12.9583\n",
      "[2892/8000] D loss: 0.6211, G loss: 5.6556\n",
      "[3252/8000] D loss: 1.0490, G loss: 4.4830\n",
      "[3612/8000] D loss: 0.8238, G loss: 3.7898\n",
      "[3972/8000] D loss: 0.6818, G loss: 8.9741\n",
      "[4332/8000] D loss: 1.0264, G loss: 2.5817\n",
      "[4692/8000] D loss: 1.0538, G loss: 2.7352\n",
      "[5052/8000] D loss: 0.9357, G loss: 4.9878\n",
      "[5412/8000] D loss: 0.7705, G loss: 9.0097\n",
      "[5772/8000] D loss: 0.5296, G loss: 12.5645\n",
      "[6132/8000] D loss: 0.8542, G loss: 10.2305\n",
      "[6492/8000] D loss: 0.7241, G loss: 13.6962\n",
      "[6852/8000] D loss: 0.7294, G loss: 8.1997\n",
      "[7212/8000] D loss: 0.7274, G loss: 3.9784\n",
      "[7572/8000] D loss: 0.6881, G loss: 6.1016\n",
      "[7932/8000] D loss: 0.8227, G loss: 10.3459\n",
      "train error: \n",
      " D loss: 0.855177, G loss: 6.873347, D accuracy: 71.6%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.946432, G loss: 19.928811, D accuracy: 79.5%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0318, G loss: 8.3851\n",
      "[372/8000] D loss: 1.0003, G loss: 4.9774\n",
      "[732/8000] D loss: 1.3158, G loss: 4.6701\n",
      "[1092/8000] D loss: 0.7548, G loss: 12.3368\n",
      "[1452/8000] D loss: 0.9155, G loss: 7.1876\n",
      "[1812/8000] D loss: 0.8263, G loss: 3.9545\n",
      "[2172/8000] D loss: 0.8110, G loss: 11.3482\n",
      "[2532/8000] D loss: 0.8322, G loss: 6.0418\n",
      "[2892/8000] D loss: 0.9406, G loss: 6.6751\n",
      "[3252/8000] D loss: 0.6491, G loss: 10.6328\n",
      "[3612/8000] D loss: 0.9797, G loss: 3.1130\n",
      "[3972/8000] D loss: 0.8207, G loss: 4.0198\n",
      "[4332/8000] D loss: 0.8497, G loss: 6.1656\n",
      "[4692/8000] D loss: 1.0270, G loss: 2.2141\n",
      "[5052/8000] D loss: 0.4273, G loss: 8.7467\n",
      "[5412/8000] D loss: 1.0032, G loss: 5.1757\n",
      "[5772/8000] D loss: 0.8359, G loss: 5.3157\n",
      "[6132/8000] D loss: 1.0134, G loss: 7.4099\n",
      "[6492/8000] D loss: 0.5177, G loss: 8.2873\n",
      "[6852/8000] D loss: 0.7574, G loss: 11.3509\n",
      "[7212/8000] D loss: 0.9938, G loss: 3.1115\n",
      "[7572/8000] D loss: 0.8104, G loss: 6.9396\n",
      "[7932/8000] D loss: 0.5804, G loss: 5.0540\n",
      "train error: \n",
      " D loss: 0.850658, G loss: 6.561795, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.039342, G loss: 20.153171, D accuracy: 77.5%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9310, G loss: 9.1302\n",
      "[372/8000] D loss: 0.5030, G loss: 10.0944\n",
      "[732/8000] D loss: 0.8981, G loss: 2.5908\n",
      "[1092/8000] D loss: 1.0087, G loss: 8.1555\n",
      "[1452/8000] D loss: 1.0464, G loss: 4.3782\n",
      "[1812/8000] D loss: 0.5204, G loss: 9.9274\n",
      "[2172/8000] D loss: 0.9377, G loss: 2.0327\n",
      "[2532/8000] D loss: 0.8288, G loss: 14.8230\n",
      "[2892/8000] D loss: 0.9808, G loss: 7.2364\n",
      "[3252/8000] D loss: 0.5329, G loss: 7.3262\n",
      "[3612/8000] D loss: 0.5502, G loss: 11.3680\n",
      "[3972/8000] D loss: 0.6348, G loss: 4.2618\n",
      "[4332/8000] D loss: 0.6420, G loss: 12.2634\n",
      "[4692/8000] D loss: 1.1780, G loss: 3.4062\n",
      "[5052/8000] D loss: 0.6519, G loss: 12.6476\n",
      "[5412/8000] D loss: 0.8012, G loss: 7.1689\n",
      "[5772/8000] D loss: 0.6649, G loss: 10.6105\n",
      "[6132/8000] D loss: 0.6493, G loss: 5.5199\n",
      "[6492/8000] D loss: 0.8071, G loss: 5.1916\n",
      "[6852/8000] D loss: 0.9665, G loss: 8.7285\n",
      "[7212/8000] D loss: 0.7539, G loss: 6.1278\n",
      "[7572/8000] D loss: 0.8957, G loss: 5.3441\n",
      "[7932/8000] D loss: 0.8339, G loss: 9.9495\n",
      "train error: \n",
      " D loss: 0.852603, G loss: 6.362729, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.941140, G loss: 19.881660, D accuracy: 81.1%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7037, G loss: 9.3297\n",
      "[372/8000] D loss: 0.7022, G loss: 7.3314\n",
      "[732/8000] D loss: 1.0570, G loss: 8.8628\n",
      "[1092/8000] D loss: 0.8691, G loss: 4.1397\n",
      "[1452/8000] D loss: 0.8055, G loss: 4.8598\n",
      "[1812/8000] D loss: 0.5829, G loss: 9.1687\n",
      "[2172/8000] D loss: 0.8666, G loss: 2.8311\n",
      "[2532/8000] D loss: 0.9799, G loss: 4.5423\n",
      "[2892/8000] D loss: 0.5832, G loss: 10.3436\n",
      "[3252/8000] D loss: 1.1617, G loss: 5.6879\n",
      "[3612/8000] D loss: 0.8772, G loss: 7.1611\n",
      "[3972/8000] D loss: 1.0181, G loss: 7.5188\n",
      "[4332/8000] D loss: 0.7648, G loss: 13.6719\n",
      "[4692/8000] D loss: 0.9331, G loss: 5.9150\n",
      "[5052/8000] D loss: 0.8478, G loss: 6.8514\n",
      "[5412/8000] D loss: 0.6959, G loss: 7.4668\n",
      "[5772/8000] D loss: 0.7793, G loss: 6.7348\n",
      "[6132/8000] D loss: 0.6923, G loss: 14.9800\n",
      "[6492/8000] D loss: 0.4819, G loss: 13.0436\n",
      "[6852/8000] D loss: 1.1622, G loss: 5.9472\n",
      "[7212/8000] D loss: 0.5395, G loss: 17.1372\n",
      "[7572/8000] D loss: 0.9462, G loss: 5.0331\n",
      "[7932/8000] D loss: 0.9338, G loss: 3.6516\n",
      "train error: \n",
      " D loss: 0.859824, G loss: 4.813114, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.955487, G loss: 16.102052, D accuracy: 77.2%, cell accuracy: 98.3%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7058, G loss: 7.0409\n",
      "[372/8000] D loss: 0.8001, G loss: 2.7273\n",
      "[732/8000] D loss: 0.8493, G loss: 6.0931\n",
      "[1092/8000] D loss: 0.9924, G loss: 6.7624\n",
      "[1452/8000] D loss: 0.8180, G loss: 7.3531\n",
      "[1812/8000] D loss: 0.3592, G loss: 13.7350\n",
      "[2172/8000] D loss: 0.8925, G loss: 10.1676\n",
      "[2532/8000] D loss: 1.0306, G loss: 11.8772\n",
      "[2892/8000] D loss: 1.0527, G loss: 4.4858\n",
      "[3252/8000] D loss: 0.7332, G loss: 15.4480\n",
      "[3612/8000] D loss: 0.6617, G loss: 6.8988\n",
      "[3972/8000] D loss: 0.8055, G loss: 8.2319\n",
      "[4332/8000] D loss: 1.1752, G loss: 1.7799\n",
      "[4692/8000] D loss: 0.5875, G loss: 5.1082\n",
      "[5052/8000] D loss: 0.9316, G loss: 3.5834\n",
      "[5412/8000] D loss: 0.9045, G loss: 6.9148\n",
      "[5772/8000] D loss: 1.1797, G loss: 3.0746\n",
      "[6132/8000] D loss: 0.8363, G loss: 3.8247\n",
      "[6492/8000] D loss: 0.4721, G loss: 8.0399\n",
      "[6852/8000] D loss: 0.6166, G loss: 10.3137\n",
      "[7212/8000] D loss: 0.7724, G loss: 7.4496\n",
      "[7572/8000] D loss: 1.1632, G loss: 1.3523\n",
      "[7932/8000] D loss: 0.8257, G loss: 6.6885\n",
      "train error: \n",
      " D loss: 0.844579, G loss: 6.174354, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.998100, G loss: 19.112307, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8228, G loss: 6.2806\n",
      "[372/8000] D loss: 0.9507, G loss: 1.8602\n",
      "[732/8000] D loss: 0.6165, G loss: 6.8777\n",
      "[1092/8000] D loss: 0.9844, G loss: 9.6520\n",
      "[1452/8000] D loss: 0.8235, G loss: 7.8546\n",
      "[1812/8000] D loss: 0.5786, G loss: 12.3552\n",
      "[2172/8000] D loss: 0.8166, G loss: 13.6019\n",
      "[2532/8000] D loss: 0.9682, G loss: 3.0751\n",
      "[2892/8000] D loss: 1.2102, G loss: 1.2768\n",
      "[3252/8000] D loss: 0.7579, G loss: 10.1917\n",
      "[3612/8000] D loss: 0.6468, G loss: 9.3269\n",
      "[3972/8000] D loss: 0.3633, G loss: 13.1552\n",
      "[4332/8000] D loss: 0.5858, G loss: 16.6845\n",
      "[4692/8000] D loss: 0.9889, G loss: 3.3087\n",
      "[5052/8000] D loss: 0.4407, G loss: 12.6515\n",
      "[5412/8000] D loss: 0.6942, G loss: 8.4355\n",
      "[5772/8000] D loss: 0.7559, G loss: 7.4910\n",
      "[6132/8000] D loss: 0.9169, G loss: 5.5323\n",
      "[6492/8000] D loss: 0.6422, G loss: 12.4553\n",
      "[6852/8000] D loss: 0.5697, G loss: 12.2165\n",
      "[7212/8000] D loss: 1.1905, G loss: 4.2783\n",
      "[7572/8000] D loss: 0.9459, G loss: 3.3687\n",
      "[7932/8000] D loss: 0.7038, G loss: 5.7457\n",
      "train error: \n",
      " D loss: 0.849339, G loss: 7.024095, D accuracy: 71.3%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.044837, G loss: 21.015775, D accuracy: 76.4%, cell accuracy: 98.2%, board accuracy: 26.7% \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2042, G loss: 3.4575\n",
      "[372/8000] D loss: 0.4991, G loss: 15.6928\n",
      "[732/8000] D loss: 0.5428, G loss: 6.1027\n",
      "[1092/8000] D loss: 0.8370, G loss: 10.4997\n",
      "[1452/8000] D loss: 1.0802, G loss: 2.8829\n",
      "[1812/8000] D loss: 0.9164, G loss: 8.5978\n",
      "[2172/8000] D loss: 0.4986, G loss: 15.5602\n",
      "[2532/8000] D loss: 0.4901, G loss: 10.5656\n",
      "[2892/8000] D loss: 1.0448, G loss: 1.9944\n",
      "[3252/8000] D loss: 0.7105, G loss: 8.3350\n",
      "[3612/8000] D loss: 0.8570, G loss: 9.0388\n",
      "[3972/8000] D loss: 1.0446, G loss: 6.5758\n",
      "[4332/8000] D loss: 0.8161, G loss: 6.7247\n",
      "[4692/8000] D loss: 0.8148, G loss: 7.0730\n",
      "[5052/8000] D loss: 0.4772, G loss: 9.9336\n",
      "[5412/8000] D loss: 1.1868, G loss: 0.9229\n",
      "[5772/8000] D loss: 0.8356, G loss: 9.3191\n",
      "[6132/8000] D loss: 0.4927, G loss: 13.7289\n",
      "[6492/8000] D loss: 0.8328, G loss: 9.0259\n",
      "[6852/8000] D loss: 0.7449, G loss: 5.6376\n",
      "[7212/8000] D loss: 1.0987, G loss: 1.6586\n",
      "[7572/8000] D loss: 0.7566, G loss: 3.0319\n",
      "[7932/8000] D loss: 0.7125, G loss: 15.0724\n",
      "train error: \n",
      " D loss: 0.855274, G loss: 7.048055, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.842938, G loss: 21.729244, D accuracy: 82.2%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5521, G loss: 10.9888\n",
      "[372/8000] D loss: 0.6706, G loss: 5.6807\n",
      "[732/8000] D loss: 0.7881, G loss: 11.1657\n",
      "[1092/8000] D loss: 0.7451, G loss: 7.1402\n",
      "[1452/8000] D loss: 0.7541, G loss: 8.9318\n",
      "[1812/8000] D loss: 1.0476, G loss: 4.7801\n",
      "[2172/8000] D loss: 0.6696, G loss: 8.2040\n",
      "[2532/8000] D loss: 0.6247, G loss: 7.5241\n",
      "[2892/8000] D loss: 1.0534, G loss: 3.1726\n",
      "[3252/8000] D loss: 0.8157, G loss: 3.3958\n",
      "[3612/8000] D loss: 0.6533, G loss: 7.6686\n",
      "[3972/8000] D loss: 1.0422, G loss: 4.9798\n",
      "[4332/8000] D loss: 0.9640, G loss: 5.8314\n",
      "[4692/8000] D loss: 1.1901, G loss: 1.8853\n",
      "[5052/8000] D loss: 1.1911, G loss: 2.8879\n",
      "[5412/8000] D loss: 0.5865, G loss: 9.5200\n",
      "[5772/8000] D loss: 0.7147, G loss: 12.5877\n",
      "[6132/8000] D loss: 0.8202, G loss: 12.0312\n",
      "[6492/8000] D loss: 0.7471, G loss: 2.4108\n",
      "[6852/8000] D loss: 1.0823, G loss: 6.4158\n",
      "[7212/8000] D loss: 1.1339, G loss: 3.0221\n",
      "[7572/8000] D loss: 0.4805, G loss: 14.3810\n",
      "[7932/8000] D loss: 0.6142, G loss: 11.5856\n",
      "train error: \n",
      " D loss: 0.846019, G loss: 6.492434, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999969, G loss: 20.318661, D accuracy: 77.4%, cell accuracy: 98.3%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6798, G loss: 9.7931\n",
      "[372/8000] D loss: 0.6893, G loss: 12.5264\n",
      "[732/8000] D loss: 0.8871, G loss: 4.1792\n",
      "[1092/8000] D loss: 0.6980, G loss: 7.5719\n",
      "[1452/8000] D loss: 0.9303, G loss: 2.7908\n",
      "[1812/8000] D loss: 0.7413, G loss: 7.9887\n",
      "[2172/8000] D loss: 0.4972, G loss: 7.5297\n",
      "[2532/8000] D loss: 1.0997, G loss: 7.4397\n",
      "[2892/8000] D loss: 0.9607, G loss: 3.5974\n",
      "[3252/8000] D loss: 0.5212, G loss: 19.2129\n",
      "[3612/8000] D loss: 1.0574, G loss: 3.2499\n",
      "[3972/8000] D loss: 0.8924, G loss: 5.7234\n",
      "[4332/8000] D loss: 0.6438, G loss: 11.1449\n",
      "[4692/8000] D loss: 0.7558, G loss: 8.9869\n",
      "[5052/8000] D loss: 0.9491, G loss: 6.0953\n",
      "[5412/8000] D loss: 0.3803, G loss: 6.5264\n",
      "[5772/8000] D loss: 0.5941, G loss: 9.7167\n",
      "[6132/8000] D loss: 1.0741, G loss: 3.8948\n",
      "[6492/8000] D loss: 0.8125, G loss: 2.5630\n",
      "[6852/8000] D loss: 0.9129, G loss: 7.8778\n",
      "[7212/8000] D loss: 0.8157, G loss: 5.7469\n",
      "[7572/8000] D loss: 0.9928, G loss: 4.2850\n",
      "[7932/8000] D loss: 0.7804, G loss: 3.5761\n",
      "train error: \n",
      " D loss: 0.850858, G loss: 4.999073, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.919902, G loss: 16.596551, D accuracy: 79.9%, cell accuracy: 98.2%, board accuracy: 26.4% \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5817, G loss: 10.6727\n",
      "[372/8000] D loss: 0.7010, G loss: 7.7293\n",
      "[732/8000] D loss: 0.7476, G loss: 4.2508\n",
      "[1092/8000] D loss: 0.8950, G loss: 3.3989\n",
      "[1452/8000] D loss: 0.4735, G loss: 7.8911\n",
      "[1812/8000] D loss: 0.7536, G loss: 7.8478\n",
      "[2172/8000] D loss: 0.5533, G loss: 7.1632\n",
      "[2532/8000] D loss: 0.8565, G loss: 5.1138\n",
      "[2892/8000] D loss: 0.7003, G loss: 10.0063\n",
      "[3252/8000] D loss: 0.7813, G loss: 5.1832\n",
      "[3612/8000] D loss: 0.5917, G loss: 7.2747\n",
      "[3972/8000] D loss: 0.8221, G loss: 8.2542\n",
      "[4332/8000] D loss: 0.8604, G loss: 5.7796\n",
      "[4692/8000] D loss: 0.8128, G loss: 9.7073\n",
      "[5052/8000] D loss: 0.6845, G loss: 7.8903\n",
      "[5412/8000] D loss: 0.6616, G loss: 13.5678\n",
      "[5772/8000] D loss: 0.5757, G loss: 10.3500\n",
      "[6132/8000] D loss: 0.7630, G loss: 7.6501\n",
      "[6492/8000] D loss: 0.9277, G loss: 6.1057\n",
      "[6852/8000] D loss: 0.9583, G loss: 6.7077\n",
      "[7212/8000] D loss: 0.4037, G loss: 13.8860\n",
      "[7572/8000] D loss: 0.8771, G loss: 4.7323\n",
      "[7932/8000] D loss: 1.2949, G loss: 0.9053\n",
      "train error: \n",
      " D loss: 0.845532, G loss: 7.799263, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.087539, G loss: 22.277155, D accuracy: 77.3%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9517, G loss: 4.3634\n",
      "[372/8000] D loss: 1.0961, G loss: 7.8740\n",
      "[732/8000] D loss: 0.6986, G loss: 6.6529\n",
      "[1092/8000] D loss: 0.9037, G loss: 4.2080\n",
      "[1452/8000] D loss: 0.7874, G loss: 6.2508\n",
      "[1812/8000] D loss: 0.8161, G loss: 10.7538\n",
      "[2172/8000] D loss: 0.8453, G loss: 6.3495\n",
      "[2532/8000] D loss: 0.8099, G loss: 9.7610\n",
      "[2892/8000] D loss: 0.6997, G loss: 8.8182\n",
      "[3252/8000] D loss: 1.0567, G loss: 4.0530\n",
      "[3612/8000] D loss: 1.1845, G loss: 5.7035\n",
      "[3972/8000] D loss: 1.0418, G loss: 8.6658\n",
      "[4332/8000] D loss: 0.7352, G loss: 5.4496\n",
      "[4692/8000] D loss: 0.6958, G loss: 7.9776\n",
      "[5052/8000] D loss: 0.9638, G loss: 8.1217\n",
      "[5412/8000] D loss: 0.8133, G loss: 15.4551\n",
      "[5772/8000] D loss: 0.8132, G loss: 10.8551\n",
      "[6132/8000] D loss: 0.5993, G loss: 16.4022\n",
      "[6492/8000] D loss: 0.5737, G loss: 8.4444\n",
      "[6852/8000] D loss: 0.7555, G loss: 10.9140\n",
      "[7212/8000] D loss: 0.4179, G loss: 18.4699\n",
      "[7572/8000] D loss: 0.5871, G loss: 19.8696\n",
      "[7932/8000] D loss: 0.7428, G loss: 6.4938\n",
      "train error: \n",
      " D loss: 0.844674, G loss: 6.641574, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.917605, G loss: 20.626493, D accuracy: 79.1%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0493, G loss: 2.9826\n",
      "[372/8000] D loss: 0.9452, G loss: 5.3610\n",
      "[732/8000] D loss: 0.6102, G loss: 6.8783\n",
      "[1092/8000] D loss: 0.8989, G loss: 4.1919\n",
      "[1452/8000] D loss: 0.6857, G loss: 18.5071\n",
      "[1812/8000] D loss: 0.7596, G loss: 9.5298\n",
      "[2172/8000] D loss: 0.6804, G loss: 10.5983\n",
      "[2532/8000] D loss: 0.5898, G loss: 9.1648\n",
      "[2892/8000] D loss: 0.9295, G loss: 3.0230\n",
      "[3252/8000] D loss: 0.8886, G loss: 4.9066\n",
      "[3612/8000] D loss: 0.7152, G loss: 5.4656\n",
      "[3972/8000] D loss: 0.9306, G loss: 9.5417\n",
      "[4332/8000] D loss: 0.8425, G loss: 9.4901\n",
      "[4692/8000] D loss: 0.8476, G loss: 4.4219\n",
      "[5052/8000] D loss: 0.8911, G loss: 7.7186\n",
      "[5412/8000] D loss: 0.4646, G loss: 5.0760\n",
      "[5772/8000] D loss: 1.0589, G loss: 3.9285\n",
      "[6132/8000] D loss: 0.6539, G loss: 5.3318\n",
      "[6492/8000] D loss: 1.0220, G loss: 3.3394\n",
      "[6852/8000] D loss: 0.5246, G loss: 13.2390\n",
      "[7212/8000] D loss: 0.9412, G loss: 4.9699\n",
      "[7572/8000] D loss: 0.7367, G loss: 4.2838\n",
      "[7932/8000] D loss: 0.7838, G loss: 13.9702\n",
      "train error: \n",
      " D loss: 0.882900, G loss: 5.575276, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.985647, G loss: 18.748752, D accuracy: 79.7%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8709, G loss: 7.5532\n",
      "[372/8000] D loss: 1.0652, G loss: 1.8366\n",
      "[732/8000] D loss: 0.7048, G loss: 5.1433\n",
      "[1092/8000] D loss: 1.0693, G loss: 1.9185\n",
      "[1452/8000] D loss: 1.2577, G loss: 2.2347\n",
      "[1812/8000] D loss: 0.7525, G loss: 7.5116\n",
      "[2172/8000] D loss: 0.6919, G loss: 9.5084\n",
      "[2532/8000] D loss: 0.7216, G loss: 8.0130\n",
      "[2892/8000] D loss: 1.0614, G loss: 7.2643\n",
      "[3252/8000] D loss: 0.6972, G loss: 5.6810\n",
      "[3612/8000] D loss: 0.6493, G loss: 9.1685\n",
      "[3972/8000] D loss: 0.8744, G loss: 5.2369\n",
      "[4332/8000] D loss: 0.6519, G loss: 5.6303\n",
      "[4692/8000] D loss: 0.9557, G loss: 2.7752\n",
      "[5052/8000] D loss: 0.8468, G loss: 2.8592\n",
      "[5412/8000] D loss: 0.8386, G loss: 5.5391\n",
      "[5772/8000] D loss: 0.6806, G loss: 12.7361\n",
      "[6132/8000] D loss: 0.5652, G loss: 7.6563\n",
      "[6492/8000] D loss: 0.6273, G loss: 16.4065\n",
      "[6852/8000] D loss: 1.1509, G loss: 1.8190\n",
      "[7212/8000] D loss: 0.8644, G loss: 7.3366\n",
      "[7572/8000] D loss: 1.0099, G loss: 6.7640\n",
      "[7932/8000] D loss: 0.8493, G loss: 4.1249\n",
      "train error: \n",
      " D loss: 0.878206, G loss: 5.287039, D accuracy: 71.5%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.796385, G loss: 18.433839, D accuracy: 82.4%, cell accuracy: 98.2%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8285, G loss: 4.1006\n",
      "[372/8000] D loss: 0.6887, G loss: 9.1699\n",
      "[732/8000] D loss: 0.8331, G loss: 5.6272\n",
      "[1092/8000] D loss: 1.1415, G loss: 5.8318\n",
      "[1452/8000] D loss: 1.0461, G loss: 4.4790\n",
      "[1812/8000] D loss: 0.9045, G loss: 6.4870\n",
      "[2172/8000] D loss: 0.8798, G loss: 8.3307\n",
      "[2532/8000] D loss: 0.7479, G loss: 4.0755\n",
      "[2892/8000] D loss: 0.6562, G loss: 14.0533\n",
      "[3252/8000] D loss: 0.3727, G loss: 9.7070\n",
      "[3612/8000] D loss: 0.8245, G loss: 8.6921\n",
      "[3972/8000] D loss: 1.0135, G loss: 2.7116\n",
      "[4332/8000] D loss: 0.9115, G loss: 3.0428\n",
      "[4692/8000] D loss: 0.8320, G loss: 6.7103\n",
      "[5052/8000] D loss: 0.6838, G loss: 8.5047\n",
      "[5412/8000] D loss: 0.8427, G loss: 4.2659\n",
      "[5772/8000] D loss: 1.1507, G loss: 2.3689\n",
      "[6132/8000] D loss: 0.4796, G loss: 6.5870\n",
      "[6492/8000] D loss: 0.6777, G loss: 9.1523\n",
      "[6852/8000] D loss: 0.8089, G loss: 5.0781\n",
      "[7212/8000] D loss: 1.0390, G loss: 2.2999\n",
      "[7572/8000] D loss: 1.0962, G loss: 2.7876\n",
      "[7932/8000] D loss: 0.7460, G loss: 5.6957\n",
      "train error: \n",
      " D loss: 0.875545, G loss: 8.789352, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.147721, G loss: 24.282898, D accuracy: 75.6%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2704, G loss: 6.0190\n",
      "[372/8000] D loss: 0.7726, G loss: 3.8332\n",
      "[732/8000] D loss: 0.8943, G loss: 8.4951\n",
      "[1092/8000] D loss: 0.5874, G loss: 6.5756\n",
      "[1452/8000] D loss: 0.7063, G loss: 10.5620\n",
      "[1812/8000] D loss: 0.3674, G loss: 13.3987\n",
      "[2172/8000] D loss: 0.8064, G loss: 7.5077\n",
      "[2532/8000] D loss: 0.9308, G loss: 9.2506\n",
      "[2892/8000] D loss: 0.7651, G loss: 7.9639\n",
      "[3252/8000] D loss: 0.8363, G loss: 4.4511\n",
      "[3612/8000] D loss: 0.7826, G loss: 6.9769\n",
      "[3972/8000] D loss: 0.5476, G loss: 10.8099\n",
      "[4332/8000] D loss: 0.7523, G loss: 11.0455\n",
      "[4692/8000] D loss: 0.6971, G loss: 8.9017\n",
      "[5052/8000] D loss: 0.5781, G loss: 12.5457\n",
      "[5412/8000] D loss: 0.9299, G loss: 5.9244\n",
      "[5772/8000] D loss: 1.0426, G loss: 11.6116\n",
      "[6132/8000] D loss: 1.1210, G loss: 1.4858\n",
      "[6492/8000] D loss: 0.8320, G loss: 8.2273\n",
      "[6852/8000] D loss: 0.6867, G loss: 4.5225\n",
      "[7212/8000] D loss: 0.3690, G loss: 12.5053\n",
      "[7572/8000] D loss: 0.5880, G loss: 4.3215\n",
      "[7932/8000] D loss: 0.8148, G loss: 4.9576\n",
      "train error: \n",
      " D loss: 0.851362, G loss: 5.823409, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.975523, G loss: 18.461346, D accuracy: 81.2%, cell accuracy: 98.2%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7384, G loss: 8.4173\n",
      "[372/8000] D loss: 0.8326, G loss: 4.0104\n",
      "[732/8000] D loss: 0.8396, G loss: 4.6884\n",
      "[1092/8000] D loss: 0.5827, G loss: 6.2135\n",
      "[1452/8000] D loss: 0.7366, G loss: 14.7084\n",
      "[1812/8000] D loss: 0.6848, G loss: 7.2944\n",
      "[2172/8000] D loss: 1.1224, G loss: 2.3432\n",
      "[2532/8000] D loss: 0.8990, G loss: 5.8399\n",
      "[2892/8000] D loss: 0.7054, G loss: 6.1232\n",
      "[3252/8000] D loss: 0.8993, G loss: 4.8942\n",
      "[3612/8000] D loss: 0.9251, G loss: 5.4869\n",
      "[3972/8000] D loss: 0.9273, G loss: 5.1569\n",
      "[4332/8000] D loss: 1.0224, G loss: 5.0069\n",
      "[4692/8000] D loss: 0.9334, G loss: 6.7847\n",
      "[5052/8000] D loss: 0.9368, G loss: 4.9097\n",
      "[5412/8000] D loss: 0.9107, G loss: 6.0871\n",
      "[5772/8000] D loss: 0.8920, G loss: 2.3988\n",
      "[6132/8000] D loss: 0.8298, G loss: 8.6730\n",
      "[6492/8000] D loss: 0.8371, G loss: 6.2560\n",
      "[6852/8000] D loss: 1.0543, G loss: 1.8780\n",
      "[7212/8000] D loss: 1.1612, G loss: 3.3451\n",
      "[7572/8000] D loss: 1.0879, G loss: 2.5766\n",
      "[7932/8000] D loss: 0.7839, G loss: 9.4399\n",
      "train error: \n",
      " D loss: 0.853599, G loss: 6.893102, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.100989, G loss: 20.393545, D accuracy: 74.9%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9197, G loss: 11.7077\n",
      "[372/8000] D loss: 0.8464, G loss: 6.4083\n",
      "[732/8000] D loss: 0.7353, G loss: 6.9098\n",
      "[1092/8000] D loss: 0.4831, G loss: 10.2626\n",
      "[1452/8000] D loss: 0.5846, G loss: 13.5787\n",
      "[1812/8000] D loss: 0.9244, G loss: 11.5456\n",
      "[2172/8000] D loss: 0.9730, G loss: 16.6230\n",
      "[2532/8000] D loss: 0.9730, G loss: 10.8279\n",
      "[2892/8000] D loss: 0.9120, G loss: 3.4241\n",
      "[3252/8000] D loss: 0.5929, G loss: 8.8597\n",
      "[3612/8000] D loss: 1.0485, G loss: 4.5513\n",
      "[3972/8000] D loss: 1.0993, G loss: 5.5892\n",
      "[4332/8000] D loss: 0.9478, G loss: 9.8827\n",
      "[4692/8000] D loss: 0.8190, G loss: 5.4733\n",
      "[5052/8000] D loss: 0.6735, G loss: 6.5349\n",
      "[5412/8000] D loss: 0.9734, G loss: 3.2936\n",
      "[5772/8000] D loss: 0.9347, G loss: 6.9035\n",
      "[6132/8000] D loss: 1.0234, G loss: 3.8809\n",
      "[6492/8000] D loss: 0.8120, G loss: 5.5797\n",
      "[6852/8000] D loss: 0.9367, G loss: 6.5020\n",
      "[7212/8000] D loss: 0.7189, G loss: 6.7788\n",
      "[7572/8000] D loss: 0.5873, G loss: 13.4409\n",
      "[7932/8000] D loss: 0.7437, G loss: 7.4770\n",
      "train error: \n",
      " D loss: 0.856555, G loss: 6.416595, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.049025, G loss: 19.452822, D accuracy: 74.5%, cell accuracy: 98.3%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8113, G loss: 6.2042\n",
      "[372/8000] D loss: 0.5093, G loss: 5.2514\n",
      "[732/8000] D loss: 0.9237, G loss: 6.1143\n",
      "[1092/8000] D loss: 0.7995, G loss: 6.1399\n",
      "[1452/8000] D loss: 1.0471, G loss: 5.4424\n",
      "[1812/8000] D loss: 0.9333, G loss: 7.3009\n",
      "[2172/8000] D loss: 1.1547, G loss: 9.1116\n",
      "[2532/8000] D loss: 1.0629, G loss: 3.3842\n",
      "[2892/8000] D loss: 0.8380, G loss: 13.9032\n",
      "[3252/8000] D loss: 0.9461, G loss: 5.0206\n",
      "[3612/8000] D loss: 1.2853, G loss: 2.1407\n",
      "[3972/8000] D loss: 0.7576, G loss: 5.3458\n",
      "[4332/8000] D loss: 1.0548, G loss: 4.4884\n",
      "[4692/8000] D loss: 0.6166, G loss: 5.6666\n",
      "[5052/8000] D loss: 1.0657, G loss: 4.9611\n",
      "[5412/8000] D loss: 0.7460, G loss: 10.9283\n",
      "[5772/8000] D loss: 1.1571, G loss: 6.6031\n",
      "[6132/8000] D loss: 0.6346, G loss: 6.9494\n",
      "[6492/8000] D loss: 0.9250, G loss: 4.4187\n",
      "[6852/8000] D loss: 0.9491, G loss: 1.6710\n",
      "[7212/8000] D loss: 1.0144, G loss: 2.4202\n",
      "[7572/8000] D loss: 0.7409, G loss: 8.1763\n",
      "[7932/8000] D loss: 0.7961, G loss: 7.5491\n",
      "train error: \n",
      " D loss: 0.844569, G loss: 5.826863, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.931458, G loss: 18.384029, D accuracy: 79.6%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1132, G loss: 1.6548\n",
      "[372/8000] D loss: 0.4896, G loss: 19.2463\n",
      "[732/8000] D loss: 1.0074, G loss: 7.3807\n",
      "[1092/8000] D loss: 1.1773, G loss: 5.5698\n",
      "[1452/8000] D loss: 0.6734, G loss: 7.0717\n",
      "[1812/8000] D loss: 0.7450, G loss: 8.3089\n",
      "[2172/8000] D loss: 0.7970, G loss: 9.0509\n",
      "[2532/8000] D loss: 1.1425, G loss: 1.9882\n",
      "[2892/8000] D loss: 0.9369, G loss: 2.8823\n",
      "[3252/8000] D loss: 1.1269, G loss: 3.5916\n",
      "[3612/8000] D loss: 0.8277, G loss: 5.1305\n",
      "[3972/8000] D loss: 0.7472, G loss: 8.9708\n",
      "[4332/8000] D loss: 0.8524, G loss: 9.1870\n",
      "[4692/8000] D loss: 0.6933, G loss: 5.0778\n",
      "[5052/8000] D loss: 1.0514, G loss: 6.7626\n",
      "[5412/8000] D loss: 1.1027, G loss: 2.9272\n",
      "[5772/8000] D loss: 0.3374, G loss: 10.7336\n",
      "[6132/8000] D loss: 0.7068, G loss: 6.7048\n",
      "[6492/8000] D loss: 0.7508, G loss: 8.5681\n",
      "[6852/8000] D loss: 0.7475, G loss: 7.6173\n",
      "[7212/8000] D loss: 0.7949, G loss: 10.4008\n",
      "[7572/8000] D loss: 1.2479, G loss: 1.5824\n",
      "[7932/8000] D loss: 0.7581, G loss: 3.8308\n",
      "train error: \n",
      " D loss: 0.853733, G loss: 4.889182, D accuracy: 72.2%, cell accuracy: 98.7%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.878766, G loss: 16.834603, D accuracy: 80.6%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0698, G loss: 2.0915\n",
      "[372/8000] D loss: 1.2094, G loss: 9.8561\n",
      "[732/8000] D loss: 0.7176, G loss: 7.5992\n",
      "[1092/8000] D loss: 0.5408, G loss: 8.3702\n",
      "[1452/8000] D loss: 1.0914, G loss: 3.5725\n",
      "[1812/8000] D loss: 0.4893, G loss: 8.7653\n",
      "[2172/8000] D loss: 0.7788, G loss: 8.1814\n",
      "[2532/8000] D loss: 0.9349, G loss: 3.8669\n",
      "[2892/8000] D loss: 0.6971, G loss: 4.8375\n",
      "[3252/8000] D loss: 0.9213, G loss: 7.5257\n",
      "[3612/8000] D loss: 1.0584, G loss: 3.2375\n",
      "[3972/8000] D loss: 0.7559, G loss: 7.3857\n",
      "[4332/8000] D loss: 1.2782, G loss: 3.2687\n",
      "[4692/8000] D loss: 0.6228, G loss: 5.8024\n",
      "[5052/8000] D loss: 0.9338, G loss: 4.7493\n",
      "[5412/8000] D loss: 0.9106, G loss: 6.0966\n",
      "[5772/8000] D loss: 0.8403, G loss: 5.5696\n",
      "[6132/8000] D loss: 0.9746, G loss: 3.5372\n",
      "[6492/8000] D loss: 0.6701, G loss: 7.2417\n",
      "[6852/8000] D loss: 1.1735, G loss: 1.4355\n",
      "[7212/8000] D loss: 0.5356, G loss: 8.6084\n",
      "[7572/8000] D loss: 0.9483, G loss: 2.5419\n",
      "[7932/8000] D loss: 0.7838, G loss: 12.7449\n",
      "train error: \n",
      " D loss: 0.847605, G loss: 6.801567, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.941598, G loss: 20.901056, D accuracy: 76.7%, cell accuracy: 98.2%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9947, G loss: 3.5810\n",
      "[372/8000] D loss: 0.6904, G loss: 11.5449\n",
      "[732/8000] D loss: 0.8865, G loss: 3.3420\n",
      "[1092/8000] D loss: 0.6329, G loss: 8.3788\n",
      "[1452/8000] D loss: 0.9430, G loss: 2.1507\n",
      "[1812/8000] D loss: 1.0476, G loss: 4.9723\n",
      "[2172/8000] D loss: 0.8332, G loss: 2.4332\n",
      "[2532/8000] D loss: 1.3797, G loss: 0.7554\n",
      "[2892/8000] D loss: 0.9261, G loss: 10.8041\n",
      "[3252/8000] D loss: 0.6835, G loss: 9.6839\n",
      "[3612/8000] D loss: 0.5155, G loss: 4.8978\n",
      "[3972/8000] D loss: 0.8734, G loss: 9.4487\n",
      "[4332/8000] D loss: 0.5807, G loss: 10.4880\n",
      "[4692/8000] D loss: 0.6222, G loss: 8.6017\n",
      "[5052/8000] D loss: 0.6959, G loss: 10.2506\n",
      "[5412/8000] D loss: 0.9313, G loss: 2.9207\n",
      "[5772/8000] D loss: 0.7576, G loss: 8.8747\n",
      "[6132/8000] D loss: 0.4132, G loss: 9.1576\n",
      "[6492/8000] D loss: 0.8121, G loss: 6.5062\n",
      "[6852/8000] D loss: 1.0757, G loss: 1.8849\n",
      "[7212/8000] D loss: 0.7149, G loss: 5.6888\n",
      "[7572/8000] D loss: 0.8868, G loss: 6.8964\n",
      "[7932/8000] D loss: 0.7830, G loss: 13.7815\n",
      "train error: \n",
      " D loss: 0.845355, G loss: 8.045769, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.953024, G loss: 23.583123, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8918, G loss: 9.4272\n",
      "[372/8000] D loss: 0.5981, G loss: 6.1903\n",
      "[732/8000] D loss: 0.4922, G loss: 12.1179\n",
      "[1092/8000] D loss: 0.5744, G loss: 4.8571\n",
      "[1452/8000] D loss: 0.5924, G loss: 4.8759\n",
      "[1812/8000] D loss: 0.9769, G loss: 2.1663\n",
      "[2172/8000] D loss: 0.7111, G loss: 7.1783\n",
      "[2532/8000] D loss: 0.6614, G loss: 12.3745\n",
      "[2892/8000] D loss: 0.8448, G loss: 9.5693\n",
      "[3252/8000] D loss: 1.0496, G loss: 2.0138\n",
      "[3612/8000] D loss: 0.8135, G loss: 6.2087\n",
      "[3972/8000] D loss: 1.0783, G loss: 4.0527\n",
      "[4332/8000] D loss: 1.0697, G loss: 3.1840\n",
      "[4692/8000] D loss: 1.1299, G loss: 5.7777\n",
      "[5052/8000] D loss: 0.9238, G loss: 3.2771\n",
      "[5412/8000] D loss: 1.1656, G loss: 6.8516\n",
      "[5772/8000] D loss: 1.0514, G loss: 4.6263\n",
      "[6132/8000] D loss: 0.6304, G loss: 2.8018\n",
      "[6492/8000] D loss: 0.5876, G loss: 7.6352\n",
      "[6852/8000] D loss: 0.9186, G loss: 6.4843\n",
      "[7212/8000] D loss: 0.9197, G loss: 2.8687\n",
      "[7572/8000] D loss: 0.7162, G loss: 5.4974\n",
      "[7932/8000] D loss: 1.0039, G loss: 13.0437\n",
      "train error: \n",
      " D loss: 0.871333, G loss: 7.827994, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.123162, G loss: 22.689417, D accuracy: 77.9%, cell accuracy: 98.3%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5278, G loss: 7.8933\n",
      "[372/8000] D loss: 1.0512, G loss: 5.2997\n",
      "[732/8000] D loss: 0.4814, G loss: 8.3999\n",
      "[1092/8000] D loss: 0.6766, G loss: 5.6744\n",
      "[1452/8000] D loss: 0.7757, G loss: 6.8018\n",
      "[1812/8000] D loss: 0.8217, G loss: 7.9856\n",
      "[2172/8000] D loss: 0.4712, G loss: 10.1350\n",
      "[2532/8000] D loss: 1.0404, G loss: 5.8616\n",
      "[2892/8000] D loss: 0.8730, G loss: 5.1523\n",
      "[3252/8000] D loss: 0.7311, G loss: 7.2858\n",
      "[3612/8000] D loss: 0.9145, G loss: 5.5486\n",
      "[3972/8000] D loss: 0.9942, G loss: 3.5811\n",
      "[4332/8000] D loss: 0.8381, G loss: 8.9316\n",
      "[4692/8000] D loss: 0.4090, G loss: 13.9413\n",
      "[5052/8000] D loss: 0.7571, G loss: 6.1783\n",
      "[5412/8000] D loss: 0.6329, G loss: 6.5415\n",
      "[5772/8000] D loss: 0.9371, G loss: 2.5249\n",
      "[6132/8000] D loss: 0.6758, G loss: 8.8002\n",
      "[6492/8000] D loss: 0.9088, G loss: 3.0406\n",
      "[6852/8000] D loss: 1.3815, G loss: 1.1544\n",
      "[7212/8000] D loss: 0.7770, G loss: 7.7684\n",
      "[7572/8000] D loss: 0.6771, G loss: 5.3636\n",
      "[7932/8000] D loss: 0.6771, G loss: 6.2509\n",
      "train error: \n",
      " D loss: 0.897373, G loss: 7.948062, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.126698, G loss: 23.217630, D accuracy: 74.3%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9480, G loss: 5.3368\n",
      "[372/8000] D loss: 0.2596, G loss: 10.8297\n",
      "[732/8000] D loss: 0.9322, G loss: 4.9527\n",
      "[1092/8000] D loss: 0.9973, G loss: 4.1737\n",
      "[1452/8000] D loss: 0.8983, G loss: 5.8762\n",
      "[1812/8000] D loss: 1.0147, G loss: 8.0389\n",
      "[2172/8000] D loss: 1.0154, G loss: 10.5265\n",
      "[2532/8000] D loss: 1.0839, G loss: 5.8640\n",
      "[2892/8000] D loss: 0.7401, G loss: 11.6543\n",
      "[3252/8000] D loss: 0.5200, G loss: 10.2466\n",
      "[3612/8000] D loss: 0.6716, G loss: 7.5767\n",
      "[3972/8000] D loss: 0.9370, G loss: 4.4297\n",
      "[4332/8000] D loss: 0.7443, G loss: 3.9272\n",
      "[4692/8000] D loss: 0.8265, G loss: 9.5170\n",
      "[5052/8000] D loss: 0.8818, G loss: 9.7520\n",
      "[5412/8000] D loss: 0.8352, G loss: 4.3276\n",
      "[5772/8000] D loss: 0.8362, G loss: 7.6851\n",
      "[6132/8000] D loss: 0.9316, G loss: 7.2210\n",
      "[6492/8000] D loss: 0.7523, G loss: 5.8805\n",
      "[6852/8000] D loss: 1.0357, G loss: 2.4870\n",
      "[7212/8000] D loss: 0.9470, G loss: 5.2358\n",
      "[7572/8000] D loss: 0.4765, G loss: 11.6299\n",
      "[7932/8000] D loss: 0.6732, G loss: 4.3689\n",
      "train error: \n",
      " D loss: 0.841991, G loss: 6.807933, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.037962, G loss: 20.586675, D accuracy: 77.3%, cell accuracy: 98.3%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8010, G loss: 5.9158\n",
      "[372/8000] D loss: 0.9065, G loss: 3.4205\n",
      "[732/8000] D loss: 1.0055, G loss: 2.3661\n",
      "[1092/8000] D loss: 0.5774, G loss: 10.9237\n",
      "[1452/8000] D loss: 0.6182, G loss: 13.7379\n",
      "[1812/8000] D loss: 0.8320, G loss: 4.2875\n",
      "[2172/8000] D loss: 0.7513, G loss: 9.3164\n",
      "[2532/8000] D loss: 1.0753, G loss: 5.4026\n",
      "[2892/8000] D loss: 0.7464, G loss: 9.5555\n",
      "[3252/8000] D loss: 0.8179, G loss: 11.0830\n",
      "[3612/8000] D loss: 0.8223, G loss: 11.4768\n",
      "[3972/8000] D loss: 0.7055, G loss: 3.7046\n",
      "[4332/8000] D loss: 0.8465, G loss: 3.7644\n",
      "[4692/8000] D loss: 0.8199, G loss: 6.9042\n",
      "[5052/8000] D loss: 0.4054, G loss: 14.1899\n",
      "[5412/8000] D loss: 0.8466, G loss: 7.9137\n",
      "[5772/8000] D loss: 0.8051, G loss: 7.0752\n",
      "[6132/8000] D loss: 1.2775, G loss: 2.3056\n",
      "[6492/8000] D loss: 0.4827, G loss: 4.8312\n",
      "[6852/8000] D loss: 0.7122, G loss: 9.8977\n",
      "[7212/8000] D loss: 0.7889, G loss: 4.6738\n",
      "[7572/8000] D loss: 0.5819, G loss: 10.3266\n",
      "[7932/8000] D loss: 0.9931, G loss: 3.3450\n",
      "train error: \n",
      " D loss: 0.853125, G loss: 5.900384, D accuracy: 71.2%, cell accuracy: 98.7%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.920633, G loss: 18.239524, D accuracy: 80.6%, cell accuracy: 98.2%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7736, G loss: 4.2141\n",
      "[372/8000] D loss: 1.1580, G loss: 2.8339\n",
      "[732/8000] D loss: 0.7483, G loss: 6.4800\n",
      "[1092/8000] D loss: 1.0267, G loss: 6.5226\n",
      "[1452/8000] D loss: 0.6984, G loss: 11.6274\n",
      "[1812/8000] D loss: 1.1849, G loss: 2.6134\n",
      "[2172/8000] D loss: 0.9186, G loss: 9.1237\n",
      "[2532/8000] D loss: 0.6955, G loss: 6.2926\n",
      "[2892/8000] D loss: 0.8505, G loss: 6.8574\n",
      "[3252/8000] D loss: 0.9463, G loss: 2.4295\n",
      "[3612/8000] D loss: 0.8472, G loss: 5.6157\n",
      "[3972/8000] D loss: 1.1958, G loss: 1.4252\n",
      "[4332/8000] D loss: 1.0348, G loss: 6.0189\n",
      "[4692/8000] D loss: 1.0263, G loss: 3.1416\n",
      "[5052/8000] D loss: 0.4693, G loss: 7.4782\n",
      "[5412/8000] D loss: 0.6136, G loss: 8.6411\n",
      "[5772/8000] D loss: 0.5855, G loss: 19.2421\n",
      "[6132/8000] D loss: 0.8614, G loss: 5.9756\n",
      "[6492/8000] D loss: 0.4912, G loss: 11.4841\n",
      "[6852/8000] D loss: 0.6807, G loss: 6.8891\n",
      "[7212/8000] D loss: 0.6202, G loss: 4.2923\n",
      "[7572/8000] D loss: 0.8863, G loss: 6.2017\n",
      "[7932/8000] D loss: 0.6160, G loss: 6.4002\n",
      "train error: \n",
      " D loss: 0.853956, G loss: 7.877164, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.069812, G loss: 23.806247, D accuracy: 78.7%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7044, G loss: 7.5590\n",
      "[372/8000] D loss: 0.9418, G loss: 4.7981\n",
      "[732/8000] D loss: 1.1544, G loss: 2.5011\n",
      "[1092/8000] D loss: 0.9364, G loss: 3.9764\n",
      "[1452/8000] D loss: 0.8149, G loss: 8.9279\n",
      "[1812/8000] D loss: 1.1646, G loss: 4.8517\n",
      "[2172/8000] D loss: 0.8239, G loss: 5.3123\n",
      "[2532/8000] D loss: 0.6770, G loss: 9.3736\n",
      "[2892/8000] D loss: 0.9318, G loss: 5.1357\n",
      "[3252/8000] D loss: 0.6972, G loss: 6.9332\n",
      "[3612/8000] D loss: 0.8398, G loss: 4.4497\n",
      "[3972/8000] D loss: 0.9532, G loss: 3.1581\n",
      "[4332/8000] D loss: 0.9568, G loss: 2.6636\n",
      "[4692/8000] D loss: 0.5899, G loss: 10.8534\n",
      "[5052/8000] D loss: 0.7561, G loss: 4.5484\n",
      "[5412/8000] D loss: 0.9315, G loss: 5.3915\n",
      "[5772/8000] D loss: 0.8658, G loss: 6.2821\n",
      "[6132/8000] D loss: 0.8645, G loss: 12.3950\n",
      "[6492/8000] D loss: 0.9065, G loss: 2.2601\n",
      "[6852/8000] D loss: 0.6236, G loss: 11.6357\n",
      "[7212/8000] D loss: 0.9410, G loss: 4.5212\n",
      "[7572/8000] D loss: 0.9259, G loss: 5.8196\n",
      "[7932/8000] D loss: 0.7127, G loss: 9.7938\n",
      "train error: \n",
      " D loss: 0.854460, G loss: 6.427893, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.978890, G loss: 19.723897, D accuracy: 76.0%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0564, G loss: 2.1297\n",
      "[372/8000] D loss: 0.6006, G loss: 7.1023\n",
      "[732/8000] D loss: 0.5628, G loss: 9.1372\n",
      "[1092/8000] D loss: 0.5935, G loss: 7.5136\n",
      "[1452/8000] D loss: 0.5997, G loss: 6.2631\n",
      "[1812/8000] D loss: 0.7708, G loss: 11.6960\n",
      "[2172/8000] D loss: 0.9726, G loss: 4.6851\n",
      "[2532/8000] D loss: 0.7524, G loss: 7.7626\n",
      "[2892/8000] D loss: 0.7332, G loss: 2.7006\n",
      "[3252/8000] D loss: 1.0013, G loss: 4.0895\n",
      "[3612/8000] D loss: 0.7006, G loss: 8.6310\n",
      "[3972/8000] D loss: 0.9347, G loss: 5.2121\n",
      "[4332/8000] D loss: 0.5858, G loss: 11.2232\n",
      "[4692/8000] D loss: 0.5057, G loss: 4.8609\n",
      "[5052/8000] D loss: 0.8661, G loss: 3.9682\n",
      "[5412/8000] D loss: 0.9135, G loss: 3.6379\n",
      "[5772/8000] D loss: 1.1502, G loss: 1.3777\n",
      "[6132/8000] D loss: 0.8154, G loss: 5.5612\n",
      "[6492/8000] D loss: 0.5694, G loss: 12.9697\n",
      "[6852/8000] D loss: 1.1886, G loss: 1.7524\n",
      "[7212/8000] D loss: 0.9322, G loss: 3.1446\n",
      "[7572/8000] D loss: 0.9071, G loss: 6.7770\n",
      "[7932/8000] D loss: 0.8933, G loss: 4.9188\n",
      "train error: \n",
      " D loss: 0.852688, G loss: 6.798920, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.017362, G loss: 21.403203, D accuracy: 77.4%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0357, G loss: 1.8668\n",
      "[372/8000] D loss: 0.8059, G loss: 12.3276\n",
      "[732/8000] D loss: 1.2039, G loss: 3.8541\n",
      "[1092/8000] D loss: 0.6929, G loss: 11.3751\n",
      "[1452/8000] D loss: 0.7619, G loss: 9.2041\n",
      "[1812/8000] D loss: 1.1097, G loss: 7.0358\n",
      "[2172/8000] D loss: 1.0477, G loss: 3.5427\n",
      "[2532/8000] D loss: 0.6518, G loss: 10.6328\n",
      "[2892/8000] D loss: 1.0266, G loss: 5.1964\n",
      "[3252/8000] D loss: 0.8151, G loss: 6.2731\n",
      "[3612/8000] D loss: 0.7537, G loss: 6.8847\n",
      "[3972/8000] D loss: 1.1009, G loss: 2.4522\n",
      "[4332/8000] D loss: 0.9522, G loss: 2.2050\n",
      "[4692/8000] D loss: 0.6180, G loss: 6.3434\n",
      "[5052/8000] D loss: 0.5775, G loss: 8.7052\n",
      "[5412/8000] D loss: 0.9867, G loss: 7.8829\n",
      "[5772/8000] D loss: 0.6312, G loss: 6.2654\n",
      "[6132/8000] D loss: 0.8574, G loss: 6.6989\n",
      "[6492/8000] D loss: 1.0510, G loss: 1.6820\n",
      "[6852/8000] D loss: 0.7809, G loss: 3.7002\n",
      "[7212/8000] D loss: 0.7255, G loss: 14.0322\n",
      "[7572/8000] D loss: 0.7664, G loss: 5.9785\n",
      "[7932/8000] D loss: 0.6097, G loss: 6.7718\n",
      "train error: \n",
      " D loss: 0.838352, G loss: 6.974845, D accuracy: 72.3%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.978946, G loss: 20.917082, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 27.2% \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0066, G loss: 4.6485\n",
      "[372/8000] D loss: 0.6937, G loss: 5.6189\n",
      "[732/8000] D loss: 1.1886, G loss: 1.9040\n",
      "[1092/8000] D loss: 0.6090, G loss: 6.6460\n",
      "[1452/8000] D loss: 0.9812, G loss: 4.6347\n",
      "[1812/8000] D loss: 0.9680, G loss: 7.3307\n",
      "[2172/8000] D loss: 0.8088, G loss: 6.4517\n",
      "[2532/8000] D loss: 1.0930, G loss: 1.8152\n",
      "[2892/8000] D loss: 0.8231, G loss: 7.4517\n",
      "[3252/8000] D loss: 0.4394, G loss: 16.1096\n",
      "[3612/8000] D loss: 0.7985, G loss: 6.1147\n",
      "[3972/8000] D loss: 0.5901, G loss: 7.6135\n",
      "[4332/8000] D loss: 0.9417, G loss: 3.0959\n",
      "[4692/8000] D loss: 1.2261, G loss: 1.5995\n",
      "[5052/8000] D loss: 0.9533, G loss: 3.7387\n",
      "[5412/8000] D loss: 0.8188, G loss: 5.7375\n",
      "[5772/8000] D loss: 1.2209, G loss: 4.4051\n",
      "[6132/8000] D loss: 0.5851, G loss: 9.8416\n",
      "[6492/8000] D loss: 0.8821, G loss: 10.3205\n",
      "[6852/8000] D loss: 0.8287, G loss: 9.5374\n",
      "[7212/8000] D loss: 0.8172, G loss: 5.8607\n",
      "[7572/8000] D loss: 0.9964, G loss: 4.8435\n",
      "[7932/8000] D loss: 1.0181, G loss: 3.4129\n",
      "train error: \n",
      " D loss: 0.855012, G loss: 5.596621, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.066216, G loss: 17.834452, D accuracy: 75.4%, cell accuracy: 98.3%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7525, G loss: 9.4943\n",
      "[372/8000] D loss: 0.7163, G loss: 3.8687\n",
      "[732/8000] D loss: 1.1459, G loss: 1.4856\n",
      "[1092/8000] D loss: 0.8202, G loss: 7.3537\n",
      "[1452/8000] D loss: 0.5975, G loss: 6.0451\n",
      "[1812/8000] D loss: 0.8206, G loss: 4.7289\n",
      "[2172/8000] D loss: 0.7485, G loss: 11.8303\n",
      "[2532/8000] D loss: 1.0408, G loss: 3.8870\n",
      "[2892/8000] D loss: 0.8596, G loss: 9.4157\n",
      "[3252/8000] D loss: 0.4604, G loss: 16.0769\n",
      "[3612/8000] D loss: 0.7072, G loss: 10.9650\n",
      "[3972/8000] D loss: 0.5880, G loss: 4.2585\n",
      "[4332/8000] D loss: 0.7516, G loss: 11.3645\n",
      "[4692/8000] D loss: 0.9856, G loss: 2.5270\n",
      "[5052/8000] D loss: 1.0634, G loss: 3.5476\n",
      "[5412/8000] D loss: 1.1589, G loss: 4.6694\n",
      "[5772/8000] D loss: 0.5738, G loss: 5.9299\n",
      "[6132/8000] D loss: 1.0194, G loss: 6.8893\n",
      "[6492/8000] D loss: 0.8977, G loss: 9.2649\n",
      "[6852/8000] D loss: 1.0346, G loss: 3.5676\n",
      "[7212/8000] D loss: 0.9248, G loss: 2.6253\n",
      "[7572/8000] D loss: 0.9216, G loss: 2.7283\n",
      "[7932/8000] D loss: 1.1506, G loss: 3.3500\n",
      "train error: \n",
      " D loss: 0.849077, G loss: 6.613309, D accuracy: 71.1%, cell accuracy: 98.7%, board accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.037317, G loss: 19.215418, D accuracy: 75.1%, cell accuracy: 98.2%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9616, G loss: 4.6479\n",
      "[372/8000] D loss: 1.0348, G loss: 4.0884\n",
      "[732/8000] D loss: 0.8375, G loss: 4.1366\n",
      "[1092/8000] D loss: 0.8098, G loss: 4.7266\n",
      "[1452/8000] D loss: 1.0536, G loss: 1.9105\n",
      "[1812/8000] D loss: 0.7791, G loss: 4.2598\n",
      "[2172/8000] D loss: 0.8963, G loss: 4.3804\n",
      "[2532/8000] D loss: 0.6730, G loss: 10.2657\n",
      "[2892/8000] D loss: 0.8624, G loss: 6.8477\n",
      "[3252/8000] D loss: 0.7995, G loss: 6.7108\n",
      "[3612/8000] D loss: 0.9464, G loss: 3.0988\n",
      "[3972/8000] D loss: 0.9313, G loss: 4.5085\n",
      "[4332/8000] D loss: 0.9036, G loss: 6.5010\n",
      "[4692/8000] D loss: 1.0913, G loss: 2.3435\n",
      "[5052/8000] D loss: 1.0440, G loss: 2.6960\n",
      "[5412/8000] D loss: 0.7030, G loss: 7.6105\n",
      "[5772/8000] D loss: 0.5955, G loss: 5.4757\n",
      "[6132/8000] D loss: 0.5750, G loss: 6.8299\n",
      "[6492/8000] D loss: 0.7878, G loss: 5.1070\n",
      "[6852/8000] D loss: 0.9726, G loss: 3.5249\n",
      "[7212/8000] D loss: 0.6490, G loss: 9.1789\n",
      "[7572/8000] D loss: 0.7884, G loss: 5.2492\n",
      "[7932/8000] D loss: 1.0166, G loss: 8.2114\n",
      "train error: \n",
      " D loss: 0.839902, G loss: 7.509892, D accuracy: 72.1%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.082478, G loss: 22.746735, D accuracy: 77.4%, cell accuracy: 98.2%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8321, G loss: 8.6935\n",
      "[372/8000] D loss: 0.9519, G loss: 2.7729\n",
      "[732/8000] D loss: 0.8111, G loss: 8.4334\n",
      "[1092/8000] D loss: 1.0838, G loss: 6.4856\n",
      "[1452/8000] D loss: 0.5991, G loss: 11.3621\n",
      "[1812/8000] D loss: 0.7103, G loss: 8.2731\n",
      "[2172/8000] D loss: 0.9847, G loss: 2.3725\n",
      "[2532/8000] D loss: 0.8588, G loss: 7.2138\n",
      "[2892/8000] D loss: 0.4780, G loss: 5.8005\n",
      "[3252/8000] D loss: 0.9045, G loss: 10.9187\n",
      "[3612/8000] D loss: 0.4743, G loss: 17.4578\n",
      "[3972/8000] D loss: 1.1426, G loss: 3.5773\n",
      "[4332/8000] D loss: 0.7775, G loss: 10.6988\n",
      "[4692/8000] D loss: 0.8441, G loss: 3.9594\n",
      "[5052/8000] D loss: 0.7673, G loss: 9.7647\n",
      "[5412/8000] D loss: 0.8281, G loss: 5.4179\n",
      "[5772/8000] D loss: 0.7983, G loss: 5.6526\n",
      "[6132/8000] D loss: 0.6672, G loss: 5.6317\n",
      "[6492/8000] D loss: 0.7205, G loss: 7.4632\n",
      "[6852/8000] D loss: 0.5717, G loss: 12.8255\n",
      "[7212/8000] D loss: 0.7672, G loss: 7.5636\n",
      "[7572/8000] D loss: 0.7707, G loss: 8.7800\n",
      "[7932/8000] D loss: 0.8000, G loss: 6.0872\n",
      "train error: \n",
      " D loss: 0.852421, G loss: 7.137819, D accuracy: 71.6%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.994049, G loss: 20.759946, D accuracy: 80.2%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7693, G loss: 5.2292\n",
      "[372/8000] D loss: 0.5678, G loss: 8.7966\n",
      "[732/8000] D loss: 0.7978, G loss: 4.9833\n",
      "[1092/8000] D loss: 0.9208, G loss: 4.5108\n",
      "[1452/8000] D loss: 0.5877, G loss: 7.2837\n",
      "[1812/8000] D loss: 1.2205, G loss: 1.5607\n",
      "[2172/8000] D loss: 0.9301, G loss: 3.0825\n",
      "[2532/8000] D loss: 1.0471, G loss: 3.2077\n",
      "[2892/8000] D loss: 0.9142, G loss: 5.2250\n",
      "[3252/8000] D loss: 0.6969, G loss: 6.0485\n",
      "[3612/8000] D loss: 0.6928, G loss: 13.8909\n",
      "[3972/8000] D loss: 0.9647, G loss: 7.9358\n",
      "[4332/8000] D loss: 0.7931, G loss: 7.8750\n",
      "[4692/8000] D loss: 0.7901, G loss: 3.9791\n",
      "[5052/8000] D loss: 1.0477, G loss: 1.6423\n",
      "[5412/8000] D loss: 0.8546, G loss: 5.4659\n",
      "[5772/8000] D loss: 1.1189, G loss: 8.9485\n",
      "[6132/8000] D loss: 0.5860, G loss: 9.4309\n",
      "[6492/8000] D loss: 0.8478, G loss: 2.8138\n",
      "[6852/8000] D loss: 0.8963, G loss: 9.7179\n",
      "[7212/8000] D loss: 0.4237, G loss: 12.0260\n",
      "[7572/8000] D loss: 0.5394, G loss: 6.4469\n",
      "[7932/8000] D loss: 0.8166, G loss: 7.9291\n",
      "train error: \n",
      " D loss: 0.850512, G loss: 7.215696, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.000587, G loss: 21.816686, D accuracy: 76.8%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1259, G loss: 2.7074\n",
      "[372/8000] D loss: 1.1296, G loss: 4.0383\n",
      "[732/8000] D loss: 0.5381, G loss: 15.1982\n",
      "[1092/8000] D loss: 1.0385, G loss: 2.5985\n",
      "[1452/8000] D loss: 0.8259, G loss: 8.1838\n",
      "[1812/8000] D loss: 0.7593, G loss: 7.7470\n",
      "[2172/8000] D loss: 1.0927, G loss: 2.3706\n",
      "[2532/8000] D loss: 0.2681, G loss: 10.5202\n",
      "[2892/8000] D loss: 0.7450, G loss: 7.9246\n",
      "[3252/8000] D loss: 0.8120, G loss: 10.0716\n",
      "[3612/8000] D loss: 0.9332, G loss: 12.8331\n",
      "[3972/8000] D loss: 0.9884, G loss: 6.6902\n",
      "[4332/8000] D loss: 0.4849, G loss: 13.0044\n",
      "[4692/8000] D loss: 0.7370, G loss: 7.8780\n",
      "[5052/8000] D loss: 0.6256, G loss: 7.5886\n",
      "[5412/8000] D loss: 0.8075, G loss: 11.8768\n",
      "[5772/8000] D loss: 0.8450, G loss: 6.2801\n",
      "[6132/8000] D loss: 0.5732, G loss: 9.4262\n",
      "[6492/8000] D loss: 0.5319, G loss: 9.9757\n",
      "[6852/8000] D loss: 0.7547, G loss: 7.8927\n",
      "[7212/8000] D loss: 0.7934, G loss: 4.7591\n",
      "[7572/8000] D loss: 0.8300, G loss: 8.0831\n",
      "[7932/8000] D loss: 1.0475, G loss: 2.6829\n",
      "train error: \n",
      " D loss: 0.848333, G loss: 7.505261, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.036119, G loss: 22.151844, D accuracy: 77.6%, cell accuracy: 98.3%, board accuracy: 27.9% \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9274, G loss: 6.9408\n",
      "[372/8000] D loss: 1.2891, G loss: 5.1791\n",
      "[732/8000] D loss: 0.9327, G loss: 4.7172\n",
      "[1092/8000] D loss: 0.8509, G loss: 7.8969\n",
      "[1452/8000] D loss: 0.8824, G loss: 12.0465\n",
      "[1812/8000] D loss: 1.0323, G loss: 8.3993\n",
      "[2172/8000] D loss: 0.7885, G loss: 7.0556\n",
      "[2532/8000] D loss: 0.5609, G loss: 8.1081\n",
      "[2892/8000] D loss: 0.6839, G loss: 5.1878\n",
      "[3252/8000] D loss: 0.8737, G loss: 2.7866\n",
      "[3612/8000] D loss: 0.9374, G loss: 3.0687\n",
      "[3972/8000] D loss: 0.9241, G loss: 2.1983\n",
      "[4332/8000] D loss: 0.9355, G loss: 3.8543\n",
      "[4692/8000] D loss: 1.2587, G loss: 1.1464\n",
      "[5052/8000] D loss: 0.6384, G loss: 7.2213\n",
      "[5412/8000] D loss: 0.8365, G loss: 8.7879\n",
      "[5772/8000] D loss: 1.1795, G loss: 2.4753\n",
      "[6132/8000] D loss: 1.0341, G loss: 6.9271\n",
      "[6492/8000] D loss: 0.9103, G loss: 4.9926\n",
      "[6852/8000] D loss: 1.0136, G loss: 10.6331\n",
      "[7212/8000] D loss: 0.7860, G loss: 4.0840\n",
      "[7572/8000] D loss: 0.6562, G loss: 6.0289\n",
      "[7932/8000] D loss: 0.7002, G loss: 7.5063\n",
      "train error: \n",
      " D loss: 0.844256, G loss: 7.155010, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.028123, G loss: 21.313838, D accuracy: 78.4%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6605, G loss: 5.9879\n",
      "[372/8000] D loss: 0.4809, G loss: 13.0970\n",
      "[732/8000] D loss: 1.1865, G loss: 3.2536\n",
      "[1092/8000] D loss: 1.0871, G loss: 2.8923\n",
      "[1452/8000] D loss: 0.8641, G loss: 5.0511\n",
      "[1812/8000] D loss: 0.6421, G loss: 5.3013\n",
      "[2172/8000] D loss: 0.6988, G loss: 11.8588\n",
      "[2532/8000] D loss: 0.8773, G loss: 7.5431\n",
      "[2892/8000] D loss: 1.1885, G loss: 2.2001\n",
      "[3252/8000] D loss: 0.8240, G loss: 8.8278\n",
      "[3612/8000] D loss: 0.4433, G loss: 16.4237\n",
      "[3972/8000] D loss: 1.1275, G loss: 6.8534\n",
      "[4332/8000] D loss: 0.7599, G loss: 5.4994\n",
      "[4692/8000] D loss: 1.3039, G loss: 0.7691\n",
      "[5052/8000] D loss: 0.9633, G loss: 11.0746\n",
      "[5412/8000] D loss: 0.6917, G loss: 9.5886\n",
      "[5772/8000] D loss: 0.7544, G loss: 4.1280\n",
      "[6132/8000] D loss: 1.0538, G loss: 6.4233\n",
      "[6492/8000] D loss: 0.8227, G loss: 6.9545\n",
      "[6852/8000] D loss: 0.7654, G loss: 5.7376\n",
      "[7212/8000] D loss: 0.6782, G loss: 11.3188\n",
      "[7572/8000] D loss: 1.0429, G loss: 4.0160\n",
      "[7932/8000] D loss: 0.9582, G loss: 4.2583\n",
      "train error: \n",
      " D loss: 0.838821, G loss: 6.762753, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.044330, G loss: 20.720320, D accuracy: 78.6%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6492, G loss: 5.6487\n",
      "[372/8000] D loss: 0.9248, G loss: 11.8200\n",
      "[732/8000] D loss: 0.4629, G loss: 10.9930\n",
      "[1092/8000] D loss: 0.8645, G loss: 3.1126\n",
      "[1452/8000] D loss: 0.8124, G loss: 2.1535\n",
      "[1812/8000] D loss: 0.9154, G loss: 7.6507\n",
      "[2172/8000] D loss: 0.8087, G loss: 6.4799\n",
      "[2532/8000] D loss: 1.0427, G loss: 3.8621\n",
      "[2892/8000] D loss: 0.7911, G loss: 13.5540\n",
      "[3252/8000] D loss: 0.9754, G loss: 7.8350\n",
      "[3612/8000] D loss: 0.7188, G loss: 6.8757\n",
      "[3972/8000] D loss: 0.6496, G loss: 8.3985\n",
      "[4332/8000] D loss: 0.6897, G loss: 12.9713\n",
      "[4692/8000] D loss: 0.9150, G loss: 7.4506\n",
      "[5052/8000] D loss: 0.6362, G loss: 5.9242\n",
      "[5412/8000] D loss: 1.1421, G loss: 2.0922\n",
      "[5772/8000] D loss: 0.8351, G loss: 11.2390\n",
      "[6132/8000] D loss: 1.0030, G loss: 3.2767\n",
      "[6492/8000] D loss: 1.1773, G loss: 2.0058\n",
      "[6852/8000] D loss: 0.6512, G loss: 6.2531\n",
      "[7212/8000] D loss: 0.7296, G loss: 8.2085\n",
      "[7572/8000] D loss: 0.8185, G loss: 12.6078\n",
      "[7932/8000] D loss: 0.8068, G loss: 4.4780\n",
      "train error: \n",
      " D loss: 0.861568, G loss: 6.977541, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.959130, G loss: 20.924118, D accuracy: 75.7%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0354, G loss: 3.0545\n",
      "[372/8000] D loss: 0.7195, G loss: 5.7651\n",
      "[732/8000] D loss: 0.8079, G loss: 10.3827\n",
      "[1092/8000] D loss: 0.3794, G loss: 8.2900\n",
      "[1452/8000] D loss: 0.4930, G loss: 15.3940\n",
      "[1812/8000] D loss: 0.7034, G loss: 7.1278\n",
      "[2172/8000] D loss: 0.9212, G loss: 4.4516\n",
      "[2532/8000] D loss: 0.8944, G loss: 5.4287\n",
      "[2892/8000] D loss: 0.6680, G loss: 8.3106\n",
      "[3252/8000] D loss: 1.0856, G loss: 5.9770\n",
      "[3612/8000] D loss: 0.9721, G loss: 3.9207\n",
      "[3972/8000] D loss: 0.9870, G loss: 6.3084\n",
      "[4332/8000] D loss: 1.0076, G loss: 4.5684\n",
      "[4692/8000] D loss: 0.6675, G loss: 16.5254\n",
      "[5052/8000] D loss: 0.5893, G loss: 18.8454\n",
      "[5412/8000] D loss: 0.9591, G loss: 3.8761\n",
      "[5772/8000] D loss: 0.4870, G loss: 12.0054\n",
      "[6132/8000] D loss: 0.9866, G loss: 3.4348\n",
      "[6492/8000] D loss: 1.1487, G loss: 1.9511\n",
      "[6852/8000] D loss: 0.7071, G loss: 9.2704\n",
      "[7212/8000] D loss: 0.4798, G loss: 13.8676\n",
      "[7572/8000] D loss: 1.0161, G loss: 2.1041\n",
      "[7932/8000] D loss: 0.9371, G loss: 4.6742\n",
      "train error: \n",
      " D loss: 0.846754, G loss: 6.397069, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.034834, G loss: 19.542594, D accuracy: 75.9%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2711, G loss: 3.6114\n",
      "[372/8000] D loss: 1.1466, G loss: 2.2202\n",
      "[732/8000] D loss: 1.3203, G loss: 0.8811\n",
      "[1092/8000] D loss: 0.9069, G loss: 7.2332\n",
      "[1452/8000] D loss: 0.7923, G loss: 9.2354\n",
      "[1812/8000] D loss: 0.8453, G loss: 5.8230\n",
      "[2172/8000] D loss: 0.8549, G loss: 7.2599\n",
      "[2532/8000] D loss: 0.7588, G loss: 8.9005\n",
      "[2892/8000] D loss: 0.8589, G loss: 11.0532\n",
      "[3252/8000] D loss: 1.0567, G loss: 3.9750\n",
      "[3612/8000] D loss: 0.2990, G loss: 17.0523\n",
      "[3972/8000] D loss: 0.6892, G loss: 8.2847\n",
      "[4332/8000] D loss: 0.7638, G loss: 7.1139\n",
      "[4692/8000] D loss: 0.6263, G loss: 10.2608\n",
      "[5052/8000] D loss: 0.6665, G loss: 4.6459\n",
      "[5412/8000] D loss: 1.1343, G loss: 1.3355\n",
      "[5772/8000] D loss: 0.7864, G loss: 6.7801\n",
      "[6132/8000] D loss: 0.9808, G loss: 7.8831\n",
      "[6492/8000] D loss: 0.7432, G loss: 8.1490\n",
      "[6852/8000] D loss: 0.3915, G loss: 14.5074\n",
      "[7212/8000] D loss: 0.8074, G loss: 9.6694\n",
      "[7572/8000] D loss: 0.9952, G loss: 7.0779\n",
      "[7932/8000] D loss: 0.9335, G loss: 5.1945\n",
      "train error: \n",
      " D loss: 0.839154, G loss: 6.814388, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.978105, G loss: 20.850180, D accuracy: 79.6%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.4854, G loss: 7.4438\n",
      "[372/8000] D loss: 0.6301, G loss: 6.7453\n",
      "[732/8000] D loss: 0.4625, G loss: 14.2721\n",
      "[1092/8000] D loss: 0.8564, G loss: 6.0853\n",
      "[1452/8000] D loss: 1.1558, G loss: 1.6525\n",
      "[1812/8000] D loss: 0.7243, G loss: 8.9678\n",
      "[2172/8000] D loss: 0.7780, G loss: 6.8788\n",
      "[2532/8000] D loss: 0.9749, G loss: 3.2891\n",
      "[2892/8000] D loss: 0.8245, G loss: 9.3052\n",
      "[3252/8000] D loss: 0.6570, G loss: 12.9314\n",
      "[3612/8000] D loss: 0.9632, G loss: 1.9416\n",
      "[3972/8000] D loss: 1.0491, G loss: 2.7536\n",
      "[4332/8000] D loss: 0.9611, G loss: 4.9715\n",
      "[4692/8000] D loss: 0.6259, G loss: 9.4442\n",
      "[5052/8000] D loss: 1.0043, G loss: 5.6832\n",
      "[5412/8000] D loss: 0.8508, G loss: 5.8314\n",
      "[5772/8000] D loss: 0.8264, G loss: 5.3496\n",
      "[6132/8000] D loss: 1.0244, G loss: 5.5938\n",
      "[6492/8000] D loss: 0.5600, G loss: 7.1713\n",
      "[6852/8000] D loss: 0.9411, G loss: 6.4380\n",
      "[7212/8000] D loss: 0.9291, G loss: 5.5833\n",
      "[7572/8000] D loss: 0.6748, G loss: 7.5296\n",
      "[7932/8000] D loss: 0.9802, G loss: 7.2009\n",
      "train error: \n",
      " D loss: 0.843928, G loss: 6.735492, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.024706, G loss: 21.078376, D accuracy: 77.6%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8710, G loss: 9.2662\n",
      "[372/8000] D loss: 0.8193, G loss: 8.0397\n",
      "[732/8000] D loss: 0.4785, G loss: 12.0137\n",
      "[1092/8000] D loss: 0.7122, G loss: 5.8893\n",
      "[1452/8000] D loss: 0.8635, G loss: 6.2484\n",
      "[1812/8000] D loss: 0.9623, G loss: 2.4094\n",
      "[2172/8000] D loss: 0.7380, G loss: 10.8143\n",
      "[2532/8000] D loss: 0.4656, G loss: 10.4751\n",
      "[2892/8000] D loss: 0.6096, G loss: 11.7776\n",
      "[3252/8000] D loss: 0.8216, G loss: 5.4720\n",
      "[3612/8000] D loss: 0.5694, G loss: 13.4633\n",
      "[3972/8000] D loss: 0.6913, G loss: 10.5535\n",
      "[4332/8000] D loss: 0.8438, G loss: 3.5789\n",
      "[4692/8000] D loss: 0.7199, G loss: 6.5837\n",
      "[5052/8000] D loss: 0.6816, G loss: 6.5077\n",
      "[5412/8000] D loss: 1.0099, G loss: 3.0211\n",
      "[5772/8000] D loss: 0.8516, G loss: 5.9914\n",
      "[6132/8000] D loss: 1.1601, G loss: 2.0931\n",
      "[6492/8000] D loss: 0.8253, G loss: 5.6258\n",
      "[6852/8000] D loss: 0.9671, G loss: 2.5635\n",
      "[7212/8000] D loss: 0.6536, G loss: 7.9864\n",
      "[7572/8000] D loss: 0.6596, G loss: 11.0128\n",
      "[7932/8000] D loss: 0.7038, G loss: 4.8517\n",
      "train error: \n",
      " D loss: 0.842390, G loss: 6.831098, D accuracy: 71.6%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.941601, G loss: 20.500097, D accuracy: 78.7%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6452, G loss: 6.1023\n",
      "[372/8000] D loss: 1.2815, G loss: 1.3075\n",
      "[732/8000] D loss: 0.4772, G loss: 7.6844\n",
      "[1092/8000] D loss: 0.6501, G loss: 14.1104\n",
      "[1452/8000] D loss: 1.0204, G loss: 2.0432\n",
      "[1812/8000] D loss: 0.6352, G loss: 13.7733\n",
      "[2172/8000] D loss: 0.9381, G loss: 5.0540\n",
      "[2532/8000] D loss: 0.6271, G loss: 8.4031\n",
      "[2892/8000] D loss: 0.9193, G loss: 3.8931\n",
      "[3252/8000] D loss: 0.8720, G loss: 2.2736\n",
      "[3612/8000] D loss: 0.4429, G loss: 16.5564\n",
      "[3972/8000] D loss: 0.6730, G loss: 13.3624\n",
      "[4332/8000] D loss: 1.1895, G loss: 2.8174\n",
      "[4692/8000] D loss: 0.8177, G loss: 9.6176\n",
      "[5052/8000] D loss: 0.9851, G loss: 3.6420\n",
      "[5412/8000] D loss: 0.9885, G loss: 6.2746\n",
      "[5772/8000] D loss: 0.8004, G loss: 8.8875\n",
      "[6132/8000] D loss: 0.9163, G loss: 7.3050\n",
      "[6492/8000] D loss: 0.4241, G loss: 9.5500\n",
      "[6852/8000] D loss: 1.0853, G loss: 8.3310\n",
      "[7212/8000] D loss: 0.8657, G loss: 2.4182\n",
      "[7572/8000] D loss: 0.8134, G loss: 6.9776\n",
      "[7932/8000] D loss: 0.8556, G loss: 3.9662\n",
      "train error: \n",
      " D loss: 0.858032, G loss: 4.983578, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.892532, G loss: 17.015405, D accuracy: 81.6%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9660, G loss: 3.6144\n",
      "[372/8000] D loss: 0.9488, G loss: 13.4254\n",
      "[732/8000] D loss: 1.1680, G loss: 1.3947\n",
      "[1092/8000] D loss: 0.9762, G loss: 4.2705\n",
      "[1452/8000] D loss: 0.6926, G loss: 11.5161\n",
      "[1812/8000] D loss: 0.8023, G loss: 8.1536\n",
      "[2172/8000] D loss: 0.8702, G loss: 5.8171\n",
      "[2532/8000] D loss: 0.7746, G loss: 7.4888\n",
      "[2892/8000] D loss: 0.9647, G loss: 3.8784\n",
      "[3252/8000] D loss: 1.0610, G loss: 5.5792\n",
      "[3612/8000] D loss: 1.1144, G loss: 3.8553\n",
      "[3972/8000] D loss: 1.0985, G loss: 4.0768\n",
      "[4332/8000] D loss: 0.7055, G loss: 9.5026\n",
      "[4692/8000] D loss: 0.6506, G loss: 11.0191\n",
      "[5052/8000] D loss: 0.6913, G loss: 6.5400\n",
      "[5412/8000] D loss: 0.7783, G loss: 14.3359\n",
      "[5772/8000] D loss: 0.5145, G loss: 8.7250\n",
      "[6132/8000] D loss: 0.6992, G loss: 8.2713\n",
      "[6492/8000] D loss: 0.8595, G loss: 6.9344\n",
      "[6852/8000] D loss: 0.9436, G loss: 10.1759\n",
      "[7212/8000] D loss: 0.7620, G loss: 4.7923\n",
      "[7572/8000] D loss: 0.6053, G loss: 9.9459\n",
      "[7932/8000] D loss: 0.7481, G loss: 4.4508\n",
      "train error: \n",
      " D loss: 0.852526, G loss: 6.457203, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.963047, G loss: 19.940929, D accuracy: 78.1%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8923, G loss: 4.5995\n",
      "[372/8000] D loss: 1.3844, G loss: 0.7472\n",
      "[732/8000] D loss: 1.0327, G loss: 3.3623\n",
      "[1092/8000] D loss: 0.9392, G loss: 2.4645\n",
      "[1452/8000] D loss: 0.7057, G loss: 13.7171\n",
      "[1812/8000] D loss: 1.0879, G loss: 4.0572\n",
      "[2172/8000] D loss: 0.6939, G loss: 8.6574\n",
      "[2532/8000] D loss: 0.9563, G loss: 2.4221\n",
      "[2892/8000] D loss: 0.7693, G loss: 5.6716\n",
      "[3252/8000] D loss: 1.0268, G loss: 1.7492\n",
      "[3612/8000] D loss: 1.0676, G loss: 3.4965\n",
      "[3972/8000] D loss: 0.8855, G loss: 9.2525\n",
      "[4332/8000] D loss: 1.0479, G loss: 1.8704\n",
      "[4692/8000] D loss: 1.0502, G loss: 5.1938\n",
      "[5052/8000] D loss: 0.6943, G loss: 8.3553\n",
      "[5412/8000] D loss: 0.7198, G loss: 12.7139\n",
      "[5772/8000] D loss: 0.7660, G loss: 6.5661\n",
      "[6132/8000] D loss: 0.6363, G loss: 7.5858\n",
      "[6492/8000] D loss: 0.6911, G loss: 8.6046\n",
      "[6852/8000] D loss: 0.6339, G loss: 8.7159\n",
      "[7212/8000] D loss: 0.8332, G loss: 5.5200\n",
      "[7572/8000] D loss: 0.8210, G loss: 8.8955\n",
      "[7932/8000] D loss: 0.6991, G loss: 8.0835\n",
      "train error: \n",
      " D loss: 0.839916, G loss: 7.067066, D accuracy: 71.7%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.001716, G loss: 21.058136, D accuracy: 78.7%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3530, G loss: 15.3724\n",
      "[372/8000] D loss: 0.8700, G loss: 2.3942\n",
      "[732/8000] D loss: 0.9363, G loss: 3.7404\n",
      "[1092/8000] D loss: 0.9289, G loss: 2.2469\n",
      "[1452/8000] D loss: 0.8270, G loss: 7.6893\n",
      "[1812/8000] D loss: 0.7571, G loss: 4.0386\n",
      "[2172/8000] D loss: 0.4817, G loss: 19.3851\n",
      "[2532/8000] D loss: 0.8677, G loss: 5.3510\n",
      "[2892/8000] D loss: 0.7470, G loss: 6.4673\n",
      "[3252/8000] D loss: 0.9649, G loss: 10.7584\n",
      "[3612/8000] D loss: 0.9978, G loss: 4.2314\n",
      "[3972/8000] D loss: 0.7035, G loss: 8.0071\n",
      "[4332/8000] D loss: 1.1191, G loss: 6.1320\n",
      "[4692/8000] D loss: 1.0497, G loss: 2.0847\n",
      "[5052/8000] D loss: 1.0424, G loss: 6.5320\n",
      "[5412/8000] D loss: 0.9009, G loss: 6.7870\n",
      "[5772/8000] D loss: 0.8812, G loss: 2.9321\n",
      "[6132/8000] D loss: 1.1433, G loss: 5.3675\n",
      "[6492/8000] D loss: 1.0434, G loss: 1.8834\n",
      "[6852/8000] D loss: 1.1807, G loss: 4.5271\n",
      "[7212/8000] D loss: 0.4752, G loss: 10.0661\n",
      "[7572/8000] D loss: 0.5694, G loss: 6.5935\n",
      "[7932/8000] D loss: 0.9335, G loss: 9.6748\n",
      "train error: \n",
      " D loss: 0.857377, G loss: 6.644524, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.087652, G loss: 19.723219, D accuracy: 76.7%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7637, G loss: 12.9408\n",
      "[372/8000] D loss: 0.7005, G loss: 6.3855\n",
      "[732/8000] D loss: 0.8196, G loss: 15.8690\n",
      "[1092/8000] D loss: 0.3708, G loss: 14.3360\n",
      "[1452/8000] D loss: 0.6291, G loss: 6.6238\n",
      "[1812/8000] D loss: 0.7008, G loss: 11.0636\n",
      "[2172/8000] D loss: 1.0474, G loss: 4.5166\n",
      "[2532/8000] D loss: 0.9270, G loss: 6.6672\n",
      "[2892/8000] D loss: 1.0579, G loss: 2.4350\n",
      "[3252/8000] D loss: 0.9599, G loss: 3.1748\n",
      "[3612/8000] D loss: 0.6102, G loss: 9.1248\n",
      "[3972/8000] D loss: 1.1138, G loss: 8.3133\n",
      "[4332/8000] D loss: 0.7090, G loss: 6.5112\n",
      "[4692/8000] D loss: 0.9065, G loss: 7.9650\n",
      "[5052/8000] D loss: 0.6478, G loss: 11.0317\n",
      "[5412/8000] D loss: 0.7037, G loss: 10.3078\n",
      "[5772/8000] D loss: 1.0103, G loss: 8.6393\n",
      "[6132/8000] D loss: 0.7631, G loss: 10.5354\n",
      "[6492/8000] D loss: 0.6458, G loss: 6.9576\n",
      "[6852/8000] D loss: 0.7623, G loss: 15.9946\n",
      "[7212/8000] D loss: 0.6045, G loss: 10.5774\n",
      "[7572/8000] D loss: 0.8129, G loss: 5.9629\n",
      "[7932/8000] D loss: 0.5614, G loss: 7.3189\n",
      "train error: \n",
      " D loss: 0.841796, G loss: 6.972932, D accuracy: 71.6%, cell accuracy: 98.8%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.939181, G loss: 21.134002, D accuracy: 79.5%, cell accuracy: 98.2%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6791, G loss: 6.2172\n",
      "[372/8000] D loss: 0.8195, G loss: 8.1222\n",
      "[732/8000] D loss: 1.2577, G loss: 0.9230\n",
      "[1092/8000] D loss: 0.9128, G loss: 6.5820\n",
      "[1452/8000] D loss: 0.4941, G loss: 16.2039\n",
      "[1812/8000] D loss: 0.8013, G loss: 9.8735\n",
      "[2172/8000] D loss: 0.7546, G loss: 5.2408\n",
      "[2532/8000] D loss: 1.3743, G loss: 2.5934\n",
      "[2892/8000] D loss: 0.4217, G loss: 10.2893\n",
      "[3252/8000] D loss: 0.9010, G loss: 10.4216\n",
      "[3612/8000] D loss: 1.1090, G loss: 3.4855\n",
      "[3972/8000] D loss: 0.6285, G loss: 9.4029\n",
      "[4332/8000] D loss: 1.0996, G loss: 4.0560\n",
      "[4692/8000] D loss: 0.6224, G loss: 8.4406\n",
      "[5052/8000] D loss: 0.8479, G loss: 6.8571\n",
      "[5412/8000] D loss: 0.6642, G loss: 7.1755\n",
      "[5772/8000] D loss: 0.9990, G loss: 2.0999\n",
      "[6132/8000] D loss: 0.7240, G loss: 10.1496\n",
      "[6492/8000] D loss: 1.0641, G loss: 4.8248\n",
      "[6852/8000] D loss: 0.7832, G loss: 9.1158\n",
      "[7212/8000] D loss: 0.9578, G loss: 5.5515\n",
      "[7572/8000] D loss: 0.9026, G loss: 8.5828\n",
      "[7932/8000] D loss: 0.9271, G loss: 4.9536\n",
      "train error: \n",
      " D loss: 0.846463, G loss: 6.753771, D accuracy: 71.2%, cell accuracy: 98.7%, board accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.027879, G loss: 19.860821, D accuracy: 74.9%, cell accuracy: 98.2%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7768, G loss: 3.7853\n",
      "[372/8000] D loss: 0.6991, G loss: 7.8576\n",
      "[732/8000] D loss: 0.5201, G loss: 10.4580\n",
      "[1092/8000] D loss: 0.9498, G loss: 6.6505\n",
      "[1452/8000] D loss: 0.5850, G loss: 16.9102\n",
      "[1812/8000] D loss: 0.8450, G loss: 3.0863\n",
      "[2172/8000] D loss: 0.8354, G loss: 4.6272\n",
      "[2532/8000] D loss: 0.7153, G loss: 5.5074\n",
      "[2892/8000] D loss: 1.0311, G loss: 3.7111\n",
      "[3252/8000] D loss: 0.6902, G loss: 7.1498\n",
      "[3612/8000] D loss: 0.6763, G loss: 10.2500\n",
      "[3972/8000] D loss: 0.7789, G loss: 4.4643\n",
      "[4332/8000] D loss: 0.9426, G loss: 10.6805\n",
      "[4692/8000] D loss: 0.6800, G loss: 7.7336\n",
      "[5052/8000] D loss: 0.9652, G loss: 8.3293\n",
      "[5412/8000] D loss: 0.5577, G loss: 10.2310\n",
      "[5772/8000] D loss: 0.6616, G loss: 5.6242\n",
      "[6132/8000] D loss: 0.6949, G loss: 9.8095\n",
      "[6492/8000] D loss: 0.9931, G loss: 1.8157\n",
      "[6852/8000] D loss: 0.9163, G loss: 7.1291\n",
      "[7212/8000] D loss: 0.7270, G loss: 10.8216\n",
      "[7572/8000] D loss: 1.0424, G loss: 3.0412\n",
      "[7932/8000] D loss: 0.8728, G loss: 2.5350\n",
      "train error: \n",
      " D loss: 0.853703, G loss: 7.158967, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.985334, G loss: 21.226168, D accuracy: 79.2%, cell accuracy: 98.3%, board accuracy: 29.5% \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6955, G loss: 8.9663\n",
      "[372/8000] D loss: 1.0450, G loss: 4.5467\n",
      "[732/8000] D loss: 0.7159, G loss: 9.5012\n",
      "[1092/8000] D loss: 1.0187, G loss: 6.3408\n",
      "[1452/8000] D loss: 0.5850, G loss: 8.1880\n",
      "[1812/8000] D loss: 0.5820, G loss: 7.4725\n",
      "[2172/8000] D loss: 0.9945, G loss: 2.2627\n",
      "[2532/8000] D loss: 0.7344, G loss: 5.8365\n",
      "[2892/8000] D loss: 0.8915, G loss: 11.6736\n",
      "[3252/8000] D loss: 0.8751, G loss: 11.2578\n",
      "[3612/8000] D loss: 0.8915, G loss: 8.4116\n",
      "[3972/8000] D loss: 0.3057, G loss: 18.4533\n",
      "[4332/8000] D loss: 1.0654, G loss: 7.7163\n",
      "[4692/8000] D loss: 0.8558, G loss: 5.8469\n",
      "[5052/8000] D loss: 0.8510, G loss: 7.9108\n",
      "[5412/8000] D loss: 0.9322, G loss: 4.1728\n",
      "[5772/8000] D loss: 1.1320, G loss: 1.6509\n",
      "[6132/8000] D loss: 0.9268, G loss: 5.3247\n",
      "[6492/8000] D loss: 1.0885, G loss: 1.6838\n",
      "[6852/8000] D loss: 0.9810, G loss: 6.6504\n",
      "[7212/8000] D loss: 0.9556, G loss: 5.4189\n",
      "[7572/8000] D loss: 0.8056, G loss: 5.4971\n",
      "[7932/8000] D loss: 1.1647, G loss: 3.9437\n",
      "train error: \n",
      " D loss: 0.851537, G loss: 7.695897, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.074840, G loss: 22.264848, D accuracy: 75.4%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6846, G loss: 8.2798\n",
      "[372/8000] D loss: 0.7470, G loss: 8.3256\n",
      "[732/8000] D loss: 0.7786, G loss: 7.2687\n",
      "[1092/8000] D loss: 0.8030, G loss: 8.2981\n",
      "[1452/8000] D loss: 0.9364, G loss: 4.5137\n",
      "[1812/8000] D loss: 0.4516, G loss: 10.9646\n",
      "[2172/8000] D loss: 0.8686, G loss: 5.8454\n",
      "[2532/8000] D loss: 0.5466, G loss: 5.7164\n",
      "[2892/8000] D loss: 0.6538, G loss: 12.7882\n",
      "[3252/8000] D loss: 1.1167, G loss: 6.1645\n",
      "[3612/8000] D loss: 1.1572, G loss: 4.1839\n",
      "[3972/8000] D loss: 0.8280, G loss: 5.0562\n",
      "[4332/8000] D loss: 0.7159, G loss: 5.0173\n",
      "[4692/8000] D loss: 1.0596, G loss: 4.9002\n",
      "[5052/8000] D loss: 0.7763, G loss: 7.3407\n",
      "[5412/8000] D loss: 1.2479, G loss: 2.8071\n",
      "[5772/8000] D loss: 0.9212, G loss: 2.0279\n",
      "[6132/8000] D loss: 0.6475, G loss: 14.7484\n",
      "[6492/8000] D loss: 0.4644, G loss: 7.4450\n",
      "[6852/8000] D loss: 0.8641, G loss: 6.1358\n",
      "[7212/8000] D loss: 0.7776, G loss: 3.3544\n",
      "[7572/8000] D loss: 1.0251, G loss: 4.5405\n",
      "[7932/8000] D loss: 0.9575, G loss: 4.0955\n",
      "train error: \n",
      " D loss: 0.862511, G loss: 6.318015, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.016490, G loss: 19.140613, D accuracy: 75.6%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1236, G loss: 1.7362\n",
      "[372/8000] D loss: 0.9750, G loss: 3.8343\n",
      "[732/8000] D loss: 0.8064, G loss: 7.2027\n",
      "[1092/8000] D loss: 0.8383, G loss: 7.8526\n",
      "[1452/8000] D loss: 0.6892, G loss: 11.8699\n",
      "[1812/8000] D loss: 1.7531, G loss: 4.4120\n",
      "[2172/8000] D loss: 0.6926, G loss: 3.4099\n",
      "[2532/8000] D loss: 1.2775, G loss: 1.0634\n",
      "[2892/8000] D loss: 1.0812, G loss: 2.2939\n",
      "[3252/8000] D loss: 0.6914, G loss: 4.7927\n",
      "[3612/8000] D loss: 0.9487, G loss: 6.2000\n",
      "[3972/8000] D loss: 0.7715, G loss: 11.4646\n",
      "[4332/8000] D loss: 0.9317, G loss: 4.0756\n",
      "[4692/8000] D loss: 0.5563, G loss: 10.9492\n",
      "[5052/8000] D loss: 0.7597, G loss: 4.7886\n",
      "[5412/8000] D loss: 0.6852, G loss: 4.6768\n",
      "[5772/8000] D loss: 1.0579, G loss: 3.3849\n",
      "[6132/8000] D loss: 0.8204, G loss: 6.2338\n",
      "[6492/8000] D loss: 0.9969, G loss: 4.1906\n",
      "[6852/8000] D loss: 0.5337, G loss: 11.2907\n",
      "[7212/8000] D loss: 0.6370, G loss: 10.4042\n",
      "[7572/8000] D loss: 0.6368, G loss: 10.1377\n",
      "[7932/8000] D loss: 1.1574, G loss: 6.0859\n",
      "train error: \n",
      " D loss: 0.833938, G loss: 7.033148, D accuracy: 72.0%, cell accuracy: 98.7%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.991898, G loss: 20.901897, D accuracy: 80.1%, cell accuracy: 98.3%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6472, G loss: 5.9233\n",
      "[372/8000] D loss: 0.9019, G loss: 4.4916\n",
      "[732/8000] D loss: 0.5231, G loss: 9.7900\n",
      "[1092/8000] D loss: 1.2113, G loss: 2.4281\n",
      "[1452/8000] D loss: 1.0496, G loss: 6.3058\n",
      "[1812/8000] D loss: 0.9515, G loss: 3.9066\n",
      "[2172/8000] D loss: 0.6175, G loss: 10.2552\n",
      "[2532/8000] D loss: 1.0981, G loss: 3.0066\n",
      "[2892/8000] D loss: 1.0564, G loss: 3.7828\n",
      "[3252/8000] D loss: 1.1346, G loss: 3.0490\n",
      "[3612/8000] D loss: 0.7669, G loss: 9.1885\n",
      "[3972/8000] D loss: 0.9727, G loss: 2.5938\n",
      "[4332/8000] D loss: 0.8978, G loss: 6.6194\n",
      "[4692/8000] D loss: 0.9477, G loss: 8.0023\n",
      "[5052/8000] D loss: 0.9343, G loss: 12.5560\n",
      "[5412/8000] D loss: 0.9785, G loss: 2.7621\n",
      "[5772/8000] D loss: 0.4199, G loss: 16.9431\n",
      "[6132/8000] D loss: 1.0569, G loss: 2.9045\n",
      "[6492/8000] D loss: 0.7537, G loss: 6.3444\n",
      "[6852/8000] D loss: 0.5197, G loss: 18.6827\n",
      "[7212/8000] D loss: 0.5902, G loss: 7.8826\n",
      "[7572/8000] D loss: 1.0663, G loss: 1.7451\n",
      "[7932/8000] D loss: 0.7430, G loss: 8.0709\n",
      "train error: \n",
      " D loss: 0.855421, G loss: 6.483917, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.968721, G loss: 19.613081, D accuracy: 80.9%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5404, G loss: 8.8077\n",
      "[372/8000] D loss: 1.1111, G loss: 8.5737\n",
      "[732/8000] D loss: 1.0200, G loss: 3.8173\n",
      "[1092/8000] D loss: 0.7078, G loss: 8.5962\n",
      "[1452/8000] D loss: 0.9329, G loss: 4.2202\n",
      "[1812/8000] D loss: 1.0473, G loss: 6.9491\n",
      "[2172/8000] D loss: 0.6569, G loss: 14.5776\n",
      "[2532/8000] D loss: 0.7869, G loss: 11.2015\n",
      "[2892/8000] D loss: 0.8228, G loss: 2.9964\n",
      "[3252/8000] D loss: 1.2903, G loss: 1.5169\n",
      "[3612/8000] D loss: 0.8375, G loss: 4.4117\n",
      "[3972/8000] D loss: 0.6533, G loss: 5.6545\n",
      "[4332/8000] D loss: 0.7559, G loss: 10.0894\n",
      "[4692/8000] D loss: 0.4161, G loss: 10.3385\n",
      "[5052/8000] D loss: 0.9419, G loss: 5.4167\n",
      "[5412/8000] D loss: 0.9134, G loss: 5.0185\n",
      "[5772/8000] D loss: 1.0805, G loss: 2.7875\n",
      "[6132/8000] D loss: 1.1826, G loss: 1.9857\n",
      "[6492/8000] D loss: 0.9251, G loss: 6.5081\n",
      "[6852/8000] D loss: 0.4476, G loss: 7.0617\n",
      "[7212/8000] D loss: 0.7809, G loss: 7.9464\n",
      "[7572/8000] D loss: 0.9129, G loss: 10.0349\n",
      "[7932/8000] D loss: 0.7246, G loss: 6.3356\n",
      "train error: \n",
      " D loss: 0.850877, G loss: 6.424849, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.901706, G loss: 20.195146, D accuracy: 80.1%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7763, G loss: 10.7262\n",
      "[372/8000] D loss: 0.4700, G loss: 9.7185\n",
      "[732/8000] D loss: 0.3073, G loss: 12.1997\n",
      "[1092/8000] D loss: 0.8105, G loss: 4.2250\n",
      "[1452/8000] D loss: 1.1776, G loss: 4.5120\n",
      "[1812/8000] D loss: 0.9298, G loss: 7.3607\n",
      "[2172/8000] D loss: 0.8043, G loss: 4.9513\n",
      "[2532/8000] D loss: 0.6066, G loss: 4.5519\n",
      "[2892/8000] D loss: 0.7327, G loss: 5.9628\n",
      "[3252/8000] D loss: 0.8852, G loss: 7.3403\n",
      "[3612/8000] D loss: 0.7480, G loss: 9.3608\n",
      "[3972/8000] D loss: 0.7852, G loss: 9.0213\n",
      "[4332/8000] D loss: 1.0063, G loss: 2.8414\n",
      "[4692/8000] D loss: 0.8349, G loss: 5.5477\n",
      "[5052/8000] D loss: 0.7050, G loss: 8.9224\n",
      "[5412/8000] D loss: 0.9940, G loss: 5.7769\n",
      "[5772/8000] D loss: 0.9851, G loss: 1.5677\n",
      "[6132/8000] D loss: 0.6387, G loss: 11.4445\n",
      "[6492/8000] D loss: 0.9022, G loss: 4.7652\n",
      "[6852/8000] D loss: 0.8151, G loss: 3.7829\n",
      "[7212/8000] D loss: 1.0599, G loss: 4.5191\n",
      "[7572/8000] D loss: 0.8568, G loss: 6.6010\n",
      "[7932/8000] D loss: 0.9276, G loss: 7.9514\n",
      "train error: \n",
      " D loss: 0.843150, G loss: 6.256039, D accuracy: 71.7%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.974440, G loss: 19.246782, D accuracy: 78.6%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2052, G loss: 1.2787\n",
      "[372/8000] D loss: 0.8177, G loss: 6.3565\n",
      "[732/8000] D loss: 0.8518, G loss: 5.1940\n",
      "[1092/8000] D loss: 0.8685, G loss: 9.0662\n",
      "[1452/8000] D loss: 0.6397, G loss: 8.6923\n",
      "[1812/8000] D loss: 0.5769, G loss: 9.0537\n",
      "[2172/8000] D loss: 0.5577, G loss: 6.9514\n",
      "[2532/8000] D loss: 1.0236, G loss: 5.2165\n",
      "[2892/8000] D loss: 0.7071, G loss: 4.3593\n",
      "[3252/8000] D loss: 0.5218, G loss: 9.9437\n",
      "[3612/8000] D loss: 1.1571, G loss: 1.3570\n",
      "[3972/8000] D loss: 0.8201, G loss: 10.2069\n",
      "[4332/8000] D loss: 0.5160, G loss: 11.6733\n",
      "[4692/8000] D loss: 0.7076, G loss: 6.8473\n",
      "[5052/8000] D loss: 0.6959, G loss: 10.3670\n",
      "[5412/8000] D loss: 1.0404, G loss: 3.6431\n",
      "[5772/8000] D loss: 0.7887, G loss: 8.2642\n",
      "[6132/8000] D loss: 0.6348, G loss: 8.0432\n",
      "[6492/8000] D loss: 0.5795, G loss: 13.6128\n",
      "[6852/8000] D loss: 0.6789, G loss: 3.7237\n",
      "[7212/8000] D loss: 1.0994, G loss: 7.0173\n",
      "[7572/8000] D loss: 0.5565, G loss: 9.4335\n",
      "[7932/8000] D loss: 0.7231, G loss: 13.9057\n",
      "train error: \n",
      " D loss: 0.850039, G loss: 6.755554, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.977825, G loss: 20.285540, D accuracy: 78.7%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4710, G loss: 6.9464\n",
      "[372/8000] D loss: 0.8340, G loss: 10.2865\n",
      "[732/8000] D loss: 0.9248, G loss: 7.7896\n",
      "[1092/8000] D loss: 1.1179, G loss: 1.6434\n",
      "[1452/8000] D loss: 0.8064, G loss: 6.1809\n",
      "[1812/8000] D loss: 0.7038, G loss: 11.7755\n",
      "[2172/8000] D loss: 0.6875, G loss: 11.0047\n",
      "[2532/8000] D loss: 0.8490, G loss: 8.5001\n",
      "[2892/8000] D loss: 1.0425, G loss: 5.1794\n",
      "[3252/8000] D loss: 0.7154, G loss: 8.8827\n",
      "[3612/8000] D loss: 0.8436, G loss: 11.2579\n",
      "[3972/8000] D loss: 0.9870, G loss: 6.9175\n",
      "[4332/8000] D loss: 0.8849, G loss: 4.4514\n",
      "[4692/8000] D loss: 1.0476, G loss: 5.1191\n",
      "[5052/8000] D loss: 0.8605, G loss: 11.0331\n",
      "[5412/8000] D loss: 0.6920, G loss: 14.0725\n",
      "[5772/8000] D loss: 0.9811, G loss: 4.6584\n",
      "[6132/8000] D loss: 0.9267, G loss: 9.6713\n",
      "[6492/8000] D loss: 0.8837, G loss: 3.8100\n",
      "[6852/8000] D loss: 0.8081, G loss: 17.0198\n",
      "[7212/8000] D loss: 0.7535, G loss: 13.4925\n",
      "[7572/8000] D loss: 0.5969, G loss: 8.9002\n",
      "[7932/8000] D loss: 0.8307, G loss: 5.7878\n",
      "train error: \n",
      " D loss: 0.850714, G loss: 7.557497, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.029115, G loss: 21.846318, D accuracy: 77.1%, cell accuracy: 98.3%, board accuracy: 29.4% \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6845, G loss: 18.7096\n",
      "[372/8000] D loss: 0.5938, G loss: 10.6403\n",
      "[732/8000] D loss: 0.6046, G loss: 13.8769\n",
      "[1092/8000] D loss: 0.8239, G loss: 3.9265\n",
      "[1452/8000] D loss: 0.5978, G loss: 4.0633\n",
      "[1812/8000] D loss: 0.6553, G loss: 7.0830\n",
      "[2172/8000] D loss: 0.7690, G loss: 9.5923\n",
      "[2532/8000] D loss: 1.0564, G loss: 1.8924\n",
      "[2892/8000] D loss: 0.8246, G loss: 6.1306\n",
      "[3252/8000] D loss: 1.0059, G loss: 8.0647\n",
      "[3612/8000] D loss: 0.7813, G loss: 5.2547\n",
      "[3972/8000] D loss: 0.6073, G loss: 15.1152\n",
      "[4332/8000] D loss: 0.8203, G loss: 11.7926\n",
      "[4692/8000] D loss: 1.0509, G loss: 4.0788\n",
      "[5052/8000] D loss: 0.9092, G loss: 9.7906\n",
      "[5412/8000] D loss: 0.4087, G loss: 14.9087\n",
      "[5772/8000] D loss: 0.8074, G loss: 3.7834\n",
      "[6132/8000] D loss: 0.9738, G loss: 5.8712\n",
      "[6492/8000] D loss: 0.8685, G loss: 5.5148\n",
      "[6852/8000] D loss: 1.0116, G loss: 7.2376\n",
      "[7212/8000] D loss: 0.8732, G loss: 5.1163\n",
      "[7572/8000] D loss: 0.8032, G loss: 6.2550\n",
      "[7932/8000] D loss: 0.9984, G loss: 3.4202\n",
      "train error: \n",
      " D loss: 0.844861, G loss: 6.867845, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999214, G loss: 20.256988, D accuracy: 77.8%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7812, G loss: 6.6196\n",
      "[372/8000] D loss: 1.0189, G loss: 5.8736\n",
      "[732/8000] D loss: 0.7482, G loss: 11.2781\n",
      "[1092/8000] D loss: 0.7645, G loss: 4.9501\n",
      "[1452/8000] D loss: 0.8719, G loss: 5.6631\n",
      "[1812/8000] D loss: 0.8305, G loss: 5.0993\n",
      "[2172/8000] D loss: 0.4716, G loss: 8.9978\n",
      "[2532/8000] D loss: 0.7872, G loss: 6.5998\n",
      "[2892/8000] D loss: 0.6185, G loss: 6.9846\n",
      "[3252/8000] D loss: 0.9288, G loss: 6.2745\n",
      "[3612/8000] D loss: 0.6910, G loss: 6.5466\n",
      "[3972/8000] D loss: 0.9746, G loss: 4.3914\n",
      "[4332/8000] D loss: 1.0809, G loss: 2.2685\n",
      "[4692/8000] D loss: 0.8604, G loss: 7.0859\n",
      "[5052/8000] D loss: 0.6010, G loss: 9.0690\n",
      "[5412/8000] D loss: 0.7216, G loss: 11.8316\n",
      "[5772/8000] D loss: 1.0523, G loss: 5.7131\n",
      "[6132/8000] D loss: 0.8913, G loss: 8.3059\n",
      "[6492/8000] D loss: 0.4849, G loss: 12.9816\n",
      "[6852/8000] D loss: 1.1409, G loss: 1.7813\n",
      "[7212/8000] D loss: 0.5698, G loss: 11.9203\n",
      "[7572/8000] D loss: 1.0053, G loss: 3.4293\n",
      "[7932/8000] D loss: 1.0099, G loss: 5.7697\n",
      "train error: \n",
      " D loss: 0.857221, G loss: 6.036062, D accuracy: 71.6%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.837530, G loss: 19.526645, D accuracy: 80.7%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6172, G loss: 9.1517\n",
      "[372/8000] D loss: 0.6149, G loss: 7.4312\n",
      "[732/8000] D loss: 0.4742, G loss: 10.9773\n",
      "[1092/8000] D loss: 0.7403, G loss: 9.2377\n",
      "[1452/8000] D loss: 1.0926, G loss: 5.9062\n",
      "[1812/8000] D loss: 0.7432, G loss: 9.1933\n",
      "[2172/8000] D loss: 0.7045, G loss: 5.7193\n",
      "[2532/8000] D loss: 0.9305, G loss: 6.6430\n",
      "[2892/8000] D loss: 0.9417, G loss: 6.7814\n",
      "[3252/8000] D loss: 0.7133, G loss: 8.4348\n",
      "[3612/8000] D loss: 0.7701, G loss: 11.4588\n",
      "[3972/8000] D loss: 0.8864, G loss: 8.6907\n",
      "[4332/8000] D loss: 0.9862, G loss: 3.2204\n",
      "[4692/8000] D loss: 1.1254, G loss: 3.2848\n",
      "[5052/8000] D loss: 1.0638, G loss: 5.2102\n",
      "[5412/8000] D loss: 0.9315, G loss: 9.9778\n",
      "[5772/8000] D loss: 0.9776, G loss: 5.0185\n",
      "[6132/8000] D loss: 0.5716, G loss: 12.8424\n",
      "[6492/8000] D loss: 0.7599, G loss: 5.9031\n",
      "[6852/8000] D loss: 1.0392, G loss: 10.6942\n",
      "[7212/8000] D loss: 1.1123, G loss: 3.5437\n",
      "[7572/8000] D loss: 0.7509, G loss: 3.8601\n",
      "[7932/8000] D loss: 0.8185, G loss: 8.4141\n",
      "train error: \n",
      " D loss: 0.861353, G loss: 6.533935, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.061266, G loss: 19.791372, D accuracy: 75.5%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7033, G loss: 8.3589\n",
      "[372/8000] D loss: 0.8752, G loss: 4.3143\n",
      "[732/8000] D loss: 0.6805, G loss: 11.3723\n",
      "[1092/8000] D loss: 0.9463, G loss: 6.7783\n",
      "[1452/8000] D loss: 0.8266, G loss: 4.1135\n",
      "[1812/8000] D loss: 0.7830, G loss: 9.7471\n",
      "[2172/8000] D loss: 0.8064, G loss: 9.9476\n",
      "[2532/8000] D loss: 0.9274, G loss: 11.2991\n",
      "[2892/8000] D loss: 0.8490, G loss: 5.1407\n",
      "[3252/8000] D loss: 0.2591, G loss: 12.5599\n",
      "[3612/8000] D loss: 0.5491, G loss: 10.6179\n",
      "[3972/8000] D loss: 0.7143, G loss: 7.9853\n",
      "[4332/8000] D loss: 0.9218, G loss: 2.5094\n",
      "[4692/8000] D loss: 0.8007, G loss: 5.0263\n",
      "[5052/8000] D loss: 0.7133, G loss: 10.7861\n",
      "[5412/8000] D loss: 1.0438, G loss: 8.2449\n",
      "[5772/8000] D loss: 0.9443, G loss: 5.8655\n",
      "[6132/8000] D loss: 0.8361, G loss: 5.3770\n",
      "[6492/8000] D loss: 0.9190, G loss: 4.0195\n",
      "[6852/8000] D loss: 0.6982, G loss: 9.1520\n",
      "[7212/8000] D loss: 0.7475, G loss: 7.9606\n",
      "[7572/8000] D loss: 0.8532, G loss: 8.2952\n",
      "[7932/8000] D loss: 0.4699, G loss: 8.1536\n",
      "train error: \n",
      " D loss: 0.847745, G loss: 5.069165, D accuracy: 71.4%, cell accuracy: 98.7%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.942736, G loss: 16.897912, D accuracy: 77.0%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8705, G loss: 5.7259\n",
      "[372/8000] D loss: 1.0052, G loss: 5.2857\n",
      "[732/8000] D loss: 0.6909, G loss: 10.5491\n",
      "[1092/8000] D loss: 0.4629, G loss: 9.5880\n",
      "[1452/8000] D loss: 0.8172, G loss: 6.5473\n",
      "[1812/8000] D loss: 0.6824, G loss: 6.9912\n",
      "[2172/8000] D loss: 0.8211, G loss: 5.6754\n",
      "[2532/8000] D loss: 1.2823, G loss: 1.4994\n",
      "[2892/8000] D loss: 0.8142, G loss: 7.0933\n",
      "[3252/8000] D loss: 1.1487, G loss: 1.3743\n",
      "[3612/8000] D loss: 0.8068, G loss: 6.9256\n",
      "[3972/8000] D loss: 1.1652, G loss: 1.2911\n",
      "[4332/8000] D loss: 0.7520, G loss: 5.7236\n",
      "[4692/8000] D loss: 1.0407, G loss: 7.1723\n",
      "[5052/8000] D loss: 0.8702, G loss: 6.9843\n",
      "[5412/8000] D loss: 0.5123, G loss: 7.8508\n",
      "[5772/8000] D loss: 0.7537, G loss: 2.6340\n",
      "[6132/8000] D loss: 0.9017, G loss: 2.9338\n",
      "[6492/8000] D loss: 0.8490, G loss: 10.2611\n",
      "[6852/8000] D loss: 0.9251, G loss: 7.5124\n",
      "[7212/8000] D loss: 0.8540, G loss: 7.1142\n",
      "[7572/8000] D loss: 0.5788, G loss: 10.3588\n",
      "[7932/8000] D loss: 0.7579, G loss: 6.4814\n",
      "train error: \n",
      " D loss: 0.844730, G loss: 7.840586, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.960895, G loss: 23.043736, D accuracy: 77.9%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9023, G loss: 4.5123\n",
      "[372/8000] D loss: 0.4368, G loss: 10.1876\n",
      "[732/8000] D loss: 1.1723, G loss: 3.6648\n",
      "[1092/8000] D loss: 0.9357, G loss: 3.0913\n",
      "[1452/8000] D loss: 0.8193, G loss: 4.9174\n",
      "[1812/8000] D loss: 0.5971, G loss: 6.2526\n",
      "[2172/8000] D loss: 0.4715, G loss: 12.2634\n",
      "[2532/8000] D loss: 1.1892, G loss: 8.0369\n",
      "[2892/8000] D loss: 1.1523, G loss: 4.8620\n",
      "[3252/8000] D loss: 1.0722, G loss: 3.3841\n",
      "[3612/8000] D loss: 0.5390, G loss: 8.8981\n",
      "[3972/8000] D loss: 0.8448, G loss: 6.7484\n",
      "[4332/8000] D loss: 1.1612, G loss: 3.9311\n",
      "[4692/8000] D loss: 0.5524, G loss: 8.6122\n",
      "[5052/8000] D loss: 0.6315, G loss: 6.2754\n",
      "[5412/8000] D loss: 0.9827, G loss: 4.8607\n",
      "[5772/8000] D loss: 1.1600, G loss: 1.7267\n",
      "[6132/8000] D loss: 0.9747, G loss: 9.8310\n",
      "[6492/8000] D loss: 0.6236, G loss: 12.5189\n",
      "[6852/8000] D loss: 0.7687, G loss: 10.4772\n",
      "[7212/8000] D loss: 0.7978, G loss: 4.1972\n",
      "[7572/8000] D loss: 0.8312, G loss: 11.7466\n",
      "[7932/8000] D loss: 0.6911, G loss: 10.8465\n",
      "train error: \n",
      " D loss: 0.840368, G loss: 6.910837, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.942810, G loss: 20.360561, D accuracy: 80.7%, cell accuracy: 98.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9474, G loss: 5.5343\n",
      "[372/8000] D loss: 0.8626, G loss: 5.4795\n",
      "[732/8000] D loss: 0.7137, G loss: 4.9390\n",
      "[1092/8000] D loss: 1.0162, G loss: 2.7251\n",
      "[1452/8000] D loss: 0.8344, G loss: 10.5506\n",
      "[1812/8000] D loss: 1.1716, G loss: 4.8616\n",
      "[2172/8000] D loss: 0.9800, G loss: 4.4991\n",
      "[2532/8000] D loss: 0.6710, G loss: 9.7921\n",
      "[2892/8000] D loss: 0.6106, G loss: 6.8167\n",
      "[3252/8000] D loss: 0.8280, G loss: 6.8095\n",
      "[3612/8000] D loss: 0.6721, G loss: 7.2873\n",
      "[3972/8000] D loss: 1.1557, G loss: 1.9087\n",
      "[4332/8000] D loss: 0.8101, G loss: 8.7336\n",
      "[4692/8000] D loss: 0.8140, G loss: 9.1844\n",
      "[5052/8000] D loss: 0.8148, G loss: 17.2345\n",
      "[5412/8000] D loss: 0.8094, G loss: 2.1164\n",
      "[5772/8000] D loss: 0.7216, G loss: 8.9067\n",
      "[6132/8000] D loss: 0.3615, G loss: 7.3277\n",
      "[6492/8000] D loss: 1.1175, G loss: 2.2475\n",
      "[6852/8000] D loss: 0.6923, G loss: 10.3701\n",
      "[7212/8000] D loss: 0.9119, G loss: 7.2303\n",
      "[7572/8000] D loss: 0.8676, G loss: 12.8787\n",
      "[7932/8000] D loss: 0.9630, G loss: 3.2425\n",
      "train error: \n",
      " D loss: 0.856448, G loss: 6.344932, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.897136, G loss: 20.072890, D accuracy: 80.2%, cell accuracy: 98.3%, board accuracy: 29.9% \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8168, G loss: 8.1192\n",
      "[372/8000] D loss: 0.8883, G loss: 2.9961\n",
      "[732/8000] D loss: 1.1551, G loss: 2.4551\n",
      "[1092/8000] D loss: 1.1657, G loss: 3.8673\n",
      "[1452/8000] D loss: 1.1799, G loss: 1.9858\n",
      "[1812/8000] D loss: 0.6238, G loss: 2.7319\n",
      "[2172/8000] D loss: 0.9136, G loss: 5.3273\n",
      "[2532/8000] D loss: 1.2752, G loss: 2.4265\n",
      "[2892/8000] D loss: 0.5776, G loss: 9.4878\n",
      "[3252/8000] D loss: 1.0348, G loss: 2.4331\n",
      "[3612/8000] D loss: 0.8863, G loss: 5.3302\n",
      "[3972/8000] D loss: 0.6536, G loss: 5.5670\n",
      "[4332/8000] D loss: 0.5062, G loss: 7.9240\n",
      "[4692/8000] D loss: 0.8468, G loss: 10.6411\n",
      "[5052/8000] D loss: 0.9332, G loss: 7.5922\n",
      "[5412/8000] D loss: 0.9843, G loss: 10.5588\n",
      "[5772/8000] D loss: 1.1379, G loss: 3.3131\n",
      "[6132/8000] D loss: 0.8193, G loss: 13.4261\n",
      "[6492/8000] D loss: 0.9868, G loss: 3.5626\n",
      "[6852/8000] D loss: 0.8183, G loss: 6.0035\n",
      "[7212/8000] D loss: 0.7508, G loss: 4.6869\n",
      "[7572/8000] D loss: 0.6344, G loss: 6.8372\n",
      "[7932/8000] D loss: 1.0121, G loss: 5.0257\n",
      "train error: \n",
      " D loss: 0.859884, G loss: 5.746877, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.884747, G loss: 18.931661, D accuracy: 80.7%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1893, G loss: 3.0977\n",
      "[372/8000] D loss: 0.9439, G loss: 7.2907\n",
      "[732/8000] D loss: 0.5801, G loss: 12.0962\n",
      "[1092/8000] D loss: 0.8127, G loss: 10.0574\n",
      "[1452/8000] D loss: 0.6149, G loss: 9.5970\n",
      "[1812/8000] D loss: 0.8008, G loss: 10.2838\n",
      "[2172/8000] D loss: 0.7161, G loss: 2.8680\n",
      "[2532/8000] D loss: 0.6602, G loss: 8.0291\n",
      "[2892/8000] D loss: 0.9207, G loss: 3.3856\n",
      "[3252/8000] D loss: 1.0535, G loss: 3.8867\n",
      "[3612/8000] D loss: 0.5488, G loss: 14.0167\n",
      "[3972/8000] D loss: 0.7518, G loss: 8.4010\n",
      "[4332/8000] D loss: 0.6914, G loss: 11.3103\n",
      "[4692/8000] D loss: 0.6505, G loss: 4.6986\n",
      "[5052/8000] D loss: 0.7386, G loss: 5.7494\n",
      "[5412/8000] D loss: 0.5880, G loss: 5.7427\n",
      "[5772/8000] D loss: 0.7953, G loss: 5.6306\n",
      "[6132/8000] D loss: 1.0348, G loss: 2.4894\n",
      "[6492/8000] D loss: 0.6494, G loss: 14.5244\n",
      "[6852/8000] D loss: 0.5824, G loss: 6.4736\n",
      "[7212/8000] D loss: 0.8189, G loss: 6.4888\n",
      "[7572/8000] D loss: 0.9374, G loss: 2.6594\n",
      "[7932/8000] D loss: 1.1745, G loss: 4.9467\n",
      "train error: \n",
      " D loss: 0.851959, G loss: 8.351184, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.111752, G loss: 24.504927, D accuracy: 75.0%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7864, G loss: 11.3518\n",
      "[372/8000] D loss: 0.7850, G loss: 9.6859\n",
      "[732/8000] D loss: 0.9795, G loss: 11.1737\n",
      "[1092/8000] D loss: 0.6962, G loss: 9.3274\n",
      "[1452/8000] D loss: 1.0740, G loss: 9.6440\n",
      "[1812/8000] D loss: 0.7858, G loss: 7.8663\n",
      "[2172/8000] D loss: 0.8467, G loss: 6.8030\n",
      "[2532/8000] D loss: 0.9620, G loss: 7.4402\n",
      "[2892/8000] D loss: 0.5943, G loss: 4.2691\n",
      "[3252/8000] D loss: 1.0431, G loss: 6.7558\n",
      "[3612/8000] D loss: 0.8705, G loss: 3.7952\n",
      "[3972/8000] D loss: 0.6622, G loss: 10.7137\n",
      "[4332/8000] D loss: 0.9266, G loss: 6.4166\n",
      "[4692/8000] D loss: 0.9016, G loss: 2.6183\n",
      "[5052/8000] D loss: 0.8163, G loss: 6.4466\n",
      "[5412/8000] D loss: 0.9409, G loss: 4.5815\n",
      "[5772/8000] D loss: 0.8370, G loss: 5.8532\n",
      "[6132/8000] D loss: 0.8035, G loss: 6.9223\n",
      "[6492/8000] D loss: 1.0242, G loss: 9.0939\n",
      "[6852/8000] D loss: 0.5392, G loss: 5.4782\n",
      "[7212/8000] D loss: 0.8477, G loss: 5.9390\n",
      "[7572/8000] D loss: 0.7694, G loss: 7.5640\n",
      "[7932/8000] D loss: 0.6720, G loss: 11.9502\n",
      "train error: \n",
      " D loss: 0.846553, G loss: 6.856330, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.987344, G loss: 21.196109, D accuracy: 80.0%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0402, G loss: 4.3477\n",
      "[372/8000] D loss: 0.6749, G loss: 5.5389\n",
      "[732/8000] D loss: 1.0455, G loss: 2.7984\n",
      "[1092/8000] D loss: 0.9469, G loss: 4.8194\n",
      "[1452/8000] D loss: 1.0895, G loss: 2.7237\n",
      "[1812/8000] D loss: 0.4255, G loss: 15.4529\n",
      "[2172/8000] D loss: 0.5338, G loss: 12.1210\n",
      "[2532/8000] D loss: 0.9731, G loss: 5.0934\n",
      "[2892/8000] D loss: 0.7677, G loss: 6.3521\n",
      "[3252/8000] D loss: 0.5313, G loss: 6.8970\n",
      "[3612/8000] D loss: 1.1047, G loss: 3.4827\n",
      "[3972/8000] D loss: 0.8118, G loss: 6.4131\n",
      "[4332/8000] D loss: 0.7679, G loss: 4.6984\n",
      "[4692/8000] D loss: 0.5756, G loss: 5.9500\n",
      "[5052/8000] D loss: 0.7342, G loss: 8.1760\n",
      "[5412/8000] D loss: 1.0639, G loss: 3.8713\n",
      "[5772/8000] D loss: 0.6781, G loss: 5.6688\n",
      "[6132/8000] D loss: 0.7339, G loss: 10.4602\n",
      "[6492/8000] D loss: 0.6280, G loss: 11.5749\n",
      "[6852/8000] D loss: 0.6922, G loss: 5.3257\n",
      "[7212/8000] D loss: 0.6875, G loss: 5.6086\n",
      "[7572/8000] D loss: 0.8346, G loss: 5.5675\n",
      "[7932/8000] D loss: 0.8511, G loss: 3.3466\n",
      "train error: \n",
      " D loss: 0.854715, G loss: 5.683056, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.970588, G loss: 18.565646, D accuracy: 80.2%, cell accuracy: 98.3%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0026, G loss: 3.5086\n",
      "[372/8000] D loss: 0.8641, G loss: 4.9559\n",
      "[732/8000] D loss: 1.0656, G loss: 3.7218\n",
      "[1092/8000] D loss: 0.9683, G loss: 8.2882\n",
      "[1452/8000] D loss: 0.6974, G loss: 4.4852\n",
      "[1812/8000] D loss: 0.4517, G loss: 10.0730\n",
      "[2172/8000] D loss: 0.8631, G loss: 6.3422\n",
      "[2532/8000] D loss: 0.6693, G loss: 10.1371\n",
      "[2892/8000] D loss: 0.3634, G loss: 12.2968\n",
      "[3252/8000] D loss: 0.4717, G loss: 16.7161\n",
      "[3612/8000] D loss: 1.2410, G loss: 2.0656\n",
      "[3972/8000] D loss: 1.0386, G loss: 2.2271\n",
      "[4332/8000] D loss: 0.7420, G loss: 5.5072\n",
      "[4692/8000] D loss: 0.8851, G loss: 5.3773\n",
      "[5052/8000] D loss: 0.6787, G loss: 9.5271\n",
      "[5412/8000] D loss: 0.5590, G loss: 14.9324\n",
      "[5772/8000] D loss: 0.8003, G loss: 8.9205\n",
      "[6132/8000] D loss: 0.5912, G loss: 8.4397\n",
      "[6492/8000] D loss: 0.9500, G loss: 6.5791\n",
      "[6852/8000] D loss: 0.3654, G loss: 13.2193\n",
      "[7212/8000] D loss: 0.9963, G loss: 4.2682\n",
      "[7572/8000] D loss: 0.8111, G loss: 7.4510\n",
      "[7932/8000] D loss: 1.1235, G loss: 3.9074\n",
      "train error: \n",
      " D loss: 0.841620, G loss: 7.228811, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.000246, G loss: 21.912367, D accuracy: 77.1%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4955, G loss: 8.3806\n",
      "[372/8000] D loss: 0.6353, G loss: 11.9187\n",
      "[732/8000] D loss: 0.8017, G loss: 14.9012\n",
      "[1092/8000] D loss: 0.6336, G loss: 6.2651\n",
      "[1452/8000] D loss: 0.9410, G loss: 7.3831\n",
      "[1812/8000] D loss: 1.0876, G loss: 5.4377\n",
      "[2172/8000] D loss: 1.0351, G loss: 2.8209\n",
      "[2532/8000] D loss: 0.6060, G loss: 9.1355\n",
      "[2892/8000] D loss: 0.8396, G loss: 5.9333\n",
      "[3252/8000] D loss: 0.6966, G loss: 6.7094\n",
      "[3612/8000] D loss: 0.8037, G loss: 2.9432\n",
      "[3972/8000] D loss: 0.5834, G loss: 3.9857\n",
      "[4332/8000] D loss: 0.6181, G loss: 7.7232\n",
      "[4692/8000] D loss: 0.9204, G loss: 7.8448\n",
      "[5052/8000] D loss: 0.9116, G loss: 4.4822\n",
      "[5412/8000] D loss: 0.7187, G loss: 3.4912\n",
      "[5772/8000] D loss: 0.7612, G loss: 4.2779\n",
      "[6132/8000] D loss: 0.8102, G loss: 7.2651\n",
      "[6492/8000] D loss: 1.3732, G loss: 2.7141\n",
      "[6852/8000] D loss: 1.1589, G loss: 4.2305\n",
      "[7212/8000] D loss: 1.0638, G loss: 3.9124\n",
      "[7572/8000] D loss: 0.7651, G loss: 7.6211\n",
      "[7932/8000] D loss: 0.6797, G loss: 7.7662\n",
      "train error: \n",
      " D loss: 0.854468, G loss: 5.879235, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.955342, G loss: 18.365696, D accuracy: 78.5%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7767, G loss: 7.7442\n",
      "[372/8000] D loss: 0.9234, G loss: 4.1455\n",
      "[732/8000] D loss: 0.8598, G loss: 4.0967\n",
      "[1092/8000] D loss: 0.9554, G loss: 2.5562\n",
      "[1452/8000] D loss: 1.0135, G loss: 6.1439\n",
      "[1812/8000] D loss: 0.6943, G loss: 10.5010\n",
      "[2172/8000] D loss: 0.5824, G loss: 7.6980\n",
      "[2532/8000] D loss: 0.8057, G loss: 4.6148\n",
      "[2892/8000] D loss: 1.1980, G loss: 2.8843\n",
      "[3252/8000] D loss: 0.6354, G loss: 8.0015\n",
      "[3612/8000] D loss: 0.7030, G loss: 6.4927\n",
      "[3972/8000] D loss: 0.7939, G loss: 11.1727\n",
      "[4332/8000] D loss: 0.7141, G loss: 5.3280\n",
      "[4692/8000] D loss: 0.8661, G loss: 6.0192\n",
      "[5052/8000] D loss: 0.8021, G loss: 4.0204\n",
      "[5412/8000] D loss: 0.5956, G loss: 7.1472\n",
      "[5772/8000] D loss: 0.6838, G loss: 5.1308\n",
      "[6132/8000] D loss: 1.0386, G loss: 7.9089\n",
      "[6492/8000] D loss: 1.0517, G loss: 6.1781\n",
      "[6852/8000] D loss: 0.7263, G loss: 3.9356\n",
      "[7212/8000] D loss: 1.1558, G loss: 5.5113\n",
      "[7572/8000] D loss: 0.9170, G loss: 6.5252\n",
      "[7932/8000] D loss: 0.8224, G loss: 5.2050\n",
      "train error: \n",
      " D loss: 0.846219, G loss: 7.205123, D accuracy: 71.8%, cell accuracy: 98.7%, board accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.991091, G loss: 21.791464, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8802, G loss: 10.4175\n",
      "[372/8000] D loss: 0.8358, G loss: 6.7594\n",
      "[732/8000] D loss: 0.5447, G loss: 4.1127\n",
      "[1092/8000] D loss: 0.7652, G loss: 3.1530\n",
      "[1452/8000] D loss: 0.8536, G loss: 4.6157\n",
      "[1812/8000] D loss: 0.8427, G loss: 5.0518\n",
      "[2172/8000] D loss: 0.7551, G loss: 4.7463\n",
      "[2532/8000] D loss: 0.4492, G loss: 8.3879\n",
      "[2892/8000] D loss: 0.8318, G loss: 9.9267\n",
      "[3252/8000] D loss: 0.8589, G loss: 9.6843\n",
      "[3612/8000] D loss: 0.8328, G loss: 4.5192\n",
      "[3972/8000] D loss: 0.8194, G loss: 5.3743\n",
      "[4332/8000] D loss: 1.0743, G loss: 1.6174\n",
      "[4692/8000] D loss: 0.8823, G loss: 9.5607\n",
      "[5052/8000] D loss: 0.6029, G loss: 5.7989\n",
      "[5412/8000] D loss: 0.8129, G loss: 2.9620\n",
      "[5772/8000] D loss: 0.6841, G loss: 5.4843\n",
      "[6132/8000] D loss: 0.6613, G loss: 6.3908\n",
      "[6492/8000] D loss: 0.8496, G loss: 2.7805\n",
      "[6852/8000] D loss: 0.7794, G loss: 11.7856\n",
      "[7212/8000] D loss: 0.8091, G loss: 9.9329\n",
      "[7572/8000] D loss: 0.6668, G loss: 6.5264\n",
      "[7932/8000] D loss: 0.9297, G loss: 2.9783\n",
      "train error: \n",
      " D loss: 0.856978, G loss: 6.477060, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.990164, G loss: 19.762421, D accuracy: 78.0%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8552, G loss: 6.2121\n",
      "[372/8000] D loss: 0.5794, G loss: 8.5424\n",
      "[732/8000] D loss: 0.4815, G loss: 11.4749\n",
      "[1092/8000] D loss: 0.8144, G loss: 7.1843\n",
      "[1452/8000] D loss: 0.8615, G loss: 6.3018\n",
      "[1812/8000] D loss: 0.7632, G loss: 7.4618\n",
      "[2172/8000] D loss: 0.9793, G loss: 8.1265\n",
      "[2532/8000] D loss: 0.9961, G loss: 3.6674\n",
      "[2892/8000] D loss: 0.5565, G loss: 4.7265\n",
      "[3252/8000] D loss: 0.8648, G loss: 5.5082\n",
      "[3612/8000] D loss: 0.7092, G loss: 3.8679\n",
      "[3972/8000] D loss: 0.5961, G loss: 19.9486\n",
      "[4332/8000] D loss: 0.8060, G loss: 8.2685\n",
      "[4692/8000] D loss: 0.9856, G loss: 3.7684\n",
      "[5052/8000] D loss: 0.9928, G loss: 6.0964\n",
      "[5412/8000] D loss: 0.7095, G loss: 4.7365\n",
      "[5772/8000] D loss: 0.4846, G loss: 6.9331\n",
      "[6132/8000] D loss: 0.8233, G loss: 4.5668\n",
      "[6492/8000] D loss: 0.7685, G loss: 5.4587\n",
      "[6852/8000] D loss: 0.6844, G loss: 8.5467\n",
      "[7212/8000] D loss: 1.0417, G loss: 7.2055\n",
      "[7572/8000] D loss: 0.8174, G loss: 6.8311\n",
      "[7932/8000] D loss: 0.7449, G loss: 6.0251\n",
      "train error: \n",
      " D loss: 0.867204, G loss: 4.878189, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.899198, G loss: 17.040929, D accuracy: 82.4%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5900, G loss: 9.6015\n",
      "[372/8000] D loss: 0.6330, G loss: 5.4827\n",
      "[732/8000] D loss: 0.4586, G loss: 12.8162\n",
      "[1092/8000] D loss: 0.7650, G loss: 9.0774\n",
      "[1452/8000] D loss: 0.8791, G loss: 5.8877\n",
      "[1812/8000] D loss: 0.5839, G loss: 11.8263\n",
      "[2172/8000] D loss: 0.5928, G loss: 10.9377\n",
      "[2532/8000] D loss: 0.9713, G loss: 7.1963\n",
      "[2892/8000] D loss: 0.6790, G loss: 7.9643\n",
      "[3252/8000] D loss: 0.7387, G loss: 6.9701\n",
      "[3612/8000] D loss: 0.9862, G loss: 5.6188\n",
      "[3972/8000] D loss: 0.8193, G loss: 7.4716\n",
      "[4332/8000] D loss: 0.4054, G loss: 9.4667\n",
      "[4692/8000] D loss: 0.7899, G loss: 9.3251\n",
      "[5052/8000] D loss: 0.8503, G loss: 5.0661\n",
      "[5412/8000] D loss: 0.8439, G loss: 10.4538\n",
      "[5772/8000] D loss: 0.8576, G loss: 7.3646\n",
      "[6132/8000] D loss: 1.0338, G loss: 4.6252\n",
      "[6492/8000] D loss: 0.5992, G loss: 8.4614\n",
      "[6852/8000] D loss: 0.8149, G loss: 5.5706\n",
      "[7212/8000] D loss: 0.8421, G loss: 4.8154\n",
      "[7572/8000] D loss: 1.0723, G loss: 4.5677\n",
      "[7932/8000] D loss: 0.7601, G loss: 10.8373\n",
      "train error: \n",
      " D loss: 0.847535, G loss: 7.424704, D accuracy: 71.6%, cell accuracy: 98.8%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.081091, G loss: 22.196988, D accuracy: 77.7%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0391, G loss: 2.2934\n",
      "[372/8000] D loss: 0.7756, G loss: 7.9679\n",
      "[732/8000] D loss: 1.0125, G loss: 11.6602\n",
      "[1092/8000] D loss: 0.7574, G loss: 9.2813\n",
      "[1452/8000] D loss: 0.5960, G loss: 14.4820\n",
      "[1812/8000] D loss: 0.9835, G loss: 5.0206\n",
      "[2172/8000] D loss: 1.0282, G loss: 2.7526\n",
      "[2532/8000] D loss: 0.8544, G loss: 6.9387\n",
      "[2892/8000] D loss: 1.1537, G loss: 4.8021\n",
      "[3252/8000] D loss: 1.1645, G loss: 1.3683\n",
      "[3612/8000] D loss: 0.9957, G loss: 5.6933\n",
      "[3972/8000] D loss: 0.8077, G loss: 5.7880\n",
      "[4332/8000] D loss: 0.7092, G loss: 7.1757\n",
      "[4692/8000] D loss: 0.9988, G loss: 4.5795\n",
      "[5052/8000] D loss: 0.4988, G loss: 6.7929\n",
      "[5412/8000] D loss: 0.6834, G loss: 4.4597\n",
      "[5772/8000] D loss: 1.1851, G loss: 5.1189\n",
      "[6132/8000] D loss: 1.0895, G loss: 2.5423\n",
      "[6492/8000] D loss: 0.6690, G loss: 5.4953\n",
      "[6852/8000] D loss: 0.8105, G loss: 7.8502\n",
      "[7212/8000] D loss: 1.0346, G loss: 10.7618\n",
      "[7572/8000] D loss: 0.5808, G loss: 11.1808\n",
      "[7932/8000] D loss: 0.9265, G loss: 6.8251\n",
      "train error: \n",
      " D loss: 0.856043, G loss: 6.689433, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.959709, G loss: 20.657708, D accuracy: 79.1%, cell accuracy: 98.3%, board accuracy: 29.3% \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0556, G loss: 4.6194\n",
      "[372/8000] D loss: 0.8133, G loss: 6.4199\n",
      "[732/8000] D loss: 0.6864, G loss: 9.5209\n",
      "[1092/8000] D loss: 0.8131, G loss: 10.7443\n",
      "[1452/8000] D loss: 1.0685, G loss: 4.9179\n",
      "[1812/8000] D loss: 0.7158, G loss: 8.2048\n",
      "[2172/8000] D loss: 0.6256, G loss: 13.2412\n",
      "[2532/8000] D loss: 0.8059, G loss: 9.0064\n",
      "[2892/8000] D loss: 0.8326, G loss: 4.3376\n",
      "[3252/8000] D loss: 0.6598, G loss: 9.3186\n",
      "[3612/8000] D loss: 0.8212, G loss: 6.9411\n",
      "[3972/8000] D loss: 0.7446, G loss: 5.5913\n",
      "[4332/8000] D loss: 0.8238, G loss: 9.1757\n",
      "[4692/8000] D loss: 1.1103, G loss: 4.4966\n",
      "[5052/8000] D loss: 0.7805, G loss: 12.4007\n",
      "[5412/8000] D loss: 0.6930, G loss: 11.8163\n",
      "[5772/8000] D loss: 0.8286, G loss: 6.7460\n",
      "[6132/8000] D loss: 0.6945, G loss: 8.6823\n",
      "[6492/8000] D loss: 0.7882, G loss: 6.8942\n",
      "[6852/8000] D loss: 0.6849, G loss: 8.6749\n",
      "[7212/8000] D loss: 0.4978, G loss: 8.9084\n",
      "[7572/8000] D loss: 0.5547, G loss: 8.0867\n",
      "[7932/8000] D loss: 1.0541, G loss: 4.1939\n",
      "train error: \n",
      " D loss: 0.844576, G loss: 7.173700, D accuracy: 71.9%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.969218, G loss: 21.374726, D accuracy: 80.2%, cell accuracy: 98.2%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4432, G loss: 15.4911\n",
      "[372/8000] D loss: 1.1230, G loss: 4.9095\n",
      "[732/8000] D loss: 0.6302, G loss: 14.0115\n",
      "[1092/8000] D loss: 0.6392, G loss: 12.8008\n",
      "[1452/8000] D loss: 0.7574, G loss: 5.4369\n",
      "[1812/8000] D loss: 0.5225, G loss: 9.9280\n",
      "[2172/8000] D loss: 0.3516, G loss: 10.9001\n",
      "[2532/8000] D loss: 0.8544, G loss: 11.6519\n",
      "[2892/8000] D loss: 0.7770, G loss: 7.2146\n",
      "[3252/8000] D loss: 0.8217, G loss: 7.2779\n",
      "[3612/8000] D loss: 0.8797, G loss: 4.3607\n",
      "[3972/8000] D loss: 0.8948, G loss: 3.7169\n",
      "[4332/8000] D loss: 0.7039, G loss: 8.6173\n",
      "[4692/8000] D loss: 0.7768, G loss: 6.3889\n",
      "[5052/8000] D loss: 1.2228, G loss: 1.7781\n",
      "[5412/8000] D loss: 0.8110, G loss: 7.1443\n",
      "[5772/8000] D loss: 0.9418, G loss: 6.0668\n",
      "[6132/8000] D loss: 0.7062, G loss: 7.7142\n",
      "[6492/8000] D loss: 1.0535, G loss: 3.5360\n",
      "[6852/8000] D loss: 1.0149, G loss: 5.7606\n",
      "[7212/8000] D loss: 0.8115, G loss: 6.2528\n",
      "[7572/8000] D loss: 0.3541, G loss: 16.4953\n",
      "[7932/8000] D loss: 0.8240, G loss: 4.8184\n",
      "train error: \n",
      " D loss: 0.865166, G loss: 5.304241, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.871202, G loss: 17.348618, D accuracy: 81.5%, cell accuracy: 98.3%, board accuracy: 30.1% \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0712, G loss: 2.3946\n",
      "[372/8000] D loss: 0.7322, G loss: 6.2018\n",
      "[732/8000] D loss: 1.1185, G loss: 4.3650\n",
      "[1092/8000] D loss: 1.1717, G loss: 1.4377\n",
      "[1452/8000] D loss: 0.8100, G loss: 4.8044\n",
      "[1812/8000] D loss: 0.7847, G loss: 4.5873\n",
      "[2172/8000] D loss: 0.7004, G loss: 8.5855\n",
      "[2532/8000] D loss: 0.5487, G loss: 9.1293\n",
      "[2892/8000] D loss: 0.5679, G loss: 9.4389\n",
      "[3252/8000] D loss: 0.6336, G loss: 10.2370\n",
      "[3612/8000] D loss: 0.8208, G loss: 4.7946\n",
      "[3972/8000] D loss: 1.0321, G loss: 4.7851\n",
      "[4332/8000] D loss: 0.4633, G loss: 11.7750\n",
      "[4692/8000] D loss: 0.6629, G loss: 8.7240\n",
      "[5052/8000] D loss: 0.8233, G loss: 5.0640\n",
      "[5412/8000] D loss: 0.9412, G loss: 5.4143\n",
      "[5772/8000] D loss: 0.8104, G loss: 8.2412\n",
      "[6132/8000] D loss: 0.8186, G loss: 7.3918\n",
      "[6492/8000] D loss: 0.4719, G loss: 14.9221\n",
      "[6852/8000] D loss: 0.9663, G loss: 7.1022\n",
      "[7212/8000] D loss: 0.7037, G loss: 9.8168\n",
      "[7572/8000] D loss: 0.5900, G loss: 9.0472\n",
      "[7932/8000] D loss: 1.0137, G loss: 6.4265\n",
      "train error: \n",
      " D loss: 0.849068, G loss: 7.099202, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.078650, G loss: 21.140080, D accuracy: 77.1%, cell accuracy: 98.3%, board accuracy: 29.7% \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3398, G loss: 15.8188\n",
      "[372/8000] D loss: 0.6281, G loss: 16.1048\n",
      "[732/8000] D loss: 0.4713, G loss: 5.3348\n",
      "[1092/8000] D loss: 1.0077, G loss: 6.4571\n",
      "[1452/8000] D loss: 0.9309, G loss: 2.2009\n",
      "[1812/8000] D loss: 1.1272, G loss: 6.1479\n",
      "[2172/8000] D loss: 0.8475, G loss: 1.9148\n",
      "[2532/8000] D loss: 0.8388, G loss: 6.7206\n",
      "[2892/8000] D loss: 0.6478, G loss: 9.7194\n",
      "[3252/8000] D loss: 0.5347, G loss: 7.2059\n",
      "[3612/8000] D loss: 1.2205, G loss: 1.5408\n",
      "[3972/8000] D loss: 1.0462, G loss: 1.8816\n",
      "[4332/8000] D loss: 0.4722, G loss: 8.7780\n",
      "[4692/8000] D loss: 0.8217, G loss: 3.9760\n",
      "[5052/8000] D loss: 0.8192, G loss: 5.4821\n",
      "[5412/8000] D loss: 0.5781, G loss: 7.4655\n",
      "[5772/8000] D loss: 0.7973, G loss: 7.1712\n",
      "[6132/8000] D loss: 0.6744, G loss: 4.6545\n",
      "[6492/8000] D loss: 0.4746, G loss: 10.2378\n",
      "[6852/8000] D loss: 0.5425, G loss: 10.2342\n",
      "[7212/8000] D loss: 0.5808, G loss: 10.6281\n",
      "[7572/8000] D loss: 0.7906, G loss: 4.7748\n",
      "[7932/8000] D loss: 0.6353, G loss: 5.8219\n",
      "train error: \n",
      " D loss: 0.859231, G loss: 6.505630, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.008937, G loss: 19.998052, D accuracy: 73.8%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7062, G loss: 7.3888\n",
      "[372/8000] D loss: 0.5656, G loss: 11.1288\n",
      "[732/8000] D loss: 1.0475, G loss: 2.1818\n",
      "[1092/8000] D loss: 1.1038, G loss: 1.6096\n",
      "[1452/8000] D loss: 0.5847, G loss: 9.8893\n",
      "[1812/8000] D loss: 0.8375, G loss: 9.5556\n",
      "[2172/8000] D loss: 0.9300, G loss: 7.0135\n",
      "[2532/8000] D loss: 0.7625, G loss: 6.6426\n",
      "[2892/8000] D loss: 1.0672, G loss: 3.1813\n",
      "[3252/8000] D loss: 0.9664, G loss: 1.9306\n",
      "[3612/8000] D loss: 1.2891, G loss: 2.7569\n",
      "[3972/8000] D loss: 0.7579, G loss: 10.2374\n",
      "[4332/8000] D loss: 0.6550, G loss: 6.9952\n",
      "[4692/8000] D loss: 0.8205, G loss: 5.8523\n",
      "[5052/8000] D loss: 0.4893, G loss: 12.1122\n",
      "[5412/8000] D loss: 1.0591, G loss: 5.6001\n",
      "[5772/8000] D loss: 0.5256, G loss: 9.3985\n",
      "[6132/8000] D loss: 1.0521, G loss: 3.6437\n",
      "[6492/8000] D loss: 0.8333, G loss: 2.7014\n",
      "[6852/8000] D loss: 0.7719, G loss: 4.9741\n",
      "[7212/8000] D loss: 1.0994, G loss: 4.8962\n",
      "[7572/8000] D loss: 1.0569, G loss: 4.4043\n",
      "[7932/8000] D loss: 1.1650, G loss: 1.7644\n",
      "train error: \n",
      " D loss: 0.843623, G loss: 8.148804, D accuracy: 72.1%, cell accuracy: 98.8%, board accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.044119, G loss: 23.305044, D accuracy: 77.8%, cell accuracy: 98.3%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5922, G loss: 7.2871\n",
      "[372/8000] D loss: 0.9969, G loss: 2.8024\n",
      "[732/8000] D loss: 0.9262, G loss: 6.0340\n",
      "[1092/8000] D loss: 1.1083, G loss: 3.3052\n",
      "[1452/8000] D loss: 0.8329, G loss: 8.2096\n",
      "[1812/8000] D loss: 0.8818, G loss: 6.6555\n",
      "[2172/8000] D loss: 1.0599, G loss: 4.4036\n",
      "[2532/8000] D loss: 1.0634, G loss: 9.9637\n",
      "[2892/8000] D loss: 0.9272, G loss: 8.9223\n",
      "[3252/8000] D loss: 1.0290, G loss: 5.5340\n",
      "[3612/8000] D loss: 0.9458, G loss: 9.3670\n",
      "[3972/8000] D loss: 0.7147, G loss: 8.3155\n",
      "[4332/8000] D loss: 0.6926, G loss: 12.2063\n",
      "[4692/8000] D loss: 0.8752, G loss: 4.2762\n",
      "[5052/8000] D loss: 0.9769, G loss: 4.2755\n",
      "[5412/8000] D loss: 0.7631, G loss: 7.8067\n",
      "[5772/8000] D loss: 1.0530, G loss: 2.3923\n",
      "[6132/8000] D loss: 0.9561, G loss: 4.1398\n",
      "[6492/8000] D loss: 1.0684, G loss: 5.1023\n",
      "[6852/8000] D loss: 0.6894, G loss: 5.4848\n",
      "[7212/8000] D loss: 0.5789, G loss: 10.2969\n",
      "[7572/8000] D loss: 0.5745, G loss: 8.4923\n",
      "[7932/8000] D loss: 0.6965, G loss: 4.4002\n",
      "train error: \n",
      " D loss: 0.867220, G loss: 6.277052, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.944323, G loss: 19.806440, D accuracy: 81.1%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9444, G loss: 3.3949\n",
      "[372/8000] D loss: 0.6750, G loss: 7.3880\n",
      "[732/8000] D loss: 0.9778, G loss: 2.9106\n",
      "[1092/8000] D loss: 0.5951, G loss: 6.9053\n",
      "[1452/8000] D loss: 0.5811, G loss: 9.4018\n",
      "[1812/8000] D loss: 0.7068, G loss: 5.7886\n",
      "[2172/8000] D loss: 0.7080, G loss: 4.1433\n",
      "[2532/8000] D loss: 0.5855, G loss: 6.7974\n",
      "[2892/8000] D loss: 0.8574, G loss: 4.2128\n",
      "[3252/8000] D loss: 0.5913, G loss: 7.1891\n",
      "[3612/8000] D loss: 0.7641, G loss: 7.8533\n",
      "[3972/8000] D loss: 1.1524, G loss: 3.5046\n",
      "[4332/8000] D loss: 0.5885, G loss: 5.6565\n",
      "[4692/8000] D loss: 0.7060, G loss: 8.4454\n",
      "[5052/8000] D loss: 0.6652, G loss: 10.4958\n",
      "[5412/8000] D loss: 0.7244, G loss: 10.6353\n",
      "[5772/8000] D loss: 0.6982, G loss: 6.6236\n",
      "[6132/8000] D loss: 0.6976, G loss: 8.7903\n",
      "[6492/8000] D loss: 0.8365, G loss: 3.4066\n",
      "[6852/8000] D loss: 0.9164, G loss: 9.9986\n",
      "[7212/8000] D loss: 0.7781, G loss: 9.8613\n",
      "[7572/8000] D loss: 0.8142, G loss: 4.7990\n",
      "[7932/8000] D loss: 0.8131, G loss: 2.3687\n",
      "train error: \n",
      " D loss: 0.874108, G loss: 4.637716, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.971713, G loss: 15.893662, D accuracy: 75.9%, cell accuracy: 98.3%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2589, G loss: 1.1121\n",
      "[372/8000] D loss: 0.8119, G loss: 5.3166\n",
      "[732/8000] D loss: 0.8198, G loss: 5.2432\n",
      "[1092/8000] D loss: 0.7656, G loss: 6.5400\n",
      "[1452/8000] D loss: 0.8495, G loss: 5.0915\n",
      "[1812/8000] D loss: 0.8776, G loss: 12.1919\n",
      "[2172/8000] D loss: 1.0902, G loss: 2.3224\n",
      "[2532/8000] D loss: 0.7375, G loss: 4.6545\n",
      "[2892/8000] D loss: 1.3927, G loss: 1.0323\n",
      "[3252/8000] D loss: 0.9187, G loss: 2.4318\n",
      "[3612/8000] D loss: 0.8408, G loss: 4.0183\n",
      "[3972/8000] D loss: 0.9318, G loss: 4.7774\n",
      "[4332/8000] D loss: 1.1047, G loss: 1.9184\n",
      "[4692/8000] D loss: 0.8278, G loss: 10.3687\n",
      "[5052/8000] D loss: 0.8008, G loss: 8.1828\n",
      "[5412/8000] D loss: 0.6144, G loss: 5.5604\n",
      "[5772/8000] D loss: 0.6741, G loss: 10.7866\n",
      "[6132/8000] D loss: 0.9308, G loss: 8.9359\n",
      "[6492/8000] D loss: 1.0001, G loss: 4.0395\n",
      "[6852/8000] D loss: 0.7481, G loss: 6.9669\n",
      "[7212/8000] D loss: 0.7071, G loss: 12.0915\n",
      "[7572/8000] D loss: 0.6681, G loss: 5.8621\n",
      "[7932/8000] D loss: 0.9190, G loss: 3.6545\n",
      "train error: \n",
      " D loss: 0.842129, G loss: 7.052159, D accuracy: 71.6%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.059225, G loss: 21.451529, D accuracy: 76.7%, cell accuracy: 98.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0569, G loss: 4.3054\n",
      "[372/8000] D loss: 1.0322, G loss: 2.6369\n",
      "[732/8000] D loss: 0.7017, G loss: 12.0979\n",
      "[1092/8000] D loss: 1.0629, G loss: 3.2880\n",
      "[1452/8000] D loss: 0.9391, G loss: 3.6083\n",
      "[1812/8000] D loss: 0.6937, G loss: 6.8637\n",
      "[2172/8000] D loss: 0.8214, G loss: 5.3926\n",
      "[2532/8000] D loss: 0.9221, G loss: 7.6211\n",
      "[2892/8000] D loss: 0.9226, G loss: 5.6645\n",
      "[3252/8000] D loss: 1.0847, G loss: 3.6005\n",
      "[3612/8000] D loss: 1.1151, G loss: 3.9884\n",
      "[3972/8000] D loss: 0.8184, G loss: 6.4775\n",
      "[4332/8000] D loss: 0.8510, G loss: 3.8579\n",
      "[4692/8000] D loss: 0.7110, G loss: 3.2908\n",
      "[5052/8000] D loss: 0.8093, G loss: 4.6229\n",
      "[5412/8000] D loss: 0.4974, G loss: 19.1926\n",
      "[5772/8000] D loss: 0.6630, G loss: 11.5018\n",
      "[6132/8000] D loss: 1.0445, G loss: 4.5039\n",
      "[6492/8000] D loss: 0.8224, G loss: 7.1316\n",
      "[6852/8000] D loss: 0.9833, G loss: 2.5507\n",
      "[7212/8000] D loss: 0.9938, G loss: 5.0725\n",
      "[7572/8000] D loss: 1.0972, G loss: 5.5337\n",
      "[7932/8000] D loss: 1.2295, G loss: 1.7991\n",
      "train error: \n",
      " D loss: 0.846942, G loss: 7.352996, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.077058, G loss: 22.176731, D accuracy: 76.8%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1568, G loss: 4.4346\n",
      "[372/8000] D loss: 1.1060, G loss: 2.2820\n",
      "[732/8000] D loss: 0.8701, G loss: 3.2609\n",
      "[1092/8000] D loss: 0.6426, G loss: 5.6761\n",
      "[1452/8000] D loss: 1.2246, G loss: 4.9186\n",
      "[1812/8000] D loss: 0.6324, G loss: 25.6768\n",
      "[2172/8000] D loss: 0.9498, G loss: 7.6926\n",
      "[2532/8000] D loss: 0.8186, G loss: 9.1148\n",
      "[2892/8000] D loss: 0.8786, G loss: 5.5749\n",
      "[3252/8000] D loss: 0.8792, G loss: 4.3844\n",
      "[3612/8000] D loss: 0.7924, G loss: 8.4886\n",
      "[3972/8000] D loss: 0.7089, G loss: 6.4662\n",
      "[4332/8000] D loss: 0.9281, G loss: 10.3864\n",
      "[4692/8000] D loss: 0.8204, G loss: 6.3448\n",
      "[5052/8000] D loss: 0.8358, G loss: 3.5805\n",
      "[5412/8000] D loss: 0.9307, G loss: 5.6873\n",
      "[5772/8000] D loss: 0.6978, G loss: 4.4967\n",
      "[6132/8000] D loss: 0.8225, G loss: 6.7584\n",
      "[6492/8000] D loss: 0.8296, G loss: 3.5451\n",
      "[6852/8000] D loss: 0.9397, G loss: 9.8072\n",
      "[7212/8000] D loss: 1.0169, G loss: 4.6356\n",
      "[7572/8000] D loss: 1.0529, G loss: 4.6454\n",
      "[7932/8000] D loss: 0.7857, G loss: 6.0505\n",
      "train error: \n",
      " D loss: 0.855771, G loss: 6.903367, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.995920, G loss: 21.489028, D accuracy: 78.0%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9453, G loss: 2.2829\n",
      "[372/8000] D loss: 1.0451, G loss: 6.9497\n",
      "[732/8000] D loss: 1.2764, G loss: 3.5108\n",
      "[1092/8000] D loss: 0.9284, G loss: 4.7693\n",
      "[1452/8000] D loss: 0.6953, G loss: 7.9242\n",
      "[1812/8000] D loss: 0.8362, G loss: 5.5425\n",
      "[2172/8000] D loss: 0.7460, G loss: 9.2018\n",
      "[2532/8000] D loss: 0.7489, G loss: 3.8932\n",
      "[2892/8000] D loss: 0.5181, G loss: 9.8994\n",
      "[3252/8000] D loss: 1.1442, G loss: 3.4891\n",
      "[3612/8000] D loss: 0.8719, G loss: 5.9888\n",
      "[3972/8000] D loss: 0.6363, G loss: 4.1464\n",
      "[4332/8000] D loss: 1.0077, G loss: 7.6557\n",
      "[4692/8000] D loss: 0.8130, G loss: 3.0726\n",
      "[5052/8000] D loss: 0.8153, G loss: 10.5196\n",
      "[5412/8000] D loss: 0.6053, G loss: 5.7403\n",
      "[5772/8000] D loss: 1.1684, G loss: 3.3742\n",
      "[6132/8000] D loss: 0.7018, G loss: 11.9830\n",
      "[6492/8000] D loss: 0.5936, G loss: 5.7956\n",
      "[6852/8000] D loss: 0.5407, G loss: 13.5268\n",
      "[7212/8000] D loss: 0.7886, G loss: 10.5083\n",
      "[7572/8000] D loss: 0.6274, G loss: 6.1720\n",
      "[7932/8000] D loss: 0.6964, G loss: 9.8999\n",
      "train error: \n",
      " D loss: 0.854095, G loss: 6.492287, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.943986, G loss: 20.347556, D accuracy: 80.1%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4708, G loss: 8.0686\n",
      "[372/8000] D loss: 0.9078, G loss: 4.3665\n",
      "[732/8000] D loss: 0.8630, G loss: 4.7685\n",
      "[1092/8000] D loss: 0.5482, G loss: 8.0227\n",
      "[1452/8000] D loss: 1.0512, G loss: 7.5352\n",
      "[1812/8000] D loss: 1.0545, G loss: 4.7425\n",
      "[2172/8000] D loss: 1.0337, G loss: 5.1697\n",
      "[2532/8000] D loss: 0.6786, G loss: 4.2498\n",
      "[2892/8000] D loss: 0.9356, G loss: 7.4533\n",
      "[3252/8000] D loss: 0.8681, G loss: 10.9324\n",
      "[3612/8000] D loss: 1.0037, G loss: 6.6916\n",
      "[3972/8000] D loss: 0.7817, G loss: 6.5448\n",
      "[4332/8000] D loss: 1.2561, G loss: 4.1230\n",
      "[4692/8000] D loss: 1.0744, G loss: 2.9148\n",
      "[5052/8000] D loss: 0.6680, G loss: 3.4649\n",
      "[5412/8000] D loss: 1.0378, G loss: 2.3647\n",
      "[5772/8000] D loss: 0.8563, G loss: 6.3268\n",
      "[6132/8000] D loss: 0.9505, G loss: 4.1506\n",
      "[6492/8000] D loss: 0.8359, G loss: 4.7918\n",
      "[6852/8000] D loss: 0.8384, G loss: 9.3960\n",
      "[7212/8000] D loss: 0.9252, G loss: 8.0134\n",
      "[7572/8000] D loss: 0.7243, G loss: 5.2658\n",
      "[7932/8000] D loss: 0.8252, G loss: 4.0741\n",
      "train error: \n",
      " D loss: 0.847475, G loss: 6.836541, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.048284, G loss: 21.145929, D accuracy: 77.7%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7325, G loss: 10.2756\n",
      "[372/8000] D loss: 0.7206, G loss: 9.2300\n",
      "[732/8000] D loss: 0.6400, G loss: 12.2467\n",
      "[1092/8000] D loss: 0.8687, G loss: 6.5109\n",
      "[1452/8000] D loss: 1.0415, G loss: 3.7147\n",
      "[1812/8000] D loss: 0.9422, G loss: 4.3721\n",
      "[2172/8000] D loss: 0.8179, G loss: 7.8642\n",
      "[2532/8000] D loss: 1.0994, G loss: 4.3226\n",
      "[2892/8000] D loss: 0.6858, G loss: 11.7681\n",
      "[3252/8000] D loss: 0.9454, G loss: 5.2249\n",
      "[3612/8000] D loss: 0.6994, G loss: 10.3438\n",
      "[3972/8000] D loss: 0.6956, G loss: 8.9315\n",
      "[4332/8000] D loss: 0.3717, G loss: 8.3567\n",
      "[4692/8000] D loss: 0.7103, G loss: 10.6535\n",
      "[5052/8000] D loss: 1.2019, G loss: 5.6954\n",
      "[5412/8000] D loss: 0.9637, G loss: 9.1689\n",
      "[5772/8000] D loss: 0.9330, G loss: 5.8589\n",
      "[6132/8000] D loss: 0.7124, G loss: 9.1054\n",
      "[6492/8000] D loss: 0.5569, G loss: 5.9244\n",
      "[6852/8000] D loss: 0.6377, G loss: 6.8720\n",
      "[7212/8000] D loss: 0.8173, G loss: 7.2621\n",
      "[7572/8000] D loss: 0.6540, G loss: 11.1021\n",
      "[7932/8000] D loss: 1.0443, G loss: 4.4420\n",
      "train error: \n",
      " D loss: 0.853137, G loss: 5.939340, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.967373, G loss: 19.517467, D accuracy: 77.9%, cell accuracy: 98.2%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9291, G loss: 4.9836\n",
      "[372/8000] D loss: 1.0030, G loss: 7.6223\n",
      "[732/8000] D loss: 0.5841, G loss: 7.4676\n",
      "[1092/8000] D loss: 0.9833, G loss: 6.5388\n",
      "[1452/8000] D loss: 0.6310, G loss: 6.4710\n",
      "[1812/8000] D loss: 0.8539, G loss: 8.8229\n",
      "[2172/8000] D loss: 1.0376, G loss: 5.0640\n",
      "[2532/8000] D loss: 0.4096, G loss: 21.7092\n",
      "[2892/8000] D loss: 0.9521, G loss: 2.0786\n",
      "[3252/8000] D loss: 0.7841, G loss: 8.4832\n",
      "[3612/8000] D loss: 0.9372, G loss: 8.0361\n",
      "[3972/8000] D loss: 1.2809, G loss: 1.5308\n",
      "[4332/8000] D loss: 0.5461, G loss: 5.6897\n",
      "[4692/8000] D loss: 1.0558, G loss: 4.2251\n",
      "[5052/8000] D loss: 0.6864, G loss: 4.7431\n",
      "[5412/8000] D loss: 1.2757, G loss: 1.1607\n",
      "[5772/8000] D loss: 1.0737, G loss: 1.8087\n",
      "[6132/8000] D loss: 0.8984, G loss: 3.9586\n",
      "[6492/8000] D loss: 0.8132, G loss: 4.3075\n",
      "[6852/8000] D loss: 0.5986, G loss: 8.3162\n",
      "[7212/8000] D loss: 1.1696, G loss: 3.0700\n",
      "[7572/8000] D loss: 0.6805, G loss: 7.7780\n",
      "[7932/8000] D loss: 0.7663, G loss: 6.1413\n",
      "train error: \n",
      " D loss: 0.859779, G loss: 6.436964, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.024376, G loss: 20.457543, D accuracy: 78.8%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5312, G loss: 6.1797\n",
      "[372/8000] D loss: 0.8333, G loss: 3.5632\n",
      "[732/8000] D loss: 0.7577, G loss: 8.2968\n",
      "[1092/8000] D loss: 1.1080, G loss: 8.3362\n",
      "[1452/8000] D loss: 0.7980, G loss: 6.7295\n",
      "[1812/8000] D loss: 1.2177, G loss: 1.3721\n",
      "[2172/8000] D loss: 0.9564, G loss: 7.8597\n",
      "[2532/8000] D loss: 0.6987, G loss: 8.7402\n",
      "[2892/8000] D loss: 1.1609, G loss: 1.9603\n",
      "[3252/8000] D loss: 1.1601, G loss: 3.6653\n",
      "[3612/8000] D loss: 1.0027, G loss: 6.4484\n",
      "[3972/8000] D loss: 0.8967, G loss: 4.0820\n",
      "[4332/8000] D loss: 0.9064, G loss: 5.7789\n",
      "[4692/8000] D loss: 0.9491, G loss: 6.4014\n",
      "[5052/8000] D loss: 1.0672, G loss: 5.7900\n",
      "[5412/8000] D loss: 0.6284, G loss: 6.2864\n",
      "[5772/8000] D loss: 1.1566, G loss: 1.9046\n",
      "[6132/8000] D loss: 0.7481, G loss: 5.3473\n",
      "[6492/8000] D loss: 0.9220, G loss: 11.3802\n",
      "[6852/8000] D loss: 0.6228, G loss: 4.7855\n",
      "[7212/8000] D loss: 0.9137, G loss: 11.2661\n",
      "[7572/8000] D loss: 0.9305, G loss: 7.6275\n",
      "[7932/8000] D loss: 0.8197, G loss: 8.5099\n",
      "train error: \n",
      " D loss: 0.857610, G loss: 5.280918, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.976042, G loss: 18.438601, D accuracy: 78.8%, cell accuracy: 98.3%, board accuracy: 29.3% \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9328, G loss: 5.7115\n",
      "[372/8000] D loss: 0.7170, G loss: 6.5366\n",
      "[732/8000] D loss: 0.6917, G loss: 6.0284\n",
      "[1092/8000] D loss: 0.7150, G loss: 5.8709\n",
      "[1452/8000] D loss: 1.5239, G loss: 1.8382\n",
      "[1812/8000] D loss: 0.6387, G loss: 8.6399\n",
      "[2172/8000] D loss: 0.8822, G loss: 6.3217\n",
      "[2532/8000] D loss: 0.8708, G loss: 6.3555\n",
      "[2892/8000] D loss: 0.5798, G loss: 13.1742\n",
      "[3252/8000] D loss: 0.8792, G loss: 4.2349\n",
      "[3612/8000] D loss: 0.7938, G loss: 7.0956\n",
      "[3972/8000] D loss: 1.1705, G loss: 1.1963\n",
      "[4332/8000] D loss: 0.7087, G loss: 12.8387\n",
      "[4692/8000] D loss: 0.4663, G loss: 9.0130\n",
      "[5052/8000] D loss: 0.8968, G loss: 7.5905\n",
      "[5412/8000] D loss: 0.7487, G loss: 7.1319\n",
      "[5772/8000] D loss: 0.9435, G loss: 5.0796\n",
      "[6132/8000] D loss: 0.8336, G loss: 4.2262\n",
      "[6492/8000] D loss: 0.6959, G loss: 5.8083\n",
      "[6852/8000] D loss: 1.2440, G loss: 4.3958\n",
      "[7212/8000] D loss: 0.5868, G loss: 8.4753\n",
      "[7572/8000] D loss: 0.9379, G loss: 5.2560\n",
      "[7932/8000] D loss: 1.1367, G loss: 5.8480\n",
      "train error: \n",
      " D loss: 0.872282, G loss: 4.791867, D accuracy: 70.3%, cell accuracy: 98.8%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.972140, G loss: 16.213213, D accuracy: 78.9%, cell accuracy: 98.3%, board accuracy: 29.5% \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6918, G loss: 8.5962\n",
      "[372/8000] D loss: 0.9476, G loss: 5.4743\n",
      "[732/8000] D loss: 0.8091, G loss: 9.7986\n",
      "[1092/8000] D loss: 0.8788, G loss: 2.8853\n",
      "[1452/8000] D loss: 0.7233, G loss: 9.5477\n",
      "[1812/8000] D loss: 0.6409, G loss: 9.1030\n",
      "[2172/8000] D loss: 1.1564, G loss: 3.4080\n",
      "[2532/8000] D loss: 0.8694, G loss: 5.6205\n",
      "[2892/8000] D loss: 0.9663, G loss: 2.4714\n",
      "[3252/8000] D loss: 0.9418, G loss: 9.7080\n",
      "[3612/8000] D loss: 0.3632, G loss: 13.4675\n",
      "[3972/8000] D loss: 1.0500, G loss: 6.7794\n",
      "[4332/8000] D loss: 0.4126, G loss: 9.0989\n",
      "[4692/8000] D loss: 0.8035, G loss: 7.4363\n",
      "[5052/8000] D loss: 0.6529, G loss: 4.3502\n",
      "[5412/8000] D loss: 0.8690, G loss: 7.2174\n",
      "[5772/8000] D loss: 0.7181, G loss: 4.7965\n",
      "[6132/8000] D loss: 0.9212, G loss: 7.3050\n",
      "[6492/8000] D loss: 0.8340, G loss: 5.5035\n",
      "[6852/8000] D loss: 0.8128, G loss: 4.2273\n",
      "[7212/8000] D loss: 0.7843, G loss: 6.3425\n",
      "[7572/8000] D loss: 1.1290, G loss: 4.5825\n",
      "[7932/8000] D loss: 0.9016, G loss: 7.1182\n",
      "train error: \n",
      " D loss: 0.875157, G loss: 5.378657, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.941250, G loss: 18.340656, D accuracy: 79.7%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8575, G loss: 3.2134\n",
      "[372/8000] D loss: 0.7011, G loss: 4.4493\n",
      "[732/8000] D loss: 0.9153, G loss: 9.6768\n",
      "[1092/8000] D loss: 1.1047, G loss: 4.2483\n",
      "[1452/8000] D loss: 0.5908, G loss: 8.7016\n",
      "[1812/8000] D loss: 0.6542, G loss: 6.0485\n",
      "[2172/8000] D loss: 0.9058, G loss: 5.6801\n",
      "[2532/8000] D loss: 0.6678, G loss: 10.2792\n",
      "[2892/8000] D loss: 0.8608, G loss: 9.9904\n",
      "[3252/8000] D loss: 0.9472, G loss: 9.0516\n",
      "[3612/8000] D loss: 1.0511, G loss: 3.0371\n",
      "[3972/8000] D loss: 0.8986, G loss: 4.1972\n",
      "[4332/8000] D loss: 0.9815, G loss: 7.9587\n",
      "[4692/8000] D loss: 0.8212, G loss: 8.1340\n",
      "[5052/8000] D loss: 0.6817, G loss: 16.3187\n",
      "[5412/8000] D loss: 1.1892, G loss: 2.0680\n",
      "[5772/8000] D loss: 0.9085, G loss: 5.4875\n",
      "[6132/8000] D loss: 1.1035, G loss: 1.8429\n",
      "[6492/8000] D loss: 0.7045, G loss: 5.7294\n",
      "[6852/8000] D loss: 1.0114, G loss: 10.8898\n",
      "[7212/8000] D loss: 0.7904, G loss: 7.2098\n",
      "[7572/8000] D loss: 1.0419, G loss: 1.9784\n",
      "[7932/8000] D loss: 0.9086, G loss: 7.5966\n",
      "train error: \n",
      " D loss: 0.853623, G loss: 7.664712, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.149704, G loss: 23.666346, D accuracy: 76.5%, cell accuracy: 98.3%, board accuracy: 29.3% \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7854, G loss: 6.7383\n",
      "[372/8000] D loss: 0.7082, G loss: 10.8525\n",
      "[732/8000] D loss: 1.0469, G loss: 4.2005\n",
      "[1092/8000] D loss: 1.1780, G loss: 2.4173\n",
      "[1452/8000] D loss: 1.0953, G loss: 1.9884\n",
      "[1812/8000] D loss: 0.8161, G loss: 9.4105\n",
      "[2172/8000] D loss: 0.7092, G loss: 11.9366\n",
      "[2532/8000] D loss: 0.9275, G loss: 5.4702\n",
      "[2892/8000] D loss: 0.5678, G loss: 14.8909\n",
      "[3252/8000] D loss: 1.0719, G loss: 5.4652\n",
      "[3612/8000] D loss: 0.6963, G loss: 7.3713\n",
      "[3972/8000] D loss: 0.6985, G loss: 6.5125\n",
      "[4332/8000] D loss: 0.8174, G loss: 8.1200\n",
      "[4692/8000] D loss: 1.0133, G loss: 1.9901\n",
      "[5052/8000] D loss: 0.6926, G loss: 6.4978\n",
      "[5412/8000] D loss: 1.1927, G loss: 3.1644\n",
      "[5772/8000] D loss: 0.8283, G loss: 5.6193\n",
      "[6132/8000] D loss: 0.8566, G loss: 6.4829\n",
      "[6492/8000] D loss: 0.8304, G loss: 3.7929\n",
      "[6852/8000] D loss: 0.5854, G loss: 11.3959\n",
      "[7212/8000] D loss: 0.9006, G loss: 8.4964\n",
      "[7572/8000] D loss: 1.1523, G loss: 4.3559\n",
      "[7932/8000] D loss: 1.0509, G loss: 1.9562\n",
      "train error: \n",
      " D loss: 0.861648, G loss: 5.608794, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.914216, G loss: 18.561756, D accuracy: 80.0%, cell accuracy: 98.3%, board accuracy: 29.7% \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5282, G loss: 7.7989\n",
      "[372/8000] D loss: 0.8131, G loss: 6.8669\n",
      "[732/8000] D loss: 1.1116, G loss: 3.4843\n",
      "[1092/8000] D loss: 1.1699, G loss: 1.4789\n",
      "[1452/8000] D loss: 1.3349, G loss: 1.0651\n",
      "[1812/8000] D loss: 0.7810, G loss: 7.1538\n",
      "[2172/8000] D loss: 0.6505, G loss: 5.0011\n",
      "[2532/8000] D loss: 0.8289, G loss: 11.8090\n",
      "[2892/8000] D loss: 0.7592, G loss: 8.7577\n",
      "[3252/8000] D loss: 0.9131, G loss: 5.6788\n",
      "[3612/8000] D loss: 0.7967, G loss: 5.9030\n",
      "[3972/8000] D loss: 1.0710, G loss: 3.3007\n",
      "[4332/8000] D loss: 0.7003, G loss: 9.7057\n",
      "[4692/8000] D loss: 0.7313, G loss: 6.4195\n",
      "[5052/8000] D loss: 1.0297, G loss: 2.9046\n",
      "[5412/8000] D loss: 0.9486, G loss: 7.2496\n",
      "[5772/8000] D loss: 1.2278, G loss: 2.0388\n",
      "[6132/8000] D loss: 0.8367, G loss: 5.3163\n",
      "[6492/8000] D loss: 1.0255, G loss: 14.8782\n",
      "[6852/8000] D loss: 0.9569, G loss: 7.3823\n",
      "[7212/8000] D loss: 1.0547, G loss: 2.2208\n",
      "[7572/8000] D loss: 0.5080, G loss: 19.4311\n",
      "[7932/8000] D loss: 1.0497, G loss: 1.7982\n",
      "train error: \n",
      " D loss: 0.860117, G loss: 7.653447, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.170713, G loss: 22.850499, D accuracy: 74.7%, cell accuracy: 98.3%, board accuracy: 29.4% \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8910, G loss: 7.7315\n",
      "[372/8000] D loss: 0.8384, G loss: 11.0424\n",
      "[732/8000] D loss: 0.5416, G loss: 5.4346\n",
      "[1092/8000] D loss: 1.0339, G loss: 8.2597\n",
      "[1452/8000] D loss: 0.7006, G loss: 12.3602\n",
      "[1812/8000] D loss: 0.8170, G loss: 11.3106\n",
      "[2172/8000] D loss: 0.5461, G loss: 7.0421\n",
      "[2532/8000] D loss: 0.9367, G loss: 3.5460\n",
      "[2892/8000] D loss: 0.8741, G loss: 3.8890\n",
      "[3252/8000] D loss: 1.1508, G loss: 5.1917\n",
      "[3612/8000] D loss: 0.8999, G loss: 6.8890\n",
      "[3972/8000] D loss: 0.8910, G loss: 12.2545\n",
      "[4332/8000] D loss: 1.0807, G loss: 5.1418\n",
      "[4692/8000] D loss: 0.7424, G loss: 8.6070\n",
      "[5052/8000] D loss: 0.7980, G loss: 10.1187\n",
      "[5412/8000] D loss: 0.7226, G loss: 7.9115\n",
      "[5772/8000] D loss: 0.8202, G loss: 6.2365\n",
      "[6132/8000] D loss: 1.0947, G loss: 4.0288\n",
      "[6492/8000] D loss: 0.6125, G loss: 21.3278\n",
      "[6852/8000] D loss: 0.8941, G loss: 2.4897\n",
      "[7212/8000] D loss: 0.9325, G loss: 8.1263\n",
      "[7572/8000] D loss: 0.8425, G loss: 6.3515\n",
      "[7932/8000] D loss: 1.0381, G loss: 3.5360\n",
      "train error: \n",
      " D loss: 0.837823, G loss: 6.338866, D accuracy: 72.5%, cell accuracy: 98.8%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.908275, G loss: 20.771774, D accuracy: 79.4%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4183, G loss: 11.4130\n",
      "[372/8000] D loss: 0.8096, G loss: 9.5910\n",
      "[732/8000] D loss: 0.5053, G loss: 8.6317\n",
      "[1092/8000] D loss: 0.9417, G loss: 6.6387\n",
      "[1452/8000] D loss: 0.6897, G loss: 5.7450\n",
      "[1812/8000] D loss: 1.0337, G loss: 4.7887\n",
      "[2172/8000] D loss: 0.9968, G loss: 2.1360\n",
      "[2532/8000] D loss: 0.5793, G loss: 14.3182\n",
      "[2892/8000] D loss: 0.6472, G loss: 10.5414\n",
      "[3252/8000] D loss: 0.7136, G loss: 8.1198\n",
      "[3612/8000] D loss: 0.6831, G loss: 7.1214\n",
      "[3972/8000] D loss: 0.6084, G loss: 13.1144\n",
      "[4332/8000] D loss: 0.9031, G loss: 7.1878\n",
      "[4692/8000] D loss: 0.5663, G loss: 6.4698\n",
      "[5052/8000] D loss: 1.0276, G loss: 6.0924\n",
      "[5412/8000] D loss: 0.8429, G loss: 3.8656\n",
      "[5772/8000] D loss: 1.0421, G loss: 8.2775\n",
      "[6132/8000] D loss: 0.8113, G loss: 3.4974\n",
      "[6492/8000] D loss: 0.5920, G loss: 6.6844\n",
      "[6852/8000] D loss: 0.8493, G loss: 5.2538\n",
      "[7212/8000] D loss: 0.9215, G loss: 5.9376\n",
      "[7572/8000] D loss: 1.0156, G loss: 4.2946\n",
      "[7932/8000] D loss: 0.9388, G loss: 6.4180\n",
      "train error: \n",
      " D loss: 0.859759, G loss: 7.059449, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.086412, G loss: 20.407358, D accuracy: 75.5%, cell accuracy: 98.3%, board accuracy: 30.5% \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8588, G loss: 10.5342\n",
      "[372/8000] D loss: 0.8147, G loss: 5.5291\n",
      "[732/8000] D loss: 0.7477, G loss: 7.4783\n",
      "[1092/8000] D loss: 0.8107, G loss: 5.8342\n",
      "[1452/8000] D loss: 1.0932, G loss: 6.7180\n",
      "[1812/8000] D loss: 0.9724, G loss: 4.5082\n",
      "[2172/8000] D loss: 0.7047, G loss: 14.1079\n",
      "[2532/8000] D loss: 0.5020, G loss: 6.9286\n",
      "[2892/8000] D loss: 0.9314, G loss: 6.6854\n",
      "[3252/8000] D loss: 1.0484, G loss: 3.5489\n",
      "[3612/8000] D loss: 0.5244, G loss: 15.7120\n",
      "[3972/8000] D loss: 0.5380, G loss: 12.9968\n",
      "[4332/8000] D loss: 0.7002, G loss: 7.4024\n",
      "[4692/8000] D loss: 1.1489, G loss: 3.4843\n",
      "[5052/8000] D loss: 0.7667, G loss: 5.0789\n",
      "[5412/8000] D loss: 1.0695, G loss: 1.4360\n",
      "[5772/8000] D loss: 0.4813, G loss: 13.2564\n",
      "[6132/8000] D loss: 1.1125, G loss: 2.5067\n",
      "[6492/8000] D loss: 0.7213, G loss: 8.4122\n",
      "[6852/8000] D loss: 0.9525, G loss: 1.6246\n",
      "[7212/8000] D loss: 0.6679, G loss: 17.1577\n",
      "[7572/8000] D loss: 1.2577, G loss: 1.1966\n",
      "[7932/8000] D loss: 0.9725, G loss: 7.7872\n",
      "train error: \n",
      " D loss: 0.851280, G loss: 6.908378, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.945576, G loss: 22.174838, D accuracy: 80.9%, cell accuracy: 98.3%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6603, G loss: 7.2331\n",
      "[372/8000] D loss: 0.9858, G loss: 2.5157\n",
      "[732/8000] D loss: 0.9170, G loss: 3.7041\n",
      "[1092/8000] D loss: 1.0975, G loss: 4.0929\n",
      "[1452/8000] D loss: 0.9054, G loss: 10.5247\n",
      "[1812/8000] D loss: 1.0748, G loss: 3.5680\n",
      "[2172/8000] D loss: 0.8830, G loss: 9.2249\n",
      "[2532/8000] D loss: 0.5853, G loss: 18.1461\n",
      "[2892/8000] D loss: 0.5963, G loss: 5.6432\n",
      "[3252/8000] D loss: 0.6896, G loss: 5.6329\n",
      "[3612/8000] D loss: 0.6743, G loss: 5.9622\n",
      "[3972/8000] D loss: 0.9119, G loss: 8.3700\n",
      "[4332/8000] D loss: 0.5848, G loss: 7.9735\n",
      "[4692/8000] D loss: 0.8209, G loss: 6.5086\n",
      "[5052/8000] D loss: 1.0208, G loss: 6.8768\n",
      "[5412/8000] D loss: 0.8657, G loss: 9.1784\n",
      "[5772/8000] D loss: 0.6465, G loss: 6.3049\n",
      "[6132/8000] D loss: 0.7052, G loss: 8.9156\n",
      "[6492/8000] D loss: 0.8128, G loss: 6.3548\n",
      "[6852/8000] D loss: 0.9965, G loss: 4.2701\n",
      "[7212/8000] D loss: 1.0957, G loss: 5.1027\n",
      "[7572/8000] D loss: 0.9170, G loss: 4.3142\n",
      "[7932/8000] D loss: 0.6961, G loss: 7.0652\n",
      "train error: \n",
      " D loss: 0.848858, G loss: 6.765311, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.969602, G loss: 21.314473, D accuracy: 78.2%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2316, G loss: 1.8059\n",
      "[372/8000] D loss: 1.1481, G loss: 3.9908\n",
      "[732/8000] D loss: 0.8124, G loss: 9.4903\n",
      "[1092/8000] D loss: 0.8212, G loss: 4.9993\n",
      "[1452/8000] D loss: 1.2205, G loss: 3.7612\n",
      "[1812/8000] D loss: 0.8243, G loss: 5.8109\n",
      "[2172/8000] D loss: 0.5413, G loss: 5.7491\n",
      "[2532/8000] D loss: 0.6721, G loss: 9.2000\n",
      "[2892/8000] D loss: 0.7989, G loss: 6.0920\n",
      "[3252/8000] D loss: 0.6541, G loss: 10.0641\n",
      "[3612/8000] D loss: 0.8220, G loss: 11.8500\n",
      "[3972/8000] D loss: 0.8998, G loss: 4.6611\n",
      "[4332/8000] D loss: 0.6509, G loss: 9.6461\n",
      "[4692/8000] D loss: 0.7729, G loss: 6.1218\n",
      "[5052/8000] D loss: 0.9624, G loss: 7.9570\n",
      "[5412/8000] D loss: 1.0141, G loss: 4.7524\n",
      "[5772/8000] D loss: 0.6207, G loss: 8.1429\n",
      "[6132/8000] D loss: 1.0138, G loss: 2.3944\n",
      "[6492/8000] D loss: 0.9075, G loss: 7.0915\n",
      "[6852/8000] D loss: 0.5817, G loss: 21.7360\n",
      "[7212/8000] D loss: 0.7006, G loss: 17.3720\n",
      "[7572/8000] D loss: 0.5885, G loss: 14.9599\n",
      "[7932/8000] D loss: 0.8093, G loss: 9.9928\n",
      "train error: \n",
      " D loss: 0.847201, G loss: 6.474670, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.976976, G loss: 20.109513, D accuracy: 78.1%, cell accuracy: 98.3%, board accuracy: 30.2% \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2993, G loss: 1.7600\n",
      "[372/8000] D loss: 0.9208, G loss: 4.7990\n",
      "[732/8000] D loss: 0.5274, G loss: 11.6690\n",
      "[1092/8000] D loss: 1.0723, G loss: 8.8738\n",
      "[1452/8000] D loss: 0.8916, G loss: 4.9231\n",
      "[1812/8000] D loss: 1.2848, G loss: 2.4265\n",
      "[2172/8000] D loss: 0.6949, G loss: 10.2613\n",
      "[2532/8000] D loss: 0.6980, G loss: 16.1348\n",
      "[2892/8000] D loss: 0.8108, G loss: 8.9197\n",
      "[3252/8000] D loss: 0.9257, G loss: 11.0693\n",
      "[3612/8000] D loss: 0.8496, G loss: 7.5548\n",
      "[3972/8000] D loss: 1.2222, G loss: 3.7909\n",
      "[4332/8000] D loss: 0.4681, G loss: 18.1313\n",
      "[4692/8000] D loss: 1.0872, G loss: 5.0104\n",
      "[5052/8000] D loss: 0.5815, G loss: 6.1999\n",
      "[5412/8000] D loss: 0.8001, G loss: 10.7514\n",
      "[5772/8000] D loss: 0.2474, G loss: 19.1948\n",
      "[6132/8000] D loss: 0.9737, G loss: 3.2563\n",
      "[6492/8000] D loss: 0.7727, G loss: 2.8631\n",
      "[6852/8000] D loss: 0.8155, G loss: 7.1725\n",
      "[7212/8000] D loss: 0.5980, G loss: 3.9511\n",
      "[7572/8000] D loss: 0.9320, G loss: 4.0557\n",
      "[7932/8000] D loss: 0.6983, G loss: 3.4936\n",
      "train error: \n",
      " D loss: 0.852917, G loss: 5.933346, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.002282, G loss: 18.664721, D accuracy: 76.7%, cell accuracy: 98.3%, board accuracy: 30.1% \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9264, G loss: 6.3552\n",
      "[372/8000] D loss: 0.7064, G loss: 4.4400\n",
      "[732/8000] D loss: 0.9831, G loss: 2.7063\n",
      "[1092/8000] D loss: 0.8046, G loss: 12.1502\n",
      "[1452/8000] D loss: 0.9547, G loss: 4.5939\n",
      "[1812/8000] D loss: 0.8495, G loss: 8.4755\n",
      "[2172/8000] D loss: 0.8254, G loss: 6.7975\n",
      "[2532/8000] D loss: 1.1168, G loss: 1.2816\n",
      "[2892/8000] D loss: 0.8146, G loss: 6.2363\n",
      "[3252/8000] D loss: 0.7211, G loss: 4.4846\n",
      "[3612/8000] D loss: 0.9765, G loss: 2.6427\n",
      "[3972/8000] D loss: 0.6679, G loss: 12.8349\n",
      "[4332/8000] D loss: 0.3727, G loss: 7.1878\n",
      "[4692/8000] D loss: 0.9925, G loss: 4.4385\n",
      "[5052/8000] D loss: 0.9053, G loss: 6.4431\n",
      "[5412/8000] D loss: 0.8177, G loss: 6.3793\n",
      "[5772/8000] D loss: 0.6028, G loss: 11.8131\n",
      "[6132/8000] D loss: 0.5446, G loss: 8.1194\n",
      "[6492/8000] D loss: 0.8791, G loss: 8.2633\n",
      "[6852/8000] D loss: 0.7437, G loss: 7.1613\n",
      "[7212/8000] D loss: 1.0078, G loss: 5.2510\n",
      "[7572/8000] D loss: 0.7012, G loss: 6.4001\n",
      "[7932/8000] D loss: 0.9318, G loss: 4.7969\n",
      "train error: \n",
      " D loss: 0.850879, G loss: 7.203605, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.024506, G loss: 21.822904, D accuracy: 76.2%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8987, G loss: 8.1925\n",
      "[372/8000] D loss: 0.5659, G loss: 6.2190\n",
      "[732/8000] D loss: 0.8328, G loss: 7.3958\n",
      "[1092/8000] D loss: 0.9232, G loss: 5.0038\n",
      "[1452/8000] D loss: 1.0150, G loss: 6.6090\n",
      "[1812/8000] D loss: 0.8983, G loss: 6.9030\n",
      "[2172/8000] D loss: 0.8175, G loss: 3.3768\n",
      "[2532/8000] D loss: 0.7681, G loss: 5.7748\n",
      "[2892/8000] D loss: 0.8399, G loss: 6.8085\n",
      "[3252/8000] D loss: 0.7090, G loss: 13.6454\n",
      "[3612/8000] D loss: 0.6868, G loss: 9.9809\n",
      "[3972/8000] D loss: 0.6067, G loss: 11.1238\n",
      "[4332/8000] D loss: 0.9398, G loss: 2.6957\n",
      "[4692/8000] D loss: 0.3544, G loss: 11.4820\n",
      "[5052/8000] D loss: 0.6163, G loss: 7.0590\n",
      "[5412/8000] D loss: 0.5426, G loss: 10.0395\n",
      "[5772/8000] D loss: 0.7029, G loss: 15.6681\n",
      "[6132/8000] D loss: 0.7042, G loss: 6.1440\n",
      "[6492/8000] D loss: 0.7303, G loss: 11.3138\n",
      "[6852/8000] D loss: 0.5256, G loss: 18.3256\n",
      "[7212/8000] D loss: 0.7359, G loss: 10.5531\n",
      "[7572/8000] D loss: 1.0559, G loss: 1.3792\n",
      "[7932/8000] D loss: 0.8148, G loss: 3.8272\n",
      "train error: \n",
      " D loss: 0.852389, G loss: 6.422520, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.962354, G loss: 20.343606, D accuracy: 80.3%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3503, G loss: 18.9979\n",
      "[372/8000] D loss: 0.6052, G loss: 12.8318\n",
      "[732/8000] D loss: 0.8540, G loss: 2.5078\n",
      "[1092/8000] D loss: 0.8185, G loss: 3.4691\n",
      "[1452/8000] D loss: 0.9687, G loss: 2.6035\n",
      "[1812/8000] D loss: 0.7011, G loss: 13.3298\n",
      "[2172/8000] D loss: 0.6141, G loss: 6.2951\n",
      "[2532/8000] D loss: 0.7132, G loss: 7.0331\n",
      "[2892/8000] D loss: 1.0991, G loss: 4.3617\n",
      "[3252/8000] D loss: 0.8747, G loss: 18.3320\n",
      "[3612/8000] D loss: 0.7957, G loss: 8.5877\n",
      "[3972/8000] D loss: 0.7186, G loss: 5.1663\n",
      "[4332/8000] D loss: 0.3491, G loss: 10.9265\n",
      "[4692/8000] D loss: 1.1273, G loss: 5.1832\n",
      "[5052/8000] D loss: 0.6389, G loss: 9.2615\n",
      "[5412/8000] D loss: 1.0214, G loss: 3.1113\n",
      "[5772/8000] D loss: 0.8466, G loss: 4.3625\n",
      "[6132/8000] D loss: 1.0780, G loss: 6.0319\n",
      "[6492/8000] D loss: 1.2132, G loss: 6.9110\n",
      "[6852/8000] D loss: 1.0731, G loss: 3.4747\n",
      "[7212/8000] D loss: 0.9468, G loss: 4.9693\n",
      "[7572/8000] D loss: 0.7017, G loss: 4.6998\n",
      "[7932/8000] D loss: 0.8132, G loss: 8.0252\n",
      "train error: \n",
      " D loss: 0.849493, G loss: 6.789887, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.988030, G loss: 21.568429, D accuracy: 79.6%, cell accuracy: 98.3%, board accuracy: 29.6% \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0423, G loss: 2.9146\n",
      "[372/8000] D loss: 0.9238, G loss: 13.4720\n",
      "[732/8000] D loss: 0.9503, G loss: 2.1363\n",
      "[1092/8000] D loss: 1.3084, G loss: 1.7209\n",
      "[1452/8000] D loss: 1.1895, G loss: 6.7876\n",
      "[1812/8000] D loss: 0.6623, G loss: 10.0359\n",
      "[2172/8000] D loss: 0.8129, G loss: 10.8174\n",
      "[2532/8000] D loss: 0.8376, G loss: 13.0282\n",
      "[2892/8000] D loss: 0.9307, G loss: 7.8961\n",
      "[3252/8000] D loss: 1.1521, G loss: 3.7102\n",
      "[3612/8000] D loss: 0.6442, G loss: 15.0983\n",
      "[3972/8000] D loss: 1.1198, G loss: 1.6268\n",
      "[4332/8000] D loss: 1.1759, G loss: 6.2089\n",
      "[4692/8000] D loss: 0.7679, G loss: 7.9376\n",
      "[5052/8000] D loss: 1.1525, G loss: 1.6283\n",
      "[5412/8000] D loss: 0.8864, G loss: 3.0131\n",
      "[5772/8000] D loss: 0.6962, G loss: 7.9707\n",
      "[6132/8000] D loss: 0.9703, G loss: 5.7165\n",
      "[6492/8000] D loss: 0.9063, G loss: 6.6139\n",
      "[6852/8000] D loss: 0.7162, G loss: 4.8964\n",
      "[7212/8000] D loss: 0.8100, G loss: 3.5349\n",
      "[7572/8000] D loss: 0.8916, G loss: 3.8006\n",
      "[7932/8000] D loss: 0.9047, G loss: 3.7550\n",
      "train error: \n",
      " D loss: 0.853132, G loss: 6.754646, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.081925, G loss: 21.168028, D accuracy: 75.7%, cell accuracy: 98.3%, board accuracy: 30.5% \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7152, G loss: 4.5867\n",
      "[372/8000] D loss: 0.8154, G loss: 7.5359\n",
      "[732/8000] D loss: 0.6000, G loss: 6.5352\n",
      "[1092/8000] D loss: 0.9308, G loss: 8.0658\n",
      "[1452/8000] D loss: 0.7253, G loss: 5.1058\n",
      "[1812/8000] D loss: 0.9006, G loss: 2.5546\n",
      "[2172/8000] D loss: 0.5812, G loss: 10.1076\n",
      "[2532/8000] D loss: 0.7051, G loss: 7.0442\n",
      "[2892/8000] D loss: 0.9872, G loss: 6.4172\n",
      "[3252/8000] D loss: 0.7242, G loss: 4.7333\n",
      "[3612/8000] D loss: 0.7467, G loss: 12.5200\n",
      "[3972/8000] D loss: 0.6980, G loss: 9.1870\n",
      "[4332/8000] D loss: 0.5797, G loss: 12.4078\n",
      "[4692/8000] D loss: 0.9851, G loss: 3.5354\n",
      "[5052/8000] D loss: 0.6989, G loss: 12.1998\n",
      "[5412/8000] D loss: 0.9417, G loss: 7.5635\n",
      "[5772/8000] D loss: 0.8522, G loss: 7.4782\n",
      "[6132/8000] D loss: 0.8517, G loss: 3.9117\n",
      "[6492/8000] D loss: 1.0180, G loss: 3.5636\n",
      "[6852/8000] D loss: 0.8182, G loss: 4.4532\n",
      "[7212/8000] D loss: 0.8234, G loss: 8.4357\n",
      "[7572/8000] D loss: 0.7728, G loss: 8.8884\n",
      "[7932/8000] D loss: 1.0188, G loss: 2.4807\n",
      "train error: \n",
      " D loss: 0.853843, G loss: 7.015038, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.035005, G loss: 21.915610, D accuracy: 76.9%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5888, G loss: 9.7144\n",
      "[372/8000] D loss: 1.1296, G loss: 3.2563\n",
      "[732/8000] D loss: 0.9548, G loss: 5.4317\n",
      "[1092/8000] D loss: 0.8935, G loss: 5.7924\n",
      "[1452/8000] D loss: 0.9191, G loss: 5.7460\n",
      "[1812/8000] D loss: 0.9193, G loss: 3.9821\n",
      "[2172/8000] D loss: 0.9506, G loss: 4.8437\n",
      "[2532/8000] D loss: 1.0547, G loss: 2.2725\n",
      "[2892/8000] D loss: 0.8081, G loss: 9.8372\n",
      "[3252/8000] D loss: 0.7534, G loss: 5.1016\n",
      "[3612/8000] D loss: 0.8015, G loss: 5.8669\n",
      "[3972/8000] D loss: 0.8836, G loss: 7.8350\n",
      "[4332/8000] D loss: 0.3608, G loss: 12.8901\n",
      "[4692/8000] D loss: 1.0190, G loss: 5.6608\n",
      "[5052/8000] D loss: 0.5641, G loss: 10.5429\n",
      "[5412/8000] D loss: 0.5107, G loss: 12.4709\n",
      "[5772/8000] D loss: 0.8125, G loss: 5.4279\n",
      "[6132/8000] D loss: 1.0331, G loss: 3.2325\n",
      "[6492/8000] D loss: 0.6074, G loss: 4.9546\n",
      "[6852/8000] D loss: 1.0783, G loss: 7.8549\n",
      "[7212/8000] D loss: 0.7014, G loss: 11.4064\n",
      "[7572/8000] D loss: 0.7219, G loss: 6.3517\n",
      "[7932/8000] D loss: 0.7382, G loss: 3.3223\n",
      "train error: \n",
      " D loss: 0.860225, G loss: 6.725591, D accuracy: 70.4%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.992179, G loss: 19.997552, D accuracy: 78.7%, cell accuracy: 98.3%, board accuracy: 30.2% \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8963, G loss: 5.9292\n",
      "[372/8000] D loss: 0.7834, G loss: 6.2344\n",
      "[732/8000] D loss: 0.9389, G loss: 5.0286\n",
      "[1092/8000] D loss: 0.8217, G loss: 7.9971\n",
      "[1452/8000] D loss: 1.2641, G loss: 3.8015\n",
      "[1812/8000] D loss: 1.1709, G loss: 1.4108\n",
      "[2172/8000] D loss: 0.6480, G loss: 9.3378\n",
      "[2532/8000] D loss: 0.6983, G loss: 7.1297\n",
      "[2892/8000] D loss: 0.7195, G loss: 17.2598\n",
      "[3252/8000] D loss: 0.7131, G loss: 7.7176\n",
      "[3612/8000] D loss: 0.8281, G loss: 6.9736\n",
      "[3972/8000] D loss: 0.6332, G loss: 10.0840\n",
      "[4332/8000] D loss: 0.9917, G loss: 3.8679\n",
      "[4692/8000] D loss: 0.7487, G loss: 3.8812\n",
      "[5052/8000] D loss: 0.5841, G loss: 6.3726\n",
      "[5412/8000] D loss: 0.2252, G loss: 11.7520\n",
      "[5772/8000] D loss: 0.8141, G loss: 5.7177\n",
      "[6132/8000] D loss: 1.0198, G loss: 4.1698\n",
      "[6492/8000] D loss: 0.7249, G loss: 12.0747\n",
      "[6852/8000] D loss: 0.9426, G loss: 4.3066\n",
      "[7212/8000] D loss: 1.1052, G loss: 2.4065\n",
      "[7572/8000] D loss: 0.8157, G loss: 11.1957\n",
      "[7932/8000] D loss: 0.8896, G loss: 5.6211\n",
      "train error: \n",
      " D loss: 0.852339, G loss: 6.336684, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.995707, G loss: 19.917162, D accuracy: 79.4%, cell accuracy: 98.3%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1330, G loss: 7.4442\n",
      "[372/8000] D loss: 0.9569, G loss: 8.3713\n",
      "[732/8000] D loss: 1.2764, G loss: 1.0721\n",
      "[1092/8000] D loss: 0.7024, G loss: 4.1419\n",
      "[1452/8000] D loss: 0.8558, G loss: 11.7245\n",
      "[1812/8000] D loss: 0.9335, G loss: 3.3533\n",
      "[2172/8000] D loss: 0.7096, G loss: 6.4454\n",
      "[2532/8000] D loss: 0.6395, G loss: 5.6545\n",
      "[2892/8000] D loss: 0.6854, G loss: 10.3115\n",
      "[3252/8000] D loss: 0.7056, G loss: 10.7160\n",
      "[3612/8000] D loss: 0.6209, G loss: 10.9384\n",
      "[3972/8000] D loss: 0.8530, G loss: 5.9285\n",
      "[4332/8000] D loss: 0.9071, G loss: 6.8688\n",
      "[4692/8000] D loss: 0.6304, G loss: 6.1482\n",
      "[5052/8000] D loss: 0.8939, G loss: 7.6093\n",
      "[5412/8000] D loss: 0.9803, G loss: 11.1939\n",
      "[5772/8000] D loss: 0.7795, G loss: 6.0793\n",
      "[6132/8000] D loss: 0.6333, G loss: 3.8693\n",
      "[6492/8000] D loss: 0.7099, G loss: 12.2949\n",
      "[6852/8000] D loss: 0.7886, G loss: 5.7405\n",
      "[7212/8000] D loss: 0.5806, G loss: 6.2741\n",
      "[7572/8000] D loss: 0.9349, G loss: 6.3033\n",
      "[7932/8000] D loss: 0.7156, G loss: 10.8980\n",
      "train error: \n",
      " D loss: 0.863897, G loss: 6.033955, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.927351, G loss: 19.876573, D accuracy: 80.5%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6124, G loss: 6.1308\n",
      "[372/8000] D loss: 0.8795, G loss: 8.0667\n",
      "[732/8000] D loss: 0.4999, G loss: 6.9148\n",
      "[1092/8000] D loss: 0.9745, G loss: 7.2911\n",
      "[1452/8000] D loss: 0.6976, G loss: 13.3954\n",
      "[1812/8000] D loss: 0.6979, G loss: 3.8178\n",
      "[2172/8000] D loss: 0.7311, G loss: 4.2802\n",
      "[2532/8000] D loss: 0.6237, G loss: 7.2925\n",
      "[2892/8000] D loss: 0.8387, G loss: 5.2870\n",
      "[3252/8000] D loss: 0.9505, G loss: 6.9590\n",
      "[3612/8000] D loss: 0.5794, G loss: 9.7813\n",
      "[3972/8000] D loss: 0.6947, G loss: 8.9074\n",
      "[4332/8000] D loss: 0.6721, G loss: 11.1321\n",
      "[4692/8000] D loss: 0.5565, G loss: 18.1693\n",
      "[5052/8000] D loss: 0.8750, G loss: 10.2498\n",
      "[5412/8000] D loss: 0.7943, G loss: 6.9758\n",
      "[5772/8000] D loss: 0.6126, G loss: 7.2817\n",
      "[6132/8000] D loss: 1.1763, G loss: 3.1760\n",
      "[6492/8000] D loss: 0.9145, G loss: 3.0724\n",
      "[6852/8000] D loss: 0.4665, G loss: 9.6789\n",
      "[7212/8000] D loss: 0.9863, G loss: 5.2589\n",
      "[7572/8000] D loss: 0.8607, G loss: 4.6490\n",
      "[7932/8000] D loss: 0.7180, G loss: 5.6466\n",
      "train error: \n",
      " D loss: 0.866802, G loss: 6.148006, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.062363, G loss: 19.552289, D accuracy: 78.9%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0821, G loss: 11.6098\n",
      "[372/8000] D loss: 0.8471, G loss: 3.4623\n",
      "[732/8000] D loss: 0.4771, G loss: 14.1694\n",
      "[1092/8000] D loss: 0.9245, G loss: 4.4793\n",
      "[1452/8000] D loss: 0.8443, G loss: 8.6771\n",
      "[1812/8000] D loss: 0.7079, G loss: 12.6616\n",
      "[2172/8000] D loss: 0.6976, G loss: 15.3011\n",
      "[2532/8000] D loss: 0.5893, G loss: 11.0944\n",
      "[2892/8000] D loss: 0.8057, G loss: 10.5144\n",
      "[3252/8000] D loss: 0.9239, G loss: 8.8216\n",
      "[3612/8000] D loss: 0.9312, G loss: 5.9354\n",
      "[3972/8000] D loss: 1.0121, G loss: 3.1468\n",
      "[4332/8000] D loss: 0.8156, G loss: 11.7717\n",
      "[4692/8000] D loss: 1.0817, G loss: 3.0978\n",
      "[5052/8000] D loss: 0.6558, G loss: 7.0036\n",
      "[5412/8000] D loss: 0.9251, G loss: 4.1923\n",
      "[5772/8000] D loss: 0.9443, G loss: 2.9311\n",
      "[6132/8000] D loss: 0.9855, G loss: 3.5438\n",
      "[6492/8000] D loss: 1.2974, G loss: 1.2499\n",
      "[6852/8000] D loss: 0.8919, G loss: 14.4212\n",
      "[7212/8000] D loss: 1.0691, G loss: 7.1251\n",
      "[7572/8000] D loss: 0.6964, G loss: 5.9031\n",
      "[7932/8000] D loss: 1.0441, G loss: 4.9606\n",
      "train error: \n",
      " D loss: 0.858529, G loss: 6.657350, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.028968, G loss: 20.134511, D accuracy: 77.5%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7892, G loss: 7.4478\n",
      "[372/8000] D loss: 1.4593, G loss: 0.7817\n",
      "[732/8000] D loss: 0.8146, G loss: 2.8581\n",
      "[1092/8000] D loss: 1.2920, G loss: 0.9218\n",
      "[1452/8000] D loss: 0.4641, G loss: 14.8825\n",
      "[1812/8000] D loss: 0.9170, G loss: 6.4663\n",
      "[2172/8000] D loss: 0.5796, G loss: 9.1632\n",
      "[2532/8000] D loss: 0.8269, G loss: 6.4519\n",
      "[2892/8000] D loss: 0.8431, G loss: 8.0975\n",
      "[3252/8000] D loss: 0.4738, G loss: 15.6636\n",
      "[3612/8000] D loss: 0.7137, G loss: 8.9212\n",
      "[3972/8000] D loss: 0.9459, G loss: 2.1107\n",
      "[4332/8000] D loss: 0.7857, G loss: 10.1674\n",
      "[4692/8000] D loss: 0.7299, G loss: 11.6702\n",
      "[5052/8000] D loss: 0.7644, G loss: 7.6727\n",
      "[5412/8000] D loss: 0.8911, G loss: 8.4467\n",
      "[5772/8000] D loss: 1.0977, G loss: 2.7114\n",
      "[6132/8000] D loss: 0.9339, G loss: 6.2085\n",
      "[6492/8000] D loss: 1.2421, G loss: 0.9528\n",
      "[6852/8000] D loss: 0.8905, G loss: 4.1454\n",
      "[7212/8000] D loss: 0.7995, G loss: 4.9411\n",
      "[7572/8000] D loss: 0.7575, G loss: 13.2281\n",
      "[7932/8000] D loss: 0.8037, G loss: 6.7990\n",
      "train error: \n",
      " D loss: 0.851432, G loss: 6.002341, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.990656, G loss: 19.511406, D accuracy: 80.0%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0547, G loss: 5.1743\n",
      "[372/8000] D loss: 1.0035, G loss: 4.6019\n",
      "[732/8000] D loss: 0.4656, G loss: 12.2739\n",
      "[1092/8000] D loss: 1.3732, G loss: 1.3624\n",
      "[1452/8000] D loss: 1.0309, G loss: 2.0191\n",
      "[1812/8000] D loss: 0.8648, G loss: 3.0251\n",
      "[2172/8000] D loss: 0.9007, G loss: 3.0588\n",
      "[2532/8000] D loss: 0.5726, G loss: 9.7544\n",
      "[2892/8000] D loss: 0.6859, G loss: 4.6042\n",
      "[3252/8000] D loss: 0.6134, G loss: 11.8939\n",
      "[3612/8000] D loss: 0.6980, G loss: 12.5088\n",
      "[3972/8000] D loss: 0.7965, G loss: 6.8640\n",
      "[4332/8000] D loss: 0.5812, G loss: 12.7792\n",
      "[4692/8000] D loss: 0.6973, G loss: 5.4422\n",
      "[5052/8000] D loss: 0.6260, G loss: 6.3762\n",
      "[5412/8000] D loss: 0.7844, G loss: 8.9746\n",
      "[5772/8000] D loss: 1.1677, G loss: 3.2649\n",
      "[6132/8000] D loss: 0.6285, G loss: 13.4357\n",
      "[6492/8000] D loss: 0.9195, G loss: 3.1954\n",
      "[6852/8000] D loss: 0.8093, G loss: 8.6395\n",
      "[7212/8000] D loss: 0.8764, G loss: 4.4909\n",
      "[7572/8000] D loss: 0.7177, G loss: 11.2703\n",
      "[7932/8000] D loss: 1.2119, G loss: 6.6961\n",
      "train error: \n",
      " D loss: 0.857498, G loss: 5.823488, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.946305, G loss: 19.180702, D accuracy: 80.3%, cell accuracy: 98.3%, board accuracy: 29.6% \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0566, G loss: 7.4845\n",
      "[372/8000] D loss: 0.9337, G loss: 5.5470\n",
      "[732/8000] D loss: 1.2987, G loss: 3.4354\n",
      "[1092/8000] D loss: 0.9411, G loss: 6.5252\n",
      "[1452/8000] D loss: 0.9891, G loss: 7.9298\n",
      "[1812/8000] D loss: 0.4304, G loss: 11.7445\n",
      "[2172/8000] D loss: 1.1233, G loss: 4.4283\n",
      "[2532/8000] D loss: 0.8152, G loss: 7.5794\n",
      "[2892/8000] D loss: 0.6264, G loss: 9.4508\n",
      "[3252/8000] D loss: 0.8893, G loss: 6.8400\n",
      "[3612/8000] D loss: 0.7354, G loss: 4.6651\n",
      "[3972/8000] D loss: 0.5952, G loss: 6.9976\n",
      "[4332/8000] D loss: 1.2682, G loss: 2.9242\n",
      "[4692/8000] D loss: 0.6781, G loss: 6.6384\n",
      "[5052/8000] D loss: 0.7013, G loss: 7.7458\n",
      "[5412/8000] D loss: 0.7710, G loss: 6.6145\n",
      "[5772/8000] D loss: 0.5868, G loss: 7.4725\n",
      "[6132/8000] D loss: 0.8013, G loss: 9.0568\n",
      "[6492/8000] D loss: 1.0834, G loss: 2.3980\n",
      "[6852/8000] D loss: 1.0032, G loss: 8.6436\n",
      "[7212/8000] D loss: 0.8997, G loss: 4.0599\n",
      "[7572/8000] D loss: 0.4024, G loss: 7.5504\n",
      "[7932/8000] D loss: 0.6827, G loss: 8.7998\n",
      "train error: \n",
      " D loss: 0.853084, G loss: 7.909880, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.056333, G loss: 23.772735, D accuracy: 79.9%, cell accuracy: 98.3%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7075, G loss: 6.2970\n",
      "[372/8000] D loss: 0.8018, G loss: 9.5031\n",
      "[732/8000] D loss: 0.9594, G loss: 8.3573\n",
      "[1092/8000] D loss: 1.0144, G loss: 5.0300\n",
      "[1452/8000] D loss: 1.0565, G loss: 3.2508\n",
      "[1812/8000] D loss: 0.5474, G loss: 17.3509\n",
      "[2172/8000] D loss: 0.6711, G loss: 18.3609\n",
      "[2532/8000] D loss: 0.6564, G loss: 6.0227\n",
      "[2892/8000] D loss: 1.1168, G loss: 8.6795\n",
      "[3252/8000] D loss: 1.0963, G loss: 2.5590\n",
      "[3612/8000] D loss: 0.9641, G loss: 3.4606\n",
      "[3972/8000] D loss: 0.7997, G loss: 6.0790\n",
      "[4332/8000] D loss: 0.9593, G loss: 6.8956\n",
      "[4692/8000] D loss: 0.9003, G loss: 8.3559\n",
      "[5052/8000] D loss: 0.8108, G loss: 3.8623\n",
      "[5412/8000] D loss: 0.7711, G loss: 9.4582\n",
      "[5772/8000] D loss: 0.9338, G loss: 5.0823\n",
      "[6132/8000] D loss: 0.7649, G loss: 11.3017\n",
      "[6492/8000] D loss: 0.8314, G loss: 8.2925\n",
      "[6852/8000] D loss: 0.9609, G loss: 11.5504\n",
      "[7212/8000] D loss: 0.8281, G loss: 6.7082\n",
      "[7572/8000] D loss: 0.4179, G loss: 18.0524\n",
      "[7932/8000] D loss: 0.9911, G loss: 8.1645\n",
      "train error: \n",
      " D loss: 0.838991, G loss: 8.754857, D accuracy: 71.9%, cell accuracy: 98.8%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.140475, G loss: 25.263624, D accuracy: 77.9%, cell accuracy: 98.2%, board accuracy: 27.4% \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8376, G loss: 6.4255\n",
      "[372/8000] D loss: 1.0525, G loss: 6.9774\n",
      "[732/8000] D loss: 0.7132, G loss: 5.2779\n",
      "[1092/8000] D loss: 0.8090, G loss: 5.9497\n",
      "[1452/8000] D loss: 0.7813, G loss: 2.0158\n",
      "[1812/8000] D loss: 0.6541, G loss: 8.6998\n",
      "[2172/8000] D loss: 0.4938, G loss: 15.5104\n",
      "[2532/8000] D loss: 0.7761, G loss: 4.5277\n",
      "[2892/8000] D loss: 0.9315, G loss: 5.7190\n",
      "[3252/8000] D loss: 0.9313, G loss: 5.2628\n",
      "[3612/8000] D loss: 0.8353, G loss: 11.0004\n",
      "[3972/8000] D loss: 0.8734, G loss: 5.4572\n",
      "[4332/8000] D loss: 0.9319, G loss: 8.9170\n",
      "[4692/8000] D loss: 0.8174, G loss: 4.3731\n",
      "[5052/8000] D loss: 0.5438, G loss: 10.8048\n",
      "[5412/8000] D loss: 0.4666, G loss: 20.3279\n",
      "[5772/8000] D loss: 0.6516, G loss: 8.2465\n",
      "[6132/8000] D loss: 0.7658, G loss: 13.3079\n",
      "[6492/8000] D loss: 0.9307, G loss: 4.4140\n",
      "[6852/8000] D loss: 1.0457, G loss: 4.1379\n",
      "[7212/8000] D loss: 0.9626, G loss: 6.8374\n",
      "[7572/8000] D loss: 0.7098, G loss: 6.7422\n",
      "[7932/8000] D loss: 0.9150, G loss: 5.7458\n",
      "train error: \n",
      " D loss: 0.858087, G loss: 6.306616, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.942610, G loss: 20.185670, D accuracy: 80.7%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6925, G loss: 9.4630\n",
      "[372/8000] D loss: 0.5765, G loss: 9.5603\n",
      "[732/8000] D loss: 0.9084, G loss: 3.9361\n",
      "[1092/8000] D loss: 0.7154, G loss: 4.8756\n",
      "[1452/8000] D loss: 1.3226, G loss: 0.7527\n",
      "[1812/8000] D loss: 0.6289, G loss: 12.5507\n",
      "[2172/8000] D loss: 0.9322, G loss: 3.9683\n",
      "[2532/8000] D loss: 0.9515, G loss: 10.1341\n",
      "[2892/8000] D loss: 0.9110, G loss: 4.0297\n",
      "[3252/8000] D loss: 1.0263, G loss: 6.9119\n",
      "[3612/8000] D loss: 0.9920, G loss: 2.7522\n",
      "[3972/8000] D loss: 0.8148, G loss: 14.4215\n",
      "[4332/8000] D loss: 0.9364, G loss: 2.2647\n",
      "[4692/8000] D loss: 0.4190, G loss: 9.7682\n",
      "[5052/8000] D loss: 0.9161, G loss: 4.5601\n",
      "[5412/8000] D loss: 1.0014, G loss: 3.5581\n",
      "[5772/8000] D loss: 1.2660, G loss: 0.9748\n",
      "[6132/8000] D loss: 0.6805, G loss: 6.6517\n",
      "[6492/8000] D loss: 0.9607, G loss: 2.3986\n",
      "[6852/8000] D loss: 1.1924, G loss: 6.3579\n",
      "[7212/8000] D loss: 0.7558, G loss: 3.2469\n",
      "[7572/8000] D loss: 0.6993, G loss: 13.7333\n",
      "[7932/8000] D loss: 0.5653, G loss: 10.8353\n",
      "train error: \n",
      " D loss: 0.847797, G loss: 6.723337, D accuracy: 71.6%, cell accuracy: 98.8%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.042829, G loss: 21.248218, D accuracy: 80.2%, cell accuracy: 98.3%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7604, G loss: 4.2000\n",
      "[372/8000] D loss: 0.7295, G loss: 12.1508\n",
      "[732/8000] D loss: 0.8967, G loss: 5.8464\n",
      "[1092/8000] D loss: 0.9270, G loss: 6.6734\n",
      "[1452/8000] D loss: 0.8329, G loss: 3.4361\n",
      "[1812/8000] D loss: 0.9332, G loss: 2.5168\n",
      "[2172/8000] D loss: 0.9271, G loss: 6.1600\n",
      "[2532/8000] D loss: 1.2390, G loss: 1.0415\n",
      "[2892/8000] D loss: 0.9503, G loss: 5.3828\n",
      "[3252/8000] D loss: 0.7119, G loss: 4.8336\n",
      "[3612/8000] D loss: 0.8990, G loss: 3.7129\n",
      "[3972/8000] D loss: 0.4017, G loss: 14.9791\n",
      "[4332/8000] D loss: 0.8034, G loss: 4.7538\n",
      "[4692/8000] D loss: 0.3212, G loss: 9.5491\n",
      "[5052/8000] D loss: 0.9384, G loss: 8.4247\n",
      "[5412/8000] D loss: 1.0899, G loss: 4.1074\n",
      "[5772/8000] D loss: 0.7837, G loss: 10.5476\n",
      "[6132/8000] D loss: 0.6924, G loss: 2.8364\n",
      "[6492/8000] D loss: 0.8846, G loss: 10.4008\n",
      "[6852/8000] D loss: 0.7022, G loss: 7.6540\n",
      "[7212/8000] D loss: 0.8748, G loss: 4.0094\n",
      "[7572/8000] D loss: 0.7115, G loss: 6.5234\n",
      "[7932/8000] D loss: 0.7782, G loss: 5.7534\n",
      "train error: \n",
      " D loss: 0.846508, G loss: 7.560566, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999103, G loss: 22.892540, D accuracy: 80.4%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2764, G loss: 0.8167\n",
      "[372/8000] D loss: 0.4926, G loss: 4.1601\n",
      "[732/8000] D loss: 0.7459, G loss: 5.3267\n",
      "[1092/8000] D loss: 0.4190, G loss: 10.2258\n",
      "[1452/8000] D loss: 0.7239, G loss: 10.6552\n",
      "[1812/8000] D loss: 1.1305, G loss: 6.8296\n",
      "[2172/8000] D loss: 1.0379, G loss: 6.3529\n",
      "[2532/8000] D loss: 0.7598, G loss: 4.0484\n",
      "[2892/8000] D loss: 0.6408, G loss: 14.2318\n",
      "[3252/8000] D loss: 0.9003, G loss: 5.7431\n",
      "[3612/8000] D loss: 0.9320, G loss: 13.4379\n",
      "[3972/8000] D loss: 0.9897, G loss: 3.6769\n",
      "[4332/8000] D loss: 0.5485, G loss: 8.6712\n",
      "[4692/8000] D loss: 1.0753, G loss: 2.7668\n",
      "[5052/8000] D loss: 1.2335, G loss: 2.3670\n",
      "[5412/8000] D loss: 0.7900, G loss: 5.4739\n",
      "[5772/8000] D loss: 0.9293, G loss: 8.1498\n",
      "[6132/8000] D loss: 1.1496, G loss: 3.9902\n",
      "[6492/8000] D loss: 0.8615, G loss: 4.7843\n",
      "[6852/8000] D loss: 1.0186, G loss: 5.3618\n",
      "[7212/8000] D loss: 1.0574, G loss: 4.8065\n",
      "[7572/8000] D loss: 0.8479, G loss: 6.2791\n",
      "[7932/8000] D loss: 0.7122, G loss: 6.7573\n",
      "train error: \n",
      " D loss: 0.856077, G loss: 6.097215, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.940453, G loss: 19.207429, D accuracy: 78.2%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8073, G loss: 11.9078\n",
      "[372/8000] D loss: 0.7594, G loss: 4.6277\n",
      "[732/8000] D loss: 0.7977, G loss: 9.0330\n",
      "[1092/8000] D loss: 1.1460, G loss: 10.3706\n",
      "[1452/8000] D loss: 1.0036, G loss: 6.4920\n",
      "[1812/8000] D loss: 1.1341, G loss: 2.9951\n",
      "[2172/8000] D loss: 1.1628, G loss: 1.5039\n",
      "[2532/8000] D loss: 0.8402, G loss: 7.7386\n",
      "[2892/8000] D loss: 0.8674, G loss: 3.3018\n",
      "[3252/8000] D loss: 0.9609, G loss: 2.2630\n",
      "[3612/8000] D loss: 0.8109, G loss: 5.7357\n",
      "[3972/8000] D loss: 0.6094, G loss: 7.3753\n",
      "[4332/8000] D loss: 0.3951, G loss: 15.5665\n",
      "[4692/8000] D loss: 0.7191, G loss: 5.3745\n",
      "[5052/8000] D loss: 0.8529, G loss: 3.8350\n",
      "[5412/8000] D loss: 1.0532, G loss: 4.5537\n",
      "[5772/8000] D loss: 0.5773, G loss: 13.3999\n",
      "[6132/8000] D loss: 0.6460, G loss: 6.2687\n",
      "[6492/8000] D loss: 0.8107, G loss: 5.8010\n",
      "[6852/8000] D loss: 0.9439, G loss: 7.2603\n",
      "[7212/8000] D loss: 0.5856, G loss: 13.9018\n",
      "[7572/8000] D loss: 0.9380, G loss: 4.9322\n",
      "[7932/8000] D loss: 0.8320, G loss: 8.3712\n",
      "train error: \n",
      " D loss: 0.849712, G loss: 6.861188, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.026424, G loss: 20.625137, D accuracy: 78.2%, cell accuracy: 98.3%, board accuracy: 29.4% \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8541, G loss: 9.6040\n",
      "[372/8000] D loss: 0.6302, G loss: 10.7680\n",
      "[732/8000] D loss: 0.8797, G loss: 4.4891\n",
      "[1092/8000] D loss: 0.9597, G loss: 9.2842\n",
      "[1452/8000] D loss: 0.8320, G loss: 7.0925\n",
      "[1812/8000] D loss: 0.7676, G loss: 3.6589\n",
      "[2172/8000] D loss: 0.5966, G loss: 13.9749\n",
      "[2532/8000] D loss: 0.8848, G loss: 5.5354\n",
      "[2892/8000] D loss: 1.0363, G loss: 4.7435\n",
      "[3252/8000] D loss: 0.5755, G loss: 6.1656\n",
      "[3612/8000] D loss: 0.9318, G loss: 6.5638\n",
      "[3972/8000] D loss: 0.7011, G loss: 9.4570\n",
      "[4332/8000] D loss: 1.0314, G loss: 7.0670\n",
      "[4692/8000] D loss: 0.5841, G loss: 9.0233\n",
      "[5052/8000] D loss: 0.5976, G loss: 16.4322\n",
      "[5412/8000] D loss: 0.8130, G loss: 10.3482\n",
      "[5772/8000] D loss: 0.8103, G loss: 6.6820\n",
      "[6132/8000] D loss: 0.6063, G loss: 15.5933\n",
      "[6492/8000] D loss: 0.5876, G loss: 13.7831\n",
      "[6852/8000] D loss: 0.6721, G loss: 7.9502\n",
      "[7212/8000] D loss: 0.7278, G loss: 15.0149\n",
      "[7572/8000] D loss: 0.6466, G loss: 8.8187\n",
      "[7932/8000] D loss: 0.6859, G loss: 12.5971\n",
      "train error: \n",
      " D loss: 0.844686, G loss: 7.650516, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.051699, G loss: 23.657138, D accuracy: 79.1%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7872, G loss: 5.7613\n",
      "[372/8000] D loss: 0.7693, G loss: 11.7065\n",
      "[732/8000] D loss: 0.9138, G loss: 3.9287\n",
      "[1092/8000] D loss: 0.5780, G loss: 7.2185\n",
      "[1452/8000] D loss: 0.7714, G loss: 5.5738\n",
      "[1812/8000] D loss: 1.1547, G loss: 10.1672\n",
      "[2172/8000] D loss: 0.8166, G loss: 10.8309\n",
      "[2532/8000] D loss: 0.7766, G loss: 15.6072\n",
      "[2892/8000] D loss: 0.9380, G loss: 5.6173\n",
      "[3252/8000] D loss: 0.8053, G loss: 8.8117\n",
      "[3612/8000] D loss: 0.7022, G loss: 15.6356\n",
      "[3972/8000] D loss: 0.9941, G loss: 7.8505\n",
      "[4332/8000] D loss: 0.8413, G loss: 4.6536\n",
      "[4692/8000] D loss: 0.9281, G loss: 2.8624\n",
      "[5052/8000] D loss: 0.7391, G loss: 10.5738\n",
      "[5412/8000] D loss: 1.0477, G loss: 6.0940\n",
      "[5772/8000] D loss: 0.8220, G loss: 11.1961\n",
      "[6132/8000] D loss: 0.8719, G loss: 4.3976\n",
      "[6492/8000] D loss: 0.8397, G loss: 11.8968\n",
      "[6852/8000] D loss: 0.8662, G loss: 11.4220\n",
      "[7212/8000] D loss: 1.2449, G loss: 1.6631\n",
      "[7572/8000] D loss: 0.9195, G loss: 7.5917\n",
      "[7932/8000] D loss: 0.8175, G loss: 11.0882\n",
      "train error: \n",
      " D loss: 0.852211, G loss: 7.211723, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.052376, G loss: 22.040431, D accuracy: 76.8%, cell accuracy: 98.3%, board accuracy: 30.8% \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2452, G loss: 10.7733\n",
      "[372/8000] D loss: 0.9012, G loss: 9.8326\n",
      "[732/8000] D loss: 1.3690, G loss: 1.2097\n",
      "[1092/8000] D loss: 0.6356, G loss: 14.9243\n",
      "[1452/8000] D loss: 0.8051, G loss: 4.4376\n",
      "[1812/8000] D loss: 0.4693, G loss: 10.6219\n",
      "[2172/8000] D loss: 0.3864, G loss: 11.4866\n",
      "[2532/8000] D loss: 0.7097, G loss: 12.4062\n",
      "[2892/8000] D loss: 1.0351, G loss: 8.1068\n",
      "[3252/8000] D loss: 1.0296, G loss: 3.9806\n",
      "[3612/8000] D loss: 0.4908, G loss: 11.5474\n",
      "[3972/8000] D loss: 0.9011, G loss: 7.2293\n",
      "[4332/8000] D loss: 0.8030, G loss: 4.7248\n",
      "[4692/8000] D loss: 0.5188, G loss: 14.3329\n",
      "[5052/8000] D loss: 0.9058, G loss: 13.0927\n",
      "[5412/8000] D loss: 0.8018, G loss: 4.9251\n",
      "[5772/8000] D loss: 0.5684, G loss: 15.7187\n",
      "[6132/8000] D loss: 0.8637, G loss: 10.2028\n",
      "[6492/8000] D loss: 0.8621, G loss: 2.6452\n",
      "[6852/8000] D loss: 0.7776, G loss: 7.3831\n",
      "[7212/8000] D loss: 0.8112, G loss: 16.3219\n",
      "[7572/8000] D loss: 0.7804, G loss: 10.8035\n",
      "[7932/8000] D loss: 0.9105, G loss: 6.7794\n",
      "train error: \n",
      " D loss: 0.846657, G loss: 6.908725, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.991238, G loss: 21.887489, D accuracy: 79.5%, cell accuracy: 98.3%, board accuracy: 29.3% \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6974, G loss: 6.0335\n",
      "[372/8000] D loss: 0.7398, G loss: 5.2056\n",
      "[732/8000] D loss: 0.8083, G loss: 11.9824\n",
      "[1092/8000] D loss: 0.8974, G loss: 11.3554\n",
      "[1452/8000] D loss: 0.7593, G loss: 5.8238\n",
      "[1812/8000] D loss: 1.1043, G loss: 13.6767\n",
      "[2172/8000] D loss: 0.5443, G loss: 6.3174\n",
      "[2532/8000] D loss: 0.8276, G loss: 7.4692\n",
      "[2892/8000] D loss: 0.9816, G loss: 2.6879\n",
      "[3252/8000] D loss: 1.1071, G loss: 3.9676\n",
      "[3612/8000] D loss: 0.7990, G loss: 5.8286\n",
      "[3972/8000] D loss: 1.0267, G loss: 3.7492\n",
      "[4332/8000] D loss: 0.4123, G loss: 12.0604\n",
      "[4692/8000] D loss: 0.9009, G loss: 5.4936\n",
      "[5052/8000] D loss: 1.0676, G loss: 4.3681\n",
      "[5412/8000] D loss: 0.5894, G loss: 14.6307\n",
      "[5772/8000] D loss: 1.1174, G loss: 4.5851\n",
      "[6132/8000] D loss: 0.9308, G loss: 5.2528\n",
      "[6492/8000] D loss: 0.6376, G loss: 13.0152\n",
      "[6852/8000] D loss: 0.9301, G loss: 8.9874\n",
      "[7212/8000] D loss: 0.9230, G loss: 6.9433\n",
      "[7572/8000] D loss: 0.7789, G loss: 6.0978\n",
      "[7932/8000] D loss: 0.9318, G loss: 4.1185\n",
      "train error: \n",
      " D loss: 0.855651, G loss: 6.823198, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.046020, G loss: 21.342447, D accuracy: 77.5%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1850, G loss: 2.1215\n",
      "[372/8000] D loss: 0.5127, G loss: 7.5037\n",
      "[732/8000] D loss: 0.7162, G loss: 5.1554\n",
      "[1092/8000] D loss: 0.7595, G loss: 10.5475\n",
      "[1452/8000] D loss: 1.0177, G loss: 5.0422\n",
      "[1812/8000] D loss: 0.8269, G loss: 6.6539\n",
      "[2172/8000] D loss: 0.8198, G loss: 7.6864\n",
      "[2532/8000] D loss: 0.8098, G loss: 10.0764\n",
      "[2892/8000] D loss: 0.7833, G loss: 6.6743\n",
      "[3252/8000] D loss: 0.8045, G loss: 9.8723\n",
      "[3612/8000] D loss: 0.7072, G loss: 9.5020\n",
      "[3972/8000] D loss: 0.8163, G loss: 11.0717\n",
      "[4332/8000] D loss: 0.7329, G loss: 13.8434\n",
      "[4692/8000] D loss: 0.8283, G loss: 6.5949\n",
      "[5052/8000] D loss: 0.9123, G loss: 7.1178\n",
      "[5412/8000] D loss: 0.9724, G loss: 9.6898\n",
      "[5772/8000] D loss: 0.4648, G loss: 18.3252\n",
      "[6132/8000] D loss: 0.6988, G loss: 10.4652\n",
      "[6492/8000] D loss: 0.5798, G loss: 17.4513\n",
      "[6852/8000] D loss: 0.7251, G loss: 7.2371\n",
      "[7212/8000] D loss: 0.7869, G loss: 4.5532\n",
      "[7572/8000] D loss: 0.6852, G loss: 6.2401\n",
      "[7932/8000] D loss: 0.9188, G loss: 3.4156\n",
      "train error: \n",
      " D loss: 0.864065, G loss: 8.766642, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.117093, G loss: 25.456365, D accuracy: 76.5%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9428, G loss: 4.5623\n",
      "[372/8000] D loss: 0.6401, G loss: 6.9169\n",
      "[732/8000] D loss: 0.4823, G loss: 18.0452\n",
      "[1092/8000] D loss: 0.9047, G loss: 4.6935\n",
      "[1452/8000] D loss: 0.6456, G loss: 7.5356\n",
      "[1812/8000] D loss: 1.1415, G loss: 6.3376\n",
      "[2172/8000] D loss: 0.8160, G loss: 8.6475\n",
      "[2532/8000] D loss: 0.9485, G loss: 6.2640\n",
      "[2892/8000] D loss: 0.8992, G loss: 2.1044\n",
      "[3252/8000] D loss: 0.5885, G loss: 10.6239\n",
      "[3612/8000] D loss: 0.8870, G loss: 4.6128\n",
      "[3972/8000] D loss: 0.8984, G loss: 9.7779\n",
      "[4332/8000] D loss: 0.9198, G loss: 8.7557\n",
      "[4692/8000] D loss: 0.7752, G loss: 10.4844\n",
      "[5052/8000] D loss: 0.8105, G loss: 6.8300\n",
      "[5412/8000] D loss: 0.9088, G loss: 6.9491\n",
      "[5772/8000] D loss: 1.0330, G loss: 2.0061\n",
      "[6132/8000] D loss: 0.8200, G loss: 11.1370\n",
      "[6492/8000] D loss: 0.7257, G loss: 8.2720\n",
      "[6852/8000] D loss: 0.8091, G loss: 3.3731\n",
      "[7212/8000] D loss: 0.9251, G loss: 7.0964\n",
      "[7572/8000] D loss: 0.2571, G loss: 14.0163\n",
      "[7932/8000] D loss: 1.0525, G loss: 6.2799\n",
      "train error: \n",
      " D loss: 0.853311, G loss: 7.194928, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.046247, G loss: 21.546574, D accuracy: 75.8%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9200, G loss: 9.0340\n",
      "[372/8000] D loss: 0.9954, G loss: 6.0076\n",
      "[732/8000] D loss: 0.7032, G loss: 13.2191\n",
      "[1092/8000] D loss: 0.7799, G loss: 7.6731\n",
      "[1452/8000] D loss: 0.8469, G loss: 8.3522\n",
      "[1812/8000] D loss: 0.9827, G loss: 5.7317\n",
      "[2172/8000] D loss: 0.5254, G loss: 6.1933\n",
      "[2532/8000] D loss: 0.9878, G loss: 4.2115\n",
      "[2892/8000] D loss: 0.6008, G loss: 12.5608\n",
      "[3252/8000] D loss: 1.0964, G loss: 2.2392\n",
      "[3612/8000] D loss: 0.3547, G loss: 10.5637\n",
      "[3972/8000] D loss: 1.1779, G loss: 1.3468\n",
      "[4332/8000] D loss: 0.9323, G loss: 3.8436\n",
      "[4692/8000] D loss: 0.9296, G loss: 7.2221\n",
      "[5052/8000] D loss: 0.4994, G loss: 10.6780\n",
      "[5412/8000] D loss: 0.4684, G loss: 11.5902\n",
      "[5772/8000] D loss: 0.7650, G loss: 4.8942\n",
      "[6132/8000] D loss: 0.7201, G loss: 10.8066\n",
      "[6492/8000] D loss: 0.9456, G loss: 5.0780\n",
      "[6852/8000] D loss: 0.9234, G loss: 8.2160\n",
      "[7212/8000] D loss: 1.0305, G loss: 1.9527\n",
      "[7572/8000] D loss: 0.7931, G loss: 9.2392\n",
      "[7932/8000] D loss: 0.7646, G loss: 17.2590\n",
      "train error: \n",
      " D loss: 0.859982, G loss: 6.736938, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.904897, G loss: 21.155813, D accuracy: 82.2%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6312, G loss: 7.2668\n",
      "[372/8000] D loss: 1.0692, G loss: 2.0125\n",
      "[732/8000] D loss: 0.6170, G loss: 11.2576\n",
      "[1092/8000] D loss: 0.8835, G loss: 5.2780\n",
      "[1452/8000] D loss: 0.6287, G loss: 10.3304\n",
      "[1812/8000] D loss: 0.6051, G loss: 6.8314\n",
      "[2172/8000] D loss: 1.1115, G loss: 1.9358\n",
      "[2532/8000] D loss: 0.9530, G loss: 7.0936\n",
      "[2892/8000] D loss: 0.8161, G loss: 9.4733\n",
      "[3252/8000] D loss: 0.8459, G loss: 8.1900\n",
      "[3612/8000] D loss: 0.9802, G loss: 4.6615\n",
      "[3972/8000] D loss: 1.0619, G loss: 2.8706\n",
      "[4332/8000] D loss: 1.0323, G loss: 4.1690\n",
      "[4692/8000] D loss: 0.7971, G loss: 5.9348\n",
      "[5052/8000] D loss: 0.8882, G loss: 7.2720\n",
      "[5412/8000] D loss: 0.8529, G loss: 14.8480\n",
      "[5772/8000] D loss: 0.9065, G loss: 3.5755\n",
      "[6132/8000] D loss: 0.9316, G loss: 6.1217\n",
      "[6492/8000] D loss: 0.8948, G loss: 7.4746\n",
      "[6852/8000] D loss: 0.5776, G loss: 13.9251\n",
      "[7212/8000] D loss: 0.8789, G loss: 10.1636\n",
      "[7572/8000] D loss: 0.6788, G loss: 6.8348\n",
      "[7932/8000] D loss: 0.6670, G loss: 16.2883\n",
      "train error: \n",
      " D loss: 0.855282, G loss: 7.599418, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.997819, G loss: 23.414523, D accuracy: 77.8%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7261, G loss: 17.1496\n",
      "[372/8000] D loss: 1.0350, G loss: 1.8811\n",
      "[732/8000] D loss: 0.6985, G loss: 9.9257\n",
      "[1092/8000] D loss: 0.7037, G loss: 8.1575\n",
      "[1452/8000] D loss: 0.7201, G loss: 8.8160\n",
      "[1812/8000] D loss: 0.8152, G loss: 3.7473\n",
      "[2172/8000] D loss: 0.8169, G loss: 5.5690\n",
      "[2532/8000] D loss: 1.1256, G loss: 3.2496\n",
      "[2892/8000] D loss: 0.8179, G loss: 13.2249\n",
      "[3252/8000] D loss: 0.6411, G loss: 4.2620\n",
      "[3612/8000] D loss: 0.7344, G loss: 4.2132\n",
      "[3972/8000] D loss: 0.8749, G loss: 4.4527\n",
      "[4332/8000] D loss: 1.1352, G loss: 4.3828\n",
      "[4692/8000] D loss: 1.2139, G loss: 1.0408\n",
      "[5052/8000] D loss: 0.7019, G loss: 16.1891\n",
      "[5412/8000] D loss: 0.7591, G loss: 4.9323\n",
      "[5772/8000] D loss: 0.7750, G loss: 8.1781\n",
      "[6132/8000] D loss: 0.6031, G loss: 7.2880\n",
      "[6492/8000] D loss: 0.7538, G loss: 6.5638\n",
      "[6852/8000] D loss: 0.8497, G loss: 4.8910\n",
      "[7212/8000] D loss: 0.9956, G loss: 3.0758\n",
      "[7572/8000] D loss: 0.8714, G loss: 11.3794\n",
      "[7932/8000] D loss: 0.9581, G loss: 4.0119\n",
      "train error: \n",
      " D loss: 0.874727, G loss: 4.919028, D accuracy: 70.5%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.055013, G loss: 17.276751, D accuracy: 73.7%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9667, G loss: 3.8330\n",
      "[372/8000] D loss: 0.7016, G loss: 5.2650\n",
      "[732/8000] D loss: 1.1062, G loss: 8.6175\n",
      "[1092/8000] D loss: 0.7673, G loss: 9.5136\n",
      "[1452/8000] D loss: 0.8038, G loss: 5.2449\n",
      "[1812/8000] D loss: 0.4782, G loss: 7.8194\n",
      "[2172/8000] D loss: 0.9516, G loss: 5.0156\n",
      "[2532/8000] D loss: 0.8606, G loss: 5.5124\n",
      "[2892/8000] D loss: 0.7918, G loss: 5.5802\n",
      "[3252/8000] D loss: 0.9659, G loss: 4.2080\n",
      "[3612/8000] D loss: 0.8976, G loss: 2.6684\n",
      "[3972/8000] D loss: 0.6345, G loss: 6.8947\n",
      "[4332/8000] D loss: 1.3034, G loss: 4.4258\n",
      "[4692/8000] D loss: 0.5912, G loss: 14.9195\n",
      "[5052/8000] D loss: 0.8549, G loss: 12.7165\n",
      "[5412/8000] D loss: 0.9246, G loss: 8.3087\n",
      "[5772/8000] D loss: 0.9260, G loss: 6.3101\n",
      "[6132/8000] D loss: 1.0533, G loss: 5.7579\n",
      "[6492/8000] D loss: 0.9379, G loss: 4.3576\n",
      "[6852/8000] D loss: 0.9226, G loss: 8.4015\n",
      "[7212/8000] D loss: 0.8823, G loss: 7.3103\n",
      "[7572/8000] D loss: 0.8576, G loss: 5.6892\n",
      "[7932/8000] D loss: 1.0485, G loss: 4.5340\n",
      "train error: \n",
      " D loss: 0.851403, G loss: 6.798549, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.085990, G loss: 21.438881, D accuracy: 78.6%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8975, G loss: 7.8796\n",
      "[372/8000] D loss: 0.5303, G loss: 6.5079\n",
      "[732/8000] D loss: 0.5788, G loss: 11.0521\n",
      "[1092/8000] D loss: 0.8195, G loss: 4.8889\n",
      "[1452/8000] D loss: 0.5781, G loss: 9.4117\n",
      "[1812/8000] D loss: 0.6679, G loss: 5.6702\n",
      "[2172/8000] D loss: 1.0414, G loss: 6.5918\n",
      "[2532/8000] D loss: 1.0217, G loss: 4.9494\n",
      "[2892/8000] D loss: 1.0596, G loss: 3.9174\n",
      "[3252/8000] D loss: 0.8152, G loss: 4.5178\n",
      "[3612/8000] D loss: 0.5781, G loss: 9.9885\n",
      "[3972/8000] D loss: 0.6056, G loss: 12.5457\n",
      "[4332/8000] D loss: 0.9043, G loss: 5.4863\n",
      "[4692/8000] D loss: 1.3293, G loss: 1.0064\n",
      "[5052/8000] D loss: 0.9146, G loss: 6.2941\n",
      "[5412/8000] D loss: 0.5914, G loss: 11.1767\n",
      "[5772/8000] D loss: 0.9761, G loss: 3.6988\n",
      "[6132/8000] D loss: 0.6946, G loss: 6.7418\n",
      "[6492/8000] D loss: 0.8033, G loss: 9.4993\n",
      "[6852/8000] D loss: 0.8283, G loss: 6.2884\n",
      "[7212/8000] D loss: 0.9562, G loss: 4.8211\n",
      "[7572/8000] D loss: 1.0099, G loss: 9.0425\n",
      "[7932/8000] D loss: 0.6931, G loss: 6.6941\n",
      "train error: \n",
      " D loss: 0.854969, G loss: 6.340342, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.992785, G loss: 20.289557, D accuracy: 79.5%, cell accuracy: 98.3%, board accuracy: 29.9% \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6170, G loss: 4.2944\n",
      "[372/8000] D loss: 0.9359, G loss: 3.4330\n",
      "[732/8000] D loss: 0.9370, G loss: 2.6471\n",
      "[1092/8000] D loss: 1.1421, G loss: 1.9873\n",
      "[1452/8000] D loss: 0.9890, G loss: 5.3134\n",
      "[1812/8000] D loss: 1.1023, G loss: 5.8594\n",
      "[2172/8000] D loss: 0.9323, G loss: 5.4592\n",
      "[2532/8000] D loss: 0.7967, G loss: 6.5410\n",
      "[2892/8000] D loss: 0.7968, G loss: 6.6922\n",
      "[3252/8000] D loss: 0.7426, G loss: 4.4469\n",
      "[3612/8000] D loss: 1.2191, G loss: 3.9400\n",
      "[3972/8000] D loss: 0.7069, G loss: 9.4805\n",
      "[4332/8000] D loss: 0.8168, G loss: 4.2181\n",
      "[4692/8000] D loss: 0.8337, G loss: 2.9422\n",
      "[5052/8000] D loss: 0.3549, G loss: 13.7612\n",
      "[5412/8000] D loss: 0.9138, G loss: 5.6751\n",
      "[5772/8000] D loss: 1.1605, G loss: 5.1371\n",
      "[6132/8000] D loss: 0.5321, G loss: 12.6665\n",
      "[6492/8000] D loss: 0.9068, G loss: 7.6006\n",
      "[6852/8000] D loss: 0.7042, G loss: 6.4411\n",
      "[7212/8000] D loss: 1.0690, G loss: 9.0140\n",
      "[7572/8000] D loss: 0.7559, G loss: 3.9835\n",
      "[7932/8000] D loss: 0.7781, G loss: 5.4057\n",
      "train error: \n",
      " D loss: 0.854361, G loss: 5.904484, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.928746, G loss: 19.488222, D accuracy: 79.4%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9237, G loss: 6.3523\n",
      "[372/8000] D loss: 1.1701, G loss: 3.1205\n",
      "[732/8000] D loss: 0.6939, G loss: 5.8908\n",
      "[1092/8000] D loss: 0.9913, G loss: 3.0360\n",
      "[1452/8000] D loss: 0.8330, G loss: 10.2295\n",
      "[1812/8000] D loss: 1.0948, G loss: 5.2535\n",
      "[2172/8000] D loss: 0.7977, G loss: 12.3136\n",
      "[2532/8000] D loss: 0.8190, G loss: 4.7272\n",
      "[2892/8000] D loss: 0.6544, G loss: 4.9038\n",
      "[3252/8000] D loss: 0.9747, G loss: 10.5762\n",
      "[3612/8000] D loss: 0.8740, G loss: 5.1844\n",
      "[3972/8000] D loss: 0.5802, G loss: 11.0704\n",
      "[4332/8000] D loss: 0.9526, G loss: 7.7839\n",
      "[4692/8000] D loss: 0.5343, G loss: 8.7804\n",
      "[5052/8000] D loss: 0.9751, G loss: 7.3238\n",
      "[5412/8000] D loss: 1.0188, G loss: 6.8449\n",
      "[5772/8000] D loss: 0.5178, G loss: 5.0749\n",
      "[6132/8000] D loss: 0.5775, G loss: 8.5172\n",
      "[6492/8000] D loss: 0.9179, G loss: 3.4038\n",
      "[6852/8000] D loss: 0.9708, G loss: 8.4558\n",
      "[7212/8000] D loss: 0.7289, G loss: 8.0775\n",
      "[7572/8000] D loss: 0.8719, G loss: 3.3513\n",
      "[7932/8000] D loss: 0.7054, G loss: 9.0201\n",
      "train error: \n",
      " D loss: 0.854888, G loss: 7.032486, D accuracy: 71.5%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.996849, G loss: 21.938648, D accuracy: 77.5%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6910, G loss: 11.5640\n",
      "[372/8000] D loss: 0.9955, G loss: 2.6191\n",
      "[732/8000] D loss: 0.9771, G loss: 6.3039\n",
      "[1092/8000] D loss: 1.1764, G loss: 2.3338\n",
      "[1452/8000] D loss: 0.9176, G loss: 10.0275\n",
      "[1812/8000] D loss: 0.7913, G loss: 7.2822\n",
      "[2172/8000] D loss: 0.9007, G loss: 6.2926\n",
      "[2532/8000] D loss: 0.5127, G loss: 14.7385\n",
      "[2892/8000] D loss: 1.0500, G loss: 6.9750\n",
      "[3252/8000] D loss: 0.8374, G loss: 5.3703\n",
      "[3612/8000] D loss: 0.8944, G loss: 7.4759\n",
      "[3972/8000] D loss: 0.7739, G loss: 8.9533\n",
      "[4332/8000] D loss: 0.7027, G loss: 9.9526\n",
      "[4692/8000] D loss: 0.9848, G loss: 2.5526\n",
      "[5052/8000] D loss: 0.9208, G loss: 3.9103\n",
      "[5412/8000] D loss: 1.0784, G loss: 6.6549\n",
      "[5772/8000] D loss: 0.8831, G loss: 5.8808\n",
      "[6132/8000] D loss: 0.8619, G loss: 8.7240\n",
      "[6492/8000] D loss: 0.7881, G loss: 11.5908\n",
      "[6852/8000] D loss: 0.6937, G loss: 4.9590\n",
      "[7212/8000] D loss: 0.8252, G loss: 8.2696\n",
      "[7572/8000] D loss: 0.4718, G loss: 12.8441\n",
      "[7932/8000] D loss: 0.6983, G loss: 4.7236\n",
      "train error: \n",
      " D loss: 0.861716, G loss: 6.364233, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.928807, G loss: 19.836929, D accuracy: 80.7%, cell accuracy: 98.3%, board accuracy: 29.5% \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3305, G loss: 11.2239\n",
      "[372/8000] D loss: 0.9266, G loss: 4.0670\n",
      "[732/8000] D loss: 0.6953, G loss: 9.2506\n",
      "[1092/8000] D loss: 0.8219, G loss: 11.9885\n",
      "[1452/8000] D loss: 0.7047, G loss: 11.4064\n",
      "[1812/8000] D loss: 0.9076, G loss: 3.5998\n",
      "[2172/8000] D loss: 0.9980, G loss: 2.2479\n",
      "[2532/8000] D loss: 0.6007, G loss: 5.3303\n",
      "[2892/8000] D loss: 0.5551, G loss: 5.4067\n",
      "[3252/8000] D loss: 0.7778, G loss: 10.2927\n",
      "[3612/8000] D loss: 1.5114, G loss: 13.6472\n",
      "[3972/8000] D loss: 0.5653, G loss: 13.3342\n",
      "[4332/8000] D loss: 1.0376, G loss: 1.7779\n",
      "[4692/8000] D loss: 0.7992, G loss: 7.6613\n",
      "[5052/8000] D loss: 0.7674, G loss: 8.5314\n",
      "[5412/8000] D loss: 1.1717, G loss: 2.4756\n",
      "[5772/8000] D loss: 1.0599, G loss: 3.6780\n",
      "[6132/8000] D loss: 0.7183, G loss: 6.8361\n",
      "[6492/8000] D loss: 0.9968, G loss: 5.2404\n",
      "[6852/8000] D loss: 0.8096, G loss: 6.4425\n",
      "[7212/8000] D loss: 0.9297, G loss: 7.2356\n",
      "[7572/8000] D loss: 0.7363, G loss: 12.5370\n",
      "[7932/8000] D loss: 0.7548, G loss: 9.8552\n",
      "train error: \n",
      " D loss: 0.864317, G loss: 6.395802, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.915107, G loss: 19.808422, D accuracy: 81.0%, cell accuracy: 98.3%, board accuracy: 30.1% \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8478, G loss: 6.0282\n",
      "[372/8000] D loss: 1.0375, G loss: 9.0259\n",
      "[732/8000] D loss: 0.5468, G loss: 17.1462\n",
      "[1092/8000] D loss: 0.8136, G loss: 4.1501\n",
      "[1452/8000] D loss: 0.6473, G loss: 14.4966\n",
      "[1812/8000] D loss: 0.9460, G loss: 9.6233\n",
      "[2172/8000] D loss: 0.7072, G loss: 7.9611\n",
      "[2532/8000] D loss: 0.9292, G loss: 7.2288\n",
      "[2892/8000] D loss: 0.8210, G loss: 7.7620\n",
      "[3252/8000] D loss: 0.5728, G loss: 10.0748\n",
      "[3612/8000] D loss: 0.7792, G loss: 13.2078\n",
      "[3972/8000] D loss: 0.4687, G loss: 10.3683\n",
      "[4332/8000] D loss: 0.8328, G loss: 11.1444\n",
      "[4692/8000] D loss: 0.8149, G loss: 9.5329\n",
      "[5052/8000] D loss: 0.7276, G loss: 8.9555\n",
      "[5412/8000] D loss: 0.6779, G loss: 9.9493\n",
      "[5772/8000] D loss: 0.8119, G loss: 5.6934\n",
      "[6132/8000] D loss: 0.7449, G loss: 12.9452\n",
      "[6492/8000] D loss: 0.6879, G loss: 6.4609\n",
      "[6852/8000] D loss: 0.8464, G loss: 3.6713\n",
      "[7212/8000] D loss: 1.0687, G loss: 3.5919\n",
      "[7572/8000] D loss: 0.9604, G loss: 10.0241\n",
      "[7932/8000] D loss: 0.8277, G loss: 4.9621\n",
      "train error: \n",
      " D loss: 0.856435, G loss: 8.086025, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.156860, G loss: 23.945420, D accuracy: 75.0%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0531, G loss: 3.5296\n",
      "[372/8000] D loss: 0.8181, G loss: 11.7788\n",
      "[732/8000] D loss: 1.0027, G loss: 9.5209\n",
      "[1092/8000] D loss: 0.8667, G loss: 3.6480\n",
      "[1452/8000] D loss: 0.7097, G loss: 3.5587\n",
      "[1812/8000] D loss: 0.6475, G loss: 15.7708\n",
      "[2172/8000] D loss: 0.5440, G loss: 18.8683\n",
      "[2532/8000] D loss: 0.6092, G loss: 8.7380\n",
      "[2892/8000] D loss: 0.6986, G loss: 6.6064\n",
      "[3252/8000] D loss: 0.9321, G loss: 7.2288\n",
      "[3612/8000] D loss: 0.6877, G loss: 7.2624\n",
      "[3972/8000] D loss: 0.6449, G loss: 9.4116\n",
      "[4332/8000] D loss: 1.0491, G loss: 2.7794\n",
      "[4692/8000] D loss: 0.8579, G loss: 10.9317\n",
      "[5052/8000] D loss: 0.5185, G loss: 10.8816\n",
      "[5412/8000] D loss: 0.7393, G loss: 7.2160\n",
      "[5772/8000] D loss: 1.0378, G loss: 1.9526\n",
      "[6132/8000] D loss: 0.7992, G loss: 3.4846\n",
      "[6492/8000] D loss: 0.8335, G loss: 4.8525\n",
      "[6852/8000] D loss: 0.8824, G loss: 6.5216\n",
      "[7212/8000] D loss: 0.8681, G loss: 4.6786\n",
      "[7572/8000] D loss: 0.8589, G loss: 4.7439\n",
      "[7932/8000] D loss: 1.0635, G loss: 3.9227\n",
      "train error: \n",
      " D loss: 0.857702, G loss: 6.516809, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.974218, G loss: 20.622768, D accuracy: 80.4%, cell accuracy: 98.3%, board accuracy: 30.6% \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0450, G loss: 5.0918\n",
      "[372/8000] D loss: 0.6668, G loss: 3.9432\n",
      "[732/8000] D loss: 0.6070, G loss: 8.0370\n",
      "[1092/8000] D loss: 1.0263, G loss: 2.6999\n",
      "[1452/8000] D loss: 0.6588, G loss: 6.5925\n",
      "[1812/8000] D loss: 0.6691, G loss: 10.2758\n",
      "[2172/8000] D loss: 0.5878, G loss: 11.7488\n",
      "[2532/8000] D loss: 0.8242, G loss: 6.8028\n",
      "[2892/8000] D loss: 0.8249, G loss: 9.6127\n",
      "[3252/8000] D loss: 0.7744, G loss: 7.1192\n",
      "[3612/8000] D loss: 0.4795, G loss: 7.9098\n",
      "[3972/8000] D loss: 1.1899, G loss: 1.9849\n",
      "[4332/8000] D loss: 0.7540, G loss: 6.8902\n",
      "[4692/8000] D loss: 1.0437, G loss: 7.1787\n",
      "[5052/8000] D loss: 0.8130, G loss: 5.2051\n",
      "[5412/8000] D loss: 0.6792, G loss: 6.8982\n",
      "[5772/8000] D loss: 1.0250, G loss: 4.6536\n",
      "[6132/8000] D loss: 0.5804, G loss: 6.5075\n",
      "[6492/8000] D loss: 0.8056, G loss: 4.5471\n",
      "[6852/8000] D loss: 0.8205, G loss: 3.7490\n",
      "[7212/8000] D loss: 0.8158, G loss: 7.6292\n",
      "[7572/8000] D loss: 0.9018, G loss: 13.0571\n",
      "[7932/8000] D loss: 0.9857, G loss: 4.3611\n",
      "train error: \n",
      " D loss: 0.853300, G loss: 7.462347, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.005909, G loss: 22.209275, D accuracy: 79.0%, cell accuracy: 98.3%, board accuracy: 29.6% \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5786, G loss: 13.2412\n",
      "[372/8000] D loss: 0.6633, G loss: 6.1609\n",
      "[732/8000] D loss: 0.9663, G loss: 2.3917\n",
      "[1092/8000] D loss: 0.8327, G loss: 7.5479\n",
      "[1452/8000] D loss: 0.7384, G loss: 5.6789\n",
      "[1812/8000] D loss: 0.6693, G loss: 7.3172\n",
      "[2172/8000] D loss: 0.9385, G loss: 9.2798\n",
      "[2532/8000] D loss: 0.4875, G loss: 21.2930\n",
      "[2892/8000] D loss: 1.0549, G loss: 1.9581\n",
      "[3252/8000] D loss: 0.8852, G loss: 4.4225\n",
      "[3612/8000] D loss: 1.0511, G loss: 2.7395\n",
      "[3972/8000] D loss: 1.2641, G loss: 1.2969\n",
      "[4332/8000] D loss: 0.8175, G loss: 6.9547\n",
      "[4692/8000] D loss: 1.2795, G loss: 3.5521\n",
      "[5052/8000] D loss: 0.9280, G loss: 8.4970\n",
      "[5412/8000] D loss: 1.3437, G loss: 1.1631\n",
      "[5772/8000] D loss: 0.7839, G loss: 9.7856\n",
      "[6132/8000] D loss: 1.2593, G loss: 1.2710\n",
      "[6492/8000] D loss: 0.8955, G loss: 6.1546\n",
      "[6852/8000] D loss: 0.5780, G loss: 8.6486\n",
      "[7212/8000] D loss: 0.9335, G loss: 4.9152\n",
      "[7572/8000] D loss: 0.8407, G loss: 8.2427\n",
      "[7932/8000] D loss: 0.7049, G loss: 7.4088\n",
      "train error: \n",
      " D loss: 0.841873, G loss: 7.537713, D accuracy: 71.6%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.052768, G loss: 22.255322, D accuracy: 78.3%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6022, G loss: 11.8810\n",
      "[372/8000] D loss: 0.7312, G loss: 9.6166\n",
      "[732/8000] D loss: 1.1301, G loss: 2.2215\n",
      "[1092/8000] D loss: 0.7515, G loss: 10.6419\n",
      "[1452/8000] D loss: 0.8303, G loss: 4.6598\n",
      "[1812/8000] D loss: 0.9008, G loss: 3.6961\n",
      "[2172/8000] D loss: 1.0540, G loss: 3.7238\n",
      "[2532/8000] D loss: 0.9381, G loss: 7.7725\n",
      "[2892/8000] D loss: 0.8491, G loss: 12.0097\n",
      "[3252/8000] D loss: 0.7703, G loss: 7.6822\n",
      "[3612/8000] D loss: 0.4686, G loss: 14.0448\n",
      "[3972/8000] D loss: 0.8282, G loss: 7.0977\n",
      "[4332/8000] D loss: 1.0906, G loss: 2.7735\n",
      "[4692/8000] D loss: 1.1259, G loss: 4.8238\n",
      "[5052/8000] D loss: 1.0054, G loss: 3.1282\n",
      "[5412/8000] D loss: 0.9289, G loss: 9.8222\n",
      "[5772/8000] D loss: 0.3763, G loss: 10.3350\n",
      "[6132/8000] D loss: 1.0428, G loss: 2.6864\n",
      "[6492/8000] D loss: 1.0576, G loss: 3.6331\n",
      "[6852/8000] D loss: 0.6582, G loss: 6.5092\n",
      "[7212/8000] D loss: 0.8266, G loss: 7.6793\n",
      "[7572/8000] D loss: 0.7437, G loss: 6.1913\n",
      "[7932/8000] D loss: 0.9279, G loss: 3.7488\n",
      "train error: \n",
      " D loss: 0.856937, G loss: 7.469563, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.057314, G loss: 23.149315, D accuracy: 76.6%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7666, G loss: 3.3732\n",
      "[372/8000] D loss: 0.8173, G loss: 5.5348\n",
      "[732/8000] D loss: 0.7725, G loss: 8.3783\n",
      "[1092/8000] D loss: 0.6375, G loss: 11.7375\n",
      "[1452/8000] D loss: 0.8688, G loss: 10.0756\n",
      "[1812/8000] D loss: 0.9613, G loss: 4.0977\n",
      "[2172/8000] D loss: 0.9336, G loss: 6.6224\n",
      "[2532/8000] D loss: 0.7634, G loss: 12.7705\n",
      "[2892/8000] D loss: 0.9981, G loss: 5.5387\n",
      "[3252/8000] D loss: 0.7728, G loss: 6.5176\n",
      "[3612/8000] D loss: 0.7929, G loss: 7.9519\n",
      "[3972/8000] D loss: 1.0054, G loss: 6.8241\n",
      "[4332/8000] D loss: 0.6263, G loss: 9.5585\n",
      "[4692/8000] D loss: 0.7844, G loss: 10.4727\n",
      "[5052/8000] D loss: 0.8700, G loss: 14.6014\n",
      "[5412/8000] D loss: 0.7471, G loss: 8.3589\n",
      "[5772/8000] D loss: 0.8084, G loss: 6.3757\n",
      "[6132/8000] D loss: 1.0318, G loss: 6.1330\n",
      "[6492/8000] D loss: 0.4820, G loss: 16.0375\n",
      "[6852/8000] D loss: 0.8151, G loss: 7.7545\n",
      "[7212/8000] D loss: 0.8357, G loss: 11.7850\n",
      "[7572/8000] D loss: 0.8134, G loss: 4.4854\n",
      "[7932/8000] D loss: 0.9148, G loss: 5.5324\n",
      "train error: \n",
      " D loss: 0.848912, G loss: 7.118560, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.007127, G loss: 21.329601, D accuracy: 79.3%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6833, G loss: 9.2767\n",
      "[372/8000] D loss: 0.5164, G loss: 10.0720\n",
      "[732/8000] D loss: 1.2603, G loss: 5.1077\n",
      "[1092/8000] D loss: 0.8110, G loss: 6.3304\n",
      "[1452/8000] D loss: 0.7113, G loss: 7.3209\n",
      "[1812/8000] D loss: 0.9426, G loss: 9.9622\n",
      "[2172/8000] D loss: 0.9465, G loss: 4.8349\n",
      "[2532/8000] D loss: 0.9562, G loss: 6.7720\n",
      "[2892/8000] D loss: 0.8996, G loss: 6.7371\n",
      "[3252/8000] D loss: 0.7624, G loss: 5.4314\n",
      "[3612/8000] D loss: 0.4692, G loss: 9.7324\n",
      "[3972/8000] D loss: 1.1959, G loss: 3.0118\n",
      "[4332/8000] D loss: 0.9440, G loss: 6.2981\n",
      "[4692/8000] D loss: 1.1227, G loss: 11.4227\n",
      "[5052/8000] D loss: 0.8033, G loss: 7.0993\n",
      "[5412/8000] D loss: 0.9058, G loss: 7.8497\n",
      "[5772/8000] D loss: 0.8840, G loss: 10.8364\n",
      "[6132/8000] D loss: 0.9521, G loss: 4.8095\n",
      "[6492/8000] D loss: 0.7495, G loss: 7.3510\n",
      "[6852/8000] D loss: 0.4721, G loss: 6.9258\n",
      "[7212/8000] D loss: 0.5330, G loss: 15.3539\n",
      "[7572/8000] D loss: 0.6121, G loss: 9.6825\n",
      "[7932/8000] D loss: 0.9740, G loss: 5.8324\n",
      "train error: \n",
      " D loss: 0.862159, G loss: 6.306880, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.918606, G loss: 19.316930, D accuracy: 81.3%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6292, G loss: 7.2673\n",
      "[372/8000] D loss: 0.6780, G loss: 7.7302\n",
      "[732/8000] D loss: 0.8659, G loss: 6.8971\n",
      "[1092/8000] D loss: 1.0402, G loss: 2.6232\n",
      "[1452/8000] D loss: 1.1776, G loss: 4.4917\n",
      "[1812/8000] D loss: 0.7779, G loss: 10.0194\n",
      "[2172/8000] D loss: 1.0481, G loss: 1.2604\n",
      "[2532/8000] D loss: 1.1952, G loss: 3.2911\n",
      "[2892/8000] D loss: 0.7080, G loss: 4.2180\n",
      "[3252/8000] D loss: 1.1251, G loss: 1.7266\n",
      "[3612/8000] D loss: 0.9303, G loss: 4.1351\n",
      "[3972/8000] D loss: 0.7887, G loss: 7.3129\n",
      "[4332/8000] D loss: 0.6495, G loss: 7.4860\n",
      "[4692/8000] D loss: 0.8418, G loss: 7.6468\n",
      "[5052/8000] D loss: 0.7573, G loss: 5.9826\n",
      "[5412/8000] D loss: 0.5956, G loss: 8.5227\n",
      "[5772/8000] D loss: 0.8691, G loss: 13.3012\n",
      "[6132/8000] D loss: 0.7121, G loss: 4.0701\n",
      "[6492/8000] D loss: 0.8845, G loss: 12.7184\n",
      "[6852/8000] D loss: 0.6993, G loss: 7.3311\n",
      "[7212/8000] D loss: 0.5876, G loss: 6.6210\n",
      "[7572/8000] D loss: 1.0340, G loss: 5.7470\n",
      "[7932/8000] D loss: 0.4693, G loss: 15.4627\n",
      "train error: \n",
      " D loss: 0.861584, G loss: 5.687955, D accuracy: 71.4%, cell accuracy: 98.8%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.838834, G loss: 18.783163, D accuracy: 82.7%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8736, G loss: 5.5230\n",
      "[372/8000] D loss: 0.8764, G loss: 3.7348\n",
      "[732/8000] D loss: 0.9928, G loss: 8.8105\n",
      "[1092/8000] D loss: 0.9450, G loss: 4.8816\n",
      "[1452/8000] D loss: 0.8003, G loss: 14.0154\n",
      "[1812/8000] D loss: 0.9335, G loss: 5.6572\n",
      "[2172/8000] D loss: 1.1365, G loss: 8.6356\n",
      "[2532/8000] D loss: 0.8837, G loss: 3.1374\n",
      "[2892/8000] D loss: 0.5844, G loss: 13.4828\n",
      "[3252/8000] D loss: 0.7141, G loss: 14.2369\n",
      "[3612/8000] D loss: 0.7704, G loss: 9.7760\n",
      "[3972/8000] D loss: 0.8389, G loss: 6.3574\n",
      "[4332/8000] D loss: 1.3215, G loss: 1.4570\n",
      "[4692/8000] D loss: 0.9459, G loss: 3.7363\n",
      "[5052/8000] D loss: 0.8518, G loss: 5.5864\n",
      "[5412/8000] D loss: 0.6379, G loss: 9.4807\n",
      "[5772/8000] D loss: 0.9291, G loss: 4.7133\n",
      "[6132/8000] D loss: 1.0268, G loss: 3.3930\n",
      "[6492/8000] D loss: 0.9505, G loss: 3.0973\n",
      "[6852/8000] D loss: 0.9811, G loss: 5.3676\n",
      "[7212/8000] D loss: 0.7580, G loss: 4.9851\n",
      "[7572/8000] D loss: 1.0358, G loss: 2.0601\n",
      "[7932/8000] D loss: 1.0075, G loss: 10.9202\n",
      "train error: \n",
      " D loss: 0.855460, G loss: 9.064810, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.076758, G loss: 26.553436, D accuracy: 75.1%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0478, G loss: 7.0624\n",
      "[372/8000] D loss: 0.9145, G loss: 6.5198\n",
      "[732/8000] D loss: 0.7855, G loss: 4.5649\n",
      "[1092/8000] D loss: 0.9382, G loss: 7.8669\n",
      "[1452/8000] D loss: 0.9545, G loss: 14.3404\n",
      "[1812/8000] D loss: 1.0489, G loss: 3.3795\n",
      "[2172/8000] D loss: 0.7095, G loss: 6.5327\n",
      "[2532/8000] D loss: 0.9512, G loss: 8.1668\n",
      "[2892/8000] D loss: 1.0644, G loss: 8.6767\n",
      "[3252/8000] D loss: 0.8150, G loss: 11.2794\n",
      "[3612/8000] D loss: 1.0302, G loss: 7.5791\n",
      "[3972/8000] D loss: 0.6145, G loss: 11.8822\n",
      "[4332/8000] D loss: 0.9345, G loss: 9.7902\n",
      "[4692/8000] D loss: 1.0418, G loss: 6.2107\n",
      "[5052/8000] D loss: 1.0023, G loss: 4.0709\n",
      "[5412/8000] D loss: 0.9904, G loss: 1.9134\n",
      "[5772/8000] D loss: 0.7963, G loss: 4.6176\n",
      "[6132/8000] D loss: 0.7610, G loss: 5.9586\n",
      "[6492/8000] D loss: 0.7027, G loss: 5.7500\n",
      "[6852/8000] D loss: 1.1528, G loss: 1.2850\n",
      "[7212/8000] D loss: 0.6994, G loss: 11.1994\n",
      "[7572/8000] D loss: 0.7033, G loss: 14.6533\n",
      "[7932/8000] D loss: 0.9170, G loss: 3.3820\n",
      "train error: \n",
      " D loss: 0.855459, G loss: 7.071565, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.979004, G loss: 21.755418, D accuracy: 78.9%, cell accuracy: 98.3%, board accuracy: 30.3% \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9456, G loss: 3.6787\n",
      "[372/8000] D loss: 0.8333, G loss: 13.3979\n",
      "[732/8000] D loss: 0.8303, G loss: 5.3235\n",
      "[1092/8000] D loss: 0.6484, G loss: 6.1229\n",
      "[1452/8000] D loss: 0.7580, G loss: 5.1137\n",
      "[1812/8000] D loss: 0.9153, G loss: 3.6106\n",
      "[2172/8000] D loss: 0.6970, G loss: 12.9928\n",
      "[2532/8000] D loss: 0.7501, G loss: 13.8393\n",
      "[2892/8000] D loss: 0.7020, G loss: 5.9301\n",
      "[3252/8000] D loss: 0.8294, G loss: 5.0395\n",
      "[3612/8000] D loss: 1.1629, G loss: 6.3848\n",
      "[3972/8000] D loss: 0.8690, G loss: 7.6039\n",
      "[4332/8000] D loss: 0.6259, G loss: 7.4357\n",
      "[4692/8000] D loss: 0.9904, G loss: 3.3950\n",
      "[5052/8000] D loss: 1.2601, G loss: 2.8074\n",
      "[5412/8000] D loss: 1.0398, G loss: 2.5863\n",
      "[5772/8000] D loss: 0.7002, G loss: 5.8897\n",
      "[6132/8000] D loss: 0.8544, G loss: 4.5866\n",
      "[6492/8000] D loss: 0.5604, G loss: 10.0395\n",
      "[6852/8000] D loss: 1.0379, G loss: 3.1194\n",
      "[7212/8000] D loss: 0.5825, G loss: 11.8145\n",
      "[7572/8000] D loss: 0.8531, G loss: 5.9363\n",
      "[7932/8000] D loss: 0.9669, G loss: 4.2024\n",
      "train error: \n",
      " D loss: 0.862493, G loss: 6.692362, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.959884, G loss: 22.009824, D accuracy: 80.2%, cell accuracy: 98.3%, board accuracy: 29.9% \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7754, G loss: 6.6053\n",
      "[372/8000] D loss: 0.7054, G loss: 7.7812\n",
      "[732/8000] D loss: 1.0692, G loss: 4.1567\n",
      "[1092/8000] D loss: 0.6406, G loss: 9.3373\n",
      "[1452/8000] D loss: 0.6943, G loss: 11.6360\n",
      "[1812/8000] D loss: 0.6450, G loss: 17.0116\n",
      "[2172/8000] D loss: 0.9294, G loss: 8.6907\n",
      "[2532/8000] D loss: 0.9956, G loss: 3.9207\n",
      "[2892/8000] D loss: 0.7003, G loss: 13.8224\n",
      "[3252/8000] D loss: 0.5238, G loss: 9.8078\n",
      "[3612/8000] D loss: 1.1270, G loss: 8.5552\n",
      "[3972/8000] D loss: 0.5918, G loss: 7.9782\n",
      "[4332/8000] D loss: 0.9376, G loss: 7.8081\n",
      "[4692/8000] D loss: 0.5011, G loss: 10.1657\n",
      "[5052/8000] D loss: 0.9227, G loss: 5.4718\n",
      "[5412/8000] D loss: 0.8535, G loss: 5.5575\n",
      "[5772/8000] D loss: 0.8814, G loss: 7.6764\n",
      "[6132/8000] D loss: 0.7047, G loss: 12.6040\n",
      "[6492/8000] D loss: 0.7056, G loss: 5.8308\n",
      "[6852/8000] D loss: 0.8186, G loss: 5.0233\n",
      "[7212/8000] D loss: 0.9609, G loss: 4.0070\n",
      "[7572/8000] D loss: 0.7099, G loss: 9.1042\n",
      "[7932/8000] D loss: 0.8994, G loss: 5.1049\n",
      "train error: \n",
      " D loss: 0.855829, G loss: 7.427409, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.087484, G loss: 23.942064, D accuracy: 79.3%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.2476, G loss: 6.8051\n",
      "[372/8000] D loss: 1.0638, G loss: 2.9870\n",
      "[732/8000] D loss: 1.0432, G loss: 12.2059\n",
      "[1092/8000] D loss: 0.8366, G loss: 6.9707\n",
      "[1452/8000] D loss: 0.8027, G loss: 6.7021\n",
      "[1812/8000] D loss: 0.8383, G loss: 9.3129\n",
      "[2172/8000] D loss: 0.8033, G loss: 5.8423\n",
      "[2532/8000] D loss: 1.2726, G loss: 1.9886\n",
      "[2892/8000] D loss: 0.8146, G loss: 7.5860\n",
      "[3252/8000] D loss: 0.5658, G loss: 9.1134\n",
      "[3612/8000] D loss: 0.5791, G loss: 8.1251\n",
      "[3972/8000] D loss: 0.9442, G loss: 7.9060\n",
      "[4332/8000] D loss: 0.9021, G loss: 7.4617\n",
      "[4692/8000] D loss: 0.8307, G loss: 3.2495\n",
      "[5052/8000] D loss: 0.9201, G loss: 6.6704\n",
      "[5412/8000] D loss: 0.7695, G loss: 12.5259\n",
      "[5772/8000] D loss: 0.8306, G loss: 8.0442\n",
      "[6132/8000] D loss: 0.7811, G loss: 3.0617\n",
      "[6492/8000] D loss: 0.8927, G loss: 6.9309\n",
      "[6852/8000] D loss: 0.3749, G loss: 22.5554\n",
      "[7212/8000] D loss: 1.0838, G loss: 11.2377\n",
      "[7572/8000] D loss: 0.7000, G loss: 11.5047\n",
      "[7932/8000] D loss: 0.5636, G loss: 14.2965\n",
      "train error: \n",
      " D loss: 0.862225, G loss: 7.191733, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.899600, G loss: 23.214238, D accuracy: 81.1%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8984, G loss: 4.7375\n",
      "[372/8000] D loss: 1.0404, G loss: 8.2193\n",
      "[732/8000] D loss: 0.6679, G loss: 7.0841\n",
      "[1092/8000] D loss: 0.4550, G loss: 12.3401\n",
      "[1452/8000] D loss: 0.4710, G loss: 7.2023\n",
      "[1812/8000] D loss: 0.9401, G loss: 3.2996\n",
      "[2172/8000] D loss: 0.4654, G loss: 7.1631\n",
      "[2532/8000] D loss: 1.0829, G loss: 1.9136\n",
      "[2892/8000] D loss: 0.9427, G loss: 3.1285\n",
      "[3252/8000] D loss: 1.1323, G loss: 2.8925\n",
      "[3612/8000] D loss: 0.6995, G loss: 7.2900\n",
      "[3972/8000] D loss: 1.0387, G loss: 5.6680\n",
      "[4332/8000] D loss: 1.2607, G loss: 2.7421\n",
      "[4692/8000] D loss: 1.3068, G loss: 0.8482\n",
      "[5052/8000] D loss: 0.9508, G loss: 1.8564\n",
      "[5412/8000] D loss: 1.1361, G loss: 1.9170\n",
      "[5772/8000] D loss: 0.8140, G loss: 2.9525\n",
      "[6132/8000] D loss: 0.9284, G loss: 8.1464\n",
      "[6492/8000] D loss: 1.0008, G loss: 5.2149\n",
      "[6852/8000] D loss: 0.8568, G loss: 6.9292\n",
      "[7212/8000] D loss: 0.6482, G loss: 11.2290\n",
      "[7572/8000] D loss: 0.7693, G loss: 11.2085\n",
      "[7932/8000] D loss: 0.5615, G loss: 10.3359\n",
      "train error: \n",
      " D loss: 0.845561, G loss: 7.742280, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.099271, G loss: 23.796640, D accuracy: 76.9%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8973, G loss: 8.1537\n",
      "[372/8000] D loss: 0.9319, G loss: 4.6469\n",
      "[732/8000] D loss: 0.9399, G loss: 10.8918\n",
      "[1092/8000] D loss: 1.0358, G loss: 5.3642\n",
      "[1452/8000] D loss: 0.7812, G loss: 5.2230\n",
      "[1812/8000] D loss: 1.1330, G loss: 4.2102\n",
      "[2172/8000] D loss: 0.4839, G loss: 7.3152\n",
      "[2532/8000] D loss: 0.7320, G loss: 6.0180\n",
      "[2892/8000] D loss: 0.5013, G loss: 13.0459\n",
      "[3252/8000] D loss: 0.7160, G loss: 7.8414\n",
      "[3612/8000] D loss: 0.9726, G loss: 6.2529\n",
      "[3972/8000] D loss: 0.8459, G loss: 5.3900\n",
      "[4332/8000] D loss: 0.9074, G loss: 5.2096\n",
      "[4692/8000] D loss: 0.5284, G loss: 6.9752\n",
      "[5052/8000] D loss: 0.8193, G loss: 4.5410\n",
      "[5412/8000] D loss: 0.4771, G loss: 7.4474\n",
      "[5772/8000] D loss: 0.7901, G loss: 12.2875\n",
      "[6132/8000] D loss: 0.7571, G loss: 5.3597\n",
      "[6492/8000] D loss: 0.8427, G loss: 4.8590\n",
      "[6852/8000] D loss: 0.9012, G loss: 4.2728\n",
      "[7212/8000] D loss: 0.6782, G loss: 11.7144\n",
      "[7572/8000] D loss: 0.7883, G loss: 5.4244\n",
      "[7932/8000] D loss: 1.0542, G loss: 2.4096\n",
      "train error: \n",
      " D loss: 0.854341, G loss: 6.321608, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.030148, G loss: 20.010361, D accuracy: 78.1%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9185, G loss: 5.3587\n",
      "[372/8000] D loss: 0.6976, G loss: 10.1181\n",
      "[732/8000] D loss: 0.8007, G loss: 6.3051\n",
      "[1092/8000] D loss: 0.6918, G loss: 12.8477\n",
      "[1452/8000] D loss: 1.1263, G loss: 5.1322\n",
      "[1812/8000] D loss: 0.8532, G loss: 5.8252\n",
      "[2172/8000] D loss: 0.9826, G loss: 2.4616\n",
      "[2532/8000] D loss: 0.7012, G loss: 12.4895\n",
      "[2892/8000] D loss: 0.5935, G loss: 10.2758\n",
      "[3252/8000] D loss: 0.7243, G loss: 14.3673\n",
      "[3612/8000] D loss: 0.9690, G loss: 4.7282\n",
      "[3972/8000] D loss: 0.5340, G loss: 11.4700\n",
      "[4332/8000] D loss: 1.1381, G loss: 3.3292\n",
      "[4692/8000] D loss: 1.1539, G loss: 2.4137\n",
      "[5052/8000] D loss: 0.7014, G loss: 10.1101\n",
      "[5412/8000] D loss: 0.9556, G loss: 4.1765\n",
      "[5772/8000] D loss: 0.7093, G loss: 16.5955\n",
      "[6132/8000] D loss: 1.0459, G loss: 6.9814\n",
      "[6492/8000] D loss: 0.8298, G loss: 3.5553\n",
      "[6852/8000] D loss: 0.6986, G loss: 10.0602\n",
      "[7212/8000] D loss: 1.1733, G loss: 2.2086\n",
      "[7572/8000] D loss: 1.1547, G loss: 5.4952\n",
      "[7932/8000] D loss: 0.7003, G loss: 9.7794\n",
      "train error: \n",
      " D loss: 0.852465, G loss: 6.444291, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.919207, G loss: 20.483850, D accuracy: 81.2%, cell accuracy: 98.3%, board accuracy: 28.3% \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9213, G loss: 4.3728\n",
      "[372/8000] D loss: 1.0191, G loss: 3.6595\n",
      "[732/8000] D loss: 0.9078, G loss: 6.4404\n",
      "[1092/8000] D loss: 0.4830, G loss: 12.4495\n",
      "[1452/8000] D loss: 0.5931, G loss: 11.3441\n",
      "[1812/8000] D loss: 0.8632, G loss: 2.7191\n",
      "[2172/8000] D loss: 0.8174, G loss: 10.3789\n",
      "[2532/8000] D loss: 0.8111, G loss: 10.6484\n",
      "[2892/8000] D loss: 0.5770, G loss: 6.4809\n",
      "[3252/8000] D loss: 0.8860, G loss: 5.1109\n",
      "[3612/8000] D loss: 0.7540, G loss: 10.7729\n",
      "[3972/8000] D loss: 1.2847, G loss: 1.1397\n",
      "[4332/8000] D loss: 0.9448, G loss: 3.9024\n",
      "[4692/8000] D loss: 0.5922, G loss: 19.0351\n",
      "[5052/8000] D loss: 0.9434, G loss: 2.8478\n",
      "[5412/8000] D loss: 0.9803, G loss: 3.4372\n",
      "[5772/8000] D loss: 0.8160, G loss: 7.8640\n",
      "[6132/8000] D loss: 0.9057, G loss: 4.7535\n",
      "[6492/8000] D loss: 0.6958, G loss: 8.3700\n",
      "[6852/8000] D loss: 0.9547, G loss: 4.1966\n",
      "[7212/8000] D loss: 1.0439, G loss: 2.7517\n",
      "[7572/8000] D loss: 0.7044, G loss: 8.0728\n",
      "[7932/8000] D loss: 0.9231, G loss: 8.2453\n",
      "train error: \n",
      " D loss: 0.865396, G loss: 7.138225, D accuracy: 70.2%, cell accuracy: 98.8%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.097048, G loss: 22.000312, D accuracy: 73.7%, cell accuracy: 98.3%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8181, G loss: 6.7400\n",
      "[372/8000] D loss: 1.0554, G loss: 6.5349\n",
      "[732/8000] D loss: 1.4968, G loss: 2.0985\n",
      "[1092/8000] D loss: 1.0570, G loss: 4.1284\n",
      "[1452/8000] D loss: 0.7018, G loss: 8.7286\n",
      "[1812/8000] D loss: 0.7416, G loss: 9.0240\n",
      "[2172/8000] D loss: 1.1588, G loss: 3.0372\n",
      "[2532/8000] D loss: 0.7353, G loss: 9.0764\n",
      "[2892/8000] D loss: 0.5229, G loss: 10.2349\n",
      "[3252/8000] D loss: 0.7054, G loss: 13.9397\n",
      "[3612/8000] D loss: 0.9311, G loss: 6.8099\n",
      "[3972/8000] D loss: 0.5231, G loss: 13.3066\n",
      "[4332/8000] D loss: 0.7717, G loss: 5.3214\n",
      "[4692/8000] D loss: 0.9297, G loss: 2.2224\n",
      "[5052/8000] D loss: 1.0473, G loss: 5.7668\n",
      "[5412/8000] D loss: 1.3032, G loss: 0.9765\n",
      "[5772/8000] D loss: 1.0105, G loss: 5.0094\n",
      "[6132/8000] D loss: 1.0788, G loss: 6.3266\n",
      "[6492/8000] D loss: 1.0392, G loss: 2.2410\n",
      "[6852/8000] D loss: 0.9682, G loss: 6.1089\n",
      "[7212/8000] D loss: 1.0983, G loss: 4.0781\n",
      "[7572/8000] D loss: 0.6138, G loss: 11.9991\n",
      "[7932/8000] D loss: 1.2793, G loss: 5.8774\n",
      "train error: \n",
      " D loss: 0.850579, G loss: 6.849528, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.006166, G loss: 20.716842, D accuracy: 78.0%, cell accuracy: 98.3%, board accuracy: 30.2% \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8165, G loss: 7.1230\n",
      "[372/8000] D loss: 0.5896, G loss: 8.5200\n",
      "[732/8000] D loss: 0.7112, G loss: 5.4357\n",
      "[1092/8000] D loss: 1.1323, G loss: 7.8791\n",
      "[1452/8000] D loss: 1.0118, G loss: 3.1951\n",
      "[1812/8000] D loss: 0.9865, G loss: 5.7746\n",
      "[2172/8000] D loss: 1.1688, G loss: 1.6276\n",
      "[2532/8000] D loss: 0.7595, G loss: 8.1997\n",
      "[2892/8000] D loss: 0.5146, G loss: 18.5813\n",
      "[3252/8000] D loss: 1.0469, G loss: 4.8026\n",
      "[3612/8000] D loss: 0.6744, G loss: 7.2154\n",
      "[3972/8000] D loss: 0.6977, G loss: 9.8310\n",
      "[4332/8000] D loss: 0.9389, G loss: 8.1250\n",
      "[4692/8000] D loss: 0.7111, G loss: 10.4243\n",
      "[5052/8000] D loss: 0.9088, G loss: 8.1519\n",
      "[5412/8000] D loss: 0.9346, G loss: 6.7509\n",
      "[5772/8000] D loss: 1.0018, G loss: 5.1475\n",
      "[6132/8000] D loss: 1.0057, G loss: 2.9231\n",
      "[6492/8000] D loss: 0.9465, G loss: 4.6214\n",
      "[6852/8000] D loss: 0.6958, G loss: 8.8406\n",
      "[7212/8000] D loss: 1.0723, G loss: 4.6959\n",
      "[7572/8000] D loss: 1.1573, G loss: 6.3062\n",
      "[7932/8000] D loss: 0.8042, G loss: 6.4674\n",
      "train error: \n",
      " D loss: 0.861904, G loss: 6.445698, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.948692, G loss: 21.176761, D accuracy: 80.7%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7146, G loss: 6.7058\n",
      "[372/8000] D loss: 0.3538, G loss: 5.9017\n",
      "[732/8000] D loss: 0.6433, G loss: 10.8849\n",
      "[1092/8000] D loss: 0.8168, G loss: 7.6301\n",
      "[1452/8000] D loss: 0.7964, G loss: 3.2180\n",
      "[1812/8000] D loss: 0.9479, G loss: 2.2218\n",
      "[2172/8000] D loss: 0.8549, G loss: 3.3725\n",
      "[2532/8000] D loss: 0.5903, G loss: 7.1064\n",
      "[2892/8000] D loss: 0.7149, G loss: 7.5709\n",
      "[3252/8000] D loss: 0.7706, G loss: 9.0700\n",
      "[3612/8000] D loss: 1.0599, G loss: 2.5202\n",
      "[3972/8000] D loss: 1.0047, G loss: 3.2432\n",
      "[4332/8000] D loss: 0.8227, G loss: 8.1590\n",
      "[4692/8000] D loss: 0.5788, G loss: 7.2347\n",
      "[5052/8000] D loss: 0.8137, G loss: 9.5542\n",
      "[5412/8000] D loss: 0.5408, G loss: 10.8497\n",
      "[5772/8000] D loss: 0.5547, G loss: 5.8520\n",
      "[6132/8000] D loss: 0.9061, G loss: 4.4390\n",
      "[6492/8000] D loss: 0.7776, G loss: 4.0872\n",
      "[6852/8000] D loss: 0.9431, G loss: 10.0459\n",
      "[7212/8000] D loss: 0.5490, G loss: 11.1709\n",
      "[7572/8000] D loss: 0.9809, G loss: 6.0649\n",
      "[7932/8000] D loss: 0.8501, G loss: 3.3837\n",
      "train error: \n",
      " D loss: 0.854390, G loss: 5.687433, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.988305, G loss: 19.147536, D accuracy: 77.4%, cell accuracy: 98.3%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5668, G loss: 10.8350\n",
      "[372/8000] D loss: 1.1259, G loss: 2.1490\n",
      "[732/8000] D loss: 0.8475, G loss: 4.7100\n",
      "[1092/8000] D loss: 0.9755, G loss: 4.2244\n",
      "[1452/8000] D loss: 1.2074, G loss: 6.9810\n",
      "[1812/8000] D loss: 0.9380, G loss: 3.5255\n",
      "[2172/8000] D loss: 0.9379, G loss: 2.8358\n",
      "[2532/8000] D loss: 0.9677, G loss: 4.5834\n",
      "[2892/8000] D loss: 0.8753, G loss: 7.3337\n",
      "[3252/8000] D loss: 0.5917, G loss: 12.0985\n",
      "[3612/8000] D loss: 0.8340, G loss: 3.4753\n",
      "[3972/8000] D loss: 0.8588, G loss: 6.4454\n",
      "[4332/8000] D loss: 0.6575, G loss: 6.8948\n",
      "[4692/8000] D loss: 0.7514, G loss: 12.5778\n",
      "[5052/8000] D loss: 0.9171, G loss: 7.7290\n",
      "[5412/8000] D loss: 0.7908, G loss: 7.6281\n",
      "[5772/8000] D loss: 0.6041, G loss: 9.8811\n",
      "[6132/8000] D loss: 0.8319, G loss: 3.4625\n",
      "[6492/8000] D loss: 1.0868, G loss: 2.2098\n",
      "[6852/8000] D loss: 0.8426, G loss: 3.0450\n",
      "[7212/8000] D loss: 0.8834, G loss: 3.9434\n",
      "[7572/8000] D loss: 0.6988, G loss: 6.1795\n",
      "[7932/8000] D loss: 0.5735, G loss: 20.8056\n",
      "train error: \n",
      " D loss: 0.852200, G loss: 7.722451, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.015795, G loss: 23.796736, D accuracy: 77.4%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8106, G loss: 10.3594\n",
      "[372/8000] D loss: 0.8393, G loss: 3.9765\n",
      "[732/8000] D loss: 0.6088, G loss: 14.4252\n",
      "[1092/8000] D loss: 0.7491, G loss: 11.8775\n",
      "[1452/8000] D loss: 0.9985, G loss: 4.8773\n",
      "[1812/8000] D loss: 0.7354, G loss: 5.4295\n",
      "[2172/8000] D loss: 0.7583, G loss: 4.3481\n",
      "[2532/8000] D loss: 1.0622, G loss: 2.8288\n",
      "[2892/8000] D loss: 1.0955, G loss: 9.4453\n",
      "[3252/8000] D loss: 0.8266, G loss: 3.9187\n",
      "[3612/8000] D loss: 0.8823, G loss: 6.2114\n",
      "[3972/8000] D loss: 1.0377, G loss: 3.0655\n",
      "[4332/8000] D loss: 0.5821, G loss: 7.5619\n",
      "[4692/8000] D loss: 0.7230, G loss: 15.4659\n",
      "[5052/8000] D loss: 1.1352, G loss: 1.3474\n",
      "[5412/8000] D loss: 0.7505, G loss: 6.0815\n",
      "[5772/8000] D loss: 0.8193, G loss: 11.6915\n",
      "[6132/8000] D loss: 0.8461, G loss: 4.4792\n",
      "[6492/8000] D loss: 0.8721, G loss: 7.0925\n",
      "[6852/8000] D loss: 0.6325, G loss: 9.9129\n",
      "[7212/8000] D loss: 0.5780, G loss: 10.7129\n",
      "[7572/8000] D loss: 0.8213, G loss: 7.7300\n",
      "[7932/8000] D loss: 0.8269, G loss: 6.2365\n",
      "train error: \n",
      " D loss: 0.855337, G loss: 5.616889, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.935811, G loss: 18.318325, D accuracy: 78.2%, cell accuracy: 98.3%, board accuracy: 30.2% \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6139, G loss: 9.7004\n",
      "[372/8000] D loss: 0.3475, G loss: 15.4964\n",
      "[732/8000] D loss: 0.8042, G loss: 12.9910\n",
      "[1092/8000] D loss: 0.5987, G loss: 11.1709\n",
      "[1452/8000] D loss: 0.7177, G loss: 13.1454\n",
      "[1812/8000] D loss: 0.7492, G loss: 9.4004\n",
      "[2172/8000] D loss: 0.9855, G loss: 6.4443\n",
      "[2532/8000] D loss: 1.0425, G loss: 5.1954\n",
      "[2892/8000] D loss: 0.9286, G loss: 7.1556\n",
      "[3252/8000] D loss: 0.8872, G loss: 6.0596\n",
      "[3612/8000] D loss: 0.6979, G loss: 8.8172\n",
      "[3972/8000] D loss: 1.1720, G loss: 1.1161\n",
      "[4332/8000] D loss: 0.6139, G loss: 10.5430\n",
      "[4692/8000] D loss: 0.7012, G loss: 9.8748\n",
      "[5052/8000] D loss: 0.8443, G loss: 5.4986\n",
      "[5412/8000] D loss: 0.9247, G loss: 3.5695\n",
      "[5772/8000] D loss: 0.6309, G loss: 15.8196\n",
      "[6132/8000] D loss: 0.6349, G loss: 7.7324\n",
      "[6492/8000] D loss: 0.4752, G loss: 13.1826\n",
      "[6852/8000] D loss: 0.9989, G loss: 5.0064\n",
      "[7212/8000] D loss: 1.0694, G loss: 3.1676\n",
      "[7572/8000] D loss: 1.0368, G loss: 7.1491\n",
      "[7932/8000] D loss: 1.0274, G loss: 6.7790\n",
      "train error: \n",
      " D loss: 0.856077, G loss: 7.888539, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.036723, G loss: 23.796239, D accuracy: 75.9%, cell accuracy: 98.3%, board accuracy: 31.0% \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3209, G loss: 27.4883\n",
      "[372/8000] D loss: 0.9439, G loss: 4.9132\n",
      "[732/8000] D loss: 1.2542, G loss: 2.3785\n",
      "[1092/8000] D loss: 0.6868, G loss: 6.8136\n",
      "[1452/8000] D loss: 0.8439, G loss: 11.6352\n",
      "[1812/8000] D loss: 0.8099, G loss: 9.0024\n",
      "[2172/8000] D loss: 0.7544, G loss: 8.0871\n",
      "[2532/8000] D loss: 0.6541, G loss: 6.5129\n",
      "[2892/8000] D loss: 0.7786, G loss: 9.5827\n",
      "[3252/8000] D loss: 1.2491, G loss: 3.7546\n",
      "[3612/8000] D loss: 0.6159, G loss: 7.6237\n",
      "[3972/8000] D loss: 1.0366, G loss: 6.4303\n",
      "[4332/8000] D loss: 0.8136, G loss: 9.6298\n",
      "[4692/8000] D loss: 0.5045, G loss: 10.9696\n",
      "[5052/8000] D loss: 0.8132, G loss: 11.6866\n",
      "[5412/8000] D loss: 1.0787, G loss: 1.8520\n",
      "[5772/8000] D loss: 0.8404, G loss: 2.8352\n",
      "[6132/8000] D loss: 1.0382, G loss: 1.4736\n",
      "[6492/8000] D loss: 0.7703, G loss: 5.2038\n",
      "[6852/8000] D loss: 0.8274, G loss: 5.5672\n",
      "[7212/8000] D loss: 0.6943, G loss: 10.9746\n",
      "[7572/8000] D loss: 0.7603, G loss: 4.8142\n",
      "[7932/8000] D loss: 1.1405, G loss: 1.3862\n",
      "train error: \n",
      " D loss: 0.852250, G loss: 7.990493, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.052416, G loss: 23.572067, D accuracy: 78.4%, cell accuracy: 98.3%, board accuracy: 29.4% \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8131, G loss: 6.7479\n",
      "[372/8000] D loss: 1.0581, G loss: 2.1695\n",
      "[732/8000] D loss: 1.2089, G loss: 5.0075\n",
      "[1092/8000] D loss: 0.7476, G loss: 9.4980\n",
      "[1452/8000] D loss: 0.8940, G loss: 10.0092\n",
      "[1812/8000] D loss: 1.1796, G loss: 5.4247\n",
      "[2172/8000] D loss: 1.0878, G loss: 3.7240\n",
      "[2532/8000] D loss: 0.9265, G loss: 4.3694\n",
      "[2892/8000] D loss: 0.6484, G loss: 7.8885\n",
      "[3252/8000] D loss: 0.7010, G loss: 5.5763\n",
      "[3612/8000] D loss: 1.0934, G loss: 2.8792\n",
      "[3972/8000] D loss: 1.0026, G loss: 11.1803\n",
      "[4332/8000] D loss: 1.1729, G loss: 1.8063\n",
      "[4692/8000] D loss: 0.5338, G loss: 9.5424\n",
      "[5052/8000] D loss: 0.8937, G loss: 4.7368\n",
      "[5412/8000] D loss: 0.8568, G loss: 9.2651\n",
      "[5772/8000] D loss: 0.8467, G loss: 4.0488\n",
      "[6132/8000] D loss: 0.8498, G loss: 9.1372\n",
      "[6492/8000] D loss: 0.8208, G loss: 8.2318\n",
      "[6852/8000] D loss: 0.6965, G loss: 11.1143\n",
      "[7212/8000] D loss: 1.0153, G loss: 7.5901\n",
      "[7572/8000] D loss: 0.9954, G loss: 2.0639\n",
      "[7932/8000] D loss: 0.9323, G loss: 12.2434\n",
      "train error: \n",
      " D loss: 0.854777, G loss: 7.783486, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.070258, G loss: 23.625863, D accuracy: 78.9%, cell accuracy: 98.3%, board accuracy: 30.2% \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8385, G loss: 10.2143\n",
      "[372/8000] D loss: 1.1014, G loss: 3.9503\n",
      "[732/8000] D loss: 0.7791, G loss: 9.9593\n",
      "[1092/8000] D loss: 0.8334, G loss: 6.9148\n",
      "[1452/8000] D loss: 0.8376, G loss: 4.7131\n",
      "[1812/8000] D loss: 0.8143, G loss: 11.0480\n",
      "[2172/8000] D loss: 0.9516, G loss: 9.9091\n",
      "[2532/8000] D loss: 0.9927, G loss: 5.4042\n",
      "[2892/8000] D loss: 0.5379, G loss: 8.5720\n",
      "[3252/8000] D loss: 0.9053, G loss: 5.3523\n",
      "[3612/8000] D loss: 0.8336, G loss: 4.9014\n",
      "[3972/8000] D loss: 1.3011, G loss: 6.5048\n",
      "[4332/8000] D loss: 1.1175, G loss: 2.7931\n",
      "[4692/8000] D loss: 0.6824, G loss: 4.7931\n",
      "[5052/8000] D loss: 1.0437, G loss: 3.7536\n",
      "[5412/8000] D loss: 0.9354, G loss: 4.4614\n",
      "[5772/8000] D loss: 0.7244, G loss: 6.1191\n",
      "[6132/8000] D loss: 0.9335, G loss: 5.9762\n",
      "[6492/8000] D loss: 0.6127, G loss: 6.3113\n",
      "[6852/8000] D loss: 0.5618, G loss: 9.2480\n",
      "[7212/8000] D loss: 0.5840, G loss: 13.1746\n",
      "[7572/8000] D loss: 0.4717, G loss: 9.5065\n",
      "[7932/8000] D loss: 1.1050, G loss: 3.6352\n",
      "train error: \n",
      " D loss: 0.852246, G loss: 6.534215, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.019331, G loss: 20.411645, D accuracy: 78.3%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7102, G loss: 8.4841\n",
      "[372/8000] D loss: 0.8281, G loss: 7.5759\n",
      "[732/8000] D loss: 0.7403, G loss: 12.5814\n",
      "[1092/8000] D loss: 0.5809, G loss: 8.1517\n",
      "[1452/8000] D loss: 0.8123, G loss: 6.9528\n",
      "[1812/8000] D loss: 1.3079, G loss: 0.9855\n",
      "[2172/8000] D loss: 0.9336, G loss: 7.9456\n",
      "[2532/8000] D loss: 0.6907, G loss: 8.3840\n",
      "[2892/8000] D loss: 0.8316, G loss: 8.5286\n",
      "[3252/8000] D loss: 0.9539, G loss: 3.6094\n",
      "[3612/8000] D loss: 0.9104, G loss: 7.4683\n",
      "[3972/8000] D loss: 0.9969, G loss: 7.6117\n",
      "[4332/8000] D loss: 0.6936, G loss: 9.2268\n",
      "[4692/8000] D loss: 0.6751, G loss: 6.3848\n",
      "[5052/8000] D loss: 0.7952, G loss: 7.3606\n",
      "[5412/8000] D loss: 0.7052, G loss: 8.2254\n",
      "[5772/8000] D loss: 1.2547, G loss: 2.4971\n",
      "[6132/8000] D loss: 1.1608, G loss: 3.2019\n",
      "[6492/8000] D loss: 0.9200, G loss: 8.0688\n",
      "[6852/8000] D loss: 0.4561, G loss: 7.7621\n",
      "[7212/8000] D loss: 0.8407, G loss: 10.1621\n",
      "[7572/8000] D loss: 0.6498, G loss: 8.2797\n",
      "[7932/8000] D loss: 0.6766, G loss: 9.4567\n",
      "train error: \n",
      " D loss: 0.873397, G loss: 5.943023, D accuracy: 70.5%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.131682, G loss: 19.801845, D accuracy: 75.3%, cell accuracy: 98.3%, board accuracy: 29.4% \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0090, G loss: 4.5328\n",
      "[372/8000] D loss: 0.8350, G loss: 7.2444\n",
      "[732/8000] D loss: 0.5857, G loss: 11.7828\n",
      "[1092/8000] D loss: 0.8178, G loss: 2.5518\n",
      "[1452/8000] D loss: 1.1675, G loss: 4.1688\n",
      "[1812/8000] D loss: 0.8372, G loss: 3.9841\n",
      "[2172/8000] D loss: 0.6773, G loss: 14.4633\n",
      "[2532/8000] D loss: 0.9220, G loss: 4.1936\n",
      "[2892/8000] D loss: 0.7827, G loss: 10.0627\n",
      "[3252/8000] D loss: 0.5886, G loss: 10.1115\n",
      "[3612/8000] D loss: 0.8096, G loss: 12.0604\n",
      "[3972/8000] D loss: 0.8603, G loss: 3.7241\n",
      "[4332/8000] D loss: 0.6825, G loss: 7.2622\n",
      "[4692/8000] D loss: 0.5225, G loss: 8.6210\n",
      "[5052/8000] D loss: 0.7055, G loss: 8.8302\n",
      "[5412/8000] D loss: 0.9413, G loss: 4.6743\n",
      "[5772/8000] D loss: 0.8234, G loss: 8.0997\n",
      "[6132/8000] D loss: 0.6108, G loss: 13.1041\n",
      "[6492/8000] D loss: 0.7036, G loss: 7.7019\n",
      "[6852/8000] D loss: 1.1189, G loss: 2.1036\n",
      "[7212/8000] D loss: 0.9060, G loss: 3.4142\n",
      "[7572/8000] D loss: 0.7809, G loss: 8.2869\n",
      "[7932/8000] D loss: 0.8778, G loss: 4.7338\n",
      "train error: \n",
      " D loss: 0.850220, G loss: 6.673328, D accuracy: 71.2%, cell accuracy: 98.8%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.050216, G loss: 21.346960, D accuracy: 78.7%, cell accuracy: 98.3%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6416, G loss: 11.9531\n",
      "[372/8000] D loss: 0.7821, G loss: 11.2374\n",
      "[732/8000] D loss: 0.5465, G loss: 5.5851\n",
      "[1092/8000] D loss: 0.5805, G loss: 11.4821\n",
      "[1452/8000] D loss: 0.6808, G loss: 7.2133\n",
      "[1812/8000] D loss: 0.9191, G loss: 8.8399\n",
      "[2172/8000] D loss: 0.8140, G loss: 6.6409\n",
      "[2532/8000] D loss: 1.0582, G loss: 5.6530\n",
      "[2892/8000] D loss: 1.0354, G loss: 6.4596\n",
      "[3252/8000] D loss: 0.9331, G loss: 7.8970\n",
      "[3612/8000] D loss: 0.7706, G loss: 10.5380\n",
      "[3972/8000] D loss: 0.9571, G loss: 8.9106\n",
      "[4332/8000] D loss: 0.9151, G loss: 3.6604\n",
      "[4692/8000] D loss: 1.0687, G loss: 2.8439\n",
      "[5052/8000] D loss: 0.8930, G loss: 9.4162\n",
      "[5412/8000] D loss: 0.7765, G loss: 7.0661\n",
      "[5772/8000] D loss: 1.0406, G loss: 5.4999\n",
      "[6132/8000] D loss: 0.8470, G loss: 6.5176\n",
      "[6492/8000] D loss: 0.8452, G loss: 4.5720\n",
      "[6852/8000] D loss: 0.7568, G loss: 16.8708\n",
      "[7212/8000] D loss: 0.8158, G loss: 6.1039\n",
      "[7572/8000] D loss: 0.8033, G loss: 5.1196\n",
      "[7932/8000] D loss: 1.0169, G loss: 2.5187\n",
      "train error: \n",
      " D loss: 0.859416, G loss: 5.435657, D accuracy: 70.5%, cell accuracy: 98.8%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.028839, G loss: 18.088250, D accuracy: 75.3%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5842, G loss: 7.9086\n",
      "[372/8000] D loss: 0.9475, G loss: 9.3720\n",
      "[732/8000] D loss: 0.3551, G loss: 14.0031\n",
      "[1092/8000] D loss: 0.5825, G loss: 8.5505\n",
      "[1452/8000] D loss: 0.9302, G loss: 6.6879\n",
      "[1812/8000] D loss: 0.9658, G loss: 3.4789\n",
      "[2172/8000] D loss: 1.1412, G loss: 7.3132\n",
      "[2532/8000] D loss: 1.0173, G loss: 12.8915\n",
      "[2892/8000] D loss: 1.0795, G loss: 6.7306\n",
      "[3252/8000] D loss: 0.8661, G loss: 10.1182\n",
      "[3612/8000] D loss: 0.7083, G loss: 8.6903\n",
      "[3972/8000] D loss: 1.2282, G loss: 2.4185\n",
      "[4332/8000] D loss: 0.5963, G loss: 12.7602\n",
      "[4692/8000] D loss: 0.9336, G loss: 11.2156\n",
      "[5052/8000] D loss: 0.6434, G loss: 10.0193\n",
      "[5412/8000] D loss: 1.1679, G loss: 4.9019\n",
      "[5772/8000] D loss: 0.7155, G loss: 4.0047\n",
      "[6132/8000] D loss: 0.6043, G loss: 9.0253\n",
      "[6492/8000] D loss: 0.4362, G loss: 16.2066\n",
      "[6852/8000] D loss: 0.7610, G loss: 6.8015\n",
      "[7212/8000] D loss: 0.9887, G loss: 2.7484\n",
      "[7572/8000] D loss: 0.8008, G loss: 6.8222\n",
      "[7932/8000] D loss: 0.6328, G loss: 14.4710\n",
      "train error: \n",
      " D loss: 0.848268, G loss: 7.871975, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.054421, G loss: 24.245379, D accuracy: 80.0%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7796, G loss: 7.0066\n",
      "[372/8000] D loss: 0.9379, G loss: 5.7706\n",
      "[732/8000] D loss: 0.9131, G loss: 5.7219\n",
      "[1092/8000] D loss: 0.5270, G loss: 15.1093\n",
      "[1452/8000] D loss: 0.6639, G loss: 5.5045\n",
      "[1812/8000] D loss: 0.5270, G loss: 9.8968\n",
      "[2172/8000] D loss: 0.8810, G loss: 3.8381\n",
      "[2532/8000] D loss: 0.7084, G loss: 7.8492\n",
      "[2892/8000] D loss: 0.7141, G loss: 9.0934\n",
      "[3252/8000] D loss: 1.0186, G loss: 9.9348\n",
      "[3612/8000] D loss: 0.5826, G loss: 15.2653\n",
      "[3972/8000] D loss: 1.0398, G loss: 1.9571\n",
      "[4332/8000] D loss: 0.6431, G loss: 11.3226\n",
      "[4692/8000] D loss: 0.8093, G loss: 10.8874\n",
      "[5052/8000] D loss: 0.6200, G loss: 7.9979\n",
      "[5412/8000] D loss: 1.1409, G loss: 1.1582\n",
      "[5772/8000] D loss: 0.9264, G loss: 8.2811\n",
      "[6132/8000] D loss: 1.0340, G loss: 6.8318\n",
      "[6492/8000] D loss: 1.0229, G loss: 3.7629\n",
      "[6852/8000] D loss: 1.0156, G loss: 4.7995\n",
      "[7212/8000] D loss: 0.6735, G loss: 11.0576\n",
      "[7572/8000] D loss: 0.8963, G loss: 3.7837\n",
      "[7932/8000] D loss: 0.8724, G loss: 8.4854\n",
      "train error: \n",
      " D loss: 0.854482, G loss: 7.650682, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.023462, G loss: 23.326984, D accuracy: 78.2%, cell accuracy: 98.3%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8112, G loss: 9.1817\n",
      "[372/8000] D loss: 1.0131, G loss: 4.0307\n",
      "[732/8000] D loss: 1.0058, G loss: 10.8903\n",
      "[1092/8000] D loss: 1.0296, G loss: 3.4894\n",
      "[1452/8000] D loss: 1.1476, G loss: 4.1907\n",
      "[1812/8000] D loss: 0.5655, G loss: 17.6877\n",
      "[2172/8000] D loss: 0.9232, G loss: 4.6595\n",
      "[2532/8000] D loss: 0.8174, G loss: 5.8142\n",
      "[2892/8000] D loss: 0.6408, G loss: 14.4610\n",
      "[3252/8000] D loss: 0.5867, G loss: 10.1571\n",
      "[3612/8000] D loss: 1.0217, G loss: 3.3028\n",
      "[3972/8000] D loss: 0.9389, G loss: 5.0440\n",
      "[4332/8000] D loss: 0.5843, G loss: 5.5419\n",
      "[4692/8000] D loss: 0.9669, G loss: 5.1678\n",
      "[5052/8000] D loss: 0.6515, G loss: 10.5631\n",
      "[5412/8000] D loss: 1.0544, G loss: 3.7024\n",
      "[5772/8000] D loss: 0.6945, G loss: 5.3756\n",
      "[6132/8000] D loss: 0.8199, G loss: 3.3724\n",
      "[6492/8000] D loss: 0.7761, G loss: 10.9206\n",
      "[6852/8000] D loss: 0.7713, G loss: 3.6550\n",
      "[7212/8000] D loss: 1.0192, G loss: 4.7034\n",
      "[7572/8000] D loss: 1.0744, G loss: 9.1407\n",
      "[7932/8000] D loss: 0.8362, G loss: 9.9468\n",
      "train error: \n",
      " D loss: 0.852109, G loss: 5.877524, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.058253, G loss: 19.082400, D accuracy: 77.0%, cell accuracy: 98.3%, board accuracy: 30.2% \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0425, G loss: 2.6608\n",
      "[372/8000] D loss: 0.8058, G loss: 3.7354\n",
      "[732/8000] D loss: 0.7452, G loss: 5.1357\n",
      "[1092/8000] D loss: 0.8902, G loss: 7.3128\n",
      "[1452/8000] D loss: 0.8377, G loss: 4.9757\n",
      "[1812/8000] D loss: 0.8372, G loss: 5.5009\n",
      "[2172/8000] D loss: 0.7802, G loss: 5.7751\n",
      "[2532/8000] D loss: 0.9314, G loss: 11.9836\n",
      "[2892/8000] D loss: 0.9660, G loss: 4.8297\n",
      "[3252/8000] D loss: 0.7056, G loss: 10.8615\n",
      "[3612/8000] D loss: 0.8752, G loss: 4.5061\n",
      "[3972/8000] D loss: 0.9345, G loss: 7.2365\n",
      "[4332/8000] D loss: 0.5829, G loss: 9.0689\n",
      "[4692/8000] D loss: 0.8568, G loss: 5.2632\n",
      "[5052/8000] D loss: 0.9613, G loss: 9.1300\n",
      "[5412/8000] D loss: 0.8169, G loss: 3.2332\n",
      "[5772/8000] D loss: 0.7219, G loss: 6.5529\n",
      "[6132/8000] D loss: 0.5486, G loss: 9.2868\n",
      "[6492/8000] D loss: 0.7183, G loss: 3.9769\n",
      "[6852/8000] D loss: 0.8766, G loss: 6.2279\n",
      "[7212/8000] D loss: 1.0816, G loss: 2.5695\n",
      "[7572/8000] D loss: 0.7083, G loss: 3.8130\n",
      "[7932/8000] D loss: 0.4813, G loss: 7.0055\n",
      "train error: \n",
      " D loss: 0.870188, G loss: 5.958029, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.131795, G loss: 20.017439, D accuracy: 76.3%, cell accuracy: 98.3%, board accuracy: 30.3% \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7189, G loss: 9.6025\n",
      "[372/8000] D loss: 1.0609, G loss: 5.3834\n",
      "[732/8000] D loss: 0.9238, G loss: 9.2943\n",
      "[1092/8000] D loss: 0.8153, G loss: 5.2990\n",
      "[1452/8000] D loss: 1.0630, G loss: 4.5498\n",
      "[1812/8000] D loss: 0.7585, G loss: 10.6962\n",
      "[2172/8000] D loss: 0.8256, G loss: 10.0145\n",
      "[2532/8000] D loss: 0.9876, G loss: 3.8239\n",
      "[2892/8000] D loss: 0.9435, G loss: 9.0611\n",
      "[3252/8000] D loss: 1.0376, G loss: 8.3031\n",
      "[3612/8000] D loss: 0.6258, G loss: 6.9175\n",
      "[3972/8000] D loss: 1.1888, G loss: 2.0096\n",
      "[4332/8000] D loss: 0.8853, G loss: 6.6143\n",
      "[4692/8000] D loss: 0.8313, G loss: 7.8906\n",
      "[5052/8000] D loss: 0.7055, G loss: 4.4553\n",
      "[5412/8000] D loss: 0.7056, G loss: 5.6869\n",
      "[5772/8000] D loss: 0.8759, G loss: 9.0721\n",
      "[6132/8000] D loss: 0.8069, G loss: 10.4786\n",
      "[6492/8000] D loss: 0.8783, G loss: 7.7210\n",
      "[6852/8000] D loss: 0.9264, G loss: 8.9823\n",
      "[7212/8000] D loss: 1.0383, G loss: 7.4723\n",
      "[7572/8000] D loss: 1.0332, G loss: 6.5862\n",
      "[7932/8000] D loss: 0.6251, G loss: 5.5865\n",
      "train error: \n",
      " D loss: 0.847905, G loss: 8.016245, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.075434, G loss: 23.803844, D accuracy: 79.0%, cell accuracy: 98.3%, board accuracy: 30.4% \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8216, G loss: 9.4922\n",
      "[372/8000] D loss: 0.8008, G loss: 11.7853\n",
      "[732/8000] D loss: 0.7059, G loss: 8.7242\n",
      "[1092/8000] D loss: 1.0308, G loss: 9.3820\n",
      "[1452/8000] D loss: 1.0382, G loss: 2.1791\n",
      "[1812/8000] D loss: 0.3869, G loss: 9.7304\n",
      "[2172/8000] D loss: 1.1557, G loss: 1.9950\n",
      "[2532/8000] D loss: 0.6582, G loss: 9.3013\n",
      "[2892/8000] D loss: 0.6071, G loss: 4.9688\n",
      "[3252/8000] D loss: 0.6640, G loss: 8.9158\n",
      "[3612/8000] D loss: 0.9292, G loss: 2.6878\n",
      "[3972/8000] D loss: 0.4671, G loss: 6.8107\n",
      "[4332/8000] D loss: 0.5572, G loss: 11.5582\n",
      "[4692/8000] D loss: 0.4663, G loss: 15.3328\n",
      "[5052/8000] D loss: 0.8201, G loss: 3.7448\n",
      "[5412/8000] D loss: 0.7112, G loss: 3.8104\n",
      "[5772/8000] D loss: 0.7767, G loss: 10.2615\n",
      "[6132/8000] D loss: 1.3874, G loss: 0.6490\n",
      "[6492/8000] D loss: 0.8992, G loss: 3.5751\n",
      "[6852/8000] D loss: 1.0609, G loss: 11.3427\n",
      "[7212/8000] D loss: 0.9584, G loss: 7.9053\n",
      "[7572/8000] D loss: 0.8224, G loss: 4.1857\n",
      "[7932/8000] D loss: 0.5414, G loss: 16.6904\n",
      "train error: \n",
      " D loss: 0.871243, G loss: 7.269954, D accuracy: 70.3%, cell accuracy: 98.8%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.990462, G loss: 22.002533, D accuracy: 77.1%, cell accuracy: 98.3%, board accuracy: 30.7% \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8133, G loss: 7.3035\n",
      "[372/8000] D loss: 1.1811, G loss: 3.5601\n",
      "[732/8000] D loss: 0.3920, G loss: 12.0562\n",
      "[1092/8000] D loss: 1.0373, G loss: 3.3081\n",
      "[1452/8000] D loss: 0.6849, G loss: 8.2165\n",
      "[1812/8000] D loss: 0.7491, G loss: 4.4812\n",
      "[2172/8000] D loss: 1.0729, G loss: 3.1325\n",
      "[2532/8000] D loss: 0.9218, G loss: 5.1385\n",
      "[2892/8000] D loss: 0.7567, G loss: 9.5908\n",
      "[3252/8000] D loss: 1.1257, G loss: 2.5787\n",
      "[3612/8000] D loss: 0.7646, G loss: 6.2929\n",
      "[3972/8000] D loss: 0.6162, G loss: 6.1576\n",
      "[4332/8000] D loss: 0.8919, G loss: 8.9536\n",
      "[4692/8000] D loss: 0.9188, G loss: 6.1806\n",
      "[5052/8000] D loss: 0.7682, G loss: 6.7504\n",
      "[5412/8000] D loss: 1.0402, G loss: 3.3216\n",
      "[5772/8000] D loss: 0.9350, G loss: 2.4063\n",
      "[6132/8000] D loss: 0.9764, G loss: 9.0553\n",
      "[6492/8000] D loss: 0.9168, G loss: 5.0415\n",
      "[6852/8000] D loss: 1.1821, G loss: 4.3070\n",
      "[7212/8000] D loss: 0.6837, G loss: 4.6564\n",
      "[7572/8000] D loss: 1.0478, G loss: 2.1002\n",
      "[7932/8000] D loss: 1.0513, G loss: 6.9324\n",
      "train error: \n",
      " D loss: 0.873793, G loss: 8.580915, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.115364, G loss: 24.943796, D accuracy: 75.4%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0333, G loss: 5.2372\n",
      "[372/8000] D loss: 0.9532, G loss: 3.3298\n",
      "[732/8000] D loss: 0.7535, G loss: 8.7697\n",
      "[1092/8000] D loss: 0.7326, G loss: 6.4259\n",
      "[1452/8000] D loss: 0.8034, G loss: 8.9829\n",
      "[1812/8000] D loss: 0.6290, G loss: 8.8654\n",
      "[2172/8000] D loss: 1.2591, G loss: 2.8430\n",
      "[2532/8000] D loss: 0.9556, G loss: 3.2869\n",
      "[2892/8000] D loss: 0.8164, G loss: 3.3212\n",
      "[3252/8000] D loss: 0.5973, G loss: 7.8834\n",
      "[3612/8000] D loss: 1.1748, G loss: 6.3810\n",
      "[3972/8000] D loss: 0.5813, G loss: 11.3651\n",
      "[4332/8000] D loss: 0.7184, G loss: 8.1515\n",
      "[4692/8000] D loss: 0.8661, G loss: 9.4179\n",
      "[5052/8000] D loss: 0.6569, G loss: 14.5772\n",
      "[5412/8000] D loss: 1.0248, G loss: 1.9486\n",
      "[5772/8000] D loss: 0.7259, G loss: 7.6460\n",
      "[6132/8000] D loss: 0.5227, G loss: 8.9863\n",
      "[6492/8000] D loss: 1.0127, G loss: 12.1168\n",
      "[6852/8000] D loss: 0.5827, G loss: 11.7214\n",
      "[7212/8000] D loss: 0.7560, G loss: 9.3219\n",
      "[7572/8000] D loss: 0.9426, G loss: 3.8688\n",
      "[7932/8000] D loss: 1.1225, G loss: 4.8341\n",
      "train error: \n",
      " D loss: 0.855892, G loss: 7.266155, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.010854, G loss: 22.490665, D accuracy: 78.8%, cell accuracy: 98.3%, board accuracy: 29.4% \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1648, G loss: 2.5919\n",
      "[372/8000] D loss: 0.9467, G loss: 3.9045\n",
      "[732/8000] D loss: 1.0337, G loss: 7.8517\n",
      "[1092/8000] D loss: 1.2238, G loss: 1.7929\n",
      "[1452/8000] D loss: 0.6608, G loss: 14.6435\n",
      "[1812/8000] D loss: 0.8423, G loss: 8.1335\n",
      "[2172/8000] D loss: 0.9828, G loss: 4.1798\n",
      "[2532/8000] D loss: 0.6891, G loss: 9.6568\n",
      "[2892/8000] D loss: 0.6751, G loss: 9.3913\n",
      "[3252/8000] D loss: 0.8792, G loss: 14.9411\n",
      "[3612/8000] D loss: 0.9656, G loss: 8.4954\n",
      "[3972/8000] D loss: 0.9251, G loss: 6.3803\n",
      "[4332/8000] D loss: 0.8738, G loss: 5.2179\n",
      "[4692/8000] D loss: 0.7589, G loss: 14.8683\n",
      "[5052/8000] D loss: 0.6744, G loss: 8.2446\n",
      "[5412/8000] D loss: 1.1247, G loss: 4.3579\n",
      "[5772/8000] D loss: 0.8864, G loss: 3.4138\n",
      "[6132/8000] D loss: 0.8298, G loss: 10.0380\n",
      "[6492/8000] D loss: 1.2757, G loss: 1.3785\n",
      "[6852/8000] D loss: 0.5619, G loss: 14.5022\n",
      "[7212/8000] D loss: 0.8267, G loss: 4.7882\n",
      "[7572/8000] D loss: 0.9303, G loss: 4.4567\n",
      "[7932/8000] D loss: 0.6924, G loss: 11.8697\n",
      "train error: \n",
      " D loss: 0.872166, G loss: 5.382635, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.920310, G loss: 18.022553, D accuracy: 78.7%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3823, G loss: 4.6032\n",
      "[372/8000] D loss: 1.0400, G loss: 3.8774\n",
      "[732/8000] D loss: 0.8995, G loss: 9.8133\n",
      "[1092/8000] D loss: 0.9008, G loss: 4.4773\n",
      "[1452/8000] D loss: 1.1609, G loss: 1.5436\n",
      "[1812/8000] D loss: 0.7016, G loss: 12.4332\n",
      "[2172/8000] D loss: 0.9962, G loss: 3.8928\n",
      "[2532/8000] D loss: 0.9346, G loss: 5.4165\n",
      "[2892/8000] D loss: 0.8616, G loss: 9.4367\n",
      "[3252/8000] D loss: 0.6996, G loss: 5.8548\n",
      "[3612/8000] D loss: 0.7097, G loss: 6.2851\n",
      "[3972/8000] D loss: 0.9305, G loss: 4.9572\n",
      "[4332/8000] D loss: 0.8045, G loss: 7.5257\n",
      "[4692/8000] D loss: 0.8959, G loss: 9.4878\n",
      "[5052/8000] D loss: 0.8354, G loss: 7.4831\n",
      "[5412/8000] D loss: 0.5887, G loss: 11.5656\n",
      "[5772/8000] D loss: 0.9345, G loss: 9.5053\n",
      "[6132/8000] D loss: 1.1852, G loss: 3.7513\n",
      "[6492/8000] D loss: 0.7541, G loss: 8.1234\n",
      "[6852/8000] D loss: 0.6985, G loss: 10.2614\n",
      "[7212/8000] D loss: 0.6936, G loss: 10.4694\n",
      "[7572/8000] D loss: 0.9628, G loss: 9.5454\n",
      "[7932/8000] D loss: 0.8915, G loss: 5.5835\n",
      "train error: \n",
      " D loss: 0.862166, G loss: 6.354168, D accuracy: 70.5%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.922244, G loss: 20.051651, D accuracy: 81.5%, cell accuracy: 98.3%, board accuracy: 29.9% \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8442, G loss: 3.8771\n",
      "[372/8000] D loss: 1.1475, G loss: 8.4382\n",
      "[732/8000] D loss: 0.9640, G loss: 3.3214\n",
      "[1092/8000] D loss: 0.8154, G loss: 9.3684\n",
      "[1452/8000] D loss: 0.8159, G loss: 9.6035\n",
      "[1812/8000] D loss: 0.9243, G loss: 4.1459\n",
      "[2172/8000] D loss: 0.5968, G loss: 14.3376\n",
      "[2532/8000] D loss: 0.7001, G loss: 12.1021\n",
      "[2892/8000] D loss: 0.7714, G loss: 12.8654\n",
      "[3252/8000] D loss: 0.5121, G loss: 8.4551\n",
      "[3612/8000] D loss: 1.0464, G loss: 7.5861\n",
      "[3972/8000] D loss: 0.8851, G loss: 5.3471\n",
      "[4332/8000] D loss: 0.5303, G loss: 18.7611\n",
      "[4692/8000] D loss: 0.7408, G loss: 8.9530\n",
      "[5052/8000] D loss: 0.6519, G loss: 7.6113\n",
      "[5412/8000] D loss: 1.1789, G loss: 4.6026\n",
      "[5772/8000] D loss: 0.8314, G loss: 6.3386\n",
      "[6132/8000] D loss: 1.0064, G loss: 8.9688\n",
      "[6492/8000] D loss: 0.9592, G loss: 3.7694\n",
      "[6852/8000] D loss: 0.9078, G loss: 8.8202\n",
      "[7212/8000] D loss: 0.5818, G loss: 8.4325\n",
      "[7572/8000] D loss: 0.5828, G loss: 8.3939\n",
      "[7932/8000] D loss: 1.0217, G loss: 2.4908\n",
      "train error: \n",
      " D loss: 0.858881, G loss: 6.307036, D accuracy: 70.6%, cell accuracy: 98.8%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.012259, G loss: 20.696437, D accuracy: 78.4%, cell accuracy: 98.3%, board accuracy: 30.4% \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0562, G loss: 3.5462\n",
      "[372/8000] D loss: 0.8993, G loss: 9.3339\n",
      "[732/8000] D loss: 1.1349, G loss: 1.6064\n",
      "[1092/8000] D loss: 1.0403, G loss: 2.5770\n",
      "[1452/8000] D loss: 0.9417, G loss: 13.3483\n",
      "[1812/8000] D loss: 0.8924, G loss: 4.6831\n",
      "[2172/8000] D loss: 0.5886, G loss: 12.0391\n",
      "[2532/8000] D loss: 1.0500, G loss: 1.6774\n",
      "[2892/8000] D loss: 0.8149, G loss: 7.6844\n",
      "[3252/8000] D loss: 0.9990, G loss: 3.6005\n",
      "[3612/8000] D loss: 0.8139, G loss: 4.8776\n",
      "[3972/8000] D loss: 0.7025, G loss: 13.0512\n",
      "[4332/8000] D loss: 0.7578, G loss: 9.3287\n",
      "[4692/8000] D loss: 0.7148, G loss: 9.5927\n",
      "[5052/8000] D loss: 0.9620, G loss: 5.1391\n",
      "[5412/8000] D loss: 0.9322, G loss: 4.5898\n",
      "[5772/8000] D loss: 0.8605, G loss: 4.4443\n",
      "[6132/8000] D loss: 0.9564, G loss: 2.8744\n",
      "[6492/8000] D loss: 0.9540, G loss: 5.8566\n",
      "[6852/8000] D loss: 1.1870, G loss: 2.4028\n",
      "[7212/8000] D loss: 0.9612, G loss: 8.5592\n",
      "[7572/8000] D loss: 0.6493, G loss: 4.7337\n",
      "[7932/8000] D loss: 1.0021, G loss: 1.7206\n",
      "train error: \n",
      " D loss: 0.867036, G loss: 5.264794, D accuracy: 70.5%, cell accuracy: 98.8%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.916706, G loss: 17.401634, D accuracy: 78.4%, cell accuracy: 98.3%, board accuracy: 30.5% \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8605, G loss: 8.3495\n",
      "[372/8000] D loss: 0.6878, G loss: 9.2874\n",
      "[732/8000] D loss: 0.5587, G loss: 7.7990\n",
      "[1092/8000] D loss: 1.2795, G loss: 3.5043\n",
      "[1452/8000] D loss: 0.4696, G loss: 21.2453\n",
      "[1812/8000] D loss: 0.8136, G loss: 10.2250\n",
      "[2172/8000] D loss: 1.0434, G loss: 4.8005\n",
      "[2532/8000] D loss: 0.9945, G loss: 4.5558\n",
      "[2892/8000] D loss: 0.9395, G loss: 6.4139\n",
      "[3252/8000] D loss: 0.9214, G loss: 2.1935\n",
      "[3612/8000] D loss: 0.7394, G loss: 9.4088\n",
      "[3972/8000] D loss: 0.9844, G loss: 3.9985\n",
      "[4332/8000] D loss: 0.9011, G loss: 6.0312\n",
      "[4692/8000] D loss: 0.7975, G loss: 7.4147\n",
      "[5052/8000] D loss: 0.7482, G loss: 7.6743\n",
      "[5412/8000] D loss: 0.8290, G loss: 9.2221\n",
      "[5772/8000] D loss: 0.6970, G loss: 3.9835\n",
      "[6132/8000] D loss: 0.4674, G loss: 11.0747\n",
      "[6492/8000] D loss: 0.7944, G loss: 7.1020\n",
      "[6852/8000] D loss: 0.7062, G loss: 8.0230\n",
      "[7212/8000] D loss: 0.7118, G loss: 4.6903\n",
      "[7572/8000] D loss: 0.9044, G loss: 2.3391\n",
      "[7932/8000] D loss: 1.1041, G loss: 4.9704\n",
      "train error: \n",
      " D loss: 0.849049, G loss: 6.697146, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.053562, G loss: 21.676919, D accuracy: 78.4%, cell accuracy: 98.3%, board accuracy: 29.4% \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0454, G loss: 14.9945\n",
      "[372/8000] D loss: 0.7557, G loss: 4.3675\n",
      "[732/8000] D loss: 0.9352, G loss: 4.4942\n",
      "[1092/8000] D loss: 0.9162, G loss: 3.5469\n",
      "[1452/8000] D loss: 0.7039, G loss: 5.9835\n",
      "[1812/8000] D loss: 0.5698, G loss: 8.4872\n",
      "[2172/8000] D loss: 1.2544, G loss: 2.9760\n",
      "[2532/8000] D loss: 0.9535, G loss: 4.0020\n",
      "[2892/8000] D loss: 0.9277, G loss: 4.5493\n",
      "[3252/8000] D loss: 0.7436, G loss: 11.8000\n",
      "[3612/8000] D loss: 0.8278, G loss: 11.0284\n",
      "[3972/8000] D loss: 1.3073, G loss: 0.7938\n",
      "[4332/8000] D loss: 0.6967, G loss: 10.2829\n",
      "[4692/8000] D loss: 0.8018, G loss: 7.4355\n",
      "[5052/8000] D loss: 1.2870, G loss: 1.0190\n",
      "[5412/8000] D loss: 0.9265, G loss: 7.1164\n",
      "[5772/8000] D loss: 0.9201, G loss: 5.5294\n",
      "[6132/8000] D loss: 0.6523, G loss: 6.9963\n",
      "[6492/8000] D loss: 1.2171, G loss: 2.1883\n",
      "[6852/8000] D loss: 1.0170, G loss: 6.0300\n",
      "[7212/8000] D loss: 0.6953, G loss: 11.6931\n",
      "[7572/8000] D loss: 1.0563, G loss: 4.2210\n",
      "[7932/8000] D loss: 0.9084, G loss: 8.6294\n",
      "train error: \n",
      " D loss: 0.869178, G loss: 7.158349, D accuracy: 70.2%, cell accuracy: 98.8%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.161213, G loss: 21.568417, D accuracy: 74.2%, cell accuracy: 98.3%, board accuracy: 30.5% \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7093, G loss: 10.7064\n",
      "[372/8000] D loss: 1.2728, G loss: 0.9206\n",
      "[732/8000] D loss: 0.5332, G loss: 5.8474\n",
      "[1092/8000] D loss: 0.7940, G loss: 9.4834\n",
      "[1452/8000] D loss: 0.8199, G loss: 9.0491\n",
      "[1812/8000] D loss: 1.1783, G loss: 1.7137\n",
      "[2172/8000] D loss: 0.6402, G loss: 9.8768\n",
      "[2532/8000] D loss: 0.8164, G loss: 5.2835\n",
      "[2892/8000] D loss: 0.9129, G loss: 7.8375\n",
      "[3252/8000] D loss: 0.8232, G loss: 5.6935\n",
      "[3612/8000] D loss: 0.7136, G loss: 4.3089\n",
      "[3972/8000] D loss: 0.9036, G loss: 4.9436\n",
      "[4332/8000] D loss: 0.6971, G loss: 6.9324\n",
      "[4692/8000] D loss: 0.7156, G loss: 6.5145\n",
      "[5052/8000] D loss: 0.6824, G loss: 9.9977\n",
      "[5412/8000] D loss: 0.8038, G loss: 5.6370\n",
      "[5772/8000] D loss: 0.5813, G loss: 12.2626\n",
      "[6132/8000] D loss: 0.7854, G loss: 4.1906\n",
      "[6492/8000] D loss: 0.7393, G loss: 4.5855\n",
      "[6852/8000] D loss: 0.6466, G loss: 6.1773\n",
      "[7212/8000] D loss: 0.8067, G loss: 7.4047\n",
      "[7572/8000] D loss: 0.9989, G loss: 5.1143\n",
      "[7932/8000] D loss: 0.9215, G loss: 2.6589\n",
      "train error: \n",
      " D loss: 0.851946, G loss: 7.599917, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.029115, G loss: 24.204904, D accuracy: 76.3%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7510, G loss: 15.7745\n",
      "[372/8000] D loss: 1.2426, G loss: 1.2218\n",
      "[732/8000] D loss: 1.0650, G loss: 2.4914\n",
      "[1092/8000] D loss: 0.9764, G loss: 3.8189\n",
      "[1452/8000] D loss: 1.0379, G loss: 2.8154\n",
      "[1812/8000] D loss: 1.0396, G loss: 5.5838\n",
      "[2172/8000] D loss: 0.9009, G loss: 6.6991\n",
      "[2532/8000] D loss: 0.9920, G loss: 5.4051\n",
      "[2892/8000] D loss: 0.8195, G loss: 9.5603\n",
      "[3252/8000] D loss: 0.6980, G loss: 6.1243\n",
      "[3612/8000] D loss: 1.1116, G loss: 2.2348\n",
      "[3972/8000] D loss: 0.9847, G loss: 8.3120\n",
      "[4332/8000] D loss: 1.0462, G loss: 2.6726\n",
      "[4692/8000] D loss: 0.8424, G loss: 3.6274\n",
      "[5052/8000] D loss: 0.4956, G loss: 10.8948\n",
      "[5412/8000] D loss: 1.0574, G loss: 5.6549\n",
      "[5772/8000] D loss: 0.9451, G loss: 4.1559\n",
      "[6132/8000] D loss: 1.1017, G loss: 3.9712\n",
      "[6492/8000] D loss: 1.1903, G loss: 2.3142\n",
      "[6852/8000] D loss: 1.0531, G loss: 3.2142\n",
      "[7212/8000] D loss: 0.5794, G loss: 10.4334\n",
      "[7572/8000] D loss: 1.0268, G loss: 5.9582\n",
      "[7932/8000] D loss: 0.9299, G loss: 6.5072\n",
      "train error: \n",
      " D loss: 0.852666, G loss: 7.938478, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.043076, G loss: 23.549249, D accuracy: 78.8%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9755, G loss: 5.7927\n",
      "[372/8000] D loss: 0.9283, G loss: 4.8353\n",
      "[732/8000] D loss: 0.8190, G loss: 5.3964\n",
      "[1092/8000] D loss: 0.6927, G loss: 9.9385\n",
      "[1452/8000] D loss: 1.0598, G loss: 4.0701\n",
      "[1812/8000] D loss: 0.8282, G loss: 3.5225\n",
      "[2172/8000] D loss: 0.8675, G loss: 3.8146\n",
      "[2532/8000] D loss: 0.9602, G loss: 6.0297\n",
      "[2892/8000] D loss: 0.6862, G loss: 12.9020\n",
      "[3252/8000] D loss: 0.7116, G loss: 5.6927\n",
      "[3612/8000] D loss: 0.7119, G loss: 5.8594\n",
      "[3972/8000] D loss: 0.7104, G loss: 6.7700\n",
      "[4332/8000] D loss: 0.9543, G loss: 6.4232\n",
      "[4692/8000] D loss: 0.8640, G loss: 7.1114\n",
      "[5052/8000] D loss: 0.6823, G loss: 8.8973\n",
      "[5412/8000] D loss: 0.9635, G loss: 10.3899\n",
      "[5772/8000] D loss: 1.0285, G loss: 3.0226\n",
      "[6132/8000] D loss: 1.0328, G loss: 3.4223\n",
      "[6492/8000] D loss: 0.6502, G loss: 6.2420\n",
      "[6852/8000] D loss: 0.6946, G loss: 4.3852\n",
      "[7212/8000] D loss: 1.0388, G loss: 2.6899\n",
      "[7572/8000] D loss: 0.8366, G loss: 9.2494\n",
      "[7932/8000] D loss: 0.9029, G loss: 3.5679\n",
      "train error: \n",
      " D loss: 0.858453, G loss: 6.336196, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.977951, G loss: 19.861199, D accuracy: 80.0%, cell accuracy: 98.3%, board accuracy: 28.8% \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5503, G loss: 5.8191\n",
      "[372/8000] D loss: 0.6174, G loss: 9.5157\n",
      "[732/8000] D loss: 0.7974, G loss: 3.0791\n",
      "[1092/8000] D loss: 0.9297, G loss: 7.7518\n",
      "[1452/8000] D loss: 1.1911, G loss: 6.1055\n",
      "[1812/8000] D loss: 0.8885, G loss: 2.6646\n",
      "[2172/8000] D loss: 0.6896, G loss: 7.6895\n",
      "[2532/8000] D loss: 0.9330, G loss: 3.4831\n",
      "[2892/8000] D loss: 0.8356, G loss: 6.5576\n",
      "[3252/8000] D loss: 0.6975, G loss: 12.2163\n",
      "[3612/8000] D loss: 1.0543, G loss: 7.3367\n",
      "[3972/8000] D loss: 0.8052, G loss: 9.8404\n",
      "[4332/8000] D loss: 0.8055, G loss: 8.3829\n",
      "[4692/8000] D loss: 1.0516, G loss: 2.3399\n",
      "[5052/8000] D loss: 1.0207, G loss: 2.8569\n",
      "[5412/8000] D loss: 1.1676, G loss: 4.3782\n",
      "[5772/8000] D loss: 0.6994, G loss: 7.5947\n",
      "[6132/8000] D loss: 0.9254, G loss: 4.9020\n",
      "[6492/8000] D loss: 0.7470, G loss: 9.3550\n",
      "[6852/8000] D loss: 0.6621, G loss: 15.4165\n",
      "[7212/8000] D loss: 0.6963, G loss: 8.1551\n",
      "[7572/8000] D loss: 0.8686, G loss: 17.3845\n",
      "[7932/8000] D loss: 0.8303, G loss: 8.2448\n",
      "train error: \n",
      " D loss: 0.861092, G loss: 6.517285, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.988194, G loss: 20.984194, D accuracy: 80.7%, cell accuracy: 98.3%, board accuracy: 29.7% \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6276, G loss: 7.6742\n",
      "[372/8000] D loss: 0.8045, G loss: 8.6863\n",
      "[732/8000] D loss: 0.6971, G loss: 7.3731\n",
      "[1092/8000] D loss: 0.8090, G loss: 4.7400\n",
      "[1452/8000] D loss: 0.9395, G loss: 3.9888\n",
      "[1812/8000] D loss: 1.0061, G loss: 4.7048\n",
      "[2172/8000] D loss: 0.7924, G loss: 9.5054\n",
      "[2532/8000] D loss: 0.7698, G loss: 4.2091\n",
      "[2892/8000] D loss: 0.9150, G loss: 7.0219\n",
      "[3252/8000] D loss: 0.8136, G loss: 4.1459\n",
      "[3612/8000] D loss: 1.1363, G loss: 2.2544\n",
      "[3972/8000] D loss: 1.0628, G loss: 3.5790\n",
      "[4332/8000] D loss: 0.5819, G loss: 10.0801\n",
      "[4692/8000] D loss: 0.7069, G loss: 10.1275\n",
      "[5052/8000] D loss: 0.8266, G loss: 9.8322\n",
      "[5412/8000] D loss: 0.9159, G loss: 7.3431\n",
      "[5772/8000] D loss: 0.9706, G loss: 3.4047\n",
      "[6132/8000] D loss: 0.4039, G loss: 9.7646\n",
      "[6492/8000] D loss: 0.6985, G loss: 4.1306\n",
      "[6852/8000] D loss: 0.7942, G loss: 7.5219\n",
      "[7212/8000] D loss: 1.2183, G loss: 2.6595\n",
      "[7572/8000] D loss: 1.1020, G loss: 3.3116\n",
      "[7932/8000] D loss: 0.7018, G loss: 3.0486\n",
      "train error: \n",
      " D loss: 0.853973, G loss: 6.920122, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.082622, G loss: 21.600297, D accuracy: 79.8%, cell accuracy: 98.3%, board accuracy: 29.1% \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9106, G loss: 5.7544\n",
      "[372/8000] D loss: 0.9091, G loss: 7.9837\n",
      "[732/8000] D loss: 0.6403, G loss: 12.3587\n",
      "[1092/8000] D loss: 0.9146, G loss: 7.1471\n",
      "[1452/8000] D loss: 1.0525, G loss: 2.6860\n",
      "[1812/8000] D loss: 0.5881, G loss: 12.9067\n",
      "[2172/8000] D loss: 0.9404, G loss: 4.7302\n",
      "[2532/8000] D loss: 0.9855, G loss: 4.5688\n",
      "[2892/8000] D loss: 1.0499, G loss: 3.3081\n",
      "[3252/8000] D loss: 0.8187, G loss: 7.9068\n",
      "[3612/8000] D loss: 0.4699, G loss: 12.1541\n",
      "[3972/8000] D loss: 1.2337, G loss: 1.1628\n",
      "[4332/8000] D loss: 0.8839, G loss: 14.5291\n",
      "[4692/8000] D loss: 0.9357, G loss: 7.8271\n",
      "[5052/8000] D loss: 1.1057, G loss: 7.7219\n",
      "[5412/8000] D loss: 0.8469, G loss: 6.0296\n",
      "[5772/8000] D loss: 0.5844, G loss: 7.6900\n",
      "[6132/8000] D loss: 1.1589, G loss: 2.2352\n",
      "[6492/8000] D loss: 1.0813, G loss: 2.6110\n",
      "[6852/8000] D loss: 0.9291, G loss: 8.0839\n",
      "[7212/8000] D loss: 0.8108, G loss: 5.1299\n",
      "[7572/8000] D loss: 1.0169, G loss: 5.5231\n",
      "[7932/8000] D loss: 0.9169, G loss: 9.0926\n",
      "train error: \n",
      " D loss: 0.841479, G loss: 7.537400, D accuracy: 71.8%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.009272, G loss: 23.217793, D accuracy: 80.4%, cell accuracy: 98.2%, board accuracy: 27.6% \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.1125, G loss: 6.4536\n",
      "[372/8000] D loss: 1.0012, G loss: 5.9488\n",
      "[732/8000] D loss: 0.8357, G loss: 11.5934\n",
      "[1092/8000] D loss: 1.1821, G loss: 2.9934\n",
      "[1452/8000] D loss: 0.7142, G loss: 8.6319\n",
      "[1812/8000] D loss: 0.6467, G loss: 5.5459\n",
      "[2172/8000] D loss: 1.0407, G loss: 2.7730\n",
      "[2532/8000] D loss: 0.8209, G loss: 2.9430\n",
      "[2892/8000] D loss: 0.9829, G loss: 7.0127\n",
      "[3252/8000] D loss: 0.6864, G loss: 5.4664\n",
      "[3612/8000] D loss: 0.8185, G loss: 5.0004\n",
      "[3972/8000] D loss: 0.9300, G loss: 5.0564\n",
      "[4332/8000] D loss: 0.7523, G loss: 6.6607\n",
      "[4692/8000] D loss: 0.6517, G loss: 7.8034\n",
      "[5052/8000] D loss: 0.9479, G loss: 2.2512\n",
      "[5412/8000] D loss: 0.9282, G loss: 6.3034\n",
      "[5772/8000] D loss: 0.5783, G loss: 10.1615\n",
      "[6132/8000] D loss: 0.8076, G loss: 6.4139\n",
      "[6492/8000] D loss: 0.8171, G loss: 9.2221\n",
      "[6852/8000] D loss: 0.7644, G loss: 7.2183\n",
      "[7212/8000] D loss: 1.1743, G loss: 1.6448\n",
      "[7572/8000] D loss: 0.4862, G loss: 12.0832\n",
      "[7932/8000] D loss: 0.9776, G loss: 7.5358\n",
      "train error: \n",
      " D loss: 0.850302, G loss: 7.181545, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.027038, G loss: 21.530474, D accuracy: 80.5%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8693, G loss: 5.0441\n",
      "[372/8000] D loss: 1.3293, G loss: 1.0235\n",
      "[732/8000] D loss: 0.4964, G loss: 8.7548\n",
      "[1092/8000] D loss: 0.5318, G loss: 10.5404\n",
      "[1452/8000] D loss: 1.0547, G loss: 4.5033\n",
      "[1812/8000] D loss: 0.7020, G loss: 5.6896\n",
      "[2172/8000] D loss: 0.5239, G loss: 12.0512\n",
      "[2532/8000] D loss: 1.1160, G loss: 3.9945\n",
      "[2892/8000] D loss: 0.9929, G loss: 7.0717\n",
      "[3252/8000] D loss: 0.9342, G loss: 6.1659\n",
      "[3612/8000] D loss: 1.1436, G loss: 2.6835\n",
      "[3972/8000] D loss: 0.6969, G loss: 5.8463\n",
      "[4332/8000] D loss: 0.8508, G loss: 10.4080\n",
      "[4692/8000] D loss: 1.2306, G loss: 6.3040\n",
      "[5052/8000] D loss: 0.9158, G loss: 4.5287\n",
      "[5412/8000] D loss: 0.8512, G loss: 8.2748\n",
      "[5772/8000] D loss: 1.0205, G loss: 12.8407\n",
      "[6132/8000] D loss: 0.7926, G loss: 5.5139\n",
      "[6492/8000] D loss: 0.7547, G loss: 5.6894\n",
      "[6852/8000] D loss: 0.5945, G loss: 9.3601\n",
      "[7212/8000] D loss: 0.9274, G loss: 4.3329\n",
      "[7572/8000] D loss: 0.6419, G loss: 13.9535\n",
      "[7932/8000] D loss: 0.9258, G loss: 8.1764\n",
      "train error: \n",
      " D loss: 0.861841, G loss: 8.038079, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.166967, G loss: 24.188086, D accuracy: 76.5%, cell accuracy: 98.3%, board accuracy: 29.9% \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8637, G loss: 8.9603\n",
      "[372/8000] D loss: 0.6995, G loss: 4.7682\n",
      "[732/8000] D loss: 0.8765, G loss: 12.7530\n",
      "[1092/8000] D loss: 0.8131, G loss: 6.4090\n",
      "[1452/8000] D loss: 0.7611, G loss: 7.4090\n",
      "[1812/8000] D loss: 0.5868, G loss: 11.2176\n",
      "[2172/8000] D loss: 1.1616, G loss: 3.7379\n",
      "[2532/8000] D loss: 0.6889, G loss: 10.8597\n",
      "[2892/8000] D loss: 0.8080, G loss: 8.3926\n",
      "[3252/8000] D loss: 0.4380, G loss: 11.9618\n",
      "[3612/8000] D loss: 1.2854, G loss: 1.9366\n",
      "[3972/8000] D loss: 0.7811, G loss: 7.8802\n",
      "[4332/8000] D loss: 0.8974, G loss: 5.6767\n",
      "[4692/8000] D loss: 0.9889, G loss: 4.2597\n",
      "[5052/8000] D loss: 1.0235, G loss: 2.2879\n",
      "[5412/8000] D loss: 0.9846, G loss: 12.0581\n",
      "[5772/8000] D loss: 0.7001, G loss: 6.1078\n",
      "[6132/8000] D loss: 0.5096, G loss: 9.4278\n",
      "[6492/8000] D loss: 1.0090, G loss: 3.0404\n",
      "[6852/8000] D loss: 1.3033, G loss: 3.1490\n",
      "[7212/8000] D loss: 1.1229, G loss: 3.3016\n",
      "[7572/8000] D loss: 0.8959, G loss: 4.3071\n",
      "[7932/8000] D loss: 0.8254, G loss: 7.2512\n",
      "train error: \n",
      " D loss: 0.915284, G loss: 4.297096, D accuracy: 69.6%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.803459, G loss: 15.611651, D accuracy: 82.1%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0385, G loss: 2.8484\n",
      "[372/8000] D loss: 0.8162, G loss: 3.5922\n",
      "[732/8000] D loss: 0.6545, G loss: 4.3270\n",
      "[1092/8000] D loss: 1.3102, G loss: 1.1886\n",
      "[1452/8000] D loss: 0.9269, G loss: 3.4529\n",
      "[1812/8000] D loss: 0.9849, G loss: 5.1379\n",
      "[2172/8000] D loss: 0.9008, G loss: 9.7042\n",
      "[2532/8000] D loss: 1.0327, G loss: 8.0203\n",
      "[2892/8000] D loss: 0.8915, G loss: 8.7031\n",
      "[3252/8000] D loss: 0.5108, G loss: 12.8383\n",
      "[3612/8000] D loss: 0.6992, G loss: 8.6665\n",
      "[3972/8000] D loss: 1.1554, G loss: 4.9157\n",
      "[4332/8000] D loss: 0.7498, G loss: 13.8387\n",
      "[4692/8000] D loss: 1.1644, G loss: 5.5547\n",
      "[5052/8000] D loss: 0.7541, G loss: 5.2119\n",
      "[5412/8000] D loss: 0.6541, G loss: 11.8818\n",
      "[5772/8000] D loss: 0.9591, G loss: 8.2568\n",
      "[6132/8000] D loss: 0.8688, G loss: 4.1016\n",
      "[6492/8000] D loss: 1.0907, G loss: 3.6226\n",
      "[6852/8000] D loss: 0.3530, G loss: 9.1316\n",
      "[7212/8000] D loss: 0.6980, G loss: 10.8782\n",
      "[7572/8000] D loss: 0.6038, G loss: 10.6440\n",
      "[7932/8000] D loss: 0.5285, G loss: 13.8409\n",
      "train error: \n",
      " D loss: 0.863648, G loss: 6.882091, D accuracy: 70.7%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.992404, G loss: 20.602688, D accuracy: 80.1%, cell accuracy: 98.3%, board accuracy: 28.5% \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6978, G loss: 12.5996\n",
      "[372/8000] D loss: 0.9234, G loss: 7.2225\n",
      "[732/8000] D loss: 0.8193, G loss: 5.9258\n",
      "[1092/8000] D loss: 0.6460, G loss: 12.5719\n",
      "[1452/8000] D loss: 0.7585, G loss: 3.2030\n",
      "[1812/8000] D loss: 0.9253, G loss: 8.7073\n",
      "[2172/8000] D loss: 0.6964, G loss: 4.1920\n",
      "[2532/8000] D loss: 0.7339, G loss: 13.5725\n",
      "[2892/8000] D loss: 0.7012, G loss: 10.5706\n",
      "[3252/8000] D loss: 0.6552, G loss: 10.2914\n",
      "[3612/8000] D loss: 0.9954, G loss: 9.0604\n",
      "[3972/8000] D loss: 0.8145, G loss: 6.9992\n",
      "[4332/8000] D loss: 0.8392, G loss: 8.2440\n",
      "[4692/8000] D loss: 0.7224, G loss: 6.8918\n",
      "[5052/8000] D loss: 0.9234, G loss: 5.2135\n",
      "[5412/8000] D loss: 1.2627, G loss: 6.0615\n",
      "[5772/8000] D loss: 0.8560, G loss: 7.6254\n",
      "[6132/8000] D loss: 0.7578, G loss: 8.8692\n",
      "[6492/8000] D loss: 0.9292, G loss: 3.1262\n",
      "[6852/8000] D loss: 0.7396, G loss: 4.5034\n",
      "[7212/8000] D loss: 0.7664, G loss: 12.7265\n",
      "[7572/8000] D loss: 0.7241, G loss: 9.6445\n",
      "[7932/8000] D loss: 0.8080, G loss: 11.2460\n",
      "train error: \n",
      " D loss: 0.860495, G loss: 7.191837, D accuracy: 71.1%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.972564, G loss: 22.273470, D accuracy: 80.7%, cell accuracy: 98.3%, board accuracy: 29.5% \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7593, G loss: 7.4076\n",
      "[372/8000] D loss: 0.6915, G loss: 6.3655\n",
      "[732/8000] D loss: 0.9334, G loss: 3.2887\n",
      "[1092/8000] D loss: 0.7087, G loss: 11.4922\n",
      "[1452/8000] D loss: 0.7585, G loss: 10.9671\n",
      "[1812/8000] D loss: 1.0469, G loss: 4.5131\n",
      "[2172/8000] D loss: 0.8120, G loss: 7.3971\n",
      "[2532/8000] D loss: 0.6199, G loss: 12.0326\n",
      "[2892/8000] D loss: 0.8108, G loss: 4.3810\n",
      "[3252/8000] D loss: 0.9821, G loss: 10.3654\n",
      "[3612/8000] D loss: 0.8773, G loss: 4.2169\n",
      "[3972/8000] D loss: 0.7383, G loss: 10.5016\n",
      "[4332/8000] D loss: 0.9358, G loss: 8.9618\n",
      "[4692/8000] D loss: 1.1818, G loss: 2.0271\n",
      "[5052/8000] D loss: 1.0335, G loss: 1.6973\n",
      "[5412/8000] D loss: 1.0181, G loss: 2.5614\n",
      "[5772/8000] D loss: 0.6715, G loss: 9.5649\n",
      "[6132/8000] D loss: 1.1620, G loss: 6.2858\n",
      "[6492/8000] D loss: 0.9245, G loss: 9.0291\n",
      "[6852/8000] D loss: 0.9164, G loss: 7.2310\n",
      "[7212/8000] D loss: 0.9137, G loss: 6.5443\n",
      "[7572/8000] D loss: 0.7033, G loss: 10.8426\n",
      "[7932/8000] D loss: 0.5820, G loss: 10.6733\n",
      "train error: \n",
      " D loss: 0.848504, G loss: 7.839985, D accuracy: 71.3%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.000652, G loss: 24.723706, D accuracy: 80.2%, cell accuracy: 98.3%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0296, G loss: 6.4213\n",
      "[372/8000] D loss: 0.7117, G loss: 21.2795\n",
      "[732/8000] D loss: 1.0301, G loss: 3.7603\n",
      "[1092/8000] D loss: 0.6177, G loss: 10.1526\n",
      "[1452/8000] D loss: 0.9370, G loss: 3.2002\n",
      "[1812/8000] D loss: 0.8183, G loss: 5.6049\n",
      "[2172/8000] D loss: 1.2430, G loss: 3.0947\n",
      "[2532/8000] D loss: 0.8206, G loss: 4.7451\n",
      "[2892/8000] D loss: 0.8404, G loss: 9.0746\n",
      "[3252/8000] D loss: 0.7205, G loss: 10.7604\n",
      "[3612/8000] D loss: 1.0240, G loss: 10.5578\n",
      "[3972/8000] D loss: 0.9372, G loss: 5.3720\n",
      "[4332/8000] D loss: 0.8724, G loss: 11.7346\n",
      "[4692/8000] D loss: 0.7555, G loss: 8.5198\n",
      "[5052/8000] D loss: 0.7986, G loss: 7.7079\n",
      "[5412/8000] D loss: 1.0511, G loss: 3.5052\n",
      "[5772/8000] D loss: 1.1160, G loss: 9.7210\n",
      "[6132/8000] D loss: 1.0294, G loss: 2.0289\n",
      "[6492/8000] D loss: 0.6959, G loss: 8.3421\n",
      "[6852/8000] D loss: 0.9516, G loss: 3.6590\n",
      "[7212/8000] D loss: 0.7171, G loss: 10.8907\n",
      "[7572/8000] D loss: 1.0250, G loss: 3.6440\n",
      "[7932/8000] D loss: 0.9277, G loss: 7.5777\n",
      "train error: \n",
      " D loss: 0.860598, G loss: 6.808363, D accuracy: 70.4%, cell accuracy: 98.8%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.035487, G loss: 21.003308, D accuracy: 75.7%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9368, G loss: 4.3433\n",
      "[372/8000] D loss: 0.8118, G loss: 10.4898\n",
      "[732/8000] D loss: 0.6752, G loss: 7.3011\n",
      "[1092/8000] D loss: 1.0458, G loss: 4.7624\n",
      "[1452/8000] D loss: 0.8357, G loss: 4.4497\n",
      "[1812/8000] D loss: 0.6114, G loss: 13.3962\n",
      "[2172/8000] D loss: 0.6694, G loss: 9.1413\n",
      "[2532/8000] D loss: 1.0939, G loss: 3.2163\n",
      "[2892/8000] D loss: 0.9579, G loss: 3.4004\n",
      "[3252/8000] D loss: 0.5960, G loss: 7.3281\n",
      "[3612/8000] D loss: 0.4914, G loss: 19.5649\n",
      "[3972/8000] D loss: 0.4705, G loss: 12.0845\n",
      "[4332/8000] D loss: 0.8738, G loss: 6.4292\n",
      "[4692/8000] D loss: 0.9181, G loss: 9.9469\n",
      "[5052/8000] D loss: 0.8531, G loss: 4.8082\n",
      "[5412/8000] D loss: 1.2611, G loss: 2.8778\n",
      "[5772/8000] D loss: 0.7740, G loss: 18.0312\n",
      "[6132/8000] D loss: 0.8828, G loss: 4.6594\n",
      "[6492/8000] D loss: 0.7554, G loss: 21.4583\n",
      "[6852/8000] D loss: 1.0204, G loss: 3.9108\n",
      "[7212/8000] D loss: 0.9836, G loss: 3.4902\n",
      "[7572/8000] D loss: 0.7298, G loss: 4.6457\n",
      "[7932/8000] D loss: 0.8832, G loss: 10.8934\n",
      "train error: \n",
      " D loss: 0.843969, G loss: 6.386611, D accuracy: 71.7%, cell accuracy: 98.8%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.970854, G loss: 20.899791, D accuracy: 80.6%, cell accuracy: 98.2%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7951, G loss: 4.5576\n",
      "[372/8000] D loss: 0.8522, G loss: 8.0277\n",
      "[732/8000] D loss: 0.9103, G loss: 3.6707\n",
      "[1092/8000] D loss: 1.1086, G loss: 5.2079\n",
      "[1452/8000] D loss: 0.9394, G loss: 4.0787\n",
      "[1812/8000] D loss: 0.5507, G loss: 6.3062\n",
      "[2172/8000] D loss: 0.8487, G loss: 14.4493\n",
      "[2532/8000] D loss: 1.1264, G loss: 4.3489\n",
      "[2892/8000] D loss: 0.7024, G loss: 9.7157\n",
      "[3252/8000] D loss: 1.0425, G loss: 4.5488\n",
      "[3612/8000] D loss: 0.8023, G loss: 10.3465\n",
      "[3972/8000] D loss: 0.3675, G loss: 11.6154\n",
      "[4332/8000] D loss: 1.2681, G loss: 2.9542\n",
      "[4692/8000] D loss: 0.7148, G loss: 7.5366\n",
      "[5052/8000] D loss: 1.1257, G loss: 1.9065\n",
      "[5412/8000] D loss: 0.3580, G loss: 13.0794\n",
      "[5772/8000] D loss: 0.7643, G loss: 3.2648\n",
      "[6132/8000] D loss: 0.5778, G loss: 13.5161\n",
      "[6492/8000] D loss: 0.7064, G loss: 11.6273\n",
      "[6852/8000] D loss: 0.7994, G loss: 3.5389\n",
      "[7212/8000] D loss: 0.9496, G loss: 5.0022\n",
      "[7572/8000] D loss: 0.7032, G loss: 12.3593\n",
      "[7932/8000] D loss: 0.9754, G loss: 5.3669\n",
      "train error: \n",
      " D loss: 0.866757, G loss: 5.931172, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.900394, G loss: 20.182312, D accuracy: 81.3%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9727, G loss: 12.7538\n",
      "[372/8000] D loss: 0.3488, G loss: 16.7364\n",
      "[732/8000] D loss: 0.5064, G loss: 7.7031\n",
      "[1092/8000] D loss: 0.7171, G loss: 10.9269\n",
      "[1452/8000] D loss: 1.0665, G loss: 5.8365\n",
      "[1812/8000] D loss: 0.9129, G loss: 8.0904\n",
      "[2172/8000] D loss: 0.6160, G loss: 9.8734\n",
      "[2532/8000] D loss: 0.6790, G loss: 7.6929\n",
      "[2892/8000] D loss: 0.8074, G loss: 6.2217\n",
      "[3252/8000] D loss: 0.8398, G loss: 6.8372\n",
      "[3612/8000] D loss: 0.7721, G loss: 7.2253\n",
      "[3972/8000] D loss: 0.5654, G loss: 8.9442\n",
      "[4332/8000] D loss: 1.0159, G loss: 2.7877\n",
      "[4692/8000] D loss: 0.8586, G loss: 5.0565\n",
      "[5052/8000] D loss: 0.9387, G loss: 8.5144\n",
      "[5412/8000] D loss: 0.8328, G loss: 7.8528\n",
      "[5772/8000] D loss: 1.0688, G loss: 2.4346\n",
      "[6132/8000] D loss: 0.5892, G loss: 6.7496\n",
      "[6492/8000] D loss: 0.9728, G loss: 3.5018\n",
      "[6852/8000] D loss: 1.2322, G loss: 1.9911\n",
      "[7212/8000] D loss: 1.3343, G loss: 2.0599\n",
      "[7572/8000] D loss: 0.9573, G loss: 3.8907\n",
      "[7932/8000] D loss: 1.0329, G loss: 10.8100\n",
      "train error: \n",
      " D loss: 0.854623, G loss: 8.275148, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.057806, G loss: 24.760098, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 29.4% \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.9233, G loss: 4.7764\n",
      "[372/8000] D loss: 1.0485, G loss: 3.0206\n",
      "[732/8000] D loss: 1.0296, G loss: 1.6592\n",
      "[1092/8000] D loss: 0.8150, G loss: 6.7408\n",
      "[1452/8000] D loss: 1.0676, G loss: 7.0937\n",
      "[1812/8000] D loss: 0.8942, G loss: 4.3037\n",
      "[2172/8000] D loss: 0.4131, G loss: 21.9725\n",
      "[2532/8000] D loss: 0.8094, G loss: 6.1398\n",
      "[2892/8000] D loss: 1.0364, G loss: 5.5938\n",
      "[3252/8000] D loss: 1.0815, G loss: 5.3677\n",
      "[3612/8000] D loss: 0.8470, G loss: 9.8143\n",
      "[3972/8000] D loss: 0.5259, G loss: 18.4530\n",
      "[4332/8000] D loss: 0.9804, G loss: 5.9895\n",
      "[4692/8000] D loss: 1.0644, G loss: 2.0009\n",
      "[5052/8000] D loss: 0.7608, G loss: 9.3765\n",
      "[5412/8000] D loss: 0.9500, G loss: 8.5116\n",
      "[5772/8000] D loss: 1.2412, G loss: 1.1254\n",
      "[6132/8000] D loss: 0.8946, G loss: 4.4809\n",
      "[6492/8000] D loss: 0.9450, G loss: 10.5079\n",
      "[6852/8000] D loss: 0.8136, G loss: 9.4363\n",
      "[7212/8000] D loss: 0.8245, G loss: 8.1189\n",
      "[7572/8000] D loss: 0.8563, G loss: 7.8067\n",
      "[7932/8000] D loss: 0.9520, G loss: 3.1737\n",
      "train error: \n",
      " D loss: 0.854095, G loss: 7.765575, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.053030, G loss: 23.215034, D accuracy: 78.4%, cell accuracy: 98.3%, board accuracy: 29.9% \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8205, G loss: 10.5834\n",
      "[372/8000] D loss: 0.8226, G loss: 4.8906\n",
      "[732/8000] D loss: 0.8290, G loss: 5.2885\n",
      "[1092/8000] D loss: 0.8407, G loss: 8.1337\n",
      "[1452/8000] D loss: 0.7011, G loss: 8.0573\n",
      "[1812/8000] D loss: 0.9371, G loss: 3.4991\n",
      "[2172/8000] D loss: 0.9131, G loss: 10.6333\n",
      "[2532/8000] D loss: 1.0338, G loss: 2.7072\n",
      "[2892/8000] D loss: 0.9568, G loss: 6.0461\n",
      "[3252/8000] D loss: 0.8868, G loss: 9.1464\n",
      "[3612/8000] D loss: 1.0751, G loss: 7.3419\n",
      "[3972/8000] D loss: 0.7025, G loss: 8.5695\n",
      "[4332/8000] D loss: 1.2175, G loss: 5.1501\n",
      "[4692/8000] D loss: 0.9989, G loss: 2.8128\n",
      "[5052/8000] D loss: 0.9764, G loss: 3.2249\n",
      "[5412/8000] D loss: 0.8267, G loss: 6.4400\n",
      "[5772/8000] D loss: 0.4792, G loss: 9.7752\n",
      "[6132/8000] D loss: 0.8694, G loss: 21.1208\n",
      "[6492/8000] D loss: 0.8837, G loss: 4.3449\n",
      "[6852/8000] D loss: 0.9245, G loss: 5.3069\n",
      "[7212/8000] D loss: 0.8349, G loss: 7.7166\n",
      "[7572/8000] D loss: 0.9512, G loss: 1.9972\n",
      "[7932/8000] D loss: 0.5973, G loss: 6.5525\n",
      "train error: \n",
      " D loss: 0.852641, G loss: 6.620265, D accuracy: 70.9%, cell accuracy: 98.8%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.003240, G loss: 20.561542, D accuracy: 78.4%, cell accuracy: 98.3%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8124, G loss: 9.0874\n",
      "[372/8000] D loss: 0.6418, G loss: 12.0132\n",
      "[732/8000] D loss: 0.8100, G loss: 4.8980\n",
      "[1092/8000] D loss: 0.8046, G loss: 4.5472\n",
      "[1452/8000] D loss: 0.8082, G loss: 6.2309\n",
      "[1812/8000] D loss: 1.2732, G loss: 1.0568\n",
      "[2172/8000] D loss: 1.1257, G loss: 2.5693\n",
      "[2532/8000] D loss: 0.7180, G loss: 4.1905\n",
      "[2892/8000] D loss: 0.6165, G loss: 6.3760\n",
      "[3252/8000] D loss: 0.9390, G loss: 4.6894\n",
      "[3612/8000] D loss: 0.5923, G loss: 11.0837\n",
      "[3972/8000] D loss: 0.4178, G loss: 9.5601\n",
      "[4332/8000] D loss: 1.2468, G loss: 1.7335\n",
      "[4692/8000] D loss: 1.0039, G loss: 3.9813\n",
      "[5052/8000] D loss: 1.1200, G loss: 5.1658\n",
      "[5412/8000] D loss: 1.0485, G loss: 2.5827\n",
      "[5772/8000] D loss: 1.0528, G loss: 9.3943\n",
      "[6132/8000] D loss: 0.8695, G loss: 9.5409\n",
      "[6492/8000] D loss: 0.6126, G loss: 8.9147\n",
      "[6852/8000] D loss: 1.0327, G loss: 2.8838\n",
      "[7212/8000] D loss: 1.0635, G loss: 3.1664\n",
      "[7572/8000] D loss: 1.2802, G loss: 1.1980\n",
      "[7932/8000] D loss: 1.0070, G loss: 4.2493\n",
      "train error: \n",
      " D loss: 0.856084, G loss: 6.897091, D accuracy: 70.8%, cell accuracy: 98.8%, board accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.006572, G loss: 22.217801, D accuracy: 77.8%, cell accuracy: 98.3%, board accuracy: 29.9% \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7084, G loss: 5.9316\n",
      "[372/8000] D loss: 1.0248, G loss: 2.5641\n",
      "[732/8000] D loss: 0.7041, G loss: 3.7604\n",
      "[1092/8000] D loss: 0.8500, G loss: 10.6682\n",
      "[1452/8000] D loss: 0.9566, G loss: 6.2825\n",
      "[1812/8000] D loss: 0.9080, G loss: 10.1284\n",
      "[2172/8000] D loss: 0.6780, G loss: 6.8844\n",
      "[2532/8000] D loss: 1.0702, G loss: 7.2956\n",
      "[2892/8000] D loss: 0.7010, G loss: 10.5872\n",
      "[3252/8000] D loss: 0.7618, G loss: 5.1370\n",
      "[3612/8000] D loss: 0.9239, G loss: 7.4164\n",
      "[3972/8000] D loss: 1.0825, G loss: 7.7788\n",
      "[4332/8000] D loss: 0.6670, G loss: 7.1760\n",
      "[4692/8000] D loss: 0.7136, G loss: 6.0023\n",
      "[5052/8000] D loss: 0.9480, G loss: 5.5824\n",
      "[5412/8000] D loss: 1.0065, G loss: 2.3040\n",
      "[5772/8000] D loss: 0.6747, G loss: 6.0120\n",
      "[6132/8000] D loss: 0.8370, G loss: 3.6582\n",
      "[6492/8000] D loss: 1.0312, G loss: 2.7278\n",
      "[6852/8000] D loss: 0.9035, G loss: 8.5100\n",
      "[7212/8000] D loss: 0.8133, G loss: 12.0632\n",
      "[7572/8000] D loss: 1.0168, G loss: 12.7027\n",
      "[7932/8000] D loss: 0.8089, G loss: 8.6662\n",
      "train error: \n",
      " D loss: 0.853106, G loss: 6.946890, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.019842, G loss: 22.543609, D accuracy: 78.3%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8357, G loss: 8.6571\n",
      "[372/8000] D loss: 0.8701, G loss: 3.0083\n",
      "[732/8000] D loss: 0.7566, G loss: 6.3304\n",
      "[1092/8000] D loss: 1.0542, G loss: 7.8728\n",
      "[1452/8000] D loss: 0.8010, G loss: 7.2966\n",
      "[1812/8000] D loss: 0.9290, G loss: 8.0822\n",
      "[2172/8000] D loss: 0.7042, G loss: 5.6662\n",
      "[2532/8000] D loss: 0.9286, G loss: 7.6838\n",
      "[2892/8000] D loss: 0.7645, G loss: 14.8812\n",
      "[3252/8000] D loss: 0.7911, G loss: 11.5114\n",
      "[3612/8000] D loss: 0.7452, G loss: 12.3581\n",
      "[3972/8000] D loss: 1.2739, G loss: 0.9360\n",
      "[4332/8000] D loss: 1.1659, G loss: 1.7394\n",
      "[4692/8000] D loss: 0.5899, G loss: 8.3499\n",
      "[5052/8000] D loss: 1.0596, G loss: 2.7030\n",
      "[5412/8000] D loss: 1.0795, G loss: 4.3755\n",
      "[5772/8000] D loss: 0.7687, G loss: 5.7748\n",
      "[6132/8000] D loss: 0.9868, G loss: 4.9500\n",
      "[6492/8000] D loss: 1.1522, G loss: 4.5204\n",
      "[6852/8000] D loss: 0.8200, G loss: 9.4878\n",
      "[7212/8000] D loss: 0.8271, G loss: 10.8916\n",
      "[7572/8000] D loss: 0.8536, G loss: 9.1223\n",
      "[7932/8000] D loss: 0.7359, G loss: 8.8723\n",
      "train error: \n",
      " D loss: 0.860064, G loss: 5.395950, D accuracy: 71.0%, cell accuracy: 98.8%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.042993, G loss: 17.979608, D accuracy: 78.0%, cell accuracy: 98.3%, board accuracy: 29.9% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "gen = train(\n",
    "    run_name=\"fine_tuning\",\n",
    "    gen_factory=lambda: AltGenerator(autoencoder, use_batch_norm=True, leak=0.2).to(device),\n",
    "    disc_factory=lambda: AltDiscriminator().to(device),\n",
    "    epochs=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for event type 'Drop':\n",
      "  Cell accuracy (train): 98.45%\n",
      "  Cell accuracy (test): 98.04%\n",
      "  Board accuracy (train): 55.58%\n",
      "  Board accuracy (test): 29.68%\n",
      "\n",
      "Stats for event type 'Left':\n",
      "  Cell accuracy (train): 99.42%\n",
      "  Cell accuracy (test): 98.74%\n",
      "  Board accuracy (train): 72.82%\n",
      "  Board accuracy (test): 31.92%\n",
      "\n",
      "Stats for event type 'Right':\n",
      "  Cell accuracy (train): 99.42%\n",
      "  Cell accuracy (test): 99.01%\n",
      "  Board accuracy (train): 78.74%\n",
      "  Board accuracy (test): 48.05%\n",
      "\n",
      "Stats for event type 'Rotate':\n",
      "  Cell accuracy (train): 98.44%\n",
      "  Cell accuracy (test): 98.12%\n",
      "  Board accuracy (train): 39.22%\n",
      "  Board accuracy (test): 19.29%\n",
      "\n",
      "Stats for event type 'Insta-drop':\n",
      "  Cell accuracy (train): 98.29%\n",
      "  Cell accuracy (test): 97.42%\n",
      "  Board accuracy (train): 34.78%\n",
      "  Board accuracy (test): 0.94%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cell_accuracies_train = compute_metric_by_event(metrics.CellAccuracy, train_dataloader)\n",
    "cell_accuracies_test = compute_metric_by_event(metrics.CellAccuracy, test_dataloader)\n",
    "board_accuracies_train = compute_metric_by_event(metrics.BoardAccuracy, train_dataloader)\n",
    "board_accuracies_test = compute_metric_by_event(metrics.BoardAccuracy, test_dataloader)\n",
    "\n",
    "for event_type in range(NUM_EVENT_TYPES):\n",
    "    print(f\"Stats for event type '{EVENT_NAMES[event_type]}':\")\n",
    "    print(f\"  Cell accuracy (train): {cell_accuracies_train[event_type]:.2%}\")\n",
    "    print(f\"  Cell accuracy (test): {cell_accuracies_test[event_type]:.2%}\")\n",
    "    print(f\"  Board accuracy (train): {board_accuracies_train[event_type]:.2%}\")\n",
    "    print(f\"  Board accuracy (test): {board_accuracies_test[event_type]:.2%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(example):\n",
    "    (b, e), y = example\n",
    "    pred = gen(b.to(device).unsqueeze(0), e.to(device).unsqueeze(0)).squeeze(0).cpu()\n",
    "    b, e, y, pred = b.argmax(0), e.argmax(0), y.argmax(0), pred.argmax(0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    fig.suptitle(f\"Prediction vs reality\\nEvent = {EVENT_NAMES[e]}\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].set_title(\"Predicted\")\n",
    "    axs[2].set_title(\"Reality\")\n",
    "\n",
    "    num_mistakes = (y != pred).type(torch.int).sum().item()\n",
    "    print(f\"Mistakes: {num_mistakes}\")\n",
    "    axs[0].imshow(render_board(b).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[1].imshow(render_board(pred).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[2].imshow(render_board(y).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 4398\n",
      "Mistakes: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAGdCAYAAACPX3D5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAArZ0lEQVR4nO3deXRUVb7+/6cyj2AIYY4hBFEagrahQSGQMEguEbwgUxSEoDSIMqnIT+lWxtW0LUIQuIDagkCwSbgahwUiLKMtUbBbaFpQFCHYDH0hIqOEQFL794ffVFMkJKEIGdjv11qsZe06++xdlY+pJ/ucU8dhjDECAADW8qruCQAAgOpFGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYACqgefPmSk1NdT3++OOP5XA49PHHH1faGA6HQ9OnT6+0/dkoMTFRiYmJrscHDhyQw+HQihUrqm1OQG1AGECNt2LFCjkcDte/gIAAtWrVSuPGjdPRo0ere3pXZf369XzgVzN+BkBJPtU9AaCiZs6cqejoaJ0/f15btmzRkiVLtH79eu3atUtBQUFVOpeuXbsqPz9ffn5+V9Vv/fr1Wrx4cakfRvn5+fLx4X/JyhQVFaX8/Hz5+vq62sr6GQC24jcPao3evXurffv2kqRRo0YpPDxc8+bN0zvvvKMHHnig1D4///yzgoODK30uXl5eCggIqNR9Vvb+arJz585VSYArXkkCUDYOE6DW6t69uyQpNzdXkpSamqqQkBDt27dPycnJCg0N1dChQyVJTqdTaWlpatOmjQICAtSwYUONGTNGJ06ccNunMUazZ89Ws2bNFBQUpG7dumn37t0lxr7SOQPbtm1TcnKywsLCFBwcrHbt2mnBggWu+S1evFiS3A57FCvtnIEdO3aod+/eqlOnjkJCQtSjRw9t3brVbZviwyg5OTl68sknFRERoeDgYPXv3195eXllvodz586Vw+HQDz/8UOK5Z599Vn5+fq73aO/evRowYIAaNWqkgIAANWvWTCkpKTp16lSZYyQmJqpt27b68ssv1bVrVwUFBWnq1KmSpIKCAk2bNk0tW7aUv7+/IiMjNWXKFBUUFLjtY/ny5erevbsaNGggf39//epXv9KSJUvKHFcqec7AlX4Gxhg1b95c//3f/11iH+fPn1fdunU1ZsyYcscDaitWBlBr7du3T5IUHh7uaissLFRSUpLi4+M1d+5c11+fY8aM0YoVKzRy5EhNmDBBubm5WrRokXbs2KGcnBzXMvLzzz+v2bNnKzk5WcnJydq+fbt69eqlCxculDufTZs2qU+fPmrcuLEmTpyoRo0a6ZtvvtH777+viRMnasyYMTpy5Ig2bdqkVatWlbu/3bt3q0uXLqpTp46mTJkiX19fLVu2TImJifrkk0/UsWNHt+3Hjx+vsLAwTZs2TQcOHFBaWprGjRuntWvXXnGMwYMHa8qUKcrIyNDTTz/t9lxGRoZ69eqlsLAwXbhwQUlJSSooKND48ePVqFEjHT58WO+//75OnjypunXrlvlajh8/rt69eyslJUXDhg1Tw4YN5XQ6dd9992nLli0aPXq0Wrdura+++krz58/Xd999p6ysLFf/JUuWqE2bNrrvvvvk4+Oj9957T4899picTqcef/zxct/LYlf6GTgcDg0bNkx/+tOf9NNPP6levXqu59577z2dPn1aw4YNq/A4QK1jgBpu+fLlRpLZvHmzycvLMwcPHjR/+ctfTHh4uAkMDDSHDh0yxhgzYsQII8k888wzbv0//fRTI8mkp6e7tX/wwQdu7ceOHTN+fn7m3nvvNU6n07Xd1KlTjSQzYsQIV1t2draRZLKzs40xxhQWFpro6GgTFRVlTpw44TbOpft6/PHHzZX+t5Nkpk2b5nrcr18/4+fnZ/bt2+dqO3LkiAkNDTVdu3Yt8f707NnTbawnnnjCeHt7m5MnT5Y6XrG7777bxMXFubV98cUXRpJZuXKlMcaYHTt2GEkmMzOzzH2VJiEhwUgyS5cudWtftWqV8fLyMp9++qlb+9KlS40kk5OT42o7d+5cif0mJSWZFi1alBgrISHB9Tg3N9dIMsuXL3e1Xeln8O233xpJZsmSJW7t9913n2nevLnbewvcaDhMgFqjZ8+eioiIUGRkpFJSUhQSEqK3335bTZs2ddtu7Nixbo8zMzNVt25d3XPPPfrxxx9d/+Li4hQSEqLs7GxJ0ubNm3XhwgWNHz/ebfl+0qRJ5c5tx44dys3N1aRJk3TTTTe5PXfpviqqqKhIH374ofr166cWLVq42hs3bqwHH3xQW7Zs0enTp936jB492m2sLl26qKioqNRDAJcaMmSIvvzyS9dKiyStXbtW/v7+rmXz4r/8N27cqHPnzl316/H399fIkSPd2jIzM9W6dWvddtttbj+X4sM/xT8XSQoMDHT996lTp/Tjjz8qISFB+/fvL/cwRUW1atVKHTt2VHp6uqvtp59+0oYNGzR06FCPfo5AbUEYQK2xePFibdq0SdnZ2fr666+1f/9+JSUluW3j4+OjZs2aubXt3btXp06dUoMGDRQREeH27+zZszp27JgkuT40b7nlFrf+ERERCgsLK3NuxR+kbdu2vabXWCwvL0/nzp3TrbfeWuK51q1by+l06uDBg27tN998s9vj4jlffl7E5QYNGiQvLy/X4QRjjDIzM13nKkhSdHS0nnzySb322muqX7++kpKStHjx4gp/EDdt2rTElRd79+7V7t27S/xMWrVqJUmun4sk5eTkqGfPngoODtZNN92kiIgI13kHlRUGJGn48OHKyclx1UJmZqYuXryohx56qNLGAGoizhlArdGhQwfX1QRX4u/vLy8v94zrdDrVoEEDt7/4LhUREVFpc6xO3t7epbYbY8rs16RJE3Xp0kUZGRmaOnWqtm7dqn/961964YUX3LZ76aWXlJqaqnfeeUcffvihJkyYoDlz5mjr1q0lAtjlLv3LvpjT6VRsbKzmzZtXap/IyEhJvwStHj166LbbbtO8efMUGRkpPz8/rV+/XvPnz5fT6Sxz7KuRkpKiJ554Qunp6Zo6dapWr16t9u3blxrKgBsJYQA3vJiYGG3evFmdO3cu9UOpWFRUlKRf/mK9dGk+Ly+v3L+uY2JiJEm7du1Sz549r7hdRZeaIyIiFBQUpG+//bbEc3v27JGXl5frw7IyDBkyRI899pi+/fZbrV27VkFBQerbt2+J7WJjYxUbG6vf//73+uyzz9S5c2ctXbpUs2fPvuoxY2JitHPnTvXo0aPM9+W9995TQUGB3n33XbfVj0sPI1yNssaqV6+e7r33XqWnp2vo0KHKyclRWlqaR+MAtQmHCXDDGzx4sIqKijRr1qwSzxUWFurkyZOSfjknwdfXVwsXLnT7a7oiHwZ33nmnoqOjlZaW5tpfsUv3VfydB5dvczlvb2/16tVL77zzjg4cOOBqP3r0qNasWaP4+HjXEn5lGDBggLy9vfXmm28qMzNTffr0cft+htOnT6uwsNCtT2xsrLy8vEpcBlhRgwcP1uHDh/Xqq6+WeC4/P18///yzpP+seFz6Pp46dUrLly/3aNzyfgYPPfSQvv76az399NPy9vZWSkqKR+MAtQkrA7jhJSQkaMyYMZozZ47+8Y9/qFevXvL19dXevXuVmZmpBQsWaODAgYqIiNDkyZM1Z84c9enTR8nJydqxY4c2bNig+vXrlzmGl5eXlixZor59++qOO+7QyJEj1bhxY+3Zs0e7d+/Wxo0bJUlxcXGSpAkTJigpKanMD5vZs2dr06ZNio+P12OPPSYfHx8tW7ZMBQUF+tOf/lSp71GDBg3UrVs3zZs3T2fOnNGQIUPcnv/oo480btw4DRo0SK1atVJhYaFWrVolb29vDRgwwKMxH3roIWVkZOjRRx9Vdna2OnfurKKiIu3Zs0cZGRnauHGj2rdvr169esnPz099+/bVmDFjdPbsWb366qtq0KCB/v3vf1/1uOX9DO69916Fh4e7zpto0KCBR68PqFWq9VoGoAKKL53729/+VuZ2I0aMMMHBwVd8/pVXXjFxcXEmMDDQhIaGmtjYWDNlyhRz5MgR1zZFRUVmxowZpnHjxiYwMNAkJiaaXbt2maioqDIvLSy2ZcsWc88995jQ0FATHBxs2rVrZxYuXOh6vrCw0IwfP95EREQYh8PhdombLru00Bhjtm/fbpKSkkxISIgJCgoy3bp1M5999lmF3p8rzfFKXn31VSPJhIaGmvz8fLfn9u/fbx5++GETExNjAgICTL169Uy3bt3M5s2by91vQkKCadOmTanPXbhwwbzwwgumTZs2xt/f34SFhZm4uDgzY8YMc+rUKdd27777rmnXrp0JCAgwzZs3Ny+88IJ5/fXXjSSTm5vrNlZ5lxaW9TMo9thjjxlJZs2aNeW+PuBG4DCmnLOLAMAyTzzxhP785z/r//7v/6r8vhdAdeCcAQC4xPnz57V69WoNGDCAIABrcM4AAOiX7zXYvHmz1q1bp+PHj2vixInVPSWgyhAGAEDS119/raFDh6pBgwZ6+eWXdccdd1T3lIAqwzkDAABYjnMGAACwHGEAAADLEQYAALAcYQD4f1asWCGHw3HFf1u3bq3uKeqzzz7T9OnTy/064+th+vTpbu9HUFCQbr75ZvXt21fLly/3+GuJAVQ/riYALjNz5kxFR0eXaG/ZsmU1zMbdZ599phkzZig1NVU33XRTtcxhyZIlCgkJUUFBgQ4fPqyNGzfq4YcfVlpamt5///1KvYESgKpBGAAu07t373JvlWyzgQMHut2r4fnnn1d6erqGDx+uQYMGlbuCcu7cOb7MB6hhOEwAXIWLFy+qXr16GjlyZInnTp8+rYCAAE2ePNnVVlBQoGnTpqlly5by9/dXZGSkpkyZUmJJ3eFwaNy4ccrKylLbtm3l7++vNm3a6IMPPnBtM336dD399NOSpOjoaNdy/aV3NawuQ4cO1ahRo7Rt2zZt2rTJ1Z6YmKi2bdvqyy+/VNeuXRUUFKSpU6dK+uVLfh555BE1bNhQAQEBuv322/XGG2+47ffAgQNyOByaO3eu5s+fr6ioKAUGBiohIUG7du2q0tcI3MhYGQAuc+rUKf34449ubQ6HQ+Hh4fL19VX//v311ltvadmyZfLz83Ntk5WVpYKCAtcd8JxOp+677z5t2bJFo0ePVuvWrfXVV19p/vz5+u6775SVleU2xpYtW/TWW2/pscceU2hoqF5++WUNGDBA//rXvxQeHq77779f3333nd58803Nnz/f9dd5RETEFV/LuXPndO7cuXJfs7e3t8LCwir6FpXqoYce0iuvvKIPP/xQ99xzj6v9+PHj6t27t1JSUjRs2DA1bNhQ+fn5SkxM1Pfff69x48YpOjpamZmZSk1N1cmTJ0t8+9/KlSt15swZPf744zp//rwWLFig7t2766uvvlLDhg2vad4AxF0LgWLFd/8r7Z+/v79ru40bNxpJ5r333nPrn5ycbFq0aOF6vGrVKuPl5WU+/fRTt+2WLl1qJJmcnBxXmyTj5+dnvv/+e1fbzp07jSS3ux6++OKLJe7UV5Zp06Zd8TVd+i8qKqrC+8rLyyv1+RMnThhJpn///q62hIQEI8ksXbrUbdu0tDQjyaxevdrVduHCBXP33XebkJAQc/r0aWPMf+46GBgYaA4dOuTadtu2bUaSeeKJJyr0PgAoGysDwGUWL16sVq1aubV5e3u7/rt79+6qX7++1q5dqz59+kiSTpw4oU2bNrkdIsjMzFTr1q112223ua00dO/eXZKUnZ2tTp06udp79uypmJgY1+N27dqpTp062r9/v8evZfjw4YqPjy93u8DAQI/HKBYSEiJJOnPmjFu7v79/icMq69evV6NGjfTAAw+42nx9fTVhwgQ98MAD+uSTT1zvrST169dPTZs2dT3u0KGDOnbsqPXr12vevHnXPHfAdoQB4DIdOnQo8wRCHx8fDRgwQGvWrFFBQYH8/f311ltv6eLFixoyZIhru7179+qbb7654jL+sWPH3B7ffPPNJbYJCwvTiRMnPHwlUosWLdSiRQuP+1+Ns2fPSpJCQ0Pd2ps2bep2OEWSfvjhB91yyy3y8nI/bal169au5y91yy23lBivVatWysjIuOZ5AyAMAB5JSUnRsmXLtGHDBvXr108ZGRm67bbbdPvtt7u2cTqdio2NveJfrpdfgnfp6sOlzDXcPuTs2bOuD+myeHt7l3nuQUUUn9B3+SWYlbHqAOD6IgwAHujatasaN26stWvXKj4+Xh999JF+97vfuW0TExOjnTt3qkePHnI4HJUy7tXuZ+7cuZoxY0a520VFRV3zVQmrVq2SJCUlJVVovH/+859yOp1uqwN79uxxPX+pvXv3ltjHd999p+bNm1/DjAEUIwwAHvDy8tLAgQP1+uuvq0OHDiosLHQ7RCBJgwcP1vr16/Xqq69q9OjRbs/l5+fL6XQqODj4qsYt3r6i30BYVecMrFmzRq+99pruvvtu9ejRo9ztk5OT9eGHH2rt2rWu8wYKCwu1cOFChYSEKCEhwW37rKwsHT582HXewBdffKFt27Zp0qRJ1zRvAL8gDACX2bBhg+sv1Et16tTJ7fj7kCFDtHDhQk2bNk2xsbGu493FHnroIWVkZOjRRx9Vdna2OnfurKKiIu3Zs0cZGRnauHHjVX+5UVxcnCTpd7/7nVJSUuTr66u+ffteMVRcj3MG1q1bp5CQEF24cMH1DYQ5OTm6/fbblZmZWaF9jB49WsuWLVNqaqq+/PJLNW/eXOvWrVNOTo7S0tJKnHfQsmVLxcfHa+zYsSooKFBaWprCw8M1ZcqUSn1tgK0IA8Blnn/++VLbly9f7vbB2qlTJ0VGRurgwYMlVgWkX1YPsrKyNH/+fK1cuVJvv/22goKC1KJFC02cOLHEFQsV8Zvf/EazZs3S0qVL9cEHH8jpdCo3N/eqVxiuxdixYyVJAQEBql+/vu644w69/vrrevDBB+Xv71+hfQQGBurjjz/WM888ozfeeEOnT5/WrbfequXLlys1NbXE9sOHD5eXl5fS0tJ07NgxdejQQYsWLVLjxo0r86UB1nKYazk7CQCuowMHDig6Olovvvii22WbACoXX0cMAIDlCAMAAFiOMAAAgOU4ZwAAAMuxMgAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYjjAAWKZ58+ZKTU11Pf7444/lcDj08ccfV9ucLnf5HIGKOHDggBwOh1asWOFqmz59uhwOR/VNqpawOgysWLFCDodDf//736t7Kjp37pymT59eo34h4/oorrvifwEBAWrVqpXGjRuno0ePVvf0Kmz9+vWaPn16dU8DNdDlNe7j46OmTZsqNTVVhw8fru7p6Q9/+IOysrKqexo1itVhoCY5d+6cZsyYQRiwyMyZM7Vq1SotWrRInTp10pIlS3T33Xfr3LlzVTqPrl27Kj8/X127dr2qfuvXr9eMGTOu06xwIyiu8aVLl6p3795avXq1EhISdP78+Sqbw+9//3vl5+e7tREGSvKp7gkAturdu7fat28vSRo1apTCw8M1b948vfPOO3rggQdKbP/zzz8rODi40ufh5eWlgICASt8vcHmN169fXy+88ILeffddDR48uErm4OPjIx8fPurKw8rAJVJTUxUSEqLDhw+rX79+CgkJUUREhCZPnqyioiLXdsXHpebOnav58+crKipKgYGBSkhI0K5du9z2mZiYqMTExFLHat68uWt/ERERkqQZM2a4ltZYgrVL9+7dJUm5ubmuWty3b5+Sk5MVGhqqoUOHSpKcTqfS0tLUpk0bBQQEqGHDhhozZoxOnDjhtj9jjGbPnq1mzZopKChI3bp10+7du0uMe6VzBrZt26bk5GSFhYUpODhY7dq104IFCyT9Ur+LFy+WJLfl4GKVPUfcGLp06SJJ2rdvn6ttz549GjhwoOrVq6eAgAC1b99e7777rlu/n376SZMnT1ZsbKxCQkJUp04d9e7dWzt37ix3zMvPGXA4HPr555/1xhtvuOo2NTVV2dnZcjgcevvtt0vsY82aNXI4HPr88889fek1HnHpMkVFRUpKSlLHjh01d+5cbd68WS+99JJiYmI0duxYt21XrlypM2fO6PHHH9f58+e1YMECde/eXV999ZUaNmxY4TEjIiK0ZMkSjR07Vv3799f9998vSWrXrl2lvjbUbMW/IMPDwyVJhYWFSkpKUnx8vObOnaugoCBJ0pgxY7RixQqNHDlSEyZMUG5urhYtWqQdO3YoJydHvr6+kqTnn39es2fPVnJyspKTk7V9+3b16tVLFy5cKHcumzZtUp8+fdS4cWNNnDhRjRo10jfffKP3339fEydO1JgxY3TkyBFt2rRJq1atKtG/KuaI2ufAgQOSpLCwMEnS7t271blzZzVt2lTPPPOMgoODlZGRoX79+ul///d/1b9/f0nS/v37lZWVpUGDBik6OlpHjx7VsmXLlJCQoK+//lpNmjSp8BxWrVqlUaNGqUOHDho9erQkKSYmRnfddZciIyOVnp7uGrdYenq6YmJidPfdd1fCu1BDGYstX77cSDJ/+9vfjDHGjBgxwkgyM2fOdNvu17/+tYmLi3M9zs3NNZJMYGCgOXTokKt927ZtRpJ54oknXG0JCQkmISGhxNgjRowwUVFRrsd5eXlGkpk2bVrlvDjUWMV1t3nzZpOXl2cOHjxo/vKXv5jw8HBXTRXX4jPPPOPW99NPPzWSTHp6ulv7Bx984NZ+7Ngx4+fnZ+69917jdDpd202dOtVIMiNGjHC1ZWdnG0kmOzvbGGNMYWGhiY6ONlFRUebEiRNu41y6r8cff9yU9ivkeswRtUtpNb5u3ToTERFh/P39zcGDB40xxvTo0cPExsaa8+fPu/o6nU7TqVMnc8stt7jazp8/b4qKitzGyM3NNf7+/m6/r4t/Ny9fvtzVNm3atBJ1GhwcXGp9Pfvss8bf39+cPHnS1Xbs2DHj4+Nzw/9u5jBBKR599FG3x126dNH+/ftLbNevXz81bdrU9bhDhw7q2LGj1q9ff93niNqvZ8+eioiIUGRkpFJSUhQSEqK3337braYuX43KzMxU3bp1dc899+jHH390/YuLi1NISIiys7MlSZs3b9aFCxc0fvx4tyXSSZMmlTuvHTt2KDc3V5MmTdJNN93k9lxFLtGqijmidri0xgcOHKjg4GC9++67atasmX766Sd99NFHGjx4sM6cOeOqk+PHjyspKUl79+51XXng7+8vL69fPq6Kiop0/PhxhYSE6NZbb9X27dsrbb7Dhw9XQUGB1q1b52pbu3atCgsLNWzYsEobpybiMMFlAgICXMfvi4WFhZU41ilJt9xyS4m2Vq1aKSMj47rNDzeOxYsXq1WrVvLx8VHDhg116623un7hSb+c+NSsWTO3Pnv37tWpU6fUoEGDUvd57NgxSdIPP/wgqWSNRkREuJZor6T4cEXbtm2v7gVV4RxROxTX+KlTp/T666/rr3/9q/z9/SVJ33//vYwxeu655/Tcc8+V2v/YsWNq2rSpnE6nFixYoP/5n/9Rbm6u2zlcxYfVKsNtt92m3/zmN0pPT9cjjzwi6ZdDBHfddZdatmxZaePURISBy3h7e1fq/hwOh4wxJdovLWbYqUOHDq4zrUtz6V9DxZxOpxo0aKD09PRS+1weZKtDbZgjqsalNd6vXz/Fx8frwQcf1Lfffiun0ylJmjx5spKSkkrtX/wB/Ic//EHPPfecHn74Yc2aNUv16tWTl5eXJk2a5NpPZRk+fLgmTpyoQ4cOqaCgQFu3btWiRYsqdYyaiDBwDfbu3Vui7bvvvnNdJSD9sqpQ2iGG4r+KivENWaiImJgYbd68WZ07d1ZgYOAVt4uKipL0S422aNHC1Z6Xl1fqKtflY0jSrl271LNnzytud6WarYo5ovbx9vbWnDlz1K1bNy1atEgPP/ywJMnX17fMOpOkdevWqVu3bvrzn//s1n7y5EnVr1//qudS1u/blJQUPfnkk3rzzTeVn58vX19fDRky5KrHqG04Z+AaZGVluX2b1hdffKFt27apd+/erraYmBjt2bNHeXl5rradO3cqJyfHbV/FZ4qfPHny+k4atdrgwYNVVFSkWbNmlXiusLDQVT89e/aUr6+vFi5c6LYylZaWVu4Yd955p6Kjo5WWllaiHi/dV/F3Hly+TVXMEbVTYmKiOnTooLS0NNWpU0eJiYlatmyZ/v3vf5fY9tLfmd7e3iVWWDMzMz3+NsPg4OAr/q6tX7++6wuS0tPT9V//9V8eBY7ahpWBa9CyZUvFx8dr7NixKigoUFpamsLDwzVlyhTXNg8//LDmzZunpKQkPfLIIzp27JiWLl2qNm3a6PTp067tAgMD9atf/Upr165Vq1atVK9ePbVt29bj47a4MSUkJGjMmDGaM2eO/vGPf6hXr17y9fXV3r17lZmZqQULFmjgwIGu78eYM2eO+vTpo+TkZO3YsUMbNmwo9xebl5eXlixZor59++qOO+7QyJEj1bhxY+3Zs0e7d+/Wxo0bJUlxcXGSpAkTJigpKUne3t5KSUmpkjmi9nr66ac1aNAgrVixQosXL1Z8fLxiY2P129/+Vi1atNDRo0f1+eef69ChQ67vEejTp49mzpypkSNHqlOnTvrqq6+Unp7utqJ0NeLi4rR582bNmzdPTZo0UXR0tDp27Oh6fvjw4Ro4cKAklRpqb0jVeSlDdSvt0sLg4OAS211+aUrx5Ssvvviieemll0xkZKTx9/c3Xbp0MTt37izRf/Xq1aZFixbGz8/P3HHHHWbjxo0lLi00xpjPPvvMxMXFGT8/Py4zvIFdXneluVItFnvllVdMXFycCQwMNKGhoSY2NtZMmTLFHDlyxLVNUVGRmTFjhmncuLEJDAw0iYmJZteuXSYqKqrMSwuLbdmyxdxzzz0mNDTUBAcHm3bt2pmFCxe6ni8sLDTjx483ERERxuFwlLh8qzLniNqlrBovKioyMTExJiYmxhQWFpp9+/aZ4cOHm0aNGhlfX1/TtGlT06dPH7Nu3TpXn/Pnz5unnnrKVSedO3c2n3/+eYlLtyt6aeGePXtM165dTWBgYKmXsRYUFJiwsDBTt25dk5+fXynvSU3nMKaUs9tQpgMHDig6OlovvviiJk+eXN3TAQBUosLCQjVp0kR9+/YtcZ7CjYpzBgAAuERWVpby8vI0fPjw6p5KleGcAQAA9Mv9OP75z39q1qxZ+vWvf62EhITqnlKVYWUAAADJdY+YBg0aaOXKldU9nSrFOQMAAFiOlQEAACxHGAAAwHIVOoHQ6XTqyJEjCg0N5Wtz4TFjjM6cOaMmTZqU+M7964XaRWWgdlFbVbR2KxQGjhw5osjIyEqbHOx28ODBEnfju16oXVQmahe1VXm1W6GIGxoaWmkTAqqynqhdVCZqF7VVefVUoTDAEhUqU1XWE7WLykTtorYqr544gRAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALBchW5hjJpr1NanqnzM1+56qcrHBABcP6wMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOe5aWENw90HYhppHbXUj1i4rAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5biFcQ3BrVVRW92It3OFHajd/2BlAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyzmMMaa8jU6fPq26detWxXxggVOnTqlOnTpVMha1i8pE7aK2Kq92WRkAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByPlez8Qsf9VRgiO9VDzKhw4ar7gNUJmoXtRW1i6rAygAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAlvO5mo3XvHdc3v7eVz3IqK1PXXUfSdqe9YlH/arL9j/+vbqnUCXMoEEe9Tt98aLqZmVV7mQqiNotG7VbNmq35qJ2y1bR2mVlAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACw3FXdwvjBvuEKDPG96kEmdHjpqvtI0p3PtPeonyR9Wd/pcV+Pzb3T466/je9WiROpmPqrZ3rU71kPxyu4cFpSloe9rw21Ww5qt0zUbsVQu+WrqbXLygAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYLmruoVxVdv+x7973DfOw9twpt4f4fGY4/961OO+nt7W8sdhz3s85h8XBXvU7+UvenvUL//sRekVj7rWOtRu+ajdmonaLd+NWLusDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYLkquWvhnR7eyaq2efbApx739fROVqOGPeXxmGbQII/6LdRZj8esbajd8lG7NRO1Wz5q9z9YGQAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALFcltzD21J39Eqph1K897vlhSHXM13O/fepmj/q1u4b3yBbU7vVF7V4/1O71VVNrl5UBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsRxgAAMByhAEAACxHGAAAwHKEAQAALEcYAADAcoQBAAAsVyV3Layeu2B55p/OX11D708qbR6oGahd1FbULq4GKwMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOWq5BbGr931kkf9Rm19qpJnUr76q2d63jnE81uG3vlMe8/HxXVD7ZaP2q2ZqN3yUbv/wcoAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGC5KrmFsae2Z33icd9eZz3v66k7+3l+K01PXcutP38c9nwlzgSXonbLR+3WTNRu+W7E2mVlAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAy1XJXQvN3Ds97On0eMw4eXYnq9T7Izwe88O38jzuO6r1Gs86/uawx2P+8a6XPOpnBg3yqN/pixf1/3nUs/pQu+Wjdmsmard81O5/sDIAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiOMAAAgOUIAwAAWI4wAACA5QgDAABYjjAAAIDlCAMAAFiuSm5hXB22//HvHvVLvb93Jc+k5vL0lpi4vqjd8lG7NRO1W76aWrusDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYDnCAAAAliMMAABgOcIAAACWIwwAAGA5wgAAAJYjDAAAYLkb9q6FL39R9XfB8vSOXZKkNypvHhX1bMMVHvWbczS1UucBd9Ru+ajdmonaLV9NrV1WBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACwHGEAAADLEQYAALAcYQAAAMsRBgAAsFyF7lpojJEknf+50KNBTp8v8qjftcg/e7HKx7wW+flnq3zMggunPep3+qJn721xv+J6qgrU7vVH7V4f1O71R+3+h8NUoLoPHTqkyMhIjyYCXO7gwYNq1qxZlYxF7aIyUbuorcqr3QqFAafTqSNHjig0NFQOh6NSJwh7GGN05swZNWnSRF5eVXOEitpFZaB2UVtVtHYrFAYAAMCNixMIAQCwHGEAAADLEQYAALAcYQAAAMsRBgAAsBxhAAAAyxEGAACw3P8PfylnUNUGVhsAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random training prediction vs reality\n",
    "import random\n",
    "\n",
    "idx = random.randrange(len(train_dataset))\n",
    "print(f\"Showing prediction for training example {idx}\")\n",
    "show_prediction(train_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), \"gamegan_emulator.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architectural imrpovements made to the board encoder and renderer from experimenting with autoencoders paid off! With transfer learning, we get 50% training and 20% test board accuracy after 1500 epochs. With fine-tuning, we get 59% training and 30% test board accuracy after 100 epochs. With fine-tuning, we also get over 85% spawn recall.\n",
    "\n",
    "I evaluated the model trained with fine-tuning by using it to play the game. Blocks spawned reliably, but they were always T-blocks. Falling blocks quickly morphed, and disappeared by the time they reached the middle of the board. Cells randomly filled in at the bottom of the board. Insta-drop didn't work properly at all. Overall, several interesting things happened, but it's not yet Tetris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Fine-tuning the trained autoencoder leads to much better performance than any GameGAN-based models tried so far. As a next step, we can try training end-to-end with the same architecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
