{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 032\n",
    "\n",
    "In this experiment, we will train end-to-end with the board encoder and renderer architectures discovered during the autoencoder experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import models\n",
    "from models import TetrisModel, TetrisDiscriminator, GameganAutoencoder\n",
    "import metrics\n",
    "from recording import FileBasedDatabaseWithEvents\n",
    "from engines import EVENT_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CELL_TYPES = 8\n",
    "NUM_EVENT_TYPES = 5\n",
    "\n",
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self._db = FileBasedDatabaseWithEvents(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._db)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        boards, events = self._db[idx]\n",
    "        b = self._transform_board(boards[-2]) # Ignore all boards except the last two\n",
    "        e = self._transform_event(events[-1])\n",
    "        x = (b, e)\n",
    "        y = self._transform_board(boards[-1])\n",
    "        return x, y\n",
    "    \n",
    "    def _transform_board(self, board):\n",
    "        board = torch.tensor(board, dtype=torch.long)\n",
    "        board = F.one_hot(board, NUM_CELL_TYPES) # One-hot encode the cell types\n",
    "        board = board.type(torch.float) # Convert to floating-point\n",
    "        board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "        return board\n",
    "    \n",
    "    def _transform_event(self, event):\n",
    "        event = torch.tensor(event, dtype=torch.long)\n",
    "        event = F.one_hot(event, NUM_EVENT_TYPES) # One-hot encode the event\n",
    "        event = event.type(torch.float) # Convert to floating-point\n",
    "        return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: shape torch.Size([12, 8, 22, 10]), dtype torch.float32\n",
      "e: shape torch.Size([12, 5]), dtype torch.float32\n",
      "y: shape torch.Size([12, 8, 22, 10]), dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Put datasets in memory for faster training\n",
    "train_dataset = list(RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\")))\n",
    "test_dataset = list(RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\")))\n",
    "batch_size = 12\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "(b, e), y = next(iter(train_dataloader))\n",
    "print(f\"x: shape {b.shape}, dtype {b.dtype}\")\n",
    "print(f\"e: shape {e.shape}, dtype {e.dtype}\")\n",
    "print(f\"y: shape {y.shape}, dtype {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_by_event(metric_cls, dataloader):\n",
    "    metrics = [metric_cls() for _ in range(NUM_EVENT_TYPES)]\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        for ((b, e), y) in dataloader:\n",
    "            b = b.to(device)\n",
    "            e = e.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            batch_size = b.size(0)\n",
    "\n",
    "            y_fake = gen(b, e)\n",
    "            \n",
    "            classes_b = torch.argmax(b, dim=1)\n",
    "            classes_e = torch.argmax(e, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "\n",
    "            for idx in range(batch_size):\n",
    "                class_e = classes_e[idx]\n",
    "                metric = metrics[class_e]\n",
    "                metric.update_state(classes_x=classes_b[idx:idx+1], classes_y_pred=classes_y_fake[idx:idx+1], classes_y=classes_y[idx:idx+1])\n",
    "\n",
    "    return [metric.result() for metric in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.10.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from engines import EventTypes\n",
    "\n",
    "def find_interesting_examples(dataset, num=3):\n",
    "    num_spawns = num\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "\n",
    "        for (b, e), y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (e.argmax(0).item() == EventTypes.DROP) & (b.argmax(0)[0] == 0).all() & (y.argmax(0)[0] > 0).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield (b, e), y\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))\n",
    "from tetris import CELL_COLORS\n",
    "\n",
    "def render_board(board):\n",
    "    height, width = board.shape\n",
    "    img = np.zeros((3, height, width))\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            img[:, row, col] = CELL_COLORS[board[row, col]]\n",
    "    img /= 255.0\n",
    "    return img\n",
    "def render_prediction(b, e, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        b: Tensor of shape (height, width), the initial board state.\n",
    "        e: Tensor of shape (1,), the event type.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the next board state.\n",
    "    \"\"\"\n",
    "    assert len(b.shape) == 2, f\"Expected tensors of shape (width, height) but got {b.shape}\"\n",
    "    assert b.shape == pred.shape, f\"Shapes do not match: {b.shape} != {pred.shape}\"\n",
    "    assert b.shape == y.shape, f\"Shapes do not match: {b.shape} != {y.shape}\"\n",
    "    assert len(e.shape) == 0, f\"Expected e of shape () but got {e.shape}\"\n",
    "    height, width = b.shape\n",
    "    with torch.no_grad():\n",
    "        b = render_board(b)\n",
    "        pred = render_board(pred)\n",
    "        y = render_board(y)\n",
    "        separator = np.ones((3, height, 1))\n",
    "        return np.concatenate((b, separator, pred, separator, y), axis=-1)\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, ((b, e), y) in enumerate(dataloader):\n",
    "        b = b.to(device)\n",
    "        e = e.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        batch_size = b.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(b, e, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(b, e)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(b, e, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(b, e, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 30 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = metrics.CellAccuracy()\n",
    "    board_accuracy = metrics.BoardAccuracy()\n",
    "    spawn_recall = metrics.SpawnRecall()\n",
    "    scores_real = np.zeros(len(dataloader.dataset))\n",
    "    scores_fake = np.zeros(len(dataloader.dataset))\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for batch, ((b, e), y) in enumerate(dataloader):\n",
    "            b = b.to(device)\n",
    "            e = e.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            batch_size = b.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(b, e, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            y_fake = gen(b, e)\n",
    "            output_fake = disc(b, e, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_b = torch.argmax(b, dim=1)\n",
    "            classes_e = torch.argmax(e, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy.update_state(classes_y_fake, classes_y)\n",
    "            board_accuracy.update_state(classes_y_fake, classes_y)\n",
    "\n",
    "            spawn_recall.update_state(classes_b, classes_y_fake, classes_y)\n",
    "\n",
    "            start_index = dataloader.batch_size * batch\n",
    "            end_index = start_index + batch_size\n",
    "            scores_real[start_index:end_index] = torch.sigmoid(output_real).cpu().numpy()\n",
    "            scores_fake[start_index:end_index] = torch.sigmoid(output_fake).cpu().numpy()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(cell_accuracy.result()):>0.1%}, board accuracy: {(board_accuracy.result()):>0.1%} \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall.result(), epoch)\n",
    "\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/real\", scores_real, epoch)\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/fake\", scores_fake, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name, gen_factory, disc_factory, epochs):\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    gen = gen_factory()\n",
    "    disc = disc_factory()\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_032\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "            train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "            test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch)\n",
    "            test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch)\n",
    "            gen_zero_grads = 0\n",
    "            for name, weight in gen.named_parameters():\n",
    "                tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "                if weight.grad is not None:\n",
    "                    tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "                    gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "            tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "            disc_zero_grads = 0\n",
    "            for name, weight in disc.named_parameters():\n",
    "                tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "                if weight.grad is not None:\n",
    "                    tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "                    disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "            tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "    finally:\n",
    "        tb_writer.close()\n",
    "        \n",
    "    print(\"Done!\")\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 590280\n"
     ]
    }
   ],
   "source": [
    "NUM_RANDOM_INPUTS = 4\n",
    "\n",
    "\n",
    "from models import Conv2dLeakyReLU, ConvTranspose2dLeakyReLU, LinearLeakyReLU\n",
    "\n",
    "\n",
    "class GameganGenerator(nn.Module):\n",
    "    def __init__(self, leak=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.leak = leak\n",
    "\n",
    "        self.board_encoder = models.GameganBoardEncoder()\n",
    "\n",
    "        self.event_encoder = nn.Sequential(\n",
    "            LinearLeakyReLU(NUM_EVENT_TYPES + NUM_RANDOM_INPUTS, 32, negative_slope=leak),\n",
    "            LinearLeakyReLU(32, 32, negative_slope=leak),\n",
    "            LinearLeakyReLU(32, 32, negative_slope=leak),\n",
    "        )\n",
    "\n",
    "        self.dynamics = nn.Sequential(\n",
    "            LinearLeakyReLU(256 + 32, 256, negative_slope=leak),\n",
    "            LinearLeakyReLU(256, 256, negative_slope=leak),\n",
    "            LinearLeakyReLU(256, 256, negative_slope=leak),\n",
    "        )\n",
    "\n",
    "        self.renderer = models.GameganRenderer()\n",
    "\n",
    "    def forward(self, b, e):\n",
    "        batch_size, cell_channels, height, width = b.shape\n",
    "\n",
    "        # Encode board state\n",
    "        s = self.board_encoder(b)\n",
    "\n",
    "        # Generate random inputs\n",
    "        z = torch.rand(batch_size, NUM_RANDOM_INPUTS, device=device)\n",
    "\n",
    "        # Encode events and random inputs\n",
    "        v = self.event_encoder(torch.cat((e, z), dim=1))\n",
    "\n",
    "        # Combine encodings\n",
    "        h = torch.cat((s, v), dim=1)\n",
    "\n",
    "        # Apply game dynamics\n",
    "        h = self.dynamics(h)\n",
    "\n",
    "        # Render new board\n",
    "        y = self.renderer(h)\n",
    "        return y\n",
    "\n",
    "\n",
    "print(f\"Parameters: {count_parameters(GameganGenerator())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 51329\n"
     ]
    }
   ],
   "source": [
    "class GameganDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "            Conv2dLeakyReLU(2 * NUM_CELL_TYPES + NUM_EVENT_TYPES, 32, kernel_size=3),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            LinearLeakyReLU(416, 32),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Flatten(start_dim=0),\n",
    "        )\n",
    "\n",
    "    def forward(self, b, e, y):\n",
    "        batch_size, cell_channels, height, width = b.shape\n",
    "\n",
    "        # Upscale events to board size\n",
    "        e = e[:, :, None, None].repeat(1, 1, height, width)\n",
    "\n",
    "        # Combine cells, events and random inputs\n",
    "        x = torch.cat((b, e, y), dim=1)\n",
    "\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "print(f\"Parameters: {count_parameters(GameganDiscriminator())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.3912, G loss: 0.6931\n",
      "[372/8000] D loss: 1.1571, G loss: 0.8569\n",
      "[732/8000] D loss: 0.3477, G loss: 2.0778\n",
      "[1092/8000] D loss: 0.1320, G loss: 3.6649\n",
      "[1452/8000] D loss: 0.0104, G loss: 5.1482\n",
      "[1812/8000] D loss: 0.0097, G loss: 6.2714\n",
      "[2172/8000] D loss: 0.0284, G loss: 6.2228\n",
      "[2532/8000] D loss: 0.0260, G loss: 5.9038\n",
      "[2892/8000] D loss: 0.0317, G loss: 6.9179\n",
      "[3252/8000] D loss: 0.0377, G loss: 5.4120\n",
      "[3612/8000] D loss: 0.4119, G loss: 4.4205\n",
      "[3972/8000] D loss: 0.2719, G loss: 3.7956\n",
      "[4332/8000] D loss: 0.1193, G loss: 4.2025\n",
      "[4692/8000] D loss: 0.1362, G loss: 4.6052\n",
      "[5052/8000] D loss: 0.0677, G loss: 4.4284\n",
      "[5412/8000] D loss: 1.0980, G loss: 1.6414\n",
      "[5772/8000] D loss: 0.5068, G loss: 3.2328\n",
      "[6132/8000] D loss: 0.1739, G loss: 5.2081\n",
      "[6492/8000] D loss: 0.1751, G loss: 4.2970\n",
      "[6852/8000] D loss: 0.2537, G loss: 2.9841\n",
      "[7212/8000] D loss: 0.1217, G loss: 4.4082\n",
      "[7572/8000] D loss: 0.2621, G loss: 5.7745\n",
      "[7932/8000] D loss: 0.1882, G loss: 3.4089\n",
      "train error: \n",
      " D loss: 0.178024, G loss: 3.576594, D accuracy: 98.6%, cell accuracy: 64.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.177626, G loss: 3.599519, D accuracy: 98.6%, cell accuracy: 64.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3234, G loss: 3.2203\n",
      "[372/8000] D loss: 0.2076, G loss: 2.8746\n",
      "[732/8000] D loss: 0.2384, G loss: 3.0808\n",
      "[1092/8000] D loss: 0.3044, G loss: 2.7421\n",
      "[1452/8000] D loss: 0.2450, G loss: 3.3004\n",
      "[1812/8000] D loss: 0.3443, G loss: 4.8210\n",
      "[2172/8000] D loss: 0.5406, G loss: 2.8327\n",
      "[2532/8000] D loss: 0.2829, G loss: 3.9371\n",
      "[2892/8000] D loss: 0.1575, G loss: 3.1842\n",
      "[3252/8000] D loss: 0.6505, G loss: 2.9148\n",
      "[3612/8000] D loss: 0.2397, G loss: 5.0566\n",
      "[3972/8000] D loss: 0.1087, G loss: 4.0463\n",
      "[4332/8000] D loss: 0.0742, G loss: 4.5262\n",
      "[4692/8000] D loss: 0.1196, G loss: 4.5850\n",
      "[5052/8000] D loss: 0.2241, G loss: 5.0734\n",
      "[5412/8000] D loss: 0.0641, G loss: 5.2541\n",
      "[5772/8000] D loss: 0.3064, G loss: 4.6501\n",
      "[6132/8000] D loss: 0.3019, G loss: 3.7141\n",
      "[6492/8000] D loss: 0.1690, G loss: 5.7173\n",
      "[6852/8000] D loss: 1.7696, G loss: 4.7964\n",
      "[7212/8000] D loss: 0.3202, G loss: 2.5436\n",
      "[7572/8000] D loss: 0.2233, G loss: 3.4545\n",
      "[7932/8000] D loss: 0.2392, G loss: 4.1632\n",
      "train error: \n",
      " D loss: 0.428862, G loss: 5.675266, D accuracy: 90.4%, cell accuracy: 71.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.442278, G loss: 5.627739, D accuracy: 90.2%, cell accuracy: 71.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5658, G loss: 4.3550\n",
      "[372/8000] D loss: 0.3220, G loss: 4.7414\n",
      "[732/8000] D loss: 0.5083, G loss: 2.3117\n",
      "[1092/8000] D loss: 0.1260, G loss: 4.3665\n",
      "[1452/8000] D loss: 0.2195, G loss: 4.9055\n",
      "[1812/8000] D loss: 0.2735, G loss: 2.3515\n",
      "[2172/8000] D loss: 0.1157, G loss: 4.6817\n",
      "[2532/8000] D loss: 0.2117, G loss: 3.5699\n",
      "[2892/8000] D loss: 0.3260, G loss: 4.9131\n",
      "[3252/8000] D loss: 0.1859, G loss: 3.7618\n",
      "[3612/8000] D loss: 0.1356, G loss: 2.1385\n",
      "[3972/8000] D loss: 0.3800, G loss: 4.3478\n",
      "[4332/8000] D loss: 0.2268, G loss: 3.1116\n",
      "[4692/8000] D loss: 0.5411, G loss: 2.2597\n",
      "[5052/8000] D loss: 0.0893, G loss: 7.0516\n",
      "[5412/8000] D loss: 0.2045, G loss: 4.2323\n",
      "[5772/8000] D loss: 0.1542, G loss: 3.7335\n",
      "[6132/8000] D loss: 0.1506, G loss: 5.2848\n",
      "[6492/8000] D loss: 0.0934, G loss: 4.7665\n",
      "[6852/8000] D loss: 0.0293, G loss: 6.8326\n",
      "[7212/8000] D loss: 0.0797, G loss: 4.1143\n",
      "[7572/8000] D loss: 0.0930, G loss: 3.7173\n",
      "[7932/8000] D loss: 0.0368, G loss: 5.9028\n",
      "train error: \n",
      " D loss: 0.136574, G loss: 5.875897, D accuracy: 98.1%, cell accuracy: 72.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.146466, G loss: 5.843845, D accuracy: 98.1%, cell accuracy: 72.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0186, G loss: 6.2350\n",
      "[372/8000] D loss: 0.1340, G loss: 5.3336\n",
      "[732/8000] D loss: 0.0574, G loss: 4.7604\n",
      "[1092/8000] D loss: 0.1063, G loss: 5.6871\n",
      "[1452/8000] D loss: 0.6700, G loss: 6.5285\n",
      "[1812/8000] D loss: 0.3520, G loss: 6.3070\n",
      "[2172/8000] D loss: 0.1515, G loss: 4.3904\n",
      "[2532/8000] D loss: 0.3306, G loss: 3.4595\n",
      "[2892/8000] D loss: 0.0508, G loss: 5.3587\n",
      "[3252/8000] D loss: 0.1946, G loss: 4.1515\n",
      "[3612/8000] D loss: 0.1131, G loss: 4.1335\n",
      "[3972/8000] D loss: 0.1435, G loss: 5.2197\n",
      "[4332/8000] D loss: 0.2540, G loss: 5.5002\n",
      "[4692/8000] D loss: 0.1307, G loss: 4.4320\n",
      "[5052/8000] D loss: 0.1396, G loss: 6.3565\n",
      "[5412/8000] D loss: 0.1633, G loss: 4.9639\n",
      "[5772/8000] D loss: 0.2071, G loss: 4.3883\n",
      "[6132/8000] D loss: 0.2048, G loss: 5.8505\n",
      "[6492/8000] D loss: 0.2191, G loss: 7.1717\n",
      "[6852/8000] D loss: 0.1067, G loss: 5.4804\n",
      "[7212/8000] D loss: 0.1570, G loss: 5.7095\n",
      "[7572/8000] D loss: 0.1369, G loss: 5.3812\n",
      "[7932/8000] D loss: 0.2246, G loss: 3.6886\n",
      "train error: \n",
      " D loss: 0.232235, G loss: 6.042279, D accuracy: 95.4%, cell accuracy: 73.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.248295, G loss: 5.975865, D accuracy: 95.2%, cell accuracy: 73.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2259, G loss: 6.3243\n",
      "[372/8000] D loss: 0.3553, G loss: 6.9573\n",
      "[732/8000] D loss: 0.6291, G loss: 3.8254\n",
      "[1092/8000] D loss: 0.1959, G loss: 5.7967\n",
      "[1452/8000] D loss: 0.0255, G loss: 5.3026\n",
      "[1812/8000] D loss: 0.5179, G loss: 3.1084\n",
      "[2172/8000] D loss: 0.1507, G loss: 4.0252\n",
      "[2532/8000] D loss: 0.0428, G loss: 4.9443\n",
      "[2892/8000] D loss: 0.0312, G loss: 5.8331\n",
      "[3252/8000] D loss: 0.1070, G loss: 5.0646\n",
      "[3612/8000] D loss: 0.0749, G loss: 6.8493\n",
      "[3972/8000] D loss: 0.0165, G loss: 6.7642\n",
      "[4332/8000] D loss: 0.3408, G loss: 3.7016\n",
      "[4692/8000] D loss: 0.2037, G loss: 6.2800\n",
      "[5052/8000] D loss: 0.1998, G loss: 4.6611\n",
      "[5412/8000] D loss: 0.0162, G loss: 6.2216\n",
      "[5772/8000] D loss: 0.1894, G loss: 3.7159\n",
      "[6132/8000] D loss: 0.2714, G loss: 4.8660\n",
      "[6492/8000] D loss: 0.2345, G loss: 4.4525\n",
      "[6852/8000] D loss: 0.3859, G loss: 7.3914\n",
      "[7212/8000] D loss: 0.1835, G loss: 5.9239\n",
      "[7572/8000] D loss: 0.0280, G loss: 6.5071\n",
      "[7932/8000] D loss: 0.2744, G loss: 7.1118\n",
      "train error: \n",
      " D loss: 0.174571, G loss: 4.363073, D accuracy: 96.5%, cell accuracy: 74.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.175548, G loss: 4.339435, D accuracy: 96.3%, cell accuracy: 74.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2258, G loss: 5.1978\n",
      "[372/8000] D loss: 0.0336, G loss: 5.6791\n",
      "[732/8000] D loss: 0.0745, G loss: 6.4319\n",
      "[1092/8000] D loss: 0.6432, G loss: 5.1768\n",
      "[1452/8000] D loss: 0.1199, G loss: 4.3209\n",
      "[1812/8000] D loss: 0.2365, G loss: 4.2160\n",
      "[2172/8000] D loss: 0.2678, G loss: 4.3297\n",
      "[2532/8000] D loss: 0.1691, G loss: 4.4107\n",
      "[2892/8000] D loss: 0.2214, G loss: 4.1143\n",
      "[3252/8000] D loss: 0.3256, G loss: 4.2557\n",
      "[3612/8000] D loss: 0.0777, G loss: 4.9937\n",
      "[3972/8000] D loss: 0.1308, G loss: 4.7880\n",
      "[4332/8000] D loss: 0.0322, G loss: 4.8634\n",
      "[4692/8000] D loss: 0.1333, G loss: 5.0919\n",
      "[5052/8000] D loss: 0.5184, G loss: 4.9401\n",
      "[5412/8000] D loss: 0.4424, G loss: 4.0436\n",
      "[5772/8000] D loss: 0.0183, G loss: 6.4110\n",
      "[6132/8000] D loss: 0.1215, G loss: 4.9656\n",
      "[6492/8000] D loss: 0.1106, G loss: 5.7827\n",
      "[6852/8000] D loss: 0.0319, G loss: 6.0007\n",
      "[7212/8000] D loss: 0.0320, G loss: 6.3050\n",
      "[7572/8000] D loss: 0.1284, G loss: 6.3202\n",
      "[7932/8000] D loss: 0.3591, G loss: 5.4537\n",
      "train error: \n",
      " D loss: 0.116754, G loss: 5.096248, D accuracy: 98.1%, cell accuracy: 74.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.124029, G loss: 5.108579, D accuracy: 98.0%, cell accuracy: 74.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0683, G loss: 5.2918\n",
      "[372/8000] D loss: 0.1466, G loss: 6.2267\n",
      "[732/8000] D loss: 0.4129, G loss: 6.0005\n",
      "[1092/8000] D loss: 0.0449, G loss: 5.0864\n",
      "[1452/8000] D loss: 0.1820, G loss: 4.7701\n",
      "[1812/8000] D loss: 0.0841, G loss: 4.6747\n",
      "[2172/8000] D loss: 0.0039, G loss: 6.8847\n",
      "[2532/8000] D loss: 0.0094, G loss: 7.6546\n",
      "[2892/8000] D loss: 0.0059, G loss: 6.7153\n",
      "[3252/8000] D loss: 0.1889, G loss: 5.1497\n",
      "[3612/8000] D loss: 0.0141, G loss: 5.1403\n",
      "[3972/8000] D loss: 0.0918, G loss: 3.5947\n",
      "[4332/8000] D loss: 0.4311, G loss: 5.1064\n",
      "[4692/8000] D loss: 0.0156, G loss: 7.5831\n",
      "[5052/8000] D loss: 0.0567, G loss: 6.4500\n",
      "[5412/8000] D loss: 0.0606, G loss: 6.8009\n",
      "[5772/8000] D loss: 0.0988, G loss: 5.2522\n",
      "[6132/8000] D loss: 0.0376, G loss: 5.9706\n",
      "[6492/8000] D loss: 0.0688, G loss: 6.0732\n",
      "[6852/8000] D loss: 0.6966, G loss: 5.4013\n",
      "[7212/8000] D loss: 0.2289, G loss: 5.9845\n",
      "[7572/8000] D loss: 0.1627, G loss: 3.7212\n",
      "[7932/8000] D loss: 0.1377, G loss: 5.5427\n",
      "train error: \n",
      " D loss: 0.123455, G loss: 5.106409, D accuracy: 98.2%, cell accuracy: 75.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.132216, G loss: 5.077852, D accuracy: 97.9%, cell accuracy: 76.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0299, G loss: 6.2935\n",
      "[372/8000] D loss: 0.0890, G loss: 4.8046\n",
      "[732/8000] D loss: 0.0403, G loss: 5.6815\n",
      "[1092/8000] D loss: 0.2702, G loss: 5.6499\n",
      "[1452/8000] D loss: 0.0271, G loss: 6.7621\n",
      "[1812/8000] D loss: 0.0349, G loss: 6.3299\n",
      "[2172/8000] D loss: 0.1544, G loss: 5.0059\n",
      "[2532/8000] D loss: 0.0035, G loss: 6.9819\n",
      "[2892/8000] D loss: 0.0476, G loss: 5.3564\n",
      "[3252/8000] D loss: 0.0155, G loss: 6.1073\n",
      "[3612/8000] D loss: 0.0677, G loss: 5.3686\n",
      "[3972/8000] D loss: 0.1375, G loss: 5.5121\n",
      "[4332/8000] D loss: 0.2259, G loss: 4.2771\n",
      "[4692/8000] D loss: 0.2049, G loss: 3.0438\n",
      "[5052/8000] D loss: 0.3948, G loss: 4.5844\n",
      "[5412/8000] D loss: 0.1221, G loss: 4.6675\n",
      "[5772/8000] D loss: 0.0128, G loss: 5.8686\n",
      "[6132/8000] D loss: 0.1358, G loss: 4.8719\n",
      "[6492/8000] D loss: 0.1568, G loss: 5.1942\n",
      "[6852/8000] D loss: 0.0725, G loss: 5.2588\n",
      "[7212/8000] D loss: 0.1952, G loss: 4.4816\n",
      "[7572/8000] D loss: 0.1295, G loss: 4.1574\n",
      "[7932/8000] D loss: 0.0286, G loss: 5.6692\n",
      "train error: \n",
      " D loss: 0.123369, G loss: 5.512794, D accuracy: 98.2%, cell accuracy: 75.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.138669, G loss: 5.549127, D accuracy: 97.4%, cell accuracy: 76.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0609, G loss: 7.0544\n",
      "[372/8000] D loss: 0.1270, G loss: 5.9505\n",
      "[732/8000] D loss: 0.0598, G loss: 5.3671\n",
      "[1092/8000] D loss: 0.0077, G loss: 6.6505\n",
      "[1452/8000] D loss: 0.0685, G loss: 5.5193\n",
      "[1812/8000] D loss: 0.4748, G loss: 3.6955\n",
      "[2172/8000] D loss: 0.3612, G loss: 5.5938\n",
      "[2532/8000] D loss: 0.0119, G loss: 5.3833\n",
      "[2892/8000] D loss: 0.2381, G loss: 4.4954\n",
      "[3252/8000] D loss: 0.1820, G loss: 6.1831\n",
      "[3612/8000] D loss: 0.0793, G loss: 5.8434\n",
      "[3972/8000] D loss: 0.2420, G loss: 3.9247\n",
      "[4332/8000] D loss: 0.2430, G loss: 5.8295\n",
      "[4692/8000] D loss: 0.1723, G loss: 4.0681\n",
      "[5052/8000] D loss: 0.0264, G loss: 5.9333\n",
      "[5412/8000] D loss: 0.0904, G loss: 5.6442\n",
      "[5772/8000] D loss: 0.0424, G loss: 4.7655\n",
      "[6132/8000] D loss: 0.0976, G loss: 6.1912\n",
      "[6492/8000] D loss: 0.5448, G loss: 6.4592\n",
      "[6852/8000] D loss: 0.0049, G loss: 6.9190\n",
      "[7212/8000] D loss: 0.1156, G loss: 6.2945\n",
      "[7572/8000] D loss: 0.2050, G loss: 7.0135\n",
      "[7932/8000] D loss: 0.1320, G loss: 5.5697\n",
      "train error: \n",
      " D loss: 0.130782, G loss: 4.833138, D accuracy: 97.9%, cell accuracy: 77.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.133035, G loss: 4.856073, D accuracy: 97.8%, cell accuracy: 77.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0148, G loss: 5.7683\n",
      "[372/8000] D loss: 0.2263, G loss: 4.3337\n",
      "[732/8000] D loss: 0.0386, G loss: 5.0875\n",
      "[1092/8000] D loss: 0.1217, G loss: 4.9293\n",
      "[1452/8000] D loss: 0.1010, G loss: 7.2239\n",
      "[1812/8000] D loss: 0.0185, G loss: 7.1687\n",
      "[2172/8000] D loss: 0.1265, G loss: 4.4710\n",
      "[2532/8000] D loss: 0.1313, G loss: 6.3615\n",
      "[2892/8000] D loss: 0.1576, G loss: 6.4339\n",
      "[3252/8000] D loss: 0.0225, G loss: 6.0535\n",
      "[3612/8000] D loss: 0.0472, G loss: 4.1320\n",
      "[3972/8000] D loss: 0.0596, G loss: 5.4088\n",
      "[4332/8000] D loss: 0.7734, G loss: 6.3710\n",
      "[4692/8000] D loss: 0.0298, G loss: 4.5872\n",
      "[5052/8000] D loss: 0.0089, G loss: 6.2248\n",
      "[5412/8000] D loss: 0.2667, G loss: 3.9069\n",
      "[5772/8000] D loss: 0.4573, G loss: 5.6704\n",
      "[6132/8000] D loss: 0.0594, G loss: 5.1587\n",
      "[6492/8000] D loss: 0.4304, G loss: 4.6033\n",
      "[6852/8000] D loss: 0.0373, G loss: 5.5246\n",
      "[7212/8000] D loss: 0.1667, G loss: 4.5207\n",
      "[7572/8000] D loss: 0.0059, G loss: 7.2990\n",
      "[7932/8000] D loss: 0.0996, G loss: 4.4432\n",
      "train error: \n",
      " D loss: 0.120193, G loss: 5.760995, D accuracy: 98.0%, cell accuracy: 77.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.130932, G loss: 5.767718, D accuracy: 98.0%, cell accuracy: 77.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0309, G loss: 7.4039\n",
      "[372/8000] D loss: 0.0582, G loss: 7.0803\n",
      "[732/8000] D loss: 1.0038, G loss: 3.5326\n",
      "[1092/8000] D loss: 0.0568, G loss: 5.5045\n",
      "[1452/8000] D loss: 0.2104, G loss: 5.5365\n",
      "[1812/8000] D loss: 0.0117, G loss: 5.4948\n",
      "[2172/8000] D loss: 0.0094, G loss: 5.7019\n",
      "[2532/8000] D loss: 0.0917, G loss: 5.7339\n",
      "[2892/8000] D loss: 0.0279, G loss: 6.3702\n",
      "[3252/8000] D loss: 0.2629, G loss: 4.3134\n",
      "[3612/8000] D loss: 0.0404, G loss: 6.2960\n",
      "[3972/8000] D loss: 0.0324, G loss: 4.3415\n",
      "[4332/8000] D loss: 0.1417, G loss: 5.4426\n",
      "[4692/8000] D loss: 0.2762, G loss: 4.4102\n",
      "[5052/8000] D loss: 0.3999, G loss: 6.8281\n",
      "[5412/8000] D loss: 0.2854, G loss: 5.9861\n",
      "[5772/8000] D loss: 0.0733, G loss: 4.3270\n",
      "[6132/8000] D loss: 0.0612, G loss: 5.7639\n",
      "[6492/8000] D loss: 0.2464, G loss: 6.2884\n",
      "[6852/8000] D loss: 0.0963, G loss: 5.2880\n",
      "[7212/8000] D loss: 0.2677, G loss: 3.0388\n",
      "[7572/8000] D loss: 0.0429, G loss: 5.5592\n",
      "[7932/8000] D loss: 0.0631, G loss: 7.5961\n",
      "train error: \n",
      " D loss: 0.127128, G loss: 6.043486, D accuracy: 97.9%, cell accuracy: 79.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.153428, G loss: 6.052987, D accuracy: 97.6%, cell accuracy: 79.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0347, G loss: 6.6914\n",
      "[372/8000] D loss: 0.0736, G loss: 6.3435\n",
      "[732/8000] D loss: 0.1355, G loss: 3.8911\n",
      "[1092/8000] D loss: 0.0288, G loss: 6.0185\n",
      "[1452/8000] D loss: 0.1739, G loss: 4.4285\n",
      "[1812/8000] D loss: 0.0241, G loss: 5.4933\n",
      "[2172/8000] D loss: 0.3674, G loss: 7.0895\n",
      "[2532/8000] D loss: 0.0491, G loss: 6.7365\n",
      "[2892/8000] D loss: 0.2259, G loss: 4.2662\n",
      "[3252/8000] D loss: 0.0115, G loss: 5.4443\n",
      "[3612/8000] D loss: 0.2766, G loss: 6.8823\n",
      "[3972/8000] D loss: 0.4362, G loss: 4.8758\n",
      "[4332/8000] D loss: 0.9738, G loss: 5.6144\n",
      "[4692/8000] D loss: 0.0562, G loss: 5.6540\n",
      "[5052/8000] D loss: 0.0856, G loss: 4.2843\n",
      "[5412/8000] D loss: 0.3954, G loss: 4.4367\n",
      "[5772/8000] D loss: 0.0518, G loss: 5.6789\n",
      "[6132/8000] D loss: 0.0315, G loss: 5.7000\n",
      "[6492/8000] D loss: 0.0565, G loss: 6.2766\n",
      "[6852/8000] D loss: 0.0182, G loss: 6.1707\n",
      "[7212/8000] D loss: 0.1167, G loss: 6.1621\n",
      "[7572/8000] D loss: 0.0055, G loss: 8.1360\n",
      "[7932/8000] D loss: 0.0462, G loss: 6.1412\n",
      "train error: \n",
      " D loss: 0.148744, G loss: 6.619097, D accuracy: 97.2%, cell accuracy: 79.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.178702, G loss: 6.632966, D accuracy: 96.5%, cell accuracy: 79.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4594, G loss: 6.7903\n",
      "[372/8000] D loss: 0.3009, G loss: 5.9683\n",
      "[732/8000] D loss: 0.0146, G loss: 6.2077\n",
      "[1092/8000] D loss: 0.3097, G loss: 5.8204\n",
      "[1452/8000] D loss: 0.0577, G loss: 4.8314\n",
      "[1812/8000] D loss: 0.0703, G loss: 6.0139\n",
      "[2172/8000] D loss: 0.1368, G loss: 4.4951\n",
      "[2532/8000] D loss: 0.0139, G loss: 7.1628\n",
      "[2892/8000] D loss: 0.0192, G loss: 7.4289\n",
      "[3252/8000] D loss: 0.0085, G loss: 9.4123\n",
      "[3612/8000] D loss: 0.0619, G loss: 8.3356\n",
      "[3972/8000] D loss: 0.0773, G loss: 7.8583\n",
      "[4332/8000] D loss: 0.0577, G loss: 7.2286\n",
      "[4692/8000] D loss: 0.1379, G loss: 5.8536\n",
      "[5052/8000] D loss: 0.1094, G loss: 4.4948\n",
      "[5412/8000] D loss: 0.0746, G loss: 5.7327\n",
      "[5772/8000] D loss: 0.1885, G loss: 5.2326\n",
      "[6132/8000] D loss: 0.0176, G loss: 6.4279\n",
      "[6492/8000] D loss: 0.0687, G loss: 6.5168\n",
      "[6852/8000] D loss: 0.0112, G loss: 6.9146\n",
      "[7212/8000] D loss: 0.4342, G loss: 4.8128\n",
      "[7572/8000] D loss: 0.5298, G loss: 8.2817\n",
      "[7932/8000] D loss: 0.1724, G loss: 5.6205\n",
      "train error: \n",
      " D loss: 0.107816, G loss: 6.272681, D accuracy: 98.1%, cell accuracy: 80.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.135455, G loss: 6.242505, D accuracy: 97.7%, cell accuracy: 80.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1384, G loss: 5.3274\n",
      "[372/8000] D loss: 0.0476, G loss: 4.8912\n",
      "[732/8000] D loss: 0.0285, G loss: 6.0338\n",
      "[1092/8000] D loss: 0.0283, G loss: 6.2278\n",
      "[1452/8000] D loss: 0.0801, G loss: 4.4475\n",
      "[1812/8000] D loss: 0.1521, G loss: 6.9693\n",
      "[2172/8000] D loss: 0.0059, G loss: 6.8350\n",
      "[2532/8000] D loss: 0.0494, G loss: 5.7526\n",
      "[2892/8000] D loss: 0.0424, G loss: 6.1608\n",
      "[3252/8000] D loss: 0.0454, G loss: 5.9943\n",
      "[3612/8000] D loss: 0.0234, G loss: 7.4951\n",
      "[3972/8000] D loss: 0.1243, G loss: 5.8296\n",
      "[4332/8000] D loss: 0.0258, G loss: 4.7755\n",
      "[4692/8000] D loss: 0.5277, G loss: 5.9307\n",
      "[5052/8000] D loss: 0.0896, G loss: 7.0074\n",
      "[5412/8000] D loss: 0.0251, G loss: 5.6647\n",
      "[5772/8000] D loss: 0.0561, G loss: 5.9787\n",
      "[6132/8000] D loss: 0.2949, G loss: 6.8992\n",
      "[6492/8000] D loss: 0.0952, G loss: 5.2744\n",
      "[6852/8000] D loss: 0.2899, G loss: 5.0145\n",
      "[7212/8000] D loss: 0.0353, G loss: 7.0368\n",
      "[7572/8000] D loss: 0.0175, G loss: 7.7300\n",
      "[7932/8000] D loss: 0.0428, G loss: 7.6444\n",
      "train error: \n",
      " D loss: 0.094140, G loss: 6.401558, D accuracy: 98.4%, cell accuracy: 79.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.119102, G loss: 6.450574, D accuracy: 98.0%, cell accuracy: 79.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0051, G loss: 6.9520\n",
      "[372/8000] D loss: 0.3445, G loss: 6.0344\n",
      "[732/8000] D loss: 0.0116, G loss: 6.2088\n",
      "[1092/8000] D loss: 0.0980, G loss: 6.5817\n",
      "[1452/8000] D loss: 0.2954, G loss: 4.8142\n",
      "[1812/8000] D loss: 0.1993, G loss: 4.4130\n",
      "[2172/8000] D loss: 0.0339, G loss: 6.1569\n",
      "[2532/8000] D loss: 0.0290, G loss: 6.7598\n",
      "[2892/8000] D loss: 0.0228, G loss: 6.7291\n",
      "[3252/8000] D loss: 0.0057, G loss: 7.0548\n",
      "[3612/8000] D loss: 0.1381, G loss: 5.4242\n",
      "[3972/8000] D loss: 0.1078, G loss: 6.4663\n",
      "[4332/8000] D loss: 0.0258, G loss: 6.0538\n",
      "[4692/8000] D loss: 0.0811, G loss: 6.9388\n",
      "[5052/8000] D loss: 0.0119, G loss: 8.6614\n",
      "[5412/8000] D loss: 0.0772, G loss: 5.4905\n",
      "[5772/8000] D loss: 0.3540, G loss: 5.0558\n",
      "[6132/8000] D loss: 0.0038, G loss: 10.6363\n",
      "[6492/8000] D loss: 0.0207, G loss: 7.4004\n",
      "[6852/8000] D loss: 0.0509, G loss: 7.2207\n",
      "[7212/8000] D loss: 0.0697, G loss: 6.3832\n",
      "[7572/8000] D loss: 0.0106, G loss: 7.9384\n",
      "[7932/8000] D loss: 0.0707, G loss: 7.1973\n",
      "train error: \n",
      " D loss: 0.244778, G loss: 8.618053, D accuracy: 94.9%, cell accuracy: 81.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.286763, G loss: 8.600727, D accuracy: 94.3%, cell accuracy: 81.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2026, G loss: 10.4156\n",
      "[372/8000] D loss: 0.0197, G loss: 7.2114\n",
      "[732/8000] D loss: 0.0737, G loss: 6.1703\n",
      "[1092/8000] D loss: 0.0157, G loss: 7.7660\n",
      "[1452/8000] D loss: 0.1610, G loss: 6.9130\n",
      "[1812/8000] D loss: 0.0159, G loss: 8.6361\n",
      "[2172/8000] D loss: 0.0037, G loss: 8.5505\n",
      "[2532/8000] D loss: 0.0871, G loss: 7.8491\n",
      "[2892/8000] D loss: 0.2756, G loss: 5.2513\n",
      "[3252/8000] D loss: 0.2676, G loss: 5.0485\n",
      "[3612/8000] D loss: 0.3138, G loss: 3.5695\n",
      "[3972/8000] D loss: 0.0191, G loss: 7.1804\n",
      "[4332/8000] D loss: 0.0062, G loss: 8.3154\n",
      "[4692/8000] D loss: 0.1757, G loss: 6.5721\n",
      "[5052/8000] D loss: 0.0170, G loss: 6.8820\n",
      "[5412/8000] D loss: 0.3562, G loss: 5.4523\n",
      "[5772/8000] D loss: 0.1412, G loss: 4.8201\n",
      "[6132/8000] D loss: 0.0056, G loss: 7.3120\n",
      "[6492/8000] D loss: 0.0138, G loss: 7.6009\n",
      "[6852/8000] D loss: 0.0238, G loss: 7.4860\n",
      "[7212/8000] D loss: 0.1674, G loss: 6.5653\n",
      "[7572/8000] D loss: 0.0663, G loss: 6.8311\n",
      "[7932/8000] D loss: 0.0105, G loss: 7.2776\n",
      "train error: \n",
      " D loss: 0.072257, G loss: 6.976583, D accuracy: 98.8%, cell accuracy: 80.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.096234, G loss: 6.965249, D accuracy: 98.4%, cell accuracy: 80.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0962, G loss: 5.8674\n",
      "[372/8000] D loss: 0.0737, G loss: 7.4363\n",
      "[732/8000] D loss: 0.0102, G loss: 7.4275\n",
      "[1092/8000] D loss: 0.0086, G loss: 9.2774\n",
      "[1452/8000] D loss: 0.3377, G loss: 6.1125\n",
      "[1812/8000] D loss: 0.2234, G loss: 5.7139\n",
      "[2172/8000] D loss: 0.0084, G loss: 10.4402\n",
      "[2532/8000] D loss: 0.0361, G loss: 6.6452\n",
      "[2892/8000] D loss: 0.0305, G loss: 7.0418\n",
      "[3252/8000] D loss: 0.0627, G loss: 5.7767\n",
      "[3612/8000] D loss: 0.0686, G loss: 6.9691\n",
      "[3972/8000] D loss: 0.0694, G loss: 6.1289\n",
      "[4332/8000] D loss: 0.0907, G loss: 7.4900\n",
      "[4692/8000] D loss: 0.1378, G loss: 5.6427\n",
      "[5052/8000] D loss: 0.0373, G loss: 6.3530\n",
      "[5412/8000] D loss: 0.0064, G loss: 7.7461\n",
      "[5772/8000] D loss: 0.0300, G loss: 4.9551\n",
      "[6132/8000] D loss: 0.0286, G loss: 5.6689\n",
      "[6492/8000] D loss: 0.3023, G loss: 5.2928\n",
      "[6852/8000] D loss: 0.0166, G loss: 8.6316\n",
      "[7212/8000] D loss: 0.1145, G loss: 7.5675\n",
      "[7572/8000] D loss: 0.0049, G loss: 9.3949\n",
      "[7932/8000] D loss: 0.3398, G loss: 7.3982\n",
      "train error: \n",
      " D loss: 0.072459, G loss: 6.750872, D accuracy: 98.9%, cell accuracy: 81.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.094777, G loss: 6.753586, D accuracy: 98.5%, cell accuracy: 81.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1001, G loss: 7.0306\n",
      "[372/8000] D loss: 0.1249, G loss: 5.2019\n",
      "[732/8000] D loss: 0.0901, G loss: 6.9684\n",
      "[1092/8000] D loss: 0.0229, G loss: 5.1743\n",
      "[1452/8000] D loss: 0.0945, G loss: 6.7459\n",
      "[1812/8000] D loss: 0.0493, G loss: 5.7310\n",
      "[2172/8000] D loss: 0.0477, G loss: 6.5697\n",
      "[2532/8000] D loss: 0.2343, G loss: 5.8890\n",
      "[2892/8000] D loss: 0.2883, G loss: 7.7230\n",
      "[3252/8000] D loss: 0.0371, G loss: 8.6669\n",
      "[3612/8000] D loss: 0.0544, G loss: 6.4630\n",
      "[3972/8000] D loss: 0.4050, G loss: 6.5016\n",
      "[4332/8000] D loss: 0.0162, G loss: 7.2099\n",
      "[4692/8000] D loss: 0.0189, G loss: 6.3895\n",
      "[5052/8000] D loss: 0.0180, G loss: 6.9790\n",
      "[5412/8000] D loss: 0.2949, G loss: 4.8212\n",
      "[5772/8000] D loss: 0.0765, G loss: 8.0780\n",
      "[6132/8000] D loss: 0.0667, G loss: 6.0771\n",
      "[6492/8000] D loss: 0.1287, G loss: 7.6423\n",
      "[6852/8000] D loss: 0.0438, G loss: 6.8563\n",
      "[7212/8000] D loss: 0.2356, G loss: 4.7286\n",
      "[7572/8000] D loss: 0.0398, G loss: 8.4653\n",
      "[7932/8000] D loss: 0.1316, G loss: 6.8821\n",
      "train error: \n",
      " D loss: 0.083532, G loss: 6.305807, D accuracy: 98.5%, cell accuracy: 81.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.110173, G loss: 6.336405, D accuracy: 98.0%, cell accuracy: 81.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0207, G loss: 7.1709\n",
      "[372/8000] D loss: 0.0044, G loss: 6.9100\n",
      "[732/8000] D loss: 0.0955, G loss: 6.6002\n",
      "[1092/8000] D loss: 0.0141, G loss: 7.0300\n",
      "[1452/8000] D loss: 0.1115, G loss: 7.0655\n",
      "[1812/8000] D loss: 0.0359, G loss: 7.1830\n",
      "[2172/8000] D loss: 0.0961, G loss: 5.9569\n",
      "[2532/8000] D loss: 0.0664, G loss: 6.8139\n",
      "[2892/8000] D loss: 0.0235, G loss: 9.5414\n",
      "[3252/8000] D loss: 0.0221, G loss: 7.5574\n",
      "[3612/8000] D loss: 0.1109, G loss: 5.9699\n",
      "[3972/8000] D loss: 0.2094, G loss: 9.2552\n",
      "[4332/8000] D loss: 0.1699, G loss: 6.6618\n",
      "[4692/8000] D loss: 0.0452, G loss: 7.5621\n",
      "[5052/8000] D loss: 0.0206, G loss: 7.5785\n",
      "[5412/8000] D loss: 0.1330, G loss: 4.8161\n",
      "[5772/8000] D loss: 0.0324, G loss: 9.1208\n",
      "[6132/8000] D loss: 0.0605, G loss: 4.2678\n",
      "[6492/8000] D loss: 0.0631, G loss: 7.4874\n",
      "[6852/8000] D loss: 0.2481, G loss: 8.5602\n",
      "[7212/8000] D loss: 0.0635, G loss: 6.3958\n",
      "[7572/8000] D loss: 0.1241, G loss: 6.1557\n",
      "[7932/8000] D loss: 0.1480, G loss: 4.3158\n",
      "train error: \n",
      " D loss: 0.129654, G loss: 7.495124, D accuracy: 97.3%, cell accuracy: 81.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.172614, G loss: 7.524449, D accuracy: 96.8%, cell accuracy: 81.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2312, G loss: 6.2016\n",
      "[372/8000] D loss: 0.0165, G loss: 11.3241\n",
      "[732/8000] D loss: 0.0602, G loss: 6.8016\n",
      "[1092/8000] D loss: 0.0155, G loss: 5.5516\n",
      "[1452/8000] D loss: 0.0235, G loss: 7.7760\n",
      "[1812/8000] D loss: 0.0507, G loss: 9.3492\n",
      "[2172/8000] D loss: 0.2697, G loss: 5.4416\n",
      "[2532/8000] D loss: 0.1162, G loss: 6.8513\n",
      "[2892/8000] D loss: 0.0013, G loss: 9.0247\n",
      "[3252/8000] D loss: 0.0182, G loss: 6.5049\n",
      "[3612/8000] D loss: 0.1179, G loss: 9.3762\n",
      "[3972/8000] D loss: 0.1271, G loss: 5.9876\n",
      "[4332/8000] D loss: 0.1167, G loss: 6.9392\n",
      "[4692/8000] D loss: 0.0213, G loss: 7.7822\n",
      "[5052/8000] D loss: 0.0737, G loss: 8.0953\n",
      "[5412/8000] D loss: 0.0790, G loss: 6.1937\n",
      "[5772/8000] D loss: 0.0341, G loss: 6.6064\n",
      "[6132/8000] D loss: 0.2128, G loss: 8.0791\n",
      "[6492/8000] D loss: 0.0687, G loss: 6.9340\n",
      "[6852/8000] D loss: 0.0306, G loss: 5.8718\n",
      "[7212/8000] D loss: 0.0037, G loss: 7.4774\n",
      "[7572/8000] D loss: 0.0724, G loss: 8.1733\n",
      "[7932/8000] D loss: 0.0684, G loss: 5.7999\n",
      "train error: \n",
      " D loss: 0.073561, G loss: 6.866800, D accuracy: 98.7%, cell accuracy: 81.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.100240, G loss: 6.864443, D accuracy: 98.0%, cell accuracy: 81.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1683, G loss: 5.2534\n",
      "[372/8000] D loss: 0.1019, G loss: 6.4582\n",
      "[732/8000] D loss: 0.0139, G loss: 7.4859\n",
      "[1092/8000] D loss: 0.0039, G loss: 7.5647\n",
      "[1452/8000] D loss: 0.0562, G loss: 5.7490\n",
      "[1812/8000] D loss: 0.0122, G loss: 8.3340\n",
      "[2172/8000] D loss: 0.0543, G loss: 7.7192\n",
      "[2532/8000] D loss: 0.4031, G loss: 4.1915\n",
      "[2892/8000] D loss: 0.0079, G loss: 7.8649\n",
      "[3252/8000] D loss: 0.0234, G loss: 9.3889\n",
      "[3612/8000] D loss: 0.1105, G loss: 9.8402\n",
      "[3972/8000] D loss: 0.0062, G loss: 6.7294\n",
      "[4332/8000] D loss: 0.0144, G loss: 7.9843\n",
      "[4692/8000] D loss: 0.0069, G loss: 7.4102\n",
      "[5052/8000] D loss: 0.0054, G loss: 8.6780\n",
      "[5412/8000] D loss: 0.0028, G loss: 7.4184\n",
      "[5772/8000] D loss: 0.0192, G loss: 7.3413\n",
      "[6132/8000] D loss: 0.0927, G loss: 10.2749\n",
      "[6492/8000] D loss: 0.0256, G loss: 6.3883\n",
      "[6852/8000] D loss: 0.2535, G loss: 6.4016\n",
      "[7212/8000] D loss: 0.1600, G loss: 8.1646\n",
      "[7572/8000] D loss: 0.0760, G loss: 8.4456\n",
      "[7932/8000] D loss: 0.0422, G loss: 6.8596\n",
      "train error: \n",
      " D loss: 0.072855, G loss: 6.394717, D accuracy: 98.9%, cell accuracy: 80.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.086254, G loss: 6.417407, D accuracy: 98.7%, cell accuracy: 80.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2189, G loss: 5.3569\n",
      "[372/8000] D loss: 0.0092, G loss: 7.2162\n",
      "[732/8000] D loss: 0.0266, G loss: 8.5041\n",
      "[1092/8000] D loss: 0.0098, G loss: 7.9134\n",
      "[1452/8000] D loss: 0.0549, G loss: 8.2243\n",
      "[1812/8000] D loss: 0.0241, G loss: 7.3825\n",
      "[2172/8000] D loss: 0.0363, G loss: 6.2571\n",
      "[2532/8000] D loss: 0.0094, G loss: 6.0125\n",
      "[2892/8000] D loss: 0.0957, G loss: 7.4036\n",
      "[3252/8000] D loss: 0.0281, G loss: 8.0630\n",
      "[3612/8000] D loss: 0.0471, G loss: 7.3940\n",
      "[3972/8000] D loss: 0.3341, G loss: 7.5532\n",
      "[4332/8000] D loss: 0.0017, G loss: 10.2243\n",
      "[4692/8000] D loss: 0.0405, G loss: 6.8424\n",
      "[5052/8000] D loss: 0.0303, G loss: 8.5172\n",
      "[5412/8000] D loss: 0.0972, G loss: 7.2915\n",
      "[5772/8000] D loss: 0.0154, G loss: 7.8379\n",
      "[6132/8000] D loss: 0.0334, G loss: 9.4151\n",
      "[6492/8000] D loss: 0.0140, G loss: 7.8003\n",
      "[6852/8000] D loss: 0.0170, G loss: 7.1848\n",
      "[7212/8000] D loss: 0.0034, G loss: 7.9914\n",
      "[7572/8000] D loss: 0.0257, G loss: 8.0198\n",
      "[7932/8000] D loss: 0.0009, G loss: 9.4785\n",
      "train error: \n",
      " D loss: 0.077794, G loss: 7.551743, D accuracy: 98.6%, cell accuracy: 80.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.105145, G loss: 7.541546, D accuracy: 98.1%, cell accuracy: 80.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0304, G loss: 7.7107\n",
      "[372/8000] D loss: 0.0359, G loss: 7.0468\n",
      "[732/8000] D loss: 0.0363, G loss: 7.5169\n",
      "[1092/8000] D loss: 0.0174, G loss: 8.1392\n",
      "[1452/8000] D loss: 0.0032, G loss: 7.6407\n",
      "[1812/8000] D loss: 0.0023, G loss: 10.9257\n",
      "[2172/8000] D loss: 0.0263, G loss: 7.7756\n",
      "[2532/8000] D loss: 0.0220, G loss: 5.1198\n",
      "[2892/8000] D loss: 0.0073, G loss: 7.2596\n",
      "[3252/8000] D loss: 0.0353, G loss: 8.2817\n",
      "[3612/8000] D loss: 0.0117, G loss: 8.0692\n",
      "[3972/8000] D loss: 0.2111, G loss: 7.5931\n",
      "[4332/8000] D loss: 0.0136, G loss: 7.9548\n",
      "[4692/8000] D loss: 0.2081, G loss: 5.6782\n",
      "[5052/8000] D loss: 0.0402, G loss: 5.6194\n",
      "[5412/8000] D loss: 0.1563, G loss: 8.8855\n",
      "[5772/8000] D loss: 0.0250, G loss: 7.9881\n",
      "[6132/8000] D loss: 0.1466, G loss: 6.3594\n",
      "[6492/8000] D loss: 0.2469, G loss: 7.0147\n",
      "[6852/8000] D loss: 0.0847, G loss: 5.9788\n",
      "[7212/8000] D loss: 0.0839, G loss: 6.2683\n",
      "[7572/8000] D loss: 0.0183, G loss: 7.3674\n",
      "[7932/8000] D loss: 0.1207, G loss: 7.8673\n",
      "train error: \n",
      " D loss: 0.065973, G loss: 7.584617, D accuracy: 99.1%, cell accuracy: 82.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.091212, G loss: 7.616196, D accuracy: 98.6%, cell accuracy: 82.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0503, G loss: 5.9752\n",
      "[372/8000] D loss: 0.0028, G loss: 8.7538\n",
      "[732/8000] D loss: 0.0143, G loss: 6.3598\n",
      "[1092/8000] D loss: 0.2890, G loss: 9.1343\n",
      "[1452/8000] D loss: 0.6687, G loss: 9.1855\n",
      "[1812/8000] D loss: 0.0463, G loss: 6.1036\n",
      "[2172/8000] D loss: 0.1013, G loss: 7.0136\n",
      "[2532/8000] D loss: 0.0058, G loss: 8.8570\n",
      "[2892/8000] D loss: 0.0042, G loss: 7.7873\n",
      "[3252/8000] D loss: 0.0229, G loss: 6.7982\n",
      "[3612/8000] D loss: 0.0189, G loss: 10.3706\n",
      "[3972/8000] D loss: 0.0260, G loss: 6.5703\n",
      "[4332/8000] D loss: 0.0439, G loss: 7.9251\n",
      "[4692/8000] D loss: 0.0837, G loss: 5.9095\n",
      "[5052/8000] D loss: 0.0524, G loss: 7.9357\n",
      "[5412/8000] D loss: 0.1135, G loss: 7.7639\n",
      "[5772/8000] D loss: 0.0011, G loss: 10.5507\n",
      "[6132/8000] D loss: 0.0182, G loss: 7.2939\n",
      "[6492/8000] D loss: 0.0062, G loss: 8.1007\n",
      "[6852/8000] D loss: 0.0052, G loss: 9.2667\n",
      "[7212/8000] D loss: 0.0130, G loss: 8.4795\n",
      "[7572/8000] D loss: 0.0722, G loss: 7.2255\n",
      "[7932/8000] D loss: 0.0072, G loss: 12.4425\n",
      "train error: \n",
      " D loss: 0.062392, G loss: 9.775798, D accuracy: 99.0%, cell accuracy: 82.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.111201, G loss: 9.828004, D accuracy: 98.3%, cell accuracy: 82.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0609, G loss: 8.2638\n",
      "[372/8000] D loss: 0.3470, G loss: 5.6809\n",
      "[732/8000] D loss: 0.3113, G loss: 7.4280\n",
      "[1092/8000] D loss: 0.0022, G loss: 8.2061\n",
      "[1452/8000] D loss: 0.1170, G loss: 7.1475\n",
      "[1812/8000] D loss: 0.0682, G loss: 7.8057\n",
      "[2172/8000] D loss: 0.0074, G loss: 8.1453\n",
      "[2532/8000] D loss: 0.4823, G loss: 5.9472\n",
      "[2892/8000] D loss: 0.0023, G loss: 8.1967\n",
      "[3252/8000] D loss: 0.0336, G loss: 4.9500\n",
      "[3612/8000] D loss: 0.1558, G loss: 6.5935\n",
      "[3972/8000] D loss: 0.0019, G loss: 9.9461\n",
      "[4332/8000] D loss: 0.0097, G loss: 7.8777\n",
      "[4692/8000] D loss: 0.0014, G loss: 8.4509\n",
      "[5052/8000] D loss: 0.0064, G loss: 9.1631\n",
      "[5412/8000] D loss: 0.0482, G loss: 7.1613\n",
      "[5772/8000] D loss: 0.0035, G loss: 8.5976\n",
      "[6132/8000] D loss: 0.0244, G loss: 8.4362\n",
      "[6492/8000] D loss: 0.0610, G loss: 5.6192\n",
      "[6852/8000] D loss: 0.1184, G loss: 6.6912\n",
      "[7212/8000] D loss: 0.0047, G loss: 11.7117\n",
      "[7572/8000] D loss: 0.0409, G loss: 8.7596\n",
      "[7932/8000] D loss: 0.0116, G loss: 8.9166\n",
      "train error: \n",
      " D loss: 0.103110, G loss: 8.015837, D accuracy: 97.9%, cell accuracy: 83.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.133097, G loss: 8.193587, D accuracy: 97.9%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0077, G loss: 9.4442\n",
      "[372/8000] D loss: 0.2246, G loss: 9.0529\n",
      "[732/8000] D loss: 0.3714, G loss: 7.3325\n",
      "[1092/8000] D loss: 0.0612, G loss: 7.7495\n",
      "[1452/8000] D loss: 0.0954, G loss: 7.1583\n",
      "[1812/8000] D loss: 0.0325, G loss: 7.7175\n",
      "[2172/8000] D loss: 0.0336, G loss: 7.0981\n",
      "[2532/8000] D loss: 0.0023, G loss: 10.5971\n",
      "[2892/8000] D loss: 0.0303, G loss: 8.9270\n",
      "[3252/8000] D loss: 0.0178, G loss: 7.4445\n",
      "[3612/8000] D loss: 0.0709, G loss: 7.0582\n",
      "[3972/8000] D loss: 0.0319, G loss: 6.9980\n",
      "[4332/8000] D loss: 0.0034, G loss: 10.8542\n",
      "[4692/8000] D loss: 0.0133, G loss: 11.7661\n",
      "[5052/8000] D loss: 0.0873, G loss: 8.4011\n",
      "[5412/8000] D loss: 0.6829, G loss: 5.1967\n",
      "[5772/8000] D loss: 0.0503, G loss: 6.0389\n",
      "[6132/8000] D loss: 0.2171, G loss: 9.2878\n",
      "[6492/8000] D loss: 0.0587, G loss: 3.4174\n",
      "[6852/8000] D loss: 0.2512, G loss: 6.6128\n",
      "[7212/8000] D loss: 0.0027, G loss: 10.0281\n",
      "[7572/8000] D loss: 0.0438, G loss: 6.5047\n",
      "[7932/8000] D loss: 0.0207, G loss: 8.6970\n",
      "train error: \n",
      " D loss: 0.084847, G loss: 8.041420, D accuracy: 98.4%, cell accuracy: 83.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.128390, G loss: 8.073869, D accuracy: 97.7%, cell accuracy: 83.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1534, G loss: 8.8655\n",
      "[372/8000] D loss: 0.1226, G loss: 5.7623\n",
      "[732/8000] D loss: 0.0335, G loss: 7.0312\n",
      "[1092/8000] D loss: 0.0126, G loss: 6.9804\n",
      "[1452/8000] D loss: 0.3039, G loss: 7.1674\n",
      "[1812/8000] D loss: 0.0989, G loss: 8.7235\n",
      "[2172/8000] D loss: 0.2881, G loss: 7.3450\n",
      "[2532/8000] D loss: 0.0092, G loss: 9.9177\n",
      "[2892/8000] D loss: 0.0578, G loss: 8.3628\n",
      "[3252/8000] D loss: 0.0111, G loss: 9.3850\n",
      "[3612/8000] D loss: 0.0215, G loss: 8.5859\n",
      "[3972/8000] D loss: 0.1407, G loss: 7.9256\n",
      "[4332/8000] D loss: 0.0070, G loss: 8.5952\n",
      "[4692/8000] D loss: 0.0106, G loss: 7.2284\n",
      "[5052/8000] D loss: 0.0262, G loss: 8.9020\n",
      "[5412/8000] D loss: 0.0981, G loss: 5.6725\n",
      "[5772/8000] D loss: 0.0430, G loss: 5.3914\n",
      "[6132/8000] D loss: 0.0591, G loss: 6.9182\n",
      "[6492/8000] D loss: 0.0071, G loss: 9.4943\n",
      "[6852/8000] D loss: 0.1476, G loss: 8.4682\n",
      "[7212/8000] D loss: 0.0165, G loss: 8.2811\n",
      "[7572/8000] D loss: 0.0305, G loss: 6.1586\n",
      "[7932/8000] D loss: 0.0636, G loss: 7.5622\n",
      "train error: \n",
      " D loss: 0.097257, G loss: 8.940968, D accuracy: 98.2%, cell accuracy: 84.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.150706, G loss: 8.992795, D accuracy: 97.6%, cell accuracy: 84.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4055, G loss: 7.6164\n",
      "[372/8000] D loss: 0.0514, G loss: 4.9081\n",
      "[732/8000] D loss: 0.0696, G loss: 6.1822\n",
      "[1092/8000] D loss: 0.3873, G loss: 4.6301\n",
      "[1452/8000] D loss: 0.0546, G loss: 7.4695\n",
      "[1812/8000] D loss: 0.0293, G loss: 8.7724\n",
      "[2172/8000] D loss: 0.2295, G loss: 10.0658\n",
      "[2532/8000] D loss: 0.1085, G loss: 6.3584\n",
      "[2892/8000] D loss: 0.0284, G loss: 6.2698\n",
      "[3252/8000] D loss: 0.1001, G loss: 6.3441\n",
      "[3612/8000] D loss: 0.0118, G loss: 6.5592\n",
      "[3972/8000] D loss: 0.0254, G loss: 4.8198\n",
      "[4332/8000] D loss: 0.2866, G loss: 6.9609\n",
      "[4692/8000] D loss: 0.1901, G loss: 4.8195\n",
      "[5052/8000] D loss: 0.6543, G loss: 8.2531\n",
      "[5412/8000] D loss: 0.0650, G loss: 5.5207\n",
      "[5772/8000] D loss: 0.0101, G loss: 6.5898\n",
      "[6132/8000] D loss: 0.1401, G loss: 8.0552\n",
      "[6492/8000] D loss: 0.2248, G loss: 6.9908\n",
      "[6852/8000] D loss: 0.0382, G loss: 9.0762\n",
      "[7212/8000] D loss: 0.0831, G loss: 5.0026\n",
      "[7572/8000] D loss: 0.2438, G loss: 4.7930\n",
      "[7932/8000] D loss: 0.0825, G loss: 9.0059\n",
      "train error: \n",
      " D loss: 0.118189, G loss: 6.365731, D accuracy: 97.8%, cell accuracy: 84.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.144664, G loss: 6.436296, D accuracy: 97.5%, cell accuracy: 84.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0897, G loss: 5.7430\n",
      "[372/8000] D loss: 0.1438, G loss: 4.9280\n",
      "[732/8000] D loss: 0.0237, G loss: 6.7068\n",
      "[1092/8000] D loss: 0.0569, G loss: 5.5698\n",
      "[1452/8000] D loss: 0.0039, G loss: 8.2108\n",
      "[1812/8000] D loss: 0.0335, G loss: 8.5118\n",
      "[2172/8000] D loss: 0.1203, G loss: 5.3393\n",
      "[2532/8000] D loss: 0.0588, G loss: 7.1850\n",
      "[2892/8000] D loss: 0.0054, G loss: 9.1833\n",
      "[3252/8000] D loss: 0.0377, G loss: 7.4532\n",
      "[3612/8000] D loss: 0.3102, G loss: 8.0950\n",
      "[3972/8000] D loss: 0.0780, G loss: 6.6884\n",
      "[4332/8000] D loss: 0.0381, G loss: 8.0097\n",
      "[4692/8000] D loss: 0.0438, G loss: 8.9378\n",
      "[5052/8000] D loss: 0.0515, G loss: 5.3265\n",
      "[5412/8000] D loss: 0.1170, G loss: 7.7943\n",
      "[5772/8000] D loss: 0.5346, G loss: 6.4472\n",
      "[6132/8000] D loss: 0.2691, G loss: 7.3424\n",
      "[6492/8000] D loss: 0.1065, G loss: 7.4458\n",
      "[6852/8000] D loss: 0.2256, G loss: 7.7846\n",
      "[7212/8000] D loss: 0.0296, G loss: 7.1108\n",
      "[7572/8000] D loss: 0.2508, G loss: 4.9591\n",
      "[7932/8000] D loss: 0.0365, G loss: 7.2203\n",
      "train error: \n",
      " D loss: 0.101008, G loss: 6.413973, D accuracy: 98.2%, cell accuracy: 85.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.132915, G loss: 6.577579, D accuracy: 97.9%, cell accuracy: 85.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1740, G loss: 6.6687\n",
      "[372/8000] D loss: 0.0458, G loss: 8.5381\n",
      "[732/8000] D loss: 0.0052, G loss: 6.5225\n",
      "[1092/8000] D loss: 0.0340, G loss: 7.0841\n",
      "[1452/8000] D loss: 0.0215, G loss: 6.6385\n",
      "[1812/8000] D loss: 0.0228, G loss: 7.0402\n",
      "[2172/8000] D loss: 0.0459, G loss: 5.9587\n",
      "[2532/8000] D loss: 0.3508, G loss: 8.6840\n",
      "[2892/8000] D loss: 0.2363, G loss: 8.6680\n",
      "[3252/8000] D loss: 0.0076, G loss: 8.0711\n",
      "[3612/8000] D loss: 0.0254, G loss: 6.5913\n",
      "[3972/8000] D loss: 0.1518, G loss: 5.9589\n",
      "[4332/8000] D loss: 0.2264, G loss: 4.1878\n",
      "[4692/8000] D loss: 0.1897, G loss: 9.1008\n",
      "[5052/8000] D loss: 0.0270, G loss: 6.8992\n",
      "[5412/8000] D loss: 0.0381, G loss: 5.9373\n",
      "[5772/8000] D loss: 0.3870, G loss: 4.9048\n",
      "[6132/8000] D loss: 0.4879, G loss: 4.2725\n",
      "[6492/8000] D loss: 0.4168, G loss: 7.1418\n",
      "[6852/8000] D loss: 0.0291, G loss: 7.7898\n",
      "[7212/8000] D loss: 0.1065, G loss: 8.0592\n",
      "[7572/8000] D loss: 0.0077, G loss: 8.0710\n",
      "[7932/8000] D loss: 0.1059, G loss: 3.8101\n",
      "train error: \n",
      " D loss: 0.173888, G loss: 8.001618, D accuracy: 96.3%, cell accuracy: 85.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.233291, G loss: 8.122347, D accuracy: 95.6%, cell accuracy: 85.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5755, G loss: 7.4782\n",
      "[372/8000] D loss: 0.1066, G loss: 6.6550\n",
      "[732/8000] D loss: 0.3324, G loss: 6.9315\n",
      "[1092/8000] D loss: 0.0071, G loss: 7.6835\n",
      "[1452/8000] D loss: 0.0754, G loss: 9.7230\n",
      "[1812/8000] D loss: 0.1271, G loss: 6.9899\n",
      "[2172/8000] D loss: 0.0355, G loss: 8.0197\n",
      "[2532/8000] D loss: 0.0071, G loss: 7.9530\n",
      "[2892/8000] D loss: 0.0298, G loss: 7.5279\n",
      "[3252/8000] D loss: 0.0736, G loss: 5.5656\n",
      "[3612/8000] D loss: 0.2497, G loss: 7.0330\n",
      "[3972/8000] D loss: 0.1393, G loss: 5.2307\n",
      "[4332/8000] D loss: 0.1365, G loss: 8.6986\n",
      "[4692/8000] D loss: 0.1140, G loss: 5.5959\n",
      "[5052/8000] D loss: 0.0472, G loss: 7.4787\n",
      "[5412/8000] D loss: 0.2939, G loss: 6.5276\n",
      "[5772/8000] D loss: 0.4552, G loss: 5.7808\n",
      "[6132/8000] D loss: 0.1455, G loss: 3.6510\n",
      "[6492/8000] D loss: 0.1571, G loss: 6.5921\n",
      "[6852/8000] D loss: 0.2113, G loss: 5.6461\n",
      "[7212/8000] D loss: 0.0163, G loss: 7.3655\n",
      "[7572/8000] D loss: 0.0849, G loss: 5.3146\n",
      "[7932/8000] D loss: 0.7889, G loss: 6.2831\n",
      "train error: \n",
      " D loss: 0.206440, G loss: 4.821420, D accuracy: 95.9%, cell accuracy: 85.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.221370, G loss: 5.002378, D accuracy: 96.1%, cell accuracy: 85.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5279, G loss: 4.6505\n",
      "[372/8000] D loss: 0.0233, G loss: 8.1777\n",
      "[732/8000] D loss: 0.1383, G loss: 6.9582\n",
      "[1092/8000] D loss: 0.8349, G loss: 7.7507\n",
      "[1452/8000] D loss: 0.0816, G loss: 5.5015\n",
      "[1812/8000] D loss: 0.1670, G loss: 6.2914\n",
      "[2172/8000] D loss: 0.0128, G loss: 7.1327\n",
      "[2532/8000] D loss: 0.0738, G loss: 5.7004\n",
      "[2892/8000] D loss: 0.0959, G loss: 7.4726\n",
      "[3252/8000] D loss: 0.0925, G loss: 8.8209\n",
      "[3612/8000] D loss: 0.1901, G loss: 7.0403\n",
      "[3972/8000] D loss: 0.1857, G loss: 6.7637\n",
      "[4332/8000] D loss: 0.0121, G loss: 7.9725\n",
      "[4692/8000] D loss: 0.1289, G loss: 7.1501\n",
      "[5052/8000] D loss: 0.1710, G loss: 5.9589\n",
      "[5412/8000] D loss: 0.0134, G loss: 8.4055\n",
      "[5772/8000] D loss: 0.0343, G loss: 7.9136\n",
      "[6132/8000] D loss: 0.0076, G loss: 7.7336\n",
      "[6492/8000] D loss: 0.0605, G loss: 7.9739\n",
      "[6852/8000] D loss: 0.1533, G loss: 5.1563\n",
      "[7212/8000] D loss: 0.1089, G loss: 5.1231\n",
      "[7572/8000] D loss: 0.2391, G loss: 6.5166\n",
      "[7932/8000] D loss: 0.1120, G loss: 7.5397\n",
      "train error: \n",
      " D loss: 0.150039, G loss: 7.185109, D accuracy: 97.3%, cell accuracy: 86.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.205560, G loss: 7.285359, D accuracy: 96.4%, cell accuracy: 86.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0560, G loss: 7.2593\n",
      "[372/8000] D loss: 0.0218, G loss: 5.8103\n",
      "[732/8000] D loss: 0.2329, G loss: 5.9505\n",
      "[1092/8000] D loss: 0.1150, G loss: 7.3052\n",
      "[1452/8000] D loss: 0.0818, G loss: 8.4341\n",
      "[1812/8000] D loss: 0.0910, G loss: 9.6276\n",
      "[2172/8000] D loss: 0.0150, G loss: 6.4481\n",
      "[2532/8000] D loss: 0.0415, G loss: 6.1481\n",
      "[2892/8000] D loss: 0.4354, G loss: 7.3744\n",
      "[3252/8000] D loss: 0.0752, G loss: 9.4098\n",
      "[3612/8000] D loss: 0.3810, G loss: 7.4885\n",
      "[3972/8000] D loss: 0.0199, G loss: 5.8408\n",
      "[4332/8000] D loss: 0.0980, G loss: 6.5141\n",
      "[4692/8000] D loss: 0.1130, G loss: 5.2328\n",
      "[5052/8000] D loss: 0.3497, G loss: 7.0601\n",
      "[5412/8000] D loss: 0.0202, G loss: 6.7168\n",
      "[5772/8000] D loss: 0.2016, G loss: 5.9887\n",
      "[6132/8000] D loss: 0.1037, G loss: 7.0561\n",
      "[6492/8000] D loss: 0.2426, G loss: 6.7643\n",
      "[6852/8000] D loss: 0.1437, G loss: 6.9375\n",
      "[7212/8000] D loss: 0.0474, G loss: 7.4215\n",
      "[7572/8000] D loss: 0.0033, G loss: 8.8793\n",
      "[7932/8000] D loss: 0.3094, G loss: 4.8149\n",
      "train error: \n",
      " D loss: 0.136169, G loss: 6.885219, D accuracy: 97.5%, cell accuracy: 86.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.189455, G loss: 6.948487, D accuracy: 96.5%, cell accuracy: 86.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0153, G loss: 7.8210\n",
      "[372/8000] D loss: 0.0807, G loss: 5.7369\n",
      "[732/8000] D loss: 0.0129, G loss: 7.4389\n",
      "[1092/8000] D loss: 0.1580, G loss: 4.3789\n",
      "[1452/8000] D loss: 0.5430, G loss: 4.9247\n",
      "[1812/8000] D loss: 0.0046, G loss: 8.2087\n",
      "[2172/8000] D loss: 0.1257, G loss: 6.3322\n",
      "[2532/8000] D loss: 0.3580, G loss: 5.1634\n",
      "[2892/8000] D loss: 0.0608, G loss: 8.3698\n",
      "[3252/8000] D loss: 0.0342, G loss: 9.2881\n",
      "[3612/8000] D loss: 0.0850, G loss: 7.2998\n",
      "[3972/8000] D loss: 0.0849, G loss: 6.4477\n",
      "[4332/8000] D loss: 0.1132, G loss: 8.7774\n",
      "[4692/8000] D loss: 0.6489, G loss: 8.1434\n",
      "[5052/8000] D loss: 0.3317, G loss: 6.4250\n",
      "[5412/8000] D loss: 0.1559, G loss: 5.7803\n",
      "[5772/8000] D loss: 0.3259, G loss: 5.7497\n",
      "[6132/8000] D loss: 0.1725, G loss: 6.0467\n",
      "[6492/8000] D loss: 0.0688, G loss: 7.4783\n",
      "[6852/8000] D loss: 0.3749, G loss: 7.5452\n",
      "[7212/8000] D loss: 0.2627, G loss: 7.5920\n",
      "[7572/8000] D loss: 0.0566, G loss: 8.5375\n",
      "[7932/8000] D loss: 0.0863, G loss: 5.6429\n",
      "train error: \n",
      " D loss: 0.189458, G loss: 5.778090, D accuracy: 96.2%, cell accuracy: 86.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.201214, G loss: 5.893857, D accuracy: 96.0%, cell accuracy: 86.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4348, G loss: 4.1627\n",
      "[372/8000] D loss: 0.0094, G loss: 7.4746\n",
      "[732/8000] D loss: 0.4062, G loss: 7.3003\n",
      "[1092/8000] D loss: 0.0291, G loss: 7.2836\n",
      "[1452/8000] D loss: 0.2672, G loss: 6.9612\n",
      "[1812/8000] D loss: 0.0959, G loss: 5.4820\n",
      "[2172/8000] D loss: 0.1482, G loss: 5.1085\n",
      "[2532/8000] D loss: 0.1375, G loss: 6.3720\n",
      "[2892/8000] D loss: 0.3416, G loss: 6.6725\n",
      "[3252/8000] D loss: 0.2004, G loss: 7.1848\n",
      "[3612/8000] D loss: 0.0794, G loss: 7.2774\n",
      "[3972/8000] D loss: 0.0876, G loss: 8.0467\n",
      "[4332/8000] D loss: 0.0678, G loss: 6.9588\n",
      "[4692/8000] D loss: 0.0753, G loss: 5.4303\n",
      "[5052/8000] D loss: 0.0351, G loss: 5.0929\n",
      "[5412/8000] D loss: 0.4254, G loss: 7.2513\n",
      "[5772/8000] D loss: 0.0324, G loss: 7.0912\n",
      "[6132/8000] D loss: 0.0099, G loss: 10.0320\n",
      "[6492/8000] D loss: 0.3891, G loss: 5.4692\n",
      "[6852/8000] D loss: 0.2887, G loss: 6.7101\n",
      "[7212/8000] D loss: 0.1317, G loss: 8.1815\n",
      "[7572/8000] D loss: 0.1505, G loss: 5.7731\n",
      "[7932/8000] D loss: 0.0871, G loss: 6.9824\n",
      "train error: \n",
      " D loss: 0.124795, G loss: 7.195619, D accuracy: 97.6%, cell accuracy: 86.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.186814, G loss: 7.304983, D accuracy: 96.7%, cell accuracy: 86.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2904, G loss: 6.0211\n",
      "[372/8000] D loss: 0.0132, G loss: 8.4236\n",
      "[732/8000] D loss: 0.0283, G loss: 7.3795\n",
      "[1092/8000] D loss: 0.2093, G loss: 6.6768\n",
      "[1452/8000] D loss: 0.0377, G loss: 5.6805\n",
      "[1812/8000] D loss: 0.2015, G loss: 8.3334\n",
      "[2172/8000] D loss: 0.0150, G loss: 7.6446\n",
      "[2532/8000] D loss: 0.4139, G loss: 5.9350\n",
      "[2892/8000] D loss: 0.2825, G loss: 5.0098\n",
      "[3252/8000] D loss: 0.1241, G loss: 4.0727\n",
      "[3612/8000] D loss: 0.0602, G loss: 5.5282\n",
      "[3972/8000] D loss: 0.1738, G loss: 7.7994\n",
      "[4332/8000] D loss: 0.0909, G loss: 6.6828\n",
      "[4692/8000] D loss: 0.2858, G loss: 5.9845\n",
      "[5052/8000] D loss: 0.2358, G loss: 6.9340\n",
      "[5412/8000] D loss: 0.3553, G loss: 6.4771\n",
      "[5772/8000] D loss: 0.0331, G loss: 5.6467\n",
      "[6132/8000] D loss: 0.0494, G loss: 5.1905\n",
      "[6492/8000] D loss: 0.0241, G loss: 6.3331\n",
      "[6852/8000] D loss: 0.0842, G loss: 6.6194\n",
      "[7212/8000] D loss: 0.0856, G loss: 4.6222\n",
      "[7572/8000] D loss: 0.0945, G loss: 7.8460\n",
      "[7932/8000] D loss: 0.0309, G loss: 7.1431\n",
      "train error: \n",
      " D loss: 0.178352, G loss: 5.161483, D accuracy: 96.3%, cell accuracy: 86.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.220224, G loss: 5.276921, D accuracy: 95.7%, cell accuracy: 86.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0608, G loss: 5.7228\n",
      "[372/8000] D loss: 0.0964, G loss: 7.0558\n",
      "[732/8000] D loss: 0.0904, G loss: 6.3840\n",
      "[1092/8000] D loss: 0.0168, G loss: 8.1523\n",
      "[1452/8000] D loss: 0.3443, G loss: 4.9835\n",
      "[1812/8000] D loss: 0.2047, G loss: 7.4860\n",
      "[2172/8000] D loss: 0.0733, G loss: 5.1772\n",
      "[2532/8000] D loss: 0.0297, G loss: 8.9755\n",
      "[2892/8000] D loss: 0.3316, G loss: 5.4322\n",
      "[3252/8000] D loss: 0.1483, G loss: 5.8679\n",
      "[3612/8000] D loss: 0.1160, G loss: 6.7924\n",
      "[3972/8000] D loss: 0.0708, G loss: 8.1272\n",
      "[4332/8000] D loss: 0.0195, G loss: 6.4262\n",
      "[4692/8000] D loss: 0.0186, G loss: 6.5937\n",
      "[5052/8000] D loss: 0.0097, G loss: 7.3402\n",
      "[5412/8000] D loss: 0.0373, G loss: 7.4966\n",
      "[5772/8000] D loss: 0.2125, G loss: 8.5886\n",
      "[6132/8000] D loss: 0.0308, G loss: 7.4892\n",
      "[6492/8000] D loss: 0.1308, G loss: 7.5799\n",
      "[6852/8000] D loss: 0.3347, G loss: 6.8983\n",
      "[7212/8000] D loss: 0.0440, G loss: 8.5765\n",
      "[7572/8000] D loss: 0.0860, G loss: 5.6176\n",
      "[7932/8000] D loss: 0.4847, G loss: 9.8699\n",
      "train error: \n",
      " D loss: 0.125122, G loss: 6.233229, D accuracy: 97.5%, cell accuracy: 87.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.153875, G loss: 6.412251, D accuracy: 97.2%, cell accuracy: 87.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0854, G loss: 6.1536\n",
      "[372/8000] D loss: 0.0048, G loss: 8.1406\n",
      "[732/8000] D loss: 0.6067, G loss: 6.0449\n",
      "[1092/8000] D loss: 0.7712, G loss: 5.5466\n",
      "[1452/8000] D loss: 0.1555, G loss: 7.5385\n",
      "[1812/8000] D loss: 0.0102, G loss: 7.8115\n",
      "[2172/8000] D loss: 0.0204, G loss: 6.8848\n",
      "[2532/8000] D loss: 0.0923, G loss: 6.8550\n",
      "[2892/8000] D loss: 0.1791, G loss: 7.8007\n",
      "[3252/8000] D loss: 0.0024, G loss: 8.1981\n",
      "[3612/8000] D loss: 0.1568, G loss: 6.3500\n",
      "[3972/8000] D loss: 0.1199, G loss: 8.4508\n",
      "[4332/8000] D loss: 0.0096, G loss: 6.6537\n",
      "[4692/8000] D loss: 0.1565, G loss: 6.8375\n",
      "[5052/8000] D loss: 0.0955, G loss: 6.2324\n",
      "[5412/8000] D loss: 0.1538, G loss: 5.5614\n",
      "[5772/8000] D loss: 0.1121, G loss: 6.2159\n",
      "[6132/8000] D loss: 0.0700, G loss: 7.8454\n",
      "[6492/8000] D loss: 0.0020, G loss: 8.3519\n",
      "[6852/8000] D loss: 0.2681, G loss: 4.8814\n",
      "[7212/8000] D loss: 0.0329, G loss: 6.7936\n",
      "[7572/8000] D loss: 0.1333, G loss: 7.5801\n",
      "[7932/8000] D loss: 0.0940, G loss: 9.1067\n",
      "train error: \n",
      " D loss: 0.135502, G loss: 5.225295, D accuracy: 97.5%, cell accuracy: 87.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.168447, G loss: 5.461926, D accuracy: 97.0%, cell accuracy: 87.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0369, G loss: 4.8154\n",
      "[372/8000] D loss: 0.1863, G loss: 5.2810\n",
      "[732/8000] D loss: 0.0833, G loss: 6.8536\n",
      "[1092/8000] D loss: 0.1356, G loss: 6.9739\n",
      "[1452/8000] D loss: 0.8559, G loss: 6.6354\n",
      "[1812/8000] D loss: 0.0095, G loss: 6.7227\n",
      "[2172/8000] D loss: 0.0879, G loss: 8.4189\n",
      "[2532/8000] D loss: 0.0439, G loss: 6.5215\n",
      "[2892/8000] D loss: 0.1300, G loss: 6.5557\n",
      "[3252/8000] D loss: 0.1483, G loss: 5.5881\n",
      "[3612/8000] D loss: 0.0092, G loss: 8.8658\n",
      "[3972/8000] D loss: 0.2210, G loss: 5.8736\n",
      "[4332/8000] D loss: 0.0204, G loss: 7.6906\n",
      "[4692/8000] D loss: 0.0887, G loss: 4.5436\n",
      "[5052/8000] D loss: 0.3566, G loss: 3.5391\n",
      "[5412/8000] D loss: 0.1237, G loss: 7.2468\n",
      "[5772/8000] D loss: 0.2445, G loss: 4.5359\n",
      "[6132/8000] D loss: 0.5268, G loss: 6.9886\n",
      "[6492/8000] D loss: 0.0255, G loss: 8.7178\n",
      "[6852/8000] D loss: 0.1323, G loss: 5.2912\n",
      "[7212/8000] D loss: 0.1272, G loss: 7.0055\n",
      "[7572/8000] D loss: 0.2979, G loss: 4.9481\n",
      "[7932/8000] D loss: 0.2131, G loss: 4.5507\n",
      "train error: \n",
      " D loss: 0.113168, G loss: 6.775752, D accuracy: 97.9%, cell accuracy: 87.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.159116, G loss: 6.927166, D accuracy: 97.0%, cell accuracy: 87.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1230, G loss: 6.9124\n",
      "[372/8000] D loss: 0.0553, G loss: 6.0772\n",
      "[732/8000] D loss: 0.2242, G loss: 7.2812\n",
      "[1092/8000] D loss: 0.1636, G loss: 5.0731\n",
      "[1452/8000] D loss: 0.2302, G loss: 6.3173\n",
      "[1812/8000] D loss: 0.0068, G loss: 7.9083\n",
      "[2172/8000] D loss: 0.1575, G loss: 7.1329\n",
      "[2532/8000] D loss: 0.0824, G loss: 4.8944\n",
      "[2892/8000] D loss: 0.0107, G loss: 9.2122\n",
      "[3252/8000] D loss: 0.0712, G loss: 6.9682\n",
      "[3612/8000] D loss: 0.3242, G loss: 5.5967\n",
      "[3972/8000] D loss: 0.2371, G loss: 8.0366\n",
      "[4332/8000] D loss: 0.0311, G loss: 8.0403\n",
      "[4692/8000] D loss: 0.0250, G loss: 8.3252\n",
      "[5052/8000] D loss: 0.1240, G loss: 7.5747\n",
      "[5412/8000] D loss: 0.0105, G loss: 8.9024\n",
      "[5772/8000] D loss: 0.3430, G loss: 8.0109\n",
      "[6132/8000] D loss: 0.1823, G loss: 7.7585\n",
      "[6492/8000] D loss: 0.0804, G loss: 5.5598\n",
      "[6852/8000] D loss: 0.0223, G loss: 6.6224\n",
      "[7212/8000] D loss: 0.0527, G loss: 8.6047\n",
      "[7572/8000] D loss: 0.2135, G loss: 9.8845\n",
      "[7932/8000] D loss: 0.1169, G loss: 8.8305\n",
      "train error: \n",
      " D loss: 0.108772, G loss: 6.847750, D accuracy: 98.0%, cell accuracy: 87.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.150391, G loss: 7.057249, D accuracy: 97.3%, cell accuracy: 87.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0365, G loss: 6.6197\n",
      "[372/8000] D loss: 0.0791, G loss: 7.3976\n",
      "[732/8000] D loss: 0.0386, G loss: 7.6325\n",
      "[1092/8000] D loss: 0.0690, G loss: 6.5669\n",
      "[1452/8000] D loss: 0.0699, G loss: 8.8570\n",
      "[1812/8000] D loss: 0.0319, G loss: 6.8850\n",
      "[2172/8000] D loss: 0.2410, G loss: 8.6762\n",
      "[2532/8000] D loss: 0.2490, G loss: 6.1296\n",
      "[2892/8000] D loss: 0.1462, G loss: 6.5183\n",
      "[3252/8000] D loss: 0.3017, G loss: 4.9204\n",
      "[3612/8000] D loss: 0.2927, G loss: 6.4376\n",
      "[3972/8000] D loss: 0.0048, G loss: 9.4789\n",
      "[4332/8000] D loss: 0.1434, G loss: 6.1979\n",
      "[4692/8000] D loss: 0.3667, G loss: 7.1295\n",
      "[5052/8000] D loss: 0.2020, G loss: 7.2834\n",
      "[5412/8000] D loss: 0.0948, G loss: 7.5659\n",
      "[5772/8000] D loss: 0.0517, G loss: 9.5611\n",
      "[6132/8000] D loss: 0.1633, G loss: 6.3211\n",
      "[6492/8000] D loss: 0.1410, G loss: 8.6507\n",
      "[6852/8000] D loss: 0.0433, G loss: 7.0008\n",
      "[7212/8000] D loss: 0.0845, G loss: 5.2077\n",
      "[7572/8000] D loss: 0.0800, G loss: 6.3233\n",
      "[7932/8000] D loss: 0.0651, G loss: 6.1311\n",
      "train error: \n",
      " D loss: 0.170993, G loss: 6.767091, D accuracy: 96.4%, cell accuracy: 87.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.231198, G loss: 6.968340, D accuracy: 95.5%, cell accuracy: 87.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0716, G loss: 6.6713\n",
      "[372/8000] D loss: 0.0246, G loss: 6.2439\n",
      "[732/8000] D loss: 0.1637, G loss: 6.2694\n",
      "[1092/8000] D loss: 0.1771, G loss: 6.7720\n",
      "[1452/8000] D loss: 0.1800, G loss: 4.2853\n",
      "[1812/8000] D loss: 0.0636, G loss: 7.9048\n",
      "[2172/8000] D loss: 0.0733, G loss: 6.3813\n",
      "[2532/8000] D loss: 0.0172, G loss: 7.3326\n",
      "[2892/8000] D loss: 0.0468, G loss: 7.8128\n",
      "[3252/8000] D loss: 0.1157, G loss: 6.6714\n",
      "[3612/8000] D loss: 0.0147, G loss: 7.2568\n",
      "[3972/8000] D loss: 0.0069, G loss: 9.7274\n",
      "[4332/8000] D loss: 0.0170, G loss: 9.5300\n",
      "[4692/8000] D loss: 0.0151, G loss: 6.6096\n",
      "[5052/8000] D loss: 0.0093, G loss: 7.2404\n",
      "[5412/8000] D loss: 0.0796, G loss: 6.6111\n",
      "[5772/8000] D loss: 0.2618, G loss: 8.2101\n",
      "[6132/8000] D loss: 0.0170, G loss: 7.4402\n",
      "[6492/8000] D loss: 0.1502, G loss: 6.0104\n",
      "[6852/8000] D loss: 0.3550, G loss: 8.0398\n",
      "[7212/8000] D loss: 0.0346, G loss: 7.7744\n",
      "[7572/8000] D loss: 0.2967, G loss: 10.4612\n",
      "[7932/8000] D loss: 0.0412, G loss: 6.9726\n",
      "train error: \n",
      " D loss: 0.168179, G loss: 6.100621, D accuracy: 96.4%, cell accuracy: 87.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.178060, G loss: 6.320749, D accuracy: 96.3%, cell accuracy: 87.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2547, G loss: 7.1168\n",
      "[372/8000] D loss: 0.1116, G loss: 6.6645\n",
      "[732/8000] D loss: 0.0225, G loss: 5.5657\n",
      "[1092/8000] D loss: 0.1051, G loss: 5.5624\n",
      "[1452/8000] D loss: 0.0022, G loss: 8.7640\n",
      "[1812/8000] D loss: 0.1198, G loss: 6.4291\n",
      "[2172/8000] D loss: 0.0860, G loss: 6.9731\n",
      "[2532/8000] D loss: 0.1844, G loss: 7.6029\n",
      "[2892/8000] D loss: 0.0679, G loss: 8.2343\n",
      "[3252/8000] D loss: 0.0930, G loss: 8.4049\n",
      "[3612/8000] D loss: 0.0698, G loss: 5.9228\n",
      "[3972/8000] D loss: 0.1714, G loss: 5.9853\n",
      "[4332/8000] D loss: 0.2252, G loss: 7.5285\n",
      "[4692/8000] D loss: 0.0935, G loss: 4.8646\n",
      "[5052/8000] D loss: 0.0300, G loss: 5.4204\n",
      "[5412/8000] D loss: 0.0115, G loss: 9.1895\n",
      "[5772/8000] D loss: 0.0455, G loss: 8.8547\n",
      "[6132/8000] D loss: 0.1324, G loss: 7.5273\n",
      "[6492/8000] D loss: 0.1135, G loss: 8.5047\n",
      "[6852/8000] D loss: 0.3770, G loss: 4.2203\n",
      "[7212/8000] D loss: 0.7888, G loss: 5.8547\n",
      "[7572/8000] D loss: 0.0476, G loss: 7.3049\n",
      "[7932/8000] D loss: 0.1298, G loss: 4.1770\n",
      "train error: \n",
      " D loss: 0.152428, G loss: 5.506182, D accuracy: 97.1%, cell accuracy: 87.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.177664, G loss: 5.677731, D accuracy: 96.9%, cell accuracy: 87.5%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0488, G loss: 7.0589\n",
      "[372/8000] D loss: 0.5417, G loss: 4.4028\n",
      "[732/8000] D loss: 0.0467, G loss: 7.5032\n",
      "[1092/8000] D loss: 0.0524, G loss: 8.5092\n",
      "[1452/8000] D loss: 0.2115, G loss: 3.5090\n",
      "[1812/8000] D loss: 0.0165, G loss: 7.6110\n",
      "[2172/8000] D loss: 0.1387, G loss: 7.5164\n",
      "[2532/8000] D loss: 0.3149, G loss: 6.2440\n",
      "[2892/8000] D loss: 0.0805, G loss: 5.2590\n",
      "[3252/8000] D loss: 0.1120, G loss: 6.5265\n",
      "[3612/8000] D loss: 0.0616, G loss: 4.9492\n",
      "[3972/8000] D loss: 0.0900, G loss: 8.4038\n",
      "[4332/8000] D loss: 0.0534, G loss: 8.7279\n",
      "[4692/8000] D loss: 0.4136, G loss: 9.5993\n",
      "[5052/8000] D loss: 0.3087, G loss: 5.7804\n",
      "[5412/8000] D loss: 0.1442, G loss: 8.0254\n",
      "[5772/8000] D loss: 0.0687, G loss: 9.4409\n",
      "[6132/8000] D loss: 0.0800, G loss: 7.6065\n",
      "[6492/8000] D loss: 0.1214, G loss: 7.6541\n",
      "[6852/8000] D loss: 0.0010, G loss: 9.4617\n",
      "[7212/8000] D loss: 0.0153, G loss: 8.5156\n",
      "[7572/8000] D loss: 0.1315, G loss: 5.6119\n",
      "[7932/8000] D loss: 0.0489, G loss: 6.4819\n",
      "train error: \n",
      " D loss: 0.136383, G loss: 6.224285, D accuracy: 97.4%, cell accuracy: 87.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.158776, G loss: 6.532786, D accuracy: 97.2%, cell accuracy: 87.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0143, G loss: 6.9874\n",
      "[372/8000] D loss: 0.0146, G loss: 6.8083\n",
      "[732/8000] D loss: 0.1053, G loss: 6.5858\n",
      "[1092/8000] D loss: 0.0014, G loss: 8.8533\n",
      "[1452/8000] D loss: 0.1155, G loss: 7.9322\n",
      "[1812/8000] D loss: 0.0206, G loss: 7.6146\n",
      "[2172/8000] D loss: 0.0228, G loss: 5.9230\n",
      "[2532/8000] D loss: 0.0036, G loss: 9.1410\n",
      "[2892/8000] D loss: 0.0296, G loss: 7.8207\n",
      "[3252/8000] D loss: 0.1377, G loss: 6.6080\n",
      "[3612/8000] D loss: 0.4692, G loss: 7.9617\n",
      "[3972/8000] D loss: 0.3591, G loss: 5.3273\n",
      "[4332/8000] D loss: 0.1089, G loss: 6.0660\n",
      "[4692/8000] D loss: 0.0478, G loss: 7.3861\n",
      "[5052/8000] D loss: 0.0053, G loss: 9.2816\n",
      "[5412/8000] D loss: 0.2472, G loss: 8.8176\n",
      "[5772/8000] D loss: 0.0086, G loss: 9.1266\n",
      "[6132/8000] D loss: 0.4152, G loss: 6.7602\n",
      "[6492/8000] D loss: 0.3796, G loss: 4.8852\n",
      "[6852/8000] D loss: 0.0242, G loss: 9.5228\n",
      "[7212/8000] D loss: 0.0465, G loss: 6.9496\n",
      "[7572/8000] D loss: 0.0647, G loss: 7.5615\n",
      "[7932/8000] D loss: 0.1654, G loss: 5.8903\n",
      "train error: \n",
      " D loss: 0.172477, G loss: 6.029897, D accuracy: 96.6%, cell accuracy: 88.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.172786, G loss: 6.239020, D accuracy: 96.8%, cell accuracy: 87.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0681, G loss: 7.4910\n",
      "[372/8000] D loss: 0.0940, G loss: 8.7126\n",
      "[732/8000] D loss: 0.0826, G loss: 6.3612\n",
      "[1092/8000] D loss: 0.2582, G loss: 7.4123\n",
      "[1452/8000] D loss: 0.0043, G loss: 8.1721\n",
      "[1812/8000] D loss: 0.2298, G loss: 5.4129\n",
      "[2172/8000] D loss: 0.1215, G loss: 4.9927\n",
      "[2532/8000] D loss: 0.1450, G loss: 8.3338\n",
      "[2892/8000] D loss: 0.2325, G loss: 6.6057\n",
      "[3252/8000] D loss: 0.0327, G loss: 7.9418\n",
      "[3612/8000] D loss: 0.4155, G loss: 4.9985\n",
      "[3972/8000] D loss: 0.1551, G loss: 5.3345\n",
      "[4332/8000] D loss: 0.0697, G loss: 8.4819\n",
      "[4692/8000] D loss: 0.1053, G loss: 5.6715\n",
      "[5052/8000] D loss: 0.1040, G loss: 4.7569\n",
      "[5412/8000] D loss: 0.0579, G loss: 5.9193\n",
      "[5772/8000] D loss: 0.0876, G loss: 7.3475\n",
      "[6132/8000] D loss: 0.4526, G loss: 7.3403\n",
      "[6492/8000] D loss: 0.5292, G loss: 5.7422\n",
      "[6852/8000] D loss: 0.0318, G loss: 6.9747\n",
      "[7212/8000] D loss: 0.1011, G loss: 8.4529\n",
      "[7572/8000] D loss: 0.5845, G loss: 5.0696\n",
      "[7932/8000] D loss: 0.1450, G loss: 5.4384\n",
      "train error: \n",
      " D loss: 0.151529, G loss: 8.696299, D accuracy: 97.1%, cell accuracy: 88.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.242592, G loss: 8.960149, D accuracy: 95.8%, cell accuracy: 88.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5337, G loss: 7.6072\n",
      "[372/8000] D loss: 0.2593, G loss: 7.6288\n",
      "[732/8000] D loss: 0.1007, G loss: 6.5844\n",
      "[1092/8000] D loss: 0.0956, G loss: 5.9986\n",
      "[1452/8000] D loss: 0.0154, G loss: 7.9501\n",
      "[1812/8000] D loss: 0.0129, G loss: 8.3965\n",
      "[2172/8000] D loss: 0.0487, G loss: 5.4854\n",
      "[2532/8000] D loss: 0.2080, G loss: 5.9267\n",
      "[2892/8000] D loss: 0.0840, G loss: 4.4191\n",
      "[3252/8000] D loss: 0.2979, G loss: 5.0064\n",
      "[3612/8000] D loss: 0.0971, G loss: 4.6716\n",
      "[3972/8000] D loss: 0.2967, G loss: 7.3981\n",
      "[4332/8000] D loss: 0.0746, G loss: 9.1813\n",
      "[4692/8000] D loss: 0.0300, G loss: 5.4902\n",
      "[5052/8000] D loss: 0.1581, G loss: 6.6872\n",
      "[5412/8000] D loss: 0.0337, G loss: 6.1606\n",
      "[5772/8000] D loss: 0.5363, G loss: 7.5401\n",
      "[6132/8000] D loss: 0.0627, G loss: 9.5638\n",
      "[6492/8000] D loss: 0.1823, G loss: 8.5285\n",
      "[6852/8000] D loss: 0.0530, G loss: 8.5877\n",
      "[7212/8000] D loss: 0.0362, G loss: 7.6793\n",
      "[7572/8000] D loss: 0.0047, G loss: 8.8547\n",
      "[7932/8000] D loss: 0.0103, G loss: 6.3883\n",
      "train error: \n",
      " D loss: 0.145204, G loss: 8.183724, D accuracy: 96.9%, cell accuracy: 88.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.218039, G loss: 8.456466, D accuracy: 95.9%, cell accuracy: 88.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0152, G loss: 8.4628\n",
      "[372/8000] D loss: 0.2653, G loss: 8.6320\n",
      "[732/8000] D loss: 0.1024, G loss: 8.1036\n",
      "[1092/8000] D loss: 0.0054, G loss: 8.3790\n",
      "[1452/8000] D loss: 0.0674, G loss: 7.7257\n",
      "[1812/8000] D loss: 0.0472, G loss: 8.3345\n",
      "[2172/8000] D loss: 0.1080, G loss: 7.9036\n",
      "[2532/8000] D loss: 0.0160, G loss: 7.6489\n",
      "[2892/8000] D loss: 0.0977, G loss: 6.9928\n",
      "[3252/8000] D loss: 0.0047, G loss: 8.2710\n",
      "[3612/8000] D loss: 0.0132, G loss: 7.4277\n",
      "[3972/8000] D loss: 0.0038, G loss: 8.0083\n",
      "[4332/8000] D loss: 0.0133, G loss: 7.9737\n",
      "[4692/8000] D loss: 0.2261, G loss: 6.4903\n",
      "[5052/8000] D loss: 0.1427, G loss: 7.5753\n",
      "[5412/8000] D loss: 0.0357, G loss: 7.3975\n",
      "[5772/8000] D loss: 0.1309, G loss: 6.1302\n",
      "[6132/8000] D loss: 0.2523, G loss: 6.4755\n",
      "[6492/8000] D loss: 0.0328, G loss: 8.4022\n",
      "[6852/8000] D loss: 0.4934, G loss: 5.5276\n",
      "[7212/8000] D loss: 0.0505, G loss: 6.7551\n",
      "[7572/8000] D loss: 0.0086, G loss: 7.4949\n",
      "[7932/8000] D loss: 0.3738, G loss: 7.2485\n",
      "train error: \n",
      " D loss: 0.153934, G loss: 8.703806, D accuracy: 96.9%, cell accuracy: 88.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.225813, G loss: 9.014074, D accuracy: 96.2%, cell accuracy: 88.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2156, G loss: 8.4892\n",
      "[372/8000] D loss: 0.0020, G loss: 9.1726\n",
      "[732/8000] D loss: 0.3477, G loss: 6.3210\n",
      "[1092/8000] D loss: 0.0141, G loss: 8.1130\n",
      "[1452/8000] D loss: 0.0167, G loss: 7.5660\n",
      "[1812/8000] D loss: 0.0384, G loss: 9.0737\n",
      "[2172/8000] D loss: 0.3539, G loss: 4.9050\n",
      "[2532/8000] D loss: 0.2157, G loss: 6.4961\n",
      "[2892/8000] D loss: 0.0635, G loss: 8.1123\n",
      "[3252/8000] D loss: 0.2173, G loss: 5.7182\n",
      "[3612/8000] D loss: 0.0403, G loss: 6.8435\n",
      "[3972/8000] D loss: 0.2769, G loss: 9.5515\n",
      "[4332/8000] D loss: 0.0332, G loss: 6.9254\n",
      "[4692/8000] D loss: 0.1282, G loss: 5.8907\n",
      "[5052/8000] D loss: 0.0180, G loss: 8.9810\n",
      "[5412/8000] D loss: 0.1640, G loss: 5.6984\n",
      "[5772/8000] D loss: 0.1215, G loss: 5.9101\n",
      "[6132/8000] D loss: 0.0046, G loss: 10.2063\n",
      "[6492/8000] D loss: 0.3322, G loss: 7.4812\n",
      "[6852/8000] D loss: 0.0811, G loss: 7.7147\n",
      "[7212/8000] D loss: 0.0823, G loss: 9.0966\n",
      "[7572/8000] D loss: 0.0328, G loss: 7.2472\n",
      "[7932/8000] D loss: 0.0346, G loss: 5.4986\n",
      "train error: \n",
      " D loss: 0.115861, G loss: 7.096045, D accuracy: 97.7%, cell accuracy: 88.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.164047, G loss: 7.427983, D accuracy: 97.0%, cell accuracy: 88.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0698, G loss: 6.4711\n",
      "[372/8000] D loss: 0.0796, G loss: 5.9324\n",
      "[732/8000] D loss: 0.1787, G loss: 7.8065\n",
      "[1092/8000] D loss: 0.1576, G loss: 6.6398\n",
      "[1452/8000] D loss: 0.5381, G loss: 6.9976\n",
      "[1812/8000] D loss: 0.0218, G loss: 7.4831\n",
      "[2172/8000] D loss: 0.0037, G loss: 7.3273\n",
      "[2532/8000] D loss: 0.2819, G loss: 5.7372\n",
      "[2892/8000] D loss: 0.1987, G loss: 8.8776\n",
      "[3252/8000] D loss: 0.1419, G loss: 6.9763\n",
      "[3612/8000] D loss: 0.0042, G loss: 8.4793\n",
      "[3972/8000] D loss: 0.0637, G loss: 8.5375\n",
      "[4332/8000] D loss: 0.0105, G loss: 6.3678\n",
      "[4692/8000] D loss: 0.1853, G loss: 6.2063\n",
      "[5052/8000] D loss: 0.1563, G loss: 5.4968\n",
      "[5412/8000] D loss: 0.0693, G loss: 7.8497\n",
      "[5772/8000] D loss: 0.2679, G loss: 8.2358\n",
      "[6132/8000] D loss: 0.3030, G loss: 6.2321\n",
      "[6492/8000] D loss: 0.0736, G loss: 7.0699\n",
      "[6852/8000] D loss: 0.1254, G loss: 6.9805\n",
      "[7212/8000] D loss: 0.3219, G loss: 5.9484\n",
      "[7572/8000] D loss: 0.0707, G loss: 5.6846\n",
      "[7932/8000] D loss: 0.0320, G loss: 9.7228\n",
      "train error: \n",
      " D loss: 0.172243, G loss: 6.557979, D accuracy: 96.7%, cell accuracy: 88.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.212029, G loss: 6.875178, D accuracy: 96.3%, cell accuracy: 88.4%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0665, G loss: 7.0674\n",
      "[372/8000] D loss: 0.4778, G loss: 5.2791\n",
      "[732/8000] D loss: 0.0418, G loss: 5.3753\n",
      "[1092/8000] D loss: 0.2402, G loss: 5.3687\n",
      "[1452/8000] D loss: 0.0203, G loss: 8.3796\n",
      "[1812/8000] D loss: 0.0413, G loss: 6.1447\n",
      "[2172/8000] D loss: 0.0485, G loss: 6.7819\n",
      "[2532/8000] D loss: 0.1157, G loss: 9.7500\n",
      "[2892/8000] D loss: 0.2906, G loss: 7.0953\n",
      "[3252/8000] D loss: 0.1564, G loss: 6.2593\n",
      "[3612/8000] D loss: 0.0552, G loss: 7.0067\n",
      "[3972/8000] D loss: 0.1108, G loss: 8.6624\n",
      "[4332/8000] D loss: 0.1874, G loss: 4.6344\n",
      "[4692/8000] D loss: 0.1018, G loss: 9.1933\n",
      "[5052/8000] D loss: 0.0114, G loss: 8.7963\n",
      "[5412/8000] D loss: 0.0314, G loss: 7.3527\n",
      "[5772/8000] D loss: 0.0487, G loss: 8.8760\n",
      "[6132/8000] D loss: 0.2695, G loss: 9.0399\n",
      "[6492/8000] D loss: 0.0883, G loss: 4.9837\n",
      "[6852/8000] D loss: 0.0669, G loss: 7.8636\n",
      "[7212/8000] D loss: 0.0710, G loss: 6.6143\n",
      "[7572/8000] D loss: 0.1972, G loss: 8.2077\n",
      "[7932/8000] D loss: 0.0769, G loss: 9.8288\n",
      "train error: \n",
      " D loss: 0.116168, G loss: 7.298126, D accuracy: 97.6%, cell accuracy: 88.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.158386, G loss: 7.704169, D accuracy: 97.1%, cell accuracy: 88.5%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0847, G loss: 7.3401\n",
      "[372/8000] D loss: 0.2906, G loss: 7.4091\n",
      "[732/8000] D loss: 0.0269, G loss: 7.3687\n",
      "[1092/8000] D loss: 0.1479, G loss: 10.0468\n",
      "[1452/8000] D loss: 0.2190, G loss: 8.3911\n",
      "[1812/8000] D loss: 0.0738, G loss: 8.6266\n",
      "[2172/8000] D loss: 0.1842, G loss: 6.2348\n",
      "[2532/8000] D loss: 0.0699, G loss: 7.5548\n",
      "[2892/8000] D loss: 0.0613, G loss: 8.0654\n",
      "[3252/8000] D loss: 0.1748, G loss: 6.8707\n",
      "[3612/8000] D loss: 0.0285, G loss: 10.1860\n",
      "[3972/8000] D loss: 0.2302, G loss: 6.9706\n",
      "[4332/8000] D loss: 0.0406, G loss: 6.7865\n",
      "[4692/8000] D loss: 0.1645, G loss: 6.8950\n",
      "[5052/8000] D loss: 0.2307, G loss: 7.4716\n",
      "[5412/8000] D loss: 0.0959, G loss: 7.0259\n",
      "[5772/8000] D loss: 0.0391, G loss: 8.8284\n",
      "[6132/8000] D loss: 0.1590, G loss: 6.7968\n",
      "[6492/8000] D loss: 0.0938, G loss: 9.2198\n",
      "[6852/8000] D loss: 0.3080, G loss: 8.6872\n",
      "[7212/8000] D loss: 0.1181, G loss: 7.6005\n",
      "[7572/8000] D loss: 0.0841, G loss: 8.0000\n",
      "[7932/8000] D loss: 0.1391, G loss: 8.3226\n",
      "train error: \n",
      " D loss: 0.092376, G loss: 7.452531, D accuracy: 98.3%, cell accuracy: 88.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.135692, G loss: 7.835269, D accuracy: 97.5%, cell accuracy: 88.6%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0194, G loss: 8.5308\n",
      "[372/8000] D loss: 0.0615, G loss: 6.9221\n",
      "[732/8000] D loss: 0.0623, G loss: 7.8830\n",
      "[1092/8000] D loss: 0.3617, G loss: 7.5558\n",
      "[1452/8000] D loss: 0.1424, G loss: 7.0140\n",
      "[1812/8000] D loss: 0.0299, G loss: 9.3326\n",
      "[2172/8000] D loss: 0.1797, G loss: 7.2676\n",
      "[2532/8000] D loss: 0.0381, G loss: 8.4909\n",
      "[2892/8000] D loss: 0.0171, G loss: 6.7041\n",
      "[3252/8000] D loss: 0.0751, G loss: 7.3507\n",
      "[3612/8000] D loss: 0.0490, G loss: 7.2486\n",
      "[3972/8000] D loss: 0.0476, G loss: 9.0383\n",
      "[4332/8000] D loss: 0.0737, G loss: 7.2794\n",
      "[4692/8000] D loss: 0.1348, G loss: 7.6754\n",
      "[5052/8000] D loss: 0.1262, G loss: 5.2382\n",
      "[5412/8000] D loss: 0.1502, G loss: 6.3640\n",
      "[5772/8000] D loss: 0.2338, G loss: 7.1331\n",
      "[6132/8000] D loss: 0.1863, G loss: 8.0107\n",
      "[6492/8000] D loss: 0.0989, G loss: 6.4918\n",
      "[6852/8000] D loss: 0.0598, G loss: 8.4214\n",
      "[7212/8000] D loss: 0.4368, G loss: 6.9983\n",
      "[7572/8000] D loss: 0.0602, G loss: 7.2113\n",
      "[7932/8000] D loss: 0.0283, G loss: 8.6048\n",
      "train error: \n",
      " D loss: 0.114674, G loss: 7.925942, D accuracy: 97.8%, cell accuracy: 88.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.166117, G loss: 8.277397, D accuracy: 97.0%, cell accuracy: 88.4%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0604, G loss: 7.8453\n",
      "[372/8000] D loss: 0.1217, G loss: 7.2767\n",
      "[732/8000] D loss: 0.1513, G loss: 7.1114\n",
      "[1092/8000] D loss: 0.1207, G loss: 11.1227\n",
      "[1452/8000] D loss: 0.0709, G loss: 7.3510\n",
      "[1812/8000] D loss: 0.1305, G loss: 6.5401\n",
      "[2172/8000] D loss: 0.0091, G loss: 7.3891\n",
      "[2532/8000] D loss: 0.2378, G loss: 8.8383\n",
      "[2892/8000] D loss: 0.2751, G loss: 5.6902\n",
      "[3252/8000] D loss: 0.1429, G loss: 6.8149\n",
      "[3612/8000] D loss: 0.1424, G loss: 6.5863\n",
      "[3972/8000] D loss: 0.3527, G loss: 6.0130\n",
      "[4332/8000] D loss: 0.0942, G loss: 6.8174\n",
      "[4692/8000] D loss: 0.1659, G loss: 5.2977\n",
      "[5052/8000] D loss: 0.0732, G loss: 8.2603\n",
      "[5412/8000] D loss: 0.0901, G loss: 5.1309\n",
      "[5772/8000] D loss: 0.0599, G loss: 6.3657\n",
      "[6132/8000] D loss: 0.0171, G loss: 8.3767\n",
      "[6492/8000] D loss: 0.0087, G loss: 8.4935\n",
      "[6852/8000] D loss: 0.0094, G loss: 7.2346\n",
      "[7212/8000] D loss: 0.0866, G loss: 5.8330\n",
      "[7572/8000] D loss: 0.0106, G loss: 9.7832\n",
      "[7932/8000] D loss: 0.1141, G loss: 9.2793\n",
      "train error: \n",
      " D loss: 0.107817, G loss: 8.142935, D accuracy: 98.0%, cell accuracy: 88.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.149734, G loss: 8.563480, D accuracy: 97.2%, cell accuracy: 88.5%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0034, G loss: 10.3667\n",
      "[372/8000] D loss: 0.0792, G loss: 6.5994\n",
      "[732/8000] D loss: 0.1733, G loss: 7.4974\n",
      "[1092/8000] D loss: 0.0282, G loss: 7.7440\n",
      "[1452/8000] D loss: 0.0119, G loss: 9.8952\n",
      "[1812/8000] D loss: 0.4424, G loss: 6.6632\n",
      "[2172/8000] D loss: 0.0476, G loss: 6.9267\n",
      "[2532/8000] D loss: 1.0193, G loss: 4.7853\n",
      "[2892/8000] D loss: 0.0029, G loss: 7.3159\n",
      "[3252/8000] D loss: 0.0643, G loss: 6.8595\n",
      "[3612/8000] D loss: 0.5770, G loss: 5.3122\n",
      "[3972/8000] D loss: 0.0898, G loss: 7.0100\n",
      "[4332/8000] D loss: 0.1892, G loss: 6.5539\n",
      "[4692/8000] D loss: 0.1014, G loss: 7.2617\n",
      "[5052/8000] D loss: 0.0055, G loss: 8.6438\n",
      "[5412/8000] D loss: 0.0875, G loss: 8.3319\n",
      "[5772/8000] D loss: 0.3994, G loss: 7.5060\n",
      "[6132/8000] D loss: 0.0052, G loss: 7.5621\n",
      "[6492/8000] D loss: 0.1617, G loss: 8.2752\n",
      "[6852/8000] D loss: 0.1246, G loss: 7.9241\n",
      "[7212/8000] D loss: 0.1854, G loss: 6.9394\n",
      "[7572/8000] D loss: 0.2266, G loss: 8.9434\n",
      "[7932/8000] D loss: 0.1973, G loss: 7.1316\n",
      "train error: \n",
      " D loss: 0.114637, G loss: 6.622893, D accuracy: 97.8%, cell accuracy: 88.9%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.135888, G loss: 6.988709, D accuracy: 97.4%, cell accuracy: 88.8%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0791, G loss: 7.5196\n",
      "[372/8000] D loss: 0.0241, G loss: 6.3024\n",
      "[732/8000] D loss: 0.0005, G loss: 9.9799\n",
      "[1092/8000] D loss: 0.1184, G loss: 7.1731\n",
      "[1452/8000] D loss: 0.0044, G loss: 10.1417\n",
      "[1812/8000] D loss: 0.0052, G loss: 9.8379\n",
      "[2172/8000] D loss: 0.0130, G loss: 9.4533\n",
      "[2532/8000] D loss: 0.1778, G loss: 7.3572\n",
      "[2892/8000] D loss: 0.0174, G loss: 8.0232\n",
      "[3252/8000] D loss: 0.0323, G loss: 6.1092\n",
      "[3612/8000] D loss: 0.0719, G loss: 5.0542\n",
      "[3972/8000] D loss: 0.0172, G loss: 8.3666\n",
      "[4332/8000] D loss: 0.0389, G loss: 8.1964\n",
      "[4692/8000] D loss: 0.0358, G loss: 6.9010\n",
      "[5052/8000] D loss: 0.2545, G loss: 5.9792\n",
      "[5412/8000] D loss: 0.0856, G loss: 10.8013\n",
      "[5772/8000] D loss: 0.0355, G loss: 10.6869\n",
      "[6132/8000] D loss: 0.4924, G loss: 7.0003\n",
      "[6492/8000] D loss: 0.4846, G loss: 8.5983\n",
      "[6852/8000] D loss: 0.0158, G loss: 8.2971\n",
      "[7212/8000] D loss: 0.0917, G loss: 4.5294\n",
      "[7572/8000] D loss: 0.0900, G loss: 8.1873\n",
      "[7932/8000] D loss: 0.0629, G loss: 6.4714\n",
      "train error: \n",
      " D loss: 0.137093, G loss: 7.934958, D accuracy: 97.3%, cell accuracy: 88.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.197992, G loss: 8.335088, D accuracy: 96.2%, cell accuracy: 88.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1212, G loss: 7.1654\n",
      "[372/8000] D loss: 0.0227, G loss: 8.9286\n",
      "[732/8000] D loss: 0.2054, G loss: 7.0838\n",
      "[1092/8000] D loss: 0.0080, G loss: 7.9239\n",
      "[1452/8000] D loss: 0.3481, G loss: 7.6484\n",
      "[1812/8000] D loss: 0.2367, G loss: 7.6441\n",
      "[2172/8000] D loss: 0.0181, G loss: 7.7626\n",
      "[2532/8000] D loss: 0.0627, G loss: 8.1697\n",
      "[2892/8000] D loss: 0.1663, G loss: 8.4894\n",
      "[3252/8000] D loss: 0.2561, G loss: 8.2458\n",
      "[3612/8000] D loss: 0.5717, G loss: 4.7779\n",
      "[3972/8000] D loss: 0.1642, G loss: 4.7406\n",
      "[4332/8000] D loss: 0.2241, G loss: 6.7033\n",
      "[4692/8000] D loss: 0.2279, G loss: 6.0854\n",
      "[5052/8000] D loss: 0.3622, G loss: 7.6241\n",
      "[5412/8000] D loss: 0.0875, G loss: 7.7472\n",
      "[5772/8000] D loss: 0.2760, G loss: 5.3076\n",
      "[6132/8000] D loss: 0.1091, G loss: 9.9064\n",
      "[6492/8000] D loss: 0.1962, G loss: 6.7422\n",
      "[6852/8000] D loss: 0.0173, G loss: 8.2020\n",
      "[7212/8000] D loss: 0.0422, G loss: 7.7700\n",
      "[7572/8000] D loss: 0.3962, G loss: 5.9633\n",
      "[7932/8000] D loss: 0.0683, G loss: 6.8491\n",
      "train error: \n",
      " D loss: 0.379213, G loss: 4.941661, D accuracy: 92.4%, cell accuracy: 89.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.317259, G loss: 5.351054, D accuracy: 93.8%, cell accuracy: 89.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1350, G loss: 4.0093\n",
      "[372/8000] D loss: 0.1680, G loss: 5.7810\n",
      "[732/8000] D loss: 0.0901, G loss: 7.8693\n",
      "[1092/8000] D loss: 0.1698, G loss: 5.6612\n",
      "[1452/8000] D loss: 0.1674, G loss: 8.9676\n",
      "[1812/8000] D loss: 0.0566, G loss: 5.8792\n",
      "[2172/8000] D loss: 0.0881, G loss: 5.8606\n",
      "[2532/8000] D loss: 0.0970, G loss: 5.5511\n",
      "[2892/8000] D loss: 0.0859, G loss: 6.2225\n",
      "[3252/8000] D loss: 0.0471, G loss: 5.0787\n",
      "[3612/8000] D loss: 0.0635, G loss: 6.6509\n",
      "[3972/8000] D loss: 0.1972, G loss: 6.5116\n",
      "[4332/8000] D loss: 0.1966, G loss: 7.2562\n",
      "[4692/8000] D loss: 0.0649, G loss: 8.8402\n",
      "[5052/8000] D loss: 0.3936, G loss: 6.2886\n",
      "[5412/8000] D loss: 0.0147, G loss: 8.5257\n",
      "[5772/8000] D loss: 0.0087, G loss: 8.8312\n",
      "[6132/8000] D loss: 0.2247, G loss: 6.9708\n",
      "[6492/8000] D loss: 0.1290, G loss: 7.6347\n",
      "[6852/8000] D loss: 0.1551, G loss: 6.0396\n",
      "[7212/8000] D loss: 0.0210, G loss: 6.7852\n",
      "[7572/8000] D loss: 0.1566, G loss: 10.2447\n",
      "[7932/8000] D loss: 0.1259, G loss: 7.0304\n",
      "train error: \n",
      " D loss: 0.140352, G loss: 7.932150, D accuracy: 97.2%, cell accuracy: 89.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.195774, G loss: 8.362625, D accuracy: 96.3%, cell accuracy: 88.9%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0530, G loss: 9.0962\n",
      "[372/8000] D loss: 0.2288, G loss: 7.3603\n",
      "[732/8000] D loss: 0.0971, G loss: 7.7618\n",
      "[1092/8000] D loss: 0.0916, G loss: 5.8868\n",
      "[1452/8000] D loss: 0.0621, G loss: 8.3330\n",
      "[1812/8000] D loss: 0.1283, G loss: 5.5526\n",
      "[2172/8000] D loss: 0.3117, G loss: 7.0876\n",
      "[2532/8000] D loss: 0.0231, G loss: 5.3603\n",
      "[2892/8000] D loss: 0.0187, G loss: 7.8772\n",
      "[3252/8000] D loss: 0.0222, G loss: 8.4163\n",
      "[3612/8000] D loss: 0.2859, G loss: 7.2025\n",
      "[3972/8000] D loss: 0.2039, G loss: 5.3039\n",
      "[4332/8000] D loss: 0.0549, G loss: 6.0259\n",
      "[4692/8000] D loss: 0.0909, G loss: 6.4786\n",
      "[5052/8000] D loss: 0.3704, G loss: 5.1818\n",
      "[5412/8000] D loss: 0.0145, G loss: 8.6460\n",
      "[5772/8000] D loss: 0.3497, G loss: 9.9692\n",
      "[6132/8000] D loss: 0.1968, G loss: 6.6237\n",
      "[6492/8000] D loss: 0.1416, G loss: 7.3974\n",
      "[6852/8000] D loss: 0.0322, G loss: 7.0622\n",
      "[7212/8000] D loss: 0.0534, G loss: 5.7064\n",
      "[7572/8000] D loss: 0.1544, G loss: 7.4628\n",
      "[7932/8000] D loss: 0.1519, G loss: 6.8151\n",
      "train error: \n",
      " D loss: 0.132155, G loss: 8.037192, D accuracy: 97.4%, cell accuracy: 89.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.204145, G loss: 8.458028, D accuracy: 96.2%, cell accuracy: 88.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3622, G loss: 8.7789\n",
      "[372/8000] D loss: 0.1148, G loss: 6.5592\n",
      "[732/8000] D loss: 0.0927, G loss: 5.6860\n",
      "[1092/8000] D loss: 0.0200, G loss: 8.8138\n",
      "[1452/8000] D loss: 0.0157, G loss: 8.8747\n",
      "[1812/8000] D loss: 0.1431, G loss: 5.9900\n",
      "[2172/8000] D loss: 0.2083, G loss: 7.5094\n",
      "[2532/8000] D loss: 0.0107, G loss: 11.1939\n",
      "[2892/8000] D loss: 0.0136, G loss: 9.6428\n",
      "[3252/8000] D loss: 0.2039, G loss: 4.7085\n",
      "[3612/8000] D loss: 0.0290, G loss: 6.5877\n",
      "[3972/8000] D loss: 0.0074, G loss: 8.7424\n",
      "[4332/8000] D loss: 0.4191, G loss: 7.9002\n",
      "[4692/8000] D loss: 0.0839, G loss: 8.7333\n",
      "[5052/8000] D loss: 0.4538, G loss: 5.8164\n",
      "[5412/8000] D loss: 0.1002, G loss: 7.6792\n",
      "[5772/8000] D loss: 0.0526, G loss: 6.5203\n",
      "[6132/8000] D loss: 0.4554, G loss: 6.9814\n",
      "[6492/8000] D loss: 0.3477, G loss: 5.5451\n",
      "[6852/8000] D loss: 0.4204, G loss: 6.1203\n",
      "[7212/8000] D loss: 0.0856, G loss: 6.7079\n",
      "[7572/8000] D loss: 0.1034, G loss: 9.1258\n",
      "[7932/8000] D loss: 0.2492, G loss: 6.2639\n",
      "train error: \n",
      " D loss: 0.130881, G loss: 7.194886, D accuracy: 97.5%, cell accuracy: 89.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.176854, G loss: 7.681034, D accuracy: 96.6%, cell accuracy: 89.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1018, G loss: 6.1065\n",
      "[372/8000] D loss: 0.1482, G loss: 7.8418\n",
      "[732/8000] D loss: 0.2979, G loss: 5.2644\n",
      "[1092/8000] D loss: 0.0583, G loss: 7.0174\n",
      "[1452/8000] D loss: 0.0727, G loss: 8.1641\n",
      "[1812/8000] D loss: 0.0846, G loss: 7.7808\n",
      "[2172/8000] D loss: 0.0122, G loss: 6.4901\n",
      "[2532/8000] D loss: 0.4223, G loss: 7.3511\n",
      "[2892/8000] D loss: 0.0082, G loss: 9.4750\n",
      "[3252/8000] D loss: 0.6411, G loss: 6.7714\n",
      "[3612/8000] D loss: 0.1554, G loss: 5.6799\n",
      "[3972/8000] D loss: 0.3317, G loss: 8.3106\n",
      "[4332/8000] D loss: 0.0829, G loss: 7.1700\n",
      "[4692/8000] D loss: 0.0614, G loss: 7.9329\n",
      "[5052/8000] D loss: 0.0448, G loss: 7.6617\n",
      "[5412/8000] D loss: 0.1282, G loss: 6.0905\n",
      "[5772/8000] D loss: 0.0288, G loss: 7.6202\n",
      "[6132/8000] D loss: 0.0451, G loss: 8.3674\n",
      "[6492/8000] D loss: 0.0990, G loss: 6.9129\n",
      "[6852/8000] D loss: 0.0929, G loss: 6.4319\n",
      "[7212/8000] D loss: 0.1555, G loss: 5.7245\n",
      "[7572/8000] D loss: 0.1471, G loss: 6.8668\n",
      "[7932/8000] D loss: 0.0453, G loss: 6.2474\n",
      "train error: \n",
      " D loss: 0.154297, G loss: 6.402336, D accuracy: 96.7%, cell accuracy: 89.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.206055, G loss: 6.898748, D accuracy: 96.2%, cell accuracy: 89.2%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1848, G loss: 5.9081\n",
      "[372/8000] D loss: 0.0352, G loss: 8.0708\n",
      "[732/8000] D loss: 0.1060, G loss: 5.4648\n",
      "[1092/8000] D loss: 0.0413, G loss: 8.9289\n",
      "[1452/8000] D loss: 0.0739, G loss: 9.2136\n",
      "[1812/8000] D loss: 0.0562, G loss: 6.2352\n",
      "[2172/8000] D loss: 0.1068, G loss: 8.4277\n",
      "[2532/8000] D loss: 0.1022, G loss: 5.8259\n",
      "[2892/8000] D loss: 0.6078, G loss: 3.7091\n",
      "[3252/8000] D loss: 0.0625, G loss: 6.4006\n",
      "[3612/8000] D loss: 0.0051, G loss: 8.0799\n",
      "[3972/8000] D loss: 0.3321, G loss: 6.8617\n",
      "[4332/8000] D loss: 0.0024, G loss: 9.2718\n",
      "[4692/8000] D loss: 0.0105, G loss: 8.5075\n",
      "[5052/8000] D loss: 0.0751, G loss: 9.5214\n",
      "[5412/8000] D loss: 0.1129, G loss: 8.6666\n",
      "[5772/8000] D loss: 0.1640, G loss: 5.7778\n",
      "[6132/8000] D loss: 0.2224, G loss: 8.5731\n",
      "[6492/8000] D loss: 0.1182, G loss: 7.4055\n",
      "[6852/8000] D loss: 0.1383, G loss: 9.3768\n",
      "[7212/8000] D loss: 0.0153, G loss: 7.1190\n",
      "[7572/8000] D loss: 0.2827, G loss: 7.0228\n",
      "[7932/8000] D loss: 0.0357, G loss: 8.3204\n",
      "train error: \n",
      " D loss: 0.159914, G loss: 6.157258, D accuracy: 96.9%, cell accuracy: 89.5%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.173285, G loss: 6.701871, D accuracy: 96.6%, cell accuracy: 89.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0743, G loss: 6.5330\n",
      "[372/8000] D loss: 0.1574, G loss: 6.4077\n",
      "[732/8000] D loss: 0.1148, G loss: 5.1498\n",
      "[1092/8000] D loss: 0.1708, G loss: 7.0317\n",
      "[1452/8000] D loss: 0.7238, G loss: 7.3466\n",
      "[1812/8000] D loss: 0.1531, G loss: 6.9001\n",
      "[2172/8000] D loss: 0.0082, G loss: 7.6510\n",
      "[2532/8000] D loss: 0.0186, G loss: 8.5280\n",
      "[2892/8000] D loss: 0.0678, G loss: 8.5962\n",
      "[3252/8000] D loss: 0.2894, G loss: 8.6403\n",
      "[3612/8000] D loss: 0.1540, G loss: 8.3317\n",
      "[3972/8000] D loss: 0.4696, G loss: 5.9307\n",
      "[4332/8000] D loss: 0.0506, G loss: 7.0070\n",
      "[4692/8000] D loss: 0.0322, G loss: 6.4165\n",
      "[5052/8000] D loss: 0.1133, G loss: 7.1737\n",
      "[5412/8000] D loss: 0.2281, G loss: 6.4982\n",
      "[5772/8000] D loss: 0.0211, G loss: 7.8676\n",
      "[6132/8000] D loss: 0.2681, G loss: 6.4379\n",
      "[6492/8000] D loss: 0.0808, G loss: 6.2365\n",
      "[6852/8000] D loss: 0.0347, G loss: 8.5520\n",
      "[7212/8000] D loss: 0.0548, G loss: 6.4053\n",
      "[7572/8000] D loss: 0.0692, G loss: 8.6387\n",
      "[7932/8000] D loss: 0.0392, G loss: 7.7512\n",
      "train error: \n",
      " D loss: 0.154628, G loss: 8.358814, D accuracy: 96.8%, cell accuracy: 89.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.231653, G loss: 8.823424, D accuracy: 95.9%, cell accuracy: 89.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0060, G loss: 9.5740\n",
      "[372/8000] D loss: 0.1583, G loss: 8.5826\n",
      "[732/8000] D loss: 0.0550, G loss: 10.8524\n",
      "[1092/8000] D loss: 0.0438, G loss: 8.1738\n",
      "[1452/8000] D loss: 0.0724, G loss: 6.8449\n",
      "[1812/8000] D loss: 0.5661, G loss: 6.5725\n",
      "[2172/8000] D loss: 0.0111, G loss: 8.7645\n",
      "[2532/8000] D loss: 0.1001, G loss: 6.5076\n",
      "[2892/8000] D loss: 0.5064, G loss: 7.7612\n",
      "[3252/8000] D loss: 0.0058, G loss: 8.1314\n",
      "[3612/8000] D loss: 0.2088, G loss: 7.1005\n",
      "[3972/8000] D loss: 0.1176, G loss: 8.3102\n",
      "[4332/8000] D loss: 0.3125, G loss: 3.8279\n",
      "[4692/8000] D loss: 0.4159, G loss: 5.0805\n",
      "[5052/8000] D loss: 0.1662, G loss: 5.8919\n",
      "[5412/8000] D loss: 0.1576, G loss: 7.5313\n",
      "[5772/8000] D loss: 0.1282, G loss: 7.3467\n",
      "[6132/8000] D loss: 0.4468, G loss: 7.7950\n",
      "[6492/8000] D loss: 0.1406, G loss: 8.7254\n",
      "[6852/8000] D loss: 0.0168, G loss: 6.4674\n",
      "[7212/8000] D loss: 0.1894, G loss: 7.7937\n",
      "[7572/8000] D loss: 0.0937, G loss: 5.7938\n",
      "[7932/8000] D loss: 0.0531, G loss: 6.7949\n",
      "train error: \n",
      " D loss: 0.150373, G loss: 6.634329, D accuracy: 97.0%, cell accuracy: 89.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.193519, G loss: 7.106573, D accuracy: 96.4%, cell accuracy: 89.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1354, G loss: 7.3111\n",
      "[372/8000] D loss: 0.1569, G loss: 5.4962\n",
      "[732/8000] D loss: 0.1257, G loss: 6.9960\n",
      "[1092/8000] D loss: 0.0031, G loss: 11.1069\n",
      "[1452/8000] D loss: 0.0676, G loss: 9.6111\n",
      "[1812/8000] D loss: 0.1055, G loss: 8.0222\n",
      "[2172/8000] D loss: 0.4794, G loss: 5.8162\n",
      "[2532/8000] D loss: 0.1141, G loss: 6.8348\n",
      "[2892/8000] D loss: 0.0105, G loss: 7.3032\n",
      "[3252/8000] D loss: 0.2550, G loss: 4.7479\n",
      "[3612/8000] D loss: 0.3184, G loss: 6.3152\n",
      "[3972/8000] D loss: 0.3488, G loss: 7.1865\n",
      "[4332/8000] D loss: 0.0500, G loss: 6.8582\n",
      "[4692/8000] D loss: 0.1485, G loss: 8.4528\n",
      "[5052/8000] D loss: 0.0265, G loss: 7.9432\n",
      "[5412/8000] D loss: 0.2207, G loss: 4.2876\n",
      "[5772/8000] D loss: 0.2428, G loss: 5.2019\n",
      "[6132/8000] D loss: 0.2547, G loss: 5.2493\n",
      "[6492/8000] D loss: 0.0276, G loss: 7.1020\n",
      "[6852/8000] D loss: 0.1544, G loss: 7.1714\n",
      "[7212/8000] D loss: 0.1789, G loss: 6.5582\n",
      "[7572/8000] D loss: 0.0900, G loss: 5.3790\n",
      "[7932/8000] D loss: 0.0664, G loss: 6.2222\n",
      "train error: \n",
      " D loss: 0.159437, G loss: 7.521421, D accuracy: 96.6%, cell accuracy: 89.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.212719, G loss: 7.956957, D accuracy: 96.0%, cell accuracy: 89.6%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0175, G loss: 7.5018\n",
      "[372/8000] D loss: 0.3266, G loss: 7.5658\n",
      "[732/8000] D loss: 0.9766, G loss: 5.2264\n",
      "[1092/8000] D loss: 0.1528, G loss: 6.9590\n",
      "[1452/8000] D loss: 0.2063, G loss: 7.1369\n",
      "[1812/8000] D loss: 0.0096, G loss: 9.5418\n",
      "[2172/8000] D loss: 0.1843, G loss: 6.5481\n",
      "[2532/8000] D loss: 0.0264, G loss: 7.2909\n",
      "[2892/8000] D loss: 0.2631, G loss: 6.1401\n",
      "[3252/8000] D loss: 0.0300, G loss: 5.7724\n",
      "[3612/8000] D loss: 0.1202, G loss: 6.7658\n",
      "[3972/8000] D loss: 0.0067, G loss: 7.5485\n",
      "[4332/8000] D loss: 0.1629, G loss: 6.2842\n",
      "[4692/8000] D loss: 0.2206, G loss: 6.5377\n",
      "[5052/8000] D loss: 0.1583, G loss: 7.4049\n",
      "[5412/8000] D loss: 0.3308, G loss: 6.9379\n",
      "[5772/8000] D loss: 0.0101, G loss: 10.4174\n",
      "[6132/8000] D loss: 0.3816, G loss: 5.8745\n",
      "[6492/8000] D loss: 0.4087, G loss: 6.8913\n",
      "[6852/8000] D loss: 0.0125, G loss: 7.7779\n",
      "[7212/8000] D loss: 0.0254, G loss: 7.2666\n",
      "[7572/8000] D loss: 0.0796, G loss: 8.6216\n",
      "[7932/8000] D loss: 0.3096, G loss: 6.1885\n",
      "train error: \n",
      " D loss: 0.253838, G loss: 8.813333, D accuracy: 95.4%, cell accuracy: 89.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.344456, G loss: 9.226519, D accuracy: 94.6%, cell accuracy: 89.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0373, G loss: 9.3332\n",
      "[372/8000] D loss: 0.0361, G loss: 7.3639\n",
      "[732/8000] D loss: 0.0899, G loss: 8.4251\n",
      "[1092/8000] D loss: 0.0240, G loss: 8.0464\n",
      "[1452/8000] D loss: 0.0565, G loss: 10.0530\n",
      "[1812/8000] D loss: 0.2278, G loss: 6.8612\n",
      "[2172/8000] D loss: 0.2116, G loss: 7.6422\n",
      "[2532/8000] D loss: 0.1229, G loss: 7.8024\n",
      "[2892/8000] D loss: 0.0237, G loss: 7.8708\n",
      "[3252/8000] D loss: 0.1929, G loss: 8.5751\n",
      "[3612/8000] D loss: 0.0310, G loss: 7.8506\n",
      "[3972/8000] D loss: 0.2436, G loss: 7.1168\n",
      "[4332/8000] D loss: 0.2053, G loss: 6.1117\n",
      "[4692/8000] D loss: 0.0563, G loss: 5.8005\n",
      "[5052/8000] D loss: 0.4868, G loss: 5.1159\n",
      "[5412/8000] D loss: 0.0249, G loss: 8.1285\n",
      "[5772/8000] D loss: 0.0243, G loss: 6.4985\n",
      "[6132/8000] D loss: 0.0401, G loss: 9.4634\n",
      "[6492/8000] D loss: 0.0243, G loss: 10.9477\n",
      "[6852/8000] D loss: 0.0833, G loss: 6.7846\n",
      "[7212/8000] D loss: 0.0164, G loss: 8.6981\n",
      "[7572/8000] D loss: 0.1216, G loss: 9.2271\n",
      "[7932/8000] D loss: 0.1791, G loss: 5.1890\n",
      "train error: \n",
      " D loss: 0.150568, G loss: 7.225561, D accuracy: 97.0%, cell accuracy: 89.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.212613, G loss: 7.713426, D accuracy: 96.1%, cell accuracy: 89.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0270, G loss: 7.3720\n",
      "[372/8000] D loss: 0.0539, G loss: 6.7298\n",
      "[732/8000] D loss: 0.0361, G loss: 7.5246\n",
      "[1092/8000] D loss: 0.0024, G loss: 8.7173\n",
      "[1452/8000] D loss: 0.0872, G loss: 5.8324\n",
      "[1812/8000] D loss: 0.1003, G loss: 7.8316\n",
      "[2172/8000] D loss: 0.4796, G loss: 8.0826\n",
      "[2532/8000] D loss: 0.1212, G loss: 7.0894\n",
      "[2892/8000] D loss: 0.0703, G loss: 7.8511\n",
      "[3252/8000] D loss: 0.0040, G loss: 8.4598\n",
      "[3612/8000] D loss: 0.0739, G loss: 7.6376\n",
      "[3972/8000] D loss: 0.1661, G loss: 5.7989\n",
      "[4332/8000] D loss: 0.0904, G loss: 7.1442\n",
      "[4692/8000] D loss: 0.0238, G loss: 6.0734\n",
      "[5052/8000] D loss: 0.1122, G loss: 6.5149\n",
      "[5412/8000] D loss: 0.0481, G loss: 8.5325\n",
      "[5772/8000] D loss: 0.2930, G loss: 8.3057\n",
      "[6132/8000] D loss: 0.0746, G loss: 8.5334\n",
      "[6492/8000] D loss: 0.1498, G loss: 5.4097\n",
      "[6852/8000] D loss: 0.1852, G loss: 8.2683\n",
      "[7212/8000] D loss: 0.2165, G loss: 9.4959\n",
      "[7572/8000] D loss: 0.2831, G loss: 6.9036\n",
      "[7932/8000] D loss: 0.1246, G loss: 8.3146\n",
      "train error: \n",
      " D loss: 0.160042, G loss: 6.572014, D accuracy: 96.8%, cell accuracy: 90.0%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.166548, G loss: 7.125383, D accuracy: 96.6%, cell accuracy: 89.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3594, G loss: 5.5278\n",
      "[372/8000] D loss: 0.0022, G loss: 9.5452\n",
      "[732/8000] D loss: 0.0185, G loss: 6.8443\n",
      "[1092/8000] D loss: 0.1877, G loss: 8.1577\n",
      "[1452/8000] D loss: 0.0852, G loss: 6.9664\n",
      "[1812/8000] D loss: 0.1584, G loss: 7.0577\n",
      "[2172/8000] D loss: 0.0024, G loss: 8.3933\n",
      "[2532/8000] D loss: 0.6320, G loss: 6.8427\n",
      "[2892/8000] D loss: 0.0397, G loss: 6.8292\n",
      "[3252/8000] D loss: 0.2685, G loss: 8.2201\n",
      "[3612/8000] D loss: 0.1227, G loss: 8.1052\n",
      "[3972/8000] D loss: 0.0266, G loss: 9.4134\n",
      "[4332/8000] D loss: 0.1496, G loss: 6.1612\n",
      "[4692/8000] D loss: 0.0609, G loss: 7.7384\n",
      "[5052/8000] D loss: 0.0314, G loss: 6.8199\n",
      "[5412/8000] D loss: 0.0271, G loss: 6.3277\n",
      "[5772/8000] D loss: 0.1866, G loss: 10.2948\n",
      "[6132/8000] D loss: 0.1568, G loss: 6.6447\n",
      "[6492/8000] D loss: 0.0128, G loss: 8.6257\n",
      "[6852/8000] D loss: 0.3340, G loss: 8.2776\n",
      "[7212/8000] D loss: 0.0144, G loss: 7.2362\n",
      "[7572/8000] D loss: 0.2333, G loss: 6.1563\n",
      "[7932/8000] D loss: 0.1273, G loss: 5.4914\n",
      "train error: \n",
      " D loss: 0.174897, G loss: 5.812249, D accuracy: 96.6%, cell accuracy: 90.0%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.189594, G loss: 6.332796, D accuracy: 96.8%, cell accuracy: 89.8%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1205, G loss: 5.7266\n",
      "[372/8000] D loss: 0.3709, G loss: 5.3489\n",
      "[732/8000] D loss: 0.2381, G loss: 6.7603\n",
      "[1092/8000] D loss: 0.0174, G loss: 5.6583\n",
      "[1452/8000] D loss: 0.1008, G loss: 5.8931\n",
      "[1812/8000] D loss: 0.3132, G loss: 4.6943\n",
      "[2172/8000] D loss: 0.0493, G loss: 6.2064\n",
      "[2532/8000] D loss: 0.0570, G loss: 6.4090\n",
      "[2892/8000] D loss: 0.0025, G loss: 9.8339\n",
      "[3252/8000] D loss: 0.1037, G loss: 7.2473\n",
      "[3612/8000] D loss: 0.2322, G loss: 7.1718\n",
      "[3972/8000] D loss: 0.0081, G loss: 10.1601\n",
      "[4332/8000] D loss: 0.0053, G loss: 9.5504\n",
      "[4692/8000] D loss: 0.0814, G loss: 7.1467\n",
      "[5052/8000] D loss: 0.0161, G loss: 7.5920\n",
      "[5412/8000] D loss: 0.1825, G loss: 7.2027\n",
      "[5772/8000] D loss: 0.2432, G loss: 4.5266\n",
      "[6132/8000] D loss: 0.0566, G loss: 5.3328\n",
      "[6492/8000] D loss: 0.2770, G loss: 8.2947\n",
      "[6852/8000] D loss: 0.2692, G loss: 6.5680\n",
      "[7212/8000] D loss: 0.1320, G loss: 9.6679\n",
      "[7572/8000] D loss: 0.3442, G loss: 5.1864\n",
      "[7932/8000] D loss: 0.0445, G loss: 6.3247\n",
      "train error: \n",
      " D loss: 0.176701, G loss: 8.166434, D accuracy: 96.6%, cell accuracy: 90.2%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.256576, G loss: 8.664386, D accuracy: 95.6%, cell accuracy: 90.0%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1232, G loss: 7.7270\n",
      "[372/8000] D loss: 0.0584, G loss: 8.3504\n",
      "[732/8000] D loss: 0.1839, G loss: 6.7580\n",
      "[1092/8000] D loss: 0.0554, G loss: 6.0348\n",
      "[1452/8000] D loss: 0.3996, G loss: 4.7951\n",
      "[1812/8000] D loss: 0.6037, G loss: 7.5194\n",
      "[2172/8000] D loss: 0.0076, G loss: 9.2423\n",
      "[2532/8000] D loss: 0.0501, G loss: 7.7186\n",
      "[2892/8000] D loss: 0.1171, G loss: 6.0797\n",
      "[3252/8000] D loss: 0.0213, G loss: 8.2814\n",
      "[3612/8000] D loss: 0.0749, G loss: 5.6994\n",
      "[3972/8000] D loss: 0.0589, G loss: 8.1391\n",
      "[4332/8000] D loss: 0.0555, G loss: 6.7093\n",
      "[4692/8000] D loss: 0.0238, G loss: 6.9038\n",
      "[5052/8000] D loss: 0.2866, G loss: 6.9971\n",
      "[5412/8000] D loss: 0.0920, G loss: 7.5014\n",
      "[5772/8000] D loss: 0.0580, G loss: 8.8270\n",
      "[6132/8000] D loss: 0.0034, G loss: 9.6259\n",
      "[6492/8000] D loss: 0.0739, G loss: 7.3225\n",
      "[6852/8000] D loss: 0.0217, G loss: 6.4981\n",
      "[7212/8000] D loss: 0.1122, G loss: 6.0720\n",
      "[7572/8000] D loss: 0.4526, G loss: 6.6106\n",
      "[7932/8000] D loss: 0.0327, G loss: 7.0648\n",
      "train error: \n",
      " D loss: 0.137536, G loss: 6.101197, D accuracy: 97.3%, cell accuracy: 90.2%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.183335, G loss: 6.661529, D accuracy: 96.4%, cell accuracy: 90.0%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0246, G loss: 6.4906\n",
      "[372/8000] D loss: 0.0774, G loss: 8.3156\n",
      "[732/8000] D loss: 0.5297, G loss: 6.8323\n",
      "[1092/8000] D loss: 0.2053, G loss: 6.3197\n",
      "[1452/8000] D loss: 0.0318, G loss: 6.5958\n",
      "[1812/8000] D loss: 0.2750, G loss: 6.7058\n",
      "[2172/8000] D loss: 0.0265, G loss: 7.9736\n",
      "[2532/8000] D loss: 0.0529, G loss: 7.4437\n",
      "[2892/8000] D loss: 0.4196, G loss: 4.6702\n",
      "[3252/8000] D loss: 0.1373, G loss: 5.0066\n",
      "[3612/8000] D loss: 0.3752, G loss: 7.1177\n",
      "[3972/8000] D loss: 0.1446, G loss: 8.4039\n",
      "[4332/8000] D loss: 0.0303, G loss: 9.1597\n",
      "[4692/8000] D loss: 0.0340, G loss: 10.3531\n",
      "[5052/8000] D loss: 0.0755, G loss: 7.5861\n",
      "[5412/8000] D loss: 0.2042, G loss: 7.6345\n",
      "[5772/8000] D loss: 0.0227, G loss: 8.6131\n",
      "[6132/8000] D loss: 0.2784, G loss: 5.5025\n",
      "[6492/8000] D loss: 0.1230, G loss: 6.9959\n",
      "[6852/8000] D loss: 0.0986, G loss: 9.5525\n",
      "[7212/8000] D loss: 0.1166, G loss: 6.3826\n",
      "[7572/8000] D loss: 0.8993, G loss: 8.9692\n",
      "[7932/8000] D loss: 0.0893, G loss: 4.6558\n",
      "train error: \n",
      " D loss: 0.209879, G loss: 8.176148, D accuracy: 95.5%, cell accuracy: 90.2%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.325508, G loss: 8.667914, D accuracy: 94.3%, cell accuracy: 90.1%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0563, G loss: 8.2236\n",
      "[372/8000] D loss: 0.1444, G loss: 7.5434\n",
      "[732/8000] D loss: 0.1378, G loss: 9.2682\n",
      "[1092/8000] D loss: 0.0599, G loss: 8.7425\n",
      "[1452/8000] D loss: 0.0722, G loss: 8.1742\n",
      "[1812/8000] D loss: 0.0779, G loss: 5.8442\n",
      "[2172/8000] D loss: 0.0227, G loss: 7.5548\n",
      "[2532/8000] D loss: 0.0126, G loss: 10.3370\n",
      "[2892/8000] D loss: 0.1873, G loss: 8.9818\n",
      "[3252/8000] D loss: 0.0033, G loss: 8.3890\n",
      "[3612/8000] D loss: 0.1783, G loss: 10.0453\n",
      "[3972/8000] D loss: 0.2556, G loss: 6.1551\n",
      "[4332/8000] D loss: 0.0413, G loss: 7.1877\n",
      "[4692/8000] D loss: 0.2773, G loss: 5.1498\n",
      "[5052/8000] D loss: 0.1662, G loss: 5.9485\n",
      "[5412/8000] D loss: 0.0680, G loss: 8.9907\n",
      "[5772/8000] D loss: 0.0520, G loss: 8.8683\n",
      "[6132/8000] D loss: 0.2232, G loss: 8.7489\n",
      "[6492/8000] D loss: 0.6314, G loss: 7.4032\n",
      "[6852/8000] D loss: 0.2435, G loss: 6.7674\n",
      "[7212/8000] D loss: 0.0567, G loss: 7.1181\n",
      "[7572/8000] D loss: 0.3052, G loss: 6.1834\n",
      "[7932/8000] D loss: 0.0618, G loss: 7.7716\n",
      "train error: \n",
      " D loss: 0.166868, G loss: 6.773271, D accuracy: 96.5%, cell accuracy: 90.4%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.204869, G loss: 7.435256, D accuracy: 96.0%, cell accuracy: 90.2%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3534, G loss: 6.0098\n",
      "[372/8000] D loss: 0.0932, G loss: 4.9302\n",
      "[732/8000] D loss: 0.0720, G loss: 7.6512\n",
      "[1092/8000] D loss: 0.2742, G loss: 4.4097\n",
      "[1452/8000] D loss: 0.0753, G loss: 6.7539\n",
      "[1812/8000] D loss: 0.1505, G loss: 8.1696\n",
      "[2172/8000] D loss: 0.0173, G loss: 9.2500\n",
      "[2532/8000] D loss: 0.1817, G loss: 6.8218\n",
      "[2892/8000] D loss: 0.0582, G loss: 6.3650\n",
      "[3252/8000] D loss: 0.1164, G loss: 7.3761\n",
      "[3612/8000] D loss: 0.0432, G loss: 8.8527\n",
      "[3972/8000] D loss: 0.2912, G loss: 8.2482\n",
      "[4332/8000] D loss: 0.1427, G loss: 5.4840\n",
      "[4692/8000] D loss: 0.0407, G loss: 6.3523\n",
      "[5052/8000] D loss: 0.0216, G loss: 6.6923\n",
      "[5412/8000] D loss: 0.0516, G loss: 8.1284\n",
      "[5772/8000] D loss: 0.0645, G loss: 10.0061\n",
      "[6132/8000] D loss: 0.0659, G loss: 7.9234\n",
      "[6492/8000] D loss: 0.0466, G loss: 6.2316\n",
      "[6852/8000] D loss: 0.3987, G loss: 8.0021\n",
      "[7212/8000] D loss: 0.0468, G loss: 7.7083\n",
      "[7572/8000] D loss: 0.0145, G loss: 7.5616\n",
      "[7932/8000] D loss: 0.7408, G loss: 8.9229\n",
      "train error: \n",
      " D loss: 0.371201, G loss: 5.279360, D accuracy: 93.1%, cell accuracy: 90.6%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.339847, G loss: 5.892872, D accuracy: 93.8%, cell accuracy: 90.3%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4661, G loss: 3.8213\n",
      "[372/8000] D loss: 0.0769, G loss: 7.4680\n",
      "[732/8000] D loss: 0.3716, G loss: 7.2297\n",
      "[1092/8000] D loss: 0.1225, G loss: 5.3599\n",
      "[1452/8000] D loss: 0.1642, G loss: 6.5160\n",
      "[1812/8000] D loss: 0.1535, G loss: 8.4166\n",
      "[2172/8000] D loss: 0.0247, G loss: 10.3000\n",
      "[2532/8000] D loss: 0.0397, G loss: 6.8434\n",
      "[2892/8000] D loss: 0.4691, G loss: 6.5651\n",
      "[3252/8000] D loss: 0.1297, G loss: 7.0692\n",
      "[3612/8000] D loss: 0.5803, G loss: 7.5073\n",
      "[3972/8000] D loss: 0.0927, G loss: 6.6639\n",
      "[4332/8000] D loss: 0.0649, G loss: 8.0214\n",
      "[4692/8000] D loss: 0.1233, G loss: 6.7955\n",
      "[5052/8000] D loss: 0.1918, G loss: 5.1355\n",
      "[5412/8000] D loss: 0.2148, G loss: 8.3272\n",
      "[5772/8000] D loss: 0.3162, G loss: 4.7505\n",
      "[6132/8000] D loss: 0.2681, G loss: 5.5559\n",
      "[6492/8000] D loss: 0.0606, G loss: 7.3638\n",
      "[6852/8000] D loss: 0.0822, G loss: 6.9064\n",
      "[7212/8000] D loss: 0.0605, G loss: 6.8144\n",
      "[7572/8000] D loss: 0.0171, G loss: 6.9890\n",
      "[7932/8000] D loss: 0.7481, G loss: 4.4323\n",
      "train error: \n",
      " D loss: 0.166779, G loss: 5.650782, D accuracy: 96.5%, cell accuracy: 90.6%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.192095, G loss: 6.244988, D accuracy: 96.3%, cell accuracy: 90.4%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1129, G loss: 6.2161\n",
      "[372/8000] D loss: 0.1433, G loss: 6.6449\n",
      "[732/8000] D loss: 0.1990, G loss: 7.1497\n",
      "[1092/8000] D loss: 0.0658, G loss: 6.9955\n",
      "[1452/8000] D loss: 0.1724, G loss: 8.9363\n",
      "[1812/8000] D loss: 0.0605, G loss: 10.7802\n",
      "[2172/8000] D loss: 0.3381, G loss: 8.7052\n",
      "[2532/8000] D loss: 0.0628, G loss: 7.9913\n",
      "[2892/8000] D loss: 0.0428, G loss: 7.6564\n",
      "[3252/8000] D loss: 0.1647, G loss: 7.6553\n",
      "[3612/8000] D loss: 0.1801, G loss: 7.0013\n",
      "[3972/8000] D loss: 0.1518, G loss: 6.5459\n",
      "[4332/8000] D loss: 0.0602, G loss: 9.0291\n",
      "[4692/8000] D loss: 0.4003, G loss: 6.9856\n",
      "[5052/8000] D loss: 0.6545, G loss: 6.2406\n",
      "[5412/8000] D loss: 0.0684, G loss: 6.8437\n",
      "[5772/8000] D loss: 0.1147, G loss: 9.9578\n",
      "[6132/8000] D loss: 0.6583, G loss: 3.8177\n",
      "[6492/8000] D loss: 0.1625, G loss: 5.3733\n",
      "[6852/8000] D loss: 0.1113, G loss: 7.3421\n",
      "[7212/8000] D loss: 0.1049, G loss: 8.4708\n",
      "[7572/8000] D loss: 0.0658, G loss: 9.6753\n",
      "[7932/8000] D loss: 0.3951, G loss: 4.8553\n",
      "train error: \n",
      " D loss: 0.189791, G loss: 8.103748, D accuracy: 96.1%, cell accuracy: 90.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.297323, G loss: 8.660805, D accuracy: 94.8%, cell accuracy: 90.5%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0169, G loss: 8.8666\n",
      "[372/8000] D loss: 0.2751, G loss: 8.3687\n",
      "[732/8000] D loss: 0.0174, G loss: 8.5040\n",
      "[1092/8000] D loss: 0.8253, G loss: 7.4266\n",
      "[1452/8000] D loss: 0.0756, G loss: 6.3895\n",
      "[1812/8000] D loss: 0.2221, G loss: 6.6295\n",
      "[2172/8000] D loss: 0.0737, G loss: 6.1598\n",
      "[2532/8000] D loss: 0.0816, G loss: 9.5999\n",
      "[2892/8000] D loss: 0.0081, G loss: 7.6367\n",
      "[3252/8000] D loss: 0.1914, G loss: 7.1717\n",
      "[3612/8000] D loss: 0.0685, G loss: 7.4204\n",
      "[3972/8000] D loss: 0.1494, G loss: 6.7759\n",
      "[4332/8000] D loss: 0.0914, G loss: 7.9436\n",
      "[4692/8000] D loss: 0.2584, G loss: 8.3428\n",
      "[5052/8000] D loss: 0.3848, G loss: 6.2699\n",
      "[5412/8000] D loss: 0.0308, G loss: 8.7984\n",
      "[5772/8000] D loss: 0.2131, G loss: 6.1077\n",
      "[6132/8000] D loss: 0.0725, G loss: 5.4620\n",
      "[6492/8000] D loss: 0.0106, G loss: 10.1028\n",
      "[6852/8000] D loss: 0.1644, G loss: 7.3759\n",
      "[7212/8000] D loss: 0.2414, G loss: 6.3384\n",
      "[7572/8000] D loss: 0.1231, G loss: 7.0780\n",
      "[7932/8000] D loss: 0.0651, G loss: 6.4667\n",
      "train error: \n",
      " D loss: 0.159929, G loss: 6.568638, D accuracy: 96.5%, cell accuracy: 90.7%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.192328, G loss: 7.284854, D accuracy: 96.1%, cell accuracy: 90.5%, board accuracy: 0.3% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0199, G loss: 9.5962\n",
      "[372/8000] D loss: 0.2065, G loss: 7.0696\n",
      "[732/8000] D loss: 0.0933, G loss: 7.2556\n",
      "[1092/8000] D loss: 0.0286, G loss: 7.5820\n",
      "[1452/8000] D loss: 0.2254, G loss: 6.9080\n",
      "[1812/8000] D loss: 0.1289, G loss: 6.2699\n",
      "[2172/8000] D loss: 0.0662, G loss: 7.1158\n",
      "[2532/8000] D loss: 0.0615, G loss: 6.6895\n",
      "[2892/8000] D loss: 0.0543, G loss: 7.6740\n",
      "[3252/8000] D loss: 0.1599, G loss: 8.6836\n",
      "[3612/8000] D loss: 0.0125, G loss: 7.8373\n",
      "[3972/8000] D loss: 0.1649, G loss: 7.9394\n",
      "[4332/8000] D loss: 0.0591, G loss: 7.1107\n",
      "[4692/8000] D loss: 0.1538, G loss: 6.9275\n",
      "[5052/8000] D loss: 0.2859, G loss: 5.6784\n",
      "[5412/8000] D loss: 0.2453, G loss: 6.3240\n",
      "[5772/8000] D loss: 0.1138, G loss: 6.8366\n",
      "[6132/8000] D loss: 0.1662, G loss: 6.3343\n",
      "[6492/8000] D loss: 0.1095, G loss: 7.6349\n",
      "[6852/8000] D loss: 0.0374, G loss: 8.6211\n",
      "[7212/8000] D loss: 0.0746, G loss: 5.9964\n",
      "[7572/8000] D loss: 0.1547, G loss: 6.9796\n",
      "[7932/8000] D loss: 0.0400, G loss: 5.9481\n",
      "train error: \n",
      " D loss: 0.205958, G loss: 5.545841, D accuracy: 95.3%, cell accuracy: 90.9%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.210989, G loss: 6.238134, D accuracy: 95.5%, cell accuracy: 90.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1067, G loss: 6.8392\n",
      "[372/8000] D loss: 0.0269, G loss: 7.0369\n",
      "[732/8000] D loss: 0.1935, G loss: 8.6381\n",
      "[1092/8000] D loss: 0.1703, G loss: 8.5588\n",
      "[1452/8000] D loss: 0.3054, G loss: 6.6290\n",
      "[1812/8000] D loss: 0.0201, G loss: 7.3355\n",
      "[2172/8000] D loss: 0.7306, G loss: 8.0525\n",
      "[2532/8000] D loss: 0.1409, G loss: 9.0270\n",
      "[2892/8000] D loss: 0.0151, G loss: 8.6662\n",
      "[3252/8000] D loss: 0.1784, G loss: 6.2162\n",
      "[3612/8000] D loss: 0.2691, G loss: 6.2417\n",
      "[3972/8000] D loss: 0.3313, G loss: 6.9484\n",
      "[4332/8000] D loss: 0.0264, G loss: 9.8293\n",
      "[4692/8000] D loss: 0.0229, G loss: 7.3348\n",
      "[5052/8000] D loss: 0.2549, G loss: 6.0813\n",
      "[5412/8000] D loss: 0.0567, G loss: 8.6205\n",
      "[5772/8000] D loss: 0.4552, G loss: 10.2688\n",
      "[6132/8000] D loss: 0.0405, G loss: 7.5290\n",
      "[6492/8000] D loss: 0.5442, G loss: 5.9520\n",
      "[6852/8000] D loss: 0.0320, G loss: 6.7927\n",
      "[7212/8000] D loss: 0.1040, G loss: 6.9010\n",
      "[7572/8000] D loss: 0.1647, G loss: 6.4275\n",
      "[7932/8000] D loss: 0.1003, G loss: 7.5205\n",
      "train error: \n",
      " D loss: 0.125098, G loss: 6.891598, D accuracy: 97.4%, cell accuracy: 90.9%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.187890, G loss: 7.578704, D accuracy: 96.5%, cell accuracy: 90.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4390, G loss: 6.1492\n",
      "[372/8000] D loss: 0.0360, G loss: 8.6668\n",
      "[732/8000] D loss: 0.1677, G loss: 6.5989\n",
      "[1092/8000] D loss: 0.1337, G loss: 8.9575\n",
      "[1452/8000] D loss: 0.0447, G loss: 6.2343\n",
      "[1812/8000] D loss: 0.4161, G loss: 7.1945\n",
      "[2172/8000] D loss: 0.2438, G loss: 5.9383\n",
      "[2532/8000] D loss: 0.0825, G loss: 11.6764\n",
      "[2892/8000] D loss: 0.2889, G loss: 6.3525\n",
      "[3252/8000] D loss: 0.1363, G loss: 5.6876\n",
      "[3612/8000] D loss: 0.0402, G loss: 11.3865\n",
      "[3972/8000] D loss: 0.2182, G loss: 6.6321\n",
      "[4332/8000] D loss: 0.0170, G loss: 6.9805\n",
      "[4692/8000] D loss: 0.0291, G loss: 7.3441\n",
      "[5052/8000] D loss: 0.0933, G loss: 6.2831\n",
      "[5412/8000] D loss: 0.0220, G loss: 6.0524\n",
      "[5772/8000] D loss: 0.1536, G loss: 9.4254\n",
      "[6132/8000] D loss: 0.0456, G loss: 8.2792\n",
      "[6492/8000] D loss: 0.0799, G loss: 7.5486\n",
      "[6852/8000] D loss: 0.0979, G loss: 7.4936\n",
      "[7212/8000] D loss: 0.0535, G loss: 7.3579\n",
      "[7572/8000] D loss: 0.2627, G loss: 5.7653\n",
      "[7932/8000] D loss: 0.1678, G loss: 8.0029\n",
      "train error: \n",
      " D loss: 0.146128, G loss: 6.848486, D accuracy: 97.0%, cell accuracy: 90.9%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.197061, G loss: 7.525319, D accuracy: 96.4%, cell accuracy: 90.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0718, G loss: 8.4890\n",
      "[372/8000] D loss: 0.1416, G loss: 8.7957\n",
      "[732/8000] D loss: 0.0102, G loss: 8.6754\n",
      "[1092/8000] D loss: 0.1211, G loss: 7.8395\n",
      "[1452/8000] D loss: 0.1915, G loss: 8.4092\n",
      "[1812/8000] D loss: 0.2091, G loss: 7.9709\n",
      "[2172/8000] D loss: 0.0444, G loss: 7.5937\n",
      "[2532/8000] D loss: 0.2870, G loss: 6.6512\n",
      "[2892/8000] D loss: 0.0362, G loss: 6.5074\n",
      "[3252/8000] D loss: 0.0389, G loss: 8.4942\n",
      "[3612/8000] D loss: 0.1296, G loss: 8.6313\n",
      "[3972/8000] D loss: 0.0641, G loss: 7.2044\n",
      "[4332/8000] D loss: 0.1152, G loss: 10.6078\n",
      "[4692/8000] D loss: 0.1791, G loss: 6.8842\n",
      "[5052/8000] D loss: 0.0141, G loss: 9.0158\n",
      "[5412/8000] D loss: 0.1964, G loss: 8.2088\n",
      "[5772/8000] D loss: 0.0524, G loss: 5.1210\n",
      "[6132/8000] D loss: 0.2618, G loss: 6.9105\n",
      "[6492/8000] D loss: 0.4162, G loss: 4.9464\n",
      "[6852/8000] D loss: 0.0045, G loss: 9.1113\n",
      "[7212/8000] D loss: 0.0234, G loss: 7.5230\n",
      "[7572/8000] D loss: 0.3336, G loss: 6.7228\n",
      "[7932/8000] D loss: 0.0182, G loss: 7.4336\n",
      "train error: \n",
      " D loss: 0.142260, G loss: 7.042067, D accuracy: 97.2%, cell accuracy: 90.9%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.215577, G loss: 7.748289, D accuracy: 96.2%, cell accuracy: 90.6%, board accuracy: 0.1% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0936, G loss: 6.3854\n",
      "[372/8000] D loss: 0.1135, G loss: 8.0492\n",
      "[732/8000] D loss: 0.1178, G loss: 6.3138\n",
      "[1092/8000] D loss: 0.2533, G loss: 10.0120\n",
      "[1452/8000] D loss: 0.0644, G loss: 7.8439\n",
      "[1812/8000] D loss: 0.0120, G loss: 10.6849\n",
      "[2172/8000] D loss: 0.2558, G loss: 6.8389\n",
      "[2532/8000] D loss: 0.1968, G loss: 7.9471\n",
      "[2892/8000] D loss: 0.0046, G loss: 9.0407\n",
      "[3252/8000] D loss: 0.1247, G loss: 6.0180\n",
      "[3612/8000] D loss: 0.0815, G loss: 8.9867\n",
      "[3972/8000] D loss: 0.2103, G loss: 7.3676\n",
      "[4332/8000] D loss: 0.0180, G loss: 7.5703\n",
      "[4692/8000] D loss: 0.1975, G loss: 8.6810\n",
      "[5052/8000] D loss: 0.3434, G loss: 6.2324\n",
      "[5412/8000] D loss: 0.0508, G loss: 7.3460\n",
      "[5772/8000] D loss: 0.1580, G loss: 7.9200\n",
      "[6132/8000] D loss: 0.0617, G loss: 8.6666\n",
      "[6492/8000] D loss: 0.2616, G loss: 9.0594\n",
      "[6852/8000] D loss: 0.3204, G loss: 6.7931\n",
      "[7212/8000] D loss: 0.3495, G loss: 4.6943\n",
      "[7572/8000] D loss: 0.0668, G loss: 10.1494\n",
      "[7932/8000] D loss: 0.0267, G loss: 8.7196\n",
      "train error: \n",
      " D loss: 0.138128, G loss: 8.108245, D accuracy: 97.4%, cell accuracy: 90.9%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.224174, G loss: 8.804164, D accuracy: 96.4%, cell accuracy: 90.7%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1904, G loss: 7.4540\n",
      "[372/8000] D loss: 0.0158, G loss: 6.1043\n",
      "[732/8000] D loss: 0.2394, G loss: 7.1724\n",
      "[1092/8000] D loss: 0.5224, G loss: 6.4793\n",
      "[1452/8000] D loss: 0.0028, G loss: 10.6869\n",
      "[1812/8000] D loss: 0.1837, G loss: 9.9269\n",
      "[2172/8000] D loss: 0.1844, G loss: 7.2042\n",
      "[2532/8000] D loss: 0.1450, G loss: 8.9895\n",
      "[2892/8000] D loss: 0.0698, G loss: 9.1181\n",
      "[3252/8000] D loss: 0.1973, G loss: 7.5161\n",
      "[3612/8000] D loss: 0.0979, G loss: 5.0547\n",
      "[3972/8000] D loss: 0.1031, G loss: 7.1458\n",
      "[4332/8000] D loss: 0.0149, G loss: 9.6411\n",
      "[4692/8000] D loss: 0.1304, G loss: 9.5761\n",
      "[5052/8000] D loss: 0.0642, G loss: 5.2470\n",
      "[5412/8000] D loss: 0.1306, G loss: 6.3032\n",
      "[5772/8000] D loss: 0.1015, G loss: 7.3359\n",
      "[6132/8000] D loss: 0.1186, G loss: 7.3941\n",
      "[6492/8000] D loss: 0.2601, G loss: 6.0910\n",
      "[6852/8000] D loss: 0.2009, G loss: 8.1244\n",
      "[7212/8000] D loss: 0.0353, G loss: 8.1850\n",
      "[7572/8000] D loss: 0.2653, G loss: 6.1651\n",
      "[7932/8000] D loss: 0.1090, G loss: 6.5650\n",
      "train error: \n",
      " D loss: 0.181707, G loss: 6.308082, D accuracy: 96.1%, cell accuracy: 90.9%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.199678, G loss: 7.122416, D accuracy: 96.0%, cell accuracy: 90.7%, board accuracy: 0.3% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0914, G loss: 7.5377\n",
      "[372/8000] D loss: 0.4181, G loss: 7.2387\n",
      "[732/8000] D loss: 0.0924, G loss: 9.9647\n",
      "[1092/8000] D loss: 0.2685, G loss: 5.6286\n",
      "[1452/8000] D loss: 0.2331, G loss: 7.0370\n",
      "[1812/8000] D loss: 0.0355, G loss: 8.4633\n",
      "[2172/8000] D loss: 0.1403, G loss: 6.9802\n",
      "[2532/8000] D loss: 0.3239, G loss: 6.7418\n",
      "[2892/8000] D loss: 0.1775, G loss: 6.4107\n",
      "[3252/8000] D loss: 0.0977, G loss: 5.0917\n",
      "[3612/8000] D loss: 0.3893, G loss: 5.5802\n",
      "[3972/8000] D loss: 0.0329, G loss: 8.8955\n",
      "[4332/8000] D loss: 0.2090, G loss: 9.6178\n",
      "[4692/8000] D loss: 0.3126, G loss: 7.5659\n",
      "[5052/8000] D loss: 0.1257, G loss: 9.1109\n",
      "[5412/8000] D loss: 0.3580, G loss: 6.2767\n",
      "[5772/8000] D loss: 0.1423, G loss: 6.9948\n",
      "[6132/8000] D loss: 0.1268, G loss: 7.0843\n",
      "[6492/8000] D loss: 0.1956, G loss: 6.4837\n",
      "[6852/8000] D loss: 0.1862, G loss: 4.5602\n",
      "[7212/8000] D loss: 0.0482, G loss: 7.3887\n",
      "[7572/8000] D loss: 0.1858, G loss: 8.4582\n",
      "[7932/8000] D loss: 0.1361, G loss: 8.9358\n",
      "train error: \n",
      " D loss: 0.169315, G loss: 6.627100, D accuracy: 96.4%, cell accuracy: 91.0%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.186238, G loss: 7.440690, D accuracy: 96.4%, cell accuracy: 90.8%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1913, G loss: 6.8161\n",
      "[372/8000] D loss: 0.0284, G loss: 9.4442\n",
      "[732/8000] D loss: 0.0243, G loss: 8.8741\n",
      "[1092/8000] D loss: 0.4343, G loss: 6.7554\n",
      "[1452/8000] D loss: 0.1113, G loss: 6.6665\n",
      "[1812/8000] D loss: 0.2885, G loss: 5.0580\n",
      "[2172/8000] D loss: 0.0086, G loss: 9.0369\n",
      "[2532/8000] D loss: 0.2372, G loss: 7.7707\n",
      "[2892/8000] D loss: 0.1532, G loss: 7.0979\n",
      "[3252/8000] D loss: 0.0624, G loss: 8.7540\n",
      "[3612/8000] D loss: 0.6199, G loss: 8.1674\n",
      "[3972/8000] D loss: 0.0935, G loss: 7.8912\n",
      "[4332/8000] D loss: 0.4951, G loss: 5.3016\n",
      "[4692/8000] D loss: 0.2360, G loss: 7.3196\n",
      "[5052/8000] D loss: 0.2770, G loss: 7.0455\n",
      "[5412/8000] D loss: 0.0068, G loss: 7.1614\n",
      "[5772/8000] D loss: 0.3637, G loss: 8.9436\n",
      "[6132/8000] D loss: 0.1115, G loss: 8.7371\n",
      "[6492/8000] D loss: 0.0977, G loss: 8.9285\n",
      "[6852/8000] D loss: 0.1173, G loss: 8.2322\n",
      "[7212/8000] D loss: 0.2315, G loss: 6.3726\n",
      "[7572/8000] D loss: 0.0095, G loss: 10.2464\n",
      "[7932/8000] D loss: 0.1008, G loss: 8.5354\n",
      "train error: \n",
      " D loss: 0.135174, G loss: 7.598089, D accuracy: 97.1%, cell accuracy: 91.0%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.181016, G loss: 8.564200, D accuracy: 96.6%, cell accuracy: 90.7%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0905, G loss: 7.9148\n",
      "[372/8000] D loss: 0.1751, G loss: 10.4634\n",
      "[732/8000] D loss: 0.0056, G loss: 9.6340\n",
      "[1092/8000] D loss: 0.0012, G loss: 11.1484\n",
      "[1452/8000] D loss: 0.1856, G loss: 9.3612\n",
      "[1812/8000] D loss: 0.2709, G loss: 5.3500\n",
      "[2172/8000] D loss: 0.0469, G loss: 9.0387\n",
      "[2532/8000] D loss: 0.0633, G loss: 10.1266\n",
      "[2892/8000] D loss: 0.0976, G loss: 7.0655\n",
      "[3252/8000] D loss: 0.0781, G loss: 8.9123\n",
      "[3612/8000] D loss: 0.1089, G loss: 6.7749\n",
      "[3972/8000] D loss: 0.4898, G loss: 5.5351\n",
      "[4332/8000] D loss: 0.1258, G loss: 8.6228\n",
      "[4692/8000] D loss: 0.0908, G loss: 7.4184\n",
      "[5052/8000] D loss: 0.1152, G loss: 6.8389\n",
      "[5412/8000] D loss: 0.4490, G loss: 6.4772\n",
      "[5772/8000] D loss: 0.0158, G loss: 8.0351\n",
      "[6132/8000] D loss: 0.0771, G loss: 5.8295\n",
      "[6492/8000] D loss: 0.2282, G loss: 8.8751\n",
      "[6852/8000] D loss: 0.0814, G loss: 7.3402\n",
      "[7212/8000] D loss: 0.1232, G loss: 6.9382\n",
      "[7572/8000] D loss: 0.2218, G loss: 9.4068\n",
      "[7932/8000] D loss: 0.2967, G loss: 6.4700\n",
      "train error: \n",
      " D loss: 0.129264, G loss: 7.398068, D accuracy: 97.5%, cell accuracy: 90.9%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.196915, G loss: 8.169161, D accuracy: 96.4%, cell accuracy: 90.6%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0096, G loss: 7.1435\n",
      "[372/8000] D loss: 0.2110, G loss: 7.7603\n",
      "[732/8000] D loss: 0.0141, G loss: 9.2047\n",
      "[1092/8000] D loss: 0.0418, G loss: 6.8890\n",
      "[1452/8000] D loss: 0.0248, G loss: 6.5697\n",
      "[1812/8000] D loss: 0.4909, G loss: 7.3683\n",
      "[2172/8000] D loss: 0.2862, G loss: 6.6774\n",
      "[2532/8000] D loss: 0.2490, G loss: 9.3027\n",
      "[2892/8000] D loss: 0.1792, G loss: 5.3273\n",
      "[3252/8000] D loss: 0.2613, G loss: 7.7087\n",
      "[3612/8000] D loss: 0.1375, G loss: 5.9235\n",
      "[3972/8000] D loss: 0.1728, G loss: 8.3034\n",
      "[4332/8000] D loss: 0.0147, G loss: 9.1675\n",
      "[4692/8000] D loss: 0.2573, G loss: 7.1495\n",
      "[5052/8000] D loss: 0.1420, G loss: 8.8475\n",
      "[5412/8000] D loss: 0.0614, G loss: 6.6739\n",
      "[5772/8000] D loss: 0.0149, G loss: 9.3808\n",
      "[6132/8000] D loss: 0.0841, G loss: 7.0677\n",
      "[6492/8000] D loss: 0.0297, G loss: 7.3078\n",
      "[6852/8000] D loss: 1.1389, G loss: 3.4094\n",
      "[7212/8000] D loss: 0.2898, G loss: 6.9306\n",
      "[7572/8000] D loss: 0.0848, G loss: 5.9681\n",
      "[7932/8000] D loss: 0.2402, G loss: 6.5154\n",
      "train error: \n",
      " D loss: 0.156847, G loss: 8.104774, D accuracy: 96.9%, cell accuracy: 91.1%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.259433, G loss: 8.811337, D accuracy: 95.1%, cell accuracy: 90.8%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3613, G loss: 7.3204\n",
      "[372/8000] D loss: 0.0133, G loss: 7.2827\n",
      "[732/8000] D loss: 0.1153, G loss: 9.6617\n",
      "[1092/8000] D loss: 0.0319, G loss: 9.2626\n",
      "[1452/8000] D loss: 0.1210, G loss: 8.7918\n",
      "[1812/8000] D loss: 0.0796, G loss: 8.7248\n",
      "[2172/8000] D loss: 0.1634, G loss: 8.7750\n",
      "[2532/8000] D loss: 0.0482, G loss: 8.3164\n",
      "[2892/8000] D loss: 0.1393, G loss: 7.9712\n",
      "[3252/8000] D loss: 0.1736, G loss: 5.4859\n",
      "[3612/8000] D loss: 0.1253, G loss: 7.2519\n",
      "[3972/8000] D loss: 0.1293, G loss: 7.1907\n",
      "[4332/8000] D loss: 0.1508, G loss: 6.4603\n",
      "[4692/8000] D loss: 0.0408, G loss: 8.6609\n",
      "[5052/8000] D loss: 0.1215, G loss: 7.9417\n",
      "[5412/8000] D loss: 0.0491, G loss: 10.1468\n",
      "[5772/8000] D loss: 0.1200, G loss: 7.0449\n",
      "[6132/8000] D loss: 0.1389, G loss: 5.7412\n",
      "[6492/8000] D loss: 0.2283, G loss: 5.4210\n",
      "[6852/8000] D loss: 0.0813, G loss: 7.9867\n",
      "[7212/8000] D loss: 0.1240, G loss: 6.9463\n",
      "[7572/8000] D loss: 0.1391, G loss: 9.8296\n",
      "[7932/8000] D loss: 0.6039, G loss: 9.6862\n",
      "train error: \n",
      " D loss: 0.157240, G loss: 6.660712, D accuracy: 96.9%, cell accuracy: 91.2%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.196162, G loss: 7.417923, D accuracy: 96.5%, cell accuracy: 90.9%, board accuracy: 0.3% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2869, G loss: 4.6072\n",
      "[372/8000] D loss: 0.2418, G loss: 6.6730\n",
      "[732/8000] D loss: 0.0836, G loss: 9.0970\n",
      "[1092/8000] D loss: 0.2265, G loss: 7.7340\n",
      "[1452/8000] D loss: 0.1778, G loss: 5.1090\n",
      "[1812/8000] D loss: 0.0676, G loss: 7.2834\n",
      "[2172/8000] D loss: 0.0197, G loss: 8.2052\n",
      "[2532/8000] D loss: 0.0656, G loss: 6.2693\n",
      "[2892/8000] D loss: 0.1672, G loss: 8.2923\n",
      "[3252/8000] D loss: 0.3416, G loss: 9.1498\n",
      "[3612/8000] D loss: 0.3358, G loss: 6.7078\n",
      "[3972/8000] D loss: 0.0108, G loss: 8.5872\n",
      "[4332/8000] D loss: 0.0547, G loss: 9.3642\n",
      "[4692/8000] D loss: 0.6384, G loss: 7.1570\n",
      "[5052/8000] D loss: 0.0950, G loss: 7.0214\n",
      "[5412/8000] D loss: 0.0322, G loss: 9.5130\n",
      "[5772/8000] D loss: 0.1581, G loss: 6.7244\n",
      "[6132/8000] D loss: 0.1602, G loss: 8.3993\n",
      "[6492/8000] D loss: 0.0783, G loss: 7.4123\n",
      "[6852/8000] D loss: 0.1730, G loss: 7.4692\n",
      "[7212/8000] D loss: 0.1210, G loss: 7.5245\n",
      "[7572/8000] D loss: 0.1847, G loss: 7.3675\n",
      "[7932/8000] D loss: 0.0041, G loss: 9.0317\n",
      "train error: \n",
      " D loss: 0.136813, G loss: 8.026233, D accuracy: 97.3%, cell accuracy: 91.3%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.217650, G loss: 8.810655, D accuracy: 96.3%, cell accuracy: 91.1%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1364, G loss: 6.9695\n",
      "[372/8000] D loss: 0.2081, G loss: 6.0758\n",
      "[732/8000] D loss: 0.0904, G loss: 8.0034\n",
      "[1092/8000] D loss: 0.1440, G loss: 6.1120\n",
      "[1452/8000] D loss: 0.2971, G loss: 8.1001\n",
      "[1812/8000] D loss: 0.0086, G loss: 8.2014\n",
      "[2172/8000] D loss: 0.0186, G loss: 9.7078\n",
      "[2532/8000] D loss: 0.0460, G loss: 7.7630\n",
      "[2892/8000] D loss: 0.1135, G loss: 8.2870\n",
      "[3252/8000] D loss: 0.0923, G loss: 6.7946\n",
      "[3612/8000] D loss: 0.0701, G loss: 9.6401\n",
      "[3972/8000] D loss: 0.0088, G loss: 9.9480\n",
      "[4332/8000] D loss: 0.0421, G loss: 8.5990\n",
      "[4692/8000] D loss: 0.3552, G loss: 6.6234\n",
      "[5052/8000] D loss: 0.1366, G loss: 8.1332\n",
      "[5412/8000] D loss: 0.0623, G loss: 7.4993\n",
      "[5772/8000] D loss: 0.0221, G loss: 9.8004\n",
      "[6132/8000] D loss: 0.0059, G loss: 10.5079\n",
      "[6492/8000] D loss: 0.1924, G loss: 10.7144\n",
      "[6852/8000] D loss: 0.1723, G loss: 7.2638\n",
      "[7212/8000] D loss: 0.0302, G loss: 7.5292\n",
      "[7572/8000] D loss: 0.3056, G loss: 9.3976\n",
      "[7932/8000] D loss: 0.2899, G loss: 5.8109\n",
      "train error: \n",
      " D loss: 0.133705, G loss: 8.096913, D accuracy: 97.3%, cell accuracy: 91.2%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.233371, G loss: 8.869453, D accuracy: 95.7%, cell accuracy: 90.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1624, G loss: 7.6393\n",
      "[372/8000] D loss: 0.0253, G loss: 6.8687\n",
      "[732/8000] D loss: 0.1310, G loss: 6.1020\n",
      "[1092/8000] D loss: 0.1737, G loss: 7.9918\n",
      "[1452/8000] D loss: 0.0395, G loss: 7.7867\n",
      "[1812/8000] D loss: 0.0566, G loss: 9.9532\n",
      "[2172/8000] D loss: 0.0191, G loss: 7.9892\n",
      "[2532/8000] D loss: 0.0157, G loss: 9.1099\n",
      "[2892/8000] D loss: 0.0108, G loss: 10.7979\n",
      "[3252/8000] D loss: 0.0111, G loss: 8.9682\n",
      "[3612/8000] D loss: 0.0984, G loss: 7.7175\n",
      "[3972/8000] D loss: 0.0344, G loss: 9.9982\n",
      "[4332/8000] D loss: 0.1811, G loss: 10.5633\n",
      "[4692/8000] D loss: 0.2224, G loss: 6.5564\n",
      "[5052/8000] D loss: 0.0623, G loss: 9.1053\n",
      "[5412/8000] D loss: 0.0544, G loss: 6.2721\n",
      "[5772/8000] D loss: 0.0927, G loss: 8.7314\n",
      "[6132/8000] D loss: 0.2915, G loss: 5.1061\n",
      "[6492/8000] D loss: 0.0409, G loss: 6.5113\n",
      "[6852/8000] D loss: 0.1563, G loss: 6.5544\n",
      "[7212/8000] D loss: 0.0109, G loss: 6.8173\n",
      "[7572/8000] D loss: 0.1242, G loss: 6.4330\n",
      "[7932/8000] D loss: 0.0810, G loss: 7.8062\n",
      "train error: \n",
      " D loss: 0.156589, G loss: 7.624217, D accuracy: 96.8%, cell accuracy: 91.3%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.204338, G loss: 8.625377, D accuracy: 96.7%, cell accuracy: 91.1%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0885, G loss: 9.1864\n",
      "[372/8000] D loss: 0.7416, G loss: 6.6139\n",
      "[732/8000] D loss: 0.1084, G loss: 7.0872\n",
      "[1092/8000] D loss: 0.0992, G loss: 7.5837\n",
      "[1452/8000] D loss: 0.1047, G loss: 9.1683\n",
      "[1812/8000] D loss: 0.1829, G loss: 8.0446\n",
      "[2172/8000] D loss: 0.0428, G loss: 8.2045\n",
      "[2532/8000] D loss: 0.1285, G loss: 8.1583\n",
      "[2892/8000] D loss: 0.3829, G loss: 7.1831\n",
      "[3252/8000] D loss: 0.4471, G loss: 5.8204\n",
      "[3612/8000] D loss: 0.2263, G loss: 7.9692\n",
      "[3972/8000] D loss: 0.0091, G loss: 7.7561\n",
      "[4332/8000] D loss: 0.1873, G loss: 8.8301\n",
      "[4692/8000] D loss: 0.0973, G loss: 6.1552\n",
      "[5052/8000] D loss: 0.0251, G loss: 6.5583\n",
      "[5412/8000] D loss: 0.2971, G loss: 6.5121\n",
      "[5772/8000] D loss: 0.0056, G loss: 10.1860\n",
      "[6132/8000] D loss: 0.1830, G loss: 6.2542\n",
      "[6492/8000] D loss: 0.0576, G loss: 7.1413\n",
      "[6852/8000] D loss: 0.2181, G loss: 6.3358\n",
      "[7212/8000] D loss: 0.0031, G loss: 8.3430\n",
      "[7572/8000] D loss: 0.3290, G loss: 6.2072\n",
      "[7932/8000] D loss: 0.2891, G loss: 4.9074\n",
      "train error: \n",
      " D loss: 0.160769, G loss: 8.627578, D accuracy: 96.6%, cell accuracy: 91.1%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.271908, G loss: 9.423066, D accuracy: 94.6%, cell accuracy: 90.9%, board accuracy: 0.3% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1642, G loss: 8.1806\n",
      "[372/8000] D loss: 0.0118, G loss: 8.5942\n",
      "[732/8000] D loss: 0.1362, G loss: 8.9884\n",
      "[1092/8000] D loss: 0.0122, G loss: 9.0695\n",
      "[1452/8000] D loss: 0.4365, G loss: 7.5440\n",
      "[1812/8000] D loss: 0.0524, G loss: 7.1532\n",
      "[2172/8000] D loss: 0.0430, G loss: 8.0230\n",
      "[2532/8000] D loss: 0.1128, G loss: 6.5644\n",
      "[2892/8000] D loss: 0.2166, G loss: 10.2824\n",
      "[3252/8000] D loss: 0.0087, G loss: 8.3189\n",
      "[3612/8000] D loss: 0.2634, G loss: 7.6487\n",
      "[3972/8000] D loss: 0.0375, G loss: 7.6807\n",
      "[4332/8000] D loss: 0.1412, G loss: 7.3596\n",
      "[4692/8000] D loss: 0.1187, G loss: 8.0296\n",
      "[5052/8000] D loss: 0.1488, G loss: 8.4145\n",
      "[5412/8000] D loss: 0.3825, G loss: 8.5633\n",
      "[5772/8000] D loss: 0.1286, G loss: 8.4177\n",
      "[6132/8000] D loss: 0.0077, G loss: 10.0755\n",
      "[6492/8000] D loss: 0.0176, G loss: 6.4127\n",
      "[6852/8000] D loss: 0.0192, G loss: 9.5641\n",
      "[7212/8000] D loss: 0.0321, G loss: 9.0180\n",
      "[7572/8000] D loss: 0.2754, G loss: 5.7981\n",
      "[7932/8000] D loss: 0.2859, G loss: 6.7099\n",
      "train error: \n",
      " D loss: 0.118448, G loss: 8.236846, D accuracy: 97.7%, cell accuracy: 91.2%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.205074, G loss: 9.179853, D accuracy: 96.5%, cell accuracy: 90.9%, board accuracy: 0.3% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0346, G loss: 8.0859\n",
      "[372/8000] D loss: 0.1052, G loss: 9.5852\n",
      "[732/8000] D loss: 0.0971, G loss: 7.5689\n",
      "[1092/8000] D loss: 0.1083, G loss: 9.1291\n",
      "[1452/8000] D loss: 0.1436, G loss: 5.6441\n",
      "[1812/8000] D loss: 0.2916, G loss: 7.6084\n",
      "[2172/8000] D loss: 0.1595, G loss: 8.9852\n",
      "[2532/8000] D loss: 0.0350, G loss: 9.9149\n",
      "[2892/8000] D loss: 0.0299, G loss: 9.8068\n",
      "[3252/8000] D loss: 0.0248, G loss: 8.1728\n",
      "[3612/8000] D loss: 0.0403, G loss: 5.9798\n",
      "[3972/8000] D loss: 0.1420, G loss: 8.7525\n",
      "[4332/8000] D loss: 0.0178, G loss: 8.9120\n",
      "[4692/8000] D loss: 0.1059, G loss: 5.9789\n",
      "[5052/8000] D loss: 0.3528, G loss: 7.0321\n",
      "[5412/8000] D loss: 0.0926, G loss: 9.3381\n",
      "[5772/8000] D loss: 0.0042, G loss: 8.9942\n",
      "[6132/8000] D loss: 0.0701, G loss: 6.3930\n",
      "[6492/8000] D loss: 0.8786, G loss: 4.5475\n",
      "[6852/8000] D loss: 0.1389, G loss: 6.5022\n",
      "[7212/8000] D loss: 0.3519, G loss: 7.9911\n",
      "[7572/8000] D loss: 0.3887, G loss: 6.7080\n",
      "[7932/8000] D loss: 0.0264, G loss: 9.3077\n",
      "train error: \n",
      " D loss: 0.139384, G loss: 7.702847, D accuracy: 97.1%, cell accuracy: 91.2%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.198077, G loss: 8.606126, D accuracy: 96.7%, cell accuracy: 91.0%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1814, G loss: 6.9604\n",
      "[372/8000] D loss: 0.0653, G loss: 12.1523\n",
      "[732/8000] D loss: 0.0116, G loss: 8.8357\n",
      "[1092/8000] D loss: 0.0817, G loss: 10.4782\n",
      "[1452/8000] D loss: 0.0548, G loss: 7.9862\n",
      "[1812/8000] D loss: 0.0088, G loss: 7.7684\n",
      "[2172/8000] D loss: 0.1321, G loss: 7.0083\n",
      "[2532/8000] D loss: 0.0360, G loss: 9.1487\n",
      "[2892/8000] D loss: 0.1545, G loss: 5.9329\n",
      "[3252/8000] D loss: 0.1815, G loss: 8.0437\n",
      "[3612/8000] D loss: 0.0038, G loss: 8.9393\n",
      "[3972/8000] D loss: 0.2577, G loss: 7.6424\n",
      "[4332/8000] D loss: 0.1082, G loss: 9.9828\n",
      "[4692/8000] D loss: 0.0606, G loss: 7.8470\n",
      "[5052/8000] D loss: 0.1475, G loss: 10.0023\n",
      "[5412/8000] D loss: 0.0918, G loss: 8.9385\n",
      "[5772/8000] D loss: 0.0359, G loss: 8.2136\n",
      "[6132/8000] D loss: 0.0677, G loss: 8.0102\n",
      "[6492/8000] D loss: 0.1075, G loss: 6.9265\n",
      "[6852/8000] D loss: 0.1500, G loss: 8.5888\n",
      "[7212/8000] D loss: 0.4468, G loss: 7.1635\n",
      "[7572/8000] D loss: 0.0725, G loss: 7.4954\n",
      "[7932/8000] D loss: 0.1550, G loss: 6.2441\n",
      "train error: \n",
      " D loss: 0.152848, G loss: 6.664700, D accuracy: 96.9%, cell accuracy: 91.1%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.196803, G loss: 7.543171, D accuracy: 96.3%, cell accuracy: 90.8%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2199, G loss: 5.8218\n",
      "[372/8000] D loss: 0.0796, G loss: 7.8692\n",
      "[732/8000] D loss: 0.1382, G loss: 6.8787\n",
      "[1092/8000] D loss: 0.3565, G loss: 7.1747\n",
      "[1452/8000] D loss: 0.1120, G loss: 6.4049\n",
      "[1812/8000] D loss: 0.0773, G loss: 9.4448\n",
      "[2172/8000] D loss: 0.1950, G loss: 8.5434\n",
      "[2532/8000] D loss: 0.1007, G loss: 7.2418\n",
      "[2892/8000] D loss: 0.0108, G loss: 8.0318\n",
      "[3252/8000] D loss: 0.1182, G loss: 9.5499\n",
      "[3612/8000] D loss: 0.1793, G loss: 5.2956\n",
      "[3972/8000] D loss: 0.0276, G loss: 6.3804\n",
      "[4332/8000] D loss: 0.1445, G loss: 7.2227\n",
      "[4692/8000] D loss: 0.0830, G loss: 6.1821\n",
      "[5052/8000] D loss: 0.3412, G loss: 7.2954\n",
      "[5412/8000] D loss: 0.2464, G loss: 7.1114\n",
      "[5772/8000] D loss: 0.2498, G loss: 5.3371\n",
      "[6132/8000] D loss: 0.1258, G loss: 7.6295\n",
      "[6492/8000] D loss: 0.1686, G loss: 4.4693\n",
      "[6852/8000] D loss: 0.3119, G loss: 7.1242\n",
      "[7212/8000] D loss: 0.3450, G loss: 5.9161\n",
      "[7572/8000] D loss: 0.1468, G loss: 5.7069\n",
      "[7932/8000] D loss: 0.0398, G loss: 9.0619\n",
      "train error: \n",
      " D loss: 0.184834, G loss: 6.352356, D accuracy: 96.0%, cell accuracy: 91.2%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.209804, G loss: 7.176571, D accuracy: 96.0%, cell accuracy: 90.9%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4147, G loss: 6.5369\n",
      "[372/8000] D loss: 0.3464, G loss: 7.2341\n",
      "[732/8000] D loss: 0.1070, G loss: 7.6034\n",
      "[1092/8000] D loss: 0.0251, G loss: 8.3658\n",
      "[1452/8000] D loss: 0.1024, G loss: 8.4348\n",
      "[1812/8000] D loss: 0.5735, G loss: 6.3615\n",
      "[2172/8000] D loss: 0.4753, G loss: 7.1446\n",
      "[2532/8000] D loss: 0.0731, G loss: 7.2018\n",
      "[2892/8000] D loss: 0.1153, G loss: 7.6100\n",
      "[3252/8000] D loss: 0.1349, G loss: 10.4906\n",
      "[3612/8000] D loss: 0.0563, G loss: 7.1153\n",
      "[3972/8000] D loss: 0.1559, G loss: 8.7121\n",
      "[4332/8000] D loss: 0.3781, G loss: 7.9981\n",
      "[4692/8000] D loss: 0.4991, G loss: 9.4267\n",
      "[5052/8000] D loss: 0.4790, G loss: 6.0714\n",
      "[5412/8000] D loss: 0.1404, G loss: 9.1452\n",
      "[5772/8000] D loss: 0.1234, G loss: 7.0111\n",
      "[6132/8000] D loss: 0.2714, G loss: 6.4462\n",
      "[6492/8000] D loss: 0.1970, G loss: 8.7201\n",
      "[6852/8000] D loss: 0.2350, G loss: 9.5728\n",
      "[7212/8000] D loss: 0.0701, G loss: 9.7804\n",
      "[7572/8000] D loss: 0.1458, G loss: 6.3662\n",
      "[7932/8000] D loss: 0.2582, G loss: 6.6821\n",
      "train error: \n",
      " D loss: 0.158670, G loss: 6.628209, D accuracy: 96.7%, cell accuracy: 91.1%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.211139, G loss: 7.405104, D accuracy: 95.8%, cell accuracy: 90.9%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0393, G loss: 6.4145\n",
      "[372/8000] D loss: 0.1486, G loss: 6.3503\n",
      "[732/8000] D loss: 0.1117, G loss: 8.8923\n",
      "[1092/8000] D loss: 0.0579, G loss: 9.1042\n",
      "[1452/8000] D loss: 0.0310, G loss: 8.6161\n",
      "[1812/8000] D loss: 0.2740, G loss: 6.4333\n",
      "[2172/8000] D loss: 0.1008, G loss: 8.4470\n",
      "[2532/8000] D loss: 0.0877, G loss: 9.1974\n",
      "[2892/8000] D loss: 0.0230, G loss: 7.7766\n",
      "[3252/8000] D loss: 0.1849, G loss: 7.7679\n",
      "[3612/8000] D loss: 0.2796, G loss: 8.0236\n",
      "[3972/8000] D loss: 0.0056, G loss: 6.9157\n",
      "[4332/8000] D loss: 0.1020, G loss: 8.2248\n",
      "[4692/8000] D loss: 0.2049, G loss: 6.2269\n",
      "[5052/8000] D loss: 0.3257, G loss: 7.3359\n",
      "[5412/8000] D loss: 0.1913, G loss: 6.5095\n",
      "[5772/8000] D loss: 0.1449, G loss: 5.7579\n",
      "[6132/8000] D loss: 0.3158, G loss: 4.1266\n",
      "[6492/8000] D loss: 0.2055, G loss: 7.9480\n",
      "[6852/8000] D loss: 0.3553, G loss: 7.4336\n",
      "[7212/8000] D loss: 0.2072, G loss: 8.4639\n",
      "[7572/8000] D loss: 0.0128, G loss: 9.3991\n",
      "[7932/8000] D loss: 0.2826, G loss: 6.7343\n",
      "train error: \n",
      " D loss: 0.140042, G loss: 7.174838, D accuracy: 97.3%, cell accuracy: 91.1%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.187141, G loss: 8.160359, D accuracy: 96.5%, cell accuracy: 90.9%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2233, G loss: 7.1199\n",
      "[372/8000] D loss: 0.1118, G loss: 7.3481\n",
      "[732/8000] D loss: 0.2231, G loss: 5.2009\n",
      "[1092/8000] D loss: 0.1080, G loss: 6.4656\n",
      "[1452/8000] D loss: 0.2107, G loss: 6.2536\n",
      "[1812/8000] D loss: 0.1899, G loss: 6.8354\n",
      "[2172/8000] D loss: 0.0154, G loss: 8.2667\n",
      "[2532/8000] D loss: 0.0647, G loss: 6.5672\n",
      "[2892/8000] D loss: 0.3489, G loss: 7.0384\n",
      "[3252/8000] D loss: 0.0232, G loss: 8.6849\n",
      "[3612/8000] D loss: 0.0207, G loss: 8.3264\n",
      "[3972/8000] D loss: 0.0385, G loss: 10.1504\n",
      "[4332/8000] D loss: 0.1201, G loss: 7.9989\n",
      "[4692/8000] D loss: 0.3384, G loss: 4.9491\n",
      "[5052/8000] D loss: 0.3190, G loss: 9.0531\n",
      "[5412/8000] D loss: 0.0025, G loss: 8.2721\n",
      "[5772/8000] D loss: 0.0797, G loss: 9.0526\n",
      "[6132/8000] D loss: 0.1909, G loss: 6.5658\n",
      "[6492/8000] D loss: 0.1314, G loss: 7.4381\n",
      "[6852/8000] D loss: 0.1682, G loss: 6.5541\n",
      "[7212/8000] D loss: 0.4062, G loss: 4.2089\n",
      "[7572/8000] D loss: 0.1412, G loss: 6.4930\n",
      "[7932/8000] D loss: 0.2986, G loss: 6.3014\n",
      "train error: \n",
      " D loss: 0.147918, G loss: 7.958671, D accuracy: 96.8%, cell accuracy: 91.1%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.235629, G loss: 8.778875, D accuracy: 95.7%, cell accuracy: 90.8%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0053, G loss: 9.3837\n",
      "[372/8000] D loss: 0.2995, G loss: 7.6554\n",
      "[732/8000] D loss: 0.3970, G loss: 7.0660\n",
      "[1092/8000] D loss: 0.1109, G loss: 7.9772\n",
      "[1452/8000] D loss: 0.2502, G loss: 8.4631\n",
      "[1812/8000] D loss: 0.1653, G loss: 8.4211\n",
      "[2172/8000] D loss: 0.2255, G loss: 4.3760\n",
      "[2532/8000] D loss: 0.0219, G loss: 6.9442\n",
      "[2892/8000] D loss: 0.1721, G loss: 8.6222\n",
      "[3252/8000] D loss: 0.0643, G loss: 8.9456\n",
      "[3612/8000] D loss: 0.0145, G loss: 10.1130\n",
      "[3972/8000] D loss: 0.0083, G loss: 6.5292\n",
      "[4332/8000] D loss: 0.0886, G loss: 6.8019\n",
      "[4692/8000] D loss: 0.0629, G loss: 9.1230\n",
      "[5052/8000] D loss: 0.0138, G loss: 8.8173\n",
      "[5412/8000] D loss: 0.1036, G loss: 6.7234\n",
      "[5772/8000] D loss: 0.1733, G loss: 7.1541\n",
      "[6132/8000] D loss: 0.2610, G loss: 7.6778\n",
      "[6492/8000] D loss: 0.0247, G loss: 6.8773\n",
      "[6852/8000] D loss: 0.1680, G loss: 8.3385\n",
      "[7212/8000] D loss: 0.3632, G loss: 9.1321\n",
      "[7572/8000] D loss: 0.5299, G loss: 7.1786\n",
      "[7932/8000] D loss: 0.1090, G loss: 9.1992\n",
      "train error: \n",
      " D loss: 0.177078, G loss: 8.457095, D accuracy: 96.3%, cell accuracy: 91.1%, board accuracy: 1.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.265063, G loss: 9.398045, D accuracy: 95.1%, cell accuracy: 90.9%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0399, G loss: 6.5092\n",
      "[372/8000] D loss: 0.0519, G loss: 11.6273\n",
      "[732/8000] D loss: 0.3528, G loss: 8.0282\n",
      "[1092/8000] D loss: 0.1149, G loss: 8.9874\n",
      "[1452/8000] D loss: 0.0027, G loss: 7.9816\n",
      "[1812/8000] D loss: 0.0325, G loss: 9.3180\n",
      "[2172/8000] D loss: 0.2544, G loss: 6.9345\n",
      "[2532/8000] D loss: 0.2948, G loss: 8.2446\n",
      "[2892/8000] D loss: 0.0397, G loss: 7.7464\n",
      "[3252/8000] D loss: 0.2721, G loss: 9.6928\n",
      "[3612/8000] D loss: 0.1413, G loss: 6.0860\n",
      "[3972/8000] D loss: 0.0239, G loss: 7.2717\n",
      "[4332/8000] D loss: 0.2771, G loss: 7.8129\n",
      "[4692/8000] D loss: 0.1628, G loss: 5.7391\n",
      "[5052/8000] D loss: 0.3528, G loss: 6.4560\n",
      "[5412/8000] D loss: 0.2067, G loss: 8.8670\n",
      "[5772/8000] D loss: 0.1197, G loss: 7.9950\n",
      "[6132/8000] D loss: 0.0887, G loss: 8.9234\n",
      "[6492/8000] D loss: 0.1386, G loss: 10.2317\n",
      "[6852/8000] D loss: 0.0681, G loss: 7.5279\n",
      "[7212/8000] D loss: 0.0197, G loss: 7.0522\n",
      "[7572/8000] D loss: 0.1309, G loss: 7.7503\n",
      "[7932/8000] D loss: 0.0611, G loss: 6.6594\n",
      "train error: \n",
      " D loss: 0.162161, G loss: 6.709407, D accuracy: 96.6%, cell accuracy: 91.3%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.180452, G loss: 7.666561, D accuracy: 96.4%, cell accuracy: 91.1%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4750, G loss: 7.3431\n",
      "[372/8000] D loss: 0.2876, G loss: 5.3654\n",
      "[732/8000] D loss: 0.4018, G loss: 8.6716\n",
      "[1092/8000] D loss: 0.1797, G loss: 8.6743\n",
      "[1452/8000] D loss: 0.1100, G loss: 6.8884\n",
      "[1812/8000] D loss: 0.2596, G loss: 5.3963\n",
      "[2172/8000] D loss: 0.1088, G loss: 8.7495\n",
      "[2532/8000] D loss: 0.1226, G loss: 6.9710\n",
      "[2892/8000] D loss: 0.0169, G loss: 7.7889\n",
      "[3252/8000] D loss: 0.1886, G loss: 7.7460\n",
      "[3612/8000] D loss: 0.0316, G loss: 8.4248\n",
      "[3972/8000] D loss: 0.4764, G loss: 5.8286\n",
      "[4332/8000] D loss: 0.1498, G loss: 7.4475\n",
      "[4692/8000] D loss: 0.2458, G loss: 8.5466\n",
      "[5052/8000] D loss: 0.2893, G loss: 8.7950\n",
      "[5412/8000] D loss: 0.1104, G loss: 10.9271\n",
      "[5772/8000] D loss: 0.1475, G loss: 6.2217\n",
      "[6132/8000] D loss: 0.3344, G loss: 7.8876\n",
      "[6492/8000] D loss: 0.4043, G loss: 7.7704\n",
      "[6852/8000] D loss: 0.0381, G loss: 8.8386\n",
      "[7212/8000] D loss: 0.2438, G loss: 9.7515\n",
      "[7572/8000] D loss: 0.1122, G loss: 8.6498\n",
      "[7932/8000] D loss: 0.0357, G loss: 9.2496\n",
      "train error: \n",
      " D loss: 0.137519, G loss: 7.568358, D accuracy: 97.0%, cell accuracy: 91.1%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.189558, G loss: 8.546066, D accuracy: 96.4%, cell accuracy: 90.9%, board accuracy: 0.3% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1059, G loss: 9.1881\n",
      "[372/8000] D loss: 0.0389, G loss: 9.1062\n",
      "[732/8000] D loss: 0.0351, G loss: 9.1288\n",
      "[1092/8000] D loss: 0.0215, G loss: 9.3935\n",
      "[1452/8000] D loss: 0.3266, G loss: 7.7351\n",
      "[1812/8000] D loss: 0.0162, G loss: 7.8966\n",
      "[2172/8000] D loss: 0.0228, G loss: 10.2200\n",
      "[2532/8000] D loss: 0.1287, G loss: 6.7953\n",
      "[2892/8000] D loss: 0.0887, G loss: 6.4480\n",
      "[3252/8000] D loss: 0.1747, G loss: 6.5489\n",
      "[3612/8000] D loss: 0.1107, G loss: 7.6550\n",
      "[3972/8000] D loss: 0.2970, G loss: 7.2301\n",
      "[4332/8000] D loss: 0.0444, G loss: 8.6015\n",
      "[4692/8000] D loss: 0.1422, G loss: 7.8906\n",
      "[5052/8000] D loss: 0.0792, G loss: 8.5696\n",
      "[5412/8000] D loss: 0.0877, G loss: 8.9621\n",
      "[5772/8000] D loss: 0.0644, G loss: 8.0639\n",
      "[6132/8000] D loss: 0.0916, G loss: 8.2977\n",
      "[6492/8000] D loss: 0.0202, G loss: 7.0170\n",
      "[6852/8000] D loss: 0.3906, G loss: 9.2729\n",
      "[7212/8000] D loss: 0.1031, G loss: 7.2328\n",
      "[7572/8000] D loss: 0.2235, G loss: 8.0663\n",
      "[7932/8000] D loss: 0.0387, G loss: 10.1105\n",
      "train error: \n",
      " D loss: 0.140299, G loss: 8.594305, D accuracy: 97.0%, cell accuracy: 90.9%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.229476, G loss: 9.590174, D accuracy: 95.9%, cell accuracy: 90.7%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3622, G loss: 9.2808\n",
      "[372/8000] D loss: 0.0992, G loss: 10.6284\n",
      "[732/8000] D loss: 0.1356, G loss: 8.0422\n",
      "[1092/8000] D loss: 0.3262, G loss: 8.1212\n",
      "[1452/8000] D loss: 0.0600, G loss: 9.2551\n",
      "[1812/8000] D loss: 0.5899, G loss: 6.1045\n",
      "[2172/8000] D loss: 0.3477, G loss: 7.0480\n",
      "[2532/8000] D loss: 0.0071, G loss: 8.5148\n",
      "[2892/8000] D loss: 0.0260, G loss: 7.8551\n",
      "[3252/8000] D loss: 0.1875, G loss: 7.9358\n",
      "[3612/8000] D loss: 0.0013, G loss: 9.2429\n",
      "[3972/8000] D loss: 0.1609, G loss: 6.2214\n",
      "[4332/8000] D loss: 0.0085, G loss: 8.2898\n",
      "[4692/8000] D loss: 0.0750, G loss: 7.5514\n",
      "[5052/8000] D loss: 0.0581, G loss: 5.7536\n",
      "[5412/8000] D loss: 0.0658, G loss: 7.6093\n",
      "[5772/8000] D loss: 0.1080, G loss: 7.9673\n",
      "[6132/8000] D loss: 0.0308, G loss: 8.4541\n",
      "[6492/8000] D loss: 0.3073, G loss: 5.1497\n",
      "[6852/8000] D loss: 0.3058, G loss: 8.4359\n",
      "[7212/8000] D loss: 0.5130, G loss: 8.5692\n",
      "[7572/8000] D loss: 0.1834, G loss: 4.0710\n",
      "[7932/8000] D loss: 0.1236, G loss: 8.2894\n",
      "train error: \n",
      " D loss: 0.141068, G loss: 7.661808, D accuracy: 97.1%, cell accuracy: 91.2%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.199160, G loss: 8.744953, D accuracy: 96.5%, cell accuracy: 90.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0606, G loss: 7.5043\n",
      "[372/8000] D loss: 0.1949, G loss: 8.3198\n",
      "[732/8000] D loss: 0.0684, G loss: 8.2053\n",
      "[1092/8000] D loss: 0.0221, G loss: 11.6819\n",
      "[1452/8000] D loss: 0.0749, G loss: 3.7180\n",
      "[1812/8000] D loss: 0.1647, G loss: 6.3058\n",
      "[2172/8000] D loss: 0.0422, G loss: 7.0444\n",
      "[2532/8000] D loss: 0.0399, G loss: 9.0356\n",
      "[2892/8000] D loss: 0.0957, G loss: 7.0342\n",
      "[3252/8000] D loss: 0.2060, G loss: 8.5310\n",
      "[3612/8000] D loss: 0.1210, G loss: 9.4598\n",
      "[3972/8000] D loss: 0.2524, G loss: 9.1047\n",
      "[4332/8000] D loss: 0.0636, G loss: 6.7875\n",
      "[4692/8000] D loss: 0.1488, G loss: 10.1476\n",
      "[5052/8000] D loss: 0.1303, G loss: 9.1873\n",
      "[5412/8000] D loss: 0.0486, G loss: 7.6082\n",
      "[5772/8000] D loss: 0.0489, G loss: 7.3463\n",
      "[6132/8000] D loss: 0.1010, G loss: 7.7731\n",
      "[6492/8000] D loss: 0.1197, G loss: 6.3545\n",
      "[6852/8000] D loss: 0.1677, G loss: 5.7601\n",
      "[7212/8000] D loss: 0.2871, G loss: 6.8410\n",
      "[7572/8000] D loss: 0.4272, G loss: 5.7884\n",
      "[7932/8000] D loss: 0.1117, G loss: 8.3944\n",
      "train error: \n",
      " D loss: 0.142822, G loss: 7.138088, D accuracy: 97.1%, cell accuracy: 91.3%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.211022, G loss: 8.091277, D accuracy: 96.1%, cell accuracy: 91.0%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0706, G loss: 6.7206\n",
      "[372/8000] D loss: 0.1089, G loss: 7.1707\n",
      "[732/8000] D loss: 0.0699, G loss: 8.5325\n",
      "[1092/8000] D loss: 0.2687, G loss: 8.1547\n",
      "[1452/8000] D loss: 0.2359, G loss: 9.2280\n",
      "[1812/8000] D loss: 0.0319, G loss: 8.0780\n",
      "[2172/8000] D loss: 0.5396, G loss: 6.9031\n",
      "[2532/8000] D loss: 0.2187, G loss: 8.0755\n",
      "[2892/8000] D loss: 0.1827, G loss: 6.8517\n",
      "[3252/8000] D loss: 0.0589, G loss: 9.3669\n",
      "[3612/8000] D loss: 0.1107, G loss: 7.4364\n",
      "[3972/8000] D loss: 0.0451, G loss: 8.8102\n",
      "[4332/8000] D loss: 0.1590, G loss: 7.2040\n",
      "[4692/8000] D loss: 0.0013, G loss: 10.4067\n",
      "[5052/8000] D loss: 0.1428, G loss: 7.2398\n",
      "[5412/8000] D loss: 0.0318, G loss: 9.4088\n",
      "[5772/8000] D loss: 0.1163, G loss: 9.0743\n",
      "[6132/8000] D loss: 0.0832, G loss: 8.1577\n",
      "[6492/8000] D loss: 0.2114, G loss: 8.7855\n",
      "[6852/8000] D loss: 0.1092, G loss: 7.3019\n",
      "[7212/8000] D loss: 0.0388, G loss: 11.7845\n",
      "[7572/8000] D loss: 0.2927, G loss: 4.7987\n",
      "[7932/8000] D loss: 0.3070, G loss: 4.1597\n",
      "train error: \n",
      " D loss: 0.166779, G loss: 8.207575, D accuracy: 96.5%, cell accuracy: 91.3%, board accuracy: 1.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.218908, G loss: 9.187582, D accuracy: 96.1%, cell accuracy: 91.1%, board accuracy: 0.6% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0421, G loss: 8.7946\n",
      "[372/8000] D loss: 0.0180, G loss: 8.6740\n",
      "[732/8000] D loss: 0.5798, G loss: 7.5112\n",
      "[1092/8000] D loss: 0.1235, G loss: 7.3347\n",
      "[1452/8000] D loss: 0.1555, G loss: 8.2866\n",
      "[1812/8000] D loss: 0.1052, G loss: 9.1636\n",
      "[2172/8000] D loss: 0.0995, G loss: 9.2779\n",
      "[2532/8000] D loss: 0.2434, G loss: 10.4473\n",
      "[2892/8000] D loss: 0.0122, G loss: 9.9464\n",
      "[3252/8000] D loss: 0.0739, G loss: 6.8485\n",
      "[3612/8000] D loss: 0.1358, G loss: 6.4545\n",
      "[3972/8000] D loss: 0.1472, G loss: 9.4392\n",
      "[4332/8000] D loss: 0.2902, G loss: 6.9801\n",
      "[4692/8000] D loss: 0.0516, G loss: 7.9857\n",
      "[5052/8000] D loss: 0.0615, G loss: 7.9902\n",
      "[5412/8000] D loss: 0.0882, G loss: 8.7361\n",
      "[5772/8000] D loss: 0.4143, G loss: 6.2534\n",
      "[6132/8000] D loss: 0.0133, G loss: 8.5641\n",
      "[6492/8000] D loss: 0.0357, G loss: 7.2450\n",
      "[6852/8000] D loss: 0.0300, G loss: 9.3388\n",
      "[7212/8000] D loss: 0.2791, G loss: 6.9529\n",
      "[7572/8000] D loss: 0.1105, G loss: 7.5774\n",
      "[7932/8000] D loss: 0.1734, G loss: 6.0729\n",
      "train error: \n",
      " D loss: 0.189675, G loss: 7.231710, D accuracy: 96.1%, cell accuracy: 91.3%, board accuracy: 1.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.247944, G loss: 8.382317, D accuracy: 95.4%, cell accuracy: 91.1%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0501, G loss: 7.6122\n",
      "[372/8000] D loss: 0.2086, G loss: 10.4955\n",
      "[732/8000] D loss: 0.0894, G loss: 7.3042\n",
      "[1092/8000] D loss: 0.1623, G loss: 8.2472\n",
      "[1452/8000] D loss: 0.4095, G loss: 5.1720\n",
      "[1812/8000] D loss: 0.0162, G loss: 10.5388\n",
      "[2172/8000] D loss: 0.0165, G loss: 6.9658\n",
      "[2532/8000] D loss: 0.0757, G loss: 7.7238\n",
      "[2892/8000] D loss: 0.0069, G loss: 8.8950\n",
      "[3252/8000] D loss: 0.2968, G loss: 6.4546\n",
      "[3612/8000] D loss: 0.0375, G loss: 7.6727\n",
      "[3972/8000] D loss: 0.2113, G loss: 7.1140\n",
      "[4332/8000] D loss: 0.4240, G loss: 5.6358\n",
      "[4692/8000] D loss: 0.0468, G loss: 8.5287\n",
      "[5052/8000] D loss: 0.2410, G loss: 7.7395\n",
      "[5412/8000] D loss: 0.0186, G loss: 11.1496\n",
      "[5772/8000] D loss: 0.1806, G loss: 9.2517\n",
      "[6132/8000] D loss: 0.0283, G loss: 8.5071\n",
      "[6492/8000] D loss: 0.0011, G loss: 10.2180\n",
      "[6852/8000] D loss: 0.1919, G loss: 3.9295\n",
      "[7212/8000] D loss: 0.1653, G loss: 9.4236\n",
      "[7572/8000] D loss: 0.0510, G loss: 7.3991\n",
      "[7932/8000] D loss: 0.0854, G loss: 7.2420\n",
      "train error: \n",
      " D loss: 0.145271, G loss: 7.394346, D accuracy: 97.1%, cell accuracy: 91.5%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.201398, G loss: 8.465344, D accuracy: 96.2%, cell accuracy: 91.2%, board accuracy: 0.4% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1537, G loss: 8.9139\n",
      "[372/8000] D loss: 0.1145, G loss: 7.7697\n",
      "[732/8000] D loss: 0.1199, G loss: 9.3552\n",
      "[1092/8000] D loss: 0.0229, G loss: 10.5013\n",
      "[1452/8000] D loss: 0.4932, G loss: 6.3260\n",
      "[1812/8000] D loss: 0.1603, G loss: 7.9998\n",
      "[2172/8000] D loss: 0.1140, G loss: 6.6539\n",
      "[2532/8000] D loss: 0.0588, G loss: 6.8912\n",
      "[2892/8000] D loss: 0.0533, G loss: 8.0898\n",
      "[3252/8000] D loss: 0.1689, G loss: 6.7436\n",
      "[3612/8000] D loss: 0.1911, G loss: 7.9216\n",
      "[3972/8000] D loss: 0.2007, G loss: 7.6065\n",
      "[4332/8000] D loss: 0.1325, G loss: 9.4334\n",
      "[4692/8000] D loss: 0.3519, G loss: 6.2561\n",
      "[5052/8000] D loss: 0.1307, G loss: 10.2861\n",
      "[5412/8000] D loss: 0.0674, G loss: 9.3071\n",
      "[5772/8000] D loss: 0.0034, G loss: 9.7506\n",
      "[6132/8000] D loss: 0.1526, G loss: 8.4311\n",
      "[6492/8000] D loss: 0.1583, G loss: 6.1486\n",
      "[6852/8000] D loss: 0.5035, G loss: 5.9026\n",
      "[7212/8000] D loss: 0.0414, G loss: 8.3099\n",
      "[7572/8000] D loss: 0.0451, G loss: 9.3678\n",
      "[7932/8000] D loss: 0.1641, G loss: 8.1686\n",
      "train error: \n",
      " D loss: 0.151200, G loss: 7.513339, D accuracy: 96.8%, cell accuracy: 91.5%, board accuracy: 1.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.203881, G loss: 8.538493, D accuracy: 96.3%, cell accuracy: 91.2%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0827, G loss: 6.1265\n",
      "[372/8000] D loss: 0.1034, G loss: 9.7078\n",
      "[732/8000] D loss: 0.1009, G loss: 8.5818\n",
      "[1092/8000] D loss: 0.0312, G loss: 10.6264\n",
      "[1452/8000] D loss: 0.1466, G loss: 9.4008\n",
      "[1812/8000] D loss: 0.0925, G loss: 6.5729\n",
      "[2172/8000] D loss: 0.0038, G loss: 9.7019\n",
      "[2532/8000] D loss: 0.0415, G loss: 10.7651\n",
      "[2892/8000] D loss: 0.0404, G loss: 7.7801\n",
      "[3252/8000] D loss: 0.0290, G loss: 8.6076\n",
      "[3612/8000] D loss: 0.1618, G loss: 8.3030\n",
      "[3972/8000] D loss: 0.2054, G loss: 7.6488\n",
      "[4332/8000] D loss: 0.2427, G loss: 5.6554\n",
      "[4692/8000] D loss: 0.2050, G loss: 6.6149\n",
      "[5052/8000] D loss: 0.0191, G loss: 11.5285\n",
      "[5412/8000] D loss: 0.2527, G loss: 9.0325\n",
      "[5772/8000] D loss: 0.0347, G loss: 6.9578\n",
      "[6132/8000] D loss: 0.0313, G loss: 8.7325\n",
      "[6492/8000] D loss: 0.1364, G loss: 8.4374\n",
      "[6852/8000] D loss: 0.1141, G loss: 7.3463\n",
      "[7212/8000] D loss: 0.0296, G loss: 8.7285\n",
      "[7572/8000] D loss: 0.2223, G loss: 8.8053\n",
      "[7932/8000] D loss: 0.0602, G loss: 12.1581\n",
      "train error: \n",
      " D loss: 0.139152, G loss: 7.670095, D accuracy: 97.0%, cell accuracy: 91.6%, board accuracy: 1.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.193858, G loss: 8.836297, D accuracy: 96.5%, cell accuracy: 91.4%, board accuracy: 0.6% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0179, G loss: 9.0859\n",
      "[372/8000] D loss: 0.1687, G loss: 9.7191\n",
      "[732/8000] D loss: 0.2985, G loss: 9.0294\n",
      "[1092/8000] D loss: 0.1271, G loss: 8.9336\n",
      "[1452/8000] D loss: 0.1039, G loss: 8.2564\n",
      "[1812/8000] D loss: 0.1717, G loss: 8.9452\n",
      "[2172/8000] D loss: 0.0137, G loss: 10.0506\n",
      "[2532/8000] D loss: 0.2918, G loss: 8.9644\n",
      "[2892/8000] D loss: 0.0530, G loss: 10.5007\n",
      "[3252/8000] D loss: 0.0070, G loss: 8.2987\n",
      "[3612/8000] D loss: 0.4610, G loss: 6.1771\n",
      "[3972/8000] D loss: 0.0223, G loss: 7.6620\n",
      "[4332/8000] D loss: 0.0981, G loss: 7.7948\n",
      "[4692/8000] D loss: 0.0306, G loss: 9.7382\n",
      "[5052/8000] D loss: 0.2329, G loss: 6.2612\n",
      "[5412/8000] D loss: 0.3467, G loss: 6.2096\n",
      "[5772/8000] D loss: 0.3093, G loss: 5.6959\n",
      "[6132/8000] D loss: 0.2457, G loss: 6.0660\n",
      "[6492/8000] D loss: 0.2435, G loss: 8.9779\n",
      "[6852/8000] D loss: 0.0084, G loss: 10.5814\n",
      "[7212/8000] D loss: 0.0070, G loss: 10.3287\n",
      "[7572/8000] D loss: 0.3413, G loss: 5.0720\n",
      "[7932/8000] D loss: 0.2365, G loss: 7.6548\n",
      "train error: \n",
      " D loss: 0.136601, G loss: 8.143790, D accuracy: 97.2%, cell accuracy: 91.7%, board accuracy: 1.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.219056, G loss: 9.259351, D accuracy: 96.3%, cell accuracy: 91.5%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0013, G loss: 9.6797\n",
      "[372/8000] D loss: 0.1954, G loss: 7.4063\n",
      "[732/8000] D loss: 0.2815, G loss: 6.3193\n",
      "[1092/8000] D loss: 0.1776, G loss: 9.6354\n",
      "[1452/8000] D loss: 0.0303, G loss: 9.2413\n",
      "[1812/8000] D loss: 0.3224, G loss: 8.7138\n",
      "[2172/8000] D loss: 0.1840, G loss: 7.4455\n",
      "[2532/8000] D loss: 0.1893, G loss: 7.1711\n",
      "[2892/8000] D loss: 0.2583, G loss: 8.5098\n",
      "[3252/8000] D loss: 0.0523, G loss: 8.9739\n",
      "[3612/8000] D loss: 0.5487, G loss: 5.2880\n",
      "[3972/8000] D loss: 0.1193, G loss: 9.8235\n",
      "[4332/8000] D loss: 0.1334, G loss: 10.1699\n",
      "[4692/8000] D loss: 0.0243, G loss: 6.7845\n",
      "[5052/8000] D loss: 0.1408, G loss: 9.0794\n",
      "[5412/8000] D loss: 0.0049, G loss: 8.3051\n",
      "[5772/8000] D loss: 0.2893, G loss: 6.1646\n",
      "[6132/8000] D loss: 0.2714, G loss: 6.5439\n",
      "[6492/8000] D loss: 0.2853, G loss: 9.4879\n",
      "[6852/8000] D loss: 0.0068, G loss: 8.9973\n",
      "[7212/8000] D loss: 0.1973, G loss: 8.0461\n",
      "[7572/8000] D loss: 0.1086, G loss: 7.7086\n",
      "[7932/8000] D loss: 0.1374, G loss: 6.5800\n",
      "train error: \n",
      " D loss: 0.140531, G loss: 8.572290, D accuracy: 97.0%, cell accuracy: 91.7%, board accuracy: 1.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.249914, G loss: 9.623252, D accuracy: 95.5%, cell accuracy: 91.4%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1076, G loss: 7.8864\n",
      "[372/8000] D loss: 0.3387, G loss: 7.6804\n",
      "[732/8000] D loss: 0.4523, G loss: 6.5166\n",
      "[1092/8000] D loss: 0.0921, G loss: 9.0152\n",
      "[1452/8000] D loss: 0.1202, G loss: 6.5600\n",
      "[1812/8000] D loss: 0.3013, G loss: 8.3012\n",
      "[2172/8000] D loss: 0.2348, G loss: 9.4460\n",
      "[2532/8000] D loss: 0.2925, G loss: 6.8717\n",
      "[2892/8000] D loss: 0.0887, G loss: 8.3594\n",
      "[3252/8000] D loss: 0.0249, G loss: 8.1471\n",
      "[3612/8000] D loss: 0.0222, G loss: 9.4766\n",
      "[3972/8000] D loss: 0.1564, G loss: 6.3102\n",
      "[4332/8000] D loss: 0.0929, G loss: 7.6473\n",
      "[4692/8000] D loss: 0.0727, G loss: 9.0995\n",
      "[5052/8000] D loss: 0.1466, G loss: 8.4226\n",
      "[5412/8000] D loss: 0.4107, G loss: 6.2962\n",
      "[5772/8000] D loss: 0.2083, G loss: 8.9038\n",
      "[6132/8000] D loss: 0.0089, G loss: 8.6555\n",
      "[6492/8000] D loss: 0.0672, G loss: 7.5629\n",
      "[6852/8000] D loss: 0.1792, G loss: 8.4870\n",
      "[7212/8000] D loss: 0.1347, G loss: 10.3873\n",
      "[7572/8000] D loss: 0.0990, G loss: 6.4199\n",
      "[7932/8000] D loss: 0.1158, G loss: 8.6421\n",
      "train error: \n",
      " D loss: 0.163940, G loss: 7.044934, D accuracy: 96.6%, cell accuracy: 91.8%, board accuracy: 1.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.199626, G loss: 8.162968, D accuracy: 96.3%, cell accuracy: 91.5%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0172, G loss: 9.0363\n",
      "[372/8000] D loss: 0.0099, G loss: 8.1763\n",
      "[732/8000] D loss: 0.2728, G loss: 4.1687\n",
      "[1092/8000] D loss: 0.0010, G loss: 10.4418\n",
      "[1452/8000] D loss: 0.2945, G loss: 6.5179\n",
      "[1812/8000] D loss: 0.1064, G loss: 6.3109\n",
      "[2172/8000] D loss: 0.1442, G loss: 8.2675\n",
      "[2532/8000] D loss: 0.1630, G loss: 7.9958\n",
      "[2892/8000] D loss: 0.0830, G loss: 8.9658\n",
      "[3252/8000] D loss: 0.0876, G loss: 7.3141\n",
      "[3612/8000] D loss: 0.1178, G loss: 7.7271\n",
      "[3972/8000] D loss: 0.1488, G loss: 8.5488\n",
      "[4332/8000] D loss: 0.0670, G loss: 9.4532\n",
      "[4692/8000] D loss: 0.3232, G loss: 5.2167\n",
      "[5052/8000] D loss: 0.3613, G loss: 7.9596\n",
      "[5412/8000] D loss: 0.1710, G loss: 10.3662\n",
      "[5772/8000] D loss: 0.2734, G loss: 9.3394\n",
      "[6132/8000] D loss: 0.1843, G loss: 6.8438\n",
      "[6492/8000] D loss: 0.0721, G loss: 9.5654\n",
      "[6852/8000] D loss: 0.1070, G loss: 7.4736\n",
      "[7212/8000] D loss: 0.2230, G loss: 8.0021\n",
      "[7572/8000] D loss: 0.0339, G loss: 8.5349\n",
      "[7932/8000] D loss: 0.1337, G loss: 6.3303\n",
      "train error: \n",
      " D loss: 0.349797, G loss: 9.579510, D accuracy: 92.9%, cell accuracy: 91.9%, board accuracy: 1.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.496648, G loss: 10.583526, D accuracy: 91.8%, cell accuracy: 91.6%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0082, G loss: 11.3638\n",
      "[372/8000] D loss: 0.0368, G loss: 7.1184\n",
      "[732/8000] D loss: 0.0604, G loss: 8.3842\n",
      "[1092/8000] D loss: 0.1727, G loss: 9.2375\n",
      "[1452/8000] D loss: 0.1553, G loss: 7.3227\n",
      "[1812/8000] D loss: 0.0252, G loss: 7.6345\n",
      "[2172/8000] D loss: 0.0146, G loss: 8.2848\n",
      "[2532/8000] D loss: 0.1069, G loss: 7.1657\n",
      "[2892/8000] D loss: 0.0340, G loss: 9.6933\n",
      "[3252/8000] D loss: 0.4301, G loss: 6.7933\n",
      "[3612/8000] D loss: 0.3030, G loss: 7.5064\n",
      "[3972/8000] D loss: 0.1265, G loss: 9.9476\n",
      "[4332/8000] D loss: 0.0337, G loss: 6.6741\n",
      "[4692/8000] D loss: 0.1110, G loss: 8.8376\n",
      "[5052/8000] D loss: 0.1213, G loss: 8.0717\n",
      "[5412/8000] D loss: 0.2464, G loss: 9.2904\n",
      "[5772/8000] D loss: 0.0604, G loss: 8.0145\n",
      "[6132/8000] D loss: 0.4686, G loss: 6.4962\n",
      "[6492/8000] D loss: 0.0755, G loss: 9.3336\n",
      "[6852/8000] D loss: 0.1458, G loss: 7.9672\n",
      "[7212/8000] D loss: 0.1167, G loss: 6.8618\n",
      "[7572/8000] D loss: 0.0938, G loss: 6.5399\n",
      "[7932/8000] D loss: 0.1464, G loss: 4.6430\n",
      "train error: \n",
      " D loss: 0.178933, G loss: 6.667227, D accuracy: 96.4%, cell accuracy: 92.0%, board accuracy: 1.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.215446, G loss: 7.782175, D accuracy: 96.0%, cell accuracy: 91.7%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1103, G loss: 7.7118\n",
      "[372/8000] D loss: 0.0812, G loss: 7.9234\n",
      "[732/8000] D loss: 0.2932, G loss: 6.6630\n",
      "[1092/8000] D loss: 0.0137, G loss: 10.3143\n",
      "[1452/8000] D loss: 0.1299, G loss: 7.5540\n",
      "[1812/8000] D loss: 0.0321, G loss: 7.6619\n",
      "[2172/8000] D loss: 0.2203, G loss: 6.6584\n",
      "[2532/8000] D loss: 0.3361, G loss: 7.5382\n",
      "[2892/8000] D loss: 0.1110, G loss: 10.4382\n",
      "[3252/8000] D loss: 0.0456, G loss: 7.5043\n",
      "[3612/8000] D loss: 0.1483, G loss: 9.1204\n",
      "[3972/8000] D loss: 0.3287, G loss: 10.1780\n",
      "[4332/8000] D loss: 0.0573, G loss: 8.9219\n",
      "[4692/8000] D loss: 0.0388, G loss: 8.3224\n",
      "[5052/8000] D loss: 0.0996, G loss: 6.3274\n",
      "[5412/8000] D loss: 0.2061, G loss: 6.1558\n",
      "[5772/8000] D loss: 0.0750, G loss: 7.5741\n",
      "[6132/8000] D loss: 0.2344, G loss: 8.5895\n",
      "[6492/8000] D loss: 0.2226, G loss: 5.0788\n",
      "[6852/8000] D loss: 0.0220, G loss: 8.5283\n",
      "[7212/8000] D loss: 0.2981, G loss: 9.6350\n",
      "[7572/8000] D loss: 0.0871, G loss: 6.7368\n",
      "[7932/8000] D loss: 0.3672, G loss: 8.4418\n",
      "train error: \n",
      " D loss: 0.151117, G loss: 8.757020, D accuracy: 96.8%, cell accuracy: 92.2%, board accuracy: 1.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.259692, G loss: 9.967807, D accuracy: 95.9%, cell accuracy: 92.0%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2622, G loss: 8.5793\n",
      "[372/8000] D loss: 0.0422, G loss: 11.6758\n",
      "[732/8000] D loss: 0.0281, G loss: 10.7269\n",
      "[1092/8000] D loss: 0.5294, G loss: 6.4990\n",
      "[1452/8000] D loss: 0.0111, G loss: 7.9718\n",
      "[1812/8000] D loss: 0.1124, G loss: 7.7732\n",
      "[2172/8000] D loss: 0.0309, G loss: 8.0161\n",
      "[2532/8000] D loss: 0.1858, G loss: 7.4589\n",
      "[2892/8000] D loss: 0.0511, G loss: 6.7701\n",
      "[3252/8000] D loss: 0.1528, G loss: 7.2930\n",
      "[3612/8000] D loss: 0.5506, G loss: 7.8206\n",
      "[3972/8000] D loss: 0.1257, G loss: 4.4868\n",
      "[4332/8000] D loss: 0.0588, G loss: 9.6614\n",
      "[4692/8000] D loss: 0.0530, G loss: 6.6311\n",
      "[5052/8000] D loss: 0.2850, G loss: 5.1698\n",
      "[5412/8000] D loss: 0.2065, G loss: 8.0467\n",
      "[5772/8000] D loss: 0.3572, G loss: 9.0154\n",
      "[6132/8000] D loss: 0.0451, G loss: 9.0001\n",
      "[6492/8000] D loss: 0.1978, G loss: 6.9548\n",
      "[6852/8000] D loss: 0.0076, G loss: 9.2801\n",
      "[7212/8000] D loss: 0.2794, G loss: 7.5134\n",
      "[7572/8000] D loss: 0.0528, G loss: 7.8122\n",
      "[7932/8000] D loss: 0.1267, G loss: 9.8899\n",
      "train error: \n",
      " D loss: 0.176853, G loss: 6.690206, D accuracy: 96.5%, cell accuracy: 92.3%, board accuracy: 1.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.215875, G loss: 7.849203, D accuracy: 95.8%, cell accuracy: 92.0%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0546, G loss: 6.2824\n",
      "[372/8000] D loss: 0.4811, G loss: 7.2247\n",
      "[732/8000] D loss: 0.1890, G loss: 8.5693\n",
      "[1092/8000] D loss: 0.4566, G loss: 7.7070\n",
      "[1452/8000] D loss: 0.0585, G loss: 7.7584\n",
      "[1812/8000] D loss: 0.0620, G loss: 7.4899\n",
      "[2172/8000] D loss: 0.1060, G loss: 7.9534\n",
      "[2532/8000] D loss: 0.4298, G loss: 4.8103\n",
      "[2892/8000] D loss: 0.4654, G loss: 6.4301\n",
      "[3252/8000] D loss: 0.5213, G loss: 10.3023\n",
      "[3612/8000] D loss: 0.0273, G loss: 9.5166\n",
      "[3972/8000] D loss: 0.0475, G loss: 9.6914\n",
      "[4332/8000] D loss: 0.1163, G loss: 6.5033\n",
      "[4692/8000] D loss: 0.0460, G loss: 7.7616\n",
      "[5052/8000] D loss: 0.1932, G loss: 8.7802\n",
      "[5412/8000] D loss: 0.3409, G loss: 6.8698\n",
      "[5772/8000] D loss: 0.0750, G loss: 7.0700\n",
      "[6132/8000] D loss: 0.1495, G loss: 8.5070\n",
      "[6492/8000] D loss: 0.0477, G loss: 7.9790\n",
      "[6852/8000] D loss: 0.1540, G loss: 6.8953\n",
      "[7212/8000] D loss: 0.0915, G loss: 9.2067\n",
      "[7572/8000] D loss: 0.3061, G loss: 7.8380\n",
      "[7932/8000] D loss: 0.1348, G loss: 5.1749\n",
      "train error: \n",
      " D loss: 0.327707, G loss: 5.020052, D accuracy: 92.9%, cell accuracy: 92.3%, board accuracy: 1.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.273506, G loss: 6.184007, D accuracy: 94.9%, cell accuracy: 92.1%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1216, G loss: 5.6393\n",
      "[372/8000] D loss: 0.1347, G loss: 7.5227\n",
      "[732/8000] D loss: 0.0722, G loss: 7.3618\n",
      "[1092/8000] D loss: 0.1246, G loss: 6.5734\n",
      "[1452/8000] D loss: 0.1472, G loss: 5.1352\n",
      "[1812/8000] D loss: 0.3213, G loss: 7.6986\n",
      "[2172/8000] D loss: 0.1042, G loss: 7.8880\n",
      "[2532/8000] D loss: 0.0029, G loss: 8.8556\n",
      "[2892/8000] D loss: 0.2057, G loss: 8.7948\n",
      "[3252/8000] D loss: 0.1924, G loss: 8.1286\n",
      "[3612/8000] D loss: 0.1130, G loss: 6.2074\n",
      "[3972/8000] D loss: 0.0473, G loss: 8.6903\n",
      "[4332/8000] D loss: 0.3988, G loss: 6.0382\n",
      "[4692/8000] D loss: 0.4719, G loss: 6.3632\n",
      "[5052/8000] D loss: 0.2504, G loss: 8.3975\n",
      "[5412/8000] D loss: 0.0957, G loss: 6.2090\n",
      "[5772/8000] D loss: 0.0054, G loss: 7.8375\n",
      "[6132/8000] D loss: 0.0827, G loss: 8.5396\n",
      "[6492/8000] D loss: 0.0262, G loss: 8.1921\n",
      "[6852/8000] D loss: 0.0955, G loss: 6.4396\n",
      "[7212/8000] D loss: 0.2365, G loss: 8.0275\n",
      "[7572/8000] D loss: 0.5296, G loss: 6.2644\n",
      "[7932/8000] D loss: 0.1297, G loss: 7.4553\n",
      "train error: \n",
      " D loss: 0.162475, G loss: 7.161631, D accuracy: 96.5%, cell accuracy: 92.5%, board accuracy: 1.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.232637, G loss: 8.340623, D accuracy: 95.4%, cell accuracy: 92.2%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2280, G loss: 7.6145\n",
      "[372/8000] D loss: 0.0365, G loss: 8.3432\n",
      "[732/8000] D loss: 0.1844, G loss: 5.6521\n",
      "[1092/8000] D loss: 0.1240, G loss: 7.4900\n",
      "[1452/8000] D loss: 0.2586, G loss: 8.3784\n",
      "[1812/8000] D loss: 0.4196, G loss: 6.4740\n",
      "[2172/8000] D loss: 0.2589, G loss: 7.2208\n",
      "[2532/8000] D loss: 0.0215, G loss: 6.7434\n",
      "[2892/8000] D loss: 0.1841, G loss: 7.3463\n",
      "[3252/8000] D loss: 0.0608, G loss: 9.2074\n",
      "[3612/8000] D loss: 0.0836, G loss: 9.0297\n",
      "[3972/8000] D loss: 0.4325, G loss: 5.4907\n",
      "[4332/8000] D loss: 0.2330, G loss: 7.5534\n",
      "[4692/8000] D loss: 0.1628, G loss: 8.9412\n",
      "[5052/8000] D loss: 0.0792, G loss: 7.0174\n",
      "[5412/8000] D loss: 0.2181, G loss: 6.8582\n",
      "[5772/8000] D loss: 0.4170, G loss: 6.5174\n",
      "[6132/8000] D loss: 0.3639, G loss: 7.0003\n",
      "[6492/8000] D loss: 0.0848, G loss: 7.3200\n",
      "[6852/8000] D loss: 0.0605, G loss: 7.0607\n",
      "[7212/8000] D loss: 0.0537, G loss: 9.0188\n",
      "[7572/8000] D loss: 0.1358, G loss: 10.2187\n",
      "[7932/8000] D loss: 0.7479, G loss: 8.7385\n",
      "train error: \n",
      " D loss: 0.228326, G loss: 6.329450, D accuracy: 95.1%, cell accuracy: 92.4%, board accuracy: 1.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.216851, G loss: 7.533651, D accuracy: 95.7%, cell accuracy: 92.2%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5530, G loss: 6.5727\n",
      "[372/8000] D loss: 0.0954, G loss: 7.1938\n",
      "[732/8000] D loss: 0.1797, G loss: 8.5203\n",
      "[1092/8000] D loss: 0.0611, G loss: 8.0655\n",
      "[1452/8000] D loss: 0.4412, G loss: 5.6183\n",
      "[1812/8000] D loss: 0.0320, G loss: 8.7526\n",
      "[2172/8000] D loss: 0.1486, G loss: 7.7598\n",
      "[2532/8000] D loss: 0.0722, G loss: 7.9675\n",
      "[2892/8000] D loss: 0.0204, G loss: 8.0332\n",
      "[3252/8000] D loss: 0.0208, G loss: 12.2815\n",
      "[3612/8000] D loss: 0.2473, G loss: 6.7573\n",
      "[3972/8000] D loss: 0.2253, G loss: 7.6874\n",
      "[4332/8000] D loss: 0.2186, G loss: 6.8117\n",
      "[4692/8000] D loss: 0.0632, G loss: 8.4786\n",
      "[5052/8000] D loss: 0.1996, G loss: 6.8390\n",
      "[5412/8000] D loss: 0.3094, G loss: 9.2079\n",
      "[5772/8000] D loss: 0.1476, G loss: 8.5439\n",
      "[6132/8000] D loss: 0.0534, G loss: 8.0162\n",
      "[6492/8000] D loss: 0.0842, G loss: 9.5048\n",
      "[6852/8000] D loss: 0.1869, G loss: 7.8336\n",
      "[7212/8000] D loss: 0.2098, G loss: 8.7478\n",
      "[7572/8000] D loss: 0.2398, G loss: 6.7965\n",
      "[7932/8000] D loss: 0.0192, G loss: 10.6889\n",
      "train error: \n",
      " D loss: 0.168977, G loss: 7.169040, D accuracy: 96.4%, cell accuracy: 92.4%, board accuracy: 1.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.204055, G loss: 8.482656, D accuracy: 96.0%, cell accuracy: 92.2%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2923, G loss: 6.7149\n",
      "[372/8000] D loss: 0.1530, G loss: 7.9995\n",
      "[732/8000] D loss: 0.2086, G loss: 8.5739\n",
      "[1092/8000] D loss: 0.0411, G loss: 11.2409\n",
      "[1452/8000] D loss: 0.1269, G loss: 9.3166\n",
      "[1812/8000] D loss: 0.0414, G loss: 9.3731\n",
      "[2172/8000] D loss: 0.3914, G loss: 11.2048\n",
      "[2532/8000] D loss: 0.1084, G loss: 7.3824\n",
      "[2892/8000] D loss: 0.3086, G loss: 9.2088\n",
      "[3252/8000] D loss: 0.0197, G loss: 12.6500\n",
      "[3612/8000] D loss: 0.8398, G loss: 4.1409\n",
      "[3972/8000] D loss: 0.2830, G loss: 8.5464\n",
      "[4332/8000] D loss: 0.1428, G loss: 10.3911\n",
      "[4692/8000] D loss: 0.0331, G loss: 7.1246\n",
      "[5052/8000] D loss: 0.4410, G loss: 5.7995\n",
      "[5412/8000] D loss: 0.2538, G loss: 4.8063\n",
      "[5772/8000] D loss: 0.0073, G loss: 7.7403\n",
      "[6132/8000] D loss: 0.2023, G loss: 7.0461\n",
      "[6492/8000] D loss: 0.4257, G loss: 8.2662\n",
      "[6852/8000] D loss: 0.1962, G loss: 6.4664\n",
      "[7212/8000] D loss: 0.0642, G loss: 9.8431\n",
      "[7572/8000] D loss: 0.1983, G loss: 5.1147\n",
      "[7932/8000] D loss: 0.1742, G loss: 9.6186\n",
      "train error: \n",
      " D loss: 0.177729, G loss: 7.123615, D accuracy: 96.2%, cell accuracy: 92.5%, board accuracy: 1.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.202397, G loss: 8.458532, D accuracy: 96.3%, cell accuracy: 92.2%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1640, G loss: 4.7113\n",
      "[372/8000] D loss: 0.4345, G loss: 8.5294\n",
      "[732/8000] D loss: 0.0124, G loss: 7.9979\n",
      "[1092/8000] D loss: 0.3357, G loss: 6.5325\n",
      "[1452/8000] D loss: 0.1475, G loss: 8.4948\n",
      "[1812/8000] D loss: 0.0906, G loss: 9.8753\n",
      "[2172/8000] D loss: 0.0873, G loss: 10.1232\n",
      "[2532/8000] D loss: 0.0047, G loss: 10.5742\n",
      "[2892/8000] D loss: 0.2275, G loss: 10.0555\n",
      "[3252/8000] D loss: 0.4854, G loss: 6.2854\n",
      "[3612/8000] D loss: 0.0815, G loss: 10.5062\n",
      "[3972/8000] D loss: 0.0040, G loss: 10.8501\n",
      "[4332/8000] D loss: 0.3326, G loss: 7.3637\n",
      "[4692/8000] D loss: 0.0765, G loss: 10.2774\n",
      "[5052/8000] D loss: 0.3162, G loss: 9.6141\n",
      "[5412/8000] D loss: 0.2513, G loss: 8.1932\n",
      "[5772/8000] D loss: 0.0037, G loss: 11.2274\n",
      "[6132/8000] D loss: 0.3690, G loss: 7.1621\n",
      "[6492/8000] D loss: 0.3967, G loss: 7.1471\n",
      "[6852/8000] D loss: 0.1248, G loss: 9.6265\n",
      "[7212/8000] D loss: 0.1198, G loss: 9.7423\n",
      "[7572/8000] D loss: 0.2262, G loss: 8.5723\n",
      "[7932/8000] D loss: 0.2857, G loss: 7.6171\n",
      "train error: \n",
      " D loss: 0.169827, G loss: 8.480709, D accuracy: 96.3%, cell accuracy: 92.5%, board accuracy: 2.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.284259, G loss: 9.695418, D accuracy: 95.0%, cell accuracy: 92.3%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0618, G loss: 9.8158\n",
      "[372/8000] D loss: 0.3857, G loss: 6.2453\n",
      "[732/8000] D loss: 0.0843, G loss: 6.4901\n",
      "[1092/8000] D loss: 0.0393, G loss: 6.9840\n",
      "[1452/8000] D loss: 0.1547, G loss: 7.6786\n",
      "[1812/8000] D loss: 0.2812, G loss: 4.6288\n",
      "[2172/8000] D loss: 0.0201, G loss: 8.2798\n",
      "[2532/8000] D loss: 0.2710, G loss: 7.7514\n",
      "[2892/8000] D loss: 0.2337, G loss: 10.1650\n",
      "[3252/8000] D loss: 0.0147, G loss: 7.4918\n",
      "[3612/8000] D loss: 0.0253, G loss: 10.9259\n",
      "[3972/8000] D loss: 0.0717, G loss: 8.2876\n",
      "[4332/8000] D loss: 0.1657, G loss: 9.7918\n",
      "[4692/8000] D loss: 0.0851, G loss: 9.8913\n",
      "[5052/8000] D loss: 0.1018, G loss: 10.1529\n",
      "[5412/8000] D loss: 0.0096, G loss: 9.4486\n",
      "[5772/8000] D loss: 0.0879, G loss: 6.9959\n",
      "[6132/8000] D loss: 0.0405, G loss: 11.4664\n",
      "[6492/8000] D loss: 0.2039, G loss: 7.5756\n",
      "[6852/8000] D loss: 0.4746, G loss: 4.4072\n",
      "[7212/8000] D loss: 0.5232, G loss: 7.1431\n",
      "[7572/8000] D loss: 0.0812, G loss: 7.2055\n",
      "[7932/8000] D loss: 0.1975, G loss: 9.1974\n",
      "train error: \n",
      " D loss: 0.177577, G loss: 6.862889, D accuracy: 96.1%, cell accuracy: 92.5%, board accuracy: 2.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.206178, G loss: 8.194194, D accuracy: 96.4%, cell accuracy: 92.2%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0279, G loss: 8.1991\n",
      "[372/8000] D loss: 0.2955, G loss: 9.0182\n",
      "[732/8000] D loss: 0.0108, G loss: 8.4114\n",
      "[1092/8000] D loss: 0.2993, G loss: 6.2833\n",
      "[1452/8000] D loss: 0.0345, G loss: 9.0992\n",
      "[1812/8000] D loss: 0.0863, G loss: 7.6954\n",
      "[2172/8000] D loss: 0.0596, G loss: 8.6331\n",
      "[2532/8000] D loss: 0.4477, G loss: 7.0169\n",
      "[2892/8000] D loss: 0.7431, G loss: 5.4887\n",
      "[3252/8000] D loss: 0.2198, G loss: 8.3253\n",
      "[3612/8000] D loss: 0.1030, G loss: 8.7215\n",
      "[3972/8000] D loss: 0.0386, G loss: 6.8525\n",
      "[4332/8000] D loss: 0.4140, G loss: 8.6954\n",
      "[4692/8000] D loss: 0.1654, G loss: 7.4191\n",
      "[5052/8000] D loss: 0.2866, G loss: 8.9288\n",
      "[5412/8000] D loss: 0.0061, G loss: 8.4134\n",
      "[5772/8000] D loss: 0.0898, G loss: 9.1576\n",
      "[6132/8000] D loss: 0.0564, G loss: 10.3523\n",
      "[6492/8000] D loss: 0.0186, G loss: 6.9794\n",
      "[6852/8000] D loss: 0.1331, G loss: 8.1336\n",
      "[7212/8000] D loss: 0.1033, G loss: 11.0581\n",
      "[7572/8000] D loss: 0.0889, G loss: 8.8704\n",
      "[7932/8000] D loss: 0.0331, G loss: 8.0005\n",
      "train error: \n",
      " D loss: 0.183430, G loss: 8.299068, D accuracy: 95.9%, cell accuracy: 92.6%, board accuracy: 2.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.301204, G loss: 9.546901, D accuracy: 95.1%, cell accuracy: 92.3%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1335, G loss: 10.3999\n",
      "[372/8000] D loss: 0.0111, G loss: 7.3838\n",
      "[732/8000] D loss: 0.0217, G loss: 9.3944\n",
      "[1092/8000] D loss: 0.5484, G loss: 6.2061\n",
      "[1452/8000] D loss: 0.1184, G loss: 8.6311\n",
      "[1812/8000] D loss: 0.2857, G loss: 8.3080\n",
      "[2172/8000] D loss: 0.0931, G loss: 8.1948\n",
      "[2532/8000] D loss: 0.0826, G loss: 8.6035\n",
      "[2892/8000] D loss: 0.9113, G loss: 3.5251\n",
      "[3252/8000] D loss: 0.3338, G loss: 6.2766\n",
      "[3612/8000] D loss: 0.1720, G loss: 8.5082\n",
      "[3972/8000] D loss: 0.4116, G loss: 10.0667\n",
      "[4332/8000] D loss: 0.0739, G loss: 8.3141\n",
      "[4692/8000] D loss: 0.0098, G loss: 8.8428\n",
      "[5052/8000] D loss: 0.4163, G loss: 7.4405\n",
      "[5412/8000] D loss: 0.1734, G loss: 8.2408\n",
      "[5772/8000] D loss: 0.0715, G loss: 7.8584\n",
      "[6132/8000] D loss: 0.4798, G loss: 7.9814\n",
      "[6492/8000] D loss: 0.2945, G loss: 7.5732\n",
      "[6852/8000] D loss: 0.1788, G loss: 6.4644\n",
      "[7212/8000] D loss: 0.9600, G loss: 9.3336\n",
      "[7572/8000] D loss: 0.0961, G loss: 8.8497\n",
      "[7932/8000] D loss: 0.1772, G loss: 5.2261\n",
      "train error: \n",
      " D loss: 0.216510, G loss: 8.007553, D accuracy: 95.2%, cell accuracy: 92.6%, board accuracy: 1.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.321473, G loss: 9.273420, D accuracy: 93.9%, cell accuracy: 92.4%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0210, G loss: 8.4248\n",
      "[372/8000] D loss: 0.0351, G loss: 8.7412\n",
      "[732/8000] D loss: 0.1100, G loss: 8.4297\n",
      "[1092/8000] D loss: 0.1012, G loss: 9.2719\n",
      "[1452/8000] D loss: 0.0661, G loss: 7.9929\n",
      "[1812/8000] D loss: 0.2752, G loss: 7.1242\n",
      "[2172/8000] D loss: 0.0394, G loss: 8.3530\n",
      "[2532/8000] D loss: 0.8372, G loss: 7.7536\n",
      "[2892/8000] D loss: 0.2530, G loss: 8.6671\n",
      "[3252/8000] D loss: 0.0454, G loss: 7.5530\n",
      "[3612/8000] D loss: 0.0189, G loss: 11.4957\n",
      "[3972/8000] D loss: 0.4043, G loss: 6.2760\n",
      "[4332/8000] D loss: 0.1818, G loss: 5.7156\n",
      "[4692/8000] D loss: 0.1450, G loss: 7.5120\n",
      "[5052/8000] D loss: 0.0612, G loss: 8.5006\n",
      "[5412/8000] D loss: 0.1621, G loss: 5.9204\n",
      "[5772/8000] D loss: 0.0692, G loss: 8.5495\n",
      "[6132/8000] D loss: 0.1496, G loss: 7.9839\n",
      "[6492/8000] D loss: 0.1942, G loss: 8.8346\n",
      "[6852/8000] D loss: 0.2649, G loss: 8.2268\n",
      "[7212/8000] D loss: 0.2669, G loss: 8.2287\n",
      "[7572/8000] D loss: 0.0388, G loss: 9.2451\n",
      "[7932/8000] D loss: 0.3071, G loss: 6.0435\n",
      "train error: \n",
      " D loss: 0.192364, G loss: 7.978648, D accuracy: 95.9%, cell accuracy: 92.8%, board accuracy: 2.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.283534, G loss: 9.237944, D accuracy: 95.2%, cell accuracy: 92.5%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1271, G loss: 7.8733\n",
      "[372/8000] D loss: 0.0287, G loss: 5.6682\n",
      "[732/8000] D loss: 0.1330, G loss: 7.0621\n",
      "[1092/8000] D loss: 0.1183, G loss: 7.4564\n",
      "[1452/8000] D loss: 0.1472, G loss: 7.7525\n",
      "[1812/8000] D loss: 0.0198, G loss: 7.8028\n",
      "[2172/8000] D loss: 0.0042, G loss: 9.0369\n",
      "[2532/8000] D loss: 0.2925, G loss: 11.4019\n",
      "[2892/8000] D loss: 0.1377, G loss: 6.1130\n",
      "[3252/8000] D loss: 0.2442, G loss: 6.9734\n",
      "[3612/8000] D loss: 0.5324, G loss: 6.1725\n",
      "[3972/8000] D loss: 0.2657, G loss: 6.4240\n",
      "[4332/8000] D loss: 0.1086, G loss: 8.4546\n",
      "[4692/8000] D loss: 0.1117, G loss: 9.4423\n",
      "[5052/8000] D loss: 0.1739, G loss: 10.7536\n",
      "[5412/8000] D loss: 0.1279, G loss: 7.5139\n",
      "[5772/8000] D loss: 0.1771, G loss: 6.3940\n",
      "[6132/8000] D loss: 0.1829, G loss: 8.0151\n",
      "[6492/8000] D loss: 0.1287, G loss: 5.4626\n",
      "[6852/8000] D loss: 0.0762, G loss: 7.0251\n",
      "[7212/8000] D loss: 0.1509, G loss: 7.1356\n",
      "[7572/8000] D loss: 0.1969, G loss: 6.2203\n",
      "[7932/8000] D loss: 0.0106, G loss: 9.6373\n",
      "train error: \n",
      " D loss: 0.170231, G loss: 7.676358, D accuracy: 96.5%, cell accuracy: 92.9%, board accuracy: 2.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.250722, G loss: 9.043312, D accuracy: 96.3%, cell accuracy: 92.6%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1982, G loss: 4.4420\n",
      "[372/8000] D loss: 0.2038, G loss: 7.7500\n",
      "[732/8000] D loss: 0.8361, G loss: 9.2849\n",
      "[1092/8000] D loss: 0.1289, G loss: 7.0727\n",
      "[1452/8000] D loss: 0.1619, G loss: 9.0573\n",
      "[1812/8000] D loss: 0.1034, G loss: 6.2088\n",
      "[2172/8000] D loss: 0.1935, G loss: 5.7061\n",
      "[2532/8000] D loss: 0.2714, G loss: 5.5395\n",
      "[2892/8000] D loss: 0.2847, G loss: 6.2363\n",
      "[3252/8000] D loss: 0.0660, G loss: 7.5235\n",
      "[3612/8000] D loss: 0.0094, G loss: 8.3212\n",
      "[3972/8000] D loss: 0.0619, G loss: 9.5364\n",
      "[4332/8000] D loss: 0.0207, G loss: 8.2790\n",
      "[4692/8000] D loss: 0.0910, G loss: 8.1420\n",
      "[5052/8000] D loss: 0.3341, G loss: 6.9199\n",
      "[5412/8000] D loss: 0.2053, G loss: 6.1088\n",
      "[5772/8000] D loss: 0.4110, G loss: 6.2555\n",
      "[6132/8000] D loss: 0.0854, G loss: 8.4104\n",
      "[6492/8000] D loss: 0.1685, G loss: 6.9325\n",
      "[6852/8000] D loss: 0.0641, G loss: 8.5626\n",
      "[7212/8000] D loss: 0.5563, G loss: 5.1194\n",
      "[7572/8000] D loss: 0.0351, G loss: 8.6229\n",
      "[7932/8000] D loss: 0.0083, G loss: 7.0098\n",
      "train error: \n",
      " D loss: 0.172987, G loss: 7.044860, D accuracy: 96.1%, cell accuracy: 93.0%, board accuracy: 2.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.235895, G loss: 8.463924, D accuracy: 95.9%, cell accuracy: 92.7%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0065, G loss: 8.7690\n",
      "[372/8000] D loss: 0.3900, G loss: 7.7178\n",
      "[732/8000] D loss: 0.2910, G loss: 7.3681\n",
      "[1092/8000] D loss: 0.2542, G loss: 5.5707\n",
      "[1452/8000] D loss: 0.0765, G loss: 10.7614\n",
      "[1812/8000] D loss: 0.0188, G loss: 9.0188\n",
      "[2172/8000] D loss: 0.0834, G loss: 9.3234\n",
      "[2532/8000] D loss: 0.2287, G loss: 7.9519\n",
      "[2892/8000] D loss: 0.0134, G loss: 11.4888\n",
      "[3252/8000] D loss: 0.0236, G loss: 9.0126\n",
      "[3612/8000] D loss: 0.2956, G loss: 6.9791\n",
      "[3972/8000] D loss: 0.0323, G loss: 8.4079\n",
      "[4332/8000] D loss: 0.0828, G loss: 10.1572\n",
      "[4692/8000] D loss: 0.1644, G loss: 9.0422\n",
      "[5052/8000] D loss: 0.0734, G loss: 7.4737\n",
      "[5412/8000] D loss: 0.3382, G loss: 10.2183\n",
      "[5772/8000] D loss: 0.1861, G loss: 7.4498\n",
      "[6132/8000] D loss: 0.1108, G loss: 9.3104\n",
      "[6492/8000] D loss: 0.2439, G loss: 6.7253\n",
      "[6852/8000] D loss: 0.1428, G loss: 6.6760\n",
      "[7212/8000] D loss: 0.1006, G loss: 7.7636\n",
      "[7572/8000] D loss: 0.4323, G loss: 6.4615\n",
      "[7932/8000] D loss: 0.3911, G loss: 7.8682\n",
      "train error: \n",
      " D loss: 0.224351, G loss: 6.384632, D accuracy: 95.1%, cell accuracy: 93.0%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.217740, G loss: 7.807132, D accuracy: 95.8%, cell accuracy: 92.7%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1668, G loss: 6.6674\n",
      "[372/8000] D loss: 0.1529, G loss: 11.6618\n",
      "[732/8000] D loss: 0.0837, G loss: 9.6497\n",
      "[1092/8000] D loss: 0.1369, G loss: 10.2273\n",
      "[1452/8000] D loss: 0.0310, G loss: 11.0839\n",
      "[1812/8000] D loss: 0.1011, G loss: 8.2905\n",
      "[2172/8000] D loss: 0.0068, G loss: 11.9292\n",
      "[2532/8000] D loss: 0.0748, G loss: 6.7312\n",
      "[2892/8000] D loss: 0.0950, G loss: 6.7513\n",
      "[3252/8000] D loss: 0.2403, G loss: 8.5813\n",
      "[3612/8000] D loss: 0.2922, G loss: 5.5897\n",
      "[3972/8000] D loss: 0.6435, G loss: 5.5468\n",
      "[4332/8000] D loss: 0.3463, G loss: 5.8810\n",
      "[4692/8000] D loss: 0.0763, G loss: 8.8071\n",
      "[5052/8000] D loss: 0.1291, G loss: 7.2401\n",
      "[5412/8000] D loss: 0.0043, G loss: 9.4142\n",
      "[5772/8000] D loss: 0.2102, G loss: 8.2072\n",
      "[6132/8000] D loss: 0.3445, G loss: 7.4630\n",
      "[6492/8000] D loss: 0.1019, G loss: 6.2983\n",
      "[6852/8000] D loss: 0.3327, G loss: 5.9453\n",
      "[7212/8000] D loss: 0.1108, G loss: 6.1940\n",
      "[7572/8000] D loss: 0.2332, G loss: 7.3201\n",
      "[7932/8000] D loss: 0.0201, G loss: 11.6131\n",
      "train error: \n",
      " D loss: 0.192324, G loss: 7.310494, D accuracy: 95.8%, cell accuracy: 93.0%, board accuracy: 2.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.242793, G loss: 8.800428, D accuracy: 95.8%, cell accuracy: 92.7%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0763, G loss: 7.7884\n",
      "[372/8000] D loss: 0.3165, G loss: 5.4861\n",
      "[732/8000] D loss: 0.2735, G loss: 7.5444\n",
      "[1092/8000] D loss: 0.1887, G loss: 8.7100\n",
      "[1452/8000] D loss: 0.2892, G loss: 7.2344\n",
      "[1812/8000] D loss: 0.0330, G loss: 7.8166\n",
      "[2172/8000] D loss: 0.2723, G loss: 7.4771\n",
      "[2532/8000] D loss: 0.1545, G loss: 8.5989\n",
      "[2892/8000] D loss: 0.1431, G loss: 7.7688\n",
      "[3252/8000] D loss: 0.0784, G loss: 7.2688\n",
      "[3612/8000] D loss: 0.2276, G loss: 7.5068\n",
      "[3972/8000] D loss: 0.2233, G loss: 5.1719\n",
      "[4332/8000] D loss: 0.6742, G loss: 5.8575\n",
      "[4692/8000] D loss: 0.0257, G loss: 7.9250\n",
      "[5052/8000] D loss: 0.1526, G loss: 6.8930\n",
      "[5412/8000] D loss: 0.0311, G loss: 7.5496\n",
      "[5772/8000] D loss: 0.0435, G loss: 6.4143\n",
      "[6132/8000] D loss: 0.4089, G loss: 6.7458\n",
      "[6492/8000] D loss: 0.0776, G loss: 9.5815\n",
      "[6852/8000] D loss: 0.1924, G loss: 6.2146\n",
      "[7212/8000] D loss: 0.3234, G loss: 8.5695\n",
      "[7572/8000] D loss: 0.0250, G loss: 11.7001\n",
      "[7932/8000] D loss: 0.1979, G loss: 5.6400\n",
      "train error: \n",
      " D loss: 0.159810, G loss: 7.241299, D accuracy: 96.7%, cell accuracy: 93.0%, board accuracy: 2.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.238914, G loss: 8.670634, D accuracy: 96.1%, cell accuracy: 92.7%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0958, G loss: 7.1756\n",
      "[372/8000] D loss: 0.2612, G loss: 8.2994\n",
      "[732/8000] D loss: 0.1570, G loss: 9.8950\n",
      "[1092/8000] D loss: 0.0999, G loss: 7.7991\n",
      "[1452/8000] D loss: 0.2409, G loss: 6.0644\n",
      "[1812/8000] D loss: 0.0173, G loss: 10.4911\n",
      "[2172/8000] D loss: 0.0190, G loss: 8.2364\n",
      "[2532/8000] D loss: 0.1687, G loss: 7.5928\n",
      "[2892/8000] D loss: 0.0651, G loss: 11.3859\n",
      "[3252/8000] D loss: 0.3143, G loss: 7.3219\n",
      "[3612/8000] D loss: 0.0641, G loss: 7.5727\n",
      "[3972/8000] D loss: 0.4135, G loss: 7.4671\n",
      "[4332/8000] D loss: 0.3663, G loss: 8.1983\n",
      "[4692/8000] D loss: 0.3593, G loss: 9.1441\n",
      "[5052/8000] D loss: 0.0544, G loss: 7.8233\n",
      "[5412/8000] D loss: 0.0656, G loss: 10.2254\n",
      "[5772/8000] D loss: 0.3960, G loss: 6.3098\n",
      "[6132/8000] D loss: 0.4938, G loss: 6.1235\n",
      "[6492/8000] D loss: 0.2643, G loss: 6.4972\n",
      "[6852/8000] D loss: 0.0178, G loss: 10.1392\n",
      "[7212/8000] D loss: 0.1761, G loss: 6.4072\n",
      "[7572/8000] D loss: 0.1926, G loss: 9.8198\n",
      "[7932/8000] D loss: 0.0087, G loss: 9.3876\n",
      "train error: \n",
      " D loss: 0.170834, G loss: 7.325780, D accuracy: 96.3%, cell accuracy: 93.0%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.233355, G loss: 8.838123, D accuracy: 95.7%, cell accuracy: 92.8%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0730, G loss: 7.4295\n",
      "[372/8000] D loss: 0.1370, G loss: 7.1813\n",
      "[732/8000] D loss: 0.1085, G loss: 7.6779\n",
      "[1092/8000] D loss: 0.0879, G loss: 8.9662\n",
      "[1452/8000] D loss: 0.2330, G loss: 6.4289\n",
      "[1812/8000] D loss: 0.1160, G loss: 6.5526\n",
      "[2172/8000] D loss: 0.0522, G loss: 9.3037\n",
      "[2532/8000] D loss: 0.0361, G loss: 8.5874\n",
      "[2892/8000] D loss: 0.0471, G loss: 7.2427\n",
      "[3252/8000] D loss: 0.1113, G loss: 8.4829\n",
      "[3612/8000] D loss: 0.1853, G loss: 6.9341\n",
      "[3972/8000] D loss: 0.2255, G loss: 8.0811\n",
      "[4332/8000] D loss: 0.1942, G loss: 5.5554\n",
      "[4692/8000] D loss: 0.0227, G loss: 9.8153\n",
      "[5052/8000] D loss: 0.4204, G loss: 8.1829\n",
      "[5412/8000] D loss: 1.0914, G loss: 13.2829\n",
      "[5772/8000] D loss: 0.1691, G loss: 6.0601\n",
      "[6132/8000] D loss: 0.0440, G loss: 10.2283\n",
      "[6492/8000] D loss: 0.1395, G loss: 5.6036\n",
      "[6852/8000] D loss: 0.2247, G loss: 6.7400\n",
      "[7212/8000] D loss: 0.1736, G loss: 6.8388\n",
      "[7572/8000] D loss: 0.0185, G loss: 9.3695\n",
      "[7932/8000] D loss: 0.2477, G loss: 8.2170\n",
      "train error: \n",
      " D loss: 0.165542, G loss: 8.082608, D accuracy: 96.3%, cell accuracy: 93.1%, board accuracy: 2.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.287828, G loss: 9.431114, D accuracy: 94.8%, cell accuracy: 92.8%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0058, G loss: 11.1473\n",
      "[372/8000] D loss: 0.1557, G loss: 8.6327\n",
      "[732/8000] D loss: 0.1903, G loss: 8.5152\n",
      "[1092/8000] D loss: 0.1923, G loss: 5.1282\n",
      "[1452/8000] D loss: 0.2119, G loss: 9.4370\n",
      "[1812/8000] D loss: 0.1368, G loss: 10.7217\n",
      "[2172/8000] D loss: 0.4941, G loss: 6.3689\n",
      "[2532/8000] D loss: 0.2374, G loss: 10.0220\n",
      "[2892/8000] D loss: 0.2472, G loss: 9.0189\n",
      "[3252/8000] D loss: 0.0528, G loss: 9.4693\n",
      "[3612/8000] D loss: 0.0106, G loss: 9.4599\n",
      "[3972/8000] D loss: 0.1800, G loss: 6.7192\n",
      "[4332/8000] D loss: 0.5668, G loss: 7.5798\n",
      "[4692/8000] D loss: 0.2268, G loss: 6.9666\n",
      "[5052/8000] D loss: 0.1876, G loss: 8.6677\n",
      "[5412/8000] D loss: 0.1044, G loss: 9.0041\n",
      "[5772/8000] D loss: 0.2085, G loss: 8.2845\n",
      "[6132/8000] D loss: 0.1340, G loss: 6.9795\n",
      "[6492/8000] D loss: 0.3011, G loss: 8.6157\n",
      "[6852/8000] D loss: 0.1361, G loss: 7.8774\n",
      "[7212/8000] D loss: 0.0781, G loss: 8.1192\n",
      "[7572/8000] D loss: 0.2902, G loss: 7.8841\n",
      "[7932/8000] D loss: 0.4388, G loss: 8.6839\n",
      "train error: \n",
      " D loss: 0.242872, G loss: 6.362598, D accuracy: 94.8%, cell accuracy: 93.1%, board accuracy: 2.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.235597, G loss: 7.884161, D accuracy: 95.7%, cell accuracy: 92.8%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0938, G loss: 5.7752\n",
      "[372/8000] D loss: 0.0534, G loss: 7.2816\n",
      "[732/8000] D loss: 0.1006, G loss: 9.5848\n",
      "[1092/8000] D loss: 0.0612, G loss: 7.8937\n",
      "[1452/8000] D loss: 0.0412, G loss: 8.7713\n",
      "[1812/8000] D loss: 0.1530, G loss: 6.9458\n",
      "[2172/8000] D loss: 0.2594, G loss: 7.2465\n",
      "[2532/8000] D loss: 0.2612, G loss: 7.3731\n",
      "[2892/8000] D loss: 0.1013, G loss: 9.0325\n",
      "[3252/8000] D loss: 0.4326, G loss: 6.4425\n",
      "[3612/8000] D loss: 0.1387, G loss: 8.9133\n",
      "[3972/8000] D loss: 0.0432, G loss: 7.6755\n",
      "[4332/8000] D loss: 0.0790, G loss: 9.3037\n",
      "[4692/8000] D loss: 0.2203, G loss: 6.3362\n",
      "[5052/8000] D loss: 0.1754, G loss: 7.3220\n",
      "[5412/8000] D loss: 0.1812, G loss: 10.7332\n",
      "[5772/8000] D loss: 0.3358, G loss: 8.1631\n",
      "[6132/8000] D loss: 0.2024, G loss: 6.9802\n",
      "[6492/8000] D loss: 0.1205, G loss: 10.9161\n",
      "[6852/8000] D loss: 0.2640, G loss: 7.0147\n",
      "[7212/8000] D loss: 0.0276, G loss: 8.4465\n",
      "[7572/8000] D loss: 0.1494, G loss: 7.9299\n",
      "[7932/8000] D loss: 0.1880, G loss: 7.3714\n",
      "train error: \n",
      " D loss: 0.168879, G loss: 8.383719, D accuracy: 96.2%, cell accuracy: 93.2%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.288116, G loss: 10.009747, D accuracy: 95.3%, cell accuracy: 92.9%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0049, G loss: 8.4794\n",
      "[372/8000] D loss: 0.1164, G loss: 7.6342\n",
      "[732/8000] D loss: 0.5860, G loss: 8.0716\n",
      "[1092/8000] D loss: 0.2197, G loss: 7.0091\n",
      "[1452/8000] D loss: 0.1130, G loss: 8.1229\n",
      "[1812/8000] D loss: 0.3822, G loss: 9.3202\n",
      "[2172/8000] D loss: 0.4256, G loss: 6.2580\n",
      "[2532/8000] D loss: 0.1952, G loss: 8.8783\n",
      "[2892/8000] D loss: 0.3086, G loss: 5.2029\n",
      "[3252/8000] D loss: 0.0646, G loss: 8.2453\n",
      "[3612/8000] D loss: 0.0702, G loss: 9.0609\n",
      "[3972/8000] D loss: 0.3531, G loss: 7.3695\n",
      "[4332/8000] D loss: 0.1759, G loss: 7.4159\n",
      "[4692/8000] D loss: 0.1307, G loss: 7.6040\n",
      "[5052/8000] D loss: 0.3411, G loss: 6.6479\n",
      "[5412/8000] D loss: 0.2127, G loss: 11.5533\n",
      "[5772/8000] D loss: 0.0780, G loss: 9.2913\n",
      "[6132/8000] D loss: 0.1368, G loss: 7.5472\n",
      "[6492/8000] D loss: 0.3502, G loss: 7.2738\n",
      "[6852/8000] D loss: 0.0039, G loss: 9.3462\n",
      "[7212/8000] D loss: 0.2496, G loss: 8.7802\n",
      "[7572/8000] D loss: 0.0239, G loss: 8.1327\n",
      "[7932/8000] D loss: 0.3564, G loss: 7.2300\n",
      "train error: \n",
      " D loss: 0.177361, G loss: 7.578315, D accuracy: 96.0%, cell accuracy: 93.2%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.275671, G loss: 9.102439, D accuracy: 95.7%, cell accuracy: 92.9%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0291, G loss: 6.6772\n",
      "[372/8000] D loss: 0.0723, G loss: 6.9990\n",
      "[732/8000] D loss: 0.0538, G loss: 8.5412\n",
      "[1092/8000] D loss: 0.0460, G loss: 8.0986\n",
      "[1452/8000] D loss: 0.4203, G loss: 5.5201\n",
      "[1812/8000] D loss: 0.1920, G loss: 9.4823\n",
      "[2172/8000] D loss: 0.1263, G loss: 10.7495\n",
      "[2532/8000] D loss: 0.1636, G loss: 9.1696\n",
      "[2892/8000] D loss: 0.0010, G loss: 13.0943\n",
      "[3252/8000] D loss: 0.2921, G loss: 8.0642\n",
      "[3612/8000] D loss: 0.0437, G loss: 9.3197\n",
      "[3972/8000] D loss: 0.3245, G loss: 6.8093\n",
      "[4332/8000] D loss: 0.2195, G loss: 5.5173\n",
      "[4692/8000] D loss: 0.1716, G loss: 6.7649\n",
      "[5052/8000] D loss: 0.0358, G loss: 8.4688\n",
      "[5412/8000] D loss: 0.0954, G loss: 9.7265\n",
      "[5772/8000] D loss: 0.1141, G loss: 6.2631\n",
      "[6132/8000] D loss: 0.1457, G loss: 5.2562\n",
      "[6492/8000] D loss: 0.0926, G loss: 8.8303\n",
      "[6852/8000] D loss: 0.1401, G loss: 7.2624\n",
      "[7212/8000] D loss: 0.1494, G loss: 6.4651\n",
      "[7572/8000] D loss: 0.0014, G loss: 11.1506\n",
      "[7932/8000] D loss: 0.4784, G loss: 6.8515\n",
      "train error: \n",
      " D loss: 0.175191, G loss: 7.658915, D accuracy: 96.3%, cell accuracy: 93.2%, board accuracy: 2.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.245489, G loss: 9.184508, D accuracy: 96.1%, cell accuracy: 92.9%, board accuracy: 1.3% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3941, G loss: 6.8893\n",
      "[372/8000] D loss: 0.1781, G loss: 6.0694\n",
      "[732/8000] D loss: 0.1587, G loss: 9.0998\n",
      "[1092/8000] D loss: 0.1446, G loss: 9.0841\n",
      "[1452/8000] D loss: 0.0063, G loss: 8.1695\n",
      "[1812/8000] D loss: 0.1013, G loss: 7.4794\n",
      "[2172/8000] D loss: 0.1545, G loss: 9.7490\n",
      "[2532/8000] D loss: 0.2049, G loss: 8.3812\n",
      "[2892/8000] D loss: 0.0914, G loss: 5.8183\n",
      "[3252/8000] D loss: 0.1503, G loss: 8.5179\n",
      "[3612/8000] D loss: 0.2442, G loss: 6.4947\n",
      "[3972/8000] D loss: 0.1324, G loss: 7.2690\n",
      "[4332/8000] D loss: 0.0729, G loss: 7.3447\n",
      "[4692/8000] D loss: 0.0722, G loss: 9.5987\n",
      "[5052/8000] D loss: 0.1809, G loss: 10.2363\n",
      "[5412/8000] D loss: 0.2391, G loss: 8.5294\n",
      "[5772/8000] D loss: 0.3740, G loss: 7.2828\n",
      "[6132/8000] D loss: 0.2263, G loss: 5.3041\n",
      "[6492/8000] D loss: 0.3810, G loss: 6.0381\n",
      "[6852/8000] D loss: 0.3509, G loss: 7.6144\n",
      "[7212/8000] D loss: 0.4420, G loss: 6.5845\n",
      "[7572/8000] D loss: 0.1618, G loss: 7.1898\n",
      "[7932/8000] D loss: 0.1156, G loss: 6.0747\n",
      "train error: \n",
      " D loss: 0.214354, G loss: 8.566248, D accuracy: 95.4%, cell accuracy: 93.2%, board accuracy: 2.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.345414, G loss: 10.048638, D accuracy: 94.2%, cell accuracy: 92.9%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4110, G loss: 7.5788\n",
      "[372/8000] D loss: 0.3168, G loss: 4.7598\n",
      "[732/8000] D loss: 0.3263, G loss: 7.8404\n",
      "[1092/8000] D loss: 0.0305, G loss: 9.0359\n",
      "[1452/8000] D loss: 0.1409, G loss: 9.4803\n",
      "[1812/8000] D loss: 0.2505, G loss: 7.1030\n",
      "[2172/8000] D loss: 0.0166, G loss: 9.6396\n",
      "[2532/8000] D loss: 0.1348, G loss: 11.9585\n",
      "[2892/8000] D loss: 0.0227, G loss: 9.2984\n",
      "[3252/8000] D loss: 0.2842, G loss: 7.6759\n",
      "[3612/8000] D loss: 0.1905, G loss: 7.1338\n",
      "[3972/8000] D loss: 0.0551, G loss: 7.4741\n",
      "[4332/8000] D loss: 0.2334, G loss: 6.2470\n",
      "[4692/8000] D loss: 0.2460, G loss: 7.4177\n",
      "[5052/8000] D loss: 0.3811, G loss: 6.9405\n",
      "[5412/8000] D loss: 0.1082, G loss: 9.1844\n",
      "[5772/8000] D loss: 0.0283, G loss: 6.9959\n",
      "[6132/8000] D loss: 0.2620, G loss: 5.8227\n",
      "[6492/8000] D loss: 0.0312, G loss: 8.5456\n",
      "[6852/8000] D loss: 0.2536, G loss: 6.1975\n",
      "[7212/8000] D loss: 0.1787, G loss: 7.6375\n",
      "[7572/8000] D loss: 0.0670, G loss: 6.4520\n",
      "[7932/8000] D loss: 0.0212, G loss: 8.8218\n",
      "train error: \n",
      " D loss: 0.171055, G loss: 7.918716, D accuracy: 96.4%, cell accuracy: 93.2%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.247401, G loss: 9.518500, D accuracy: 95.9%, cell accuracy: 92.9%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2097, G loss: 6.6583\n",
      "[372/8000] D loss: 0.1258, G loss: 7.7790\n",
      "[732/8000] D loss: 0.3459, G loss: 7.3827\n",
      "[1092/8000] D loss: 0.3416, G loss: 7.0159\n",
      "[1452/8000] D loss: 0.2827, G loss: 6.4884\n",
      "[1812/8000] D loss: 0.0617, G loss: 9.7635\n",
      "[2172/8000] D loss: 0.1405, G loss: 8.7701\n",
      "[2532/8000] D loss: 0.0438, G loss: 9.1015\n",
      "[2892/8000] D loss: 0.5868, G loss: 4.7128\n",
      "[3252/8000] D loss: 0.4371, G loss: 8.1351\n",
      "[3612/8000] D loss: 0.1490, G loss: 7.7631\n",
      "[3972/8000] D loss: 0.1340, G loss: 12.5417\n",
      "[4332/8000] D loss: 0.1652, G loss: 9.2238\n",
      "[4692/8000] D loss: 0.1659, G loss: 5.9377\n",
      "[5052/8000] D loss: 0.2804, G loss: 7.7501\n",
      "[5412/8000] D loss: 0.1853, G loss: 7.0303\n",
      "[5772/8000] D loss: 0.2255, G loss: 6.0047\n",
      "[6132/8000] D loss: 0.0298, G loss: 7.1864\n",
      "[6492/8000] D loss: 0.0114, G loss: 7.4704\n",
      "[6852/8000] D loss: 0.0172, G loss: 8.6768\n",
      "[7212/8000] D loss: 0.1723, G loss: 7.7686\n",
      "[7572/8000] D loss: 0.0307, G loss: 7.6849\n",
      "[7932/8000] D loss: 0.0742, G loss: 9.3621\n",
      "train error: \n",
      " D loss: 0.198055, G loss: 7.316911, D accuracy: 95.7%, cell accuracy: 93.3%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.239751, G loss: 8.909360, D accuracy: 95.6%, cell accuracy: 93.0%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0559, G loss: 6.0914\n",
      "[372/8000] D loss: 0.0622, G loss: 7.3615\n",
      "[732/8000] D loss: 0.0885, G loss: 7.0427\n",
      "[1092/8000] D loss: 0.2971, G loss: 5.4725\n",
      "[1452/8000] D loss: 0.0520, G loss: 9.2082\n",
      "[1812/8000] D loss: 0.0954, G loss: 9.6046\n",
      "[2172/8000] D loss: 0.0553, G loss: 6.4815\n",
      "[2532/8000] D loss: 0.1561, G loss: 7.9022\n",
      "[2892/8000] D loss: 0.5154, G loss: 7.5664\n",
      "[3252/8000] D loss: 0.1739, G loss: 7.4878\n",
      "[3612/8000] D loss: 0.2291, G loss: 8.4372\n",
      "[3972/8000] D loss: 0.2526, G loss: 6.9971\n",
      "[4332/8000] D loss: 0.7971, G loss: 5.5361\n",
      "[4692/8000] D loss: 0.1446, G loss: 6.6422\n",
      "[5052/8000] D loss: 0.1180, G loss: 7.7981\n",
      "[5412/8000] D loss: 0.1139, G loss: 8.0308\n",
      "[5772/8000] D loss: 0.4257, G loss: 8.0511\n",
      "[6132/8000] D loss: 0.1695, G loss: 6.4235\n",
      "[6492/8000] D loss: 0.0217, G loss: 8.4539\n",
      "[6852/8000] D loss: 0.0830, G loss: 5.8167\n",
      "[7212/8000] D loss: 0.0815, G loss: 7.5812\n",
      "[7572/8000] D loss: 0.2199, G loss: 8.9751\n",
      "[7932/8000] D loss: 0.0595, G loss: 6.2052\n",
      "train error: \n",
      " D loss: 0.184235, G loss: 7.338945, D accuracy: 96.0%, cell accuracy: 93.2%, board accuracy: 3.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.250633, G loss: 8.976713, D accuracy: 95.5%, cell accuracy: 93.0%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0777, G loss: 7.0305\n",
      "[372/8000] D loss: 0.2220, G loss: 7.2170\n",
      "[732/8000] D loss: 0.1787, G loss: 6.7800\n",
      "[1092/8000] D loss: 0.1778, G loss: 6.6293\n",
      "[1452/8000] D loss: 0.1458, G loss: 8.8590\n",
      "[1812/8000] D loss: 0.4684, G loss: 7.9047\n",
      "[2172/8000] D loss: 0.0736, G loss: 8.8814\n",
      "[2532/8000] D loss: 0.0588, G loss: 9.8097\n",
      "[2892/8000] D loss: 0.2058, G loss: 7.6800\n",
      "[3252/8000] D loss: 0.0081, G loss: 9.3442\n",
      "[3612/8000] D loss: 0.0734, G loss: 8.7750\n",
      "[3972/8000] D loss: 0.1069, G loss: 10.6831\n",
      "[4332/8000] D loss: 0.1802, G loss: 7.8367\n",
      "[4692/8000] D loss: 0.3230, G loss: 6.6262\n",
      "[5052/8000] D loss: 0.1018, G loss: 7.8203\n",
      "[5412/8000] D loss: 0.2042, G loss: 6.1836\n",
      "[5772/8000] D loss: 0.0496, G loss: 9.0050\n",
      "[6132/8000] D loss: 0.1249, G loss: 6.0156\n",
      "[6492/8000] D loss: 0.4256, G loss: 8.1550\n",
      "[6852/8000] D loss: 0.3121, G loss: 8.2972\n",
      "[7212/8000] D loss: 0.0576, G loss: 9.5305\n",
      "[7572/8000] D loss: 0.0075, G loss: 10.4574\n",
      "[7932/8000] D loss: 0.5866, G loss: 6.9713\n",
      "train error: \n",
      " D loss: 0.171991, G loss: 8.270992, D accuracy: 96.2%, cell accuracy: 93.3%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.311186, G loss: 9.758688, D accuracy: 94.8%, cell accuracy: 93.0%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0368, G loss: 6.3876\n",
      "[372/8000] D loss: 0.1891, G loss: 7.4777\n",
      "[732/8000] D loss: 0.1499, G loss: 6.8840\n",
      "[1092/8000] D loss: 0.2605, G loss: 8.6340\n",
      "[1452/8000] D loss: 0.0722, G loss: 10.4072\n",
      "[1812/8000] D loss: 0.1546, G loss: 8.5205\n",
      "[2172/8000] D loss: 0.2153, G loss: 10.3573\n",
      "[2532/8000] D loss: 0.0326, G loss: 8.7747\n",
      "[2892/8000] D loss: 0.0510, G loss: 11.2895\n",
      "[3252/8000] D loss: 0.0177, G loss: 10.3746\n",
      "[3612/8000] D loss: 0.0205, G loss: 8.7448\n",
      "[3972/8000] D loss: 0.0478, G loss: 8.2002\n",
      "[4332/8000] D loss: 0.2740, G loss: 7.6863\n",
      "[4692/8000] D loss: 0.2539, G loss: 7.2152\n",
      "[5052/8000] D loss: 0.1168, G loss: 10.0685\n",
      "[5412/8000] D loss: 0.1564, G loss: 7.8252\n",
      "[5772/8000] D loss: 0.4873, G loss: 8.7688\n",
      "[6132/8000] D loss: 0.1300, G loss: 7.6155\n",
      "[6492/8000] D loss: 0.0230, G loss: 7.5753\n",
      "[6852/8000] D loss: 0.1117, G loss: 9.2675\n",
      "[7212/8000] D loss: 0.3378, G loss: 5.5840\n",
      "[7572/8000] D loss: 0.0085, G loss: 10.1833\n",
      "[7932/8000] D loss: 0.2617, G loss: 9.9485\n",
      "train error: \n",
      " D loss: 0.227632, G loss: 9.201860, D accuracy: 95.3%, cell accuracy: 93.3%, board accuracy: 3.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.398655, G loss: 10.800955, D accuracy: 94.0%, cell accuracy: 93.0%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0435, G loss: 10.2927\n",
      "[372/8000] D loss: 0.0390, G loss: 7.0947\n",
      "[732/8000] D loss: 0.2963, G loss: 6.8674\n",
      "[1092/8000] D loss: 0.3830, G loss: 8.1767\n",
      "[1452/8000] D loss: 0.1803, G loss: 9.9969\n",
      "[1812/8000] D loss: 0.1030, G loss: 7.8292\n",
      "[2172/8000] D loss: 0.0354, G loss: 8.6035\n",
      "[2532/8000] D loss: 0.1105, G loss: 7.9062\n",
      "[2892/8000] D loss: 0.1936, G loss: 8.1027\n",
      "[3252/8000] D loss: 0.0915, G loss: 9.1675\n",
      "[3612/8000] D loss: 0.5215, G loss: 5.3778\n",
      "[3972/8000] D loss: 0.1358, G loss: 9.2239\n",
      "[4332/8000] D loss: 0.1021, G loss: 6.8248\n",
      "[4692/8000] D loss: 0.0074, G loss: 9.8611\n",
      "[5052/8000] D loss: 0.1793, G loss: 8.3539\n",
      "[5412/8000] D loss: 0.1869, G loss: 6.4236\n",
      "[5772/8000] D loss: 0.3459, G loss: 4.7256\n",
      "[6132/8000] D loss: 0.0448, G loss: 8.4146\n",
      "[6492/8000] D loss: 0.1449, G loss: 10.3524\n",
      "[6852/8000] D loss: 0.2214, G loss: 9.7601\n",
      "[7212/8000] D loss: 0.1778, G loss: 7.2688\n",
      "[7572/8000] D loss: 0.3023, G loss: 10.3288\n",
      "[7932/8000] D loss: 0.2449, G loss: 5.8679\n",
      "train error: \n",
      " D loss: 0.210336, G loss: 7.120402, D accuracy: 95.4%, cell accuracy: 93.3%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.255738, G loss: 8.702352, D accuracy: 95.4%, cell accuracy: 93.0%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0828, G loss: 7.1323\n",
      "[372/8000] D loss: 0.3238, G loss: 5.7510\n",
      "[732/8000] D loss: 0.0420, G loss: 9.9972\n",
      "[1092/8000] D loss: 0.0442, G loss: 9.1603\n",
      "[1452/8000] D loss: 0.0986, G loss: 8.6235\n",
      "[1812/8000] D loss: 0.0143, G loss: 8.3389\n",
      "[2172/8000] D loss: 0.0282, G loss: 7.5819\n",
      "[2532/8000] D loss: 0.2151, G loss: 6.6664\n",
      "[2892/8000] D loss: 0.0055, G loss: 11.5098\n",
      "[3252/8000] D loss: 0.3690, G loss: 9.0090\n",
      "[3612/8000] D loss: 0.4726, G loss: 8.9704\n",
      "[3972/8000] D loss: 0.1218, G loss: 8.3112\n",
      "[4332/8000] D loss: 0.1081, G loss: 11.1828\n",
      "[4692/8000] D loss: 0.0765, G loss: 8.8201\n",
      "[5052/8000] D loss: 0.0203, G loss: 10.4828\n",
      "[5412/8000] D loss: 0.2869, G loss: 9.3500\n",
      "[5772/8000] D loss: 0.2970, G loss: 6.4566\n",
      "[6132/8000] D loss: 0.1747, G loss: 6.5083\n",
      "[6492/8000] D loss: 0.0108, G loss: 12.2000\n",
      "[6852/8000] D loss: 0.0189, G loss: 9.2780\n",
      "[7212/8000] D loss: 0.1553, G loss: 7.9217\n",
      "[7572/8000] D loss: 0.1598, G loss: 7.8062\n",
      "[7932/8000] D loss: 0.1433, G loss: 8.4770\n",
      "train error: \n",
      " D loss: 0.147023, G loss: 8.437896, D accuracy: 96.8%, cell accuracy: 93.4%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.278722, G loss: 10.011407, D accuracy: 95.3%, cell accuracy: 93.1%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4554, G loss: 8.5019\n",
      "[372/8000] D loss: 0.2607, G loss: 8.4510\n",
      "[732/8000] D loss: 0.0350, G loss: 8.7497\n",
      "[1092/8000] D loss: 0.1704, G loss: 8.8817\n",
      "[1452/8000] D loss: 0.2564, G loss: 8.9519\n",
      "[1812/8000] D loss: 0.1937, G loss: 6.2230\n",
      "[2172/8000] D loss: 0.0256, G loss: 7.8334\n",
      "[2532/8000] D loss: 0.1663, G loss: 7.1876\n",
      "[2892/8000] D loss: 0.1908, G loss: 9.2072\n",
      "[3252/8000] D loss: 0.0447, G loss: 9.2036\n",
      "[3612/8000] D loss: 0.1166, G loss: 6.0188\n",
      "[3972/8000] D loss: 0.3217, G loss: 7.4744\n",
      "[4332/8000] D loss: 0.3859, G loss: 6.1403\n",
      "[4692/8000] D loss: 0.0426, G loss: 8.8421\n",
      "[5052/8000] D loss: 0.0391, G loss: 12.4125\n",
      "[5412/8000] D loss: 0.3351, G loss: 6.9906\n",
      "[5772/8000] D loss: 0.1120, G loss: 7.3661\n",
      "[6132/8000] D loss: 0.0273, G loss: 8.7216\n",
      "[6492/8000] D loss: 0.1454, G loss: 5.8454\n",
      "[6852/8000] D loss: 0.2190, G loss: 8.9405\n",
      "[7212/8000] D loss: 0.1787, G loss: 6.1698\n",
      "[7572/8000] D loss: 0.0289, G loss: 7.0736\n",
      "[7932/8000] D loss: 0.0985, G loss: 5.8426\n",
      "train error: \n",
      " D loss: 0.248224, G loss: 9.261726, D accuracy: 94.3%, cell accuracy: 93.3%, board accuracy: 3.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.440751, G loss: 10.762074, D accuracy: 92.4%, cell accuracy: 93.0%, board accuracy: 1.7% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3596, G loss: 8.6309\n",
      "[372/8000] D loss: 0.1170, G loss: 8.9051\n",
      "[732/8000] D loss: 0.0415, G loss: 9.5724\n",
      "[1092/8000] D loss: 0.2753, G loss: 8.5437\n",
      "[1452/8000] D loss: 0.0489, G loss: 7.9116\n",
      "[1812/8000] D loss: 0.1587, G loss: 7.7325\n",
      "[2172/8000] D loss: 0.0077, G loss: 8.2664\n",
      "[2532/8000] D loss: 0.2603, G loss: 8.7583\n",
      "[2892/8000] D loss: 0.1116, G loss: 9.0690\n",
      "[3252/8000] D loss: 0.0414, G loss: 11.6661\n",
      "[3612/8000] D loss: 0.2669, G loss: 9.0103\n",
      "[3972/8000] D loss: 0.5546, G loss: 6.6091\n",
      "[4332/8000] D loss: 0.1183, G loss: 7.8036\n",
      "[4692/8000] D loss: 0.0660, G loss: 8.2498\n",
      "[5052/8000] D loss: 0.1841, G loss: 6.6380\n",
      "[5412/8000] D loss: 0.0110, G loss: 11.8594\n",
      "[5772/8000] D loss: 0.1250, G loss: 7.9444\n",
      "[6132/8000] D loss: 0.2082, G loss: 5.9049\n",
      "[6492/8000] D loss: 0.0117, G loss: 12.1483\n",
      "[6852/8000] D loss: 0.2134, G loss: 10.2793\n",
      "[7212/8000] D loss: 0.1695, G loss: 7.5149\n",
      "[7572/8000] D loss: 0.1980, G loss: 6.9200\n",
      "[7932/8000] D loss: 0.0748, G loss: 8.4566\n",
      "train error: \n",
      " D loss: 0.172357, G loss: 8.895910, D accuracy: 96.2%, cell accuracy: 93.3%, board accuracy: 3.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.324911, G loss: 10.557004, D accuracy: 95.0%, cell accuracy: 93.0%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0473, G loss: 9.6499\n",
      "[372/8000] D loss: 0.2449, G loss: 9.8164\n",
      "[732/8000] D loss: 0.0451, G loss: 8.5370\n",
      "[1092/8000] D loss: 0.1592, G loss: 9.5211\n",
      "[1452/8000] D loss: 0.1327, G loss: 8.6760\n",
      "[1812/8000] D loss: 0.0921, G loss: 7.8121\n",
      "[2172/8000] D loss: 0.0086, G loss: 8.9967\n",
      "[2532/8000] D loss: 0.3828, G loss: 9.3800\n",
      "[2892/8000] D loss: 0.0050, G loss: 12.0380\n",
      "[3252/8000] D loss: 0.1055, G loss: 5.7201\n",
      "[3612/8000] D loss: 0.0487, G loss: 12.3613\n",
      "[3972/8000] D loss: 0.3321, G loss: 9.1470\n",
      "[4332/8000] D loss: 0.1307, G loss: 12.1395\n",
      "[4692/8000] D loss: 0.1374, G loss: 6.9815\n",
      "[5052/8000] D loss: 0.2452, G loss: 9.1386\n",
      "[5412/8000] D loss: 0.0537, G loss: 9.5930\n",
      "[5772/8000] D loss: 0.4156, G loss: 5.8594\n",
      "[6132/8000] D loss: 0.0398, G loss: 6.7364\n",
      "[6492/8000] D loss: 0.1408, G loss: 7.1213\n",
      "[6852/8000] D loss: 0.1744, G loss: 7.8617\n",
      "[7212/8000] D loss: 0.3494, G loss: 8.5778\n",
      "[7572/8000] D loss: 0.0270, G loss: 7.8471\n",
      "[7932/8000] D loss: 0.0669, G loss: 10.3932\n",
      "train error: \n",
      " D loss: 0.309697, G loss: 6.330139, D accuracy: 93.4%, cell accuracy: 93.3%, board accuracy: 3.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.258438, G loss: 7.945282, D accuracy: 95.4%, cell accuracy: 93.0%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5109, G loss: 5.9267\n",
      "[372/8000] D loss: 0.1863, G loss: 8.6503\n",
      "[732/8000] D loss: 0.2043, G loss: 6.9726\n",
      "[1092/8000] D loss: 0.1230, G loss: 6.9389\n",
      "[1452/8000] D loss: 0.1931, G loss: 7.6247\n",
      "[1812/8000] D loss: 0.2386, G loss: 8.1455\n",
      "[2172/8000] D loss: 0.2864, G loss: 6.4364\n",
      "[2532/8000] D loss: 0.0343, G loss: 9.3394\n",
      "[2892/8000] D loss: 0.0211, G loss: 8.1391\n",
      "[3252/8000] D loss: 0.0231, G loss: 12.2665\n",
      "[3612/8000] D loss: 0.2526, G loss: 5.5796\n",
      "[3972/8000] D loss: 0.1471, G loss: 10.6973\n",
      "[4332/8000] D loss: 0.0590, G loss: 5.6224\n",
      "[4692/8000] D loss: 0.2932, G loss: 6.7655\n",
      "[5052/8000] D loss: 0.2946, G loss: 9.8707\n",
      "[5412/8000] D loss: 0.1429, G loss: 8.7443\n",
      "[5772/8000] D loss: 0.1466, G loss: 7.9223\n",
      "[6132/8000] D loss: 0.1653, G loss: 11.0193\n",
      "[6492/8000] D loss: 0.2020, G loss: 9.3689\n",
      "[6852/8000] D loss: 0.1876, G loss: 10.9337\n",
      "[7212/8000] D loss: 0.3438, G loss: 9.0975\n",
      "[7572/8000] D loss: 0.0364, G loss: 9.1031\n",
      "[7932/8000] D loss: 0.5305, G loss: 6.2110\n",
      "train error: \n",
      " D loss: 0.158051, G loss: 8.107214, D accuracy: 96.5%, cell accuracy: 93.3%, board accuracy: 3.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.279455, G loss: 9.769659, D accuracy: 95.5%, cell accuracy: 93.0%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0293, G loss: 10.2911\n",
      "[372/8000] D loss: 0.0406, G loss: 8.0828\n",
      "[732/8000] D loss: 0.3100, G loss: 4.9466\n",
      "[1092/8000] D loss: 0.1218, G loss: 10.5738\n",
      "[1452/8000] D loss: 0.0197, G loss: 9.7840\n",
      "[1812/8000] D loss: 0.0712, G loss: 10.6780\n",
      "[2172/8000] D loss: 0.1509, G loss: 8.0072\n",
      "[2532/8000] D loss: 0.0646, G loss: 8.8591\n",
      "[2892/8000] D loss: 0.2568, G loss: 6.1918\n",
      "[3252/8000] D loss: 0.1865, G loss: 6.8502\n",
      "[3612/8000] D loss: 0.0517, G loss: 10.1285\n",
      "[3972/8000] D loss: 0.1293, G loss: 7.1367\n",
      "[4332/8000] D loss: 0.2802, G loss: 9.2967\n",
      "[4692/8000] D loss: 0.1710, G loss: 7.5821\n",
      "[5052/8000] D loss: 0.3235, G loss: 7.4266\n",
      "[5412/8000] D loss: 0.2162, G loss: 8.7982\n",
      "[5772/8000] D loss: 0.1480, G loss: 7.7022\n",
      "[6132/8000] D loss: 0.0129, G loss: 10.0837\n",
      "[6492/8000] D loss: 0.1819, G loss: 7.7185\n",
      "[6852/8000] D loss: 0.1530, G loss: 9.8911\n",
      "[7212/8000] D loss: 0.1865, G loss: 7.4047\n",
      "[7572/8000] D loss: 0.0431, G loss: 7.8403\n",
      "[7932/8000] D loss: 0.1521, G loss: 8.3687\n",
      "train error: \n",
      " D loss: 0.156874, G loss: 8.376854, D accuracy: 96.5%, cell accuracy: 93.3%, board accuracy: 3.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.263424, G loss: 10.043991, D accuracy: 95.8%, cell accuracy: 93.0%, board accuracy: 1.7% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2261, G loss: 7.1157\n",
      "[372/8000] D loss: 0.2281, G loss: 9.0317\n",
      "[732/8000] D loss: 0.2602, G loss: 6.7637\n",
      "[1092/8000] D loss: 0.0647, G loss: 8.1267\n",
      "[1452/8000] D loss: 0.2113, G loss: 6.5928\n",
      "[1812/8000] D loss: 0.3165, G loss: 6.3356\n",
      "[2172/8000] D loss: 0.1481, G loss: 10.1407\n",
      "[2532/8000] D loss: 0.3986, G loss: 8.2558\n",
      "[2892/8000] D loss: 0.0678, G loss: 9.5097\n",
      "[3252/8000] D loss: 0.3579, G loss: 6.2572\n",
      "[3612/8000] D loss: 0.2465, G loss: 4.2522\n",
      "[3972/8000] D loss: 0.1111, G loss: 6.8560\n",
      "[4332/8000] D loss: 0.1263, G loss: 8.5669\n",
      "[4692/8000] D loss: 0.2045, G loss: 8.9702\n",
      "[5052/8000] D loss: 0.0521, G loss: 7.8220\n",
      "[5412/8000] D loss: 0.1702, G loss: 6.3208\n",
      "[5772/8000] D loss: 0.2736, G loss: 8.4254\n",
      "[6132/8000] D loss: 0.2507, G loss: 8.1964\n",
      "[6492/8000] D loss: 0.2653, G loss: 7.1822\n",
      "[6852/8000] D loss: 0.0088, G loss: 8.0056\n",
      "[7212/8000] D loss: 0.3501, G loss: 6.5370\n",
      "[7572/8000] D loss: 0.3929, G loss: 7.6645\n",
      "[7932/8000] D loss: 0.2831, G loss: 8.6305\n",
      "train error: \n",
      " D loss: 0.182842, G loss: 8.384638, D accuracy: 95.9%, cell accuracy: 93.3%, board accuracy: 3.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.272553, G loss: 10.133011, D accuracy: 95.9%, cell accuracy: 93.1%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1131, G loss: 11.0599\n",
      "[372/8000] D loss: 0.0662, G loss: 8.3414\n",
      "[732/8000] D loss: 0.1044, G loss: 5.8383\n",
      "[1092/8000] D loss: 0.2510, G loss: 6.1419\n",
      "[1452/8000] D loss: 0.1737, G loss: 10.6056\n",
      "[1812/8000] D loss: 0.2057, G loss: 7.2512\n",
      "[2172/8000] D loss: 0.3005, G loss: 8.3665\n",
      "[2532/8000] D loss: 0.0435, G loss: 9.9656\n",
      "[2892/8000] D loss: 0.0911, G loss: 11.0583\n",
      "[3252/8000] D loss: 0.0147, G loss: 6.5557\n",
      "[3612/8000] D loss: 0.0656, G loss: 7.8344\n",
      "[3972/8000] D loss: 0.2621, G loss: 7.3425\n",
      "[4332/8000] D loss: 0.1404, G loss: 9.1082\n",
      "[4692/8000] D loss: 0.0603, G loss: 9.9389\n",
      "[5052/8000] D loss: 0.1523, G loss: 8.9195\n",
      "[5412/8000] D loss: 0.0720, G loss: 9.6712\n",
      "[5772/8000] D loss: 0.6024, G loss: 8.2253\n",
      "[6132/8000] D loss: 0.2679, G loss: 6.6310\n",
      "[6492/8000] D loss: 0.1517, G loss: 8.8904\n",
      "[6852/8000] D loss: 0.0247, G loss: 8.9143\n",
      "[7212/8000] D loss: 0.1462, G loss: 6.4132\n",
      "[7572/8000] D loss: 0.1127, G loss: 6.0718\n",
      "[7932/8000] D loss: 0.0341, G loss: 10.7840\n",
      "train error: \n",
      " D loss: 0.183039, G loss: 8.261782, D accuracy: 95.9%, cell accuracy: 93.3%, board accuracy: 3.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.315458, G loss: 9.883307, D accuracy: 94.9%, cell accuracy: 93.0%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3710, G loss: 7.1368\n",
      "[372/8000] D loss: 0.0181, G loss: 9.8494\n",
      "[732/8000] D loss: 0.2344, G loss: 7.3092\n",
      "[1092/8000] D loss: 0.0996, G loss: 9.7423\n",
      "[1452/8000] D loss: 0.0876, G loss: 6.0452\n",
      "[1812/8000] D loss: 0.1421, G loss: 7.3669\n",
      "[2172/8000] D loss: 0.1720, G loss: 7.3373\n",
      "[2532/8000] D loss: 0.2213, G loss: 6.8980\n",
      "[2892/8000] D loss: 0.0132, G loss: 9.3352\n",
      "[3252/8000] D loss: 0.0252, G loss: 8.7744\n",
      "[3612/8000] D loss: 0.2755, G loss: 9.1263\n",
      "[3972/8000] D loss: 0.1214, G loss: 7.4592\n",
      "[4332/8000] D loss: 0.4864, G loss: 8.3885\n",
      "[4692/8000] D loss: 0.0858, G loss: 7.4117\n",
      "[5052/8000] D loss: 0.1299, G loss: 7.2133\n",
      "[5412/8000] D loss: 0.2600, G loss: 6.7894\n",
      "[5772/8000] D loss: 0.1329, G loss: 7.0328\n",
      "[6132/8000] D loss: 0.0651, G loss: 8.9977\n",
      "[6492/8000] D loss: 0.0443, G loss: 9.2687\n",
      "[6852/8000] D loss: 0.6087, G loss: 6.1468\n",
      "[7212/8000] D loss: 0.1890, G loss: 5.7992\n",
      "[7572/8000] D loss: 0.3511, G loss: 7.5241\n",
      "[7932/8000] D loss: 0.1330, G loss: 6.5508\n",
      "train error: \n",
      " D loss: 0.184514, G loss: 7.383218, D accuracy: 96.0%, cell accuracy: 93.3%, board accuracy: 3.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.240935, G loss: 9.099432, D accuracy: 95.7%, cell accuracy: 93.0%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2212, G loss: 5.6691\n",
      "[372/8000] D loss: 0.3324, G loss: 6.0873\n",
      "[732/8000] D loss: 0.2469, G loss: 6.7245\n",
      "[1092/8000] D loss: 0.1034, G loss: 7.1781\n",
      "[1452/8000] D loss: 0.2671, G loss: 9.1595\n",
      "[1812/8000] D loss: 0.0818, G loss: 8.9110\n",
      "[2172/8000] D loss: 0.0438, G loss: 7.8711\n",
      "[2532/8000] D loss: 0.0395, G loss: 7.0865\n",
      "[2892/8000] D loss: 0.3248, G loss: 8.8962\n",
      "[3252/8000] D loss: 0.0416, G loss: 8.2330\n",
      "[3612/8000] D loss: 0.4824, G loss: 8.1548\n",
      "[3972/8000] D loss: 0.1344, G loss: 9.5503\n",
      "[4332/8000] D loss: 0.2284, G loss: 8.2597\n",
      "[4692/8000] D loss: 0.0050, G loss: 12.0364\n",
      "[5052/8000] D loss: 0.3815, G loss: 7.0274\n",
      "[5412/8000] D loss: 0.4243, G loss: 9.9235\n",
      "[5772/8000] D loss: 0.0477, G loss: 10.0655\n",
      "[6132/8000] D loss: 0.0681, G loss: 9.1921\n",
      "[6492/8000] D loss: 0.4168, G loss: 6.1695\n",
      "[6852/8000] D loss: 0.1726, G loss: 9.3851\n",
      "[7212/8000] D loss: 0.1290, G loss: 8.7526\n",
      "[7572/8000] D loss: 0.0894, G loss: 6.7289\n",
      "[7932/8000] D loss: 0.0725, G loss: 7.9681\n",
      "train error: \n",
      " D loss: 0.145583, G loss: 8.308209, D accuracy: 96.9%, cell accuracy: 93.3%, board accuracy: 3.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.286869, G loss: 9.929217, D accuracy: 95.2%, cell accuracy: 93.0%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0114, G loss: 10.0972\n",
      "[372/8000] D loss: 0.0173, G loss: 9.8884\n",
      "[732/8000] D loss: 0.0151, G loss: 10.5372\n",
      "[1092/8000] D loss: 0.2331, G loss: 7.2222\n",
      "[1452/8000] D loss: 0.0025, G loss: 10.6408\n",
      "[1812/8000] D loss: 0.2310, G loss: 7.8991\n",
      "[2172/8000] D loss: 0.2859, G loss: 9.6449\n",
      "[2532/8000] D loss: 0.1505, G loss: 7.1355\n",
      "[2892/8000] D loss: 0.0454, G loss: 7.8566\n",
      "[3252/8000] D loss: 0.1307, G loss: 9.6979\n",
      "[3612/8000] D loss: 0.1194, G loss: 7.0034\n",
      "[3972/8000] D loss: 0.2134, G loss: 5.6302\n",
      "[4332/8000] D loss: 0.0159, G loss: 10.1967\n",
      "[4692/8000] D loss: 0.1900, G loss: 8.9227\n",
      "[5052/8000] D loss: 0.1482, G loss: 8.1189\n",
      "[5412/8000] D loss: 0.0341, G loss: 9.4546\n",
      "[5772/8000] D loss: 0.0697, G loss: 11.1027\n",
      "[6132/8000] D loss: 0.0314, G loss: 9.6179\n",
      "[6492/8000] D loss: 0.1849, G loss: 6.2585\n",
      "[6852/8000] D loss: 0.2572, G loss: 8.8500\n",
      "[7212/8000] D loss: 0.0009, G loss: 12.7661\n",
      "[7572/8000] D loss: 0.1662, G loss: 9.6735\n",
      "[7932/8000] D loss: 0.0088, G loss: 9.4039\n",
      "train error: \n",
      " D loss: 0.170339, G loss: 7.803705, D accuracy: 96.2%, cell accuracy: 93.3%, board accuracy: 3.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.239636, G loss: 9.629305, D accuracy: 96.1%, cell accuracy: 93.1%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2212, G loss: 8.7050\n",
      "[372/8000] D loss: 0.2529, G loss: 7.7249\n",
      "[732/8000] D loss: 0.1365, G loss: 7.9860\n",
      "[1092/8000] D loss: 0.1495, G loss: 9.4332\n",
      "[1452/8000] D loss: 0.1645, G loss: 9.2926\n",
      "[1812/8000] D loss: 0.0866, G loss: 10.2635\n",
      "[2172/8000] D loss: 0.2008, G loss: 7.5374\n",
      "[2532/8000] D loss: 0.2228, G loss: 7.8093\n",
      "[2892/8000] D loss: 0.1156, G loss: 8.0958\n",
      "[3252/8000] D loss: 0.0852, G loss: 8.4542\n",
      "[3612/8000] D loss: 0.1215, G loss: 9.6075\n",
      "[3972/8000] D loss: 0.0264, G loss: 11.1767\n",
      "[4332/8000] D loss: 0.0097, G loss: 10.9188\n",
      "[4692/8000] D loss: 0.2536, G loss: 6.1865\n",
      "[5052/8000] D loss: 0.0721, G loss: 7.4124\n",
      "[5412/8000] D loss: 0.1335, G loss: 8.8842\n",
      "[5772/8000] D loss: 0.1052, G loss: 7.4237\n",
      "[6132/8000] D loss: 0.4845, G loss: 6.9953\n",
      "[6492/8000] D loss: 0.1910, G loss: 7.5598\n",
      "[6852/8000] D loss: 0.1311, G loss: 8.1998\n",
      "[7212/8000] D loss: 0.0140, G loss: 10.9008\n",
      "[7572/8000] D loss: 0.1236, G loss: 7.8470\n",
      "[7932/8000] D loss: 0.1827, G loss: 7.2662\n",
      "train error: \n",
      " D loss: 0.193037, G loss: 7.366230, D accuracy: 95.9%, cell accuracy: 93.3%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.256729, G loss: 9.167352, D accuracy: 96.0%, cell accuracy: 93.1%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1892, G loss: 8.2976\n",
      "[372/8000] D loss: 0.0333, G loss: 8.1875\n",
      "[732/8000] D loss: 0.0285, G loss: 9.2636\n",
      "[1092/8000] D loss: 0.1417, G loss: 7.6472\n",
      "[1452/8000] D loss: 0.1303, G loss: 10.9861\n",
      "[1812/8000] D loss: 0.2566, G loss: 8.3914\n",
      "[2172/8000] D loss: 0.0439, G loss: 10.6187\n",
      "[2532/8000] D loss: 0.3236, G loss: 7.1287\n",
      "[2892/8000] D loss: 0.1734, G loss: 7.4972\n",
      "[3252/8000] D loss: 0.1882, G loss: 7.3906\n",
      "[3612/8000] D loss: 0.0221, G loss: 7.8925\n",
      "[3972/8000] D loss: 0.0325, G loss: 7.9872\n",
      "[4332/8000] D loss: 0.2961, G loss: 8.6115\n",
      "[4692/8000] D loss: 0.4033, G loss: 6.0446\n",
      "[5052/8000] D loss: 0.1646, G loss: 7.9125\n",
      "[5412/8000] D loss: 0.2687, G loss: 8.5050\n",
      "[5772/8000] D loss: 0.2446, G loss: 7.5706\n",
      "[6132/8000] D loss: 0.1793, G loss: 6.7524\n",
      "[6492/8000] D loss: 0.2744, G loss: 9.3318\n",
      "[6852/8000] D loss: 0.0805, G loss: 7.3417\n",
      "[7212/8000] D loss: 0.0820, G loss: 6.3239\n",
      "[7572/8000] D loss: 0.2596, G loss: 6.1524\n",
      "[7932/8000] D loss: 0.2959, G loss: 7.4655\n",
      "train error: \n",
      " D loss: 0.205256, G loss: 8.959677, D accuracy: 95.5%, cell accuracy: 93.3%, board accuracy: 3.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.358634, G loss: 10.633394, D accuracy: 94.4%, cell accuracy: 93.0%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1714, G loss: 10.5814\n",
      "[372/8000] D loss: 0.1170, G loss: 5.2683\n",
      "[732/8000] D loss: 0.0225, G loss: 7.9267\n",
      "[1092/8000] D loss: 0.1387, G loss: 7.1148\n",
      "[1452/8000] D loss: 0.1195, G loss: 10.2835\n",
      "[1812/8000] D loss: 0.0330, G loss: 10.9360\n",
      "[2172/8000] D loss: 0.1552, G loss: 8.1168\n",
      "[2532/8000] D loss: 0.1535, G loss: 6.1769\n",
      "[2892/8000] D loss: 0.2113, G loss: 7.6104\n",
      "[3252/8000] D loss: 0.2236, G loss: 9.0484\n",
      "[3612/8000] D loss: 0.1382, G loss: 7.6688\n",
      "[3972/8000] D loss: 0.0299, G loss: 10.7421\n",
      "[4332/8000] D loss: 0.1084, G loss: 8.4280\n",
      "[4692/8000] D loss: 0.4663, G loss: 7.0609\n",
      "[5052/8000] D loss: 0.5367, G loss: 4.6561\n",
      "[5412/8000] D loss: 0.0784, G loss: 10.6078\n",
      "[5772/8000] D loss: 0.4553, G loss: 6.4023\n",
      "[6132/8000] D loss: 0.2622, G loss: 5.4007\n",
      "[6492/8000] D loss: 0.0129, G loss: 8.3190\n",
      "[6852/8000] D loss: 0.1195, G loss: 11.0416\n",
      "[7212/8000] D loss: 0.0017, G loss: 12.0412\n",
      "[7572/8000] D loss: 0.0816, G loss: 10.3496\n",
      "[7932/8000] D loss: 0.1974, G loss: 8.4485\n",
      "train error: \n",
      " D loss: 0.181308, G loss: 8.044648, D accuracy: 96.1%, cell accuracy: 93.3%, board accuracy: 3.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.312052, G loss: 9.807108, D accuracy: 95.1%, cell accuracy: 93.0%, board accuracy: 1.9% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2053, G loss: 7.9416\n",
      "[372/8000] D loss: 0.0289, G loss: 9.0684\n",
      "[732/8000] D loss: 0.0550, G loss: 10.4457\n",
      "[1092/8000] D loss: 0.3477, G loss: 5.1098\n",
      "[1452/8000] D loss: 0.6261, G loss: 5.7302\n",
      "[1812/8000] D loss: 0.0502, G loss: 7.7662\n",
      "[2172/8000] D loss: 0.0053, G loss: 10.4740\n",
      "[2532/8000] D loss: 0.3619, G loss: 6.4102\n",
      "[2892/8000] D loss: 0.0073, G loss: 8.8224\n",
      "[3252/8000] D loss: 0.0081, G loss: 10.5494\n",
      "[3612/8000] D loss: 0.1607, G loss: 12.2126\n",
      "[3972/8000] D loss: 0.3365, G loss: 7.7069\n",
      "[4332/8000] D loss: 0.0856, G loss: 10.5640\n",
      "[4692/8000] D loss: 0.3426, G loss: 7.5329\n",
      "[5052/8000] D loss: 0.0277, G loss: 9.3016\n",
      "[5412/8000] D loss: 0.4103, G loss: 8.0065\n",
      "[5772/8000] D loss: 0.0043, G loss: 11.6776\n",
      "[6132/8000] D loss: 0.0514, G loss: 10.4740\n",
      "[6492/8000] D loss: 0.0918, G loss: 7.6641\n",
      "[6852/8000] D loss: 0.2986, G loss: 4.9714\n",
      "[7212/8000] D loss: 0.2033, G loss: 7.8889\n",
      "[7572/8000] D loss: 0.6548, G loss: 5.0001\n",
      "[7932/8000] D loss: 0.0506, G loss: 8.6056\n",
      "train error: \n",
      " D loss: 0.188651, G loss: 7.235184, D accuracy: 95.8%, cell accuracy: 93.3%, board accuracy: 3.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.245541, G loss: 8.948791, D accuracy: 95.7%, cell accuracy: 93.0%, board accuracy: 1.9% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2244, G loss: 9.3112\n",
      "[372/8000] D loss: 0.0572, G loss: 8.2482\n",
      "[732/8000] D loss: 0.2060, G loss: 8.4990\n",
      "[1092/8000] D loss: 0.4177, G loss: 5.2109\n",
      "[1452/8000] D loss: 0.0616, G loss: 8.9743\n",
      "[1812/8000] D loss: 0.2800, G loss: 5.5585\n",
      "[2172/8000] D loss: 0.2798, G loss: 7.1761\n",
      "[2532/8000] D loss: 0.3355, G loss: 7.5965\n",
      "[2892/8000] D loss: 0.2403, G loss: 6.6038\n",
      "[3252/8000] D loss: 0.1635, G loss: 7.4342\n",
      "[3612/8000] D loss: 0.2791, G loss: 6.6014\n",
      "[3972/8000] D loss: 0.1030, G loss: 10.8606\n",
      "[4332/8000] D loss: 0.0347, G loss: 7.6905\n",
      "[4692/8000] D loss: 0.0778, G loss: 10.3563\n",
      "[5052/8000] D loss: 0.2605, G loss: 10.3474\n",
      "[5412/8000] D loss: 0.2346, G loss: 4.5327\n",
      "[5772/8000] D loss: 0.0096, G loss: 10.5836\n",
      "[6132/8000] D loss: 0.1742, G loss: 7.6243\n",
      "[6492/8000] D loss: 0.0211, G loss: 9.6366\n",
      "[6852/8000] D loss: 0.1292, G loss: 8.3371\n",
      "[7212/8000] D loss: 0.0275, G loss: 10.2464\n",
      "[7572/8000] D loss: 0.0452, G loss: 7.6824\n",
      "[7932/8000] D loss: 0.0948, G loss: 6.8690\n",
      "train error: \n",
      " D loss: 0.186954, G loss: 8.690427, D accuracy: 95.8%, cell accuracy: 93.4%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.339077, G loss: 10.444067, D accuracy: 94.6%, cell accuracy: 93.1%, board accuracy: 1.7% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1758, G loss: 10.9974\n",
      "[372/8000] D loss: 0.0332, G loss: 9.8937\n",
      "[732/8000] D loss: 0.3259, G loss: 6.1582\n",
      "[1092/8000] D loss: 0.1345, G loss: 7.1181\n",
      "[1452/8000] D loss: 0.4425, G loss: 7.7268\n",
      "[1812/8000] D loss: 0.3451, G loss: 5.4431\n",
      "[2172/8000] D loss: 0.1726, G loss: 11.9899\n",
      "[2532/8000] D loss: 0.0252, G loss: 7.1729\n",
      "[2892/8000] D loss: 0.1828, G loss: 6.6569\n",
      "[3252/8000] D loss: 0.2671, G loss: 8.1433\n",
      "[3612/8000] D loss: 0.2154, G loss: 7.6087\n",
      "[3972/8000] D loss: 0.2513, G loss: 8.3064\n",
      "[4332/8000] D loss: 0.0621, G loss: 11.5791\n",
      "[4692/8000] D loss: 0.0242, G loss: 6.7159\n",
      "[5052/8000] D loss: 0.1476, G loss: 10.1654\n",
      "[5412/8000] D loss: 0.0622, G loss: 8.0741\n",
      "[5772/8000] D loss: 0.0451, G loss: 11.7641\n",
      "[6132/8000] D loss: 0.1132, G loss: 10.0469\n",
      "[6492/8000] D loss: 0.1625, G loss: 7.8538\n",
      "[6852/8000] D loss: 0.0606, G loss: 11.9401\n",
      "[7212/8000] D loss: 0.5756, G loss: 8.8828\n",
      "[7572/8000] D loss: 0.2898, G loss: 4.8226\n",
      "[7932/8000] D loss: 0.0590, G loss: 7.1406\n",
      "train error: \n",
      " D loss: 0.178741, G loss: 8.802669, D accuracy: 95.8%, cell accuracy: 93.4%, board accuracy: 3.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.298091, G loss: 10.643272, D accuracy: 95.6%, cell accuracy: 93.1%, board accuracy: 2.1% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1104, G loss: 10.1410\n",
      "[372/8000] D loss: 0.3491, G loss: 6.2116\n",
      "[732/8000] D loss: 0.0874, G loss: 9.2345\n",
      "[1092/8000] D loss: 0.0320, G loss: 7.9959\n",
      "[1452/8000] D loss: 0.0082, G loss: 9.0340\n",
      "[1812/8000] D loss: 0.1726, G loss: 6.8170\n",
      "[2172/8000] D loss: 0.0296, G loss: 10.0205\n",
      "[2532/8000] D loss: 0.0364, G loss: 8.9156\n",
      "[2892/8000] D loss: 0.1126, G loss: 12.3966\n",
      "[3252/8000] D loss: 0.2014, G loss: 9.7093\n",
      "[3612/8000] D loss: 0.0696, G loss: 8.2612\n",
      "[3972/8000] D loss: 0.3481, G loss: 9.9426\n",
      "[4332/8000] D loss: 0.4907, G loss: 5.1955\n",
      "[4692/8000] D loss: 0.3826, G loss: 6.8254\n",
      "[5052/8000] D loss: 0.1884, G loss: 8.4796\n",
      "[5412/8000] D loss: 0.2661, G loss: 8.5932\n",
      "[5772/8000] D loss: 0.0908, G loss: 7.6793\n",
      "[6132/8000] D loss: 0.1887, G loss: 11.3336\n",
      "[6492/8000] D loss: 0.0895, G loss: 7.7951\n",
      "[6852/8000] D loss: 0.1340, G loss: 7.2396\n",
      "[7212/8000] D loss: 0.2813, G loss: 7.0878\n",
      "[7572/8000] D loss: 0.1835, G loss: 7.5619\n",
      "[7932/8000] D loss: 0.3695, G loss: 6.6563\n",
      "train error: \n",
      " D loss: 0.184885, G loss: 8.047265, D accuracy: 95.7%, cell accuracy: 93.4%, board accuracy: 3.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.281783, G loss: 9.917063, D accuracy: 95.8%, cell accuracy: 93.1%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0377, G loss: 12.1228\n",
      "[372/8000] D loss: 0.0207, G loss: 10.6748\n",
      "[732/8000] D loss: 0.0058, G loss: 11.9058\n",
      "[1092/8000] D loss: 0.0349, G loss: 8.2903\n",
      "[1452/8000] D loss: 0.2150, G loss: 7.3813\n",
      "[1812/8000] D loss: 0.0417, G loss: 9.0787\n",
      "[2172/8000] D loss: 0.0251, G loss: 8.6207\n",
      "[2532/8000] D loss: 0.0124, G loss: 7.7959\n",
      "[2892/8000] D loss: 0.1598, G loss: 11.6397\n",
      "[3252/8000] D loss: 0.1144, G loss: 8.8806\n",
      "[3612/8000] D loss: 0.3762, G loss: 6.8332\n",
      "[3972/8000] D loss: 0.1348, G loss: 8.0082\n",
      "[4332/8000] D loss: 0.0855, G loss: 11.0933\n",
      "[4692/8000] D loss: 0.2803, G loss: 9.2387\n",
      "[5052/8000] D loss: 0.3421, G loss: 5.4685\n",
      "[5412/8000] D loss: 0.1646, G loss: 5.8758\n",
      "[5772/8000] D loss: 0.1947, G loss: 7.8096\n",
      "[6132/8000] D loss: 0.2006, G loss: 10.6859\n",
      "[6492/8000] D loss: 0.0550, G loss: 8.0705\n",
      "[6852/8000] D loss: 0.1700, G loss: 8.8505\n",
      "[7212/8000] D loss: 0.0056, G loss: 9.8682\n",
      "[7572/8000] D loss: 0.0351, G loss: 7.8944\n",
      "[7932/8000] D loss: 0.1180, G loss: 6.9928\n",
      "train error: \n",
      " D loss: 0.170791, G loss: 8.736309, D accuracy: 96.1%, cell accuracy: 93.4%, board accuracy: 4.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.307892, G loss: 10.559419, D accuracy: 95.4%, cell accuracy: 93.2%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3586, G loss: 6.3334\n",
      "[372/8000] D loss: 0.0932, G loss: 9.0890\n",
      "[732/8000] D loss: 0.0847, G loss: 6.0320\n",
      "[1092/8000] D loss: 0.3517, G loss: 5.7744\n",
      "[1452/8000] D loss: 0.2300, G loss: 9.5424\n",
      "[1812/8000] D loss: 0.1335, G loss: 8.9562\n",
      "[2172/8000] D loss: 0.3186, G loss: 8.0158\n",
      "[2532/8000] D loss: 0.2256, G loss: 8.6310\n",
      "[2892/8000] D loss: 0.1636, G loss: 11.3122\n",
      "[3252/8000] D loss: 0.0579, G loss: 10.6579\n",
      "[3612/8000] D loss: 0.0893, G loss: 9.1097\n",
      "[3972/8000] D loss: 0.0990, G loss: 8.3493\n",
      "[4332/8000] D loss: 0.1991, G loss: 8.2593\n",
      "[4692/8000] D loss: 0.2544, G loss: 6.6019\n",
      "[5052/8000] D loss: 0.1854, G loss: 9.7157\n",
      "[5412/8000] D loss: 0.0393, G loss: 7.2927\n",
      "[5772/8000] D loss: 0.2654, G loss: 10.5331\n",
      "[6132/8000] D loss: 0.8856, G loss: 10.3564\n",
      "[6492/8000] D loss: 0.0487, G loss: 8.9017\n",
      "[6852/8000] D loss: 0.0461, G loss: 11.1401\n",
      "[7212/8000] D loss: 0.2379, G loss: 7.2931\n",
      "[7572/8000] D loss: 0.0212, G loss: 8.8823\n",
      "[7932/8000] D loss: 0.3957, G loss: 7.1321\n",
      "train error: \n",
      " D loss: 0.158299, G loss: 8.386276, D accuracy: 96.5%, cell accuracy: 93.4%, board accuracy: 3.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.278083, G loss: 10.204498, D accuracy: 95.4%, cell accuracy: 93.1%, board accuracy: 1.9% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0303, G loss: 10.6306\n",
      "[372/8000] D loss: 0.2231, G loss: 7.5085\n",
      "[732/8000] D loss: 0.0582, G loss: 9.5549\n",
      "[1092/8000] D loss: 0.2398, G loss: 7.2310\n",
      "[1452/8000] D loss: 0.1231, G loss: 6.8402\n",
      "[1812/8000] D loss: 0.1984, G loss: 8.9099\n",
      "[2172/8000] D loss: 0.0766, G loss: 8.1358\n",
      "[2532/8000] D loss: 0.0640, G loss: 6.9102\n",
      "[2892/8000] D loss: 0.2480, G loss: 5.9557\n",
      "[3252/8000] D loss: 0.2881, G loss: 7.9942\n",
      "[3612/8000] D loss: 0.3241, G loss: 6.6666\n",
      "[3972/8000] D loss: 0.4495, G loss: 6.6952\n",
      "[4332/8000] D loss: 0.0317, G loss: 12.0372\n",
      "[4692/8000] D loss: 0.4969, G loss: 6.9343\n",
      "[5052/8000] D loss: 0.3859, G loss: 8.5946\n",
      "[5412/8000] D loss: 0.2728, G loss: 9.3358\n",
      "[5772/8000] D loss: 0.4894, G loss: 8.9586\n",
      "[6132/8000] D loss: 0.1618, G loss: 7.3464\n",
      "[6492/8000] D loss: 0.0175, G loss: 8.5244\n",
      "[6852/8000] D loss: 0.2812, G loss: 11.4454\n",
      "[7212/8000] D loss: 0.4588, G loss: 8.6977\n",
      "[7572/8000] D loss: 0.0956, G loss: 10.0281\n",
      "[7932/8000] D loss: 0.1572, G loss: 7.6284\n",
      "train error: \n",
      " D loss: 0.175582, G loss: 9.381041, D accuracy: 96.0%, cell accuracy: 93.4%, board accuracy: 4.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.345585, G loss: 11.309221, D accuracy: 95.1%, cell accuracy: 93.1%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3054, G loss: 7.4769\n",
      "[372/8000] D loss: 0.3512, G loss: 6.7256\n",
      "[732/8000] D loss: 0.2059, G loss: 8.5105\n",
      "[1092/8000] D loss: 0.0997, G loss: 7.7517\n",
      "[1452/8000] D loss: 0.0704, G loss: 8.9094\n",
      "[1812/8000] D loss: 0.3085, G loss: 8.4401\n",
      "[2172/8000] D loss: 0.0764, G loss: 6.9527\n",
      "[2532/8000] D loss: 0.0147, G loss: 8.1271\n",
      "[2892/8000] D loss: 0.0442, G loss: 10.2897\n",
      "[3252/8000] D loss: 0.0644, G loss: 8.7027\n",
      "[3612/8000] D loss: 0.1837, G loss: 8.1913\n",
      "[3972/8000] D loss: 0.2627, G loss: 6.2242\n",
      "[4332/8000] D loss: 0.2635, G loss: 7.7280\n",
      "[4692/8000] D loss: 0.2023, G loss: 8.0097\n",
      "[5052/8000] D loss: 0.0481, G loss: 9.8869\n",
      "[5412/8000] D loss: 0.4631, G loss: 6.0788\n",
      "[5772/8000] D loss: 0.1503, G loss: 8.3810\n",
      "[6132/8000] D loss: 0.4326, G loss: 6.1346\n",
      "[6492/8000] D loss: 0.0955, G loss: 8.9630\n",
      "[6852/8000] D loss: 0.0161, G loss: 9.0024\n",
      "[7212/8000] D loss: 0.1024, G loss: 12.6851\n",
      "[7572/8000] D loss: 0.0582, G loss: 8.9673\n",
      "[7932/8000] D loss: 0.0472, G loss: 9.0693\n",
      "train error: \n",
      " D loss: 0.166705, G loss: 8.054799, D accuracy: 96.1%, cell accuracy: 93.4%, board accuracy: 4.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.272255, G loss: 9.815254, D accuracy: 95.4%, cell accuracy: 93.1%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2615, G loss: 8.9527\n",
      "[372/8000] D loss: 0.0876, G loss: 9.4319\n",
      "[732/8000] D loss: 0.0489, G loss: 10.4731\n",
      "[1092/8000] D loss: 0.3142, G loss: 7.7750\n",
      "[1452/8000] D loss: 0.0121, G loss: 10.2776\n",
      "[1812/8000] D loss: 0.2224, G loss: 8.4740\n",
      "[2172/8000] D loss: 0.2446, G loss: 6.2942\n",
      "[2532/8000] D loss: 0.1467, G loss: 8.4362\n",
      "[2892/8000] D loss: 0.5118, G loss: 5.3736\n",
      "[3252/8000] D loss: 0.0357, G loss: 10.6565\n",
      "[3612/8000] D loss: 0.1440, G loss: 6.3416\n",
      "[3972/8000] D loss: 0.0810, G loss: 8.0185\n",
      "[4332/8000] D loss: 0.1525, G loss: 9.7354\n",
      "[4692/8000] D loss: 0.2735, G loss: 5.7701\n",
      "[5052/8000] D loss: 0.0487, G loss: 9.5931\n",
      "[5412/8000] D loss: 0.1506, G loss: 10.4432\n",
      "[5772/8000] D loss: 0.3073, G loss: 6.6307\n",
      "[6132/8000] D loss: 0.2980, G loss: 9.4953\n",
      "[6492/8000] D loss: 0.2334, G loss: 6.7934\n",
      "[6852/8000] D loss: 0.1555, G loss: 8.0519\n",
      "[7212/8000] D loss: 0.3856, G loss: 7.7027\n",
      "[7572/8000] D loss: 0.3499, G loss: 8.3540\n",
      "[7932/8000] D loss: 0.5762, G loss: 6.6651\n",
      "train error: \n",
      " D loss: 0.176321, G loss: 9.714007, D accuracy: 95.9%, cell accuracy: 93.5%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.380173, G loss: 11.610022, D accuracy: 94.1%, cell accuracy: 93.2%, board accuracy: 1.9% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1652, G loss: 8.1268\n",
      "[372/8000] D loss: 0.0264, G loss: 11.9597\n",
      "[732/8000] D loss: 0.1498, G loss: 8.8648\n",
      "[1092/8000] D loss: 0.0395, G loss: 8.4046\n",
      "[1452/8000] D loss: 0.2227, G loss: 8.8346\n",
      "[1812/8000] D loss: 0.1159, G loss: 8.5928\n",
      "[2172/8000] D loss: 0.1232, G loss: 7.3726\n",
      "[2532/8000] D loss: 0.0394, G loss: 9.6210\n",
      "[2892/8000] D loss: 0.0297, G loss: 8.1727\n",
      "[3252/8000] D loss: 0.3041, G loss: 9.9015\n",
      "[3612/8000] D loss: 0.0615, G loss: 7.9742\n",
      "[3972/8000] D loss: 0.2813, G loss: 9.1845\n",
      "[4332/8000] D loss: 0.2792, G loss: 9.8031\n",
      "[4692/8000] D loss: 0.2581, G loss: 6.5422\n",
      "[5052/8000] D loss: 0.1306, G loss: 6.7225\n",
      "[5412/8000] D loss: 0.3469, G loss: 10.2130\n",
      "[5772/8000] D loss: 0.0078, G loss: 10.8367\n",
      "[6132/8000] D loss: 0.1294, G loss: 7.6809\n",
      "[6492/8000] D loss: 0.1391, G loss: 11.0702\n",
      "[6852/8000] D loss: 0.0706, G loss: 7.9859\n",
      "[7212/8000] D loss: 0.1789, G loss: 11.2659\n",
      "[7572/8000] D loss: 0.1121, G loss: 8.5095\n",
      "[7932/8000] D loss: 0.3847, G loss: 8.6708\n",
      "train error: \n",
      " D loss: 0.182527, G loss: 8.382269, D accuracy: 95.7%, cell accuracy: 93.5%, board accuracy: 4.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.333862, G loss: 10.247978, D accuracy: 94.6%, cell accuracy: 93.1%, board accuracy: 2.1% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0047, G loss: 12.2978\n",
      "[372/8000] D loss: 0.1143, G loss: 11.2170\n",
      "[732/8000] D loss: 0.0040, G loss: 9.8991\n",
      "[1092/8000] D loss: 0.1104, G loss: 10.6601\n",
      "[1452/8000] D loss: 0.0260, G loss: 9.1473\n",
      "[1812/8000] D loss: 0.2441, G loss: 5.5956\n",
      "[2172/8000] D loss: 0.0943, G loss: 7.9887\n",
      "[2532/8000] D loss: 0.2353, G loss: 9.1419\n",
      "[2892/8000] D loss: 0.1413, G loss: 7.6655\n",
      "[3252/8000] D loss: 0.1672, G loss: 6.4591\n",
      "[3612/8000] D loss: 0.1100, G loss: 9.2876\n",
      "[3972/8000] D loss: 0.1232, G loss: 10.7132\n",
      "[4332/8000] D loss: 0.2429, G loss: 6.8399\n",
      "[4692/8000] D loss: 0.3233, G loss: 7.5045\n",
      "[5052/8000] D loss: 0.0974, G loss: 9.7538\n",
      "[5412/8000] D loss: 0.1180, G loss: 7.2666\n",
      "[5772/8000] D loss: 0.1227, G loss: 7.5530\n",
      "[6132/8000] D loss: 0.2373, G loss: 10.9207\n",
      "[6492/8000] D loss: 0.1320, G loss: 8.9058\n",
      "[6852/8000] D loss: 0.4100, G loss: 6.4891\n",
      "[7212/8000] D loss: 0.1611, G loss: 11.0844\n",
      "[7572/8000] D loss: 0.6507, G loss: 7.3081\n",
      "[7932/8000] D loss: 0.2854, G loss: 9.2917\n",
      "train error: \n",
      " D loss: 0.233589, G loss: 6.966902, D accuracy: 95.1%, cell accuracy: 93.5%, board accuracy: 4.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.269926, G loss: 8.687139, D accuracy: 95.4%, cell accuracy: 93.2%, board accuracy: 2.3% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1500, G loss: 6.7879\n",
      "[372/8000] D loss: 0.1431, G loss: 9.7012\n",
      "[732/8000] D loss: 0.2152, G loss: 5.5085\n",
      "[1092/8000] D loss: 0.5991, G loss: 7.2668\n",
      "[1452/8000] D loss: 0.0553, G loss: 9.3775\n",
      "[1812/8000] D loss: 0.1427, G loss: 10.5271\n",
      "[2172/8000] D loss: 0.0125, G loss: 9.3746\n",
      "[2532/8000] D loss: 0.2566, G loss: 8.4253\n",
      "[2892/8000] D loss: 0.2461, G loss: 7.6075\n",
      "[3252/8000] D loss: 0.0889, G loss: 8.2416\n",
      "[3612/8000] D loss: 0.0509, G loss: 7.8316\n",
      "[3972/8000] D loss: 0.0252, G loss: 10.3162\n",
      "[4332/8000] D loss: 0.1415, G loss: 6.0283\n",
      "[4692/8000] D loss: 0.0570, G loss: 7.8110\n",
      "[5052/8000] D loss: 0.0426, G loss: 7.6034\n",
      "[5412/8000] D loss: 0.0062, G loss: 8.7490\n",
      "[5772/8000] D loss: 0.2002, G loss: 8.1587\n",
      "[6132/8000] D loss: 0.0171, G loss: 11.1875\n",
      "[6492/8000] D loss: 0.1343, G loss: 8.8746\n",
      "[6852/8000] D loss: 0.0149, G loss: 8.5313\n",
      "[7212/8000] D loss: 0.4215, G loss: 7.9595\n",
      "[7572/8000] D loss: 0.1664, G loss: 10.9269\n",
      "[7932/8000] D loss: 0.2415, G loss: 12.2989\n",
      "train error: \n",
      " D loss: 0.161136, G loss: 8.597982, D accuracy: 96.2%, cell accuracy: 93.5%, board accuracy: 4.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.298478, G loss: 10.497027, D accuracy: 95.2%, cell accuracy: 93.2%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0349, G loss: 9.0935\n",
      "[372/8000] D loss: 0.0600, G loss: 8.2257\n",
      "[732/8000] D loss: 0.0551, G loss: 10.2824\n",
      "[1092/8000] D loss: 0.0357, G loss: 8.5065\n",
      "[1452/8000] D loss: 0.1468, G loss: 10.1554\n",
      "[1812/8000] D loss: 0.0297, G loss: 11.4349\n",
      "[2172/8000] D loss: 0.2961, G loss: 9.8894\n",
      "[2532/8000] D loss: 0.2386, G loss: 6.4188\n",
      "[2892/8000] D loss: 0.1817, G loss: 9.4767\n",
      "[3252/8000] D loss: 0.1095, G loss: 6.8037\n",
      "[3612/8000] D loss: 0.1556, G loss: 8.4186\n",
      "[3972/8000] D loss: 0.7016, G loss: 7.6090\n",
      "[4332/8000] D loss: 0.0389, G loss: 10.6776\n",
      "[4692/8000] D loss: 0.0486, G loss: 8.7610\n",
      "[5052/8000] D loss: 0.1321, G loss: 8.9888\n",
      "[5412/8000] D loss: 0.3211, G loss: 9.7503\n",
      "[5772/8000] D loss: 0.1098, G loss: 8.7717\n",
      "[6132/8000] D loss: 0.3322, G loss: 5.2362\n",
      "[6492/8000] D loss: 0.1532, G loss: 7.0254\n",
      "[6852/8000] D loss: 0.0014, G loss: 12.4208\n",
      "[7212/8000] D loss: 0.2029, G loss: 8.0370\n",
      "[7572/8000] D loss: 0.4079, G loss: 6.5618\n",
      "[7932/8000] D loss: 0.0994, G loss: 8.5791\n",
      "train error: \n",
      " D loss: 0.215411, G loss: 7.226994, D accuracy: 95.2%, cell accuracy: 93.5%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.267021, G loss: 9.177513, D accuracy: 95.4%, cell accuracy: 93.2%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1323, G loss: 7.5601\n",
      "[372/8000] D loss: 0.0032, G loss: 9.7714\n",
      "[732/8000] D loss: 0.1829, G loss: 8.8638\n",
      "[1092/8000] D loss: 0.3589, G loss: 10.0878\n",
      "[1452/8000] D loss: 0.0169, G loss: 11.0178\n",
      "[1812/8000] D loss: 0.1750, G loss: 7.4612\n",
      "[2172/8000] D loss: 0.1018, G loss: 9.9464\n",
      "[2532/8000] D loss: 0.4852, G loss: 11.4906\n",
      "[2892/8000] D loss: 0.3664, G loss: 9.2567\n",
      "[3252/8000] D loss: 0.1510, G loss: 8.4012\n",
      "[3612/8000] D loss: 0.0344, G loss: 7.1064\n",
      "[3972/8000] D loss: 0.1438, G loss: 8.0488\n",
      "[4332/8000] D loss: 0.6574, G loss: 7.8426\n",
      "[4692/8000] D loss: 0.0131, G loss: 11.8244\n",
      "[5052/8000] D loss: 0.0341, G loss: 8.8541\n",
      "[5412/8000] D loss: 0.0320, G loss: 10.4802\n",
      "[5772/8000] D loss: 0.0412, G loss: 11.0884\n",
      "[6132/8000] D loss: 0.1503, G loss: 6.7175\n",
      "[6492/8000] D loss: 0.2899, G loss: 6.6651\n",
      "[6852/8000] D loss: 0.2734, G loss: 7.6058\n",
      "[7212/8000] D loss: 0.0396, G loss: 9.0461\n",
      "[7572/8000] D loss: 0.2838, G loss: 8.0485\n",
      "[7932/8000] D loss: 0.4453, G loss: 6.5410\n",
      "train error: \n",
      " D loss: 0.180427, G loss: 8.768186, D accuracy: 95.7%, cell accuracy: 93.6%, board accuracy: 4.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.315092, G loss: 10.614339, D accuracy: 95.1%, cell accuracy: 93.3%, board accuracy: 2.4% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0725, G loss: 7.7369\n",
      "[372/8000] D loss: 0.4820, G loss: 7.7836\n",
      "[732/8000] D loss: 0.0669, G loss: 9.7002\n",
      "[1092/8000] D loss: 0.2665, G loss: 8.4580\n",
      "[1452/8000] D loss: 0.0999, G loss: 7.9902\n",
      "[1812/8000] D loss: 0.3594, G loss: 6.0801\n",
      "[2172/8000] D loss: 0.6462, G loss: 8.2028\n",
      "[2532/8000] D loss: 0.2283, G loss: 7.2869\n",
      "[2892/8000] D loss: 0.0504, G loss: 7.7870\n",
      "[3252/8000] D loss: 0.0053, G loss: 10.7588\n",
      "[3612/8000] D loss: 0.2183, G loss: 8.2902\n",
      "[3972/8000] D loss: 0.1129, G loss: 9.9944\n",
      "[4332/8000] D loss: 0.0674, G loss: 7.1393\n",
      "[4692/8000] D loss: 0.2748, G loss: 6.6801\n",
      "[5052/8000] D loss: 0.0823, G loss: 10.0216\n",
      "[5412/8000] D loss: 0.0517, G loss: 6.1038\n",
      "[5772/8000] D loss: 0.2700, G loss: 3.9186\n",
      "[6132/8000] D loss: 0.4204, G loss: 6.7396\n",
      "[6492/8000] D loss: 0.0492, G loss: 7.4905\n",
      "[6852/8000] D loss: 0.2546, G loss: 11.1560\n",
      "[7212/8000] D loss: 0.1382, G loss: 9.5956\n",
      "[7572/8000] D loss: 0.3080, G loss: 9.6287\n",
      "[7932/8000] D loss: 0.0606, G loss: 10.4680\n",
      "train error: \n",
      " D loss: 0.197608, G loss: 7.296119, D accuracy: 95.6%, cell accuracy: 93.5%, board accuracy: 4.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.295829, G loss: 9.173210, D accuracy: 95.2%, cell accuracy: 93.2%, board accuracy: 2.4% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0167, G loss: 9.3920\n",
      "[372/8000] D loss: 0.2683, G loss: 7.1236\n",
      "[732/8000] D loss: 0.0810, G loss: 11.5944\n",
      "[1092/8000] D loss: 0.2651, G loss: 5.5402\n",
      "[1452/8000] D loss: 0.0024, G loss: 13.3395\n",
      "[1812/8000] D loss: 0.0334, G loss: 8.2265\n",
      "[2172/8000] D loss: 0.2345, G loss: 9.1102\n",
      "[2532/8000] D loss: 0.1416, G loss: 8.6923\n",
      "[2892/8000] D loss: 0.0233, G loss: 8.0242\n",
      "[3252/8000] D loss: 0.1214, G loss: 8.2259\n",
      "[3612/8000] D loss: 0.5960, G loss: 8.1566\n",
      "[3972/8000] D loss: 0.0474, G loss: 10.7367\n",
      "[4332/8000] D loss: 0.0271, G loss: 9.0424\n",
      "[4692/8000] D loss: 0.0169, G loss: 9.5926\n",
      "[5052/8000] D loss: 0.1450, G loss: 8.4883\n",
      "[5412/8000] D loss: 0.0209, G loss: 10.4376\n",
      "[5772/8000] D loss: 0.1725, G loss: 9.4170\n",
      "[6132/8000] D loss: 0.6586, G loss: 6.4496\n",
      "[6492/8000] D loss: 0.2903, G loss: 8.0109\n",
      "[6852/8000] D loss: 0.0975, G loss: 8.0250\n",
      "[7212/8000] D loss: 0.0686, G loss: 6.0202\n",
      "[7572/8000] D loss: 0.1301, G loss: 7.6565\n",
      "[7932/8000] D loss: 0.0918, G loss: 7.7521\n",
      "train error: \n",
      " D loss: 0.185335, G loss: 8.504438, D accuracy: 95.7%, cell accuracy: 93.5%, board accuracy: 4.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.307619, G loss: 10.493624, D accuracy: 95.0%, cell accuracy: 93.2%, board accuracy: 2.4% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0199, G loss: 9.3742\n",
      "[372/8000] D loss: 0.0096, G loss: 9.3404\n",
      "[732/8000] D loss: 0.2988, G loss: 8.5386\n",
      "[1092/8000] D loss: 0.0882, G loss: 9.0386\n",
      "[1452/8000] D loss: 0.0696, G loss: 12.1218\n",
      "[1812/8000] D loss: 0.1864, G loss: 6.7076\n",
      "[2172/8000] D loss: 0.1411, G loss: 7.8611\n",
      "[2532/8000] D loss: 0.2783, G loss: 9.9984\n",
      "[2892/8000] D loss: 0.2826, G loss: 8.0313\n",
      "[3252/8000] D loss: 0.7217, G loss: 7.3995\n",
      "[3612/8000] D loss: 0.0573, G loss: 10.5902\n",
      "[3972/8000] D loss: 0.0289, G loss: 9.1383\n",
      "[4332/8000] D loss: 0.0917, G loss: 8.8812\n",
      "[4692/8000] D loss: 0.3992, G loss: 7.2849\n",
      "[5052/8000] D loss: 0.3129, G loss: 10.3399\n",
      "[5412/8000] D loss: 0.0086, G loss: 7.8621\n",
      "[5772/8000] D loss: 0.2791, G loss: 7.1454\n",
      "[6132/8000] D loss: 0.0893, G loss: 9.6177\n",
      "[6492/8000] D loss: 0.2027, G loss: 7.9123\n",
      "[6852/8000] D loss: 0.2075, G loss: 7.9440\n",
      "[7212/8000] D loss: 0.2013, G loss: 7.8633\n",
      "[7572/8000] D loss: 0.1901, G loss: 10.9013\n",
      "[7932/8000] D loss: 0.0445, G loss: 7.5536\n",
      "train error: \n",
      " D loss: 0.176515, G loss: 9.141070, D accuracy: 95.9%, cell accuracy: 93.5%, board accuracy: 4.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.329262, G loss: 10.951869, D accuracy: 94.7%, cell accuracy: 93.2%, board accuracy: 2.1% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0535, G loss: 10.8895\n",
      "[372/8000] D loss: 0.6535, G loss: 5.0242\n",
      "[732/8000] D loss: 0.2891, G loss: 8.6418\n",
      "[1092/8000] D loss: 0.2553, G loss: 10.0596\n",
      "[1452/8000] D loss: 0.0582, G loss: 9.9514\n",
      "[1812/8000] D loss: 0.2311, G loss: 7.9920\n",
      "[2172/8000] D loss: 0.2534, G loss: 5.8733\n",
      "[2532/8000] D loss: 0.0070, G loss: 11.9365\n",
      "[2892/8000] D loss: 0.0489, G loss: 13.0894\n",
      "[3252/8000] D loss: 0.2800, G loss: 8.2112\n",
      "[3612/8000] D loss: 0.1392, G loss: 8.8257\n",
      "[3972/8000] D loss: 0.4272, G loss: 8.6173\n",
      "[4332/8000] D loss: 0.2374, G loss: 8.8266\n",
      "[4692/8000] D loss: 0.2754, G loss: 9.6590\n",
      "[5052/8000] D loss: 0.1771, G loss: 10.4429\n",
      "[5412/8000] D loss: 0.0302, G loss: 9.0117\n",
      "[5772/8000] D loss: 0.2358, G loss: 7.5061\n",
      "[6132/8000] D loss: 0.3289, G loss: 8.1925\n",
      "[6492/8000] D loss: 0.0387, G loss: 7.1615\n",
      "[6852/8000] D loss: 0.0582, G loss: 9.7973\n",
      "[7212/8000] D loss: 0.1153, G loss: 6.2306\n",
      "[7572/8000] D loss: 0.1605, G loss: 9.2168\n",
      "[7932/8000] D loss: 0.0213, G loss: 8.0457\n",
      "train error: \n",
      " D loss: 0.227742, G loss: 7.066865, D accuracy: 95.0%, cell accuracy: 93.6%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.299691, G loss: 9.033809, D accuracy: 95.2%, cell accuracy: 93.3%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3831, G loss: 6.9535\n",
      "[372/8000] D loss: 0.3324, G loss: 8.6825\n",
      "[732/8000] D loss: 0.3747, G loss: 7.1043\n",
      "[1092/8000] D loss: 0.0092, G loss: 9.7047\n",
      "[1452/8000] D loss: 0.0784, G loss: 10.5072\n",
      "[1812/8000] D loss: 0.2317, G loss: 10.4953\n",
      "[2172/8000] D loss: 0.1716, G loss: 7.6970\n",
      "[2532/8000] D loss: 0.0745, G loss: 8.6933\n",
      "[2892/8000] D loss: 0.2764, G loss: 6.5261\n",
      "[3252/8000] D loss: 0.3812, G loss: 5.6829\n",
      "[3612/8000] D loss: 0.0874, G loss: 9.1636\n",
      "[3972/8000] D loss: 0.2442, G loss: 9.1184\n",
      "[4332/8000] D loss: 0.2693, G loss: 12.0889\n",
      "[4692/8000] D loss: 0.1831, G loss: 7.6932\n",
      "[5052/8000] D loss: 0.1442, G loss: 11.9393\n",
      "[5412/8000] D loss: 0.1101, G loss: 9.0789\n",
      "[5772/8000] D loss: 0.1431, G loss: 9.1199\n",
      "[6132/8000] D loss: 0.1351, G loss: 9.4215\n",
      "[6492/8000] D loss: 0.1604, G loss: 9.7480\n",
      "[6852/8000] D loss: 0.1899, G loss: 7.7037\n",
      "[7212/8000] D loss: 0.1040, G loss: 8.5001\n",
      "[7572/8000] D loss: 0.2368, G loss: 4.9318\n",
      "[7932/8000] D loss: 0.3325, G loss: 7.7401\n",
      "train error: \n",
      " D loss: 0.174372, G loss: 8.870860, D accuracy: 95.9%, cell accuracy: 93.6%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.357933, G loss: 10.808587, D accuracy: 94.1%, cell accuracy: 93.3%, board accuracy: 2.1% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2294, G loss: 11.1710\n",
      "[372/8000] D loss: 0.0530, G loss: 8.7036\n",
      "[732/8000] D loss: 0.0334, G loss: 9.6913\n",
      "[1092/8000] D loss: 0.2902, G loss: 7.4006\n",
      "[1452/8000] D loss: 0.4170, G loss: 7.5299\n",
      "[1812/8000] D loss: 0.1423, G loss: 8.7049\n",
      "[2172/8000] D loss: 0.1192, G loss: 11.2884\n",
      "[2532/8000] D loss: 0.2087, G loss: 7.6637\n",
      "[2892/8000] D loss: 0.2483, G loss: 9.1082\n",
      "[3252/8000] D loss: 0.5516, G loss: 8.0915\n",
      "[3612/8000] D loss: 0.1871, G loss: 10.1606\n",
      "[3972/8000] D loss: 0.3004, G loss: 8.1234\n",
      "[4332/8000] D loss: 0.2707, G loss: 8.9236\n",
      "[4692/8000] D loss: 0.0212, G loss: 7.8717\n",
      "[5052/8000] D loss: 0.4764, G loss: 7.8304\n",
      "[5412/8000] D loss: 0.3176, G loss: 6.8864\n",
      "[5772/8000] D loss: 0.1352, G loss: 9.5923\n",
      "[6132/8000] D loss: 0.3121, G loss: 7.1775\n",
      "[6492/8000] D loss: 0.1380, G loss: 12.0403\n",
      "[6852/8000] D loss: 0.0310, G loss: 10.1927\n",
      "[7212/8000] D loss: 0.1776, G loss: 5.7798\n",
      "[7572/8000] D loss: 0.2381, G loss: 9.8927\n",
      "[7932/8000] D loss: 0.1503, G loss: 8.4389\n",
      "train error: \n",
      " D loss: 0.181218, G loss: 10.200549, D accuracy: 95.6%, cell accuracy: 93.6%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.401835, G loss: 12.298442, D accuracy: 94.4%, cell accuracy: 93.2%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0299, G loss: 9.8502\n",
      "[372/8000] D loss: 0.2404, G loss: 7.8158\n",
      "[732/8000] D loss: 0.0321, G loss: 8.9115\n",
      "[1092/8000] D loss: 0.1500, G loss: 9.9337\n",
      "[1452/8000] D loss: 0.2118, G loss: 10.8613\n",
      "[1812/8000] D loss: 0.3650, G loss: 7.9230\n",
      "[2172/8000] D loss: 0.0285, G loss: 11.2360\n",
      "[2532/8000] D loss: 0.1907, G loss: 7.6221\n",
      "[2892/8000] D loss: 0.2844, G loss: 8.4356\n",
      "[3252/8000] D loss: 0.1003, G loss: 8.1225\n",
      "[3612/8000] D loss: 0.1826, G loss: 8.1459\n",
      "[3972/8000] D loss: 0.1364, G loss: 8.8509\n",
      "[4332/8000] D loss: 0.0036, G loss: 11.8296\n",
      "[4692/8000] D loss: 0.0580, G loss: 9.1989\n",
      "[5052/8000] D loss: 0.2189, G loss: 6.6373\n",
      "[5412/8000] D loss: 0.2849, G loss: 8.9005\n",
      "[5772/8000] D loss: 0.0071, G loss: 10.8059\n",
      "[6132/8000] D loss: 0.0942, G loss: 9.4013\n",
      "[6492/8000] D loss: 0.4447, G loss: 5.2983\n",
      "[6852/8000] D loss: 0.2794, G loss: 11.5075\n",
      "[7212/8000] D loss: 0.1087, G loss: 10.1138\n",
      "[7572/8000] D loss: 0.0689, G loss: 8.1374\n",
      "[7932/8000] D loss: 0.3526, G loss: 10.7167\n",
      "train error: \n",
      " D loss: 0.332565, G loss: 5.954195, D accuracy: 93.0%, cell accuracy: 93.6%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.277543, G loss: 7.888626, D accuracy: 95.1%, cell accuracy: 93.3%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0994, G loss: 5.3756\n",
      "[372/8000] D loss: 0.0092, G loss: 11.7861\n",
      "[732/8000] D loss: 0.0561, G loss: 10.2991\n",
      "[1092/8000] D loss: 0.0847, G loss: 11.2234\n",
      "[1452/8000] D loss: 0.2382, G loss: 7.9949\n",
      "[1812/8000] D loss: 0.0398, G loss: 7.6404\n",
      "[2172/8000] D loss: 0.0905, G loss: 7.6716\n",
      "[2532/8000] D loss: 0.1437, G loss: 11.0017\n",
      "[2892/8000] D loss: 0.2122, G loss: 10.0763\n",
      "[3252/8000] D loss: 0.0748, G loss: 10.4986\n",
      "[3612/8000] D loss: 0.4980, G loss: 8.7851\n",
      "[3972/8000] D loss: 0.1409, G loss: 7.6643\n",
      "[4332/8000] D loss: 0.1572, G loss: 9.8477\n",
      "[4692/8000] D loss: 0.1655, G loss: 9.2387\n",
      "[5052/8000] D loss: 0.0028, G loss: 14.2984\n",
      "[5412/8000] D loss: 0.2238, G loss: 7.9510\n",
      "[5772/8000] D loss: 0.0278, G loss: 9.5660\n",
      "[6132/8000] D loss: 0.1347, G loss: 10.0217\n",
      "[6492/8000] D loss: 0.1274, G loss: 7.9083\n",
      "[6852/8000] D loss: 0.0385, G loss: 10.2704\n",
      "[7212/8000] D loss: 0.2739, G loss: 7.5761\n",
      "[7572/8000] D loss: 0.0787, G loss: 8.8122\n",
      "[7932/8000] D loss: 0.0174, G loss: 10.3198\n",
      "train error: \n",
      " D loss: 0.196494, G loss: 7.837517, D accuracy: 95.6%, cell accuracy: 93.6%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.302914, G loss: 9.809575, D accuracy: 94.9%, cell accuracy: 93.3%, board accuracy: 2.4% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1680, G loss: 7.0683\n",
      "[372/8000] D loss: 0.1195, G loss: 8.5773\n",
      "[732/8000] D loss: 0.3870, G loss: 5.6529\n",
      "[1092/8000] D loss: 0.2129, G loss: 8.3020\n",
      "[1452/8000] D loss: 0.1727, G loss: 6.4449\n",
      "[1812/8000] D loss: 0.3192, G loss: 9.2361\n",
      "[2172/8000] D loss: 0.1802, G loss: 8.4500\n",
      "[2532/8000] D loss: 0.0135, G loss: 9.6600\n",
      "[2892/8000] D loss: 0.1761, G loss: 5.0047\n",
      "[3252/8000] D loss: 0.0992, G loss: 11.2612\n",
      "[3612/8000] D loss: 0.0394, G loss: 8.4910\n",
      "[3972/8000] D loss: 0.0315, G loss: 8.6323\n",
      "[4332/8000] D loss: 0.1129, G loss: 7.6221\n",
      "[4692/8000] D loss: 0.1613, G loss: 12.0556\n",
      "[5052/8000] D loss: 0.3475, G loss: 7.7913\n",
      "[5412/8000] D loss: 0.2634, G loss: 7.7200\n",
      "[5772/8000] D loss: 0.1140, G loss: 10.1625\n",
      "[6132/8000] D loss: 0.0656, G loss: 11.1443\n",
      "[6492/8000] D loss: 0.0090, G loss: 11.8068\n",
      "[6852/8000] D loss: 0.2885, G loss: 7.2976\n",
      "[7212/8000] D loss: 0.0036, G loss: 10.7550\n",
      "[7572/8000] D loss: 0.1546, G loss: 13.0859\n",
      "[7932/8000] D loss: 0.3026, G loss: 8.1338\n",
      "train error: \n",
      " D loss: 0.165659, G loss: 8.776275, D accuracy: 96.0%, cell accuracy: 93.6%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.347413, G loss: 10.807812, D accuracy: 94.5%, cell accuracy: 93.3%, board accuracy: 2.1% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4249, G loss: 6.3341\n",
      "[372/8000] D loss: 0.2536, G loss: 6.1779\n",
      "[732/8000] D loss: 0.0356, G loss: 8.8498\n",
      "[1092/8000] D loss: 0.1336, G loss: 14.0847\n",
      "[1452/8000] D loss: 0.3159, G loss: 10.1793\n",
      "[1812/8000] D loss: 0.2522, G loss: 8.0462\n",
      "[2172/8000] D loss: 0.1665, G loss: 6.4132\n",
      "[2532/8000] D loss: 0.0280, G loss: 9.2262\n",
      "[2892/8000] D loss: 0.0166, G loss: 9.8665\n",
      "[3252/8000] D loss: 0.4206, G loss: 7.2314\n",
      "[3612/8000] D loss: 0.4703, G loss: 9.3706\n",
      "[3972/8000] D loss: 0.0070, G loss: 12.1740\n",
      "[4332/8000] D loss: 0.3765, G loss: 7.2518\n",
      "[4692/8000] D loss: 0.3144, G loss: 7.5314\n",
      "[5052/8000] D loss: 0.1708, G loss: 12.6561\n",
      "[5412/8000] D loss: 0.2366, G loss: 10.1695\n",
      "[5772/8000] D loss: 0.0377, G loss: 6.9660\n",
      "[6132/8000] D loss: 0.3449, G loss: 9.6737\n",
      "[6492/8000] D loss: 0.0220, G loss: 12.7414\n",
      "[6852/8000] D loss: 0.1138, G loss: 8.8353\n",
      "[7212/8000] D loss: 0.1641, G loss: 7.6669\n",
      "[7572/8000] D loss: 0.0872, G loss: 9.1119\n",
      "[7932/8000] D loss: 0.4189, G loss: 5.6727\n",
      "train error: \n",
      " D loss: 0.196115, G loss: 7.426389, D accuracy: 95.5%, cell accuracy: 93.6%, board accuracy: 5.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.290584, G loss: 9.325905, D accuracy: 94.6%, cell accuracy: 93.3%, board accuracy: 2.6% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2173, G loss: 6.3736\n",
      "[372/8000] D loss: 0.1777, G loss: 7.9881\n",
      "[732/8000] D loss: 0.0378, G loss: 9.5168\n",
      "[1092/8000] D loss: 0.0539, G loss: 7.0968\n",
      "[1452/8000] D loss: 0.3107, G loss: 8.8903\n",
      "[1812/8000] D loss: 0.5458, G loss: 7.7355\n",
      "[2172/8000] D loss: 0.3951, G loss: 6.6880\n",
      "[2532/8000] D loss: 0.0612, G loss: 8.2456\n",
      "[2892/8000] D loss: 0.1544, G loss: 8.8495\n",
      "[3252/8000] D loss: 0.1812, G loss: 9.7797\n",
      "[3612/8000] D loss: 0.0404, G loss: 10.3615\n",
      "[3972/8000] D loss: 0.1779, G loss: 8.5484\n",
      "[4332/8000] D loss: 0.0497, G loss: 10.6627\n",
      "[4692/8000] D loss: 0.1044, G loss: 8.1350\n",
      "[5052/8000] D loss: 0.3132, G loss: 5.4276\n",
      "[5412/8000] D loss: 0.1327, G loss: 7.6858\n",
      "[5772/8000] D loss: 0.4359, G loss: 7.9663\n",
      "[6132/8000] D loss: 0.1577, G loss: 5.1290\n",
      "[6492/8000] D loss: 0.2749, G loss: 7.3787\n",
      "[6852/8000] D loss: 0.0816, G loss: 9.0401\n",
      "[7212/8000] D loss: 0.1427, G loss: 9.5506\n",
      "[7572/8000] D loss: 0.2751, G loss: 8.4876\n",
      "[7932/8000] D loss: 0.1963, G loss: 9.4046\n",
      "train error: \n",
      " D loss: 0.168243, G loss: 8.806040, D accuracy: 96.1%, cell accuracy: 93.6%, board accuracy: 5.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.313483, G loss: 10.857210, D accuracy: 95.1%, cell accuracy: 93.3%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1461, G loss: 12.3598\n",
      "[372/8000] D loss: 0.2423, G loss: 9.1680\n",
      "[732/8000] D loss: 0.2939, G loss: 10.3435\n",
      "[1092/8000] D loss: 0.2650, G loss: 7.7874\n",
      "[1452/8000] D loss: 0.2179, G loss: 7.3071\n",
      "[1812/8000] D loss: 0.4102, G loss: 5.3463\n",
      "[2172/8000] D loss: 0.1669, G loss: 10.7302\n",
      "[2532/8000] D loss: 0.0208, G loss: 11.7776\n",
      "[2892/8000] D loss: 0.0347, G loss: 9.4005\n",
      "[3252/8000] D loss: 0.0692, G loss: 11.8364\n",
      "[3612/8000] D loss: 0.3785, G loss: 7.2655\n",
      "[3972/8000] D loss: 0.2745, G loss: 10.0389\n",
      "[4332/8000] D loss: 0.1527, G loss: 8.4264\n",
      "[4692/8000] D loss: 0.1356, G loss: 9.7321\n",
      "[5052/8000] D loss: 0.4004, G loss: 7.3587\n",
      "[5412/8000] D loss: 0.2855, G loss: 6.9886\n",
      "[5772/8000] D loss: 0.0765, G loss: 8.5542\n",
      "[6132/8000] D loss: 0.1695, G loss: 6.9828\n",
      "[6492/8000] D loss: 0.1850, G loss: 8.3335\n",
      "[6852/8000] D loss: 0.2311, G loss: 6.4842\n",
      "[7212/8000] D loss: 0.1559, G loss: 10.3721\n",
      "[7572/8000] D loss: 0.2639, G loss: 8.6516\n",
      "[7932/8000] D loss: 0.0123, G loss: 11.8422\n",
      "train error: \n",
      " D loss: 0.180057, G loss: 9.256456, D accuracy: 95.7%, cell accuracy: 93.7%, board accuracy: 4.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.365067, G loss: 11.160680, D accuracy: 94.0%, cell accuracy: 93.4%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0959, G loss: 10.6708\n",
      "[372/8000] D loss: 0.1379, G loss: 6.7392\n",
      "[732/8000] D loss: 0.2693, G loss: 6.9111\n",
      "[1092/8000] D loss: 0.5069, G loss: 5.4768\n",
      "[1452/8000] D loss: 0.0522, G loss: 10.0989\n",
      "[1812/8000] D loss: 0.0498, G loss: 6.8959\n",
      "[2172/8000] D loss: 0.2191, G loss: 7.2340\n",
      "[2532/8000] D loss: 0.1754, G loss: 9.6555\n",
      "[2892/8000] D loss: 0.0330, G loss: 9.0029\n",
      "[3252/8000] D loss: 0.3488, G loss: 8.4583\n",
      "[3612/8000] D loss: 0.2503, G loss: 8.4903\n",
      "[3972/8000] D loss: 0.0117, G loss: 7.7860\n",
      "[4332/8000] D loss: 0.3620, G loss: 9.4976\n",
      "[4692/8000] D loss: 0.2872, G loss: 7.8473\n",
      "[5052/8000] D loss: 0.1467, G loss: 9.3881\n",
      "[5412/8000] D loss: 0.1632, G loss: 8.0012\n",
      "[5772/8000] D loss: 0.0740, G loss: 8.3519\n",
      "[6132/8000] D loss: 0.3481, G loss: 5.3546\n",
      "[6492/8000] D loss: 0.4270, G loss: 8.5949\n",
      "[6852/8000] D loss: 0.0311, G loss: 11.0488\n",
      "[7212/8000] D loss: 0.2235, G loss: 7.8803\n",
      "[7572/8000] D loss: 0.2624, G loss: 6.1805\n",
      "[7932/8000] D loss: 0.2667, G loss: 13.5694\n",
      "train error: \n",
      " D loss: 0.242382, G loss: 7.474707, D accuracy: 94.4%, cell accuracy: 93.7%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.322798, G loss: 9.392443, D accuracy: 94.8%, cell accuracy: 93.4%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0420, G loss: 8.4949\n",
      "[372/8000] D loss: 0.0233, G loss: 11.5265\n",
      "[732/8000] D loss: 0.0409, G loss: 10.1622\n",
      "[1092/8000] D loss: 0.5243, G loss: 4.0931\n",
      "[1452/8000] D loss: 0.1316, G loss: 6.5003\n",
      "[1812/8000] D loss: 0.0141, G loss: 10.6073\n",
      "[2172/8000] D loss: 0.4034, G loss: 6.3699\n",
      "[2532/8000] D loss: 0.0515, G loss: 7.6267\n",
      "[2892/8000] D loss: 0.0413, G loss: 9.1712\n",
      "[3252/8000] D loss: 0.1139, G loss: 8.3013\n",
      "[3612/8000] D loss: 0.2889, G loss: 6.9479\n",
      "[3972/8000] D loss: 0.0418, G loss: 7.6585\n",
      "[4332/8000] D loss: 0.1049, G loss: 9.6742\n",
      "[4692/8000] D loss: 0.4278, G loss: 5.7287\n",
      "[5052/8000] D loss: 0.3241, G loss: 9.8161\n",
      "[5412/8000] D loss: 0.4277, G loss: 7.7510\n",
      "[5772/8000] D loss: 0.2398, G loss: 8.6249\n",
      "[6132/8000] D loss: 0.0797, G loss: 8.4462\n",
      "[6492/8000] D loss: 0.2944, G loss: 7.0401\n",
      "[6852/8000] D loss: 0.1211, G loss: 13.2269\n",
      "[7212/8000] D loss: 0.0943, G loss: 9.3191\n",
      "[7572/8000] D loss: 0.1438, G loss: 8.1604\n",
      "[7932/8000] D loss: 0.2377, G loss: 9.5590\n",
      "train error: \n",
      " D loss: 0.195223, G loss: 8.650998, D accuracy: 95.5%, cell accuracy: 93.7%, board accuracy: 5.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.375307, G loss: 10.774114, D accuracy: 94.1%, cell accuracy: 93.4%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4327, G loss: 9.7379\n",
      "[372/8000] D loss: 0.1870, G loss: 8.9474\n",
      "[732/8000] D loss: 0.2750, G loss: 6.5288\n",
      "[1092/8000] D loss: 0.1533, G loss: 8.8257\n",
      "[1452/8000] D loss: 0.2405, G loss: 7.1257\n",
      "[1812/8000] D loss: 0.4867, G loss: 5.9463\n",
      "[2172/8000] D loss: 0.2013, G loss: 7.5963\n",
      "[2532/8000] D loss: 0.3784, G loss: 6.0324\n",
      "[2892/8000] D loss: 0.4303, G loss: 7.2490\n",
      "[3252/8000] D loss: 0.0494, G loss: 8.7085\n",
      "[3612/8000] D loss: 0.3204, G loss: 8.3005\n",
      "[3972/8000] D loss: 0.3879, G loss: 7.2036\n",
      "[4332/8000] D loss: 0.0073, G loss: 11.3774\n",
      "[4692/8000] D loss: 0.0452, G loss: 6.6172\n",
      "[5052/8000] D loss: 0.2379, G loss: 8.2564\n",
      "[5412/8000] D loss: 0.0651, G loss: 9.7123\n",
      "[5772/8000] D loss: 0.2840, G loss: 8.6536\n",
      "[6132/8000] D loss: 0.0257, G loss: 8.9271\n",
      "[6492/8000] D loss: 0.3287, G loss: 6.0993\n",
      "[6852/8000] D loss: 0.2910, G loss: 8.5957\n",
      "[7212/8000] D loss: 0.2840, G loss: 8.1183\n",
      "[7572/8000] D loss: 0.1335, G loss: 8.5196\n",
      "[7932/8000] D loss: 0.3223, G loss: 7.5341\n",
      "train error: \n",
      " D loss: 0.175064, G loss: 8.743165, D accuracy: 95.9%, cell accuracy: 93.7%, board accuracy: 4.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.320596, G loss: 10.766445, D accuracy: 95.2%, cell accuracy: 93.3%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0697, G loss: 7.7633\n",
      "[372/8000] D loss: 0.0885, G loss: 7.8266\n",
      "[732/8000] D loss: 0.5192, G loss: 8.5374\n",
      "[1092/8000] D loss: 0.3497, G loss: 6.1091\n",
      "[1452/8000] D loss: 0.0557, G loss: 10.0227\n",
      "[1812/8000] D loss: 0.0813, G loss: 9.4028\n",
      "[2172/8000] D loss: 0.0848, G loss: 10.3718\n",
      "[2532/8000] D loss: 0.1186, G loss: 11.0760\n",
      "[2892/8000] D loss: 0.1816, G loss: 9.9238\n",
      "[3252/8000] D loss: 0.0550, G loss: 7.1371\n",
      "[3612/8000] D loss: 0.1364, G loss: 10.1358\n",
      "[3972/8000] D loss: 0.2663, G loss: 7.7240\n",
      "[4332/8000] D loss: 0.3517, G loss: 8.6022\n",
      "[4692/8000] D loss: 0.2966, G loss: 9.8193\n",
      "[5052/8000] D loss: 0.6801, G loss: 6.6268\n",
      "[5412/8000] D loss: 0.0127, G loss: 9.6074\n",
      "[5772/8000] D loss: 0.1152, G loss: 8.9620\n",
      "[6132/8000] D loss: 0.3797, G loss: 6.4310\n",
      "[6492/8000] D loss: 0.4020, G loss: 10.8195\n",
      "[6852/8000] D loss: 0.0022, G loss: 11.5307\n",
      "[7212/8000] D loss: 0.0073, G loss: 11.3948\n",
      "[7572/8000] D loss: 0.2716, G loss: 6.2229\n",
      "[7932/8000] D loss: 0.1520, G loss: 9.9285\n",
      "train error: \n",
      " D loss: 0.218673, G loss: 7.307843, D accuracy: 95.0%, cell accuracy: 93.7%, board accuracy: 5.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.277483, G loss: 9.375254, D accuracy: 95.5%, cell accuracy: 93.4%, board accuracy: 1.7% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1363, G loss: 8.5488\n",
      "[372/8000] D loss: 0.0452, G loss: 7.6816\n",
      "[732/8000] D loss: 0.0092, G loss: 9.1706\n",
      "[1092/8000] D loss: 0.2392, G loss: 5.9662\n",
      "[1452/8000] D loss: 0.0676, G loss: 6.7114\n",
      "[1812/8000] D loss: 0.1775, G loss: 6.0126\n",
      "[2172/8000] D loss: 0.1321, G loss: 7.9257\n",
      "[2532/8000] D loss: 0.1101, G loss: 10.9962\n",
      "[2892/8000] D loss: 0.3578, G loss: 8.0365\n",
      "[3252/8000] D loss: 0.0043, G loss: 12.6860\n",
      "[3612/8000] D loss: 0.0032, G loss: 11.0740\n",
      "[3972/8000] D loss: 0.2125, G loss: 7.6499\n",
      "[4332/8000] D loss: 0.2713, G loss: 4.3380\n",
      "[4692/8000] D loss: 0.1761, G loss: 8.0189\n",
      "[5052/8000] D loss: 0.2801, G loss: 6.5786\n",
      "[5412/8000] D loss: 0.1631, G loss: 8.5291\n",
      "[5772/8000] D loss: 0.0341, G loss: 9.2104\n",
      "[6132/8000] D loss: 0.3303, G loss: 6.7781\n",
      "[6492/8000] D loss: 0.2655, G loss: 8.1384\n",
      "[6852/8000] D loss: 0.0298, G loss: 9.0737\n",
      "[7212/8000] D loss: 0.0429, G loss: 11.3326\n",
      "[7572/8000] D loss: 0.2743, G loss: 7.3460\n",
      "[7932/8000] D loss: 0.0599, G loss: 9.3535\n",
      "train error: \n",
      " D loss: 0.188758, G loss: 7.337964, D accuracy: 95.5%, cell accuracy: 93.8%, board accuracy: 5.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.298401, G loss: 9.228491, D accuracy: 94.8%, cell accuracy: 93.5%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1667, G loss: 9.4166\n",
      "[372/8000] D loss: 0.0897, G loss: 7.6790\n",
      "[732/8000] D loss: 0.1720, G loss: 7.3971\n",
      "[1092/8000] D loss: 0.2596, G loss: 6.0280\n",
      "[1452/8000] D loss: 0.0708, G loss: 7.9223\n",
      "[1812/8000] D loss: 0.4514, G loss: 6.2429\n",
      "[2172/8000] D loss: 0.1041, G loss: 7.5296\n",
      "[2532/8000] D loss: 0.0343, G loss: 9.0661\n",
      "[2892/8000] D loss: 0.3121, G loss: 8.7306\n",
      "[3252/8000] D loss: 0.1559, G loss: 8.6353\n",
      "[3612/8000] D loss: 0.0525, G loss: 6.4855\n",
      "[3972/8000] D loss: 0.0237, G loss: 9.4024\n",
      "[4332/8000] D loss: 0.0130, G loss: 9.6163\n",
      "[4692/8000] D loss: 0.0221, G loss: 8.8163\n",
      "[5052/8000] D loss: 0.0396, G loss: 7.5529\n",
      "[5412/8000] D loss: 0.5959, G loss: 6.7718\n",
      "[5772/8000] D loss: 0.1840, G loss: 9.0653\n",
      "[6132/8000] D loss: 0.0147, G loss: 9.5313\n",
      "[6492/8000] D loss: 0.1153, G loss: 11.4499\n",
      "[6852/8000] D loss: 0.0179, G loss: 10.6279\n",
      "[7212/8000] D loss: 0.0285, G loss: 13.3124\n",
      "[7572/8000] D loss: 0.1885, G loss: 10.1142\n",
      "[7932/8000] D loss: 0.4597, G loss: 5.4949\n",
      "train error: \n",
      " D loss: 0.221174, G loss: 7.311496, D accuracy: 94.9%, cell accuracy: 93.8%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.324784, G loss: 9.430764, D accuracy: 94.9%, cell accuracy: 93.5%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3184, G loss: 8.0387\n",
      "[372/8000] D loss: 0.0351, G loss: 8.9931\n",
      "[732/8000] D loss: 0.0864, G loss: 9.0293\n",
      "[1092/8000] D loss: 0.1397, G loss: 5.6283\n",
      "[1452/8000] D loss: 0.4860, G loss: 8.0337\n",
      "[1812/8000] D loss: 0.0133, G loss: 11.5041\n",
      "[2172/8000] D loss: 0.4137, G loss: 8.4351\n",
      "[2532/8000] D loss: 0.0485, G loss: 9.1516\n",
      "[2892/8000] D loss: 0.0852, G loss: 10.2577\n",
      "[3252/8000] D loss: 0.1753, G loss: 7.1966\n",
      "[3612/8000] D loss: 0.2790, G loss: 10.2803\n",
      "[3972/8000] D loss: 0.1683, G loss: 5.6378\n",
      "[4332/8000] D loss: 0.2904, G loss: 8.6618\n",
      "[4692/8000] D loss: 0.1651, G loss: 8.2313\n",
      "[5052/8000] D loss: 0.3043, G loss: 7.9838\n",
      "[5412/8000] D loss: 0.2611, G loss: 7.8622\n",
      "[5772/8000] D loss: 0.2819, G loss: 7.9492\n",
      "[6132/8000] D loss: 0.0989, G loss: 10.0252\n",
      "[6492/8000] D loss: 0.4140, G loss: 7.7888\n",
      "[6852/8000] D loss: 0.2745, G loss: 8.7349\n",
      "[7212/8000] D loss: 0.1297, G loss: 7.7180\n",
      "[7572/8000] D loss: 0.2524, G loss: 10.0846\n",
      "[7932/8000] D loss: 0.6879, G loss: 3.7686\n",
      "train error: \n",
      " D loss: 0.310871, G loss: 9.264231, D accuracy: 93.0%, cell accuracy: 93.8%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.559990, G loss: 11.081577, D accuracy: 91.3%, cell accuracy: 93.5%, board accuracy: 1.9% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3018, G loss: 11.4242\n",
      "[372/8000] D loss: 0.1226, G loss: 8.6469\n",
      "[732/8000] D loss: 0.3627, G loss: 9.9299\n",
      "[1092/8000] D loss: 0.4256, G loss: 5.5000\n",
      "[1452/8000] D loss: 0.0269, G loss: 13.0572\n",
      "[1812/8000] D loss: 0.1512, G loss: 6.6845\n",
      "[2172/8000] D loss: 0.1738, G loss: 7.9848\n",
      "[2532/8000] D loss: 0.1413, G loss: 8.6603\n",
      "[2892/8000] D loss: 0.2632, G loss: 7.0381\n",
      "[3252/8000] D loss: 0.1305, G loss: 8.9204\n",
      "[3612/8000] D loss: 0.0106, G loss: 8.8787\n",
      "[3972/8000] D loss: 0.2523, G loss: 9.8913\n",
      "[4332/8000] D loss: 0.0283, G loss: 7.1391\n",
      "[4692/8000] D loss: 0.2506, G loss: 9.1707\n",
      "[5052/8000] D loss: 0.1883, G loss: 8.2695\n",
      "[5412/8000] D loss: 0.3090, G loss: 7.6103\n",
      "[5772/8000] D loss: 0.1536, G loss: 10.8552\n",
      "[6132/8000] D loss: 0.2977, G loss: 8.9169\n",
      "[6492/8000] D loss: 0.3078, G loss: 7.2159\n",
      "[6852/8000] D loss: 0.1180, G loss: 11.0844\n",
      "[7212/8000] D loss: 0.1882, G loss: 8.3742\n",
      "[7572/8000] D loss: 0.3572, G loss: 10.4827\n",
      "[7932/8000] D loss: 0.4528, G loss: 11.2146\n",
      "train error: \n",
      " D loss: 0.326237, G loss: 6.387082, D accuracy: 92.9%, cell accuracy: 93.8%, board accuracy: 5.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.305690, G loss: 8.206206, D accuracy: 94.4%, cell accuracy: 93.5%, board accuracy: 2.1% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2667, G loss: 7.5334\n",
      "[372/8000] D loss: 0.3449, G loss: 8.7429\n",
      "[732/8000] D loss: 0.3229, G loss: 6.7929\n",
      "[1092/8000] D loss: 0.4581, G loss: 8.5781\n",
      "[1452/8000] D loss: 0.1496, G loss: 6.8441\n",
      "[1812/8000] D loss: 0.0385, G loss: 10.0002\n",
      "[2172/8000] D loss: 0.3021, G loss: 8.2610\n",
      "[2532/8000] D loss: 0.2363, G loss: 6.5793\n",
      "[2892/8000] D loss: 0.0815, G loss: 8.2529\n",
      "[3252/8000] D loss: 0.1264, G loss: 7.8961\n",
      "[3612/8000] D loss: 0.4695, G loss: 7.3907\n",
      "[3972/8000] D loss: 0.7353, G loss: 7.9180\n",
      "[4332/8000] D loss: 0.1418, G loss: 9.9471\n",
      "[4692/8000] D loss: 0.1086, G loss: 11.9102\n",
      "[5052/8000] D loss: 0.1883, G loss: 7.5423\n",
      "[5412/8000] D loss: 0.0184, G loss: 7.3746\n",
      "[5772/8000] D loss: 0.0670, G loss: 7.8873\n",
      "[6132/8000] D loss: 0.1321, G loss: 9.9875\n",
      "[6492/8000] D loss: 0.0299, G loss: 9.5122\n",
      "[6852/8000] D loss: 0.1959, G loss: 9.0639\n",
      "[7212/8000] D loss: 0.2278, G loss: 6.2527\n",
      "[7572/8000] D loss: 0.0624, G loss: 12.4629\n",
      "[7932/8000] D loss: 0.2871, G loss: 8.2383\n",
      "train error: \n",
      " D loss: 0.202094, G loss: 8.670894, D accuracy: 95.0%, cell accuracy: 93.9%, board accuracy: 5.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.416798, G loss: 10.686599, D accuracy: 93.4%, cell accuracy: 93.6%, board accuracy: 2.1% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2014, G loss: 9.1164\n",
      "[372/8000] D loss: 0.0022, G loss: 11.3030\n",
      "[732/8000] D loss: 0.1112, G loss: 9.2410\n",
      "[1092/8000] D loss: 0.0150, G loss: 9.1722\n",
      "[1452/8000] D loss: 0.0074, G loss: 11.8406\n",
      "[1812/8000] D loss: 0.0480, G loss: 6.7822\n",
      "[2172/8000] D loss: 0.1374, G loss: 8.1723\n",
      "[2532/8000] D loss: 0.1369, G loss: 8.9184\n",
      "[2892/8000] D loss: 0.0300, G loss: 9.8797\n",
      "[3252/8000] D loss: 0.3681, G loss: 4.7723\n",
      "[3612/8000] D loss: 0.2254, G loss: 7.6908\n",
      "[3972/8000] D loss: 0.1918, G loss: 7.4712\n",
      "[4332/8000] D loss: 0.0561, G loss: 11.7961\n",
      "[4692/8000] D loss: 0.3604, G loss: 7.6805\n",
      "[5052/8000] D loss: 0.2601, G loss: 9.0436\n",
      "[5412/8000] D loss: 0.2097, G loss: 6.7375\n",
      "[5772/8000] D loss: 0.1534, G loss: 9.6289\n",
      "[6132/8000] D loss: 0.0594, G loss: 7.9753\n",
      "[6492/8000] D loss: 0.2334, G loss: 8.2493\n",
      "[6852/8000] D loss: 0.0324, G loss: 9.2873\n",
      "[7212/8000] D loss: 0.2261, G loss: 6.8631\n",
      "[7572/8000] D loss: 0.0352, G loss: 10.5617\n",
      "[7932/8000] D loss: 0.1079, G loss: 8.4748\n",
      "train error: \n",
      " D loss: 0.189699, G loss: 7.916567, D accuracy: 95.4%, cell accuracy: 93.9%, board accuracy: 5.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.317497, G loss: 10.154826, D accuracy: 94.8%, cell accuracy: 93.5%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0981, G loss: 7.5001\n",
      "[372/8000] D loss: 0.1813, G loss: 10.3571\n",
      "[732/8000] D loss: 0.2741, G loss: 7.3986\n",
      "[1092/8000] D loss: 0.0370, G loss: 10.2771\n",
      "[1452/8000] D loss: 0.0033, G loss: 11.0183\n",
      "[1812/8000] D loss: 0.0863, G loss: 8.4337\n",
      "[2172/8000] D loss: 0.3675, G loss: 7.8154\n",
      "[2532/8000] D loss: 0.4624, G loss: 9.1313\n",
      "[2892/8000] D loss: 0.1961, G loss: 7.1426\n",
      "[3252/8000] D loss: 0.1857, G loss: 9.2772\n",
      "[3612/8000] D loss: 0.0190, G loss: 9.7026\n",
      "[3972/8000] D loss: 0.1390, G loss: 8.8545\n",
      "[4332/8000] D loss: 0.1920, G loss: 10.2616\n",
      "[4692/8000] D loss: 0.3256, G loss: 6.7663\n",
      "[5052/8000] D loss: 0.1547, G loss: 13.1518\n",
      "[5412/8000] D loss: 0.0166, G loss: 8.3109\n",
      "[5772/8000] D loss: 0.0992, G loss: 11.0220\n",
      "[6132/8000] D loss: 0.0734, G loss: 7.8527\n",
      "[6492/8000] D loss: 0.0214, G loss: 6.9486\n",
      "[6852/8000] D loss: 0.0314, G loss: 8.0259\n",
      "[7212/8000] D loss: 0.0661, G loss: 8.9486\n",
      "[7572/8000] D loss: 0.3027, G loss: 8.2120\n",
      "[7932/8000] D loss: 0.0395, G loss: 10.3264\n",
      "train error: \n",
      " D loss: 0.195869, G loss: 8.590288, D accuracy: 95.4%, cell accuracy: 93.9%, board accuracy: 5.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.358001, G loss: 10.768720, D accuracy: 94.8%, cell accuracy: 93.5%, board accuracy: 2.7% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2618, G loss: 7.9868\n",
      "[372/8000] D loss: 0.1485, G loss: 10.0185\n",
      "[732/8000] D loss: 0.2407, G loss: 8.4070\n",
      "[1092/8000] D loss: 0.0801, G loss: 8.8179\n",
      "[1452/8000] D loss: 0.1390, G loss: 11.6466\n",
      "[1812/8000] D loss: 0.1489, G loss: 8.0237\n",
      "[2172/8000] D loss: 0.1217, G loss: 8.8575\n",
      "[2532/8000] D loss: 0.2617, G loss: 8.3920\n",
      "[2892/8000] D loss: 0.6652, G loss: 5.7856\n",
      "[3252/8000] D loss: 0.5561, G loss: 7.8590\n",
      "[3612/8000] D loss: 0.0164, G loss: 11.9065\n",
      "[3972/8000] D loss: 0.5216, G loss: 7.3317\n",
      "[4332/8000] D loss: 0.0447, G loss: 7.9696\n",
      "[4692/8000] D loss: 0.1080, G loss: 7.9095\n",
      "[5052/8000] D loss: 0.3721, G loss: 6.4040\n",
      "[5412/8000] D loss: 0.0361, G loss: 9.6527\n",
      "[5772/8000] D loss: 0.5391, G loss: 7.3069\n",
      "[6132/8000] D loss: 0.1272, G loss: 9.6457\n",
      "[6492/8000] D loss: 0.2392, G loss: 9.3792\n",
      "[6852/8000] D loss: 0.0429, G loss: 10.3245\n",
      "[7212/8000] D loss: 0.0237, G loss: 9.5039\n",
      "[7572/8000] D loss: 0.1043, G loss: 6.9519\n",
      "[7932/8000] D loss: 0.6933, G loss: 8.3756\n",
      "train error: \n",
      " D loss: 0.185364, G loss: 8.182503, D accuracy: 95.7%, cell accuracy: 93.9%, board accuracy: 5.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.330805, G loss: 10.386820, D accuracy: 95.1%, cell accuracy: 93.6%, board accuracy: 2.3% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1552, G loss: 10.3192\n",
      "[372/8000] D loss: 0.1606, G loss: 6.3779\n",
      "[732/8000] D loss: 0.3095, G loss: 5.4900\n",
      "[1092/8000] D loss: 0.0029, G loss: 11.5901\n",
      "[1452/8000] D loss: 0.4637, G loss: 9.2825\n",
      "[1812/8000] D loss: 0.0277, G loss: 10.1241\n",
      "[2172/8000] D loss: 0.0060, G loss: 8.9834\n",
      "[2532/8000] D loss: 0.1860, G loss: 10.4098\n",
      "[2892/8000] D loss: 0.1687, G loss: 7.0119\n",
      "[3252/8000] D loss: 0.0564, G loss: 10.9460\n",
      "[3612/8000] D loss: 0.1905, G loss: 10.9104\n",
      "[3972/8000] D loss: 0.1921, G loss: 5.8056\n",
      "[4332/8000] D loss: 0.2589, G loss: 9.3531\n",
      "[4692/8000] D loss: 0.1531, G loss: 10.8397\n",
      "[5052/8000] D loss: 0.4620, G loss: 5.2144\n",
      "[5412/8000] D loss: 0.2933, G loss: 8.1078\n",
      "[5772/8000] D loss: 0.2393, G loss: 10.3636\n",
      "[6132/8000] D loss: 0.1282, G loss: 10.3873\n",
      "[6492/8000] D loss: 0.1681, G loss: 8.0177\n",
      "[6852/8000] D loss: 0.1866, G loss: 8.9348\n",
      "[7212/8000] D loss: 0.3382, G loss: 4.8950\n",
      "[7572/8000] D loss: 0.0199, G loss: 12.4717\n",
      "[7932/8000] D loss: 0.0413, G loss: 9.5254\n",
      "train error: \n",
      " D loss: 0.270833, G loss: 6.986580, D accuracy: 93.8%, cell accuracy: 93.9%, board accuracy: 5.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.308619, G loss: 9.240056, D accuracy: 95.0%, cell accuracy: 93.6%, board accuracy: 2.4% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2989, G loss: 7.3668\n",
      "[372/8000] D loss: 0.1662, G loss: 7.5307\n",
      "[732/8000] D loss: 0.1780, G loss: 7.8425\n",
      "[1092/8000] D loss: 0.0430, G loss: 8.0303\n",
      "[1452/8000] D loss: 0.0110, G loss: 10.9065\n",
      "[1812/8000] D loss: 0.1185, G loss: 10.2361\n",
      "[2172/8000] D loss: 0.0903, G loss: 11.2838\n",
      "[2532/8000] D loss: 0.2383, G loss: 5.7518\n",
      "[2892/8000] D loss: 0.0223, G loss: 11.6157\n",
      "[3252/8000] D loss: 0.2155, G loss: 8.5126\n",
      "[3612/8000] D loss: 0.1154, G loss: 10.1875\n",
      "[3972/8000] D loss: 0.0648, G loss: 10.0124\n",
      "[4332/8000] D loss: 0.2603, G loss: 8.4562\n",
      "[4692/8000] D loss: 0.1282, G loss: 5.6480\n",
      "[5052/8000] D loss: 0.2163, G loss: 7.7646\n",
      "[5412/8000] D loss: 0.2885, G loss: 11.3206\n",
      "[5772/8000] D loss: 0.0040, G loss: 12.7886\n",
      "[6132/8000] D loss: 0.4920, G loss: 10.5762\n",
      "[6492/8000] D loss: 0.0644, G loss: 8.7764\n",
      "[6852/8000] D loss: 0.1721, G loss: 10.1003\n",
      "[7212/8000] D loss: 0.3166, G loss: 8.5553\n",
      "[7572/8000] D loss: 0.1905, G loss: 9.4895\n",
      "[7932/8000] D loss: 0.2620, G loss: 6.5026\n",
      "train error: \n",
      " D loss: 0.231144, G loss: 9.501872, D accuracy: 94.5%, cell accuracy: 94.0%, board accuracy: 6.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.468422, G loss: 11.703477, D accuracy: 92.5%, cell accuracy: 93.6%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3799, G loss: 6.4299\n",
      "[372/8000] D loss: 0.4482, G loss: 5.8358\n",
      "[732/8000] D loss: 0.1868, G loss: 6.9740\n",
      "[1092/8000] D loss: 0.1204, G loss: 10.4532\n",
      "[1452/8000] D loss: 0.1161, G loss: 13.4290\n",
      "[1812/8000] D loss: 0.1771, G loss: 8.1370\n",
      "[2172/8000] D loss: 0.1400, G loss: 8.4719\n",
      "[2532/8000] D loss: 0.1505, G loss: 8.1696\n",
      "[2892/8000] D loss: 0.0022, G loss: 12.0651\n",
      "[3252/8000] D loss: 0.2741, G loss: 5.6606\n",
      "[3612/8000] D loss: 0.1990, G loss: 8.9360\n",
      "[3972/8000] D loss: 0.1152, G loss: 10.2645\n",
      "[4332/8000] D loss: 0.2289, G loss: 9.7591\n",
      "[4692/8000] D loss: 0.3078, G loss: 6.8992\n",
      "[5052/8000] D loss: 0.1329, G loss: 12.3399\n",
      "[5412/8000] D loss: 0.2552, G loss: 9.5471\n",
      "[5772/8000] D loss: 0.2553, G loss: 8.3150\n",
      "[6132/8000] D loss: 0.1602, G loss: 9.2714\n",
      "[6492/8000] D loss: 0.0779, G loss: 9.4054\n",
      "[6852/8000] D loss: 0.0242, G loss: 10.1171\n",
      "[7212/8000] D loss: 0.2208, G loss: 8.4916\n",
      "[7572/8000] D loss: 0.5977, G loss: 5.2289\n",
      "[7932/8000] D loss: 0.0214, G loss: 10.3143\n",
      "train error: \n",
      " D loss: 0.201310, G loss: 8.692606, D accuracy: 95.3%, cell accuracy: 94.0%, board accuracy: 6.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.373872, G loss: 10.803290, D accuracy: 94.5%, cell accuracy: 93.6%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3152, G loss: 10.7533\n",
      "[372/8000] D loss: 0.1294, G loss: 11.3017\n",
      "[732/8000] D loss: 0.1090, G loss: 9.8871\n",
      "[1092/8000] D loss: 0.3147, G loss: 6.7293\n",
      "[1452/8000] D loss: 0.1001, G loss: 9.5648\n",
      "[1812/8000] D loss: 0.2313, G loss: 9.9838\n",
      "[2172/8000] D loss: 0.1902, G loss: 8.8110\n",
      "[2532/8000] D loss: 0.1176, G loss: 9.5613\n",
      "[2892/8000] D loss: 0.0385, G loss: 7.7273\n",
      "[3252/8000] D loss: 0.0341, G loss: 9.1312\n",
      "[3612/8000] D loss: 0.4940, G loss: 9.6957\n",
      "[3972/8000] D loss: 0.1362, G loss: 7.5541\n",
      "[4332/8000] D loss: 0.0978, G loss: 6.3682\n",
      "[4692/8000] D loss: 0.3809, G loss: 6.6583\n",
      "[5052/8000] D loss: 0.0033, G loss: 11.4409\n",
      "[5412/8000] D loss: 0.6053, G loss: 4.7971\n",
      "[5772/8000] D loss: 0.3935, G loss: 8.0707\n",
      "[6132/8000] D loss: 0.0591, G loss: 8.4062\n",
      "[6492/8000] D loss: 0.3113, G loss: 8.3625\n",
      "[6852/8000] D loss: 0.1702, G loss: 10.1527\n",
      "[7212/8000] D loss: 0.1842, G loss: 7.0893\n",
      "[7572/8000] D loss: 0.1193, G loss: 8.4451\n",
      "[7932/8000] D loss: 0.1811, G loss: 7.0974\n",
      "train error: \n",
      " D loss: 0.257042, G loss: 6.803946, D accuracy: 94.2%, cell accuracy: 94.0%, board accuracy: 6.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.292349, G loss: 9.044943, D accuracy: 94.8%, cell accuracy: 93.6%, board accuracy: 2.6% \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1490, G loss: 5.7742\n",
      "[372/8000] D loss: 0.3616, G loss: 9.5483\n",
      "[732/8000] D loss: 0.1740, G loss: 9.2790\n",
      "[1092/8000] D loss: 0.1208, G loss: 10.3751\n",
      "[1452/8000] D loss: 0.2288, G loss: 8.2285\n",
      "[1812/8000] D loss: 0.1249, G loss: 8.1218\n",
      "[2172/8000] D loss: 0.0108, G loss: 10.7785\n",
      "[2532/8000] D loss: 0.3186, G loss: 9.2632\n",
      "[2892/8000] D loss: 0.3657, G loss: 4.2771\n",
      "[3252/8000] D loss: 0.3096, G loss: 6.4387\n",
      "[3612/8000] D loss: 0.2500, G loss: 10.3644\n",
      "[3972/8000] D loss: 0.2668, G loss: 5.4917\n",
      "[4332/8000] D loss: 0.3180, G loss: 8.3296\n",
      "[4692/8000] D loss: 0.4281, G loss: 7.1890\n",
      "[5052/8000] D loss: 0.0830, G loss: 8.7221\n",
      "[5412/8000] D loss: 0.0258, G loss: 8.1005\n",
      "[5772/8000] D loss: 0.1447, G loss: 9.4599\n",
      "[6132/8000] D loss: 0.1506, G loss: 9.6087\n",
      "[6492/8000] D loss: 0.0476, G loss: 7.8459\n",
      "[6852/8000] D loss: 0.1002, G loss: 10.4976\n",
      "[7212/8000] D loss: 0.0223, G loss: 11.5257\n",
      "[7572/8000] D loss: 0.3470, G loss: 8.5230\n",
      "[7932/8000] D loss: 0.0067, G loss: 10.7737\n",
      "train error: \n",
      " D loss: 0.199597, G loss: 8.194693, D accuracy: 95.4%, cell accuracy: 94.0%, board accuracy: 6.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.344495, G loss: 10.425964, D accuracy: 95.1%, cell accuracy: 93.7%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4668, G loss: 5.6261\n",
      "[372/8000] D loss: 0.3037, G loss: 7.3700\n",
      "[732/8000] D loss: 0.0603, G loss: 10.6314\n",
      "[1092/8000] D loss: 0.2115, G loss: 10.1278\n",
      "[1452/8000] D loss: 0.1359, G loss: 10.6719\n",
      "[1812/8000] D loss: 0.0148, G loss: 10.7066\n",
      "[2172/8000] D loss: 0.1496, G loss: 10.5920\n",
      "[2532/8000] D loss: 0.3676, G loss: 8.8939\n",
      "[2892/8000] D loss: 0.0085, G loss: 10.3114\n",
      "[3252/8000] D loss: 0.1173, G loss: 10.0054\n",
      "[3612/8000] D loss: 0.1348, G loss: 8.6131\n",
      "[3972/8000] D loss: 0.2110, G loss: 7.8173\n",
      "[4332/8000] D loss: 0.1407, G loss: 10.2526\n",
      "[4692/8000] D loss: 0.0157, G loss: 9.5357\n",
      "[5052/8000] D loss: 0.2412, G loss: 10.2423\n",
      "[5412/8000] D loss: 0.3261, G loss: 8.6062\n",
      "[5772/8000] D loss: 0.1396, G loss: 8.7565\n",
      "[6132/8000] D loss: 0.1260, G loss: 10.1025\n",
      "[6492/8000] D loss: 0.3270, G loss: 12.2532\n",
      "[6852/8000] D loss: 0.3332, G loss: 9.0502\n",
      "[7212/8000] D loss: 0.1167, G loss: 6.3732\n",
      "[7572/8000] D loss: 0.1583, G loss: 10.5922\n",
      "[7932/8000] D loss: 0.1153, G loss: 9.8063\n",
      "train error: \n",
      " D loss: 0.239550, G loss: 7.688222, D accuracy: 94.5%, cell accuracy: 94.0%, board accuracy: 6.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.322080, G loss: 9.928069, D accuracy: 95.1%, cell accuracy: 93.6%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3146, G loss: 6.7101\n",
      "[372/8000] D loss: 0.1468, G loss: 9.8374\n",
      "[732/8000] D loss: 0.2755, G loss: 7.6101\n",
      "[1092/8000] D loss: 0.0880, G loss: 5.9227\n",
      "[1452/8000] D loss: 0.1727, G loss: 9.6292\n",
      "[1812/8000] D loss: 0.1113, G loss: 10.2724\n",
      "[2172/8000] D loss: 0.0212, G loss: 7.2770\n",
      "[2532/8000] D loss: 0.1362, G loss: 7.0656\n",
      "[2892/8000] D loss: 0.0023, G loss: 12.4217\n",
      "[3252/8000] D loss: 0.2517, G loss: 9.4930\n",
      "[3612/8000] D loss: 0.2957, G loss: 9.2840\n",
      "[3972/8000] D loss: 0.0135, G loss: 8.9006\n",
      "[4332/8000] D loss: 0.1520, G loss: 11.9482\n",
      "[4692/8000] D loss: 0.4417, G loss: 7.6884\n",
      "[5052/8000] D loss: 0.0236, G loss: 8.2221\n",
      "[5412/8000] D loss: 0.0148, G loss: 7.7154\n",
      "[5772/8000] D loss: 0.1933, G loss: 7.7906\n",
      "[6132/8000] D loss: 0.1267, G loss: 9.0000\n",
      "[6492/8000] D loss: 0.2218, G loss: 5.4933\n",
      "[6852/8000] D loss: 0.3884, G loss: 6.3170\n",
      "[7212/8000] D loss: 0.2068, G loss: 10.5513\n",
      "[7572/8000] D loss: 0.4255, G loss: 10.3311\n",
      "[7932/8000] D loss: 0.0500, G loss: 7.2374\n",
      "train error: \n",
      " D loss: 0.239161, G loss: 8.371179, D accuracy: 94.3%, cell accuracy: 94.0%, board accuracy: 6.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.337352, G loss: 10.769284, D accuracy: 95.0%, cell accuracy: 93.7%, board accuracy: 2.6% \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2069, G loss: 8.7148\n",
      "[372/8000] D loss: 0.0244, G loss: 8.0987\n",
      "[732/8000] D loss: 0.0968, G loss: 7.9957\n",
      "[1092/8000] D loss: 0.0487, G loss: 11.7333\n",
      "[1452/8000] D loss: 0.0026, G loss: 11.8904\n",
      "[1812/8000] D loss: 0.0030, G loss: 12.1968\n",
      "[2172/8000] D loss: 0.2905, G loss: 7.9281\n",
      "[2532/8000] D loss: 0.0122, G loss: 11.5660\n",
      "[2892/8000] D loss: 0.0437, G loss: 13.9114\n",
      "[3252/8000] D loss: 0.0961, G loss: 9.8546\n",
      "[3612/8000] D loss: 0.1039, G loss: 8.3412\n",
      "[3972/8000] D loss: 0.3523, G loss: 5.8963\n",
      "[4332/8000] D loss: 0.1337, G loss: 8.1961\n",
      "[4692/8000] D loss: 0.2273, G loss: 10.6006\n",
      "[5052/8000] D loss: 0.1360, G loss: 9.2121\n",
      "[5412/8000] D loss: 0.2757, G loss: 9.4845\n",
      "[5772/8000] D loss: 0.0728, G loss: 7.3728\n",
      "[6132/8000] D loss: 0.2046, G loss: 7.4113\n",
      "[6492/8000] D loss: 0.1200, G loss: 12.9197\n",
      "[6852/8000] D loss: 0.1470, G loss: 10.4650\n",
      "[7212/8000] D loss: 0.1313, G loss: 10.6124\n",
      "[7572/8000] D loss: 0.2826, G loss: 7.9840\n",
      "[7932/8000] D loss: 0.0108, G loss: 13.4320\n",
      "train error: \n",
      " D loss: 0.198317, G loss: 8.270829, D accuracy: 95.0%, cell accuracy: 94.0%, board accuracy: 6.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.326860, G loss: 10.574808, D accuracy: 95.0%, cell accuracy: 93.6%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1992, G loss: 6.8817\n",
      "[372/8000] D loss: 0.2171, G loss: 7.4580\n",
      "[732/8000] D loss: 0.0496, G loss: 10.8121\n",
      "[1092/8000] D loss: 0.1222, G loss: 8.9180\n",
      "[1452/8000] D loss: 0.1909, G loss: 10.4239\n",
      "[1812/8000] D loss: 0.1558, G loss: 7.3933\n",
      "[2172/8000] D loss: 0.3516, G loss: 7.4382\n",
      "[2532/8000] D loss: 0.1595, G loss: 10.9790\n",
      "[2892/8000] D loss: 0.1528, G loss: 9.0450\n",
      "[3252/8000] D loss: 0.1305, G loss: 9.5155\n",
      "[3612/8000] D loss: 0.0532, G loss: 9.7892\n",
      "[3972/8000] D loss: 0.1925, G loss: 8.9453\n",
      "[4332/8000] D loss: 0.0345, G loss: 11.4828\n",
      "[4692/8000] D loss: 0.4583, G loss: 10.1820\n",
      "[5052/8000] D loss: 0.1849, G loss: 8.4689\n",
      "[5412/8000] D loss: 0.6484, G loss: 8.3992\n",
      "[5772/8000] D loss: 0.4261, G loss: 5.8653\n",
      "[6132/8000] D loss: 0.3557, G loss: 9.1456\n",
      "[6492/8000] D loss: 0.4915, G loss: 6.0795\n",
      "[6852/8000] D loss: 0.1495, G loss: 9.9697\n",
      "[7212/8000] D loss: 0.2167, G loss: 7.1170\n",
      "[7572/8000] D loss: 0.1057, G loss: 10.0812\n",
      "[7932/8000] D loss: 0.1082, G loss: 11.5205\n",
      "train error: \n",
      " D loss: 0.195677, G loss: 8.762304, D accuracy: 95.1%, cell accuracy: 94.0%, board accuracy: 6.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.372696, G loss: 11.091547, D accuracy: 94.3%, cell accuracy: 93.6%, board accuracy: 2.6% \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1936, G loss: 6.5179\n",
      "[372/8000] D loss: 0.4000, G loss: 10.3439\n",
      "[732/8000] D loss: 0.1486, G loss: 6.8325\n",
      "[1092/8000] D loss: 0.2730, G loss: 9.7569\n",
      "[1452/8000] D loss: 0.2495, G loss: 6.5671\n",
      "[1812/8000] D loss: 0.5597, G loss: 8.8106\n",
      "[2172/8000] D loss: 0.2411, G loss: 7.8681\n",
      "[2532/8000] D loss: 0.2560, G loss: 6.9044\n",
      "[2892/8000] D loss: 0.1235, G loss: 10.6777\n",
      "[3252/8000] D loss: 0.1257, G loss: 7.0457\n",
      "[3612/8000] D loss: 0.3470, G loss: 9.5713\n",
      "[3972/8000] D loss: 0.1306, G loss: 7.7548\n",
      "[4332/8000] D loss: 0.0880, G loss: 9.1508\n",
      "[4692/8000] D loss: 0.2803, G loss: 6.7714\n",
      "[5052/8000] D loss: 0.1134, G loss: 11.3573\n",
      "[5412/8000] D loss: 0.0928, G loss: 12.4035\n",
      "[5772/8000] D loss: 0.2177, G loss: 6.8233\n",
      "[6132/8000] D loss: 0.2762, G loss: 9.6278\n",
      "[6492/8000] D loss: 0.2455, G loss: 12.1102\n",
      "[6852/8000] D loss: 0.7338, G loss: 5.4998\n",
      "[7212/8000] D loss: 0.3205, G loss: 5.5002\n",
      "[7572/8000] D loss: 0.1432, G loss: 6.6128\n",
      "[7932/8000] D loss: 0.2710, G loss: 8.5486\n",
      "train error: \n",
      " D loss: 0.204080, G loss: 8.689935, D accuracy: 95.0%, cell accuracy: 94.0%, board accuracy: 6.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.376544, G loss: 10.844438, D accuracy: 94.3%, cell accuracy: 93.6%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2262, G loss: 6.2237\n",
      "[372/8000] D loss: 0.2209, G loss: 11.1069\n",
      "[732/8000] D loss: 0.1198, G loss: 7.9868\n",
      "[1092/8000] D loss: 0.2820, G loss: 8.0356\n",
      "[1452/8000] D loss: 0.6197, G loss: 4.2767\n",
      "[1812/8000] D loss: 0.2049, G loss: 7.3970\n",
      "[2172/8000] D loss: 0.1241, G loss: 10.4637\n",
      "[2532/8000] D loss: 0.4786, G loss: 6.6037\n",
      "[2892/8000] D loss: 0.2769, G loss: 5.6166\n",
      "[3252/8000] D loss: 0.4880, G loss: 8.5313\n",
      "[3612/8000] D loss: 0.3199, G loss: 9.4462\n",
      "[3972/8000] D loss: 0.0948, G loss: 8.7630\n",
      "[4332/8000] D loss: 0.3653, G loss: 6.7587\n",
      "[4692/8000] D loss: 0.3625, G loss: 6.1801\n",
      "[5052/8000] D loss: 0.1018, G loss: 13.0747\n",
      "[5412/8000] D loss: 0.2749, G loss: 9.9293\n",
      "[5772/8000] D loss: 0.2817, G loss: 6.9047\n",
      "[6132/8000] D loss: 0.1562, G loss: 8.3654\n",
      "[6492/8000] D loss: 0.1588, G loss: 8.0767\n",
      "[6852/8000] D loss: 0.1993, G loss: 7.5805\n",
      "[7212/8000] D loss: 0.2602, G loss: 8.1770\n",
      "[7572/8000] D loss: 0.1254, G loss: 8.7676\n",
      "[7932/8000] D loss: 0.0427, G loss: 9.5990\n",
      "train error: \n",
      " D loss: 0.192504, G loss: 9.121217, D accuracy: 95.2%, cell accuracy: 93.9%, board accuracy: 6.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.384044, G loss: 11.521879, D accuracy: 94.9%, cell accuracy: 93.5%, board accuracy: 2.6% \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0037, G loss: 11.9618\n",
      "[372/8000] D loss: 0.0248, G loss: 11.4523\n",
      "[732/8000] D loss: 0.2236, G loss: 7.4971\n",
      "[1092/8000] D loss: 0.4912, G loss: 7.3569\n",
      "[1452/8000] D loss: 0.0489, G loss: 9.5993\n",
      "[1812/8000] D loss: 0.0124, G loss: 10.5741\n",
      "[2172/8000] D loss: 0.4034, G loss: 6.8348\n",
      "[2532/8000] D loss: 0.2374, G loss: 8.3543\n",
      "[2892/8000] D loss: 0.2469, G loss: 7.7717\n",
      "[3252/8000] D loss: 0.3921, G loss: 6.7256\n",
      "[3612/8000] D loss: 0.4668, G loss: 11.1966\n",
      "[3972/8000] D loss: 0.0602, G loss: 9.5804\n",
      "[4332/8000] D loss: 0.0321, G loss: 10.4000\n",
      "[4692/8000] D loss: 0.1501, G loss: 8.9363\n",
      "[5052/8000] D loss: 0.1817, G loss: 7.8183\n",
      "[5412/8000] D loss: 0.2018, G loss: 9.2423\n",
      "[5772/8000] D loss: 0.1624, G loss: 9.1869\n",
      "[6132/8000] D loss: 0.2826, G loss: 10.0090\n",
      "[6492/8000] D loss: 0.2780, G loss: 6.5579\n",
      "[6852/8000] D loss: 0.0159, G loss: 7.3406\n",
      "[7212/8000] D loss: 0.1265, G loss: 10.6653\n",
      "[7572/8000] D loss: 0.0024, G loss: 10.4824\n",
      "[7932/8000] D loss: 0.1931, G loss: 9.8702\n",
      "train error: \n",
      " D loss: 0.244388, G loss: 10.698591, D accuracy: 94.0%, cell accuracy: 94.0%, board accuracy: 6.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.497877, G loss: 13.008236, D accuracy: 93.0%, cell accuracy: 93.6%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0055, G loss: 14.7517\n",
      "[372/8000] D loss: 0.0400, G loss: 12.9485\n",
      "[732/8000] D loss: 0.2875, G loss: 9.7130\n",
      "[1092/8000] D loss: 0.0016, G loss: 11.5557\n",
      "[1452/8000] D loss: 0.2265, G loss: 9.9067\n",
      "[1812/8000] D loss: 0.1368, G loss: 10.5546\n",
      "[2172/8000] D loss: 0.1584, G loss: 9.8714\n",
      "[2532/8000] D loss: 0.3081, G loss: 7.3469\n",
      "[2892/8000] D loss: 0.5372, G loss: 8.1576\n",
      "[3252/8000] D loss: 0.0952, G loss: 10.0187\n",
      "[3612/8000] D loss: 0.1673, G loss: 12.4364\n",
      "[3972/8000] D loss: 0.1559, G loss: 9.6338\n",
      "[4332/8000] D loss: 0.0863, G loss: 10.0223\n",
      "[4692/8000] D loss: 0.1077, G loss: 7.6797\n",
      "[5052/8000] D loss: 0.0510, G loss: 8.9232\n",
      "[5412/8000] D loss: 0.5378, G loss: 7.3147\n",
      "[5772/8000] D loss: 0.0093, G loss: 12.2941\n",
      "[6132/8000] D loss: 0.2678, G loss: 5.5162\n",
      "[6492/8000] D loss: 0.2518, G loss: 8.7902\n",
      "[6852/8000] D loss: 0.0191, G loss: 9.4083\n",
      "[7212/8000] D loss: 0.1126, G loss: 7.2780\n",
      "[7572/8000] D loss: 0.5327, G loss: 9.3619\n",
      "[7932/8000] D loss: 0.1197, G loss: 9.5134\n",
      "train error: \n",
      " D loss: 0.193220, G loss: 8.625558, D accuracy: 95.1%, cell accuracy: 94.0%, board accuracy: 7.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.377411, G loss: 10.870447, D accuracy: 94.1%, cell accuracy: 93.6%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1887, G loss: 11.2200\n",
      "[372/8000] D loss: 0.3961, G loss: 6.1631\n",
      "[732/8000] D loss: 0.0340, G loss: 12.5777\n",
      "[1092/8000] D loss: 0.5118, G loss: 6.5256\n",
      "[1452/8000] D loss: 0.1397, G loss: 9.1519\n",
      "[1812/8000] D loss: 0.1956, G loss: 9.6606\n",
      "[2172/8000] D loss: 0.2174, G loss: 11.5031\n",
      "[2532/8000] D loss: 0.5953, G loss: 8.9675\n",
      "[2892/8000] D loss: 0.1986, G loss: 11.3556\n",
      "[3252/8000] D loss: 0.2064, G loss: 8.9422\n",
      "[3612/8000] D loss: 0.2528, G loss: 8.5080\n",
      "[3972/8000] D loss: 0.0411, G loss: 11.1534\n",
      "[4332/8000] D loss: 0.3349, G loss: 6.5939\n",
      "[4692/8000] D loss: 0.2203, G loss: 7.4413\n",
      "[5052/8000] D loss: 0.2798, G loss: 9.3939\n",
      "[5412/8000] D loss: 0.2226, G loss: 10.4370\n",
      "[5772/8000] D loss: 0.1770, G loss: 7.3334\n",
      "[6132/8000] D loss: 0.0515, G loss: 12.4313\n",
      "[6492/8000] D loss: 0.0704, G loss: 9.1379\n",
      "[6852/8000] D loss: 0.2709, G loss: 8.9042\n",
      "[7212/8000] D loss: 0.3745, G loss: 7.5327\n",
      "[7572/8000] D loss: 0.0215, G loss: 12.2025\n",
      "[7932/8000] D loss: 0.0886, G loss: 7.5166\n",
      "train error: \n",
      " D loss: 0.190642, G loss: 8.331989, D accuracy: 95.2%, cell accuracy: 94.0%, board accuracy: 6.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.322868, G loss: 10.700427, D accuracy: 95.1%, cell accuracy: 93.6%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1275, G loss: 7.6197\n",
      "[372/8000] D loss: 0.1291, G loss: 11.4798\n",
      "[732/8000] D loss: 0.3811, G loss: 8.2137\n",
      "[1092/8000] D loss: 0.1806, G loss: 9.1506\n",
      "[1452/8000] D loss: 0.4233, G loss: 12.2592\n",
      "[1812/8000] D loss: 0.0118, G loss: 11.3784\n",
      "[2172/8000] D loss: 0.3049, G loss: 10.6015\n",
      "[2532/8000] D loss: 0.1738, G loss: 6.6527\n",
      "[2892/8000] D loss: 0.1942, G loss: 8.3295\n",
      "[3252/8000] D loss: 0.3941, G loss: 7.3277\n",
      "[3612/8000] D loss: 0.0112, G loss: 11.1963\n",
      "[3972/8000] D loss: 0.0457, G loss: 10.5391\n",
      "[4332/8000] D loss: 0.3016, G loss: 9.2241\n",
      "[4692/8000] D loss: 0.0602, G loss: 8.5916\n",
      "[5052/8000] D loss: 0.0751, G loss: 11.0476\n",
      "[5412/8000] D loss: 0.1702, G loss: 8.5848\n",
      "[5772/8000] D loss: 0.3257, G loss: 8.4574\n",
      "[6132/8000] D loss: 0.1284, G loss: 9.1322\n",
      "[6492/8000] D loss: 0.0964, G loss: 10.3034\n",
      "[6852/8000] D loss: 0.2899, G loss: 10.4885\n",
      "[7212/8000] D loss: 0.2066, G loss: 8.1006\n",
      "[7572/8000] D loss: 0.4877, G loss: 7.1538\n",
      "[7932/8000] D loss: 0.2598, G loss: 9.2608\n",
      "train error: \n",
      " D loss: 0.217492, G loss: 8.598074, D accuracy: 94.9%, cell accuracy: 94.1%, board accuracy: 7.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.386016, G loss: 11.053776, D accuracy: 94.5%, cell accuracy: 93.7%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4300, G loss: 8.4383\n",
      "[372/8000] D loss: 0.1872, G loss: 6.7705\n",
      "[732/8000] D loss: 0.5440, G loss: 9.5057\n",
      "[1092/8000] D loss: 0.2634, G loss: 7.6078\n",
      "[1452/8000] D loss: 0.0305, G loss: 9.5297\n",
      "[1812/8000] D loss: 0.5396, G loss: 9.7652\n",
      "[2172/8000] D loss: 0.0864, G loss: 9.3533\n",
      "[2532/8000] D loss: 0.0158, G loss: 9.3199\n",
      "[2892/8000] D loss: 0.0527, G loss: 9.7478\n",
      "[3252/8000] D loss: 0.1474, G loss: 9.4389\n",
      "[3612/8000] D loss: 0.0418, G loss: 11.6229\n",
      "[3972/8000] D loss: 0.1989, G loss: 6.9779\n",
      "[4332/8000] D loss: 0.1010, G loss: 10.2244\n",
      "[4692/8000] D loss: 0.0464, G loss: 8.9819\n",
      "[5052/8000] D loss: 0.0702, G loss: 11.1873\n",
      "[5412/8000] D loss: 0.2888, G loss: 7.0231\n",
      "[5772/8000] D loss: 0.1869, G loss: 7.7400\n",
      "[6132/8000] D loss: 0.2481, G loss: 7.6487\n",
      "[6492/8000] D loss: 0.6696, G loss: 9.1803\n",
      "[6852/8000] D loss: 0.1797, G loss: 9.2276\n",
      "[7212/8000] D loss: 0.0221, G loss: 12.0695\n",
      "[7572/8000] D loss: 0.4530, G loss: 5.6624\n",
      "[7932/8000] D loss: 0.1683, G loss: 8.1914\n",
      "train error: \n",
      " D loss: 0.192713, G loss: 8.726627, D accuracy: 95.2%, cell accuracy: 94.0%, board accuracy: 6.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.371613, G loss: 11.066564, D accuracy: 94.6%, cell accuracy: 93.6%, board accuracy: 2.7% \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4616, G loss: 6.5520\n",
      "[372/8000] D loss: 0.1862, G loss: 8.6882\n",
      "[732/8000] D loss: 0.0681, G loss: 12.6199\n",
      "[1092/8000] D loss: 0.4880, G loss: 8.0612\n",
      "[1452/8000] D loss: 0.3867, G loss: 9.1039\n",
      "[1812/8000] D loss: 0.0710, G loss: 10.3548\n",
      "[2172/8000] D loss: 0.0133, G loss: 8.7540\n",
      "[2532/8000] D loss: 0.0774, G loss: 9.0498\n",
      "[2892/8000] D loss: 0.3584, G loss: 9.9138\n",
      "[3252/8000] D loss: 0.0458, G loss: 8.1358\n",
      "[3612/8000] D loss: 0.0272, G loss: 12.1303\n",
      "[3972/8000] D loss: 0.1455, G loss: 9.8763\n",
      "[4332/8000] D loss: 0.1560, G loss: 9.4627\n",
      "[4692/8000] D loss: 0.2310, G loss: 7.4907\n",
      "[5052/8000] D loss: 0.1524, G loss: 9.5073\n",
      "[5412/8000] D loss: 0.4263, G loss: 7.9212\n",
      "[5772/8000] D loss: 0.0591, G loss: 6.7998\n",
      "[6132/8000] D loss: 0.2063, G loss: 11.8021\n",
      "[6492/8000] D loss: 0.5716, G loss: 6.8323\n",
      "[6852/8000] D loss: 0.2545, G loss: 9.1073\n",
      "[7212/8000] D loss: 0.0941, G loss: 7.0536\n",
      "[7572/8000] D loss: 0.0511, G loss: 10.4325\n",
      "[7932/8000] D loss: 0.0811, G loss: 6.6122\n",
      "train error: \n",
      " D loss: 0.277340, G loss: 6.976879, D accuracy: 93.8%, cell accuracy: 94.0%, board accuracy: 6.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.311003, G loss: 9.308058, D accuracy: 95.0%, cell accuracy: 93.6%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5884, G loss: 7.0821\n",
      "[372/8000] D loss: 0.2088, G loss: 7.7755\n",
      "[732/8000] D loss: 0.0434, G loss: 9.2207\n",
      "[1092/8000] D loss: 0.1439, G loss: 8.3464\n",
      "[1452/8000] D loss: 0.2864, G loss: 5.6724\n",
      "[1812/8000] D loss: 0.4648, G loss: 8.0856\n",
      "[2172/8000] D loss: 0.1811, G loss: 8.5661\n",
      "[2532/8000] D loss: 0.2062, G loss: 8.9880\n",
      "[2892/8000] D loss: 0.6211, G loss: 6.2808\n",
      "[3252/8000] D loss: 0.0568, G loss: 11.7491\n",
      "[3612/8000] D loss: 0.1623, G loss: 9.4668\n",
      "[3972/8000] D loss: 0.1110, G loss: 11.2528\n",
      "[4332/8000] D loss: 0.0544, G loss: 9.1403\n",
      "[4692/8000] D loss: 0.4251, G loss: 10.4704\n",
      "[5052/8000] D loss: 0.1558, G loss: 9.6624\n",
      "[5412/8000] D loss: 0.5271, G loss: 5.2148\n",
      "[5772/8000] D loss: 0.1177, G loss: 8.2158\n",
      "[6132/8000] D loss: 0.1335, G loss: 9.4588\n",
      "[6492/8000] D loss: 0.1323, G loss: 9.5327\n",
      "[6852/8000] D loss: 0.1088, G loss: 12.4801\n",
      "[7212/8000] D loss: 0.1207, G loss: 9.0773\n",
      "[7572/8000] D loss: 0.0320, G loss: 10.8768\n",
      "[7932/8000] D loss: 0.1646, G loss: 7.1231\n",
      "train error: \n",
      " D loss: 0.208999, G loss: 8.417236, D accuracy: 94.8%, cell accuracy: 94.0%, board accuracy: 6.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.345217, G loss: 10.727351, D accuracy: 94.8%, cell accuracy: 93.7%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0096, G loss: 10.6841\n",
      "[372/8000] D loss: 0.3243, G loss: 9.0452\n",
      "[732/8000] D loss: 0.4545, G loss: 7.5267\n",
      "[1092/8000] D loss: 0.1713, G loss: 9.0222\n",
      "[1452/8000] D loss: 0.1587, G loss: 8.2185\n",
      "[1812/8000] D loss: 0.0394, G loss: 10.5519\n",
      "[2172/8000] D loss: 0.1313, G loss: 10.7781\n",
      "[2532/8000] D loss: 0.0146, G loss: 12.1104\n",
      "[2892/8000] D loss: 0.0266, G loss: 12.9245\n",
      "[3252/8000] D loss: 0.2573, G loss: 7.3440\n",
      "[3612/8000] D loss: 0.3057, G loss: 4.0881\n",
      "[3972/8000] D loss: 0.1280, G loss: 9.3156\n",
      "[4332/8000] D loss: 0.5003, G loss: 7.1119\n",
      "[4692/8000] D loss: 0.0908, G loss: 8.3183\n",
      "[5052/8000] D loss: 0.1951, G loss: 12.0243\n",
      "[5412/8000] D loss: 0.3993, G loss: 10.4435\n",
      "[5772/8000] D loss: 0.1293, G loss: 11.2792\n",
      "[6132/8000] D loss: 0.5756, G loss: 10.0984\n",
      "[6492/8000] D loss: 0.0230, G loss: 13.2909\n",
      "[6852/8000] D loss: 0.0546, G loss: 6.0092\n",
      "[7212/8000] D loss: 0.2316, G loss: 9.7575\n",
      "[7572/8000] D loss: 0.3631, G loss: 8.0498\n",
      "[7932/8000] D loss: 0.1521, G loss: 10.2583\n",
      "train error: \n",
      " D loss: 0.207231, G loss: 8.915538, D accuracy: 94.8%, cell accuracy: 94.0%, board accuracy: 6.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.441868, G loss: 11.146750, D accuracy: 93.6%, cell accuracy: 93.7%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0135, G loss: 9.9168\n",
      "[372/8000] D loss: 0.1433, G loss: 8.0591\n",
      "[732/8000] D loss: 0.5116, G loss: 6.3073\n",
      "[1092/8000] D loss: 0.5835, G loss: 7.5165\n",
      "[1452/8000] D loss: 0.0232, G loss: 12.2285\n",
      "[1812/8000] D loss: 0.3107, G loss: 8.8086\n",
      "[2172/8000] D loss: 0.0187, G loss: 13.1124\n",
      "[2532/8000] D loss: 0.4495, G loss: 7.1992\n",
      "[2892/8000] D loss: 0.0396, G loss: 10.1609\n",
      "[3252/8000] D loss: 0.1637, G loss: 8.8371\n",
      "[3612/8000] D loss: 0.1881, G loss: 5.6599\n",
      "[3972/8000] D loss: 0.1324, G loss: 8.4101\n",
      "[4332/8000] D loss: 0.3474, G loss: 7.2724\n",
      "[4692/8000] D loss: 0.4621, G loss: 4.2912\n",
      "[5052/8000] D loss: 0.1693, G loss: 12.1621\n",
      "[5412/8000] D loss: 0.0874, G loss: 8.6433\n",
      "[5772/8000] D loss: 0.1354, G loss: 13.0433\n",
      "[6132/8000] D loss: 0.3883, G loss: 6.7031\n",
      "[6492/8000] D loss: 0.7013, G loss: 12.3757\n",
      "[6852/8000] D loss: 0.1147, G loss: 8.6480\n",
      "[7212/8000] D loss: 0.1999, G loss: 8.8249\n",
      "[7572/8000] D loss: 0.0690, G loss: 6.0130\n",
      "[7932/8000] D loss: 0.2107, G loss: 10.3600\n",
      "train error: \n",
      " D loss: 0.202397, G loss: 9.053913, D accuracy: 94.9%, cell accuracy: 94.1%, board accuracy: 7.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.407504, G loss: 11.401776, D accuracy: 94.2%, cell accuracy: 93.8%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0603, G loss: 8.5523\n",
      "[372/8000] D loss: 0.3260, G loss: 6.3019\n",
      "[732/8000] D loss: 0.2116, G loss: 11.2053\n",
      "[1092/8000] D loss: 0.0135, G loss: 13.2607\n",
      "[1452/8000] D loss: 0.2252, G loss: 9.8585\n",
      "[1812/8000] D loss: 0.1460, G loss: 9.6028\n",
      "[2172/8000] D loss: 0.1663, G loss: 10.1328\n",
      "[2532/8000] D loss: 0.0054, G loss: 11.2602\n",
      "[2892/8000] D loss: 0.0338, G loss: 10.4308\n",
      "[3252/8000] D loss: 0.1471, G loss: 8.3511\n",
      "[3612/8000] D loss: 0.5696, G loss: 8.2404\n",
      "[3972/8000] D loss: 0.0866, G loss: 6.0206\n",
      "[4332/8000] D loss: 0.1613, G loss: 9.7285\n",
      "[4692/8000] D loss: 0.1158, G loss: 7.8192\n",
      "[5052/8000] D loss: 0.4780, G loss: 6.6953\n",
      "[5412/8000] D loss: 0.1446, G loss: 8.9926\n",
      "[5772/8000] D loss: 0.3364, G loss: 6.5757\n",
      "[6132/8000] D loss: 0.3073, G loss: 8.5309\n",
      "[6492/8000] D loss: 0.6054, G loss: 5.1048\n",
      "[6852/8000] D loss: 0.0023, G loss: 11.9753\n",
      "[7212/8000] D loss: 0.1152, G loss: 8.2835\n",
      "[7572/8000] D loss: 0.0096, G loss: 11.2436\n",
      "[7932/8000] D loss: 0.2460, G loss: 8.1921\n",
      "train error: \n",
      " D loss: 0.226786, G loss: 7.688335, D accuracy: 94.7%, cell accuracy: 94.0%, board accuracy: 6.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.334773, G loss: 9.992322, D accuracy: 94.7%, cell accuracy: 93.6%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0423, G loss: 10.5518\n",
      "[372/8000] D loss: 0.1314, G loss: 8.9124\n",
      "[732/8000] D loss: 0.1747, G loss: 10.4020\n",
      "[1092/8000] D loss: 0.2380, G loss: 8.0279\n",
      "[1452/8000] D loss: 0.2087, G loss: 6.2607\n",
      "[1812/8000] D loss: 0.1466, G loss: 8.8996\n",
      "[2172/8000] D loss: 0.3013, G loss: 10.1494\n",
      "[2532/8000] D loss: 0.2998, G loss: 8.4581\n",
      "[2892/8000] D loss: 0.0137, G loss: 12.8940\n",
      "[3252/8000] D loss: 0.0186, G loss: 8.6901\n",
      "[3612/8000] D loss: 0.6025, G loss: 5.5611\n",
      "[3972/8000] D loss: 0.2699, G loss: 8.9994\n",
      "[4332/8000] D loss: 0.3039, G loss: 10.0568\n",
      "[4692/8000] D loss: 0.1115, G loss: 9.3632\n",
      "[5052/8000] D loss: 0.6140, G loss: 7.6731\n",
      "[5412/8000] D loss: 0.5256, G loss: 7.9976\n",
      "[5772/8000] D loss: 0.1968, G loss: 6.8313\n",
      "[6132/8000] D loss: 0.4428, G loss: 5.4697\n",
      "[6492/8000] D loss: 0.4638, G loss: 9.0280\n",
      "[6852/8000] D loss: 0.0211, G loss: 8.9005\n",
      "[7212/8000] D loss: 0.4116, G loss: 10.1265\n",
      "[7572/8000] D loss: 0.5195, G loss: 7.7467\n",
      "[7932/8000] D loss: 0.1405, G loss: 10.3359\n",
      "train error: \n",
      " D loss: 0.209150, G loss: 8.906115, D accuracy: 94.8%, cell accuracy: 94.0%, board accuracy: 7.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.354048, G loss: 11.284554, D accuracy: 95.1%, cell accuracy: 93.7%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0094, G loss: 9.9370\n",
      "[372/8000] D loss: 0.1691, G loss: 7.7132\n",
      "[732/8000] D loss: 0.1972, G loss: 10.2267\n",
      "[1092/8000] D loss: 0.0249, G loss: 11.2971\n",
      "[1452/8000] D loss: 0.3244, G loss: 9.1641\n",
      "[1812/8000] D loss: 0.2198, G loss: 8.1121\n",
      "[2172/8000] D loss: 0.0667, G loss: 10.1587\n",
      "[2532/8000] D loss: 0.1677, G loss: 9.1170\n",
      "[2892/8000] D loss: 0.0580, G loss: 7.6925\n",
      "[3252/8000] D loss: 0.3444, G loss: 9.6545\n",
      "[3612/8000] D loss: 0.1988, G loss: 10.5189\n",
      "[3972/8000] D loss: 0.2488, G loss: 8.3869\n",
      "[4332/8000] D loss: 0.1632, G loss: 11.6219\n",
      "[4692/8000] D loss: 0.2028, G loss: 7.8458\n",
      "[5052/8000] D loss: 0.0265, G loss: 10.3849\n",
      "[5412/8000] D loss: 0.2611, G loss: 10.1133\n",
      "[5772/8000] D loss: 0.2052, G loss: 6.4409\n",
      "[6132/8000] D loss: 0.1467, G loss: 8.2376\n",
      "[6492/8000] D loss: 0.0198, G loss: 10.6463\n",
      "[6852/8000] D loss: 0.1040, G loss: 12.5214\n",
      "[7212/8000] D loss: 0.0239, G loss: 9.6816\n",
      "[7572/8000] D loss: 0.1864, G loss: 8.1288\n",
      "[7932/8000] D loss: 0.1888, G loss: 9.5833\n",
      "train error: \n",
      " D loss: 0.229200, G loss: 10.345934, D accuracy: 94.3%, cell accuracy: 94.1%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.512902, G loss: 12.783080, D accuracy: 92.8%, cell accuracy: 93.7%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1415, G loss: 12.6186\n",
      "[372/8000] D loss: 0.2699, G loss: 6.3044\n",
      "[732/8000] D loss: 0.4277, G loss: 6.5007\n",
      "[1092/8000] D loss: 0.0244, G loss: 10.6879\n",
      "[1452/8000] D loss: 0.2142, G loss: 9.1356\n",
      "[1812/8000] D loss: 0.3464, G loss: 9.0158\n",
      "[2172/8000] D loss: 0.3510, G loss: 7.8727\n",
      "[2532/8000] D loss: 0.0835, G loss: 11.2237\n",
      "[2892/8000] D loss: 0.1883, G loss: 5.8663\n",
      "[3252/8000] D loss: 0.2565, G loss: 8.0976\n",
      "[3612/8000] D loss: 0.2595, G loss: 10.3853\n",
      "[3972/8000] D loss: 0.0359, G loss: 8.4311\n",
      "[4332/8000] D loss: 0.1723, G loss: 9.4799\n",
      "[4692/8000] D loss: 0.0810, G loss: 11.4767\n",
      "[5052/8000] D loss: 0.2121, G loss: 6.0273\n",
      "[5412/8000] D loss: 0.3292, G loss: 9.1796\n",
      "[5772/8000] D loss: 0.2099, G loss: 10.1342\n",
      "[6132/8000] D loss: 0.1599, G loss: 8.9393\n",
      "[6492/8000] D loss: 0.0123, G loss: 9.2602\n",
      "[6852/8000] D loss: 0.0224, G loss: 7.9719\n",
      "[7212/8000] D loss: 0.1845, G loss: 10.4694\n",
      "[7572/8000] D loss: 0.3393, G loss: 8.6560\n",
      "[7932/8000] D loss: 0.0294, G loss: 10.9346\n",
      "train error: \n",
      " D loss: 0.207372, G loss: 9.078977, D accuracy: 94.8%, cell accuracy: 94.1%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.411012, G loss: 11.380297, D accuracy: 93.5%, cell accuracy: 93.7%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0605, G loss: 9.2201\n",
      "[372/8000] D loss: 0.2736, G loss: 5.8208\n",
      "[732/8000] D loss: 0.1979, G loss: 8.2681\n",
      "[1092/8000] D loss: 0.3929, G loss: 8.1909\n",
      "[1452/8000] D loss: 0.4030, G loss: 10.5068\n",
      "[1812/8000] D loss: 0.3152, G loss: 10.5205\n",
      "[2172/8000] D loss: 0.0117, G loss: 9.1764\n",
      "[2532/8000] D loss: 0.3211, G loss: 8.9029\n",
      "[2892/8000] D loss: 0.1850, G loss: 8.6912\n",
      "[3252/8000] D loss: 0.2085, G loss: 6.2357\n",
      "[3612/8000] D loss: 0.1201, G loss: 8.3228\n",
      "[3972/8000] D loss: 0.0082, G loss: 9.4197\n",
      "[4332/8000] D loss: 0.0290, G loss: 11.7087\n",
      "[4692/8000] D loss: 0.2649, G loss: 7.0918\n",
      "[5052/8000] D loss: 0.1183, G loss: 10.3471\n",
      "[5412/8000] D loss: 0.2083, G loss: 7.2490\n",
      "[5772/8000] D loss: 0.4011, G loss: 6.6346\n",
      "[6132/8000] D loss: 0.4104, G loss: 8.5857\n",
      "[6492/8000] D loss: 0.1411, G loss: 9.6936\n",
      "[6852/8000] D loss: 0.4761, G loss: 6.3937\n",
      "[7212/8000] D loss: 0.0381, G loss: 9.8014\n",
      "[7572/8000] D loss: 0.3962, G loss: 7.8206\n",
      "[7932/8000] D loss: 0.2482, G loss: 8.8933\n",
      "train error: \n",
      " D loss: 0.216294, G loss: 8.436823, D accuracy: 95.0%, cell accuracy: 94.1%, board accuracy: 6.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.339770, G loss: 10.874291, D accuracy: 95.2%, cell accuracy: 93.7%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1214, G loss: 10.3529\n",
      "[372/8000] D loss: 0.0501, G loss: 7.7402\n",
      "[732/8000] D loss: 0.2762, G loss: 9.5266\n",
      "[1092/8000] D loss: 0.5810, G loss: 7.2418\n",
      "[1452/8000] D loss: 0.3185, G loss: 7.9891\n",
      "[1812/8000] D loss: 0.1158, G loss: 8.9023\n",
      "[2172/8000] D loss: 0.1222, G loss: 9.7341\n",
      "[2532/8000] D loss: 0.0488, G loss: 10.9340\n",
      "[2892/8000] D loss: 0.2686, G loss: 8.1429\n",
      "[3252/8000] D loss: 0.1442, G loss: 9.2413\n",
      "[3612/8000] D loss: 0.0397, G loss: 9.8054\n",
      "[3972/8000] D loss: 0.1886, G loss: 9.5640\n",
      "[4332/8000] D loss: 0.3926, G loss: 7.4790\n",
      "[4692/8000] D loss: 0.1457, G loss: 9.8292\n",
      "[5052/8000] D loss: 0.2735, G loss: 11.5170\n",
      "[5412/8000] D loss: 0.1723, G loss: 9.6197\n",
      "[5772/8000] D loss: 0.1456, G loss: 10.0589\n",
      "[6132/8000] D loss: 0.4664, G loss: 8.5442\n",
      "[6492/8000] D loss: 0.1737, G loss: 7.4992\n",
      "[6852/8000] D loss: 0.2105, G loss: 9.9022\n",
      "[7212/8000] D loss: 0.2656, G loss: 9.5929\n",
      "[7572/8000] D loss: 0.3142, G loss: 7.4822\n",
      "[7932/8000] D loss: 0.2119, G loss: 9.7281\n",
      "train error: \n",
      " D loss: 0.218813, G loss: 8.832112, D accuracy: 94.6%, cell accuracy: 94.1%, board accuracy: 7.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.385005, G loss: 11.247810, D accuracy: 94.6%, cell accuracy: 93.7%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0194, G loss: 10.8485\n",
      "[372/8000] D loss: 0.2433, G loss: 11.5887\n",
      "[732/8000] D loss: 0.2587, G loss: 8.0316\n",
      "[1092/8000] D loss: 0.0663, G loss: 9.7660\n",
      "[1452/8000] D loss: 0.1388, G loss: 7.0463\n",
      "[1812/8000] D loss: 0.2585, G loss: 8.7826\n",
      "[2172/8000] D loss: 0.1389, G loss: 9.4492\n",
      "[2532/8000] D loss: 0.2038, G loss: 12.0987\n",
      "[2892/8000] D loss: 0.1968, G loss: 9.8613\n",
      "[3252/8000] D loss: 0.2837, G loss: 9.9867\n",
      "[3612/8000] D loss: 0.0433, G loss: 9.8562\n",
      "[3972/8000] D loss: 0.0894, G loss: 8.9811\n",
      "[4332/8000] D loss: 0.0926, G loss: 9.1032\n",
      "[4692/8000] D loss: 0.0282, G loss: 11.6237\n",
      "[5052/8000] D loss: 0.1595, G loss: 11.5425\n",
      "[5412/8000] D loss: 0.0063, G loss: 11.6951\n",
      "[5772/8000] D loss: 0.2035, G loss: 9.6305\n",
      "[6132/8000] D loss: 0.3548, G loss: 8.6876\n",
      "[6492/8000] D loss: 0.1541, G loss: 9.2423\n",
      "[6852/8000] D loss: 0.0062, G loss: 11.3023\n",
      "[7212/8000] D loss: 0.1408, G loss: 10.4237\n",
      "[7572/8000] D loss: 0.2911, G loss: 8.6408\n",
      "[7932/8000] D loss: 0.1659, G loss: 10.4388\n",
      "train error: \n",
      " D loss: 0.246136, G loss: 9.361337, D accuracy: 94.1%, cell accuracy: 94.1%, board accuracy: 7.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.447148, G loss: 11.637829, D accuracy: 93.2%, cell accuracy: 93.7%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2550, G loss: 9.3176\n",
      "[372/8000] D loss: 0.0622, G loss: 10.1859\n",
      "[732/8000] D loss: 0.1315, G loss: 7.8830\n",
      "[1092/8000] D loss: 0.2926, G loss: 10.3299\n",
      "[1452/8000] D loss: 0.5301, G loss: 7.3910\n",
      "[1812/8000] D loss: 0.1494, G loss: 10.2667\n",
      "[2172/8000] D loss: 0.1259, G loss: 10.4793\n",
      "[2532/8000] D loss: 0.2813, G loss: 4.6062\n",
      "[2892/8000] D loss: 0.2746, G loss: 11.7953\n",
      "[3252/8000] D loss: 0.0051, G loss: 9.7098\n",
      "[3612/8000] D loss: 0.0019, G loss: 14.4289\n",
      "[3972/8000] D loss: 0.2315, G loss: 8.3871\n",
      "[4332/8000] D loss: 0.2553, G loss: 10.1508\n",
      "[4692/8000] D loss: 0.1842, G loss: 11.0691\n",
      "[5052/8000] D loss: 0.1295, G loss: 11.8471\n",
      "[5412/8000] D loss: 0.2153, G loss: 10.2448\n",
      "[5772/8000] D loss: 0.4185, G loss: 6.4975\n",
      "[6132/8000] D loss: 0.0355, G loss: 11.8747\n",
      "[6492/8000] D loss: 0.2464, G loss: 8.9788\n",
      "[6852/8000] D loss: 0.1161, G loss: 12.4612\n",
      "[7212/8000] D loss: 0.5106, G loss: 7.2831\n",
      "[7572/8000] D loss: 0.2479, G loss: 8.7177\n",
      "[7932/8000] D loss: 0.0420, G loss: 10.3099\n",
      "train error: \n",
      " D loss: 0.198039, G loss: 8.500119, D accuracy: 94.9%, cell accuracy: 94.1%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.373051, G loss: 10.959800, D accuracy: 94.7%, cell accuracy: 93.7%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0885, G loss: 10.5071\n",
      "[372/8000] D loss: 0.0375, G loss: 12.2841\n",
      "[732/8000] D loss: 0.1706, G loss: 5.6238\n",
      "[1092/8000] D loss: 0.2048, G loss: 9.0792\n",
      "[1452/8000] D loss: 0.1593, G loss: 9.2125\n",
      "[1812/8000] D loss: 0.1335, G loss: 9.6830\n",
      "[2172/8000] D loss: 0.0212, G loss: 12.6227\n",
      "[2532/8000] D loss: 0.4987, G loss: 11.1635\n",
      "[2892/8000] D loss: 0.0393, G loss: 13.6836\n",
      "[3252/8000] D loss: 0.2064, G loss: 7.5068\n",
      "[3612/8000] D loss: 0.0065, G loss: 13.1778\n",
      "[3972/8000] D loss: 0.3617, G loss: 7.7288\n",
      "[4332/8000] D loss: 0.2562, G loss: 7.5411\n",
      "[4692/8000] D loss: 0.1933, G loss: 9.5036\n",
      "[5052/8000] D loss: 0.1582, G loss: 7.7853\n",
      "[5412/8000] D loss: 0.2358, G loss: 12.5911\n",
      "[5772/8000] D loss: 0.3143, G loss: 8.1442\n",
      "[6132/8000] D loss: 0.1523, G loss: 12.5011\n",
      "[6492/8000] D loss: 0.3145, G loss: 8.8786\n",
      "[6852/8000] D loss: 0.1334, G loss: 13.2472\n",
      "[7212/8000] D loss: 0.2059, G loss: 8.1860\n",
      "[7572/8000] D loss: 0.0461, G loss: 9.7518\n",
      "[7932/8000] D loss: 0.0188, G loss: 11.8761\n",
      "train error: \n",
      " D loss: 0.196301, G loss: 9.220386, D accuracy: 95.0%, cell accuracy: 94.0%, board accuracy: 7.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.377941, G loss: 11.757304, D accuracy: 95.1%, cell accuracy: 93.7%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3291, G loss: 5.8740\n",
      "[372/8000] D loss: 0.2374, G loss: 6.0724\n",
      "[732/8000] D loss: 0.1004, G loss: 9.1129\n",
      "[1092/8000] D loss: 0.1871, G loss: 11.4179\n",
      "[1452/8000] D loss: 0.1537, G loss: 11.4113\n",
      "[1812/8000] D loss: 0.1283, G loss: 12.6041\n",
      "[2172/8000] D loss: 0.0943, G loss: 6.5893\n",
      "[2532/8000] D loss: 0.4579, G loss: 9.0748\n",
      "[2892/8000] D loss: 0.1993, G loss: 9.6777\n",
      "[3252/8000] D loss: 0.0578, G loss: 11.1729\n",
      "[3612/8000] D loss: 0.0842, G loss: 10.6067\n",
      "[3972/8000] D loss: 0.1795, G loss: 10.5784\n",
      "[4332/8000] D loss: 0.1642, G loss: 8.5783\n",
      "[4692/8000] D loss: 0.2320, G loss: 9.3565\n",
      "[5052/8000] D loss: 0.2093, G loss: 11.4380\n",
      "[5412/8000] D loss: 0.2079, G loss: 9.4812\n",
      "[5772/8000] D loss: 0.2140, G loss: 11.7534\n",
      "[6132/8000] D loss: 0.1913, G loss: 8.0316\n",
      "[6492/8000] D loss: 0.1219, G loss: 10.1002\n",
      "[6852/8000] D loss: 0.2936, G loss: 11.1255\n",
      "[7212/8000] D loss: 0.2230, G loss: 9.8144\n",
      "[7572/8000] D loss: 0.1069, G loss: 8.3081\n",
      "[7932/8000] D loss: 0.1138, G loss: 9.5631\n",
      "train error: \n",
      " D loss: 0.217316, G loss: 8.404194, D accuracy: 94.7%, cell accuracy: 94.1%, board accuracy: 7.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.361802, G loss: 10.906833, D accuracy: 94.6%, cell accuracy: 93.7%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0261, G loss: 8.3262\n",
      "[372/8000] D loss: 0.4306, G loss: 8.7230\n",
      "[732/8000] D loss: 0.0146, G loss: 9.3796\n",
      "[1092/8000] D loss: 0.3254, G loss: 8.4402\n",
      "[1452/8000] D loss: 0.1100, G loss: 9.0416\n",
      "[1812/8000] D loss: 0.1928, G loss: 13.0483\n",
      "[2172/8000] D loss: 0.5454, G loss: 8.6441\n",
      "[2532/8000] D loss: 0.1817, G loss: 8.2440\n",
      "[2892/8000] D loss: 0.0928, G loss: 7.9532\n",
      "[3252/8000] D loss: 0.2067, G loss: 10.1118\n",
      "[3612/8000] D loss: 0.1346, G loss: 11.6327\n",
      "[3972/8000] D loss: 0.1294, G loss: 11.9860\n",
      "[4332/8000] D loss: 0.4019, G loss: 9.2604\n",
      "[4692/8000] D loss: 0.4009, G loss: 5.7528\n",
      "[5052/8000] D loss: 0.0053, G loss: 9.5731\n",
      "[5412/8000] D loss: 0.3960, G loss: 7.6707\n",
      "[5772/8000] D loss: 0.0149, G loss: 7.8694\n",
      "[6132/8000] D loss: 0.2680, G loss: 7.6117\n",
      "[6492/8000] D loss: 0.1879, G loss: 10.5515\n",
      "[6852/8000] D loss: 0.0204, G loss: 11.4698\n",
      "[7212/8000] D loss: 0.4071, G loss: 6.8964\n",
      "[7572/8000] D loss: 0.1836, G loss: 11.7461\n",
      "[7932/8000] D loss: 0.1450, G loss: 6.8283\n",
      "train error: \n",
      " D loss: 0.214352, G loss: 9.450939, D accuracy: 94.5%, cell accuracy: 94.1%, board accuracy: 7.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.462873, G loss: 11.947686, D accuracy: 92.9%, cell accuracy: 93.7%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1268, G loss: 8.5079\n",
      "[372/8000] D loss: 0.1762, G loss: 10.4385\n",
      "[732/8000] D loss: 0.4958, G loss: 7.7365\n",
      "[1092/8000] D loss: 0.5213, G loss: 7.6234\n",
      "[1452/8000] D loss: 0.1250, G loss: 9.9417\n",
      "[1812/8000] D loss: 0.3848, G loss: 6.3042\n",
      "[2172/8000] D loss: 0.0252, G loss: 7.3216\n",
      "[2532/8000] D loss: 0.0475, G loss: 8.6824\n",
      "[2892/8000] D loss: 0.2609, G loss: 8.1093\n",
      "[3252/8000] D loss: 0.3201, G loss: 8.1767\n",
      "[3612/8000] D loss: 0.4371, G loss: 5.1574\n",
      "[3972/8000] D loss: 0.2703, G loss: 11.0676\n",
      "[4332/8000] D loss: 0.0474, G loss: 10.4536\n",
      "[4692/8000] D loss: 0.0155, G loss: 13.2273\n",
      "[5052/8000] D loss: 0.0610, G loss: 8.6357\n",
      "[5412/8000] D loss: 0.2682, G loss: 10.3144\n",
      "[5772/8000] D loss: 0.1221, G loss: 8.6794\n",
      "[6132/8000] D loss: 0.1242, G loss: 11.6644\n",
      "[6492/8000] D loss: 0.0953, G loss: 12.7517\n",
      "[6852/8000] D loss: 0.1537, G loss: 7.8736\n",
      "[7212/8000] D loss: 0.4748, G loss: 5.0700\n",
      "[7572/8000] D loss: 0.7041, G loss: 5.3381\n",
      "[7932/8000] D loss: 0.3546, G loss: 7.4906\n",
      "train error: \n",
      " D loss: 0.200930, G loss: 9.436506, D accuracy: 94.9%, cell accuracy: 94.1%, board accuracy: 7.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.408770, G loss: 12.017275, D accuracy: 94.3%, cell accuracy: 93.7%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4385, G loss: 8.7503\n",
      "[372/8000] D loss: 0.1162, G loss: 7.8907\n",
      "[732/8000] D loss: 0.0149, G loss: 11.8767\n",
      "[1092/8000] D loss: 0.1839, G loss: 9.7468\n",
      "[1452/8000] D loss: 0.4183, G loss: 6.1206\n",
      "[1812/8000] D loss: 0.3376, G loss: 8.7843\n",
      "[2172/8000] D loss: 0.0108, G loss: 10.5354\n",
      "[2532/8000] D loss: 0.1024, G loss: 6.2303\n",
      "[2892/8000] D loss: 0.3957, G loss: 8.1360\n",
      "[3252/8000] D loss: 0.0297, G loss: 10.2374\n",
      "[3612/8000] D loss: 0.5105, G loss: 7.5055\n",
      "[3972/8000] D loss: 0.1680, G loss: 9.2485\n",
      "[4332/8000] D loss: 0.0773, G loss: 9.7271\n",
      "[4692/8000] D loss: 0.2356, G loss: 10.2278\n",
      "[5052/8000] D loss: 0.1279, G loss: 13.2037\n",
      "[5412/8000] D loss: 0.1496, G loss: 9.7768\n",
      "[5772/8000] D loss: 0.3033, G loss: 9.0323\n",
      "[6132/8000] D loss: 0.1660, G loss: 9.8876\n",
      "[6492/8000] D loss: 0.2960, G loss: 8.5160\n",
      "[6852/8000] D loss: 0.1393, G loss: 8.9771\n",
      "[7212/8000] D loss: 0.2568, G loss: 10.0187\n",
      "[7572/8000] D loss: 0.0038, G loss: 10.4147\n",
      "[7932/8000] D loss: 0.1042, G loss: 10.5824\n",
      "train error: \n",
      " D loss: 0.203156, G loss: 8.905241, D accuracy: 94.7%, cell accuracy: 94.1%, board accuracy: 7.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.387991, G loss: 11.536389, D accuracy: 94.3%, cell accuracy: 93.8%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2219, G loss: 8.2503\n",
      "[372/8000] D loss: 0.1716, G loss: 9.4309\n",
      "[732/8000] D loss: 0.4764, G loss: 7.2311\n",
      "[1092/8000] D loss: 0.1201, G loss: 10.7395\n",
      "[1452/8000] D loss: 0.3646, G loss: 7.4426\n",
      "[1812/8000] D loss: 0.1247, G loss: 9.2975\n",
      "[2172/8000] D loss: 0.3389, G loss: 9.8992\n",
      "[2532/8000] D loss: 0.4314, G loss: 9.3187\n",
      "[2892/8000] D loss: 0.1018, G loss: 8.2317\n",
      "[3252/8000] D loss: 0.1619, G loss: 8.4996\n",
      "[3612/8000] D loss: 0.2507, G loss: 9.7782\n",
      "[3972/8000] D loss: 0.0099, G loss: 9.6127\n",
      "[4332/8000] D loss: 0.2122, G loss: 7.3715\n",
      "[4692/8000] D loss: 0.1391, G loss: 10.4328\n",
      "[5052/8000] D loss: 0.1257, G loss: 8.0034\n",
      "[5412/8000] D loss: 0.2448, G loss: 8.8443\n",
      "[5772/8000] D loss: 0.2419, G loss: 10.5729\n",
      "[6132/8000] D loss: 0.2130, G loss: 9.4728\n",
      "[6492/8000] D loss: 0.1510, G loss: 12.3491\n",
      "[6852/8000] D loss: 0.3719, G loss: 7.9945\n",
      "[7212/8000] D loss: 0.1688, G loss: 9.5947\n",
      "[7572/8000] D loss: 0.3451, G loss: 10.2668\n",
      "[7932/8000] D loss: 0.1678, G loss: 11.7538\n",
      "train error: \n",
      " D loss: 0.198433, G loss: 9.254017, D accuracy: 95.0%, cell accuracy: 94.1%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.395336, G loss: 11.984802, D accuracy: 94.4%, cell accuracy: 93.7%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0404, G loss: 10.5251\n",
      "[372/8000] D loss: 0.0350, G loss: 11.4086\n",
      "[732/8000] D loss: 0.1722, G loss: 8.9700\n",
      "[1092/8000] D loss: 0.2095, G loss: 10.7843\n",
      "[1452/8000] D loss: 0.0111, G loss: 10.0860\n",
      "[1812/8000] D loss: 0.1346, G loss: 10.1086\n",
      "[2172/8000] D loss: 0.0850, G loss: 11.5132\n",
      "[2532/8000] D loss: 0.5355, G loss: 7.0953\n",
      "[2892/8000] D loss: 0.2318, G loss: 5.3532\n",
      "[3252/8000] D loss: 0.2470, G loss: 9.0474\n",
      "[3612/8000] D loss: 0.4521, G loss: 5.3749\n",
      "[3972/8000] D loss: 0.0305, G loss: 8.5461\n",
      "[4332/8000] D loss: 0.0075, G loss: 12.2650\n",
      "[4692/8000] D loss: 0.3756, G loss: 10.0934\n",
      "[5052/8000] D loss: 0.1686, G loss: 8.8714\n",
      "[5412/8000] D loss: 0.1959, G loss: 13.7598\n",
      "[5772/8000] D loss: 0.1076, G loss: 11.2468\n",
      "[6132/8000] D loss: 0.1183, G loss: 12.3017\n",
      "[6492/8000] D loss: 0.0262, G loss: 10.9747\n",
      "[6852/8000] D loss: 0.1990, G loss: 5.3505\n",
      "[7212/8000] D loss: 0.4106, G loss: 7.0212\n",
      "[7572/8000] D loss: 0.0609, G loss: 11.1686\n",
      "[7932/8000] D loss: 0.3227, G loss: 11.1571\n",
      "train error: \n",
      " D loss: 0.271252, G loss: 7.028681, D accuracy: 93.7%, cell accuracy: 94.1%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.312200, G loss: 9.604423, D accuracy: 95.1%, cell accuracy: 93.8%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1525, G loss: 7.0460\n",
      "[372/8000] D loss: 0.3619, G loss: 8.1219\n",
      "[732/8000] D loss: 0.1321, G loss: 10.5993\n",
      "[1092/8000] D loss: 0.3203, G loss: 8.9254\n",
      "[1452/8000] D loss: 0.0039, G loss: 13.7527\n",
      "[1812/8000] D loss: 0.5370, G loss: 7.2902\n",
      "[2172/8000] D loss: 0.0971, G loss: 10.7328\n",
      "[2532/8000] D loss: 0.3666, G loss: 7.1530\n",
      "[2892/8000] D loss: 0.1670, G loss: 8.4699\n",
      "[3252/8000] D loss: 0.1008, G loss: 10.4882\n",
      "[3612/8000] D loss: 0.0351, G loss: 8.6583\n",
      "[3972/8000] D loss: 0.2157, G loss: 9.4403\n",
      "[4332/8000] D loss: 0.0745, G loss: 9.8865\n",
      "[4692/8000] D loss: 0.0411, G loss: 9.2433\n",
      "[5052/8000] D loss: 0.0429, G loss: 8.0829\n",
      "[5412/8000] D loss: 0.1492, G loss: 9.3878\n",
      "[5772/8000] D loss: 0.2543, G loss: 13.7364\n",
      "[6132/8000] D loss: 0.1191, G loss: 11.1395\n",
      "[6492/8000] D loss: 0.1636, G loss: 8.2678\n",
      "[6852/8000] D loss: 0.0797, G loss: 11.0870\n",
      "[7212/8000] D loss: 0.1924, G loss: 6.4459\n",
      "[7572/8000] D loss: 0.2281, G loss: 10.2989\n",
      "[7932/8000] D loss: 0.1510, G loss: 10.0933\n",
      "train error: \n",
      " D loss: 0.266406, G loss: 11.434127, D accuracy: 93.3%, cell accuracy: 94.1%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.601770, G loss: 14.172451, D accuracy: 92.6%, cell accuracy: 93.8%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5999, G loss: 7.2255\n",
      "[372/8000] D loss: 0.4360, G loss: 9.1779\n",
      "[732/8000] D loss: 0.0027, G loss: 11.9673\n",
      "[1092/8000] D loss: 0.5331, G loss: 8.7864\n",
      "[1452/8000] D loss: 0.4411, G loss: 10.4076\n",
      "[1812/8000] D loss: 0.2137, G loss: 8.7560\n",
      "[2172/8000] D loss: 0.1625, G loss: 9.6298\n",
      "[2532/8000] D loss: 0.3777, G loss: 5.9860\n",
      "[2892/8000] D loss: 0.4034, G loss: 6.2105\n",
      "[3252/8000] D loss: 0.2533, G loss: 8.2869\n",
      "[3612/8000] D loss: 0.4283, G loss: 9.3536\n",
      "[3972/8000] D loss: 0.3951, G loss: 5.4334\n",
      "[4332/8000] D loss: 0.0010, G loss: 14.1152\n",
      "[4692/8000] D loss: 0.2401, G loss: 10.0686\n",
      "[5052/8000] D loss: 0.2317, G loss: 8.6189\n",
      "[5412/8000] D loss: 0.1138, G loss: 9.6339\n",
      "[5772/8000] D loss: 0.0032, G loss: 9.4977\n",
      "[6132/8000] D loss: 0.1219, G loss: 10.0904\n",
      "[6492/8000] D loss: 0.4743, G loss: 8.8564\n",
      "[6852/8000] D loss: 0.0331, G loss: 10.8211\n",
      "[7212/8000] D loss: 0.0847, G loss: 10.6056\n",
      "[7572/8000] D loss: 0.1557, G loss: 6.8575\n",
      "[7932/8000] D loss: 0.5124, G loss: 10.1917\n",
      "train error: \n",
      " D loss: 0.212928, G loss: 10.328040, D accuracy: 94.5%, cell accuracy: 94.1%, board accuracy: 7.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.445747, G loss: 13.114360, D accuracy: 94.5%, cell accuracy: 93.8%, board accuracy: 2.6% \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1445, G loss: 10.1197\n",
      "[372/8000] D loss: 0.1338, G loss: 12.6797\n",
      "[732/8000] D loss: 0.2948, G loss: 10.2077\n",
      "[1092/8000] D loss: 0.2588, G loss: 8.5402\n",
      "[1452/8000] D loss: 0.0330, G loss: 10.5531\n",
      "[1812/8000] D loss: 0.0314, G loss: 11.5299\n",
      "[2172/8000] D loss: 0.2966, G loss: 6.7638\n",
      "[2532/8000] D loss: 0.0498, G loss: 12.1630\n",
      "[2892/8000] D loss: 0.1524, G loss: 5.9668\n",
      "[3252/8000] D loss: 0.3455, G loss: 7.8654\n",
      "[3612/8000] D loss: 0.1200, G loss: 10.7895\n",
      "[3972/8000] D loss: 0.0089, G loss: 10.5676\n",
      "[4332/8000] D loss: 0.4769, G loss: 7.8454\n",
      "[4692/8000] D loss: 0.0361, G loss: 8.2847\n",
      "[5052/8000] D loss: 0.3053, G loss: 8.1029\n",
      "[5412/8000] D loss: 0.3164, G loss: 10.8962\n",
      "[5772/8000] D loss: 0.5336, G loss: 4.4477\n",
      "[6132/8000] D loss: 0.5395, G loss: 7.6625\n",
      "[6492/8000] D loss: 0.2554, G loss: 8.1280\n",
      "[6852/8000] D loss: 0.2886, G loss: 10.5317\n",
      "[7212/8000] D loss: 0.0655, G loss: 7.4097\n",
      "[7572/8000] D loss: 0.0487, G loss: 7.9217\n",
      "[7932/8000] D loss: 0.2683, G loss: 10.2383\n",
      "train error: \n",
      " D loss: 0.194556, G loss: 10.042398, D accuracy: 95.0%, cell accuracy: 94.1%, board accuracy: 7.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.471529, G loss: 12.761193, D accuracy: 93.6%, cell accuracy: 93.8%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2531, G loss: 7.4208\n",
      "[372/8000] D loss: 0.1961, G loss: 9.1933\n",
      "[732/8000] D loss: 0.2191, G loss: 7.3370\n",
      "[1092/8000] D loss: 0.3389, G loss: 9.0164\n",
      "[1452/8000] D loss: 0.0366, G loss: 14.1861\n",
      "[1812/8000] D loss: 0.2336, G loss: 8.6229\n",
      "[2172/8000] D loss: 0.3292, G loss: 8.6266\n",
      "[2532/8000] D loss: 0.1297, G loss: 11.9883\n",
      "[2892/8000] D loss: 0.0073, G loss: 11.3906\n",
      "[3252/8000] D loss: 0.2229, G loss: 9.6263\n",
      "[3612/8000] D loss: 0.4563, G loss: 8.2010\n",
      "[3972/8000] D loss: 0.1896, G loss: 10.7550\n",
      "[4332/8000] D loss: 0.2082, G loss: 9.7632\n",
      "[4692/8000] D loss: 0.2731, G loss: 8.5143\n",
      "[5052/8000] D loss: 0.1679, G loss: 8.1140\n",
      "[5412/8000] D loss: 0.5344, G loss: 8.0698\n",
      "[5772/8000] D loss: 0.2124, G loss: 11.8473\n",
      "[6132/8000] D loss: 0.2691, G loss: 9.0591\n",
      "[6492/8000] D loss: 0.1401, G loss: 10.0836\n",
      "[6852/8000] D loss: 0.4796, G loss: 5.8173\n",
      "[7212/8000] D loss: 0.1189, G loss: 10.4932\n",
      "[7572/8000] D loss: 0.4200, G loss: 6.1761\n",
      "[7932/8000] D loss: 0.1654, G loss: 10.0480\n",
      "train error: \n",
      " D loss: 0.215094, G loss: 8.860528, D accuracy: 94.7%, cell accuracy: 94.1%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.398608, G loss: 11.427286, D accuracy: 94.0%, cell accuracy: 93.8%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1003, G loss: 9.8873\n",
      "[372/8000] D loss: 0.3264, G loss: 12.4524\n",
      "[732/8000] D loss: 0.3157, G loss: 8.1393\n",
      "[1092/8000] D loss: 0.0203, G loss: 10.0853\n",
      "[1452/8000] D loss: 0.2777, G loss: 11.4652\n",
      "[1812/8000] D loss: 0.4409, G loss: 11.5104\n",
      "[2172/8000] D loss: 0.0986, G loss: 9.6771\n",
      "[2532/8000] D loss: 0.1322, G loss: 7.2642\n",
      "[2892/8000] D loss: 0.2469, G loss: 9.2398\n",
      "[3252/8000] D loss: 0.3445, G loss: 11.2097\n",
      "[3612/8000] D loss: 0.1586, G loss: 8.4064\n",
      "[3972/8000] D loss: 0.0757, G loss: 10.5205\n",
      "[4332/8000] D loss: 0.0309, G loss: 10.1456\n",
      "[4692/8000] D loss: 0.4918, G loss: 10.7815\n",
      "[5052/8000] D loss: 0.1509, G loss: 7.3934\n",
      "[5412/8000] D loss: 0.0103, G loss: 12.1784\n",
      "[5772/8000] D loss: 0.1731, G loss: 9.0094\n",
      "[6132/8000] D loss: 0.1818, G loss: 8.4098\n",
      "[6492/8000] D loss: 0.3849, G loss: 9.1606\n",
      "[6852/8000] D loss: 0.0679, G loss: 11.1796\n",
      "[7212/8000] D loss: 0.1553, G loss: 10.1632\n",
      "[7572/8000] D loss: 0.1433, G loss: 9.3633\n",
      "[7932/8000] D loss: 0.3028, G loss: 9.9067\n",
      "train error: \n",
      " D loss: 0.217364, G loss: 8.947086, D accuracy: 94.7%, cell accuracy: 94.1%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.421796, G loss: 11.752519, D accuracy: 94.8%, cell accuracy: 93.7%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2025, G loss: 4.3363\n",
      "[372/8000] D loss: 0.1819, G loss: 7.9761\n",
      "[732/8000] D loss: 0.2109, G loss: 8.4318\n",
      "[1092/8000] D loss: 0.0125, G loss: 12.0476\n",
      "[1452/8000] D loss: 0.1970, G loss: 7.8295\n",
      "[1812/8000] D loss: 0.0213, G loss: 12.5471\n",
      "[2172/8000] D loss: 0.0141, G loss: 9.9650\n",
      "[2532/8000] D loss: 0.1736, G loss: 9.5485\n",
      "[2892/8000] D loss: 0.2045, G loss: 9.5470\n",
      "[3252/8000] D loss: 0.1789, G loss: 7.1640\n",
      "[3612/8000] D loss: 0.3656, G loss: 10.5435\n",
      "[3972/8000] D loss: 0.2085, G loss: 9.0227\n",
      "[4332/8000] D loss: 0.2271, G loss: 10.2745\n",
      "[4692/8000] D loss: 0.0730, G loss: 8.8803\n",
      "[5052/8000] D loss: 0.2447, G loss: 10.1746\n",
      "[5412/8000] D loss: 0.0320, G loss: 12.2174\n",
      "[5772/8000] D loss: 0.1667, G loss: 10.0504\n",
      "[6132/8000] D loss: 0.1100, G loss: 9.2658\n",
      "[6492/8000] D loss: 0.2693, G loss: 11.0784\n",
      "[6852/8000] D loss: 0.0427, G loss: 10.4182\n",
      "[7212/8000] D loss: 0.4695, G loss: 7.6222\n",
      "[7572/8000] D loss: 0.1640, G loss: 10.7777\n",
      "[7932/8000] D loss: 0.4606, G loss: 6.7595\n",
      "train error: \n",
      " D loss: 0.185631, G loss: 9.419664, D accuracy: 95.2%, cell accuracy: 94.1%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.436645, G loss: 12.079010, D accuracy: 93.9%, cell accuracy: 93.8%, board accuracy: 3.3% \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1650, G loss: 9.2483\n",
      "[372/8000] D loss: 0.1275, G loss: 13.6090\n",
      "[732/8000] D loss: 0.1326, G loss: 8.4721\n",
      "[1092/8000] D loss: 0.2523, G loss: 9.3917\n",
      "[1452/8000] D loss: 0.1491, G loss: 11.7364\n",
      "[1812/8000] D loss: 0.2906, G loss: 7.7439\n",
      "[2172/8000] D loss: 0.1302, G loss: 11.3391\n",
      "[2532/8000] D loss: 0.0821, G loss: 13.5349\n",
      "[2892/8000] D loss: 0.1417, G loss: 8.0949\n",
      "[3252/8000] D loss: 0.2443, G loss: 9.4858\n",
      "[3612/8000] D loss: 0.1293, G loss: 10.4352\n",
      "[3972/8000] D loss: 0.2263, G loss: 6.0184\n",
      "[4332/8000] D loss: 0.2418, G loss: 9.3975\n",
      "[4692/8000] D loss: 0.1155, G loss: 11.0869\n",
      "[5052/8000] D loss: 0.2766, G loss: 6.3341\n",
      "[5412/8000] D loss: 0.1664, G loss: 12.9014\n",
      "[5772/8000] D loss: 0.2058, G loss: 7.4783\n",
      "[6132/8000] D loss: 0.4473, G loss: 7.8001\n",
      "[6492/8000] D loss: 0.2385, G loss: 8.7203\n",
      "[6852/8000] D loss: 0.0933, G loss: 12.3645\n",
      "[7212/8000] D loss: 0.1856, G loss: 10.1069\n",
      "[7572/8000] D loss: 0.1381, G loss: 10.6445\n",
      "[7932/8000] D loss: 0.0154, G loss: 15.1666\n",
      "train error: \n",
      " D loss: 0.220849, G loss: 11.164191, D accuracy: 94.5%, cell accuracy: 94.1%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.515186, G loss: 13.944717, D accuracy: 93.2%, cell accuracy: 93.8%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2889, G loss: 12.1667\n",
      "[372/8000] D loss: 0.2617, G loss: 8.6930\n",
      "[732/8000] D loss: 0.0081, G loss: 9.6461\n",
      "[1092/8000] D loss: 0.1604, G loss: 8.1847\n",
      "[1452/8000] D loss: 0.3042, G loss: 7.0844\n",
      "[1812/8000] D loss: 0.1518, G loss: 10.3381\n",
      "[2172/8000] D loss: 0.3031, G loss: 8.1376\n",
      "[2532/8000] D loss: 0.1142, G loss: 10.4421\n",
      "[2892/8000] D loss: 0.2112, G loss: 13.0712\n",
      "[3252/8000] D loss: 0.1590, G loss: 9.5677\n",
      "[3612/8000] D loss: 0.0201, G loss: 9.2863\n",
      "[3972/8000] D loss: 0.2882, G loss: 7.3990\n",
      "[4332/8000] D loss: 0.4378, G loss: 7.2479\n",
      "[4692/8000] D loss: 0.1587, G loss: 8.6180\n",
      "[5052/8000] D loss: 0.0805, G loss: 8.2914\n",
      "[5412/8000] D loss: 0.2265, G loss: 10.9539\n",
      "[5772/8000] D loss: 0.3721, G loss: 8.2216\n",
      "[6132/8000] D loss: 0.1454, G loss: 11.0323\n",
      "[6492/8000] D loss: 0.1898, G loss: 7.9715\n",
      "[6852/8000] D loss: 0.0207, G loss: 7.9051\n",
      "[7212/8000] D loss: 0.0316, G loss: 10.9800\n",
      "[7572/8000] D loss: 0.1704, G loss: 9.6111\n",
      "[7932/8000] D loss: 0.1858, G loss: 13.4060\n",
      "train error: \n",
      " D loss: 0.202291, G loss: 8.794203, D accuracy: 94.9%, cell accuracy: 94.1%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.385948, G loss: 11.570103, D accuracy: 94.9%, cell accuracy: 93.8%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2230, G loss: 8.3039\n",
      "[372/8000] D loss: 0.7098, G loss: 6.2390\n",
      "[732/8000] D loss: 0.1660, G loss: 8.2979\n",
      "[1092/8000] D loss: 0.0222, G loss: 10.8151\n",
      "[1452/8000] D loss: 0.3599, G loss: 10.0068\n",
      "[1812/8000] D loss: 0.1903, G loss: 11.2702\n",
      "[2172/8000] D loss: 0.1523, G loss: 10.7781\n",
      "[2532/8000] D loss: 0.2328, G loss: 10.3505\n",
      "[2892/8000] D loss: 0.1574, G loss: 10.6915\n",
      "[3252/8000] D loss: 0.1860, G loss: 12.1588\n",
      "[3612/8000] D loss: 0.0353, G loss: 10.6675\n",
      "[3972/8000] D loss: 0.2544, G loss: 9.5137\n",
      "[4332/8000] D loss: 0.0268, G loss: 9.5546\n",
      "[4692/8000] D loss: 0.1396, G loss: 7.9956\n",
      "[5052/8000] D loss: 0.0943, G loss: 11.1540\n",
      "[5412/8000] D loss: 0.1244, G loss: 10.7678\n",
      "[5772/8000] D loss: 0.1899, G loss: 12.9320\n",
      "[6132/8000] D loss: 0.0452, G loss: 7.1890\n",
      "[6492/8000] D loss: 0.2101, G loss: 9.7651\n",
      "[6852/8000] D loss: 0.0210, G loss: 9.6049\n",
      "[7212/8000] D loss: 0.2199, G loss: 8.6555\n",
      "[7572/8000] D loss: 0.0630, G loss: 11.9717\n",
      "[7932/8000] D loss: 0.0408, G loss: 10.1259\n",
      "train error: \n",
      " D loss: 0.209591, G loss: 8.662568, D accuracy: 94.8%, cell accuracy: 94.1%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.379196, G loss: 11.417850, D accuracy: 94.9%, cell accuracy: 93.8%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2638, G loss: 10.0232\n",
      "[372/8000] D loss: 0.0575, G loss: 9.8104\n",
      "[732/8000] D loss: 0.1413, G loss: 9.0170\n",
      "[1092/8000] D loss: 0.2775, G loss: 9.6068\n",
      "[1452/8000] D loss: 0.2282, G loss: 10.6142\n",
      "[1812/8000] D loss: 0.1306, G loss: 11.7641\n",
      "[2172/8000] D loss: 0.0693, G loss: 8.8812\n",
      "[2532/8000] D loss: 0.1462, G loss: 12.7494\n",
      "[2892/8000] D loss: 0.2962, G loss: 10.2994\n",
      "[3252/8000] D loss: 0.1371, G loss: 7.9359\n",
      "[3612/8000] D loss: 0.0285, G loss: 9.3142\n",
      "[3972/8000] D loss: 0.2120, G loss: 10.5705\n",
      "[4332/8000] D loss: 0.1902, G loss: 7.8475\n",
      "[4692/8000] D loss: 0.0740, G loss: 7.7848\n",
      "[5052/8000] D loss: 0.1927, G loss: 6.3327\n",
      "[5412/8000] D loss: 0.0175, G loss: 15.3192\n",
      "[5772/8000] D loss: 0.8558, G loss: 7.0999\n",
      "[6132/8000] D loss: 0.0247, G loss: 7.7567\n",
      "[6492/8000] D loss: 0.1678, G loss: 12.5262\n",
      "[6852/8000] D loss: 0.0932, G loss: 9.7176\n",
      "[7212/8000] D loss: 0.0098, G loss: 10.0036\n",
      "[7572/8000] D loss: 0.4289, G loss: 9.0895\n",
      "[7932/8000] D loss: 0.2493, G loss: 10.3327\n",
      "train error: \n",
      " D loss: 0.208578, G loss: 9.001945, D accuracy: 94.7%, cell accuracy: 94.1%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.413653, G loss: 11.816139, D accuracy: 94.4%, cell accuracy: 93.8%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0133, G loss: 10.1473\n",
      "[372/8000] D loss: 0.2866, G loss: 6.9531\n",
      "[732/8000] D loss: 0.2940, G loss: 10.1429\n",
      "[1092/8000] D loss: 0.1775, G loss: 8.4626\n",
      "[1452/8000] D loss: 0.1396, G loss: 8.8302\n",
      "[1812/8000] D loss: 0.4333, G loss: 8.1606\n",
      "[2172/8000] D loss: 0.0413, G loss: 9.7423\n",
      "[2532/8000] D loss: 0.0459, G loss: 10.1346\n",
      "[2892/8000] D loss: 0.0578, G loss: 7.9583\n",
      "[3252/8000] D loss: 0.0238, G loss: 9.4258\n",
      "[3612/8000] D loss: 0.0036, G loss: 11.9563\n",
      "[3972/8000] D loss: 0.1281, G loss: 12.1917\n",
      "[4332/8000] D loss: 0.2760, G loss: 7.6671\n",
      "[4692/8000] D loss: 0.4008, G loss: 8.3743\n",
      "[5052/8000] D loss: 0.2976, G loss: 8.1888\n",
      "[5412/8000] D loss: 0.2670, G loss: 7.0121\n",
      "[5772/8000] D loss: 0.0079, G loss: 12.4545\n",
      "[6132/8000] D loss: 0.3274, G loss: 8.4067\n",
      "[6492/8000] D loss: 0.3001, G loss: 9.7598\n",
      "[6852/8000] D loss: 0.3020, G loss: 8.7838\n",
      "[7212/8000] D loss: 0.2053, G loss: 11.3198\n",
      "[7572/8000] D loss: 0.1405, G loss: 13.5411\n",
      "[7932/8000] D loss: 0.4902, G loss: 7.4462\n",
      "train error: \n",
      " D loss: 0.195614, G loss: 9.634115, D accuracy: 94.8%, cell accuracy: 94.2%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.461198, G loss: 12.388473, D accuracy: 93.8%, cell accuracy: 93.8%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0295, G loss: 13.1814\n",
      "[372/8000] D loss: 0.3952, G loss: 11.5683\n",
      "[732/8000] D loss: 0.2629, G loss: 9.2416\n",
      "[1092/8000] D loss: 0.1020, G loss: 6.5270\n",
      "[1452/8000] D loss: 0.1031, G loss: 9.0692\n",
      "[1812/8000] D loss: 0.0162, G loss: 13.9105\n",
      "[2172/8000] D loss: 0.0732, G loss: 10.6683\n",
      "[2532/8000] D loss: 0.6336, G loss: 6.1685\n",
      "[2892/8000] D loss: 0.2106, G loss: 8.9353\n",
      "[3252/8000] D loss: 0.0497, G loss: 10.4797\n",
      "[3612/8000] D loss: 0.1314, G loss: 9.2394\n",
      "[3972/8000] D loss: 0.0715, G loss: 11.1126\n",
      "[4332/8000] D loss: 0.1674, G loss: 9.7375\n",
      "[4692/8000] D loss: 0.1207, G loss: 9.5106\n",
      "[5052/8000] D loss: 0.1945, G loss: 7.5469\n",
      "[5412/8000] D loss: 0.1324, G loss: 12.6475\n",
      "[5772/8000] D loss: 0.0207, G loss: 8.4625\n",
      "[6132/8000] D loss: 0.0356, G loss: 9.6876\n",
      "[6492/8000] D loss: 0.0058, G loss: 9.1820\n",
      "[6852/8000] D loss: 0.4376, G loss: 7.5206\n",
      "[7212/8000] D loss: 0.2075, G loss: 11.7690\n",
      "[7572/8000] D loss: 0.1353, G loss: 11.6142\n",
      "[7932/8000] D loss: 0.0174, G loss: 9.5075\n",
      "train error: \n",
      " D loss: 0.196627, G loss: 10.125287, D accuracy: 94.8%, cell accuracy: 94.1%, board accuracy: 8.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.416984, G loss: 12.967342, D accuracy: 94.5%, cell accuracy: 93.8%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4528, G loss: 10.2619\n",
      "[372/8000] D loss: 0.1878, G loss: 10.4975\n",
      "[732/8000] D loss: 0.2700, G loss: 10.2964\n",
      "[1092/8000] D loss: 0.4102, G loss: 10.4108\n",
      "[1452/8000] D loss: 0.3782, G loss: 6.1881\n",
      "[1812/8000] D loss: 0.2751, G loss: 7.0195\n",
      "[2172/8000] D loss: 0.0846, G loss: 8.1109\n",
      "[2532/8000] D loss: 0.1862, G loss: 11.8329\n",
      "[2892/8000] D loss: 0.2429, G loss: 7.6136\n",
      "[3252/8000] D loss: 0.1937, G loss: 9.4823\n",
      "[3612/8000] D loss: 0.1209, G loss: 8.6077\n",
      "[3972/8000] D loss: 0.1970, G loss: 7.3069\n",
      "[4332/8000] D loss: 0.2633, G loss: 7.5146\n",
      "[4692/8000] D loss: 0.0244, G loss: 7.9031\n",
      "[5052/8000] D loss: 0.0781, G loss: 11.1619\n",
      "[5412/8000] D loss: 0.3236, G loss: 8.4734\n",
      "[5772/8000] D loss: 0.0363, G loss: 10.4951\n",
      "[6132/8000] D loss: 0.0448, G loss: 11.3258\n",
      "[6492/8000] D loss: 0.6212, G loss: 9.4887\n",
      "[6852/8000] D loss: 0.0271, G loss: 13.4891\n",
      "[7212/8000] D loss: 0.4008, G loss: 7.5114\n",
      "[7572/8000] D loss: 0.8978, G loss: 11.9811\n",
      "[7932/8000] D loss: 0.0788, G loss: 8.8887\n",
      "train error: \n",
      " D loss: 0.213999, G loss: 8.908369, D accuracy: 94.6%, cell accuracy: 94.1%, board accuracy: 8.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.374759, G loss: 11.572072, D accuracy: 94.6%, cell accuracy: 93.8%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1055, G loss: 8.6315\n",
      "[372/8000] D loss: 0.0952, G loss: 12.0242\n",
      "[732/8000] D loss: 0.1723, G loss: 9.0859\n",
      "[1092/8000] D loss: 0.1939, G loss: 9.7779\n",
      "[1452/8000] D loss: 0.1717, G loss: 6.7772\n",
      "[1812/8000] D loss: 0.1268, G loss: 11.9561\n",
      "[2172/8000] D loss: 0.2493, G loss: 7.3435\n",
      "[2532/8000] D loss: 0.3206, G loss: 7.2390\n",
      "[2892/8000] D loss: 0.2606, G loss: 8.7358\n",
      "[3252/8000] D loss: 0.2150, G loss: 6.5787\n",
      "[3612/8000] D loss: 0.0466, G loss: 12.4064\n",
      "[3972/8000] D loss: 0.2059, G loss: 10.6537\n",
      "[4332/8000] D loss: 0.0736, G loss: 10.4561\n",
      "[4692/8000] D loss: 0.0145, G loss: 13.6581\n",
      "[5052/8000] D loss: 0.2992, G loss: 9.6486\n",
      "[5412/8000] D loss: 0.2472, G loss: 8.9785\n",
      "[5772/8000] D loss: 0.1260, G loss: 10.0116\n",
      "[6132/8000] D loss: 0.2367, G loss: 11.0725\n",
      "[6492/8000] D loss: 0.2427, G loss: 7.4899\n",
      "[6852/8000] D loss: 0.2973, G loss: 6.1796\n",
      "[7212/8000] D loss: 0.3299, G loss: 10.8551\n",
      "[7572/8000] D loss: 0.3324, G loss: 5.3049\n",
      "[7932/8000] D loss: 0.2564, G loss: 10.4289\n",
      "train error: \n",
      " D loss: 0.204976, G loss: 9.812493, D accuracy: 94.7%, cell accuracy: 94.2%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.427505, G loss: 12.627116, D accuracy: 94.4%, cell accuracy: 93.8%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1610, G loss: 7.9907\n",
      "[372/8000] D loss: 0.1683, G loss: 11.9451\n",
      "[732/8000] D loss: 0.3696, G loss: 7.8996\n",
      "[1092/8000] D loss: 0.2526, G loss: 7.6425\n",
      "[1452/8000] D loss: 0.4337, G loss: 10.8574\n",
      "[1812/8000] D loss: 0.2596, G loss: 12.6580\n",
      "[2172/8000] D loss: 0.0957, G loss: 7.6404\n",
      "[2532/8000] D loss: 0.0109, G loss: 13.2260\n",
      "[2892/8000] D loss: 0.2423, G loss: 6.8341\n",
      "[3252/8000] D loss: 0.2269, G loss: 9.3440\n",
      "[3612/8000] D loss: 0.1812, G loss: 6.5898\n",
      "[3972/8000] D loss: 0.1542, G loss: 11.4516\n",
      "[4332/8000] D loss: 0.0908, G loss: 9.4968\n",
      "[4692/8000] D loss: 0.1725, G loss: 8.5073\n",
      "[5052/8000] D loss: 0.1577, G loss: 9.9704\n",
      "[5412/8000] D loss: 0.0889, G loss: 10.6325\n",
      "[5772/8000] D loss: 0.1889, G loss: 7.2517\n",
      "[6132/8000] D loss: 0.3460, G loss: 7.3931\n",
      "[6492/8000] D loss: 0.1293, G loss: 9.7698\n",
      "[6852/8000] D loss: 0.3556, G loss: 7.0500\n",
      "[7212/8000] D loss: 0.1442, G loss: 12.1459\n",
      "[7572/8000] D loss: 0.2457, G loss: 7.7646\n",
      "[7932/8000] D loss: 0.4850, G loss: 6.0187\n",
      "train error: \n",
      " D loss: 0.215333, G loss: 10.434654, D accuracy: 94.5%, cell accuracy: 94.1%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.446734, G loss: 13.291964, D accuracy: 93.8%, cell accuracy: 93.8%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.8042, G loss: 4.6495\n",
      "[372/8000] D loss: 0.1748, G loss: 9.3391\n",
      "[732/8000] D loss: 0.1311, G loss: 9.0166\n",
      "[1092/8000] D loss: 0.2587, G loss: 7.6931\n",
      "[1452/8000] D loss: 0.1472, G loss: 7.4875\n",
      "[1812/8000] D loss: 0.0343, G loss: 10.3200\n",
      "[2172/8000] D loss: 0.0640, G loss: 8.4486\n",
      "[2532/8000] D loss: 0.1410, G loss: 11.6247\n",
      "[2892/8000] D loss: 0.1978, G loss: 10.4743\n",
      "[3252/8000] D loss: 0.0916, G loss: 13.2819\n",
      "[3612/8000] D loss: 0.1067, G loss: 13.1226\n",
      "[3972/8000] D loss: 0.1481, G loss: 11.4847\n",
      "[4332/8000] D loss: 0.0259, G loss: 10.3023\n",
      "[4692/8000] D loss: 0.0614, G loss: 8.7901\n",
      "[5052/8000] D loss: 0.3199, G loss: 11.2052\n",
      "[5412/8000] D loss: 0.0370, G loss: 11.2167\n",
      "[5772/8000] D loss: 0.1520, G loss: 11.7176\n",
      "[6132/8000] D loss: 0.0151, G loss: 9.5400\n",
      "[6492/8000] D loss: 0.2428, G loss: 9.5127\n",
      "[6852/8000] D loss: 0.1770, G loss: 6.9663\n",
      "[7212/8000] D loss: 0.3562, G loss: 10.2740\n",
      "[7572/8000] D loss: 0.1162, G loss: 7.0925\n",
      "[7932/8000] D loss: 0.3509, G loss: 11.7564\n",
      "train error: \n",
      " D loss: 0.211765, G loss: 9.321302, D accuracy: 94.7%, cell accuracy: 94.2%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.396028, G loss: 12.121453, D accuracy: 94.7%, cell accuracy: 93.8%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2255, G loss: 7.4997\n",
      "[372/8000] D loss: 0.0057, G loss: 10.0668\n",
      "[732/8000] D loss: 0.2424, G loss: 10.0751\n",
      "[1092/8000] D loss: 0.2299, G loss: 6.8426\n",
      "[1452/8000] D loss: 0.1437, G loss: 11.4395\n",
      "[1812/8000] D loss: 0.3206, G loss: 6.5882\n",
      "[2172/8000] D loss: 0.0645, G loss: 11.4912\n",
      "[2532/8000] D loss: 0.1903, G loss: 11.3349\n",
      "[2892/8000] D loss: 0.2319, G loss: 10.8352\n",
      "[3252/8000] D loss: 0.1761, G loss: 13.5628\n",
      "[3612/8000] D loss: 0.1366, G loss: 9.4615\n",
      "[3972/8000] D loss: 0.2436, G loss: 10.3304\n",
      "[4332/8000] D loss: 0.0306, G loss: 7.7217\n",
      "[4692/8000] D loss: 0.0465, G loss: 12.9460\n",
      "[5052/8000] D loss: 0.1357, G loss: 11.9589\n",
      "[5412/8000] D loss: 0.0319, G loss: 10.8900\n",
      "[5772/8000] D loss: 0.4330, G loss: 8.0123\n",
      "[6132/8000] D loss: 0.4826, G loss: 5.4184\n",
      "[6492/8000] D loss: 0.0540, G loss: 13.6319\n",
      "[6852/8000] D loss: 0.3978, G loss: 10.6562\n",
      "[7212/8000] D loss: 0.0761, G loss: 13.4484\n",
      "[7572/8000] D loss: 0.0212, G loss: 9.9420\n",
      "[7932/8000] D loss: 0.3851, G loss: 9.9077\n",
      "train error: \n",
      " D loss: 0.195787, G loss: 9.533992, D accuracy: 94.9%, cell accuracy: 94.2%, board accuracy: 7.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.424279, G loss: 12.213394, D accuracy: 94.2%, cell accuracy: 93.9%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3055, G loss: 5.6896\n",
      "[372/8000] D loss: 0.1432, G loss: 9.2834\n",
      "[732/8000] D loss: 0.1185, G loss: 9.1002\n",
      "[1092/8000] D loss: 0.2198, G loss: 7.1481\n",
      "[1452/8000] D loss: 0.1388, G loss: 11.2236\n",
      "[1812/8000] D loss: 0.0446, G loss: 8.0185\n",
      "[2172/8000] D loss: 0.0348, G loss: 11.0226\n",
      "[2532/8000] D loss: 0.2395, G loss: 11.1089\n",
      "[2892/8000] D loss: 0.0004, G loss: 11.4768\n",
      "[3252/8000] D loss: 0.1728, G loss: 9.0347\n",
      "[3612/8000] D loss: 0.1634, G loss: 8.2546\n",
      "[3972/8000] D loss: 0.1688, G loss: 6.7171\n",
      "[4332/8000] D loss: 0.0182, G loss: 7.3807\n",
      "[4692/8000] D loss: 0.0981, G loss: 7.7961\n",
      "[5052/8000] D loss: 0.1303, G loss: 12.2235\n",
      "[5412/8000] D loss: 0.1860, G loss: 8.8479\n",
      "[5772/8000] D loss: 0.2756, G loss: 7.8139\n",
      "[6132/8000] D loss: 0.1598, G loss: 9.8876\n",
      "[6492/8000] D loss: 0.0956, G loss: 9.7958\n",
      "[6852/8000] D loss: 0.1384, G loss: 9.2079\n",
      "[7212/8000] D loss: 0.1346, G loss: 8.5557\n",
      "[7572/8000] D loss: 0.1554, G loss: 9.9910\n",
      "[7932/8000] D loss: 0.3402, G loss: 10.0254\n",
      "train error: \n",
      " D loss: 0.190842, G loss: 9.843711, D accuracy: 95.0%, cell accuracy: 94.1%, board accuracy: 7.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.413706, G loss: 12.611125, D accuracy: 94.4%, cell accuracy: 93.8%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1487, G loss: 9.7080\n",
      "[372/8000] D loss: 0.2406, G loss: 9.6956\n",
      "[732/8000] D loss: 0.0470, G loss: 13.0520\n",
      "[1092/8000] D loss: 0.3092, G loss: 7.7224\n",
      "[1452/8000] D loss: 0.2610, G loss: 10.9549\n",
      "[1812/8000] D loss: 0.0640, G loss: 10.3391\n",
      "[2172/8000] D loss: 0.0938, G loss: 10.3280\n",
      "[2532/8000] D loss: 0.2515, G loss: 9.2155\n",
      "[2892/8000] D loss: 0.3333, G loss: 9.9624\n",
      "[3252/8000] D loss: 0.2774, G loss: 10.1281\n",
      "[3612/8000] D loss: 0.3246, G loss: 9.2769\n",
      "[3972/8000] D loss: 0.1595, G loss: 10.7086\n",
      "[4332/8000] D loss: 0.1248, G loss: 10.3760\n",
      "[4692/8000] D loss: 0.0933, G loss: 5.9302\n",
      "[5052/8000] D loss: 0.1705, G loss: 11.5750\n",
      "[5412/8000] D loss: 0.3369, G loss: 7.4603\n",
      "[5772/8000] D loss: 0.4084, G loss: 10.5514\n",
      "[6132/8000] D loss: 0.3258, G loss: 7.8928\n",
      "[6492/8000] D loss: 0.1332, G loss: 11.5838\n",
      "[6852/8000] D loss: 0.0232, G loss: 11.7280\n",
      "[7212/8000] D loss: 0.2412, G loss: 8.2740\n",
      "[7572/8000] D loss: 0.2630, G loss: 10.6384\n",
      "[7932/8000] D loss: 0.6793, G loss: 7.1516\n",
      "train error: \n",
      " D loss: 0.253343, G loss: 11.617015, D accuracy: 93.7%, cell accuracy: 94.2%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.605152, G loss: 14.448273, D accuracy: 92.2%, cell accuracy: 93.8%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4056, G loss: 11.1460\n",
      "[372/8000] D loss: 0.2796, G loss: 11.3772\n",
      "[732/8000] D loss: 0.0708, G loss: 6.5195\n",
      "[1092/8000] D loss: 0.2584, G loss: 10.0975\n",
      "[1452/8000] D loss: 0.1609, G loss: 10.2953\n",
      "[1812/8000] D loss: 0.0086, G loss: 9.9757\n",
      "[2172/8000] D loss: 0.0130, G loss: 11.6736\n",
      "[2532/8000] D loss: 0.3364, G loss: 7.4628\n",
      "[2892/8000] D loss: 0.1820, G loss: 11.1044\n",
      "[3252/8000] D loss: 0.1346, G loss: 10.5948\n",
      "[3612/8000] D loss: 0.0129, G loss: 11.3614\n",
      "[3972/8000] D loss: 0.2806, G loss: 9.1343\n",
      "[4332/8000] D loss: 0.4527, G loss: 7.9651\n",
      "[4692/8000] D loss: 0.1256, G loss: 10.0189\n",
      "[5052/8000] D loss: 0.1299, G loss: 11.7082\n",
      "[5412/8000] D loss: 0.2144, G loss: 10.5907\n",
      "[5772/8000] D loss: 0.1257, G loss: 9.1063\n",
      "[6132/8000] D loss: 0.1148, G loss: 12.5204\n",
      "[6492/8000] D loss: 0.1028, G loss: 6.8729\n",
      "[6852/8000] D loss: 0.0606, G loss: 11.8447\n",
      "[7212/8000] D loss: 0.3730, G loss: 8.7549\n",
      "[7572/8000] D loss: 0.1010, G loss: 7.2764\n",
      "[7932/8000] D loss: 0.2367, G loss: 9.7955\n",
      "train error: \n",
      " D loss: 0.204387, G loss: 10.628199, D accuracy: 94.6%, cell accuracy: 94.2%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.478411, G loss: 13.396525, D accuracy: 94.1%, cell accuracy: 93.8%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1473, G loss: 12.6913\n",
      "[372/8000] D loss: 0.2695, G loss: 10.5265\n",
      "[732/8000] D loss: 0.3953, G loss: 7.5117\n",
      "[1092/8000] D loss: 0.3769, G loss: 8.8636\n",
      "[1452/8000] D loss: 0.1355, G loss: 10.9696\n",
      "[1812/8000] D loss: 0.0651, G loss: 12.1211\n",
      "[2172/8000] D loss: 0.2762, G loss: 9.9011\n",
      "[2532/8000] D loss: 0.0955, G loss: 11.6106\n",
      "[2892/8000] D loss: 0.2194, G loss: 12.2216\n",
      "[3252/8000] D loss: 0.2535, G loss: 11.4502\n",
      "[3612/8000] D loss: 0.4022, G loss: 7.8632\n",
      "[3972/8000] D loss: 0.3123, G loss: 8.5882\n",
      "[4332/8000] D loss: 0.5552, G loss: 8.4505\n",
      "[4692/8000] D loss: 0.2371, G loss: 10.1003\n",
      "[5052/8000] D loss: 0.1486, G loss: 9.9756\n",
      "[5412/8000] D loss: 0.1679, G loss: 10.4823\n",
      "[5772/8000] D loss: 0.4334, G loss: 7.1370\n",
      "[6132/8000] D loss: 0.1455, G loss: 9.9359\n",
      "[6492/8000] D loss: 0.2164, G loss: 9.8236\n",
      "[6852/8000] D loss: 0.1115, G loss: 10.0748\n",
      "[7212/8000] D loss: 0.0324, G loss: 12.0809\n",
      "[7572/8000] D loss: 0.4022, G loss: 6.0597\n",
      "[7932/8000] D loss: 0.1678, G loss: 8.4530\n",
      "train error: \n",
      " D loss: 0.210006, G loss: 10.344257, D accuracy: 94.6%, cell accuracy: 94.2%, board accuracy: 8.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.491535, G loss: 13.130471, D accuracy: 93.7%, cell accuracy: 93.8%, board accuracy: 3.3% \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1241, G loss: 11.7096\n",
      "[372/8000] D loss: 0.2940, G loss: 9.5472\n",
      "[732/8000] D loss: 0.2194, G loss: 13.3699\n",
      "[1092/8000] D loss: 0.0219, G loss: 12.0186\n",
      "[1452/8000] D loss: 0.3270, G loss: 8.7373\n",
      "[1812/8000] D loss: 0.2981, G loss: 8.6475\n",
      "[2172/8000] D loss: 0.2578, G loss: 6.9678\n",
      "[2532/8000] D loss: 0.2136, G loss: 10.2233\n",
      "[2892/8000] D loss: 0.2893, G loss: 8.0245\n",
      "[3252/8000] D loss: 0.1468, G loss: 8.7285\n",
      "[3612/8000] D loss: 0.1814, G loss: 8.1304\n",
      "[3972/8000] D loss: 0.1237, G loss: 10.2286\n",
      "[4332/8000] D loss: 0.3229, G loss: 9.4749\n",
      "[4692/8000] D loss: 0.2815, G loss: 8.9380\n",
      "[5052/8000] D loss: 0.5521, G loss: 11.0513\n",
      "[5412/8000] D loss: 0.8458, G loss: 9.2321\n",
      "[5772/8000] D loss: 0.1869, G loss: 7.3392\n",
      "[6132/8000] D loss: 0.0193, G loss: 12.3706\n",
      "[6492/8000] D loss: 0.3276, G loss: 7.7342\n",
      "[6852/8000] D loss: 0.0619, G loss: 12.8229\n",
      "[7212/8000] D loss: 0.1896, G loss: 9.0103\n",
      "[7572/8000] D loss: 0.0860, G loss: 9.5859\n",
      "[7932/8000] D loss: 0.3923, G loss: 10.1535\n",
      "train error: \n",
      " D loss: 0.226718, G loss: 8.460499, D accuracy: 94.4%, cell accuracy: 94.2%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.353792, G loss: 11.171234, D accuracy: 95.1%, cell accuracy: 93.8%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0228, G loss: 8.2018\n",
      "[372/8000] D loss: 0.1641, G loss: 13.7824\n",
      "[732/8000] D loss: 0.1738, G loss: 9.0731\n",
      "[1092/8000] D loss: 0.2272, G loss: 11.3783\n",
      "[1452/8000] D loss: 0.0122, G loss: 9.9002\n",
      "[1812/8000] D loss: 0.1457, G loss: 8.6304\n",
      "[2172/8000] D loss: 0.0030, G loss: 14.1854\n",
      "[2532/8000] D loss: 0.1505, G loss: 6.8392\n",
      "[2892/8000] D loss: 0.1561, G loss: 8.6312\n",
      "[3252/8000] D loss: 0.2281, G loss: 7.6277\n",
      "[3612/8000] D loss: 0.4818, G loss: 8.3065\n",
      "[3972/8000] D loss: 0.5735, G loss: 6.1346\n",
      "[4332/8000] D loss: 0.1617, G loss: 9.8949\n",
      "[4692/8000] D loss: 0.1826, G loss: 9.9414\n",
      "[5052/8000] D loss: 0.2585, G loss: 9.8972\n",
      "[5412/8000] D loss: 0.1248, G loss: 10.2020\n",
      "[5772/8000] D loss: 0.2187, G loss: 9.6323\n",
      "[6132/8000] D loss: 0.1678, G loss: 9.5034\n",
      "[6492/8000] D loss: 0.4414, G loss: 10.2896\n",
      "[6852/8000] D loss: 0.1573, G loss: 10.4734\n",
      "[7212/8000] D loss: 0.1113, G loss: 10.2024\n",
      "[7572/8000] D loss: 0.3909, G loss: 6.6398\n",
      "[7932/8000] D loss: 0.1995, G loss: 9.2281\n",
      "train error: \n",
      " D loss: 0.239709, G loss: 11.207547, D accuracy: 94.1%, cell accuracy: 94.2%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.521698, G loss: 13.927934, D accuracy: 92.8%, cell accuracy: 93.8%, board accuracy: 2.6% \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3449, G loss: 11.7837\n",
      "[372/8000] D loss: 0.2584, G loss: 9.3306\n",
      "[732/8000] D loss: 0.3688, G loss: 8.1191\n",
      "[1092/8000] D loss: 0.1285, G loss: 8.9990\n",
      "[1452/8000] D loss: 0.2080, G loss: 9.2681\n",
      "[1812/8000] D loss: 0.2429, G loss: 9.3201\n",
      "[2172/8000] D loss: 0.6609, G loss: 7.9028\n",
      "[2532/8000] D loss: 0.5038, G loss: 9.9186\n",
      "[2892/8000] D loss: 0.4340, G loss: 10.7234\n",
      "[3252/8000] D loss: 0.1868, G loss: 10.7646\n",
      "[3612/8000] D loss: 0.0385, G loss: 8.3569\n",
      "[3972/8000] D loss: 0.0482, G loss: 9.0377\n",
      "[4332/8000] D loss: 0.0088, G loss: 10.9199\n",
      "[4692/8000] D loss: 0.1688, G loss: 5.7208\n",
      "[5052/8000] D loss: 0.0247, G loss: 10.0662\n",
      "[5412/8000] D loss: 0.1018, G loss: 11.6278\n",
      "[5772/8000] D loss: 0.0034, G loss: 14.1570\n",
      "[6132/8000] D loss: 0.6195, G loss: 6.4358\n",
      "[6492/8000] D loss: 0.0706, G loss: 8.5397\n",
      "[6852/8000] D loss: 0.1401, G loss: 10.6224\n",
      "[7212/8000] D loss: 0.1246, G loss: 7.9895\n",
      "[7572/8000] D loss: 0.2002, G loss: 9.7741\n",
      "[7932/8000] D loss: 0.1495, G loss: 9.2508\n",
      "train error: \n",
      " D loss: 0.207127, G loss: 8.714129, D accuracy: 94.7%, cell accuracy: 94.2%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.374594, G loss: 11.548689, D accuracy: 94.9%, cell accuracy: 93.8%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4679, G loss: 8.8532\n",
      "[372/8000] D loss: 0.1921, G loss: 10.2539\n",
      "[732/8000] D loss: 0.2443, G loss: 9.3605\n",
      "[1092/8000] D loss: 0.1460, G loss: 8.0890\n",
      "[1452/8000] D loss: 0.2867, G loss: 8.7341\n",
      "[1812/8000] D loss: 0.0441, G loss: 11.8677\n",
      "[2172/8000] D loss: 0.0416, G loss: 7.6120\n",
      "[2532/8000] D loss: 0.2371, G loss: 9.0442\n",
      "[2892/8000] D loss: 0.3377, G loss: 9.4622\n",
      "[3252/8000] D loss: 0.2174, G loss: 10.0962\n",
      "[3612/8000] D loss: 0.0777, G loss: 9.6357\n",
      "[3972/8000] D loss: 0.4009, G loss: 8.1105\n",
      "[4332/8000] D loss: 0.1679, G loss: 13.3671\n",
      "[4692/8000] D loss: 0.3010, G loss: 9.7560\n",
      "[5052/8000] D loss: 0.2095, G loss: 6.9020\n",
      "[5412/8000] D loss: 0.0541, G loss: 12.5751\n",
      "[5772/8000] D loss: 0.6573, G loss: 8.9442\n",
      "[6132/8000] D loss: 0.0361, G loss: 11.0970\n",
      "[6492/8000] D loss: 0.3091, G loss: 14.0602\n",
      "[6852/8000] D loss: 0.1640, G loss: 10.0384\n",
      "[7212/8000] D loss: 0.3903, G loss: 9.4903\n",
      "[7572/8000] D loss: 0.0238, G loss: 7.0119\n",
      "[7932/8000] D loss: 0.1687, G loss: 11.5629\n",
      "train error: \n",
      " D loss: 0.194665, G loss: 9.532353, D accuracy: 94.9%, cell accuracy: 94.2%, board accuracy: 8.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.435425, G loss: 12.284763, D accuracy: 94.0%, cell accuracy: 93.8%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2264, G loss: 8.3070\n",
      "[372/8000] D loss: 0.2702, G loss: 9.5175\n",
      "[732/8000] D loss: 0.1413, G loss: 13.5291\n",
      "[1092/8000] D loss: 0.2386, G loss: 10.3982\n",
      "[1452/8000] D loss: 0.1133, G loss: 10.3156\n",
      "[1812/8000] D loss: 0.4371, G loss: 7.2469\n",
      "[2172/8000] D loss: 0.1381, G loss: 8.3053\n",
      "[2532/8000] D loss: 0.0009, G loss: 14.4432\n",
      "[2892/8000] D loss: 0.5360, G loss: 7.7484\n",
      "[3252/8000] D loss: 0.2635, G loss: 7.7063\n",
      "[3612/8000] D loss: 0.1390, G loss: 10.7171\n",
      "[3972/8000] D loss: 0.1389, G loss: 9.4496\n",
      "[4332/8000] D loss: 0.1732, G loss: 8.0379\n",
      "[4692/8000] D loss: 0.1247, G loss: 9.1291\n",
      "[5052/8000] D loss: 0.1185, G loss: 10.3186\n",
      "[5412/8000] D loss: 0.0814, G loss: 9.8139\n",
      "[5772/8000] D loss: 0.1227, G loss: 9.3394\n",
      "[6132/8000] D loss: 0.0020, G loss: 14.0229\n",
      "[6492/8000] D loss: 0.3110, G loss: 10.1237\n",
      "[6852/8000] D loss: 0.4646, G loss: 9.7513\n",
      "[7212/8000] D loss: 0.1695, G loss: 9.5119\n",
      "[7572/8000] D loss: 0.1754, G loss: 8.0938\n",
      "[7932/8000] D loss: 0.0724, G loss: 8.9856\n",
      "train error: \n",
      " D loss: 0.209121, G loss: 10.104963, D accuracy: 94.8%, cell accuracy: 94.2%, board accuracy: 8.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.488737, G loss: 12.868122, D accuracy: 93.4%, cell accuracy: 93.9%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2047, G loss: 8.7117\n",
      "[372/8000] D loss: 0.1832, G loss: 11.5157\n",
      "[732/8000] D loss: 0.2699, G loss: 10.7213\n",
      "[1092/8000] D loss: 0.2135, G loss: 7.5120\n",
      "[1452/8000] D loss: 0.2574, G loss: 10.8347\n",
      "[1812/8000] D loss: 0.6496, G loss: 9.0279\n",
      "[2172/8000] D loss: 0.1305, G loss: 8.5910\n",
      "[2532/8000] D loss: 0.1008, G loss: 12.8999\n",
      "[2892/8000] D loss: 0.0182, G loss: 10.8740\n",
      "[3252/8000] D loss: 0.0047, G loss: 10.8590\n",
      "[3612/8000] D loss: 0.2600, G loss: 8.8679\n",
      "[3972/8000] D loss: 0.2972, G loss: 7.7457\n",
      "[4332/8000] D loss: 0.2544, G loss: 8.7679\n",
      "[4692/8000] D loss: 0.2413, G loss: 13.0395\n",
      "[5052/8000] D loss: 0.3795, G loss: 10.1069\n",
      "[5412/8000] D loss: 0.0209, G loss: 12.3273\n",
      "[5772/8000] D loss: 0.2124, G loss: 6.9665\n",
      "[6132/8000] D loss: 0.1145, G loss: 11.7260\n",
      "[6492/8000] D loss: 0.0497, G loss: 10.9527\n",
      "[6852/8000] D loss: 0.1247, G loss: 9.9358\n",
      "[7212/8000] D loss: 0.1852, G loss: 9.6151\n",
      "[7572/8000] D loss: 0.1409, G loss: 9.4808\n",
      "[7932/8000] D loss: 0.2134, G loss: 9.6445\n",
      "train error: \n",
      " D loss: 0.218761, G loss: 10.459082, D accuracy: 94.4%, cell accuracy: 94.2%, board accuracy: 8.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.525328, G loss: 13.177278, D accuracy: 93.8%, cell accuracy: 93.9%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0824, G loss: 12.0730\n",
      "[372/8000] D loss: 0.1632, G loss: 8.8358\n",
      "[732/8000] D loss: 0.0698, G loss: 8.2478\n",
      "[1092/8000] D loss: 0.2713, G loss: 11.7852\n",
      "[1452/8000] D loss: 0.3788, G loss: 9.0418\n",
      "[1812/8000] D loss: 0.1127, G loss: 11.9227\n",
      "[2172/8000] D loss: 0.2166, G loss: 7.2823\n",
      "[2532/8000] D loss: 0.7530, G loss: 7.0008\n",
      "[2892/8000] D loss: 0.0170, G loss: 11.5414\n",
      "[3252/8000] D loss: 0.0007, G loss: 10.9992\n",
      "[3612/8000] D loss: 0.1011, G loss: 8.2253\n",
      "[3972/8000] D loss: 0.6615, G loss: 3.9111\n",
      "[4332/8000] D loss: 0.0204, G loss: 10.8694\n",
      "[4692/8000] D loss: 0.0866, G loss: 12.8305\n",
      "[5052/8000] D loss: 0.0264, G loss: 12.0540\n",
      "[5412/8000] D loss: 0.1711, G loss: 8.8733\n",
      "[5772/8000] D loss: 0.1614, G loss: 10.1731\n",
      "[6132/8000] D loss: 0.3595, G loss: 8.6596\n",
      "[6492/8000] D loss: 0.1828, G loss: 9.6332\n",
      "[6852/8000] D loss: 0.2454, G loss: 7.7786\n",
      "[7212/8000] D loss: 0.1207, G loss: 8.7302\n",
      "[7572/8000] D loss: 0.1593, G loss: 10.9871\n",
      "[7932/8000] D loss: 0.2627, G loss: 6.3826\n",
      "train error: \n",
      " D loss: 0.203146, G loss: 8.700092, D accuracy: 94.8%, cell accuracy: 94.2%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.407923, G loss: 11.513067, D accuracy: 93.9%, cell accuracy: 93.8%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0274, G loss: 8.2265\n",
      "[372/8000] D loss: 0.2305, G loss: 8.7229\n",
      "[732/8000] D loss: 0.1786, G loss: 11.1764\n",
      "[1092/8000] D loss: 0.1996, G loss: 10.9613\n",
      "[1452/8000] D loss: 0.0049, G loss: 11.3041\n",
      "[1812/8000] D loss: 0.0158, G loss: 10.2224\n",
      "[2172/8000] D loss: 0.0737, G loss: 9.8068\n",
      "[2532/8000] D loss: 0.1578, G loss: 11.0703\n",
      "[2892/8000] D loss: 0.1713, G loss: 7.7465\n",
      "[3252/8000] D loss: 0.1481, G loss: 8.6397\n",
      "[3612/8000] D loss: 0.1496, G loss: 10.8066\n",
      "[3972/8000] D loss: 0.5909, G loss: 4.9008\n",
      "[4332/8000] D loss: 0.1463, G loss: 7.6489\n",
      "[4692/8000] D loss: 0.0331, G loss: 8.8695\n",
      "[5052/8000] D loss: 0.1620, G loss: 10.9418\n",
      "[5412/8000] D loss: 0.1112, G loss: 10.7122\n",
      "[5772/8000] D loss: 0.1528, G loss: 9.3409\n",
      "[6132/8000] D loss: 0.0048, G loss: 14.3423\n",
      "[6492/8000] D loss: 0.3312, G loss: 6.7204\n",
      "[6852/8000] D loss: 0.1088, G loss: 8.8000\n",
      "[7212/8000] D loss: 0.0134, G loss: 9.7175\n",
      "[7572/8000] D loss: 0.1428, G loss: 9.0312\n",
      "[7932/8000] D loss: 0.2395, G loss: 8.5389\n",
      "train error: \n",
      " D loss: 0.197445, G loss: 9.986160, D accuracy: 94.6%, cell accuracy: 94.2%, board accuracy: 8.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.479997, G loss: 12.758690, D accuracy: 93.5%, cell accuracy: 93.8%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4954, G loss: 7.6759\n",
      "[372/8000] D loss: 0.3802, G loss: 10.7203\n",
      "[732/8000] D loss: 0.2862, G loss: 7.7246\n",
      "[1092/8000] D loss: 0.0538, G loss: 8.3398\n",
      "[1452/8000] D loss: 0.1390, G loss: 8.8841\n",
      "[1812/8000] D loss: 0.1952, G loss: 9.3527\n",
      "[2172/8000] D loss: 0.0051, G loss: 9.5450\n",
      "[2532/8000] D loss: 0.0474, G loss: 15.5508\n",
      "[2892/8000] D loss: 0.2831, G loss: 8.6258\n",
      "[3252/8000] D loss: 0.3300, G loss: 7.7582\n",
      "[3612/8000] D loss: 0.1504, G loss: 11.6070\n",
      "[3972/8000] D loss: 0.2277, G loss: 11.5771\n",
      "[4332/8000] D loss: 0.0504, G loss: 9.9359\n",
      "[4692/8000] D loss: 0.2235, G loss: 9.2223\n",
      "[5052/8000] D loss: 0.1965, G loss: 10.4237\n",
      "[5412/8000] D loss: 0.0816, G loss: 8.6911\n",
      "[5772/8000] D loss: 0.0245, G loss: 11.6532\n",
      "[6132/8000] D loss: 0.0252, G loss: 10.1468\n",
      "[6492/8000] D loss: 0.4403, G loss: 12.5977\n",
      "[6852/8000] D loss: 0.1554, G loss: 7.6478\n",
      "[7212/8000] D loss: 0.2422, G loss: 11.6500\n",
      "[7572/8000] D loss: 0.2451, G loss: 11.3435\n",
      "[7932/8000] D loss: 0.0229, G loss: 10.2093\n",
      "train error: \n",
      " D loss: 0.193802, G loss: 10.195584, D accuracy: 94.8%, cell accuracy: 94.2%, board accuracy: 8.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.467719, G loss: 13.208049, D accuracy: 94.2%, cell accuracy: 93.8%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3817, G loss: 8.6670\n",
      "[372/8000] D loss: 0.3083, G loss: 9.8381\n",
      "[732/8000] D loss: 0.3116, G loss: 10.0100\n",
      "[1092/8000] D loss: 0.0700, G loss: 11.6583\n",
      "[1452/8000] D loss: 0.1553, G loss: 12.2592\n",
      "[1812/8000] D loss: 0.0859, G loss: 11.3391\n",
      "[2172/8000] D loss: 0.4113, G loss: 4.1267\n",
      "[2532/8000] D loss: 0.0185, G loss: 10.4693\n",
      "[2892/8000] D loss: 0.0057, G loss: 9.2417\n",
      "[3252/8000] D loss: 0.3369, G loss: 9.0265\n",
      "[3612/8000] D loss: 0.0218, G loss: 13.3584\n",
      "[3972/8000] D loss: 0.2738, G loss: 7.4050\n",
      "[4332/8000] D loss: 0.6740, G loss: 6.5852\n",
      "[4692/8000] D loss: 0.6722, G loss: 10.6860\n",
      "[5052/8000] D loss: 0.1406, G loss: 8.9925\n",
      "[5412/8000] D loss: 0.0747, G loss: 7.4876\n",
      "[5772/8000] D loss: 0.4010, G loss: 8.3122\n",
      "[6132/8000] D loss: 0.1065, G loss: 8.0510\n",
      "[6492/8000] D loss: 0.4026, G loss: 5.3073\n",
      "[6852/8000] D loss: 0.1072, G loss: 11.7236\n",
      "[7212/8000] D loss: 0.1559, G loss: 11.3410\n",
      "[7572/8000] D loss: 0.0602, G loss: 9.4494\n",
      "[7932/8000] D loss: 0.3054, G loss: 7.4741\n",
      "train error: \n",
      " D loss: 0.213701, G loss: 10.103274, D accuracy: 94.4%, cell accuracy: 94.2%, board accuracy: 8.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.510061, G loss: 12.966470, D accuracy: 93.5%, cell accuracy: 93.8%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0755, G loss: 12.0857\n",
      "[372/8000] D loss: 0.1001, G loss: 11.6209\n",
      "[732/8000] D loss: 0.0372, G loss: 5.1964\n",
      "[1092/8000] D loss: 0.3373, G loss: 6.8159\n",
      "[1452/8000] D loss: 0.1552, G loss: 10.3440\n",
      "[1812/8000] D loss: 0.0907, G loss: 12.3986\n",
      "[2172/8000] D loss: 0.1582, G loss: 10.9438\n",
      "[2532/8000] D loss: 0.1507, G loss: 13.1530\n",
      "[2892/8000] D loss: 0.1374, G loss: 7.2375\n",
      "[3252/8000] D loss: 0.0223, G loss: 9.8362\n",
      "[3612/8000] D loss: 0.4626, G loss: 7.9170\n",
      "[3972/8000] D loss: 0.2484, G loss: 8.3681\n",
      "[4332/8000] D loss: 0.2834, G loss: 8.3044\n",
      "[4692/8000] D loss: 0.1443, G loss: 9.3232\n",
      "[5052/8000] D loss: 0.0159, G loss: 12.3824\n",
      "[5412/8000] D loss: 0.0444, G loss: 12.7712\n",
      "[5772/8000] D loss: 0.8419, G loss: 4.8101\n",
      "[6132/8000] D loss: 0.1434, G loss: 10.0105\n",
      "[6492/8000] D loss: 0.4409, G loss: 5.1239\n",
      "[6852/8000] D loss: 0.1543, G loss: 8.9426\n",
      "[7212/8000] D loss: 0.1793, G loss: 7.3064\n",
      "[7572/8000] D loss: 0.1799, G loss: 10.2495\n",
      "[7932/8000] D loss: 0.8174, G loss: 9.3934\n",
      "train error: \n",
      " D loss: 0.207910, G loss: 8.883615, D accuracy: 94.7%, cell accuracy: 94.2%, board accuracy: 8.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.387647, G loss: 11.784327, D accuracy: 94.8%, cell accuracy: 93.9%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1183, G loss: 10.2187\n",
      "[372/8000] D loss: 0.2584, G loss: 10.0503\n",
      "[732/8000] D loss: 0.2605, G loss: 9.1307\n",
      "[1092/8000] D loss: 0.1351, G loss: 10.3332\n",
      "[1452/8000] D loss: 0.3337, G loss: 10.5066\n",
      "[1812/8000] D loss: 0.1999, G loss: 8.0970\n",
      "[2172/8000] D loss: 0.2574, G loss: 6.5034\n",
      "[2532/8000] D loss: 0.1920, G loss: 9.0335\n",
      "[2892/8000] D loss: 0.2581, G loss: 7.4503\n",
      "[3252/8000] D loss: 0.0249, G loss: 10.9963\n",
      "[3612/8000] D loss: 0.0164, G loss: 14.9088\n",
      "[3972/8000] D loss: 0.2781, G loss: 7.8464\n",
      "[4332/8000] D loss: 0.2737, G loss: 7.7036\n",
      "[4692/8000] D loss: 0.2269, G loss: 11.3570\n",
      "[5052/8000] D loss: 0.2534, G loss: 11.3981\n",
      "[5412/8000] D loss: 0.1977, G loss: 6.4224\n",
      "[5772/8000] D loss: 0.4182, G loss: 8.7926\n",
      "[6132/8000] D loss: 0.3139, G loss: 8.6393\n",
      "[6492/8000] D loss: 0.1251, G loss: 9.2349\n",
      "[6852/8000] D loss: 0.3927, G loss: 7.8640\n",
      "[7212/8000] D loss: 0.2201, G loss: 9.2035\n",
      "[7572/8000] D loss: 0.3729, G loss: 8.2034\n",
      "[7932/8000] D loss: 0.4236, G loss: 8.0148\n",
      "train error: \n",
      " D loss: 0.219736, G loss: 8.378621, D accuracy: 94.4%, cell accuracy: 94.2%, board accuracy: 8.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.377442, G loss: 11.089895, D accuracy: 94.1%, cell accuracy: 93.9%, board accuracy: 2.9% \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1300, G loss: 10.1250\n",
      "[372/8000] D loss: 0.1990, G loss: 9.1372\n",
      "[732/8000] D loss: 0.2419, G loss: 11.5973\n",
      "[1092/8000] D loss: 0.1383, G loss: 11.0259\n",
      "[1452/8000] D loss: 0.1362, G loss: 9.5311\n",
      "[1812/8000] D loss: 0.0154, G loss: 8.3778\n",
      "[2172/8000] D loss: 0.2591, G loss: 11.5042\n",
      "[2532/8000] D loss: 0.0064, G loss: 12.3223\n",
      "[2892/8000] D loss: 0.2077, G loss: 10.5459\n",
      "[3252/8000] D loss: 0.1620, G loss: 11.8579\n",
      "[3612/8000] D loss: 0.5324, G loss: 6.5650\n",
      "[3972/8000] D loss: 0.1198, G loss: 11.7359\n",
      "[4332/8000] D loss: 0.0483, G loss: 9.9779\n",
      "[4692/8000] D loss: 0.0559, G loss: 8.2478\n",
      "[5052/8000] D loss: 0.2117, G loss: 8.6418\n",
      "[5412/8000] D loss: 0.2574, G loss: 10.0310\n",
      "[5772/8000] D loss: 0.5282, G loss: 7.5726\n",
      "[6132/8000] D loss: 0.3377, G loss: 9.0860\n",
      "[6492/8000] D loss: 0.0925, G loss: 12.0870\n",
      "[6852/8000] D loss: 0.5478, G loss: 9.3836\n",
      "[7212/8000] D loss: 0.2491, G loss: 6.9041\n",
      "[7572/8000] D loss: 0.0045, G loss: 12.0434\n",
      "[7932/8000] D loss: 0.6363, G loss: 5.9270\n",
      "train error: \n",
      " D loss: 0.217215, G loss: 8.331767, D accuracy: 94.5%, cell accuracy: 94.2%, board accuracy: 8.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.394947, G loss: 11.048996, D accuracy: 94.4%, cell accuracy: 93.9%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0108, G loss: 11.3013\n",
      "[372/8000] D loss: 0.1375, G loss: 8.8356\n",
      "[732/8000] D loss: 0.2580, G loss: 9.6523\n",
      "[1092/8000] D loss: 0.0124, G loss: 14.3088\n",
      "[1452/8000] D loss: 0.1568, G loss: 8.7752\n",
      "[1812/8000] D loss: 0.2438, G loss: 10.4533\n",
      "[2172/8000] D loss: 0.2147, G loss: 8.5108\n",
      "[2532/8000] D loss: 0.1279, G loss: 10.9939\n",
      "[2892/8000] D loss: 0.1725, G loss: 9.0613\n",
      "[3252/8000] D loss: 0.1846, G loss: 11.4361\n",
      "[3612/8000] D loss: 0.3988, G loss: 6.6303\n",
      "[3972/8000] D loss: 0.0934, G loss: 9.1778\n",
      "[4332/8000] D loss: 0.1266, G loss: 8.8131\n",
      "[4692/8000] D loss: 0.1211, G loss: 10.4845\n",
      "[5052/8000] D loss: 0.3177, G loss: 8.3524\n",
      "[5412/8000] D loss: 0.3112, G loss: 9.1465\n",
      "[5772/8000] D loss: 0.1829, G loss: 10.9990\n",
      "[6132/8000] D loss: 0.0285, G loss: 8.7552\n",
      "[6492/8000] D loss: 0.3994, G loss: 9.1621\n",
      "[6852/8000] D loss: 0.1356, G loss: 9.8029\n",
      "[7212/8000] D loss: 0.3889, G loss: 8.3365\n",
      "[7572/8000] D loss: 0.3270, G loss: 8.7427\n",
      "[7932/8000] D loss: 0.2286, G loss: 8.8474\n",
      "train error: \n",
      " D loss: 0.205814, G loss: 8.834435, D accuracy: 94.7%, cell accuracy: 94.2%, board accuracy: 8.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.419427, G loss: 11.699727, D accuracy: 94.4%, cell accuracy: 93.9%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1877, G loss: 10.8553\n",
      "[372/8000] D loss: 0.6068, G loss: 7.5041\n",
      "[732/8000] D loss: 0.4156, G loss: 10.5932\n",
      "[1092/8000] D loss: 0.4326, G loss: 6.7202\n",
      "[1452/8000] D loss: 0.1551, G loss: 10.1252\n",
      "[1812/8000] D loss: 0.2664, G loss: 9.2735\n",
      "[2172/8000] D loss: 0.3500, G loss: 8.7041\n",
      "[2532/8000] D loss: 0.4153, G loss: 8.5430\n",
      "[2892/8000] D loss: 0.3197, G loss: 6.5387\n",
      "[3252/8000] D loss: 0.1487, G loss: 10.3160\n",
      "[3612/8000] D loss: 0.0455, G loss: 12.6885\n",
      "[3972/8000] D loss: 0.1084, G loss: 11.4588\n",
      "[4332/8000] D loss: 0.2031, G loss: 11.0646\n",
      "[4692/8000] D loss: 0.2190, G loss: 9.2375\n",
      "[5052/8000] D loss: 0.1241, G loss: 9.7175\n",
      "[5412/8000] D loss: 0.1867, G loss: 8.8830\n",
      "[5772/8000] D loss: 0.0801, G loss: 8.9927\n",
      "[6132/8000] D loss: 0.2807, G loss: 12.2977\n",
      "[6492/8000] D loss: 0.2870, G loss: 11.4475\n",
      "[6852/8000] D loss: 0.1996, G loss: 9.9062\n",
      "[7212/8000] D loss: 0.3018, G loss: 7.8582\n",
      "[7572/8000] D loss: 0.1422, G loss: 9.9587\n",
      "[7932/8000] D loss: 0.4326, G loss: 6.4983\n",
      "train error: \n",
      " D loss: 0.209456, G loss: 10.102171, D accuracy: 94.4%, cell accuracy: 94.2%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.488946, G loss: 12.959580, D accuracy: 93.6%, cell accuracy: 93.9%, board accuracy: 3.3% \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1537, G loss: 9.8552\n",
      "[372/8000] D loss: 0.1551, G loss: 9.8230\n",
      "[732/8000] D loss: 0.1806, G loss: 7.0182\n",
      "[1092/8000] D loss: 0.1537, G loss: 9.6716\n",
      "[1452/8000] D loss: 0.2527, G loss: 10.3721\n",
      "[1812/8000] D loss: 0.2278, G loss: 12.2879\n",
      "[2172/8000] D loss: 0.0163, G loss: 14.0840\n",
      "[2532/8000] D loss: 0.3640, G loss: 7.2334\n",
      "[2892/8000] D loss: 0.1439, G loss: 9.8714\n",
      "[3252/8000] D loss: 0.2043, G loss: 7.3046\n",
      "[3612/8000] D loss: 0.0274, G loss: 10.3762\n",
      "[3972/8000] D loss: 0.2979, G loss: 9.2995\n",
      "[4332/8000] D loss: 0.2865, G loss: 10.5860\n",
      "[4692/8000] D loss: 0.3537, G loss: 9.4966\n",
      "[5052/8000] D loss: 0.1636, G loss: 8.8904\n",
      "[5412/8000] D loss: 0.1707, G loss: 10.5419\n",
      "[5772/8000] D loss: 0.0178, G loss: 12.9339\n",
      "[6132/8000] D loss: 0.0292, G loss: 11.2499\n",
      "[6492/8000] D loss: 0.0137, G loss: 11.5606\n",
      "[6852/8000] D loss: 0.3960, G loss: 10.9064\n",
      "[7212/8000] D loss: 0.4966, G loss: 8.5000\n",
      "[7572/8000] D loss: 0.0180, G loss: 8.9111\n",
      "[7932/8000] D loss: 0.1334, G loss: 12.2643\n",
      "train error: \n",
      " D loss: 0.203643, G loss: 9.804419, D accuracy: 94.8%, cell accuracy: 94.2%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.428933, G loss: 12.617211, D accuracy: 94.1%, cell accuracy: 93.9%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0144, G loss: 9.2811\n",
      "[372/8000] D loss: 0.1541, G loss: 8.6144\n",
      "[732/8000] D loss: 0.0234, G loss: 10.3553\n",
      "[1092/8000] D loss: 0.1270, G loss: 9.7212\n",
      "[1452/8000] D loss: 0.1818, G loss: 11.3600\n",
      "[1812/8000] D loss: 0.1168, G loss: 9.9175\n",
      "[2172/8000] D loss: 0.0365, G loss: 10.7184\n",
      "[2532/8000] D loss: 0.0493, G loss: 8.6270\n",
      "[2892/8000] D loss: 0.0169, G loss: 8.2657\n",
      "[3252/8000] D loss: 0.3327, G loss: 7.2103\n",
      "[3612/8000] D loss: 0.2773, G loss: 7.5785\n",
      "[3972/8000] D loss: 0.5299, G loss: 7.8195\n",
      "[4332/8000] D loss: 0.2643, G loss: 8.9919\n",
      "[4692/8000] D loss: 0.2272, G loss: 7.8923\n",
      "[5052/8000] D loss: 0.2047, G loss: 8.6441\n",
      "[5412/8000] D loss: 0.7892, G loss: 8.9822\n",
      "[5772/8000] D loss: 0.1036, G loss: 10.5450\n",
      "[6132/8000] D loss: 0.0940, G loss: 13.4066\n",
      "[6492/8000] D loss: 0.0190, G loss: 10.0666\n",
      "[6852/8000] D loss: 0.1241, G loss: 11.9134\n",
      "[7212/8000] D loss: 0.0547, G loss: 8.8919\n",
      "[7572/8000] D loss: 0.0104, G loss: 9.5987\n",
      "[7932/8000] D loss: 0.1720, G loss: 11.9497\n",
      "train error: \n",
      " D loss: 0.206099, G loss: 9.503236, D accuracy: 94.5%, cell accuracy: 94.2%, board accuracy: 8.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.419587, G loss: 12.547267, D accuracy: 94.4%, cell accuracy: 93.9%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1458, G loss: 8.7170\n",
      "[372/8000] D loss: 0.1410, G loss: 9.9576\n",
      "[732/8000] D loss: 0.1468, G loss: 16.6292\n",
      "[1092/8000] D loss: 0.1309, G loss: 10.1702\n",
      "[1452/8000] D loss: 0.2816, G loss: 9.8341\n",
      "[1812/8000] D loss: 0.2877, G loss: 12.5583\n",
      "[2172/8000] D loss: 0.1430, G loss: 7.9110\n",
      "[2532/8000] D loss: 0.1653, G loss: 13.3863\n",
      "[2892/8000] D loss: 0.1720, G loss: 6.0500\n",
      "[3252/8000] D loss: 0.2164, G loss: 15.7932\n",
      "[3612/8000] D loss: 0.1678, G loss: 7.2761\n",
      "[3972/8000] D loss: 0.2300, G loss: 9.2913\n",
      "[4332/8000] D loss: 0.0135, G loss: 13.0045\n",
      "[4692/8000] D loss: 0.4248, G loss: 6.1209\n",
      "[5052/8000] D loss: 0.0774, G loss: 8.9357\n",
      "[5412/8000] D loss: 0.1767, G loss: 12.5133\n",
      "[5772/8000] D loss: 0.5908, G loss: 9.1320\n",
      "[6132/8000] D loss: 0.0154, G loss: 14.9518\n",
      "[6492/8000] D loss: 0.8151, G loss: 6.3768\n",
      "[6852/8000] D loss: 0.1584, G loss: 11.0252\n",
      "[7212/8000] D loss: 0.1446, G loss: 11.0786\n",
      "[7572/8000] D loss: 0.0092, G loss: 10.1753\n",
      "[7932/8000] D loss: 0.4874, G loss: 9.7447\n",
      "train error: \n",
      " D loss: 0.197458, G loss: 10.126828, D accuracy: 94.7%, cell accuracy: 94.2%, board accuracy: 8.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.456066, G loss: 13.144455, D accuracy: 94.4%, cell accuracy: 93.9%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2240, G loss: 10.5041\n",
      "[372/8000] D loss: 0.1305, G loss: 11.6562\n",
      "[732/8000] D loss: 0.3312, G loss: 9.9426\n",
      "[1092/8000] D loss: 0.0493, G loss: 15.2878\n",
      "[1452/8000] D loss: 0.0592, G loss: 15.5706\n",
      "[1812/8000] D loss: 0.2910, G loss: 7.5205\n",
      "[2172/8000] D loss: 0.6190, G loss: 9.8715\n",
      "[2532/8000] D loss: 0.1217, G loss: 11.7057\n",
      "[2892/8000] D loss: 0.0025, G loss: 11.1552\n",
      "[3252/8000] D loss: 0.1515, G loss: 12.0333\n",
      "[3612/8000] D loss: 0.7561, G loss: 7.2561\n",
      "[3972/8000] D loss: 0.3451, G loss: 11.0738\n",
      "[4332/8000] D loss: 0.0176, G loss: 11.6662\n",
      "[4692/8000] D loss: 0.2393, G loss: 7.7059\n",
      "[5052/8000] D loss: 0.1918, G loss: 9.7989\n",
      "[5412/8000] D loss: 0.1621, G loss: 9.4752\n",
      "[5772/8000] D loss: 0.0376, G loss: 14.2166\n",
      "[6132/8000] D loss: 0.0107, G loss: 10.4769\n",
      "[6492/8000] D loss: 0.0851, G loss: 8.9550\n",
      "[6852/8000] D loss: 0.2376, G loss: 9.1467\n",
      "[7212/8000] D loss: 0.1617, G loss: 7.3446\n",
      "[7572/8000] D loss: 0.4671, G loss: 8.8232\n",
      "[7932/8000] D loss: 0.0061, G loss: 12.0942\n",
      "train error: \n",
      " D loss: 0.211454, G loss: 9.745038, D accuracy: 94.3%, cell accuracy: 94.2%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.455533, G loss: 12.651528, D accuracy: 94.3%, cell accuracy: 93.9%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0133, G loss: 9.7314\n",
      "[372/8000] D loss: 0.0752, G loss: 12.9224\n",
      "[732/8000] D loss: 0.1175, G loss: 12.4662\n",
      "[1092/8000] D loss: 0.4311, G loss: 10.3481\n",
      "[1452/8000] D loss: 0.0089, G loss: 12.7200\n",
      "[1812/8000] D loss: 0.2423, G loss: 8.6650\n",
      "[2172/8000] D loss: 0.2427, G loss: 12.1503\n",
      "[2532/8000] D loss: 0.1389, G loss: 8.6518\n",
      "[2892/8000] D loss: 0.3121, G loss: 7.7695\n",
      "[3252/8000] D loss: 0.2604, G loss: 9.6714\n",
      "[3612/8000] D loss: 0.0036, G loss: 14.8270\n",
      "[3972/8000] D loss: 0.0131, G loss: 10.1777\n",
      "[4332/8000] D loss: 0.0031, G loss: 13.0943\n",
      "[4692/8000] D loss: 0.1959, G loss: 8.5035\n",
      "[5052/8000] D loss: 0.2858, G loss: 12.1569\n",
      "[5412/8000] D loss: 0.0507, G loss: 8.9299\n",
      "[5772/8000] D loss: 0.1401, G loss: 12.0304\n",
      "[6132/8000] D loss: 0.1695, G loss: 8.8959\n",
      "[6492/8000] D loss: 0.0983, G loss: 8.6339\n",
      "[6852/8000] D loss: 0.2900, G loss: 7.9053\n",
      "[7212/8000] D loss: 0.2937, G loss: 12.7617\n",
      "[7572/8000] D loss: 0.2535, G loss: 8.9414\n",
      "[7932/8000] D loss: 0.1761, G loss: 10.8085\n",
      "train error: \n",
      " D loss: 0.225155, G loss: 9.292101, D accuracy: 94.2%, cell accuracy: 94.2%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.389931, G loss: 12.252350, D accuracy: 95.0%, cell accuracy: 93.9%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5781, G loss: 8.2871\n",
      "[372/8000] D loss: 0.0130, G loss: 11.1909\n",
      "[732/8000] D loss: 0.1734, G loss: 10.9238\n",
      "[1092/8000] D loss: 0.0548, G loss: 8.5258\n",
      "[1452/8000] D loss: 0.9193, G loss: 8.8665\n",
      "[1812/8000] D loss: 0.1385, G loss: 10.2459\n",
      "[2172/8000] D loss: 0.1264, G loss: 9.0565\n",
      "[2532/8000] D loss: 0.0209, G loss: 10.6689\n",
      "[2892/8000] D loss: 0.5198, G loss: 6.8332\n",
      "[3252/8000] D loss: 0.2204, G loss: 12.9391\n",
      "[3612/8000] D loss: 0.3469, G loss: 6.8042\n",
      "[3972/8000] D loss: 0.2592, G loss: 9.9095\n",
      "[4332/8000] D loss: 0.2425, G loss: 9.3067\n",
      "[4692/8000] D loss: 0.0041, G loss: 11.9499\n",
      "[5052/8000] D loss: 0.2150, G loss: 8.5011\n",
      "[5412/8000] D loss: 0.0390, G loss: 12.8609\n",
      "[5772/8000] D loss: 0.3152, G loss: 13.2036\n",
      "[6132/8000] D loss: 0.6081, G loss: 10.0403\n",
      "[6492/8000] D loss: 0.3258, G loss: 7.7835\n",
      "[6852/8000] D loss: 0.0556, G loss: 7.3499\n",
      "[7212/8000] D loss: 0.1546, G loss: 13.4436\n",
      "[7572/8000] D loss: 0.0179, G loss: 11.1943\n",
      "[7932/8000] D loss: 0.2989, G loss: 8.1802\n",
      "train error: \n",
      " D loss: 0.218226, G loss: 8.551933, D accuracy: 94.5%, cell accuracy: 94.3%, board accuracy: 8.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.393986, G loss: 11.443644, D accuracy: 94.8%, cell accuracy: 93.9%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5091, G loss: 9.6794\n",
      "[372/8000] D loss: 0.0020, G loss: 14.0120\n",
      "[732/8000] D loss: 0.4792, G loss: 7.9925\n",
      "[1092/8000] D loss: 0.1399, G loss: 8.8381\n",
      "[1452/8000] D loss: 0.1583, G loss: 11.5872\n",
      "[1812/8000] D loss: 0.4655, G loss: 8.2571\n",
      "[2172/8000] D loss: 0.5543, G loss: 5.9833\n",
      "[2532/8000] D loss: 0.1589, G loss: 12.2989\n",
      "[2892/8000] D loss: 0.3282, G loss: 8.2749\n",
      "[3252/8000] D loss: 0.1840, G loss: 8.2151\n",
      "[3612/8000] D loss: 0.1156, G loss: 9.7756\n",
      "[3972/8000] D loss: 0.0433, G loss: 8.5786\n",
      "[4332/8000] D loss: 0.2469, G loss: 8.2680\n",
      "[4692/8000] D loss: 0.1736, G loss: 12.2978\n",
      "[5052/8000] D loss: 0.0251, G loss: 11.0127\n",
      "[5412/8000] D loss: 0.0577, G loss: 6.7752\n",
      "[5772/8000] D loss: 0.2143, G loss: 7.3374\n",
      "[6132/8000] D loss: 0.1571, G loss: 8.5352\n",
      "[6492/8000] D loss: 0.1668, G loss: 11.4921\n",
      "[6852/8000] D loss: 0.0847, G loss: 9.7260\n",
      "[7212/8000] D loss: 0.2831, G loss: 8.4936\n",
      "[7572/8000] D loss: 0.4601, G loss: 7.1581\n",
      "[7932/8000] D loss: 0.0222, G loss: 8.7176\n",
      "train error: \n",
      " D loss: 0.214800, G loss: 9.603949, D accuracy: 94.4%, cell accuracy: 94.3%, board accuracy: 9.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.457717, G loss: 12.371006, D accuracy: 93.5%, cell accuracy: 93.9%, board accuracy: 3.9% \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3920, G loss: 9.3082\n",
      "[372/8000] D loss: 0.6397, G loss: 6.4432\n",
      "[732/8000] D loss: 0.0874, G loss: 9.5502\n",
      "[1092/8000] D loss: 0.3801, G loss: 8.8424\n",
      "[1452/8000] D loss: 0.2571, G loss: 10.2549\n",
      "[1812/8000] D loss: 0.1405, G loss: 10.5653\n",
      "[2172/8000] D loss: 0.3906, G loss: 6.0635\n",
      "[2532/8000] D loss: 0.0523, G loss: 10.4484\n",
      "[2892/8000] D loss: 0.3097, G loss: 6.7793\n",
      "[3252/8000] D loss: 0.3307, G loss: 11.0825\n",
      "[3612/8000] D loss: 0.1398, G loss: 8.4416\n",
      "[3972/8000] D loss: 0.2547, G loss: 12.7558\n",
      "[4332/8000] D loss: 0.0336, G loss: 7.4120\n",
      "[4692/8000] D loss: 0.0554, G loss: 9.4055\n",
      "[5052/8000] D loss: 0.1254, G loss: 11.2483\n",
      "[5412/8000] D loss: 0.2317, G loss: 7.7567\n",
      "[5772/8000] D loss: 0.1682, G loss: 9.3721\n",
      "[6132/8000] D loss: 0.5149, G loss: 10.5034\n",
      "[6492/8000] D loss: 0.2606, G loss: 7.8112\n",
      "[6852/8000] D loss: 0.4194, G loss: 4.5458\n",
      "[7212/8000] D loss: 0.1216, G loss: 9.6636\n",
      "[7572/8000] D loss: 0.0164, G loss: 9.2975\n",
      "[7932/8000] D loss: 0.2773, G loss: 12.3600\n",
      "train error: \n",
      " D loss: 0.209498, G loss: 8.958394, D accuracy: 94.6%, cell accuracy: 94.3%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.408967, G loss: 11.646451, D accuracy: 94.6%, cell accuracy: 93.9%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1936, G loss: 8.2762\n",
      "[372/8000] D loss: 0.0080, G loss: 15.0471\n",
      "[732/8000] D loss: 0.0245, G loss: 9.1189\n",
      "[1092/8000] D loss: 0.2367, G loss: 9.3925\n",
      "[1452/8000] D loss: 0.2001, G loss: 11.7389\n",
      "[1812/8000] D loss: 0.3277, G loss: 10.1903\n",
      "[2172/8000] D loss: 0.3288, G loss: 7.4570\n",
      "[2532/8000] D loss: 0.4768, G loss: 6.5241\n",
      "[2892/8000] D loss: 0.0491, G loss: 12.2304\n",
      "[3252/8000] D loss: 0.3081, G loss: 9.4531\n",
      "[3612/8000] D loss: 0.2422, G loss: 7.8384\n",
      "[3972/8000] D loss: 0.2749, G loss: 11.5520\n",
      "[4332/8000] D loss: 0.0388, G loss: 10.7965\n",
      "[4692/8000] D loss: 0.1304, G loss: 8.0354\n",
      "[5052/8000] D loss: 0.1276, G loss: 7.4764\n",
      "[5412/8000] D loss: 0.3388, G loss: 8.6920\n",
      "[5772/8000] D loss: 0.1454, G loss: 11.0467\n",
      "[6132/8000] D loss: 0.1364, G loss: 11.5786\n",
      "[6492/8000] D loss: 0.1486, G loss: 9.1206\n",
      "[6852/8000] D loss: 0.3775, G loss: 8.2890\n",
      "[7212/8000] D loss: 0.1229, G loss: 11.0529\n",
      "[7572/8000] D loss: 0.2901, G loss: 11.2084\n",
      "[7932/8000] D loss: 0.0700, G loss: 12.5192\n",
      "train error: \n",
      " D loss: 0.208723, G loss: 9.773030, D accuracy: 94.5%, cell accuracy: 94.3%, board accuracy: 8.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.448622, G loss: 12.546806, D accuracy: 94.1%, cell accuracy: 93.9%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0332, G loss: 8.1681\n",
      "[372/8000] D loss: 0.4116, G loss: 6.9053\n",
      "[732/8000] D loss: 0.2127, G loss: 12.3796\n",
      "[1092/8000] D loss: 0.0393, G loss: 9.9182\n",
      "[1452/8000] D loss: 0.3841, G loss: 6.5318\n",
      "[1812/8000] D loss: 0.3363, G loss: 11.5449\n",
      "[2172/8000] D loss: 0.0735, G loss: 10.3076\n",
      "[2532/8000] D loss: 0.1264, G loss: 12.7283\n",
      "[2892/8000] D loss: 0.2283, G loss: 7.2065\n",
      "[3252/8000] D loss: 0.2518, G loss: 10.1643\n",
      "[3612/8000] D loss: 0.5106, G loss: 7.1420\n",
      "[3972/8000] D loss: 0.0029, G loss: 11.9231\n",
      "[4332/8000] D loss: 0.3538, G loss: 6.8652\n",
      "[4692/8000] D loss: 0.1431, G loss: 10.4870\n",
      "[5052/8000] D loss: 0.0435, G loss: 9.2549\n",
      "[5412/8000] D loss: 0.1391, G loss: 15.4133\n",
      "[5772/8000] D loss: 0.1453, G loss: 6.1714\n",
      "[6132/8000] D loss: 0.2990, G loss: 6.4811\n",
      "[6492/8000] D loss: 0.0356, G loss: 9.5143\n",
      "[6852/8000] D loss: 0.4096, G loss: 9.7493\n",
      "[7212/8000] D loss: 0.0154, G loss: 10.5704\n",
      "[7572/8000] D loss: 0.1813, G loss: 9.5657\n",
      "[7932/8000] D loss: 0.1513, G loss: 10.7465\n",
      "train error: \n",
      " D loss: 0.203939, G loss: 10.628190, D accuracy: 94.6%, cell accuracy: 94.3%, board accuracy: 9.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.462907, G loss: 13.601214, D accuracy: 94.2%, cell accuracy: 93.9%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4236, G loss: 10.0579\n",
      "[372/8000] D loss: 0.2676, G loss: 9.0509\n",
      "[732/8000] D loss: 0.1499, G loss: 10.4877\n",
      "[1092/8000] D loss: 0.1879, G loss: 10.6666\n",
      "[1452/8000] D loss: 0.1453, G loss: 9.2721\n",
      "[1812/8000] D loss: 0.1493, G loss: 10.9358\n",
      "[2172/8000] D loss: 0.0303, G loss: 10.2323\n",
      "[2532/8000] D loss: 0.1687, G loss: 11.1289\n",
      "[2892/8000] D loss: 0.4202, G loss: 6.8622\n",
      "[3252/8000] D loss: 0.1234, G loss: 10.9220\n",
      "[3612/8000] D loss: 0.4079, G loss: 7.2656\n",
      "[3972/8000] D loss: 0.1480, G loss: 11.2477\n",
      "[4332/8000] D loss: 0.3624, G loss: 6.4956\n",
      "[4692/8000] D loss: 0.2985, G loss: 6.8928\n",
      "[5052/8000] D loss: 0.0081, G loss: 11.8052\n",
      "[5412/8000] D loss: 0.2532, G loss: 10.2244\n",
      "[5772/8000] D loss: 0.1881, G loss: 10.7592\n",
      "[6132/8000] D loss: 0.0945, G loss: 15.2275\n",
      "[6492/8000] D loss: 0.3792, G loss: 9.1938\n",
      "[6852/8000] D loss: 0.1640, G loss: 8.2084\n",
      "[7212/8000] D loss: 0.1685, G loss: 10.6249\n",
      "[7572/8000] D loss: 0.4555, G loss: 6.1148\n",
      "[7932/8000] D loss: 0.2601, G loss: 9.0283\n",
      "train error: \n",
      " D loss: 0.210222, G loss: 10.471509, D accuracy: 94.6%, cell accuracy: 94.3%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.474231, G loss: 13.621402, D accuracy: 94.6%, cell accuracy: 93.9%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3562, G loss: 10.9205\n",
      "[372/8000] D loss: 0.3563, G loss: 11.2747\n",
      "[732/8000] D loss: 0.2754, G loss: 5.3387\n",
      "[1092/8000] D loss: 0.1941, G loss: 11.2233\n",
      "[1452/8000] D loss: 0.3911, G loss: 8.8553\n",
      "[1812/8000] D loss: 0.3998, G loss: 7.6818\n",
      "[2172/8000] D loss: 0.1253, G loss: 13.6147\n",
      "[2532/8000] D loss: 0.0896, G loss: 6.3625\n",
      "[2892/8000] D loss: 0.3056, G loss: 6.8320\n",
      "[3252/8000] D loss: 0.2701, G loss: 6.4980\n",
      "[3612/8000] D loss: 0.1483, G loss: 12.2857\n",
      "[3972/8000] D loss: 0.4251, G loss: 9.6628\n",
      "[4332/8000] D loss: 0.3029, G loss: 11.0107\n",
      "[4692/8000] D loss: 0.6852, G loss: 6.3399\n",
      "[5052/8000] D loss: 0.2648, G loss: 9.6810\n",
      "[5412/8000] D loss: 0.3574, G loss: 8.0217\n",
      "[5772/8000] D loss: 0.1717, G loss: 9.5544\n",
      "[6132/8000] D loss: 0.0958, G loss: 11.0636\n",
      "[6492/8000] D loss: 0.3893, G loss: 11.7239\n",
      "[6852/8000] D loss: 0.1627, G loss: 7.3100\n",
      "[7212/8000] D loss: 0.1022, G loss: 7.3672\n",
      "[7572/8000] D loss: 0.1322, G loss: 8.4947\n",
      "[7932/8000] D loss: 0.0904, G loss: 13.5222\n",
      "train error: \n",
      " D loss: 0.222623, G loss: 8.337273, D accuracy: 94.5%, cell accuracy: 94.3%, board accuracy: 8.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.362902, G loss: 11.311361, D accuracy: 94.8%, cell accuracy: 93.9%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2797, G loss: 8.8513\n",
      "[372/8000] D loss: 0.2401, G loss: 7.4509\n",
      "[732/8000] D loss: 0.1585, G loss: 6.6975\n",
      "[1092/8000] D loss: 0.2477, G loss: 10.9796\n",
      "[1452/8000] D loss: 0.3697, G loss: 10.2512\n",
      "[1812/8000] D loss: 0.1561, G loss: 10.3461\n",
      "[2172/8000] D loss: 0.3942, G loss: 8.6391\n",
      "[2532/8000] D loss: 0.3344, G loss: 6.4295\n",
      "[2892/8000] D loss: 0.1207, G loss: 9.7201\n",
      "[3252/8000] D loss: 0.1282, G loss: 10.3491\n",
      "[3612/8000] D loss: 0.1614, G loss: 8.3140\n",
      "[3972/8000] D loss: 0.4122, G loss: 8.3348\n",
      "[4332/8000] D loss: 0.2224, G loss: 9.1548\n",
      "[4692/8000] D loss: 0.1113, G loss: 9.3209\n",
      "[5052/8000] D loss: 0.1870, G loss: 11.6875\n",
      "[5412/8000] D loss: 0.2802, G loss: 7.6997\n",
      "[5772/8000] D loss: 0.2513, G loss: 11.9246\n",
      "[6132/8000] D loss: 0.1902, G loss: 9.2517\n",
      "[6492/8000] D loss: 0.1660, G loss: 9.2825\n",
      "[6852/8000] D loss: 0.1592, G loss: 9.7429\n",
      "[7212/8000] D loss: 0.0368, G loss: 8.2976\n",
      "[7572/8000] D loss: 0.1454, G loss: 10.7108\n",
      "[7932/8000] D loss: 0.2648, G loss: 13.2768\n",
      "train error: \n",
      " D loss: 0.193115, G loss: 9.953058, D accuracy: 94.9%, cell accuracy: 94.3%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.456146, G loss: 12.997135, D accuracy: 94.1%, cell accuracy: 93.9%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1164, G loss: 10.5470\n",
      "[372/8000] D loss: 0.2463, G loss: 7.6598\n",
      "[732/8000] D loss: 0.0426, G loss: 10.0105\n",
      "[1092/8000] D loss: 0.3817, G loss: 9.3517\n",
      "[1452/8000] D loss: 0.2093, G loss: 15.0327\n",
      "[1812/8000] D loss: 0.1384, G loss: 10.3052\n",
      "[2172/8000] D loss: 0.1363, G loss: 10.8732\n",
      "[2532/8000] D loss: 0.6177, G loss: 8.7387\n",
      "[2892/8000] D loss: 0.0374, G loss: 12.6377\n",
      "[3252/8000] D loss: 0.1239, G loss: 9.0847\n",
      "[3612/8000] D loss: 0.1294, G loss: 11.8251\n",
      "[3972/8000] D loss: 0.3424, G loss: 4.6089\n",
      "[4332/8000] D loss: 0.1195, G loss: 10.9619\n",
      "[4692/8000] D loss: 0.2422, G loss: 10.6489\n",
      "[5052/8000] D loss: 0.2356, G loss: 12.0603\n",
      "[5412/8000] D loss: 0.3109, G loss: 9.0586\n",
      "[5772/8000] D loss: 0.0936, G loss: 8.4795\n",
      "[6132/8000] D loss: 0.1584, G loss: 11.3764\n",
      "[6492/8000] D loss: 0.5243, G loss: 7.1700\n",
      "[6852/8000] D loss: 0.3677, G loss: 10.3660\n",
      "[7212/8000] D loss: 0.4527, G loss: 8.2899\n",
      "[7572/8000] D loss: 0.0239, G loss: 11.7007\n",
      "[7932/8000] D loss: 0.3102, G loss: 10.9718\n",
      "train error: \n",
      " D loss: 0.210683, G loss: 10.004042, D accuracy: 94.3%, cell accuracy: 94.3%, board accuracy: 9.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.498824, G loss: 13.004887, D accuracy: 94.0%, cell accuracy: 94.0%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0628, G loss: 13.3736\n",
      "[372/8000] D loss: 0.3263, G loss: 6.3647\n",
      "[732/8000] D loss: 0.0966, G loss: 8.6178\n",
      "[1092/8000] D loss: 0.1886, G loss: 11.6843\n",
      "[1452/8000] D loss: 0.0047, G loss: 11.1079\n",
      "[1812/8000] D loss: 0.3941, G loss: 7.1824\n",
      "[2172/8000] D loss: 0.3613, G loss: 8.8446\n",
      "[2532/8000] D loss: 0.0881, G loss: 15.2344\n",
      "[2892/8000] D loss: 0.4207, G loss: 9.2451\n",
      "[3252/8000] D loss: 0.1745, G loss: 11.3958\n",
      "[3612/8000] D loss: 0.1625, G loss: 10.8421\n",
      "[3972/8000] D loss: 0.0492, G loss: 8.0109\n",
      "[4332/8000] D loss: 0.0473, G loss: 11.6036\n",
      "[4692/8000] D loss: 0.3232, G loss: 9.8386\n",
      "[5052/8000] D loss: 0.1349, G loss: 11.1361\n",
      "[5412/8000] D loss: 0.1824, G loss: 7.5889\n",
      "[5772/8000] D loss: 0.3381, G loss: 10.4501\n",
      "[6132/8000] D loss: 0.1280, G loss: 10.1265\n",
      "[6492/8000] D loss: 0.2795, G loss: 8.2458\n",
      "[6852/8000] D loss: 0.3471, G loss: 6.5180\n",
      "[7212/8000] D loss: 0.4369, G loss: 8.6734\n",
      "[7572/8000] D loss: 0.3128, G loss: 9.0204\n",
      "[7932/8000] D loss: 0.3414, G loss: 7.2739\n",
      "train error: \n",
      " D loss: 0.211531, G loss: 9.279130, D accuracy: 94.5%, cell accuracy: 94.3%, board accuracy: 9.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.407036, G loss: 12.225768, D accuracy: 94.8%, cell accuracy: 93.9%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0117, G loss: 12.9439\n",
      "[372/8000] D loss: 0.1377, G loss: 9.4409\n",
      "[732/8000] D loss: 0.2046, G loss: 10.2301\n",
      "[1092/8000] D loss: 0.2433, G loss: 12.3970\n",
      "[1452/8000] D loss: 0.2708, G loss: 10.0144\n",
      "[1812/8000] D loss: 0.0705, G loss: 17.0528\n",
      "[2172/8000] D loss: 0.1899, G loss: 9.2616\n",
      "[2532/8000] D loss: 0.4092, G loss: 6.1061\n",
      "[2892/8000] D loss: 0.2791, G loss: 9.4910\n",
      "[3252/8000] D loss: 0.3074, G loss: 9.7884\n",
      "[3612/8000] D loss: 0.2001, G loss: 8.6954\n",
      "[3972/8000] D loss: 0.1150, G loss: 6.2511\n",
      "[4332/8000] D loss: 0.2410, G loss: 7.2224\n",
      "[4692/8000] D loss: 0.5659, G loss: 6.7194\n",
      "[5052/8000] D loss: 0.0688, G loss: 8.4378\n",
      "[5412/8000] D loss: 0.1843, G loss: 7.6198\n",
      "[5772/8000] D loss: 0.3280, G loss: 8.6677\n",
      "[6132/8000] D loss: 0.3404, G loss: 8.2931\n",
      "[6492/8000] D loss: 0.5520, G loss: 6.5083\n",
      "[6852/8000] D loss: 0.0053, G loss: 15.7777\n",
      "[7212/8000] D loss: 0.2741, G loss: 10.0686\n",
      "[7572/8000] D loss: 0.2820, G loss: 10.3602\n",
      "[7932/8000] D loss: 0.1924, G loss: 7.8634\n",
      "train error: \n",
      " D loss: 0.198888, G loss: 9.902849, D accuracy: 94.7%, cell accuracy: 94.3%, board accuracy: 9.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.457297, G loss: 13.111327, D accuracy: 94.4%, cell accuracy: 94.0%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0459, G loss: 10.8992\n",
      "[372/8000] D loss: 0.0288, G loss: 12.7727\n",
      "[732/8000] D loss: 0.2289, G loss: 9.9547\n",
      "[1092/8000] D loss: 0.0546, G loss: 12.6125\n",
      "[1452/8000] D loss: 0.2646, G loss: 10.9058\n",
      "[1812/8000] D loss: 0.2607, G loss: 9.0910\n",
      "[2172/8000] D loss: 0.1587, G loss: 7.8074\n",
      "[2532/8000] D loss: 0.3433, G loss: 9.4609\n",
      "[2892/8000] D loss: 0.0448, G loss: 9.6853\n",
      "[3252/8000] D loss: 0.0936, G loss: 9.5347\n",
      "[3612/8000] D loss: 0.6264, G loss: 5.8267\n",
      "[3972/8000] D loss: 0.0113, G loss: 14.2577\n",
      "[4332/8000] D loss: 0.2155, G loss: 10.1454\n",
      "[4692/8000] D loss: 0.5480, G loss: 10.9873\n",
      "[5052/8000] D loss: 0.3147, G loss: 12.6029\n",
      "[5412/8000] D loss: 0.1918, G loss: 9.2053\n",
      "[5772/8000] D loss: 0.2185, G loss: 8.4853\n",
      "[6132/8000] D loss: 0.4607, G loss: 7.8805\n",
      "[6492/8000] D loss: 0.4320, G loss: 8.8239\n",
      "[6852/8000] D loss: 0.2392, G loss: 10.6069\n",
      "[7212/8000] D loss: 0.2149, G loss: 9.1238\n",
      "[7572/8000] D loss: 0.4423, G loss: 7.2412\n",
      "[7932/8000] D loss: 0.2689, G loss: 11.2582\n",
      "train error: \n",
      " D loss: 0.210191, G loss: 10.321048, D accuracy: 94.3%, cell accuracy: 94.3%, board accuracy: 9.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.504910, G loss: 13.430006, D accuracy: 93.5%, cell accuracy: 94.0%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2528, G loss: 8.0780\n",
      "[372/8000] D loss: 0.2429, G loss: 12.3431\n",
      "[732/8000] D loss: 0.0797, G loss: 9.0596\n",
      "[1092/8000] D loss: 0.2286, G loss: 11.0742\n",
      "[1452/8000] D loss: 0.8210, G loss: 11.8712\n",
      "[1812/8000] D loss: 0.6167, G loss: 8.6285\n",
      "[2172/8000] D loss: 0.0192, G loss: 10.8439\n",
      "[2532/8000] D loss: 0.2131, G loss: 9.5861\n",
      "[2892/8000] D loss: 0.1325, G loss: 13.0068\n",
      "[3252/8000] D loss: 0.2691, G loss: 8.1395\n",
      "[3612/8000] D loss: 0.3610, G loss: 10.2593\n",
      "[3972/8000] D loss: 0.3488, G loss: 8.2514\n",
      "[4332/8000] D loss: 0.1996, G loss: 12.6439\n",
      "[4692/8000] D loss: 0.2426, G loss: 8.5565\n",
      "[5052/8000] D loss: 0.1051, G loss: 9.9213\n",
      "[5412/8000] D loss: 0.1504, G loss: 9.2317\n",
      "[5772/8000] D loss: 0.0992, G loss: 11.5690\n",
      "[6132/8000] D loss: 0.1402, G loss: 8.6967\n",
      "[6492/8000] D loss: 0.1198, G loss: 11.3797\n",
      "[6852/8000] D loss: 0.2363, G loss: 13.0008\n",
      "[7212/8000] D loss: 0.2094, G loss: 9.1080\n",
      "[7572/8000] D loss: 0.2520, G loss: 7.4882\n",
      "[7932/8000] D loss: 0.1346, G loss: 11.4423\n",
      "train error: \n",
      " D loss: 0.215341, G loss: 9.443782, D accuracy: 94.4%, cell accuracy: 94.3%, board accuracy: 8.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.451218, G loss: 12.542495, D accuracy: 94.6%, cell accuracy: 93.9%, board accuracy: 3.1% \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3599, G loss: 8.7921\n",
      "[372/8000] D loss: 0.2488, G loss: 7.2700\n",
      "[732/8000] D loss: 0.2257, G loss: 12.2720\n",
      "[1092/8000] D loss: 0.2610, G loss: 8.9969\n",
      "[1452/8000] D loss: 0.0326, G loss: 12.4374\n",
      "[1812/8000] D loss: 0.0422, G loss: 10.2180\n",
      "[2172/8000] D loss: 0.0083, G loss: 10.7994\n",
      "[2532/8000] D loss: 0.1884, G loss: 9.4428\n",
      "[2892/8000] D loss: 0.0138, G loss: 10.7916\n",
      "[3252/8000] D loss: 0.1954, G loss: 15.8097\n",
      "[3612/8000] D loss: 0.4342, G loss: 10.5733\n",
      "[3972/8000] D loss: 0.2200, G loss: 10.4444\n",
      "[4332/8000] D loss: 0.1797, G loss: 11.2878\n",
      "[4692/8000] D loss: 0.0073, G loss: 9.0156\n",
      "[5052/8000] D loss: 0.3254, G loss: 6.4256\n",
      "[5412/8000] D loss: 0.2920, G loss: 5.6672\n",
      "[5772/8000] D loss: 0.5021, G loss: 9.1436\n",
      "[6132/8000] D loss: 0.2870, G loss: 10.1247\n",
      "[6492/8000] D loss: 0.1253, G loss: 9.0113\n",
      "[6852/8000] D loss: 0.3660, G loss: 10.1595\n",
      "[7212/8000] D loss: 0.0028, G loss: 12.9967\n",
      "[7572/8000] D loss: 0.2309, G loss: 13.9027\n",
      "[7932/8000] D loss: 0.2016, G loss: 8.1764\n",
      "train error: \n",
      " D loss: 0.231707, G loss: 8.854916, D accuracy: 94.1%, cell accuracy: 94.3%, board accuracy: 9.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.372667, G loss: 11.811572, D accuracy: 94.4%, cell accuracy: 94.0%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0090, G loss: 12.0720\n",
      "[372/8000] D loss: 0.3555, G loss: 8.6967\n",
      "[732/8000] D loss: 0.3266, G loss: 8.2323\n",
      "[1092/8000] D loss: 0.2501, G loss: 7.5510\n",
      "[1452/8000] D loss: 0.1778, G loss: 11.5766\n",
      "[1812/8000] D loss: 0.3841, G loss: 7.8105\n",
      "[2172/8000] D loss: 0.3193, G loss: 11.5905\n",
      "[2532/8000] D loss: 0.1885, G loss: 13.0464\n",
      "[2892/8000] D loss: 0.2421, G loss: 9.0724\n",
      "[3252/8000] D loss: 0.0584, G loss: 12.8921\n",
      "[3612/8000] D loss: 0.4007, G loss: 6.2593\n",
      "[3972/8000] D loss: 0.1902, G loss: 9.2435\n",
      "[4332/8000] D loss: 0.2490, G loss: 6.7786\n",
      "[4692/8000] D loss: 0.4125, G loss: 8.5731\n",
      "[5052/8000] D loss: 0.1405, G loss: 11.8241\n",
      "[5412/8000] D loss: 0.1292, G loss: 8.3822\n",
      "[5772/8000] D loss: 0.3167, G loss: 6.7063\n",
      "[6132/8000] D loss: 0.3225, G loss: 8.9534\n",
      "[6492/8000] D loss: 0.5439, G loss: 9.1262\n",
      "[6852/8000] D loss: 0.0172, G loss: 7.8450\n",
      "[7212/8000] D loss: 0.3970, G loss: 9.5097\n",
      "[7572/8000] D loss: 0.2980, G loss: 7.4411\n",
      "[7932/8000] D loss: 0.2613, G loss: 8.7213\n",
      "train error: \n",
      " D loss: 0.217276, G loss: 9.706774, D accuracy: 94.3%, cell accuracy: 94.4%, board accuracy: 9.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.481659, G loss: 12.685299, D accuracy: 93.7%, cell accuracy: 94.0%, board accuracy: 3.9% \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1522, G loss: 7.6343\n",
      "[372/8000] D loss: 0.2711, G loss: 8.8418\n",
      "[732/8000] D loss: 0.2952, G loss: 10.2896\n",
      "[1092/8000] D loss: 0.4256, G loss: 7.3292\n",
      "[1452/8000] D loss: 0.3759, G loss: 6.5247\n",
      "[1812/8000] D loss: 0.2713, G loss: 8.0464\n",
      "[2172/8000] D loss: 0.0048, G loss: 12.5837\n",
      "[2532/8000] D loss: 0.2407, G loss: 8.8766\n",
      "[2892/8000] D loss: 0.0173, G loss: 8.9744\n",
      "[3252/8000] D loss: 0.5300, G loss: 7.6375\n",
      "[3612/8000] D loss: 0.5024, G loss: 6.7545\n",
      "[3972/8000] D loss: 0.2808, G loss: 9.4929\n",
      "[4332/8000] D loss: 0.0343, G loss: 9.2412\n",
      "[4692/8000] D loss: 0.2093, G loss: 6.4721\n",
      "[5052/8000] D loss: 0.1238, G loss: 11.7160\n",
      "[5412/8000] D loss: 0.1512, G loss: 11.0011\n",
      "[5772/8000] D loss: 0.0197, G loss: 9.6868\n",
      "[6132/8000] D loss: 0.1521, G loss: 9.4460\n",
      "[6492/8000] D loss: 0.3517, G loss: 7.1108\n",
      "[6852/8000] D loss: 0.0140, G loss: 10.3713\n",
      "[7212/8000] D loss: 0.0732, G loss: 7.9364\n",
      "[7572/8000] D loss: 0.1769, G loss: 9.9238\n",
      "[7932/8000] D loss: 0.1447, G loss: 10.7064\n",
      "train error: \n",
      " D loss: 0.240225, G loss: 10.207636, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.518407, G loss: 13.274813, D accuracy: 93.8%, cell accuracy: 94.0%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1323, G loss: 11.9084\n",
      "[372/8000] D loss: 0.2549, G loss: 4.8560\n",
      "[732/8000] D loss: 0.3418, G loss: 12.2044\n",
      "[1092/8000] D loss: 0.2125, G loss: 7.7689\n",
      "[1452/8000] D loss: 0.3562, G loss: 8.8147\n",
      "[1812/8000] D loss: 0.0211, G loss: 13.3908\n",
      "[2172/8000] D loss: 0.3430, G loss: 7.9503\n",
      "[2532/8000] D loss: 0.0567, G loss: 11.0795\n",
      "[2892/8000] D loss: 0.0419, G loss: 9.6005\n",
      "[3252/8000] D loss: 0.4325, G loss: 9.8654\n",
      "[3612/8000] D loss: 0.0375, G loss: 10.1269\n",
      "[3972/8000] D loss: 0.3587, G loss: 7.0134\n",
      "[4332/8000] D loss: 0.0044, G loss: 10.3571\n",
      "[4692/8000] D loss: 0.5332, G loss: 6.7914\n",
      "[5052/8000] D loss: 0.2533, G loss: 12.1513\n",
      "[5412/8000] D loss: 0.1411, G loss: 10.6386\n",
      "[5772/8000] D loss: 0.2212, G loss: 8.0304\n",
      "[6132/8000] D loss: 0.7201, G loss: 9.7899\n",
      "[6492/8000] D loss: 0.0856, G loss: 14.6409\n",
      "[6852/8000] D loss: 0.0163, G loss: 14.5861\n",
      "[7212/8000] D loss: 0.3994, G loss: 8.1158\n",
      "[7572/8000] D loss: 0.0730, G loss: 11.6304\n",
      "[7932/8000] D loss: 0.1999, G loss: 10.4146\n",
      "train error: \n",
      " D loss: 0.238185, G loss: 11.249458, D accuracy: 93.9%, cell accuracy: 94.3%, board accuracy: 9.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.575533, G loss: 14.461851, D accuracy: 93.7%, cell accuracy: 93.9%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3034, G loss: 9.7395\n",
      "[372/8000] D loss: 0.2605, G loss: 10.6095\n",
      "[732/8000] D loss: 0.1687, G loss: 8.1925\n",
      "[1092/8000] D loss: 0.2135, G loss: 10.2439\n",
      "[1452/8000] D loss: 0.0376, G loss: 10.9405\n",
      "[1812/8000] D loss: 0.5130, G loss: 8.0459\n",
      "[2172/8000] D loss: 0.1354, G loss: 12.1593\n",
      "[2532/8000] D loss: 0.1052, G loss: 10.9512\n",
      "[2892/8000] D loss: 0.0684, G loss: 7.4774\n",
      "[3252/8000] D loss: 0.1904, G loss: 6.7189\n",
      "[3612/8000] D loss: 0.3126, G loss: 8.0135\n",
      "[3972/8000] D loss: 0.1700, G loss: 10.6386\n",
      "[4332/8000] D loss: 0.1325, G loss: 11.2817\n",
      "[4692/8000] D loss: 0.1671, G loss: 11.0348\n",
      "[5052/8000] D loss: 0.3268, G loss: 9.3262\n",
      "[5412/8000] D loss: 0.3622, G loss: 11.5058\n",
      "[5772/8000] D loss: 0.4665, G loss: 7.8678\n",
      "[6132/8000] D loss: 0.1855, G loss: 9.0243\n",
      "[6492/8000] D loss: 0.0117, G loss: 12.9580\n",
      "[6852/8000] D loss: 0.3999, G loss: 5.7219\n",
      "[7212/8000] D loss: 0.1628, G loss: 10.2797\n",
      "[7572/8000] D loss: 0.2456, G loss: 8.5631\n",
      "[7932/8000] D loss: 0.0812, G loss: 12.4611\n",
      "train error: \n",
      " D loss: 0.212189, G loss: 10.020327, D accuracy: 94.4%, cell accuracy: 94.4%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.414858, G loss: 13.126172, D accuracy: 94.5%, cell accuracy: 94.0%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2551, G loss: 8.0947\n",
      "[372/8000] D loss: 0.1816, G loss: 10.5213\n",
      "[732/8000] D loss: 0.3993, G loss: 7.5048\n",
      "[1092/8000] D loss: 0.2587, G loss: 8.4617\n",
      "[1452/8000] D loss: 0.4883, G loss: 7.9901\n",
      "[1812/8000] D loss: 0.1294, G loss: 12.8282\n",
      "[2172/8000] D loss: 0.2155, G loss: 12.3192\n",
      "[2532/8000] D loss: 0.3299, G loss: 14.2012\n",
      "[2892/8000] D loss: 0.3639, G loss: 11.0683\n",
      "[3252/8000] D loss: 0.2009, G loss: 10.0424\n",
      "[3612/8000] D loss: 0.2370, G loss: 8.2620\n",
      "[3972/8000] D loss: 0.0597, G loss: 10.5777\n",
      "[4332/8000] D loss: 0.2994, G loss: 8.6337\n",
      "[4692/8000] D loss: 0.3207, G loss: 7.0313\n",
      "[5052/8000] D loss: 0.1454, G loss: 9.5526\n",
      "[5412/8000] D loss: 0.2109, G loss: 7.2869\n",
      "[5772/8000] D loss: 0.2636, G loss: 9.7860\n",
      "[6132/8000] D loss: 0.0669, G loss: 9.2128\n",
      "[6492/8000] D loss: 0.7038, G loss: 10.2203\n",
      "[6852/8000] D loss: 0.0031, G loss: 13.3860\n",
      "[7212/8000] D loss: 0.2040, G loss: 10.6564\n",
      "[7572/8000] D loss: 0.0088, G loss: 11.3426\n",
      "[7932/8000] D loss: 0.0871, G loss: 14.3978\n",
      "train error: \n",
      " D loss: 0.213306, G loss: 10.572727, D accuracy: 94.4%, cell accuracy: 94.3%, board accuracy: 9.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.495862, G loss: 13.535037, D accuracy: 93.7%, cell accuracy: 94.0%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3082, G loss: 6.5747\n",
      "[372/8000] D loss: 0.6028, G loss: 9.6696\n",
      "[732/8000] D loss: 0.2076, G loss: 8.5539\n",
      "[1092/8000] D loss: 0.4269, G loss: 8.6822\n",
      "[1452/8000] D loss: 0.3267, G loss: 12.7951\n",
      "[1812/8000] D loss: 0.1299, G loss: 11.9685\n",
      "[2172/8000] D loss: 0.1418, G loss: 9.9348\n",
      "[2532/8000] D loss: 0.2067, G loss: 9.4579\n",
      "[2892/8000] D loss: 0.1447, G loss: 8.2461\n",
      "[3252/8000] D loss: 0.6152, G loss: 11.1207\n",
      "[3612/8000] D loss: 0.2552, G loss: 10.8234\n",
      "[3972/8000] D loss: 0.3465, G loss: 7.5974\n",
      "[4332/8000] D loss: 0.1399, G loss: 10.8748\n",
      "[4692/8000] D loss: 0.3086, G loss: 10.6977\n",
      "[5052/8000] D loss: 0.0857, G loss: 8.3592\n",
      "[5412/8000] D loss: 0.0136, G loss: 10.0278\n",
      "[5772/8000] D loss: 0.2071, G loss: 9.7827\n",
      "[6132/8000] D loss: 0.3691, G loss: 8.9320\n",
      "[6492/8000] D loss: 0.0182, G loss: 9.8678\n",
      "[6852/8000] D loss: 0.0775, G loss: 10.9437\n",
      "[7212/8000] D loss: 0.2899, G loss: 9.0915\n",
      "[7572/8000] D loss: 0.1365, G loss: 10.8185\n",
      "[7932/8000] D loss: 0.0370, G loss: 8.5764\n",
      "train error: \n",
      " D loss: 0.211033, G loss: 10.702180, D accuracy: 94.3%, cell accuracy: 94.4%, board accuracy: 9.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.491004, G loss: 13.635384, D accuracy: 93.7%, cell accuracy: 94.0%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3423, G loss: 10.1495\n",
      "[372/8000] D loss: 0.0342, G loss: 12.6823\n",
      "[732/8000] D loss: 0.1860, G loss: 14.1195\n",
      "[1092/8000] D loss: 0.0847, G loss: 11.7437\n",
      "[1452/8000] D loss: 0.2210, G loss: 9.9629\n",
      "[1812/8000] D loss: 0.6372, G loss: 5.8987\n",
      "[2172/8000] D loss: 0.1697, G loss: 10.6316\n",
      "[2532/8000] D loss: 0.2820, G loss: 10.8926\n",
      "[2892/8000] D loss: 0.3631, G loss: 8.1642\n",
      "[3252/8000] D loss: 0.0680, G loss: 10.2135\n",
      "[3612/8000] D loss: 0.7568, G loss: 5.8829\n",
      "[3972/8000] D loss: 0.0235, G loss: 11.7765\n",
      "[4332/8000] D loss: 0.2043, G loss: 11.8344\n",
      "[4692/8000] D loss: 0.2682, G loss: 7.4811\n",
      "[5052/8000] D loss: 0.2416, G loss: 9.9658\n",
      "[5412/8000] D loss: 0.3754, G loss: 7.3714\n",
      "[5772/8000] D loss: 0.2558, G loss: 9.9473\n",
      "[6132/8000] D loss: 0.1850, G loss: 11.2410\n",
      "[6492/8000] D loss: 0.0151, G loss: 9.8668\n",
      "[6852/8000] D loss: 0.5320, G loss: 7.5685\n",
      "[7212/8000] D loss: 0.5584, G loss: 10.9598\n",
      "[7572/8000] D loss: 0.2574, G loss: 10.7905\n",
      "[7932/8000] D loss: 0.2880, G loss: 8.8975\n",
      "train error: \n",
      " D loss: 0.210121, G loss: 11.044812, D accuracy: 94.3%, cell accuracy: 94.3%, board accuracy: 9.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.552158, G loss: 14.185524, D accuracy: 93.0%, cell accuracy: 93.9%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1465, G loss: 12.1306\n",
      "[372/8000] D loss: 0.3675, G loss: 10.2931\n",
      "[732/8000] D loss: 0.1416, G loss: 10.9748\n",
      "[1092/8000] D loss: 0.2498, G loss: 7.2480\n",
      "[1452/8000] D loss: 0.1028, G loss: 11.6650\n",
      "[1812/8000] D loss: 0.1700, G loss: 8.7290\n",
      "[2172/8000] D loss: 0.3008, G loss: 10.3389\n",
      "[2532/8000] D loss: 0.1655, G loss: 11.9659\n",
      "[2892/8000] D loss: 0.2297, G loss: 10.0917\n",
      "[3252/8000] D loss: 0.2028, G loss: 9.3931\n",
      "[3612/8000] D loss: 0.1196, G loss: 7.6184\n",
      "[3972/8000] D loss: 0.3702, G loss: 9.7824\n",
      "[4332/8000] D loss: 0.1194, G loss: 10.6808\n",
      "[4692/8000] D loss: 0.3677, G loss: 9.7233\n",
      "[5052/8000] D loss: 0.5079, G loss: 7.4620\n",
      "[5412/8000] D loss: 0.1458, G loss: 8.9380\n",
      "[5772/8000] D loss: 0.1286, G loss: 9.2937\n",
      "[6132/8000] D loss: 0.2990, G loss: 9.2056\n",
      "[6492/8000] D loss: 0.1407, G loss: 9.9194\n",
      "[6852/8000] D loss: 0.2501, G loss: 10.8191\n",
      "[7212/8000] D loss: 0.2139, G loss: 10.0948\n",
      "[7572/8000] D loss: 0.1432, G loss: 8.5500\n",
      "[7932/8000] D loss: 0.5172, G loss: 9.8463\n",
      "train error: \n",
      " D loss: 0.213940, G loss: 9.851446, D accuracy: 94.3%, cell accuracy: 94.4%, board accuracy: 9.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.481064, G loss: 13.000043, D accuracy: 94.1%, cell accuracy: 94.0%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3482, G loss: 7.1132\n",
      "[372/8000] D loss: 0.3787, G loss: 13.1246\n",
      "[732/8000] D loss: 0.1780, G loss: 9.1325\n",
      "[1092/8000] D loss: 0.3904, G loss: 7.2035\n",
      "[1452/8000] D loss: 0.2272, G loss: 9.0810\n",
      "[1812/8000] D loss: 0.2510, G loss: 10.4962\n",
      "[2172/8000] D loss: 0.2300, G loss: 11.8640\n",
      "[2532/8000] D loss: 0.0143, G loss: 13.0477\n",
      "[2892/8000] D loss: 0.2733, G loss: 8.2267\n",
      "[3252/8000] D loss: 0.2442, G loss: 7.6260\n",
      "[3612/8000] D loss: 0.3033, G loss: 9.3598\n",
      "[3972/8000] D loss: 0.2429, G loss: 9.3389\n",
      "[4332/8000] D loss: 0.0124, G loss: 10.8033\n",
      "[4692/8000] D loss: 0.1712, G loss: 9.6560\n",
      "[5052/8000] D loss: 0.0908, G loss: 6.7318\n",
      "[5412/8000] D loss: 0.1114, G loss: 9.7482\n",
      "[5772/8000] D loss: 0.0136, G loss: 10.4106\n",
      "[6132/8000] D loss: 0.0118, G loss: 13.4268\n",
      "[6492/8000] D loss: 0.1229, G loss: 9.4448\n",
      "[6852/8000] D loss: 0.1263, G loss: 12.5814\n",
      "[7212/8000] D loss: 0.2495, G loss: 11.4089\n",
      "[7572/8000] D loss: 0.1273, G loss: 10.9269\n",
      "[7932/8000] D loss: 0.0475, G loss: 9.1900\n",
      "train error: \n",
      " D loss: 0.213822, G loss: 8.548768, D accuracy: 94.3%, cell accuracy: 94.3%, board accuracy: 9.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.421947, G loss: 11.435811, D accuracy: 94.3%, cell accuracy: 94.0%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1078, G loss: 9.5005\n",
      "[372/8000] D loss: 0.1765, G loss: 11.4839\n",
      "[732/8000] D loss: 0.0656, G loss: 13.5492\n",
      "[1092/8000] D loss: 0.1317, G loss: 11.3115\n",
      "[1452/8000] D loss: 0.2193, G loss: 10.8958\n",
      "[1812/8000] D loss: 0.0136, G loss: 13.4636\n",
      "[2172/8000] D loss: 0.2799, G loss: 9.7688\n",
      "[2532/8000] D loss: 0.0208, G loss: 12.0046\n",
      "[2892/8000] D loss: 0.2079, G loss: 9.4336\n",
      "[3252/8000] D loss: 0.1005, G loss: 10.8294\n",
      "[3612/8000] D loss: 0.0244, G loss: 9.9984\n",
      "[3972/8000] D loss: 0.4532, G loss: 9.5616\n",
      "[4332/8000] D loss: 0.3636, G loss: 10.3753\n",
      "[4692/8000] D loss: 0.2767, G loss: 12.4649\n",
      "[5052/8000] D loss: 0.4387, G loss: 10.4427\n",
      "[5412/8000] D loss: 0.1402, G loss: 11.0448\n",
      "[5772/8000] D loss: 0.3598, G loss: 9.6240\n",
      "[6132/8000] D loss: 0.2826, G loss: 11.7139\n",
      "[6492/8000] D loss: 0.2118, G loss: 9.4829\n",
      "[6852/8000] D loss: 0.1435, G loss: 7.9572\n",
      "[7212/8000] D loss: 0.0264, G loss: 10.4697\n",
      "[7572/8000] D loss: 0.3686, G loss: 7.6005\n",
      "[7932/8000] D loss: 0.1456, G loss: 10.4364\n",
      "train error: \n",
      " D loss: 0.207512, G loss: 9.498951, D accuracy: 94.4%, cell accuracy: 94.4%, board accuracy: 9.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.464213, G loss: 12.370660, D accuracy: 93.5%, cell accuracy: 94.0%, board accuracy: 3.7% \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1208, G loss: 7.8758\n",
      "[372/8000] D loss: 0.0645, G loss: 11.7124\n",
      "[732/8000] D loss: 0.0520, G loss: 11.4097\n",
      "[1092/8000] D loss: 0.3396, G loss: 9.7606\n",
      "[1452/8000] D loss: 0.3411, G loss: 8.2151\n",
      "[1812/8000] D loss: 0.4754, G loss: 6.8192\n",
      "[2172/8000] D loss: 0.2946, G loss: 11.2648\n",
      "[2532/8000] D loss: 0.1440, G loss: 8.8139\n",
      "[2892/8000] D loss: 0.1377, G loss: 9.6485\n",
      "[3252/8000] D loss: 0.3874, G loss: 12.2974\n",
      "[3612/8000] D loss: 0.1283, G loss: 9.5132\n",
      "[3972/8000] D loss: 0.2786, G loss: 9.8727\n",
      "[4332/8000] D loss: 0.2690, G loss: 10.3517\n",
      "[4692/8000] D loss: 0.2352, G loss: 11.7697\n",
      "[5052/8000] D loss: 0.1999, G loss: 9.6404\n",
      "[5412/8000] D loss: 0.3057, G loss: 10.1419\n",
      "[5772/8000] D loss: 0.3016, G loss: 9.8413\n",
      "[6132/8000] D loss: 0.1214, G loss: 10.5739\n",
      "[6492/8000] D loss: 0.2116, G loss: 10.0999\n",
      "[6852/8000] D loss: 0.1169, G loss: 12.1946\n",
      "[7212/8000] D loss: 0.1631, G loss: 6.4400\n",
      "[7572/8000] D loss: 0.1878, G loss: 10.6537\n",
      "[7932/8000] D loss: 0.1256, G loss: 10.5700\n",
      "train error: \n",
      " D loss: 0.218625, G loss: 9.827673, D accuracy: 94.4%, cell accuracy: 94.4%, board accuracy: 9.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.457390, G loss: 12.802865, D accuracy: 94.3%, cell accuracy: 94.0%, board accuracy: 3.9% \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2011, G loss: 7.9332\n",
      "[372/8000] D loss: 0.1797, G loss: 11.6997\n",
      "[732/8000] D loss: 0.2226, G loss: 10.0544\n",
      "[1092/8000] D loss: 0.0329, G loss: 13.6984\n",
      "[1452/8000] D loss: 0.1736, G loss: 10.4051\n",
      "[1812/8000] D loss: 0.0042, G loss: 10.9733\n",
      "[2172/8000] D loss: 0.3219, G loss: 10.4471\n",
      "[2532/8000] D loss: 0.2752, G loss: 6.2211\n",
      "[2892/8000] D loss: 0.2649, G loss: 7.2408\n",
      "[3252/8000] D loss: 0.2643, G loss: 10.3114\n",
      "[3612/8000] D loss: 0.0132, G loss: 13.5576\n",
      "[3972/8000] D loss: 0.2497, G loss: 11.2564\n",
      "[4332/8000] D loss: 0.1198, G loss: 9.6891\n",
      "[4692/8000] D loss: 0.0910, G loss: 12.3241\n",
      "[5052/8000] D loss: 0.2746, G loss: 11.1853\n",
      "[5412/8000] D loss: 0.2441, G loss: 9.3944\n",
      "[5772/8000] D loss: 0.7128, G loss: 8.5930\n",
      "[6132/8000] D loss: 0.1517, G loss: 9.9221\n",
      "[6492/8000] D loss: 0.0091, G loss: 12.7889\n",
      "[6852/8000] D loss: 0.3610, G loss: 14.2167\n",
      "[7212/8000] D loss: 0.0251, G loss: 8.3600\n",
      "[7572/8000] D loss: 0.1448, G loss: 11.7048\n",
      "[7932/8000] D loss: 0.1300, G loss: 13.8484\n",
      "train error: \n",
      " D loss: 0.224168, G loss: 9.778831, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 9.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.439736, G loss: 12.838418, D accuracy: 94.5%, cell accuracy: 94.0%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2160, G loss: 8.5511\n",
      "[372/8000] D loss: 0.5411, G loss: 10.1391\n",
      "[732/8000] D loss: 0.2377, G loss: 6.6267\n",
      "[1092/8000] D loss: 0.4753, G loss: 9.6291\n",
      "[1452/8000] D loss: 0.4160, G loss: 8.1855\n",
      "[1812/8000] D loss: 0.1302, G loss: 10.3618\n",
      "[2172/8000] D loss: 0.2451, G loss: 12.5329\n",
      "[2532/8000] D loss: 0.1474, G loss: 11.0691\n",
      "[2892/8000] D loss: 0.0391, G loss: 10.1565\n",
      "[3252/8000] D loss: 0.1901, G loss: 11.1871\n",
      "[3612/8000] D loss: 0.0194, G loss: 12.6377\n",
      "[3972/8000] D loss: 0.0340, G loss: 10.3551\n",
      "[4332/8000] D loss: 0.0742, G loss: 12.4911\n",
      "[4692/8000] D loss: 0.1295, G loss: 11.4517\n",
      "[5052/8000] D loss: 0.1764, G loss: 13.2584\n",
      "[5412/8000] D loss: 0.1909, G loss: 10.3573\n",
      "[5772/8000] D loss: 0.1121, G loss: 11.3692\n",
      "[6132/8000] D loss: 0.2834, G loss: 8.2815\n",
      "[6492/8000] D loss: 0.1916, G loss: 9.4557\n",
      "[6852/8000] D loss: 0.4986, G loss: 11.4215\n",
      "[7212/8000] D loss: 0.0273, G loss: 11.1735\n",
      "[7572/8000] D loss: 0.3668, G loss: 9.6589\n",
      "[7932/8000] D loss: 0.0587, G loss: 9.1650\n",
      "train error: \n",
      " D loss: 0.213614, G loss: 9.027336, D accuracy: 94.3%, cell accuracy: 94.3%, board accuracy: 9.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.425020, G loss: 11.982401, D accuracy: 93.9%, cell accuracy: 94.0%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4476, G loss: 8.3846\n",
      "[372/8000] D loss: 0.0708, G loss: 11.2242\n",
      "[732/8000] D loss: 0.4053, G loss: 6.9944\n",
      "[1092/8000] D loss: 0.2742, G loss: 9.0529\n",
      "[1452/8000] D loss: 0.0558, G loss: 10.2916\n",
      "[1812/8000] D loss: 0.2397, G loss: 12.1500\n",
      "[2172/8000] D loss: 0.0846, G loss: 10.2170\n",
      "[2532/8000] D loss: 0.4852, G loss: 6.8829\n",
      "[2892/8000] D loss: 0.1519, G loss: 11.5659\n",
      "[3252/8000] D loss: 0.1342, G loss: 9.3304\n",
      "[3612/8000] D loss: 0.4614, G loss: 7.2583\n",
      "[3972/8000] D loss: 0.1065, G loss: 11.0850\n",
      "[4332/8000] D loss: 0.0189, G loss: 10.6356\n",
      "[4692/8000] D loss: 0.0669, G loss: 11.7520\n",
      "[5052/8000] D loss: 0.2014, G loss: 8.0467\n",
      "[5412/8000] D loss: 0.1911, G loss: 9.5325\n",
      "[5772/8000] D loss: 0.3424, G loss: 7.0195\n",
      "[6132/8000] D loss: 0.1366, G loss: 7.9875\n",
      "[6492/8000] D loss: 0.1523, G loss: 10.3289\n",
      "[6852/8000] D loss: 0.3571, G loss: 12.3440\n",
      "[7212/8000] D loss: 0.2840, G loss: 7.6329\n",
      "[7572/8000] D loss: 0.1619, G loss: 6.9434\n",
      "[7932/8000] D loss: 0.3592, G loss: 9.4505\n",
      "train error: \n",
      " D loss: 0.209253, G loss: 10.836574, D accuracy: 94.4%, cell accuracy: 94.3%, board accuracy: 9.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.533575, G loss: 13.919456, D accuracy: 93.0%, cell accuracy: 93.9%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2729, G loss: 11.3461\n",
      "[372/8000] D loss: 0.8715, G loss: 7.3498\n",
      "[732/8000] D loss: 0.4654, G loss: 7.9668\n",
      "[1092/8000] D loss: 0.0372, G loss: 8.1771\n",
      "[1452/8000] D loss: 0.0397, G loss: 7.0863\n",
      "[1812/8000] D loss: 0.5346, G loss: 7.1142\n",
      "[2172/8000] D loss: 0.1776, G loss: 11.0387\n",
      "[2532/8000] D loss: 0.0699, G loss: 13.7867\n",
      "[2892/8000] D loss: 0.0148, G loss: 11.3059\n",
      "[3252/8000] D loss: 0.0664, G loss: 17.5263\n",
      "[3612/8000] D loss: 0.2811, G loss: 8.0686\n",
      "[3972/8000] D loss: 0.1167, G loss: 12.1708\n",
      "[4332/8000] D loss: 0.2345, G loss: 8.3718\n",
      "[4692/8000] D loss: 0.1442, G loss: 12.8526\n",
      "[5052/8000] D loss: 0.3635, G loss: 9.8088\n",
      "[5412/8000] D loss: 0.0693, G loss: 8.4474\n",
      "[5772/8000] D loss: 0.4277, G loss: 9.3248\n",
      "[6132/8000] D loss: 0.5121, G loss: 8.9692\n",
      "[6492/8000] D loss: 0.1832, G loss: 7.7819\n",
      "[6852/8000] D loss: 0.4785, G loss: 11.1687\n",
      "[7212/8000] D loss: 0.4486, G loss: 6.9614\n",
      "[7572/8000] D loss: 0.1235, G loss: 8.6376\n",
      "[7932/8000] D loss: 0.1706, G loss: 8.4424\n",
      "train error: \n",
      " D loss: 0.200053, G loss: 9.745483, D accuracy: 94.8%, cell accuracy: 94.3%, board accuracy: 9.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.453930, G loss: 12.910629, D accuracy: 94.1%, cell accuracy: 93.9%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3439, G loss: 9.7118\n",
      "[372/8000] D loss: 0.0592, G loss: 11.6905\n",
      "[732/8000] D loss: 0.2136, G loss: 13.0153\n",
      "[1092/8000] D loss: 0.1615, G loss: 9.4645\n",
      "[1452/8000] D loss: 0.2045, G loss: 9.5264\n",
      "[1812/8000] D loss: 0.1349, G loss: 10.5273\n",
      "[2172/8000] D loss: 0.0185, G loss: 12.3877\n",
      "[2532/8000] D loss: 0.3411, G loss: 13.3883\n",
      "[2892/8000] D loss: 0.2979, G loss: 6.9689\n",
      "[3252/8000] D loss: 0.2459, G loss: 8.2547\n",
      "[3612/8000] D loss: 0.1131, G loss: 9.7224\n",
      "[3972/8000] D loss: 0.3814, G loss: 12.8895\n",
      "[4332/8000] D loss: 0.0910, G loss: 16.1935\n",
      "[4692/8000] D loss: 0.0919, G loss: 11.1198\n",
      "[5052/8000] D loss: 0.1725, G loss: 13.1806\n",
      "[5412/8000] D loss: 0.0337, G loss: 11.0532\n",
      "[5772/8000] D loss: 0.2664, G loss: 10.6737\n",
      "[6132/8000] D loss: 0.1283, G loss: 8.8425\n",
      "[6492/8000] D loss: 0.2760, G loss: 9.5657\n",
      "[6852/8000] D loss: 0.1011, G loss: 11.0181\n",
      "[7212/8000] D loss: 0.1774, G loss: 6.0004\n",
      "[7572/8000] D loss: 0.0298, G loss: 9.8250\n",
      "[7932/8000] D loss: 0.1504, G loss: 8.4946\n",
      "train error: \n",
      " D loss: 0.232868, G loss: 8.975322, D accuracy: 93.7%, cell accuracy: 94.3%, board accuracy: 9.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.440446, G loss: 11.998311, D accuracy: 93.8%, cell accuracy: 93.9%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0117, G loss: 13.2742\n",
      "[372/8000] D loss: 0.1244, G loss: 9.8739\n",
      "[732/8000] D loss: 0.4134, G loss: 11.1798\n",
      "[1092/8000] D loss: 0.0080, G loss: 11.3231\n",
      "[1452/8000] D loss: 0.2400, G loss: 9.7599\n",
      "[1812/8000] D loss: 0.5158, G loss: 9.1556\n",
      "[2172/8000] D loss: 0.2894, G loss: 8.6546\n",
      "[2532/8000] D loss: 0.1268, G loss: 10.8001\n",
      "[2892/8000] D loss: 0.1405, G loss: 13.9294\n",
      "[3252/8000] D loss: 0.0036, G loss: 9.3498\n",
      "[3612/8000] D loss: 0.1317, G loss: 11.9360\n",
      "[3972/8000] D loss: 0.2207, G loss: 5.8004\n",
      "[4332/8000] D loss: 0.2622, G loss: 9.9162\n",
      "[4692/8000] D loss: 0.2294, G loss: 8.5244\n",
      "[5052/8000] D loss: 0.2079, G loss: 14.8916\n",
      "[5412/8000] D loss: 0.3454, G loss: 12.8141\n",
      "[5772/8000] D loss: 0.3783, G loss: 6.1951\n",
      "[6132/8000] D loss: 0.4907, G loss: 7.7439\n",
      "[6492/8000] D loss: 0.1414, G loss: 6.8124\n",
      "[6852/8000] D loss: 0.3402, G loss: 7.5555\n",
      "[7212/8000] D loss: 0.5009, G loss: 8.3410\n",
      "[7572/8000] D loss: 0.2490, G loss: 11.9674\n",
      "[7932/8000] D loss: 0.1227, G loss: 10.9520\n",
      "train error: \n",
      " D loss: 0.211639, G loss: 10.170195, D accuracy: 94.2%, cell accuracy: 94.3%, board accuracy: 9.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.491465, G loss: 13.317634, D accuracy: 93.8%, cell accuracy: 94.0%, board accuracy: 3.7% \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0312, G loss: 11.4073\n",
      "[372/8000] D loss: 0.1607, G loss: 13.1094\n",
      "[732/8000] D loss: 0.3681, G loss: 4.8921\n",
      "[1092/8000] D loss: 0.0283, G loss: 12.3339\n",
      "[1452/8000] D loss: 0.1195, G loss: 10.8069\n",
      "[1812/8000] D loss: 0.2021, G loss: 7.7933\n",
      "[2172/8000] D loss: 0.1440, G loss: 9.8401\n",
      "[2532/8000] D loss: 0.1990, G loss: 11.1646\n",
      "[2892/8000] D loss: 0.2001, G loss: 14.0022\n",
      "[3252/8000] D loss: 0.0184, G loss: 10.0199\n",
      "[3612/8000] D loss: 0.1573, G loss: 7.2071\n",
      "[3972/8000] D loss: 0.2316, G loss: 10.4643\n",
      "[4332/8000] D loss: 0.1200, G loss: 9.9891\n",
      "[4692/8000] D loss: 0.1128, G loss: 7.9869\n",
      "[5052/8000] D loss: 0.2096, G loss: 9.9746\n",
      "[5412/8000] D loss: 0.1482, G loss: 10.7306\n",
      "[5772/8000] D loss: 0.1774, G loss: 7.2391\n",
      "[6132/8000] D loss: 0.0772, G loss: 11.1269\n",
      "[6492/8000] D loss: 0.1720, G loss: 12.0453\n",
      "[6852/8000] D loss: 0.1223, G loss: 9.7191\n",
      "[7212/8000] D loss: 0.3450, G loss: 8.2161\n",
      "[7572/8000] D loss: 0.1714, G loss: 9.1992\n",
      "[7932/8000] D loss: 0.0835, G loss: 9.0927\n",
      "train error: \n",
      " D loss: 0.235020, G loss: 8.568771, D accuracy: 93.9%, cell accuracy: 94.3%, board accuracy: 9.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.404562, G loss: 11.525293, D accuracy: 94.8%, cell accuracy: 94.0%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0470, G loss: 10.3877\n",
      "[372/8000] D loss: 0.0992, G loss: 12.2991\n",
      "[732/8000] D loss: 0.1625, G loss: 11.4566\n",
      "[1092/8000] D loss: 0.0948, G loss: 10.2366\n",
      "[1452/8000] D loss: 0.0443, G loss: 8.4884\n",
      "[1812/8000] D loss: 0.0835, G loss: 11.6084\n",
      "[2172/8000] D loss: 0.3686, G loss: 9.6840\n",
      "[2532/8000] D loss: 0.8325, G loss: 5.2612\n",
      "[2892/8000] D loss: 0.1273, G loss: 11.0916\n",
      "[3252/8000] D loss: 0.2713, G loss: 6.9263\n",
      "[3612/8000] D loss: 0.1758, G loss: 11.1507\n",
      "[3972/8000] D loss: 0.2368, G loss: 9.6395\n",
      "[4332/8000] D loss: 0.0391, G loss: 7.7037\n",
      "[4692/8000] D loss: 0.0096, G loss: 10.2365\n",
      "[5052/8000] D loss: 0.0335, G loss: 10.5557\n",
      "[5412/8000] D loss: 0.4045, G loss: 7.1353\n",
      "[5772/8000] D loss: 0.2006, G loss: 11.4499\n",
      "[6132/8000] D loss: 0.0248, G loss: 9.3865\n",
      "[6492/8000] D loss: 0.1551, G loss: 11.1046\n",
      "[6852/8000] D loss: 0.1576, G loss: 11.5590\n",
      "[7212/8000] D loss: 0.0326, G loss: 9.8768\n",
      "[7572/8000] D loss: 0.1212, G loss: 7.6161\n",
      "[7932/8000] D loss: 0.2865, G loss: 11.1280\n",
      "train error: \n",
      " D loss: 0.215357, G loss: 10.227964, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 9.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.455884, G loss: 13.281080, D accuracy: 94.0%, cell accuracy: 94.0%, board accuracy: 4.3% \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1600, G loss: 9.8905\n",
      "[372/8000] D loss: 0.2036, G loss: 9.3882\n",
      "[732/8000] D loss: 0.3155, G loss: 6.8885\n",
      "[1092/8000] D loss: 0.1554, G loss: 7.1605\n",
      "[1452/8000] D loss: 0.0803, G loss: 9.9894\n",
      "[1812/8000] D loss: 0.2502, G loss: 12.3752\n",
      "[2172/8000] D loss: 0.1326, G loss: 12.2187\n",
      "[2532/8000] D loss: 0.3236, G loss: 10.4476\n",
      "[2892/8000] D loss: 0.1304, G loss: 11.4918\n",
      "[3252/8000] D loss: 0.1324, G loss: 7.4545\n",
      "[3612/8000] D loss: 0.1026, G loss: 9.4947\n",
      "[3972/8000] D loss: 0.1511, G loss: 10.2532\n",
      "[4332/8000] D loss: 0.4667, G loss: 8.9041\n",
      "[4692/8000] D loss: 0.2635, G loss: 9.6270\n",
      "[5052/8000] D loss: 0.2278, G loss: 10.1834\n",
      "[5412/8000] D loss: 0.2772, G loss: 10.0580\n",
      "[5772/8000] D loss: 0.5316, G loss: 7.9569\n",
      "[6132/8000] D loss: 0.5901, G loss: 7.5533\n",
      "[6492/8000] D loss: 0.0051, G loss: 12.1220\n",
      "[6852/8000] D loss: 0.2884, G loss: 12.8904\n",
      "[7212/8000] D loss: 0.5292, G loss: 8.4475\n",
      "[7572/8000] D loss: 0.0031, G loss: 10.4054\n",
      "[7932/8000] D loss: 0.2334, G loss: 11.2170\n",
      "train error: \n",
      " D loss: 0.226103, G loss: 9.412826, D accuracy: 94.0%, cell accuracy: 94.4%, board accuracy: 9.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.434374, G loss: 12.514206, D accuracy: 94.6%, cell accuracy: 94.0%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2937, G loss: 10.3093\n",
      "[372/8000] D loss: 0.0146, G loss: 13.5106\n",
      "[732/8000] D loss: 0.2077, G loss: 8.4849\n",
      "[1092/8000] D loss: 0.3030, G loss: 12.3806\n",
      "[1452/8000] D loss: 0.0406, G loss: 13.0778\n",
      "[1812/8000] D loss: 0.0049, G loss: 11.9507\n",
      "[2172/8000] D loss: 0.3405, G loss: 8.8499\n",
      "[2532/8000] D loss: 0.0056, G loss: 14.6604\n",
      "[2892/8000] D loss: 0.4249, G loss: 12.4687\n",
      "[3252/8000] D loss: 0.2309, G loss: 12.6979\n",
      "[3612/8000] D loss: 0.2087, G loss: 9.9006\n",
      "[3972/8000] D loss: 0.2783, G loss: 8.1436\n",
      "[4332/8000] D loss: 0.5147, G loss: 8.8364\n",
      "[4692/8000] D loss: 0.1124, G loss: 11.9818\n",
      "[5052/8000] D loss: 0.5153, G loss: 4.3756\n",
      "[5412/8000] D loss: 0.1709, G loss: 10.8917\n",
      "[5772/8000] D loss: 0.0055, G loss: 10.2393\n",
      "[6132/8000] D loss: 0.2363, G loss: 10.9721\n",
      "[6492/8000] D loss: 0.0023, G loss: 13.1803\n",
      "[6852/8000] D loss: 0.3216, G loss: 6.7921\n",
      "[7212/8000] D loss: 0.2245, G loss: 7.1083\n",
      "[7572/8000] D loss: 0.2624, G loss: 9.9441\n",
      "[7932/8000] D loss: 0.1085, G loss: 9.2687\n",
      "train error: \n",
      " D loss: 0.212880, G loss: 9.726487, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 9.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.430440, G loss: 12.890141, D accuracy: 94.1%, cell accuracy: 94.0%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1100, G loss: 12.3601\n",
      "[372/8000] D loss: 0.0703, G loss: 8.6426\n",
      "[732/8000] D loss: 0.1902, G loss: 12.1436\n",
      "[1092/8000] D loss: 0.0047, G loss: 11.9176\n",
      "[1452/8000] D loss: 0.1528, G loss: 9.1760\n",
      "[1812/8000] D loss: 0.3546, G loss: 9.3788\n",
      "[2172/8000] D loss: 0.7252, G loss: 6.3606\n",
      "[2532/8000] D loss: 0.2770, G loss: 7.9534\n",
      "[2892/8000] D loss: 0.0126, G loss: 11.9694\n",
      "[3252/8000] D loss: 0.1299, G loss: 7.0573\n",
      "[3612/8000] D loss: 0.0093, G loss: 13.2763\n",
      "[3972/8000] D loss: 0.0102, G loss: 11.9099\n",
      "[4332/8000] D loss: 0.4080, G loss: 9.8652\n",
      "[4692/8000] D loss: 0.5435, G loss: 6.9651\n",
      "[5052/8000] D loss: 0.1870, G loss: 10.5483\n",
      "[5412/8000] D loss: 0.2751, G loss: 9.3035\n",
      "[5772/8000] D loss: 0.0106, G loss: 10.6976\n",
      "[6132/8000] D loss: 0.0969, G loss: 9.8940\n",
      "[6492/8000] D loss: 0.1889, G loss: 9.4056\n",
      "[6852/8000] D loss: 0.4654, G loss: 7.2491\n",
      "[7212/8000] D loss: 0.5867, G loss: 8.1448\n",
      "[7572/8000] D loss: 0.0073, G loss: 11.3344\n",
      "[7932/8000] D loss: 0.1859, G loss: 8.9478\n",
      "train error: \n",
      " D loss: 0.243234, G loss: 9.841661, D accuracy: 93.6%, cell accuracy: 94.4%, board accuracy: 9.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.541496, G loss: 12.744578, D accuracy: 92.1%, cell accuracy: 94.0%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1470, G loss: 11.5679\n",
      "[372/8000] D loss: 0.3696, G loss: 9.1432\n",
      "[732/8000] D loss: 0.3366, G loss: 9.5034\n",
      "[1092/8000] D loss: 0.3039, G loss: 8.1216\n",
      "[1452/8000] D loss: 0.0332, G loss: 10.2292\n",
      "[1812/8000] D loss: 0.2276, G loss: 9.1589\n",
      "[2172/8000] D loss: 0.1182, G loss: 9.6449\n",
      "[2532/8000] D loss: 0.2629, G loss: 9.5125\n",
      "[2892/8000] D loss: 0.0092, G loss: 12.3592\n",
      "[3252/8000] D loss: 0.5011, G loss: 8.8903\n",
      "[3612/8000] D loss: 0.1285, G loss: 9.5975\n",
      "[3972/8000] D loss: 0.0828, G loss: 10.2771\n",
      "[4332/8000] D loss: 0.2942, G loss: 10.4230\n",
      "[4692/8000] D loss: 0.1690, G loss: 10.5031\n",
      "[5052/8000] D loss: 0.4003, G loss: 10.3381\n",
      "[5412/8000] D loss: 0.2787, G loss: 8.3158\n",
      "[5772/8000] D loss: 0.1594, G loss: 12.4758\n",
      "[6132/8000] D loss: 0.0632, G loss: 11.6819\n",
      "[6492/8000] D loss: 0.0144, G loss: 11.1284\n",
      "[6852/8000] D loss: 0.1605, G loss: 7.7850\n",
      "[7212/8000] D loss: 0.1992, G loss: 8.4056\n",
      "[7572/8000] D loss: 0.7061, G loss: 8.1242\n",
      "[7932/8000] D loss: 0.2391, G loss: 11.9167\n",
      "train error: \n",
      " D loss: 0.225228, G loss: 10.043303, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 9.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.489322, G loss: 13.081715, D accuracy: 93.0%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0176, G loss: 10.7672\n",
      "[372/8000] D loss: 0.0245, G loss: 11.3290\n",
      "[732/8000] D loss: 0.3291, G loss: 9.8972\n",
      "[1092/8000] D loss: 0.1298, G loss: 14.0687\n",
      "[1452/8000] D loss: 0.4450, G loss: 7.0056\n",
      "[1812/8000] D loss: 0.0063, G loss: 13.3207\n",
      "[2172/8000] D loss: 0.0688, G loss: 9.2502\n",
      "[2532/8000] D loss: 0.6701, G loss: 5.9627\n",
      "[2892/8000] D loss: 0.0535, G loss: 12.1998\n",
      "[3252/8000] D loss: 0.1923, G loss: 8.6223\n",
      "[3612/8000] D loss: 0.3582, G loss: 7.8550\n",
      "[3972/8000] D loss: 0.3122, G loss: 7.4619\n",
      "[4332/8000] D loss: 0.1561, G loss: 8.6110\n",
      "[4692/8000] D loss: 0.0052, G loss: 13.1332\n",
      "[5052/8000] D loss: 0.1264, G loss: 11.9839\n",
      "[5412/8000] D loss: 0.4620, G loss: 7.6052\n",
      "[5772/8000] D loss: 0.1456, G loss: 11.4522\n",
      "[6132/8000] D loss: 0.0409, G loss: 12.9169\n",
      "[6492/8000] D loss: 0.3991, G loss: 11.4480\n",
      "[6852/8000] D loss: 0.1473, G loss: 9.4129\n",
      "[7212/8000] D loss: 0.1796, G loss: 9.7572\n",
      "[7572/8000] D loss: 0.2622, G loss: 9.1621\n",
      "[7932/8000] D loss: 0.8185, G loss: 8.1150\n",
      "train error: \n",
      " D loss: 0.215637, G loss: 9.964693, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 10.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.457082, G loss: 13.241436, D accuracy: 94.4%, cell accuracy: 94.0%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1624, G loss: 9.3334\n",
      "[372/8000] D loss: 0.0590, G loss: 9.2203\n",
      "[732/8000] D loss: 0.0161, G loss: 8.6240\n",
      "[1092/8000] D loss: 0.3515, G loss: 8.6122\n",
      "[1452/8000] D loss: 0.0485, G loss: 12.5848\n",
      "[1812/8000] D loss: 0.1475, G loss: 10.6821\n",
      "[2172/8000] D loss: 0.2323, G loss: 11.5419\n",
      "[2532/8000] D loss: 0.0060, G loss: 12.5899\n",
      "[2892/8000] D loss: 0.4960, G loss: 8.3501\n",
      "[3252/8000] D loss: 0.1437, G loss: 10.3258\n",
      "[3612/8000] D loss: 0.0228, G loss: 9.8969\n",
      "[3972/8000] D loss: 0.4687, G loss: 8.5144\n",
      "[4332/8000] D loss: 0.0907, G loss: 7.4453\n",
      "[4692/8000] D loss: 0.0157, G loss: 11.8345\n",
      "[5052/8000] D loss: 0.3623, G loss: 8.1666\n",
      "[5412/8000] D loss: 0.1722, G loss: 8.4523\n",
      "[5772/8000] D loss: 0.1671, G loss: 9.0549\n",
      "[6132/8000] D loss: 0.1416, G loss: 8.3885\n",
      "[6492/8000] D loss: 0.0095, G loss: 15.6831\n",
      "[6852/8000] D loss: 0.2831, G loss: 8.5296\n",
      "[7212/8000] D loss: 0.0058, G loss: 13.8078\n",
      "[7572/8000] D loss: 0.0641, G loss: 9.6028\n",
      "[7932/8000] D loss: 0.3010, G loss: 10.3497\n",
      "train error: \n",
      " D loss: 0.220189, G loss: 10.797043, D accuracy: 94.0%, cell accuracy: 94.4%, board accuracy: 10.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.570910, G loss: 13.992052, D accuracy: 92.9%, cell accuracy: 94.0%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1169, G loss: 16.6337\n",
      "[372/8000] D loss: 0.1311, G loss: 9.8873\n",
      "[732/8000] D loss: 0.0622, G loss: 11.5575\n",
      "[1092/8000] D loss: 0.4457, G loss: 9.7559\n",
      "[1452/8000] D loss: 0.1500, G loss: 11.4956\n",
      "[1812/8000] D loss: 0.7743, G loss: 4.4862\n",
      "[2172/8000] D loss: 0.3212, G loss: 12.7824\n",
      "[2532/8000] D loss: 0.6828, G loss: 5.7875\n",
      "[2892/8000] D loss: 0.1118, G loss: 11.9192\n",
      "[3252/8000] D loss: 0.0392, G loss: 10.6802\n",
      "[3612/8000] D loss: 0.1183, G loss: 7.7653\n",
      "[3972/8000] D loss: 0.2910, G loss: 11.7879\n",
      "[4332/8000] D loss: 0.1990, G loss: 11.8895\n",
      "[4692/8000] D loss: 0.2752, G loss: 10.6760\n",
      "[5052/8000] D loss: 0.3062, G loss: 7.4003\n",
      "[5412/8000] D loss: 0.3533, G loss: 8.0277\n",
      "[5772/8000] D loss: 0.2476, G loss: 12.7748\n",
      "[6132/8000] D loss: 0.1831, G loss: 12.1698\n",
      "[6492/8000] D loss: 0.0233, G loss: 12.8403\n",
      "[6852/8000] D loss: 0.5317, G loss: 7.3699\n",
      "[7212/8000] D loss: 0.1630, G loss: 12.6553\n",
      "[7572/8000] D loss: 0.1288, G loss: 9.3198\n",
      "[7932/8000] D loss: 0.3410, G loss: 6.6859\n",
      "train error: \n",
      " D loss: 0.245113, G loss: 10.994847, D accuracy: 93.5%, cell accuracy: 94.4%, board accuracy: 10.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.598382, G loss: 14.277402, D accuracy: 91.7%, cell accuracy: 94.0%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0259, G loss: 14.0808\n",
      "[372/8000] D loss: 0.2477, G loss: 11.1580\n",
      "[732/8000] D loss: 0.2977, G loss: 9.6730\n",
      "[1092/8000] D loss: 0.1718, G loss: 10.3479\n",
      "[1452/8000] D loss: 0.4013, G loss: 10.4908\n",
      "[1812/8000] D loss: 0.2551, G loss: 8.8631\n",
      "[2172/8000] D loss: 0.1148, G loss: 11.6918\n",
      "[2532/8000] D loss: 0.2457, G loss: 11.0201\n",
      "[2892/8000] D loss: 0.2521, G loss: 10.8358\n",
      "[3252/8000] D loss: 0.2589, G loss: 9.8083\n",
      "[3612/8000] D loss: 0.1226, G loss: 13.7066\n",
      "[3972/8000] D loss: 0.1151, G loss: 7.7136\n",
      "[4332/8000] D loss: 0.1461, G loss: 11.4753\n",
      "[4692/8000] D loss: 0.1558, G loss: 10.1459\n",
      "[5052/8000] D loss: 0.6190, G loss: 6.3357\n",
      "[5412/8000] D loss: 0.0027, G loss: 10.4346\n",
      "[5772/8000] D loss: 0.2222, G loss: 12.3149\n",
      "[6132/8000] D loss: 0.2113, G loss: 7.6567\n",
      "[6492/8000] D loss: 0.6437, G loss: 12.8204\n",
      "[6852/8000] D loss: 0.2635, G loss: 7.9303\n",
      "[7212/8000] D loss: 0.3356, G loss: 9.4379\n",
      "[7572/8000] D loss: 0.1069, G loss: 6.1789\n",
      "[7932/8000] D loss: 0.1896, G loss: 6.5982\n",
      "train error: \n",
      " D loss: 0.215245, G loss: 9.640025, D accuracy: 94.1%, cell accuracy: 94.3%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.487744, G loss: 12.649090, D accuracy: 93.2%, cell accuracy: 94.0%, board accuracy: 4.7% \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0416, G loss: 8.6954\n",
      "[372/8000] D loss: 0.1315, G loss: 9.9309\n",
      "[732/8000] D loss: 0.1574, G loss: 11.0445\n",
      "[1092/8000] D loss: 0.0076, G loss: 13.6586\n",
      "[1452/8000] D loss: 0.5469, G loss: 8.2080\n",
      "[1812/8000] D loss: 0.1282, G loss: 11.7481\n",
      "[2172/8000] D loss: 0.0962, G loss: 13.1091\n",
      "[2532/8000] D loss: 0.0930, G loss: 12.2348\n",
      "[2892/8000] D loss: 0.0075, G loss: 12.5239\n",
      "[3252/8000] D loss: 0.0791, G loss: 12.1358\n",
      "[3612/8000] D loss: 0.4066, G loss: 7.6638\n",
      "[3972/8000] D loss: 0.1302, G loss: 8.3821\n",
      "[4332/8000] D loss: 0.0942, G loss: 9.9662\n",
      "[4692/8000] D loss: 0.2264, G loss: 9.5406\n",
      "[5052/8000] D loss: 0.6114, G loss: 8.2790\n",
      "[5412/8000] D loss: 0.1722, G loss: 7.2869\n",
      "[5772/8000] D loss: 0.2531, G loss: 10.9968\n",
      "[6132/8000] D loss: 0.3443, G loss: 8.6664\n",
      "[6492/8000] D loss: 0.0059, G loss: 12.8691\n",
      "[6852/8000] D loss: 0.2597, G loss: 11.0961\n",
      "[7212/8000] D loss: 0.2061, G loss: 10.9317\n",
      "[7572/8000] D loss: 0.2205, G loss: 12.8364\n",
      "[7932/8000] D loss: 0.2253, G loss: 10.5724\n",
      "train error: \n",
      " D loss: 0.205607, G loss: 10.824549, D accuracy: 94.4%, cell accuracy: 94.4%, board accuracy: 10.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.522541, G loss: 14.062221, D accuracy: 93.1%, cell accuracy: 94.0%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1633, G loss: 7.4725\n",
      "[372/8000] D loss: 0.3445, G loss: 6.9433\n",
      "[732/8000] D loss: 0.3735, G loss: 9.4347\n",
      "[1092/8000] D loss: 0.1221, G loss: 10.0342\n",
      "[1452/8000] D loss: 0.2242, G loss: 11.9054\n",
      "[1812/8000] D loss: 0.3365, G loss: 8.8169\n",
      "[2172/8000] D loss: 0.3876, G loss: 7.5683\n",
      "[2532/8000] D loss: 0.0663, G loss: 10.1351\n",
      "[2892/8000] D loss: 0.0389, G loss: 13.2263\n",
      "[3252/8000] D loss: 0.1732, G loss: 11.1647\n",
      "[3612/8000] D loss: 0.3521, G loss: 9.0399\n",
      "[3972/8000] D loss: 0.4635, G loss: 6.3375\n",
      "[4332/8000] D loss: 0.2548, G loss: 9.2370\n",
      "[4692/8000] D loss: 0.3197, G loss: 8.2074\n",
      "[5052/8000] D loss: 0.0306, G loss: 9.7674\n",
      "[5412/8000] D loss: 0.0072, G loss: 11.8636\n",
      "[5772/8000] D loss: 0.1906, G loss: 11.3438\n",
      "[6132/8000] D loss: 0.2554, G loss: 9.9848\n",
      "[6492/8000] D loss: 0.0018, G loss: 17.2214\n",
      "[6852/8000] D loss: 0.1207, G loss: 8.3389\n",
      "[7212/8000] D loss: 0.1509, G loss: 10.6932\n",
      "[7572/8000] D loss: 0.1352, G loss: 8.7623\n",
      "[7932/8000] D loss: 0.3294, G loss: 7.9547\n",
      "train error: \n",
      " D loss: 0.221051, G loss: 10.374592, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 10.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.497481, G loss: 13.685074, D accuracy: 93.1%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0694, G loss: 9.1887\n",
      "[372/8000] D loss: 0.2558, G loss: 8.6866\n",
      "[732/8000] D loss: 0.4724, G loss: 8.7226\n",
      "[1092/8000] D loss: 0.1421, G loss: 12.1379\n",
      "[1452/8000] D loss: 0.2121, G loss: 14.6263\n",
      "[1812/8000] D loss: 0.1247, G loss: 10.2293\n",
      "[2172/8000] D loss: 0.2743, G loss: 9.1648\n",
      "[2532/8000] D loss: 0.2563, G loss: 9.5654\n",
      "[2892/8000] D loss: 0.2511, G loss: 7.3173\n",
      "[3252/8000] D loss: 0.1799, G loss: 9.6093\n",
      "[3612/8000] D loss: 0.1584, G loss: 12.8571\n",
      "[3972/8000] D loss: 0.2463, G loss: 12.4293\n",
      "[4332/8000] D loss: 0.1988, G loss: 11.2788\n",
      "[4692/8000] D loss: 0.5254, G loss: 8.0122\n",
      "[5052/8000] D loss: 0.1314, G loss: 8.9640\n",
      "[5412/8000] D loss: 0.1642, G loss: 11.0753\n",
      "[5772/8000] D loss: 0.3423, G loss: 7.1259\n",
      "[6132/8000] D loss: 0.4172, G loss: 7.3011\n",
      "[6492/8000] D loss: 0.2913, G loss: 11.2197\n",
      "[6852/8000] D loss: 0.2056, G loss: 7.1130\n",
      "[7212/8000] D loss: 0.1868, G loss: 11.7886\n",
      "[7572/8000] D loss: 0.3592, G loss: 10.2475\n",
      "[7932/8000] D loss: 0.5513, G loss: 6.9077\n",
      "train error: \n",
      " D loss: 0.260611, G loss: 13.307206, D accuracy: 93.2%, cell accuracy: 94.4%, board accuracy: 9.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.716988, G loss: 16.814547, D accuracy: 91.5%, cell accuracy: 94.0%, board accuracy: 4.3% \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0061, G loss: 16.3973\n",
      "[372/8000] D loss: 0.1370, G loss: 13.3279\n",
      "[732/8000] D loss: 0.2546, G loss: 8.9563\n",
      "[1092/8000] D loss: 0.0113, G loss: 10.2647\n",
      "[1452/8000] D loss: 0.1504, G loss: 8.6518\n",
      "[1812/8000] D loss: 0.2224, G loss: 8.1827\n",
      "[2172/8000] D loss: 0.1256, G loss: 7.1823\n",
      "[2532/8000] D loss: 0.1013, G loss: 12.5013\n",
      "[2892/8000] D loss: 0.1289, G loss: 14.2160\n",
      "[3252/8000] D loss: 0.0690, G loss: 10.4633\n",
      "[3612/8000] D loss: 0.0962, G loss: 10.4370\n",
      "[3972/8000] D loss: 0.4032, G loss: 10.7118\n",
      "[4332/8000] D loss: 0.0596, G loss: 12.5392\n",
      "[4692/8000] D loss: 0.1547, G loss: 6.9750\n",
      "[5052/8000] D loss: 0.4533, G loss: 11.6576\n",
      "[5412/8000] D loss: 0.2140, G loss: 9.9319\n",
      "[5772/8000] D loss: 0.1462, G loss: 12.2290\n",
      "[6132/8000] D loss: 0.4253, G loss: 8.7623\n",
      "[6492/8000] D loss: 0.0247, G loss: 10.9643\n",
      "[6852/8000] D loss: 0.0279, G loss: 10.1196\n",
      "[7212/8000] D loss: 0.1751, G loss: 7.4392\n",
      "[7572/8000] D loss: 0.2940, G loss: 11.1869\n",
      "[7932/8000] D loss: 0.6315, G loss: 7.7507\n",
      "train error: \n",
      " D loss: 0.210837, G loss: 10.120147, D accuracy: 94.2%, cell accuracy: 94.4%, board accuracy: 10.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.489003, G loss: 13.170502, D accuracy: 93.6%, cell accuracy: 94.0%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1038, G loss: 12.9217\n",
      "[372/8000] D loss: 0.4258, G loss: 7.6465\n",
      "[732/8000] D loss: 0.1754, G loss: 12.9318\n",
      "[1092/8000] D loss: 0.2446, G loss: 9.5956\n",
      "[1452/8000] D loss: 0.5232, G loss: 10.0146\n",
      "[1812/8000] D loss: 0.0082, G loss: 11.6236\n",
      "[2172/8000] D loss: 0.2273, G loss: 8.3515\n",
      "[2532/8000] D loss: 0.0189, G loss: 15.0018\n",
      "[2892/8000] D loss: 0.2381, G loss: 15.9200\n",
      "[3252/8000] D loss: 0.4053, G loss: 9.5382\n",
      "[3612/8000] D loss: 0.4257, G loss: 10.0614\n",
      "[3972/8000] D loss: 0.6421, G loss: 6.3230\n",
      "[4332/8000] D loss: 0.1128, G loss: 14.1748\n",
      "[4692/8000] D loss: 0.1631, G loss: 11.5516\n",
      "[5052/8000] D loss: 0.3967, G loss: 11.2917\n",
      "[5412/8000] D loss: 0.1985, G loss: 11.3228\n",
      "[5772/8000] D loss: 0.2583, G loss: 8.5502\n",
      "[6132/8000] D loss: 0.2555, G loss: 10.6362\n",
      "[6492/8000] D loss: 0.4015, G loss: 8.0001\n",
      "[6852/8000] D loss: 0.3965, G loss: 6.7277\n",
      "[7212/8000] D loss: 0.4883, G loss: 9.2669\n",
      "[7572/8000] D loss: 0.1839, G loss: 10.7365\n",
      "[7932/8000] D loss: 0.2906, G loss: 7.6544\n",
      "train error: \n",
      " D loss: 0.218863, G loss: 10.280121, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 10.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.494239, G loss: 13.256009, D accuracy: 93.0%, cell accuracy: 94.0%, board accuracy: 4.3% \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2114, G loss: 11.2827\n",
      "[372/8000] D loss: 0.2726, G loss: 8.2646\n",
      "[732/8000] D loss: 0.1176, G loss: 9.9391\n",
      "[1092/8000] D loss: 0.2016, G loss: 10.1910\n",
      "[1452/8000] D loss: 0.0549, G loss: 12.1947\n",
      "[1812/8000] D loss: 0.0242, G loss: 9.8343\n",
      "[2172/8000] D loss: 0.0003, G loss: 13.0611\n",
      "[2532/8000] D loss: 0.0064, G loss: 13.2373\n",
      "[2892/8000] D loss: 0.1613, G loss: 10.2376\n",
      "[3252/8000] D loss: 0.1143, G loss: 10.7417\n",
      "[3612/8000] D loss: 0.1576, G loss: 8.9089\n",
      "[3972/8000] D loss: 0.4146, G loss: 9.4900\n",
      "[4332/8000] D loss: 0.4050, G loss: 9.2965\n",
      "[4692/8000] D loss: 0.2409, G loss: 10.3938\n",
      "[5052/8000] D loss: 0.2477, G loss: 10.1792\n",
      "[5412/8000] D loss: 0.3400, G loss: 6.5206\n",
      "[5772/8000] D loss: 0.2781, G loss: 8.2015\n",
      "[6132/8000] D loss: 0.1382, G loss: 10.5066\n",
      "[6492/8000] D loss: 0.1969, G loss: 8.9753\n",
      "[6852/8000] D loss: 0.2649, G loss: 11.2352\n",
      "[7212/8000] D loss: 0.3176, G loss: 10.8982\n",
      "[7572/8000] D loss: 0.0110, G loss: 12.9723\n",
      "[7932/8000] D loss: 0.1908, G loss: 10.7560\n",
      "train error: \n",
      " D loss: 0.214873, G loss: 9.594188, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.456963, G loss: 12.745313, D accuracy: 94.1%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0073, G loss: 13.6016\n",
      "[372/8000] D loss: 0.3015, G loss: 9.1822\n",
      "[732/8000] D loss: 0.3573, G loss: 7.7203\n",
      "[1092/8000] D loss: 0.0688, G loss: 6.8879\n",
      "[1452/8000] D loss: 0.1818, G loss: 10.5765\n",
      "[1812/8000] D loss: 0.1789, G loss: 9.4979\n",
      "[2172/8000] D loss: 0.2277, G loss: 5.9528\n",
      "[2532/8000] D loss: 0.1801, G loss: 9.3181\n",
      "[2892/8000] D loss: 0.4306, G loss: 8.3230\n",
      "[3252/8000] D loss: 0.3269, G loss: 10.3700\n",
      "[3612/8000] D loss: 0.1210, G loss: 12.1039\n",
      "[3972/8000] D loss: 0.0686, G loss: 11.2825\n",
      "[4332/8000] D loss: 0.3355, G loss: 12.3013\n",
      "[4692/8000] D loss: 0.3805, G loss: 10.2879\n",
      "[5052/8000] D loss: 0.1514, G loss: 10.2743\n",
      "[5412/8000] D loss: 0.0533, G loss: 13.2113\n",
      "[5772/8000] D loss: 0.0486, G loss: 8.4785\n",
      "[6132/8000] D loss: 0.3591, G loss: 11.1969\n",
      "[6492/8000] D loss: 0.0050, G loss: 9.8019\n",
      "[6852/8000] D loss: 0.0548, G loss: 9.6075\n",
      "[7212/8000] D loss: 0.7572, G loss: 6.4282\n",
      "[7572/8000] D loss: 0.0204, G loss: 8.9090\n",
      "[7932/8000] D loss: 0.1562, G loss: 12.8579\n",
      "train error: \n",
      " D loss: 0.209236, G loss: 9.932761, D accuracy: 94.4%, cell accuracy: 94.4%, board accuracy: 9.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.442686, G loss: 13.219849, D accuracy: 94.7%, cell accuracy: 94.0%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1463, G loss: 9.2394\n",
      "[372/8000] D loss: 0.0490, G loss: 8.1177\n",
      "[732/8000] D loss: 0.3533, G loss: 10.3392\n",
      "[1092/8000] D loss: 0.1506, G loss: 14.6638\n",
      "[1452/8000] D loss: 0.2661, G loss: 11.7015\n",
      "[1812/8000] D loss: 0.1126, G loss: 15.6380\n",
      "[2172/8000] D loss: 0.0429, G loss: 8.7982\n",
      "[2532/8000] D loss: 0.1661, G loss: 12.1469\n",
      "[2892/8000] D loss: 0.3035, G loss: 9.0136\n",
      "[3252/8000] D loss: 0.3954, G loss: 10.4156\n",
      "[3612/8000] D loss: 0.1509, G loss: 11.0429\n",
      "[3972/8000] D loss: 0.0943, G loss: 10.0762\n",
      "[4332/8000] D loss: 0.3214, G loss: 9.5814\n",
      "[4692/8000] D loss: 0.3808, G loss: 8.2420\n",
      "[5052/8000] D loss: 0.0926, G loss: 7.4431\n",
      "[5412/8000] D loss: 0.0929, G loss: 10.5361\n",
      "[5772/8000] D loss: 0.1851, G loss: 8.1507\n",
      "[6132/8000] D loss: 0.2959, G loss: 11.8190\n",
      "[6492/8000] D loss: 0.2075, G loss: 12.0656\n",
      "[6852/8000] D loss: 0.2455, G loss: 6.5873\n",
      "[7212/8000] D loss: 0.1545, G loss: 12.6596\n",
      "[7572/8000] D loss: 0.4583, G loss: 6.9481\n",
      "[7932/8000] D loss: 0.2971, G loss: 7.6381\n",
      "train error: \n",
      " D loss: 0.214779, G loss: 9.629903, D accuracy: 94.4%, cell accuracy: 94.4%, board accuracy: 9.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.489726, G loss: 12.659950, D accuracy: 93.8%, cell accuracy: 94.0%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1746, G loss: 12.2072\n",
      "[372/8000] D loss: 0.2366, G loss: 11.8444\n",
      "[732/8000] D loss: 0.2515, G loss: 6.7591\n",
      "[1092/8000] D loss: 0.0756, G loss: 12.6084\n",
      "[1452/8000] D loss: 0.4556, G loss: 9.8890\n",
      "[1812/8000] D loss: 0.3663, G loss: 11.5808\n",
      "[2172/8000] D loss: 0.1619, G loss: 7.3095\n",
      "[2532/8000] D loss: 0.0750, G loss: 8.1625\n",
      "[2892/8000] D loss: 0.2186, G loss: 10.1225\n",
      "[3252/8000] D loss: 0.0392, G loss: 8.7538\n",
      "[3612/8000] D loss: 0.3922, G loss: 8.6011\n",
      "[3972/8000] D loss: 0.2346, G loss: 9.1263\n",
      "[4332/8000] D loss: 0.2662, G loss: 10.2659\n",
      "[4692/8000] D loss: 0.1503, G loss: 9.1211\n",
      "[5052/8000] D loss: 0.4914, G loss: 8.7530\n",
      "[5412/8000] D loss: 0.1624, G loss: 10.0319\n",
      "[5772/8000] D loss: 0.0031, G loss: 12.7930\n",
      "[6132/8000] D loss: 0.2274, G loss: 5.7115\n",
      "[6492/8000] D loss: 0.2833, G loss: 12.9590\n",
      "[6852/8000] D loss: 0.4910, G loss: 6.0417\n",
      "[7212/8000] D loss: 0.1534, G loss: 7.9431\n",
      "[7572/8000] D loss: 0.2868, G loss: 13.9526\n",
      "[7932/8000] D loss: 0.0670, G loss: 8.3234\n",
      "train error: \n",
      " D loss: 0.222979, G loss: 9.304990, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 9.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.424855, G loss: 12.529950, D accuracy: 93.9%, cell accuracy: 94.0%, board accuracy: 4.9% \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0187, G loss: 10.3242\n",
      "[372/8000] D loss: 0.2536, G loss: 17.7602\n",
      "[732/8000] D loss: 0.2275, G loss: 6.6772\n",
      "[1092/8000] D loss: 0.2043, G loss: 9.9550\n",
      "[1452/8000] D loss: 0.0523, G loss: 12.0338\n",
      "[1812/8000] D loss: 0.0318, G loss: 11.0880\n",
      "[2172/8000] D loss: 0.2132, G loss: 11.0601\n",
      "[2532/8000] D loss: 0.1693, G loss: 9.4205\n",
      "[2892/8000] D loss: 0.1442, G loss: 13.3973\n",
      "[3252/8000] D loss: 0.4442, G loss: 8.8852\n",
      "[3612/8000] D loss: 0.0082, G loss: 14.6777\n",
      "[3972/8000] D loss: 0.2063, G loss: 8.1072\n",
      "[4332/8000] D loss: 0.0726, G loss: 10.3337\n",
      "[4692/8000] D loss: 0.1352, G loss: 9.5953\n",
      "[5052/8000] D loss: 0.4449, G loss: 9.1857\n",
      "[5412/8000] D loss: 0.1615, G loss: 11.6419\n",
      "[5772/8000] D loss: 0.3611, G loss: 8.6141\n",
      "[6132/8000] D loss: 0.1594, G loss: 8.6922\n",
      "[6492/8000] D loss: 0.1665, G loss: 8.9367\n",
      "[6852/8000] D loss: 0.0088, G loss: 10.0664\n",
      "[7212/8000] D loss: 0.0327, G loss: 8.3618\n",
      "[7572/8000] D loss: 0.1251, G loss: 13.1620\n",
      "[7932/8000] D loss: 0.1829, G loss: 11.5681\n",
      "train error: \n",
      " D loss: 0.239347, G loss: 9.192222, D accuracy: 93.8%, cell accuracy: 94.3%, board accuracy: 10.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.430129, G loss: 12.208525, D accuracy: 94.2%, cell accuracy: 93.9%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1855, G loss: 9.1966\n",
      "[372/8000] D loss: 0.3933, G loss: 8.0832\n",
      "[732/8000] D loss: 0.2454, G loss: 8.6631\n",
      "[1092/8000] D loss: 0.1842, G loss: 8.9923\n",
      "[1452/8000] D loss: 0.1544, G loss: 10.8595\n",
      "[1812/8000] D loss: 0.2945, G loss: 12.9357\n",
      "[2172/8000] D loss: 0.3178, G loss: 8.9884\n",
      "[2532/8000] D loss: 0.5721, G loss: 6.9328\n",
      "[2892/8000] D loss: 0.5775, G loss: 10.0779\n",
      "[3252/8000] D loss: 0.2295, G loss: 10.3322\n",
      "[3612/8000] D loss: 0.1574, G loss: 12.9636\n",
      "[3972/8000] D loss: 0.2774, G loss: 8.4056\n",
      "[4332/8000] D loss: 0.3333, G loss: 6.8594\n",
      "[4692/8000] D loss: 0.2279, G loss: 6.9070\n",
      "[5052/8000] D loss: 0.2851, G loss: 10.1350\n",
      "[5412/8000] D loss: 0.0073, G loss: 16.1404\n",
      "[5772/8000] D loss: 0.4791, G loss: 7.6300\n",
      "[6132/8000] D loss: 0.1911, G loss: 11.1207\n",
      "[6492/8000] D loss: 0.0796, G loss: 10.9609\n",
      "[6852/8000] D loss: 0.1274, G loss: 9.5591\n",
      "[7212/8000] D loss: 0.0254, G loss: 9.0798\n",
      "[7572/8000] D loss: 0.0861, G loss: 9.2425\n",
      "[7932/8000] D loss: 0.2164, G loss: 9.5382\n",
      "train error: \n",
      " D loss: 0.220212, G loss: 9.566849, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.495876, G loss: 12.668259, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 4.9% \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1999, G loss: 8.8039\n",
      "[372/8000] D loss: 0.0042, G loss: 15.0814\n",
      "[732/8000] D loss: 0.0846, G loss: 9.9459\n",
      "[1092/8000] D loss: 0.1289, G loss: 12.7744\n",
      "[1452/8000] D loss: 0.1208, G loss: 10.4737\n",
      "[1812/8000] D loss: 0.1077, G loss: 13.8981\n",
      "[2172/8000] D loss: 0.1575, G loss: 11.0015\n",
      "[2532/8000] D loss: 0.1811, G loss: 8.0243\n",
      "[2892/8000] D loss: 0.1381, G loss: 10.5376\n",
      "[3252/8000] D loss: 0.3314, G loss: 11.3733\n",
      "[3612/8000] D loss: 0.2116, G loss: 10.5321\n",
      "[3972/8000] D loss: 0.1730, G loss: 8.9707\n",
      "[4332/8000] D loss: 0.3076, G loss: 8.8118\n",
      "[4692/8000] D loss: 0.1678, G loss: 11.6247\n",
      "[5052/8000] D loss: 0.3290, G loss: 7.5911\n",
      "[5412/8000] D loss: 0.1084, G loss: 10.1481\n",
      "[5772/8000] D loss: 0.1615, G loss: 8.5970\n",
      "[6132/8000] D loss: 0.0983, G loss: 10.9799\n",
      "[6492/8000] D loss: 0.2276, G loss: 6.4374\n",
      "[6852/8000] D loss: 0.2760, G loss: 9.0335\n",
      "[7212/8000] D loss: 0.4836, G loss: 7.6109\n",
      "[7572/8000] D loss: 0.2125, G loss: 15.1768\n",
      "[7932/8000] D loss: 0.2491, G loss: 7.8010\n",
      "train error: \n",
      " D loss: 0.236890, G loss: 8.238880, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 9.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.444842, G loss: 11.153311, D accuracy: 93.6%, cell accuracy: 94.0%, board accuracy: 4.7% \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0111, G loss: 11.4838\n",
      "[372/8000] D loss: 0.3517, G loss: 7.2741\n",
      "[732/8000] D loss: 0.1719, G loss: 9.0137\n",
      "[1092/8000] D loss: 0.0837, G loss: 10.1142\n",
      "[1452/8000] D loss: 0.1223, G loss: 8.1825\n",
      "[1812/8000] D loss: 0.0477, G loss: 11.5781\n",
      "[2172/8000] D loss: 0.3813, G loss: 6.8569\n",
      "[2532/8000] D loss: 0.4948, G loss: 7.2682\n",
      "[2892/8000] D loss: 0.0454, G loss: 14.7505\n",
      "[3252/8000] D loss: 0.4805, G loss: 7.2073\n",
      "[3612/8000] D loss: 0.0898, G loss: 11.9746\n",
      "[3972/8000] D loss: 0.0148, G loss: 13.2393\n",
      "[4332/8000] D loss: 0.2837, G loss: 9.3770\n",
      "[4692/8000] D loss: 0.2370, G loss: 12.2002\n",
      "[5052/8000] D loss: 0.2145, G loss: 9.4895\n",
      "[5412/8000] D loss: 0.2481, G loss: 12.1791\n",
      "[5772/8000] D loss: 0.3766, G loss: 9.3424\n",
      "[6132/8000] D loss: 0.2984, G loss: 9.8193\n",
      "[6492/8000] D loss: 0.0145, G loss: 13.1935\n",
      "[6852/8000] D loss: 0.1284, G loss: 7.7655\n",
      "[7212/8000] D loss: 0.1569, G loss: 10.3396\n",
      "[7572/8000] D loss: 0.2477, G loss: 11.2925\n",
      "[7932/8000] D loss: 0.2721, G loss: 11.3147\n",
      "train error: \n",
      " D loss: 0.215022, G loss: 10.294647, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.520993, G loss: 13.575254, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 4.6% \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2676, G loss: 7.9022\n",
      "[372/8000] D loss: 0.2117, G loss: 11.2083\n",
      "[732/8000] D loss: 0.1961, G loss: 13.2698\n",
      "[1092/8000] D loss: 0.0072, G loss: 11.9291\n",
      "[1452/8000] D loss: 0.1954, G loss: 8.6415\n",
      "[1812/8000] D loss: 0.1655, G loss: 7.6227\n",
      "[2172/8000] D loss: 0.1467, G loss: 8.0052\n",
      "[2532/8000] D loss: 0.1194, G loss: 11.3633\n",
      "[2892/8000] D loss: 0.1572, G loss: 12.2017\n",
      "[3252/8000] D loss: 0.6610, G loss: 9.1014\n",
      "[3612/8000] D loss: 0.1922, G loss: 12.1262\n",
      "[3972/8000] D loss: 0.2298, G loss: 8.8215\n",
      "[4332/8000] D loss: 0.3200, G loss: 8.3467\n",
      "[4692/8000] D loss: 0.0182, G loss: 11.5013\n",
      "[5052/8000] D loss: 0.0227, G loss: 14.3114\n",
      "[5412/8000] D loss: 0.2756, G loss: 14.5425\n",
      "[5772/8000] D loss: 0.1347, G loss: 7.8121\n",
      "[6132/8000] D loss: 0.0428, G loss: 8.4991\n",
      "[6492/8000] D loss: 0.3795, G loss: 8.7798\n",
      "[6852/8000] D loss: 0.2577, G loss: 9.3441\n",
      "[7212/8000] D loss: 0.1197, G loss: 11.1423\n",
      "[7572/8000] D loss: 0.1230, G loss: 8.6628\n",
      "[7932/8000] D loss: 0.0030, G loss: 10.4666\n",
      "train error: \n",
      " D loss: 0.214425, G loss: 10.528570, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.481249, G loss: 13.947084, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 4.6% \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2100, G loss: 11.3229\n",
      "[372/8000] D loss: 0.0624, G loss: 13.5136\n",
      "[732/8000] D loss: 0.1468, G loss: 12.6443\n",
      "[1092/8000] D loss: 0.6642, G loss: 5.6464\n",
      "[1452/8000] D loss: 0.0321, G loss: 15.3711\n",
      "[1812/8000] D loss: 0.1693, G loss: 9.5371\n",
      "[2172/8000] D loss: 0.0094, G loss: 12.6147\n",
      "[2532/8000] D loss: 0.1690, G loss: 10.9401\n",
      "[2892/8000] D loss: 0.1155, G loss: 9.6162\n",
      "[3252/8000] D loss: 0.1538, G loss: 6.5196\n",
      "[3612/8000] D loss: 0.1443, G loss: 8.9739\n",
      "[3972/8000] D loss: 0.2012, G loss: 10.2975\n",
      "[4332/8000] D loss: 0.2610, G loss: 11.7987\n",
      "[4692/8000] D loss: 0.3164, G loss: 11.9263\n",
      "[5052/8000] D loss: 0.2525, G loss: 11.1798\n",
      "[5412/8000] D loss: 0.1513, G loss: 10.3836\n",
      "[5772/8000] D loss: 0.0139, G loss: 12.6180\n",
      "[6132/8000] D loss: 0.1020, G loss: 12.5874\n",
      "[6492/8000] D loss: 0.0921, G loss: 11.4232\n",
      "[6852/8000] D loss: 0.0224, G loss: 7.9229\n",
      "[7212/8000] D loss: 0.1355, G loss: 11.2440\n",
      "[7572/8000] D loss: 0.3227, G loss: 5.8656\n",
      "[7932/8000] D loss: 0.3846, G loss: 9.8030\n",
      "train error: \n",
      " D loss: 0.212573, G loss: 10.618356, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.506770, G loss: 13.922578, D accuracy: 93.3%, cell accuracy: 94.1%, board accuracy: 4.9% \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2769, G loss: 8.7234\n",
      "[372/8000] D loss: 0.1950, G loss: 10.3214\n",
      "[732/8000] D loss: 0.0153, G loss: 13.4392\n",
      "[1092/8000] D loss: 0.1253, G loss: 9.3625\n",
      "[1452/8000] D loss: 0.4536, G loss: 7.8452\n",
      "[1812/8000] D loss: 0.1228, G loss: 11.3476\n",
      "[2172/8000] D loss: 0.4073, G loss: 5.2361\n",
      "[2532/8000] D loss: 0.2808, G loss: 9.2444\n",
      "[2892/8000] D loss: 0.1994, G loss: 9.2508\n",
      "[3252/8000] D loss: 0.2977, G loss: 6.3463\n",
      "[3612/8000] D loss: 0.1477, G loss: 12.8136\n",
      "[3972/8000] D loss: 0.0142, G loss: 12.5071\n",
      "[4332/8000] D loss: 0.2231, G loss: 9.2679\n",
      "[4692/8000] D loss: 0.1529, G loss: 10.0497\n",
      "[5052/8000] D loss: 0.2318, G loss: 12.2265\n",
      "[5412/8000] D loss: 0.4752, G loss: 6.5884\n",
      "[5772/8000] D loss: 0.0355, G loss: 13.2516\n",
      "[6132/8000] D loss: 0.0535, G loss: 11.5680\n",
      "[6492/8000] D loss: 0.0151, G loss: 10.1103\n",
      "[6852/8000] D loss: 0.1041, G loss: 10.4835\n",
      "[7212/8000] D loss: 0.1417, G loss: 12.0498\n",
      "[7572/8000] D loss: 0.4761, G loss: 6.8912\n",
      "[7932/8000] D loss: 0.3487, G loss: 9.8953\n",
      "train error: \n",
      " D loss: 0.227231, G loss: 11.162572, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 10.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.583831, G loss: 14.472374, D accuracy: 93.0%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0254, G loss: 7.6976\n",
      "[372/8000] D loss: 0.0135, G loss: 8.8996\n",
      "[732/8000] D loss: 0.3938, G loss: 10.9078\n",
      "[1092/8000] D loss: 0.0472, G loss: 11.5695\n",
      "[1452/8000] D loss: 0.2858, G loss: 13.0379\n",
      "[1812/8000] D loss: 0.1367, G loss: 15.3660\n",
      "[2172/8000] D loss: 0.0030, G loss: 11.8303\n",
      "[2532/8000] D loss: 0.2164, G loss: 11.5152\n",
      "[2892/8000] D loss: 0.1835, G loss: 10.1355\n",
      "[3252/8000] D loss: 0.1322, G loss: 12.0813\n",
      "[3612/8000] D loss: 0.1887, G loss: 9.9436\n",
      "[3972/8000] D loss: 0.1029, G loss: 9.2359\n",
      "[4332/8000] D loss: 0.0350, G loss: 8.6629\n",
      "[4692/8000] D loss: 0.2638, G loss: 8.0698\n",
      "[5052/8000] D loss: 0.2893, G loss: 8.7715\n",
      "[5412/8000] D loss: 0.0010, G loss: 14.0812\n",
      "[5772/8000] D loss: 0.0321, G loss: 10.2997\n",
      "[6132/8000] D loss: 0.1623, G loss: 10.4850\n",
      "[6492/8000] D loss: 0.1359, G loss: 11.0619\n",
      "[6852/8000] D loss: 0.2598, G loss: 9.8656\n",
      "[7212/8000] D loss: 0.1764, G loss: 7.9584\n",
      "[7572/8000] D loss: 0.1969, G loss: 9.5640\n",
      "[7932/8000] D loss: 0.1106, G loss: 16.0571\n",
      "train error: \n",
      " D loss: 0.227439, G loss: 10.534950, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.575153, G loss: 13.743781, D accuracy: 92.2%, cell accuracy: 94.0%, board accuracy: 4.7% \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0128, G loss: 12.6356\n",
      "[372/8000] D loss: 0.0034, G loss: 10.2756\n",
      "[732/8000] D loss: 0.0702, G loss: 11.6198\n",
      "[1092/8000] D loss: 0.1837, G loss: 11.6486\n",
      "[1452/8000] D loss: 0.1540, G loss: 7.1860\n",
      "[1812/8000] D loss: 0.2390, G loss: 11.9233\n",
      "[2172/8000] D loss: 0.0089, G loss: 13.0361\n",
      "[2532/8000] D loss: 0.1496, G loss: 11.7115\n",
      "[2892/8000] D loss: 0.1943, G loss: 14.3002\n",
      "[3252/8000] D loss: 0.1198, G loss: 10.0645\n",
      "[3612/8000] D loss: 0.3351, G loss: 10.4685\n",
      "[3972/8000] D loss: 0.0077, G loss: 12.6337\n",
      "[4332/8000] D loss: 0.3490, G loss: 6.7903\n",
      "[4692/8000] D loss: 0.6738, G loss: 4.0802\n",
      "[5052/8000] D loss: 0.1416, G loss: 10.4284\n",
      "[5412/8000] D loss: 0.2266, G loss: 11.2816\n",
      "[5772/8000] D loss: 0.1655, G loss: 7.7613\n",
      "[6132/8000] D loss: 0.3239, G loss: 10.6381\n",
      "[6492/8000] D loss: 0.2222, G loss: 11.0694\n",
      "[6852/8000] D loss: 0.0024, G loss: 13.9636\n",
      "[7212/8000] D loss: 0.1910, G loss: 9.5332\n",
      "[7572/8000] D loss: 0.8217, G loss: 4.5774\n",
      "[7932/8000] D loss: 0.2178, G loss: 10.1827\n",
      "train error: \n",
      " D loss: 0.261072, G loss: 7.943635, D accuracy: 93.1%, cell accuracy: 94.4%, board accuracy: 10.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.416200, G loss: 10.868482, D accuracy: 93.8%, cell accuracy: 94.0%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1102, G loss: 9.1807\n",
      "[372/8000] D loss: 0.1673, G loss: 10.4087\n",
      "[732/8000] D loss: 0.1312, G loss: 7.3429\n",
      "[1092/8000] D loss: 0.1782, G loss: 12.3003\n",
      "[1452/8000] D loss: 0.1947, G loss: 6.3098\n",
      "[1812/8000] D loss: 0.3022, G loss: 9.2142\n",
      "[2172/8000] D loss: 0.1615, G loss: 9.0746\n",
      "[2532/8000] D loss: 0.0093, G loss: 10.4596\n",
      "[2892/8000] D loss: 0.1275, G loss: 10.6593\n",
      "[3252/8000] D loss: 0.0363, G loss: 8.4381\n",
      "[3612/8000] D loss: 0.1149, G loss: 12.5434\n",
      "[3972/8000] D loss: 0.0184, G loss: 13.4105\n",
      "[4332/8000] D loss: 0.4355, G loss: 9.1806\n",
      "[4692/8000] D loss: 0.2328, G loss: 12.8364\n",
      "[5052/8000] D loss: 0.5024, G loss: 5.3926\n",
      "[5412/8000] D loss: 0.3509, G loss: 6.6840\n",
      "[5772/8000] D loss: 0.3789, G loss: 12.6090\n",
      "[6132/8000] D loss: 0.1346, G loss: 8.3023\n",
      "[6492/8000] D loss: 0.1947, G loss: 11.3030\n",
      "[6852/8000] D loss: 0.2430, G loss: 9.6840\n",
      "[7212/8000] D loss: 0.1888, G loss: 8.7474\n",
      "[7572/8000] D loss: 0.1400, G loss: 8.3050\n",
      "[7932/8000] D loss: 0.0373, G loss: 10.2395\n",
      "train error: \n",
      " D loss: 0.216912, G loss: 9.799910, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.529853, G loss: 12.854484, D accuracy: 92.4%, cell accuracy: 94.0%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2543, G loss: 8.8964\n",
      "[372/8000] D loss: 0.2868, G loss: 8.5147\n",
      "[732/8000] D loss: 0.2597, G loss: 8.9289\n",
      "[1092/8000] D loss: 0.3632, G loss: 7.8291\n",
      "[1452/8000] D loss: 0.1296, G loss: 12.9143\n",
      "[1812/8000] D loss: 0.1738, G loss: 9.5972\n",
      "[2172/8000] D loss: 0.1562, G loss: 7.4863\n",
      "[2532/8000] D loss: 0.0134, G loss: 12.5612\n",
      "[2892/8000] D loss: 0.1200, G loss: 12.0164\n",
      "[3252/8000] D loss: 0.3659, G loss: 12.1408\n",
      "[3612/8000] D loss: 0.2357, G loss: 9.1069\n",
      "[3972/8000] D loss: 0.3023, G loss: 7.1792\n",
      "[4332/8000] D loss: 0.0233, G loss: 12.3498\n",
      "[4692/8000] D loss: 0.2797, G loss: 12.9615\n",
      "[5052/8000] D loss: 0.0547, G loss: 15.9589\n",
      "[5412/8000] D loss: 0.3082, G loss: 7.9688\n",
      "[5772/8000] D loss: 0.4092, G loss: 10.7372\n",
      "[6132/8000] D loss: 0.1320, G loss: 7.0245\n",
      "[6492/8000] D loss: 0.3857, G loss: 5.4081\n",
      "[6852/8000] D loss: 0.3701, G loss: 10.8196\n",
      "[7212/8000] D loss: 0.2351, G loss: 11.9737\n",
      "[7572/8000] D loss: 0.1072, G loss: 9.7674\n",
      "[7932/8000] D loss: 0.4558, G loss: 8.3044\n",
      "train error: \n",
      " D loss: 0.217104, G loss: 11.281732, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 10.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592438, G loss: 14.578822, D accuracy: 92.3%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1699, G loss: 12.5497\n",
      "[372/8000] D loss: 0.5506, G loss: 9.6847\n",
      "[732/8000] D loss: 0.1306, G loss: 10.4457\n",
      "[1092/8000] D loss: 0.2985, G loss: 9.5519\n",
      "[1452/8000] D loss: 0.3212, G loss: 14.9827\n",
      "[1812/8000] D loss: 0.1541, G loss: 10.5173\n",
      "[2172/8000] D loss: 0.0184, G loss: 14.2781\n",
      "[2532/8000] D loss: 0.1691, G loss: 9.2482\n",
      "[2892/8000] D loss: 0.2907, G loss: 6.1754\n",
      "[3252/8000] D loss: 0.0557, G loss: 13.0820\n",
      "[3612/8000] D loss: 0.2400, G loss: 10.1153\n",
      "[3972/8000] D loss: 0.0951, G loss: 9.5097\n",
      "[4332/8000] D loss: 0.0195, G loss: 9.8138\n",
      "[4692/8000] D loss: 0.5045, G loss: 8.9498\n",
      "[5052/8000] D loss: 0.2440, G loss: 11.7573\n",
      "[5412/8000] D loss: 0.2820, G loss: 7.7325\n",
      "[5772/8000] D loss: 0.0405, G loss: 8.7319\n",
      "[6132/8000] D loss: 0.2073, G loss: 10.1853\n",
      "[6492/8000] D loss: 0.1410, G loss: 9.1591\n",
      "[6852/8000] D loss: 0.1222, G loss: 13.2641\n",
      "[7212/8000] D loss: 0.1451, G loss: 8.9072\n",
      "[7572/8000] D loss: 0.7787, G loss: 8.5978\n",
      "[7932/8000] D loss: 0.1378, G loss: 9.5893\n",
      "train error: \n",
      " D loss: 0.220279, G loss: 9.965938, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 10.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.464780, G loss: 13.202250, D accuracy: 93.8%, cell accuracy: 94.0%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0423, G loss: 11.7063\n",
      "[372/8000] D loss: 0.0725, G loss: 9.7392\n",
      "[732/8000] D loss: 0.2629, G loss: 10.1702\n",
      "[1092/8000] D loss: 0.3535, G loss: 6.3968\n",
      "[1452/8000] D loss: 0.1025, G loss: 14.4898\n",
      "[1812/8000] D loss: 0.1449, G loss: 12.0160\n",
      "[2172/8000] D loss: 0.3550, G loss: 9.6416\n",
      "[2532/8000] D loss: 0.1526, G loss: 9.3243\n",
      "[2892/8000] D loss: 0.3572, G loss: 12.2615\n",
      "[3252/8000] D loss: 0.1504, G loss: 10.5193\n",
      "[3612/8000] D loss: 0.0125, G loss: 8.5170\n",
      "[3972/8000] D loss: 0.0115, G loss: 11.2191\n",
      "[4332/8000] D loss: 0.1268, G loss: 9.1233\n",
      "[4692/8000] D loss: 0.0062, G loss: 9.7270\n",
      "[5052/8000] D loss: 0.2696, G loss: 10.6062\n",
      "[5412/8000] D loss: 0.1286, G loss: 9.0874\n",
      "[5772/8000] D loss: 0.2106, G loss: 12.8112\n",
      "[6132/8000] D loss: 0.5335, G loss: 8.7819\n",
      "[6492/8000] D loss: 0.2457, G loss: 11.2624\n",
      "[6852/8000] D loss: 0.1777, G loss: 8.9558\n",
      "[7212/8000] D loss: 0.0649, G loss: 9.5717\n",
      "[7572/8000] D loss: 0.2333, G loss: 11.1488\n",
      "[7932/8000] D loss: 0.2107, G loss: 12.1560\n",
      "train error: \n",
      " D loss: 0.234650, G loss: 9.370302, D accuracy: 93.7%, cell accuracy: 94.4%, board accuracy: 10.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.467442, G loss: 12.569631, D accuracy: 93.6%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2441, G loss: 10.9831\n",
      "[372/8000] D loss: 0.2501, G loss: 8.0530\n",
      "[732/8000] D loss: 0.0121, G loss: 12.0677\n",
      "[1092/8000] D loss: 0.3870, G loss: 8.6633\n",
      "[1452/8000] D loss: 0.1412, G loss: 14.3018\n",
      "[1812/8000] D loss: 0.0139, G loss: 10.9828\n",
      "[2172/8000] D loss: 0.3005, G loss: 14.2230\n",
      "[2532/8000] D loss: 0.0514, G loss: 10.8988\n",
      "[2892/8000] D loss: 0.5074, G loss: 7.6142\n",
      "[3252/8000] D loss: 0.2127, G loss: 10.9919\n",
      "[3612/8000] D loss: 0.0943, G loss: 13.7802\n",
      "[3972/8000] D loss: 0.4405, G loss: 8.7101\n",
      "[4332/8000] D loss: 0.1658, G loss: 8.5439\n",
      "[4692/8000] D loss: 0.2665, G loss: 11.9265\n",
      "[5052/8000] D loss: 0.1312, G loss: 9.7664\n",
      "[5412/8000] D loss: 0.1253, G loss: 10.2710\n",
      "[5772/8000] D loss: 0.6207, G loss: 6.3474\n",
      "[6132/8000] D loss: 0.3646, G loss: 9.9525\n",
      "[6492/8000] D loss: 0.1191, G loss: 12.7510\n",
      "[6852/8000] D loss: 0.1263, G loss: 10.6247\n",
      "[7212/8000] D loss: 0.0857, G loss: 9.0013\n",
      "[7572/8000] D loss: 0.0177, G loss: 10.5330\n",
      "[7932/8000] D loss: 0.1573, G loss: 11.4312\n",
      "train error: \n",
      " D loss: 0.229523, G loss: 9.565106, D accuracy: 93.7%, cell accuracy: 94.4%, board accuracy: 10.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.446590, G loss: 12.758516, D accuracy: 93.2%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1868, G loss: 8.5767\n",
      "[372/8000] D loss: 0.3219, G loss: 6.4149\n",
      "[732/8000] D loss: 0.0757, G loss: 11.3748\n",
      "[1092/8000] D loss: 0.2585, G loss: 12.9466\n",
      "[1452/8000] D loss: 0.1324, G loss: 10.1933\n",
      "[1812/8000] D loss: 0.1919, G loss: 9.1908\n",
      "[2172/8000] D loss: 0.3518, G loss: 10.5080\n",
      "[2532/8000] D loss: 0.2998, G loss: 10.4762\n",
      "[2892/8000] D loss: 0.0322, G loss: 8.3768\n",
      "[3252/8000] D loss: 0.1858, G loss: 10.2748\n",
      "[3612/8000] D loss: 0.1567, G loss: 11.9533\n",
      "[3972/8000] D loss: 0.3485, G loss: 10.1964\n",
      "[4332/8000] D loss: 0.1914, G loss: 9.4282\n",
      "[4692/8000] D loss: 0.1336, G loss: 10.2561\n",
      "[5052/8000] D loss: 0.1945, G loss: 10.7843\n",
      "[5412/8000] D loss: 0.4172, G loss: 8.3837\n",
      "[5772/8000] D loss: 0.2189, G loss: 11.8125\n",
      "[6132/8000] D loss: 0.1672, G loss: 12.4603\n",
      "[6492/8000] D loss: 0.3929, G loss: 7.2345\n",
      "[6852/8000] D loss: 0.1656, G loss: 9.7174\n",
      "[7212/8000] D loss: 0.1237, G loss: 13.0341\n",
      "[7572/8000] D loss: 0.1839, G loss: 9.1557\n",
      "[7932/8000] D loss: 0.1293, G loss: 10.7837\n",
      "train error: \n",
      " D loss: 0.224762, G loss: 9.393883, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.477760, G loss: 12.675579, D accuracy: 93.8%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2346, G loss: 8.9535\n",
      "[372/8000] D loss: 0.2879, G loss: 10.1414\n",
      "[732/8000] D loss: 0.0292, G loss: 8.1455\n",
      "[1092/8000] D loss: 0.0306, G loss: 13.9923\n",
      "[1452/8000] D loss: 0.3205, G loss: 11.2540\n",
      "[1812/8000] D loss: 0.3730, G loss: 8.6586\n",
      "[2172/8000] D loss: 0.2634, G loss: 9.3674\n",
      "[2532/8000] D loss: 0.1304, G loss: 11.0022\n",
      "[2892/8000] D loss: 0.0812, G loss: 9.3093\n",
      "[3252/8000] D loss: 0.2565, G loss: 11.0402\n",
      "[3612/8000] D loss: 0.4290, G loss: 11.0719\n",
      "[3972/8000] D loss: 0.0099, G loss: 9.0996\n",
      "[4332/8000] D loss: 0.3207, G loss: 9.5014\n",
      "[4692/8000] D loss: 0.0107, G loss: 11.3556\n",
      "[5052/8000] D loss: 0.4205, G loss: 8.3534\n",
      "[5412/8000] D loss: 0.2582, G loss: 8.6970\n",
      "[5772/8000] D loss: 0.3029, G loss: 8.5152\n",
      "[6132/8000] D loss: 0.0061, G loss: 11.6180\n",
      "[6492/8000] D loss: 0.3714, G loss: 9.3237\n",
      "[6852/8000] D loss: 0.2749, G loss: 11.6499\n",
      "[7212/8000] D loss: 0.0438, G loss: 8.2644\n",
      "[7572/8000] D loss: 0.0281, G loss: 14.1821\n",
      "[7932/8000] D loss: 0.3526, G loss: 8.4984\n",
      "train error: \n",
      " D loss: 0.240903, G loss: 10.535629, D accuracy: 93.7%, cell accuracy: 94.3%, board accuracy: 10.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.532942, G loss: 13.723480, D accuracy: 92.3%, cell accuracy: 93.9%, board accuracy: 4.9% \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1911, G loss: 11.0324\n",
      "[372/8000] D loss: 0.2295, G loss: 10.5194\n",
      "[732/8000] D loss: 0.0254, G loss: 11.1483\n",
      "[1092/8000] D loss: 0.0848, G loss: 8.1149\n",
      "[1452/8000] D loss: 0.3368, G loss: 8.3618\n",
      "[1812/8000] D loss: 0.2757, G loss: 7.3679\n",
      "[2172/8000] D loss: 0.5105, G loss: 7.0404\n",
      "[2532/8000] D loss: 0.0218, G loss: 12.6818\n",
      "[2892/8000] D loss: 0.1812, G loss: 6.0410\n",
      "[3252/8000] D loss: 0.2644, G loss: 11.5556\n",
      "[3612/8000] D loss: 0.2709, G loss: 11.5484\n",
      "[3972/8000] D loss: 0.3103, G loss: 11.0726\n",
      "[4332/8000] D loss: 0.0501, G loss: 10.9745\n",
      "[4692/8000] D loss: 0.5056, G loss: 8.0793\n",
      "[5052/8000] D loss: 0.0114, G loss: 12.7933\n",
      "[5412/8000] D loss: 0.0174, G loss: 16.2689\n",
      "[5772/8000] D loss: 0.0859, G loss: 13.0919\n",
      "[6132/8000] D loss: 0.1375, G loss: 10.9838\n",
      "[6492/8000] D loss: 0.2441, G loss: 10.4678\n",
      "[6852/8000] D loss: 0.1254, G loss: 10.1197\n",
      "[7212/8000] D loss: 0.0175, G loss: 11.7730\n",
      "[7572/8000] D loss: 0.1567, G loss: 11.3099\n",
      "[7932/8000] D loss: 0.0814, G loss: 10.7995\n",
      "train error: \n",
      " D loss: 0.224045, G loss: 9.801041, D accuracy: 94.0%, cell accuracy: 94.4%, board accuracy: 10.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.484895, G loss: 12.978644, D accuracy: 93.8%, cell accuracy: 94.0%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1649, G loss: 7.1706\n",
      "[372/8000] D loss: 0.4579, G loss: 7.9263\n",
      "[732/8000] D loss: 0.3946, G loss: 9.2203\n",
      "[1092/8000] D loss: 0.4874, G loss: 7.7884\n",
      "[1452/8000] D loss: 0.5020, G loss: 9.0092\n",
      "[1812/8000] D loss: 0.3440, G loss: 7.0792\n",
      "[2172/8000] D loss: 0.3225, G loss: 8.6921\n",
      "[2532/8000] D loss: 0.6230, G loss: 5.7936\n",
      "[2892/8000] D loss: 0.2322, G loss: 12.0392\n",
      "[3252/8000] D loss: 0.4885, G loss: 8.4212\n",
      "[3612/8000] D loss: 0.2536, G loss: 8.9540\n",
      "[3972/8000] D loss: 0.0037, G loss: 10.6629\n",
      "[4332/8000] D loss: 0.1972, G loss: 14.4457\n",
      "[4692/8000] D loss: 0.0103, G loss: 12.3710\n",
      "[5052/8000] D loss: 0.1356, G loss: 8.5243\n",
      "[5412/8000] D loss: 0.0107, G loss: 12.8420\n",
      "[5772/8000] D loss: 0.1297, G loss: 11.6068\n",
      "[6132/8000] D loss: 0.0062, G loss: 15.7081\n",
      "[6492/8000] D loss: 0.4154, G loss: 8.2653\n",
      "[6852/8000] D loss: 0.0763, G loss: 12.0390\n",
      "[7212/8000] D loss: 0.4593, G loss: 8.5437\n",
      "[7572/8000] D loss: 0.3465, G loss: 9.2694\n",
      "[7932/8000] D loss: 0.0011, G loss: 13.5752\n",
      "train error: \n",
      " D loss: 0.211062, G loss: 9.982737, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.481473, G loss: 13.244924, D accuracy: 93.3%, cell accuracy: 94.0%, board accuracy: 4.9% \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0093, G loss: 9.7445\n",
      "[372/8000] D loss: 0.2604, G loss: 8.8646\n",
      "[732/8000] D loss: 0.4127, G loss: 8.3843\n",
      "[1092/8000] D loss: 0.2633, G loss: 7.8619\n",
      "[1452/8000] D loss: 0.0184, G loss: 10.7707\n",
      "[1812/8000] D loss: 0.1788, G loss: 8.2152\n",
      "[2172/8000] D loss: 0.7783, G loss: 7.9046\n",
      "[2532/8000] D loss: 0.2321, G loss: 10.7287\n",
      "[2892/8000] D loss: 0.4335, G loss: 12.0215\n",
      "[3252/8000] D loss: 0.1761, G loss: 7.4603\n",
      "[3612/8000] D loss: 0.1358, G loss: 10.1839\n",
      "[3972/8000] D loss: 0.2777, G loss: 8.5604\n",
      "[4332/8000] D loss: 0.1088, G loss: 13.2363\n",
      "[4692/8000] D loss: 0.0094, G loss: 10.8548\n",
      "[5052/8000] D loss: 0.1561, G loss: 10.9630\n",
      "[5412/8000] D loss: 0.1304, G loss: 13.2542\n",
      "[5772/8000] D loss: 0.0022, G loss: 17.3087\n",
      "[6132/8000] D loss: 0.2364, G loss: 8.0719\n",
      "[6492/8000] D loss: 0.0011, G loss: 12.9597\n",
      "[6852/8000] D loss: 0.0243, G loss: 11.7513\n",
      "[7212/8000] D loss: 0.0345, G loss: 8.8147\n",
      "[7572/8000] D loss: 0.0469, G loss: 11.5688\n",
      "[7932/8000] D loss: 0.2035, G loss: 11.9402\n",
      "train error: \n",
      " D loss: 0.209711, G loss: 11.518239, D accuracy: 94.1%, cell accuracy: 94.4%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.574074, G loss: 14.938024, D accuracy: 92.6%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1455, G loss: 12.9115\n",
      "[372/8000] D loss: 0.0081, G loss: 14.9828\n",
      "[732/8000] D loss: 0.3793, G loss: 6.5756\n",
      "[1092/8000] D loss: 0.1382, G loss: 10.7841\n",
      "[1452/8000] D loss: 0.3252, G loss: 9.4443\n",
      "[1812/8000] D loss: 0.4527, G loss: 10.1583\n",
      "[2172/8000] D loss: 0.2601, G loss: 11.4692\n",
      "[2532/8000] D loss: 0.2409, G loss: 8.1610\n",
      "[2892/8000] D loss: 0.2523, G loss: 10.2134\n",
      "[3252/8000] D loss: 0.1053, G loss: 10.5510\n",
      "[3612/8000] D loss: 0.5888, G loss: 6.4994\n",
      "[3972/8000] D loss: 0.0434, G loss: 9.7352\n",
      "[4332/8000] D loss: 0.1864, G loss: 9.5006\n",
      "[4692/8000] D loss: 0.0132, G loss: 11.6444\n",
      "[5052/8000] D loss: 0.2127, G loss: 5.8770\n",
      "[5412/8000] D loss: 0.1294, G loss: 12.6065\n",
      "[5772/8000] D loss: 0.3470, G loss: 8.6641\n",
      "[6132/8000] D loss: 0.4467, G loss: 6.3681\n",
      "[6492/8000] D loss: 0.6835, G loss: 6.8145\n",
      "[6852/8000] D loss: 0.2771, G loss: 9.5470\n",
      "[7212/8000] D loss: 0.3084, G loss: 9.7206\n",
      "[7572/8000] D loss: 0.1800, G loss: 11.9413\n",
      "[7932/8000] D loss: 0.5453, G loss: 7.5487\n",
      "train error: \n",
      " D loss: 0.227897, G loss: 9.728089, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 10.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.482537, G loss: 13.045704, D accuracy: 93.5%, cell accuracy: 94.0%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3215, G loss: 11.1100\n",
      "[372/8000] D loss: 0.4348, G loss: 7.0180\n",
      "[732/8000] D loss: 0.0592, G loss: 9.7677\n",
      "[1092/8000] D loss: 0.2717, G loss: 11.5978\n",
      "[1452/8000] D loss: 0.0826, G loss: 9.6986\n",
      "[1812/8000] D loss: 0.2945, G loss: 11.0847\n",
      "[2172/8000] D loss: 0.0502, G loss: 8.7662\n",
      "[2532/8000] D loss: 0.2018, G loss: 10.0714\n",
      "[2892/8000] D loss: 0.1433, G loss: 9.6238\n",
      "[3252/8000] D loss: 0.2782, G loss: 6.2592\n",
      "[3612/8000] D loss: 0.2669, G loss: 14.9222\n",
      "[3972/8000] D loss: 0.3829, G loss: 10.1681\n",
      "[4332/8000] D loss: 0.4056, G loss: 11.4232\n",
      "[4692/8000] D loss: 0.1251, G loss: 12.5052\n",
      "[5052/8000] D loss: 0.2811, G loss: 9.7711\n",
      "[5412/8000] D loss: 0.1235, G loss: 14.3587\n",
      "[5772/8000] D loss: 0.1341, G loss: 8.4638\n",
      "[6132/8000] D loss: 0.3055, G loss: 6.6432\n",
      "[6492/8000] D loss: 0.5055, G loss: 6.6921\n",
      "[6852/8000] D loss: 0.1819, G loss: 8.9684\n",
      "[7212/8000] D loss: 0.1475, G loss: 8.6759\n",
      "[7572/8000] D loss: 0.1244, G loss: 10.1938\n",
      "[7932/8000] D loss: 0.1684, G loss: 7.7801\n",
      "train error: \n",
      " D loss: 0.235421, G loss: 11.087286, D accuracy: 93.6%, cell accuracy: 94.4%, board accuracy: 10.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.621934, G loss: 14.359918, D accuracy: 92.4%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1785, G loss: 13.2963\n",
      "[372/8000] D loss: 0.4571, G loss: 11.4925\n",
      "[732/8000] D loss: 0.1743, G loss: 10.5597\n",
      "[1092/8000] D loss: 0.2607, G loss: 8.2479\n",
      "[1452/8000] D loss: 0.2702, G loss: 11.2789\n",
      "[1812/8000] D loss: 0.6733, G loss: 6.2135\n",
      "[2172/8000] D loss: 0.2565, G loss: 9.2454\n",
      "[2532/8000] D loss: 0.1094, G loss: 11.3331\n",
      "[2892/8000] D loss: 0.0441, G loss: 14.2607\n",
      "[3252/8000] D loss: 0.1313, G loss: 10.7214\n",
      "[3612/8000] D loss: 0.0051, G loss: 18.8730\n",
      "[3972/8000] D loss: 0.2553, G loss: 10.1244\n",
      "[4332/8000] D loss: 0.0554, G loss: 9.1607\n",
      "[4692/8000] D loss: 0.1540, G loss: 13.3989\n",
      "[5052/8000] D loss: 0.1492, G loss: 11.6574\n",
      "[5412/8000] D loss: 0.2211, G loss: 10.9876\n",
      "[5772/8000] D loss: 0.2771, G loss: 12.7156\n",
      "[6132/8000] D loss: 0.2480, G loss: 8.3479\n",
      "[6492/8000] D loss: 0.1308, G loss: 13.9116\n",
      "[6852/8000] D loss: 0.1334, G loss: 9.9575\n",
      "[7212/8000] D loss: 0.1290, G loss: 8.6501\n",
      "[7572/8000] D loss: 0.4121, G loss: 7.7867\n",
      "[7932/8000] D loss: 0.3155, G loss: 7.4284\n",
      "train error: \n",
      " D loss: 0.259113, G loss: 8.518787, D accuracy: 93.2%, cell accuracy: 94.4%, board accuracy: 10.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.451678, G loss: 11.747510, D accuracy: 93.3%, cell accuracy: 94.0%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0960, G loss: 10.0216\n",
      "[372/8000] D loss: 0.0178, G loss: 11.6346\n",
      "[732/8000] D loss: 0.2829, G loss: 7.9550\n",
      "[1092/8000] D loss: 0.0241, G loss: 15.3103\n",
      "[1452/8000] D loss: 0.2385, G loss: 10.5046\n",
      "[1812/8000] D loss: 0.2451, G loss: 9.3647\n",
      "[2172/8000] D loss: 0.2675, G loss: 8.8115\n",
      "[2532/8000] D loss: 0.0373, G loss: 10.5824\n",
      "[2892/8000] D loss: 0.2489, G loss: 9.2783\n",
      "[3252/8000] D loss: 0.2116, G loss: 12.2599\n",
      "[3612/8000] D loss: 0.1294, G loss: 11.5030\n",
      "[3972/8000] D loss: 0.2763, G loss: 7.8149\n",
      "[4332/8000] D loss: 0.1288, G loss: 12.8257\n",
      "[4692/8000] D loss: 0.1291, G loss: 10.5362\n",
      "[5052/8000] D loss: 0.3413, G loss: 8.8762\n",
      "[5412/8000] D loss: 0.2178, G loss: 9.6484\n",
      "[5772/8000] D loss: 0.1976, G loss: 8.6556\n",
      "[6132/8000] D loss: 0.1303, G loss: 8.7739\n",
      "[6492/8000] D loss: 0.4757, G loss: 10.6546\n",
      "[6852/8000] D loss: 0.3819, G loss: 7.5004\n",
      "[7212/8000] D loss: 0.2223, G loss: 8.8140\n",
      "[7572/8000] D loss: 0.1059, G loss: 12.0616\n",
      "[7932/8000] D loss: 0.4362, G loss: 10.4724\n",
      "train error: \n",
      " D loss: 0.231292, G loss: 10.982025, D accuracy: 93.7%, cell accuracy: 94.4%, board accuracy: 10.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.567877, G loss: 14.189711, D accuracy: 92.3%, cell accuracy: 94.0%, board accuracy: 4.7% \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1798, G loss: 9.0524\n",
      "[372/8000] D loss: 0.0299, G loss: 8.1212\n",
      "[732/8000] D loss: 0.4711, G loss: 8.8129\n",
      "[1092/8000] D loss: 0.2870, G loss: 6.9581\n",
      "[1452/8000] D loss: 0.1831, G loss: 9.7943\n",
      "[1812/8000] D loss: 0.2758, G loss: 7.8544\n",
      "[2172/8000] D loss: 0.0499, G loss: 8.8878\n",
      "[2532/8000] D loss: 0.1051, G loss: 10.0390\n",
      "[2892/8000] D loss: 0.1252, G loss: 16.3375\n",
      "[3252/8000] D loss: 0.0014, G loss: 14.6818\n",
      "[3612/8000] D loss: 0.0379, G loss: 13.2761\n",
      "[3972/8000] D loss: 0.1459, G loss: 11.2046\n",
      "[4332/8000] D loss: 0.2647, G loss: 8.7114\n",
      "[4692/8000] D loss: 0.5832, G loss: 4.6835\n",
      "[5052/8000] D loss: 0.2629, G loss: 10.2579\n",
      "[5412/8000] D loss: 0.5117, G loss: 8.3131\n",
      "[5772/8000] D loss: 0.1178, G loss: 12.4155\n",
      "[6132/8000] D loss: 0.2583, G loss: 8.5037\n",
      "[6492/8000] D loss: 0.3691, G loss: 8.9396\n",
      "[6852/8000] D loss: 0.4913, G loss: 9.8708\n",
      "[7212/8000] D loss: 0.3794, G loss: 9.1864\n",
      "[7572/8000] D loss: 0.1700, G loss: 10.4792\n",
      "[7932/8000] D loss: 0.1050, G loss: 10.5853\n",
      "train error: \n",
      " D loss: 0.229896, G loss: 9.016821, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 11.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.488098, G loss: 12.139069, D accuracy: 93.7%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2009, G loss: 8.3767\n",
      "[372/8000] D loss: 0.6787, G loss: 6.5554\n",
      "[732/8000] D loss: 0.1341, G loss: 10.8647\n",
      "[1092/8000] D loss: 0.3733, G loss: 8.6470\n",
      "[1452/8000] D loss: 0.3701, G loss: 6.8257\n",
      "[1812/8000] D loss: 0.0027, G loss: 11.4033\n",
      "[2172/8000] D loss: 0.4224, G loss: 6.9907\n",
      "[2532/8000] D loss: 0.2123, G loss: 10.6614\n",
      "[2892/8000] D loss: 0.1515, G loss: 7.5421\n",
      "[3252/8000] D loss: 0.1379, G loss: 13.4102\n",
      "[3612/8000] D loss: 0.0485, G loss: 12.3579\n",
      "[3972/8000] D loss: 0.2596, G loss: 10.2407\n",
      "[4332/8000] D loss: 0.4451, G loss: 6.0830\n",
      "[4692/8000] D loss: 0.2914, G loss: 10.1664\n",
      "[5052/8000] D loss: 0.3913, G loss: 6.3873\n",
      "[5412/8000] D loss: 0.1818, G loss: 9.1282\n",
      "[5772/8000] D loss: 0.2217, G loss: 12.2269\n",
      "[6132/8000] D loss: 0.1192, G loss: 12.3901\n",
      "[6492/8000] D loss: 0.2451, G loss: 8.5163\n",
      "[6852/8000] D loss: 0.3669, G loss: 8.1265\n",
      "[7212/8000] D loss: 0.0218, G loss: 16.2144\n",
      "[7572/8000] D loss: 0.1576, G loss: 7.7004\n",
      "[7932/8000] D loss: 0.4476, G loss: 9.1258\n",
      "train error: \n",
      " D loss: 0.234925, G loss: 9.685550, D accuracy: 93.7%, cell accuracy: 94.4%, board accuracy: 10.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.499798, G loss: 13.137645, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2827, G loss: 10.1228\n",
      "[372/8000] D loss: 0.3988, G loss: 8.3101\n",
      "[732/8000] D loss: 0.4162, G loss: 8.7044\n",
      "[1092/8000] D loss: 0.0487, G loss: 10.7903\n",
      "[1452/8000] D loss: 0.0449, G loss: 9.1984\n",
      "[1812/8000] D loss: 0.0487, G loss: 9.4818\n",
      "[2172/8000] D loss: 0.1617, G loss: 11.2878\n",
      "[2532/8000] D loss: 0.1194, G loss: 12.3787\n",
      "[2892/8000] D loss: 0.1748, G loss: 10.5475\n",
      "[3252/8000] D loss: 0.0871, G loss: 9.4982\n",
      "[3612/8000] D loss: 0.2882, G loss: 12.2444\n",
      "[3972/8000] D loss: 0.1185, G loss: 10.8312\n",
      "[4332/8000] D loss: 0.2309, G loss: 9.0124\n",
      "[4692/8000] D loss: 0.3520, G loss: 9.5364\n",
      "[5052/8000] D loss: 0.1056, G loss: 11.0628\n",
      "[5412/8000] D loss: 0.1538, G loss: 9.3169\n",
      "[5772/8000] D loss: 0.0867, G loss: 11.3895\n",
      "[6132/8000] D loss: 0.2882, G loss: 10.2148\n",
      "[6492/8000] D loss: 0.1399, G loss: 8.9930\n",
      "[6852/8000] D loss: 0.2196, G loss: 13.2425\n",
      "[7212/8000] D loss: 0.6612, G loss: 5.7987\n",
      "[7572/8000] D loss: 0.1134, G loss: 8.6598\n",
      "[7932/8000] D loss: 0.3239, G loss: 9.0634\n",
      "train error: \n",
      " D loss: 0.232708, G loss: 10.617790, D accuracy: 93.7%, cell accuracy: 94.4%, board accuracy: 10.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.536085, G loss: 13.951743, D accuracy: 93.5%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0162, G loss: 10.5128\n",
      "[372/8000] D loss: 0.1826, G loss: 12.8792\n",
      "[732/8000] D loss: 0.0852, G loss: 16.0183\n",
      "[1092/8000] D loss: 0.2024, G loss: 8.5292\n",
      "[1452/8000] D loss: 0.2607, G loss: 6.4760\n",
      "[1812/8000] D loss: 0.6099, G loss: 8.0668\n",
      "[2172/8000] D loss: 0.1093, G loss: 12.6570\n",
      "[2532/8000] D loss: 0.4480, G loss: 8.5426\n",
      "[2892/8000] D loss: 0.3162, G loss: 9.8593\n",
      "[3252/8000] D loss: 0.0179, G loss: 10.9844\n",
      "[3612/8000] D loss: 0.2976, G loss: 6.2222\n",
      "[3972/8000] D loss: 0.1170, G loss: 9.7424\n",
      "[4332/8000] D loss: 0.4317, G loss: 12.8071\n",
      "[4692/8000] D loss: 0.1190, G loss: 9.3931\n",
      "[5052/8000] D loss: 0.0583, G loss: 10.5230\n",
      "[5412/8000] D loss: 0.4026, G loss: 6.5167\n",
      "[5772/8000] D loss: 0.2450, G loss: 12.8203\n",
      "[6132/8000] D loss: 0.0031, G loss: 12.3477\n",
      "[6492/8000] D loss: 0.2200, G loss: 6.4915\n",
      "[6852/8000] D loss: 0.0948, G loss: 9.6354\n",
      "[7212/8000] D loss: 0.0982, G loss: 9.1920\n",
      "[7572/8000] D loss: 0.1346, G loss: 9.1687\n",
      "[7932/8000] D loss: 0.0868, G loss: 9.7483\n",
      "train error: \n",
      " D loss: 0.246626, G loss: 9.871618, D accuracy: 93.3%, cell accuracy: 94.4%, board accuracy: 10.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.554578, G loss: 13.000170, D accuracy: 91.8%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3929, G loss: 7.6146\n",
      "[372/8000] D loss: 0.0788, G loss: 11.3847\n",
      "[732/8000] D loss: 0.2884, G loss: 8.8049\n",
      "[1092/8000] D loss: 0.0551, G loss: 12.9093\n",
      "[1452/8000] D loss: 0.5030, G loss: 7.8735\n",
      "[1812/8000] D loss: 0.3811, G loss: 12.0644\n",
      "[2172/8000] D loss: 0.3424, G loss: 10.1269\n",
      "[2532/8000] D loss: 0.3479, G loss: 9.3991\n",
      "[2892/8000] D loss: 0.1829, G loss: 11.4050\n",
      "[3252/8000] D loss: 0.0132, G loss: 12.3240\n",
      "[3612/8000] D loss: 0.1514, G loss: 15.2354\n",
      "[3972/8000] D loss: 0.1515, G loss: 9.2123\n",
      "[4332/8000] D loss: 0.1445, G loss: 10.7223\n",
      "[4692/8000] D loss: 0.3939, G loss: 6.9083\n",
      "[5052/8000] D loss: 0.1587, G loss: 11.8215\n",
      "[5412/8000] D loss: 0.0726, G loss: 13.6149\n",
      "[5772/8000] D loss: 0.1017, G loss: 11.6793\n",
      "[6132/8000] D loss: 0.3261, G loss: 6.4996\n",
      "[6492/8000] D loss: 0.2656, G loss: 7.8121\n",
      "[6852/8000] D loss: 0.0170, G loss: 8.7932\n",
      "[7212/8000] D loss: 0.3498, G loss: 8.7503\n",
      "[7572/8000] D loss: 0.1994, G loss: 11.8905\n",
      "[7932/8000] D loss: 0.0477, G loss: 10.4635\n",
      "train error: \n",
      " D loss: 0.223452, G loss: 9.604982, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 10.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.499146, G loss: 12.764416, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0633, G loss: 10.8490\n",
      "[372/8000] D loss: 0.1130, G loss: 13.0418\n",
      "[732/8000] D loss: 0.1399, G loss: 11.9303\n",
      "[1092/8000] D loss: 0.2345, G loss: 11.4552\n",
      "[1452/8000] D loss: 0.0813, G loss: 8.9760\n",
      "[1812/8000] D loss: 0.2012, G loss: 9.2669\n",
      "[2172/8000] D loss: 0.0830, G loss: 13.8820\n",
      "[2532/8000] D loss: 0.1212, G loss: 8.4864\n",
      "[2892/8000] D loss: 0.2665, G loss: 10.1835\n",
      "[3252/8000] D loss: 0.1347, G loss: 8.4487\n",
      "[3612/8000] D loss: 0.1805, G loss: 11.3867\n",
      "[3972/8000] D loss: 0.1955, G loss: 9.6157\n",
      "[4332/8000] D loss: 0.1814, G loss: 7.3345\n",
      "[4692/8000] D loss: 0.2568, G loss: 8.3899\n",
      "[5052/8000] D loss: 0.2210, G loss: 9.5056\n",
      "[5412/8000] D loss: 0.2947, G loss: 8.3366\n",
      "[5772/8000] D loss: 0.1986, G loss: 8.8266\n",
      "[6132/8000] D loss: 0.1910, G loss: 7.8912\n",
      "[6492/8000] D loss: 0.3440, G loss: 8.8836\n",
      "[6852/8000] D loss: 0.3135, G loss: 7.8382\n",
      "[7212/8000] D loss: 0.2067, G loss: 9.5750\n",
      "[7572/8000] D loss: 0.1356, G loss: 10.7114\n",
      "[7932/8000] D loss: 0.2603, G loss: 10.9525\n",
      "train error: \n",
      " D loss: 0.219875, G loss: 10.625353, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 10.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.560501, G loss: 14.064955, D accuracy: 92.8%, cell accuracy: 94.0%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0071, G loss: 13.8997\n",
      "[372/8000] D loss: 0.0050, G loss: 12.5621\n",
      "[732/8000] D loss: 0.0386, G loss: 14.5186\n",
      "[1092/8000] D loss: 0.3383, G loss: 10.4891\n",
      "[1452/8000] D loss: 0.0252, G loss: 12.9118\n",
      "[1812/8000] D loss: 0.2454, G loss: 10.1887\n",
      "[2172/8000] D loss: 0.0452, G loss: 10.1671\n",
      "[2532/8000] D loss: 0.0397, G loss: 12.1432\n",
      "[2892/8000] D loss: 0.0370, G loss: 11.5261\n",
      "[3252/8000] D loss: 0.1291, G loss: 10.1198\n",
      "[3612/8000] D loss: 0.5184, G loss: 10.1398\n",
      "[3972/8000] D loss: 0.0539, G loss: 9.9636\n",
      "[4332/8000] D loss: 0.2853, G loss: 12.6654\n",
      "[4692/8000] D loss: 0.1585, G loss: 9.0516\n",
      "[5052/8000] D loss: 0.3325, G loss: 6.4095\n",
      "[5412/8000] D loss: 0.2697, G loss: 10.4336\n",
      "[5772/8000] D loss: 0.5632, G loss: 6.8445\n",
      "[6132/8000] D loss: 0.2444, G loss: 9.9124\n",
      "[6492/8000] D loss: 0.0414, G loss: 10.5360\n",
      "[6852/8000] D loss: 0.2359, G loss: 11.7154\n",
      "[7212/8000] D loss: 0.1320, G loss: 10.6133\n",
      "[7572/8000] D loss: 0.1955, G loss: 9.8184\n",
      "[7932/8000] D loss: 0.2511, G loss: 9.1488\n",
      "train error: \n",
      " D loss: 0.224862, G loss: 9.303259, D accuracy: 93.6%, cell accuracy: 94.4%, board accuracy: 11.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.470531, G loss: 12.576596, D accuracy: 93.5%, cell accuracy: 94.0%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0691, G loss: 9.0180\n",
      "[372/8000] D loss: 0.0948, G loss: 10.2994\n",
      "[732/8000] D loss: 0.0784, G loss: 9.5975\n",
      "[1092/8000] D loss: 0.1449, G loss: 8.7766\n",
      "[1452/8000] D loss: 0.1435, G loss: 10.9234\n",
      "[1812/8000] D loss: 0.3704, G loss: 8.1551\n",
      "[2172/8000] D loss: 0.3684, G loss: 4.7304\n",
      "[2532/8000] D loss: 0.1971, G loss: 8.5696\n",
      "[2892/8000] D loss: 0.5425, G loss: 8.0733\n",
      "[3252/8000] D loss: 0.1977, G loss: 10.8706\n",
      "[3612/8000] D loss: 0.1177, G loss: 10.1374\n",
      "[3972/8000] D loss: 0.1435, G loss: 13.5762\n",
      "[4332/8000] D loss: 0.1168, G loss: 13.2125\n",
      "[4692/8000] D loss: 0.1361, G loss: 9.0589\n",
      "[5052/8000] D loss: 0.2106, G loss: 9.9002\n",
      "[5412/8000] D loss: 0.1596, G loss: 10.4770\n",
      "[5772/8000] D loss: 0.4721, G loss: 8.5386\n",
      "[6132/8000] D loss: 0.0488, G loss: 9.5943\n",
      "[6492/8000] D loss: 0.1946, G loss: 11.3905\n",
      "[6852/8000] D loss: 0.0196, G loss: 14.3694\n",
      "[7212/8000] D loss: 0.0112, G loss: 10.4159\n",
      "[7572/8000] D loss: 0.1766, G loss: 11.9125\n",
      "[7932/8000] D loss: 0.1024, G loss: 7.4429\n",
      "train error: \n",
      " D loss: 0.226989, G loss: 10.562966, D accuracy: 93.7%, cell accuracy: 94.4%, board accuracy: 10.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.517464, G loss: 14.003064, D accuracy: 93.5%, cell accuracy: 94.0%, board accuracy: 4.9% \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4771, G loss: 5.9190\n",
      "[372/8000] D loss: 0.1172, G loss: 9.3628\n",
      "[732/8000] D loss: 0.4472, G loss: 11.5812\n",
      "[1092/8000] D loss: 0.1730, G loss: 8.0724\n",
      "[1452/8000] D loss: 0.2641, G loss: 10.1938\n",
      "[1812/8000] D loss: 0.1146, G loss: 10.1293\n",
      "[2172/8000] D loss: 0.1432, G loss: 8.4871\n",
      "[2532/8000] D loss: 0.2117, G loss: 11.7325\n",
      "[2892/8000] D loss: 0.2085, G loss: 11.7580\n",
      "[3252/8000] D loss: 0.3613, G loss: 7.5481\n",
      "[3612/8000] D loss: 0.0438, G loss: 10.9505\n",
      "[3972/8000] D loss: 0.2378, G loss: 10.0262\n",
      "[4332/8000] D loss: 0.1337, G loss: 10.9677\n",
      "[4692/8000] D loss: 0.5617, G loss: 6.8582\n",
      "[5052/8000] D loss: 0.2584, G loss: 8.1081\n",
      "[5412/8000] D loss: 0.2328, G loss: 10.7133\n",
      "[5772/8000] D loss: 0.2606, G loss: 8.4968\n",
      "[6132/8000] D loss: 0.2504, G loss: 10.2834\n",
      "[6492/8000] D loss: 0.3521, G loss: 15.2774\n",
      "[6852/8000] D loss: 0.4439, G loss: 10.2081\n",
      "[7212/8000] D loss: 0.1268, G loss: 9.0431\n",
      "[7572/8000] D loss: 0.0131, G loss: 11.4481\n",
      "[7932/8000] D loss: 0.1454, G loss: 12.6869\n",
      "train error: \n",
      " D loss: 0.226829, G loss: 9.629602, D accuracy: 93.7%, cell accuracy: 94.4%, board accuracy: 11.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.487250, G loss: 13.078047, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2604, G loss: 8.4718\n",
      "[372/8000] D loss: 0.2870, G loss: 9.9454\n",
      "[732/8000] D loss: 0.3093, G loss: 8.4599\n",
      "[1092/8000] D loss: 0.1223, G loss: 9.9912\n",
      "[1452/8000] D loss: 0.3589, G loss: 10.4119\n",
      "[1812/8000] D loss: 0.2900, G loss: 7.9033\n",
      "[2172/8000] D loss: 0.1804, G loss: 8.0203\n",
      "[2532/8000] D loss: 0.3197, G loss: 5.9411\n",
      "[2892/8000] D loss: 0.2600, G loss: 13.2472\n",
      "[3252/8000] D loss: 0.0111, G loss: 12.2706\n",
      "[3612/8000] D loss: 0.1085, G loss: 10.7554\n",
      "[3972/8000] D loss: 0.0881, G loss: 11.7366\n",
      "[4332/8000] D loss: 0.4642, G loss: 10.3793\n",
      "[4692/8000] D loss: 0.1886, G loss: 8.6765\n",
      "[5052/8000] D loss: 0.0742, G loss: 13.0762\n",
      "[5412/8000] D loss: 0.1147, G loss: 12.6002\n",
      "[5772/8000] D loss: 0.2833, G loss: 8.4952\n",
      "[6132/8000] D loss: 0.3744, G loss: 6.6609\n",
      "[6492/8000] D loss: 0.1587, G loss: 8.6988\n",
      "[6852/8000] D loss: 0.1322, G loss: 9.1572\n",
      "[7212/8000] D loss: 0.2233, G loss: 9.9596\n",
      "[7572/8000] D loss: 0.0395, G loss: 10.8940\n",
      "[7932/8000] D loss: 0.1101, G loss: 10.5210\n",
      "train error: \n",
      " D loss: 0.252816, G loss: 9.014247, D accuracy: 93.4%, cell accuracy: 94.4%, board accuracy: 11.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.453558, G loss: 12.328544, D accuracy: 94.1%, cell accuracy: 94.0%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5019, G loss: 10.0847\n",
      "[372/8000] D loss: 0.0813, G loss: 10.9504\n",
      "[732/8000] D loss: 0.1858, G loss: 6.6880\n",
      "[1092/8000] D loss: 0.4124, G loss: 9.3909\n",
      "[1452/8000] D loss: 0.1133, G loss: 12.0296\n",
      "[1812/8000] D loss: 0.0092, G loss: 10.2852\n",
      "[2172/8000] D loss: 0.2384, G loss: 9.9703\n",
      "[2532/8000] D loss: 0.6306, G loss: 5.6405\n",
      "[2892/8000] D loss: 0.1363, G loss: 7.1595\n",
      "[3252/8000] D loss: 0.0293, G loss: 10.2250\n",
      "[3612/8000] D loss: 0.2548, G loss: 8.2063\n",
      "[3972/8000] D loss: 0.0155, G loss: 9.6327\n",
      "[4332/8000] D loss: 0.6232, G loss: 8.2837\n",
      "[4692/8000] D loss: 0.5599, G loss: 7.9943\n",
      "[5052/8000] D loss: 0.3785, G loss: 6.3690\n",
      "[5412/8000] D loss: 0.1473, G loss: 10.0120\n",
      "[5772/8000] D loss: 0.3562, G loss: 7.6356\n",
      "[6132/8000] D loss: 0.2651, G loss: 10.2885\n",
      "[6492/8000] D loss: 0.2910, G loss: 9.9379\n",
      "[6852/8000] D loss: 0.0092, G loss: 9.6003\n",
      "[7212/8000] D loss: 0.2073, G loss: 9.4001\n",
      "[7572/8000] D loss: 0.3429, G loss: 7.2324\n",
      "[7932/8000] D loss: 0.2625, G loss: 10.7139\n",
      "train error: \n",
      " D loss: 0.230779, G loss: 9.452776, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 10.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.489504, G loss: 12.657437, D accuracy: 93.6%, cell accuracy: 94.0%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3953, G loss: 8.4889\n",
      "[372/8000] D loss: 0.1426, G loss: 12.1875\n",
      "[732/8000] D loss: 0.0241, G loss: 9.4749\n",
      "[1092/8000] D loss: 0.1535, G loss: 11.7449\n",
      "[1452/8000] D loss: 0.2736, G loss: 8.0344\n",
      "[1812/8000] D loss: 0.1572, G loss: 8.2276\n",
      "[2172/8000] D loss: 0.2100, G loss: 9.3842\n",
      "[2532/8000] D loss: 0.4074, G loss: 10.2760\n",
      "[2892/8000] D loss: 0.0589, G loss: 10.1918\n",
      "[3252/8000] D loss: 0.2475, G loss: 11.6391\n",
      "[3612/8000] D loss: 0.3002, G loss: 7.8621\n",
      "[3972/8000] D loss: 0.2198, G loss: 12.2664\n",
      "[4332/8000] D loss: 0.1449, G loss: 9.2177\n",
      "[4692/8000] D loss: 0.2465, G loss: 10.7468\n",
      "[5052/8000] D loss: 0.0059, G loss: 9.9366\n",
      "[5412/8000] D loss: 0.3338, G loss: 9.5176\n",
      "[5772/8000] D loss: 0.3835, G loss: 10.7141\n",
      "[6132/8000] D loss: 0.3390, G loss: 10.3705\n",
      "[6492/8000] D loss: 0.4660, G loss: 10.5832\n",
      "[6852/8000] D loss: 0.1636, G loss: 12.5363\n",
      "[7212/8000] D loss: 0.1370, G loss: 10.5721\n",
      "[7572/8000] D loss: 0.0169, G loss: 12.3445\n",
      "[7932/8000] D loss: 0.1274, G loss: 11.5221\n",
      "train error: \n",
      " D loss: 0.220581, G loss: 10.394660, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 10.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.510817, G loss: 13.898346, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3513, G loss: 9.7715\n",
      "[372/8000] D loss: 0.4567, G loss: 6.5616\n",
      "[732/8000] D loss: 0.0409, G loss: 11.3589\n",
      "[1092/8000] D loss: 0.1471, G loss: 7.8101\n",
      "[1452/8000] D loss: 0.2670, G loss: 12.6043\n",
      "[1812/8000] D loss: 0.1479, G loss: 9.4372\n",
      "[2172/8000] D loss: 0.2010, G loss: 10.2298\n",
      "[2532/8000] D loss: 0.2159, G loss: 10.0997\n",
      "[2892/8000] D loss: 0.2625, G loss: 11.0787\n",
      "[3252/8000] D loss: 0.3425, G loss: 8.6005\n",
      "[3612/8000] D loss: 0.0104, G loss: 15.6517\n",
      "[3972/8000] D loss: 0.1723, G loss: 7.8330\n",
      "[4332/8000] D loss: 0.1242, G loss: 10.3428\n",
      "[4692/8000] D loss: 0.1142, G loss: 13.3585\n",
      "[5052/8000] D loss: 0.0031, G loss: 10.3437\n",
      "[5412/8000] D loss: 0.3581, G loss: 7.5080\n",
      "[5772/8000] D loss: 0.5466, G loss: 8.0014\n",
      "[6132/8000] D loss: 0.2670, G loss: 11.9064\n",
      "[6492/8000] D loss: 0.2468, G loss: 8.6661\n",
      "[6852/8000] D loss: 0.1175, G loss: 11.8655\n",
      "[7212/8000] D loss: 0.0118, G loss: 10.1119\n",
      "[7572/8000] D loss: 0.2763, G loss: 9.5025\n",
      "[7932/8000] D loss: 0.4629, G loss: 6.8627\n",
      "train error: \n",
      " D loss: 0.217108, G loss: 9.802555, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 11.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.484693, G loss: 13.339244, D accuracy: 93.8%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0679, G loss: 13.4581\n",
      "[372/8000] D loss: 0.3876, G loss: 6.5752\n",
      "[732/8000] D loss: 0.3696, G loss: 10.0460\n",
      "[1092/8000] D loss: 0.5128, G loss: 10.1803\n",
      "[1452/8000] D loss: 0.0668, G loss: 10.4192\n",
      "[1812/8000] D loss: 0.2769, G loss: 8.7344\n",
      "[2172/8000] D loss: 0.6068, G loss: 5.8638\n",
      "[2532/8000] D loss: 0.3369, G loss: 6.6320\n",
      "[2892/8000] D loss: 0.1321, G loss: 13.7316\n",
      "[3252/8000] D loss: 0.3429, G loss: 10.5482\n",
      "[3612/8000] D loss: 0.2285, G loss: 11.8662\n",
      "[3972/8000] D loss: 0.3259, G loss: 10.9339\n",
      "[4332/8000] D loss: 0.3215, G loss: 8.1089\n",
      "[4692/8000] D loss: 0.1274, G loss: 9.1150\n",
      "[5052/8000] D loss: 0.2531, G loss: 7.4873\n",
      "[5412/8000] D loss: 0.0246, G loss: 14.2586\n",
      "[5772/8000] D loss: 0.3800, G loss: 12.0965\n",
      "[6132/8000] D loss: 0.0255, G loss: 11.8153\n",
      "[6492/8000] D loss: 0.0444, G loss: 11.4406\n",
      "[6852/8000] D loss: 0.5354, G loss: 12.6291\n",
      "[7212/8000] D loss: 0.4329, G loss: 5.1984\n",
      "[7572/8000] D loss: 0.2656, G loss: 11.4565\n",
      "[7932/8000] D loss: 0.2551, G loss: 7.9241\n",
      "train error: \n",
      " D loss: 0.244068, G loss: 9.635370, D accuracy: 93.4%, cell accuracy: 94.5%, board accuracy: 10.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.511922, G loss: 12.837790, D accuracy: 91.7%, cell accuracy: 94.0%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2097, G loss: 11.4696\n",
      "[372/8000] D loss: 0.0163, G loss: 10.6768\n",
      "[732/8000] D loss: 0.1622, G loss: 9.1996\n",
      "[1092/8000] D loss: 0.2333, G loss: 9.7385\n",
      "[1452/8000] D loss: 0.3554, G loss: 9.2953\n",
      "[1812/8000] D loss: 0.1258, G loss: 12.6610\n",
      "[2172/8000] D loss: 0.3043, G loss: 12.1514\n",
      "[2532/8000] D loss: 0.1922, G loss: 10.2072\n",
      "[2892/8000] D loss: 0.1372, G loss: 12.8447\n",
      "[3252/8000] D loss: 0.2346, G loss: 13.8619\n",
      "[3612/8000] D loss: 0.2693, G loss: 7.4155\n",
      "[3972/8000] D loss: 0.2768, G loss: 11.2578\n",
      "[4332/8000] D loss: 0.0668, G loss: 8.5052\n",
      "[4692/8000] D loss: 0.2577, G loss: 12.2245\n",
      "[5052/8000] D loss: 0.3182, G loss: 7.8179\n",
      "[5412/8000] D loss: 0.2404, G loss: 7.1674\n",
      "[5772/8000] D loss: 0.5393, G loss: 6.8280\n",
      "[6132/8000] D loss: 0.2341, G loss: 9.8484\n",
      "[6492/8000] D loss: 0.2846, G loss: 10.8741\n",
      "[6852/8000] D loss: 0.1027, G loss: 10.7308\n",
      "[7212/8000] D loss: 0.2447, G loss: 10.5207\n",
      "[7572/8000] D loss: 0.1598, G loss: 13.1890\n",
      "[7932/8000] D loss: 0.1384, G loss: 10.8890\n",
      "train error: \n",
      " D loss: 0.220175, G loss: 9.857635, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 10.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.497981, G loss: 13.200505, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0050, G loss: 10.6527\n",
      "[372/8000] D loss: 0.2594, G loss: 11.3363\n",
      "[732/8000] D loss: 0.1285, G loss: 11.7431\n",
      "[1092/8000] D loss: 0.3526, G loss: 9.5528\n",
      "[1452/8000] D loss: 0.2022, G loss: 9.7613\n",
      "[1812/8000] D loss: 0.3122, G loss: 7.4914\n",
      "[2172/8000] D loss: 0.0915, G loss: 10.3346\n",
      "[2532/8000] D loss: 0.0156, G loss: 8.7360\n",
      "[2892/8000] D loss: 0.2303, G loss: 15.2219\n",
      "[3252/8000] D loss: 0.0067, G loss: 10.9622\n",
      "[3612/8000] D loss: 0.1284, G loss: 11.4406\n",
      "[3972/8000] D loss: 0.3287, G loss: 8.6277\n",
      "[4332/8000] D loss: 0.0707, G loss: 9.5231\n",
      "[4692/8000] D loss: 0.0056, G loss: 10.5346\n",
      "[5052/8000] D loss: 0.2417, G loss: 7.5405\n",
      "[5412/8000] D loss: 0.1590, G loss: 9.8186\n",
      "[5772/8000] D loss: 0.3115, G loss: 9.6082\n",
      "[6132/8000] D loss: 0.2906, G loss: 13.4529\n",
      "[6492/8000] D loss: 0.0821, G loss: 7.9486\n",
      "[6852/8000] D loss: 0.2856, G loss: 8.3529\n",
      "[7212/8000] D loss: 0.1480, G loss: 12.2220\n",
      "[7572/8000] D loss: 0.1227, G loss: 14.2785\n",
      "[7932/8000] D loss: 0.0056, G loss: 12.0792\n",
      "train error: \n",
      " D loss: 0.216006, G loss: 9.981574, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 10.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.502927, G loss: 13.371386, D accuracy: 93.1%, cell accuracy: 94.0%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2377, G loss: 10.0264\n",
      "[372/8000] D loss: 0.2393, G loss: 11.7440\n",
      "[732/8000] D loss: 0.3437, G loss: 10.4631\n",
      "[1092/8000] D loss: 0.2089, G loss: 9.8963\n",
      "[1452/8000] D loss: 0.3865, G loss: 8.8159\n",
      "[1812/8000] D loss: 0.1295, G loss: 10.9207\n",
      "[2172/8000] D loss: 0.1209, G loss: 12.3664\n",
      "[2532/8000] D loss: 0.1951, G loss: 9.5770\n",
      "[2892/8000] D loss: 0.1987, G loss: 9.4734\n",
      "[3252/8000] D loss: 0.2741, G loss: 11.2170\n",
      "[3612/8000] D loss: 0.0027, G loss: 14.4565\n",
      "[3972/8000] D loss: 0.2487, G loss: 11.4271\n",
      "[4332/8000] D loss: 0.1527, G loss: 9.4734\n",
      "[4692/8000] D loss: 0.1728, G loss: 9.7458\n",
      "[5052/8000] D loss: 0.1092, G loss: 12.7413\n",
      "[5412/8000] D loss: 0.4014, G loss: 10.0827\n",
      "[5772/8000] D loss: 0.1769, G loss: 7.0004\n",
      "[6132/8000] D loss: 0.0024, G loss: 12.3117\n",
      "[6492/8000] D loss: 0.1829, G loss: 9.6469\n",
      "[6852/8000] D loss: 0.1648, G loss: 9.0275\n",
      "[7212/8000] D loss: 0.2406, G loss: 8.4149\n",
      "[7572/8000] D loss: 0.3426, G loss: 7.0602\n",
      "[7932/8000] D loss: 0.0191, G loss: 12.7740\n",
      "train error: \n",
      " D loss: 0.244343, G loss: 10.843641, D accuracy: 93.3%, cell accuracy: 94.4%, board accuracy: 11.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609795, G loss: 14.075238, D accuracy: 91.7%, cell accuracy: 94.1%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4308, G loss: 7.2820\n",
      "[372/8000] D loss: 0.0466, G loss: 8.5651\n",
      "[732/8000] D loss: 0.2674, G loss: 8.9422\n",
      "[1092/8000] D loss: 0.3762, G loss: 8.2433\n",
      "[1452/8000] D loss: 0.3032, G loss: 9.2845\n",
      "[1812/8000] D loss: 0.1164, G loss: 14.5053\n",
      "[2172/8000] D loss: 0.2866, G loss: 10.2252\n",
      "[2532/8000] D loss: 0.0272, G loss: 9.8417\n",
      "[2892/8000] D loss: 0.0211, G loss: 9.9193\n",
      "[3252/8000] D loss: 0.1943, G loss: 9.0492\n",
      "[3612/8000] D loss: 0.3043, G loss: 10.3442\n",
      "[3972/8000] D loss: 0.1254, G loss: 11.0759\n",
      "[4332/8000] D loss: 0.2749, G loss: 11.0115\n",
      "[4692/8000] D loss: 0.4698, G loss: 6.7618\n",
      "[5052/8000] D loss: 0.2558, G loss: 10.2607\n",
      "[5412/8000] D loss: 0.0275, G loss: 15.1478\n",
      "[5772/8000] D loss: 0.5379, G loss: 5.9490\n",
      "[6132/8000] D loss: 0.2503, G loss: 11.5652\n",
      "[6492/8000] D loss: 0.2113, G loss: 8.6238\n",
      "[6852/8000] D loss: 0.1416, G loss: 13.1334\n",
      "[7212/8000] D loss: 0.1322, G loss: 12.8910\n",
      "[7572/8000] D loss: 0.1580, G loss: 12.4216\n",
      "[7932/8000] D loss: 0.0458, G loss: 10.7073\n",
      "train error: \n",
      " D loss: 0.226273, G loss: 9.213485, D accuracy: 93.7%, cell accuracy: 94.4%, board accuracy: 10.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.443188, G loss: 12.527141, D accuracy: 93.6%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3323, G loss: 7.8358\n",
      "[372/8000] D loss: 0.2165, G loss: 11.8252\n",
      "[732/8000] D loss: 0.4282, G loss: 8.3477\n",
      "[1092/8000] D loss: 0.0345, G loss: 11.6128\n",
      "[1452/8000] D loss: 0.2448, G loss: 11.3038\n",
      "[1812/8000] D loss: 0.1479, G loss: 9.9406\n",
      "[2172/8000] D loss: 0.1809, G loss: 7.9821\n",
      "[2532/8000] D loss: 0.1803, G loss: 10.7327\n",
      "[2892/8000] D loss: 0.0270, G loss: 11.8592\n",
      "[3252/8000] D loss: 0.2164, G loss: 9.6871\n",
      "[3612/8000] D loss: 0.5648, G loss: 6.6470\n",
      "[3972/8000] D loss: 0.1918, G loss: 8.2061\n",
      "[4332/8000] D loss: 0.2344, G loss: 9.0074\n",
      "[4692/8000] D loss: 0.2689, G loss: 11.0019\n",
      "[5052/8000] D loss: 0.0312, G loss: 9.7016\n",
      "[5412/8000] D loss: 0.2148, G loss: 9.7841\n",
      "[5772/8000] D loss: 0.1556, G loss: 12.1260\n",
      "[6132/8000] D loss: 0.6352, G loss: 10.1646\n",
      "[6492/8000] D loss: 0.1504, G loss: 8.4279\n",
      "[6852/8000] D loss: 0.2858, G loss: 8.7612\n",
      "[7212/8000] D loss: 0.1408, G loss: 13.2143\n",
      "[7572/8000] D loss: 0.3157, G loss: 9.2986\n",
      "[7932/8000] D loss: 0.1119, G loss: 8.9596\n",
      "train error: \n",
      " D loss: 0.223633, G loss: 10.014968, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 11.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.523810, G loss: 13.190238, D accuracy: 92.5%, cell accuracy: 94.0%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3691, G loss: 9.9688\n",
      "[372/8000] D loss: 0.2544, G loss: 10.3742\n",
      "[732/8000] D loss: 0.1496, G loss: 9.0319\n",
      "[1092/8000] D loss: 0.1550, G loss: 10.4074\n",
      "[1452/8000] D loss: 0.2776, G loss: 9.5420\n",
      "[1812/8000] D loss: 0.1662, G loss: 7.8076\n",
      "[2172/8000] D loss: 0.2934, G loss: 7.6693\n",
      "[2532/8000] D loss: 0.1055, G loss: 11.2809\n",
      "[2892/8000] D loss: 0.3197, G loss: 6.6262\n",
      "[3252/8000] D loss: 0.5847, G loss: 9.6593\n",
      "[3612/8000] D loss: 0.0005, G loss: 14.7460\n",
      "[3972/8000] D loss: 0.1321, G loss: 12.5525\n",
      "[4332/8000] D loss: 0.1561, G loss: 12.0782\n",
      "[4692/8000] D loss: 0.0029, G loss: 10.3776\n",
      "[5052/8000] D loss: 0.1712, G loss: 11.0665\n",
      "[5412/8000] D loss: 0.2026, G loss: 8.4107\n",
      "[5772/8000] D loss: 0.5224, G loss: 6.6809\n",
      "[6132/8000] D loss: 0.3854, G loss: 10.0054\n",
      "[6492/8000] D loss: 0.0268, G loss: 11.9418\n",
      "[6852/8000] D loss: 0.0625, G loss: 9.1867\n",
      "[7212/8000] D loss: 0.0748, G loss: 14.3476\n",
      "[7572/8000] D loss: 0.1612, G loss: 9.0228\n",
      "[7932/8000] D loss: 0.3516, G loss: 10.6901\n",
      "train error: \n",
      " D loss: 0.222319, G loss: 10.051370, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 11.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.510376, G loss: 13.444461, D accuracy: 93.1%, cell accuracy: 94.0%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1730, G loss: 9.6741\n",
      "[372/8000] D loss: 0.2921, G loss: 9.7486\n",
      "[732/8000] D loss: 0.2224, G loss: 8.8034\n",
      "[1092/8000] D loss: 0.4102, G loss: 9.4769\n",
      "[1452/8000] D loss: 0.3025, G loss: 9.0585\n",
      "[1812/8000] D loss: 0.0455, G loss: 10.3737\n",
      "[2172/8000] D loss: 0.4510, G loss: 8.9068\n",
      "[2532/8000] D loss: 0.1170, G loss: 13.4138\n",
      "[2892/8000] D loss: 0.2379, G loss: 15.5505\n",
      "[3252/8000] D loss: 0.1860, G loss: 9.7572\n",
      "[3612/8000] D loss: 0.4134, G loss: 7.4425\n",
      "[3972/8000] D loss: 0.1196, G loss: 9.1437\n",
      "[4332/8000] D loss: 0.1769, G loss: 11.1021\n",
      "[4692/8000] D loss: 0.1330, G loss: 10.9212\n",
      "[5052/8000] D loss: 0.0750, G loss: 11.8561\n",
      "[5412/8000] D loss: 0.1714, G loss: 10.1335\n",
      "[5772/8000] D loss: 0.1247, G loss: 14.7248\n",
      "[6132/8000] D loss: 0.3178, G loss: 9.6097\n",
      "[6492/8000] D loss: 0.0076, G loss: 13.1782\n",
      "[6852/8000] D loss: 0.2722, G loss: 11.4753\n",
      "[7212/8000] D loss: 0.3336, G loss: 6.7570\n",
      "[7572/8000] D loss: 0.1458, G loss: 9.1294\n",
      "[7932/8000] D loss: 0.1575, G loss: 14.0397\n",
      "train error: \n",
      " D loss: 0.220678, G loss: 9.947284, D accuracy: 93.9%, cell accuracy: 94.4%, board accuracy: 10.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.521562, G loss: 13.305971, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1391, G loss: 7.0028\n",
      "[372/8000] D loss: 0.1631, G loss: 10.1669\n",
      "[732/8000] D loss: 0.5941, G loss: 6.5632\n",
      "[1092/8000] D loss: 0.4477, G loss: 10.3708\n",
      "[1452/8000] D loss: 0.2082, G loss: 13.9269\n",
      "[1812/8000] D loss: 0.1364, G loss: 10.7421\n",
      "[2172/8000] D loss: 0.1236, G loss: 11.5321\n",
      "[2532/8000] D loss: 0.3414, G loss: 10.7231\n",
      "[2892/8000] D loss: 0.0972, G loss: 13.9375\n",
      "[3252/8000] D loss: 0.3937, G loss: 9.3313\n",
      "[3612/8000] D loss: 0.1601, G loss: 12.0027\n",
      "[3972/8000] D loss: 0.4241, G loss: 11.6554\n",
      "[4332/8000] D loss: 0.2239, G loss: 11.4910\n",
      "[4692/8000] D loss: 0.3395, G loss: 9.7001\n",
      "[5052/8000] D loss: 0.0067, G loss: 16.6870\n",
      "[5412/8000] D loss: 0.1204, G loss: 8.9169\n",
      "[5772/8000] D loss: 0.1630, G loss: 14.6793\n",
      "[6132/8000] D loss: 0.2713, G loss: 8.6680\n",
      "[6492/8000] D loss: 0.3231, G loss: 11.5974\n",
      "[6852/8000] D loss: 0.1845, G loss: 9.1683\n",
      "[7212/8000] D loss: 0.2831, G loss: 6.9397\n",
      "[7572/8000] D loss: 0.1114, G loss: 9.3886\n",
      "[7932/8000] D loss: 0.1813, G loss: 12.0290\n",
      "train error: \n",
      " D loss: 0.230558, G loss: 10.672898, D accuracy: 93.6%, cell accuracy: 94.4%, board accuracy: 10.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.580577, G loss: 14.095207, D accuracy: 91.9%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2587, G loss: 7.7895\n",
      "[372/8000] D loss: 0.2020, G loss: 10.7124\n",
      "[732/8000] D loss: 0.2455, G loss: 9.8622\n",
      "[1092/8000] D loss: 0.4135, G loss: 9.1662\n",
      "[1452/8000] D loss: 0.0138, G loss: 14.6521\n",
      "[1812/8000] D loss: 0.1613, G loss: 10.0588\n",
      "[2172/8000] D loss: 0.3951, G loss: 12.2674\n",
      "[2532/8000] D loss: 0.0102, G loss: 12.4165\n",
      "[2892/8000] D loss: 0.2281, G loss: 10.5963\n",
      "[3252/8000] D loss: 0.0229, G loss: 11.7080\n",
      "[3612/8000] D loss: 0.2010, G loss: 7.9245\n",
      "[3972/8000] D loss: 0.3921, G loss: 8.7149\n",
      "[4332/8000] D loss: 0.5220, G loss: 6.8548\n",
      "[4692/8000] D loss: 0.5088, G loss: 9.0765\n",
      "[5052/8000] D loss: 0.2690, G loss: 10.0659\n",
      "[5412/8000] D loss: 0.1387, G loss: 11.8464\n",
      "[5772/8000] D loss: 0.3653, G loss: 9.7782\n",
      "[6132/8000] D loss: 0.2842, G loss: 8.5498\n",
      "[6492/8000] D loss: 0.4863, G loss: 7.8049\n",
      "[6852/8000] D loss: 0.1240, G loss: 11.8573\n",
      "[7212/8000] D loss: 0.3028, G loss: 8.9765\n",
      "[7572/8000] D loss: 0.1463, G loss: 10.7515\n",
      "[7932/8000] D loss: 0.2673, G loss: 10.5803\n",
      "train error: \n",
      " D loss: 0.242555, G loss: 8.854740, D accuracy: 93.4%, cell accuracy: 94.4%, board accuracy: 11.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.450164, G loss: 12.161492, D accuracy: 93.9%, cell accuracy: 93.9%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4380, G loss: 7.8575\n",
      "[372/8000] D loss: 0.2608, G loss: 10.0899\n",
      "[732/8000] D loss: 0.4577, G loss: 7.5816\n",
      "[1092/8000] D loss: 0.3328, G loss: 11.5278\n",
      "[1452/8000] D loss: 0.3259, G loss: 7.5365\n",
      "[1812/8000] D loss: 0.0349, G loss: 10.4351\n",
      "[2172/8000] D loss: 0.1385, G loss: 11.1817\n",
      "[2532/8000] D loss: 0.0813, G loss: 16.7358\n",
      "[2892/8000] D loss: 0.4894, G loss: 10.4756\n",
      "[3252/8000] D loss: 0.1698, G loss: 8.4996\n",
      "[3612/8000] D loss: 0.0070, G loss: 12.0470\n",
      "[3972/8000] D loss: 0.1827, G loss: 11.1233\n",
      "[4332/8000] D loss: 0.0376, G loss: 15.2599\n",
      "[4692/8000] D loss: 0.0866, G loss: 11.0337\n",
      "[5052/8000] D loss: 0.2129, G loss: 7.7859\n",
      "[5412/8000] D loss: 0.2013, G loss: 10.5797\n",
      "[5772/8000] D loss: 0.3461, G loss: 14.8396\n",
      "[6132/8000] D loss: 0.6796, G loss: 8.5592\n",
      "[6492/8000] D loss: 0.0486, G loss: 10.2320\n",
      "[6852/8000] D loss: 0.1156, G loss: 11.4774\n",
      "[7212/8000] D loss: 0.3454, G loss: 11.1813\n",
      "[7572/8000] D loss: 0.1445, G loss: 16.8412\n",
      "[7932/8000] D loss: 0.4244, G loss: 7.4580\n",
      "train error: \n",
      " D loss: 0.226551, G loss: 11.625351, D accuracy: 93.4%, cell accuracy: 94.4%, board accuracy: 11.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608505, G loss: 15.275993, D accuracy: 91.7%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0126, G loss: 13.8826\n",
      "[372/8000] D loss: 0.5960, G loss: 5.8022\n",
      "[732/8000] D loss: 0.4854, G loss: 8.1765\n",
      "[1092/8000] D loss: 0.0110, G loss: 15.0275\n",
      "[1452/8000] D loss: 0.3748, G loss: 11.3024\n",
      "[1812/8000] D loss: 0.4560, G loss: 7.9120\n",
      "[2172/8000] D loss: 0.4998, G loss: 8.3893\n",
      "[2532/8000] D loss: 0.0539, G loss: 13.4922\n",
      "[2892/8000] D loss: 0.0706, G loss: 12.2057\n",
      "[3252/8000] D loss: 0.1243, G loss: 11.6666\n",
      "[3612/8000] D loss: 0.0080, G loss: 11.3791\n",
      "[3972/8000] D loss: 0.2296, G loss: 9.4785\n",
      "[4332/8000] D loss: 0.2975, G loss: 8.4756\n",
      "[4692/8000] D loss: 0.1626, G loss: 9.5881\n",
      "[5052/8000] D loss: 0.3504, G loss: 8.4981\n",
      "[5412/8000] D loss: 0.2568, G loss: 9.9782\n",
      "[5772/8000] D loss: 0.1075, G loss: 13.0677\n",
      "[6132/8000] D loss: 0.1658, G loss: 8.2571\n",
      "[6492/8000] D loss: 0.4277, G loss: 6.2152\n",
      "[6852/8000] D loss: 0.3835, G loss: 12.1657\n",
      "[7212/8000] D loss: 0.1458, G loss: 8.2619\n",
      "[7572/8000] D loss: 0.1608, G loss: 9.9140\n",
      "[7932/8000] D loss: 0.0543, G loss: 11.9564\n",
      "train error: \n",
      " D loss: 0.239593, G loss: 9.778384, D accuracy: 93.3%, cell accuracy: 94.4%, board accuracy: 11.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.534325, G loss: 13.091627, D accuracy: 92.9%, cell accuracy: 94.0%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2335, G loss: 8.6218\n",
      "[372/8000] D loss: 0.5000, G loss: 6.3961\n",
      "[732/8000] D loss: 0.0153, G loss: 10.0751\n",
      "[1092/8000] D loss: 0.2028, G loss: 8.0111\n",
      "[1452/8000] D loss: 0.4223, G loss: 10.8740\n",
      "[1812/8000] D loss: 0.2746, G loss: 10.8148\n",
      "[2172/8000] D loss: 0.0682, G loss: 9.0709\n",
      "[2532/8000] D loss: 0.2636, G loss: 15.5162\n",
      "[2892/8000] D loss: 0.2205, G loss: 12.6736\n",
      "[3252/8000] D loss: 0.3172, G loss: 9.1208\n",
      "[3612/8000] D loss: 0.4892, G loss: 7.5308\n",
      "[3972/8000] D loss: 0.2123, G loss: 9.7428\n",
      "[4332/8000] D loss: 0.1374, G loss: 10.3145\n",
      "[4692/8000] D loss: 0.2150, G loss: 9.7429\n",
      "[5052/8000] D loss: 0.1750, G loss: 9.3410\n",
      "[5412/8000] D loss: 0.2293, G loss: 12.6607\n",
      "[5772/8000] D loss: 0.0839, G loss: 8.9502\n",
      "[6132/8000] D loss: 0.1562, G loss: 11.0382\n",
      "[6492/8000] D loss: 0.1372, G loss: 12.7454\n",
      "[6852/8000] D loss: 0.2419, G loss: 8.2880\n",
      "[7212/8000] D loss: 0.1283, G loss: 12.1532\n",
      "[7572/8000] D loss: 0.0616, G loss: 11.7160\n",
      "[7932/8000] D loss: 0.3517, G loss: 9.1863\n",
      "train error: \n",
      " D loss: 0.231391, G loss: 9.584639, D accuracy: 93.8%, cell accuracy: 94.4%, board accuracy: 10.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.492978, G loss: 12.973723, D accuracy: 93.5%, cell accuracy: 94.0%, board accuracy: 4.6% \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1533, G loss: 9.6705\n",
      "[372/8000] D loss: 0.1197, G loss: 10.3551\n",
      "[732/8000] D loss: 0.4084, G loss: 8.4930\n",
      "[1092/8000] D loss: 0.0201, G loss: 8.4754\n",
      "[1452/8000] D loss: 0.3746, G loss: 8.2960\n",
      "[1812/8000] D loss: 0.3440, G loss: 9.0233\n",
      "[2172/8000] D loss: 0.2612, G loss: 11.5091\n",
      "[2532/8000] D loss: 0.0209, G loss: 13.7650\n",
      "[2892/8000] D loss: 0.2309, G loss: 11.5225\n",
      "[3252/8000] D loss: 0.0066, G loss: 11.1320\n",
      "[3612/8000] D loss: 0.1430, G loss: 12.2142\n",
      "[3972/8000] D loss: 0.2381, G loss: 7.3135\n",
      "[4332/8000] D loss: 0.0219, G loss: 13.1830\n",
      "[4692/8000] D loss: 0.0248, G loss: 11.5743\n",
      "[5052/8000] D loss: 0.1945, G loss: 9.1182\n",
      "[5412/8000] D loss: 0.2740, G loss: 9.3302\n",
      "[5772/8000] D loss: 0.8763, G loss: 10.9765\n",
      "[6132/8000] D loss: 0.3324, G loss: 8.1617\n",
      "[6492/8000] D loss: 0.4518, G loss: 7.6621\n",
      "[6852/8000] D loss: 0.1433, G loss: 8.2944\n",
      "[7212/8000] D loss: 0.2670, G loss: 10.0105\n",
      "[7572/8000] D loss: 0.2478, G loss: 8.6069\n",
      "[7932/8000] D loss: 0.1306, G loss: 13.2049\n",
      "train error: \n",
      " D loss: 0.270298, G loss: 10.105550, D accuracy: 92.9%, cell accuracy: 94.5%, board accuracy: 11.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.512511, G loss: 13.569654, D accuracy: 92.5%, cell accuracy: 94.1%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3018, G loss: 8.7095\n",
      "[372/8000] D loss: 0.4070, G loss: 10.4754\n",
      "[732/8000] D loss: 0.0763, G loss: 11.6558\n",
      "[1092/8000] D loss: 0.0850, G loss: 13.6109\n",
      "[1452/8000] D loss: 0.1747, G loss: 8.6549\n",
      "[1812/8000] D loss: 0.1391, G loss: 8.9948\n",
      "[2172/8000] D loss: 0.1110, G loss: 12.2983\n",
      "[2532/8000] D loss: 0.3722, G loss: 9.2155\n",
      "[2892/8000] D loss: 0.2968, G loss: 6.7179\n",
      "[3252/8000] D loss: 0.1194, G loss: 14.1266\n",
      "[3612/8000] D loss: 0.0116, G loss: 14.5416\n",
      "[3972/8000] D loss: 0.0174, G loss: 10.1011\n",
      "[4332/8000] D loss: 0.4324, G loss: 6.9971\n",
      "[4692/8000] D loss: 0.2422, G loss: 12.3308\n",
      "[5052/8000] D loss: 0.1396, G loss: 10.6677\n",
      "[5412/8000] D loss: 0.2437, G loss: 7.6339\n",
      "[5772/8000] D loss: 0.0433, G loss: 14.0740\n",
      "[6132/8000] D loss: 0.1895, G loss: 10.0771\n",
      "[6492/8000] D loss: 0.1270, G loss: 11.6697\n",
      "[6852/8000] D loss: 0.1544, G loss: 8.2911\n",
      "[7212/8000] D loss: 0.1265, G loss: 11.2176\n",
      "[7572/8000] D loss: 0.1201, G loss: 12.0191\n",
      "[7932/8000] D loss: 0.5368, G loss: 10.4708\n",
      "train error: \n",
      " D loss: 0.232843, G loss: 10.193359, D accuracy: 93.4%, cell accuracy: 94.5%, board accuracy: 11.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.589628, G loss: 13.599903, D accuracy: 92.1%, cell accuracy: 94.1%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0154, G loss: 7.8205\n",
      "[372/8000] D loss: 0.1622, G loss: 10.2396\n",
      "[732/8000] D loss: 0.2862, G loss: 8.2715\n",
      "[1092/8000] D loss: 0.1260, G loss: 11.4395\n",
      "[1452/8000] D loss: 0.0753, G loss: 12.1247\n",
      "[1812/8000] D loss: 0.1329, G loss: 11.1615\n",
      "[2172/8000] D loss: 0.0940, G loss: 10.1504\n",
      "[2532/8000] D loss: 0.2057, G loss: 9.6783\n",
      "[2892/8000] D loss: 0.6812, G loss: 4.6925\n",
      "[3252/8000] D loss: 0.1579, G loss: 12.9200\n",
      "[3612/8000] D loss: 0.3937, G loss: 11.3164\n",
      "[3972/8000] D loss: 0.2248, G loss: 11.3640\n",
      "[4332/8000] D loss: 0.2713, G loss: 9.7302\n",
      "[4692/8000] D loss: 0.0224, G loss: 10.9439\n",
      "[5052/8000] D loss: 0.2641, G loss: 9.1874\n",
      "[5412/8000] D loss: 0.1429, G loss: 11.3581\n",
      "[5772/8000] D loss: 0.1363, G loss: 8.9685\n",
      "[6132/8000] D loss: 0.5108, G loss: 8.6930\n",
      "[6492/8000] D loss: 0.1308, G loss: 12.6301\n",
      "[6852/8000] D loss: 0.2626, G loss: 9.1660\n",
      "[7212/8000] D loss: 0.1303, G loss: 12.8009\n",
      "[7572/8000] D loss: 0.7600, G loss: 6.8143\n",
      "[7932/8000] D loss: 0.1891, G loss: 12.6433\n",
      "train error: \n",
      " D loss: 0.246804, G loss: 9.065413, D accuracy: 93.3%, cell accuracy: 94.5%, board accuracy: 11.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.449679, G loss: 12.494118, D accuracy: 93.9%, cell accuracy: 94.1%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3600, G loss: 6.0610\n",
      "[372/8000] D loss: 0.2160, G loss: 10.4923\n",
      "[732/8000] D loss: 0.4108, G loss: 10.0431\n",
      "[1092/8000] D loss: 0.4085, G loss: 7.3553\n",
      "[1452/8000] D loss: 0.1284, G loss: 10.7916\n",
      "[1812/8000] D loss: 0.4597, G loss: 9.5249\n",
      "[2172/8000] D loss: 0.0399, G loss: 10.9380\n",
      "[2532/8000] D loss: 0.5288, G loss: 11.8391\n",
      "[2892/8000] D loss: 0.2637, G loss: 7.5652\n",
      "[3252/8000] D loss: 0.4468, G loss: 10.9593\n",
      "[3612/8000] D loss: 0.1324, G loss: 10.1857\n",
      "[3972/8000] D loss: 0.1695, G loss: 9.7361\n",
      "[4332/8000] D loss: 0.4343, G loss: 10.0577\n",
      "[4692/8000] D loss: 0.1624, G loss: 10.1916\n",
      "[5052/8000] D loss: 0.0236, G loss: 12.0975\n",
      "[5412/8000] D loss: 0.1452, G loss: 8.5084\n",
      "[5772/8000] D loss: 0.0259, G loss: 12.8169\n",
      "[6132/8000] D loss: 0.2154, G loss: 10.4248\n",
      "[6492/8000] D loss: 0.0455, G loss: 11.5249\n",
      "[6852/8000] D loss: 0.2612, G loss: 7.6959\n",
      "[7212/8000] D loss: 0.3428, G loss: 12.4271\n",
      "[7572/8000] D loss: 0.3028, G loss: 10.2598\n",
      "[7932/8000] D loss: 0.2170, G loss: 7.2408\n",
      "train error: \n",
      " D loss: 0.250139, G loss: 9.433259, D accuracy: 92.9%, cell accuracy: 94.5%, board accuracy: 11.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.513367, G loss: 12.483416, D accuracy: 91.7%, cell accuracy: 94.1%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2325, G loss: 10.5064\n",
      "[372/8000] D loss: 0.0070, G loss: 10.3872\n",
      "[732/8000] D loss: 0.0306, G loss: 11.1119\n",
      "[1092/8000] D loss: 0.3293, G loss: 10.7084\n",
      "[1452/8000] D loss: 0.8435, G loss: 3.6984\n",
      "[1812/8000] D loss: 0.1288, G loss: 9.5638\n",
      "[2172/8000] D loss: 0.3588, G loss: 9.7095\n",
      "[2532/8000] D loss: 0.1962, G loss: 9.8451\n",
      "[2892/8000] D loss: 0.0815, G loss: 11.9413\n",
      "[3252/8000] D loss: 0.1568, G loss: 5.9763\n",
      "[3612/8000] D loss: 0.1045, G loss: 10.1741\n",
      "[3972/8000] D loss: 0.0495, G loss: 12.4934\n",
      "[4332/8000] D loss: 0.4656, G loss: 6.8260\n",
      "[4692/8000] D loss: 0.3701, G loss: 9.6296\n",
      "[5052/8000] D loss: 0.4128, G loss: 6.0770\n",
      "[5412/8000] D loss: 0.3200, G loss: 6.2464\n",
      "[5772/8000] D loss: 0.5280, G loss: 5.6981\n",
      "[6132/8000] D loss: 0.3488, G loss: 7.7255\n",
      "[6492/8000] D loss: 0.1664, G loss: 8.9070\n",
      "[6852/8000] D loss: 0.0279, G loss: 10.8121\n",
      "[7212/8000] D loss: 0.1360, G loss: 14.4696\n",
      "[7572/8000] D loss: 0.0076, G loss: 12.0702\n",
      "[7932/8000] D loss: 0.2720, G loss: 9.8912\n",
      "train error: \n",
      " D loss: 0.238668, G loss: 9.714906, D accuracy: 93.1%, cell accuracy: 94.5%, board accuracy: 11.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.553520, G loss: 12.986055, D accuracy: 92.1%, cell accuracy: 94.1%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3102, G loss: 8.2875\n",
      "[372/8000] D loss: 0.4489, G loss: 6.9701\n",
      "[732/8000] D loss: 0.2455, G loss: 12.3946\n",
      "[1092/8000] D loss: 0.3849, G loss: 9.2017\n",
      "[1452/8000] D loss: 0.1902, G loss: 11.6102\n",
      "[1812/8000] D loss: 0.0876, G loss: 11.1735\n",
      "[2172/8000] D loss: 0.2613, G loss: 9.0097\n",
      "[2532/8000] D loss: 0.1953, G loss: 10.7354\n",
      "[2892/8000] D loss: 0.0247, G loss: 9.4406\n",
      "[3252/8000] D loss: 0.2222, G loss: 7.7200\n",
      "[3612/8000] D loss: 0.2132, G loss: 11.1708\n",
      "[3972/8000] D loss: 0.4957, G loss: 10.1508\n",
      "[4332/8000] D loss: 0.3750, G loss: 9.6888\n",
      "[4692/8000] D loss: 0.1602, G loss: 10.3339\n",
      "[5052/8000] D loss: 0.1901, G loss: 11.8125\n",
      "[5412/8000] D loss: 0.2926, G loss: 8.6693\n",
      "[5772/8000] D loss: 0.1356, G loss: 9.6189\n",
      "[6132/8000] D loss: 0.3828, G loss: 12.0094\n",
      "[6492/8000] D loss: 0.3333, G loss: 11.0259\n",
      "[6852/8000] D loss: 0.2750, G loss: 8.1746\n",
      "[7212/8000] D loss: 0.1941, G loss: 10.7197\n",
      "[7572/8000] D loss: 0.2386, G loss: 9.0886\n",
      "[7932/8000] D loss: 0.1190, G loss: 11.8985\n",
      "train error: \n",
      " D loss: 0.238846, G loss: 10.238086, D accuracy: 93.5%, cell accuracy: 94.5%, board accuracy: 11.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.497108, G loss: 13.669860, D accuracy: 93.3%, cell accuracy: 94.0%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1189, G loss: 14.8700\n",
      "[372/8000] D loss: 0.6302, G loss: 4.9937\n",
      "[732/8000] D loss: 0.1348, G loss: 13.0843\n",
      "[1092/8000] D loss: 0.1372, G loss: 9.5994\n",
      "[1452/8000] D loss: 0.2674, G loss: 10.3544\n",
      "[1812/8000] D loss: 0.3817, G loss: 9.8054\n",
      "[2172/8000] D loss: 0.4874, G loss: 8.3526\n",
      "[2532/8000] D loss: 0.2175, G loss: 8.2129\n",
      "[2892/8000] D loss: 0.2967, G loss: 10.0561\n",
      "[3252/8000] D loss: 0.0576, G loss: 10.4560\n",
      "[3612/8000] D loss: 0.0518, G loss: 13.5883\n",
      "[3972/8000] D loss: 0.1490, G loss: 12.0498\n",
      "[4332/8000] D loss: 0.3222, G loss: 9.9458\n",
      "[4692/8000] D loss: 0.3964, G loss: 10.4189\n",
      "[5052/8000] D loss: 0.2998, G loss: 10.3259\n",
      "[5412/8000] D loss: 0.4437, G loss: 12.8156\n",
      "[5772/8000] D loss: 0.0161, G loss: 13.8197\n",
      "[6132/8000] D loss: 0.4183, G loss: 6.9655\n",
      "[6492/8000] D loss: 0.3945, G loss: 6.9202\n",
      "[6852/8000] D loss: 0.0660, G loss: 13.8733\n",
      "[7212/8000] D loss: 0.2916, G loss: 10.3028\n",
      "[7572/8000] D loss: 0.2988, G loss: 12.1421\n",
      "[7932/8000] D loss: 0.3876, G loss: 11.3911\n",
      "train error: \n",
      " D loss: 0.233994, G loss: 9.285665, D accuracy: 93.5%, cell accuracy: 94.5%, board accuracy: 11.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.483344, G loss: 12.573206, D accuracy: 93.3%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1548, G loss: 8.5331\n",
      "[372/8000] D loss: 0.1221, G loss: 10.3203\n",
      "[732/8000] D loss: 0.1306, G loss: 12.5680\n",
      "[1092/8000] D loss: 0.1252, G loss: 9.8661\n",
      "[1452/8000] D loss: 0.3858, G loss: 8.8331\n",
      "[1812/8000] D loss: 0.5027, G loss: 8.2482\n",
      "[2172/8000] D loss: 0.5161, G loss: 8.9719\n",
      "[2532/8000] D loss: 0.2578, G loss: 9.9962\n",
      "[2892/8000] D loss: 0.2645, G loss: 6.9658\n",
      "[3252/8000] D loss: 0.4457, G loss: 8.0121\n",
      "[3612/8000] D loss: 0.8676, G loss: 6.9341\n",
      "[3972/8000] D loss: 0.2941, G loss: 10.8657\n",
      "[4332/8000] D loss: 0.2735, G loss: 8.6199\n",
      "[4692/8000] D loss: 0.1980, G loss: 7.9503\n",
      "[5052/8000] D loss: 0.4245, G loss: 7.0354\n",
      "[5412/8000] D loss: 0.5629, G loss: 7.8395\n",
      "[5772/8000] D loss: 0.5224, G loss: 8.8254\n",
      "[6132/8000] D loss: 0.1980, G loss: 11.8807\n",
      "[6492/8000] D loss: 0.3767, G loss: 8.0149\n",
      "[6852/8000] D loss: 0.5802, G loss: 4.9494\n",
      "[7212/8000] D loss: 0.0583, G loss: 9.2382\n",
      "[7572/8000] D loss: 0.3831, G loss: 9.9667\n",
      "[7932/8000] D loss: 0.2643, G loss: 12.8987\n",
      "train error: \n",
      " D loss: 0.224692, G loss: 10.142466, D accuracy: 93.5%, cell accuracy: 94.5%, board accuracy: 12.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.545018, G loss: 13.569806, D accuracy: 92.8%, cell accuracy: 94.1%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3493, G loss: 6.6565\n",
      "[372/8000] D loss: 0.5948, G loss: 10.3682\n",
      "[732/8000] D loss: 0.0211, G loss: 13.4577\n",
      "[1092/8000] D loss: 0.7268, G loss: 6.1226\n",
      "[1452/8000] D loss: 0.3906, G loss: 10.2032\n",
      "[1812/8000] D loss: 0.2028, G loss: 10.5384\n",
      "[2172/8000] D loss: 0.3126, G loss: 10.4336\n",
      "[2532/8000] D loss: 0.1101, G loss: 9.6612\n",
      "[2892/8000] D loss: 0.3244, G loss: 9.0340\n",
      "[3252/8000] D loss: 0.3459, G loss: 8.8303\n",
      "[3612/8000] D loss: 0.3011, G loss: 8.7332\n",
      "[3972/8000] D loss: 0.2078, G loss: 9.0284\n",
      "[4332/8000] D loss: 0.1116, G loss: 9.1561\n",
      "[4692/8000] D loss: 0.5471, G loss: 6.8627\n",
      "[5052/8000] D loss: 0.0283, G loss: 11.0435\n",
      "[5412/8000] D loss: 0.1301, G loss: 9.6331\n",
      "[5772/8000] D loss: 0.2214, G loss: 8.4867\n",
      "[6132/8000] D loss: 0.0474, G loss: 8.9712\n",
      "[6492/8000] D loss: 0.5692, G loss: 7.0641\n",
      "[6852/8000] D loss: 0.2698, G loss: 10.8828\n",
      "[7212/8000] D loss: 0.2142, G loss: 16.2558\n",
      "[7572/8000] D loss: 0.3621, G loss: 8.2372\n",
      "[7932/8000] D loss: 0.2757, G loss: 8.1286\n",
      "train error: \n",
      " D loss: 0.244015, G loss: 8.839293, D accuracy: 93.3%, cell accuracy: 94.4%, board accuracy: 11.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.450646, G loss: 12.241602, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1846, G loss: 9.7055\n",
      "[372/8000] D loss: 0.2878, G loss: 16.8011\n",
      "[732/8000] D loss: 0.2517, G loss: 11.7627\n",
      "[1092/8000] D loss: 0.0340, G loss: 13.5817\n",
      "[1452/8000] D loss: 0.2848, G loss: 8.4787\n",
      "[1812/8000] D loss: 0.1202, G loss: 8.1248\n",
      "[2172/8000] D loss: 0.2511, G loss: 10.9614\n",
      "[2532/8000] D loss: 0.3816, G loss: 9.1738\n",
      "[2892/8000] D loss: 0.0065, G loss: 10.9158\n",
      "[3252/8000] D loss: 0.1315, G loss: 10.7702\n",
      "[3612/8000] D loss: 0.1375, G loss: 13.0751\n",
      "[3972/8000] D loss: 0.2322, G loss: 11.1287\n",
      "[4332/8000] D loss: 0.6299, G loss: 7.3082\n",
      "[4692/8000] D loss: 0.2886, G loss: 9.4181\n",
      "[5052/8000] D loss: 0.2996, G loss: 6.5982\n",
      "[5412/8000] D loss: 0.0589, G loss: 13.6890\n",
      "[5772/8000] D loss: 0.0063, G loss: 13.8997\n",
      "[6132/8000] D loss: 0.5984, G loss: 9.6014\n",
      "[6492/8000] D loss: 0.1258, G loss: 9.6156\n",
      "[6852/8000] D loss: 0.2182, G loss: 12.6088\n",
      "[7212/8000] D loss: 0.0139, G loss: 11.2073\n",
      "[7572/8000] D loss: 0.3831, G loss: 9.1888\n",
      "[7932/8000] D loss: 0.2849, G loss: 8.1452\n",
      "train error: \n",
      " D loss: 0.235670, G loss: 10.798387, D accuracy: 93.2%, cell accuracy: 94.5%, board accuracy: 11.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.542515, G loss: 14.240279, D accuracy: 92.7%, cell accuracy: 94.1%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2232, G loss: 9.8566\n",
      "[372/8000] D loss: 0.1415, G loss: 13.6692\n",
      "[732/8000] D loss: 0.0623, G loss: 12.5956\n",
      "[1092/8000] D loss: 0.4346, G loss: 7.3416\n",
      "[1452/8000] D loss: 0.0117, G loss: 11.5539\n",
      "[1812/8000] D loss: 0.1493, G loss: 10.9473\n",
      "[2172/8000] D loss: 0.2922, G loss: 10.4664\n",
      "[2532/8000] D loss: 0.1215, G loss: 11.3573\n",
      "[2892/8000] D loss: 0.3115, G loss: 10.7557\n",
      "[3252/8000] D loss: 0.1940, G loss: 9.5250\n",
      "[3612/8000] D loss: 0.4108, G loss: 7.8735\n",
      "[3972/8000] D loss: 0.0134, G loss: 10.8280\n",
      "[4332/8000] D loss: 0.3355, G loss: 10.6981\n",
      "[4692/8000] D loss: 0.0648, G loss: 7.9127\n",
      "[5052/8000] D loss: 0.0159, G loss: 11.8997\n",
      "[5412/8000] D loss: 0.3283, G loss: 10.0487\n",
      "[5772/8000] D loss: 0.2675, G loss: 10.2264\n",
      "[6132/8000] D loss: 0.2839, G loss: 12.0319\n",
      "[6492/8000] D loss: 0.0097, G loss: 9.9659\n",
      "[6852/8000] D loss: 0.4006, G loss: 9.2121\n",
      "[7212/8000] D loss: 0.5776, G loss: 10.9107\n",
      "[7572/8000] D loss: 0.3977, G loss: 12.5981\n",
      "[7932/8000] D loss: 0.2583, G loss: 9.2730\n",
      "train error: \n",
      " D loss: 0.262655, G loss: 9.314219, D accuracy: 93.0%, cell accuracy: 94.5%, board accuracy: 11.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.470758, G loss: 12.739151, D accuracy: 94.1%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2893, G loss: 7.1755\n",
      "[372/8000] D loss: 0.3796, G loss: 11.5117\n",
      "[732/8000] D loss: 0.1037, G loss: 14.1485\n",
      "[1092/8000] D loss: 0.5347, G loss: 8.7551\n",
      "[1452/8000] D loss: 0.5666, G loss: 6.8193\n",
      "[1812/8000] D loss: 0.5350, G loss: 11.2806\n",
      "[2172/8000] D loss: 0.1174, G loss: 13.2186\n",
      "[2532/8000] D loss: 0.2355, G loss: 9.6995\n",
      "[2892/8000] D loss: 0.1940, G loss: 13.7025\n",
      "[3252/8000] D loss: 0.2467, G loss: 7.2058\n",
      "[3612/8000] D loss: 0.0772, G loss: 8.9382\n",
      "[3972/8000] D loss: 0.3947, G loss: 10.9091\n",
      "[4332/8000] D loss: 0.4385, G loss: 11.2459\n",
      "[4692/8000] D loss: 0.1432, G loss: 11.9746\n",
      "[5052/8000] D loss: 0.2774, G loss: 9.2625\n",
      "[5412/8000] D loss: 0.1057, G loss: 11.8671\n",
      "[5772/8000] D loss: 0.2381, G loss: 9.8271\n",
      "[6132/8000] D loss: 0.1271, G loss: 9.3604\n",
      "[6492/8000] D loss: 0.1537, G loss: 11.7379\n",
      "[6852/8000] D loss: 0.2515, G loss: 9.5507\n",
      "[7212/8000] D loss: 0.1964, G loss: 12.0957\n",
      "[7572/8000] D loss: 0.2670, G loss: 8.2867\n",
      "[7932/8000] D loss: 0.2325, G loss: 12.5529\n",
      "train error: \n",
      " D loss: 0.235559, G loss: 10.233027, D accuracy: 93.3%, cell accuracy: 94.5%, board accuracy: 11.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.544534, G loss: 13.717891, D accuracy: 93.2%, cell accuracy: 94.1%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3637, G loss: 7.2795\n",
      "[372/8000] D loss: 0.3526, G loss: 6.9871\n",
      "[732/8000] D loss: 0.6910, G loss: 8.2263\n",
      "[1092/8000] D loss: 0.1998, G loss: 9.5899\n",
      "[1452/8000] D loss: 0.1443, G loss: 11.7713\n",
      "[1812/8000] D loss: 0.3882, G loss: 8.3499\n",
      "[2172/8000] D loss: 0.4231, G loss: 8.0475\n",
      "[2532/8000] D loss: 0.3498, G loss: 10.8827\n",
      "[2892/8000] D loss: 0.2555, G loss: 10.8985\n",
      "[3252/8000] D loss: 0.3951, G loss: 6.3176\n",
      "[3612/8000] D loss: 0.2171, G loss: 7.3473\n",
      "[3972/8000] D loss: 0.2175, G loss: 12.4460\n",
      "[4332/8000] D loss: 0.3308, G loss: 7.9220\n",
      "[4692/8000] D loss: 0.1621, G loss: 12.3953\n",
      "[5052/8000] D loss: 0.1243, G loss: 10.1120\n",
      "[5412/8000] D loss: 0.2981, G loss: 10.5620\n",
      "[5772/8000] D loss: 0.1861, G loss: 11.8065\n",
      "[6132/8000] D loss: 0.0162, G loss: 8.2983\n",
      "[6492/8000] D loss: 0.1948, G loss: 8.2753\n",
      "[6852/8000] D loss: 0.2517, G loss: 11.6581\n",
      "[7212/8000] D loss: 0.3931, G loss: 6.9959\n",
      "[7572/8000] D loss: 0.5139, G loss: 9.0383\n",
      "[7932/8000] D loss: 0.3881, G loss: 9.6501\n",
      "train error: \n",
      " D loss: 0.243905, G loss: 9.010145, D accuracy: 93.2%, cell accuracy: 94.5%, board accuracy: 11.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.472710, G loss: 12.394607, D accuracy: 93.3%, cell accuracy: 94.0%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0111, G loss: 11.6951\n",
      "[372/8000] D loss: 0.1230, G loss: 11.8510\n",
      "[732/8000] D loss: 0.2971, G loss: 9.0133\n",
      "[1092/8000] D loss: 0.1714, G loss: 11.1022\n",
      "[1452/8000] D loss: 0.1502, G loss: 11.8644\n",
      "[1812/8000] D loss: 0.1374, G loss: 10.7281\n",
      "[2172/8000] D loss: 0.1354, G loss: 10.0324\n",
      "[2532/8000] D loss: 0.1985, G loss: 9.1971\n",
      "[2892/8000] D loss: 0.1230, G loss: 9.6812\n",
      "[3252/8000] D loss: 0.4143, G loss: 9.6552\n",
      "[3612/8000] D loss: 0.3369, G loss: 8.9604\n",
      "[3972/8000] D loss: 0.2465, G loss: 9.1032\n",
      "[4332/8000] D loss: 0.3543, G loss: 11.2687\n",
      "[4692/8000] D loss: 0.0059, G loss: 14.1487\n",
      "[5052/8000] D loss: 0.1479, G loss: 8.5934\n",
      "[5412/8000] D loss: 0.1374, G loss: 8.1911\n",
      "[5772/8000] D loss: 0.0938, G loss: 15.2684\n",
      "[6132/8000] D loss: 0.0692, G loss: 9.4370\n",
      "[6492/8000] D loss: 0.2799, G loss: 8.7175\n",
      "[6852/8000] D loss: 0.3706, G loss: 8.0988\n",
      "[7212/8000] D loss: 0.1350, G loss: 9.5060\n",
      "[7572/8000] D loss: 0.1006, G loss: 9.7059\n",
      "[7932/8000] D loss: 0.0441, G loss: 12.3163\n",
      "train error: \n",
      " D loss: 0.237538, G loss: 9.700474, D accuracy: 93.3%, cell accuracy: 94.4%, board accuracy: 11.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.510097, G loss: 13.166219, D accuracy: 93.2%, cell accuracy: 94.0%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1234, G loss: 10.6408\n",
      "[372/8000] D loss: 0.1111, G loss: 9.9397\n",
      "[732/8000] D loss: 0.1166, G loss: 11.8552\n",
      "[1092/8000] D loss: 0.3910, G loss: 8.4985\n",
      "[1452/8000] D loss: 0.1275, G loss: 11.3503\n",
      "[1812/8000] D loss: 0.2638, G loss: 9.2864\n",
      "[2172/8000] D loss: 0.0155, G loss: 9.2253\n",
      "[2532/8000] D loss: 0.2024, G loss: 10.3601\n",
      "[2892/8000] D loss: 0.0153, G loss: 14.5798\n",
      "[3252/8000] D loss: 0.3446, G loss: 12.5304\n",
      "[3612/8000] D loss: 0.4175, G loss: 10.2587\n",
      "[3972/8000] D loss: 0.1503, G loss: 10.6581\n",
      "[4332/8000] D loss: 0.2559, G loss: 7.1866\n",
      "[4692/8000] D loss: 0.1197, G loss: 13.2298\n",
      "[5052/8000] D loss: 0.1959, G loss: 8.3350\n",
      "[5412/8000] D loss: 0.2319, G loss: 10.7784\n",
      "[5772/8000] D loss: 0.2007, G loss: 10.8002\n",
      "[6132/8000] D loss: 0.1192, G loss: 11.5816\n",
      "[6492/8000] D loss: 0.2972, G loss: 7.6223\n",
      "[6852/8000] D loss: 0.2370, G loss: 13.8746\n",
      "[7212/8000] D loss: 0.1379, G loss: 8.2030\n",
      "[7572/8000] D loss: 0.2407, G loss: 13.8130\n",
      "[7932/8000] D loss: 0.4564, G loss: 9.1565\n",
      "train error: \n",
      " D loss: 0.236019, G loss: 10.047460, D accuracy: 93.3%, cell accuracy: 94.4%, board accuracy: 12.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.544559, G loss: 13.483202, D accuracy: 92.6%, cell accuracy: 94.0%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0113, G loss: 12.3941\n",
      "[372/8000] D loss: 0.1896, G loss: 8.2732\n",
      "[732/8000] D loss: 0.2922, G loss: 11.0885\n",
      "[1092/8000] D loss: 0.2809, G loss: 7.1966\n",
      "[1452/8000] D loss: 0.4829, G loss: 7.5854\n",
      "[1812/8000] D loss: 0.3135, G loss: 9.7499\n",
      "[2172/8000] D loss: 0.1732, G loss: 9.3501\n",
      "[2532/8000] D loss: 0.3937, G loss: 11.9913\n",
      "[2892/8000] D loss: 0.1541, G loss: 10.3301\n",
      "[3252/8000] D loss: 0.2431, G loss: 9.8473\n",
      "[3612/8000] D loss: 0.0113, G loss: 6.6511\n",
      "[3972/8000] D loss: 0.0522, G loss: 12.5364\n",
      "[4332/8000] D loss: 0.2969, G loss: 9.8853\n",
      "[4692/8000] D loss: 0.2930, G loss: 10.1517\n",
      "[5052/8000] D loss: 0.1289, G loss: 10.2115\n",
      "[5412/8000] D loss: 0.4196, G loss: 8.2817\n",
      "[5772/8000] D loss: 0.1712, G loss: 8.2071\n",
      "[6132/8000] D loss: 0.1326, G loss: 11.6239\n",
      "[6492/8000] D loss: 0.4820, G loss: 6.4658\n",
      "[6852/8000] D loss: 0.4865, G loss: 9.5890\n",
      "[7212/8000] D loss: 0.1844, G loss: 11.3762\n",
      "[7572/8000] D loss: 0.4783, G loss: 10.2955\n",
      "[7932/8000] D loss: 0.1181, G loss: 10.3424\n",
      "train error: \n",
      " D loss: 0.246393, G loss: 9.078840, D accuracy: 93.2%, cell accuracy: 94.4%, board accuracy: 11.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.452859, G loss: 12.447525, D accuracy: 93.4%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3449, G loss: 7.7110\n",
      "[372/8000] D loss: 0.0911, G loss: 10.5434\n",
      "[732/8000] D loss: 0.1192, G loss: 11.6689\n",
      "[1092/8000] D loss: 0.3659, G loss: 6.8549\n",
      "[1452/8000] D loss: 0.0025, G loss: 16.4815\n",
      "[1812/8000] D loss: 0.0369, G loss: 10.9517\n",
      "[2172/8000] D loss: 0.2118, G loss: 13.1541\n",
      "[2532/8000] D loss: 0.2057, G loss: 12.2676\n",
      "[2892/8000] D loss: 0.1326, G loss: 8.4244\n",
      "[3252/8000] D loss: 0.0085, G loss: 12.7917\n",
      "[3612/8000] D loss: 0.2874, G loss: 10.9025\n",
      "[3972/8000] D loss: 0.1540, G loss: 10.0262\n",
      "[4332/8000] D loss: 0.0192, G loss: 10.3829\n",
      "[4692/8000] D loss: 0.0040, G loss: 13.6139\n",
      "[5052/8000] D loss: 0.1165, G loss: 14.0121\n",
      "[5412/8000] D loss: 0.2468, G loss: 5.6988\n",
      "[5772/8000] D loss: 0.1292, G loss: 11.4801\n",
      "[6132/8000] D loss: 0.1393, G loss: 11.9983\n",
      "[6492/8000] D loss: 0.0039, G loss: 8.8189\n",
      "[6852/8000] D loss: 0.4372, G loss: 8.9107\n",
      "[7212/8000] D loss: 0.4938, G loss: 9.8200\n",
      "[7572/8000] D loss: 0.1327, G loss: 10.4022\n",
      "[7932/8000] D loss: 0.3556, G loss: 9.2966\n",
      "train error: \n",
      " D loss: 0.240598, G loss: 10.445285, D accuracy: 93.2%, cell accuracy: 94.5%, board accuracy: 12.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.574845, G loss: 14.164000, D accuracy: 92.8%, cell accuracy: 94.0%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0026, G loss: 11.1485\n",
      "[372/8000] D loss: 0.0080, G loss: 17.1963\n",
      "[732/8000] D loss: 0.2346, G loss: 9.6629\n",
      "[1092/8000] D loss: 0.3598, G loss: 7.4523\n",
      "[1452/8000] D loss: 0.1992, G loss: 12.2190\n",
      "[1812/8000] D loss: 0.3727, G loss: 10.5846\n",
      "[2172/8000] D loss: 0.2636, G loss: 8.8920\n",
      "[2532/8000] D loss: 0.3401, G loss: 11.0431\n",
      "[2892/8000] D loss: 0.1644, G loss: 8.6385\n",
      "[3252/8000] D loss: 0.2036, G loss: 11.7309\n",
      "[3612/8000] D loss: 0.0007, G loss: 19.1804\n",
      "[3972/8000] D loss: 0.2835, G loss: 7.3467\n",
      "[4332/8000] D loss: 0.1321, G loss: 10.8250\n",
      "[4692/8000] D loss: 0.3502, G loss: 9.4340\n",
      "[5052/8000] D loss: 0.4879, G loss: 6.5612\n",
      "[5412/8000] D loss: 0.3177, G loss: 7.8548\n",
      "[5772/8000] D loss: 0.3793, G loss: 10.9629\n",
      "[6132/8000] D loss: 0.1340, G loss: 10.7205\n",
      "[6492/8000] D loss: 0.5389, G loss: 9.0333\n",
      "[6852/8000] D loss: 0.2514, G loss: 12.6190\n",
      "[7212/8000] D loss: 0.1304, G loss: 7.1147\n",
      "[7572/8000] D loss: 0.1534, G loss: 13.1530\n",
      "[7932/8000] D loss: 0.2770, G loss: 11.2054\n",
      "train error: \n",
      " D loss: 0.266581, G loss: 9.477803, D accuracy: 92.8%, cell accuracy: 94.5%, board accuracy: 12.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.543027, G loss: 13.018939, D accuracy: 93.1%, cell accuracy: 94.0%, board accuracy: 5.3% \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2750, G loss: 8.4490\n",
      "[372/8000] D loss: 0.1714, G loss: 8.3653\n",
      "[732/8000] D loss: 0.4088, G loss: 8.9893\n",
      "[1092/8000] D loss: 0.0083, G loss: 11.4568\n",
      "[1452/8000] D loss: 0.1352, G loss: 9.7047\n",
      "[1812/8000] D loss: 0.0989, G loss: 16.7211\n",
      "[2172/8000] D loss: 0.2616, G loss: 11.6601\n",
      "[2532/8000] D loss: 0.0301, G loss: 11.2410\n",
      "[2892/8000] D loss: 0.6049, G loss: 4.9381\n",
      "[3252/8000] D loss: 0.3848, G loss: 5.6997\n",
      "[3612/8000] D loss: 0.2480, G loss: 9.9044\n",
      "[3972/8000] D loss: 0.0863, G loss: 9.1377\n",
      "[4332/8000] D loss: 0.1280, G loss: 10.2627\n",
      "[4692/8000] D loss: 0.3674, G loss: 11.1109\n",
      "[5052/8000] D loss: 0.2603, G loss: 10.0733\n",
      "[5412/8000] D loss: 0.3849, G loss: 9.1294\n",
      "[5772/8000] D loss: 0.3164, G loss: 9.9336\n",
      "[6132/8000] D loss: 0.1702, G loss: 10.0146\n",
      "[6492/8000] D loss: 0.1202, G loss: 13.5277\n",
      "[6852/8000] D loss: 0.1359, G loss: 10.0026\n",
      "[7212/8000] D loss: 0.5453, G loss: 8.1753\n",
      "[7572/8000] D loss: 0.2922, G loss: 14.3580\n",
      "[7932/8000] D loss: 0.0096, G loss: 10.2387\n",
      "train error: \n",
      " D loss: 0.252148, G loss: 8.361616, D accuracy: 93.2%, cell accuracy: 94.4%, board accuracy: 11.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.438081, G loss: 11.702622, D accuracy: 93.6%, cell accuracy: 94.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2545, G loss: 5.9602\n",
      "[372/8000] D loss: 0.2140, G loss: 7.5351\n",
      "[732/8000] D loss: 0.3151, G loss: 8.6179\n",
      "[1092/8000] D loss: 0.3651, G loss: 10.5010\n",
      "[1452/8000] D loss: 0.1307, G loss: 9.1886\n",
      "[1812/8000] D loss: 0.1387, G loss: 11.5767\n",
      "[2172/8000] D loss: 0.1357, G loss: 11.2888\n",
      "[2532/8000] D loss: 0.3758, G loss: 7.2844\n",
      "[2892/8000] D loss: 0.0216, G loss: 10.5540\n",
      "[3252/8000] D loss: 0.2589, G loss: 10.5878\n",
      "[3612/8000] D loss: 0.3039, G loss: 13.8379\n",
      "[3972/8000] D loss: 0.1068, G loss: 8.3842\n",
      "[4332/8000] D loss: 0.3426, G loss: 9.7031\n",
      "[4692/8000] D loss: 0.0652, G loss: 8.6190\n",
      "[5052/8000] D loss: 0.1945, G loss: 11.7469\n",
      "[5412/8000] D loss: 0.1611, G loss: 8.2428\n",
      "[5772/8000] D loss: 0.1936, G loss: 8.5979\n",
      "[6132/8000] D loss: 0.2592, G loss: 9.5707\n",
      "[6492/8000] D loss: 0.1240, G loss: 10.0539\n",
      "[6852/8000] D loss: 0.1279, G loss: 10.7615\n",
      "[7212/8000] D loss: 0.1333, G loss: 8.0294\n",
      "[7572/8000] D loss: 0.5191, G loss: 9.4918\n",
      "[7932/8000] D loss: 0.1018, G loss: 13.6097\n",
      "train error: \n",
      " D loss: 0.235330, G loss: 10.353991, D accuracy: 93.3%, cell accuracy: 94.5%, board accuracy: 12.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.566972, G loss: 13.997944, D accuracy: 92.6%, cell accuracy: 94.1%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1192, G loss: 12.0273\n",
      "[372/8000] D loss: 0.2648, G loss: 9.3664\n",
      "[732/8000] D loss: 0.1709, G loss: 10.5480\n",
      "[1092/8000] D loss: 0.2994, G loss: 11.0026\n",
      "[1452/8000] D loss: 0.1369, G loss: 13.1480\n",
      "[1812/8000] D loss: 0.2873, G loss: 8.4280\n",
      "[2172/8000] D loss: 0.1221, G loss: 11.1845\n",
      "[2532/8000] D loss: 0.2635, G loss: 8.3914\n",
      "[2892/8000] D loss: 0.2569, G loss: 7.6085\n",
      "[3252/8000] D loss: 0.2643, G loss: 7.7966\n",
      "[3612/8000] D loss: 0.1768, G loss: 10.3143\n",
      "[3972/8000] D loss: 0.2506, G loss: 11.2920\n",
      "[4332/8000] D loss: 0.0751, G loss: 8.5825\n",
      "[4692/8000] D loss: 0.2642, G loss: 8.8010\n",
      "[5052/8000] D loss: 0.0130, G loss: 11.2068\n",
      "[5412/8000] D loss: 0.0082, G loss: 13.6419\n",
      "[5772/8000] D loss: 0.5064, G loss: 7.6244\n",
      "[6132/8000] D loss: 0.6022, G loss: 9.3289\n",
      "[6492/8000] D loss: 0.1296, G loss: 12.4191\n",
      "[6852/8000] D loss: 0.1019, G loss: 11.7372\n",
      "[7212/8000] D loss: 0.7211, G loss: 7.5487\n",
      "[7572/8000] D loss: 0.1851, G loss: 10.1119\n",
      "[7932/8000] D loss: 0.3483, G loss: 11.0286\n",
      "train error: \n",
      " D loss: 0.243630, G loss: 9.717019, D accuracy: 93.2%, cell accuracy: 94.5%, board accuracy: 12.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.526468, G loss: 13.277205, D accuracy: 93.2%, cell accuracy: 94.1%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3182, G loss: 10.7156\n",
      "[372/8000] D loss: 0.1221, G loss: 12.4616\n",
      "[732/8000] D loss: 0.4203, G loss: 6.2043\n",
      "[1092/8000] D loss: 0.1928, G loss: 10.7852\n",
      "[1452/8000] D loss: 0.0505, G loss: 12.8064\n",
      "[1812/8000] D loss: 0.1387, G loss: 8.2439\n",
      "[2172/8000] D loss: 0.3673, G loss: 6.7200\n",
      "[2532/8000] D loss: 0.0247, G loss: 9.9996\n",
      "[2892/8000] D loss: 0.2862, G loss: 7.9262\n",
      "[3252/8000] D loss: 0.2136, G loss: 8.7178\n",
      "[3612/8000] D loss: 0.1336, G loss: 9.4753\n",
      "[3972/8000] D loss: 0.1318, G loss: 10.8764\n",
      "[4332/8000] D loss: 0.2096, G loss: 11.0467\n",
      "[4692/8000] D loss: 0.4005, G loss: 8.9168\n",
      "[5052/8000] D loss: 0.3787, G loss: 8.7699\n",
      "[5412/8000] D loss: 0.2263, G loss: 10.9252\n",
      "[5772/8000] D loss: 0.0681, G loss: 13.0881\n",
      "[6132/8000] D loss: 0.0421, G loss: 11.9344\n",
      "[6492/8000] D loss: 0.1265, G loss: 9.8590\n",
      "[6852/8000] D loss: 0.1832, G loss: 7.9703\n",
      "[7212/8000] D loss: 0.2519, G loss: 8.6317\n",
      "[7572/8000] D loss: 0.3201, G loss: 9.2369\n",
      "[7932/8000] D loss: 0.3934, G loss: 13.2853\n",
      "train error: \n",
      " D loss: 0.238524, G loss: 10.164285, D accuracy: 93.2%, cell accuracy: 94.5%, board accuracy: 12.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.557475, G loss: 13.679534, D accuracy: 92.0%, cell accuracy: 94.1%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1600, G loss: 9.7789\n",
      "[372/8000] D loss: 0.4647, G loss: 9.6855\n",
      "[732/8000] D loss: 0.5786, G loss: 10.1540\n",
      "[1092/8000] D loss: 0.1364, G loss: 9.3294\n",
      "[1452/8000] D loss: 0.1166, G loss: 11.1301\n",
      "[1812/8000] D loss: 0.0210, G loss: 13.7232\n",
      "[2172/8000] D loss: 0.2783, G loss: 8.5530\n",
      "[2532/8000] D loss: 0.0035, G loss: 11.2409\n",
      "[2892/8000] D loss: 0.1187, G loss: 10.3758\n",
      "[3252/8000] D loss: 0.4523, G loss: 9.8408\n",
      "[3612/8000] D loss: 0.2520, G loss: 11.8918\n",
      "[3972/8000] D loss: 0.1370, G loss: 11.6313\n",
      "[4332/8000] D loss: 0.2144, G loss: 12.3652\n",
      "[4692/8000] D loss: 0.2906, G loss: 7.5610\n",
      "[5052/8000] D loss: 0.0812, G loss: 9.7322\n",
      "[5412/8000] D loss: 0.2702, G loss: 11.4463\n",
      "[5772/8000] D loss: 0.3163, G loss: 11.4006\n",
      "[6132/8000] D loss: 0.3087, G loss: 14.6176\n",
      "[6492/8000] D loss: 0.1384, G loss: 11.4428\n",
      "[6852/8000] D loss: 0.0423, G loss: 14.2329\n",
      "[7212/8000] D loss: 0.3920, G loss: 9.0766\n",
      "[7572/8000] D loss: 0.3408, G loss: 9.7882\n",
      "[7932/8000] D loss: 0.1927, G loss: 10.1533\n",
      "train error: \n",
      " D loss: 0.236041, G loss: 10.076541, D accuracy: 93.4%, cell accuracy: 94.5%, board accuracy: 12.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.520503, G loss: 13.635712, D accuracy: 93.1%, cell accuracy: 94.1%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0258, G loss: 9.5705\n",
      "[372/8000] D loss: 0.3834, G loss: 10.1886\n",
      "[732/8000] D loss: 0.2324, G loss: 10.6035\n",
      "[1092/8000] D loss: 0.0844, G loss: 12.1907\n",
      "[1452/8000] D loss: 0.3481, G loss: 9.8968\n",
      "[1812/8000] D loss: 0.3683, G loss: 8.7702\n",
      "[2172/8000] D loss: 0.2308, G loss: 10.2498\n",
      "[2532/8000] D loss: 0.1200, G loss: 9.2946\n",
      "[2892/8000] D loss: 0.1829, G loss: 11.1383\n",
      "[3252/8000] D loss: 0.3819, G loss: 12.0195\n",
      "[3612/8000] D loss: 0.2663, G loss: 11.4870\n",
      "[3972/8000] D loss: 0.2696, G loss: 7.0803\n",
      "[4332/8000] D loss: 0.2146, G loss: 12.2662\n",
      "[4692/8000] D loss: 0.2076, G loss: 8.8591\n",
      "[5052/8000] D loss: 0.1499, G loss: 12.7724\n",
      "[5412/8000] D loss: 0.0454, G loss: 13.6556\n",
      "[5772/8000] D loss: 0.4440, G loss: 9.0798\n",
      "[6132/8000] D loss: 0.2107, G loss: 8.0274\n",
      "[6492/8000] D loss: 0.0966, G loss: 10.9796\n",
      "[6852/8000] D loss: 0.1784, G loss: 13.4066\n",
      "[7212/8000] D loss: 0.2381, G loss: 9.2327\n",
      "[7572/8000] D loss: 0.3605, G loss: 10.8570\n",
      "[7932/8000] D loss: 0.1250, G loss: 10.2695\n",
      "train error: \n",
      " D loss: 0.248246, G loss: 9.267755, D accuracy: 93.1%, cell accuracy: 94.5%, board accuracy: 12.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.512079, G loss: 12.665579, D accuracy: 92.7%, cell accuracy: 94.1%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3650, G loss: 4.9047\n",
      "[372/8000] D loss: 0.2256, G loss: 7.4014\n",
      "[732/8000] D loss: 0.2449, G loss: 12.2365\n",
      "[1092/8000] D loss: 0.0070, G loss: 13.0480\n",
      "[1452/8000] D loss: 0.0436, G loss: 8.3967\n",
      "[1812/8000] D loss: 0.3046, G loss: 11.5177\n",
      "[2172/8000] D loss: 0.3825, G loss: 6.1216\n",
      "[2532/8000] D loss: 0.0059, G loss: 12.6981\n",
      "[2892/8000] D loss: 0.1786, G loss: 11.6420\n",
      "[3252/8000] D loss: 0.1825, G loss: 11.8688\n",
      "[3612/8000] D loss: 0.3255, G loss: 8.7325\n",
      "[3972/8000] D loss: 0.2624, G loss: 8.9122\n",
      "[4332/8000] D loss: 0.4729, G loss: 7.5706\n",
      "[4692/8000] D loss: 0.3447, G loss: 4.7732\n",
      "[5052/8000] D loss: 0.3610, G loss: 12.1524\n",
      "[5412/8000] D loss: 0.2279, G loss: 10.2172\n",
      "[5772/8000] D loss: 0.4396, G loss: 8.5374\n",
      "[6132/8000] D loss: 0.1542, G loss: 7.8654\n",
      "[6492/8000] D loss: 0.5761, G loss: 11.5113\n",
      "[6852/8000] D loss: 0.2032, G loss: 9.8957\n",
      "[7212/8000] D loss: 0.1427, G loss: 9.8139\n",
      "[7572/8000] D loss: 0.0065, G loss: 10.1933\n",
      "[7932/8000] D loss: 0.1473, G loss: 14.0147\n",
      "train error: \n",
      " D loss: 0.280349, G loss: 8.646260, D accuracy: 92.5%, cell accuracy: 94.5%, board accuracy: 12.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.442378, G loss: 12.139475, D accuracy: 93.2%, cell accuracy: 94.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4601, G loss: 7.4684\n",
      "[372/8000] D loss: 0.0268, G loss: 11.5737\n",
      "[732/8000] D loss: 0.1753, G loss: 8.9968\n",
      "[1092/8000] D loss: 0.2662, G loss: 9.4256\n",
      "[1452/8000] D loss: 0.5822, G loss: 7.2302\n",
      "[1812/8000] D loss: 0.3761, G loss: 9.3140\n",
      "[2172/8000] D loss: 0.2189, G loss: 9.1987\n",
      "[2532/8000] D loss: 0.2571, G loss: 9.3448\n",
      "[2892/8000] D loss: 0.2524, G loss: 7.1964\n",
      "[3252/8000] D loss: 0.0317, G loss: 10.3004\n",
      "[3612/8000] D loss: 0.3956, G loss: 6.5252\n",
      "[3972/8000] D loss: 0.0372, G loss: 9.3545\n",
      "[4332/8000] D loss: 0.0066, G loss: 11.4370\n",
      "[4692/8000] D loss: 0.4072, G loss: 9.6727\n",
      "[5052/8000] D loss: 0.1522, G loss: 9.5244\n",
      "[5412/8000] D loss: 0.2902, G loss: 9.9207\n",
      "[5772/8000] D loss: 0.4207, G loss: 9.8244\n",
      "[6132/8000] D loss: 0.1290, G loss: 6.6113\n",
      "[6492/8000] D loss: 0.0168, G loss: 9.8307\n",
      "[6852/8000] D loss: 0.5246, G loss: 8.5747\n",
      "[7212/8000] D loss: 0.4527, G loss: 6.9584\n",
      "[7572/8000] D loss: 0.0336, G loss: 11.1694\n",
      "[7932/8000] D loss: 0.3529, G loss: 8.4227\n",
      "train error: \n",
      " D loss: 0.237445, G loss: 10.854088, D accuracy: 93.3%, cell accuracy: 94.5%, board accuracy: 12.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.577513, G loss: 14.336676, D accuracy: 92.5%, cell accuracy: 94.1%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1256, G loss: 12.7562\n",
      "[372/8000] D loss: 0.1246, G loss: 9.9101\n",
      "[732/8000] D loss: 0.0221, G loss: 15.0138\n",
      "[1092/8000] D loss: 0.1759, G loss: 6.9328\n",
      "[1452/8000] D loss: 0.2792, G loss: 6.4803\n",
      "[1812/8000] D loss: 0.2872, G loss: 8.9702\n",
      "[2172/8000] D loss: 0.4868, G loss: 11.7797\n",
      "[2532/8000] D loss: 0.3316, G loss: 8.9521\n",
      "[2892/8000] D loss: 0.0205, G loss: 11.5335\n",
      "[3252/8000] D loss: 0.4649, G loss: 10.6878\n",
      "[3612/8000] D loss: 0.1594, G loss: 9.0169\n",
      "[3972/8000] D loss: 0.1945, G loss: 8.0981\n",
      "[4332/8000] D loss: 0.2069, G loss: 7.5895\n",
      "[4692/8000] D loss: 0.3383, G loss: 9.5142\n",
      "[5052/8000] D loss: 0.3913, G loss: 11.2035\n",
      "[5412/8000] D loss: 0.2914, G loss: 9.9583\n",
      "[5772/8000] D loss: 0.1827, G loss: 9.2544\n",
      "[6132/8000] D loss: 0.2137, G loss: 11.5265\n",
      "[6492/8000] D loss: 0.1739, G loss: 6.7810\n",
      "[6852/8000] D loss: 0.3891, G loss: 8.6921\n",
      "[7212/8000] D loss: 0.1213, G loss: 8.4228\n",
      "[7572/8000] D loss: 0.0291, G loss: 13.4004\n",
      "[7932/8000] D loss: 0.1744, G loss: 11.1437\n",
      "train error: \n",
      " D loss: 0.251394, G loss: 8.541576, D accuracy: 93.0%, cell accuracy: 94.5%, board accuracy: 12.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.466052, G loss: 11.878540, D accuracy: 93.1%, cell accuracy: 94.1%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3825, G loss: 7.6161\n",
      "[372/8000] D loss: 0.2542, G loss: 8.4404\n",
      "[732/8000] D loss: 0.3790, G loss: 9.1210\n",
      "[1092/8000] D loss: 0.1618, G loss: 9.4758\n",
      "[1452/8000] D loss: 0.2685, G loss: 9.3941\n",
      "[1812/8000] D loss: 0.2935, G loss: 10.8916\n",
      "[2172/8000] D loss: 0.0773, G loss: 15.1403\n",
      "[2532/8000] D loss: 0.0583, G loss: 13.4879\n",
      "[2892/8000] D loss: 0.2631, G loss: 8.6193\n",
      "[3252/8000] D loss: 0.0569, G loss: 14.0711\n",
      "[3612/8000] D loss: 0.4956, G loss: 7.2379\n",
      "[3972/8000] D loss: 0.1225, G loss: 12.8401\n",
      "[4332/8000] D loss: 0.1060, G loss: 10.6357\n",
      "[4692/8000] D loss: 0.0109, G loss: 12.1609\n",
      "[5052/8000] D loss: 0.2730, G loss: 13.0358\n",
      "[5412/8000] D loss: 0.1267, G loss: 12.8868\n",
      "[5772/8000] D loss: 0.3120, G loss: 12.6601\n",
      "[6132/8000] D loss: 0.3460, G loss: 5.3990\n",
      "[6492/8000] D loss: 0.2415, G loss: 11.4743\n",
      "[6852/8000] D loss: 0.2376, G loss: 11.2008\n",
      "[7212/8000] D loss: 0.2542, G loss: 9.2448\n",
      "[7572/8000] D loss: 0.0530, G loss: 10.5496\n",
      "[7932/8000] D loss: 0.1158, G loss: 11.0247\n",
      "train error: \n",
      " D loss: 0.231605, G loss: 10.342780, D accuracy: 93.2%, cell accuracy: 94.5%, board accuracy: 12.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.565175, G loss: 13.932310, D accuracy: 92.1%, cell accuracy: 94.0%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0851, G loss: 9.0791\n",
      "[372/8000] D loss: 0.4082, G loss: 6.3286\n",
      "[732/8000] D loss: 0.2431, G loss: 12.3825\n",
      "[1092/8000] D loss: 0.3711, G loss: 7.9366\n",
      "[1452/8000] D loss: 0.3134, G loss: 12.5709\n",
      "[1812/8000] D loss: 0.3671, G loss: 10.8930\n",
      "[2172/8000] D loss: 0.2364, G loss: 10.3130\n",
      "[2532/8000] D loss: 0.1343, G loss: 10.9749\n",
      "[2892/8000] D loss: 0.1349, G loss: 10.2650\n",
      "[3252/8000] D loss: 0.2869, G loss: 10.1467\n",
      "[3612/8000] D loss: 0.1609, G loss: 12.4835\n",
      "[3972/8000] D loss: 0.0329, G loss: 9.8535\n",
      "[4332/8000] D loss: 0.4331, G loss: 5.3946\n",
      "[4692/8000] D loss: 0.2793, G loss: 11.0274\n",
      "[5052/8000] D loss: 0.4405, G loss: 10.0142\n",
      "[5412/8000] D loss: 0.5192, G loss: 8.1542\n",
      "[5772/8000] D loss: 0.0490, G loss: 10.5470\n",
      "[6132/8000] D loss: 0.3911, G loss: 10.0225\n",
      "[6492/8000] D loss: 0.2467, G loss: 12.0745\n",
      "[6852/8000] D loss: 0.2979, G loss: 8.9759\n",
      "[7212/8000] D loss: 0.1650, G loss: 11.1255\n",
      "[7572/8000] D loss: 0.2707, G loss: 9.1040\n",
      "[7932/8000] D loss: 0.0942, G loss: 11.6621\n",
      "train error: \n",
      " D loss: 0.231887, G loss: 10.127707, D accuracy: 93.3%, cell accuracy: 94.5%, board accuracy: 12.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.547475, G loss: 13.745622, D accuracy: 92.6%, cell accuracy: 94.0%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2379, G loss: 11.9449\n",
      "[372/8000] D loss: 0.2706, G loss: 7.4336\n",
      "[732/8000] D loss: 0.3181, G loss: 10.1413\n",
      "[1092/8000] D loss: 0.2782, G loss: 5.8317\n",
      "[1452/8000] D loss: 0.2712, G loss: 8.8304\n",
      "[1812/8000] D loss: 0.1605, G loss: 10.1184\n",
      "[2172/8000] D loss: 0.3536, G loss: 8.3447\n",
      "[2532/8000] D loss: 0.0502, G loss: 10.9746\n",
      "[2892/8000] D loss: 0.2900, G loss: 7.7941\n",
      "[3252/8000] D loss: 0.3178, G loss: 6.4971\n",
      "[3612/8000] D loss: 0.2851, G loss: 8.8866\n",
      "[3972/8000] D loss: 0.3979, G loss: 11.2173\n",
      "[4332/8000] D loss: 0.2353, G loss: 10.8776\n",
      "[4692/8000] D loss: 0.5085, G loss: 8.1529\n",
      "[5052/8000] D loss: 0.2277, G loss: 11.0251\n",
      "[5412/8000] D loss: 0.1556, G loss: 8.5763\n",
      "[5772/8000] D loss: 0.1922, G loss: 9.4788\n",
      "[6132/8000] D loss: 0.1206, G loss: 11.5211\n",
      "[6492/8000] D loss: 0.2439, G loss: 8.5784\n",
      "[6852/8000] D loss: 0.1244, G loss: 9.7010\n",
      "[7212/8000] D loss: 0.2476, G loss: 6.8666\n",
      "[7572/8000] D loss: 0.0070, G loss: 9.2700\n",
      "[7932/8000] D loss: 0.3772, G loss: 7.1240\n",
      "train error: \n",
      " D loss: 0.259151, G loss: 8.668551, D accuracy: 92.8%, cell accuracy: 94.5%, board accuracy: 12.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.489543, G loss: 12.078948, D accuracy: 92.6%, cell accuracy: 94.1%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0255, G loss: 9.5190\n",
      "[372/8000] D loss: 0.3714, G loss: 11.3270\n",
      "[732/8000] D loss: 0.4532, G loss: 8.3004\n",
      "[1092/8000] D loss: 0.2329, G loss: 10.4154\n",
      "[1452/8000] D loss: 1.0428, G loss: 9.3018\n",
      "[1812/8000] D loss: 0.1367, G loss: 13.0016\n",
      "[2172/8000] D loss: 0.3869, G loss: 10.3928\n",
      "[2532/8000] D loss: 0.3010, G loss: 10.5011\n",
      "[2892/8000] D loss: 0.3184, G loss: 6.2942\n",
      "[3252/8000] D loss: 0.1594, G loss: 10.0763\n",
      "[3612/8000] D loss: 0.1302, G loss: 9.8495\n",
      "[3972/8000] D loss: 0.3078, G loss: 8.1882\n",
      "[4332/8000] D loss: 0.7365, G loss: 6.6849\n",
      "[4692/8000] D loss: 0.0390, G loss: 10.7306\n",
      "[5052/8000] D loss: 0.2113, G loss: 8.8521\n",
      "[5412/8000] D loss: 0.1505, G loss: 9.4630\n",
      "[5772/8000] D loss: 0.2855, G loss: 8.6288\n",
      "[6132/8000] D loss: 0.0153, G loss: 10.1011\n",
      "[6492/8000] D loss: 0.4071, G loss: 7.8902\n",
      "[6852/8000] D loss: 0.2541, G loss: 14.3341\n",
      "[7212/8000] D loss: 0.3322, G loss: 12.7948\n",
      "[7572/8000] D loss: 0.0087, G loss: 10.2961\n",
      "[7932/8000] D loss: 0.1220, G loss: 10.0522\n",
      "train error: \n",
      " D loss: 0.229141, G loss: 10.344790, D accuracy: 93.4%, cell accuracy: 94.5%, board accuracy: 12.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.521737, G loss: 14.004122, D accuracy: 92.7%, cell accuracy: 94.1%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4034, G loss: 10.0593\n",
      "[372/8000] D loss: 0.1558, G loss: 7.3667\n",
      "[732/8000] D loss: 0.1094, G loss: 7.3648\n",
      "[1092/8000] D loss: 0.3284, G loss: 9.8973\n",
      "[1452/8000] D loss: 0.2972, G loss: 7.8027\n",
      "[1812/8000] D loss: 0.4570, G loss: 8.5907\n",
      "[2172/8000] D loss: 0.0092, G loss: 10.3026\n",
      "[2532/8000] D loss: 0.1218, G loss: 8.6996\n",
      "[2892/8000] D loss: 0.4086, G loss: 8.6284\n",
      "[3252/8000] D loss: 0.2229, G loss: 10.7462\n",
      "[3612/8000] D loss: 0.1217, G loss: 11.0602\n",
      "[3972/8000] D loss: 0.3611, G loss: 10.2933\n",
      "[4332/8000] D loss: 0.1928, G loss: 8.2818\n",
      "[4692/8000] D loss: 0.2418, G loss: 8.7454\n",
      "[5052/8000] D loss: 0.2684, G loss: 9.0223\n",
      "[5412/8000] D loss: 0.2611, G loss: 9.9622\n",
      "[5772/8000] D loss: 0.5190, G loss: 6.9863\n",
      "[6132/8000] D loss: 0.1943, G loss: 10.1358\n",
      "[6492/8000] D loss: 0.1875, G loss: 8.4226\n",
      "[6852/8000] D loss: 0.3274, G loss: 8.2716\n",
      "[7212/8000] D loss: 0.4867, G loss: 5.8218\n",
      "[7572/8000] D loss: 0.1282, G loss: 12.3981\n",
      "[7932/8000] D loss: 0.0603, G loss: 12.3539\n",
      "train error: \n",
      " D loss: 0.234398, G loss: 10.244034, D accuracy: 93.3%, cell accuracy: 94.5%, board accuracy: 12.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.542088, G loss: 13.691343, D accuracy: 92.8%, cell accuracy: 94.1%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1372, G loss: 12.2615\n",
      "[372/8000] D loss: 0.2505, G loss: 12.7306\n",
      "[732/8000] D loss: 0.2640, G loss: 10.2323\n",
      "[1092/8000] D loss: 0.0771, G loss: 8.4701\n",
      "[1452/8000] D loss: 0.1733, G loss: 11.4836\n",
      "[1812/8000] D loss: 0.0192, G loss: 13.1076\n",
      "[2172/8000] D loss: 0.0411, G loss: 10.4969\n",
      "[2532/8000] D loss: 0.1643, G loss: 9.3042\n",
      "[2892/8000] D loss: 0.4685, G loss: 8.9610\n",
      "[3252/8000] D loss: 0.2857, G loss: 11.2898\n",
      "[3612/8000] D loss: 0.3608, G loss: 10.8721\n",
      "[3972/8000] D loss: 0.3904, G loss: 9.6986\n",
      "[4332/8000] D loss: 0.1590, G loss: 10.9012\n",
      "[4692/8000] D loss: 0.1814, G loss: 10.8143\n",
      "[5052/8000] D loss: 0.0203, G loss: 12.4288\n",
      "[5412/8000] D loss: 0.0271, G loss: 9.9049\n",
      "[5772/8000] D loss: 0.2433, G loss: 13.5810\n",
      "[6132/8000] D loss: 0.3211, G loss: 11.9111\n",
      "[6492/8000] D loss: 0.4756, G loss: 8.3618\n",
      "[6852/8000] D loss: 0.1583, G loss: 10.8015\n",
      "[7212/8000] D loss: 0.2692, G loss: 11.3299\n",
      "[7572/8000] D loss: 0.1946, G loss: 10.8483\n",
      "[7932/8000] D loss: 0.1237, G loss: 11.7498\n",
      "train error: \n",
      " D loss: 0.246926, G loss: 10.802300, D accuracy: 92.9%, cell accuracy: 94.5%, board accuracy: 12.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.597439, G loss: 14.508415, D accuracy: 92.0%, cell accuracy: 94.1%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3141, G loss: 12.9228\n",
      "[372/8000] D loss: 0.2128, G loss: 7.6363\n",
      "[732/8000] D loss: 0.3286, G loss: 10.5829\n",
      "[1092/8000] D loss: 0.2560, G loss: 8.2352\n",
      "[1452/8000] D loss: 0.1598, G loss: 11.9058\n",
      "[1812/8000] D loss: 0.0114, G loss: 11.0855\n",
      "[2172/8000] D loss: 0.1603, G loss: 13.1550\n",
      "[2532/8000] D loss: 0.2584, G loss: 11.4744\n",
      "[2892/8000] D loss: 0.2939, G loss: 11.4551\n",
      "[3252/8000] D loss: 0.2430, G loss: 9.5615\n",
      "[3612/8000] D loss: 0.1454, G loss: 11.2336\n",
      "[3972/8000] D loss: 0.3681, G loss: 9.4762\n",
      "[4332/8000] D loss: 0.1981, G loss: 11.2948\n",
      "[4692/8000] D loss: 0.2658, G loss: 10.1005\n",
      "[5052/8000] D loss: 0.0042, G loss: 10.2116\n",
      "[5412/8000] D loss: 0.1341, G loss: 10.8901\n",
      "[5772/8000] D loss: 0.1852, G loss: 9.6534\n",
      "[6132/8000] D loss: 0.0447, G loss: 12.0668\n",
      "[6492/8000] D loss: 0.1112, G loss: 7.9119\n",
      "[6852/8000] D loss: 0.1164, G loss: 14.7070\n",
      "[7212/8000] D loss: 0.6461, G loss: 6.4011\n",
      "[7572/8000] D loss: 0.1222, G loss: 12.2208\n",
      "[7932/8000] D loss: 0.3818, G loss: 10.5190\n",
      "train error: \n",
      " D loss: 0.265207, G loss: 9.113182, D accuracy: 92.7%, cell accuracy: 94.5%, board accuracy: 12.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.485977, G loss: 12.844127, D accuracy: 93.4%, cell accuracy: 94.1%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2525, G loss: 7.1625\n",
      "[372/8000] D loss: 0.3643, G loss: 9.5591\n",
      "[732/8000] D loss: 0.5422, G loss: 9.6774\n",
      "[1092/8000] D loss: 0.2921, G loss: 10.8712\n",
      "[1452/8000] D loss: 0.2294, G loss: 12.4908\n",
      "[1812/8000] D loss: 0.0571, G loss: 12.5167\n",
      "[2172/8000] D loss: 0.2230, G loss: 9.4930\n",
      "[2532/8000] D loss: 0.1492, G loss: 9.7402\n",
      "[2892/8000] D loss: 0.2908, G loss: 7.8242\n",
      "[3252/8000] D loss: 0.2973, G loss: 9.5455\n",
      "[3612/8000] D loss: 0.1996, G loss: 10.2348\n",
      "[3972/8000] D loss: 0.3897, G loss: 7.7876\n",
      "[4332/8000] D loss: 0.5747, G loss: 5.9388\n",
      "[4692/8000] D loss: 0.0460, G loss: 12.2112\n",
      "[5052/8000] D loss: 0.0762, G loss: 10.4706\n",
      "[5412/8000] D loss: 0.3298, G loss: 8.0480\n",
      "[5772/8000] D loss: 0.1601, G loss: 11.5723\n",
      "[6132/8000] D loss: 0.1129, G loss: 8.4905\n",
      "[6492/8000] D loss: 0.3005, G loss: 12.2021\n",
      "[6852/8000] D loss: 0.2808, G loss: 10.3878\n",
      "[7212/8000] D loss: 0.3029, G loss: 8.1892\n",
      "[7572/8000] D loss: 0.6106, G loss: 4.7570\n",
      "[7932/8000] D loss: 0.2310, G loss: 10.9777\n",
      "train error: \n",
      " D loss: 0.236931, G loss: 10.295157, D accuracy: 93.1%, cell accuracy: 94.5%, board accuracy: 12.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.560437, G loss: 13.871511, D accuracy: 92.2%, cell accuracy: 94.1%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6066, G loss: 8.4698\n",
      "[372/8000] D loss: 0.1184, G loss: 11.0912\n",
      "[732/8000] D loss: 0.2289, G loss: 11.0866\n",
      "[1092/8000] D loss: 0.1389, G loss: 9.8235\n",
      "[1452/8000] D loss: 0.1186, G loss: 9.6007\n",
      "[1812/8000] D loss: 0.4627, G loss: 12.0091\n",
      "[2172/8000] D loss: 0.1561, G loss: 11.9944\n",
      "[2532/8000] D loss: 0.1964, G loss: 11.9420\n",
      "[2892/8000] D loss: 0.2776, G loss: 11.6301\n",
      "[3252/8000] D loss: 0.4310, G loss: 7.3949\n",
      "[3612/8000] D loss: 0.1357, G loss: 12.5870\n",
      "[3972/8000] D loss: 0.0482, G loss: 12.0767\n",
      "[4332/8000] D loss: 0.0260, G loss: 11.8129\n",
      "[4692/8000] D loss: 0.2069, G loss: 10.2462\n",
      "[5052/8000] D loss: 0.0121, G loss: 10.1546\n",
      "[5412/8000] D loss: 0.5337, G loss: 5.7313\n",
      "[5772/8000] D loss: 0.2686, G loss: 8.5870\n",
      "[6132/8000] D loss: 0.3236, G loss: 8.3014\n",
      "[6492/8000] D loss: 0.2703, G loss: 8.6918\n",
      "[6852/8000] D loss: 0.5192, G loss: 9.2059\n",
      "[7212/8000] D loss: 0.2375, G loss: 11.4843\n",
      "[7572/8000] D loss: 0.1302, G loss: 11.1852\n",
      "[7932/8000] D loss: 0.1543, G loss: 13.4462\n",
      "train error: \n",
      " D loss: 0.241169, G loss: 9.484637, D accuracy: 93.4%, cell accuracy: 94.5%, board accuracy: 12.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.520810, G loss: 12.932711, D accuracy: 92.7%, cell accuracy: 94.1%, board accuracy: 5.3% \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2602, G loss: 7.5926\n",
      "[372/8000] D loss: 0.2069, G loss: 7.9993\n",
      "[732/8000] D loss: 0.3096, G loss: 6.4511\n",
      "[1092/8000] D loss: 0.3859, G loss: 9.8509\n",
      "[1452/8000] D loss: 0.1160, G loss: 12.7760\n",
      "[1812/8000] D loss: 0.4504, G loss: 6.7473\n",
      "[2172/8000] D loss: 0.0041, G loss: 14.4556\n",
      "[2532/8000] D loss: 0.0309, G loss: 10.9041\n",
      "[2892/8000] D loss: 0.4063, G loss: 9.0355\n",
      "[3252/8000] D loss: 0.2709, G loss: 11.7161\n",
      "[3612/8000] D loss: 0.4795, G loss: 5.5442\n",
      "[3972/8000] D loss: 0.1259, G loss: 11.5489\n",
      "[4332/8000] D loss: 0.2716, G loss: 7.7690\n",
      "[4692/8000] D loss: 0.1309, G loss: 10.1431\n",
      "[5052/8000] D loss: 0.1325, G loss: 10.2583\n",
      "[5412/8000] D loss: 0.1339, G loss: 9.5604\n",
      "[5772/8000] D loss: 0.0022, G loss: 13.8876\n",
      "[6132/8000] D loss: 0.0048, G loss: 13.6970\n",
      "[6492/8000] D loss: 0.1659, G loss: 10.3522\n",
      "[6852/8000] D loss: 0.1823, G loss: 10.3734\n",
      "[7212/8000] D loss: 0.2794, G loss: 9.6167\n",
      "[7572/8000] D loss: 0.1710, G loss: 6.7124\n",
      "[7932/8000] D loss: 0.7300, G loss: 5.5884\n",
      "train error: \n",
      " D loss: 0.264181, G loss: 10.819327, D accuracy: 92.8%, cell accuracy: 94.6%, board accuracy: 12.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.632196, G loss: 14.497394, D accuracy: 91.7%, cell accuracy: 94.1%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2084, G loss: 10.1836\n",
      "[372/8000] D loss: 0.1284, G loss: 10.4840\n",
      "[732/8000] D loss: 0.3518, G loss: 12.7442\n",
      "[1092/8000] D loss: 0.1664, G loss: 6.6121\n",
      "[1452/8000] D loss: 0.1578, G loss: 11.0034\n",
      "[1812/8000] D loss: 0.5597, G loss: 7.8996\n",
      "[2172/8000] D loss: 0.5001, G loss: 4.6500\n",
      "[2532/8000] D loss: 0.1421, G loss: 9.2098\n",
      "[2892/8000] D loss: 0.4820, G loss: 4.9409\n",
      "[3252/8000] D loss: 0.0835, G loss: 13.3199\n",
      "[3612/8000] D loss: 0.2287, G loss: 8.4140\n",
      "[3972/8000] D loss: 0.2907, G loss: 10.2369\n",
      "[4332/8000] D loss: 0.1233, G loss: 11.7425\n",
      "[4692/8000] D loss: 0.1208, G loss: 11.3641\n",
      "[5052/8000] D loss: 0.1336, G loss: 9.6203\n",
      "[5412/8000] D loss: 0.2512, G loss: 11.6821\n",
      "[5772/8000] D loss: 0.2733, G loss: 12.0596\n",
      "[6132/8000] D loss: 0.2511, G loss: 11.6124\n",
      "[6492/8000] D loss: 0.1858, G loss: 9.6814\n",
      "[6852/8000] D loss: 0.0254, G loss: 10.1621\n",
      "[7212/8000] D loss: 0.1524, G loss: 13.1208\n",
      "[7572/8000] D loss: 0.3014, G loss: 11.2001\n",
      "[7932/8000] D loss: 0.1218, G loss: 10.1619\n",
      "train error: \n",
      " D loss: 0.234938, G loss: 9.337750, D accuracy: 93.3%, cell accuracy: 94.6%, board accuracy: 12.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.501786, G loss: 12.891471, D accuracy: 92.8%, cell accuracy: 94.1%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2073, G loss: 8.5032\n",
      "[372/8000] D loss: 0.1848, G loss: 10.5196\n",
      "[732/8000] D loss: 0.4739, G loss: 7.3528\n",
      "[1092/8000] D loss: 0.2221, G loss: 11.4664\n",
      "[1452/8000] D loss: 0.3374, G loss: 10.3851\n",
      "[1812/8000] D loss: 0.2546, G loss: 9.6247\n",
      "[2172/8000] D loss: 0.4622, G loss: 6.5953\n",
      "[2532/8000] D loss: 0.1697, G loss: 11.2465\n",
      "[2892/8000] D loss: 0.2119, G loss: 10.1983\n",
      "[3252/8000] D loss: 0.4988, G loss: 9.4638\n",
      "[3612/8000] D loss: 0.1261, G loss: 9.8870\n",
      "[3972/8000] D loss: 0.2399, G loss: 10.9770\n",
      "[4332/8000] D loss: 0.0099, G loss: 11.6026\n",
      "[4692/8000] D loss: 0.0103, G loss: 10.4160\n",
      "[5052/8000] D loss: 0.2285, G loss: 10.0775\n",
      "[5412/8000] D loss: 0.0127, G loss: 13.0835\n",
      "[5772/8000] D loss: 0.2718, G loss: 10.8863\n",
      "[6132/8000] D loss: 0.1435, G loss: 11.1336\n",
      "[6492/8000] D loss: 0.1452, G loss: 9.4079\n",
      "[6852/8000] D loss: 1.1870, G loss: 9.5351\n",
      "[7212/8000] D loss: 0.1084, G loss: 9.1789\n",
      "[7572/8000] D loss: 0.1323, G loss: 11.3899\n",
      "[7932/8000] D loss: 0.0089, G loss: 14.1990\n",
      "train error: \n",
      " D loss: 0.252593, G loss: 10.435202, D accuracy: 92.8%, cell accuracy: 94.6%, board accuracy: 12.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.625323, G loss: 13.927366, D accuracy: 91.6%, cell accuracy: 94.1%, board accuracy: 5.3% \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1633, G loss: 12.1718\n",
      "[372/8000] D loss: 0.1267, G loss: 11.0613\n",
      "[732/8000] D loss: 0.2720, G loss: 8.2623\n",
      "[1092/8000] D loss: 0.6269, G loss: 8.3334\n",
      "[1452/8000] D loss: 0.2985, G loss: 12.9964\n",
      "[1812/8000] D loss: 0.1686, G loss: 8.8427\n",
      "[2172/8000] D loss: 0.3680, G loss: 9.2230\n",
      "[2532/8000] D loss: 0.3471, G loss: 8.9508\n",
      "[2892/8000] D loss: 0.2705, G loss: 12.8486\n",
      "[3252/8000] D loss: 0.0144, G loss: 11.4879\n",
      "[3612/8000] D loss: 0.0419, G loss: 9.8946\n",
      "[3972/8000] D loss: 0.0199, G loss: 10.6693\n",
      "[4332/8000] D loss: 0.2759, G loss: 9.1781\n",
      "[4692/8000] D loss: 0.2273, G loss: 10.4210\n",
      "[5052/8000] D loss: 0.3474, G loss: 11.0380\n",
      "[5412/8000] D loss: 0.1262, G loss: 12.5103\n",
      "[5772/8000] D loss: 0.2829, G loss: 7.7611\n",
      "[6132/8000] D loss: 0.1528, G loss: 8.7863\n",
      "[6492/8000] D loss: 0.1011, G loss: 15.3347\n",
      "[6852/8000] D loss: 0.3832, G loss: 10.6062\n",
      "[7212/8000] D loss: 0.0541, G loss: 11.6876\n",
      "[7572/8000] D loss: 0.1115, G loss: 14.5173\n",
      "[7932/8000] D loss: 0.2684, G loss: 8.3792\n",
      "train error: \n",
      " D loss: 0.268960, G loss: 10.853803, D accuracy: 92.6%, cell accuracy: 94.6%, board accuracy: 12.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.573551, G loss: 14.690837, D accuracy: 92.4%, cell accuracy: 94.1%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1673, G loss: 13.0004\n",
      "[372/8000] D loss: 0.1701, G loss: 6.9279\n",
      "[732/8000] D loss: 0.6039, G loss: 7.0602\n",
      "[1092/8000] D loss: 0.5723, G loss: 5.4625\n",
      "[1452/8000] D loss: 0.1790, G loss: 9.5414\n",
      "[1812/8000] D loss: 0.1481, G loss: 13.3569\n",
      "[2172/8000] D loss: 0.1339, G loss: 15.1044\n",
      "[2532/8000] D loss: 0.3245, G loss: 14.0226\n",
      "[2892/8000] D loss: 0.1906, G loss: 11.7793\n",
      "[3252/8000] D loss: 0.2062, G loss: 12.7333\n",
      "[3612/8000] D loss: 0.0769, G loss: 13.5424\n",
      "[3972/8000] D loss: 0.3540, G loss: 7.5943\n",
      "[4332/8000] D loss: 0.1464, G loss: 9.5913\n",
      "[4692/8000] D loss: 0.3722, G loss: 9.0179\n",
      "[5052/8000] D loss: 0.0126, G loss: 13.1274\n",
      "[5412/8000] D loss: 0.3406, G loss: 10.9807\n",
      "[5772/8000] D loss: 0.1061, G loss: 12.8639\n",
      "[6132/8000] D loss: 0.4827, G loss: 7.0814\n",
      "[6492/8000] D loss: 0.1644, G loss: 9.4740\n",
      "[6852/8000] D loss: 0.0476, G loss: 12.0183\n",
      "[7212/8000] D loss: 0.3695, G loss: 10.4224\n",
      "[7572/8000] D loss: 0.0732, G loss: 9.3343\n",
      "[7932/8000] D loss: 0.1681, G loss: 11.0178\n",
      "train error: \n",
      " D loss: 0.256986, G loss: 10.556783, D accuracy: 92.7%, cell accuracy: 94.6%, board accuracy: 13.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.538109, G loss: 14.319605, D accuracy: 93.2%, cell accuracy: 94.1%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4065, G loss: 8.8496\n",
      "[372/8000] D loss: 0.1483, G loss: 11.4230\n",
      "[732/8000] D loss: 0.1413, G loss: 11.6857\n",
      "[1092/8000] D loss: 0.1385, G loss: 14.2446\n",
      "[1452/8000] D loss: 0.1049, G loss: 9.7788\n",
      "[1812/8000] D loss: 0.4194, G loss: 12.3055\n",
      "[2172/8000] D loss: 0.2807, G loss: 8.8670\n",
      "[2532/8000] D loss: 0.2262, G loss: 9.9369\n",
      "[2892/8000] D loss: 0.1388, G loss: 11.2948\n",
      "[3252/8000] D loss: 0.2175, G loss: 5.2546\n",
      "[3612/8000] D loss: 0.1948, G loss: 4.6725\n",
      "[3972/8000] D loss: 0.0075, G loss: 14.9442\n",
      "[4332/8000] D loss: 0.0030, G loss: 10.9394\n",
      "[4692/8000] D loss: 0.3767, G loss: 9.6361\n",
      "[5052/8000] D loss: 0.2246, G loss: 11.3814\n",
      "[5412/8000] D loss: 0.2563, G loss: 9.7213\n",
      "[5772/8000] D loss: 0.4081, G loss: 12.2009\n",
      "[6132/8000] D loss: 0.0132, G loss: 10.3732\n",
      "[6492/8000] D loss: 0.3507, G loss: 7.6934\n",
      "[6852/8000] D loss: 0.0029, G loss: 12.4092\n",
      "[7212/8000] D loss: 0.0785, G loss: 10.2041\n",
      "[7572/8000] D loss: 0.1472, G loss: 8.7429\n",
      "[7932/8000] D loss: 0.0079, G loss: 8.9906\n",
      "train error: \n",
      " D loss: 0.243206, G loss: 9.289765, D accuracy: 93.3%, cell accuracy: 94.6%, board accuracy: 12.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.535114, G loss: 12.762710, D accuracy: 92.4%, cell accuracy: 94.1%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1627, G loss: 12.3125\n",
      "[372/8000] D loss: 0.1142, G loss: 10.9517\n",
      "[732/8000] D loss: 0.1398, G loss: 8.3116\n",
      "[1092/8000] D loss: 0.1331, G loss: 10.4400\n",
      "[1452/8000] D loss: 0.6082, G loss: 7.4286\n",
      "[1812/8000] D loss: 0.5249, G loss: 7.1005\n",
      "[2172/8000] D loss: 0.2452, G loss: 6.4644\n",
      "[2532/8000] D loss: 0.3388, G loss: 8.3247\n",
      "[2892/8000] D loss: 0.0533, G loss: 9.1444\n",
      "[3252/8000] D loss: 0.1353, G loss: 9.6142\n",
      "[3612/8000] D loss: 0.3826, G loss: 9.5518\n",
      "[3972/8000] D loss: 0.0468, G loss: 13.9033\n",
      "[4332/8000] D loss: 0.0344, G loss: 11.5948\n",
      "[4692/8000] D loss: 0.1283, G loss: 12.9856\n",
      "[5052/8000] D loss: 0.1227, G loss: 10.6991\n",
      "[5412/8000] D loss: 0.2378, G loss: 11.1801\n",
      "[5772/8000] D loss: 0.2359, G loss: 9.2111\n",
      "[6132/8000] D loss: 0.2562, G loss: 8.1732\n",
      "[6492/8000] D loss: 0.0164, G loss: 12.0854\n",
      "[6852/8000] D loss: 0.2426, G loss: 8.7171\n",
      "[7212/8000] D loss: 0.3087, G loss: 8.9246\n",
      "[7572/8000] D loss: 0.1719, G loss: 13.1261\n",
      "[7932/8000] D loss: 0.5086, G loss: 10.5938\n",
      "train error: \n",
      " D loss: 0.252475, G loss: 10.362559, D accuracy: 92.9%, cell accuracy: 94.6%, board accuracy: 12.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.553579, G loss: 14.104968, D accuracy: 92.9%, cell accuracy: 94.1%, board accuracy: 5.3% \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1901, G loss: 9.6235\n",
      "[372/8000] D loss: 0.1411, G loss: 12.7386\n",
      "[732/8000] D loss: 0.2206, G loss: 16.9552\n",
      "[1092/8000] D loss: 0.5098, G loss: 9.6597\n",
      "[1452/8000] D loss: 0.2126, G loss: 6.4445\n",
      "[1812/8000] D loss: 0.3252, G loss: 10.4229\n",
      "[2172/8000] D loss: 0.5450, G loss: 8.0049\n",
      "[2532/8000] D loss: 0.1282, G loss: 9.7862\n",
      "[2892/8000] D loss: 0.3744, G loss: 7.0928\n",
      "[3252/8000] D loss: 0.0098, G loss: 11.2336\n",
      "[3612/8000] D loss: 0.2572, G loss: 12.1312\n",
      "[3972/8000] D loss: 0.2246, G loss: 10.7674\n",
      "[4332/8000] D loss: 0.1289, G loss: 9.1674\n",
      "[4692/8000] D loss: 0.2565, G loss: 13.8991\n",
      "[5052/8000] D loss: 0.1237, G loss: 11.9179\n",
      "[5412/8000] D loss: 0.3972, G loss: 9.9791\n",
      "[5772/8000] D loss: 0.2069, G loss: 9.1060\n",
      "[6132/8000] D loss: 0.4365, G loss: 8.1162\n",
      "[6492/8000] D loss: 0.2037, G loss: 12.0868\n",
      "[6852/8000] D loss: 0.0136, G loss: 10.0024\n",
      "[7212/8000] D loss: 0.2478, G loss: 9.6613\n",
      "[7572/8000] D loss: 0.1376, G loss: 9.9797\n",
      "[7932/8000] D loss: 0.6433, G loss: 5.3844\n",
      "train error: \n",
      " D loss: 0.255770, G loss: 9.684543, D accuracy: 92.9%, cell accuracy: 94.6%, board accuracy: 12.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.536366, G loss: 13.244386, D accuracy: 93.0%, cell accuracy: 94.2%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3066, G loss: 9.4142\n",
      "[372/8000] D loss: 0.0965, G loss: 8.9496\n",
      "[732/8000] D loss: 0.3176, G loss: 8.3497\n",
      "[1092/8000] D loss: 0.2432, G loss: 12.2177\n",
      "[1452/8000] D loss: 0.1334, G loss: 13.4862\n",
      "[1812/8000] D loss: 0.5930, G loss: 8.1265\n",
      "[2172/8000] D loss: 0.3805, G loss: 6.8883\n",
      "[2532/8000] D loss: 0.1268, G loss: 11.1380\n",
      "[2892/8000] D loss: 0.3786, G loss: 8.9891\n",
      "[3252/8000] D loss: 0.2777, G loss: 5.9036\n",
      "[3612/8000] D loss: 0.0383, G loss: 13.1670\n",
      "[3972/8000] D loss: 0.2593, G loss: 9.1997\n",
      "[4332/8000] D loss: 0.3716, G loss: 8.4405\n",
      "[4692/8000] D loss: 0.1211, G loss: 14.0091\n",
      "[5052/8000] D loss: 0.2730, G loss: 9.3987\n",
      "[5412/8000] D loss: 0.1487, G loss: 11.9087\n",
      "[5772/8000] D loss: 0.3853, G loss: 9.4947\n",
      "[6132/8000] D loss: 0.0090, G loss: 11.4175\n",
      "[6492/8000] D loss: 0.1547, G loss: 9.8040\n",
      "[6852/8000] D loss: 0.2530, G loss: 9.8881\n",
      "[7212/8000] D loss: 0.5031, G loss: 8.7341\n",
      "[7572/8000] D loss: 0.0874, G loss: 12.4628\n",
      "[7932/8000] D loss: 0.2806, G loss: 9.1411\n",
      "train error: \n",
      " D loss: 0.253165, G loss: 8.343798, D accuracy: 92.8%, cell accuracy: 94.6%, board accuracy: 12.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.465021, G loss: 11.745475, D accuracy: 92.7%, cell accuracy: 94.2%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0549, G loss: 10.4562\n",
      "[372/8000] D loss: 0.1676, G loss: 10.4063\n",
      "[732/8000] D loss: 0.2407, G loss: 12.1015\n",
      "[1092/8000] D loss: 0.3451, G loss: 9.8601\n",
      "[1452/8000] D loss: 0.2819, G loss: 9.9159\n",
      "[1812/8000] D loss: 0.0059, G loss: 11.3999\n",
      "[2172/8000] D loss: 0.1566, G loss: 12.3334\n",
      "[2532/8000] D loss: 0.0562, G loss: 10.2808\n",
      "[2892/8000] D loss: 0.2209, G loss: 12.3025\n",
      "[3252/8000] D loss: 0.1633, G loss: 10.0435\n",
      "[3612/8000] D loss: 0.0006, G loss: 15.8703\n",
      "[3972/8000] D loss: 0.4532, G loss: 9.2686\n",
      "[4332/8000] D loss: 0.1296, G loss: 15.7496\n",
      "[4692/8000] D loss: 0.4261, G loss: 9.7213\n",
      "[5052/8000] D loss: 0.0174, G loss: 10.9288\n",
      "[5412/8000] D loss: 0.2633, G loss: 8.9492\n",
      "[5772/8000] D loss: 0.1405, G loss: 12.4101\n",
      "[6132/8000] D loss: 0.2480, G loss: 9.1987\n",
      "[6492/8000] D loss: 0.3284, G loss: 7.0711\n",
      "[6852/8000] D loss: 0.2947, G loss: 13.3994\n",
      "[7212/8000] D loss: 0.2653, G loss: 7.6927\n",
      "[7572/8000] D loss: 0.0059, G loss: 14.7636\n",
      "[7932/8000] D loss: 0.0035, G loss: 11.8720\n",
      "train error: \n",
      " D loss: 0.246645, G loss: 9.499441, D accuracy: 92.9%, cell accuracy: 94.6%, board accuracy: 12.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.501170, G loss: 13.114824, D accuracy: 92.5%, cell accuracy: 94.2%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4659, G loss: 7.4019\n",
      "[372/8000] D loss: 0.1597, G loss: 11.3786\n",
      "[732/8000] D loss: 0.0684, G loss: 14.0747\n",
      "[1092/8000] D loss: 0.0273, G loss: 13.3531\n",
      "[1452/8000] D loss: 0.2981, G loss: 12.0776\n",
      "[1812/8000] D loss: 0.3480, G loss: 7.0350\n",
      "[2172/8000] D loss: 0.1579, G loss: 10.8012\n",
      "[2532/8000] D loss: 0.2835, G loss: 7.8045\n",
      "[2892/8000] D loss: 0.2380, G loss: 12.6929\n",
      "[3252/8000] D loss: 0.0167, G loss: 14.1667\n",
      "[3612/8000] D loss: 0.4226, G loss: 9.9420\n",
      "[3972/8000] D loss: 0.0283, G loss: 11.2205\n",
      "[4332/8000] D loss: 0.0685, G loss: 9.0551\n",
      "[4692/8000] D loss: 0.5476, G loss: 4.8402\n",
      "[5052/8000] D loss: 0.0068, G loss: 10.3987\n",
      "[5412/8000] D loss: 0.2870, G loss: 13.2448\n",
      "[5772/8000] D loss: 0.0114, G loss: 13.6328\n",
      "[6132/8000] D loss: 0.1854, G loss: 8.9801\n",
      "[6492/8000] D loss: 0.3947, G loss: 11.1215\n",
      "[6852/8000] D loss: 0.2375, G loss: 7.8457\n",
      "[7212/8000] D loss: 0.2536, G loss: 8.0363\n",
      "[7572/8000] D loss: 0.2602, G loss: 10.6517\n",
      "[7932/8000] D loss: 0.5242, G loss: 6.0351\n",
      "train error: \n",
      " D loss: 0.249069, G loss: 9.844418, D accuracy: 92.8%, cell accuracy: 94.6%, board accuracy: 12.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.571276, G loss: 13.154873, D accuracy: 91.8%, cell accuracy: 94.2%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1592, G loss: 10.6607\n",
      "[372/8000] D loss: 0.0490, G loss: 12.9874\n",
      "[732/8000] D loss: 0.1363, G loss: 10.8568\n",
      "[1092/8000] D loss: 0.0961, G loss: 11.5203\n",
      "[1452/8000] D loss: 0.3955, G loss: 6.7293\n",
      "[1812/8000] D loss: 0.2529, G loss: 12.6608\n",
      "[2172/8000] D loss: 0.6643, G loss: 8.4287\n",
      "[2532/8000] D loss: 0.2076, G loss: 10.7683\n",
      "[2892/8000] D loss: 0.1784, G loss: 11.1634\n",
      "[3252/8000] D loss: 0.2635, G loss: 9.0071\n",
      "[3612/8000] D loss: 0.0093, G loss: 10.9767\n",
      "[3972/8000] D loss: 0.2211, G loss: 11.0704\n",
      "[4332/8000] D loss: 0.4337, G loss: 9.9073\n",
      "[4692/8000] D loss: 0.1347, G loss: 8.6445\n",
      "[5052/8000] D loss: 0.3066, G loss: 9.4112\n",
      "[5412/8000] D loss: 0.4238, G loss: 6.9621\n",
      "[5772/8000] D loss: 0.0894, G loss: 10.4480\n",
      "[6132/8000] D loss: 0.0102, G loss: 11.0456\n",
      "[6492/8000] D loss: 0.2624, G loss: 12.9851\n",
      "[6852/8000] D loss: 0.2138, G loss: 12.4518\n",
      "[7212/8000] D loss: 0.2312, G loss: 10.5440\n",
      "[7572/8000] D loss: 0.1004, G loss: 12.9506\n",
      "[7932/8000] D loss: 0.0207, G loss: 15.1723\n",
      "train error: \n",
      " D loss: 0.254267, G loss: 9.413607, D accuracy: 92.8%, cell accuracy: 94.6%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.492200, G loss: 12.955909, D accuracy: 93.1%, cell accuracy: 94.2%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3189, G loss: 10.2127\n",
      "[372/8000] D loss: 0.4151, G loss: 9.0242\n",
      "[732/8000] D loss: 0.2243, G loss: 11.5947\n",
      "[1092/8000] D loss: 0.1306, G loss: 11.9220\n",
      "[1452/8000] D loss: 0.0040, G loss: 11.1928\n",
      "[1812/8000] D loss: 0.2720, G loss: 11.9668\n",
      "[2172/8000] D loss: 0.1323, G loss: 7.3508\n",
      "[2532/8000] D loss: 0.4164, G loss: 7.8044\n",
      "[2892/8000] D loss: 0.2539, G loss: 8.8829\n",
      "[3252/8000] D loss: 0.5286, G loss: 6.4533\n",
      "[3612/8000] D loss: 0.0076, G loss: 13.7162\n",
      "[3972/8000] D loss: 0.4842, G loss: 9.1291\n",
      "[4332/8000] D loss: 0.4308, G loss: 8.1369\n",
      "[4692/8000] D loss: 0.1295, G loss: 11.5387\n",
      "[5052/8000] D loss: 0.4291, G loss: 8.8934\n",
      "[5412/8000] D loss: 0.2256, G loss: 10.9151\n",
      "[5772/8000] D loss: 0.2862, G loss: 10.0596\n",
      "[6132/8000] D loss: 0.5463, G loss: 8.9585\n",
      "[6492/8000] D loss: 0.1935, G loss: 10.5432\n",
      "[6852/8000] D loss: 0.1530, G loss: 11.2594\n",
      "[7212/8000] D loss: 0.1481, G loss: 8.7577\n",
      "[7572/8000] D loss: 0.0350, G loss: 14.0732\n",
      "[7932/8000] D loss: 0.3003, G loss: 9.8989\n",
      "train error: \n",
      " D loss: 0.259286, G loss: 9.314911, D accuracy: 92.7%, cell accuracy: 94.6%, board accuracy: 13.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.515302, G loss: 12.734997, D accuracy: 93.3%, cell accuracy: 94.2%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3930, G loss: 11.5768\n",
      "[372/8000] D loss: 0.3640, G loss: 10.3285\n",
      "[732/8000] D loss: 0.1582, G loss: 10.2932\n",
      "[1092/8000] D loss: 0.2614, G loss: 10.0591\n",
      "[1452/8000] D loss: 0.3652, G loss: 8.6179\n",
      "[1812/8000] D loss: 0.3207, G loss: 10.6108\n",
      "[2172/8000] D loss: 0.0124, G loss: 11.7951\n",
      "[2532/8000] D loss: 0.1585, G loss: 8.8066\n",
      "[2892/8000] D loss: 0.2159, G loss: 13.6276\n",
      "[3252/8000] D loss: 0.1125, G loss: 11.4895\n",
      "[3612/8000] D loss: 0.2815, G loss: 8.4204\n",
      "[3972/8000] D loss: 0.1275, G loss: 13.2950\n",
      "[4332/8000] D loss: 0.5671, G loss: 6.2008\n",
      "[4692/8000] D loss: 0.2574, G loss: 9.3745\n",
      "[5052/8000] D loss: 0.0485, G loss: 10.4037\n",
      "[5412/8000] D loss: 0.2713, G loss: 11.0997\n",
      "[5772/8000] D loss: 0.4296, G loss: 9.0718\n",
      "[6132/8000] D loss: 0.1229, G loss: 9.1768\n",
      "[6492/8000] D loss: 0.5986, G loss: 9.0740\n",
      "[6852/8000] D loss: 0.5171, G loss: 8.2671\n",
      "[7212/8000] D loss: 0.0095, G loss: 11.0659\n",
      "[7572/8000] D loss: 0.0407, G loss: 14.0833\n",
      "[7932/8000] D loss: 0.1934, G loss: 11.4950\n",
      "train error: \n",
      " D loss: 0.258651, G loss: 9.361170, D accuracy: 92.7%, cell accuracy: 94.6%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.552853, G loss: 12.829153, D accuracy: 92.5%, cell accuracy: 94.2%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3211, G loss: 9.4003\n",
      "[372/8000] D loss: 0.0256, G loss: 10.5949\n",
      "[732/8000] D loss: 0.3921, G loss: 10.3701\n",
      "[1092/8000] D loss: 0.2674, G loss: 8.2472\n",
      "[1452/8000] D loss: 0.3701, G loss: 10.8020\n",
      "[1812/8000] D loss: 0.2553, G loss: 11.9866\n",
      "[2172/8000] D loss: 0.3726, G loss: 10.1150\n",
      "[2532/8000] D loss: 0.1437, G loss: 11.4734\n",
      "[2892/8000] D loss: 0.2754, G loss: 8.6139\n",
      "[3252/8000] D loss: 0.4054, G loss: 8.0792\n",
      "[3612/8000] D loss: 0.1666, G loss: 11.3348\n",
      "[3972/8000] D loss: 0.0714, G loss: 13.0283\n",
      "[4332/8000] D loss: 0.3838, G loss: 14.4665\n",
      "[4692/8000] D loss: 0.4550, G loss: 7.1154\n",
      "[5052/8000] D loss: 0.1854, G loss: 10.6822\n",
      "[5412/8000] D loss: 0.5134, G loss: 5.7449\n",
      "[5772/8000] D loss: 0.1419, G loss: 8.7823\n",
      "[6132/8000] D loss: 0.0882, G loss: 11.7735\n",
      "[6492/8000] D loss: 0.1350, G loss: 10.9409\n",
      "[6852/8000] D loss: 0.2311, G loss: 7.5706\n",
      "[7212/8000] D loss: 0.5087, G loss: 6.7840\n",
      "[7572/8000] D loss: 0.2352, G loss: 9.2670\n",
      "[7932/8000] D loss: 0.2192, G loss: 11.0021\n",
      "train error: \n",
      " D loss: 0.237914, G loss: 9.921365, D accuracy: 93.0%, cell accuracy: 94.6%, board accuracy: 13.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.540635, G loss: 13.479395, D accuracy: 92.8%, cell accuracy: 94.2%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3652, G loss: 10.8347\n",
      "[372/8000] D loss: 0.2616, G loss: 10.1836\n",
      "[732/8000] D loss: 0.1949, G loss: 6.6127\n",
      "[1092/8000] D loss: 0.2641, G loss: 9.2005\n",
      "[1452/8000] D loss: 0.0494, G loss: 14.8112\n",
      "[1812/8000] D loss: 0.0176, G loss: 11.2634\n",
      "[2172/8000] D loss: 0.1447, G loss: 10.6922\n",
      "[2532/8000] D loss: 0.2397, G loss: 8.9260\n",
      "[2892/8000] D loss: 0.3063, G loss: 14.7888\n",
      "[3252/8000] D loss: 0.1718, G loss: 8.0317\n",
      "[3612/8000] D loss: 0.2915, G loss: 8.8140\n",
      "[3972/8000] D loss: 0.2717, G loss: 9.9672\n",
      "[4332/8000] D loss: 0.1276, G loss: 10.9245\n",
      "[4692/8000] D loss: 0.2372, G loss: 14.1597\n",
      "[5052/8000] D loss: 0.2075, G loss: 6.9436\n",
      "[5412/8000] D loss: 0.0351, G loss: 13.5078\n",
      "[5772/8000] D loss: 0.3584, G loss: 7.3749\n",
      "[6132/8000] D loss: 0.2043, G loss: 9.5431\n",
      "[6492/8000] D loss: 0.0759, G loss: 8.3130\n",
      "[6852/8000] D loss: 0.2383, G loss: 7.4778\n",
      "[7212/8000] D loss: 0.2353, G loss: 8.2360\n",
      "[7572/8000] D loss: 0.3147, G loss: 10.2533\n",
      "[7932/8000] D loss: 0.3875, G loss: 9.0685\n",
      "train error: \n",
      " D loss: 0.241452, G loss: 10.080089, D accuracy: 93.0%, cell accuracy: 94.6%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.527047, G loss: 13.740492, D accuracy: 92.8%, cell accuracy: 94.2%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1221, G loss: 10.9428\n",
      "[372/8000] D loss: 0.0867, G loss: 11.8711\n",
      "[732/8000] D loss: 0.4644, G loss: 9.1654\n",
      "[1092/8000] D loss: 0.3260, G loss: 8.3989\n",
      "[1452/8000] D loss: 0.1257, G loss: 9.0337\n",
      "[1812/8000] D loss: 0.2747, G loss: 10.1930\n",
      "[2172/8000] D loss: 0.2584, G loss: 10.6875\n",
      "[2532/8000] D loss: 0.6180, G loss: 4.8982\n",
      "[2892/8000] D loss: 0.2598, G loss: 11.8597\n",
      "[3252/8000] D loss: 0.3859, G loss: 6.3411\n",
      "[3612/8000] D loss: 0.0569, G loss: 12.9363\n",
      "[3972/8000] D loss: 0.3618, G loss: 10.3388\n",
      "[4332/8000] D loss: 0.0363, G loss: 15.2690\n",
      "[4692/8000] D loss: 0.0065, G loss: 11.6272\n",
      "[5052/8000] D loss: 0.1463, G loss: 8.4073\n",
      "[5412/8000] D loss: 0.2220, G loss: 10.4360\n",
      "[5772/8000] D loss: 0.2694, G loss: 9.9326\n",
      "[6132/8000] D loss: 0.2461, G loss: 10.9261\n",
      "[6492/8000] D loss: 0.3368, G loss: 10.0320\n",
      "[6852/8000] D loss: 0.2584, G loss: 11.1423\n",
      "[7212/8000] D loss: 0.4656, G loss: 6.4908\n",
      "[7572/8000] D loss: 0.2284, G loss: 10.1829\n",
      "[7932/8000] D loss: 0.2947, G loss: 9.8515\n",
      "train error: \n",
      " D loss: 0.244191, G loss: 10.116386, D accuracy: 93.0%, cell accuracy: 94.6%, board accuracy: 13.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.566041, G loss: 13.655971, D accuracy: 92.4%, cell accuracy: 94.2%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2026, G loss: 10.6012\n",
      "[372/8000] D loss: 0.1351, G loss: 10.3795\n",
      "[732/8000] D loss: 0.0487, G loss: 6.7751\n",
      "[1092/8000] D loss: 0.1527, G loss: 15.0093\n",
      "[1452/8000] D loss: 0.2029, G loss: 8.7069\n",
      "[1812/8000] D loss: 0.1196, G loss: 9.3271\n",
      "[2172/8000] D loss: 0.4891, G loss: 7.3550\n",
      "[2532/8000] D loss: 0.4602, G loss: 9.2954\n",
      "[2892/8000] D loss: 0.0191, G loss: 8.9487\n",
      "[3252/8000] D loss: 0.5418, G loss: 11.6744\n",
      "[3612/8000] D loss: 0.4711, G loss: 12.5909\n",
      "[3972/8000] D loss: 0.1637, G loss: 11.9647\n",
      "[4332/8000] D loss: 0.3166, G loss: 10.1295\n",
      "[4692/8000] D loss: 0.0201, G loss: 10.1941\n",
      "[5052/8000] D loss: 0.1436, G loss: 11.5180\n",
      "[5412/8000] D loss: 0.3000, G loss: 12.9716\n",
      "[5772/8000] D loss: 0.3260, G loss: 5.4466\n",
      "[6132/8000] D loss: 0.3183, G loss: 9.2272\n",
      "[6492/8000] D loss: 0.2458, G loss: 7.8244\n",
      "[6852/8000] D loss: 0.1810, G loss: 9.7760\n",
      "[7212/8000] D loss: 0.0045, G loss: 10.2756\n",
      "[7572/8000] D loss: 0.0150, G loss: 10.0569\n",
      "[7932/8000] D loss: 0.0041, G loss: 14.7808\n",
      "train error: \n",
      " D loss: 0.241528, G loss: 10.394227, D accuracy: 93.0%, cell accuracy: 94.6%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.560067, G loss: 14.203115, D accuracy: 92.8%, cell accuracy: 94.2%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2519, G loss: 11.8419\n",
      "[372/8000] D loss: 0.1225, G loss: 13.9799\n",
      "[732/8000] D loss: 0.1221, G loss: 12.7278\n",
      "[1092/8000] D loss: 0.3848, G loss: 7.5457\n",
      "[1452/8000] D loss: 0.1169, G loss: 9.1683\n",
      "[1812/8000] D loss: 0.3704, G loss: 8.8028\n",
      "[2172/8000] D loss: 0.1073, G loss: 8.4674\n",
      "[2532/8000] D loss: 0.0021, G loss: 13.2144\n",
      "[2892/8000] D loss: 0.1608, G loss: 12.3127\n",
      "[3252/8000] D loss: 0.2881, G loss: 10.5706\n",
      "[3612/8000] D loss: 0.3303, G loss: 6.4960\n",
      "[3972/8000] D loss: 0.2515, G loss: 6.1913\n",
      "[4332/8000] D loss: 0.4809, G loss: 6.2372\n",
      "[4692/8000] D loss: 0.2981, G loss: 4.6644\n",
      "[5052/8000] D loss: 0.2710, G loss: 8.9980\n",
      "[5412/8000] D loss: 0.2655, G loss: 9.1942\n",
      "[5772/8000] D loss: 0.5641, G loss: 10.2527\n",
      "[6132/8000] D loss: 0.6412, G loss: 8.0080\n",
      "[6492/8000] D loss: 0.2552, G loss: 8.9069\n",
      "[6852/8000] D loss: 0.3560, G loss: 8.4255\n",
      "[7212/8000] D loss: 0.2223, G loss: 8.0295\n",
      "[7572/8000] D loss: 0.4424, G loss: 5.8117\n",
      "[7932/8000] D loss: 0.2527, G loss: 9.0940\n",
      "train error: \n",
      " D loss: 0.238934, G loss: 10.048617, D accuracy: 93.0%, cell accuracy: 94.6%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.539186, G loss: 13.717810, D accuracy: 92.5%, cell accuracy: 94.2%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0370, G loss: 8.5773\n",
      "[372/8000] D loss: 0.1334, G loss: 13.9674\n",
      "[732/8000] D loss: 0.0096, G loss: 8.9936\n",
      "[1092/8000] D loss: 0.2286, G loss: 9.5979\n",
      "[1452/8000] D loss: 0.3745, G loss: 9.0451\n",
      "[1812/8000] D loss: 0.6672, G loss: 6.9514\n",
      "[2172/8000] D loss: 0.1939, G loss: 9.7629\n",
      "[2532/8000] D loss: 0.2549, G loss: 7.3380\n",
      "[2892/8000] D loss: 0.2134, G loss: 7.9249\n",
      "[3252/8000] D loss: 0.4383, G loss: 7.7704\n",
      "[3612/8000] D loss: 0.4592, G loss: 9.3874\n",
      "[3972/8000] D loss: 0.5053, G loss: 10.0469\n",
      "[4332/8000] D loss: 0.0156, G loss: 12.6611\n",
      "[4692/8000] D loss: 0.6173, G loss: 8.4483\n",
      "[5052/8000] D loss: 0.4265, G loss: 8.8685\n",
      "[5412/8000] D loss: 0.0688, G loss: 8.7867\n",
      "[5772/8000] D loss: 0.1368, G loss: 12.4648\n",
      "[6132/8000] D loss: 0.0867, G loss: 9.3225\n",
      "[6492/8000] D loss: 0.2944, G loss: 8.3872\n",
      "[6852/8000] D loss: 0.2083, G loss: 8.3076\n",
      "[7212/8000] D loss: 0.7148, G loss: 7.3838\n",
      "[7572/8000] D loss: 0.2339, G loss: 6.7136\n",
      "[7932/8000] D loss: 0.0156, G loss: 9.9962\n",
      "train error: \n",
      " D loss: 0.401174, G loss: 13.413016, D accuracy: 90.5%, cell accuracy: 94.6%, board accuracy: 12.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.930338, G loss: 17.199680, D accuracy: 87.6%, cell accuracy: 94.2%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4104, G loss: 12.8366\n",
      "[372/8000] D loss: 0.2543, G loss: 9.7803\n",
      "[732/8000] D loss: 0.1248, G loss: 11.1973\n",
      "[1092/8000] D loss: 0.2465, G loss: 8.8255\n",
      "[1452/8000] D loss: 0.2525, G loss: 8.6002\n",
      "[1812/8000] D loss: 0.3162, G loss: 8.9092\n",
      "[2172/8000] D loss: 0.1680, G loss: 8.4704\n",
      "[2532/8000] D loss: 0.2503, G loss: 10.1746\n",
      "[2892/8000] D loss: 0.1164, G loss: 11.4184\n",
      "[3252/8000] D loss: 0.0783, G loss: 9.9097\n",
      "[3612/8000] D loss: 0.2538, G loss: 8.9755\n",
      "[3972/8000] D loss: 0.2990, G loss: 9.5504\n",
      "[4332/8000] D loss: 0.2509, G loss: 8.2590\n",
      "[4692/8000] D loss: 0.1245, G loss: 9.2617\n",
      "[5052/8000] D loss: 0.4084, G loss: 9.3641\n",
      "[5412/8000] D loss: 0.3822, G loss: 7.7638\n",
      "[5772/8000] D loss: 0.0584, G loss: 11.7547\n",
      "[6132/8000] D loss: 0.6276, G loss: 5.9827\n",
      "[6492/8000] D loss: 0.4674, G loss: 11.0793\n",
      "[6852/8000] D loss: 0.0060, G loss: 15.1307\n",
      "[7212/8000] D loss: 0.2939, G loss: 9.2404\n",
      "[7572/8000] D loss: 0.1313, G loss: 10.0595\n",
      "[7932/8000] D loss: 0.3522, G loss: 7.8965\n",
      "train error: \n",
      " D loss: 0.241396, G loss: 10.645117, D accuracy: 92.9%, cell accuracy: 94.7%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.589534, G loss: 14.423400, D accuracy: 91.8%, cell accuracy: 94.2%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3671, G loss: 7.0278\n",
      "[372/8000] D loss: 0.2339, G loss: 9.2295\n",
      "[732/8000] D loss: 0.2322, G loss: 9.0791\n",
      "[1092/8000] D loss: 0.0128, G loss: 9.7562\n",
      "[1452/8000] D loss: 0.0366, G loss: 13.1233\n",
      "[1812/8000] D loss: 0.1416, G loss: 9.9178\n",
      "[2172/8000] D loss: 0.1112, G loss: 11.7127\n",
      "[2532/8000] D loss: 0.2561, G loss: 14.3151\n",
      "[2892/8000] D loss: 0.2326, G loss: 12.8371\n",
      "[3252/8000] D loss: 0.2563, G loss: 11.0189\n",
      "[3612/8000] D loss: 0.3172, G loss: 9.2632\n",
      "[3972/8000] D loss: 0.2474, G loss: 10.2711\n",
      "[4332/8000] D loss: 0.2262, G loss: 7.5899\n",
      "[4692/8000] D loss: 0.2148, G loss: 12.2598\n",
      "[5052/8000] D loss: 0.3867, G loss: 8.3575\n",
      "[5412/8000] D loss: 0.1392, G loss: 13.7979\n",
      "[5772/8000] D loss: 0.3230, G loss: 9.3177\n",
      "[6132/8000] D loss: 0.2797, G loss: 12.1553\n",
      "[6492/8000] D loss: 0.7081, G loss: 6.5990\n",
      "[6852/8000] D loss: 0.0980, G loss: 9.4327\n",
      "[7212/8000] D loss: 0.2637, G loss: 11.1366\n",
      "[7572/8000] D loss: 0.5000, G loss: 9.0068\n",
      "[7932/8000] D loss: 0.4411, G loss: 7.8274\n",
      "train error: \n",
      " D loss: 0.264821, G loss: 11.437426, D accuracy: 92.6%, cell accuracy: 94.6%, board accuracy: 13.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609142, G loss: 15.538326, D accuracy: 93.0%, cell accuracy: 94.2%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3536, G loss: 10.1526\n",
      "[372/8000] D loss: 0.2188, G loss: 11.3856\n",
      "[732/8000] D loss: 0.1306, G loss: 10.3436\n",
      "[1092/8000] D loss: 0.1827, G loss: 14.2578\n",
      "[1452/8000] D loss: 0.3152, G loss: 7.1882\n",
      "[1812/8000] D loss: 0.1538, G loss: 13.3995\n",
      "[2172/8000] D loss: 0.5505, G loss: 10.3244\n",
      "[2532/8000] D loss: 0.2247, G loss: 13.8734\n",
      "[2892/8000] D loss: 0.1432, G loss: 8.7091\n",
      "[3252/8000] D loss: 0.4278, G loss: 11.2478\n",
      "[3612/8000] D loss: 0.2546, G loss: 13.5041\n",
      "[3972/8000] D loss: 0.3599, G loss: 11.2769\n",
      "[4332/8000] D loss: 0.3063, G loss: 9.7881\n",
      "[4692/8000] D loss: 0.0771, G loss: 13.7418\n",
      "[5052/8000] D loss: 0.3485, G loss: 12.4094\n",
      "[5412/8000] D loss: 0.3969, G loss: 11.6382\n",
      "[5772/8000] D loss: 0.2017, G loss: 7.9841\n",
      "[6132/8000] D loss: 0.3430, G loss: 11.9722\n",
      "[6492/8000] D loss: 0.2002, G loss: 7.8576\n",
      "[6852/8000] D loss: 0.1756, G loss: 9.9808\n",
      "[7212/8000] D loss: 0.6141, G loss: 5.7740\n",
      "[7572/8000] D loss: 0.1390, G loss: 7.1972\n",
      "[7932/8000] D loss: 0.3280, G loss: 10.3397\n",
      "train error: \n",
      " D loss: 0.237966, G loss: 10.648874, D accuracy: 92.9%, cell accuracy: 94.7%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.577154, G loss: 14.555495, D accuracy: 92.3%, cell accuracy: 94.2%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3525, G loss: 8.4093\n",
      "[372/8000] D loss: 0.2306, G loss: 7.3998\n",
      "[732/8000] D loss: 0.4027, G loss: 8.6067\n",
      "[1092/8000] D loss: 0.0071, G loss: 14.8644\n",
      "[1452/8000] D loss: 0.1212, G loss: 9.7564\n",
      "[1812/8000] D loss: 0.4043, G loss: 8.5018\n",
      "[2172/8000] D loss: 0.1221, G loss: 10.6121\n",
      "[2532/8000] D loss: 0.1003, G loss: 10.2619\n",
      "[2892/8000] D loss: 0.1381, G loss: 9.2624\n",
      "[3252/8000] D loss: 0.1090, G loss: 15.2024\n",
      "[3612/8000] D loss: 0.0735, G loss: 8.6491\n",
      "[3972/8000] D loss: 0.3612, G loss: 12.9872\n",
      "[4332/8000] D loss: 0.1895, G loss: 7.2244\n",
      "[4692/8000] D loss: 0.0440, G loss: 9.5771\n",
      "[5052/8000] D loss: 0.0325, G loss: 11.4713\n",
      "[5412/8000] D loss: 0.1903, G loss: 9.5507\n",
      "[5772/8000] D loss: 0.2627, G loss: 10.3351\n",
      "[6132/8000] D loss: 0.2330, G loss: 10.0352\n",
      "[6492/8000] D loss: 0.1346, G loss: 11.8484\n",
      "[6852/8000] D loss: 0.0225, G loss: 11.3749\n",
      "[7212/8000] D loss: 0.2800, G loss: 9.5399\n",
      "[7572/8000] D loss: 0.2335, G loss: 10.4093\n",
      "[7932/8000] D loss: 0.5562, G loss: 8.6421\n",
      "train error: \n",
      " D loss: 0.263512, G loss: 9.034242, D accuracy: 92.6%, cell accuracy: 94.7%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.488279, G loss: 12.686585, D accuracy: 93.2%, cell accuracy: 94.2%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4882, G loss: 9.0152\n",
      "[372/8000] D loss: 0.2354, G loss: 9.4927\n",
      "[732/8000] D loss: 0.2815, G loss: 8.9568\n",
      "[1092/8000] D loss: 0.3076, G loss: 14.2956\n",
      "[1452/8000] D loss: 0.6947, G loss: 7.2831\n",
      "[1812/8000] D loss: 0.3098, G loss: 8.6879\n",
      "[2172/8000] D loss: 0.2369, G loss: 6.5213\n",
      "[2532/8000] D loss: 0.2999, G loss: 6.7002\n",
      "[2892/8000] D loss: 0.2547, G loss: 7.7817\n",
      "[3252/8000] D loss: 0.3601, G loss: 10.3911\n",
      "[3612/8000] D loss: 0.4208, G loss: 8.1685\n",
      "[3972/8000] D loss: 0.3578, G loss: 10.2437\n",
      "[4332/8000] D loss: 0.4070, G loss: 12.0325\n",
      "[4692/8000] D loss: 0.2052, G loss: 11.7187\n",
      "[5052/8000] D loss: 0.2859, G loss: 11.0010\n",
      "[5412/8000] D loss: 0.2841, G loss: 9.5710\n",
      "[5772/8000] D loss: 0.2201, G loss: 7.9695\n",
      "[6132/8000] D loss: 0.4249, G loss: 8.1053\n",
      "[6492/8000] D loss: 0.0052, G loss: 12.6981\n",
      "[6852/8000] D loss: 0.1293, G loss: 10.4337\n",
      "[7212/8000] D loss: 0.3451, G loss: 8.2936\n",
      "[7572/8000] D loss: 0.0545, G loss: 15.9673\n",
      "[7932/8000] D loss: 0.2534, G loss: 10.3532\n",
      "train error: \n",
      " D loss: 0.245097, G loss: 10.209887, D accuracy: 92.9%, cell accuracy: 94.7%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.559267, G loss: 14.094253, D accuracy: 93.1%, cell accuracy: 94.2%, board accuracy: 5.6% \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0020, G loss: 12.2511\n",
      "[372/8000] D loss: 0.3227, G loss: 9.6283\n",
      "[732/8000] D loss: 0.1737, G loss: 8.5598\n",
      "[1092/8000] D loss: 0.3800, G loss: 10.1716\n",
      "[1452/8000] D loss: 0.1604, G loss: 10.4660\n",
      "[1812/8000] D loss: 0.1620, G loss: 9.9780\n",
      "[2172/8000] D loss: 0.1170, G loss: 12.5777\n",
      "[2532/8000] D loss: 0.0597, G loss: 11.3757\n",
      "[2892/8000] D loss: 0.0306, G loss: 13.2904\n",
      "[3252/8000] D loss: 0.2095, G loss: 9.6259\n",
      "[3612/8000] D loss: 0.1416, G loss: 15.1218\n",
      "[3972/8000] D loss: 0.0329, G loss: 10.4498\n",
      "[4332/8000] D loss: 0.2555, G loss: 7.3852\n",
      "[4692/8000] D loss: 0.2636, G loss: 7.6795\n",
      "[5052/8000] D loss: 0.2524, G loss: 8.4095\n",
      "[5412/8000] D loss: 0.5766, G loss: 7.2790\n",
      "[5772/8000] D loss: 0.2083, G loss: 10.2939\n",
      "[6132/8000] D loss: 0.2787, G loss: 8.5265\n",
      "[6492/8000] D loss: 0.2103, G loss: 9.5659\n",
      "[6852/8000] D loss: 0.0773, G loss: 10.0923\n",
      "[7212/8000] D loss: 0.4368, G loss: 8.0762\n",
      "[7572/8000] D loss: 0.0194, G loss: 12.0040\n",
      "[7932/8000] D loss: 0.0690, G loss: 13.4344\n",
      "train error: \n",
      " D loss: 0.252858, G loss: 9.686711, D accuracy: 92.7%, cell accuracy: 94.7%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.502909, G loss: 13.516494, D accuracy: 93.2%, cell accuracy: 94.2%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1113, G loss: 10.1317\n",
      "[372/8000] D loss: 0.4740, G loss: 7.5336\n",
      "[732/8000] D loss: 0.2575, G loss: 14.3804\n",
      "[1092/8000] D loss: 0.1199, G loss: 11.7600\n",
      "[1452/8000] D loss: 0.3968, G loss: 7.1309\n",
      "[1812/8000] D loss: 0.4377, G loss: 7.5753\n",
      "[2172/8000] D loss: 0.8157, G loss: 7.4113\n",
      "[2532/8000] D loss: 0.1146, G loss: 13.4700\n",
      "[2892/8000] D loss: 0.0244, G loss: 8.4404\n",
      "[3252/8000] D loss: 0.2647, G loss: 9.1178\n",
      "[3612/8000] D loss: 0.2293, G loss: 10.1094\n",
      "[3972/8000] D loss: 0.2523, G loss: 10.6464\n",
      "[4332/8000] D loss: 0.1276, G loss: 10.8873\n",
      "[4692/8000] D loss: 0.1590, G loss: 7.9360\n",
      "[5052/8000] D loss: 0.0504, G loss: 16.0380\n",
      "[5412/8000] D loss: 0.2693, G loss: 10.5875\n",
      "[5772/8000] D loss: 0.0218, G loss: 11.4045\n",
      "[6132/8000] D loss: 0.3610, G loss: 11.3331\n",
      "[6492/8000] D loss: 0.1630, G loss: 10.4078\n",
      "[6852/8000] D loss: 0.0545, G loss: 13.6517\n",
      "[7212/8000] D loss: 0.5653, G loss: 9.5417\n",
      "[7572/8000] D loss: 0.2628, G loss: 11.6337\n",
      "[7932/8000] D loss: 0.4350, G loss: 11.1110\n",
      "train error: \n",
      " D loss: 0.292535, G loss: 8.662032, D accuracy: 92.0%, cell accuracy: 94.7%, board accuracy: 13.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.497948, G loss: 12.376318, D accuracy: 92.8%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1228, G loss: 10.6213\n",
      "[372/8000] D loss: 0.3103, G loss: 8.8440\n",
      "[732/8000] D loss: 0.1454, G loss: 10.9897\n",
      "[1092/8000] D loss: 0.0021, G loss: 18.1439\n",
      "[1452/8000] D loss: 0.2106, G loss: 13.2645\n",
      "[1812/8000] D loss: 0.1177, G loss: 12.1242\n",
      "[2172/8000] D loss: 0.2689, G loss: 12.9429\n",
      "[2532/8000] D loss: 0.2780, G loss: 11.7851\n",
      "[2892/8000] D loss: 0.1195, G loss: 12.8476\n",
      "[3252/8000] D loss: 0.3689, G loss: 9.1237\n",
      "[3612/8000] D loss: 0.3687, G loss: 10.9192\n",
      "[3972/8000] D loss: 0.3006, G loss: 9.2593\n",
      "[4332/8000] D loss: 0.3274, G loss: 12.6583\n",
      "[4692/8000] D loss: 0.1519, G loss: 8.4277\n",
      "[5052/8000] D loss: 0.5438, G loss: 8.2306\n",
      "[5412/8000] D loss: 0.1983, G loss: 13.0967\n",
      "[5772/8000] D loss: 0.1234, G loss: 8.8758\n",
      "[6132/8000] D loss: 0.3743, G loss: 9.2380\n",
      "[6492/8000] D loss: 0.3500, G loss: 8.7293\n",
      "[6852/8000] D loss: 0.2255, G loss: 9.9039\n",
      "[7212/8000] D loss: 0.3057, G loss: 6.7932\n",
      "[7572/8000] D loss: 0.2946, G loss: 9.5332\n",
      "[7932/8000] D loss: 0.1456, G loss: 10.1601\n",
      "train error: \n",
      " D loss: 0.248682, G loss: 10.701407, D accuracy: 92.9%, cell accuracy: 94.7%, board accuracy: 13.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.565512, G loss: 14.248787, D accuracy: 92.6%, cell accuracy: 94.3%, board accuracy: 5.3% \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1477, G loss: 13.9183\n",
      "[372/8000] D loss: 0.1587, G loss: 9.2005\n",
      "[732/8000] D loss: 0.2616, G loss: 15.1297\n",
      "[1092/8000] D loss: 0.2031, G loss: 7.9994\n",
      "[1452/8000] D loss: 0.4910, G loss: 9.2822\n",
      "[1812/8000] D loss: 0.3846, G loss: 8.5367\n",
      "[2172/8000] D loss: 0.5084, G loss: 8.3514\n",
      "[2532/8000] D loss: 0.1186, G loss: 10.6327\n",
      "[2892/8000] D loss: 0.2711, G loss: 8.9195\n",
      "[3252/8000] D loss: 0.1296, G loss: 13.8110\n",
      "[3612/8000] D loss: 0.2558, G loss: 7.7425\n",
      "[3972/8000] D loss: 0.4689, G loss: 7.5050\n",
      "[4332/8000] D loss: 0.2564, G loss: 11.4563\n",
      "[4692/8000] D loss: 0.2796, G loss: 11.7034\n",
      "[5052/8000] D loss: 0.2931, G loss: 9.6944\n",
      "[5412/8000] D loss: 0.2512, G loss: 8.4648\n",
      "[5772/8000] D loss: 0.1111, G loss: 10.3122\n",
      "[6132/8000] D loss: 0.1531, G loss: 13.9660\n",
      "[6492/8000] D loss: 0.2091, G loss: 12.6409\n",
      "[6852/8000] D loss: 0.0248, G loss: 10.0957\n",
      "[7212/8000] D loss: 0.3143, G loss: 11.1146\n",
      "[7572/8000] D loss: 0.4773, G loss: 6.7058\n",
      "[7932/8000] D loss: 0.4191, G loss: 11.2241\n",
      "train error: \n",
      " D loss: 0.258365, G loss: 10.177949, D accuracy: 92.8%, cell accuracy: 94.7%, board accuracy: 13.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.525070, G loss: 14.013147, D accuracy: 93.1%, cell accuracy: 94.3%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5506, G loss: 6.5125\n",
      "[372/8000] D loss: 0.2511, G loss: 10.2325\n",
      "[732/8000] D loss: 0.0271, G loss: 11.9945\n",
      "[1092/8000] D loss: 0.0345, G loss: 10.6614\n",
      "[1452/8000] D loss: 0.2672, G loss: 10.4113\n",
      "[1812/8000] D loss: 0.0146, G loss: 11.4021\n",
      "[2172/8000] D loss: 0.2801, G loss: 7.4946\n",
      "[2532/8000] D loss: 0.0227, G loss: 8.0803\n",
      "[2892/8000] D loss: 0.1345, G loss: 12.6117\n",
      "[3252/8000] D loss: 0.4559, G loss: 9.0716\n",
      "[3612/8000] D loss: 0.0922, G loss: 11.2514\n",
      "[3972/8000] D loss: 0.3860, G loss: 10.3141\n",
      "[4332/8000] D loss: 0.4925, G loss: 6.2894\n",
      "[4692/8000] D loss: 0.0406, G loss: 8.9348\n",
      "[5052/8000] D loss: 0.3071, G loss: 8.3484\n",
      "[5412/8000] D loss: 0.3892, G loss: 8.8498\n",
      "[5772/8000] D loss: 0.2475, G loss: 9.1484\n",
      "[6132/8000] D loss: 0.5389, G loss: 6.8809\n",
      "[6492/8000] D loss: 0.2723, G loss: 10.4565\n",
      "[6852/8000] D loss: 0.3059, G loss: 13.3993\n",
      "[7212/8000] D loss: 0.2560, G loss: 11.0598\n",
      "[7572/8000] D loss: 0.0127, G loss: 10.7387\n",
      "[7932/8000] D loss: 0.1118, G loss: 16.3859\n",
      "train error: \n",
      " D loss: 0.254681, G loss: 10.273248, D accuracy: 92.8%, cell accuracy: 94.7%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.547800, G loss: 14.244433, D accuracy: 92.8%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2860, G loss: 11.2978\n",
      "[372/8000] D loss: 0.2483, G loss: 10.7061\n",
      "[732/8000] D loss: 0.2860, G loss: 7.8721\n",
      "[1092/8000] D loss: 0.8739, G loss: 9.6683\n",
      "[1452/8000] D loss: 0.1371, G loss: 11.0209\n",
      "[1812/8000] D loss: 0.3737, G loss: 8.4759\n",
      "[2172/8000] D loss: 0.4805, G loss: 9.5779\n",
      "[2532/8000] D loss: 0.1406, G loss: 12.5128\n",
      "[2892/8000] D loss: 0.4461, G loss: 7.8935\n",
      "[3252/8000] D loss: 0.2377, G loss: 9.9655\n",
      "[3612/8000] D loss: 0.2354, G loss: 10.9143\n",
      "[3972/8000] D loss: 0.1023, G loss: 11.9054\n",
      "[4332/8000] D loss: 0.0185, G loss: 11.1788\n",
      "[4692/8000] D loss: 0.2357, G loss: 11.1523\n",
      "[5052/8000] D loss: 0.4971, G loss: 8.7669\n",
      "[5412/8000] D loss: 0.5896, G loss: 9.0663\n",
      "[5772/8000] D loss: 0.4071, G loss: 6.3575\n",
      "[6132/8000] D loss: 0.2073, G loss: 11.4997\n",
      "[6492/8000] D loss: 0.1384, G loss: 10.7858\n",
      "[6852/8000] D loss: 0.1152, G loss: 10.5131\n",
      "[7212/8000] D loss: 0.2332, G loss: 11.0306\n",
      "[7572/8000] D loss: 0.3283, G loss: 10.9625\n",
      "[7932/8000] D loss: 0.0196, G loss: 11.6115\n",
      "train error: \n",
      " D loss: 0.254557, G loss: 9.846550, D accuracy: 92.8%, cell accuracy: 94.7%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.563231, G loss: 13.571252, D accuracy: 92.6%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1913, G loss: 10.4953\n",
      "[372/8000] D loss: 0.1241, G loss: 12.7796\n",
      "[732/8000] D loss: 0.4661, G loss: 6.2470\n",
      "[1092/8000] D loss: 0.1606, G loss: 7.4944\n",
      "[1452/8000] D loss: 0.1714, G loss: 8.6347\n",
      "[1812/8000] D loss: 0.6018, G loss: 9.0113\n",
      "[2172/8000] D loss: 0.3828, G loss: 11.0412\n",
      "[2532/8000] D loss: 0.1437, G loss: 12.5575\n",
      "[2892/8000] D loss: 0.1414, G loss: 8.0943\n",
      "[3252/8000] D loss: 0.0656, G loss: 12.0031\n",
      "[3612/8000] D loss: 0.3429, G loss: 5.7989\n",
      "[3972/8000] D loss: 0.2297, G loss: 14.1278\n",
      "[4332/8000] D loss: 0.0759, G loss: 11.2316\n",
      "[4692/8000] D loss: 0.0166, G loss: 9.3718\n",
      "[5052/8000] D loss: 0.3377, G loss: 10.2975\n",
      "[5412/8000] D loss: 0.1110, G loss: 13.2465\n",
      "[5772/8000] D loss: 0.1784, G loss: 12.8269\n",
      "[6132/8000] D loss: 0.0434, G loss: 14.0012\n",
      "[6492/8000] D loss: 0.2458, G loss: 13.6363\n",
      "[6852/8000] D loss: 0.4361, G loss: 8.1860\n",
      "[7212/8000] D loss: 0.2958, G loss: 11.0248\n",
      "[7572/8000] D loss: 0.0146, G loss: 8.8119\n",
      "[7932/8000] D loss: 0.3484, G loss: 8.2300\n",
      "train error: \n",
      " D loss: 0.267332, G loss: 10.750104, D accuracy: 92.5%, cell accuracy: 94.7%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.661251, G loss: 14.255707, D accuracy: 90.5%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2472, G loss: 13.2824\n",
      "[372/8000] D loss: 0.0094, G loss: 14.0356\n",
      "[732/8000] D loss: 0.1271, G loss: 9.0393\n",
      "[1092/8000] D loss: 0.3862, G loss: 8.6757\n",
      "[1452/8000] D loss: 0.7900, G loss: 10.7881\n",
      "[1812/8000] D loss: 0.2624, G loss: 9.2982\n",
      "[2172/8000] D loss: 0.3779, G loss: 9.4797\n",
      "[2532/8000] D loss: 0.3868, G loss: 8.7681\n",
      "[2892/8000] D loss: 0.2720, G loss: 15.3634\n",
      "[3252/8000] D loss: 0.1287, G loss: 12.3234\n",
      "[3612/8000] D loss: 0.2988, G loss: 8.4135\n",
      "[3972/8000] D loss: 0.2554, G loss: 7.8780\n",
      "[4332/8000] D loss: 0.6311, G loss: 8.1945\n",
      "[4692/8000] D loss: 0.0517, G loss: 11.0272\n",
      "[5052/8000] D loss: 0.6529, G loss: 6.1198\n",
      "[5412/8000] D loss: 0.1404, G loss: 12.0268\n",
      "[5772/8000] D loss: 0.2864, G loss: 9.4563\n",
      "[6132/8000] D loss: 0.2500, G loss: 10.5921\n",
      "[6492/8000] D loss: 0.2286, G loss: 8.3096\n",
      "[6852/8000] D loss: 0.2656, G loss: 8.0787\n",
      "[7212/8000] D loss: 0.3456, G loss: 10.9000\n",
      "[7572/8000] D loss: 0.1699, G loss: 17.3831\n",
      "[7932/8000] D loss: 0.1413, G loss: 12.3664\n",
      "train error: \n",
      " D loss: 0.245715, G loss: 10.241716, D accuracy: 93.1%, cell accuracy: 94.7%, board accuracy: 12.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.557420, G loss: 13.854959, D accuracy: 92.9%, cell accuracy: 94.3%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1657, G loss: 11.0750\n",
      "[372/8000] D loss: 0.0089, G loss: 13.0172\n",
      "[732/8000] D loss: 0.1878, G loss: 10.5766\n",
      "[1092/8000] D loss: 0.5436, G loss: 6.2296\n",
      "[1452/8000] D loss: 0.2622, G loss: 11.6229\n",
      "[1812/8000] D loss: 0.1094, G loss: 10.2954\n",
      "[2172/8000] D loss: 0.5395, G loss: 11.6853\n",
      "[2532/8000] D loss: 0.2307, G loss: 13.6635\n",
      "[2892/8000] D loss: 0.3283, G loss: 6.1698\n",
      "[3252/8000] D loss: 0.2698, G loss: 8.2843\n",
      "[3612/8000] D loss: 0.1947, G loss: 7.8444\n",
      "[3972/8000] D loss: 0.1971, G loss: 8.7456\n",
      "[4332/8000] D loss: 0.3386, G loss: 9.6047\n",
      "[4692/8000] D loss: 0.1917, G loss: 13.1493\n",
      "[5052/8000] D loss: 0.0205, G loss: 10.7483\n",
      "[5412/8000] D loss: 0.3812, G loss: 9.9856\n",
      "[5772/8000] D loss: 0.1622, G loss: 10.6745\n",
      "[6132/8000] D loss: 0.0064, G loss: 14.0883\n",
      "[6492/8000] D loss: 0.3525, G loss: 12.8365\n",
      "[6852/8000] D loss: 0.1815, G loss: 9.1403\n",
      "[7212/8000] D loss: 0.4028, G loss: 8.4178\n",
      "[7572/8000] D loss: 0.1399, G loss: 13.2979\n",
      "[7932/8000] D loss: 0.1287, G loss: 10.8466\n",
      "train error: \n",
      " D loss: 0.240535, G loss: 10.686292, D accuracy: 93.1%, cell accuracy: 94.8%, board accuracy: 13.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.564913, G loss: 14.594641, D accuracy: 92.6%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3711, G loss: 9.5146\n",
      "[372/8000] D loss: 0.2595, G loss: 8.9029\n",
      "[732/8000] D loss: 0.3888, G loss: 11.1576\n",
      "[1092/8000] D loss: 0.1346, G loss: 12.5251\n",
      "[1452/8000] D loss: 0.4897, G loss: 6.8521\n",
      "[1812/8000] D loss: 0.0444, G loss: 12.8824\n",
      "[2172/8000] D loss: 0.1540, G loss: 9.8902\n",
      "[2532/8000] D loss: 0.5012, G loss: 8.0766\n",
      "[2892/8000] D loss: 0.2588, G loss: 10.8355\n",
      "[3252/8000] D loss: 0.2128, G loss: 10.1284\n",
      "[3612/8000] D loss: 0.0507, G loss: 7.9596\n",
      "[3972/8000] D loss: 0.1902, G loss: 12.5267\n",
      "[4332/8000] D loss: 0.3794, G loss: 7.4425\n",
      "[4692/8000] D loss: 0.0449, G loss: 10.7392\n",
      "[5052/8000] D loss: 0.5623, G loss: 7.1289\n",
      "[5412/8000] D loss: 0.2290, G loss: 11.0097\n",
      "[5772/8000] D loss: 0.5152, G loss: 8.2649\n",
      "[6132/8000] D loss: 0.3055, G loss: 8.6054\n",
      "[6492/8000] D loss: 0.1208, G loss: 10.9697\n",
      "[6852/8000] D loss: 0.1344, G loss: 12.8956\n",
      "[7212/8000] D loss: 0.3042, G loss: 10.7056\n",
      "[7572/8000] D loss: 0.3049, G loss: 10.3004\n",
      "[7932/8000] D loss: 0.5841, G loss: 9.8766\n",
      "train error: \n",
      " D loss: 0.253844, G loss: 9.981010, D accuracy: 92.7%, cell accuracy: 94.7%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.564159, G loss: 13.683865, D accuracy: 92.7%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0340, G loss: 9.9633\n",
      "[372/8000] D loss: 0.2624, G loss: 10.8177\n",
      "[732/8000] D loss: 0.1225, G loss: 12.7025\n",
      "[1092/8000] D loss: 0.1177, G loss: 14.8114\n",
      "[1452/8000] D loss: 0.3105, G loss: 10.4357\n",
      "[1812/8000] D loss: 0.2192, G loss: 14.1811\n",
      "[2172/8000] D loss: 0.0214, G loss: 14.0233\n",
      "[2532/8000] D loss: 0.1464, G loss: 11.2792\n",
      "[2892/8000] D loss: 0.2375, G loss: 12.3741\n",
      "[3252/8000] D loss: 0.3643, G loss: 11.8541\n",
      "[3612/8000] D loss: 0.2091, G loss: 10.4167\n",
      "[3972/8000] D loss: 0.2866, G loss: 6.6019\n",
      "[4332/8000] D loss: 0.4271, G loss: 10.9606\n",
      "[4692/8000] D loss: 0.3908, G loss: 8.4075\n",
      "[5052/8000] D loss: 0.1238, G loss: 11.2050\n",
      "[5412/8000] D loss: 0.2745, G loss: 10.7769\n",
      "[5772/8000] D loss: 0.1798, G loss: 11.8429\n",
      "[6132/8000] D loss: 0.1939, G loss: 8.2202\n",
      "[6492/8000] D loss: 0.2625, G loss: 12.8799\n",
      "[6852/8000] D loss: 0.2590, G loss: 9.3625\n",
      "[7212/8000] D loss: 0.3102, G loss: 9.7886\n",
      "[7572/8000] D loss: 0.0644, G loss: 10.9830\n",
      "[7932/8000] D loss: 0.4518, G loss: 8.2425\n",
      "train error: \n",
      " D loss: 0.248367, G loss: 10.254791, D accuracy: 92.7%, cell accuracy: 94.8%, board accuracy: 13.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.576660, G loss: 14.082524, D accuracy: 92.3%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1298, G loss: 11.4378\n",
      "[372/8000] D loss: 0.0158, G loss: 13.4651\n",
      "[732/8000] D loss: 0.1427, G loss: 10.9360\n",
      "[1092/8000] D loss: 0.3179, G loss: 10.2700\n",
      "[1452/8000] D loss: 0.0109, G loss: 10.0684\n",
      "[1812/8000] D loss: 0.2204, G loss: 8.0138\n",
      "[2172/8000] D loss: 0.3412, G loss: 12.2085\n",
      "[2532/8000] D loss: 0.0141, G loss: 13.7544\n",
      "[2892/8000] D loss: 0.1190, G loss: 13.8858\n",
      "[3252/8000] D loss: 0.2442, G loss: 11.1309\n",
      "[3612/8000] D loss: 0.2553, G loss: 8.0282\n",
      "[3972/8000] D loss: 0.1216, G loss: 13.6033\n",
      "[4332/8000] D loss: 0.2345, G loss: 11.6650\n",
      "[4692/8000] D loss: 0.4118, G loss: 9.6716\n",
      "[5052/8000] D loss: 0.2107, G loss: 10.0781\n",
      "[5412/8000] D loss: 0.0603, G loss: 12.2706\n",
      "[5772/8000] D loss: 0.5716, G loss: 11.2684\n",
      "[6132/8000] D loss: 0.0159, G loss: 15.4380\n",
      "[6492/8000] D loss: 0.0033, G loss: 12.6311\n",
      "[6852/8000] D loss: 0.4050, G loss: 11.4084\n",
      "[7212/8000] D loss: 0.2354, G loss: 9.3331\n",
      "[7572/8000] D loss: 0.4555, G loss: 10.3474\n",
      "[7932/8000] D loss: 0.2711, G loss: 9.5388\n",
      "train error: \n",
      " D loss: 0.274790, G loss: 8.863167, D accuracy: 92.3%, cell accuracy: 94.7%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.484006, G loss: 12.490116, D accuracy: 93.1%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3094, G loss: 7.9563\n",
      "[372/8000] D loss: 0.2445, G loss: 8.2348\n",
      "[732/8000] D loss: 0.0195, G loss: 13.0193\n",
      "[1092/8000] D loss: 0.1066, G loss: 10.6531\n",
      "[1452/8000] D loss: 0.1776, G loss: 11.7508\n",
      "[1812/8000] D loss: 0.3519, G loss: 10.2947\n",
      "[2172/8000] D loss: 0.2484, G loss: 12.6177\n",
      "[2532/8000] D loss: 0.4858, G loss: 10.7671\n",
      "[2892/8000] D loss: 0.0076, G loss: 11.7967\n",
      "[3252/8000] D loss: 0.1107, G loss: 11.4898\n",
      "[3612/8000] D loss: 0.5137, G loss: 8.5277\n",
      "[3972/8000] D loss: 0.0984, G loss: 9.0427\n",
      "[4332/8000] D loss: 0.1351, G loss: 11.0263\n",
      "[4692/8000] D loss: 0.0093, G loss: 12.0263\n",
      "[5052/8000] D loss: 0.2730, G loss: 10.9252\n",
      "[5412/8000] D loss: 0.4564, G loss: 8.3962\n",
      "[5772/8000] D loss: 0.1065, G loss: 17.2775\n",
      "[6132/8000] D loss: 0.0986, G loss: 13.5330\n",
      "[6492/8000] D loss: 0.3471, G loss: 8.5878\n",
      "[6852/8000] D loss: 0.2532, G loss: 10.1159\n",
      "[7212/8000] D loss: 0.5195, G loss: 12.7459\n",
      "[7572/8000] D loss: 0.4341, G loss: 6.3622\n",
      "[7932/8000] D loss: 0.4713, G loss: 9.0544\n",
      "train error: \n",
      " D loss: 0.248138, G loss: 11.281490, D accuracy: 92.7%, cell accuracy: 94.7%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.615529, G loss: 15.382274, D accuracy: 91.8%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1188, G loss: 12.5737\n",
      "[372/8000] D loss: 0.2600, G loss: 10.9695\n",
      "[732/8000] D loss: 0.4058, G loss: 11.8251\n",
      "[1092/8000] D loss: 0.1449, G loss: 12.2418\n",
      "[1452/8000] D loss: 0.2506, G loss: 10.0892\n",
      "[1812/8000] D loss: 0.4103, G loss: 9.4638\n",
      "[2172/8000] D loss: 0.6381, G loss: 5.9859\n",
      "[2532/8000] D loss: 0.2511, G loss: 10.8788\n",
      "[2892/8000] D loss: 0.1821, G loss: 12.7849\n",
      "[3252/8000] D loss: 0.2662, G loss: 10.0507\n",
      "[3612/8000] D loss: 0.1256, G loss: 12.5820\n",
      "[3972/8000] D loss: 0.3516, G loss: 8.8759\n",
      "[4332/8000] D loss: 0.2326, G loss: 11.8161\n",
      "[4692/8000] D loss: 0.3695, G loss: 11.4781\n",
      "[5052/8000] D loss: 0.0540, G loss: 12.1761\n",
      "[5412/8000] D loss: 0.1286, G loss: 15.3211\n",
      "[5772/8000] D loss: 0.1609, G loss: 7.1013\n",
      "[6132/8000] D loss: 0.2631, G loss: 7.9594\n",
      "[6492/8000] D loss: 0.3325, G loss: 7.9567\n",
      "[6852/8000] D loss: 0.1635, G loss: 9.4217\n",
      "[7212/8000] D loss: 0.4871, G loss: 8.3253\n",
      "[7572/8000] D loss: 0.0193, G loss: 14.3860\n",
      "[7932/8000] D loss: 0.4019, G loss: 11.7316\n",
      "train error: \n",
      " D loss: 0.265892, G loss: 9.282058, D accuracy: 92.5%, cell accuracy: 94.7%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.519102, G loss: 12.973539, D accuracy: 92.8%, cell accuracy: 94.3%, board accuracy: 6.1% \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2596, G loss: 8.3283\n",
      "[372/8000] D loss: 0.5019, G loss: 6.0859\n",
      "[732/8000] D loss: 0.3585, G loss: 8.7603\n",
      "[1092/8000] D loss: 0.1169, G loss: 13.2868\n",
      "[1452/8000] D loss: 0.2306, G loss: 13.3751\n",
      "[1812/8000] D loss: 0.0016, G loss: 14.9297\n",
      "[2172/8000] D loss: 0.0645, G loss: 11.9480\n",
      "[2532/8000] D loss: 0.3446, G loss: 6.3140\n",
      "[2892/8000] D loss: 0.1014, G loss: 10.6486\n",
      "[3252/8000] D loss: 0.3882, G loss: 10.0151\n",
      "[3612/8000] D loss: 0.2920, G loss: 8.7193\n",
      "[3972/8000] D loss: 0.4583, G loss: 10.6578\n",
      "[4332/8000] D loss: 0.1324, G loss: 9.0229\n",
      "[4692/8000] D loss: 0.1226, G loss: 10.6061\n",
      "[5052/8000] D loss: 0.2739, G loss: 10.2097\n",
      "[5412/8000] D loss: 0.3035, G loss: 9.0959\n",
      "[5772/8000] D loss: 0.2426, G loss: 9.5872\n",
      "[6132/8000] D loss: 0.2333, G loss: 10.8068\n",
      "[6492/8000] D loss: 0.1553, G loss: 10.1452\n",
      "[6852/8000] D loss: 0.4480, G loss: 10.8654\n",
      "[7212/8000] D loss: 0.1668, G loss: 10.9254\n",
      "[7572/8000] D loss: 0.4632, G loss: 6.9102\n",
      "[7932/8000] D loss: 0.2590, G loss: 7.1872\n",
      "train error: \n",
      " D loss: 0.250007, G loss: 9.285198, D accuracy: 92.8%, cell accuracy: 94.7%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.521545, G loss: 12.678247, D accuracy: 92.3%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1600, G loss: 7.9627\n",
      "[372/8000] D loss: 0.1370, G loss: 8.2963\n",
      "[732/8000] D loss: 0.1486, G loss: 11.7201\n",
      "[1092/8000] D loss: 0.0084, G loss: 13.6500\n",
      "[1452/8000] D loss: 0.0597, G loss: 12.3504\n",
      "[1812/8000] D loss: 0.3194, G loss: 10.6406\n",
      "[2172/8000] D loss: 0.4224, G loss: 11.5386\n",
      "[2532/8000] D loss: 0.2811, G loss: 9.5845\n",
      "[2892/8000] D loss: 0.2001, G loss: 6.0395\n",
      "[3252/8000] D loss: 0.1348, G loss: 10.2762\n",
      "[3612/8000] D loss: 0.2545, G loss: 12.4127\n",
      "[3972/8000] D loss: 0.1193, G loss: 14.7562\n",
      "[4332/8000] D loss: 0.5079, G loss: 7.4900\n",
      "[4692/8000] D loss: 0.0342, G loss: 14.6335\n",
      "[5052/8000] D loss: 0.6129, G loss: 5.5353\n",
      "[5412/8000] D loss: 0.1917, G loss: 9.6247\n",
      "[5772/8000] D loss: 0.1445, G loss: 12.5755\n",
      "[6132/8000] D loss: 0.0076, G loss: 17.0232\n",
      "[6492/8000] D loss: 0.2980, G loss: 8.4925\n",
      "[6852/8000] D loss: 0.1339, G loss: 9.4771\n",
      "[7212/8000] D loss: 0.2054, G loss: 7.8262\n",
      "[7572/8000] D loss: 0.0065, G loss: 15.6628\n",
      "[7932/8000] D loss: 0.2475, G loss: 9.9394\n",
      "train error: \n",
      " D loss: 0.253932, G loss: 10.352219, D accuracy: 92.5%, cell accuracy: 94.7%, board accuracy: 13.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.584586, G loss: 14.216576, D accuracy: 91.9%, cell accuracy: 94.2%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2716, G loss: 8.0891\n",
      "[372/8000] D loss: 0.2718, G loss: 10.6064\n",
      "[732/8000] D loss: 0.4799, G loss: 7.4462\n",
      "[1092/8000] D loss: 0.3267, G loss: 9.2724\n",
      "[1452/8000] D loss: 0.2772, G loss: 8.6082\n",
      "[1812/8000] D loss: 0.2615, G loss: 7.5974\n",
      "[2172/8000] D loss: 0.2268, G loss: 10.6095\n",
      "[2532/8000] D loss: 0.6164, G loss: 8.9706\n",
      "[2892/8000] D loss: 0.1647, G loss: 9.5416\n",
      "[3252/8000] D loss: 0.1365, G loss: 9.2538\n",
      "[3612/8000] D loss: 0.2493, G loss: 9.0120\n",
      "[3972/8000] D loss: 0.3627, G loss: 8.0584\n",
      "[4332/8000] D loss: 0.2813, G loss: 11.6505\n",
      "[4692/8000] D loss: 0.0026, G loss: 10.9751\n",
      "[5052/8000] D loss: 0.3810, G loss: 8.2873\n",
      "[5412/8000] D loss: 0.1139, G loss: 12.1576\n",
      "[5772/8000] D loss: 0.3002, G loss: 8.9022\n",
      "[6132/8000] D loss: 0.2801, G loss: 14.1226\n",
      "[6492/8000] D loss: 0.2566, G loss: 9.7324\n",
      "[6852/8000] D loss: 0.2705, G loss: 10.9337\n",
      "[7212/8000] D loss: 0.2787, G loss: 6.5301\n",
      "[7572/8000] D loss: 0.2751, G loss: 7.3275\n",
      "[7932/8000] D loss: 0.1938, G loss: 8.2493\n",
      "train error: \n",
      " D loss: 0.265873, G loss: 9.000861, D accuracy: 92.5%, cell accuracy: 94.7%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.510418, G loss: 12.393930, D accuracy: 91.9%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4267, G loss: 9.9801\n",
      "[372/8000] D loss: 0.3043, G loss: 10.0070\n",
      "[732/8000] D loss: 0.1347, G loss: 10.3585\n",
      "[1092/8000] D loss: 0.2390, G loss: 9.8495\n",
      "[1452/8000] D loss: 0.1811, G loss: 10.3538\n",
      "[1812/8000] D loss: 0.2990, G loss: 10.1702\n",
      "[2172/8000] D loss: 0.2627, G loss: 9.7906\n",
      "[2532/8000] D loss: 0.3264, G loss: 7.5118\n",
      "[2892/8000] D loss: 0.5657, G loss: 9.3778\n",
      "[3252/8000] D loss: 0.0121, G loss: 12.4538\n",
      "[3612/8000] D loss: 0.3734, G loss: 10.3632\n",
      "[3972/8000] D loss: 0.0949, G loss: 11.1223\n",
      "[4332/8000] D loss: 0.1644, G loss: 8.6137\n",
      "[4692/8000] D loss: 0.1467, G loss: 9.9675\n",
      "[5052/8000] D loss: 0.3741, G loss: 7.4265\n",
      "[5412/8000] D loss: 0.1269, G loss: 9.2203\n",
      "[5772/8000] D loss: 0.2619, G loss: 7.9943\n",
      "[6132/8000] D loss: 0.1666, G loss: 11.8668\n",
      "[6492/8000] D loss: 0.2259, G loss: 10.0750\n",
      "[6852/8000] D loss: 0.4326, G loss: 6.3008\n",
      "[7212/8000] D loss: 0.0131, G loss: 10.0922\n",
      "[7572/8000] D loss: 1.0974, G loss: 9.8581\n",
      "[7932/8000] D loss: 0.2209, G loss: 10.8188\n",
      "train error: \n",
      " D loss: 0.278618, G loss: 8.668193, D accuracy: 92.2%, cell accuracy: 94.7%, board accuracy: 13.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.510332, G loss: 12.151592, D accuracy: 92.4%, cell accuracy: 94.3%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3518, G loss: 8.4987\n",
      "[372/8000] D loss: 0.0198, G loss: 10.0224\n",
      "[732/8000] D loss: 0.4156, G loss: 7.4462\n",
      "[1092/8000] D loss: 0.2514, G loss: 13.4539\n",
      "[1452/8000] D loss: 0.0534, G loss: 14.3147\n",
      "[1812/8000] D loss: 0.1950, G loss: 7.4277\n",
      "[2172/8000] D loss: 0.0869, G loss: 11.6296\n",
      "[2532/8000] D loss: 0.1178, G loss: 9.9670\n",
      "[2892/8000] D loss: 0.1254, G loss: 12.6178\n",
      "[3252/8000] D loss: 0.0058, G loss: 12.5485\n",
      "[3612/8000] D loss: 0.2670, G loss: 8.4184\n",
      "[3972/8000] D loss: 0.2154, G loss: 10.9058\n",
      "[4332/8000] D loss: 0.0167, G loss: 10.5878\n",
      "[4692/8000] D loss: 0.1227, G loss: 12.4197\n",
      "[5052/8000] D loss: 0.0360, G loss: 15.1191\n",
      "[5412/8000] D loss: 0.2200, G loss: 13.1283\n",
      "[5772/8000] D loss: 0.4526, G loss: 10.5826\n",
      "[6132/8000] D loss: 0.2167, G loss: 10.6958\n",
      "[6492/8000] D loss: 0.3483, G loss: 10.5021\n",
      "[6852/8000] D loss: 0.3406, G loss: 6.9299\n",
      "[7212/8000] D loss: 0.1279, G loss: 12.2526\n",
      "[7572/8000] D loss: 0.7347, G loss: 8.7440\n",
      "[7932/8000] D loss: 0.1319, G loss: 10.0348\n",
      "train error: \n",
      " D loss: 0.277389, G loss: 11.679469, D accuracy: 92.1%, cell accuracy: 94.7%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.689238, G loss: 15.589346, D accuracy: 90.7%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3713, G loss: 11.7810\n",
      "[372/8000] D loss: 0.4117, G loss: 7.9026\n",
      "[732/8000] D loss: 0.1932, G loss: 9.7446\n",
      "[1092/8000] D loss: 0.1311, G loss: 12.6745\n",
      "[1452/8000] D loss: 0.1832, G loss: 10.0569\n",
      "[1812/8000] D loss: 0.8619, G loss: 5.8393\n",
      "[2172/8000] D loss: 0.2008, G loss: 13.1985\n",
      "[2532/8000] D loss: 0.2147, G loss: 9.7635\n",
      "[2892/8000] D loss: 0.2335, G loss: 11.3872\n",
      "[3252/8000] D loss: 0.0564, G loss: 12.0886\n",
      "[3612/8000] D loss: 0.3212, G loss: 10.4360\n",
      "[3972/8000] D loss: 0.5475, G loss: 10.2996\n",
      "[4332/8000] D loss: 0.1174, G loss: 10.6132\n",
      "[4692/8000] D loss: 0.0046, G loss: 9.9188\n",
      "[5052/8000] D loss: 0.5123, G loss: 11.3424\n",
      "[5412/8000] D loss: 0.2734, G loss: 10.5372\n",
      "[5772/8000] D loss: 0.3440, G loss: 11.8683\n",
      "[6132/8000] D loss: 0.0571, G loss: 11.5929\n",
      "[6492/8000] D loss: 0.1998, G loss: 8.9057\n",
      "[6852/8000] D loss: 0.1834, G loss: 8.3981\n",
      "[7212/8000] D loss: 0.2445, G loss: 11.8818\n",
      "[7572/8000] D loss: 0.2358, G loss: 7.4341\n",
      "[7932/8000] D loss: 0.3538, G loss: 9.2501\n",
      "train error: \n",
      " D loss: 0.254965, G loss: 10.144367, D accuracy: 92.5%, cell accuracy: 94.7%, board accuracy: 13.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.576149, G loss: 13.875189, D accuracy: 92.2%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6023, G loss: 4.9694\n",
      "[372/8000] D loss: 0.6925, G loss: 6.5618\n",
      "[732/8000] D loss: 0.2113, G loss: 9.6890\n",
      "[1092/8000] D loss: 0.1175, G loss: 14.8683\n",
      "[1452/8000] D loss: 0.2995, G loss: 13.7715\n",
      "[1812/8000] D loss: 0.1917, G loss: 10.5444\n",
      "[2172/8000] D loss: 0.2910, G loss: 8.6310\n",
      "[2532/8000] D loss: 0.0070, G loss: 14.5951\n",
      "[2892/8000] D loss: 0.1217, G loss: 13.7081\n",
      "[3252/8000] D loss: 0.2523, G loss: 14.6325\n",
      "[3612/8000] D loss: 0.3587, G loss: 6.7979\n",
      "[3972/8000] D loss: 0.4703, G loss: 8.4420\n",
      "[4332/8000] D loss: 0.5164, G loss: 9.3595\n",
      "[4692/8000] D loss: 0.6827, G loss: 4.7452\n",
      "[5052/8000] D loss: 0.1494, G loss: 8.4491\n",
      "[5412/8000] D loss: 0.5758, G loss: 10.0696\n",
      "[5772/8000] D loss: 0.2843, G loss: 8.1272\n",
      "[6132/8000] D loss: 0.5249, G loss: 7.0252\n",
      "[6492/8000] D loss: 0.3051, G loss: 11.6850\n",
      "[6852/8000] D loss: 0.3470, G loss: 8.4075\n",
      "[7212/8000] D loss: 0.6146, G loss: 5.5835\n",
      "[7572/8000] D loss: 0.3622, G loss: 9.6584\n",
      "[7932/8000] D loss: 0.1131, G loss: 9.6573\n",
      "train error: \n",
      " D loss: 0.270980, G loss: 9.321218, D accuracy: 92.3%, cell accuracy: 94.7%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.544545, G loss: 13.087401, D accuracy: 92.4%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2181, G loss: 10.2319\n",
      "[372/8000] D loss: 0.2509, G loss: 8.8044\n",
      "[732/8000] D loss: 0.2213, G loss: 7.3652\n",
      "[1092/8000] D loss: 0.3422, G loss: 11.1491\n",
      "[1452/8000] D loss: 0.0140, G loss: 10.5733\n",
      "[1812/8000] D loss: 0.0197, G loss: 12.8026\n",
      "[2172/8000] D loss: 0.1439, G loss: 9.3826\n",
      "[2532/8000] D loss: 0.1105, G loss: 10.9147\n",
      "[2892/8000] D loss: 0.2851, G loss: 8.0798\n",
      "[3252/8000] D loss: 0.0368, G loss: 13.2090\n",
      "[3612/8000] D loss: 0.3847, G loss: 14.2100\n",
      "[3972/8000] D loss: 0.2570, G loss: 11.2172\n",
      "[4332/8000] D loss: 0.1529, G loss: 10.6773\n",
      "[4692/8000] D loss: 0.5366, G loss: 8.7966\n",
      "[5052/8000] D loss: 0.2313, G loss: 11.4880\n",
      "[5412/8000] D loss: 0.2319, G loss: 12.0850\n",
      "[5772/8000] D loss: 0.2381, G loss: 10.7046\n",
      "[6132/8000] D loss: 0.3444, G loss: 10.6148\n",
      "[6492/8000] D loss: 0.5174, G loss: 10.0249\n",
      "[6852/8000] D loss: 0.0207, G loss: 14.1688\n",
      "[7212/8000] D loss: 0.3511, G loss: 10.4538\n",
      "[7572/8000] D loss: 0.1760, G loss: 11.4567\n",
      "[7932/8000] D loss: 0.1368, G loss: 10.0242\n",
      "train error: \n",
      " D loss: 0.283602, G loss: 7.970588, D accuracy: 92.0%, cell accuracy: 94.7%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.475377, G loss: 11.441619, D accuracy: 92.7%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2203, G loss: 6.5522\n",
      "[372/8000] D loss: 0.2661, G loss: 10.0417\n",
      "[732/8000] D loss: 0.1183, G loss: 12.7689\n",
      "[1092/8000] D loss: 0.0260, G loss: 9.7539\n",
      "[1452/8000] D loss: 0.1944, G loss: 8.6098\n",
      "[1812/8000] D loss: 0.4131, G loss: 7.2459\n",
      "[2172/8000] D loss: 0.2162, G loss: 10.9401\n",
      "[2532/8000] D loss: 0.5012, G loss: 9.8059\n",
      "[2892/8000] D loss: 0.2750, G loss: 8.2273\n",
      "[3252/8000] D loss: 0.3933, G loss: 10.0430\n",
      "[3612/8000] D loss: 0.1539, G loss: 11.6887\n",
      "[3972/8000] D loss: 0.1959, G loss: 9.9794\n",
      "[4332/8000] D loss: 0.4782, G loss: 12.0106\n",
      "[4692/8000] D loss: 0.7179, G loss: 9.0357\n",
      "[5052/8000] D loss: 0.1247, G loss: 12.0654\n",
      "[5412/8000] D loss: 0.0644, G loss: 13.5963\n",
      "[5772/8000] D loss: 0.3909, G loss: 11.8136\n",
      "[6132/8000] D loss: 0.3848, G loss: 8.5708\n",
      "[6492/8000] D loss: 0.3532, G loss: 8.2906\n",
      "[6852/8000] D loss: 0.8837, G loss: 5.7399\n",
      "[7212/8000] D loss: 0.1223, G loss: 8.8477\n",
      "[7572/8000] D loss: 0.0392, G loss: 12.6361\n",
      "[7932/8000] D loss: 0.2152, G loss: 9.9765\n",
      "train error: \n",
      " D loss: 0.274529, G loss: 9.026125, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 13.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.501191, G loss: 12.460848, D accuracy: 92.8%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3682, G loss: 9.5685\n",
      "[372/8000] D loss: 0.2116, G loss: 9.6986\n",
      "[732/8000] D loss: 0.3619, G loss: 9.5288\n",
      "[1092/8000] D loss: 0.2513, G loss: 9.5125\n",
      "[1452/8000] D loss: 0.0172, G loss: 10.1622\n",
      "[1812/8000] D loss: 0.1363, G loss: 10.3183\n",
      "[2172/8000] D loss: 0.2497, G loss: 11.3072\n",
      "[2532/8000] D loss: 0.3319, G loss: 10.3169\n",
      "[2892/8000] D loss: 0.4130, G loss: 10.8256\n",
      "[3252/8000] D loss: 0.1805, G loss: 11.5974\n",
      "[3612/8000] D loss: 0.2899, G loss: 5.7185\n",
      "[3972/8000] D loss: 0.2434, G loss: 13.0366\n",
      "[4332/8000] D loss: 0.1802, G loss: 10.0905\n",
      "[4692/8000] D loss: 0.1326, G loss: 9.1401\n",
      "[5052/8000] D loss: 0.4986, G loss: 9.3038\n",
      "[5412/8000] D loss: 0.0758, G loss: 14.2505\n",
      "[5772/8000] D loss: 0.3886, G loss: 14.5047\n",
      "[6132/8000] D loss: 0.1176, G loss: 8.2269\n",
      "[6492/8000] D loss: 0.3045, G loss: 10.5480\n",
      "[6852/8000] D loss: 0.2444, G loss: 10.1034\n",
      "[7212/8000] D loss: 0.0661, G loss: 8.7661\n",
      "[7572/8000] D loss: 0.1196, G loss: 11.1109\n",
      "[7932/8000] D loss: 0.0075, G loss: 11.7994\n",
      "train error: \n",
      " D loss: 0.256637, G loss: 9.811038, D accuracy: 92.4%, cell accuracy: 94.7%, board accuracy: 13.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.591062, G loss: 13.546685, D accuracy: 91.5%, cell accuracy: 94.2%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5877, G loss: 6.5222\n",
      "[372/8000] D loss: 0.0196, G loss: 12.7809\n",
      "[732/8000] D loss: 0.4960, G loss: 6.3478\n",
      "[1092/8000] D loss: 0.0533, G loss: 10.9175\n",
      "[1452/8000] D loss: 0.3110, G loss: 7.1748\n",
      "[1812/8000] D loss: 0.6361, G loss: 7.6896\n",
      "[2172/8000] D loss: 0.4074, G loss: 9.1501\n",
      "[2532/8000] D loss: 0.3629, G loss: 7.5298\n",
      "[2892/8000] D loss: 0.1217, G loss: 10.4047\n",
      "[3252/8000] D loss: 0.5306, G loss: 10.8873\n",
      "[3612/8000] D loss: 0.0230, G loss: 11.1481\n",
      "[3972/8000] D loss: 0.3798, G loss: 7.7701\n",
      "[4332/8000] D loss: 0.3314, G loss: 10.3173\n",
      "[4692/8000] D loss: 0.3283, G loss: 8.2735\n",
      "[5052/8000] D loss: 0.5538, G loss: 9.5921\n",
      "[5412/8000] D loss: 0.2014, G loss: 14.0662\n",
      "[5772/8000] D loss: 0.3683, G loss: 9.0078\n",
      "[6132/8000] D loss: 0.3678, G loss: 8.8891\n",
      "[6492/8000] D loss: 0.0415, G loss: 12.0285\n",
      "[6852/8000] D loss: 0.0455, G loss: 9.3382\n",
      "[7212/8000] D loss: 0.2972, G loss: 9.9966\n",
      "[7572/8000] D loss: 0.0567, G loss: 8.2438\n",
      "[7932/8000] D loss: 0.1552, G loss: 12.6499\n",
      "train error: \n",
      " D loss: 0.274054, G loss: 11.354498, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.679006, G loss: 15.266205, D accuracy: 90.8%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4407, G loss: 9.4599\n",
      "[372/8000] D loss: 0.1368, G loss: 9.1633\n",
      "[732/8000] D loss: 0.6831, G loss: 6.8794\n",
      "[1092/8000] D loss: 0.4111, G loss: 7.6642\n",
      "[1452/8000] D loss: 0.1364, G loss: 14.5930\n",
      "[1812/8000] D loss: 0.2582, G loss: 8.8492\n",
      "[2172/8000] D loss: 0.4720, G loss: 7.4174\n",
      "[2532/8000] D loss: 0.3767, G loss: 7.6576\n",
      "[2892/8000] D loss: 0.2487, G loss: 7.6537\n",
      "[3252/8000] D loss: 0.4826, G loss: 8.7210\n",
      "[3612/8000] D loss: 0.5008, G loss: 10.5392\n",
      "[3972/8000] D loss: 0.0269, G loss: 10.3624\n",
      "[4332/8000] D loss: 0.2818, G loss: 8.6469\n",
      "[4692/8000] D loss: 0.0030, G loss: 12.6014\n",
      "[5052/8000] D loss: 0.1162, G loss: 11.5953\n",
      "[5412/8000] D loss: 0.1395, G loss: 11.5668\n",
      "[5772/8000] D loss: 0.5213, G loss: 9.7196\n",
      "[6132/8000] D loss: 0.1959, G loss: 10.5600\n",
      "[6492/8000] D loss: 0.6126, G loss: 5.7835\n",
      "[6852/8000] D loss: 0.2711, G loss: 9.3872\n",
      "[7212/8000] D loss: 0.0094, G loss: 12.6066\n",
      "[7572/8000] D loss: 0.3616, G loss: 13.0483\n",
      "[7932/8000] D loss: 0.2643, G loss: 13.1093\n",
      "train error: \n",
      " D loss: 0.287697, G loss: 9.112418, D accuracy: 92.1%, cell accuracy: 94.7%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.486165, G loss: 12.867532, D accuracy: 92.8%, cell accuracy: 94.3%, board accuracy: 6.1% \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0558, G loss: 10.2924\n",
      "[372/8000] D loss: 0.0959, G loss: 11.8274\n",
      "[732/8000] D loss: 0.3880, G loss: 10.1038\n",
      "[1092/8000] D loss: 0.3248, G loss: 9.8462\n",
      "[1452/8000] D loss: 0.0823, G loss: 11.5821\n",
      "[1812/8000] D loss: 0.1310, G loss: 8.6089\n",
      "[2172/8000] D loss: 0.2767, G loss: 7.4261\n",
      "[2532/8000] D loss: 0.2173, G loss: 12.5637\n",
      "[2892/8000] D loss: 0.4763, G loss: 9.1084\n",
      "[3252/8000] D loss: 0.3004, G loss: 9.4196\n",
      "[3612/8000] D loss: 0.0623, G loss: 11.5368\n",
      "[3972/8000] D loss: 0.1356, G loss: 10.8988\n",
      "[4332/8000] D loss: 0.3165, G loss: 8.0054\n",
      "[4692/8000] D loss: 0.5458, G loss: 7.4800\n",
      "[5052/8000] D loss: 0.1791, G loss: 9.7669\n",
      "[5412/8000] D loss: 0.2663, G loss: 9.6366\n",
      "[5772/8000] D loss: 0.0299, G loss: 13.4472\n",
      "[6132/8000] D loss: 0.0282, G loss: 13.2213\n",
      "[6492/8000] D loss: 0.2161, G loss: 9.1021\n",
      "[6852/8000] D loss: 0.3002, G loss: 11.5043\n",
      "[7212/8000] D loss: 0.4357, G loss: 8.0538\n",
      "[7572/8000] D loss: 0.3759, G loss: 7.7296\n",
      "[7932/8000] D loss: 0.0692, G loss: 15.0775\n",
      "train error: \n",
      " D loss: 0.266973, G loss: 11.886211, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 13.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.659652, G loss: 16.062690, D accuracy: 91.5%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6092, G loss: 7.4421\n",
      "[372/8000] D loss: 0.2486, G loss: 10.3816\n",
      "[732/8000] D loss: 0.1444, G loss: 18.6733\n",
      "[1092/8000] D loss: 0.0984, G loss: 11.9837\n",
      "[1452/8000] D loss: 0.1255, G loss: 8.7794\n",
      "[1812/8000] D loss: 0.1904, G loss: 11.5000\n",
      "[2172/8000] D loss: 0.0891, G loss: 12.0700\n",
      "[2532/8000] D loss: 0.2401, G loss: 10.4302\n",
      "[2892/8000] D loss: 0.4305, G loss: 7.6463\n",
      "[3252/8000] D loss: 0.5044, G loss: 7.8213\n",
      "[3612/8000] D loss: 0.1968, G loss: 9.5074\n",
      "[3972/8000] D loss: 0.0821, G loss: 8.8958\n",
      "[4332/8000] D loss: 0.3690, G loss: 8.9586\n",
      "[4692/8000] D loss: 0.4075, G loss: 6.3172\n",
      "[5052/8000] D loss: 0.2718, G loss: 10.2522\n",
      "[5412/8000] D loss: 0.4527, G loss: 10.2080\n",
      "[5772/8000] D loss: 0.3733, G loss: 6.0353\n",
      "[6132/8000] D loss: 0.4150, G loss: 10.4815\n",
      "[6492/8000] D loss: 0.4757, G loss: 10.4462\n",
      "[6852/8000] D loss: 0.2721, G loss: 13.3447\n",
      "[7212/8000] D loss: 0.7705, G loss: 9.4895\n",
      "[7572/8000] D loss: 0.2638, G loss: 8.7598\n",
      "[7932/8000] D loss: 0.0038, G loss: 13.2902\n",
      "train error: \n",
      " D loss: 0.256794, G loss: 9.677662, D accuracy: 92.5%, cell accuracy: 94.7%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.569452, G loss: 13.516889, D accuracy: 91.9%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0583, G loss: 12.6343\n",
      "[372/8000] D loss: 0.2982, G loss: 11.7705\n",
      "[732/8000] D loss: 0.5492, G loss: 9.4762\n",
      "[1092/8000] D loss: 0.3111, G loss: 12.1192\n",
      "[1452/8000] D loss: 0.5389, G loss: 6.8238\n",
      "[1812/8000] D loss: 0.4944, G loss: 6.0197\n",
      "[2172/8000] D loss: 0.2047, G loss: 9.0472\n",
      "[2532/8000] D loss: 0.1445, G loss: 8.4751\n",
      "[2892/8000] D loss: 0.1512, G loss: 8.3878\n",
      "[3252/8000] D loss: 0.5187, G loss: 7.5909\n",
      "[3612/8000] D loss: 0.2297, G loss: 7.0808\n",
      "[3972/8000] D loss: 0.2884, G loss: 10.4051\n",
      "[4332/8000] D loss: 0.1146, G loss: 10.4073\n",
      "[4692/8000] D loss: 0.0308, G loss: 11.7360\n",
      "[5052/8000] D loss: 0.3692, G loss: 10.7627\n",
      "[5412/8000] D loss: 0.0950, G loss: 9.2685\n",
      "[5772/8000] D loss: 0.1044, G loss: 11.1725\n",
      "[6132/8000] D loss: 0.1215, G loss: 10.3900\n",
      "[6492/8000] D loss: 0.5338, G loss: 7.7172\n",
      "[6852/8000] D loss: 0.1780, G loss: 14.7908\n",
      "[7212/8000] D loss: 0.2442, G loss: 11.0115\n",
      "[7572/8000] D loss: 0.3654, G loss: 8.5528\n",
      "[7932/8000] D loss: 0.0492, G loss: 10.7198\n",
      "train error: \n",
      " D loss: 0.255836, G loss: 10.324121, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.567870, G loss: 14.195993, D accuracy: 92.0%, cell accuracy: 94.3%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5718, G loss: 6.5152\n",
      "[372/8000] D loss: 0.5114, G loss: 6.5086\n",
      "[732/8000] D loss: 0.1484, G loss: 8.3666\n",
      "[1092/8000] D loss: 0.0189, G loss: 14.9695\n",
      "[1452/8000] D loss: 0.3542, G loss: 9.3009\n",
      "[1812/8000] D loss: 0.3999, G loss: 10.5826\n",
      "[2172/8000] D loss: 0.2952, G loss: 11.3622\n",
      "[2532/8000] D loss: 0.3418, G loss: 7.0104\n",
      "[2892/8000] D loss: 0.5191, G loss: 8.0356\n",
      "[3252/8000] D loss: 0.2805, G loss: 9.3150\n",
      "[3612/8000] D loss: 0.0048, G loss: 14.1318\n",
      "[3972/8000] D loss: 0.5967, G loss: 7.8507\n",
      "[4332/8000] D loss: 0.0400, G loss: 10.7481\n",
      "[4692/8000] D loss: 0.1267, G loss: 10.7356\n",
      "[5052/8000] D loss: 0.0429, G loss: 11.2490\n",
      "[5412/8000] D loss: 0.4841, G loss: 8.0506\n",
      "[5772/8000] D loss: 0.2225, G loss: 9.8530\n",
      "[6132/8000] D loss: 0.0257, G loss: 11.6634\n",
      "[6492/8000] D loss: 0.0029, G loss: 14.4469\n",
      "[6852/8000] D loss: 0.3037, G loss: 9.7107\n",
      "[7212/8000] D loss: 0.1215, G loss: 9.9325\n",
      "[7572/8000] D loss: 0.1372, G loss: 10.2469\n",
      "[7932/8000] D loss: 0.1248, G loss: 12.5185\n",
      "train error: \n",
      " D loss: 0.264908, G loss: 9.925683, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.610729, G loss: 13.702924, D accuracy: 91.5%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3612, G loss: 6.3111\n",
      "[372/8000] D loss: 0.1520, G loss: 11.6314\n",
      "[732/8000] D loss: 0.1174, G loss: 10.1982\n",
      "[1092/8000] D loss: 0.3508, G loss: 8.3334\n",
      "[1452/8000] D loss: 0.4393, G loss: 10.7370\n",
      "[1812/8000] D loss: 0.1213, G loss: 11.2092\n",
      "[2172/8000] D loss: 0.2462, G loss: 10.6640\n",
      "[2532/8000] D loss: 0.1387, G loss: 9.8269\n",
      "[2892/8000] D loss: 0.1230, G loss: 10.1463\n",
      "[3252/8000] D loss: 0.2193, G loss: 11.3179\n",
      "[3612/8000] D loss: 0.1240, G loss: 11.8769\n",
      "[3972/8000] D loss: 0.4216, G loss: 7.6554\n",
      "[4332/8000] D loss: 0.0136, G loss: 9.2069\n",
      "[4692/8000] D loss: 0.2917, G loss: 11.4376\n",
      "[5052/8000] D loss: 0.3500, G loss: 9.6561\n",
      "[5412/8000] D loss: 0.3665, G loss: 7.0833\n",
      "[5772/8000] D loss: 0.2869, G loss: 11.3384\n",
      "[6132/8000] D loss: 0.2502, G loss: 9.1284\n",
      "[6492/8000] D loss: 0.0432, G loss: 9.2384\n",
      "[6852/8000] D loss: 0.1519, G loss: 9.6643\n",
      "[7212/8000] D loss: 0.0132, G loss: 12.9939\n",
      "[7572/8000] D loss: 0.2675, G loss: 7.1270\n",
      "[7932/8000] D loss: 0.0131, G loss: 11.9589\n",
      "train error: \n",
      " D loss: 0.255350, G loss: 9.511671, D accuracy: 92.5%, cell accuracy: 94.7%, board accuracy: 13.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.565717, G loss: 13.339446, D accuracy: 92.2%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3834, G loss: 8.2070\n",
      "[372/8000] D loss: 0.5436, G loss: 6.5908\n",
      "[732/8000] D loss: 0.2825, G loss: 6.8430\n",
      "[1092/8000] D loss: 0.2347, G loss: 9.2760\n",
      "[1452/8000] D loss: 0.1976, G loss: 13.4912\n",
      "[1812/8000] D loss: 0.0135, G loss: 12.8733\n",
      "[2172/8000] D loss: 0.4833, G loss: 8.2262\n",
      "[2532/8000] D loss: 0.3250, G loss: 9.0951\n",
      "[2892/8000] D loss: 0.7078, G loss: 9.4984\n",
      "[3252/8000] D loss: 0.4949, G loss: 8.8642\n",
      "[3612/8000] D loss: 0.0468, G loss: 11.8539\n",
      "[3972/8000] D loss: 0.1291, G loss: 11.6274\n",
      "[4332/8000] D loss: 0.1148, G loss: 12.4446\n",
      "[4692/8000] D loss: 0.5460, G loss: 6.8936\n",
      "[5052/8000] D loss: 0.2788, G loss: 10.3053\n",
      "[5412/8000] D loss: 0.4768, G loss: 12.9478\n",
      "[5772/8000] D loss: 0.2365, G loss: 11.9199\n",
      "[6132/8000] D loss: 0.1277, G loss: 11.2573\n",
      "[6492/8000] D loss: 0.4244, G loss: 8.4376\n",
      "[6852/8000] D loss: 0.6353, G loss: 7.3994\n",
      "[7212/8000] D loss: 0.3158, G loss: 9.2177\n",
      "[7572/8000] D loss: 0.2262, G loss: 12.8785\n",
      "[7932/8000] D loss: 0.2306, G loss: 11.6114\n",
      "train error: \n",
      " D loss: 0.250005, G loss: 10.624121, D accuracy: 92.5%, cell accuracy: 94.7%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603216, G loss: 14.572189, D accuracy: 91.6%, cell accuracy: 94.3%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3494, G loss: 9.5907\n",
      "[372/8000] D loss: 0.4180, G loss: 6.7736\n",
      "[732/8000] D loss: 0.1246, G loss: 11.3772\n",
      "[1092/8000] D loss: 0.4807, G loss: 7.0037\n",
      "[1452/8000] D loss: 0.1275, G loss: 13.1339\n",
      "[1812/8000] D loss: 0.1205, G loss: 9.5389\n",
      "[2172/8000] D loss: 0.0892, G loss: 13.1538\n",
      "[2532/8000] D loss: 0.2712, G loss: 11.6480\n",
      "[2892/8000] D loss: 0.2836, G loss: 9.2857\n",
      "[3252/8000] D loss: 0.0090, G loss: 13.9694\n",
      "[3612/8000] D loss: 0.4112, G loss: 8.7898\n",
      "[3972/8000] D loss: 0.2901, G loss: 9.2059\n",
      "[4332/8000] D loss: 0.7264, G loss: 8.3717\n",
      "[4692/8000] D loss: 0.3218, G loss: 9.5192\n",
      "[5052/8000] D loss: 0.1420, G loss: 10.7178\n",
      "[5412/8000] D loss: 0.2470, G loss: 12.6318\n",
      "[5772/8000] D loss: 0.2259, G loss: 11.0539\n",
      "[6132/8000] D loss: 0.1595, G loss: 8.1560\n",
      "[6492/8000] D loss: 0.2767, G loss: 5.2705\n",
      "[6852/8000] D loss: 0.2103, G loss: 15.0544\n",
      "[7212/8000] D loss: 0.3632, G loss: 9.6871\n",
      "[7572/8000] D loss: 0.9310, G loss: 8.5597\n",
      "[7932/8000] D loss: 0.3132, G loss: 8.0985\n",
      "train error: \n",
      " D loss: 0.281009, G loss: 10.189199, D accuracy: 92.0%, cell accuracy: 94.7%, board accuracy: 13.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.635410, G loss: 13.890249, D accuracy: 90.7%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3185, G loss: 10.3902\n",
      "[372/8000] D loss: 0.0109, G loss: 10.6807\n",
      "[732/8000] D loss: 0.2486, G loss: 12.2475\n",
      "[1092/8000] D loss: 0.2081, G loss: 10.8417\n",
      "[1452/8000] D loss: 0.2696, G loss: 12.5915\n",
      "[1812/8000] D loss: 0.2548, G loss: 9.4284\n",
      "[2172/8000] D loss: 0.1722, G loss: 5.7118\n",
      "[2532/8000] D loss: 0.3791, G loss: 10.0952\n",
      "[2892/8000] D loss: 0.1905, G loss: 11.0516\n",
      "[3252/8000] D loss: 0.1721, G loss: 11.9391\n",
      "[3612/8000] D loss: 0.2567, G loss: 8.1653\n",
      "[3972/8000] D loss: 0.3120, G loss: 10.2532\n",
      "[4332/8000] D loss: 0.2732, G loss: 9.3717\n",
      "[4692/8000] D loss: 0.5447, G loss: 9.5713\n",
      "[5052/8000] D loss: 0.4224, G loss: 9.3327\n",
      "[5412/8000] D loss: 0.5146, G loss: 6.3410\n",
      "[5772/8000] D loss: 0.2688, G loss: 10.5990\n",
      "[6132/8000] D loss: 0.2558, G loss: 10.5671\n",
      "[6492/8000] D loss: 0.2659, G loss: 11.9117\n",
      "[6852/8000] D loss: 0.0161, G loss: 11.1526\n",
      "[7212/8000] D loss: 0.7896, G loss: 9.9680\n",
      "[7572/8000] D loss: 0.2600, G loss: 12.3770\n",
      "[7932/8000] D loss: 0.2124, G loss: 16.0126\n",
      "train error: \n",
      " D loss: 0.292923, G loss: 12.453737, D accuracy: 91.8%, cell accuracy: 94.7%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.770069, G loss: 16.539389, D accuracy: 89.9%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4890, G loss: 8.8313\n",
      "[372/8000] D loss: 0.3976, G loss: 6.9471\n",
      "[732/8000] D loss: 0.1384, G loss: 10.2963\n",
      "[1092/8000] D loss: 0.3879, G loss: 7.8922\n",
      "[1452/8000] D loss: 0.3496, G loss: 8.5634\n",
      "[1812/8000] D loss: 0.2433, G loss: 11.3349\n",
      "[2172/8000] D loss: 0.2204, G loss: 11.8244\n",
      "[2532/8000] D loss: 0.1101, G loss: 12.9225\n",
      "[2892/8000] D loss: 0.3226, G loss: 6.7427\n",
      "[3252/8000] D loss: 0.4073, G loss: 9.7900\n",
      "[3612/8000] D loss: 0.0504, G loss: 12.8534\n",
      "[3972/8000] D loss: 0.3647, G loss: 8.3512\n",
      "[4332/8000] D loss: 0.2777, G loss: 7.0918\n",
      "[4692/8000] D loss: 0.7875, G loss: 8.7681\n",
      "[5052/8000] D loss: 0.3644, G loss: 12.9766\n",
      "[5412/8000] D loss: 0.2682, G loss: 15.5250\n",
      "[5772/8000] D loss: 0.2750, G loss: 6.2326\n",
      "[6132/8000] D loss: 0.0078, G loss: 13.8690\n",
      "[6492/8000] D loss: 0.0030, G loss: 15.8034\n",
      "[6852/8000] D loss: 0.1594, G loss: 6.6351\n",
      "[7212/8000] D loss: 0.2640, G loss: 14.6385\n",
      "[7572/8000] D loss: 0.2513, G loss: 8.7522\n",
      "[7932/8000] D loss: 0.2770, G loss: 8.9549\n",
      "train error: \n",
      " D loss: 0.260145, G loss: 10.334777, D accuracy: 92.4%, cell accuracy: 94.7%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.575717, G loss: 14.345350, D accuracy: 92.6%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1697, G loss: 13.7933\n",
      "[372/8000] D loss: 0.6117, G loss: 10.0656\n",
      "[732/8000] D loss: 0.2556, G loss: 13.5777\n",
      "[1092/8000] D loss: 0.0699, G loss: 10.2029\n",
      "[1452/8000] D loss: 0.5201, G loss: 6.1597\n",
      "[1812/8000] D loss: 0.1173, G loss: 12.8859\n",
      "[2172/8000] D loss: 0.1316, G loss: 14.5421\n",
      "[2532/8000] D loss: 0.2563, G loss: 10.9097\n",
      "[2892/8000] D loss: 0.3607, G loss: 10.5298\n",
      "[3252/8000] D loss: 0.3601, G loss: 9.8596\n",
      "[3612/8000] D loss: 0.3879, G loss: 9.4663\n",
      "[3972/8000] D loss: 0.2484, G loss: 11.7536\n",
      "[4332/8000] D loss: 0.6984, G loss: 7.6873\n",
      "[4692/8000] D loss: 0.2148, G loss: 12.0713\n",
      "[5052/8000] D loss: 0.4735, G loss: 8.1147\n",
      "[5412/8000] D loss: 0.1515, G loss: 10.7064\n",
      "[5772/8000] D loss: 0.2520, G loss: 9.8747\n",
      "[6132/8000] D loss: 0.0125, G loss: 13.5377\n",
      "[6492/8000] D loss: 0.2706, G loss: 9.2797\n",
      "[6852/8000] D loss: 0.5991, G loss: 8.8698\n",
      "[7212/8000] D loss: 0.0392, G loss: 8.5313\n",
      "[7572/8000] D loss: 0.0563, G loss: 12.6812\n",
      "[7932/8000] D loss: 0.1293, G loss: 15.0833\n",
      "train error: \n",
      " D loss: 0.248900, G loss: 10.948240, D accuracy: 92.5%, cell accuracy: 94.7%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.606975, G loss: 15.158122, D accuracy: 92.0%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2332, G loss: 12.7667\n",
      "[372/8000] D loss: 0.0627, G loss: 16.6480\n",
      "[732/8000] D loss: 0.3396, G loss: 9.9287\n",
      "[1092/8000] D loss: 0.0062, G loss: 10.9233\n",
      "[1452/8000] D loss: 0.1278, G loss: 15.0567\n",
      "[1812/8000] D loss: 0.1345, G loss: 10.6959\n",
      "[2172/8000] D loss: 0.3585, G loss: 10.2700\n",
      "[2532/8000] D loss: 0.1381, G loss: 11.0031\n",
      "[2892/8000] D loss: 0.4252, G loss: 7.0433\n",
      "[3252/8000] D loss: 0.3024, G loss: 8.8228\n",
      "[3612/8000] D loss: 0.2250, G loss: 14.2485\n",
      "[3972/8000] D loss: 0.2404, G loss: 11.8755\n",
      "[4332/8000] D loss: 0.3717, G loss: 7.8315\n",
      "[4692/8000] D loss: 0.2420, G loss: 11.2521\n",
      "[5052/8000] D loss: 0.1224, G loss: 10.7255\n",
      "[5412/8000] D loss: 0.0408, G loss: 10.1556\n",
      "[5772/8000] D loss: 0.2859, G loss: 8.4136\n",
      "[6132/8000] D loss: 0.3529, G loss: 10.2411\n",
      "[6492/8000] D loss: 0.1429, G loss: 11.0758\n",
      "[6852/8000] D loss: 0.1371, G loss: 13.7535\n",
      "[7212/8000] D loss: 0.2440, G loss: 8.7539\n",
      "[7572/8000] D loss: 0.2424, G loss: 10.7417\n",
      "[7932/8000] D loss: 0.3496, G loss: 9.2516\n",
      "train error: \n",
      " D loss: 0.255765, G loss: 10.537643, D accuracy: 92.4%, cell accuracy: 94.7%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.582542, G loss: 14.531594, D accuracy: 91.7%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3305, G loss: 11.5489\n",
      "[372/8000] D loss: 0.2525, G loss: 15.5093\n",
      "[732/8000] D loss: 0.2500, G loss: 10.4026\n",
      "[1092/8000] D loss: 0.1146, G loss: 12.0999\n",
      "[1452/8000] D loss: 0.1326, G loss: 10.7809\n",
      "[1812/8000] D loss: 0.3968, G loss: 9.8150\n",
      "[2172/8000] D loss: 0.2605, G loss: 8.9454\n",
      "[2532/8000] D loss: 0.1793, G loss: 11.2033\n",
      "[2892/8000] D loss: 0.3217, G loss: 9.2220\n",
      "[3252/8000] D loss: 0.2315, G loss: 10.6306\n",
      "[3612/8000] D loss: 0.1595, G loss: 10.8018\n",
      "[3972/8000] D loss: 0.4213, G loss: 9.0818\n",
      "[4332/8000] D loss: 0.7072, G loss: 7.0107\n",
      "[4692/8000] D loss: 0.3404, G loss: 10.3926\n",
      "[5052/8000] D loss: 0.3540, G loss: 12.2503\n",
      "[5412/8000] D loss: 0.3365, G loss: 11.1786\n",
      "[5772/8000] D loss: 0.1416, G loss: 7.6328\n",
      "[6132/8000] D loss: 0.0213, G loss: 15.8286\n",
      "[6492/8000] D loss: 0.3349, G loss: 7.4535\n",
      "[6852/8000] D loss: 0.5282, G loss: 8.1724\n",
      "[7212/8000] D loss: 0.6305, G loss: 8.1969\n",
      "[7572/8000] D loss: 0.1933, G loss: 12.9474\n",
      "[7932/8000] D loss: 0.1500, G loss: 10.7055\n",
      "train error: \n",
      " D loss: 0.264404, G loss: 10.955686, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.653895, G loss: 14.658886, D accuracy: 90.9%, cell accuracy: 94.3%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3565, G loss: 12.0925\n",
      "[372/8000] D loss: 0.3613, G loss: 8.8722\n",
      "[732/8000] D loss: 0.2749, G loss: 7.7500\n",
      "[1092/8000] D loss: 0.2643, G loss: 9.7474\n",
      "[1452/8000] D loss: 0.2370, G loss: 11.8505\n",
      "[1812/8000] D loss: 0.5540, G loss: 5.3461\n",
      "[2172/8000] D loss: 0.0171, G loss: 12.6678\n",
      "[2532/8000] D loss: 0.1814, G loss: 10.1741\n",
      "[2892/8000] D loss: 0.0936, G loss: 11.7737\n",
      "[3252/8000] D loss: 0.5649, G loss: 10.0026\n",
      "[3612/8000] D loss: 0.3262, G loss: 10.7141\n",
      "[3972/8000] D loss: 0.1303, G loss: 10.7318\n",
      "[4332/8000] D loss: 0.3206, G loss: 7.9093\n",
      "[4692/8000] D loss: 0.2528, G loss: 12.8846\n",
      "[5052/8000] D loss: 0.3657, G loss: 10.0121\n",
      "[5412/8000] D loss: 0.4094, G loss: 11.4768\n",
      "[5772/8000] D loss: 0.2205, G loss: 9.6482\n",
      "[6132/8000] D loss: 0.3677, G loss: 9.1793\n",
      "[6492/8000] D loss: 0.2493, G loss: 8.5054\n",
      "[6852/8000] D loss: 0.5427, G loss: 7.4783\n",
      "[7212/8000] D loss: 0.2713, G loss: 8.4369\n",
      "[7572/8000] D loss: 0.0189, G loss: 14.0993\n",
      "[7932/8000] D loss: 0.0888, G loss: 14.8195\n",
      "train error: \n",
      " D loss: 0.279455, G loss: 10.422739, D accuracy: 92.1%, cell accuracy: 94.7%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.566966, G loss: 14.437792, D accuracy: 93.0%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4564, G loss: 8.2266\n",
      "[372/8000] D loss: 0.5531, G loss: 5.7434\n",
      "[732/8000] D loss: 0.3890, G loss: 7.5673\n",
      "[1092/8000] D loss: 0.1264, G loss: 11.3633\n",
      "[1452/8000] D loss: 0.3681, G loss: 7.8672\n",
      "[1812/8000] D loss: 0.2113, G loss: 9.0051\n",
      "[2172/8000] D loss: 0.1734, G loss: 12.5224\n",
      "[2532/8000] D loss: 0.3468, G loss: 9.9699\n",
      "[2892/8000] D loss: 0.3702, G loss: 8.1543\n",
      "[3252/8000] D loss: 0.1217, G loss: 10.3153\n",
      "[3612/8000] D loss: 0.1738, G loss: 9.9871\n",
      "[3972/8000] D loss: 0.1436, G loss: 10.6175\n",
      "[4332/8000] D loss: 0.1197, G loss: 12.1244\n",
      "[4692/8000] D loss: 0.0063, G loss: 12.0778\n",
      "[5052/8000] D loss: 0.2481, G loss: 17.1990\n",
      "[5412/8000] D loss: 0.1602, G loss: 11.5190\n",
      "[5772/8000] D loss: 0.1166, G loss: 16.6004\n",
      "[6132/8000] D loss: 0.1911, G loss: 9.1891\n",
      "[6492/8000] D loss: 0.1674, G loss: 12.2413\n",
      "[6852/8000] D loss: 0.2244, G loss: 11.9650\n",
      "[7212/8000] D loss: 0.1300, G loss: 12.6115\n",
      "[7572/8000] D loss: 0.4425, G loss: 8.4826\n",
      "[7932/8000] D loss: 0.3664, G loss: 11.3808\n",
      "train error: \n",
      " D loss: 0.257588, G loss: 9.916029, D accuracy: 92.6%, cell accuracy: 94.7%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.515825, G loss: 13.805698, D accuracy: 93.0%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3465, G loss: 7.3260\n",
      "[372/8000] D loss: 0.0487, G loss: 9.2148\n",
      "[732/8000] D loss: 0.4523, G loss: 9.4447\n",
      "[1092/8000] D loss: 0.6107, G loss: 7.4410\n",
      "[1452/8000] D loss: 0.3313, G loss: 9.2339\n",
      "[1812/8000] D loss: 0.3750, G loss: 9.3948\n",
      "[2172/8000] D loss: 0.0895, G loss: 11.7185\n",
      "[2532/8000] D loss: 0.4033, G loss: 7.1321\n",
      "[2892/8000] D loss: 0.1341, G loss: 10.1341\n",
      "[3252/8000] D loss: 0.1279, G loss: 11.0360\n",
      "[3612/8000] D loss: 0.1257, G loss: 11.9984\n",
      "[3972/8000] D loss: 0.3052, G loss: 7.9102\n",
      "[4332/8000] D loss: 0.2604, G loss: 14.2520\n",
      "[4692/8000] D loss: 0.2790, G loss: 13.8257\n",
      "[5052/8000] D loss: 0.1326, G loss: 9.4168\n",
      "[5412/8000] D loss: 0.2597, G loss: 12.2752\n",
      "[5772/8000] D loss: 0.1128, G loss: 10.5817\n",
      "[6132/8000] D loss: 0.3706, G loss: 8.8247\n",
      "[6492/8000] D loss: 0.0451, G loss: 9.1383\n",
      "[6852/8000] D loss: 0.8035, G loss: 5.6651\n",
      "[7212/8000] D loss: 0.2558, G loss: 11.1013\n",
      "[7572/8000] D loss: 0.2275, G loss: 11.8729\n",
      "[7932/8000] D loss: 0.1345, G loss: 13.0689\n",
      "train error: \n",
      " D loss: 0.258511, G loss: 9.362565, D accuracy: 92.4%, cell accuracy: 94.7%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.541604, G loss: 13.061717, D accuracy: 92.1%, cell accuracy: 94.2%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1523, G loss: 9.8493\n",
      "[372/8000] D loss: 0.1404, G loss: 9.3751\n",
      "[732/8000] D loss: 0.4595, G loss: 6.7099\n",
      "[1092/8000] D loss: 0.0636, G loss: 10.3722\n",
      "[1452/8000] D loss: 0.3815, G loss: 7.7545\n",
      "[1812/8000] D loss: 0.6617, G loss: 6.2924\n",
      "[2172/8000] D loss: 0.4377, G loss: 9.3498\n",
      "[2532/8000] D loss: 0.4144, G loss: 5.7616\n",
      "[2892/8000] D loss: 0.3880, G loss: 10.7146\n",
      "[3252/8000] D loss: 0.1468, G loss: 13.0288\n",
      "[3612/8000] D loss: 0.2023, G loss: 7.4822\n",
      "[3972/8000] D loss: 0.1160, G loss: 14.2738\n",
      "[4332/8000] D loss: 0.2918, G loss: 7.2074\n",
      "[4692/8000] D loss: 0.2313, G loss: 7.1845\n",
      "[5052/8000] D loss: 0.0089, G loss: 12.8365\n",
      "[5412/8000] D loss: 0.4570, G loss: 9.0016\n",
      "[5772/8000] D loss: 0.3243, G loss: 10.1719\n",
      "[6132/8000] D loss: 0.1373, G loss: 11.1616\n",
      "[6492/8000] D loss: 0.1202, G loss: 12.0552\n",
      "[6852/8000] D loss: 0.3419, G loss: 8.2986\n",
      "[7212/8000] D loss: 0.1433, G loss: 8.2484\n",
      "[7572/8000] D loss: 0.2383, G loss: 9.6104\n",
      "[7932/8000] D loss: 0.5843, G loss: 8.7655\n",
      "train error: \n",
      " D loss: 0.262410, G loss: 9.654213, D accuracy: 92.5%, cell accuracy: 94.8%, board accuracy: 13.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.530282, G loss: 13.596952, D accuracy: 92.3%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1670, G loss: 12.8512\n",
      "[372/8000] D loss: 0.1164, G loss: 14.5741\n",
      "[732/8000] D loss: 0.3077, G loss: 11.4441\n",
      "[1092/8000] D loss: 0.4321, G loss: 12.6463\n",
      "[1452/8000] D loss: 0.1401, G loss: 9.3405\n",
      "[1812/8000] D loss: 0.2824, G loss: 9.7246\n",
      "[2172/8000] D loss: 0.0083, G loss: 14.7376\n",
      "[2532/8000] D loss: 0.0165, G loss: 9.6790\n",
      "[2892/8000] D loss: 0.0055, G loss: 15.3110\n",
      "[3252/8000] D loss: 0.1196, G loss: 12.3949\n",
      "[3612/8000] D loss: 0.4887, G loss: 6.7040\n",
      "[3972/8000] D loss: 0.0199, G loss: 10.6732\n",
      "[4332/8000] D loss: 0.3842, G loss: 8.9455\n",
      "[4692/8000] D loss: 0.0105, G loss: 12.7564\n",
      "[5052/8000] D loss: 0.1180, G loss: 13.7058\n",
      "[5412/8000] D loss: 0.0058, G loss: 12.9412\n",
      "[5772/8000] D loss: 0.0070, G loss: 13.4936\n",
      "[6132/8000] D loss: 0.2163, G loss: 9.9527\n",
      "[6492/8000] D loss: 0.3816, G loss: 6.7415\n",
      "[6852/8000] D loss: 0.5903, G loss: 8.2156\n",
      "[7212/8000] D loss: 0.2941, G loss: 8.8141\n",
      "[7572/8000] D loss: 0.2249, G loss: 9.1352\n",
      "[7932/8000] D loss: 0.4148, G loss: 13.5113\n",
      "train error: \n",
      " D loss: 0.250339, G loss: 10.567961, D accuracy: 92.7%, cell accuracy: 94.7%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.579813, G loss: 14.510028, D accuracy: 92.1%, cell accuracy: 94.2%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3499, G loss: 9.9700\n",
      "[372/8000] D loss: 0.3892, G loss: 7.9147\n",
      "[732/8000] D loss: 0.1946, G loss: 11.9173\n",
      "[1092/8000] D loss: 0.3070, G loss: 11.2022\n",
      "[1452/8000] D loss: 0.1148, G loss: 9.8281\n",
      "[1812/8000] D loss: 0.1469, G loss: 11.3079\n",
      "[2172/8000] D loss: 0.2617, G loss: 11.5679\n",
      "[2532/8000] D loss: 0.3124, G loss: 9.6336\n",
      "[2892/8000] D loss: 0.2515, G loss: 9.3022\n",
      "[3252/8000] D loss: 0.2979, G loss: 9.8957\n",
      "[3612/8000] D loss: 0.5206, G loss: 6.7420\n",
      "[3972/8000] D loss: 0.5291, G loss: 8.5994\n",
      "[4332/8000] D loss: 0.4625, G loss: 9.3039\n",
      "[4692/8000] D loss: 0.2841, G loss: 10.8937\n",
      "[5052/8000] D loss: 0.2665, G loss: 7.9699\n",
      "[5412/8000] D loss: 0.3494, G loss: 13.4295\n",
      "[5772/8000] D loss: 0.2709, G loss: 12.9051\n",
      "[6132/8000] D loss: 0.1928, G loss: 10.0432\n",
      "[6492/8000] D loss: 0.2709, G loss: 12.3288\n",
      "[6852/8000] D loss: 0.4135, G loss: 14.8937\n",
      "[7212/8000] D loss: 0.3394, G loss: 8.9963\n",
      "[7572/8000] D loss: 0.0021, G loss: 13.1608\n",
      "[7932/8000] D loss: 0.3484, G loss: 9.3873\n",
      "train error: \n",
      " D loss: 0.269422, G loss: 11.371817, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.681791, G loss: 15.643184, D accuracy: 91.5%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1123, G loss: 12.0649\n",
      "[372/8000] D loss: 0.2081, G loss: 12.9760\n",
      "[732/8000] D loss: 0.2108, G loss: 12.1564\n",
      "[1092/8000] D loss: 0.0813, G loss: 13.7265\n",
      "[1452/8000] D loss: 0.2853, G loss: 10.4720\n",
      "[1812/8000] D loss: 0.2348, G loss: 7.3586\n",
      "[2172/8000] D loss: 0.8000, G loss: 7.1193\n",
      "[2532/8000] D loss: 0.2340, G loss: 10.5087\n",
      "[2892/8000] D loss: 0.3273, G loss: 9.8409\n",
      "[3252/8000] D loss: 0.1505, G loss: 16.3360\n",
      "[3612/8000] D loss: 0.0455, G loss: 10.7497\n",
      "[3972/8000] D loss: 0.3085, G loss: 9.2275\n",
      "[4332/8000] D loss: 0.3821, G loss: 7.3130\n",
      "[4692/8000] D loss: 0.2373, G loss: 12.1234\n",
      "[5052/8000] D loss: 0.2568, G loss: 9.7587\n",
      "[5412/8000] D loss: 0.5374, G loss: 8.2942\n",
      "[5772/8000] D loss: 0.4912, G loss: 6.5048\n",
      "[6132/8000] D loss: 0.3876, G loss: 10.2415\n",
      "[6492/8000] D loss: 0.2180, G loss: 8.4547\n",
      "[6852/8000] D loss: 0.4630, G loss: 8.8407\n",
      "[7212/8000] D loss: 0.3940, G loss: 9.0071\n",
      "[7572/8000] D loss: 0.1302, G loss: 9.4361\n",
      "[7932/8000] D loss: 0.4012, G loss: 8.9467\n",
      "train error: \n",
      " D loss: 0.257285, G loss: 10.828155, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 13.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.632405, G loss: 15.010534, D accuracy: 91.6%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2428, G loss: 13.9609\n",
      "[372/8000] D loss: 0.2147, G loss: 13.7878\n",
      "[732/8000] D loss: 0.2604, G loss: 8.0850\n",
      "[1092/8000] D loss: 0.3968, G loss: 7.7953\n",
      "[1452/8000] D loss: 0.1998, G loss: 8.9767\n",
      "[1812/8000] D loss: 0.2375, G loss: 9.9657\n",
      "[2172/8000] D loss: 0.4542, G loss: 7.9487\n",
      "[2532/8000] D loss: 0.3833, G loss: 6.9457\n",
      "[2892/8000] D loss: 0.2968, G loss: 8.7747\n",
      "[3252/8000] D loss: 0.6122, G loss: 5.3123\n",
      "[3612/8000] D loss: 0.0428, G loss: 9.5930\n",
      "[3972/8000] D loss: 0.0391, G loss: 11.8849\n",
      "[4332/8000] D loss: 0.0459, G loss: 12.0405\n",
      "[4692/8000] D loss: 0.0202, G loss: 11.3602\n",
      "[5052/8000] D loss: 0.2496, G loss: 9.5730\n",
      "[5412/8000] D loss: 0.5089, G loss: 7.7003\n",
      "[5772/8000] D loss: 0.1480, G loss: 13.1334\n",
      "[6132/8000] D loss: 0.2673, G loss: 14.2908\n",
      "[6492/8000] D loss: 0.3350, G loss: 12.4624\n",
      "[6852/8000] D loss: 0.0867, G loss: 7.9047\n",
      "[7212/8000] D loss: 0.1201, G loss: 15.3186\n",
      "[7572/8000] D loss: 0.0133, G loss: 11.8896\n",
      "[7932/8000] D loss: 0.3406, G loss: 10.9901\n",
      "train error: \n",
      " D loss: 0.257524, G loss: 10.447894, D accuracy: 92.7%, cell accuracy: 94.7%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.556259, G loss: 14.522585, D accuracy: 92.8%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0870, G loss: 10.8732\n",
      "[372/8000] D loss: 0.5043, G loss: 10.7974\n",
      "[732/8000] D loss: 0.3536, G loss: 9.0556\n",
      "[1092/8000] D loss: 0.1352, G loss: 11.2400\n",
      "[1452/8000] D loss: 0.5023, G loss: 7.8944\n",
      "[1812/8000] D loss: 0.1397, G loss: 11.5069\n",
      "[2172/8000] D loss: 0.5793, G loss: 12.6651\n",
      "[2532/8000] D loss: 0.0035, G loss: 14.2470\n",
      "[2892/8000] D loss: 0.1243, G loss: 11.4545\n",
      "[3252/8000] D loss: 0.4926, G loss: 10.6669\n",
      "[3612/8000] D loss: 0.0908, G loss: 12.4974\n",
      "[3972/8000] D loss: 0.2773, G loss: 7.5230\n",
      "[4332/8000] D loss: 0.0180, G loss: 11.3173\n",
      "[4692/8000] D loss: 0.1179, G loss: 10.5098\n",
      "[5052/8000] D loss: 0.1695, G loss: 8.1673\n",
      "[5412/8000] D loss: 0.3131, G loss: 10.5012\n",
      "[5772/8000] D loss: 0.1171, G loss: 12.7530\n",
      "[6132/8000] D loss: 0.3843, G loss: 7.6100\n",
      "[6492/8000] D loss: 0.1609, G loss: 14.2049\n",
      "[6852/8000] D loss: 0.1549, G loss: 9.9824\n",
      "[7212/8000] D loss: 0.4006, G loss: 7.2597\n",
      "[7572/8000] D loss: 0.4659, G loss: 6.6663\n",
      "[7932/8000] D loss: 0.2532, G loss: 9.9210\n",
      "train error: \n",
      " D loss: 0.274624, G loss: 11.139215, D accuracy: 92.2%, cell accuracy: 94.7%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.620053, G loss: 15.235017, D accuracy: 92.7%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3098, G loss: 10.7861\n",
      "[372/8000] D loss: 0.2468, G loss: 8.6597\n",
      "[732/8000] D loss: 0.5387, G loss: 9.0213\n",
      "[1092/8000] D loss: 0.4505, G loss: 9.3353\n",
      "[1452/8000] D loss: 0.3535, G loss: 8.3355\n",
      "[1812/8000] D loss: 0.1158, G loss: 11.1236\n",
      "[2172/8000] D loss: 0.2747, G loss: 7.1913\n",
      "[2532/8000] D loss: 0.4776, G loss: 7.9916\n",
      "[2892/8000] D loss: 0.3868, G loss: 8.7784\n",
      "[3252/8000] D loss: 0.4948, G loss: 7.8881\n",
      "[3612/8000] D loss: 0.3918, G loss: 9.9578\n",
      "[3972/8000] D loss: 0.0601, G loss: 14.0366\n",
      "[4332/8000] D loss: 0.1240, G loss: 15.1026\n",
      "[4692/8000] D loss: 0.6079, G loss: 8.8902\n",
      "[5052/8000] D loss: 0.2820, G loss: 12.2869\n",
      "[5412/8000] D loss: 0.5062, G loss: 8.1898\n",
      "[5772/8000] D loss: 0.4182, G loss: 6.6230\n",
      "[6132/8000] D loss: 0.4252, G loss: 5.6030\n",
      "[6492/8000] D loss: 0.2464, G loss: 10.1292\n",
      "[6852/8000] D loss: 0.4055, G loss: 11.3413\n",
      "[7212/8000] D loss: 0.2404, G loss: 10.0816\n",
      "[7572/8000] D loss: 0.4423, G loss: 8.1113\n",
      "[7932/8000] D loss: 0.2299, G loss: 11.1501\n",
      "train error: \n",
      " D loss: 0.268741, G loss: 11.783911, D accuracy: 92.2%, cell accuracy: 94.7%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.662028, G loss: 16.108566, D accuracy: 90.6%, cell accuracy: 94.3%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4572, G loss: 9.5928\n",
      "[372/8000] D loss: 0.0107, G loss: 12.6885\n",
      "[732/8000] D loss: 0.4464, G loss: 13.8607\n",
      "[1092/8000] D loss: 0.4713, G loss: 7.4534\n",
      "[1452/8000] D loss: 0.3933, G loss: 8.3167\n",
      "[1812/8000] D loss: 0.3643, G loss: 9.7064\n",
      "[2172/8000] D loss: 0.0292, G loss: 13.3673\n",
      "[2532/8000] D loss: 0.1171, G loss: 14.3114\n",
      "[2892/8000] D loss: 0.0158, G loss: 13.3077\n",
      "[3252/8000] D loss: 0.2528, G loss: 8.5165\n",
      "[3612/8000] D loss: 0.4972, G loss: 8.1387\n",
      "[3972/8000] D loss: 0.3510, G loss: 9.5037\n",
      "[4332/8000] D loss: 0.2524, G loss: 9.3015\n",
      "[4692/8000] D loss: 0.1959, G loss: 9.3941\n",
      "[5052/8000] D loss: 0.1466, G loss: 10.1687\n",
      "[5412/8000] D loss: 0.3613, G loss: 7.2297\n",
      "[5772/8000] D loss: 0.0226, G loss: 11.7761\n",
      "[6132/8000] D loss: 0.2503, G loss: 10.5709\n",
      "[6492/8000] D loss: 0.2560, G loss: 12.4041\n",
      "[6852/8000] D loss: 0.0292, G loss: 10.8845\n",
      "[7212/8000] D loss: 0.4998, G loss: 6.5862\n",
      "[7572/8000] D loss: 0.1027, G loss: 12.9527\n",
      "[7932/8000] D loss: 0.3033, G loss: 9.9631\n",
      "train error: \n",
      " D loss: 0.256111, G loss: 10.811355, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.582635, G loss: 14.815805, D accuracy: 92.0%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1263, G loss: 8.9058\n",
      "[372/8000] D loss: 0.1465, G loss: 10.6239\n",
      "[732/8000] D loss: 0.1509, G loss: 15.7416\n",
      "[1092/8000] D loss: 0.1342, G loss: 10.9909\n",
      "[1452/8000] D loss: 0.2809, G loss: 9.5535\n",
      "[1812/8000] D loss: 0.0523, G loss: 7.3373\n",
      "[2172/8000] D loss: 0.1267, G loss: 11.4593\n",
      "[2532/8000] D loss: 0.0042, G loss: 13.6095\n",
      "[2892/8000] D loss: 0.1213, G loss: 12.4842\n",
      "[3252/8000] D loss: 0.2296, G loss: 8.4678\n",
      "[3612/8000] D loss: 0.1535, G loss: 14.0093\n",
      "[3972/8000] D loss: 0.0327, G loss: 12.4555\n",
      "[4332/8000] D loss: 0.1359, G loss: 9.3761\n",
      "[4692/8000] D loss: 0.1418, G loss: 10.9726\n",
      "[5052/8000] D loss: 0.1212, G loss: 11.9224\n",
      "[5412/8000] D loss: 0.2723, G loss: 8.2705\n",
      "[5772/8000] D loss: 0.0910, G loss: 9.4615\n",
      "[6132/8000] D loss: 0.1493, G loss: 8.3250\n",
      "[6492/8000] D loss: 0.5560, G loss: 7.4209\n",
      "[6852/8000] D loss: 0.1578, G loss: 13.6503\n",
      "[7212/8000] D loss: 0.2592, G loss: 8.7073\n",
      "[7572/8000] D loss: 0.1401, G loss: 12.9450\n",
      "[7932/8000] D loss: 0.4117, G loss: 8.9035\n",
      "train error: \n",
      " D loss: 0.254155, G loss: 9.872993, D accuracy: 92.6%, cell accuracy: 94.7%, board accuracy: 13.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.560088, G loss: 13.956306, D accuracy: 92.4%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1230, G loss: 10.5346\n",
      "[372/8000] D loss: 0.3836, G loss: 10.1553\n",
      "[732/8000] D loss: 0.3592, G loss: 8.5415\n",
      "[1092/8000] D loss: 0.5517, G loss: 5.5339\n",
      "[1452/8000] D loss: 0.2907, G loss: 9.3703\n",
      "[1812/8000] D loss: 0.2588, G loss: 10.3728\n",
      "[2172/8000] D loss: 0.1280, G loss: 12.9278\n",
      "[2532/8000] D loss: 0.0688, G loss: 12.0669\n",
      "[2892/8000] D loss: 0.2517, G loss: 11.8563\n",
      "[3252/8000] D loss: 0.0253, G loss: 12.0593\n",
      "[3612/8000] D loss: 0.1005, G loss: 10.0495\n",
      "[3972/8000] D loss: 0.3878, G loss: 5.6665\n",
      "[4332/8000] D loss: 0.1316, G loss: 11.7867\n",
      "[4692/8000] D loss: 0.3948, G loss: 7.0735\n",
      "[5052/8000] D loss: 0.1618, G loss: 13.5802\n",
      "[5412/8000] D loss: 0.2035, G loss: 9.2845\n",
      "[5772/8000] D loss: 0.3246, G loss: 8.4790\n",
      "[6132/8000] D loss: 0.2866, G loss: 7.4110\n",
      "[6492/8000] D loss: 0.3703, G loss: 12.6823\n",
      "[6852/8000] D loss: 0.2003, G loss: 8.5856\n",
      "[7212/8000] D loss: 0.3119, G loss: 8.7578\n",
      "[7572/8000] D loss: 0.5440, G loss: 9.5116\n",
      "[7932/8000] D loss: 0.3448, G loss: 7.8610\n",
      "train error: \n",
      " D loss: 0.256158, G loss: 9.664236, D accuracy: 92.5%, cell accuracy: 94.8%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.571378, G loss: 13.622681, D accuracy: 91.4%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3449, G loss: 6.2616\n",
      "[372/8000] D loss: 0.1156, G loss: 13.1782\n",
      "[732/8000] D loss: 0.2416, G loss: 10.5175\n",
      "[1092/8000] D loss: 0.0015, G loss: 9.4323\n",
      "[1452/8000] D loss: 0.2857, G loss: 9.1487\n",
      "[1812/8000] D loss: 0.3253, G loss: 11.4464\n",
      "[2172/8000] D loss: 0.0324, G loss: 10.3201\n",
      "[2532/8000] D loss: 0.4399, G loss: 14.0944\n",
      "[2892/8000] D loss: 0.1112, G loss: 9.9087\n",
      "[3252/8000] D loss: 0.4959, G loss: 9.6399\n",
      "[3612/8000] D loss: 0.1541, G loss: 10.2813\n",
      "[3972/8000] D loss: 0.1305, G loss: 8.2604\n",
      "[4332/8000] D loss: 0.1806, G loss: 12.3273\n",
      "[4692/8000] D loss: 0.3630, G loss: 9.4949\n",
      "[5052/8000] D loss: 0.3363, G loss: 9.6649\n",
      "[5412/8000] D loss: 0.3843, G loss: 7.2658\n",
      "[5772/8000] D loss: 0.4187, G loss: 14.1366\n",
      "[6132/8000] D loss: 0.0208, G loss: 13.0856\n",
      "[6492/8000] D loss: 0.1196, G loss: 10.0757\n",
      "[6852/8000] D loss: 0.3596, G loss: 10.0480\n",
      "[7212/8000] D loss: 0.2798, G loss: 9.5202\n",
      "[7572/8000] D loss: 0.4399, G loss: 9.7733\n",
      "[7932/8000] D loss: 0.5816, G loss: 9.1691\n",
      "train error: \n",
      " D loss: 0.261815, G loss: 10.386125, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.584639, G loss: 14.656486, D accuracy: 92.5%, cell accuracy: 94.3%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0033, G loss: 11.6275\n",
      "[372/8000] D loss: 0.2729, G loss: 10.9054\n",
      "[732/8000] D loss: 0.1650, G loss: 10.0450\n",
      "[1092/8000] D loss: 0.1300, G loss: 10.0144\n",
      "[1452/8000] D loss: 0.3582, G loss: 11.3414\n",
      "[1812/8000] D loss: 0.1864, G loss: 11.4138\n",
      "[2172/8000] D loss: 0.1856, G loss: 13.5549\n",
      "[2532/8000] D loss: 0.1526, G loss: 10.6239\n",
      "[2892/8000] D loss: 0.1088, G loss: 14.1798\n",
      "[3252/8000] D loss: 0.3504, G loss: 11.9819\n",
      "[3612/8000] D loss: 0.1661, G loss: 11.9370\n",
      "[3972/8000] D loss: 0.0603, G loss: 15.0505\n",
      "[4332/8000] D loss: 0.2389, G loss: 13.9113\n",
      "[4692/8000] D loss: 0.0032, G loss: 12.3567\n",
      "[5052/8000] D loss: 0.5543, G loss: 9.7845\n",
      "[5412/8000] D loss: 0.3900, G loss: 7.9813\n",
      "[5772/8000] D loss: 0.4502, G loss: 7.4258\n",
      "[6132/8000] D loss: 0.3577, G loss: 10.8729\n",
      "[6492/8000] D loss: 0.2854, G loss: 13.2056\n",
      "[6852/8000] D loss: 0.3562, G loss: 8.6800\n",
      "[7212/8000] D loss: 0.2634, G loss: 10.5771\n",
      "[7572/8000] D loss: 0.0034, G loss: 13.4206\n",
      "[7932/8000] D loss: 0.2410, G loss: 9.6874\n",
      "train error: \n",
      " D loss: 0.262351, G loss: 10.979054, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.636188, G loss: 15.223147, D accuracy: 91.4%, cell accuracy: 94.3%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2397, G loss: 15.4164\n",
      "[372/8000] D loss: 0.2442, G loss: 15.2273\n",
      "[732/8000] D loss: 0.2384, G loss: 8.1864\n",
      "[1092/8000] D loss: 0.4397, G loss: 11.0272\n",
      "[1452/8000] D loss: 0.1407, G loss: 9.8884\n",
      "[1812/8000] D loss: 0.1261, G loss: 14.4728\n",
      "[2172/8000] D loss: 0.6079, G loss: 6.8822\n",
      "[2532/8000] D loss: 0.0603, G loss: 15.4955\n",
      "[2892/8000] D loss: 0.0083, G loss: 14.8682\n",
      "[3252/8000] D loss: 0.1087, G loss: 11.3609\n",
      "[3612/8000] D loss: 0.4586, G loss: 5.6716\n",
      "[3972/8000] D loss: 0.1217, G loss: 15.9051\n",
      "[4332/8000] D loss: 0.2811, G loss: 11.1426\n",
      "[4692/8000] D loss: 0.1785, G loss: 10.6323\n",
      "[5052/8000] D loss: 0.3058, G loss: 10.8291\n",
      "[5412/8000] D loss: 0.2525, G loss: 9.3429\n",
      "[5772/8000] D loss: 0.3194, G loss: 10.5742\n",
      "[6132/8000] D loss: 0.3499, G loss: 9.8915\n",
      "[6492/8000] D loss: 0.7704, G loss: 4.5092\n",
      "[6852/8000] D loss: 0.2374, G loss: 11.8048\n",
      "[7212/8000] D loss: 0.7692, G loss: 7.9957\n",
      "[7572/8000] D loss: 0.2548, G loss: 10.6919\n",
      "[7932/8000] D loss: 0.1839, G loss: 11.4067\n",
      "train error: \n",
      " D loss: 0.263523, G loss: 10.471712, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 14.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.600457, G loss: 14.801764, D accuracy: 92.1%, cell accuracy: 94.3%, board accuracy: 6.1% \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2867, G loss: 9.9343\n",
      "[372/8000] D loss: 0.0289, G loss: 11.5997\n",
      "[732/8000] D loss: 0.6038, G loss: 8.0957\n",
      "[1092/8000] D loss: 0.4849, G loss: 8.8525\n",
      "[1452/8000] D loss: 0.1264, G loss: 9.4244\n",
      "[1812/8000] D loss: 0.4651, G loss: 11.7477\n",
      "[2172/8000] D loss: 0.3661, G loss: 9.4452\n",
      "[2532/8000] D loss: 0.1180, G loss: 7.1563\n",
      "[2892/8000] D loss: 0.3445, G loss: 10.5090\n",
      "[3252/8000] D loss: 0.3817, G loss: 12.9362\n",
      "[3612/8000] D loss: 0.0454, G loss: 13.9720\n",
      "[3972/8000] D loss: 0.1302, G loss: 17.0184\n",
      "[4332/8000] D loss: 0.1452, G loss: 12.0833\n",
      "[4692/8000] D loss: 0.3625, G loss: 7.4130\n",
      "[5052/8000] D loss: 0.2446, G loss: 10.1498\n",
      "[5412/8000] D loss: 0.2614, G loss: 7.3334\n",
      "[5772/8000] D loss: 0.2749, G loss: 11.8190\n",
      "[6132/8000] D loss: 0.1012, G loss: 10.6498\n",
      "[6492/8000] D loss: 0.1253, G loss: 13.1810\n",
      "[6852/8000] D loss: 0.0539, G loss: 12.2885\n",
      "[7212/8000] D loss: 0.1234, G loss: 10.9504\n",
      "[7572/8000] D loss: 0.2655, G loss: 11.0158\n",
      "[7932/8000] D loss: 0.1485, G loss: 11.7753\n",
      "train error: \n",
      " D loss: 0.261390, G loss: 12.017806, D accuracy: 92.5%, cell accuracy: 94.8%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.651367, G loss: 16.445858, D accuracy: 91.5%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2459, G loss: 13.5518\n",
      "[372/8000] D loss: 0.1078, G loss: 14.3152\n",
      "[732/8000] D loss: 0.0055, G loss: 18.3289\n",
      "[1092/8000] D loss: 0.2976, G loss: 10.6632\n",
      "[1452/8000] D loss: 0.4877, G loss: 8.8567\n",
      "[1812/8000] D loss: 0.0851, G loss: 16.5974\n",
      "[2172/8000] D loss: 0.3525, G loss: 10.9667\n",
      "[2532/8000] D loss: 0.3705, G loss: 8.6875\n",
      "[2892/8000] D loss: 0.2737, G loss: 8.8341\n",
      "[3252/8000] D loss: 0.1493, G loss: 6.3924\n",
      "[3612/8000] D loss: 0.3671, G loss: 9.6163\n",
      "[3972/8000] D loss: 0.4694, G loss: 11.8895\n",
      "[4332/8000] D loss: 0.3379, G loss: 8.8548\n",
      "[4692/8000] D loss: 0.3247, G loss: 8.8966\n",
      "[5052/8000] D loss: 0.4194, G loss: 8.5828\n",
      "[5412/8000] D loss: 0.1203, G loss: 8.3746\n",
      "[5772/8000] D loss: 0.1283, G loss: 8.0511\n",
      "[6132/8000] D loss: 0.4613, G loss: 8.2983\n",
      "[6492/8000] D loss: 0.0190, G loss: 12.5643\n",
      "[6852/8000] D loss: 0.1282, G loss: 8.7113\n",
      "[7212/8000] D loss: 0.1065, G loss: 11.8579\n",
      "[7572/8000] D loss: 0.2395, G loss: 11.6946\n",
      "[7932/8000] D loss: 0.0066, G loss: 15.6051\n",
      "train error: \n",
      " D loss: 0.255541, G loss: 10.542913, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.562958, G loss: 15.042947, D accuracy: 92.0%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5496, G loss: 7.0315\n",
      "[372/8000] D loss: 0.2140, G loss: 13.2603\n",
      "[732/8000] D loss: 0.2477, G loss: 12.1548\n",
      "[1092/8000] D loss: 0.1284, G loss: 11.1250\n",
      "[1452/8000] D loss: 0.2834, G loss: 12.9089\n",
      "[1812/8000] D loss: 0.3883, G loss: 9.0766\n",
      "[2172/8000] D loss: 0.0312, G loss: 13.4235\n",
      "[2532/8000] D loss: 1.0751, G loss: 8.2476\n",
      "[2892/8000] D loss: 0.4529, G loss: 9.4077\n",
      "[3252/8000] D loss: 0.1116, G loss: 9.6807\n",
      "[3612/8000] D loss: 0.0293, G loss: 12.6029\n",
      "[3972/8000] D loss: 0.3119, G loss: 7.0735\n",
      "[4332/8000] D loss: 0.3386, G loss: 7.2202\n",
      "[4692/8000] D loss: 0.2396, G loss: 12.5604\n",
      "[5052/8000] D loss: 0.2570, G loss: 13.0366\n",
      "[5412/8000] D loss: 0.1917, G loss: 10.1632\n",
      "[5772/8000] D loss: 0.6035, G loss: 10.0508\n",
      "[6132/8000] D loss: 0.2420, G loss: 9.5019\n",
      "[6492/8000] D loss: 0.3663, G loss: 10.3613\n",
      "[6852/8000] D loss: 0.2969, G loss: 11.7187\n",
      "[7212/8000] D loss: 0.5106, G loss: 8.3168\n",
      "[7572/8000] D loss: 0.3278, G loss: 10.7140\n",
      "[7932/8000] D loss: 0.3562, G loss: 9.6334\n",
      "train error: \n",
      " D loss: 0.254576, G loss: 10.586553, D accuracy: 92.6%, cell accuracy: 94.8%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592151, G loss: 14.843790, D accuracy: 91.7%, cell accuracy: 94.3%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3844, G loss: 10.7727\n",
      "[372/8000] D loss: 0.0546, G loss: 14.4782\n",
      "[732/8000] D loss: 0.5821, G loss: 12.2396\n",
      "[1092/8000] D loss: 0.3718, G loss: 8.0178\n",
      "[1452/8000] D loss: 0.0041, G loss: 11.7996\n",
      "[1812/8000] D loss: 0.1968, G loss: 9.1358\n",
      "[2172/8000] D loss: 0.5141, G loss: 11.7683\n",
      "[2532/8000] D loss: 0.1207, G loss: 7.5748\n",
      "[2892/8000] D loss: 0.3733, G loss: 9.5796\n",
      "[3252/8000] D loss: 0.2963, G loss: 10.1745\n",
      "[3612/8000] D loss: 0.1333, G loss: 11.0206\n",
      "[3972/8000] D loss: 0.0105, G loss: 12.5915\n",
      "[4332/8000] D loss: 0.0832, G loss: 9.9285\n",
      "[4692/8000] D loss: 0.0078, G loss: 13.0691\n",
      "[5052/8000] D loss: 0.4647, G loss: 10.7848\n",
      "[5412/8000] D loss: 0.2282, G loss: 13.9730\n",
      "[5772/8000] D loss: 0.3648, G loss: 8.0858\n",
      "[6132/8000] D loss: 0.5156, G loss: 11.2149\n",
      "[6492/8000] D loss: 0.3840, G loss: 9.9597\n",
      "[6852/8000] D loss: 0.2265, G loss: 10.5290\n",
      "[7212/8000] D loss: 0.5715, G loss: 6.0945\n",
      "[7572/8000] D loss: 0.0040, G loss: 15.0815\n",
      "[7932/8000] D loss: 0.2654, G loss: 13.2239\n",
      "train error: \n",
      " D loss: 0.270997, G loss: 9.991742, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.513090, G loss: 14.086446, D accuracy: 93.0%, cell accuracy: 94.3%, board accuracy: 5.1% \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4017, G loss: 5.4842\n",
      "[372/8000] D loss: 0.4437, G loss: 9.9181\n",
      "[732/8000] D loss: 0.3814, G loss: 11.0489\n",
      "[1092/8000] D loss: 0.2333, G loss: 9.6017\n",
      "[1452/8000] D loss: 0.4776, G loss: 9.5401\n",
      "[1812/8000] D loss: 0.7706, G loss: 10.6623\n",
      "[2172/8000] D loss: 0.2786, G loss: 8.7981\n",
      "[2532/8000] D loss: 0.7509, G loss: 6.1252\n",
      "[2892/8000] D loss: 0.1859, G loss: 12.3850\n",
      "[3252/8000] D loss: 0.3618, G loss: 8.4385\n",
      "[3612/8000] D loss: 0.2411, G loss: 10.0863\n",
      "[3972/8000] D loss: 0.3645, G loss: 8.9994\n",
      "[4332/8000] D loss: 0.3685, G loss: 10.5649\n",
      "[4692/8000] D loss: 0.1595, G loss: 10.6762\n",
      "[5052/8000] D loss: 0.5408, G loss: 5.6362\n",
      "[5412/8000] D loss: 0.0091, G loss: 15.2140\n",
      "[5772/8000] D loss: 0.2489, G loss: 10.5004\n",
      "[6132/8000] D loss: 0.1926, G loss: 10.0823\n",
      "[6492/8000] D loss: 0.3225, G loss: 7.5348\n",
      "[6852/8000] D loss: 0.4494, G loss: 8.8826\n",
      "[7212/8000] D loss: 0.0068, G loss: 11.7648\n",
      "[7572/8000] D loss: 0.2470, G loss: 11.6864\n",
      "[7932/8000] D loss: 0.2472, G loss: 13.2034\n",
      "train error: \n",
      " D loss: 0.264522, G loss: 13.143517, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.705755, G loss: 17.759527, D accuracy: 91.0%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1299, G loss: 15.7980\n",
      "[372/8000] D loss: 0.1240, G loss: 12.8868\n",
      "[732/8000] D loss: 0.2612, G loss: 8.8790\n",
      "[1092/8000] D loss: 0.0116, G loss: 13.4848\n",
      "[1452/8000] D loss: 0.2292, G loss: 8.6034\n",
      "[1812/8000] D loss: 0.0862, G loss: 10.3779\n",
      "[2172/8000] D loss: 0.2083, G loss: 13.0572\n",
      "[2532/8000] D loss: 0.2238, G loss: 7.1987\n",
      "[2892/8000] D loss: 0.2133, G loss: 11.7115\n",
      "[3252/8000] D loss: 0.3877, G loss: 9.7098\n",
      "[3612/8000] D loss: 0.1729, G loss: 18.6994\n",
      "[3972/8000] D loss: 0.3845, G loss: 11.5843\n",
      "[4332/8000] D loss: 0.2225, G loss: 9.2713\n",
      "[4692/8000] D loss: 0.0192, G loss: 15.7350\n",
      "[5052/8000] D loss: 0.2448, G loss: 11.5789\n",
      "[5412/8000] D loss: 0.0025, G loss: 16.8198\n",
      "[5772/8000] D loss: 0.1286, G loss: 15.6822\n",
      "[6132/8000] D loss: 0.2616, G loss: 10.8604\n",
      "[6492/8000] D loss: 0.3623, G loss: 9.3164\n",
      "[6852/8000] D loss: 0.2581, G loss: 11.4292\n",
      "[7212/8000] D loss: 0.0729, G loss: 14.4086\n",
      "[7572/8000] D loss: 0.3616, G loss: 10.1982\n",
      "[7932/8000] D loss: 0.1624, G loss: 8.9158\n",
      "train error: \n",
      " D loss: 0.272572, G loss: 11.281652, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.701572, G loss: 15.502291, D accuracy: 90.4%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "[12/8000] D loss: 1.0443, G loss: 7.4809\n",
      "[372/8000] D loss: 0.0070, G loss: 9.9793\n",
      "[732/8000] D loss: 0.1438, G loss: 11.9178\n",
      "[1092/8000] D loss: 0.5907, G loss: 7.1151\n",
      "[1452/8000] D loss: 0.2606, G loss: 10.0823\n",
      "[1812/8000] D loss: 0.2328, G loss: 9.8750\n",
      "[2172/8000] D loss: 0.1169, G loss: 14.1578\n",
      "[2532/8000] D loss: 0.0533, G loss: 13.2174\n",
      "[2892/8000] D loss: 0.2600, G loss: 13.3103\n",
      "[3252/8000] D loss: 0.1160, G loss: 12.9879\n",
      "[3612/8000] D loss: 0.2377, G loss: 10.4735\n",
      "[3972/8000] D loss: 0.2933, G loss: 12.6340\n",
      "[4332/8000] D loss: 0.2943, G loss: 13.7267\n",
      "[4692/8000] D loss: 0.4662, G loss: 6.6252\n",
      "[5052/8000] D loss: 0.2430, G loss: 11.6744\n",
      "[5412/8000] D loss: 0.2974, G loss: 11.8756\n",
      "[5772/8000] D loss: 0.3657, G loss: 5.5943\n",
      "[6132/8000] D loss: 0.2331, G loss: 12.3303\n",
      "[6492/8000] D loss: 0.0014, G loss: 14.2689\n",
      "[6852/8000] D loss: 0.2220, G loss: 11.7869\n",
      "[7212/8000] D loss: 0.6350, G loss: 9.5720\n",
      "[7572/8000] D loss: 0.4795, G loss: 8.3663\n",
      "[7932/8000] D loss: 0.4824, G loss: 7.7227\n",
      "train error: \n",
      " D loss: 0.269233, G loss: 9.496638, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 14.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.496552, G loss: 13.552520, D accuracy: 92.2%, cell accuracy: 94.3%, board accuracy: 5.4% \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5050, G loss: 7.6692\n",
      "[372/8000] D loss: 0.0027, G loss: 14.3376\n",
      "[732/8000] D loss: 0.1333, G loss: 10.5994\n",
      "[1092/8000] D loss: 0.2415, G loss: 9.4196\n",
      "[1452/8000] D loss: 0.1832, G loss: 12.6255\n",
      "[1812/8000] D loss: 0.1653, G loss: 10.9885\n",
      "[2172/8000] D loss: 0.1290, G loss: 10.4092\n",
      "[2532/8000] D loss: 0.3544, G loss: 10.4148\n",
      "[2892/8000] D loss: 0.3252, G loss: 7.1881\n",
      "[3252/8000] D loss: 0.5577, G loss: 9.9321\n",
      "[3612/8000] D loss: 0.2364, G loss: 14.5819\n",
      "[3972/8000] D loss: 0.5809, G loss: 6.4475\n",
      "[4332/8000] D loss: 0.3476, G loss: 10.4814\n",
      "[4692/8000] D loss: 0.2972, G loss: 11.2669\n",
      "[5052/8000] D loss: 0.1491, G loss: 15.1052\n",
      "[5412/8000] D loss: 0.1226, G loss: 7.1688\n",
      "[5772/8000] D loss: 0.1196, G loss: 12.9871\n",
      "[6132/8000] D loss: 0.0217, G loss: 13.3137\n",
      "[6492/8000] D loss: 0.3479, G loss: 8.3797\n",
      "[6852/8000] D loss: 0.1153, G loss: 16.1342\n",
      "[7212/8000] D loss: 0.1542, G loss: 9.3173\n",
      "[7572/8000] D loss: 0.1624, G loss: 10.3691\n",
      "[7932/8000] D loss: 0.0605, G loss: 6.6698\n",
      "train error: \n",
      " D loss: 0.276851, G loss: 10.348125, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.633397, G loss: 14.362962, D accuracy: 91.7%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1312, G loss: 11.6379\n",
      "[372/8000] D loss: 0.2745, G loss: 9.0790\n",
      "[732/8000] D loss: 0.2266, G loss: 11.8502\n",
      "[1092/8000] D loss: 0.1326, G loss: 10.0821\n",
      "[1452/8000] D loss: 0.1161, G loss: 16.9378\n",
      "[1812/8000] D loss: 0.1519, G loss: 11.7563\n",
      "[2172/8000] D loss: 0.4613, G loss: 9.3522\n",
      "[2532/8000] D loss: 0.2186, G loss: 11.2052\n",
      "[2892/8000] D loss: 0.5847, G loss: 10.6796\n",
      "[3252/8000] D loss: 0.2716, G loss: 10.2705\n",
      "[3612/8000] D loss: 0.0310, G loss: 11.7229\n",
      "[3972/8000] D loss: 0.5045, G loss: 5.9792\n",
      "[4332/8000] D loss: 0.2423, G loss: 14.4247\n",
      "[4692/8000] D loss: 0.1579, G loss: 14.8283\n",
      "[5052/8000] D loss: 0.1278, G loss: 13.2122\n",
      "[5412/8000] D loss: 0.2491, G loss: 10.9356\n",
      "[5772/8000] D loss: 0.0104, G loss: 16.1295\n",
      "[6132/8000] D loss: 0.2485, G loss: 9.7366\n",
      "[6492/8000] D loss: 0.3955, G loss: 7.8621\n",
      "[6852/8000] D loss: 0.2374, G loss: 12.7111\n",
      "[7212/8000] D loss: 0.2988, G loss: 11.0241\n",
      "[7572/8000] D loss: 0.2645, G loss: 12.6471\n",
      "[7932/8000] D loss: 0.8200, G loss: 8.9206\n",
      "train error: \n",
      " D loss: 0.264132, G loss: 9.269938, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.508542, G loss: 13.392702, D accuracy: 92.7%, cell accuracy: 94.3%, board accuracy: 5.6% \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0670, G loss: 11.3924\n",
      "[372/8000] D loss: 0.1196, G loss: 13.3947\n",
      "[732/8000] D loss: 0.2882, G loss: 12.8104\n",
      "[1092/8000] D loss: 0.1463, G loss: 13.9770\n",
      "[1452/8000] D loss: 0.1594, G loss: 9.3479\n",
      "[1812/8000] D loss: 0.5468, G loss: 9.1650\n",
      "[2172/8000] D loss: 0.2605, G loss: 13.5438\n",
      "[2532/8000] D loss: 0.2506, G loss: 10.3972\n",
      "[2892/8000] D loss: 0.4399, G loss: 9.3060\n",
      "[3252/8000] D loss: 0.3002, G loss: 7.4217\n",
      "[3612/8000] D loss: 0.4048, G loss: 6.5316\n",
      "[3972/8000] D loss: 0.0296, G loss: 11.8181\n",
      "[4332/8000] D loss: 0.4277, G loss: 9.2405\n",
      "[4692/8000] D loss: 0.4195, G loss: 10.0138\n",
      "[5052/8000] D loss: 0.1448, G loss: 10.0520\n",
      "[5412/8000] D loss: 0.2614, G loss: 12.6809\n",
      "[5772/8000] D loss: 0.0457, G loss: 11.3718\n",
      "[6132/8000] D loss: 0.2413, G loss: 8.9614\n",
      "[6492/8000] D loss: 0.3217, G loss: 12.5447\n",
      "[6852/8000] D loss: 0.3286, G loss: 7.0999\n",
      "[7212/8000] D loss: 0.2470, G loss: 10.3636\n",
      "[7572/8000] D loss: 0.2160, G loss: 9.6307\n",
      "[7932/8000] D loss: 0.1384, G loss: 13.7861\n",
      "train error: \n",
      " D loss: 0.263738, G loss: 8.994747, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.476545, G loss: 12.955265, D accuracy: 92.7%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2464, G loss: 6.7510\n",
      "[372/8000] D loss: 0.2539, G loss: 11.6947\n",
      "[732/8000] D loss: 0.1588, G loss: 11.8867\n",
      "[1092/8000] D loss: 0.1363, G loss: 12.8070\n",
      "[1452/8000] D loss: 0.1399, G loss: 14.2131\n",
      "[1812/8000] D loss: 0.1285, G loss: 10.0921\n",
      "[2172/8000] D loss: 0.3417, G loss: 9.8117\n",
      "[2532/8000] D loss: 0.6263, G loss: 9.6644\n",
      "[2892/8000] D loss: 0.2062, G loss: 12.8090\n",
      "[3252/8000] D loss: 0.3776, G loss: 10.9061\n",
      "[3612/8000] D loss: 0.1306, G loss: 12.4825\n",
      "[3972/8000] D loss: 0.4409, G loss: 8.5571\n",
      "[4332/8000] D loss: 0.4618, G loss: 9.3396\n",
      "[4692/8000] D loss: 0.3713, G loss: 10.5616\n",
      "[5052/8000] D loss: 0.3573, G loss: 8.3882\n",
      "[5412/8000] D loss: 0.4764, G loss: 10.4622\n",
      "[5772/8000] D loss: 0.4358, G loss: 8.8680\n",
      "[6132/8000] D loss: 0.3641, G loss: 14.2634\n",
      "[6492/8000] D loss: 0.2825, G loss: 8.0709\n",
      "[6852/8000] D loss: 0.0271, G loss: 12.1667\n",
      "[7212/8000] D loss: 0.1578, G loss: 13.1483\n",
      "[7572/8000] D loss: 0.4053, G loss: 7.7830\n",
      "[7932/8000] D loss: 0.5727, G loss: 7.1117\n",
      "train error: \n",
      " D loss: 0.246532, G loss: 10.312135, D accuracy: 92.6%, cell accuracy: 94.8%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.561573, G loss: 14.477500, D accuracy: 91.9%, cell accuracy: 94.3%, board accuracy: 5.3% \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3629, G loss: 9.9283\n",
      "[372/8000] D loss: 0.2294, G loss: 11.5064\n",
      "[732/8000] D loss: 0.1344, G loss: 12.2900\n",
      "[1092/8000] D loss: 0.2846, G loss: 10.8203\n",
      "[1452/8000] D loss: 0.1840, G loss: 13.4343\n",
      "[1812/8000] D loss: 0.0209, G loss: 13.9005\n",
      "[2172/8000] D loss: 0.0672, G loss: 13.0603\n",
      "[2532/8000] D loss: 0.1637, G loss: 9.4433\n",
      "[2892/8000] D loss: 0.2305, G loss: 8.5884\n",
      "[3252/8000] D loss: 0.4077, G loss: 7.6105\n",
      "[3612/8000] D loss: 0.1280, G loss: 10.6270\n",
      "[3972/8000] D loss: 0.0024, G loss: 15.1301\n",
      "[4332/8000] D loss: 0.1026, G loss: 12.4920\n",
      "[4692/8000] D loss: 0.3635, G loss: 8.8730\n",
      "[5052/8000] D loss: 0.1363, G loss: 11.3144\n",
      "[5412/8000] D loss: 0.3556, G loss: 9.3958\n",
      "[5772/8000] D loss: 0.3654, G loss: 11.6841\n",
      "[6132/8000] D loss: 0.1978, G loss: 11.3118\n",
      "[6492/8000] D loss: 0.2386, G loss: 13.1363\n",
      "[6852/8000] D loss: 0.3719, G loss: 13.4427\n",
      "[7212/8000] D loss: 0.2435, G loss: 8.5770\n",
      "[7572/8000] D loss: 0.0201, G loss: 12.3836\n",
      "[7932/8000] D loss: 0.5075, G loss: 8.3058\n",
      "train error: \n",
      " D loss: 0.277159, G loss: 13.141755, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.773088, G loss: 17.653533, D accuracy: 90.9%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1666, G loss: 12.1549\n",
      "[372/8000] D loss: 0.0051, G loss: 12.5611\n",
      "[732/8000] D loss: 0.2626, G loss: 12.6457\n",
      "[1092/8000] D loss: 0.4204, G loss: 9.2707\n",
      "[1452/8000] D loss: 0.1056, G loss: 13.0412\n",
      "[1812/8000] D loss: 0.0268, G loss: 11.7200\n",
      "[2172/8000] D loss: 0.0048, G loss: 15.2913\n",
      "[2532/8000] D loss: 0.2213, G loss: 14.2287\n",
      "[2892/8000] D loss: 0.2762, G loss: 11.8697\n",
      "[3252/8000] D loss: 0.2763, G loss: 10.6140\n",
      "[3612/8000] D loss: 0.5022, G loss: 6.8423\n",
      "[3972/8000] D loss: 0.2598, G loss: 13.7842\n",
      "[4332/8000] D loss: 0.0125, G loss: 13.8592\n",
      "[4692/8000] D loss: 0.2716, G loss: 12.3819\n",
      "[5052/8000] D loss: 0.4295, G loss: 8.9029\n",
      "[5412/8000] D loss: 0.5018, G loss: 9.6198\n",
      "[5772/8000] D loss: 0.2753, G loss: 11.2721\n",
      "[6132/8000] D loss: 0.1515, G loss: 7.8312\n",
      "[6492/8000] D loss: 0.1249, G loss: 9.5990\n",
      "[6852/8000] D loss: 0.5851, G loss: 9.2738\n",
      "[7212/8000] D loss: 0.2884, G loss: 11.5005\n",
      "[7572/8000] D loss: 0.3050, G loss: 10.3404\n",
      "[7932/8000] D loss: 0.1328, G loss: 13.8810\n",
      "train error: \n",
      " D loss: 0.249703, G loss: 10.812476, D accuracy: 92.5%, cell accuracy: 94.8%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.557069, G loss: 15.070579, D accuracy: 92.6%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3698, G loss: 8.7522\n",
      "[372/8000] D loss: 0.3542, G loss: 10.6760\n",
      "[732/8000] D loss: 0.0064, G loss: 12.3788\n",
      "[1092/8000] D loss: 0.7781, G loss: 6.3874\n",
      "[1452/8000] D loss: 0.1492, G loss: 11.2751\n",
      "[1812/8000] D loss: 0.2549, G loss: 10.6148\n",
      "[2172/8000] D loss: 0.1205, G loss: 10.2367\n",
      "[2532/8000] D loss: 0.1424, G loss: 11.5133\n",
      "[2892/8000] D loss: 0.2513, G loss: 13.5605\n",
      "[3252/8000] D loss: 0.5883, G loss: 6.1607\n",
      "[3612/8000] D loss: 0.3607, G loss: 7.8865\n",
      "[3972/8000] D loss: 0.0093, G loss: 11.3536\n",
      "[4332/8000] D loss: 0.1242, G loss: 11.9080\n",
      "[4692/8000] D loss: 0.1768, G loss: 7.4200\n",
      "[5052/8000] D loss: 0.3098, G loss: 9.5228\n",
      "[5412/8000] D loss: 0.1270, G loss: 13.1259\n",
      "[5772/8000] D loss: 0.3381, G loss: 9.5368\n",
      "[6132/8000] D loss: 0.1260, G loss: 15.5849\n",
      "[6492/8000] D loss: 0.1367, G loss: 13.6057\n",
      "[6852/8000] D loss: 0.3469, G loss: 11.9822\n",
      "[7212/8000] D loss: 0.0975, G loss: 8.8385\n",
      "[7572/8000] D loss: 0.1180, G loss: 12.6326\n",
      "[7932/8000] D loss: 0.3346, G loss: 9.0064\n",
      "train error: \n",
      " D loss: 0.253879, G loss: 11.403567, D accuracy: 92.3%, cell accuracy: 94.7%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.649888, G loss: 15.714891, D accuracy: 91.5%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2534, G loss: 10.7863\n",
      "[372/8000] D loss: 0.2368, G loss: 9.4275\n",
      "[732/8000] D loss: 0.2339, G loss: 9.8825\n",
      "[1092/8000] D loss: 0.1393, G loss: 14.5447\n",
      "[1452/8000] D loss: 0.1099, G loss: 14.6722\n",
      "[1812/8000] D loss: 0.3792, G loss: 9.1377\n",
      "[2172/8000] D loss: 0.0067, G loss: 16.4358\n",
      "[2532/8000] D loss: 0.2589, G loss: 10.5229\n",
      "[2892/8000] D loss: 0.6096, G loss: 7.6436\n",
      "[3252/8000] D loss: 0.1214, G loss: 12.8984\n",
      "[3612/8000] D loss: 0.1853, G loss: 10.1352\n",
      "[3972/8000] D loss: 0.3147, G loss: 11.9394\n",
      "[4332/8000] D loss: 0.1265, G loss: 10.8104\n",
      "[4692/8000] D loss: 0.1404, G loss: 10.4360\n",
      "[5052/8000] D loss: 0.2578, G loss: 12.7072\n",
      "[5412/8000] D loss: 0.3868, G loss: 8.1117\n",
      "[5772/8000] D loss: 0.4201, G loss: 11.5876\n",
      "[6132/8000] D loss: 0.0162, G loss: 12.3253\n",
      "[6492/8000] D loss: 0.1520, G loss: 10.5290\n",
      "[6852/8000] D loss: 0.1235, G loss: 12.6050\n",
      "[7212/8000] D loss: 0.0558, G loss: 13.5792\n",
      "[7572/8000] D loss: 0.1312, G loss: 12.8921\n",
      "[7932/8000] D loss: 0.0152, G loss: 12.4465\n",
      "train error: \n",
      " D loss: 0.267851, G loss: 8.973110, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 14.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.520025, G loss: 12.972978, D accuracy: 92.5%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2706, G loss: 8.3442\n",
      "[372/8000] D loss: 0.2402, G loss: 17.2181\n",
      "[732/8000] D loss: 0.1184, G loss: 11.3985\n",
      "[1092/8000] D loss: 0.2293, G loss: 9.3358\n",
      "[1452/8000] D loss: 0.4540, G loss: 8.5988\n",
      "[1812/8000] D loss: 0.1421, G loss: 12.6146\n",
      "[2172/8000] D loss: 0.3703, G loss: 10.9136\n",
      "[2532/8000] D loss: 0.3517, G loss: 8.2011\n",
      "[2892/8000] D loss: 0.2130, G loss: 15.9897\n",
      "[3252/8000] D loss: 0.1560, G loss: 10.9761\n",
      "[3612/8000] D loss: 0.3048, G loss: 7.7833\n",
      "[3972/8000] D loss: 0.4226, G loss: 9.8808\n",
      "[4332/8000] D loss: 0.1312, G loss: 11.0991\n",
      "[4692/8000] D loss: 0.3695, G loss: 8.0968\n",
      "[5052/8000] D loss: 0.0442, G loss: 10.8628\n",
      "[5412/8000] D loss: 0.2316, G loss: 10.4259\n",
      "[5772/8000] D loss: 0.1733, G loss: 10.8938\n",
      "[6132/8000] D loss: 0.4955, G loss: 9.3844\n",
      "[6492/8000] D loss: 0.1358, G loss: 10.1086\n",
      "[6852/8000] D loss: 0.2815, G loss: 10.1663\n",
      "[7212/8000] D loss: 0.2601, G loss: 10.0938\n",
      "[7572/8000] D loss: 0.2912, G loss: 11.5489\n",
      "[7932/8000] D loss: 0.2085, G loss: 8.9301\n",
      "train error: \n",
      " D loss: 0.262664, G loss: 9.219432, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.506084, G loss: 13.375164, D accuracy: 93.0%, cell accuracy: 94.3%, board accuracy: 5.3% \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0083, G loss: 8.5506\n",
      "[372/8000] D loss: 0.2474, G loss: 12.3602\n",
      "[732/8000] D loss: 0.4287, G loss: 10.2986\n",
      "[1092/8000] D loss: 0.0389, G loss: 10.9167\n",
      "[1452/8000] D loss: 0.1815, G loss: 8.3910\n",
      "[1812/8000] D loss: 0.4333, G loss: 9.8660\n",
      "[2172/8000] D loss: 0.3707, G loss: 9.5835\n",
      "[2532/8000] D loss: 0.3532, G loss: 11.5112\n",
      "[2892/8000] D loss: 0.2451, G loss: 10.1944\n",
      "[3252/8000] D loss: 0.3734, G loss: 10.3814\n",
      "[3612/8000] D loss: 0.4128, G loss: 14.3351\n",
      "[3972/8000] D loss: 0.3539, G loss: 12.8122\n",
      "[4332/8000] D loss: 0.0376, G loss: 10.4743\n",
      "[4692/8000] D loss: 0.2430, G loss: 12.6072\n",
      "[5052/8000] D loss: 0.3306, G loss: 8.8627\n",
      "[5412/8000] D loss: 0.1163, G loss: 10.4730\n",
      "[5772/8000] D loss: 0.5489, G loss: 7.3065\n",
      "[6132/8000] D loss: 0.7239, G loss: 6.7708\n",
      "[6492/8000] D loss: 0.2332, G loss: 9.2756\n",
      "[6852/8000] D loss: 0.3585, G loss: 7.5018\n",
      "[7212/8000] D loss: 0.1400, G loss: 11.0872\n",
      "[7572/8000] D loss: 0.3156, G loss: 9.8870\n",
      "[7932/8000] D loss: 0.2803, G loss: 9.4410\n",
      "train error: \n",
      " D loss: 0.256354, G loss: 10.869886, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.596961, G loss: 15.212681, D accuracy: 91.8%, cell accuracy: 94.3%, board accuracy: 5.6% \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1765, G loss: 16.4550\n",
      "[372/8000] D loss: 0.1252, G loss: 14.4817\n",
      "[732/8000] D loss: 0.3170, G loss: 12.7095\n",
      "[1092/8000] D loss: 0.5017, G loss: 6.6957\n",
      "[1452/8000] D loss: 0.0970, G loss: 11.1826\n",
      "[1812/8000] D loss: 0.2652, G loss: 12.5898\n",
      "[2172/8000] D loss: 0.1152, G loss: 11.2379\n",
      "[2532/8000] D loss: 0.3181, G loss: 9.2238\n",
      "[2892/8000] D loss: 0.1190, G loss: 13.4702\n",
      "[3252/8000] D loss: 0.4636, G loss: 10.1945\n",
      "[3612/8000] D loss: 0.4868, G loss: 10.4319\n",
      "[3972/8000] D loss: 0.4369, G loss: 10.3188\n",
      "[4332/8000] D loss: 0.3582, G loss: 10.4049\n",
      "[4692/8000] D loss: 0.1291, G loss: 11.5604\n",
      "[5052/8000] D loss: 0.5339, G loss: 9.1389\n",
      "[5412/8000] D loss: 0.0361, G loss: 12.7669\n",
      "[5772/8000] D loss: 0.1622, G loss: 9.4495\n",
      "[6132/8000] D loss: 0.2348, G loss: 9.8275\n",
      "[6492/8000] D loss: 0.3520, G loss: 10.6807\n",
      "[6852/8000] D loss: 0.2597, G loss: 11.4879\n",
      "[7212/8000] D loss: 0.8393, G loss: 4.8375\n",
      "[7572/8000] D loss: 0.3630, G loss: 10.8165\n",
      "[7932/8000] D loss: 0.0264, G loss: 10.8813\n",
      "train error: \n",
      " D loss: 0.255464, G loss: 11.092210, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.590701, G loss: 15.560628, D accuracy: 91.8%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2375, G loss: 12.5732\n",
      "[372/8000] D loss: 0.2307, G loss: 9.2422\n",
      "[732/8000] D loss: 0.0134, G loss: 13.6492\n",
      "[1092/8000] D loss: 0.0860, G loss: 11.2912\n",
      "[1452/8000] D loss: 0.4020, G loss: 8.9033\n",
      "[1812/8000] D loss: 0.2471, G loss: 13.0316\n",
      "[2172/8000] D loss: 0.2352, G loss: 9.8126\n",
      "[2532/8000] D loss: 0.3494, G loss: 7.7727\n",
      "[2892/8000] D loss: 0.1515, G loss: 11.4030\n",
      "[3252/8000] D loss: 0.2443, G loss: 12.8168\n",
      "[3612/8000] D loss: 0.0255, G loss: 15.8436\n",
      "[3972/8000] D loss: 0.5112, G loss: 9.8754\n",
      "[4332/8000] D loss: 0.1219, G loss: 11.3563\n",
      "[4692/8000] D loss: 0.2853, G loss: 12.3089\n",
      "[5052/8000] D loss: 0.1603, G loss: 11.8221\n",
      "[5412/8000] D loss: 0.2196, G loss: 9.1181\n",
      "[5772/8000] D loss: 0.1574, G loss: 9.8069\n",
      "[6132/8000] D loss: 0.2511, G loss: 16.9978\n",
      "[6492/8000] D loss: 0.3628, G loss: 9.0211\n",
      "[6852/8000] D loss: 0.2342, G loss: 7.4471\n",
      "[7212/8000] D loss: 0.2239, G loss: 14.6779\n",
      "[7572/8000] D loss: 0.2080, G loss: 10.3809\n",
      "[7932/8000] D loss: 0.5477, G loss: 7.7916\n",
      "train error: \n",
      " D loss: 0.250620, G loss: 10.646759, D accuracy: 92.6%, cell accuracy: 94.8%, board accuracy: 14.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.586554, G loss: 14.933282, D accuracy: 92.1%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1448, G loss: 12.7256\n",
      "[372/8000] D loss: 0.0957, G loss: 13.3980\n",
      "[732/8000] D loss: 0.2848, G loss: 10.4803\n",
      "[1092/8000] D loss: 0.2408, G loss: 15.4508\n",
      "[1452/8000] D loss: 0.1495, G loss: 16.4303\n",
      "[1812/8000] D loss: 0.2332, G loss: 11.7808\n",
      "[2172/8000] D loss: 0.2450, G loss: 11.7238\n",
      "[2532/8000] D loss: 0.4407, G loss: 8.4080\n",
      "[2892/8000] D loss: 0.1334, G loss: 13.4051\n",
      "[3252/8000] D loss: 0.2207, G loss: 11.9823\n",
      "[3612/8000] D loss: 0.3136, G loss: 9.3435\n",
      "[3972/8000] D loss: 0.2159, G loss: 12.1453\n",
      "[4332/8000] D loss: 0.2795, G loss: 10.7591\n",
      "[4692/8000] D loss: 0.3596, G loss: 11.1178\n",
      "[5052/8000] D loss: 0.3006, G loss: 7.9298\n",
      "[5412/8000] D loss: 0.2321, G loss: 10.8217\n",
      "[5772/8000] D loss: 0.2958, G loss: 8.0440\n",
      "[6132/8000] D loss: 0.7032, G loss: 7.0327\n",
      "[6492/8000] D loss: 0.1288, G loss: 11.8389\n",
      "[6852/8000] D loss: 0.4649, G loss: 9.2417\n",
      "[7212/8000] D loss: 0.4034, G loss: 9.2814\n",
      "[7572/8000] D loss: 0.2571, G loss: 7.6335\n",
      "[7932/8000] D loss: 0.5966, G loss: 8.7831\n",
      "train error: \n",
      " D loss: 0.278390, G loss: 11.383501, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.597673, G loss: 16.051196, D accuracy: 92.9%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2556, G loss: 6.8917\n",
      "[372/8000] D loss: 0.4928, G loss: 9.6578\n",
      "[732/8000] D loss: 0.2646, G loss: 9.2507\n",
      "[1092/8000] D loss: 0.1965, G loss: 11.3378\n",
      "[1452/8000] D loss: 0.1167, G loss: 14.2209\n",
      "[1812/8000] D loss: 0.1173, G loss: 15.8647\n",
      "[2172/8000] D loss: 0.2405, G loss: 12.9778\n",
      "[2532/8000] D loss: 0.2473, G loss: 10.2616\n",
      "[2892/8000] D loss: 0.1767, G loss: 8.3603\n",
      "[3252/8000] D loss: 0.2401, G loss: 10.5980\n",
      "[3612/8000] D loss: 0.4927, G loss: 7.2055\n",
      "[3972/8000] D loss: 0.4600, G loss: 11.4784\n",
      "[4332/8000] D loss: 0.2208, G loss: 8.6630\n",
      "[4692/8000] D loss: 0.1754, G loss: 9.9605\n",
      "[5052/8000] D loss: 0.1735, G loss: 9.9912\n",
      "[5412/8000] D loss: 0.3440, G loss: 9.3111\n",
      "[5772/8000] D loss: 0.2616, G loss: 9.4283\n",
      "[6132/8000] D loss: 0.0648, G loss: 11.5993\n",
      "[6492/8000] D loss: 0.1209, G loss: 9.7703\n",
      "[6852/8000] D loss: 0.3783, G loss: 8.6297\n",
      "[7212/8000] D loss: 0.3937, G loss: 9.4379\n",
      "[7572/8000] D loss: 0.1389, G loss: 9.7038\n",
      "[7932/8000] D loss: 0.0166, G loss: 15.4601\n",
      "train error: \n",
      " D loss: 0.306426, G loss: 11.400041, D accuracy: 91.6%, cell accuracy: 94.8%, board accuracy: 14.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.716657, G loss: 15.494398, D accuracy: 90.3%, cell accuracy: 94.3%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4512, G loss: 9.4591\n",
      "[372/8000] D loss: 0.2930, G loss: 10.4178\n",
      "[732/8000] D loss: 0.3945, G loss: 9.8986\n",
      "[1092/8000] D loss: 0.1499, G loss: 9.7482\n",
      "[1452/8000] D loss: 0.0169, G loss: 12.0816\n",
      "[1812/8000] D loss: 0.2465, G loss: 19.3219\n",
      "[2172/8000] D loss: 0.1108, G loss: 12.1728\n",
      "[2532/8000] D loss: 0.0173, G loss: 13.6286\n",
      "[2892/8000] D loss: 0.0530, G loss: 8.8524\n",
      "[3252/8000] D loss: 0.4659, G loss: 7.6911\n",
      "[3612/8000] D loss: 0.1123, G loss: 8.1325\n",
      "[3972/8000] D loss: 0.0701, G loss: 10.1493\n",
      "[4332/8000] D loss: 0.5352, G loss: 9.0666\n",
      "[4692/8000] D loss: 0.2546, G loss: 10.7954\n",
      "[5052/8000] D loss: 0.2438, G loss: 6.0086\n",
      "[5412/8000] D loss: 0.1421, G loss: 10.7472\n",
      "[5772/8000] D loss: 0.3414, G loss: 10.2762\n",
      "[6132/8000] D loss: 0.0117, G loss: 11.2697\n",
      "[6492/8000] D loss: 0.1288, G loss: 12.2073\n",
      "[6852/8000] D loss: 0.1488, G loss: 15.2730\n",
      "[7212/8000] D loss: 0.1546, G loss: 9.0089\n",
      "[7572/8000] D loss: 0.4678, G loss: 8.5786\n",
      "[7932/8000] D loss: 0.5128, G loss: 8.6883\n",
      "train error: \n",
      " D loss: 0.262631, G loss: 9.833604, D accuracy: 92.5%, cell accuracy: 94.8%, board accuracy: 13.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.535335, G loss: 14.185812, D accuracy: 92.6%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1548, G loss: 11.3587\n",
      "[372/8000] D loss: 0.0065, G loss: 10.4592\n",
      "[732/8000] D loss: 0.1281, G loss: 11.2245\n",
      "[1092/8000] D loss: 0.3596, G loss: 7.7362\n",
      "[1452/8000] D loss: 0.4420, G loss: 7.6638\n",
      "[1812/8000] D loss: 0.0035, G loss: 12.4696\n",
      "[2172/8000] D loss: 0.0306, G loss: 10.1776\n",
      "[2532/8000] D loss: 0.4242, G loss: 10.0699\n",
      "[2892/8000] D loss: 0.2377, G loss: 9.0177\n",
      "[3252/8000] D loss: 0.3460, G loss: 12.4401\n",
      "[3612/8000] D loss: 0.2299, G loss: 10.9840\n",
      "[3972/8000] D loss: 0.2469, G loss: 13.7095\n",
      "[4332/8000] D loss: 0.1829, G loss: 11.4529\n",
      "[4692/8000] D loss: 0.0059, G loss: 9.1351\n",
      "[5052/8000] D loss: 0.1255, G loss: 12.4155\n",
      "[5412/8000] D loss: 0.0970, G loss: 9.0100\n",
      "[5772/8000] D loss: 0.1017, G loss: 9.9692\n",
      "[6132/8000] D loss: 0.1502, G loss: 10.1182\n",
      "[6492/8000] D loss: 0.4459, G loss: 7.2387\n",
      "[6852/8000] D loss: 0.5228, G loss: 8.6772\n",
      "[7212/8000] D loss: 0.0717, G loss: 11.7781\n",
      "[7572/8000] D loss: 0.3527, G loss: 10.3659\n",
      "[7932/8000] D loss: 0.0007, G loss: 13.2615\n",
      "train error: \n",
      " D loss: 0.258919, G loss: 10.403881, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 14.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.581971, G loss: 14.608941, D accuracy: 91.9%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2538, G loss: 11.9804\n",
      "[372/8000] D loss: 0.1815, G loss: 9.1384\n",
      "[732/8000] D loss: 0.1331, G loss: 9.9587\n",
      "[1092/8000] D loss: 0.2704, G loss: 11.9805\n",
      "[1452/8000] D loss: 0.1610, G loss: 12.5034\n",
      "[1812/8000] D loss: 0.2421, G loss: 7.8271\n",
      "[2172/8000] D loss: 0.4598, G loss: 10.1965\n",
      "[2532/8000] D loss: 0.0075, G loss: 13.3835\n",
      "[2892/8000] D loss: 0.1539, G loss: 12.2362\n",
      "[3252/8000] D loss: 0.2837, G loss: 10.1234\n",
      "[3612/8000] D loss: 0.2374, G loss: 9.4962\n",
      "[3972/8000] D loss: 0.1289, G loss: 14.6294\n",
      "[4332/8000] D loss: 0.4710, G loss: 7.8997\n",
      "[4692/8000] D loss: 0.1407, G loss: 12.2450\n",
      "[5052/8000] D loss: 0.2505, G loss: 8.4852\n",
      "[5412/8000] D loss: 0.2602, G loss: 11.4682\n",
      "[5772/8000] D loss: 0.2481, G loss: 13.2772\n",
      "[6132/8000] D loss: 0.5395, G loss: 6.8268\n",
      "[6492/8000] D loss: 0.1140, G loss: 13.2263\n",
      "[6852/8000] D loss: 0.4398, G loss: 7.0960\n",
      "[7212/8000] D loss: 0.2371, G loss: 10.1043\n",
      "[7572/8000] D loss: 0.7399, G loss: 7.1451\n",
      "[7932/8000] D loss: 0.3250, G loss: 7.2799\n",
      "train error: \n",
      " D loss: 0.253484, G loss: 10.216893, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.581971, G loss: 14.524755, D accuracy: 92.1%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1232, G loss: 13.4846\n",
      "[372/8000] D loss: 0.1365, G loss: 12.9654\n",
      "[732/8000] D loss: 0.0947, G loss: 14.5382\n",
      "[1092/8000] D loss: 0.3108, G loss: 14.6713\n",
      "[1452/8000] D loss: 0.3049, G loss: 11.2324\n",
      "[1812/8000] D loss: 0.3777, G loss: 10.5301\n",
      "[2172/8000] D loss: 0.2373, G loss: 11.6687\n",
      "[2532/8000] D loss: 0.2636, G loss: 8.0443\n",
      "[2892/8000] D loss: 0.1273, G loss: 11.9603\n",
      "[3252/8000] D loss: 0.4077, G loss: 9.7584\n",
      "[3612/8000] D loss: 0.2143, G loss: 12.1228\n",
      "[3972/8000] D loss: 0.3960, G loss: 12.8116\n",
      "[4332/8000] D loss: 0.2404, G loss: 11.6876\n",
      "[4692/8000] D loss: 0.1303, G loss: 15.1010\n",
      "[5052/8000] D loss: 0.4292, G loss: 9.9810\n",
      "[5412/8000] D loss: 0.1996, G loss: 14.1172\n",
      "[5772/8000] D loss: 0.2597, G loss: 7.3160\n",
      "[6132/8000] D loss: 0.4011, G loss: 9.0258\n",
      "[6492/8000] D loss: 0.2320, G loss: 10.0729\n",
      "[6852/8000] D loss: 0.0196, G loss: 10.9453\n",
      "[7212/8000] D loss: 0.1411, G loss: 10.0188\n",
      "[7572/8000] D loss: 0.2700, G loss: 13.8204\n",
      "[7932/8000] D loss: 0.1366, G loss: 8.7299\n",
      "train error: \n",
      " D loss: 0.259380, G loss: 10.730627, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.642191, G loss: 15.183395, D accuracy: 91.8%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4325, G loss: 10.7805\n",
      "[372/8000] D loss: 0.2390, G loss: 10.9695\n",
      "[732/8000] D loss: 0.3561, G loss: 8.7400\n",
      "[1092/8000] D loss: 0.4354, G loss: 9.4887\n",
      "[1452/8000] D loss: 0.4387, G loss: 6.8557\n",
      "[1812/8000] D loss: 0.1447, G loss: 8.4864\n",
      "[2172/8000] D loss: 0.3041, G loss: 11.0127\n",
      "[2532/8000] D loss: 0.0371, G loss: 12.9478\n",
      "[2892/8000] D loss: 0.1451, G loss: 11.6830\n",
      "[3252/8000] D loss: 0.5483, G loss: 8.9102\n",
      "[3612/8000] D loss: 0.3474, G loss: 10.8804\n",
      "[3972/8000] D loss: 0.4548, G loss: 8.2383\n",
      "[4332/8000] D loss: 0.3026, G loss: 9.0265\n",
      "[4692/8000] D loss: 0.3705, G loss: 11.5224\n",
      "[5052/8000] D loss: 0.3555, G loss: 9.4834\n",
      "[5412/8000] D loss: 0.3545, G loss: 11.9035\n",
      "[5772/8000] D loss: 0.3699, G loss: 8.2966\n",
      "[6132/8000] D loss: 0.2927, G loss: 11.2351\n",
      "[6492/8000] D loss: 0.0304, G loss: 13.4128\n",
      "[6852/8000] D loss: 0.0417, G loss: 12.3611\n",
      "[7212/8000] D loss: 0.5630, G loss: 11.7116\n",
      "[7572/8000] D loss: 0.1212, G loss: 9.3384\n",
      "[7932/8000] D loss: 0.2946, G loss: 11.9454\n",
      "train error: \n",
      " D loss: 0.258753, G loss: 11.027384, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.586341, G loss: 15.508400, D accuracy: 92.1%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1686, G loss: 12.2543\n",
      "[372/8000] D loss: 0.1192, G loss: 10.9082\n",
      "[732/8000] D loss: 0.1640, G loss: 11.1526\n",
      "[1092/8000] D loss: 0.2031, G loss: 14.7157\n",
      "[1452/8000] D loss: 0.2913, G loss: 9.4884\n",
      "[1812/8000] D loss: 0.2814, G loss: 11.3387\n",
      "[2172/8000] D loss: 0.1401, G loss: 9.2429\n",
      "[2532/8000] D loss: 0.2415, G loss: 8.8790\n",
      "[2892/8000] D loss: 0.3473, G loss: 6.1138\n",
      "[3252/8000] D loss: 0.2472, G loss: 11.6196\n",
      "[3612/8000] D loss: 0.3183, G loss: 8.5164\n",
      "[3972/8000] D loss: 0.1395, G loss: 13.5959\n",
      "[4332/8000] D loss: 0.1298, G loss: 10.7812\n",
      "[4692/8000] D loss: 0.0153, G loss: 13.7060\n",
      "[5052/8000] D loss: 0.0137, G loss: 11.2479\n",
      "[5412/8000] D loss: 0.6122, G loss: 8.5913\n",
      "[5772/8000] D loss: 0.3510, G loss: 10.1823\n",
      "[6132/8000] D loss: 0.2422, G loss: 14.9042\n",
      "[6492/8000] D loss: 0.1188, G loss: 12.0745\n",
      "[6852/8000] D loss: 0.3916, G loss: 9.7414\n",
      "[7212/8000] D loss: 0.1203, G loss: 13.3037\n",
      "[7572/8000] D loss: 0.4432, G loss: 11.7976\n",
      "[7932/8000] D loss: 0.2212, G loss: 9.3329\n",
      "train error: \n",
      " D loss: 0.275989, G loss: 10.915998, D accuracy: 91.7%, cell accuracy: 94.8%, board accuracy: 14.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.630140, G loss: 15.283822, D accuracy: 91.1%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3714, G loss: 6.9621\n",
      "[372/8000] D loss: 0.1301, G loss: 9.8550\n",
      "[732/8000] D loss: 0.1214, G loss: 11.1858\n",
      "[1092/8000] D loss: 0.2629, G loss: 8.7156\n",
      "[1452/8000] D loss: 0.2668, G loss: 10.5120\n",
      "[1812/8000] D loss: 0.0107, G loss: 9.8688\n",
      "[2172/8000] D loss: 0.2554, G loss: 11.6413\n",
      "[2532/8000] D loss: 0.1214, G loss: 9.7359\n",
      "[2892/8000] D loss: 0.2690, G loss: 7.3797\n",
      "[3252/8000] D loss: 0.1290, G loss: 10.3114\n",
      "[3612/8000] D loss: 0.1175, G loss: 12.0527\n",
      "[3972/8000] D loss: 0.4187, G loss: 8.5081\n",
      "[4332/8000] D loss: 0.3168, G loss: 8.6509\n",
      "[4692/8000] D loss: 0.4229, G loss: 11.0994\n",
      "[5052/8000] D loss: 0.3733, G loss: 8.9399\n",
      "[5412/8000] D loss: 0.6243, G loss: 8.5951\n",
      "[5772/8000] D loss: 0.1944, G loss: 10.9830\n",
      "[6132/8000] D loss: 0.3315, G loss: 7.4128\n",
      "[6492/8000] D loss: 0.3484, G loss: 11.8511\n",
      "[6852/8000] D loss: 0.0029, G loss: 11.8121\n",
      "[7212/8000] D loss: 0.2793, G loss: 10.3983\n",
      "[7572/8000] D loss: 0.2490, G loss: 9.3900\n",
      "[7932/8000] D loss: 0.0032, G loss: 13.3559\n",
      "train error: \n",
      " D loss: 0.258177, G loss: 10.129408, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 14.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.574130, G loss: 14.430730, D accuracy: 92.4%, cell accuracy: 94.3%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1297, G loss: 7.2387\n",
      "[372/8000] D loss: 0.0795, G loss: 9.5276\n",
      "[732/8000] D loss: 0.3250, G loss: 10.0452\n",
      "[1092/8000] D loss: 0.3723, G loss: 6.1182\n",
      "[1452/8000] D loss: 0.2266, G loss: 11.9610\n",
      "[1812/8000] D loss: 0.3560, G loss: 9.8868\n",
      "[2172/8000] D loss: 0.3721, G loss: 8.1025\n",
      "[2532/8000] D loss: 0.1308, G loss: 16.4990\n",
      "[2892/8000] D loss: 0.6469, G loss: 9.2229\n",
      "[3252/8000] D loss: 0.3814, G loss: 11.0452\n",
      "[3612/8000] D loss: 0.1710, G loss: 10.3889\n",
      "[3972/8000] D loss: 0.0065, G loss: 16.7949\n",
      "[4332/8000] D loss: 0.1455, G loss: 7.5791\n",
      "[4692/8000] D loss: 0.3225, G loss: 11.2236\n",
      "[5052/8000] D loss: 0.3306, G loss: 6.5018\n",
      "[5412/8000] D loss: 0.4540, G loss: 9.6146\n",
      "[5772/8000] D loss: 0.2414, G loss: 9.2379\n",
      "[6132/8000] D loss: 0.2311, G loss: 10.9258\n",
      "[6492/8000] D loss: 0.1187, G loss: 9.6983\n",
      "[6852/8000] D loss: 0.0176, G loss: 8.2976\n",
      "[7212/8000] D loss: 0.2245, G loss: 6.9613\n",
      "[7572/8000] D loss: 0.0007, G loss: 15.9126\n",
      "[7932/8000] D loss: 0.4201, G loss: 9.1436\n",
      "train error: \n",
      " D loss: 0.288591, G loss: 10.583326, D accuracy: 91.8%, cell accuracy: 94.8%, board accuracy: 14.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626024, G loss: 14.945757, D accuracy: 90.6%, cell accuracy: 94.4%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0840, G loss: 13.2846\n",
      "[372/8000] D loss: 0.3516, G loss: 12.1939\n",
      "[732/8000] D loss: 0.2389, G loss: 9.8935\n",
      "[1092/8000] D loss: 0.0101, G loss: 8.8461\n",
      "[1452/8000] D loss: 0.3806, G loss: 8.2557\n",
      "[1812/8000] D loss: 0.4797, G loss: 11.3765\n",
      "[2172/8000] D loss: 0.3545, G loss: 13.9758\n",
      "[2532/8000] D loss: 0.6061, G loss: 8.6554\n",
      "[2892/8000] D loss: 0.2397, G loss: 12.0890\n",
      "[3252/8000] D loss: 0.6690, G loss: 7.9410\n",
      "[3612/8000] D loss: 0.2851, G loss: 10.9326\n",
      "[3972/8000] D loss: 0.2924, G loss: 8.4090\n",
      "[4332/8000] D loss: 0.3649, G loss: 7.6058\n",
      "[4692/8000] D loss: 0.2568, G loss: 7.1307\n",
      "[5052/8000] D loss: 0.3807, G loss: 10.3644\n",
      "[5412/8000] D loss: 0.2697, G loss: 9.9392\n",
      "[5772/8000] D loss: 0.1929, G loss: 11.8978\n",
      "[6132/8000] D loss: 0.3425, G loss: 6.6520\n",
      "[6492/8000] D loss: 0.1798, G loss: 13.2972\n",
      "[6852/8000] D loss: 0.0274, G loss: 11.9096\n",
      "[7212/8000] D loss: 0.1190, G loss: 13.7087\n",
      "[7572/8000] D loss: 0.5450, G loss: 7.8040\n",
      "[7932/8000] D loss: 0.2888, G loss: 9.4268\n",
      "train error: \n",
      " D loss: 0.272435, G loss: 10.758812, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 14.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.650288, G loss: 15.136215, D accuracy: 91.1%, cell accuracy: 94.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3128, G loss: 7.3761\n",
      "[372/8000] D loss: 0.2395, G loss: 11.6748\n",
      "[732/8000] D loss: 0.3986, G loss: 9.8217\n",
      "[1092/8000] D loss: 0.1358, G loss: 12.9664\n",
      "[1452/8000] D loss: 0.2944, G loss: 13.8741\n",
      "[1812/8000] D loss: 0.1905, G loss: 10.9158\n",
      "[2172/8000] D loss: 0.4434, G loss: 11.7146\n",
      "[2532/8000] D loss: 0.4979, G loss: 10.4828\n",
      "[2892/8000] D loss: 0.0617, G loss: 12.8872\n",
      "[3252/8000] D loss: 0.1224, G loss: 11.2247\n",
      "[3612/8000] D loss: 0.1274, G loss: 12.4644\n",
      "[3972/8000] D loss: 0.3320, G loss: 13.8955\n",
      "[4332/8000] D loss: 0.3881, G loss: 13.7842\n",
      "[4692/8000] D loss: 0.1198, G loss: 12.8071\n",
      "[5052/8000] D loss: 0.1737, G loss: 12.1264\n",
      "[5412/8000] D loss: 0.3429, G loss: 11.3297\n",
      "[5772/8000] D loss: 0.3415, G loss: 10.9934\n",
      "[6132/8000] D loss: 0.0001, G loss: 19.1225\n",
      "[6492/8000] D loss: 0.3213, G loss: 9.7242\n",
      "[6852/8000] D loss: 0.2610, G loss: 10.0382\n",
      "[7212/8000] D loss: 0.3760, G loss: 8.3795\n",
      "[7572/8000] D loss: 0.1932, G loss: 11.1711\n",
      "[7932/8000] D loss: 0.6335, G loss: 7.1351\n",
      "train error: \n",
      " D loss: 0.276809, G loss: 10.818013, D accuracy: 91.8%, cell accuracy: 94.8%, board accuracy: 14.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.665915, G loss: 14.992186, D accuracy: 90.7%, cell accuracy: 94.4%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2242, G loss: 11.0114\n",
      "[372/8000] D loss: 0.4893, G loss: 10.3603\n",
      "[732/8000] D loss: 0.2456, G loss: 6.2464\n",
      "[1092/8000] D loss: 0.1231, G loss: 14.9065\n",
      "[1452/8000] D loss: 0.3661, G loss: 10.7341\n",
      "[1812/8000] D loss: 0.0184, G loss: 10.7916\n",
      "[2172/8000] D loss: 0.4837, G loss: 13.6175\n",
      "[2532/8000] D loss: 0.1225, G loss: 9.9155\n",
      "[2892/8000] D loss: 0.1915, G loss: 11.6605\n",
      "[3252/8000] D loss: 0.0228, G loss: 14.1639\n",
      "[3612/8000] D loss: 0.6325, G loss: 7.1049\n",
      "[3972/8000] D loss: 0.1310, G loss: 9.5289\n",
      "[4332/8000] D loss: 0.2939, G loss: 11.5753\n",
      "[4692/8000] D loss: 0.1593, G loss: 8.2658\n",
      "[5052/8000] D loss: 0.2030, G loss: 9.1331\n",
      "[5412/8000] D loss: 0.3875, G loss: 9.1716\n",
      "[5772/8000] D loss: 0.3827, G loss: 7.5157\n",
      "[6132/8000] D loss: 0.1997, G loss: 11.9968\n",
      "[6492/8000] D loss: 0.5805, G loss: 9.7889\n",
      "[6852/8000] D loss: 0.2306, G loss: 9.0375\n",
      "[7212/8000] D loss: 0.3961, G loss: 9.7657\n",
      "[7572/8000] D loss: 0.2643, G loss: 6.3980\n",
      "[7932/8000] D loss: 0.2563, G loss: 14.9635\n",
      "train error: \n",
      " D loss: 0.258888, G loss: 11.772778, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 14.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.642397, G loss: 16.385470, D accuracy: 92.0%, cell accuracy: 94.4%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2421, G loss: 10.4695\n",
      "[372/8000] D loss: 0.3316, G loss: 11.2656\n",
      "[732/8000] D loss: 0.1451, G loss: 13.7014\n",
      "[1092/8000] D loss: 0.0270, G loss: 15.0079\n",
      "[1452/8000] D loss: 0.3835, G loss: 8.8350\n",
      "[1812/8000] D loss: 0.2519, G loss: 11.8618\n",
      "[2172/8000] D loss: 0.4909, G loss: 7.7309\n",
      "[2532/8000] D loss: 0.1469, G loss: 12.4569\n",
      "[2892/8000] D loss: 0.3328, G loss: 9.5435\n",
      "[3252/8000] D loss: 0.4411, G loss: 6.6839\n",
      "[3612/8000] D loss: 0.4484, G loss: 13.6158\n",
      "[3972/8000] D loss: 0.3641, G loss: 10.0231\n",
      "[4332/8000] D loss: 0.1479, G loss: 10.6330\n",
      "[4692/8000] D loss: 0.1262, G loss: 14.2452\n",
      "[5052/8000] D loss: 0.3830, G loss: 7.3342\n",
      "[5412/8000] D loss: 0.1927, G loss: 10.4511\n",
      "[5772/8000] D loss: 0.2560, G loss: 8.0650\n",
      "[6132/8000] D loss: 0.0475, G loss: 12.8871\n",
      "[6492/8000] D loss: 0.2182, G loss: 8.2101\n",
      "[6852/8000] D loss: 0.2566, G loss: 10.9934\n",
      "[7212/8000] D loss: 0.3464, G loss: 9.7713\n",
      "[7572/8000] D loss: 0.0115, G loss: 10.2423\n",
      "[7932/8000] D loss: 0.1170, G loss: 10.9281\n",
      "train error: \n",
      " D loss: 0.265597, G loss: 9.578723, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 14.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.556272, G loss: 13.813085, D accuracy: 91.7%, cell accuracy: 94.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1624, G loss: 8.0548\n",
      "[372/8000] D loss: 0.3587, G loss: 13.0288\n",
      "[732/8000] D loss: 0.2654, G loss: 9.3994\n",
      "[1092/8000] D loss: 0.2372, G loss: 10.4834\n",
      "[1452/8000] D loss: 0.2695, G loss: 8.3342\n",
      "[1812/8000] D loss: 0.1355, G loss: 9.1376\n",
      "[2172/8000] D loss: 0.4126, G loss: 8.8944\n",
      "[2532/8000] D loss: 0.2292, G loss: 11.5282\n",
      "[2892/8000] D loss: 0.2463, G loss: 12.8497\n",
      "[3252/8000] D loss: 0.3529, G loss: 8.2067\n",
      "[3612/8000] D loss: 0.0216, G loss: 9.9356\n",
      "[3972/8000] D loss: 0.0132, G loss: 10.4905\n",
      "[4332/8000] D loss: 0.1965, G loss: 9.4317\n",
      "[4692/8000] D loss: 0.2974, G loss: 10.6229\n",
      "[5052/8000] D loss: 0.2863, G loss: 10.4740\n",
      "[5412/8000] D loss: 0.0285, G loss: 12.5071\n",
      "[5772/8000] D loss: 0.5546, G loss: 6.7173\n",
      "[6132/8000] D loss: 0.4192, G loss: 6.2931\n",
      "[6492/8000] D loss: 0.1509, G loss: 13.1541\n",
      "[6852/8000] D loss: 0.1249, G loss: 8.1677\n",
      "[7212/8000] D loss: 0.1193, G loss: 12.5388\n",
      "[7572/8000] D loss: 0.2926, G loss: 9.9925\n",
      "[7932/8000] D loss: 0.1696, G loss: 12.7766\n",
      "train error: \n",
      " D loss: 0.271635, G loss: 9.246349, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 14.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.494327, G loss: 13.471060, D accuracy: 92.8%, cell accuracy: 94.4%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3707, G loss: 7.9827\n",
      "[372/8000] D loss: 0.6179, G loss: 7.8705\n",
      "[732/8000] D loss: 0.1232, G loss: 14.2434\n",
      "[1092/8000] D loss: 0.5588, G loss: 8.8114\n",
      "[1452/8000] D loss: 0.1257, G loss: 11.3435\n",
      "[1812/8000] D loss: 0.3770, G loss: 7.6474\n",
      "[2172/8000] D loss: 0.2403, G loss: 11.3671\n",
      "[2532/8000] D loss: 0.1508, G loss: 10.8447\n",
      "[2892/8000] D loss: 0.2390, G loss: 10.8486\n",
      "[3252/8000] D loss: 0.2286, G loss: 10.6637\n",
      "[3612/8000] D loss: 0.0234, G loss: 10.1792\n",
      "[3972/8000] D loss: 0.1393, G loss: 10.5458\n",
      "[4332/8000] D loss: 0.2506, G loss: 11.2079\n",
      "[4692/8000] D loss: 0.1750, G loss: 9.0108\n",
      "[5052/8000] D loss: 0.3398, G loss: 11.1093\n",
      "[5412/8000] D loss: 0.3613, G loss: 10.4321\n",
      "[5772/8000] D loss: 0.4438, G loss: 8.6092\n",
      "[6132/8000] D loss: 0.0048, G loss: 13.6322\n",
      "[6492/8000] D loss: 0.4830, G loss: 4.8408\n",
      "[6852/8000] D loss: 0.3610, G loss: 10.9739\n",
      "[7212/8000] D loss: 0.2651, G loss: 7.4651\n",
      "[7572/8000] D loss: 0.0101, G loss: 10.9075\n",
      "[7932/8000] D loss: 0.5473, G loss: 7.4911\n",
      "train error: \n",
      " D loss: 0.266917, G loss: 9.696465, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 14.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.564057, G loss: 13.731451, D accuracy: 91.4%, cell accuracy: 94.4%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3372, G loss: 9.3949\n",
      "[372/8000] D loss: 0.2782, G loss: 9.2532\n",
      "[732/8000] D loss: 0.2626, G loss: 10.5448\n",
      "[1092/8000] D loss: 0.3667, G loss: 9.6175\n",
      "[1452/8000] D loss: 0.4829, G loss: 7.3687\n",
      "[1812/8000] D loss: 0.4746, G loss: 9.9044\n",
      "[2172/8000] D loss: 0.3351, G loss: 8.1338\n",
      "[2532/8000] D loss: 0.3209, G loss: 9.7066\n",
      "[2892/8000] D loss: 0.6178, G loss: 7.9302\n",
      "[3252/8000] D loss: 0.2436, G loss: 10.5813\n",
      "[3612/8000] D loss: 0.1420, G loss: 10.0772\n",
      "[3972/8000] D loss: 0.2015, G loss: 10.5096\n",
      "[4332/8000] D loss: 0.0346, G loss: 10.1824\n",
      "[4692/8000] D loss: 0.0109, G loss: 10.7872\n",
      "[5052/8000] D loss: 0.3616, G loss: 12.1473\n",
      "[5412/8000] D loss: 0.4009, G loss: 9.4598\n",
      "[5772/8000] D loss: 0.1894, G loss: 15.5800\n",
      "[6132/8000] D loss: 0.1075, G loss: 9.8629\n",
      "[6492/8000] D loss: 0.2493, G loss: 11.7350\n",
      "[6852/8000] D loss: 0.1278, G loss: 8.0584\n",
      "[7212/8000] D loss: 0.1435, G loss: 13.5315\n",
      "[7572/8000] D loss: 0.4337, G loss: 7.7570\n",
      "[7932/8000] D loss: 0.2666, G loss: 8.9258\n",
      "train error: \n",
      " D loss: 0.267363, G loss: 9.584735, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 14.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.507091, G loss: 13.973359, D accuracy: 92.8%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0329, G loss: 9.0141\n",
      "[372/8000] D loss: 0.1778, G loss: 9.2915\n",
      "[732/8000] D loss: 0.0281, G loss: 13.4457\n",
      "[1092/8000] D loss: 0.0944, G loss: 11.9901\n",
      "[1452/8000] D loss: 0.4138, G loss: 9.1709\n",
      "[1812/8000] D loss: 0.3373, G loss: 9.7735\n",
      "[2172/8000] D loss: 0.4825, G loss: 9.2671\n",
      "[2532/8000] D loss: 0.6684, G loss: 4.6965\n",
      "[2892/8000] D loss: 0.5543, G loss: 6.6981\n",
      "[3252/8000] D loss: 0.1869, G loss: 8.4688\n",
      "[3612/8000] D loss: 0.3254, G loss: 10.0455\n",
      "[3972/8000] D loss: 0.6688, G loss: 5.5389\n",
      "[4332/8000] D loss: 0.3848, G loss: 11.2212\n",
      "[4692/8000] D loss: 0.0045, G loss: 14.4924\n",
      "[5052/8000] D loss: 0.2804, G loss: 12.4433\n",
      "[5412/8000] D loss: 0.3228, G loss: 8.1684\n",
      "[5772/8000] D loss: 0.0762, G loss: 10.1129\n",
      "[6132/8000] D loss: 0.1202, G loss: 12.7690\n",
      "[6492/8000] D loss: 0.5342, G loss: 6.8122\n",
      "[6852/8000] D loss: 0.5541, G loss: 8.8042\n",
      "[7212/8000] D loss: 0.1276, G loss: 14.3459\n",
      "[7572/8000] D loss: 0.2812, G loss: 10.4762\n",
      "[7932/8000] D loss: 0.7561, G loss: 5.5381\n",
      "train error: \n",
      " D loss: 0.287007, G loss: 8.908805, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.478065, G loss: 12.776758, D accuracy: 92.9%, cell accuracy: 94.4%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5064, G loss: 8.4115\n",
      "[372/8000] D loss: 0.0240, G loss: 10.7600\n",
      "[732/8000] D loss: 0.4086, G loss: 9.6423\n",
      "[1092/8000] D loss: 0.2941, G loss: 12.8822\n",
      "[1452/8000] D loss: 0.0299, G loss: 10.1297\n",
      "[1812/8000] D loss: 0.1261, G loss: 12.6896\n",
      "[2172/8000] D loss: 0.2088, G loss: 10.0055\n",
      "[2532/8000] D loss: 0.4050, G loss: 6.3386\n",
      "[2892/8000] D loss: 0.2416, G loss: 11.4017\n",
      "[3252/8000] D loss: 0.0060, G loss: 15.5656\n",
      "[3612/8000] D loss: 0.2868, G loss: 9.5845\n",
      "[3972/8000] D loss: 0.4939, G loss: 7.0841\n",
      "[4332/8000] D loss: 0.4122, G loss: 10.1593\n",
      "[4692/8000] D loss: 0.2386, G loss: 12.9821\n",
      "[5052/8000] D loss: 0.4927, G loss: 8.7539\n",
      "[5412/8000] D loss: 0.0626, G loss: 12.3624\n",
      "[5772/8000] D loss: 0.3154, G loss: 8.2070\n",
      "[6132/8000] D loss: 0.2892, G loss: 9.2204\n",
      "[6492/8000] D loss: 0.1073, G loss: 14.5731\n",
      "[6852/8000] D loss: 0.3091, G loss: 10.5154\n",
      "[7212/8000] D loss: 0.2501, G loss: 7.3217\n",
      "[7572/8000] D loss: 0.2399, G loss: 9.9682\n",
      "[7932/8000] D loss: 0.4571, G loss: 8.8136\n",
      "train error: \n",
      " D loss: 0.265094, G loss: 10.238280, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 14.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.578310, G loss: 14.722847, D accuracy: 91.9%, cell accuracy: 94.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1219, G loss: 11.2348\n",
      "[372/8000] D loss: 0.4885, G loss: 11.4249\n",
      "[732/8000] D loss: 0.3104, G loss: 11.3804\n",
      "[1092/8000] D loss: 0.2487, G loss: 11.7090\n",
      "[1452/8000] D loss: 0.3226, G loss: 10.3150\n",
      "[1812/8000] D loss: 0.0502, G loss: 14.4530\n",
      "[2172/8000] D loss: 0.1484, G loss: 12.2705\n",
      "[2532/8000] D loss: 0.2654, G loss: 13.6365\n",
      "[2892/8000] D loss: 0.3295, G loss: 11.1881\n",
      "[3252/8000] D loss: 0.0052, G loss: 15.6983\n",
      "[3612/8000] D loss: 0.1285, G loss: 12.1133\n",
      "[3972/8000] D loss: 0.2481, G loss: 9.1803\n",
      "[4332/8000] D loss: 0.0165, G loss: 11.3190\n",
      "[4692/8000] D loss: 0.3645, G loss: 9.0806\n",
      "[5052/8000] D loss: 0.3857, G loss: 9.1499\n",
      "[5412/8000] D loss: 0.1752, G loss: 6.9383\n",
      "[5772/8000] D loss: 0.3093, G loss: 8.2656\n",
      "[6132/8000] D loss: 0.2554, G loss: 11.0915\n",
      "[6492/8000] D loss: 0.1527, G loss: 11.1274\n",
      "[6852/8000] D loss: 0.0728, G loss: 11.3391\n",
      "[7212/8000] D loss: 0.2323, G loss: 9.6909\n",
      "[7572/8000] D loss: 0.3172, G loss: 10.9049\n",
      "[7932/8000] D loss: 0.2802, G loss: 9.8423\n",
      "train error: \n",
      " D loss: 0.271227, G loss: 9.232547, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 14.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.501523, G loss: 13.622398, D accuracy: 92.7%, cell accuracy: 94.4%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2082, G loss: 12.9940\n",
      "[372/8000] D loss: 0.2534, G loss: 8.5911\n",
      "[732/8000] D loss: 0.0037, G loss: 13.8986\n",
      "[1092/8000] D loss: 0.3674, G loss: 10.3318\n",
      "[1452/8000] D loss: 0.3506, G loss: 7.6617\n",
      "[1812/8000] D loss: 0.2776, G loss: 9.8893\n",
      "[2172/8000] D loss: 0.4506, G loss: 10.9366\n",
      "[2532/8000] D loss: 0.2033, G loss: 10.1417\n",
      "[2892/8000] D loss: 0.0121, G loss: 16.4435\n",
      "[3252/8000] D loss: 0.2235, G loss: 11.5415\n",
      "[3612/8000] D loss: 0.3627, G loss: 9.3216\n",
      "[3972/8000] D loss: 0.5359, G loss: 9.8508\n",
      "[4332/8000] D loss: 0.0064, G loss: 15.5614\n",
      "[4692/8000] D loss: 0.3480, G loss: 12.0966\n",
      "[5052/8000] D loss: 0.1364, G loss: 11.9221\n",
      "[5412/8000] D loss: 0.3688, G loss: 8.8315\n",
      "[5772/8000] D loss: 0.3259, G loss: 12.7783\n",
      "[6132/8000] D loss: 0.0046, G loss: 18.2114\n",
      "[6492/8000] D loss: 0.3649, G loss: 9.8048\n",
      "[6852/8000] D loss: 0.3861, G loss: 7.9463\n",
      "[7212/8000] D loss: 0.1350, G loss: 10.2363\n",
      "[7572/8000] D loss: 0.3608, G loss: 11.1336\n",
      "[7932/8000] D loss: 0.7094, G loss: 7.0462\n",
      "train error: \n",
      " D loss: 0.269338, G loss: 9.660849, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.513148, G loss: 14.077545, D accuracy: 92.7%, cell accuracy: 94.4%, board accuracy: 6.1% \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2631, G loss: 11.8237\n",
      "[372/8000] D loss: 0.1467, G loss: 8.8998\n",
      "[732/8000] D loss: 0.2563, G loss: 9.2742\n",
      "[1092/8000] D loss: 0.4923, G loss: 12.2171\n",
      "[1452/8000] D loss: 0.5530, G loss: 7.9274\n",
      "[1812/8000] D loss: 0.1664, G loss: 9.8306\n",
      "[2172/8000] D loss: 0.3494, G loss: 9.9016\n",
      "[2532/8000] D loss: 0.0269, G loss: 13.0692\n",
      "[2892/8000] D loss: 0.0467, G loss: 14.1428\n",
      "[3252/8000] D loss: 0.3565, G loss: 9.3534\n",
      "[3612/8000] D loss: 0.0414, G loss: 11.1701\n",
      "[3972/8000] D loss: 0.4625, G loss: 9.3575\n",
      "[4332/8000] D loss: 0.2941, G loss: 8.8990\n",
      "[4692/8000] D loss: 0.2431, G loss: 9.2273\n",
      "[5052/8000] D loss: 0.1286, G loss: 14.0524\n",
      "[5412/8000] D loss: 0.0096, G loss: 14.2417\n",
      "[5772/8000] D loss: 0.1527, G loss: 12.8932\n",
      "[6132/8000] D loss: 0.1990, G loss: 15.5943\n",
      "[6492/8000] D loss: 0.0046, G loss: 16.2884\n",
      "[6852/8000] D loss: 0.3442, G loss: 13.3233\n",
      "[7212/8000] D loss: 0.2717, G loss: 6.9856\n",
      "[7572/8000] D loss: 0.3293, G loss: 10.2441\n",
      "[7932/8000] D loss: 0.3592, G loss: 10.5541\n",
      "train error: \n",
      " D loss: 0.268471, G loss: 11.817343, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.681343, G loss: 16.425230, D accuracy: 90.8%, cell accuracy: 94.3%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1642, G loss: 14.9304\n",
      "[372/8000] D loss: 0.2407, G loss: 9.8972\n",
      "[732/8000] D loss: 0.2299, G loss: 9.1370\n",
      "[1092/8000] D loss: 0.3698, G loss: 14.0755\n",
      "[1452/8000] D loss: 0.1174, G loss: 11.0727\n",
      "[1812/8000] D loss: 0.2339, G loss: 10.1801\n",
      "[2172/8000] D loss: 0.4937, G loss: 10.4545\n",
      "[2532/8000] D loss: 0.4435, G loss: 13.1642\n",
      "[2892/8000] D loss: 0.2322, G loss: 10.2557\n",
      "[3252/8000] D loss: 0.2122, G loss: 14.5199\n",
      "[3612/8000] D loss: 0.2549, G loss: 11.5585\n",
      "[3972/8000] D loss: 0.0358, G loss: 13.7859\n",
      "[4332/8000] D loss: 0.1140, G loss: 11.8794\n",
      "[4692/8000] D loss: 0.4315, G loss: 7.6145\n",
      "[5052/8000] D loss: 0.1293, G loss: 10.3838\n",
      "[5412/8000] D loss: 0.1214, G loss: 12.2710\n",
      "[5772/8000] D loss: 0.2719, G loss: 8.4581\n",
      "[6132/8000] D loss: 0.0104, G loss: 13.2884\n",
      "[6492/8000] D loss: 0.1125, G loss: 12.6713\n",
      "[6852/8000] D loss: 0.2338, G loss: 15.1766\n",
      "[7212/8000] D loss: 0.1325, G loss: 14.6814\n",
      "[7572/8000] D loss: 0.4241, G loss: 8.4882\n",
      "[7932/8000] D loss: 0.2334, G loss: 11.0671\n",
      "train error: \n",
      " D loss: 0.254329, G loss: 10.764288, D accuracy: 92.4%, cell accuracy: 94.8%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.590241, G loss: 15.327686, D accuracy: 92.1%, cell accuracy: 94.3%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1356, G loss: 12.4386\n",
      "[372/8000] D loss: 0.2862, G loss: 12.1205\n",
      "[732/8000] D loss: 0.3444, G loss: 12.4026\n",
      "[1092/8000] D loss: 0.3373, G loss: 11.8004\n",
      "[1452/8000] D loss: 0.2426, G loss: 10.2899\n",
      "[1812/8000] D loss: 0.0139, G loss: 12.8414\n",
      "[2172/8000] D loss: 0.3196, G loss: 10.6475\n",
      "[2532/8000] D loss: 0.2762, G loss: 12.4939\n",
      "[2892/8000] D loss: 0.5402, G loss: 7.0591\n",
      "[3252/8000] D loss: 0.3670, G loss: 11.7448\n",
      "[3612/8000] D loss: 0.4782, G loss: 10.4754\n",
      "[3972/8000] D loss: 0.1191, G loss: 14.7394\n",
      "[4332/8000] D loss: 0.3012, G loss: 13.9468\n",
      "[4692/8000] D loss: 0.5006, G loss: 8.7492\n",
      "[5052/8000] D loss: 0.0053, G loss: 10.7308\n",
      "[5412/8000] D loss: 0.2569, G loss: 8.7854\n",
      "[5772/8000] D loss: 0.2874, G loss: 11.3460\n",
      "[6132/8000] D loss: 0.1996, G loss: 11.5057\n",
      "[6492/8000] D loss: 0.5829, G loss: 6.8105\n",
      "[6852/8000] D loss: 0.4870, G loss: 7.2222\n",
      "[7212/8000] D loss: 0.3473, G loss: 10.4643\n",
      "[7572/8000] D loss: 0.0003, G loss: 15.0277\n",
      "[7932/8000] D loss: 0.6448, G loss: 7.0990\n",
      "train error: \n",
      " D loss: 0.267623, G loss: 9.575449, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.528045, G loss: 13.879600, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3592, G loss: 10.3104\n",
      "[372/8000] D loss: 0.4283, G loss: 8.3687\n",
      "[732/8000] D loss: 0.1582, G loss: 13.2078\n",
      "[1092/8000] D loss: 0.2289, G loss: 12.0261\n",
      "[1452/8000] D loss: 0.2016, G loss: 11.9543\n",
      "[1812/8000] D loss: 0.2021, G loss: 14.9644\n",
      "[2172/8000] D loss: 0.3835, G loss: 11.5633\n",
      "[2532/8000] D loss: 0.2695, G loss: 11.2778\n",
      "[2892/8000] D loss: 0.0007, G loss: 13.1993\n",
      "[3252/8000] D loss: 0.3783, G loss: 11.2896\n",
      "[3612/8000] D loss: 0.1224, G loss: 11.2965\n",
      "[3972/8000] D loss: 0.1357, G loss: 11.6269\n",
      "[4332/8000] D loss: 0.0473, G loss: 18.2640\n",
      "[4692/8000] D loss: 0.1629, G loss: 10.7746\n",
      "[5052/8000] D loss: 0.5442, G loss: 13.6560\n",
      "[5412/8000] D loss: 0.0908, G loss: 13.3003\n",
      "[5772/8000] D loss: 0.4820, G loss: 9.9691\n",
      "[6132/8000] D loss: 0.1273, G loss: 9.4783\n",
      "[6492/8000] D loss: 0.1168, G loss: 13.8512\n",
      "[6852/8000] D loss: 0.2555, G loss: 8.9648\n",
      "[7212/8000] D loss: 0.5860, G loss: 10.6393\n",
      "[7572/8000] D loss: 0.2017, G loss: 8.9279\n",
      "[7932/8000] D loss: 0.3793, G loss: 10.1381\n",
      "train error: \n",
      " D loss: 0.268490, G loss: 11.872998, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.694796, G loss: 16.652121, D accuracy: 91.1%, cell accuracy: 94.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1423, G loss: 12.7870\n",
      "[372/8000] D loss: 0.3672, G loss: 9.2140\n",
      "[732/8000] D loss: 0.2498, G loss: 11.0176\n",
      "[1092/8000] D loss: 0.3373, G loss: 12.3334\n",
      "[1452/8000] D loss: 0.0647, G loss: 11.2838\n",
      "[1812/8000] D loss: 0.1488, G loss: 9.5046\n",
      "[2172/8000] D loss: 0.3497, G loss: 11.0054\n",
      "[2532/8000] D loss: 0.1338, G loss: 11.3134\n",
      "[2892/8000] D loss: 0.3379, G loss: 10.8951\n",
      "[3252/8000] D loss: 0.3860, G loss: 10.0196\n",
      "[3612/8000] D loss: 0.2312, G loss: 8.5649\n",
      "[3972/8000] D loss: 0.3642, G loss: 13.6985\n",
      "[4332/8000] D loss: 0.1233, G loss: 12.2620\n",
      "[4692/8000] D loss: 0.2446, G loss: 11.0235\n",
      "[5052/8000] D loss: 0.4440, G loss: 10.5366\n",
      "[5412/8000] D loss: 0.0030, G loss: 16.2173\n",
      "[5772/8000] D loss: 0.1267, G loss: 10.2604\n",
      "[6132/8000] D loss: 0.3592, G loss: 11.1378\n",
      "[6492/8000] D loss: 0.1730, G loss: 10.3910\n",
      "[6852/8000] D loss: 0.1551, G loss: 12.2029\n",
      "[7212/8000] D loss: 0.1340, G loss: 10.8185\n",
      "[7572/8000] D loss: 0.3256, G loss: 8.4044\n",
      "[7932/8000] D loss: 0.1714, G loss: 9.8765\n",
      "train error: \n",
      " D loss: 0.273032, G loss: 9.786649, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 14.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.512075, G loss: 14.196553, D accuracy: 92.9%, cell accuracy: 94.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2464, G loss: 7.3437\n",
      "[372/8000] D loss: 0.4109, G loss: 8.4063\n",
      "[732/8000] D loss: 0.0681, G loss: 11.7344\n",
      "[1092/8000] D loss: 0.4909, G loss: 9.1723\n",
      "[1452/8000] D loss: 0.4843, G loss: 6.3323\n",
      "[1812/8000] D loss: 0.1178, G loss: 12.2847\n",
      "[2172/8000] D loss: 0.2593, G loss: 12.1372\n",
      "[2532/8000] D loss: 0.1186, G loss: 12.3727\n",
      "[2892/8000] D loss: 0.2151, G loss: 12.4983\n",
      "[3252/8000] D loss: 0.3389, G loss: 8.2858\n",
      "[3612/8000] D loss: 0.3768, G loss: 13.0219\n",
      "[3972/8000] D loss: 0.2601, G loss: 13.2491\n",
      "[4332/8000] D loss: 0.3985, G loss: 7.1503\n",
      "[4692/8000] D loss: 0.2666, G loss: 11.1164\n",
      "[5052/8000] D loss: 0.0851, G loss: 11.8147\n",
      "[5412/8000] D loss: 0.0065, G loss: 13.4606\n",
      "[5772/8000] D loss: 0.1432, G loss: 10.7783\n",
      "[6132/8000] D loss: 0.3581, G loss: 11.5437\n",
      "[6492/8000] D loss: 0.3369, G loss: 11.9127\n",
      "[6852/8000] D loss: 0.0667, G loss: 13.7083\n",
      "[7212/8000] D loss: 0.4235, G loss: 8.1367\n",
      "[7572/8000] D loss: 0.1607, G loss: 12.0036\n",
      "[7932/8000] D loss: 0.1335, G loss: 8.9881\n",
      "train error: \n",
      " D loss: 0.265422, G loss: 10.545313, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.560739, G loss: 15.216996, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3723, G loss: 7.9139\n",
      "[372/8000] D loss: 0.2527, G loss: 9.3962\n",
      "[732/8000] D loss: 0.0061, G loss: 11.0824\n",
      "[1092/8000] D loss: 0.5096, G loss: 7.3190\n",
      "[1452/8000] D loss: 0.1185, G loss: 9.2367\n",
      "[1812/8000] D loss: 0.2405, G loss: 10.5672\n",
      "[2172/8000] D loss: 0.4781, G loss: 10.8706\n",
      "[2532/8000] D loss: 0.5010, G loss: 10.4747\n",
      "[2892/8000] D loss: 0.2639, G loss: 8.7383\n",
      "[3252/8000] D loss: 0.5504, G loss: 13.4439\n",
      "[3612/8000] D loss: 0.3083, G loss: 8.8362\n",
      "[3972/8000] D loss: 0.6404, G loss: 4.0530\n",
      "[4332/8000] D loss: 0.2871, G loss: 11.3669\n",
      "[4692/8000] D loss: 0.3698, G loss: 10.9041\n",
      "[5052/8000] D loss: 0.4155, G loss: 6.1949\n",
      "[5412/8000] D loss: 0.1680, G loss: 12.7919\n",
      "[5772/8000] D loss: 0.2144, G loss: 14.1168\n",
      "[6132/8000] D loss: 0.1607, G loss: 11.2941\n",
      "[6492/8000] D loss: 0.1393, G loss: 13.6781\n",
      "[6852/8000] D loss: 0.3572, G loss: 9.5567\n",
      "[7212/8000] D loss: 0.5181, G loss: 9.7581\n",
      "[7572/8000] D loss: 0.2495, G loss: 11.2710\n",
      "[7932/8000] D loss: 0.0853, G loss: 8.7785\n",
      "train error: \n",
      " D loss: 0.265718, G loss: 9.505608, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.516210, G loss: 13.680491, D accuracy: 92.4%, cell accuracy: 94.4%, board accuracy: 6.1% \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4196, G loss: 9.0897\n",
      "[372/8000] D loss: 0.1180, G loss: 11.4169\n",
      "[732/8000] D loss: 0.3478, G loss: 9.0412\n",
      "[1092/8000] D loss: 0.3816, G loss: 10.4106\n",
      "[1452/8000] D loss: 0.4900, G loss: 9.4334\n",
      "[1812/8000] D loss: 0.3077, G loss: 10.2186\n",
      "[2172/8000] D loss: 0.5825, G loss: 7.7251\n",
      "[2532/8000] D loss: 0.4531, G loss: 9.8428\n",
      "[2892/8000] D loss: 0.1669, G loss: 13.7339\n",
      "[3252/8000] D loss: 0.3104, G loss: 7.2094\n",
      "[3612/8000] D loss: 0.1776, G loss: 9.0381\n",
      "[3972/8000] D loss: 0.3372, G loss: 9.9496\n",
      "[4332/8000] D loss: 0.1173, G loss: 15.3088\n",
      "[4692/8000] D loss: 0.0067, G loss: 17.7035\n",
      "[5052/8000] D loss: 0.0043, G loss: 14.9525\n",
      "[5412/8000] D loss: 0.0100, G loss: 10.5415\n",
      "[5772/8000] D loss: 0.0308, G loss: 8.8363\n",
      "[6132/8000] D loss: 0.2086, G loss: 11.7339\n",
      "[6492/8000] D loss: 0.1555, G loss: 12.7004\n",
      "[6852/8000] D loss: 0.2818, G loss: 10.3619\n",
      "[7212/8000] D loss: 0.1340, G loss: 10.5374\n",
      "[7572/8000] D loss: 0.1735, G loss: 11.9733\n",
      "[7932/8000] D loss: 0.3549, G loss: 8.6758\n",
      "train error: \n",
      " D loss: 0.266066, G loss: 10.037502, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.544131, G loss: 14.551448, D accuracy: 92.3%, cell accuracy: 94.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1465, G loss: 13.1353\n",
      "[372/8000] D loss: 0.2467, G loss: 11.6120\n",
      "[732/8000] D loss: 0.2618, G loss: 8.9720\n",
      "[1092/8000] D loss: 0.4779, G loss: 8.3489\n",
      "[1452/8000] D loss: 0.5597, G loss: 9.2656\n",
      "[1812/8000] D loss: 0.1359, G loss: 12.8855\n",
      "[2172/8000] D loss: 0.2747, G loss: 8.6367\n",
      "[2532/8000] D loss: 0.2741, G loss: 7.6724\n",
      "[2892/8000] D loss: 0.2704, G loss: 7.5251\n",
      "[3252/8000] D loss: 0.1505, G loss: 12.2108\n",
      "[3612/8000] D loss: 0.0208, G loss: 11.5473\n",
      "[3972/8000] D loss: 0.1017, G loss: 13.0345\n",
      "[4332/8000] D loss: 0.1536, G loss: 12.9064\n",
      "[4692/8000] D loss: 0.1250, G loss: 8.0666\n",
      "[5052/8000] D loss: 0.1240, G loss: 12.5098\n",
      "[5412/8000] D loss: 0.1182, G loss: 8.6588\n",
      "[5772/8000] D loss: 0.1677, G loss: 10.6444\n",
      "[6132/8000] D loss: 0.2436, G loss: 9.8498\n",
      "[6492/8000] D loss: 0.2618, G loss: 8.8107\n",
      "[6852/8000] D loss: 0.2409, G loss: 7.4250\n",
      "[7212/8000] D loss: 0.1128, G loss: 17.3797\n",
      "[7572/8000] D loss: 0.3909, G loss: 8.3211\n",
      "[7932/8000] D loss: 0.2974, G loss: 8.5069\n",
      "train error: \n",
      " D loss: 0.256521, G loss: 10.883877, D accuracy: 92.3%, cell accuracy: 94.8%, board accuracy: 15.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.602306, G loss: 15.411527, D accuracy: 91.8%, cell accuracy: 94.4%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3079, G loss: 8.7487\n",
      "[372/8000] D loss: 0.7759, G loss: 10.2362\n",
      "[732/8000] D loss: 0.3958, G loss: 8.5588\n",
      "[1092/8000] D loss: 0.2490, G loss: 9.6495\n",
      "[1452/8000] D loss: 0.4815, G loss: 8.5445\n",
      "[1812/8000] D loss: 0.2401, G loss: 10.2146\n",
      "[2172/8000] D loss: 0.1218, G loss: 11.9015\n",
      "[2532/8000] D loss: 0.3677, G loss: 8.7275\n",
      "[2892/8000] D loss: 0.0236, G loss: 13.2606\n",
      "[3252/8000] D loss: 0.2326, G loss: 10.1980\n",
      "[3612/8000] D loss: 0.2327, G loss: 10.3245\n",
      "[3972/8000] D loss: 0.4589, G loss: 10.0287\n",
      "[4332/8000] D loss: 0.4428, G loss: 11.1519\n",
      "[4692/8000] D loss: 0.3071, G loss: 9.7362\n",
      "[5052/8000] D loss: 0.0259, G loss: 11.2527\n",
      "[5412/8000] D loss: 0.4660, G loss: 11.4494\n",
      "[5772/8000] D loss: 0.2855, G loss: 9.8390\n",
      "[6132/8000] D loss: 0.1202, G loss: 10.1348\n",
      "[6492/8000] D loss: 0.3291, G loss: 10.9625\n",
      "[6852/8000] D loss: 0.2557, G loss: 9.1864\n",
      "[7212/8000] D loss: 0.3921, G loss: 6.3971\n",
      "[7572/8000] D loss: 0.4248, G loss: 10.7736\n",
      "[7932/8000] D loss: 0.0235, G loss: 12.8651\n",
      "train error: \n",
      " D loss: 0.269757, G loss: 11.490387, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 14.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.619137, G loss: 15.913290, D accuracy: 91.1%, cell accuracy: 94.4%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0406, G loss: 11.6480\n",
      "[372/8000] D loss: 0.1222, G loss: 10.9745\n",
      "[732/8000] D loss: 0.2951, G loss: 12.5834\n",
      "[1092/8000] D loss: 0.4015, G loss: 9.0353\n",
      "[1452/8000] D loss: 0.2715, G loss: 8.5942\n",
      "[1812/8000] D loss: 0.0025, G loss: 20.0267\n",
      "[2172/8000] D loss: 0.2004, G loss: 12.0745\n",
      "[2532/8000] D loss: 0.0093, G loss: 13.3423\n",
      "[2892/8000] D loss: 0.1271, G loss: 12.5529\n",
      "[3252/8000] D loss: 0.0237, G loss: 12.6945\n",
      "[3612/8000] D loss: 0.0006, G loss: 17.4069\n",
      "[3972/8000] D loss: 0.4820, G loss: 11.7573\n",
      "[4332/8000] D loss: 0.2501, G loss: 10.5605\n",
      "[4692/8000] D loss: 0.2020, G loss: 9.5652\n",
      "[5052/8000] D loss: 0.3736, G loss: 10.0000\n",
      "[5412/8000] D loss: 0.1843, G loss: 10.9948\n",
      "[5772/8000] D loss: 0.3633, G loss: 9.4094\n",
      "[6132/8000] D loss: 0.2476, G loss: 10.3632\n",
      "[6492/8000] D loss: 0.4697, G loss: 12.8041\n",
      "[6852/8000] D loss: 0.2216, G loss: 12.0374\n",
      "[7212/8000] D loss: 0.5319, G loss: 8.5500\n",
      "[7572/8000] D loss: 0.2180, G loss: 10.3841\n",
      "[7932/8000] D loss: 0.0107, G loss: 12.1605\n",
      "train error: \n",
      " D loss: 0.275101, G loss: 12.237346, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 14.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.687309, G loss: 16.874651, D accuracy: 90.2%, cell accuracy: 94.3%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4182, G loss: 12.5549\n",
      "[372/8000] D loss: 0.1813, G loss: 12.2618\n",
      "[732/8000] D loss: 0.5200, G loss: 11.1662\n",
      "[1092/8000] D loss: 0.0076, G loss: 11.7875\n",
      "[1452/8000] D loss: 0.2598, G loss: 12.9849\n",
      "[1812/8000] D loss: 0.1147, G loss: 13.4989\n",
      "[2172/8000] D loss: 0.2950, G loss: 7.6003\n",
      "[2532/8000] D loss: 0.3593, G loss: 11.4180\n",
      "[2892/8000] D loss: 0.1442, G loss: 10.2920\n",
      "[3252/8000] D loss: 0.2818, G loss: 14.4558\n",
      "[3612/8000] D loss: 0.1848, G loss: 11.9020\n",
      "[3972/8000] D loss: 0.2372, G loss: 13.1535\n",
      "[4332/8000] D loss: 0.2058, G loss: 10.3608\n",
      "[4692/8000] D loss: 0.2960, G loss: 12.6355\n",
      "[5052/8000] D loss: 0.2403, G loss: 10.9770\n",
      "[5412/8000] D loss: 0.1860, G loss: 12.6846\n",
      "[5772/8000] D loss: 0.2903, G loss: 10.9763\n",
      "[6132/8000] D loss: 0.4947, G loss: 11.6942\n",
      "[6492/8000] D loss: 0.1255, G loss: 9.2232\n",
      "[6852/8000] D loss: 0.5044, G loss: 9.7904\n",
      "[7212/8000] D loss: 0.2741, G loss: 9.8254\n",
      "[7572/8000] D loss: 0.2441, G loss: 12.8541\n",
      "[7932/8000] D loss: 0.1527, G loss: 10.4634\n",
      "train error: \n",
      " D loss: 0.268205, G loss: 10.482022, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.546601, G loss: 14.827497, D accuracy: 92.3%, cell accuracy: 94.4%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2604, G loss: 10.7689\n",
      "[372/8000] D loss: 0.3010, G loss: 8.0932\n",
      "[732/8000] D loss: 0.3452, G loss: 10.3237\n",
      "[1092/8000] D loss: 0.0029, G loss: 13.2463\n",
      "[1452/8000] D loss: 0.2483, G loss: 11.1051\n",
      "[1812/8000] D loss: 0.1793, G loss: 10.6328\n",
      "[2172/8000] D loss: 0.1264, G loss: 12.4645\n",
      "[2532/8000] D loss: 0.4668, G loss: 7.6141\n",
      "[2892/8000] D loss: 0.1291, G loss: 11.6858\n",
      "[3252/8000] D loss: 0.1374, G loss: 12.9723\n",
      "[3612/8000] D loss: 0.2852, G loss: 9.9221\n",
      "[3972/8000] D loss: 0.0563, G loss: 13.3743\n",
      "[4332/8000] D loss: 0.3206, G loss: 13.1252\n",
      "[4692/8000] D loss: 0.4984, G loss: 9.0348\n",
      "[5052/8000] D loss: 0.2511, G loss: 11.4539\n",
      "[5412/8000] D loss: 0.1638, G loss: 11.8515\n",
      "[5772/8000] D loss: 0.2387, G loss: 7.9252\n",
      "[6132/8000] D loss: 0.1451, G loss: 8.5020\n",
      "[6492/8000] D loss: 0.1840, G loss: 9.7662\n",
      "[6852/8000] D loss: 0.3870, G loss: 7.9521\n",
      "[7212/8000] D loss: 0.0819, G loss: 8.8198\n",
      "[7572/8000] D loss: 0.1219, G loss: 14.4933\n",
      "[7932/8000] D loss: 0.2897, G loss: 9.9520\n",
      "train error: \n",
      " D loss: 0.265867, G loss: 10.700037, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.589620, G loss: 15.094493, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 6.4% \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1541, G loss: 11.6780\n",
      "[372/8000] D loss: 0.2935, G loss: 12.3647\n",
      "[732/8000] D loss: 0.1176, G loss: 13.1160\n",
      "[1092/8000] D loss: 0.1965, G loss: 10.2220\n",
      "[1452/8000] D loss: 0.3413, G loss: 13.9106\n",
      "[1812/8000] D loss: 0.4743, G loss: 7.2662\n",
      "[2172/8000] D loss: 0.3532, G loss: 11.1608\n",
      "[2532/8000] D loss: 0.0253, G loss: 14.6766\n",
      "[2892/8000] D loss: 0.2125, G loss: 11.5221\n",
      "[3252/8000] D loss: 0.3317, G loss: 9.4685\n",
      "[3612/8000] D loss: 0.1886, G loss: 9.3748\n",
      "[3972/8000] D loss: 0.4217, G loss: 10.0316\n",
      "[4332/8000] D loss: 0.4047, G loss: 14.0297\n",
      "[4692/8000] D loss: 0.1291, G loss: 13.3693\n",
      "[5052/8000] D loss: 0.0064, G loss: 12.9165\n",
      "[5412/8000] D loss: 0.3348, G loss: 10.5123\n",
      "[5772/8000] D loss: 0.1966, G loss: 11.2968\n",
      "[6132/8000] D loss: 0.4265, G loss: 13.1680\n",
      "[6492/8000] D loss: 0.0067, G loss: 10.4482\n",
      "[6852/8000] D loss: 0.5580, G loss: 4.8893\n",
      "[7212/8000] D loss: 0.2715, G loss: 10.5675\n",
      "[7572/8000] D loss: 0.3529, G loss: 10.1992\n",
      "[7932/8000] D loss: 0.3337, G loss: 8.3408\n",
      "train error: \n",
      " D loss: 0.258086, G loss: 10.996429, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 15.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.554477, G loss: 15.610987, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0422, G loss: 14.5797\n",
      "[372/8000] D loss: 0.2930, G loss: 11.1570\n",
      "[732/8000] D loss: 0.2964, G loss: 13.2775\n",
      "[1092/8000] D loss: 0.0999, G loss: 10.9324\n",
      "[1452/8000] D loss: 0.2509, G loss: 10.5364\n",
      "[1812/8000] D loss: 0.1506, G loss: 13.4686\n",
      "[2172/8000] D loss: 0.6261, G loss: 5.4455\n",
      "[2532/8000] D loss: 0.0775, G loss: 11.3106\n",
      "[2892/8000] D loss: 0.1842, G loss: 12.7073\n",
      "[3252/8000] D loss: 0.0023, G loss: 15.5761\n",
      "[3612/8000] D loss: 0.2493, G loss: 5.9435\n",
      "[3972/8000] D loss: 0.6379, G loss: 9.3956\n",
      "[4332/8000] D loss: 0.0111, G loss: 12.5993\n",
      "[4692/8000] D loss: 0.0122, G loss: 12.1922\n",
      "[5052/8000] D loss: 0.2731, G loss: 10.2389\n",
      "[5412/8000] D loss: 0.0344, G loss: 13.3340\n",
      "[5772/8000] D loss: 0.2313, G loss: 14.0792\n",
      "[6132/8000] D loss: 0.4786, G loss: 11.1160\n",
      "[6492/8000] D loss: 0.2284, G loss: 11.3827\n",
      "[6852/8000] D loss: 0.1310, G loss: 9.4240\n",
      "[7212/8000] D loss: 0.2703, G loss: 9.3625\n",
      "[7572/8000] D loss: 0.1189, G loss: 13.7031\n",
      "[7932/8000] D loss: 0.5354, G loss: 9.3440\n",
      "train error: \n",
      " D loss: 0.264568, G loss: 10.200234, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.559291, G loss: 14.546757, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 6.4% \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0613, G loss: 14.8810\n",
      "[372/8000] D loss: 0.6794, G loss: 7.0095\n",
      "[732/8000] D loss: 0.1205, G loss: 14.4555\n",
      "[1092/8000] D loss: 0.2434, G loss: 11.6099\n",
      "[1452/8000] D loss: 0.0448, G loss: 12.2078\n",
      "[1812/8000] D loss: 0.4826, G loss: 9.2282\n",
      "[2172/8000] D loss: 0.1204, G loss: 12.8395\n",
      "[2532/8000] D loss: 0.2812, G loss: 7.6279\n",
      "[2892/8000] D loss: 1.2745, G loss: 6.6905\n",
      "[3252/8000] D loss: 0.3613, G loss: 7.6795\n",
      "[3612/8000] D loss: 0.4879, G loss: 8.2581\n",
      "[3972/8000] D loss: 0.2113, G loss: 8.8854\n",
      "[4332/8000] D loss: 0.1187, G loss: 12.4554\n",
      "[4692/8000] D loss: 0.1276, G loss: 9.3532\n",
      "[5052/8000] D loss: 0.3791, G loss: 6.7796\n",
      "[5412/8000] D loss: 0.1898, G loss: 9.5786\n",
      "[5772/8000] D loss: 0.3711, G loss: 10.8094\n",
      "[6132/8000] D loss: 0.2925, G loss: 13.2328\n",
      "[6492/8000] D loss: 0.4757, G loss: 6.3289\n",
      "[6852/8000] D loss: 0.3940, G loss: 10.0903\n",
      "[7212/8000] D loss: 0.4479, G loss: 14.6953\n",
      "[7572/8000] D loss: 0.5921, G loss: 9.6750\n",
      "[7932/8000] D loss: 0.1444, G loss: 15.3374\n",
      "train error: \n",
      " D loss: 0.282270, G loss: 9.468892, D accuracy: 91.7%, cell accuracy: 94.8%, board accuracy: 15.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.507374, G loss: 13.923495, D accuracy: 93.0%, cell accuracy: 94.3%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4377, G loss: 9.6943\n",
      "[372/8000] D loss: 0.3429, G loss: 8.3879\n",
      "[732/8000] D loss: 0.1251, G loss: 8.6241\n",
      "[1092/8000] D loss: 0.1251, G loss: 15.2896\n",
      "[1452/8000] D loss: 0.1401, G loss: 12.0051\n",
      "[1812/8000] D loss: 0.0072, G loss: 9.5926\n",
      "[2172/8000] D loss: 0.3008, G loss: 9.8325\n",
      "[2532/8000] D loss: 0.0055, G loss: 13.0338\n",
      "[2892/8000] D loss: 0.1169, G loss: 11.8778\n",
      "[3252/8000] D loss: 0.4226, G loss: 10.4281\n",
      "[3612/8000] D loss: 0.2579, G loss: 9.7137\n",
      "[3972/8000] D loss: 0.5182, G loss: 10.0792\n",
      "[4332/8000] D loss: 0.0016, G loss: 15.9220\n",
      "[4692/8000] D loss: 0.2185, G loss: 9.4243\n",
      "[5052/8000] D loss: 0.1309, G loss: 14.4085\n",
      "[5412/8000] D loss: 0.0642, G loss: 14.9246\n",
      "[5772/8000] D loss: 0.1392, G loss: 9.9496\n",
      "[6132/8000] D loss: 0.1408, G loss: 10.7755\n",
      "[6492/8000] D loss: 0.5725, G loss: 8.2607\n",
      "[6852/8000] D loss: 0.1182, G loss: 13.8485\n",
      "[7212/8000] D loss: 0.1258, G loss: 9.8933\n",
      "[7572/8000] D loss: 0.3310, G loss: 9.6871\n",
      "[7932/8000] D loss: 0.3455, G loss: 11.7413\n",
      "train error: \n",
      " D loss: 0.259380, G loss: 10.562293, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 15.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.556305, G loss: 15.006445, D accuracy: 92.6%, cell accuracy: 94.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1076, G loss: 13.5938\n",
      "[372/8000] D loss: 0.1952, G loss: 8.2465\n",
      "[732/8000] D loss: 0.3234, G loss: 11.5011\n",
      "[1092/8000] D loss: 0.1815, G loss: 7.7255\n",
      "[1452/8000] D loss: 0.2704, G loss: 10.5569\n",
      "[1812/8000] D loss: 0.1576, G loss: 13.3489\n",
      "[2172/8000] D loss: 0.2733, G loss: 9.0024\n",
      "[2532/8000] D loss: 0.3466, G loss: 9.5128\n",
      "[2892/8000] D loss: 0.4957, G loss: 8.4216\n",
      "[3252/8000] D loss: 0.3545, G loss: 12.2265\n",
      "[3612/8000] D loss: 0.2739, G loss: 13.5261\n",
      "[3972/8000] D loss: 0.2512, G loss: 10.4668\n",
      "[4332/8000] D loss: 0.3619, G loss: 12.8931\n",
      "[4692/8000] D loss: 0.4041, G loss: 9.9417\n",
      "[5052/8000] D loss: 0.2633, G loss: 12.7911\n",
      "[5412/8000] D loss: 0.2673, G loss: 13.4753\n",
      "[5772/8000] D loss: 0.4138, G loss: 7.7362\n",
      "[6132/8000] D loss: 0.5685, G loss: 7.9786\n",
      "[6492/8000] D loss: 0.5618, G loss: 6.8867\n",
      "[6852/8000] D loss: 0.2529, G loss: 8.7482\n",
      "[7212/8000] D loss: 0.2745, G loss: 9.9572\n",
      "[7572/8000] D loss: 0.0901, G loss: 10.9488\n",
      "[7932/8000] D loss: 0.2625, G loss: 11.3436\n",
      "train error: \n",
      " D loss: 0.263847, G loss: 10.896315, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.589155, G loss: 15.212273, D accuracy: 91.7%, cell accuracy: 94.3%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0236, G loss: 12.0195\n",
      "[372/8000] D loss: 0.7242, G loss: 5.4228\n",
      "[732/8000] D loss: 0.2333, G loss: 10.7775\n",
      "[1092/8000] D loss: 0.2770, G loss: 10.3637\n",
      "[1452/8000] D loss: 0.2372, G loss: 11.5186\n",
      "[1812/8000] D loss: 0.2098, G loss: 8.6443\n",
      "[2172/8000] D loss: 0.1820, G loss: 11.7019\n",
      "[2532/8000] D loss: 0.1579, G loss: 11.7175\n",
      "[2892/8000] D loss: 0.4763, G loss: 9.3665\n",
      "[3252/8000] D loss: 0.2798, G loss: 11.3097\n",
      "[3612/8000] D loss: 0.1461, G loss: 13.8160\n",
      "[3972/8000] D loss: 0.2759, G loss: 10.8654\n",
      "[4332/8000] D loss: 0.3253, G loss: 10.0602\n",
      "[4692/8000] D loss: 0.3216, G loss: 10.0230\n",
      "[5052/8000] D loss: 0.4455, G loss: 9.9155\n",
      "[5412/8000] D loss: 0.4216, G loss: 10.5122\n",
      "[5772/8000] D loss: 0.1129, G loss: 10.8225\n",
      "[6132/8000] D loss: 0.2989, G loss: 12.3303\n",
      "[6492/8000] D loss: 0.0557, G loss: 15.7678\n",
      "[6852/8000] D loss: 0.2915, G loss: 11.0006\n",
      "[7212/8000] D loss: 0.0600, G loss: 10.5978\n",
      "[7572/8000] D loss: 0.2166, G loss: 13.1448\n",
      "[7932/8000] D loss: 0.3475, G loss: 12.0915\n",
      "train error: \n",
      " D loss: 0.277269, G loss: 10.429283, D accuracy: 91.7%, cell accuracy: 94.8%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.598821, G loss: 14.647783, D accuracy: 91.1%, cell accuracy: 94.4%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2488, G loss: 11.7456\n",
      "[372/8000] D loss: 0.3079, G loss: 8.5688\n",
      "[732/8000] D loss: 0.2381, G loss: 8.0829\n",
      "[1092/8000] D loss: 0.1229, G loss: 12.7970\n",
      "[1452/8000] D loss: 0.3548, G loss: 9.6538\n",
      "[1812/8000] D loss: 0.0021, G loss: 16.7423\n",
      "[2172/8000] D loss: 0.1234, G loss: 16.3020\n",
      "[2532/8000] D loss: 0.2424, G loss: 12.9278\n",
      "[2892/8000] D loss: 0.4709, G loss: 8.0542\n",
      "[3252/8000] D loss: 0.3723, G loss: 9.6954\n",
      "[3612/8000] D loss: 0.4231, G loss: 10.2917\n",
      "[3972/8000] D loss: 0.0305, G loss: 13.3078\n",
      "[4332/8000] D loss: 0.2829, G loss: 9.7178\n",
      "[4692/8000] D loss: 0.0353, G loss: 11.4207\n",
      "[5052/8000] D loss: 0.2239, G loss: 10.1072\n",
      "[5412/8000] D loss: 0.3664, G loss: 11.0246\n",
      "[5772/8000] D loss: 0.1221, G loss: 11.8435\n",
      "[6132/8000] D loss: 0.3736, G loss: 11.9555\n",
      "[6492/8000] D loss: 0.3704, G loss: 9.8131\n",
      "[6852/8000] D loss: 0.3056, G loss: 12.1207\n",
      "[7212/8000] D loss: 0.1683, G loss: 10.0659\n",
      "[7572/8000] D loss: 0.2575, G loss: 8.8808\n",
      "[7932/8000] D loss: 0.1450, G loss: 12.9171\n",
      "train error: \n",
      " D loss: 0.266114, G loss: 10.546916, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 15.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.552071, G loss: 15.266580, D accuracy: 92.0%, cell accuracy: 94.3%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2063, G loss: 17.4187\n",
      "[372/8000] D loss: 0.0010, G loss: 14.6812\n",
      "[732/8000] D loss: 0.4751, G loss: 8.6165\n",
      "[1092/8000] D loss: 0.3827, G loss: 9.0303\n",
      "[1452/8000] D loss: 0.4221, G loss: 9.4775\n",
      "[1812/8000] D loss: 0.0176, G loss: 9.7722\n",
      "[2172/8000] D loss: 0.1722, G loss: 12.5771\n",
      "[2532/8000] D loss: 0.2343, G loss: 16.6771\n",
      "[2892/8000] D loss: 0.4066, G loss: 12.8273\n",
      "[3252/8000] D loss: 0.3753, G loss: 11.9720\n",
      "[3612/8000] D loss: 0.1374, G loss: 14.6104\n",
      "[3972/8000] D loss: 0.4198, G loss: 8.5586\n",
      "[4332/8000] D loss: 0.4062, G loss: 7.8514\n",
      "[4692/8000] D loss: 0.1662, G loss: 8.7738\n",
      "[5052/8000] D loss: 0.1753, G loss: 10.6199\n",
      "[5412/8000] D loss: 0.0856, G loss: 15.1091\n",
      "[5772/8000] D loss: 0.4054, G loss: 13.1908\n",
      "[6132/8000] D loss: 0.1401, G loss: 6.2761\n",
      "[6492/8000] D loss: 0.2887, G loss: 9.8659\n",
      "[6852/8000] D loss: 0.2751, G loss: 11.4279\n",
      "[7212/8000] D loss: 0.2458, G loss: 13.2334\n",
      "[7572/8000] D loss: 0.1926, G loss: 10.6987\n",
      "[7932/8000] D loss: 0.1315, G loss: 9.0214\n",
      "train error: \n",
      " D loss: 0.297334, G loss: 8.791504, D accuracy: 91.5%, cell accuracy: 94.8%, board accuracy: 15.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.473246, G loss: 13.027858, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1250, G loss: 8.1172\n",
      "[372/8000] D loss: 0.2307, G loss: 13.4390\n",
      "[732/8000] D loss: 0.5218, G loss: 8.8971\n",
      "[1092/8000] D loss: 0.2934, G loss: 10.9680\n",
      "[1452/8000] D loss: 0.3946, G loss: 10.4824\n",
      "[1812/8000] D loss: 0.2116, G loss: 10.1267\n",
      "[2172/8000] D loss: 0.1508, G loss: 13.3376\n",
      "[2532/8000] D loss: 0.6602, G loss: 8.8759\n",
      "[2892/8000] D loss: 0.1085, G loss: 14.1565\n",
      "[3252/8000] D loss: 0.2647, G loss: 10.2148\n",
      "[3612/8000] D loss: 0.2598, G loss: 7.4856\n",
      "[3972/8000] D loss: 0.1229, G loss: 12.7134\n",
      "[4332/8000] D loss: 0.3791, G loss: 10.9564\n",
      "[4692/8000] D loss: 0.0009, G loss: 16.7767\n",
      "[5052/8000] D loss: 0.3613, G loss: 12.0358\n",
      "[5412/8000] D loss: 0.3010, G loss: 10.3827\n",
      "[5772/8000] D loss: 0.0181, G loss: 8.6439\n",
      "[6132/8000] D loss: 0.0449, G loss: 15.7852\n",
      "[6492/8000] D loss: 0.0003, G loss: 17.9054\n",
      "[6852/8000] D loss: 0.1593, G loss: 12.3605\n",
      "[7212/8000] D loss: 0.2281, G loss: 10.7372\n",
      "[7572/8000] D loss: 0.3522, G loss: 12.5890\n",
      "[7932/8000] D loss: 0.2597, G loss: 9.6919\n",
      "train error: \n",
      " D loss: 0.273574, G loss: 9.131318, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 15.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.511841, G loss: 13.374546, D accuracy: 92.6%, cell accuracy: 94.3%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2458, G loss: 12.3442\n",
      "[372/8000] D loss: 0.0017, G loss: 14.7052\n",
      "[732/8000] D loss: 0.1265, G loss: 13.0365\n",
      "[1092/8000] D loss: 0.1286, G loss: 16.7984\n",
      "[1452/8000] D loss: 0.1247, G loss: 13.7234\n",
      "[1812/8000] D loss: 0.2574, G loss: 7.5031\n",
      "[2172/8000] D loss: 0.2879, G loss: 10.8142\n",
      "[2532/8000] D loss: 0.4866, G loss: 5.6990\n",
      "[2892/8000] D loss: 0.3065, G loss: 8.6481\n",
      "[3252/8000] D loss: 0.1386, G loss: 9.7083\n",
      "[3612/8000] D loss: 0.1181, G loss: 11.1659\n",
      "[3972/8000] D loss: 0.3972, G loss: 7.9325\n",
      "[4332/8000] D loss: 0.1803, G loss: 11.1362\n",
      "[4692/8000] D loss: 0.0173, G loss: 12.8338\n",
      "[5052/8000] D loss: 0.2637, G loss: 11.6395\n",
      "[5412/8000] D loss: 0.3455, G loss: 8.7161\n",
      "[5772/8000] D loss: 0.1357, G loss: 11.2158\n",
      "[6132/8000] D loss: 0.0725, G loss: 10.9258\n",
      "[6492/8000] D loss: 0.1708, G loss: 11.9927\n",
      "[6852/8000] D loss: 0.2473, G loss: 12.0965\n",
      "[7212/8000] D loss: 0.1773, G loss: 16.9383\n",
      "[7572/8000] D loss: 0.4043, G loss: 9.5885\n",
      "[7932/8000] D loss: 0.4114, G loss: 8.5595\n",
      "train error: \n",
      " D loss: 0.267652, G loss: 12.409844, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 15.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.656385, G loss: 17.087458, D accuracy: 91.2%, cell accuracy: 94.3%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2901, G loss: 12.7470\n",
      "[372/8000] D loss: 0.1154, G loss: 13.4020\n",
      "[732/8000] D loss: 0.1272, G loss: 10.1028\n",
      "[1092/8000] D loss: 0.3914, G loss: 8.7505\n",
      "[1452/8000] D loss: 0.1368, G loss: 11.8896\n",
      "[1812/8000] D loss: 0.1904, G loss: 12.2648\n",
      "[2172/8000] D loss: 0.4007, G loss: 10.4654\n",
      "[2532/8000] D loss: 0.2881, G loss: 9.2736\n",
      "[2892/8000] D loss: 0.5307, G loss: 7.8068\n",
      "[3252/8000] D loss: 0.4848, G loss: 6.6355\n",
      "[3612/8000] D loss: 0.2583, G loss: 9.6597\n",
      "[3972/8000] D loss: 0.7759, G loss: 6.3612\n",
      "[4332/8000] D loss: 0.2636, G loss: 10.5803\n",
      "[4692/8000] D loss: 0.0250, G loss: 11.0892\n",
      "[5052/8000] D loss: 0.3427, G loss: 7.4134\n",
      "[5412/8000] D loss: 0.3047, G loss: 7.3538\n",
      "[5772/8000] D loss: 0.0169, G loss: 13.9320\n",
      "[6132/8000] D loss: 0.2392, G loss: 11.0355\n",
      "[6492/8000] D loss: 0.1648, G loss: 12.8086\n",
      "[6852/8000] D loss: 0.2164, G loss: 12.6556\n",
      "[7212/8000] D loss: 0.3594, G loss: 12.1044\n",
      "[7572/8000] D loss: 0.2653, G loss: 8.0280\n",
      "[7932/8000] D loss: 0.1286, G loss: 11.1066\n",
      "train error: \n",
      " D loss: 0.262104, G loss: 11.099112, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.617929, G loss: 15.478897, D accuracy: 91.6%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1855, G loss: 11.7931\n",
      "[372/8000] D loss: 0.0062, G loss: 14.7927\n",
      "[732/8000] D loss: 0.1209, G loss: 13.8401\n",
      "[1092/8000] D loss: 0.1327, G loss: 14.8221\n",
      "[1452/8000] D loss: 0.2616, G loss: 9.9985\n",
      "[1812/8000] D loss: 0.0821, G loss: 12.7663\n",
      "[2172/8000] D loss: 0.2501, G loss: 11.4282\n",
      "[2532/8000] D loss: 0.1222, G loss: 11.0163\n",
      "[2892/8000] D loss: 0.2743, G loss: 11.8406\n",
      "[3252/8000] D loss: 0.2468, G loss: 10.0576\n",
      "[3612/8000] D loss: 0.0126, G loss: 9.5960\n",
      "[3972/8000] D loss: 0.1243, G loss: 10.6588\n",
      "[4332/8000] D loss: 0.1769, G loss: 11.5753\n",
      "[4692/8000] D loss: 0.0276, G loss: 11.1257\n",
      "[5052/8000] D loss: 0.3617, G loss: 7.7965\n",
      "[5412/8000] D loss: 0.2052, G loss: 9.2196\n",
      "[5772/8000] D loss: 0.4497, G loss: 9.2383\n",
      "[6132/8000] D loss: 0.2670, G loss: 9.6921\n",
      "[6492/8000] D loss: 0.1551, G loss: 11.4476\n",
      "[6852/8000] D loss: 0.1341, G loss: 13.2032\n",
      "[7212/8000] D loss: 0.3066, G loss: 9.0384\n",
      "[7572/8000] D loss: 0.1343, G loss: 9.4221\n",
      "[7932/8000] D loss: 0.2601, G loss: 11.3957\n",
      "train error: \n",
      " D loss: 0.270911, G loss: 10.342773, D accuracy: 91.6%, cell accuracy: 94.8%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.605066, G loss: 14.715029, D accuracy: 90.8%, cell accuracy: 94.3%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1161, G loss: 12.0928\n",
      "[372/8000] D loss: 0.1602, G loss: 14.8546\n",
      "[732/8000] D loss: 0.0579, G loss: 8.7354\n",
      "[1092/8000] D loss: 0.1351, G loss: 12.0213\n",
      "[1452/8000] D loss: 0.2658, G loss: 11.8986\n",
      "[1812/8000] D loss: 0.2041, G loss: 9.7016\n",
      "[2172/8000] D loss: 0.3529, G loss: 9.7556\n",
      "[2532/8000] D loss: 0.3270, G loss: 8.0227\n",
      "[2892/8000] D loss: 0.2446, G loss: 12.1059\n",
      "[3252/8000] D loss: 0.3856, G loss: 15.9590\n",
      "[3612/8000] D loss: 0.3919, G loss: 7.4866\n",
      "[3972/8000] D loss: 0.2886, G loss: 9.0825\n",
      "[4332/8000] D loss: 0.1353, G loss: 12.1292\n",
      "[4692/8000] D loss: 0.4295, G loss: 7.2748\n",
      "[5052/8000] D loss: 0.3705, G loss: 12.4897\n",
      "[5412/8000] D loss: 0.3480, G loss: 8.3698\n",
      "[5772/8000] D loss: 0.5921, G loss: 6.4411\n",
      "[6132/8000] D loss: 0.2729, G loss: 12.9142\n",
      "[6492/8000] D loss: 0.5687, G loss: 9.2408\n",
      "[6852/8000] D loss: 0.2534, G loss: 9.3714\n",
      "[7212/8000] D loss: 0.1267, G loss: 11.3462\n",
      "[7572/8000] D loss: 0.1480, G loss: 11.6994\n",
      "[7932/8000] D loss: 0.1234, G loss: 13.2172\n",
      "train error: \n",
      " D loss: 0.260330, G loss: 11.534616, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603737, G loss: 16.043697, D accuracy: 91.6%, cell accuracy: 94.4%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3099, G loss: 11.3011\n",
      "[372/8000] D loss: 0.0020, G loss: 16.7840\n",
      "[732/8000] D loss: 0.3800, G loss: 9.6758\n",
      "[1092/8000] D loss: 0.4107, G loss: 9.8220\n",
      "[1452/8000] D loss: 0.1928, G loss: 8.7799\n",
      "[1812/8000] D loss: 0.2868, G loss: 9.7717\n",
      "[2172/8000] D loss: 0.2644, G loss: 11.5947\n",
      "[2532/8000] D loss: 0.0036, G loss: 11.6795\n",
      "[2892/8000] D loss: 0.1351, G loss: 13.3804\n",
      "[3252/8000] D loss: 0.3274, G loss: 12.3616\n",
      "[3612/8000] D loss: 0.0106, G loss: 9.6628\n",
      "[3972/8000] D loss: 0.0767, G loss: 10.9899\n",
      "[4332/8000] D loss: 0.2447, G loss: 9.7224\n",
      "[4692/8000] D loss: 0.1480, G loss: 11.8425\n",
      "[5052/8000] D loss: 0.1800, G loss: 11.4875\n",
      "[5412/8000] D loss: 0.0141, G loss: 13.9632\n",
      "[5772/8000] D loss: 0.3791, G loss: 8.6962\n",
      "[6132/8000] D loss: 0.2682, G loss: 14.7129\n",
      "[6492/8000] D loss: 0.5099, G loss: 8.0093\n",
      "[6852/8000] D loss: 0.3745, G loss: 6.5908\n",
      "[7212/8000] D loss: 0.1783, G loss: 10.4420\n",
      "[7572/8000] D loss: 0.5200, G loss: 8.1756\n",
      "[7932/8000] D loss: 0.1809, G loss: 14.2090\n",
      "train error: \n",
      " D loss: 0.272592, G loss: 9.778982, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 15.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.519760, G loss: 14.168191, D accuracy: 92.4%, cell accuracy: 94.3%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2326, G loss: 9.2006\n",
      "[372/8000] D loss: 0.1713, G loss: 11.3187\n",
      "[732/8000] D loss: 0.2504, G loss: 10.8843\n",
      "[1092/8000] D loss: 0.0071, G loss: 13.6721\n",
      "[1452/8000] D loss: 0.3646, G loss: 11.4176\n",
      "[1812/8000] D loss: 0.2370, G loss: 9.1773\n",
      "[2172/8000] D loss: 0.4681, G loss: 9.7477\n",
      "[2532/8000] D loss: 0.3283, G loss: 11.0753\n",
      "[2892/8000] D loss: 0.4024, G loss: 11.2372\n",
      "[3252/8000] D loss: 0.3361, G loss: 8.5836\n",
      "[3612/8000] D loss: 0.3881, G loss: 9.8182\n",
      "[3972/8000] D loss: 0.4736, G loss: 12.8049\n",
      "[4332/8000] D loss: 0.1320, G loss: 14.0627\n",
      "[4692/8000] D loss: 0.3825, G loss: 8.8627\n",
      "[5052/8000] D loss: 0.2453, G loss: 11.8545\n",
      "[5412/8000] D loss: 0.2531, G loss: 10.7758\n",
      "[5772/8000] D loss: 0.3534, G loss: 7.6070\n",
      "[6132/8000] D loss: 0.1195, G loss: 11.3169\n",
      "[6492/8000] D loss: 0.1839, G loss: 7.9597\n",
      "[6852/8000] D loss: 0.3951, G loss: 11.0721\n",
      "[7212/8000] D loss: 0.2358, G loss: 9.3588\n",
      "[7572/8000] D loss: 0.4168, G loss: 9.5231\n",
      "[7932/8000] D loss: 0.2092, G loss: 11.4169\n",
      "train error: \n",
      " D loss: 0.271014, G loss: 10.368361, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609712, G loss: 14.816970, D accuracy: 91.8%, cell accuracy: 94.4%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4755, G loss: 7.7214\n",
      "[372/8000] D loss: 0.2046, G loss: 7.5864\n",
      "[732/8000] D loss: 0.0920, G loss: 10.4121\n",
      "[1092/8000] D loss: 0.4797, G loss: 8.9501\n",
      "[1452/8000] D loss: 0.5497, G loss: 7.6396\n",
      "[1812/8000] D loss: 0.2325, G loss: 10.4633\n",
      "[2172/8000] D loss: 0.2731, G loss: 11.7669\n",
      "[2532/8000] D loss: 0.2399, G loss: 10.4482\n",
      "[2892/8000] D loss: 0.4926, G loss: 5.8452\n",
      "[3252/8000] D loss: 0.0363, G loss: 12.7958\n",
      "[3612/8000] D loss: 0.3818, G loss: 9.0247\n",
      "[3972/8000] D loss: 0.2387, G loss: 11.1549\n",
      "[4332/8000] D loss: 0.2554, G loss: 6.8447\n",
      "[4692/8000] D loss: 0.3338, G loss: 9.6238\n",
      "[5052/8000] D loss: 0.0168, G loss: 12.1691\n",
      "[5412/8000] D loss: 0.3534, G loss: 10.4110\n",
      "[5772/8000] D loss: 0.4863, G loss: 9.3558\n",
      "[6132/8000] D loss: 0.2529, G loss: 9.6129\n",
      "[6492/8000] D loss: 0.3465, G loss: 7.2349\n",
      "[6852/8000] D loss: 0.0029, G loss: 11.3567\n",
      "[7212/8000] D loss: 0.0112, G loss: 10.7552\n",
      "[7572/8000] D loss: 0.2468, G loss: 10.4042\n",
      "[7932/8000] D loss: 0.1469, G loss: 10.3204\n",
      "train error: \n",
      " D loss: 0.268919, G loss: 11.333892, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658174, G loss: 15.795179, D accuracy: 91.1%, cell accuracy: 94.4%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2709, G loss: 12.1137\n",
      "[372/8000] D loss: 0.2463, G loss: 10.4892\n",
      "[732/8000] D loss: 0.5023, G loss: 9.6708\n",
      "[1092/8000] D loss: 0.2426, G loss: 9.8599\n",
      "[1452/8000] D loss: 0.1043, G loss: 13.8260\n",
      "[1812/8000] D loss: 0.2479, G loss: 10.3715\n",
      "[2172/8000] D loss: 0.1390, G loss: 13.6795\n",
      "[2532/8000] D loss: 0.2333, G loss: 10.7973\n",
      "[2892/8000] D loss: 0.2448, G loss: 12.5297\n",
      "[3252/8000] D loss: 0.1252, G loss: 9.4211\n",
      "[3612/8000] D loss: 0.0236, G loss: 12.8999\n",
      "[3972/8000] D loss: 1.2472, G loss: 8.0082\n",
      "[4332/8000] D loss: 0.3726, G loss: 11.9843\n",
      "[4692/8000] D loss: 0.3461, G loss: 10.5735\n",
      "[5052/8000] D loss: 0.3718, G loss: 12.0236\n",
      "[5412/8000] D loss: 0.6019, G loss: 8.3993\n",
      "[5772/8000] D loss: 0.3062, G loss: 10.4624\n",
      "[6132/8000] D loss: 0.4504, G loss: 9.5389\n",
      "[6492/8000] D loss: 0.0158, G loss: 12.6302\n",
      "[6852/8000] D loss: 0.2038, G loss: 9.5726\n",
      "[7212/8000] D loss: 0.4278, G loss: 7.1310\n",
      "[7572/8000] D loss: 0.4173, G loss: 11.7881\n",
      "[7932/8000] D loss: 0.0601, G loss: 8.7477\n",
      "train error: \n",
      " D loss: 0.262057, G loss: 10.714042, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.562743, G loss: 15.172452, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3387, G loss: 12.2748\n",
      "[372/8000] D loss: 0.3513, G loss: 8.5770\n",
      "[732/8000] D loss: 0.1211, G loss: 12.0865\n",
      "[1092/8000] D loss: 0.0259, G loss: 11.0288\n",
      "[1452/8000] D loss: 0.1216, G loss: 11.3380\n",
      "[1812/8000] D loss: 0.0012, G loss: 12.3005\n",
      "[2172/8000] D loss: 0.0103, G loss: 13.1004\n",
      "[2532/8000] D loss: 0.0045, G loss: 17.3343\n",
      "[2892/8000] D loss: 0.1145, G loss: 11.4621\n",
      "[3252/8000] D loss: 0.3742, G loss: 11.2141\n",
      "[3612/8000] D loss: 0.3485, G loss: 7.5470\n",
      "[3972/8000] D loss: 0.2249, G loss: 9.1640\n",
      "[4332/8000] D loss: 0.2417, G loss: 13.4231\n",
      "[4692/8000] D loss: 0.1428, G loss: 12.4017\n",
      "[5052/8000] D loss: 0.1934, G loss: 8.7807\n",
      "[5412/8000] D loss: 0.3009, G loss: 9.8227\n",
      "[5772/8000] D loss: 0.4268, G loss: 8.4999\n",
      "[6132/8000] D loss: 0.4922, G loss: 6.5129\n",
      "[6492/8000] D loss: 0.2730, G loss: 8.6658\n",
      "[6852/8000] D loss: 0.1739, G loss: 7.5006\n",
      "[7212/8000] D loss: 0.2649, G loss: 9.2625\n",
      "[7572/8000] D loss: 0.1837, G loss: 14.6108\n",
      "[7932/8000] D loss: 0.3900, G loss: 12.3141\n",
      "train error: \n",
      " D loss: 0.261959, G loss: 10.654062, D accuracy: 92.1%, cell accuracy: 94.8%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.590714, G loss: 15.023629, D accuracy: 92.0%, cell accuracy: 94.4%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3510, G loss: 11.5970\n",
      "[372/8000] D loss: 0.2353, G loss: 12.4466\n",
      "[732/8000] D loss: 0.4021, G loss: 8.5655\n",
      "[1092/8000] D loss: 0.1704, G loss: 15.6564\n",
      "[1452/8000] D loss: 0.1972, G loss: 9.6425\n",
      "[1812/8000] D loss: 0.0980, G loss: 13.3432\n",
      "[2172/8000] D loss: 0.2918, G loss: 10.5817\n",
      "[2532/8000] D loss: 0.5592, G loss: 9.2062\n",
      "[2892/8000] D loss: 0.2433, G loss: 16.1072\n",
      "[3252/8000] D loss: 0.0083, G loss: 10.8596\n",
      "[3612/8000] D loss: 0.1765, G loss: 12.0700\n",
      "[3972/8000] D loss: 0.1219, G loss: 12.8154\n",
      "[4332/8000] D loss: 0.1576, G loss: 15.1141\n",
      "[4692/8000] D loss: 0.4658, G loss: 8.2690\n",
      "[5052/8000] D loss: 0.3513, G loss: 8.5648\n",
      "[5412/8000] D loss: 0.2707, G loss: 11.6051\n",
      "[5772/8000] D loss: 0.1136, G loss: 13.9467\n",
      "[6132/8000] D loss: 0.3920, G loss: 7.6192\n",
      "[6492/8000] D loss: 0.5247, G loss: 9.3220\n",
      "[6852/8000] D loss: 0.1204, G loss: 12.3063\n",
      "[7212/8000] D loss: 0.3752, G loss: 7.2812\n",
      "[7572/8000] D loss: 0.2501, G loss: 10.2624\n",
      "[7932/8000] D loss: 0.2054, G loss: 11.7620\n",
      "train error: \n",
      " D loss: 0.267205, G loss: 10.134626, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 15.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.587137, G loss: 14.570420, D accuracy: 91.9%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5901, G loss: 5.2803\n",
      "[372/8000] D loss: 0.3485, G loss: 15.2598\n",
      "[732/8000] D loss: 0.1238, G loss: 14.3800\n",
      "[1092/8000] D loss: 0.2712, G loss: 8.8585\n",
      "[1452/8000] D loss: 0.1497, G loss: 11.2980\n",
      "[1812/8000] D loss: 0.1429, G loss: 8.9860\n",
      "[2172/8000] D loss: 0.4700, G loss: 7.6600\n",
      "[2532/8000] D loss: 0.2276, G loss: 8.0201\n",
      "[2892/8000] D loss: 0.1870, G loss: 9.7234\n",
      "[3252/8000] D loss: 0.1262, G loss: 13.2998\n",
      "[3612/8000] D loss: 0.3843, G loss: 8.0164\n",
      "[3972/8000] D loss: 0.3443, G loss: 9.7245\n",
      "[4332/8000] D loss: 0.2517, G loss: 10.4719\n",
      "[4692/8000] D loss: 0.2364, G loss: 13.8366\n",
      "[5052/8000] D loss: 0.1903, G loss: 10.3648\n",
      "[5412/8000] D loss: 0.1932, G loss: 13.1509\n",
      "[5772/8000] D loss: 0.3056, G loss: 11.8694\n",
      "[6132/8000] D loss: 0.2754, G loss: 8.7712\n",
      "[6492/8000] D loss: 0.1173, G loss: 9.2756\n",
      "[6852/8000] D loss: 0.5901, G loss: 6.1648\n",
      "[7212/8000] D loss: 0.3437, G loss: 13.7878\n",
      "[7572/8000] D loss: 0.2621, G loss: 11.9564\n",
      "[7932/8000] D loss: 0.1693, G loss: 12.2862\n",
      "train error: \n",
      " D loss: 0.257543, G loss: 11.281174, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.611323, G loss: 15.900614, D accuracy: 91.4%, cell accuracy: 94.3%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3763, G loss: 9.7023\n",
      "[372/8000] D loss: 0.2367, G loss: 15.1229\n",
      "[732/8000] D loss: 0.7957, G loss: 5.4076\n",
      "[1092/8000] D loss: 0.3392, G loss: 8.1707\n",
      "[1452/8000] D loss: 0.1209, G loss: 14.4017\n",
      "[1812/8000] D loss: 0.0419, G loss: 17.0673\n",
      "[2172/8000] D loss: 0.1235, G loss: 14.6778\n",
      "[2532/8000] D loss: 0.2299, G loss: 12.7136\n",
      "[2892/8000] D loss: 0.2248, G loss: 15.6114\n",
      "[3252/8000] D loss: 0.1693, G loss: 10.0022\n",
      "[3612/8000] D loss: 0.3529, G loss: 10.1308\n",
      "[3972/8000] D loss: 0.2928, G loss: 10.3526\n",
      "[4332/8000] D loss: 0.0014, G loss: 13.4684\n",
      "[4692/8000] D loss: 0.1212, G loss: 14.9599\n",
      "[5052/8000] D loss: 0.2758, G loss: 10.0607\n",
      "[5412/8000] D loss: 0.3571, G loss: 9.8908\n",
      "[5772/8000] D loss: 0.0427, G loss: 14.4139\n",
      "[6132/8000] D loss: 0.2458, G loss: 14.0289\n",
      "[6492/8000] D loss: 0.3557, G loss: 10.9516\n",
      "[6852/8000] D loss: 0.2282, G loss: 9.4743\n",
      "[7212/8000] D loss: 0.2658, G loss: 7.6943\n",
      "[7572/8000] D loss: 0.1770, G loss: 10.6699\n",
      "[7932/8000] D loss: 0.2289, G loss: 11.1036\n",
      "train error: \n",
      " D loss: 0.274073, G loss: 10.558353, D accuracy: 91.6%, cell accuracy: 94.8%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.624010, G loss: 15.071907, D accuracy: 90.9%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0514, G loss: 12.6671\n",
      "[372/8000] D loss: 0.3481, G loss: 6.5432\n",
      "[732/8000] D loss: 0.2356, G loss: 10.8979\n",
      "[1092/8000] D loss: 0.2004, G loss: 13.6102\n",
      "[1452/8000] D loss: 0.5119, G loss: 8.1713\n",
      "[1812/8000] D loss: 0.3256, G loss: 5.1968\n",
      "[2172/8000] D loss: 0.2362, G loss: 15.0820\n",
      "[2532/8000] D loss: 0.1341, G loss: 10.7505\n",
      "[2892/8000] D loss: 0.1164, G loss: 7.4747\n",
      "[3252/8000] D loss: 0.1136, G loss: 12.1817\n",
      "[3612/8000] D loss: 0.5735, G loss: 8.5163\n",
      "[3972/8000] D loss: 0.6290, G loss: 8.5555\n",
      "[4332/8000] D loss: 0.2231, G loss: 13.5923\n",
      "[4692/8000] D loss: 0.1260, G loss: 14.1188\n",
      "[5052/8000] D loss: 0.3618, G loss: 12.6426\n",
      "[5412/8000] D loss: 0.1181, G loss: 13.6184\n",
      "[5772/8000] D loss: 0.2433, G loss: 10.0105\n",
      "[6132/8000] D loss: 0.1417, G loss: 9.7125\n",
      "[6492/8000] D loss: 0.1052, G loss: 15.0500\n",
      "[6852/8000] D loss: 0.9492, G loss: 3.6613\n",
      "[7212/8000] D loss: 0.0828, G loss: 11.7147\n",
      "[7572/8000] D loss: 0.2991, G loss: 11.4570\n",
      "[7932/8000] D loss: 0.5573, G loss: 10.3168\n",
      "train error: \n",
      " D loss: 0.265838, G loss: 11.101522, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 15.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626039, G loss: 15.815979, D accuracy: 91.3%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5203, G loss: 8.8147\n",
      "[372/8000] D loss: 0.0195, G loss: 12.3652\n",
      "[732/8000] D loss: 0.2428, G loss: 15.2223\n",
      "[1092/8000] D loss: 0.1659, G loss: 11.2172\n",
      "[1452/8000] D loss: 0.3161, G loss: 11.5814\n",
      "[1812/8000] D loss: 0.0650, G loss: 9.3764\n",
      "[2172/8000] D loss: 0.4220, G loss: 9.1308\n",
      "[2532/8000] D loss: 0.0459, G loss: 12.2410\n",
      "[2892/8000] D loss: 0.1249, G loss: 13.1957\n",
      "[3252/8000] D loss: 0.2385, G loss: 13.0599\n",
      "[3612/8000] D loss: 0.4664, G loss: 7.9139\n",
      "[3972/8000] D loss: 0.2573, G loss: 10.5488\n",
      "[4332/8000] D loss: 0.2418, G loss: 9.6402\n",
      "[4692/8000] D loss: 0.4128, G loss: 9.0953\n",
      "[5052/8000] D loss: 0.1690, G loss: 10.0918\n",
      "[5412/8000] D loss: 0.3472, G loss: 12.7482\n",
      "[5772/8000] D loss: 0.1441, G loss: 13.2726\n",
      "[6132/8000] D loss: 0.3502, G loss: 13.0240\n",
      "[6492/8000] D loss: 0.3872, G loss: 7.7107\n",
      "[6852/8000] D loss: 0.0144, G loss: 11.7531\n",
      "[7212/8000] D loss: 0.3461, G loss: 9.5393\n",
      "[7572/8000] D loss: 0.2109, G loss: 9.4941\n",
      "[7932/8000] D loss: 0.4073, G loss: 9.2548\n",
      "train error: \n",
      " D loss: 0.268934, G loss: 11.255036, D accuracy: 91.9%, cell accuracy: 94.8%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.598802, G loss: 16.040432, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5225, G loss: 7.9912\n",
      "[372/8000] D loss: 0.0023, G loss: 13.7784\n",
      "[732/8000] D loss: 0.2346, G loss: 10.0046\n",
      "[1092/8000] D loss: 0.1150, G loss: 13.0630\n",
      "[1452/8000] D loss: 0.3207, G loss: 12.7247\n",
      "[1812/8000] D loss: 0.4791, G loss: 8.3226\n",
      "[2172/8000] D loss: 0.2429, G loss: 9.5394\n",
      "[2532/8000] D loss: 0.2466, G loss: 10.5329\n",
      "[2892/8000] D loss: 0.6884, G loss: 7.9016\n",
      "[3252/8000] D loss: 0.2290, G loss: 11.7765\n",
      "[3612/8000] D loss: 0.0018, G loss: 17.2408\n",
      "[3972/8000] D loss: 0.2299, G loss: 14.1817\n",
      "[4332/8000] D loss: 0.3738, G loss: 7.9196\n",
      "[4692/8000] D loss: 0.1599, G loss: 13.1468\n",
      "[5052/8000] D loss: 0.6485, G loss: 7.1049\n",
      "[5412/8000] D loss: 0.0859, G loss: 12.6288\n",
      "[5772/8000] D loss: 0.3101, G loss: 9.3154\n",
      "[6132/8000] D loss: 0.1153, G loss: 14.0905\n",
      "[6492/8000] D loss: 0.1648, G loss: 15.4101\n",
      "[6852/8000] D loss: 0.1793, G loss: 9.6816\n",
      "[7212/8000] D loss: 0.3101, G loss: 8.2444\n",
      "[7572/8000] D loss: 0.5072, G loss: 7.8365\n",
      "[7932/8000] D loss: 0.4886, G loss: 10.2588\n",
      "train error: \n",
      " D loss: 0.265329, G loss: 10.643736, D accuracy: 91.8%, cell accuracy: 94.8%, board accuracy: 15.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.572447, G loss: 15.197667, D accuracy: 91.7%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2492, G loss: 11.0841\n",
      "[372/8000] D loss: 0.2779, G loss: 12.4807\n",
      "[732/8000] D loss: 0.1352, G loss: 13.7672\n",
      "[1092/8000] D loss: 0.0683, G loss: 13.1580\n",
      "[1452/8000] D loss: 0.2307, G loss: 11.6984\n",
      "[1812/8000] D loss: 0.1170, G loss: 13.1651\n",
      "[2172/8000] D loss: 0.5340, G loss: 7.7232\n",
      "[2532/8000] D loss: 0.2649, G loss: 5.5982\n",
      "[2892/8000] D loss: 0.1294, G loss: 13.6592\n",
      "[3252/8000] D loss: 0.1189, G loss: 13.6149\n",
      "[3612/8000] D loss: 0.0101, G loss: 12.5174\n",
      "[3972/8000] D loss: 0.1289, G loss: 14.2084\n",
      "[4332/8000] D loss: 0.2359, G loss: 11.4306\n",
      "[4692/8000] D loss: 0.1552, G loss: 10.9085\n",
      "[5052/8000] D loss: 0.1546, G loss: 10.1055\n",
      "[5412/8000] D loss: 0.0172, G loss: 10.4193\n",
      "[5772/8000] D loss: 0.3541, G loss: 11.3119\n",
      "[6132/8000] D loss: 0.2987, G loss: 9.4542\n",
      "[6492/8000] D loss: 0.5574, G loss: 7.4554\n",
      "[6852/8000] D loss: 0.1302, G loss: 11.1572\n",
      "[7212/8000] D loss: 0.3800, G loss: 11.8900\n",
      "[7572/8000] D loss: 0.3809, G loss: 7.1379\n",
      "[7932/8000] D loss: 0.1752, G loss: 10.4947\n",
      "train error: \n",
      " D loss: 0.264204, G loss: 10.195021, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 14.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.555056, G loss: 14.711409, D accuracy: 92.2%, cell accuracy: 94.3%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1211, G loss: 11.6385\n",
      "[372/8000] D loss: 0.1949, G loss: 8.4060\n",
      "[732/8000] D loss: 0.0195, G loss: 15.3947\n",
      "[1092/8000] D loss: 0.4015, G loss: 7.6724\n",
      "[1452/8000] D loss: 0.1320, G loss: 12.2356\n",
      "[1812/8000] D loss: 0.4521, G loss: 9.8357\n",
      "[2172/8000] D loss: 0.0631, G loss: 14.6222\n",
      "[2532/8000] D loss: 0.4765, G loss: 8.2636\n",
      "[2892/8000] D loss: 0.1616, G loss: 12.4002\n",
      "[3252/8000] D loss: 0.1184, G loss: 11.4364\n",
      "[3612/8000] D loss: 0.3782, G loss: 6.3246\n",
      "[3972/8000] D loss: 0.0148, G loss: 14.7323\n",
      "[4332/8000] D loss: 0.2146, G loss: 9.9845\n",
      "[4692/8000] D loss: 0.2389, G loss: 11.8933\n",
      "[5052/8000] D loss: 0.1321, G loss: 9.4579\n",
      "[5412/8000] D loss: 0.3121, G loss: 7.3424\n",
      "[5772/8000] D loss: 0.0064, G loss: 12.7344\n",
      "[6132/8000] D loss: 0.2869, G loss: 10.8492\n",
      "[6492/8000] D loss: 0.2138, G loss: 7.4657\n",
      "[6852/8000] D loss: 0.2344, G loss: 9.8857\n",
      "[7212/8000] D loss: 0.2455, G loss: 10.7637\n",
      "[7572/8000] D loss: 0.3819, G loss: 9.2564\n",
      "[7932/8000] D loss: 0.3676, G loss: 9.7760\n",
      "train error: \n",
      " D loss: 0.277332, G loss: 10.560435, D accuracy: 91.6%, cell accuracy: 94.8%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.633918, G loss: 15.092825, D accuracy: 90.8%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4915, G loss: 5.9453\n",
      "[372/8000] D loss: 0.2451, G loss: 9.7939\n",
      "[732/8000] D loss: 0.1263, G loss: 9.1761\n",
      "[1092/8000] D loss: 0.2423, G loss: 9.3637\n",
      "[1452/8000] D loss: 0.2477, G loss: 8.4436\n",
      "[1812/8000] D loss: 0.3763, G loss: 13.7660\n",
      "[2172/8000] D loss: 0.2348, G loss: 14.0596\n",
      "[2532/8000] D loss: 0.2534, G loss: 8.8834\n",
      "[2892/8000] D loss: 0.4349, G loss: 7.7417\n",
      "[3252/8000] D loss: 0.2518, G loss: 10.8231\n",
      "[3612/8000] D loss: 0.1777, G loss: 10.4550\n",
      "[3972/8000] D loss: 0.4122, G loss: 9.3823\n",
      "[4332/8000] D loss: 0.4557, G loss: 9.3478\n",
      "[4692/8000] D loss: 0.2384, G loss: 9.3348\n",
      "[5052/8000] D loss: 0.0079, G loss: 16.9723\n",
      "[5412/8000] D loss: 0.1677, G loss: 8.2651\n",
      "[5772/8000] D loss: 0.2279, G loss: 10.3691\n",
      "[6132/8000] D loss: 0.5879, G loss: 9.5802\n",
      "[6492/8000] D loss: 0.4312, G loss: 10.4432\n",
      "[6852/8000] D loss: 0.1255, G loss: 11.8930\n",
      "[7212/8000] D loss: 0.5103, G loss: 10.5261\n",
      "[7572/8000] D loss: 0.2558, G loss: 9.9463\n",
      "[7932/8000] D loss: 0.2588, G loss: 8.4762\n",
      "train error: \n",
      " D loss: 0.268420, G loss: 11.167151, D accuracy: 91.8%, cell accuracy: 94.8%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.620073, G loss: 15.632683, D accuracy: 91.1%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3840, G loss: 11.0132\n",
      "[372/8000] D loss: 0.2365, G loss: 11.3637\n",
      "[732/8000] D loss: 0.2150, G loss: 11.3594\n",
      "[1092/8000] D loss: 0.2458, G loss: 14.2350\n",
      "[1452/8000] D loss: 0.0078, G loss: 13.6658\n",
      "[1812/8000] D loss: 0.3264, G loss: 9.0543\n",
      "[2172/8000] D loss: 0.0068, G loss: 15.6873\n",
      "[2532/8000] D loss: 0.1158, G loss: 14.1698\n",
      "[2892/8000] D loss: 0.4629, G loss: 9.8521\n",
      "[3252/8000] D loss: 0.1832, G loss: 14.3602\n",
      "[3612/8000] D loss: 0.4668, G loss: 8.6141\n",
      "[3972/8000] D loss: 0.3268, G loss: 10.3537\n",
      "[4332/8000] D loss: 0.1759, G loss: 9.1155\n",
      "[4692/8000] D loss: 0.3529, G loss: 11.1731\n",
      "[5052/8000] D loss: 0.4028, G loss: 9.7358\n",
      "[5412/8000] D loss: 0.2459, G loss: 13.0261\n",
      "[5772/8000] D loss: 0.3489, G loss: 8.9445\n",
      "[6132/8000] D loss: 0.2913, G loss: 11.4798\n",
      "[6492/8000] D loss: 0.2766, G loss: 11.0159\n",
      "[6852/8000] D loss: 0.1315, G loss: 11.7779\n",
      "[7212/8000] D loss: 0.2610, G loss: 8.7074\n",
      "[7572/8000] D loss: 0.3249, G loss: 13.3284\n",
      "[7932/8000] D loss: 0.5860, G loss: 6.7549\n",
      "train error: \n",
      " D loss: 0.277051, G loss: 12.303302, D accuracy: 91.7%, cell accuracy: 94.8%, board accuracy: 15.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.700137, G loss: 17.200172, D accuracy: 90.8%, cell accuracy: 94.3%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4214, G loss: 8.1465\n",
      "[372/8000] D loss: 0.1661, G loss: 11.1971\n",
      "[732/8000] D loss: 0.5917, G loss: 8.2039\n",
      "[1092/8000] D loss: 0.1866, G loss: 11.9417\n",
      "[1452/8000] D loss: 0.0787, G loss: 10.1251\n",
      "[1812/8000] D loss: 0.1347, G loss: 12.2880\n",
      "[2172/8000] D loss: 0.1539, G loss: 12.4461\n",
      "[2532/8000] D loss: 0.2415, G loss: 16.4319\n",
      "[2892/8000] D loss: 0.4267, G loss: 9.7097\n",
      "[3252/8000] D loss: 0.3185, G loss: 7.0546\n",
      "[3612/8000] D loss: 0.2535, G loss: 9.8206\n",
      "[3972/8000] D loss: 0.0009, G loss: 14.7485\n",
      "[4332/8000] D loss: 0.0404, G loss: 9.0811\n",
      "[4692/8000] D loss: 0.2676, G loss: 8.3587\n",
      "[5052/8000] D loss: 0.4008, G loss: 8.5040\n",
      "[5412/8000] D loss: 0.0140, G loss: 13.5030\n",
      "[5772/8000] D loss: 0.4863, G loss: 9.5405\n",
      "[6132/8000] D loss: 0.3900, G loss: 6.2872\n",
      "[6492/8000] D loss: 0.0107, G loss: 10.8782\n",
      "[6852/8000] D loss: 0.3589, G loss: 11.0180\n",
      "[7212/8000] D loss: 0.1214, G loss: 20.5782\n",
      "[7572/8000] D loss: 0.3490, G loss: 9.9426\n",
      "[7932/8000] D loss: 0.1446, G loss: 12.2482\n",
      "train error: \n",
      " D loss: 0.259287, G loss: 11.343474, D accuracy: 92.2%, cell accuracy: 94.8%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608189, G loss: 16.115003, D accuracy: 91.3%, cell accuracy: 94.4%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0023, G loss: 15.0315\n",
      "[372/8000] D loss: 0.1392, G loss: 11.8012\n",
      "[732/8000] D loss: 0.2324, G loss: 15.3886\n",
      "[1092/8000] D loss: 0.4888, G loss: 10.2089\n",
      "[1452/8000] D loss: 0.4465, G loss: 7.3860\n",
      "[1812/8000] D loss: 0.0942, G loss: 11.5236\n",
      "[2172/8000] D loss: 0.2411, G loss: 13.1735\n",
      "[2532/8000] D loss: 0.3225, G loss: 9.2409\n",
      "[2892/8000] D loss: 0.3111, G loss: 11.4040\n",
      "[3252/8000] D loss: 0.4134, G loss: 10.6304\n",
      "[3612/8000] D loss: 0.2897, G loss: 12.2431\n",
      "[3972/8000] D loss: 0.0294, G loss: 15.0261\n",
      "[4332/8000] D loss: 0.0177, G loss: 11.5684\n",
      "[4692/8000] D loss: 0.2908, G loss: 15.7447\n",
      "[5052/8000] D loss: 0.2206, G loss: 12.1000\n",
      "[5412/8000] D loss: 0.2475, G loss: 11.2589\n",
      "[5772/8000] D loss: 0.4119, G loss: 6.4519\n",
      "[6132/8000] D loss: 0.4453, G loss: 10.3893\n",
      "[6492/8000] D loss: 0.2392, G loss: 9.2736\n",
      "[6852/8000] D loss: 0.2847, G loss: 9.2963\n",
      "[7212/8000] D loss: 0.1046, G loss: 12.2465\n",
      "[7572/8000] D loss: 0.2967, G loss: 9.5696\n",
      "[7932/8000] D loss: 0.1377, G loss: 14.0054\n",
      "train error: \n",
      " D loss: 0.266626, G loss: 11.128589, D accuracy: 91.7%, cell accuracy: 94.8%, board accuracy: 15.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.621648, G loss: 15.673504, D accuracy: 91.8%, cell accuracy: 94.3%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1346, G loss: 14.6587\n",
      "[372/8000] D loss: 0.1449, G loss: 12.8468\n",
      "[732/8000] D loss: 0.1156, G loss: 15.4269\n",
      "[1092/8000] D loss: 0.0475, G loss: 13.7366\n",
      "[1452/8000] D loss: 0.5133, G loss: 5.8902\n",
      "[1812/8000] D loss: 0.3972, G loss: 9.8792\n",
      "[2172/8000] D loss: 0.3858, G loss: 6.8222\n",
      "[2532/8000] D loss: 0.2761, G loss: 11.5153\n",
      "[2892/8000] D loss: 0.0019, G loss: 12.7839\n",
      "[3252/8000] D loss: 0.1824, G loss: 12.2708\n",
      "[3612/8000] D loss: 0.3749, G loss: 9.0213\n",
      "[3972/8000] D loss: 0.0070, G loss: 13.3783\n",
      "[4332/8000] D loss: 0.0030, G loss: 13.7977\n",
      "[4692/8000] D loss: 0.2601, G loss: 11.7123\n",
      "[5052/8000] D loss: 0.4078, G loss: 10.7269\n",
      "[5412/8000] D loss: 0.0221, G loss: 12.3946\n",
      "[5772/8000] D loss: 0.3546, G loss: 12.2175\n",
      "[6132/8000] D loss: 0.2867, G loss: 9.6956\n",
      "[6492/8000] D loss: 0.2365, G loss: 7.9311\n",
      "[6852/8000] D loss: 0.2372, G loss: 9.8265\n",
      "[7212/8000] D loss: 0.2811, G loss: 9.8694\n",
      "[7572/8000] D loss: 0.2959, G loss: 12.8218\n",
      "[7932/8000] D loss: 0.1070, G loss: 11.0222\n",
      "train error: \n",
      " D loss: 0.270138, G loss: 10.176392, D accuracy: 91.8%, cell accuracy: 94.8%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.574270, G loss: 14.746505, D accuracy: 91.9%, cell accuracy: 94.3%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2834, G loss: 7.8830\n",
      "[372/8000] D loss: 0.0233, G loss: 13.2061\n",
      "[732/8000] D loss: 0.1576, G loss: 12.2668\n",
      "[1092/8000] D loss: 0.1983, G loss: 11.9295\n",
      "[1452/8000] D loss: 0.3594, G loss: 9.3791\n",
      "[1812/8000] D loss: 0.3692, G loss: 11.2389\n",
      "[2172/8000] D loss: 0.3850, G loss: 7.9864\n",
      "[2532/8000] D loss: 0.3731, G loss: 11.8782\n",
      "[2892/8000] D loss: 0.4538, G loss: 9.9606\n",
      "[3252/8000] D loss: 0.3203, G loss: 10.4602\n",
      "[3612/8000] D loss: 0.1188, G loss: 11.4316\n",
      "[3972/8000] D loss: 0.1406, G loss: 14.4659\n",
      "[4332/8000] D loss: 0.5230, G loss: 8.9961\n",
      "[4692/8000] D loss: 0.0972, G loss: 13.8352\n",
      "[5052/8000] D loss: 0.1956, G loss: 13.1452\n",
      "[5412/8000] D loss: 0.5083, G loss: 7.2906\n",
      "[5772/8000] D loss: 0.3396, G loss: 14.1341\n",
      "[6132/8000] D loss: 0.1035, G loss: 14.2532\n",
      "[6492/8000] D loss: 0.2199, G loss: 13.8855\n",
      "[6852/8000] D loss: 0.0062, G loss: 13.9958\n",
      "[7212/8000] D loss: 0.2412, G loss: 10.8084\n",
      "[7572/8000] D loss: 0.1411, G loss: 11.1264\n",
      "[7932/8000] D loss: 0.1355, G loss: 9.4006\n",
      "train error: \n",
      " D loss: 0.265564, G loss: 10.670203, D accuracy: 92.0%, cell accuracy: 94.9%, board accuracy: 15.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.629268, G loss: 15.326249, D accuracy: 91.8%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1459, G loss: 12.8860\n",
      "[372/8000] D loss: 0.4845, G loss: 7.1508\n",
      "[732/8000] D loss: 0.3849, G loss: 11.3782\n",
      "[1092/8000] D loss: 0.3726, G loss: 10.2486\n",
      "[1452/8000] D loss: 0.2662, G loss: 12.2108\n",
      "[1812/8000] D loss: 0.3728, G loss: 12.9787\n",
      "[2172/8000] D loss: 0.1870, G loss: 11.1516\n",
      "[2532/8000] D loss: 0.2386, G loss: 9.3428\n",
      "[2892/8000] D loss: 0.2795, G loss: 13.2166\n",
      "[3252/8000] D loss: 0.2870, G loss: 12.5076\n",
      "[3612/8000] D loss: 0.2378, G loss: 7.8074\n",
      "[3972/8000] D loss: 0.2288, G loss: 8.7244\n",
      "[4332/8000] D loss: 0.1112, G loss: 12.4069\n",
      "[4692/8000] D loss: 0.1755, G loss: 11.7145\n",
      "[5052/8000] D loss: 0.5501, G loss: 7.2245\n",
      "[5412/8000] D loss: 0.1358, G loss: 14.1501\n",
      "[5772/8000] D loss: 0.2635, G loss: 12.4886\n",
      "[6132/8000] D loss: 0.3911, G loss: 11.1557\n",
      "[6492/8000] D loss: 0.3887, G loss: 8.3857\n",
      "[6852/8000] D loss: 0.2325, G loss: 9.3960\n",
      "[7212/8000] D loss: 0.0305, G loss: 12.1807\n",
      "[7572/8000] D loss: 0.1274, G loss: 13.0465\n",
      "[7932/8000] D loss: 0.3784, G loss: 10.3657\n",
      "train error: \n",
      " D loss: 0.265411, G loss: 11.270014, D accuracy: 92.0%, cell accuracy: 94.9%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.623294, G loss: 15.982773, D accuracy: 92.0%, cell accuracy: 94.4%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3252, G loss: 10.4184\n",
      "[372/8000] D loss: 0.6050, G loss: 5.5435\n",
      "[732/8000] D loss: 0.1299, G loss: 10.6644\n",
      "[1092/8000] D loss: 0.7503, G loss: 10.6861\n",
      "[1452/8000] D loss: 0.0085, G loss: 15.7349\n",
      "[1812/8000] D loss: 0.4147, G loss: 8.9743\n",
      "[2172/8000] D loss: 0.2040, G loss: 7.5548\n",
      "[2532/8000] D loss: 0.3287, G loss: 10.3017\n",
      "[2892/8000] D loss: 0.3475, G loss: 8.2319\n",
      "[3252/8000] D loss: 0.2280, G loss: 11.1678\n",
      "[3612/8000] D loss: 0.3612, G loss: 9.7869\n",
      "[3972/8000] D loss: 0.2386, G loss: 12.4085\n",
      "[4332/8000] D loss: 0.2398, G loss: 11.4289\n",
      "[4692/8000] D loss: 0.2337, G loss: 10.5270\n",
      "[5052/8000] D loss: 0.2910, G loss: 10.4764\n",
      "[5412/8000] D loss: 0.1821, G loss: 14.3560\n",
      "[5772/8000] D loss: 0.1752, G loss: 9.6958\n",
      "[6132/8000] D loss: 0.2622, G loss: 11.0184\n",
      "[6492/8000] D loss: 0.1456, G loss: 12.5048\n",
      "[6852/8000] D loss: 0.3644, G loss: 13.7494\n",
      "[7212/8000] D loss: 0.6408, G loss: 7.0093\n",
      "[7572/8000] D loss: 0.0267, G loss: 11.1341\n",
      "[7932/8000] D loss: 0.1208, G loss: 13.1691\n",
      "train error: \n",
      " D loss: 0.266110, G loss: 10.933672, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592754, G loss: 15.700956, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3607, G loss: 10.8112\n",
      "[372/8000] D loss: 0.1176, G loss: 13.1317\n",
      "[732/8000] D loss: 0.4317, G loss: 8.5252\n",
      "[1092/8000] D loss: 0.3788, G loss: 9.5990\n",
      "[1452/8000] D loss: 0.0462, G loss: 17.8371\n",
      "[1812/8000] D loss: 0.1854, G loss: 8.4007\n",
      "[2172/8000] D loss: 0.2338, G loss: 15.4098\n",
      "[2532/8000] D loss: 0.5425, G loss: 8.4315\n",
      "[2892/8000] D loss: 0.2877, G loss: 13.7065\n",
      "[3252/8000] D loss: 0.0087, G loss: 11.6007\n",
      "[3612/8000] D loss: 0.3402, G loss: 10.3928\n",
      "[3972/8000] D loss: 0.4562, G loss: 10.5538\n",
      "[4332/8000] D loss: 0.2215, G loss: 11.5830\n",
      "[4692/8000] D loss: 0.1591, G loss: 8.6250\n",
      "[5052/8000] D loss: 0.1174, G loss: 13.3853\n",
      "[5412/8000] D loss: 0.0012, G loss: 15.9448\n",
      "[5772/8000] D loss: 0.2486, G loss: 9.6849\n",
      "[6132/8000] D loss: 0.0038, G loss: 12.8246\n",
      "[6492/8000] D loss: 0.3044, G loss: 9.6095\n",
      "[6852/8000] D loss: 0.2579, G loss: 12.5268\n",
      "[7212/8000] D loss: 0.2393, G loss: 7.6205\n",
      "[7572/8000] D loss: 0.1294, G loss: 10.2997\n",
      "[7932/8000] D loss: 0.3085, G loss: 8.4915\n",
      "train error: \n",
      " D loss: 0.270126, G loss: 11.324585, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.602752, G loss: 16.076739, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2443, G loss: 10.2181\n",
      "[372/8000] D loss: 0.3057, G loss: 10.3251\n",
      "[732/8000] D loss: 0.0912, G loss: 9.0831\n",
      "[1092/8000] D loss: 0.3582, G loss: 10.2884\n",
      "[1452/8000] D loss: 0.2446, G loss: 8.2832\n",
      "[1812/8000] D loss: 0.4294, G loss: 8.4086\n",
      "[2172/8000] D loss: 0.5361, G loss: 6.6452\n",
      "[2532/8000] D loss: 0.1555, G loss: 10.2857\n",
      "[2892/8000] D loss: 0.4929, G loss: 8.0336\n",
      "[3252/8000] D loss: 0.1777, G loss: 11.3111\n",
      "[3612/8000] D loss: 0.3409, G loss: 9.8685\n",
      "[3972/8000] D loss: 0.1523, G loss: 11.8587\n",
      "[4332/8000] D loss: 0.0396, G loss: 15.2712\n",
      "[4692/8000] D loss: 0.0028, G loss: 14.7826\n",
      "[5052/8000] D loss: 0.2393, G loss: 13.9838\n",
      "[5412/8000] D loss: 0.1118, G loss: 13.9709\n",
      "[5772/8000] D loss: 0.1298, G loss: 8.2213\n",
      "[6132/8000] D loss: 0.3727, G loss: 8.6783\n",
      "[6492/8000] D loss: 0.1551, G loss: 11.5461\n",
      "[6852/8000] D loss: 0.3634, G loss: 6.1162\n",
      "[7212/8000] D loss: 0.1272, G loss: 11.1036\n",
      "[7572/8000] D loss: 0.2245, G loss: 8.3656\n",
      "[7932/8000] D loss: 0.1449, G loss: 14.0307\n",
      "train error: \n",
      " D loss: 0.274539, G loss: 10.430496, D accuracy: 91.9%, cell accuracy: 94.9%, board accuracy: 15.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.577047, G loss: 15.183374, D accuracy: 92.4%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3275, G loss: 10.1037\n",
      "[372/8000] D loss: 0.3642, G loss: 12.4777\n",
      "[732/8000] D loss: 0.2375, G loss: 13.0499\n",
      "[1092/8000] D loss: 0.4473, G loss: 7.0977\n",
      "[1452/8000] D loss: 0.0499, G loss: 15.9613\n",
      "[1812/8000] D loss: 0.0012, G loss: 14.4034\n",
      "[2172/8000] D loss: 0.3840, G loss: 5.8664\n",
      "[2532/8000] D loss: 0.2812, G loss: 10.6092\n",
      "[2892/8000] D loss: 0.3013, G loss: 10.1696\n",
      "[3252/8000] D loss: 0.2779, G loss: 11.5917\n",
      "[3612/8000] D loss: 0.1350, G loss: 8.0387\n",
      "[3972/8000] D loss: 0.0011, G loss: 17.5000\n",
      "[4332/8000] D loss: 0.1104, G loss: 13.4027\n",
      "[4692/8000] D loss: 0.1210, G loss: 13.9087\n",
      "[5052/8000] D loss: 0.2379, G loss: 10.0534\n",
      "[5412/8000] D loss: 0.0820, G loss: 12.3389\n",
      "[5772/8000] D loss: 0.1446, G loss: 11.0593\n",
      "[6132/8000] D loss: 0.1394, G loss: 14.6150\n",
      "[6492/8000] D loss: 0.2174, G loss: 14.0305\n",
      "[6852/8000] D loss: 0.1283, G loss: 12.7204\n",
      "[7212/8000] D loss: 0.3956, G loss: 10.5818\n",
      "[7572/8000] D loss: 0.3536, G loss: 11.7233\n",
      "[7932/8000] D loss: 0.1204, G loss: 11.4708\n",
      "train error: \n",
      " D loss: 0.269571, G loss: 9.768605, D accuracy: 91.9%, cell accuracy: 94.9%, board accuracy: 15.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.539291, G loss: 14.136697, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2490, G loss: 8.8355\n",
      "[372/8000] D loss: 0.0184, G loss: 12.3007\n",
      "[732/8000] D loss: 0.0247, G loss: 11.7371\n",
      "[1092/8000] D loss: 0.3530, G loss: 7.1326\n",
      "[1452/8000] D loss: 0.3195, G loss: 7.5964\n",
      "[1812/8000] D loss: 0.5026, G loss: 5.4221\n",
      "[2172/8000] D loss: 0.2010, G loss: 13.1603\n",
      "[2532/8000] D loss: 0.4892, G loss: 9.1993\n",
      "[2892/8000] D loss: 0.0044, G loss: 12.7936\n",
      "[3252/8000] D loss: 1.0057, G loss: 8.2221\n",
      "[3612/8000] D loss: 0.5201, G loss: 7.8372\n",
      "[3972/8000] D loss: 0.4745, G loss: 7.0630\n",
      "[4332/8000] D loss: 0.2010, G loss: 7.9353\n",
      "[4692/8000] D loss: 0.1784, G loss: 8.7155\n",
      "[5052/8000] D loss: 0.3019, G loss: 8.6099\n",
      "[5412/8000] D loss: 0.0104, G loss: 8.4649\n",
      "[5772/8000] D loss: 0.0352, G loss: 12.4221\n",
      "[6132/8000] D loss: 0.2087, G loss: 12.6760\n",
      "[6492/8000] D loss: 0.2188, G loss: 12.5907\n",
      "[6852/8000] D loss: 0.1232, G loss: 12.5133\n",
      "[7212/8000] D loss: 0.1478, G loss: 11.6965\n",
      "[7572/8000] D loss: 0.1293, G loss: 11.6608\n",
      "[7932/8000] D loss: 0.3463, G loss: 10.6552\n",
      "train error: \n",
      " D loss: 0.263838, G loss: 10.783338, D accuracy: 91.8%, cell accuracy: 94.8%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.574353, G loss: 15.445581, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 6.4% \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2856, G loss: 7.4741\n",
      "[372/8000] D loss: 0.3680, G loss: 11.4364\n",
      "[732/8000] D loss: 0.4228, G loss: 8.1432\n",
      "[1092/8000] D loss: 0.1200, G loss: 10.0952\n",
      "[1452/8000] D loss: 0.2444, G loss: 9.7927\n",
      "[1812/8000] D loss: 0.4191, G loss: 10.2558\n",
      "[2172/8000] D loss: 0.0053, G loss: 18.5463\n",
      "[2532/8000] D loss: 0.3521, G loss: 11.7049\n",
      "[2892/8000] D loss: 0.1216, G loss: 13.9536\n",
      "[3252/8000] D loss: 0.0972, G loss: 11.6078\n",
      "[3612/8000] D loss: 0.3924, G loss: 11.1333\n",
      "[3972/8000] D loss: 0.0054, G loss: 15.6485\n",
      "[4332/8000] D loss: 0.1297, G loss: 9.9570\n",
      "[4692/8000] D loss: 0.2911, G loss: 9.1154\n",
      "[5052/8000] D loss: 0.1172, G loss: 11.7547\n",
      "[5412/8000] D loss: 0.4522, G loss: 5.8863\n",
      "[5772/8000] D loss: 0.3716, G loss: 12.0169\n",
      "[6132/8000] D loss: 0.2883, G loss: 14.9266\n",
      "[6492/8000] D loss: 0.1572, G loss: 10.4361\n",
      "[6852/8000] D loss: 0.4806, G loss: 8.5223\n",
      "[7212/8000] D loss: 0.2410, G loss: 12.7826\n",
      "[7572/8000] D loss: 0.2353, G loss: 11.2882\n",
      "[7932/8000] D loss: 0.2242, G loss: 15.3528\n",
      "train error: \n",
      " D loss: 0.269856, G loss: 12.691683, D accuracy: 91.8%, cell accuracy: 94.8%, board accuracy: 15.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.686674, G loss: 17.558676, D accuracy: 91.6%, cell accuracy: 94.4%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1468, G loss: 13.9361\n",
      "[372/8000] D loss: 0.5397, G loss: 7.0969\n",
      "[732/8000] D loss: 0.1137, G loss: 16.0324\n",
      "[1092/8000] D loss: 0.2398, G loss: 16.3782\n",
      "[1452/8000] D loss: 0.0942, G loss: 11.8394\n",
      "[1812/8000] D loss: 0.4927, G loss: 9.3836\n",
      "[2172/8000] D loss: 0.1254, G loss: 9.4228\n",
      "[2532/8000] D loss: 0.4153, G loss: 8.1263\n",
      "[2892/8000] D loss: 0.3615, G loss: 8.5893\n",
      "[3252/8000] D loss: 0.4186, G loss: 12.1435\n",
      "[3612/8000] D loss: 0.2497, G loss: 9.0809\n",
      "[3972/8000] D loss: 0.3733, G loss: 10.7846\n",
      "[4332/8000] D loss: 0.3594, G loss: 8.1421\n",
      "[4692/8000] D loss: 0.1481, G loss: 14.9260\n",
      "[5052/8000] D loss: 0.5097, G loss: 6.9638\n",
      "[5412/8000] D loss: 0.0360, G loss: 13.6505\n",
      "[5772/8000] D loss: 0.2015, G loss: 10.3078\n",
      "[6132/8000] D loss: 0.1219, G loss: 10.8031\n",
      "[6492/8000] D loss: 0.3242, G loss: 8.9506\n",
      "[6852/8000] D loss: 0.0022, G loss: 13.0143\n",
      "[7212/8000] D loss: 0.2646, G loss: 12.7370\n",
      "[7572/8000] D loss: 0.4848, G loss: 11.3027\n",
      "[7932/8000] D loss: 0.6023, G loss: 5.8293\n",
      "train error: \n",
      " D loss: 0.268119, G loss: 10.625749, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 15.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608172, G loss: 15.126576, D accuracy: 91.6%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2399, G loss: 11.2244\n",
      "[372/8000] D loss: 0.4072, G loss: 6.7695\n",
      "[732/8000] D loss: 0.1390, G loss: 11.7754\n",
      "[1092/8000] D loss: 0.0284, G loss: 12.7639\n",
      "[1452/8000] D loss: 0.1855, G loss: 6.4153\n",
      "[1812/8000] D loss: 0.1220, G loss: 11.3921\n",
      "[2172/8000] D loss: 0.3132, G loss: 10.2293\n",
      "[2532/8000] D loss: 0.3288, G loss: 8.1200\n",
      "[2892/8000] D loss: 0.4193, G loss: 13.9261\n",
      "[3252/8000] D loss: 0.2366, G loss: 9.4761\n",
      "[3612/8000] D loss: 0.4072, G loss: 16.3223\n",
      "[3972/8000] D loss: 0.3323, G loss: 13.1745\n",
      "[4332/8000] D loss: 0.3519, G loss: 10.4178\n",
      "[4692/8000] D loss: 0.0650, G loss: 7.6150\n",
      "[5052/8000] D loss: 0.3658, G loss: 9.8836\n",
      "[5412/8000] D loss: 0.4460, G loss: 9.3230\n",
      "[5772/8000] D loss: 0.1161, G loss: 9.9359\n",
      "[6132/8000] D loss: 0.1601, G loss: 11.4229\n",
      "[6492/8000] D loss: 0.2556, G loss: 12.0545\n",
      "[6852/8000] D loss: 0.0261, G loss: 12.7921\n",
      "[7212/8000] D loss: 0.2436, G loss: 14.2455\n",
      "[7572/8000] D loss: 0.2429, G loss: 11.4253\n",
      "[7932/8000] D loss: 0.3432, G loss: 11.9537\n",
      "train error: \n",
      " D loss: 0.270814, G loss: 10.730763, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 15.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.582041, G loss: 15.281471, D accuracy: 91.7%, cell accuracy: 94.4%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1446, G loss: 14.0774\n",
      "[372/8000] D loss: 0.4204, G loss: 8.2373\n",
      "[732/8000] D loss: 0.3005, G loss: 9.9984\n",
      "[1092/8000] D loss: 0.2304, G loss: 10.9453\n",
      "[1452/8000] D loss: 0.4344, G loss: 4.6652\n",
      "[1812/8000] D loss: 0.4824, G loss: 9.1448\n",
      "[2172/8000] D loss: 0.1418, G loss: 12.6034\n",
      "[2532/8000] D loss: 0.3759, G loss: 7.8595\n",
      "[2892/8000] D loss: 0.3772, G loss: 8.7837\n",
      "[3252/8000] D loss: 0.2316, G loss: 10.8082\n",
      "[3612/8000] D loss: 0.2890, G loss: 10.4330\n",
      "[3972/8000] D loss: 0.1384, G loss: 14.7011\n",
      "[4332/8000] D loss: 0.3899, G loss: 9.4562\n",
      "[4692/8000] D loss: 0.2639, G loss: 11.6423\n",
      "[5052/8000] D loss: 0.0028, G loss: 15.0122\n",
      "[5412/8000] D loss: 0.0057, G loss: 13.3990\n",
      "[5772/8000] D loss: 0.0316, G loss: 19.1227\n",
      "[6132/8000] D loss: 0.1340, G loss: 10.3558\n",
      "[6492/8000] D loss: 0.3716, G loss: 10.0402\n",
      "[6852/8000] D loss: 0.1366, G loss: 16.8053\n",
      "[7212/8000] D loss: 0.2747, G loss: 11.5348\n",
      "[7572/8000] D loss: 0.1229, G loss: 13.7379\n",
      "[7932/8000] D loss: 0.2520, G loss: 13.0768\n",
      "train error: \n",
      " D loss: 0.271458, G loss: 10.596947, D accuracy: 92.0%, cell accuracy: 94.9%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.587176, G loss: 15.155771, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0055, G loss: 15.1324\n",
      "[372/8000] D loss: 0.0039, G loss: 15.8943\n",
      "[732/8000] D loss: 0.0950, G loss: 10.6857\n",
      "[1092/8000] D loss: 0.2372, G loss: 8.4939\n",
      "[1452/8000] D loss: 0.2409, G loss: 8.6722\n",
      "[1812/8000] D loss: 0.0293, G loss: 13.7338\n",
      "[2172/8000] D loss: 0.1180, G loss: 9.2057\n",
      "[2532/8000] D loss: 0.3808, G loss: 10.3465\n",
      "[2892/8000] D loss: 0.0015, G loss: 14.9605\n",
      "[3252/8000] D loss: 0.1625, G loss: 13.4494\n",
      "[3612/8000] D loss: 0.2381, G loss: 11.0664\n",
      "[3972/8000] D loss: 0.3464, G loss: 10.4002\n",
      "[4332/8000] D loss: 0.1838, G loss: 13.7659\n",
      "[4692/8000] D loss: 0.5070, G loss: 9.5309\n",
      "[5052/8000] D loss: 0.1249, G loss: 15.2541\n",
      "[5412/8000] D loss: 0.4360, G loss: 8.3494\n",
      "[5772/8000] D loss: 0.1606, G loss: 11.7687\n",
      "[6132/8000] D loss: 0.2818, G loss: 14.4202\n",
      "[6492/8000] D loss: 0.1349, G loss: 10.7744\n",
      "[6852/8000] D loss: 0.1425, G loss: 8.0096\n",
      "[7212/8000] D loss: 0.2340, G loss: 12.0601\n",
      "[7572/8000] D loss: 0.5560, G loss: 10.4707\n",
      "[7932/8000] D loss: 0.1900, G loss: 9.8427\n",
      "train error: \n",
      " D loss: 0.273809, G loss: 11.734762, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 15.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.666495, G loss: 16.547762, D accuracy: 90.8%, cell accuracy: 94.4%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1399, G loss: 9.7361\n",
      "[372/8000] D loss: 0.1222, G loss: 12.7377\n",
      "[732/8000] D loss: 0.2606, G loss: 12.4789\n",
      "[1092/8000] D loss: 0.0018, G loss: 15.2199\n",
      "[1452/8000] D loss: 0.5302, G loss: 8.2695\n",
      "[1812/8000] D loss: 0.1250, G loss: 12.4545\n",
      "[2172/8000] D loss: 0.2348, G loss: 12.7153\n",
      "[2532/8000] D loss: 0.5264, G loss: 7.4558\n",
      "[2892/8000] D loss: 0.2365, G loss: 13.1931\n",
      "[3252/8000] D loss: 0.1213, G loss: 15.7437\n",
      "[3612/8000] D loss: 0.4206, G loss: 11.7198\n",
      "[3972/8000] D loss: 0.0042, G loss: 12.3035\n",
      "[4332/8000] D loss: 0.4637, G loss: 9.6554\n",
      "[4692/8000] D loss: 0.0091, G loss: 14.0789\n",
      "[5052/8000] D loss: 0.3924, G loss: 11.2887\n",
      "[5412/8000] D loss: 0.1173, G loss: 14.2889\n",
      "[5772/8000] D loss: 0.0031, G loss: 11.5301\n",
      "[6132/8000] D loss: 0.3870, G loss: 12.1123\n",
      "[6492/8000] D loss: 0.4635, G loss: 6.4821\n",
      "[6852/8000] D loss: 0.2548, G loss: 9.0531\n",
      "[7212/8000] D loss: 0.5249, G loss: 9.4445\n",
      "[7572/8000] D loss: 0.2670, G loss: 9.9964\n",
      "[7932/8000] D loss: 0.4130, G loss: 6.6096\n",
      "train error: \n",
      " D loss: 0.266835, G loss: 11.175876, D accuracy: 91.9%, cell accuracy: 94.9%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.607049, G loss: 15.778259, D accuracy: 92.0%, cell accuracy: 94.4%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3446, G loss: 13.9821\n",
      "[372/8000] D loss: 0.2420, G loss: 13.2648\n",
      "[732/8000] D loss: 0.5076, G loss: 7.1546\n",
      "[1092/8000] D loss: 0.1187, G loss: 12.2283\n",
      "[1452/8000] D loss: 0.4361, G loss: 7.0676\n",
      "[1812/8000] D loss: 0.2837, G loss: 10.8410\n",
      "[2172/8000] D loss: 0.1142, G loss: 12.1508\n",
      "[2532/8000] D loss: 0.0038, G loss: 12.2891\n",
      "[2892/8000] D loss: 0.3572, G loss: 16.3320\n",
      "[3252/8000] D loss: 0.2757, G loss: 9.9139\n",
      "[3612/8000] D loss: 0.4771, G loss: 7.6822\n",
      "[3972/8000] D loss: 0.1260, G loss: 13.7027\n",
      "[4332/8000] D loss: 0.1291, G loss: 11.2605\n",
      "[4692/8000] D loss: 0.3069, G loss: 8.0428\n",
      "[5052/8000] D loss: 0.4622, G loss: 6.7324\n",
      "[5412/8000] D loss: 0.3829, G loss: 8.1130\n",
      "[5772/8000] D loss: 0.1787, G loss: 9.6675\n",
      "[6132/8000] D loss: 0.1173, G loss: 13.3269\n",
      "[6492/8000] D loss: 0.3294, G loss: 9.3493\n",
      "[6852/8000] D loss: 0.2562, G loss: 8.5156\n",
      "[7212/8000] D loss: 0.2714, G loss: 8.2883\n",
      "[7572/8000] D loss: 0.2500, G loss: 10.1708\n",
      "[7932/8000] D loss: 0.2853, G loss: 11.9242\n",
      "train error: \n",
      " D loss: 0.275229, G loss: 10.085961, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.540975, G loss: 14.717343, D accuracy: 92.3%, cell accuracy: 94.4%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3094, G loss: 9.6463\n",
      "[372/8000] D loss: 0.4373, G loss: 9.0290\n",
      "[732/8000] D loss: 0.6550, G loss: 4.4832\n",
      "[1092/8000] D loss: 0.4556, G loss: 12.2418\n",
      "[1452/8000] D loss: 0.1442, G loss: 14.1128\n",
      "[1812/8000] D loss: 0.0562, G loss: 10.6435\n",
      "[2172/8000] D loss: 0.2878, G loss: 9.0369\n",
      "[2532/8000] D loss: 0.2830, G loss: 9.0925\n",
      "[2892/8000] D loss: 0.0987, G loss: 12.7979\n",
      "[3252/8000] D loss: 0.3594, G loss: 10.7604\n",
      "[3612/8000] D loss: 0.0079, G loss: 13.0759\n",
      "[3972/8000] D loss: 0.3005, G loss: 7.9251\n",
      "[4332/8000] D loss: 0.4227, G loss: 10.0843\n",
      "[4692/8000] D loss: 0.4492, G loss: 9.1068\n",
      "[5052/8000] D loss: 0.0029, G loss: 13.2590\n",
      "[5412/8000] D loss: 0.1562, G loss: 9.7832\n",
      "[5772/8000] D loss: 0.0765, G loss: 11.6293\n",
      "[6132/8000] D loss: 0.3688, G loss: 10.8561\n",
      "[6492/8000] D loss: 0.2987, G loss: 8.4874\n",
      "[6852/8000] D loss: 0.2845, G loss: 11.8377\n",
      "[7212/8000] D loss: 0.3082, G loss: 11.6382\n",
      "[7572/8000] D loss: 0.0266, G loss: 14.1372\n",
      "[7932/8000] D loss: 0.2247, G loss: 7.5894\n",
      "train error: \n",
      " D loss: 0.270855, G loss: 10.475609, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.591600, G loss: 15.203995, D accuracy: 92.0%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2449, G loss: 10.5962\n",
      "[372/8000] D loss: 0.3296, G loss: 14.0616\n",
      "[732/8000] D loss: 0.1247, G loss: 13.5238\n",
      "[1092/8000] D loss: 0.0640, G loss: 14.5819\n",
      "[1452/8000] D loss: 0.4808, G loss: 12.3605\n",
      "[1812/8000] D loss: 0.1660, G loss: 11.3412\n",
      "[2172/8000] D loss: 0.0023, G loss: 14.0962\n",
      "[2532/8000] D loss: 0.2519, G loss: 11.1048\n",
      "[2892/8000] D loss: 0.3476, G loss: 9.6783\n",
      "[3252/8000] D loss: 0.5366, G loss: 9.3669\n",
      "[3612/8000] D loss: 0.2832, G loss: 10.5731\n",
      "[3972/8000] D loss: 0.3970, G loss: 8.5603\n",
      "[4332/8000] D loss: 0.3859, G loss: 10.7654\n",
      "[4692/8000] D loss: 0.1605, G loss: 12.1981\n",
      "[5052/8000] D loss: 0.1522, G loss: 16.8404\n",
      "[5412/8000] D loss: 0.2374, G loss: 11.7634\n",
      "[5772/8000] D loss: 0.4937, G loss: 7.8505\n",
      "[6132/8000] D loss: 0.1399, G loss: 12.7204\n",
      "[6492/8000] D loss: 0.2921, G loss: 10.4838\n",
      "[6852/8000] D loss: 0.1235, G loss: 12.8882\n",
      "[7212/8000] D loss: 0.1413, G loss: 9.5554\n",
      "[7572/8000] D loss: 0.1180, G loss: 12.4222\n",
      "[7932/8000] D loss: 0.2214, G loss: 12.8334\n",
      "train error: \n",
      " D loss: 0.270038, G loss: 11.938495, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 15.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.648758, G loss: 16.651418, D accuracy: 91.8%, cell accuracy: 94.4%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0232, G loss: 12.3153\n",
      "[372/8000] D loss: 0.3669, G loss: 8.1711\n",
      "[732/8000] D loss: 0.2369, G loss: 14.0955\n",
      "[1092/8000] D loss: 0.1095, G loss: 14.7279\n",
      "[1452/8000] D loss: 0.1361, G loss: 10.3165\n",
      "[1812/8000] D loss: 0.0919, G loss: 15.6193\n",
      "[2172/8000] D loss: 0.2331, G loss: 13.4069\n",
      "[2532/8000] D loss: 0.3178, G loss: 8.9865\n",
      "[2892/8000] D loss: 0.1919, G loss: 7.6444\n",
      "[3252/8000] D loss: 0.4388, G loss: 7.2069\n",
      "[3612/8000] D loss: 0.2964, G loss: 10.9218\n",
      "[3972/8000] D loss: 0.4869, G loss: 11.1152\n",
      "[4332/8000] D loss: 0.4778, G loss: 7.4414\n",
      "[4692/8000] D loss: 0.2800, G loss: 11.4800\n",
      "[5052/8000] D loss: 0.3265, G loss: 7.3901\n",
      "[5412/8000] D loss: 0.3552, G loss: 11.9804\n",
      "[5772/8000] D loss: 0.2068, G loss: 15.2913\n",
      "[6132/8000] D loss: 0.2896, G loss: 9.6621\n",
      "[6492/8000] D loss: 0.6085, G loss: 7.4684\n",
      "[6852/8000] D loss: 0.1717, G loss: 11.3814\n",
      "[7212/8000] D loss: 0.1325, G loss: 9.7373\n",
      "[7572/8000] D loss: 0.1215, G loss: 11.2353\n",
      "[7932/8000] D loss: 0.0888, G loss: 9.7205\n",
      "train error: \n",
      " D loss: 0.261869, G loss: 10.914358, D accuracy: 92.0%, cell accuracy: 94.8%, board accuracy: 15.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592355, G loss: 15.842500, D accuracy: 91.7%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2829, G loss: 12.7878\n",
      "[372/8000] D loss: 0.2395, G loss: 13.5158\n",
      "[732/8000] D loss: 0.2531, G loss: 9.5300\n",
      "[1092/8000] D loss: 0.1288, G loss: 11.3374\n",
      "[1452/8000] D loss: 0.3182, G loss: 10.6954\n",
      "[1812/8000] D loss: 0.2679, G loss: 12.9220\n",
      "[2172/8000] D loss: 0.3775, G loss: 12.4591\n",
      "[2532/8000] D loss: 0.0217, G loss: 14.1973\n",
      "[2892/8000] D loss: 0.3647, G loss: 10.3581\n",
      "[3252/8000] D loss: 0.0041, G loss: 13.7936\n",
      "[3612/8000] D loss: 0.0273, G loss: 12.2476\n",
      "[3972/8000] D loss: 0.2236, G loss: 7.9163\n",
      "[4332/8000] D loss: 0.4081, G loss: 9.1679\n",
      "[4692/8000] D loss: 0.2943, G loss: 9.5446\n",
      "[5052/8000] D loss: 0.1553, G loss: 7.9151\n",
      "[5412/8000] D loss: 0.2791, G loss: 13.4773\n",
      "[5772/8000] D loss: 0.1599, G loss: 13.8351\n",
      "[6132/8000] D loss: 0.3398, G loss: 11.4092\n",
      "[6492/8000] D loss: 0.3544, G loss: 12.7865\n",
      "[6852/8000] D loss: 0.1806, G loss: 10.5252\n",
      "[7212/8000] D loss: 0.2364, G loss: 11.5946\n",
      "[7572/8000] D loss: 0.2469, G loss: 9.8566\n",
      "[7932/8000] D loss: 0.2610, G loss: 9.4014\n",
      "train error: \n",
      " D loss: 0.270701, G loss: 10.684536, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.605250, G loss: 15.385816, D accuracy: 91.8%, cell accuracy: 94.4%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2555, G loss: 14.7850\n",
      "[372/8000] D loss: 0.3506, G loss: 13.2767\n",
      "[732/8000] D loss: 0.1824, G loss: 14.8994\n",
      "[1092/8000] D loss: 0.2939, G loss: 11.0151\n",
      "[1452/8000] D loss: 0.2530, G loss: 11.1446\n",
      "[1812/8000] D loss: 0.3491, G loss: 12.7904\n",
      "[2172/8000] D loss: 0.3558, G loss: 10.3325\n",
      "[2532/8000] D loss: 0.3858, G loss: 8.6662\n",
      "[2892/8000] D loss: 0.0291, G loss: 10.4345\n",
      "[3252/8000] D loss: 0.3078, G loss: 13.0929\n",
      "[3612/8000] D loss: 0.3501, G loss: 9.0389\n",
      "[3972/8000] D loss: 0.2777, G loss: 8.6792\n",
      "[4332/8000] D loss: 0.5402, G loss: 12.3801\n",
      "[4692/8000] D loss: 0.3024, G loss: 10.0138\n",
      "[5052/8000] D loss: 0.0058, G loss: 15.1548\n",
      "[5412/8000] D loss: 0.0101, G loss: 11.9658\n",
      "[5772/8000] D loss: 0.3069, G loss: 11.4507\n",
      "[6132/8000] D loss: 0.0179, G loss: 12.9246\n",
      "[6492/8000] D loss: 0.3408, G loss: 14.0347\n",
      "[6852/8000] D loss: 0.2912, G loss: 8.5282\n",
      "[7212/8000] D loss: 0.5734, G loss: 11.0845\n",
      "[7572/8000] D loss: 0.2684, G loss: 11.8557\n",
      "[7932/8000] D loss: 0.2298, G loss: 11.8326\n",
      "train error: \n",
      " D loss: 0.272524, G loss: 11.394383, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.618886, G loss: 16.206825, D accuracy: 92.0%, cell accuracy: 94.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0095, G loss: 12.3128\n",
      "[372/8000] D loss: 0.4991, G loss: 9.6836\n",
      "[732/8000] D loss: 0.1540, G loss: 10.0799\n",
      "[1092/8000] D loss: 0.3489, G loss: 7.0096\n",
      "[1452/8000] D loss: 0.4103, G loss: 11.2073\n",
      "[1812/8000] D loss: 0.5931, G loss: 6.3608\n",
      "[2172/8000] D loss: 0.2187, G loss: 11.9726\n",
      "[2532/8000] D loss: 0.3572, G loss: 13.3035\n",
      "[2892/8000] D loss: 0.2678, G loss: 8.9875\n",
      "[3252/8000] D loss: 0.4527, G loss: 11.8779\n",
      "[3612/8000] D loss: 0.2377, G loss: 11.5710\n",
      "[3972/8000] D loss: 0.1373, G loss: 16.6447\n",
      "[4332/8000] D loss: 0.2224, G loss: 13.5259\n",
      "[4692/8000] D loss: 0.1310, G loss: 12.4505\n",
      "[5052/8000] D loss: 0.2971, G loss: 11.9399\n",
      "[5412/8000] D loss: 0.6164, G loss: 8.9373\n",
      "[5772/8000] D loss: 0.0003, G loss: 14.6228\n",
      "[6132/8000] D loss: 0.2802, G loss: 12.6788\n",
      "[6492/8000] D loss: 0.6299, G loss: 5.5904\n",
      "[6852/8000] D loss: 0.1767, G loss: 13.3824\n",
      "[7212/8000] D loss: 0.2493, G loss: 9.5161\n",
      "[7572/8000] D loss: 0.1172, G loss: 15.1990\n",
      "[7932/8000] D loss: 0.1514, G loss: 9.8329\n",
      "train error: \n",
      " D loss: 0.287641, G loss: 10.445579, D accuracy: 91.4%, cell accuracy: 94.9%, board accuracy: 15.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.602114, G loss: 14.970298, D accuracy: 90.7%, cell accuracy: 94.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2950, G loss: 5.5262\n",
      "[372/8000] D loss: 0.1378, G loss: 10.9290\n",
      "[732/8000] D loss: 0.1289, G loss: 12.2157\n",
      "[1092/8000] D loss: 0.4724, G loss: 9.7932\n",
      "[1452/8000] D loss: 0.2378, G loss: 12.2136\n",
      "[1812/8000] D loss: 0.2565, G loss: 13.1581\n",
      "[2172/8000] D loss: 0.2924, G loss: 9.5126\n",
      "[2532/8000] D loss: 0.2414, G loss: 9.2169\n",
      "[2892/8000] D loss: 0.3482, G loss: 8.0768\n",
      "[3252/8000] D loss: 0.2445, G loss: 10.3224\n",
      "[3612/8000] D loss: 0.3224, G loss: 11.8146\n",
      "[3972/8000] D loss: 0.2361, G loss: 10.5939\n",
      "[4332/8000] D loss: 0.1989, G loss: 12.4812\n",
      "[4692/8000] D loss: 0.1234, G loss: 12.0657\n",
      "[5052/8000] D loss: 0.3310, G loss: 13.5696\n",
      "[5412/8000] D loss: 0.0380, G loss: 13.0772\n",
      "[5772/8000] D loss: 0.1651, G loss: 14.2107\n",
      "[6132/8000] D loss: 0.3233, G loss: 9.6642\n",
      "[6492/8000] D loss: 0.2438, G loss: 14.9735\n",
      "[6852/8000] D loss: 0.1349, G loss: 14.5776\n",
      "[7212/8000] D loss: 0.4595, G loss: 5.1557\n",
      "[7572/8000] D loss: 0.2606, G loss: 11.1020\n",
      "[7932/8000] D loss: 0.1865, G loss: 11.3873\n",
      "train error: \n",
      " D loss: 0.269096, G loss: 11.436213, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.611820, G loss: 16.253412, D accuracy: 91.8%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2430, G loss: 14.1679\n",
      "[372/8000] D loss: 0.5077, G loss: 10.7341\n",
      "[732/8000] D loss: 0.2022, G loss: 10.5403\n",
      "[1092/8000] D loss: 0.3919, G loss: 10.3498\n",
      "[1452/8000] D loss: 0.3425, G loss: 11.0016\n",
      "[1812/8000] D loss: 0.1393, G loss: 14.3995\n",
      "[2172/8000] D loss: 0.1282, G loss: 16.9709\n",
      "[2532/8000] D loss: 0.1287, G loss: 16.5368\n",
      "[2892/8000] D loss: 0.2595, G loss: 8.9657\n",
      "[3252/8000] D loss: 0.2290, G loss: 11.8424\n",
      "[3612/8000] D loss: 0.0017, G loss: 17.9225\n",
      "[3972/8000] D loss: 0.3417, G loss: 8.7018\n",
      "[4332/8000] D loss: 0.4578, G loss: 11.6402\n",
      "[4692/8000] D loss: 0.2333, G loss: 10.5151\n",
      "[5052/8000] D loss: 0.1009, G loss: 14.9329\n",
      "[5412/8000] D loss: 0.2131, G loss: 10.7065\n",
      "[5772/8000] D loss: 0.0725, G loss: 12.8222\n",
      "[6132/8000] D loss: 0.3203, G loss: 12.4032\n",
      "[6492/8000] D loss: 0.1189, G loss: 16.5121\n",
      "[6852/8000] D loss: 0.0115, G loss: 13.2292\n",
      "[7212/8000] D loss: 0.0959, G loss: 8.2075\n",
      "[7572/8000] D loss: 0.1257, G loss: 11.7399\n",
      "[7932/8000] D loss: 0.0670, G loss: 11.1048\n",
      "train error: \n",
      " D loss: 0.280488, G loss: 10.013653, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.563169, G loss: 14.571652, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2285, G loss: 12.0723\n",
      "[372/8000] D loss: 0.5969, G loss: 8.0217\n",
      "[732/8000] D loss: 0.1371, G loss: 15.5506\n",
      "[1092/8000] D loss: 0.0519, G loss: 11.3472\n",
      "[1452/8000] D loss: 0.1232, G loss: 12.0465\n",
      "[1812/8000] D loss: 0.0057, G loss: 14.2996\n",
      "[2172/8000] D loss: 0.3495, G loss: 11.1385\n",
      "[2532/8000] D loss: 0.3254, G loss: 6.6792\n",
      "[2892/8000] D loss: 0.1426, G loss: 10.8690\n",
      "[3252/8000] D loss: 0.2782, G loss: 11.0358\n",
      "[3612/8000] D loss: 0.4878, G loss: 8.7851\n",
      "[3972/8000] D loss: 0.4701, G loss: 9.1210\n",
      "[4332/8000] D loss: 0.2822, G loss: 13.9022\n",
      "[4692/8000] D loss: 0.3585, G loss: 8.9334\n",
      "[5052/8000] D loss: 0.7546, G loss: 6.3411\n",
      "[5412/8000] D loss: 0.3646, G loss: 13.6981\n",
      "[5772/8000] D loss: 0.3631, G loss: 10.3290\n",
      "[6132/8000] D loss: 0.1798, G loss: 10.8065\n",
      "[6492/8000] D loss: 0.5546, G loss: 10.4986\n",
      "[6852/8000] D loss: 0.2674, G loss: 9.5538\n",
      "[7212/8000] D loss: 0.2271, G loss: 15.6928\n",
      "[7572/8000] D loss: 0.1677, G loss: 9.5353\n",
      "[7932/8000] D loss: 0.2676, G loss: 9.6821\n",
      "train error: \n",
      " D loss: 0.269103, G loss: 10.786953, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.557012, G loss: 15.622421, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1286, G loss: 11.6735\n",
      "[372/8000] D loss: 0.1877, G loss: 12.7183\n",
      "[732/8000] D loss: 0.4848, G loss: 12.0290\n",
      "[1092/8000] D loss: 0.3540, G loss: 8.4454\n",
      "[1452/8000] D loss: 0.2648, G loss: 11.1126\n",
      "[1812/8000] D loss: 0.2503, G loss: 12.7126\n",
      "[2172/8000] D loss: 0.1281, G loss: 18.1823\n",
      "[2532/8000] D loss: 0.0250, G loss: 14.1162\n",
      "[2892/8000] D loss: 0.1554, G loss: 13.7598\n",
      "[3252/8000] D loss: 0.2330, G loss: 10.1641\n",
      "[3612/8000] D loss: 0.0034, G loss: 16.5067\n",
      "[3972/8000] D loss: 0.4662, G loss: 8.0050\n",
      "[4332/8000] D loss: 0.2372, G loss: 9.4569\n",
      "[4692/8000] D loss: 0.3651, G loss: 9.8626\n",
      "[5052/8000] D loss: 0.4230, G loss: 7.7852\n",
      "[5412/8000] D loss: 0.0021, G loss: 11.2647\n",
      "[5772/8000] D loss: 0.2428, G loss: 10.0275\n",
      "[6132/8000] D loss: 0.0017, G loss: 15.0171\n",
      "[6492/8000] D loss: 0.1187, G loss: 16.4110\n",
      "[6852/8000] D loss: 0.4610, G loss: 11.6067\n",
      "[7212/8000] D loss: 0.1613, G loss: 10.7835\n",
      "[7572/8000] D loss: 0.3042, G loss: 10.4833\n",
      "[7932/8000] D loss: 0.1724, G loss: 13.8296\n",
      "train error: \n",
      " D loss: 0.275259, G loss: 10.910614, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.577940, G loss: 15.594377, D accuracy: 91.6%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2939, G loss: 10.6238\n",
      "[372/8000] D loss: 0.4437, G loss: 10.8900\n",
      "[732/8000] D loss: 0.5237, G loss: 7.8894\n",
      "[1092/8000] D loss: 0.3339, G loss: 9.5652\n",
      "[1452/8000] D loss: 0.3480, G loss: 9.3412\n",
      "[1812/8000] D loss: 0.2586, G loss: 12.1348\n",
      "[2172/8000] D loss: 0.4960, G loss: 9.3971\n",
      "[2532/8000] D loss: 0.1251, G loss: 15.1023\n",
      "[2892/8000] D loss: 0.2637, G loss: 16.1808\n",
      "[3252/8000] D loss: 0.2542, G loss: 8.1386\n",
      "[3612/8000] D loss: 0.3118, G loss: 8.5311\n",
      "[3972/8000] D loss: 0.2413, G loss: 13.4865\n",
      "[4332/8000] D loss: 0.5638, G loss: 5.9914\n",
      "[4692/8000] D loss: 0.1172, G loss: 13.0613\n",
      "[5052/8000] D loss: 0.3599, G loss: 11.8166\n",
      "[5412/8000] D loss: 0.3288, G loss: 9.1752\n",
      "[5772/8000] D loss: 0.2746, G loss: 12.0463\n",
      "[6132/8000] D loss: 0.1085, G loss: 10.4328\n",
      "[6492/8000] D loss: 0.2825, G loss: 9.6987\n",
      "[6852/8000] D loss: 0.1198, G loss: 11.2808\n",
      "[7212/8000] D loss: 0.2328, G loss: 10.6609\n",
      "[7572/8000] D loss: 0.1183, G loss: 13.5539\n",
      "[7932/8000] D loss: 0.0031, G loss: 14.4804\n",
      "train error: \n",
      " D loss: 0.271608, G loss: 10.933001, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.565352, G loss: 15.876777, D accuracy: 92.3%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3267, G loss: 8.7696\n",
      "[372/8000] D loss: 0.2631, G loss: 11.9353\n",
      "[732/8000] D loss: 0.3167, G loss: 11.4517\n",
      "[1092/8000] D loss: 0.1452, G loss: 12.5330\n",
      "[1452/8000] D loss: 0.1959, G loss: 6.7224\n",
      "[1812/8000] D loss: 0.2522, G loss: 10.6882\n",
      "[2172/8000] D loss: 0.2410, G loss: 6.7984\n",
      "[2532/8000] D loss: 0.0220, G loss: 8.0687\n",
      "[2892/8000] D loss: 0.4678, G loss: 10.9573\n",
      "[3252/8000] D loss: 0.3409, G loss: 8.2362\n",
      "[3612/8000] D loss: 0.1216, G loss: 13.9110\n",
      "[3972/8000] D loss: 0.2530, G loss: 13.8175\n",
      "[4332/8000] D loss: 0.5450, G loss: 10.3873\n",
      "[4692/8000] D loss: 0.4652, G loss: 9.7078\n",
      "[5052/8000] D loss: 0.5427, G loss: 13.1286\n",
      "[5412/8000] D loss: 0.2518, G loss: 8.1131\n",
      "[5772/8000] D loss: 0.2105, G loss: 12.9361\n",
      "[6132/8000] D loss: 0.3046, G loss: 8.0020\n",
      "[6492/8000] D loss: 0.2594, G loss: 12.6034\n",
      "[6852/8000] D loss: 0.1782, G loss: 12.3071\n",
      "[7212/8000] D loss: 0.2417, G loss: 14.0702\n",
      "[7572/8000] D loss: 0.3289, G loss: 11.9717\n",
      "[7932/8000] D loss: 0.1399, G loss: 13.2263\n",
      "train error: \n",
      " D loss: 0.272103, G loss: 12.684945, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.660675, G loss: 17.887217, D accuracy: 91.5%, cell accuracy: 94.4%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2340, G loss: 11.0213\n",
      "[372/8000] D loss: 0.0250, G loss: 15.0776\n",
      "[732/8000] D loss: 0.1789, G loss: 12.0255\n",
      "[1092/8000] D loss: 0.1326, G loss: 14.9110\n",
      "[1452/8000] D loss: 0.2208, G loss: 11.2492\n",
      "[1812/8000] D loss: 0.4219, G loss: 8.9509\n",
      "[2172/8000] D loss: 0.5239, G loss: 10.0923\n",
      "[2532/8000] D loss: 0.3803, G loss: 11.3499\n",
      "[2892/8000] D loss: 0.5006, G loss: 11.7357\n",
      "[3252/8000] D loss: 0.3287, G loss: 10.5558\n",
      "[3612/8000] D loss: 0.2340, G loss: 15.1573\n",
      "[3972/8000] D loss: 0.1876, G loss: 9.5732\n",
      "[4332/8000] D loss: 0.3601, G loss: 9.3873\n",
      "[4692/8000] D loss: 0.7029, G loss: 8.4912\n",
      "[5052/8000] D loss: 0.5874, G loss: 8.8205\n",
      "[5412/8000] D loss: 0.2735, G loss: 10.0482\n",
      "[5772/8000] D loss: 0.3576, G loss: 10.7474\n",
      "[6132/8000] D loss: 0.2619, G loss: 14.6453\n",
      "[6492/8000] D loss: 0.1513, G loss: 10.1026\n",
      "[6852/8000] D loss: 0.0075, G loss: 13.9051\n",
      "[7212/8000] D loss: 0.0559, G loss: 13.4490\n",
      "[7572/8000] D loss: 0.1569, G loss: 17.9939\n",
      "[7932/8000] D loss: 0.5280, G loss: 11.4455\n",
      "train error: \n",
      " D loss: 0.270632, G loss: 10.952698, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626535, G loss: 15.743552, D accuracy: 91.6%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2486, G loss: 9.8813\n",
      "[372/8000] D loss: 0.5348, G loss: 10.8237\n",
      "[732/8000] D loss: 0.1583, G loss: 9.8203\n",
      "[1092/8000] D loss: 0.2767, G loss: 8.8601\n",
      "[1452/8000] D loss: 0.0241, G loss: 11.0779\n",
      "[1812/8000] D loss: 0.4173, G loss: 8.7724\n",
      "[2172/8000] D loss: 0.5347, G loss: 7.4244\n",
      "[2532/8000] D loss: 0.0178, G loss: 14.1331\n",
      "[2892/8000] D loss: 0.4667, G loss: 8.9606\n",
      "[3252/8000] D loss: 0.0596, G loss: 16.9933\n",
      "[3612/8000] D loss: 0.0404, G loss: 8.3460\n",
      "[3972/8000] D loss: 0.2550, G loss: 11.9419\n",
      "[4332/8000] D loss: 0.3973, G loss: 12.6991\n",
      "[4692/8000] D loss: 0.2010, G loss: 9.0784\n",
      "[5052/8000] D loss: 0.4988, G loss: 12.1600\n",
      "[5412/8000] D loss: 0.4061, G loss: 6.8832\n",
      "[5772/8000] D loss: 0.2002, G loss: 12.6558\n",
      "[6132/8000] D loss: 0.1278, G loss: 14.6931\n",
      "[6492/8000] D loss: 0.4813, G loss: 11.2057\n",
      "[6852/8000] D loss: 0.2119, G loss: 10.6393\n",
      "[7212/8000] D loss: 0.7036, G loss: 6.7490\n",
      "[7572/8000] D loss: 0.1600, G loss: 11.2908\n",
      "[7932/8000] D loss: 0.3117, G loss: 11.3736\n",
      "train error: \n",
      " D loss: 0.281869, G loss: 10.222990, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.521653, G loss: 14.965172, D accuracy: 92.7%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.6613, G loss: 4.6382\n",
      "[372/8000] D loss: 0.2499, G loss: 13.3620\n",
      "[732/8000] D loss: 0.2359, G loss: 11.4350\n",
      "[1092/8000] D loss: 0.2843, G loss: 14.1062\n",
      "[1452/8000] D loss: 0.1770, G loss: 10.5836\n",
      "[1812/8000] D loss: 0.1228, G loss: 14.3049\n",
      "[2172/8000] D loss: 0.2356, G loss: 10.9856\n",
      "[2532/8000] D loss: 0.3568, G loss: 8.3826\n",
      "[2892/8000] D loss: 0.2647, G loss: 13.6112\n",
      "[3252/8000] D loss: 0.2623, G loss: 13.4318\n",
      "[3612/8000] D loss: 0.2312, G loss: 9.5477\n",
      "[3972/8000] D loss: 0.0020, G loss: 17.6739\n",
      "[4332/8000] D loss: 0.0780, G loss: 10.5973\n",
      "[4692/8000] D loss: 0.2159, G loss: 9.7263\n",
      "[5052/8000] D loss: 0.0186, G loss: 14.5891\n",
      "[5412/8000] D loss: 0.5739, G loss: 5.9749\n",
      "[5772/8000] D loss: 0.3662, G loss: 9.1326\n",
      "[6132/8000] D loss: 0.2410, G loss: 14.1444\n",
      "[6492/8000] D loss: 0.6635, G loss: 10.5169\n",
      "[6852/8000] D loss: 0.2302, G loss: 11.6141\n",
      "[7212/8000] D loss: 0.3658, G loss: 9.0589\n",
      "[7572/8000] D loss: 0.1213, G loss: 14.6535\n",
      "[7932/8000] D loss: 0.3821, G loss: 11.1396\n",
      "train error: \n",
      " D loss: 0.265937, G loss: 11.636120, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.624352, G loss: 16.601447, D accuracy: 91.4%, cell accuracy: 94.4%, board accuracy: 6.4% \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5949, G loss: 9.0219\n",
      "[372/8000] D loss: 0.1216, G loss: 14.4982\n",
      "[732/8000] D loss: 0.6930, G loss: 7.0930\n",
      "[1092/8000] D loss: 0.1227, G loss: 12.9809\n",
      "[1452/8000] D loss: 0.3172, G loss: 10.6892\n",
      "[1812/8000] D loss: 0.8505, G loss: 3.5726\n",
      "[2172/8000] D loss: 0.2789, G loss: 11.3587\n",
      "[2532/8000] D loss: 0.1517, G loss: 8.8427\n",
      "[2892/8000] D loss: 0.5250, G loss: 6.1185\n",
      "[3252/8000] D loss: 0.3027, G loss: 8.6742\n",
      "[3612/8000] D loss: 0.4957, G loss: 6.5590\n",
      "[3972/8000] D loss: 0.1210, G loss: 11.9389\n",
      "[4332/8000] D loss: 0.1691, G loss: 12.5550\n",
      "[4692/8000] D loss: 0.2842, G loss: 10.2148\n",
      "[5052/8000] D loss: 0.3250, G loss: 9.1957\n",
      "[5412/8000] D loss: 0.2529, G loss: 11.1218\n",
      "[5772/8000] D loss: 0.2838, G loss: 9.7308\n",
      "[6132/8000] D loss: 0.1520, G loss: 10.5785\n",
      "[6492/8000] D loss: 0.0864, G loss: 11.8163\n",
      "[6852/8000] D loss: 0.2218, G loss: 12.6252\n",
      "[7212/8000] D loss: 0.2411, G loss: 13.6415\n",
      "[7572/8000] D loss: 0.3469, G loss: 10.2180\n",
      "[7932/8000] D loss: 0.1493, G loss: 14.0350\n",
      "train error: \n",
      " D loss: 0.271837, G loss: 11.466022, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.616307, G loss: 16.329842, D accuracy: 91.8%, cell accuracy: 94.4%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5514, G loss: 7.7114\n",
      "[372/8000] D loss: 0.1357, G loss: 12.8299\n",
      "[732/8000] D loss: 0.5329, G loss: 9.5805\n",
      "[1092/8000] D loss: 0.4840, G loss: 13.8136\n",
      "[1452/8000] D loss: 0.1175, G loss: 10.0013\n",
      "[1812/8000] D loss: 0.1145, G loss: 13.7833\n",
      "[2172/8000] D loss: 0.2559, G loss: 8.9668\n",
      "[2532/8000] D loss: 0.3671, G loss: 13.7514\n",
      "[2892/8000] D loss: 0.2325, G loss: 12.2426\n",
      "[3252/8000] D loss: 0.3916, G loss: 6.6988\n",
      "[3612/8000] D loss: 0.4987, G loss: 11.0118\n",
      "[3972/8000] D loss: 0.1592, G loss: 13.1101\n",
      "[4332/8000] D loss: 0.0532, G loss: 12.6564\n",
      "[4692/8000] D loss: 0.3684, G loss: 7.8492\n",
      "[5052/8000] D loss: 0.0053, G loss: 13.3557\n",
      "[5412/8000] D loss: 0.3012, G loss: 9.2342\n",
      "[5772/8000] D loss: 0.1560, G loss: 16.5762\n",
      "[6132/8000] D loss: 0.1648, G loss: 13.9544\n",
      "[6492/8000] D loss: 0.1527, G loss: 12.5125\n",
      "[6852/8000] D loss: 0.5981, G loss: 8.8515\n",
      "[7212/8000] D loss: 0.3154, G loss: 13.3661\n",
      "[7572/8000] D loss: 0.3901, G loss: 8.9788\n",
      "[7932/8000] D loss: 0.2457, G loss: 10.4749\n",
      "train error: \n",
      " D loss: 0.271889, G loss: 10.676769, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 15.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.557205, G loss: 15.367540, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2449, G loss: 10.2015\n",
      "[372/8000] D loss: 0.4105, G loss: 8.2946\n",
      "[732/8000] D loss: 0.3471, G loss: 9.0270\n",
      "[1092/8000] D loss: 0.2485, G loss: 11.7930\n",
      "[1452/8000] D loss: 0.6579, G loss: 5.5097\n",
      "[1812/8000] D loss: 0.1714, G loss: 15.6048\n",
      "[2172/8000] D loss: 0.0146, G loss: 8.9006\n",
      "[2532/8000] D loss: 0.1522, G loss: 8.5070\n",
      "[2892/8000] D loss: 0.1917, G loss: 9.6265\n",
      "[3252/8000] D loss: 0.1190, G loss: 16.4396\n",
      "[3612/8000] D loss: 0.0008, G loss: 15.3988\n",
      "[3972/8000] D loss: 0.2966, G loss: 11.0002\n",
      "[4332/8000] D loss: 0.4562, G loss: 11.9252\n",
      "[4692/8000] D loss: 0.1339, G loss: 13.7114\n",
      "[5052/8000] D loss: 0.4756, G loss: 8.3616\n",
      "[5412/8000] D loss: 0.2614, G loss: 12.4852\n",
      "[5772/8000] D loss: 0.5495, G loss: 7.9439\n",
      "[6132/8000] D loss: 0.5373, G loss: 10.8177\n",
      "[6492/8000] D loss: 0.5534, G loss: 6.3845\n",
      "[6852/8000] D loss: 0.1889, G loss: 11.5447\n",
      "[7212/8000] D loss: 0.0102, G loss: 14.6731\n",
      "[7572/8000] D loss: 0.3808, G loss: 11.1973\n",
      "[7932/8000] D loss: 0.2193, G loss: 10.9164\n",
      "train error: \n",
      " D loss: 0.262464, G loss: 11.857608, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.605817, G loss: 16.835999, D accuracy: 91.7%, cell accuracy: 94.4%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1521, G loss: 13.1714\n",
      "[372/8000] D loss: 0.2516, G loss: 12.4755\n",
      "[732/8000] D loss: 0.1183, G loss: 10.2467\n",
      "[1092/8000] D loss: 0.1791, G loss: 8.2912\n",
      "[1452/8000] D loss: 0.2352, G loss: 12.3041\n",
      "[1812/8000] D loss: 0.2642, G loss: 11.4649\n",
      "[2172/8000] D loss: 0.1182, G loss: 15.4947\n",
      "[2532/8000] D loss: 0.3548, G loss: 12.0982\n",
      "[2892/8000] D loss: 0.2342, G loss: 11.8999\n",
      "[3252/8000] D loss: 0.3267, G loss: 10.5115\n",
      "[3612/8000] D loss: 0.2063, G loss: 10.8777\n",
      "[3972/8000] D loss: 0.4729, G loss: 8.9707\n",
      "[4332/8000] D loss: 0.0396, G loss: 14.4650\n",
      "[4692/8000] D loss: 0.3003, G loss: 11.3930\n",
      "[5052/8000] D loss: 0.3129, G loss: 12.8111\n",
      "[5412/8000] D loss: 0.3553, G loss: 6.3491\n",
      "[5772/8000] D loss: 0.4616, G loss: 12.4224\n",
      "[6132/8000] D loss: 0.2441, G loss: 12.5540\n",
      "[6492/8000] D loss: 0.4971, G loss: 8.8418\n",
      "[6852/8000] D loss: 0.2889, G loss: 7.1298\n",
      "[7212/8000] D loss: 0.2625, G loss: 6.7824\n",
      "[7572/8000] D loss: 0.3557, G loss: 11.3409\n",
      "[7932/8000] D loss: 0.0616, G loss: 14.8011\n",
      "train error: \n",
      " D loss: 0.287596, G loss: 10.050496, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.561515, G loss: 14.639952, D accuracy: 92.3%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4558, G loss: 8.4663\n",
      "[372/8000] D loss: 0.5363, G loss: 8.8523\n",
      "[732/8000] D loss: 0.1329, G loss: 10.9006\n",
      "[1092/8000] D loss: 0.6239, G loss: 11.4843\n",
      "[1452/8000] D loss: 0.3623, G loss: 10.7152\n",
      "[1812/8000] D loss: 0.1317, G loss: 11.2888\n",
      "[2172/8000] D loss: 0.2735, G loss: 9.3200\n",
      "[2532/8000] D loss: 0.4596, G loss: 7.4623\n",
      "[2892/8000] D loss: 0.3503, G loss: 9.1485\n",
      "[3252/8000] D loss: 0.4984, G loss: 6.6293\n",
      "[3612/8000] D loss: 0.2540, G loss: 8.4544\n",
      "[3972/8000] D loss: 0.1152, G loss: 15.1493\n",
      "[4332/8000] D loss: 0.0117, G loss: 12.5246\n",
      "[4692/8000] D loss: 0.1220, G loss: 12.0417\n",
      "[5052/8000] D loss: 0.4407, G loss: 10.0380\n",
      "[5412/8000] D loss: 0.5890, G loss: 7.0977\n",
      "[5772/8000] D loss: 0.1428, G loss: 10.3416\n",
      "[6132/8000] D loss: 0.1198, G loss: 8.3825\n",
      "[6492/8000] D loss: 0.2647, G loss: 7.7617\n",
      "[6852/8000] D loss: 0.0010, G loss: 16.4808\n",
      "[7212/8000] D loss: 0.2430, G loss: 11.3016\n",
      "[7572/8000] D loss: 0.1130, G loss: 13.1099\n",
      "[7932/8000] D loss: 0.1181, G loss: 15.9909\n",
      "train error: \n",
      " D loss: 0.284744, G loss: 11.687810, D accuracy: 91.2%, cell accuracy: 94.9%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.618764, G loss: 16.101005, D accuracy: 91.6%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1396, G loss: 17.4340\n",
      "[372/8000] D loss: 0.2051, G loss: 14.5455\n",
      "[732/8000] D loss: 0.5068, G loss: 12.2836\n",
      "[1092/8000] D loss: 0.0026, G loss: 10.8236\n",
      "[1452/8000] D loss: 0.2317, G loss: 14.5822\n",
      "[1812/8000] D loss: 0.2125, G loss: 10.3216\n",
      "[2172/8000] D loss: 0.1162, G loss: 16.6612\n",
      "[2532/8000] D loss: 0.0117, G loss: 13.9383\n",
      "[2892/8000] D loss: 0.3755, G loss: 10.9308\n",
      "[3252/8000] D loss: 0.3081, G loss: 12.8365\n",
      "[3612/8000] D loss: 0.0162, G loss: 14.3553\n",
      "[3972/8000] D loss: 0.1171, G loss: 15.1477\n",
      "[4332/8000] D loss: 0.2506, G loss: 11.7325\n",
      "[4692/8000] D loss: 0.5312, G loss: 9.7460\n",
      "[5052/8000] D loss: 0.1949, G loss: 11.0697\n",
      "[5412/8000] D loss: 0.1559, G loss: 13.1494\n",
      "[5772/8000] D loss: 0.2325, G loss: 10.7241\n",
      "[6132/8000] D loss: 0.3665, G loss: 8.4775\n",
      "[6492/8000] D loss: 0.3530, G loss: 9.4707\n",
      "[6852/8000] D loss: 0.4172, G loss: 10.7948\n",
      "[7212/8000] D loss: 0.2451, G loss: 17.6522\n",
      "[7572/8000] D loss: 0.4762, G loss: 9.7739\n",
      "[7932/8000] D loss: 0.1139, G loss: 12.5047\n",
      "train error: \n",
      " D loss: 0.268981, G loss: 10.830619, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.554582, G loss: 15.449717, D accuracy: 92.5%, cell accuracy: 94.4%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1215, G loss: 14.0619\n",
      "[372/8000] D loss: 0.2479, G loss: 12.5989\n",
      "[732/8000] D loss: 0.0003, G loss: 17.2855\n",
      "[1092/8000] D loss: 0.2655, G loss: 12.0143\n",
      "[1452/8000] D loss: 0.4097, G loss: 8.9147\n",
      "[1812/8000] D loss: 0.1326, G loss: 10.6856\n",
      "[2172/8000] D loss: 0.4165, G loss: 10.4580\n",
      "[2532/8000] D loss: 0.0398, G loss: 12.6413\n",
      "[2892/8000] D loss: 0.3514, G loss: 9.0670\n",
      "[3252/8000] D loss: 0.0034, G loss: 15.8407\n",
      "[3612/8000] D loss: 0.2636, G loss: 10.3224\n",
      "[3972/8000] D loss: 0.2675, G loss: 8.2968\n",
      "[4332/8000] D loss: 0.2835, G loss: 14.3658\n",
      "[4692/8000] D loss: 0.2133, G loss: 12.9833\n",
      "[5052/8000] D loss: 0.3259, G loss: 7.2929\n",
      "[5412/8000] D loss: 0.4584, G loss: 14.9128\n",
      "[5772/8000] D loss: 0.5260, G loss: 9.6708\n",
      "[6132/8000] D loss: 0.2521, G loss: 9.2631\n",
      "[6492/8000] D loss: 0.2354, G loss: 13.9009\n",
      "[6852/8000] D loss: 0.1414, G loss: 12.2257\n",
      "[7212/8000] D loss: 0.2180, G loss: 13.0206\n",
      "[7572/8000] D loss: 0.3665, G loss: 10.8810\n",
      "[7932/8000] D loss: 0.2727, G loss: 9.9255\n",
      "train error: \n",
      " D loss: 0.271463, G loss: 10.339390, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 15.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.561839, G loss: 15.113600, D accuracy: 91.9%, cell accuracy: 94.4%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4577, G loss: 9.1801\n",
      "[372/8000] D loss: 0.2342, G loss: 7.9542\n",
      "[732/8000] D loss: 0.6257, G loss: 7.4782\n",
      "[1092/8000] D loss: 0.2675, G loss: 11.5843\n",
      "[1452/8000] D loss: 0.2324, G loss: 13.3711\n",
      "[1812/8000] D loss: 0.7860, G loss: 7.3556\n",
      "[2172/8000] D loss: 0.4712, G loss: 7.8384\n",
      "[2532/8000] D loss: 0.1880, G loss: 14.3342\n",
      "[2892/8000] D loss: 0.3671, G loss: 9.2293\n",
      "[3252/8000] D loss: 0.1282, G loss: 13.6879\n",
      "[3612/8000] D loss: 0.3544, G loss: 11.4128\n",
      "[3972/8000] D loss: 0.0205, G loss: 11.0160\n",
      "[4332/8000] D loss: 0.1233, G loss: 13.4506\n",
      "[4692/8000] D loss: 0.0120, G loss: 12.0848\n",
      "[5052/8000] D loss: 0.4111, G loss: 9.6799\n",
      "[5412/8000] D loss: 0.4853, G loss: 8.6647\n",
      "[5772/8000] D loss: 0.3245, G loss: 11.1227\n",
      "[6132/8000] D loss: 0.4606, G loss: 9.7801\n",
      "[6492/8000] D loss: 0.2298, G loss: 16.2244\n",
      "[6852/8000] D loss: 0.4405, G loss: 12.8083\n",
      "[7212/8000] D loss: 0.0792, G loss: 13.2836\n",
      "[7572/8000] D loss: 0.2305, G loss: 10.0530\n",
      "[7932/8000] D loss: 0.3529, G loss: 12.1050\n",
      "train error: \n",
      " D loss: 0.264269, G loss: 10.956222, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.594979, G loss: 15.774207, D accuracy: 91.6%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5520, G loss: 7.2501\n",
      "[372/8000] D loss: 0.2314, G loss: 12.1786\n",
      "[732/8000] D loss: 0.2397, G loss: 11.6724\n",
      "[1092/8000] D loss: 0.3639, G loss: 10.9249\n",
      "[1452/8000] D loss: 0.1684, G loss: 10.9480\n",
      "[1812/8000] D loss: 0.1232, G loss: 11.8742\n",
      "[2172/8000] D loss: 0.2265, G loss: 9.5101\n",
      "[2532/8000] D loss: 0.1255, G loss: 12.3580\n",
      "[2892/8000] D loss: 0.0140, G loss: 12.1267\n",
      "[3252/8000] D loss: 0.2413, G loss: 15.1007\n",
      "[3612/8000] D loss: 0.2513, G loss: 10.2948\n",
      "[3972/8000] D loss: 0.3776, G loss: 9.8250\n",
      "[4332/8000] D loss: 0.2716, G loss: 12.2644\n",
      "[4692/8000] D loss: 0.3434, G loss: 9.3323\n",
      "[5052/8000] D loss: 0.1403, G loss: 11.5375\n",
      "[5412/8000] D loss: 0.3905, G loss: 9.2342\n",
      "[5772/8000] D loss: 0.5754, G loss: 10.8759\n",
      "[6132/8000] D loss: 0.2386, G loss: 10.9575\n",
      "[6492/8000] D loss: 0.3175, G loss: 11.5962\n",
      "[6852/8000] D loss: 0.2315, G loss: 11.6212\n",
      "[7212/8000] D loss: 0.1590, G loss: 12.0393\n",
      "[7572/8000] D loss: 0.3857, G loss: 10.6626\n",
      "[7932/8000] D loss: 0.2381, G loss: 9.9461\n",
      "train error: \n",
      " D loss: 0.269727, G loss: 11.305315, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.630847, G loss: 16.117348, D accuracy: 91.8%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1876, G loss: 10.6917\n",
      "[372/8000] D loss: 0.1613, G loss: 12.1625\n",
      "[732/8000] D loss: 0.1769, G loss: 10.7389\n",
      "[1092/8000] D loss: 0.2709, G loss: 8.9500\n",
      "[1452/8000] D loss: 0.4855, G loss: 8.2048\n",
      "[1812/8000] D loss: 0.2681, G loss: 10.4270\n",
      "[2172/8000] D loss: 0.1165, G loss: 11.6677\n",
      "[2532/8000] D loss: 0.2990, G loss: 8.9377\n",
      "[2892/8000] D loss: 0.3462, G loss: 10.6462\n",
      "[3252/8000] D loss: 0.5375, G loss: 8.1907\n",
      "[3612/8000] D loss: 0.1940, G loss: 9.8028\n",
      "[3972/8000] D loss: 0.3711, G loss: 11.1889\n",
      "[4332/8000] D loss: 0.1252, G loss: 11.7415\n",
      "[4692/8000] D loss: 0.4128, G loss: 8.1118\n",
      "[5052/8000] D loss: 0.2410, G loss: 10.6251\n",
      "[5412/8000] D loss: 0.1454, G loss: 10.1116\n",
      "[5772/8000] D loss: 0.2780, G loss: 12.7817\n",
      "[6132/8000] D loss: 0.3043, G loss: 15.7221\n",
      "[6492/8000] D loss: 0.2668, G loss: 12.7939\n",
      "[6852/8000] D loss: 0.4290, G loss: 8.3238\n",
      "[7212/8000] D loss: 0.2022, G loss: 14.7401\n",
      "[7572/8000] D loss: 0.1239, G loss: 14.3142\n",
      "[7932/8000] D loss: 0.1231, G loss: 10.3806\n",
      "train error: \n",
      " D loss: 0.271447, G loss: 11.241266, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.630376, G loss: 15.935468, D accuracy: 91.5%, cell accuracy: 94.4%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4093, G loss: 10.8546\n",
      "[372/8000] D loss: 0.0655, G loss: 12.0924\n",
      "[732/8000] D loss: 0.3058, G loss: 12.4184\n",
      "[1092/8000] D loss: 0.7841, G loss: 5.1265\n",
      "[1452/8000] D loss: 0.1193, G loss: 13.5254\n",
      "[1812/8000] D loss: 0.2548, G loss: 11.7347\n",
      "[2172/8000] D loss: 0.1148, G loss: 11.4038\n",
      "[2532/8000] D loss: 0.2316, G loss: 10.9417\n",
      "[2892/8000] D loss: 0.2283, G loss: 10.5149\n",
      "[3252/8000] D loss: 0.4832, G loss: 8.8520\n",
      "[3612/8000] D loss: 0.4120, G loss: 10.6004\n",
      "[3972/8000] D loss: 0.4584, G loss: 9.8649\n",
      "[4332/8000] D loss: 0.2472, G loss: 10.2348\n",
      "[4692/8000] D loss: 0.1810, G loss: 10.1785\n",
      "[5052/8000] D loss: 0.4945, G loss: 13.3834\n",
      "[5412/8000] D loss: 0.2387, G loss: 10.4301\n",
      "[5772/8000] D loss: 0.3324, G loss: 12.4120\n",
      "[6132/8000] D loss: 0.2516, G loss: 11.2108\n",
      "[6492/8000] D loss: 0.3568, G loss: 9.1704\n",
      "[6852/8000] D loss: 0.2482, G loss: 8.7207\n",
      "[7212/8000] D loss: 0.4016, G loss: 15.3232\n",
      "[7572/8000] D loss: 0.3421, G loss: 8.5816\n",
      "[7932/8000] D loss: 0.3112, G loss: 13.1929\n",
      "train error: \n",
      " D loss: 0.275062, G loss: 11.238067, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.566499, G loss: 16.089736, D accuracy: 92.8%, cell accuracy: 94.4%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2335, G loss: 10.8824\n",
      "[372/8000] D loss: 0.0897, G loss: 15.0026\n",
      "[732/8000] D loss: 0.1240, G loss: 12.2607\n",
      "[1092/8000] D loss: 0.0346, G loss: 13.2622\n",
      "[1452/8000] D loss: 0.0054, G loss: 12.3037\n",
      "[1812/8000] D loss: 0.3943, G loss: 6.4178\n",
      "[2172/8000] D loss: 0.3387, G loss: 12.3750\n",
      "[2532/8000] D loss: 0.2390, G loss: 8.8146\n",
      "[2892/8000] D loss: 0.3719, G loss: 11.0070\n",
      "[3252/8000] D loss: 0.2337, G loss: 9.8889\n",
      "[3612/8000] D loss: 0.2433, G loss: 12.3948\n",
      "[3972/8000] D loss: 0.0025, G loss: 15.2784\n",
      "[4332/8000] D loss: 0.1247, G loss: 15.5966\n",
      "[4692/8000] D loss: 0.0109, G loss: 12.0567\n",
      "[5052/8000] D loss: 0.4909, G loss: 13.3520\n",
      "[5412/8000] D loss: 0.2472, G loss: 10.1682\n",
      "[5772/8000] D loss: 0.2904, G loss: 11.3698\n",
      "[6132/8000] D loss: 0.1054, G loss: 9.3362\n",
      "[6492/8000] D loss: 0.1384, G loss: 12.8963\n",
      "[6852/8000] D loss: 0.3723, G loss: 7.5415\n",
      "[7212/8000] D loss: 0.3885, G loss: 8.1940\n",
      "[7572/8000] D loss: 0.3864, G loss: 9.8380\n",
      "[7932/8000] D loss: 0.1678, G loss: 11.4186\n",
      "train error: \n",
      " D loss: 0.276869, G loss: 10.412928, D accuracy: 91.7%, cell accuracy: 94.8%, board accuracy: 15.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.552752, G loss: 15.066978, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1045, G loss: 13.0661\n",
      "[372/8000] D loss: 0.4248, G loss: 7.2884\n",
      "[732/8000] D loss: 0.2321, G loss: 12.0125\n",
      "[1092/8000] D loss: 0.2389, G loss: 10.5903\n",
      "[1452/8000] D loss: 0.2072, G loss: 14.0928\n",
      "[1812/8000] D loss: 0.2281, G loss: 12.0447\n",
      "[2172/8000] D loss: 0.1600, G loss: 13.3266\n",
      "[2532/8000] D loss: 0.3601, G loss: 9.9936\n",
      "[2892/8000] D loss: 0.1895, G loss: 9.9070\n",
      "[3252/8000] D loss: 0.3162, G loss: 6.9998\n",
      "[3612/8000] D loss: 0.1899, G loss: 9.0247\n",
      "[3972/8000] D loss: 0.3816, G loss: 7.6702\n",
      "[4332/8000] D loss: 0.1244, G loss: 14.4514\n",
      "[4692/8000] D loss: 0.6388, G loss: 6.3486\n",
      "[5052/8000] D loss: 0.5507, G loss: 9.7085\n",
      "[5412/8000] D loss: 0.2446, G loss: 8.7146\n",
      "[5772/8000] D loss: 0.2319, G loss: 11.2488\n",
      "[6132/8000] D loss: 0.5817, G loss: 9.1578\n",
      "[6492/8000] D loss: 0.1280, G loss: 9.3829\n",
      "[6852/8000] D loss: 0.0433, G loss: 13.6606\n",
      "[7212/8000] D loss: 0.2670, G loss: 9.7954\n",
      "[7572/8000] D loss: 0.1431, G loss: 11.8829\n",
      "[7932/8000] D loss: 0.1471, G loss: 9.9257\n",
      "train error: \n",
      " D loss: 0.270974, G loss: 10.585542, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.579824, G loss: 15.209894, D accuracy: 91.0%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2313, G loss: 12.3867\n",
      "[372/8000] D loss: 0.2342, G loss: 11.7645\n",
      "[732/8000] D loss: 0.7462, G loss: 6.7969\n",
      "[1092/8000] D loss: 0.0145, G loss: 10.6948\n",
      "[1452/8000] D loss: 0.1997, G loss: 11.9159\n",
      "[1812/8000] D loss: 0.1197, G loss: 12.7310\n",
      "[2172/8000] D loss: 0.1117, G loss: 12.0026\n",
      "[2532/8000] D loss: 0.2739, G loss: 7.4251\n",
      "[2892/8000] D loss: 0.4685, G loss: 8.8857\n",
      "[3252/8000] D loss: 0.2480, G loss: 8.8883\n",
      "[3612/8000] D loss: 0.1374, G loss: 15.2569\n",
      "[3972/8000] D loss: 0.2474, G loss: 8.8614\n",
      "[4332/8000] D loss: 0.2416, G loss: 8.7218\n",
      "[4692/8000] D loss: 0.2576, G loss: 10.4577\n",
      "[5052/8000] D loss: 0.1933, G loss: 9.4358\n",
      "[5412/8000] D loss: 0.3454, G loss: 12.5153\n",
      "[5772/8000] D loss: 0.2377, G loss: 13.0729\n",
      "[6132/8000] D loss: 0.2480, G loss: 11.5559\n",
      "[6492/8000] D loss: 0.1249, G loss: 11.9642\n",
      "[6852/8000] D loss: 0.1311, G loss: 11.2936\n",
      "[7212/8000] D loss: 0.2349, G loss: 10.1383\n",
      "[7572/8000] D loss: 0.3491, G loss: 10.7782\n",
      "[7932/8000] D loss: 0.1173, G loss: 17.0675\n",
      "train error: \n",
      " D loss: 0.269859, G loss: 11.340089, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.562574, G loss: 16.191794, D accuracy: 92.4%, cell accuracy: 94.4%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2442, G loss: 12.3356\n",
      "[372/8000] D loss: 0.1610, G loss: 8.9676\n",
      "[732/8000] D loss: 0.4577, G loss: 8.9966\n",
      "[1092/8000] D loss: 0.0015, G loss: 13.8861\n",
      "[1452/8000] D loss: 0.1770, G loss: 9.5316\n",
      "[1812/8000] D loss: 0.3320, G loss: 6.7080\n",
      "[2172/8000] D loss: 0.1215, G loss: 14.1542\n",
      "[2532/8000] D loss: 0.3539, G loss: 8.4646\n",
      "[2892/8000] D loss: 0.2461, G loss: 8.7120\n",
      "[3252/8000] D loss: 0.3683, G loss: 6.1507\n",
      "[3612/8000] D loss: 0.2070, G loss: 13.1666\n",
      "[3972/8000] D loss: 0.5525, G loss: 10.1226\n",
      "[4332/8000] D loss: 0.3655, G loss: 12.5760\n",
      "[4692/8000] D loss: 0.1577, G loss: 10.3674\n",
      "[5052/8000] D loss: 0.2212, G loss: 14.2026\n",
      "[5412/8000] D loss: 0.1331, G loss: 7.4572\n",
      "[5772/8000] D loss: 0.6963, G loss: 2.9530\n",
      "[6132/8000] D loss: 0.0015, G loss: 14.4157\n",
      "[6492/8000] D loss: 0.2669, G loss: 11.6442\n",
      "[6852/8000] D loss: 0.2162, G loss: 10.6048\n",
      "[7212/8000] D loss: 0.3681, G loss: 12.5069\n",
      "[7572/8000] D loss: 0.2364, G loss: 12.9726\n",
      "[7932/8000] D loss: 0.3624, G loss: 12.4146\n",
      "train error: \n",
      " D loss: 0.276890, G loss: 11.096666, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.593046, G loss: 15.970737, D accuracy: 92.2%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5523, G loss: 9.7861\n",
      "[372/8000] D loss: 0.6013, G loss: 9.4029\n",
      "[732/8000] D loss: 0.0740, G loss: 13.0036\n",
      "[1092/8000] D loss: 0.5278, G loss: 11.0922\n",
      "[1452/8000] D loss: 0.1170, G loss: 19.3623\n",
      "[1812/8000] D loss: 0.2326, G loss: 14.0724\n",
      "[2172/8000] D loss: 0.2760, G loss: 10.3435\n",
      "[2532/8000] D loss: 0.1363, G loss: 12.9566\n",
      "[2892/8000] D loss: 0.5870, G loss: 5.5523\n",
      "[3252/8000] D loss: 0.1947, G loss: 8.3066\n",
      "[3612/8000] D loss: 0.1984, G loss: 12.1696\n",
      "[3972/8000] D loss: 0.2389, G loss: 12.6153\n",
      "[4332/8000] D loss: 0.2383, G loss: 9.4367\n",
      "[4692/8000] D loss: 0.1587, G loss: 11.6264\n",
      "[5052/8000] D loss: 0.3763, G loss: 7.9768\n",
      "[5412/8000] D loss: 0.0039, G loss: 12.0510\n",
      "[5772/8000] D loss: 0.0263, G loss: 11.1752\n",
      "[6132/8000] D loss: 0.3635, G loss: 8.3331\n",
      "[6492/8000] D loss: 0.0039, G loss: 11.7243\n",
      "[6852/8000] D loss: 0.2478, G loss: 10.2720\n",
      "[7212/8000] D loss: 0.3977, G loss: 10.7450\n",
      "[7572/8000] D loss: 0.0370, G loss: 9.0187\n",
      "[7932/8000] D loss: 0.3436, G loss: 12.3805\n",
      "train error: \n",
      " D loss: 0.265975, G loss: 10.974820, D accuracy: 92.0%, cell accuracy: 94.9%, board accuracy: 15.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.588709, G loss: 15.679025, D accuracy: 91.6%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1271, G loss: 11.9542\n",
      "[372/8000] D loss: 0.5245, G loss: 10.0350\n",
      "[732/8000] D loss: 0.3768, G loss: 8.1267\n",
      "[1092/8000] D loss: 0.1436, G loss: 8.7888\n",
      "[1452/8000] D loss: 0.8955, G loss: 5.5395\n",
      "[1812/8000] D loss: 0.2332, G loss: 11.3255\n",
      "[2172/8000] D loss: 0.1156, G loss: 12.0745\n",
      "[2532/8000] D loss: 0.3512, G loss: 11.0686\n",
      "[2892/8000] D loss: 0.3014, G loss: 8.7110\n",
      "[3252/8000] D loss: 0.3530, G loss: 12.6354\n",
      "[3612/8000] D loss: 0.2488, G loss: 11.0843\n",
      "[3972/8000] D loss: 0.3086, G loss: 10.0329\n",
      "[4332/8000] D loss: 0.3634, G loss: 16.1202\n",
      "[4692/8000] D loss: 0.1346, G loss: 13.7500\n",
      "[5052/8000] D loss: 0.4811, G loss: 9.1437\n",
      "[5412/8000] D loss: 0.1814, G loss: 11.6998\n",
      "[5772/8000] D loss: 0.1232, G loss: 12.7053\n",
      "[6132/8000] D loss: 0.1532, G loss: 8.8054\n",
      "[6492/8000] D loss: 0.1921, G loss: 16.2667\n",
      "[6852/8000] D loss: 0.5841, G loss: 12.2543\n",
      "[7212/8000] D loss: 0.2473, G loss: 11.5911\n",
      "[7572/8000] D loss: 0.1256, G loss: 13.4452\n",
      "[7932/8000] D loss: 0.5091, G loss: 6.3867\n",
      "train error: \n",
      " D loss: 0.263544, G loss: 11.704591, D accuracy: 92.0%, cell accuracy: 94.9%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.596721, G loss: 16.659004, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3540, G loss: 13.6446\n",
      "[372/8000] D loss: 0.2298, G loss: 13.2448\n",
      "[732/8000] D loss: 0.1370, G loss: 13.4240\n",
      "[1092/8000] D loss: 0.3437, G loss: 13.4962\n",
      "[1452/8000] D loss: 0.2089, G loss: 11.1109\n",
      "[1812/8000] D loss: 0.0267, G loss: 12.9145\n",
      "[2172/8000] D loss: 0.1214, G loss: 10.6302\n",
      "[2532/8000] D loss: 0.3215, G loss: 8.6071\n",
      "[2892/8000] D loss: 0.1230, G loss: 13.1118\n",
      "[3252/8000] D loss: 0.4592, G loss: 9.0048\n",
      "[3612/8000] D loss: 0.3463, G loss: 9.6925\n",
      "[3972/8000] D loss: 0.4953, G loss: 9.3772\n",
      "[4332/8000] D loss: 0.2080, G loss: 10.1301\n",
      "[4692/8000] D loss: 0.3594, G loss: 10.0527\n",
      "[5052/8000] D loss: 0.2556, G loss: 6.5972\n",
      "[5412/8000] D loss: 0.1164, G loss: 14.0641\n",
      "[5772/8000] D loss: 0.2700, G loss: 11.7516\n",
      "[6132/8000] D loss: 0.5035, G loss: 7.5394\n",
      "[6492/8000] D loss: 0.5592, G loss: 9.5045\n",
      "[6852/8000] D loss: 0.1144, G loss: 10.4025\n",
      "[7212/8000] D loss: 0.2404, G loss: 9.0511\n",
      "[7572/8000] D loss: 0.2384, G loss: 12.0648\n",
      "[7932/8000] D loss: 0.2318, G loss: 11.8704\n",
      "train error: \n",
      " D loss: 0.268909, G loss: 11.592721, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.612396, G loss: 16.383096, D accuracy: 91.5%, cell accuracy: 94.5%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2267, G loss: 11.7083\n",
      "[372/8000] D loss: 0.4845, G loss: 11.0678\n",
      "[732/8000] D loss: 0.3632, G loss: 7.7635\n",
      "[1092/8000] D loss: 0.3175, G loss: 8.5202\n",
      "[1452/8000] D loss: 0.4539, G loss: 14.5927\n",
      "[1812/8000] D loss: 0.3697, G loss: 11.1792\n",
      "[2172/8000] D loss: 0.3607, G loss: 12.2368\n",
      "[2532/8000] D loss: 0.0792, G loss: 11.0111\n",
      "[2892/8000] D loss: 0.4149, G loss: 10.3306\n",
      "[3252/8000] D loss: 0.3732, G loss: 10.5360\n",
      "[3612/8000] D loss: 0.4014, G loss: 7.8896\n",
      "[3972/8000] D loss: 0.2967, G loss: 8.9007\n",
      "[4332/8000] D loss: 0.4857, G loss: 9.8431\n",
      "[4692/8000] D loss: 0.1718, G loss: 11.7550\n",
      "[5052/8000] D loss: 0.0578, G loss: 10.7615\n",
      "[5412/8000] D loss: 0.0201, G loss: 16.4013\n",
      "[5772/8000] D loss: 0.1158, G loss: 9.2669\n",
      "[6132/8000] D loss: 0.2402, G loss: 13.7092\n",
      "[6492/8000] D loss: 0.4834, G loss: 8.4783\n",
      "[6852/8000] D loss: 0.1262, G loss: 13.0310\n",
      "[7212/8000] D loss: 0.2725, G loss: 11.3471\n",
      "[7572/8000] D loss: 0.3265, G loss: 8.4279\n",
      "[7932/8000] D loss: 0.2016, G loss: 13.4784\n",
      "train error: \n",
      " D loss: 0.266240, G loss: 11.134127, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.610360, G loss: 16.065450, D accuracy: 91.7%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4128, G loss: 10.5507\n",
      "[372/8000] D loss: 0.3794, G loss: 9.2834\n",
      "[732/8000] D loss: 0.1352, G loss: 13.0284\n",
      "[1092/8000] D loss: 0.3402, G loss: 13.9735\n",
      "[1452/8000] D loss: 0.3812, G loss: 6.6158\n",
      "[1812/8000] D loss: 0.1149, G loss: 13.9061\n",
      "[2172/8000] D loss: 0.2406, G loss: 10.1337\n",
      "[2532/8000] D loss: 0.3383, G loss: 10.1090\n",
      "[2892/8000] D loss: 0.2719, G loss: 10.0625\n",
      "[3252/8000] D loss: 0.1236, G loss: 15.3692\n",
      "[3612/8000] D loss: 0.3323, G loss: 9.8813\n",
      "[3972/8000] D loss: 0.2364, G loss: 12.0360\n",
      "[4332/8000] D loss: 0.3644, G loss: 9.7518\n",
      "[4692/8000] D loss: 0.5479, G loss: 10.2833\n",
      "[5052/8000] D loss: 0.3825, G loss: 10.6494\n",
      "[5412/8000] D loss: 0.1142, G loss: 15.2681\n",
      "[5772/8000] D loss: 0.4096, G loss: 10.2548\n",
      "[6132/8000] D loss: 0.1677, G loss: 10.5744\n",
      "[6492/8000] D loss: 0.4426, G loss: 10.7316\n",
      "[6852/8000] D loss: 0.2377, G loss: 11.4571\n",
      "[7212/8000] D loss: 0.0524, G loss: 9.2007\n",
      "[7572/8000] D loss: 0.1319, G loss: 9.4574\n",
      "[7932/8000] D loss: 0.4295, G loss: 8.1507\n",
      "train error: \n",
      " D loss: 0.271866, G loss: 11.637694, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.625245, G loss: 16.568188, D accuracy: 91.0%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2407, G loss: 17.3463\n",
      "[372/8000] D loss: 0.4442, G loss: 11.3137\n",
      "[732/8000] D loss: 0.0341, G loss: 18.2578\n",
      "[1092/8000] D loss: 0.3268, G loss: 13.2267\n",
      "[1452/8000] D loss: 0.4800, G loss: 8.8134\n",
      "[1812/8000] D loss: 0.3393, G loss: 9.8472\n",
      "[2172/8000] D loss: 0.4706, G loss: 10.4595\n",
      "[2532/8000] D loss: 0.2504, G loss: 10.9965\n",
      "[2892/8000] D loss: 0.8068, G loss: 8.0657\n",
      "[3252/8000] D loss: 0.2331, G loss: 10.6011\n",
      "[3612/8000] D loss: 0.0015, G loss: 15.7863\n",
      "[3972/8000] D loss: 0.1278, G loss: 12.7376\n",
      "[4332/8000] D loss: 0.2416, G loss: 13.5503\n",
      "[4692/8000] D loss: 0.0118, G loss: 12.3897\n",
      "[5052/8000] D loss: 0.1385, G loss: 10.3880\n",
      "[5412/8000] D loss: 0.1190, G loss: 12.7839\n",
      "[5772/8000] D loss: 0.2211, G loss: 9.0354\n",
      "[6132/8000] D loss: 0.0900, G loss: 16.2530\n",
      "[6492/8000] D loss: 0.1345, G loss: 12.8596\n",
      "[6852/8000] D loss: 0.3236, G loss: 11.0855\n",
      "[7212/8000] D loss: 0.0971, G loss: 9.7800\n",
      "[7572/8000] D loss: 0.3671, G loss: 7.4277\n",
      "[7932/8000] D loss: 0.3717, G loss: 10.3784\n",
      "train error: \n",
      " D loss: 0.285024, G loss: 11.905479, D accuracy: 91.3%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.684142, G loss: 16.683314, D accuracy: 90.3%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2602, G loss: 13.2622\n",
      "[372/8000] D loss: 0.0104, G loss: 13.8136\n",
      "[732/8000] D loss: 0.5626, G loss: 7.3370\n",
      "[1092/8000] D loss: 0.2207, G loss: 10.1382\n",
      "[1452/8000] D loss: 0.2256, G loss: 12.0560\n",
      "[1812/8000] D loss: 0.2707, G loss: 10.6671\n",
      "[2172/8000] D loss: 0.1349, G loss: 15.0962\n",
      "[2532/8000] D loss: 0.4424, G loss: 6.5194\n",
      "[2892/8000] D loss: 0.2750, G loss: 13.4144\n",
      "[3252/8000] D loss: 0.0054, G loss: 13.2635\n",
      "[3612/8000] D loss: 0.5023, G loss: 8.4041\n",
      "[3972/8000] D loss: 0.2535, G loss: 11.6477\n",
      "[4332/8000] D loss: 0.4793, G loss: 8.1718\n",
      "[4692/8000] D loss: 0.1376, G loss: 11.3581\n",
      "[5052/8000] D loss: 0.2064, G loss: 13.7161\n",
      "[5412/8000] D loss: 0.1172, G loss: 13.3396\n",
      "[5772/8000] D loss: 0.4914, G loss: 10.1489\n",
      "[6132/8000] D loss: 0.0427, G loss: 11.0781\n",
      "[6492/8000] D loss: 0.2643, G loss: 6.9314\n",
      "[6852/8000] D loss: 0.7960, G loss: 8.9907\n",
      "[7212/8000] D loss: 0.1640, G loss: 11.0702\n",
      "[7572/8000] D loss: 0.1974, G loss: 12.5508\n",
      "[7932/8000] D loss: 0.3862, G loss: 10.1803\n",
      "train error: \n",
      " D loss: 0.269930, G loss: 11.433734, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.622986, G loss: 16.238008, D accuracy: 91.8%, cell accuracy: 94.4%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4840, G loss: 9.7223\n",
      "[372/8000] D loss: 0.0069, G loss: 12.0944\n",
      "[732/8000] D loss: 0.2477, G loss: 10.1498\n",
      "[1092/8000] D loss: 0.1605, G loss: 7.9200\n",
      "[1452/8000] D loss: 0.4724, G loss: 6.9143\n",
      "[1812/8000] D loss: 0.3451, G loss: 7.7160\n",
      "[2172/8000] D loss: 0.2782, G loss: 12.2340\n",
      "[2532/8000] D loss: 0.3331, G loss: 9.3828\n",
      "[2892/8000] D loss: 0.3408, G loss: 14.2546\n",
      "[3252/8000] D loss: 0.2628, G loss: 13.1707\n",
      "[3612/8000] D loss: 0.3785, G loss: 10.9366\n",
      "[3972/8000] D loss: 0.2379, G loss: 15.1865\n",
      "[4332/8000] D loss: 0.6978, G loss: 7.8966\n",
      "[4692/8000] D loss: 0.3817, G loss: 11.7298\n",
      "[5052/8000] D loss: 0.1178, G loss: 14.5818\n",
      "[5412/8000] D loss: 0.4731, G loss: 9.6964\n",
      "[5772/8000] D loss: 0.0075, G loss: 11.2230\n",
      "[6132/8000] D loss: 0.1415, G loss: 12.4353\n",
      "[6492/8000] D loss: 0.1305, G loss: 12.9753\n",
      "[6852/8000] D loss: 0.1613, G loss: 14.3800\n",
      "[7212/8000] D loss: 0.3726, G loss: 10.0211\n",
      "[7572/8000] D loss: 0.1242, G loss: 14.3977\n",
      "[7932/8000] D loss: 0.0058, G loss: 18.0110\n",
      "train error: \n",
      " D loss: 0.277621, G loss: 12.126891, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.676400, G loss: 17.125941, D accuracy: 90.4%, cell accuracy: 94.5%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1875, G loss: 10.8900\n",
      "[372/8000] D loss: 0.2819, G loss: 8.5929\n",
      "[732/8000] D loss: 0.4738, G loss: 10.6272\n",
      "[1092/8000] D loss: 0.2376, G loss: 8.4890\n",
      "[1452/8000] D loss: 0.3430, G loss: 10.8859\n",
      "[1812/8000] D loss: 0.2356, G loss: 8.8419\n",
      "[2172/8000] D loss: 0.3363, G loss: 10.7550\n",
      "[2532/8000] D loss: 0.3550, G loss: 12.9548\n",
      "[2892/8000] D loss: 0.1285, G loss: 12.2008\n",
      "[3252/8000] D loss: 0.1018, G loss: 11.9537\n",
      "[3612/8000] D loss: 0.0056, G loss: 12.9968\n",
      "[3972/8000] D loss: 0.0631, G loss: 14.7983\n",
      "[4332/8000] D loss: 0.2397, G loss: 11.4991\n",
      "[4692/8000] D loss: 0.3923, G loss: 8.0999\n",
      "[5052/8000] D loss: 0.4945, G loss: 7.2462\n",
      "[5412/8000] D loss: 0.1154, G loss: 14.2258\n",
      "[5772/8000] D loss: 0.1198, G loss: 10.7930\n",
      "[6132/8000] D loss: 0.0457, G loss: 12.8093\n",
      "[6492/8000] D loss: 0.1777, G loss: 12.2081\n",
      "[6852/8000] D loss: 0.1186, G loss: 13.2884\n",
      "[7212/8000] D loss: 0.0696, G loss: 15.0983\n",
      "[7572/8000] D loss: 0.2690, G loss: 11.9315\n",
      "[7932/8000] D loss: 0.4772, G loss: 11.3432\n",
      "train error: \n",
      " D loss: 0.276654, G loss: 11.038907, D accuracy: 91.4%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.571125, G loss: 16.005556, D accuracy: 91.5%, cell accuracy: 94.4%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1113, G loss: 11.8853\n",
      "[372/8000] D loss: 0.3625, G loss: 8.1901\n",
      "[732/8000] D loss: 0.2810, G loss: 12.2329\n",
      "[1092/8000] D loss: 0.2366, G loss: 10.9045\n",
      "[1452/8000] D loss: 0.1207, G loss: 10.6333\n",
      "[1812/8000] D loss: 0.3386, G loss: 11.7934\n",
      "[2172/8000] D loss: 0.4628, G loss: 6.1286\n",
      "[2532/8000] D loss: 0.5717, G loss: 6.5654\n",
      "[2892/8000] D loss: 0.5665, G loss: 10.8756\n",
      "[3252/8000] D loss: 0.3193, G loss: 14.4727\n",
      "[3612/8000] D loss: 0.0030, G loss: 15.1845\n",
      "[3972/8000] D loss: 0.2426, G loss: 10.0990\n",
      "[4332/8000] D loss: 0.3397, G loss: 10.6509\n",
      "[4692/8000] D loss: 0.1389, G loss: 9.9999\n",
      "[5052/8000] D loss: 0.4862, G loss: 7.6440\n",
      "[5412/8000] D loss: 0.3535, G loss: 11.8800\n",
      "[5772/8000] D loss: 0.4797, G loss: 8.6973\n",
      "[6132/8000] D loss: 0.6046, G loss: 6.8380\n",
      "[6492/8000] D loss: 0.2619, G loss: 11.7956\n",
      "[6852/8000] D loss: 0.1271, G loss: 16.0289\n",
      "[7212/8000] D loss: 0.2467, G loss: 9.0032\n",
      "[7572/8000] D loss: 0.1220, G loss: 9.3530\n",
      "[7932/8000] D loss: 0.1277, G loss: 10.2177\n",
      "train error: \n",
      " D loss: 0.268750, G loss: 11.431195, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.642053, G loss: 16.343906, D accuracy: 91.4%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2448, G loss: 8.2775\n",
      "[372/8000] D loss: 0.1588, G loss: 9.6582\n",
      "[732/8000] D loss: 0.3472, G loss: 10.6610\n",
      "[1092/8000] D loss: 0.1176, G loss: 12.1627\n",
      "[1452/8000] D loss: 0.1645, G loss: 10.7352\n",
      "[1812/8000] D loss: 0.3411, G loss: 14.2674\n",
      "[2172/8000] D loss: 0.5024, G loss: 8.4748\n",
      "[2532/8000] D loss: 0.3390, G loss: 12.0148\n",
      "[2892/8000] D loss: 0.1516, G loss: 7.4760\n",
      "[3252/8000] D loss: 0.1153, G loss: 14.8756\n",
      "[3612/8000] D loss: 0.2459, G loss: 9.9696\n",
      "[3972/8000] D loss: 0.0179, G loss: 18.4619\n",
      "[4332/8000] D loss: 0.1952, G loss: 11.5152\n",
      "[4692/8000] D loss: 0.1202, G loss: 16.0866\n",
      "[5052/8000] D loss: 0.0291, G loss: 12.7472\n",
      "[5412/8000] D loss: 0.2315, G loss: 13.9666\n",
      "[5772/8000] D loss: 0.2294, G loss: 11.3901\n",
      "[6132/8000] D loss: 0.1300, G loss: 12.4458\n",
      "[6492/8000] D loss: 0.5988, G loss: 8.3547\n",
      "[6852/8000] D loss: 0.0196, G loss: 13.3212\n",
      "[7212/8000] D loss: 0.2322, G loss: 13.0078\n",
      "[7572/8000] D loss: 0.1855, G loss: 10.2638\n",
      "[7932/8000] D loss: 0.1215, G loss: 12.1420\n",
      "train error: \n",
      " D loss: 0.277214, G loss: 11.868829, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.656393, G loss: 16.981324, D accuracy: 91.9%, cell accuracy: 94.5%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0680, G loss: 15.0462\n",
      "[372/8000] D loss: 0.1717, G loss: 9.7982\n",
      "[732/8000] D loss: 0.1508, G loss: 13.0461\n",
      "[1092/8000] D loss: 0.1241, G loss: 11.4184\n",
      "[1452/8000] D loss: 0.2641, G loss: 12.0684\n",
      "[1812/8000] D loss: 0.2645, G loss: 14.0861\n",
      "[2172/8000] D loss: 0.4269, G loss: 13.8560\n",
      "[2532/8000] D loss: 0.3275, G loss: 12.6880\n",
      "[2892/8000] D loss: 0.1117, G loss: 11.2972\n",
      "[3252/8000] D loss: 0.2350, G loss: 12.1486\n",
      "[3612/8000] D loss: 0.1127, G loss: 16.3569\n",
      "[3972/8000] D loss: 0.2809, G loss: 8.3302\n",
      "[4332/8000] D loss: 0.4515, G loss: 8.4188\n",
      "[4692/8000] D loss: 0.3669, G loss: 6.3575\n",
      "[5052/8000] D loss: 0.4238, G loss: 6.8164\n",
      "[5412/8000] D loss: 0.2933, G loss: 12.3548\n",
      "[5772/8000] D loss: 0.5884, G loss: 11.2470\n",
      "[6132/8000] D loss: 0.2245, G loss: 10.5978\n",
      "[6492/8000] D loss: 0.4435, G loss: 10.6512\n",
      "[6852/8000] D loss: 0.1288, G loss: 7.5834\n",
      "[7212/8000] D loss: 0.2720, G loss: 14.0729\n",
      "[7572/8000] D loss: 0.1172, G loss: 11.5689\n",
      "[7932/8000] D loss: 0.2454, G loss: 11.5017\n",
      "train error: \n",
      " D loss: 0.275549, G loss: 11.904949, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.627583, G loss: 16.740973, D accuracy: 91.8%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3777, G loss: 11.5774\n",
      "[372/8000] D loss: 0.4193, G loss: 9.1430\n",
      "[732/8000] D loss: 0.0103, G loss: 18.7736\n",
      "[1092/8000] D loss: 0.3863, G loss: 11.0227\n",
      "[1452/8000] D loss: 0.4602, G loss: 5.9827\n",
      "[1812/8000] D loss: 0.1248, G loss: 11.5832\n",
      "[2172/8000] D loss: 0.2240, G loss: 13.0450\n",
      "[2532/8000] D loss: 0.2766, G loss: 17.0323\n",
      "[2892/8000] D loss: 0.1279, G loss: 9.7001\n",
      "[3252/8000] D loss: 0.1791, G loss: 8.5509\n",
      "[3612/8000] D loss: 0.5116, G loss: 9.7275\n",
      "[3972/8000] D loss: 0.1198, G loss: 14.0551\n",
      "[4332/8000] D loss: 0.1528, G loss: 11.3442\n",
      "[4692/8000] D loss: 0.6416, G loss: 8.6591\n",
      "[5052/8000] D loss: 0.2877, G loss: 7.7185\n",
      "[5412/8000] D loss: 0.1203, G loss: 11.3766\n",
      "[5772/8000] D loss: 0.1181, G loss: 16.8175\n",
      "[6132/8000] D loss: 0.2074, G loss: 17.4068\n",
      "[6492/8000] D loss: 0.5269, G loss: 8.4216\n",
      "[6852/8000] D loss: 0.1591, G loss: 12.3077\n",
      "[7212/8000] D loss: 0.1215, G loss: 18.2439\n",
      "[7572/8000] D loss: 0.0168, G loss: 14.3965\n",
      "[7932/8000] D loss: 0.4985, G loss: 5.9056\n",
      "train error: \n",
      " D loss: 0.311103, G loss: 8.497065, D accuracy: 91.1%, cell accuracy: 94.9%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.463766, G loss: 13.028974, D accuracy: 93.0%, cell accuracy: 94.4%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2908, G loss: 6.6252\n",
      "[372/8000] D loss: 0.1243, G loss: 11.8560\n",
      "[732/8000] D loss: 0.1460, G loss: 12.7920\n",
      "[1092/8000] D loss: 0.1077, G loss: 13.4635\n",
      "[1452/8000] D loss: 0.1239, G loss: 12.4195\n",
      "[1812/8000] D loss: 0.1210, G loss: 13.6887\n",
      "[2172/8000] D loss: 0.3496, G loss: 13.2507\n",
      "[2532/8000] D loss: 0.2527, G loss: 10.7980\n",
      "[2892/8000] D loss: 0.4633, G loss: 10.0218\n",
      "[3252/8000] D loss: 0.3577, G loss: 9.6315\n",
      "[3612/8000] D loss: 0.0111, G loss: 13.2685\n",
      "[3972/8000] D loss: 0.1789, G loss: 11.0266\n",
      "[4332/8000] D loss: 0.3605, G loss: 9.6431\n",
      "[4692/8000] D loss: 0.2718, G loss: 7.8953\n",
      "[5052/8000] D loss: 0.1605, G loss: 10.4204\n",
      "[5412/8000] D loss: 0.5182, G loss: 8.4177\n",
      "[5772/8000] D loss: 0.1195, G loss: 13.9301\n",
      "[6132/8000] D loss: 0.6728, G loss: 8.4526\n",
      "[6492/8000] D loss: 0.2265, G loss: 13.2420\n",
      "[6852/8000] D loss: 0.2401, G loss: 12.5552\n",
      "[7212/8000] D loss: 0.4331, G loss: 13.2911\n",
      "[7572/8000] D loss: 0.1782, G loss: 12.9200\n",
      "[7932/8000] D loss: 0.0123, G loss: 11.9768\n",
      "train error: \n",
      " D loss: 0.282755, G loss: 11.818479, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608882, G loss: 16.859212, D accuracy: 91.5%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0181, G loss: 11.8267\n",
      "[372/8000] D loss: 0.3011, G loss: 12.4748\n",
      "[732/8000] D loss: 0.4789, G loss: 11.6492\n",
      "[1092/8000] D loss: 0.1687, G loss: 10.3894\n",
      "[1452/8000] D loss: 0.1245, G loss: 15.7914\n",
      "[1812/8000] D loss: 0.1889, G loss: 12.8629\n",
      "[2172/8000] D loss: 0.2432, G loss: 12.1008\n",
      "[2532/8000] D loss: 0.3613, G loss: 10.9353\n",
      "[2892/8000] D loss: 0.3734, G loss: 6.6763\n",
      "[3252/8000] D loss: 0.3231, G loss: 7.3871\n",
      "[3612/8000] D loss: 0.1664, G loss: 10.5517\n",
      "[3972/8000] D loss: 0.4655, G loss: 10.5918\n",
      "[4332/8000] D loss: 0.1855, G loss: 11.5971\n",
      "[4692/8000] D loss: 0.1403, G loss: 9.7122\n",
      "[5052/8000] D loss: 0.3309, G loss: 11.6374\n",
      "[5412/8000] D loss: 0.5041, G loss: 10.6679\n",
      "[5772/8000] D loss: 0.4541, G loss: 12.1430\n",
      "[6132/8000] D loss: 0.4021, G loss: 12.0577\n",
      "[6492/8000] D loss: 0.2324, G loss: 11.9304\n",
      "[6852/8000] D loss: 0.5215, G loss: 7.8733\n",
      "[7212/8000] D loss: 0.3698, G loss: 11.2227\n",
      "[7572/8000] D loss: 0.1639, G loss: 13.2332\n",
      "[7932/8000] D loss: 0.2754, G loss: 13.0075\n",
      "train error: \n",
      " D loss: 0.307680, G loss: 9.690335, D accuracy: 91.2%, cell accuracy: 94.9%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.530165, G loss: 14.580674, D accuracy: 93.3%, cell accuracy: 94.4%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1341, G loss: 9.9425\n",
      "[372/8000] D loss: 0.0696, G loss: 13.4006\n",
      "[732/8000] D loss: 0.3068, G loss: 10.6271\n",
      "[1092/8000] D loss: 0.3531, G loss: 11.4922\n",
      "[1452/8000] D loss: 0.0010, G loss: 17.8242\n",
      "[1812/8000] D loss: 0.0025, G loss: 18.8729\n",
      "[2172/8000] D loss: 0.2240, G loss: 11.7372\n",
      "[2532/8000] D loss: 0.7070, G loss: 6.4273\n",
      "[2892/8000] D loss: 0.6515, G loss: 9.1904\n",
      "[3252/8000] D loss: 0.2516, G loss: 8.0848\n",
      "[3612/8000] D loss: 0.3609, G loss: 8.3381\n",
      "[3972/8000] D loss: 0.3383, G loss: 7.9414\n",
      "[4332/8000] D loss: 0.0065, G loss: 10.9475\n",
      "[4692/8000] D loss: 0.3732, G loss: 6.2392\n",
      "[5052/8000] D loss: 0.2169, G loss: 11.3117\n",
      "[5412/8000] D loss: 0.6558, G loss: 8.6618\n",
      "[5772/8000] D loss: 0.1502, G loss: 14.6146\n",
      "[6132/8000] D loss: 0.2130, G loss: 13.3360\n",
      "[6492/8000] D loss: 0.0134, G loss: 14.7123\n",
      "[6852/8000] D loss: 0.1273, G loss: 21.9356\n",
      "[7212/8000] D loss: 0.6065, G loss: 4.7756\n",
      "[7572/8000] D loss: 0.2412, G loss: 12.0695\n",
      "[7932/8000] D loss: 0.0012, G loss: 15.1134\n",
      "train error: \n",
      " D loss: 0.267585, G loss: 11.689587, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.612916, G loss: 16.823152, D accuracy: 92.0%, cell accuracy: 94.4%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0888, G loss: 16.1899\n",
      "[372/8000] D loss: 0.4139, G loss: 6.8054\n",
      "[732/8000] D loss: 0.4422, G loss: 10.6940\n",
      "[1092/8000] D loss: 0.2563, G loss: 10.4410\n",
      "[1452/8000] D loss: 0.2482, G loss: 9.0485\n",
      "[1812/8000] D loss: 0.1202, G loss: 11.6854\n",
      "[2172/8000] D loss: 0.4635, G loss: 8.8384\n",
      "[2532/8000] D loss: 0.1214, G loss: 13.6412\n",
      "[2892/8000] D loss: 0.0575, G loss: 11.3779\n",
      "[3252/8000] D loss: 0.3447, G loss: 9.3741\n",
      "[3612/8000] D loss: 0.1925, G loss: 21.4567\n",
      "[3972/8000] D loss: 0.1133, G loss: 14.4902\n",
      "[4332/8000] D loss: 0.4905, G loss: 9.3673\n",
      "[4692/8000] D loss: 0.2400, G loss: 10.5025\n",
      "[5052/8000] D loss: 0.2584, G loss: 9.5631\n",
      "[5412/8000] D loss: 0.1213, G loss: 14.0344\n",
      "[5772/8000] D loss: 0.2922, G loss: 10.6479\n",
      "[6132/8000] D loss: 0.2438, G loss: 15.3769\n",
      "[6492/8000] D loss: 0.3299, G loss: 9.3420\n",
      "[6852/8000] D loss: 0.2457, G loss: 13.9128\n",
      "[7212/8000] D loss: 0.2307, G loss: 10.0589\n",
      "[7572/8000] D loss: 0.0180, G loss: 11.9118\n",
      "[7932/8000] D loss: 0.5984, G loss: 7.4936\n",
      "train error: \n",
      " D loss: 0.265693, G loss: 11.650954, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.612122, G loss: 16.720167, D accuracy: 91.5%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2386, G loss: 14.1992\n",
      "[372/8000] D loss: 0.1161, G loss: 12.4654\n",
      "[732/8000] D loss: 0.1440, G loss: 12.6220\n",
      "[1092/8000] D loss: 0.4189, G loss: 8.9376\n",
      "[1452/8000] D loss: 0.4498, G loss: 16.0236\n",
      "[1812/8000] D loss: 0.2209, G loss: 9.0887\n",
      "[2172/8000] D loss: 0.1999, G loss: 8.8561\n",
      "[2532/8000] D loss: 0.2023, G loss: 6.3388\n",
      "[2892/8000] D loss: 0.2859, G loss: 10.9528\n",
      "[3252/8000] D loss: 0.2076, G loss: 11.2341\n",
      "[3612/8000] D loss: 0.0434, G loss: 13.3623\n",
      "[3972/8000] D loss: 0.3187, G loss: 12.6189\n",
      "[4332/8000] D loss: 0.0548, G loss: 11.6355\n",
      "[4692/8000] D loss: 0.2257, G loss: 13.1087\n",
      "[5052/8000] D loss: 0.1187, G loss: 13.0527\n",
      "[5412/8000] D loss: 0.2358, G loss: 14.6278\n",
      "[5772/8000] D loss: 0.1323, G loss: 10.6107\n",
      "[6132/8000] D loss: 0.4696, G loss: 6.2692\n",
      "[6492/8000] D loss: 0.1701, G loss: 12.2709\n",
      "[6852/8000] D loss: 0.1290, G loss: 11.6660\n",
      "[7212/8000] D loss: 0.3472, G loss: 10.7297\n",
      "[7572/8000] D loss: 0.1312, G loss: 12.9987\n",
      "[7932/8000] D loss: 0.3783, G loss: 11.6464\n",
      "train error: \n",
      " D loss: 0.272635, G loss: 11.377197, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 15.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.579164, G loss: 16.430276, D accuracy: 92.3%, cell accuracy: 94.4%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1267, G loss: 12.3114\n",
      "[372/8000] D loss: 0.5718, G loss: 11.5388\n",
      "[732/8000] D loss: 0.2710, G loss: 12.1684\n",
      "[1092/8000] D loss: 0.4725, G loss: 10.9409\n",
      "[1452/8000] D loss: 0.0243, G loss: 15.5175\n",
      "[1812/8000] D loss: 0.3247, G loss: 11.8808\n",
      "[2172/8000] D loss: 0.1417, G loss: 14.5664\n",
      "[2532/8000] D loss: 0.0149, G loss: 15.3024\n",
      "[2892/8000] D loss: 0.2679, G loss: 12.3477\n",
      "[3252/8000] D loss: 0.2686, G loss: 11.3833\n",
      "[3612/8000] D loss: 0.3327, G loss: 12.4331\n",
      "[3972/8000] D loss: 0.6079, G loss: 8.4712\n",
      "[4332/8000] D loss: 0.1426, G loss: 14.0594\n",
      "[4692/8000] D loss: 0.2739, G loss: 12.6259\n",
      "[5052/8000] D loss: 0.1203, G loss: 11.3542\n",
      "[5412/8000] D loss: 0.2368, G loss: 13.7952\n",
      "[5772/8000] D loss: 0.2686, G loss: 13.7121\n",
      "[6132/8000] D loss: 0.3825, G loss: 7.8860\n",
      "[6492/8000] D loss: 0.2725, G loss: 10.8196\n",
      "[6852/8000] D loss: 0.5636, G loss: 9.8062\n",
      "[7212/8000] D loss: 0.1253, G loss: 9.5578\n",
      "[7572/8000] D loss: 0.3516, G loss: 8.1182\n",
      "[7932/8000] D loss: 0.0113, G loss: 12.8254\n",
      "train error: \n",
      " D loss: 0.273205, G loss: 12.123916, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.656080, G loss: 17.297868, D accuracy: 91.5%, cell accuracy: 94.5%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1321, G loss: 17.1746\n",
      "[372/8000] D loss: 0.4285, G loss: 14.7104\n",
      "[732/8000] D loss: 0.3943, G loss: 11.5004\n",
      "[1092/8000] D loss: 0.3503, G loss: 11.1580\n",
      "[1452/8000] D loss: 0.1418, G loss: 15.0397\n",
      "[1812/8000] D loss: 0.3108, G loss: 7.9276\n",
      "[2172/8000] D loss: 0.2329, G loss: 13.3397\n",
      "[2532/8000] D loss: 0.1737, G loss: 16.4258\n",
      "[2892/8000] D loss: 0.1440, G loss: 11.6204\n",
      "[3252/8000] D loss: 0.4831, G loss: 11.3433\n",
      "[3612/8000] D loss: 0.3524, G loss: 16.1545\n",
      "[3972/8000] D loss: 0.3060, G loss: 11.0490\n",
      "[4332/8000] D loss: 0.1648, G loss: 14.3732\n",
      "[4692/8000] D loss: 0.3391, G loss: 9.4507\n",
      "[5052/8000] D loss: 0.4950, G loss: 10.6181\n",
      "[5412/8000] D loss: 0.4017, G loss: 10.1532\n",
      "[5772/8000] D loss: 0.1899, G loss: 10.4311\n",
      "[6132/8000] D loss: 0.3559, G loss: 10.6306\n",
      "[6492/8000] D loss: 0.4282, G loss: 14.4686\n",
      "[6852/8000] D loss: 0.5097, G loss: 8.4914\n",
      "[7212/8000] D loss: 0.6476, G loss: 7.7822\n",
      "[7572/8000] D loss: 0.1374, G loss: 14.0366\n",
      "[7932/8000] D loss: 0.3946, G loss: 8.5029\n",
      "train error: \n",
      " D loss: 0.308986, G loss: 8.716441, D accuracy: 91.1%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.515742, G loss: 13.214692, D accuracy: 92.3%, cell accuracy: 94.5%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3204, G loss: 7.0657\n",
      "[372/8000] D loss: 0.2364, G loss: 14.7503\n",
      "[732/8000] D loss: 0.2154, G loss: 11.8988\n",
      "[1092/8000] D loss: 0.3748, G loss: 9.3850\n",
      "[1452/8000] D loss: 0.2346, G loss: 9.2606\n",
      "[1812/8000] D loss: 0.2531, G loss: 14.0639\n",
      "[2172/8000] D loss: 0.2522, G loss: 14.0572\n",
      "[2532/8000] D loss: 0.2462, G loss: 13.9032\n",
      "[2892/8000] D loss: 0.0765, G loss: 11.9523\n",
      "[3252/8000] D loss: 0.2364, G loss: 7.6405\n",
      "[3612/8000] D loss: 0.0132, G loss: 13.0554\n",
      "[3972/8000] D loss: 0.0090, G loss: 10.1424\n",
      "[4332/8000] D loss: 0.3910, G loss: 10.5397\n",
      "[4692/8000] D loss: 0.3667, G loss: 11.3532\n",
      "[5052/8000] D loss: 0.1121, G loss: 13.0474\n",
      "[5412/8000] D loss: 0.4486, G loss: 9.0786\n",
      "[5772/8000] D loss: 0.2836, G loss: 8.7533\n",
      "[6132/8000] D loss: 0.1230, G loss: 10.7504\n",
      "[6492/8000] D loss: 0.3336, G loss: 12.3742\n",
      "[6852/8000] D loss: 0.0062, G loss: 10.9260\n",
      "[7212/8000] D loss: 0.3662, G loss: 8.9855\n",
      "[7572/8000] D loss: 0.3487, G loss: 7.6825\n",
      "[7932/8000] D loss: 0.3044, G loss: 13.6579\n",
      "train error: \n",
      " D loss: 0.273143, G loss: 10.373282, D accuracy: 91.4%, cell accuracy: 94.9%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.563419, G loss: 15.289337, D accuracy: 92.0%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2453, G loss: 8.7978\n",
      "[372/8000] D loss: 0.4648, G loss: 11.8842\n",
      "[732/8000] D loss: 0.1150, G loss: 15.4265\n",
      "[1092/8000] D loss: 0.1265, G loss: 11.6987\n",
      "[1452/8000] D loss: 0.1196, G loss: 11.0131\n",
      "[1812/8000] D loss: 0.2389, G loss: 8.9789\n",
      "[2172/8000] D loss: 0.4751, G loss: 10.4648\n",
      "[2532/8000] D loss: 0.1532, G loss: 17.2691\n",
      "[2892/8000] D loss: 0.2499, G loss: 12.3840\n",
      "[3252/8000] D loss: 0.5171, G loss: 5.7728\n",
      "[3612/8000] D loss: 0.1220, G loss: 15.7962\n",
      "[3972/8000] D loss: 0.1469, G loss: 10.1212\n",
      "[4332/8000] D loss: 0.1214, G loss: 12.2157\n",
      "[4692/8000] D loss: 0.3064, G loss: 13.2037\n",
      "[5052/8000] D loss: 0.3570, G loss: 19.7842\n",
      "[5412/8000] D loss: 0.2650, G loss: 9.0579\n",
      "[5772/8000] D loss: 0.2845, G loss: 11.9508\n",
      "[6132/8000] D loss: 0.2111, G loss: 11.6937\n",
      "[6492/8000] D loss: 0.3660, G loss: 12.1525\n",
      "[6852/8000] D loss: 0.1193, G loss: 12.6836\n",
      "[7212/8000] D loss: 0.3007, G loss: 9.7736\n",
      "[7572/8000] D loss: 0.0072, G loss: 15.3678\n",
      "[7932/8000] D loss: 0.4725, G loss: 9.7933\n",
      "train error: \n",
      " D loss: 0.274097, G loss: 11.165817, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.557194, G loss: 16.140670, D accuracy: 92.2%, cell accuracy: 94.5%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2587, G loss: 8.8343\n",
      "[372/8000] D loss: 0.4364, G loss: 13.0022\n",
      "[732/8000] D loss: 0.1204, G loss: 16.5083\n",
      "[1092/8000] D loss: 0.1781, G loss: 14.1856\n",
      "[1452/8000] D loss: 0.3446, G loss: 12.1706\n",
      "[1812/8000] D loss: 0.1311, G loss: 11.4327\n",
      "[2172/8000] D loss: 0.5095, G loss: 7.7260\n",
      "[2532/8000] D loss: 0.4820, G loss: 9.4355\n",
      "[2892/8000] D loss: 0.0110, G loss: 13.6242\n",
      "[3252/8000] D loss: 0.4668, G loss: 10.1212\n",
      "[3612/8000] D loss: 0.1276, G loss: 12.0213\n",
      "[3972/8000] D loss: 0.0337, G loss: 13.2073\n",
      "[4332/8000] D loss: 0.1184, G loss: 18.3903\n",
      "[4692/8000] D loss: 0.2725, G loss: 9.9382\n",
      "[5052/8000] D loss: 0.3745, G loss: 9.3221\n",
      "[5412/8000] D loss: 0.2368, G loss: 11.7107\n",
      "[5772/8000] D loss: 0.2979, G loss: 10.1209\n",
      "[6132/8000] D loss: 0.1136, G loss: 11.7980\n",
      "[6492/8000] D loss: 0.3548, G loss: 11.5779\n",
      "[6852/8000] D loss: 0.2448, G loss: 13.8938\n",
      "[7212/8000] D loss: 0.2996, G loss: 8.2120\n",
      "[7572/8000] D loss: 0.1259, G loss: 11.0236\n",
      "[7932/8000] D loss: 0.0169, G loss: 7.1187\n",
      "train error: \n",
      " D loss: 0.284110, G loss: 9.408815, D accuracy: 91.1%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.579731, G loss: 14.086409, D accuracy: 90.6%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3233, G loss: 8.3443\n",
      "[372/8000] D loss: 0.2575, G loss: 12.5446\n",
      "[732/8000] D loss: 0.3399, G loss: 10.7199\n",
      "[1092/8000] D loss: 0.5049, G loss: 13.7406\n",
      "[1452/8000] D loss: 0.3568, G loss: 9.8188\n",
      "[1812/8000] D loss: 0.3432, G loss: 7.7585\n",
      "[2172/8000] D loss: 0.1232, G loss: 15.0570\n",
      "[2532/8000] D loss: 0.1902, G loss: 16.4866\n",
      "[2892/8000] D loss: 0.2902, G loss: 10.9763\n",
      "[3252/8000] D loss: 0.3250, G loss: 11.9585\n",
      "[3612/8000] D loss: 0.6712, G loss: 11.3615\n",
      "[3972/8000] D loss: 0.3715, G loss: 11.6418\n",
      "[4332/8000] D loss: 0.6155, G loss: 11.2731\n",
      "[4692/8000] D loss: 0.4485, G loss: 12.6847\n",
      "[5052/8000] D loss: 0.3569, G loss: 12.7978\n",
      "[5412/8000] D loss: 0.2226, G loss: 12.9509\n",
      "[5772/8000] D loss: 0.2221, G loss: 9.1836\n",
      "[6132/8000] D loss: 0.1594, G loss: 10.8732\n",
      "[6492/8000] D loss: 0.4059, G loss: 9.7197\n",
      "[6852/8000] D loss: 0.0287, G loss: 12.0278\n",
      "[7212/8000] D loss: 0.7515, G loss: 10.5893\n",
      "[7572/8000] D loss: 0.3432, G loss: 11.1514\n",
      "[7932/8000] D loss: 0.1733, G loss: 13.1320\n",
      "train error: \n",
      " D loss: 0.295598, G loss: 9.348481, D accuracy: 91.2%, cell accuracy: 94.9%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.495104, G loss: 14.030788, D accuracy: 92.1%, cell accuracy: 94.4%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4814, G loss: 9.0088\n",
      "[372/8000] D loss: 0.4450, G loss: 11.9489\n",
      "[732/8000] D loss: 0.0018, G loss: 13.0560\n",
      "[1092/8000] D loss: 0.2450, G loss: 10.4902\n",
      "[1452/8000] D loss: 0.5830, G loss: 7.0431\n",
      "[1812/8000] D loss: 0.2709, G loss: 9.9287\n",
      "[2172/8000] D loss: 0.1436, G loss: 14.1938\n",
      "[2532/8000] D loss: 0.2344, G loss: 14.2394\n",
      "[2892/8000] D loss: 0.0134, G loss: 17.6374\n",
      "[3252/8000] D loss: 0.2579, G loss: 10.6647\n",
      "[3612/8000] D loss: 0.2620, G loss: 8.9507\n",
      "[3972/8000] D loss: 0.1841, G loss: 13.9031\n",
      "[4332/8000] D loss: 0.7112, G loss: 9.3756\n",
      "[4692/8000] D loss: 0.2356, G loss: 9.5053\n",
      "[5052/8000] D loss: 0.3865, G loss: 6.2645\n",
      "[5412/8000] D loss: 0.2642, G loss: 11.8334\n",
      "[5772/8000] D loss: 0.3995, G loss: 11.4293\n",
      "[6132/8000] D loss: 0.1179, G loss: 17.9608\n",
      "[6492/8000] D loss: 0.5080, G loss: 7.3517\n",
      "[6852/8000] D loss: 0.0016, G loss: 14.0632\n",
      "[7212/8000] D loss: 0.2466, G loss: 9.0164\n",
      "[7572/8000] D loss: 0.4920, G loss: 9.6615\n",
      "[7932/8000] D loss: 0.1272, G loss: 15.4384\n",
      "train error: \n",
      " D loss: 0.277895, G loss: 10.623267, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.550022, G loss: 15.612982, D accuracy: 92.1%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2603, G loss: 8.9255\n",
      "[372/8000] D loss: 0.2753, G loss: 10.3498\n",
      "[732/8000] D loss: 0.0799, G loss: 9.1404\n",
      "[1092/8000] D loss: 0.2230, G loss: 9.7143\n",
      "[1452/8000] D loss: 0.3991, G loss: 10.8543\n",
      "[1812/8000] D loss: 0.4622, G loss: 11.0888\n",
      "[2172/8000] D loss: 0.3719, G loss: 12.1952\n",
      "[2532/8000] D loss: 0.2435, G loss: 11.9068\n",
      "[2892/8000] D loss: 0.2514, G loss: 8.6627\n",
      "[3252/8000] D loss: 0.1495, G loss: 14.5157\n",
      "[3612/8000] D loss: 0.2450, G loss: 8.6604\n",
      "[3972/8000] D loss: 0.4809, G loss: 10.1938\n",
      "[4332/8000] D loss: 0.4856, G loss: 9.2066\n",
      "[4692/8000] D loss: 0.5244, G loss: 8.9222\n",
      "[5052/8000] D loss: 0.3614, G loss: 10.4947\n",
      "[5412/8000] D loss: 0.3032, G loss: 12.4026\n",
      "[5772/8000] D loss: 0.2581, G loss: 10.0106\n",
      "[6132/8000] D loss: 0.5511, G loss: 17.0855\n",
      "[6492/8000] D loss: 0.2536, G loss: 10.2591\n",
      "[6852/8000] D loss: 0.1411, G loss: 14.3178\n",
      "[7212/8000] D loss: 0.4092, G loss: 7.2041\n",
      "[7572/8000] D loss: 0.0621, G loss: 12.0033\n",
      "[7932/8000] D loss: 0.1474, G loss: 12.7427\n",
      "train error: \n",
      " D loss: 0.263957, G loss: 11.809182, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.642034, G loss: 17.033084, D accuracy: 91.5%, cell accuracy: 94.5%, board accuracy: 6.4% \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3628, G loss: 7.8248\n",
      "[372/8000] D loss: 0.2329, G loss: 14.7365\n",
      "[732/8000] D loss: 0.3317, G loss: 11.0258\n",
      "[1092/8000] D loss: 0.0041, G loss: 17.9069\n",
      "[1452/8000] D loss: 0.2424, G loss: 12.7847\n",
      "[1812/8000] D loss: 0.3565, G loss: 14.5014\n",
      "[2172/8000] D loss: 0.3828, G loss: 13.8227\n",
      "[2532/8000] D loss: 0.4543, G loss: 7.0890\n",
      "[2892/8000] D loss: 0.1419, G loss: 15.7538\n",
      "[3252/8000] D loss: 0.0779, G loss: 14.0459\n",
      "[3612/8000] D loss: 0.5120, G loss: 10.2577\n",
      "[3972/8000] D loss: 0.2352, G loss: 9.4859\n",
      "[4332/8000] D loss: 0.1237, G loss: 12.2767\n",
      "[4692/8000] D loss: 0.3406, G loss: 11.9723\n",
      "[5052/8000] D loss: 0.3615, G loss: 10.6062\n",
      "[5412/8000] D loss: 0.1363, G loss: 11.0579\n",
      "[5772/8000] D loss: 0.1748, G loss: 11.5758\n",
      "[6132/8000] D loss: 0.1237, G loss: 11.1649\n",
      "[6492/8000] D loss: 0.2399, G loss: 11.9480\n",
      "[6852/8000] D loss: 0.1545, G loss: 6.0621\n",
      "[7212/8000] D loss: 0.2868, G loss: 9.3423\n",
      "[7572/8000] D loss: 0.2514, G loss: 9.5741\n",
      "[7932/8000] D loss: 0.2411, G loss: 12.3992\n",
      "train error: \n",
      " D loss: 0.267982, G loss: 11.072437, D accuracy: 91.7%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603203, G loss: 16.099902, D accuracy: 91.6%, cell accuracy: 94.5%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3814, G loss: 8.6456\n",
      "[372/8000] D loss: 0.1198, G loss: 12.9438\n",
      "[732/8000] D loss: 0.2038, G loss: 14.7019\n",
      "[1092/8000] D loss: 0.2610, G loss: 13.0684\n",
      "[1452/8000] D loss: 0.0362, G loss: 15.5365\n",
      "[1812/8000] D loss: 0.5732, G loss: 8.7849\n",
      "[2172/8000] D loss: 0.1595, G loss: 14.3223\n",
      "[2532/8000] D loss: 0.4887, G loss: 12.3062\n",
      "[2892/8000] D loss: 0.3817, G loss: 12.8307\n",
      "[3252/8000] D loss: 0.1304, G loss: 10.4345\n",
      "[3612/8000] D loss: 0.0017, G loss: 15.7924\n",
      "[3972/8000] D loss: 0.5092, G loss: 9.1026\n",
      "[4332/8000] D loss: 0.2330, G loss: 16.3343\n",
      "[4692/8000] D loss: 0.2004, G loss: 10.4370\n",
      "[5052/8000] D loss: 0.1149, G loss: 13.8663\n",
      "[5412/8000] D loss: 0.4934, G loss: 11.2745\n",
      "[5772/8000] D loss: 0.3438, G loss: 10.6831\n",
      "[6132/8000] D loss: 0.1847, G loss: 6.9177\n",
      "[6492/8000] D loss: 0.4063, G loss: 9.9559\n",
      "[6852/8000] D loss: 0.4707, G loss: 11.4769\n",
      "[7212/8000] D loss: 0.2480, G loss: 12.0600\n",
      "[7572/8000] D loss: 0.2503, G loss: 10.7131\n",
      "[7932/8000] D loss: 0.2542, G loss: 11.0402\n",
      "train error: \n",
      " D loss: 0.274871, G loss: 10.714255, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603577, G loss: 15.412873, D accuracy: 91.4%, cell accuracy: 94.5%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2657, G loss: 10.2165\n",
      "[372/8000] D loss: 0.3502, G loss: 8.7777\n",
      "[732/8000] D loss: 0.3541, G loss: 15.4355\n",
      "[1092/8000] D loss: 0.4693, G loss: 8.9060\n",
      "[1452/8000] D loss: 0.1308, G loss: 11.0601\n",
      "[1812/8000] D loss: 0.6640, G loss: 10.1806\n",
      "[2172/8000] D loss: 0.3398, G loss: 12.7547\n",
      "[2532/8000] D loss: 0.3550, G loss: 15.0797\n",
      "[2892/8000] D loss: 0.1272, G loss: 10.7808\n",
      "[3252/8000] D loss: 0.2273, G loss: 16.2372\n",
      "[3612/8000] D loss: 0.6833, G loss: 11.2276\n",
      "[3972/8000] D loss: 0.4232, G loss: 9.8376\n",
      "[4332/8000] D loss: 0.3359, G loss: 12.0443\n",
      "[4692/8000] D loss: 0.2420, G loss: 10.8415\n",
      "[5052/8000] D loss: 0.2286, G loss: 11.7970\n",
      "[5412/8000] D loss: 0.0376, G loss: 17.5743\n",
      "[5772/8000] D loss: 0.2118, G loss: 9.8234\n",
      "[6132/8000] D loss: 0.0032, G loss: 13.6227\n",
      "[6492/8000] D loss: 0.2683, G loss: 10.0316\n",
      "[6852/8000] D loss: 0.1203, G loss: 17.2559\n",
      "[7212/8000] D loss: 0.3501, G loss: 11.3573\n",
      "[7572/8000] D loss: 0.1243, G loss: 15.6599\n",
      "[7932/8000] D loss: 0.2486, G loss: 14.3867\n",
      "train error: \n",
      " D loss: 0.268663, G loss: 11.710691, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.689283, G loss: 16.745534, D accuracy: 91.1%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5189, G loss: 7.6477\n",
      "[372/8000] D loss: 0.3656, G loss: 11.2734\n",
      "[732/8000] D loss: 0.2506, G loss: 11.8291\n",
      "[1092/8000] D loss: 0.1160, G loss: 12.0743\n",
      "[1452/8000] D loss: 0.1418, G loss: 6.7581\n",
      "[1812/8000] D loss: 0.1319, G loss: 12.1120\n",
      "[2172/8000] D loss: 0.1264, G loss: 15.5186\n",
      "[2532/8000] D loss: 0.3610, G loss: 14.1652\n",
      "[2892/8000] D loss: 0.3945, G loss: 9.4537\n",
      "[3252/8000] D loss: 0.1485, G loss: 9.8906\n",
      "[3612/8000] D loss: 0.6324, G loss: 9.4365\n",
      "[3972/8000] D loss: 0.5595, G loss: 8.6277\n",
      "[4332/8000] D loss: 0.1221, G loss: 10.3661\n",
      "[4692/8000] D loss: 0.3787, G loss: 9.6769\n",
      "[5052/8000] D loss: 0.0048, G loss: 15.4633\n",
      "[5412/8000] D loss: 0.5558, G loss: 8.1385\n",
      "[5772/8000] D loss: 0.4707, G loss: 12.2323\n",
      "[6132/8000] D loss: 0.3079, G loss: 12.9354\n",
      "[6492/8000] D loss: 0.2506, G loss: 10.0646\n",
      "[6852/8000] D loss: 0.2213, G loss: 11.6774\n",
      "[7212/8000] D loss: 0.1187, G loss: 12.6349\n",
      "[7572/8000] D loss: 0.1454, G loss: 8.5805\n",
      "[7932/8000] D loss: 0.1464, G loss: 10.3079\n",
      "train error: \n",
      " D loss: 0.283220, G loss: 12.366382, D accuracy: 91.3%, cell accuracy: 94.9%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.712549, G loss: 17.553496, D accuracy: 90.3%, cell accuracy: 94.5%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3428, G loss: 11.3334\n",
      "[372/8000] D loss: 0.3725, G loss: 8.5787\n",
      "[732/8000] D loss: 0.2127, G loss: 13.9889\n",
      "[1092/8000] D loss: 0.1139, G loss: 13.7388\n",
      "[1452/8000] D loss: 0.2335, G loss: 12.6030\n",
      "[1812/8000] D loss: 0.2517, G loss: 12.2696\n",
      "[2172/8000] D loss: 0.3118, G loss: 11.1943\n",
      "[2532/8000] D loss: 0.4167, G loss: 7.3452\n",
      "[2892/8000] D loss: 0.2086, G loss: 9.8531\n",
      "[3252/8000] D loss: 0.3872, G loss: 12.5970\n",
      "[3612/8000] D loss: 0.3703, G loss: 11.5621\n",
      "[3972/8000] D loss: 0.2387, G loss: 13.2337\n",
      "[4332/8000] D loss: 0.8078, G loss: 5.4013\n",
      "[4692/8000] D loss: 0.6150, G loss: 10.8198\n",
      "[5052/8000] D loss: 0.3367, G loss: 9.8074\n",
      "[5412/8000] D loss: 0.1189, G loss: 13.6965\n",
      "[5772/8000] D loss: 0.3629, G loss: 11.0305\n",
      "[6132/8000] D loss: 0.0006, G loss: 17.9093\n",
      "[6492/8000] D loss: 0.3846, G loss: 8.7319\n",
      "[6852/8000] D loss: 0.2550, G loss: 9.6175\n",
      "[7212/8000] D loss: 0.6777, G loss: 6.8222\n",
      "[7572/8000] D loss: 0.2740, G loss: 9.7105\n",
      "[7932/8000] D loss: 0.3317, G loss: 10.0804\n",
      "train error: \n",
      " D loss: 0.272945, G loss: 10.823115, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.606357, G loss: 15.814208, D accuracy: 91.1%, cell accuracy: 94.5%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2325, G loss: 11.6292\n",
      "[372/8000] D loss: 0.1708, G loss: 10.3615\n",
      "[732/8000] D loss: 0.5013, G loss: 10.8305\n",
      "[1092/8000] D loss: 0.7256, G loss: 7.2187\n",
      "[1452/8000] D loss: 0.3677, G loss: 9.5498\n",
      "[1812/8000] D loss: 0.0028, G loss: 13.4366\n",
      "[2172/8000] D loss: 0.2504, G loss: 8.3435\n",
      "[2532/8000] D loss: 0.4803, G loss: 9.3859\n",
      "[2892/8000] D loss: 0.1858, G loss: 12.9413\n",
      "[3252/8000] D loss: 0.0197, G loss: 13.1894\n",
      "[3612/8000] D loss: 0.3515, G loss: 9.9400\n",
      "[3972/8000] D loss: 0.2335, G loss: 10.3020\n",
      "[4332/8000] D loss: 0.1172, G loss: 15.4169\n",
      "[4692/8000] D loss: 0.0773, G loss: 11.2108\n",
      "[5052/8000] D loss: 0.2271, G loss: 12.9764\n",
      "[5412/8000] D loss: 0.1992, G loss: 12.9286\n",
      "[5772/8000] D loss: 0.2555, G loss: 10.1243\n",
      "[6132/8000] D loss: 0.3613, G loss: 7.4323\n",
      "[6492/8000] D loss: 0.3624, G loss: 10.7387\n",
      "[6852/8000] D loss: 0.3618, G loss: 7.7072\n",
      "[7212/8000] D loss: 0.0124, G loss: 15.8389\n",
      "[7572/8000] D loss: 0.4797, G loss: 9.0361\n",
      "[7932/8000] D loss: 0.3872, G loss: 10.3671\n",
      "train error: \n",
      " D loss: 0.273649, G loss: 12.443594, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.700377, G loss: 17.606943, D accuracy: 91.0%, cell accuracy: 94.5%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2381, G loss: 14.3723\n",
      "[372/8000] D loss: 0.3516, G loss: 9.4292\n",
      "[732/8000] D loss: 0.1191, G loss: 10.8304\n",
      "[1092/8000] D loss: 0.2396, G loss: 12.1303\n",
      "[1452/8000] D loss: 0.0336, G loss: 14.3894\n",
      "[1812/8000] D loss: 0.4746, G loss: 9.2476\n",
      "[2172/8000] D loss: 0.5595, G loss: 9.6443\n",
      "[2532/8000] D loss: 0.2382, G loss: 14.9167\n",
      "[2892/8000] D loss: 0.2176, G loss: 10.9652\n",
      "[3252/8000] D loss: 0.4477, G loss: 11.6748\n",
      "[3612/8000] D loss: 0.1329, G loss: 16.2691\n",
      "[3972/8000] D loss: 0.2384, G loss: 11.5195\n",
      "[4332/8000] D loss: 0.3712, G loss: 14.4482\n",
      "[4692/8000] D loss: 0.2539, G loss: 13.4881\n",
      "[5052/8000] D loss: 0.1549, G loss: 12.1421\n",
      "[5412/8000] D loss: 0.2418, G loss: 15.1441\n",
      "[5772/8000] D loss: 0.3739, G loss: 10.8985\n",
      "[6132/8000] D loss: 0.2593, G loss: 10.2632\n",
      "[6492/8000] D loss: 0.2337, G loss: 10.3251\n",
      "[6852/8000] D loss: 0.4038, G loss: 10.3817\n",
      "[7212/8000] D loss: 0.5023, G loss: 9.5743\n",
      "[7572/8000] D loss: 0.3547, G loss: 14.4809\n",
      "[7932/8000] D loss: 0.4531, G loss: 14.3887\n",
      "train error: \n",
      " D loss: 0.275795, G loss: 11.730059, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.612053, G loss: 16.885976, D accuracy: 92.0%, cell accuracy: 94.5%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5840, G loss: 9.5899\n",
      "[372/8000] D loss: 0.3069, G loss: 11.3180\n",
      "[732/8000] D loss: 0.2423, G loss: 15.7638\n",
      "[1092/8000] D loss: 0.0974, G loss: 16.8739\n",
      "[1452/8000] D loss: 0.1054, G loss: 11.4642\n",
      "[1812/8000] D loss: 0.1336, G loss: 16.9629\n",
      "[2172/8000] D loss: 0.2170, G loss: 14.8008\n",
      "[2532/8000] D loss: 0.2330, G loss: 12.1587\n",
      "[2892/8000] D loss: 0.0150, G loss: 11.8227\n",
      "[3252/8000] D loss: 0.1295, G loss: 8.8870\n",
      "[3612/8000] D loss: 0.2558, G loss: 11.0261\n",
      "[3972/8000] D loss: 0.3445, G loss: 14.2980\n",
      "[4332/8000] D loss: 0.5222, G loss: 9.9034\n",
      "[4692/8000] D loss: 0.1890, G loss: 12.6262\n",
      "[5052/8000] D loss: 0.2994, G loss: 10.7271\n",
      "[5412/8000] D loss: 0.4247, G loss: 9.1294\n",
      "[5772/8000] D loss: 0.1225, G loss: 13.0824\n",
      "[6132/8000] D loss: 0.1154, G loss: 13.8327\n",
      "[6492/8000] D loss: 0.4731, G loss: 9.7079\n",
      "[6852/8000] D loss: 0.2607, G loss: 11.6666\n",
      "[7212/8000] D loss: 0.2070, G loss: 11.7737\n",
      "[7572/8000] D loss: 0.2379, G loss: 14.0289\n",
      "[7932/8000] D loss: 0.4546, G loss: 10.3080\n",
      "train error: \n",
      " D loss: 0.271974, G loss: 10.610682, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.576783, G loss: 15.623131, D accuracy: 91.6%, cell accuracy: 94.5%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3855, G loss: 10.5592\n",
      "[372/8000] D loss: 0.2518, G loss: 7.1532\n",
      "[732/8000] D loss: 0.2386, G loss: 12.3781\n",
      "[1092/8000] D loss: 0.2252, G loss: 13.6402\n",
      "[1452/8000] D loss: 0.5294, G loss: 8.1298\n",
      "[1812/8000] D loss: 0.5563, G loss: 6.7759\n",
      "[2172/8000] D loss: 0.1150, G loss: 12.1193\n",
      "[2532/8000] D loss: 0.6073, G loss: 7.0441\n",
      "[2892/8000] D loss: 0.0082, G loss: 12.8559\n",
      "[3252/8000] D loss: 0.2333, G loss: 14.4655\n",
      "[3612/8000] D loss: 0.3533, G loss: 9.4865\n",
      "[3972/8000] D loss: 0.2300, G loss: 14.8884\n",
      "[4332/8000] D loss: 0.2751, G loss: 12.0252\n",
      "[4692/8000] D loss: 0.4012, G loss: 12.3535\n",
      "[5052/8000] D loss: 0.0122, G loss: 15.4794\n",
      "[5412/8000] D loss: 0.6388, G loss: 7.5605\n",
      "[5772/8000] D loss: 0.1248, G loss: 16.5231\n",
      "[6132/8000] D loss: 0.3186, G loss: 10.2136\n",
      "[6492/8000] D loss: 0.4820, G loss: 10.7491\n",
      "[6852/8000] D loss: 0.2806, G loss: 12.0558\n",
      "[7212/8000] D loss: 0.2096, G loss: 11.7414\n",
      "[7572/8000] D loss: 0.1620, G loss: 9.9474\n",
      "[7932/8000] D loss: 0.1244, G loss: 10.3730\n",
      "train error: \n",
      " D loss: 0.299818, G loss: 12.867886, D accuracy: 91.2%, cell accuracy: 94.9%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.753681, G loss: 18.264680, D accuracy: 90.2%, cell accuracy: 94.5%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2961, G loss: 10.5441\n",
      "[372/8000] D loss: 0.0362, G loss: 15.3231\n",
      "[732/8000] D loss: 0.3619, G loss: 10.7346\n",
      "[1092/8000] D loss: 0.4229, G loss: 13.9368\n",
      "[1452/8000] D loss: 0.3335, G loss: 8.8428\n",
      "[1812/8000] D loss: 0.1868, G loss: 14.4346\n",
      "[2172/8000] D loss: 0.1425, G loss: 10.6167\n",
      "[2532/8000] D loss: 0.2541, G loss: 11.0294\n",
      "[2892/8000] D loss: 0.1583, G loss: 11.9235\n",
      "[3252/8000] D loss: 0.3388, G loss: 11.2653\n",
      "[3612/8000] D loss: 0.2487, G loss: 11.8478\n",
      "[3972/8000] D loss: 0.2410, G loss: 10.7507\n",
      "[4332/8000] D loss: 0.3561, G loss: 11.6640\n",
      "[4692/8000] D loss: 0.0097, G loss: 15.1040\n",
      "[5052/8000] D loss: 0.3647, G loss: 9.9195\n",
      "[5412/8000] D loss: 0.0075, G loss: 12.6070\n",
      "[5772/8000] D loss: 0.2478, G loss: 16.3349\n",
      "[6132/8000] D loss: 0.6642, G loss: 7.6120\n",
      "[6492/8000] D loss: 0.1368, G loss: 14.9830\n",
      "[6852/8000] D loss: 0.1295, G loss: 11.1572\n",
      "[7212/8000] D loss: 0.5197, G loss: 8.8502\n",
      "[7572/8000] D loss: 0.2437, G loss: 9.2002\n",
      "[7932/8000] D loss: 0.2169, G loss: 10.3923\n",
      "train error: \n",
      " D loss: 0.266768, G loss: 11.864573, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.648576, G loss: 17.095557, D accuracy: 91.2%, cell accuracy: 94.5%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1485, G loss: 11.9578\n",
      "[372/8000] D loss: 0.1611, G loss: 10.5842\n",
      "[732/8000] D loss: 0.2458, G loss: 11.9370\n",
      "[1092/8000] D loss: 0.5040, G loss: 8.2634\n",
      "[1452/8000] D loss: 0.3827, G loss: 9.1083\n",
      "[1812/8000] D loss: 0.3453, G loss: 9.7724\n",
      "[2172/8000] D loss: 0.3714, G loss: 11.0667\n",
      "[2532/8000] D loss: 0.2273, G loss: 9.8532\n",
      "[2892/8000] D loss: 0.2238, G loss: 12.7538\n",
      "[3252/8000] D loss: 0.1413, G loss: 10.5238\n",
      "[3612/8000] D loss: 0.7190, G loss: 7.8071\n",
      "[3972/8000] D loss: 0.4795, G loss: 10.5090\n",
      "[4332/8000] D loss: 0.1838, G loss: 11.5843\n",
      "[4692/8000] D loss: 0.0941, G loss: 10.8418\n",
      "[5052/8000] D loss: 0.1192, G loss: 14.3205\n",
      "[5412/8000] D loss: 0.2810, G loss: 13.0065\n",
      "[5772/8000] D loss: 0.2321, G loss: 12.1161\n",
      "[6132/8000] D loss: 0.1437, G loss: 9.2599\n",
      "[6492/8000] D loss: 0.0057, G loss: 14.3209\n",
      "[6852/8000] D loss: 0.1588, G loss: 13.1612\n",
      "[7212/8000] D loss: 0.4492, G loss: 9.5211\n",
      "[7572/8000] D loss: 0.2598, G loss: 8.6736\n",
      "[7932/8000] D loss: 0.7244, G loss: 6.2552\n",
      "train error: \n",
      " D loss: 0.273714, G loss: 11.359075, D accuracy: 91.4%, cell accuracy: 94.9%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.595269, G loss: 16.345496, D accuracy: 91.5%, cell accuracy: 94.5%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1346, G loss: 14.4479\n",
      "[372/8000] D loss: 0.2645, G loss: 12.4901\n",
      "[732/8000] D loss: 0.1294, G loss: 14.2210\n",
      "[1092/8000] D loss: 0.3162, G loss: 9.8531\n",
      "[1452/8000] D loss: 0.2439, G loss: 10.2031\n",
      "[1812/8000] D loss: 0.2329, G loss: 12.9244\n",
      "[2172/8000] D loss: 0.2145, G loss: 12.1110\n",
      "[2532/8000] D loss: 0.1286, G loss: 16.6600\n",
      "[2892/8000] D loss: 0.2297, G loss: 12.2863\n",
      "[3252/8000] D loss: 0.0180, G loss: 13.2911\n",
      "[3612/8000] D loss: 0.2490, G loss: 8.6995\n",
      "[3972/8000] D loss: 0.2531, G loss: 6.3485\n",
      "[4332/8000] D loss: 0.2248, G loss: 13.2648\n",
      "[4692/8000] D loss: 0.3087, G loss: 10.9035\n",
      "[5052/8000] D loss: 0.2547, G loss: 11.4912\n",
      "[5412/8000] D loss: 0.3348, G loss: 10.3210\n",
      "[5772/8000] D loss: 0.6224, G loss: 7.8183\n",
      "[6132/8000] D loss: 0.1502, G loss: 10.1751\n",
      "[6492/8000] D loss: 0.3012, G loss: 11.2804\n",
      "[6852/8000] D loss: 0.1577, G loss: 12.8007\n",
      "[7212/8000] D loss: 0.1251, G loss: 14.3833\n",
      "[7572/8000] D loss: 0.4850, G loss: 8.8996\n",
      "[7932/8000] D loss: 0.5538, G loss: 9.5370\n",
      "train error: \n",
      " D loss: 0.266242, G loss: 11.807681, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.662853, G loss: 17.076941, D accuracy: 91.2%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1407, G loss: 14.5145\n",
      "[372/8000] D loss: 0.3193, G loss: 8.8595\n",
      "[732/8000] D loss: 0.5492, G loss: 8.9468\n",
      "[1092/8000] D loss: 0.2829, G loss: 8.6447\n",
      "[1452/8000] D loss: 0.1206, G loss: 13.2009\n",
      "[1812/8000] D loss: 0.2325, G loss: 13.2243\n",
      "[2172/8000] D loss: 0.6498, G loss: 8.7687\n",
      "[2532/8000] D loss: 0.2914, G loss: 7.7003\n",
      "[2892/8000] D loss: 0.5975, G loss: 7.6251\n",
      "[3252/8000] D loss: 0.2375, G loss: 12.7083\n",
      "[3612/8000] D loss: 0.0064, G loss: 16.0645\n",
      "[3972/8000] D loss: 0.3540, G loss: 8.2668\n",
      "[4332/8000] D loss: 0.2429, G loss: 14.1137\n",
      "[4692/8000] D loss: 0.2476, G loss: 8.3191\n",
      "[5052/8000] D loss: 0.4276, G loss: 10.8174\n",
      "[5412/8000] D loss: 0.2315, G loss: 13.6744\n",
      "[5772/8000] D loss: 0.0880, G loss: 11.4739\n",
      "[6132/8000] D loss: 0.1390, G loss: 10.1311\n",
      "[6492/8000] D loss: 0.3503, G loss: 9.5145\n",
      "[6852/8000] D loss: 0.0457, G loss: 20.5774\n",
      "[7212/8000] D loss: 0.2477, G loss: 12.8032\n",
      "[7572/8000] D loss: 0.3456, G loss: 8.7134\n",
      "[7932/8000] D loss: 0.3655, G loss: 6.6929\n",
      "train error: \n",
      " D loss: 0.270037, G loss: 11.846711, D accuracy: 91.8%, cell accuracy: 95.0%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.607637, G loss: 17.162574, D accuracy: 91.4%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1697, G loss: 12.3920\n",
      "[372/8000] D loss: 0.2519, G loss: 13.2364\n",
      "[732/8000] D loss: 0.3545, G loss: 9.7226\n",
      "[1092/8000] D loss: 0.1181, G loss: 11.6943\n",
      "[1452/8000] D loss: 0.1391, G loss: 13.8242\n",
      "[1812/8000] D loss: 0.2628, G loss: 9.3417\n",
      "[2172/8000] D loss: 0.2805, G loss: 14.4377\n",
      "[2532/8000] D loss: 0.3841, G loss: 11.5040\n",
      "[2892/8000] D loss: 0.1528, G loss: 17.2447\n",
      "[3252/8000] D loss: 0.3632, G loss: 9.2438\n",
      "[3612/8000] D loss: 0.1412, G loss: 14.3137\n",
      "[3972/8000] D loss: 0.2278, G loss: 14.7610\n",
      "[4332/8000] D loss: 0.1572, G loss: 10.6564\n",
      "[4692/8000] D loss: 0.1235, G loss: 16.5930\n",
      "[5052/8000] D loss: 0.2173, G loss: 13.4392\n",
      "[5412/8000] D loss: 0.0355, G loss: 13.2612\n",
      "[5772/8000] D loss: 0.3585, G loss: 12.9126\n",
      "[6132/8000] D loss: 0.1188, G loss: 12.6344\n",
      "[6492/8000] D loss: 0.0031, G loss: 20.3334\n",
      "[6852/8000] D loss: 0.1472, G loss: 11.6357\n",
      "[7212/8000] D loss: 0.4746, G loss: 8.9033\n",
      "[7572/8000] D loss: 0.2298, G loss: 12.1045\n",
      "[7932/8000] D loss: 0.4278, G loss: 15.3343\n",
      "train error: \n",
      " D loss: 0.276373, G loss: 10.387562, D accuracy: 91.6%, cell accuracy: 95.0%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.569384, G loss: 15.491343, D accuracy: 92.8%, cell accuracy: 94.5%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1401, G loss: 8.0353\n",
      "[372/8000] D loss: 0.1474, G loss: 11.9975\n",
      "[732/8000] D loss: 0.3249, G loss: 12.0546\n",
      "[1092/8000] D loss: 0.1280, G loss: 10.2349\n",
      "[1452/8000] D loss: 0.4478, G loss: 11.7044\n",
      "[1812/8000] D loss: 0.1999, G loss: 10.7617\n",
      "[2172/8000] D loss: 0.2912, G loss: 8.5291\n",
      "[2532/8000] D loss: 0.4476, G loss: 13.2202\n",
      "[2892/8000] D loss: 0.3930, G loss: 10.4693\n",
      "[3252/8000] D loss: 0.2831, G loss: 8.9344\n",
      "[3612/8000] D loss: 0.1178, G loss: 11.3816\n",
      "[3972/8000] D loss: 0.2342, G loss: 11.2850\n",
      "[4332/8000] D loss: 0.2870, G loss: 10.7666\n",
      "[4692/8000] D loss: 0.2217, G loss: 16.9367\n",
      "[5052/8000] D loss: 0.2322, G loss: 10.3063\n",
      "[5412/8000] D loss: 0.3164, G loss: 7.9910\n",
      "[5772/8000] D loss: 0.1185, G loss: 11.1783\n",
      "[6132/8000] D loss: 0.2316, G loss: 13.4818\n",
      "[6492/8000] D loss: 0.1579, G loss: 11.2250\n",
      "[6852/8000] D loss: 0.1342, G loss: 15.0696\n",
      "[7212/8000] D loss: 0.2573, G loss: 13.7465\n",
      "[7572/8000] D loss: 0.0021, G loss: 15.1132\n",
      "[7932/8000] D loss: 0.2485, G loss: 11.1700\n",
      "train error: \n",
      " D loss: 0.265724, G loss: 12.302004, D accuracy: 91.8%, cell accuracy: 94.9%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.647098, G loss: 17.607042, D accuracy: 91.5%, cell accuracy: 94.5%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1240, G loss: 11.9818\n",
      "[372/8000] D loss: 0.4677, G loss: 9.6867\n",
      "[732/8000] D loss: 0.3565, G loss: 12.6606\n",
      "[1092/8000] D loss: 0.4841, G loss: 7.1792\n",
      "[1452/8000] D loss: 0.1557, G loss: 12.6656\n",
      "[1812/8000] D loss: 0.2523, G loss: 10.9692\n",
      "[2172/8000] D loss: 0.0064, G loss: 17.2283\n",
      "[2532/8000] D loss: 0.3496, G loss: 10.6277\n",
      "[2892/8000] D loss: 0.2328, G loss: 11.2759\n",
      "[3252/8000] D loss: 0.7134, G loss: 5.0676\n",
      "[3612/8000] D loss: 0.2349, G loss: 15.5284\n",
      "[3972/8000] D loss: 0.1213, G loss: 13.7198\n",
      "[4332/8000] D loss: 0.1200, G loss: 15.1934\n",
      "[4692/8000] D loss: 0.4088, G loss: 7.4071\n",
      "[5052/8000] D loss: 0.3157, G loss: 9.6659\n",
      "[5412/8000] D loss: 0.2857, G loss: 13.3881\n",
      "[5772/8000] D loss: 0.2100, G loss: 10.6069\n",
      "[6132/8000] D loss: 0.3876, G loss: 12.9199\n",
      "[6492/8000] D loss: 0.0046, G loss: 12.9300\n",
      "[6852/8000] D loss: 0.0980, G loss: 8.8135\n",
      "[7212/8000] D loss: 0.3481, G loss: 11.0362\n",
      "[7572/8000] D loss: 0.0494, G loss: 13.6550\n",
      "[7932/8000] D loss: 0.3449, G loss: 8.7492\n",
      "train error: \n",
      " D loss: 0.268690, G loss: 11.185450, D accuracy: 91.8%, cell accuracy: 95.0%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.571897, G loss: 16.290666, D accuracy: 92.8%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2821, G loss: 14.9800\n",
      "[372/8000] D loss: 0.2490, G loss: 13.1697\n",
      "[732/8000] D loss: 0.2336, G loss: 12.0851\n",
      "[1092/8000] D loss: 0.3787, G loss: 11.7066\n",
      "[1452/8000] D loss: 0.0132, G loss: 16.9529\n",
      "[1812/8000] D loss: 0.2897, G loss: 12.2421\n",
      "[2172/8000] D loss: 0.5953, G loss: 11.7646\n",
      "[2532/8000] D loss: 0.3447, G loss: 9.0414\n",
      "[2892/8000] D loss: 0.2326, G loss: 11.7669\n",
      "[3252/8000] D loss: 0.2362, G loss: 10.0851\n",
      "[3612/8000] D loss: 0.4762, G loss: 11.3725\n",
      "[3972/8000] D loss: 0.6141, G loss: 9.6979\n",
      "[4332/8000] D loss: 0.2389, G loss: 8.5025\n",
      "[4692/8000] D loss: 0.3078, G loss: 10.3681\n",
      "[5052/8000] D loss: 0.5246, G loss: 10.7022\n",
      "[5412/8000] D loss: 0.0588, G loss: 11.9435\n",
      "[5772/8000] D loss: 0.3578, G loss: 12.4184\n",
      "[6132/8000] D loss: 0.1741, G loss: 11.1035\n",
      "[6492/8000] D loss: 0.1196, G loss: 13.0980\n",
      "[6852/8000] D loss: 0.1388, G loss: 12.8594\n",
      "[7212/8000] D loss: 0.1258, G loss: 10.3905\n",
      "[7572/8000] D loss: 0.2356, G loss: 11.8590\n",
      "[7932/8000] D loss: 0.1202, G loss: 8.6417\n",
      "train error: \n",
      " D loss: 0.264522, G loss: 12.383712, D accuracy: 91.9%, cell accuracy: 95.0%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.634141, G loss: 17.796395, D accuracy: 91.8%, cell accuracy: 94.5%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0145, G loss: 11.7319\n",
      "[372/8000] D loss: 0.3449, G loss: 11.5386\n",
      "[732/8000] D loss: 0.0037, G loss: 18.7289\n",
      "[1092/8000] D loss: 0.4708, G loss: 9.9905\n",
      "[1452/8000] D loss: 0.2640, G loss: 10.5053\n",
      "[1812/8000] D loss: 0.1192, G loss: 12.9527\n",
      "[2172/8000] D loss: 0.3888, G loss: 5.5941\n",
      "[2532/8000] D loss: 0.2316, G loss: 14.7859\n",
      "[2892/8000] D loss: 0.1425, G loss: 12.4371\n",
      "[3252/8000] D loss: 0.1827, G loss: 8.1338\n",
      "[3612/8000] D loss: 0.1226, G loss: 14.8809\n",
      "[3972/8000] D loss: 0.1551, G loss: 15.2723\n",
      "[4332/8000] D loss: 0.4538, G loss: 9.4511\n",
      "[4692/8000] D loss: 0.2251, G loss: 13.2740\n",
      "[5052/8000] D loss: 0.2084, G loss: 13.4125\n",
      "[5412/8000] D loss: 0.3508, G loss: 10.3840\n",
      "[5772/8000] D loss: 0.4735, G loss: 11.5327\n",
      "[6132/8000] D loss: 0.2359, G loss: 7.4198\n",
      "[6492/8000] D loss: 0.2703, G loss: 8.1321\n",
      "[6852/8000] D loss: 0.2845, G loss: 14.9807\n",
      "[7212/8000] D loss: 0.2729, G loss: 10.5709\n",
      "[7572/8000] D loss: 0.1238, G loss: 13.6306\n",
      "[7932/8000] D loss: 0.2087, G loss: 10.3755\n",
      "train error: \n",
      " D loss: 0.270288, G loss: 12.369022, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.698179, G loss: 17.736393, D accuracy: 90.9%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2000, G loss: 14.8943\n",
      "[372/8000] D loss: 0.4599, G loss: 14.2399\n",
      "[732/8000] D loss: 0.5816, G loss: 10.7790\n",
      "[1092/8000] D loss: 0.2749, G loss: 14.5514\n",
      "[1452/8000] D loss: 0.2652, G loss: 13.3848\n",
      "[1812/8000] D loss: 0.3335, G loss: 12.1246\n",
      "[2172/8000] D loss: 0.2346, G loss: 15.0438\n",
      "[2532/8000] D loss: 0.0390, G loss: 8.8581\n",
      "[2892/8000] D loss: 0.5326, G loss: 11.6161\n",
      "[3252/8000] D loss: 0.1212, G loss: 11.5044\n",
      "[3612/8000] D loss: 0.2430, G loss: 10.5995\n",
      "[3972/8000] D loss: 0.1267, G loss: 9.5951\n",
      "[4332/8000] D loss: 0.0064, G loss: 14.8939\n",
      "[4692/8000] D loss: 0.5181, G loss: 12.8996\n",
      "[5052/8000] D loss: 0.5341, G loss: 4.9056\n",
      "[5412/8000] D loss: 0.1265, G loss: 13.1620\n",
      "[5772/8000] D loss: 0.2403, G loss: 11.0191\n",
      "[6132/8000] D loss: 0.1311, G loss: 9.3293\n",
      "[6492/8000] D loss: 0.2966, G loss: 7.1691\n",
      "[6852/8000] D loss: 0.2950, G loss: 11.1850\n",
      "[7212/8000] D loss: 0.2433, G loss: 10.9575\n",
      "[7572/8000] D loss: 0.4028, G loss: 12.5604\n",
      "[7932/8000] D loss: 0.2798, G loss: 14.4683\n",
      "train error: \n",
      " D loss: 0.280127, G loss: 10.254162, D accuracy: 91.4%, cell accuracy: 94.9%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.554238, G loss: 15.215138, D accuracy: 91.9%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4421, G loss: 8.9443\n",
      "[372/8000] D loss: 0.3744, G loss: 10.0957\n",
      "[732/8000] D loss: 0.0262, G loss: 14.3995\n",
      "[1092/8000] D loss: 0.3551, G loss: 11.5123\n",
      "[1452/8000] D loss: 0.3749, G loss: 7.3771\n",
      "[1812/8000] D loss: 0.1379, G loss: 10.4686\n",
      "[2172/8000] D loss: 0.1675, G loss: 13.7315\n",
      "[2532/8000] D loss: 0.4267, G loss: 9.9243\n",
      "[2892/8000] D loss: 0.2357, G loss: 8.4376\n",
      "[3252/8000] D loss: 0.1392, G loss: 13.1258\n",
      "[3612/8000] D loss: 0.3552, G loss: 11.4536\n",
      "[3972/8000] D loss: 0.4792, G loss: 13.1500\n",
      "[4332/8000] D loss: 0.1439, G loss: 13.1924\n",
      "[4692/8000] D loss: 0.1374, G loss: 11.6147\n",
      "[5052/8000] D loss: 0.2434, G loss: 13.7764\n",
      "[5412/8000] D loss: 0.1249, G loss: 13.8304\n",
      "[5772/8000] D loss: 0.2273, G loss: 15.9134\n",
      "[6132/8000] D loss: 0.2468, G loss: 9.5899\n",
      "[6492/8000] D loss: 0.1089, G loss: 14.9758\n",
      "[6852/8000] D loss: 0.1197, G loss: 14.8172\n",
      "[7212/8000] D loss: 0.2329, G loss: 13.7356\n",
      "[7572/8000] D loss: 0.2003, G loss: 12.7838\n",
      "[7932/8000] D loss: 0.2467, G loss: 12.3296\n",
      "train error: \n",
      " D loss: 0.270842, G loss: 10.712806, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.575404, G loss: 15.568611, D accuracy: 91.6%, cell accuracy: 94.5%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1594, G loss: 12.3978\n",
      "[372/8000] D loss: 0.3602, G loss: 13.5104\n",
      "[732/8000] D loss: 0.1161, G loss: 12.1944\n",
      "[1092/8000] D loss: 0.1175, G loss: 13.1063\n",
      "[1452/8000] D loss: 0.4364, G loss: 6.6942\n",
      "[1812/8000] D loss: 0.3658, G loss: 11.5387\n",
      "[2172/8000] D loss: 0.2464, G loss: 13.6855\n",
      "[2532/8000] D loss: 0.2531, G loss: 12.3531\n",
      "[2892/8000] D loss: 0.6643, G loss: 8.9214\n",
      "[3252/8000] D loss: 0.2675, G loss: 9.5960\n",
      "[3612/8000] D loss: 0.1650, G loss: 12.2606\n",
      "[3972/8000] D loss: 0.3699, G loss: 8.3900\n",
      "[4332/8000] D loss: 0.1121, G loss: 15.0665\n",
      "[4692/8000] D loss: 0.1514, G loss: 9.5012\n",
      "[5052/8000] D loss: 0.3987, G loss: 7.9017\n",
      "[5412/8000] D loss: 0.0171, G loss: 17.5166\n",
      "[5772/8000] D loss: 0.0604, G loss: 12.2607\n",
      "[6132/8000] D loss: 0.1233, G loss: 10.2569\n",
      "[6492/8000] D loss: 0.4472, G loss: 12.0143\n",
      "[6852/8000] D loss: 0.2282, G loss: 11.1901\n",
      "[7212/8000] D loss: 0.0015, G loss: 10.5944\n",
      "[7572/8000] D loss: 0.4113, G loss: 10.0959\n",
      "[7932/8000] D loss: 0.3473, G loss: 12.2238\n",
      "train error: \n",
      " D loss: 0.279514, G loss: 12.671540, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.693496, G loss: 17.790328, D accuracy: 90.3%, cell accuracy: 94.5%, board accuracy: 6.4% \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3349, G loss: 14.0610\n",
      "[372/8000] D loss: 0.3633, G loss: 13.9442\n",
      "[732/8000] D loss: 0.2657, G loss: 10.2295\n",
      "[1092/8000] D loss: 0.2838, G loss: 14.7559\n",
      "[1452/8000] D loss: 0.2442, G loss: 12.0298\n",
      "[1812/8000] D loss: 0.2557, G loss: 12.2313\n",
      "[2172/8000] D loss: 0.1058, G loss: 8.3175\n",
      "[2532/8000] D loss: 0.1350, G loss: 10.3529\n",
      "[2892/8000] D loss: 0.3512, G loss: 7.6574\n",
      "[3252/8000] D loss: 0.1156, G loss: 18.5016\n",
      "[3612/8000] D loss: 0.1130, G loss: 13.1516\n",
      "[3972/8000] D loss: 0.2425, G loss: 13.4187\n",
      "[4332/8000] D loss: 0.2097, G loss: 12.1058\n",
      "[4692/8000] D loss: 0.1282, G loss: 19.9390\n",
      "[5052/8000] D loss: 0.2302, G loss: 10.3227\n",
      "[5412/8000] D loss: 0.4026, G loss: 9.9949\n",
      "[5772/8000] D loss: 0.4546, G loss: 11.8070\n",
      "[6132/8000] D loss: 0.2602, G loss: 11.9928\n",
      "[6492/8000] D loss: 0.3969, G loss: 8.4756\n",
      "[6852/8000] D loss: 0.2348, G loss: 13.1062\n",
      "[7212/8000] D loss: 0.3575, G loss: 8.2537\n",
      "[7572/8000] D loss: 0.1356, G loss: 15.3414\n",
      "[7932/8000] D loss: 0.2887, G loss: 13.9893\n",
      "train error: \n",
      " D loss: 0.273650, G loss: 12.430758, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.661923, G loss: 17.822467, D accuracy: 92.4%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2388, G loss: 10.8187\n",
      "[372/8000] D loss: 0.1430, G loss: 9.7567\n",
      "[732/8000] D loss: 0.3495, G loss: 12.4550\n",
      "[1092/8000] D loss: 0.1153, G loss: 13.6413\n",
      "[1452/8000] D loss: 0.4878, G loss: 4.3712\n",
      "[1812/8000] D loss: 0.3846, G loss: 12.3523\n",
      "[2172/8000] D loss: 0.1216, G loss: 14.1427\n",
      "[2532/8000] D loss: 0.2412, G loss: 8.5494\n",
      "[2892/8000] D loss: 0.2137, G loss: 12.6197\n",
      "[3252/8000] D loss: 0.1249, G loss: 11.5362\n",
      "[3612/8000] D loss: 0.1300, G loss: 13.3689\n",
      "[3972/8000] D loss: 0.3681, G loss: 8.5460\n",
      "[4332/8000] D loss: 0.6372, G loss: 6.9192\n",
      "[4692/8000] D loss: 0.1345, G loss: 11.5059\n",
      "[5052/8000] D loss: 0.5096, G loss: 10.4427\n",
      "[5412/8000] D loss: 0.2399, G loss: 7.6170\n",
      "[5772/8000] D loss: 0.2494, G loss: 14.5315\n",
      "[6132/8000] D loss: 0.1659, G loss: 15.6286\n",
      "[6492/8000] D loss: 0.3786, G loss: 7.5452\n",
      "[6852/8000] D loss: 0.2625, G loss: 11.0743\n",
      "[7212/8000] D loss: 0.1162, G loss: 9.9502\n",
      "[7572/8000] D loss: 0.4086, G loss: 6.9332\n",
      "[7932/8000] D loss: 0.1483, G loss: 9.2429\n",
      "train error: \n",
      " D loss: 0.275858, G loss: 11.577199, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.644343, G loss: 16.733921, D accuracy: 91.4%, cell accuracy: 94.5%, board accuracy: 6.3% \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1138, G loss: 18.1006\n",
      "[372/8000] D loss: 0.1357, G loss: 11.3603\n",
      "[732/8000] D loss: 0.2929, G loss: 13.7266\n",
      "[1092/8000] D loss: 0.1347, G loss: 13.0251\n",
      "[1452/8000] D loss: 0.2378, G loss: 10.5043\n",
      "[1812/8000] D loss: 0.1174, G loss: 11.6530\n",
      "[2172/8000] D loss: 0.4637, G loss: 8.6760\n",
      "[2532/8000] D loss: 0.5352, G loss: 12.6858\n",
      "[2892/8000] D loss: 0.0176, G loss: 11.2943\n",
      "[3252/8000] D loss: 0.2078, G loss: 11.8481\n",
      "[3612/8000] D loss: 0.5241, G loss: 7.1557\n",
      "[3972/8000] D loss: 0.2399, G loss: 11.6143\n",
      "[4332/8000] D loss: 0.3242, G loss: 8.1503\n",
      "[4692/8000] D loss: 0.2835, G loss: 13.6526\n",
      "[5052/8000] D loss: 0.1158, G loss: 18.8522\n",
      "[5412/8000] D loss: 0.5811, G loss: 8.0051\n",
      "[5772/8000] D loss: 0.1207, G loss: 11.9653\n",
      "[6132/8000] D loss: 0.2266, G loss: 10.1125\n",
      "[6492/8000] D loss: 0.1182, G loss: 14.5234\n",
      "[6852/8000] D loss: 0.3313, G loss: 8.5601\n",
      "[7212/8000] D loss: 0.4532, G loss: 8.8306\n",
      "[7572/8000] D loss: 0.0051, G loss: 13.0365\n",
      "[7932/8000] D loss: 0.3657, G loss: 9.9766\n",
      "train error: \n",
      " D loss: 0.280031, G loss: 13.233861, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.733938, G loss: 18.704069, D accuracy: 90.4%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1623, G loss: 13.2563\n",
      "[372/8000] D loss: 0.3591, G loss: 13.3649\n",
      "[732/8000] D loss: 0.6968, G loss: 10.2976\n",
      "[1092/8000] D loss: 0.5447, G loss: 8.2997\n",
      "[1452/8000] D loss: 0.5034, G loss: 5.5746\n",
      "[1812/8000] D loss: 0.3558, G loss: 7.2221\n",
      "[2172/8000] D loss: 0.2213, G loss: 12.3268\n",
      "[2532/8000] D loss: 0.1148, G loss: 12.8585\n",
      "[2892/8000] D loss: 0.8413, G loss: 10.0810\n",
      "[3252/8000] D loss: 0.1181, G loss: 13.1723\n",
      "[3612/8000] D loss: 0.2421, G loss: 10.2785\n",
      "[3972/8000] D loss: 0.5848, G loss: 9.0689\n",
      "[4332/8000] D loss: 0.2651, G loss: 8.8661\n",
      "[4692/8000] D loss: 0.4927, G loss: 8.0714\n",
      "[5052/8000] D loss: 0.3525, G loss: 11.2944\n",
      "[5412/8000] D loss: 0.2379, G loss: 10.0780\n",
      "[5772/8000] D loss: 0.3501, G loss: 8.9404\n",
      "[6132/8000] D loss: 0.1894, G loss: 13.6973\n",
      "[6492/8000] D loss: 0.3166, G loss: 9.0418\n",
      "[6852/8000] D loss: 0.3764, G loss: 10.5871\n",
      "[7212/8000] D loss: 0.0523, G loss: 15.7076\n",
      "[7572/8000] D loss: 0.3433, G loss: 9.7168\n",
      "[7932/8000] D loss: 0.3996, G loss: 10.1344\n",
      "train error: \n",
      " D loss: 0.275632, G loss: 10.564715, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.550300, G loss: 15.787509, D accuracy: 91.9%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4457, G loss: 8.9948\n",
      "[372/8000] D loss: 0.2843, G loss: 10.5098\n",
      "[732/8000] D loss: 0.4600, G loss: 8.6711\n",
      "[1092/8000] D loss: 0.0175, G loss: 9.2681\n",
      "[1452/8000] D loss: 0.4320, G loss: 8.5085\n",
      "[1812/8000] D loss: 0.1188, G loss: 13.1565\n",
      "[2172/8000] D loss: 0.2902, G loss: 8.5735\n",
      "[2532/8000] D loss: 0.4940, G loss: 8.5730\n",
      "[2892/8000] D loss: 0.3821, G loss: 13.6917\n",
      "[3252/8000] D loss: 0.3185, G loss: 12.6090\n",
      "[3612/8000] D loss: 0.2380, G loss: 13.2668\n",
      "[3972/8000] D loss: 0.3166, G loss: 9.3948\n",
      "[4332/8000] D loss: 0.2107, G loss: 11.7849\n",
      "[4692/8000] D loss: 0.2183, G loss: 11.4628\n",
      "[5052/8000] D loss: 0.2532, G loss: 16.3989\n",
      "[5412/8000] D loss: 0.1228, G loss: 11.7649\n",
      "[5772/8000] D loss: 0.3303, G loss: 15.8545\n",
      "[6132/8000] D loss: 0.3248, G loss: 8.9906\n",
      "[6492/8000] D loss: 0.3841, G loss: 11.9222\n",
      "[6852/8000] D loss: 0.1550, G loss: 15.5771\n",
      "[7212/8000] D loss: 0.1598, G loss: 12.1098\n",
      "[7572/8000] D loss: 0.5316, G loss: 9.5946\n",
      "[7932/8000] D loss: 0.1447, G loss: 10.8187\n",
      "train error: \n",
      " D loss: 0.275061, G loss: 10.061166, D accuracy: 91.5%, cell accuracy: 94.9%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.541402, G loss: 14.968366, D accuracy: 92.0%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2404, G loss: 13.5788\n",
      "[372/8000] D loss: 0.4069, G loss: 13.1651\n",
      "[732/8000] D loss: 0.2881, G loss: 13.1776\n",
      "[1092/8000] D loss: 0.2323, G loss: 13.5109\n",
      "[1452/8000] D loss: 0.3559, G loss: 12.3025\n",
      "[1812/8000] D loss: 0.0043, G loss: 12.3619\n",
      "[2172/8000] D loss: 0.1256, G loss: 11.5328\n",
      "[2532/8000] D loss: 0.1223, G loss: 14.5050\n",
      "[2892/8000] D loss: 0.2260, G loss: 16.4683\n",
      "[3252/8000] D loss: 0.5899, G loss: 11.3760\n",
      "[3612/8000] D loss: 0.5739, G loss: 6.7379\n",
      "[3972/8000] D loss: 0.6460, G loss: 8.3782\n",
      "[4332/8000] D loss: 0.3865, G loss: 11.8055\n",
      "[4692/8000] D loss: 0.2289, G loss: 11.2550\n",
      "[5052/8000] D loss: 0.1107, G loss: 11.2592\n",
      "[5412/8000] D loss: 0.3973, G loss: 6.9079\n",
      "[5772/8000] D loss: 0.2347, G loss: 11.1773\n",
      "[6132/8000] D loss: 0.4775, G loss: 11.1971\n",
      "[6492/8000] D loss: 0.2397, G loss: 12.4241\n",
      "[6852/8000] D loss: 0.2422, G loss: 11.2323\n",
      "[7212/8000] D loss: 0.1490, G loss: 8.2413\n",
      "[7572/8000] D loss: 0.4744, G loss: 11.1803\n",
      "[7932/8000] D loss: 0.1186, G loss: 12.5896\n",
      "train error: \n",
      " D loss: 0.272620, G loss: 12.157930, D accuracy: 91.6%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.667977, G loss: 17.450377, D accuracy: 90.7%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1742, G loss: 14.1939\n",
      "[372/8000] D loss: 0.3362, G loss: 8.3583\n",
      "[732/8000] D loss: 0.2334, G loss: 11.9682\n",
      "[1092/8000] D loss: 0.1114, G loss: 10.8201\n",
      "[1452/8000] D loss: 0.3466, G loss: 13.4414\n",
      "[1812/8000] D loss: 0.0023, G loss: 12.0054\n",
      "[2172/8000] D loss: 0.2671, G loss: 11.7185\n",
      "[2532/8000] D loss: 0.1256, G loss: 17.3207\n",
      "[2892/8000] D loss: 0.3775, G loss: 13.1660\n",
      "[3252/8000] D loss: 0.5821, G loss: 7.5413\n",
      "[3612/8000] D loss: 0.0112, G loss: 16.5955\n",
      "[3972/8000] D loss: 0.4907, G loss: 7.8870\n",
      "[4332/8000] D loss: 0.1844, G loss: 11.0261\n",
      "[4692/8000] D loss: 0.1227, G loss: 13.2506\n",
      "[5052/8000] D loss: 0.4155, G loss: 8.7977\n",
      "[5412/8000] D loss: 0.2278, G loss: 8.7636\n",
      "[5772/8000] D loss: 0.1059, G loss: 13.1626\n",
      "[6132/8000] D loss: 0.0018, G loss: 12.9326\n",
      "[6492/8000] D loss: 0.1254, G loss: 11.0998\n",
      "[6852/8000] D loss: 0.3707, G loss: 8.6902\n",
      "[7212/8000] D loss: 0.4146, G loss: 12.1540\n",
      "[7572/8000] D loss: 0.2423, G loss: 11.1688\n",
      "[7932/8000] D loss: 0.1739, G loss: 10.6248\n",
      "train error: \n",
      " D loss: 0.295514, G loss: 9.139508, D accuracy: 91.1%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.491218, G loss: 14.048231, D accuracy: 92.9%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0525, G loss: 11.2127\n",
      "[372/8000] D loss: 0.0036, G loss: 14.4644\n",
      "[732/8000] D loss: 0.2169, G loss: 11.7470\n",
      "[1092/8000] D loss: 0.1211, G loss: 14.8872\n",
      "[1452/8000] D loss: 0.4865, G loss: 7.1398\n",
      "[1812/8000] D loss: 0.0038, G loss: 12.6237\n",
      "[2172/8000] D loss: 0.1235, G loss: 10.2082\n",
      "[2532/8000] D loss: 0.3426, G loss: 13.3686\n",
      "[2892/8000] D loss: 0.2121, G loss: 12.5136\n",
      "[3252/8000] D loss: 0.5946, G loss: 6.8712\n",
      "[3612/8000] D loss: 0.3574, G loss: 10.3389\n",
      "[3972/8000] D loss: 0.1277, G loss: 11.7425\n",
      "[4332/8000] D loss: 0.2403, G loss: 12.2191\n",
      "[4692/8000] D loss: 0.2799, G loss: 12.8243\n",
      "[5052/8000] D loss: 0.4140, G loss: 13.1212\n",
      "[5412/8000] D loss: 0.3529, G loss: 12.1520\n",
      "[5772/8000] D loss: 0.3519, G loss: 8.2042\n",
      "[6132/8000] D loss: 0.3857, G loss: 7.8605\n",
      "[6492/8000] D loss: 0.1345, G loss: 9.1032\n",
      "[6852/8000] D loss: 0.4308, G loss: 9.5031\n",
      "[7212/8000] D loss: 0.2896, G loss: 9.6429\n",
      "[7572/8000] D loss: 0.4679, G loss: 9.8013\n",
      "[7932/8000] D loss: 0.4648, G loss: 7.3702\n",
      "train error: \n",
      " D loss: 0.270870, G loss: 10.151788, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.573496, G loss: 15.143705, D accuracy: 91.7%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4843, G loss: 11.3356\n",
      "[372/8000] D loss: 0.2422, G loss: 14.2514\n",
      "[732/8000] D loss: 0.1163, G loss: 15.8582\n",
      "[1092/8000] D loss: 0.2598, G loss: 11.7866\n",
      "[1452/8000] D loss: 0.1221, G loss: 13.3184\n",
      "[1812/8000] D loss: 0.1248, G loss: 8.5295\n",
      "[2172/8000] D loss: 0.0252, G loss: 11.0163\n",
      "[2532/8000] D loss: 0.1451, G loss: 14.5391\n",
      "[2892/8000] D loss: 0.3090, G loss: 13.4969\n",
      "[3252/8000] D loss: 0.3456, G loss: 11.8241\n",
      "[3612/8000] D loss: 0.1364, G loss: 8.7772\n",
      "[3972/8000] D loss: 0.0074, G loss: 10.9155\n",
      "[4332/8000] D loss: 0.2642, G loss: 9.5756\n",
      "[4692/8000] D loss: 0.3522, G loss: 9.3707\n",
      "[5052/8000] D loss: 0.6115, G loss: 7.2769\n",
      "[5412/8000] D loss: 0.2667, G loss: 15.0371\n",
      "[5772/8000] D loss: 0.2729, G loss: 12.7207\n",
      "[6132/8000] D loss: 0.4206, G loss: 9.0112\n",
      "[6492/8000] D loss: 0.2591, G loss: 13.8610\n",
      "[6852/8000] D loss: 0.4727, G loss: 10.4912\n",
      "[7212/8000] D loss: 0.4811, G loss: 10.5863\n",
      "[7572/8000] D loss: 0.0974, G loss: 14.2430\n",
      "[7932/8000] D loss: 0.2874, G loss: 7.8511\n",
      "train error: \n",
      " D loss: 0.289977, G loss: 10.216213, D accuracy: 91.1%, cell accuracy: 95.0%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.615456, G loss: 14.884771, D accuracy: 90.3%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5009, G loss: 8.9223\n",
      "[372/8000] D loss: 0.3503, G loss: 9.2984\n",
      "[732/8000] D loss: 0.1208, G loss: 11.7052\n",
      "[1092/8000] D loss: 0.4737, G loss: 13.6242\n",
      "[1452/8000] D loss: 0.4474, G loss: 10.3879\n",
      "[1812/8000] D loss: 0.0025, G loss: 14.6891\n",
      "[2172/8000] D loss: 0.1155, G loss: 19.5671\n",
      "[2532/8000] D loss: 0.4084, G loss: 9.9569\n",
      "[2892/8000] D loss: 0.1237, G loss: 11.2536\n",
      "[3252/8000] D loss: 0.2177, G loss: 9.3770\n",
      "[3612/8000] D loss: 0.0051, G loss: 13.2110\n",
      "[3972/8000] D loss: 0.1512, G loss: 13.1360\n",
      "[4332/8000] D loss: 0.1421, G loss: 10.0428\n",
      "[4692/8000] D loss: 0.1286, G loss: 11.4396\n",
      "[5052/8000] D loss: 0.1282, G loss: 12.0360\n",
      "[5412/8000] D loss: 0.0356, G loss: 15.2412\n",
      "[5772/8000] D loss: 0.3437, G loss: 11.9064\n",
      "[6132/8000] D loss: 0.0317, G loss: 12.1075\n",
      "[6492/8000] D loss: 0.5234, G loss: 8.3466\n",
      "[6852/8000] D loss: 0.2466, G loss: 10.2632\n",
      "[7212/8000] D loss: 0.1129, G loss: 13.3160\n",
      "[7572/8000] D loss: 0.1858, G loss: 9.9925\n",
      "[7932/8000] D loss: 0.1941, G loss: 10.5923\n",
      "train error: \n",
      " D loss: 0.273665, G loss: 11.079905, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.587980, G loss: 15.953078, D accuracy: 91.9%, cell accuracy: 94.5%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2551, G loss: 9.3829\n",
      "[372/8000] D loss: 0.4485, G loss: 9.4382\n",
      "[732/8000] D loss: 0.3122, G loss: 10.9079\n",
      "[1092/8000] D loss: 0.1196, G loss: 11.6097\n",
      "[1452/8000] D loss: 0.1723, G loss: 9.4691\n",
      "[1812/8000] D loss: 0.2670, G loss: 9.1670\n",
      "[2172/8000] D loss: 0.1255, G loss: 8.2561\n",
      "[2532/8000] D loss: 0.4797, G loss: 9.5736\n",
      "[2892/8000] D loss: 0.2168, G loss: 9.6490\n",
      "[3252/8000] D loss: 0.3039, G loss: 10.2571\n",
      "[3612/8000] D loss: 0.4563, G loss: 7.7132\n",
      "[3972/8000] D loss: 0.3683, G loss: 11.6267\n",
      "[4332/8000] D loss: 0.3417, G loss: 12.0541\n",
      "[4692/8000] D loss: 0.1234, G loss: 11.1605\n",
      "[5052/8000] D loss: 0.3893, G loss: 10.5982\n",
      "[5412/8000] D loss: 0.2619, G loss: 5.7983\n",
      "[5772/8000] D loss: 0.2196, G loss: 8.9064\n",
      "[6132/8000] D loss: 0.5485, G loss: 6.4529\n",
      "[6492/8000] D loss: 0.2821, G loss: 11.4306\n",
      "[6852/8000] D loss: 0.3080, G loss: 13.1027\n",
      "[7212/8000] D loss: 0.3109, G loss: 8.5086\n",
      "[7572/8000] D loss: 0.0091, G loss: 10.2433\n",
      "[7932/8000] D loss: 0.4238, G loss: 8.1339\n",
      "train error: \n",
      " D loss: 0.265727, G loss: 11.458438, D accuracy: 91.6%, cell accuracy: 94.9%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.611279, G loss: 16.681908, D accuracy: 91.4%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1729, G loss: 14.8677\n",
      "[372/8000] D loss: 0.3225, G loss: 6.0803\n",
      "[732/8000] D loss: 0.2384, G loss: 12.5377\n",
      "[1092/8000] D loss: 0.2423, G loss: 9.6984\n",
      "[1452/8000] D loss: 0.4795, G loss: 11.1268\n",
      "[1812/8000] D loss: 0.2473, G loss: 9.6115\n",
      "[2172/8000] D loss: 0.0118, G loss: 13.9770\n",
      "[2532/8000] D loss: 0.2377, G loss: 11.0838\n",
      "[2892/8000] D loss: 0.0110, G loss: 13.9491\n",
      "[3252/8000] D loss: 0.5828, G loss: 7.1897\n",
      "[3612/8000] D loss: 0.1193, G loss: 9.0018\n",
      "[3972/8000] D loss: 0.0008, G loss: 17.5032\n",
      "[4332/8000] D loss: 0.1307, G loss: 11.8157\n",
      "[4692/8000] D loss: 0.2420, G loss: 10.7964\n",
      "[5052/8000] D loss: 0.4416, G loss: 11.5927\n",
      "[5412/8000] D loss: 0.4677, G loss: 11.5430\n",
      "[5772/8000] D loss: 0.1304, G loss: 15.5415\n",
      "[6132/8000] D loss: 0.2429, G loss: 12.0649\n",
      "[6492/8000] D loss: 0.0030, G loss: 12.6245\n",
      "[6852/8000] D loss: 0.1157, G loss: 15.3037\n",
      "[7212/8000] D loss: 0.5807, G loss: 6.9984\n",
      "[7572/8000] D loss: 0.2024, G loss: 11.6993\n",
      "[7932/8000] D loss: 0.2850, G loss: 10.4638\n",
      "train error: \n",
      " D loss: 0.271018, G loss: 12.279172, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658590, G loss: 17.598873, D accuracy: 91.0%, cell accuracy: 94.5%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2439, G loss: 10.4171\n",
      "[372/8000] D loss: 0.4293, G loss: 8.9976\n",
      "[732/8000] D loss: 0.3195, G loss: 10.4372\n",
      "[1092/8000] D loss: 0.2471, G loss: 9.6988\n",
      "[1452/8000] D loss: 0.0907, G loss: 13.1786\n",
      "[1812/8000] D loss: 0.3630, G loss: 12.5969\n",
      "[2172/8000] D loss: 0.6273, G loss: 8.1387\n",
      "[2532/8000] D loss: 0.1324, G loss: 13.5909\n",
      "[2892/8000] D loss: 0.3841, G loss: 8.6310\n",
      "[3252/8000] D loss: 0.1469, G loss: 11.3992\n",
      "[3612/8000] D loss: 0.2304, G loss: 15.4757\n",
      "[3972/8000] D loss: 0.2327, G loss: 13.8672\n",
      "[4332/8000] D loss: 0.3942, G loss: 14.0376\n",
      "[4692/8000] D loss: 0.1305, G loss: 14.0620\n",
      "[5052/8000] D loss: 0.5101, G loss: 9.0282\n",
      "[5412/8000] D loss: 0.4649, G loss: 6.8534\n",
      "[5772/8000] D loss: 0.2815, G loss: 13.9021\n",
      "[6132/8000] D loss: 0.5080, G loss: 6.1887\n",
      "[6492/8000] D loss: 0.0690, G loss: 14.2618\n",
      "[6852/8000] D loss: 0.3240, G loss: 8.7191\n",
      "[7212/8000] D loss: 0.2341, G loss: 12.2320\n",
      "[7572/8000] D loss: 0.2446, G loss: 15.8555\n",
      "[7932/8000] D loss: 0.2394, G loss: 12.4270\n",
      "train error: \n",
      " D loss: 0.268708, G loss: 12.568940, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.668519, G loss: 17.901846, D accuracy: 91.5%, cell accuracy: 94.6%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1734, G loss: 13.8710\n",
      "[372/8000] D loss: 0.1253, G loss: 15.2564\n",
      "[732/8000] D loss: 0.0149, G loss: 12.4608\n",
      "[1092/8000] D loss: 0.3661, G loss: 12.8867\n",
      "[1452/8000] D loss: 0.3018, G loss: 10.9415\n",
      "[1812/8000] D loss: 0.1976, G loss: 15.4927\n",
      "[2172/8000] D loss: 0.1949, G loss: 11.0127\n",
      "[2532/8000] D loss: 0.1221, G loss: 12.2595\n",
      "[2892/8000] D loss: 0.0132, G loss: 13.3838\n",
      "[3252/8000] D loss: 0.2328, G loss: 12.1450\n",
      "[3612/8000] D loss: 0.2262, G loss: 13.3106\n",
      "[3972/8000] D loss: 0.4953, G loss: 7.9840\n",
      "[4332/8000] D loss: 0.4747, G loss: 6.0700\n",
      "[4692/8000] D loss: 0.2390, G loss: 8.1809\n",
      "[5052/8000] D loss: 0.2348, G loss: 9.6980\n",
      "[5412/8000] D loss: 0.1332, G loss: 8.5867\n",
      "[5772/8000] D loss: 0.8846, G loss: 5.9959\n",
      "[6132/8000] D loss: 0.4568, G loss: 8.9863\n",
      "[6492/8000] D loss: 0.2423, G loss: 12.2280\n",
      "[6852/8000] D loss: 0.2609, G loss: 12.6427\n",
      "[7212/8000] D loss: 0.1167, G loss: 11.4855\n",
      "[7572/8000] D loss: 0.6016, G loss: 7.5034\n",
      "[7932/8000] D loss: 0.1064, G loss: 13.2162\n",
      "train error: \n",
      " D loss: 0.293489, G loss: 9.983215, D accuracy: 91.2%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.543654, G loss: 15.111087, D accuracy: 92.5%, cell accuracy: 94.5%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1355, G loss: 11.7031\n",
      "[372/8000] D loss: 0.1240, G loss: 11.5123\n",
      "[732/8000] D loss: 0.3127, G loss: 9.3603\n",
      "[1092/8000] D loss: 0.2369, G loss: 13.3751\n",
      "[1452/8000] D loss: 0.0027, G loss: 13.9471\n",
      "[1812/8000] D loss: 0.3199, G loss: 12.8733\n",
      "[2172/8000] D loss: 0.3336, G loss: 9.6761\n",
      "[2532/8000] D loss: 0.0021, G loss: 12.8047\n",
      "[2892/8000] D loss: 0.2925, G loss: 13.1232\n",
      "[3252/8000] D loss: 0.0072, G loss: 16.3514\n",
      "[3612/8000] D loss: 0.5474, G loss: 12.0834\n",
      "[3972/8000] D loss: 0.1128, G loss: 13.2348\n",
      "[4332/8000] D loss: 0.1462, G loss: 12.3197\n",
      "[4692/8000] D loss: 0.2995, G loss: 12.4774\n",
      "[5052/8000] D loss: 0.2606, G loss: 10.5299\n",
      "[5412/8000] D loss: 0.3641, G loss: 8.3675\n",
      "[5772/8000] D loss: 0.4233, G loss: 9.8311\n",
      "[6132/8000] D loss: 0.1309, G loss: 10.4587\n",
      "[6492/8000] D loss: 0.1585, G loss: 15.5628\n",
      "[6852/8000] D loss: 0.4623, G loss: 5.7610\n",
      "[7212/8000] D loss: 0.4727, G loss: 12.4971\n",
      "[7572/8000] D loss: 0.3980, G loss: 10.1553\n",
      "[7932/8000] D loss: 0.4486, G loss: 12.6521\n",
      "train error: \n",
      " D loss: 0.285729, G loss: 13.204058, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.771374, G loss: 18.575005, D accuracy: 90.6%, cell accuracy: 94.6%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1173, G loss: 17.6639\n",
      "[372/8000] D loss: 0.5154, G loss: 10.5670\n",
      "[732/8000] D loss: 0.2896, G loss: 8.9250\n",
      "[1092/8000] D loss: 0.0025, G loss: 16.0468\n",
      "[1452/8000] D loss: 0.1633, G loss: 10.1464\n",
      "[1812/8000] D loss: 0.0038, G loss: 15.2757\n",
      "[2172/8000] D loss: 0.1360, G loss: 12.0946\n",
      "[2532/8000] D loss: 0.3506, G loss: 14.3349\n",
      "[2892/8000] D loss: 0.4162, G loss: 11.4026\n",
      "[3252/8000] D loss: 0.3578, G loss: 8.6965\n",
      "[3612/8000] D loss: 0.0650, G loss: 14.1597\n",
      "[3972/8000] D loss: 0.2479, G loss: 10.2500\n",
      "[4332/8000] D loss: 0.6182, G loss: 9.0679\n",
      "[4692/8000] D loss: 0.3793, G loss: 14.2658\n",
      "[5052/8000] D loss: 0.0027, G loss: 19.8283\n",
      "[5412/8000] D loss: 0.2439, G loss: 11.4753\n",
      "[5772/8000] D loss: 0.0017, G loss: 13.8122\n",
      "[6132/8000] D loss: 0.3856, G loss: 8.3530\n",
      "[6492/8000] D loss: 0.2633, G loss: 12.5913\n",
      "[6852/8000] D loss: 0.5835, G loss: 7.0450\n",
      "[7212/8000] D loss: 0.1278, G loss: 15.8173\n",
      "[7572/8000] D loss: 0.2413, G loss: 9.4580\n",
      "[7932/8000] D loss: 0.2375, G loss: 10.9169\n",
      "train error: \n",
      " D loss: 0.276932, G loss: 9.910625, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.537104, G loss: 14.918478, D accuracy: 92.4%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1609, G loss: 13.1400\n",
      "[372/8000] D loss: 0.3502, G loss: 11.3937\n",
      "[732/8000] D loss: 0.1927, G loss: 12.3609\n",
      "[1092/8000] D loss: 0.3197, G loss: 10.0713\n",
      "[1452/8000] D loss: 0.3730, G loss: 12.5119\n",
      "[1812/8000] D loss: 0.2439, G loss: 11.4844\n",
      "[2172/8000] D loss: 0.1464, G loss: 10.7374\n",
      "[2532/8000] D loss: 0.1671, G loss: 19.3050\n",
      "[2892/8000] D loss: 0.2549, G loss: 12.8104\n",
      "[3252/8000] D loss: 0.2433, G loss: 10.8586\n",
      "[3612/8000] D loss: 0.3224, G loss: 10.1462\n",
      "[3972/8000] D loss: 0.0040, G loss: 16.4925\n",
      "[4332/8000] D loss: 0.2416, G loss: 10.0396\n",
      "[4692/8000] D loss: 0.1435, G loss: 11.1333\n",
      "[5052/8000] D loss: 0.2500, G loss: 11.4514\n",
      "[5412/8000] D loss: 0.3774, G loss: 12.3355\n",
      "[5772/8000] D loss: 0.1279, G loss: 13.1530\n",
      "[6132/8000] D loss: 0.3739, G loss: 11.6991\n",
      "[6492/8000] D loss: 0.2771, G loss: 14.8577\n",
      "[6852/8000] D loss: 0.0631, G loss: 10.4525\n",
      "[7212/8000] D loss: 0.1275, G loss: 13.2004\n",
      "[7572/8000] D loss: 0.2302, G loss: 10.7502\n",
      "[7932/8000] D loss: 0.0040, G loss: 13.9530\n",
      "train error: \n",
      " D loss: 0.271543, G loss: 11.378683, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.599591, G loss: 16.752601, D accuracy: 91.8%, cell accuracy: 94.5%, board accuracy: 7.6% \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2461, G loss: 12.4355\n",
      "[372/8000] D loss: 0.2433, G loss: 12.7869\n",
      "[732/8000] D loss: 0.2453, G loss: 11.4379\n",
      "[1092/8000] D loss: 0.2353, G loss: 14.4666\n",
      "[1452/8000] D loss: 0.0185, G loss: 12.3831\n",
      "[1812/8000] D loss: 0.1437, G loss: 10.4690\n",
      "[2172/8000] D loss: 0.2262, G loss: 10.8907\n",
      "[2532/8000] D loss: 0.5088, G loss: 8.0904\n",
      "[2892/8000] D loss: 0.3665, G loss: 9.1878\n",
      "[3252/8000] D loss: 0.1417, G loss: 10.2548\n",
      "[3612/8000] D loss: 0.4920, G loss: 11.3688\n",
      "[3972/8000] D loss: 0.1233, G loss: 11.6463\n",
      "[4332/8000] D loss: 0.1243, G loss: 15.8951\n",
      "[4692/8000] D loss: 0.2691, G loss: 11.6829\n",
      "[5052/8000] D loss: 0.3717, G loss: 6.7400\n",
      "[5412/8000] D loss: 0.2320, G loss: 13.0627\n",
      "[5772/8000] D loss: 0.1105, G loss: 12.6455\n",
      "[6132/8000] D loss: 0.0954, G loss: 18.1297\n",
      "[6492/8000] D loss: 0.5129, G loss: 5.4726\n",
      "[6852/8000] D loss: 0.3996, G loss: 10.9729\n",
      "[7212/8000] D loss: 0.2812, G loss: 11.7303\n",
      "[7572/8000] D loss: 0.2331, G loss: 11.9429\n",
      "[7932/8000] D loss: 0.2010, G loss: 10.4989\n",
      "train error: \n",
      " D loss: 0.266800, G loss: 11.359800, D accuracy: 91.6%, cell accuracy: 95.0%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603347, G loss: 16.549513, D accuracy: 91.6%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4760, G loss: 8.3054\n",
      "[372/8000] D loss: 0.2150, G loss: 12.9100\n",
      "[732/8000] D loss: 0.1198, G loss: 10.0561\n",
      "[1092/8000] D loss: 0.4641, G loss: 9.4752\n",
      "[1452/8000] D loss: 0.7102, G loss: 7.4732\n",
      "[1812/8000] D loss: 0.3316, G loss: 10.3950\n",
      "[2172/8000] D loss: 0.1160, G loss: 14.9887\n",
      "[2532/8000] D loss: 0.2426, G loss: 11.3673\n",
      "[2892/8000] D loss: 0.3453, G loss: 8.6927\n",
      "[3252/8000] D loss: 0.0070, G loss: 12.7366\n",
      "[3612/8000] D loss: 0.3323, G loss: 9.8430\n",
      "[3972/8000] D loss: 0.3754, G loss: 8.0800\n",
      "[4332/8000] D loss: 0.2119, G loss: 15.4780\n",
      "[4692/8000] D loss: 0.2252, G loss: 11.6640\n",
      "[5052/8000] D loss: 0.3054, G loss: 13.2636\n",
      "[5412/8000] D loss: 0.1288, G loss: 14.7375\n",
      "[5772/8000] D loss: 0.3364, G loss: 12.2689\n",
      "[6132/8000] D loss: 0.3855, G loss: 13.7770\n",
      "[6492/8000] D loss: 0.1229, G loss: 16.8790\n",
      "[6852/8000] D loss: 0.4769, G loss: 10.7842\n",
      "[7212/8000] D loss: 0.2024, G loss: 10.5202\n",
      "[7572/8000] D loss: 0.2174, G loss: 10.3600\n",
      "[7932/8000] D loss: 0.2794, G loss: 12.2987\n",
      "train error: \n",
      " D loss: 0.272770, G loss: 11.438660, D accuracy: 91.6%, cell accuracy: 95.0%, board accuracy: 17.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.601070, G loss: 16.737246, D accuracy: 92.2%, cell accuracy: 94.6%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5774, G loss: 8.0675\n",
      "[372/8000] D loss: 0.0046, G loss: 14.6472\n",
      "[732/8000] D loss: 0.3964, G loss: 9.5894\n",
      "[1092/8000] D loss: 0.1700, G loss: 11.7501\n",
      "[1452/8000] D loss: 0.1206, G loss: 24.0312\n",
      "[1812/8000] D loss: 0.1361, G loss: 16.6795\n",
      "[2172/8000] D loss: 0.3159, G loss: 10.4164\n",
      "[2532/8000] D loss: 0.2363, G loss: 12.5876\n",
      "[2892/8000] D loss: 0.4592, G loss: 7.6658\n",
      "[3252/8000] D loss: 0.2206, G loss: 10.9121\n",
      "[3612/8000] D loss: 0.1189, G loss: 14.7097\n",
      "[3972/8000] D loss: 0.1170, G loss: 11.8789\n",
      "[4332/8000] D loss: 0.3471, G loss: 8.3448\n",
      "[4692/8000] D loss: 0.2482, G loss: 9.9491\n",
      "[5052/8000] D loss: 0.0022, G loss: 13.2273\n",
      "[5412/8000] D loss: 0.4692, G loss: 8.2907\n",
      "[5772/8000] D loss: 0.3654, G loss: 9.5170\n",
      "[6132/8000] D loss: 0.3947, G loss: 10.0106\n",
      "[6492/8000] D loss: 0.2495, G loss: 12.5177\n",
      "[6852/8000] D loss: 0.4585, G loss: 10.6035\n",
      "[7212/8000] D loss: 0.2636, G loss: 12.7217\n",
      "[7572/8000] D loss: 0.6620, G loss: 8.3695\n",
      "[7932/8000] D loss: 0.5078, G loss: 9.2967\n",
      "train error: \n",
      " D loss: 0.298125, G loss: 10.029195, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.568227, G loss: 14.939623, D accuracy: 92.5%, cell accuracy: 94.6%, board accuracy: 7.3% \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2790, G loss: 10.2688\n",
      "[372/8000] D loss: 0.3477, G loss: 11.0830\n",
      "[732/8000] D loss: 0.4584, G loss: 9.6214\n",
      "[1092/8000] D loss: 0.1448, G loss: 10.3620\n",
      "[1452/8000] D loss: 0.4603, G loss: 14.0994\n",
      "[1812/8000] D loss: 0.2340, G loss: 13.5989\n",
      "[2172/8000] D loss: 0.4728, G loss: 11.3729\n",
      "[2532/8000] D loss: 0.3518, G loss: 12.7926\n",
      "[2892/8000] D loss: 0.1219, G loss: 14.9920\n",
      "[3252/8000] D loss: 0.3785, G loss: 10.6183\n",
      "[3612/8000] D loss: 0.2177, G loss: 10.9363\n",
      "[3972/8000] D loss: 0.3036, G loss: 11.9146\n",
      "[4332/8000] D loss: 0.1347, G loss: 10.3235\n",
      "[4692/8000] D loss: 0.1032, G loss: 11.2518\n",
      "[5052/8000] D loss: 0.0034, G loss: 16.6585\n",
      "[5412/8000] D loss: 0.2412, G loss: 15.6233\n",
      "[5772/8000] D loss: 0.0578, G loss: 10.2484\n",
      "[6132/8000] D loss: 0.3417, G loss: 10.0224\n",
      "[6492/8000] D loss: 0.2451, G loss: 8.2941\n",
      "[6852/8000] D loss: 0.5195, G loss: 8.9754\n",
      "[7212/8000] D loss: 0.3806, G loss: 9.6056\n",
      "[7572/8000] D loss: 0.1056, G loss: 11.8174\n",
      "[7932/8000] D loss: 0.4238, G loss: 9.8559\n",
      "train error: \n",
      " D loss: 0.271058, G loss: 11.635825, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.642730, G loss: 16.678026, D accuracy: 91.5%, cell accuracy: 94.5%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4365, G loss: 11.5610\n",
      "[372/8000] D loss: 0.5251, G loss: 7.4566\n",
      "[732/8000] D loss: 0.1361, G loss: 10.4896\n",
      "[1092/8000] D loss: 0.1225, G loss: 16.9880\n",
      "[1452/8000] D loss: 0.2370, G loss: 9.1462\n",
      "[1812/8000] D loss: 0.2128, G loss: 10.7424\n",
      "[2172/8000] D loss: 0.1308, G loss: 12.4343\n",
      "[2532/8000] D loss: 0.1156, G loss: 15.2411\n",
      "[2892/8000] D loss: 0.4628, G loss: 8.0594\n",
      "[3252/8000] D loss: 0.3592, G loss: 13.1133\n",
      "[3612/8000] D loss: 0.2253, G loss: 10.8022\n",
      "[3972/8000] D loss: 0.2353, G loss: 7.5051\n",
      "[4332/8000] D loss: 0.2327, G loss: 14.7518\n",
      "[4692/8000] D loss: 0.1199, G loss: 14.2847\n",
      "[5052/8000] D loss: 0.6616, G loss: 7.0396\n",
      "[5412/8000] D loss: 0.1224, G loss: 10.3397\n",
      "[5772/8000] D loss: 0.1205, G loss: 12.4330\n",
      "[6132/8000] D loss: 0.7218, G loss: 8.8418\n",
      "[6492/8000] D loss: 0.1040, G loss: 10.8245\n",
      "[6852/8000] D loss: 0.1257, G loss: 7.5287\n",
      "[7212/8000] D loss: 0.2661, G loss: 10.8135\n",
      "[7572/8000] D loss: 0.1157, G loss: 12.0689\n",
      "[7932/8000] D loss: 0.3006, G loss: 10.3576\n",
      "train error: \n",
      " D loss: 0.272646, G loss: 10.646988, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.559908, G loss: 15.801837, D accuracy: 92.3%, cell accuracy: 94.6%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0016, G loss: 16.3426\n",
      "[372/8000] D loss: 0.1933, G loss: 15.3267\n",
      "[732/8000] D loss: 0.1190, G loss: 13.8142\n",
      "[1092/8000] D loss: 0.3594, G loss: 12.2987\n",
      "[1452/8000] D loss: 0.3733, G loss: 8.4156\n",
      "[1812/8000] D loss: 0.1896, G loss: 11.6040\n",
      "[2172/8000] D loss: 0.1257, G loss: 11.8579\n",
      "[2532/8000] D loss: 0.2756, G loss: 15.2038\n",
      "[2892/8000] D loss: 0.3559, G loss: 10.1885\n",
      "[3252/8000] D loss: 0.2567, G loss: 7.5691\n",
      "[3612/8000] D loss: 0.3386, G loss: 11.9995\n",
      "[3972/8000] D loss: 0.1228, G loss: 11.0319\n",
      "[4332/8000] D loss: 0.3517, G loss: 14.0786\n",
      "[4692/8000] D loss: 0.5059, G loss: 9.1052\n",
      "[5052/8000] D loss: 0.0024, G loss: 16.3263\n",
      "[5412/8000] D loss: 0.3534, G loss: 11.6982\n",
      "[5772/8000] D loss: 0.3955, G loss: 14.0560\n",
      "[6132/8000] D loss: 0.1174, G loss: 9.1483\n",
      "[6492/8000] D loss: 0.2631, G loss: 9.0440\n",
      "[6852/8000] D loss: 0.4852, G loss: 9.0616\n",
      "[7212/8000] D loss: 0.4333, G loss: 10.2317\n",
      "[7572/8000] D loss: 0.2291, G loss: 12.4274\n",
      "[7932/8000] D loss: 0.3916, G loss: 11.4776\n",
      "train error: \n",
      " D loss: 0.272364, G loss: 11.591732, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.619884, G loss: 16.897445, D accuracy: 91.9%, cell accuracy: 94.6%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2522, G loss: 11.0591\n",
      "[372/8000] D loss: 0.2460, G loss: 11.2306\n",
      "[732/8000] D loss: 0.0801, G loss: 11.6271\n",
      "[1092/8000] D loss: 0.4960, G loss: 8.7412\n",
      "[1452/8000] D loss: 0.2525, G loss: 7.6987\n",
      "[1812/8000] D loss: 0.1751, G loss: 9.6270\n",
      "[2172/8000] D loss: 0.3771, G loss: 10.2994\n",
      "[2532/8000] D loss: 0.3376, G loss: 14.7439\n",
      "[2892/8000] D loss: 0.1282, G loss: 11.9980\n",
      "[3252/8000] D loss: 0.3548, G loss: 10.2941\n",
      "[3612/8000] D loss: 0.1235, G loss: 13.7150\n",
      "[3972/8000] D loss: 0.0017, G loss: 16.8929\n",
      "[4332/8000] D loss: 0.3044, G loss: 8.3477\n",
      "[4692/8000] D loss: 0.4298, G loss: 6.3867\n",
      "[5052/8000] D loss: 0.5165, G loss: 8.3146\n",
      "[5412/8000] D loss: 0.2035, G loss: 10.9359\n",
      "[5772/8000] D loss: 0.2520, G loss: 12.2441\n",
      "[6132/8000] D loss: 0.3711, G loss: 10.4994\n",
      "[6492/8000] D loss: 0.3573, G loss: 10.5265\n",
      "[6852/8000] D loss: 0.0033, G loss: 12.7727\n",
      "[7212/8000] D loss: 0.2885, G loss: 7.4746\n",
      "[7572/8000] D loss: 0.1212, G loss: 10.1850\n",
      "[7932/8000] D loss: 0.6282, G loss: 8.1935\n",
      "train error: \n",
      " D loss: 0.273509, G loss: 11.043164, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.601112, G loss: 16.166245, D accuracy: 91.7%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0074, G loss: 15.5375\n",
      "[372/8000] D loss: 0.2366, G loss: 11.1803\n",
      "[732/8000] D loss: 0.1286, G loss: 10.8633\n",
      "[1092/8000] D loss: 0.1693, G loss: 11.3404\n",
      "[1452/8000] D loss: 0.2426, G loss: 12.4467\n",
      "[1812/8000] D loss: 0.0023, G loss: 12.9911\n",
      "[2172/8000] D loss: 0.3451, G loss: 13.2467\n",
      "[2532/8000] D loss: 0.0013, G loss: 13.1967\n",
      "[2892/8000] D loss: 0.4738, G loss: 7.5700\n",
      "[3252/8000] D loss: 0.5564, G loss: 4.9749\n",
      "[3612/8000] D loss: 0.2931, G loss: 8.8618\n",
      "[3972/8000] D loss: 0.0071, G loss: 10.5071\n",
      "[4332/8000] D loss: 0.1325, G loss: 15.9765\n",
      "[4692/8000] D loss: 0.1254, G loss: 15.6744\n",
      "[5052/8000] D loss: 0.4675, G loss: 9.1779\n",
      "[5412/8000] D loss: 0.2389, G loss: 9.1990\n",
      "[5772/8000] D loss: 0.5301, G loss: 6.9843\n",
      "[6132/8000] D loss: 0.2356, G loss: 11.4334\n",
      "[6492/8000] D loss: 0.3244, G loss: 12.7929\n",
      "[6852/8000] D loss: 0.1171, G loss: 15.5890\n",
      "[7212/8000] D loss: 0.4315, G loss: 11.1355\n",
      "[7572/8000] D loss: 0.7436, G loss: 9.2529\n",
      "[7932/8000] D loss: 0.1183, G loss: 12.8556\n",
      "train error: \n",
      " D loss: 0.270807, G loss: 10.932811, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592107, G loss: 16.256426, D accuracy: 91.5%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0139, G loss: 16.5108\n",
      "[372/8000] D loss: 0.0039, G loss: 18.4472\n",
      "[732/8000] D loss: 0.3720, G loss: 10.1334\n",
      "[1092/8000] D loss: 0.5989, G loss: 7.8356\n",
      "[1452/8000] D loss: 0.2339, G loss: 12.5779\n",
      "[1812/8000] D loss: 0.4326, G loss: 10.0675\n",
      "[2172/8000] D loss: 0.5843, G loss: 7.4168\n",
      "[2532/8000] D loss: 0.2472, G loss: 12.1998\n",
      "[2892/8000] D loss: 0.2037, G loss: 11.5424\n",
      "[3252/8000] D loss: 0.0003, G loss: 17.9318\n",
      "[3612/8000] D loss: 0.3453, G loss: 13.2990\n",
      "[3972/8000] D loss: 0.3680, G loss: 11.4070\n",
      "[4332/8000] D loss: 0.0148, G loss: 9.4764\n",
      "[4692/8000] D loss: 0.0130, G loss: 11.6340\n",
      "[5052/8000] D loss: 0.3567, G loss: 11.5937\n",
      "[5412/8000] D loss: 0.3528, G loss: 9.7414\n",
      "[5772/8000] D loss: 0.0050, G loss: 11.7984\n",
      "[6132/8000] D loss: 0.1238, G loss: 13.1088\n",
      "[6492/8000] D loss: 0.2418, G loss: 10.8754\n",
      "[6852/8000] D loss: 0.2436, G loss: 11.1687\n",
      "[7212/8000] D loss: 0.3029, G loss: 8.0889\n",
      "[7572/8000] D loss: 0.0161, G loss: 14.2163\n",
      "[7932/8000] D loss: 0.1132, G loss: 16.4454\n",
      "train error: \n",
      " D loss: 0.273510, G loss: 12.048618, D accuracy: 91.6%, cell accuracy: 95.0%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.643105, G loss: 17.637019, D accuracy: 91.7%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2399, G loss: 11.3340\n",
      "[372/8000] D loss: 0.4568, G loss: 9.2889\n",
      "[732/8000] D loss: 0.2200, G loss: 13.8622\n",
      "[1092/8000] D loss: 0.2350, G loss: 13.1115\n",
      "[1452/8000] D loss: 0.4513, G loss: 8.0222\n",
      "[1812/8000] D loss: 0.1949, G loss: 14.6137\n",
      "[2172/8000] D loss: 0.3633, G loss: 8.4942\n",
      "[2532/8000] D loss: 0.1823, G loss: 12.2699\n",
      "[2892/8000] D loss: 0.0104, G loss: 11.6399\n",
      "[3252/8000] D loss: 0.4456, G loss: 12.5369\n",
      "[3612/8000] D loss: 0.4186, G loss: 6.7999\n",
      "[3972/8000] D loss: 0.4579, G loss: 10.2782\n",
      "[4332/8000] D loss: 0.3834, G loss: 9.9659\n",
      "[4692/8000] D loss: 0.5367, G loss: 9.8448\n",
      "[5052/8000] D loss: 0.2445, G loss: 7.8526\n",
      "[5412/8000] D loss: 0.2019, G loss: 13.5420\n",
      "[5772/8000] D loss: 0.2302, G loss: 12.5079\n",
      "[6132/8000] D loss: 0.6073, G loss: 10.2555\n",
      "[6492/8000] D loss: 0.6104, G loss: 7.7331\n",
      "[6852/8000] D loss: 0.2288, G loss: 9.4317\n",
      "[7212/8000] D loss: 0.1277, G loss: 10.8337\n",
      "[7572/8000] D loss: 0.1115, G loss: 11.8169\n",
      "[7932/8000] D loss: 0.2788, G loss: 9.5905\n",
      "train error: \n",
      " D loss: 0.284962, G loss: 10.586540, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.558839, G loss: 15.803450, D accuracy: 92.6%, cell accuracy: 94.5%, board accuracy: 7.3% \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1238, G loss: 13.4951\n",
      "[372/8000] D loss: 0.0089, G loss: 11.4875\n",
      "[732/8000] D loss: 0.4042, G loss: 8.3891\n",
      "[1092/8000] D loss: 0.3501, G loss: 10.4165\n",
      "[1452/8000] D loss: 0.2618, G loss: 8.4521\n",
      "[1812/8000] D loss: 0.5958, G loss: 6.0165\n",
      "[2172/8000] D loss: 0.2410, G loss: 11.4405\n",
      "[2532/8000] D loss: 0.1203, G loss: 12.7415\n",
      "[2892/8000] D loss: 0.3543, G loss: 8.8985\n",
      "[3252/8000] D loss: 0.1696, G loss: 11.5921\n",
      "[3612/8000] D loss: 0.3073, G loss: 10.4039\n",
      "[3972/8000] D loss: 0.2547, G loss: 12.6658\n",
      "[4332/8000] D loss: 0.0025, G loss: 12.6877\n",
      "[4692/8000] D loss: 0.4243, G loss: 12.9922\n",
      "[5052/8000] D loss: 0.1490, G loss: 11.1561\n",
      "[5412/8000] D loss: 0.0087, G loss: 15.1024\n",
      "[5772/8000] D loss: 0.4587, G loss: 9.9241\n",
      "[6132/8000] D loss: 0.2681, G loss: 14.7423\n",
      "[6492/8000] D loss: 0.1353, G loss: 8.8920\n",
      "[6852/8000] D loss: 0.3862, G loss: 9.4000\n",
      "[7212/8000] D loss: 0.1514, G loss: 10.5504\n",
      "[7572/8000] D loss: 0.1849, G loss: 10.3565\n",
      "[7932/8000] D loss: 0.5426, G loss: 8.8975\n",
      "train error: \n",
      " D loss: 0.278537, G loss: 10.451024, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.577095, G loss: 15.348771, D accuracy: 91.0%, cell accuracy: 94.5%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4691, G loss: 9.9848\n",
      "[372/8000] D loss: 0.3502, G loss: 10.1541\n",
      "[732/8000] D loss: 0.1211, G loss: 12.2670\n",
      "[1092/8000] D loss: 0.1262, G loss: 14.9660\n",
      "[1452/8000] D loss: 0.4407, G loss: 11.2663\n",
      "[1812/8000] D loss: 0.1233, G loss: 9.1768\n",
      "[2172/8000] D loss: 0.4117, G loss: 7.6635\n",
      "[2532/8000] D loss: 0.1497, G loss: 10.2027\n",
      "[2892/8000] D loss: 0.2172, G loss: 12.6641\n",
      "[3252/8000] D loss: 0.2360, G loss: 11.7168\n",
      "[3612/8000] D loss: 0.2221, G loss: 11.5103\n",
      "[3972/8000] D loss: 0.3985, G loss: 9.3455\n",
      "[4332/8000] D loss: 0.3525, G loss: 7.9971\n",
      "[4692/8000] D loss: 0.0195, G loss: 8.3831\n",
      "[5052/8000] D loss: 0.1267, G loss: 12.6732\n",
      "[5412/8000] D loss: 0.4773, G loss: 13.9419\n",
      "[5772/8000] D loss: 0.1110, G loss: 13.4750\n",
      "[6132/8000] D loss: 0.3477, G loss: 14.3647\n",
      "[6492/8000] D loss: 0.3265, G loss: 11.7826\n",
      "[6852/8000] D loss: 0.2123, G loss: 10.8701\n",
      "[7212/8000] D loss: 0.3020, G loss: 12.4188\n",
      "[7572/8000] D loss: 0.1707, G loss: 8.8089\n",
      "[7932/8000] D loss: 0.2400, G loss: 12.8629\n",
      "train error: \n",
      " D loss: 0.290961, G loss: 10.938241, D accuracy: 91.2%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.661351, G loss: 16.067301, D accuracy: 90.2%, cell accuracy: 94.6%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.7189, G loss: 5.7280\n",
      "[372/8000] D loss: 0.2781, G loss: 11.2487\n",
      "[732/8000] D loss: 0.3611, G loss: 8.0282\n",
      "[1092/8000] D loss: 0.1165, G loss: 13.2550\n",
      "[1452/8000] D loss: 0.1436, G loss: 11.3243\n",
      "[1812/8000] D loss: 0.2472, G loss: 9.2626\n",
      "[2172/8000] D loss: 0.5199, G loss: 9.4576\n",
      "[2532/8000] D loss: 0.0733, G loss: 13.0140\n",
      "[2892/8000] D loss: 0.1242, G loss: 10.5569\n",
      "[3252/8000] D loss: 0.3610, G loss: 12.6760\n",
      "[3612/8000] D loss: 0.2479, G loss: 11.1900\n",
      "[3972/8000] D loss: 0.4014, G loss: 10.6038\n",
      "[4332/8000] D loss: 0.4711, G loss: 8.6341\n",
      "[4692/8000] D loss: 0.1204, G loss: 15.2738\n",
      "[5052/8000] D loss: 0.4656, G loss: 7.4421\n",
      "[5412/8000] D loss: 0.1361, G loss: 12.1646\n",
      "[5772/8000] D loss: 0.2379, G loss: 13.7004\n",
      "[6132/8000] D loss: 0.2346, G loss: 13.5476\n",
      "[6492/8000] D loss: 0.1185, G loss: 11.7807\n",
      "[6852/8000] D loss: 0.0592, G loss: 8.8637\n",
      "[7212/8000] D loss: 0.4379, G loss: 12.3540\n",
      "[7572/8000] D loss: 0.2220, G loss: 11.3391\n",
      "[7932/8000] D loss: 0.3623, G loss: 10.0798\n",
      "train error: \n",
      " D loss: 0.271553, G loss: 11.146515, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 17.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.616424, G loss: 16.476678, D accuracy: 91.4%, cell accuracy: 94.5%, board accuracy: 7.6% \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1263, G loss: 12.0777\n",
      "[372/8000] D loss: 0.1160, G loss: 16.8505\n",
      "[732/8000] D loss: 0.2322, G loss: 15.1690\n",
      "[1092/8000] D loss: 0.2198, G loss: 12.2527\n",
      "[1452/8000] D loss: 0.3326, G loss: 12.4067\n",
      "[1812/8000] D loss: 0.1178, G loss: 13.3218\n",
      "[2172/8000] D loss: 0.2609, G loss: 10.2748\n",
      "[2532/8000] D loss: 0.5020, G loss: 11.3853\n",
      "[2892/8000] D loss: 0.2311, G loss: 17.2081\n",
      "[3252/8000] D loss: 0.1118, G loss: 15.1629\n",
      "[3612/8000] D loss: 0.2703, G loss: 10.1393\n",
      "[3972/8000] D loss: 0.2355, G loss: 12.7252\n",
      "[4332/8000] D loss: 0.0009, G loss: 13.0334\n",
      "[4692/8000] D loss: 0.1608, G loss: 15.2871\n",
      "[5052/8000] D loss: 0.3324, G loss: 12.1433\n",
      "[5412/8000] D loss: 0.2171, G loss: 11.3362\n",
      "[5772/8000] D loss: 0.5461, G loss: 9.0729\n",
      "[6132/8000] D loss: 0.6935, G loss: 7.0496\n",
      "[6492/8000] D loss: 0.3993, G loss: 9.9833\n",
      "[6852/8000] D loss: 0.3464, G loss: 10.0117\n",
      "[7212/8000] D loss: 0.4745, G loss: 11.7398\n",
      "[7572/8000] D loss: 0.4299, G loss: 7.2778\n",
      "[7932/8000] D loss: 0.3245, G loss: 12.2292\n",
      "train error: \n",
      " D loss: 0.275522, G loss: 11.196680, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.604997, G loss: 16.500702, D accuracy: 91.8%, cell accuracy: 94.5%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2463, G loss: 14.6713\n",
      "[372/8000] D loss: 0.2364, G loss: 12.9391\n",
      "[732/8000] D loss: 0.4561, G loss: 10.9107\n",
      "[1092/8000] D loss: 0.1830, G loss: 16.2610\n",
      "[1452/8000] D loss: 0.6739, G loss: 8.3052\n",
      "[1812/8000] D loss: 0.3745, G loss: 8.7470\n",
      "[2172/8000] D loss: 0.4659, G loss: 8.5514\n",
      "[2532/8000] D loss: 0.3536, G loss: 9.3382\n",
      "[2892/8000] D loss: 0.5268, G loss: 9.3074\n",
      "[3252/8000] D loss: 0.2496, G loss: 6.6393\n",
      "[3612/8000] D loss: 0.1382, G loss: 11.2453\n",
      "[3972/8000] D loss: 0.6579, G loss: 5.5996\n",
      "[4332/8000] D loss: 0.5902, G loss: 10.0497\n",
      "[4692/8000] D loss: 0.2317, G loss: 8.1307\n",
      "[5052/8000] D loss: 0.1185, G loss: 13.0960\n",
      "[5412/8000] D loss: 0.6471, G loss: 11.2417\n",
      "[5772/8000] D loss: 0.2140, G loss: 9.8086\n",
      "[6132/8000] D loss: 0.1739, G loss: 11.7614\n",
      "[6492/8000] D loss: 0.4709, G loss: 7.3451\n",
      "[6852/8000] D loss: 0.1296, G loss: 14.8517\n",
      "[7212/8000] D loss: 0.4777, G loss: 13.9313\n",
      "[7572/8000] D loss: 0.1085, G loss: 13.6295\n",
      "[7932/8000] D loss: 0.3052, G loss: 14.3397\n",
      "train error: \n",
      " D loss: 0.274006, G loss: 10.229498, D accuracy: 91.7%, cell accuracy: 95.0%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.568264, G loss: 15.363378, D accuracy: 91.8%, cell accuracy: 94.5%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3611, G loss: 7.4580\n",
      "[372/8000] D loss: 0.2436, G loss: 12.7006\n",
      "[732/8000] D loss: 0.3770, G loss: 11.2147\n",
      "[1092/8000] D loss: 0.4052, G loss: 8.8566\n",
      "[1452/8000] D loss: 0.0052, G loss: 12.0183\n",
      "[1812/8000] D loss: 0.1356, G loss: 13.1008\n",
      "[2172/8000] D loss: 0.3408, G loss: 10.2890\n",
      "[2532/8000] D loss: 0.2448, G loss: 10.8486\n",
      "[2892/8000] D loss: 0.3446, G loss: 6.8747\n",
      "[3252/8000] D loss: 0.1760, G loss: 12.7980\n",
      "[3612/8000] D loss: 0.2399, G loss: 13.7957\n",
      "[3972/8000] D loss: 0.3234, G loss: 12.1695\n",
      "[4332/8000] D loss: 0.6041, G loss: 7.5748\n",
      "[4692/8000] D loss: 0.2220, G loss: 12.1275\n",
      "[5052/8000] D loss: 0.2475, G loss: 12.2562\n",
      "[5412/8000] D loss: 0.2218, G loss: 10.4052\n",
      "[5772/8000] D loss: 0.1210, G loss: 11.1095\n",
      "[6132/8000] D loss: 0.0069, G loss: 15.2228\n",
      "[6492/8000] D loss: 0.1202, G loss: 13.2676\n",
      "[6852/8000] D loss: 0.5998, G loss: 7.3943\n",
      "[7212/8000] D loss: 0.2850, G loss: 14.9995\n",
      "[7572/8000] D loss: 0.1203, G loss: 15.3743\n",
      "[7932/8000] D loss: 0.1411, G loss: 7.9795\n",
      "train error: \n",
      " D loss: 0.271751, G loss: 11.177915, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 17.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.589219, G loss: 16.556665, D accuracy: 92.2%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1156, G loss: 17.5725\n",
      "[372/8000] D loss: 0.2405, G loss: 9.1712\n",
      "[732/8000] D loss: 0.3123, G loss: 14.0824\n",
      "[1092/8000] D loss: 0.1281, G loss: 13.9713\n",
      "[1452/8000] D loss: 0.2472, G loss: 12.0746\n",
      "[1812/8000] D loss: 0.3242, G loss: 6.9469\n",
      "[2172/8000] D loss: 0.2488, G loss: 13.7668\n",
      "[2532/8000] D loss: 0.3975, G loss: 9.6569\n",
      "[2892/8000] D loss: 0.3407, G loss: 16.2356\n",
      "[3252/8000] D loss: 0.3572, G loss: 7.2775\n",
      "[3612/8000] D loss: 0.1515, G loss: 14.3209\n",
      "[3972/8000] D loss: 0.2520, G loss: 9.3134\n",
      "[4332/8000] D loss: 0.0046, G loss: 12.6064\n",
      "[4692/8000] D loss: 0.2980, G loss: 13.5546\n",
      "[5052/8000] D loss: 0.1493, G loss: 15.6953\n",
      "[5412/8000] D loss: 0.2506, G loss: 8.6143\n",
      "[5772/8000] D loss: 0.5255, G loss: 7.0532\n",
      "[6132/8000] D loss: 0.2360, G loss: 11.9666\n",
      "[6492/8000] D loss: 0.2487, G loss: 8.5171\n",
      "[6852/8000] D loss: 0.2553, G loss: 12.5912\n",
      "[7212/8000] D loss: 0.1803, G loss: 13.5345\n",
      "[7572/8000] D loss: 0.1207, G loss: 11.2565\n",
      "[7932/8000] D loss: 0.3549, G loss: 10.6800\n",
      "train error: \n",
      " D loss: 0.275985, G loss: 11.687929, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.641766, G loss: 17.033985, D accuracy: 91.9%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1538, G loss: 11.5012\n",
      "[372/8000] D loss: 0.2490, G loss: 8.9700\n",
      "[732/8000] D loss: 0.3006, G loss: 11.8365\n",
      "[1092/8000] D loss: 0.7294, G loss: 7.5252\n",
      "[1452/8000] D loss: 0.0233, G loss: 11.1311\n",
      "[1812/8000] D loss: 0.2542, G loss: 11.4808\n",
      "[2172/8000] D loss: 0.0578, G loss: 12.6629\n",
      "[2532/8000] D loss: 0.0580, G loss: 12.6109\n",
      "[2892/8000] D loss: 0.1119, G loss: 10.6060\n",
      "[3252/8000] D loss: 0.2626, G loss: 10.7799\n",
      "[3612/8000] D loss: 0.2388, G loss: 13.9455\n",
      "[3972/8000] D loss: 0.5150, G loss: 10.6518\n",
      "[4332/8000] D loss: 0.2434, G loss: 11.0963\n",
      "[4692/8000] D loss: 0.2055, G loss: 12.7873\n",
      "[5052/8000] D loss: 0.2442, G loss: 11.0700\n",
      "[5412/8000] D loss: 0.3042, G loss: 12.4975\n",
      "[5772/8000] D loss: 0.2326, G loss: 16.5139\n",
      "[6132/8000] D loss: 0.0078, G loss: 13.6762\n",
      "[6492/8000] D loss: 0.4755, G loss: 10.4529\n",
      "[6852/8000] D loss: 0.2438, G loss: 10.4682\n",
      "[7212/8000] D loss: 0.0009, G loss: 17.2474\n",
      "[7572/8000] D loss: 0.5401, G loss: 9.0890\n",
      "[7932/8000] D loss: 0.1419, G loss: 14.8204\n",
      "train error: \n",
      " D loss: 0.277655, G loss: 12.267377, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.696562, G loss: 17.523614, D accuracy: 91.0%, cell accuracy: 94.5%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1351, G loss: 7.9907\n",
      "[372/8000] D loss: 0.0923, G loss: 13.4229\n",
      "[732/8000] D loss: 0.2341, G loss: 7.9653\n",
      "[1092/8000] D loss: 0.3309, G loss: 9.1884\n",
      "[1452/8000] D loss: 0.4873, G loss: 9.5923\n",
      "[1812/8000] D loss: 0.4778, G loss: 12.4369\n",
      "[2172/8000] D loss: 0.1711, G loss: 15.2649\n",
      "[2532/8000] D loss: 0.1135, G loss: 14.1019\n",
      "[2892/8000] D loss: 0.1118, G loss: 13.8640\n",
      "[3252/8000] D loss: 0.3886, G loss: 8.5260\n",
      "[3612/8000] D loss: 0.1339, G loss: 11.7111\n",
      "[3972/8000] D loss: 0.3532, G loss: 7.9233\n",
      "[4332/8000] D loss: 0.4401, G loss: 8.8470\n",
      "[4692/8000] D loss: 0.5820, G loss: 9.0411\n",
      "[5052/8000] D loss: 0.3209, G loss: 8.7786\n",
      "[5412/8000] D loss: 0.1865, G loss: 17.2686\n",
      "[5772/8000] D loss: 0.2630, G loss: 12.0198\n",
      "[6132/8000] D loss: 0.2898, G loss: 9.1712\n",
      "[6492/8000] D loss: 0.2378, G loss: 14.9800\n",
      "[6852/8000] D loss: 0.3593, G loss: 8.1404\n",
      "[7212/8000] D loss: 0.1725, G loss: 12.2837\n",
      "[7572/8000] D loss: 0.2344, G loss: 14.5297\n",
      "[7932/8000] D loss: 0.2485, G loss: 10.1030\n",
      "train error: \n",
      " D loss: 0.276456, G loss: 11.094061, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.577670, G loss: 16.655002, D accuracy: 92.4%, cell accuracy: 94.6%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0802, G loss: 8.9074\n",
      "[372/8000] D loss: 0.2159, G loss: 10.6405\n",
      "[732/8000] D loss: 0.1110, G loss: 15.2343\n",
      "[1092/8000] D loss: 0.3419, G loss: 8.5505\n",
      "[1452/8000] D loss: 0.1873, G loss: 13.1744\n",
      "[1812/8000] D loss: 0.2915, G loss: 13.5769\n",
      "[2172/8000] D loss: 0.2325, G loss: 14.7230\n",
      "[2532/8000] D loss: 0.2216, G loss: 18.6828\n",
      "[2892/8000] D loss: 0.2321, G loss: 12.4387\n",
      "[3252/8000] D loss: 0.0093, G loss: 13.9076\n",
      "[3612/8000] D loss: 0.1862, G loss: 12.5220\n",
      "[3972/8000] D loss: 0.4116, G loss: 7.6591\n",
      "[4332/8000] D loss: 0.1293, G loss: 9.4305\n",
      "[4692/8000] D loss: 0.2545, G loss: 10.4946\n",
      "[5052/8000] D loss: 0.3548, G loss: 12.0778\n",
      "[5412/8000] D loss: 0.3131, G loss: 10.5443\n",
      "[5772/8000] D loss: 0.2421, G loss: 11.6644\n",
      "[6132/8000] D loss: 0.2609, G loss: 8.7949\n",
      "[6492/8000] D loss: 0.5966, G loss: 6.3832\n",
      "[6852/8000] D loss: 0.2352, G loss: 15.3360\n",
      "[7212/8000] D loss: 0.2841, G loss: 10.4825\n",
      "[7572/8000] D loss: 0.5609, G loss: 10.0581\n",
      "[7932/8000] D loss: 0.2973, G loss: 12.8639\n",
      "train error: \n",
      " D loss: 0.279619, G loss: 12.263660, D accuracy: 91.2%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.690015, G loss: 17.697049, D accuracy: 91.4%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3345, G loss: 9.2294\n",
      "[372/8000] D loss: 0.2888, G loss: 8.7442\n",
      "[732/8000] D loss: 0.2373, G loss: 10.4588\n",
      "[1092/8000] D loss: 0.2789, G loss: 10.6503\n",
      "[1452/8000] D loss: 0.2413, G loss: 8.8719\n",
      "[1812/8000] D loss: 0.3389, G loss: 9.3626\n",
      "[2172/8000] D loss: 0.1177, G loss: 12.9732\n",
      "[2532/8000] D loss: 0.1232, G loss: 12.5256\n",
      "[2892/8000] D loss: 0.2269, G loss: 13.8129\n",
      "[3252/8000] D loss: 0.3295, G loss: 12.9893\n",
      "[3612/8000] D loss: 0.3242, G loss: 9.3757\n",
      "[3972/8000] D loss: 0.1199, G loss: 14.4716\n",
      "[4332/8000] D loss: 0.4090, G loss: 13.2879\n",
      "[4692/8000] D loss: 0.0950, G loss: 13.0959\n",
      "[5052/8000] D loss: 0.4766, G loss: 10.7530\n",
      "[5412/8000] D loss: 0.1281, G loss: 13.9229\n",
      "[5772/8000] D loss: 0.5441, G loss: 7.5508\n",
      "[6132/8000] D loss: 0.4907, G loss: 9.7545\n",
      "[6492/8000] D loss: 0.4617, G loss: 12.2653\n",
      "[6852/8000] D loss: 0.5245, G loss: 7.9463\n",
      "[7212/8000] D loss: 0.3874, G loss: 8.7634\n",
      "[7572/8000] D loss: 0.1083, G loss: 12.3630\n",
      "[7932/8000] D loss: 0.0005, G loss: 15.8581\n",
      "train error: \n",
      " D loss: 0.276844, G loss: 12.158861, D accuracy: 91.2%, cell accuracy: 95.0%, board accuracy: 17.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.735853, G loss: 17.746412, D accuracy: 91.0%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1086, G loss: 14.2938\n",
      "[372/8000] D loss: 0.3678, G loss: 8.0237\n",
      "[732/8000] D loss: 0.3506, G loss: 10.1063\n",
      "[1092/8000] D loss: 0.2567, G loss: 8.7673\n",
      "[1452/8000] D loss: 0.1288, G loss: 11.9956\n",
      "[1812/8000] D loss: 0.2358, G loss: 12.0975\n",
      "[2172/8000] D loss: 0.1495, G loss: 16.5446\n",
      "[2532/8000] D loss: 0.3539, G loss: 12.8443\n",
      "[2892/8000] D loss: 0.2227, G loss: 9.7120\n",
      "[3252/8000] D loss: 0.3732, G loss: 13.4875\n",
      "[3612/8000] D loss: 0.3230, G loss: 10.7482\n",
      "[3972/8000] D loss: 0.1038, G loss: 14.0615\n",
      "[4332/8000] D loss: 0.2650, G loss: 14.4986\n",
      "[4692/8000] D loss: 0.3535, G loss: 14.0903\n",
      "[5052/8000] D loss: 0.2827, G loss: 11.3933\n",
      "[5412/8000] D loss: 0.4350, G loss: 9.4246\n",
      "[5772/8000] D loss: 0.2351, G loss: 12.4707\n",
      "[6132/8000] D loss: 0.1004, G loss: 12.3862\n",
      "[6492/8000] D loss: 0.0077, G loss: 11.4940\n",
      "[6852/8000] D loss: 0.3685, G loss: 8.3959\n",
      "[7212/8000] D loss: 0.3272, G loss: 10.0306\n",
      "[7572/8000] D loss: 0.2383, G loss: 9.4270\n",
      "[7932/8000] D loss: 0.1490, G loss: 10.0228\n",
      "train error: \n",
      " D loss: 0.295126, G loss: 9.927871, D accuracy: 91.1%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.547305, G loss: 14.996447, D accuracy: 92.8%, cell accuracy: 94.5%, board accuracy: 6.6% \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1688, G loss: 8.9418\n",
      "[372/8000] D loss: 0.1537, G loss: 9.1947\n",
      "[732/8000] D loss: 0.7313, G loss: 8.3562\n",
      "[1092/8000] D loss: 0.1148, G loss: 14.3292\n",
      "[1452/8000] D loss: 0.3869, G loss: 12.9481\n",
      "[1812/8000] D loss: 0.1497, G loss: 12.5142\n",
      "[2172/8000] D loss: 0.3541, G loss: 6.3694\n",
      "[2532/8000] D loss: 0.2404, G loss: 8.0235\n",
      "[2892/8000] D loss: 0.4306, G loss: 9.9492\n",
      "[3252/8000] D loss: 0.1499, G loss: 16.4181\n",
      "[3612/8000] D loss: 0.3941, G loss: 8.2866\n",
      "[3972/8000] D loss: 0.1432, G loss: 15.2732\n",
      "[4332/8000] D loss: 0.4119, G loss: 11.3333\n",
      "[4692/8000] D loss: 0.5058, G loss: 7.3269\n",
      "[5052/8000] D loss: 0.2517, G loss: 9.7873\n",
      "[5412/8000] D loss: 0.3921, G loss: 10.3165\n",
      "[5772/8000] D loss: 0.4776, G loss: 10.8123\n",
      "[6132/8000] D loss: 0.2883, G loss: 13.8738\n",
      "[6492/8000] D loss: 0.4126, G loss: 9.4452\n",
      "[6852/8000] D loss: 0.2432, G loss: 15.2700\n",
      "[7212/8000] D loss: 0.3517, G loss: 13.8029\n",
      "[7572/8000] D loss: 0.5250, G loss: 9.3356\n",
      "[7932/8000] D loss: 0.2410, G loss: 11.0653\n",
      "train error: \n",
      " D loss: 0.265514, G loss: 11.065687, D accuracy: 91.6%, cell accuracy: 95.0%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.565328, G loss: 16.509025, D accuracy: 91.9%, cell accuracy: 94.5%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0180, G loss: 15.3487\n",
      "[372/8000] D loss: 0.3852, G loss: 11.8010\n",
      "[732/8000] D loss: 0.2687, G loss: 13.1238\n",
      "[1092/8000] D loss: 0.0103, G loss: 9.6742\n",
      "[1452/8000] D loss: 0.6858, G loss: 15.1511\n",
      "[1812/8000] D loss: 0.2299, G loss: 16.2031\n",
      "[2172/8000] D loss: 0.4865, G loss: 7.2984\n",
      "[2532/8000] D loss: 0.1319, G loss: 12.7742\n",
      "[2892/8000] D loss: 0.1223, G loss: 11.1224\n",
      "[3252/8000] D loss: 0.1163, G loss: 18.8761\n",
      "[3612/8000] D loss: 0.1296, G loss: 12.6881\n",
      "[3972/8000] D loss: 0.4820, G loss: 11.9656\n",
      "[4332/8000] D loss: 0.2582, G loss: 11.7425\n",
      "[4692/8000] D loss: 0.5693, G loss: 8.6941\n",
      "[5052/8000] D loss: 0.1880, G loss: 13.6884\n",
      "[5412/8000] D loss: 0.1053, G loss: 10.4292\n",
      "[5772/8000] D loss: 0.4099, G loss: 13.0745\n",
      "[6132/8000] D loss: 0.1242, G loss: 10.7473\n",
      "[6492/8000] D loss: 0.4692, G loss: 5.2106\n",
      "[6852/8000] D loss: 0.1011, G loss: 16.0875\n",
      "[7212/8000] D loss: 0.1681, G loss: 8.7536\n",
      "[7572/8000] D loss: 0.2449, G loss: 11.1903\n",
      "[7932/8000] D loss: 0.2531, G loss: 16.0263\n",
      "train error: \n",
      " D loss: 0.269976, G loss: 12.255789, D accuracy: 91.7%, cell accuracy: 95.0%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.630958, G loss: 17.622474, D accuracy: 91.0%, cell accuracy: 94.5%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1302, G loss: 13.1691\n",
      "[372/8000] D loss: 0.5085, G loss: 6.5728\n",
      "[732/8000] D loss: 0.2401, G loss: 10.5489\n",
      "[1092/8000] D loss: 0.6290, G loss: 7.5450\n",
      "[1452/8000] D loss: 0.2636, G loss: 11.5348\n",
      "[1812/8000] D loss: 0.3956, G loss: 11.9205\n",
      "[2172/8000] D loss: 0.2952, G loss: 11.8337\n",
      "[2532/8000] D loss: 0.3650, G loss: 13.9188\n",
      "[2892/8000] D loss: 0.3223, G loss: 12.8236\n",
      "[3252/8000] D loss: 0.4892, G loss: 8.4123\n",
      "[3612/8000] D loss: 0.5990, G loss: 7.0125\n",
      "[3972/8000] D loss: 0.2704, G loss: 10.2797\n",
      "[4332/8000] D loss: 0.3101, G loss: 11.9690\n",
      "[4692/8000] D loss: 0.3225, G loss: 11.0357\n",
      "[5052/8000] D loss: 0.2158, G loss: 14.5568\n",
      "[5412/8000] D loss: 0.3616, G loss: 13.3179\n",
      "[5772/8000] D loss: 0.1182, G loss: 13.5711\n",
      "[6132/8000] D loss: 0.0128, G loss: 14.6978\n",
      "[6492/8000] D loss: 0.0018, G loss: 14.9264\n",
      "[6852/8000] D loss: 0.1335, G loss: 15.6051\n",
      "[7212/8000] D loss: 0.1219, G loss: 11.3463\n",
      "[7572/8000] D loss: 0.0138, G loss: 11.5631\n",
      "[7932/8000] D loss: 0.4949, G loss: 10.9272\n",
      "train error: \n",
      " D loss: 0.286778, G loss: 12.504209, D accuracy: 91.1%, cell accuracy: 95.0%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.739105, G loss: 17.795047, D accuracy: 89.8%, cell accuracy: 94.6%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1430, G loss: 11.9172\n",
      "[372/8000] D loss: 0.1238, G loss: 12.1404\n",
      "[732/8000] D loss: 0.6501, G loss: 7.9609\n",
      "[1092/8000] D loss: 0.2320, G loss: 13.7183\n",
      "[1452/8000] D loss: 0.3383, G loss: 10.5794\n",
      "[1812/8000] D loss: 0.2724, G loss: 8.9990\n",
      "[2172/8000] D loss: 0.2879, G loss: 8.0291\n",
      "[2532/8000] D loss: 0.2035, G loss: 13.7910\n",
      "[2892/8000] D loss: 0.1319, G loss: 14.6795\n",
      "[3252/8000] D loss: 0.0042, G loss: 10.8060\n",
      "[3612/8000] D loss: 0.2456, G loss: 10.0638\n",
      "[3972/8000] D loss: 0.2864, G loss: 8.5899\n",
      "[4332/8000] D loss: 0.2133, G loss: 14.4577\n",
      "[4692/8000] D loss: 0.2376, G loss: 14.0707\n",
      "[5052/8000] D loss: 0.3621, G loss: 9.7062\n",
      "[5412/8000] D loss: 0.2577, G loss: 11.9965\n",
      "[5772/8000] D loss: 0.1769, G loss: 12.7333\n",
      "[6132/8000] D loss: 0.2463, G loss: 12.6918\n",
      "[6492/8000] D loss: 0.2541, G loss: 11.0331\n",
      "[6852/8000] D loss: 0.4135, G loss: 10.5075\n",
      "[7212/8000] D loss: 0.2034, G loss: 10.8352\n",
      "[7572/8000] D loss: 0.0987, G loss: 12.3818\n",
      "[7932/8000] D loss: 0.2327, G loss: 12.1179\n",
      "train error: \n",
      " D loss: 0.277512, G loss: 11.485679, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626461, G loss: 16.773275, D accuracy: 91.9%, cell accuracy: 94.6%, board accuracy: 7.3% \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1841, G loss: 11.6323\n",
      "[372/8000] D loss: 0.3116, G loss: 12.0653\n",
      "[732/8000] D loss: 0.4671, G loss: 9.7416\n",
      "[1092/8000] D loss: 0.0477, G loss: 9.2588\n",
      "[1452/8000] D loss: 0.1497, G loss: 10.4746\n",
      "[1812/8000] D loss: 0.2807, G loss: 9.9798\n",
      "[2172/8000] D loss: 0.3876, G loss: 12.8399\n",
      "[2532/8000] D loss: 0.2215, G loss: 13.7033\n",
      "[2892/8000] D loss: 0.2367, G loss: 12.6132\n",
      "[3252/8000] D loss: 0.6925, G loss: 7.5077\n",
      "[3612/8000] D loss: 0.0059, G loss: 14.7155\n",
      "[3972/8000] D loss: 0.1182, G loss: 11.8066\n",
      "[4332/8000] D loss: 0.6390, G loss: 13.2764\n",
      "[4692/8000] D loss: 0.1425, G loss: 10.4064\n",
      "[5052/8000] D loss: 0.1891, G loss: 11.6724\n",
      "[5412/8000] D loss: 0.2597, G loss: 12.7107\n",
      "[5772/8000] D loss: 0.2678, G loss: 14.1053\n",
      "[6132/8000] D loss: 0.2402, G loss: 9.3120\n",
      "[6492/8000] D loss: 0.0054, G loss: 11.6409\n",
      "[6852/8000] D loss: 0.3526, G loss: 11.8597\n",
      "[7212/8000] D loss: 0.1178, G loss: 14.4336\n",
      "[7572/8000] D loss: 0.2512, G loss: 12.5385\n",
      "[7932/8000] D loss: 0.3380, G loss: 9.1565\n",
      "train error: \n",
      " D loss: 0.278616, G loss: 13.664086, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.793677, G loss: 19.189911, D accuracy: 90.9%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0016, G loss: 18.2204\n",
      "[372/8000] D loss: 0.1974, G loss: 12.4777\n",
      "[732/8000] D loss: 0.2293, G loss: 8.6313\n",
      "[1092/8000] D loss: 0.1217, G loss: 11.6834\n",
      "[1452/8000] D loss: 0.4976, G loss: 8.7805\n",
      "[1812/8000] D loss: 0.4410, G loss: 14.9556\n",
      "[2172/8000] D loss: 0.0066, G loss: 13.6348\n",
      "[2532/8000] D loss: 0.1686, G loss: 10.8452\n",
      "[2892/8000] D loss: 0.4304, G loss: 5.9149\n",
      "[3252/8000] D loss: 0.3589, G loss: 8.8389\n",
      "[3612/8000] D loss: 0.2570, G loss: 12.7883\n",
      "[3972/8000] D loss: 0.1341, G loss: 14.4341\n",
      "[4332/8000] D loss: 0.2438, G loss: 11.7519\n",
      "[4692/8000] D loss: 0.2650, G loss: 12.7276\n",
      "[5052/8000] D loss: 0.2100, G loss: 14.6673\n",
      "[5412/8000] D loss: 0.2378, G loss: 12.5924\n",
      "[5772/8000] D loss: 0.3756, G loss: 12.6547\n",
      "[6132/8000] D loss: 0.2386, G loss: 14.8590\n",
      "[6492/8000] D loss: 0.1569, G loss: 11.7745\n",
      "[6852/8000] D loss: 0.3554, G loss: 11.5404\n",
      "[7212/8000] D loss: 0.6751, G loss: 8.9566\n",
      "[7572/8000] D loss: 0.2412, G loss: 14.2387\n",
      "[7932/8000] D loss: 0.2545, G loss: 10.8505\n",
      "train error: \n",
      " D loss: 0.273038, G loss: 12.183770, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658157, G loss: 17.637923, D accuracy: 91.1%, cell accuracy: 94.6%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3521, G loss: 8.1486\n",
      "[372/8000] D loss: 0.1210, G loss: 16.2640\n",
      "[732/8000] D loss: 0.2678, G loss: 11.2063\n",
      "[1092/8000] D loss: 0.2585, G loss: 12.4372\n",
      "[1452/8000] D loss: 0.2387, G loss: 8.2719\n",
      "[1812/8000] D loss: 0.1217, G loss: 12.4217\n",
      "[2172/8000] D loss: 0.2288, G loss: 10.0875\n",
      "[2532/8000] D loss: 0.4788, G loss: 8.2382\n",
      "[2892/8000] D loss: 0.2341, G loss: 11.0066\n",
      "[3252/8000] D loss: 0.3624, G loss: 11.9577\n",
      "[3612/8000] D loss: 0.2960, G loss: 13.7237\n",
      "[3972/8000] D loss: 0.0206, G loss: 15.5398\n",
      "[4332/8000] D loss: 0.2917, G loss: 12.1941\n",
      "[4692/8000] D loss: 0.4212, G loss: 8.0258\n",
      "[5052/8000] D loss: 0.4069, G loss: 9.2180\n",
      "[5412/8000] D loss: 0.2410, G loss: 14.9576\n",
      "[5772/8000] D loss: 0.2858, G loss: 7.1015\n",
      "[6132/8000] D loss: 0.2763, G loss: 13.7975\n",
      "[6492/8000] D loss: 0.3626, G loss: 11.4741\n",
      "[6852/8000] D loss: 0.2324, G loss: 12.0363\n",
      "[7212/8000] D loss: 0.1518, G loss: 11.7281\n",
      "[7572/8000] D loss: 0.1598, G loss: 11.7110\n",
      "[7932/8000] D loss: 0.3366, G loss: 13.6000\n",
      "train error: \n",
      " D loss: 0.269629, G loss: 13.048247, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.687831, G loss: 18.604335, D accuracy: 91.1%, cell accuracy: 94.5%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0033, G loss: 18.9891\n",
      "[372/8000] D loss: 0.3584, G loss: 16.2044\n",
      "[732/8000] D loss: 0.2356, G loss: 8.4513\n",
      "[1092/8000] D loss: 0.5176, G loss: 10.9086\n",
      "[1452/8000] D loss: 0.2466, G loss: 8.3620\n",
      "[1812/8000] D loss: 0.1174, G loss: 14.8978\n",
      "[2172/8000] D loss: 0.2856, G loss: 11.1056\n",
      "[2532/8000] D loss: 0.3135, G loss: 7.7709\n",
      "[2892/8000] D loss: 0.5537, G loss: 8.6112\n",
      "[3252/8000] D loss: 0.6744, G loss: 8.1948\n",
      "[3612/8000] D loss: 0.3643, G loss: 8.2991\n",
      "[3972/8000] D loss: 0.2628, G loss: 12.6417\n",
      "[4332/8000] D loss: 0.3475, G loss: 8.6013\n",
      "[4692/8000] D loss: 0.3681, G loss: 9.9640\n",
      "[5052/8000] D loss: 0.3853, G loss: 12.1887\n",
      "[5412/8000] D loss: 0.3292, G loss: 10.9889\n",
      "[5772/8000] D loss: 0.3617, G loss: 11.7161\n",
      "[6132/8000] D loss: 0.4395, G loss: 9.7834\n",
      "[6492/8000] D loss: 0.1930, G loss: 12.0043\n",
      "[6852/8000] D loss: 0.1181, G loss: 15.2300\n",
      "[7212/8000] D loss: 0.0032, G loss: 11.6985\n",
      "[7572/8000] D loss: 0.2321, G loss: 10.0956\n",
      "[7932/8000] D loss: 0.1244, G loss: 13.0541\n",
      "train error: \n",
      " D loss: 0.278746, G loss: 11.471240, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.682288, G loss: 16.742336, D accuracy: 91.0%, cell accuracy: 94.6%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4802, G loss: 10.3331\n",
      "[372/8000] D loss: 0.5345, G loss: 8.7587\n",
      "[732/8000] D loss: 0.2420, G loss: 8.7961\n",
      "[1092/8000] D loss: 0.3692, G loss: 11.0279\n",
      "[1452/8000] D loss: 0.1246, G loss: 17.1132\n",
      "[1812/8000] D loss: 0.2455, G loss: 13.4413\n",
      "[2172/8000] D loss: 0.1617, G loss: 11.1345\n",
      "[2532/8000] D loss: 0.1275, G loss: 10.7672\n",
      "[2892/8000] D loss: 0.1483, G loss: 12.0905\n",
      "[3252/8000] D loss: 0.5215, G loss: 10.1863\n",
      "[3612/8000] D loss: 0.0247, G loss: 15.6623\n",
      "[3972/8000] D loss: 0.3487, G loss: 12.6915\n",
      "[4332/8000] D loss: 0.3588, G loss: 7.7110\n",
      "[4692/8000] D loss: 0.1278, G loss: 13.6041\n",
      "[5052/8000] D loss: 0.2483, G loss: 12.6670\n",
      "[5412/8000] D loss: 0.1506, G loss: 13.0979\n",
      "[5772/8000] D loss: 0.3496, G loss: 10.9716\n",
      "[6132/8000] D loss: 0.1992, G loss: 13.1874\n",
      "[6492/8000] D loss: 0.3543, G loss: 12.0700\n",
      "[6852/8000] D loss: 0.2436, G loss: 14.2668\n",
      "[7212/8000] D loss: 0.2325, G loss: 10.2128\n",
      "[7572/8000] D loss: 0.4827, G loss: 10.0782\n",
      "[7932/8000] D loss: 0.1207, G loss: 11.0537\n",
      "train error: \n",
      " D loss: 0.286407, G loss: 10.218248, D accuracy: 91.1%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.602022, G loss: 15.070021, D accuracy: 91.5%, cell accuracy: 94.6%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4676, G loss: 11.8606\n",
      "[372/8000] D loss: 0.6146, G loss: 10.3467\n",
      "[732/8000] D loss: 0.2496, G loss: 10.8777\n",
      "[1092/8000] D loss: 0.1264, G loss: 13.2545\n",
      "[1452/8000] D loss: 0.4787, G loss: 8.3069\n",
      "[1812/8000] D loss: 0.3638, G loss: 7.4012\n",
      "[2172/8000] D loss: 0.1252, G loss: 15.3559\n",
      "[2532/8000] D loss: 0.1223, G loss: 18.4405\n",
      "[2892/8000] D loss: 0.0050, G loss: 17.3043\n",
      "[3252/8000] D loss: 0.3744, G loss: 11.8447\n",
      "[3612/8000] D loss: 0.5851, G loss: 9.0791\n",
      "[3972/8000] D loss: 0.1345, G loss: 10.2388\n",
      "[4332/8000] D loss: 0.6943, G loss: 7.1627\n",
      "[4692/8000] D loss: 0.3349, G loss: 10.7122\n",
      "[5052/8000] D loss: 0.0597, G loss: 13.0333\n",
      "[5412/8000] D loss: 0.1494, G loss: 7.7374\n",
      "[5772/8000] D loss: 0.1354, G loss: 12.7681\n",
      "[6132/8000] D loss: 0.4796, G loss: 9.6692\n",
      "[6492/8000] D loss: 0.3959, G loss: 12.8404\n",
      "[6852/8000] D loss: 0.4665, G loss: 7.1037\n",
      "[7212/8000] D loss: 0.2334, G loss: 10.2494\n",
      "[7572/8000] D loss: 0.0276, G loss: 13.7130\n",
      "[7932/8000] D loss: 0.2609, G loss: 15.1841\n",
      "train error: \n",
      " D loss: 0.277355, G loss: 11.802907, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.593653, G loss: 17.396798, D accuracy: 92.2%, cell accuracy: 94.5%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3641, G loss: 9.0286\n",
      "[372/8000] D loss: 0.4518, G loss: 10.7717\n",
      "[732/8000] D loss: 0.4757, G loss: 13.1189\n",
      "[1092/8000] D loss: 0.4007, G loss: 9.3372\n",
      "[1452/8000] D loss: 0.1352, G loss: 14.3028\n",
      "[1812/8000] D loss: 0.3697, G loss: 11.6559\n",
      "[2172/8000] D loss: 0.4754, G loss: 9.6910\n",
      "[2532/8000] D loss: 0.1198, G loss: 14.5095\n",
      "[2892/8000] D loss: 0.0397, G loss: 9.9584\n",
      "[3252/8000] D loss: 0.2511, G loss: 11.0690\n",
      "[3612/8000] D loss: 0.4219, G loss: 11.8115\n",
      "[3972/8000] D loss: 0.6269, G loss: 6.2947\n",
      "[4332/8000] D loss: 0.3554, G loss: 10.0247\n",
      "[4692/8000] D loss: 0.2647, G loss: 9.9302\n",
      "[5052/8000] D loss: 0.3735, G loss: 13.7404\n",
      "[5412/8000] D loss: 0.1373, G loss: 11.5912\n",
      "[5772/8000] D loss: 0.2420, G loss: 12.8433\n",
      "[6132/8000] D loss: 0.5292, G loss: 10.4585\n",
      "[6492/8000] D loss: 0.0036, G loss: 11.8936\n",
      "[6852/8000] D loss: 0.2772, G loss: 14.0982\n",
      "[7212/8000] D loss: 0.2794, G loss: 12.5599\n",
      "[7572/8000] D loss: 0.5886, G loss: 12.4763\n",
      "[7932/8000] D loss: 0.4229, G loss: 11.1392\n",
      "train error: \n",
      " D loss: 0.298003, G loss: 10.079183, D accuracy: 91.0%, cell accuracy: 95.0%, board accuracy: 17.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.569569, G loss: 15.177595, D accuracy: 93.0%, cell accuracy: 94.6%, board accuracy: 6.7% \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4429, G loss: 8.7354\n",
      "[372/8000] D loss: 0.3501, G loss: 10.6201\n",
      "[732/8000] D loss: 0.0084, G loss: 15.7917\n",
      "[1092/8000] D loss: 0.3554, G loss: 12.7569\n",
      "[1452/8000] D loss: 0.4843, G loss: 9.6492\n",
      "[1812/8000] D loss: 0.3342, G loss: 8.7261\n",
      "[2172/8000] D loss: 0.5491, G loss: 14.7680\n",
      "[2532/8000] D loss: 0.3310, G loss: 10.0715\n",
      "[2892/8000] D loss: 0.3425, G loss: 8.8779\n",
      "[3252/8000] D loss: 0.3847, G loss: 9.6691\n",
      "[3612/8000] D loss: 0.2497, G loss: 12.9724\n",
      "[3972/8000] D loss: 0.2341, G loss: 7.2997\n",
      "[4332/8000] D loss: 0.5907, G loss: 6.6991\n",
      "[4692/8000] D loss: 0.3800, G loss: 9.6886\n",
      "[5052/8000] D loss: 0.4070, G loss: 12.6742\n",
      "[5412/8000] D loss: 0.2365, G loss: 14.1463\n",
      "[5772/8000] D loss: 0.4684, G loss: 12.1538\n",
      "[6132/8000] D loss: 0.3777, G loss: 7.7138\n",
      "[6492/8000] D loss: 0.3728, G loss: 10.2504\n",
      "[6852/8000] D loss: 0.2307, G loss: 10.3395\n",
      "[7212/8000] D loss: 0.2159, G loss: 11.5284\n",
      "[7572/8000] D loss: 0.2362, G loss: 14.9966\n",
      "[7932/8000] D loss: 0.1622, G loss: 11.7998\n",
      "train error: \n",
      " D loss: 0.271856, G loss: 11.746420, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.653844, G loss: 17.099201, D accuracy: 91.6%, cell accuracy: 94.6%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2309, G loss: 13.4487\n",
      "[372/8000] D loss: 0.1767, G loss: 11.7962\n",
      "[732/8000] D loss: 0.1931, G loss: 17.0930\n",
      "[1092/8000] D loss: 0.4334, G loss: 13.0346\n",
      "[1452/8000] D loss: 0.3671, G loss: 9.0309\n",
      "[1812/8000] D loss: 0.0117, G loss: 13.4202\n",
      "[2172/8000] D loss: 0.0231, G loss: 13.7708\n",
      "[2532/8000] D loss: 0.4723, G loss: 12.8355\n",
      "[2892/8000] D loss: 0.4461, G loss: 6.7433\n",
      "[3252/8000] D loss: 0.3881, G loss: 9.0772\n",
      "[3612/8000] D loss: 0.3397, G loss: 10.2428\n",
      "[3972/8000] D loss: 0.7129, G loss: 4.9578\n",
      "[4332/8000] D loss: 0.2616, G loss: 12.4418\n",
      "[4692/8000] D loss: 0.2230, G loss: 11.7571\n",
      "[5052/8000] D loss: 0.3708, G loss: 9.4689\n",
      "[5412/8000] D loss: 0.1424, G loss: 15.9900\n",
      "[5772/8000] D loss: 0.1829, G loss: 8.5706\n",
      "[6132/8000] D loss: 0.1232, G loss: 11.5867\n",
      "[6492/8000] D loss: 0.6263, G loss: 9.2294\n",
      "[6852/8000] D loss: 0.2479, G loss: 10.6345\n",
      "[7212/8000] D loss: 0.4602, G loss: 10.2308\n",
      "[7572/8000] D loss: 0.3327, G loss: 10.0022\n",
      "[7932/8000] D loss: 0.2558, G loss: 10.2893\n",
      "train error: \n",
      " D loss: 0.271394, G loss: 11.476774, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 17.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.665754, G loss: 16.709743, D accuracy: 90.8%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4058, G loss: 11.3507\n",
      "[372/8000] D loss: 0.1126, G loss: 14.7096\n",
      "[732/8000] D loss: 0.2604, G loss: 15.3549\n",
      "[1092/8000] D loss: 0.0035, G loss: 14.3410\n",
      "[1452/8000] D loss: 0.1430, G loss: 11.4197\n",
      "[1812/8000] D loss: 0.2877, G loss: 10.6831\n",
      "[2172/8000] D loss: 0.1381, G loss: 11.2282\n",
      "[2532/8000] D loss: 0.2356, G loss: 12.6092\n",
      "[2892/8000] D loss: 0.3780, G loss: 10.6600\n",
      "[3252/8000] D loss: 0.3499, G loss: 9.8128\n",
      "[3612/8000] D loss: 0.1327, G loss: 14.5567\n",
      "[3972/8000] D loss: 0.1285, G loss: 11.8423\n",
      "[4332/8000] D loss: 0.0148, G loss: 12.5104\n",
      "[4692/8000] D loss: 0.2374, G loss: 9.9776\n",
      "[5052/8000] D loss: 0.2334, G loss: 10.6084\n",
      "[5412/8000] D loss: 0.2446, G loss: 14.1660\n",
      "[5772/8000] D loss: 0.1625, G loss: 12.2349\n",
      "[6132/8000] D loss: 0.1213, G loss: 15.4331\n",
      "[6492/8000] D loss: 0.4182, G loss: 13.7283\n",
      "[6852/8000] D loss: 0.1526, G loss: 13.4803\n",
      "[7212/8000] D loss: 0.2277, G loss: 13.2068\n",
      "[7572/8000] D loss: 0.1479, G loss: 11.8854\n",
      "[7932/8000] D loss: 0.1730, G loss: 15.8756\n",
      "train error: \n",
      " D loss: 0.271507, G loss: 11.899784, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.636673, G loss: 17.473479, D accuracy: 91.7%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.4177, G loss: 13.1983\n",
      "[372/8000] D loss: 0.7242, G loss: 7.9001\n",
      "[732/8000] D loss: 0.1641, G loss: 12.4180\n",
      "[1092/8000] D loss: 0.7746, G loss: 6.7592\n",
      "[1452/8000] D loss: 0.4787, G loss: 6.9528\n",
      "[1812/8000] D loss: 0.5456, G loss: 9.0313\n",
      "[2172/8000] D loss: 0.1634, G loss: 12.7706\n",
      "[2532/8000] D loss: 0.1484, G loss: 11.5807\n",
      "[2892/8000] D loss: 0.2369, G loss: 13.5029\n",
      "[3252/8000] D loss: 0.5927, G loss: 11.9115\n",
      "[3612/8000] D loss: 0.5868, G loss: 6.7180\n",
      "[3972/8000] D loss: 0.1302, G loss: 13.3425\n",
      "[4332/8000] D loss: 0.0165, G loss: 15.0821\n",
      "[4692/8000] D loss: 0.2330, G loss: 9.5117\n",
      "[5052/8000] D loss: 0.1290, G loss: 12.0734\n",
      "[5412/8000] D loss: 0.1178, G loss: 12.1746\n",
      "[5772/8000] D loss: 0.0463, G loss: 13.0516\n",
      "[6132/8000] D loss: 0.1327, G loss: 12.6666\n",
      "[6492/8000] D loss: 0.3711, G loss: 12.9712\n",
      "[6852/8000] D loss: 0.4729, G loss: 8.9599\n",
      "[7212/8000] D loss: 0.4638, G loss: 7.5924\n",
      "[7572/8000] D loss: 0.0019, G loss: 18.1040\n",
      "[7932/8000] D loss: 0.1429, G loss: 9.0614\n",
      "train error: \n",
      " D loss: 0.280101, G loss: 12.318953, D accuracy: 91.2%, cell accuracy: 95.0%, board accuracy: 17.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.666493, G loss: 17.685796, D accuracy: 91.4%, cell accuracy: 94.6%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.0188, G loss: 14.1685\n",
      "[372/8000] D loss: 0.5751, G loss: 6.9543\n",
      "[732/8000] D loss: 0.3546, G loss: 12.7005\n",
      "[1092/8000] D loss: 0.2521, G loss: 9.8672\n",
      "[1452/8000] D loss: 0.1171, G loss: 12.5475\n",
      "[1812/8000] D loss: 0.2389, G loss: 15.1634\n",
      "[2172/8000] D loss: 0.3343, G loss: 15.4561\n",
      "[2532/8000] D loss: 0.1702, G loss: 9.8720\n",
      "[2892/8000] D loss: 0.1170, G loss: 11.7817\n",
      "[3252/8000] D loss: 0.4609, G loss: 6.4190\n",
      "[3612/8000] D loss: 0.3605, G loss: 9.7497\n",
      "[3972/8000] D loss: 0.5183, G loss: 11.9870\n",
      "[4332/8000] D loss: 0.1271, G loss: 11.4068\n",
      "[4692/8000] D loss: 0.5729, G loss: 11.3702\n",
      "[5052/8000] D loss: 0.0018, G loss: 15.5407\n",
      "[5412/8000] D loss: 0.0054, G loss: 13.2248\n",
      "[5772/8000] D loss: 0.2364, G loss: 13.3096\n",
      "[6132/8000] D loss: 0.5737, G loss: 9.7820\n",
      "[6492/8000] D loss: 0.4825, G loss: 10.3894\n",
      "[6852/8000] D loss: 0.3471, G loss: 12.4014\n",
      "[7212/8000] D loss: 0.1753, G loss: 9.3315\n",
      "[7572/8000] D loss: 0.4589, G loss: 5.1278\n",
      "[7932/8000] D loss: 0.4933, G loss: 9.3178\n",
      "train error: \n",
      " D loss: 0.289237, G loss: 11.472738, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.640863, G loss: 16.768139, D accuracy: 92.0%, cell accuracy: 94.5%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2771, G loss: 10.2064\n",
      "[372/8000] D loss: 0.2280, G loss: 12.6544\n",
      "[732/8000] D loss: 0.2490, G loss: 11.3107\n",
      "[1092/8000] D loss: 0.1423, G loss: 11.9467\n",
      "[1452/8000] D loss: 0.2413, G loss: 11.9769\n",
      "[1812/8000] D loss: 0.0066, G loss: 11.6652\n",
      "[2172/8000] D loss: 0.3729, G loss: 8.7207\n",
      "[2532/8000] D loss: 0.2890, G loss: 11.0310\n",
      "[2892/8000] D loss: 0.0008, G loss: 15.0181\n",
      "[3252/8000] D loss: 0.5324, G loss: 10.7486\n",
      "[3612/8000] D loss: 0.3394, G loss: 11.5595\n",
      "[3972/8000] D loss: 0.4764, G loss: 12.6180\n",
      "[4332/8000] D loss: 0.2372, G loss: 15.5333\n",
      "[4692/8000] D loss: 0.2380, G loss: 15.7558\n",
      "[5052/8000] D loss: 0.0262, G loss: 9.6847\n",
      "[5412/8000] D loss: 0.1452, G loss: 12.3617\n",
      "[5772/8000] D loss: 0.1309, G loss: 14.6625\n",
      "[6132/8000] D loss: 0.3967, G loss: 13.5943\n",
      "[6492/8000] D loss: 0.1052, G loss: 13.3210\n",
      "[6852/8000] D loss: 0.1042, G loss: 13.5965\n",
      "[7212/8000] D loss: 0.1271, G loss: 11.3210\n",
      "[7572/8000] D loss: 0.2341, G loss: 14.7296\n",
      "[7932/8000] D loss: 0.2400, G loss: 18.0257\n",
      "train error: \n",
      " D loss: 0.269355, G loss: 12.124924, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608493, G loss: 17.724178, D accuracy: 91.6%, cell accuracy: 94.6%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1187, G loss: 16.5491\n",
      "[372/8000] D loss: 0.3533, G loss: 14.1369\n",
      "[732/8000] D loss: 0.2285, G loss: 16.6593\n",
      "[1092/8000] D loss: 0.3617, G loss: 13.3120\n",
      "[1452/8000] D loss: 0.3755, G loss: 13.9730\n",
      "[1812/8000] D loss: 0.1421, G loss: 17.7624\n",
      "[2172/8000] D loss: 0.1345, G loss: 15.7238\n",
      "[2532/8000] D loss: 0.3646, G loss: 11.1477\n",
      "[2892/8000] D loss: 0.2370, G loss: 9.9518\n",
      "[3252/8000] D loss: 0.4798, G loss: 10.5120\n",
      "[3612/8000] D loss: 0.5086, G loss: 7.1179\n",
      "[3972/8000] D loss: 0.5610, G loss: 12.8454\n",
      "[4332/8000] D loss: 0.2324, G loss: 15.5732\n",
      "[4692/8000] D loss: 0.1385, G loss: 9.7078\n",
      "[5052/8000] D loss: 0.2662, G loss: 14.2894\n",
      "[5412/8000] D loss: 0.2420, G loss: 10.2958\n",
      "[5772/8000] D loss: 0.2326, G loss: 11.1944\n",
      "[6132/8000] D loss: 0.1164, G loss: 17.0879\n",
      "[6492/8000] D loss: 0.4841, G loss: 10.9845\n",
      "[6852/8000] D loss: 0.2292, G loss: 13.4224\n",
      "[7212/8000] D loss: 0.2143, G loss: 12.9795\n",
      "[7572/8000] D loss: 0.4083, G loss: 6.6001\n",
      "[7932/8000] D loss: 0.2445, G loss: 9.4194\n",
      "train error: \n",
      " D loss: 0.270771, G loss: 11.599758, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.636902, G loss: 16.864205, D accuracy: 91.2%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3645, G loss: 5.2733\n",
      "[372/8000] D loss: 0.5104, G loss: 8.4429\n",
      "[732/8000] D loss: 0.6802, G loss: 6.7983\n",
      "[1092/8000] D loss: 0.3457, G loss: 8.5460\n",
      "[1452/8000] D loss: 0.3431, G loss: 11.8813\n",
      "[1812/8000] D loss: 0.4860, G loss: 8.9484\n",
      "[2172/8000] D loss: 0.2435, G loss: 11.5445\n",
      "[2532/8000] D loss: 0.1293, G loss: 13.9345\n",
      "[2892/8000] D loss: 0.1302, G loss: 13.6750\n",
      "[3252/8000] D loss: 0.5675, G loss: 9.4387\n",
      "[3612/8000] D loss: 0.5431, G loss: 10.4427\n",
      "[3972/8000] D loss: 0.0341, G loss: 16.4024\n",
      "[4332/8000] D loss: 0.0070, G loss: 18.6456\n",
      "[4692/8000] D loss: 0.2551, G loss: 11.6990\n",
      "[5052/8000] D loss: 0.3280, G loss: 10.6379\n",
      "[5412/8000] D loss: 0.1222, G loss: 14.0266\n",
      "[5772/8000] D loss: 0.3457, G loss: 10.5641\n",
      "[6132/8000] D loss: 0.4798, G loss: 9.4472\n",
      "[6492/8000] D loss: 0.2421, G loss: 11.0979\n",
      "[6852/8000] D loss: 0.2533, G loss: 16.3978\n",
      "[7212/8000] D loss: 0.2565, G loss: 14.4610\n",
      "[7572/8000] D loss: 0.6143, G loss: 5.2447\n",
      "[7932/8000] D loss: 0.1191, G loss: 12.5960\n",
      "train error: \n",
      " D loss: 0.271960, G loss: 12.245195, D accuracy: 91.5%, cell accuracy: 95.0%, board accuracy: 17.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.659857, G loss: 17.717639, D accuracy: 91.5%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3288, G loss: 10.1607\n",
      "[372/8000] D loss: 0.4898, G loss: 9.3713\n",
      "[732/8000] D loss: 0.3502, G loss: 14.7483\n",
      "[1092/8000] D loss: 0.2972, G loss: 11.4701\n",
      "[1452/8000] D loss: 0.3059, G loss: 12.6047\n",
      "[1812/8000] D loss: 0.4651, G loss: 11.7721\n",
      "[2172/8000] D loss: 0.1151, G loss: 10.0992\n",
      "[2532/8000] D loss: 0.3465, G loss: 11.2499\n",
      "[2892/8000] D loss: 0.3567, G loss: 9.7844\n",
      "[3252/8000] D loss: 0.3251, G loss: 9.6802\n",
      "[3612/8000] D loss: 0.3473, G loss: 15.4144\n",
      "[3972/8000] D loss: 0.3538, G loss: 11.9487\n",
      "[4332/8000] D loss: 0.0174, G loss: 13.8090\n",
      "[4692/8000] D loss: 0.3771, G loss: 9.7785\n",
      "[5052/8000] D loss: 0.1300, G loss: 9.2216\n",
      "[5412/8000] D loss: 0.1230, G loss: 16.2300\n",
      "[5772/8000] D loss: 0.2935, G loss: 11.3838\n",
      "[6132/8000] D loss: 0.3280, G loss: 11.2297\n",
      "[6492/8000] D loss: 0.2672, G loss: 13.8266\n",
      "[6852/8000] D loss: 0.4674, G loss: 12.0425\n",
      "[7212/8000] D loss: 0.3471, G loss: 12.2303\n",
      "[7572/8000] D loss: 0.3527, G loss: 7.9512\n",
      "[7932/8000] D loss: 0.3074, G loss: 9.4982\n",
      "train error: \n",
      " D loss: 0.274783, G loss: 10.620380, D accuracy: 91.2%, cell accuracy: 95.0%, board accuracy: 17.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.586838, G loss: 15.795087, D accuracy: 91.2%, cell accuracy: 94.6%, board accuracy: 7.3% \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3682, G loss: 12.0987\n",
      "[372/8000] D loss: 0.4577, G loss: 8.5789\n",
      "[732/8000] D loss: 0.2054, G loss: 8.8718\n",
      "[1092/8000] D loss: 0.3443, G loss: 12.8425\n",
      "[1452/8000] D loss: 0.2496, G loss: 9.8870\n",
      "[1812/8000] D loss: 0.4874, G loss: 10.8337\n",
      "[2172/8000] D loss: 0.5692, G loss: 9.9257\n",
      "[2532/8000] D loss: 0.3706, G loss: 11.8265\n",
      "[2892/8000] D loss: 0.0022, G loss: 13.3106\n",
      "[3252/8000] D loss: 0.2478, G loss: 14.1290\n",
      "[3612/8000] D loss: 0.0106, G loss: 13.9223\n",
      "[3972/8000] D loss: 0.1615, G loss: 11.4333\n",
      "[4332/8000] D loss: 0.3683, G loss: 8.8168\n",
      "[4692/8000] D loss: 0.2663, G loss: 12.5130\n",
      "[5052/8000] D loss: 0.4614, G loss: 10.7004\n",
      "[5412/8000] D loss: 0.5806, G loss: 9.4052\n",
      "[5772/8000] D loss: 0.1503, G loss: 11.5510\n",
      "[6132/8000] D loss: 0.1875, G loss: 10.7300\n",
      "[6492/8000] D loss: 0.1384, G loss: 11.4160\n",
      "[6852/8000] D loss: 0.2351, G loss: 17.7426\n",
      "[7212/8000] D loss: 0.2345, G loss: 14.6742\n",
      "[7572/8000] D loss: 0.2195, G loss: 14.1216\n",
      "[7932/8000] D loss: 0.2550, G loss: 10.4462\n",
      "train error: \n",
      " D loss: 0.275252, G loss: 11.809822, D accuracy: 91.2%, cell accuracy: 95.0%, board accuracy: 17.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.662164, G loss: 17.058138, D accuracy: 91.1%, cell accuracy: 94.6%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3532, G loss: 12.3618\n",
      "[372/8000] D loss: 0.5810, G loss: 7.9398\n",
      "[732/8000] D loss: 0.2933, G loss: 8.7282\n",
      "[1092/8000] D loss: 0.3405, G loss: 11.2088\n",
      "[1452/8000] D loss: 0.2206, G loss: 11.5970\n",
      "[1812/8000] D loss: 0.2351, G loss: 8.6967\n",
      "[2172/8000] D loss: 0.2466, G loss: 11.3108\n",
      "[2532/8000] D loss: 0.4241, G loss: 8.2284\n",
      "[2892/8000] D loss: 0.5648, G loss: 9.8986\n",
      "[3252/8000] D loss: 0.4764, G loss: 11.8776\n",
      "[3612/8000] D loss: 0.2973, G loss: 10.9927\n",
      "[3972/8000] D loss: 0.7041, G loss: 5.3726\n",
      "[4332/8000] D loss: 0.0224, G loss: 10.6778\n",
      "[4692/8000] D loss: 0.0670, G loss: 17.9903\n",
      "[5052/8000] D loss: 0.1225, G loss: 11.4341\n",
      "[5412/8000] D loss: 0.4262, G loss: 8.3680\n",
      "[5772/8000] D loss: 0.1229, G loss: 11.5842\n",
      "[6132/8000] D loss: 0.2605, G loss: 11.4433\n",
      "[6492/8000] D loss: 0.1279, G loss: 15.4234\n",
      "[6852/8000] D loss: 0.5887, G loss: 5.6785\n",
      "[7212/8000] D loss: 0.1536, G loss: 10.6155\n",
      "[7572/8000] D loss: 0.1199, G loss: 11.3206\n",
      "[7932/8000] D loss: 0.2257, G loss: 14.5683\n",
      "train error: \n",
      " D loss: 0.283272, G loss: 9.521608, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.544240, G loss: 14.548726, D accuracy: 92.1%, cell accuracy: 94.6%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2244, G loss: 13.7270\n",
      "[372/8000] D loss: 0.2079, G loss: 9.3577\n",
      "[732/8000] D loss: 0.0316, G loss: 10.8166\n",
      "[1092/8000] D loss: 0.2345, G loss: 13.0012\n",
      "[1452/8000] D loss: 0.1295, G loss: 10.8663\n",
      "[1812/8000] D loss: 0.7368, G loss: 10.7659\n",
      "[2172/8000] D loss: 0.2785, G loss: 11.3492\n",
      "[2532/8000] D loss: 0.2418, G loss: 9.3118\n",
      "[2892/8000] D loss: 0.1208, G loss: 11.0751\n",
      "[3252/8000] D loss: 0.3470, G loss: 9.0301\n",
      "[3612/8000] D loss: 0.1789, G loss: 8.0233\n",
      "[3972/8000] D loss: 0.3834, G loss: 11.9488\n",
      "[4332/8000] D loss: 0.1265, G loss: 12.9564\n",
      "[4692/8000] D loss: 0.1203, G loss: 16.2985\n",
      "[5052/8000] D loss: 0.4879, G loss: 8.8691\n",
      "[5412/8000] D loss: 0.2346, G loss: 13.2735\n",
      "[5772/8000] D loss: 0.0021, G loss: 21.0124\n",
      "[6132/8000] D loss: 0.3193, G loss: 10.8600\n",
      "[6492/8000] D loss: 0.3527, G loss: 12.1816\n",
      "[6852/8000] D loss: 0.1162, G loss: 13.0560\n",
      "[7212/8000] D loss: 0.3021, G loss: 13.0714\n",
      "[7572/8000] D loss: 0.1018, G loss: 12.7385\n",
      "[7932/8000] D loss: 0.2812, G loss: 9.9035\n",
      "train error: \n",
      " D loss: 0.283290, G loss: 12.027472, D accuracy: 91.0%, cell accuracy: 95.0%, board accuracy: 17.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.666500, G loss: 17.637143, D accuracy: 90.5%, cell accuracy: 94.6%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3757, G loss: 10.6911\n",
      "[372/8000] D loss: 0.2347, G loss: 20.6440\n",
      "[732/8000] D loss: 0.4675, G loss: 5.5297\n",
      "[1092/8000] D loss: 0.2757, G loss: 9.6968\n",
      "[1452/8000] D loss: 0.0035, G loss: 12.5216\n",
      "[1812/8000] D loss: 0.4551, G loss: 13.6823\n",
      "[2172/8000] D loss: 0.5087, G loss: 8.4995\n",
      "[2532/8000] D loss: 0.0142, G loss: 15.5517\n",
      "[2892/8000] D loss: 0.6215, G loss: 8.5948\n",
      "[3252/8000] D loss: 0.4834, G loss: 12.3449\n",
      "[3612/8000] D loss: 0.1341, G loss: 10.6235\n",
      "[3972/8000] D loss: 0.2448, G loss: 14.5092\n",
      "[4332/8000] D loss: 0.3434, G loss: 13.4875\n",
      "[4692/8000] D loss: 0.3650, G loss: 10.0219\n",
      "[5052/8000] D loss: 0.1144, G loss: 15.0983\n",
      "[5412/8000] D loss: 0.3673, G loss: 9.0415\n",
      "[5772/8000] D loss: 0.1608, G loss: 18.2444\n",
      "[6132/8000] D loss: 0.2254, G loss: 15.5944\n",
      "[6492/8000] D loss: 0.2247, G loss: 15.1289\n",
      "[6852/8000] D loss: 0.3340, G loss: 9.9759\n",
      "[7212/8000] D loss: 0.1288, G loss: 10.7378\n",
      "[7572/8000] D loss: 0.6102, G loss: 8.5744\n",
      "[7932/8000] D loss: 0.2829, G loss: 10.3744\n",
      "train error: \n",
      " D loss: 0.284080, G loss: 11.737129, D accuracy: 91.2%, cell accuracy: 95.0%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.632430, G loss: 17.207838, D accuracy: 91.5%, cell accuracy: 94.6%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3752, G loss: 9.1515\n",
      "[372/8000] D loss: 0.2133, G loss: 14.1121\n",
      "[732/8000] D loss: 0.2174, G loss: 16.9202\n",
      "[1092/8000] D loss: 0.3878, G loss: 9.5301\n",
      "[1452/8000] D loss: 0.2577, G loss: 12.1227\n",
      "[1812/8000] D loss: 0.1183, G loss: 18.3962\n",
      "[2172/8000] D loss: 0.1509, G loss: 15.9083\n",
      "[2532/8000] D loss: 0.3632, G loss: 10.3411\n",
      "[2892/8000] D loss: 0.2729, G loss: 8.8260\n",
      "[3252/8000] D loss: 0.3615, G loss: 7.3347\n",
      "[3612/8000] D loss: 0.2287, G loss: 13.2562\n",
      "[3972/8000] D loss: 0.5994, G loss: 9.6256\n",
      "[4332/8000] D loss: 0.1272, G loss: 13.3417\n",
      "[4692/8000] D loss: 0.3079, G loss: 13.3271\n",
      "[5052/8000] D loss: 0.4851, G loss: 7.1991\n",
      "[5412/8000] D loss: 0.1282, G loss: 13.1942\n",
      "[5772/8000] D loss: 0.2842, G loss: 12.1254\n",
      "[6132/8000] D loss: 0.4978, G loss: 8.9771\n",
      "[6492/8000] D loss: 0.2919, G loss: 11.9059\n",
      "[6852/8000] D loss: 0.2459, G loss: 10.7020\n",
      "[7212/8000] D loss: 0.3279, G loss: 9.8408\n",
      "[7572/8000] D loss: 0.1613, G loss: 14.7737\n",
      "[7932/8000] D loss: 0.7103, G loss: 10.2109\n",
      "train error: \n",
      " D loss: 0.279980, G loss: 12.663325, D accuracy: 91.1%, cell accuracy: 95.0%, board accuracy: 17.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.703805, G loss: 18.201888, D accuracy: 90.2%, cell accuracy: 94.5%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1266, G loss: 11.0725\n",
      "[372/8000] D loss: 0.1256, G loss: 13.3841\n",
      "[732/8000] D loss: 0.3902, G loss: 8.8802\n",
      "[1092/8000] D loss: 0.0010, G loss: 12.5007\n",
      "[1452/8000] D loss: 0.4291, G loss: 8.1055\n",
      "[1812/8000] D loss: 0.3578, G loss: 10.0643\n",
      "[2172/8000] D loss: 0.2330, G loss: 14.5710\n",
      "[2532/8000] D loss: 0.3636, G loss: 10.8609\n",
      "[2892/8000] D loss: 0.2291, G loss: 9.1744\n",
      "[3252/8000] D loss: 0.6657, G loss: 6.5032\n",
      "[3612/8000] D loss: 0.5451, G loss: 5.8988\n",
      "[3972/8000] D loss: 0.3411, G loss: 13.9297\n",
      "[4332/8000] D loss: 0.1270, G loss: 16.2594\n",
      "[4692/8000] D loss: 0.5284, G loss: 10.7618\n",
      "[5052/8000] D loss: 0.3699, G loss: 13.0325\n",
      "[5412/8000] D loss: 0.5538, G loss: 8.0148\n",
      "[5772/8000] D loss: 0.2401, G loss: 11.0671\n",
      "[6132/8000] D loss: 0.2218, G loss: 10.5403\n",
      "[6492/8000] D loss: 0.1365, G loss: 14.5249\n",
      "[6852/8000] D loss: 0.2390, G loss: 17.3567\n",
      "[7212/8000] D loss: 0.1042, G loss: 10.3708\n",
      "[7572/8000] D loss: 0.1118, G loss: 13.0359\n",
      "[7932/8000] D loss: 0.2431, G loss: 12.8290\n",
      "train error: \n",
      " D loss: 0.281660, G loss: 13.362777, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.734639, G loss: 19.106053, D accuracy: 90.8%, cell accuracy: 94.6%, board accuracy: 6.9% \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3453, G loss: 13.2727\n",
      "[372/8000] D loss: 0.2319, G loss: 11.7023\n",
      "[732/8000] D loss: 0.2476, G loss: 11.3364\n",
      "[1092/8000] D loss: 0.0029, G loss: 13.6142\n",
      "[1452/8000] D loss: 0.2321, G loss: 8.2475\n",
      "[1812/8000] D loss: 0.4674, G loss: 9.3337\n",
      "[2172/8000] D loss: 0.4823, G loss: 10.9501\n",
      "[2532/8000] D loss: 0.5923, G loss: 13.0066\n",
      "[2892/8000] D loss: 0.3807, G loss: 12.5951\n",
      "[3252/8000] D loss: 0.3735, G loss: 10.0245\n",
      "[3612/8000] D loss: 0.0245, G loss: 13.4891\n",
      "[3972/8000] D loss: 0.2338, G loss: 16.6149\n",
      "[4332/8000] D loss: 0.5674, G loss: 9.9712\n",
      "[4692/8000] D loss: 0.2012, G loss: 9.5175\n",
      "[5052/8000] D loss: 0.3459, G loss: 10.9787\n",
      "[5412/8000] D loss: 0.6832, G loss: 6.6042\n",
      "[5772/8000] D loss: 0.1265, G loss: 10.6969\n",
      "[6132/8000] D loss: 0.3909, G loss: 14.8763\n",
      "[6492/8000] D loss: 0.3584, G loss: 12.3307\n",
      "[6852/8000] D loss: 0.0114, G loss: 10.5217\n",
      "[7212/8000] D loss: 0.1518, G loss: 11.0924\n",
      "[7572/8000] D loss: 0.2972, G loss: 10.9267\n",
      "[7932/8000] D loss: 0.0624, G loss: 11.5132\n",
      "train error: \n",
      " D loss: 0.276934, G loss: 11.024895, D accuracy: 91.2%, cell accuracy: 95.0%, board accuracy: 17.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.625442, G loss: 16.036270, D accuracy: 91.0%, cell accuracy: 94.6%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.2404, G loss: 11.0226\n",
      "[372/8000] D loss: 0.4443, G loss: 9.1642\n",
      "[732/8000] D loss: 0.2423, G loss: 8.4453\n",
      "[1092/8000] D loss: 0.3659, G loss: 9.1795\n",
      "[1452/8000] D loss: 0.3542, G loss: 9.8637\n",
      "[1812/8000] D loss: 0.3953, G loss: 11.7341\n",
      "[2172/8000] D loss: 0.1510, G loss: 12.5635\n",
      "[2532/8000] D loss: 0.1276, G loss: 12.4840\n",
      "[2892/8000] D loss: 0.1157, G loss: 12.2587\n",
      "[3252/8000] D loss: 0.1399, G loss: 13.8292\n",
      "[3612/8000] D loss: 0.4768, G loss: 10.7506\n",
      "[3972/8000] D loss: 0.0001, G loss: 19.8130\n",
      "[4332/8000] D loss: 0.6670, G loss: 7.6979\n",
      "[4692/8000] D loss: 0.0080, G loss: 11.5068\n",
      "[5052/8000] D loss: 0.2604, G loss: 11.3082\n",
      "[5412/8000] D loss: 0.7192, G loss: 7.0114\n",
      "[5772/8000] D loss: 0.3665, G loss: 9.2850\n",
      "[6132/8000] D loss: 0.1191, G loss: 14.7328\n",
      "[6492/8000] D loss: 0.2370, G loss: 13.8631\n",
      "[6852/8000] D loss: 0.3714, G loss: 10.4963\n",
      "[7212/8000] D loss: 0.2303, G loss: 15.3944\n",
      "[7572/8000] D loss: 0.1205, G loss: 14.6559\n",
      "[7932/8000] D loss: 0.4461, G loss: 9.9170\n",
      "train error: \n",
      " D loss: 0.278612, G loss: 11.012137, D accuracy: 91.1%, cell accuracy: 95.0%, board accuracy: 17.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.630291, G loss: 16.320716, D accuracy: 91.1%, cell accuracy: 94.5%, board accuracy: 7.1% \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3556, G loss: 11.3743\n",
      "[372/8000] D loss: 0.2585, G loss: 14.3821\n",
      "[732/8000] D loss: 0.4623, G loss: 11.0214\n",
      "[1092/8000] D loss: 0.3662, G loss: 9.4219\n",
      "[1452/8000] D loss: 0.1221, G loss: 14.3615\n",
      "[1812/8000] D loss: 0.3054, G loss: 7.7634\n",
      "[2172/8000] D loss: 0.1286, G loss: 12.6212\n",
      "[2532/8000] D loss: 0.3758, G loss: 13.9750\n",
      "[2892/8000] D loss: 0.1161, G loss: 13.7418\n",
      "[3252/8000] D loss: 0.1232, G loss: 10.7567\n",
      "[3612/8000] D loss: 0.2579, G loss: 12.2124\n",
      "[3972/8000] D loss: 0.4070, G loss: 7.4943\n",
      "[4332/8000] D loss: 0.1171, G loss: 11.6058\n",
      "[4692/8000] D loss: 0.1367, G loss: 14.0871\n",
      "[5052/8000] D loss: 0.3530, G loss: 10.5160\n",
      "[5412/8000] D loss: 0.0032, G loss: 18.5079\n",
      "[5772/8000] D loss: 0.0054, G loss: 15.5910\n",
      "[6132/8000] D loss: 0.2383, G loss: 9.8066\n",
      "[6492/8000] D loss: 0.6679, G loss: 11.0677\n",
      "[6852/8000] D loss: 0.3233, G loss: 14.2643\n",
      "[7212/8000] D loss: 0.1589, G loss: 14.2352\n",
      "[7572/8000] D loss: 0.1141, G loss: 11.8691\n",
      "[7932/8000] D loss: 0.1274, G loss: 17.5385\n",
      "train error: \n",
      " D loss: 0.278478, G loss: 12.125277, D accuracy: 91.4%, cell accuracy: 95.0%, board accuracy: 17.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.669841, G loss: 17.656361, D accuracy: 91.4%, cell accuracy: 94.6%, board accuracy: 7.4% \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.3237, G loss: 13.2454\n",
      "[372/8000] D loss: 0.3982, G loss: 9.4941\n",
      "[732/8000] D loss: 0.3726, G loss: 10.6764\n",
      "[1092/8000] D loss: 0.2466, G loss: 12.9589\n",
      "[1452/8000] D loss: 0.4638, G loss: 10.8117\n",
      "[1812/8000] D loss: 0.3599, G loss: 10.3981\n",
      "[2172/8000] D loss: 0.2529, G loss: 13.4299\n",
      "[2532/8000] D loss: 0.2438, G loss: 10.4504\n",
      "[2892/8000] D loss: 0.4170, G loss: 9.4222\n",
      "[3252/8000] D loss: 0.1728, G loss: 11.8183\n",
      "[3612/8000] D loss: 0.7958, G loss: 7.6997\n",
      "[3972/8000] D loss: 0.2624, G loss: 10.7421\n",
      "[4332/8000] D loss: 0.2431, G loss: 13.6846\n",
      "[4692/8000] D loss: 0.5931, G loss: 13.4716\n",
      "[5052/8000] D loss: 0.3456, G loss: 10.0838\n",
      "[5412/8000] D loss: 0.2342, G loss: 17.0175\n",
      "[5772/8000] D loss: 0.2287, G loss: 13.4988\n",
      "[6132/8000] D loss: 0.4224, G loss: 12.5723\n",
      "[6492/8000] D loss: 0.2457, G loss: 10.7584\n",
      "[6852/8000] D loss: 0.4742, G loss: 10.8975\n",
      "[7212/8000] D loss: 0.2405, G loss: 12.9799\n",
      "[7572/8000] D loss: 0.1398, G loss: 10.3426\n",
      "[7932/8000] D loss: 0.3620, G loss: 7.5721\n",
      "train error: \n",
      " D loss: 0.282708, G loss: 10.170534, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.538565, G loss: 15.260653, D accuracy: 92.4%, cell accuracy: 94.6%, board accuracy: 7.3% \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.5179, G loss: 8.8379\n",
      "[372/8000] D loss: 0.3632, G loss: 12.7543\n",
      "[732/8000] D loss: 0.1132, G loss: 14.4159\n",
      "[1092/8000] D loss: 0.2088, G loss: 14.0152\n",
      "[1452/8000] D loss: 0.3712, G loss: 6.4911\n",
      "[1812/8000] D loss: 0.2269, G loss: 16.1724\n",
      "[2172/8000] D loss: 0.1476, G loss: 13.8755\n",
      "[2532/8000] D loss: 0.4545, G loss: 6.9175\n",
      "[2892/8000] D loss: 0.2328, G loss: 12.2628\n",
      "[3252/8000] D loss: 0.2765, G loss: 10.6525\n",
      "[3612/8000] D loss: 0.2572, G loss: 13.5507\n",
      "[3972/8000] D loss: 0.2120, G loss: 11.0381\n",
      "[4332/8000] D loss: 0.3467, G loss: 12.0943\n",
      "[4692/8000] D loss: 0.4408, G loss: 7.0877\n",
      "[5052/8000] D loss: 0.1151, G loss: 12.0604\n",
      "[5412/8000] D loss: 0.4137, G loss: 11.4432\n",
      "[5772/8000] D loss: 0.5061, G loss: 11.3545\n",
      "[6132/8000] D loss: 0.4894, G loss: 10.3258\n",
      "[6492/8000] D loss: 0.1086, G loss: 13.1222\n",
      "[6852/8000] D loss: 0.4401, G loss: 8.4279\n",
      "[7212/8000] D loss: 0.2449, G loss: 13.3848\n",
      "[7572/8000] D loss: 0.4827, G loss: 5.8799\n",
      "[7932/8000] D loss: 0.1812, G loss: 15.1446\n",
      "train error: \n",
      " D loss: 0.280139, G loss: 12.682286, D accuracy: 91.1%, cell accuracy: 95.0%, board accuracy: 17.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.702127, G loss: 18.183088, D accuracy: 90.8%, cell accuracy: 94.5%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "[12/8000] D loss: 0.1198, G loss: 15.4147\n",
      "[372/8000] D loss: 0.1154, G loss: 12.9414\n",
      "[732/8000] D loss: 0.1466, G loss: 11.9878\n",
      "[1092/8000] D loss: 0.3057, G loss: 12.8968\n",
      "[1452/8000] D loss: 0.3522, G loss: 11.7902\n",
      "[1812/8000] D loss: 0.1194, G loss: 10.7161\n",
      "[2172/8000] D loss: 0.2407, G loss: 11.1490\n",
      "[2532/8000] D loss: 0.2390, G loss: 12.5903\n",
      "[2892/8000] D loss: 0.3584, G loss: 9.6342\n",
      "[3252/8000] D loss: 0.1195, G loss: 16.4437\n",
      "[3612/8000] D loss: 0.5215, G loss: 6.7563\n",
      "[3972/8000] D loss: 0.2150, G loss: 14.8442\n",
      "[4332/8000] D loss: 0.4695, G loss: 9.3170\n",
      "[4692/8000] D loss: 0.1328, G loss: 7.7783\n",
      "[5052/8000] D loss: 0.2085, G loss: 11.9966\n",
      "[5412/8000] D loss: 0.2379, G loss: 16.6333\n",
      "[5772/8000] D loss: 0.2633, G loss: 9.9834\n",
      "[6132/8000] D loss: 0.2499, G loss: 13.9606\n",
      "[6492/8000] D loss: 0.3678, G loss: 8.0435\n",
      "[6852/8000] D loss: 0.3495, G loss: 7.0283\n",
      "[7212/8000] D loss: 0.1143, G loss: 15.2490\n",
      "[7572/8000] D loss: 0.2539, G loss: 8.1176\n",
      "[7932/8000] D loss: 0.2348, G loss: 12.2086\n",
      "train error: \n",
      " D loss: 0.280323, G loss: 11.034845, D accuracy: 91.3%, cell accuracy: 95.0%, board accuracy: 17.3% \n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gen = train(\n",
    "    run_name=\"run\",\n",
    "    gen_factory=lambda: GameganGenerator(leak=0.2).to(device),\n",
    "    disc_factory=lambda: GameganDiscriminator().to(device),\n",
    "    epochs=1500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for event type 'Drop':\n",
      "  Cell accuracy (train): 93.03%\n",
      "  Cell accuracy (test): 92.84%\n",
      "  Board accuracy (train): 1.93%\n",
      "  Board accuracy (test): 1.46%\n",
      "\n",
      "Stats for event type 'Left':\n",
      "  Cell accuracy (train): 92.22%\n",
      "  Cell accuracy (test): 91.78%\n",
      "  Board accuracy (train): 0.41%\n",
      "  Board accuracy (test): 0.00%\n",
      "\n",
      "Stats for event type 'Right':\n",
      "  Cell accuracy (train): 92.34%\n",
      "  Cell accuracy (test): 92.13%\n",
      "  Board accuracy (train): 0.63%\n",
      "  Board accuracy (test): 0.23%\n",
      "\n",
      "Stats for event type 'Rotate':\n",
      "  Cell accuracy (train): 91.53%\n",
      "  Cell accuracy (test): 91.80%\n",
      "  Board accuracy (train): 0.00%\n",
      "  Board accuracy (test): 0.00%\n",
      "\n",
      "Stats for event type 'Insta-drop':\n",
      "  Cell accuracy (train): 92.59%\n",
      "  Cell accuracy (test): 92.34%\n",
      "  Board accuracy (train): 0.60%\n",
      "  Board accuracy (test): 0.47%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cell_accuracies_train = compute_metric_by_event(metrics.CellAccuracy, train_dataloader)\n",
    "cell_accuracies_test = compute_metric_by_event(metrics.CellAccuracy, test_dataloader)\n",
    "board_accuracies_train = compute_metric_by_event(metrics.BoardAccuracy, train_dataloader)\n",
    "board_accuracies_test = compute_metric_by_event(metrics.BoardAccuracy, test_dataloader)\n",
    "\n",
    "for event_type in range(NUM_EVENT_TYPES):\n",
    "    print(f\"Stats for event type '{EVENT_NAMES[event_type]}':\")\n",
    "    print(f\"  Cell accuracy (train): {cell_accuracies_train[event_type]:.2%}\")\n",
    "    print(f\"  Cell accuracy (test): {cell_accuracies_test[event_type]:.2%}\")\n",
    "    print(f\"  Board accuracy (train): {board_accuracies_train[event_type]:.2%}\")\n",
    "    print(f\"  Board accuracy (test): {board_accuracies_test[event_type]:.2%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(example):\n",
    "    (b, e), y = example\n",
    "    pred = gen(b.to(device).unsqueeze(0), e.to(device).unsqueeze(0)).squeeze(0).cpu()\n",
    "    b, e, y, pred = b.argmax(0), e.argmax(0), y.argmax(0), pred.argmax(0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    fig.suptitle(f\"Prediction vs reality\\nEvent = {EVENT_NAMES[e]}\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].set_title(\"Predicted\")\n",
    "    axs[2].set_title(\"Reality\")\n",
    "\n",
    "    num_mistakes = (y != pred).type(torch.int).sum().item()\n",
    "    print(f\"Mistakes: {num_mistakes}\")\n",
    "    axs[0].imshow(render_board(b).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[1].imshow(render_board(pred).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[2].imshow(render_board(y).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 4396\n",
      "Mistakes: 15\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random training prediction vs reality\n",
    "import random\n",
    "\n",
    "idx = random.randrange(len(train_dataset))\n",
    "print(f\"Showing prediction for training example {idx}\")\n",
    "show_prediction(train_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(gen.state_dict(), \"gamegan_emulator.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The generator learns a lot more slowly when trained end-to-end with the discriminator, and after 731 epochs (thanks to Windows Update for restarting my PC during a training run!!) we only get 17% training and 7% test board accuracy.\n",
    "\n",
    "Therefore, we should keep using fine-tuning for now. To test whether it is the GAN training itself causing the poor result in end-to-end training, we can try training without the discriminator and just computing the MSE loss between the real and predicted next frame."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
