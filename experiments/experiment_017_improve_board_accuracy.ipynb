{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 017\n",
    "\n",
    "In this experiment, we will try to improve the board accuracy of the generator. Since the generator is based on a model architecture that worked very well in the non-GAN setting, we will keep the generator fixed for now and try improving the discriminator architecture. In particular, we should make it better at dealing with block spawns and with fine details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError()\n",
    "        with os.scandir(self.path) as it:\n",
    "            entry: os.DirEntry = next(iter(it))\n",
    "            _, self.ext = os.path.splitext(entry.name)\n",
    "            self.highest_index = max((int(Path(file.path).stem) for file in it), default=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.highest_index + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = os.path.join(self.path, f\"{idx}{self.ext}\")\n",
    "        if not os.path.exists(file):\n",
    "            raise IndexError()\n",
    "        boards = np.load(file)\n",
    "\n",
    "        def transform(board):\n",
    "            board = torch.tensor(board, dtype=torch.long)\n",
    "            board = F.one_hot(board, 2) # One-hot encode the cell types\n",
    "            board = board.type(torch.float) # Convert to floating-point\n",
    "            board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "            return board\n",
    "\n",
    "        x = transform(boards[-2]) # Ignore all boards except the last two\n",
    "        y = transform(boards[-1])\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 22, 10]) torch.float32\n",
      "torch.Size([4, 2, 22, 10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisModel(nn.Module):\n",
    "    \"\"\"Predicts the next state of the cells.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        z: Tensor of float32 of shape (batch_size, 4). The entries should be random numbers sampled from a uniform distribution.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, height, width), logits for the new cells. Probabilities close to 0 (negative logits)\n",
    "             correspond to empty cells, and probabilities close to 1 (positive logits) correspond to filled cells.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        z = z[:, :, None, None] # Expand dims to match x\n",
    "        z = z.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        x_glob = self.glob(x)\n",
    "        x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "        x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisDiscriminator(nn.Module):\n",
    "    \"\"\"A discriminator for the cell state predictions. Assesses the output of the generator.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        y: Tensor of float32 of shape (batch_size, channels, height, width), as with x. This should be either the output of the\n",
    "           generator (with exp applied) or the one-hot encoding of the ground truth of the next cell states.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, 1), decisions on whether the data are real or fake. Probabilities close to 0 (negative logits)\n",
    "             correspond to fake data, and probabilities close to 1 (positive logits) correspond to real data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(160, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def check_disc(disc):\n",
    "    gen = TetrisModel().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X, y = next(iter(train_dataloader))\n",
    "        z = torch.rand(batch_size, 4)\n",
    "        y_gen = gen(X, z)\n",
    "        pred_on_real = F.sigmoid(disc(X, y)[0])\n",
    "        pred_on_fake = F.sigmoid(disc(X, y_gen)[0])\n",
    "        print(f\"Number of discriminator parameters: {count_parameters(disc)}\")\n",
    "        print(f\"Predicted label for real data: {pred_on_real}\")\n",
    "        print(f\"Predicted label for fake data: {pred_on_fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_interesting_examples(dataset, num=4):\n",
    "    num_spawns = num // 2\n",
    "    num_normal = num - num_spawns\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "        num_normal_left = num_normal\n",
    "\n",
    "        for x, y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (x.argmax(0)[0] == 0).all() & (y.argmax(0)[0] == 1).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield x, y\n",
    "                else:\n",
    "                    continue\n",
    "            # Yield general examples\n",
    "            if num_normal_left > 0:\n",
    "                num_normal_left -= 1\n",
    "                yield x, y\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prediction(x, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        x: Tensor of shape (height, width), the model input.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the target.\n",
    "    \"\"\"\n",
    "    assert len(x.shape) == 2, f\"Expected tensors of shape (width, height) but got {x.shape}\"\n",
    "    assert x.shape == pred.shape, f\"Shapes do not match: {x.shape} != {pred.shape}\"\n",
    "    assert x.shape == y.shape, f\"Shapes do not match: {x.shape} != {y.shape}\"\n",
    "    height, width = x.shape\n",
    "    with torch.no_grad():\n",
    "        separator = torch.ones(height, 1, dtype=x.dtype)\n",
    "        return torch.cat((x, separator, pred, separator, y), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(X, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        z = torch.rand(batch_size, 4, device=device)\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(X, z)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(X, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(X, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 20 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "    spawn_recall = 0.0\n",
    "    num_spawns = 0.0\n",
    "    spawn_precision = 0.0\n",
    "    num_predicted_spawns = 0.0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for X, y in dataloader:\n",
    "            batch_size = X.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(X, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            z = torch.rand(batch_size, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            output_fake = disc(X, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_X = torch.argmax(X, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy += (classes_y_fake == classes_y).type(torch.float).mean().item()\n",
    "            board_accuracy += (classes_y_fake == classes_y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "            actual_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y[:, 0, :] == 1).any(-1)\n",
    "            predicted_spawns = (classes_y_fake[:, 0, :] == 1).any(-1)\n",
    "            num_true_positives = (actual_spawns & predicted_spawns).type(torch.float).sum().item()\n",
    "            spawn_recall += num_true_positives\n",
    "            num_spawns += actual_spawns.type(torch.float).sum().item()\n",
    "            spawn_precision += num_true_positives\n",
    "            num_predicted_spawns += predicted_spawns.type(torch.float).sum().item()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    spawn_recall /= num_spawns\n",
    "    spawn_precision = np.nan if (num_predicted_spawns == 0.0) else (spawn_precision / num_predicted_spawns)\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(100*cell_accuracy):>0.1f}%, board accuracy: {(100*board_accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(examples):\n",
    "            X, y = X.unsqueeze(0), y.unsqueeze(0)\n",
    "            z = torch.rand(1, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            X, y, y_fake = X.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            X, y, y_fake = X.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(X, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch, dataformats=\"HW\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", disc_cls=TetrisDiscriminator):\n",
    "    learning_rate = 1e-2\n",
    "    epochs = 50\n",
    "\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = disc_cls().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.SGD(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.SGD(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_017\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 5793\n",
      "Predicted label for real data: 0.4673059284687042\n",
      "Predicted label for fake data: 0.46102985739707947\n"
     ]
    }
   ],
   "source": [
    "class DiscWithMoreLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(160, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithMoreLinear().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 10961\n",
      "Predicted label for real data: 0.41659843921661377\n",
      "Predicted label for fake data: 0.41942277550697327\n"
     ]
    }
   ],
   "source": [
    "class WiderDisc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 24, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(24, 24, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(24),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(240, 20),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(20, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(WiderDisc().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 7089\n",
      "Predicted label for real data: 0.5074602961540222\n",
      "Predicted label for fake data: 0.5116638541221619\n"
     ]
    }
   ],
   "source": [
    "class DiscWithNoUnevenMaxPools(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1), # (batch_size, 16, 22, 10)\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2), # (batch_size, 16, 11, 5)\n",
    "                nn.Conv2d(16, 16, 3, bias=False), # (batch_size, 16, 9, 3)\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, bias=False), # (batch_size, 16, 7, 1)\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithNoUnevenMaxPools().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 5521\n",
      "Predicted label for real data: 0.5421004295349121\n",
      "Predicted label for fake data: 0.5194949507713318\n"
     ]
    }
   ],
   "source": [
    "class DiscWithStridedConvs(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, kernel_size=3, stride=2, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, kernel_size=3, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(160, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithStridedConvs().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3850, G loss: 0.8843\n",
      "[84/1762] D loss: 1.0081, G loss: 1.1623\n",
      "[164/1762] D loss: 1.1196, G loss: 0.4879\n",
      "[244/1762] D loss: 1.1974, G loss: 0.3559\n",
      "[324/1762] D loss: 1.0870, G loss: 1.2813\n",
      "[404/1762] D loss: 1.0741, G loss: 1.6333\n",
      "[484/1762] D loss: 1.2479, G loss: 0.3509\n",
      "[564/1762] D loss: 1.2631, G loss: 3.2276\n",
      "[644/1762] D loss: 1.4808, G loss: 0.7716\n",
      "[724/1762] D loss: 0.8095, G loss: 0.9920\n",
      "[804/1762] D loss: 0.9246, G loss: 0.6251\n",
      "[884/1762] D loss: 1.3909, G loss: 0.9660\n",
      "[964/1762] D loss: 1.2716, G loss: 0.6807\n",
      "[1044/1762] D loss: 1.1564, G loss: 0.2983\n",
      "[1124/1762] D loss: 1.6253, G loss: 0.3096\n",
      "[1204/1762] D loss: 1.3028, G loss: 0.6137\n",
      "[1284/1762] D loss: 1.5668, G loss: 1.2429\n",
      "[1364/1762] D loss: 1.3711, G loss: 0.4331\n",
      "[1444/1762] D loss: 1.2696, G loss: 1.1483\n",
      "[1524/1762] D loss: 1.4281, G loss: 0.5287\n",
      "[1604/1762] D loss: 1.3756, G loss: 0.5091\n",
      "[1684/1762] D loss: 1.1031, G loss: 0.8073\n",
      "[1762/1762] D loss: 1.3796, G loss: 0.8306\n",
      "train error: \n",
      " D loss: 1.294782, G loss: 0.832076, D accuracy: 60.5%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281982, G loss: 0.853491, D accuracy: 59.9%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.6945\n",
      "[84/1762] D loss: 0.9715, G loss: 1.0681\n",
      "[164/1762] D loss: 1.0548, G loss: 1.3156\n",
      "[244/1762] D loss: 1.4051, G loss: 1.0393\n",
      "[324/1762] D loss: 1.2821, G loss: 0.6893\n",
      "[404/1762] D loss: 1.0733, G loss: 1.1976\n",
      "[484/1762] D loss: 1.3816, G loss: 0.5100\n",
      "[564/1762] D loss: 1.3982, G loss: 0.5591\n",
      "[644/1762] D loss: 1.3839, G loss: 0.6770\n",
      "[724/1762] D loss: 1.3766, G loss: 0.7784\n",
      "[804/1762] D loss: 1.4640, G loss: 0.5646\n",
      "[884/1762] D loss: 1.1050, G loss: 1.0149\n",
      "[964/1762] D loss: 1.0747, G loss: 1.3286\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.7029\n",
      "[1124/1762] D loss: 1.4588, G loss: 0.4383\n",
      "[1204/1762] D loss: 0.9678, G loss: 1.1707\n",
      "[1284/1762] D loss: 1.4118, G loss: 0.7834\n",
      "[1364/1762] D loss: 1.0646, G loss: 1.2940\n",
      "[1444/1762] D loss: 1.3830, G loss: 0.6828\n",
      "[1524/1762] D loss: 0.9143, G loss: 1.1446\n",
      "[1604/1762] D loss: 0.9295, G loss: 1.2430\n",
      "[1684/1762] D loss: 1.3957, G loss: 0.6488\n",
      "[1762/1762] D loss: 0.6359, G loss: 2.0373\n",
      "train error: \n",
      " D loss: 1.311541, G loss: 1.024384, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299435, G loss: 1.057145, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8583, G loss: 1.1728\n",
      "[84/1762] D loss: 1.3741, G loss: 0.6861\n",
      "[164/1762] D loss: 1.4182, G loss: 0.8672\n",
      "[244/1762] D loss: 0.9962, G loss: 1.4743\n",
      "[324/1762] D loss: 1.4061, G loss: 0.6209\n",
      "[404/1762] D loss: 1.3828, G loss: 0.7344\n",
      "[484/1762] D loss: 1.4076, G loss: 0.6315\n",
      "[564/1762] D loss: 1.3936, G loss: 0.7493\n",
      "[644/1762] D loss: 1.3362, G loss: 0.8784\n",
      "[724/1762] D loss: 1.2973, G loss: 0.7109\n",
      "[804/1762] D loss: 1.4681, G loss: 0.6229\n",
      "[884/1762] D loss: 0.8560, G loss: 1.6630\n",
      "[964/1762] D loss: 1.4213, G loss: 0.5519\n",
      "[1044/1762] D loss: 0.7055, G loss: 1.5995\n",
      "[1124/1762] D loss: 1.4698, G loss: 0.7176\n",
      "[1204/1762] D loss: 0.6709, G loss: 1.5172\n",
      "[1284/1762] D loss: 1.4231, G loss: 0.7153\n",
      "[1364/1762] D loss: 1.3213, G loss: 0.8907\n",
      "[1444/1762] D loss: 1.3596, G loss: 0.8288\n",
      "[1524/1762] D loss: 1.0808, G loss: 1.7729\n",
      "[1604/1762] D loss: 1.4339, G loss: 0.5813\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.8002\n",
      "[1762/1762] D loss: 1.6072, G loss: 0.4160\n",
      "train error: \n",
      " D loss: 1.709883, G loss: 0.274025, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.697683, G loss: 0.278907, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8883, G loss: 1.4875\n",
      "[84/1762] D loss: 1.4193, G loss: 0.6157\n",
      "[164/1762] D loss: 1.3922, G loss: 0.6004\n",
      "[244/1762] D loss: 1.7377, G loss: 0.6948\n",
      "[324/1762] D loss: 1.4735, G loss: 0.9313\n",
      "[404/1762] D loss: 1.3713, G loss: 0.7163\n",
      "[484/1762] D loss: 1.5942, G loss: 0.4056\n",
      "[564/1762] D loss: 1.3856, G loss: 0.5607\n",
      "[644/1762] D loss: 1.3648, G loss: 0.7651\n",
      "[724/1762] D loss: 1.3665, G loss: 0.6810\n",
      "[804/1762] D loss: 0.9159, G loss: 1.1469\n",
      "[884/1762] D loss: 1.4683, G loss: 0.5910\n",
      "[964/1762] D loss: 0.6390, G loss: 1.6007\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.7157\n",
      "[1124/1762] D loss: 1.3795, G loss: 0.7121\n",
      "[1204/1762] D loss: 1.3620, G loss: 0.7816\n",
      "[1284/1762] D loss: 1.4676, G loss: 0.6121\n",
      "[1364/1762] D loss: 1.4405, G loss: 0.7883\n",
      "[1444/1762] D loss: 1.5940, G loss: 0.8504\n",
      "[1524/1762] D loss: 1.4022, G loss: 0.7044\n",
      "[1604/1762] D loss: 1.3921, G loss: 0.7023\n",
      "[1684/1762] D loss: 1.3792, G loss: 0.7007\n",
      "[1762/1762] D loss: 1.3823, G loss: 0.7312\n",
      "train error: \n",
      " D loss: 1.347658, G loss: 0.877749, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329418, G loss: 0.898265, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9575, G loss: 1.1114\n",
      "[84/1762] D loss: 1.5617, G loss: 0.5530\n",
      "[164/1762] D loss: 0.7600, G loss: 1.7683\n",
      "[244/1762] D loss: 1.2958, G loss: 0.7202\n",
      "[324/1762] D loss: 0.8858, G loss: 1.3485\n",
      "[404/1762] D loss: 1.2542, G loss: 0.9450\n",
      "[484/1762] D loss: 1.3047, G loss: 0.6852\n",
      "[564/1762] D loss: 1.4299, G loss: 0.6417\n",
      "[644/1762] D loss: 1.4360, G loss: 0.6826\n",
      "[724/1762] D loss: 1.3991, G loss: 0.6499\n",
      "[804/1762] D loss: 1.4473, G loss: 0.7842\n",
      "[884/1762] D loss: 1.3946, G loss: 0.6900\n",
      "[964/1762] D loss: 1.5634, G loss: 0.8122\n",
      "[1044/1762] D loss: 1.4069, G loss: 0.6670\n",
      "[1124/1762] D loss: 1.4760, G loss: 0.6507\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.7157\n",
      "[1284/1762] D loss: 0.6429, G loss: 1.5350\n",
      "[1364/1762] D loss: 1.6776, G loss: 0.5994\n",
      "[1444/1762] D loss: 0.6759, G loss: 1.5560\n",
      "[1524/1762] D loss: 1.4505, G loss: 0.8507\n",
      "[1604/1762] D loss: 0.1585, G loss: 2.7831\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.6974\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.6517\n",
      "train error: \n",
      " D loss: 1.360168, G loss: 0.593327, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339291, G loss: 0.601963, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3842, G loss: 0.7258\n",
      "[84/1762] D loss: 0.5869, G loss: 1.6255\n",
      "[164/1762] D loss: 1.4105, G loss: 0.7217\n",
      "[244/1762] D loss: 0.6350, G loss: 1.6784\n",
      "[324/1762] D loss: 1.3111, G loss: 0.8115\n",
      "[404/1762] D loss: 1.3248, G loss: 0.7698\n",
      "[484/1762] D loss: 1.4252, G loss: 0.8050\n",
      "[564/1762] D loss: 1.4210, G loss: 0.6925\n",
      "[644/1762] D loss: 1.3455, G loss: 0.6910\n",
      "[724/1762] D loss: 0.6040, G loss: 1.4906\n",
      "[804/1762] D loss: 1.4017, G loss: 0.7014\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7115\n",
      "[964/1762] D loss: 1.6913, G loss: 0.6745\n",
      "[1044/1762] D loss: 1.4746, G loss: 0.7144\n",
      "[1124/1762] D loss: 1.4699, G loss: 0.6748\n",
      "[1204/1762] D loss: 1.4016, G loss: 0.6958\n",
      "[1284/1762] D loss: 1.1633, G loss: 0.8796\n",
      "[1364/1762] D loss: 1.5209, G loss: 0.5564\n",
      "[1444/1762] D loss: 1.4155, G loss: 0.6364\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.6946\n",
      "[1604/1762] D loss: 0.4667, G loss: 1.9548\n",
      "[1684/1762] D loss: 1.4322, G loss: 0.7455\n",
      "[1762/1762] D loss: 1.5642, G loss: 0.6421\n",
      "train error: \n",
      " D loss: 1.346984, G loss: 0.648218, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330669, G loss: 0.642847, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4376, G loss: 0.6888\n",
      "[84/1762] D loss: 1.5565, G loss: 0.7152\n",
      "[164/1762] D loss: 1.4025, G loss: 0.7303\n",
      "[244/1762] D loss: 1.3952, G loss: 0.6920\n",
      "[324/1762] D loss: 1.3925, G loss: 0.6803\n",
      "[404/1762] D loss: 1.4588, G loss: 0.6923\n",
      "[484/1762] D loss: 1.4896, G loss: 0.6932\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6969\n",
      "[644/1762] D loss: 1.3917, G loss: 0.7177\n",
      "[724/1762] D loss: 1.6381, G loss: 0.6878\n",
      "[804/1762] D loss: 1.3882, G loss: 0.7002\n",
      "[884/1762] D loss: 1.3972, G loss: 0.7132\n",
      "[964/1762] D loss: 1.3936, G loss: 0.6866\n",
      "[1044/1762] D loss: 1.6619, G loss: 0.6731\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.6968\n",
      "[1204/1762] D loss: 0.5004, G loss: 1.6512\n",
      "[1284/1762] D loss: 1.4007, G loss: 0.6996\n",
      "[1364/1762] D loss: 1.8178, G loss: 0.7200\n",
      "[1444/1762] D loss: 0.5988, G loss: 1.4259\n",
      "[1524/1762] D loss: 1.3902, G loss: 0.7005\n",
      "[1604/1762] D loss: 0.4980, G loss: 1.5676\n",
      "[1684/1762] D loss: 0.5657, G loss: 1.5467\n",
      "[1762/1762] D loss: 1.4929, G loss: 0.5975\n",
      "train error: \n",
      " D loss: 1.622384, G loss: 0.323470, D accuracy: 51.6%, cell accuracy: 99.6%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.603165, G loss: 0.332824, D accuracy: 51.9%, cell accuracy: 99.5%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3794, G loss: 0.7062\n",
      "[84/1762] D loss: 1.5686, G loss: 0.7169\n",
      "[164/1762] D loss: 0.3747, G loss: 1.9381\n",
      "[244/1762] D loss: 1.4107, G loss: 0.7057\n",
      "[324/1762] D loss: 0.5289, G loss: 1.4528\n",
      "[404/1762] D loss: 1.3974, G loss: 0.7117\n",
      "[484/1762] D loss: 1.4326, G loss: 0.7426\n",
      "[564/1762] D loss: 1.3029, G loss: 0.8822\n",
      "[644/1762] D loss: 1.4324, G loss: 0.7407\n",
      "[724/1762] D loss: 1.5546, G loss: 0.6888\n",
      "[804/1762] D loss: 1.3977, G loss: 0.7005\n",
      "[884/1762] D loss: 1.3748, G loss: 0.7574\n",
      "[964/1762] D loss: 0.5597, G loss: 1.3600\n",
      "[1044/1762] D loss: 1.5260, G loss: 0.6536\n",
      "[1124/1762] D loss: 1.3984, G loss: 0.7408\n",
      "[1204/1762] D loss: 1.4167, G loss: 0.6577\n",
      "[1284/1762] D loss: 0.3898, G loss: 1.8233\n",
      "[1364/1762] D loss: 1.4392, G loss: 0.6480\n",
      "[1444/1762] D loss: 1.4069, G loss: 0.6542\n",
      "[1524/1762] D loss: 0.4849, G loss: 1.5970\n",
      "[1604/1762] D loss: 0.5289, G loss: 1.5484\n",
      "[1684/1762] D loss: 1.4079, G loss: 0.7107\n",
      "[1762/1762] D loss: 1.4065, G loss: 0.7280\n",
      "train error: \n",
      " D loss: 1.360405, G loss: 0.602638, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347386, G loss: 0.608259, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4232, G loss: 0.7075\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7097\n",
      "[164/1762] D loss: 1.3945, G loss: 0.7032\n",
      "[244/1762] D loss: 1.4075, G loss: 0.8648\n",
      "[324/1762] D loss: 1.3941, G loss: 0.6883\n",
      "[404/1762] D loss: 1.5447, G loss: 0.5961\n",
      "[484/1762] D loss: 1.4825, G loss: 0.6608\n",
      "[564/1762] D loss: 1.9677, G loss: 0.6210\n",
      "[644/1762] D loss: 1.3842, G loss: 0.6900\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6964\n",
      "[804/1762] D loss: 1.4128, G loss: 0.6613\n",
      "[884/1762] D loss: 0.4588, G loss: 1.6833\n",
      "[964/1762] D loss: 0.2857, G loss: 2.1217\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.7015\n",
      "[1124/1762] D loss: 0.6433, G loss: 1.3338\n",
      "[1204/1762] D loss: 1.4073, G loss: 0.7196\n",
      "[1284/1762] D loss: 0.6168, G loss: 1.6491\n",
      "[1364/1762] D loss: 1.4574, G loss: 0.6351\n",
      "[1444/1762] D loss: 0.7295, G loss: 1.6147\n",
      "[1524/1762] D loss: 1.3934, G loss: 0.6920\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.6974\n",
      "[1684/1762] D loss: 1.4061, G loss: 0.6864\n",
      "[1762/1762] D loss: 1.4259, G loss: 0.6238\n",
      "train error: \n",
      " D loss: 1.304449, G loss: 0.770626, D accuracy: 58.4%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299149, G loss: 0.760453, D accuracy: 58.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4014, G loss: 0.7024\n",
      "[84/1762] D loss: 0.4158, G loss: 1.6185\n",
      "[164/1762] D loss: 0.2439, G loss: 2.1769\n",
      "[244/1762] D loss: 0.5604, G loss: 2.1670\n",
      "[324/1762] D loss: 1.3928, G loss: 0.6993\n",
      "[404/1762] D loss: 1.4860, G loss: 0.6729\n",
      "[484/1762] D loss: 1.3886, G loss: 0.6905\n",
      "[564/1762] D loss: 1.4093, G loss: 0.6126\n",
      "[644/1762] D loss: 1.3851, G loss: 0.7007\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7113\n",
      "[804/1762] D loss: 1.3949, G loss: 0.6795\n",
      "[884/1762] D loss: 0.4545, G loss: 1.6893\n",
      "[964/1762] D loss: 1.4096, G loss: 0.6988\n",
      "[1044/1762] D loss: 1.4159, G loss: 0.6751\n",
      "[1124/1762] D loss: 0.4767, G loss: 1.5652\n",
      "[1204/1762] D loss: 1.4001, G loss: 0.7046\n",
      "[1284/1762] D loss: 1.4294, G loss: 0.6579\n",
      "[1364/1762] D loss: 0.4372, G loss: 1.5415\n",
      "[1444/1762] D loss: 1.4022, G loss: 0.7050\n",
      "[1524/1762] D loss: 1.3987, G loss: 0.6085\n",
      "[1604/1762] D loss: 1.4011, G loss: 0.6782\n",
      "[1684/1762] D loss: 1.4066, G loss: 0.7558\n",
      "[1762/1762] D loss: 1.5327, G loss: 0.5441\n",
      "train error: \n",
      " D loss: 1.570869, G loss: 0.392790, D accuracy: 50.3%, cell accuracy: 99.7%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.572390, G loss: 0.393574, D accuracy: 50.5%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4223, G loss: 0.7295\n",
      "[84/1762] D loss: 0.6499, G loss: 1.5557\n",
      "[164/1762] D loss: 1.3903, G loss: 0.7091\n",
      "[244/1762] D loss: 0.4435, G loss: 1.7737\n",
      "[324/1762] D loss: 1.7793, G loss: 0.6271\n",
      "[404/1762] D loss: 1.4699, G loss: 0.5212\n",
      "[484/1762] D loss: 0.3678, G loss: 1.7178\n",
      "[564/1762] D loss: 1.3369, G loss: 0.9538\n",
      "[644/1762] D loss: 1.4169, G loss: 0.7150\n",
      "[724/1762] D loss: 1.4594, G loss: 0.6751\n",
      "[804/1762] D loss: 1.2424, G loss: 0.7262\n",
      "[884/1762] D loss: 1.4292, G loss: 0.6913\n",
      "[964/1762] D loss: 1.4419, G loss: 0.6491\n",
      "[1044/1762] D loss: 0.4301, G loss: 1.6280\n",
      "[1124/1762] D loss: 1.5393, G loss: 0.7252\n",
      "[1204/1762] D loss: 1.4663, G loss: 0.7419\n",
      "[1284/1762] D loss: 1.4044, G loss: 0.7237\n",
      "[1364/1762] D loss: 1.4857, G loss: 0.6822\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[1524/1762] D loss: 0.1900, G loss: 2.2720\n",
      "[1604/1762] D loss: 0.4887, G loss: 1.5209\n",
      "[1684/1762] D loss: 1.4250, G loss: 0.7323\n",
      "[1762/1762] D loss: 1.3547, G loss: 0.7768\n",
      "train error: \n",
      " D loss: 1.461898, G loss: 0.467341, D accuracy: 52.5%, cell accuracy: 99.5%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.491421, G loss: 0.457744, D accuracy: 52.3%, cell accuracy: 99.4%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3194, G loss: 0.8325\n",
      "[84/1762] D loss: 0.4342, G loss: 1.9258\n",
      "[164/1762] D loss: 1.3941, G loss: 0.6974\n",
      "[244/1762] D loss: 1.4033, G loss: 0.7282\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7006\n",
      "[404/1762] D loss: 1.4139, G loss: 0.6941\n",
      "[484/1762] D loss: 1.3950, G loss: 0.6896\n",
      "[564/1762] D loss: 1.4198, G loss: 0.7479\n",
      "[644/1762] D loss: 1.4524, G loss: 0.7326\n",
      "[724/1762] D loss: 0.5099, G loss: 1.9483\n",
      "[804/1762] D loss: 1.3957, G loss: 0.6918\n",
      "[884/1762] D loss: 1.5337, G loss: 0.7224\n",
      "[964/1762] D loss: 1.3950, G loss: 0.7058\n",
      "[1044/1762] D loss: 1.4023, G loss: 0.6913\n",
      "[1124/1762] D loss: 1.4053, G loss: 0.6877\n",
      "[1204/1762] D loss: 0.4264, G loss: 1.6898\n",
      "[1284/1762] D loss: 1.2603, G loss: 0.8014\n",
      "[1364/1762] D loss: 1.3990, G loss: 0.6491\n",
      "[1444/1762] D loss: 1.3993, G loss: 0.7080\n",
      "[1524/1762] D loss: 1.5615, G loss: 0.6898\n",
      "[1604/1762] D loss: 0.3519, G loss: 2.0382\n",
      "[1684/1762] D loss: 1.4722, G loss: 0.7374\n",
      "[1762/1762] D loss: 0.2113, G loss: 2.7215\n",
      "train error: \n",
      " D loss: 1.516371, G loss: 0.451880, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.490037, G loss: 0.485812, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4863, G loss: 0.7976\n",
      "[84/1762] D loss: 0.0908, G loss: 3.0064\n",
      "[164/1762] D loss: 1.3930, G loss: 0.7343\n",
      "[244/1762] D loss: 1.4028, G loss: 0.6583\n",
      "[324/1762] D loss: 0.4292, G loss: 1.8124\n",
      "[404/1762] D loss: 1.4052, G loss: 0.6969\n",
      "[484/1762] D loss: 0.4398, G loss: 1.5018\n",
      "[564/1762] D loss: 1.3806, G loss: 0.6883\n",
      "[644/1762] D loss: 0.1741, G loss: 2.4500\n",
      "[724/1762] D loss: 1.3936, G loss: 0.6985\n",
      "[804/1762] D loss: 1.4044, G loss: 0.6794\n",
      "[884/1762] D loss: 0.3494, G loss: 2.1187\n",
      "[964/1762] D loss: 1.4498, G loss: 0.6511\n",
      "[1044/1762] D loss: 1.3964, G loss: 0.7317\n",
      "[1124/1762] D loss: 1.4592, G loss: 0.6892\n",
      "[1204/1762] D loss: 1.3132, G loss: 0.8064\n",
      "[1284/1762] D loss: 1.7787, G loss: 1.0087\n",
      "[1364/1762] D loss: 1.3711, G loss: 0.7123\n",
      "[1444/1762] D loss: 1.2810, G loss: 1.1328\n",
      "[1524/1762] D loss: 1.4296, G loss: 0.6277\n",
      "[1604/1762] D loss: 1.2172, G loss: 0.7979\n",
      "[1684/1762] D loss: 1.4068, G loss: 0.6758\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.6906\n",
      "train error: \n",
      " D loss: 1.323041, G loss: 0.790957, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309780, G loss: 0.796230, D accuracy: 56.7%, cell accuracy: 99.6%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.6838\n",
      "[84/1762] D loss: 1.2678, G loss: 0.7178\n",
      "[164/1762] D loss: 1.1186, G loss: 1.0746\n",
      "[244/1762] D loss: 1.3553, G loss: 0.6799\n",
      "[324/1762] D loss: 1.0543, G loss: 1.4909\n",
      "[404/1762] D loss: 1.4288, G loss: 0.5883\n",
      "[484/1762] D loss: 1.3915, G loss: 0.6589\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6961\n",
      "[644/1762] D loss: 1.1824, G loss: 1.3343\n",
      "[724/1762] D loss: 1.3946, G loss: 0.6959\n",
      "[804/1762] D loss: 1.3892, G loss: 0.7060\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6923\n",
      "[964/1762] D loss: 1.4313, G loss: 0.6724\n",
      "[1044/1762] D loss: 1.4047, G loss: 0.6667\n",
      "[1124/1762] D loss: 1.3791, G loss: 0.7095\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.7148\n",
      "[1284/1762] D loss: 1.4079, G loss: 0.7279\n",
      "[1364/1762] D loss: 1.3073, G loss: 0.7037\n",
      "[1444/1762] D loss: 1.1943, G loss: 1.0355\n",
      "[1524/1762] D loss: 1.4205, G loss: 0.6020\n",
      "[1604/1762] D loss: 1.3600, G loss: 0.7851\n",
      "[1684/1762] D loss: 1.3992, G loss: 0.6151\n",
      "[1762/1762] D loss: 1.3822, G loss: 0.6620\n",
      "train error: \n",
      " D loss: 1.368724, G loss: 0.689078, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378672, G loss: 0.689143, D accuracy: 51.9%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.7182\n",
      "[84/1762] D loss: 1.4040, G loss: 0.6548\n",
      "[164/1762] D loss: 1.3051, G loss: 0.6641\n",
      "[244/1762] D loss: 1.4185, G loss: 0.6397\n",
      "[324/1762] D loss: 1.2019, G loss: 0.8728\n",
      "[404/1762] D loss: 1.3928, G loss: 0.6618\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7133\n",
      "[564/1762] D loss: 1.5131, G loss: 0.6160\n",
      "[644/1762] D loss: 1.3558, G loss: 0.9200\n",
      "[724/1762] D loss: 1.3941, G loss: 0.7392\n",
      "[804/1762] D loss: 0.8649, G loss: 1.7722\n",
      "[884/1762] D loss: 1.3909, G loss: 0.6500\n",
      "[964/1762] D loss: 1.1327, G loss: 0.9512\n",
      "[1044/1762] D loss: 1.3548, G loss: 0.7290\n",
      "[1124/1762] D loss: 1.3203, G loss: 1.1710\n",
      "[1204/1762] D loss: 0.8341, G loss: 1.3046\n",
      "[1284/1762] D loss: 1.1920, G loss: 0.8700\n",
      "[1364/1762] D loss: 1.4976, G loss: 0.5642\n",
      "[1444/1762] D loss: 1.3991, G loss: 0.6716\n",
      "[1524/1762] D loss: 1.3994, G loss: 0.6679\n",
      "[1604/1762] D loss: 1.4056, G loss: 0.6530\n",
      "[1684/1762] D loss: 1.4050, G loss: 0.7092\n",
      "[1762/1762] D loss: 0.5034, G loss: 2.0406\n",
      "train error: \n",
      " D loss: 1.332451, G loss: 1.004517, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310712, G loss: 1.069785, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3984, G loss: 0.7470\n",
      "[84/1762] D loss: 1.4591, G loss: 0.7189\n",
      "[164/1762] D loss: 1.4326, G loss: 0.7336\n",
      "[244/1762] D loss: 1.2779, G loss: 0.8976\n",
      "[324/1762] D loss: 0.7988, G loss: 1.6756\n",
      "[404/1762] D loss: 1.3257, G loss: 1.4657\n",
      "[484/1762] D loss: 1.4111, G loss: 0.6906\n",
      "[564/1762] D loss: 0.7265, G loss: 1.5632\n",
      "[644/1762] D loss: 1.3939, G loss: 0.6529\n",
      "[724/1762] D loss: 1.3984, G loss: 0.6881\n",
      "[804/1762] D loss: 0.6151, G loss: 2.0331\n",
      "[884/1762] D loss: 1.3814, G loss: 0.8606\n",
      "[964/1762] D loss: 1.3972, G loss: 0.8084\n",
      "[1044/1762] D loss: 1.4513, G loss: 0.5646\n",
      "[1124/1762] D loss: 0.5870, G loss: 2.1660\n",
      "[1204/1762] D loss: 0.4795, G loss: 1.8718\n",
      "[1284/1762] D loss: 0.3436, G loss: 2.3320\n",
      "[1364/1762] D loss: 0.1608, G loss: 2.5259\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.7594\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.6768\n",
      "[1604/1762] D loss: 0.4494, G loss: 1.9068\n",
      "[1684/1762] D loss: 1.4173, G loss: 0.7748\n",
      "[1762/1762] D loss: 1.4059, G loss: 0.5261\n",
      "train error: \n",
      " D loss: 1.311391, G loss: 0.717613, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279309, G loss: 0.776070, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4702, G loss: 1.9196\n",
      "[84/1762] D loss: 0.2922, G loss: 2.4186\n",
      "[164/1762] D loss: 1.3910, G loss: 0.6974\n",
      "[244/1762] D loss: 1.4159, G loss: 0.6466\n",
      "[324/1762] D loss: 1.4184, G loss: 0.6565\n",
      "[404/1762] D loss: 1.5562, G loss: 0.5999\n",
      "[484/1762] D loss: 1.4179, G loss: 0.7311\n",
      "[564/1762] D loss: 0.4678, G loss: 1.6855\n",
      "[644/1762] D loss: 1.3158, G loss: 0.8723\n",
      "[724/1762] D loss: 1.3894, G loss: 0.6940\n",
      "[804/1762] D loss: 1.3729, G loss: 0.6530\n",
      "[884/1762] D loss: 0.2207, G loss: 2.4589\n",
      "[964/1762] D loss: 1.8074, G loss: 0.5784\n",
      "[1044/1762] D loss: 0.2364, G loss: 2.5055\n",
      "[1124/1762] D loss: 1.2891, G loss: 0.7481\n",
      "[1204/1762] D loss: 1.5758, G loss: 0.9313\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.6801\n",
      "[1364/1762] D loss: 1.3798, G loss: 0.7093\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.7105\n",
      "[1524/1762] D loss: 1.3761, G loss: 0.7432\n",
      "[1604/1762] D loss: 1.3260, G loss: 0.8742\n",
      "[1684/1762] D loss: 1.3857, G loss: 0.6710\n",
      "[1762/1762] D loss: 1.3346, G loss: 0.7022\n",
      "train error: \n",
      " D loss: 1.323278, G loss: 0.977010, D accuracy: 55.4%, cell accuracy: 99.6%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314910, G loss: 1.089741, D accuracy: 56.2%, cell accuracy: 99.4%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2953, G loss: 0.8314\n",
      "[84/1762] D loss: 1.0814, G loss: 1.1684\n",
      "[164/1762] D loss: 1.3964, G loss: 0.6866\n",
      "[244/1762] D loss: 1.3996, G loss: 0.6471\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6946\n",
      "[404/1762] D loss: 1.3228, G loss: 0.7896\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6561\n",
      "[564/1762] D loss: 1.3863, G loss: 0.7078\n",
      "[644/1762] D loss: 1.3905, G loss: 0.5995\n",
      "[724/1762] D loss: 0.8572, G loss: 1.6670\n",
      "[804/1762] D loss: 1.3914, G loss: 0.7069\n",
      "[884/1762] D loss: 1.2919, G loss: 0.9179\n",
      "[964/1762] D loss: 1.3631, G loss: 1.0061\n",
      "[1044/1762] D loss: 1.2975, G loss: 0.7817\n",
      "[1124/1762] D loss: 1.0532, G loss: 1.3340\n",
      "[1204/1762] D loss: 1.3695, G loss: 0.7364\n",
      "[1284/1762] D loss: 1.0611, G loss: 1.5198\n",
      "[1364/1762] D loss: 1.4737, G loss: 0.5454\n",
      "[1444/1762] D loss: 1.4146, G loss: 0.6694\n",
      "[1524/1762] D loss: 1.0432, G loss: 1.5066\n",
      "[1604/1762] D loss: 1.7382, G loss: 0.8567\n",
      "[1684/1762] D loss: 1.2874, G loss: 0.9387\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7000\n",
      "train error: \n",
      " D loss: 1.281056, G loss: 0.950281, D accuracy: 56.1%, cell accuracy: 99.6%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249156, G loss: 1.022466, D accuracy: 57.6%, cell accuracy: 99.6%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1344, G loss: 1.2755\n",
      "[84/1762] D loss: 0.8488, G loss: 2.3605\n",
      "[164/1762] D loss: 1.7755, G loss: 0.6181\n",
      "[244/1762] D loss: 1.4137, G loss: 0.7317\n",
      "[324/1762] D loss: 1.3412, G loss: 0.5417\n",
      "[404/1762] D loss: 1.1758, G loss: 1.5142\n",
      "[484/1762] D loss: 1.4177, G loss: 0.6773\n",
      "[564/1762] D loss: 1.3930, G loss: 0.6728\n",
      "[644/1762] D loss: 1.2017, G loss: 0.9414\n",
      "[724/1762] D loss: 1.4343, G loss: 0.9468\n",
      "[804/1762] D loss: 1.3902, G loss: 0.6933\n",
      "[884/1762] D loss: 1.3968, G loss: 0.6890\n",
      "[964/1762] D loss: 1.3893, G loss: 0.6802\n",
      "[1044/1762] D loss: 1.2671, G loss: 1.1136\n",
      "[1124/1762] D loss: 1.1739, G loss: 0.7854\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6780\n",
      "[1284/1762] D loss: 1.3996, G loss: 0.6153\n",
      "[1364/1762] D loss: 1.4042, G loss: 0.7098\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.7202\n",
      "[1524/1762] D loss: 1.3792, G loss: 0.7091\n",
      "[1604/1762] D loss: 1.4409, G loss: 1.1593\n",
      "[1684/1762] D loss: 1.1128, G loss: 1.0275\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.7045\n",
      "train error: \n",
      " D loss: 1.327396, G loss: 0.828278, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311604, G loss: 0.844391, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1423, G loss: 0.9668\n",
      "[84/1762] D loss: 1.4406, G loss: 0.6191\n",
      "[164/1762] D loss: 1.4021, G loss: 0.6498\n",
      "[244/1762] D loss: 0.9020, G loss: 1.6312\n",
      "[324/1762] D loss: 0.7895, G loss: 2.0696\n",
      "[404/1762] D loss: 0.9238, G loss: 1.5937\n",
      "[484/1762] D loss: 1.0012, G loss: 1.0786\n",
      "[564/1762] D loss: 1.4028, G loss: 0.6128\n",
      "[644/1762] D loss: 1.5370, G loss: 0.4149\n",
      "[724/1762] D loss: 1.4095, G loss: 0.8480\n",
      "[804/1762] D loss: 0.5809, G loss: 1.8238\n",
      "[884/1762] D loss: 1.3991, G loss: 0.8025\n",
      "[964/1762] D loss: 1.3239, G loss: 0.8154\n",
      "[1044/1762] D loss: 1.3475, G loss: 1.0962\n",
      "[1124/1762] D loss: 1.4356, G loss: 0.5949\n",
      "[1204/1762] D loss: 1.4462, G loss: 1.2893\n",
      "[1284/1762] D loss: 1.4014, G loss: 0.7732\n",
      "[1364/1762] D loss: 1.4296, G loss: 0.6075\n",
      "[1444/1762] D loss: 0.2397, G loss: 2.7551\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7039\n",
      "[1604/1762] D loss: 1.3428, G loss: 0.7194\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.8602\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.8300\n",
      "train error: \n",
      " D loss: 1.369574, G loss: 1.056272, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348515, G loss: 1.107404, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959, G loss: 0.7079\n",
      "[84/1762] D loss: 1.3794, G loss: 0.6917\n",
      "[164/1762] D loss: 0.1942, G loss: 2.4548\n",
      "[244/1762] D loss: 1.3724, G loss: 0.7148\n",
      "[324/1762] D loss: 1.1909, G loss: 0.9223\n",
      "[404/1762] D loss: 1.5207, G loss: 0.8457\n",
      "[484/1762] D loss: 1.3946, G loss: 0.6895\n",
      "[564/1762] D loss: 0.3303, G loss: 2.5906\n",
      "[644/1762] D loss: 1.3967, G loss: 0.7080\n",
      "[724/1762] D loss: 1.4112, G loss: 0.7659\n",
      "[804/1762] D loss: 1.4020, G loss: 0.7891\n",
      "[884/1762] D loss: 1.3946, G loss: 0.6933\n",
      "[964/1762] D loss: 1.4344, G loss: 0.7974\n",
      "[1044/1762] D loss: 0.2116, G loss: 2.7654\n",
      "[1124/1762] D loss: 0.3659, G loss: 2.2184\n",
      "[1204/1762] D loss: 0.2754, G loss: 2.3388\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.7095\n",
      "[1364/1762] D loss: 1.4055, G loss: 0.7731\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6952\n",
      "[1524/1762] D loss: 1.4026, G loss: 0.6626\n",
      "[1604/1762] D loss: 0.3851, G loss: 2.1338\n",
      "[1684/1762] D loss: 1.3985, G loss: 0.6716\n",
      "[1762/1762] D loss: 1.3950, G loss: 0.6243\n",
      "train error: \n",
      " D loss: 1.377616, G loss: 0.860405, D accuracy: 49.5%, cell accuracy: 99.3%, board accuracy: 67.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365095, G loss: 0.892117, D accuracy: 51.6%, cell accuracy: 99.1%, board accuracy: 64.3% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4256, G loss: 1.8347\n",
      "[84/1762] D loss: 1.5007, G loss: 0.6683\n",
      "[164/1762] D loss: 1.4147, G loss: 0.6229\n",
      "[244/1762] D loss: 0.0468, G loss: 4.0271\n",
      "[324/1762] D loss: 1.4260, G loss: 0.7138\n",
      "[404/1762] D loss: 1.3965, G loss: 0.6814\n",
      "[484/1762] D loss: 1.3526, G loss: 0.8835\n",
      "[564/1762] D loss: 1.3819, G loss: 0.6118\n",
      "[644/1762] D loss: 1.3941, G loss: 0.7244\n",
      "[724/1762] D loss: 0.0517, G loss: 3.7616\n",
      "[804/1762] D loss: 0.2523, G loss: 2.3957\n",
      "[884/1762] D loss: 1.4151, G loss: 0.6703\n",
      "[964/1762] D loss: 1.4019, G loss: 0.7340\n",
      "[1044/1762] D loss: 1.4000, G loss: 0.6931\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.7393\n",
      "[1204/1762] D loss: 1.3991, G loss: 0.6544\n",
      "[1284/1762] D loss: 1.3971, G loss: 0.6497\n",
      "[1364/1762] D loss: 1.3962, G loss: 0.7046\n",
      "[1444/1762] D loss: 0.4603, G loss: 2.0065\n",
      "[1524/1762] D loss: 1.4128, G loss: 0.7403\n",
      "[1604/1762] D loss: 1.4012, G loss: 0.5055\n",
      "[1684/1762] D loss: 1.4071, G loss: 0.7353\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.6876\n",
      "train error: \n",
      " D loss: 1.335189, G loss: 0.767031, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301211, G loss: 0.818700, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.6843\n",
      "[84/1762] D loss: 1.3879, G loss: 0.6982\n",
      "[164/1762] D loss: 0.3878, G loss: 2.1751\n",
      "[244/1762] D loss: 1.3922, G loss: 0.6942\n",
      "[324/1762] D loss: 1.3958, G loss: 0.7174\n",
      "[404/1762] D loss: 0.0603, G loss: 4.1879\n",
      "[484/1762] D loss: 1.4190, G loss: 0.6791\n",
      "[564/1762] D loss: 1.4286, G loss: 0.6646\n",
      "[644/1762] D loss: 1.4506, G loss: 0.5151\n",
      "[724/1762] D loss: 0.2824, G loss: 2.2961\n",
      "[804/1762] D loss: 1.4004, G loss: 0.7086\n",
      "[884/1762] D loss: 1.4245, G loss: 0.7083\n",
      "[964/1762] D loss: 1.4034, G loss: 0.7068\n",
      "[1044/1762] D loss: 1.4785, G loss: 0.6702\n",
      "[1124/1762] D loss: 1.4062, G loss: 0.7398\n",
      "[1204/1762] D loss: 1.3994, G loss: 0.7773\n",
      "[1284/1762] D loss: 1.1181, G loss: 0.8742\n",
      "[1364/1762] D loss: 1.4508, G loss: 0.6108\n",
      "[1444/1762] D loss: 1.4841, G loss: 0.6030\n",
      "[1524/1762] D loss: 1.5416, G loss: 0.4857\n",
      "[1604/1762] D loss: 1.0562, G loss: 1.5661\n",
      "[1684/1762] D loss: 1.4064, G loss: 0.7966\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.6737\n",
      "train error: \n",
      " D loss: 1.345025, G loss: 0.713755, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326424, G loss: 0.774032, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4063, G loss: 0.7865\n",
      "[84/1762] D loss: 0.1913, G loss: 2.5951\n",
      "[164/1762] D loss: 1.4571, G loss: 0.5851\n",
      "[244/1762] D loss: 1.4373, G loss: 0.7046\n",
      "[324/1762] D loss: 1.3934, G loss: 0.6937\n",
      "[404/1762] D loss: 1.4043, G loss: 0.6723\n",
      "[484/1762] D loss: 1.3968, G loss: 0.6714\n",
      "[564/1762] D loss: 0.3881, G loss: 2.0475\n",
      "[644/1762] D loss: 1.4298, G loss: 0.6995\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6897\n",
      "[804/1762] D loss: 1.0958, G loss: 0.7411\n",
      "[884/1762] D loss: 1.4047, G loss: 0.7911\n",
      "[964/1762] D loss: 1.4131, G loss: 0.7338\n",
      "[1044/1762] D loss: 1.3980, G loss: 0.7084\n",
      "[1124/1762] D loss: 1.2915, G loss: 0.9127\n",
      "[1204/1762] D loss: 1.5190, G loss: 0.8892\n",
      "[1284/1762] D loss: 1.4194, G loss: 0.7272\n",
      "[1364/1762] D loss: 1.4148, G loss: 0.6600\n",
      "[1444/1762] D loss: 1.3943, G loss: 0.7308\n",
      "[1524/1762] D loss: 1.2830, G loss: 0.7738\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.7148\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.6385\n",
      "[1762/1762] D loss: 1.4194, G loss: 0.6728\n",
      "train error: \n",
      " D loss: 1.372790, G loss: 1.092168, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352685, G loss: 1.165253, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5044, G loss: 0.7082\n",
      "[84/1762] D loss: 1.4116, G loss: 0.6988\n",
      "[164/1762] D loss: 1.4382, G loss: 0.7469\n",
      "[244/1762] D loss: 1.4814, G loss: 0.8082\n",
      "[324/1762] D loss: 1.0635, G loss: 0.9570\n",
      "[404/1762] D loss: 1.4812, G loss: 0.6250\n",
      "[484/1762] D loss: 1.3902, G loss: 0.6953\n",
      "[564/1762] D loss: 1.3812, G loss: 0.6772\n",
      "[644/1762] D loss: 1.3905, G loss: 0.7360\n",
      "[724/1762] D loss: 1.3948, G loss: 0.6753\n",
      "[804/1762] D loss: 1.1745, G loss: 1.2276\n",
      "[884/1762] D loss: 1.3918, G loss: 0.6513\n",
      "[964/1762] D loss: 1.3892, G loss: 1.1825\n",
      "[1044/1762] D loss: 1.3316, G loss: 1.0036\n",
      "[1124/1762] D loss: 1.4055, G loss: 0.6980\n",
      "[1204/1762] D loss: 1.4212, G loss: 0.6909\n",
      "[1284/1762] D loss: 0.7905, G loss: 1.5621\n",
      "[1364/1762] D loss: 1.4157, G loss: 0.7390\n",
      "[1444/1762] D loss: 1.2578, G loss: 0.7913\n",
      "[1524/1762] D loss: 1.1072, G loss: 1.1615\n",
      "[1604/1762] D loss: 1.0953, G loss: 1.0911\n",
      "[1684/1762] D loss: 1.0973, G loss: 1.3414\n",
      "[1762/1762] D loss: 1.3964, G loss: 0.6694\n",
      "train error: \n",
      " D loss: 1.347147, G loss: 0.752819, D accuracy: 52.3%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337912, G loss: 0.753342, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3316, G loss: 0.8396\n",
      "[84/1762] D loss: 1.3972, G loss: 0.6870\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6974\n",
      "[244/1762] D loss: 1.3985, G loss: 0.6824\n",
      "[324/1762] D loss: 1.3921, G loss: 0.7042\n",
      "[404/1762] D loss: 1.3994, G loss: 0.7861\n",
      "[484/1762] D loss: 1.3931, G loss: 0.6978\n",
      "[564/1762] D loss: 1.3917, G loss: 0.6708\n",
      "[644/1762] D loss: 0.9651, G loss: 1.0052\n",
      "[724/1762] D loss: 0.7600, G loss: 2.3692\n",
      "[804/1762] D loss: 1.4064, G loss: 0.7093\n",
      "[884/1762] D loss: 0.9201, G loss: 1.2334\n",
      "[964/1762] D loss: 0.8649, G loss: 1.2548\n",
      "[1044/1762] D loss: 1.4089, G loss: 0.6521\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.6935\n",
      "[1204/1762] D loss: 1.1477, G loss: 1.5348\n",
      "[1284/1762] D loss: 1.2258, G loss: 0.6217\n",
      "[1364/1762] D loss: 1.3972, G loss: 0.6080\n",
      "[1444/1762] D loss: 1.0030, G loss: 2.0488\n",
      "[1524/1762] D loss: 1.2994, G loss: 0.8422\n",
      "[1604/1762] D loss: 0.4284, G loss: 2.3491\n",
      "[1684/1762] D loss: 0.1730, G loss: 2.9926\n",
      "[1762/1762] D loss: 0.3725, G loss: 2.4209\n",
      "train error: \n",
      " D loss: 1.486356, G loss: 2.914712, D accuracy: 51.7%, cell accuracy: 97.4%, board accuracy: 23.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.473442, G loss: 3.068711, D accuracy: 51.8%, cell accuracy: 97.3%, board accuracy: 20.5% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2665, G loss: 2.8338\n",
      "[84/1762] D loss: 0.1480, G loss: 3.2698\n",
      "[164/1762] D loss: 1.1996, G loss: 0.8514\n",
      "[244/1762] D loss: 1.4408, G loss: 0.6309\n",
      "[324/1762] D loss: 1.4597, G loss: 0.5258\n",
      "[404/1762] D loss: 1.5763, G loss: 0.4614\n",
      "[484/1762] D loss: 1.4324, G loss: 0.8144\n",
      "[564/1762] D loss: 1.3750, G loss: 0.7577\n",
      "[644/1762] D loss: 1.6738, G loss: 0.7526\n",
      "[724/1762] D loss: 1.3845, G loss: 0.7167\n",
      "[804/1762] D loss: 0.5474, G loss: 1.9373\n",
      "[884/1762] D loss: 1.4551, G loss: 0.5806\n",
      "[964/1762] D loss: 1.4324, G loss: 0.8336\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6543\n",
      "[1124/1762] D loss: 1.3837, G loss: 0.6826\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.6822\n",
      "[1284/1762] D loss: 1.2319, G loss: 0.8283\n",
      "[1364/1762] D loss: 0.2174, G loss: 2.7329\n",
      "[1444/1762] D loss: 0.2898, G loss: 2.4168\n",
      "[1524/1762] D loss: 1.4296, G loss: 0.6300\n",
      "[1604/1762] D loss: 0.0544, G loss: 3.6499\n",
      "[1684/1762] D loss: 1.6222, G loss: 0.2732\n",
      "[1762/1762] D loss: 1.6206, G loss: 0.2774\n",
      "train error: \n",
      " D loss: 1.339088, G loss: 0.735886, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312229, G loss: 0.796415, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5567, G loss: 0.8473\n",
      "[84/1762] D loss: 1.4977, G loss: 0.6485\n",
      "[164/1762] D loss: 0.2558, G loss: 2.3659\n",
      "[244/1762] D loss: 1.4463, G loss: 0.6024\n",
      "[324/1762] D loss: 0.1637, G loss: 2.7512\n",
      "[404/1762] D loss: 0.3631, G loss: 2.7333\n",
      "[484/1762] D loss: 1.4407, G loss: 0.6204\n",
      "[564/1762] D loss: 0.0826, G loss: 3.6817\n",
      "[644/1762] D loss: 1.4549, G loss: 0.5416\n",
      "[724/1762] D loss: 1.5341, G loss: 0.5573\n",
      "[804/1762] D loss: 1.4321, G loss: 0.7051\n",
      "[884/1762] D loss: 0.1365, G loss: 3.0964\n",
      "[964/1762] D loss: 1.4131, G loss: 0.7705\n",
      "[1044/1762] D loss: 0.8433, G loss: 1.5608\n",
      "[1124/1762] D loss: 1.4498, G loss: 0.6609\n",
      "[1204/1762] D loss: 1.4432, G loss: 0.6167\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.6790\n",
      "[1364/1762] D loss: 1.4380, G loss: 0.8875\n",
      "[1444/1762] D loss: 1.4206, G loss: 0.7561\n",
      "[1524/1762] D loss: 1.3496, G loss: 0.7094\n",
      "[1604/1762] D loss: 1.4062, G loss: 0.6797\n",
      "[1684/1762] D loss: 1.4028, G loss: 0.6611\n",
      "[1762/1762] D loss: 1.3946, G loss: 0.6580\n",
      "train error: \n",
      " D loss: 1.372161, G loss: 0.638066, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349840, G loss: 0.674880, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4034, G loss: 0.6805\n",
      "[84/1762] D loss: 1.4709, G loss: 0.6310\n",
      "[164/1762] D loss: 1.3958, G loss: 0.7082\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7281\n",
      "[324/1762] D loss: 1.5012, G loss: 0.4532\n",
      "[404/1762] D loss: 1.3988, G loss: 0.6880\n",
      "[484/1762] D loss: 1.4455, G loss: 0.7909\n",
      "[564/1762] D loss: 0.2662, G loss: 2.6884\n",
      "[644/1762] D loss: 1.3825, G loss: 0.7030\n",
      "[724/1762] D loss: 1.4101, G loss: 0.6648\n",
      "[804/1762] D loss: 1.4184, G loss: 0.6828\n",
      "[884/1762] D loss: 1.4055, G loss: 0.7380\n",
      "[964/1762] D loss: 1.4841, G loss: 0.6588\n",
      "[1044/1762] D loss: 1.3842, G loss: 0.7007\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.6878\n",
      "[1204/1762] D loss: 0.2214, G loss: 2.9224\n",
      "[1284/1762] D loss: 1.4058, G loss: 0.6133\n",
      "[1364/1762] D loss: 1.4434, G loss: 0.7593\n",
      "[1444/1762] D loss: 1.4101, G loss: 0.7238\n",
      "[1524/1762] D loss: 0.1332, G loss: 2.8034\n",
      "[1604/1762] D loss: 1.3921, G loss: 0.6910\n",
      "[1684/1762] D loss: 1.3975, G loss: 0.7025\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.7053\n",
      "train error: \n",
      " D loss: 1.312306, G loss: 0.834711, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280364, G loss: 0.959497, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3481, G loss: 1.0080\n",
      "[84/1762] D loss: 1.4513, G loss: 0.6826\n",
      "[164/1762] D loss: 1.3908, G loss: 0.6777\n",
      "[244/1762] D loss: 1.4015, G loss: 0.6557\n",
      "[324/1762] D loss: 0.1839, G loss: 3.2702\n",
      "[404/1762] D loss: 1.3970, G loss: 0.7277\n",
      "[484/1762] D loss: 1.4800, G loss: 0.6748\n",
      "[564/1762] D loss: 1.3910, G loss: 0.6763\n",
      "[644/1762] D loss: 1.4781, G loss: 0.7784\n",
      "[724/1762] D loss: 1.3998, G loss: 0.7752\n",
      "[804/1762] D loss: 0.2348, G loss: 3.0480\n",
      "[884/1762] D loss: 0.1387, G loss: 3.5117\n",
      "[964/1762] D loss: 1.3827, G loss: 0.7365\n",
      "[1044/1762] D loss: 1.3828, G loss: 0.7109\n",
      "[1124/1762] D loss: 1.4153, G loss: 0.6750\n",
      "[1204/1762] D loss: 1.5873, G loss: 0.5135\n",
      "[1284/1762] D loss: 1.4154, G loss: 0.6782\n",
      "[1364/1762] D loss: 1.1571, G loss: 1.1774\n",
      "[1444/1762] D loss: 0.2989, G loss: 2.2389\n",
      "[1524/1762] D loss: 1.4016, G loss: 0.6115\n",
      "[1604/1762] D loss: 1.4041, G loss: 0.7765\n",
      "[1684/1762] D loss: 1.3963, G loss: 0.6790\n",
      "[1762/1762] D loss: 1.4370, G loss: 0.6004\n",
      "train error: \n",
      " D loss: 1.330160, G loss: 0.837813, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324606, G loss: 0.865720, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4324, G loss: 0.7354\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6988\n",
      "[164/1762] D loss: 1.4915, G loss: 0.8341\n",
      "[244/1762] D loss: 1.3043, G loss: 0.7950\n",
      "[324/1762] D loss: 1.3979, G loss: 0.7862\n",
      "[404/1762] D loss: 1.4085, G loss: 0.6128\n",
      "[484/1762] D loss: 0.1666, G loss: 2.8388\n",
      "[564/1762] D loss: 0.3123, G loss: 2.9224\n",
      "[644/1762] D loss: 1.4072, G loss: 0.7183\n",
      "[724/1762] D loss: 0.2038, G loss: 3.2455\n",
      "[804/1762] D loss: 1.1619, G loss: 0.6562\n",
      "[884/1762] D loss: 1.4115, G loss: 0.6303\n",
      "[964/1762] D loss: 1.3891, G loss: 0.8140\n",
      "[1044/1762] D loss: 1.4451, G loss: 0.8712\n",
      "[1124/1762] D loss: 1.3937, G loss: 0.7020\n",
      "[1204/1762] D loss: 1.3971, G loss: 0.6975\n",
      "[1284/1762] D loss: 0.0699, G loss: 3.6268\n",
      "[1364/1762] D loss: 1.2352, G loss: 0.8538\n",
      "[1444/1762] D loss: 1.4039, G loss: 0.7381\n",
      "[1524/1762] D loss: 1.4147, G loss: 0.7970\n",
      "[1604/1762] D loss: 1.3922, G loss: 0.6483\n",
      "[1684/1762] D loss: 0.2208, G loss: 2.9090\n",
      "[1762/1762] D loss: 1.4128, G loss: 1.3056\n",
      "train error: \n",
      " D loss: 1.320306, G loss: 0.880778, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291279, G loss: 0.984306, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4073, G loss: 0.6069\n",
      "[84/1762] D loss: 1.3989, G loss: 0.6717\n",
      "[164/1762] D loss: 0.1571, G loss: 2.9979\n",
      "[244/1762] D loss: 1.4370, G loss: 0.9111\n",
      "[324/1762] D loss: 0.4091, G loss: 2.2785\n",
      "[404/1762] D loss: 1.4367, G loss: 0.5789\n",
      "[484/1762] D loss: 1.4009, G loss: 0.6372\n",
      "[564/1762] D loss: 1.2279, G loss: 0.7369\n",
      "[644/1762] D loss: 0.2044, G loss: 4.2037\n",
      "[724/1762] D loss: 1.4872, G loss: 0.9150\n",
      "[804/1762] D loss: 0.2379, G loss: 2.6228\n",
      "[884/1762] D loss: 1.4765, G loss: 0.6019\n",
      "[964/1762] D loss: 1.4009, G loss: 0.7075\n",
      "[1044/1762] D loss: 1.4187, G loss: 0.6516\n",
      "[1124/1762] D loss: 1.3998, G loss: 0.7945\n",
      "[1204/1762] D loss: 1.3971, G loss: 0.7021\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6743\n",
      "[1364/1762] D loss: 1.4009, G loss: 0.7022\n",
      "[1444/1762] D loss: 0.3121, G loss: 2.6892\n",
      "[1524/1762] D loss: 1.4380, G loss: 0.7616\n",
      "[1604/1762] D loss: 1.4040, G loss: 0.6434\n",
      "[1684/1762] D loss: 0.2573, G loss: 2.4865\n",
      "[1762/1762] D loss: 0.7250, G loss: 2.1447\n",
      "train error: \n",
      " D loss: 1.948671, G loss: 3.304524, D accuracy: 53.2%, cell accuracy: 95.6%, board accuracy: 21.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.920929, G loss: 3.336236, D accuracy: 53.8%, cell accuracy: 95.4%, board accuracy: 21.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3745, G loss: 3.1664\n",
      "[84/1762] D loss: 0.0776, G loss: 3.5824\n",
      "[164/1762] D loss: 0.2190, G loss: 3.2162\n",
      "[244/1762] D loss: 0.1159, G loss: 3.0539\n",
      "[324/1762] D loss: 3.1596, G loss: 0.5567\n",
      "[404/1762] D loss: 1.4297, G loss: 0.5680\n",
      "[484/1762] D loss: 1.4676, G loss: 0.8748\n",
      "[564/1762] D loss: 1.4939, G loss: 0.6589\n",
      "[644/1762] D loss: 0.3133, G loss: 2.2644\n",
      "[724/1762] D loss: 1.3792, G loss: 0.7431\n",
      "[804/1762] D loss: 0.1265, G loss: 2.7485\n",
      "[884/1762] D loss: 1.4295, G loss: 0.6925\n",
      "[964/1762] D loss: 1.4044, G loss: 0.6399\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.6971\n",
      "[1124/1762] D loss: 1.2338, G loss: 0.8803\n",
      "[1204/1762] D loss: 0.1772, G loss: 2.6352\n",
      "[1284/1762] D loss: 0.2167, G loss: 2.6585\n",
      "[1364/1762] D loss: 1.4381, G loss: 0.5854\n",
      "[1444/1762] D loss: 1.4015, G loss: 0.6235\n",
      "[1524/1762] D loss: 1.4529, G loss: 0.5788\n",
      "[1604/1762] D loss: 1.4387, G loss: 0.8056\n",
      "[1684/1762] D loss: 1.3959, G loss: 0.7061\n",
      "[1762/1762] D loss: 1.5114, G loss: 0.5700\n",
      "train error: \n",
      " D loss: 1.322434, G loss: 0.808229, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298517, G loss: 0.886128, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2783, G loss: 2.2479\n",
      "[84/1762] D loss: 1.3965, G loss: 0.7145\n",
      "[164/1762] D loss: 1.3925, G loss: 0.7199\n",
      "[244/1762] D loss: 0.0681, G loss: 4.2093\n",
      "[324/1762] D loss: 1.3919, G loss: 0.7509\n",
      "[404/1762] D loss: 1.4024, G loss: 0.7073\n",
      "[484/1762] D loss: 1.3454, G loss: 1.1481\n",
      "[564/1762] D loss: 1.3953, G loss: 0.7253\n",
      "[644/1762] D loss: 0.1726, G loss: 2.5480\n",
      "[724/1762] D loss: 1.4039, G loss: 0.6606\n",
      "[804/1762] D loss: 1.3940, G loss: 0.6992\n",
      "[884/1762] D loss: 1.4175, G loss: 0.6761\n",
      "[964/1762] D loss: 1.4697, G loss: 0.6060\n",
      "[1044/1762] D loss: 0.1973, G loss: 3.4788\n",
      "[1124/1762] D loss: 1.4147, G loss: 0.6521\n",
      "[1204/1762] D loss: 1.4129, G loss: 0.6988\n",
      "[1284/1762] D loss: 1.4074, G loss: 0.7022\n",
      "[1364/1762] D loss: 0.2220, G loss: 3.0971\n",
      "[1444/1762] D loss: 1.4302, G loss: 0.6970\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.7025\n",
      "[1604/1762] D loss: 0.8782, G loss: 1.6029\n",
      "[1684/1762] D loss: 1.3422, G loss: 0.7505\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.7053\n",
      "train error: \n",
      " D loss: 1.349897, G loss: 0.805007, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354058, G loss: 0.886518, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4410, G loss: 0.5878\n",
      "[84/1762] D loss: 1.3482, G loss: 0.6974\n",
      "[164/1762] D loss: 1.3942, G loss: 0.6903\n",
      "[244/1762] D loss: 0.1022, G loss: 3.2810\n",
      "[324/1762] D loss: 0.1883, G loss: 2.9832\n",
      "[404/1762] D loss: 0.5879, G loss: 1.8033\n",
      "[484/1762] D loss: 1.4393, G loss: 0.6610\n",
      "[564/1762] D loss: 1.4357, G loss: 0.5887\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6895\n",
      "[724/1762] D loss: 1.4139, G loss: 0.6427\n",
      "[804/1762] D loss: 0.1348, G loss: 3.3317\n",
      "[884/1762] D loss: 1.4605, G loss: 0.6594\n",
      "[964/1762] D loss: 1.4334, G loss: 0.7304\n",
      "[1044/1762] D loss: 1.4732, G loss: 0.6106\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.6998\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.6645\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7093\n",
      "[1364/1762] D loss: 1.4300, G loss: 0.6479\n",
      "[1444/1762] D loss: 0.2205, G loss: 2.6222\n",
      "[1524/1762] D loss: 0.1776, G loss: 3.0058\n",
      "[1604/1762] D loss: 0.1506, G loss: 2.7730\n",
      "[1684/1762] D loss: 1.4007, G loss: 0.6694\n",
      "[1762/1762] D loss: 0.0097, G loss: 5.1918\n",
      "train error: \n",
      " D loss: 0.909674, G loss: 1.806482, D accuracy: 79.8%, cell accuracy: 98.4%, board accuracy: 21.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.845735, G loss: 1.947715, D accuracy: 82.4%, cell accuracy: 98.2%, board accuracy: 19.5% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0453, G loss: 3.7751\n",
      "[84/1762] D loss: 0.9118, G loss: 2.2793\n",
      "[164/1762] D loss: 1.2065, G loss: 0.7727\n",
      "[244/1762] D loss: 1.9325, G loss: 0.9077\n",
      "[324/1762] D loss: 0.0728, G loss: 3.9656\n",
      "[404/1762] D loss: 1.0168, G loss: 1.5884\n",
      "[484/1762] D loss: 0.1707, G loss: 3.0296\n",
      "[564/1762] D loss: 1.3827, G loss: 0.6520\n",
      "[644/1762] D loss: 0.1654, G loss: 2.9933\n",
      "[724/1762] D loss: 0.1564, G loss: 3.0176\n",
      "[804/1762] D loss: 1.2978, G loss: 0.8734\n",
      "[884/1762] D loss: 0.4962, G loss: 2.1281\n",
      "[964/1762] D loss: 1.3018, G loss: 0.7197\n",
      "[1044/1762] D loss: 1.4321, G loss: 0.6382\n",
      "[1124/1762] D loss: 0.1532, G loss: 3.3341\n",
      "[1204/1762] D loss: 1.4405, G loss: 0.6642\n",
      "[1284/1762] D loss: 1.3927, G loss: 0.7071\n",
      "[1364/1762] D loss: 1.4298, G loss: 0.6771\n",
      "[1444/1762] D loss: 1.4433, G loss: 0.6586\n",
      "[1524/1762] D loss: 1.3992, G loss: 0.6708\n",
      "[1604/1762] D loss: 0.1875, G loss: 2.8993\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.6931\n",
      "[1762/1762] D loss: 1.3923, G loss: 0.6497\n",
      "train error: \n",
      " D loss: 1.378265, G loss: 0.724738, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343026, G loss: 0.840717, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3954, G loss: 0.6952\n",
      "[84/1762] D loss: 1.5369, G loss: 0.6194\n",
      "[164/1762] D loss: 1.3901, G loss: 0.6674\n",
      "[244/1762] D loss: 1.3886, G loss: 0.6809\n",
      "[324/1762] D loss: 1.4186, G loss: 0.6678\n",
      "[404/1762] D loss: 1.3923, G loss: 0.6799\n",
      "[484/1762] D loss: 1.3948, G loss: 0.6726\n",
      "[564/1762] D loss: 1.4023, G loss: 0.6916\n",
      "[644/1762] D loss: 1.3982, G loss: 0.7030\n",
      "[724/1762] D loss: 0.1070, G loss: 3.5702\n",
      "[804/1762] D loss: 0.0593, G loss: 3.5005\n",
      "[884/1762] D loss: 1.4469, G loss: 0.7137\n",
      "[964/1762] D loss: 0.0621, G loss: 3.7368\n",
      "[1044/1762] D loss: 1.5264, G loss: 0.5068\n",
      "[1124/1762] D loss: 0.1991, G loss: 2.5098\n",
      "[1204/1762] D loss: 1.3237, G loss: 1.4795\n",
      "[1284/1762] D loss: 1.4045, G loss: 0.6725\n",
      "[1364/1762] D loss: 1.3919, G loss: 0.6959\n",
      "[1444/1762] D loss: 0.0933, G loss: 3.1165\n",
      "[1524/1762] D loss: 1.5688, G loss: 0.4212\n",
      "[1604/1762] D loss: 1.4320, G loss: 0.7240\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.7340\n",
      "[1762/1762] D loss: 1.5056, G loss: 0.5053\n",
      "train error: \n",
      " D loss: 1.543276, G loss: 0.581174, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.510979, G loss: 0.604495, D accuracy: 56.4%, cell accuracy: 99.5%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2199, G loss: 0.8951\n",
      "[84/1762] D loss: 1.3787, G loss: 0.7329\n",
      "[164/1762] D loss: 0.0227, G loss: 4.3816\n",
      "[244/1762] D loss: 1.3979, G loss: 0.7136\n",
      "[324/1762] D loss: 1.3930, G loss: 0.6950\n",
      "[404/1762] D loss: 1.4912, G loss: 0.3719\n",
      "[484/1762] D loss: 1.3938, G loss: 0.7076\n",
      "[564/1762] D loss: 0.1203, G loss: 3.5558\n",
      "[644/1762] D loss: 0.0832, G loss: 4.6322\n",
      "[724/1762] D loss: 1.5319, G loss: 0.7257\n",
      "[804/1762] D loss: 1.3176, G loss: 1.1677\n",
      "[884/1762] D loss: 1.4129, G loss: 0.6606\n",
      "[964/1762] D loss: 1.3225, G loss: 0.8914\n",
      "[1044/1762] D loss: 0.0994, G loss: 3.7039\n",
      "[1124/1762] D loss: 1.4141, G loss: 0.7021\n",
      "[1204/1762] D loss: 1.3946, G loss: 0.6872\n",
      "[1284/1762] D loss: 1.4381, G loss: 0.6594\n",
      "[1364/1762] D loss: 0.1515, G loss: 2.6391\n",
      "[1444/1762] D loss: 1.4008, G loss: 0.6805\n",
      "[1524/1762] D loss: 1.3928, G loss: 0.7815\n",
      "[1604/1762] D loss: 1.4150, G loss: 0.7061\n",
      "[1684/1762] D loss: 1.4161, G loss: 0.6807\n",
      "[1762/1762] D loss: 1.4308, G loss: 0.5063\n",
      "train error: \n",
      " D loss: 1.327381, G loss: 0.920813, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300746, G loss: 0.994611, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2088, G loss: 3.0391\n",
      "[84/1762] D loss: 1.5539, G loss: 0.7778\n",
      "[164/1762] D loss: 1.4330, G loss: 0.6671\n",
      "[244/1762] D loss: 0.0050, G loss: 6.0877\n",
      "[324/1762] D loss: 0.0828, G loss: 3.5736\n",
      "[404/1762] D loss: 1.4013, G loss: 0.7075\n",
      "[484/1762] D loss: 1.4936, G loss: 0.6058\n",
      "[564/1762] D loss: 0.1566, G loss: 3.7213\n",
      "[644/1762] D loss: 1.3979, G loss: 0.6986\n",
      "[724/1762] D loss: 1.3874, G loss: 0.7092\n",
      "[804/1762] D loss: 1.3911, G loss: 0.7098\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6880\n",
      "[964/1762] D loss: 1.3855, G loss: 0.7012\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6835\n",
      "[1124/1762] D loss: 1.4052, G loss: 0.6709\n",
      "[1204/1762] D loss: 1.3991, G loss: 0.7009\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.6865\n",
      "[1364/1762] D loss: 1.4028, G loss: 0.7028\n",
      "[1444/1762] D loss: 1.3937, G loss: 0.6963\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.7091\n",
      "[1604/1762] D loss: 1.9075, G loss: 0.3763\n",
      "[1684/1762] D loss: 1.3897, G loss: 0.6801\n",
      "[1762/1762] D loss: 1.4399, G loss: 0.6472\n",
      "train error: \n",
      " D loss: 1.308687, G loss: 0.959024, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286064, G loss: 1.040194, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[84/1762] D loss: 1.3910, G loss: 0.6884\n",
      "[164/1762] D loss: 0.1158, G loss: 3.2460\n",
      "[244/1762] D loss: 1.4048, G loss: 0.6922\n",
      "[324/1762] D loss: 1.4148, G loss: 0.7013\n",
      "[404/1762] D loss: 1.3914, G loss: 0.6641\n",
      "[484/1762] D loss: 1.3931, G loss: 0.6864\n",
      "[564/1762] D loss: 1.3896, G loss: 0.6958\n",
      "[644/1762] D loss: 1.4119, G loss: 0.8617\n",
      "[724/1762] D loss: 0.1785, G loss: 3.4727\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6778\n",
      "[884/1762] D loss: 1.3926, G loss: 0.6957\n",
      "[964/1762] D loss: 1.3905, G loss: 0.6923\n",
      "[1044/1762] D loss: 1.4046, G loss: 0.6899\n",
      "[1124/1762] D loss: 1.3940, G loss: 0.6893\n",
      "[1204/1762] D loss: 1.3982, G loss: 0.7150\n",
      "[1284/1762] D loss: 1.4029, G loss: 0.6840\n",
      "[1364/1762] D loss: 1.4047, G loss: 0.6874\n",
      "[1444/1762] D loss: 1.2438, G loss: 0.8943\n",
      "[1524/1762] D loss: 0.7151, G loss: 2.5183\n",
      "[1604/1762] D loss: 1.4225, G loss: 0.6920\n",
      "[1684/1762] D loss: 1.3957, G loss: 0.7088\n",
      "[1762/1762] D loss: 1.5150, G loss: 0.6708\n",
      "train error: \n",
      " D loss: 1.373895, G loss: 1.132540, D accuracy: 53.0%, cell accuracy: 99.5%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368648, G loss: 1.103214, D accuracy: 53.4%, cell accuracy: 99.3%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1738, G loss: 2.6026\n",
      "[84/1762] D loss: 1.3212, G loss: 0.7708\n",
      "[164/1762] D loss: 1.4705, G loss: 0.6860\n",
      "[244/1762] D loss: 0.1503, G loss: 2.6038\n",
      "[324/1762] D loss: 1.4283, G loss: 0.6426\n",
      "[404/1762] D loss: 1.3801, G loss: 0.6948\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6893\n",
      "[564/1762] D loss: 0.0272, G loss: 5.4313\n",
      "[644/1762] D loss: 1.4240, G loss: 0.6480\n",
      "[724/1762] D loss: 1.2008, G loss: 0.9531\n",
      "[804/1762] D loss: 1.3994, G loss: 0.7035\n",
      "[884/1762] D loss: 1.3773, G loss: 0.7030\n",
      "[964/1762] D loss: 0.0961, G loss: 3.5639\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6941\n",
      "[1204/1762] D loss: 0.1382, G loss: 3.3343\n",
      "[1284/1762] D loss: 1.3858, G loss: 0.6930\n",
      "[1364/1762] D loss: 0.2072, G loss: 3.4051\n",
      "[1444/1762] D loss: 0.8404, G loss: 3.1324\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.6852\n",
      "[1604/1762] D loss: 1.4268, G loss: 0.6772\n",
      "[1684/1762] D loss: 1.3941, G loss: 0.7120\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.6777\n",
      "train error: \n",
      " D loss: 1.308721, G loss: 0.962187, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279624, G loss: 1.069358, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4048, G loss: 0.6545\n",
      "[84/1762] D loss: 0.1111, G loss: 3.5166\n",
      "[164/1762] D loss: 1.3936, G loss: 0.6957\n",
      "[244/1762] D loss: 0.1462, G loss: 4.2241\n",
      "[324/1762] D loss: 1.5570, G loss: 0.9205\n",
      "[404/1762] D loss: 1.3964, G loss: 0.6786\n",
      "[484/1762] D loss: 0.1514, G loss: 4.0991\n",
      "[564/1762] D loss: 0.1878, G loss: 3.7046\n",
      "[644/1762] D loss: 0.1654, G loss: 3.6336\n",
      "[724/1762] D loss: 0.3570, G loss: 4.0347\n",
      "[804/1762] D loss: 1.4122, G loss: 0.6966\n",
      "[884/1762] D loss: 0.1792, G loss: 3.4984\n",
      "[964/1762] D loss: 1.4228, G loss: 0.6961\n",
      "[1044/1762] D loss: 1.3950, G loss: 0.6656\n",
      "[1124/1762] D loss: 1.3989, G loss: 0.6821\n",
      "[1204/1762] D loss: 1.4276, G loss: 0.6707\n",
      "[1284/1762] D loss: 0.0986, G loss: 3.6892\n",
      "[1364/1762] D loss: 1.4053, G loss: 0.6301\n",
      "[1444/1762] D loss: 1.4318, G loss: 0.5438\n",
      "[1524/1762] D loss: 0.0958, G loss: 3.6902\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.6783\n",
      "[1684/1762] D loss: 1.4004, G loss: 0.7009\n",
      "[1762/1762] D loss: 0.0815, G loss: 3.5493\n",
      "train error: \n",
      " D loss: 2.073498, G loss: 0.315498, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.032869, G loss: 0.343092, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4832, G loss: 0.5685\n",
      "[84/1762] D loss: 1.3914, G loss: 0.7019\n",
      "[164/1762] D loss: 0.9248, G loss: 2.2081\n",
      "[244/1762] D loss: 1.3986, G loss: 0.6982\n",
      "[324/1762] D loss: 1.3928, G loss: 0.6851\n",
      "[404/1762] D loss: 0.1109, G loss: 3.7699\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6963\n",
      "[564/1762] D loss: 1.1818, G loss: 1.0782\n",
      "[644/1762] D loss: 1.4009, G loss: 0.6725\n",
      "[724/1762] D loss: 0.0495, G loss: 4.1959\n",
      "[804/1762] D loss: 1.3935, G loss: 0.7287\n",
      "[884/1762] D loss: 0.1146, G loss: 3.1692\n",
      "[964/1762] D loss: 0.0616, G loss: 3.4082\n",
      "[1044/1762] D loss: 1.4073, G loss: 0.6764\n",
      "[1124/1762] D loss: 1.4253, G loss: 0.7049\n",
      "[1204/1762] D loss: 1.3927, G loss: 0.6934\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6912\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6958\n",
      "[1444/1762] D loss: 1.1943, G loss: 0.8587\n",
      "[1524/1762] D loss: 0.0563, G loss: 4.2127\n",
      "[1604/1762] D loss: 0.1922, G loss: 3.0478\n",
      "[1684/1762] D loss: 1.3925, G loss: 0.6957\n",
      "[1762/1762] D loss: 1.3939, G loss: 0.7135\n",
      "train error: \n",
      " D loss: 1.297354, G loss: 1.065623, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272515, G loss: 1.182493, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4024, G loss: 0.6636\n",
      "[84/1762] D loss: 1.3938, G loss: 0.6918\n",
      "[164/1762] D loss: 1.6047, G loss: 0.4644\n",
      "[244/1762] D loss: 1.4033, G loss: 0.6867\n",
      "[324/1762] D loss: 1.4262, G loss: 0.5071\n",
      "[404/1762] D loss: 1.3988, G loss: 0.8443\n",
      "[484/1762] D loss: 1.3921, G loss: 0.6890\n",
      "[564/1762] D loss: 1.3891, G loss: 0.6949\n",
      "[644/1762] D loss: 0.0673, G loss: 3.9010\n",
      "[724/1762] D loss: 1.3908, G loss: 0.6903\n",
      "[804/1762] D loss: 1.4268, G loss: 0.7105\n",
      "[884/1762] D loss: 0.0055, G loss: 6.4679\n",
      "[964/1762] D loss: 1.4130, G loss: 0.6377\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.6976\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.6610\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6997\n",
      "[1284/1762] D loss: 1.4118, G loss: 0.6254\n",
      "[1364/1762] D loss: 1.1905, G loss: 1.2751\n",
      "[1444/1762] D loss: 0.0780, G loss: 3.6134\n",
      "[1524/1762] D loss: 1.4205, G loss: 0.6577\n",
      "[1604/1762] D loss: 0.1086, G loss: 4.0244\n",
      "[1684/1762] D loss: 1.4088, G loss: 0.6709\n",
      "[1762/1762] D loss: 1.3937, G loss: 0.7037\n",
      "train error: \n",
      " D loss: 1.337551, G loss: 0.759721, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308019, G loss: 0.843780, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4024, G loss: 0.7071\n",
      "[84/1762] D loss: 1.4004, G loss: 0.7142\n",
      "[164/1762] D loss: 0.0910, G loss: 3.1980\n",
      "[244/1762] D loss: 1.4112, G loss: 0.6709\n",
      "[324/1762] D loss: 0.2163, G loss: 4.5722\n",
      "[404/1762] D loss: 0.1344, G loss: 4.6243\n",
      "[484/1762] D loss: 0.0436, G loss: 5.9461\n",
      "[564/1762] D loss: 0.0103, G loss: 5.4590\n",
      "[644/1762] D loss: 0.0222, G loss: 5.3155\n",
      "[724/1762] D loss: 0.0132, G loss: 5.9100\n",
      "[804/1762] D loss: 0.0089, G loss: 6.0171\n",
      "[884/1762] D loss: 0.0015, G loss: 6.8023\n",
      "[964/1762] D loss: 0.0053, G loss: 6.7775\n",
      "[1044/1762] D loss: 0.0199, G loss: 5.7316\n",
      "[1124/1762] D loss: 0.0722, G loss: 4.8217\n",
      "[1204/1762] D loss: 4.0201, G loss: 11.0390\n",
      "[1284/1762] D loss: 0.0151, G loss: 4.8551\n",
      "[1364/1762] D loss: 1.2722, G loss: 4.2479\n",
      "[1444/1762] D loss: 0.0176, G loss: 6.0148\n",
      "[1524/1762] D loss: 0.0333, G loss: 5.9475\n",
      "[1604/1762] D loss: 0.0095, G loss: 6.9924\n",
      "[1684/1762] D loss: 0.0095, G loss: 8.6358\n",
      "[1762/1762] D loss: 0.1021, G loss: 5.2002\n",
      "train error: \n",
      " D loss: 2.125251, G loss: 6.998427, D accuracy: 50.9%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.145099, G loss: 6.945298, D accuracy: 50.7%, cell accuracy: 96.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0474, G loss: 6.3802\n",
      "[84/1762] D loss: 0.8881, G loss: 3.3256\n",
      "[164/1762] D loss: 3.1723, G loss: 0.1150\n",
      "[244/1762] D loss: 0.6502, G loss: 2.4365\n",
      "[324/1762] D loss: 0.2081, G loss: 3.8791\n",
      "[404/1762] D loss: 0.0098, G loss: 6.5298\n",
      "[484/1762] D loss: 0.0382, G loss: 4.8517\n",
      "[564/1762] D loss: 0.2328, G loss: 3.1066\n",
      "[644/1762] D loss: 1.5707, G loss: 0.9416\n",
      "[724/1762] D loss: 1.1677, G loss: 0.8355\n",
      "[804/1762] D loss: 1.1247, G loss: 0.9476\n",
      "[884/1762] D loss: 1.3699, G loss: 0.6780\n",
      "[964/1762] D loss: 1.3523, G loss: 0.7642\n",
      "[1044/1762] D loss: 1.1350, G loss: 1.3026\n",
      "[1124/1762] D loss: 0.1314, G loss: 3.9430\n",
      "[1204/1762] D loss: 0.0086, G loss: 6.0622\n",
      "[1284/1762] D loss: 1.3859, G loss: 0.6216\n",
      "[1364/1762] D loss: 1.4135, G loss: 0.7155\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.6959\n",
      "[1524/1762] D loss: 1.4204, G loss: 0.6569\n",
      "[1604/1762] D loss: 1.3981, G loss: 0.6940\n",
      "[1684/1762] D loss: 1.3851, G loss: 0.6850\n",
      "[1762/1762] D loss: 1.3519, G loss: 0.7178\n",
      "train error: \n",
      " D loss: 1.311105, G loss: 1.019610, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287409, G loss: 1.126657, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3858, G loss: 0.6944\n",
      "[84/1762] D loss: 0.1368, G loss: 2.8882\n",
      "[164/1762] D loss: 1.4094, G loss: 0.6740\n",
      "[244/1762] D loss: 0.0085, G loss: 6.7698\n",
      "[324/1762] D loss: 1.3911, G loss: 0.6515\n",
      "[404/1762] D loss: 1.3823, G loss: 0.6802\n",
      "[484/1762] D loss: 1.4479, G loss: 0.6789\n",
      "[564/1762] D loss: 1.3842, G loss: 0.6806\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6810\n",
      "[724/1762] D loss: 0.1554, G loss: 3.1818\n",
      "[804/1762] D loss: 1.4084, G loss: 0.6685\n",
      "[884/1762] D loss: 1.3919, G loss: 0.6765\n",
      "[964/1762] D loss: 1.3993, G loss: 0.8070\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6873\n",
      "[1124/1762] D loss: 1.4080, G loss: 1.0808\n",
      "[1204/1762] D loss: 1.4161, G loss: 0.6286\n",
      "[1284/1762] D loss: 1.4135, G loss: 0.6138\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.6926\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6897\n",
      "[1524/1762] D loss: 1.3982, G loss: 0.6734\n",
      "[1604/1762] D loss: 1.3944, G loss: 0.6852\n",
      "[1684/1762] D loss: 1.3850, G loss: 0.7139\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.7329\n",
      "train error: \n",
      " D loss: 1.319542, G loss: 0.935695, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291276, G loss: 1.073210, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0667, G loss: 4.0250\n",
      "[84/1762] D loss: 0.0290, G loss: 4.3904\n",
      "[164/1762] D loss: 0.0798, G loss: 4.0857\n",
      "[244/1762] D loss: 1.4429, G loss: 0.6649\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6835\n",
      "[404/1762] D loss: 1.3797, G loss: 0.7038\n",
      "[484/1762] D loss: 1.4094, G loss: 0.6911\n",
      "[564/1762] D loss: 1.3837, G loss: 0.6695\n",
      "[644/1762] D loss: 1.4025, G loss: 0.6662\n",
      "[724/1762] D loss: 1.4086, G loss: 0.6789\n",
      "[804/1762] D loss: 1.3956, G loss: 0.7226\n",
      "[884/1762] D loss: 1.4034, G loss: 0.6141\n",
      "[964/1762] D loss: 0.2613, G loss: 3.6043\n",
      "[1044/1762] D loss: 1.3958, G loss: 0.7868\n",
      "[1124/1762] D loss: 1.7241, G loss: 0.5663\n",
      "[1204/1762] D loss: 1.4129, G loss: 0.6464\n",
      "[1284/1762] D loss: 0.1072, G loss: 3.5419\n",
      "[1364/1762] D loss: 1.3979, G loss: 0.6883\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.6941\n",
      "[1524/1762] D loss: 2.0791, G loss: 0.9035\n",
      "[1604/1762] D loss: 0.1017, G loss: 4.8371\n",
      "[1684/1762] D loss: 1.4046, G loss: 0.6657\n",
      "[1762/1762] D loss: 1.3839, G loss: 0.6864\n",
      "train error: \n",
      " D loss: 1.300607, G loss: 1.071179, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269421, G loss: 1.237849, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3113, G loss: 2.6931\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6766\n",
      "[164/1762] D loss: 1.4132, G loss: 0.7357\n",
      "[244/1762] D loss: 0.2591, G loss: 2.7272\n",
      "[324/1762] D loss: 1.4015, G loss: 0.6400\n",
      "[404/1762] D loss: 1.3858, G loss: 0.7017\n",
      "[484/1762] D loss: 1.4031, G loss: 0.6506\n",
      "[564/1762] D loss: 1.1547, G loss: 1.2078\n",
      "[644/1762] D loss: 1.4341, G loss: 0.6031\n",
      "[724/1762] D loss: 1.3678, G loss: 0.8375\n",
      "[804/1762] D loss: 1.4014, G loss: 0.6729\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7011\n",
      "[964/1762] D loss: 1.4218, G loss: 0.6354\n",
      "[1044/1762] D loss: 1.4076, G loss: 0.6715\n",
      "[1124/1762] D loss: 1.4090, G loss: 0.7502\n",
      "[1204/1762] D loss: 1.3901, G loss: 0.6749\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6902\n",
      "[1364/1762] D loss: 1.3960, G loss: 0.7051\n",
      "[1444/1762] D loss: 1.4612, G loss: 0.6574\n",
      "[1524/1762] D loss: 0.0069, G loss: 6.1373\n",
      "[1604/1762] D loss: 0.0206, G loss: 4.8589\n",
      "[1684/1762] D loss: 1.3770, G loss: 0.6687\n",
      "[1762/1762] D loss: 1.4579, G loss: 0.7668\n",
      "train error: \n",
      " D loss: 1.330221, G loss: 0.925152, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303843, G loss: 1.063141, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3856, G loss: 0.7072\n",
      "[84/1762] D loss: 1.3873, G loss: 0.7001\n",
      "[164/1762] D loss: 1.3827, G loss: 0.7057\n",
      "[244/1762] D loss: 1.3817, G loss: 0.7039\n",
      "[324/1762] D loss: 1.3891, G loss: 0.6739\n",
      "[404/1762] D loss: 1.3895, G loss: 0.7069\n",
      "[484/1762] D loss: 1.3793, G loss: 0.6758\n",
      "[564/1762] D loss: 1.4193, G loss: 0.6245\n",
      "[644/1762] D loss: 0.3376, G loss: 2.6546\n",
      "[724/1762] D loss: 1.4294, G loss: 0.8216\n",
      "[804/1762] D loss: 0.1567, G loss: 4.9231\n",
      "[884/1762] D loss: 0.0899, G loss: 3.6856\n",
      "[964/1762] D loss: 0.1225, G loss: 3.6063\n",
      "[1044/1762] D loss: 1.3825, G loss: 0.6959\n",
      "[1124/1762] D loss: 1.4011, G loss: 0.6657\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.6837\n",
      "[1284/1762] D loss: 1.3787, G loss: 0.6966\n",
      "[1364/1762] D loss: 1.3910, G loss: 0.6929\n",
      "[1444/1762] D loss: 0.0182, G loss: 5.9201\n",
      "[1524/1762] D loss: 0.1132, G loss: 3.2595\n",
      "[1604/1762] D loss: 1.3827, G loss: 0.7213\n",
      "[1684/1762] D loss: 1.3915, G loss: 0.6968\n",
      "[1762/1762] D loss: 1.4787, G loss: 0.6994\n",
      "train error: \n",
      " D loss: 1.335077, G loss: 0.987495, D accuracy: 49.0%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305870, G loss: 1.139599, D accuracy: 49.1%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3965, G loss: 0.6150\n",
      "[84/1762] D loss: 1.3775, G loss: 0.6205\n",
      "[164/1762] D loss: 1.3202, G loss: 0.6402\n",
      "[244/1762] D loss: 1.2231, G loss: 0.6443\n",
      "[324/1762] D loss: 0.9934, G loss: 0.7204\n",
      "[404/1762] D loss: 0.7850, G loss: 0.8358\n",
      "[484/1762] D loss: 0.5186, G loss: 1.2324\n",
      "[564/1762] D loss: 0.3612, G loss: 1.8632\n",
      "[644/1762] D loss: 0.1901, G loss: 2.2325\n",
      "[724/1762] D loss: 0.4501, G loss: 0.8989\n",
      "[804/1762] D loss: 0.8489, G loss: 1.0718\n",
      "[884/1762] D loss: 0.8099, G loss: 2.2472\n",
      "[964/1762] D loss: 1.1600, G loss: 0.4762\n",
      "[1044/1762] D loss: 1.4211, G loss: 0.5312\n",
      "[1124/1762] D loss: 1.2168, G loss: 1.2139\n",
      "[1204/1762] D loss: 1.1367, G loss: 0.7660\n",
      "[1284/1762] D loss: 1.1516, G loss: 0.5757\n",
      "[1364/1762] D loss: 1.0062, G loss: 1.5498\n",
      "[1444/1762] D loss: 1.4033, G loss: 0.4894\n",
      "[1524/1762] D loss: 1.2828, G loss: 0.8063\n",
      "[1604/1762] D loss: 1.2628, G loss: 0.5917\n",
      "[1684/1762] D loss: 1.3579, G loss: 1.1062\n",
      "[1762/1762] D loss: 0.9656, G loss: 1.2517\n",
      "train error: \n",
      " D loss: 1.360604, G loss: 1.086510, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 66.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345323, G loss: 1.082170, D accuracy: 56.8%, cell accuracy: 99.5%, board accuracy: 61.4% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4766, G loss: 0.5807\n",
      "[84/1762] D loss: 1.3215, G loss: 1.1344\n",
      "[164/1762] D loss: 1.1296, G loss: 1.2631\n",
      "[244/1762] D loss: 1.4510, G loss: 1.2465\n",
      "[324/1762] D loss: 1.0942, G loss: 1.0792\n",
      "[404/1762] D loss: 1.5278, G loss: 0.7447\n",
      "[484/1762] D loss: 1.2462, G loss: 0.6521\n",
      "[564/1762] D loss: 1.3670, G loss: 0.5320\n",
      "[644/1762] D loss: 1.3470, G loss: 0.4958\n",
      "[724/1762] D loss: 1.6064, G loss: 0.8999\n",
      "[804/1762] D loss: 1.4018, G loss: 0.8069\n",
      "[884/1762] D loss: 1.3653, G loss: 0.8115\n",
      "[964/1762] D loss: 1.3661, G loss: 0.7817\n",
      "[1044/1762] D loss: 1.3411, G loss: 0.8085\n",
      "[1124/1762] D loss: 1.0190, G loss: 1.0582\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.7397\n",
      "[1284/1762] D loss: 1.0884, G loss: 0.8629\n",
      "[1364/1762] D loss: 1.2075, G loss: 0.9459\n",
      "[1444/1762] D loss: 1.3966, G loss: 0.7476\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.6066\n",
      "[1604/1762] D loss: 1.4414, G loss: 0.5872\n",
      "[1684/1762] D loss: 1.0372, G loss: 1.1244\n",
      "[1762/1762] D loss: 1.4053, G loss: 0.6763\n",
      "train error: \n",
      " D loss: 1.353527, G loss: 0.727745, D accuracy: 56.2%, cell accuracy: 99.5%, board accuracy: 61.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342623, G loss: 0.744573, D accuracy: 59.2%, cell accuracy: 99.4%, board accuracy: 60.7% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3712, G loss: 0.7071\n",
      "[84/1762] D loss: 1.3654, G loss: 0.6528\n",
      "[164/1762] D loss: 1.4050, G loss: 0.6397\n",
      "[244/1762] D loss: 1.3441, G loss: 0.6014\n",
      "[324/1762] D loss: 1.3355, G loss: 0.7001\n",
      "[404/1762] D loss: 1.1214, G loss: 0.9936\n",
      "[484/1762] D loss: 1.3184, G loss: 0.7773\n",
      "[564/1762] D loss: 1.5234, G loss: 0.6630\n",
      "[644/1762] D loss: 1.4864, G loss: 0.9336\n",
      "[724/1762] D loss: 1.3848, G loss: 0.6000\n",
      "[804/1762] D loss: 1.3878, G loss: 0.6479\n",
      "[884/1762] D loss: 1.3961, G loss: 0.5771\n",
      "[964/1762] D loss: 1.3251, G loss: 0.8532\n",
      "[1044/1762] D loss: 1.4070, G loss: 0.7285\n",
      "[1124/1762] D loss: 1.3670, G loss: 0.6976\n",
      "[1204/1762] D loss: 1.3756, G loss: 0.7209\n",
      "[1284/1762] D loss: 1.5461, G loss: 1.1940\n",
      "[1364/1762] D loss: 1.4790, G loss: 0.5938\n",
      "[1444/1762] D loss: 1.1237, G loss: 0.6899\n",
      "[1524/1762] D loss: 1.4175, G loss: 0.7628\n",
      "[1604/1762] D loss: 1.2502, G loss: 0.9331\n",
      "[1684/1762] D loss: 1.3744, G loss: 0.7000\n",
      "[1762/1762] D loss: 1.5818, G loss: 0.8711\n",
      "train error: \n",
      " D loss: 1.339875, G loss: 0.787151, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 73.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333919, G loss: 0.796209, D accuracy: 56.7%, cell accuracy: 99.6%, board accuracy: 70.2% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4106, G loss: 0.7137\n",
      "[84/1762] D loss: 1.4017, G loss: 0.7395\n",
      "[164/1762] D loss: 1.6189, G loss: 0.8719\n",
      "[244/1762] D loss: 1.3624, G loss: 0.6784\n",
      "[324/1762] D loss: 0.9797, G loss: 1.0209\n",
      "[404/1762] D loss: 0.8073, G loss: 1.1427\n",
      "[484/1762] D loss: 1.3435, G loss: 0.6331\n",
      "[564/1762] D loss: 1.4039, G loss: 0.7672\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6959\n",
      "[724/1762] D loss: 1.4275, G loss: 0.7745\n",
      "[804/1762] D loss: 0.8815, G loss: 1.5372\n",
      "[884/1762] D loss: 1.2887, G loss: 0.9714\n",
      "[964/1762] D loss: 1.4331, G loss: 0.6745\n",
      "[1044/1762] D loss: 1.3575, G loss: 0.7950\n",
      "[1124/1762] D loss: 1.4562, G loss: 1.0695\n",
      "[1204/1762] D loss: 1.3964, G loss: 0.7266\n",
      "[1284/1762] D loss: 1.6313, G loss: 0.6885\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6908\n",
      "[1444/1762] D loss: 1.2978, G loss: 0.9378\n",
      "[1524/1762] D loss: 1.4091, G loss: 0.6961\n",
      "[1604/1762] D loss: 1.2827, G loss: 0.7813\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.7009\n",
      "[1762/1762] D loss: 1.4638, G loss: 0.6121\n",
      "train error: \n",
      " D loss: 1.348715, G loss: 0.587826, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332581, G loss: 0.597126, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9445, G loss: 1.0986\n",
      "[84/1762] D loss: 1.3951, G loss: 0.6291\n",
      "[164/1762] D loss: 1.3930, G loss: 0.7803\n",
      "[244/1762] D loss: 1.4281, G loss: 0.7072\n",
      "[324/1762] D loss: 1.4170, G loss: 0.8339\n",
      "[404/1762] D loss: 1.3207, G loss: 0.6208\n",
      "[484/1762] D loss: 1.8055, G loss: 0.6750\n",
      "[564/1762] D loss: 1.3684, G loss: 0.6432\n",
      "[644/1762] D loss: 1.4882, G loss: 0.6703\n",
      "[724/1762] D loss: 1.3552, G loss: 0.8708\n",
      "[804/1762] D loss: 1.3678, G loss: 0.7160\n",
      "[884/1762] D loss: 1.3402, G loss: 0.7984\n",
      "[964/1762] D loss: 1.3531, G loss: 0.6714\n",
      "[1044/1762] D loss: 0.8565, G loss: 1.1607\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.7114\n",
      "[1204/1762] D loss: 1.0425, G loss: 1.0454\n",
      "[1284/1762] D loss: 1.4061, G loss: 0.7437\n",
      "[1364/1762] D loss: 1.3474, G loss: 0.7102\n",
      "[1444/1762] D loss: 1.7697, G loss: 0.9467\n",
      "[1524/1762] D loss: 1.5156, G loss: 0.6482\n",
      "[1604/1762] D loss: 1.4218, G loss: 0.5358\n",
      "[1684/1762] D loss: 1.1072, G loss: 0.8799\n",
      "[1762/1762] D loss: 1.4092, G loss: 0.7611\n",
      "train error: \n",
      " D loss: 1.360844, G loss: 0.725347, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 77.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346931, G loss: 0.750050, D accuracy: 56.2%, cell accuracy: 99.6%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2832, G loss: 0.7608\n",
      "[84/1762] D loss: 1.4110, G loss: 0.7329\n",
      "[164/1762] D loss: 1.4172, G loss: 0.7366\n",
      "[244/1762] D loss: 1.4386, G loss: 0.6317\n",
      "[324/1762] D loss: 1.4294, G loss: 0.5416\n",
      "[404/1762] D loss: 1.4400, G loss: 0.7468\n",
      "[484/1762] D loss: 0.7394, G loss: 1.2161\n",
      "[564/1762] D loss: 0.7736, G loss: 1.2574\n",
      "[644/1762] D loss: 1.4051, G loss: 0.7190\n",
      "[724/1762] D loss: 1.3930, G loss: 0.7672\n",
      "[804/1762] D loss: 1.2398, G loss: 0.7269\n",
      "[884/1762] D loss: 1.3816, G loss: 0.7189\n",
      "[964/1762] D loss: 1.3632, G loss: 0.6976\n",
      "[1044/1762] D loss: 1.3858, G loss: 0.7272\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7055\n",
      "[1204/1762] D loss: 0.8964, G loss: 1.2514\n",
      "[1284/1762] D loss: 1.0598, G loss: 1.1124\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.6057\n",
      "[1444/1762] D loss: 1.3355, G loss: 0.7807\n",
      "[1524/1762] D loss: 1.4285, G loss: 0.5593\n",
      "[1604/1762] D loss: 1.4131, G loss: 0.7676\n",
      "[1684/1762] D loss: 1.5258, G loss: 0.7679\n",
      "[1762/1762] D loss: 1.1191, G loss: 0.9687\n",
      "train error: \n",
      " D loss: 1.390038, G loss: 0.549546, D accuracy: 62.1%, cell accuracy: 99.5%, board accuracy: 63.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379361, G loss: 0.562236, D accuracy: 61.7%, cell accuracy: 99.5%, board accuracy: 63.9% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7505, G loss: 1.2628\n",
      "[84/1762] D loss: 1.3756, G loss: 0.6428\n",
      "[164/1762] D loss: 1.4863, G loss: 0.5659\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6804\n",
      "[324/1762] D loss: 1.3259, G loss: 0.8386\n",
      "[404/1762] D loss: 1.4124, G loss: 0.6664\n",
      "[484/1762] D loss: 1.3840, G loss: 0.6959\n",
      "[564/1762] D loss: 1.4059, G loss: 0.6373\n",
      "[644/1762] D loss: 0.7450, G loss: 1.5072\n",
      "[724/1762] D loss: 1.4821, G loss: 0.3644\n",
      "[804/1762] D loss: 1.4563, G loss: 0.7619\n",
      "[884/1762] D loss: 1.4058, G loss: 0.7457\n",
      "[964/1762] D loss: 1.4018, G loss: 0.7074\n",
      "[1044/1762] D loss: 1.4116, G loss: 0.6722\n",
      "[1124/1762] D loss: 1.4021, G loss: 0.6470\n",
      "[1204/1762] D loss: 1.4237, G loss: 0.7144\n",
      "[1284/1762] D loss: 1.3859, G loss: 0.7077\n",
      "[1364/1762] D loss: 1.4216, G loss: 0.7900\n",
      "[1444/1762] D loss: 1.3404, G loss: 0.7672\n",
      "[1524/1762] D loss: 1.4867, G loss: 0.5035\n",
      "[1604/1762] D loss: 0.7865, G loss: 1.2651\n",
      "[1684/1762] D loss: 1.3886, G loss: 0.7482\n",
      "[1762/1762] D loss: 0.3583, G loss: 1.8668\n",
      "train error: \n",
      " D loss: 1.328845, G loss: 0.771741, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316611, G loss: 0.769088, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7449, G loss: 0.5329\n",
      "[84/1762] D loss: 0.5874, G loss: 1.5083\n",
      "[164/1762] D loss: 1.4131, G loss: 0.6724\n",
      "[244/1762] D loss: 0.8808, G loss: 1.0372\n",
      "[324/1762] D loss: 1.3544, G loss: 0.7848\n",
      "[404/1762] D loss: 1.3434, G loss: 0.7596\n",
      "[484/1762] D loss: 1.3652, G loss: 0.6724\n",
      "[564/1762] D loss: 1.3856, G loss: 0.7394\n",
      "[644/1762] D loss: 1.4457, G loss: 0.7465\n",
      "[724/1762] D loss: 1.3844, G loss: 0.6861\n",
      "[804/1762] D loss: 1.3903, G loss: 0.6731\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6299\n",
      "[964/1762] D loss: 1.2843, G loss: 0.7788\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.6851\n",
      "[1124/1762] D loss: 1.4346, G loss: 0.6264\n",
      "[1204/1762] D loss: 1.3848, G loss: 0.7327\n",
      "[1284/1762] D loss: 0.8874, G loss: 1.1033\n",
      "[1364/1762] D loss: 0.6133, G loss: 1.3860\n",
      "[1444/1762] D loss: 1.5699, G loss: 0.4619\n",
      "[1524/1762] D loss: 0.9632, G loss: 1.4450\n",
      "[1604/1762] D loss: 1.3987, G loss: 0.8523\n",
      "[1684/1762] D loss: 1.3646, G loss: 0.7286\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7311\n",
      "train error: \n",
      " D loss: 1.334944, G loss: 0.741293, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325305, G loss: 0.734830, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4199, G loss: 0.7022\n",
      "[84/1762] D loss: 1.4761, G loss: 0.5251\n",
      "[164/1762] D loss: 1.4055, G loss: 0.7524\n",
      "[244/1762] D loss: 0.5304, G loss: 1.5198\n",
      "[324/1762] D loss: 1.4499, G loss: 0.7094\n",
      "[404/1762] D loss: 1.3928, G loss: 0.6853\n",
      "[484/1762] D loss: 0.6596, G loss: 1.3929\n",
      "[564/1762] D loss: 1.4104, G loss: 0.7021\n",
      "[644/1762] D loss: 1.4596, G loss: 0.6967\n",
      "[724/1762] D loss: 0.4770, G loss: 1.7712\n",
      "[804/1762] D loss: 1.3894, G loss: 0.6927\n",
      "[884/1762] D loss: 0.4168, G loss: 1.5451\n",
      "[964/1762] D loss: 1.2838, G loss: 0.8819\n",
      "[1044/1762] D loss: 1.4390, G loss: 0.6875\n",
      "[1124/1762] D loss: 1.2777, G loss: 0.8006\n",
      "[1204/1762] D loss: 1.4677, G loss: 0.7930\n",
      "[1284/1762] D loss: 1.3945, G loss: 0.7116\n",
      "[1364/1762] D loss: 1.3985, G loss: 0.6792\n",
      "[1444/1762] D loss: 0.9955, G loss: 0.8848\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.6850\n",
      "[1604/1762] D loss: 0.9782, G loss: 0.9391\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.7226\n",
      "[1762/1762] D loss: 1.3210, G loss: 0.7746\n",
      "train error: \n",
      " D loss: 1.400575, G loss: 0.510765, D accuracy: 60.7%, cell accuracy: 99.5%, board accuracy: 61.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372267, G loss: 0.538001, D accuracy: 61.8%, cell accuracy: 99.4%, board accuracy: 56.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3949, G loss: 0.6869\n",
      "[84/1762] D loss: 1.4117, G loss: 0.6895\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7201\n",
      "[244/1762] D loss: 1.4150, G loss: 0.7983\n",
      "[324/1762] D loss: 1.4130, G loss: 0.6741\n",
      "[404/1762] D loss: 1.5880, G loss: 0.7061\n",
      "[484/1762] D loss: 1.3917, G loss: 0.6890\n",
      "[564/1762] D loss: 1.4102, G loss: 0.6862\n",
      "[644/1762] D loss: 0.4467, G loss: 1.5600\n",
      "[724/1762] D loss: 0.6272, G loss: 1.4074\n",
      "[804/1762] D loss: 1.3416, G loss: 0.6701\n",
      "[884/1762] D loss: 0.3492, G loss: 1.7575\n",
      "[964/1762] D loss: 1.4562, G loss: 0.8236\n",
      "[1044/1762] D loss: 1.4036, G loss: 0.6761\n",
      "[1124/1762] D loss: 1.4049, G loss: 0.6986\n",
      "[1204/1762] D loss: 1.5027, G loss: 0.5811\n",
      "[1284/1762] D loss: 1.3823, G loss: 0.6646\n",
      "[1364/1762] D loss: 0.6928, G loss: 1.3205\n",
      "[1444/1762] D loss: 1.3916, G loss: 0.6929\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.6790\n",
      "[1604/1762] D loss: 1.4546, G loss: 0.7176\n",
      "[1684/1762] D loss: 1.4640, G loss: 0.7192\n",
      "[1762/1762] D loss: 1.4002, G loss: 0.6755\n",
      "train error: \n",
      " D loss: 1.342493, G loss: 0.789784, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330292, G loss: 0.805808, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4102, G loss: 0.7058\n",
      "[84/1762] D loss: 0.6231, G loss: 1.2158\n",
      "[164/1762] D loss: 1.3901, G loss: 0.6260\n",
      "[244/1762] D loss: 1.6092, G loss: 0.7388\n",
      "[324/1762] D loss: 0.2721, G loss: 1.6351\n",
      "[404/1762] D loss: 1.4653, G loss: 0.7123\n",
      "[484/1762] D loss: 1.4051, G loss: 0.6633\n",
      "[564/1762] D loss: 0.3594, G loss: 1.5814\n",
      "[644/1762] D loss: 1.3964, G loss: 0.7064\n",
      "[724/1762] D loss: 0.5196, G loss: 1.3980\n",
      "[804/1762] D loss: 1.3924, G loss: 0.7136\n",
      "[884/1762] D loss: 0.2138, G loss: 1.8520\n",
      "[964/1762] D loss: 1.3956, G loss: 0.7222\n",
      "[1044/1762] D loss: 0.4729, G loss: 1.5108\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6959\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.6810\n",
      "[1284/1762] D loss: 0.3591, G loss: 1.5507\n",
      "[1364/1762] D loss: 1.3857, G loss: 0.7116\n",
      "[1444/1762] D loss: 0.7547, G loss: 1.0850\n",
      "[1524/1762] D loss: 1.3709, G loss: 0.7008\n",
      "[1604/1762] D loss: 1.4082, G loss: 0.7432\n",
      "[1684/1762] D loss: 0.2589, G loss: 1.7384\n",
      "[1762/1762] D loss: 1.4838, G loss: 0.6380\n",
      "train error: \n",
      " D loss: 1.360860, G loss: 0.741019, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351648, G loss: 0.755911, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4083, G loss: 1.5608\n",
      "[84/1762] D loss: 1.4479, G loss: 0.6973\n",
      "[164/1762] D loss: 1.3821, G loss: 0.6999\n",
      "[244/1762] D loss: 1.3915, G loss: 0.7185\n",
      "[324/1762] D loss: 1.3830, G loss: 0.6955\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6748\n",
      "[484/1762] D loss: 0.8906, G loss: 1.0409\n",
      "[564/1762] D loss: 1.3942, G loss: 0.7024\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6704\n",
      "[724/1762] D loss: 1.4301, G loss: 0.6620\n",
      "[804/1762] D loss: 1.4017, G loss: 0.6944\n",
      "[884/1762] D loss: 0.3710, G loss: 1.6000\n",
      "[964/1762] D loss: 1.4129, G loss: 0.7207\n",
      "[1044/1762] D loss: 1.4753, G loss: 0.6291\n",
      "[1124/1762] D loss: 1.4190, G loss: 0.7135\n",
      "[1204/1762] D loss: 1.4031, G loss: 0.7096\n",
      "[1284/1762] D loss: 1.5680, G loss: 0.8644\n",
      "[1364/1762] D loss: 1.3828, G loss: 0.6831\n",
      "[1444/1762] D loss: 1.3948, G loss: 0.7164\n",
      "[1524/1762] D loss: 1.3965, G loss: 0.7133\n",
      "[1604/1762] D loss: 1.4217, G loss: 0.6768\n",
      "[1684/1762] D loss: 0.5390, G loss: 1.3442\n",
      "[1762/1762] D loss: 1.3842, G loss: 0.7228\n",
      "train error: \n",
      " D loss: 1.373070, G loss: 0.603538, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366149, G loss: 0.612222, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3693, G loss: 0.6754\n",
      "[84/1762] D loss: 1.6189, G loss: 0.7066\n",
      "[164/1762] D loss: 0.3694, G loss: 1.5793\n",
      "[244/1762] D loss: 1.3892, G loss: 0.6641\n",
      "[324/1762] D loss: 1.4223, G loss: 0.7305\n",
      "[404/1762] D loss: 1.3472, G loss: 0.7120\n",
      "[484/1762] D loss: 1.4857, G loss: 0.6319\n",
      "[564/1762] D loss: 1.3800, G loss: 0.7036\n",
      "[644/1762] D loss: 1.3938, G loss: 0.6914\n",
      "[724/1762] D loss: 1.6724, G loss: 0.8719\n",
      "[804/1762] D loss: 1.3989, G loss: 0.7092\n",
      "[884/1762] D loss: 1.3958, G loss: 0.7048\n",
      "[964/1762] D loss: 1.4061, G loss: 0.6826\n",
      "[1044/1762] D loss: 0.7066, G loss: 1.1771\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.6922\n",
      "[1204/1762] D loss: 1.3918, G loss: 0.7091\n",
      "[1284/1762] D loss: 0.5459, G loss: 1.2498\n",
      "[1364/1762] D loss: 1.4036, G loss: 0.7012\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.6896\n",
      "[1524/1762] D loss: 1.5331, G loss: 0.7853\n",
      "[1604/1762] D loss: 1.4040, G loss: 0.7957\n",
      "[1684/1762] D loss: 0.4858, G loss: 1.4170\n",
      "[1762/1762] D loss: 1.3767, G loss: 0.7196\n",
      "train error: \n",
      " D loss: 1.331729, G loss: 0.780097, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 72.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320784, G loss: 0.784095, D accuracy: 54.5%, cell accuracy: 99.5%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6948\n",
      "[84/1762] D loss: 1.3808, G loss: 0.6702\n",
      "[164/1762] D loss: 1.4940, G loss: 0.7610\n",
      "[244/1762] D loss: 1.4021, G loss: 0.7086\n",
      "[324/1762] D loss: 1.3907, G loss: 0.6960\n",
      "[404/1762] D loss: 0.5493, G loss: 1.1621\n",
      "[484/1762] D loss: 0.4360, G loss: 1.3837\n",
      "[564/1762] D loss: 1.4080, G loss: 0.7127\n",
      "[644/1762] D loss: 1.3944, G loss: 0.6992\n",
      "[724/1762] D loss: 1.4433, G loss: 0.7568\n",
      "[804/1762] D loss: 0.4578, G loss: 1.5025\n",
      "[884/1762] D loss: 0.6332, G loss: 1.2507\n",
      "[964/1762] D loss: 1.3984, G loss: 0.7137\n",
      "[1044/1762] D loss: 0.3717, G loss: 1.5040\n",
      "[1124/1762] D loss: 1.3961, G loss: 0.7163\n",
      "[1204/1762] D loss: 0.3170, G loss: 1.6171\n",
      "[1284/1762] D loss: 0.2992, G loss: 1.6575\n",
      "[1364/1762] D loss: 1.4605, G loss: 0.6597\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.7052\n",
      "[1524/1762] D loss: 1.3942, G loss: 0.6974\n",
      "[1604/1762] D loss: 1.3987, G loss: 0.7101\n",
      "[1684/1762] D loss: 1.6659, G loss: 0.9311\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.7357\n",
      "train error: \n",
      " D loss: 1.371142, G loss: 0.554211, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362143, G loss: 0.559942, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5906, G loss: 1.1951\n",
      "[84/1762] D loss: 1.4159, G loss: 0.7167\n",
      "[164/1762] D loss: 1.3997, G loss: 0.7055\n",
      "[244/1762] D loss: 1.4241, G loss: 0.7618\n",
      "[324/1762] D loss: 1.4094, G loss: 0.7125\n",
      "[404/1762] D loss: 1.4064, G loss: 0.7381\n",
      "[484/1762] D loss: 1.4830, G loss: 0.7838\n",
      "[564/1762] D loss: 0.3014, G loss: 1.6733\n",
      "[644/1762] D loss: 1.3979, G loss: 0.7258\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6898\n",
      "[804/1762] D loss: 1.4106, G loss: 0.6975\n",
      "[884/1762] D loss: 1.3921, G loss: 0.7029\n",
      "[964/1762] D loss: 1.3916, G loss: 0.7051\n",
      "[1044/1762] D loss: 1.3857, G loss: 0.7166\n",
      "[1124/1762] D loss: 1.4011, G loss: 0.7141\n",
      "[1204/1762] D loss: 1.3940, G loss: 0.7667\n",
      "[1284/1762] D loss: 1.4004, G loss: 0.7222\n",
      "[1364/1762] D loss: 1.3996, G loss: 0.7203\n",
      "[1444/1762] D loss: 0.4932, G loss: 1.3991\n",
      "[1524/1762] D loss: 1.4310, G loss: 0.6819\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.7036\n",
      "[1684/1762] D loss: 1.6260, G loss: 0.8403\n",
      "[1762/1762] D loss: 0.3343, G loss: 1.7344\n",
      "train error: \n",
      " D loss: 2.162934, G loss: 0.168991, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.132620, G loss: 0.178042, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4030, G loss: 0.7196\n",
      "[84/1762] D loss: 1.4251, G loss: 0.7314\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7296\n",
      "[244/1762] D loss: 1.4083, G loss: 0.7731\n",
      "[324/1762] D loss: 0.2352, G loss: 1.8691\n",
      "[404/1762] D loss: 1.4406, G loss: 0.7568\n",
      "[484/1762] D loss: 1.4362, G loss: 0.7638\n",
      "[564/1762] D loss: 0.3183, G loss: 1.5343\n",
      "[644/1762] D loss: 1.4535, G loss: 0.8209\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6912\n",
      "[804/1762] D loss: 1.3993, G loss: 0.6921\n",
      "[884/1762] D loss: 1.6616, G loss: 0.8897\n",
      "[964/1762] D loss: 0.5940, G loss: 1.2724\n",
      "[1044/1762] D loss: 1.2181, G loss: 0.9264\n",
      "[1124/1762] D loss: 1.5707, G loss: 0.8595\n",
      "[1204/1762] D loss: 1.4190, G loss: 0.7350\n",
      "[1284/1762] D loss: 0.5455, G loss: 1.2047\n",
      "[1364/1762] D loss: 1.4115, G loss: 0.7150\n",
      "[1444/1762] D loss: 1.4285, G loss: 0.7422\n",
      "[1524/1762] D loss: 1.4444, G loss: 0.7539\n",
      "[1604/1762] D loss: 1.4886, G loss: 0.7446\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.7009\n",
      "[1762/1762] D loss: 1.4113, G loss: 0.5784\n",
      "train error: \n",
      " D loss: 1.622916, G loss: 0.424566, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.618857, G loss: 0.444489, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3559, G loss: 0.9019\n",
      "[84/1762] D loss: 0.4442, G loss: 1.3856\n",
      "[164/1762] D loss: 1.4055, G loss: 0.7085\n",
      "[244/1762] D loss: 1.4136, G loss: 0.7418\n",
      "[324/1762] D loss: 1.4318, G loss: 0.6320\n",
      "[404/1762] D loss: 1.2218, G loss: 0.9047\n",
      "[484/1762] D loss: 1.3811, G loss: 0.7391\n",
      "[564/1762] D loss: 1.3898, G loss: 0.6922\n",
      "[644/1762] D loss: 1.3986, G loss: 0.6580\n",
      "[724/1762] D loss: 1.1489, G loss: 0.9443\n",
      "[804/1762] D loss: 1.3603, G loss: 0.7395\n",
      "[884/1762] D loss: 1.8744, G loss: 1.1254\n",
      "[964/1762] D loss: 1.3793, G loss: 0.6967\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7076\n",
      "[1124/1762] D loss: 2.5047, G loss: 1.4827\n",
      "[1204/1762] D loss: 1.3306, G loss: 0.7789\n",
      "[1284/1762] D loss: 1.1654, G loss: 0.8758\n",
      "[1364/1762] D loss: 1.4008, G loss: 0.7242\n",
      "[1444/1762] D loss: 1.4517, G loss: 1.0347\n",
      "[1524/1762] D loss: 1.1451, G loss: 0.8928\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6654\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.6756\n",
      "[1762/1762] D loss: 1.0163, G loss: 1.0638\n",
      "train error: \n",
      " D loss: 1.358677, G loss: 0.851400, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347311, G loss: 0.880743, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.7111\n",
      "[84/1762] D loss: 1.2983, G loss: 0.7903\n",
      "[164/1762] D loss: 1.3977, G loss: 0.7048\n",
      "[244/1762] D loss: 1.3912, G loss: 0.6706\n",
      "[324/1762] D loss: 1.3797, G loss: 0.6901\n",
      "[404/1762] D loss: 1.3897, G loss: 0.6793\n",
      "[484/1762] D loss: 1.3775, G loss: 0.7077\n",
      "[564/1762] D loss: 1.3669, G loss: 0.8645\n",
      "[644/1762] D loss: 1.3934, G loss: 0.7179\n",
      "[724/1762] D loss: 1.3904, G loss: 0.6743\n",
      "[804/1762] D loss: 1.4061, G loss: 0.6315\n",
      "[884/1762] D loss: 1.3938, G loss: 0.6928\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6913\n",
      "[1044/1762] D loss: 1.3903, G loss: 0.6858\n",
      "[1124/1762] D loss: 1.3784, G loss: 0.6974\n",
      "[1204/1762] D loss: 1.2199, G loss: 0.8400\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.6762\n",
      "[1364/1762] D loss: 1.4189, G loss: 0.7651\n",
      "[1444/1762] D loss: 1.2218, G loss: 1.0241\n",
      "[1524/1762] D loss: 1.4272, G loss: 0.6816\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.7139\n",
      "[1684/1762] D loss: 1.3927, G loss: 0.7278\n",
      "[1762/1762] D loss: 1.2318, G loss: 0.9931\n",
      "train error: \n",
      " D loss: 2.189435, G loss: 0.414840, D accuracy: 56.9%, cell accuracy: 95.0%, board accuracy: 8.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.006333, G loss: 0.451821, D accuracy: 58.3%, cell accuracy: 95.2%, board accuracy: 10.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4116, G loss: 0.7039\n",
      "[84/1762] D loss: 1.3992, G loss: 0.7299\n",
      "[164/1762] D loss: 1.4073, G loss: 0.6737\n",
      "[244/1762] D loss: 1.4522, G loss: 0.7408\n",
      "[324/1762] D loss: 0.5481, G loss: 1.4034\n",
      "[404/1762] D loss: 1.3918, G loss: 0.7072\n",
      "[484/1762] D loss: 1.3947, G loss: 0.7139\n",
      "[564/1762] D loss: 1.3920, G loss: 0.6988\n",
      "[644/1762] D loss: 1.4191, G loss: 0.7446\n",
      "[724/1762] D loss: 1.4210, G loss: 0.7154\n",
      "[804/1762] D loss: 1.3387, G loss: 0.7654\n",
      "[884/1762] D loss: 1.3877, G loss: 0.6836\n",
      "[964/1762] D loss: 1.3787, G loss: 0.7182\n",
      "[1044/1762] D loss: 1.5226, G loss: 1.2458\n",
      "[1124/1762] D loss: 1.4261, G loss: 0.7613\n",
      "[1204/1762] D loss: 1.9255, G loss: 1.9921\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.6960\n",
      "[1364/1762] D loss: 1.6687, G loss: 0.9073\n",
      "[1444/1762] D loss: 1.3944, G loss: 0.7523\n",
      "[1524/1762] D loss: 1.4279, G loss: 0.8127\n",
      "[1604/1762] D loss: 1.3849, G loss: 0.6784\n",
      "[1684/1762] D loss: 1.4088, G loss: 0.7517\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.6721\n",
      "train error: \n",
      " D loss: 1.349999, G loss: 0.730714, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336260, G loss: 0.737794, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3955, G loss: 0.6604\n",
      "[84/1762] D loss: 1.3924, G loss: 0.7213\n",
      "[164/1762] D loss: 1.4740, G loss: 0.8921\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7446\n",
      "[324/1762] D loss: 1.8110, G loss: 1.3943\n",
      "[404/1762] D loss: 1.0146, G loss: 1.0064\n",
      "[484/1762] D loss: 1.3947, G loss: 0.6605\n",
      "[564/1762] D loss: 0.9116, G loss: 1.0044\n",
      "[644/1762] D loss: 1.3863, G loss: 0.7030\n",
      "[724/1762] D loss: 0.8302, G loss: 0.8024\n",
      "[804/1762] D loss: 1.3900, G loss: 0.7234\n",
      "[884/1762] D loss: 0.9094, G loss: 0.9266\n",
      "[964/1762] D loss: 1.3391, G loss: 0.7618\n",
      "[1044/1762] D loss: 1.4212, G loss: 0.7806\n",
      "[1124/1762] D loss: 0.8010, G loss: 1.2423\n",
      "[1204/1762] D loss: 1.4057, G loss: 0.7383\n",
      "[1284/1762] D loss: 0.4645, G loss: 1.4655\n",
      "[1364/1762] D loss: 1.4092, G loss: 0.6718\n",
      "[1444/1762] D loss: 0.5947, G loss: 1.1175\n",
      "[1524/1762] D loss: 1.4195, G loss: 0.7946\n",
      "[1604/1762] D loss: 1.4266, G loss: 0.7611\n",
      "[1684/1762] D loss: 1.3489, G loss: 0.7750\n",
      "[1762/1762] D loss: 1.3979, G loss: 0.8139\n",
      "train error: \n",
      " D loss: 1.381431, G loss: 0.857217, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371510, G loss: 0.870997, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4408, G loss: 1.4001\n",
      "[84/1762] D loss: 0.4822, G loss: 1.2843\n",
      "[164/1762] D loss: 1.4010, G loss: 0.7610\n",
      "[244/1762] D loss: 0.5175, G loss: 1.4631\n",
      "[324/1762] D loss: 0.5456, G loss: 1.2537\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7128\n",
      "[484/1762] D loss: 1.4242, G loss: 0.7602\n",
      "[564/1762] D loss: 1.4570, G loss: 0.6262\n",
      "[644/1762] D loss: 1.5190, G loss: 0.8133\n",
      "[724/1762] D loss: 0.4340, G loss: 1.3531\n",
      "[804/1762] D loss: 1.4260, G loss: 0.8384\n",
      "[884/1762] D loss: 1.4062, G loss: 0.7660\n",
      "[964/1762] D loss: 1.5682, G loss: 0.7266\n",
      "[1044/1762] D loss: 1.4202, G loss: 0.8285\n",
      "[1124/1762] D loss: 1.4277, G loss: 0.7380\n",
      "[1204/1762] D loss: 1.3429, G loss: 0.8247\n",
      "[1284/1762] D loss: 1.3843, G loss: 0.6968\n",
      "[1364/1762] D loss: 1.4386, G loss: 0.8041\n",
      "[1444/1762] D loss: 1.4429, G loss: 0.7467\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.7125\n",
      "[1604/1762] D loss: 1.4157, G loss: 0.7342\n",
      "[1684/1762] D loss: 0.4628, G loss: 1.2514\n",
      "[1762/1762] D loss: 1.3833, G loss: 0.5293\n",
      "train error: \n",
      " D loss: 1.440419, G loss: 0.500511, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.418874, G loss: 0.515851, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4011, G loss: 0.6969\n",
      "[84/1762] D loss: 1.4105, G loss: 0.7298\n",
      "[164/1762] D loss: 1.3987, G loss: 0.7324\n",
      "[244/1762] D loss: 0.4092, G loss: 1.4600\n",
      "[324/1762] D loss: 1.3944, G loss: 0.7140\n",
      "[404/1762] D loss: 0.4968, G loss: 1.1267\n",
      "[484/1762] D loss: 1.3778, G loss: 0.6833\n",
      "[564/1762] D loss: 1.5561, G loss: 0.9463\n",
      "[644/1762] D loss: 0.5520, G loss: 1.3443\n",
      "[724/1762] D loss: 1.3976, G loss: 0.7093\n",
      "[804/1762] D loss: 1.3289, G loss: 0.6918\n",
      "[884/1762] D loss: 1.3925, G loss: 0.7055\n",
      "[964/1762] D loss: 1.3845, G loss: 0.7005\n",
      "[1044/1762] D loss: 0.4205, G loss: 1.4198\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.6755\n",
      "[1204/1762] D loss: 1.4758, G loss: 0.8440\n",
      "[1284/1762] D loss: 0.4853, G loss: 1.1931\n",
      "[1364/1762] D loss: 1.4265, G loss: 0.7913\n",
      "[1444/1762] D loss: 1.3914, G loss: 0.6971\n",
      "[1524/1762] D loss: 1.5357, G loss: 0.9189\n",
      "[1604/1762] D loss: 1.3689, G loss: 0.6994\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.7135\n",
      "[1762/1762] D loss: 0.4745, G loss: 1.6299\n",
      "train error: \n",
      " D loss: 2.279930, G loss: 0.166537, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.233114, G loss: 0.175725, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4532, G loss: 0.8375\n",
      "[84/1762] D loss: 0.4911, G loss: 1.2072\n",
      "[164/1762] D loss: 0.3282, G loss: 1.6477\n",
      "[244/1762] D loss: 1.4184, G loss: 0.7423\n",
      "[324/1762] D loss: 0.4105, G loss: 1.4365\n",
      "[404/1762] D loss: 1.3837, G loss: 0.6931\n",
      "[484/1762] D loss: 0.4265, G loss: 1.7118\n",
      "[564/1762] D loss: 1.4164, G loss: 0.6962\n",
      "[644/1762] D loss: 1.4175, G loss: 0.6523\n",
      "[724/1762] D loss: 1.3820, G loss: 0.6878\n",
      "[804/1762] D loss: 0.5227, G loss: 1.4087\n",
      "[884/1762] D loss: 1.4464, G loss: 0.9823\n",
      "[964/1762] D loss: 1.3887, G loss: 0.6943\n",
      "[1044/1762] D loss: 0.5159, G loss: 1.4331\n",
      "[1124/1762] D loss: 0.3275, G loss: 1.6701\n",
      "[1204/1762] D loss: 1.4344, G loss: 0.6924\n",
      "[1284/1762] D loss: 1.4031, G loss: 0.7035\n",
      "[1364/1762] D loss: 0.3502, G loss: 1.6236\n",
      "[1444/1762] D loss: 1.4597, G loss: 0.7658\n",
      "[1524/1762] D loss: 1.4019, G loss: 0.7638\n",
      "[1604/1762] D loss: 0.3702, G loss: 1.5810\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.7062\n",
      "[1762/1762] D loss: 1.5837, G loss: 0.7569\n",
      "train error: \n",
      " D loss: 1.335195, G loss: 0.810262, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318329, G loss: 0.844005, D accuracy: 53.9%, cell accuracy: 99.6%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5119, G loss: 1.3319\n",
      "[84/1762] D loss: 1.4185, G loss: 0.7583\n",
      "[164/1762] D loss: 1.5714, G loss: 0.7288\n",
      "[244/1762] D loss: 1.3948, G loss: 0.7186\n",
      "[324/1762] D loss: 0.4162, G loss: 1.3833\n",
      "[404/1762] D loss: 1.4048, G loss: 0.7002\n",
      "[484/1762] D loss: 1.4040, G loss: 0.7072\n",
      "[564/1762] D loss: 1.3911, G loss: 0.7178\n",
      "[644/1762] D loss: 1.3913, G loss: 0.7082\n",
      "[724/1762] D loss: 1.3962, G loss: 0.7544\n",
      "[804/1762] D loss: 0.3633, G loss: 1.5651\n",
      "[884/1762] D loss: 0.4013, G loss: 1.4900\n",
      "[964/1762] D loss: 0.4038, G loss: 1.5042\n",
      "[1044/1762] D loss: 1.6035, G loss: 0.7332\n",
      "[1124/1762] D loss: 1.3964, G loss: 0.6892\n",
      "[1204/1762] D loss: 1.5882, G loss: 0.8474\n",
      "[1284/1762] D loss: 0.4378, G loss: 1.4836\n",
      "[1364/1762] D loss: 1.3900, G loss: 0.7049\n",
      "[1444/1762] D loss: 0.4966, G loss: 1.4499\n",
      "[1524/1762] D loss: 1.4899, G loss: 0.8084\n",
      "[1604/1762] D loss: 1.3925, G loss: 0.6980\n",
      "[1684/1762] D loss: 1.3991, G loss: 0.7212\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.6816\n",
      "train error: \n",
      " D loss: 1.360306, G loss: 0.701714, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349778, G loss: 0.730336, D accuracy: 53.0%, cell accuracy: 99.6%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.7139\n",
      "[84/1762] D loss: 1.3417, G loss: 0.7026\n",
      "[164/1762] D loss: 1.3897, G loss: 0.6944\n",
      "[244/1762] D loss: 1.3999, G loss: 0.7072\n",
      "[324/1762] D loss: 1.4850, G loss: 0.7356\n",
      "[404/1762] D loss: 0.3394, G loss: 1.5661\n",
      "[484/1762] D loss: 1.4092, G loss: 0.7170\n",
      "[564/1762] D loss: 1.3904, G loss: 0.6894\n",
      "[644/1762] D loss: 0.3979, G loss: 1.6598\n",
      "[724/1762] D loss: 1.5001, G loss: 0.7277\n",
      "[804/1762] D loss: 1.3857, G loss: 0.6944\n",
      "[884/1762] D loss: 0.2632, G loss: 1.9473\n",
      "[964/1762] D loss: 1.3965, G loss: 0.7421\n",
      "[1044/1762] D loss: 1.3944, G loss: 0.7052\n",
      "[1124/1762] D loss: 1.4015, G loss: 0.7193\n",
      "[1204/1762] D loss: 1.4015, G loss: 0.7091\n",
      "[1284/1762] D loss: 0.3548, G loss: 1.6554\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6895\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.7065\n",
      "[1524/1762] D loss: 1.3917, G loss: 0.6959\n",
      "[1604/1762] D loss: 0.2684, G loss: 1.9990\n",
      "[1684/1762] D loss: 0.3871, G loss: 1.7303\n",
      "[1762/1762] D loss: 0.2324, G loss: 2.3715\n",
      "train error: \n",
      " D loss: 1.536726, G loss: 0.406968, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.505461, G loss: 0.428354, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4903, G loss: 0.6231\n",
      "[84/1762] D loss: 1.4235, G loss: 0.6889\n",
      "[164/1762] D loss: 1.4123, G loss: 0.6904\n",
      "[244/1762] D loss: 1.4071, G loss: 0.6593\n",
      "[324/1762] D loss: 0.3864, G loss: 1.4460\n",
      "[404/1762] D loss: 1.3888, G loss: 0.6904\n",
      "[484/1762] D loss: 0.4309, G loss: 1.7337\n",
      "[564/1762] D loss: 0.3854, G loss: 1.7589\n",
      "[644/1762] D loss: 1.3905, G loss: 0.7015\n",
      "[724/1762] D loss: 0.3338, G loss: 1.7092\n",
      "[804/1762] D loss: 1.6350, G loss: 0.8214\n",
      "[884/1762] D loss: 1.4969, G loss: 0.6686\n",
      "[964/1762] D loss: 1.3906, G loss: 0.6971\n",
      "[1044/1762] D loss: 0.2748, G loss: 1.8606\n",
      "[1124/1762] D loss: 1.4330, G loss: 0.7235\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.6991\n",
      "[1284/1762] D loss: 1.4132, G loss: 0.7456\n",
      "[1364/1762] D loss: 0.2419, G loss: 1.9128\n",
      "[1444/1762] D loss: 1.5332, G loss: 0.6457\n",
      "[1524/1762] D loss: 1.4417, G loss: 0.6910\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.6876\n",
      "[1684/1762] D loss: 1.2564, G loss: 0.8377\n",
      "[1762/1762] D loss: 1.6440, G loss: 0.9258\n",
      "train error: \n",
      " D loss: 1.449126, G loss: 1.015829, D accuracy: 51.8%, cell accuracy: 99.7%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.436820, G loss: 1.036202, D accuracy: 52.5%, cell accuracy: 99.6%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4347, G loss: 0.7515\n",
      "[84/1762] D loss: 0.4983, G loss: 1.3743\n",
      "[164/1762] D loss: 0.3229, G loss: 1.8748\n",
      "[244/1762] D loss: 1.2649, G loss: 0.7719\n",
      "[324/1762] D loss: 1.3806, G loss: 0.6958\n",
      "[404/1762] D loss: 1.4088, G loss: 0.6906\n",
      "[484/1762] D loss: 2.3659, G loss: 1.1381\n",
      "[564/1762] D loss: 1.8320, G loss: 1.1792\n",
      "[644/1762] D loss: 1.4397, G loss: 0.6319\n",
      "[724/1762] D loss: 1.3908, G loss: 0.7300\n",
      "[804/1762] D loss: 1.3837, G loss: 0.6814\n",
      "[884/1762] D loss: 1.4055, G loss: 0.7104\n",
      "[964/1762] D loss: 1.2259, G loss: 1.2047\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.7287\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.6549\n",
      "[1204/1762] D loss: 1.2393, G loss: 0.8695\n",
      "[1284/1762] D loss: 1.3845, G loss: 0.7098\n",
      "[1364/1762] D loss: 1.3833, G loss: 0.7182\n",
      "[1444/1762] D loss: 0.4471, G loss: 1.4051\n",
      "[1524/1762] D loss: 0.4255, G loss: 1.6805\n",
      "[1604/1762] D loss: 1.3913, G loss: 0.7270\n",
      "[1684/1762] D loss: 1.4291, G loss: 0.6896\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6975\n",
      "train error: \n",
      " D loss: 1.380010, G loss: 0.782778, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374765, G loss: 0.786919, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3591, G loss: 1.8567\n",
      "[84/1762] D loss: 1.3596, G loss: 0.7335\n",
      "[164/1762] D loss: 1.3974, G loss: 0.7425\n",
      "[244/1762] D loss: 1.5784, G loss: 0.4602\n",
      "[324/1762] D loss: 1.6155, G loss: 0.8350\n",
      "[404/1762] D loss: 1.4082, G loss: 0.7592\n",
      "[484/1762] D loss: 1.2583, G loss: 0.7998\n",
      "[564/1762] D loss: 1.4113, G loss: 0.7487\n",
      "[644/1762] D loss: 1.4684, G loss: 0.6723\n",
      "[724/1762] D loss: 1.4290, G loss: 0.7060\n",
      "[804/1762] D loss: 1.1288, G loss: 0.8216\n",
      "[884/1762] D loss: 1.3905, G loss: 0.7240\n",
      "[964/1762] D loss: 1.3438, G loss: 0.7934\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6926\n",
      "[1124/1762] D loss: 1.3659, G loss: 0.6381\n",
      "[1204/1762] D loss: 1.4542, G loss: 0.7461\n",
      "[1284/1762] D loss: 0.4988, G loss: 1.5046\n",
      "[1364/1762] D loss: 1.4133, G loss: 0.7390\n",
      "[1444/1762] D loss: 0.6605, G loss: 1.4856\n",
      "[1524/1762] D loss: 1.4138, G loss: 0.6998\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.6769\n",
      "[1684/1762] D loss: 1.3032, G loss: 0.7735\n",
      "[1762/1762] D loss: 1.4329, G loss: 0.7287\n",
      "train error: \n",
      " D loss: 1.346934, G loss: 0.933689, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 73.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342089, G loss: 0.937998, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8039, G loss: 1.1918\n",
      "[84/1762] D loss: 1.4139, G loss: 0.7661\n",
      "[164/1762] D loss: 1.5304, G loss: 0.9441\n",
      "[244/1762] D loss: 0.9988, G loss: 0.8820\n",
      "[324/1762] D loss: 1.3953, G loss: 0.7262\n",
      "[404/1762] D loss: 1.4128, G loss: 0.7787\n",
      "[484/1762] D loss: 1.4701, G loss: 0.8199\n",
      "[564/1762] D loss: 1.3963, G loss: 0.7604\n",
      "[644/1762] D loss: 1.7783, G loss: 0.8662\n",
      "[724/1762] D loss: 1.2498, G loss: 1.0089\n",
      "[804/1762] D loss: 1.4026, G loss: 0.6529\n",
      "[884/1762] D loss: 1.2810, G loss: 0.8026\n",
      "[964/1762] D loss: 1.3684, G loss: 0.7227\n",
      "[1044/1762] D loss: 1.3838, G loss: 0.7124\n",
      "[1124/1762] D loss: 1.3369, G loss: 0.6624\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6673\n",
      "[1284/1762] D loss: 1.4085, G loss: 0.6409\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.6806\n",
      "[1444/1762] D loss: 1.3888, G loss: 0.6780\n",
      "[1524/1762] D loss: 1.3095, G loss: 0.7621\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6808\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6930\n",
      "[1762/1762] D loss: 1.3993, G loss: 0.6972\n",
      "train error: \n",
      " D loss: 1.368911, G loss: 0.677129, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350940, G loss: 0.680825, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905, G loss: 0.6020\n",
      "[84/1762] D loss: 0.4301, G loss: 1.5194\n",
      "[164/1762] D loss: 0.8947, G loss: 1.1850\n",
      "[244/1762] D loss: 1.4118, G loss: 0.6497\n",
      "[324/1762] D loss: 1.3861, G loss: 0.6894\n",
      "[404/1762] D loss: 1.3909, G loss: 0.6716\n",
      "[484/1762] D loss: 1.3886, G loss: 0.6891\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6794\n",
      "[644/1762] D loss: 1.3908, G loss: 0.7023\n",
      "[724/1762] D loss: 1.4014, G loss: 0.6636\n",
      "[804/1762] D loss: 1.3918, G loss: 0.6615\n",
      "[884/1762] D loss: 1.2824, G loss: 0.7891\n",
      "[964/1762] D loss: 1.1370, G loss: 0.9530\n",
      "[1044/1762] D loss: 0.9746, G loss: 1.1459\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.8591\n",
      "[1204/1762] D loss: 1.3750, G loss: 0.6886\n",
      "[1284/1762] D loss: 1.3902, G loss: 0.6929\n",
      "[1364/1762] D loss: 1.3947, G loss: 0.6645\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.7085\n",
      "[1524/1762] D loss: 1.4070, G loss: 0.7511\n",
      "[1604/1762] D loss: 1.4300, G loss: 0.7330\n",
      "[1684/1762] D loss: 1.3966, G loss: 0.7365\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7059\n",
      "train error: \n",
      " D loss: 1.330750, G loss: 0.757089, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308768, G loss: 0.769896, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5142, G loss: 0.7161\n",
      "[84/1762] D loss: 1.3905, G loss: 0.6831\n",
      "[164/1762] D loss: 1.4072, G loss: 0.7468\n",
      "[244/1762] D loss: 1.5408, G loss: 0.9326\n",
      "[324/1762] D loss: 1.3894, G loss: 0.6958\n",
      "[404/1762] D loss: 1.3996, G loss: 0.6942\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6954\n",
      "[564/1762] D loss: 1.4482, G loss: 0.8658\n",
      "[644/1762] D loss: 1.3201, G loss: 0.8725\n",
      "[724/1762] D loss: 1.3960, G loss: 0.7008\n",
      "[804/1762] D loss: 1.4118, G loss: 0.6663\n",
      "[884/1762] D loss: 1.3916, G loss: 0.6789\n",
      "[964/1762] D loss: 1.3929, G loss: 0.7314\n",
      "[1044/1762] D loss: 1.1480, G loss: 0.9278\n",
      "[1124/1762] D loss: 1.3983, G loss: 0.7503\n",
      "[1204/1762] D loss: 1.2870, G loss: 0.6200\n",
      "[1284/1762] D loss: 1.4059, G loss: 0.7815\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.7065\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7116\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.6909\n",
      "[1604/1762] D loss: 1.3520, G loss: 0.9424\n",
      "[1684/1762] D loss: 1.3958, G loss: 0.7738\n",
      "[1762/1762] D loss: 1.3953, G loss: 0.7460\n",
      "train error: \n",
      " D loss: 1.332596, G loss: 0.780597, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307557, G loss: 0.807888, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3888, G loss: 0.7083\n",
      "[84/1762] D loss: 1.3928, G loss: 0.7271\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6910\n",
      "[244/1762] D loss: 1.3923, G loss: 0.7208\n",
      "[324/1762] D loss: 1.3870, G loss: 0.7083\n",
      "[404/1762] D loss: 0.6779, G loss: 1.6074\n",
      "[484/1762] D loss: 1.3963, G loss: 0.7658\n",
      "[564/1762] D loss: 1.4079, G loss: 0.7618\n",
      "[644/1762] D loss: 1.4129, G loss: 0.7562\n",
      "[724/1762] D loss: 1.3929, G loss: 0.7052\n",
      "[804/1762] D loss: 0.9800, G loss: 1.0785\n",
      "[884/1762] D loss: 1.2988, G loss: 0.5896\n",
      "[964/1762] D loss: 1.3884, G loss: 0.7145\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6876\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.7013\n",
      "[1204/1762] D loss: 1.4092, G loss: 0.7186\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.7227\n",
      "[1364/1762] D loss: 1.4584, G loss: 0.8732\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6842\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6649\n",
      "[1604/1762] D loss: 1.1289, G loss: 0.6533\n",
      "[1684/1762] D loss: 1.3899, G loss: 0.6879\n",
      "[1762/1762] D loss: 1.4356, G loss: 0.7673\n",
      "train error: \n",
      " D loss: 1.366071, G loss: 0.672026, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346427, G loss: 0.668194, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3986, G loss: 0.6510\n",
      "[84/1762] D loss: 1.3991, G loss: 0.7705\n",
      "[164/1762] D loss: 1.4006, G loss: 0.7277\n",
      "[244/1762] D loss: 0.8255, G loss: 0.7707\n",
      "[324/1762] D loss: 1.3928, G loss: 0.7482\n",
      "[404/1762] D loss: 0.6654, G loss: 1.0537\n",
      "[484/1762] D loss: 1.4199, G loss: 0.8050\n",
      "[564/1762] D loss: 1.4062, G loss: 0.7708\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6805\n",
      "[724/1762] D loss: 1.3925, G loss: 0.7439\n",
      "[804/1762] D loss: 1.4004, G loss: 0.7777\n",
      "[884/1762] D loss: 1.3937, G loss: 0.6756\n",
      "[964/1762] D loss: 1.3938, G loss: 0.7356\n",
      "[1044/1762] D loss: 1.1306, G loss: 1.1721\n",
      "[1124/1762] D loss: 1.3928, G loss: 0.7111\n",
      "[1204/1762] D loss: 1.3957, G loss: 0.6792\n",
      "[1284/1762] D loss: 0.5898, G loss: 1.4129\n",
      "[1364/1762] D loss: 1.3938, G loss: 0.7169\n",
      "[1444/1762] D loss: 0.3527, G loss: 1.6809\n",
      "[1524/1762] D loss: 1.3793, G loss: 0.7630\n",
      "[1604/1762] D loss: 1.7905, G loss: 1.2335\n",
      "[1684/1762] D loss: 1.4028, G loss: 0.6864\n",
      "[1762/1762] D loss: 0.6082, G loss: 0.9089\n",
      "train error: \n",
      " D loss: 1.366905, G loss: 0.736151, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356033, G loss: 0.733839, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6693\n",
      "[84/1762] D loss: 1.3894, G loss: 0.6706\n",
      "[164/1762] D loss: 1.3889, G loss: 0.7130\n",
      "[244/1762] D loss: 1.3980, G loss: 0.7906\n",
      "[324/1762] D loss: 1.2312, G loss: 0.9635\n",
      "[404/1762] D loss: 1.4775, G loss: 0.8242\n",
      "[484/1762] D loss: 1.3917, G loss: 0.7023\n",
      "[564/1762] D loss: 1.3916, G loss: 0.7232\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6695\n",
      "[724/1762] D loss: 1.4104, G loss: 0.6596\n",
      "[804/1762] D loss: 0.3891, G loss: 1.2505\n",
      "[884/1762] D loss: 1.3951, G loss: 0.6976\n",
      "[964/1762] D loss: 1.3952, G loss: 0.7839\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.6982\n",
      "[1124/1762] D loss: 1.4025, G loss: 0.7571\n",
      "[1204/1762] D loss: 0.5086, G loss: 1.2574\n",
      "[1284/1762] D loss: 1.4618, G loss: 0.7626\n",
      "[1364/1762] D loss: 1.6401, G loss: 1.1445\n",
      "[1444/1762] D loss: 1.3402, G loss: 0.9053\n",
      "[1524/1762] D loss: 1.4344, G loss: 0.8184\n",
      "[1604/1762] D loss: 1.4033, G loss: 0.6988\n",
      "[1684/1762] D loss: 0.6353, G loss: 1.1075\n",
      "[1762/1762] D loss: 1.4049, G loss: 0.8082\n",
      "train error: \n",
      " D loss: 1.388047, G loss: 0.795845, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369205, G loss: 0.825114, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8934, G loss: 0.9334\n",
      "[84/1762] D loss: 1.3926, G loss: 0.7907\n",
      "[164/1762] D loss: 1.3896, G loss: 0.7143\n",
      "[244/1762] D loss: 1.3951, G loss: 0.6906\n",
      "[324/1762] D loss: 1.3967, G loss: 0.7588\n",
      "[404/1762] D loss: 1.3890, G loss: 0.6514\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6985\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7299\n",
      "[644/1762] D loss: 1.3902, G loss: 0.6698\n",
      "[724/1762] D loss: 1.4200, G loss: 0.8603\n",
      "[804/1762] D loss: 1.2148, G loss: 0.9222\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6863\n",
      "[964/1762] D loss: 1.0096, G loss: 1.3274\n",
      "[1044/1762] D loss: 1.3070, G loss: 0.8183\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6683\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.6815\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6661\n",
      "[1364/1762] D loss: 1.4032, G loss: 0.6497\n",
      "[1444/1762] D loss: 1.3943, G loss: 0.6987\n",
      "[1524/1762] D loss: 1.3898, G loss: 0.7082\n",
      "[1604/1762] D loss: 1.3959, G loss: 0.7421\n",
      "[1684/1762] D loss: 1.3994, G loss: 0.7656\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.7171\n",
      "train error: \n",
      " D loss: 1.424360, G loss: 0.999943, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.406139, G loss: 1.044896, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5235, G loss: 1.2073\n",
      "[84/1762] D loss: 1.4502, G loss: 0.8967\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6957\n",
      "[244/1762] D loss: 1.3984, G loss: 0.7788\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6900\n",
      "[404/1762] D loss: 1.3899, G loss: 0.7067\n",
      "[484/1762] D loss: 1.3974, G loss: 0.7418\n",
      "[564/1762] D loss: 0.4354, G loss: 1.4432\n",
      "[644/1762] D loss: 0.4448, G loss: 1.4597\n",
      "[724/1762] D loss: 0.4087, G loss: 1.4181\n",
      "[804/1762] D loss: 1.4100, G loss: 0.8403\n",
      "[884/1762] D loss: 1.3929, G loss: 0.7392\n",
      "[964/1762] D loss: 1.3916, G loss: 0.7206\n",
      "[1044/1762] D loss: 0.4347, G loss: 1.3721\n",
      "[1124/1762] D loss: 1.3983, G loss: 0.7260\n",
      "[1204/1762] D loss: 1.4208, G loss: 0.8226\n",
      "[1284/1762] D loss: 0.4393, G loss: 1.3511\n",
      "[1364/1762] D loss: 1.4074, G loss: 0.7738\n",
      "[1444/1762] D loss: 1.3914, G loss: 0.7144\n",
      "[1524/1762] D loss: 1.4546, G loss: 0.8757\n",
      "[1604/1762] D loss: 0.3984, G loss: 1.5947\n",
      "[1684/1762] D loss: 1.5074, G loss: 0.9607\n",
      "[1762/1762] D loss: 0.2004, G loss: 1.8088\n",
      "train error: \n",
      " D loss: 1.805915, G loss: 0.330438, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.737771, G loss: 0.371791, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4125, G loss: 0.7729\n",
      "[84/1762] D loss: 0.3165, G loss: 1.8629\n",
      "[164/1762] D loss: 1.4643, G loss: 0.8238\n",
      "[244/1762] D loss: 1.3994, G loss: 0.7325\n",
      "[324/1762] D loss: 1.4321, G loss: 0.9110\n",
      "[404/1762] D loss: 1.3819, G loss: 0.7301\n",
      "[484/1762] D loss: 0.4454, G loss: 1.2799\n",
      "[564/1762] D loss: 0.4324, G loss: 1.3875\n",
      "[644/1762] D loss: 1.4622, G loss: 0.8529\n",
      "[724/1762] D loss: 1.4365, G loss: 0.8139\n",
      "[804/1762] D loss: 1.5375, G loss: 0.8331\n",
      "[884/1762] D loss: 0.4572, G loss: 1.4434\n",
      "[964/1762] D loss: 1.3956, G loss: 0.7093\n",
      "[1044/1762] D loss: 1.4251, G loss: 0.7291\n",
      "[1124/1762] D loss: 1.3508, G loss: 0.7907\n",
      "[1204/1762] D loss: 1.3907, G loss: 0.7076\n",
      "[1284/1762] D loss: 0.5752, G loss: 1.3056\n",
      "[1364/1762] D loss: 0.2902, G loss: 1.7462\n",
      "[1444/1762] D loss: 1.3923, G loss: 0.7131\n",
      "[1524/1762] D loss: 1.4184, G loss: 0.7616\n",
      "[1604/1762] D loss: 1.3942, G loss: 0.7156\n",
      "[1684/1762] D loss: 1.4057, G loss: 0.7243\n",
      "[1762/1762] D loss: 1.6164, G loss: 0.8727\n",
      "train error: \n",
      " D loss: 1.441382, G loss: 0.658312, D accuracy: 49.3%, cell accuracy: 99.7%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.447464, G loss: 0.676962, D accuracy: 49.4%, cell accuracy: 99.5%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4759, G loss: 0.8345\n",
      "[84/1762] D loss: 1.3882, G loss: 0.6875\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6940\n",
      "[244/1762] D loss: 1.4244, G loss: 0.7212\n",
      "[324/1762] D loss: 0.2419, G loss: 2.1688\n",
      "[404/1762] D loss: 1.4208, G loss: 0.7367\n",
      "[484/1762] D loss: 1.4544, G loss: 1.1330\n",
      "[564/1762] D loss: 0.2241, G loss: 1.8979\n",
      "[644/1762] D loss: 1.3996, G loss: 0.6459\n",
      "[724/1762] D loss: 1.3996, G loss: 0.6898\n",
      "[804/1762] D loss: 1.4064, G loss: 0.7058\n",
      "[884/1762] D loss: 1.4027, G loss: 0.7192\n",
      "[964/1762] D loss: 1.3967, G loss: 0.7028\n",
      "[1044/1762] D loss: 0.2875, G loss: 1.8050\n",
      "[1124/1762] D loss: 1.3937, G loss: 0.6942\n",
      "[1204/1762] D loss: 0.4108, G loss: 1.5444\n",
      "[1284/1762] D loss: 1.3987, G loss: 0.6964\n",
      "[1364/1762] D loss: 1.3677, G loss: 0.8650\n",
      "[1444/1762] D loss: 1.3917, G loss: 0.6363\n",
      "[1524/1762] D loss: 0.4244, G loss: 1.7399\n",
      "[1604/1762] D loss: 1.4499, G loss: 0.7035\n",
      "[1684/1762] D loss: 1.3970, G loss: 0.7169\n",
      "[1762/1762] D loss: 1.4056, G loss: 0.6669\n",
      "train error: \n",
      " D loss: 1.392009, G loss: 0.695423, D accuracy: 51.7%, cell accuracy: 99.7%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400229, G loss: 0.704558, D accuracy: 52.2%, cell accuracy: 99.6%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2732, G loss: 1.9443\n",
      "[84/1762] D loss: 1.4269, G loss: 0.7273\n",
      "[164/1762] D loss: 0.3313, G loss: 1.7725\n",
      "[244/1762] D loss: 1.5494, G loss: 0.8162\n",
      "[324/1762] D loss: 1.3890, G loss: 0.6971\n",
      "[404/1762] D loss: 1.4698, G loss: 0.6699\n",
      "[484/1762] D loss: 1.4447, G loss: 0.7550\n",
      "[564/1762] D loss: 1.4576, G loss: 0.7175\n",
      "[644/1762] D loss: 1.3934, G loss: 0.6847\n",
      "[724/1762] D loss: 0.3045, G loss: 1.8048\n",
      "[804/1762] D loss: 1.4044, G loss: 0.6436\n",
      "[884/1762] D loss: 1.4739, G loss: 0.6935\n",
      "[964/1762] D loss: 1.4071, G loss: 0.7513\n",
      "[1044/1762] D loss: 1.4928, G loss: 0.6675\n",
      "[1124/1762] D loss: 0.2882, G loss: 1.9336\n",
      "[1204/1762] D loss: 1.3911, G loss: 0.7143\n",
      "[1284/1762] D loss: 0.1938, G loss: 2.6714\n",
      "[1364/1762] D loss: 1.4816, G loss: 0.6225\n",
      "[1444/1762] D loss: 0.1952, G loss: 2.3579\n",
      "[1524/1762] D loss: 1.4002, G loss: 0.6876\n",
      "[1604/1762] D loss: 0.2976, G loss: 1.7471\n",
      "[1684/1762] D loss: 0.2596, G loss: 2.0496\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.6957\n",
      "train error: \n",
      " D loss: 1.407055, G loss: 0.901990, D accuracy: 51.4%, cell accuracy: 99.7%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.414746, G loss: 0.946207, D accuracy: 52.5%, cell accuracy: 99.6%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3082, G loss: 1.8383\n",
      "[84/1762] D loss: 1.4806, G loss: 0.8568\n",
      "[164/1762] D loss: 0.1929, G loss: 2.3972\n",
      "[244/1762] D loss: 1.4021, G loss: 0.6897\n",
      "[324/1762] D loss: 0.2637, G loss: 2.0688\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7054\n",
      "[484/1762] D loss: 1.3883, G loss: 0.7102\n",
      "[564/1762] D loss: 1.3965, G loss: 0.6829\n",
      "[644/1762] D loss: 0.4609, G loss: 1.7560\n",
      "[724/1762] D loss: 0.3678, G loss: 1.7733\n",
      "[804/1762] D loss: 0.3558, G loss: 1.7216\n",
      "[884/1762] D loss: 1.3701, G loss: 1.0361\n",
      "[964/1762] D loss: 1.3971, G loss: 0.7210\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.7038\n",
      "[1124/1762] D loss: 1.6768, G loss: 0.6601\n",
      "[1204/1762] D loss: 0.4247, G loss: 1.7305\n",
      "[1284/1762] D loss: 1.3570, G loss: 0.7624\n",
      "[1364/1762] D loss: 1.3990, G loss: 0.7244\n",
      "[1444/1762] D loss: 1.7152, G loss: 0.4475\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.6929\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7082\n",
      "[1684/1762] D loss: 1.4035, G loss: 0.7744\n",
      "[1762/1762] D loss: 1.4646, G loss: 0.5165\n",
      "train error: \n",
      " D loss: 1.453664, G loss: 0.577864, D accuracy: 51.7%, cell accuracy: 99.7%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.469189, G loss: 0.600922, D accuracy: 52.4%, cell accuracy: 99.5%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4083, G loss: 0.6812\n",
      "[84/1762] D loss: 1.5482, G loss: 0.7323\n",
      "[164/1762] D loss: 0.3787, G loss: 1.8337\n",
      "[244/1762] D loss: 1.3915, G loss: 0.6888\n",
      "[324/1762] D loss: 0.2503, G loss: 2.1360\n",
      "[404/1762] D loss: 1.4536, G loss: 0.7118\n",
      "[484/1762] D loss: 1.3981, G loss: 0.7022\n",
      "[564/1762] D loss: 1.4534, G loss: 0.7905\n",
      "[644/1762] D loss: 0.3548, G loss: 2.0324\n",
      "[724/1762] D loss: 1.3874, G loss: 0.7007\n",
      "[804/1762] D loss: 1.3613, G loss: 0.8085\n",
      "[884/1762] D loss: 0.2934, G loss: 2.0216\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7052\n",
      "[1044/1762] D loss: 1.2574, G loss: 1.2478\n",
      "[1124/1762] D loss: 1.3718, G loss: 0.7097\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.7005\n",
      "[1284/1762] D loss: 1.3427, G loss: 0.7999\n",
      "[1364/1762] D loss: 1.3768, G loss: 0.8595\n",
      "[1444/1762] D loss: 0.1673, G loss: 2.5561\n",
      "[1524/1762] D loss: 1.3948, G loss: 0.7426\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.6909\n",
      "[1684/1762] D loss: 1.5245, G loss: 0.6933\n",
      "[1762/1762] D loss: 1.6702, G loss: 0.5827\n",
      "train error: \n",
      " D loss: 1.800060, G loss: 0.297902, D accuracy: 49.5%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.812310, G loss: 0.304853, D accuracy: 49.4%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5302, G loss: 1.8475\n",
      "[84/1762] D loss: 1.3882, G loss: 0.6912\n",
      "[164/1762] D loss: 1.3963, G loss: 0.6946\n",
      "[244/1762] D loss: 1.4113, G loss: 0.7000\n",
      "[324/1762] D loss: 1.4153, G loss: 0.6977\n",
      "[404/1762] D loss: 1.3188, G loss: 0.8258\n",
      "[484/1762] D loss: 0.1481, G loss: 2.6778\n",
      "[564/1762] D loss: 1.5532, G loss: 0.6385\n",
      "[644/1762] D loss: 1.4711, G loss: 0.6870\n",
      "[724/1762] D loss: 1.0748, G loss: 1.0701\n",
      "[804/1762] D loss: 1.6670, G loss: 3.2042\n",
      "[884/1762] D loss: 1.4228, G loss: 0.8351\n",
      "[964/1762] D loss: 1.4771, G loss: 0.7844\n",
      "[1044/1762] D loss: 1.3368, G loss: 0.7283\n",
      "[1124/1762] D loss: 1.3960, G loss: 0.7208\n",
      "[1204/1762] D loss: 1.3995, G loss: 0.6827\n",
      "[1284/1762] D loss: 0.4023, G loss: 2.1655\n",
      "[1364/1762] D loss: 1.4170, G loss: 0.5508\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7266\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.6838\n",
      "[1604/1762] D loss: 0.1441, G loss: 2.6574\n",
      "[1684/1762] D loss: 0.3913, G loss: 2.0265\n",
      "[1762/1762] D loss: 1.4848, G loss: 0.6598\n",
      "train error: \n",
      " D loss: 1.490674, G loss: 0.552082, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.491694, G loss: 0.600219, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4012, G loss: 0.7020\n",
      "[84/1762] D loss: 1.3012, G loss: 0.8227\n",
      "[164/1762] D loss: 1.6633, G loss: 0.7275\n",
      "[244/1762] D loss: 1.4056, G loss: 0.7506\n",
      "[324/1762] D loss: 0.2391, G loss: 2.4557\n",
      "[404/1762] D loss: 0.3262, G loss: 1.9067\n",
      "[484/1762] D loss: 1.4108, G loss: 0.6841\n",
      "[564/1762] D loss: 1.5055, G loss: 0.5871\n",
      "[644/1762] D loss: 1.3973, G loss: 0.6983\n",
      "[724/1762] D loss: 0.2940, G loss: 2.1724\n",
      "[804/1762] D loss: 1.2978, G loss: 0.7074\n",
      "[884/1762] D loss: 1.3958, G loss: 0.6952\n",
      "[964/1762] D loss: 1.3199, G loss: 0.8058\n",
      "[1044/1762] D loss: 1.3970, G loss: 0.7117\n",
      "[1124/1762] D loss: 1.3366, G loss: 0.7179\n",
      "[1204/1762] D loss: 1.3737, G loss: 0.7119\n",
      "[1284/1762] D loss: 1.4138, G loss: 0.6908\n",
      "[1364/1762] D loss: 1.4016, G loss: 0.6922\n",
      "[1444/1762] D loss: 1.4399, G loss: 0.6560\n",
      "[1524/1762] D loss: 1.4918, G loss: 0.6524\n",
      "[1604/1762] D loss: 0.4895, G loss: 2.0525\n",
      "[1684/1762] D loss: 0.2521, G loss: 2.5350\n",
      "[1762/1762] D loss: 1.4694, G loss: 0.6406\n",
      "train error: \n",
      " D loss: 1.377089, G loss: 0.936505, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383729, G loss: 0.969899, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4041, G loss: 1.6420\n",
      "[84/1762] D loss: 1.4044, G loss: 0.7217\n",
      "[164/1762] D loss: 1.3846, G loss: 0.6993\n",
      "[244/1762] D loss: 0.1251, G loss: 3.4186\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6930\n",
      "[404/1762] D loss: 1.3961, G loss: 0.6608\n",
      "[484/1762] D loss: 1.4204, G loss: 0.7150\n",
      "[564/1762] D loss: 0.4001, G loss: 1.9985\n",
      "[644/1762] D loss: 1.4037, G loss: 0.7110\n",
      "[724/1762] D loss: 1.5158, G loss: 0.7184\n",
      "[804/1762] D loss: 1.0501, G loss: 1.3946\n",
      "[884/1762] D loss: 1.4204, G loss: 0.7364\n",
      "[964/1762] D loss: 1.5150, G loss: 0.6550\n",
      "[1044/1762] D loss: 1.4328, G loss: 0.6147\n",
      "[1124/1762] D loss: 1.4127, G loss: 0.6616\n",
      "[1204/1762] D loss: 0.3539, G loss: 2.1349\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.6821\n",
      "[1364/1762] D loss: 1.5634, G loss: 1.1282\n",
      "[1444/1762] D loss: 0.2416, G loss: 2.5537\n",
      "[1524/1762] D loss: 1.4212, G loss: 0.7073\n",
      "[1604/1762] D loss: 1.4335, G loss: 0.6448\n",
      "[1684/1762] D loss: 1.4023, G loss: 0.6645\n",
      "[1762/1762] D loss: 1.5430, G loss: 0.4916\n",
      "train error: \n",
      " D loss: 1.642260, G loss: 0.468215, D accuracy: 51.7%, cell accuracy: 99.6%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.611488, G loss: 0.535304, D accuracy: 52.4%, cell accuracy: 99.5%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4672, G loss: 2.0483\n",
      "[84/1762] D loss: 0.2962, G loss: 2.2004\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7129\n",
      "[244/1762] D loss: 1.3926, G loss: 0.7118\n",
      "[324/1762] D loss: 1.4530, G loss: 0.7353\n",
      "[404/1762] D loss: 0.0697, G loss: 3.4511\n",
      "[484/1762] D loss: 0.3911, G loss: 2.0660\n",
      "[564/1762] D loss: 1.4083, G loss: 0.6736\n",
      "[644/1762] D loss: 1.3980, G loss: 0.7137\n",
      "[724/1762] D loss: 1.5799, G loss: 0.7708\n",
      "[804/1762] D loss: 1.4256, G loss: 0.8282\n",
      "[884/1762] D loss: 1.3886, G loss: 0.6908\n",
      "[964/1762] D loss: 0.3416, G loss: 2.2083\n",
      "[1044/1762] D loss: 1.5285, G loss: 0.6254\n",
      "[1124/1762] D loss: 1.6092, G loss: 0.7267\n",
      "[1204/1762] D loss: 1.4044, G loss: 0.7281\n",
      "[1284/1762] D loss: 1.4114, G loss: 0.6928\n",
      "[1364/1762] D loss: 0.4095, G loss: 2.2460\n",
      "[1444/1762] D loss: 1.4044, G loss: 0.6893\n",
      "[1524/1762] D loss: 0.9927, G loss: 1.3623\n",
      "[1604/1762] D loss: 1.3943, G loss: 0.6940\n",
      "[1684/1762] D loss: 0.3167, G loss: 2.0210\n",
      "[1762/1762] D loss: 1.4306, G loss: 0.5735\n",
      "train error: \n",
      " D loss: 1.432143, G loss: 0.703571, D accuracy: 52.1%, cell accuracy: 99.7%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.439451, G loss: 0.729602, D accuracy: 53.2%, cell accuracy: 99.6%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4088, G loss: 0.6819\n",
      "[84/1762] D loss: 1.3990, G loss: 0.7007\n",
      "[164/1762] D loss: 1.4514, G loss: 0.7675\n",
      "[244/1762] D loss: 0.2095, G loss: 2.9829\n",
      "[324/1762] D loss: 1.3947, G loss: 0.6725\n",
      "[404/1762] D loss: 1.3827, G loss: 0.6798\n",
      "[484/1762] D loss: 1.5190, G loss: 0.6983\n",
      "[564/1762] D loss: 1.7443, G loss: 0.7338\n",
      "[644/1762] D loss: 1.4746, G loss: 0.5118\n",
      "[724/1762] D loss: 0.0438, G loss: 4.3811\n",
      "[804/1762] D loss: 1.3863, G loss: 0.7008\n",
      "[884/1762] D loss: 1.3985, G loss: 0.7114\n",
      "[964/1762] D loss: 1.3896, G loss: 0.7174\n",
      "[1044/1762] D loss: 1.3952, G loss: 0.6993\n",
      "[1124/1762] D loss: 1.4156, G loss: 0.6711\n",
      "[1204/1762] D loss: 1.3111, G loss: 0.7576\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.7022\n",
      "[1364/1762] D loss: 1.6623, G loss: 0.6965\n",
      "[1444/1762] D loss: 1.4442, G loss: 0.6346\n",
      "[1524/1762] D loss: 0.3101, G loss: 2.1307\n",
      "[1604/1762] D loss: 1.3970, G loss: 0.7034\n",
      "[1684/1762] D loss: 1.4235, G loss: 0.6807\n",
      "[1762/1762] D loss: 1.3929, G loss: 0.7199\n",
      "train error: \n",
      " D loss: 1.392679, G loss: 0.854534, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401999, G loss: 0.929302, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.7009\n",
      "[84/1762] D loss: 0.4228, G loss: 1.7883\n",
      "[164/1762] D loss: 1.3041, G loss: 0.7225\n",
      "[244/1762] D loss: 1.3958, G loss: 0.6998\n",
      "[324/1762] D loss: 0.2907, G loss: 2.3507\n",
      "[404/1762] D loss: 1.3762, G loss: 0.7306\n",
      "[484/1762] D loss: 0.0825, G loss: 2.9632\n",
      "[564/1762] D loss: 1.3878, G loss: 0.6901\n",
      "[644/1762] D loss: 1.3915, G loss: 0.6537\n",
      "[724/1762] D loss: 1.3604, G loss: 0.8434\n",
      "[804/1762] D loss: 0.2159, G loss: 2.4097\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6858\n",
      "[964/1762] D loss: 1.5360, G loss: 0.9970\n",
      "[1044/1762] D loss: 0.5657, G loss: 2.1907\n",
      "[1124/1762] D loss: 1.4133, G loss: 0.6933\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6876\n",
      "[1284/1762] D loss: 1.4146, G loss: 0.7130\n",
      "[1364/1762] D loss: 1.4078, G loss: 0.6991\n",
      "[1444/1762] D loss: 1.3847, G loss: 0.7013\n",
      "[1524/1762] D loss: 1.4065, G loss: 0.6747\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.6967\n",
      "[1684/1762] D loss: 1.3981, G loss: 0.6440\n",
      "[1762/1762] D loss: 1.4101, G loss: 0.6113\n",
      "train error: \n",
      " D loss: 1.599370, G loss: 0.643895, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.638917, G loss: 0.680968, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4319, G loss: 0.7337\n",
      "[84/1762] D loss: 1.2630, G loss: 1.0214\n",
      "[164/1762] D loss: 1.4106, G loss: 0.6757\n",
      "[244/1762] D loss: 1.4060, G loss: 0.6853\n",
      "[324/1762] D loss: 1.3963, G loss: 0.6931\n",
      "[404/1762] D loss: 1.3903, G loss: 0.6805\n",
      "[484/1762] D loss: 1.4307, G loss: 0.6342\n",
      "[564/1762] D loss: 0.3391, G loss: 2.7990\n",
      "[644/1762] D loss: 1.3854, G loss: 0.6994\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6906\n",
      "[804/1762] D loss: 1.3519, G loss: 0.8382\n",
      "[884/1762] D loss: 1.4594, G loss: 0.6409\n",
      "[964/1762] D loss: 1.6383, G loss: 0.5778\n",
      "[1044/1762] D loss: 0.2386, G loss: 2.6832\n",
      "[1124/1762] D loss: 0.2730, G loss: 2.8723\n",
      "[1204/1762] D loss: 0.3439, G loss: 2.4866\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6999\n",
      "[1364/1762] D loss: 1.6076, G loss: 0.6480\n",
      "[1444/1762] D loss: 1.4908, G loss: 0.7229\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6901\n",
      "[1604/1762] D loss: 1.5241, G loss: 0.9990\n",
      "[1684/1762] D loss: 1.4083, G loss: 0.7041\n",
      "[1762/1762] D loss: 1.4117, G loss: 0.7498\n",
      "train error: \n",
      " D loss: 1.632512, G loss: 0.873616, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.670295, G loss: 0.935743, D accuracy: 51.0%, cell accuracy: 99.5%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1582, G loss: 2.5528\n",
      "[84/1762] D loss: 1.4145, G loss: 0.6576\n",
      "[164/1762] D loss: 1.3377, G loss: 1.2011\n",
      "[244/1762] D loss: 1.4193, G loss: 0.7165\n",
      "[324/1762] D loss: 1.3913, G loss: 0.7013\n",
      "[404/1762] D loss: 0.3201, G loss: 2.6331\n",
      "[484/1762] D loss: 0.1013, G loss: 3.0927\n",
      "[564/1762] D loss: 1.4042, G loss: 0.6948\n",
      "[644/1762] D loss: 0.2287, G loss: 2.4471\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6854\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6947\n",
      "[884/1762] D loss: 1.5566, G loss: 0.5157\n",
      "[964/1762] D loss: 0.3716, G loss: 2.3261\n",
      "[1044/1762] D loss: 1.4695, G loss: 0.7739\n",
      "[1124/1762] D loss: 0.2303, G loss: 2.5918\n",
      "[1204/1762] D loss: 1.3825, G loss: 0.7222\n",
      "[1284/1762] D loss: 1.4769, G loss: 0.6549\n",
      "[1364/1762] D loss: 1.1223, G loss: 1.5565\n",
      "[1444/1762] D loss: 1.3946, G loss: 0.6872\n",
      "[1524/1762] D loss: 0.3712, G loss: 2.3945\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.6846\n",
      "[1684/1762] D loss: 1.3546, G loss: 0.7960\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.6422\n",
      "train error: \n",
      " D loss: 2.768917, G loss: 0.137834, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.772015, G loss: 0.160545, D accuracy: 50.5%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4630, G loss: 0.6294\n",
      "[84/1762] D loss: 1.4480, G loss: 0.6250\n",
      "[164/1762] D loss: 0.2385, G loss: 2.4085\n",
      "[244/1762] D loss: 1.3403, G loss: 0.8933\n",
      "[324/1762] D loss: 1.4307, G loss: 0.7006\n",
      "[404/1762] D loss: 1.3945, G loss: 0.7162\n",
      "[484/1762] D loss: 1.3990, G loss: 0.6567\n",
      "[564/1762] D loss: 1.2869, G loss: 0.9682\n",
      "[644/1762] D loss: 1.3878, G loss: 0.7120\n",
      "[724/1762] D loss: 0.1523, G loss: 2.8199\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6855\n",
      "[884/1762] D loss: 1.2832, G loss: 0.8487\n",
      "[964/1762] D loss: 1.4333, G loss: 0.6698\n",
      "[1044/1762] D loss: 1.4938, G loss: 0.6721\n",
      "[1124/1762] D loss: 0.1292, G loss: 2.9124\n",
      "[1204/1762] D loss: 1.3974, G loss: 0.7560\n",
      "[1284/1762] D loss: 0.0732, G loss: 3.5367\n",
      "[1364/1762] D loss: 1.4638, G loss: 0.7842\n",
      "[1444/1762] D loss: 1.4376, G loss: 0.6349\n",
      "[1524/1762] D loss: 1.6630, G loss: 0.8247\n",
      "[1604/1762] D loss: 1.4195, G loss: 0.6168\n",
      "[1684/1762] D loss: 1.4125, G loss: 0.7354\n",
      "[1762/1762] D loss: 1.5739, G loss: 0.6289\n",
      "train error: \n",
      " D loss: 1.449686, G loss: 0.570381, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.427869, G loss: 0.666912, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3752, G loss: 0.7055\n",
      "[84/1762] D loss: 0.9515, G loss: 1.0361\n",
      "[164/1762] D loss: 0.7753, G loss: 2.3234\n",
      "[244/1762] D loss: 1.4385, G loss: 2.6395\n",
      "[324/1762] D loss: 0.9011, G loss: 1.2109\n",
      "[404/1762] D loss: 0.9224, G loss: 1.0330\n",
      "[484/1762] D loss: 1.7294, G loss: 1.3628\n",
      "[564/1762] D loss: 1.1770, G loss: 1.0818\n",
      "[644/1762] D loss: 1.1583, G loss: 1.3276\n",
      "[724/1762] D loss: 1.1617, G loss: 0.4973\n",
      "[804/1762] D loss: 1.2489, G loss: 0.9138\n",
      "[884/1762] D loss: 1.2836, G loss: 0.9677\n",
      "[964/1762] D loss: 1.3714, G loss: 0.5803\n",
      "[1044/1762] D loss: 1.4174, G loss: 0.5079\n",
      "[1124/1762] D loss: 1.3364, G loss: 0.9567\n",
      "[1204/1762] D loss: 1.3437, G loss: 0.7997\n",
      "[1284/1762] D loss: 1.1324, G loss: 1.0542\n",
      "[1364/1762] D loss: 1.3270, G loss: 0.5996\n",
      "[1444/1762] D loss: 1.1653, G loss: 0.5390\n",
      "[1524/1762] D loss: 1.4569, G loss: 0.6588\n",
      "[1604/1762] D loss: 1.3221, G loss: 0.5602\n",
      "[1684/1762] D loss: 1.3691, G loss: 0.5571\n",
      "[1762/1762] D loss: 1.4474, G loss: 0.9881\n",
      "train error: \n",
      " D loss: 1.332089, G loss: 0.910687, D accuracy: 57.1%, cell accuracy: 99.7%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325750, G loss: 0.933304, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3681, G loss: 0.6235\n",
      "[84/1762] D loss: 1.3840, G loss: 0.5872\n",
      "[164/1762] D loss: 1.4445, G loss: 0.7138\n",
      "[244/1762] D loss: 1.3682, G loss: 0.7872\n",
      "[324/1762] D loss: 1.3634, G loss: 0.6409\n",
      "[404/1762] D loss: 1.1951, G loss: 0.7794\n",
      "[484/1762] D loss: 1.3736, G loss: 0.6652\n",
      "[564/1762] D loss: 1.2509, G loss: 0.6273\n",
      "[644/1762] D loss: 1.0929, G loss: 0.8826\n",
      "[724/1762] D loss: 1.2746, G loss: 1.1919\n",
      "[804/1762] D loss: 1.3730, G loss: 0.6524\n",
      "[884/1762] D loss: 1.3853, G loss: 0.5770\n",
      "[964/1762] D loss: 1.5198, G loss: 0.7691\n",
      "[1044/1762] D loss: 1.1936, G loss: 0.7072\n",
      "[1124/1762] D loss: 1.2718, G loss: 0.9440\n",
      "[1204/1762] D loss: 1.1114, G loss: 0.7048\n",
      "[1284/1762] D loss: 1.0896, G loss: 0.9861\n",
      "[1364/1762] D loss: 1.2683, G loss: 0.7416\n",
      "[1444/1762] D loss: 1.2631, G loss: 1.2205\n",
      "[1524/1762] D loss: 1.3855, G loss: 0.7741\n",
      "[1604/1762] D loss: 1.4638, G loss: 0.9306\n",
      "[1684/1762] D loss: 1.0822, G loss: 1.1469\n",
      "[1762/1762] D loss: 1.3531, G loss: 0.5592\n",
      "train error: \n",
      " D loss: 1.312205, G loss: 0.581364, D accuracy: 56.1%, cell accuracy: 99.5%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297358, G loss: 0.596013, D accuracy: 57.8%, cell accuracy: 99.4%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4051, G loss: 0.9781\n",
      "[84/1762] D loss: 1.1337, G loss: 0.6536\n",
      "[164/1762] D loss: 1.4349, G loss: 0.8136\n",
      "[244/1762] D loss: 1.4348, G loss: 0.6662\n",
      "[324/1762] D loss: 1.3536, G loss: 0.7621\n",
      "[404/1762] D loss: 1.4212, G loss: 0.6397\n",
      "[484/1762] D loss: 0.9718, G loss: 1.2705\n",
      "[564/1762] D loss: 1.0367, G loss: 0.8837\n",
      "[644/1762] D loss: 1.3915, G loss: 0.5970\n",
      "[724/1762] D loss: 1.3726, G loss: 0.6341\n",
      "[804/1762] D loss: 1.4146, G loss: 0.8526\n",
      "[884/1762] D loss: 1.2010, G loss: 1.1369\n",
      "[964/1762] D loss: 1.3835, G loss: 0.6691\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.5856\n",
      "[1124/1762] D loss: 1.4255, G loss: 0.7270\n",
      "[1204/1762] D loss: 1.3626, G loss: 0.6322\n",
      "[1284/1762] D loss: 1.4077, G loss: 0.6036\n",
      "[1364/1762] D loss: 1.0959, G loss: 0.7683\n",
      "[1444/1762] D loss: 1.5161, G loss: 0.9017\n",
      "[1524/1762] D loss: 1.5140, G loss: 0.5847\n",
      "[1604/1762] D loss: 1.4068, G loss: 0.6120\n",
      "[1684/1762] D loss: 1.3590, G loss: 0.8578\n",
      "[1762/1762] D loss: 1.3739, G loss: 0.6906\n",
      "train error: \n",
      " D loss: 1.421768, G loss: 0.479544, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.413746, G loss: 0.490157, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1884, G loss: 0.9755\n",
      "[84/1762] D loss: 1.0104, G loss: 1.3028\n",
      "[164/1762] D loss: 1.4848, G loss: 0.9949\n",
      "[244/1762] D loss: 1.4040, G loss: 0.4768\n",
      "[324/1762] D loss: 1.4125, G loss: 0.7089\n",
      "[404/1762] D loss: 1.0112, G loss: 1.0031\n",
      "[484/1762] D loss: 1.3916, G loss: 0.8948\n",
      "[564/1762] D loss: 0.9930, G loss: 1.8038\n",
      "[644/1762] D loss: 1.4000, G loss: 0.5833\n",
      "[724/1762] D loss: 1.4032, G loss: 0.7553\n",
      "[804/1762] D loss: 1.4412, G loss: 1.0212\n",
      "[884/1762] D loss: 1.5547, G loss: 0.4849\n",
      "[964/1762] D loss: 0.3703, G loss: 2.0200\n",
      "[1044/1762] D loss: 1.4122, G loss: 0.5775\n",
      "[1124/1762] D loss: 1.4009, G loss: 0.6464\n",
      "[1204/1762] D loss: 0.6674, G loss: 1.5378\n",
      "[1284/1762] D loss: 1.4560, G loss: 0.5095\n",
      "[1364/1762] D loss: 1.5127, G loss: 0.4419\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.8119\n",
      "[1524/1762] D loss: 1.4317, G loss: 0.5869\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7020\n",
      "[1684/1762] D loss: 1.4001, G loss: 0.7746\n",
      "[1762/1762] D loss: 1.4205, G loss: 0.8513\n",
      "train error: \n",
      " D loss: 1.301797, G loss: 0.815736, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284846, G loss: 0.830774, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4167, G loss: 0.6053\n",
      "[84/1762] D loss: 1.2131, G loss: 1.1910\n",
      "[164/1762] D loss: 1.3994, G loss: 0.6954\n",
      "[244/1762] D loss: 1.4365, G loss: 0.9001\n",
      "[324/1762] D loss: 0.8383, G loss: 1.5141\n",
      "[404/1762] D loss: 1.4510, G loss: 0.6396\n",
      "[484/1762] D loss: 1.4840, G loss: 0.8886\n",
      "[564/1762] D loss: 1.3926, G loss: 0.7628\n",
      "[644/1762] D loss: 1.4029, G loss: 0.6085\n",
      "[724/1762] D loss: 1.5260, G loss: 0.5485\n",
      "[804/1762] D loss: 0.3965, G loss: 2.0015\n",
      "[884/1762] D loss: 1.4049, G loss: 0.7150\n",
      "[964/1762] D loss: 1.6339, G loss: 0.5245\n",
      "[1044/1762] D loss: 1.4264, G loss: 0.8011\n",
      "[1124/1762] D loss: 1.4355, G loss: 0.8323\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.6160\n",
      "[1284/1762] D loss: 0.8402, G loss: 1.6690\n",
      "[1364/1762] D loss: 0.6078, G loss: 1.5385\n",
      "[1444/1762] D loss: 1.3744, G loss: 0.7005\n",
      "[1524/1762] D loss: 1.4057, G loss: 0.6536\n",
      "[1604/1762] D loss: 1.4541, G loss: 0.4437\n",
      "[1684/1762] D loss: 1.4233, G loss: 0.6617\n",
      "[1762/1762] D loss: 1.4549, G loss: 0.6219\n",
      "train error: \n",
      " D loss: 1.315501, G loss: 0.709007, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303901, G loss: 0.724403, D accuracy: 58.4%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3761, G loss: 0.6996\n",
      "[84/1762] D loss: 0.4599, G loss: 1.7559\n",
      "[164/1762] D loss: 1.4342, G loss: 0.8700\n",
      "[244/1762] D loss: 1.4594, G loss: 0.8261\n",
      "[324/1762] D loss: 1.5608, G loss: 0.5591\n",
      "[404/1762] D loss: 1.3856, G loss: 0.6730\n",
      "[484/1762] D loss: 0.3508, G loss: 1.8086\n",
      "[564/1762] D loss: 1.6985, G loss: 0.4025\n",
      "[644/1762] D loss: 1.3788, G loss: 0.7290\n",
      "[724/1762] D loss: 1.3824, G loss: 0.9502\n",
      "[804/1762] D loss: 1.2531, G loss: 1.2120\n",
      "[884/1762] D loss: 1.2425, G loss: 0.8387\n",
      "[964/1762] D loss: 1.1445, G loss: 0.9889\n",
      "[1044/1762] D loss: 1.4032, G loss: 0.6674\n",
      "[1124/1762] D loss: 1.3951, G loss: 0.6547\n",
      "[1204/1762] D loss: 1.1372, G loss: 0.7949\n",
      "[1284/1762] D loss: 1.3566, G loss: 0.9213\n",
      "[1364/1762] D loss: 1.3758, G loss: 0.6886\n",
      "[1444/1762] D loss: 1.4072, G loss: 0.6942\n",
      "[1524/1762] D loss: 1.4871, G loss: 0.7959\n",
      "[1604/1762] D loss: 1.1357, G loss: 0.9308\n",
      "[1684/1762] D loss: 1.3977, G loss: 0.7011\n",
      "[1762/1762] D loss: 1.3919, G loss: 0.6483\n",
      "train error: \n",
      " D loss: 1.347031, G loss: 0.619020, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331798, G loss: 0.632673, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3775, G loss: 0.7260\n",
      "[84/1762] D loss: 1.3962, G loss: 0.5937\n",
      "[164/1762] D loss: 1.3911, G loss: 0.6836\n",
      "[244/1762] D loss: 0.9492, G loss: 1.1918\n",
      "[324/1762] D loss: 0.9910, G loss: 1.1664\n",
      "[404/1762] D loss: 1.3512, G loss: 0.5668\n",
      "[484/1762] D loss: 1.3959, G loss: 0.6798\n",
      "[564/1762] D loss: 1.3769, G loss: 0.7508\n",
      "[644/1762] D loss: 0.9201, G loss: 1.5447\n",
      "[724/1762] D loss: 1.3911, G loss: 0.7187\n",
      "[804/1762] D loss: 1.3616, G loss: 0.6899\n",
      "[884/1762] D loss: 0.7865, G loss: 1.4166\n",
      "[964/1762] D loss: 1.3126, G loss: 0.6287\n",
      "[1044/1762] D loss: 1.4060, G loss: 0.6557\n",
      "[1124/1762] D loss: 0.6654, G loss: 1.5625\n",
      "[1204/1762] D loss: 1.3469, G loss: 0.7206\n",
      "[1284/1762] D loss: 1.3618, G loss: 0.7283\n",
      "[1364/1762] D loss: 1.2387, G loss: 0.8837\n",
      "[1444/1762] D loss: 0.3742, G loss: 2.1242\n",
      "[1524/1762] D loss: 1.3947, G loss: 0.7862\n",
      "[1604/1762] D loss: 0.5416, G loss: 1.4479\n",
      "[1684/1762] D loss: 1.5262, G loss: 0.3902\n",
      "[1762/1762] D loss: 1.3320, G loss: 0.6817\n",
      "train error: \n",
      " D loss: 1.290693, G loss: 0.867332, D accuracy: 56.6%, cell accuracy: 99.6%, board accuracy: 75.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272571, G loss: 0.876511, D accuracy: 57.2%, cell accuracy: 99.5%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3585, G loss: 0.7190\n",
      "[84/1762] D loss: 1.5581, G loss: 0.5486\n",
      "[164/1762] D loss: 1.5738, G loss: 0.6479\n",
      "[244/1762] D loss: 0.4439, G loss: 1.7780\n",
      "[324/1762] D loss: 1.3371, G loss: 0.7078\n",
      "[404/1762] D loss: 1.4214, G loss: 0.7073\n",
      "[484/1762] D loss: 1.4979, G loss: 0.5702\n",
      "[564/1762] D loss: 1.3939, G loss: 0.6802\n",
      "[644/1762] D loss: 1.3919, G loss: 0.7583\n",
      "[724/1762] D loss: 0.4957, G loss: 1.7302\n",
      "[804/1762] D loss: 0.1598, G loss: 2.4093\n",
      "[884/1762] D loss: 0.6542, G loss: 1.7709\n",
      "[964/1762] D loss: 1.4020, G loss: 0.6968\n",
      "[1044/1762] D loss: 0.2528, G loss: 2.0089\n",
      "[1124/1762] D loss: 1.3771, G loss: 0.7145\n",
      "[1204/1762] D loss: 1.4032, G loss: 0.7377\n",
      "[1284/1762] D loss: 1.3905, G loss: 0.7054\n",
      "[1364/1762] D loss: 1.4014, G loss: 0.6961\n",
      "[1444/1762] D loss: 0.6287, G loss: 1.6816\n",
      "[1524/1762] D loss: 1.4108, G loss: 0.6516\n",
      "[1604/1762] D loss: 1.4930, G loss: 0.7801\n",
      "[1684/1762] D loss: 1.3969, G loss: 0.7231\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.5669\n",
      "train error: \n",
      " D loss: 1.500871, G loss: 0.417825, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.484334, G loss: 0.436762, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3856, G loss: 0.6896\n",
      "[84/1762] D loss: 1.3797, G loss: 0.7261\n",
      "[164/1762] D loss: 1.4123, G loss: 0.7924\n",
      "[244/1762] D loss: 1.3985, G loss: 0.6856\n",
      "[324/1762] D loss: 1.5174, G loss: 0.6845\n",
      "[404/1762] D loss: 1.4102, G loss: 0.7115\n",
      "[484/1762] D loss: 1.5494, G loss: 0.7564\n",
      "[564/1762] D loss: 0.4988, G loss: 1.7005\n",
      "[644/1762] D loss: 1.4017, G loss: 0.7875\n",
      "[724/1762] D loss: 1.4770, G loss: 0.7765\n",
      "[804/1762] D loss: 1.4101, G loss: 0.6765\n",
      "[884/1762] D loss: 1.4221, G loss: 0.8631\n",
      "[964/1762] D loss: 1.3941, G loss: 0.6981\n",
      "[1044/1762] D loss: 0.5695, G loss: 1.3676\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.7041\n",
      "[1204/1762] D loss: 1.0779, G loss: 0.8735\n",
      "[1284/1762] D loss: 1.3488, G loss: 0.7957\n",
      "[1364/1762] D loss: 0.6794, G loss: 1.5229\n",
      "[1444/1762] D loss: 1.1437, G loss: 1.1093\n",
      "[1524/1762] D loss: 1.3942, G loss: 0.7121\n",
      "[1604/1762] D loss: 1.3940, G loss: 0.7033\n",
      "[1684/1762] D loss: 1.4068, G loss: 0.7652\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6831\n",
      "train error: \n",
      " D loss: 1.346500, G loss: 0.762618, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331561, G loss: 0.775192, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3425, G loss: 0.7058\n",
      "[84/1762] D loss: 1.3926, G loss: 0.7131\n",
      "[164/1762] D loss: 1.4093, G loss: 0.7994\n",
      "[244/1762] D loss: 1.4008, G loss: 0.6956\n",
      "[324/1762] D loss: 1.3961, G loss: 0.6521\n",
      "[404/1762] D loss: 1.3942, G loss: 0.6784\n",
      "[484/1762] D loss: 1.3861, G loss: 0.6949\n",
      "[564/1762] D loss: 1.3855, G loss: 0.7078\n",
      "[644/1762] D loss: 1.3947, G loss: 0.6838\n",
      "[724/1762] D loss: 1.1750, G loss: 0.9170\n",
      "[804/1762] D loss: 1.3906, G loss: 0.7146\n",
      "[884/1762] D loss: 1.3589, G loss: 0.6713\n",
      "[964/1762] D loss: 1.0887, G loss: 1.1023\n",
      "[1044/1762] D loss: 1.4092, G loss: 0.6558\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.6840\n",
      "[1204/1762] D loss: 1.2955, G loss: 0.8822\n",
      "[1284/1762] D loss: 1.3739, G loss: 0.6806\n",
      "[1364/1762] D loss: 1.0771, G loss: 1.3259\n",
      "[1444/1762] D loss: 1.4335, G loss: 1.0192\n",
      "[1524/1762] D loss: 1.2409, G loss: 0.9880\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.6308\n",
      "[1684/1762] D loss: 1.1592, G loss: 0.9101\n",
      "[1762/1762] D loss: 1.4062, G loss: 0.7359\n",
      "train error: \n",
      " D loss: 1.350984, G loss: 0.808356, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346082, G loss: 0.801424, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4188, G loss: 0.5871\n",
      "[84/1762] D loss: 1.3968, G loss: 0.7191\n",
      "[164/1762] D loss: 0.7001, G loss: 1.4203\n",
      "[244/1762] D loss: 0.5851, G loss: 1.7066\n",
      "[324/1762] D loss: 1.4031, G loss: 0.7220\n",
      "[404/1762] D loss: 0.4826, G loss: 1.7672\n",
      "[484/1762] D loss: 1.3974, G loss: 0.7906\n",
      "[564/1762] D loss: 1.4169, G loss: 0.6339\n",
      "[644/1762] D loss: 0.7999, G loss: 1.4935\n",
      "[724/1762] D loss: 1.3680, G loss: 0.7028\n",
      "[804/1762] D loss: 1.3964, G loss: 0.6897\n",
      "[884/1762] D loss: 1.2454, G loss: 0.9060\n",
      "[964/1762] D loss: 1.4333, G loss: 0.9791\n",
      "[1044/1762] D loss: 1.3315, G loss: 0.8412\n",
      "[1124/1762] D loss: 1.4657, G loss: 0.6944\n",
      "[1204/1762] D loss: 1.3968, G loss: 0.6785\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.7079\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.6832\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.7230\n",
      "[1524/1762] D loss: 1.3529, G loss: 0.6564\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.7440\n",
      "[1684/1762] D loss: 1.3906, G loss: 0.6405\n",
      "[1762/1762] D loss: 0.9950, G loss: 2.0853\n",
      "train error: \n",
      " D loss: 1.391916, G loss: 1.184695, D accuracy: 51.9%, cell accuracy: 99.7%, board accuracy: 84.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389861, G loss: 1.227625, D accuracy: 52.7%, cell accuracy: 99.6%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5762, G loss: 0.6327\n",
      "[84/1762] D loss: 1.3853, G loss: 0.7085\n",
      "[164/1762] D loss: 1.5151, G loss: 0.5283\n",
      "[244/1762] D loss: 1.2645, G loss: 1.0858\n",
      "[324/1762] D loss: 1.5531, G loss: 0.6996\n",
      "[404/1762] D loss: 1.2560, G loss: 2.6739\n",
      "[484/1762] D loss: 1.2358, G loss: 1.0081\n",
      "[564/1762] D loss: 1.3861, G loss: 0.6953\n",
      "[644/1762] D loss: 1.3960, G loss: 0.6730\n",
      "[724/1762] D loss: 1.3861, G loss: 0.7153\n",
      "[804/1762] D loss: 1.3973, G loss: 0.6894\n",
      "[884/1762] D loss: 1.4381, G loss: 0.7582\n",
      "[964/1762] D loss: 0.6093, G loss: 1.8510\n",
      "[1044/1762] D loss: 1.3547, G loss: 0.7175\n",
      "[1124/1762] D loss: 0.5376, G loss: 1.9861\n",
      "[1204/1762] D loss: 1.4006, G loss: 0.6645\n",
      "[1284/1762] D loss: 1.4084, G loss: 0.7493\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.7004\n",
      "[1444/1762] D loss: 1.4066, G loss: 0.6873\n",
      "[1524/1762] D loss: 1.4818, G loss: 0.5213\n",
      "[1604/1762] D loss: 0.4952, G loss: 1.7407\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.6911\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.7193\n",
      "train error: \n",
      " D loss: 1.327371, G loss: 0.661521, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302386, G loss: 0.691328, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3948, G loss: 0.6761\n",
      "[84/1762] D loss: 1.4032, G loss: 0.6859\n",
      "[164/1762] D loss: 1.4130, G loss: 0.6683\n",
      "[244/1762] D loss: 1.3933, G loss: 0.6551\n",
      "[324/1762] D loss: 1.6343, G loss: 0.3342\n",
      "[404/1762] D loss: 1.4824, G loss: 0.6384\n",
      "[484/1762] D loss: 1.3964, G loss: 0.7390\n",
      "[564/1762] D loss: 1.3479, G loss: 0.7514\n",
      "[644/1762] D loss: 1.4121, G loss: 0.6587\n",
      "[724/1762] D loss: 1.3936, G loss: 0.6793\n",
      "[804/1762] D loss: 1.3881, G loss: 0.7125\n",
      "[884/1762] D loss: 1.3922, G loss: 0.6936\n",
      "[964/1762] D loss: 1.3795, G loss: 0.7127\n",
      "[1044/1762] D loss: 1.4698, G loss: 0.6222\n",
      "[1124/1762] D loss: 1.3983, G loss: 0.7143\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.7096\n",
      "[1284/1762] D loss: 1.4328, G loss: 0.7872\n",
      "[1364/1762] D loss: 1.5767, G loss: 0.9706\n",
      "[1444/1762] D loss: 0.3666, G loss: 1.9437\n",
      "[1524/1762] D loss: 0.4948, G loss: 1.8717\n",
      "[1604/1762] D loss: 0.1520, G loss: 2.6214\n",
      "[1684/1762] D loss: 0.1708, G loss: 2.4716\n",
      "[1762/1762] D loss: 1.4162, G loss: 0.9427\n",
      "train error: \n",
      " D loss: 1.307762, G loss: 0.638106, D accuracy: 57.6%, cell accuracy: 99.2%, board accuracy: 71.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293303, G loss: 0.663685, D accuracy: 58.2%, cell accuracy: 99.0%, board accuracy: 69.3% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4122, G loss: 0.6229\n",
      "[84/1762] D loss: 1.3997, G loss: 0.6827\n",
      "[164/1762] D loss: 1.4103, G loss: 0.7129\n",
      "[244/1762] D loss: 1.4104, G loss: 0.7223\n",
      "[324/1762] D loss: 1.3536, G loss: 0.7231\n",
      "[404/1762] D loss: 1.2565, G loss: 0.7872\n",
      "[484/1762] D loss: 1.3453, G loss: 0.7668\n",
      "[564/1762] D loss: 0.2444, G loss: 2.4791\n",
      "[644/1762] D loss: 1.4301, G loss: 0.6766\n",
      "[724/1762] D loss: 0.9720, G loss: 0.8948\n",
      "[804/1762] D loss: 2.2872, G loss: 0.3553\n",
      "[884/1762] D loss: 1.4161, G loss: 0.7563\n",
      "[964/1762] D loss: 1.3999, G loss: 0.6909\n",
      "[1044/1762] D loss: 1.2448, G loss: 1.1077\n",
      "[1124/1762] D loss: 1.7687, G loss: 0.6979\n",
      "[1204/1762] D loss: 1.4130, G loss: 0.6114\n",
      "[1284/1762] D loss: 1.5081, G loss: 0.5951\n",
      "[1364/1762] D loss: 0.3637, G loss: 2.1056\n",
      "[1444/1762] D loss: 1.3983, G loss: 0.7182\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6940\n",
      "[1604/1762] D loss: 1.3827, G loss: 0.7036\n",
      "[1684/1762] D loss: 1.3905, G loss: 0.6861\n",
      "[1762/1762] D loss: 1.3928, G loss: 0.5902\n",
      "train error: \n",
      " D loss: 1.301133, G loss: 0.836845, D accuracy: 55.0%, cell accuracy: 99.4%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280613, G loss: 0.883550, D accuracy: 55.5%, cell accuracy: 99.2%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4098, G loss: 0.7422\n",
      "[84/1762] D loss: 1.3803, G loss: 0.7010\n",
      "[164/1762] D loss: 0.2633, G loss: 1.9610\n",
      "[244/1762] D loss: 1.3941, G loss: 0.7010\n",
      "[324/1762] D loss: 0.5684, G loss: 2.2357\n",
      "[404/1762] D loss: 1.3948, G loss: 0.7098\n",
      "[484/1762] D loss: 1.4776, G loss: 0.8417\n",
      "[564/1762] D loss: 1.4127, G loss: 0.6836\n",
      "[644/1762] D loss: 1.5555, G loss: 0.7240\n",
      "[724/1762] D loss: 0.3038, G loss: 2.2446\n",
      "[804/1762] D loss: 1.6451, G loss: 0.7487\n",
      "[884/1762] D loss: 1.4326, G loss: 0.7271\n",
      "[964/1762] D loss: 0.6179, G loss: 1.2482\n",
      "[1044/1762] D loss: 1.3960, G loss: 0.6868\n",
      "[1124/1762] D loss: 1.4343, G loss: 0.7258\n",
      "[1204/1762] D loss: 1.4054, G loss: 0.6774\n",
      "[1284/1762] D loss: 1.5135, G loss: 0.5857\n",
      "[1364/1762] D loss: 1.4350, G loss: 0.6483\n",
      "[1444/1762] D loss: 1.4063, G loss: 0.7653\n",
      "[1524/1762] D loss: 0.3052, G loss: 2.2473\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.8889\n",
      "[1684/1762] D loss: 1.4127, G loss: 0.6482\n",
      "[1762/1762] D loss: 1.4220, G loss: 0.5884\n",
      "train error: \n",
      " D loss: 1.347563, G loss: 0.686080, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321243, G loss: 0.723165, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2891, G loss: 2.3450\n",
      "[84/1762] D loss: 1.6140, G loss: 0.7781\n",
      "[164/1762] D loss: 0.2555, G loss: 2.0299\n",
      "[244/1762] D loss: 1.4074, G loss: 0.6868\n",
      "[324/1762] D loss: 1.6373, G loss: 0.5443\n",
      "[404/1762] D loss: 1.4341, G loss: 0.7247\n",
      "[484/1762] D loss: 1.4270, G loss: 1.0042\n",
      "[564/1762] D loss: 1.4146, G loss: 0.6706\n",
      "[644/1762] D loss: 1.3962, G loss: 0.6577\n",
      "[724/1762] D loss: 0.9678, G loss: 1.0174\n",
      "[804/1762] D loss: 1.2379, G loss: 0.8168\n",
      "[884/1762] D loss: 1.3965, G loss: 0.6704\n",
      "[964/1762] D loss: 1.4676, G loss: 0.8178\n",
      "[1044/1762] D loss: 1.4051, G loss: 0.7601\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6943\n",
      "[1204/1762] D loss: 1.3983, G loss: 0.7367\n",
      "[1284/1762] D loss: 1.4246, G loss: 0.6616\n",
      "[1364/1762] D loss: 1.6555, G loss: 0.5651\n",
      "[1444/1762] D loss: 0.1919, G loss: 2.2595\n",
      "[1524/1762] D loss: 1.4039, G loss: 0.6408\n",
      "[1604/1762] D loss: 0.3006, G loss: 2.1781\n",
      "[1684/1762] D loss: 1.4003, G loss: 0.6861\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.7664\n",
      "train error: \n",
      " D loss: 1.328974, G loss: 0.693398, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302872, G loss: 0.738587, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4001, G loss: 0.6338\n",
      "[84/1762] D loss: 0.3332, G loss: 2.3079\n",
      "[164/1762] D loss: 0.4541, G loss: 1.8939\n",
      "[244/1762] D loss: 0.3388, G loss: 2.1737\n",
      "[324/1762] D loss: 1.4068, G loss: 0.7550\n",
      "[404/1762] D loss: 1.3939, G loss: 0.6519\n",
      "[484/1762] D loss: 1.5133, G loss: 0.5298\n",
      "[564/1762] D loss: 0.3705, G loss: 2.2604\n",
      "[644/1762] D loss: 1.4695, G loss: 0.6292\n",
      "[724/1762] D loss: 1.4219, G loss: 0.6543\n",
      "[804/1762] D loss: 1.4735, G loss: 0.7613\n",
      "[884/1762] D loss: 1.4110, G loss: 0.7381\n",
      "[964/1762] D loss: 1.2283, G loss: 0.8396\n",
      "[1044/1762] D loss: 1.4651, G loss: 0.7733\n",
      "[1124/1762] D loss: 1.4021, G loss: 0.6984\n",
      "[1204/1762] D loss: 1.4402, G loss: 0.7913\n",
      "[1284/1762] D loss: 1.5684, G loss: 0.5200\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.6898\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.6846\n",
      "[1524/1762] D loss: 1.4452, G loss: 0.6737\n",
      "[1604/1762] D loss: 1.4495, G loss: 0.6957\n",
      "[1684/1762] D loss: 1.5443, G loss: 1.1632\n",
      "[1762/1762] D loss: 1.6910, G loss: 0.4100\n",
      "train error: \n",
      " D loss: 1.336928, G loss: 0.817661, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311850, G loss: 0.849126, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6087, G loss: 0.9746\n",
      "[84/1762] D loss: 1.3971, G loss: 0.6925\n",
      "[164/1762] D loss: 0.2387, G loss: 2.3235\n",
      "[244/1762] D loss: 1.3822, G loss: 0.6930\n",
      "[324/1762] D loss: 0.3349, G loss: 2.0889\n",
      "[404/1762] D loss: 1.4549, G loss: 0.7401\n",
      "[484/1762] D loss: 0.4286, G loss: 1.9349\n",
      "[564/1762] D loss: 1.3995, G loss: 0.6910\n",
      "[644/1762] D loss: 0.4132, G loss: 1.8707\n",
      "[724/1762] D loss: 1.4423, G loss: 0.7037\n",
      "[804/1762] D loss: 1.4491, G loss: 0.7487\n",
      "[884/1762] D loss: 1.5489, G loss: 0.5712\n",
      "[964/1762] D loss: 1.3902, G loss: 0.6824\n",
      "[1044/1762] D loss: 0.1676, G loss: 2.6393\n",
      "[1124/1762] D loss: 1.3910, G loss: 0.7040\n",
      "[1204/1762] D loss: 1.4392, G loss: 0.7383\n",
      "[1284/1762] D loss: 1.4052, G loss: 0.6707\n",
      "[1364/1762] D loss: 1.4329, G loss: 0.7406\n",
      "[1444/1762] D loss: 1.4202, G loss: 0.6463\n",
      "[1524/1762] D loss: 0.3506, G loss: 1.9785\n",
      "[1604/1762] D loss: 1.3843, G loss: 0.6928\n",
      "[1684/1762] D loss: 1.4718, G loss: 0.6521\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.6804\n",
      "train error: \n",
      " D loss: 1.308393, G loss: 0.842454, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283369, G loss: 0.903685, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3888, G loss: 0.6931\n",
      "[84/1762] D loss: 1.3929, G loss: 0.6977\n",
      "[164/1762] D loss: 0.2777, G loss: 2.0439\n",
      "[244/1762] D loss: 1.4051, G loss: 0.7529\n",
      "[324/1762] D loss: 0.1223, G loss: 2.9391\n",
      "[404/1762] D loss: 1.4030, G loss: 0.7093\n",
      "[484/1762] D loss: 0.0975, G loss: 3.3898\n",
      "[564/1762] D loss: 0.3438, G loss: 2.1079\n",
      "[644/1762] D loss: 1.5025, G loss: 0.3955\n",
      "[724/1762] D loss: 0.2621, G loss: 2.5221\n",
      "[804/1762] D loss: 1.5662, G loss: 0.6718\n",
      "[884/1762] D loss: 1.5424, G loss: 1.0674\n",
      "[964/1762] D loss: 0.1750, G loss: 2.7021\n",
      "[1044/1762] D loss: 1.6563, G loss: 2.1523\n",
      "[1124/1762] D loss: 1.6013, G loss: 0.4827\n",
      "[1204/1762] D loss: 1.7726, G loss: 0.5060\n",
      "[1284/1762] D loss: 1.5028, G loss: 0.5917\n",
      "[1364/1762] D loss: 1.3991, G loss: 0.6859\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6854\n",
      "[1524/1762] D loss: 1.2582, G loss: 0.7872\n",
      "[1604/1762] D loss: 1.3925, G loss: 0.7218\n",
      "[1684/1762] D loss: 1.3965, G loss: 0.7080\n",
      "[1762/1762] D loss: 1.3985, G loss: 0.6242\n",
      "train error: \n",
      " D loss: 1.334767, G loss: 0.772495, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312784, G loss: 0.848268, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4000, G loss: 0.7182\n",
      "[84/1762] D loss: 1.3958, G loss: 0.6846\n",
      "[164/1762] D loss: 1.3996, G loss: 0.7035\n",
      "[244/1762] D loss: 1.4913, G loss: 0.6383\n",
      "[324/1762] D loss: 1.4334, G loss: 0.4912\n",
      "[404/1762] D loss: 1.3983, G loss: 0.6837\n",
      "[484/1762] D loss: 1.4265, G loss: 0.7885\n",
      "[564/1762] D loss: 1.4342, G loss: 0.7001\n",
      "[644/1762] D loss: 1.4316, G loss: 0.8401\n",
      "[724/1762] D loss: 1.0743, G loss: 0.8830\n",
      "[804/1762] D loss: 1.9883, G loss: 2.0110\n",
      "[884/1762] D loss: 1.5929, G loss: 0.5012\n",
      "[964/1762] D loss: 1.4097, G loss: 0.6681\n",
      "[1044/1762] D loss: 1.5473, G loss: 0.4302\n",
      "[1124/1762] D loss: 0.0635, G loss: 3.1198\n",
      "[1204/1762] D loss: 1.4455, G loss: 0.5912\n",
      "[1284/1762] D loss: 1.2075, G loss: 0.9770\n",
      "[1364/1762] D loss: 1.4077, G loss: 0.9379\n",
      "[1444/1762] D loss: 1.4043, G loss: 0.6445\n",
      "[1524/1762] D loss: 1.2692, G loss: 0.5632\n",
      "[1604/1762] D loss: 0.1108, G loss: 2.8534\n",
      "[1684/1762] D loss: 0.3081, G loss: 2.2480\n",
      "[1762/1762] D loss: 1.6139, G loss: 1.8757\n",
      "train error: \n",
      " D loss: 1.964912, G loss: 1.840252, D accuracy: 47.8%, cell accuracy: 98.9%, board accuracy: 66.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.947560, G loss: 1.926296, D accuracy: 46.8%, cell accuracy: 98.7%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0955, G loss: 1.3538\n",
      "[84/1762] D loss: 1.2399, G loss: 0.8830\n",
      "[164/1762] D loss: 1.0699, G loss: 1.5137\n",
      "[244/1762] D loss: 1.3817, G loss: 0.6240\n",
      "[324/1762] D loss: 0.2624, G loss: 2.5008\n",
      "[404/1762] D loss: 1.1331, G loss: 0.8468\n",
      "[484/1762] D loss: 1.1481, G loss: 0.8886\n",
      "[564/1762] D loss: 1.3951, G loss: 0.6380\n",
      "[644/1762] D loss: 1.4104, G loss: 0.6386\n",
      "[724/1762] D loss: 0.2726, G loss: 2.3042\n",
      "[804/1762] D loss: 1.4107, G loss: 0.6921\n",
      "[884/1762] D loss: 1.4113, G loss: 0.6858\n",
      "[964/1762] D loss: 0.8839, G loss: 1.6683\n",
      "[1044/1762] D loss: 1.4586, G loss: 0.6179\n",
      "[1124/1762] D loss: 1.4770, G loss: 0.6035\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.6673\n",
      "[1284/1762] D loss: 1.4386, G loss: 1.7272\n",
      "[1364/1762] D loss: 0.4158, G loss: 2.0263\n",
      "[1444/1762] D loss: 0.1454, G loss: 2.9937\n",
      "[1524/1762] D loss: 1.4049, G loss: 0.7819\n",
      "[1604/1762] D loss: 1.4813, G loss: 0.3972\n",
      "[1684/1762] D loss: 1.5673, G loss: 0.5867\n",
      "[1762/1762] D loss: 1.4004, G loss: 0.5975\n",
      "train error: \n",
      " D loss: 1.339835, G loss: 0.777187, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310578, G loss: 0.869421, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4014, G loss: 0.6634\n",
      "[84/1762] D loss: 1.3923, G loss: 0.7272\n",
      "[164/1762] D loss: 1.4469, G loss: 0.5791\n",
      "[244/1762] D loss: 1.3608, G loss: 1.3461\n",
      "[324/1762] D loss: 1.3776, G loss: 0.7114\n",
      "[404/1762] D loss: 0.2017, G loss: 3.2023\n",
      "[484/1762] D loss: 1.3957, G loss: 0.7084\n",
      "[564/1762] D loss: 1.4019, G loss: 0.6899\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6812\n",
      "[724/1762] D loss: 0.1610, G loss: 2.9815\n",
      "[804/1762] D loss: 1.4551, G loss: 0.7400\n",
      "[884/1762] D loss: 1.4543, G loss: 0.6855\n",
      "[964/1762] D loss: 0.9930, G loss: 1.8439\n",
      "[1044/1762] D loss: 1.4109, G loss: 0.5588\n",
      "[1124/1762] D loss: 0.1216, G loss: 2.8429\n",
      "[1204/1762] D loss: 1.4725, G loss: 0.8605\n",
      "[1284/1762] D loss: 1.4256, G loss: 0.7417\n",
      "[1364/1762] D loss: 1.4448, G loss: 0.6650\n",
      "[1444/1762] D loss: 1.4100, G loss: 0.7074\n",
      "[1524/1762] D loss: 1.3488, G loss: 0.6150\n",
      "[1604/1762] D loss: 1.4554, G loss: 0.6882\n",
      "[1684/1762] D loss: 1.3914, G loss: 0.7150\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6898\n",
      "train error: \n",
      " D loss: 1.304731, G loss: 0.898351, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281297, G loss: 0.988156, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4006, G loss: 0.6858\n",
      "[84/1762] D loss: 1.4031, G loss: 0.6988\n",
      "[164/1762] D loss: 0.2646, G loss: 2.1342\n",
      "[244/1762] D loss: 1.4487, G loss: 0.6645\n",
      "[324/1762] D loss: 0.1954, G loss: 2.8013\n",
      "[404/1762] D loss: 1.3901, G loss: 0.6830\n",
      "[484/1762] D loss: 1.4260, G loss: 0.5646\n",
      "[564/1762] D loss: 0.0349, G loss: 3.8756\n",
      "[644/1762] D loss: 0.1358, G loss: 3.1718\n",
      "[724/1762] D loss: 0.2686, G loss: 2.7130\n",
      "[804/1762] D loss: 0.2886, G loss: 2.3726\n",
      "[884/1762] D loss: 1.3941, G loss: 0.6867\n",
      "[964/1762] D loss: 1.4024, G loss: 0.6830\n",
      "[1044/1762] D loss: 1.4425, G loss: 0.6369\n",
      "[1124/1762] D loss: 1.3835, G loss: 0.7062\n",
      "[1204/1762] D loss: 1.4697, G loss: 0.6008\n",
      "[1284/1762] D loss: 0.2756, G loss: 2.7469\n",
      "[1364/1762] D loss: 1.3966, G loss: 0.7157\n",
      "[1444/1762] D loss: 0.1884, G loss: 2.4790\n",
      "[1524/1762] D loss: 1.4044, G loss: 0.7097\n",
      "[1604/1762] D loss: 1.4212, G loss: 0.6820\n",
      "[1684/1762] D loss: 0.0236, G loss: 4.4766\n",
      "[1762/1762] D loss: 1.4581, G loss: 0.7945\n",
      "train error: \n",
      " D loss: 1.345930, G loss: 0.796859, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319296, G loss: 0.913647, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4446, G loss: 0.6575\n",
      "[84/1762] D loss: 1.4210, G loss: 0.5765\n",
      "[164/1762] D loss: 1.3963, G loss: 0.6633\n",
      "[244/1762] D loss: 1.4000, G loss: 0.6914\n",
      "[324/1762] D loss: 1.5322, G loss: 0.6277\n",
      "[404/1762] D loss: 1.4411, G loss: 0.7267\n",
      "[484/1762] D loss: 0.0207, G loss: 4.6452\n",
      "[564/1762] D loss: 0.1325, G loss: 3.2146\n",
      "[644/1762] D loss: 1.3912, G loss: 0.6958\n",
      "[724/1762] D loss: 1.4079, G loss: 0.7266\n",
      "[804/1762] D loss: 1.4088, G loss: 0.6913\n",
      "[884/1762] D loss: 0.0331, G loss: 4.3610\n",
      "[964/1762] D loss: 0.0201, G loss: 4.8954\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.6680\n",
      "[1124/1762] D loss: 1.4055, G loss: 0.7283\n",
      "[1204/1762] D loss: 1.4117, G loss: 0.6714\n",
      "[1284/1762] D loss: 0.1924, G loss: 2.9337\n",
      "[1364/1762] D loss: 1.4076, G loss: 0.6984\n",
      "[1444/1762] D loss: 1.4037, G loss: 0.6733\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.7328\n",
      "[1604/1762] D loss: 0.0165, G loss: 4.9787\n",
      "[1684/1762] D loss: 1.4004, G loss: 0.7825\n",
      "[1762/1762] D loss: 0.0057, G loss: 6.0283\n",
      "train error: \n",
      " D loss: 1.575235, G loss: 0.573692, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.541073, G loss: 0.665144, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4879, G loss: 0.4733\n",
      "[84/1762] D loss: 1.3943, G loss: 0.7019\n",
      "[164/1762] D loss: 1.5097, G loss: 0.5373\n",
      "[244/1762] D loss: 0.1840, G loss: 3.0707\n",
      "[324/1762] D loss: 1.3964, G loss: 0.6910\n",
      "[404/1762] D loss: 1.4095, G loss: 0.6706\n",
      "[484/1762] D loss: 1.4162, G loss: 0.6264\n",
      "[564/1762] D loss: 1.3933, G loss: 0.7055\n",
      "[644/1762] D loss: 1.5459, G loss: 0.7384\n",
      "[724/1762] D loss: 1.3976, G loss: 0.7370\n",
      "[804/1762] D loss: 1.1794, G loss: 1.1595\n",
      "[884/1762] D loss: 0.1829, G loss: 2.7944\n",
      "[964/1762] D loss: 0.9298, G loss: 1.2834\n",
      "[1044/1762] D loss: 1.4569, G loss: 0.4976\n",
      "[1124/1762] D loss: 1.3958, G loss: 0.6869\n",
      "[1204/1762] D loss: 0.0958, G loss: 3.4189\n",
      "[1284/1762] D loss: 0.1041, G loss: 3.1861\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7601\n",
      "[1444/1762] D loss: 1.2603, G loss: 0.9903\n",
      "[1524/1762] D loss: 1.4268, G loss: 0.5977\n",
      "[1604/1762] D loss: 0.1087, G loss: 3.1438\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6920\n",
      "[1762/1762] D loss: 0.0152, G loss: 4.6849\n",
      "train error: \n",
      " D loss: 1.760992, G loss: 0.433587, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.713022, G loss: 0.496624, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4024, G loss: 0.6667\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6923\n",
      "[164/1762] D loss: 0.1610, G loss: 2.7849\n",
      "[244/1762] D loss: 1.3932, G loss: 0.6963\n",
      "[324/1762] D loss: 0.0373, G loss: 4.0157\n",
      "[404/1762] D loss: 0.1721, G loss: 2.6954\n",
      "[484/1762] D loss: 0.5745, G loss: 2.5222\n",
      "[564/1762] D loss: 0.2643, G loss: 3.1276\n",
      "[644/1762] D loss: 1.4980, G loss: 0.8768\n",
      "[724/1762] D loss: 0.5197, G loss: 1.7775\n",
      "[804/1762] D loss: 0.1539, G loss: 2.5349\n",
      "[884/1762] D loss: 1.3840, G loss: 0.6274\n",
      "[964/1762] D loss: 1.5676, G loss: 0.5412\n",
      "[1044/1762] D loss: 0.1616, G loss: 2.7076\n",
      "[1124/1762] D loss: 1.4023, G loss: 0.6922\n",
      "[1204/1762] D loss: 1.1340, G loss: 0.9094\n",
      "[1284/1762] D loss: 0.2086, G loss: 3.0793\n",
      "[1364/1762] D loss: 1.3987, G loss: 0.6554\n",
      "[1444/1762] D loss: 1.5871, G loss: 0.4752\n",
      "[1524/1762] D loss: 1.4460, G loss: 0.6605\n",
      "[1604/1762] D loss: 1.3829, G loss: 0.7023\n",
      "[1684/1762] D loss: 0.1741, G loss: 3.2007\n",
      "[1762/1762] D loss: 1.4042, G loss: 0.6160\n",
      "train error: \n",
      " D loss: 1.323585, G loss: 0.842916, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302426, G loss: 0.981722, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1268, G loss: 1.0025\n",
      "[84/1762] D loss: 0.0918, G loss: 3.3604\n",
      "[164/1762] D loss: 1.4005, G loss: 0.6490\n",
      "[244/1762] D loss: 0.1454, G loss: 3.0522\n",
      "[324/1762] D loss: 0.3754, G loss: 2.4902\n",
      "[404/1762] D loss: 0.3288, G loss: 3.0741\n",
      "[484/1762] D loss: 0.0979, G loss: 4.1827\n",
      "[564/1762] D loss: 0.1059, G loss: 3.2860\n",
      "[644/1762] D loss: 0.3515, G loss: 4.4002\n",
      "[724/1762] D loss: 0.0681, G loss: 3.9102\n",
      "[804/1762] D loss: 1.4548, G loss: 1.0118\n",
      "[884/1762] D loss: 1.4325, G loss: 0.8110\n",
      "[964/1762] D loss: 0.8749, G loss: 1.4964\n",
      "[1044/1762] D loss: 1.8548, G loss: 0.3241\n",
      "[1124/1762] D loss: 1.4499, G loss: 1.2236\n",
      "[1204/1762] D loss: 1.4052, G loss: 0.5852\n",
      "[1284/1762] D loss: 1.4098, G loss: 0.9064\n",
      "[1364/1762] D loss: 1.4107, G loss: 0.7017\n",
      "[1444/1762] D loss: 1.5039, G loss: 0.6405\n",
      "[1524/1762] D loss: 1.6043, G loss: 0.5270\n",
      "[1604/1762] D loss: 0.2770, G loss: 3.0121\n",
      "[1684/1762] D loss: 1.4170, G loss: 0.8776\n",
      "[1762/1762] D loss: 1.4224, G loss: 0.7422\n",
      "train error: \n",
      " D loss: 1.295490, G loss: 1.065020, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267878, G loss: 1.174579, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2511, G loss: 2.8088\n",
      "[84/1762] D loss: 1.4326, G loss: 0.6887\n",
      "[164/1762] D loss: 1.4133, G loss: 0.7050\n",
      "[244/1762] D loss: 1.3931, G loss: 0.7095\n",
      "[324/1762] D loss: 0.2704, G loss: 3.2871\n",
      "[404/1762] D loss: 0.3368, G loss: 2.4128\n",
      "[484/1762] D loss: 1.4880, G loss: 0.5555\n",
      "[564/1762] D loss: 1.4864, G loss: 0.5138\n",
      "[644/1762] D loss: 0.2754, G loss: 3.0703\n",
      "[724/1762] D loss: 1.4099, G loss: 0.7292\n",
      "[804/1762] D loss: 1.4877, G loss: 0.5484\n",
      "[884/1762] D loss: 1.0286, G loss: 1.3837\n",
      "[964/1762] D loss: 1.3912, G loss: 0.6818\n",
      "[1044/1762] D loss: 0.9062, G loss: 1.6560\n",
      "[1124/1762] D loss: 1.1526, G loss: 1.2858\n",
      "[1204/1762] D loss: 1.3804, G loss: 0.7071\n",
      "[1284/1762] D loss: 0.3918, G loss: 3.0166\n",
      "[1364/1762] D loss: 1.5356, G loss: 0.5995\n",
      "[1444/1762] D loss: 0.2159, G loss: 3.1566\n",
      "[1524/1762] D loss: 1.5590, G loss: 0.3620\n",
      "[1604/1762] D loss: 1.3922, G loss: 0.7065\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.6984\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.7108\n",
      "train error: \n",
      " D loss: 1.321272, G loss: 0.899683, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291134, G loss: 1.040147, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2032, G loss: 2.7528\n",
      "[84/1762] D loss: 1.3882, G loss: 0.6908\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6895\n",
      "[244/1762] D loss: 1.3982, G loss: 0.7090\n",
      "[324/1762] D loss: 1.4330, G loss: 0.6104\n",
      "[404/1762] D loss: 1.4124, G loss: 0.6793\n",
      "[484/1762] D loss: 1.3941, G loss: 0.6923\n",
      "[564/1762] D loss: 0.1370, G loss: 3.6628\n",
      "[644/1762] D loss: 1.3862, G loss: 0.6973\n",
      "[724/1762] D loss: 1.3841, G loss: 0.6938\n",
      "[804/1762] D loss: 1.3901, G loss: 0.6765\n",
      "[884/1762] D loss: 1.4035, G loss: 0.6525\n",
      "[964/1762] D loss: 1.3887, G loss: 0.7019\n",
      "[1044/1762] D loss: 1.3852, G loss: 0.6851\n",
      "[1124/1762] D loss: 0.1122, G loss: 3.6700\n",
      "[1204/1762] D loss: 1.4039, G loss: 0.6646\n",
      "[1284/1762] D loss: 1.4361, G loss: 0.5886\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6691\n",
      "[1444/1762] D loss: 1.1808, G loss: 1.3318\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.7024\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6688\n",
      "[1684/1762] D loss: 1.4145, G loss: 0.7072\n",
      "[1762/1762] D loss: 1.4072, G loss: 0.6642\n",
      "train error: \n",
      " D loss: 1.318432, G loss: 1.162760, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291446, G loss: 1.278577, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4069, G loss: 0.6633\n",
      "[84/1762] D loss: 1.4235, G loss: 0.6051\n",
      "[164/1762] D loss: 1.4001, G loss: 0.6643\n",
      "[244/1762] D loss: 1.7607, G loss: 0.4802\n",
      "[324/1762] D loss: 0.1632, G loss: 3.5234\n",
      "[404/1762] D loss: 1.3977, G loss: 0.6856\n",
      "[484/1762] D loss: 1.3969, G loss: 0.6214\n",
      "[564/1762] D loss: 1.3913, G loss: 0.6824\n",
      "[644/1762] D loss: 1.3928, G loss: 0.6504\n",
      "[724/1762] D loss: 0.8432, G loss: 2.3737\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6932\n",
      "[884/1762] D loss: 1.3984, G loss: 0.6776\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7031\n",
      "[1044/1762] D loss: 1.1047, G loss: 1.3029\n",
      "[1124/1762] D loss: 1.4049, G loss: 0.6676\n",
      "[1204/1762] D loss: 0.9722, G loss: 1.5565\n",
      "[1284/1762] D loss: 1.3851, G loss: 1.0235\n",
      "[1364/1762] D loss: 0.3402, G loss: 3.0792\n",
      "[1444/1762] D loss: 1.3963, G loss: 0.6982\n",
      "[1524/1762] D loss: 1.3955, G loss: 0.6775\n",
      "[1604/1762] D loss: 1.4161, G loss: 0.6624\n",
      "[1684/1762] D loss: 1.4028, G loss: 0.6753\n",
      "[1762/1762] D loss: 1.4421, G loss: 0.6287\n",
      "train error: \n",
      " D loss: 1.367099, G loss: 0.949807, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346681, G loss: 1.039401, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4441, G loss: 0.7411\n",
      "[84/1762] D loss: 0.1043, G loss: 3.4695\n",
      "[164/1762] D loss: 1.4025, G loss: 0.6642\n",
      "[244/1762] D loss: 1.4464, G loss: 0.5238\n",
      "[324/1762] D loss: 1.4212, G loss: 0.6229\n",
      "[404/1762] D loss: 0.1027, G loss: 3.5039\n",
      "[484/1762] D loss: 1.3925, G loss: 0.6364\n",
      "[564/1762] D loss: 0.0880, G loss: 4.1118\n",
      "[644/1762] D loss: 1.1832, G loss: 1.3314\n",
      "[724/1762] D loss: 1.4469, G loss: 0.6469\n",
      "[804/1762] D loss: 1.4313, G loss: 0.7091\n",
      "[884/1762] D loss: 0.0269, G loss: 4.9877\n",
      "[964/1762] D loss: 1.5217, G loss: 0.4545\n",
      "[1044/1762] D loss: 1.4126, G loss: 0.6388\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.6859\n",
      "[1204/1762] D loss: 0.3988, G loss: 2.9837\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.6702\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6620\n",
      "[1444/1762] D loss: 1.3890, G loss: 0.6954\n",
      "[1524/1762] D loss: 0.2634, G loss: 3.4655\n",
      "[1604/1762] D loss: 1.7680, G loss: 0.4110\n",
      "[1684/1762] D loss: 0.0671, G loss: 4.4978\n",
      "[1762/1762] D loss: 1.3996, G loss: 0.6460\n",
      "train error: \n",
      " D loss: 1.464904, G loss: 0.799924, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.437006, G loss: 0.935961, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909, G loss: 0.7249\n",
      "[84/1762] D loss: 1.3919, G loss: 0.7252\n",
      "[164/1762] D loss: 1.3931, G loss: 0.7166\n",
      "[244/1762] D loss: 1.3995, G loss: 0.6215\n",
      "[324/1762] D loss: 1.4704, G loss: 0.6519\n",
      "[404/1762] D loss: 1.2570, G loss: 1.0014\n",
      "[484/1762] D loss: 1.4551, G loss: 0.4678\n",
      "[564/1762] D loss: 0.0185, G loss: 5.3960\n",
      "[644/1762] D loss: 1.4053, G loss: 0.6031\n",
      "[724/1762] D loss: 0.2180, G loss: 4.8125\n",
      "[804/1762] D loss: 0.0285, G loss: 4.2305\n",
      "[884/1762] D loss: 0.2882, G loss: 3.4043\n",
      "[964/1762] D loss: 0.0655, G loss: 4.1016\n",
      "[1044/1762] D loss: 1.4228, G loss: 0.6098\n",
      "[1124/1762] D loss: 1.3664, G loss: 0.7359\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.6485\n",
      "[1284/1762] D loss: 0.0041, G loss: 8.6130\n",
      "[1364/1762] D loss: 1.4214, G loss: 0.6011\n",
      "[1444/1762] D loss: 0.2919, G loss: 4.4383\n",
      "[1524/1762] D loss: 1.4111, G loss: 0.6833\n",
      "[1604/1762] D loss: 1.4213, G loss: 0.6042\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.6964\n",
      "[1762/1762] D loss: 1.2198, G loss: 2.0172\n",
      "train error: \n",
      " D loss: 1.288223, G loss: 1.175930, D accuracy: 55.1%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265090, G loss: 1.331570, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3590, G loss: 0.7712\n",
      "[84/1762] D loss: 1.4137, G loss: 0.6186\n",
      "[164/1762] D loss: 1.3745, G loss: 0.7085\n",
      "[244/1762] D loss: 1.5187, G loss: 0.6977\n",
      "[324/1762] D loss: 0.2639, G loss: 3.1254\n",
      "[404/1762] D loss: 1.2939, G loss: 1.3128\n",
      "[484/1762] D loss: 1.1040, G loss: 1.1515\n",
      "[564/1762] D loss: 1.4037, G loss: 0.6333\n",
      "[644/1762] D loss: 1.2243, G loss: 1.8046\n",
      "[724/1762] D loss: 0.0779, G loss: 4.9184\n",
      "[804/1762] D loss: 1.4062, G loss: 0.6429\n",
      "[884/1762] D loss: 1.4282, G loss: 0.6642\n",
      "[964/1762] D loss: 1.3948, G loss: 0.6650\n",
      "[1044/1762] D loss: 1.4655, G loss: 0.6349\n",
      "[1124/1762] D loss: 1.3967, G loss: 0.6778\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6800\n",
      "[1284/1762] D loss: 0.3166, G loss: 4.1674\n",
      "[1364/1762] D loss: 1.3815, G loss: 0.7017\n",
      "[1444/1762] D loss: 1.3979, G loss: 0.6869\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.6744\n",
      "[1604/1762] D loss: 0.1541, G loss: 4.0571\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.6640\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6686\n",
      "train error: \n",
      " D loss: 1.291878, G loss: 1.044448, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260210, G loss: 1.213940, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3939, G loss: 0.6683\n",
      "[84/1762] D loss: 1.3953, G loss: 0.6386\n",
      "[164/1762] D loss: 1.3965, G loss: 0.6703\n",
      "[244/1762] D loss: 1.4001, G loss: 0.6846\n",
      "[324/1762] D loss: 1.3875, G loss: 0.6739\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6811\n",
      "[484/1762] D loss: 0.1034, G loss: 4.8510\n",
      "[564/1762] D loss: 1.3946, G loss: 0.6583\n",
      "[644/1762] D loss: 1.3927, G loss: 0.6485\n",
      "[724/1762] D loss: 0.0013, G loss: 7.3059\n",
      "[804/1762] D loss: 1.4617, G loss: 0.6063\n",
      "[884/1762] D loss: 1.5027, G loss: 0.6082\n",
      "[964/1762] D loss: 1.4233, G loss: 0.6031\n",
      "[1044/1762] D loss: 1.3960, G loss: 0.6870\n",
      "[1124/1762] D loss: 1.3938, G loss: 0.6356\n",
      "[1204/1762] D loss: 1.4019, G loss: 0.6460\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.6573\n",
      "[1364/1762] D loss: 1.4045, G loss: 0.6303\n",
      "[1444/1762] D loss: 1.4028, G loss: 0.6049\n",
      "[1524/1762] D loss: 1.3898, G loss: 0.6699\n",
      "[1604/1762] D loss: 0.0718, G loss: 3.8136\n",
      "[1684/1762] D loss: 0.3354, G loss: 3.6382\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6511\n",
      "train error: \n",
      " D loss: 1.291231, G loss: 0.972505, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264538, G loss: 1.075383, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0511, G loss: 4.1614\n",
      "[84/1762] D loss: 1.4680, G loss: 0.6223\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6675\n",
      "[244/1762] D loss: 1.2644, G loss: 1.5646\n",
      "[324/1762] D loss: 0.0566, G loss: 4.4641\n",
      "[404/1762] D loss: 1.3857, G loss: 0.7006\n",
      "[484/1762] D loss: 1.3861, G loss: 0.6650\n",
      "[564/1762] D loss: 1.4485, G loss: 0.5982\n",
      "[644/1762] D loss: 1.4358, G loss: 0.5654\n",
      "[724/1762] D loss: 1.3963, G loss: 0.6244\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6984\n",
      "[884/1762] D loss: 0.0472, G loss: 4.7097\n",
      "[964/1762] D loss: 0.0821, G loss: 4.4371\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6713\n",
      "[1124/1762] D loss: 1.2437, G loss: 1.0146\n",
      "[1204/1762] D loss: 1.0007, G loss: 0.9528\n",
      "[1284/1762] D loss: 0.8844, G loss: 2.4313\n",
      "[1364/1762] D loss: 1.4737, G loss: 0.4967\n",
      "[1444/1762] D loss: 0.0109, G loss: 12.3114\n",
      "[1524/1762] D loss: 0.9307, G loss: 4.2121\n",
      "[1604/1762] D loss: 0.1782, G loss: 4.2165\n",
      "[1684/1762] D loss: 0.0463, G loss: 4.7308\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6829\n",
      "train error: \n",
      " D loss: 1.291368, G loss: 1.105224, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264282, G loss: 1.275640, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.6777\n",
      "[84/1762] D loss: 1.3900, G loss: 0.6546\n",
      "[164/1762] D loss: 1.3977, G loss: 0.7239\n",
      "[244/1762] D loss: 1.3907, G loss: 0.7185\n",
      "[324/1762] D loss: 1.3889, G loss: 0.6996\n",
      "[404/1762] D loss: 1.3902, G loss: 0.6847\n",
      "[484/1762] D loss: 1.3319, G loss: 0.9180\n",
      "[564/1762] D loss: 1.4049, G loss: 0.6067\n",
      "[644/1762] D loss: 0.1899, G loss: 4.5399\n",
      "[724/1762] D loss: 0.0829, G loss: 4.7068\n",
      "[804/1762] D loss: 1.4776, G loss: 0.6156\n",
      "[884/1762] D loss: 1.3809, G loss: 0.6692\n",
      "[964/1762] D loss: 1.3921, G loss: 0.6901\n",
      "[1044/1762] D loss: 0.1700, G loss: 4.1636\n",
      "[1124/1762] D loss: 0.0939, G loss: 5.2905\n",
      "[1204/1762] D loss: 1.1834, G loss: 3.2564\n",
      "[1284/1762] D loss: 2.6229, G loss: 0.5157\n",
      "[1364/1762] D loss: 1.3960, G loss: 0.6775\n",
      "[1444/1762] D loss: 0.7248, G loss: 3.6944\n",
      "[1524/1762] D loss: 1.3610, G loss: 0.6750\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.6599\n",
      "[1684/1762] D loss: 1.3789, G loss: 0.7556\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.9056\n",
      "train error: \n",
      " D loss: 1.279247, G loss: 1.007515, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254357, G loss: 1.122565, D accuracy: 59.0%, cell accuracy: 99.5%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6422, G loss: 3.0030\n",
      "[84/1762] D loss: 0.6302, G loss: 3.2641\n",
      "[164/1762] D loss: 1.4263, G loss: 0.6857\n",
      "[244/1762] D loss: 1.4265, G loss: 0.5728\n",
      "[324/1762] D loss: 1.4246, G loss: 0.5811\n",
      "[404/1762] D loss: 1.3850, G loss: 0.6490\n",
      "[484/1762] D loss: 0.3320, G loss: 4.1744\n",
      "[564/1762] D loss: 1.3824, G loss: 0.6506\n",
      "[644/1762] D loss: 1.2954, G loss: 0.3692\n",
      "[724/1762] D loss: 1.4026, G loss: 0.6694\n",
      "[804/1762] D loss: 1.2363, G loss: 1.0463\n",
      "[884/1762] D loss: 0.3514, G loss: 2.7880\n",
      "[964/1762] D loss: 0.8900, G loss: 2.0723\n",
      "[1044/1762] D loss: 1.4169, G loss: 0.5798\n",
      "[1124/1762] D loss: 0.5789, G loss: 1.9386\n",
      "[1204/1762] D loss: 1.4081, G loss: 0.7470\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.6857\n",
      "[1364/1762] D loss: 1.3485, G loss: 0.7128\n",
      "[1444/1762] D loss: 1.0380, G loss: 1.5118\n",
      "[1524/1762] D loss: 1.3820, G loss: 0.6909\n",
      "[1604/1762] D loss: 0.6217, G loss: 2.0311\n",
      "[1684/1762] D loss: 1.1757, G loss: 2.4341\n",
      "[1762/1762] D loss: 0.2324, G loss: 3.5243\n",
      "train error: \n",
      " D loss: 1.419540, G loss: 0.647240, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392801, G loss: 0.681255, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3664, G loss: 0.7087\n",
      "[84/1762] D loss: 0.2848, G loss: 3.2767\n",
      "[164/1762] D loss: 0.7829, G loss: 1.4977\n",
      "[244/1762] D loss: 1.4395, G loss: 0.5722\n",
      "[324/1762] D loss: 1.3913, G loss: 0.6765\n",
      "[404/1762] D loss: 1.3984, G loss: 0.7003\n",
      "[484/1762] D loss: 0.8290, G loss: 1.3702\n",
      "[564/1762] D loss: 1.4265, G loss: 0.7120\n",
      "[644/1762] D loss: 1.3925, G loss: 0.6763\n",
      "[724/1762] D loss: 1.3901, G loss: 0.7001\n",
      "[804/1762] D loss: 0.1159, G loss: 3.1763\n",
      "[884/1762] D loss: 1.3987, G loss: 0.6705\n",
      "[964/1762] D loss: 1.4392, G loss: 0.6178\n",
      "[1044/1762] D loss: 1.4154, G loss: 0.7263\n",
      "[1124/1762] D loss: 0.1559, G loss: 3.4140\n",
      "[1204/1762] D loss: 0.3001, G loss: 2.6760\n",
      "[1284/1762] D loss: 1.4009, G loss: 0.6754\n",
      "[1364/1762] D loss: 1.4042, G loss: 0.7187\n",
      "[1444/1762] D loss: 1.4795, G loss: 0.6625\n",
      "[1524/1762] D loss: 0.4430, G loss: 2.5037\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6493\n",
      "[1684/1762] D loss: 1.4087, G loss: 0.7180\n",
      "[1762/1762] D loss: 1.1396, G loss: 0.7073\n",
      "train error: \n",
      " D loss: 1.402896, G loss: 1.253252, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367052, G loss: 1.320257, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2315, G loss: 2.9104\n",
      "[84/1762] D loss: 0.1482, G loss: 2.9370\n",
      "[164/1762] D loss: 0.8266, G loss: 1.6677\n",
      "[244/1762] D loss: 1.3934, G loss: 0.6914\n",
      "[324/1762] D loss: 1.4010, G loss: 0.6717\n",
      "[404/1762] D loss: 1.3906, G loss: 0.6824\n",
      "[484/1762] D loss: 1.1963, G loss: 1.5797\n",
      "[564/1762] D loss: 1.3917, G loss: 0.6949\n",
      "[644/1762] D loss: 1.4343, G loss: 0.7500\n",
      "[724/1762] D loss: 1.3993, G loss: 0.6563\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6755\n",
      "[884/1762] D loss: 0.4123, G loss: 2.5171\n",
      "[964/1762] D loss: 1.2668, G loss: 0.8771\n",
      "[1044/1762] D loss: 1.4034, G loss: 0.7029\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.7131\n",
      "[1204/1762] D loss: 1.4766, G loss: 0.5742\n",
      "[1284/1762] D loss: 0.0123, G loss: 4.6976\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.6964\n",
      "[1444/1762] D loss: 0.1649, G loss: 3.0132\n",
      "[1524/1762] D loss: 1.3852, G loss: 0.6974\n",
      "[1604/1762] D loss: 0.3107, G loss: 2.7426\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6844\n",
      "[1762/1762] D loss: 1.3899, G loss: 0.7057\n",
      "train error: \n",
      " D loss: 1.305950, G loss: 1.086053, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294547, G loss: 1.190766, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.7139\n",
      "[84/1762] D loss: 1.3929, G loss: 0.7082\n",
      "[164/1762] D loss: 1.4807, G loss: 0.9516\n",
      "[244/1762] D loss: 1.3584, G loss: 0.9543\n",
      "[324/1762] D loss: 0.1789, G loss: 3.9816\n",
      "[404/1762] D loss: 1.4044, G loss: 0.6807\n",
      "[484/1762] D loss: 0.3265, G loss: 2.5565\n",
      "[564/1762] D loss: 1.2962, G loss: 0.7050\n",
      "[644/1762] D loss: 1.4298, G loss: 0.7525\n",
      "[724/1762] D loss: 1.3917, G loss: 0.6973\n",
      "[804/1762] D loss: 1.3968, G loss: 0.7058\n",
      "[884/1762] D loss: 1.3956, G loss: 0.7183\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6905\n",
      "[1044/1762] D loss: 1.4181, G loss: 0.6431\n",
      "[1124/1762] D loss: 1.4076, G loss: 0.6947\n",
      "[1204/1762] D loss: 0.2283, G loss: 2.8740\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.7025\n",
      "[1364/1762] D loss: 0.3387, G loss: 2.9622\n",
      "[1444/1762] D loss: 1.2347, G loss: 0.9783\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6532\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.6735\n",
      "[1684/1762] D loss: 1.3971, G loss: 0.6761\n",
      "[1762/1762] D loss: 1.4075, G loss: 0.7388\n",
      "train error: \n",
      " D loss: 1.341905, G loss: 1.064076, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367506, G loss: 1.177939, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4091, G loss: 0.6848\n",
      "[84/1762] D loss: 1.4169, G loss: 0.6854\n",
      "[164/1762] D loss: 1.3943, G loss: 0.7051\n",
      "[244/1762] D loss: 1.4558, G loss: 0.6262\n",
      "[324/1762] D loss: 1.4108, G loss: 0.6159\n",
      "[404/1762] D loss: 1.4236, G loss: 0.5983\n",
      "[484/1762] D loss: 1.3896, G loss: 0.6897\n",
      "[564/1762] D loss: 1.4616, G loss: 0.6176\n",
      "[644/1762] D loss: 1.3912, G loss: 0.6875\n",
      "[724/1762] D loss: 1.3968, G loss: 0.8076\n",
      "[804/1762] D loss: 1.4179, G loss: 0.6387\n",
      "[884/1762] D loss: 0.0201, G loss: 4.8438\n",
      "[964/1762] D loss: 1.3886, G loss: 0.7021\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.7015\n",
      "[1124/1762] D loss: 0.3823, G loss: 2.8156\n",
      "[1204/1762] D loss: 1.5208, G loss: 0.6193\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.7002\n",
      "[1364/1762] D loss: 1.3934, G loss: 0.6702\n",
      "[1444/1762] D loss: 1.3981, G loss: 0.6768\n",
      "[1524/1762] D loss: 0.7466, G loss: 1.3851\n",
      "[1604/1762] D loss: 0.0519, G loss: 4.0041\n",
      "[1684/1762] D loss: 0.1105, G loss: 3.6832\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.6750\n",
      "train error: \n",
      " D loss: 1.306965, G loss: 0.925349, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286518, G loss: 0.997418, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1991, G loss: 4.0578\n",
      "[84/1762] D loss: 1.3918, G loss: 0.6575\n",
      "[164/1762] D loss: 1.3910, G loss: 0.7032\n",
      "[244/1762] D loss: 1.4092, G loss: 0.7173\n",
      "[324/1762] D loss: 1.3939, G loss: 0.6711\n",
      "[404/1762] D loss: 0.1376, G loss: 4.1909\n",
      "[484/1762] D loss: 1.1609, G loss: 1.3701\n",
      "[564/1762] D loss: 1.3880, G loss: 0.7110\n",
      "[644/1762] D loss: 1.3895, G loss: 0.8076\n",
      "[724/1762] D loss: 1.3809, G loss: 0.7029\n",
      "[804/1762] D loss: 1.4278, G loss: 0.6935\n",
      "[884/1762] D loss: 1.3907, G loss: 0.6959\n",
      "[964/1762] D loss: 1.3898, G loss: 0.7077\n",
      "[1044/1762] D loss: 1.3705, G loss: 0.7139\n",
      "[1124/1762] D loss: 1.0816, G loss: 1.5087\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6919\n",
      "[1284/1762] D loss: 0.1313, G loss: 5.8363\n",
      "[1364/1762] D loss: 0.0634, G loss: 5.9900\n",
      "[1444/1762] D loss: 1.7300, G loss: 6.9769\n",
      "[1524/1762] D loss: 0.3506, G loss: 3.4355\n",
      "[1604/1762] D loss: 0.2983, G loss: 2.9753\n",
      "[1684/1762] D loss: 1.3838, G loss: 0.6910\n",
      "[1762/1762] D loss: 1.3959, G loss: 0.6430\n",
      "train error: \n",
      " D loss: 1.330658, G loss: 1.033184, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328929, G loss: 1.132549, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3907, G loss: 0.6670\n",
      "[84/1762] D loss: 1.3905, G loss: 0.6827\n",
      "[164/1762] D loss: 1.4178, G loss: 0.5997\n",
      "[244/1762] D loss: 1.3843, G loss: 0.7123\n",
      "[324/1762] D loss: 1.3938, G loss: 0.6427\n",
      "[404/1762] D loss: 1.4026, G loss: 0.6094\n",
      "[484/1762] D loss: 1.3902, G loss: 0.6469\n",
      "[564/1762] D loss: 1.4025, G loss: 0.6189\n",
      "[644/1762] D loss: 0.2712, G loss: 2.6054\n",
      "[724/1762] D loss: 1.3903, G loss: 0.7252\n",
      "[804/1762] D loss: 1.5080, G loss: 0.7094\n",
      "[884/1762] D loss: 1.3884, G loss: 0.7223\n",
      "[964/1762] D loss: 1.4064, G loss: 0.7143\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.7005\n",
      "[1124/1762] D loss: 1.4207, G loss: 0.6664\n",
      "[1204/1762] D loss: 1.1874, G loss: 1.0450\n",
      "[1284/1762] D loss: 1.4058, G loss: 0.7478\n",
      "[1364/1762] D loss: 0.0764, G loss: 4.1119\n",
      "[1444/1762] D loss: 0.1153, G loss: 4.1654\n",
      "[1524/1762] D loss: 1.3827, G loss: 0.6742\n",
      "[1604/1762] D loss: 0.0826, G loss: 3.8119\n",
      "[1684/1762] D loss: 1.4025, G loss: 0.6763\n",
      "[1762/1762] D loss: 1.4231, G loss: 0.5981\n",
      "train error: \n",
      " D loss: 1.293757, G loss: 1.001158, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270994, G loss: 1.142155, D accuracy: 55.6%, cell accuracy: 99.5%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962, G loss: 0.6187\n",
      "[84/1762] D loss: 1.6958, G loss: 0.7103\n",
      "[164/1762] D loss: 1.3882, G loss: 0.6845\n",
      "[244/1762] D loss: 1.3897, G loss: 0.6637\n",
      "[324/1762] D loss: 0.0303, G loss: 6.0600\n",
      "[404/1762] D loss: 1.1964, G loss: 1.2233\n",
      "[484/1762] D loss: 1.4633, G loss: 0.5792\n",
      "[564/1762] D loss: 1.3902, G loss: 0.7046\n",
      "[644/1762] D loss: 0.1998, G loss: 3.8792\n",
      "[724/1762] D loss: 1.4003, G loss: 0.6898\n",
      "[804/1762] D loss: 1.1783, G loss: 1.4485\n",
      "[884/1762] D loss: 1.4008, G loss: 0.6574\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6969\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6896\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.6962\n",
      "[1204/1762] D loss: 0.1970, G loss: 3.8014\n",
      "[1284/1762] D loss: 1.4126, G loss: 0.6523\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6912\n",
      "[1444/1762] D loss: 0.1736, G loss: 3.9231\n",
      "[1524/1762] D loss: 1.4139, G loss: 0.6366\n",
      "[1604/1762] D loss: 0.0248, G loss: 4.8572\n",
      "[1684/1762] D loss: 0.0801, G loss: 3.6438\n",
      "[1762/1762] D loss: 1.4181, G loss: 0.6044\n",
      "train error: \n",
      " D loss: 1.576980, G loss: 1.571412, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.555595, G loss: 1.664167, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.6547\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6064\n",
      "[164/1762] D loss: 1.3943, G loss: 0.6891\n",
      "[244/1762] D loss: 0.9650, G loss: 3.0848\n",
      "[324/1762] D loss: 1.4360, G loss: 0.6700\n",
      "[404/1762] D loss: 1.3924, G loss: 0.6775\n",
      "[484/1762] D loss: 1.3947, G loss: 0.7108\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6826\n",
      "[644/1762] D loss: 1.3892, G loss: 0.6584\n",
      "[724/1762] D loss: 1.3946, G loss: 0.6975\n",
      "[804/1762] D loss: 1.3917, G loss: 0.6533\n",
      "[884/1762] D loss: 1.3980, G loss: 0.6407\n",
      "[964/1762] D loss: 0.0070, G loss: 5.6484\n",
      "[1044/1762] D loss: 1.3896, G loss: 0.7110\n",
      "[1124/1762] D loss: 0.0004, G loss: 8.2895\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6868\n",
      "[1284/1762] D loss: 0.0487, G loss: 4.5670\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6755\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.6873\n",
      "[1524/1762] D loss: 1.3815, G loss: 1.3591\n",
      "[1604/1762] D loss: 1.4225, G loss: 0.6527\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7035\n",
      "[1762/1762] D loss: 1.4108, G loss: 0.6251\n",
      "train error: \n",
      " D loss: 1.296929, G loss: 1.186990, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270979, G loss: 1.313612, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0011, G loss: 10.9060\n",
      "[84/1762] D loss: 0.0589, G loss: 4.6753\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6643\n",
      "[244/1762] D loss: 1.3878, G loss: 0.6796\n",
      "[324/1762] D loss: 1.3943, G loss: 0.7161\n",
      "[404/1762] D loss: 1.3914, G loss: 0.6499\n",
      "[484/1762] D loss: 1.3932, G loss: 0.6551\n",
      "[564/1762] D loss: 1.8759, G loss: 0.5493\n",
      "[644/1762] D loss: 0.0018, G loss: 6.6988\n",
      "[724/1762] D loss: 1.3884, G loss: 0.7252\n",
      "[804/1762] D loss: 1.3893, G loss: 0.7340\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7186\n",
      "[964/1762] D loss: 1.3927, G loss: 0.7495\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6874\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.7151\n",
      "[1204/1762] D loss: 0.0648, G loss: 4.4456\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.6758\n",
      "[1364/1762] D loss: 1.3887, G loss: 0.7144\n",
      "[1444/1762] D loss: 1.3974, G loss: 0.6288\n",
      "[1524/1762] D loss: 0.0419, G loss: 4.9031\n",
      "[1604/1762] D loss: 0.0263, G loss: 4.8495\n",
      "[1684/1762] D loss: 1.4010, G loss: 0.6761\n",
      "[1762/1762] D loss: 1.3966, G loss: 0.6773\n",
      "train error: \n",
      " D loss: 1.290832, G loss: 1.115951, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272145, G loss: 1.253436, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.6688\n",
      "[84/1762] D loss: 1.3967, G loss: 0.6861\n",
      "[164/1762] D loss: 1.3925, G loss: 0.6416\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6805\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6644\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6744\n",
      "[484/1762] D loss: 1.2510, G loss: 0.7438\n",
      "[564/1762] D loss: 1.3887, G loss: 0.7160\n",
      "[644/1762] D loss: 0.0199, G loss: 5.3087\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6763\n",
      "[804/1762] D loss: 0.1098, G loss: 5.0985\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6888\n",
      "[964/1762] D loss: 0.0134, G loss: 5.2340\n",
      "[1044/1762] D loss: 0.0144, G loss: 5.2437\n",
      "[1124/1762] D loss: 1.4340, G loss: 0.6117\n",
      "[1204/1762] D loss: 1.3935, G loss: 0.7086\n",
      "[1284/1762] D loss: 1.4054, G loss: 0.6178\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.6597\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6535\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6991\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6847\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.6903\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.7232\n",
      "train error: \n",
      " D loss: 1.511508, G loss: 1.532221, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.492128, G loss: 1.673055, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.6948\n",
      "[84/1762] D loss: 1.3955, G loss: 0.6425\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6968\n",
      "[244/1762] D loss: 1.3882, G loss: 0.6704\n",
      "[324/1762] D loss: 0.0092, G loss: 6.0737\n",
      "[404/1762] D loss: 1.3961, G loss: 0.7175\n",
      "[484/1762] D loss: 0.6997, G loss: 7.7392\n",
      "[564/1762] D loss: 0.0976, G loss: 5.5724\n",
      "[644/1762] D loss: 0.7393, G loss: 4.1859\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6469\n",
      "[804/1762] D loss: 0.0444, G loss: 5.0737\n",
      "[884/1762] D loss: 1.3890, G loss: 0.6670\n",
      "[964/1762] D loss: 1.3814, G loss: 0.6679\n",
      "[1044/1762] D loss: 1.4011, G loss: 0.6085\n",
      "[1124/1762] D loss: 1.3933, G loss: 0.6367\n",
      "[1204/1762] D loss: 0.3097, G loss: 2.7207\n",
      "[1284/1762] D loss: 1.3846, G loss: 0.6900\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6720\n",
      "[1444/1762] D loss: 1.5442, G loss: 0.5927\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.6671\n",
      "[1604/1762] D loss: 0.0396, G loss: 4.8910\n",
      "[1684/1762] D loss: 1.1945, G loss: 1.0580\n",
      "[1762/1762] D loss: 0.0014, G loss: 12.5271\n",
      "train error: \n",
      " D loss: 2.266634, G loss: 2.734824, D accuracy: 51.7%, cell accuracy: 99.3%, board accuracy: 73.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.250486, G loss: 3.093052, D accuracy: 52.5%, cell accuracy: 99.0%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0226, G loss: 8.8047\n",
      "[84/1762] D loss: 1.3557, G loss: 0.8916\n",
      "[164/1762] D loss: 1.4282, G loss: 0.5557\n",
      "[244/1762] D loss: 0.0247, G loss: 4.8065\n",
      "[324/1762] D loss: 0.0033, G loss: 7.5756\n",
      "[404/1762] D loss: 1.3958, G loss: 0.6698\n",
      "[484/1762] D loss: 1.9034, G loss: 0.4858\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6797\n",
      "[644/1762] D loss: 1.3942, G loss: 0.6665\n",
      "[724/1762] D loss: 1.3918, G loss: 0.6595\n",
      "[804/1762] D loss: 1.4123, G loss: 0.6255\n",
      "[884/1762] D loss: 0.1470, G loss: 4.9721\n",
      "[964/1762] D loss: 0.1345, G loss: 5.3264\n",
      "[1044/1762] D loss: 1.3915, G loss: 0.6875\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.6511\n",
      "[1204/1762] D loss: 0.0699, G loss: 4.5388\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6688\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.6416\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.7036\n",
      "[1524/1762] D loss: 1.1202, G loss: 1.9218\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.6780\n",
      "[1684/1762] D loss: 0.0228, G loss: 6.6871\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6548\n",
      "train error: \n",
      " D loss: 1.286741, G loss: 1.092871, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258930, G loss: 1.226417, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0031, G loss: 9.1764\n",
      "[84/1762] D loss: 1.3968, G loss: 0.6276\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6902\n",
      "[244/1762] D loss: 0.6484, G loss: 7.7942\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6745\n",
      "[404/1762] D loss: 0.0276, G loss: 4.8832\n",
      "[484/1762] D loss: 1.3858, G loss: 0.6828\n",
      "[564/1762] D loss: 1.3892, G loss: 0.6971\n",
      "[644/1762] D loss: 1.3902, G loss: 0.6622\n",
      "[724/1762] D loss: 1.3902, G loss: 0.6811\n",
      "[804/1762] D loss: 0.0214, G loss: 5.3315\n",
      "[884/1762] D loss: 0.0134, G loss: 5.2980\n",
      "[964/1762] D loss: 1.3890, G loss: 0.6754\n",
      "[1044/1762] D loss: 1.4312, G loss: 0.6483\n",
      "[1124/1762] D loss: 1.3961, G loss: 0.6229\n",
      "[1204/1762] D loss: 1.3852, G loss: 0.8637\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6949\n",
      "[1364/1762] D loss: 1.4112, G loss: 0.5873\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.6945\n",
      "[1524/1762] D loss: 1.3898, G loss: 0.6742\n",
      "[1604/1762] D loss: 1.4674, G loss: 0.6264\n",
      "[1684/1762] D loss: 0.3330, G loss: 3.2102\n",
      "[1762/1762] D loss: 0.9416, G loss: 2.6402\n",
      "train error: \n",
      " D loss: 1.307831, G loss: 1.291288, D accuracy: 52.1%, cell accuracy: 99.5%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271435, G loss: 1.445024, D accuracy: 53.5%, cell accuracy: 99.4%, board accuracy: 75.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3051, G loss: 0.8732\n",
      "[84/1762] D loss: 1.3131, G loss: 0.8050\n",
      "[164/1762] D loss: 1.1591, G loss: 0.8694\n",
      "[244/1762] D loss: 1.0588, G loss: 0.9044\n",
      "[324/1762] D loss: 0.7888, G loss: 1.2210\n",
      "[404/1762] D loss: 0.6676, G loss: 1.3030\n",
      "[484/1762] D loss: 0.8365, G loss: 1.9691\n",
      "[564/1762] D loss: 1.0108, G loss: 1.4212\n",
      "[644/1762] D loss: 0.7711, G loss: 1.9723\n",
      "[724/1762] D loss: 1.1836, G loss: 1.1516\n",
      "[804/1762] D loss: 0.9011, G loss: 0.1965\n",
      "[884/1762] D loss: 1.0503, G loss: 2.7025\n",
      "[964/1762] D loss: 1.5228, G loss: 1.5826\n",
      "[1044/1762] D loss: 1.0535, G loss: 1.0688\n",
      "[1124/1762] D loss: 1.4018, G loss: 0.5841\n",
      "[1204/1762] D loss: 1.1885, G loss: 0.9506\n",
      "[1284/1762] D loss: 1.3244, G loss: 0.4928\n",
      "[1364/1762] D loss: 1.3447, G loss: 0.6124\n",
      "[1444/1762] D loss: 1.3598, G loss: 0.6551\n",
      "[1524/1762] D loss: 1.1558, G loss: 0.6537\n",
      "[1604/1762] D loss: 1.4265, G loss: 0.5657\n",
      "[1684/1762] D loss: 1.3083, G loss: 0.7859\n",
      "[1762/1762] D loss: 1.3391, G loss: 1.0878\n",
      "train error: \n",
      " D loss: 1.362568, G loss: 0.806702, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361578, G loss: 0.813342, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3407, G loss: 0.6817\n",
      "[84/1762] D loss: 1.2279, G loss: 1.0905\n",
      "[164/1762] D loss: 1.2109, G loss: 1.2991\n",
      "[244/1762] D loss: 1.3805, G loss: 0.6854\n",
      "[324/1762] D loss: 1.3857, G loss: 0.8014\n",
      "[404/1762] D loss: 1.1621, G loss: 0.8250\n",
      "[484/1762] D loss: 1.3853, G loss: 0.6966\n",
      "[564/1762] D loss: 1.1200, G loss: 1.0634\n",
      "[644/1762] D loss: 1.3762, G loss: 0.5893\n",
      "[724/1762] D loss: 1.0834, G loss: 0.9544\n",
      "[804/1762] D loss: 1.1001, G loss: 1.6228\n",
      "[884/1762] D loss: 1.3745, G loss: 0.6207\n",
      "[964/1762] D loss: 1.3682, G loss: 0.7950\n",
      "[1044/1762] D loss: 1.3484, G loss: 0.9647\n",
      "[1124/1762] D loss: 1.3292, G loss: 0.5800\n",
      "[1204/1762] D loss: 1.3142, G loss: 0.7325\n",
      "[1284/1762] D loss: 0.9860, G loss: 0.8552\n",
      "[1364/1762] D loss: 0.9963, G loss: 1.0980\n",
      "[1444/1762] D loss: 1.3729, G loss: 0.8153\n",
      "[1524/1762] D loss: 1.3979, G loss: 0.6892\n",
      "[1604/1762] D loss: 1.3400, G loss: 0.7652\n",
      "[1684/1762] D loss: 1.4520, G loss: 0.7293\n",
      "[1762/1762] D loss: 1.4346, G loss: 0.8973\n",
      "train error: \n",
      " D loss: 1.410658, G loss: 1.095744, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408216, G loss: 1.137377, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8193, G loss: 1.1330\n",
      "[84/1762] D loss: 1.4379, G loss: 0.6302\n",
      "[164/1762] D loss: 1.4514, G loss: 0.8403\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6654\n",
      "[324/1762] D loss: 0.8189, G loss: 1.1385\n",
      "[404/1762] D loss: 1.3927, G loss: 0.8070\n",
      "[484/1762] D loss: 1.4858, G loss: 0.4483\n",
      "[564/1762] D loss: 0.6050, G loss: 1.4127\n",
      "[644/1762] D loss: 0.6308, G loss: 1.2710\n",
      "[724/1762] D loss: 1.3954, G loss: 0.7359\n",
      "[804/1762] D loss: 1.3996, G loss: 0.6163\n",
      "[884/1762] D loss: 1.2765, G loss: 0.6279\n",
      "[964/1762] D loss: 1.3422, G loss: 0.7291\n",
      "[1044/1762] D loss: 1.5118, G loss: 0.5464\n",
      "[1124/1762] D loss: 1.4436, G loss: 0.6033\n",
      "[1204/1762] D loss: 0.6928, G loss: 1.3213\n",
      "[1284/1762] D loss: 0.5321, G loss: 1.4370\n",
      "[1364/1762] D loss: 1.3964, G loss: 0.6960\n",
      "[1444/1762] D loss: 1.3142, G loss: 0.8486\n",
      "[1524/1762] D loss: 1.4576, G loss: 0.7690\n",
      "[1604/1762] D loss: 1.3814, G loss: 0.7054\n",
      "[1684/1762] D loss: 1.3521, G loss: 0.7235\n",
      "[1762/1762] D loss: 0.3095, G loss: 2.2636\n",
      "train error: \n",
      " D loss: 1.371459, G loss: 0.909811, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347708, G loss: 0.916496, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6872, G loss: 0.3326\n",
      "[84/1762] D loss: 1.5325, G loss: 0.5842\n",
      "[164/1762] D loss: 1.6076, G loss: 0.9297\n",
      "[244/1762] D loss: 0.3684, G loss: 1.8206\n",
      "[324/1762] D loss: 1.5570, G loss: 0.5310\n",
      "[404/1762] D loss: 1.4078, G loss: 0.7135\n",
      "[484/1762] D loss: 1.3189, G loss: 0.7392\n",
      "[564/1762] D loss: 1.4054, G loss: 0.7048\n",
      "[644/1762] D loss: 0.7867, G loss: 1.3605\n",
      "[724/1762] D loss: 1.4350, G loss: 0.7260\n",
      "[804/1762] D loss: 1.3893, G loss: 0.7084\n",
      "[884/1762] D loss: 0.7782, G loss: 1.4075\n",
      "[964/1762] D loss: 1.4633, G loss: 0.6117\n",
      "[1044/1762] D loss: 0.6663, G loss: 1.3605\n",
      "[1124/1762] D loss: 1.4511, G loss: 0.6441\n",
      "[1204/1762] D loss: 0.5768, G loss: 1.4745\n",
      "[1284/1762] D loss: 0.5510, G loss: 1.6110\n",
      "[1364/1762] D loss: 1.4069, G loss: 0.6908\n",
      "[1444/1762] D loss: 1.1845, G loss: 0.9376\n",
      "[1524/1762] D loss: 1.4306, G loss: 0.7819\n",
      "[1604/1762] D loss: 0.4749, G loss: 1.6081\n",
      "[1684/1762] D loss: 1.5423, G loss: 0.5829\n",
      "[1762/1762] D loss: 1.4149, G loss: 0.5981\n",
      "train error: \n",
      " D loss: 1.388201, G loss: 0.535842, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367466, G loss: 0.557039, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3961, G loss: 0.6970\n",
      "[84/1762] D loss: 1.4251, G loss: 0.7618\n",
      "[164/1762] D loss: 1.5352, G loss: 0.5423\n",
      "[244/1762] D loss: 0.6954, G loss: 1.8415\n",
      "[324/1762] D loss: 1.4598, G loss: 0.6637\n",
      "[404/1762] D loss: 1.4241, G loss: 0.6786\n",
      "[484/1762] D loss: 1.4556, G loss: 0.6022\n",
      "[564/1762] D loss: 1.4501, G loss: 0.6739\n",
      "[644/1762] D loss: 1.3616, G loss: 0.6986\n",
      "[724/1762] D loss: 1.4578, G loss: 0.6101\n",
      "[804/1762] D loss: 1.5368, G loss: 0.7015\n",
      "[884/1762] D loss: 1.4284, G loss: 0.7714\n",
      "[964/1762] D loss: 1.4486, G loss: 0.6990\n",
      "[1044/1762] D loss: 1.5955, G loss: 0.6309\n",
      "[1124/1762] D loss: 0.5532, G loss: 1.4745\n",
      "[1204/1762] D loss: 1.4868, G loss: 0.6282\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.6751\n",
      "[1364/1762] D loss: 1.5054, G loss: 0.7590\n",
      "[1444/1762] D loss: 0.5516, G loss: 2.1335\n",
      "[1524/1762] D loss: 1.4395, G loss: 0.7005\n",
      "[1604/1762] D loss: 1.7537, G loss: 0.7157\n",
      "[1684/1762] D loss: 1.4009, G loss: 0.6853\n",
      "[1762/1762] D loss: 1.4329, G loss: 0.7668\n",
      "train error: \n",
      " D loss: 1.333207, G loss: 0.861961, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315017, G loss: 0.885307, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4982, G loss: 0.6889\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6860\n",
      "[164/1762] D loss: 1.3866, G loss: 0.7936\n",
      "[244/1762] D loss: 1.4790, G loss: 0.6190\n",
      "[324/1762] D loss: 1.5824, G loss: 0.7616\n",
      "[404/1762] D loss: 1.3981, G loss: 0.7138\n",
      "[484/1762] D loss: 1.3835, G loss: 0.6886\n",
      "[564/1762] D loss: 1.5182, G loss: 0.7182\n",
      "[644/1762] D loss: 1.3966, G loss: 0.6962\n",
      "[724/1762] D loss: 1.5584, G loss: 0.6749\n",
      "[804/1762] D loss: 1.4705, G loss: 0.6038\n",
      "[884/1762] D loss: 1.4100, G loss: 0.7035\n",
      "[964/1762] D loss: 1.4201, G loss: 0.7093\n",
      "[1044/1762] D loss: 1.4125, G loss: 1.0062\n",
      "[1124/1762] D loss: 1.3677, G loss: 0.7604\n",
      "[1204/1762] D loss: 1.8034, G loss: 0.8124\n",
      "[1284/1762] D loss: 0.4380, G loss: 1.6199\n",
      "[1364/1762] D loss: 0.4157, G loss: 1.6234\n",
      "[1444/1762] D loss: 1.3930, G loss: 0.6652\n",
      "[1524/1762] D loss: 1.4078, G loss: 0.6831\n",
      "[1604/1762] D loss: 1.3980, G loss: 0.7160\n",
      "[1684/1762] D loss: 0.4037, G loss: 1.7338\n",
      "[1762/1762] D loss: 1.4486, G loss: 0.6663\n",
      "train error: \n",
      " D loss: 1.594417, G loss: 0.330684, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.585638, G loss: 0.330120, D accuracy: 50.0%, cell accuracy: 99.6%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.6477\n",
      "[84/1762] D loss: 0.5954, G loss: 1.4843\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6765\n",
      "[244/1762] D loss: 1.3925, G loss: 0.6792\n",
      "[324/1762] D loss: 0.5023, G loss: 1.5798\n",
      "[404/1762] D loss: 1.3853, G loss: 0.7015\n",
      "[484/1762] D loss: 0.6342, G loss: 1.3665\n",
      "[564/1762] D loss: 1.4463, G loss: 0.7269\n",
      "[644/1762] D loss: 1.4270, G loss: 0.6703\n",
      "[724/1762] D loss: 0.4518, G loss: 1.6513\n",
      "[804/1762] D loss: 0.5465, G loss: 1.5570\n",
      "[884/1762] D loss: 1.4073, G loss: 0.7207\n",
      "[964/1762] D loss: 1.4259, G loss: 0.6817\n",
      "[1044/1762] D loss: 1.3683, G loss: 0.7106\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.7000\n",
      "[1204/1762] D loss: 0.3728, G loss: 1.9065\n",
      "[1284/1762] D loss: 0.4767, G loss: 1.6101\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6941\n",
      "[1444/1762] D loss: 1.6042, G loss: 0.5612\n",
      "[1524/1762] D loss: 1.4127, G loss: 0.6476\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.6835\n",
      "[1684/1762] D loss: 1.4002, G loss: 0.6717\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.9417\n",
      "train error: \n",
      " D loss: 1.356744, G loss: 0.794881, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337683, G loss: 0.823154, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4543, G loss: 0.7308\n",
      "[84/1762] D loss: 0.3455, G loss: 1.7069\n",
      "[164/1762] D loss: 1.3929, G loss: 0.7360\n",
      "[244/1762] D loss: 1.5754, G loss: 0.7717\n",
      "[324/1762] D loss: 0.2045, G loss: 2.2270\n",
      "[404/1762] D loss: 1.3853, G loss: 0.6898\n",
      "[484/1762] D loss: 1.3468, G loss: 0.6853\n",
      "[564/1762] D loss: 1.4152, G loss: 0.6908\n",
      "[644/1762] D loss: 0.2487, G loss: 1.9136\n",
      "[724/1762] D loss: 1.4784, G loss: 0.7398\n",
      "[804/1762] D loss: 1.8519, G loss: 0.8182\n",
      "[884/1762] D loss: 0.4350, G loss: 1.6100\n",
      "[964/1762] D loss: 0.3209, G loss: 1.6350\n",
      "[1044/1762] D loss: 1.4053, G loss: 0.6756\n",
      "[1124/1762] D loss: 1.4222, G loss: 0.7228\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.6842\n",
      "[1284/1762] D loss: 1.4208, G loss: 0.6798\n",
      "[1364/1762] D loss: 0.4521, G loss: 1.4927\n",
      "[1444/1762] D loss: 0.2862, G loss: 1.7782\n",
      "[1524/1762] D loss: 1.3889, G loss: 0.7005\n",
      "[1604/1762] D loss: 1.5440, G loss: 0.6743\n",
      "[1684/1762] D loss: 1.4170, G loss: 0.6918\n",
      "[1762/1762] D loss: 0.2879, G loss: 2.9443\n",
      "train error: \n",
      " D loss: 1.441217, G loss: 1.721575, D accuracy: 53.2%, cell accuracy: 99.0%, board accuracy: 55.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.433317, G loss: 1.735169, D accuracy: 53.8%, cell accuracy: 98.9%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0408, G loss: 1.2368\n",
      "[84/1762] D loss: 0.5070, G loss: 1.4166\n",
      "[164/1762] D loss: 1.4171, G loss: 0.6865\n",
      "[244/1762] D loss: 1.4277, G loss: 0.7128\n",
      "[324/1762] D loss: 1.4286, G loss: 0.7297\n",
      "[404/1762] D loss: 1.4141, G loss: 0.7174\n",
      "[484/1762] D loss: 1.5776, G loss: 0.7905\n",
      "[564/1762] D loss: 1.3902, G loss: 0.7129\n",
      "[644/1762] D loss: 1.4243, G loss: 0.6942\n",
      "[724/1762] D loss: 0.2799, G loss: 1.9872\n",
      "[804/1762] D loss: 1.4090, G loss: 0.7687\n",
      "[884/1762] D loss: 1.4230, G loss: 0.9079\n",
      "[964/1762] D loss: 1.4194, G loss: 0.6686\n",
      "[1044/1762] D loss: 1.3736, G loss: 0.7461\n",
      "[1124/1762] D loss: 0.4508, G loss: 1.6301\n",
      "[1204/1762] D loss: 1.4045, G loss: 0.6877\n",
      "[1284/1762] D loss: 1.4463, G loss: 0.7050\n",
      "[1364/1762] D loss: 1.4788, G loss: 0.7810\n",
      "[1444/1762] D loss: 1.3986, G loss: 0.7238\n",
      "[1524/1762] D loss: 1.3791, G loss: 0.7130\n",
      "[1604/1762] D loss: 1.4256, G loss: 0.7155\n",
      "[1684/1762] D loss: 0.3360, G loss: 1.7608\n",
      "[1762/1762] D loss: 1.4771, G loss: 0.5085\n",
      "train error: \n",
      " D loss: 1.367573, G loss: 0.729476, D accuracy: 50.5%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351462, G loss: 0.738420, D accuracy: 51.8%, cell accuracy: 99.6%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3544, G loss: 0.7613\n",
      "[84/1762] D loss: 1.5798, G loss: 0.7256\n",
      "[164/1762] D loss: 1.5361, G loss: 0.6007\n",
      "[244/1762] D loss: 1.4100, G loss: 0.7051\n",
      "[324/1762] D loss: 1.4409, G loss: 0.6588\n",
      "[404/1762] D loss: 1.4147, G loss: 0.6644\n",
      "[484/1762] D loss: 1.4027, G loss: 0.6975\n",
      "[564/1762] D loss: 1.4035, G loss: 0.6982\n",
      "[644/1762] D loss: 1.3982, G loss: 0.6917\n",
      "[724/1762] D loss: 1.3315, G loss: 0.6845\n",
      "[804/1762] D loss: 0.3892, G loss: 1.6824\n",
      "[884/1762] D loss: 1.4236, G loss: 0.6746\n",
      "[964/1762] D loss: 1.4666, G loss: 0.7274\n",
      "[1044/1762] D loss: 1.4820, G loss: 0.7513\n",
      "[1124/1762] D loss: 1.3922, G loss: 0.6889\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.7181\n",
      "[1284/1762] D loss: 1.4006, G loss: 0.7116\n",
      "[1364/1762] D loss: 1.3947, G loss: 0.7291\n",
      "[1444/1762] D loss: 1.4496, G loss: 0.6960\n",
      "[1524/1762] D loss: 0.5180, G loss: 1.6371\n",
      "[1604/1762] D loss: 1.5145, G loss: 0.7376\n",
      "[1684/1762] D loss: 1.4437, G loss: 0.7073\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7179\n",
      "train error: \n",
      " D loss: 1.330431, G loss: 0.757159, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309449, G loss: 0.768146, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3986, G loss: 0.7172\n",
      "[84/1762] D loss: 1.3962, G loss: 0.7258\n",
      "[164/1762] D loss: 0.5078, G loss: 1.4474\n",
      "[244/1762] D loss: 0.3371, G loss: 1.6380\n",
      "[324/1762] D loss: 0.3327, G loss: 1.7412\n",
      "[404/1762] D loss: 0.4355, G loss: 1.5323\n",
      "[484/1762] D loss: 1.3969, G loss: 0.7205\n",
      "[564/1762] D loss: 1.4405, G loss: 0.6405\n",
      "[644/1762] D loss: 0.3029, G loss: 1.7826\n",
      "[724/1762] D loss: 1.3998, G loss: 0.7094\n",
      "[804/1762] D loss: 1.3919, G loss: 0.6885\n",
      "[884/1762] D loss: 1.4618, G loss: 0.8512\n",
      "[964/1762] D loss: 0.4367, G loss: 1.5496\n",
      "[1044/1762] D loss: 1.4227, G loss: 0.7084\n",
      "[1124/1762] D loss: 1.3957, G loss: 0.7072\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.7472\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7026\n",
      "[1364/1762] D loss: 1.4206, G loss: 0.6468\n",
      "[1444/1762] D loss: 1.4982, G loss: 0.6489\n",
      "[1524/1762] D loss: 1.4543, G loss: 0.6212\n",
      "[1604/1762] D loss: 1.4451, G loss: 0.7520\n",
      "[1684/1762] D loss: 0.3197, G loss: 1.8625\n",
      "[1762/1762] D loss: 1.4740, G loss: 0.9059\n",
      "train error: \n",
      " D loss: 1.343072, G loss: 0.720349, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327139, G loss: 0.722131, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4822, G loss: 0.6743\n",
      "[84/1762] D loss: 1.4030, G loss: 0.6839\n",
      "[164/1762] D loss: 0.2166, G loss: 2.0904\n",
      "[244/1762] D loss: 1.4788, G loss: 0.6769\n",
      "[324/1762] D loss: 1.4542, G loss: 0.6890\n",
      "[404/1762] D loss: 1.5727, G loss: 0.4819\n",
      "[484/1762] D loss: 1.3825, G loss: 0.6933\n",
      "[564/1762] D loss: 0.4209, G loss: 1.6167\n",
      "[644/1762] D loss: 1.4368, G loss: 0.6578\n",
      "[724/1762] D loss: 0.4525, G loss: 1.5470\n",
      "[804/1762] D loss: 1.4016, G loss: 0.6734\n",
      "[884/1762] D loss: 1.4115, G loss: 0.7091\n",
      "[964/1762] D loss: 1.4078, G loss: 0.7055\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.6940\n",
      "[1124/1762] D loss: 1.3974, G loss: 0.6789\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.7007\n",
      "[1284/1762] D loss: 1.3497, G loss: 0.7317\n",
      "[1364/1762] D loss: 1.4361, G loss: 0.8205\n",
      "[1444/1762] D loss: 1.4183, G loss: 0.7033\n",
      "[1524/1762] D loss: 1.5921, G loss: 0.6268\n",
      "[1604/1762] D loss: 1.3835, G loss: 0.7398\n",
      "[1684/1762] D loss: 1.3639, G loss: 0.6866\n",
      "[1762/1762] D loss: 1.4006, G loss: 0.6722\n",
      "train error: \n",
      " D loss: 1.323509, G loss: 0.776927, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299035, G loss: 0.789278, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3983, G loss: 0.6862\n",
      "[84/1762] D loss: 0.6419, G loss: 1.4694\n",
      "[164/1762] D loss: 0.4219, G loss: 1.7732\n",
      "[244/1762] D loss: 1.2236, G loss: 0.8165\n",
      "[324/1762] D loss: 1.3892, G loss: 0.6909\n",
      "[404/1762] D loss: 1.4618, G loss: 0.7796\n",
      "[484/1762] D loss: 1.4543, G loss: 0.7009\n",
      "[564/1762] D loss: 1.4710, G loss: 0.6769\n",
      "[644/1762] D loss: 0.1597, G loss: 2.2926\n",
      "[724/1762] D loss: 0.1780, G loss: 2.2093\n",
      "[804/1762] D loss: 1.4108, G loss: 0.7051\n",
      "[884/1762] D loss: 0.1975, G loss: 2.3436\n",
      "[964/1762] D loss: 0.8736, G loss: 1.2407\n",
      "[1044/1762] D loss: 1.4346, G loss: 0.7364\n",
      "[1124/1762] D loss: 1.4349, G loss: 0.6610\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6938\n",
      "[1284/1762] D loss: 1.3422, G loss: 0.7155\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.6612\n",
      "[1444/1762] D loss: 1.4128, G loss: 0.6643\n",
      "[1524/1762] D loss: 0.2457, G loss: 1.9361\n",
      "[1604/1762] D loss: 1.4428, G loss: 0.6750\n",
      "[1684/1762] D loss: 0.2190, G loss: 2.1919\n",
      "[1762/1762] D loss: 1.5922, G loss: 0.5316\n",
      "train error: \n",
      " D loss: 1.395711, G loss: 0.543939, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378659, G loss: 0.549309, D accuracy: 52.0%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4355, G loss: 0.6317\n",
      "[84/1762] D loss: 1.5122, G loss: 0.6484\n",
      "[164/1762] D loss: 0.1931, G loss: 2.2486\n",
      "[244/1762] D loss: 1.4384, G loss: 0.7669\n",
      "[324/1762] D loss: 1.3956, G loss: 0.6988\n",
      "[404/1762] D loss: 1.3963, G loss: 0.6682\n",
      "[484/1762] D loss: 1.3109, G loss: 0.8554\n",
      "[564/1762] D loss: 1.3891, G loss: 0.6809\n",
      "[644/1762] D loss: 1.4520, G loss: 0.6311\n",
      "[724/1762] D loss: 1.4447, G loss: 0.5935\n",
      "[804/1762] D loss: 1.4081, G loss: 0.6787\n",
      "[884/1762] D loss: 1.4461, G loss: 0.6797\n",
      "[964/1762] D loss: 1.8097, G loss: 0.5589\n",
      "[1044/1762] D loss: 1.4361, G loss: 0.6460\n",
      "[1124/1762] D loss: 1.4124, G loss: 0.7215\n",
      "[1204/1762] D loss: 0.2183, G loss: 2.0703\n",
      "[1284/1762] D loss: 0.5174, G loss: 1.5237\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7021\n",
      "[1444/1762] D loss: 0.1790, G loss: 2.3732\n",
      "[1524/1762] D loss: 1.4032, G loss: 0.6255\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.8502\n",
      "[1684/1762] D loss: 0.1793, G loss: 2.3454\n",
      "[1762/1762] D loss: 1.2775, G loss: 0.7436\n",
      "train error: \n",
      " D loss: 1.339733, G loss: 0.672769, D accuracy: 61.8%, cell accuracy: 98.6%, board accuracy: 27.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339415, G loss: 0.667591, D accuracy: 60.3%, cell accuracy: 98.4%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3813, G loss: 0.6045\n",
      "[84/1762] D loss: 1.2720, G loss: 0.8230\n",
      "[164/1762] D loss: 0.4853, G loss: 1.8410\n",
      "[244/1762] D loss: 1.4026, G loss: 0.6057\n",
      "[324/1762] D loss: 1.3991, G loss: 0.6857\n",
      "[404/1762] D loss: 1.3809, G loss: 0.7670\n",
      "[484/1762] D loss: 1.3976, G loss: 0.7019\n",
      "[564/1762] D loss: 1.6034, G loss: 0.4986\n",
      "[644/1762] D loss: 1.7907, G loss: 0.6827\n",
      "[724/1762] D loss: 1.4320, G loss: 0.5626\n",
      "[804/1762] D loss: 1.9553, G loss: 0.7749\n",
      "[884/1762] D loss: 1.4403, G loss: 0.6722\n",
      "[964/1762] D loss: 1.4020, G loss: 0.7060\n",
      "[1044/1762] D loss: 1.4307, G loss: 0.6357\n",
      "[1124/1762] D loss: 0.1892, G loss: 2.2155\n",
      "[1204/1762] D loss: 1.4053, G loss: 0.6455\n",
      "[1284/1762] D loss: 0.2005, G loss: 2.2020\n",
      "[1364/1762] D loss: 1.4169, G loss: 0.7077\n",
      "[1444/1762] D loss: 1.4594, G loss: 0.6354\n",
      "[1524/1762] D loss: 0.2636, G loss: 1.9917\n",
      "[1604/1762] D loss: 0.2864, G loss: 1.9195\n",
      "[1684/1762] D loss: 1.5364, G loss: 0.6856\n",
      "[1762/1762] D loss: 1.4017, G loss: 0.7920\n",
      "train error: \n",
      " D loss: 1.325457, G loss: 0.752605, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307551, G loss: 0.775651, D accuracy: 55.0%, cell accuracy: 99.6%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3934, G loss: 0.6583\n",
      "[84/1762] D loss: 1.5990, G loss: 0.5514\n",
      "[164/1762] D loss: 1.4904, G loss: 0.8260\n",
      "[244/1762] D loss: 1.4229, G loss: 0.7888\n",
      "[324/1762] D loss: 1.4211, G loss: 0.7205\n",
      "[404/1762] D loss: 1.3944, G loss: 0.7447\n",
      "[484/1762] D loss: 0.2409, G loss: 2.1128\n",
      "[564/1762] D loss: 0.2992, G loss: 1.8469\n",
      "[644/1762] D loss: 1.3364, G loss: 0.7707\n",
      "[724/1762] D loss: 0.3824, G loss: 1.9433\n",
      "[804/1762] D loss: 1.3826, G loss: 0.7218\n",
      "[884/1762] D loss: 0.2473, G loss: 2.1600\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6889\n",
      "[1044/1762] D loss: 0.3824, G loss: 2.0084\n",
      "[1124/1762] D loss: 0.2408, G loss: 2.1003\n",
      "[1204/1762] D loss: 1.6771, G loss: 0.6278\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.7279\n",
      "[1364/1762] D loss: 0.3280, G loss: 1.8328\n",
      "[1444/1762] D loss: 0.2393, G loss: 2.0589\n",
      "[1524/1762] D loss: 0.1597, G loss: 2.3710\n",
      "[1604/1762] D loss: 1.3536, G loss: 0.8193\n",
      "[1684/1762] D loss: 1.3925, G loss: 0.6489\n",
      "[1762/1762] D loss: 1.4061, G loss: 0.7083\n",
      "train error: \n",
      " D loss: 1.353458, G loss: 0.599324, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342380, G loss: 0.611324, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4523, G loss: 0.7835\n",
      "[84/1762] D loss: 1.3891, G loss: 0.6897\n",
      "[164/1762] D loss: 0.0734, G loss: 2.9048\n",
      "[244/1762] D loss: 1.4314, G loss: 0.8319\n",
      "[324/1762] D loss: 1.3980, G loss: 0.7334\n",
      "[404/1762] D loss: 1.3967, G loss: 0.5883\n",
      "[484/1762] D loss: 1.4119, G loss: 0.8131\n",
      "[564/1762] D loss: 1.4808, G loss: 0.5972\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6964\n",
      "[724/1762] D loss: 0.2234, G loss: 2.3322\n",
      "[804/1762] D loss: 0.3848, G loss: 2.0697\n",
      "[884/1762] D loss: 0.2653, G loss: 2.2693\n",
      "[964/1762] D loss: 1.4235, G loss: 0.7008\n",
      "[1044/1762] D loss: 0.1524, G loss: 2.4957\n",
      "[1124/1762] D loss: 1.4184, G loss: 0.6791\n",
      "[1204/1762] D loss: 0.3575, G loss: 1.7667\n",
      "[1284/1762] D loss: 0.2436, G loss: 2.2280\n",
      "[1364/1762] D loss: 0.3498, G loss: 2.5606\n",
      "[1444/1762] D loss: 1.4074, G loss: 0.7135\n",
      "[1524/1762] D loss: 1.4030, G loss: 0.7159\n",
      "[1604/1762] D loss: 1.3984, G loss: 0.7148\n",
      "[1684/1762] D loss: 0.0486, G loss: 3.1710\n",
      "[1762/1762] D loss: 0.1726, G loss: 2.5068\n",
      "train error: \n",
      " D loss: 1.514223, G loss: 0.415609, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.501587, G loss: 0.423845, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3968, G loss: 0.8897\n",
      "[84/1762] D loss: 0.2640, G loss: 2.0912\n",
      "[164/1762] D loss: 1.4360, G loss: 0.8618\n",
      "[244/1762] D loss: 1.4962, G loss: 0.6222\n",
      "[324/1762] D loss: 1.4143, G loss: 0.7116\n",
      "[404/1762] D loss: 1.4530, G loss: 0.5804\n",
      "[484/1762] D loss: 0.0788, G loss: 2.9948\n",
      "[564/1762] D loss: 1.3951, G loss: 0.6966\n",
      "[644/1762] D loss: 0.1784, G loss: 2.4871\n",
      "[724/1762] D loss: 1.4283, G loss: 0.6942\n",
      "[804/1762] D loss: 1.4236, G loss: 0.6564\n",
      "[884/1762] D loss: 1.4912, G loss: 0.5119\n",
      "[964/1762] D loss: 1.3953, G loss: 0.6637\n",
      "[1044/1762] D loss: 1.4835, G loss: 0.6376\n",
      "[1124/1762] D loss: 0.1749, G loss: 2.4007\n",
      "[1204/1762] D loss: 1.4042, G loss: 0.8046\n",
      "[1284/1762] D loss: 1.4617, G loss: 0.6541\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.7118\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.7022\n",
      "[1524/1762] D loss: 1.3158, G loss: 0.7103\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.6612\n",
      "[1684/1762] D loss: 1.4672, G loss: 0.6645\n",
      "[1762/1762] D loss: 1.6676, G loss: 0.4054\n",
      "train error: \n",
      " D loss: 1.529927, G loss: 0.922950, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.504018, G loss: 0.948128, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4435, G loss: 0.7711\n",
      "[84/1762] D loss: 1.3974, G loss: 0.6852\n",
      "[164/1762] D loss: 1.4573, G loss: 0.5955\n",
      "[244/1762] D loss: 1.4251, G loss: 0.6599\n",
      "[324/1762] D loss: 1.4293, G loss: 0.6980\n",
      "[404/1762] D loss: 0.2395, G loss: 2.0736\n",
      "[484/1762] D loss: 1.4948, G loss: 0.9392\n",
      "[564/1762] D loss: 1.4078, G loss: 0.6539\n",
      "[644/1762] D loss: 0.2770, G loss: 1.8740\n",
      "[724/1762] D loss: 1.4060, G loss: 0.6917\n",
      "[804/1762] D loss: 1.4004, G loss: 0.6596\n",
      "[884/1762] D loss: 0.1344, G loss: 2.4380\n",
      "[964/1762] D loss: 0.1932, G loss: 2.3334\n",
      "[1044/1762] D loss: 1.3712, G loss: 0.6937\n",
      "[1124/1762] D loss: 1.4108, G loss: 0.5947\n",
      "[1204/1762] D loss: 0.0675, G loss: 2.8242\n",
      "[1284/1762] D loss: 1.4212, G loss: 0.6563\n",
      "[1364/1762] D loss: 1.3931, G loss: 0.6777\n",
      "[1444/1762] D loss: 1.3921, G loss: 0.6858\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6867\n",
      "[1604/1762] D loss: 0.1473, G loss: 2.4127\n",
      "[1684/1762] D loss: 0.1701, G loss: 2.4247\n",
      "[1762/1762] D loss: 0.2405, G loss: 2.6728\n",
      "train error: \n",
      " D loss: 1.389557, G loss: 0.510566, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378718, G loss: 0.516477, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4172, G loss: 0.5988\n",
      "[84/1762] D loss: 0.1941, G loss: 2.4977\n",
      "[164/1762] D loss: 1.3922, G loss: 0.7134\n",
      "[244/1762] D loss: 1.3714, G loss: 0.7049\n",
      "[324/1762] D loss: 0.2231, G loss: 2.2197\n",
      "[404/1762] D loss: 0.3411, G loss: 2.0502\n",
      "[484/1762] D loss: 1.4344, G loss: 0.7247\n",
      "[564/1762] D loss: 0.3623, G loss: 1.7718\n",
      "[644/1762] D loss: 1.4007, G loss: 0.7127\n",
      "[724/1762] D loss: 0.2279, G loss: 2.0029\n",
      "[804/1762] D loss: 1.3977, G loss: 0.7049\n",
      "[884/1762] D loss: 1.4120, G loss: 0.7718\n",
      "[964/1762] D loss: 0.1701, G loss: 2.4863\n",
      "[1044/1762] D loss: 1.3790, G loss: 0.6585\n",
      "[1124/1762] D loss: 1.2898, G loss: 1.1277\n",
      "[1204/1762] D loss: 1.4223, G loss: 0.7086\n",
      "[1284/1762] D loss: 1.4220, G loss: 0.7573\n",
      "[1364/1762] D loss: 1.4957, G loss: 0.6346\n",
      "[1444/1762] D loss: 1.4226, G loss: 0.6985\n",
      "[1524/1762] D loss: 0.4596, G loss: 1.9688\n",
      "[1604/1762] D loss: 0.1694, G loss: 2.7505\n",
      "[1684/1762] D loss: 1.5137, G loss: 0.8914\n",
      "[1762/1762] D loss: 0.0430, G loss: 3.2907\n",
      "train error: \n",
      " D loss: 1.530105, G loss: 0.380258, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.507363, G loss: 0.388603, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4102, G loss: 0.6894\n",
      "[84/1762] D loss: 1.3945, G loss: 0.6959\n",
      "[164/1762] D loss: 1.5959, G loss: 0.4488\n",
      "[244/1762] D loss: 1.4496, G loss: 0.8218\n",
      "[324/1762] D loss: 1.4807, G loss: 0.4866\n",
      "[404/1762] D loss: 1.4216, G loss: 0.7503\n",
      "[484/1762] D loss: 0.1687, G loss: 2.4026\n",
      "[564/1762] D loss: 1.2992, G loss: 0.9927\n",
      "[644/1762] D loss: 0.1681, G loss: 2.4518\n",
      "[724/1762] D loss: 0.2686, G loss: 2.4136\n",
      "[804/1762] D loss: 1.0059, G loss: 1.5764\n",
      "[884/1762] D loss: 0.4374, G loss: 1.7438\n",
      "[964/1762] D loss: 1.3135, G loss: 0.7473\n",
      "[1044/1762] D loss: 0.3665, G loss: 1.9017\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.6872\n",
      "[1204/1762] D loss: 1.4595, G loss: 0.5912\n",
      "[1284/1762] D loss: 0.1617, G loss: 2.3571\n",
      "[1364/1762] D loss: 0.2017, G loss: 2.4103\n",
      "[1444/1762] D loss: 0.1922, G loss: 2.4250\n",
      "[1524/1762] D loss: 1.3612, G loss: 0.7734\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.6601\n",
      "[1684/1762] D loss: 1.5433, G loss: 0.5172\n",
      "[1762/1762] D loss: 1.4203, G loss: 0.5880\n",
      "train error: \n",
      " D loss: 1.355902, G loss: 0.838674, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335041, G loss: 0.851800, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4274, G loss: 0.6343\n",
      "[84/1762] D loss: 1.4475, G loss: 0.6050\n",
      "[164/1762] D loss: 1.0934, G loss: 1.4423\n",
      "[244/1762] D loss: 1.7505, G loss: 0.5628\n",
      "[324/1762] D loss: 0.4299, G loss: 2.4339\n",
      "[404/1762] D loss: 1.3859, G loss: 0.6844\n",
      "[484/1762] D loss: 1.4408, G loss: 0.7640\n",
      "[564/1762] D loss: 1.4064, G loss: 0.6939\n",
      "[644/1762] D loss: 1.3972, G loss: 0.7658\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6907\n",
      "[804/1762] D loss: 0.1511, G loss: 2.2921\n",
      "[884/1762] D loss: 1.3881, G loss: 0.7553\n",
      "[964/1762] D loss: 1.5157, G loss: 0.6129\n",
      "[1044/1762] D loss: 1.4306, G loss: 0.7771\n",
      "[1124/1762] D loss: 1.3843, G loss: 0.7240\n",
      "[1204/1762] D loss: 1.4115, G loss: 0.6103\n",
      "[1284/1762] D loss: 1.4279, G loss: 0.6802\n",
      "[1364/1762] D loss: 0.2376, G loss: 2.3476\n",
      "[1444/1762] D loss: 1.4207, G loss: 0.7691\n",
      "[1524/1762] D loss: 1.5305, G loss: 0.6327\n",
      "[1604/1762] D loss: 1.4242, G loss: 0.7868\n",
      "[1684/1762] D loss: 1.4812, G loss: 0.5248\n",
      "[1762/1762] D loss: 1.4143, G loss: 0.7857\n",
      "train error: \n",
      " D loss: 1.327292, G loss: 0.716190, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301176, G loss: 0.745166, D accuracy: 55.1%, cell accuracy: 99.5%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3945, G loss: 0.7386\n",
      "[84/1762] D loss: 1.2916, G loss: 1.2105\n",
      "[164/1762] D loss: 1.0440, G loss: 0.7409\n",
      "[244/1762] D loss: 0.1022, G loss: 2.7595\n",
      "[324/1762] D loss: 1.4914, G loss: 1.1358\n",
      "[404/1762] D loss: 1.4129, G loss: 0.5914\n",
      "[484/1762] D loss: 1.4763, G loss: 0.7869\n",
      "[564/1762] D loss: 1.3241, G loss: 0.7708\n",
      "[644/1762] D loss: 0.0597, G loss: 3.0509\n",
      "[724/1762] D loss: 1.4121, G loss: 0.7253\n",
      "[804/1762] D loss: 1.6091, G loss: 0.4651\n",
      "[884/1762] D loss: 1.4037, G loss: 0.6981\n",
      "[964/1762] D loss: 1.4785, G loss: 0.5960\n",
      "[1044/1762] D loss: 1.0780, G loss: 1.0877\n",
      "[1124/1762] D loss: 1.4197, G loss: 0.7236\n",
      "[1204/1762] D loss: 1.4291, G loss: 0.7694\n",
      "[1284/1762] D loss: 1.4317, G loss: 0.6552\n",
      "[1364/1762] D loss: 0.0318, G loss: 3.5898\n",
      "[1444/1762] D loss: 1.4218, G loss: 0.7548\n",
      "[1524/1762] D loss: 0.2125, G loss: 2.3190\n",
      "[1604/1762] D loss: 0.2092, G loss: 2.4355\n",
      "[1684/1762] D loss: 0.1354, G loss: 2.7894\n",
      "[1762/1762] D loss: 0.0212, G loss: 3.9492\n",
      "train error: \n",
      " D loss: 1.358907, G loss: 0.615353, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335619, G loss: 0.633221, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4014, G loss: 0.6510\n",
      "[84/1762] D loss: 1.4269, G loss: 0.7089\n",
      "[164/1762] D loss: 0.9576, G loss: 1.1600\n",
      "[244/1762] D loss: 1.4002, G loss: 0.7132\n",
      "[324/1762] D loss: 1.4831, G loss: 1.0687\n",
      "[404/1762] D loss: 1.4024, G loss: 0.6276\n",
      "[484/1762] D loss: 1.3958, G loss: 0.7610\n",
      "[564/1762] D loss: 1.3639, G loss: 0.9351\n",
      "[644/1762] D loss: 0.2347, G loss: 2.2283\n",
      "[724/1762] D loss: 1.4241, G loss: 0.6382\n",
      "[804/1762] D loss: 0.1155, G loss: 2.5724\n",
      "[884/1762] D loss: 0.0949, G loss: 2.7777\n",
      "[964/1762] D loss: 1.4221, G loss: 0.6111\n",
      "[1044/1762] D loss: 1.4210, G loss: 0.7491\n",
      "[1124/1762] D loss: 1.3620, G loss: 0.4798\n",
      "[1204/1762] D loss: 0.2501, G loss: 2.2262\n",
      "[1284/1762] D loss: 1.3967, G loss: 0.5939\n",
      "[1364/1762] D loss: 0.0517, G loss: 3.6593\n",
      "[1444/1762] D loss: 0.1454, G loss: 2.5105\n",
      "[1524/1762] D loss: 0.0232, G loss: 3.9384\n",
      "[1604/1762] D loss: 1.4761, G loss: 0.8951\n",
      "[1684/1762] D loss: 1.4088, G loss: 0.6361\n",
      "[1762/1762] D loss: 1.4098, G loss: 0.6131\n",
      "train error: \n",
      " D loss: 1.341189, G loss: 0.890754, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319566, G loss: 0.901946, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4214, G loss: 0.6201\n",
      "[84/1762] D loss: 1.3924, G loss: 0.6861\n",
      "[164/1762] D loss: 1.3947, G loss: 0.6920\n",
      "[244/1762] D loss: 1.0601, G loss: 1.8567\n",
      "[324/1762] D loss: 1.5450, G loss: 0.8024\n",
      "[404/1762] D loss: 1.4210, G loss: 0.5459\n",
      "[484/1762] D loss: 1.3897, G loss: 0.7088\n",
      "[564/1762] D loss: 1.3993, G loss: 0.6111\n",
      "[644/1762] D loss: 1.3922, G loss: 0.6701\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6598\n",
      "[804/1762] D loss: 0.1047, G loss: 2.7780\n",
      "[884/1762] D loss: 0.1694, G loss: 2.3848\n",
      "[964/1762] D loss: 0.2090, G loss: 2.2409\n",
      "[1044/1762] D loss: 1.3951, G loss: 0.7251\n",
      "[1124/1762] D loss: 1.4249, G loss: 0.8472\n",
      "[1204/1762] D loss: 1.4010, G loss: 0.6925\n",
      "[1284/1762] D loss: 0.1421, G loss: 2.5558\n",
      "[1364/1762] D loss: 1.3896, G loss: 0.7033\n",
      "[1444/1762] D loss: 1.3849, G loss: 0.6582\n",
      "[1524/1762] D loss: 1.4055, G loss: 0.6583\n",
      "[1604/1762] D loss: 1.2819, G loss: 0.7711\n",
      "[1684/1762] D loss: 0.1531, G loss: 2.7632\n",
      "[1762/1762] D loss: 0.0339, G loss: 3.5346\n",
      "train error: \n",
      " D loss: 1.285001, G loss: 0.755906, D accuracy: 58.0%, cell accuracy: 99.3%, board accuracy: 70.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259574, G loss: 0.787680, D accuracy: 59.2%, cell accuracy: 99.2%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2329, G loss: 1.1621\n",
      "[84/1762] D loss: 1.2301, G loss: 1.2544\n",
      "[164/1762] D loss: 1.4011, G loss: 0.7032\n",
      "[244/1762] D loss: 0.2287, G loss: 2.6046\n",
      "[324/1762] D loss: 0.9262, G loss: 1.6512\n",
      "[404/1762] D loss: 1.4186, G loss: 0.6133\n",
      "[484/1762] D loss: 1.4908, G loss: 0.4609\n",
      "[564/1762] D loss: 1.3982, G loss: 0.9284\n",
      "[644/1762] D loss: 1.4000, G loss: 0.6984\n",
      "[724/1762] D loss: 0.1008, G loss: 2.6852\n",
      "[804/1762] D loss: 1.4127, G loss: 0.9635\n",
      "[884/1762] D loss: 1.4268, G loss: 0.5832\n",
      "[964/1762] D loss: 1.3991, G loss: 0.6653\n",
      "[1044/1762] D loss: 1.4291, G loss: 0.7076\n",
      "[1124/1762] D loss: 0.3170, G loss: 1.8450\n",
      "[1204/1762] D loss: 1.4705, G loss: 0.5951\n",
      "[1284/1762] D loss: 1.6748, G loss: 0.4548\n",
      "[1364/1762] D loss: 0.1404, G loss: 2.4921\n",
      "[1444/1762] D loss: 0.2388, G loss: 1.9226\n",
      "[1524/1762] D loss: 0.0390, G loss: 3.5358\n",
      "[1604/1762] D loss: 1.2616, G loss: 1.2428\n",
      "[1684/1762] D loss: 0.2678, G loss: 2.1793\n",
      "[1762/1762] D loss: 1.4293, G loss: 0.7289\n",
      "train error: \n",
      " D loss: 1.322568, G loss: 0.817295, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304621, G loss: 0.853461, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4370, G loss: 0.5356\n",
      "[84/1762] D loss: 0.8041, G loss: 1.6230\n",
      "[164/1762] D loss: 1.4864, G loss: 1.0833\n",
      "[244/1762] D loss: 1.6561, G loss: 0.3354\n",
      "[324/1762] D loss: 0.1147, G loss: 2.7097\n",
      "[404/1762] D loss: 0.6593, G loss: 2.0626\n",
      "[484/1762] D loss: 0.9669, G loss: 1.2474\n",
      "[564/1762] D loss: 1.4362, G loss: 0.6752\n",
      "[644/1762] D loss: 1.4452, G loss: 0.7858\n",
      "[724/1762] D loss: 1.4222, G loss: 0.6688\n",
      "[804/1762] D loss: 0.1406, G loss: 2.5667\n",
      "[884/1762] D loss: 1.4549, G loss: 0.5399\n",
      "[964/1762] D loss: 1.4176, G loss: 0.7308\n",
      "[1044/1762] D loss: 1.4052, G loss: 0.6534\n",
      "[1124/1762] D loss: 1.4002, G loss: 0.6818\n",
      "[1204/1762] D loss: 0.3296, G loss: 2.0438\n",
      "[1284/1762] D loss: 0.0490, G loss: 3.2104\n",
      "[1364/1762] D loss: 0.1451, G loss: 2.4559\n",
      "[1444/1762] D loss: 1.4167, G loss: 0.7757\n",
      "[1524/1762] D loss: 1.1853, G loss: 1.8832\n",
      "[1604/1762] D loss: 0.9721, G loss: 1.2384\n",
      "[1684/1762] D loss: 1.4923, G loss: 0.5802\n",
      "[1762/1762] D loss: 1.4418, G loss: 0.6478\n",
      "train error: \n",
      " D loss: 1.352881, G loss: 0.605515, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343214, G loss: 0.607003, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4049, G loss: 0.6844\n",
      "[84/1762] D loss: 1.3957, G loss: 0.7600\n",
      "[164/1762] D loss: 0.0975, G loss: 2.8297\n",
      "[244/1762] D loss: 1.3916, G loss: 0.6708\n",
      "[324/1762] D loss: 1.4087, G loss: 0.9277\n",
      "[404/1762] D loss: 1.4823, G loss: 0.5919\n",
      "[484/1762] D loss: 0.0218, G loss: 4.0952\n",
      "[564/1762] D loss: 1.4115, G loss: 0.6876\n",
      "[644/1762] D loss: 0.0208, G loss: 3.9518\n",
      "[724/1762] D loss: 1.4093, G loss: 0.7350\n",
      "[804/1762] D loss: 1.4358, G loss: 0.6819\n",
      "[884/1762] D loss: 0.2076, G loss: 2.2186\n",
      "[964/1762] D loss: 0.0586, G loss: 3.1227\n",
      "[1044/1762] D loss: 1.4316, G loss: 0.5800\n",
      "[1124/1762] D loss: 0.0624, G loss: 3.0278\n",
      "[1204/1762] D loss: 0.1718, G loss: 2.4226\n",
      "[1284/1762] D loss: 1.3823, G loss: 0.6882\n",
      "[1364/1762] D loss: 1.4183, G loss: 0.6412\n",
      "[1444/1762] D loss: 0.1056, G loss: 2.7594\n",
      "[1524/1762] D loss: 1.4169, G loss: 0.6511\n",
      "[1604/1762] D loss: 1.4254, G loss: 0.7898\n",
      "[1684/1762] D loss: 1.4070, G loss: 0.7548\n",
      "[1762/1762] D loss: 1.4238, G loss: 0.6196\n",
      "train error: \n",
      " D loss: 1.333848, G loss: 0.788119, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319407, G loss: 0.801056, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4415, G loss: 0.7704\n",
      "[84/1762] D loss: 1.3965, G loss: 0.6081\n",
      "[164/1762] D loss: 1.4221, G loss: 0.5552\n",
      "[244/1762] D loss: 0.1101, G loss: 2.9066\n",
      "[324/1762] D loss: 0.2246, G loss: 2.4631\n",
      "[404/1762] D loss: 1.4426, G loss: 0.4967\n",
      "[484/1762] D loss: 1.7984, G loss: 0.5818\n",
      "[564/1762] D loss: 0.1197, G loss: 2.6773\n",
      "[644/1762] D loss: 1.4049, G loss: 0.6424\n",
      "[724/1762] D loss: 0.0136, G loss: 4.4787\n",
      "[804/1762] D loss: 1.1673, G loss: 1.0020\n",
      "[884/1762] D loss: 0.1783, G loss: 2.5659\n",
      "[964/1762] D loss: 1.4614, G loss: 1.0992\n",
      "[1044/1762] D loss: 1.4171, G loss: 0.6756\n",
      "[1124/1762] D loss: 1.4422, G loss: 0.6101\n",
      "[1204/1762] D loss: 1.4039, G loss: 0.6802\n",
      "[1284/1762] D loss: 1.4153, G loss: 0.7067\n",
      "[1364/1762] D loss: 0.0815, G loss: 3.0024\n",
      "[1444/1762] D loss: 1.4004, G loss: 0.6575\n",
      "[1524/1762] D loss: 1.3697, G loss: 0.7472\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.6291\n",
      "[1684/1762] D loss: 0.0980, G loss: 3.0071\n",
      "[1762/1762] D loss: 1.4906, G loss: 1.1319\n",
      "train error: \n",
      " D loss: 1.413161, G loss: 0.942438, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390819, G loss: 0.967453, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4336, G loss: 0.6552\n",
      "[84/1762] D loss: 1.3990, G loss: 0.6134\n",
      "[164/1762] D loss: 1.4330, G loss: 0.8540\n",
      "[244/1762] D loss: 1.4744, G loss: 0.8979\n",
      "[324/1762] D loss: 1.4338, G loss: 0.6462\n",
      "[404/1762] D loss: 1.3966, G loss: 0.6929\n",
      "[484/1762] D loss: 0.1071, G loss: 2.6065\n",
      "[564/1762] D loss: 0.0932, G loss: 2.7907\n",
      "[644/1762] D loss: 1.4094, G loss: 0.6792\n",
      "[724/1762] D loss: 1.4395, G loss: 0.6467\n",
      "[804/1762] D loss: 0.0433, G loss: 3.5832\n",
      "[884/1762] D loss: 1.3963, G loss: 0.8027\n",
      "[964/1762] D loss: 1.5813, G loss: 0.3158\n",
      "[1044/1762] D loss: 1.4438, G loss: 0.6754\n",
      "[1124/1762] D loss: 1.4226, G loss: 0.7811\n",
      "[1204/1762] D loss: 1.3985, G loss: 0.6712\n",
      "[1284/1762] D loss: 1.3969, G loss: 0.6472\n",
      "[1364/1762] D loss: 1.4103, G loss: 0.5381\n",
      "[1444/1762] D loss: 1.4701, G loss: 0.8415\n",
      "[1524/1762] D loss: 1.3779, G loss: 0.6837\n",
      "[1604/1762] D loss: 1.4109, G loss: 0.7181\n",
      "[1684/1762] D loss: 1.4089, G loss: 0.8454\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6411\n",
      "train error: \n",
      " D loss: 1.343539, G loss: 0.910651, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320766, G loss: 0.938647, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0589, G loss: 3.2923\n",
      "[84/1762] D loss: 1.3963, G loss: 0.9437\n",
      "[164/1762] D loss: 1.4142, G loss: 0.7279\n",
      "[244/1762] D loss: 1.4169, G loss: 0.6872\n",
      "[324/1762] D loss: 1.4100, G loss: 0.6402\n",
      "[404/1762] D loss: 1.4356, G loss: 0.7387\n",
      "[484/1762] D loss: 0.8649, G loss: 1.5545\n",
      "[564/1762] D loss: 1.4086, G loss: 0.6329\n",
      "[644/1762] D loss: 1.4126, G loss: 0.6377\n",
      "[724/1762] D loss: 0.0422, G loss: 3.5830\n",
      "[804/1762] D loss: 1.4034, G loss: 0.6586\n",
      "[884/1762] D loss: 1.3931, G loss: 0.6486\n",
      "[964/1762] D loss: 1.4033, G loss: 0.6631\n",
      "[1044/1762] D loss: 1.5056, G loss: 0.6605\n",
      "[1124/1762] D loss: 0.0961, G loss: 2.8052\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.6610\n",
      "[1284/1762] D loss: 1.4022, G loss: 0.7200\n",
      "[1364/1762] D loss: 0.1411, G loss: 2.3367\n",
      "[1444/1762] D loss: 0.0246, G loss: 4.0168\n",
      "[1524/1762] D loss: 1.4404, G loss: 0.7343\n",
      "[1604/1762] D loss: 1.4112, G loss: 0.6944\n",
      "[1684/1762] D loss: 0.1469, G loss: 2.5272\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.6432\n",
      "train error: \n",
      " D loss: 1.327038, G loss: 0.723664, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303789, G loss: 0.734894, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7001\n",
      "[84/1762] D loss: 0.1661, G loss: 2.4404\n",
      "[164/1762] D loss: 0.1910, G loss: 2.3192\n",
      "[244/1762] D loss: 1.5725, G loss: 0.3695\n",
      "[324/1762] D loss: 1.4276, G loss: 1.0695\n",
      "[404/1762] D loss: 1.3887, G loss: 0.6926\n",
      "[484/1762] D loss: 1.4057, G loss: 0.7001\n",
      "[564/1762] D loss: 0.0173, G loss: 4.1249\n",
      "[644/1762] D loss: 0.1245, G loss: 2.7521\n",
      "[724/1762] D loss: 0.9247, G loss: 1.2538\n",
      "[804/1762] D loss: 1.3932, G loss: 0.7006\n",
      "[884/1762] D loss: 1.4096, G loss: 0.5768\n",
      "[964/1762] D loss: 1.3843, G loss: 0.6865\n",
      "[1044/1762] D loss: 0.0168, G loss: 4.5195\n",
      "[1124/1762] D loss: 1.8276, G loss: 2.0238\n",
      "[1204/1762] D loss: 1.4898, G loss: 1.0828\n",
      "[1284/1762] D loss: 0.1246, G loss: 3.0172\n",
      "[1364/1762] D loss: 0.1102, G loss: 2.8863\n",
      "[1444/1762] D loss: 0.1586, G loss: 2.5551\n",
      "[1524/1762] D loss: 1.4053, G loss: 0.6478\n",
      "[1604/1762] D loss: 1.3937, G loss: 0.7348\n",
      "[1684/1762] D loss: 0.1225, G loss: 2.6454\n",
      "[1762/1762] D loss: 1.4169, G loss: 0.6965\n",
      "train error: \n",
      " D loss: 1.336957, G loss: 0.798481, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315205, G loss: 0.807023, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4811, G loss: 0.5886\n",
      "[84/1762] D loss: 0.1124, G loss: 2.8560\n",
      "[164/1762] D loss: 1.4041, G loss: 0.7084\n",
      "[244/1762] D loss: 1.2950, G loss: 1.1862\n",
      "[324/1762] D loss: 1.4865, G loss: 0.8097\n",
      "[404/1762] D loss: 0.1164, G loss: 2.7661\n",
      "[484/1762] D loss: 0.0383, G loss: 3.6000\n",
      "[564/1762] D loss: 0.2851, G loss: 2.6067\n",
      "[644/1762] D loss: 0.1614, G loss: 2.4869\n",
      "[724/1762] D loss: 0.0329, G loss: 3.6327\n",
      "[804/1762] D loss: 1.4536, G loss: 0.8983\n",
      "[884/1762] D loss: 1.4862, G loss: 0.7532\n",
      "[964/1762] D loss: 1.4686, G loss: 0.5517\n",
      "[1044/1762] D loss: 1.4659, G loss: 0.8463\n",
      "[1124/1762] D loss: 1.4095, G loss: 0.6791\n",
      "[1204/1762] D loss: 1.4226, G loss: 0.6224\n",
      "[1284/1762] D loss: 0.1966, G loss: 2.5930\n",
      "[1364/1762] D loss: 0.1117, G loss: 2.7874\n",
      "[1444/1762] D loss: 0.9815, G loss: 2.4031\n",
      "[1524/1762] D loss: 0.0832, G loss: 2.9496\n",
      "[1604/1762] D loss: 0.2195, G loss: 2.2678\n",
      "[1684/1762] D loss: 0.0511, G loss: 3.3981\n",
      "[1762/1762] D loss: 1.4459, G loss: 0.8938\n",
      "train error: \n",
      " D loss: 1.362766, G loss: 1.048334, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344609, G loss: 1.085729, D accuracy: 53.8%, cell accuracy: 99.5%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1290, G loss: 2.8334\n",
      "[84/1762] D loss: 1.5277, G loss: 0.4371\n",
      "[164/1762] D loss: 1.1655, G loss: 0.8753\n",
      "[244/1762] D loss: 1.3958, G loss: 0.7510\n",
      "[324/1762] D loss: 0.3937, G loss: 1.9037\n",
      "[404/1762] D loss: 1.4152, G loss: 0.8525\n",
      "[484/1762] D loss: 1.4200, G loss: 0.6625\n",
      "[564/1762] D loss: 0.0503, G loss: 3.4557\n",
      "[644/1762] D loss: 1.4070, G loss: 0.6583\n",
      "[724/1762] D loss: 1.4091, G loss: 0.6445\n",
      "[804/1762] D loss: 1.4054, G loss: 0.6854\n",
      "[884/1762] D loss: 1.4911, G loss: 0.8121\n",
      "[964/1762] D loss: 0.0787, G loss: 2.8913\n",
      "[1044/1762] D loss: 0.0810, G loss: 3.0503\n",
      "[1124/1762] D loss: 0.1311, G loss: 2.6094\n",
      "[1204/1762] D loss: 0.0777, G loss: 3.0897\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.6968\n",
      "[1364/1762] D loss: 1.4027, G loss: 0.6491\n",
      "[1444/1762] D loss: 0.0721, G loss: 3.0095\n",
      "[1524/1762] D loss: 1.4246, G loss: 0.6347\n",
      "[1604/1762] D loss: 1.3735, G loss: 0.9651\n",
      "[1684/1762] D loss: 1.0142, G loss: 1.2309\n",
      "[1762/1762] D loss: 0.7531, G loss: 1.8987\n",
      "train error: \n",
      " D loss: 1.298500, G loss: 0.812866, D accuracy: 56.9%, cell accuracy: 99.2%, board accuracy: 56.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269984, G loss: 0.832888, D accuracy: 58.0%, cell accuracy: 99.1%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1937, G loss: 2.7240\n",
      "[84/1762] D loss: 1.3997, G loss: 0.5935\n",
      "[164/1762] D loss: 1.4788, G loss: 0.7775\n",
      "[244/1762] D loss: 0.0911, G loss: 2.7537\n",
      "[324/1762] D loss: 1.4246, G loss: 0.7203\n",
      "[404/1762] D loss: 1.4304, G loss: 0.9329\n",
      "[484/1762] D loss: 1.3973, G loss: 0.6812\n",
      "[564/1762] D loss: 1.4218, G loss: 0.6236\n",
      "[644/1762] D loss: 0.0740, G loss: 3.0695\n",
      "[724/1762] D loss: 1.4031, G loss: 0.6465\n",
      "[804/1762] D loss: 0.0561, G loss: 3.3168\n",
      "[884/1762] D loss: 1.7056, G loss: 1.1774\n",
      "[964/1762] D loss: 1.2215, G loss: 1.0214\n",
      "[1044/1762] D loss: 0.1439, G loss: 3.1491\n",
      "[1124/1762] D loss: 0.4820, G loss: 2.1338\n",
      "[1204/1762] D loss: 0.2169, G loss: 2.4063\n",
      "[1284/1762] D loss: 0.1180, G loss: 2.8656\n",
      "[1364/1762] D loss: 1.3958, G loss: 0.7692\n",
      "[1444/1762] D loss: 0.1821, G loss: 2.4208\n",
      "[1524/1762] D loss: 1.4088, G loss: 0.7247\n",
      "[1604/1762] D loss: 1.3972, G loss: 0.6447\n",
      "[1684/1762] D loss: 0.1378, G loss: 3.0271\n",
      "[1762/1762] D loss: 0.3646, G loss: 2.5080\n",
      "train error: \n",
      " D loss: 1.376913, G loss: 0.911121, D accuracy: 52.2%, cell accuracy: 99.6%, board accuracy: 82.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369416, G loss: 0.917012, D accuracy: 53.1%, cell accuracy: 99.5%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4607, G loss: 0.6960\n",
      "[84/1762] D loss: 1.4453, G loss: 0.7664\n",
      "[164/1762] D loss: 1.4052, G loss: 0.6980\n",
      "[244/1762] D loss: 1.6209, G loss: 0.5966\n",
      "[324/1762] D loss: 0.9696, G loss: 1.1046\n",
      "[404/1762] D loss: 1.4043, G loss: 0.6876\n",
      "[484/1762] D loss: 1.5493, G loss: 0.4825\n",
      "[564/1762] D loss: 1.4331, G loss: 0.6691\n",
      "[644/1762] D loss: 1.3928, G loss: 0.6287\n",
      "[724/1762] D loss: 1.4734, G loss: 0.7560\n",
      "[804/1762] D loss: 1.3986, G loss: 0.6767\n",
      "[884/1762] D loss: 1.3818, G loss: 0.8614\n",
      "[964/1762] D loss: 1.4153, G loss: 0.7755\n",
      "[1044/1762] D loss: 1.3968, G loss: 0.6763\n",
      "[1124/1762] D loss: 0.0383, G loss: 3.5848\n",
      "[1204/1762] D loss: 0.0574, G loss: 3.2080\n",
      "[1284/1762] D loss: 1.3922, G loss: 0.7592\n",
      "[1364/1762] D loss: 0.1717, G loss: 2.4771\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7028\n",
      "[1524/1762] D loss: 0.1672, G loss: 2.5164\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.5600\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6898\n",
      "[1762/1762] D loss: 1.3663, G loss: 0.7075\n",
      "train error: \n",
      " D loss: 1.372619, G loss: 1.038774, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373564, G loss: 1.073708, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3998, G loss: 0.6965\n",
      "[84/1762] D loss: 0.1537, G loss: 2.4808\n",
      "[164/1762] D loss: 0.0597, G loss: 3.0809\n",
      "[244/1762] D loss: 1.3937, G loss: 0.7087\n",
      "[324/1762] D loss: 0.9813, G loss: 1.3901\n",
      "[404/1762] D loss: 1.3928, G loss: 0.6758\n",
      "[484/1762] D loss: 1.4065, G loss: 0.7317\n",
      "[564/1762] D loss: 0.0979, G loss: 2.8198\n",
      "[644/1762] D loss: 1.4390, G loss: 0.7755\n",
      "[724/1762] D loss: 1.4491, G loss: 0.6037\n",
      "[804/1762] D loss: 1.4039, G loss: 0.7256\n",
      "[884/1762] D loss: 1.4022, G loss: 0.7683\n",
      "[964/1762] D loss: 0.0742, G loss: 3.2485\n",
      "[1044/1762] D loss: 1.4067, G loss: 0.6486\n",
      "[1124/1762] D loss: 1.4373, G loss: 0.7973\n",
      "[1204/1762] D loss: 1.4059, G loss: 0.7238\n",
      "[1284/1762] D loss: 1.4178, G loss: 0.7024\n",
      "[1364/1762] D loss: 0.0647, G loss: 3.1241\n",
      "[1444/1762] D loss: 0.0865, G loss: 2.8923\n",
      "[1524/1762] D loss: 1.2702, G loss: 0.7257\n",
      "[1604/1762] D loss: 1.3943, G loss: 0.6900\n",
      "[1684/1762] D loss: 1.3957, G loss: 0.6186\n",
      "[1762/1762] D loss: 0.0100, G loss: 4.8360\n",
      "train error: \n",
      " D loss: 1.510437, G loss: 1.289544, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.500519, G loss: 1.307985, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4141, G loss: 0.6188\n",
      "[84/1762] D loss: 1.4064, G loss: 0.7614\n",
      "[164/1762] D loss: 1.4048, G loss: 0.8023\n",
      "[244/1762] D loss: 1.3808, G loss: 0.8336\n",
      "[324/1762] D loss: 1.3958, G loss: 0.6677\n",
      "[404/1762] D loss: 1.3881, G loss: 0.6562\n",
      "[484/1762] D loss: 1.4049, G loss: 0.6985\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6428\n",
      "[644/1762] D loss: 1.4194, G loss: 0.6048\n",
      "[724/1762] D loss: 1.4112, G loss: 0.7344\n",
      "[804/1762] D loss: 1.4163, G loss: 0.6111\n",
      "[884/1762] D loss: 0.0752, G loss: 2.9600\n",
      "[964/1762] D loss: 0.1539, G loss: 2.5516\n",
      "[1044/1762] D loss: 1.4145, G loss: 0.6048\n",
      "[1124/1762] D loss: 1.4118, G loss: 0.5813\n",
      "[1204/1762] D loss: 0.0467, G loss: 3.3897\n",
      "[1284/1762] D loss: 1.3973, G loss: 0.7176\n",
      "[1364/1762] D loss: 1.4278, G loss: 1.2247\n",
      "[1444/1762] D loss: 1.4146, G loss: 0.7570\n",
      "[1524/1762] D loss: 1.7251, G loss: 0.9602\n",
      "[1604/1762] D loss: 1.4312, G loss: 0.2482\n",
      "[1684/1762] D loss: 1.4081, G loss: 0.7140\n",
      "[1762/1762] D loss: 1.3945, G loss: 0.7864\n",
      "train error: \n",
      " D loss: 1.401317, G loss: 1.190574, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386770, G loss: 1.221352, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0354, G loss: 3.8568\n",
      "[84/1762] D loss: 0.0434, G loss: 3.5146\n",
      "[164/1762] D loss: 1.4802, G loss: 0.8091\n",
      "[244/1762] D loss: 1.3938, G loss: 0.6704\n",
      "[324/1762] D loss: 1.4775, G loss: 0.7818\n",
      "[404/1762] D loss: 1.4130, G loss: 0.6540\n",
      "[484/1762] D loss: 1.3983, G loss: 0.5751\n",
      "[564/1762] D loss: 1.1756, G loss: 1.0317\n",
      "[644/1762] D loss: 0.0126, G loss: 4.4676\n",
      "[724/1762] D loss: 0.0888, G loss: 2.8777\n",
      "[804/1762] D loss: 1.3985, G loss: 0.6020\n",
      "[884/1762] D loss: 0.0435, G loss: 3.4720\n",
      "[964/1762] D loss: 1.4245, G loss: 0.6122\n",
      "[1044/1762] D loss: 0.9463, G loss: 0.7093\n",
      "[1124/1762] D loss: 0.1315, G loss: 3.0098\n",
      "[1204/1762] D loss: 0.2885, G loss: 2.3327\n",
      "[1284/1762] D loss: 0.1486, G loss: 2.7793\n",
      "[1364/1762] D loss: 0.0998, G loss: 3.0347\n",
      "[1444/1762] D loss: 0.1022, G loss: 3.5803\n",
      "[1524/1762] D loss: 0.2175, G loss: 3.0216\n",
      "[1604/1762] D loss: 0.0439, G loss: 4.0648\n",
      "[1684/1762] D loss: 0.3392, G loss: 2.7062\n",
      "[1762/1762] D loss: 0.5906, G loss: 3.6567\n",
      "train error: \n",
      " D loss: 3.444285, G loss: 5.312347, D accuracy: 50.0%, cell accuracy: 96.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.488571, G loss: 5.349240, D accuracy: 49.9%, cell accuracy: 96.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1532, G loss: 4.3787\n",
      "[84/1762] D loss: 0.0256, G loss: 4.6520\n",
      "[164/1762] D loss: 0.0170, G loss: 4.8599\n",
      "[244/1762] D loss: 0.0110, G loss: 4.9586\n",
      "[324/1762] D loss: 0.0065, G loss: 5.2923\n",
      "[404/1762] D loss: 0.0124, G loss: 4.8424\n",
      "[484/1762] D loss: 0.0222, G loss: 4.5661\n",
      "[564/1762] D loss: 0.0190, G loss: 4.4930\n",
      "[644/1762] D loss: 0.0224, G loss: 4.8303\n",
      "[724/1762] D loss: 0.0107, G loss: 5.1007\n",
      "[804/1762] D loss: 0.0516, G loss: 3.6812\n",
      "[884/1762] D loss: 0.0200, G loss: 4.9030\n",
      "[964/1762] D loss: 0.0138, G loss: 4.6080\n",
      "[1044/1762] D loss: 0.0187, G loss: 5.5547\n",
      "[1124/1762] D loss: 0.0821, G loss: 4.2317\n",
      "[1204/1762] D loss: 0.0171, G loss: 4.7986\n",
      "[1284/1762] D loss: 0.0332, G loss: 5.6851\n",
      "[1364/1762] D loss: 0.0095, G loss: 5.5237\n",
      "[1444/1762] D loss: 0.0266, G loss: 5.6364\n",
      "[1524/1762] D loss: 0.0121, G loss: 6.0871\n",
      "[1604/1762] D loss: 0.0158, G loss: 5.7005\n",
      "[1684/1762] D loss: 0.1587, G loss: 5.7773\n",
      "[1762/1762] D loss: 0.0284, G loss: 4.7306\n",
      "train error: \n",
      " D loss: 5.925247, G loss: 5.981608, D accuracy: 50.0%, cell accuracy: 94.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.893468, G loss: 6.130441, D accuracy: 50.0%, cell accuracy: 94.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0085, G loss: 5.7556\n",
      "[84/1762] D loss: 0.0133, G loss: 5.2166\n",
      "[164/1762] D loss: 0.0097, G loss: 5.7064\n",
      "[244/1762] D loss: 0.0122, G loss: 5.9434\n",
      "[324/1762] D loss: 0.0098, G loss: 5.4282\n",
      "[404/1762] D loss: 0.0490, G loss: 4.4666\n",
      "[484/1762] D loss: 0.0219, G loss: 5.2870\n",
      "[564/1762] D loss: 0.0217, G loss: 4.7396\n",
      "[644/1762] D loss: 0.0271, G loss: 7.9966\n",
      "[724/1762] D loss: 1.1148, G loss: 2.6746\n",
      "[804/1762] D loss: 0.3594, G loss: 2.1754\n",
      "[884/1762] D loss: 1.5914, G loss: 0.4364\n",
      "[964/1762] D loss: 1.5071, G loss: 0.8652\n",
      "[1044/1762] D loss: 0.4702, G loss: 1.7376\n",
      "[1124/1762] D loss: 1.6501, G loss: 0.3126\n",
      "[1204/1762] D loss: 0.1948, G loss: 2.4272\n",
      "[1284/1762] D loss: 1.4784, G loss: 0.5654\n",
      "[1364/1762] D loss: 1.6147, G loss: 0.9612\n",
      "[1444/1762] D loss: 1.4043, G loss: 0.6696\n",
      "[1524/1762] D loss: 1.5432, G loss: 1.0672\n",
      "[1604/1762] D loss: 0.1533, G loss: 2.4731\n",
      "[1684/1762] D loss: 1.2292, G loss: 0.7119\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7320\n",
      "train error: \n",
      " D loss: 1.324697, G loss: 0.796438, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302217, G loss: 0.833553, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959, G loss: 0.7189\n",
      "[84/1762] D loss: 0.0935, G loss: 2.8441\n",
      "[164/1762] D loss: 1.4085, G loss: 0.8633\n",
      "[244/1762] D loss: 1.3780, G loss: 0.7486\n",
      "[324/1762] D loss: 1.4003, G loss: 0.6631\n",
      "[404/1762] D loss: 1.3886, G loss: 0.6772\n",
      "[484/1762] D loss: 1.3937, G loss: 0.6808\n",
      "[564/1762] D loss: 1.4140, G loss: 0.6576\n",
      "[644/1762] D loss: 0.0292, G loss: 3.9208\n",
      "[724/1762] D loss: 0.1140, G loss: 2.7809\n",
      "[804/1762] D loss: 1.3959, G loss: 0.6918\n",
      "[884/1762] D loss: 1.6068, G loss: 1.1240\n",
      "[964/1762] D loss: 0.1318, G loss: 2.6835\n",
      "[1044/1762] D loss: 1.6009, G loss: 0.3423\n",
      "[1124/1762] D loss: 0.1237, G loss: 2.6562\n",
      "[1204/1762] D loss: 0.1375, G loss: 2.6652\n",
      "[1284/1762] D loss: 1.4187, G loss: 0.7841\n",
      "[1364/1762] D loss: 1.4262, G loss: 0.8253\n",
      "[1444/1762] D loss: 1.4135, G loss: 0.6804\n",
      "[1524/1762] D loss: 0.0796, G loss: 2.9894\n",
      "[1604/1762] D loss: 0.1742, G loss: 2.5013\n",
      "[1684/1762] D loss: 0.1680, G loss: 2.4580\n",
      "[1762/1762] D loss: 1.4014, G loss: 0.7146\n",
      "train error: \n",
      " D loss: 1.318998, G loss: 0.732160, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293567, G loss: 0.756789, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4102, G loss: 0.7597\n",
      "[84/1762] D loss: 1.4082, G loss: 0.6189\n",
      "[164/1762] D loss: 1.4702, G loss: 0.4955\n",
      "[244/1762] D loss: 1.4145, G loss: 0.8449\n",
      "[324/1762] D loss: 0.0738, G loss: 3.2263\n",
      "[404/1762] D loss: 1.4107, G loss: 0.5941\n",
      "[484/1762] D loss: 1.7770, G loss: 0.5227\n",
      "[564/1762] D loss: 1.3959, G loss: 0.6740\n",
      "[644/1762] D loss: 1.3615, G loss: 0.8383\n",
      "[724/1762] D loss: 1.1329, G loss: 1.0767\n",
      "[804/1762] D loss: 0.0983, G loss: 2.9391\n",
      "[884/1762] D loss: 0.0865, G loss: 2.9024\n",
      "[964/1762] D loss: 1.4124, G loss: 0.5823\n",
      "[1044/1762] D loss: 1.3298, G loss: 0.9815\n",
      "[1124/1762] D loss: 1.5401, G loss: 0.5204\n",
      "[1204/1762] D loss: 1.4087, G loss: 0.7309\n",
      "[1284/1762] D loss: 1.4183, G loss: 0.7022\n",
      "[1364/1762] D loss: 1.4350, G loss: 0.6703\n",
      "[1444/1762] D loss: 1.2288, G loss: 0.9513\n",
      "[1524/1762] D loss: 1.4302, G loss: 0.6279\n",
      "[1604/1762] D loss: 1.3080, G loss: 0.7117\n",
      "[1684/1762] D loss: 1.4114, G loss: 0.9158\n",
      "[1762/1762] D loss: 1.4238, G loss: 0.5496\n",
      "train error: \n",
      " D loss: 1.368951, G loss: 0.678620, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342168, G loss: 0.704589, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1170, G loss: 2.8767\n",
      "[84/1762] D loss: 1.4441, G loss: 0.5566\n",
      "[164/1762] D loss: 0.2116, G loss: 2.3018\n",
      "[244/1762] D loss: 1.4121, G loss: 0.7168\n",
      "[324/1762] D loss: 1.4139, G loss: 0.6059\n",
      "[404/1762] D loss: 1.3941, G loss: 0.7221\n",
      "[484/1762] D loss: 1.4101, G loss: 0.6464\n",
      "[564/1762] D loss: 1.4186, G loss: 0.7315\n",
      "[644/1762] D loss: 1.4060, G loss: 0.7185\n",
      "[724/1762] D loss: 1.5303, G loss: 0.4464\n",
      "[804/1762] D loss: 1.4049, G loss: 0.7959\n",
      "[884/1762] D loss: 1.3926, G loss: 0.7344\n",
      "[964/1762] D loss: 1.4519, G loss: 0.9888\n",
      "[1044/1762] D loss: 0.0500, G loss: 3.3246\n",
      "[1124/1762] D loss: 1.4281, G loss: 0.5741\n",
      "[1204/1762] D loss: 1.4079, G loss: 0.7499\n",
      "[1284/1762] D loss: 1.3839, G loss: 0.6908\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.6818\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.7004\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.6292\n",
      "[1604/1762] D loss: 0.0338, G loss: 3.6906\n",
      "[1684/1762] D loss: 0.0456, G loss: 3.5004\n",
      "[1762/1762] D loss: 0.0114, G loss: 4.6699\n",
      "train error: \n",
      " D loss: 1.865606, G loss: 1.748980, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.828919, G loss: 1.742218, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3849, G loss: 0.7341\n",
      "[84/1762] D loss: 1.4094, G loss: 0.6995\n",
      "[164/1762] D loss: 1.4434, G loss: 0.7150\n",
      "[244/1762] D loss: 1.3991, G loss: 0.6895\n",
      "[324/1762] D loss: 0.0604, G loss: 3.3762\n",
      "[404/1762] D loss: 1.4031, G loss: 0.7017\n",
      "[484/1762] D loss: 1.4010, G loss: 0.5879\n",
      "[564/1762] D loss: 0.1503, G loss: 2.5020\n",
      "[644/1762] D loss: 1.4082, G loss: 0.8665\n",
      "[724/1762] D loss: 1.4325, G loss: 0.7514\n",
      "[804/1762] D loss: 1.6180, G loss: 0.4526\n",
      "[884/1762] D loss: 1.1990, G loss: 1.5588\n",
      "[964/1762] D loss: 1.3899, G loss: 0.6496\n",
      "[1044/1762] D loss: 1.3986, G loss: 0.6864\n",
      "[1124/1762] D loss: 1.3999, G loss: 0.8831\n",
      "[1204/1762] D loss: 1.4081, G loss: 0.6873\n",
      "[1284/1762] D loss: 1.2507, G loss: 0.9346\n",
      "[1364/1762] D loss: 1.4600, G loss: 0.5971\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6950\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6986\n",
      "[1604/1762] D loss: 1.3233, G loss: 0.7695\n",
      "[1684/1762] D loss: 1.3842, G loss: 0.7144\n",
      "[1762/1762] D loss: 1.4343, G loss: 1.1254\n",
      "train error: \n",
      " D loss: 1.512590, G loss: 1.399933, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.491098, G loss: 1.462211, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4703, G loss: 0.5671\n",
      "[84/1762] D loss: 0.0893, G loss: 3.0855\n",
      "[164/1762] D loss: 0.0522, G loss: 3.3897\n",
      "[244/1762] D loss: 1.4024, G loss: 0.5693\n",
      "[324/1762] D loss: 0.0740, G loss: 3.3221\n",
      "[404/1762] D loss: 0.1531, G loss: 2.4327\n",
      "[484/1762] D loss: 1.4594, G loss: 0.7791\n",
      "[564/1762] D loss: 1.4120, G loss: 0.7197\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6829\n",
      "[724/1762] D loss: 1.4008, G loss: 0.7357\n",
      "[804/1762] D loss: 1.4353, G loss: 0.6165\n",
      "[884/1762] D loss: 1.4015, G loss: 0.7114\n",
      "[964/1762] D loss: 1.4140, G loss: 0.6435\n",
      "[1044/1762] D loss: 1.4747, G loss: 2.1146\n",
      "[1124/1762] D loss: 1.4097, G loss: 0.6024\n",
      "[1204/1762] D loss: 1.4297, G loss: 0.6646\n",
      "[1284/1762] D loss: 1.5032, G loss: 1.0986\n",
      "[1364/1762] D loss: 1.4818, G loss: 0.5463\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.7105\n",
      "[1524/1762] D loss: 1.4154, G loss: 0.6192\n",
      "[1604/1762] D loss: 0.0978, G loss: 2.9026\n",
      "[1684/1762] D loss: 1.4488, G loss: 0.9019\n",
      "[1762/1762] D loss: 1.3945, G loss: 0.6136\n",
      "train error: \n",
      " D loss: 1.364659, G loss: 0.993378, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344624, G loss: 1.020816, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.6877\n",
      "[84/1762] D loss: 0.0707, G loss: 3.1534\n",
      "[164/1762] D loss: 1.3985, G loss: 0.6836\n",
      "[244/1762] D loss: 1.4999, G loss: 0.7339\n",
      "[324/1762] D loss: 1.4004, G loss: 0.6793\n",
      "[404/1762] D loss: 0.0656, G loss: 3.1341\n",
      "[484/1762] D loss: 1.3951, G loss: 0.7194\n",
      "[564/1762] D loss: 1.3907, G loss: 0.6756\n",
      "[644/1762] D loss: 0.0835, G loss: 3.1235\n",
      "[724/1762] D loss: 1.3976, G loss: 0.6298\n",
      "[804/1762] D loss: 1.4033, G loss: 0.6786\n",
      "[884/1762] D loss: 0.0724, G loss: 3.1126\n",
      "[964/1762] D loss: 1.3856, G loss: 0.6909\n",
      "[1044/1762] D loss: 1.3953, G loss: 0.6915\n",
      "[1124/1762] D loss: 1.4008, G loss: 0.7351\n",
      "[1204/1762] D loss: 0.0719, G loss: 2.9485\n",
      "[1284/1762] D loss: 0.0804, G loss: 3.1060\n",
      "[1364/1762] D loss: 1.3985, G loss: 0.6772\n",
      "[1444/1762] D loss: 1.4006, G loss: 0.7507\n",
      "[1524/1762] D loss: 0.0450, G loss: 3.4643\n",
      "[1604/1762] D loss: 1.4468, G loss: 0.4915\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6941\n",
      "[1762/1762] D loss: 1.4075, G loss: 0.6006\n",
      "train error: \n",
      " D loss: 1.326488, G loss: 0.674704, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304282, G loss: 0.688614, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.7129\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7020\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7301\n",
      "[244/1762] D loss: 0.0705, G loss: 3.1845\n",
      "[324/1762] D loss: 1.4012, G loss: 0.7270\n",
      "[404/1762] D loss: 1.3975, G loss: 0.5709\n",
      "[484/1762] D loss: 1.4242, G loss: 0.7056\n",
      "[564/1762] D loss: 1.4944, G loss: 0.6787\n",
      "[644/1762] D loss: 1.4078, G loss: 0.6433\n",
      "[724/1762] D loss: 0.0379, G loss: 3.6422\n",
      "[804/1762] D loss: 1.4010, G loss: 0.6993\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6943\n",
      "[964/1762] D loss: 0.0793, G loss: 2.9618\n",
      "[1044/1762] D loss: 0.0482, G loss: 3.6266\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.7304\n",
      "[1204/1762] D loss: 1.3972, G loss: 0.6829\n",
      "[1284/1762] D loss: 1.4290, G loss: 0.7187\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.6854\n",
      "[1444/1762] D loss: 0.1033, G loss: 2.8132\n",
      "[1524/1762] D loss: 1.4069, G loss: 0.7085\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.7164\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.6920\n",
      "[1762/1762] D loss: 1.3921, G loss: 0.6858\n",
      "train error: \n",
      " D loss: 1.352560, G loss: 0.915890, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337307, G loss: 0.923274, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.6861\n",
      "[84/1762] D loss: 0.0702, G loss: 3.2621\n",
      "[164/1762] D loss: 1.3994, G loss: 0.7856\n",
      "[244/1762] D loss: 1.4253, G loss: 0.5546\n",
      "[324/1762] D loss: 1.4526, G loss: 0.7260\n",
      "[404/1762] D loss: 0.6646, G loss: 1.9189\n",
      "[484/1762] D loss: 1.8580, G loss: 1.0663\n",
      "[564/1762] D loss: 1.4310, G loss: 0.6683\n",
      "[644/1762] D loss: 0.0632, G loss: 3.2194\n",
      "[724/1762] D loss: 0.1987, G loss: 2.1925\n",
      "[804/1762] D loss: 0.1585, G loss: 2.9994\n",
      "[884/1762] D loss: 1.5368, G loss: 0.4301\n",
      "[964/1762] D loss: 1.4341, G loss: 0.6154\n",
      "[1044/1762] D loss: 0.0700, G loss: 3.3996\n",
      "[1124/1762] D loss: 0.1071, G loss: 2.6981\n",
      "[1204/1762] D loss: 0.0991, G loss: 2.7899\n",
      "[1284/1762] D loss: 1.4211, G loss: 0.7573\n",
      "[1364/1762] D loss: 1.4328, G loss: 0.6445\n",
      "[1444/1762] D loss: 1.4123, G loss: 0.6642\n",
      "[1524/1762] D loss: 1.3992, G loss: 0.6575\n",
      "[1604/1762] D loss: 0.0572, G loss: 3.5061\n",
      "[1684/1762] D loss: 0.1530, G loss: 2.6519\n",
      "[1762/1762] D loss: 1.4375, G loss: 0.5903\n",
      "train error: \n",
      " D loss: 1.352264, G loss: 1.176815, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327659, G loss: 1.248914, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0734, G loss: 1.9933\n",
      "[84/1762] D loss: 0.0466, G loss: 3.3459\n",
      "[164/1762] D loss: 0.0235, G loss: 4.0263\n",
      "[244/1762] D loss: 1.4024, G loss: 0.7976\n",
      "[324/1762] D loss: 1.5222, G loss: 0.8790\n",
      "[404/1762] D loss: 0.0428, G loss: 3.4013\n",
      "[484/1762] D loss: 1.4069, G loss: 0.6783\n",
      "[564/1762] D loss: 1.4107, G loss: 0.7650\n",
      "[644/1762] D loss: 1.4201, G loss: 0.6533\n",
      "[724/1762] D loss: 1.4187, G loss: 0.8862\n",
      "[804/1762] D loss: 0.6104, G loss: 1.7894\n",
      "[884/1762] D loss: 1.4251, G loss: 0.7598\n",
      "[964/1762] D loss: 1.4867, G loss: 0.8273\n",
      "[1044/1762] D loss: 1.4043, G loss: 0.7118\n",
      "[1124/1762] D loss: 1.5279, G loss: 0.3659\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6505\n",
      "[1284/1762] D loss: 1.3965, G loss: 0.6863\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.7436\n",
      "[1444/1762] D loss: 0.0955, G loss: 3.0943\n",
      "[1524/1762] D loss: 1.3967, G loss: 0.7127\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.7023\n",
      "[1684/1762] D loss: 0.1046, G loss: 2.7392\n",
      "[1762/1762] D loss: 0.0172, G loss: 4.3061\n",
      "train error: \n",
      " D loss: 1.368753, G loss: 1.012235, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358847, G loss: 1.062756, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3957, G loss: 0.6866\n",
      "[84/1762] D loss: 1.1819, G loss: 0.7707\n",
      "[164/1762] D loss: 1.0440, G loss: 0.8039\n",
      "[244/1762] D loss: 0.8235, G loss: 1.0506\n",
      "[324/1762] D loss: 0.8163, G loss: 1.4257\n",
      "[404/1762] D loss: 1.1204, G loss: 0.6331\n",
      "[484/1762] D loss: 1.0162, G loss: 1.2801\n",
      "[564/1762] D loss: 1.4363, G loss: 0.9810\n",
      "[644/1762] D loss: 1.8105, G loss: 1.2639\n",
      "[724/1762] D loss: 0.9197, G loss: 0.6123\n",
      "[804/1762] D loss: 1.2145, G loss: 1.3104\n",
      "[884/1762] D loss: 1.0293, G loss: 0.6831\n",
      "[964/1762] D loss: 1.2888, G loss: 0.4581\n",
      "[1044/1762] D loss: 0.8995, G loss: 0.9701\n",
      "[1124/1762] D loss: 1.0339, G loss: 1.5886\n",
      "[1204/1762] D loss: 0.9955, G loss: 1.7398\n",
      "[1284/1762] D loss: 1.1207, G loss: 1.9041\n",
      "[1364/1762] D loss: 1.3280, G loss: 1.0588\n",
      "[1444/1762] D loss: 1.3362, G loss: 0.6979\n",
      "[1524/1762] D loss: 1.4304, G loss: 0.8384\n",
      "[1604/1762] D loss: 1.4473, G loss: 0.6402\n",
      "[1684/1762] D loss: 1.3516, G loss: 0.7268\n",
      "[1762/1762] D loss: 1.1274, G loss: 0.8690\n",
      "train error: \n",
      " D loss: 1.292746, G loss: 0.709515, D accuracy: 63.1%, cell accuracy: 99.3%, board accuracy: 27.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285729, G loss: 0.723946, D accuracy: 63.1%, cell accuracy: 99.2%, board accuracy: 29.5% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2065, G loss: 1.1193\n",
      "[84/1762] D loss: 1.4316, G loss: 0.5973\n",
      "[164/1762] D loss: 1.3347, G loss: 0.5757\n",
      "[244/1762] D loss: 1.3294, G loss: 0.8495\n",
      "[324/1762] D loss: 1.2668, G loss: 1.2759\n",
      "[404/1762] D loss: 1.2194, G loss: 0.8921\n",
      "[484/1762] D loss: 1.3524, G loss: 0.6621\n",
      "[564/1762] D loss: 1.3667, G loss: 1.1032\n",
      "[644/1762] D loss: 1.1469, G loss: 1.0841\n",
      "[724/1762] D loss: 1.3056, G loss: 0.8185\n",
      "[804/1762] D loss: 0.8934, G loss: 1.1573\n",
      "[884/1762] D loss: 1.4063, G loss: 0.6844\n",
      "[964/1762] D loss: 1.3890, G loss: 0.7212\n",
      "[1044/1762] D loss: 0.9896, G loss: 0.9426\n",
      "[1124/1762] D loss: 1.1743, G loss: 1.0538\n",
      "[1204/1762] D loss: 1.1600, G loss: 1.1807\n",
      "[1284/1762] D loss: 1.3778, G loss: 0.6820\n",
      "[1364/1762] D loss: 1.0866, G loss: 1.0828\n",
      "[1444/1762] D loss: 1.2712, G loss: 0.8120\n",
      "[1524/1762] D loss: 1.3596, G loss: 0.7841\n",
      "[1604/1762] D loss: 1.7404, G loss: 0.9573\n",
      "[1684/1762] D loss: 1.0655, G loss: 1.0731\n",
      "[1762/1762] D loss: 1.4689, G loss: 0.4687\n",
      "train error: \n",
      " D loss: 1.377495, G loss: 0.489387, D accuracy: 53.0%, cell accuracy: 99.6%, board accuracy: 65.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365754, G loss: 0.494587, D accuracy: 53.4%, cell accuracy: 99.6%, board accuracy: 64.8% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4052, G loss: 0.8647\n",
      "[84/1762] D loss: 1.3034, G loss: 0.7157\n",
      "[164/1762] D loss: 1.6148, G loss: 0.6660\n",
      "[244/1762] D loss: 1.3039, G loss: 0.7347\n",
      "[324/1762] D loss: 1.4410, G loss: 0.7350\n",
      "[404/1762] D loss: 1.4255, G loss: 0.6789\n",
      "[484/1762] D loss: 1.4278, G loss: 0.6938\n",
      "[564/1762] D loss: 1.4142, G loss: 0.6691\n",
      "[644/1762] D loss: 0.8819, G loss: 1.0467\n",
      "[724/1762] D loss: 1.4505, G loss: 0.7103\n",
      "[804/1762] D loss: 0.9346, G loss: 1.0294\n",
      "[884/1762] D loss: 1.3620, G loss: 0.6747\n",
      "[964/1762] D loss: 1.4596, G loss: 0.6504\n",
      "[1044/1762] D loss: 1.4204, G loss: 0.8092\n",
      "[1124/1762] D loss: 1.4262, G loss: 0.6581\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.8614\n",
      "[1284/1762] D loss: 1.4001, G loss: 0.7298\n",
      "[1364/1762] D loss: 1.4190, G loss: 0.7004\n",
      "[1444/1762] D loss: 1.0893, G loss: 0.9229\n",
      "[1524/1762] D loss: 1.0809, G loss: 0.8913\n",
      "[1604/1762] D loss: 1.3629, G loss: 0.6861\n",
      "[1684/1762] D loss: 0.9756, G loss: 0.9964\n",
      "[1762/1762] D loss: 1.5580, G loss: 0.7489\n",
      "train error: \n",
      " D loss: 1.306337, G loss: 0.758230, D accuracy: 57.7%, cell accuracy: 99.7%, board accuracy: 72.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292442, G loss: 0.764058, D accuracy: 59.1%, cell accuracy: 99.6%, board accuracy: 71.1% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0314, G loss: 0.9448\n",
      "[84/1762] D loss: 1.2858, G loss: 0.8458\n",
      "[164/1762] D loss: 1.4041, G loss: 0.7962\n",
      "[244/1762] D loss: 1.3697, G loss: 0.7443\n",
      "[324/1762] D loss: 1.2715, G loss: 0.7150\n",
      "[404/1762] D loss: 1.1359, G loss: 0.7982\n",
      "[484/1762] D loss: 1.3656, G loss: 0.7794\n",
      "[564/1762] D loss: 1.5348, G loss: 0.7360\n",
      "[644/1762] D loss: 1.4067, G loss: 0.7006\n",
      "[724/1762] D loss: 1.2092, G loss: 0.7814\n",
      "[804/1762] D loss: 1.4159, G loss: 0.7508\n",
      "[884/1762] D loss: 1.0085, G loss: 1.0627\n",
      "[964/1762] D loss: 1.2692, G loss: 0.7962\n",
      "[1044/1762] D loss: 1.4022, G loss: 0.7027\n",
      "[1124/1762] D loss: 1.0254, G loss: 0.9721\n",
      "[1204/1762] D loss: 0.9132, G loss: 1.0229\n",
      "[1284/1762] D loss: 1.4210, G loss: 0.7448\n",
      "[1364/1762] D loss: 1.2201, G loss: 1.1130\n",
      "[1444/1762] D loss: 1.3757, G loss: 0.7457\n",
      "[1524/1762] D loss: 1.4208, G loss: 0.7130\n",
      "[1604/1762] D loss: 1.3774, G loss: 0.6766\n",
      "[1684/1762] D loss: 1.3789, G loss: 0.6995\n",
      "[1762/1762] D loss: 1.3384, G loss: 0.5844\n",
      "train error: \n",
      " D loss: 1.359888, G loss: 0.569764, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353125, G loss: 0.569149, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909, G loss: 0.7731\n",
      "[84/1762] D loss: 1.3669, G loss: 0.6847\n",
      "[164/1762] D loss: 1.3974, G loss: 0.7374\n",
      "[244/1762] D loss: 1.3914, G loss: 0.7131\n",
      "[324/1762] D loss: 1.3874, G loss: 0.7065\n",
      "[404/1762] D loss: 1.3786, G loss: 0.6995\n",
      "[484/1762] D loss: 1.4440, G loss: 0.7920\n",
      "[564/1762] D loss: 1.2078, G loss: 0.9834\n",
      "[644/1762] D loss: 1.2524, G loss: 0.8797\n",
      "[724/1762] D loss: 1.2066, G loss: 0.8983\n",
      "[804/1762] D loss: 1.0253, G loss: 0.9202\n",
      "[884/1762] D loss: 1.3929, G loss: 0.6660\n",
      "[964/1762] D loss: 1.3939, G loss: 0.6728\n",
      "[1044/1762] D loss: 1.4112, G loss: 0.8506\n",
      "[1124/1762] D loss: 1.3446, G loss: 0.7655\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6802\n",
      "[1284/1762] D loss: 1.3839, G loss: 0.6951\n",
      "[1364/1762] D loss: 1.3308, G loss: 0.6015\n",
      "[1444/1762] D loss: 1.3992, G loss: 0.7435\n",
      "[1524/1762] D loss: 1.4203, G loss: 0.7786\n",
      "[1604/1762] D loss: 1.4518, G loss: 0.7884\n",
      "[1684/1762] D loss: 1.1077, G loss: 0.9433\n",
      "[1762/1762] D loss: 1.4120, G loss: 0.7642\n",
      "train error: \n",
      " D loss: 1.353221, G loss: 0.563466, D accuracy: 54.8%, cell accuracy: 99.4%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340579, G loss: 0.566803, D accuracy: 55.8%, cell accuracy: 99.3%, board accuracy: 50.9% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4025, G loss: 0.6832\n",
      "[84/1762] D loss: 1.3156, G loss: 0.7456\n",
      "[164/1762] D loss: 1.4001, G loss: 0.7092\n",
      "[244/1762] D loss: 1.3726, G loss: 0.6968\n",
      "[324/1762] D loss: 1.3959, G loss: 0.7160\n",
      "[404/1762] D loss: 1.0208, G loss: 0.9707\n",
      "[484/1762] D loss: 1.4061, G loss: 0.6800\n",
      "[564/1762] D loss: 1.2924, G loss: 0.9358\n",
      "[644/1762] D loss: 1.2904, G loss: 0.8455\n",
      "[724/1762] D loss: 1.4018, G loss: 0.7934\n",
      "[804/1762] D loss: 1.3907, G loss: 0.6498\n",
      "[884/1762] D loss: 1.3975, G loss: 0.7780\n",
      "[964/1762] D loss: 0.8251, G loss: 1.1457\n",
      "[1044/1762] D loss: 1.3713, G loss: 0.7214\n",
      "[1124/1762] D loss: 1.3781, G loss: 0.7022\n",
      "[1204/1762] D loss: 1.4029, G loss: 0.7037\n",
      "[1284/1762] D loss: 1.7956, G loss: 0.6741\n",
      "[1364/1762] D loss: 1.3583, G loss: 0.7776\n",
      "[1444/1762] D loss: 1.3797, G loss: 0.7573\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.7015\n",
      "[1604/1762] D loss: 1.3755, G loss: 0.7459\n",
      "[1684/1762] D loss: 1.3811, G loss: 0.7014\n",
      "[1762/1762] D loss: 1.3845, G loss: 0.7259\n",
      "train error: \n",
      " D loss: 1.314107, G loss: 0.855226, D accuracy: 57.1%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302620, G loss: 0.867758, D accuracy: 58.2%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4003, G loss: 0.6916\n",
      "[84/1762] D loss: 1.4302, G loss: 0.6586\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6535\n",
      "[244/1762] D loss: 1.3954, G loss: 0.6917\n",
      "[324/1762] D loss: 1.8483, G loss: 0.6042\n",
      "[404/1762] D loss: 1.3722, G loss: 0.7595\n",
      "[484/1762] D loss: 1.4172, G loss: 0.7315\n",
      "[564/1762] D loss: 1.3912, G loss: 0.7119\n",
      "[644/1762] D loss: 1.1677, G loss: 0.9099\n",
      "[724/1762] D loss: 1.2202, G loss: 0.8189\n",
      "[804/1762] D loss: 1.3621, G loss: 0.7286\n",
      "[884/1762] D loss: 1.4527, G loss: 0.6714\n",
      "[964/1762] D loss: 1.4013, G loss: 0.7177\n",
      "[1044/1762] D loss: 0.8825, G loss: 1.2666\n",
      "[1124/1762] D loss: 1.3989, G loss: 0.6631\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.6659\n",
      "[1284/1762] D loss: 1.4053, G loss: 0.7275\n",
      "[1364/1762] D loss: 1.5237, G loss: 0.6677\n",
      "[1444/1762] D loss: 1.4917, G loss: 0.4778\n",
      "[1524/1762] D loss: 1.1034, G loss: 0.9678\n",
      "[1604/1762] D loss: 1.4944, G loss: 0.7779\n",
      "[1684/1762] D loss: 0.8162, G loss: 1.1190\n",
      "[1762/1762] D loss: 1.4078, G loss: 0.6413\n",
      "train error: \n",
      " D loss: 1.307032, G loss: 0.666962, D accuracy: 58.6%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291512, G loss: 0.662567, D accuracy: 60.1%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4438, G loss: 0.6810\n",
      "[84/1762] D loss: 0.8451, G loss: 1.2249\n",
      "[164/1762] D loss: 1.4283, G loss: 0.7115\n",
      "[244/1762] D loss: 0.7922, G loss: 1.5703\n",
      "[324/1762] D loss: 1.4675, G loss: 0.6472\n",
      "[404/1762] D loss: 1.7384, G loss: 0.5742\n",
      "[484/1762] D loss: 1.3876, G loss: 1.2336\n",
      "[564/1762] D loss: 1.4472, G loss: 0.6838\n",
      "[644/1762] D loss: 0.6840, G loss: 1.5431\n",
      "[724/1762] D loss: 0.8592, G loss: 1.1197\n",
      "[804/1762] D loss: 1.4136, G loss: 0.7395\n",
      "[884/1762] D loss: 1.4076, G loss: 0.7361\n",
      "[964/1762] D loss: 1.4408, G loss: 0.6430\n",
      "[1044/1762] D loss: 0.6149, G loss: 1.2665\n",
      "[1124/1762] D loss: 1.3166, G loss: 0.7925\n",
      "[1204/1762] D loss: 1.4118, G loss: 0.8690\n",
      "[1284/1762] D loss: 1.1432, G loss: 0.9025\n",
      "[1364/1762] D loss: 0.9569, G loss: 1.0197\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.7110\n",
      "[1524/1762] D loss: 0.7594, G loss: 1.2736\n",
      "[1604/1762] D loss: 1.3992, G loss: 0.7068\n",
      "[1684/1762] D loss: 0.6646, G loss: 1.3375\n",
      "[1762/1762] D loss: 0.8087, G loss: 1.8984\n",
      "train error: \n",
      " D loss: 1.306728, G loss: 0.680016, D accuracy: 61.8%, cell accuracy: 99.5%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297366, G loss: 0.677683, D accuracy: 60.7%, cell accuracy: 99.4%, board accuracy: 60.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5765, G loss: 0.6800\n",
      "[84/1762] D loss: 1.5094, G loss: 0.9734\n",
      "[164/1762] D loss: 1.2457, G loss: 1.0171\n",
      "[244/1762] D loss: 1.3429, G loss: 0.8031\n",
      "[324/1762] D loss: 1.4407, G loss: 0.8053\n",
      "[404/1762] D loss: 1.0955, G loss: 0.9288\n",
      "[484/1762] D loss: 1.3854, G loss: 0.7216\n",
      "[564/1762] D loss: 1.3858, G loss: 0.7478\n",
      "[644/1762] D loss: 1.3495, G loss: 0.6918\n",
      "[724/1762] D loss: 1.5043, G loss: 0.7226\n",
      "[804/1762] D loss: 1.3661, G loss: 0.7151\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6944\n",
      "[964/1762] D loss: 1.4105, G loss: 0.6502\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.6801\n",
      "[1124/1762] D loss: 1.7006, G loss: 0.7265\n",
      "[1204/1762] D loss: 1.4526, G loss: 0.7857\n",
      "[1284/1762] D loss: 1.0457, G loss: 1.2044\n",
      "[1364/1762] D loss: 1.3815, G loss: 0.7908\n",
      "[1444/1762] D loss: 1.3833, G loss: 0.6870\n",
      "[1524/1762] D loss: 1.3804, G loss: 0.7212\n",
      "[1604/1762] D loss: 1.3839, G loss: 0.6755\n",
      "[1684/1762] D loss: 0.8736, G loss: 1.3201\n",
      "[1762/1762] D loss: 1.4862, G loss: 0.6808\n",
      "train error: \n",
      " D loss: 1.331737, G loss: 0.602137, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317894, G loss: 0.609454, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4254, G loss: 0.6820\n",
      "[84/1762] D loss: 1.4057, G loss: 0.7003\n",
      "[164/1762] D loss: 0.8843, G loss: 1.2907\n",
      "[244/1762] D loss: 0.4168, G loss: 1.6850\n",
      "[324/1762] D loss: 1.4290, G loss: 0.6942\n",
      "[404/1762] D loss: 1.4083, G loss: 0.7462\n",
      "[484/1762] D loss: 0.9019, G loss: 1.2067\n",
      "[564/1762] D loss: 1.3975, G loss: 0.6820\n",
      "[644/1762] D loss: 1.4182, G loss: 0.6910\n",
      "[724/1762] D loss: 1.4098, G loss: 0.7146\n",
      "[804/1762] D loss: 1.3958, G loss: 0.7047\n",
      "[884/1762] D loss: 1.3928, G loss: 0.7072\n",
      "[964/1762] D loss: 1.3917, G loss: 0.7016\n",
      "[1044/1762] D loss: 0.7168, G loss: 1.2170\n",
      "[1124/1762] D loss: 1.3716, G loss: 0.6762\n",
      "[1204/1762] D loss: 1.4312, G loss: 0.7354\n",
      "[1284/1762] D loss: 1.4153, G loss: 0.7198\n",
      "[1364/1762] D loss: 1.4439, G loss: 0.6751\n",
      "[1444/1762] D loss: 1.3172, G loss: 0.8128\n",
      "[1524/1762] D loss: 0.4434, G loss: 1.6462\n",
      "[1604/1762] D loss: 0.6517, G loss: 1.5501\n",
      "[1684/1762] D loss: 1.4565, G loss: 0.8226\n",
      "[1762/1762] D loss: 1.4406, G loss: 0.6927\n",
      "train error: \n",
      " D loss: 1.282103, G loss: 0.876036, D accuracy: 57.3%, cell accuracy: 99.4%, board accuracy: 67.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271367, G loss: 0.882638, D accuracy: 58.0%, cell accuracy: 99.4%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5075, G loss: 0.6924\n",
      "[84/1762] D loss: 1.4034, G loss: 0.6828\n",
      "[164/1762] D loss: 0.8786, G loss: 1.0984\n",
      "[244/1762] D loss: 0.5822, G loss: 1.6186\n",
      "[324/1762] D loss: 1.4148, G loss: 0.6767\n",
      "[404/1762] D loss: 1.5262, G loss: 0.6518\n",
      "[484/1762] D loss: 1.4263, G loss: 0.7199\n",
      "[564/1762] D loss: 1.3860, G loss: 0.7281\n",
      "[644/1762] D loss: 1.4343, G loss: 0.6652\n",
      "[724/1762] D loss: 1.4336, G loss: 0.6675\n",
      "[804/1762] D loss: 1.3324, G loss: 0.7181\n",
      "[884/1762] D loss: 1.3202, G loss: 0.7582\n",
      "[964/1762] D loss: 0.5534, G loss: 1.8730\n",
      "[1044/1762] D loss: 1.4897, G loss: 0.5301\n",
      "[1124/1762] D loss: 1.5893, G loss: 0.5298\n",
      "[1204/1762] D loss: 1.4689, G loss: 0.6278\n",
      "[1284/1762] D loss: 1.8691, G loss: 0.9252\n",
      "[1364/1762] D loss: 1.1186, G loss: 1.0277\n",
      "[1444/1762] D loss: 1.5013, G loss: 0.6610\n",
      "[1524/1762] D loss: 0.6338, G loss: 1.3485\n",
      "[1604/1762] D loss: 1.3860, G loss: 0.7072\n",
      "[1684/1762] D loss: 1.3772, G loss: 0.7014\n",
      "[1762/1762] D loss: 1.4372, G loss: 0.6869\n",
      "train error: \n",
      " D loss: 1.333661, G loss: 0.650984, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316209, G loss: 0.654224, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4096, G loss: 0.6903\n",
      "[84/1762] D loss: 1.3907, G loss: 0.7076\n",
      "[164/1762] D loss: 1.3900, G loss: 0.6929\n",
      "[244/1762] D loss: 0.5876, G loss: 1.3537\n",
      "[324/1762] D loss: 1.3899, G loss: 0.7081\n",
      "[404/1762] D loss: 1.4093, G loss: 0.6731\n",
      "[484/1762] D loss: 1.4428, G loss: 0.6948\n",
      "[564/1762] D loss: 1.3952, G loss: 0.6796\n",
      "[644/1762] D loss: 1.4421, G loss: 0.6716\n",
      "[724/1762] D loss: 1.4508, G loss: 0.6694\n",
      "[804/1762] D loss: 1.4020, G loss: 0.7314\n",
      "[884/1762] D loss: 1.4169, G loss: 0.7316\n",
      "[964/1762] D loss: 1.4174, G loss: 0.6969\n",
      "[1044/1762] D loss: 1.4083, G loss: 0.7330\n",
      "[1124/1762] D loss: 1.4045, G loss: 0.7118\n",
      "[1204/1762] D loss: 0.5706, G loss: 1.5210\n",
      "[1284/1762] D loss: 1.4135, G loss: 0.7224\n",
      "[1364/1762] D loss: 1.4517, G loss: 0.6658\n",
      "[1444/1762] D loss: 1.4008, G loss: 0.7069\n",
      "[1524/1762] D loss: 0.4454, G loss: 1.7557\n",
      "[1604/1762] D loss: 1.3080, G loss: 0.7850\n",
      "[1684/1762] D loss: 0.7514, G loss: 1.5486\n",
      "[1762/1762] D loss: 1.4268, G loss: 0.7016\n",
      "train error: \n",
      " D loss: 1.314265, G loss: 0.833406, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295780, G loss: 0.828886, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4004, G loss: 0.8113\n",
      "[84/1762] D loss: 0.7743, G loss: 1.2687\n",
      "[164/1762] D loss: 0.4106, G loss: 1.6731\n",
      "[244/1762] D loss: 1.4447, G loss: 0.6708\n",
      "[324/1762] D loss: 0.5058, G loss: 1.4560\n",
      "[404/1762] D loss: 1.4003, G loss: 0.6885\n",
      "[484/1762] D loss: 1.3124, G loss: 0.8188\n",
      "[564/1762] D loss: 0.7359, G loss: 1.2769\n",
      "[644/1762] D loss: 1.4386, G loss: 0.7613\n",
      "[724/1762] D loss: 1.4163, G loss: 0.6649\n",
      "[804/1762] D loss: 1.4323, G loss: 0.7061\n",
      "[884/1762] D loss: 1.4270, G loss: 0.6962\n",
      "[964/1762] D loss: 1.4125, G loss: 0.7181\n",
      "[1044/1762] D loss: 1.5623, G loss: 0.6832\n",
      "[1124/1762] D loss: 0.6422, G loss: 1.2497\n",
      "[1204/1762] D loss: 0.4862, G loss: 1.5411\n",
      "[1284/1762] D loss: 1.5614, G loss: 0.7243\n",
      "[1364/1762] D loss: 1.4063, G loss: 0.6992\n",
      "[1444/1762] D loss: 1.4387, G loss: 0.7247\n",
      "[1524/1762] D loss: 0.6410, G loss: 1.2527\n",
      "[1604/1762] D loss: 1.3959, G loss: 0.6797\n",
      "[1684/1762] D loss: 0.4731, G loss: 1.4973\n",
      "[1762/1762] D loss: 1.4291, G loss: 0.7708\n",
      "train error: \n",
      " D loss: 1.327976, G loss: 0.952603, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303987, G loss: 0.957808, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4166, G loss: 0.7183\n",
      "[84/1762] D loss: 0.2748, G loss: 1.8359\n",
      "[164/1762] D loss: 1.3977, G loss: 0.6949\n",
      "[244/1762] D loss: 1.4260, G loss: 0.6606\n",
      "[324/1762] D loss: 1.3899, G loss: 0.6951\n",
      "[404/1762] D loss: 1.3855, G loss: 0.7296\n",
      "[484/1762] D loss: 1.4667, G loss: 0.7441\n",
      "[564/1762] D loss: 1.4562, G loss: 0.7591\n",
      "[644/1762] D loss: 1.3966, G loss: 0.6755\n",
      "[724/1762] D loss: 1.5920, G loss: 0.8436\n",
      "[804/1762] D loss: 0.9140, G loss: 1.3028\n",
      "[884/1762] D loss: 1.4259, G loss: 0.7161\n",
      "[964/1762] D loss: 1.4760, G loss: 0.7501\n",
      "[1044/1762] D loss: 0.4048, G loss: 1.6557\n",
      "[1124/1762] D loss: 1.4879, G loss: 0.7530\n",
      "[1204/1762] D loss: 1.4169, G loss: 0.7724\n",
      "[1284/1762] D loss: 1.6908, G loss: 0.8461\n",
      "[1364/1762] D loss: 1.4065, G loss: 0.7167\n",
      "[1444/1762] D loss: 1.4809, G loss: 0.8387\n",
      "[1524/1762] D loss: 1.4219, G loss: 0.6941\n",
      "[1604/1762] D loss: 0.6992, G loss: 1.3210\n",
      "[1684/1762] D loss: 1.4196, G loss: 0.7151\n",
      "[1762/1762] D loss: 0.2213, G loss: 1.9985\n",
      "train error: \n",
      " D loss: 1.376311, G loss: 0.534185, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360040, G loss: 0.540972, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.7007\n",
      "[84/1762] D loss: 1.4071, G loss: 0.6992\n",
      "[164/1762] D loss: 1.4235, G loss: 0.7173\n",
      "[244/1762] D loss: 1.4591, G loss: 0.7972\n",
      "[324/1762] D loss: 1.4973, G loss: 0.7552\n",
      "[404/1762] D loss: 1.3446, G loss: 0.7208\n",
      "[484/1762] D loss: 1.4362, G loss: 0.7095\n",
      "[564/1762] D loss: 1.3536, G loss: 0.9161\n",
      "[644/1762] D loss: 0.5912, G loss: 1.4195\n",
      "[724/1762] D loss: 0.5054, G loss: 1.4888\n",
      "[804/1762] D loss: 1.4478, G loss: 0.7205\n",
      "[884/1762] D loss: 0.5560, G loss: 1.5086\n",
      "[964/1762] D loss: 1.3777, G loss: 0.7301\n",
      "[1044/1762] D loss: 1.4556, G loss: 0.7171\n",
      "[1124/1762] D loss: 1.3936, G loss: 0.6971\n",
      "[1204/1762] D loss: 1.1450, G loss: 1.4588\n",
      "[1284/1762] D loss: 1.3540, G loss: 1.1204\n",
      "[1364/1762] D loss: 1.1482, G loss: 0.9411\n",
      "[1444/1762] D loss: 1.0901, G loss: 0.9248\n",
      "[1524/1762] D loss: 0.9839, G loss: 0.9188\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.7017\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.6867\n",
      "[1762/1762] D loss: 1.4192, G loss: 0.7391\n",
      "train error: \n",
      " D loss: 1.335177, G loss: 0.624941, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319079, G loss: 0.630955, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3970, G loss: 0.6882\n",
      "[84/1762] D loss: 1.3882, G loss: 0.6840\n",
      "[164/1762] D loss: 0.7182, G loss: 1.1261\n",
      "[244/1762] D loss: 1.4779, G loss: 0.7135\n",
      "[324/1762] D loss: 1.4106, G loss: 0.6770\n",
      "[404/1762] D loss: 1.3984, G loss: 0.6994\n",
      "[484/1762] D loss: 0.6530, G loss: 1.2775\n",
      "[564/1762] D loss: 1.4009, G loss: 0.7462\n",
      "[644/1762] D loss: 1.3685, G loss: 0.9874\n",
      "[724/1762] D loss: 1.3995, G loss: 0.7040\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6956\n",
      "[884/1762] D loss: 1.3921, G loss: 0.7222\n",
      "[964/1762] D loss: 1.4387, G loss: 0.7233\n",
      "[1044/1762] D loss: 1.3248, G loss: 0.7353\n",
      "[1124/1762] D loss: 1.4020, G loss: 0.6923\n",
      "[1204/1762] D loss: 1.4162, G loss: 0.6539\n",
      "[1284/1762] D loss: 1.4024, G loss: 0.6944\n",
      "[1364/1762] D loss: 1.4175, G loss: 0.6576\n",
      "[1444/1762] D loss: 1.3783, G loss: 0.6978\n",
      "[1524/1762] D loss: 1.4626, G loss: 0.7073\n",
      "[1604/1762] D loss: 1.2925, G loss: 0.7259\n",
      "[1684/1762] D loss: 1.3898, G loss: 0.7296\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.6836\n",
      "train error: \n",
      " D loss: 1.452019, G loss: 0.487419, D accuracy: 56.2%, cell accuracy: 99.6%, board accuracy: 71.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.443558, G loss: 0.492891, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4023, G loss: 0.7367\n",
      "[84/1762] D loss: 1.4432, G loss: 0.7244\n",
      "[164/1762] D loss: 0.2843, G loss: 1.8250\n",
      "[244/1762] D loss: 0.6351, G loss: 1.3775\n",
      "[324/1762] D loss: 0.5076, G loss: 1.7507\n",
      "[404/1762] D loss: 1.4030, G loss: 0.7115\n",
      "[484/1762] D loss: 1.4036, G loss: 0.7119\n",
      "[564/1762] D loss: 0.4667, G loss: 1.4130\n",
      "[644/1762] D loss: 1.5228, G loss: 0.7237\n",
      "[724/1762] D loss: 0.4651, G loss: 1.6110\n",
      "[804/1762] D loss: 0.7015, G loss: 1.1845\n",
      "[884/1762] D loss: 1.4190, G loss: 0.6905\n",
      "[964/1762] D loss: 0.6039, G loss: 1.3903\n",
      "[1044/1762] D loss: 1.3815, G loss: 0.7198\n",
      "[1124/1762] D loss: 1.7148, G loss: 0.8100\n",
      "[1204/1762] D loss: 1.5116, G loss: 0.7103\n",
      "[1284/1762] D loss: 0.4642, G loss: 1.4923\n",
      "[1364/1762] D loss: 1.3157, G loss: 0.8051\n",
      "[1444/1762] D loss: 1.3853, G loss: 0.7101\n",
      "[1524/1762] D loss: 1.4206, G loss: 0.7501\n",
      "[1604/1762] D loss: 1.3952, G loss: 0.7034\n",
      "[1684/1762] D loss: 1.4798, G loss: 0.8907\n",
      "[1762/1762] D loss: 0.7480, G loss: 1.5184\n",
      "train error: \n",
      " D loss: 1.079150, G loss: 0.972699, D accuracy: 76.6%, cell accuracy: 98.1%, board accuracy: 19.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.074538, G loss: 0.984672, D accuracy: 76.5%, cell accuracy: 98.0%, board accuracy: 18.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4730, G loss: 0.7832\n",
      "[84/1762] D loss: 1.3972, G loss: 0.6911\n",
      "[164/1762] D loss: 1.4386, G loss: 1.2619\n",
      "[244/1762] D loss: 1.4200, G loss: 0.6772\n",
      "[324/1762] D loss: 1.4233, G loss: 0.6812\n",
      "[404/1762] D loss: 1.4315, G loss: 0.7649\n",
      "[484/1762] D loss: 1.4020, G loss: 0.6623\n",
      "[564/1762] D loss: 1.6035, G loss: 0.7148\n",
      "[644/1762] D loss: 1.3980, G loss: 0.7307\n",
      "[724/1762] D loss: 0.4908, G loss: 1.5660\n",
      "[804/1762] D loss: 1.4380, G loss: 0.7460\n",
      "[884/1762] D loss: 1.4794, G loss: 0.7635\n",
      "[964/1762] D loss: 1.4070, G loss: 0.6703\n",
      "[1044/1762] D loss: 1.4502, G loss: 0.7340\n",
      "[1124/1762] D loss: 1.4641, G loss: 0.7618\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.7190\n",
      "[1284/1762] D loss: 1.1327, G loss: 0.8280\n",
      "[1364/1762] D loss: 1.3611, G loss: 0.8951\n",
      "[1444/1762] D loss: 1.4050, G loss: 0.6978\n",
      "[1524/1762] D loss: 0.8016, G loss: 1.1229\n",
      "[1604/1762] D loss: 1.3401, G loss: 0.7337\n",
      "[1684/1762] D loss: 1.4297, G loss: 0.7363\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.6736\n",
      "train error: \n",
      " D loss: 1.350753, G loss: 0.649629, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332083, G loss: 0.663726, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3833, G loss: 0.7324\n",
      "[84/1762] D loss: 1.3890, G loss: 0.6961\n",
      "[164/1762] D loss: 1.3660, G loss: 0.6893\n",
      "[244/1762] D loss: 1.3784, G loss: 0.7197\n",
      "[324/1762] D loss: 1.3906, G loss: 0.6891\n",
      "[404/1762] D loss: 1.2613, G loss: 0.9966\n",
      "[484/1762] D loss: 1.4016, G loss: 0.6836\n",
      "[564/1762] D loss: 1.3847, G loss: 0.6984\n",
      "[644/1762] D loss: 1.4051, G loss: 0.6777\n",
      "[724/1762] D loss: 0.7857, G loss: 1.1435\n",
      "[804/1762] D loss: 0.8981, G loss: 1.0263\n",
      "[884/1762] D loss: 1.4213, G loss: 0.6717\n",
      "[964/1762] D loss: 0.6037, G loss: 1.4219\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6959\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.7125\n",
      "[1204/1762] D loss: 1.3995, G loss: 0.7051\n",
      "[1284/1762] D loss: 1.4098, G loss: 0.7030\n",
      "[1364/1762] D loss: 1.4288, G loss: 0.7955\n",
      "[1444/1762] D loss: 1.4184, G loss: 0.6585\n",
      "[1524/1762] D loss: 1.3969, G loss: 0.6862\n",
      "[1604/1762] D loss: 1.3931, G loss: 0.6934\n",
      "[1684/1762] D loss: 1.3972, G loss: 0.7815\n",
      "[1762/1762] D loss: 1.2988, G loss: 0.9466\n",
      "train error: \n",
      " D loss: 1.050549, G loss: 1.092519, D accuracy: 80.6%, cell accuracy: 98.6%, board accuracy: 16.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.033705, G loss: 1.142162, D accuracy: 80.3%, cell accuracy: 98.5%, board accuracy: 13.2% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3069, G loss: 0.7385\n",
      "[84/1762] D loss: 1.4321, G loss: 0.6773\n",
      "[164/1762] D loss: 1.3591, G loss: 0.6710\n",
      "[244/1762] D loss: 1.5130, G loss: 0.6513\n",
      "[324/1762] D loss: 1.4281, G loss: 0.6677\n",
      "[404/1762] D loss: 1.4451, G loss: 0.5568\n",
      "[484/1762] D loss: 1.4064, G loss: 0.7710\n",
      "[564/1762] D loss: 1.4307, G loss: 0.7625\n",
      "[644/1762] D loss: 1.3428, G loss: 0.7657\n",
      "[724/1762] D loss: 0.4141, G loss: 1.8704\n",
      "[804/1762] D loss: 1.6093, G loss: 1.2857\n",
      "[884/1762] D loss: 1.5590, G loss: 0.9611\n",
      "[964/1762] D loss: 0.8363, G loss: 1.1880\n",
      "[1044/1762] D loss: 1.4192, G loss: 0.7155\n",
      "[1124/1762] D loss: 1.5470, G loss: 0.6448\n",
      "[1204/1762] D loss: 1.4062, G loss: 0.6683\n",
      "[1284/1762] D loss: 1.4089, G loss: 0.6982\n",
      "[1364/1762] D loss: 1.4169, G loss: 0.7684\n",
      "[1444/1762] D loss: 0.8006, G loss: 1.2620\n",
      "[1524/1762] D loss: 1.3681, G loss: 0.7234\n",
      "[1604/1762] D loss: 1.4316, G loss: 0.7235\n",
      "[1684/1762] D loss: 1.4481, G loss: 0.6777\n",
      "[1762/1762] D loss: 0.2879, G loss: 1.9503\n",
      "train error: \n",
      " D loss: 1.334531, G loss: 0.884101, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311133, G loss: 0.887671, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4335, G loss: 1.6163\n",
      "[84/1762] D loss: 1.4231, G loss: 0.7111\n",
      "[164/1762] D loss: 1.3645, G loss: 0.6831\n",
      "[244/1762] D loss: 1.4116, G loss: 0.6926\n",
      "[324/1762] D loss: 0.5420, G loss: 1.5076\n",
      "[404/1762] D loss: 1.6493, G loss: 0.6096\n",
      "[484/1762] D loss: 1.5366, G loss: 0.6298\n",
      "[564/1762] D loss: 1.4167, G loss: 0.7224\n",
      "[644/1762] D loss: 0.6385, G loss: 1.2590\n",
      "[724/1762] D loss: 1.4258, G loss: 0.7223\n",
      "[804/1762] D loss: 0.5551, G loss: 1.5093\n",
      "[884/1762] D loss: 1.3804, G loss: 0.7082\n",
      "[964/1762] D loss: 1.4062, G loss: 0.7488\n",
      "[1044/1762] D loss: 1.9002, G loss: 0.5814\n",
      "[1124/1762] D loss: 1.4286, G loss: 0.6499\n",
      "[1204/1762] D loss: 0.3561, G loss: 1.6572\n",
      "[1284/1762] D loss: 0.3639, G loss: 1.7296\n",
      "[1364/1762] D loss: 1.3942, G loss: 0.6841\n",
      "[1444/1762] D loss: 1.5840, G loss: 0.7031\n",
      "[1524/1762] D loss: 1.7622, G loss: 1.3154\n",
      "[1604/1762] D loss: 1.5358, G loss: 0.7833\n",
      "[1684/1762] D loss: 1.3812, G loss: 1.3763\n",
      "[1762/1762] D loss: 1.3629, G loss: 0.7552\n",
      "train error: \n",
      " D loss: 1.317169, G loss: 0.706500, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 79.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317174, G loss: 0.697057, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3562, G loss: 0.9872\n",
      "[84/1762] D loss: 1.4232, G loss: 0.7120\n",
      "[164/1762] D loss: 0.8800, G loss: 1.3731\n",
      "[244/1762] D loss: 1.3627, G loss: 0.7093\n",
      "[324/1762] D loss: 1.3622, G loss: 0.6896\n",
      "[404/1762] D loss: 1.3804, G loss: 0.7140\n",
      "[484/1762] D loss: 1.3951, G loss: 0.6985\n",
      "[564/1762] D loss: 1.4128, G loss: 0.6918\n",
      "[644/1762] D loss: 1.4130, G loss: 0.6969\n",
      "[724/1762] D loss: 1.3954, G loss: 0.7132\n",
      "[804/1762] D loss: 1.3999, G loss: 0.7043\n",
      "[884/1762] D loss: 1.4027, G loss: 0.7062\n",
      "[964/1762] D loss: 1.3400, G loss: 0.7744\n",
      "[1044/1762] D loss: 0.3986, G loss: 1.5793\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6687\n",
      "[1204/1762] D loss: 1.3999, G loss: 0.7259\n",
      "[1284/1762] D loss: 1.3926, G loss: 0.7131\n",
      "[1364/1762] D loss: 1.4242, G loss: 0.7594\n",
      "[1444/1762] D loss: 1.4049, G loss: 0.7142\n",
      "[1524/1762] D loss: 0.3034, G loss: 1.9977\n",
      "[1604/1762] D loss: 1.3781, G loss: 0.6910\n",
      "[1684/1762] D loss: 0.7951, G loss: 1.5696\n",
      "[1762/1762] D loss: 1.3966, G loss: 0.7234\n",
      "train error: \n",
      " D loss: 1.326178, G loss: 0.887503, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 74.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326368, G loss: 0.847695, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 72.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4442, G loss: 0.8613\n",
      "[84/1762] D loss: 1.4142, G loss: 0.7014\n",
      "[164/1762] D loss: 1.3877, G loss: 0.6904\n",
      "[244/1762] D loss: 1.4124, G loss: 0.8011\n",
      "[324/1762] D loss: 1.3311, G loss: 1.1059\n",
      "[404/1762] D loss: 1.3820, G loss: 0.7705\n",
      "[484/1762] D loss: 1.3922, G loss: 0.6815\n",
      "[564/1762] D loss: 0.4382, G loss: 1.6686\n",
      "[644/1762] D loss: 0.4403, G loss: 1.7972\n",
      "[724/1762] D loss: 0.5610, G loss: 1.4394\n",
      "[804/1762] D loss: 1.5628, G loss: 0.7658\n",
      "[884/1762] D loss: 1.4926, G loss: 0.6860\n",
      "[964/1762] D loss: 1.4471, G loss: 0.7532\n",
      "[1044/1762] D loss: 1.4067, G loss: 0.7194\n",
      "[1124/1762] D loss: 1.4152, G loss: 0.7337\n",
      "[1204/1762] D loss: 1.5882, G loss: 0.7764\n",
      "[1284/1762] D loss: 1.4034, G loss: 0.7192\n",
      "[1364/1762] D loss: 0.7881, G loss: 1.7067\n",
      "[1444/1762] D loss: 1.7145, G loss: 0.8482\n",
      "[1524/1762] D loss: 1.3766, G loss: 0.7808\n",
      "[1604/1762] D loss: 1.4106, G loss: 0.7200\n",
      "[1684/1762] D loss: 1.6079, G loss: 0.8545\n",
      "[1762/1762] D loss: 1.0512, G loss: 1.6387\n",
      "train error: \n",
      " D loss: 1.297668, G loss: 1.201631, D accuracy: 57.1%, cell accuracy: 99.5%, board accuracy: 71.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280783, G loss: 1.220108, D accuracy: 57.3%, cell accuracy: 99.5%, board accuracy: 67.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3447, G loss: 0.9050\n",
      "[84/1762] D loss: 1.3934, G loss: 0.6904\n",
      "[164/1762] D loss: 1.3964, G loss: 0.6751\n",
      "[244/1762] D loss: 1.4049, G loss: 0.7031\n",
      "[324/1762] D loss: 1.3952, G loss: 0.7101\n",
      "[404/1762] D loss: 1.2372, G loss: 0.8992\n",
      "[484/1762] D loss: 1.3913, G loss: 0.7484\n",
      "[564/1762] D loss: 0.9576, G loss: 1.1025\n",
      "[644/1762] D loss: 1.4134, G loss: 0.6618\n",
      "[724/1762] D loss: 1.3894, G loss: 0.6975\n",
      "[804/1762] D loss: 0.8091, G loss: 1.1230\n",
      "[884/1762] D loss: 1.3994, G loss: 0.7078\n",
      "[964/1762] D loss: 1.4270, G loss: 0.7199\n",
      "[1044/1762] D loss: 1.3971, G loss: 0.7140\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.6840\n",
      "[1204/1762] D loss: 1.9590, G loss: 0.6987\n",
      "[1284/1762] D loss: 1.4032, G loss: 0.7181\n",
      "[1364/1762] D loss: 1.4045, G loss: 0.7430\n",
      "[1444/1762] D loss: 1.4240, G loss: 0.7353\n",
      "[1524/1762] D loss: 1.4175, G loss: 0.6901\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.9168\n",
      "[1684/1762] D loss: 1.2203, G loss: 0.7847\n",
      "[1762/1762] D loss: 1.6101, G loss: 0.7203\n",
      "train error: \n",
      " D loss: 1.370572, G loss: 0.734231, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357036, G loss: 0.768251, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4126, G loss: 0.6911\n",
      "[84/1762] D loss: 1.3898, G loss: 0.6788\n",
      "[164/1762] D loss: 1.0697, G loss: 0.9929\n",
      "[244/1762] D loss: 1.3846, G loss: 0.6814\n",
      "[324/1762] D loss: 1.4011, G loss: 0.6733\n",
      "[404/1762] D loss: 1.4081, G loss: 0.7073\n",
      "[484/1762] D loss: 1.4150, G loss: 0.7125\n",
      "[564/1762] D loss: 1.4319, G loss: 0.7585\n",
      "[644/1762] D loss: 1.3886, G loss: 0.7137\n",
      "[724/1762] D loss: 1.3937, G loss: 0.6881\n",
      "[804/1762] D loss: 1.3885, G loss: 0.7050\n",
      "[884/1762] D loss: 1.3939, G loss: 0.6784\n",
      "[964/1762] D loss: 1.3970, G loss: 0.6898\n",
      "[1044/1762] D loss: 1.3955, G loss: 0.7158\n",
      "[1124/1762] D loss: 0.9841, G loss: 0.9193\n",
      "[1204/1762] D loss: 1.3391, G loss: 0.9011\n",
      "[1284/1762] D loss: 1.8106, G loss: 1.8423\n",
      "[1364/1762] D loss: 1.3981, G loss: 0.6923\n",
      "[1444/1762] D loss: 1.0550, G loss: 0.9288\n",
      "[1524/1762] D loss: 1.3374, G loss: 0.8227\n",
      "[1604/1762] D loss: 1.3983, G loss: 0.7005\n",
      "[1684/1762] D loss: 1.3346, G loss: 1.2375\n",
      "[1762/1762] D loss: 1.5177, G loss: 0.8952\n",
      "train error: \n",
      " D loss: 1.556293, G loss: 0.504050, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.543880, G loss: 0.508954, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4114, G loss: 0.6821\n",
      "[84/1762] D loss: 1.3923, G loss: 0.6930\n",
      "[164/1762] D loss: 1.3528, G loss: 0.7133\n",
      "[244/1762] D loss: 1.4163, G loss: 0.7132\n",
      "[324/1762] D loss: 1.4079, G loss: 0.6806\n",
      "[404/1762] D loss: 1.3984, G loss: 0.7036\n",
      "[484/1762] D loss: 1.3980, G loss: 0.7018\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6874\n",
      "[644/1762] D loss: 1.4076, G loss: 0.7314\n",
      "[724/1762] D loss: 0.7235, G loss: 1.3034\n",
      "[804/1762] D loss: 1.3391, G loss: 1.2735\n",
      "[884/1762] D loss: 1.3431, G loss: 0.7136\n",
      "[964/1762] D loss: 1.4099, G loss: 0.6647\n",
      "[1044/1762] D loss: 1.2216, G loss: 1.2984\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6903\n",
      "[1204/1762] D loss: 1.3957, G loss: 0.6968\n",
      "[1284/1762] D loss: 1.6373, G loss: 0.7302\n",
      "[1364/1762] D loss: 1.4054, G loss: 0.6500\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6756\n",
      "[1524/1762] D loss: 1.0028, G loss: 1.0248\n",
      "[1604/1762] D loss: 1.4518, G loss: 0.7190\n",
      "[1684/1762] D loss: 0.7177, G loss: 1.2860\n",
      "[1762/1762] D loss: 1.6602, G loss: 1.9348\n",
      "train error: \n",
      " D loss: 1.763768, G loss: 0.404730, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.746249, G loss: 0.421527, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5747, G loss: 0.6898\n",
      "[84/1762] D loss: 0.7739, G loss: 1.2218\n",
      "[164/1762] D loss: 1.3849, G loss: 0.6767\n",
      "[244/1762] D loss: 1.1170, G loss: 1.2400\n",
      "[324/1762] D loss: 1.2744, G loss: 0.8933\n",
      "[404/1762] D loss: 1.4097, G loss: 0.6928\n",
      "[484/1762] D loss: 0.9330, G loss: 0.9660\n",
      "[564/1762] D loss: 0.7208, G loss: 1.2334\n",
      "[644/1762] D loss: 1.3095, G loss: 0.8563\n",
      "[724/1762] D loss: 0.9156, G loss: 1.3082\n",
      "[804/1762] D loss: 1.4478, G loss: 0.6740\n",
      "[884/1762] D loss: 1.3320, G loss: 0.7988\n",
      "[964/1762] D loss: 0.6130, G loss: 1.5299\n",
      "[1044/1762] D loss: 1.3999, G loss: 0.7545\n",
      "[1124/1762] D loss: 1.3671, G loss: 0.7142\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7183\n",
      "[1284/1762] D loss: 1.3916, G loss: 0.7071\n",
      "[1364/1762] D loss: 1.4129, G loss: 0.6282\n",
      "[1444/1762] D loss: 1.4259, G loss: 0.7300\n",
      "[1524/1762] D loss: 1.3778, G loss: 0.7099\n",
      "[1604/1762] D loss: 1.4205, G loss: 0.6726\n",
      "[1684/1762] D loss: 1.4135, G loss: 0.6782\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6904\n",
      "train error: \n",
      " D loss: 1.376744, G loss: 0.674569, D accuracy: 52.1%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368066, G loss: 0.665411, D accuracy: 52.3%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958, G loss: 0.7135\n",
      "[84/1762] D loss: 1.5019, G loss: 0.6462\n",
      "[164/1762] D loss: 1.3990, G loss: 1.3404\n",
      "[244/1762] D loss: 1.3863, G loss: 0.7027\n",
      "[324/1762] D loss: 1.4030, G loss: 0.7018\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6927\n",
      "[484/1762] D loss: 1.3991, G loss: 0.6731\n",
      "[564/1762] D loss: 1.4114, G loss: 0.6940\n",
      "[644/1762] D loss: 0.7867, G loss: 1.1374\n",
      "[724/1762] D loss: 1.4045, G loss: 0.7162\n",
      "[804/1762] D loss: 0.9351, G loss: 0.9514\n",
      "[884/1762] D loss: 1.8046, G loss: 0.7299\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6808\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7182\n",
      "[1124/1762] D loss: 1.2138, G loss: 0.8194\n",
      "[1204/1762] D loss: 1.4227, G loss: 0.7720\n",
      "[1284/1762] D loss: 0.5236, G loss: 1.7401\n",
      "[1364/1762] D loss: 1.3994, G loss: 0.6908\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.6625\n",
      "[1524/1762] D loss: 1.3594, G loss: 0.7332\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7093\n",
      "[1684/1762] D loss: 0.6738, G loss: 1.2832\n",
      "[1762/1762] D loss: 1.3757, G loss: 0.7266\n",
      "train error: \n",
      " D loss: 1.384680, G loss: 0.566939, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374570, G loss: 0.569192, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.7115\n",
      "[84/1762] D loss: 1.3978, G loss: 0.6817\n",
      "[164/1762] D loss: 0.9361, G loss: 0.9858\n",
      "[244/1762] D loss: 1.4195, G loss: 0.7009\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6887\n",
      "[404/1762] D loss: 1.3903, G loss: 0.7114\n",
      "[484/1762] D loss: 1.0505, G loss: 0.8322\n",
      "[564/1762] D loss: 1.4610, G loss: 0.7378\n",
      "[644/1762] D loss: 1.3930, G loss: 0.6998\n",
      "[724/1762] D loss: 1.3951, G loss: 0.6504\n",
      "[804/1762] D loss: 0.7717, G loss: 1.2278\n",
      "[884/1762] D loss: 2.1163, G loss: 1.2370\n",
      "[964/1762] D loss: 1.3664, G loss: 0.6982\n",
      "[1044/1762] D loss: 1.3936, G loss: 0.6789\n",
      "[1124/1762] D loss: 1.3937, G loss: 0.6900\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6979\n",
      "[1284/1762] D loss: 1.4008, G loss: 0.6959\n",
      "[1364/1762] D loss: 1.4658, G loss: 0.6615\n",
      "[1444/1762] D loss: 1.3999, G loss: 0.6775\n",
      "[1524/1762] D loss: 1.4209, G loss: 0.6948\n",
      "[1604/1762] D loss: 1.2331, G loss: 0.9342\n",
      "[1684/1762] D loss: 1.3962, G loss: 0.7089\n",
      "[1762/1762] D loss: 0.7907, G loss: 1.8289\n",
      "train error: \n",
      " D loss: 1.355359, G loss: 0.889089, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341142, G loss: 0.922573, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9848, G loss: 1.0619\n",
      "[84/1762] D loss: 1.3859, G loss: 0.6783\n",
      "[164/1762] D loss: 1.6795, G loss: 0.7869\n",
      "[244/1762] D loss: 1.3807, G loss: 0.7031\n",
      "[324/1762] D loss: 0.6129, G loss: 1.3162\n",
      "[404/1762] D loss: 1.3915, G loss: 0.6850\n",
      "[484/1762] D loss: 1.4047, G loss: 0.6746\n",
      "[564/1762] D loss: 1.2620, G loss: 0.7073\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7284\n",
      "[724/1762] D loss: 1.4079, G loss: 0.6733\n",
      "[804/1762] D loss: 1.4006, G loss: 0.6889\n",
      "[884/1762] D loss: 1.4184, G loss: 0.7330\n",
      "[964/1762] D loss: 1.4108, G loss: 0.7102\n",
      "[1044/1762] D loss: 1.4010, G loss: 0.7446\n",
      "[1124/1762] D loss: 1.3955, G loss: 0.6703\n",
      "[1204/1762] D loss: 1.4033, G loss: 0.6643\n",
      "[1284/1762] D loss: 1.3984, G loss: 0.6915\n",
      "[1364/1762] D loss: 1.3963, G loss: 0.7288\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.6889\n",
      "[1524/1762] D loss: 1.4090, G loss: 0.6688\n",
      "[1604/1762] D loss: 1.3920, G loss: 0.7083\n",
      "[1684/1762] D loss: 1.6268, G loss: 0.7125\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6915\n",
      "train error: \n",
      " D loss: 1.380037, G loss: 0.832446, D accuracy: 51.9%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349381, G loss: 0.852306, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3907, G loss: 0.6865\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7459\n",
      "[164/1762] D loss: 1.3889, G loss: 0.6961\n",
      "[244/1762] D loss: 1.4243, G loss: 0.7238\n",
      "[324/1762] D loss: 1.4095, G loss: 0.6862\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7002\n",
      "[484/1762] D loss: 1.4227, G loss: 0.7226\n",
      "[564/1762] D loss: 1.3902, G loss: 0.6899\n",
      "[644/1762] D loss: 1.4716, G loss: 0.7006\n",
      "[724/1762] D loss: 0.3520, G loss: 1.6148\n",
      "[804/1762] D loss: 0.4513, G loss: 1.6040\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6902\n",
      "[964/1762] D loss: 1.4072, G loss: 0.7257\n",
      "[1044/1762] D loss: 1.4021, G loss: 0.7007\n",
      "[1124/1762] D loss: 0.6516, G loss: 1.3633\n",
      "[1204/1762] D loss: 1.4009, G loss: 0.7019\n",
      "[1284/1762] D loss: 0.5812, G loss: 1.3271\n",
      "[1364/1762] D loss: 1.8483, G loss: 0.9126\n",
      "[1444/1762] D loss: 1.3967, G loss: 0.7243\n",
      "[1524/1762] D loss: 1.4145, G loss: 0.7150\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.7073\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.6433\n",
      "[1762/1762] D loss: 1.3980, G loss: 0.7122\n",
      "train error: \n",
      " D loss: 1.362338, G loss: 0.751240, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340489, G loss: 0.765884, D accuracy: 52.4%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3986, G loss: 0.7363\n",
      "[84/1762] D loss: 1.1324, G loss: 0.8247\n",
      "[164/1762] D loss: 0.7912, G loss: 1.4326\n",
      "[244/1762] D loss: 1.3815, G loss: 0.7037\n",
      "[324/1762] D loss: 1.4165, G loss: 0.7106\n",
      "[404/1762] D loss: 1.4850, G loss: 0.7040\n",
      "[484/1762] D loss: 1.4423, G loss: 0.7358\n",
      "[564/1762] D loss: 1.3960, G loss: 0.6968\n",
      "[644/1762] D loss: 1.2098, G loss: 0.9933\n",
      "[724/1762] D loss: 1.3934, G loss: 0.6943\n",
      "[804/1762] D loss: 1.3878, G loss: 0.6969\n",
      "[884/1762] D loss: 1.4446, G loss: 0.7700\n",
      "[964/1762] D loss: 0.6176, G loss: 1.3760\n",
      "[1044/1762] D loss: 1.1592, G loss: 0.8977\n",
      "[1124/1762] D loss: 1.3597, G loss: 0.7068\n",
      "[1204/1762] D loss: 1.4022, G loss: 0.6717\n",
      "[1284/1762] D loss: 1.3973, G loss: 0.7574\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.7066\n",
      "[1444/1762] D loss: 1.0431, G loss: 0.9465\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7163\n",
      "[1604/1762] D loss: 1.3497, G loss: 0.8451\n",
      "[1684/1762] D loss: 1.2182, G loss: 0.8130\n",
      "[1762/1762] D loss: 0.2590, G loss: 1.9391\n",
      "train error: \n",
      " D loss: 1.372144, G loss: 0.834875, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335740, G loss: 0.866447, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2447, G loss: 0.7510\n",
      "[84/1762] D loss: 1.4438, G loss: 0.6707\n",
      "[164/1762] D loss: 1.4045, G loss: 0.7182\n",
      "[244/1762] D loss: 1.3996, G loss: 0.7163\n",
      "[324/1762] D loss: 1.3938, G loss: 0.6703\n",
      "[404/1762] D loss: 1.3934, G loss: 0.7377\n",
      "[484/1762] D loss: 1.3970, G loss: 0.6722\n",
      "[564/1762] D loss: 1.4255, G loss: 0.7722\n",
      "[644/1762] D loss: 0.9904, G loss: 1.3731\n",
      "[724/1762] D loss: 1.4077, G loss: 0.7191\n",
      "[804/1762] D loss: 1.3933, G loss: 0.6438\n",
      "[884/1762] D loss: 1.5562, G loss: 0.7930\n",
      "[964/1762] D loss: 1.3943, G loss: 0.7528\n",
      "[1044/1762] D loss: 1.4005, G loss: 0.7112\n",
      "[1124/1762] D loss: 1.4030, G loss: 0.6971\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.7545\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6801\n",
      "[1364/1762] D loss: 0.7208, G loss: 1.4763\n",
      "[1444/1762] D loss: 1.3904, G loss: 0.6676\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.6713\n",
      "[1604/1762] D loss: 1.4100, G loss: 0.6619\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6957\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.6915\n",
      "train error: \n",
      " D loss: 1.341568, G loss: 0.799221, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320897, G loss: 0.821447, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.7100\n",
      "[84/1762] D loss: 1.4375, G loss: 0.5989\n",
      "[164/1762] D loss: 1.3903, G loss: 0.6814\n",
      "[244/1762] D loss: 1.3957, G loss: 0.6953\n",
      "[324/1762] D loss: 1.0825, G loss: 0.8347\n",
      "[404/1762] D loss: 0.5974, G loss: 1.2648\n",
      "[484/1762] D loss: 1.3904, G loss: 0.6742\n",
      "[564/1762] D loss: 1.4023, G loss: 0.7173\n",
      "[644/1762] D loss: 1.8071, G loss: 0.7071\n",
      "[724/1762] D loss: 1.4113, G loss: 0.7606\n",
      "[804/1762] D loss: 1.3898, G loss: 0.6695\n",
      "[884/1762] D loss: 0.9508, G loss: 0.8728\n",
      "[964/1762] D loss: 1.4951, G loss: 0.7356\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.7072\n",
      "[1124/1762] D loss: 1.2143, G loss: 0.9218\n",
      "[1204/1762] D loss: 1.4244, G loss: 0.6718\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.6845\n",
      "[1364/1762] D loss: 0.7328, G loss: 1.0102\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.7155\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6999\n",
      "[1604/1762] D loss: 1.4042, G loss: 0.6421\n",
      "[1684/1762] D loss: 1.3970, G loss: 0.6856\n",
      "[1762/1762] D loss: 1.3927, G loss: 0.7261\n",
      "train error: \n",
      " D loss: 1.361655, G loss: 0.753938, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351954, G loss: 0.763343, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2541, G loss: 0.7671\n",
      "[84/1762] D loss: 1.3941, G loss: 0.7318\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6789\n",
      "[244/1762] D loss: 1.3822, G loss: 0.7183\n",
      "[324/1762] D loss: 1.3980, G loss: 0.7525\n",
      "[404/1762] D loss: 0.5410, G loss: 1.2385\n",
      "[484/1762] D loss: 1.3820, G loss: 0.7213\n",
      "[564/1762] D loss: 1.4029, G loss: 0.7476\n",
      "[644/1762] D loss: 1.5345, G loss: 0.7965\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6932\n",
      "[804/1762] D loss: 1.3167, G loss: 0.8945\n",
      "[884/1762] D loss: 1.4724, G loss: 0.8719\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6642\n",
      "[1044/1762] D loss: 1.4190, G loss: 0.6302\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6781\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.7270\n",
      "[1284/1762] D loss: 1.3920, G loss: 0.7057\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6801\n",
      "[1444/1762] D loss: 1.3854, G loss: 0.7332\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.7098\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7103\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.7238\n",
      "[1762/1762] D loss: 1.3956, G loss: 0.7132\n",
      "train error: \n",
      " D loss: 1.352802, G loss: 0.756839, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338827, G loss: 0.772221, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6468, G loss: 1.1369\n",
      "[84/1762] D loss: 1.3924, G loss: 0.6678\n",
      "[164/1762] D loss: 1.4544, G loss: 0.8430\n",
      "[244/1762] D loss: 1.3813, G loss: 0.7510\n",
      "[324/1762] D loss: 1.3989, G loss: 0.6712\n",
      "[404/1762] D loss: 1.3909, G loss: 0.6760\n",
      "[484/1762] D loss: 1.4104, G loss: 0.7849\n",
      "[564/1762] D loss: 1.3892, G loss: 0.6825\n",
      "[644/1762] D loss: 1.3912, G loss: 0.7161\n",
      "[724/1762] D loss: 1.4244, G loss: 0.8052\n",
      "[804/1762] D loss: 1.4134, G loss: 0.7808\n",
      "[884/1762] D loss: 1.4389, G loss: 0.7692\n",
      "[964/1762] D loss: 1.4048, G loss: 0.7460\n",
      "[1044/1762] D loss: 1.4029, G loss: 0.6366\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.6563\n",
      "[1204/1762] D loss: 1.3483, G loss: 0.7453\n",
      "[1284/1762] D loss: 1.3997, G loss: 0.6869\n",
      "[1364/1762] D loss: 1.4129, G loss: 0.7491\n",
      "[1444/1762] D loss: 1.4016, G loss: 0.7086\n",
      "[1524/1762] D loss: 1.3998, G loss: 0.7522\n",
      "[1604/1762] D loss: 1.3982, G loss: 0.7213\n",
      "[1684/1762] D loss: 1.3971, G loss: 0.7004\n",
      "[1762/1762] D loss: 1.4093, G loss: 0.6992\n",
      "train error: \n",
      " D loss: 1.361643, G loss: 0.676366, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346886, G loss: 0.684383, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4038, G loss: 0.7289\n",
      "[84/1762] D loss: 1.3913, G loss: 0.7193\n",
      "[164/1762] D loss: 1.3953, G loss: 0.7106\n",
      "[244/1762] D loss: 1.3954, G loss: 0.7244\n",
      "[324/1762] D loss: 1.3930, G loss: 0.6683\n",
      "[404/1762] D loss: 1.3973, G loss: 0.7217\n",
      "[484/1762] D loss: 1.3839, G loss: 0.6986\n",
      "[564/1762] D loss: 1.3915, G loss: 0.7582\n",
      "[644/1762] D loss: 1.3948, G loss: 0.6760\n",
      "[724/1762] D loss: 1.3443, G loss: 0.7740\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7131\n",
      "[884/1762] D loss: 0.6143, G loss: 1.2603\n",
      "[964/1762] D loss: 1.4164, G loss: 0.7271\n",
      "[1044/1762] D loss: 1.3753, G loss: 0.5513\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.6989\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6799\n",
      "[1284/1762] D loss: 1.3898, G loss: 0.7344\n",
      "[1364/1762] D loss: 1.3932, G loss: 0.6802\n",
      "[1444/1762] D loss: 1.3970, G loss: 0.7534\n",
      "[1524/1762] D loss: 1.3970, G loss: 0.6597\n",
      "[1604/1762] D loss: 0.8112, G loss: 1.1067\n",
      "[1684/1762] D loss: 1.3704, G loss: 1.0910\n",
      "[1762/1762] D loss: 1.4003, G loss: 0.7546\n",
      "train error: \n",
      " D loss: 1.367557, G loss: 0.782068, D accuracy: 51.8%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357596, G loss: 0.803704, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3824, G loss: 0.7210\n",
      "[84/1762] D loss: 1.3948, G loss: 0.7151\n",
      "[164/1762] D loss: 1.4038, G loss: 0.6697\n",
      "[244/1762] D loss: 1.0896, G loss: 1.3616\n",
      "[324/1762] D loss: 1.4167, G loss: 0.7976\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6957\n",
      "[484/1762] D loss: 1.3988, G loss: 0.6480\n",
      "[564/1762] D loss: 1.4073, G loss: 0.6953\n",
      "[644/1762] D loss: 1.2869, G loss: 0.8174\n",
      "[724/1762] D loss: 1.4657, G loss: 0.8031\n",
      "[804/1762] D loss: 1.3925, G loss: 0.6535\n",
      "[884/1762] D loss: 1.3908, G loss: 0.6802\n",
      "[964/1762] D loss: 1.3888, G loss: 0.6842\n",
      "[1044/1762] D loss: 1.3997, G loss: 0.7306\n",
      "[1124/1762] D loss: 1.3855, G loss: 0.6893\n",
      "[1204/1762] D loss: 0.7920, G loss: 1.0528\n",
      "[1284/1762] D loss: 1.3920, G loss: 0.6990\n",
      "[1364/1762] D loss: 1.4059, G loss: 0.7908\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6727\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.6962\n",
      "[1604/1762] D loss: 0.7800, G loss: 0.9941\n",
      "[1684/1762] D loss: 1.3860, G loss: 0.6888\n",
      "[1762/1762] D loss: 0.5387, G loss: 1.6918\n",
      "train error: \n",
      " D loss: 1.434042, G loss: 0.593436, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410690, G loss: 0.620928, D accuracy: 51.8%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5280, G loss: 1.0478\n",
      "[84/1762] D loss: 1.2697, G loss: 0.8109\n",
      "[164/1762] D loss: 1.0123, G loss: 0.7795\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6846\n",
      "[324/1762] D loss: 1.6045, G loss: 0.8554\n",
      "[404/1762] D loss: 1.3955, G loss: 0.7363\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6897\n",
      "[564/1762] D loss: 1.3950, G loss: 0.7098\n",
      "[644/1762] D loss: 1.3942, G loss: 0.6991\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6848\n",
      "[804/1762] D loss: 1.3917, G loss: 0.7145\n",
      "[884/1762] D loss: 1.0301, G loss: 1.3527\n",
      "[964/1762] D loss: 1.3915, G loss: 0.6773\n",
      "[1044/1762] D loss: 1.0500, G loss: 0.9536\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.6709\n",
      "[1204/1762] D loss: 1.4199, G loss: 0.8331\n",
      "[1284/1762] D loss: 1.3945, G loss: 0.7294\n",
      "[1364/1762] D loss: 1.3817, G loss: 0.7071\n",
      "[1444/1762] D loss: 1.4783, G loss: 0.7222\n",
      "[1524/1762] D loss: 1.4008, G loss: 0.7349\n",
      "[1604/1762] D loss: 1.4331, G loss: 0.6394\n",
      "[1684/1762] D loss: 1.1414, G loss: 0.9863\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.7278\n",
      "train error: \n",
      " D loss: 1.371438, G loss: 0.828190, D accuracy: 51.8%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334067, G loss: 0.850281, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4333, G loss: 0.7002\n",
      "[84/1762] D loss: 1.3981, G loss: 0.7149\n",
      "[164/1762] D loss: 1.4218, G loss: 0.7027\n",
      "[244/1762] D loss: 1.3639, G loss: 0.7021\n",
      "[324/1762] D loss: 1.3911, G loss: 0.7032\n",
      "[404/1762] D loss: 1.3956, G loss: 0.6985\n",
      "[484/1762] D loss: 0.8167, G loss: 0.9809\n",
      "[564/1762] D loss: 0.6411, G loss: 1.1412\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6881\n",
      "[724/1762] D loss: 1.4058, G loss: 0.7303\n",
      "[804/1762] D loss: 1.4089, G loss: 0.6464\n",
      "[884/1762] D loss: 1.3839, G loss: 0.6962\n",
      "[964/1762] D loss: 1.4084, G loss: 0.7428\n",
      "[1044/1762] D loss: 1.4037, G loss: 0.6563\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.7081\n",
      "[1204/1762] D loss: 1.3848, G loss: 0.7050\n",
      "[1284/1762] D loss: 1.4059, G loss: 0.7422\n",
      "[1364/1762] D loss: 1.4718, G loss: 0.8291\n",
      "[1444/1762] D loss: 1.3957, G loss: 0.7292\n",
      "[1524/1762] D loss: 1.3777, G loss: 0.6907\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.6937\n",
      "[1684/1762] D loss: 1.0699, G loss: 0.9295\n",
      "[1762/1762] D loss: 2.5030, G loss: 1.0008\n",
      "train error: \n",
      " D loss: 1.384826, G loss: 0.733724, D accuracy: 51.8%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367727, G loss: 0.751192, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4026, G loss: 0.7830\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7173\n",
      "[164/1762] D loss: 0.9963, G loss: 0.8598\n",
      "[244/1762] D loss: 1.3893, G loss: 0.6903\n",
      "[324/1762] D loss: 1.3920, G loss: 0.7074\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6854\n",
      "[484/1762] D loss: 1.3897, G loss: 0.7081\n",
      "[564/1762] D loss: 0.8209, G loss: 0.9718\n",
      "[644/1762] D loss: 1.3919, G loss: 0.7019\n",
      "[724/1762] D loss: 1.4033, G loss: 0.7045\n",
      "[804/1762] D loss: 1.3789, G loss: 0.7261\n",
      "[884/1762] D loss: 1.3104, G loss: 0.7704\n",
      "[964/1762] D loss: 1.3928, G loss: 0.6645\n",
      "[1044/1762] D loss: 1.4414, G loss: 0.8074\n",
      "[1124/1762] D loss: 1.3909, G loss: 0.7127\n",
      "[1204/1762] D loss: 1.3902, G loss: 0.7012\n",
      "[1284/1762] D loss: 2.0505, G loss: 0.9439\n",
      "[1364/1762] D loss: 0.5666, G loss: 1.2543\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.6733\n",
      "[1524/1762] D loss: 1.3897, G loss: 0.6757\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.7056\n",
      "[1684/1762] D loss: 1.3989, G loss: 0.7251\n",
      "[1762/1762] D loss: 1.3981, G loss: 0.7564\n",
      "train error: \n",
      " D loss: 1.372244, G loss: 0.709016, D accuracy: 51.4%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353107, G loss: 0.721233, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5572, G loss: 1.3985\n",
      "[84/1762] D loss: 1.3723, G loss: 0.6982\n",
      "[164/1762] D loss: 1.3998, G loss: 0.7121\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6995\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6945\n",
      "[404/1762] D loss: 1.4020, G loss: 0.6719\n",
      "[484/1762] D loss: 1.3893, G loss: 0.6980\n",
      "[564/1762] D loss: 0.6299, G loss: 1.1793\n",
      "[644/1762] D loss: 1.3930, G loss: 0.7052\n",
      "[724/1762] D loss: 1.3911, G loss: 0.6653\n",
      "[804/1762] D loss: 1.3927, G loss: 0.6693\n",
      "[884/1762] D loss: 1.4181, G loss: 0.7998\n",
      "[964/1762] D loss: 0.7012, G loss: 1.2129\n",
      "[1044/1762] D loss: 1.3977, G loss: 0.6647\n",
      "[1124/1762] D loss: 1.3843, G loss: 0.7468\n",
      "[1204/1762] D loss: 1.3979, G loss: 0.7422\n",
      "[1284/1762] D loss: 1.3898, G loss: 0.6826\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.6863\n",
      "[1444/1762] D loss: 1.5260, G loss: 0.7050\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.6848\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.6640\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.6894\n",
      "[1762/1762] D loss: 1.3923, G loss: 0.7541\n",
      "train error: \n",
      " D loss: 1.379519, G loss: 0.703824, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371895, G loss: 0.705444, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3840, G loss: 0.6752\n",
      "[84/1762] D loss: 1.3934, G loss: 0.6818\n",
      "[164/1762] D loss: 1.3900, G loss: 0.6836\n",
      "[244/1762] D loss: 1.4025, G loss: 0.7475\n",
      "[324/1762] D loss: 1.4005, G loss: 0.6268\n",
      "[404/1762] D loss: 1.3913, G loss: 0.6640\n",
      "[484/1762] D loss: 1.3927, G loss: 0.7012\n",
      "[564/1762] D loss: 0.7452, G loss: 0.9581\n",
      "[644/1762] D loss: 1.4011, G loss: 0.6768\n",
      "[724/1762] D loss: 0.7937, G loss: 0.9888\n",
      "[804/1762] D loss: 1.3857, G loss: 0.7509\n",
      "[884/1762] D loss: 1.2942, G loss: 0.7825\n",
      "[964/1762] D loss: 1.3991, G loss: 0.6833\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.7087\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.7130\n",
      "[1204/1762] D loss: 1.3813, G loss: 0.6044\n",
      "[1284/1762] D loss: 1.4445, G loss: 0.8572\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6809\n",
      "[1444/1762] D loss: 0.9515, G loss: 0.9927\n",
      "[1524/1762] D loss: 0.7289, G loss: 1.1624\n",
      "[1604/1762] D loss: 1.3948, G loss: 0.6361\n",
      "[1684/1762] D loss: 1.4051, G loss: 0.6366\n",
      "[1762/1762] D loss: 1.4120, G loss: 0.6377\n",
      "train error: \n",
      " D loss: 1.355052, G loss: 0.745174, D accuracy: 52.2%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342471, G loss: 0.761095, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4001, G loss: 0.7687\n",
      "[84/1762] D loss: 1.4002, G loss: 0.7268\n",
      "[164/1762] D loss: 1.4122, G loss: 0.6711\n",
      "[244/1762] D loss: 1.4027, G loss: 0.7894\n",
      "[324/1762] D loss: 0.5805, G loss: 1.1100\n",
      "[404/1762] D loss: 1.3934, G loss: 0.7355\n",
      "[484/1762] D loss: 1.3321, G loss: 0.7137\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7067\n",
      "[644/1762] D loss: 1.3926, G loss: 0.6554\n",
      "[724/1762] D loss: 1.4163, G loss: 0.7998\n",
      "[804/1762] D loss: 1.3152, G loss: 0.9568\n",
      "[884/1762] D loss: 0.8909, G loss: 0.8763\n",
      "[964/1762] D loss: 1.3966, G loss: 0.7322\n",
      "[1044/1762] D loss: 1.3996, G loss: 0.7102\n",
      "[1124/1762] D loss: 0.7249, G loss: 1.2125\n",
      "[1204/1762] D loss: 1.4004, G loss: 0.7507\n",
      "[1284/1762] D loss: 0.5917, G loss: 1.2499\n",
      "[1364/1762] D loss: 0.7644, G loss: 0.9588\n",
      "[1444/1762] D loss: 1.4097, G loss: 0.7089\n",
      "[1524/1762] D loss: 1.4218, G loss: 0.7262\n",
      "[1604/1762] D loss: 1.3919, G loss: 0.7073\n",
      "[1684/1762] D loss: 0.5155, G loss: 1.1741\n",
      "[1762/1762] D loss: 1.3964, G loss: 0.7540\n",
      "train error: \n",
      " D loss: 1.349612, G loss: 0.712230, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344470, G loss: 0.714629, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4029, G loss: 0.7665\n",
      "[84/1762] D loss: 0.5060, G loss: 1.1820\n",
      "[164/1762] D loss: 1.4177, G loss: 0.7937\n",
      "[244/1762] D loss: 0.5520, G loss: 1.0773\n",
      "[324/1762] D loss: 1.3960, G loss: 0.7358\n",
      "[404/1762] D loss: 1.4058, G loss: 0.7537\n",
      "[484/1762] D loss: 0.5753, G loss: 1.0684\n",
      "[564/1762] D loss: 1.4075, G loss: 0.7592\n",
      "[644/1762] D loss: 1.4011, G loss: 0.7294\n",
      "[724/1762] D loss: 1.3993, G loss: 0.7152\n",
      "[804/1762] D loss: 1.4121, G loss: 0.7199\n",
      "[884/1762] D loss: 1.4179, G loss: 0.8149\n",
      "[964/1762] D loss: 1.3900, G loss: 0.7168\n",
      "[1044/1762] D loss: 1.3995, G loss: 0.6802\n",
      "[1124/1762] D loss: 0.5348, G loss: 1.2161\n",
      "[1204/1762] D loss: 1.4136, G loss: 0.6992\n",
      "[1284/1762] D loss: 1.8658, G loss: 0.8333\n",
      "[1364/1762] D loss: 1.3837, G loss: 0.7306\n",
      "[1444/1762] D loss: 1.4054, G loss: 0.6590\n",
      "[1524/1762] D loss: 1.1867, G loss: 0.8060\n",
      "[1604/1762] D loss: 0.9236, G loss: 1.0317\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.7172\n",
      "[1762/1762] D loss: 1.0504, G loss: 1.1002\n",
      "train error: \n",
      " D loss: 1.381891, G loss: 0.811779, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359915, G loss: 0.844122, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1332, G loss: 0.9515\n",
      "[84/1762] D loss: 1.3908, G loss: 0.6847\n",
      "[164/1762] D loss: 1.5812, G loss: 0.8602\n",
      "[244/1762] D loss: 1.3910, G loss: 0.6742\n",
      "[324/1762] D loss: 1.3930, G loss: 0.7152\n",
      "[404/1762] D loss: 1.3998, G loss: 0.7704\n",
      "[484/1762] D loss: 1.3975, G loss: 0.6543\n",
      "[564/1762] D loss: 1.4001, G loss: 0.7716\n",
      "[644/1762] D loss: 1.3844, G loss: 0.7328\n",
      "[724/1762] D loss: 1.3968, G loss: 0.7388\n",
      "[804/1762] D loss: 1.3936, G loss: 0.7214\n",
      "[884/1762] D loss: 1.4062, G loss: 0.7806\n",
      "[964/1762] D loss: 1.3900, G loss: 0.7052\n",
      "[1044/1762] D loss: 0.8688, G loss: 0.8280\n",
      "[1124/1762] D loss: 1.0347, G loss: 0.9147\n",
      "[1204/1762] D loss: 1.3648, G loss: 0.7457\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.6347\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.7109\n",
      "[1444/1762] D loss: 1.3934, G loss: 0.7337\n",
      "[1524/1762] D loss: 1.3718, G loss: 0.7212\n",
      "[1604/1762] D loss: 1.3846, G loss: 0.7132\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.7292\n",
      "[1762/1762] D loss: 1.4023, G loss: 0.7464\n",
      "train error: \n",
      " D loss: 1.386988, G loss: 0.789144, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379217, G loss: 0.806304, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4571, G loss: 0.9848\n",
      "[84/1762] D loss: 1.4118, G loss: 0.7908\n",
      "[164/1762] D loss: 1.3909, G loss: 0.6691\n",
      "[244/1762] D loss: 1.4151, G loss: 0.8159\n",
      "[324/1762] D loss: 1.4279, G loss: 0.8206\n",
      "[404/1762] D loss: 1.3952, G loss: 0.7449\n",
      "[484/1762] D loss: 1.3873, G loss: 0.6818\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6882\n",
      "[644/1762] D loss: 1.3957, G loss: 0.7487\n",
      "[724/1762] D loss: 1.3991, G loss: 0.7312\n",
      "[804/1762] D loss: 1.4019, G loss: 0.7861\n",
      "[884/1762] D loss: 1.3937, G loss: 0.7004\n",
      "[964/1762] D loss: 1.3982, G loss: 0.7664\n",
      "[1044/1762] D loss: 1.3928, G loss: 0.6662\n",
      "[1124/1762] D loss: 1.2349, G loss: 0.7527\n",
      "[1204/1762] D loss: 1.3905, G loss: 0.7249\n",
      "[1284/1762] D loss: 1.4082, G loss: 0.8003\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.6775\n",
      "[1444/1762] D loss: 1.3944, G loss: 0.6527\n",
      "[1524/1762] D loss: 1.3572, G loss: 0.8610\n",
      "[1604/1762] D loss: 1.1566, G loss: 0.8958\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.6784\n",
      "[1762/1762] D loss: 1.3589, G loss: 0.7061\n",
      "train error: \n",
      " D loss: 1.380600, G loss: 0.714629, D accuracy: 51.2%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363914, G loss: 0.722655, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3985, G loss: 0.7596\n",
      "[84/1762] D loss: 1.3896, G loss: 0.6727\n",
      "[164/1762] D loss: 1.3986, G loss: 0.6316\n",
      "[244/1762] D loss: 1.3902, G loss: 0.6594\n",
      "[324/1762] D loss: 1.3948, G loss: 0.6583\n",
      "[404/1762] D loss: 1.4059, G loss: 0.7141\n",
      "[484/1762] D loss: 1.3773, G loss: 0.7059\n",
      "[564/1762] D loss: 1.9184, G loss: 0.7664\n",
      "[644/1762] D loss: 1.4246, G loss: 0.7803\n",
      "[724/1762] D loss: 1.3916, G loss: 0.7292\n",
      "[804/1762] D loss: 1.0236, G loss: 0.8334\n",
      "[884/1762] D loss: 1.3888, G loss: 0.6935\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6554\n",
      "[1044/1762] D loss: 1.4222, G loss: 0.7852\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6846\n",
      "[1204/1762] D loss: 1.4120, G loss: 0.7612\n",
      "[1284/1762] D loss: 1.3137, G loss: 0.7412\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.6986\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.6633\n",
      "[1524/1762] D loss: 1.3857, G loss: 0.6804\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.7149\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6897\n",
      "[1762/1762] D loss: 1.2636, G loss: 0.7908\n",
      "train error: \n",
      " D loss: 1.375840, G loss: 0.757861, D accuracy: 51.2%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368375, G loss: 0.768580, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6650\n",
      "[84/1762] D loss: 1.3901, G loss: 0.6550\n",
      "[164/1762] D loss: 1.3954, G loss: 0.6278\n",
      "[244/1762] D loss: 1.4309, G loss: 0.8547\n",
      "[324/1762] D loss: 1.3817, G loss: 0.6880\n",
      "[404/1762] D loss: 1.4150, G loss: 0.7194\n",
      "[484/1762] D loss: 1.3923, G loss: 0.6527\n",
      "[564/1762] D loss: 1.3927, G loss: 0.7425\n",
      "[644/1762] D loss: 0.6094, G loss: 1.0973\n",
      "[724/1762] D loss: 1.4006, G loss: 0.7863\n",
      "[804/1762] D loss: 1.3997, G loss: 0.7887\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6740\n",
      "[964/1762] D loss: 1.4039, G loss: 0.7877\n",
      "[1044/1762] D loss: 1.4174, G loss: 0.8442\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.6662\n",
      "[1204/1762] D loss: 1.4062, G loss: 0.6589\n",
      "[1284/1762] D loss: 1.2327, G loss: 0.8095\n",
      "[1364/1762] D loss: 1.3939, G loss: 0.6864\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.6739\n",
      "[1524/1762] D loss: 0.5377, G loss: 1.2087\n",
      "[1604/1762] D loss: 1.4058, G loss: 0.6872\n",
      "[1684/1762] D loss: 1.4028, G loss: 0.7222\n",
      "[1762/1762] D loss: 1.3930, G loss: 0.7528\n",
      "train error: \n",
      " D loss: 1.385601, G loss: 0.876623, D accuracy: 51.1%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369239, G loss: 0.914116, D accuracy: 52.4%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3961, G loss: 0.6892\n",
      "[84/1762] D loss: 1.4015, G loss: 0.7424\n",
      "[164/1762] D loss: 1.4050, G loss: 0.6304\n",
      "[244/1762] D loss: 1.3897, G loss: 0.7322\n",
      "[324/1762] D loss: 1.7403, G loss: 0.7459\n",
      "[404/1762] D loss: 1.3888, G loss: 0.7269\n",
      "[484/1762] D loss: 1.3942, G loss: 0.6656\n",
      "[564/1762] D loss: 1.4073, G loss: 0.6720\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6974\n",
      "[724/1762] D loss: 1.3898, G loss: 0.7404\n",
      "[804/1762] D loss: 1.3929, G loss: 0.6589\n",
      "[884/1762] D loss: 1.3919, G loss: 0.6969\n",
      "[964/1762] D loss: 1.4043, G loss: 0.7673\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.6556\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.6643\n",
      "[1204/1762] D loss: 1.9955, G loss: 0.7239\n",
      "[1284/1762] D loss: 1.3962, G loss: 0.7293\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6862\n",
      "[1444/1762] D loss: 1.3903, G loss: 0.6574\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.6661\n",
      "[1604/1762] D loss: 1.3853, G loss: 0.7724\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.6511\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.6484\n",
      "train error: \n",
      " D loss: 1.373944, G loss: 0.713731, D accuracy: 51.7%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358219, G loss: 0.731861, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 87.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3840, G loss: 0.7339\n",
      "[84/1762] D loss: 0.9234, G loss: 1.0449\n",
      "[164/1762] D loss: 0.5513, G loss: 1.5440\n",
      "[244/1762] D loss: 0.4893, G loss: 2.0997\n",
      "[324/1762] D loss: 0.6942, G loss: 3.2256\n",
      "[404/1762] D loss: 0.7540, G loss: 0.3305\n",
      "[484/1762] D loss: 1.2589, G loss: 0.1877\n",
      "[564/1762] D loss: 1.0526, G loss: 1.9688\n",
      "[644/1762] D loss: 1.2616, G loss: 2.4122\n",
      "[724/1762] D loss: 1.0923, G loss: 0.7718\n",
      "[804/1762] D loss: 1.1145, G loss: 0.7640\n",
      "[884/1762] D loss: 1.2429, G loss: 0.8569\n",
      "[964/1762] D loss: 1.2428, G loss: 1.1312\n",
      "[1044/1762] D loss: 1.0624, G loss: 0.7190\n",
      "[1124/1762] D loss: 1.1342, G loss: 0.7429\n",
      "[1204/1762] D loss: 1.4166, G loss: 1.0863\n",
      "[1284/1762] D loss: 1.5129, G loss: 1.0934\n",
      "[1364/1762] D loss: 1.1700, G loss: 0.7698\n",
      "[1444/1762] D loss: 1.3495, G loss: 0.5784\n",
      "[1524/1762] D loss: 1.2311, G loss: 0.6576\n",
      "[1604/1762] D loss: 1.7324, G loss: 1.7311\n",
      "[1684/1762] D loss: 1.3722, G loss: 0.6728\n",
      "[1762/1762] D loss: 1.3759, G loss: 0.5165\n",
      "train error: \n",
      " D loss: 1.335322, G loss: 0.620876, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327022, G loss: 0.621696, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2185, G loss: 0.8409\n",
      "[84/1762] D loss: 1.1349, G loss: 0.9551\n",
      "[164/1762] D loss: 1.4348, G loss: 0.3422\n",
      "[244/1762] D loss: 1.4301, G loss: 0.8270\n",
      "[324/1762] D loss: 1.2455, G loss: 0.6348\n",
      "[404/1762] D loss: 1.4121, G loss: 0.9007\n",
      "[484/1762] D loss: 1.4350, G loss: 0.5824\n",
      "[564/1762] D loss: 1.1205, G loss: 1.0349\n",
      "[644/1762] D loss: 1.5161, G loss: 0.5371\n",
      "[724/1762] D loss: 1.1552, G loss: 0.8893\n",
      "[804/1762] D loss: 1.3798, G loss: 0.6912\n",
      "[884/1762] D loss: 1.3642, G loss: 0.6097\n",
      "[964/1762] D loss: 1.1398, G loss: 1.0869\n",
      "[1044/1762] D loss: 1.4079, G loss: 0.6375\n",
      "[1124/1762] D loss: 1.3933, G loss: 0.6417\n",
      "[1204/1762] D loss: 1.3979, G loss: 0.7834\n",
      "[1284/1762] D loss: 1.4073, G loss: 0.6481\n",
      "[1364/1762] D loss: 1.4397, G loss: 0.5167\n",
      "[1444/1762] D loss: 1.4759, G loss: 0.4910\n",
      "[1524/1762] D loss: 1.3454, G loss: 0.7408\n",
      "[1604/1762] D loss: 1.4559, G loss: 0.5023\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.6575\n",
      "[1762/1762] D loss: 1.4546, G loss: 0.3711\n",
      "train error: \n",
      " D loss: 1.461005, G loss: 0.416661, D accuracy: 50.8%, cell accuracy: 99.6%, board accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.454841, G loss: 0.417540, D accuracy: 50.3%, cell accuracy: 99.5%, board accuracy: 51.4% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6830, G loss: 1.4798\n",
      "[84/1762] D loss: 1.3784, G loss: 0.7559\n",
      "[164/1762] D loss: 1.1133, G loss: 0.7732\n",
      "[244/1762] D loss: 1.3848, G loss: 0.6377\n",
      "[324/1762] D loss: 1.3803, G loss: 0.8865\n",
      "[404/1762] D loss: 2.0532, G loss: 0.5872\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6980\n",
      "[564/1762] D loss: 1.3918, G loss: 0.6490\n",
      "[644/1762] D loss: 1.3908, G loss: 0.6148\n",
      "[724/1762] D loss: 1.3956, G loss: 0.6644\n",
      "[804/1762] D loss: 1.4091, G loss: 0.7383\n",
      "[884/1762] D loss: 1.3664, G loss: 0.5256\n",
      "[964/1762] D loss: 1.0643, G loss: 1.0436\n",
      "[1044/1762] D loss: 1.0378, G loss: 0.9406\n",
      "[1124/1762] D loss: 1.2145, G loss: 0.8340\n",
      "[1204/1762] D loss: 1.3995, G loss: 0.7954\n",
      "[1284/1762] D loss: 1.4336, G loss: 0.5826\n",
      "[1364/1762] D loss: 1.3680, G loss: 0.9056\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.7095\n",
      "[1524/1762] D loss: 1.3680, G loss: 0.7774\n",
      "[1604/1762] D loss: 0.9411, G loss: 1.0958\n",
      "[1684/1762] D loss: 1.3664, G loss: 0.6038\n",
      "[1762/1762] D loss: 1.4031, G loss: 0.4374\n",
      "train error: \n",
      " D loss: 1.357985, G loss: 0.627737, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346568, G loss: 0.640766, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0068, G loss: 1.2566\n",
      "[84/1762] D loss: 0.9603, G loss: 1.2393\n",
      "[164/1762] D loss: 1.1725, G loss: 0.7747\n",
      "[244/1762] D loss: 1.4115, G loss: 0.5905\n",
      "[324/1762] D loss: 1.4982, G loss: 1.0007\n",
      "[404/1762] D loss: 1.3994, G loss: 0.5941\n",
      "[484/1762] D loss: 1.3848, G loss: 0.7029\n",
      "[564/1762] D loss: 1.3860, G loss: 0.7865\n",
      "[644/1762] D loss: 1.3915, G loss: 0.7045\n",
      "[724/1762] D loss: 0.9353, G loss: 1.3650\n",
      "[804/1762] D loss: 1.3967, G loss: 0.7131\n",
      "[884/1762] D loss: 1.4396, G loss: 0.5755\n",
      "[964/1762] D loss: 1.4661, G loss: 0.5348\n",
      "[1044/1762] D loss: 1.4847, G loss: 0.3638\n",
      "[1124/1762] D loss: 1.2758, G loss: 0.9180\n",
      "[1204/1762] D loss: 1.3954, G loss: 0.6642\n",
      "[1284/1762] D loss: 1.4074, G loss: 0.8344\n",
      "[1364/1762] D loss: 1.2810, G loss: 0.8061\n",
      "[1444/1762] D loss: 1.4544, G loss: 0.8982\n",
      "[1524/1762] D loss: 1.4059, G loss: 0.7366\n",
      "[1604/1762] D loss: 0.4776, G loss: 1.7108\n",
      "[1684/1762] D loss: 1.4245, G loss: 0.6854\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6720\n",
      "train error: \n",
      " D loss: 1.341523, G loss: 0.626133, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321216, G loss: 0.637008, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5869, G loss: 1.6302\n",
      "[84/1762] D loss: 1.4042, G loss: 0.7088\n",
      "[164/1762] D loss: 1.5111, G loss: 0.4847\n",
      "[244/1762] D loss: 1.4224, G loss: 1.0059\n",
      "[324/1762] D loss: 1.3986, G loss: 0.7360\n",
      "[404/1762] D loss: 1.4057, G loss: 0.7318\n",
      "[484/1762] D loss: 1.4117, G loss: 0.6909\n",
      "[564/1762] D loss: 1.4523, G loss: 0.5890\n",
      "[644/1762] D loss: 1.3791, G loss: 0.7032\n",
      "[724/1762] D loss: 0.6154, G loss: 1.4266\n",
      "[804/1762] D loss: 1.3950, G loss: 0.7509\n",
      "[884/1762] D loss: 1.5535, G loss: 0.6872\n",
      "[964/1762] D loss: 1.3972, G loss: 0.7026\n",
      "[1044/1762] D loss: 1.3656, G loss: 0.6795\n",
      "[1124/1762] D loss: 1.3852, G loss: 0.6956\n",
      "[1204/1762] D loss: 1.4043, G loss: 0.7873\n",
      "[1284/1762] D loss: 0.8031, G loss: 1.2796\n",
      "[1364/1762] D loss: 1.4246, G loss: 0.7716\n",
      "[1444/1762] D loss: 2.1403, G loss: 0.9060\n",
      "[1524/1762] D loss: 1.4462, G loss: 0.7415\n",
      "[1604/1762] D loss: 1.3924, G loss: 0.6795\n",
      "[1684/1762] D loss: 1.3242, G loss: 0.8106\n",
      "[1762/1762] D loss: 1.3968, G loss: 0.7933\n",
      "train error: \n",
      " D loss: 1.405777, G loss: 0.852875, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.430526, G loss: 0.851886, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3851, G loss: 0.7853\n",
      "[84/1762] D loss: 1.3742, G loss: 0.6332\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6966\n",
      "[244/1762] D loss: 1.4070, G loss: 0.7094\n",
      "[324/1762] D loss: 1.4609, G loss: 0.7615\n",
      "[404/1762] D loss: 1.4270, G loss: 0.6777\n",
      "[484/1762] D loss: 1.3424, G loss: 0.7272\n",
      "[564/1762] D loss: 1.1252, G loss: 0.9927\n",
      "[644/1762] D loss: 0.9042, G loss: 1.2098\n",
      "[724/1762] D loss: 0.9725, G loss: 1.0505\n",
      "[804/1762] D loss: 1.2632, G loss: 0.9502\n",
      "[884/1762] D loss: 0.8952, G loss: 1.1921\n",
      "[964/1762] D loss: 1.3645, G loss: 0.6861\n",
      "[1044/1762] D loss: 1.3842, G loss: 0.6485\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.6764\n",
      "[1204/1762] D loss: 0.7495, G loss: 1.4782\n",
      "[1284/1762] D loss: 1.5099, G loss: 0.4320\n",
      "[1364/1762] D loss: 1.4237, G loss: 0.8987\n",
      "[1444/1762] D loss: 1.3824, G loss: 0.8683\n",
      "[1524/1762] D loss: 1.4053, G loss: 0.7993\n",
      "[1604/1762] D loss: 1.4633, G loss: 0.8709\n",
      "[1684/1762] D loss: 0.4393, G loss: 1.7711\n",
      "[1762/1762] D loss: 1.4293, G loss: 0.5891\n",
      "train error: \n",
      " D loss: 1.526600, G loss: 0.478838, D accuracy: 49.9%, cell accuracy: 99.6%, board accuracy: 73.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.555251, G loss: 0.483228, D accuracy: 49.1%, cell accuracy: 99.6%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4092, G loss: 0.8075\n",
      "[84/1762] D loss: 1.3167, G loss: 0.8831\n",
      "[164/1762] D loss: 0.7699, G loss: 1.3852\n",
      "[244/1762] D loss: 1.5831, G loss: 0.6359\n",
      "[324/1762] D loss: 1.3749, G loss: 0.7364\n",
      "[404/1762] D loss: 1.4065, G loss: 0.6333\n",
      "[484/1762] D loss: 0.7238, G loss: 1.7364\n",
      "[564/1762] D loss: 1.4906, G loss: 0.5483\n",
      "[644/1762] D loss: 1.4353, G loss: 0.7841\n",
      "[724/1762] D loss: 0.6336, G loss: 1.5579\n",
      "[804/1762] D loss: 0.6969, G loss: 1.6581\n",
      "[884/1762] D loss: 1.5296, G loss: 0.5930\n",
      "[964/1762] D loss: 0.5085, G loss: 1.6431\n",
      "[1044/1762] D loss: 0.4804, G loss: 1.8092\n",
      "[1124/1762] D loss: 1.4186, G loss: 0.5479\n",
      "[1204/1762] D loss: 1.4229, G loss: 0.6658\n",
      "[1284/1762] D loss: 0.4774, G loss: 1.6509\n",
      "[1364/1762] D loss: 0.8803, G loss: 1.6643\n",
      "[1444/1762] D loss: 0.3492, G loss: 1.7888\n",
      "[1524/1762] D loss: 1.4345, G loss: 0.6872\n",
      "[1604/1762] D loss: 1.4041, G loss: 0.6995\n",
      "[1684/1762] D loss: 1.3997, G loss: 0.6948\n",
      "[1762/1762] D loss: 1.3898, G loss: 0.7402\n",
      "train error: \n",
      " D loss: 1.334595, G loss: 0.794933, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321042, G loss: 0.806223, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4174, G loss: 0.6937\n",
      "[84/1762] D loss: 2.0022, G loss: 0.7231\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6206\n",
      "[244/1762] D loss: 1.4014, G loss: 0.7233\n",
      "[324/1762] D loss: 1.4285, G loss: 0.5946\n",
      "[404/1762] D loss: 0.5888, G loss: 1.4256\n",
      "[484/1762] D loss: 1.3885, G loss: 0.7338\n",
      "[564/1762] D loss: 1.3686, G loss: 0.7136\n",
      "[644/1762] D loss: 0.4418, G loss: 1.8115\n",
      "[724/1762] D loss: 1.3588, G loss: 0.7183\n",
      "[804/1762] D loss: 1.4967, G loss: 0.6795\n",
      "[884/1762] D loss: 1.4068, G loss: 0.6889\n",
      "[964/1762] D loss: 1.5378, G loss: 0.7106\n",
      "[1044/1762] D loss: 0.5045, G loss: 1.6059\n",
      "[1124/1762] D loss: 1.5183, G loss: 0.7145\n",
      "[1204/1762] D loss: 1.3859, G loss: 0.6568\n",
      "[1284/1762] D loss: 0.5319, G loss: 1.4980\n",
      "[1364/1762] D loss: 0.6835, G loss: 1.2766\n",
      "[1444/1762] D loss: 1.4313, G loss: 0.5746\n",
      "[1524/1762] D loss: 1.4162, G loss: 0.7032\n",
      "[1604/1762] D loss: 0.5599, G loss: 1.4271\n",
      "[1684/1762] D loss: 0.6060, G loss: 1.4497\n",
      "[1762/1762] D loss: 1.4990, G loss: 0.3873\n",
      "train error: \n",
      " D loss: 1.431968, G loss: 0.472979, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 71.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411133, G loss: 0.491752, D accuracy: 56.0%, cell accuracy: 99.5%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3991, G loss: 0.6899\n",
      "[84/1762] D loss: 0.7355, G loss: 1.3141\n",
      "[164/1762] D loss: 1.3936, G loss: 0.6352\n",
      "[244/1762] D loss: 1.3998, G loss: 0.7222\n",
      "[324/1762] D loss: 1.3902, G loss: 0.6904\n",
      "[404/1762] D loss: 1.3814, G loss: 0.7082\n",
      "[484/1762] D loss: 1.3696, G loss: 0.7165\n",
      "[564/1762] D loss: 1.2922, G loss: 0.7617\n",
      "[644/1762] D loss: 0.4079, G loss: 1.7897\n",
      "[724/1762] D loss: 1.4155, G loss: 0.6585\n",
      "[804/1762] D loss: 1.3712, G loss: 0.7203\n",
      "[884/1762] D loss: 1.3895, G loss: 0.6574\n",
      "[964/1762] D loss: 1.4374, G loss: 0.7871\n",
      "[1044/1762] D loss: 0.2870, G loss: 1.9141\n",
      "[1124/1762] D loss: 1.3966, G loss: 0.7162\n",
      "[1204/1762] D loss: 0.4323, G loss: 1.6345\n",
      "[1284/1762] D loss: 0.5187, G loss: 1.5283\n",
      "[1364/1762] D loss: 1.3830, G loss: 0.6952\n",
      "[1444/1762] D loss: 1.4839, G loss: 0.6123\n",
      "[1524/1762] D loss: 1.4121, G loss: 0.7281\n",
      "[1604/1762] D loss: 1.6516, G loss: 0.7829\n",
      "[1684/1762] D loss: 1.3975, G loss: 0.6988\n",
      "[1762/1762] D loss: 1.2410, G loss: 0.8293\n",
      "train error: \n",
      " D loss: 1.183020, G loss: 0.910351, D accuracy: 75.9%, cell accuracy: 98.4%, board accuracy: 42.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.187933, G loss: 0.909377, D accuracy: 73.6%, cell accuracy: 98.4%, board accuracy: 40.7% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4803, G loss: 0.7336\n",
      "[84/1762] D loss: 1.3070, G loss: 0.7383\n",
      "[164/1762] D loss: 0.7134, G loss: 1.2423\n",
      "[244/1762] D loss: 1.3879, G loss: 0.7014\n",
      "[324/1762] D loss: 1.1977, G loss: 0.9959\n",
      "[404/1762] D loss: 1.4078, G loss: 0.6967\n",
      "[484/1762] D loss: 1.3960, G loss: 0.6904\n",
      "[564/1762] D loss: 1.3340, G loss: 0.7805\n",
      "[644/1762] D loss: 1.0108, G loss: 1.0456\n",
      "[724/1762] D loss: 1.3963, G loss: 0.6761\n",
      "[804/1762] D loss: 0.5736, G loss: 1.5685\n",
      "[884/1762] D loss: 1.3957, G loss: 0.6233\n",
      "[964/1762] D loss: 1.4704, G loss: 0.6352\n",
      "[1044/1762] D loss: 1.4333, G loss: 0.7535\n",
      "[1124/1762] D loss: 1.5362, G loss: 0.6689\n",
      "[1204/1762] D loss: 1.4213, G loss: 0.6314\n",
      "[1284/1762] D loss: 1.4061, G loss: 0.7396\n",
      "[1364/1762] D loss: 1.4028, G loss: 0.7204\n",
      "[1444/1762] D loss: 1.3812, G loss: 0.7036\n",
      "[1524/1762] D loss: 1.4115, G loss: 0.6922\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.6980\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.7132\n",
      "[1762/1762] D loss: 1.4067, G loss: 0.7635\n",
      "train error: \n",
      " D loss: 1.354614, G loss: 0.758734, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350371, G loss: 0.762877, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4096, G loss: 0.6837\n",
      "[84/1762] D loss: 1.8995, G loss: 0.6960\n",
      "[164/1762] D loss: 1.3830, G loss: 0.6858\n",
      "[244/1762] D loss: 1.3733, G loss: 0.6952\n",
      "[324/1762] D loss: 1.3955, G loss: 0.7212\n",
      "[404/1762] D loss: 1.3483, G loss: 0.6962\n",
      "[484/1762] D loss: 1.3973, G loss: 0.7038\n",
      "[564/1762] D loss: 1.1881, G loss: 0.9419\n",
      "[644/1762] D loss: 1.2477, G loss: 1.0429\n",
      "[724/1762] D loss: 1.1286, G loss: 0.9345\n",
      "[804/1762] D loss: 1.3785, G loss: 0.7326\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7359\n",
      "[964/1762] D loss: 1.4220, G loss: 0.7343\n",
      "[1044/1762] D loss: 1.5268, G loss: 0.6133\n",
      "[1124/1762] D loss: 1.2009, G loss: 0.8982\n",
      "[1204/1762] D loss: 0.7417, G loss: 1.3628\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.6794\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.6992\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.6572\n",
      "[1524/1762] D loss: 0.8443, G loss: 1.1601\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.7026\n",
      "[1684/1762] D loss: 1.4299, G loss: 0.7110\n",
      "[1762/1762] D loss: 1.3729, G loss: 0.6268\n",
      "train error: \n",
      " D loss: 1.326308, G loss: 0.716328, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306088, G loss: 0.737725, D accuracy: 57.6%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4057, G loss: 0.6708\n",
      "[84/1762] D loss: 1.3775, G loss: 0.6974\n",
      "[164/1762] D loss: 1.5025, G loss: 0.5940\n",
      "[244/1762] D loss: 1.4541, G loss: 0.6122\n",
      "[324/1762] D loss: 1.3942, G loss: 0.6968\n",
      "[404/1762] D loss: 1.4077, G loss: 0.5773\n",
      "[484/1762] D loss: 1.9315, G loss: 0.4326\n",
      "[564/1762] D loss: 1.4243, G loss: 0.8269\n",
      "[644/1762] D loss: 0.4783, G loss: 1.7407\n",
      "[724/1762] D loss: 1.4029, G loss: 0.6462\n",
      "[804/1762] D loss: 1.4044, G loss: 0.7103\n",
      "[884/1762] D loss: 1.6101, G loss: 0.5417\n",
      "[964/1762] D loss: 1.5934, G loss: 0.6383\n",
      "[1044/1762] D loss: 1.4268, G loss: 0.7391\n",
      "[1124/1762] D loss: 1.4330, G loss: 0.6335\n",
      "[1204/1762] D loss: 1.7119, G loss: 0.6173\n",
      "[1284/1762] D loss: 1.4096, G loss: 0.6965\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.7068\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.7003\n",
      "[1524/1762] D loss: 1.4328, G loss: 0.6836\n",
      "[1604/1762] D loss: 1.4320, G loss: 0.6700\n",
      "[1684/1762] D loss: 0.1772, G loss: 2.4572\n",
      "[1762/1762] D loss: 1.5638, G loss: 0.4406\n",
      "train error: \n",
      " D loss: 1.392080, G loss: 0.499178, D accuracy: 54.4%, cell accuracy: 99.5%, board accuracy: 66.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380116, G loss: 0.502892, D accuracy: 54.2%, cell accuracy: 99.4%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7534, G loss: 1.3422\n",
      "[84/1762] D loss: 1.3697, G loss: 0.8077\n",
      "[164/1762] D loss: 1.4026, G loss: 0.6858\n",
      "[244/1762] D loss: 0.5890, G loss: 1.6016\n",
      "[324/1762] D loss: 1.3834, G loss: 0.7025\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6834\n",
      "[484/1762] D loss: 1.5383, G loss: 0.8625\n",
      "[564/1762] D loss: 1.3627, G loss: 0.7136\n",
      "[644/1762] D loss: 1.3847, G loss: 0.6935\n",
      "[724/1762] D loss: 1.3979, G loss: 0.6837\n",
      "[804/1762] D loss: 1.4106, G loss: 0.7057\n",
      "[884/1762] D loss: 1.4118, G loss: 0.7211\n",
      "[964/1762] D loss: 1.4017, G loss: 0.7043\n",
      "[1044/1762] D loss: 1.2887, G loss: 0.9802\n",
      "[1124/1762] D loss: 1.2393, G loss: 0.9394\n",
      "[1204/1762] D loss: 1.0867, G loss: 1.2352\n",
      "[1284/1762] D loss: 1.1897, G loss: 0.8334\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7145\n",
      "[1444/1762] D loss: 1.3966, G loss: 0.7058\n",
      "[1524/1762] D loss: 1.3431, G loss: 0.6959\n",
      "[1604/1762] D loss: 0.7482, G loss: 1.4458\n",
      "[1684/1762] D loss: 0.5915, G loss: 1.6185\n",
      "[1762/1762] D loss: 0.2501, G loss: 2.2348\n",
      "train error: \n",
      " D loss: 1.419969, G loss: 0.553795, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411700, G loss: 0.553385, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5036, G loss: 1.9170\n",
      "[84/1762] D loss: 1.4081, G loss: 0.5727\n",
      "[164/1762] D loss: 1.4041, G loss: 0.7695\n",
      "[244/1762] D loss: 0.6206, G loss: 1.6053\n",
      "[324/1762] D loss: 0.8007, G loss: 1.3629\n",
      "[404/1762] D loss: 1.5771, G loss: 0.4525\n",
      "[484/1762] D loss: 0.4711, G loss: 1.8596\n",
      "[564/1762] D loss: 1.4113, G loss: 0.6579\n",
      "[644/1762] D loss: 1.4265, G loss: 0.6226\n",
      "[724/1762] D loss: 1.7494, G loss: 0.5893\n",
      "[804/1762] D loss: 1.3838, G loss: 0.6933\n",
      "[884/1762] D loss: 1.4060, G loss: 0.6432\n",
      "[964/1762] D loss: 1.3554, G loss: 0.8015\n",
      "[1044/1762] D loss: 1.1810, G loss: 0.9621\n",
      "[1124/1762] D loss: 1.4349, G loss: 0.6737\n",
      "[1204/1762] D loss: 0.5482, G loss: 1.6127\n",
      "[1284/1762] D loss: 1.3932, G loss: 0.6860\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.6855\n",
      "[1444/1762] D loss: 1.4488, G loss: 0.6444\n",
      "[1524/1762] D loss: 1.4012, G loss: 0.6562\n",
      "[1604/1762] D loss: 1.4006, G loss: 0.7170\n",
      "[1684/1762] D loss: 1.4062, G loss: 0.6879\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.6354\n",
      "train error: \n",
      " D loss: 1.321271, G loss: 0.725483, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304369, G loss: 0.741486, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5279, G loss: 1.6418\n",
      "[84/1762] D loss: 0.4327, G loss: 1.5551\n",
      "[164/1762] D loss: 1.4113, G loss: 0.7002\n",
      "[244/1762] D loss: 1.0017, G loss: 1.0551\n",
      "[324/1762] D loss: 1.4726, G loss: 0.5136\n",
      "[404/1762] D loss: 0.7421, G loss: 1.3104\n",
      "[484/1762] D loss: 1.1981, G loss: 0.8590\n",
      "[564/1762] D loss: 0.4614, G loss: 1.5388\n",
      "[644/1762] D loss: 1.4036, G loss: 0.6739\n",
      "[724/1762] D loss: 1.3922, G loss: 0.7134\n",
      "[804/1762] D loss: 0.4768, G loss: 1.8086\n",
      "[884/1762] D loss: 1.4275, G loss: 0.7392\n",
      "[964/1762] D loss: 1.7287, G loss: 0.5773\n",
      "[1044/1762] D loss: 1.4553, G loss: 0.7004\n",
      "[1124/1762] D loss: 1.3926, G loss: 0.6462\n",
      "[1204/1762] D loss: 1.4059, G loss: 0.7552\n",
      "[1284/1762] D loss: 1.4900, G loss: 0.6844\n",
      "[1364/1762] D loss: 1.4887, G loss: 0.6851\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.6332\n",
      "[1524/1762] D loss: 1.2195, G loss: 0.9404\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7165\n",
      "[1684/1762] D loss: 1.1529, G loss: 0.7945\n",
      "[1762/1762] D loss: 1.3956, G loss: 0.7484\n",
      "train error: \n",
      " D loss: 1.344522, G loss: 0.873366, D accuracy: 51.8%, cell accuracy: 99.7%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353237, G loss: 0.853847, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3351, G loss: 0.8946\n",
      "[84/1762] D loss: 1.4157, G loss: 0.7197\n",
      "[164/1762] D loss: 1.4305, G loss: 1.1619\n",
      "[244/1762] D loss: 1.3851, G loss: 0.7140\n",
      "[324/1762] D loss: 1.3898, G loss: 0.6936\n",
      "[404/1762] D loss: 1.0359, G loss: 0.9435\n",
      "[484/1762] D loss: 1.4166, G loss: 0.7266\n",
      "[564/1762] D loss: 0.5841, G loss: 1.4229\n",
      "[644/1762] D loss: 0.2289, G loss: 2.1338\n",
      "[724/1762] D loss: 1.3989, G loss: 0.6862\n",
      "[804/1762] D loss: 1.3853, G loss: 0.5859\n",
      "[884/1762] D loss: 0.4317, G loss: 1.6008\n",
      "[964/1762] D loss: 1.3964, G loss: 0.7130\n",
      "[1044/1762] D loss: 0.8144, G loss: 1.3749\n",
      "[1124/1762] D loss: 1.5460, G loss: 0.7647\n",
      "[1204/1762] D loss: 1.3854, G loss: 0.7260\n",
      "[1284/1762] D loss: 1.4115, G loss: 0.7402\n",
      "[1364/1762] D loss: 1.3847, G loss: 0.6898\n",
      "[1444/1762] D loss: 1.3207, G loss: 0.9932\n",
      "[1524/1762] D loss: 1.3995, G loss: 0.6830\n",
      "[1604/1762] D loss: 1.3124, G loss: 0.8509\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.7084\n",
      "[1762/1762] D loss: 1.3704, G loss: 0.6340\n",
      "train error: \n",
      " D loss: 1.371629, G loss: 0.737339, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374248, G loss: 0.726819, D accuracy: 50.5%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921, G loss: 0.6954\n",
      "[84/1762] D loss: 1.3943, G loss: 0.6728\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6992\n",
      "[244/1762] D loss: 1.4001, G loss: 0.6685\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6847\n",
      "[404/1762] D loss: 1.3880, G loss: 0.7013\n",
      "[484/1762] D loss: 1.3986, G loss: 0.6697\n",
      "[564/1762] D loss: 1.2066, G loss: 0.8575\n",
      "[644/1762] D loss: 0.9405, G loss: 1.0038\n",
      "[724/1762] D loss: 1.3855, G loss: 0.6869\n",
      "[804/1762] D loss: 1.3894, G loss: 0.6772\n",
      "[884/1762] D loss: 1.4106, G loss: 0.7168\n",
      "[964/1762] D loss: 1.3811, G loss: 0.6924\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.7025\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.7086\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.7132\n",
      "[1284/1762] D loss: 1.4245, G loss: 0.6838\n",
      "[1364/1762] D loss: 1.4157, G loss: 0.5570\n",
      "[1444/1762] D loss: 1.4662, G loss: 0.7566\n",
      "[1524/1762] D loss: 1.3947, G loss: 0.7100\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.6538\n",
      "[1684/1762] D loss: 1.3947, G loss: 0.8023\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6976\n",
      "train error: \n",
      " D loss: 1.351524, G loss: 0.758787, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337172, G loss: 0.756414, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0967, G loss: 0.8398\n",
      "[84/1762] D loss: 1.3977, G loss: 0.6543\n",
      "[164/1762] D loss: 1.4251, G loss: 0.6497\n",
      "[244/1762] D loss: 1.3982, G loss: 0.6518\n",
      "[324/1762] D loss: 1.5880, G loss: 0.9978\n",
      "[404/1762] D loss: 1.5293, G loss: 0.4625\n",
      "[484/1762] D loss: 1.4685, G loss: 0.5281\n",
      "[564/1762] D loss: 0.9792, G loss: 1.0119\n",
      "[644/1762] D loss: 1.3887, G loss: 0.7136\n",
      "[724/1762] D loss: 1.4128, G loss: 0.6698\n",
      "[804/1762] D loss: 1.3891, G loss: 0.6884\n",
      "[884/1762] D loss: 0.7268, G loss: 1.6207\n",
      "[964/1762] D loss: 1.3975, G loss: 0.6294\n",
      "[1044/1762] D loss: 1.2678, G loss: 0.9781\n",
      "[1124/1762] D loss: 0.6998, G loss: 1.2916\n",
      "[1204/1762] D loss: 1.5369, G loss: 0.7970\n",
      "[1284/1762] D loss: 1.3953, G loss: 0.6629\n",
      "[1364/1762] D loss: 1.4598, G loss: 0.7736\n",
      "[1444/1762] D loss: 1.3834, G loss: 0.6853\n",
      "[1524/1762] D loss: 0.9309, G loss: 1.1551\n",
      "[1604/1762] D loss: 1.6529, G loss: 0.6576\n",
      "[1684/1762] D loss: 1.4041, G loss: 0.7149\n",
      "[1762/1762] D loss: 1.4566, G loss: 0.6400\n",
      "train error: \n",
      " D loss: 1.341362, G loss: 0.696227, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330898, G loss: 0.708147, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4176, G loss: 0.6319\n",
      "[84/1762] D loss: 0.5318, G loss: 1.4289\n",
      "[164/1762] D loss: 1.3673, G loss: 0.8813\n",
      "[244/1762] D loss: 1.4205, G loss: 0.6901\n",
      "[324/1762] D loss: 1.3913, G loss: 0.7009\n",
      "[404/1762] D loss: 1.3937, G loss: 0.6988\n",
      "[484/1762] D loss: 1.0597, G loss: 1.0354\n",
      "[564/1762] D loss: 1.4131, G loss: 0.6244\n",
      "[644/1762] D loss: 1.4141, G loss: 0.7743\n",
      "[724/1762] D loss: 1.4259, G loss: 0.6337\n",
      "[804/1762] D loss: 1.0628, G loss: 0.9135\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7024\n",
      "[964/1762] D loss: 1.3855, G loss: 0.6982\n",
      "[1044/1762] D loss: 1.1925, G loss: 0.6992\n",
      "[1124/1762] D loss: 1.3225, G loss: 0.7188\n",
      "[1204/1762] D loss: 1.3458, G loss: 0.7502\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.7585\n",
      "[1364/1762] D loss: 0.7708, G loss: 1.2820\n",
      "[1444/1762] D loss: 0.9482, G loss: 1.3715\n",
      "[1524/1762] D loss: 1.3374, G loss: 0.9177\n",
      "[1604/1762] D loss: 1.1041, G loss: 0.9576\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6788\n",
      "[1762/1762] D loss: 1.3071, G loss: 0.9026\n",
      "train error: \n",
      " D loss: 1.385391, G loss: 0.612614, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378535, G loss: 0.619257, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2384, G loss: 0.7444\n",
      "[84/1762] D loss: 1.3617, G loss: 0.7230\n",
      "[164/1762] D loss: 1.2562, G loss: 0.9075\n",
      "[244/1762] D loss: 1.1154, G loss: 0.9506\n",
      "[324/1762] D loss: 1.3888, G loss: 0.6844\n",
      "[404/1762] D loss: 1.3896, G loss: 0.7000\n",
      "[484/1762] D loss: 1.3965, G loss: 0.7156\n",
      "[564/1762] D loss: 1.4289, G loss: 0.6949\n",
      "[644/1762] D loss: 1.3909, G loss: 0.6708\n",
      "[724/1762] D loss: 1.2468, G loss: 0.8641\n",
      "[804/1762] D loss: 1.3888, G loss: 0.7159\n",
      "[884/1762] D loss: 1.1202, G loss: 0.6546\n",
      "[964/1762] D loss: 1.3804, G loss: 0.6986\n",
      "[1044/1762] D loss: 1.3545, G loss: 0.7140\n",
      "[1124/1762] D loss: 1.3971, G loss: 0.6811\n",
      "[1204/1762] D loss: 1.3949, G loss: 0.7262\n",
      "[1284/1762] D loss: 1.0340, G loss: 1.0567\n",
      "[1364/1762] D loss: 1.4062, G loss: 0.6861\n",
      "[1444/1762] D loss: 0.8997, G loss: 1.1251\n",
      "[1524/1762] D loss: 1.6428, G loss: 0.8833\n",
      "[1604/1762] D loss: 1.4248, G loss: 0.7485\n",
      "[1684/1762] D loss: 1.3823, G loss: 0.6829\n",
      "[1762/1762] D loss: 1.4230, G loss: 0.5492\n",
      "train error: \n",
      " D loss: 1.334645, G loss: 0.766560, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308940, G loss: 0.807086, D accuracy: 54.7%, cell accuracy: 99.9%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5423, G loss: 1.5646\n",
      "[84/1762] D loss: 0.6468, G loss: 1.5199\n",
      "[164/1762] D loss: 1.3920, G loss: 0.6987\n",
      "[244/1762] D loss: 0.8160, G loss: 1.1660\n",
      "[324/1762] D loss: 1.3889, G loss: 0.7006\n",
      "[404/1762] D loss: 1.3967, G loss: 0.7163\n",
      "[484/1762] D loss: 1.0438, G loss: 1.0776\n",
      "[564/1762] D loss: 1.3930, G loss: 0.6924\n",
      "[644/1762] D loss: 1.4013, G loss: 0.7130\n",
      "[724/1762] D loss: 1.3812, G loss: 0.6701\n",
      "[804/1762] D loss: 0.7898, G loss: 1.2876\n",
      "[884/1762] D loss: 1.4027, G loss: 0.6992\n",
      "[964/1762] D loss: 1.6713, G loss: 1.6294\n",
      "[1044/1762] D loss: 1.1455, G loss: 1.1166\n",
      "[1124/1762] D loss: 1.4612, G loss: 0.7313\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.7223\n",
      "[1284/1762] D loss: 1.0664, G loss: 0.8902\n",
      "[1364/1762] D loss: 1.2170, G loss: 0.8479\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.6863\n",
      "[1524/1762] D loss: 1.1710, G loss: 0.9151\n",
      "[1604/1762] D loss: 0.9173, G loss: 1.1347\n",
      "[1684/1762] D loss: 1.3886, G loss: 0.6891\n",
      "[1762/1762] D loss: 1.3933, G loss: 0.7132\n",
      "train error: \n",
      " D loss: 1.411821, G loss: 0.935698, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395448, G loss: 0.965205, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7269\n",
      "[84/1762] D loss: 1.3992, G loss: 0.6989\n",
      "[164/1762] D loss: 1.3921, G loss: 0.6841\n",
      "[244/1762] D loss: 1.3899, G loss: 0.7054\n",
      "[324/1762] D loss: 0.6921, G loss: 1.1811\n",
      "[404/1762] D loss: 1.2874, G loss: 1.3771\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6959\n",
      "[564/1762] D loss: 1.3782, G loss: 0.7002\n",
      "[644/1762] D loss: 1.1895, G loss: 0.9093\n",
      "[724/1762] D loss: 1.4354, G loss: 0.7138\n",
      "[804/1762] D loss: 1.3895, G loss: 0.7619\n",
      "[884/1762] D loss: 1.4047, G loss: 0.7269\n",
      "[964/1762] D loss: 1.3915, G loss: 0.6927\n",
      "[1044/1762] D loss: 1.4180, G loss: 0.6247\n",
      "[1124/1762] D loss: 1.4918, G loss: 1.4222\n",
      "[1204/1762] D loss: 1.4359, G loss: 0.6111\n",
      "[1284/1762] D loss: 1.4071, G loss: 0.7089\n",
      "[1364/1762] D loss: 1.6351, G loss: 0.5976\n",
      "[1444/1762] D loss: 1.4798, G loss: 0.8291\n",
      "[1524/1762] D loss: 1.4032, G loss: 0.7776\n",
      "[1604/1762] D loss: 1.3925, G loss: 0.7011\n",
      "[1684/1762] D loss: 1.5868, G loss: 0.8509\n",
      "[1762/1762] D loss: 1.3921, G loss: 0.6678\n",
      "train error: \n",
      " D loss: 1.387666, G loss: 0.905301, D accuracy: 52.4%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372358, G loss: 0.913761, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.6987\n",
      "[84/1762] D loss: 1.3998, G loss: 0.6813\n",
      "[164/1762] D loss: 1.3958, G loss: 0.6942\n",
      "[244/1762] D loss: 1.4055, G loss: 0.7552\n",
      "[324/1762] D loss: 1.3854, G loss: 0.6885\n",
      "[404/1762] D loss: 1.2628, G loss: 0.8175\n",
      "[484/1762] D loss: 1.3917, G loss: 0.7209\n",
      "[564/1762] D loss: 1.3917, G loss: 0.6730\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7334\n",
      "[724/1762] D loss: 1.4010, G loss: 0.6797\n",
      "[804/1762] D loss: 1.4268, G loss: 0.7705\n",
      "[884/1762] D loss: 1.4118, G loss: 0.7261\n",
      "[964/1762] D loss: 0.5544, G loss: 1.3647\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6875\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.6865\n",
      "[1204/1762] D loss: 0.4671, G loss: 1.5083\n",
      "[1284/1762] D loss: 1.5527, G loss: 1.0490\n",
      "[1364/1762] D loss: 1.4101, G loss: 0.7018\n",
      "[1444/1762] D loss: 1.4037, G loss: 0.7831\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.7071\n",
      "[1604/1762] D loss: 1.4122, G loss: 0.7051\n",
      "[1684/1762] D loss: 1.4100, G loss: 0.7074\n",
      "[1762/1762] D loss: 1.4575, G loss: 0.7299\n",
      "train error: \n",
      " D loss: 1.346108, G loss: 0.610306, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325330, G loss: 0.620437, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3937, G loss: 0.7150\n",
      "[84/1762] D loss: 0.4805, G loss: 1.4285\n",
      "[164/1762] D loss: 1.2230, G loss: 1.2741\n",
      "[244/1762] D loss: 1.4903, G loss: 0.7535\n",
      "[324/1762] D loss: 1.3983, G loss: 0.6868\n",
      "[404/1762] D loss: 0.7615, G loss: 1.2546\n",
      "[484/1762] D loss: 0.9716, G loss: 1.0710\n",
      "[564/1762] D loss: 1.2243, G loss: 1.1080\n",
      "[644/1762] D loss: 1.3918, G loss: 0.7054\n",
      "[724/1762] D loss: 1.4448, G loss: 0.7817\n",
      "[804/1762] D loss: 1.4444, G loss: 0.6415\n",
      "[884/1762] D loss: 1.4235, G loss: 0.6918\n",
      "[964/1762] D loss: 1.3962, G loss: 0.6893\n",
      "[1044/1762] D loss: 1.3855, G loss: 0.7049\n",
      "[1124/1762] D loss: 0.4108, G loss: 1.5516\n",
      "[1204/1762] D loss: 1.5635, G loss: 0.9077\n",
      "[1284/1762] D loss: 1.3935, G loss: 0.7108\n",
      "[1364/1762] D loss: 1.4003, G loss: 0.7263\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.7020\n",
      "[1524/1762] D loss: 1.4091, G loss: 0.7447\n",
      "[1604/1762] D loss: 1.4065, G loss: 0.6780\n",
      "[1684/1762] D loss: 1.4250, G loss: 0.7471\n",
      "[1762/1762] D loss: 1.4206, G loss: 0.6798\n",
      "train error: \n",
      " D loss: 1.334104, G loss: 0.721470, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322568, G loss: 0.721282, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4132, G loss: 0.6631\n",
      "[84/1762] D loss: 1.4007, G loss: 0.7350\n",
      "[164/1762] D loss: 1.3914, G loss: 0.7080\n",
      "[244/1762] D loss: 1.1232, G loss: 1.0825\n",
      "[324/1762] D loss: 1.3983, G loss: 0.6782\n",
      "[404/1762] D loss: 2.1428, G loss: 1.9179\n",
      "[484/1762] D loss: 1.4007, G loss: 0.6694\n",
      "[564/1762] D loss: 1.4047, G loss: 0.7520\n",
      "[644/1762] D loss: 1.3910, G loss: 0.7020\n",
      "[724/1762] D loss: 1.3966, G loss: 0.6622\n",
      "[804/1762] D loss: 1.1121, G loss: 1.0232\n",
      "[884/1762] D loss: 1.3945, G loss: 0.7276\n",
      "[964/1762] D loss: 1.4342, G loss: 0.6813\n",
      "[1044/1762] D loss: 1.3992, G loss: 0.7712\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7001\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.7255\n",
      "[1284/1762] D loss: 1.3929, G loss: 0.7005\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7125\n",
      "[1444/1762] D loss: 0.6273, G loss: 1.2797\n",
      "[1524/1762] D loss: 1.4221, G loss: 0.7016\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.7044\n",
      "[1684/1762] D loss: 1.3704, G loss: 0.7019\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.7080\n",
      "train error: \n",
      " D loss: 1.339731, G loss: 0.686114, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326976, G loss: 0.696169, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4763, G loss: 1.4297\n",
      "[84/1762] D loss: 0.5015, G loss: 1.3873\n",
      "[164/1762] D loss: 0.3268, G loss: 1.6748\n",
      "[244/1762] D loss: 1.3919, G loss: 0.6872\n",
      "[324/1762] D loss: 1.3990, G loss: 0.7026\n",
      "[404/1762] D loss: 1.5038, G loss: 0.9881\n",
      "[484/1762] D loss: 1.4028, G loss: 0.6762\n",
      "[564/1762] D loss: 1.4069, G loss: 0.7100\n",
      "[644/1762] D loss: 1.3931, G loss: 0.7016\n",
      "[724/1762] D loss: 1.3841, G loss: 0.7062\n",
      "[804/1762] D loss: 0.9602, G loss: 0.9798\n",
      "[884/1762] D loss: 1.3906, G loss: 0.6818\n",
      "[964/1762] D loss: 0.9887, G loss: 1.1644\n",
      "[1044/1762] D loss: 0.8680, G loss: 1.1325\n",
      "[1124/1762] D loss: 0.5217, G loss: 2.0011\n",
      "[1204/1762] D loss: 1.2784, G loss: 1.8510\n",
      "[1284/1762] D loss: 0.3655, G loss: 1.7770\n",
      "[1364/1762] D loss: 1.4018, G loss: 0.6863\n",
      "[1444/1762] D loss: 1.3995, G loss: 0.7175\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.7031\n",
      "[1604/1762] D loss: 1.5220, G loss: 0.7651\n",
      "[1684/1762] D loss: 1.2965, G loss: 1.0618\n",
      "[1762/1762] D loss: 0.6435, G loss: 1.6900\n",
      "train error: \n",
      " D loss: 1.387176, G loss: 0.785885, D accuracy: 47.9%, cell accuracy: 99.9%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374580, G loss: 0.830936, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5293, G loss: 1.5157\n",
      "[84/1762] D loss: 1.3881, G loss: 0.7030\n",
      "[164/1762] D loss: 1.1466, G loss: 0.8582\n",
      "[244/1762] D loss: 1.3133, G loss: 0.7432\n",
      "[324/1762] D loss: 1.2021, G loss: 0.9644\n",
      "[404/1762] D loss: 1.3952, G loss: 0.7046\n",
      "[484/1762] D loss: 1.4063, G loss: 0.7272\n",
      "[564/1762] D loss: 1.3907, G loss: 0.6872\n",
      "[644/1762] D loss: 0.9110, G loss: 0.9450\n",
      "[724/1762] D loss: 1.3886, G loss: 0.6878\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6822\n",
      "[884/1762] D loss: 0.9328, G loss: 1.1412\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6962\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.6963\n",
      "[1124/1762] D loss: 1.3951, G loss: 0.6935\n",
      "[1204/1762] D loss: 1.4046, G loss: 0.7519\n",
      "[1284/1762] D loss: 1.5165, G loss: 0.6690\n",
      "[1364/1762] D loss: 0.4685, G loss: 1.8582\n",
      "[1444/1762] D loss: 0.6884, G loss: 1.3618\n",
      "[1524/1762] D loss: 1.4095, G loss: 0.6576\n",
      "[1604/1762] D loss: 1.3966, G loss: 0.7379\n",
      "[1684/1762] D loss: 1.3986, G loss: 0.7317\n",
      "[1762/1762] D loss: 1.4374, G loss: 0.6413\n",
      "train error: \n",
      " D loss: 1.349759, G loss: 0.677648, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332829, G loss: 0.687653, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4025, G loss: 0.7718\n",
      "[84/1762] D loss: 1.3906, G loss: 0.6681\n",
      "[164/1762] D loss: 1.4109, G loss: 0.7281\n",
      "[244/1762] D loss: 0.9076, G loss: 0.7716\n",
      "[324/1762] D loss: 1.3910, G loss: 0.6899\n",
      "[404/1762] D loss: 1.3164, G loss: 0.7853\n",
      "[484/1762] D loss: 1.3924, G loss: 0.7006\n",
      "[564/1762] D loss: 1.3856, G loss: 0.6986\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6665\n",
      "[724/1762] D loss: 0.3389, G loss: 1.8025\n",
      "[804/1762] D loss: 1.5804, G loss: 0.8222\n",
      "[884/1762] D loss: 1.3781, G loss: 0.7463\n",
      "[964/1762] D loss: 0.5873, G loss: 1.3987\n",
      "[1044/1762] D loss: 0.3704, G loss: 1.7132\n",
      "[1124/1762] D loss: 1.4074, G loss: 0.7157\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.6965\n",
      "[1284/1762] D loss: 1.4108, G loss: 0.7116\n",
      "[1364/1762] D loss: 1.3951, G loss: 0.7000\n",
      "[1444/1762] D loss: 0.4135, G loss: 1.5615\n",
      "[1524/1762] D loss: 1.4110, G loss: 0.7129\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6891\n",
      "[1684/1762] D loss: 0.5235, G loss: 1.4895\n",
      "[1762/1762] D loss: 1.4728, G loss: 0.6947\n",
      "train error: \n",
      " D loss: 1.993536, G loss: 0.194536, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.981671, G loss: 0.203876, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4111, G loss: 0.7159\n",
      "[84/1762] D loss: 1.4912, G loss: 0.8158\n",
      "[164/1762] D loss: 1.3990, G loss: 0.7398\n",
      "[244/1762] D loss: 1.3907, G loss: 0.6890\n",
      "[324/1762] D loss: 1.3908, G loss: 0.6730\n",
      "[404/1762] D loss: 1.4093, G loss: 0.7103\n",
      "[484/1762] D loss: 0.4936, G loss: 1.3743\n",
      "[564/1762] D loss: 0.3959, G loss: 1.4217\n",
      "[644/1762] D loss: 0.4862, G loss: 1.3177\n",
      "[724/1762] D loss: 1.5097, G loss: 0.8408\n",
      "[804/1762] D loss: 1.3908, G loss: 0.7184\n",
      "[884/1762] D loss: 1.4131, G loss: 0.8821\n",
      "[964/1762] D loss: 1.4013, G loss: 0.7335\n",
      "[1044/1762] D loss: 0.6545, G loss: 1.1061\n",
      "[1124/1762] D loss: 1.4046, G loss: 0.7395\n",
      "[1204/1762] D loss: 1.4136, G loss: 0.7859\n",
      "[1284/1762] D loss: 1.4970, G loss: 0.8527\n",
      "[1364/1762] D loss: 1.3101, G loss: 0.6967\n",
      "[1444/1762] D loss: 1.4291, G loss: 0.7382\n",
      "[1524/1762] D loss: 1.3387, G loss: 0.7269\n",
      "[1604/1762] D loss: 1.5462, G loss: 0.8465\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6967\n",
      "[1762/1762] D loss: 1.2906, G loss: 0.9922\n",
      "train error: \n",
      " D loss: 1.287607, G loss: 0.998417, D accuracy: 52.8%, cell accuracy: 98.6%, board accuracy: 30.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266968, G loss: 1.027965, D accuracy: 53.5%, cell accuracy: 98.5%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3217, G loss: 0.9214\n",
      "[84/1762] D loss: 1.3917, G loss: 0.6542\n",
      "[164/1762] D loss: 0.8977, G loss: 1.1319\n",
      "[244/1762] D loss: 1.1833, G loss: 1.1143\n",
      "[324/1762] D loss: 1.2493, G loss: 0.9524\n",
      "[404/1762] D loss: 1.1830, G loss: 1.0094\n",
      "[484/1762] D loss: 1.3990, G loss: 0.6841\n",
      "[564/1762] D loss: 1.4483, G loss: 0.7100\n",
      "[644/1762] D loss: 1.4595, G loss: 0.7631\n",
      "[724/1762] D loss: 1.3933, G loss: 0.6821\n",
      "[804/1762] D loss: 1.3964, G loss: 0.6784\n",
      "[884/1762] D loss: 0.3393, G loss: 1.6923\n",
      "[964/1762] D loss: 1.5869, G loss: 0.7673\n",
      "[1044/1762] D loss: 1.4009, G loss: 0.7233\n",
      "[1124/1762] D loss: 1.3845, G loss: 0.6978\n",
      "[1204/1762] D loss: 1.3924, G loss: 0.6966\n",
      "[1284/1762] D loss: 1.5512, G loss: 0.7391\n",
      "[1364/1762] D loss: 1.4079, G loss: 0.7399\n",
      "[1444/1762] D loss: 0.4767, G loss: 1.4264\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6962\n",
      "[1604/1762] D loss: 1.3948, G loss: 0.6990\n",
      "[1684/1762] D loss: 1.3860, G loss: 0.6928\n",
      "[1762/1762] D loss: 1.4121, G loss: 0.6254\n",
      "train error: \n",
      " D loss: 1.412975, G loss: 0.484174, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402815, G loss: 0.484767, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.6800\n",
      "[84/1762] D loss: 1.3570, G loss: 0.6954\n",
      "[164/1762] D loss: 1.3914, G loss: 0.7110\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6952\n",
      "[324/1762] D loss: 1.3645, G loss: 0.7011\n",
      "[404/1762] D loss: 1.4441, G loss: 0.6810\n",
      "[484/1762] D loss: 1.5503, G loss: 0.7083\n",
      "[564/1762] D loss: 0.4498, G loss: 1.7185\n",
      "[644/1762] D loss: 0.3734, G loss: 1.5542\n",
      "[724/1762] D loss: 1.5835, G loss: 0.7372\n",
      "[804/1762] D loss: 0.3009, G loss: 1.8244\n",
      "[884/1762] D loss: 1.3967, G loss: 0.7091\n",
      "[964/1762] D loss: 1.3942, G loss: 0.7029\n",
      "[1044/1762] D loss: 1.4088, G loss: 0.7264\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.6966\n",
      "[1204/1762] D loss: 1.4985, G loss: 0.7662\n",
      "[1284/1762] D loss: 1.3947, G loss: 0.7118\n",
      "[1364/1762] D loss: 0.4736, G loss: 1.4616\n",
      "[1444/1762] D loss: 1.4252, G loss: 0.7306\n",
      "[1524/1762] D loss: 1.3986, G loss: 0.7057\n",
      "[1604/1762] D loss: 1.4624, G loss: 0.7661\n",
      "[1684/1762] D loss: 1.6529, G loss: 0.7899\n",
      "[1762/1762] D loss: 1.5369, G loss: 0.6292\n",
      "train error: \n",
      " D loss: 1.348357, G loss: 0.607204, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332875, G loss: 0.612592, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903, G loss: 0.6975\n",
      "[84/1762] D loss: 1.3910, G loss: 0.7038\n",
      "[164/1762] D loss: 0.1815, G loss: 2.0979\n",
      "[244/1762] D loss: 1.3935, G loss: 0.7106\n",
      "[324/1762] D loss: 1.3916, G loss: 0.6828\n",
      "[404/1762] D loss: 1.5303, G loss: 0.7209\n",
      "[484/1762] D loss: 1.4209, G loss: 0.7345\n",
      "[564/1762] D loss: 1.3951, G loss: 0.7078\n",
      "[644/1762] D loss: 1.4716, G loss: 0.7759\n",
      "[724/1762] D loss: 1.4072, G loss: 0.7066\n",
      "[804/1762] D loss: 1.3520, G loss: 0.6862\n",
      "[884/1762] D loss: 1.4228, G loss: 0.6655\n",
      "[964/1762] D loss: 0.3582, G loss: 1.5675\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.7017\n",
      "[1124/1762] D loss: 0.3757, G loss: 1.5667\n",
      "[1204/1762] D loss: 1.3973, G loss: 0.6771\n",
      "[1284/1762] D loss: 1.4392, G loss: 0.7442\n",
      "[1364/1762] D loss: 1.3950, G loss: 0.7112\n",
      "[1444/1762] D loss: 1.6787, G loss: 0.8628\n",
      "[1524/1762] D loss: 1.4031, G loss: 0.7016\n",
      "[1604/1762] D loss: 1.8761, G loss: 0.7404\n",
      "[1684/1762] D loss: 1.4321, G loss: 0.6031\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6979\n",
      "train error: \n",
      " D loss: 1.346959, G loss: 0.610149, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329327, G loss: 0.619810, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4135, G loss: 1.5637\n",
      "[84/1762] D loss: 1.4881, G loss: 0.7931\n",
      "[164/1762] D loss: 1.4419, G loss: 0.7500\n",
      "[244/1762] D loss: 0.3628, G loss: 1.5998\n",
      "[324/1762] D loss: 1.5298, G loss: 0.7091\n",
      "[404/1762] D loss: 1.4086, G loss: 0.7175\n",
      "[484/1762] D loss: 1.4225, G loss: 0.7008\n",
      "[564/1762] D loss: 0.4704, G loss: 1.3833\n",
      "[644/1762] D loss: 1.4008, G loss: 0.6723\n",
      "[724/1762] D loss: 1.4317, G loss: 0.7150\n",
      "[804/1762] D loss: 1.4048, G loss: 0.7462\n",
      "[884/1762] D loss: 1.3675, G loss: 0.7891\n",
      "[964/1762] D loss: 1.4145, G loss: 0.6705\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.6944\n",
      "[1124/1762] D loss: 1.4059, G loss: 0.6537\n",
      "[1204/1762] D loss: 1.3987, G loss: 0.7219\n",
      "[1284/1762] D loss: 1.3905, G loss: 0.7115\n",
      "[1364/1762] D loss: 1.4080, G loss: 0.7395\n",
      "[1444/1762] D loss: 1.1453, G loss: 0.9625\n",
      "[1524/1762] D loss: 1.3304, G loss: 0.7464\n",
      "[1604/1762] D loss: 1.7786, G loss: 0.5628\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.7222\n",
      "[1762/1762] D loss: 1.2421, G loss: 0.6624\n",
      "train error: \n",
      " D loss: 1.380783, G loss: 0.649181, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377859, G loss: 0.646352, D accuracy: 50.5%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3232, G loss: 0.8040\n",
      "[84/1762] D loss: 1.3975, G loss: 0.7399\n",
      "[164/1762] D loss: 0.9830, G loss: 1.0747\n",
      "[244/1762] D loss: 1.3916, G loss: 0.8039\n",
      "[324/1762] D loss: 1.3901, G loss: 0.7019\n",
      "[404/1762] D loss: 1.3917, G loss: 0.6697\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6970\n",
      "[564/1762] D loss: 1.3962, G loss: 0.6892\n",
      "[644/1762] D loss: 1.3847, G loss: 0.6922\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7004\n",
      "[804/1762] D loss: 1.4385, G loss: 0.7517\n",
      "[884/1762] D loss: 1.4063, G loss: 0.6910\n",
      "[964/1762] D loss: 1.4054, G loss: 0.7151\n",
      "[1044/1762] D loss: 1.2641, G loss: 0.9575\n",
      "[1124/1762] D loss: 1.3957, G loss: 0.6733\n",
      "[1204/1762] D loss: 1.0971, G loss: 1.3728\n",
      "[1284/1762] D loss: 0.8004, G loss: 1.3002\n",
      "[1364/1762] D loss: 1.4120, G loss: 0.6638\n",
      "[1444/1762] D loss: 1.0866, G loss: 1.1995\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.7403\n",
      "[1604/1762] D loss: 1.0911, G loss: 1.0240\n",
      "[1684/1762] D loss: 1.4253, G loss: 0.6686\n",
      "[1762/1762] D loss: 1.4884, G loss: 0.7226\n",
      "train error: \n",
      " D loss: 1.354885, G loss: 0.666772, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344690, G loss: 0.668570, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3834, G loss: 0.6913\n",
      "[84/1762] D loss: 1.3918, G loss: 0.7069\n",
      "[164/1762] D loss: 1.3984, G loss: 0.6657\n",
      "[244/1762] D loss: 1.4094, G loss: 0.7011\n",
      "[324/1762] D loss: 1.4170, G loss: 0.7091\n",
      "[404/1762] D loss: 1.3989, G loss: 0.7161\n",
      "[484/1762] D loss: 0.5868, G loss: 1.5081\n",
      "[564/1762] D loss: 1.3894, G loss: 1.0547\n",
      "[644/1762] D loss: 1.4251, G loss: 0.6631\n",
      "[724/1762] D loss: 1.4100, G loss: 0.7037\n",
      "[804/1762] D loss: 1.0226, G loss: 1.2944\n",
      "[884/1762] D loss: 1.3971, G loss: 0.6965\n",
      "[964/1762] D loss: 1.6693, G loss: 0.6452\n",
      "[1044/1762] D loss: 1.3966, G loss: 0.6910\n",
      "[1124/1762] D loss: 1.4052, G loss: 0.7360\n",
      "[1204/1762] D loss: 1.8394, G loss: 0.9511\n",
      "[1284/1762] D loss: 1.4096, G loss: 0.7380\n",
      "[1364/1762] D loss: 1.4026, G loss: 0.7018\n",
      "[1444/1762] D loss: 0.9119, G loss: 0.9995\n",
      "[1524/1762] D loss: 1.3931, G loss: 0.6765\n",
      "[1604/1762] D loss: 1.9949, G loss: 1.3096\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.6865\n",
      "[1762/1762] D loss: 1.2473, G loss: 0.8150\n",
      "train error: \n",
      " D loss: 1.393643, G loss: 0.604168, D accuracy: 52.4%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382695, G loss: 0.619156, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7449, G loss: 1.3162\n",
      "[84/1762] D loss: 1.2565, G loss: 0.9368\n",
      "[164/1762] D loss: 0.3975, G loss: 1.5402\n",
      "[244/1762] D loss: 1.3973, G loss: 0.6989\n",
      "[324/1762] D loss: 0.5492, G loss: 1.4128\n",
      "[404/1762] D loss: 1.3928, G loss: 0.7049\n",
      "[484/1762] D loss: 1.4380, G loss: 0.8631\n",
      "[564/1762] D loss: 1.4028, G loss: 0.6303\n",
      "[644/1762] D loss: 1.3918, G loss: 0.8119\n",
      "[724/1762] D loss: 1.4230, G loss: 0.8848\n",
      "[804/1762] D loss: 0.5539, G loss: 1.5237\n",
      "[884/1762] D loss: 1.3996, G loss: 0.6665\n",
      "[964/1762] D loss: 1.4133, G loss: 0.7052\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.6950\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.7039\n",
      "[1204/1762] D loss: 1.1485, G loss: 0.8064\n",
      "[1284/1762] D loss: 1.4710, G loss: 0.5927\n",
      "[1364/1762] D loss: 1.4031, G loss: 0.6679\n",
      "[1444/1762] D loss: 1.3646, G loss: 0.7442\n",
      "[1524/1762] D loss: 1.5085, G loss: 0.7865\n",
      "[1604/1762] D loss: 0.5579, G loss: 1.3143\n",
      "[1684/1762] D loss: 1.3981, G loss: 0.7163\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.7070\n",
      "train error: \n",
      " D loss: 1.452448, G loss: 0.507649, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.439566, G loss: 0.512506, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4001, G loss: 0.6608\n",
      "[84/1762] D loss: 1.3909, G loss: 0.6943\n",
      "[164/1762] D loss: 1.3935, G loss: 0.7151\n",
      "[244/1762] D loss: 1.5641, G loss: 0.6983\n",
      "[324/1762] D loss: 1.3910, G loss: 0.7444\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7023\n",
      "[484/1762] D loss: 1.4166, G loss: 0.6803\n",
      "[564/1762] D loss: 1.4249, G loss: 0.6010\n",
      "[644/1762] D loss: 1.4161, G loss: 0.6656\n",
      "[724/1762] D loss: 1.2520, G loss: 0.9583\n",
      "[804/1762] D loss: 1.4073, G loss: 0.6910\n",
      "[884/1762] D loss: 0.7214, G loss: 2.0305\n",
      "[964/1762] D loss: 1.5730, G loss: 0.5794\n",
      "[1044/1762] D loss: 1.3939, G loss: 0.7073\n",
      "[1124/1762] D loss: 1.4056, G loss: 0.7254\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.7055\n",
      "[1284/1762] D loss: 0.3858, G loss: 1.6194\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.6922\n",
      "[1444/1762] D loss: 1.4058, G loss: 0.7129\n",
      "[1524/1762] D loss: 1.5671, G loss: 0.8232\n",
      "[1604/1762] D loss: 0.5475, G loss: 1.3858\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6925\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.8400\n",
      "train error: \n",
      " D loss: 1.344804, G loss: 0.708240, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327876, G loss: 0.711137, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.7317\n",
      "[84/1762] D loss: 1.3950, G loss: 0.7128\n",
      "[164/1762] D loss: 1.6975, G loss: 0.9767\n",
      "[244/1762] D loss: 1.4165, G loss: 0.8381\n",
      "[324/1762] D loss: 1.4372, G loss: 0.7581\n",
      "[404/1762] D loss: 0.7089, G loss: 1.0710\n",
      "[484/1762] D loss: 1.3890, G loss: 0.7108\n",
      "[564/1762] D loss: 1.3129, G loss: 1.6293\n",
      "[644/1762] D loss: 1.4152, G loss: 0.6564\n",
      "[724/1762] D loss: 1.4063, G loss: 0.6785\n",
      "[804/1762] D loss: 1.3894, G loss: 0.6883\n",
      "[884/1762] D loss: 1.3902, G loss: 0.7130\n",
      "[964/1762] D loss: 1.3893, G loss: 0.6884\n",
      "[1044/1762] D loss: 0.6239, G loss: 1.6044\n",
      "[1124/1762] D loss: 1.4106, G loss: 0.5811\n",
      "[1204/1762] D loss: 1.3914, G loss: 0.6905\n",
      "[1284/1762] D loss: 0.4932, G loss: 1.3420\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.6909\n",
      "[1444/1762] D loss: 0.4474, G loss: 1.3531\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.7012\n",
      "[1604/1762] D loss: 1.3729, G loss: 0.6814\n",
      "[1684/1762] D loss: 1.5597, G loss: 0.6957\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6960\n",
      "train error: \n",
      " D loss: 1.355429, G loss: 0.619077, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339446, G loss: 0.620205, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.7154\n",
      "[84/1762] D loss: 0.4245, G loss: 1.5063\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7087\n",
      "[244/1762] D loss: 1.3926, G loss: 0.6992\n",
      "[324/1762] D loss: 1.4216, G loss: 0.7422\n",
      "[404/1762] D loss: 0.7366, G loss: 1.1182\n",
      "[484/1762] D loss: 0.3410, G loss: 1.7574\n",
      "[564/1762] D loss: 0.3320, G loss: 1.6976\n",
      "[644/1762] D loss: 2.3966, G loss: 1.4234\n",
      "[724/1762] D loss: 1.3971, G loss: 0.7116\n",
      "[804/1762] D loss: 1.0640, G loss: 1.0553\n",
      "[884/1762] D loss: 1.4590, G loss: 0.7619\n",
      "[964/1762] D loss: 0.3197, G loss: 1.6378\n",
      "[1044/1762] D loss: 1.3915, G loss: 0.7011\n",
      "[1124/1762] D loss: 1.4100, G loss: 0.7429\n",
      "[1204/1762] D loss: 1.4134, G loss: 0.7485\n",
      "[1284/1762] D loss: 1.3994, G loss: 0.6720\n",
      "[1364/1762] D loss: 0.3534, G loss: 1.6577\n",
      "[1444/1762] D loss: 0.4873, G loss: 1.5597\n",
      "[1524/1762] D loss: 1.4039, G loss: 0.6881\n",
      "[1604/1762] D loss: 0.5057, G loss: 1.3476\n",
      "[1684/1762] D loss: 1.4031, G loss: 0.7092\n",
      "[1762/1762] D loss: 1.3977, G loss: 0.7071\n",
      "train error: \n",
      " D loss: 1.293690, G loss: 0.831486, D accuracy: 55.4%, cell accuracy: 99.6%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264945, G loss: 0.858135, D accuracy: 57.3%, cell accuracy: 99.5%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4313, G loss: 0.6708\n",
      "[84/1762] D loss: 1.4637, G loss: 0.7263\n",
      "[164/1762] D loss: 0.5596, G loss: 1.3779\n",
      "[244/1762] D loss: 0.6665, G loss: 1.3528\n",
      "[324/1762] D loss: 0.6383, G loss: 1.2415\n",
      "[404/1762] D loss: 1.4008, G loss: 0.6805\n",
      "[484/1762] D loss: 1.3984, G loss: 0.6797\n",
      "[564/1762] D loss: 0.6734, G loss: 1.2571\n",
      "[644/1762] D loss: 1.3855, G loss: 0.7068\n",
      "[724/1762] D loss: 1.4001, G loss: 0.6855\n",
      "[804/1762] D loss: 0.3890, G loss: 1.7062\n",
      "[884/1762] D loss: 0.9330, G loss: 1.0529\n",
      "[964/1762] D loss: 1.4144, G loss: 0.7351\n",
      "[1044/1762] D loss: 0.6780, G loss: 1.2967\n",
      "[1124/1762] D loss: 1.8823, G loss: 0.9622\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7050\n",
      "[1284/1762] D loss: 1.4162, G loss: 0.7101\n",
      "[1364/1762] D loss: 0.6525, G loss: 1.3588\n",
      "[1444/1762] D loss: 1.3948, G loss: 0.7041\n",
      "[1524/1762] D loss: 1.4049, G loss: 0.7273\n",
      "[1604/1762] D loss: 1.5508, G loss: 0.8481\n",
      "[1684/1762] D loss: 0.7539, G loss: 1.3598\n",
      "[1762/1762] D loss: 1.3906, G loss: 0.7006\n",
      "train error: \n",
      " D loss: 1.501169, G loss: 1.188125, D accuracy: 51.8%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.497293, G loss: 1.205475, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.6922\n",
      "[84/1762] D loss: 1.3925, G loss: 0.6973\n",
      "[164/1762] D loss: 1.3977, G loss: 0.6941\n",
      "[244/1762] D loss: 1.3909, G loss: 0.6792\n",
      "[324/1762] D loss: 1.3913, G loss: 0.6893\n",
      "[404/1762] D loss: 1.4026, G loss: 0.6876\n",
      "[484/1762] D loss: 1.4030, G loss: 0.7052\n",
      "[564/1762] D loss: 1.6120, G loss: 0.6298\n",
      "[644/1762] D loss: 1.3859, G loss: 0.6946\n",
      "[724/1762] D loss: 0.2937, G loss: 1.8773\n",
      "[804/1762] D loss: 1.6422, G loss: 1.1802\n",
      "[884/1762] D loss: 1.3940, G loss: 0.7284\n",
      "[964/1762] D loss: 1.3843, G loss: 0.6983\n",
      "[1044/1762] D loss: 1.7157, G loss: 0.8867\n",
      "[1124/1762] D loss: 0.5242, G loss: 1.5679\n",
      "[1204/1762] D loss: 1.3724, G loss: 0.7340\n",
      "[1284/1762] D loss: 0.2220, G loss: 1.9470\n",
      "[1364/1762] D loss: 1.4161, G loss: 0.7232\n",
      "[1444/1762] D loss: 1.3980, G loss: 0.6964\n",
      "[1524/1762] D loss: 0.3411, G loss: 1.6330\n",
      "[1604/1762] D loss: 1.4907, G loss: 0.8210\n",
      "[1684/1762] D loss: 1.4117, G loss: 0.7070\n",
      "[1762/1762] D loss: 1.4779, G loss: 0.7473\n",
      "train error: \n",
      " D loss: 1.360870, G loss: 0.588491, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339808, G loss: 0.606757, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4371, G loss: 0.7377\n",
      "[84/1762] D loss: 1.4051, G loss: 0.7303\n",
      "[164/1762] D loss: 1.3916, G loss: 0.6989\n",
      "[244/1762] D loss: 1.3938, G loss: 0.6825\n",
      "[324/1762] D loss: 1.5891, G loss: 0.7958\n",
      "[404/1762] D loss: 1.3891, G loss: 0.7022\n",
      "[484/1762] D loss: 1.3927, G loss: 0.7100\n",
      "[564/1762] D loss: 0.5561, G loss: 1.3955\n",
      "[644/1762] D loss: 1.3930, G loss: 0.6991\n",
      "[724/1762] D loss: 1.3891, G loss: 0.6966\n",
      "[804/1762] D loss: 1.4253, G loss: 0.7088\n",
      "[884/1762] D loss: 0.2009, G loss: 1.9354\n",
      "[964/1762] D loss: 1.3932, G loss: 0.7159\n",
      "[1044/1762] D loss: 1.3827, G loss: 0.7228\n",
      "[1124/1762] D loss: 1.3528, G loss: 0.7341\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.7047\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.7028\n",
      "[1364/1762] D loss: 1.3947, G loss: 0.6976\n",
      "[1444/1762] D loss: 1.5378, G loss: 0.7349\n",
      "[1524/1762] D loss: 1.4039, G loss: 0.7289\n",
      "[1604/1762] D loss: 1.4202, G loss: 0.7456\n",
      "[1684/1762] D loss: 0.1975, G loss: 1.8822\n",
      "[1762/1762] D loss: 1.4197, G loss: 0.7292\n",
      "train error: \n",
      " D loss: 1.325600, G loss: 0.769115, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304316, G loss: 0.793192, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4183, G loss: 0.7409\n",
      "[84/1762] D loss: 1.4141, G loss: 0.6846\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6922\n",
      "[244/1762] D loss: 0.3965, G loss: 1.6575\n",
      "[324/1762] D loss: 1.3764, G loss: 0.7216\n",
      "[404/1762] D loss: 1.4014, G loss: 0.7239\n",
      "[484/1762] D loss: 1.4473, G loss: 0.7387\n",
      "[564/1762] D loss: 1.3919, G loss: 0.6920\n",
      "[644/1762] D loss: 1.4379, G loss: 0.7156\n",
      "[724/1762] D loss: 0.9365, G loss: 1.1530\n",
      "[804/1762] D loss: 1.4078, G loss: 0.7175\n",
      "[884/1762] D loss: 0.3907, G loss: 1.7906\n",
      "[964/1762] D loss: 1.4211, G loss: 0.7306\n",
      "[1044/1762] D loss: 1.3860, G loss: 0.6943\n",
      "[1124/1762] D loss: 1.4570, G loss: 0.7339\n",
      "[1204/1762] D loss: 1.3470, G loss: 1.0985\n",
      "[1284/1762] D loss: 0.2080, G loss: 2.2228\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.6923\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.7030\n",
      "[1524/1762] D loss: 0.2763, G loss: 1.8953\n",
      "[1604/1762] D loss: 1.3936, G loss: 0.6880\n",
      "[1684/1762] D loss: 1.4539, G loss: 0.7842\n",
      "[1762/1762] D loss: 0.1823, G loss: 2.2531\n",
      "train error: \n",
      " D loss: 1.397287, G loss: 1.051053, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373050, G loss: 1.065885, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3841, G loss: 0.7493\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6912\n",
      "[164/1762] D loss: 0.2616, G loss: 1.7805\n",
      "[244/1762] D loss: 1.4030, G loss: 0.7104\n",
      "[324/1762] D loss: 1.3922, G loss: 0.7060\n",
      "[404/1762] D loss: 1.4479, G loss: 0.6583\n",
      "[484/1762] D loss: 0.3584, G loss: 1.5880\n",
      "[564/1762] D loss: 1.4089, G loss: 0.7035\n",
      "[644/1762] D loss: 0.4122, G loss: 1.5668\n",
      "[724/1762] D loss: 0.3787, G loss: 1.5958\n",
      "[804/1762] D loss: 1.4031, G loss: 0.7286\n",
      "[884/1762] D loss: 0.5327, G loss: 1.4790\n",
      "[964/1762] D loss: 0.7512, G loss: 1.1368\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.6804\n",
      "[1124/1762] D loss: 0.3534, G loss: 1.5881\n",
      "[1204/1762] D loss: 1.3944, G loss: 0.7390\n",
      "[1284/1762] D loss: 1.5473, G loss: 0.6798\n",
      "[1364/1762] D loss: 1.0292, G loss: 1.0612\n",
      "[1444/1762] D loss: 1.5171, G loss: 0.8354\n",
      "[1524/1762] D loss: 0.5877, G loss: 1.2105\n",
      "[1604/1762] D loss: 1.4145, G loss: 0.7299\n",
      "[1684/1762] D loss: 1.4518, G loss: 0.7720\n",
      "[1762/1762] D loss: 1.3999, G loss: 0.7078\n",
      "train error: \n",
      " D loss: 1.331891, G loss: 0.694587, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314738, G loss: 0.699343, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4079, G loss: 0.7428\n",
      "[84/1762] D loss: 0.4750, G loss: 1.3642\n",
      "[164/1762] D loss: 0.4149, G loss: 1.4903\n",
      "[244/1762] D loss: 0.5507, G loss: 1.2290\n",
      "[324/1762] D loss: 1.3291, G loss: 0.7966\n",
      "[404/1762] D loss: 1.4356, G loss: 0.8056\n",
      "[484/1762] D loss: 1.3904, G loss: 0.7082\n",
      "[564/1762] D loss: 1.3950, G loss: 0.6975\n",
      "[644/1762] D loss: 1.4376, G loss: 0.6690\n",
      "[724/1762] D loss: 1.4190, G loss: 0.7330\n",
      "[804/1762] D loss: 1.5694, G loss: 0.7713\n",
      "[884/1762] D loss: 1.3907, G loss: 0.6757\n",
      "[964/1762] D loss: 1.5297, G loss: 0.8782\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.6663\n",
      "[1124/1762] D loss: 1.3915, G loss: 0.6888\n",
      "[1204/1762] D loss: 0.4119, G loss: 1.3428\n",
      "[1284/1762] D loss: 1.3687, G loss: 0.7260\n",
      "[1364/1762] D loss: 0.3507, G loss: 1.5404\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.6659\n",
      "[1524/1762] D loss: 1.3902, G loss: 0.6830\n",
      "[1604/1762] D loss: 1.3981, G loss: 0.6849\n",
      "[1684/1762] D loss: 1.4023, G loss: 0.7380\n",
      "[1762/1762] D loss: 1.4345, G loss: 0.7698\n",
      "train error: \n",
      " D loss: 1.324479, G loss: 0.701259, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306166, G loss: 0.705818, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6961\n",
      "[84/1762] D loss: 1.4789, G loss: 0.8469\n",
      "[164/1762] D loss: 1.3937, G loss: 0.6740\n",
      "[244/1762] D loss: 1.3932, G loss: 0.6679\n",
      "[324/1762] D loss: 1.3629, G loss: 0.7229\n",
      "[404/1762] D loss: 1.4042, G loss: 0.6691\n",
      "[484/1762] D loss: 1.3908, G loss: 0.6889\n",
      "[564/1762] D loss: 1.3922, G loss: 0.6831\n",
      "[644/1762] D loss: 1.3942, G loss: 0.6745\n",
      "[724/1762] D loss: 1.3552, G loss: 0.7165\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6854\n",
      "[884/1762] D loss: 1.4046, G loss: 0.6561\n",
      "[964/1762] D loss: 1.4498, G loss: 0.7741\n",
      "[1044/1762] D loss: 1.3329, G loss: 1.1287\n",
      "[1124/1762] D loss: 1.4350, G loss: 0.7682\n",
      "[1204/1762] D loss: 1.3769, G loss: 1.3332\n",
      "[1284/1762] D loss: 1.4290, G loss: 0.6339\n",
      "[1364/1762] D loss: 1.4523, G loss: 0.7427\n",
      "[1444/1762] D loss: 1.3900, G loss: 0.6795\n",
      "[1524/1762] D loss: 0.3180, G loss: 1.6505\n",
      "[1604/1762] D loss: 0.7717, G loss: 1.2970\n",
      "[1684/1762] D loss: 0.2329, G loss: 1.9900\n",
      "[1762/1762] D loss: 0.1686, G loss: 2.2195\n",
      "train error: \n",
      " D loss: 2.275588, G loss: 0.155703, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.238873, G loss: 0.169154, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4406, G loss: 0.7711\n",
      "[84/1762] D loss: 1.4676, G loss: 0.7887\n",
      "[164/1762] D loss: 1.4967, G loss: 0.7796\n",
      "[244/1762] D loss: 1.8267, G loss: 0.9360\n",
      "[324/1762] D loss: 1.3897, G loss: 0.7136\n",
      "[404/1762] D loss: 0.4884, G loss: 1.2769\n",
      "[484/1762] D loss: 1.3902, G loss: 0.6937\n",
      "[564/1762] D loss: 1.3963, G loss: 0.7316\n",
      "[644/1762] D loss: 0.6306, G loss: 1.0887\n",
      "[724/1762] D loss: 1.4181, G loss: 0.7184\n",
      "[804/1762] D loss: 0.4831, G loss: 1.2771\n",
      "[884/1762] D loss: 1.4035, G loss: 0.8117\n",
      "[964/1762] D loss: 1.3910, G loss: 0.6815\n",
      "[1044/1762] D loss: 0.4243, G loss: 1.4824\n",
      "[1124/1762] D loss: 1.4000, G loss: 0.7063\n",
      "[1204/1762] D loss: 1.3931, G loss: 0.7175\n",
      "[1284/1762] D loss: 0.2590, G loss: 1.7547\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.6927\n",
      "[1444/1762] D loss: 2.2191, G loss: 1.6477\n",
      "[1524/1762] D loss: 1.4063, G loss: 0.7492\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.6971\n",
      "[1684/1762] D loss: 1.4373, G loss: 0.8032\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6943\n",
      "train error: \n",
      " D loss: 1.322219, G loss: 0.696317, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302455, G loss: 0.709337, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.7203\n",
      "[84/1762] D loss: 0.4297, G loss: 1.4416\n",
      "[164/1762] D loss: 1.4545, G loss: 0.7992\n",
      "[244/1762] D loss: 1.3948, G loss: 0.7218\n",
      "[324/1762] D loss: 0.4608, G loss: 1.3316\n",
      "[404/1762] D loss: 0.4179, G loss: 1.4583\n",
      "[484/1762] D loss: 1.3913, G loss: 0.7166\n",
      "[564/1762] D loss: 1.3950, G loss: 0.7368\n",
      "[644/1762] D loss: 1.4035, G loss: 0.6564\n",
      "[724/1762] D loss: 1.4243, G loss: 0.7561\n",
      "[804/1762] D loss: 1.4068, G loss: 0.7047\n",
      "[884/1762] D loss: 1.3945, G loss: 0.6946\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6838\n",
      "[1044/1762] D loss: 0.3952, G loss: 1.5094\n",
      "[1124/1762] D loss: 1.3946, G loss: 0.7122\n",
      "[1204/1762] D loss: 1.3961, G loss: 0.6978\n",
      "[1284/1762] D loss: 0.3529, G loss: 1.6651\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6888\n",
      "[1444/1762] D loss: 0.4138, G loss: 1.5987\n",
      "[1524/1762] D loss: 1.4188, G loss: 0.7234\n",
      "[1604/1762] D loss: 0.3712, G loss: 1.5809\n",
      "[1684/1762] D loss: 0.8234, G loss: 0.8813\n",
      "[1762/1762] D loss: 1.3923, G loss: 0.7165\n",
      "train error: \n",
      " D loss: 1.351671, G loss: 0.742894, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330782, G loss: 0.762965, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4419, G loss: 0.7168\n",
      "[84/1762] D loss: 0.6960, G loss: 1.4242\n",
      "[164/1762] D loss: 1.4463, G loss: 0.8085\n",
      "[244/1762] D loss: 1.5303, G loss: 0.8941\n",
      "[324/1762] D loss: 1.4233, G loss: 0.7247\n",
      "[404/1762] D loss: 1.1777, G loss: 0.9498\n",
      "[484/1762] D loss: 0.5894, G loss: 1.3490\n",
      "[564/1762] D loss: 1.3664, G loss: 0.7113\n",
      "[644/1762] D loss: 0.4695, G loss: 1.5485\n",
      "[724/1762] D loss: 1.4113, G loss: 0.6174\n",
      "[804/1762] D loss: 0.3263, G loss: 1.7570\n",
      "[884/1762] D loss: 1.3683, G loss: 0.7419\n",
      "[964/1762] D loss: 1.4172, G loss: 0.7148\n",
      "[1044/1762] D loss: 1.4605, G loss: 0.7082\n",
      "[1124/1762] D loss: 1.4255, G loss: 0.6919\n",
      "[1204/1762] D loss: 0.1754, G loss: 2.1816\n",
      "[1284/1762] D loss: 1.3926, G loss: 0.7221\n",
      "[1364/1762] D loss: 1.4164, G loss: 0.6952\n",
      "[1444/1762] D loss: 1.4242, G loss: 0.6689\n",
      "[1524/1762] D loss: 1.3654, G loss: 0.7293\n",
      "[1604/1762] D loss: 0.4398, G loss: 1.6544\n",
      "[1684/1762] D loss: 1.4020, G loss: 0.6949\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6916\n",
      "train error: \n",
      " D loss: 1.315457, G loss: 0.727200, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295336, G loss: 0.738548, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3906, G loss: 0.6995\n",
      "[84/1762] D loss: 1.4279, G loss: 0.6494\n",
      "[164/1762] D loss: 0.3584, G loss: 1.5474\n",
      "[244/1762] D loss: 1.4032, G loss: 0.6999\n",
      "[324/1762] D loss: 1.3928, G loss: 0.6652\n",
      "[404/1762] D loss: 1.3995, G loss: 0.6988\n",
      "[484/1762] D loss: 1.3963, G loss: 0.6841\n",
      "[564/1762] D loss: 1.3921, G loss: 0.6992\n",
      "[644/1762] D loss: 1.3900, G loss: 0.7809\n",
      "[724/1762] D loss: 1.4081, G loss: 0.7215\n",
      "[804/1762] D loss: 1.3962, G loss: 0.6948\n",
      "[884/1762] D loss: 1.3997, G loss: 0.7078\n",
      "[964/1762] D loss: 1.4039, G loss: 0.6672\n",
      "[1044/1762] D loss: 1.4102, G loss: 0.7364\n",
      "[1124/1762] D loss: 0.4493, G loss: 1.5599\n",
      "[1204/1762] D loss: 0.5077, G loss: 1.5426\n",
      "[1284/1762] D loss: 1.3947, G loss: 0.6755\n",
      "[1364/1762] D loss: 1.4322, G loss: 0.6987\n",
      "[1444/1762] D loss: 0.3306, G loss: 1.7060\n",
      "[1524/1762] D loss: 1.3960, G loss: 0.6983\n",
      "[1604/1762] D loss: 0.3436, G loss: 1.7309\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.6881\n",
      "[1762/1762] D loss: 1.4362, G loss: 0.7109\n",
      "train error: \n",
      " D loss: 1.372311, G loss: 0.545716, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 80.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353901, G loss: 0.552370, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 77.3% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4004, G loss: 0.8435\n",
      "[84/1762] D loss: 1.3445, G loss: 0.7969\n",
      "[164/1762] D loss: 1.2705, G loss: 0.7704\n",
      "[244/1762] D loss: 1.0908, G loss: 0.8779\n",
      "[324/1762] D loss: 0.9045, G loss: 0.9841\n",
      "[404/1762] D loss: 0.4900, G loss: 1.6259\n",
      "[484/1762] D loss: 0.5852, G loss: 1.5091\n",
      "[564/1762] D loss: 1.3138, G loss: 1.0230\n",
      "[644/1762] D loss: 0.6725, G loss: 1.1593\n",
      "[724/1762] D loss: 0.9404, G loss: 0.7708\n",
      "[804/1762] D loss: 1.1698, G loss: 1.7121\n",
      "[884/1762] D loss: 1.0419, G loss: 0.7241\n",
      "[964/1762] D loss: 1.1527, G loss: 0.7287\n",
      "[1044/1762] D loss: 1.1859, G loss: 0.5692\n",
      "[1124/1762] D loss: 1.3159, G loss: 0.8437\n",
      "[1204/1762] D loss: 1.1560, G loss: 0.7984\n",
      "[1284/1762] D loss: 1.2158, G loss: 1.1805\n",
      "[1364/1762] D loss: 1.3386, G loss: 0.6692\n",
      "[1444/1762] D loss: 1.2982, G loss: 0.7762\n",
      "[1524/1762] D loss: 1.2028, G loss: 0.9538\n",
      "[1604/1762] D loss: 1.3660, G loss: 0.6154\n",
      "[1684/1762] D loss: 1.5264, G loss: 0.4087\n",
      "[1762/1762] D loss: 1.4156, G loss: 0.4851\n",
      "train error: \n",
      " D loss: 1.489845, G loss: 0.443206, D accuracy: 52.2%, cell accuracy: 99.7%, board accuracy: 76.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.477467, G loss: 0.449876, D accuracy: 51.7%, cell accuracy: 99.6%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4698, G loss: 0.8725\n",
      "[84/1762] D loss: 1.2363, G loss: 0.6323\n",
      "[164/1762] D loss: 1.2836, G loss: 0.8518\n",
      "[244/1762] D loss: 1.3223, G loss: 0.6972\n",
      "[324/1762] D loss: 1.3133, G loss: 0.8747\n",
      "[404/1762] D loss: 1.3516, G loss: 0.6893\n",
      "[484/1762] D loss: 1.3674, G loss: 0.8341\n",
      "[564/1762] D loss: 1.2763, G loss: 0.9455\n",
      "[644/1762] D loss: 1.3193, G loss: 0.8195\n",
      "[724/1762] D loss: 1.4203, G loss: 0.7088\n",
      "[804/1762] D loss: 1.0786, G loss: 1.5036\n",
      "[884/1762] D loss: 1.3031, G loss: 0.9367\n",
      "[964/1762] D loss: 1.3943, G loss: 0.8743\n",
      "[1044/1762] D loss: 1.3503, G loss: 0.6117\n",
      "[1124/1762] D loss: 1.2807, G loss: 1.2677\n",
      "[1204/1762] D loss: 1.0981, G loss: 1.1110\n",
      "[1284/1762] D loss: 1.1603, G loss: 1.3566\n",
      "[1364/1762] D loss: 1.4483, G loss: 1.1026\n",
      "[1444/1762] D loss: 1.1064, G loss: 1.0579\n",
      "[1524/1762] D loss: 1.0399, G loss: 0.9975\n",
      "[1604/1762] D loss: 1.3200, G loss: 0.8063\n",
      "[1684/1762] D loss: 1.3852, G loss: 0.8823\n",
      "[1762/1762] D loss: 1.4486, G loss: 1.2038\n",
      "train error: \n",
      " D loss: 1.626802, G loss: 1.543888, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.618552, G loss: 1.563051, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4176, G loss: 0.5442\n",
      "[84/1762] D loss: 1.4095, G loss: 0.4655\n",
      "[164/1762] D loss: 1.3422, G loss: 0.6698\n",
      "[244/1762] D loss: 0.8261, G loss: 1.0882\n",
      "[324/1762] D loss: 1.4284, G loss: 0.8163\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7338\n",
      "[484/1762] D loss: 0.9231, G loss: 1.1219\n",
      "[564/1762] D loss: 1.4487, G loss: 0.5662\n",
      "[644/1762] D loss: 1.4606, G loss: 1.0418\n",
      "[724/1762] D loss: 1.4362, G loss: 0.5680\n",
      "[804/1762] D loss: 1.3994, G loss: 0.4929\n",
      "[884/1762] D loss: 1.4434, G loss: 1.1332\n",
      "[964/1762] D loss: 1.4340, G loss: 0.6188\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.6773\n",
      "[1124/1762] D loss: 1.0118, G loss: 1.2441\n",
      "[1204/1762] D loss: 1.3395, G loss: 0.8003\n",
      "[1284/1762] D loss: 1.6827, G loss: 0.3593\n",
      "[1364/1762] D loss: 1.2086, G loss: 0.7886\n",
      "[1444/1762] D loss: 1.0485, G loss: 1.3093\n",
      "[1524/1762] D loss: 1.3740, G loss: 0.6028\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.8341\n",
      "[1684/1762] D loss: 1.4113, G loss: 0.6254\n",
      "[1762/1762] D loss: 1.9058, G loss: 0.3712\n",
      "train error: \n",
      " D loss: 1.680039, G loss: 0.299722, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.665981, G loss: 0.303835, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4471, G loss: 0.8782\n",
      "[84/1762] D loss: 0.9882, G loss: 1.4109\n",
      "[164/1762] D loss: 0.6512, G loss: 1.7505\n",
      "[244/1762] D loss: 0.7629, G loss: 1.3360\n",
      "[324/1762] D loss: 1.8136, G loss: 1.0250\n",
      "[404/1762] D loss: 0.8735, G loss: 1.2051\n",
      "[484/1762] D loss: 1.4119, G loss: 0.6095\n",
      "[564/1762] D loss: 0.9104, G loss: 0.6644\n",
      "[644/1762] D loss: 1.4518, G loss: 0.5442\n",
      "[724/1762] D loss: 1.3975, G loss: 0.7061\n",
      "[804/1762] D loss: 0.7497, G loss: 1.4691\n",
      "[884/1762] D loss: 1.3673, G loss: 0.6906\n",
      "[964/1762] D loss: 1.3840, G loss: 0.6520\n",
      "[1044/1762] D loss: 1.3981, G loss: 0.6157\n",
      "[1124/1762] D loss: 1.9539, G loss: 1.2511\n",
      "[1204/1762] D loss: 1.3968, G loss: 0.7122\n",
      "[1284/1762] D loss: 1.4442, G loss: 0.4232\n",
      "[1364/1762] D loss: 1.3944, G loss: 0.7952\n",
      "[1444/1762] D loss: 0.7127, G loss: 1.4919\n",
      "[1524/1762] D loss: 1.4468, G loss: 0.8786\n",
      "[1604/1762] D loss: 1.4455, G loss: 0.8847\n",
      "[1684/1762] D loss: 1.4732, G loss: 0.6220\n",
      "[1762/1762] D loss: 1.5608, G loss: 0.4423\n",
      "train error: \n",
      " D loss: 1.357434, G loss: 0.654936, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342147, G loss: 0.681249, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2820, G loss: 0.8314\n",
      "[84/1762] D loss: 1.3820, G loss: 0.7964\n",
      "[164/1762] D loss: 1.7988, G loss: 0.8932\n",
      "[244/1762] D loss: 1.4209, G loss: 0.5810\n",
      "[324/1762] D loss: 0.7357, G loss: 1.1361\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6915\n",
      "[484/1762] D loss: 1.4085, G loss: 0.6245\n",
      "[564/1762] D loss: 0.4602, G loss: 2.0578\n",
      "[644/1762] D loss: 1.4003, G loss: 0.6862\n",
      "[724/1762] D loss: 1.5033, G loss: 0.6050\n",
      "[804/1762] D loss: 1.4340, G loss: 0.9900\n",
      "[884/1762] D loss: 1.4224, G loss: 0.8014\n",
      "[964/1762] D loss: 0.6306, G loss: 1.5506\n",
      "[1044/1762] D loss: 1.4097, G loss: 0.7301\n",
      "[1124/1762] D loss: 1.5420, G loss: 0.6688\n",
      "[1204/1762] D loss: 1.3944, G loss: 0.7901\n",
      "[1284/1762] D loss: 1.4087, G loss: 0.6273\n",
      "[1364/1762] D loss: 1.4459, G loss: 0.5751\n",
      "[1444/1762] D loss: 1.4189, G loss: 0.7623\n",
      "[1524/1762] D loss: 1.3990, G loss: 0.6175\n",
      "[1604/1762] D loss: 0.5120, G loss: 1.4672\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.6124\n",
      "[1762/1762] D loss: 1.4855, G loss: 0.5298\n",
      "train error: \n",
      " D loss: 1.433202, G loss: 0.479270, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416516, G loss: 0.497305, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.6705\n",
      "[84/1762] D loss: 1.4131, G loss: 0.7411\n",
      "[164/1762] D loss: 1.4182, G loss: 0.7539\n",
      "[244/1762] D loss: 1.3496, G loss: 0.7556\n",
      "[324/1762] D loss: 1.3807, G loss: 0.7490\n",
      "[404/1762] D loss: 1.4061, G loss: 0.7506\n",
      "[484/1762] D loss: 0.3871, G loss: 1.7718\n",
      "[564/1762] D loss: 1.4197, G loss: 0.5464\n",
      "[644/1762] D loss: 1.4216, G loss: 0.7482\n",
      "[724/1762] D loss: 0.4241, G loss: 1.6202\n",
      "[804/1762] D loss: 1.4397, G loss: 0.6786\n",
      "[884/1762] D loss: 0.5834, G loss: 1.5279\n",
      "[964/1762] D loss: 1.4270, G loss: 0.5867\n",
      "[1044/1762] D loss: 1.5013, G loss: 0.6378\n",
      "[1124/1762] D loss: 1.3744, G loss: 0.7511\n",
      "[1204/1762] D loss: 1.3932, G loss: 0.7372\n",
      "[1284/1762] D loss: 1.4432, G loss: 0.7902\n",
      "[1364/1762] D loss: 0.5062, G loss: 1.3104\n",
      "[1444/1762] D loss: 1.4453, G loss: 0.7553\n",
      "[1524/1762] D loss: 0.5354, G loss: 1.2367\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.6785\n",
      "[1684/1762] D loss: 1.4517, G loss: 0.8007\n",
      "[1762/1762] D loss: 1.4512, G loss: 0.6112\n",
      "train error: \n",
      " D loss: 1.605190, G loss: 0.358368, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.588787, G loss: 0.360936, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.7717\n",
      "[84/1762] D loss: 1.4060, G loss: 0.7097\n",
      "[164/1762] D loss: 1.4658, G loss: 0.8627\n",
      "[244/1762] D loss: 1.3729, G loss: 0.7258\n",
      "[324/1762] D loss: 1.4040, G loss: 0.7426\n",
      "[404/1762] D loss: 1.4791, G loss: 0.7991\n",
      "[484/1762] D loss: 0.4475, G loss: 1.3230\n",
      "[564/1762] D loss: 1.3886, G loss: 0.7207\n",
      "[644/1762] D loss: 0.4617, G loss: 1.2289\n",
      "[724/1762] D loss: 0.4468, G loss: 1.3679\n",
      "[804/1762] D loss: 1.4460, G loss: 0.8350\n",
      "[884/1762] D loss: 1.4050, G loss: 0.6899\n",
      "[964/1762] D loss: 0.4657, G loss: 1.3452\n",
      "[1044/1762] D loss: 1.4001, G loss: 0.6735\n",
      "[1124/1762] D loss: 1.4014, G loss: 0.6454\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.6410\n",
      "[1284/1762] D loss: 0.5473, G loss: 1.2612\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.7281\n",
      "[1444/1762] D loss: 0.3373, G loss: 1.6745\n",
      "[1524/1762] D loss: 1.4071, G loss: 0.7339\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.7271\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.7242\n",
      "[1762/1762] D loss: 1.3945, G loss: 0.7132\n",
      "train error: \n",
      " D loss: 1.347277, G loss: 0.764322, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335197, G loss: 0.775212, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005, G loss: 0.8036\n",
      "[84/1762] D loss: 0.4048, G loss: 1.4258\n",
      "[164/1762] D loss: 0.4733, G loss: 1.3612\n",
      "[244/1762] D loss: 1.4324, G loss: 0.7079\n",
      "[324/1762] D loss: 1.4114, G loss: 0.7008\n",
      "[404/1762] D loss: 1.4139, G loss: 0.7597\n",
      "[484/1762] D loss: 0.6053, G loss: 1.1447\n",
      "[564/1762] D loss: 1.3939, G loss: 0.7170\n",
      "[644/1762] D loss: 1.4103, G loss: 0.7393\n",
      "[724/1762] D loss: 1.3656, G loss: 0.6804\n",
      "[804/1762] D loss: 1.3891, G loss: 0.7012\n",
      "[884/1762] D loss: 1.4473, G loss: 0.7989\n",
      "[964/1762] D loss: 1.3968, G loss: 0.7690\n",
      "[1044/1762] D loss: 1.4231, G loss: 0.7690\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7015\n",
      "[1204/1762] D loss: 1.3977, G loss: 0.6549\n",
      "[1284/1762] D loss: 1.5632, G loss: 0.7211\n",
      "[1364/1762] D loss: 1.3967, G loss: 0.7239\n",
      "[1444/1762] D loss: 1.4179, G loss: 0.7723\n",
      "[1524/1762] D loss: 1.4012, G loss: 0.7340\n",
      "[1604/1762] D loss: 0.3152, G loss: 1.7813\n",
      "[1684/1762] D loss: 1.3995, G loss: 0.7548\n",
      "[1762/1762] D loss: 1.4555, G loss: 0.7837\n",
      "train error: \n",
      " D loss: 1.379966, G loss: 0.568661, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361005, G loss: 0.588389, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3956, G loss: 0.7270\n",
      "[84/1762] D loss: 0.4052, G loss: 1.4429\n",
      "[164/1762] D loss: 0.3978, G loss: 1.3905\n",
      "[244/1762] D loss: 1.3703, G loss: 0.6687\n",
      "[324/1762] D loss: 0.4649, G loss: 1.3204\n",
      "[404/1762] D loss: 1.4065, G loss: 0.7384\n",
      "[484/1762] D loss: 1.3946, G loss: 0.7596\n",
      "[564/1762] D loss: 0.4979, G loss: 1.3122\n",
      "[644/1762] D loss: 1.4079, G loss: 0.7306\n",
      "[724/1762] D loss: 1.5476, G loss: 0.7990\n",
      "[804/1762] D loss: 1.5089, G loss: 0.7876\n",
      "[884/1762] D loss: 1.4703, G loss: 0.8480\n",
      "[964/1762] D loss: 0.3911, G loss: 1.4450\n",
      "[1044/1762] D loss: 1.3827, G loss: 0.6947\n",
      "[1124/1762] D loss: 1.3811, G loss: 0.7156\n",
      "[1204/1762] D loss: 0.4883, G loss: 1.3189\n",
      "[1284/1762] D loss: 1.3836, G loss: 0.7698\n",
      "[1364/1762] D loss: 1.4170, G loss: 0.7329\n",
      "[1444/1762] D loss: 1.3458, G loss: 0.7242\n",
      "[1524/1762] D loss: 1.4392, G loss: 0.7532\n",
      "[1604/1762] D loss: 0.5150, G loss: 1.3338\n",
      "[1684/1762] D loss: 1.4442, G loss: 0.8116\n",
      "[1762/1762] D loss: 0.3280, G loss: 1.8129\n",
      "train error: \n",
      " D loss: 1.200108, G loss: 0.834126, D accuracy: 71.1%, cell accuracy: 99.1%, board accuracy: 42.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.211790, G loss: 0.814294, D accuracy: 70.8%, cell accuracy: 99.1%, board accuracy: 43.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3535, G loss: 0.7437\n",
      "[84/1762] D loss: 0.3586, G loss: 1.7144\n",
      "[164/1762] D loss: 1.4014, G loss: 0.7235\n",
      "[244/1762] D loss: 0.4634, G loss: 1.6438\n",
      "[324/1762] D loss: 1.3395, G loss: 0.6131\n",
      "[404/1762] D loss: 0.3657, G loss: 1.5972\n",
      "[484/1762] D loss: 1.4082, G loss: 0.7750\n",
      "[564/1762] D loss: 1.4379, G loss: 0.7742\n",
      "[644/1762] D loss: 0.3267, G loss: 1.8237\n",
      "[724/1762] D loss: 1.5692, G loss: 0.7645\n",
      "[804/1762] D loss: 1.0439, G loss: 2.2805\n",
      "[884/1762] D loss: 1.3069, G loss: 0.8657\n",
      "[964/1762] D loss: 0.5090, G loss: 1.4307\n",
      "[1044/1762] D loss: 1.3691, G loss: 0.9047\n",
      "[1124/1762] D loss: 0.4245, G loss: 1.3851\n",
      "[1204/1762] D loss: 0.4010, G loss: 1.5395\n",
      "[1284/1762] D loss: 1.3697, G loss: 0.7417\n",
      "[1364/1762] D loss: 1.4047, G loss: 0.7162\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.7642\n",
      "[1524/1762] D loss: 1.3413, G loss: 0.6521\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.7354\n",
      "[1684/1762] D loss: 1.3914, G loss: 0.7214\n",
      "[1762/1762] D loss: 1.3828, G loss: 0.6920\n",
      "train error: \n",
      " D loss: 1.359442, G loss: 0.690987, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351799, G loss: 0.705351, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5142, G loss: 1.2889\n",
      "[84/1762] D loss: 0.4894, G loss: 1.2168\n",
      "[164/1762] D loss: 1.4045, G loss: 0.7536\n",
      "[244/1762] D loss: 0.5229, G loss: 1.2946\n",
      "[324/1762] D loss: 1.4735, G loss: 0.8338\n",
      "[404/1762] D loss: 1.3702, G loss: 0.7348\n",
      "[484/1762] D loss: 1.3908, G loss: 0.7263\n",
      "[564/1762] D loss: 1.4577, G loss: 0.7427\n",
      "[644/1762] D loss: 0.3777, G loss: 1.5353\n",
      "[724/1762] D loss: 1.4309, G loss: 0.7556\n",
      "[804/1762] D loss: 1.0955, G loss: 1.2284\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6816\n",
      "[964/1762] D loss: 1.4189, G loss: 0.6782\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.7232\n",
      "[1124/1762] D loss: 1.3926, G loss: 0.7247\n",
      "[1204/1762] D loss: 0.3188, G loss: 1.7142\n",
      "[1284/1762] D loss: 1.6981, G loss: 0.8873\n",
      "[1364/1762] D loss: 0.4882, G loss: 1.5017\n",
      "[1444/1762] D loss: 1.4394, G loss: 0.8259\n",
      "[1524/1762] D loss: 0.2524, G loss: 1.8451\n",
      "[1604/1762] D loss: 0.4108, G loss: 1.5182\n",
      "[1684/1762] D loss: 0.4266, G loss: 1.4098\n",
      "[1762/1762] D loss: 1.4220, G loss: 0.7464\n",
      "train error: \n",
      " D loss: 1.355893, G loss: 0.767350, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349484, G loss: 0.800578, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4246, G loss: 0.7402\n",
      "[84/1762] D loss: 1.3845, G loss: 0.6997\n",
      "[164/1762] D loss: 1.3255, G loss: 0.8603\n",
      "[244/1762] D loss: 1.3907, G loss: 0.7149\n",
      "[324/1762] D loss: 1.3877, G loss: 0.7177\n",
      "[404/1762] D loss: 3.0442, G loss: 1.5127\n",
      "[484/1762] D loss: 0.6812, G loss: 1.0388\n",
      "[564/1762] D loss: 1.4015, G loss: 0.7438\n",
      "[644/1762] D loss: 1.3957, G loss: 0.7377\n",
      "[724/1762] D loss: 1.4077, G loss: 0.7575\n",
      "[804/1762] D loss: 1.3934, G loss: 0.7044\n",
      "[884/1762] D loss: 1.3356, G loss: 0.7450\n",
      "[964/1762] D loss: 1.4210, G loss: 0.6461\n",
      "[1044/1762] D loss: 1.7031, G loss: 0.7650\n",
      "[1124/1762] D loss: 0.4514, G loss: 1.3899\n",
      "[1204/1762] D loss: 0.3572, G loss: 1.5522\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.7037\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7160\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.7031\n",
      "[1524/1762] D loss: 1.3934, G loss: 0.6994\n",
      "[1604/1762] D loss: 0.4282, G loss: 1.4450\n",
      "[1684/1762] D loss: 1.4308, G loss: 0.5450\n",
      "[1762/1762] D loss: 1.3781, G loss: 0.7163\n",
      "train error: \n",
      " D loss: 1.345769, G loss: 0.702608, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327225, G loss: 0.757636, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4155, G loss: 0.7024\n",
      "[84/1762] D loss: 1.4090, G loss: 0.7310\n",
      "[164/1762] D loss: 0.2664, G loss: 1.6874\n",
      "[244/1762] D loss: 0.4026, G loss: 1.6626\n",
      "[324/1762] D loss: 1.4102, G loss: 0.7326\n",
      "[404/1762] D loss: 1.4039, G loss: 0.8257\n",
      "[484/1762] D loss: 0.3712, G loss: 1.8611\n",
      "[564/1762] D loss: 1.4289, G loss: 0.7572\n",
      "[644/1762] D loss: 1.4077, G loss: 0.7540\n",
      "[724/1762] D loss: 1.3902, G loss: 0.7067\n",
      "[804/1762] D loss: 1.3906, G loss: 0.7178\n",
      "[884/1762] D loss: 1.3853, G loss: 0.7046\n",
      "[964/1762] D loss: 1.4022, G loss: 0.7304\n",
      "[1044/1762] D loss: 1.2190, G loss: 0.9127\n",
      "[1124/1762] D loss: 1.0968, G loss: 0.9928\n",
      "[1204/1762] D loss: 0.2938, G loss: 1.5629\n",
      "[1284/1762] D loss: 1.4160, G loss: 1.4261\n",
      "[1364/1762] D loss: 1.5021, G loss: 1.2588\n",
      "[1444/1762] D loss: 1.4228, G loss: 0.7638\n",
      "[1524/1762] D loss: 1.3920, G loss: 0.6983\n",
      "[1604/1762] D loss: 1.4054, G loss: 0.7154\n",
      "[1684/1762] D loss: 0.4863, G loss: 1.4255\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.6958\n",
      "train error: \n",
      " D loss: 1.343302, G loss: 0.826998, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333671, G loss: 0.859190, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3969, G loss: 0.7246\n",
      "[84/1762] D loss: 1.3940, G loss: 0.7173\n",
      "[164/1762] D loss: 0.4367, G loss: 1.6148\n",
      "[244/1762] D loss: 1.3960, G loss: 0.7224\n",
      "[324/1762] D loss: 1.4681, G loss: 0.7490\n",
      "[404/1762] D loss: 1.4872, G loss: 0.7918\n",
      "[484/1762] D loss: 0.4138, G loss: 1.6385\n",
      "[564/1762] D loss: 1.3290, G loss: 0.6826\n",
      "[644/1762] D loss: 1.4074, G loss: 0.7803\n",
      "[724/1762] D loss: 1.4050, G loss: 0.7389\n",
      "[804/1762] D loss: 0.3905, G loss: 1.8033\n",
      "[884/1762] D loss: 1.3986, G loss: 0.7271\n",
      "[964/1762] D loss: 1.3897, G loss: 0.6992\n",
      "[1044/1762] D loss: 1.4113, G loss: 0.7458\n",
      "[1124/1762] D loss: 1.3999, G loss: 0.7095\n",
      "[1204/1762] D loss: 1.4549, G loss: 0.7122\n",
      "[1284/1762] D loss: 1.5041, G loss: 0.7539\n",
      "[1364/1762] D loss: 1.0978, G loss: 0.6736\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6989\n",
      "[1524/1762] D loss: 1.4156, G loss: 0.7566\n",
      "[1604/1762] D loss: 1.3969, G loss: 0.7147\n",
      "[1684/1762] D loss: 1.3426, G loss: 0.9895\n",
      "[1762/1762] D loss: 0.6719, G loss: 1.3286\n",
      "train error: \n",
      " D loss: 1.358120, G loss: 0.970441, D accuracy: 52.2%, cell accuracy: 98.9%, board accuracy: 34.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335741, G loss: 0.994374, D accuracy: 54.2%, cell accuracy: 98.8%, board accuracy: 31.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3559, G loss: 1.0568\n",
      "[84/1762] D loss: 1.2141, G loss: 1.0073\n",
      "[164/1762] D loss: 1.6704, G loss: 1.0676\n",
      "[244/1762] D loss: 1.6079, G loss: 0.7266\n",
      "[324/1762] D loss: 1.4635, G loss: 0.8571\n",
      "[404/1762] D loss: 1.3938, G loss: 0.6968\n",
      "[484/1762] D loss: 0.3953, G loss: 1.8468\n",
      "[564/1762] D loss: 1.4754, G loss: 0.9126\n",
      "[644/1762] D loss: 0.4346, G loss: 1.7859\n",
      "[724/1762] D loss: 1.3259, G loss: 0.6837\n",
      "[804/1762] D loss: 0.2831, G loss: 1.9327\n",
      "[884/1762] D loss: 1.4280, G loss: 0.4531\n",
      "[964/1762] D loss: 1.7037, G loss: 0.7427\n",
      "[1044/1762] D loss: 1.4185, G loss: 0.7335\n",
      "[1124/1762] D loss: 1.4210, G loss: 0.7053\n",
      "[1204/1762] D loss: 1.4139, G loss: 0.7010\n",
      "[1284/1762] D loss: 1.3695, G loss: 0.7178\n",
      "[1364/1762] D loss: 1.4434, G loss: 0.7020\n",
      "[1444/1762] D loss: 1.3512, G loss: 0.7614\n",
      "[1524/1762] D loss: 1.3972, G loss: 0.7086\n",
      "[1604/1762] D loss: 1.4104, G loss: 0.6903\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.6885\n",
      "[1762/1762] D loss: 1.4176, G loss: 0.6970\n",
      "train error: \n",
      " D loss: 1.319147, G loss: 0.836786, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308530, G loss: 0.877734, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4175, G loss: 0.7662\n",
      "[84/1762] D loss: 1.4363, G loss: 0.7316\n",
      "[164/1762] D loss: 0.3630, G loss: 1.7608\n",
      "[244/1762] D loss: 0.2270, G loss: 2.3309\n",
      "[324/1762] D loss: 1.4178, G loss: 0.7450\n",
      "[404/1762] D loss: 1.4156, G loss: 0.6841\n",
      "[484/1762] D loss: 1.4110, G loss: 0.7008\n",
      "[564/1762] D loss: 1.4360, G loss: 0.7204\n",
      "[644/1762] D loss: 1.4356, G loss: 0.7164\n",
      "[724/1762] D loss: 0.2039, G loss: 2.5961\n",
      "[804/1762] D loss: 1.4202, G loss: 0.6181\n",
      "[884/1762] D loss: 1.4491, G loss: 0.7535\n",
      "[964/1762] D loss: 1.4453, G loss: 0.6507\n",
      "[1044/1762] D loss: 1.0261, G loss: 1.1407\n",
      "[1124/1762] D loss: 1.4273, G loss: 0.6774\n",
      "[1204/1762] D loss: 1.2164, G loss: 0.8519\n",
      "[1284/1762] D loss: 1.4173, G loss: 0.7826\n",
      "[1364/1762] D loss: 1.4538, G loss: 0.6322\n",
      "[1444/1762] D loss: 1.4002, G loss: 0.6654\n",
      "[1524/1762] D loss: 1.4052, G loss: 0.6318\n",
      "[1604/1762] D loss: 1.0651, G loss: 1.1960\n",
      "[1684/1762] D loss: 1.4004, G loss: 0.6916\n",
      "[1762/1762] D loss: 1.7794, G loss: 0.9161\n",
      "train error: \n",
      " D loss: 1.507057, G loss: 1.199537, D accuracy: 50.0%, cell accuracy: 99.6%, board accuracy: 83.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.502840, G loss: 1.223771, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2706, G loss: 0.8774\n",
      "[84/1762] D loss: 0.9422, G loss: 1.4802\n",
      "[164/1762] D loss: 1.4334, G loss: 0.6645\n",
      "[244/1762] D loss: 1.3993, G loss: 0.6956\n",
      "[324/1762] D loss: 1.2553, G loss: 0.6557\n",
      "[404/1762] D loss: 1.4032, G loss: 0.6297\n",
      "[484/1762] D loss: 1.3959, G loss: 0.6770\n",
      "[564/1762] D loss: 0.2840, G loss: 1.9603\n",
      "[644/1762] D loss: 1.0110, G loss: 1.1877\n",
      "[724/1762] D loss: 0.5686, G loss: 1.5324\n",
      "[804/1762] D loss: 1.4101, G loss: 0.7036\n",
      "[884/1762] D loss: 0.3256, G loss: 2.1236\n",
      "[964/1762] D loss: 1.4765, G loss: 0.8416\n",
      "[1044/1762] D loss: 1.3463, G loss: 0.6778\n",
      "[1124/1762] D loss: 1.3577, G loss: 0.9341\n",
      "[1204/1762] D loss: 1.3516, G loss: 0.7252\n",
      "[1284/1762] D loss: 1.4115, G loss: 0.6848\n",
      "[1364/1762] D loss: 1.3720, G loss: 0.6915\n",
      "[1444/1762] D loss: 1.3374, G loss: 0.7664\n",
      "[1524/1762] D loss: 1.1681, G loss: 1.1955\n",
      "[1604/1762] D loss: 1.4199, G loss: 0.7152\n",
      "[1684/1762] D loss: 1.3978, G loss: 0.6726\n",
      "[1762/1762] D loss: 1.4548, G loss: 1.2979\n",
      "train error: \n",
      " D loss: 1.486261, G loss: 0.490484, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.476796, G loss: 0.509902, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4155, G loss: 0.7774\n",
      "[84/1762] D loss: 1.3917, G loss: 0.6609\n",
      "[164/1762] D loss: 1.3903, G loss: 0.6946\n",
      "[244/1762] D loss: 1.3911, G loss: 0.7084\n",
      "[324/1762] D loss: 1.3925, G loss: 0.6825\n",
      "[404/1762] D loss: 1.4013, G loss: 0.6547\n",
      "[484/1762] D loss: 1.4520, G loss: 0.6444\n",
      "[564/1762] D loss: 1.2910, G loss: 0.9087\n",
      "[644/1762] D loss: 1.1381, G loss: 1.0227\n",
      "[724/1762] D loss: 1.3989, G loss: 0.7714\n",
      "[804/1762] D loss: 1.2761, G loss: 0.7565\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6687\n",
      "[964/1762] D loss: 1.7216, G loss: 0.7648\n",
      "[1044/1762] D loss: 1.2620, G loss: 0.8240\n",
      "[1124/1762] D loss: 1.3770, G loss: 0.6793\n",
      "[1204/1762] D loss: 1.3591, G loss: 0.7627\n",
      "[1284/1762] D loss: 1.3855, G loss: 0.6682\n",
      "[1364/1762] D loss: 1.4507, G loss: 0.7363\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6913\n",
      "[1524/1762] D loss: 1.3745, G loss: 0.6972\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.6934\n",
      "[1684/1762] D loss: 1.3763, G loss: 0.6774\n",
      "[1762/1762] D loss: 1.3952, G loss: 0.6602\n",
      "train error: \n",
      " D loss: 1.371169, G loss: 0.693897, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369586, G loss: 0.701290, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2879, G loss: 0.7196\n",
      "[84/1762] D loss: 1.3660, G loss: 1.0472\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7121\n",
      "[244/1762] D loss: 1.3860, G loss: 0.6913\n",
      "[324/1762] D loss: 1.2935, G loss: 0.8525\n",
      "[404/1762] D loss: 1.3966, G loss: 0.7744\n",
      "[484/1762] D loss: 1.3888, G loss: 0.6652\n",
      "[564/1762] D loss: 1.3976, G loss: 0.7237\n",
      "[644/1762] D loss: 1.3818, G loss: 0.6684\n",
      "[724/1762] D loss: 1.3836, G loss: 0.6891\n",
      "[804/1762] D loss: 1.3861, G loss: 0.6953\n",
      "[884/1762] D loss: 1.3955, G loss: 0.7314\n",
      "[964/1762] D loss: 1.3988, G loss: 1.9096\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.6965\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.6585\n",
      "[1204/1762] D loss: 1.4292, G loss: 0.6421\n",
      "[1284/1762] D loss: 1.3684, G loss: 0.6199\n",
      "[1364/1762] D loss: 1.3958, G loss: 0.6572\n",
      "[1444/1762] D loss: 1.3973, G loss: 0.6958\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.7070\n",
      "[1604/1762] D loss: 1.3923, G loss: 0.6576\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.6813\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7090\n",
      "train error: \n",
      " D loss: 1.435147, G loss: 0.630795, D accuracy: 56.4%, cell accuracy: 99.6%, board accuracy: 76.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.452796, G loss: 0.624966, D accuracy: 56.6%, cell accuracy: 99.5%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6156, G loss: 1.0710\n",
      "[84/1762] D loss: 1.3893, G loss: 0.7151\n",
      "[164/1762] D loss: 1.2340, G loss: 1.0344\n",
      "[244/1762] D loss: 1.2544, G loss: 0.7379\n",
      "[324/1762] D loss: 1.3946, G loss: 0.7003\n",
      "[404/1762] D loss: 1.3797, G loss: 0.6961\n",
      "[484/1762] D loss: 1.4025, G loss: 0.7297\n",
      "[564/1762] D loss: 1.4007, G loss: 1.3797\n",
      "[644/1762] D loss: 1.5026, G loss: 0.7679\n",
      "[724/1762] D loss: 1.3885, G loss: 0.7032\n",
      "[804/1762] D loss: 1.3908, G loss: 0.6900\n",
      "[884/1762] D loss: 1.3926, G loss: 0.7028\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6744\n",
      "[1044/1762] D loss: 1.3236, G loss: 0.9248\n",
      "[1124/1762] D loss: 1.2133, G loss: 0.9320\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.6782\n",
      "[1284/1762] D loss: 1.3854, G loss: 0.9182\n",
      "[1364/1762] D loss: 1.0819, G loss: 1.4378\n",
      "[1444/1762] D loss: 1.4095, G loss: 0.7436\n",
      "[1524/1762] D loss: 1.4449, G loss: 0.6865\n",
      "[1604/1762] D loss: 1.3940, G loss: 0.6712\n",
      "[1684/1762] D loss: 1.3970, G loss: 0.6989\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.7151\n",
      "train error: \n",
      " D loss: 1.394842, G loss: 0.599085, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387387, G loss: 0.612538, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6861\n",
      "[84/1762] D loss: 1.3254, G loss: 0.8355\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6961\n",
      "[244/1762] D loss: 1.3892, G loss: 0.6827\n",
      "[324/1762] D loss: 1.3180, G loss: 0.7624\n",
      "[404/1762] D loss: 1.1202, G loss: 1.0670\n",
      "[484/1762] D loss: 1.4068, G loss: 0.7510\n",
      "[564/1762] D loss: 1.3655, G loss: 0.6644\n",
      "[644/1762] D loss: 1.4033, G loss: 0.7068\n",
      "[724/1762] D loss: 1.3928, G loss: 0.6948\n",
      "[804/1762] D loss: 1.3982, G loss: 0.6861\n",
      "[884/1762] D loss: 1.3901, G loss: 0.6885\n",
      "[964/1762] D loss: 1.2820, G loss: 0.8021\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6942\n",
      "[1124/1762] D loss: 1.4195, G loss: 0.6108\n",
      "[1204/1762] D loss: 1.3844, G loss: 0.7290\n",
      "[1284/1762] D loss: 1.3975, G loss: 0.7721\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.6899\n",
      "[1444/1762] D loss: 1.3485, G loss: 0.7574\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6845\n",
      "[1604/1762] D loss: 1.2137, G loss: 1.0081\n",
      "[1684/1762] D loss: 1.3949, G loss: 0.7315\n",
      "[1762/1762] D loss: 0.9907, G loss: 1.3439\n",
      "train error: \n",
      " D loss: 1.403236, G loss: 0.998468, D accuracy: 50.4%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397333, G loss: 1.043706, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3231, G loss: 0.7539\n",
      "[84/1762] D loss: 1.3884, G loss: 0.6927\n",
      "[164/1762] D loss: 1.4100, G loss: 0.6892\n",
      "[244/1762] D loss: 0.6921, G loss: 1.0213\n",
      "[324/1762] D loss: 1.8271, G loss: 0.7833\n",
      "[404/1762] D loss: 1.8169, G loss: 1.3192\n",
      "[484/1762] D loss: 1.3900, G loss: 0.7026\n",
      "[564/1762] D loss: 1.2747, G loss: 1.0103\n",
      "[644/1762] D loss: 1.4012, G loss: 0.6843\n",
      "[724/1762] D loss: 1.1084, G loss: 1.1311\n",
      "[804/1762] D loss: 1.3921, G loss: 0.6911\n",
      "[884/1762] D loss: 1.3987, G loss: 0.7010\n",
      "[964/1762] D loss: 1.3944, G loss: 0.6951\n",
      "[1044/1762] D loss: 1.0546, G loss: 0.9375\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.6915\n",
      "[1204/1762] D loss: 1.3943, G loss: 0.7154\n",
      "[1284/1762] D loss: 1.3535, G loss: 0.7465\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.8670\n",
      "[1444/1762] D loss: 1.3907, G loss: 0.6840\n",
      "[1524/1762] D loss: 1.4084, G loss: 0.6847\n",
      "[1604/1762] D loss: 1.4192, G loss: 0.7420\n",
      "[1684/1762] D loss: 1.4099, G loss: 0.6774\n",
      "[1762/1762] D loss: 1.4088, G loss: 0.6844\n",
      "train error: \n",
      " D loss: 1.345086, G loss: 0.776149, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338666, G loss: 0.787189, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8628, G loss: 1.4699\n",
      "[84/1762] D loss: 1.4043, G loss: 0.6990\n",
      "[164/1762] D loss: 1.4136, G loss: 0.7384\n",
      "[244/1762] D loss: 1.3921, G loss: 0.7052\n",
      "[324/1762] D loss: 1.3910, G loss: 0.6891\n",
      "[404/1762] D loss: 1.4487, G loss: 0.7529\n",
      "[484/1762] D loss: 1.4070, G loss: 0.7169\n",
      "[564/1762] D loss: 1.4002, G loss: 0.6952\n",
      "[644/1762] D loss: 1.3216, G loss: 0.6976\n",
      "[724/1762] D loss: 1.2828, G loss: 0.5281\n",
      "[804/1762] D loss: 1.3906, G loss: 0.6945\n",
      "[884/1762] D loss: 1.1465, G loss: 1.1767\n",
      "[964/1762] D loss: 1.3955, G loss: 0.7103\n",
      "[1044/1762] D loss: 1.3963, G loss: 0.6638\n",
      "[1124/1762] D loss: 1.4274, G loss: 0.9728\n",
      "[1204/1762] D loss: 1.3832, G loss: 0.7247\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.6711\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.6878\n",
      "[1444/1762] D loss: 1.3935, G loss: 0.7149\n",
      "[1524/1762] D loss: 1.3945, G loss: 0.6849\n",
      "[1604/1762] D loss: 0.9594, G loss: 1.2048\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6996\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.6895\n",
      "train error: \n",
      " D loss: 1.335479, G loss: 0.749071, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324263, G loss: 0.764028, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8802, G loss: 0.9926\n",
      "[84/1762] D loss: 1.3784, G loss: 0.7815\n",
      "[164/1762] D loss: 1.3991, G loss: 0.6885\n",
      "[244/1762] D loss: 1.3947, G loss: 0.7496\n",
      "[324/1762] D loss: 1.3918, G loss: 0.7035\n",
      "[404/1762] D loss: 1.3923, G loss: 0.7025\n",
      "[484/1762] D loss: 1.2935, G loss: 0.9302\n",
      "[564/1762] D loss: 1.3713, G loss: 0.7535\n",
      "[644/1762] D loss: 0.7832, G loss: 0.9725\n",
      "[724/1762] D loss: 1.2168, G loss: 1.0064\n",
      "[804/1762] D loss: 1.3889, G loss: 0.6864\n",
      "[884/1762] D loss: 1.3306, G loss: 0.8014\n",
      "[964/1762] D loss: 1.4031, G loss: 0.7043\n",
      "[1044/1762] D loss: 1.5333, G loss: 1.0830\n",
      "[1124/1762] D loss: 1.2156, G loss: 1.1554\n",
      "[1204/1762] D loss: 1.3988, G loss: 0.7280\n",
      "[1284/1762] D loss: 1.4266, G loss: 0.7266\n",
      "[1364/1762] D loss: 0.2916, G loss: 2.0976\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.7271\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6656\n",
      "[1604/1762] D loss: 0.2900, G loss: 1.6199\n",
      "[1684/1762] D loss: 1.4079, G loss: 0.7171\n",
      "[1762/1762] D loss: 2.0048, G loss: 1.1228\n",
      "train error: \n",
      " D loss: 1.436719, G loss: 1.033653, D accuracy: 52.3%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.427748, G loss: 1.024708, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3856, G loss: 0.6960\n",
      "[84/1762] D loss: 1.3776, G loss: 0.7269\n",
      "[164/1762] D loss: 1.3553, G loss: 0.8373\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7018\n",
      "[324/1762] D loss: 1.3898, G loss: 0.7011\n",
      "[404/1762] D loss: 1.4055, G loss: 0.6855\n",
      "[484/1762] D loss: 1.3190, G loss: 0.7569\n",
      "[564/1762] D loss: 1.4003, G loss: 0.6291\n",
      "[644/1762] D loss: 1.3934, G loss: 0.6345\n",
      "[724/1762] D loss: 1.5554, G loss: 0.6704\n",
      "[804/1762] D loss: 1.3894, G loss: 0.7088\n",
      "[884/1762] D loss: 1.4555, G loss: 0.9200\n",
      "[964/1762] D loss: 1.3908, G loss: 0.7305\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.6830\n",
      "[1124/1762] D loss: 1.4261, G loss: 0.8135\n",
      "[1204/1762] D loss: 0.7704, G loss: 1.2842\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6778\n",
      "[1364/1762] D loss: 1.4155, G loss: 0.7380\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6897\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6903\n",
      "[1604/1762] D loss: 1.3807, G loss: 0.7304\n",
      "[1684/1762] D loss: 1.3658, G loss: 0.6443\n",
      "[1762/1762] D loss: 1.3949, G loss: 0.6515\n",
      "train error: \n",
      " D loss: 1.400150, G loss: 0.706593, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.406392, G loss: 0.705375, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6764\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6808\n",
      "[164/1762] D loss: 1.3063, G loss: 0.8390\n",
      "[244/1762] D loss: 1.1320, G loss: 0.9269\n",
      "[324/1762] D loss: 1.3938, G loss: 0.6516\n",
      "[404/1762] D loss: 1.7275, G loss: 1.1031\n",
      "[484/1762] D loss: 1.3850, G loss: 0.6892\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6881\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6739\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6828\n",
      "[804/1762] D loss: 1.3931, G loss: 0.6765\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[964/1762] D loss: 1.8437, G loss: 0.8645\n",
      "[1044/1762] D loss: 0.9674, G loss: 1.0259\n",
      "[1124/1762] D loss: 1.4013, G loss: 0.6589\n",
      "[1204/1762] D loss: 1.3974, G loss: 0.6766\n",
      "[1284/1762] D loss: 1.1376, G loss: 1.0667\n",
      "[1364/1762] D loss: 1.5569, G loss: 0.8551\n",
      "[1444/1762] D loss: 1.3922, G loss: 0.7422\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.6727\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6820\n",
      "[1684/1762] D loss: 0.3597, G loss: 1.5407\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7024\n",
      "train error: \n",
      " D loss: 1.438657, G loss: 0.771556, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.442866, G loss: 0.802198, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3926, G loss: 0.7526\n",
      "[84/1762] D loss: 1.3848, G loss: 0.6798\n",
      "[164/1762] D loss: 1.0522, G loss: 0.7660\n",
      "[244/1762] D loss: 0.5611, G loss: 1.6638\n",
      "[324/1762] D loss: 1.2775, G loss: 0.9365\n",
      "[404/1762] D loss: 1.1033, G loss: 1.4550\n",
      "[484/1762] D loss: 1.1727, G loss: 1.3173\n",
      "[564/1762] D loss: 0.4631, G loss: 1.6697\n",
      "[644/1762] D loss: 1.4618, G loss: 0.5379\n",
      "[724/1762] D loss: 1.3767, G loss: 0.7306\n",
      "[804/1762] D loss: 1.3807, G loss: 0.7883\n",
      "[884/1762] D loss: 1.3958, G loss: 0.6900\n",
      "[964/1762] D loss: 1.2263, G loss: 0.8128\n",
      "[1044/1762] D loss: 1.2619, G loss: 1.3660\n",
      "[1124/1762] D loss: 1.4050, G loss: 0.6418\n",
      "[1204/1762] D loss: 1.1484, G loss: 1.4892\n",
      "[1284/1762] D loss: 1.4132, G loss: 0.7769\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6978\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.7088\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.7174\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6754\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.7144\n",
      "[1762/1762] D loss: 0.9301, G loss: 1.0569\n",
      "train error: \n",
      " D loss: 1.341624, G loss: 0.727688, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336475, G loss: 0.736480, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.7201\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6967\n",
      "[164/1762] D loss: 1.3895, G loss: 0.7358\n",
      "[244/1762] D loss: 1.3936, G loss: 0.7380\n",
      "[324/1762] D loss: 1.1913, G loss: 1.0008\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6855\n",
      "[484/1762] D loss: 0.8172, G loss: 1.1615\n",
      "[564/1762] D loss: 1.3857, G loss: 0.6918\n",
      "[644/1762] D loss: 1.4194, G loss: 0.8053\n",
      "[724/1762] D loss: 1.3921, G loss: 0.7259\n",
      "[804/1762] D loss: 1.3967, G loss: 0.7466\n",
      "[884/1762] D loss: 1.3913, G loss: 0.6731\n",
      "[964/1762] D loss: 1.3911, G loss: 0.6807\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.6737\n",
      "[1124/1762] D loss: 1.1326, G loss: 0.8374\n",
      "[1204/1762] D loss: 1.3983, G loss: 0.6867\n",
      "[1284/1762] D loss: 1.3616, G loss: 0.6963\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6950\n",
      "[1444/1762] D loss: 1.3810, G loss: 0.6944\n",
      "[1524/1762] D loss: 0.6044, G loss: 1.4507\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6997\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.7065\n",
      "[1762/1762] D loss: 1.3977, G loss: 0.6914\n",
      "train error: \n",
      " D loss: 1.369233, G loss: 0.772533, D accuracy: 51.7%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369466, G loss: 0.795744, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.6965\n",
      "[84/1762] D loss: 1.4388, G loss: 0.6886\n",
      "[164/1762] D loss: 1.3758, G loss: 0.6917\n",
      "[244/1762] D loss: 1.4043, G loss: 0.7353\n",
      "[324/1762] D loss: 0.4810, G loss: 1.4506\n",
      "[404/1762] D loss: 1.4172, G loss: 0.6909\n",
      "[484/1762] D loss: 0.6500, G loss: 1.3430\n",
      "[564/1762] D loss: 1.3979, G loss: 0.6673\n",
      "[644/1762] D loss: 1.3913, G loss: 0.6951\n",
      "[724/1762] D loss: 1.4251, G loss: 0.7062\n",
      "[804/1762] D loss: 0.7480, G loss: 1.0412\n",
      "[884/1762] D loss: 1.3915, G loss: 0.6659\n",
      "[964/1762] D loss: 1.4118, G loss: 0.6758\n",
      "[1044/1762] D loss: 0.4156, G loss: 1.3436\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6845\n",
      "[1204/1762] D loss: 1.3562, G loss: 0.8947\n",
      "[1284/1762] D loss: 1.3930, G loss: 0.7591\n",
      "[1364/1762] D loss: 1.3932, G loss: 0.7524\n",
      "[1444/1762] D loss: 1.3853, G loss: 0.6907\n",
      "[1524/1762] D loss: 1.4378, G loss: 0.7865\n",
      "[1604/1762] D loss: 0.9928, G loss: 0.8784\n",
      "[1684/1762] D loss: 1.3962, G loss: 0.7797\n",
      "[1762/1762] D loss: 1.3839, G loss: 0.6939\n",
      "train error: \n",
      " D loss: 1.329390, G loss: 0.784615, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312620, G loss: 0.825687, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9515, G loss: 1.0556\n",
      "[84/1762] D loss: 0.5190, G loss: 1.3777\n",
      "[164/1762] D loss: 1.4136, G loss: 0.7019\n",
      "[244/1762] D loss: 0.3054, G loss: 1.9040\n",
      "[324/1762] D loss: 1.4187, G loss: 0.5641\n",
      "[404/1762] D loss: 1.3909, G loss: 0.6779\n",
      "[484/1762] D loss: 1.3898, G loss: 0.7202\n",
      "[564/1762] D loss: 1.4069, G loss: 0.6845\n",
      "[644/1762] D loss: 0.8218, G loss: 0.8748\n",
      "[724/1762] D loss: 1.3918, G loss: 0.7182\n",
      "[804/1762] D loss: 1.3996, G loss: 0.6873\n",
      "[884/1762] D loss: 1.3928, G loss: 0.6906\n",
      "[964/1762] D loss: 1.3923, G loss: 0.6698\n",
      "[1044/1762] D loss: 1.4129, G loss: 0.5842\n",
      "[1124/1762] D loss: 1.4248, G loss: 0.8087\n",
      "[1204/1762] D loss: 1.4008, G loss: 0.7770\n",
      "[1284/1762] D loss: 1.4089, G loss: 0.7470\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7112\n",
      "[1444/1762] D loss: 1.4078, G loss: 0.7081\n",
      "[1524/1762] D loss: 1.3920, G loss: 0.7040\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6862\n",
      "[1684/1762] D loss: 1.0043, G loss: 1.1791\n",
      "[1762/1762] D loss: 1.3956, G loss: 0.6967\n",
      "train error: \n",
      " D loss: 1.348544, G loss: 0.802267, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323875, G loss: 0.836588, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8419, G loss: 1.1283\n",
      "[84/1762] D loss: 1.0488, G loss: 0.9308\n",
      "[164/1762] D loss: 1.3882, G loss: 0.6584\n",
      "[244/1762] D loss: 1.3927, G loss: 0.7500\n",
      "[324/1762] D loss: 1.2120, G loss: 1.0163\n",
      "[404/1762] D loss: 0.8821, G loss: 1.4133\n",
      "[484/1762] D loss: 1.3892, G loss: 0.6511\n",
      "[564/1762] D loss: 0.7039, G loss: 1.3924\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7098\n",
      "[724/1762] D loss: 1.3916, G loss: 0.6410\n",
      "[804/1762] D loss: 1.3923, G loss: 0.7006\n",
      "[884/1762] D loss: 1.3934, G loss: 0.6925\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6674\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.7008\n",
      "[1124/1762] D loss: 0.6252, G loss: 1.4679\n",
      "[1204/1762] D loss: 1.3948, G loss: 0.6773\n",
      "[1284/1762] D loss: 1.4478, G loss: 0.7325\n",
      "[1364/1762] D loss: 1.4199, G loss: 0.7489\n",
      "[1444/1762] D loss: 1.3860, G loss: 0.6898\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.6936\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6816\n",
      "[1684/1762] D loss: 1.2747, G loss: 0.9096\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.6719\n",
      "train error: \n",
      " D loss: 1.372679, G loss: 0.932280, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349171, G loss: 0.922544, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904, G loss: 0.6528\n",
      "[84/1762] D loss: 1.1402, G loss: 0.8933\n",
      "[164/1762] D loss: 1.3761, G loss: 0.6775\n",
      "[244/1762] D loss: 1.3914, G loss: 0.6827\n",
      "[324/1762] D loss: 1.3901, G loss: 0.7089\n",
      "[404/1762] D loss: 2.2001, G loss: 1.1068\n",
      "[484/1762] D loss: 1.3958, G loss: 0.6700\n",
      "[564/1762] D loss: 1.6582, G loss: 1.2446\n",
      "[644/1762] D loss: 1.3893, G loss: 0.6811\n",
      "[724/1762] D loss: 1.3910, G loss: 0.6498\n",
      "[804/1762] D loss: 1.3914, G loss: 0.6834\n",
      "[884/1762] D loss: 1.3896, G loss: 0.7193\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6863\n",
      "[1044/1762] D loss: 0.4180, G loss: 1.3789\n",
      "[1124/1762] D loss: 1.3842, G loss: 0.7043\n",
      "[1204/1762] D loss: 0.4336, G loss: 1.5808\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6890\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6776\n",
      "[1444/1762] D loss: 1.4069, G loss: 0.7362\n",
      "[1524/1762] D loss: 1.3987, G loss: 0.6374\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.6662\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6990\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6878\n",
      "train error: \n",
      " D loss: 1.348605, G loss: 0.780247, D accuracy: 52.2%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334024, G loss: 0.794319, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6893\n",
      "[84/1762] D loss: 0.2863, G loss: 1.5461\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6897\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7005\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6679\n",
      "[404/1762] D loss: 0.7610, G loss: 0.8662\n",
      "[484/1762] D loss: 1.4199, G loss: 0.8363\n",
      "[564/1762] D loss: 1.3851, G loss: 0.7045\n",
      "[644/1762] D loss: 1.4164, G loss: 0.8068\n",
      "[724/1762] D loss: 1.4983, G loss: 0.9192\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6823\n",
      "[884/1762] D loss: 1.3516, G loss: 0.8994\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7135\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6844\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.6702\n",
      "[1204/1762] D loss: 1.2622, G loss: 0.8889\n",
      "[1284/1762] D loss: 1.3888, G loss: 0.7061\n",
      "[1364/1762] D loss: 1.3896, G loss: 0.7062\n",
      "[1444/1762] D loss: 1.3902, G loss: 0.6964\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.7229\n",
      "[1604/1762] D loss: 0.6346, G loss: 0.8854\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7097\n",
      "[1762/1762] D loss: 1.3902, G loss: 0.7659\n",
      "train error: \n",
      " D loss: 1.313798, G loss: 0.830323, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292039, G loss: 0.877395, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962, G loss: 0.7644\n",
      "[84/1762] D loss: 1.4439, G loss: 0.9001\n",
      "[164/1762] D loss: 1.3964, G loss: 0.7773\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7262\n",
      "[324/1762] D loss: 1.5124, G loss: 0.8636\n",
      "[404/1762] D loss: 1.3726, G loss: 0.8394\n",
      "[484/1762] D loss: 1.3791, G loss: 0.7377\n",
      "[564/1762] D loss: 1.4048, G loss: 0.8013\n",
      "[644/1762] D loss: 1.3918, G loss: 0.8125\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7174\n",
      "[804/1762] D loss: 1.3907, G loss: 0.7445\n",
      "[884/1762] D loss: 1.4003, G loss: 0.8011\n",
      "[964/1762] D loss: 1.3902, G loss: 0.7196\n",
      "[1044/1762] D loss: 1.1830, G loss: 0.7918\n",
      "[1124/1762] D loss: 0.9325, G loss: 1.0246\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7023\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.7330\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.7097\n",
      "[1444/1762] D loss: 1.4652, G loss: 0.9213\n",
      "[1524/1762] D loss: 1.6242, G loss: 1.2564\n",
      "[1604/1762] D loss: 1.3939, G loss: 0.7171\n",
      "[1684/1762] D loss: 1.4132, G loss: 0.7001\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.6451\n",
      "train error: \n",
      " D loss: 1.337818, G loss: 0.768015, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316312, G loss: 0.789780, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3855, G loss: 0.6770\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6817\n",
      "[164/1762] D loss: 0.2818, G loss: 1.7100\n",
      "[244/1762] D loss: 1.3894, G loss: 0.6814\n",
      "[324/1762] D loss: 1.3995, G loss: 0.6854\n",
      "[404/1762] D loss: 1.3849, G loss: 0.6966\n",
      "[484/1762] D loss: 1.4828, G loss: 0.7338\n",
      "[564/1762] D loss: 1.0322, G loss: 1.2155\n",
      "[644/1762] D loss: 1.4075, G loss: 0.7229\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6962\n",
      "[804/1762] D loss: 1.3896, G loss: 0.7402\n",
      "[884/1762] D loss: 0.8537, G loss: 1.1725\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6853\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6637\n",
      "[1124/1762] D loss: 1.3969, G loss: 0.6589\n",
      "[1204/1762] D loss: 1.6776, G loss: 1.3014\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[1364/1762] D loss: 1.4306, G loss: 1.0611\n",
      "[1444/1762] D loss: 1.3853, G loss: 0.6849\n",
      "[1524/1762] D loss: 1.4189, G loss: 0.6787\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.7558\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.7066\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6785\n",
      "train error: \n",
      " D loss: 1.376715, G loss: 0.727976, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369728, G loss: 0.742371, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1277, G loss: 1.0173\n",
      "[84/1762] D loss: 1.3936, G loss: 0.7736\n",
      "[164/1762] D loss: 1.2040, G loss: 1.1001\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6710\n",
      "[324/1762] D loss: 1.3881, G loss: 0.7131\n",
      "[404/1762] D loss: 1.3915, G loss: 0.6479\n",
      "[484/1762] D loss: 1.3974, G loss: 0.7019\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6780\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6932\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7077\n",
      "[804/1762] D loss: 1.3890, G loss: 0.7187\n",
      "[884/1762] D loss: 0.3186, G loss: 1.4867\n",
      "[964/1762] D loss: 1.6755, G loss: 1.3957\n",
      "[1044/1762] D loss: 0.2158, G loss: 1.9256\n",
      "[1124/1762] D loss: 1.3937, G loss: 0.7282\n",
      "[1204/1762] D loss: 0.1924, G loss: 1.9079\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.7094\n",
      "[1364/1762] D loss: 1.0181, G loss: 1.6253\n",
      "[1444/1762] D loss: 1.7228, G loss: 1.0737\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6918\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.7409\n",
      "[1684/1762] D loss: 1.3986, G loss: 0.7921\n",
      "[1762/1762] D loss: 1.5630, G loss: 0.6375\n",
      "train error: \n",
      " D loss: 1.368052, G loss: 0.677987, D accuracy: 53.9%, cell accuracy: 99.6%, board accuracy: 68.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344071, G loss: 0.727715, D accuracy: 54.8%, cell accuracy: 99.5%, board accuracy: 67.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4412, G loss: 2.1219\n",
      "[84/1762] D loss: 1.3579, G loss: 0.8108\n",
      "[164/1762] D loss: 0.3669, G loss: 2.0429\n",
      "[244/1762] D loss: 1.3987, G loss: 0.6881\n",
      "[324/1762] D loss: 1.3961, G loss: 0.6641\n",
      "[404/1762] D loss: 1.2921, G loss: 0.8925\n",
      "[484/1762] D loss: 1.3894, G loss: 0.7378\n",
      "[564/1762] D loss: 1.4383, G loss: 0.7888\n",
      "[644/1762] D loss: 0.8154, G loss: 1.7030\n",
      "[724/1762] D loss: 1.3983, G loss: 0.6865\n",
      "[804/1762] D loss: 1.4004, G loss: 0.6282\n",
      "[884/1762] D loss: 1.4434, G loss: 0.6891\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6679\n",
      "[1044/1762] D loss: 1.3958, G loss: 0.7747\n",
      "[1124/1762] D loss: 0.5717, G loss: 1.0459\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.7422\n",
      "[1284/1762] D loss: 1.5706, G loss: 1.2601\n",
      "[1364/1762] D loss: 1.4290, G loss: 0.9771\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.6327\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.6344\n",
      "[1604/1762] D loss: 1.1808, G loss: 0.9153\n",
      "[1684/1762] D loss: 1.0794, G loss: 1.2226\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6580\n",
      "train error: \n",
      " D loss: 1.380311, G loss: 0.912958, D accuracy: 52.1%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374278, G loss: 0.936313, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7367\n",
      "[84/1762] D loss: 1.3950, G loss: 0.7058\n",
      "[164/1762] D loss: 1.3906, G loss: 0.6969\n",
      "[244/1762] D loss: 1.4835, G loss: 1.0167\n",
      "[324/1762] D loss: 1.3882, G loss: 0.6989\n",
      "[404/1762] D loss: 1.3882, G loss: 0.6828\n",
      "[484/1762] D loss: 1.3842, G loss: 0.7046\n",
      "[564/1762] D loss: 1.4086, G loss: 0.7426\n",
      "[644/1762] D loss: 1.3871, G loss: 0.7211\n",
      "[724/1762] D loss: 1.3697, G loss: 0.7515\n",
      "[804/1762] D loss: 1.1824, G loss: 0.9356\n",
      "[884/1762] D loss: 1.3898, G loss: 0.6565\n",
      "[964/1762] D loss: 1.3985, G loss: 0.7582\n",
      "[1044/1762] D loss: 1.4061, G loss: 0.7470\n",
      "[1124/1762] D loss: 1.6055, G loss: 0.8081\n",
      "[1204/1762] D loss: 1.2405, G loss: 0.6037\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6896\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6854\n",
      "[1444/1762] D loss: 1.3859, G loss: 0.7152\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6904\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6978\n",
      "[1684/1762] D loss: 1.4707, G loss: 0.6305\n",
      "[1762/1762] D loss: 0.3267, G loss: 1.3951\n",
      "train error: \n",
      " D loss: 1.396870, G loss: 0.984850, D accuracy: 51.8%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379434, G loss: 1.032168, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.7076\n",
      "[84/1762] D loss: 1.3998, G loss: 0.7604\n",
      "[164/1762] D loss: 1.4063, G loss: 0.7267\n",
      "[244/1762] D loss: 1.3880, G loss: 0.7206\n",
      "[324/1762] D loss: 1.7891, G loss: 1.2868\n",
      "[404/1762] D loss: 1.3973, G loss: 0.6585\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6756\n",
      "[564/1762] D loss: 0.7324, G loss: 1.3913\n",
      "[644/1762] D loss: 0.2986, G loss: 1.5986\n",
      "[724/1762] D loss: 1.3849, G loss: 0.7093\n",
      "[804/1762] D loss: 1.4020, G loss: 0.6858\n",
      "[884/1762] D loss: 1.3829, G loss: 0.6794\n",
      "[964/1762] D loss: 1.2007, G loss: 1.4028\n",
      "[1044/1762] D loss: 0.3981, G loss: 1.6020\n",
      "[1124/1762] D loss: 1.3950, G loss: 0.6314\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6784\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6711\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.6701\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.6478\n",
      "[1524/1762] D loss: 1.4186, G loss: 0.5257\n",
      "[1604/1762] D loss: 1.4364, G loss: 0.5401\n",
      "[1684/1762] D loss: 1.3991, G loss: 0.7257\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6889\n",
      "train error: \n",
      " D loss: 1.395523, G loss: 1.039739, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 78.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368609, G loss: 1.049173, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2668, G loss: 0.8433\n",
      "[84/1762] D loss: 0.2386, G loss: 2.2655\n",
      "[164/1762] D loss: 0.3598, G loss: 1.9736\n",
      "[244/1762] D loss: 1.4084, G loss: 0.8003\n",
      "[324/1762] D loss: 1.4206, G loss: 0.8247\n",
      "[404/1762] D loss: 1.4534, G loss: 0.8343\n",
      "[484/1762] D loss: 1.6632, G loss: 0.7775\n",
      "[564/1762] D loss: 1.3950, G loss: 0.7026\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7489\n",
      "[724/1762] D loss: 1.3889, G loss: 0.6973\n",
      "[804/1762] D loss: 1.3942, G loss: 0.6361\n",
      "[884/1762] D loss: 1.5236, G loss: 0.7887\n",
      "[964/1762] D loss: 1.4051, G loss: 0.7516\n",
      "[1044/1762] D loss: 1.4002, G loss: 0.6643\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6783\n",
      "[1204/1762] D loss: 1.4007, G loss: 0.7429\n",
      "[1284/1762] D loss: 0.2581, G loss: 2.2307\n",
      "[1364/1762] D loss: 1.3945, G loss: 0.7236\n",
      "[1444/1762] D loss: 0.6848, G loss: 0.9335\n",
      "[1524/1762] D loss: 0.3420, G loss: 2.5495\n",
      "[1604/1762] D loss: 0.3405, G loss: 2.5679\n",
      "[1684/1762] D loss: 1.4042, G loss: 0.6610\n",
      "[1762/1762] D loss: 1.3928, G loss: 0.6313\n",
      "train error: \n",
      " D loss: 1.580040, G loss: 1.329509, D accuracy: 52.7%, cell accuracy: 99.6%, board accuracy: 73.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.534998, G loss: 1.320912, D accuracy: 53.6%, cell accuracy: 99.4%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4155, G loss: 0.6485\n",
      "[84/1762] D loss: 1.3887, G loss: 0.7171\n",
      "[164/1762] D loss: 1.4408, G loss: 0.6478\n",
      "[244/1762] D loss: 1.4392, G loss: 0.7738\n",
      "[324/1762] D loss: 0.2954, G loss: 2.5611\n",
      "[404/1762] D loss: 0.5804, G loss: 1.4171\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6952\n",
      "[564/1762] D loss: 1.4020, G loss: 0.7896\n",
      "[644/1762] D loss: 1.3931, G loss: 0.7075\n",
      "[724/1762] D loss: 0.2007, G loss: 3.2153\n",
      "[804/1762] D loss: 1.5526, G loss: 0.7331\n",
      "[884/1762] D loss: 0.2424, G loss: 2.8981\n",
      "[964/1762] D loss: 1.4012, G loss: 0.6777\n",
      "[1044/1762] D loss: 1.3986, G loss: 0.6479\n",
      "[1124/1762] D loss: 0.1609, G loss: 2.9418\n",
      "[1204/1762] D loss: 1.3950, G loss: 0.6739\n",
      "[1284/1762] D loss: 1.4349, G loss: 0.7259\n",
      "[1364/1762] D loss: 0.1659, G loss: 2.4056\n",
      "[1444/1762] D loss: 1.4198, G loss: 0.5720\n",
      "[1524/1762] D loss: 1.2751, G loss: 1.3140\n",
      "[1604/1762] D loss: 0.0910, G loss: 3.1201\n",
      "[1684/1762] D loss: 0.9753, G loss: 2.1806\n",
      "[1762/1762] D loss: 1.4054, G loss: 0.6653\n",
      "train error: \n",
      " D loss: 1.464454, G loss: 0.489416, D accuracy: 52.1%, cell accuracy: 99.6%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.449372, G loss: 0.496010, D accuracy: 53.2%, cell accuracy: 99.4%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3366, G loss: 1.9194\n",
      "[84/1762] D loss: 1.4093, G loss: 0.6629\n",
      "[164/1762] D loss: 0.2236, G loss: 2.3869\n",
      "[244/1762] D loss: 1.4813, G loss: 0.7771\n",
      "[324/1762] D loss: 1.3935, G loss: 0.7112\n",
      "[404/1762] D loss: 1.3897, G loss: 0.6673\n",
      "[484/1762] D loss: 1.3885, G loss: 0.6847\n",
      "[564/1762] D loss: 0.2975, G loss: 2.8519\n",
      "[644/1762] D loss: 1.4017, G loss: 0.6330\n",
      "[724/1762] D loss: 0.4537, G loss: 2.3059\n",
      "[804/1762] D loss: 0.4015, G loss: 1.8244\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7207\n",
      "[964/1762] D loss: 1.3902, G loss: 0.7455\n",
      "[1044/1762] D loss: 1.3614, G loss: 0.8627\n",
      "[1124/1762] D loss: 1.3804, G loss: 0.7104\n",
      "[1204/1762] D loss: 1.3933, G loss: 0.6827\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7111\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6773\n",
      "[1444/1762] D loss: 1.4175, G loss: 0.5837\n",
      "[1524/1762] D loss: 0.5535, G loss: 1.3684\n",
      "[1604/1762] D loss: 0.1263, G loss: 2.7674\n",
      "[1684/1762] D loss: 0.0822, G loss: 4.1481\n",
      "[1762/1762] D loss: 0.0637, G loss: 3.9361\n",
      "train error: \n",
      " D loss: 2.319879, G loss: 3.826315, D accuracy: 50.7%, cell accuracy: 82.3%, board accuracy: 1.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.269414, G loss: 3.762848, D accuracy: 51.2%, cell accuracy: 82.3%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0484, G loss: 4.0931\n",
      "[84/1762] D loss: 0.0523, G loss: 3.8584\n",
      "[164/1762] D loss: 0.0496, G loss: 4.3060\n",
      "[244/1762] D loss: 0.0296, G loss: 4.4137\n",
      "[324/1762] D loss: 0.0192, G loss: 4.5819\n",
      "[404/1762] D loss: 0.0126, G loss: 5.0165\n",
      "[484/1762] D loss: 0.0128, G loss: 5.1875\n",
      "[564/1762] D loss: 0.0147, G loss: 4.9731\n",
      "[644/1762] D loss: 0.0113, G loss: 5.1914\n",
      "[724/1762] D loss: 0.0084, G loss: 5.3046\n",
      "[804/1762] D loss: 0.0235, G loss: 4.3679\n",
      "[884/1762] D loss: 0.0090, G loss: 5.5297\n",
      "[964/1762] D loss: 0.5744, G loss: 8.0637\n",
      "[1044/1762] D loss: 0.1306, G loss: 5.3364\n",
      "[1124/1762] D loss: 1.6072, G loss: 1.8451\n",
      "[1204/1762] D loss: 4.7922, G loss: 2.0401\n",
      "[1284/1762] D loss: 0.6674, G loss: 1.0255\n",
      "[1364/1762] D loss: 1.2061, G loss: 1.9684\n",
      "[1444/1762] D loss: 1.3943, G loss: 0.7456\n",
      "[1524/1762] D loss: 0.5054, G loss: 2.2496\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.5983\n",
      "[1684/1762] D loss: 1.4901, G loss: 0.8179\n",
      "[1762/1762] D loss: 1.3801, G loss: 0.6667\n",
      "train error: \n",
      " D loss: 1.432511, G loss: 1.346095, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416759, G loss: 1.454081, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3821, G loss: 0.7227\n",
      "[84/1762] D loss: 2.0337, G loss: 1.1102\n",
      "[164/1762] D loss: 1.3594, G loss: 0.7325\n",
      "[244/1762] D loss: 1.3916, G loss: 0.6872\n",
      "[324/1762] D loss: 1.3227, G loss: 0.7549\n",
      "[404/1762] D loss: 0.4323, G loss: 1.9910\n",
      "[484/1762] D loss: 1.4314, G loss: 0.7088\n",
      "[564/1762] D loss: 0.3393, G loss: 2.4933\n",
      "[644/1762] D loss: 1.4322, G loss: 0.7735\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6966\n",
      "[804/1762] D loss: 1.4559, G loss: 0.7293\n",
      "[884/1762] D loss: 0.1032, G loss: 3.1256\n",
      "[964/1762] D loss: 0.3872, G loss: 1.9060\n",
      "[1044/1762] D loss: 1.3627, G loss: 0.7154\n",
      "[1124/1762] D loss: 1.1934, G loss: 2.2455\n",
      "[1204/1762] D loss: 0.0539, G loss: 4.4777\n",
      "[1284/1762] D loss: 1.3403, G loss: 0.8658\n",
      "[1364/1762] D loss: 0.3288, G loss: 1.8682\n",
      "[1444/1762] D loss: 0.3669, G loss: 2.4009\n",
      "[1524/1762] D loss: 1.4410, G loss: 0.5971\n",
      "[1604/1762] D loss: 1.4336, G loss: 0.8280\n",
      "[1684/1762] D loss: 1.4216, G loss: 0.6653\n",
      "[1762/1762] D loss: 0.1955, G loss: 3.4890\n",
      "train error: \n",
      " D loss: 2.141798, G loss: 2.403759, D accuracy: 50.8%, cell accuracy: 98.9%, board accuracy: 8.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.119823, G loss: 2.372035, D accuracy: 50.7%, cell accuracy: 98.8%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4045, G loss: 2.8365\n",
      "[84/1762] D loss: 1.5870, G loss: 0.5199\n",
      "[164/1762] D loss: 0.7591, G loss: 3.3407\n",
      "[244/1762] D loss: 1.3931, G loss: 1.2366\n",
      "[324/1762] D loss: 1.4560, G loss: 0.5426\n",
      "[404/1762] D loss: 1.1717, G loss: 1.5911\n",
      "[484/1762] D loss: 1.3659, G loss: 0.8212\n",
      "[564/1762] D loss: 1.3799, G loss: 0.7278\n",
      "[644/1762] D loss: 1.4357, G loss: 0.6875\n",
      "[724/1762] D loss: 1.4003, G loss: 0.7119\n",
      "[804/1762] D loss: 1.6600, G loss: 0.7150\n",
      "[884/1762] D loss: 1.3902, G loss: 0.6799\n",
      "[964/1762] D loss: 0.2026, G loss: 3.2061\n",
      "[1044/1762] D loss: 1.4034, G loss: 0.6862\n",
      "[1124/1762] D loss: 1.4029, G loss: 0.7154\n",
      "[1204/1762] D loss: 1.4364, G loss: 0.8012\n",
      "[1284/1762] D loss: 1.3819, G loss: 0.6430\n",
      "[1364/1762] D loss: 1.4072, G loss: 0.7178\n",
      "[1444/1762] D loss: 1.3528, G loss: 0.7628\n",
      "[1524/1762] D loss: 0.5561, G loss: 2.8549\n",
      "[1604/1762] D loss: 1.4065, G loss: 0.7503\n",
      "[1684/1762] D loss: 0.0911, G loss: 3.0044\n",
      "[1762/1762] D loss: 0.4620, G loss: 2.5975\n",
      "train error: \n",
      " D loss: 2.644782, G loss: 2.006996, D accuracy: 52.1%, cell accuracy: 97.7%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.633724, G loss: 2.028179, D accuracy: 53.3%, cell accuracy: 97.7%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3567, G loss: 2.9819\n",
      "[84/1762] D loss: 0.5774, G loss: 1.6271\n",
      "[164/1762] D loss: 1.5313, G loss: 0.5223\n",
      "[244/1762] D loss: 1.4030, G loss: 0.6809\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7118\n",
      "[404/1762] D loss: 1.4105, G loss: 0.6593\n",
      "[484/1762] D loss: 0.4497, G loss: 2.4733\n",
      "[564/1762] D loss: 0.3112, G loss: 2.1012\n",
      "[644/1762] D loss: 1.4021, G loss: 0.7439\n",
      "[724/1762] D loss: 1.4041, G loss: 0.8044\n",
      "[804/1762] D loss: 1.6748, G loss: 0.7944\n",
      "[884/1762] D loss: 1.3961, G loss: 0.6450\n",
      "[964/1762] D loss: 1.4045, G loss: 0.7061\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.7018\n",
      "[1124/1762] D loss: 1.1788, G loss: 2.7575\n",
      "[1204/1762] D loss: 1.0232, G loss: 2.4490\n",
      "[1284/1762] D loss: 0.9844, G loss: 2.6947\n",
      "[1364/1762] D loss: 1.5676, G loss: 0.6702\n",
      "[1444/1762] D loss: 0.8138, G loss: 3.6209\n",
      "[1524/1762] D loss: 1.0239, G loss: 2.3878\n",
      "[1604/1762] D loss: 1.4181, G loss: 0.6881\n",
      "[1684/1762] D loss: 1.4023, G loss: 0.6614\n",
      "[1762/1762] D loss: 0.0312, G loss: 7.0890\n",
      "train error: \n",
      " D loss: 1.463342, G loss: 0.998290, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.455921, G loss: 1.047472, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9349, G loss: 2.2695\n",
      "[84/1762] D loss: 1.1183, G loss: 1.5967\n",
      "[164/1762] D loss: 1.2316, G loss: 0.9952\n",
      "[244/1762] D loss: 1.3731, G loss: 0.7076\n",
      "[324/1762] D loss: 1.5301, G loss: 0.6720\n",
      "[404/1762] D loss: 1.5476, G loss: 0.6971\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6187\n",
      "[564/1762] D loss: 1.3930, G loss: 0.7249\n",
      "[644/1762] D loss: 0.6485, G loss: 2.9370\n",
      "[724/1762] D loss: 1.3016, G loss: 0.9831\n",
      "[804/1762] D loss: 0.0738, G loss: 3.7206\n",
      "[884/1762] D loss: 1.3877, G loss: 0.6547\n",
      "[964/1762] D loss: 1.3474, G loss: 0.6680\n",
      "[1044/1762] D loss: 0.4100, G loss: 4.0636\n",
      "[1124/1762] D loss: 1.4507, G loss: 0.4964\n",
      "[1204/1762] D loss: 1.3322, G loss: 0.6313\n",
      "[1284/1762] D loss: 0.5003, G loss: 2.2500\n",
      "[1364/1762] D loss: 0.4199, G loss: 1.7071\n",
      "[1444/1762] D loss: 0.4131, G loss: 3.1036\n",
      "[1524/1762] D loss: 0.1076, G loss: 4.3500\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6794\n",
      "[1684/1762] D loss: 1.3897, G loss: 0.6729\n",
      "[1762/1762] D loss: 1.4752, G loss: 0.6748\n",
      "train error: \n",
      " D loss: 1.342501, G loss: 1.091460, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306964, G loss: 1.141231, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6837\n",
      "[84/1762] D loss: 1.4106, G loss: 0.7742\n",
      "[164/1762] D loss: 0.4373, G loss: 1.8763\n",
      "[244/1762] D loss: 1.3881, G loss: 0.7164\n",
      "[324/1762] D loss: 1.4006, G loss: 0.6718\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6956\n",
      "[484/1762] D loss: 1.5252, G loss: 0.6798\n",
      "[564/1762] D loss: 1.3904, G loss: 0.6872\n",
      "[644/1762] D loss: 1.4154, G loss: 0.7158\n",
      "[724/1762] D loss: 1.3266, G loss: 0.9779\n",
      "[804/1762] D loss: 0.2982, G loss: 3.1647\n",
      "[884/1762] D loss: 0.2283, G loss: 3.1925\n",
      "[964/1762] D loss: 0.0266, G loss: 4.3980\n",
      "[1044/1762] D loss: 1.3970, G loss: 0.6078\n",
      "[1124/1762] D loss: 0.3452, G loss: 3.0229\n",
      "[1204/1762] D loss: 1.3332, G loss: 0.9841\n",
      "[1284/1762] D loss: 0.4277, G loss: 2.6202\n",
      "[1364/1762] D loss: 1.4389, G loss: 0.7675\n",
      "[1444/1762] D loss: 0.3056, G loss: 2.8963\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7628\n",
      "[1604/1762] D loss: 1.3854, G loss: 0.7075\n",
      "[1684/1762] D loss: 0.0180, G loss: 4.7654\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.7025\n",
      "train error: \n",
      " D loss: 1.301282, G loss: 1.075984, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273929, G loss: 1.169871, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3792, G loss: 0.6973\n",
      "[84/1762] D loss: 1.3917, G loss: 0.7073\n",
      "[164/1762] D loss: 1.3857, G loss: 0.7027\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7046\n",
      "[324/1762] D loss: 1.3435, G loss: 0.7328\n",
      "[404/1762] D loss: 1.4323, G loss: 0.6910\n",
      "[484/1762] D loss: 1.3805, G loss: 0.7239\n",
      "[564/1762] D loss: 1.3968, G loss: 0.7668\n",
      "[644/1762] D loss: 0.2198, G loss: 3.2401\n",
      "[724/1762] D loss: 0.2937, G loss: 3.4828\n",
      "[804/1762] D loss: 1.3850, G loss: 0.7075\n",
      "[884/1762] D loss: 1.3884, G loss: 0.6601\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6587\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7005\n",
      "[1124/1762] D loss: 1.3938, G loss: 0.7119\n",
      "[1204/1762] D loss: 0.0123, G loss: 5.1669\n",
      "[1284/1762] D loss: 1.3959, G loss: 0.6477\n",
      "[1364/1762] D loss: 0.0515, G loss: 4.0227\n",
      "[1444/1762] D loss: 1.3930, G loss: 0.6799\n",
      "[1524/1762] D loss: 1.3984, G loss: 0.6940\n",
      "[1604/1762] D loss: 1.3960, G loss: 0.7132\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6817\n",
      "[1762/1762] D loss: 1.4222, G loss: 0.7145\n",
      "train error: \n",
      " D loss: 1.362221, G loss: 1.252884, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332437, G loss: 1.420986, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6972\n",
      "[84/1762] D loss: 1.3853, G loss: 0.7453\n",
      "[164/1762] D loss: 1.7089, G loss: 0.6898\n",
      "[244/1762] D loss: 1.4898, G loss: 0.7001\n",
      "[324/1762] D loss: 1.3884, G loss: 0.7102\n",
      "[404/1762] D loss: 1.5115, G loss: 0.7139\n",
      "[484/1762] D loss: 1.3998, G loss: 0.7314\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[644/1762] D loss: 1.4417, G loss: 0.7243\n",
      "[724/1762] D loss: 1.3678, G loss: 0.7128\n",
      "[804/1762] D loss: 1.3849, G loss: 0.6997\n",
      "[884/1762] D loss: 1.5662, G loss: 0.6509\n",
      "[964/1762] D loss: 0.1956, G loss: 3.3761\n",
      "[1044/1762] D loss: 0.0229, G loss: 5.1419\n",
      "[1124/1762] D loss: 1.2935, G loss: 1.3857\n",
      "[1204/1762] D loss: 1.4612, G loss: 0.7115\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6725\n",
      "[1364/1762] D loss: 1.5692, G loss: 0.6899\n",
      "[1444/1762] D loss: 1.4502, G loss: 0.6997\n",
      "[1524/1762] D loss: 0.2919, G loss: 3.3789\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7103\n",
      "[1684/1762] D loss: 0.1382, G loss: 5.2797\n",
      "[1762/1762] D loss: 1.3984, G loss: 0.5989\n",
      "train error: \n",
      " D loss: 2.129243, G loss: 2.105358, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 76.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.080013, G loss: 2.116252, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4201, G loss: 0.8087\n",
      "[84/1762] D loss: 0.8559, G loss: 1.1480\n",
      "[164/1762] D loss: 0.4297, G loss: 1.7034\n",
      "[244/1762] D loss: 0.3760, G loss: 2.0447\n",
      "[324/1762] D loss: 0.8494, G loss: 0.9548\n",
      "[404/1762] D loss: 1.3388, G loss: 0.4563\n",
      "[484/1762] D loss: 1.7394, G loss: 2.2097\n",
      "[564/1762] D loss: 0.7183, G loss: 1.6787\n",
      "[644/1762] D loss: 0.9117, G loss: 1.0464\n",
      "[724/1762] D loss: 1.2497, G loss: 0.6370\n",
      "[804/1762] D loss: 1.3266, G loss: 1.0276\n",
      "[884/1762] D loss: 1.2400, G loss: 0.9303\n",
      "[964/1762] D loss: 1.2103, G loss: 0.6343\n",
      "[1044/1762] D loss: 1.1103, G loss: 1.7200\n",
      "[1124/1762] D loss: 1.4904, G loss: 0.3717\n",
      "[1204/1762] D loss: 1.2904, G loss: 0.5778\n",
      "[1284/1762] D loss: 1.2749, G loss: 0.6316\n",
      "[1364/1762] D loss: 1.3450, G loss: 1.0250\n",
      "[1444/1762] D loss: 1.1540, G loss: 0.8528\n",
      "[1524/1762] D loss: 1.1368, G loss: 1.3890\n",
      "[1604/1762] D loss: 1.3711, G loss: 0.4583\n",
      "[1684/1762] D loss: 1.3247, G loss: 0.8610\n",
      "[1762/1762] D loss: 1.3034, G loss: 0.7327\n",
      "train error: \n",
      " D loss: 1.304516, G loss: 0.777536, D accuracy: 59.6%, cell accuracy: 99.7%, board accuracy: 77.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290384, G loss: 0.797381, D accuracy: 61.8%, cell accuracy: 99.6%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3290, G loss: 0.7362\n",
      "[84/1762] D loss: 1.1531, G loss: 1.4156\n",
      "[164/1762] D loss: 1.4520, G loss: 1.2940\n",
      "[244/1762] D loss: 1.0644, G loss: 1.0806\n",
      "[324/1762] D loss: 1.3911, G loss: 0.7939\n",
      "[404/1762] D loss: 1.3779, G loss: 0.6943\n",
      "[484/1762] D loss: 1.4042, G loss: 0.6672\n",
      "[564/1762] D loss: 1.3922, G loss: 0.6620\n",
      "[644/1762] D loss: 1.4018, G loss: 0.8454\n",
      "[724/1762] D loss: 1.4535, G loss: 0.4804\n",
      "[804/1762] D loss: 1.4131, G loss: 0.4557\n",
      "[884/1762] D loss: 1.3724, G loss: 0.8122\n",
      "[964/1762] D loss: 1.4093, G loss: 0.6424\n",
      "[1044/1762] D loss: 1.4923, G loss: 0.4113\n",
      "[1124/1762] D loss: 1.4047, G loss: 0.8296\n",
      "[1204/1762] D loss: 1.0842, G loss: 0.7528\n",
      "[1284/1762] D loss: 0.9768, G loss: 1.2091\n",
      "[1364/1762] D loss: 0.9093, G loss: 1.2456\n",
      "[1444/1762] D loss: 1.5403, G loss: 0.4538\n",
      "[1524/1762] D loss: 1.4202, G loss: 0.9232\n",
      "[1604/1762] D loss: 1.4729, G loss: 0.5000\n",
      "[1684/1762] D loss: 1.4034, G loss: 0.6191\n",
      "[1762/1762] D loss: 0.6788, G loss: 1.8346\n",
      "train error: \n",
      " D loss: 1.390461, G loss: 1.051547, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377579, G loss: 1.061857, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4893, G loss: 0.5204\n",
      "[84/1762] D loss: 1.4123, G loss: 0.8732\n",
      "[164/1762] D loss: 1.3270, G loss: 0.7304\n",
      "[244/1762] D loss: 1.4573, G loss: 0.9343\n",
      "[324/1762] D loss: 1.3167, G loss: 1.3066\n",
      "[404/1762] D loss: 1.4623, G loss: 0.5704\n",
      "[484/1762] D loss: 0.8230, G loss: 1.4064\n",
      "[564/1762] D loss: 1.5276, G loss: 0.5962\n",
      "[644/1762] D loss: 1.3850, G loss: 0.6550\n",
      "[724/1762] D loss: 1.3975, G loss: 0.6508\n",
      "[804/1762] D loss: 1.4972, G loss: 1.0658\n",
      "[884/1762] D loss: 1.4317, G loss: 0.5891\n",
      "[964/1762] D loss: 1.4646, G loss: 0.5308\n",
      "[1044/1762] D loss: 0.7311, G loss: 1.2633\n",
      "[1124/1762] D loss: 1.3468, G loss: 0.6777\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.6707\n",
      "[1284/1762] D loss: 0.7472, G loss: 1.7974\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6514\n",
      "[1444/1762] D loss: 0.7143, G loss: 1.4605\n",
      "[1524/1762] D loss: 1.3826, G loss: 0.6941\n",
      "[1604/1762] D loss: 0.5967, G loss: 1.6828\n",
      "[1684/1762] D loss: 1.0256, G loss: 1.4727\n",
      "[1762/1762] D loss: 1.4221, G loss: 0.6851\n",
      "train error: \n",
      " D loss: 1.379355, G loss: 0.596346, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378531, G loss: 0.602322, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3838, G loss: 0.7310\n",
      "[84/1762] D loss: 1.3896, G loss: 0.7680\n",
      "[164/1762] D loss: 1.4578, G loss: 0.8288\n",
      "[244/1762] D loss: 1.5192, G loss: 0.3998\n",
      "[324/1762] D loss: 1.4914, G loss: 0.5563\n",
      "[404/1762] D loss: 0.6204, G loss: 1.4914\n",
      "[484/1762] D loss: 1.7683, G loss: 0.8018\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7186\n",
      "[644/1762] D loss: 1.4063, G loss: 0.7467\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6771\n",
      "[804/1762] D loss: 1.3914, G loss: 0.7017\n",
      "[884/1762] D loss: 1.4992, G loss: 0.9424\n",
      "[964/1762] D loss: 1.6321, G loss: 0.7704\n",
      "[1044/1762] D loss: 1.3956, G loss: 0.6529\n",
      "[1124/1762] D loss: 1.4080, G loss: 0.7382\n",
      "[1204/1762] D loss: 1.4063, G loss: 0.7466\n",
      "[1284/1762] D loss: 1.3922, G loss: 0.7048\n",
      "[1364/1762] D loss: 0.5547, G loss: 1.5992\n",
      "[1444/1762] D loss: 1.4061, G loss: 0.7820\n",
      "[1524/1762] D loss: 0.5890, G loss: 1.5477\n",
      "[1604/1762] D loss: 0.7520, G loss: 1.6412\n",
      "[1684/1762] D loss: 0.7342, G loss: 1.5839\n",
      "[1762/1762] D loss: 0.2810, G loss: 2.1278\n",
      "train error: \n",
      " D loss: 1.326056, G loss: 0.735602, D accuracy: 56.5%, cell accuracy: 99.0%, board accuracy: 44.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318025, G loss: 0.740937, D accuracy: 55.3%, cell accuracy: 98.9%, board accuracy: 43.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3628, G loss: 1.9712\n",
      "[84/1762] D loss: 1.5240, G loss: 0.7023\n",
      "[164/1762] D loss: 1.5593, G loss: 0.6037\n",
      "[244/1762] D loss: 2.8601, G loss: 0.5555\n",
      "[324/1762] D loss: 1.3889, G loss: 0.6904\n",
      "[404/1762] D loss: 1.4489, G loss: 0.7187\n",
      "[484/1762] D loss: 0.9042, G loss: 1.2924\n",
      "[564/1762] D loss: 1.4338, G loss: 0.6880\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6988\n",
      "[724/1762] D loss: 0.7479, G loss: 1.3684\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6957\n",
      "[884/1762] D loss: 0.8636, G loss: 1.2750\n",
      "[964/1762] D loss: 1.3875, G loss: 0.5969\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.6871\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7631\n",
      "[1204/1762] D loss: 1.3838, G loss: 0.6999\n",
      "[1284/1762] D loss: 1.3811, G loss: 0.7123\n",
      "[1364/1762] D loss: 0.5312, G loss: 1.6956\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.6404\n",
      "[1524/1762] D loss: 1.5937, G loss: 0.5817\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.6977\n",
      "[1684/1762] D loss: 1.3920, G loss: 0.6897\n",
      "[1762/1762] D loss: 1.4446, G loss: 0.6032\n",
      "train error: \n",
      " D loss: 1.385969, G loss: 0.508213, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367479, G loss: 0.522748, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3954, G loss: 0.7377\n",
      "[84/1762] D loss: 1.3916, G loss: 0.7264\n",
      "[164/1762] D loss: 1.3900, G loss: 0.7746\n",
      "[244/1762] D loss: 0.4436, G loss: 2.0387\n",
      "[324/1762] D loss: 0.3399, G loss: 2.1717\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7511\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6981\n",
      "[564/1762] D loss: 1.3924, G loss: 0.6533\n",
      "[644/1762] D loss: 1.3966, G loss: 0.7238\n",
      "[724/1762] D loss: 1.4020, G loss: 0.6543\n",
      "[804/1762] D loss: 1.3974, G loss: 0.7091\n",
      "[884/1762] D loss: 1.4691, G loss: 0.6504\n",
      "[964/1762] D loss: 1.3849, G loss: 0.6873\n",
      "[1044/1762] D loss: 0.5004, G loss: 1.6948\n",
      "[1124/1762] D loss: 1.3936, G loss: 0.6730\n",
      "[1204/1762] D loss: 1.3621, G loss: 0.7277\n",
      "[1284/1762] D loss: 1.4616, G loss: 0.7134\n",
      "[1364/1762] D loss: 0.7212, G loss: 1.6743\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.7097\n",
      "[1524/1762] D loss: 0.5389, G loss: 1.6167\n",
      "[1604/1762] D loss: 1.3952, G loss: 0.6840\n",
      "[1684/1762] D loss: 1.3771, G loss: 0.7113\n",
      "[1762/1762] D loss: 1.3854, G loss: 0.6773\n",
      "train error: \n",
      " D loss: 1.403628, G loss: 0.494295, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388914, G loss: 0.513053, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4032, G loss: 0.7078\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6905\n",
      "[164/1762] D loss: 1.3977, G loss: 0.7112\n",
      "[244/1762] D loss: 1.4148, G loss: 0.7063\n",
      "[324/1762] D loss: 1.4096, G loss: 1.3378\n",
      "[404/1762] D loss: 0.6380, G loss: 1.4698\n",
      "[484/1762] D loss: 1.3815, G loss: 0.6830\n",
      "[564/1762] D loss: 1.4077, G loss: 0.6831\n",
      "[644/1762] D loss: 0.5938, G loss: 1.6503\n",
      "[724/1762] D loss: 0.5618, G loss: 1.6111\n",
      "[804/1762] D loss: 1.3877, G loss: 0.7319\n",
      "[884/1762] D loss: 1.4321, G loss: 0.8185\n",
      "[964/1762] D loss: 0.5563, G loss: 1.5225\n",
      "[1044/1762] D loss: 1.4232, G loss: 0.6606\n",
      "[1124/1762] D loss: 0.2280, G loss: 2.4643\n",
      "[1204/1762] D loss: 1.5165, G loss: 0.5475\n",
      "[1284/1762] D loss: 0.7531, G loss: 1.6581\n",
      "[1364/1762] D loss: 0.9754, G loss: 1.2353\n",
      "[1444/1762] D loss: 1.3728, G loss: 0.7873\n",
      "[1524/1762] D loss: 0.6363, G loss: 1.6231\n",
      "[1604/1762] D loss: 1.4098, G loss: 0.7242\n",
      "[1684/1762] D loss: 1.1980, G loss: 0.8406\n",
      "[1762/1762] D loss: 0.2577, G loss: 2.2234\n",
      "train error: \n",
      " D loss: 1.454713, G loss: 0.453179, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.440310, G loss: 0.472360, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4109, G loss: 1.8758\n",
      "[84/1762] D loss: 1.4846, G loss: 0.6654\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7031\n",
      "[244/1762] D loss: 1.3326, G loss: 0.7944\n",
      "[324/1762] D loss: 1.4178, G loss: 0.6589\n",
      "[404/1762] D loss: 1.1734, G loss: 0.8169\n",
      "[484/1762] D loss: 0.4174, G loss: 2.1465\n",
      "[564/1762] D loss: 1.4025, G loss: 0.6503\n",
      "[644/1762] D loss: 0.5083, G loss: 1.9989\n",
      "[724/1762] D loss: 0.0752, G loss: 3.2352\n",
      "[804/1762] D loss: 1.4132, G loss: 0.6519\n",
      "[884/1762] D loss: 1.4002, G loss: 0.6984\n",
      "[964/1762] D loss: 1.3899, G loss: 0.7129\n",
      "[1044/1762] D loss: 1.4022, G loss: 0.7347\n",
      "[1124/1762] D loss: 1.3928, G loss: 0.7222\n",
      "[1204/1762] D loss: 1.3836, G loss: 0.7202\n",
      "[1284/1762] D loss: 0.4726, G loss: 1.6520\n",
      "[1364/1762] D loss: 1.4008, G loss: 0.7550\n",
      "[1444/1762] D loss: 1.4680, G loss: 0.6993\n",
      "[1524/1762] D loss: 1.3102, G loss: 0.8205\n",
      "[1604/1762] D loss: 1.1772, G loss: 0.8989\n",
      "[1684/1762] D loss: 1.3974, G loss: 0.6967\n",
      "[1762/1762] D loss: 1.5066, G loss: 0.6234\n",
      "train error: \n",
      " D loss: 1.391529, G loss: 0.556112, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371512, G loss: 0.586885, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.6968\n",
      "[84/1762] D loss: 1.4195, G loss: 0.7329\n",
      "[164/1762] D loss: 1.4002, G loss: 0.6411\n",
      "[244/1762] D loss: 0.4278, G loss: 1.8119\n",
      "[324/1762] D loss: 0.5142, G loss: 1.6345\n",
      "[404/1762] D loss: 1.6389, G loss: 0.7340\n",
      "[484/1762] D loss: 0.6259, G loss: 1.4343\n",
      "[564/1762] D loss: 0.5131, G loss: 1.8594\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6990\n",
      "[724/1762] D loss: 1.3912, G loss: 0.7036\n",
      "[804/1762] D loss: 1.3905, G loss: 0.7215\n",
      "[884/1762] D loss: 0.2193, G loss: 2.7222\n",
      "[964/1762] D loss: 1.5682, G loss: 0.5539\n",
      "[1044/1762] D loss: 1.3994, G loss: 0.6728\n",
      "[1124/1762] D loss: 1.4672, G loss: 0.6172\n",
      "[1204/1762] D loss: 1.3009, G loss: 0.6556\n",
      "[1284/1762] D loss: 1.4835, G loss: 0.7813\n",
      "[1364/1762] D loss: 1.4109, G loss: 0.6665\n",
      "[1444/1762] D loss: 1.4326, G loss: 0.6614\n",
      "[1524/1762] D loss: 1.4443, G loss: 0.6039\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.6995\n",
      "[1684/1762] D loss: 0.5873, G loss: 1.7480\n",
      "[1762/1762] D loss: 1.4180, G loss: 0.9201\n",
      "train error: \n",
      " D loss: 1.338580, G loss: 0.870862, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317776, G loss: 0.901755, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4054, G loss: 0.6284\n",
      "[84/1762] D loss: 1.3934, G loss: 0.6636\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6782\n",
      "[244/1762] D loss: 0.2916, G loss: 2.0986\n",
      "[324/1762] D loss: 1.3850, G loss: 0.7071\n",
      "[404/1762] D loss: 1.3884, G loss: 0.6534\n",
      "[484/1762] D loss: 1.4404, G loss: 0.7713\n",
      "[564/1762] D loss: 1.4070, G loss: 0.6842\n",
      "[644/1762] D loss: 1.8103, G loss: 0.6823\n",
      "[724/1762] D loss: 1.4421, G loss: 0.7757\n",
      "[804/1762] D loss: 1.4333, G loss: 0.7748\n",
      "[884/1762] D loss: 0.4836, G loss: 1.8100\n",
      "[964/1762] D loss: 1.3050, G loss: 0.8376\n",
      "[1044/1762] D loss: 1.2893, G loss: 0.8563\n",
      "[1124/1762] D loss: 1.3990, G loss: 0.9831\n",
      "[1204/1762] D loss: 1.3716, G loss: 0.7860\n",
      "[1284/1762] D loss: 1.3653, G loss: 0.8298\n",
      "[1364/1762] D loss: 1.3887, G loss: 0.7518\n",
      "[1444/1762] D loss: 1.1968, G loss: 0.9229\n",
      "[1524/1762] D loss: 1.1603, G loss: 0.9412\n",
      "[1604/1762] D loss: 1.4227, G loss: 0.7953\n",
      "[1684/1762] D loss: 1.3628, G loss: 0.8511\n",
      "[1762/1762] D loss: 0.9423, G loss: 1.1315\n",
      "train error: \n",
      " D loss: 1.608473, G loss: 1.283689, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.621012, G loss: 1.283609, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4268, G loss: 0.6674\n",
      "[84/1762] D loss: 1.4058, G loss: 0.8043\n",
      "[164/1762] D loss: 1.1774, G loss: 1.0760\n",
      "[244/1762] D loss: 1.3884, G loss: 0.6882\n",
      "[324/1762] D loss: 1.3929, G loss: 0.6769\n",
      "[404/1762] D loss: 1.2296, G loss: 0.9650\n",
      "[484/1762] D loss: 1.3933, G loss: 0.7092\n",
      "[564/1762] D loss: 1.2498, G loss: 0.8519\n",
      "[644/1762] D loss: 1.2787, G loss: 0.8806\n",
      "[724/1762] D loss: 1.4172, G loss: 0.7523\n",
      "[804/1762] D loss: 1.3923, G loss: 0.8155\n",
      "[884/1762] D loss: 1.3937, G loss: 0.7159\n",
      "[964/1762] D loss: 1.3714, G loss: 0.7284\n",
      "[1044/1762] D loss: 1.3847, G loss: 0.7307\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6954\n",
      "[1204/1762] D loss: 0.7066, G loss: 1.8166\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6908\n",
      "[1364/1762] D loss: 1.2807, G loss: 0.7349\n",
      "[1444/1762] D loss: 1.1677, G loss: 1.0576\n",
      "[1524/1762] D loss: 1.0850, G loss: 0.9158\n",
      "[1604/1762] D loss: 1.2064, G loss: 0.8188\n",
      "[1684/1762] D loss: 1.3172, G loss: 0.9045\n",
      "[1762/1762] D loss: 1.3828, G loss: 0.6857\n",
      "train error: \n",
      " D loss: 1.379193, G loss: 0.709204, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365453, G loss: 0.735759, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0821, G loss: 1.1033\n",
      "[84/1762] D loss: 1.3862, G loss: 0.7048\n",
      "[164/1762] D loss: 1.4104, G loss: 0.6872\n",
      "[244/1762] D loss: 1.4117, G loss: 0.7248\n",
      "[324/1762] D loss: 1.6885, G loss: 0.4398\n",
      "[404/1762] D loss: 1.4882, G loss: 0.6392\n",
      "[484/1762] D loss: 1.3977, G loss: 0.6543\n",
      "[564/1762] D loss: 1.2484, G loss: 0.8140\n",
      "[644/1762] D loss: 1.2939, G loss: 1.0016\n",
      "[724/1762] D loss: 1.3485, G loss: 0.8257\n",
      "[804/1762] D loss: 1.2799, G loss: 0.8547\n",
      "[884/1762] D loss: 1.2865, G loss: 0.7626\n",
      "[964/1762] D loss: 1.3628, G loss: 0.5442\n",
      "[1044/1762] D loss: 1.3630, G loss: 0.8854\n",
      "[1124/1762] D loss: 1.3953, G loss: 0.7113\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.7609\n",
      "[1284/1762] D loss: 0.9485, G loss: 1.4341\n",
      "[1364/1762] D loss: 1.3951, G loss: 0.6591\n",
      "[1444/1762] D loss: 1.1809, G loss: 0.4221\n",
      "[1524/1762] D loss: 1.3924, G loss: 0.7996\n",
      "[1604/1762] D loss: 0.8784, G loss: 2.8488\n",
      "[1684/1762] D loss: 1.4109, G loss: 0.4973\n",
      "[1762/1762] D loss: 1.5721, G loss: 1.1366\n",
      "train error: \n",
      " D loss: 1.330328, G loss: 0.989099, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319683, G loss: 1.012227, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0657, G loss: 1.1111\n",
      "[84/1762] D loss: 1.4645, G loss: 0.5518\n",
      "[164/1762] D loss: 1.4617, G loss: 0.8594\n",
      "[244/1762] D loss: 1.4178, G loss: 0.7212\n",
      "[324/1762] D loss: 0.9392, G loss: 1.5248\n",
      "[404/1762] D loss: 1.4693, G loss: 0.7208\n",
      "[484/1762] D loss: 1.4260, G loss: 0.6757\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6858\n",
      "[644/1762] D loss: 1.3906, G loss: 0.6631\n",
      "[724/1762] D loss: 0.9788, G loss: 0.9820\n",
      "[804/1762] D loss: 1.3999, G loss: 0.9328\n",
      "[884/1762] D loss: 1.3895, G loss: 0.6828\n",
      "[964/1762] D loss: 0.7761, G loss: 1.2992\n",
      "[1044/1762] D loss: 1.4164, G loss: 0.7997\n",
      "[1124/1762] D loss: 1.3835, G loss: 0.6983\n",
      "[1204/1762] D loss: 1.4159, G loss: 0.6512\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.6977\n",
      "[1364/1762] D loss: 1.4930, G loss: 0.7767\n",
      "[1444/1762] D loss: 1.4009, G loss: 0.7340\n",
      "[1524/1762] D loss: 0.7597, G loss: 1.5856\n",
      "[1604/1762] D loss: 1.3979, G loss: 0.6690\n",
      "[1684/1762] D loss: 1.4057, G loss: 0.7383\n",
      "[1762/1762] D loss: 1.4337, G loss: 0.9213\n",
      "train error: \n",
      " D loss: 1.347175, G loss: 0.874687, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332237, G loss: 0.896147, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3965, G loss: 0.6639\n",
      "[84/1762] D loss: 1.4020, G loss: 0.6958\n",
      "[164/1762] D loss: 1.4540, G loss: 0.6747\n",
      "[244/1762] D loss: 1.4083, G loss: 0.6676\n",
      "[324/1762] D loss: 1.3894, G loss: 0.6932\n",
      "[404/1762] D loss: 1.4321, G loss: 0.7361\n",
      "[484/1762] D loss: 1.3929, G loss: 0.7012\n",
      "[564/1762] D loss: 1.4153, G loss: 0.6218\n",
      "[644/1762] D loss: 1.4212, G loss: 0.6283\n",
      "[724/1762] D loss: 1.2320, G loss: 0.9448\n",
      "[804/1762] D loss: 1.3770, G loss: 0.7637\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7011\n",
      "[964/1762] D loss: 0.6596, G loss: 2.1476\n",
      "[1044/1762] D loss: 1.2945, G loss: 0.9968\n",
      "[1124/1762] D loss: 1.2292, G loss: 0.7978\n",
      "[1204/1762] D loss: 1.4117, G loss: 0.6356\n",
      "[1284/1762] D loss: 1.4032, G loss: 0.7537\n",
      "[1364/1762] D loss: 1.0703, G loss: 1.0182\n",
      "[1444/1762] D loss: 1.3998, G loss: 0.7202\n",
      "[1524/1762] D loss: 1.1320, G loss: 0.9801\n",
      "[1604/1762] D loss: 1.4092, G loss: 0.7334\n",
      "[1684/1762] D loss: 1.5584, G loss: 0.3853\n",
      "[1762/1762] D loss: 0.8436, G loss: 1.1580\n",
      "train error: \n",
      " D loss: 1.367274, G loss: 0.664788, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361374, G loss: 0.664229, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3751, G loss: 0.7027\n",
      "[84/1762] D loss: 1.2757, G loss: 0.8736\n",
      "[164/1762] D loss: 1.3804, G loss: 0.6855\n",
      "[244/1762] D loss: 1.3856, G loss: 0.6818\n",
      "[324/1762] D loss: 1.2960, G loss: 0.7417\n",
      "[404/1762] D loss: 1.3896, G loss: 0.6980\n",
      "[484/1762] D loss: 1.4147, G loss: 0.6833\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6838\n",
      "[644/1762] D loss: 1.0293, G loss: 0.9870\n",
      "[724/1762] D loss: 1.3999, G loss: 0.7083\n",
      "[804/1762] D loss: 0.8891, G loss: 1.2035\n",
      "[884/1762] D loss: 1.3896, G loss: 0.6990\n",
      "[964/1762] D loss: 1.3904, G loss: 0.6981\n",
      "[1044/1762] D loss: 1.4780, G loss: 0.6493\n",
      "[1124/1762] D loss: 1.0964, G loss: 0.8623\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.7011\n",
      "[1284/1762] D loss: 1.3497, G loss: 1.3321\n",
      "[1364/1762] D loss: 1.2498, G loss: 0.8083\n",
      "[1444/1762] D loss: 1.3966, G loss: 0.6915\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.6943\n",
      "[1604/1762] D loss: 1.4051, G loss: 0.6972\n",
      "[1684/1762] D loss: 0.7085, G loss: 1.3900\n",
      "[1762/1762] D loss: 1.4061, G loss: 0.7341\n",
      "train error: \n",
      " D loss: 1.346035, G loss: 0.699446, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332097, G loss: 0.713123, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8529, G loss: 1.2466\n",
      "[84/1762] D loss: 1.4312, G loss: 0.6697\n",
      "[164/1762] D loss: 1.3957, G loss: 0.6993\n",
      "[244/1762] D loss: 1.4711, G loss: 0.5648\n",
      "[324/1762] D loss: 1.4088, G loss: 0.6852\n",
      "[404/1762] D loss: 1.2193, G loss: 0.7248\n",
      "[484/1762] D loss: 1.4041, G loss: 0.7674\n",
      "[564/1762] D loss: 1.3996, G loss: 0.7278\n",
      "[644/1762] D loss: 1.3583, G loss: 0.8107\n",
      "[724/1762] D loss: 0.6024, G loss: 1.7669\n",
      "[804/1762] D loss: 0.9462, G loss: 1.6940\n",
      "[884/1762] D loss: 1.3956, G loss: 0.6819\n",
      "[964/1762] D loss: 1.6006, G loss: 0.6405\n",
      "[1044/1762] D loss: 1.4291, G loss: 0.6885\n",
      "[1124/1762] D loss: 0.7918, G loss: 1.1774\n",
      "[1204/1762] D loss: 1.5013, G loss: 0.7216\n",
      "[1284/1762] D loss: 1.4110, G loss: 0.7066\n",
      "[1364/1762] D loss: 0.6219, G loss: 1.3166\n",
      "[1444/1762] D loss: 1.4766, G loss: 0.8883\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.6573\n",
      "[1604/1762] D loss: 0.6299, G loss: 1.9056\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6100\n",
      "[1762/1762] D loss: 1.3960, G loss: 0.6962\n",
      "train error: \n",
      " D loss: 1.374705, G loss: 0.598245, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350434, G loss: 0.624885, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4658, G loss: 1.6228\n",
      "[84/1762] D loss: 1.4078, G loss: 0.6962\n",
      "[164/1762] D loss: 1.4002, G loss: 0.7019\n",
      "[244/1762] D loss: 1.3041, G loss: 0.8921\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6707\n",
      "[404/1762] D loss: 0.9030, G loss: 1.1883\n",
      "[484/1762] D loss: 1.3378, G loss: 0.7451\n",
      "[564/1762] D loss: 1.3856, G loss: 0.6935\n",
      "[644/1762] D loss: 1.3931, G loss: 0.7282\n",
      "[724/1762] D loss: 1.4047, G loss: 0.7323\n",
      "[804/1762] D loss: 0.7247, G loss: 1.2533\n",
      "[884/1762] D loss: 1.3951, G loss: 0.6898\n",
      "[964/1762] D loss: 0.7327, G loss: 1.2001\n",
      "[1044/1762] D loss: 1.3994, G loss: 0.7396\n",
      "[1124/1762] D loss: 1.3920, G loss: 0.7178\n",
      "[1204/1762] D loss: 0.8714, G loss: 1.4743\n",
      "[1284/1762] D loss: 1.4133, G loss: 0.6922\n",
      "[1364/1762] D loss: 1.3992, G loss: 0.6962\n",
      "[1444/1762] D loss: 0.9938, G loss: 0.9521\n",
      "[1524/1762] D loss: 1.4306, G loss: 0.6050\n",
      "[1604/1762] D loss: 1.3652, G loss: 0.6669\n",
      "[1684/1762] D loss: 1.4894, G loss: 0.7369\n",
      "[1762/1762] D loss: 1.4103, G loss: 0.8681\n",
      "train error: \n",
      " D loss: 1.487067, G loss: 1.280548, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 78.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.464917, G loss: 1.307906, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3847, G loss: 0.5779\n",
      "[84/1762] D loss: 1.3927, G loss: 0.5624\n",
      "[164/1762] D loss: 0.3255, G loss: 1.9905\n",
      "[244/1762] D loss: 0.4520, G loss: 1.8461\n",
      "[324/1762] D loss: 1.6306, G loss: 0.9476\n",
      "[404/1762] D loss: 0.4619, G loss: 1.7030\n",
      "[484/1762] D loss: 0.5036, G loss: 1.6779\n",
      "[564/1762] D loss: 1.5651, G loss: 0.4745\n",
      "[644/1762] D loss: 1.3842, G loss: 0.6666\n",
      "[724/1762] D loss: 0.6554, G loss: 2.1804\n",
      "[804/1762] D loss: 0.4213, G loss: 1.9624\n",
      "[884/1762] D loss: 1.3896, G loss: 0.7128\n",
      "[964/1762] D loss: 0.4112, G loss: 2.0556\n",
      "[1044/1762] D loss: 1.3997, G loss: 0.6617\n",
      "[1124/1762] D loss: 1.6999, G loss: 0.9245\n",
      "[1204/1762] D loss: 1.5071, G loss: 0.8792\n",
      "[1284/1762] D loss: 1.3969, G loss: 0.7124\n",
      "[1364/1762] D loss: 0.4357, G loss: 1.5578\n",
      "[1444/1762] D loss: 1.4650, G loss: 0.5998\n",
      "[1524/1762] D loss: 1.4363, G loss: 0.7458\n",
      "[1604/1762] D loss: 1.5295, G loss: 0.9527\n",
      "[1684/1762] D loss: 1.4114, G loss: 0.6996\n",
      "[1762/1762] D loss: 1.4056, G loss: 0.6227\n",
      "train error: \n",
      " D loss: 1.541083, G loss: 0.397868, D accuracy: 51.7%, cell accuracy: 99.7%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.524680, G loss: 0.405382, D accuracy: 51.8%, cell accuracy: 99.5%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3505, G loss: 0.7454\n",
      "[84/1762] D loss: 0.4051, G loss: 1.4991\n",
      "[164/1762] D loss: 0.3020, G loss: 1.9968\n",
      "[244/1762] D loss: 1.4592, G loss: 0.6942\n",
      "[324/1762] D loss: 0.4181, G loss: 1.7052\n",
      "[404/1762] D loss: 1.7015, G loss: 1.4126\n",
      "[484/1762] D loss: 1.4725, G loss: 0.8233\n",
      "[564/1762] D loss: 1.4361, G loss: 0.6638\n",
      "[644/1762] D loss: 0.2198, G loss: 2.1001\n",
      "[724/1762] D loss: 1.5173, G loss: 0.5126\n",
      "[804/1762] D loss: 1.3860, G loss: 0.5572\n",
      "[884/1762] D loss: 1.4132, G loss: 0.5998\n",
      "[964/1762] D loss: 1.4213, G loss: 0.7221\n",
      "[1044/1762] D loss: 0.6203, G loss: 1.4850\n",
      "[1124/1762] D loss: 1.4819, G loss: 0.6942\n",
      "[1204/1762] D loss: 0.3198, G loss: 1.9562\n",
      "[1284/1762] D loss: 1.5552, G loss: 0.8870\n",
      "[1364/1762] D loss: 1.4304, G loss: 0.5184\n",
      "[1444/1762] D loss: 1.4225, G loss: 0.5335\n",
      "[1524/1762] D loss: 2.0000, G loss: 0.5316\n",
      "[1604/1762] D loss: 1.4143, G loss: 0.7169\n",
      "[1684/1762] D loss: 1.6246, G loss: 0.8043\n",
      "[1762/1762] D loss: 1.4029, G loss: 0.5076\n",
      "train error: \n",
      " D loss: 1.330677, G loss: 0.722440, D accuracy: 52.7%, cell accuracy: 99.6%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313100, G loss: 0.739363, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3441, G loss: 1.9628\n",
      "[84/1762] D loss: 1.3874, G loss: 0.8321\n",
      "[164/1762] D loss: 1.4466, G loss: 0.6208\n",
      "[244/1762] D loss: 1.4755, G loss: 0.8428\n",
      "[324/1762] D loss: 1.3899, G loss: 0.7097\n",
      "[404/1762] D loss: 0.4032, G loss: 1.4728\n",
      "[484/1762] D loss: 1.3984, G loss: 0.6834\n",
      "[564/1762] D loss: 1.4043, G loss: 0.7133\n",
      "[644/1762] D loss: 1.3991, G loss: 0.7178\n",
      "[724/1762] D loss: 1.3977, G loss: 0.7201\n",
      "[804/1762] D loss: 1.3967, G loss: 0.6297\n",
      "[884/1762] D loss: 0.5410, G loss: 1.6380\n",
      "[964/1762] D loss: 1.4049, G loss: 0.7253\n",
      "[1044/1762] D loss: 1.1606, G loss: 1.6377\n",
      "[1124/1762] D loss: 1.4603, G loss: 0.8187\n",
      "[1204/1762] D loss: 1.4200, G loss: 0.7829\n",
      "[1284/1762] D loss: 1.3967, G loss: 0.7100\n",
      "[1364/1762] D loss: 1.4198, G loss: 0.6650\n",
      "[1444/1762] D loss: 1.3374, G loss: 0.7696\n",
      "[1524/1762] D loss: 0.3010, G loss: 1.6598\n",
      "[1604/1762] D loss: 1.4108, G loss: 0.6632\n",
      "[1684/1762] D loss: 1.4049, G loss: 0.6824\n",
      "[1762/1762] D loss: 0.1671, G loss: 3.0148\n",
      "train error: \n",
      " D loss: 1.673832, G loss: 0.358211, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.626486, G loss: 0.403064, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3449, G loss: 1.9626\n",
      "[84/1762] D loss: 0.3151, G loss: 2.1813\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7142\n",
      "[244/1762] D loss: 1.3940, G loss: 0.7163\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6896\n",
      "[404/1762] D loss: 1.3886, G loss: 0.7091\n",
      "[484/1762] D loss: 0.3815, G loss: 2.0014\n",
      "[564/1762] D loss: 1.5538, G loss: 0.8872\n",
      "[644/1762] D loss: 1.3975, G loss: 0.7092\n",
      "[724/1762] D loss: 1.3949, G loss: 0.6869\n",
      "[804/1762] D loss: 1.3974, G loss: 0.6977\n",
      "[884/1762] D loss: 1.4388, G loss: 0.8214\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6852\n",
      "[1044/1762] D loss: 0.3991, G loss: 1.9326\n",
      "[1124/1762] D loss: 1.6909, G loss: 0.6681\n",
      "[1204/1762] D loss: 1.4532, G loss: 0.6927\n",
      "[1284/1762] D loss: 0.3342, G loss: 2.2014\n",
      "[1364/1762] D loss: 1.4183, G loss: 0.6722\n",
      "[1444/1762] D loss: 1.4078, G loss: 0.6315\n",
      "[1524/1762] D loss: 0.2453, G loss: 2.5925\n",
      "[1604/1762] D loss: 1.3957, G loss: 0.7488\n",
      "[1684/1762] D loss: 1.3976, G loss: 0.7056\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6677\n",
      "train error: \n",
      " D loss: 1.551230, G loss: 0.417198, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.525430, G loss: 0.458467, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2833, G loss: 1.1428\n",
      "[84/1762] D loss: 1.4237, G loss: 0.8916\n",
      "[164/1762] D loss: 1.4257, G loss: 0.7047\n",
      "[244/1762] D loss: 0.4498, G loss: 2.0293\n",
      "[324/1762] D loss: 1.4121, G loss: 0.7220\n",
      "[404/1762] D loss: 1.3994, G loss: 0.6842\n",
      "[484/1762] D loss: 0.4018, G loss: 1.9845\n",
      "[564/1762] D loss: 1.4035, G loss: 0.6122\n",
      "[644/1762] D loss: 1.1208, G loss: 0.8038\n",
      "[724/1762] D loss: 1.3999, G loss: 0.7638\n",
      "[804/1762] D loss: 0.0920, G loss: 2.9488\n",
      "[884/1762] D loss: 1.7430, G loss: 0.6264\n",
      "[964/1762] D loss: 1.7500, G loss: 0.7313\n",
      "[1044/1762] D loss: 0.3782, G loss: 2.0464\n",
      "[1124/1762] D loss: 1.5493, G loss: 0.7110\n",
      "[1204/1762] D loss: 0.2040, G loss: 2.2366\n",
      "[1284/1762] D loss: 1.3854, G loss: 0.7158\n",
      "[1364/1762] D loss: 1.4334, G loss: 0.6720\n",
      "[1444/1762] D loss: 1.4189, G loss: 0.6171\n",
      "[1524/1762] D loss: 0.3815, G loss: 2.3098\n",
      "[1604/1762] D loss: 1.4149, G loss: 0.7612\n",
      "[1684/1762] D loss: 1.4008, G loss: 0.7153\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.6860\n",
      "train error: \n",
      " D loss: 1.534045, G loss: 0.458556, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.497527, G loss: 0.517260, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.7035\n",
      "[84/1762] D loss: 1.4451, G loss: 0.8108\n",
      "[164/1762] D loss: 1.3850, G loss: 0.6980\n",
      "[244/1762] D loss: 0.4064, G loss: 1.7597\n",
      "[324/1762] D loss: 1.3926, G loss: 0.7176\n",
      "[404/1762] D loss: 0.3384, G loss: 2.0698\n",
      "[484/1762] D loss: 1.4269, G loss: 0.6179\n",
      "[564/1762] D loss: 1.4019, G loss: 0.7086\n",
      "[644/1762] D loss: 1.4168, G loss: 0.6508\n",
      "[724/1762] D loss: 1.4642, G loss: 0.7098\n",
      "[804/1762] D loss: 1.0688, G loss: 1.1057\n",
      "[884/1762] D loss: 0.6579, G loss: 1.2822\n",
      "[964/1762] D loss: 1.4020, G loss: 0.6848\n",
      "[1044/1762] D loss: 0.1970, G loss: 2.1200\n",
      "[1124/1762] D loss: 1.4487, G loss: 0.6910\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.6813\n",
      "[1284/1762] D loss: 1.3986, G loss: 0.6534\n",
      "[1364/1762] D loss: 0.3331, G loss: 2.2634\n",
      "[1444/1762] D loss: 0.3266, G loss: 1.7960\n",
      "[1524/1762] D loss: 1.4170, G loss: 0.7567\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.6925\n",
      "[1684/1762] D loss: 0.4159, G loss: 2.1196\n",
      "[1762/1762] D loss: 1.2062, G loss: 0.9048\n",
      "train error: \n",
      " D loss: 1.324101, G loss: 0.787247, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311428, G loss: 0.806181, D accuracy: 55.5%, cell accuracy: 99.5%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4080, G loss: 0.7247\n",
      "[84/1762] D loss: 0.2135, G loss: 2.5630\n",
      "[164/1762] D loss: 1.3905, G loss: 0.7186\n",
      "[244/1762] D loss: 1.3019, G loss: 0.9071\n",
      "[324/1762] D loss: 0.5181, G loss: 2.1317\n",
      "[404/1762] D loss: 0.3170, G loss: 2.7730\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6872\n",
      "[564/1762] D loss: 1.3987, G loss: 0.7039\n",
      "[644/1762] D loss: 1.4016, G loss: 0.6879\n",
      "[724/1762] D loss: 1.1479, G loss: 1.5159\n",
      "[804/1762] D loss: 1.4634, G loss: 0.5738\n",
      "[884/1762] D loss: 0.1553, G loss: 2.5299\n",
      "[964/1762] D loss: 1.4164, G loss: 0.6889\n",
      "[1044/1762] D loss: 1.4520, G loss: 0.6770\n",
      "[1124/1762] D loss: 1.3920, G loss: 0.6996\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.6976\n",
      "[1284/1762] D loss: 1.4183, G loss: 0.6674\n",
      "[1364/1762] D loss: 1.3390, G loss: 1.0455\n",
      "[1444/1762] D loss: 1.4733, G loss: 0.5380\n",
      "[1524/1762] D loss: 1.4401, G loss: 0.7723\n",
      "[1604/1762] D loss: 0.3047, G loss: 2.3793\n",
      "[1684/1762] D loss: 1.4059, G loss: 0.6994\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.6769\n",
      "train error: \n",
      " D loss: 1.322707, G loss: 0.772194, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309582, G loss: 0.818500, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.7017\n",
      "[84/1762] D loss: 0.2788, G loss: 2.5565\n",
      "[164/1762] D loss: 1.4459, G loss: 0.5493\n",
      "[244/1762] D loss: 1.3893, G loss: 0.6949\n",
      "[324/1762] D loss: 1.1855, G loss: 1.0143\n",
      "[404/1762] D loss: 0.0684, G loss: 3.8258\n",
      "[484/1762] D loss: 0.0338, G loss: 4.0284\n",
      "[564/1762] D loss: 0.4883, G loss: 1.7291\n",
      "[644/1762] D loss: 1.4468, G loss: 0.8397\n",
      "[724/1762] D loss: 1.3140, G loss: 0.8015\n",
      "[804/1762] D loss: 1.3927, G loss: 0.6403\n",
      "[884/1762] D loss: 0.3116, G loss: 1.8999\n",
      "[964/1762] D loss: 0.3148, G loss: 2.1207\n",
      "[1044/1762] D loss: 1.4008, G loss: 0.7129\n",
      "[1124/1762] D loss: 1.4497, G loss: 0.6681\n",
      "[1204/1762] D loss: 1.1502, G loss: 0.9439\n",
      "[1284/1762] D loss: 1.4197, G loss: 0.6903\n",
      "[1364/1762] D loss: 1.3992, G loss: 0.6830\n",
      "[1444/1762] D loss: 1.4852, G loss: 2.4252\n",
      "[1524/1762] D loss: 1.4017, G loss: 0.7149\n",
      "[1604/1762] D loss: 1.2476, G loss: 1.4140\n",
      "[1684/1762] D loss: 1.3709, G loss: 0.7240\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.6795\n",
      "train error: \n",
      " D loss: 1.384502, G loss: 0.859925, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380405, G loss: 0.877651, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3975, G loss: 0.6963\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7067\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6984\n",
      "[244/1762] D loss: 1.3886, G loss: 0.7239\n",
      "[324/1762] D loss: 1.3926, G loss: 0.7122\n",
      "[404/1762] D loss: 0.7898, G loss: 1.7142\n",
      "[484/1762] D loss: 1.4860, G loss: 0.8292\n",
      "[564/1762] D loss: 1.3915, G loss: 0.6813\n",
      "[644/1762] D loss: 1.3908, G loss: 0.6765\n",
      "[724/1762] D loss: 1.1478, G loss: 0.7009\n",
      "[804/1762] D loss: 1.4026, G loss: 0.7366\n",
      "[884/1762] D loss: 1.1923, G loss: 0.8641\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6867\n",
      "[1044/1762] D loss: 0.9084, G loss: 1.4346\n",
      "[1124/1762] D loss: 1.3890, G loss: 0.7125\n",
      "[1204/1762] D loss: 0.6835, G loss: 1.1676\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7068\n",
      "[1364/1762] D loss: 1.5464, G loss: 0.9240\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.6927\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.7098\n",
      "[1604/1762] D loss: 1.4009, G loss: 0.7390\n",
      "[1684/1762] D loss: 1.4466, G loss: 0.8562\n",
      "[1762/1762] D loss: 1.3975, G loss: 0.6613\n",
      "train error: \n",
      " D loss: 1.358428, G loss: 0.751485, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356620, G loss: 0.749570, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3960, G loss: 0.6958\n",
      "[84/1762] D loss: 1.3880, G loss: 0.6965\n",
      "[164/1762] D loss: 0.7597, G loss: 1.5839\n",
      "[244/1762] D loss: 1.3886, G loss: 0.6987\n",
      "[324/1762] D loss: 0.5813, G loss: 1.5870\n",
      "[404/1762] D loss: 1.3879, G loss: 0.7133\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7123\n",
      "[564/1762] D loss: 1.4723, G loss: 0.8184\n",
      "[644/1762] D loss: 0.3498, G loss: 1.8001\n",
      "[724/1762] D loss: 1.3856, G loss: 0.7029\n",
      "[804/1762] D loss: 1.4753, G loss: 0.7772\n",
      "[884/1762] D loss: 1.3923, G loss: 0.7804\n",
      "[964/1762] D loss: 1.4029, G loss: 0.7248\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7138\n",
      "[1124/1762] D loss: 1.3938, G loss: 0.7019\n",
      "[1204/1762] D loss: 1.4107, G loss: 0.7733\n",
      "[1284/1762] D loss: 1.3942, G loss: 0.6998\n",
      "[1364/1762] D loss: 1.4053, G loss: 0.6841\n",
      "[1444/1762] D loss: 0.3467, G loss: 2.0622\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.7125\n",
      "[1604/1762] D loss: 1.4334, G loss: 0.7370\n",
      "[1684/1762] D loss: 1.5050, G loss: 0.7366\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.6921\n",
      "train error: \n",
      " D loss: 1.514075, G loss: 0.525537, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.477799, G loss: 0.588241, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005, G loss: 0.7206\n",
      "[84/1762] D loss: 1.4129, G loss: 0.6629\n",
      "[164/1762] D loss: 1.4253, G loss: 0.7047\n",
      "[244/1762] D loss: 1.4004, G loss: 0.7024\n",
      "[324/1762] D loss: 1.3894, G loss: 0.6811\n",
      "[404/1762] D loss: 1.3993, G loss: 0.7073\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6953\n",
      "[564/1762] D loss: 1.5488, G loss: 0.6358\n",
      "[644/1762] D loss: 0.2710, G loss: 2.2104\n",
      "[724/1762] D loss: 1.1841, G loss: 1.4312\n",
      "[804/1762] D loss: 1.4058, G loss: 0.7068\n",
      "[884/1762] D loss: 1.4221, G loss: 0.5693\n",
      "[964/1762] D loss: 1.3110, G loss: 1.0664\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.6927\n",
      "[1124/1762] D loss: 1.1870, G loss: 0.3900\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7034\n",
      "[1284/1762] D loss: 1.1322, G loss: 0.9144\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6769\n",
      "[1444/1762] D loss: 1.5635, G loss: 0.8544\n",
      "[1524/1762] D loss: 1.3942, G loss: 0.6933\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.6940\n",
      "[1684/1762] D loss: 1.3957, G loss: 0.7178\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6856\n",
      "train error: \n",
      " D loss: 1.381314, G loss: 0.687180, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380257, G loss: 0.683224, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.7003\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6875\n",
      "[164/1762] D loss: 1.3963, G loss: 0.6865\n",
      "[244/1762] D loss: 1.4698, G loss: 0.6827\n",
      "[324/1762] D loss: 0.9134, G loss: 1.1771\n",
      "[404/1762] D loss: 1.4599, G loss: 1.1128\n",
      "[484/1762] D loss: 1.2992, G loss: 0.7178\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6917\n",
      "[644/1762] D loss: 1.1717, G loss: 1.1356\n",
      "[724/1762] D loss: 1.0366, G loss: 1.2151\n",
      "[804/1762] D loss: 1.3954, G loss: 0.6808\n",
      "[884/1762] D loss: 1.3944, G loss: 0.7241\n",
      "[964/1762] D loss: 1.4398, G loss: 0.7960\n",
      "[1044/1762] D loss: 1.4345, G loss: 0.7335\n",
      "[1124/1762] D loss: 1.0789, G loss: 1.3095\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.7017\n",
      "[1284/1762] D loss: 1.4937, G loss: 0.7930\n",
      "[1364/1762] D loss: 2.9433, G loss: 4.3190\n",
      "[1444/1762] D loss: 1.4045, G loss: 0.6288\n",
      "[1524/1762] D loss: 1.3719, G loss: 0.7045\n",
      "[1604/1762] D loss: 1.4663, G loss: 0.9172\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6922\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.6968\n",
      "train error: \n",
      " D loss: 1.439748, G loss: 1.071467, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.415988, G loss: 1.076896, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3855, G loss: 0.6738\n",
      "[84/1762] D loss: 1.3890, G loss: 0.6641\n",
      "[164/1762] D loss: 1.3968, G loss: 0.7014\n",
      "[244/1762] D loss: 1.3397, G loss: 0.7877\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6910\n",
      "[404/1762] D loss: 0.9982, G loss: 0.9946\n",
      "[484/1762] D loss: 1.5563, G loss: 1.1293\n",
      "[564/1762] D loss: 1.1551, G loss: 0.7044\n",
      "[644/1762] D loss: 1.4141, G loss: 0.7968\n",
      "[724/1762] D loss: 1.3819, G loss: 0.6772\n",
      "[804/1762] D loss: 1.4012, G loss: 0.6316\n",
      "[884/1762] D loss: 1.1044, G loss: 1.4705\n",
      "[964/1762] D loss: 1.4175, G loss: 0.6108\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.6824\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.6841\n",
      "[1204/1762] D loss: 1.0120, G loss: 1.0667\n",
      "[1284/1762] D loss: 1.4001, G loss: 0.7387\n",
      "[1364/1762] D loss: 1.4024, G loss: 0.7170\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.7311\n",
      "[1524/1762] D loss: 1.4206, G loss: 0.7132\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.7021\n",
      "[1684/1762] D loss: 1.3922, G loss: 0.7251\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6932\n",
      "train error: \n",
      " D loss: 1.351123, G loss: 0.707222, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341950, G loss: 0.711391, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.6596\n",
      "[84/1762] D loss: 0.6213, G loss: 2.3725\n",
      "[164/1762] D loss: 1.4001, G loss: 0.7061\n",
      "[244/1762] D loss: 1.3893, G loss: 0.6719\n",
      "[324/1762] D loss: 1.0980, G loss: 0.7953\n",
      "[404/1762] D loss: 1.3938, G loss: 0.6921\n",
      "[484/1762] D loss: 1.3885, G loss: 0.6773\n",
      "[564/1762] D loss: 1.4471, G loss: 0.8311\n",
      "[644/1762] D loss: 1.2847, G loss: 0.8008\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6875\n",
      "[804/1762] D loss: 1.5936, G loss: 0.4823\n",
      "[884/1762] D loss: 1.4319, G loss: 0.7868\n",
      "[964/1762] D loss: 0.3084, G loss: 2.4169\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.7133\n",
      "[1124/1762] D loss: 1.3920, G loss: 0.7108\n",
      "[1204/1762] D loss: 1.3944, G loss: 0.7357\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.7110\n",
      "[1364/1762] D loss: 1.4469, G loss: 0.8568\n",
      "[1444/1762] D loss: 1.4002, G loss: 0.7716\n",
      "[1524/1762] D loss: 0.3877, G loss: 1.5786\n",
      "[1604/1762] D loss: 0.5011, G loss: 1.8191\n",
      "[1684/1762] D loss: 1.4344, G loss: 0.9039\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.7646\n",
      "train error: \n",
      " D loss: 1.369794, G loss: 0.726329, D accuracy: 51.7%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363202, G loss: 0.732239, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3853, G loss: 0.6933\n",
      "[84/1762] D loss: 1.3883, G loss: 0.6742\n",
      "[164/1762] D loss: 1.4025, G loss: 0.7401\n",
      "[244/1762] D loss: 1.3544, G loss: 0.8245\n",
      "[324/1762] D loss: 1.3883, G loss: 0.6909\n",
      "[404/1762] D loss: 1.3789, G loss: 0.7201\n",
      "[484/1762] D loss: 1.2487, G loss: 0.8728\n",
      "[564/1762] D loss: 1.3904, G loss: 0.6509\n",
      "[644/1762] D loss: 1.3961, G loss: 0.7499\n",
      "[724/1762] D loss: 1.4292, G loss: 0.8792\n",
      "[804/1762] D loss: 0.5317, G loss: 1.2306\n",
      "[884/1762] D loss: 1.4145, G loss: 0.8447\n",
      "[964/1762] D loss: 0.3948, G loss: 1.4033\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6567\n",
      "[1124/1762] D loss: 0.7045, G loss: 1.6333\n",
      "[1204/1762] D loss: 0.3118, G loss: 2.0677\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.6677\n",
      "[1364/1762] D loss: 1.4010, G loss: 0.7087\n",
      "[1444/1762] D loss: 1.3993, G loss: 0.6548\n",
      "[1524/1762] D loss: 1.4085, G loss: 0.7108\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6788\n",
      "[1684/1762] D loss: 1.3967, G loss: 0.6997\n",
      "[1762/1762] D loss: 1.4168, G loss: 2.0719\n",
      "train error: \n",
      " D loss: 1.488301, G loss: 0.902696, D accuracy: 49.4%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.500506, G loss: 0.953323, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4123, G loss: 0.7679\n",
      "[84/1762] D loss: 1.4110, G loss: 0.8293\n",
      "[164/1762] D loss: 1.3555, G loss: 0.6752\n",
      "[244/1762] D loss: 1.3514, G loss: 0.7156\n",
      "[324/1762] D loss: 1.4044, G loss: 0.7679\n",
      "[404/1762] D loss: 1.4108, G loss: 0.8312\n",
      "[484/1762] D loss: 1.3970, G loss: 0.7668\n",
      "[564/1762] D loss: 1.4096, G loss: 0.8228\n",
      "[644/1762] D loss: 1.3889, G loss: 0.7307\n",
      "[724/1762] D loss: 1.4068, G loss: 0.7279\n",
      "[804/1762] D loss: 1.4054, G loss: 0.8698\n",
      "[884/1762] D loss: 1.3953, G loss: 0.7521\n",
      "[964/1762] D loss: 1.1779, G loss: 1.0469\n",
      "[1044/1762] D loss: 0.2874, G loss: 2.4476\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.7246\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.6933\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.6880\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.7094\n",
      "[1444/1762] D loss: 1.3904, G loss: 0.7230\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.6861\n",
      "[1604/1762] D loss: 1.3849, G loss: 0.6976\n",
      "[1684/1762] D loss: 1.4047, G loss: 0.7704\n",
      "[1762/1762] D loss: 1.4015, G loss: 0.6900\n",
      "train error: \n",
      " D loss: 1.345420, G loss: 0.829299, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311470, G loss: 0.862345, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3970, G loss: 0.7118\n",
      "[84/1762] D loss: 1.2137, G loss: 1.2981\n",
      "[164/1762] D loss: 2.0141, G loss: 1.2450\n",
      "[244/1762] D loss: 1.3987, G loss: 0.7686\n",
      "[324/1762] D loss: 0.5494, G loss: 1.9449\n",
      "[404/1762] D loss: 1.3969, G loss: 0.7535\n",
      "[484/1762] D loss: 1.3614, G loss: 1.0465\n",
      "[564/1762] D loss: 1.3728, G loss: 0.7051\n",
      "[644/1762] D loss: 1.3904, G loss: 0.7067\n",
      "[724/1762] D loss: 1.6221, G loss: 0.8527\n",
      "[804/1762] D loss: 0.4140, G loss: 1.4127\n",
      "[884/1762] D loss: 1.4007, G loss: 0.7075\n",
      "[964/1762] D loss: 1.3917, G loss: 0.7008\n",
      "[1044/1762] D loss: 1.3973, G loss: 0.6454\n",
      "[1124/1762] D loss: 1.2753, G loss: 0.9479\n",
      "[1204/1762] D loss: 1.4666, G loss: 1.4193\n",
      "[1284/1762] D loss: 1.3544, G loss: 0.9568\n",
      "[1364/1762] D loss: 0.6910, G loss: 1.4571\n",
      "[1444/1762] D loss: 1.3963, G loss: 0.7257\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.7072\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.6962\n",
      "[1684/1762] D loss: 0.9026, G loss: 1.1873\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.7027\n",
      "train error: \n",
      " D loss: 1.328114, G loss: 0.919895, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305033, G loss: 0.982951, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6984\n",
      "[84/1762] D loss: 1.3915, G loss: 0.7343\n",
      "[164/1762] D loss: 1.4119, G loss: 0.8154\n",
      "[244/1762] D loss: 1.0795, G loss: 1.2064\n",
      "[324/1762] D loss: 1.3891, G loss: 0.6850\n",
      "[404/1762] D loss: 1.3911, G loss: 0.6734\n",
      "[484/1762] D loss: 1.3894, G loss: 0.6932\n",
      "[564/1762] D loss: 1.3922, G loss: 0.7472\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6756\n",
      "[724/1762] D loss: 1.1352, G loss: 1.2434\n",
      "[804/1762] D loss: 1.3883, G loss: 0.7451\n",
      "[884/1762] D loss: 0.6099, G loss: 1.5559\n",
      "[964/1762] D loss: 1.4181, G loss: 0.8683\n",
      "[1044/1762] D loss: 1.3856, G loss: 0.7032\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.7427\n",
      "[1204/1762] D loss: 1.4285, G loss: 0.8722\n",
      "[1284/1762] D loss: 1.4236, G loss: 0.8545\n",
      "[1364/1762] D loss: 1.4290, G loss: 0.7962\n",
      "[1444/1762] D loss: 1.4398, G loss: 0.7114\n",
      "[1524/1762] D loss: 1.3903, G loss: 0.6773\n",
      "[1604/1762] D loss: 1.3968, G loss: 0.7105\n",
      "[1684/1762] D loss: 1.3818, G loss: 0.7758\n",
      "[1762/1762] D loss: 1.3840, G loss: 0.7207\n",
      "train error: \n",
      " D loss: 1.337032, G loss: 1.097745, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337362, G loss: 1.198790, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6072, G loss: 2.0092\n",
      "[84/1762] D loss: 1.0836, G loss: 1.2096\n",
      "[164/1762] D loss: 1.3848, G loss: 0.6901\n",
      "[244/1762] D loss: 1.3956, G loss: 0.6546\n",
      "[324/1762] D loss: 1.4022, G loss: 0.7754\n",
      "[404/1762] D loss: 1.3900, G loss: 0.7190\n",
      "[484/1762] D loss: 1.3921, G loss: 0.6575\n",
      "[564/1762] D loss: 1.3968, G loss: 0.6688\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6824\n",
      "[724/1762] D loss: 1.3745, G loss: 0.6571\n",
      "[804/1762] D loss: 1.3786, G loss: 0.7438\n",
      "[884/1762] D loss: 1.4019, G loss: 0.7954\n",
      "[964/1762] D loss: 1.3943, G loss: 0.7340\n",
      "[1044/1762] D loss: 1.3900, G loss: 0.6687\n",
      "[1124/1762] D loss: 0.6950, G loss: 2.2515\n",
      "[1204/1762] D loss: 1.4023, G loss: 0.6564\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.6891\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7103\n",
      "[1444/1762] D loss: 1.3911, G loss: 0.7082\n",
      "[1524/1762] D loss: 1.3716, G loss: 0.7429\n",
      "[1604/1762] D loss: 1.4018, G loss: 0.7634\n",
      "[1684/1762] D loss: 1.4309, G loss: 0.6901\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7339\n",
      "train error: \n",
      " D loss: 1.360449, G loss: 0.832899, D accuracy: 52.4%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357099, G loss: 0.841007, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4138, G loss: 0.7104\n",
      "[84/1762] D loss: 0.5983, G loss: 1.1528\n",
      "[164/1762] D loss: 1.4491, G loss: 0.7495\n",
      "[244/1762] D loss: 1.4025, G loss: 0.8900\n",
      "[324/1762] D loss: 0.2626, G loss: 1.8596\n",
      "[404/1762] D loss: 1.4176, G loss: 0.6718\n",
      "[484/1762] D loss: 1.3929, G loss: 0.6983\n",
      "[564/1762] D loss: 1.3914, G loss: 0.7286\n",
      "[644/1762] D loss: 1.3854, G loss: 0.6808\n",
      "[724/1762] D loss: 1.3328, G loss: 0.8094\n",
      "[804/1762] D loss: 0.4854, G loss: 1.3922\n",
      "[884/1762] D loss: 0.1791, G loss: 2.6594\n",
      "[964/1762] D loss: 1.4388, G loss: 0.5712\n",
      "[1044/1762] D loss: 1.3733, G loss: 0.7234\n",
      "[1124/1762] D loss: 1.4035, G loss: 0.7401\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.6776\n",
      "[1284/1762] D loss: 1.3542, G loss: 0.8536\n",
      "[1364/1762] D loss: 1.5947, G loss: 1.6758\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7345\n",
      "[1524/1762] D loss: 1.4216, G loss: 0.8514\n",
      "[1604/1762] D loss: 0.6280, G loss: 1.5338\n",
      "[1684/1762] D loss: 1.4269, G loss: 0.6958\n",
      "[1762/1762] D loss: 1.4278, G loss: 0.8504\n",
      "train error: \n",
      " D loss: 1.364978, G loss: 0.885250, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348633, G loss: 0.896254, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7131, G loss: 1.0320\n",
      "[84/1762] D loss: 1.3915, G loss: 0.7154\n",
      "[164/1762] D loss: 1.3936, G loss: 0.7451\n",
      "[244/1762] D loss: 1.6903, G loss: 1.0258\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6731\n",
      "[404/1762] D loss: 1.4227, G loss: 0.6979\n",
      "[484/1762] D loss: 1.3914, G loss: 0.7150\n",
      "[564/1762] D loss: 1.2136, G loss: 0.8610\n",
      "[644/1762] D loss: 1.4305, G loss: 0.8679\n",
      "[724/1762] D loss: 0.4704, G loss: 1.2949\n",
      "[804/1762] D loss: 1.3919, G loss: 0.6892\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7025\n",
      "[964/1762] D loss: 1.3955, G loss: 0.7659\n",
      "[1044/1762] D loss: 1.3923, G loss: 0.7321\n",
      "[1124/1762] D loss: 1.3707, G loss: 0.7061\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6650\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.7408\n",
      "[1364/1762] D loss: 1.3924, G loss: 0.7559\n",
      "[1444/1762] D loss: 1.3943, G loss: 0.7750\n",
      "[1524/1762] D loss: 0.8406, G loss: 0.7532\n",
      "[1604/1762] D loss: 1.3996, G loss: 0.7598\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.7508\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.7015\n",
      "train error: \n",
      " D loss: 1.343058, G loss: 0.703847, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 79.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333230, G loss: 0.699555, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.7214\n",
      "[84/1762] D loss: 1.3794, G loss: 0.7512\n",
      "[164/1762] D loss: 1.3880, G loss: 0.7013\n",
      "[244/1762] D loss: 1.0965, G loss: 0.7796\n",
      "[324/1762] D loss: 1.3892, G loss: 0.7278\n",
      "[404/1762] D loss: 1.3882, G loss: 0.6985\n",
      "[484/1762] D loss: 1.3948, G loss: 0.8779\n",
      "[564/1762] D loss: 1.3892, G loss: 0.7442\n",
      "[644/1762] D loss: 1.3934, G loss: 0.7690\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7318\n",
      "[804/1762] D loss: 1.1831, G loss: 0.7850\n",
      "[884/1762] D loss: 0.9512, G loss: 0.9129\n",
      "[964/1762] D loss: 1.3881, G loss: 0.7375\n",
      "[1044/1762] D loss: 1.2005, G loss: 0.7949\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.7297\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.7227\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7251\n",
      "[1364/1762] D loss: 0.8725, G loss: 1.1692\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7167\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.7198\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7115\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.7465\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6614\n",
      "train error: \n",
      " D loss: 1.348689, G loss: 0.807909, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334075, G loss: 0.821576, D accuracy: 52.2%, cell accuracy: 99.6%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0816, G loss: 1.1709\n",
      "[84/1762] D loss: 1.5693, G loss: 0.6759\n",
      "[164/1762] D loss: 1.4001, G loss: 0.7968\n",
      "[244/1762] D loss: 1.2321, G loss: 1.2383\n",
      "[324/1762] D loss: 1.3880, G loss: 0.7307\n",
      "[404/1762] D loss: 1.3848, G loss: 0.6969\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7045\n",
      "[564/1762] D loss: 1.3892, G loss: 0.6499\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6949\n",
      "[724/1762] D loss: 1.3008, G loss: 0.9043\n",
      "[804/1762] D loss: 1.4014, G loss: 0.5952\n",
      "[884/1762] D loss: 1.3806, G loss: 0.6880\n",
      "[964/1762] D loss: 1.2160, G loss: 0.7860\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.7004\n",
      "[1124/1762] D loss: 1.3801, G loss: 0.6481\n",
      "[1204/1762] D loss: 1.4873, G loss: 0.6466\n",
      "[1284/1762] D loss: 1.3608, G loss: 1.3119\n",
      "[1364/1762] D loss: 1.3924, G loss: 0.7727\n",
      "[1444/1762] D loss: 1.1398, G loss: 1.2647\n",
      "[1524/1762] D loss: 1.4030, G loss: 0.6533\n",
      "[1604/1762] D loss: 0.4287, G loss: 1.2904\n",
      "[1684/1762] D loss: 1.3886, G loss: 0.7009\n",
      "[1762/1762] D loss: 0.5284, G loss: 1.6242\n",
      "train error: \n",
      " D loss: 1.376999, G loss: 0.699098, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359331, G loss: 0.740179, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3345, G loss: 1.0192\n",
      "[84/1762] D loss: 1.4059, G loss: 0.7318\n",
      "[164/1762] D loss: 1.3957, G loss: 0.6594\n",
      "[244/1762] D loss: 1.3938, G loss: 0.6828\n",
      "[324/1762] D loss: 1.3839, G loss: 0.7095\n",
      "[404/1762] D loss: 1.3980, G loss: 0.6929\n",
      "[484/1762] D loss: 1.3974, G loss: 0.6502\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6858\n",
      "[644/1762] D loss: 1.3915, G loss: 0.7331\n",
      "[724/1762] D loss: 1.0426, G loss: 1.6523\n",
      "[804/1762] D loss: 0.0635, G loss: 3.6592\n",
      "[884/1762] D loss: 1.3913, G loss: 0.7059\n",
      "[964/1762] D loss: 1.9784, G loss: 0.0749\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.6868\n",
      "[1124/1762] D loss: 1.4021, G loss: 0.7436\n",
      "[1204/1762] D loss: 1.4272, G loss: 0.8881\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6839\n",
      "[1364/1762] D loss: 1.5125, G loss: 0.7931\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.7244\n",
      "[1524/1762] D loss: 1.3814, G loss: 0.6904\n",
      "[1604/1762] D loss: 0.5073, G loss: 1.0221\n",
      "[1684/1762] D loss: 1.0386, G loss: 0.8811\n",
      "[1762/1762] D loss: 1.3977, G loss: 0.6707\n",
      "train error: \n",
      " D loss: 1.466473, G loss: 0.637562, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.488016, G loss: 0.623076, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.6888\n",
      "[84/1762] D loss: 1.3917, G loss: 0.7250\n",
      "[164/1762] D loss: 1.4099, G loss: 0.7984\n",
      "[244/1762] D loss: 1.3855, G loss: 0.6765\n",
      "[324/1762] D loss: 0.4912, G loss: 1.3198\n",
      "[404/1762] D loss: 1.2497, G loss: 0.8060\n",
      "[484/1762] D loss: 0.2273, G loss: 2.0480\n",
      "[564/1762] D loss: 1.4151, G loss: 0.7090\n",
      "[644/1762] D loss: 0.2105, G loss: 1.9244\n",
      "[724/1762] D loss: 1.4819, G loss: 0.7707\n",
      "[804/1762] D loss: 0.4244, G loss: 1.9285\n",
      "[884/1762] D loss: 1.3934, G loss: 0.6527\n",
      "[964/1762] D loss: 1.3000, G loss: 0.8081\n",
      "[1044/1762] D loss: 1.4055, G loss: 0.6119\n",
      "[1124/1762] D loss: 1.2488, G loss: 0.9226\n",
      "[1204/1762] D loss: 1.3974, G loss: 0.7615\n",
      "[1284/1762] D loss: 1.3898, G loss: 0.6656\n",
      "[1364/1762] D loss: 0.6009, G loss: 1.7208\n",
      "[1444/1762] D loss: 0.5682, G loss: 1.0676\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.6935\n",
      "[1604/1762] D loss: 1.4004, G loss: 0.7618\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6790\n",
      "[1762/1762] D loss: 1.3987, G loss: 0.7277\n",
      "train error: \n",
      " D loss: 1.337865, G loss: 0.772831, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317355, G loss: 0.790466, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4704, G loss: 1.5680\n",
      "[84/1762] D loss: 1.2778, G loss: 0.7759\n",
      "[164/1762] D loss: 1.3968, G loss: 0.7054\n",
      "[244/1762] D loss: 1.4634, G loss: 0.7610\n",
      "[324/1762] D loss: 1.3906, G loss: 0.6750\n",
      "[404/1762] D loss: 1.3975, G loss: 0.7061\n",
      "[484/1762] D loss: 1.1861, G loss: 0.8234\n",
      "[564/1762] D loss: 1.4125, G loss: 0.6951\n",
      "[644/1762] D loss: 1.3910, G loss: 0.6579\n",
      "[724/1762] D loss: 1.3889, G loss: 0.6636\n",
      "[804/1762] D loss: 1.3965, G loss: 0.7722\n",
      "[884/1762] D loss: 1.1183, G loss: 0.8119\n",
      "[964/1762] D loss: 1.3896, G loss: 0.7350\n",
      "[1044/1762] D loss: 1.2054, G loss: 1.0382\n",
      "[1124/1762] D loss: 1.3994, G loss: 0.6491\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.7072\n",
      "[1284/1762] D loss: 1.3925, G loss: 0.6682\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7046\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.6922\n",
      "[1524/1762] D loss: 1.3634, G loss: 0.8287\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6940\n",
      "[1684/1762] D loss: 0.8549, G loss: 0.9742\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6861\n",
      "train error: \n",
      " D loss: 1.398873, G loss: 0.724361, D accuracy: 50.5%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378053, G loss: 0.739334, D accuracy: 51.4%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.6729\n",
      "[84/1762] D loss: 1.3878, G loss: 0.7067\n",
      "[164/1762] D loss: 1.3955, G loss: 0.6258\n",
      "[244/1762] D loss: 1.5075, G loss: 0.7462\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7279\n",
      "[404/1762] D loss: 1.3900, G loss: 0.7301\n",
      "[484/1762] D loss: 1.3879, G loss: 0.7034\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7098\n",
      "[644/1762] D loss: 1.3880, G loss: 0.8726\n",
      "[724/1762] D loss: 1.0842, G loss: 2.1116\n",
      "[804/1762] D loss: 1.3927, G loss: 0.7380\n",
      "[884/1762] D loss: 1.3945, G loss: 0.6526\n",
      "[964/1762] D loss: 1.3905, G loss: 0.6928\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7322\n",
      "[1124/1762] D loss: 1.3216, G loss: 1.3037\n",
      "[1204/1762] D loss: 1.3951, G loss: 0.6902\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.7000\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.7306\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6809\n",
      "[1524/1762] D loss: 1.2563, G loss: 0.9490\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6872\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.7366\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7434\n",
      "train error: \n",
      " D loss: 1.404422, G loss: 0.639984, D accuracy: 49.8%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.407519, G loss: 0.616370, D accuracy: 49.5%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0609, G loss: 1.0269\n",
      "[84/1762] D loss: 1.3884, G loss: 0.6981\n",
      "[164/1762] D loss: 1.3893, G loss: 0.7362\n",
      "[244/1762] D loss: 1.3880, G loss: 0.7158\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7003\n",
      "[404/1762] D loss: 1.1248, G loss: 1.1981\n",
      "[484/1762] D loss: 1.3889, G loss: 0.7314\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7215\n",
      "[644/1762] D loss: 1.3869, G loss: 0.7143\n",
      "[724/1762] D loss: 1.3882, G loss: 0.7015\n",
      "[804/1762] D loss: 1.3901, G loss: 0.7465\n",
      "[884/1762] D loss: 0.4644, G loss: 1.7959\n",
      "[964/1762] D loss: 1.4141, G loss: 0.7637\n",
      "[1044/1762] D loss: 1.3640, G loss: 0.7670\n",
      "[1124/1762] D loss: 1.3926, G loss: 0.7454\n",
      "[1204/1762] D loss: 1.3857, G loss: 0.7174\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6673\n",
      "[1364/1762] D loss: 1.3606, G loss: 0.7978\n",
      "[1444/1762] D loss: 1.1947, G loss: 0.6702\n",
      "[1524/1762] D loss: 1.3366, G loss: 0.4884\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.7454\n",
      "[1684/1762] D loss: 1.4184, G loss: 0.9239\n",
      "[1762/1762] D loss: 1.4056, G loss: 0.8111\n",
      "train error: \n",
      " D loss: 1.427958, G loss: 0.969755, D accuracy: 52.4%, cell accuracy: 99.5%, board accuracy: 82.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403864, G loss: 0.998939, D accuracy: 53.1%, cell accuracy: 99.4%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4158, G loss: 0.8173\n",
      "[84/1762] D loss: 0.5660, G loss: 1.0421\n",
      "[164/1762] D loss: 1.4121, G loss: 0.8187\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7009\n",
      "[324/1762] D loss: 1.3924, G loss: 0.7278\n",
      "[404/1762] D loss: 1.3430, G loss: 0.8010\n",
      "[484/1762] D loss: 0.4307, G loss: 2.2194\n",
      "[564/1762] D loss: 1.4415, G loss: 0.8148\n",
      "[644/1762] D loss: 1.4257, G loss: 0.8518\n",
      "[724/1762] D loss: 1.4491, G loss: 0.7493\n",
      "[804/1762] D loss: 1.4630, G loss: 0.7243\n",
      "[884/1762] D loss: 0.3663, G loss: 2.0512\n",
      "[964/1762] D loss: 0.5539, G loss: 1.8006\n",
      "[1044/1762] D loss: 1.2534, G loss: 1.0904\n",
      "[1124/1762] D loss: 1.3844, G loss: 0.6742\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.6891\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6860\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.7002\n",
      "[1444/1762] D loss: 1.4320, G loss: 0.8276\n",
      "[1524/1762] D loss: 0.4555, G loss: 1.8067\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.6547\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6838\n",
      "[1762/1762] D loss: 1.5075, G loss: 0.7921\n",
      "train error: \n",
      " D loss: 1.755321, G loss: 0.352424, D accuracy: 52.0%, cell accuracy: 99.7%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.766776, G loss: 0.357592, D accuracy: 52.4%, cell accuracy: 99.6%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2875, G loss: 0.9535\n",
      "[84/1762] D loss: 1.2186, G loss: 1.7708\n",
      "[164/1762] D loss: 1.4165, G loss: 0.6778\n",
      "[244/1762] D loss: 1.5983, G loss: 0.6221\n",
      "[324/1762] D loss: 1.3968, G loss: 0.6556\n",
      "[404/1762] D loss: 0.8952, G loss: 1.9056\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7046\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6623\n",
      "[644/1762] D loss: 0.5126, G loss: 1.7006\n",
      "[724/1762] D loss: 1.3858, G loss: 0.6657\n",
      "[804/1762] D loss: 0.8584, G loss: 1.8731\n",
      "[884/1762] D loss: 1.3936, G loss: 0.7447\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6790\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.7379\n",
      "[1124/1762] D loss: 0.9002, G loss: 1.0735\n",
      "[1204/1762] D loss: 1.3902, G loss: 0.6786\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.7327\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7256\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6925\n",
      "[1524/1762] D loss: 1.3931, G loss: 0.6292\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.6582\n",
      "[1684/1762] D loss: 0.4945, G loss: 1.0984\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7003\n",
      "train error: \n",
      " D loss: 1.342436, G loss: 0.757537, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320675, G loss: 0.760939, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6992\n",
      "[84/1762] D loss: 1.5727, G loss: 1.0334\n",
      "[164/1762] D loss: 1.3935, G loss: 0.7217\n",
      "[244/1762] D loss: 1.3709, G loss: 0.7074\n",
      "[324/1762] D loss: 1.4184, G loss: 0.8726\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7147\n",
      "[484/1762] D loss: 1.1120, G loss: 0.9326\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7121\n",
      "[644/1762] D loss: 1.3885, G loss: 0.7122\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7069\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7139\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6871\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6937\n",
      "[1044/1762] D loss: 1.0543, G loss: 1.1091\n",
      "[1124/1762] D loss: 1.3906, G loss: 0.7218\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.6612\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6784\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6589\n",
      "[1444/1762] D loss: 1.4023, G loss: 0.6999\n",
      "[1524/1762] D loss: 1.4666, G loss: 0.6823\n",
      "[1604/1762] D loss: 1.3775, G loss: 0.6809\n",
      "[1684/1762] D loss: 0.9129, G loss: 0.9688\n",
      "[1762/1762] D loss: 0.5467, G loss: 1.1945\n",
      "train error: \n",
      " D loss: 1.358771, G loss: 0.765187, D accuracy: 52.2%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338495, G loss: 0.771544, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7301, G loss: 0.8839\n",
      "[84/1762] D loss: 1.3923, G loss: 0.7402\n",
      "[164/1762] D loss: 1.3982, G loss: 0.7454\n",
      "[244/1762] D loss: 1.3979, G loss: 0.6137\n",
      "[324/1762] D loss: 1.7777, G loss: 0.9510\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6719\n",
      "[484/1762] D loss: 1.3938, G loss: 0.7504\n",
      "[564/1762] D loss: 1.8333, G loss: 1.0706\n",
      "[644/1762] D loss: 1.3888, G loss: 0.6754\n",
      "[724/1762] D loss: 0.4759, G loss: 1.2552\n",
      "[804/1762] D loss: 1.3903, G loss: 0.6489\n",
      "[884/1762] D loss: 1.3883, G loss: 0.6619\n",
      "[964/1762] D loss: 1.3984, G loss: 0.6418\n",
      "[1044/1762] D loss: 1.4099, G loss: 0.7869\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6795\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.7191\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6831\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6927\n",
      "[1444/1762] D loss: 1.7622, G loss: 1.0690\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6670\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.6700\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7239\n",
      "[1762/1762] D loss: 1.3971, G loss: 0.7770\n",
      "train error: \n",
      " D loss: 1.341757, G loss: 0.893424, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 76.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309788, G loss: 0.950963, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.1703, G loss: 1.0091\n",
      "[84/1762] D loss: 1.3529, G loss: 0.7871\n",
      "[164/1762] D loss: 1.3876, G loss: 0.7061\n",
      "[244/1762] D loss: 1.3910, G loss: 0.6478\n",
      "[324/1762] D loss: 1.3938, G loss: 0.6255\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7011\n",
      "[484/1762] D loss: 1.3757, G loss: 0.6885\n",
      "[564/1762] D loss: 1.0765, G loss: 0.6583\n",
      "[644/1762] D loss: 1.3804, G loss: 0.7226\n",
      "[724/1762] D loss: 1.3900, G loss: 0.7307\n",
      "[804/1762] D loss: 1.3828, G loss: 0.7231\n",
      "[884/1762] D loss: 1.3900, G loss: 0.7305\n",
      "[964/1762] D loss: 1.3796, G loss: 0.7395\n",
      "[1044/1762] D loss: 1.3894, G loss: 0.7099\n",
      "[1124/1762] D loss: 0.5704, G loss: 0.9978\n",
      "[1204/1762] D loss: 1.3382, G loss: 0.7781\n",
      "[1284/1762] D loss: 0.5490, G loss: 1.0833\n",
      "[1364/1762] D loss: 1.4058, G loss: 0.7884\n",
      "[1444/1762] D loss: 1.5402, G loss: 0.8740\n",
      "[1524/1762] D loss: 0.9587, G loss: 0.9440\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.7211\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.6955\n",
      "[1762/1762] D loss: 1.3939, G loss: 0.6366\n",
      "train error: \n",
      " D loss: 1.358145, G loss: 0.758698, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350221, G loss: 0.764737, D accuracy: 52.3%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.8253\n",
      "[84/1762] D loss: 1.2926, G loss: 0.9280\n",
      "[164/1762] D loss: 1.2712, G loss: 0.8338\n",
      "[244/1762] D loss: 1.1416, G loss: 0.9293\n",
      "[324/1762] D loss: 1.0480, G loss: 1.0587\n",
      "[404/1762] D loss: 1.0027, G loss: 1.1443\n",
      "[484/1762] D loss: 0.7621, G loss: 1.5258\n",
      "[564/1762] D loss: 0.5649, G loss: 1.9683\n",
      "[644/1762] D loss: 0.7241, G loss: 2.6526\n",
      "[724/1762] D loss: 1.4865, G loss: 0.7221\n",
      "[804/1762] D loss: 1.1076, G loss: 0.4390\n",
      "[884/1762] D loss: 1.0976, G loss: 1.1211\n",
      "[964/1762] D loss: 1.2608, G loss: 0.7068\n",
      "[1044/1762] D loss: 1.4154, G loss: 0.9173\n",
      "[1124/1762] D loss: 1.3345, G loss: 0.8725\n",
      "[1204/1762] D loss: 1.1948, G loss: 1.1331\n",
      "[1284/1762] D loss: 1.3577, G loss: 0.4204\n",
      "[1364/1762] D loss: 1.3729, G loss: 0.7354\n",
      "[1444/1762] D loss: 1.1679, G loss: 0.8241\n",
      "[1524/1762] D loss: 1.3826, G loss: 0.7952\n",
      "[1604/1762] D loss: 1.2126, G loss: 1.5777\n",
      "[1684/1762] D loss: 1.4297, G loss: 0.8984\n",
      "[1762/1762] D loss: 1.7102, G loss: 0.6629\n",
      "train error: \n",
      " D loss: 1.370862, G loss: 0.551537, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362287, G loss: 0.556310, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2757, G loss: 0.7702\n",
      "[84/1762] D loss: 1.4710, G loss: 0.8698\n",
      "[164/1762] D loss: 1.0795, G loss: 1.2233\n",
      "[244/1762] D loss: 1.3776, G loss: 0.6544\n",
      "[324/1762] D loss: 1.3711, G loss: 1.0392\n",
      "[404/1762] D loss: 1.3813, G loss: 0.7254\n",
      "[484/1762] D loss: 0.6774, G loss: 1.6461\n",
      "[564/1762] D loss: 1.3644, G loss: 0.7074\n",
      "[644/1762] D loss: 1.0656, G loss: 1.0555\n",
      "[724/1762] D loss: 1.0332, G loss: 1.1549\n",
      "[804/1762] D loss: 1.3495, G loss: 0.5815\n",
      "[884/1762] D loss: 1.1178, G loss: 0.9820\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6777\n",
      "[1044/1762] D loss: 1.2933, G loss: 0.7697\n",
      "[1124/1762] D loss: 0.9089, G loss: 1.3144\n",
      "[1204/1762] D loss: 1.4791, G loss: 0.6868\n",
      "[1284/1762] D loss: 1.4100, G loss: 0.9068\n",
      "[1364/1762] D loss: 1.4069, G loss: 0.7447\n",
      "[1444/1762] D loss: 1.3782, G loss: 0.7186\n",
      "[1524/1762] D loss: 1.2990, G loss: 0.9979\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.7253\n",
      "[1684/1762] D loss: 1.3787, G loss: 0.7456\n",
      "[1762/1762] D loss: 0.9084, G loss: 1.0074\n",
      "train error: \n",
      " D loss: 1.472555, G loss: 0.495119, D accuracy: 52.4%, cell accuracy: 99.6%, board accuracy: 68.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.470082, G loss: 0.496770, D accuracy: 53.1%, cell accuracy: 99.5%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5379, G loss: 0.6749\n",
      "[84/1762] D loss: 0.9101, G loss: 1.0552\n",
      "[164/1762] D loss: 1.4973, G loss: 0.7706\n",
      "[244/1762] D loss: 1.4028, G loss: 0.6742\n",
      "[324/1762] D loss: 1.3665, G loss: 0.7400\n",
      "[404/1762] D loss: 1.1316, G loss: 1.0401\n",
      "[484/1762] D loss: 1.3904, G loss: 0.6925\n",
      "[564/1762] D loss: 1.1352, G loss: 0.9364\n",
      "[644/1762] D loss: 1.3659, G loss: 0.6992\n",
      "[724/1762] D loss: 1.0407, G loss: 1.1047\n",
      "[804/1762] D loss: 1.4706, G loss: 0.5945\n",
      "[884/1762] D loss: 1.3803, G loss: 0.6968\n",
      "[964/1762] D loss: 1.3240, G loss: 0.7733\n",
      "[1044/1762] D loss: 1.3981, G loss: 0.8519\n",
      "[1124/1762] D loss: 1.3798, G loss: 0.6835\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.6733\n",
      "[1284/1762] D loss: 1.3310, G loss: 0.7590\n",
      "[1364/1762] D loss: 1.0302, G loss: 1.1009\n",
      "[1444/1762] D loss: 1.5212, G loss: 0.5381\n",
      "[1524/1762] D loss: 1.1228, G loss: 0.8754\n",
      "[1604/1762] D loss: 1.1381, G loss: 0.9236\n",
      "[1684/1762] D loss: 1.3266, G loss: 0.8353\n",
      "[1762/1762] D loss: 1.3544, G loss: 0.6008\n",
      "train error: \n",
      " D loss: 1.354099, G loss: 0.668284, D accuracy: 56.2%, cell accuracy: 99.5%, board accuracy: 71.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350749, G loss: 0.680665, D accuracy: 55.8%, cell accuracy: 99.5%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3738, G loss: 0.8031\n",
      "[84/1762] D loss: 1.2927, G loss: 0.7558\n",
      "[164/1762] D loss: 1.3621, G loss: 0.8098\n",
      "[244/1762] D loss: 1.3995, G loss: 0.7221\n",
      "[324/1762] D loss: 1.3423, G loss: 0.7557\n",
      "[404/1762] D loss: 1.1543, G loss: 0.8922\n",
      "[484/1762] D loss: 1.3885, G loss: 0.7368\n",
      "[564/1762] D loss: 1.1093, G loss: 0.9760\n",
      "[644/1762] D loss: 1.0541, G loss: 0.9929\n",
      "[724/1762] D loss: 1.4142, G loss: 0.6792\n",
      "[804/1762] D loss: 1.4627, G loss: 0.6603\n",
      "[884/1762] D loss: 1.4783, G loss: 0.6513\n",
      "[964/1762] D loss: 1.3946, G loss: 0.6018\n",
      "[1044/1762] D loss: 1.1402, G loss: 1.3587\n",
      "[1124/1762] D loss: 0.6479, G loss: 1.6417\n",
      "[1204/1762] D loss: 1.5149, G loss: 0.6558\n",
      "[1284/1762] D loss: 1.2338, G loss: 0.9288\n",
      "[1364/1762] D loss: 1.3238, G loss: 0.8004\n",
      "[1444/1762] D loss: 0.9659, G loss: 1.0392\n",
      "[1524/1762] D loss: 1.3964, G loss: 0.7578\n",
      "[1604/1762] D loss: 1.5437, G loss: 0.7786\n",
      "[1684/1762] D loss: 1.4045, G loss: 0.8281\n",
      "[1762/1762] D loss: 1.6612, G loss: 0.2955\n",
      "train error: \n",
      " D loss: 1.356039, G loss: 0.628753, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344565, G loss: 0.639085, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5373, G loss: 0.6324\n",
      "[84/1762] D loss: 0.8157, G loss: 1.2329\n",
      "[164/1762] D loss: 1.4226, G loss: 0.7707\n",
      "[244/1762] D loss: 1.4120, G loss: 0.7176\n",
      "[324/1762] D loss: 0.9494, G loss: 1.1210\n",
      "[404/1762] D loss: 1.4023, G loss: 0.7038\n",
      "[484/1762] D loss: 1.4111, G loss: 0.7103\n",
      "[564/1762] D loss: 0.8206, G loss: 1.2548\n",
      "[644/1762] D loss: 1.4885, G loss: 0.6639\n",
      "[724/1762] D loss: 1.1041, G loss: 1.1609\n",
      "[804/1762] D loss: 1.4088, G loss: 0.8613\n",
      "[884/1762] D loss: 1.0043, G loss: 1.1545\n",
      "[964/1762] D loss: 1.3976, G loss: 0.6791\n",
      "[1044/1762] D loss: 1.3948, G loss: 0.7236\n",
      "[1124/1762] D loss: 1.3970, G loss: 0.6894\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6918\n",
      "[1284/1762] D loss: 0.8570, G loss: 1.2437\n",
      "[1364/1762] D loss: 1.3471, G loss: 0.7659\n",
      "[1444/1762] D loss: 0.7935, G loss: 1.5411\n",
      "[1524/1762] D loss: 1.5347, G loss: 0.5310\n",
      "[1604/1762] D loss: 0.6446, G loss: 1.7993\n",
      "[1684/1762] D loss: 0.8343, G loss: 1.2563\n",
      "[1762/1762] D loss: 1.4903, G loss: 0.6359\n",
      "train error: \n",
      " D loss: 1.345855, G loss: 0.665281, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331061, G loss: 0.686507, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8109, G loss: 1.2207\n",
      "[84/1762] D loss: 0.5508, G loss: 1.6476\n",
      "[164/1762] D loss: 1.4823, G loss: 0.5720\n",
      "[244/1762] D loss: 1.4415, G loss: 0.6728\n",
      "[324/1762] D loss: 1.4070, G loss: 0.7356\n",
      "[404/1762] D loss: 1.3977, G loss: 0.7947\n",
      "[484/1762] D loss: 0.7283, G loss: 1.5016\n",
      "[564/1762] D loss: 1.7082, G loss: 0.5677\n",
      "[644/1762] D loss: 0.5946, G loss: 1.5167\n",
      "[724/1762] D loss: 1.4314, G loss: 0.7905\n",
      "[804/1762] D loss: 0.5805, G loss: 1.6347\n",
      "[884/1762] D loss: 1.3960, G loss: 0.7279\n",
      "[964/1762] D loss: 1.3967, G loss: 0.6737\n",
      "[1044/1762] D loss: 1.3217, G loss: 0.7568\n",
      "[1124/1762] D loss: 1.4015, G loss: 0.6728\n",
      "[1204/1762] D loss: 1.6459, G loss: 0.5939\n",
      "[1284/1762] D loss: 0.5575, G loss: 1.5610\n",
      "[1364/1762] D loss: 0.4419, G loss: 1.8558\n",
      "[1444/1762] D loss: 1.4218, G loss: 0.7002\n",
      "[1524/1762] D loss: 0.5554, G loss: 1.6400\n",
      "[1604/1762] D loss: 1.3950, G loss: 0.6763\n",
      "[1684/1762] D loss: 0.4640, G loss: 1.7547\n",
      "[1762/1762] D loss: 1.4250, G loss: 0.4376\n",
      "train error: \n",
      " D loss: 1.368665, G loss: 0.595732, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353618, G loss: 0.603595, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4271, G loss: 0.5688\n",
      "[84/1762] D loss: 1.3901, G loss: 0.7338\n",
      "[164/1762] D loss: 1.6572, G loss: 0.6824\n",
      "[244/1762] D loss: 1.3934, G loss: 0.6932\n",
      "[324/1762] D loss: 1.4359, G loss: 0.7400\n",
      "[404/1762] D loss: 1.4212, G loss: 0.6638\n",
      "[484/1762] D loss: 0.5967, G loss: 1.7882\n",
      "[564/1762] D loss: 1.3953, G loss: 0.6916\n",
      "[644/1762] D loss: 1.4278, G loss: 0.7106\n",
      "[724/1762] D loss: 1.4257, G loss: 0.6413\n",
      "[804/1762] D loss: 1.4193, G loss: 0.7438\n",
      "[884/1762] D loss: 1.4322, G loss: 0.6220\n",
      "[964/1762] D loss: 0.6483, G loss: 1.4820\n",
      "[1044/1762] D loss: 0.7836, G loss: 1.2112\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.6988\n",
      "[1204/1762] D loss: 0.8612, G loss: 1.2326\n",
      "[1284/1762] D loss: 1.4245, G loss: 0.6356\n",
      "[1364/1762] D loss: 1.4010, G loss: 0.6974\n",
      "[1444/1762] D loss: 0.6749, G loss: 1.4522\n",
      "[1524/1762] D loss: 1.3929, G loss: 0.6270\n",
      "[1604/1762] D loss: 1.5183, G loss: 0.7902\n",
      "[1684/1762] D loss: 1.5382, G loss: 0.6893\n",
      "[1762/1762] D loss: 1.4043, G loss: 0.7082\n",
      "train error: \n",
      " D loss: 1.343354, G loss: 0.681631, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324218, G loss: 0.690317, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4965, G loss: 0.6495\n",
      "[84/1762] D loss: 1.5454, G loss: 0.8192\n",
      "[164/1762] D loss: 1.6233, G loss: 0.6778\n",
      "[244/1762] D loss: 1.3973, G loss: 0.6831\n",
      "[324/1762] D loss: 1.4168, G loss: 0.8077\n",
      "[404/1762] D loss: 1.4206, G loss: 0.7947\n",
      "[484/1762] D loss: 1.3882, G loss: 0.7010\n",
      "[564/1762] D loss: 1.1121, G loss: 0.8499\n",
      "[644/1762] D loss: 1.7382, G loss: 0.8573\n",
      "[724/1762] D loss: 1.3604, G loss: 0.7250\n",
      "[804/1762] D loss: 1.4038, G loss: 0.6981\n",
      "[884/1762] D loss: 1.3916, G loss: 0.6820\n",
      "[964/1762] D loss: 0.8589, G loss: 1.0495\n",
      "[1044/1762] D loss: 1.3928, G loss: 0.6972\n",
      "[1124/1762] D loss: 1.4149, G loss: 0.6571\n",
      "[1204/1762] D loss: 1.5108, G loss: 0.6771\n",
      "[1284/1762] D loss: 1.3723, G loss: 0.7700\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.6844\n",
      "[1444/1762] D loss: 1.2707, G loss: 0.6338\n",
      "[1524/1762] D loss: 1.3978, G loss: 0.6998\n",
      "[1604/1762] D loss: 1.3927, G loss: 0.6843\n",
      "[1684/1762] D loss: 0.7355, G loss: 1.2843\n",
      "[1762/1762] D loss: 1.4091, G loss: 0.6863\n",
      "train error: \n",
      " D loss: 1.372952, G loss: 0.541534, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362765, G loss: 0.540012, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4128, G loss: 0.6941\n",
      "[84/1762] D loss: 1.4035, G loss: 0.7209\n",
      "[164/1762] D loss: 0.6525, G loss: 1.3584\n",
      "[244/1762] D loss: 1.3491, G loss: 0.9237\n",
      "[324/1762] D loss: 1.4049, G loss: 0.7022\n",
      "[404/1762] D loss: 1.3921, G loss: 0.7079\n",
      "[484/1762] D loss: 1.3973, G loss: 0.7069\n",
      "[564/1762] D loss: 1.3898, G loss: 0.6779\n",
      "[644/1762] D loss: 1.3222, G loss: 0.9703\n",
      "[724/1762] D loss: 1.3965, G loss: 0.6691\n",
      "[804/1762] D loss: 1.6426, G loss: 0.5633\n",
      "[884/1762] D loss: 0.4030, G loss: 1.9955\n",
      "[964/1762] D loss: 1.6421, G loss: 0.4745\n",
      "[1044/1762] D loss: 0.4513, G loss: 1.6266\n",
      "[1124/1762] D loss: 1.3990, G loss: 0.6723\n",
      "[1204/1762] D loss: 1.5615, G loss: 0.6187\n",
      "[1284/1762] D loss: 0.3523, G loss: 1.9055\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7008\n",
      "[1444/1762] D loss: 1.4770, G loss: 0.6016\n",
      "[1524/1762] D loss: 1.4028, G loss: 0.7015\n",
      "[1604/1762] D loss: 1.4332, G loss: 0.6779\n",
      "[1684/1762] D loss: 0.3480, G loss: 1.8346\n",
      "[1762/1762] D loss: 1.6246, G loss: 0.8067\n",
      "train error: \n",
      " D loss: 1.696665, G loss: 0.297516, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.691729, G loss: 0.296917, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4048, G loss: 0.7587\n",
      "[84/1762] D loss: 1.3894, G loss: 0.6994\n",
      "[164/1762] D loss: 1.3539, G loss: 0.7899\n",
      "[244/1762] D loss: 0.7022, G loss: 1.4442\n",
      "[324/1762] D loss: 1.5512, G loss: 1.2215\n",
      "[404/1762] D loss: 1.6125, G loss: 0.6598\n",
      "[484/1762] D loss: 1.4072, G loss: 0.6927\n",
      "[564/1762] D loss: 0.3955, G loss: 1.8561\n",
      "[644/1762] D loss: 1.4640, G loss: 0.6870\n",
      "[724/1762] D loss: 1.2573, G loss: 0.8081\n",
      "[804/1762] D loss: 1.4614, G loss: 0.7090\n",
      "[884/1762] D loss: 1.4352, G loss: 0.6806\n",
      "[964/1762] D loss: 1.3970, G loss: 0.6987\n",
      "[1044/1762] D loss: 1.3172, G loss: 0.7833\n",
      "[1124/1762] D loss: 0.4616, G loss: 1.8303\n",
      "[1204/1762] D loss: 1.4079, G loss: 0.7296\n",
      "[1284/1762] D loss: 1.4226, G loss: 0.7328\n",
      "[1364/1762] D loss: 1.4270, G loss: 0.7365\n",
      "[1444/1762] D loss: 1.3813, G loss: 0.6951\n",
      "[1524/1762] D loss: 1.3976, G loss: 0.7126\n",
      "[1604/1762] D loss: 1.4306, G loss: 0.8995\n",
      "[1684/1762] D loss: 1.6266, G loss: 0.7193\n",
      "[1762/1762] D loss: 1.4660, G loss: 0.7866\n",
      "train error: \n",
      " D loss: 1.393018, G loss: 0.512367, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376922, G loss: 0.520216, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3949, G loss: 0.6975\n",
      "[84/1762] D loss: 1.4566, G loss: 0.6485\n",
      "[164/1762] D loss: 1.5040, G loss: 0.9027\n",
      "[244/1762] D loss: 0.4863, G loss: 1.7348\n",
      "[324/1762] D loss: 1.2953, G loss: 0.7815\n",
      "[404/1762] D loss: 0.1745, G loss: 2.4888\n",
      "[484/1762] D loss: 1.2760, G loss: 0.8396\n",
      "[564/1762] D loss: 1.4338, G loss: 0.6377\n",
      "[644/1762] D loss: 1.3792, G loss: 0.7010\n",
      "[724/1762] D loss: 0.8573, G loss: 1.2223\n",
      "[804/1762] D loss: 1.3482, G loss: 0.7301\n",
      "[884/1762] D loss: 1.4543, G loss: 0.5902\n",
      "[964/1762] D loss: 1.4055, G loss: 0.6963\n",
      "[1044/1762] D loss: 1.3953, G loss: 0.6813\n",
      "[1124/1762] D loss: 1.3622, G loss: 0.7506\n",
      "[1204/1762] D loss: 1.4669, G loss: 0.7967\n",
      "[1284/1762] D loss: 1.4411, G loss: 0.7891\n",
      "[1364/1762] D loss: 1.4232, G loss: 0.6609\n",
      "[1444/1762] D loss: 1.4165, G loss: 0.6751\n",
      "[1524/1762] D loss: 1.1508, G loss: 1.6658\n",
      "[1604/1762] D loss: 1.3937, G loss: 0.8310\n",
      "[1684/1762] D loss: 1.3378, G loss: 0.9668\n",
      "[1762/1762] D loss: 1.4011, G loss: 0.6696\n",
      "train error: \n",
      " D loss: 1.389486, G loss: 1.051462, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366705, G loss: 1.061143, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4364, G loss: 0.6702\n",
      "[84/1762] D loss: 1.4052, G loss: 0.7321\n",
      "[164/1762] D loss: 1.1484, G loss: 0.9002\n",
      "[244/1762] D loss: 0.5703, G loss: 1.6106\n",
      "[324/1762] D loss: 1.3340, G loss: 0.8491\n",
      "[404/1762] D loss: 1.4516, G loss: 0.4931\n",
      "[484/1762] D loss: 0.2199, G loss: 2.2010\n",
      "[564/1762] D loss: 0.4752, G loss: 1.7428\n",
      "[644/1762] D loss: 1.3898, G loss: 0.7648\n",
      "[724/1762] D loss: 1.3142, G loss: 0.7916\n",
      "[804/1762] D loss: 0.4633, G loss: 1.6781\n",
      "[884/1762] D loss: 1.4415, G loss: 0.6448\n",
      "[964/1762] D loss: 0.3330, G loss: 1.8830\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.6731\n",
      "[1124/1762] D loss: 0.0926, G loss: 3.4347\n",
      "[1204/1762] D loss: 1.4516, G loss: 0.8458\n",
      "[1284/1762] D loss: 1.4042, G loss: 0.7030\n",
      "[1364/1762] D loss: 1.4029, G loss: 0.7604\n",
      "[1444/1762] D loss: 1.3462, G loss: 0.8177\n",
      "[1524/1762] D loss: 1.8004, G loss: 1.4231\n",
      "[1604/1762] D loss: 1.2123, G loss: 0.9460\n",
      "[1684/1762] D loss: 1.5019, G loss: 0.6644\n",
      "[1762/1762] D loss: 1.3767, G loss: 0.6883\n",
      "train error: \n",
      " D loss: 1.354206, G loss: 0.731277, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351671, G loss: 0.736979, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4153, G loss: 0.7099\n",
      "[84/1762] D loss: 1.4007, G loss: 0.6572\n",
      "[164/1762] D loss: 0.8690, G loss: 1.1014\n",
      "[244/1762] D loss: 1.4526, G loss: 0.7633\n",
      "[324/1762] D loss: 0.5437, G loss: 1.4341\n",
      "[404/1762] D loss: 0.4962, G loss: 1.4691\n",
      "[484/1762] D loss: 1.3895, G loss: 0.7138\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7599\n",
      "[644/1762] D loss: 0.8476, G loss: 1.2547\n",
      "[724/1762] D loss: 1.3615, G loss: 0.7571\n",
      "[804/1762] D loss: 1.4140, G loss: 0.6857\n",
      "[884/1762] D loss: 1.4032, G loss: 0.7054\n",
      "[964/1762] D loss: 1.3992, G loss: 0.7018\n",
      "[1044/1762] D loss: 1.4366, G loss: 0.5492\n",
      "[1124/1762] D loss: 1.4528, G loss: 0.7650\n",
      "[1204/1762] D loss: 1.4075, G loss: 0.6110\n",
      "[1284/1762] D loss: 0.5784, G loss: 1.4581\n",
      "[1364/1762] D loss: 1.4529, G loss: 0.6719\n",
      "[1444/1762] D loss: 1.3752, G loss: 0.7129\n",
      "[1524/1762] D loss: 1.3710, G loss: 0.7594\n",
      "[1604/1762] D loss: 1.4058, G loss: 0.7622\n",
      "[1684/1762] D loss: 0.2199, G loss: 2.3923\n",
      "[1762/1762] D loss: 1.4504, G loss: 0.7502\n",
      "train error: \n",
      " D loss: 1.350562, G loss: 0.776862, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331189, G loss: 0.778028, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4399, G loss: 0.6601\n",
      "[84/1762] D loss: 0.5412, G loss: 1.4812\n",
      "[164/1762] D loss: 1.4377, G loss: 0.6625\n",
      "[244/1762] D loss: 1.2683, G loss: 0.9994\n",
      "[324/1762] D loss: 1.4129, G loss: 0.7725\n",
      "[404/1762] D loss: 0.3214, G loss: 1.8427\n",
      "[484/1762] D loss: 0.3214, G loss: 1.8835\n",
      "[564/1762] D loss: 0.3962, G loss: 2.1510\n",
      "[644/1762] D loss: 1.3887, G loss: 0.6880\n",
      "[724/1762] D loss: 1.5718, G loss: 0.7407\n",
      "[804/1762] D loss: 1.5150, G loss: 0.6190\n",
      "[884/1762] D loss: 1.4203, G loss: 0.7100\n",
      "[964/1762] D loss: 0.4177, G loss: 1.9405\n",
      "[1044/1762] D loss: 0.3907, G loss: 1.7316\n",
      "[1124/1762] D loss: 0.4992, G loss: 1.5494\n",
      "[1204/1762] D loss: 1.3907, G loss: 0.6991\n",
      "[1284/1762] D loss: 1.4031, G loss: 0.7157\n",
      "[1364/1762] D loss: 1.3208, G loss: 0.7517\n",
      "[1444/1762] D loss: 1.4138, G loss: 0.6475\n",
      "[1524/1762] D loss: 0.4277, G loss: 1.6899\n",
      "[1604/1762] D loss: 1.4086, G loss: 0.6695\n",
      "[1684/1762] D loss: 1.5242, G loss: 0.5233\n",
      "[1762/1762] D loss: 1.4221, G loss: 0.7948\n",
      "train error: \n",
      " D loss: 1.323217, G loss: 0.740706, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303450, G loss: 0.747606, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4153, G loss: 0.6339\n",
      "[84/1762] D loss: 0.4188, G loss: 1.8264\n",
      "[164/1762] D loss: 1.3952, G loss: 0.7005\n",
      "[244/1762] D loss: 1.4110, G loss: 0.6934\n",
      "[324/1762] D loss: 1.4702, G loss: 0.6666\n",
      "[404/1762] D loss: 0.2342, G loss: 2.0677\n",
      "[484/1762] D loss: 1.4329, G loss: 0.6600\n",
      "[564/1762] D loss: 1.3964, G loss: 0.7021\n",
      "[644/1762] D loss: 1.3840, G loss: 0.6902\n",
      "[724/1762] D loss: 1.4578, G loss: 0.8461\n",
      "[804/1762] D loss: 0.2049, G loss: 2.2621\n",
      "[884/1762] D loss: 1.4133, G loss: 0.6256\n",
      "[964/1762] D loss: 1.5199, G loss: 0.5633\n",
      "[1044/1762] D loss: 1.4405, G loss: 0.7514\n",
      "[1124/1762] D loss: 1.3998, G loss: 0.7093\n",
      "[1204/1762] D loss: 0.2834, G loss: 1.9401\n",
      "[1284/1762] D loss: 0.2731, G loss: 1.9717\n",
      "[1364/1762] D loss: 0.4046, G loss: 1.7230\n",
      "[1444/1762] D loss: 1.4101, G loss: 0.7154\n",
      "[1524/1762] D loss: 1.4865, G loss: 0.6122\n",
      "[1604/1762] D loss: 1.4224, G loss: 0.6393\n",
      "[1684/1762] D loss: 0.4926, G loss: 1.5055\n",
      "[1762/1762] D loss: 0.1182, G loss: 2.6030\n",
      "train error: \n",
      " D loss: 1.329998, G loss: 0.712024, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317375, G loss: 0.707103, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2332, G loss: 2.0786\n",
      "[84/1762] D loss: 1.5108, G loss: 0.6142\n",
      "[164/1762] D loss: 1.2572, G loss: 0.9268\n",
      "[244/1762] D loss: 1.3962, G loss: 0.7434\n",
      "[324/1762] D loss: 1.3984, G loss: 0.7327\n",
      "[404/1762] D loss: 0.4127, G loss: 1.8496\n",
      "[484/1762] D loss: 0.3569, G loss: 1.7961\n",
      "[564/1762] D loss: 0.3633, G loss: 1.8713\n",
      "[644/1762] D loss: 1.3833, G loss: 0.7201\n",
      "[724/1762] D loss: 1.5347, G loss: 1.0966\n",
      "[804/1762] D loss: 0.2573, G loss: 2.2044\n",
      "[884/1762] D loss: 0.3041, G loss: 1.9881\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7211\n",
      "[1044/1762] D loss: 0.3029, G loss: 2.1270\n",
      "[1124/1762] D loss: 1.3300, G loss: 1.1543\n",
      "[1204/1762] D loss: 1.3696, G loss: 0.6929\n",
      "[1284/1762] D loss: 0.3981, G loss: 1.9256\n",
      "[1364/1762] D loss: 0.2702, G loss: 2.0357\n",
      "[1444/1762] D loss: 1.3192, G loss: 1.1077\n",
      "[1524/1762] D loss: 1.4074, G loss: 0.6619\n",
      "[1604/1762] D loss: 1.2602, G loss: 0.8359\n",
      "[1684/1762] D loss: 0.1783, G loss: 2.4475\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6953\n",
      "train error: \n",
      " D loss: 1.320126, G loss: 0.730946, D accuracy: 55.2%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303302, G loss: 0.732832, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2218, G loss: 0.9247\n",
      "[84/1762] D loss: 1.3816, G loss: 0.6803\n",
      "[164/1762] D loss: 0.1915, G loss: 2.3791\n",
      "[244/1762] D loss: 1.5010, G loss: 0.7988\n",
      "[324/1762] D loss: 1.3907, G loss: 0.6773\n",
      "[404/1762] D loss: 1.4109, G loss: 0.6274\n",
      "[484/1762] D loss: 0.1809, G loss: 2.5889\n",
      "[564/1762] D loss: 1.1669, G loss: 0.7939\n",
      "[644/1762] D loss: 1.5284, G loss: 0.4447\n",
      "[724/1762] D loss: 1.3696, G loss: 0.7193\n",
      "[804/1762] D loss: 1.2776, G loss: 0.7818\n",
      "[884/1762] D loss: 1.4929, G loss: 0.7335\n",
      "[964/1762] D loss: 1.4101, G loss: 0.7142\n",
      "[1044/1762] D loss: 1.3992, G loss: 0.6942\n",
      "[1124/1762] D loss: 1.4376, G loss: 0.7354\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.6833\n",
      "[1284/1762] D loss: 1.4462, G loss: 0.7405\n",
      "[1364/1762] D loss: 0.2733, G loss: 2.3099\n",
      "[1444/1762] D loss: 0.1614, G loss: 2.4865\n",
      "[1524/1762] D loss: 1.4405, G loss: 0.3857\n",
      "[1604/1762] D loss: 1.3069, G loss: 0.7504\n",
      "[1684/1762] D loss: 0.2519, G loss: 2.7271\n",
      "[1762/1762] D loss: 1.4107, G loss: 0.6144\n",
      "train error: \n",
      " D loss: 1.403298, G loss: 0.537115, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390489, G loss: 0.535341, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3897, G loss: 0.6957\n",
      "[84/1762] D loss: 1.4114, G loss: 0.6485\n",
      "[164/1762] D loss: 1.4455, G loss: 0.7347\n",
      "[244/1762] D loss: 0.2796, G loss: 2.0550\n",
      "[324/1762] D loss: 1.4339, G loss: 0.5768\n",
      "[404/1762] D loss: 0.4139, G loss: 2.0414\n",
      "[484/1762] D loss: 1.4350, G loss: 0.6820\n",
      "[564/1762] D loss: 0.5342, G loss: 2.0370\n",
      "[644/1762] D loss: 1.3859, G loss: 0.7200\n",
      "[724/1762] D loss: 0.1450, G loss: 2.7121\n",
      "[804/1762] D loss: 1.3974, G loss: 0.6512\n",
      "[884/1762] D loss: 1.3958, G loss: 0.6798\n",
      "[964/1762] D loss: 1.3956, G loss: 0.7109\n",
      "[1044/1762] D loss: 0.2190, G loss: 2.2310\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.7050\n",
      "[1204/1762] D loss: 1.3976, G loss: 0.7342\n",
      "[1284/1762] D loss: 0.2917, G loss: 2.0168\n",
      "[1364/1762] D loss: 1.4061, G loss: 0.6328\n",
      "[1444/1762] D loss: 1.4791, G loss: 0.5928\n",
      "[1524/1762] D loss: 1.4442, G loss: 0.5664\n",
      "[1604/1762] D loss: 1.4810, G loss: 0.5651\n",
      "[1684/1762] D loss: 1.4954, G loss: 0.8275\n",
      "[1762/1762] D loss: 1.3926, G loss: 0.6682\n",
      "train error: \n",
      " D loss: 1.354074, G loss: 0.605148, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343011, G loss: 0.609487, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3955, G loss: 0.6928\n",
      "[84/1762] D loss: 1.3860, G loss: 0.6880\n",
      "[164/1762] D loss: 1.4007, G loss: 0.7014\n",
      "[244/1762] D loss: 1.4868, G loss: 0.6865\n",
      "[324/1762] D loss: 1.5815, G loss: 0.6129\n",
      "[404/1762] D loss: 0.4492, G loss: 1.8053\n",
      "[484/1762] D loss: 0.3841, G loss: 1.9950\n",
      "[564/1762] D loss: 1.3709, G loss: 0.7190\n",
      "[644/1762] D loss: 1.7506, G loss: 0.4257\n",
      "[724/1762] D loss: 0.5163, G loss: 2.1972\n",
      "[804/1762] D loss: 1.1744, G loss: 1.1583\n",
      "[884/1762] D loss: 0.4990, G loss: 1.6643\n",
      "[964/1762] D loss: 1.4012, G loss: 0.7148\n",
      "[1044/1762] D loss: 0.5881, G loss: 1.7318\n",
      "[1124/1762] D loss: 0.2468, G loss: 2.2929\n",
      "[1204/1762] D loss: 0.1969, G loss: 2.3613\n",
      "[1284/1762] D loss: 1.5031, G loss: 0.4834\n",
      "[1364/1762] D loss: 0.7971, G loss: 1.6897\n",
      "[1444/1762] D loss: 1.4067, G loss: 0.6895\n",
      "[1524/1762] D loss: 1.4068, G loss: 0.6774\n",
      "[1604/1762] D loss: 1.6058, G loss: 0.5931\n",
      "[1684/1762] D loss: 1.3835, G loss: 0.6980\n",
      "[1762/1762] D loss: 1.4141, G loss: 0.8249\n",
      "train error: \n",
      " D loss: 1.325100, G loss: 0.804557, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301315, G loss: 0.831749, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4037, G loss: 0.6429\n",
      "[84/1762] D loss: 1.3637, G loss: 0.7000\n",
      "[164/1762] D loss: 1.4446, G loss: 0.7422\n",
      "[244/1762] D loss: 1.4256, G loss: 0.6438\n",
      "[324/1762] D loss: 1.4072, G loss: 0.6643\n",
      "[404/1762] D loss: 1.5195, G loss: 0.6564\n",
      "[484/1762] D loss: 1.4224, G loss: 1.1508\n",
      "[564/1762] D loss: 1.4122, G loss: 0.7096\n",
      "[644/1762] D loss: 1.4808, G loss: 0.6744\n",
      "[724/1762] D loss: 1.4546, G loss: 0.8536\n",
      "[804/1762] D loss: 0.3435, G loss: 2.3376\n",
      "[884/1762] D loss: 0.2301, G loss: 2.0965\n",
      "[964/1762] D loss: 0.5279, G loss: 1.7121\n",
      "[1044/1762] D loss: 1.4137, G loss: 0.6401\n",
      "[1124/1762] D loss: 1.4889, G loss: 0.6075\n",
      "[1204/1762] D loss: 0.2220, G loss: 2.2171\n",
      "[1284/1762] D loss: 1.2894, G loss: 0.7829\n",
      "[1364/1762] D loss: 1.4299, G loss: 0.6521\n",
      "[1444/1762] D loss: 1.1110, G loss: 0.9101\n",
      "[1524/1762] D loss: 1.4763, G loss: 1.1255\n",
      "[1604/1762] D loss: 1.6418, G loss: 0.4409\n",
      "[1684/1762] D loss: 0.3732, G loss: 1.8958\n",
      "[1762/1762] D loss: 1.5393, G loss: 0.9724\n",
      "train error: \n",
      " D loss: 1.345306, G loss: 0.889132, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323536, G loss: 0.898466, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4099, G loss: 0.6713\n",
      "[84/1762] D loss: 1.4301, G loss: 0.6009\n",
      "[164/1762] D loss: 0.4044, G loss: 1.7456\n",
      "[244/1762] D loss: 1.4069, G loss: 0.6437\n",
      "[324/1762] D loss: 1.4328, G loss: 0.5325\n",
      "[404/1762] D loss: 1.3441, G loss: 0.8317\n",
      "[484/1762] D loss: 0.2656, G loss: 2.2199\n",
      "[564/1762] D loss: 1.2747, G loss: 1.1598\n",
      "[644/1762] D loss: 1.6780, G loss: 0.5302\n",
      "[724/1762] D loss: 1.4394, G loss: 0.4383\n",
      "[804/1762] D loss: 1.4380, G loss: 0.6123\n",
      "[884/1762] D loss: 1.3617, G loss: 0.7200\n",
      "[964/1762] D loss: 1.4141, G loss: 0.7057\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.6770\n",
      "[1124/1762] D loss: 1.4146, G loss: 0.6935\n",
      "[1204/1762] D loss: 1.4003, G loss: 0.6651\n",
      "[1284/1762] D loss: 1.4108, G loss: 0.6731\n",
      "[1364/1762] D loss: 1.4007, G loss: 0.6612\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.6925\n",
      "[1524/1762] D loss: 1.4260, G loss: 0.6439\n",
      "[1604/1762] D loss: 1.4113, G loss: 0.6194\n",
      "[1684/1762] D loss: 1.4294, G loss: 0.8243\n",
      "[1762/1762] D loss: 1.2894, G loss: 0.7383\n",
      "train error: \n",
      " D loss: 1.423997, G loss: 0.476981, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411339, G loss: 0.480908, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2724, G loss: 2.0629\n",
      "[84/1762] D loss: 1.4007, G loss: 0.6666\n",
      "[164/1762] D loss: 1.4038, G loss: 0.6588\n",
      "[244/1762] D loss: 1.4577, G loss: 0.6035\n",
      "[324/1762] D loss: 0.2280, G loss: 2.2722\n",
      "[404/1762] D loss: 1.7374, G loss: 0.4620\n",
      "[484/1762] D loss: 0.1690, G loss: 2.4870\n",
      "[564/1762] D loss: 2.1551, G loss: 1.7965\n",
      "[644/1762] D loss: 0.2890, G loss: 1.9881\n",
      "[724/1762] D loss: 0.1324, G loss: 2.6533\n",
      "[804/1762] D loss: 1.5321, G loss: 0.5554\n",
      "[884/1762] D loss: 1.3463, G loss: 0.7602\n",
      "[964/1762] D loss: 0.7704, G loss: 2.0203\n",
      "[1044/1762] D loss: 1.4024, G loss: 0.6797\n",
      "[1124/1762] D loss: 0.3077, G loss: 2.2584\n",
      "[1204/1762] D loss: 1.5944, G loss: 1.6625\n",
      "[1284/1762] D loss: 1.4160, G loss: 0.6673\n",
      "[1364/1762] D loss: 1.5291, G loss: 0.5672\n",
      "[1444/1762] D loss: 1.2158, G loss: 1.1760\n",
      "[1524/1762] D loss: 1.5101, G loss: 0.4445\n",
      "[1604/1762] D loss: 1.1715, G loss: 1.0302\n",
      "[1684/1762] D loss: 1.4317, G loss: 0.7768\n",
      "[1762/1762] D loss: 1.3970, G loss: 0.7299\n",
      "train error: \n",
      " D loss: 1.319873, G loss: 0.818173, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300296, G loss: 0.836627, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1799, G loss: 2.6096\n",
      "[84/1762] D loss: 1.4544, G loss: 0.8537\n",
      "[164/1762] D loss: 0.1974, G loss: 2.3075\n",
      "[244/1762] D loss: 1.3839, G loss: 0.7141\n",
      "[324/1762] D loss: 1.2015, G loss: 0.9643\n",
      "[404/1762] D loss: 1.8687, G loss: 0.4297\n",
      "[484/1762] D loss: 1.3096, G loss: 0.7915\n",
      "[564/1762] D loss: 1.4259, G loss: 0.7658\n",
      "[644/1762] D loss: 0.3807, G loss: 1.7393\n",
      "[724/1762] D loss: 0.0588, G loss: 3.1807\n",
      "[804/1762] D loss: 1.4239, G loss: 0.6545\n",
      "[884/1762] D loss: 1.4741, G loss: 0.4590\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6822\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.7035\n",
      "[1124/1762] D loss: 0.4034, G loss: 1.7684\n",
      "[1204/1762] D loss: 0.8078, G loss: 1.4473\n",
      "[1284/1762] D loss: 1.4425, G loss: 1.1727\n",
      "[1364/1762] D loss: 0.2399, G loss: 2.0868\n",
      "[1444/1762] D loss: 0.2806, G loss: 2.7359\n",
      "[1524/1762] D loss: 1.4165, G loss: 0.6185\n",
      "[1604/1762] D loss: 1.2635, G loss: 1.3315\n",
      "[1684/1762] D loss: 0.3531, G loss: 2.2348\n",
      "[1762/1762] D loss: 1.5599, G loss: 1.1595\n",
      "train error: \n",
      " D loss: 1.354075, G loss: 0.698175, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337898, G loss: 0.700513, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5761, G loss: 0.5367\n",
      "[84/1762] D loss: 1.3897, G loss: 0.7050\n",
      "[164/1762] D loss: 1.3855, G loss: 0.6860\n",
      "[244/1762] D loss: 0.3070, G loss: 2.0937\n",
      "[324/1762] D loss: 0.1882, G loss: 2.4241\n",
      "[404/1762] D loss: 1.4622, G loss: 0.5223\n",
      "[484/1762] D loss: 0.3761, G loss: 2.4874\n",
      "[564/1762] D loss: 1.4011, G loss: 0.6007\n",
      "[644/1762] D loss: 1.4514, G loss: 0.7787\n",
      "[724/1762] D loss: 1.5593, G loss: 0.4687\n",
      "[804/1762] D loss: 0.1939, G loss: 2.5938\n",
      "[884/1762] D loss: 1.4697, G loss: 0.7640\n",
      "[964/1762] D loss: 0.1784, G loss: 2.4009\n",
      "[1044/1762] D loss: 0.1327, G loss: 2.7378\n",
      "[1124/1762] D loss: 0.7167, G loss: 1.5644\n",
      "[1204/1762] D loss: 1.3967, G loss: 0.7254\n",
      "[1284/1762] D loss: 1.4354, G loss: 0.6759\n",
      "[1364/1762] D loss: 0.1482, G loss: 2.4456\n",
      "[1444/1762] D loss: 0.6325, G loss: 2.1963\n",
      "[1524/1762] D loss: 1.3369, G loss: 0.7999\n",
      "[1604/1762] D loss: 1.4811, G loss: 0.7849\n",
      "[1684/1762] D loss: 1.3981, G loss: 0.6606\n",
      "[1762/1762] D loss: 1.4496, G loss: 0.5752\n",
      "train error: \n",
      " D loss: 1.333249, G loss: 0.740698, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308550, G loss: 0.752066, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3630, G loss: 0.6591\n",
      "[84/1762] D loss: 0.3168, G loss: 2.2553\n",
      "[164/1762] D loss: 0.7411, G loss: 2.0961\n",
      "[244/1762] D loss: 1.3932, G loss: 0.7569\n",
      "[324/1762] D loss: 0.3484, G loss: 2.0026\n",
      "[404/1762] D loss: 1.4141, G loss: 0.7286\n",
      "[484/1762] D loss: 0.1722, G loss: 2.6543\n",
      "[564/1762] D loss: 1.4071, G loss: 0.8851\n",
      "[644/1762] D loss: 1.3399, G loss: 0.7397\n",
      "[724/1762] D loss: 1.4065, G loss: 0.6643\n",
      "[804/1762] D loss: 0.1023, G loss: 2.8962\n",
      "[884/1762] D loss: 1.4223, G loss: 0.7153\n",
      "[964/1762] D loss: 0.2406, G loss: 2.2339\n",
      "[1044/1762] D loss: 0.1930, G loss: 2.2892\n",
      "[1124/1762] D loss: 1.3589, G loss: 0.7764\n",
      "[1204/1762] D loss: 0.2701, G loss: 2.2312\n",
      "[1284/1762] D loss: 1.4216, G loss: 0.6962\n",
      "[1364/1762] D loss: 1.4034, G loss: 0.6471\n",
      "[1444/1762] D loss: 1.3991, G loss: 1.4511\n",
      "[1524/1762] D loss: 0.2188, G loss: 2.4336\n",
      "[1604/1762] D loss: 1.4165, G loss: 0.6250\n",
      "[1684/1762] D loss: 1.4441, G loss: 0.7721\n",
      "[1762/1762] D loss: 0.1152, G loss: 2.8593\n",
      "train error: \n",
      " D loss: 1.340799, G loss: 0.648053, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330065, G loss: 0.645094, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3826, G loss: 0.7116\n",
      "[84/1762] D loss: 1.4267, G loss: 0.6402\n",
      "[164/1762] D loss: 0.6926, G loss: 1.8178\n",
      "[244/1762] D loss: 1.2061, G loss: 1.2037\n",
      "[324/1762] D loss: 1.5507, G loss: 0.4181\n",
      "[404/1762] D loss: 1.7887, G loss: 0.5911\n",
      "[484/1762] D loss: 1.5307, G loss: 0.8758\n",
      "[564/1762] D loss: 0.1650, G loss: 2.6200\n",
      "[644/1762] D loss: 1.4208, G loss: 0.5790\n",
      "[724/1762] D loss: 1.4177, G loss: 0.7111\n",
      "[804/1762] D loss: 0.1035, G loss: 3.1634\n",
      "[884/1762] D loss: 1.5984, G loss: 0.4214\n",
      "[964/1762] D loss: 1.3900, G loss: 0.6969\n",
      "[1044/1762] D loss: 1.4094, G loss: 0.5861\n",
      "[1124/1762] D loss: 1.3915, G loss: 0.7975\n",
      "[1204/1762] D loss: 1.4123, G loss: 0.7204\n",
      "[1284/1762] D loss: 1.4040, G loss: 0.7212\n",
      "[1364/1762] D loss: 0.0250, G loss: 4.0221\n",
      "[1444/1762] D loss: 0.2577, G loss: 2.1011\n",
      "[1524/1762] D loss: 1.4006, G loss: 0.7807\n",
      "[1604/1762] D loss: 1.4915, G loss: 0.7646\n",
      "[1684/1762] D loss: 1.3717, G loss: 0.6534\n",
      "[1762/1762] D loss: 1.4542, G loss: 0.1632\n",
      "train error: \n",
      " D loss: 1.458720, G loss: 0.917136, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.435356, G loss: 0.904450, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2702, G loss: 0.8284\n",
      "[84/1762] D loss: 0.0518, G loss: 3.4662\n",
      "[164/1762] D loss: 0.2017, G loss: 2.4969\n",
      "[244/1762] D loss: 1.4064, G loss: 0.6271\n",
      "[324/1762] D loss: 1.4640, G loss: 0.5496\n",
      "[404/1762] D loss: 1.5134, G loss: 0.6618\n",
      "[484/1762] D loss: 1.3975, G loss: 0.7320\n",
      "[564/1762] D loss: 0.2656, G loss: 2.0331\n",
      "[644/1762] D loss: 1.3910, G loss: 0.6755\n",
      "[724/1762] D loss: 0.3285, G loss: 2.2081\n",
      "[804/1762] D loss: 1.4160, G loss: 0.6631\n",
      "[884/1762] D loss: 1.5547, G loss: 0.5171\n",
      "[964/1762] D loss: 1.4772, G loss: 0.9098\n",
      "[1044/1762] D loss: 0.6368, G loss: 1.5780\n",
      "[1124/1762] D loss: 1.4450, G loss: 0.6467\n",
      "[1204/1762] D loss: 1.3941, G loss: 0.7053\n",
      "[1284/1762] D loss: 1.4265, G loss: 0.4809\n",
      "[1364/1762] D loss: 1.3896, G loss: 0.6857\n",
      "[1444/1762] D loss: 1.4318, G loss: 0.7180\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6887\n",
      "[1604/1762] D loss: 1.4154, G loss: 0.6830\n",
      "[1684/1762] D loss: 1.3990, G loss: 0.7013\n",
      "[1762/1762] D loss: 0.8403, G loss: 1.4682\n",
      "train error: \n",
      " D loss: 1.569590, G loss: 1.206670, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.530074, G loss: 1.205075, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4416, G loss: 0.6306\n",
      "[84/1762] D loss: 1.4087, G loss: 0.6881\n",
      "[164/1762] D loss: 1.4208, G loss: 0.6910\n",
      "[244/1762] D loss: 1.3995, G loss: 0.7096\n",
      "[324/1762] D loss: 1.3770, G loss: 1.0304\n",
      "[404/1762] D loss: 1.4478, G loss: 0.6976\n",
      "[484/1762] D loss: 1.4340, G loss: 0.6851\n",
      "[564/1762] D loss: 1.3555, G loss: 0.7277\n",
      "[644/1762] D loss: 1.2734, G loss: 1.0681\n",
      "[724/1762] D loss: 1.4004, G loss: 0.6640\n",
      "[804/1762] D loss: 1.4320, G loss: 0.7227\n",
      "[884/1762] D loss: 0.1630, G loss: 2.7421\n",
      "[964/1762] D loss: 1.4581, G loss: 0.7861\n",
      "[1044/1762] D loss: 0.0560, G loss: 3.6529\n",
      "[1124/1762] D loss: 1.7269, G loss: 1.0188\n",
      "[1204/1762] D loss: 1.4043, G loss: 0.7124\n",
      "[1284/1762] D loss: 1.3831, G loss: 0.7007\n",
      "[1364/1762] D loss: 0.2714, G loss: 2.0067\n",
      "[1444/1762] D loss: 1.3323, G loss: 0.9019\n",
      "[1524/1762] D loss: 1.4133, G loss: 0.7324\n",
      "[1604/1762] D loss: 1.2852, G loss: 1.1313\n",
      "[1684/1762] D loss: 1.5561, G loss: 0.8298\n",
      "[1762/1762] D loss: 1.3853, G loss: 0.7228\n",
      "train error: \n",
      " D loss: 1.347931, G loss: 0.690768, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338062, G loss: 0.693363, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4471, G loss: 0.7151\n",
      "[84/1762] D loss: 1.4069, G loss: 0.7013\n",
      "[164/1762] D loss: 0.4214, G loss: 1.9885\n",
      "[244/1762] D loss: 1.0363, G loss: 2.3713\n",
      "[324/1762] D loss: 1.4014, G loss: 1.1310\n",
      "[404/1762] D loss: 2.0276, G loss: 2.9439\n",
      "[484/1762] D loss: 1.3977, G loss: 0.6738\n",
      "[564/1762] D loss: 1.4278, G loss: 0.6868\n",
      "[644/1762] D loss: 1.2388, G loss: 0.8980\n",
      "[724/1762] D loss: 1.6876, G loss: 0.9384\n",
      "[804/1762] D loss: 1.4215, G loss: 0.6648\n",
      "[884/1762] D loss: 1.4959, G loss: 0.6543\n",
      "[964/1762] D loss: 1.2999, G loss: 1.4415\n",
      "[1044/1762] D loss: 1.4882, G loss: 0.6793\n",
      "[1124/1762] D loss: 1.4924, G loss: 0.6487\n",
      "[1204/1762] D loss: 1.1253, G loss: 1.0719\n",
      "[1284/1762] D loss: 0.1580, G loss: 2.6577\n",
      "[1364/1762] D loss: 1.4062, G loss: 0.6934\n",
      "[1444/1762] D loss: 1.4297, G loss: 0.7159\n",
      "[1524/1762] D loss: 1.3902, G loss: 0.7161\n",
      "[1604/1762] D loss: 0.2466, G loss: 2.1294\n",
      "[1684/1762] D loss: 1.3926, G loss: 0.6598\n",
      "[1762/1762] D loss: 1.4296, G loss: 0.9509\n",
      "train error: \n",
      " D loss: 1.332626, G loss: 0.725061, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314775, G loss: 0.728340, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4152, G loss: 0.6752\n",
      "[84/1762] D loss: 1.3920, G loss: 0.7098\n",
      "[164/1762] D loss: 1.4080, G loss: 0.6739\n",
      "[244/1762] D loss: 1.4684, G loss: 0.6842\n",
      "[324/1762] D loss: 1.4074, G loss: 0.5665\n",
      "[404/1762] D loss: 1.8803, G loss: 0.9782\n",
      "[484/1762] D loss: 1.2129, G loss: 0.9104\n",
      "[564/1762] D loss: 1.4054, G loss: 0.7016\n",
      "[644/1762] D loss: 1.4078, G loss: 0.5450\n",
      "[724/1762] D loss: 1.6777, G loss: 0.8714\n",
      "[804/1762] D loss: 1.4150, G loss: 0.7681\n",
      "[884/1762] D loss: 0.7442, G loss: 1.6497\n",
      "[964/1762] D loss: 1.2803, G loss: 0.7802\n",
      "[1044/1762] D loss: 0.8998, G loss: 1.6754\n",
      "[1124/1762] D loss: 1.3644, G loss: 0.7958\n",
      "[1204/1762] D loss: 0.6740, G loss: 1.3582\n",
      "[1284/1762] D loss: 1.4632, G loss: 0.6178\n",
      "[1364/1762] D loss: 1.4093, G loss: 0.6763\n",
      "[1444/1762] D loss: 1.4156, G loss: 0.6602\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.6904\n",
      "[1604/1762] D loss: 1.4107, G loss: 0.7446\n",
      "[1684/1762] D loss: 1.4111, G loss: 0.6222\n",
      "[1762/1762] D loss: 1.8011, G loss: 2.6436\n",
      "train error: \n",
      " D loss: 1.494738, G loss: 1.804454, D accuracy: 50.1%, cell accuracy: 99.2%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.533086, G loss: 1.811990, D accuracy: 50.3%, cell accuracy: 99.2%, board accuracy: 61.4% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7946, G loss: 2.3536\n",
      "[84/1762] D loss: 1.8499, G loss: 0.6907\n",
      "[164/1762] D loss: 1.4116, G loss: 0.7182\n",
      "[244/1762] D loss: 1.3419, G loss: 0.7618\n",
      "[324/1762] D loss: 1.4098, G loss: 0.6966\n",
      "[404/1762] D loss: 1.3874, G loss: 0.7248\n",
      "[484/1762] D loss: 1.3908, G loss: 0.7003\n",
      "[564/1762] D loss: 1.3859, G loss: 0.7098\n",
      "[644/1762] D loss: 1.1200, G loss: 1.3052\n",
      "[724/1762] D loss: 1.3885, G loss: 0.5622\n",
      "[804/1762] D loss: 1.3967, G loss: 0.6869\n",
      "[884/1762] D loss: 0.9974, G loss: 1.1402\n",
      "[964/1762] D loss: 1.4097, G loss: 0.6979\n",
      "[1044/1762] D loss: 1.2520, G loss: 1.3989\n",
      "[1124/1762] D loss: 1.4471, G loss: 0.6726\n",
      "[1204/1762] D loss: 1.0916, G loss: 1.3011\n",
      "[1284/1762] D loss: 0.8696, G loss: 1.3348\n",
      "[1364/1762] D loss: 1.3935, G loss: 0.6876\n",
      "[1444/1762] D loss: 1.4056, G loss: 0.7009\n",
      "[1524/1762] D loss: 0.9113, G loss: 1.5377\n",
      "[1604/1762] D loss: 1.4110, G loss: 0.6873\n",
      "[1684/1762] D loss: 1.1184, G loss: 1.5003\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6731\n",
      "train error: \n",
      " D loss: 1.369725, G loss: 0.771995, D accuracy: 51.4%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362811, G loss: 0.776038, D accuracy: 51.8%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4248, G loss: 0.6872\n",
      "[84/1762] D loss: 1.3980, G loss: 0.6917\n",
      "[164/1762] D loss: 1.4313, G loss: 0.6955\n",
      "[244/1762] D loss: 1.3908, G loss: 0.7137\n",
      "[324/1762] D loss: 1.3997, G loss: 0.6712\n",
      "[404/1762] D loss: 1.3832, G loss: 0.6865\n",
      "[484/1762] D loss: 1.3837, G loss: 0.7131\n",
      "[564/1762] D loss: 1.3920, G loss: 0.6969\n",
      "[644/1762] D loss: 1.3992, G loss: 0.6163\n",
      "[724/1762] D loss: 1.4430, G loss: 0.6173\n",
      "[804/1762] D loss: 1.0840, G loss: 3.2656\n",
      "[884/1762] D loss: 1.3991, G loss: 0.7414\n",
      "[964/1762] D loss: 1.4102, G loss: 0.6979\n",
      "[1044/1762] D loss: 1.5719, G loss: 0.7511\n",
      "[1124/1762] D loss: 1.4018, G loss: 0.6510\n",
      "[1204/1762] D loss: 1.1882, G loss: 0.9267\n",
      "[1284/1762] D loss: 1.3976, G loss: 0.7150\n",
      "[1364/1762] D loss: 1.4345, G loss: 0.6416\n",
      "[1444/1762] D loss: 1.4268, G loss: 0.6906\n",
      "[1524/1762] D loss: 0.9552, G loss: 2.1337\n",
      "[1604/1762] D loss: 1.3590, G loss: 0.7115\n",
      "[1684/1762] D loss: 1.3984, G loss: 0.7011\n",
      "[1762/1762] D loss: 0.0849, G loss: 2.7976\n",
      "train error: \n",
      " D loss: 1.336306, G loss: 0.772075, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316571, G loss: 0.794915, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2565, G loss: 2.0828\n",
      "[84/1762] D loss: 1.3883, G loss: 0.7011\n",
      "[164/1762] D loss: 1.3200, G loss: 1.1959\n",
      "[244/1762] D loss: 1.3962, G loss: 0.7093\n",
      "[324/1762] D loss: 1.3916, G loss: 0.6672\n",
      "[404/1762] D loss: 0.7376, G loss: 1.2185\n",
      "[484/1762] D loss: 1.3936, G loss: 0.6249\n",
      "[564/1762] D loss: 0.4916, G loss: 1.6015\n",
      "[644/1762] D loss: 1.4062, G loss: 0.6897\n",
      "[724/1762] D loss: 1.3930, G loss: 0.6809\n",
      "[804/1762] D loss: 1.4040, G loss: 0.6764\n",
      "[884/1762] D loss: 0.5159, G loss: 1.8873\n",
      "[964/1762] D loss: 1.4091, G loss: 0.6665\n",
      "[1044/1762] D loss: 1.3660, G loss: 0.7297\n",
      "[1124/1762] D loss: 1.4012, G loss: 0.6922\n",
      "[1204/1762] D loss: 1.2330, G loss: 1.0618\n",
      "[1284/1762] D loss: 1.0282, G loss: 1.0754\n",
      "[1364/1762] D loss: 1.3836, G loss: 0.7246\n",
      "[1444/1762] D loss: 1.2430, G loss: 1.1804\n",
      "[1524/1762] D loss: 1.4439, G loss: 0.7428\n",
      "[1604/1762] D loss: 1.4060, G loss: 0.6964\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.6953\n",
      "[1762/1762] D loss: 0.3309, G loss: 2.2006\n",
      "train error: \n",
      " D loss: 1.434357, G loss: 1.099332, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 78.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.430669, G loss: 1.111521, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0371, G loss: 1.0325\n",
      "[84/1762] D loss: 1.3967, G loss: 0.7004\n",
      "[164/1762] D loss: 1.0148, G loss: 1.5374\n",
      "[244/1762] D loss: 1.5347, G loss: 0.7205\n",
      "[324/1762] D loss: 0.4900, G loss: 1.4887\n",
      "[404/1762] D loss: 1.4008, G loss: 0.6554\n",
      "[484/1762] D loss: 1.4569, G loss: 0.6902\n",
      "[564/1762] D loss: 1.3953, G loss: 0.7077\n",
      "[644/1762] D loss: 1.9229, G loss: 0.4721\n",
      "[724/1762] D loss: 1.4567, G loss: 0.6504\n",
      "[804/1762] D loss: 1.4154, G loss: 0.6742\n",
      "[884/1762] D loss: 0.3953, G loss: 1.6291\n",
      "[964/1762] D loss: 1.8465, G loss: 0.9151\n",
      "[1044/1762] D loss: 0.3031, G loss: 1.8587\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.7026\n",
      "[1204/1762] D loss: 1.4662, G loss: 0.7180\n",
      "[1284/1762] D loss: 1.4009, G loss: 0.7010\n",
      "[1364/1762] D loss: 1.6937, G loss: 2.5617\n",
      "[1444/1762] D loss: 0.8230, G loss: 1.2027\n",
      "[1524/1762] D loss: 1.9217, G loss: 0.7724\n",
      "[1604/1762] D loss: 1.7913, G loss: 0.7193\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6842\n",
      "[1762/1762] D loss: 1.4322, G loss: 0.5984\n",
      "train error: \n",
      " D loss: 1.386749, G loss: 0.702372, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390831, G loss: 0.700306, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1982, G loss: 0.7740\n",
      "[84/1762] D loss: 1.4084, G loss: 0.6611\n",
      "[164/1762] D loss: 1.4063, G loss: 0.7265\n",
      "[244/1762] D loss: 1.3953, G loss: 0.6581\n",
      "[324/1762] D loss: 1.4156, G loss: 0.7294\n",
      "[404/1762] D loss: 1.4035, G loss: 0.6899\n",
      "[484/1762] D loss: 0.8017, G loss: 1.4918\n",
      "[564/1762] D loss: 1.3957, G loss: 0.7144\n",
      "[644/1762] D loss: 0.6750, G loss: 1.3308\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6949\n",
      "[804/1762] D loss: 1.3859, G loss: 0.6687\n",
      "[884/1762] D loss: 1.4132, G loss: 0.9405\n",
      "[964/1762] D loss: 1.4117, G loss: 0.8206\n",
      "[1044/1762] D loss: 1.3512, G loss: 0.7448\n",
      "[1124/1762] D loss: 0.8994, G loss: 1.0955\n",
      "[1204/1762] D loss: 0.4844, G loss: 1.6390\n",
      "[1284/1762] D loss: 0.4587, G loss: 1.5382\n",
      "[1364/1762] D loss: 1.4002, G loss: 0.6758\n",
      "[1444/1762] D loss: 0.6269, G loss: 1.1442\n",
      "[1524/1762] D loss: 1.4004, G loss: 0.6943\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.6976\n",
      "[1684/1762] D loss: 1.4094, G loss: 0.7225\n",
      "[1762/1762] D loss: 1.3942, G loss: 0.7056\n",
      "train error: \n",
      " D loss: 1.352740, G loss: 0.817891, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337634, G loss: 0.821671, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4035, G loss: 0.7113\n",
      "[84/1762] D loss: 0.3164, G loss: 1.8547\n",
      "[164/1762] D loss: 1.5110, G loss: 0.6984\n",
      "[244/1762] D loss: 1.3855, G loss: 0.6922\n",
      "[324/1762] D loss: 1.3978, G loss: 0.7061\n",
      "[404/1762] D loss: 0.7447, G loss: 1.3104\n",
      "[484/1762] D loss: 1.4007, G loss: 0.7304\n",
      "[564/1762] D loss: 1.3801, G loss: 0.7104\n",
      "[644/1762] D loss: 1.4358, G loss: 0.7582\n",
      "[724/1762] D loss: 1.3985, G loss: 0.6571\n",
      "[804/1762] D loss: 1.4089, G loss: 0.6464\n",
      "[884/1762] D loss: 1.2035, G loss: 1.0244\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7061\n",
      "[1044/1762] D loss: 1.4270, G loss: 0.7007\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.6864\n",
      "[1204/1762] D loss: 1.4597, G loss: 0.7746\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.7052\n",
      "[1364/1762] D loss: 0.7171, G loss: 1.5527\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.7082\n",
      "[1524/1762] D loss: 1.3967, G loss: 0.6795\n",
      "[1604/1762] D loss: 0.2336, G loss: 2.0497\n",
      "[1684/1762] D loss: 0.6121, G loss: 1.4551\n",
      "[1762/1762] D loss: 0.5252, G loss: 1.2735\n",
      "train error: \n",
      " D loss: 1.407266, G loss: 0.755246, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.415644, G loss: 0.748638, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4025, G loss: 0.6519\n",
      "[84/1762] D loss: 1.3832, G loss: 0.7035\n",
      "[164/1762] D loss: 1.4097, G loss: 0.7438\n",
      "[244/1762] D loss: 1.3883, G loss: 0.6833\n",
      "[324/1762] D loss: 1.3909, G loss: 0.6929\n",
      "[404/1762] D loss: 1.3898, G loss: 0.7047\n",
      "[484/1762] D loss: 0.4506, G loss: 1.6961\n",
      "[564/1762] D loss: 1.3984, G loss: 0.7365\n",
      "[644/1762] D loss: 1.4092, G loss: 0.7419\n",
      "[724/1762] D loss: 1.3767, G loss: 0.7003\n",
      "[804/1762] D loss: 1.4162, G loss: 0.6824\n",
      "[884/1762] D loss: 0.7421, G loss: 1.6905\n",
      "[964/1762] D loss: 0.8257, G loss: 1.8858\n",
      "[1044/1762] D loss: 1.3950, G loss: 0.6705\n",
      "[1124/1762] D loss: 0.4343, G loss: 1.6477\n",
      "[1204/1762] D loss: 0.3703, G loss: 1.8202\n",
      "[1284/1762] D loss: 1.3957, G loss: 0.6813\n",
      "[1364/1762] D loss: 1.3929, G loss: 0.7176\n",
      "[1444/1762] D loss: 1.4228, G loss: 0.7368\n",
      "[1524/1762] D loss: 0.6727, G loss: 1.1973\n",
      "[1604/1762] D loss: 1.4003, G loss: 0.6885\n",
      "[1684/1762] D loss: 1.4327, G loss: 0.6996\n",
      "[1762/1762] D loss: 1.4145, G loss: 0.7095\n",
      "train error: \n",
      " D loss: 1.353082, G loss: 0.747322, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342498, G loss: 0.756558, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3948, G loss: 0.6771\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6967\n",
      "[164/1762] D loss: 1.4004, G loss: 0.6534\n",
      "[244/1762] D loss: 1.4313, G loss: 0.6347\n",
      "[324/1762] D loss: 1.4010, G loss: 0.6429\n",
      "[404/1762] D loss: 1.4163, G loss: 0.6476\n",
      "[484/1762] D loss: 1.3954, G loss: 0.7121\n",
      "[564/1762] D loss: 0.2669, G loss: 1.8017\n",
      "[644/1762] D loss: 1.4187, G loss: 0.6262\n",
      "[724/1762] D loss: 1.3911, G loss: 0.6639\n",
      "[804/1762] D loss: 1.4006, G loss: 0.6723\n",
      "[884/1762] D loss: 1.3965, G loss: 0.7026\n",
      "[964/1762] D loss: 1.4010, G loss: 0.7164\n",
      "[1044/1762] D loss: 0.8959, G loss: 1.1342\n",
      "[1124/1762] D loss: 1.4667, G loss: 0.8219\n",
      "[1204/1762] D loss: 1.3959, G loss: 0.6670\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.6743\n",
      "[1364/1762] D loss: 1.4139, G loss: 0.6532\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.7080\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.7003\n",
      "[1604/1762] D loss: 0.4098, G loss: 1.6074\n",
      "[1684/1762] D loss: 0.3863, G loss: 1.7487\n",
      "[1762/1762] D loss: 1.5292, G loss: 0.8171\n",
      "train error: \n",
      " D loss: 1.429611, G loss: 0.533708, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.407941, G loss: 0.542496, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4237, G loss: 0.7218\n",
      "[84/1762] D loss: 1.4619, G loss: 0.7757\n",
      "[164/1762] D loss: 0.3580, G loss: 1.7868\n",
      "[244/1762] D loss: 1.4690, G loss: 0.8379\n",
      "[324/1762] D loss: 0.5140, G loss: 1.5001\n",
      "[404/1762] D loss: 1.3721, G loss: 0.7429\n",
      "[484/1762] D loss: 1.4027, G loss: 0.6498\n",
      "[564/1762] D loss: 1.3927, G loss: 0.7037\n",
      "[644/1762] D loss: 1.3924, G loss: 0.6763\n",
      "[724/1762] D loss: 1.3947, G loss: 0.7020\n",
      "[804/1762] D loss: 0.7908, G loss: 1.2441\n",
      "[884/1762] D loss: 1.1472, G loss: 1.1018\n",
      "[964/1762] D loss: 1.4278, G loss: 0.7406\n",
      "[1044/1762] D loss: 0.9054, G loss: 1.0024\n",
      "[1124/1762] D loss: 1.4015, G loss: 0.7364\n",
      "[1204/1762] D loss: 1.4088, G loss: 0.6482\n",
      "[1284/1762] D loss: 1.4697, G loss: 0.6600\n",
      "[1364/1762] D loss: 1.4476, G loss: 0.7245\n",
      "[1444/1762] D loss: 1.3934, G loss: 0.7060\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.7071\n",
      "[1604/1762] D loss: 1.3961, G loss: 0.7170\n",
      "[1684/1762] D loss: 1.4289, G loss: 0.6754\n",
      "[1762/1762] D loss: 0.1953, G loss: 2.4751\n",
      "train error: \n",
      " D loss: 1.342851, G loss: 0.811262, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323752, G loss: 0.829860, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4041, G loss: 0.7222\n",
      "[84/1762] D loss: 1.3938, G loss: 0.7049\n",
      "[164/1762] D loss: 1.4798, G loss: 0.7803\n",
      "[244/1762] D loss: 1.4015, G loss: 0.6780\n",
      "[324/1762] D loss: 1.3956, G loss: 0.6676\n",
      "[404/1762] D loss: 1.4013, G loss: 0.6824\n",
      "[484/1762] D loss: 0.6905, G loss: 1.2456\n",
      "[564/1762] D loss: 1.4648, G loss: 0.6803\n",
      "[644/1762] D loss: 0.3224, G loss: 1.8727\n",
      "[724/1762] D loss: 1.8306, G loss: 0.9963\n",
      "[804/1762] D loss: 1.8050, G loss: 0.8564\n",
      "[884/1762] D loss: 1.3910, G loss: 0.6643\n",
      "[964/1762] D loss: 1.4043, G loss: 0.6606\n",
      "[1044/1762] D loss: 0.6946, G loss: 1.2275\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7016\n",
      "[1204/1762] D loss: 1.4192, G loss: 0.7574\n",
      "[1284/1762] D loss: 1.9706, G loss: 0.8844\n",
      "[1364/1762] D loss: 0.8878, G loss: 0.9885\n",
      "[1444/1762] D loss: 1.4507, G loss: 0.6999\n",
      "[1524/1762] D loss: 1.4037, G loss: 0.7075\n",
      "[1604/1762] D loss: 1.4358, G loss: 0.7249\n",
      "[1684/1762] D loss: 1.4175, G loss: 0.6260\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6890\n",
      "train error: \n",
      " D loss: 1.374286, G loss: 0.633186, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370324, G loss: 0.634442, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4042, G loss: 0.6480\n",
      "[84/1762] D loss: 0.4546, G loss: 1.5113\n",
      "[164/1762] D loss: 1.3921, G loss: 0.6869\n",
      "[244/1762] D loss: 0.3797, G loss: 1.6240\n",
      "[324/1762] D loss: 0.6277, G loss: 2.0541\n",
      "[404/1762] D loss: 1.3957, G loss: 0.7259\n",
      "[484/1762] D loss: 0.4082, G loss: 1.5112\n",
      "[564/1762] D loss: 1.4055, G loss: 0.7267\n",
      "[644/1762] D loss: 1.3950, G loss: 0.7175\n",
      "[724/1762] D loss: 1.4043, G loss: 0.7364\n",
      "[804/1762] D loss: 1.3034, G loss: 0.7564\n",
      "[884/1762] D loss: 1.3895, G loss: 0.7194\n",
      "[964/1762] D loss: 1.3953, G loss: 0.7278\n",
      "[1044/1762] D loss: 0.3476, G loss: 1.5705\n",
      "[1124/1762] D loss: 0.2665, G loss: 1.8652\n",
      "[1204/1762] D loss: 1.3907, G loss: 0.7038\n",
      "[1284/1762] D loss: 1.4368, G loss: 0.6981\n",
      "[1364/1762] D loss: 0.2151, G loss: 1.8174\n",
      "[1444/1762] D loss: 1.4039, G loss: 0.6533\n",
      "[1524/1762] D loss: 0.3544, G loss: 1.4908\n",
      "[1604/1762] D loss: 0.5053, G loss: 1.2694\n",
      "[1684/1762] D loss: 1.4338, G loss: 0.7093\n",
      "[1762/1762] D loss: 0.4042, G loss: 1.5312\n",
      "train error: \n",
      " D loss: 1.429391, G loss: 0.479405, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412450, G loss: 0.496520, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3516, G loss: 1.6236\n",
      "[84/1762] D loss: 1.3388, G loss: 0.8144\n",
      "[164/1762] D loss: 1.4093, G loss: 0.7385\n",
      "[244/1762] D loss: 1.4211, G loss: 0.7866\n",
      "[324/1762] D loss: 0.6914, G loss: 1.0979\n",
      "[404/1762] D loss: 1.4228, G loss: 0.7572\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6784\n",
      "[564/1762] D loss: 1.3856, G loss: 0.7102\n",
      "[644/1762] D loss: 1.3916, G loss: 0.7251\n",
      "[724/1762] D loss: 1.5138, G loss: 0.9524\n",
      "[804/1762] D loss: 1.3963, G loss: 0.7446\n",
      "[884/1762] D loss: 0.8128, G loss: 1.0987\n",
      "[964/1762] D loss: 1.3907, G loss: 0.7185\n",
      "[1044/1762] D loss: 1.4246, G loss: 0.6966\n",
      "[1124/1762] D loss: 1.1515, G loss: 0.9029\n",
      "[1204/1762] D loss: 0.9539, G loss: 0.8719\n",
      "[1284/1762] D loss: 0.5728, G loss: 1.2197\n",
      "[1364/1762] D loss: 1.4004, G loss: 0.6649\n",
      "[1444/1762] D loss: 0.4873, G loss: 1.2673\n",
      "[1524/1762] D loss: 1.3954, G loss: 0.6938\n",
      "[1604/1762] D loss: 1.3987, G loss: 0.7328\n",
      "[1684/1762] D loss: 1.3996, G loss: 0.6914\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.7060\n",
      "train error: \n",
      " D loss: 1.334722, G loss: 0.778026, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318537, G loss: 0.790500, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4053, G loss: 0.7249\n",
      "[84/1762] D loss: 1.4344, G loss: 0.7644\n",
      "[164/1762] D loss: 1.3913, G loss: 0.6650\n",
      "[244/1762] D loss: 1.5784, G loss: 0.9457\n",
      "[324/1762] D loss: 1.4011, G loss: 0.7317\n",
      "[404/1762] D loss: 1.4107, G loss: 0.6324\n",
      "[484/1762] D loss: 1.4051, G loss: 0.6464\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6918\n",
      "[644/1762] D loss: 1.4204, G loss: 0.7043\n",
      "[724/1762] D loss: 1.5154, G loss: 0.8658\n",
      "[804/1762] D loss: 1.5680, G loss: 1.0285\n",
      "[884/1762] D loss: 1.3974, G loss: 0.6437\n",
      "[964/1762] D loss: 1.3893, G loss: 0.7181\n",
      "[1044/1762] D loss: 0.3081, G loss: 1.5258\n",
      "[1124/1762] D loss: 2.1252, G loss: 1.4958\n",
      "[1204/1762] D loss: 1.3946, G loss: 0.7121\n",
      "[1284/1762] D loss: 1.4074, G loss: 0.7451\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6909\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6792\n",
      "[1524/1762] D loss: 1.4314, G loss: 0.6721\n",
      "[1604/1762] D loss: 1.3948, G loss: 0.6775\n",
      "[1684/1762] D loss: 1.4101, G loss: 0.7610\n",
      "[1762/1762] D loss: 1.4226, G loss: 0.7688\n",
      "train error: \n",
      " D loss: 1.344156, G loss: 0.701646, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328390, G loss: 0.713226, D accuracy: 54.7%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3543, G loss: 0.7623\n",
      "[84/1762] D loss: 1.4271, G loss: 0.7376\n",
      "[164/1762] D loss: 1.3925, G loss: 0.7211\n",
      "[244/1762] D loss: 1.3927, G loss: 0.7206\n",
      "[324/1762] D loss: 1.3910, G loss: 0.6845\n",
      "[404/1762] D loss: 0.3870, G loss: 1.5056\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6899\n",
      "[564/1762] D loss: 0.3986, G loss: 1.5355\n",
      "[644/1762] D loss: 1.4784, G loss: 0.7706\n",
      "[724/1762] D loss: 1.3950, G loss: 0.7001\n",
      "[804/1762] D loss: 1.4098, G loss: 0.6728\n",
      "[884/1762] D loss: 1.4822, G loss: 0.7814\n",
      "[964/1762] D loss: 1.4002, G loss: 0.6709\n",
      "[1044/1762] D loss: 0.4778, G loss: 1.4578\n",
      "[1124/1762] D loss: 1.4925, G loss: 0.7711\n",
      "[1204/1762] D loss: 0.3855, G loss: 1.5906\n",
      "[1284/1762] D loss: 1.4277, G loss: 0.7225\n",
      "[1364/1762] D loss: 1.3919, G loss: 0.6769\n",
      "[1444/1762] D loss: 0.4128, G loss: 1.6322\n",
      "[1524/1762] D loss: 1.3817, G loss: 0.6976\n",
      "[1604/1762] D loss: 1.4055, G loss: 0.7154\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6747\n",
      "[1762/1762] D loss: 1.4101, G loss: 0.6894\n",
      "train error: \n",
      " D loss: 1.337371, G loss: 0.643702, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317960, G loss: 0.645136, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4103, G loss: 0.6704\n",
      "[84/1762] D loss: 1.4040, G loss: 0.6604\n",
      "[164/1762] D loss: 1.4231, G loss: 0.7218\n",
      "[244/1762] D loss: 1.4446, G loss: 0.8815\n",
      "[324/1762] D loss: 1.3923, G loss: 0.6969\n",
      "[404/1762] D loss: 1.5604, G loss: 0.6830\n",
      "[484/1762] D loss: 0.3205, G loss: 1.9531\n",
      "[564/1762] D loss: 0.3122, G loss: 1.9389\n",
      "[644/1762] D loss: 1.5305, G loss: 0.7008\n",
      "[724/1762] D loss: 1.4527, G loss: 1.0538\n",
      "[804/1762] D loss: 0.3922, G loss: 1.7390\n",
      "[884/1762] D loss: 1.4481, G loss: 0.6514\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6869\n",
      "[1044/1762] D loss: 1.4033, G loss: 0.6637\n",
      "[1124/1762] D loss: 1.4630, G loss: 0.7832\n",
      "[1204/1762] D loss: 1.4105, G loss: 0.7058\n",
      "[1284/1762] D loss: 1.4003, G loss: 0.6735\n",
      "[1364/1762] D loss: 1.3988, G loss: 0.6972\n",
      "[1444/1762] D loss: 1.3989, G loss: 0.6707\n",
      "[1524/1762] D loss: 3.5446, G loss: 2.5085\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.7162\n",
      "[1684/1762] D loss: 1.3676, G loss: 0.7746\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6818\n",
      "train error: \n",
      " D loss: 1.346687, G loss: 0.889420, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333401, G loss: 0.898792, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3834, G loss: 0.7172\n",
      "[84/1762] D loss: 0.3902, G loss: 1.6251\n",
      "[164/1762] D loss: 1.3920, G loss: 0.6901\n",
      "[244/1762] D loss: 1.3963, G loss: 0.6984\n",
      "[324/1762] D loss: 1.4772, G loss: 0.6203\n",
      "[404/1762] D loss: 1.4299, G loss: 0.6464\n",
      "[484/1762] D loss: 1.3969, G loss: 0.6924\n",
      "[564/1762] D loss: 1.3949, G loss: 0.6955\n",
      "[644/1762] D loss: 1.6763, G loss: 2.4873\n",
      "[724/1762] D loss: 1.4075, G loss: 0.6854\n",
      "[804/1762] D loss: 1.3933, G loss: 0.6619\n",
      "[884/1762] D loss: 1.7611, G loss: 1.1383\n",
      "[964/1762] D loss: 0.4678, G loss: 1.4375\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.7260\n",
      "[1124/1762] D loss: 1.3994, G loss: 0.6700\n",
      "[1204/1762] D loss: 1.3939, G loss: 0.6990\n",
      "[1284/1762] D loss: 0.3471, G loss: 1.5209\n",
      "[1364/1762] D loss: 1.3994, G loss: 0.6798\n",
      "[1444/1762] D loss: 1.4407, G loss: 0.5920\n",
      "[1524/1762] D loss: 1.4301, G loss: 0.7321\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.6927\n",
      "[1684/1762] D loss: 1.3943, G loss: 0.6783\n",
      "[1762/1762] D loss: 1.3960, G loss: 0.7079\n",
      "train error: \n",
      " D loss: 1.363034, G loss: 0.745096, D accuracy: 52.3%, cell accuracy: 99.9%, board accuracy: 93.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355907, G loss: 0.754320, D accuracy: 52.4%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3963, G loss: 0.7032\n",
      "[84/1762] D loss: 1.4056, G loss: 0.7145\n",
      "[164/1762] D loss: 1.4331, G loss: 0.6638\n",
      "[244/1762] D loss: 1.3969, G loss: 0.6886\n",
      "[324/1762] D loss: 1.5262, G loss: 0.6752\n",
      "[404/1762] D loss: 1.7354, G loss: 0.3877\n",
      "[484/1762] D loss: 1.3980, G loss: 0.6623\n",
      "[564/1762] D loss: 1.4105, G loss: 0.7062\n",
      "[644/1762] D loss: 1.3957, G loss: 0.6627\n",
      "[724/1762] D loss: 0.9207, G loss: 1.2694\n",
      "[804/1762] D loss: 1.3974, G loss: 0.7216\n",
      "[884/1762] D loss: 1.4203, G loss: 0.7550\n",
      "[964/1762] D loss: 0.4251, G loss: 1.4194\n",
      "[1044/1762] D loss: 1.4181, G loss: 0.7218\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.6898\n",
      "[1204/1762] D loss: 1.0561, G loss: 1.6935\n",
      "[1284/1762] D loss: 1.4551, G loss: 0.7691\n",
      "[1364/1762] D loss: 1.4531, G loss: 0.6518\n",
      "[1444/1762] D loss: 1.3908, G loss: 0.6839\n",
      "[1524/1762] D loss: 1.3923, G loss: 0.6810\n",
      "[1604/1762] D loss: 1.4003, G loss: 0.7122\n",
      "[1684/1762] D loss: 1.3952, G loss: 0.6914\n",
      "[1762/1762] D loss: 0.6848, G loss: 0.4340\n",
      "train error: \n",
      " D loss: 1.432705, G loss: 0.878056, D accuracy: 47.7%, cell accuracy: 98.7%, board accuracy: 32.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.419971, G loss: 0.882481, D accuracy: 49.7%, cell accuracy: 98.6%, board accuracy: 32.7% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2219, G loss: 1.1845\n",
      "[84/1762] D loss: 1.4139, G loss: 0.7123\n",
      "[164/1762] D loss: 1.4133, G loss: 0.6423\n",
      "[244/1762] D loss: 1.3904, G loss: 0.6935\n",
      "[324/1762] D loss: 0.4359, G loss: 1.5057\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6933\n",
      "[484/1762] D loss: 1.4308, G loss: 0.7040\n",
      "[564/1762] D loss: 1.4110, G loss: 0.9334\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6767\n",
      "[724/1762] D loss: 1.4131, G loss: 0.6673\n",
      "[804/1762] D loss: 1.3988, G loss: 0.6748\n",
      "[884/1762] D loss: 0.5188, G loss: 1.6217\n",
      "[964/1762] D loss: 1.3862, G loss: 0.7100\n",
      "[1044/1762] D loss: 0.4920, G loss: 1.3938\n",
      "[1124/1762] D loss: 1.4159, G loss: 0.6814\n",
      "[1204/1762] D loss: 1.3923, G loss: 0.6883\n",
      "[1284/1762] D loss: 1.4038, G loss: 0.6945\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.7080\n",
      "[1444/1762] D loss: 1.3951, G loss: 0.7040\n",
      "[1524/1762] D loss: 1.1181, G loss: 0.9034\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6876\n",
      "[1684/1762] D loss: 1.4150, G loss: 0.7414\n",
      "[1762/1762] D loss: 1.4018, G loss: 0.6328\n",
      "train error: \n",
      " D loss: 1.366896, G loss: 0.725770, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361823, G loss: 0.734789, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3999, G loss: 0.6894\n",
      "[84/1762] D loss: 1.3881, G loss: 0.7379\n",
      "[164/1762] D loss: 0.4777, G loss: 1.3280\n",
      "[244/1762] D loss: 1.3917, G loss: 0.6899\n",
      "[324/1762] D loss: 1.3997, G loss: 0.7484\n",
      "[404/1762] D loss: 0.2552, G loss: 1.9049\n",
      "[484/1762] D loss: 1.3999, G loss: 0.6697\n",
      "[564/1762] D loss: 1.4078, G loss: 0.7299\n",
      "[644/1762] D loss: 1.4177, G loss: 0.7382\n",
      "[724/1762] D loss: 1.3930, G loss: 0.6587\n",
      "[804/1762] D loss: 1.3916, G loss: 0.7006\n",
      "[884/1762] D loss: 0.2183, G loss: 2.0606\n",
      "[964/1762] D loss: 1.4139, G loss: 0.7562\n",
      "[1044/1762] D loss: 1.3958, G loss: 0.7076\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.6723\n",
      "[1204/1762] D loss: 1.3701, G loss: 0.7703\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.6835\n",
      "[1364/1762] D loss: 0.1119, G loss: 2.4782\n",
      "[1444/1762] D loss: 1.3936, G loss: 0.6547\n",
      "[1524/1762] D loss: 1.4062, G loss: 1.3108\n",
      "[1604/1762] D loss: 1.4029, G loss: 0.6864\n",
      "[1684/1762] D loss: 0.1538, G loss: 2.2579\n",
      "[1762/1762] D loss: 1.4149, G loss: 0.5969\n",
      "train error: \n",
      " D loss: 1.334386, G loss: 0.774574, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309626, G loss: 0.776255, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1804, G loss: 2.2003\n",
      "[84/1762] D loss: 0.2778, G loss: 1.9657\n",
      "[164/1762] D loss: 0.2404, G loss: 2.0166\n",
      "[244/1762] D loss: 0.2159, G loss: 2.0495\n",
      "[324/1762] D loss: 1.4014, G loss: 0.6650\n",
      "[404/1762] D loss: 1.4023, G loss: 0.6737\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7118\n",
      "[564/1762] D loss: 1.4072, G loss: 0.6099\n",
      "[644/1762] D loss: 1.4039, G loss: 0.6566\n",
      "[724/1762] D loss: 1.6746, G loss: 0.6711\n",
      "[804/1762] D loss: 1.3962, G loss: 0.6856\n",
      "[884/1762] D loss: 1.4152, G loss: 0.6895\n",
      "[964/1762] D loss: 1.4022, G loss: 0.7015\n",
      "[1044/1762] D loss: 1.4085, G loss: 0.7186\n",
      "[1124/1762] D loss: 1.4120, G loss: 0.6933\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6838\n",
      "[1284/1762] D loss: 1.4223, G loss: 0.6459\n",
      "[1364/1762] D loss: 1.4078, G loss: 0.7334\n",
      "[1444/1762] D loss: 1.4016, G loss: 0.6889\n",
      "[1524/1762] D loss: 1.4143, G loss: 0.7017\n",
      "[1604/1762] D loss: 0.0825, G loss: 2.8257\n",
      "[1684/1762] D loss: 1.3982, G loss: 0.6866\n",
      "[1762/1762] D loss: 1.4038, G loss: 0.7496\n",
      "train error: \n",
      " D loss: 1.330483, G loss: 0.735992, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310197, G loss: 0.741667, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4315, G loss: 0.6021\n",
      "[84/1762] D loss: 1.2624, G loss: 0.6790\n",
      "[164/1762] D loss: 1.0019, G loss: 0.8166\n",
      "[244/1762] D loss: 0.6513, G loss: 1.1054\n",
      "[324/1762] D loss: 0.5031, G loss: 1.4060\n",
      "[404/1762] D loss: 0.6489, G loss: 1.2071\n",
      "[484/1762] D loss: 1.2070, G loss: 0.1416\n",
      "[564/1762] D loss: 1.1373, G loss: 2.1226\n",
      "[644/1762] D loss: 1.0993, G loss: 1.5944\n",
      "[724/1762] D loss: 1.2964, G loss: 0.8265\n",
      "[804/1762] D loss: 1.4950, G loss: 1.2588\n",
      "[884/1762] D loss: 1.8882, G loss: 1.7096\n",
      "[964/1762] D loss: 1.1492, G loss: 0.5279\n",
      "[1044/1762] D loss: 1.1274, G loss: 1.3193\n",
      "[1124/1762] D loss: 1.0229, G loss: 1.5906\n",
      "[1204/1762] D loss: 1.2625, G loss: 0.9168\n",
      "[1284/1762] D loss: 1.4414, G loss: 1.5740\n",
      "[1364/1762] D loss: 1.2921, G loss: 0.5545\n",
      "[1444/1762] D loss: 1.4127, G loss: 0.8776\n",
      "[1524/1762] D loss: 1.3186, G loss: 0.6626\n",
      "[1604/1762] D loss: 1.0899, G loss: 1.0637\n",
      "[1684/1762] D loss: 1.2428, G loss: 0.9792\n",
      "[1762/1762] D loss: 1.3526, G loss: 0.5661\n",
      "train error: \n",
      " D loss: 1.382917, G loss: 0.607936, D accuracy: 55.8%, cell accuracy: 99.5%, board accuracy: 62.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385067, G loss: 0.603210, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 64.8% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3126, G loss: 0.8728\n",
      "[84/1762] D loss: 1.4315, G loss: 0.4706\n",
      "[164/1762] D loss: 1.3767, G loss: 0.6957\n",
      "[244/1762] D loss: 1.3824, G loss: 0.7307\n",
      "[324/1762] D loss: 1.2353, G loss: 0.8320\n",
      "[404/1762] D loss: 1.1319, G loss: 1.3145\n",
      "[484/1762] D loss: 1.4083, G loss: 0.4912\n",
      "[564/1762] D loss: 1.3552, G loss: 0.5873\n",
      "[644/1762] D loss: 1.3728, G loss: 0.6704\n",
      "[724/1762] D loss: 1.3640, G loss: 0.6965\n",
      "[804/1762] D loss: 1.4135, G loss: 0.5477\n",
      "[884/1762] D loss: 1.3850, G loss: 0.7376\n",
      "[964/1762] D loss: 1.4277, G loss: 0.8855\n",
      "[1044/1762] D loss: 1.3650, G loss: 0.7231\n",
      "[1124/1762] D loss: 1.3681, G loss: 1.0826\n",
      "[1204/1762] D loss: 1.3685, G loss: 0.7108\n",
      "[1284/1762] D loss: 1.3856, G loss: 0.6925\n",
      "[1364/1762] D loss: 1.3824, G loss: 0.6392\n",
      "[1444/1762] D loss: 1.3719, G loss: 0.8215\n",
      "[1524/1762] D loss: 1.1166, G loss: 0.9317\n",
      "[1604/1762] D loss: 1.3688, G loss: 0.5915\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.5924\n",
      "[1762/1762] D loss: 1.6117, G loss: 0.8820\n",
      "train error: \n",
      " D loss: 1.399147, G loss: 1.112702, D accuracy: 50.1%, cell accuracy: 99.1%, board accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409203, G loss: 1.126011, D accuracy: 50.1%, cell accuracy: 99.0%, board accuracy: 54.1% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3535, G loss: 0.8159\n",
      "[84/1762] D loss: 1.2498, G loss: 0.8939\n",
      "[164/1762] D loss: 1.4001, G loss: 0.6634\n",
      "[244/1762] D loss: 1.3967, G loss: 0.6801\n",
      "[324/1762] D loss: 1.3721, G loss: 0.7050\n",
      "[404/1762] D loss: 1.3891, G loss: 0.6851\n",
      "[484/1762] D loss: 1.3886, G loss: 0.7181\n",
      "[564/1762] D loss: 1.4005, G loss: 0.7985\n",
      "[644/1762] D loss: 1.3774, G loss: 0.7373\n",
      "[724/1762] D loss: 1.4573, G loss: 0.5988\n",
      "[804/1762] D loss: 1.3649, G loss: 0.6438\n",
      "[884/1762] D loss: 1.4090, G loss: 0.5705\n",
      "[964/1762] D loss: 1.5325, G loss: 0.9180\n",
      "[1044/1762] D loss: 1.5015, G loss: 0.6902\n",
      "[1124/1762] D loss: 1.3503, G loss: 0.6875\n",
      "[1204/1762] D loss: 1.3811, G loss: 0.6211\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.6308\n",
      "[1364/1762] D loss: 1.3595, G loss: 0.7434\n",
      "[1444/1762] D loss: 1.3780, G loss: 0.7181\n",
      "[1524/1762] D loss: 1.4023, G loss: 0.7024\n",
      "[1604/1762] D loss: 1.3617, G loss: 0.7199\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.7075\n",
      "[1762/1762] D loss: 1.3769, G loss: 0.6548\n",
      "train error: \n",
      " D loss: 1.342631, G loss: 0.744626, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333143, G loss: 0.748877, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0732, G loss: 0.8984\n",
      "[84/1762] D loss: 1.4153, G loss: 0.7283\n",
      "[164/1762] D loss: 1.0944, G loss: 0.9296\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7063\n",
      "[324/1762] D loss: 1.1752, G loss: 0.9203\n",
      "[404/1762] D loss: 1.3715, G loss: 0.6901\n",
      "[484/1762] D loss: 1.4185, G loss: 0.7134\n",
      "[564/1762] D loss: 1.3730, G loss: 0.6808\n",
      "[644/1762] D loss: 1.3930, G loss: 0.7900\n",
      "[724/1762] D loss: 1.0122, G loss: 0.9550\n",
      "[804/1762] D loss: 1.4040, G loss: 0.6923\n",
      "[884/1762] D loss: 1.3957, G loss: 0.7125\n",
      "[964/1762] D loss: 1.3829, G loss: 0.6878\n",
      "[1044/1762] D loss: 1.3453, G loss: 0.7394\n",
      "[1124/1762] D loss: 1.3786, G loss: 0.6934\n",
      "[1204/1762] D loss: 1.3799, G loss: 0.7000\n",
      "[1284/1762] D loss: 1.4523, G loss: 0.7577\n",
      "[1364/1762] D loss: 1.2911, G loss: 0.9086\n",
      "[1444/1762] D loss: 1.3937, G loss: 0.6814\n",
      "[1524/1762] D loss: 0.9701, G loss: 0.9717\n",
      "[1604/1762] D loss: 0.7976, G loss: 1.2096\n",
      "[1684/1762] D loss: 0.8296, G loss: 1.1908\n",
      "[1762/1762] D loss: 1.4386, G loss: 0.6150\n",
      "train error: \n",
      " D loss: 1.366173, G loss: 0.559961, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357902, G loss: 0.566753, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3096, G loss: 0.7780\n",
      "[84/1762] D loss: 1.3627, G loss: 0.7757\n",
      "[164/1762] D loss: 1.4154, G loss: 0.6380\n",
      "[244/1762] D loss: 1.4768, G loss: 0.6871\n",
      "[324/1762] D loss: 1.4305, G loss: 0.7533\n",
      "[404/1762] D loss: 1.3882, G loss: 0.6911\n",
      "[484/1762] D loss: 1.4073, G loss: 0.7046\n",
      "[564/1762] D loss: 1.3839, G loss: 0.6791\n",
      "[644/1762] D loss: 1.4056, G loss: 0.6950\n",
      "[724/1762] D loss: 1.4306, G loss: 0.6656\n",
      "[804/1762] D loss: 1.4158, G loss: 0.6924\n",
      "[884/1762] D loss: 0.8608, G loss: 1.2348\n",
      "[964/1762] D loss: 0.8754, G loss: 1.2622\n",
      "[1044/1762] D loss: 1.5530, G loss: 0.6756\n",
      "[1124/1762] D loss: 0.8492, G loss: 1.0335\n",
      "[1204/1762] D loss: 1.3636, G loss: 0.6972\n",
      "[1284/1762] D loss: 1.4019, G loss: 0.6850\n",
      "[1364/1762] D loss: 0.7223, G loss: 1.2182\n",
      "[1444/1762] D loss: 0.6241, G loss: 1.2857\n",
      "[1524/1762] D loss: 1.0745, G loss: 1.1663\n",
      "[1604/1762] D loss: 1.4590, G loss: 0.9197\n",
      "[1684/1762] D loss: 1.4331, G loss: 0.8344\n",
      "[1762/1762] D loss: 0.7128, G loss: 1.2892\n",
      "train error: \n",
      " D loss: 1.213842, G loss: 1.095761, D accuracy: 57.3%, cell accuracy: 98.5%, board accuracy: 19.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.194075, G loss: 1.120298, D accuracy: 59.3%, cell accuracy: 98.3%, board accuracy: 18.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2998, G loss: 0.7781\n",
      "[84/1762] D loss: 1.5194, G loss: 0.7653\n",
      "[164/1762] D loss: 1.4312, G loss: 0.7515\n",
      "[244/1762] D loss: 1.3742, G loss: 0.7128\n",
      "[324/1762] D loss: 1.4480, G loss: 0.6788\n",
      "[404/1762] D loss: 0.7873, G loss: 1.0513\n",
      "[484/1762] D loss: 1.3836, G loss: 0.6975\n",
      "[564/1762] D loss: 0.6003, G loss: 1.5064\n",
      "[644/1762] D loss: 1.3462, G loss: 0.7139\n",
      "[724/1762] D loss: 0.4291, G loss: 1.5104\n",
      "[804/1762] D loss: 1.5140, G loss: 0.7383\n",
      "[884/1762] D loss: 1.3093, G loss: 0.7359\n",
      "[964/1762] D loss: 1.0518, G loss: 0.8777\n",
      "[1044/1762] D loss: 1.3837, G loss: 0.7060\n",
      "[1124/1762] D loss: 1.5039, G loss: 0.7491\n",
      "[1204/1762] D loss: 0.7041, G loss: 1.5454\n",
      "[1284/1762] D loss: 1.3924, G loss: 0.7067\n",
      "[1364/1762] D loss: 1.4104, G loss: 0.7322\n",
      "[1444/1762] D loss: 1.3607, G loss: 0.6811\n",
      "[1524/1762] D loss: 1.3938, G loss: 0.6976\n",
      "[1604/1762] D loss: 0.5937, G loss: 1.2954\n",
      "[1684/1762] D loss: 0.4517, G loss: 1.4887\n",
      "[1762/1762] D loss: 1.3422, G loss: 0.7636\n",
      "train error: \n",
      " D loss: 1.323992, G loss: 0.956510, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 64.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304164, G loss: 0.964583, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 61.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3586, G loss: 0.7082\n",
      "[84/1762] D loss: 0.7491, G loss: 1.2170\n",
      "[164/1762] D loss: 1.3809, G loss: 0.7214\n",
      "[244/1762] D loss: 1.4585, G loss: 0.7927\n",
      "[324/1762] D loss: 0.6889, G loss: 1.2797\n",
      "[404/1762] D loss: 1.4574, G loss: 0.7843\n",
      "[484/1762] D loss: 1.4656, G loss: 0.7999\n",
      "[564/1762] D loss: 1.4205, G loss: 0.7287\n",
      "[644/1762] D loss: 1.5324, G loss: 0.7465\n",
      "[724/1762] D loss: 1.3319, G loss: 0.8686\n",
      "[804/1762] D loss: 1.6067, G loss: 0.6941\n",
      "[884/1762] D loss: 1.3915, G loss: 0.7086\n",
      "[964/1762] D loss: 1.3890, G loss: 0.6995\n",
      "[1044/1762] D loss: 1.3858, G loss: 0.7062\n",
      "[1124/1762] D loss: 0.9876, G loss: 0.8319\n",
      "[1204/1762] D loss: 1.4317, G loss: 0.7311\n",
      "[1284/1762] D loss: 1.3579, G loss: 0.7440\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.7039\n",
      "[1444/1762] D loss: 1.3970, G loss: 0.7145\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.7688\n",
      "[1604/1762] D loss: 0.9255, G loss: 0.8689\n",
      "[1684/1762] D loss: 0.6114, G loss: 1.1884\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6990\n",
      "train error: \n",
      " D loss: 1.368665, G loss: 0.572944, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360457, G loss: 0.572273, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.6987\n",
      "[84/1762] D loss: 1.3966, G loss: 0.7221\n",
      "[164/1762] D loss: 1.3664, G loss: 0.6778\n",
      "[244/1762] D loss: 1.4042, G loss: 0.7291\n",
      "[324/1762] D loss: 0.5944, G loss: 1.3149\n",
      "[404/1762] D loss: 0.4444, G loss: 1.4364\n",
      "[484/1762] D loss: 0.5394, G loss: 1.4402\n",
      "[564/1762] D loss: 2.1310, G loss: 0.6372\n",
      "[644/1762] D loss: 1.3894, G loss: 0.6969\n",
      "[724/1762] D loss: 1.3863, G loss: 0.7474\n",
      "[804/1762] D loss: 1.3690, G loss: 0.7199\n",
      "[884/1762] D loss: 1.3950, G loss: 0.6878\n",
      "[964/1762] D loss: 1.4215, G loss: 0.7979\n",
      "[1044/1762] D loss: 0.9311, G loss: 0.8823\n",
      "[1124/1762] D loss: 0.5996, G loss: 1.1479\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7331\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.7178\n",
      "[1364/1762] D loss: 1.4078, G loss: 0.7992\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.7525\n",
      "[1524/1762] D loss: 1.4406, G loss: 0.6554\n",
      "[1604/1762] D loss: 1.3709, G loss: 0.7131\n",
      "[1684/1762] D loss: 1.3741, G loss: 0.7322\n",
      "[1762/1762] D loss: 1.4226, G loss: 0.6787\n",
      "train error: \n",
      " D loss: 1.390199, G loss: 0.749892, D accuracy: 50.7%, cell accuracy: 99.4%, board accuracy: 48.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397664, G loss: 0.752156, D accuracy: 50.9%, cell accuracy: 99.4%, board accuracy: 46.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4031, G loss: 0.6517\n",
      "[84/1762] D loss: 1.3874, G loss: 0.7235\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6764\n",
      "[244/1762] D loss: 1.1678, G loss: 0.7708\n",
      "[324/1762] D loss: 1.3971, G loss: 0.6323\n",
      "[404/1762] D loss: 1.3815, G loss: 0.7128\n",
      "[484/1762] D loss: 1.4102, G loss: 0.7777\n",
      "[564/1762] D loss: 0.8103, G loss: 1.1758\n",
      "[644/1762] D loss: 0.6045, G loss: 1.1956\n",
      "[724/1762] D loss: 1.3802, G loss: 0.7720\n",
      "[804/1762] D loss: 1.4097, G loss: 0.7085\n",
      "[884/1762] D loss: 1.3844, G loss: 0.7103\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6801\n",
      "[1044/1762] D loss: 1.4082, G loss: 0.7200\n",
      "[1124/1762] D loss: 1.3475, G loss: 0.6841\n",
      "[1204/1762] D loss: 1.4477, G loss: 0.7627\n",
      "[1284/1762] D loss: 1.4310, G loss: 0.7251\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.6813\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.6931\n",
      "[1524/1762] D loss: 1.4084, G loss: 0.7216\n",
      "[1604/1762] D loss: 1.4900, G loss: 0.8512\n",
      "[1684/1762] D loss: 1.7466, G loss: 1.0155\n",
      "[1762/1762] D loss: 1.4553, G loss: 0.7024\n",
      "train error: \n",
      " D loss: 1.351248, G loss: 0.622607, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340027, G loss: 0.625850, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5859, G loss: 1.2863\n",
      "[84/1762] D loss: 1.3417, G loss: 0.7917\n",
      "[164/1762] D loss: 1.3987, G loss: 0.7350\n",
      "[244/1762] D loss: 1.4017, G loss: 0.7281\n",
      "[324/1762] D loss: 0.4574, G loss: 1.4055\n",
      "[404/1762] D loss: 1.4025, G loss: 0.7215\n",
      "[484/1762] D loss: 1.4279, G loss: 0.6462\n",
      "[564/1762] D loss: 1.4299, G loss: 0.7195\n",
      "[644/1762] D loss: 0.5575, G loss: 1.2763\n",
      "[724/1762] D loss: 1.3991, G loss: 0.7067\n",
      "[804/1762] D loss: 1.3945, G loss: 0.6991\n",
      "[884/1762] D loss: 1.3947, G loss: 0.7247\n",
      "[964/1762] D loss: 1.5529, G loss: 0.9616\n",
      "[1044/1762] D loss: 1.4535, G loss: 0.7836\n",
      "[1124/1762] D loss: 1.4183, G loss: 0.6650\n",
      "[1204/1762] D loss: 1.4031, G loss: 0.7052\n",
      "[1284/1762] D loss: 0.6276, G loss: 1.1429\n",
      "[1364/1762] D loss: 1.5672, G loss: 0.8735\n",
      "[1444/1762] D loss: 1.4956, G loss: 0.7198\n",
      "[1524/1762] D loss: 0.6353, G loss: 1.2072\n",
      "[1604/1762] D loss: 1.2783, G loss: 0.7519\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.7172\n",
      "[1762/1762] D loss: 1.4109, G loss: 0.7080\n",
      "train error: \n",
      " D loss: 1.335189, G loss: 0.636934, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 77.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323899, G loss: 0.641042, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3825, G loss: 0.6797\n",
      "[84/1762] D loss: 1.3897, G loss: 0.8092\n",
      "[164/1762] D loss: 1.3886, G loss: 0.7345\n",
      "[244/1762] D loss: 0.5006, G loss: 1.2324\n",
      "[324/1762] D loss: 0.3959, G loss: 1.4306\n",
      "[404/1762] D loss: 1.4031, G loss: 0.7503\n",
      "[484/1762] D loss: 1.5598, G loss: 0.9057\n",
      "[564/1762] D loss: 0.6335, G loss: 1.2055\n",
      "[644/1762] D loss: 1.3924, G loss: 0.8663\n",
      "[724/1762] D loss: 0.6650, G loss: 1.0724\n",
      "[804/1762] D loss: 1.4485, G loss: 0.8312\n",
      "[884/1762] D loss: 0.4380, G loss: 1.2565\n",
      "[964/1762] D loss: 1.3939, G loss: 0.6844\n",
      "[1044/1762] D loss: 1.4786, G loss: 0.8880\n",
      "[1124/1762] D loss: 1.4256, G loss: 0.6847\n",
      "[1204/1762] D loss: 1.3668, G loss: 0.7140\n",
      "[1284/1762] D loss: 1.4182, G loss: 0.7409\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.7181\n",
      "[1444/1762] D loss: 1.3840, G loss: 0.6989\n",
      "[1524/1762] D loss: 0.5976, G loss: 1.0957\n",
      "[1604/1762] D loss: 1.3990, G loss: 0.7325\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.7000\n",
      "[1762/1762] D loss: 1.4103, G loss: 0.7668\n",
      "train error: \n",
      " D loss: 1.335970, G loss: 0.670877, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321577, G loss: 0.676506, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6880\n",
      "[84/1762] D loss: 1.4064, G loss: 0.7721\n",
      "[164/1762] D loss: 1.3916, G loss: 0.7188\n",
      "[244/1762] D loss: 0.5495, G loss: 1.1498\n",
      "[324/1762] D loss: 1.3918, G loss: 0.7031\n",
      "[404/1762] D loss: 1.3932, G loss: 0.7438\n",
      "[484/1762] D loss: 1.4888, G loss: 0.8901\n",
      "[564/1762] D loss: 1.3979, G loss: 0.6617\n",
      "[644/1762] D loss: 1.4062, G loss: 0.7333\n",
      "[724/1762] D loss: 1.3996, G loss: 0.7178\n",
      "[804/1762] D loss: 1.4016, G loss: 0.7103\n",
      "[884/1762] D loss: 0.5627, G loss: 1.1321\n",
      "[964/1762] D loss: 1.5498, G loss: 0.9205\n",
      "[1044/1762] D loss: 1.4028, G loss: 0.7013\n",
      "[1124/1762] D loss: 1.4290, G loss: 0.7543\n",
      "[1204/1762] D loss: 1.4509, G loss: 0.7899\n",
      "[1284/1762] D loss: 1.4171, G loss: 0.7429\n",
      "[1364/1762] D loss: 0.5899, G loss: 1.1116\n",
      "[1444/1762] D loss: 1.4310, G loss: 0.7661\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.7080\n",
      "[1604/1762] D loss: 1.4171, G loss: 0.7292\n",
      "[1684/1762] D loss: 1.4331, G loss: 0.8156\n",
      "[1762/1762] D loss: 0.4468, G loss: 1.3526\n",
      "train error: \n",
      " D loss: 1.720100, G loss: 0.267557, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.716214, G loss: 0.270543, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4650, G loss: 1.2664\n",
      "[84/1762] D loss: 1.4292, G loss: 0.7369\n",
      "[164/1762] D loss: 1.4549, G loss: 0.8802\n",
      "[244/1762] D loss: 0.6900, G loss: 1.0545\n",
      "[324/1762] D loss: 1.4211, G loss: 0.8031\n",
      "[404/1762] D loss: 0.5334, G loss: 1.1700\n",
      "[484/1762] D loss: 1.5329, G loss: 0.9159\n",
      "[564/1762] D loss: 1.3402, G loss: 0.7847\n",
      "[644/1762] D loss: 0.3947, G loss: 1.3581\n",
      "[724/1762] D loss: 1.3905, G loss: 0.6781\n",
      "[804/1762] D loss: 1.5036, G loss: 0.7476\n",
      "[884/1762] D loss: 0.6693, G loss: 1.1464\n",
      "[964/1762] D loss: 1.3784, G loss: 0.6949\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.7128\n",
      "[1124/1762] D loss: 1.4311, G loss: 0.7856\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.7283\n",
      "[1284/1762] D loss: 1.3996, G loss: 0.7058\n",
      "[1364/1762] D loss: 1.3351, G loss: 0.7508\n",
      "[1444/1762] D loss: 1.6458, G loss: 0.8929\n",
      "[1524/1762] D loss: 0.4442, G loss: 1.2176\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.7491\n",
      "[1684/1762] D loss: 1.4119, G loss: 0.7307\n",
      "[1762/1762] D loss: 0.4379, G loss: 1.3825\n",
      "train error: \n",
      " D loss: 1.403374, G loss: 0.503258, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390659, G loss: 0.507634, D accuracy: 50.5%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4270, G loss: 0.7757\n",
      "[84/1762] D loss: 1.4803, G loss: 0.8106\n",
      "[164/1762] D loss: 1.4383, G loss: 0.7328\n",
      "[244/1762] D loss: 1.3924, G loss: 0.7398\n",
      "[324/1762] D loss: 1.3593, G loss: 0.8122\n",
      "[404/1762] D loss: 0.4231, G loss: 1.2614\n",
      "[484/1762] D loss: 1.4143, G loss: 0.7706\n",
      "[564/1762] D loss: 0.5153, G loss: 1.1663\n",
      "[644/1762] D loss: 1.3741, G loss: 0.6727\n",
      "[724/1762] D loss: 1.5420, G loss: 0.9626\n",
      "[804/1762] D loss: 0.6324, G loss: 1.1256\n",
      "[884/1762] D loss: 0.5398, G loss: 1.2389\n",
      "[964/1762] D loss: 1.4990, G loss: 0.8514\n",
      "[1044/1762] D loss: 1.4042, G loss: 0.7502\n",
      "[1124/1762] D loss: 1.4105, G loss: 0.7425\n",
      "[1204/1762] D loss: 1.4665, G loss: 0.8721\n",
      "[1284/1762] D loss: 1.3683, G loss: 0.6867\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7739\n",
      "[1444/1762] D loss: 1.3546, G loss: 0.7883\n",
      "[1524/1762] D loss: 1.3836, G loss: 0.6983\n",
      "[1604/1762] D loss: 1.4121, G loss: 0.7834\n",
      "[1684/1762] D loss: 1.4120, G loss: 0.7410\n",
      "[1762/1762] D loss: 1.4301, G loss: 0.7341\n",
      "train error: \n",
      " D loss: 1.370311, G loss: 0.553203, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357584, G loss: 0.552132, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6910, G loss: 1.0897\n",
      "[84/1762] D loss: 1.4291, G loss: 0.8283\n",
      "[164/1762] D loss: 0.4327, G loss: 1.2568\n",
      "[244/1762] D loss: 1.3989, G loss: 0.7256\n",
      "[324/1762] D loss: 1.4769, G loss: 0.8257\n",
      "[404/1762] D loss: 1.3945, G loss: 0.8453\n",
      "[484/1762] D loss: 1.4611, G loss: 0.7796\n",
      "[564/1762] D loss: 0.3900, G loss: 1.3530\n",
      "[644/1762] D loss: 0.4626, G loss: 1.2584\n",
      "[724/1762] D loss: 1.3950, G loss: 0.7224\n",
      "[804/1762] D loss: 1.4123, G loss: 0.7484\n",
      "[884/1762] D loss: 0.5027, G loss: 1.2692\n",
      "[964/1762] D loss: 1.4601, G loss: 0.7522\n",
      "[1044/1762] D loss: 1.3798, G loss: 0.8620\n",
      "[1124/1762] D loss: 1.4272, G loss: 0.8001\n",
      "[1204/1762] D loss: 1.4542, G loss: 0.8263\n",
      "[1284/1762] D loss: 1.4058, G loss: 0.7900\n",
      "[1364/1762] D loss: 1.4555, G loss: 0.7863\n",
      "[1444/1762] D loss: 1.3938, G loss: 0.6666\n",
      "[1524/1762] D loss: 1.4223, G loss: 0.7955\n",
      "[1604/1762] D loss: 0.4122, G loss: 1.2839\n",
      "[1684/1762] D loss: 1.4071, G loss: 0.7444\n",
      "[1762/1762] D loss: 1.4171, G loss: 0.7488\n",
      "train error: \n",
      " D loss: 1.594707, G loss: 0.334837, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.581378, G loss: 0.337784, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4446, G loss: 0.8030\n",
      "[84/1762] D loss: 1.3963, G loss: 0.7050\n",
      "[164/1762] D loss: 1.4134, G loss: 0.7441\n",
      "[244/1762] D loss: 0.4872, G loss: 1.2654\n",
      "[324/1762] D loss: 1.4060, G loss: 0.6651\n",
      "[404/1762] D loss: 0.4224, G loss: 1.3183\n",
      "[484/1762] D loss: 1.4628, G loss: 0.7868\n",
      "[564/1762] D loss: 0.4521, G loss: 1.2829\n",
      "[644/1762] D loss: 1.4384, G loss: 0.8215\n",
      "[724/1762] D loss: 0.3962, G loss: 1.3693\n",
      "[804/1762] D loss: 0.4998, G loss: 1.2281\n",
      "[884/1762] D loss: 1.4223, G loss: 0.8262\n",
      "[964/1762] D loss: 1.3939, G loss: 0.8184\n",
      "[1044/1762] D loss: 0.5761, G loss: 1.1337\n",
      "[1124/1762] D loss: 0.5457, G loss: 1.1918\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.7108\n",
      "[1284/1762] D loss: 1.3721, G loss: 0.6953\n",
      "[1364/1762] D loss: 1.4174, G loss: 0.7228\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.7060\n",
      "[1524/1762] D loss: 1.6026, G loss: 1.0035\n",
      "[1604/1762] D loss: 1.4267, G loss: 0.8005\n",
      "[1684/1762] D loss: 1.3994, G loss: 0.7019\n",
      "[1762/1762] D loss: 1.4060, G loss: 0.6697\n",
      "train error: \n",
      " D loss: 1.388606, G loss: 0.557927, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377229, G loss: 0.559273, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951, G loss: 0.6979\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6839\n",
      "[164/1762] D loss: 1.4040, G loss: 0.6665\n",
      "[244/1762] D loss: 0.4483, G loss: 1.2917\n",
      "[324/1762] D loss: 1.4285, G loss: 0.7583\n",
      "[404/1762] D loss: 1.3874, G loss: 0.7084\n",
      "[484/1762] D loss: 1.4033, G loss: 0.7561\n",
      "[564/1762] D loss: 1.3970, G loss: 0.7233\n",
      "[644/1762] D loss: 1.4061, G loss: 0.7281\n",
      "[724/1762] D loss: 1.3959, G loss: 0.6666\n",
      "[804/1762] D loss: 1.5291, G loss: 0.6808\n",
      "[884/1762] D loss: 1.3962, G loss: 0.6981\n",
      "[964/1762] D loss: 0.5209, G loss: 1.1944\n",
      "[1044/1762] D loss: 1.3966, G loss: 0.7549\n",
      "[1124/1762] D loss: 1.6497, G loss: 0.8729\n",
      "[1204/1762] D loss: 1.4752, G loss: 0.8031\n",
      "[1284/1762] D loss: 1.4057, G loss: 0.7532\n",
      "[1364/1762] D loss: 1.5005, G loss: 0.7498\n",
      "[1444/1762] D loss: 1.4048, G loss: 0.7229\n",
      "[1524/1762] D loss: 0.5069, G loss: 1.3270\n",
      "[1604/1762] D loss: 1.4310, G loss: 0.7555\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.7065\n",
      "[1762/1762] D loss: 0.2879, G loss: 1.6391\n",
      "train error: \n",
      " D loss: 1.423155, G loss: 0.481459, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416779, G loss: 0.483174, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5521, G loss: 0.9195\n",
      "[84/1762] D loss: 1.4099, G loss: 0.7712\n",
      "[164/1762] D loss: 0.4716, G loss: 1.3284\n",
      "[244/1762] D loss: 0.4544, G loss: 1.3894\n",
      "[324/1762] D loss: 0.4627, G loss: 1.2793\n",
      "[404/1762] D loss: 1.4024, G loss: 0.6888\n",
      "[484/1762] D loss: 1.3923, G loss: 0.7100\n",
      "[564/1762] D loss: 1.7038, G loss: 0.9167\n",
      "[644/1762] D loss: 1.5502, G loss: 0.8627\n",
      "[724/1762] D loss: 0.4158, G loss: 1.3035\n",
      "[804/1762] D loss: 1.4102, G loss: 0.6865\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6982\n",
      "[964/1762] D loss: 1.3892, G loss: 0.7037\n",
      "[1044/1762] D loss: 1.3927, G loss: 0.7122\n",
      "[1124/1762] D loss: 1.5061, G loss: 0.8728\n",
      "[1204/1762] D loss: 0.5090, G loss: 1.1989\n",
      "[1284/1762] D loss: 1.4345, G loss: 0.7817\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6695\n",
      "[1444/1762] D loss: 1.3965, G loss: 0.7140\n",
      "[1524/1762] D loss: 1.3941, G loss: 0.7198\n",
      "[1604/1762] D loss: 1.4449, G loss: 0.8141\n",
      "[1684/1762] D loss: 0.6012, G loss: 1.0645\n",
      "[1762/1762] D loss: 1.3965, G loss: 0.6239\n",
      "train error: \n",
      " D loss: 1.347901, G loss: 0.643000, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336262, G loss: 0.637953, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4202, G loss: 0.7707\n",
      "[84/1762] D loss: 1.5850, G loss: 0.9926\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6927\n",
      "[244/1762] D loss: 0.4752, G loss: 1.2055\n",
      "[324/1762] D loss: 0.3360, G loss: 1.4756\n",
      "[404/1762] D loss: 0.4301, G loss: 1.2943\n",
      "[484/1762] D loss: 1.3935, G loss: 0.7228\n",
      "[564/1762] D loss: 0.5528, G loss: 1.2268\n",
      "[644/1762] D loss: 1.4292, G loss: 0.7856\n",
      "[724/1762] D loss: 0.3207, G loss: 1.4923\n",
      "[804/1762] D loss: 0.6561, G loss: 1.1030\n",
      "[884/1762] D loss: 0.5781, G loss: 1.0765\n",
      "[964/1762] D loss: 1.4825, G loss: 0.8378\n",
      "[1044/1762] D loss: 1.4485, G loss: 0.8157\n",
      "[1124/1762] D loss: 0.3850, G loss: 1.4424\n",
      "[1204/1762] D loss: 0.4903, G loss: 1.4287\n",
      "[1284/1762] D loss: 1.4362, G loss: 0.8578\n",
      "[1364/1762] D loss: 1.4200, G loss: 0.7431\n",
      "[1444/1762] D loss: 1.3917, G loss: 0.6921\n",
      "[1524/1762] D loss: 0.4619, G loss: 1.3183\n",
      "[1604/1762] D loss: 0.4894, G loss: 1.2478\n",
      "[1684/1762] D loss: 1.3976, G loss: 0.7436\n",
      "[1762/1762] D loss: 1.3965, G loss: 0.7166\n",
      "train error: \n",
      " D loss: 1.340049, G loss: 0.681959, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326969, G loss: 0.683772, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980, G loss: 0.6991\n",
      "[84/1762] D loss: 0.4088, G loss: 1.3098\n",
      "[164/1762] D loss: 1.4168, G loss: 0.8048\n",
      "[244/1762] D loss: 0.3591, G loss: 1.3716\n",
      "[324/1762] D loss: 1.4712, G loss: 0.8700\n",
      "[404/1762] D loss: 1.4273, G loss: 0.7320\n",
      "[484/1762] D loss: 0.3814, G loss: 1.4335\n",
      "[564/1762] D loss: 0.3530, G loss: 1.4413\n",
      "[644/1762] D loss: 1.4302, G loss: 0.8018\n",
      "[724/1762] D loss: 0.5377, G loss: 1.2518\n",
      "[804/1762] D loss: 1.3906, G loss: 0.6870\n",
      "[884/1762] D loss: 1.3911, G loss: 0.7048\n",
      "[964/1762] D loss: 0.5236, G loss: 1.2680\n",
      "[1044/1762] D loss: 1.4566, G loss: 0.8057\n",
      "[1124/1762] D loss: 1.4129, G loss: 0.7247\n",
      "[1204/1762] D loss: 1.4488, G loss: 0.7075\n",
      "[1284/1762] D loss: 1.4403, G loss: 0.7610\n",
      "[1364/1762] D loss: 1.3989, G loss: 0.7221\n",
      "[1444/1762] D loss: 1.4464, G loss: 0.8213\n",
      "[1524/1762] D loss: 1.4146, G loss: 0.7676\n",
      "[1604/1762] D loss: 1.4017, G loss: 0.7609\n",
      "[1684/1762] D loss: 1.4461, G loss: 0.7993\n",
      "[1762/1762] D loss: 1.4173, G loss: 0.7539\n",
      "train error: \n",
      " D loss: 1.342708, G loss: 0.669121, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330235, G loss: 0.668516, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4188, G loss: 0.7718\n",
      "[84/1762] D loss: 0.4392, G loss: 1.3282\n",
      "[164/1762] D loss: 1.4056, G loss: 0.6652\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7337\n",
      "[324/1762] D loss: 1.4273, G loss: 0.7568\n",
      "[404/1762] D loss: 0.6323, G loss: 1.1440\n",
      "[484/1762] D loss: 1.3924, G loss: 0.7009\n",
      "[564/1762] D loss: 1.3933, G loss: 0.6794\n",
      "[644/1762] D loss: 1.3892, G loss: 0.7035\n",
      "[724/1762] D loss: 0.4416, G loss: 1.3318\n",
      "[804/1762] D loss: 1.4805, G loss: 0.8446\n",
      "[884/1762] D loss: 1.4348, G loss: 0.7526\n",
      "[964/1762] D loss: 0.5243, G loss: 1.1880\n",
      "[1044/1762] D loss: 1.3936, G loss: 0.7199\n",
      "[1124/1762] D loss: 1.3909, G loss: 0.6902\n",
      "[1204/1762] D loss: 1.3859, G loss: 0.7196\n",
      "[1284/1762] D loss: 1.4529, G loss: 0.7743\n",
      "[1364/1762] D loss: 1.5210, G loss: 0.8980\n",
      "[1444/1762] D loss: 1.4047, G loss: 0.7643\n",
      "[1524/1762] D loss: 1.4002, G loss: 0.7204\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.7274\n",
      "[1684/1762] D loss: 1.4171, G loss: 0.7957\n",
      "[1762/1762] D loss: 1.4936, G loss: 0.6409\n",
      "train error: \n",
      " D loss: 1.493179, G loss: 0.442116, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.479190, G loss: 0.442918, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5405, G loss: 1.3742\n",
      "[84/1762] D loss: 1.4896, G loss: 0.7493\n",
      "[164/1762] D loss: 1.3950, G loss: 0.7269\n",
      "[244/1762] D loss: 1.3891, G loss: 0.7137\n",
      "[324/1762] D loss: 1.3905, G loss: 0.7098\n",
      "[404/1762] D loss: 1.3919, G loss: 0.7068\n",
      "[484/1762] D loss: 1.3947, G loss: 0.6939\n",
      "[564/1762] D loss: 1.3999, G loss: 0.6742\n",
      "[644/1762] D loss: 0.3712, G loss: 1.3871\n",
      "[724/1762] D loss: 1.6161, G loss: 0.6235\n",
      "[804/1762] D loss: 0.6218, G loss: 1.2756\n",
      "[884/1762] D loss: 1.4639, G loss: 0.8317\n",
      "[964/1762] D loss: 1.5676, G loss: 0.9676\n",
      "[1044/1762] D loss: 1.3984, G loss: 0.7045\n",
      "[1124/1762] D loss: 1.4143, G loss: 0.7716\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.6914\n",
      "[1284/1762] D loss: 1.4379, G loss: 0.8279\n",
      "[1364/1762] D loss: 0.5872, G loss: 1.1353\n",
      "[1444/1762] D loss: 0.5170, G loss: 1.3000\n",
      "[1524/1762] D loss: 1.4200, G loss: 0.7351\n",
      "[1604/1762] D loss: 1.4078, G loss: 0.7507\n",
      "[1684/1762] D loss: 0.5705, G loss: 1.1505\n",
      "[1762/1762] D loss: 1.5628, G loss: 0.6828\n",
      "train error: \n",
      " D loss: 1.372399, G loss: 0.545630, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362095, G loss: 0.545205, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.7173\n",
      "[84/1762] D loss: 1.3894, G loss: 0.7088\n",
      "[164/1762] D loss: 0.4641, G loss: 1.2324\n",
      "[244/1762] D loss: 1.3958, G loss: 0.7100\n",
      "[324/1762] D loss: 1.4174, G loss: 0.7697\n",
      "[404/1762] D loss: 1.4264, G loss: 0.7300\n",
      "[484/1762] D loss: 0.9292, G loss: 1.3577\n",
      "[564/1762] D loss: 1.4217, G loss: 0.7713\n",
      "[644/1762] D loss: 1.4040, G loss: 0.7294\n",
      "[724/1762] D loss: 1.3910, G loss: 0.6793\n",
      "[804/1762] D loss: 1.3905, G loss: 0.6854\n",
      "[884/1762] D loss: 1.3963, G loss: 0.7150\n",
      "[964/1762] D loss: 1.4586, G loss: 0.7277\n",
      "[1044/1762] D loss: 1.4012, G loss: 0.7018\n",
      "[1124/1762] D loss: 0.3584, G loss: 1.4636\n",
      "[1204/1762] D loss: 1.4214, G loss: 0.7291\n",
      "[1284/1762] D loss: 1.4078, G loss: 0.7377\n",
      "[1364/1762] D loss: 0.5870, G loss: 1.2037\n",
      "[1444/1762] D loss: 0.5820, G loss: 1.2385\n",
      "[1524/1762] D loss: 1.3942, G loss: 0.7171\n",
      "[1604/1762] D loss: 1.4188, G loss: 0.7549\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.6965\n",
      "[1762/1762] D loss: 1.4031, G loss: 0.7629\n",
      "train error: \n",
      " D loss: 1.358993, G loss: 0.615735, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345650, G loss: 0.612344, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4192, G loss: 0.7415\n",
      "[84/1762] D loss: 1.3937, G loss: 0.6796\n",
      "[164/1762] D loss: 1.4045, G loss: 0.6603\n",
      "[244/1762] D loss: 0.3605, G loss: 1.5124\n",
      "[324/1762] D loss: 1.4274, G loss: 0.7993\n",
      "[404/1762] D loss: 1.4605, G loss: 0.8138\n",
      "[484/1762] D loss: 1.4948, G loss: 0.8007\n",
      "[564/1762] D loss: 0.4541, G loss: 1.2845\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7475\n",
      "[724/1762] D loss: 1.4200, G loss: 0.7613\n",
      "[804/1762] D loss: 0.5051, G loss: 1.2237\n",
      "[884/1762] D loss: 0.5552, G loss: 1.2250\n",
      "[964/1762] D loss: 1.4904, G loss: 0.8048\n",
      "[1044/1762] D loss: 1.4396, G loss: 0.7694\n",
      "[1124/1762] D loss: 1.4133, G loss: 0.7533\n",
      "[1204/1762] D loss: 1.6208, G loss: 0.8901\n",
      "[1284/1762] D loss: 1.3978, G loss: 0.7035\n",
      "[1364/1762] D loss: 1.3859, G loss: 0.7051\n",
      "[1444/1762] D loss: 1.4088, G loss: 0.6957\n",
      "[1524/1762] D loss: 1.4064, G loss: 0.7284\n",
      "[1604/1762] D loss: 0.3801, G loss: 1.4067\n",
      "[1684/1762] D loss: 1.4620, G loss: 0.7672\n",
      "[1762/1762] D loss: 0.2124, G loss: 1.8241\n",
      "train error: \n",
      " D loss: 1.487963, G loss: 0.430339, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.478474, G loss: 0.428785, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3272, G loss: 1.5507\n",
      "[84/1762] D loss: 1.3934, G loss: 0.7150\n",
      "[164/1762] D loss: 0.3301, G loss: 1.5721\n",
      "[244/1762] D loss: 1.4561, G loss: 0.8162\n",
      "[324/1762] D loss: 1.4517, G loss: 0.7126\n",
      "[404/1762] D loss: 0.5448, G loss: 1.2971\n",
      "[484/1762] D loss: 0.5233, G loss: 1.3464\n",
      "[564/1762] D loss: 1.4056, G loss: 0.7178\n",
      "[644/1762] D loss: 1.3706, G loss: 0.6847\n",
      "[724/1762] D loss: 0.4510, G loss: 1.3361\n",
      "[804/1762] D loss: 1.4351, G loss: 0.7427\n",
      "[884/1762] D loss: 0.4977, G loss: 1.2835\n",
      "[964/1762] D loss: 1.4196, G loss: 0.6545\n",
      "[1044/1762] D loss: 1.4512, G loss: 0.7498\n",
      "[1124/1762] D loss: 0.4275, G loss: 1.3387\n",
      "[1204/1762] D loss: 0.3669, G loss: 1.4242\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.7077\n",
      "[1364/1762] D loss: 1.4967, G loss: 0.7845\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.6979\n",
      "[1524/1762] D loss: 1.4176, G loss: 0.7198\n",
      "[1604/1762] D loss: 1.4065, G loss: 0.6767\n",
      "[1684/1762] D loss: 0.2457, G loss: 1.7958\n",
      "[1762/1762] D loss: 1.4323, G loss: 0.7112\n",
      "train error: \n",
      " D loss: 1.383642, G loss: 0.557649, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374107, G loss: 0.557510, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.7010\n",
      "[84/1762] D loss: 1.3915, G loss: 0.7016\n",
      "[164/1762] D loss: 0.3403, G loss: 1.4720\n",
      "[244/1762] D loss: 1.3594, G loss: 0.7822\n",
      "[324/1762] D loss: 1.3961, G loss: 0.7237\n",
      "[404/1762] D loss: 1.3969, G loss: 0.6932\n",
      "[484/1762] D loss: 1.5146, G loss: 0.8863\n",
      "[564/1762] D loss: 1.4591, G loss: 0.7881\n",
      "[644/1762] D loss: 1.4405, G loss: 0.7282\n",
      "[724/1762] D loss: 1.3640, G loss: 0.7053\n",
      "[804/1762] D loss: 1.5376, G loss: 0.9181\n",
      "[884/1762] D loss: 0.4089, G loss: 1.3945\n",
      "[964/1762] D loss: 1.4088, G loss: 0.6733\n",
      "[1044/1762] D loss: 1.4055, G loss: 0.6798\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.7155\n",
      "[1204/1762] D loss: 0.5803, G loss: 1.1672\n",
      "[1284/1762] D loss: 1.4522, G loss: 0.7889\n",
      "[1364/1762] D loss: 0.5260, G loss: 1.2352\n",
      "[1444/1762] D loss: 1.4277, G loss: 0.7453\n",
      "[1524/1762] D loss: 1.4382, G loss: 0.7622\n",
      "[1604/1762] D loss: 1.4150, G loss: 0.7039\n",
      "[1684/1762] D loss: 1.4509, G loss: 1.0115\n",
      "[1762/1762] D loss: 1.4305, G loss: 0.6663\n",
      "train error: \n",
      " D loss: 1.351610, G loss: 0.663255, D accuracy: 52.2%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337789, G loss: 0.663007, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4259, G loss: 0.7605\n",
      "[84/1762] D loss: 1.4801, G loss: 0.8655\n",
      "[164/1762] D loss: 0.4374, G loss: 1.3167\n",
      "[244/1762] D loss: 0.4005, G loss: 1.4791\n",
      "[324/1762] D loss: 1.3858, G loss: 0.7111\n",
      "[404/1762] D loss: 0.5122, G loss: 1.2584\n",
      "[484/1762] D loss: 1.3528, G loss: 0.7071\n",
      "[564/1762] D loss: 1.3738, G loss: 0.7529\n",
      "[644/1762] D loss: 1.4837, G loss: 0.7769\n",
      "[724/1762] D loss: 1.4148, G loss: 0.7275\n",
      "[804/1762] D loss: 1.4533, G loss: 0.7824\n",
      "[884/1762] D loss: 1.4371, G loss: 0.7506\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7273\n",
      "[1044/1762] D loss: 1.4055, G loss: 0.7185\n",
      "[1124/1762] D loss: 1.3947, G loss: 0.6879\n",
      "[1204/1762] D loss: 0.2913, G loss: 1.6217\n",
      "[1284/1762] D loss: 1.6139, G loss: 0.7747\n",
      "[1364/1762] D loss: 1.4179, G loss: 0.7224\n",
      "[1444/1762] D loss: 1.5050, G loss: 0.8100\n",
      "[1524/1762] D loss: 1.3963, G loss: 0.7088\n",
      "[1604/1762] D loss: 1.4066, G loss: 0.7283\n",
      "[1684/1762] D loss: 1.3935, G loss: 0.6793\n",
      "[1762/1762] D loss: 1.4460, G loss: 0.7210\n",
      "train error: \n",
      " D loss: 1.318314, G loss: 0.785432, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301920, G loss: 0.792599, D accuracy: 55.1%, cell accuracy: 99.5%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2563, G loss: 0.9849\n",
      "[84/1762] D loss: 1.3983, G loss: 0.6825\n",
      "[164/1762] D loss: 1.4369, G loss: 0.8091\n",
      "[244/1762] D loss: 1.3940, G loss: 0.7066\n",
      "[324/1762] D loss: 0.4147, G loss: 1.4500\n",
      "[404/1762] D loss: 1.4242, G loss: 0.7406\n",
      "[484/1762] D loss: 1.3927, G loss: 0.7152\n",
      "[564/1762] D loss: 1.4458, G loss: 0.7556\n",
      "[644/1762] D loss: 0.3838, G loss: 1.4466\n",
      "[724/1762] D loss: 1.4581, G loss: 0.7809\n",
      "[804/1762] D loss: 1.4493, G loss: 0.7313\n",
      "[884/1762] D loss: 1.5080, G loss: 0.8333\n",
      "[964/1762] D loss: 0.4538, G loss: 1.4592\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6992\n",
      "[1124/1762] D loss: 1.4162, G loss: 0.7721\n",
      "[1204/1762] D loss: 1.4019, G loss: 0.7387\n",
      "[1284/1762] D loss: 0.5700, G loss: 1.2298\n",
      "[1364/1762] D loss: 1.4054, G loss: 0.7375\n",
      "[1444/1762] D loss: 0.4873, G loss: 1.2894\n",
      "[1524/1762] D loss: 1.4017, G loss: 0.7399\n",
      "[1604/1762] D loss: 1.3995, G loss: 0.6611\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.7074\n",
      "[1762/1762] D loss: 1.3899, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.344947, G loss: 0.641446, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331239, G loss: 0.645996, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4037, G loss: 0.7358\n",
      "[84/1762] D loss: 0.5162, G loss: 1.2806\n",
      "[164/1762] D loss: 1.4015, G loss: 0.7283\n",
      "[244/1762] D loss: 1.3937, G loss: 0.7154\n",
      "[324/1762] D loss: 0.3434, G loss: 1.4667\n",
      "[404/1762] D loss: 0.4992, G loss: 1.1675\n",
      "[484/1762] D loss: 1.4253, G loss: 0.7711\n",
      "[564/1762] D loss: 0.4694, G loss: 1.3271\n",
      "[644/1762] D loss: 0.5164, G loss: 1.3004\n",
      "[724/1762] D loss: 1.6369, G loss: 0.8633\n",
      "[804/1762] D loss: 1.4122, G loss: 0.7071\n",
      "[884/1762] D loss: 1.4232, G loss: 0.7679\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6810\n",
      "[1044/1762] D loss: 0.3618, G loss: 1.5044\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.6713\n",
      "[1204/1762] D loss: 0.3826, G loss: 1.4220\n",
      "[1284/1762] D loss: 0.3807, G loss: 1.4932\n",
      "[1364/1762] D loss: 1.4300, G loss: 0.6909\n",
      "[1444/1762] D loss: 0.5026, G loss: 1.2693\n",
      "[1524/1762] D loss: 0.4818, G loss: 1.4217\n",
      "[1604/1762] D loss: 1.3847, G loss: 0.6977\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.6833\n",
      "[1762/1762] D loss: 1.3654, G loss: 0.7905\n",
      "train error: \n",
      " D loss: 1.350444, G loss: 0.647686, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335361, G loss: 0.651517, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7101, G loss: 1.1942\n",
      "[84/1762] D loss: 1.3970, G loss: 0.7048\n",
      "[164/1762] D loss: 1.4380, G loss: 0.7114\n",
      "[244/1762] D loss: 1.4129, G loss: 0.7449\n",
      "[324/1762] D loss: 1.4042, G loss: 0.7168\n",
      "[404/1762] D loss: 1.3992, G loss: 0.6584\n",
      "[484/1762] D loss: 1.4866, G loss: 0.7903\n",
      "[564/1762] D loss: 1.4050, G loss: 0.6949\n",
      "[644/1762] D loss: 1.3767, G loss: 0.7109\n",
      "[724/1762] D loss: 0.1599, G loss: 2.0482\n",
      "[804/1762] D loss: 1.4920, G loss: 0.7619\n",
      "[884/1762] D loss: 1.4522, G loss: 0.7440\n",
      "[964/1762] D loss: 1.4018, G loss: 0.6417\n",
      "[1044/1762] D loss: 1.4004, G loss: 0.6823\n",
      "[1124/1762] D loss: 1.3845, G loss: 0.7058\n",
      "[1204/1762] D loss: 0.2530, G loss: 1.7991\n",
      "[1284/1762] D loss: 1.3948, G loss: 0.7063\n",
      "[1364/1762] D loss: 1.6081, G loss: 0.6898\n",
      "[1444/1762] D loss: 1.3967, G loss: 0.6791\n",
      "[1524/1762] D loss: 1.4306, G loss: 0.7144\n",
      "[1604/1762] D loss: 1.4330, G loss: 0.7908\n",
      "[1684/1762] D loss: 1.4056, G loss: 0.6697\n",
      "[1762/1762] D loss: 1.3962, G loss: 0.6819\n",
      "train error: \n",
      " D loss: 1.340379, G loss: 0.637189, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322404, G loss: 0.646784, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3975, G loss: 0.6769\n",
      "[84/1762] D loss: 0.5408, G loss: 1.2509\n",
      "[164/1762] D loss: 0.3961, G loss: 1.4201\n",
      "[244/1762] D loss: 0.4176, G loss: 1.3818\n",
      "[324/1762] D loss: 1.4121, G loss: 0.7553\n",
      "[404/1762] D loss: 0.6239, G loss: 1.1846\n",
      "[484/1762] D loss: 1.5831, G loss: 0.8547\n",
      "[564/1762] D loss: 0.6777, G loss: 1.2413\n",
      "[644/1762] D loss: 1.3933, G loss: 0.7176\n",
      "[724/1762] D loss: 1.4191, G loss: 0.7490\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6852\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7297\n",
      "[964/1762] D loss: 1.3859, G loss: 0.6945\n",
      "[1044/1762] D loss: 1.4145, G loss: 0.6741\n",
      "[1124/1762] D loss: 0.4474, G loss: 1.4753\n",
      "[1204/1762] D loss: 0.2212, G loss: 1.7995\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6842\n",
      "[1364/1762] D loss: 1.4119, G loss: 0.7448\n",
      "[1444/1762] D loss: 1.3913, G loss: 0.7124\n",
      "[1524/1762] D loss: 1.5229, G loss: 0.7440\n",
      "[1604/1762] D loss: 1.4284, G loss: 0.7603\n",
      "[1684/1762] D loss: 1.5404, G loss: 0.7350\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6867\n",
      "train error: \n",
      " D loss: 1.343045, G loss: 0.644411, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327883, G loss: 0.648518, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.7251\n",
      "[84/1762] D loss: 1.4229, G loss: 0.7323\n",
      "[164/1762] D loss: 0.3215, G loss: 1.5583\n",
      "[244/1762] D loss: 1.3897, G loss: 0.6999\n",
      "[324/1762] D loss: 1.3859, G loss: 0.7109\n",
      "[404/1762] D loss: 1.3665, G loss: 0.7021\n",
      "[484/1762] D loss: 1.3773, G loss: 0.6877\n",
      "[564/1762] D loss: 0.5286, G loss: 1.3363\n",
      "[644/1762] D loss: 0.4921, G loss: 1.3743\n",
      "[724/1762] D loss: 1.3989, G loss: 0.6976\n",
      "[804/1762] D loss: 1.3921, G loss: 0.6874\n",
      "[884/1762] D loss: 1.3914, G loss: 0.6936\n",
      "[964/1762] D loss: 0.3426, G loss: 1.5261\n",
      "[1044/1762] D loss: 0.3615, G loss: 1.4468\n",
      "[1124/1762] D loss: 1.4301, G loss: 0.7409\n",
      "[1204/1762] D loss: 1.4080, G loss: 0.7499\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.7005\n",
      "[1364/1762] D loss: 1.5385, G loss: 0.5698\n",
      "[1444/1762] D loss: 1.4180, G loss: 0.6641\n",
      "[1524/1762] D loss: 1.4033, G loss: 0.6981\n",
      "[1604/1762] D loss: 1.4135, G loss: 0.6776\n",
      "[1684/1762] D loss: 1.3747, G loss: 0.7040\n",
      "[1762/1762] D loss: 1.6752, G loss: 0.9101\n",
      "train error: \n",
      " D loss: 1.359663, G loss: 0.627040, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342878, G loss: 0.627032, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3471, G loss: 1.6855\n",
      "[84/1762] D loss: 1.3903, G loss: 0.7073\n",
      "[164/1762] D loss: 0.4327, G loss: 1.3433\n",
      "[244/1762] D loss: 1.3968, G loss: 0.6876\n",
      "[324/1762] D loss: 1.4288, G loss: 0.6745\n",
      "[404/1762] D loss: 1.3858, G loss: 0.7089\n",
      "[484/1762] D loss: 1.3934, G loss: 0.7047\n",
      "[564/1762] D loss: 1.4385, G loss: 0.7360\n",
      "[644/1762] D loss: 0.4135, G loss: 1.4931\n",
      "[724/1762] D loss: 1.6844, G loss: 0.8393\n",
      "[804/1762] D loss: 1.3993, G loss: 0.6997\n",
      "[884/1762] D loss: 1.3928, G loss: 0.6777\n",
      "[964/1762] D loss: 1.4724, G loss: 0.8109\n",
      "[1044/1762] D loss: 1.3951, G loss: 0.6998\n",
      "[1124/1762] D loss: 1.4082, G loss: 0.7395\n",
      "[1204/1762] D loss: 1.4681, G loss: 0.7708\n",
      "[1284/1762] D loss: 0.2480, G loss: 1.7435\n",
      "[1364/1762] D loss: 1.4263, G loss: 0.7137\n",
      "[1444/1762] D loss: 0.5910, G loss: 1.4771\n",
      "[1524/1762] D loss: 0.6394, G loss: 1.3077\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.7457\n",
      "[1684/1762] D loss: 1.3686, G loss: 0.7070\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.6788\n",
      "train error: \n",
      " D loss: 1.366786, G loss: 0.596188, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354681, G loss: 0.591609, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.7019\n",
      "[84/1762] D loss: 1.3938, G loss: 0.7228\n",
      "[164/1762] D loss: 0.3805, G loss: 1.4413\n",
      "[244/1762] D loss: 1.4210, G loss: 0.6829\n",
      "[324/1762] D loss: 1.3993, G loss: 0.7121\n",
      "[404/1762] D loss: 1.3936, G loss: 0.6841\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6905\n",
      "[564/1762] D loss: 1.4517, G loss: 0.6910\n",
      "[644/1762] D loss: 1.4190, G loss: 0.7046\n",
      "[724/1762] D loss: 1.5148, G loss: 0.7962\n",
      "[804/1762] D loss: 0.5518, G loss: 1.5232\n",
      "[884/1762] D loss: 0.3593, G loss: 1.6095\n",
      "[964/1762] D loss: 1.4326, G loss: 0.7326\n",
      "[1044/1762] D loss: 0.3192, G loss: 1.6101\n",
      "[1124/1762] D loss: 1.3909, G loss: 0.7116\n",
      "[1204/1762] D loss: 1.4453, G loss: 0.7649\n",
      "[1284/1762] D loss: 1.3966, G loss: 0.7102\n",
      "[1364/1762] D loss: 0.3637, G loss: 1.4791\n",
      "[1444/1762] D loss: 1.3980, G loss: 0.6893\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7041\n",
      "[1604/1762] D loss: 1.3931, G loss: 0.6744\n",
      "[1684/1762] D loss: 1.3847, G loss: 0.6775\n",
      "[1762/1762] D loss: 1.4341, G loss: 0.7591\n",
      "train error: \n",
      " D loss: 1.486306, G loss: 0.422558, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.483789, G loss: 0.415234, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4056, G loss: 0.7204\n",
      "[84/1762] D loss: 1.4958, G loss: 0.6803\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6836\n",
      "[244/1762] D loss: 1.3959, G loss: 0.7070\n",
      "[324/1762] D loss: 0.4691, G loss: 1.4585\n",
      "[404/1762] D loss: 0.4204, G loss: 1.4472\n",
      "[484/1762] D loss: 1.3976, G loss: 0.6918\n",
      "[564/1762] D loss: 0.2727, G loss: 1.7673\n",
      "[644/1762] D loss: 0.3971, G loss: 1.5013\n",
      "[724/1762] D loss: 1.4053, G loss: 0.7806\n",
      "[804/1762] D loss: 1.3976, G loss: 0.6788\n",
      "[884/1762] D loss: 1.4704, G loss: 0.7613\n",
      "[964/1762] D loss: 0.4597, G loss: 1.4663\n",
      "[1044/1762] D loss: 1.5362, G loss: 0.8024\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.7036\n",
      "[1204/1762] D loss: 1.5275, G loss: 0.7748\n",
      "[1284/1762] D loss: 1.4297, G loss: 0.7338\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.6968\n",
      "[1444/1762] D loss: 1.4203, G loss: 0.7703\n",
      "[1524/1762] D loss: 1.4832, G loss: 0.7212\n",
      "[1604/1762] D loss: 1.3872, G loss: 1.1140\n",
      "[1684/1762] D loss: 1.4490, G loss: 0.7147\n",
      "[1762/1762] D loss: 1.3958, G loss: 0.6908\n",
      "train error: \n",
      " D loss: 1.353985, G loss: 0.669874, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341576, G loss: 0.669340, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4042, G loss: 0.7193\n",
      "[84/1762] D loss: 0.2825, G loss: 1.7427\n",
      "[164/1762] D loss: 0.4707, G loss: 1.4068\n",
      "[244/1762] D loss: 1.4760, G loss: 0.8030\n",
      "[324/1762] D loss: 0.5200, G loss: 1.3421\n",
      "[404/1762] D loss: 0.4613, G loss: 1.5067\n",
      "[484/1762] D loss: 0.3443, G loss: 1.5025\n",
      "[564/1762] D loss: 0.2218, G loss: 1.9279\n",
      "[644/1762] D loss: 1.3980, G loss: 0.7085\n",
      "[724/1762] D loss: 1.4109, G loss: 0.7105\n",
      "[804/1762] D loss: 1.3946, G loss: 0.7204\n",
      "[884/1762] D loss: 0.2636, G loss: 1.7748\n",
      "[964/1762] D loss: 1.3897, G loss: 0.6776\n",
      "[1044/1762] D loss: 1.4248, G loss: 0.7059\n",
      "[1124/1762] D loss: 1.5139, G loss: 0.7073\n",
      "[1204/1762] D loss: 1.3935, G loss: 0.7193\n",
      "[1284/1762] D loss: 1.4169, G loss: 0.6735\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6958\n",
      "[1444/1762] D loss: 1.5033, G loss: 0.7460\n",
      "[1524/1762] D loss: 1.4636, G loss: 0.7932\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.6915\n",
      "[1684/1762] D loss: 1.3857, G loss: 0.7083\n",
      "[1762/1762] D loss: 1.4042, G loss: 0.7084\n",
      "train error: \n",
      " D loss: 1.335175, G loss: 0.728381, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318237, G loss: 0.734023, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.6751\n",
      "[84/1762] D loss: 1.3956, G loss: 0.7191\n",
      "[164/1762] D loss: 1.3918, G loss: 0.6900\n",
      "[244/1762] D loss: 1.4076, G loss: 0.7210\n",
      "[324/1762] D loss: 0.3625, G loss: 1.4932\n",
      "[404/1762] D loss: 1.3956, G loss: 0.7280\n",
      "[484/1762] D loss: 1.3859, G loss: 0.7007\n",
      "[564/1762] D loss: 1.3972, G loss: 0.7102\n",
      "[644/1762] D loss: 1.3843, G loss: 0.6980\n",
      "[724/1762] D loss: 1.4854, G loss: 0.7426\n",
      "[804/1762] D loss: 0.3560, G loss: 1.5264\n",
      "[884/1762] D loss: 1.4034, G loss: 0.6653\n",
      "[964/1762] D loss: 1.4416, G loss: 0.7334\n",
      "[1044/1762] D loss: 1.4077, G loss: 0.6644\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.6837\n",
      "[1204/1762] D loss: 1.4399, G loss: 0.6963\n",
      "[1284/1762] D loss: 1.4406, G loss: 0.7409\n",
      "[1364/1762] D loss: 0.4759, G loss: 1.3919\n",
      "[1444/1762] D loss: 0.5209, G loss: 1.4414\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.7222\n",
      "[1604/1762] D loss: 0.4433, G loss: 1.5588\n",
      "[1684/1762] D loss: 1.4001, G loss: 0.7085\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7149\n",
      "train error: \n",
      " D loss: 1.358249, G loss: 0.732886, D accuracy: 46.9%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341184, G loss: 0.731227, D accuracy: 48.3%, cell accuracy: 99.7%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4414, G loss: 1.3713\n",
      "[84/1762] D loss: 1.4747, G loss: 0.7590\n",
      "[164/1762] D loss: 1.3856, G loss: 0.6865\n",
      "[244/1762] D loss: 1.3929, G loss: 0.6794\n",
      "[324/1762] D loss: 1.3797, G loss: 0.7090\n",
      "[404/1762] D loss: 1.4460, G loss: 0.7395\n",
      "[484/1762] D loss: 0.3209, G loss: 1.8340\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6935\n",
      "[644/1762] D loss: 0.4279, G loss: 1.4592\n",
      "[724/1762] D loss: 1.4441, G loss: 0.7042\n",
      "[804/1762] D loss: 1.3745, G loss: 0.7420\n",
      "[884/1762] D loss: 1.0935, G loss: 0.9025\n",
      "[964/1762] D loss: 1.4334, G loss: 0.6600\n",
      "[1044/1762] D loss: 1.4461, G loss: 0.9586\n",
      "[1124/1762] D loss: 1.4645, G loss: 0.7182\n",
      "[1204/1762] D loss: 1.2511, G loss: 0.7920\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.9281\n",
      "[1364/1762] D loss: 1.3998, G loss: 0.7233\n",
      "[1444/1762] D loss: 1.4066, G loss: 0.6942\n",
      "[1524/1762] D loss: 0.2753, G loss: 1.7505\n",
      "[1604/1762] D loss: 1.4082, G loss: 0.6298\n",
      "[1684/1762] D loss: 1.3947, G loss: 0.6903\n",
      "[1762/1762] D loss: 1.3997, G loss: 0.7013\n",
      "train error: \n",
      " D loss: 1.329972, G loss: 0.718582, D accuracy: 52.3%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310463, G loss: 0.727691, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4666, G loss: 0.7254\n",
      "[84/1762] D loss: 1.3974, G loss: 0.7068\n",
      "[164/1762] D loss: 0.3613, G loss: 1.5951\n",
      "[244/1762] D loss: 0.1973, G loss: 2.0143\n",
      "[324/1762] D loss: 1.3922, G loss: 0.7034\n",
      "[404/1762] D loss: 1.3955, G loss: 0.6788\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7069\n",
      "[564/1762] D loss: 1.4193, G loss: 0.7340\n",
      "[644/1762] D loss: 1.3834, G loss: 0.6815\n",
      "[724/1762] D loss: 1.4021, G loss: 0.7294\n",
      "[804/1762] D loss: 1.3939, G loss: 0.7037\n",
      "[884/1762] D loss: 1.4143, G loss: 0.6579\n",
      "[964/1762] D loss: 1.1126, G loss: 1.0140\n",
      "[1044/1762] D loss: 1.3926, G loss: 0.6805\n",
      "[1124/1762] D loss: 0.3170, G loss: 1.6897\n",
      "[1204/1762] D loss: 1.4035, G loss: 0.6979\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6937\n",
      "[1364/1762] D loss: 1.4048, G loss: 0.7118\n",
      "[1444/1762] D loss: 1.4055, G loss: 0.6824\n",
      "[1524/1762] D loss: 1.7954, G loss: 0.8382\n",
      "[1604/1762] D loss: 1.4467, G loss: 0.7425\n",
      "[1684/1762] D loss: 0.4500, G loss: 1.5118\n",
      "[1762/1762] D loss: 1.4003, G loss: 0.6811\n",
      "train error: \n",
      " D loss: 1.358795, G loss: 0.596198, D accuracy: 52.2%, cell accuracy: 99.7%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347716, G loss: 0.599282, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3873, G loss: 1.5434\n",
      "[84/1762] D loss: 0.1224, G loss: 2.6502\n",
      "[164/1762] D loss: 1.3383, G loss: 0.8269\n",
      "[244/1762] D loss: 0.1996, G loss: 1.9723\n",
      "[324/1762] D loss: 0.3546, G loss: 1.6372\n",
      "[404/1762] D loss: 0.2310, G loss: 1.9247\n",
      "[484/1762] D loss: 0.3359, G loss: 1.8012\n",
      "[564/1762] D loss: 0.3601, G loss: 1.6759\n",
      "[644/1762] D loss: 1.3941, G loss: 0.7034\n",
      "[724/1762] D loss: 0.3918, G loss: 1.7558\n",
      "[804/1762] D loss: 1.4031, G loss: 0.7405\n",
      "[884/1762] D loss: 0.3459, G loss: 1.6225\n",
      "[964/1762] D loss: 0.2679, G loss: 1.8745\n",
      "[1044/1762] D loss: 1.3919, G loss: 0.6796\n",
      "[1124/1762] D loss: 0.2380, G loss: 1.8261\n",
      "[1204/1762] D loss: 1.4689, G loss: 1.0115\n",
      "[1284/1762] D loss: 1.4102, G loss: 0.7141\n",
      "[1364/1762] D loss: 1.4016, G loss: 0.6975\n",
      "[1444/1762] D loss: 1.2550, G loss: 0.8885\n",
      "[1524/1762] D loss: 0.3741, G loss: 1.6533\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6957\n",
      "[1684/1762] D loss: 1.3779, G loss: 0.8386\n",
      "[1762/1762] D loss: 1.4447, G loss: 0.6630\n",
      "train error: \n",
      " D loss: 1.322673, G loss: 0.826335, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300903, G loss: 0.836920, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.6773\n",
      "[84/1762] D loss: 1.3962, G loss: 0.6605\n",
      "[164/1762] D loss: 0.1710, G loss: 2.0834\n",
      "[244/1762] D loss: 1.6262, G loss: 0.6881\n",
      "[324/1762] D loss: 1.4960, G loss: 0.7271\n",
      "[404/1762] D loss: 0.2092, G loss: 2.0525\n",
      "[484/1762] D loss: 1.4356, G loss: 0.7024\n",
      "[564/1762] D loss: 1.3897, G loss: 0.7344\n",
      "[644/1762] D loss: 0.3819, G loss: 1.5967\n",
      "[724/1762] D loss: 0.2523, G loss: 1.9264\n",
      "[804/1762] D loss: 0.3699, G loss: 1.6803\n",
      "[884/1762] D loss: 1.6206, G loss: 0.7333\n",
      "[964/1762] D loss: 1.4185, G loss: 0.6707\n",
      "[1044/1762] D loss: 0.3057, G loss: 1.6867\n",
      "[1124/1762] D loss: 0.2064, G loss: 2.0001\n",
      "[1204/1762] D loss: 1.5367, G loss: 0.7886\n",
      "[1284/1762] D loss: 0.3499, G loss: 1.6196\n",
      "[1364/1762] D loss: 1.4716, G loss: 0.7465\n",
      "[1444/1762] D loss: 1.3905, G loss: 0.6853\n",
      "[1524/1762] D loss: 1.5543, G loss: 0.7429\n",
      "[1604/1762] D loss: 1.4011, G loss: 0.6849\n",
      "[1684/1762] D loss: 1.4249, G loss: 0.7016\n",
      "[1762/1762] D loss: 1.3828, G loss: 0.6818\n",
      "train error: \n",
      " D loss: 1.376040, G loss: 0.570525, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356824, G loss: 0.579405, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.6947\n",
      "[84/1762] D loss: 1.3901, G loss: 0.6829\n",
      "[164/1762] D loss: 0.2571, G loss: 1.9213\n",
      "[244/1762] D loss: 0.3551, G loss: 1.7142\n",
      "[324/1762] D loss: 0.3819, G loss: 1.6337\n",
      "[404/1762] D loss: 1.3935, G loss: 0.7024\n",
      "[484/1762] D loss: 1.3807, G loss: 0.7056\n",
      "[564/1762] D loss: 0.2112, G loss: 1.9807\n",
      "[644/1762] D loss: 0.5723, G loss: 2.2012\n",
      "[724/1762] D loss: 1.4104, G loss: 0.6233\n",
      "[804/1762] D loss: 1.3939, G loss: 0.6944\n",
      "[884/1762] D loss: 1.3981, G loss: 0.6921\n",
      "[964/1762] D loss: 0.3435, G loss: 1.6651\n",
      "[1044/1762] D loss: 1.4003, G loss: 0.6960\n",
      "[1124/1762] D loss: 1.4055, G loss: 0.7068\n",
      "[1204/1762] D loss: 1.6935, G loss: 0.8101\n",
      "[1284/1762] D loss: 1.4172, G loss: 0.6858\n",
      "[1364/1762] D loss: 1.5282, G loss: 0.6496\n",
      "[1444/1762] D loss: 1.3941, G loss: 0.7043\n",
      "[1524/1762] D loss: 1.4208, G loss: 0.7383\n",
      "[1604/1762] D loss: 0.2673, G loss: 1.8618\n",
      "[1684/1762] D loss: 1.3934, G loss: 0.7028\n",
      "[1762/1762] D loss: 0.0721, G loss: 2.8114\n",
      "train error: \n",
      " D loss: 1.479588, G loss: 0.477836, D accuracy: 49.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.481555, G loss: 0.474563, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1724, G loss: 2.2211\n",
      "[84/1762] D loss: 1.6758, G loss: 0.6160\n",
      "[164/1762] D loss: 0.1731, G loss: 2.1240\n",
      "[244/1762] D loss: 1.3973, G loss: 0.6787\n",
      "[324/1762] D loss: 1.3915, G loss: 0.6904\n",
      "[404/1762] D loss: 1.3927, G loss: 0.6889\n",
      "[484/1762] D loss: 1.3887, G loss: 0.6957\n",
      "[564/1762] D loss: 0.3641, G loss: 1.8401\n",
      "[644/1762] D loss: 0.3549, G loss: 1.7392\n",
      "[724/1762] D loss: 1.3950, G loss: 0.6895\n",
      "[804/1762] D loss: 1.4621, G loss: 0.5964\n",
      "[884/1762] D loss: 1.3854, G loss: 0.7132\n",
      "[964/1762] D loss: 1.3910, G loss: 0.7028\n",
      "[1044/1762] D loss: 0.4593, G loss: 1.6271\n",
      "[1124/1762] D loss: 1.4194, G loss: 0.6813\n",
      "[1204/1762] D loss: 1.4386, G loss: 0.6831\n",
      "[1284/1762] D loss: 0.3039, G loss: 1.9202\n",
      "[1364/1762] D loss: 1.5655, G loss: 0.8553\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.7098\n",
      "[1524/1762] D loss: 0.2987, G loss: 2.2055\n",
      "[1604/1762] D loss: 1.4019, G loss: 0.6791\n",
      "[1684/1762] D loss: 1.3886, G loss: 0.6961\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.7276\n",
      "train error: \n",
      " D loss: 1.340496, G loss: 0.666984, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322375, G loss: 0.673087, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3932, G loss: 0.6858\n",
      "[84/1762] D loss: 1.4061, G loss: 0.7438\n",
      "[164/1762] D loss: 1.4258, G loss: 0.7200\n",
      "[244/1762] D loss: 1.5286, G loss: 0.7356\n",
      "[324/1762] D loss: 1.3882, G loss: 0.6894\n",
      "[404/1762] D loss: 0.2738, G loss: 1.9118\n",
      "[484/1762] D loss: 1.3920, G loss: 0.6920\n",
      "[564/1762] D loss: 0.3697, G loss: 1.8916\n",
      "[644/1762] D loss: 1.3790, G loss: 0.6945\n",
      "[724/1762] D loss: 1.4176, G loss: 0.6980\n",
      "[804/1762] D loss: 1.3951, G loss: 0.7018\n",
      "[884/1762] D loss: 0.4221, G loss: 1.8054\n",
      "[964/1762] D loss: 0.2085, G loss: 1.9577\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.6995\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.6778\n",
      "[1204/1762] D loss: 1.4214, G loss: 0.7245\n",
      "[1284/1762] D loss: 1.4309, G loss: 0.6326\n",
      "[1364/1762] D loss: 1.4930, G loss: 0.6619\n",
      "[1444/1762] D loss: 1.3966, G loss: 0.7071\n",
      "[1524/1762] D loss: 0.2071, G loss: 2.1116\n",
      "[1604/1762] D loss: 0.1669, G loss: 2.2306\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6898\n",
      "[1762/1762] D loss: 1.3987, G loss: 0.6835\n",
      "train error: \n",
      " D loss: 1.431135, G loss: 0.488426, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416385, G loss: 0.493036, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3939, G loss: 0.7078\n",
      "[84/1762] D loss: 1.4171, G loss: 0.6794\n",
      "[164/1762] D loss: 1.3887, G loss: 0.6929\n",
      "[244/1762] D loss: 0.2661, G loss: 1.8988\n",
      "[324/1762] D loss: 1.4178, G loss: 0.6976\n",
      "[404/1762] D loss: 0.2498, G loss: 1.9121\n",
      "[484/1762] D loss: 0.1936, G loss: 2.1458\n",
      "[564/1762] D loss: 1.4944, G loss: 0.6658\n",
      "[644/1762] D loss: 1.4064, G loss: 0.6603\n",
      "[724/1762] D loss: 1.4049, G loss: 0.6671\n",
      "[804/1762] D loss: 1.4441, G loss: 0.6157\n",
      "[884/1762] D loss: 1.3423, G loss: 0.8785\n",
      "[964/1762] D loss: 1.3943, G loss: 0.6902\n",
      "[1044/1762] D loss: 1.4247, G loss: 0.6222\n",
      "[1124/1762] D loss: 0.0952, G loss: 2.6748\n",
      "[1204/1762] D loss: 0.2991, G loss: 1.9748\n",
      "[1284/1762] D loss: 1.4229, G loss: 0.6610\n",
      "[1364/1762] D loss: 1.4066, G loss: 0.6806\n",
      "[1444/1762] D loss: 1.4097, G loss: 0.7035\n",
      "[1524/1762] D loss: 1.4917, G loss: 0.6847\n",
      "[1604/1762] D loss: 1.4121, G loss: 0.7159\n",
      "[1684/1762] D loss: 1.4317, G loss: 0.6623\n",
      "[1762/1762] D loss: 1.5826, G loss: 0.9817\n",
      "train error: \n",
      " D loss: 1.444462, G loss: 0.984076, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.429077, G loss: 0.979184, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4038, G loss: 0.6072\n",
      "[84/1762] D loss: 0.3487, G loss: 1.7228\n",
      "[164/1762] D loss: 1.4424, G loss: 0.5128\n",
      "[244/1762] D loss: 1.4930, G loss: 0.7527\n",
      "[324/1762] D loss: 0.2741, G loss: 1.8736\n",
      "[404/1762] D loss: 1.4133, G loss: 0.6717\n",
      "[484/1762] D loss: 1.3992, G loss: 0.6884\n",
      "[564/1762] D loss: 1.3899, G loss: 0.6889\n",
      "[644/1762] D loss: 1.3849, G loss: 0.6882\n",
      "[724/1762] D loss: 1.4196, G loss: 0.6824\n",
      "[804/1762] D loss: 0.7229, G loss: 2.4223\n",
      "[884/1762] D loss: 1.4231, G loss: 0.6700\n",
      "[964/1762] D loss: 1.4939, G loss: 0.6769\n",
      "[1044/1762] D loss: 0.3062, G loss: 1.8038\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6937\n",
      "[1204/1762] D loss: 1.5870, G loss: 0.4107\n",
      "[1284/1762] D loss: 0.4149, G loss: 1.8248\n",
      "[1364/1762] D loss: 1.4976, G loss: 0.5605\n",
      "[1444/1762] D loss: 1.3934, G loss: 0.6958\n",
      "[1524/1762] D loss: 1.4026, G loss: 0.7538\n",
      "[1604/1762] D loss: 1.3951, G loss: 0.6868\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6960\n",
      "[1762/1762] D loss: 0.3408, G loss: 2.1287\n",
      "train error: \n",
      " D loss: 1.441068, G loss: 0.469116, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.430296, G loss: 0.472004, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3964, G loss: 0.6750\n",
      "[84/1762] D loss: 1.4003, G loss: 0.6954\n",
      "[164/1762] D loss: 1.5279, G loss: 0.7822\n",
      "[244/1762] D loss: 0.0677, G loss: 2.9745\n",
      "[324/1762] D loss: 1.4000, G loss: 0.6864\n",
      "[404/1762] D loss: 1.4084, G loss: 0.7693\n",
      "[484/1762] D loss: 1.4580, G loss: 0.6627\n",
      "[564/1762] D loss: 0.0952, G loss: 2.6577\n",
      "[644/1762] D loss: 1.4399, G loss: 0.6563\n",
      "[724/1762] D loss: 1.4072, G loss: 0.6929\n",
      "[804/1762] D loss: 1.4230, G loss: 0.6911\n",
      "[884/1762] D loss: 0.3859, G loss: 1.9706\n",
      "[964/1762] D loss: 1.3329, G loss: 0.9235\n",
      "[1044/1762] D loss: 1.3995, G loss: 0.6724\n",
      "[1124/1762] D loss: 1.5865, G loss: 0.7462\n",
      "[1204/1762] D loss: 1.4021, G loss: 0.7580\n",
      "[1284/1762] D loss: 1.4044, G loss: 0.7157\n",
      "[1364/1762] D loss: 1.3918, G loss: 0.6860\n",
      "[1444/1762] D loss: 1.4055, G loss: 0.7141\n",
      "[1524/1762] D loss: 0.1321, G loss: 2.4239\n",
      "[1604/1762] D loss: 1.4235, G loss: 0.6895\n",
      "[1684/1762] D loss: 1.4782, G loss: 0.6951\n",
      "[1762/1762] D loss: 0.0852, G loss: 2.7029\n",
      "train error: \n",
      " D loss: 1.410863, G loss: 0.498454, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.405478, G loss: 0.499549, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1995, G loss: 2.1530\n",
      "[84/1762] D loss: 1.4106, G loss: 0.6754\n",
      "[164/1762] D loss: 1.4423, G loss: 0.7063\n",
      "[244/1762] D loss: 1.3942, G loss: 0.7210\n",
      "[324/1762] D loss: 1.3904, G loss: 0.7023\n",
      "[404/1762] D loss: 0.2376, G loss: 2.0345\n",
      "[484/1762] D loss: 1.3747, G loss: 0.7041\n",
      "[564/1762] D loss: 1.3960, G loss: 0.6992\n",
      "[644/1762] D loss: 1.3944, G loss: 0.6783\n",
      "[724/1762] D loss: 1.4422, G loss: 0.8554\n",
      "[804/1762] D loss: 1.4191, G loss: 0.6623\n",
      "[884/1762] D loss: 1.4074, G loss: 0.7009\n",
      "[964/1762] D loss: 0.3568, G loss: 1.7527\n",
      "[1044/1762] D loss: 1.3894, G loss: 0.6725\n",
      "[1124/1762] D loss: 1.4053, G loss: 0.7007\n",
      "[1204/1762] D loss: 0.2668, G loss: 2.0724\n",
      "[1284/1762] D loss: 1.4384, G loss: 0.6751\n",
      "[1364/1762] D loss: 1.6839, G loss: 0.7721\n",
      "[1444/1762] D loss: 1.4317, G loss: 0.7327\n",
      "[1524/1762] D loss: 1.3935, G loss: 0.6928\n",
      "[1604/1762] D loss: 1.6100, G loss: 0.6448\n",
      "[1684/1762] D loss: 1.4082, G loss: 0.6930\n",
      "[1762/1762] D loss: 0.0128, G loss: 4.4027\n",
      "train error: \n",
      " D loss: 1.989060, G loss: 0.197244, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.963662, G loss: 0.203025, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4583, G loss: 0.6406\n",
      "[84/1762] D loss: 0.2164, G loss: 2.0852\n",
      "[164/1762] D loss: 1.5925, G loss: 0.5955\n",
      "[244/1762] D loss: 1.4311, G loss: 0.6985\n",
      "[324/1762] D loss: 1.4414, G loss: 0.7036\n",
      "[404/1762] D loss: 1.3920, G loss: 0.6879\n",
      "[484/1762] D loss: 1.4355, G loss: 0.6144\n",
      "[564/1762] D loss: 0.3930, G loss: 1.7585\n",
      "[644/1762] D loss: 0.2245, G loss: 2.0148\n",
      "[724/1762] D loss: 1.4245, G loss: 0.6999\n",
      "[804/1762] D loss: 0.4204, G loss: 1.7543\n",
      "[884/1762] D loss: 1.4056, G loss: 0.6359\n",
      "[964/1762] D loss: 1.4478, G loss: 0.7058\n",
      "[1044/1762] D loss: 1.4246, G loss: 0.6537\n",
      "[1124/1762] D loss: 0.3739, G loss: 1.7901\n",
      "[1204/1762] D loss: 0.2683, G loss: 1.8838\n",
      "[1284/1762] D loss: 1.3920, G loss: 0.6987\n",
      "[1364/1762] D loss: 1.4013, G loss: 0.7066\n",
      "[1444/1762] D loss: 1.3905, G loss: 0.6957\n",
      "[1524/1762] D loss: 1.4070, G loss: 0.6847\n",
      "[1604/1762] D loss: 0.2321, G loss: 1.9914\n",
      "[1684/1762] D loss: 1.3975, G loss: 0.7806\n",
      "[1762/1762] D loss: 1.3962, G loss: 0.7000\n",
      "train error: \n",
      " D loss: 1.330029, G loss: 0.650576, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307460, G loss: 0.666685, D accuracy: 56.6%, cell accuracy: 99.5%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3288, G loss: 1.8574\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6913\n",
      "[164/1762] D loss: 1.3847, G loss: 0.7021\n",
      "[244/1762] D loss: 1.4093, G loss: 0.7235\n",
      "[324/1762] D loss: 0.2562, G loss: 2.0345\n",
      "[404/1762] D loss: 0.2844, G loss: 1.9235\n",
      "[484/1762] D loss: 0.3402, G loss: 1.8615\n",
      "[564/1762] D loss: 1.6025, G loss: 0.6225\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6989\n",
      "[724/1762] D loss: 0.2570, G loss: 1.9597\n",
      "[804/1762] D loss: 1.4156, G loss: 0.6708\n",
      "[884/1762] D loss: 0.2778, G loss: 1.9977\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6782\n",
      "[1044/1762] D loss: 0.1207, G loss: 2.6913\n",
      "[1124/1762] D loss: 0.3163, G loss: 1.8849\n",
      "[1204/1762] D loss: 0.4630, G loss: 1.7556\n",
      "[1284/1762] D loss: 1.4046, G loss: 0.6822\n",
      "[1364/1762] D loss: 1.6088, G loss: 0.6754\n",
      "[1444/1762] D loss: 1.3353, G loss: 0.8015\n",
      "[1524/1762] D loss: 1.4170, G loss: 0.7665\n",
      "[1604/1762] D loss: 0.0870, G loss: 2.7183\n",
      "[1684/1762] D loss: 1.4529, G loss: 0.6943\n",
      "[1762/1762] D loss: 1.4633, G loss: 0.4444\n",
      "train error: \n",
      " D loss: 1.433660, G loss: 0.473463, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.421647, G loss: 0.475563, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for cls in [TetrisDiscriminator, DiscWithMoreLinear, WiderDisc, DiscWithNoUnevenMaxPools, DiscWithStridedConvs]:\n",
    "        train(run_name=cls.__name__, disc_cls=cls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of these architectures show an improvement from the original. Let's try some more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 18577\n",
      "Predicted label for real data: 0.47213485836982727\n",
      "Predicted label for fake data: 0.4246426224708557\n"
     ]
    }
   ],
   "source": [
    "class DiagnosticModule(nn.Module):\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DiscWithOnlyStride1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, (3, 1), bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, (3, 1), bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, (3, 1), bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, (3, 1), bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(192, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithOnlyStride1().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 16959\n",
      "Predicted label for real data: 0.6477737426757812\n",
      "Predicted label for fake data: 0.537103533744812\n"
     ]
    }
   ],
   "source": [
    "class DiscLocalGlobal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(4, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Flatten(start_dim=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        x = torch.cat((x, y), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        x_glob = self.glob(x)\n",
    "        x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "        x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "check_disc(DiscLocalGlobal().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4203, G loss: 0.9099\n",
      "[84/1762] D loss: 0.8477, G loss: 1.1711\n",
      "[164/1762] D loss: 0.4096, G loss: 2.1617\n",
      "[244/1762] D loss: 1.0265, G loss: 1.8500\n",
      "[324/1762] D loss: 0.3854, G loss: 2.5364\n",
      "[404/1762] D loss: 1.1058, G loss: 0.4992\n",
      "[484/1762] D loss: 1.6507, G loss: 0.7138\n",
      "[564/1762] D loss: 0.9371, G loss: 3.1695\n",
      "[644/1762] D loss: 1.2465, G loss: 0.7443\n",
      "[724/1762] D loss: 0.7628, G loss: 1.0091\n",
      "[804/1762] D loss: 1.1668, G loss: 1.1341\n",
      "[884/1762] D loss: 1.4849, G loss: 1.3587\n",
      "[964/1762] D loss: 1.4227, G loss: 1.2098\n",
      "[1044/1762] D loss: 0.8404, G loss: 1.0708\n",
      "[1124/1762] D loss: 1.4440, G loss: 0.7386\n",
      "[1204/1762] D loss: 1.0633, G loss: 0.8057\n",
      "[1284/1762] D loss: 1.3203, G loss: 0.6451\n",
      "[1364/1762] D loss: 1.3255, G loss: 1.0049\n",
      "[1444/1762] D loss: 1.1209, G loss: 0.9180\n",
      "[1524/1762] D loss: 1.9330, G loss: 1.4650\n",
      "[1604/1762] D loss: 1.3262, G loss: 1.1155\n",
      "[1684/1762] D loss: 1.3644, G loss: 0.8625\n",
      "[1762/1762] D loss: 1.3943, G loss: 0.3019\n",
      "train error: \n",
      " D loss: 1.417270, G loss: 0.631111, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416318, G loss: 0.662441, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5794, G loss: 1.0973\n",
      "[84/1762] D loss: 1.3946, G loss: 0.6149\n",
      "[164/1762] D loss: 0.9375, G loss: 1.7577\n",
      "[244/1762] D loss: 1.2986, G loss: 1.0495\n",
      "[324/1762] D loss: 1.4168, G loss: 1.4239\n",
      "[404/1762] D loss: 1.2530, G loss: 1.5234\n",
      "[484/1762] D loss: 1.3019, G loss: 1.1519\n",
      "[564/1762] D loss: 1.4027, G loss: 1.4513\n",
      "[644/1762] D loss: 1.4721, G loss: 0.3560\n",
      "[724/1762] D loss: 1.0344, G loss: 0.2645\n",
      "[804/1762] D loss: 0.6333, G loss: 1.7263\n",
      "[884/1762] D loss: 1.4278, G loss: 0.5592\n",
      "[964/1762] D loss: 1.5676, G loss: 1.2048\n",
      "[1044/1762] D loss: 0.4149, G loss: 1.9324\n",
      "[1124/1762] D loss: 1.4453, G loss: 1.9409\n",
      "[1204/1762] D loss: 1.8618, G loss: 0.1770\n",
      "[1284/1762] D loss: 1.4003, G loss: 2.0842\n",
      "[1364/1762] D loss: 1.2494, G loss: 1.7313\n",
      "[1444/1762] D loss: 0.9889, G loss: 1.8188\n",
      "[1524/1762] D loss: 0.8709, G loss: 2.3088\n",
      "[1604/1762] D loss: 0.3763, G loss: 2.0153\n",
      "[1684/1762] D loss: 0.2859, G loss: 2.2134\n",
      "[1762/1762] D loss: 1.5739, G loss: 1.7261\n",
      "train error: \n",
      " D loss: 1.635560, G loss: 1.467847, D accuracy: 50.0%, cell accuracy: 99.2%, board accuracy: 63.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.650250, G loss: 1.490885, D accuracy: 50.0%, cell accuracy: 99.2%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2295, G loss: 2.6483\n",
      "[84/1762] D loss: 1.1690, G loss: 2.4730\n",
      "[164/1762] D loss: 1.5142, G loss: 0.8195\n",
      "[244/1762] D loss: 0.4700, G loss: 2.3296\n",
      "[324/1762] D loss: 0.6197, G loss: 1.7811\n",
      "[404/1762] D loss: 1.1275, G loss: 1.0005\n",
      "[484/1762] D loss: 1.9695, G loss: 1.3266\n",
      "[564/1762] D loss: 0.1452, G loss: 2.5794\n",
      "[644/1762] D loss: 1.2067, G loss: 1.3004\n",
      "[724/1762] D loss: 1.2253, G loss: 0.7444\n",
      "[804/1762] D loss: 1.4618, G loss: 0.8119\n",
      "[884/1762] D loss: 1.7809, G loss: 0.5872\n",
      "[964/1762] D loss: 0.9153, G loss: 1.5763\n",
      "[1044/1762] D loss: 1.0947, G loss: 1.5130\n",
      "[1124/1762] D loss: 1.5280, G loss: 0.4161\n",
      "[1204/1762] D loss: 1.4425, G loss: 0.6330\n",
      "[1284/1762] D loss: 1.5118, G loss: 0.5038\n",
      "[1364/1762] D loss: 1.3660, G loss: 0.8577\n",
      "[1444/1762] D loss: 1.3780, G loss: 0.6919\n",
      "[1524/1762] D loss: 1.4340, G loss: 0.8942\n",
      "[1604/1762] D loss: 1.2770, G loss: 1.1712\n",
      "[1684/1762] D loss: 1.4194, G loss: 0.6250\n",
      "[1762/1762] D loss: 1.3727, G loss: 0.7268\n",
      "train error: \n",
      " D loss: 1.596477, G loss: 0.693863, D accuracy: 46.9%, cell accuracy: 99.7%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.662504, G loss: 0.678161, D accuracy: 46.4%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3659, G loss: 0.7036\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6710\n",
      "[164/1762] D loss: 1.3677, G loss: 0.9605\n",
      "[244/1762] D loss: 0.1220, G loss: 2.4497\n",
      "[324/1762] D loss: 1.3823, G loss: 0.7517\n",
      "[404/1762] D loss: 1.5539, G loss: 1.2913\n",
      "[484/1762] D loss: 1.4838, G loss: 0.8129\n",
      "[564/1762] D loss: 1.2466, G loss: 1.1516\n",
      "[644/1762] D loss: 0.5171, G loss: 2.1987\n",
      "[724/1762] D loss: 0.0543, G loss: 3.5839\n",
      "[804/1762] D loss: 1.3342, G loss: 3.7954\n",
      "[884/1762] D loss: 1.7548, G loss: 1.9777\n",
      "[964/1762] D loss: 1.6102, G loss: 1.2377\n",
      "[1044/1762] D loss: 1.3399, G loss: 0.7804\n",
      "[1124/1762] D loss: 1.2018, G loss: 0.8289\n",
      "[1204/1762] D loss: 1.2943, G loss: 0.9531\n",
      "[1284/1762] D loss: 1.1002, G loss: 2.8741\n",
      "[1364/1762] D loss: 0.2750, G loss: 2.5150\n",
      "[1444/1762] D loss: 0.1002, G loss: 3.2624\n",
      "[1524/1762] D loss: 1.3132, G loss: 0.8941\n",
      "[1604/1762] D loss: 1.0356, G loss: 1.2455\n",
      "[1684/1762] D loss: 1.2743, G loss: 0.9214\n",
      "[1762/1762] D loss: 0.9682, G loss: 1.7092\n",
      "train error: \n",
      " D loss: 1.692923, G loss: 1.354749, D accuracy: 49.4%, cell accuracy: 99.2%, board accuracy: 21.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.748072, G loss: 1.355606, D accuracy: 49.5%, cell accuracy: 99.2%, board accuracy: 22.7% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0721, G loss: 2.0796\n",
      "[84/1762] D loss: 1.2593, G loss: 0.9932\n",
      "[164/1762] D loss: 0.2081, G loss: 3.0703\n",
      "[244/1762] D loss: 1.6557, G loss: 0.8582\n",
      "[324/1762] D loss: 1.0807, G loss: 0.4256\n",
      "[404/1762] D loss: 0.8217, G loss: 1.5219\n",
      "[484/1762] D loss: 0.4794, G loss: 1.9109\n",
      "[564/1762] D loss: 0.0968, G loss: 2.9975\n",
      "[644/1762] D loss: 1.4915, G loss: 0.7047\n",
      "[724/1762] D loss: 0.1466, G loss: 2.9891\n",
      "[804/1762] D loss: 0.3815, G loss: 3.1580\n",
      "[884/1762] D loss: 0.0977, G loss: 3.4574\n",
      "[964/1762] D loss: 0.2795, G loss: 2.8965\n",
      "[1044/1762] D loss: 0.0871, G loss: 2.9884\n",
      "[1124/1762] D loss: 0.4602, G loss: 2.6646\n",
      "[1204/1762] D loss: 1.4032, G loss: 0.8157\n",
      "[1284/1762] D loss: 1.3847, G loss: 0.6558\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6838\n",
      "[1444/1762] D loss: 1.4236, G loss: 0.6933\n",
      "[1524/1762] D loss: 0.0937, G loss: 2.9062\n",
      "[1604/1762] D loss: 1.5329, G loss: 1.6280\n",
      "[1684/1762] D loss: 1.1588, G loss: 1.0295\n",
      "[1762/1762] D loss: 1.6104, G loss: 2.7969\n",
      "train error: \n",
      " D loss: 1.769071, G loss: 1.143399, D accuracy: 49.8%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.836768, G loss: 1.131008, D accuracy: 49.8%, cell accuracy: 99.6%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4407, G loss: 0.9312\n",
      "[84/1762] D loss: 1.3859, G loss: 0.6493\n",
      "[164/1762] D loss: 1.4292, G loss: 1.0605\n",
      "[244/1762] D loss: 0.4719, G loss: 2.8411\n",
      "[324/1762] D loss: 0.0341, G loss: 4.0136\n",
      "[404/1762] D loss: 0.1120, G loss: 3.7831\n",
      "[484/1762] D loss: 2.1303, G loss: 1.8277\n",
      "[564/1762] D loss: 1.3967, G loss: 0.6926\n",
      "[644/1762] D loss: 1.3829, G loss: 0.6944\n",
      "[724/1762] D loss: 1.2884, G loss: 0.7510\n",
      "[804/1762] D loss: 1.3916, G loss: 0.6696\n",
      "[884/1762] D loss: 1.3983, G loss: 0.7585\n",
      "[964/1762] D loss: 0.9804, G loss: 1.4054\n",
      "[1044/1762] D loss: 1.4050, G loss: 0.7629\n",
      "[1124/1762] D loss: 1.4529, G loss: 0.6348\n",
      "[1204/1762] D loss: 0.0476, G loss: 3.7497\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6429\n",
      "[1364/1762] D loss: 1.0251, G loss: 3.6402\n",
      "[1444/1762] D loss: 0.2155, G loss: 4.2451\n",
      "[1524/1762] D loss: 0.0202, G loss: 4.9703\n",
      "[1604/1762] D loss: 0.0419, G loss: 4.6275\n",
      "[1684/1762] D loss: 0.0321, G loss: 4.1724\n",
      "[1762/1762] D loss: 0.0071, G loss: 6.1381\n",
      "train error: \n",
      " D loss: 1.633755, G loss: 3.685535, D accuracy: 51.2%, cell accuracy: 95.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.618154, G loss: 3.662320, D accuracy: 51.4%, cell accuracy: 95.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0432, G loss: 4.0901\n",
      "[84/1762] D loss: 0.0337, G loss: 4.6554\n",
      "[164/1762] D loss: 8.0094, G loss: 4.5705\n",
      "[244/1762] D loss: 0.3206, G loss: 1.9536\n",
      "[324/1762] D loss: 1.3212, G loss: 0.8956\n",
      "[404/1762] D loss: 1.3772, G loss: 0.8385\n",
      "[484/1762] D loss: 1.4661, G loss: 0.6510\n",
      "[564/1762] D loss: 1.2486, G loss: 0.9553\n",
      "[644/1762] D loss: 1.4941, G loss: 0.7028\n",
      "[724/1762] D loss: 1.4235, G loss: 0.6046\n",
      "[804/1762] D loss: 1.5230, G loss: 0.3263\n",
      "[884/1762] D loss: 0.3588, G loss: 1.8305\n",
      "[964/1762] D loss: 0.1974, G loss: 2.0317\n",
      "[1044/1762] D loss: 0.2137, G loss: 2.1100\n",
      "[1124/1762] D loss: 0.4901, G loss: 2.7361\n",
      "[1204/1762] D loss: 0.0427, G loss: 3.4405\n",
      "[1284/1762] D loss: 0.0417, G loss: 3.9963\n",
      "[1364/1762] D loss: 0.0376, G loss: 3.7293\n",
      "[1444/1762] D loss: 0.0073, G loss: 5.1495\n",
      "[1524/1762] D loss: 0.0266, G loss: 4.3804\n",
      "[1604/1762] D loss: 0.0111, G loss: 5.1505\n",
      "[1684/1762] D loss: 0.0153, G loss: 4.5023\n",
      "[1762/1762] D loss: 0.0152, G loss: 6.3815\n",
      "train error: \n",
      " D loss: 0.136505, G loss: 3.399942, D accuracy: 99.5%, cell accuracy: 92.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.127547, G loss: 3.402567, D accuracy: 99.5%, cell accuracy: 92.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0132, G loss: 5.0446\n",
      "[84/1762] D loss: 0.0061, G loss: 6.0765\n",
      "[164/1762] D loss: 0.0035, G loss: 5.8065\n",
      "[244/1762] D loss: 1.7298, G loss: 1.1633\n",
      "[324/1762] D loss: 1.4541, G loss: 0.6854\n",
      "[404/1762] D loss: 1.5395, G loss: 0.6625\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7072\n",
      "[564/1762] D loss: 1.3759, G loss: 0.7008\n",
      "[644/1762] D loss: 1.4259, G loss: 0.6920\n",
      "[724/1762] D loss: 1.0403, G loss: 1.8263\n",
      "[804/1762] D loss: 1.0327, G loss: 1.1752\n",
      "[884/1762] D loss: 0.1818, G loss: 2.2347\n",
      "[964/1762] D loss: 1.6534, G loss: 1.1705\n",
      "[1044/1762] D loss: 1.4047, G loss: 0.6373\n",
      "[1124/1762] D loss: 1.2759, G loss: 1.2666\n",
      "[1204/1762] D loss: 0.8797, G loss: 0.9263\n",
      "[1284/1762] D loss: 1.4905, G loss: 1.0723\n",
      "[1364/1762] D loss: 0.4989, G loss: 2.2678\n",
      "[1444/1762] D loss: 2.6527, G loss: 0.1213\n",
      "[1524/1762] D loss: 1.1484, G loss: 1.1004\n",
      "[1604/1762] D loss: 0.1495, G loss: 2.4010\n",
      "[1684/1762] D loss: 0.0531, G loss: 3.5484\n",
      "[1762/1762] D loss: 0.2723, G loss: 4.2979\n",
      "train error: \n",
      " D loss: 1.907218, G loss: 1.711611, D accuracy: 49.7%, cell accuracy: 98.6%, board accuracy: 43.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.945847, G loss: 1.773117, D accuracy: 49.4%, cell accuracy: 98.3%, board accuracy: 38.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2990, G loss: 2.8277\n",
      "[84/1762] D loss: 0.6374, G loss: 2.8279\n",
      "[164/1762] D loss: 1.5753, G loss: 0.1814\n",
      "[244/1762] D loss: 0.6042, G loss: 1.9501\n",
      "[324/1762] D loss: 0.9982, G loss: 2.3143\n",
      "[404/1762] D loss: 1.3680, G loss: 0.5989\n",
      "[484/1762] D loss: 1.3378, G loss: 1.1683\n",
      "[564/1762] D loss: 0.0786, G loss: 2.8991\n",
      "[644/1762] D loss: 1.0374, G loss: 1.4194\n",
      "[724/1762] D loss: 0.8515, G loss: 1.1152\n",
      "[804/1762] D loss: 0.5942, G loss: 2.8944\n",
      "[884/1762] D loss: 1.4142, G loss: 0.6998\n",
      "[964/1762] D loss: 1.3781, G loss: 0.8146\n",
      "[1044/1762] D loss: 0.2274, G loss: 2.4429\n",
      "[1124/1762] D loss: 1.3983, G loss: 0.8723\n",
      "[1204/1762] D loss: 2.0776, G loss: 0.7129\n",
      "[1284/1762] D loss: 0.3369, G loss: 2.3268\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7406\n",
      "[1444/1762] D loss: 1.4331, G loss: 0.8249\n",
      "[1524/1762] D loss: 0.6953, G loss: 2.3261\n",
      "[1604/1762] D loss: 0.8169, G loss: 1.9791\n",
      "[1684/1762] D loss: 0.0642, G loss: 5.3565\n",
      "[1762/1762] D loss: 0.0082, G loss: 5.5063\n",
      "train error: \n",
      " D loss: 4.318372, G loss: 4.287097, D accuracy: 49.3%, cell accuracy: 98.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.292121, G loss: 4.271189, D accuracy: 49.4%, cell accuracy: 98.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0238, G loss: 5.0045\n",
      "[84/1762] D loss: 0.0155, G loss: 5.6167\n",
      "[164/1762] D loss: 0.0071, G loss: 6.2363\n",
      "[244/1762] D loss: 0.0040, G loss: 6.4706\n",
      "[324/1762] D loss: 0.0095, G loss: 5.3583\n",
      "[404/1762] D loss: 0.0051, G loss: 6.8958\n",
      "[484/1762] D loss: 0.0075, G loss: 5.7282\n",
      "[564/1762] D loss: 0.0140, G loss: 5.6538\n",
      "[644/1762] D loss: 0.0053, G loss: 6.1830\n",
      "[724/1762] D loss: 0.0108, G loss: 5.0681\n",
      "[804/1762] D loss: 0.0028, G loss: 6.3061\n",
      "[884/1762] D loss: 0.0174, G loss: 5.0053\n",
      "[964/1762] D loss: 0.0077, G loss: 5.3192\n",
      "[1044/1762] D loss: 0.0102, G loss: 5.5622\n",
      "[1124/1762] D loss: 0.0046, G loss: 5.9179\n",
      "[1204/1762] D loss: 0.0094, G loss: 5.2065\n",
      "[1284/1762] D loss: 0.0007, G loss: 7.8605\n",
      "[1364/1762] D loss: 0.0010, G loss: 7.6565\n",
      "[1444/1762] D loss: 0.0030, G loss: 6.4002\n",
      "[1524/1762] D loss: 0.0350, G loss: 5.5373\n",
      "[1604/1762] D loss: 0.0016, G loss: 8.2466\n",
      "[1684/1762] D loss: 0.0166, G loss: 5.5761\n",
      "[1762/1762] D loss: 0.0022, G loss: 6.3780\n",
      "train error: \n",
      " D loss: 4.923960, G loss: 2.911006, D accuracy: 45.8%, cell accuracy: 98.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.948440, G loss: 3.006166, D accuracy: 45.6%, cell accuracy: 98.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0046, G loss: 6.6673\n",
      "[84/1762] D loss: 0.0007, G loss: 7.7004\n",
      "[164/1762] D loss: 0.0019, G loss: 6.7672\n",
      "[244/1762] D loss: 0.0036, G loss: 7.6037\n",
      "[324/1762] D loss: 0.0029, G loss: 6.5937\n",
      "[404/1762] D loss: 0.0035, G loss: 5.8147\n",
      "[484/1762] D loss: 0.0013, G loss: 7.1914\n",
      "[564/1762] D loss: 0.0074, G loss: 5.9626\n",
      "[644/1762] D loss: 0.0017, G loss: 6.9899\n",
      "[724/1762] D loss: 0.0013, G loss: 8.0302\n",
      "[804/1762] D loss: 0.0030, G loss: 8.4667\n",
      "[884/1762] D loss: 0.0024, G loss: 6.3608\n",
      "[964/1762] D loss: 0.0024, G loss: 6.3074\n",
      "[1044/1762] D loss: 0.0032, G loss: 6.4667\n",
      "[1124/1762] D loss: 0.0017, G loss: 8.6666\n",
      "[1204/1762] D loss: 0.0135, G loss: 5.2483\n",
      "[1284/1762] D loss: 0.0044, G loss: 6.5882\n",
      "[1364/1762] D loss: 0.0011, G loss: 7.8926\n",
      "[1444/1762] D loss: 0.0049, G loss: 7.6336\n",
      "[1524/1762] D loss: 0.0026, G loss: 7.6678\n",
      "[1604/1762] D loss: 0.0010, G loss: 8.4076\n",
      "[1684/1762] D loss: 0.0003, G loss: 10.0787\n",
      "[1762/1762] D loss: 0.0112, G loss: 5.3098\n",
      "train error: \n",
      " D loss: 5.358052, G loss: 4.267445, D accuracy: 48.9%, cell accuracy: 99.1%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 5.503256, G loss: 4.373466, D accuracy: 49.1%, cell accuracy: 99.0%, board accuracy: 13.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 9.7685\n",
      "[84/1762] D loss: 0.0006, G loss: 7.7158\n",
      "[164/1762] D loss: 0.0184, G loss: 5.1625\n",
      "[244/1762] D loss: 4.8603, G loss: 2.0254\n",
      "[324/1762] D loss: 5.2271, G loss: 2.4578\n",
      "[404/1762] D loss: 2.1608, G loss: 3.0637\n",
      "[484/1762] D loss: 1.1153, G loss: 0.5421\n",
      "[564/1762] D loss: 2.1590, G loss: 5.8497\n",
      "[644/1762] D loss: 0.7954, G loss: 1.9717\n",
      "[724/1762] D loss: 0.2522, G loss: 1.7225\n",
      "[804/1762] D loss: 1.4860, G loss: 0.3183\n",
      "[884/1762] D loss: 1.2061, G loss: 0.5078\n",
      "[964/1762] D loss: 1.6059, G loss: 0.5887\n",
      "[1044/1762] D loss: 0.1076, G loss: 2.6353\n",
      "[1124/1762] D loss: 1.4065, G loss: 0.5789\n",
      "[1204/1762] D loss: 1.3263, G loss: 0.7134\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.6882\n",
      "[1364/1762] D loss: 0.0332, G loss: 3.9475\n",
      "[1444/1762] D loss: 1.1537, G loss: 2.1598\n",
      "[1524/1762] D loss: 1.6782, G loss: 0.5624\n",
      "[1604/1762] D loss: 1.3829, G loss: 0.6880\n",
      "[1684/1762] D loss: 0.0288, G loss: 4.2309\n",
      "[1762/1762] D loss: 1.3804, G loss: 0.6993\n",
      "train error: \n",
      " D loss: 2.143111, G loss: 1.038518, D accuracy: 45.8%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.308389, G loss: 1.005910, D accuracy: 44.7%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3713, G loss: 0.9307\n",
      "[84/1762] D loss: 1.2106, G loss: 1.1960\n",
      "[164/1762] D loss: 1.4048, G loss: 0.6221\n",
      "[244/1762] D loss: 1.4094, G loss: 0.6322\n",
      "[324/1762] D loss: 1.3460, G loss: 1.6051\n",
      "[404/1762] D loss: 1.4028, G loss: 0.5741\n",
      "[484/1762] D loss: 1.4023, G loss: 0.5857\n",
      "[564/1762] D loss: 1.3852, G loss: 0.6495\n",
      "[644/1762] D loss: 1.1829, G loss: 2.1627\n",
      "[724/1762] D loss: 0.6062, G loss: 2.2303\n",
      "[804/1762] D loss: 1.6628, G loss: 0.4324\n",
      "[884/1762] D loss: 1.3070, G loss: 1.5917\n",
      "[964/1762] D loss: 1.3852, G loss: 0.6604\n",
      "[1044/1762] D loss: 1.4121, G loss: 0.5864\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.6104\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.6780\n",
      "[1284/1762] D loss: 0.0101, G loss: 6.0280\n",
      "[1364/1762] D loss: 1.3965, G loss: 0.6022\n",
      "[1444/1762] D loss: 1.3838, G loss: 0.6867\n",
      "[1524/1762] D loss: 0.0251, G loss: 4.4104\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.6182\n",
      "[1684/1762] D loss: 1.4251, G loss: 0.5759\n",
      "[1762/1762] D loss: 1.3930, G loss: 0.6261\n",
      "train error: \n",
      " D loss: 1.802403, G loss: 1.097957, D accuracy: 48.8%, cell accuracy: 99.6%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.867501, G loss: 1.098407, D accuracy: 47.8%, cell accuracy: 99.4%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.6442\n",
      "[84/1762] D loss: 0.0348, G loss: 3.9021\n",
      "[164/1762] D loss: 0.0369, G loss: 4.0134\n",
      "[244/1762] D loss: 1.3742, G loss: 0.7951\n",
      "[324/1762] D loss: 1.4023, G loss: 0.5958\n",
      "[404/1762] D loss: 1.3902, G loss: 0.6329\n",
      "[484/1762] D loss: 1.4030, G loss: 0.6139\n",
      "[564/1762] D loss: 1.3919, G loss: 0.6331\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6671\n",
      "[724/1762] D loss: 1.0489, G loss: 2.6106\n",
      "[804/1762] D loss: 1.4286, G loss: 0.5394\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6440\n",
      "[964/1762] D loss: 0.0084, G loss: 5.8460\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.6442\n",
      "[1124/1762] D loss: 1.3848, G loss: 0.6792\n",
      "[1204/1762] D loss: 0.0077, G loss: 5.8288\n",
      "[1284/1762] D loss: 1.3961, G loss: 0.6574\n",
      "[1364/1762] D loss: 1.3822, G loss: 0.6678\n",
      "[1444/1762] D loss: 0.5108, G loss: 4.5977\n",
      "[1524/1762] D loss: 0.6933, G loss: 3.4392\n",
      "[1604/1762] D loss: 0.0315, G loss: 5.2582\n",
      "[1684/1762] D loss: 0.0942, G loss: 3.5121\n",
      "[1762/1762] D loss: 0.0255, G loss: 4.0395\n",
      "train error: \n",
      " D loss: 1.642067, G loss: 0.746011, D accuracy: 48.9%, cell accuracy: 99.7%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.722166, G loss: 0.734737, D accuracy: 48.0%, cell accuracy: 99.7%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0370, G loss: 4.0713\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6775\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6784\n",
      "[244/1762] D loss: 0.0088, G loss: 6.2493\n",
      "[324/1762] D loss: 0.6450, G loss: 3.8587\n",
      "[404/1762] D loss: 1.3776, G loss: 0.5626\n",
      "[484/1762] D loss: 1.3586, G loss: 0.6662\n",
      "[564/1762] D loss: 0.1176, G loss: 3.3186\n",
      "[644/1762] D loss: 1.0479, G loss: 3.7832\n",
      "[724/1762] D loss: 1.4008, G loss: 0.6260\n",
      "[804/1762] D loss: 1.3659, G loss: 0.7137\n",
      "[884/1762] D loss: 0.6535, G loss: 3.0518\n",
      "[964/1762] D loss: 0.0077, G loss: 6.8412\n",
      "[1044/1762] D loss: 1.4192, G loss: 0.5693\n",
      "[1124/1762] D loss: 0.0038, G loss: 7.2106\n",
      "[1204/1762] D loss: 0.0159, G loss: 5.2348\n",
      "[1284/1762] D loss: 1.6470, G loss: 0.5997\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.7387\n",
      "[1444/1762] D loss: 1.2797, G loss: 2.1259\n",
      "[1524/1762] D loss: 1.3646, G loss: 0.7429\n",
      "[1604/1762] D loss: 0.6686, G loss: 6.0846\n",
      "[1684/1762] D loss: 0.0133, G loss: 4.7944\n",
      "[1762/1762] D loss: 1.4519, G loss: 0.5683\n",
      "train error: \n",
      " D loss: 1.550502, G loss: 0.669963, D accuracy: 48.5%, cell accuracy: 99.4%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.502529, G loss: 0.697210, D accuracy: 48.2%, cell accuracy: 99.2%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3830, G loss: 0.6055\n",
      "[84/1762] D loss: 0.0546, G loss: 3.3070\n",
      "[164/1762] D loss: 1.3910, G loss: 0.6400\n",
      "[244/1762] D loss: 0.0084, G loss: 6.4728\n",
      "[324/1762] D loss: 1.4078, G loss: 0.5730\n",
      "[404/1762] D loss: 1.4282, G loss: 0.5261\n",
      "[484/1762] D loss: 0.4928, G loss: 5.1372\n",
      "[564/1762] D loss: 0.6418, G loss: 6.4359\n",
      "[644/1762] D loss: 1.4042, G loss: 0.5795\n",
      "[724/1762] D loss: 0.0097, G loss: 6.4141\n",
      "[804/1762] D loss: 0.0132, G loss: 5.0473\n",
      "[884/1762] D loss: 0.4224, G loss: 4.6863\n",
      "[964/1762] D loss: 0.1778, G loss: 4.8072\n",
      "[1044/1762] D loss: 1.0401, G loss: 0.5308\n",
      "[1124/1762] D loss: 0.5248, G loss: 3.0424\n",
      "[1204/1762] D loss: 1.9967, G loss: 0.3895\n",
      "[1284/1762] D loss: 0.0658, G loss: 3.0489\n",
      "[1364/1762] D loss: 1.4562, G loss: 0.7163\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6749\n",
      "[1524/1762] D loss: 1.3889, G loss: 0.6307\n",
      "[1604/1762] D loss: 0.0788, G loss: 3.2027\n",
      "[1684/1762] D loss: 0.0303, G loss: 4.1266\n",
      "[1762/1762] D loss: 1.5566, G loss: 0.6926\n",
      "train error: \n",
      " D loss: 1.606218, G loss: 1.171252, D accuracy: 49.7%, cell accuracy: 99.5%, board accuracy: 84.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.583268, G loss: 1.191006, D accuracy: 50.1%, cell accuracy: 99.5%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3708, G loss: 0.6758\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6183\n",
      "[164/1762] D loss: 0.0037, G loss: 6.4747\n",
      "[244/1762] D loss: 1.3913, G loss: 0.6216\n",
      "[324/1762] D loss: 1.3960, G loss: 0.6062\n",
      "[404/1762] D loss: 1.3932, G loss: 0.6438\n",
      "[484/1762] D loss: 0.0961, G loss: 2.8327\n",
      "[564/1762] D loss: 1.3647, G loss: 0.9768\n",
      "[644/1762] D loss: 1.2558, G loss: 1.4593\n",
      "[724/1762] D loss: 0.0083, G loss: 5.9563\n",
      "[804/1762] D loss: 1.3949, G loss: 0.6130\n",
      "[884/1762] D loss: 1.4007, G loss: 0.6514\n",
      "[964/1762] D loss: 1.1186, G loss: 2.1681\n",
      "[1044/1762] D loss: 0.0067, G loss: 6.1930\n",
      "[1124/1762] D loss: 1.3985, G loss: 0.6037\n",
      "[1204/1762] D loss: 1.3809, G loss: 0.6262\n",
      "[1284/1762] D loss: 0.0663, G loss: 3.1465\n",
      "[1364/1762] D loss: 1.3879, G loss: 0.6621\n",
      "[1444/1762] D loss: 0.1360, G loss: 3.1536\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.6393\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.7127\n",
      "[1684/1762] D loss: 1.3942, G loss: 0.6545\n",
      "[1762/1762] D loss: 0.9127, G loss: 6.8719\n",
      "train error: \n",
      " D loss: 2.936982, G loss: 2.091636, D accuracy: 48.6%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.052639, G loss: 2.040124, D accuracy: 48.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3999, G loss: 0.6016\n",
      "[84/1762] D loss: 1.3921, G loss: 0.6361\n",
      "[164/1762] D loss: 1.3781, G loss: 0.6967\n",
      "[244/1762] D loss: 1.4804, G loss: 0.4727\n",
      "[324/1762] D loss: 1.3890, G loss: 0.6422\n",
      "[404/1762] D loss: 0.4612, G loss: 4.0859\n",
      "[484/1762] D loss: 0.4920, G loss: 5.2809\n",
      "[564/1762] D loss: 1.8384, G loss: 0.4637\n",
      "[644/1762] D loss: 1.4928, G loss: 0.4957\n",
      "[724/1762] D loss: 1.4094, G loss: 0.6260\n",
      "[804/1762] D loss: 0.0187, G loss: 4.3452\n",
      "[884/1762] D loss: 1.3852, G loss: 0.6711\n",
      "[964/1762] D loss: 1.3926, G loss: 0.6425\n",
      "[1044/1762] D loss: 1.3856, G loss: 0.7096\n",
      "[1124/1762] D loss: 0.2280, G loss: 2.8646\n",
      "[1204/1762] D loss: 1.3901, G loss: 0.6353\n",
      "[1284/1762] D loss: 0.0030, G loss: 6.9290\n",
      "[1364/1762] D loss: 1.3826, G loss: 0.6596\n",
      "[1444/1762] D loss: 0.0054, G loss: 6.5355\n",
      "[1524/1762] D loss: 1.3708, G loss: 0.7646\n",
      "[1604/1762] D loss: 0.0029, G loss: 6.3407\n",
      "[1684/1762] D loss: 1.3842, G loss: 0.6557\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.6489\n",
      "train error: \n",
      " D loss: 2.152257, G loss: 1.221539, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.295717, G loss: 1.262976, D accuracy: 48.8%, cell accuracy: 99.7%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0035, G loss: 6.3877\n",
      "[84/1762] D loss: 1.3819, G loss: 0.7008\n",
      "[164/1762] D loss: 1.3774, G loss: 0.7214\n",
      "[244/1762] D loss: 1.3120, G loss: 0.7398\n",
      "[324/1762] D loss: 1.4038, G loss: 0.7069\n",
      "[404/1762] D loss: 1.3903, G loss: 0.6544\n",
      "[484/1762] D loss: 1.3873, G loss: 0.6611\n",
      "[564/1762] D loss: 1.3833, G loss: 0.6923\n",
      "[644/1762] D loss: 0.0074, G loss: 6.2379\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6951\n",
      "[804/1762] D loss: 1.3713, G loss: 0.7001\n",
      "[884/1762] D loss: 1.4058, G loss: 0.6225\n",
      "[964/1762] D loss: 0.0073, G loss: 6.5000\n",
      "[1044/1762] D loss: 0.1519, G loss: 4.6296\n",
      "[1124/1762] D loss: 0.0408, G loss: 5.6142\n",
      "[1204/1762] D loss: 0.7169, G loss: 7.4184\n",
      "[1284/1762] D loss: 0.0551, G loss: 4.7544\n",
      "[1364/1762] D loss: 0.2075, G loss: 3.2720\n",
      "[1444/1762] D loss: 1.4284, G loss: 0.5997\n",
      "[1524/1762] D loss: 1.5566, G loss: 0.5331\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6690\n",
      "[1684/1762] D loss: 1.4027, G loss: 0.6095\n",
      "[1762/1762] D loss: 1.4018, G loss: 0.5834\n",
      "train error: \n",
      " D loss: 1.814042, G loss: 0.671563, D accuracy: 49.1%, cell accuracy: 99.5%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.842394, G loss: 0.731531, D accuracy: 50.5%, cell accuracy: 99.3%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1016, G loss: 1.9696\n",
      "[84/1762] D loss: 0.0086, G loss: 5.1082\n",
      "[164/1762] D loss: 1.3937, G loss: 0.6574\n",
      "[244/1762] D loss: 1.4622, G loss: 0.5118\n",
      "[324/1762] D loss: 0.0092, G loss: 5.0746\n",
      "[404/1762] D loss: 0.8668, G loss: 1.7819\n",
      "[484/1762] D loss: 1.3784, G loss: 0.6949\n",
      "[564/1762] D loss: 1.3901, G loss: 0.6624\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6761\n",
      "[724/1762] D loss: 0.0322, G loss: 3.7221\n",
      "[804/1762] D loss: 1.3833, G loss: 0.7001\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6898\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6810\n",
      "[1044/1762] D loss: 0.0204, G loss: 4.3308\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.6496\n",
      "[1204/1762] D loss: 1.3933, G loss: 0.6249\n",
      "[1284/1762] D loss: 0.9836, G loss: 5.7019\n",
      "[1364/1762] D loss: 1.3923, G loss: 0.6392\n",
      "[1444/1762] D loss: 1.3955, G loss: 0.6454\n",
      "[1524/1762] D loss: 1.4013, G loss: 0.6090\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6746\n",
      "[1684/1762] D loss: 0.0096, G loss: 7.7200\n",
      "[1762/1762] D loss: 0.0372, G loss: 3.5987\n",
      "train error: \n",
      " D loss: 2.092804, G loss: 1.475358, D accuracy: 49.1%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.193744, G loss: 1.533097, D accuracy: 48.6%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3974, G loss: 0.6087\n",
      "[84/1762] D loss: 1.3925, G loss: 0.6211\n",
      "[164/1762] D loss: 1.1681, G loss: 2.8369\n",
      "[244/1762] D loss: 0.0089, G loss: 6.6754\n",
      "[324/1762] D loss: 1.4078, G loss: 0.5782\n",
      "[404/1762] D loss: 1.5787, G loss: 0.5979\n",
      "[484/1762] D loss: 1.3780, G loss: 0.6911\n",
      "[564/1762] D loss: 1.3933, G loss: 0.6332\n",
      "[644/1762] D loss: 1.3785, G loss: 0.7200\n",
      "[724/1762] D loss: 1.3801, G loss: 0.6750\n",
      "[804/1762] D loss: 1.5599, G loss: 0.5383\n",
      "[884/1762] D loss: 1.3777, G loss: 0.6420\n",
      "[964/1762] D loss: 1.3792, G loss: 0.6819\n",
      "[1044/1762] D loss: 0.0422, G loss: 3.8316\n",
      "[1124/1762] D loss: 1.0471, G loss: 6.4537\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6810\n",
      "[1284/1762] D loss: 0.0244, G loss: 5.3977\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.6497\n",
      "[1444/1762] D loss: 0.3630, G loss: 2.5582\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6825\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7033\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6860\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7156\n",
      "train error: \n",
      " D loss: 1.633524, G loss: 0.763156, D accuracy: 48.1%, cell accuracy: 99.7%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.721819, G loss: 0.771417, D accuracy: 47.2%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7122\n",
      "[84/1762] D loss: 1.3852, G loss: 0.6824\n",
      "[164/1762] D loss: 0.0070, G loss: 7.9979\n",
      "[244/1762] D loss: 1.9471, G loss: 0.4697\n",
      "[324/1762] D loss: 0.0816, G loss: 3.4558\n",
      "[404/1762] D loss: 0.0046, G loss: 6.1158\n",
      "[484/1762] D loss: 1.3934, G loss: 0.6918\n",
      "[564/1762] D loss: 1.3897, G loss: 0.6436\n",
      "[644/1762] D loss: 0.0114, G loss: 4.8599\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6802\n",
      "[804/1762] D loss: 1.3546, G loss: 0.7789\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6706\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6814\n",
      "[1044/1762] D loss: 1.3821, G loss: 0.6787\n",
      "[1124/1762] D loss: 1.3844, G loss: 0.6870\n",
      "[1204/1762] D loss: 1.3821, G loss: 0.6905\n",
      "[1284/1762] D loss: 0.0057, G loss: 5.8334\n",
      "[1364/1762] D loss: 1.4740, G loss: 0.5652\n",
      "[1444/1762] D loss: 0.0098, G loss: 4.8459\n",
      "[1524/1762] D loss: 0.0024, G loss: 6.9734\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6679\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6835\n",
      "[1762/1762] D loss: 0.0018, G loss: 6.9786\n",
      "train error: \n",
      " D loss: 2.417100, G loss: 1.774911, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.540378, G loss: 1.790373, D accuracy: 48.4%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0048, G loss: 5.5217\n",
      "[84/1762] D loss: 0.0029, G loss: 6.3742\n",
      "[164/1762] D loss: 0.7896, G loss: 3.0054\n",
      "[244/1762] D loss: 0.0072, G loss: 5.1767\n",
      "[324/1762] D loss: 1.1885, G loss: 1.7700\n",
      "[404/1762] D loss: 1.3858, G loss: 0.7079\n",
      "[484/1762] D loss: 1.3852, G loss: 0.6898\n",
      "[564/1762] D loss: 1.4172, G loss: 0.6376\n",
      "[644/1762] D loss: 0.0123, G loss: 4.8612\n",
      "[724/1762] D loss: 1.3821, G loss: 0.6623\n",
      "[804/1762] D loss: 1.3809, G loss: 0.6682\n",
      "[884/1762] D loss: 0.1732, G loss: 5.8647\n",
      "[964/1762] D loss: 0.0092, G loss: 6.3664\n",
      "[1044/1762] D loss: 0.0072, G loss: 7.0763\n",
      "[1124/1762] D loss: 0.0005, G loss: 8.3089\n",
      "[1204/1762] D loss: 0.0003, G loss: 8.3385\n",
      "[1284/1762] D loss: 0.0003, G loss: 8.3686\n",
      "[1364/1762] D loss: 0.0027, G loss: 7.6862\n",
      "[1444/1762] D loss: 0.0016, G loss: 7.9387\n",
      "[1524/1762] D loss: 0.0032, G loss: 7.3269\n",
      "[1604/1762] D loss: 0.0021, G loss: 7.1438\n",
      "[1684/1762] D loss: 0.0007, G loss: 8.0821\n",
      "[1762/1762] D loss: 8.0624, G loss: 3.4080\n",
      "train error: \n",
      " D loss: 8.175724, G loss: 0.116384, D accuracy: 5.0%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 8.002039, G loss: 0.137109, D accuracy: 6.2%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.6022, G loss: 2.5533\n",
      "[84/1762] D loss: 0.1300, G loss: 2.7361\n",
      "[164/1762] D loss: 0.0280, G loss: 4.0824\n",
      "[244/1762] D loss: 0.0109, G loss: 4.8336\n",
      "[324/1762] D loss: 0.0095, G loss: 6.1253\n",
      "[404/1762] D loss: 5.6634, G loss: 1.1054\n",
      "[484/1762] D loss: 1.0573, G loss: 0.5616\n",
      "[564/1762] D loss: 0.3028, G loss: 3.0254\n",
      "[644/1762] D loss: 1.4227, G loss: 0.7613\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6649\n",
      "[804/1762] D loss: 1.3996, G loss: 0.6039\n",
      "[884/1762] D loss: 1.4026, G loss: 0.5875\n",
      "[964/1762] D loss: 1.3926, G loss: 0.6357\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6725\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.6725\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6703\n",
      "[1284/1762] D loss: 0.0637, G loss: 4.6748\n",
      "[1364/1762] D loss: 1.3992, G loss: 0.6871\n",
      "[1444/1762] D loss: 1.4005, G loss: 0.5932\n",
      "[1524/1762] D loss: 0.4888, G loss: 3.6453\n",
      "[1604/1762] D loss: 1.3940, G loss: 0.6155\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.6379\n",
      "[1762/1762] D loss: 1.3978, G loss: 0.6363\n",
      "train error: \n",
      " D loss: 1.610467, G loss: 0.829878, D accuracy: 48.6%, cell accuracy: 99.7%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.657256, G loss: 0.859221, D accuracy: 48.2%, cell accuracy: 99.6%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0689, G loss: 3.5152\n",
      "[84/1762] D loss: 1.3718, G loss: 0.6762\n",
      "[164/1762] D loss: 1.4027, G loss: 0.6295\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6630\n",
      "[324/1762] D loss: 1.3769, G loss: 0.6902\n",
      "[404/1762] D loss: 1.3526, G loss: 0.7213\n",
      "[484/1762] D loss: 1.3941, G loss: 0.6360\n",
      "[564/1762] D loss: 1.3925, G loss: 0.6300\n",
      "[644/1762] D loss: 1.3849, G loss: 0.7096\n",
      "[724/1762] D loss: 0.8524, G loss: 2.7570\n",
      "[804/1762] D loss: 1.4233, G loss: 0.5788\n",
      "[884/1762] D loss: 0.0096, G loss: 5.1393\n",
      "[964/1762] D loss: 1.3851, G loss: 0.6837\n",
      "[1044/1762] D loss: 1.3800, G loss: 0.6540\n",
      "[1124/1762] D loss: 1.4285, G loss: 0.6613\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6566\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.6567\n",
      "[1364/1762] D loss: 0.0042, G loss: 6.2946\n",
      "[1444/1762] D loss: 0.9182, G loss: 4.6444\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6831\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.6940\n",
      "[1684/1762] D loss: 1.3402, G loss: 1.6577\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.6081\n",
      "train error: \n",
      " D loss: 1.852902, G loss: 0.671893, D accuracy: 47.6%, cell accuracy: 99.7%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.932728, G loss: 0.658348, D accuracy: 46.6%, cell accuracy: 99.6%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3857, G loss: 0.6967\n",
      "[84/1762] D loss: 0.0172, G loss: 4.7336\n",
      "[164/1762] D loss: 1.4027, G loss: 0.6056\n",
      "[244/1762] D loss: 0.0268, G loss: 3.8735\n",
      "[324/1762] D loss: 1.3803, G loss: 0.6814\n",
      "[404/1762] D loss: 1.3882, G loss: 0.6752\n",
      "[484/1762] D loss: 0.2082, G loss: 3.9623\n",
      "[564/1762] D loss: 0.0249, G loss: 4.5878\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6969\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6893\n",
      "[804/1762] D loss: 0.0048, G loss: 5.6682\n",
      "[884/1762] D loss: 0.0018, G loss: 7.1986\n",
      "[964/1762] D loss: 1.3943, G loss: 0.6249\n",
      "[1044/1762] D loss: 1.3270, G loss: 0.8989\n",
      "[1124/1762] D loss: 0.0097, G loss: 5.3442\n",
      "[1204/1762] D loss: 1.3848, G loss: 0.6860\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6654\n",
      "[1364/1762] D loss: 1.3850, G loss: 0.6767\n",
      "[1444/1762] D loss: 1.3825, G loss: 0.6678\n",
      "[1524/1762] D loss: 1.4049, G loss: 0.5966\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6902\n",
      "[1684/1762] D loss: 1.3813, G loss: 0.6652\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6781\n",
      "train error: \n",
      " D loss: 1.687461, G loss: 0.858515, D accuracy: 49.5%, cell accuracy: 99.7%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.754786, G loss: 0.926523, D accuracy: 49.4%, cell accuracy: 99.6%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3835, G loss: 0.6949\n",
      "[84/1762] D loss: 1.3943, G loss: 0.6355\n",
      "[164/1762] D loss: 1.3931, G loss: 0.6306\n",
      "[244/1762] D loss: 0.0975, G loss: 2.8322\n",
      "[324/1762] D loss: 1.3861, G loss: 0.6381\n",
      "[404/1762] D loss: 1.3759, G loss: 0.7369\n",
      "[484/1762] D loss: 0.0287, G loss: 8.9619\n",
      "[564/1762] D loss: 1.3964, G loss: 0.5848\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6628\n",
      "[724/1762] D loss: 1.3827, G loss: 0.6703\n",
      "[804/1762] D loss: 0.0033, G loss: 6.0950\n",
      "[884/1762] D loss: 1.3845, G loss: 0.7015\n",
      "[964/1762] D loss: 0.0019, G loss: 7.2102\n",
      "[1044/1762] D loss: 1.3820, G loss: 0.6704\n",
      "[1124/1762] D loss: 1.3828, G loss: 0.7238\n",
      "[1204/1762] D loss: 1.3815, G loss: 0.6963\n",
      "[1284/1762] D loss: 1.3828, G loss: 0.6874\n",
      "[1364/1762] D loss: 1.3845, G loss: 0.7040\n",
      "[1444/1762] D loss: 0.0008, G loss: 7.5810\n",
      "[1524/1762] D loss: 1.3852, G loss: 0.6586\n",
      "[1604/1762] D loss: 1.3942, G loss: 0.6174\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.6293\n",
      "[1762/1762] D loss: 0.0008, G loss: 8.0777\n",
      "train error: \n",
      " D loss: 2.990231, G loss: 2.362972, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 3.119772, G loss: 2.409700, D accuracy: 49.4%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3824, G loss: 0.6844\n",
      "[84/1762] D loss: 0.0052, G loss: 5.8628\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6789\n",
      "[244/1762] D loss: 1.3863, G loss: 0.7115\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6895\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6705\n",
      "[484/1762] D loss: 1.3859, G loss: 0.6651\n",
      "[564/1762] D loss: 0.0056, G loss: 5.3286\n",
      "[644/1762] D loss: 1.3769, G loss: 0.7207\n",
      "[724/1762] D loss: 1.3726, G loss: 0.6962\n",
      "[804/1762] D loss: 1.3845, G loss: 0.6608\n",
      "[884/1762] D loss: 1.4044, G loss: 0.6412\n",
      "[964/1762] D loss: 1.3843, G loss: 0.7582\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7431\n",
      "[1124/1762] D loss: 1.4343, G loss: 0.7162\n",
      "[1204/1762] D loss: 1.3858, G loss: 0.6537\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.7112\n",
      "[1364/1762] D loss: 0.1237, G loss: 2.9872\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6881\n",
      "[1524/1762] D loss: 1.3853, G loss: 0.6568\n",
      "[1604/1762] D loss: 1.3830, G loss: 0.6948\n",
      "[1684/1762] D loss: 1.3836, G loss: 0.6912\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6599\n",
      "train error: \n",
      " D loss: 1.787228, G loss: 0.769289, D accuracy: 48.7%, cell accuracy: 99.7%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.856904, G loss: 0.829400, D accuracy: 48.2%, cell accuracy: 99.5%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3856, G loss: 0.6754\n",
      "[84/1762] D loss: 1.3616, G loss: 0.7371\n",
      "[164/1762] D loss: 1.3847, G loss: 0.7238\n",
      "[244/1762] D loss: 1.3833, G loss: 0.6832\n",
      "[324/1762] D loss: 0.1469, G loss: 3.7666\n",
      "[404/1762] D loss: 1.3815, G loss: 0.6776\n",
      "[484/1762] D loss: 1.3831, G loss: 0.6832\n",
      "[564/1762] D loss: 1.3818, G loss: 0.6700\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6476\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6964\n",
      "[804/1762] D loss: 1.3821, G loss: 0.6977\n",
      "[884/1762] D loss: 1.3837, G loss: 0.7112\n",
      "[964/1762] D loss: 1.3811, G loss: 0.7214\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.6805\n",
      "[1124/1762] D loss: 1.3849, G loss: 0.6805\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.6793\n",
      "[1284/1762] D loss: 1.3836, G loss: 0.6815\n",
      "[1364/1762] D loss: 1.3744, G loss: 1.2119\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6735\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6572\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6717\n",
      "[1684/1762] D loss: 0.0034, G loss: 6.0718\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.7027\n",
      "train error: \n",
      " D loss: 2.089387, G loss: 0.917404, D accuracy: 49.0%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.224621, G loss: 0.958946, D accuracy: 48.8%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3856, G loss: 0.6807\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7330\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6843\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6830\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6687\n",
      "[404/1762] D loss: 0.9926, G loss: 2.9876\n",
      "[484/1762] D loss: 1.3944, G loss: 0.6242\n",
      "[564/1762] D loss: 1.3805, G loss: 0.6677\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6664\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6778\n",
      "[804/1762] D loss: 1.3839, G loss: 0.6702\n",
      "[884/1762] D loss: 1.3850, G loss: 0.7040\n",
      "[964/1762] D loss: 1.3847, G loss: 0.6901\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6852\n",
      "[1124/1762] D loss: 1.3817, G loss: 0.7039\n",
      "[1204/1762] D loss: 0.0060, G loss: 6.7240\n",
      "[1284/1762] D loss: 0.0051, G loss: 5.6843\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.6906\n",
      "[1444/1762] D loss: 1.3839, G loss: 0.6944\n",
      "[1524/1762] D loss: 0.0454, G loss: 4.9394\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.6570\n",
      "[1684/1762] D loss: 1.3902, G loss: 0.6611\n",
      "[1762/1762] D loss: 1.3854, G loss: 0.6899\n",
      "train error: \n",
      " D loss: 2.339230, G loss: 1.477463, D accuracy: 49.1%, cell accuracy: 99.7%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.526069, G loss: 1.497077, D accuracy: 48.6%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3837, G loss: 0.6978\n",
      "[84/1762] D loss: 1.3857, G loss: 0.6849\n",
      "[164/1762] D loss: 1.3855, G loss: 0.6734\n",
      "[244/1762] D loss: 0.0119, G loss: 4.9649\n",
      "[324/1762] D loss: 1.3834, G loss: 0.7168\n",
      "[404/1762] D loss: 1.0269, G loss: 5.0062\n",
      "[484/1762] D loss: 0.0038, G loss: 6.6104\n",
      "[564/1762] D loss: 1.3834, G loss: 0.6530\n",
      "[644/1762] D loss: 1.3739, G loss: 0.9969\n",
      "[724/1762] D loss: 1.3853, G loss: 0.6816\n",
      "[804/1762] D loss: 1.3835, G loss: 0.7154\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6654\n",
      "[964/1762] D loss: 0.0016, G loss: 7.4994\n",
      "[1044/1762] D loss: 1.3827, G loss: 0.6966\n",
      "[1124/1762] D loss: 0.0008, G loss: 8.9258\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6748\n",
      "[1284/1762] D loss: 0.0029, G loss: 6.2017\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.6677\n",
      "[1444/1762] D loss: 1.3804, G loss: 0.6769\n",
      "[1524/1762] D loss: 1.3889, G loss: 0.6329\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.6748\n",
      "[1684/1762] D loss: 0.0092, G loss: 5.6539\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6747\n",
      "train error: \n",
      " D loss: 2.203201, G loss: 1.037332, D accuracy: 48.5%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.391952, G loss: 1.083835, D accuracy: 47.8%, cell accuracy: 99.7%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0021, G loss: 6.6949\n",
      "[84/1762] D loss: 1.3854, G loss: 0.6666\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6575\n",
      "[244/1762] D loss: 0.5299, G loss: 4.8252\n",
      "[324/1762] D loss: 1.3818, G loss: 0.7090\n",
      "[404/1762] D loss: 0.0116, G loss: 6.6313\n",
      "[484/1762] D loss: 1.3824, G loss: 0.7048\n",
      "[564/1762] D loss: 0.0046, G loss: 7.2088\n",
      "[644/1762] D loss: 1.3809, G loss: 0.6852\n",
      "[724/1762] D loss: 0.0033, G loss: 6.4843\n",
      "[804/1762] D loss: 1.3801, G loss: 0.6636\n",
      "[884/1762] D loss: 1.3784, G loss: 0.7188\n",
      "[964/1762] D loss: 1.3762, G loss: 0.6837\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.6319\n",
      "[1124/1762] D loss: 1.3856, G loss: 0.6521\n",
      "[1204/1762] D loss: 1.3225, G loss: 1.4097\n",
      "[1284/1762] D loss: 1.3842, G loss: 0.6736\n",
      "[1364/1762] D loss: 1.3815, G loss: 0.6766\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.7173\n",
      "[1524/1762] D loss: 1.3812, G loss: 0.7191\n",
      "[1604/1762] D loss: 1.3843, G loss: 0.6570\n",
      "[1684/1762] D loss: 0.0016, G loss: 6.6504\n",
      "[1762/1762] D loss: 0.0298, G loss: 3.8433\n",
      "train error: \n",
      " D loss: 2.255997, G loss: 1.440665, D accuracy: 48.6%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.411516, G loss: 1.504538, D accuracy: 48.3%, cell accuracy: 99.7%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3839, G loss: 0.6752\n",
      "[84/1762] D loss: 1.3816, G loss: 0.6971\n",
      "[164/1762] D loss: 1.3819, G loss: 0.6834\n",
      "[244/1762] D loss: 0.0018, G loss: 7.3405\n",
      "[324/1762] D loss: 0.0040, G loss: 6.6942\n",
      "[404/1762] D loss: 1.3975, G loss: 0.6048\n",
      "[484/1762] D loss: 1.3775, G loss: 0.6728\n",
      "[564/1762] D loss: 1.3465, G loss: 0.8234\n",
      "[644/1762] D loss: 1.3831, G loss: 0.6771\n",
      "[724/1762] D loss: 0.0341, G loss: 4.6520\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6792\n",
      "[884/1762] D loss: 0.0028, G loss: 6.2795\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6831\n",
      "[1044/1762] D loss: 1.4207, G loss: 0.6878\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.6137\n",
      "[1204/1762] D loss: 0.0018, G loss: 7.7488\n",
      "[1284/1762] D loss: 0.7494, G loss: 0.8398\n",
      "[1364/1762] D loss: 0.0206, G loss: 7.6236\n",
      "[1444/1762] D loss: 0.0016, G loss: 7.1705\n",
      "[1524/1762] D loss: 0.0381, G loss: 4.0159\n",
      "[1604/1762] D loss: 0.7261, G loss: 5.2968\n",
      "[1684/1762] D loss: 1.6445, G loss: 0.4836\n",
      "[1762/1762] D loss: 0.0030, G loss: 6.4943\n",
      "train error: \n",
      " D loss: 2.046785, G loss: 1.837000, D accuracy: 50.3%, cell accuracy: 99.7%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.102864, G loss: 1.873602, D accuracy: 49.9%, cell accuracy: 99.6%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0058, G loss: 6.4004\n",
      "[84/1762] D loss: 0.0060, G loss: 5.9757\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6773\n",
      "[244/1762] D loss: 1.3820, G loss: 0.7132\n",
      "[324/1762] D loss: 1.3559, G loss: 0.7769\n",
      "[404/1762] D loss: 0.0022, G loss: 7.5403\n",
      "[484/1762] D loss: 1.4052, G loss: 0.7133\n",
      "[564/1762] D loss: 0.0062, G loss: 6.1869\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6795\n",
      "[724/1762] D loss: 1.3856, G loss: 0.6811\n",
      "[804/1762] D loss: 0.0009, G loss: 7.8175\n",
      "[884/1762] D loss: 0.0011, G loss: 7.6626\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6938\n",
      "[1044/1762] D loss: 1.3803, G loss: 0.7115\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7042\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6865\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6993\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7007\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.6271\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6894\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.7205\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6960\n",
      "[1762/1762] D loss: 1.3959, G loss: 0.5979\n",
      "train error: \n",
      " D loss: 2.648333, G loss: 1.717147, D accuracy: 39.5%, cell accuracy: 98.6%, board accuracy: 44.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.732709, G loss: 1.812884, D accuracy: 38.0%, cell accuracy: 98.3%, board accuracy: 39.3% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5647, G loss: 9.3742\n",
      "[84/1762] D loss: 1.4424, G loss: 0.6940\n",
      "[164/1762] D loss: 1.3721, G loss: 0.6995\n",
      "[244/1762] D loss: 0.0026, G loss: 6.9122\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6922\n",
      "[404/1762] D loss: 1.3896, G loss: 0.6557\n",
      "[484/1762] D loss: 0.0006, G loss: 8.0495\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6702\n",
      "[644/1762] D loss: 0.0029, G loss: 7.0617\n",
      "[724/1762] D loss: 1.3908, G loss: 0.7094\n",
      "[804/1762] D loss: 0.0036, G loss: 6.1067\n",
      "[884/1762] D loss: 1.3924, G loss: 0.6584\n",
      "[964/1762] D loss: 0.0004, G loss: 9.3990\n",
      "[1044/1762] D loss: 1.4036, G loss: 0.6006\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.6666\n",
      "[1204/1762] D loss: 0.0003, G loss: 9.1033\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.6452\n",
      "[1364/1762] D loss: 1.3475, G loss: 1.1696\n",
      "[1444/1762] D loss: 0.0007, G loss: 8.1110\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.6512\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6842\n",
      "[1684/1762] D loss: 1.3913, G loss: 0.7314\n",
      "[1762/1762] D loss: 1.3834, G loss: 0.6877\n",
      "train error: \n",
      " D loss: 2.012013, G loss: 0.851512, D accuracy: 49.1%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.161743, G loss: 0.837333, D accuracy: 48.1%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0041, G loss: 5.7554\n",
      "[84/1762] D loss: 0.0112, G loss: 7.3945\n",
      "[164/1762] D loss: 1.3859, G loss: 0.6617\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6835\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6954\n",
      "[404/1762] D loss: 0.0067, G loss: 7.4712\n",
      "[484/1762] D loss: 1.3693, G loss: 0.6373\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7000\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6634\n",
      "[724/1762] D loss: 1.2152, G loss: 2.0651\n",
      "[804/1762] D loss: 0.0023, G loss: 6.8836\n",
      "[884/1762] D loss: 1.4377, G loss: 0.5231\n",
      "[964/1762] D loss: 1.3993, G loss: 0.5971\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6984\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.7177\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6833\n",
      "[1284/1762] D loss: 0.0016, G loss: 7.5041\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.7050\n",
      "[1444/1762] D loss: 1.3783, G loss: 0.6833\n",
      "[1524/1762] D loss: 1.3918, G loss: 0.6322\n",
      "[1604/1762] D loss: 0.0190, G loss: 6.7355\n",
      "[1684/1762] D loss: 0.0041, G loss: 7.3187\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6642\n",
      "train error: \n",
      " D loss: 2.751391, G loss: 2.369360, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.881393, G loss: 2.468098, D accuracy: 49.4%, cell accuracy: 99.7%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0092, G loss: 6.2644\n",
      "[84/1762] D loss: 0.0014, G loss: 7.6491\n",
      "[164/1762] D loss: 0.0047, G loss: 7.2282\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7019\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6886\n",
      "[404/1762] D loss: 1.3888, G loss: 0.6580\n",
      "[484/1762] D loss: 1.4459, G loss: 0.5188\n",
      "[564/1762] D loss: 1.3895, G loss: 0.6490\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6896\n",
      "[724/1762] D loss: 1.3799, G loss: 0.7091\n",
      "[804/1762] D loss: 1.3855, G loss: 0.6582\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6720\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6968\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6623\n",
      "[1124/1762] D loss: 0.0006, G loss: 8.5958\n",
      "[1204/1762] D loss: 0.0010, G loss: 7.8998\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6867\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.6453\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6933\n",
      "[1524/1762] D loss: 1.3823, G loss: 0.7418\n",
      "[1604/1762] D loss: 1.3793, G loss: 0.6964\n",
      "[1684/1762] D loss: 1.3662, G loss: 0.7960\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7096\n",
      "train error: \n",
      " D loss: 3.125317, G loss: 2.490366, D accuracy: 49.1%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.358092, G loss: 2.656936, D accuracy: 49.0%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0008, G loss: 8.7679\n",
      "[84/1762] D loss: 0.0010, G loss: 7.6883\n",
      "[164/1762] D loss: 0.0014, G loss: 8.8971\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7165\n",
      "[324/1762] D loss: 0.0029, G loss: 8.1859\n",
      "[404/1762] D loss: 1.3856, G loss: 0.6641\n",
      "[484/1762] D loss: 1.3834, G loss: 0.6784\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6792\n",
      "[644/1762] D loss: 1.3856, G loss: 0.6886\n",
      "[724/1762] D loss: 0.0016, G loss: 9.0619\n",
      "[804/1762] D loss: 1.3839, G loss: 0.7067\n",
      "[884/1762] D loss: 1.3937, G loss: 0.7130\n",
      "[964/1762] D loss: 0.0007, G loss: 8.9679\n",
      "[1044/1762] D loss: 0.0022, G loss: 6.5168\n",
      "[1124/1762] D loss: 0.0004, G loss: 8.6763\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6482\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6506\n",
      "[1364/1762] D loss: 1.3853, G loss: 0.6509\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6688\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6617\n",
      "[1604/1762] D loss: 0.0003, G loss: 8.6073\n",
      "[1684/1762] D loss: 0.0004, G loss: 8.7327\n",
      "[1762/1762] D loss: 1.3809, G loss: 0.9201\n",
      "train error: \n",
      " D loss: 3.109265, G loss: 2.516118, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.300062, G loss: 2.618047, D accuracy: 48.9%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7399\n",
      "[84/1762] D loss: 0.0002, G loss: 9.6967\n",
      "[164/1762] D loss: 0.0037, G loss: 6.1941\n",
      "[244/1762] D loss: 1.3849, G loss: 0.6985\n",
      "[324/1762] D loss: 1.3846, G loss: 0.6853\n",
      "[404/1762] D loss: 1.3849, G loss: 0.6951\n",
      "[484/1762] D loss: 1.3845, G loss: 0.7246\n",
      "[564/1762] D loss: 1.3722, G loss: 0.7065\n",
      "[644/1762] D loss: 1.3856, G loss: 0.7241\n",
      "[724/1762] D loss: 0.0020, G loss: 6.8053\n",
      "[804/1762] D loss: 0.0082, G loss: 5.7629\n",
      "[884/1762] D loss: 1.3863, G loss: 0.7118\n",
      "[964/1762] D loss: 1.3854, G loss: 0.6934\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.6939\n",
      "[1124/1762] D loss: 1.3856, G loss: 0.7041\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.7282\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6835\n",
      "[1364/1762] D loss: 1.3790, G loss: 0.6648\n",
      "[1444/1762] D loss: 1.3858, G loss: 0.6784\n",
      "[1524/1762] D loss: 1.3849, G loss: 0.6792\n",
      "[1604/1762] D loss: 1.3844, G loss: 0.6862\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.6502\n",
      "[1762/1762] D loss: 1.3851, G loss: 0.7079\n",
      "train error: \n",
      " D loss: 1.863198, G loss: 0.884797, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.965229, G loss: 0.884608, D accuracy: 48.6%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5115, G loss: 0.5803\n",
      "[84/1762] D loss: 0.0005, G loss: 8.9024\n",
      "[164/1762] D loss: 1.3857, G loss: 0.7042\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7179\n",
      "[324/1762] D loss: 0.0014, G loss: 7.3881\n",
      "[404/1762] D loss: 1.3898, G loss: 0.7525\n",
      "[484/1762] D loss: 1.3860, G loss: 0.7125\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6804\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6719\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6947\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6598\n",
      "[884/1762] D loss: 1.3877, G loss: 0.7383\n",
      "[964/1762] D loss: 1.3925, G loss: 0.7320\n",
      "[1044/1762] D loss: 0.0043, G loss: 7.7240\n",
      "[1124/1762] D loss: 0.0012, G loss: 9.0475\n",
      "[1204/1762] D loss: 0.0005, G loss: 7.9608\n",
      "[1284/1762] D loss: 1.3844, G loss: 0.6661\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.7185\n",
      "[1444/1762] D loss: 0.0004, G loss: 8.6036\n",
      "[1524/1762] D loss: 1.3854, G loss: 0.6869\n",
      "[1604/1762] D loss: 1.3847, G loss: 0.7073\n",
      "[1684/1762] D loss: 0.0008, G loss: 8.4173\n",
      "[1762/1762] D loss: 1.3933, G loss: 0.7189\n",
      "train error: \n",
      " D loss: 3.258403, G loss: 2.770561, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.381832, G loss: 2.827817, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3832, G loss: 0.6994\n",
      "[84/1762] D loss: 0.0005, G loss: 8.2510\n",
      "[164/1762] D loss: 1.3815, G loss: 0.7209\n",
      "[244/1762] D loss: 1.3787, G loss: 0.6803\n",
      "[324/1762] D loss: 0.0022, G loss: 8.5403\n",
      "[404/1762] D loss: 1.3854, G loss: 0.7107\n",
      "[484/1762] D loss: 1.3794, G loss: 0.7181\n",
      "[564/1762] D loss: 1.3690, G loss: 0.6888\n",
      "[644/1762] D loss: 1.3852, G loss: 0.6769\n",
      "[724/1762] D loss: 1.3861, G loss: 0.6833\n",
      "[804/1762] D loss: 0.0004, G loss: 9.6167\n",
      "[884/1762] D loss: 0.0003, G loss: 9.7324\n",
      "[964/1762] D loss: 0.0004, G loss: 8.3547\n",
      "[1044/1762] D loss: 1.3856, G loss: 0.7395\n",
      "[1124/1762] D loss: 0.0008, G loss: 8.0058\n",
      "[1204/1762] D loss: 1.3842, G loss: 0.6762\n",
      "[1284/1762] D loss: 1.3846, G loss: 0.6885\n",
      "[1364/1762] D loss: 1.3788, G loss: 0.6978\n",
      "[1444/1762] D loss: 0.0034, G loss: 8.7584\n",
      "[1524/1762] D loss: 1.3842, G loss: 0.6936\n",
      "[1604/1762] D loss: 0.0015, G loss: 7.2227\n",
      "[1684/1762] D loss: 1.3841, G loss: 0.6797\n",
      "[1762/1762] D loss: 0.4519, G loss: 8.9795\n",
      "train error: \n",
      " D loss: 4.678216, G loss: 4.005328, D accuracy: 49.9%, cell accuracy: 99.5%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 4.927077, G loss: 4.060635, D accuracy: 49.9%, cell accuracy: 99.3%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5513, G loss: 0.4275\n",
      "[84/1762] D loss: 0.0032, G loss: 8.7533\n",
      "[164/1762] D loss: 1.3846, G loss: 0.6730\n",
      "[244/1762] D loss: 0.0011, G loss: 8.5354\n",
      "[324/1762] D loss: 1.3845, G loss: 0.6988\n",
      "[404/1762] D loss: 1.3842, G loss: 0.6939\n",
      "[484/1762] D loss: 0.0006, G loss: 8.1672\n",
      "[564/1762] D loss: 1.3846, G loss: 0.6939\n",
      "[644/1762] D loss: 0.6080, G loss: 3.9163\n",
      "[724/1762] D loss: 1.3844, G loss: 0.6738\n",
      "[804/1762] D loss: 1.3856, G loss: 0.6840\n",
      "[884/1762] D loss: 0.0004, G loss: 8.8917\n",
      "[964/1762] D loss: 1.4403, G loss: 0.5345\n",
      "[1044/1762] D loss: 1.3852, G loss: 0.6738\n",
      "[1124/1762] D loss: 1.3819, G loss: 0.7040\n",
      "[1204/1762] D loss: 1.3841, G loss: 0.6879\n",
      "[1284/1762] D loss: 1.3837, G loss: 0.7196\n",
      "[1364/1762] D loss: 1.3829, G loss: 0.6942\n",
      "[1444/1762] D loss: 1.3809, G loss: 0.7030\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.6092\n",
      "[1604/1762] D loss: 0.0031, G loss: 6.1031\n",
      "[1684/1762] D loss: 0.0007, G loss: 8.1509\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.7126\n",
      "train error: \n",
      " D loss: 2.283943, G loss: 1.082255, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.472783, G loss: 1.104229, D accuracy: 48.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004, G loss: 8.1196\n",
      "[84/1762] D loss: 1.3832, G loss: 0.6938\n",
      "[164/1762] D loss: 1.3836, G loss: 0.7253\n",
      "[244/1762] D loss: 1.3855, G loss: 0.6901\n",
      "[324/1762] D loss: 1.3800, G loss: 0.7163\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6359\n",
      "[484/1762] D loss: 0.0003, G loss: 9.4725\n",
      "[564/1762] D loss: 1.3836, G loss: 0.7034\n",
      "[644/1762] D loss: 0.0208, G loss: 4.6539\n",
      "[724/1762] D loss: 0.0002, G loss: 9.7283\n",
      "[804/1762] D loss: 0.0004, G loss: 10.3308\n",
      "[884/1762] D loss: 0.0024, G loss: 7.7413\n",
      "[964/1762] D loss: 1.3973, G loss: 0.5882\n",
      "[1044/1762] D loss: 0.0004, G loss: 10.9570\n",
      "[1124/1762] D loss: 0.0001, G loss: 12.1814\n",
      "[1204/1762] D loss: 0.1322, G loss: 9.0122\n",
      "[1284/1762] D loss: 0.0001, G loss: 11.9355\n",
      "[1364/1762] D loss: 0.0325, G loss: 7.3187\n",
      "[1444/1762] D loss: 0.0024, G loss: 6.3448\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6872\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6792\n",
      "[1684/1762] D loss: 0.1368, G loss: 3.9890\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.6604\n",
      "train error: \n",
      " D loss: 2.672813, G loss: 1.561375, D accuracy: 48.8%, cell accuracy: 99.7%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.836697, G loss: 1.615755, D accuracy: 49.1%, cell accuracy: 99.6%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3900, G loss: 0.6548\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6807\n",
      "[164/1762] D loss: 0.6623, G loss: 0.7962\n",
      "[244/1762] D loss: 1.3570, G loss: 0.7127\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6876\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7104\n",
      "[484/1762] D loss: 0.0005, G loss: 8.3047\n",
      "[564/1762] D loss: 0.0003, G loss: 8.9500\n",
      "[644/1762] D loss: 2.3217, G loss: 0.7182\n",
      "[724/1762] D loss: 1.3920, G loss: 0.7539\n",
      "[804/1762] D loss: 0.0043, G loss: 5.7522\n",
      "[884/1762] D loss: 1.3891, G loss: 0.6493\n",
      "[964/1762] D loss: 0.0019, G loss: 6.7132\n",
      "[1044/1762] D loss: 0.0013, G loss: 6.9687\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6813\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.7072\n",
      "[1284/1762] D loss: 1.3703, G loss: 0.7123\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6759\n",
      "[1444/1762] D loss: 0.0008, G loss: 8.4566\n",
      "[1524/1762] D loss: 0.7036, G loss: 8.8281\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.7036\n",
      "[1684/1762] D loss: 0.6830, G loss: 7.8013\n",
      "[1762/1762] D loss: 0.1212, G loss: 7.2796\n",
      "train error: \n",
      " D loss: 3.155472, G loss: 2.958280, D accuracy: 47.4%, cell accuracy: 99.7%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 3.169032, G loss: 2.900149, D accuracy: 46.6%, cell accuracy: 99.6%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.6458\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6568\n",
      "[164/1762] D loss: 1.3901, G loss: 0.6432\n",
      "[244/1762] D loss: 0.0015, G loss: 8.0039\n",
      "[324/1762] D loss: 1.4261, G loss: 0.5422\n",
      "[404/1762] D loss: 0.2517, G loss: 5.8658\n",
      "[484/1762] D loss: 0.0008, G loss: 10.7547\n",
      "[564/1762] D loss: 1.3312, G loss: 2.7437\n",
      "[644/1762] D loss: 1.8759, G loss: 0.5288\n",
      "[724/1762] D loss: 0.0001, G loss: 11.4183\n",
      "[804/1762] D loss: 0.0707, G loss: 4.7401\n",
      "[884/1762] D loss: 0.0261, G loss: 8.5950\n",
      "[964/1762] D loss: 0.0022, G loss: 6.9915\n",
      "[1044/1762] D loss: 0.0176, G loss: 5.3787\n",
      "[1124/1762] D loss: 0.0006, G loss: 7.5892\n",
      "[1204/1762] D loss: 0.0089, G loss: 8.5335\n",
      "[1284/1762] D loss: 0.0012, G loss: 7.1580\n",
      "[1364/1762] D loss: 0.0004, G loss: 7.9025\n",
      "[1444/1762] D loss: 0.0014, G loss: 7.1157\n",
      "[1524/1762] D loss: 0.0049, G loss: 9.6537\n",
      "[1604/1762] D loss: 0.0039, G loss: 8.2377\n",
      "[1684/1762] D loss: 0.0050, G loss: 7.3843\n",
      "[1762/1762] D loss: 0.0091, G loss: 8.3245\n",
      "train error: \n",
      " D loss: 9.276553, G loss: 4.978971, D accuracy: 48.1%, cell accuracy: 93.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 9.249566, G loss: 5.064086, D accuracy: 48.5%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 8.8040\n",
      "[84/1762] D loss: 0.0035, G loss: 7.5564\n",
      "[164/1762] D loss: 0.0031, G loss: 8.1300\n",
      "[244/1762] D loss: 0.0001, G loss: 9.0736\n",
      "[324/1762] D loss: 0.0026, G loss: 8.1335\n",
      "[404/1762] D loss: 0.0031, G loss: 7.2040\n",
      "[484/1762] D loss: 0.0002, G loss: 8.8249\n",
      "[564/1762] D loss: 0.0027, G loss: 7.1943\n",
      "[644/1762] D loss: 0.0023, G loss: 7.8059\n",
      "[724/1762] D loss: 0.0018, G loss: 8.4076\n",
      "[804/1762] D loss: 0.0002, G loss: 8.4310\n",
      "[884/1762] D loss: 0.0019, G loss: 7.8554\n",
      "[964/1762] D loss: 0.0016, G loss: 8.3286\n",
      "[1044/1762] D loss: 0.0015, G loss: 8.8217\n",
      "[1124/1762] D loss: 0.0001, G loss: 10.0274\n",
      "[1204/1762] D loss: 0.0019, G loss: 7.8350\n",
      "[1284/1762] D loss: 0.0014, G loss: 7.9459\n",
      "[1364/1762] D loss: 0.0015, G loss: 9.3090\n",
      "[1444/1762] D loss: 0.0000, G loss: 10.2162\n",
      "[1524/1762] D loss: 0.0001, G loss: 9.6215\n",
      "[1604/1762] D loss: 0.0015, G loss: 8.9525\n",
      "[1684/1762] D loss: 0.0014, G loss: 9.1859\n",
      "[1762/1762] D loss: 0.0011, G loss: 9.0541\n",
      "train error: \n",
      " D loss: 9.864807, G loss: 3.247974, D accuracy: 46.0%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 9.876421, G loss: 3.255037, D accuracy: 45.8%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009, G loss: 9.6628\n",
      "[84/1762] D loss: 0.0011, G loss: 8.3239\n",
      "[164/1762] D loss: 0.0009, G loss: 10.2732\n",
      "[244/1762] D loss: 0.0008, G loss: 9.0063\n",
      "[324/1762] D loss: 0.0010, G loss: 8.9218\n",
      "[404/1762] D loss: 0.0010, G loss: 9.3465\n",
      "[484/1762] D loss: 0.0017, G loss: 7.7514\n",
      "[564/1762] D loss: 0.0013, G loss: 8.0294\n",
      "[644/1762] D loss: 0.0010, G loss: 8.5374\n",
      "[724/1762] D loss: 0.0011, G loss: 8.6216\n",
      "[804/1762] D loss: 0.0005, G loss: 8.5855\n",
      "[884/1762] D loss: 0.0017, G loss: 7.0074\n",
      "[964/1762] D loss: 0.0012, G loss: 7.9770\n",
      "[1044/1762] D loss: 0.0011, G loss: 8.0628\n",
      "[1124/1762] D loss: 0.0002, G loss: 8.8075\n",
      "[1204/1762] D loss: 0.0010, G loss: 8.6415\n",
      "[1284/1762] D loss: 0.0004, G loss: 7.9096\n",
      "[1364/1762] D loss: 0.0009, G loss: 8.2717\n",
      "[1444/1762] D loss: 0.0007, G loss: 9.3095\n",
      "[1524/1762] D loss: 0.0003, G loss: 9.1867\n",
      "[1604/1762] D loss: 0.0002, G loss: 9.0468\n",
      "[1684/1762] D loss: 0.0012, G loss: 8.2019\n",
      "[1762/1762] D loss: 0.0008, G loss: 8.6719\n",
      "train error: \n",
      " D loss: 12.120172, G loss: 1.847382, D accuracy: 38.7%, cell accuracy: 90.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 12.218548, G loss: 1.808414, D accuracy: 38.2%, cell accuracy: 90.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009, G loss: 8.8494\n",
      "[84/1762] D loss: 0.0010, G loss: 8.5358\n",
      "[164/1762] D loss: 0.0009, G loss: 7.9103\n",
      "[244/1762] D loss: 0.0004, G loss: 8.5299\n",
      "[324/1762] D loss: 0.0010, G loss: 9.4185\n",
      "[404/1762] D loss: 0.0008, G loss: 8.5957\n",
      "[484/1762] D loss: 0.0006, G loss: 9.1889\n",
      "[564/1762] D loss: 0.0010, G loss: 8.2034\n",
      "[644/1762] D loss: 0.0006, G loss: 9.0023\n",
      "[724/1762] D loss: 0.0008, G loss: 8.1902\n",
      "[804/1762] D loss: 0.0005, G loss: 7.7687\n",
      "[884/1762] D loss: 0.0003, G loss: 8.7792\n",
      "[964/1762] D loss: 0.0009, G loss: 8.3517\n",
      "[1044/1762] D loss: 0.0001, G loss: 9.5090\n",
      "[1124/1762] D loss: 0.0007, G loss: 9.4900\n",
      "[1204/1762] D loss: 0.0002, G loss: 8.9848\n",
      "[1284/1762] D loss: 0.0010, G loss: 7.9522\n",
      "[1364/1762] D loss: 0.0007, G loss: 8.4233\n",
      "[1444/1762] D loss: 0.0001, G loss: 9.2579\n",
      "[1524/1762] D loss: 0.0004, G loss: 8.2670\n",
      "[1604/1762] D loss: 0.0008, G loss: 8.4985\n",
      "[1684/1762] D loss: 0.0006, G loss: 9.1052\n",
      "[1762/1762] D loss: 0.0008, G loss: 9.0838\n",
      "train error: \n",
      " D loss: 9.847191, G loss: 4.251204, D accuracy: 49.3%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 9.826110, G loss: 4.232455, D accuracy: 49.5%, cell accuracy: 93.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006, G loss: 9.7924\n",
      "[84/1762] D loss: 0.0004, G loss: 7.8713\n",
      "[164/1762] D loss: 0.0009, G loss: 7.0080\n",
      "[244/1762] D loss: 0.0007, G loss: 8.4015\n",
      "[324/1762] D loss: 0.0011, G loss: 8.8634\n",
      "[404/1762] D loss: 0.0028, G loss: 6.1368\n",
      "[484/1762] D loss: 0.0008, G loss: 7.5013\n",
      "[564/1762] D loss: 0.0034, G loss: 6.5709\n",
      "[644/1762] D loss: 0.0002, G loss: 9.4021\n",
      "[724/1762] D loss: 0.0010, G loss: 7.9593\n",
      "[804/1762] D loss: 0.0007, G loss: 8.7749\n",
      "[884/1762] D loss: 0.0007, G loss: 9.3132\n",
      "[964/1762] D loss: 0.0002, G loss: 9.0446\n",
      "[1044/1762] D loss: 0.0007, G loss: 8.7800\n",
      "[1124/1762] D loss: 0.0215, G loss: 7.4393\n",
      "[1204/1762] D loss: 0.0011, G loss: 7.6711\n",
      "[1284/1762] D loss: 0.0011, G loss: 7.5695\n",
      "[1364/1762] D loss: 0.0014, G loss: 8.2411\n",
      "[1444/1762] D loss: 0.0011, G loss: 7.4352\n",
      "[1524/1762] D loss: 0.0007, G loss: 8.8602\n",
      "[1604/1762] D loss: 0.0020, G loss: 6.5716\n",
      "[1684/1762] D loss: 0.0006, G loss: 9.1672\n",
      "[1762/1762] D loss: 0.0006, G loss: 8.4986\n",
      "train error: \n",
      " D loss: 15.626941, G loss: 0.000040, D accuracy: 6.2%, cell accuracy: 77.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 15.810299, G loss: 0.000040, D accuracy: 6.6%, cell accuracy: 77.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006, G loss: 9.8822\n",
      "[84/1762] D loss: 0.0013, G loss: 7.6103\n",
      "[164/1762] D loss: 0.0006, G loss: 8.6153\n",
      "[244/1762] D loss: 0.0005, G loss: 7.7264\n",
      "[324/1762] D loss: 0.0005, G loss: 8.7963\n",
      "[404/1762] D loss: 0.0004, G loss: 7.9639\n",
      "[484/1762] D loss: 0.0009, G loss: 10.3630\n",
      "[564/1762] D loss: 0.0004, G loss: 10.6078\n",
      "[644/1762] D loss: 0.0007, G loss: 8.7418\n",
      "[724/1762] D loss: 0.0010, G loss: 7.6949\n",
      "[804/1762] D loss: 0.0007, G loss: 8.3390\n",
      "[884/1762] D loss: 0.0006, G loss: 8.1706\n",
      "[964/1762] D loss: 0.0007, G loss: 8.5081\n",
      "[1044/1762] D loss: 0.0002, G loss: 9.2876\n",
      "[1124/1762] D loss: 0.0005, G loss: 8.9348\n",
      "[1204/1762] D loss: 0.0001, G loss: 9.4128\n",
      "[1284/1762] D loss: 0.0004, G loss: 8.0256\n",
      "[1364/1762] D loss: 0.0003, G loss: 8.6144\n",
      "[1444/1762] D loss: 0.0004, G loss: 9.5442\n",
      "[1524/1762] D loss: 0.0001, G loss: 9.0184\n",
      "[1604/1762] D loss: 0.0001, G loss: 9.9775\n",
      "[1684/1762] D loss: 0.0009, G loss: 8.1512\n",
      "[1762/1762] D loss: 0.0014, G loss: 10.5934\n",
      "train error: \n",
      " D loss: 11.850068, G loss: 0.001742, D accuracy: 3.0%, cell accuracy: 79.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 11.898195, G loss: 0.001365, D accuracy: 3.0%, cell accuracy: 79.3%, board accuracy: 0.0% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for cls in [DiscWithOnlyStride1, DiscLocalGlobal]:\n",
    "    train(run_name=cls.__name__, disc_cls=cls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of these discriminator architectures fixes the issue. The `DiscWithOnlyStride1` architecture actually makes the issue worse.\n",
    "\n",
    "It's time to question whether it is actually the discriminator that's at fault. Let's ignore the generator for now, generate some data that includes the kinds of mistakes we're trying to make the discriminator robust to, and train the discriminator to tell the difference between these and the real data.\n",
    "\n",
    "Another explanation might be that the random number input to the generator is confusing it. We could try:\n",
    "* Inputting fewer random numbers, like 1 or 2 instead of 4.\n",
    "* Inputting normally distributed random numbers instead of uniformly distributed ones (although it is trying to model a uniform distribution of block types, so I'm not sure how much this would help).\n",
    "* Inputting the random numbers at a higher layer, once it has processed some of the spatial information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train discriminator on synthetic fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True],\n",
      "          [False,  True,  True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True],\n",
      "          [False,  True,  True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True],\n",
      "          [ True, False,  True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True],\n",
      "          [ True, False,  True,  True,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True, False,  True]],\n",
      "\n",
      "         [[ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True, False,  True]]],\n",
      "\n",
      "\n",
      "        [[[ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True],\n",
      "          [ True, False,  True,  True,  True]],\n",
      "\n",
      "         [[ True,  True,  True,  True,  True],\n",
      "          [ True,  True,  True,  True,  True],\n",
      "          [ True, False,  True,  True,  True]]]])\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def perturb_data(y, num):\n",
    "    # This algorithm might flip less than the request number of cells, because the random coordinates are drawn with replacement.\n",
    "    y = y.clone()\n",
    "    batch_size, channels, height, width = y.shape\n",
    "    i_ = torch.randint(high=height, size=(batch_size, num))\n",
    "    j_ = torch.randint(high=width, size=(batch_size, num))\n",
    "    y_flipped = y.flip(dims=[1])\n",
    "    for batch in range(batch_size):\n",
    "        for repeat in range(num):\n",
    "            i = i_[batch, repeat]\n",
    "            j = j_[batch, repeat]\n",
    "            y[batch, :, i, j] = y_flipped[batch, :, i, j]\n",
    "    return y\n",
    "\n",
    "\n",
    "y = torch.rand(4, 2, 3, 5)\n",
    "print(y == perturb_data(y, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1892f53ba00>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, y = train_dataset[0]\n",
    "y_fake = perturb_data(y.unsqueeze(0), 10).squeeze(0)\n",
    "plt.imshow(render_prediction(y.argmax(0), y_fake.argmax(0), torch.zeros(22, 10)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll redefine the training and test loops to just train the discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, disc, loss_fn, optimizer_disc, perturb_num):\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(X, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = perturb_data(y, perturb_num)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(X, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 20 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, disc, loss_fn, tb_writer, epoch, perturb_num):\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for X, y in dataloader:\n",
    "            batch_size = X.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(X, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            y_fake = perturb_data(y, perturb_num)\n",
    "            output_fake = disc(X, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", disc_cls=TetrisDiscriminator, perturb_num=1, epochs=50, learning_rate=1e-2):\n",
    "    disc = disc_cls().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_disc = torch.optim.SGD(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_017\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, disc, loss_fn, optimizer_disc, perturb_num)\n",
    "        test_loop(\"train\", train_dataloader, disc, loss_fn, tb_writer, epoch, perturb_num)\n",
    "        test_loop(\"test\", test_dataloader, disc, loss_fn, tb_writer, epoch, perturb_num)\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877\n",
      "[84/1762] D loss: 1.3890\n",
      "[164/1762] D loss: 1.3962\n",
      "[244/1762] D loss: 1.3913\n",
      "[324/1762] D loss: 1.3757\n",
      "[404/1762] D loss: 1.3908\n",
      "[484/1762] D loss: 1.3921\n",
      "[564/1762] D loss: 1.3837\n",
      "[644/1762] D loss: 1.3885\n",
      "[724/1762] D loss: 1.3829\n",
      "[804/1762] D loss: 1.3851\n",
      "[884/1762] D loss: 1.3742\n",
      "[964/1762] D loss: 1.3987\n",
      "[1044/1762] D loss: 1.3893\n",
      "[1124/1762] D loss: 1.3944\n",
      "[1204/1762] D loss: 1.3885\n",
      "[1284/1762] D loss: 1.3813\n",
      "[1364/1762] D loss: 1.3849\n",
      "[1444/1762] D loss: 1.3819\n",
      "[1524/1762] D loss: 1.3830\n",
      "[1604/1762] D loss: 1.3863\n",
      "[1684/1762] D loss: 1.3781\n",
      "[1762/1762] D loss: 1.3887\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     train(run_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdisc_only_perturbed\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[112], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(run_name, disc_cls, perturb_num)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m train_loop(train_dataloader, disc, loss_fn, optimizer_disc, perturb_num)\n\u001b[1;32m---> 17\u001b[0m test_loop(\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m, train_dataloader, disc, loss_fn, tb_writer, epoch, perturb_num)\n\u001b[0;32m     18\u001b[0m test_loop(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, test_dataloader, disc, loss_fn, tb_writer, epoch, perturb_num)\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m name, weight \u001b[39min\u001b[39;00m disc\u001b[39m.\u001b[39mnamed_parameters():\n",
      "Cell \u001b[1;32mIn[111], line 65\u001b[0m, in \u001b[0;36mtest_loop\u001b[1;34m(split_name, dataloader, disc, loss_fn, tb_writer, epoch, perturb_num)\u001b[0m\n\u001b[0;32m     62\u001b[0m output_real \u001b[39m=\u001b[39m disc(X, y)\n\u001b[0;32m     63\u001b[0m loss_disc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(output_real, real_labels)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m---> 65\u001b[0m y_fake \u001b[39m=\u001b[39m perturb_data(y, perturb_num)\n\u001b[0;32m     66\u001b[0m output_fake \u001b[39m=\u001b[39m disc(X, y_fake)\n\u001b[0;32m     68\u001b[0m loss_disc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(output_fake, fake_labels)\u001b[39m.\u001b[39mitem()\n",
      "Cell \u001b[1;32mIn[109], line 14\u001b[0m, in \u001b[0;36mperturb_data\u001b[1;34m(y, num)\u001b[0m\n\u001b[0;32m     12\u001b[0m         i \u001b[39m=\u001b[39m i_[batch, repeat]\n\u001b[0;32m     13\u001b[0m         j \u001b[39m=\u001b[39m j_[batch, repeat]\n\u001b[1;32m---> 14\u001b[0m         y[batch, :, i, j] \u001b[39m=\u001b[39m y_flipped[batch, :, i, j]\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    train(run_name=\"disc_only_perturbed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discriminator fails to learn the difference. This could be because the discriminator architecture isn't good enough, or it could be because the task starts out too difficult. Let's try increasing the number of perturbations to see if this discriminator architecture can succeed on _some_ variant of this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5771\n",
      "[84/1762] D loss: 1.3010\n",
      "[164/1762] D loss: 1.2541\n",
      "[244/1762] D loss: 1.0397\n",
      "[324/1762] D loss: 0.5639\n",
      "[404/1762] D loss: 0.5956\n",
      "[484/1762] D loss: 0.1088\n",
      "[564/1762] D loss: 0.0952\n",
      "[644/1762] D loss: 0.0437\n",
      "[724/1762] D loss: 0.0602\n",
      "[804/1762] D loss: 0.0304\n",
      "[884/1762] D loss: 0.0435\n",
      "[964/1762] D loss: 0.0247\n",
      "[1044/1762] D loss: 0.0157\n",
      "[1124/1762] D loss: 0.0219\n",
      "[1204/1762] D loss: 0.0065\n",
      "[1284/1762] D loss: 0.0137\n",
      "[1364/1762] D loss: 0.0072\n",
      "[1444/1762] D loss: 0.0067\n",
      "[1524/1762] D loss: 0.0054\n",
      "[1604/1762] D loss: 0.0088\n",
      "[1684/1762] D loss: 0.0065\n",
      "[1762/1762] D loss: 0.0050\n",
      "train error: \n",
      " D loss: 0.031289, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.030356, D accuracy: 100.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0044\n",
      "[84/1762] D loss: 0.0134\n",
      "[164/1762] D loss: 0.0112\n",
      "[244/1762] D loss: 0.0039\n",
      "[324/1762] D loss: 0.0068\n",
      "[404/1762] D loss: 0.0020\n",
      "[484/1762] D loss: 0.0044\n",
      "[564/1762] D loss: 0.0028\n",
      "[644/1762] D loss: 0.0022\n",
      "[724/1762] D loss: 0.0070\n",
      "[804/1762] D loss: 0.0026\n",
      "[884/1762] D loss: 0.0013\n",
      "[964/1762] D loss: 0.0018\n",
      "[1044/1762] D loss: 0.0018\n",
      "[1124/1762] D loss: 0.0023\n",
      "[1204/1762] D loss: 0.0053\n",
      "[1284/1762] D loss: 0.0021\n",
      "[1364/1762] D loss: 0.0029\n",
      "[1444/1762] D loss: 0.0011\n",
      "[1524/1762] D loss: 0.0155\n",
      "[1604/1762] D loss: 0.0015\n",
      "[1684/1762] D loss: 0.0015\n",
      "[1762/1762] D loss: 0.0011\n",
      "train error: \n",
      " D loss: 0.021573, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.021378, D accuracy: 100.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0080\n",
      "[164/1762] D loss: 0.0015\n",
      "[244/1762] D loss: 0.0024\n",
      "[324/1762] D loss: 0.0168\n",
      "[404/1762] D loss: 0.0012\n",
      "[484/1762] D loss: 0.0015\n",
      "[564/1762] D loss: 0.0011\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0016\n",
      "[884/1762] D loss: 0.0007\n",
      "[964/1762] D loss: 0.0015\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0008\n",
      "[1204/1762] D loss: 0.0020\n",
      "[1284/1762] D loss: 0.0007\n",
      "[1364/1762] D loss: 0.0006\n",
      "[1444/1762] D loss: 0.0011\n",
      "[1524/1762] D loss: 0.0007\n",
      "[1604/1762] D loss: 0.0022\n",
      "[1684/1762] D loss: 0.0008\n",
      "[1762/1762] D loss: 0.0010\n",
      "train error: \n",
      " D loss: 0.016977, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.016838, D accuracy: 100.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0014\n",
      "[164/1762] D loss: 0.0009\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0007\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0013\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0007\n",
      "[724/1762] D loss: 0.0009\n",
      "[804/1762] D loss: 0.0025\n",
      "[884/1762] D loss: 0.0007\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0048\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0025\n",
      "[1284/1762] D loss: 0.0063\n",
      "[1364/1762] D loss: 0.0007\n",
      "[1444/1762] D loss: 0.0006\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0036\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0016\n",
      "train error: \n",
      " D loss: 0.018543, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.018280, D accuracy: 100.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0013\n",
      "[84/1762] D loss: 0.0007\n",
      "[164/1762] D loss: 0.0005\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0023\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0008\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0010\n",
      "[964/1762] D loss: 0.0009\n",
      "[1044/1762] D loss: 0.0005\n",
      "[1124/1762] D loss: 0.0012\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0005\n",
      "[1364/1762] D loss: 0.0011\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0018\n",
      "train error: \n",
      " D loss: 0.015027, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.014770, D accuracy: 100.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0006\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0018\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0013\n",
      "[564/1762] D loss: 0.0004\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0012\n",
      "[884/1762] D loss: 0.0007\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0132\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.014433, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.014244, D accuracy: 100.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0009\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0006\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0013\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0005\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0006\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.012877, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.012746, D accuracy: 100.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0006\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0039\n",
      "[804/1762] D loss: 0.0009\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0012\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.011513, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.011359, D accuracy: 100.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0025\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0006\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.008912, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.008758, D accuracy: 100.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.013889, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.013590, D accuracy: 100.0% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for perturb_num in [20]:\n",
    "    train(run_name=f\"perturb_{perturb_num}\", perturb_num=perturb_num, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 20 perturbations, the model learns easily. Let's try reducing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4080\n",
      "[84/1762] D loss: 1.3617\n",
      "[164/1762] D loss: 1.2850\n",
      "[244/1762] D loss: 1.3432\n",
      "[324/1762] D loss: 1.2020\n",
      "[404/1762] D loss: 1.1239\n",
      "[484/1762] D loss: 0.7668\n",
      "[564/1762] D loss: 0.7501\n",
      "[644/1762] D loss: 0.2956\n",
      "[724/1762] D loss: 1.3914\n",
      "[804/1762] D loss: 0.0563\n",
      "[884/1762] D loss: 0.0329\n",
      "[964/1762] D loss: 0.0500\n",
      "[1044/1762] D loss: 0.0386\n",
      "[1124/1762] D loss: 0.0275\n",
      "[1204/1762] D loss: 0.0175\n",
      "[1284/1762] D loss: 0.0099\n",
      "[1364/1762] D loss: 0.0085\n",
      "[1444/1762] D loss: 0.0079\n",
      "[1524/1762] D loss: 0.0070\n",
      "[1604/1762] D loss: 0.0052\n",
      "[1684/1762] D loss: 0.0042\n",
      "[1762/1762] D loss: 0.0283\n",
      "train error: \n",
      " D loss: 0.124173, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.129760, D accuracy: 100.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0078\n",
      "[84/1762] D loss: 0.0225\n",
      "[164/1762] D loss: 0.0041\n",
      "[244/1762] D loss: 0.0026\n",
      "[324/1762] D loss: 0.0033\n",
      "[404/1762] D loss: 0.0022\n",
      "[484/1762] D loss: 0.0102\n",
      "[564/1762] D loss: 0.0146\n",
      "[644/1762] D loss: 0.0019\n",
      "[724/1762] D loss: 0.0059\n",
      "[804/1762] D loss: 0.0020\n",
      "[884/1762] D loss: 0.0042\n",
      "[964/1762] D loss: 0.0040\n",
      "[1044/1762] D loss: 0.0015\n",
      "[1124/1762] D loss: 0.0047\n",
      "[1204/1762] D loss: 0.0074\n",
      "[1284/1762] D loss: 0.0052\n",
      "[1364/1762] D loss: 0.0045\n",
      "[1444/1762] D loss: 0.0069\n",
      "[1524/1762] D loss: 0.0014\n",
      "[1604/1762] D loss: 0.0019\n",
      "[1684/1762] D loss: 0.0009\n",
      "[1762/1762] D loss: 0.0016\n",
      "train error: \n",
      " D loss: 0.105913, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.110639, D accuracy: 100.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0065\n",
      "[84/1762] D loss: 0.0008\n",
      "[164/1762] D loss: 0.0020\n",
      "[244/1762] D loss: 0.0023\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0026\n",
      "[484/1762] D loss: 0.0008\n",
      "[564/1762] D loss: 0.0033\n",
      "[644/1762] D loss: 0.0008\n",
      "[724/1762] D loss: 0.0035\n",
      "[804/1762] D loss: 0.0282\n",
      "[884/1762] D loss: 0.0012\n",
      "[964/1762] D loss: 0.0010\n",
      "[1044/1762] D loss: 0.0006\n",
      "[1124/1762] D loss: 0.0025\n",
      "[1204/1762] D loss: 0.0008\n",
      "[1284/1762] D loss: 0.0008\n",
      "[1364/1762] D loss: 0.0004\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0040\n",
      "[1604/1762] D loss: 0.0029\n",
      "[1684/1762] D loss: 0.0016\n",
      "[1762/1762] D loss: 0.0025\n",
      "train error: \n",
      " D loss: 0.172432, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.181475, D accuracy: 100.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0017\n",
      "[84/1762] D loss: 0.0012\n",
      "[164/1762] D loss: 0.0059\n",
      "[244/1762] D loss: 0.0006\n",
      "[324/1762] D loss: 0.0007\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0007\n",
      "[564/1762] D loss: 0.0010\n",
      "[644/1762] D loss: 0.0013\n",
      "[724/1762] D loss: 0.0011\n",
      "[804/1762] D loss: 0.0042\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0007\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0034\n",
      "[1364/1762] D loss: 0.0013\n",
      "[1444/1762] D loss: 0.0008\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0017\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.140777, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.148012, D accuracy: 100.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0018\n",
      "[84/1762] D loss: 0.0069\n",
      "[164/1762] D loss: 0.0007\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0006\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0008\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0009\n",
      "[1364/1762] D loss: 0.0005\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0008\n",
      "[1762/1762] D loss: 0.0015\n",
      "train error: \n",
      " D loss: 0.142799, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.150103, D accuracy: 100.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0022\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0023\n",
      "[724/1762] D loss: 0.0015\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0007\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0013\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0008\n",
      "[1604/1762] D loss: 0.0006\n",
      "[1684/1762] D loss: 0.0012\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 0.149875, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.157415, D accuracy: 100.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0010\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0821\n",
      "[484/1762] D loss: 0.0105\n",
      "[564/1762] D loss: 0.0099\n",
      "[644/1762] D loss: 0.0097\n",
      "[724/1762] D loss: 0.0060\n",
      "[804/1762] D loss: 0.0060\n",
      "[884/1762] D loss: 0.0008\n",
      "[964/1762] D loss: 0.0038\n",
      "[1044/1762] D loss: 0.0894\n",
      "[1124/1762] D loss: 0.0038\n",
      "[1204/1762] D loss: 0.0040\n",
      "[1284/1762] D loss: 0.0050\n",
      "[1364/1762] D loss: 0.0035\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0008\n",
      "[1604/1762] D loss: 0.0014\n",
      "[1684/1762] D loss: 0.0011\n",
      "[1762/1762] D loss: 0.0005\n",
      "train error: \n",
      " D loss: 0.086321, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.090939, D accuracy: 100.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0022\n",
      "[84/1762] D loss: 0.0032\n",
      "[164/1762] D loss: 0.0014\n",
      "[244/1762] D loss: 0.0010\n",
      "[324/1762] D loss: 0.0017\n",
      "[404/1762] D loss: 0.0013\n",
      "[484/1762] D loss: 0.0022\n",
      "[564/1762] D loss: 0.0010\n",
      "[644/1762] D loss: 0.0012\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0030\n",
      "[884/1762] D loss: 0.0021\n",
      "[964/1762] D loss: 0.0023\n",
      "[1044/1762] D loss: 0.0019\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0018\n",
      "[1284/1762] D loss: 0.0005\n",
      "[1364/1762] D loss: 0.0005\n",
      "[1444/1762] D loss: 0.0015\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0023\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0029\n",
      "train error: \n",
      " D loss: 0.084122, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.088658, D accuracy: 100.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0013\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0012\n",
      "[324/1762] D loss: 0.0007\n",
      "[404/1762] D loss: 0.0008\n",
      "[484/1762] D loss: 0.0008\n",
      "[564/1762] D loss: 0.0021\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0016\n",
      "[804/1762] D loss: 0.0013\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0009\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0015\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0086\n",
      "[1684/1762] D loss: 0.0008\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.088534, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.093165, D accuracy: 100.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0014\n",
      "[164/1762] D loss: 0.0017\n",
      "[244/1762] D loss: 0.0005\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0005\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0015\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0012\n",
      "[1204/1762] D loss: 0.0165\n",
      "[1284/1762] D loss: 0.0017\n",
      "[1364/1762] D loss: 0.0008\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0006\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.102672, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.107502, D accuracy: 100.0% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for perturb_num in [10]:\n",
    "    train(run_name=f\"perturb_{perturb_num}\", perturb_num=perturb_num, epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 10 perturbations, the loss is a bit higher, but we still get 100% training and test accuracy within 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903\n",
      "[84/1762] D loss: 1.3958\n",
      "[164/1762] D loss: 1.3777\n",
      "[244/1762] D loss: 1.3919\n",
      "[324/1762] D loss: 1.3784\n",
      "[404/1762] D loss: 1.3854\n",
      "[484/1762] D loss: 1.3724\n",
      "[564/1762] D loss: 1.3850\n",
      "[644/1762] D loss: 1.3795\n",
      "[724/1762] D loss: 1.3760\n",
      "[804/1762] D loss: 1.3632\n",
      "[884/1762] D loss: 1.3328\n",
      "[964/1762] D loss: 1.3593\n",
      "[1044/1762] D loss: 1.3674\n",
      "[1124/1762] D loss: 1.3672\n",
      "[1204/1762] D loss: 1.3441\n",
      "[1284/1762] D loss: 1.3414\n",
      "[1364/1762] D loss: 1.3580\n",
      "[1444/1762] D loss: 1.2776\n",
      "[1524/1762] D loss: 1.3506\n",
      "[1604/1762] D loss: 1.2070\n",
      "[1684/1762] D loss: 1.2633\n",
      "[1762/1762] D loss: 1.2085\n",
      "train error: \n",
      " D loss: 1.230228, D accuracy: 76.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.238164, D accuracy: 75.8% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1309\n",
      "[84/1762] D loss: 1.2966\n",
      "[164/1762] D loss: 1.0203\n",
      "[244/1762] D loss: 0.9868\n",
      "[324/1762] D loss: 0.8806\n",
      "[404/1762] D loss: 1.1621\n",
      "[484/1762] D loss: 0.9313\n",
      "[564/1762] D loss: 1.0454\n",
      "[644/1762] D loss: 0.7706\n",
      "[724/1762] D loss: 0.7789\n",
      "[804/1762] D loss: 0.5469\n",
      "[884/1762] D loss: 0.3578\n",
      "[964/1762] D loss: 0.9664\n",
      "[1044/1762] D loss: 1.5087\n",
      "[1124/1762] D loss: 0.5709\n",
      "[1204/1762] D loss: 0.4099\n",
      "[1284/1762] D loss: 0.2307\n",
      "[1364/1762] D loss: 0.1879\n",
      "[1444/1762] D loss: 0.2552\n",
      "[1524/1762] D loss: 0.6350\n",
      "[1604/1762] D loss: 0.2915\n",
      "[1684/1762] D loss: 0.3990\n",
      "[1762/1762] D loss: 1.4627\n",
      "train error: \n",
      " D loss: 2.107393, D accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.104501, D accuracy: 56.8% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0309\n",
      "[84/1762] D loss: 0.3087\n",
      "[164/1762] D loss: 0.4328\n",
      "[244/1762] D loss: 0.0328\n",
      "[324/1762] D loss: 0.1157\n",
      "[404/1762] D loss: 0.0629\n",
      "[484/1762] D loss: 0.0429\n",
      "[564/1762] D loss: 0.0317\n",
      "[644/1762] D loss: 0.0343\n",
      "[724/1762] D loss: 0.0191\n",
      "[804/1762] D loss: 0.0051\n",
      "[884/1762] D loss: 0.0055\n",
      "[964/1762] D loss: 0.1116\n",
      "[1044/1762] D loss: 0.0045\n",
      "[1124/1762] D loss: 0.0027\n",
      "[1204/1762] D loss: 0.0065\n",
      "[1284/1762] D loss: 0.0056\n",
      "[1364/1762] D loss: 0.0055\n",
      "[1444/1762] D loss: 0.0020\n",
      "[1524/1762] D loss: 0.0376\n",
      "[1604/1762] D loss: 0.0036\n",
      "[1684/1762] D loss: 0.0019\n",
      "[1762/1762] D loss: 0.0013\n",
      "train error: \n",
      " D loss: 1.659768, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.671682, D accuracy: 50.1% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0127\n",
      "[84/1762] D loss: 0.0028\n",
      "[164/1762] D loss: 0.0029\n",
      "[244/1762] D loss: 0.0046\n",
      "[324/1762] D loss: 0.0040\n",
      "[404/1762] D loss: 0.0016\n",
      "[484/1762] D loss: 0.0024\n",
      "[564/1762] D loss: 0.0061\n",
      "[644/1762] D loss: 0.0012\n",
      "[724/1762] D loss: 0.0012\n",
      "[804/1762] D loss: 0.0019\n",
      "[884/1762] D loss: 0.0171\n",
      "[964/1762] D loss: 0.0153\n",
      "[1044/1762] D loss: 0.0012\n",
      "[1124/1762] D loss: 0.0054\n",
      "[1204/1762] D loss: 0.0054\n",
      "[1284/1762] D loss: 0.0023\n",
      "[1364/1762] D loss: 0.0012\n",
      "[1444/1762] D loss: 0.0009\n",
      "[1524/1762] D loss: 0.0007\n",
      "[1604/1762] D loss: 0.0008\n",
      "[1684/1762] D loss: 0.0054\n",
      "[1762/1762] D loss: 0.0112\n",
      "train error: \n",
      " D loss: 2.511968, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.512738, D accuracy: 50.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0017\n",
      "[84/1762] D loss: 0.0006\n",
      "[164/1762] D loss: 0.0013\n",
      "[244/1762] D loss: 0.0015\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0010\n",
      "[484/1762] D loss: 0.0058\n",
      "[564/1762] D loss: 0.0009\n",
      "[644/1762] D loss: 0.0011\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0017\n",
      "[884/1762] D loss: 0.0005\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0016\n",
      "[1124/1762] D loss: 0.0013\n",
      "[1204/1762] D loss: 0.0010\n",
      "[1284/1762] D loss: 0.0007\n",
      "[1364/1762] D loss: 0.0012\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0008\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0164\n",
      "[1762/1762] D loss: 0.0012\n",
      "train error: \n",
      " D loss: 3.293928, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.295051, D accuracy: 50.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0012\n",
      "[84/1762] D loss: 0.0009\n",
      "[164/1762] D loss: 0.0006\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0010\n",
      "[404/1762] D loss: 0.0009\n",
      "[484/1762] D loss: 0.0007\n",
      "[564/1762] D loss: 0.0008\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0009\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0008\n",
      "[964/1762] D loss: 0.0012\n",
      "[1044/1762] D loss: 0.0012\n",
      "[1124/1762] D loss: 0.0009\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0006\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0008\n",
      "[1762/1762] D loss: 0.0010\n",
      "train error: \n",
      " D loss: 3.607047, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.606334, D accuracy: 50.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0009\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0063\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0005\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0008\n",
      "[1524/1762] D loss: 0.0015\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 3.425580, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.425831, D accuracy: 50.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0032\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0017\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 4.057694, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.064003, D accuracy: 50.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0005\n",
      "[164/1762] D loss: 0.0016\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0008\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0006\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0006\n",
      "train error: \n",
      " D loss: 4.000562, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.007292, D accuracy: 50.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0745\n",
      "[84/1762] D loss: 0.0096\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0015\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0011\n",
      "[564/1762] D loss: 0.0008\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0007\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0012\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0024\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0124\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0007\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 4.274371, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.282774, D accuracy: 50.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0011\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0004\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0009\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 4.468751, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.474498, D accuracy: 50.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0015\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 4.521292, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.534174, D accuracy: 50.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0005\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0054\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0015\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0008\n",
      "[1284/1762] D loss: 0.0007\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 4.689170, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.702422, D accuracy: 50.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0018\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0025\n",
      "train error: \n",
      " D loss: 4.889845, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.904021, D accuracy: 50.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0078\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0004\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0015\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 5.073625, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.087309, D accuracy: 50.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0005\n",
      "[804/1762] D loss: 0.0009\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 4.896380, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.908425, D accuracy: 50.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0007\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0006\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 5.183583, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.200105, D accuracy: 50.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0008\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0005\n",
      "train error: \n",
      " D loss: 5.361014, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.376248, D accuracy: 50.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0004\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0005\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0009\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 5.051045, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.074142, D accuracy: 50.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 5.032959, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.055066, D accuracy: 50.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3756\n",
      "[84/1762] D loss: 1.3627\n",
      "[164/1762] D loss: 1.3434\n",
      "[244/1762] D loss: 1.3471\n",
      "[324/1762] D loss: 1.3726\n",
      "[404/1762] D loss: 1.3127\n",
      "[484/1762] D loss: 1.3344\n",
      "[564/1762] D loss: 1.3144\n",
      "[644/1762] D loss: 1.3245\n",
      "[724/1762] D loss: 1.1721\n",
      "[804/1762] D loss: 1.0158\n",
      "[884/1762] D loss: 1.0615\n",
      "[964/1762] D loss: 1.0690\n",
      "[1044/1762] D loss: 0.6574\n",
      "[1124/1762] D loss: 0.3986\n",
      "[1204/1762] D loss: 0.6931\n",
      "[1284/1762] D loss: 0.6713\n",
      "[1364/1762] D loss: 0.1788\n",
      "[1444/1762] D loss: 0.0515\n",
      "[1524/1762] D loss: 0.0983\n",
      "[1604/1762] D loss: 0.0410\n",
      "[1684/1762] D loss: 0.0289\n",
      "[1762/1762] D loss: 0.1162\n",
      "train error: \n",
      " D loss: 0.653789, D accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.668023, D accuracy: 79.8% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1291\n",
      "[84/1762] D loss: 0.0758\n",
      "[164/1762] D loss: 1.6021\n",
      "[244/1762] D loss: 0.1763\n",
      "[324/1762] D loss: 0.1277\n",
      "[404/1762] D loss: 0.1814\n",
      "[484/1762] D loss: 0.1841\n",
      "[564/1762] D loss: 0.0131\n",
      "[644/1762] D loss: 0.0101\n",
      "[724/1762] D loss: 0.0059\n",
      "[804/1762] D loss: 0.0093\n",
      "[884/1762] D loss: 0.0088\n",
      "[964/1762] D loss: 0.0028\n",
      "[1044/1762] D loss: 0.0040\n",
      "[1124/1762] D loss: 0.0017\n",
      "[1204/1762] D loss: 0.0626\n",
      "[1284/1762] D loss: 0.0038\n",
      "[1364/1762] D loss: 0.0075\n",
      "[1444/1762] D loss: 0.0024\n",
      "[1524/1762] D loss: 0.0071\n",
      "[1604/1762] D loss: 0.0030\n",
      "[1684/1762] D loss: 0.0011\n",
      "[1762/1762] D loss: 0.0013\n",
      "train error: \n",
      " D loss: 0.347185, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.345754, D accuracy: 99.8% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0016\n",
      "[84/1762] D loss: 0.0199\n",
      "[164/1762] D loss: 0.0012\n",
      "[244/1762] D loss: 0.0024\n",
      "[324/1762] D loss: 0.0009\n",
      "[404/1762] D loss: 0.0022\n",
      "[484/1762] D loss: 0.0016\n",
      "[564/1762] D loss: 0.0009\n",
      "[644/1762] D loss: 0.0022\n",
      "[724/1762] D loss: 0.0028\n",
      "[804/1762] D loss: 0.0011\n",
      "[884/1762] D loss: 0.0058\n",
      "[964/1762] D loss: 0.0074\n",
      "[1044/1762] D loss: 0.0014\n",
      "[1124/1762] D loss: 0.0367\n",
      "[1204/1762] D loss: 0.0055\n",
      "[1284/1762] D loss: 0.0008\n",
      "[1364/1762] D loss: 0.0017\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0019\n",
      "[1684/1762] D loss: 0.0118\n",
      "[1762/1762] D loss: 0.0019\n",
      "train error: \n",
      " D loss: 1.004199, D accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.005627, D accuracy: 50.9% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0020\n",
      "[84/1762] D loss: 0.0054\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0008\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0006\n",
      "[484/1762] D loss: 0.0060\n",
      "[564/1762] D loss: 0.0108\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0007\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0010\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0008\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0010\n",
      "[1604/1762] D loss: 0.0006\n",
      "[1684/1762] D loss: 0.0008\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.946294, D accuracy: 51.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.941355, D accuracy: 51.7% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0071\n",
      "[164/1762] D loss: 0.0015\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0013\n",
      "[564/1762] D loss: 0.0007\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0006\n",
      "[804/1762] D loss: 0.0025\n",
      "[884/1762] D loss: 0.0005\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.901947, D accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.899936, D accuracy: 52.6% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0119\n",
      "[244/1762] D loss: 0.0023\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0016\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0136\n",
      "[964/1762] D loss: 0.0103\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0015\n",
      "[1204/1762] D loss: 0.0012\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0023\n",
      "[1684/1762] D loss: 0.0007\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.019131, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.018656, D accuracy: 50.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0007\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0025\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0011\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0012\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0006\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 1.047346, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.046792, D accuracy: 50.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0005\n",
      "[84/1762] D loss: 0.0011\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0017\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0004\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0010\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0078\n",
      "train error: \n",
      " D loss: 1.088085, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.089335, D accuracy: 50.1% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0013\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0015\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0028\n",
      "[484/1762] D loss: 0.0021\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0011\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0016\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0021\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0033\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 1.248811, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249198, D accuracy: 50.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0005\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0147\n",
      "[1524/1762] D loss: 0.0009\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.159178, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.156814, D accuracy: 50.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0010\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0012\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0043\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0011\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.256863, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256534, D accuracy: 50.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0011\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0009\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.259479, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257349, D accuracy: 50.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0005\n",
      "[244/1762] D loss: 0.0130\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0015\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0008\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 1.423696, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.425941, D accuracy: 50.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.301895, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296020, D accuracy: 50.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0044\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0014\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.653976, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.648971, D accuracy: 50.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0009\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.586095, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.583326, D accuracy: 50.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0048\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0019\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.353642, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350188, D accuracy: 50.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0019\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.627284, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.622380, D accuracy: 50.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.483714, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.479477, D accuracy: 50.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0021\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.496756, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.491901, D accuracy: 50.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3765\n",
      "[84/1762] D loss: 1.3968\n",
      "[164/1762] D loss: 1.3852\n",
      "[244/1762] D loss: 1.3433\n",
      "[324/1762] D loss: 1.3856\n",
      "[404/1762] D loss: 1.3330\n",
      "[484/1762] D loss: 1.3402\n",
      "[564/1762] D loss: 1.3041\n",
      "[644/1762] D loss: 1.2676\n",
      "[724/1762] D loss: 1.1736\n",
      "[804/1762] D loss: 1.1470\n",
      "[884/1762] D loss: 0.9158\n",
      "[964/1762] D loss: 0.9823\n",
      "[1044/1762] D loss: 0.4472\n",
      "[1124/1762] D loss: 0.6458\n",
      "[1204/1762] D loss: 0.5144\n",
      "[1284/1762] D loss: 1.1759\n",
      "[1364/1762] D loss: 0.3385\n",
      "[1444/1762] D loss: 0.1266\n",
      "[1524/1762] D loss: 0.2572\n",
      "[1604/1762] D loss: 0.1183\n",
      "[1684/1762] D loss: 0.1051\n",
      "[1762/1762] D loss: 0.0206\n",
      "train error: \n",
      " D loss: 0.254141, D accuracy: 99.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.272693, D accuracy: 98.3% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0296\n",
      "[84/1762] D loss: 0.0175\n",
      "[164/1762] D loss: 0.0329\n",
      "[244/1762] D loss: 0.9833\n",
      "[324/1762] D loss: 0.2386\n",
      "[404/1762] D loss: 0.0647\n",
      "[484/1762] D loss: 0.0335\n",
      "[564/1762] D loss: 0.4210\n",
      "[644/1762] D loss: 1.2992\n",
      "[724/1762] D loss: 0.0481\n",
      "[804/1762] D loss: 0.0229\n",
      "[884/1762] D loss: 0.0667\n",
      "[964/1762] D loss: 0.0709\n",
      "[1044/1762] D loss: 0.0311\n",
      "[1124/1762] D loss: 0.0234\n",
      "[1204/1762] D loss: 0.0069\n",
      "[1284/1762] D loss: 0.0120\n",
      "[1364/1762] D loss: 0.0419\n",
      "[1444/1762] D loss: 0.0072\n",
      "[1524/1762] D loss: 0.1395\n",
      "[1604/1762] D loss: 0.0371\n",
      "[1684/1762] D loss: 0.0057\n",
      "[1762/1762] D loss: 0.0247\n",
      "train error: \n",
      " D loss: 0.077432, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.079725, D accuracy: 99.8% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0827\n",
      "[84/1762] D loss: 0.0131\n",
      "[164/1762] D loss: 0.0558\n",
      "[244/1762] D loss: 0.0096\n",
      "[324/1762] D loss: 0.0036\n",
      "[404/1762] D loss: 0.0067\n",
      "[484/1762] D loss: 0.0089\n",
      "[564/1762] D loss: 0.0028\n",
      "[644/1762] D loss: 0.0029\n",
      "[724/1762] D loss: 0.0019\n",
      "[804/1762] D loss: 0.0036\n",
      "[884/1762] D loss: 0.0030\n",
      "[964/1762] D loss: 0.0031\n",
      "[1044/1762] D loss: 0.0055\n",
      "[1124/1762] D loss: 0.0835\n",
      "[1204/1762] D loss: 0.0113\n",
      "[1284/1762] D loss: 0.0020\n",
      "[1364/1762] D loss: 0.0014\n",
      "[1444/1762] D loss: 0.0017\n",
      "[1524/1762] D loss: 0.0022\n",
      "[1604/1762] D loss: 0.0009\n",
      "[1684/1762] D loss: 0.0030\n",
      "[1762/1762] D loss: 0.0084\n",
      "train error: \n",
      " D loss: 0.052534, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.059310, D accuracy: 99.8% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0030\n",
      "[84/1762] D loss: 0.0024\n",
      "[164/1762] D loss: 0.0040\n",
      "[244/1762] D loss: 0.0048\n",
      "[324/1762] D loss: 0.0045\n",
      "[404/1762] D loss: 0.0018\n",
      "[484/1762] D loss: 0.0024\n",
      "[564/1762] D loss: 0.0017\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0016\n",
      "[804/1762] D loss: 0.0017\n",
      "[884/1762] D loss: 0.0007\n",
      "[964/1762] D loss: 0.0974\n",
      "[1044/1762] D loss: 0.0013\n",
      "[1124/1762] D loss: 0.0011\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0166\n",
      "[1364/1762] D loss: 0.0018\n",
      "[1444/1762] D loss: 0.0033\n",
      "[1524/1762] D loss: 0.0006\n",
      "[1604/1762] D loss: 0.0019\n",
      "[1684/1762] D loss: 0.0011\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 0.094331, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.096560, D accuracy: 99.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0038\n",
      "[84/1762] D loss: 0.0016\n",
      "[164/1762] D loss: 0.0015\n",
      "[244/1762] D loss: 0.0018\n",
      "[324/1762] D loss: 0.0009\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0009\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0013\n",
      "[804/1762] D loss: 0.0006\n",
      "[884/1762] D loss: 0.0009\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0009\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0027\n",
      "[1364/1762] D loss: 0.0004\n",
      "[1444/1762] D loss: 0.0106\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0007\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0012\n",
      "train error: \n",
      " D loss: 0.110611, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.115377, D accuracy: 99.8% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0102\n",
      "[84/1762] D loss: 0.0011\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0007\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0004\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0008\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0012\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.2118\n",
      "[1444/1762] D loss: 0.0622\n",
      "[1524/1762] D loss: 0.0168\n",
      "[1604/1762] D loss: 0.0093\n",
      "[1684/1762] D loss: 0.0046\n",
      "[1762/1762] D loss: 0.0053\n",
      "train error: \n",
      " D loss: 0.250777, D accuracy: 98.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.238031, D accuracy: 99.3% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0182\n",
      "[84/1762] D loss: 0.0032\n",
      "[164/1762] D loss: 0.0138\n",
      "[244/1762] D loss: 0.0016\n",
      "[324/1762] D loss: 0.0025\n",
      "[404/1762] D loss: 0.0028\n",
      "[484/1762] D loss: 0.0030\n",
      "[564/1762] D loss: 0.0020\n",
      "[644/1762] D loss: 0.0019\n",
      "[724/1762] D loss: 0.0043\n",
      "[804/1762] D loss: 0.0048\n",
      "[884/1762] D loss: 0.0025\n",
      "[964/1762] D loss: 0.0071\n",
      "[1044/1762] D loss: 0.0023\n",
      "[1124/1762] D loss: 0.0042\n",
      "[1204/1762] D loss: 0.0066\n",
      "[1284/1762] D loss: 0.0030\n",
      "[1364/1762] D loss: 0.0004\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0024\n",
      "[1604/1762] D loss: 0.0047\n",
      "[1684/1762] D loss: 0.0019\n",
      "[1762/1762] D loss: 0.0011\n",
      "train error: \n",
      " D loss: 0.104621, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.107291, D accuracy: 99.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0010\n",
      "[84/1762] D loss: 0.0018\n",
      "[164/1762] D loss: 0.0006\n",
      "[244/1762] D loss: 0.0045\n",
      "[324/1762] D loss: 0.0142\n",
      "[404/1762] D loss: 0.0009\n",
      "[484/1762] D loss: 0.0008\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0009\n",
      "[724/1762] D loss: 0.0007\n",
      "[804/1762] D loss: 0.0032\n",
      "[884/1762] D loss: 0.0022\n",
      "[964/1762] D loss: 0.0011\n",
      "[1044/1762] D loss: 0.0078\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0013\n",
      "[1284/1762] D loss: 0.0017\n",
      "[1364/1762] D loss: 0.0020\n",
      "[1444/1762] D loss: 0.0045\n",
      "[1524/1762] D loss: 0.0039\n",
      "[1604/1762] D loss: 0.0007\n",
      "[1684/1762] D loss: 0.0011\n",
      "[1762/1762] D loss: 1.6505\n",
      "train error: \n",
      " D loss: 4.870853, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.792881, D accuracy: 50.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.9943\n",
      "[84/1762] D loss: 0.1829\n",
      "[164/1762] D loss: 0.0412\n",
      "[244/1762] D loss: 0.0506\n",
      "[324/1762] D loss: 0.0308\n",
      "[404/1762] D loss: 0.0383\n",
      "[484/1762] D loss: 0.0124\n",
      "[564/1762] D loss: 0.0193\n",
      "[644/1762] D loss: 0.0025\n",
      "[724/1762] D loss: 0.0345\n",
      "[804/1762] D loss: 0.0114\n",
      "[884/1762] D loss: 0.0061\n",
      "[964/1762] D loss: 0.0019\n",
      "[1044/1762] D loss: 0.0024\n",
      "[1124/1762] D loss: 0.0037\n",
      "[1204/1762] D loss: 0.0067\n",
      "[1284/1762] D loss: 0.0051\n",
      "[1364/1762] D loss: 0.0103\n",
      "[1444/1762] D loss: 0.0106\n",
      "[1524/1762] D loss: 0.0038\n",
      "[1604/1762] D loss: 0.0101\n",
      "[1684/1762] D loss: 0.0118\n",
      "[1762/1762] D loss: 0.0019\n",
      "train error: \n",
      " D loss: 0.120354, D accuracy: 98.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.136902, D accuracy: 98.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0049\n",
      "[84/1762] D loss: 0.0007\n",
      "[164/1762] D loss: 0.0429\n",
      "[244/1762] D loss: 0.0093\n",
      "[324/1762] D loss: 0.0377\n",
      "[404/1762] D loss: 0.0064\n",
      "[484/1762] D loss: 0.0027\n",
      "[564/1762] D loss: 0.0029\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0068\n",
      "[804/1762] D loss: 0.0008\n",
      "[884/1762] D loss: 0.0013\n",
      "[964/1762] D loss: 0.0043\n",
      "[1044/1762] D loss: 0.0018\n",
      "[1124/1762] D loss: 0.0036\n",
      "[1204/1762] D loss: 0.0058\n",
      "[1284/1762] D loss: 0.0011\n",
      "[1364/1762] D loss: 0.0020\n",
      "[1444/1762] D loss: 0.0015\n",
      "[1524/1762] D loss: 0.0021\n",
      "[1604/1762] D loss: 0.0055\n",
      "[1684/1762] D loss: 0.0020\n",
      "[1762/1762] D loss: 0.0074\n",
      "train error: \n",
      " D loss: 0.254767, D accuracy: 97.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.255111, D accuracy: 97.4% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0025\n",
      "[84/1762] D loss: 0.0033\n",
      "[164/1762] D loss: 0.0021\n",
      "[244/1762] D loss: 0.0008\n",
      "[324/1762] D loss: 0.0013\n",
      "[404/1762] D loss: 0.0019\n",
      "[484/1762] D loss: 0.0017\n",
      "[564/1762] D loss: 0.0037\n",
      "[644/1762] D loss: 0.0012\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0011\n",
      "[884/1762] D loss: 0.0009\n",
      "[964/1762] D loss: 0.0033\n",
      "[1044/1762] D loss: 0.0011\n",
      "[1124/1762] D loss: 0.0008\n",
      "[1204/1762] D loss: 0.0009\n",
      "[1284/1762] D loss: 0.0017\n",
      "[1364/1762] D loss: 0.0010\n",
      "[1444/1762] D loss: 0.0018\n",
      "[1524/1762] D loss: 0.0013\n",
      "[1604/1762] D loss: 0.0014\n",
      "[1684/1762] D loss: 0.0064\n",
      "[1762/1762] D loss: 0.0006\n",
      "train error: \n",
      " D loss: 0.180278, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.179479, D accuracy: 99.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0015\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0012\n",
      "[644/1762] D loss: 0.0022\n",
      "[724/1762] D loss: 0.0014\n",
      "[804/1762] D loss: 0.0008\n",
      "[884/1762] D loss: 0.0008\n",
      "[964/1762] D loss: 0.0008\n",
      "[1044/1762] D loss: 0.0019\n",
      "[1124/1762] D loss: 0.0019\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0021\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0108\n",
      "[1524/1762] D loss: 0.0006\n",
      "[1604/1762] D loss: 0.0090\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.220618, D accuracy: 98.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.225657, D accuracy: 98.1% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0019\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0017\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0015\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0011\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0007\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0018\n",
      "[1762/1762] D loss: 0.0007\n",
      "train error: \n",
      " D loss: 0.157165, D accuracy: 99.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.171574, D accuracy: 99.1% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0005\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0012\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0022\n",
      "[964/1762] D loss: 0.0028\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0010\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0025\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0009\n",
      "train error: \n",
      " D loss: 0.219802, D accuracy: 99.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.227209, D accuracy: 98.3% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0007\n",
      "[324/1762] D loss: 0.0010\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0004\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0020\n",
      "[804/1762] D loss: 0.0015\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0014\n",
      "[1044/1762] D loss: 0.0005\n",
      "[1124/1762] D loss: 0.0572\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0009\n",
      "[1364/1762] D loss: 0.0005\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 0.204259, D accuracy: 99.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.208498, D accuracy: 98.6% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0005\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0058\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0011\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0015\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.268414, D accuracy: 98.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.270619, D accuracy: 97.7% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0006\n",
      "[324/1762] D loss: 0.0013\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0010\n",
      "[564/1762] D loss: 0.0010\n",
      "[644/1762] D loss: 0.0094\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0010\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0222\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0015\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0012\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.395652, D accuracy: 94.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.399849, D accuracy: 93.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0009\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0004\n",
      "[644/1762] D loss: 0.0065\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0011\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0004\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0006\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 0.300286, D accuracy: 98.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.305635, D accuracy: 97.3% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0016\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0133\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.190520, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.194980, D accuracy: 99.3% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0012\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.270599, D accuracy: 99.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.277171, D accuracy: 97.8% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4018\n",
      "[84/1762] D loss: 1.3870\n",
      "[164/1762] D loss: 1.3492\n",
      "[244/1762] D loss: 1.3050\n",
      "[324/1762] D loss: 1.2737\n",
      "[404/1762] D loss: 1.2346\n",
      "[484/1762] D loss: 1.0018\n",
      "[564/1762] D loss: 0.7736\n",
      "[644/1762] D loss: 0.7314\n",
      "[724/1762] D loss: 0.7948\n",
      "[804/1762] D loss: 0.1368\n",
      "[884/1762] D loss: 0.2255\n",
      "[964/1762] D loss: 0.0555\n",
      "[1044/1762] D loss: 0.1357\n",
      "[1124/1762] D loss: 0.0117\n",
      "[1204/1762] D loss: 0.1315\n",
      "[1284/1762] D loss: 0.0112\n",
      "[1364/1762] D loss: 0.0098\n",
      "[1444/1762] D loss: 0.0069\n",
      "[1524/1762] D loss: 0.0080\n",
      "[1604/1762] D loss: 0.0138\n",
      "[1684/1762] D loss: 0.0189\n",
      "[1762/1762] D loss: 0.0953\n",
      "train error: \n",
      " D loss: 0.142214, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.153120, D accuracy: 99.9% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0635\n",
      "[84/1762] D loss: 0.0105\n",
      "[164/1762] D loss: 0.0050\n",
      "[244/1762] D loss: 0.0222\n",
      "[324/1762] D loss: 0.8291\n",
      "[404/1762] D loss: 0.3682\n",
      "[484/1762] D loss: 0.0705\n",
      "[564/1762] D loss: 0.0069\n",
      "[644/1762] D loss: 0.0050\n",
      "[724/1762] D loss: 0.0196\n",
      "[804/1762] D loss: 0.0043\n",
      "[884/1762] D loss: 0.0084\n",
      "[964/1762] D loss: 0.0414\n",
      "[1044/1762] D loss: 0.0023\n",
      "[1124/1762] D loss: 0.0032\n",
      "[1204/1762] D loss: 0.0035\n",
      "[1284/1762] D loss: 0.0085\n",
      "[1364/1762] D loss: 0.0027\n",
      "[1444/1762] D loss: 0.0022\n",
      "[1524/1762] D loss: 0.0011\n",
      "[1604/1762] D loss: 0.0042\n",
      "[1684/1762] D loss: 0.0089\n",
      "[1762/1762] D loss: 0.0025\n",
      "train error: \n",
      " D loss: 0.093141, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.094944, D accuracy: 100.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0047\n",
      "[84/1762] D loss: 0.0024\n",
      "[164/1762] D loss: 0.0037\n",
      "[244/1762] D loss: 0.0022\n",
      "[324/1762] D loss: 0.0016\n",
      "[404/1762] D loss: 0.0027\n",
      "[484/1762] D loss: 0.0012\n",
      "[564/1762] D loss: 0.0020\n",
      "[644/1762] D loss: 0.0013\n",
      "[724/1762] D loss: 0.0028\n",
      "[804/1762] D loss: 0.0037\n",
      "[884/1762] D loss: 0.0008\n",
      "[964/1762] D loss: 0.0018\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0070\n",
      "[1204/1762] D loss: 0.0027\n",
      "[1284/1762] D loss: 3.1055\n",
      "[1364/1762] D loss: 1.3631\n",
      "[1444/1762] D loss: 1.2770\n",
      "[1524/1762] D loss: 1.3162\n",
      "[1604/1762] D loss: 1.2726\n",
      "[1684/1762] D loss: 1.0870\n",
      "[1762/1762] D loss: 1.3441\n",
      "train error: \n",
      " D loss: 2.646941, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.655992, D accuracy: 50.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4481\n",
      "[84/1762] D loss: 1.5015\n",
      "[164/1762] D loss: 0.9621\n",
      "[244/1762] D loss: 0.9265\n",
      "[324/1762] D loss: 0.3906\n",
      "[404/1762] D loss: 0.5734\n",
      "[484/1762] D loss: 1.1548\n",
      "[564/1762] D loss: 0.2244\n",
      "[644/1762] D loss: 0.0352\n",
      "[724/1762] D loss: 0.1212\n",
      "[804/1762] D loss: 0.1158\n",
      "[884/1762] D loss: 0.0324\n",
      "[964/1762] D loss: 0.0269\n",
      "[1044/1762] D loss: 0.0840\n",
      "[1124/1762] D loss: 0.0819\n",
      "[1204/1762] D loss: 0.0033\n",
      "[1284/1762] D loss: 0.0528\n",
      "[1364/1762] D loss: 0.0054\n",
      "[1444/1762] D loss: 0.0089\n",
      "[1524/1762] D loss: 0.0015\n",
      "[1604/1762] D loss: 0.0103\n",
      "[1684/1762] D loss: 0.0032\n",
      "[1762/1762] D loss: 0.0007\n",
      "train error: \n",
      " D loss: 1.061556, D accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.087862, D accuracy: 54.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0040\n",
      "[84/1762] D loss: 0.0005\n",
      "[164/1762] D loss: 0.0029\n",
      "[244/1762] D loss: 0.0011\n",
      "[324/1762] D loss: 0.0007\n",
      "[404/1762] D loss: 0.0019\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0033\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0013\n",
      "[964/1762] D loss: 0.0031\n",
      "[1044/1762] D loss: 0.0007\n",
      "[1124/1762] D loss: 0.0027\n",
      "[1204/1762] D loss: 0.0016\n",
      "[1284/1762] D loss: 0.0007\n",
      "[1364/1762] D loss: 0.0030\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0294\n",
      "[1684/1762] D loss: 0.0044\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.671027, D accuracy: 77.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.686683, D accuracy: 76.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0020\n",
      "[164/1762] D loss: 0.0022\n",
      "[244/1762] D loss: 0.0034\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0015\n",
      "[484/1762] D loss: 0.0024\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0072\n",
      "[724/1762] D loss: 0.0011\n",
      "[804/1762] D loss: 0.0024\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0008\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0117\n",
      "[1444/1762] D loss: 0.0055\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.896615, D accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.916487, D accuracy: 58.3% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0005\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0018\n",
      "[484/1762] D loss: 0.0010\n",
      "[564/1762] D loss: 0.0019\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0014\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0018\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0026\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0037\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.598517, D accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.614128, D accuracy: 84.4% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0055\n",
      "[244/1762] D loss: 0.0025\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0056\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.905873, D accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.929180, D accuracy: 58.4% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0025\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0558\n",
      "[404/1762] D loss: 0.0065\n",
      "[484/1762] D loss: 0.0008\n",
      "[564/1762] D loss: 0.0010\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0019\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0233\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.353470, D accuracy: 51.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380667, D accuracy: 52.2% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0008\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0026\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 1.7038\n",
      "[1364/1762] D loss: 1.3957\n",
      "[1444/1762] D loss: 1.3697\n",
      "[1524/1762] D loss: 1.3816\n",
      "[1604/1762] D loss: 1.3131\n",
      "[1684/1762] D loss: 1.3352\n",
      "[1762/1762] D loss: 1.0695\n",
      "train error: \n",
      " D loss: 1.256221, D accuracy: 62.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258790, D accuracy: 61.8% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3421\n",
      "[84/1762] D loss: 1.3065\n",
      "[164/1762] D loss: 0.9911\n",
      "[244/1762] D loss: 2.2592\n",
      "[324/1762] D loss: 0.8255\n",
      "[404/1762] D loss: 0.7736\n",
      "[484/1762] D loss: 0.3880\n",
      "[564/1762] D loss: 0.3643\n",
      "[644/1762] D loss: 0.2507\n",
      "[724/1762] D loss: 0.3554\n",
      "[804/1762] D loss: 0.9201\n",
      "[884/1762] D loss: 0.1678\n",
      "[964/1762] D loss: 0.0283\n",
      "[1044/1762] D loss: 0.0151\n",
      "[1124/1762] D loss: 0.0334\n",
      "[1204/1762] D loss: 0.0503\n",
      "[1284/1762] D loss: 0.0072\n",
      "[1364/1762] D loss: 0.0287\n",
      "[1444/1762] D loss: 0.0561\n",
      "[1524/1762] D loss: 0.0221\n",
      "[1604/1762] D loss: 0.0088\n",
      "[1684/1762] D loss: 0.0140\n",
      "[1762/1762] D loss: 0.0705\n",
      "train error: \n",
      " D loss: 0.095812, D accuracy: 98.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.095913, D accuracy: 98.4% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0250\n",
      "[84/1762] D loss: 0.0126\n",
      "[164/1762] D loss: 0.0548\n",
      "[244/1762] D loss: 0.0129\n",
      "[324/1762] D loss: 0.0218\n",
      "[404/1762] D loss: 0.0056\n",
      "[484/1762] D loss: 0.0023\n",
      "[564/1762] D loss: 0.0062\n",
      "[644/1762] D loss: 0.0085\n",
      "[724/1762] D loss: 0.0012\n",
      "[804/1762] D loss: 0.0056\n",
      "[884/1762] D loss: 0.0062\n",
      "[964/1762] D loss: 0.0047\n",
      "[1044/1762] D loss: 0.0022\n",
      "[1124/1762] D loss: 0.0027\n",
      "[1204/1762] D loss: 0.0022\n",
      "[1284/1762] D loss: 0.0067\n",
      "[1364/1762] D loss: 0.0038\n",
      "[1444/1762] D loss: 0.0018\n",
      "[1524/1762] D loss: 0.0056\n",
      "[1604/1762] D loss: 0.0100\n",
      "[1684/1762] D loss: 0.0026\n",
      "[1762/1762] D loss: 0.0022\n",
      "train error: \n",
      " D loss: 0.009847, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.016226, D accuracy: 99.8% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0012\n",
      "[84/1762] D loss: 0.0125\n",
      "[164/1762] D loss: 0.0023\n",
      "[244/1762] D loss: 0.0021\n",
      "[324/1762] D loss: 0.0728\n",
      "[404/1762] D loss: 0.0131\n",
      "[484/1762] D loss: 0.0010\n",
      "[564/1762] D loss: 0.0017\n",
      "[644/1762] D loss: 0.0018\n",
      "[724/1762] D loss: 0.0012\n",
      "[804/1762] D loss: 0.0011\n",
      "[884/1762] D loss: 0.0013\n",
      "[964/1762] D loss: 0.0054\n",
      "[1044/1762] D loss: 0.0024\n",
      "[1124/1762] D loss: 0.0012\n",
      "[1204/1762] D loss: 0.0010\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0053\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0008\n",
      "[1604/1762] D loss: 0.0019\n",
      "[1684/1762] D loss: 0.0026\n",
      "[1762/1762] D loss: 0.0031\n",
      "train error: \n",
      " D loss: 0.009603, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.009149, D accuracy: 100.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0013\n",
      "[84/1762] D loss: 0.0013\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0012\n",
      "[324/1762] D loss: 0.0019\n",
      "[404/1762] D loss: 0.0021\n",
      "[484/1762] D loss: 0.0039\n",
      "[564/1762] D loss: 0.0017\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0015\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0027\n",
      "[1124/1762] D loss: 0.0009\n",
      "[1204/1762] D loss: 0.0032\n",
      "[1284/1762] D loss: 0.0021\n",
      "[1364/1762] D loss: 0.0014\n",
      "[1444/1762] D loss: 0.0012\n",
      "[1524/1762] D loss: 0.0023\n",
      "[1604/1762] D loss: 0.0027\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0013\n",
      "train error: \n",
      " D loss: 0.013719, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.014333, D accuracy: 100.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0014\n",
      "[84/1762] D loss: 0.0009\n",
      "[164/1762] D loss: 0.0016\n",
      "[244/1762] D loss: 0.0010\n",
      "[324/1762] D loss: 0.0009\n",
      "[404/1762] D loss: 0.0007\n",
      "[484/1762] D loss: 0.6900\n",
      "[564/1762] D loss: 0.0569\n",
      "[644/1762] D loss: 0.0274\n",
      "[724/1762] D loss: 0.0431\n",
      "[804/1762] D loss: 0.0185\n",
      "[884/1762] D loss: 0.0185\n",
      "[964/1762] D loss: 0.0016\n",
      "[1044/1762] D loss: 0.0014\n",
      "[1124/1762] D loss: 0.0038\n",
      "[1204/1762] D loss: 0.0025\n",
      "[1284/1762] D loss: 0.0142\n",
      "[1364/1762] D loss: 0.0051\n",
      "[1444/1762] D loss: 0.0035\n",
      "[1524/1762] D loss: 0.0062\n",
      "[1604/1762] D loss: 0.2351\n",
      "[1684/1762] D loss: 0.0058\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 0.019690, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.021529, D accuracy: 99.9% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0048\n",
      "[84/1762] D loss: 0.0027\n",
      "[164/1762] D loss: 0.0024\n",
      "[244/1762] D loss: 0.0073\n",
      "[324/1762] D loss: 0.0279\n",
      "[404/1762] D loss: 0.0007\n",
      "[484/1762] D loss: 0.0025\n",
      "[564/1762] D loss: 0.0010\n",
      "[644/1762] D loss: 0.0014\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0009\n",
      "[884/1762] D loss: 0.0017\n",
      "[964/1762] D loss: 0.0028\n",
      "[1044/1762] D loss: 0.0017\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0015\n",
      "[1284/1762] D loss: 0.0022\n",
      "[1364/1762] D loss: 0.0008\n",
      "[1444/1762] D loss: 0.0008\n",
      "[1524/1762] D loss: 0.0095\n",
      "[1604/1762] D loss: 0.0016\n",
      "[1684/1762] D loss: 0.0018\n",
      "[1762/1762] D loss: 7.5870\n",
      "train error: \n",
      " D loss: 16.027402, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 16.012199, D accuracy: 50.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9209\n",
      "[84/1762] D loss: 0.8514\n",
      "[164/1762] D loss: 0.5977\n",
      "[244/1762] D loss: 1.2219\n",
      "[324/1762] D loss: 0.4685\n",
      "[404/1762] D loss: 2.0534\n",
      "[484/1762] D loss: 0.1844\n",
      "[564/1762] D loss: 0.3286\n",
      "[644/1762] D loss: 0.1064\n",
      "[724/1762] D loss: 0.2157\n",
      "[804/1762] D loss: 0.0652\n",
      "[884/1762] D loss: 0.0231\n",
      "[964/1762] D loss: 0.1491\n",
      "[1044/1762] D loss: 0.0093\n",
      "[1124/1762] D loss: 0.0539\n",
      "[1204/1762] D loss: 0.0831\n",
      "[1284/1762] D loss: 0.0201\n",
      "[1364/1762] D loss: 0.0067\n",
      "[1444/1762] D loss: 0.0067\n",
      "[1524/1762] D loss: 0.0286\n",
      "[1604/1762] D loss: 0.0168\n",
      "[1684/1762] D loss: 0.0103\n",
      "[1762/1762] D loss: 0.0029\n",
      "train error: \n",
      " D loss: 0.015599, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.015911, D accuracy: 100.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0030\n",
      "[84/1762] D loss: 0.0095\n",
      "[164/1762] D loss: 0.0036\n",
      "[244/1762] D loss: 0.0039\n",
      "[324/1762] D loss: 0.0102\n",
      "[404/1762] D loss: 0.0318\n",
      "[484/1762] D loss: 0.0059\n",
      "[564/1762] D loss: 0.0039\n",
      "[644/1762] D loss: 0.0019\n",
      "[724/1762] D loss: 0.0041\n",
      "[804/1762] D loss: 0.0051\n",
      "[884/1762] D loss: 0.0025\n",
      "[964/1762] D loss: 0.0025\n",
      "[1044/1762] D loss: 0.0029\n",
      "[1124/1762] D loss: 0.0027\n",
      "[1204/1762] D loss: 0.0016\n",
      "[1284/1762] D loss: 0.0019\n",
      "[1364/1762] D loss: 0.0012\n",
      "[1444/1762] D loss: 0.0010\n",
      "[1524/1762] D loss: 0.0017\n",
      "[1604/1762] D loss: 0.0026\n",
      "[1684/1762] D loss: 0.0022\n",
      "[1762/1762] D loss: 0.0014\n",
      "train error: \n",
      " D loss: 0.011376, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.008145, D accuracy: 100.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0008\n",
      "[164/1762] D loss: 0.0012\n",
      "[244/1762] D loss: 0.0046\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0019\n",
      "[484/1762] D loss: 0.0024\n",
      "[564/1762] D loss: 0.0014\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0009\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0012\n",
      "[964/1762] D loss: 0.0034\n",
      "[1044/1762] D loss: 0.0107\n",
      "[1124/1762] D loss: 0.0009\n",
      "[1204/1762] D loss: 0.0030\n",
      "[1284/1762] D loss: 0.0019\n",
      "[1364/1762] D loss: 0.0016\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0043\n",
      "[1604/1762] D loss: 0.0006\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.007849, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.006403, D accuracy: 100.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0008\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0005\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0937\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0021\n",
      "[804/1762] D loss: 0.0016\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0009\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0122\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0006\n",
      "[1684/1762] D loss: 0.0006\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 0.005427, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.005711, D accuracy: 100.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4317\n",
      "[84/1762] D loss: 1.3677\n",
      "[164/1762] D loss: 1.3430\n",
      "[244/1762] D loss: 1.3095\n",
      "[324/1762] D loss: 1.2276\n",
      "[404/1762] D loss: 1.1084\n",
      "[484/1762] D loss: 1.1416\n",
      "[564/1762] D loss: 0.8289\n",
      "[644/1762] D loss: 0.6030\n",
      "[724/1762] D loss: 0.7029\n",
      "[804/1762] D loss: 0.2737\n",
      "[884/1762] D loss: 0.5910\n",
      "[964/1762] D loss: 0.3692\n",
      "[1044/1762] D loss: 0.0331\n",
      "[1124/1762] D loss: 0.0237\n",
      "[1204/1762] D loss: 0.0744\n",
      "[1284/1762] D loss: 0.0286\n",
      "[1364/1762] D loss: 0.0151\n",
      "[1444/1762] D loss: 0.0153\n",
      "[1524/1762] D loss: 0.0760\n",
      "[1604/1762] D loss: 0.0084\n",
      "[1684/1762] D loss: 0.0130\n",
      "[1762/1762] D loss: 0.0033\n",
      "train error: \n",
      " D loss: 0.082500, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.085411, D accuracy: 100.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0099\n",
      "[84/1762] D loss: 0.0045\n",
      "[164/1762] D loss: 0.0068\n",
      "[244/1762] D loss: 0.0134\n",
      "[324/1762] D loss: 0.0047\n",
      "[404/1762] D loss: 0.0047\n",
      "[484/1762] D loss: 0.0043\n",
      "[564/1762] D loss: 0.0084\n",
      "[644/1762] D loss: 0.0017\n",
      "[724/1762] D loss: 0.0054\n",
      "[804/1762] D loss: 0.0016\n",
      "[884/1762] D loss: 0.0053\n",
      "[964/1762] D loss: 0.0015\n",
      "[1044/1762] D loss: 0.0024\n",
      "[1124/1762] D loss: 0.0064\n",
      "[1204/1762] D loss: 0.0018\n",
      "[1284/1762] D loss: 0.0037\n",
      "[1364/1762] D loss: 0.0013\n",
      "[1444/1762] D loss: 0.0019\n",
      "[1524/1762] D loss: 0.0026\n",
      "[1604/1762] D loss: 0.0010\n",
      "[1684/1762] D loss: 0.0009\n",
      "[1762/1762] D loss: 0.0005\n",
      "train error: \n",
      " D loss: 0.086759, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.088141, D accuracy: 100.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0015\n",
      "[84/1762] D loss: 0.0024\n",
      "[164/1762] D loss: 0.0028\n",
      "[244/1762] D loss: 0.0063\n",
      "[324/1762] D loss: 0.0018\n",
      "[404/1762] D loss: 0.0007\n",
      "[484/1762] D loss: 0.0026\n",
      "[564/1762] D loss: 0.0021\n",
      "[644/1762] D loss: 0.0007\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0014\n",
      "[884/1762] D loss: 0.0013\n",
      "[964/1762] D loss: 0.0010\n",
      "[1044/1762] D loss: 0.0048\n",
      "[1124/1762] D loss: 0.0021\n",
      "[1204/1762] D loss: 0.0016\n",
      "[1284/1762] D loss: 0.0009\n",
      "[1364/1762] D loss: 0.0009\n",
      "[1444/1762] D loss: 0.0017\n",
      "[1524/1762] D loss: 0.0006\n",
      "[1604/1762] D loss: 0.0009\n",
      "[1684/1762] D loss: 0.0025\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 0.069251, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.069271, D accuracy: 100.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0005\n",
      "[84/1762] D loss: 0.0018\n",
      "[164/1762] D loss: 0.0011\n",
      "[244/1762] D loss: 0.0006\n",
      "[324/1762] D loss: 0.0026\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0023\n",
      "[644/1762] D loss: 0.0017\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0011\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0013\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0007\n",
      "[1284/1762] D loss: 0.0011\n",
      "[1364/1762] D loss: 0.0072\n",
      "[1444/1762] D loss: 0.0011\n",
      "[1524/1762] D loss: 0.0011\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0038\n",
      "[1762/1762] D loss: 0.0006\n",
      "train error: \n",
      " D loss: 0.086840, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.086140, D accuracy: 100.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0016\n",
      "[84/1762] D loss: 0.0008\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0007\n",
      "[644/1762] D loss: 0.0010\n",
      "[724/1762] D loss: 0.0035\n",
      "[804/1762] D loss: 0.0012\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0014\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0008\n",
      "[1204/1762] D loss: 0.0016\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0010\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0011\n",
      "[1604/1762] D loss: 0.0006\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.076460, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.075169, D accuracy: 100.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0005\n",
      "[84/1762] D loss: 0.0005\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0007\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0008\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.097220, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.096860, D accuracy: 100.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0005\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0026\n",
      "[644/1762] D loss: 0.0037\n",
      "[724/1762] D loss: 0.0016\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.093435, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.092764, D accuracy: 100.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0007\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0007\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.089654, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.088731, D accuracy: 100.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0010\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0007\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0008\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0008\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0046\n",
      "train error: \n",
      " D loss: 0.072295, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.071358, D accuracy: 100.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0009\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0009\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0007\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.088965, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.087810, D accuracy: 100.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0007\n",
      "[644/1762] D loss: 0.0007\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0016\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0007\n",
      "[1364/1762] D loss: 0.0005\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.095721, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.093957, D accuracy: 100.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0005\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0014\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0011\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 0.085051, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.083364, D accuracy: 100.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.106551, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.104418, D accuracy: 100.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0009\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.098147, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.096807, D accuracy: 100.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0008\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.094467, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.092944, D accuracy: 100.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0010\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.111147, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.109299, D accuracy: 100.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0012\n",
      "train error: \n",
      " D loss: 0.097896, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.096951, D accuracy: 100.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.121578, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.119765, D accuracy: 100.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0009\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0010\n",
      "[564/1762] D loss: 0.0006\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0009\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.093074, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.091452, D accuracy: 100.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.099783, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.097754, D accuracy: 100.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4737\n",
      "[84/1762] D loss: 1.3914\n",
      "[164/1762] D loss: 1.3785\n",
      "[244/1762] D loss: 1.3842\n",
      "[324/1762] D loss: 1.3825\n",
      "[404/1762] D loss: 1.3834\n",
      "[484/1762] D loss: 1.3772\n",
      "[564/1762] D loss: 1.3832\n",
      "[644/1762] D loss: 1.3644\n",
      "[724/1762] D loss: 1.3713\n",
      "[804/1762] D loss: 1.3525\n",
      "[884/1762] D loss: 1.3679\n",
      "[964/1762] D loss: 1.3654\n",
      "[1044/1762] D loss: 1.3671\n",
      "[1124/1762] D loss: 1.3458\n",
      "[1204/1762] D loss: 1.3669\n",
      "[1284/1762] D loss: 1.3158\n",
      "[1364/1762] D loss: 1.2795\n",
      "[1444/1762] D loss: 1.3937\n",
      "[1524/1762] D loss: 1.2689\n",
      "[1604/1762] D loss: 1.1869\n",
      "[1684/1762] D loss: 1.2439\n",
      "[1762/1762] D loss: 0.9486\n",
      "train error: \n",
      " D loss: 1.405808, D accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398068, D accuracy: 50.8% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3739\n",
      "[84/1762] D loss: 1.0992\n",
      "[164/1762] D loss: 1.1668\n",
      "[244/1762] D loss: 1.0005\n",
      "[324/1762] D loss: 1.0201\n",
      "[404/1762] D loss: 0.7693\n",
      "[484/1762] D loss: 0.9755\n",
      "[564/1762] D loss: 0.8070\n",
      "[644/1762] D loss: 0.3825\n",
      "[724/1762] D loss: 0.8697\n",
      "[804/1762] D loss: 0.5751\n",
      "[884/1762] D loss: 0.6170\n",
      "[964/1762] D loss: 0.3037\n",
      "[1044/1762] D loss: 0.1943\n",
      "[1124/1762] D loss: 0.1529\n",
      "[1204/1762] D loss: 1.4775\n",
      "[1284/1762] D loss: 0.8602\n",
      "[1364/1762] D loss: 0.3779\n",
      "[1444/1762] D loss: 0.0965\n",
      "[1524/1762] D loss: 0.2570\n",
      "[1604/1762] D loss: 0.1930\n",
      "[1684/1762] D loss: 0.0127\n",
      "[1762/1762] D loss: 0.5588\n",
      "train error: \n",
      " D loss: 5.028840, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.075007, D accuracy: 50.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 4.5012\n",
      "[84/1762] D loss: 0.8583\n",
      "[164/1762] D loss: 0.0300\n",
      "[244/1762] D loss: 0.0187\n",
      "[324/1762] D loss: 0.0090\n",
      "[404/1762] D loss: 0.0244\n",
      "[484/1762] D loss: 0.7049\n",
      "[564/1762] D loss: 0.0044\n",
      "[644/1762] D loss: 0.0107\n",
      "[724/1762] D loss: 0.1282\n",
      "[804/1762] D loss: 0.0047\n",
      "[884/1762] D loss: 0.0045\n",
      "[964/1762] D loss: 0.0034\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0101\n",
      "[1204/1762] D loss: 0.0017\n",
      "[1284/1762] D loss: 0.0040\n",
      "[1364/1762] D loss: 0.0059\n",
      "[1444/1762] D loss: 0.0043\n",
      "[1524/1762] D loss: 0.0029\n",
      "[1604/1762] D loss: 0.0070\n",
      "[1684/1762] D loss: 0.0016\n",
      "[1762/1762] D loss: 0.0010\n",
      "train error: \n",
      " D loss: 1.534357, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.566259, D accuracy: 50.1% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0022\n",
      "[164/1762] D loss: 0.0033\n",
      "[244/1762] D loss: 0.0010\n",
      "[324/1762] D loss: 0.0312\n",
      "[404/1762] D loss: 0.0766\n",
      "[484/1762] D loss: 0.0019\n",
      "[564/1762] D loss: 0.0008\n",
      "[644/1762] D loss: 0.0020\n",
      "[724/1762] D loss: 0.0010\n",
      "[804/1762] D loss: 0.0223\n",
      "[884/1762] D loss: 0.0024\n",
      "[964/1762] D loss: 0.0042\n",
      "[1044/1762] D loss: 0.0024\n",
      "[1124/1762] D loss: 0.0013\n",
      "[1204/1762] D loss: 0.0020\n",
      "[1284/1762] D loss: 0.0270\n",
      "[1364/1762] D loss: 0.0009\n",
      "[1444/1762] D loss: 0.0019\n",
      "[1524/1762] D loss: 0.0024\n",
      "[1604/1762] D loss: 0.0016\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0011\n",
      "train error: \n",
      " D loss: 2.079146, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.120186, D accuracy: 50.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0015\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0036\n",
      "[244/1762] D loss: 0.0012\n",
      "[324/1762] D loss: 0.0050\n",
      "[404/1762] D loss: 0.0014\n",
      "[484/1762] D loss: 0.0007\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0067\n",
      "[724/1762] D loss: 0.0007\n",
      "[804/1762] D loss: 0.0012\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0006\n",
      "[1044/1762] D loss: 0.0017\n",
      "[1124/1762] D loss: 0.0062\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0008\n",
      "[1364/1762] D loss: 0.0046\n",
      "[1444/1762] D loss: 0.0039\n",
      "[1524/1762] D loss: 0.0007\n",
      "[1604/1762] D loss: 0.0037\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 3.432258, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.485755, D accuracy: 50.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0019\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0015\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0027\n",
      "[644/1762] D loss: 0.0008\n",
      "[724/1762] D loss: 0.0015\n",
      "[804/1762] D loss: 0.0015\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0012\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0074\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0005\n",
      "[1364/1762] D loss: 0.0005\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 3.779217, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.825910, D accuracy: 50.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0015\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0007\n",
      "[564/1762] D loss: 0.0007\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0023\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0013\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 3.857281, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.912476, D accuracy: 50.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0086\n",
      "[84/1762] D loss: 0.0017\n",
      "[164/1762] D loss: 0.0012\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0026\n",
      "[1284/1762] D loss: 0.0011\n",
      "[1364/1762] D loss: 0.0010\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0007\n",
      "[1604/1762] D loss: 0.0024\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0022\n",
      "train error: \n",
      " D loss: 4.309716, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.363585, D accuracy: 50.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0007\n",
      "[644/1762] D loss: 0.0007\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0014\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 4.696069, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.749815, D accuracy: 50.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0012\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0006\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0023\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 4.694087, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.747921, D accuracy: 50.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0016\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0021\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0012\n",
      "[964/1762] D loss: 0.0011\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0019\n",
      "[1762/1762] D loss: 0.0014\n",
      "train error: \n",
      " D loss: 4.417227, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.473957, D accuracy: 50.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 4.919159, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.984331, D accuracy: 50.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0005\n",
      "[84/1762] D loss: 0.0009\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0034\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0007\n",
      "[1204/1762] D loss: 0.0014\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0028\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0022\n",
      "train error: \n",
      " D loss: 4.452131, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.513209, D accuracy: 50.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0010\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 5.153488, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.216737, D accuracy: 50.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0035\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0007\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 5.742664, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.808806, D accuracy: 50.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0013\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0004\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 4.995441, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.055413, D accuracy: 50.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 4.975646, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.035007, D accuracy: 50.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 5.630553, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.691142, D accuracy: 50.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 5.815339, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.880217, D accuracy: 50.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0166\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 5.765920, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.826903, D accuracy: 50.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4354\n",
      "[84/1762] D loss: 1.3849\n",
      "[164/1762] D loss: 1.3845\n",
      "[244/1762] D loss: 1.3834\n",
      "[324/1762] D loss: 1.3846\n",
      "[404/1762] D loss: 1.3470\n",
      "[484/1762] D loss: 1.3587\n",
      "[564/1762] D loss: 1.3783\n",
      "[644/1762] D loss: 1.3740\n",
      "[724/1762] D loss: 1.3572\n",
      "[804/1762] D loss: 1.3606\n",
      "[884/1762] D loss: 1.3721\n",
      "[964/1762] D loss: 1.3491\n",
      "[1044/1762] D loss: 1.2254\n",
      "[1124/1762] D loss: 1.2222\n",
      "[1204/1762] D loss: 1.2068\n",
      "[1284/1762] D loss: 0.9130\n",
      "[1364/1762] D loss: 0.7534\n",
      "[1444/1762] D loss: 0.6512\n",
      "[1524/1762] D loss: 0.4535\n",
      "[1604/1762] D loss: 0.2268\n",
      "[1684/1762] D loss: 0.5699\n",
      "[1762/1762] D loss: 0.1336\n",
      "train error: \n",
      " D loss: 0.608959, D accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.632455, D accuracy: 91.1% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3503\n",
      "[84/1762] D loss: 0.4904\n",
      "[164/1762] D loss: 0.1373\n",
      "[244/1762] D loss: 0.0314\n",
      "[324/1762] D loss: 0.0492\n",
      "[404/1762] D loss: 0.6363\n",
      "[484/1762] D loss: 0.1375\n",
      "[564/1762] D loss: 0.3423\n",
      "[644/1762] D loss: 0.1499\n",
      "[724/1762] D loss: 0.0369\n",
      "[804/1762] D loss: 0.0677\n",
      "[884/1762] D loss: 0.1069\n",
      "[964/1762] D loss: 0.1446\n",
      "[1044/1762] D loss: 0.0247\n",
      "[1124/1762] D loss: 0.0049\n",
      "[1204/1762] D loss: 0.0066\n",
      "[1284/1762] D loss: 0.0058\n",
      "[1364/1762] D loss: 0.0366\n",
      "[1444/1762] D loss: 0.0047\n",
      "[1524/1762] D loss: 0.0128\n",
      "[1604/1762] D loss: 0.0020\n",
      "[1684/1762] D loss: 0.0153\n",
      "[1762/1762] D loss: 0.0023\n",
      "train error: \n",
      " D loss: 0.621984, D accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626951, D accuracy: 84.9% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0020\n",
      "[84/1762] D loss: 0.0043\n",
      "[164/1762] D loss: 0.0021\n",
      "[244/1762] D loss: 0.0228\n",
      "[324/1762] D loss: 0.0130\n",
      "[404/1762] D loss: 1.8160\n",
      "[484/1762] D loss: 0.0318\n",
      "[564/1762] D loss: 0.2797\n",
      "[644/1762] D loss: 0.0046\n",
      "[724/1762] D loss: 0.0040\n",
      "[804/1762] D loss: 0.0523\n",
      "[884/1762] D loss: 0.0048\n",
      "[964/1762] D loss: 0.0039\n",
      "[1044/1762] D loss: 0.0177\n",
      "[1124/1762] D loss: 0.0264\n",
      "[1204/1762] D loss: 0.0058\n",
      "[1284/1762] D loss: 0.0016\n",
      "[1364/1762] D loss: 0.0109\n",
      "[1444/1762] D loss: 0.0017\n",
      "[1524/1762] D loss: 0.0133\n",
      "[1604/1762] D loss: 0.0017\n",
      "[1684/1762] D loss: 0.0110\n",
      "[1762/1762] D loss: 0.0245\n",
      "train error: \n",
      " D loss: 0.433523, D accuracy: 93.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.440396, D accuracy: 93.4% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0010\n",
      "[84/1762] D loss: 0.0024\n",
      "[164/1762] D loss: 0.0009\n",
      "[244/1762] D loss: 0.0096\n",
      "[324/1762] D loss: 0.0015\n",
      "[404/1762] D loss: 0.0044\n",
      "[484/1762] D loss: 0.0012\n",
      "[564/1762] D loss: 0.0004\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0189\n",
      "[804/1762] D loss: 0.0012\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0007\n",
      "[1044/1762] D loss: 0.0151\n",
      "[1124/1762] D loss: 0.0025\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0064\n",
      "[1364/1762] D loss: 0.0013\n",
      "[1444/1762] D loss: 0.0011\n",
      "[1524/1762] D loss: 0.0010\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0018\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.578945, D accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.587337, D accuracy: 86.4% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006\n",
      "[84/1762] D loss: 0.0009\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0006\n",
      "[484/1762] D loss: 0.0030\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0048\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0012\n",
      "[1124/1762] D loss: 0.0058\n",
      "[1204/1762] D loss: 0.0035\n",
      "[1284/1762] D loss: 0.0005\n",
      "[1364/1762] D loss: 0.0017\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0006\n",
      "[1762/1762] D loss: 0.0016\n",
      "train error: \n",
      " D loss: 0.681383, D accuracy: 79.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.692290, D accuracy: 78.8% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0022\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0021\n",
      "[884/1762] D loss: 0.0014\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0006\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.506724, D accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.523441, D accuracy: 91.1% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0096\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0039\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0015\n",
      "[644/1762] D loss: 0.0018\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0007\n",
      "[1204/1762] D loss: 0.0012\n",
      "[1284/1762] D loss: 0.0014\n",
      "[1364/1762] D loss: 0.0008\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0037\n",
      "[1684/1762] D loss: 0.0040\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 1.317325, D accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331785, D accuracy: 51.8% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0006\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0011\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0007\n",
      "[724/1762] D loss: 0.0006\n",
      "[804/1762] D loss: 0.0025\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0006\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0018\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0037\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.264061, D accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274803, D accuracy: 52.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0101\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0008\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0039\n",
      "[964/1762] D loss: 0.0014\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0246\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 0.942668, D accuracy: 64.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.960603, D accuracy: 65.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0017\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0044\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0086\n",
      "[1204/1762] D loss: 0.0010\n",
      "[1284/1762] D loss: 0.0034\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.253446, D accuracy: 51.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270768, D accuracy: 51.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0006\n",
      "[164/1762] D loss: 0.0031\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.862172, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.877731, D accuracy: 50.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0008\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0009\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.444573, D accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.465804, D accuracy: 50.8% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0008\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0010\n",
      "[1044/1762] D loss: 0.0027\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.609897, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.631229, D accuracy: 50.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0025\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.508656, D accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.530121, D accuracy: 50.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0030\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0009\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.346835, D accuracy: 51.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371356, D accuracy: 51.2% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0022\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 2.375044, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.400008, D accuracy: 50.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0005\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0017\n",
      "[1204/1762] D loss: 0.0042\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.698827, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.719394, D accuracy: 50.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0007\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 2.000258, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.019956, D accuracy: 50.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0078\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.805489, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.834200, D accuracy: 50.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0005\n",
      "[164/1762] D loss: 0.0010\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0056\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0020\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.585212, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.611441, D accuracy: 50.3% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3828\n",
      "[84/1762] D loss: 1.3798\n",
      "[164/1762] D loss: 1.3753\n",
      "[244/1762] D loss: 1.3672\n",
      "[324/1762] D loss: 1.3063\n",
      "[404/1762] D loss: 1.2957\n",
      "[484/1762] D loss: 1.1764\n",
      "[564/1762] D loss: 1.2190\n",
      "[644/1762] D loss: 0.9423\n",
      "[724/1762] D loss: 0.9316\n",
      "[804/1762] D loss: 0.5985\n",
      "[884/1762] D loss: 0.3367\n",
      "[964/1762] D loss: 0.2743\n",
      "[1044/1762] D loss: 0.9643\n",
      "[1124/1762] D loss: 0.2036\n",
      "[1204/1762] D loss: 0.0772\n",
      "[1284/1762] D loss: 0.3087\n",
      "[1364/1762] D loss: 0.5914\n",
      "[1444/1762] D loss: 0.3874\n",
      "[1524/1762] D loss: 0.0134\n",
      "[1604/1762] D loss: 0.0224\n",
      "[1684/1762] D loss: 0.0094\n",
      "[1762/1762] D loss: 0.0302\n",
      "train error: \n",
      " D loss: 0.096169, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.098820, D accuracy: 99.9% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0086\n",
      "[84/1762] D loss: 0.0039\n",
      "[164/1762] D loss: 0.0082\n",
      "[244/1762] D loss: 0.0089\n",
      "[324/1762] D loss: 0.0054\n",
      "[404/1762] D loss: 0.0322\n",
      "[484/1762] D loss: 0.0032\n",
      "[564/1762] D loss: 0.0074\n",
      "[644/1762] D loss: 0.0012\n",
      "[724/1762] D loss: 0.0026\n",
      "[804/1762] D loss: 0.0026\n",
      "[884/1762] D loss: 0.0020\n",
      "[964/1762] D loss: 0.0014\n",
      "[1044/1762] D loss: 0.0043\n",
      "[1124/1762] D loss: 0.0039\n",
      "[1204/1762] D loss: 0.0033\n",
      "[1284/1762] D loss: 0.0012\n",
      "[1364/1762] D loss: 0.0012\n",
      "[1444/1762] D loss: 0.0011\n",
      "[1524/1762] D loss: 0.0015\n",
      "[1604/1762] D loss: 0.0017\n",
      "[1684/1762] D loss: 0.0024\n",
      "[1762/1762] D loss: 0.0021\n",
      "train error: \n",
      " D loss: 0.247616, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.248756, D accuracy: 99.9% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0098\n",
      "[84/1762] D loss: 0.0051\n",
      "[164/1762] D loss: 0.0035\n",
      "[244/1762] D loss: 0.0016\n",
      "[324/1762] D loss: 0.0016\n",
      "[404/1762] D loss: 0.0008\n",
      "[484/1762] D loss: 0.0011\n",
      "[564/1762] D loss: 0.0006\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0012\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0017\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0011\n",
      "[1204/1762] D loss: 0.0019\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0009\n",
      "[1444/1762] D loss: 0.0019\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0037\n",
      "[1684/1762] D loss: 0.0024\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 0.228323, D accuracy: 99.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.223064, D accuracy: 100.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0013\n",
      "[84/1762] D loss: 0.0016\n",
      "[164/1762] D loss: 0.0006\n",
      "[244/1762] D loss: 0.0007\n",
      "[324/1762] D loss: 0.0008\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0013\n",
      "[644/1762] D loss: 0.0008\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0019\n",
      "[1044/1762] D loss: 0.0005\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0773\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0006\n",
      "[1444/1762] D loss: 0.0017\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0009\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.258479, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.252489, D accuracy: 100.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0008\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0014\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0011\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0005\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0088\n",
      "train error: \n",
      " D loss: 0.192405, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.189404, D accuracy: 100.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006\n",
      "[84/1762] D loss: 0.0006\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0010\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0018\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0031\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.347149, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.343285, D accuracy: 99.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0007\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.479797, D accuracy: 98.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.474908, D accuracy: 99.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0011\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0011\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.377107, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.372490, D accuracy: 99.9% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.365839, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.361490, D accuracy: 99.7% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0020\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.352471, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.348895, D accuracy: 99.9% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0044\n",
      "train error: \n",
      " D loss: 0.323386, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.321165, D accuracy: 99.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0011\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.524387, D accuracy: 97.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.521204, D accuracy: 98.3% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0005\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.581100, D accuracy: 95.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.578011, D accuracy: 96.4% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.664045, D accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.661663, D accuracy: 85.3% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.982646, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.981880, D accuracy: 50.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0009\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.604401, D accuracy: 95.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603156, D accuracy: 95.6% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.791378, D accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.790552, D accuracy: 58.8% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0007\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.651789, D accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.650627, D accuracy: 88.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.831674, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.829391, D accuracy: 50.1% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.604005, D accuracy: 95.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.602777, D accuracy: 95.8% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899\n",
      "[84/1762] D loss: 1.3668\n",
      "[164/1762] D loss: 1.3863\n",
      "[244/1762] D loss: 1.3604\n",
      "[324/1762] D loss: 1.3023\n",
      "[404/1762] D loss: 1.2620\n",
      "[484/1762] D loss: 1.2509\n",
      "[564/1762] D loss: 1.0952\n",
      "[644/1762] D loss: 1.1274\n",
      "[724/1762] D loss: 1.0385\n",
      "[804/1762] D loss: 0.6888\n",
      "[884/1762] D loss: 0.2817\n",
      "[964/1762] D loss: 0.4869\n",
      "[1044/1762] D loss: 0.0656\n",
      "[1124/1762] D loss: 0.0372\n",
      "[1204/1762] D loss: 0.0823\n",
      "[1284/1762] D loss: 0.0421\n",
      "[1364/1762] D loss: 0.0284\n",
      "[1444/1762] D loss: 0.0218\n",
      "[1524/1762] D loss: 0.0105\n",
      "[1604/1762] D loss: 0.0109\n",
      "[1684/1762] D loss: 0.0113\n",
      "[1762/1762] D loss: 0.0086\n",
      "train error: \n",
      " D loss: 0.065668, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.068204, D accuracy: 99.9% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0264\n",
      "[84/1762] D loss: 0.0288\n",
      "[164/1762] D loss: 0.0116\n",
      "[244/1762] D loss: 3.4083\n",
      "[324/1762] D loss: 0.2661\n",
      "[404/1762] D loss: 0.0246\n",
      "[484/1762] D loss: 0.0193\n",
      "[564/1762] D loss: 0.2136\n",
      "[644/1762] D loss: 0.0240\n",
      "[724/1762] D loss: 0.0078\n",
      "[804/1762] D loss: 0.0133\n",
      "[884/1762] D loss: 0.0074\n",
      "[964/1762] D loss: 0.0136\n",
      "[1044/1762] D loss: 0.0035\n",
      "[1124/1762] D loss: 0.0095\n",
      "[1204/1762] D loss: 0.0150\n",
      "[1284/1762] D loss: 0.0034\n",
      "[1364/1762] D loss: 0.0168\n",
      "[1444/1762] D loss: 0.0041\n",
      "[1524/1762] D loss: 0.6475\n",
      "[1604/1762] D loss: 0.0654\n",
      "[1684/1762] D loss: 0.0446\n",
      "[1762/1762] D loss: 0.0398\n",
      "train error: \n",
      " D loss: 0.180153, D accuracy: 99.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.207325, D accuracy: 98.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1146\n",
      "[84/1762] D loss: 0.0110\n",
      "[164/1762] D loss: 0.0141\n",
      "[244/1762] D loss: 0.0099\n",
      "[324/1762] D loss: 0.0143\n",
      "[404/1762] D loss: 0.0067\n",
      "[484/1762] D loss: 0.0048\n",
      "[564/1762] D loss: 0.0163\n",
      "[644/1762] D loss: 0.0056\n",
      "[724/1762] D loss: 0.1374\n",
      "[804/1762] D loss: 0.0253\n",
      "[884/1762] D loss: 0.0087\n",
      "[964/1762] D loss: 0.0123\n",
      "[1044/1762] D loss: 0.0142\n",
      "[1124/1762] D loss: 0.0157\n",
      "[1204/1762] D loss: 0.0042\n",
      "[1284/1762] D loss: 0.0026\n",
      "[1364/1762] D loss: 0.0088\n",
      "[1444/1762] D loss: 0.0060\n",
      "[1524/1762] D loss: 0.0032\n",
      "[1604/1762] D loss: 0.0107\n",
      "[1684/1762] D loss: 0.0079\n",
      "[1762/1762] D loss: 0.0021\n",
      "train error: \n",
      " D loss: 0.178847, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.182421, D accuracy: 99.9% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0034\n",
      "[84/1762] D loss: 0.0052\n",
      "[164/1762] D loss: 0.0045\n",
      "[244/1762] D loss: 0.0013\n",
      "[324/1762] D loss: 0.0025\n",
      "[404/1762] D loss: 0.0285\n",
      "[484/1762] D loss: 0.0022\n",
      "[564/1762] D loss: 0.0013\n",
      "[644/1762] D loss: 0.0060\n",
      "[724/1762] D loss: 0.0026\n",
      "[804/1762] D loss: 0.0058\n",
      "[884/1762] D loss: 0.0055\n",
      "[964/1762] D loss: 0.0010\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0021\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0331\n",
      "[1444/1762] D loss: 0.0019\n",
      "[1524/1762] D loss: 0.0011\n",
      "[1604/1762] D loss: 0.0007\n",
      "[1684/1762] D loss: 0.0029\n",
      "[1762/1762] D loss: 0.0026\n",
      "train error: \n",
      " D loss: 0.151880, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.158503, D accuracy: 99.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0041\n",
      "[84/1762] D loss: 0.0024\n",
      "[164/1762] D loss: 0.0007\n",
      "[244/1762] D loss: 0.0031\n",
      "[324/1762] D loss: 0.0014\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0014\n",
      "[564/1762] D loss: 0.0024\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0012\n",
      "[804/1762] D loss: 0.0013\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0011\n",
      "[1204/1762] D loss: 0.0008\n",
      "[1284/1762] D loss: 0.0005\n",
      "[1364/1762] D loss: 0.0015\n",
      "[1444/1762] D loss: 0.0036\n",
      "[1524/1762] D loss: 0.0015\n",
      "[1604/1762] D loss: 0.0037\n",
      "[1684/1762] D loss: 0.0013\n",
      "[1762/1762] D loss: 0.0007\n",
      "train error: \n",
      " D loss: 0.210428, D accuracy: 99.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.218224, D accuracy: 99.4% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0005\n",
      "[84/1762] D loss: 0.0021\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0013\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0011\n",
      "[804/1762] D loss: 0.0008\n",
      "[884/1762] D loss: 0.0015\n",
      "[964/1762] D loss: 0.0006\n",
      "[1044/1762] D loss: 0.0006\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0014\n",
      "[1364/1762] D loss: 0.0005\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0009\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 0.303681, D accuracy: 99.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.318049, D accuracy: 98.9% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0010\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0009\n",
      "[324/1762] D loss: 0.0008\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0010\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0012\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0005\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0012\n",
      "[1444/1762] D loss: 0.1685\n",
      "[1524/1762] D loss: 0.0089\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0013\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.245670, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.245773, D accuracy: 99.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0016\n",
      "[84/1762] D loss: 0.0007\n",
      "[164/1762] D loss: 0.0009\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0007\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0027\n",
      "[724/1762] D loss: 0.0009\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0038\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0028\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0006\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 0.310221, D accuracy: 97.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.326625, D accuracy: 97.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0015\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0006\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.2206\n",
      "[1604/1762] D loss: 0.1428\n",
      "[1684/1762] D loss: 0.0205\n",
      "[1762/1762] D loss: 0.0112\n",
      "train error: \n",
      " D loss: 0.458703, D accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.465133, D accuracy: 91.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0099\n",
      "[84/1762] D loss: 0.0125\n",
      "[164/1762] D loss: 0.0029\n",
      "[244/1762] D loss: 0.0019\n",
      "[324/1762] D loss: 0.0026\n",
      "[404/1762] D loss: 0.0061\n",
      "[484/1762] D loss: 0.0025\n",
      "[564/1762] D loss: 0.0045\n",
      "[644/1762] D loss: 0.0015\n",
      "[724/1762] D loss: 0.0009\n",
      "[804/1762] D loss: 0.0023\n",
      "[884/1762] D loss: 0.0010\n",
      "[964/1762] D loss: 0.0024\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0015\n",
      "[1204/1762] D loss: 0.0007\n",
      "[1284/1762] D loss: 0.0015\n",
      "[1364/1762] D loss: 0.0007\n",
      "[1444/1762] D loss: 0.0057\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0082\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 0.334650, D accuracy: 97.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.347916, D accuracy: 96.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0012\n",
      "[84/1762] D loss: 0.0035\n",
      "[164/1762] D loss: 0.0009\n",
      "[244/1762] D loss: 0.0048\n",
      "[324/1762] D loss: 0.0016\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0008\n",
      "[564/1762] D loss: 0.0004\n",
      "[644/1762] D loss: 0.0009\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0009\n",
      "[964/1762] D loss: 0.0006\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0016\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0004\n",
      "[1444/1762] D loss: 0.0007\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0008\n",
      "[1684/1762] D loss: 0.0016\n",
      "[1762/1762] D loss: 0.0027\n",
      "train error: \n",
      " D loss: 0.272150, D accuracy: 99.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.283810, D accuracy: 98.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0010\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0013\n",
      "[964/1762] D loss: 0.0008\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0007\n",
      "[1284/1762] D loss: 0.0005\n",
      "[1364/1762] D loss: 0.0008\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0037\n",
      "[1604/1762] D loss: 0.0007\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.515033, D accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.536638, D accuracy: 88.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0009\n",
      "[404/1762] D loss: 0.0006\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0028\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0028\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0014\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0004\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0006\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.416912, D accuracy: 94.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.435310, D accuracy: 93.3% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004\n",
      "[84/1762] D loss: 0.0005\n",
      "[164/1762] D loss: 0.0028\n",
      "[244/1762] D loss: 0.0009\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0005\n",
      "[964/1762] D loss: 0.0007\n",
      "[1044/1762] D loss: 0.0018\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0008\n",
      "[1762/1762] D loss: 0.0032\n",
      "train error: \n",
      " D loss: 0.607779, D accuracy: 83.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.629197, D accuracy: 83.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0009\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.459708, D accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.479740, D accuracy: 91.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0010\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0051\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0008\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0012\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.598270, D accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626634, D accuracy: 84.9% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.542463, D accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.564255, D accuracy: 87.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.621354, D accuracy: 83.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.642351, D accuracy: 82.7% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.510323, D accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.531978, D accuracy: 89.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0008\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 1.1668\n",
      "[1124/1762] D loss: 0.0336\n",
      "[1204/1762] D loss: 0.0575\n",
      "[1284/1762] D loss: 0.0124\n",
      "[1364/1762] D loss: 0.0023\n",
      "[1444/1762] D loss: 0.0031\n",
      "[1524/1762] D loss: 0.0159\n",
      "[1604/1762] D loss: 0.0049\n",
      "[1684/1762] D loss: 0.0034\n",
      "[1762/1762] D loss: 0.0010\n",
      "train error: \n",
      " D loss: 0.268854, D accuracy: 97.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.261849, D accuracy: 98.3% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3743\n",
      "[84/1762] D loss: 1.3559\n",
      "[164/1762] D loss: 1.3381\n",
      "[244/1762] D loss: 1.2586\n",
      "[324/1762] D loss: 1.2111\n",
      "[404/1762] D loss: 1.0699\n",
      "[484/1762] D loss: 0.8434\n",
      "[564/1762] D loss: 0.4623\n",
      "[644/1762] D loss: 0.3067\n",
      "[724/1762] D loss: 0.2688\n",
      "[804/1762] D loss: 0.1966\n",
      "[884/1762] D loss: 0.0773\n",
      "[964/1762] D loss: 0.0287\n",
      "[1044/1762] D loss: 0.0794\n",
      "[1124/1762] D loss: 0.0342\n",
      "[1204/1762] D loss: 0.0382\n",
      "[1284/1762] D loss: 0.0111\n",
      "[1364/1762] D loss: 0.0349\n",
      "[1444/1762] D loss: 0.0155\n",
      "[1524/1762] D loss: 0.0082\n",
      "[1604/1762] D loss: 0.0091\n",
      "[1684/1762] D loss: 0.0102\n",
      "[1762/1762] D loss: 0.0035\n",
      "train error: \n",
      " D loss: 0.045109, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.049760, D accuracy: 99.9% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0188\n",
      "[84/1762] D loss: 0.0063\n",
      "[164/1762] D loss: 0.0047\n",
      "[244/1762] D loss: 0.0034\n",
      "[324/1762] D loss: 0.0027\n",
      "[404/1762] D loss: 0.0044\n",
      "[484/1762] D loss: 0.0189\n",
      "[564/1762] D loss: 0.0054\n",
      "[644/1762] D loss: 0.0034\n",
      "[724/1762] D loss: 0.0440\n",
      "[804/1762] D loss: 0.0017\n",
      "[884/1762] D loss: 0.0059\n",
      "[964/1762] D loss: 0.0106\n",
      "[1044/1762] D loss: 0.0051\n",
      "[1124/1762] D loss: 0.0015\n",
      "[1204/1762] D loss: 0.0028\n",
      "[1284/1762] D loss: 0.0045\n",
      "[1364/1762] D loss: 0.0045\n",
      "[1444/1762] D loss: 0.0045\n",
      "[1524/1762] D loss: 0.0045\n",
      "[1604/1762] D loss: 0.0032\n",
      "[1684/1762] D loss: 0.0041\n",
      "[1762/1762] D loss: 0.0016\n",
      "train error: \n",
      " D loss: 0.028996, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.036651, D accuracy: 99.9% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0012\n",
      "[84/1762] D loss: 0.0027\n",
      "[164/1762] D loss: 0.0044\n",
      "[244/1762] D loss: 0.0012\n",
      "[324/1762] D loss: 0.0021\n",
      "[404/1762] D loss: 0.0020\n",
      "[484/1762] D loss: 0.0068\n",
      "[564/1762] D loss: 0.0011\n",
      "[644/1762] D loss: 0.0026\n",
      "[724/1762] D loss: 0.0006\n",
      "[804/1762] D loss: 0.0019\n",
      "[884/1762] D loss: 0.0042\n",
      "[964/1762] D loss: 0.0012\n",
      "[1044/1762] D loss: 0.0013\n",
      "[1124/1762] D loss: 0.0008\n",
      "[1204/1762] D loss: 0.0025\n",
      "[1284/1762] D loss: 0.0023\n",
      "[1364/1762] D loss: 0.0006\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0016\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0022\n",
      "[1762/1762] D loss: 0.0011\n",
      "train error: \n",
      " D loss: 0.023115, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.023521, D accuracy: 100.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0024\n",
      "[84/1762] D loss: 0.0012\n",
      "[164/1762] D loss: 0.0015\n",
      "[244/1762] D loss: 0.0005\n",
      "[324/1762] D loss: 0.0022\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0008\n",
      "[644/1762] D loss: 0.0013\n",
      "[724/1762] D loss: 0.0014\n",
      "[804/1762] D loss: 0.0013\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0013\n",
      "[1044/1762] D loss: 0.0007\n",
      "[1124/1762] D loss: 0.0029\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0034\n",
      "[1364/1762] D loss: 0.0011\n",
      "[1444/1762] D loss: 0.0006\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0011\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0011\n",
      "train error: \n",
      " D loss: 0.017845, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.019978, D accuracy: 100.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0007\n",
      "[164/1762] D loss: 0.0012\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0009\n",
      "[404/1762] D loss: 0.0012\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0006\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0005\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0006\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0012\n",
      "[1444/1762] D loss: 0.0011\n",
      "[1524/1762] D loss: 0.0007\n",
      "[1604/1762] D loss: 0.0015\n",
      "[1684/1762] D loss: 0.0012\n",
      "[1762/1762] D loss: 0.0054\n",
      "train error: \n",
      " D loss: 0.014949, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.017270, D accuracy: 100.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0018\n",
      "[84/1762] D loss: 0.0032\n",
      "[164/1762] D loss: 0.0007\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0016\n",
      "[404/1762] D loss: 0.0008\n",
      "[484/1762] D loss: 0.0007\n",
      "[564/1762] D loss: 0.0008\n",
      "[644/1762] D loss: 0.0008\n",
      "[724/1762] D loss: 0.0005\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0041\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0011\n",
      "[1364/1762] D loss: 0.0005\n",
      "[1444/1762] D loss: 0.0032\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0014\n",
      "[1762/1762] D loss: 0.0010\n",
      "train error: \n",
      " D loss: 0.021912, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.023616, D accuracy: 100.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0133\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0023\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0006\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0007\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0006\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0013\n",
      "train error: \n",
      " D loss: 0.055951, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.061007, D accuracy: 100.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0007\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0015\n",
      "[564/1762] D loss: 0.0006\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0034\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 0.034808, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.037978, D accuracy: 100.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0011\n",
      "[84/1762] D loss: 0.0006\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0014\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0004\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0003\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0005\n",
      "train error: \n",
      " D loss: 0.017156, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.018725, D accuracy: 100.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0012\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0005\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0012\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.018514, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.020533, D accuracy: 100.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0013\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.014701, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.016052, D accuracy: 100.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0014\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0002\n",
      "[324/1762] D loss: 0.0007\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0008\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0007\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.016045, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.017107, D accuracy: 100.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0026\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0012\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0009\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0006\n",
      "[1684/1762] D loss: 0.0007\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.014192, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.015320, D accuracy: 100.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.014821, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.016302, D accuracy: 100.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0005\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0036\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.016713, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.018381, D accuracy: 100.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0006\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.020975, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.022903, D accuracy: 100.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0006\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0008\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.022033, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.023950, D accuracy: 100.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.016307, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.017778, D accuracy: 100.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0023\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0024\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 0.019640, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.021390, D accuracy: 100.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0009\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.019605, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.021190, D accuracy: 100.0% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for perturb_num in [2, 4, 6, 8, 10]:\n",
    "        train(run_name=f\"perturb_{perturb_num}\", perturb_num=perturb_num, epochs=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model continues to do well with 10 perturbations, but doesn't always stay at 100%. With 6 and 8 perturbations, the training becomes unstable. With 2 and 4 perturbations, the loss increases on every epoch, which suggests that the learning rate needs to be lowered.\n",
    "\n",
    "Next, let's fix the number of perturbations to 4 and lower the learning rate to see if we can coax the model to learn effectively in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941\n",
      "[84/1762] D loss: 1.4073\n",
      "[164/1762] D loss: 1.3972\n",
      "[244/1762] D loss: 1.3715\n",
      "[324/1762] D loss: 1.3696\n",
      "[404/1762] D loss: 1.3413\n",
      "[484/1762] D loss: 1.3662\n",
      "[564/1762] D loss: 1.3501\n",
      "[644/1762] D loss: 1.3445\n",
      "[724/1762] D loss: 1.3190\n",
      "[804/1762] D loss: 1.2975\n",
      "[884/1762] D loss: 1.2266\n",
      "[964/1762] D loss: 1.2772\n",
      "[1044/1762] D loss: 1.2165\n",
      "[1124/1762] D loss: 1.1634\n",
      "[1204/1762] D loss: 1.0208\n",
      "[1284/1762] D loss: 1.0255\n",
      "[1364/1762] D loss: 1.2045\n",
      "[1444/1762] D loss: 0.5860\n",
      "[1524/1762] D loss: 0.6540\n",
      "[1604/1762] D loss: 0.3736\n",
      "[1684/1762] D loss: 0.2220\n",
      "[1762/1762] D loss: 0.1225\n",
      "train error: \n",
      " D loss: 0.344409, D accuracy: 95.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.343718, D accuracy: 95.7% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7793\n",
      "[84/1762] D loss: 0.0899\n",
      "[164/1762] D loss: 0.0676\n",
      "[244/1762] D loss: 0.5823\n",
      "[324/1762] D loss: 0.2182\n",
      "[404/1762] D loss: 0.1524\n",
      "[484/1762] D loss: 0.7471\n",
      "[564/1762] D loss: 0.2382\n",
      "[644/1762] D loss: 0.2824\n",
      "[724/1762] D loss: 0.1425\n",
      "[804/1762] D loss: 0.0220\n",
      "[884/1762] D loss: 0.0135\n",
      "[964/1762] D loss: 0.0251\n",
      "[1044/1762] D loss: 0.0113\n",
      "[1124/1762] D loss: 0.0453\n",
      "[1204/1762] D loss: 0.0081\n",
      "[1284/1762] D loss: 0.0282\n",
      "[1364/1762] D loss: 0.0047\n",
      "[1444/1762] D loss: 0.0072\n",
      "[1524/1762] D loss: 0.0514\n",
      "[1604/1762] D loss: 0.0056\n",
      "[1684/1762] D loss: 0.0044\n",
      "[1762/1762] D loss: 0.0048\n",
      "train error: \n",
      " D loss: 0.189078, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.178020, D accuracy: 99.9% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0049\n",
      "[84/1762] D loss: 0.3256\n",
      "[164/1762] D loss: 1.1474\n",
      "[244/1762] D loss: 0.2037\n",
      "[324/1762] D loss: 0.2553\n",
      "[404/1762] D loss: 0.1575\n",
      "[484/1762] D loss: 0.1795\n",
      "[564/1762] D loss: 0.0325\n",
      "[644/1762] D loss: 0.0048\n",
      "[724/1762] D loss: 0.1472\n",
      "[804/1762] D loss: 0.0152\n",
      "[884/1762] D loss: 0.0159\n",
      "[964/1762] D loss: 0.0047\n",
      "[1044/1762] D loss: 0.0066\n",
      "[1124/1762] D loss: 0.0163\n",
      "[1204/1762] D loss: 0.0030\n",
      "[1284/1762] D loss: 0.0041\n",
      "[1364/1762] D loss: 0.0022\n",
      "[1444/1762] D loss: 0.0695\n",
      "[1524/1762] D loss: 0.1661\n",
      "[1604/1762] D loss: 0.3464\n",
      "[1684/1762] D loss: 0.0597\n",
      "[1762/1762] D loss: 0.0088\n",
      "train error: \n",
      " D loss: 0.359095, D accuracy: 98.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.371282, D accuracy: 98.1% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0064\n",
      "[84/1762] D loss: 0.0090\n",
      "[164/1762] D loss: 0.0343\n",
      "[244/1762] D loss: 0.1000\n",
      "[324/1762] D loss: 0.0048\n",
      "[404/1762] D loss: 0.0182\n",
      "[484/1762] D loss: 0.0128\n",
      "[564/1762] D loss: 0.0353\n",
      "[644/1762] D loss: 0.0341\n",
      "[724/1762] D loss: 0.0136\n",
      "[804/1762] D loss: 0.9917\n",
      "[884/1762] D loss: 0.0246\n",
      "[964/1762] D loss: 1.0803\n",
      "[1044/1762] D loss: 0.3643\n",
      "[1124/1762] D loss: 0.3597\n",
      "[1204/1762] D loss: 0.0082\n",
      "[1284/1762] D loss: 0.0732\n",
      "[1364/1762] D loss: 0.0506\n",
      "[1444/1762] D loss: 0.0201\n",
      "[1524/1762] D loss: 0.1392\n",
      "[1604/1762] D loss: 0.0145\n",
      "[1684/1762] D loss: 0.0053\n",
      "[1762/1762] D loss: 0.0413\n",
      "train error: \n",
      " D loss: 0.823360, D accuracy: 62.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.820889, D accuracy: 62.8% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0059\n",
      "[84/1762] D loss: 0.0021\n",
      "[164/1762] D loss: 0.0019\n",
      "[244/1762] D loss: 0.0016\n",
      "[324/1762] D loss: 0.0031\n",
      "[404/1762] D loss: 0.0250\n",
      "[484/1762] D loss: 0.0018\n",
      "[564/1762] D loss: 0.0038\n",
      "[644/1762] D loss: 0.0161\n",
      "[724/1762] D loss: 0.0307\n",
      "[804/1762] D loss: 0.0022\n",
      "[884/1762] D loss: 0.0100\n",
      "[964/1762] D loss: 0.0045\n",
      "[1044/1762] D loss: 0.0031\n",
      "[1124/1762] D loss: 0.0077\n",
      "[1204/1762] D loss: 0.0013\n",
      "[1284/1762] D loss: 0.0018\n",
      "[1364/1762] D loss: 0.0016\n",
      "[1444/1762] D loss: 0.0025\n",
      "[1524/1762] D loss: 0.0066\n",
      "[1604/1762] D loss: 0.0017\n",
      "[1684/1762] D loss: 0.0007\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 3.116061, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.127610, D accuracy: 49.9% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0104\n",
      "[84/1762] D loss: 0.0346\n",
      "[164/1762] D loss: 0.0050\n",
      "[244/1762] D loss: 0.0068\n",
      "[324/1762] D loss: 0.0031\n",
      "[404/1762] D loss: 0.0013\n",
      "[484/1762] D loss: 0.0031\n",
      "[564/1762] D loss: 0.0009\n",
      "[644/1762] D loss: 0.0012\n",
      "[724/1762] D loss: 0.0006\n",
      "[804/1762] D loss: 0.0006\n",
      "[884/1762] D loss: 0.0005\n",
      "[964/1762] D loss: 0.0027\n",
      "[1044/1762] D loss: 0.0012\n",
      "[1124/1762] D loss: 0.0007\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0025\n",
      "[1364/1762] D loss: 0.0063\n",
      "[1444/1762] D loss: 0.0005\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0006\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 2.323798, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.337695, D accuracy: 50.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0008\n",
      "[84/1762] D loss: 0.0010\n",
      "[164/1762] D loss: 0.0011\n",
      "[244/1762] D loss: 0.0012\n",
      "[324/1762] D loss: 0.0005\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0013\n",
      "[644/1762] D loss: 0.0044\n",
      "[724/1762] D loss: 1.7188\n",
      "[804/1762] D loss: 0.5190\n",
      "[884/1762] D loss: 0.0775\n",
      "[964/1762] D loss: 0.0086\n",
      "[1044/1762] D loss: 0.0420\n",
      "[1124/1762] D loss: 0.0029\n",
      "[1204/1762] D loss: 0.0141\n",
      "[1284/1762] D loss: 0.0168\n",
      "[1364/1762] D loss: 0.0030\n",
      "[1444/1762] D loss: 0.0008\n",
      "[1524/1762] D loss: 0.0019\n",
      "[1604/1762] D loss: 0.0009\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0011\n",
      "train error: \n",
      " D loss: 0.983965, D accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.027779, D accuracy: 52.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0005\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0013\n",
      "[404/1762] D loss: 0.0017\n",
      "[484/1762] D loss: 0.0007\n",
      "[564/1762] D loss: 0.0029\n",
      "[644/1762] D loss: 0.0036\n",
      "[724/1762] D loss: 0.0022\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 1.2062\n",
      "[1124/1762] D loss: 0.7679\n",
      "[1204/1762] D loss: 0.5608\n",
      "[1284/1762] D loss: 0.1428\n",
      "[1364/1762] D loss: 0.0254\n",
      "[1444/1762] D loss: 0.0446\n",
      "[1524/1762] D loss: 0.2238\n",
      "[1604/1762] D loss: 0.0823\n",
      "[1684/1762] D loss: 0.1113\n",
      "[1762/1762] D loss: 0.0866\n",
      "train error: \n",
      " D loss: 0.349659, D accuracy: 95.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.359517, D accuracy: 94.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0256\n",
      "[84/1762] D loss: 0.2175\n",
      "[164/1762] D loss: 0.0127\n",
      "[244/1762] D loss: 0.0034\n",
      "[324/1762] D loss: 0.0086\n",
      "[404/1762] D loss: 0.0164\n",
      "[484/1762] D loss: 0.1626\n",
      "[564/1762] D loss: 0.0009\n",
      "[644/1762] D loss: 0.0021\n",
      "[724/1762] D loss: 0.1620\n",
      "[804/1762] D loss: 0.0098\n",
      "[884/1762] D loss: 0.0028\n",
      "[964/1762] D loss: 0.0068\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0021\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0018\n",
      "[1444/1762] D loss: 0.0007\n",
      "[1524/1762] D loss: 0.0193\n",
      "[1604/1762] D loss: 0.0023\n",
      "[1684/1762] D loss: 0.0026\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.253937, D accuracy: 97.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.257896, D accuracy: 96.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0018\n",
      "[84/1762] D loss: 0.0017\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0199\n",
      "[324/1762] D loss: 0.0012\n",
      "[404/1762] D loss: 0.0008\n",
      "[484/1762] D loss: 0.0009\n",
      "[564/1762] D loss: 0.0016\n",
      "[644/1762] D loss: 0.0008\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0009\n",
      "[884/1762] D loss: 0.0007\n",
      "[964/1762] D loss: 0.0010\n",
      "[1044/1762] D loss: 0.0176\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0005\n",
      "[1284/1762] D loss: 0.0009\n",
      "[1364/1762] D loss: 0.0011\n",
      "[1444/1762] D loss: 0.0448\n",
      "[1524/1762] D loss: 0.0028\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0005\n",
      "train error: \n",
      " D loss: 0.886361, D accuracy: 65.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.922796, D accuracy: 65.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0007\n",
      "[164/1762] D loss: 0.0007\n",
      "[244/1762] D loss: 0.0009\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0014\n",
      "[724/1762] D loss: 0.0043\n",
      "[804/1762] D loss: 0.0009\n",
      "[884/1762] D loss: 0.0008\n",
      "[964/1762] D loss: 0.0006\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0010\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.226740, D accuracy: 51.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250305, D accuracy: 51.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0036\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0007\n",
      "[324/1762] D loss: 0.0009\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0009\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0048\n",
      "[1044/1762] D loss: 0.0012\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0007\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0011\n",
      "[1444/1762] D loss: 0.0007\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0027\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.619364, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.660931, D accuracy: 50.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0013\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0162\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0002\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0016\n",
      "[1524/1762] D loss: 0.0002\n",
      "[1604/1762] D loss: 0.0046\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 2.212613, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.255234, D accuracy: 50.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0060\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0008\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0004\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0009\n",
      "[1444/1762] D loss: 0.0010\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 2.121609, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.158422, D accuracy: 50.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0006\n",
      "[164/1762] D loss: 0.0014\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0009\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0007\n",
      "[1444/1762] D loss: 0.0034\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.887256, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.922003, D accuracy: 50.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.953062, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.982662, D accuracy: 50.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0009\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0008\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.654015, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.689417, D accuracy: 50.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0006\n",
      "[164/1762] D loss: 0.0013\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 2.105703, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.140910, D accuracy: 50.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0011\n",
      "[324/1762] D loss: 0.0003\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 2.069620, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.101306, D accuracy: 50.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0005\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0007\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0015\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.550799, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.582794, D accuracy: 50.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4009\n",
      "[84/1762] D loss: 1.3822\n",
      "[164/1762] D loss: 1.4025\n",
      "[244/1762] D loss: 1.4037\n",
      "[324/1762] D loss: 1.3864\n",
      "[404/1762] D loss: 1.3906\n",
      "[484/1762] D loss: 1.3981\n",
      "[564/1762] D loss: 1.4075\n",
      "[644/1762] D loss: 1.3984\n",
      "[724/1762] D loss: 1.4187\n",
      "[804/1762] D loss: 1.3861\n",
      "[884/1762] D loss: 1.3921\n",
      "[964/1762] D loss: 1.3930\n",
      "[1044/1762] D loss: 1.3752\n",
      "[1124/1762] D loss: 1.3819\n",
      "[1204/1762] D loss: 1.4034\n",
      "[1284/1762] D loss: 1.3906\n",
      "[1364/1762] D loss: 1.3854\n",
      "[1444/1762] D loss: 1.3882\n",
      "[1524/1762] D loss: 1.3774\n",
      "[1604/1762] D loss: 1.3873\n",
      "[1684/1762] D loss: 1.3514\n",
      "[1762/1762] D loss: 1.4050\n",
      "train error: \n",
      " D loss: 1.382963, D accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384366, D accuracy: 51.8% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4000\n",
      "[84/1762] D loss: 1.3487\n",
      "[164/1762] D loss: 1.3732\n",
      "[244/1762] D loss: 1.4006\n",
      "[324/1762] D loss: 1.3851\n",
      "[404/1762] D loss: 1.3875\n",
      "[484/1762] D loss: 1.3565\n",
      "[564/1762] D loss: 1.3724\n",
      "[644/1762] D loss: 1.3835\n",
      "[724/1762] D loss: 1.3823\n",
      "[804/1762] D loss: 1.3987\n",
      "[884/1762] D loss: 1.3771\n",
      "[964/1762] D loss: 1.3785\n",
      "[1044/1762] D loss: 1.3550\n",
      "[1124/1762] D loss: 1.3644\n",
      "[1204/1762] D loss: 1.3784\n",
      "[1284/1762] D loss: 1.3773\n",
      "[1364/1762] D loss: 1.3793\n",
      "[1444/1762] D loss: 1.3657\n",
      "[1524/1762] D loss: 1.3389\n",
      "[1604/1762] D loss: 1.3659\n",
      "[1684/1762] D loss: 1.3996\n",
      "[1762/1762] D loss: 1.3720\n",
      "train error: \n",
      " D loss: 1.371202, D accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366748, D accuracy: 59.3% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3741\n",
      "[84/1762] D loss: 1.3819\n",
      "[164/1762] D loss: 1.3729\n",
      "[244/1762] D loss: 1.3541\n",
      "[324/1762] D loss: 1.3799\n",
      "[404/1762] D loss: 1.3734\n",
      "[484/1762] D loss: 1.3538\n",
      "[564/1762] D loss: 1.3435\n",
      "[644/1762] D loss: 1.3443\n",
      "[724/1762] D loss: 1.3197\n",
      "[804/1762] D loss: 1.3424\n",
      "[884/1762] D loss: 1.3624\n",
      "[964/1762] D loss: 1.3619\n",
      "[1044/1762] D loss: 1.3214\n",
      "[1124/1762] D loss: 1.3901\n",
      "[1204/1762] D loss: 1.3257\n",
      "[1284/1762] D loss: 1.3779\n",
      "[1364/1762] D loss: 1.3462\n",
      "[1444/1762] D loss: 1.3802\n",
      "[1524/1762] D loss: 1.3779\n",
      "[1604/1762] D loss: 1.3295\n",
      "[1684/1762] D loss: 1.3299\n",
      "[1762/1762] D loss: 1.3368\n",
      "train error: \n",
      " D loss: 1.349050, D accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348878, D accuracy: 61.8% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3293\n",
      "[84/1762] D loss: 1.3119\n",
      "[164/1762] D loss: 1.2932\n",
      "[244/1762] D loss: 1.3357\n",
      "[324/1762] D loss: 1.3539\n",
      "[404/1762] D loss: 1.3788\n",
      "[484/1762] D loss: 1.3069\n",
      "[564/1762] D loss: 1.3506\n",
      "[644/1762] D loss: 1.2949\n",
      "[724/1762] D loss: 1.2933\n",
      "[804/1762] D loss: 1.3106\n",
      "[884/1762] D loss: 1.3267\n",
      "[964/1762] D loss: 1.3183\n",
      "[1044/1762] D loss: 1.3187\n",
      "[1124/1762] D loss: 1.2823\n",
      "[1204/1762] D loss: 1.2705\n",
      "[1284/1762] D loss: 1.2558\n",
      "[1364/1762] D loss: 1.3231\n",
      "[1444/1762] D loss: 1.3001\n",
      "[1524/1762] D loss: 1.2943\n",
      "[1604/1762] D loss: 1.2443\n",
      "[1684/1762] D loss: 1.2770\n",
      "[1762/1762] D loss: 1.2488\n",
      "train error: \n",
      " D loss: 1.292767, D accuracy: 72.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291187, D accuracy: 72.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3148\n",
      "[84/1762] D loss: 1.2459\n",
      "[164/1762] D loss: 1.1719\n",
      "[244/1762] D loss: 1.2564\n",
      "[324/1762] D loss: 1.2793\n",
      "[404/1762] D loss: 1.2393\n",
      "[484/1762] D loss: 1.2076\n",
      "[564/1762] D loss: 1.2290\n",
      "[644/1762] D loss: 1.1759\n",
      "[724/1762] D loss: 1.1436\n",
      "[804/1762] D loss: 1.0804\n",
      "[884/1762] D loss: 1.2393\n",
      "[964/1762] D loss: 1.1414\n",
      "[1044/1762] D loss: 1.2751\n",
      "[1124/1762] D loss: 1.0790\n",
      "[1204/1762] D loss: 1.1715\n",
      "[1284/1762] D loss: 1.1198\n",
      "[1364/1762] D loss: 1.1873\n",
      "[1444/1762] D loss: 1.1704\n",
      "[1524/1762] D loss: 0.9189\n",
      "[1604/1762] D loss: 1.0206\n",
      "[1684/1762] D loss: 0.9658\n",
      "[1762/1762] D loss: 1.1095\n",
      "train error: \n",
      " D loss: 1.114192, D accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.110798, D accuracy: 86.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0800\n",
      "[84/1762] D loss: 1.2158\n",
      "[164/1762] D loss: 1.0546\n",
      "[244/1762] D loss: 1.1012\n",
      "[324/1762] D loss: 0.9607\n",
      "[404/1762] D loss: 0.9622\n",
      "[484/1762] D loss: 0.9231\n",
      "[564/1762] D loss: 0.9919\n",
      "[644/1762] D loss: 0.7985\n",
      "[724/1762] D loss: 0.7322\n",
      "[804/1762] D loss: 0.8913\n",
      "[884/1762] D loss: 0.6860\n",
      "[964/1762] D loss: 0.7670\n",
      "[1044/1762] D loss: 0.5651\n",
      "[1124/1762] D loss: 0.5705\n",
      "[1204/1762] D loss: 0.8211\n",
      "[1284/1762] D loss: 0.7528\n",
      "[1364/1762] D loss: 0.8108\n",
      "[1444/1762] D loss: 0.5786\n",
      "[1524/1762] D loss: 0.5107\n",
      "[1604/1762] D loss: 0.8542\n",
      "[1684/1762] D loss: 0.7575\n",
      "[1762/1762] D loss: 0.3549\n",
      "train error: \n",
      " D loss: 0.636202, D accuracy: 95.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.637315, D accuracy: 97.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4729\n",
      "[84/1762] D loss: 0.5124\n",
      "[164/1762] D loss: 0.4645\n",
      "[244/1762] D loss: 0.4189\n",
      "[324/1762] D loss: 0.3856\n",
      "[404/1762] D loss: 0.3584\n",
      "[484/1762] D loss: 0.3936\n",
      "[564/1762] D loss: 0.3485\n",
      "[644/1762] D loss: 0.3770\n",
      "[724/1762] D loss: 0.3753\n",
      "[804/1762] D loss: 0.4122\n",
      "[884/1762] D loss: 0.5061\n",
      "[964/1762] D loss: 0.3645\n",
      "[1044/1762] D loss: 0.3384\n",
      "[1124/1762] D loss: 0.3809\n",
      "[1204/1762] D loss: 0.5063\n",
      "[1284/1762] D loss: 0.2408\n",
      "[1364/1762] D loss: 0.1874\n",
      "[1444/1762] D loss: 0.4236\n",
      "[1524/1762] D loss: 0.2259\n",
      "[1604/1762] D loss: 0.1947\n",
      "[1684/1762] D loss: 0.1796\n",
      "[1762/1762] D loss: 0.1424\n",
      "train error: \n",
      " D loss: 0.274183, D accuracy: 99.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.282794, D accuracy: 99.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2154\n",
      "[84/1762] D loss: 0.1427\n",
      "[164/1762] D loss: 0.1544\n",
      "[244/1762] D loss: 0.1389\n",
      "[324/1762] D loss: 0.2123\n",
      "[404/1762] D loss: 0.0569\n",
      "[484/1762] D loss: 0.0469\n",
      "[564/1762] D loss: 0.1400\n",
      "[644/1762] D loss: 0.1021\n",
      "[724/1762] D loss: 0.0879\n",
      "[804/1762] D loss: 0.0505\n",
      "[884/1762] D loss: 0.0891\n",
      "[964/1762] D loss: 0.0544\n",
      "[1044/1762] D loss: 0.0287\n",
      "[1124/1762] D loss: 0.1668\n",
      "[1204/1762] D loss: 0.1324\n",
      "[1284/1762] D loss: 0.1114\n",
      "[1364/1762] D loss: 0.2263\n",
      "[1444/1762] D loss: 0.0926\n",
      "[1524/1762] D loss: 0.0534\n",
      "[1604/1762] D loss: 0.0426\n",
      "[1684/1762] D loss: 0.1090\n",
      "[1762/1762] D loss: 0.1712\n",
      "train error: \n",
      " D loss: 0.190261, D accuracy: 98.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.193299, D accuracy: 98.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0732\n",
      "[84/1762] D loss: 0.0833\n",
      "[164/1762] D loss: 0.0722\n",
      "[244/1762] D loss: 0.0631\n",
      "[324/1762] D loss: 0.1180\n",
      "[404/1762] D loss: 0.0656\n",
      "[484/1762] D loss: 0.0300\n",
      "[564/1762] D loss: 0.0414\n",
      "[644/1762] D loss: 0.0645\n",
      "[724/1762] D loss: 0.1292\n",
      "[804/1762] D loss: 0.0461\n",
      "[884/1762] D loss: 0.1324\n",
      "[964/1762] D loss: 0.2355\n",
      "[1044/1762] D loss: 0.0275\n",
      "[1124/1762] D loss: 0.3487\n",
      "[1204/1762] D loss: 0.0430\n",
      "[1284/1762] D loss: 0.0289\n",
      "[1364/1762] D loss: 0.0213\n",
      "[1444/1762] D loss: 0.0168\n",
      "[1524/1762] D loss: 0.0202\n",
      "[1604/1762] D loss: 0.1253\n",
      "[1684/1762] D loss: 0.0216\n",
      "[1762/1762] D loss: 0.0140\n",
      "train error: \n",
      " D loss: 0.253693, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.265298, D accuracy: 99.7% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0317\n",
      "[84/1762] D loss: 0.0349\n",
      "[164/1762] D loss: 0.0377\n",
      "[244/1762] D loss: 0.0344\n",
      "[324/1762] D loss: 0.0255\n",
      "[404/1762] D loss: 0.0854\n",
      "[484/1762] D loss: 0.0364\n",
      "[564/1762] D loss: 0.0515\n",
      "[644/1762] D loss: 0.0194\n",
      "[724/1762] D loss: 0.0112\n",
      "[804/1762] D loss: 0.0394\n",
      "[884/1762] D loss: 0.0165\n",
      "[964/1762] D loss: 0.0145\n",
      "[1044/1762] D loss: 0.0171\n",
      "[1124/1762] D loss: 0.0110\n",
      "[1204/1762] D loss: 0.0416\n",
      "[1284/1762] D loss: 0.0175\n",
      "[1364/1762] D loss: 0.0316\n",
      "[1444/1762] D loss: 0.0144\n",
      "[1524/1762] D loss: 0.0262\n",
      "[1604/1762] D loss: 0.0070\n",
      "[1684/1762] D loss: 0.0396\n",
      "[1762/1762] D loss: 0.0153\n",
      "train error: \n",
      " D loss: 0.161201, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.167522, D accuracy: 99.9% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0105\n",
      "[84/1762] D loss: 0.0875\n",
      "[164/1762] D loss: 0.0351\n",
      "[244/1762] D loss: 0.0299\n",
      "[324/1762] D loss: 0.0308\n",
      "[404/1762] D loss: 0.0864\n",
      "[484/1762] D loss: 0.0216\n",
      "[564/1762] D loss: 0.0174\n",
      "[644/1762] D loss: 0.0190\n",
      "[724/1762] D loss: 0.0401\n",
      "[804/1762] D loss: 0.0059\n",
      "[884/1762] D loss: 0.0128\n",
      "[964/1762] D loss: 0.0074\n",
      "[1044/1762] D loss: 0.0063\n",
      "[1124/1762] D loss: 0.0275\n",
      "[1204/1762] D loss: 0.0408\n",
      "[1284/1762] D loss: 0.0099\n",
      "[1364/1762] D loss: 0.0121\n",
      "[1444/1762] D loss: 0.0095\n",
      "[1524/1762] D loss: 0.0133\n",
      "[1604/1762] D loss: 0.0211\n",
      "[1684/1762] D loss: 0.0132\n",
      "[1762/1762] D loss: 0.0092\n",
      "train error: \n",
      " D loss: 0.164090, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.169517, D accuracy: 99.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0146\n",
      "[84/1762] D loss: 0.0213\n",
      "[164/1762] D loss: 0.0979\n",
      "[244/1762] D loss: 0.0118\n",
      "[324/1762] D loss: 0.0095\n",
      "[404/1762] D loss: 0.0079\n",
      "[484/1762] D loss: 0.0055\n",
      "[564/1762] D loss: 0.0061\n",
      "[644/1762] D loss: 0.0495\n",
      "[724/1762] D loss: 0.0119\n",
      "[804/1762] D loss: 0.0152\n",
      "[884/1762] D loss: 0.0073\n",
      "[964/1762] D loss: 0.0480\n",
      "[1044/1762] D loss: 0.0084\n",
      "[1124/1762] D loss: 0.0083\n",
      "[1204/1762] D loss: 0.0106\n",
      "[1284/1762] D loss: 0.0206\n",
      "[1364/1762] D loss: 0.0159\n",
      "[1444/1762] D loss: 0.0044\n",
      "[1524/1762] D loss: 0.0221\n",
      "[1604/1762] D loss: 0.0038\n",
      "[1684/1762] D loss: 0.0098\n",
      "[1762/1762] D loss: 0.0093\n",
      "train error: \n",
      " D loss: 0.157446, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.159143, D accuracy: 100.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0230\n",
      "[84/1762] D loss: 0.0119\n",
      "[164/1762] D loss: 0.0115\n",
      "[244/1762] D loss: 0.0059\n",
      "[324/1762] D loss: 0.0101\n",
      "[404/1762] D loss: 0.0042\n",
      "[484/1762] D loss: 0.0043\n",
      "[564/1762] D loss: 0.0031\n",
      "[644/1762] D loss: 0.0048\n",
      "[724/1762] D loss: 0.0084\n",
      "[804/1762] D loss: 0.0479\n",
      "[884/1762] D loss: 0.0040\n",
      "[964/1762] D loss: 0.0057\n",
      "[1044/1762] D loss: 0.0228\n",
      "[1124/1762] D loss: 0.0053\n",
      "[1204/1762] D loss: 0.0052\n",
      "[1284/1762] D loss: 0.0067\n",
      "[1364/1762] D loss: 0.0263\n",
      "[1444/1762] D loss: 0.0232\n",
      "[1524/1762] D loss: 0.0057\n",
      "[1604/1762] D loss: 0.0200\n",
      "[1684/1762] D loss: 0.0117\n",
      "[1762/1762] D loss: 0.0030\n",
      "train error: \n",
      " D loss: 0.143755, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.149596, D accuracy: 99.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0114\n",
      "[84/1762] D loss: 0.0081\n",
      "[164/1762] D loss: 0.0045\n",
      "[244/1762] D loss: 0.0104\n",
      "[324/1762] D loss: 0.0132\n",
      "[404/1762] D loss: 0.0497\n",
      "[484/1762] D loss: 0.0103\n",
      "[564/1762] D loss: 0.0035\n",
      "[644/1762] D loss: 0.0052\n",
      "[724/1762] D loss: 0.0166\n",
      "[804/1762] D loss: 0.0050\n",
      "[884/1762] D loss: 0.0062\n",
      "[964/1762] D loss: 0.0032\n",
      "[1044/1762] D loss: 0.0069\n",
      "[1124/1762] D loss: 0.0061\n",
      "[1204/1762] D loss: 0.0204\n",
      "[1284/1762] D loss: 0.0115\n",
      "[1364/1762] D loss: 0.0032\n",
      "[1444/1762] D loss: 0.0021\n",
      "[1524/1762] D loss: 0.0121\n",
      "[1604/1762] D loss: 0.0163\n",
      "[1684/1762] D loss: 0.0130\n",
      "[1762/1762] D loss: 0.0097\n",
      "train error: \n",
      " D loss: 0.189741, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.194861, D accuracy: 99.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0586\n",
      "[84/1762] D loss: 0.0133\n",
      "[164/1762] D loss: 0.0029\n",
      "[244/1762] D loss: 0.0019\n",
      "[324/1762] D loss: 0.0025\n",
      "[404/1762] D loss: 0.0091\n",
      "[484/1762] D loss: 0.0039\n",
      "[564/1762] D loss: 0.0046\n",
      "[644/1762] D loss: 0.0088\n",
      "[724/1762] D loss: 0.0111\n",
      "[804/1762] D loss: 0.0494\n",
      "[884/1762] D loss: 0.0073\n",
      "[964/1762] D loss: 0.0029\n",
      "[1044/1762] D loss: 0.0089\n",
      "[1124/1762] D loss: 0.0044\n",
      "[1204/1762] D loss: 0.0056\n",
      "[1284/1762] D loss: 0.0040\n",
      "[1364/1762] D loss: 0.0083\n",
      "[1444/1762] D loss: 0.0093\n",
      "[1524/1762] D loss: 0.0122\n",
      "[1604/1762] D loss: 0.0020\n",
      "[1684/1762] D loss: 0.0038\n",
      "[1762/1762] D loss: 0.0037\n",
      "train error: \n",
      " D loss: 0.160342, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.172224, D accuracy: 99.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0030\n",
      "[84/1762] D loss: 0.0034\n",
      "[164/1762] D loss: 0.0068\n",
      "[244/1762] D loss: 0.0294\n",
      "[324/1762] D loss: 0.0045\n",
      "[404/1762] D loss: 0.0044\n",
      "[484/1762] D loss: 0.0021\n",
      "[564/1762] D loss: 0.0025\n",
      "[644/1762] D loss: 0.0036\n",
      "[724/1762] D loss: 0.0339\n",
      "[804/1762] D loss: 0.0021\n",
      "[884/1762] D loss: 0.0119\n",
      "[964/1762] D loss: 0.0034\n",
      "[1044/1762] D loss: 0.0030\n",
      "[1124/1762] D loss: 0.0067\n",
      "[1204/1762] D loss: 0.0029\n",
      "[1284/1762] D loss: 0.0020\n",
      "[1364/1762] D loss: 0.0665\n",
      "[1444/1762] D loss: 0.0389\n",
      "[1524/1762] D loss: 0.0079\n",
      "[1604/1762] D loss: 0.0116\n",
      "[1684/1762] D loss: 0.0125\n",
      "[1762/1762] D loss: 0.0016\n",
      "train error: \n",
      " D loss: 0.141813, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.144862, D accuracy: 100.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0014\n",
      "[164/1762] D loss: 0.0015\n",
      "[244/1762] D loss: 0.0016\n",
      "[324/1762] D loss: 0.0081\n",
      "[404/1762] D loss: 0.0018\n",
      "[484/1762] D loss: 0.0040\n",
      "[564/1762] D loss: 0.0020\n",
      "[644/1762] D loss: 0.0017\n",
      "[724/1762] D loss: 0.0068\n",
      "[804/1762] D loss: 0.0027\n",
      "[884/1762] D loss: 0.0090\n",
      "[964/1762] D loss: 0.0064\n",
      "[1044/1762] D loss: 0.0091\n",
      "[1124/1762] D loss: 0.0023\n",
      "[1204/1762] D loss: 0.0023\n",
      "[1284/1762] D loss: 0.0016\n",
      "[1364/1762] D loss: 0.0027\n",
      "[1444/1762] D loss: 0.0144\n",
      "[1524/1762] D loss: 0.0052\n",
      "[1604/1762] D loss: 0.0049\n",
      "[1684/1762] D loss: 0.0025\n",
      "[1762/1762] D loss: 0.0022\n",
      "train error: \n",
      " D loss: 0.161136, D accuracy: 100.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.171909, D accuracy: 99.8% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0028\n",
      "[84/1762] D loss: 0.0023\n",
      "[164/1762] D loss: 0.0031\n",
      "[244/1762] D loss: 0.0032\n",
      "[324/1762] D loss: 0.0030\n",
      "[404/1762] D loss: 0.0071\n",
      "[484/1762] D loss: 0.0058\n",
      "[564/1762] D loss: 0.0043\n",
      "[644/1762] D loss: 0.0055\n",
      "[724/1762] D loss: 0.0015\n",
      "[804/1762] D loss: 0.0030\n",
      "[884/1762] D loss: 0.0025\n",
      "[964/1762] D loss: 0.0080\n",
      "[1044/1762] D loss: 0.0097\n",
      "[1124/1762] D loss: 0.0010\n",
      "[1204/1762] D loss: 0.0029\n",
      "[1284/1762] D loss: 0.0095\n",
      "[1364/1762] D loss: 0.0016\n",
      "[1444/1762] D loss: 0.0044\n",
      "[1524/1762] D loss: 0.0029\n",
      "[1604/1762] D loss: 0.0018\n",
      "[1684/1762] D loss: 0.0026\n",
      "[1762/1762] D loss: 0.0032\n",
      "train error: \n",
      " D loss: 0.192926, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.201193, D accuracy: 99.7% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0017\n",
      "[84/1762] D loss: 0.0052\n",
      "[164/1762] D loss: 0.0013\n",
      "[244/1762] D loss: 0.0053\n",
      "[324/1762] D loss: 0.0133\n",
      "[404/1762] D loss: 0.0017\n",
      "[484/1762] D loss: 0.0012\n",
      "[564/1762] D loss: 0.0011\n",
      "[644/1762] D loss: 0.0023\n",
      "[724/1762] D loss: 0.0048\n",
      "[804/1762] D loss: 0.0013\n",
      "[884/1762] D loss: 0.0031\n",
      "[964/1762] D loss: 0.0016\n",
      "[1044/1762] D loss: 0.0018\n",
      "[1124/1762] D loss: 0.0056\n",
      "[1204/1762] D loss: 0.0011\n",
      "[1284/1762] D loss: 0.0040\n",
      "[1364/1762] D loss: 0.0017\n",
      "[1444/1762] D loss: 0.0014\n",
      "[1524/1762] D loss: 0.0037\n",
      "[1604/1762] D loss: 0.0048\n",
      "[1684/1762] D loss: 0.0269\n",
      "[1762/1762] D loss: 0.0026\n",
      "train error: \n",
      " D loss: 0.216257, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.225464, D accuracy: 99.8% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0041\n",
      "[84/1762] D loss: 0.0038\n",
      "[164/1762] D loss: 0.0041\n",
      "[244/1762] D loss: 0.0019\n",
      "[324/1762] D loss: 0.0022\n",
      "[404/1762] D loss: 0.0011\n",
      "[484/1762] D loss: 0.0069\n",
      "[564/1762] D loss: 0.0030\n",
      "[644/1762] D loss: 0.0008\n",
      "[724/1762] D loss: 0.0150\n",
      "[804/1762] D loss: 0.0016\n",
      "[884/1762] D loss: 0.0009\n",
      "[964/1762] D loss: 0.0075\n",
      "[1044/1762] D loss: 0.0077\n",
      "[1124/1762] D loss: 0.0036\n",
      "[1204/1762] D loss: 0.0030\n",
      "[1284/1762] D loss: 0.0036\n",
      "[1364/1762] D loss: 0.0040\n",
      "[1444/1762] D loss: 0.0018\n",
      "[1524/1762] D loss: 0.0009\n",
      "[1604/1762] D loss: 0.0173\n",
      "[1684/1762] D loss: 0.0119\n",
      "[1762/1762] D loss: 0.0007\n",
      "train error: \n",
      " D loss: 0.237947, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.248900, D accuracy: 99.8% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3942\n",
      "[84/1762] D loss: 1.3849\n",
      "[164/1762] D loss: 1.3824\n",
      "[244/1762] D loss: 1.4036\n",
      "[324/1762] D loss: 1.4113\n",
      "[404/1762] D loss: 1.4001\n",
      "[484/1762] D loss: 1.3869\n",
      "[564/1762] D loss: 1.3859\n",
      "[644/1762] D loss: 1.3998\n",
      "[724/1762] D loss: 1.3960\n",
      "[804/1762] D loss: 1.4087\n",
      "[884/1762] D loss: 1.3651\n",
      "[964/1762] D loss: 1.4160\n",
      "[1044/1762] D loss: 1.3926\n",
      "[1124/1762] D loss: 1.3976\n",
      "[1204/1762] D loss: 1.3845\n",
      "[1284/1762] D loss: 1.3912\n",
      "[1364/1762] D loss: 1.4110\n",
      "[1444/1762] D loss: 1.3909\n",
      "[1524/1762] D loss: 1.3744\n",
      "[1604/1762] D loss: 1.3963\n",
      "[1684/1762] D loss: 1.4005\n",
      "[1762/1762] D loss: 1.3624\n",
      "train error: \n",
      " D loss: 1.387501, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389311, D accuracy: 50.3% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3846\n",
      "[84/1762] D loss: 1.3950\n",
      "[164/1762] D loss: 1.3937\n",
      "[244/1762] D loss: 1.3838\n",
      "[324/1762] D loss: 1.3893\n",
      "[404/1762] D loss: 1.3930\n",
      "[484/1762] D loss: 1.3824\n",
      "[564/1762] D loss: 1.3839\n",
      "[644/1762] D loss: 1.3898\n",
      "[724/1762] D loss: 1.3694\n",
      "[804/1762] D loss: 1.3891\n",
      "[884/1762] D loss: 1.4042\n",
      "[964/1762] D loss: 1.3858\n",
      "[1044/1762] D loss: 1.3688\n",
      "[1124/1762] D loss: 1.3793\n",
      "[1204/1762] D loss: 1.3901\n",
      "[1284/1762] D loss: 1.3904\n",
      "[1364/1762] D loss: 1.3953\n",
      "[1444/1762] D loss: 1.3859\n",
      "[1524/1762] D loss: 1.3854\n",
      "[1604/1762] D loss: 1.4039\n",
      "[1684/1762] D loss: 1.3784\n",
      "[1762/1762] D loss: 1.3984\n",
      "train error: \n",
      " D loss: 1.385379, D accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387144, D accuracy: 51.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4067\n",
      "[84/1762] D loss: 1.3798\n",
      "[164/1762] D loss: 1.3849\n",
      "[244/1762] D loss: 1.3764\n",
      "[324/1762] D loss: 1.3880\n",
      "[404/1762] D loss: 1.3860\n",
      "[484/1762] D loss: 1.4047\n",
      "[564/1762] D loss: 1.3990\n",
      "[644/1762] D loss: 1.3874\n",
      "[724/1762] D loss: 1.3852\n",
      "[804/1762] D loss: 1.3890\n",
      "[884/1762] D loss: 1.3758\n",
      "[964/1762] D loss: 1.3852\n",
      "[1044/1762] D loss: 1.4006\n",
      "[1124/1762] D loss: 1.3883\n",
      "[1204/1762] D loss: 1.3874\n",
      "[1284/1762] D loss: 1.3888\n",
      "[1364/1762] D loss: 1.3998\n",
      "[1444/1762] D loss: 1.3909\n",
      "[1524/1762] D loss: 1.3974\n",
      "[1604/1762] D loss: 1.4027\n",
      "[1684/1762] D loss: 1.3689\n",
      "[1762/1762] D loss: 1.3854\n",
      "train error: \n",
      " D loss: 1.384272, D accuracy: 51.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385243, D accuracy: 51.6% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871\n",
      "[84/1762] D loss: 1.4048\n",
      "[164/1762] D loss: 1.3826\n",
      "[244/1762] D loss: 1.3595\n",
      "[324/1762] D loss: 1.3760\n",
      "[404/1762] D loss: 1.3827\n",
      "[484/1762] D loss: 1.3705\n",
      "[564/1762] D loss: 1.3977\n",
      "[644/1762] D loss: 1.3825\n",
      "[724/1762] D loss: 1.3938\n",
      "[804/1762] D loss: 1.3844\n",
      "[884/1762] D loss: 1.4061\n",
      "[964/1762] D loss: 1.3818\n",
      "[1044/1762] D loss: 1.3886\n",
      "[1124/1762] D loss: 1.3857\n",
      "[1204/1762] D loss: 1.3899\n",
      "[1284/1762] D loss: 1.3578\n",
      "[1364/1762] D loss: 1.4016\n",
      "[1444/1762] D loss: 1.3709\n",
      "[1524/1762] D loss: 1.3918\n",
      "[1604/1762] D loss: 1.3863\n",
      "[1684/1762] D loss: 1.3791\n",
      "[1762/1762] D loss: 1.3707\n",
      "train error: \n",
      " D loss: 1.382687, D accuracy: 52.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383468, D accuracy: 51.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884\n",
      "[84/1762] D loss: 1.3847\n",
      "[164/1762] D loss: 1.3746\n",
      "[244/1762] D loss: 1.3935\n",
      "[324/1762] D loss: 1.3801\n",
      "[404/1762] D loss: 1.3623\n",
      "[484/1762] D loss: 1.3776\n",
      "[564/1762] D loss: 1.3811\n",
      "[644/1762] D loss: 1.3808\n",
      "[724/1762] D loss: 1.3940\n",
      "[804/1762] D loss: 1.3647\n",
      "[884/1762] D loss: 1.3877\n",
      "[964/1762] D loss: 1.3834\n",
      "[1044/1762] D loss: 1.3853\n",
      "[1124/1762] D loss: 1.3846\n",
      "[1204/1762] D loss: 1.3723\n",
      "[1284/1762] D loss: 1.3813\n",
      "[1364/1762] D loss: 1.3917\n",
      "[1444/1762] D loss: 1.3586\n",
      "[1524/1762] D loss: 1.3628\n",
      "[1604/1762] D loss: 1.3794\n",
      "[1684/1762] D loss: 1.3850\n",
      "[1762/1762] D loss: 1.3808\n",
      "train error: \n",
      " D loss: 1.381382, D accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384594, D accuracy: 52.3% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3799\n",
      "[84/1762] D loss: 1.3882\n",
      "[164/1762] D loss: 1.3682\n",
      "[244/1762] D loss: 1.3744\n",
      "[324/1762] D loss: 1.3865\n",
      "[404/1762] D loss: 1.3789\n",
      "[484/1762] D loss: 1.3771\n",
      "[564/1762] D loss: 1.3906\n",
      "[644/1762] D loss: 1.3578\n",
      "[724/1762] D loss: 1.3745\n",
      "[804/1762] D loss: 1.3730\n",
      "[884/1762] D loss: 1.4112\n",
      "[964/1762] D loss: 1.3832\n",
      "[1044/1762] D loss: 1.3755\n",
      "[1124/1762] D loss: 1.3887\n",
      "[1204/1762] D loss: 1.3830\n",
      "[1284/1762] D loss: 1.3817\n",
      "[1364/1762] D loss: 1.3869\n",
      "[1444/1762] D loss: 1.3729\n",
      "[1524/1762] D loss: 1.3949\n",
      "[1604/1762] D loss: 1.3933\n",
      "[1684/1762] D loss: 1.3708\n",
      "[1762/1762] D loss: 1.3948\n",
      "train error: \n",
      " D loss: 1.380405, D accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381519, D accuracy: 54.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3761\n",
      "[84/1762] D loss: 1.3694\n",
      "[164/1762] D loss: 1.3986\n",
      "[244/1762] D loss: 1.3802\n",
      "[324/1762] D loss: 1.3677\n",
      "[404/1762] D loss: 1.3879\n",
      "[484/1762] D loss: 1.3646\n",
      "[564/1762] D loss: 1.3770\n",
      "[644/1762] D loss: 1.3982\n",
      "[724/1762] D loss: 1.3689\n",
      "[804/1762] D loss: 1.3702\n",
      "[884/1762] D loss: 1.3797\n",
      "[964/1762] D loss: 1.3602\n",
      "[1044/1762] D loss: 1.3830\n",
      "[1124/1762] D loss: 1.3759\n",
      "[1204/1762] D loss: 1.3865\n",
      "[1284/1762] D loss: 1.3729\n",
      "[1364/1762] D loss: 1.3733\n",
      "[1444/1762] D loss: 1.3740\n",
      "[1524/1762] D loss: 1.4013\n",
      "[1604/1762] D loss: 1.3690\n",
      "[1684/1762] D loss: 1.3889\n",
      "[1762/1762] D loss: 1.3953\n",
      "train error: \n",
      " D loss: 1.380475, D accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379534, D accuracy: 54.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3675\n",
      "[84/1762] D loss: 1.3749\n",
      "[164/1762] D loss: 1.3861\n",
      "[244/1762] D loss: 1.3669\n",
      "[324/1762] D loss: 1.3867\n",
      "[404/1762] D loss: 1.3710\n",
      "[484/1762] D loss: 1.3850\n",
      "[564/1762] D loss: 1.3607\n",
      "[644/1762] D loss: 1.3972\n",
      "[724/1762] D loss: 1.3856\n",
      "[804/1762] D loss: 1.3830\n",
      "[884/1762] D loss: 1.3670\n",
      "[964/1762] D loss: 1.3752\n",
      "[1044/1762] D loss: 1.3655\n",
      "[1124/1762] D loss: 1.3756\n",
      "[1204/1762] D loss: 1.3643\n",
      "[1284/1762] D loss: 1.3905\n",
      "[1364/1762] D loss: 1.4000\n",
      "[1444/1762] D loss: 1.3856\n",
      "[1524/1762] D loss: 1.3752\n",
      "[1604/1762] D loss: 1.3901\n",
      "[1684/1762] D loss: 1.3613\n",
      "[1762/1762] D loss: 1.3748\n",
      "train error: \n",
      " D loss: 1.378251, D accuracy: 55.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379790, D accuracy: 53.4% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3732\n",
      "[84/1762] D loss: 1.3500\n",
      "[164/1762] D loss: 1.3679\n",
      "[244/1762] D loss: 1.3938\n",
      "[324/1762] D loss: 1.3739\n",
      "[404/1762] D loss: 1.3709\n",
      "[484/1762] D loss: 1.3821\n",
      "[564/1762] D loss: 1.3939\n",
      "[644/1762] D loss: 1.3738\n",
      "[724/1762] D loss: 1.3647\n",
      "[804/1762] D loss: 1.3658\n",
      "[884/1762] D loss: 1.3631\n",
      "[964/1762] D loss: 1.3667\n",
      "[1044/1762] D loss: 1.3701\n",
      "[1124/1762] D loss: 1.3694\n",
      "[1204/1762] D loss: 1.3922\n",
      "[1284/1762] D loss: 1.3758\n",
      "[1364/1762] D loss: 1.3818\n",
      "[1444/1762] D loss: 1.3751\n",
      "[1524/1762] D loss: 1.3779\n",
      "[1604/1762] D loss: 1.3898\n",
      "[1684/1762] D loss: 1.3757\n",
      "[1762/1762] D loss: 1.3760\n",
      "train error: \n",
      " D loss: 1.377103, D accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379422, D accuracy: 54.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885\n",
      "[84/1762] D loss: 1.3726\n",
      "[164/1762] D loss: 1.3698\n",
      "[244/1762] D loss: 1.3847\n",
      "[324/1762] D loss: 1.3799\n",
      "[404/1762] D loss: 1.3842\n",
      "[484/1762] D loss: 1.3814\n",
      "[564/1762] D loss: 1.3616\n",
      "[644/1762] D loss: 1.3690\n",
      "[724/1762] D loss: 1.3574\n",
      "[804/1762] D loss: 1.3908\n",
      "[884/1762] D loss: 1.3663\n",
      "[964/1762] D loss: 1.3631\n",
      "[1044/1762] D loss: 1.3757\n",
      "[1124/1762] D loss: 1.3843\n",
      "[1204/1762] D loss: 1.3969\n",
      "[1284/1762] D loss: 1.3484\n",
      "[1364/1762] D loss: 1.3740\n",
      "[1444/1762] D loss: 1.3576\n",
      "[1524/1762] D loss: 1.3692\n",
      "[1604/1762] D loss: 1.3855\n",
      "[1684/1762] D loss: 1.3862\n",
      "[1762/1762] D loss: 1.3828\n",
      "train error: \n",
      " D loss: 1.377570, D accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378217, D accuracy: 55.2% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3622\n",
      "[84/1762] D loss: 1.3535\n",
      "[164/1762] D loss: 1.3609\n",
      "[244/1762] D loss: 1.3874\n",
      "[324/1762] D loss: 1.3671\n",
      "[404/1762] D loss: 1.3905\n",
      "[484/1762] D loss: 1.3746\n",
      "[564/1762] D loss: 1.3692\n",
      "[644/1762] D loss: 1.3776\n",
      "[724/1762] D loss: 1.3728\n",
      "[804/1762] D loss: 1.3642\n",
      "[884/1762] D loss: 1.3755\n",
      "[964/1762] D loss: 1.3802\n",
      "[1044/1762] D loss: 1.3892\n",
      "[1124/1762] D loss: 1.3843\n",
      "[1204/1762] D loss: 1.3826\n",
      "[1284/1762] D loss: 1.3949\n",
      "[1364/1762] D loss: 1.3717\n",
      "[1444/1762] D loss: 1.3926\n",
      "[1524/1762] D loss: 1.3902\n",
      "[1604/1762] D loss: 1.3645\n",
      "[1684/1762] D loss: 1.3705\n",
      "[1762/1762] D loss: 1.3807\n",
      "train error: \n",
      " D loss: 1.375047, D accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375775, D accuracy: 55.7% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911\n",
      "[84/1762] D loss: 1.3656\n",
      "[164/1762] D loss: 1.3718\n",
      "[244/1762] D loss: 1.3841\n",
      "[324/1762] D loss: 1.3815\n",
      "[404/1762] D loss: 1.3502\n",
      "[484/1762] D loss: 1.3780\n",
      "[564/1762] D loss: 1.3583\n",
      "[644/1762] D loss: 1.3960\n",
      "[724/1762] D loss: 1.3796\n",
      "[804/1762] D loss: 1.3922\n",
      "[884/1762] D loss: 1.3662\n",
      "[964/1762] D loss: 1.3676\n",
      "[1044/1762] D loss: 1.3654\n",
      "[1124/1762] D loss: 1.3586\n",
      "[1204/1762] D loss: 1.3802\n",
      "[1284/1762] D loss: 1.3762\n",
      "[1364/1762] D loss: 1.3706\n",
      "[1444/1762] D loss: 1.3706\n",
      "[1524/1762] D loss: 1.3765\n",
      "[1604/1762] D loss: 1.3813\n",
      "[1684/1762] D loss: 1.3941\n",
      "[1762/1762] D loss: 1.3670\n",
      "train error: \n",
      " D loss: 1.373994, D accuracy: 57.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374043, D accuracy: 57.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3648\n",
      "[84/1762] D loss: 1.3890\n",
      "[164/1762] D loss: 1.4029\n",
      "[244/1762] D loss: 1.3638\n",
      "[324/1762] D loss: 1.3805\n",
      "[404/1762] D loss: 1.3539\n",
      "[484/1762] D loss: 1.3864\n",
      "[564/1762] D loss: 1.3853\n",
      "[644/1762] D loss: 1.3742\n",
      "[724/1762] D loss: 1.3673\n",
      "[804/1762] D loss: 1.3794\n",
      "[884/1762] D loss: 1.3620\n",
      "[964/1762] D loss: 1.3534\n",
      "[1044/1762] D loss: 1.3809\n",
      "[1124/1762] D loss: 1.3705\n",
      "[1204/1762] D loss: 1.3687\n",
      "[1284/1762] D loss: 1.3616\n",
      "[1364/1762] D loss: 1.3724\n",
      "[1444/1762] D loss: 1.3605\n",
      "[1524/1762] D loss: 1.3732\n",
      "[1604/1762] D loss: 1.3804\n",
      "[1684/1762] D loss: 1.3822\n",
      "[1762/1762] D loss: 1.3536\n",
      "train error: \n",
      " D loss: 1.373819, D accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374377, D accuracy: 56.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3410\n",
      "[84/1762] D loss: 1.3828\n",
      "[164/1762] D loss: 1.3667\n",
      "[244/1762] D loss: 1.3739\n",
      "[324/1762] D loss: 1.3718\n",
      "[404/1762] D loss: 1.3971\n",
      "[484/1762] D loss: 1.3763\n",
      "[564/1762] D loss: 1.3812\n",
      "[644/1762] D loss: 1.3679\n",
      "[724/1762] D loss: 1.3573\n",
      "[804/1762] D loss: 1.3724\n",
      "[884/1762] D loss: 1.3629\n",
      "[964/1762] D loss: 1.3892\n",
      "[1044/1762] D loss: 1.3578\n",
      "[1124/1762] D loss: 1.3746\n",
      "[1204/1762] D loss: 1.3671\n",
      "[1284/1762] D loss: 1.3664\n",
      "[1364/1762] D loss: 1.3738\n",
      "[1444/1762] D loss: 1.3925\n",
      "[1524/1762] D loss: 1.3767\n",
      "[1604/1762] D loss: 1.3555\n",
      "[1684/1762] D loss: 1.3628\n",
      "[1762/1762] D loss: 1.3776\n",
      "train error: \n",
      " D loss: 1.371887, D accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373491, D accuracy: 56.7% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3690\n",
      "[84/1762] D loss: 1.3884\n",
      "[164/1762] D loss: 1.3882\n",
      "[244/1762] D loss: 1.3829\n",
      "[324/1762] D loss: 1.3838\n",
      "[404/1762] D loss: 1.3774\n",
      "[484/1762] D loss: 1.3604\n",
      "[564/1762] D loss: 1.3731\n",
      "[644/1762] D loss: 1.3645\n",
      "[724/1762] D loss: 1.3781\n",
      "[804/1762] D loss: 1.3715\n",
      "[884/1762] D loss: 1.3753\n",
      "[964/1762] D loss: 1.3600\n",
      "[1044/1762] D loss: 1.3606\n",
      "[1124/1762] D loss: 1.3514\n",
      "[1204/1762] D loss: 1.3685\n",
      "[1284/1762] D loss: 1.3803\n",
      "[1364/1762] D loss: 1.3630\n",
      "[1444/1762] D loss: 1.3584\n",
      "[1524/1762] D loss: 1.3567\n",
      "[1604/1762] D loss: 1.3821\n",
      "[1684/1762] D loss: 1.3524\n",
      "[1762/1762] D loss: 1.3826\n",
      "train error: \n",
      " D loss: 1.370228, D accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370681, D accuracy: 57.4% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3618\n",
      "[84/1762] D loss: 1.3675\n",
      "[164/1762] D loss: 1.3859\n",
      "[244/1762] D loss: 1.3820\n",
      "[324/1762] D loss: 1.3696\n",
      "[404/1762] D loss: 1.3663\n",
      "[484/1762] D loss: 1.3753\n",
      "[564/1762] D loss: 1.3571\n",
      "[644/1762] D loss: 1.3808\n",
      "[724/1762] D loss: 1.4051\n",
      "[804/1762] D loss: 1.3729\n",
      "[884/1762] D loss: 1.3849\n",
      "[964/1762] D loss: 1.3628\n",
      "[1044/1762] D loss: 1.3632\n",
      "[1124/1762] D loss: 1.3705\n",
      "[1204/1762] D loss: 1.3685\n",
      "[1284/1762] D loss: 1.3824\n",
      "[1364/1762] D loss: 1.3739\n",
      "[1444/1762] D loss: 1.3635\n",
      "[1524/1762] D loss: 1.3908\n",
      "[1604/1762] D loss: 1.3434\n",
      "[1684/1762] D loss: 1.3701\n",
      "[1762/1762] D loss: 1.3710\n",
      "train error: \n",
      " D loss: 1.367163, D accuracy: 60.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369795, D accuracy: 57.7% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3659\n",
      "[84/1762] D loss: 1.3596\n",
      "[164/1762] D loss: 1.3712\n",
      "[244/1762] D loss: 1.3699\n",
      "[324/1762] D loss: 1.3940\n",
      "[404/1762] D loss: 1.3941\n",
      "[484/1762] D loss: 1.3587\n",
      "[564/1762] D loss: 1.3691\n",
      "[644/1762] D loss: 1.3655\n",
      "[724/1762] D loss: 1.3872\n",
      "[804/1762] D loss: 1.3652\n",
      "[884/1762] D loss: 1.3749\n",
      "[964/1762] D loss: 1.3745\n",
      "[1044/1762] D loss: 1.3534\n",
      "[1124/1762] D loss: 1.3595\n",
      "[1204/1762] D loss: 1.3737\n",
      "[1284/1762] D loss: 1.3812\n",
      "[1364/1762] D loss: 1.3733\n",
      "[1444/1762] D loss: 1.3577\n",
      "[1524/1762] D loss: 1.3752\n",
      "[1604/1762] D loss: 1.3520\n",
      "[1684/1762] D loss: 1.3730\n",
      "[1762/1762] D loss: 1.3701\n",
      "train error: \n",
      " D loss: 1.366117, D accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365058, D accuracy: 59.9% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3625\n",
      "[84/1762] D loss: 1.3660\n",
      "[164/1762] D loss: 1.3375\n",
      "[244/1762] D loss: 1.3796\n",
      "[324/1762] D loss: 1.3510\n",
      "[404/1762] D loss: 1.3632\n",
      "[484/1762] D loss: 1.3528\n",
      "[564/1762] D loss: 1.3744\n",
      "[644/1762] D loss: 1.3602\n",
      "[724/1762] D loss: 1.3844\n",
      "[804/1762] D loss: 1.3763\n",
      "[884/1762] D loss: 1.3628\n",
      "[964/1762] D loss: 1.3638\n",
      "[1044/1762] D loss: 1.3550\n",
      "[1124/1762] D loss: 1.3626\n",
      "[1204/1762] D loss: 1.3822\n",
      "[1284/1762] D loss: 1.3689\n",
      "[1364/1762] D loss: 1.3918\n",
      "[1444/1762] D loss: 1.3480\n",
      "[1524/1762] D loss: 1.3674\n",
      "[1604/1762] D loss: 1.3630\n",
      "[1684/1762] D loss: 1.3552\n",
      "[1762/1762] D loss: 1.3589\n",
      "train error: \n",
      " D loss: 1.364356, D accuracy: 60.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366221, D accuracy: 60.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3657\n",
      "[84/1762] D loss: 1.3256\n",
      "[164/1762] D loss: 1.3600\n",
      "[244/1762] D loss: 1.3666\n",
      "[324/1762] D loss: 1.3745\n",
      "[404/1762] D loss: 1.3443\n",
      "[484/1762] D loss: 1.3733\n",
      "[564/1762] D loss: 1.3629\n",
      "[644/1762] D loss: 1.3630\n",
      "[724/1762] D loss: 1.3739\n",
      "[804/1762] D loss: 1.3646\n",
      "[884/1762] D loss: 1.3707\n",
      "[964/1762] D loss: 1.3693\n",
      "[1044/1762] D loss: 1.3301\n",
      "[1124/1762] D loss: 1.3448\n",
      "[1204/1762] D loss: 1.3460\n",
      "[1284/1762] D loss: 1.3771\n",
      "[1364/1762] D loss: 1.3415\n",
      "[1444/1762] D loss: 1.3913\n",
      "[1524/1762] D loss: 1.3719\n",
      "[1604/1762] D loss: 1.3399\n",
      "[1684/1762] D loss: 1.3721\n",
      "[1762/1762] D loss: 1.3643\n",
      "train error: \n",
      " D loss: 1.361668, D accuracy: 62.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364930, D accuracy: 60.7% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3565\n",
      "[84/1762] D loss: 1.3702\n",
      "[164/1762] D loss: 1.3794\n",
      "[244/1762] D loss: 1.3614\n",
      "[324/1762] D loss: 1.3641\n",
      "[404/1762] D loss: 1.3688\n",
      "[484/1762] D loss: 1.3715\n",
      "[564/1762] D loss: 1.3532\n",
      "[644/1762] D loss: 1.3863\n",
      "[724/1762] D loss: 1.3526\n",
      "[804/1762] D loss: 1.3602\n",
      "[884/1762] D loss: 1.3820\n",
      "[964/1762] D loss: 1.3532\n",
      "[1044/1762] D loss: 1.3540\n",
      "[1124/1762] D loss: 1.3610\n",
      "[1204/1762] D loss: 1.3502\n",
      "[1284/1762] D loss: 1.3599\n",
      "[1364/1762] D loss: 1.3506\n",
      "[1444/1762] D loss: 1.3429\n",
      "[1524/1762] D loss: 1.3616\n",
      "[1604/1762] D loss: 1.3685\n",
      "[1684/1762] D loss: 1.3383\n",
      "[1762/1762] D loss: 1.3348\n",
      "train error: \n",
      " D loss: 1.358280, D accuracy: 63.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358587, D accuracy: 61.7% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4485\n",
      "[84/1762] D loss: 1.4604\n",
      "[164/1762] D loss: 1.4479\n",
      "[244/1762] D loss: 1.4419\n",
      "[324/1762] D loss: 1.4325\n",
      "[404/1762] D loss: 1.4656\n",
      "[484/1762] D loss: 1.4651\n",
      "[564/1762] D loss: 1.4499\n",
      "[644/1762] D loss: 1.4190\n",
      "[724/1762] D loss: 1.4233\n",
      "[804/1762] D loss: 1.4415\n",
      "[884/1762] D loss: 1.4150\n",
      "[964/1762] D loss: 1.4479\n",
      "[1044/1762] D loss: 1.4437\n",
      "[1124/1762] D loss: 1.4333\n",
      "[1204/1762] D loss: 1.4435\n",
      "[1284/1762] D loss: 1.4470\n",
      "[1364/1762] D loss: 1.4484\n",
      "[1444/1762] D loss: 1.4514\n",
      "[1524/1762] D loss: 1.4260\n",
      "[1604/1762] D loss: 1.4244\n",
      "[1684/1762] D loss: 1.4488\n",
      "[1762/1762] D loss: 1.4109\n",
      "train error: \n",
      " D loss: 1.435126, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.434111, D accuracy: 50.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4426\n",
      "[84/1762] D loss: 1.4481\n",
      "[164/1762] D loss: 1.4210\n",
      "[244/1762] D loss: 1.4287\n",
      "[324/1762] D loss: 1.4381\n",
      "[404/1762] D loss: 1.4323\n",
      "[484/1762] D loss: 1.4474\n",
      "[564/1762] D loss: 1.4203\n",
      "[644/1762] D loss: 1.4247\n",
      "[724/1762] D loss: 1.4175\n",
      "[804/1762] D loss: 1.4298\n",
      "[884/1762] D loss: 1.4290\n",
      "[964/1762] D loss: 1.3904\n",
      "[1044/1762] D loss: 1.4150\n",
      "[1124/1762] D loss: 1.4530\n",
      "[1204/1762] D loss: 1.4260\n",
      "[1284/1762] D loss: 1.4357\n",
      "[1364/1762] D loss: 1.4400\n",
      "[1444/1762] D loss: 1.4275\n",
      "[1524/1762] D loss: 1.4188\n",
      "[1604/1762] D loss: 1.4484\n",
      "[1684/1762] D loss: 1.4454\n",
      "[1762/1762] D loss: 1.4245\n",
      "train error: \n",
      " D loss: 1.433194, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.432023, D accuracy: 50.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4278\n",
      "[84/1762] D loss: 1.4122\n",
      "[164/1762] D loss: 1.4242\n",
      "[244/1762] D loss: 1.4266\n",
      "[324/1762] D loss: 1.4182\n",
      "[404/1762] D loss: 1.4324\n",
      "[484/1762] D loss: 1.4385\n",
      "[564/1762] D loss: 1.4131\n",
      "[644/1762] D loss: 1.4152\n",
      "[724/1762] D loss: 1.4377\n",
      "[804/1762] D loss: 1.4258\n",
      "[884/1762] D loss: 1.4407\n",
      "[964/1762] D loss: 1.4102\n",
      "[1044/1762] D loss: 1.4182\n",
      "[1124/1762] D loss: 1.4011\n",
      "[1204/1762] D loss: 1.4186\n",
      "[1284/1762] D loss: 1.4208\n",
      "[1364/1762] D loss: 1.4172\n",
      "[1444/1762] D loss: 1.4335\n",
      "[1524/1762] D loss: 1.4169\n",
      "[1604/1762] D loss: 1.4370\n",
      "[1684/1762] D loss: 1.4305\n",
      "[1762/1762] D loss: 1.4265\n",
      "train error: \n",
      " D loss: 1.423646, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.421390, D accuracy: 50.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4131\n",
      "[84/1762] D loss: 1.4126\n",
      "[164/1762] D loss: 1.4487\n",
      "[244/1762] D loss: 1.4080\n",
      "[324/1762] D loss: 1.4529\n",
      "[404/1762] D loss: 1.4135\n",
      "[484/1762] D loss: 1.4294\n",
      "[564/1762] D loss: 1.4214\n",
      "[644/1762] D loss: 1.4173\n",
      "[724/1762] D loss: 1.4196\n",
      "[804/1762] D loss: 1.4357\n",
      "[884/1762] D loss: 1.4106\n",
      "[964/1762] D loss: 1.4461\n",
      "[1044/1762] D loss: 1.4188\n",
      "[1124/1762] D loss: 1.3977\n",
      "[1204/1762] D loss: 1.4129\n",
      "[1284/1762] D loss: 1.3884\n",
      "[1364/1762] D loss: 1.4352\n",
      "[1444/1762] D loss: 1.4057\n",
      "[1524/1762] D loss: 1.4114\n",
      "[1604/1762] D loss: 1.4114\n",
      "[1684/1762] D loss: 1.4053\n",
      "[1762/1762] D loss: 1.4235\n",
      "train error: \n",
      " D loss: 1.418624, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416786, D accuracy: 50.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4182\n",
      "[84/1762] D loss: 1.4338\n",
      "[164/1762] D loss: 1.4166\n",
      "[244/1762] D loss: 1.4277\n",
      "[324/1762] D loss: 1.4095\n",
      "[404/1762] D loss: 1.4146\n",
      "[484/1762] D loss: 1.3941\n",
      "[564/1762] D loss: 1.4089\n",
      "[644/1762] D loss: 1.4087\n",
      "[724/1762] D loss: 1.4342\n",
      "[804/1762] D loss: 1.4180\n",
      "[884/1762] D loss: 1.4196\n",
      "[964/1762] D loss: 1.3974\n",
      "[1044/1762] D loss: 1.4044\n",
      "[1124/1762] D loss: 1.4187\n",
      "[1204/1762] D loss: 1.4109\n",
      "[1284/1762] D loss: 1.4224\n",
      "[1364/1762] D loss: 1.3894\n",
      "[1444/1762] D loss: 1.4064\n",
      "[1524/1762] D loss: 1.4088\n",
      "[1604/1762] D loss: 1.3974\n",
      "[1684/1762] D loss: 1.4118\n",
      "[1762/1762] D loss: 1.4185\n",
      "train error: \n",
      " D loss: 1.413914, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.415138, D accuracy: 50.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4062\n",
      "[84/1762] D loss: 1.4218\n",
      "[164/1762] D loss: 1.4012\n",
      "[244/1762] D loss: 1.4109\n",
      "[324/1762] D loss: 1.3849\n",
      "[404/1762] D loss: 1.4125\n",
      "[484/1762] D loss: 1.4322\n",
      "[564/1762] D loss: 1.4062\n",
      "[644/1762] D loss: 1.4344\n",
      "[724/1762] D loss: 1.4252\n",
      "[804/1762] D loss: 1.4047\n",
      "[884/1762] D loss: 1.4084\n",
      "[964/1762] D loss: 1.4142\n",
      "[1044/1762] D loss: 1.4079\n",
      "[1124/1762] D loss: 1.4180\n",
      "[1204/1762] D loss: 1.4096\n",
      "[1284/1762] D loss: 1.4243\n",
      "[1364/1762] D loss: 1.4130\n",
      "[1444/1762] D loss: 1.4243\n",
      "[1524/1762] D loss: 1.3974\n",
      "[1604/1762] D loss: 1.4303\n",
      "[1684/1762] D loss: 1.4366\n",
      "[1762/1762] D loss: 1.4176\n",
      "train error: \n",
      " D loss: 1.408752, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408612, D accuracy: 50.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933\n",
      "[84/1762] D loss: 1.4184\n",
      "[164/1762] D loss: 1.3865\n",
      "[244/1762] D loss: 1.3896\n",
      "[324/1762] D loss: 1.4188\n",
      "[404/1762] D loss: 1.4010\n",
      "[484/1762] D loss: 1.4257\n",
      "[564/1762] D loss: 1.4105\n",
      "[644/1762] D loss: 1.4064\n",
      "[724/1762] D loss: 1.3995\n",
      "[804/1762] D loss: 1.3928\n",
      "[884/1762] D loss: 1.4104\n",
      "[964/1762] D loss: 1.4194\n",
      "[1044/1762] D loss: 1.4186\n",
      "[1124/1762] D loss: 1.4062\n",
      "[1204/1762] D loss: 1.4108\n",
      "[1284/1762] D loss: 1.4034\n",
      "[1364/1762] D loss: 1.3912\n",
      "[1444/1762] D loss: 1.3879\n",
      "[1524/1762] D loss: 1.4367\n",
      "[1604/1762] D loss: 1.4055\n",
      "[1684/1762] D loss: 1.4117\n",
      "[1762/1762] D loss: 1.3974\n",
      "train error: \n",
      " D loss: 1.404675, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404540, D accuracy: 50.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917\n",
      "[84/1762] D loss: 1.3979\n",
      "[164/1762] D loss: 1.4030\n",
      "[244/1762] D loss: 1.4135\n",
      "[324/1762] D loss: 1.4066\n",
      "[404/1762] D loss: 1.4057\n",
      "[484/1762] D loss: 1.4309\n",
      "[564/1762] D loss: 1.4059\n",
      "[644/1762] D loss: 1.3841\n",
      "[724/1762] D loss: 1.4165\n",
      "[804/1762] D loss: 1.4000\n",
      "[884/1762] D loss: 1.4030\n",
      "[964/1762] D loss: 1.4075\n",
      "[1044/1762] D loss: 1.4259\n",
      "[1124/1762] D loss: 1.4153\n",
      "[1204/1762] D loss: 1.3802\n",
      "[1284/1762] D loss: 1.3899\n",
      "[1364/1762] D loss: 1.3840\n",
      "[1444/1762] D loss: 1.3845\n",
      "[1524/1762] D loss: 1.3867\n",
      "[1604/1762] D loss: 1.4084\n",
      "[1684/1762] D loss: 1.4169\n",
      "[1762/1762] D loss: 1.3915\n",
      "train error: \n",
      " D loss: 1.401022, D accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399652, D accuracy: 49.9% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4098\n",
      "[84/1762] D loss: 1.4089\n",
      "[164/1762] D loss: 1.4268\n",
      "[244/1762] D loss: 1.4039\n",
      "[324/1762] D loss: 1.4120\n",
      "[404/1762] D loss: 1.4240\n",
      "[484/1762] D loss: 1.3986\n",
      "[564/1762] D loss: 1.4088\n",
      "[644/1762] D loss: 1.3890\n",
      "[724/1762] D loss: 1.3932\n",
      "[804/1762] D loss: 1.3892\n",
      "[884/1762] D loss: 1.4058\n",
      "[964/1762] D loss: 1.3963\n",
      "[1044/1762] D loss: 1.4192\n",
      "[1124/1762] D loss: 1.4007\n",
      "[1204/1762] D loss: 1.3803\n",
      "[1284/1762] D loss: 1.4173\n",
      "[1364/1762] D loss: 1.4084\n",
      "[1444/1762] D loss: 1.3956\n",
      "[1524/1762] D loss: 1.4106\n",
      "[1604/1762] D loss: 1.4166\n",
      "[1684/1762] D loss: 1.3890\n",
      "[1762/1762] D loss: 1.4019\n",
      "train error: \n",
      " D loss: 1.399214, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397533, D accuracy: 50.1% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3993\n",
      "[84/1762] D loss: 1.4178\n",
      "[164/1762] D loss: 1.3946\n",
      "[244/1762] D loss: 1.3917\n",
      "[324/1762] D loss: 1.4023\n",
      "[404/1762] D loss: 1.4153\n",
      "[484/1762] D loss: 1.4007\n",
      "[564/1762] D loss: 1.4058\n",
      "[644/1762] D loss: 1.3830\n",
      "[724/1762] D loss: 1.3861\n",
      "[804/1762] D loss: 1.3817\n",
      "[884/1762] D loss: 1.4027\n",
      "[964/1762] D loss: 1.3907\n",
      "[1044/1762] D loss: 1.3752\n",
      "[1124/1762] D loss: 1.3948\n",
      "[1204/1762] D loss: 1.3863\n",
      "[1284/1762] D loss: 1.3983\n",
      "[1364/1762] D loss: 1.4051\n",
      "[1444/1762] D loss: 1.3885\n",
      "[1524/1762] D loss: 1.4076\n",
      "[1604/1762] D loss: 1.4061\n",
      "[1684/1762] D loss: 1.4019\n",
      "[1762/1762] D loss: 1.3948\n",
      "train error: \n",
      " D loss: 1.396199, D accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396964, D accuracy: 49.9% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4023\n",
      "[84/1762] D loss: 1.3980\n",
      "[164/1762] D loss: 1.3942\n",
      "[244/1762] D loss: 1.4031\n",
      "[324/1762] D loss: 1.3636\n",
      "[404/1762] D loss: 1.4189\n",
      "[484/1762] D loss: 1.3893\n",
      "[564/1762] D loss: 1.3982\n",
      "[644/1762] D loss: 1.4007\n",
      "[724/1762] D loss: 1.3961\n",
      "[804/1762] D loss: 1.4021\n",
      "[884/1762] D loss: 1.3849\n",
      "[964/1762] D loss: 1.4138\n",
      "[1044/1762] D loss: 1.4216\n",
      "[1124/1762] D loss: 1.3944\n",
      "[1204/1762] D loss: 1.4096\n",
      "[1284/1762] D loss: 1.4155\n",
      "[1364/1762] D loss: 1.4041\n",
      "[1444/1762] D loss: 1.4041\n",
      "[1524/1762] D loss: 1.3990\n",
      "[1604/1762] D loss: 1.3907\n",
      "[1684/1762] D loss: 1.4029\n",
      "[1762/1762] D loss: 1.3985\n",
      "train error: \n",
      " D loss: 1.394389, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394737, D accuracy: 50.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889\n",
      "[84/1762] D loss: 1.3849\n",
      "[164/1762] D loss: 1.3982\n",
      "[244/1762] D loss: 1.3967\n",
      "[324/1762] D loss: 1.4038\n",
      "[404/1762] D loss: 1.3789\n",
      "[484/1762] D loss: 1.4122\n",
      "[564/1762] D loss: 1.4051\n",
      "[644/1762] D loss: 1.4007\n",
      "[724/1762] D loss: 1.4006\n",
      "[804/1762] D loss: 1.4129\n",
      "[884/1762] D loss: 1.3792\n",
      "[964/1762] D loss: 1.3898\n",
      "[1044/1762] D loss: 1.3960\n",
      "[1124/1762] D loss: 1.3835\n",
      "[1204/1762] D loss: 1.3833\n",
      "[1284/1762] D loss: 1.4112\n",
      "[1364/1762] D loss: 1.3890\n",
      "[1444/1762] D loss: 1.3879\n",
      "[1524/1762] D loss: 1.3837\n",
      "[1604/1762] D loss: 1.3835\n",
      "[1684/1762] D loss: 1.3846\n",
      "[1762/1762] D loss: 1.3832\n",
      "train error: \n",
      " D loss: 1.393371, D accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392474, D accuracy: 50.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873\n",
      "[84/1762] D loss: 1.3963\n",
      "[164/1762] D loss: 1.4014\n",
      "[244/1762] D loss: 1.4105\n",
      "[324/1762] D loss: 1.3976\n",
      "[404/1762] D loss: 1.4162\n",
      "[484/1762] D loss: 1.3952\n",
      "[564/1762] D loss: 1.4009\n",
      "[644/1762] D loss: 1.3980\n",
      "[724/1762] D loss: 1.4001\n",
      "[804/1762] D loss: 1.3990\n",
      "[884/1762] D loss: 1.3952\n",
      "[964/1762] D loss: 1.3962\n",
      "[1044/1762] D loss: 1.3927\n",
      "[1124/1762] D loss: 1.3842\n",
      "[1204/1762] D loss: 1.3896\n",
      "[1284/1762] D loss: 1.4097\n",
      "[1364/1762] D loss: 1.3803\n",
      "[1444/1762] D loss: 1.3921\n",
      "[1524/1762] D loss: 1.4022\n",
      "[1604/1762] D loss: 1.4108\n",
      "[1684/1762] D loss: 1.3885\n",
      "[1762/1762] D loss: 1.3746\n",
      "train error: \n",
      " D loss: 1.391527, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391210, D accuracy: 50.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4011\n",
      "[84/1762] D loss: 1.3961\n",
      "[164/1762] D loss: 1.4066\n",
      "[244/1762] D loss: 1.3877\n",
      "[324/1762] D loss: 1.4055\n",
      "[404/1762] D loss: 1.4243\n",
      "[484/1762] D loss: 1.3762\n",
      "[564/1762] D loss: 1.3853\n",
      "[644/1762] D loss: 1.4010\n",
      "[724/1762] D loss: 1.4040\n",
      "[804/1762] D loss: 1.3875\n",
      "[884/1762] D loss: 1.4036\n",
      "[964/1762] D loss: 1.3906\n",
      "[1044/1762] D loss: 1.3945\n",
      "[1124/1762] D loss: 1.3987\n",
      "[1204/1762] D loss: 1.4040\n",
      "[1284/1762] D loss: 1.3947\n",
      "[1364/1762] D loss: 1.3978\n",
      "[1444/1762] D loss: 1.3992\n",
      "[1524/1762] D loss: 1.3872\n",
      "[1604/1762] D loss: 1.3870\n",
      "[1684/1762] D loss: 1.3940\n",
      "[1762/1762] D loss: 1.3756\n",
      "train error: \n",
      " D loss: 1.390915, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387231, D accuracy: 49.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3912\n",
      "[84/1762] D loss: 1.3982\n",
      "[164/1762] D loss: 1.4003\n",
      "[244/1762] D loss: 1.3883\n",
      "[324/1762] D loss: 1.3824\n",
      "[404/1762] D loss: 1.3985\n",
      "[484/1762] D loss: 1.3888\n",
      "[564/1762] D loss: 1.3840\n",
      "[644/1762] D loss: 1.3815\n",
      "[724/1762] D loss: 1.3877\n",
      "[804/1762] D loss: 1.3833\n",
      "[884/1762] D loss: 1.4128\n",
      "[964/1762] D loss: 1.3732\n",
      "[1044/1762] D loss: 1.3805\n",
      "[1124/1762] D loss: 1.3881\n",
      "[1204/1762] D loss: 1.3899\n",
      "[1284/1762] D loss: 1.3351\n",
      "[1364/1762] D loss: 1.3837\n",
      "[1444/1762] D loss: 1.3938\n",
      "[1524/1762] D loss: 1.4124\n",
      "[1604/1762] D loss: 1.3879\n",
      "[1684/1762] D loss: 1.3781\n",
      "[1762/1762] D loss: 1.4094\n",
      "train error: \n",
      " D loss: 1.389149, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386805, D accuracy: 50.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3956\n",
      "[84/1762] D loss: 1.3724\n",
      "[164/1762] D loss: 1.3697\n",
      "[244/1762] D loss: 1.4035\n",
      "[324/1762] D loss: 1.3880\n",
      "[404/1762] D loss: 1.3790\n",
      "[484/1762] D loss: 1.4043\n",
      "[564/1762] D loss: 1.3813\n",
      "[644/1762] D loss: 1.4076\n",
      "[724/1762] D loss: 1.3945\n",
      "[804/1762] D loss: 1.3930\n",
      "[884/1762] D loss: 1.3837\n",
      "[964/1762] D loss: 1.3710\n",
      "[1044/1762] D loss: 1.3881\n",
      "[1124/1762] D loss: 1.3872\n",
      "[1204/1762] D loss: 1.4022\n",
      "[1284/1762] D loss: 1.4097\n",
      "[1364/1762] D loss: 1.4067\n",
      "[1444/1762] D loss: 1.3980\n",
      "[1524/1762] D loss: 1.4051\n",
      "[1604/1762] D loss: 1.3887\n",
      "[1684/1762] D loss: 1.3852\n",
      "[1762/1762] D loss: 1.3891\n",
      "train error: \n",
      " D loss: 1.387016, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386441, D accuracy: 50.6% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3828\n",
      "[84/1762] D loss: 1.3803\n",
      "[164/1762] D loss: 1.3971\n",
      "[244/1762] D loss: 1.3891\n",
      "[324/1762] D loss: 1.3800\n",
      "[404/1762] D loss: 1.3884\n",
      "[484/1762] D loss: 1.3860\n",
      "[564/1762] D loss: 1.3964\n",
      "[644/1762] D loss: 1.3888\n",
      "[724/1762] D loss: 1.3831\n",
      "[804/1762] D loss: 1.3686\n",
      "[884/1762] D loss: 1.3836\n",
      "[964/1762] D loss: 1.3735\n",
      "[1044/1762] D loss: 1.3889\n",
      "[1124/1762] D loss: 1.3876\n",
      "[1204/1762] D loss: 1.3999\n",
      "[1284/1762] D loss: 1.3917\n",
      "[1364/1762] D loss: 1.3967\n",
      "[1444/1762] D loss: 1.3870\n",
      "[1524/1762] D loss: 1.3750\n",
      "[1604/1762] D loss: 1.3508\n",
      "[1684/1762] D loss: 1.3805\n",
      "[1762/1762] D loss: 1.3773\n",
      "train error: \n",
      " D loss: 1.387313, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387038, D accuracy: 49.7% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951\n",
      "[84/1762] D loss: 1.3702\n",
      "[164/1762] D loss: 1.3793\n",
      "[244/1762] D loss: 1.3999\n",
      "[324/1762] D loss: 1.3724\n",
      "[404/1762] D loss: 1.3842\n",
      "[484/1762] D loss: 1.3711\n",
      "[564/1762] D loss: 1.3916\n",
      "[644/1762] D loss: 1.3954\n",
      "[724/1762] D loss: 1.3806\n",
      "[804/1762] D loss: 1.3626\n",
      "[884/1762] D loss: 1.3822\n",
      "[964/1762] D loss: 1.3840\n",
      "[1044/1762] D loss: 1.3934\n",
      "[1124/1762] D loss: 1.3905\n",
      "[1204/1762] D loss: 1.3829\n",
      "[1284/1762] D loss: 1.3753\n",
      "[1364/1762] D loss: 1.3781\n",
      "[1444/1762] D loss: 1.3923\n",
      "[1524/1762] D loss: 1.4011\n",
      "[1604/1762] D loss: 1.3961\n",
      "[1684/1762] D loss: 1.4007\n",
      "[1762/1762] D loss: 1.3803\n",
      "train error: \n",
      " D loss: 1.386863, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386524, D accuracy: 50.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3832\n",
      "[84/1762] D loss: 1.3845\n",
      "[164/1762] D loss: 1.3784\n",
      "[244/1762] D loss: 1.4103\n",
      "[324/1762] D loss: 1.3827\n",
      "[404/1762] D loss: 1.3675\n",
      "[484/1762] D loss: 1.3715\n",
      "[564/1762] D loss: 1.3882\n",
      "[644/1762] D loss: 1.3939\n",
      "[724/1762] D loss: 1.4040\n",
      "[804/1762] D loss: 1.3863\n",
      "[884/1762] D loss: 1.3809\n",
      "[964/1762] D loss: 1.3721\n",
      "[1044/1762] D loss: 1.3612\n",
      "[1124/1762] D loss: 1.3856\n",
      "[1204/1762] D loss: 1.4086\n",
      "[1284/1762] D loss: 1.3906\n",
      "[1364/1762] D loss: 1.3982\n",
      "[1444/1762] D loss: 1.3922\n",
      "[1524/1762] D loss: 1.3727\n",
      "[1604/1762] D loss: 1.3816\n",
      "[1684/1762] D loss: 1.3693\n",
      "[1762/1762] D loss: 1.3814\n",
      "train error: \n",
      " D loss: 1.385487, D accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387413, D accuracy: 49.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3694\n",
      "[84/1762] D loss: 1.3779\n",
      "[164/1762] D loss: 1.3801\n",
      "[244/1762] D loss: 1.3776\n",
      "[324/1762] D loss: 1.3800\n",
      "[404/1762] D loss: 1.3821\n",
      "[484/1762] D loss: 1.3794\n",
      "[564/1762] D loss: 1.3845\n",
      "[644/1762] D loss: 1.3717\n",
      "[724/1762] D loss: 1.3845\n",
      "[804/1762] D loss: 1.3797\n",
      "[884/1762] D loss: 1.3728\n",
      "[964/1762] D loss: 1.3683\n",
      "[1044/1762] D loss: 1.3924\n",
      "[1124/1762] D loss: 1.3888\n",
      "[1204/1762] D loss: 1.3779\n",
      "[1284/1762] D loss: 1.3736\n",
      "[1364/1762] D loss: 1.4040\n",
      "[1444/1762] D loss: 1.4030\n",
      "[1524/1762] D loss: 1.3791\n",
      "[1604/1762] D loss: 1.3886\n",
      "[1684/1762] D loss: 1.3853\n",
      "[1762/1762] D loss: 1.4120\n",
      "train error: \n",
      " D loss: 1.385316, D accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384104, D accuracy: 50.6% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3830\n",
      "[84/1762] D loss: 1.4039\n",
      "[164/1762] D loss: 1.4233\n",
      "[244/1762] D loss: 1.4218\n",
      "[324/1762] D loss: 1.4251\n",
      "[404/1762] D loss: 1.4132\n",
      "[484/1762] D loss: 1.4202\n",
      "[564/1762] D loss: 1.3987\n",
      "[644/1762] D loss: 1.4268\n",
      "[724/1762] D loss: 1.4094\n",
      "[804/1762] D loss: 1.4418\n",
      "[884/1762] D loss: 1.4227\n",
      "[964/1762] D loss: 1.4101\n",
      "[1044/1762] D loss: 1.4005\n",
      "[1124/1762] D loss: 1.3938\n",
      "[1204/1762] D loss: 1.4511\n",
      "[1284/1762] D loss: 1.4267\n",
      "[1364/1762] D loss: 1.3704\n",
      "[1444/1762] D loss: 1.4068\n",
      "[1524/1762] D loss: 1.3763\n",
      "[1604/1762] D loss: 1.4436\n",
      "[1684/1762] D loss: 1.4203\n",
      "[1762/1762] D loss: 1.4177\n",
      "train error: \n",
      " D loss: 1.418452, D accuracy: 48.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417424, D accuracy: 48.2% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4304\n",
      "[84/1762] D loss: 1.3712\n",
      "[164/1762] D loss: 1.3987\n",
      "[244/1762] D loss: 1.4457\n",
      "[324/1762] D loss: 1.4200\n",
      "[404/1762] D loss: 1.4154\n",
      "[484/1762] D loss: 1.3903\n",
      "[564/1762] D loss: 1.3884\n",
      "[644/1762] D loss: 1.4025\n",
      "[724/1762] D loss: 1.4083\n",
      "[804/1762] D loss: 1.4591\n",
      "[884/1762] D loss: 1.4040\n",
      "[964/1762] D loss: 1.4388\n",
      "[1044/1762] D loss: 1.4303\n",
      "[1124/1762] D loss: 1.4231\n",
      "[1204/1762] D loss: 1.4006\n",
      "[1284/1762] D loss: 1.4097\n",
      "[1364/1762] D loss: 1.4262\n",
      "[1444/1762] D loss: 1.4425\n",
      "[1524/1762] D loss: 1.3991\n",
      "[1604/1762] D loss: 1.4148\n",
      "[1684/1762] D loss: 1.3909\n",
      "[1762/1762] D loss: 1.4041\n",
      "train error: \n",
      " D loss: 1.418132, D accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417364, D accuracy: 48.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4254\n",
      "[84/1762] D loss: 1.4034\n",
      "[164/1762] D loss: 1.4637\n",
      "[244/1762] D loss: 1.4290\n",
      "[324/1762] D loss: 1.4440\n",
      "[404/1762] D loss: 1.4335\n",
      "[484/1762] D loss: 1.4020\n",
      "[564/1762] D loss: 1.4036\n",
      "[644/1762] D loss: 1.4067\n",
      "[724/1762] D loss: 1.4240\n",
      "[804/1762] D loss: 1.4293\n",
      "[884/1762] D loss: 1.4019\n",
      "[964/1762] D loss: 1.4044\n",
      "[1044/1762] D loss: 1.3755\n",
      "[1124/1762] D loss: 1.4126\n",
      "[1204/1762] D loss: 1.4125\n",
      "[1284/1762] D loss: 1.3896\n",
      "[1364/1762] D loss: 1.4364\n",
      "[1444/1762] D loss: 1.4006\n",
      "[1524/1762] D loss: 1.4025\n",
      "[1604/1762] D loss: 1.4087\n",
      "[1684/1762] D loss: 1.3755\n",
      "[1762/1762] D loss: 1.4016\n",
      "train error: \n",
      " D loss: 1.415881, D accuracy: 49.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.415621, D accuracy: 48.2% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4067\n",
      "[84/1762] D loss: 1.3774\n",
      "[164/1762] D loss: 1.4084\n",
      "[244/1762] D loss: 1.4070\n",
      "[324/1762] D loss: 1.3786\n",
      "[404/1762] D loss: 1.4533\n",
      "[484/1762] D loss: 1.3940\n",
      "[564/1762] D loss: 1.4480\n",
      "[644/1762] D loss: 1.4342\n",
      "[724/1762] D loss: 1.4520\n",
      "[804/1762] D loss: 1.4260\n",
      "[884/1762] D loss: 1.4001\n",
      "[964/1762] D loss: 1.4094\n",
      "[1044/1762] D loss: 1.4596\n",
      "[1124/1762] D loss: 1.4361\n",
      "[1204/1762] D loss: 1.3874\n",
      "[1284/1762] D loss: 1.3928\n",
      "[1364/1762] D loss: 1.3770\n",
      "[1444/1762] D loss: 1.4287\n",
      "[1524/1762] D loss: 1.4247\n",
      "[1604/1762] D loss: 1.4314\n",
      "[1684/1762] D loss: 1.4151\n",
      "[1762/1762] D loss: 1.3985\n",
      "train error: \n",
      " D loss: 1.416626, D accuracy: 48.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417748, D accuracy: 48.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4106\n",
      "[84/1762] D loss: 1.4041\n",
      "[164/1762] D loss: 1.4124\n",
      "[244/1762] D loss: 1.4107\n",
      "[324/1762] D loss: 1.3949\n",
      "[404/1762] D loss: 1.3879\n",
      "[484/1762] D loss: 1.4232\n",
      "[564/1762] D loss: 1.4210\n",
      "[644/1762] D loss: 1.4547\n",
      "[724/1762] D loss: 1.4420\n",
      "[804/1762] D loss: 1.3962\n",
      "[884/1762] D loss: 1.4034\n",
      "[964/1762] D loss: 1.4096\n",
      "[1044/1762] D loss: 1.4308\n",
      "[1124/1762] D loss: 1.4236\n",
      "[1204/1762] D loss: 1.4007\n",
      "[1284/1762] D loss: 1.4213\n",
      "[1364/1762] D loss: 1.3943\n",
      "[1444/1762] D loss: 1.4167\n",
      "[1524/1762] D loss: 1.4175\n",
      "[1604/1762] D loss: 1.4474\n",
      "[1684/1762] D loss: 1.3939\n",
      "[1762/1762] D loss: 1.4076\n",
      "train error: \n",
      " D loss: 1.414343, D accuracy: 49.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.414058, D accuracy: 48.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4109\n",
      "[84/1762] D loss: 1.4289\n",
      "[164/1762] D loss: 1.3957\n",
      "[244/1762] D loss: 1.3986\n",
      "[324/1762] D loss: 1.4481\n",
      "[404/1762] D loss: 1.3892\n",
      "[484/1762] D loss: 1.4154\n",
      "[564/1762] D loss: 1.4288\n",
      "[644/1762] D loss: 1.4117\n",
      "[724/1762] D loss: 1.4145\n",
      "[804/1762] D loss: 1.3877\n",
      "[884/1762] D loss: 1.4044\n",
      "[964/1762] D loss: 1.3912\n",
      "[1044/1762] D loss: 1.4329\n",
      "[1124/1762] D loss: 1.4041\n",
      "[1204/1762] D loss: 1.4180\n",
      "[1284/1762] D loss: 1.4022\n",
      "[1364/1762] D loss: 1.3972\n",
      "[1444/1762] D loss: 1.3979\n",
      "[1524/1762] D loss: 1.4029\n",
      "[1604/1762] D loss: 1.4039\n",
      "[1684/1762] D loss: 1.4534\n",
      "[1762/1762] D loss: 1.4504\n",
      "train error: \n",
      " D loss: 1.419475, D accuracy: 48.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416607, D accuracy: 48.9% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4101\n",
      "[84/1762] D loss: 1.4367\n",
      "[164/1762] D loss: 1.4172\n",
      "[244/1762] D loss: 1.3954\n",
      "[324/1762] D loss: 1.3943\n",
      "[404/1762] D loss: 1.3788\n",
      "[484/1762] D loss: 1.4013\n",
      "[564/1762] D loss: 1.4192\n",
      "[644/1762] D loss: 1.3891\n",
      "[724/1762] D loss: 1.4227\n",
      "[804/1762] D loss: 1.3821\n",
      "[884/1762] D loss: 1.4050\n",
      "[964/1762] D loss: 1.4100\n",
      "[1044/1762] D loss: 1.4265\n",
      "[1124/1762] D loss: 1.4101\n",
      "[1204/1762] D loss: 1.4173\n",
      "[1284/1762] D loss: 1.3706\n",
      "[1364/1762] D loss: 1.3838\n",
      "[1444/1762] D loss: 1.4263\n",
      "[1524/1762] D loss: 1.4323\n",
      "[1604/1762] D loss: 1.4134\n",
      "[1684/1762] D loss: 1.3799\n",
      "[1762/1762] D loss: 1.4485\n",
      "train error: \n",
      " D loss: 1.413176, D accuracy: 48.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412545, D accuracy: 47.6% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4239\n",
      "[84/1762] D loss: 1.3820\n",
      "[164/1762] D loss: 1.3901\n",
      "[244/1762] D loss: 1.4143\n",
      "[324/1762] D loss: 1.4171\n",
      "[404/1762] D loss: 1.4144\n",
      "[484/1762] D loss: 1.3934\n",
      "[564/1762] D loss: 1.4319\n",
      "[644/1762] D loss: 1.3736\n",
      "[724/1762] D loss: 1.4110\n",
      "[804/1762] D loss: 1.4228\n",
      "[884/1762] D loss: 1.3727\n",
      "[964/1762] D loss: 1.3878\n",
      "[1044/1762] D loss: 1.4282\n",
      "[1124/1762] D loss: 1.4124\n",
      "[1204/1762] D loss: 1.4002\n",
      "[1284/1762] D loss: 1.3961\n",
      "[1364/1762] D loss: 1.3936\n",
      "[1444/1762] D loss: 1.3938\n",
      "[1524/1762] D loss: 1.3829\n",
      "[1604/1762] D loss: 1.4084\n",
      "[1684/1762] D loss: 1.4234\n",
      "[1762/1762] D loss: 1.4020\n",
      "train error: \n",
      " D loss: 1.417336, D accuracy: 48.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.415952, D accuracy: 48.8% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4300\n",
      "[84/1762] D loss: 1.4176\n",
      "[164/1762] D loss: 1.4263\n",
      "[244/1762] D loss: 1.4106\n",
      "[324/1762] D loss: 1.4387\n",
      "[404/1762] D loss: 1.4054\n",
      "[484/1762] D loss: 1.4189\n",
      "[564/1762] D loss: 1.4145\n",
      "[644/1762] D loss: 1.4021\n",
      "[724/1762] D loss: 1.3791\n",
      "[804/1762] D loss: 1.3952\n",
      "[884/1762] D loss: 1.3720\n",
      "[964/1762] D loss: 1.4256\n",
      "[1044/1762] D loss: 1.4087\n",
      "[1124/1762] D loss: 1.4226\n",
      "[1204/1762] D loss: 1.3872\n",
      "[1284/1762] D loss: 1.4118\n",
      "[1364/1762] D loss: 1.4142\n",
      "[1444/1762] D loss: 1.3896\n",
      "[1524/1762] D loss: 1.4070\n",
      "[1604/1762] D loss: 1.4036\n",
      "[1684/1762] D loss: 1.4265\n",
      "[1762/1762] D loss: 1.4249\n",
      "train error: \n",
      " D loss: 1.416350, D accuracy: 48.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.415417, D accuracy: 48.3% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4032\n",
      "[84/1762] D loss: 1.3885\n",
      "[164/1762] D loss: 1.4048\n",
      "[244/1762] D loss: 1.3971\n",
      "[324/1762] D loss: 1.3888\n",
      "[404/1762] D loss: 1.4293\n",
      "[484/1762] D loss: 1.4192\n",
      "[564/1762] D loss: 1.4063\n",
      "[644/1762] D loss: 1.3774\n",
      "[724/1762] D loss: 1.4000\n",
      "[804/1762] D loss: 1.4073\n",
      "[884/1762] D loss: 1.3812\n",
      "[964/1762] D loss: 1.3954\n",
      "[1044/1762] D loss: 1.4127\n",
      "[1124/1762] D loss: 1.4106\n",
      "[1204/1762] D loss: 1.4114\n",
      "[1284/1762] D loss: 1.3917\n",
      "[1364/1762] D loss: 1.4237\n",
      "[1444/1762] D loss: 1.3995\n",
      "[1524/1762] D loss: 1.4439\n",
      "[1604/1762] D loss: 1.4191\n",
      "[1684/1762] D loss: 1.4178\n",
      "[1762/1762] D loss: 1.4567\n",
      "train error: \n",
      " D loss: 1.414662, D accuracy: 48.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410124, D accuracy: 48.8% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4340\n",
      "[84/1762] D loss: 1.4177\n",
      "[164/1762] D loss: 1.4200\n",
      "[244/1762] D loss: 1.4024\n",
      "[324/1762] D loss: 1.4355\n",
      "[404/1762] D loss: 1.4261\n",
      "[484/1762] D loss: 1.3844\n",
      "[564/1762] D loss: 1.3961\n",
      "[644/1762] D loss: 1.4249\n",
      "[724/1762] D loss: 1.3925\n",
      "[804/1762] D loss: 1.4211\n",
      "[884/1762] D loss: 1.4078\n",
      "[964/1762] D loss: 1.4153\n",
      "[1044/1762] D loss: 1.4060\n",
      "[1124/1762] D loss: 1.4049\n",
      "[1204/1762] D loss: 1.4184\n",
      "[1284/1762] D loss: 1.4060\n",
      "[1364/1762] D loss: 1.4279\n",
      "[1444/1762] D loss: 1.3983\n",
      "[1524/1762] D loss: 1.4187\n",
      "[1604/1762] D loss: 1.3963\n",
      "[1684/1762] D loss: 1.4192\n",
      "[1762/1762] D loss: 1.4038\n",
      "train error: \n",
      " D loss: 1.416305, D accuracy: 48.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416113, D accuracy: 47.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4309\n",
      "[84/1762] D loss: 1.4057\n",
      "[164/1762] D loss: 1.3901\n",
      "[244/1762] D loss: 1.4560\n",
      "[324/1762] D loss: 1.3511\n",
      "[404/1762] D loss: 1.3794\n",
      "[484/1762] D loss: 1.4154\n",
      "[564/1762] D loss: 1.4119\n",
      "[644/1762] D loss: 1.3988\n",
      "[724/1762] D loss: 1.4133\n",
      "[804/1762] D loss: 1.4121\n",
      "[884/1762] D loss: 1.4294\n",
      "[964/1762] D loss: 1.4271\n",
      "[1044/1762] D loss: 1.3907\n",
      "[1124/1762] D loss: 1.4071\n",
      "[1204/1762] D loss: 1.4144\n",
      "[1284/1762] D loss: 1.4347\n",
      "[1364/1762] D loss: 1.3709\n",
      "[1444/1762] D loss: 1.4340\n",
      "[1524/1762] D loss: 1.4008\n",
      "[1604/1762] D loss: 1.3885\n",
      "[1684/1762] D loss: 1.3859\n",
      "[1762/1762] D loss: 1.3898\n",
      "train error: \n",
      " D loss: 1.412736, D accuracy: 48.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.413603, D accuracy: 48.3% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4475\n",
      "[84/1762] D loss: 1.4318\n",
      "[164/1762] D loss: 1.4004\n",
      "[244/1762] D loss: 1.4056\n",
      "[324/1762] D loss: 1.4208\n",
      "[404/1762] D loss: 1.3945\n",
      "[484/1762] D loss: 1.4173\n",
      "[564/1762] D loss: 1.3733\n",
      "[644/1762] D loss: 1.4317\n",
      "[724/1762] D loss: 1.4111\n",
      "[804/1762] D loss: 1.3863\n",
      "[884/1762] D loss: 1.3917\n",
      "[964/1762] D loss: 1.3879\n",
      "[1044/1762] D loss: 1.3863\n",
      "[1124/1762] D loss: 1.3934\n",
      "[1204/1762] D loss: 1.4163\n",
      "[1284/1762] D loss: 1.4198\n",
      "[1364/1762] D loss: 1.3904\n",
      "[1444/1762] D loss: 1.3866\n",
      "[1524/1762] D loss: 1.4047\n",
      "[1604/1762] D loss: 1.4266\n",
      "[1684/1762] D loss: 1.3930\n",
      "[1762/1762] D loss: 1.4708\n",
      "train error: \n",
      " D loss: 1.415110, D accuracy: 48.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416827, D accuracy: 48.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4114\n",
      "[84/1762] D loss: 1.3715\n",
      "[164/1762] D loss: 1.4395\n",
      "[244/1762] D loss: 1.3784\n",
      "[324/1762] D loss: 1.4129\n",
      "[404/1762] D loss: 1.4061\n",
      "[484/1762] D loss: 1.4230\n",
      "[564/1762] D loss: 1.4081\n",
      "[644/1762] D loss: 1.4436\n",
      "[724/1762] D loss: 1.4037\n",
      "[804/1762] D loss: 1.4034\n",
      "[884/1762] D loss: 1.4278\n",
      "[964/1762] D loss: 1.4101\n",
      "[1044/1762] D loss: 1.4131\n",
      "[1124/1762] D loss: 1.4072\n",
      "[1204/1762] D loss: 1.4217\n",
      "[1284/1762] D loss: 1.4265\n",
      "[1364/1762] D loss: 1.4103\n",
      "[1444/1762] D loss: 1.3788\n",
      "[1524/1762] D loss: 1.3992\n",
      "[1604/1762] D loss: 1.3896\n",
      "[1684/1762] D loss: 1.4358\n",
      "[1762/1762] D loss: 1.4249\n",
      "train error: \n",
      " D loss: 1.414027, D accuracy: 48.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.413652, D accuracy: 48.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4234\n",
      "[84/1762] D loss: 1.4564\n",
      "[164/1762] D loss: 1.4168\n",
      "[244/1762] D loss: 1.4474\n",
      "[324/1762] D loss: 1.3783\n",
      "[404/1762] D loss: 1.4061\n",
      "[484/1762] D loss: 1.4446\n",
      "[564/1762] D loss: 1.4132\n",
      "[644/1762] D loss: 1.4021\n",
      "[724/1762] D loss: 1.3688\n",
      "[804/1762] D loss: 1.3855\n",
      "[884/1762] D loss: 1.4131\n",
      "[964/1762] D loss: 1.4048\n",
      "[1044/1762] D loss: 1.4096\n",
      "[1124/1762] D loss: 1.3865\n",
      "[1204/1762] D loss: 1.4100\n",
      "[1284/1762] D loss: 1.4127\n",
      "[1364/1762] D loss: 1.4263\n",
      "[1444/1762] D loss: 1.4162\n",
      "[1524/1762] D loss: 1.3919\n",
      "[1604/1762] D loss: 1.4250\n",
      "[1684/1762] D loss: 1.4085\n",
      "[1762/1762] D loss: 1.3935\n",
      "train error: \n",
      " D loss: 1.411286, D accuracy: 49.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.414281, D accuracy: 48.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874\n",
      "[84/1762] D loss: 1.4045\n",
      "[164/1762] D loss: 1.3944\n",
      "[244/1762] D loss: 1.4157\n",
      "[324/1762] D loss: 1.4167\n",
      "[404/1762] D loss: 1.4144\n",
      "[484/1762] D loss: 1.3972\n",
      "[564/1762] D loss: 1.4070\n",
      "[644/1762] D loss: 1.4044\n",
      "[724/1762] D loss: 1.4180\n",
      "[804/1762] D loss: 1.3942\n",
      "[884/1762] D loss: 1.3839\n",
      "[964/1762] D loss: 1.4337\n",
      "[1044/1762] D loss: 1.4095\n",
      "[1124/1762] D loss: 1.3907\n",
      "[1204/1762] D loss: 1.3949\n",
      "[1284/1762] D loss: 1.4213\n",
      "[1364/1762] D loss: 1.4446\n",
      "[1444/1762] D loss: 1.3912\n",
      "[1524/1762] D loss: 1.4497\n",
      "[1604/1762] D loss: 1.3981\n",
      "[1684/1762] D loss: 1.3893\n",
      "[1762/1762] D loss: 1.4028\n",
      "train error: \n",
      " D loss: 1.410928, D accuracy: 48.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.413338, D accuracy: 47.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933\n",
      "[84/1762] D loss: 1.3712\n",
      "[164/1762] D loss: 1.3770\n",
      "[244/1762] D loss: 1.3908\n",
      "[324/1762] D loss: 1.4056\n",
      "[404/1762] D loss: 1.4106\n",
      "[484/1762] D loss: 1.4285\n",
      "[564/1762] D loss: 1.3697\n",
      "[644/1762] D loss: 1.4147\n",
      "[724/1762] D loss: 1.3754\n",
      "[804/1762] D loss: 1.3712\n",
      "[884/1762] D loss: 1.4161\n",
      "[964/1762] D loss: 1.4112\n",
      "[1044/1762] D loss: 1.4020\n",
      "[1124/1762] D loss: 1.4104\n",
      "[1204/1762] D loss: 1.4121\n",
      "[1284/1762] D loss: 1.3957\n",
      "[1364/1762] D loss: 1.3980\n",
      "[1444/1762] D loss: 1.4172\n",
      "[1524/1762] D loss: 1.4202\n",
      "[1604/1762] D loss: 1.4176\n",
      "[1684/1762] D loss: 1.4277\n",
      "[1762/1762] D loss: 1.4564\n",
      "train error: \n",
      " D loss: 1.412501, D accuracy: 48.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410792, D accuracy: 48.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911\n",
      "[84/1762] D loss: 1.4567\n",
      "[164/1762] D loss: 1.4046\n",
      "[244/1762] D loss: 1.3981\n",
      "[324/1762] D loss: 1.3772\n",
      "[404/1762] D loss: 1.4076\n",
      "[484/1762] D loss: 1.4334\n",
      "[564/1762] D loss: 1.4092\n",
      "[644/1762] D loss: 1.4017\n",
      "[724/1762] D loss: 1.4037\n",
      "[804/1762] D loss: 1.4077\n",
      "[884/1762] D loss: 1.4084\n",
      "[964/1762] D loss: 1.4321\n",
      "[1044/1762] D loss: 1.3990\n",
      "[1124/1762] D loss: 1.3802\n",
      "[1204/1762] D loss: 1.3948\n",
      "[1284/1762] D loss: 1.4021\n",
      "[1364/1762] D loss: 1.4350\n",
      "[1444/1762] D loss: 1.4000\n",
      "[1524/1762] D loss: 1.4053\n",
      "[1604/1762] D loss: 1.4084\n",
      "[1684/1762] D loss: 1.3949\n",
      "[1762/1762] D loss: 1.4012\n",
      "train error: \n",
      " D loss: 1.409663, D accuracy: 48.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409145, D accuracy: 47.8% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005\n",
      "[84/1762] D loss: 1.4332\n",
      "[164/1762] D loss: 1.3990\n",
      "[244/1762] D loss: 1.4281\n",
      "[324/1762] D loss: 1.4343\n",
      "[404/1762] D loss: 1.4181\n",
      "[484/1762] D loss: 1.4012\n",
      "[564/1762] D loss: 1.3681\n",
      "[644/1762] D loss: 1.4369\n",
      "[724/1762] D loss: 1.4230\n",
      "[804/1762] D loss: 1.4251\n",
      "[884/1762] D loss: 1.4156\n",
      "[964/1762] D loss: 1.3836\n",
      "[1044/1762] D loss: 1.3931\n",
      "[1124/1762] D loss: 1.3883\n",
      "[1204/1762] D loss: 1.3859\n",
      "[1284/1762] D loss: 1.3868\n",
      "[1364/1762] D loss: 1.3860\n",
      "[1444/1762] D loss: 1.3938\n",
      "[1524/1762] D loss: 1.3841\n",
      "[1604/1762] D loss: 1.3980\n",
      "[1684/1762] D loss: 1.3978\n",
      "[1762/1762] D loss: 1.4265\n",
      "train error: \n",
      " D loss: 1.410239, D accuracy: 48.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408125, D accuracy: 47.8% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4105\n",
      "[84/1762] D loss: 1.4067\n",
      "[164/1762] D loss: 1.4057\n",
      "[244/1762] D loss: 1.4171\n",
      "[324/1762] D loss: 1.4172\n",
      "[404/1762] D loss: 1.3569\n",
      "[484/1762] D loss: 1.3952\n",
      "[564/1762] D loss: 1.3947\n",
      "[644/1762] D loss: 1.3605\n",
      "[724/1762] D loss: 1.4088\n",
      "[804/1762] D loss: 1.3745\n",
      "[884/1762] D loss: 1.4067\n",
      "[964/1762] D loss: 1.4129\n",
      "[1044/1762] D loss: 1.4128\n",
      "[1124/1762] D loss: 1.4359\n",
      "[1204/1762] D loss: 1.4079\n",
      "[1284/1762] D loss: 1.4315\n",
      "[1364/1762] D loss: 1.4120\n",
      "[1444/1762] D loss: 1.4064\n",
      "[1524/1762] D loss: 1.4305\n",
      "[1604/1762] D loss: 1.4020\n",
      "[1684/1762] D loss: 1.3777\n",
      "[1762/1762] D loss: 1.3658\n",
      "train error: \n",
      " D loss: 1.407793, D accuracy: 48.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409982, D accuracy: 47.8% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899\n",
      "[84/1762] D loss: 1.3686\n",
      "[164/1762] D loss: 1.3709\n",
      "[244/1762] D loss: 1.3728\n",
      "[324/1762] D loss: 1.3748\n",
      "[404/1762] D loss: 1.3146\n",
      "[484/1762] D loss: 1.3183\n",
      "[564/1762] D loss: 1.2822\n",
      "[644/1762] D loss: 1.3343\n",
      "[724/1762] D loss: 1.2539\n",
      "[804/1762] D loss: 1.2628\n",
      "[884/1762] D loss: 1.2837\n",
      "[964/1762] D loss: 0.9684\n",
      "[1044/1762] D loss: 0.9255\n",
      "[1124/1762] D loss: 0.6958\n",
      "[1204/1762] D loss: 0.9915\n",
      "[1284/1762] D loss: 0.4977\n",
      "[1364/1762] D loss: 0.1657\n",
      "[1444/1762] D loss: 0.2845\n",
      "[1524/1762] D loss: 0.1972\n",
      "[1604/1762] D loss: 0.1126\n",
      "[1684/1762] D loss: 0.0634\n",
      "[1762/1762] D loss: 0.0564\n",
      "train error: \n",
      " D loss: 0.247420, D accuracy: 97.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.246864, D accuracy: 97.2% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1292\n",
      "[84/1762] D loss: 0.2034\n",
      "[164/1762] D loss: 0.0240\n",
      "[244/1762] D loss: 0.0634\n",
      "[324/1762] D loss: 0.0377\n",
      "[404/1762] D loss: 0.0147\n",
      "[484/1762] D loss: 0.0039\n",
      "[564/1762] D loss: 0.0195\n",
      "[644/1762] D loss: 0.0260\n",
      "[724/1762] D loss: 0.0117\n",
      "[804/1762] D loss: 0.3360\n",
      "[884/1762] D loss: 0.8492\n",
      "[964/1762] D loss: 0.0169\n",
      "[1044/1762] D loss: 0.6394\n",
      "[1124/1762] D loss: 0.1080\n",
      "[1204/1762] D loss: 0.0165\n",
      "[1284/1762] D loss: 0.0176\n",
      "[1364/1762] D loss: 0.0404\n",
      "[1444/1762] D loss: 0.0049\n",
      "[1524/1762] D loss: 0.0028\n",
      "[1604/1762] D loss: 0.0067\n",
      "[1684/1762] D loss: 0.0031\n",
      "[1762/1762] D loss: 0.0234\n",
      "train error: \n",
      " D loss: 0.207012, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.218831, D accuracy: 99.8% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0257\n",
      "[84/1762] D loss: 0.0045\n",
      "[164/1762] D loss: 0.0009\n",
      "[244/1762] D loss: 0.0142\n",
      "[324/1762] D loss: 0.0036\n",
      "[404/1762] D loss: 0.0331\n",
      "[484/1762] D loss: 0.0080\n",
      "[564/1762] D loss: 0.0059\n",
      "[644/1762] D loss: 0.0027\n",
      "[724/1762] D loss: 0.0151\n",
      "[804/1762] D loss: 0.0016\n",
      "[884/1762] D loss: 0.0018\n",
      "[964/1762] D loss: 0.0006\n",
      "[1044/1762] D loss: 0.0024\n",
      "[1124/1762] D loss: 0.0545\n",
      "[1204/1762] D loss: 0.0009\n",
      "[1284/1762] D loss: 0.0058\n",
      "[1364/1762] D loss: 0.0028\n",
      "[1444/1762] D loss: 0.0006\n",
      "[1524/1762] D loss: 0.0009\n",
      "[1604/1762] D loss: 0.0127\n",
      "[1684/1762] D loss: 0.0015\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 0.244341, D accuracy: 99.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.256276, D accuracy: 99.9% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0015\n",
      "[84/1762] D loss: 0.0012\n",
      "[164/1762] D loss: 0.0011\n",
      "[244/1762] D loss: 0.0032\n",
      "[324/1762] D loss: 0.0057\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0011\n",
      "[564/1762] D loss: 0.0029\n",
      "[644/1762] D loss: 0.0111\n",
      "[724/1762] D loss: 0.0009\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0064\n",
      "[964/1762] D loss: 0.1029\n",
      "[1044/1762] D loss: 0.0287\n",
      "[1124/1762] D loss: 0.0134\n",
      "[1204/1762] D loss: 0.0092\n",
      "[1284/1762] D loss: 0.0132\n",
      "[1364/1762] D loss: 0.0019\n",
      "[1444/1762] D loss: 0.3579\n",
      "[1524/1762] D loss: 0.4864\n",
      "[1604/1762] D loss: 0.0127\n",
      "[1684/1762] D loss: 0.0121\n",
      "[1762/1762] D loss: 0.0036\n",
      "train error: \n",
      " D loss: 0.188762, D accuracy: 99.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.195161, D accuracy: 99.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0071\n",
      "[84/1762] D loss: 0.0040\n",
      "[164/1762] D loss: 0.0010\n",
      "[244/1762] D loss: 0.0010\n",
      "[324/1762] D loss: 0.0019\n",
      "[404/1762] D loss: 0.0149\n",
      "[484/1762] D loss: 0.0014\n",
      "[564/1762] D loss: 0.0021\n",
      "[644/1762] D loss: 0.0006\n",
      "[724/1762] D loss: 0.0071\n",
      "[804/1762] D loss: 0.0014\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0078\n",
      "[1124/1762] D loss: 0.0007\n",
      "[1204/1762] D loss: 0.0023\n",
      "[1284/1762] D loss: 0.0009\n",
      "[1364/1762] D loss: 0.0007\n",
      "[1444/1762] D loss: 0.0006\n",
      "[1524/1762] D loss: 0.0302\n",
      "[1604/1762] D loss: 0.0024\n",
      "[1684/1762] D loss: 0.0095\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 0.209334, D accuracy: 99.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.217388, D accuracy: 99.7% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0013\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0008\n",
      "[244/1762] D loss: 0.0004\n",
      "[324/1762] D loss: 0.0040\n",
      "[404/1762] D loss: 0.0011\n",
      "[484/1762] D loss: 0.0132\n",
      "[564/1762] D loss: 0.0204\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0007\n",
      "[804/1762] D loss: 0.0008\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0007\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0016\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 0.322008, D accuracy: 98.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.342062, D accuracy: 97.4% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0095\n",
      "[164/1762] D loss: 0.0028\n",
      "[244/1762] D loss: 0.0017\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0032\n",
      "[564/1762] D loss: 0.0021\n",
      "[644/1762] D loss: 0.0003\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0010\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0038\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0009\n",
      "[1364/1762] D loss: 0.0009\n",
      "[1444/1762] D loss: 0.0070\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0080\n",
      "[1684/1762] D loss: 0.0011\n",
      "[1762/1762] D loss: 0.0011\n",
      "train error: \n",
      " D loss: 0.634931, D accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.662109, D accuracy: 81.6% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0096\n",
      "[84/1762] D loss: 0.0027\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0156\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0006\n",
      "[884/1762] D loss: 0.0010\n",
      "[964/1762] D loss: 0.0002\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0015\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0007\n",
      "[1524/1762] D loss: 0.0007\n",
      "[1604/1762] D loss: 0.0018\n",
      "[1684/1762] D loss: 0.0006\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.655406, D accuracy: 81.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.681079, D accuracy: 79.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0010\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0005\n",
      "[564/1762] D loss: 0.0401\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0006\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0123\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0002\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.845028, D accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.871598, D accuracy: 66.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0251\n",
      "[84/1762] D loss: 0.0012\n",
      "[164/1762] D loss: 0.0074\n",
      "[244/1762] D loss: 0.0012\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0009\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0023\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0007\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0001\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0002\n",
      "train error: \n",
      " D loss: 0.701487, D accuracy: 78.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.725660, D accuracy: 75.8% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0002\n",
      "[164/1762] D loss: 0.0001\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0002\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0099\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0002\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0054\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0001\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0021\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.965416, D accuracy: 61.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999253, D accuracy: 60.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0002\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0002\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0005\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0003\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.823077, D accuracy: 70.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.850881, D accuracy: 67.8% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0009\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0001\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0015\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0022\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0031\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 0.962695, D accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.990746, D accuracy: 60.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0007\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0001\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.194862, D accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.230308, D accuracy: 53.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0001\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0027\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0005\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0002\n",
      "[1284/1762] D loss: 0.0003\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0001\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.133239, D accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.165891, D accuracy: 54.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0001\n",
      "[804/1762] D loss: 0.0006\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0001\n",
      "[1044/1762] D loss: 0.0004\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0011\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0040\n",
      "[1524/1762] D loss: 0.0020\n",
      "[1604/1762] D loss: 0.0002\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0001\n",
      "train error: \n",
      " D loss: 1.500710, D accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.530685, D accuracy: 51.1% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001\n",
      "[84/1762] D loss: 0.0001\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0002\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0001\n",
      "[724/1762] D loss: 0.0007\n",
      "[804/1762] D loss: 0.0001\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0066\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.661226, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.695776, D accuracy: 50.6% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0008\n",
      "[164/1762] D loss: 0.0007\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0001\n",
      "[404/1762] D loss: 0.0000\n",
      "[484/1762] D loss: 0.0137\n",
      "[564/1762] D loss: 0.0003\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0000\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0003\n",
      "[1444/1762] D loss: 0.0000\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.410030, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.445033, D accuracy: 51.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0000\n",
      "[244/1762] D loss: 0.0000\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0000\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0000\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0001\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0001\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0000\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0001\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0000\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0000\n",
      "train error: \n",
      " D loss: 1.449763, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.482051, D accuracy: 50.8% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000\n",
      "[84/1762] D loss: 0.0000\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0001\n",
      "[324/1762] D loss: 0.0000\n",
      "[404/1762] D loss: 0.0001\n",
      "[484/1762] D loss: 0.0000\n",
      "[564/1762] D loss: 0.0002\n",
      "[644/1762] D loss: 0.0000\n",
      "[724/1762] D loss: 0.0003\n",
      "[804/1762] D loss: 0.0000\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0000\n",
      "[1044/1762] D loss: 0.0000\n",
      "[1124/1762] D loss: 0.0000\n",
      "[1204/1762] D loss: 0.0001\n",
      "[1284/1762] D loss: 0.0000\n",
      "[1364/1762] D loss: 0.0000\n",
      "[1444/1762] D loss: 0.0002\n",
      "[1524/1762] D loss: 0.0000\n",
      "[1604/1762] D loss: 0.0001\n",
      "[1684/1762] D loss: 0.0000\n",
      "[1762/1762] D loss: 0.0013\n",
      "train error: \n",
      " D loss: 1.205033, D accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.233772, D accuracy: 53.2% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868\n",
      "[84/1762] D loss: 1.3780\n",
      "[164/1762] D loss: 1.3987\n",
      "[244/1762] D loss: 1.3604\n",
      "[324/1762] D loss: 1.3719\n",
      "[404/1762] D loss: 1.3896\n",
      "[484/1762] D loss: 1.3835\n",
      "[564/1762] D loss: 1.3665\n",
      "[644/1762] D loss: 1.3719\n",
      "[724/1762] D loss: 1.3633\n",
      "[804/1762] D loss: 1.3532\n",
      "[884/1762] D loss: 1.4023\n",
      "[964/1762] D loss: 1.3803\n",
      "[1044/1762] D loss: 1.3555\n",
      "[1124/1762] D loss: 1.3834\n",
      "[1204/1762] D loss: 1.3676\n",
      "[1284/1762] D loss: 1.3729\n",
      "[1364/1762] D loss: 1.3853\n",
      "[1444/1762] D loss: 1.3774\n",
      "[1524/1762] D loss: 1.3824\n",
      "[1604/1762] D loss: 1.3573\n",
      "[1684/1762] D loss: 1.3834\n",
      "[1762/1762] D loss: 1.3578\n",
      "train error: \n",
      " D loss: 1.372299, D accuracy: 56.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370492, D accuracy: 58.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4125\n",
      "[84/1762] D loss: 1.3357\n",
      "[164/1762] D loss: 1.3748\n",
      "[244/1762] D loss: 1.3595\n",
      "[324/1762] D loss: 1.3773\n",
      "[404/1762] D loss: 1.3846\n",
      "[484/1762] D loss: 1.3852\n",
      "[564/1762] D loss: 1.3711\n",
      "[644/1762] D loss: 1.3914\n",
      "[724/1762] D loss: 1.3669\n",
      "[804/1762] D loss: 1.3830\n",
      "[884/1762] D loss: 1.3690\n",
      "[964/1762] D loss: 1.3492\n",
      "[1044/1762] D loss: 1.3526\n",
      "[1124/1762] D loss: 1.3657\n",
      "[1204/1762] D loss: 1.3686\n",
      "[1284/1762] D loss: 1.3689\n",
      "[1364/1762] D loss: 1.3688\n",
      "[1444/1762] D loss: 1.3374\n",
      "[1524/1762] D loss: 1.3969\n",
      "[1604/1762] D loss: 1.3963\n",
      "[1684/1762] D loss: 1.3579\n",
      "[1762/1762] D loss: 1.3775\n",
      "train error: \n",
      " D loss: 1.360247, D accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357411, D accuracy: 59.4% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3682\n",
      "[84/1762] D loss: 1.3674\n",
      "[164/1762] D loss: 1.3880\n",
      "[244/1762] D loss: 1.3590\n",
      "[324/1762] D loss: 1.3485\n",
      "[404/1762] D loss: 1.4070\n",
      "[484/1762] D loss: 1.3358\n",
      "[564/1762] D loss: 1.2905\n",
      "[644/1762] D loss: 1.3656\n",
      "[724/1762] D loss: 1.3753\n",
      "[804/1762] D loss: 1.3676\n",
      "[884/1762] D loss: 1.3942\n",
      "[964/1762] D loss: 1.3638\n",
      "[1044/1762] D loss: 1.3593\n",
      "[1124/1762] D loss: 1.3700\n",
      "[1204/1762] D loss: 1.3276\n",
      "[1284/1762] D loss: 1.3434\n",
      "[1364/1762] D loss: 1.3572\n",
      "[1444/1762] D loss: 1.3272\n",
      "[1524/1762] D loss: 1.3636\n",
      "[1604/1762] D loss: 1.3660\n",
      "[1684/1762] D loss: 1.3691\n",
      "[1762/1762] D loss: 1.2988\n",
      "train error: \n",
      " D loss: 1.341743, D accuracy: 62.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345947, D accuracy: 61.1% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3462\n",
      "[84/1762] D loss: 1.3376\n",
      "[164/1762] D loss: 1.3318\n",
      "[244/1762] D loss: 1.3917\n",
      "[324/1762] D loss: 1.3509\n",
      "[404/1762] D loss: 1.3363\n",
      "[484/1762] D loss: 1.3592\n",
      "[564/1762] D loss: 1.3416\n",
      "[644/1762] D loss: 1.3747\n",
      "[724/1762] D loss: 1.3215\n",
      "[804/1762] D loss: 1.3106\n",
      "[884/1762] D loss: 1.2983\n",
      "[964/1762] D loss: 1.3426\n",
      "[1044/1762] D loss: 1.3194\n",
      "[1124/1762] D loss: 1.3894\n",
      "[1204/1762] D loss: 1.3374\n",
      "[1284/1762] D loss: 1.3426\n",
      "[1364/1762] D loss: 1.3685\n",
      "[1444/1762] D loss: 1.3473\n",
      "[1524/1762] D loss: 1.3505\n",
      "[1604/1762] D loss: 1.3578\n",
      "[1684/1762] D loss: 1.2918\n",
      "[1762/1762] D loss: 1.3008\n",
      "train error: \n",
      " D loss: 1.313129, D accuracy: 66.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309411, D accuracy: 67.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3347\n",
      "[84/1762] D loss: 1.2645\n",
      "[164/1762] D loss: 1.3380\n",
      "[244/1762] D loss: 1.3544\n",
      "[324/1762] D loss: 1.3147\n",
      "[404/1762] D loss: 1.2402\n",
      "[484/1762] D loss: 1.2331\n",
      "[564/1762] D loss: 1.3356\n",
      "[644/1762] D loss: 1.2146\n",
      "[724/1762] D loss: 1.2984\n",
      "[804/1762] D loss: 1.3219\n",
      "[884/1762] D loss: 1.3021\n",
      "[964/1762] D loss: 1.3046\n",
      "[1044/1762] D loss: 1.2378\n",
      "[1124/1762] D loss: 1.2739\n",
      "[1204/1762] D loss: 1.3021\n",
      "[1284/1762] D loss: 1.2822\n",
      "[1364/1762] D loss: 1.3039\n",
      "[1444/1762] D loss: 1.2645\n",
      "[1524/1762] D loss: 1.2608\n",
      "[1604/1762] D loss: 1.1580\n",
      "[1684/1762] D loss: 1.2387\n",
      "[1762/1762] D loss: 1.2937\n",
      "train error: \n",
      " D loss: 1.237373, D accuracy: 76.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.234079, D accuracy: 77.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2232\n",
      "[84/1762] D loss: 1.2245\n",
      "[164/1762] D loss: 1.2274\n",
      "[244/1762] D loss: 1.1676\n",
      "[324/1762] D loss: 1.2242\n",
      "[404/1762] D loss: 1.2159\n",
      "[484/1762] D loss: 1.2071\n",
      "[564/1762] D loss: 1.1934\n",
      "[644/1762] D loss: 1.1619\n",
      "[724/1762] D loss: 1.2435\n",
      "[804/1762] D loss: 1.1086\n",
      "[884/1762] D loss: 1.1513\n",
      "[964/1762] D loss: 1.0966\n",
      "[1044/1762] D loss: 1.1142\n",
      "[1124/1762] D loss: 1.0866\n",
      "[1204/1762] D loss: 1.1554\n",
      "[1284/1762] D loss: 1.2319\n",
      "[1364/1762] D loss: 0.8970\n",
      "[1444/1762] D loss: 1.1634\n",
      "[1524/1762] D loss: 0.9755\n",
      "[1604/1762] D loss: 1.1166\n",
      "[1684/1762] D loss: 1.1166\n",
      "[1762/1762] D loss: 1.1574\n",
      "train error: \n",
      " D loss: 1.003202, D accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.011835, D accuracy: 90.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9241\n",
      "[84/1762] D loss: 0.9457\n",
      "[164/1762] D loss: 1.2190\n",
      "[244/1762] D loss: 1.0891\n",
      "[324/1762] D loss: 1.0778\n",
      "[404/1762] D loss: 0.8367\n",
      "[484/1762] D loss: 0.9943\n",
      "[564/1762] D loss: 0.7748\n",
      "[644/1762] D loss: 0.9113\n",
      "[724/1762] D loss: 0.9799\n",
      "[804/1762] D loss: 0.9683\n",
      "[884/1762] D loss: 0.6064\n",
      "[964/1762] D loss: 0.8607\n",
      "[1044/1762] D loss: 0.7350\n",
      "[1124/1762] D loss: 0.6937\n",
      "[1204/1762] D loss: 0.7511\n",
      "[1284/1762] D loss: 0.6179\n",
      "[1364/1762] D loss: 0.9125\n",
      "[1444/1762] D loss: 0.6005\n",
      "[1524/1762] D loss: 0.7206\n",
      "[1604/1762] D loss: 0.5783\n",
      "[1684/1762] D loss: 0.6488\n",
      "[1762/1762] D loss: 0.7769\n",
      "train error: \n",
      " D loss: 0.561542, D accuracy: 95.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.550994, D accuracy: 96.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2574\n",
      "[84/1762] D loss: 0.6349\n",
      "[164/1762] D loss: 0.4798\n",
      "[244/1762] D loss: 0.7670\n",
      "[324/1762] D loss: 0.4938\n",
      "[404/1762] D loss: 0.5123\n",
      "[484/1762] D loss: 0.3938\n",
      "[564/1762] D loss: 0.5137\n",
      "[644/1762] D loss: 0.5749\n",
      "[724/1762] D loss: 0.7746\n",
      "[804/1762] D loss: 0.6328\n",
      "[884/1762] D loss: 0.2581\n",
      "[964/1762] D loss: 0.4931\n",
      "[1044/1762] D loss: 0.6336\n",
      "[1124/1762] D loss: 0.3124\n",
      "[1204/1762] D loss: 1.0097\n",
      "[1284/1762] D loss: 0.3072\n",
      "[1364/1762] D loss: 0.2101\n",
      "[1444/1762] D loss: 0.1992\n",
      "[1524/1762] D loss: 0.3983\n",
      "[1604/1762] D loss: 0.1898\n",
      "[1684/1762] D loss: 0.2153\n",
      "[1762/1762] D loss: 0.6839\n",
      "train error: \n",
      " D loss: 0.322384, D accuracy: 99.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.343512, D accuracy: 98.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3803\n",
      "[84/1762] D loss: 0.1375\n",
      "[164/1762] D loss: 0.1737\n",
      "[244/1762] D loss: 0.2000\n",
      "[324/1762] D loss: 0.1541\n",
      "[404/1762] D loss: 0.1095\n",
      "[484/1762] D loss: 0.4073\n",
      "[564/1762] D loss: 0.2413\n",
      "[644/1762] D loss: 0.3860\n",
      "[724/1762] D loss: 0.0920\n",
      "[804/1762] D loss: 0.2699\n",
      "[884/1762] D loss: 0.1206\n",
      "[964/1762] D loss: 0.0973\n",
      "[1044/1762] D loss: 0.1961\n",
      "[1124/1762] D loss: 0.2767\n",
      "[1204/1762] D loss: 0.0684\n",
      "[1284/1762] D loss: 0.1962\n",
      "[1364/1762] D loss: 0.1827\n",
      "[1444/1762] D loss: 0.2157\n",
      "[1524/1762] D loss: 0.0584\n",
      "[1604/1762] D loss: 0.1229\n",
      "[1684/1762] D loss: 0.0840\n",
      "[1762/1762] D loss: 0.0872\n",
      "train error: \n",
      " D loss: 0.196521, D accuracy: 99.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.192221, D accuracy: 99.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0764\n",
      "[84/1762] D loss: 0.1146\n",
      "[164/1762] D loss: 0.1378\n",
      "[244/1762] D loss: 0.0340\n",
      "[324/1762] D loss: 0.1070\n",
      "[404/1762] D loss: 0.0760\n",
      "[484/1762] D loss: 0.0870\n",
      "[564/1762] D loss: 0.0764\n",
      "[644/1762] D loss: 0.0289\n",
      "[724/1762] D loss: 0.1065\n",
      "[804/1762] D loss: 0.0536\n",
      "[884/1762] D loss: 0.0401\n",
      "[964/1762] D loss: 0.1582\n",
      "[1044/1762] D loss: 0.3455\n",
      "[1124/1762] D loss: 0.0619\n",
      "[1204/1762] D loss: 0.0355\n",
      "[1284/1762] D loss: 0.0221\n",
      "[1364/1762] D loss: 0.0716\n",
      "[1444/1762] D loss: 0.0414\n",
      "[1524/1762] D loss: 0.0504\n",
      "[1604/1762] D loss: 0.0908\n",
      "[1684/1762] D loss: 0.0207\n",
      "[1762/1762] D loss: 0.0143\n",
      "train error: \n",
      " D loss: 0.149965, D accuracy: 99.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.170133, D accuracy: 98.9% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0948\n",
      "[84/1762] D loss: 0.0373\n",
      "[164/1762] D loss: 0.0392\n",
      "[244/1762] D loss: 0.0616\n",
      "[324/1762] D loss: 0.0580\n",
      "[404/1762] D loss: 0.0476\n",
      "[484/1762] D loss: 0.0348\n",
      "[564/1762] D loss: 0.1459\n",
      "[644/1762] D loss: 0.0458\n",
      "[724/1762] D loss: 0.0141\n",
      "[804/1762] D loss: 0.0279\n",
      "[884/1762] D loss: 0.0389\n",
      "[964/1762] D loss: 0.0097\n",
      "[1044/1762] D loss: 0.0151\n",
      "[1124/1762] D loss: 0.4891\n",
      "[1204/1762] D loss: 0.0227\n",
      "[1284/1762] D loss: 0.0463\n",
      "[1364/1762] D loss: 0.0279\n",
      "[1444/1762] D loss: 0.0688\n",
      "[1524/1762] D loss: 0.0168\n",
      "[1604/1762] D loss: 0.0092\n",
      "[1684/1762] D loss: 0.0239\n",
      "[1762/1762] D loss: 0.0415\n",
      "train error: \n",
      " D loss: 0.155711, D accuracy: 99.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.175514, D accuracy: 99.1% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0420\n",
      "[84/1762] D loss: 0.0350\n",
      "[164/1762] D loss: 0.0295\n",
      "[244/1762] D loss: 0.0154\n",
      "[324/1762] D loss: 0.0475\n",
      "[404/1762] D loss: 0.0116\n",
      "[484/1762] D loss: 0.0830\n",
      "[564/1762] D loss: 0.0201\n",
      "[644/1762] D loss: 0.1168\n",
      "[724/1762] D loss: 0.0110\n",
      "[804/1762] D loss: 0.0268\n",
      "[884/1762] D loss: 0.0462\n",
      "[964/1762] D loss: 0.0240\n",
      "[1044/1762] D loss: 0.0060\n",
      "[1124/1762] D loss: 0.0193\n",
      "[1204/1762] D loss: 0.0131\n",
      "[1284/1762] D loss: 0.0201\n",
      "[1364/1762] D loss: 0.0144\n",
      "[1444/1762] D loss: 0.0121\n",
      "[1524/1762] D loss: 0.0157\n",
      "[1604/1762] D loss: 0.0238\n",
      "[1684/1762] D loss: 0.0510\n",
      "[1762/1762] D loss: 0.0329\n",
      "train error: \n",
      " D loss: 0.109502, D accuracy: 99.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.108884, D accuracy: 99.7% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0153\n",
      "[84/1762] D loss: 0.0305\n",
      "[164/1762] D loss: 0.0259\n",
      "[244/1762] D loss: 0.0302\n",
      "[324/1762] D loss: 0.0419\n",
      "[404/1762] D loss: 0.0077\n",
      "[484/1762] D loss: 0.0380\n",
      "[564/1762] D loss: 0.0499\n",
      "[644/1762] D loss: 0.0460\n",
      "[724/1762] D loss: 0.0145\n",
      "[804/1762] D loss: 0.0206\n",
      "[884/1762] D loss: 0.0956\n",
      "[964/1762] D loss: 0.0214\n",
      "[1044/1762] D loss: 0.0141\n",
      "[1124/1762] D loss: 0.0229\n",
      "[1204/1762] D loss: 0.0139\n",
      "[1284/1762] D loss: 0.0078\n",
      "[1364/1762] D loss: 0.0083\n",
      "[1444/1762] D loss: 0.0345\n",
      "[1524/1762] D loss: 0.0089\n",
      "[1604/1762] D loss: 0.0253\n",
      "[1684/1762] D loss: 0.0072\n",
      "[1762/1762] D loss: 0.0095\n",
      "train error: \n",
      " D loss: 0.123416, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.128838, D accuracy: 99.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0192\n",
      "[84/1762] D loss: 0.0293\n",
      "[164/1762] D loss: 0.0313\n",
      "[244/1762] D loss: 0.0153\n",
      "[324/1762] D loss: 0.0154\n",
      "[404/1762] D loss: 0.0876\n",
      "[484/1762] D loss: 0.0101\n",
      "[564/1762] D loss: 0.0085\n",
      "[644/1762] D loss: 0.0340\n",
      "[724/1762] D loss: 0.0059\n",
      "[804/1762] D loss: 0.0079\n",
      "[884/1762] D loss: 0.0375\n",
      "[964/1762] D loss: 0.0901\n",
      "[1044/1762] D loss: 0.0378\n",
      "[1124/1762] D loss: 0.0353\n",
      "[1204/1762] D loss: 0.0709\n",
      "[1284/1762] D loss: 0.1812\n",
      "[1364/1762] D loss: 0.0044\n",
      "[1444/1762] D loss: 0.0114\n",
      "[1524/1762] D loss: 0.0162\n",
      "[1604/1762] D loss: 0.0442\n",
      "[1684/1762] D loss: 0.0702\n",
      "[1762/1762] D loss: 0.0132\n",
      "train error: \n",
      " D loss: 0.140314, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.147289, D accuracy: 99.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0064\n",
      "[84/1762] D loss: 0.0265\n",
      "[164/1762] D loss: 0.0147\n",
      "[244/1762] D loss: 0.0076\n",
      "[324/1762] D loss: 0.0248\n",
      "[404/1762] D loss: 0.0225\n",
      "[484/1762] D loss: 0.0234\n",
      "[564/1762] D loss: 0.0098\n",
      "[644/1762] D loss: 0.0089\n",
      "[724/1762] D loss: 0.0052\n",
      "[804/1762] D loss: 0.0079\n",
      "[884/1762] D loss: 0.0073\n",
      "[964/1762] D loss: 0.0087\n",
      "[1044/1762] D loss: 0.0105\n",
      "[1124/1762] D loss: 0.0167\n",
      "[1204/1762] D loss: 0.0189\n",
      "[1284/1762] D loss: 0.0076\n",
      "[1364/1762] D loss: 0.0199\n",
      "[1444/1762] D loss: 0.0071\n",
      "[1524/1762] D loss: 0.0039\n",
      "[1604/1762] D loss: 0.0152\n",
      "[1684/1762] D loss: 0.1396\n",
      "[1762/1762] D loss: 0.0146\n",
      "train error: \n",
      " D loss: 0.150968, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.141066, D accuracy: 99.9% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0111\n",
      "[84/1762] D loss: 0.0069\n",
      "[164/1762] D loss: 0.0042\n",
      "[244/1762] D loss: 0.0108\n",
      "[324/1762] D loss: 0.0066\n",
      "[404/1762] D loss: 0.0057\n",
      "[484/1762] D loss: 0.0068\n",
      "[564/1762] D loss: 0.0044\n",
      "[644/1762] D loss: 0.0134\n",
      "[724/1762] D loss: 0.0088\n",
      "[804/1762] D loss: 0.0408\n",
      "[884/1762] D loss: 0.0155\n",
      "[964/1762] D loss: 0.0073\n",
      "[1044/1762] D loss: 0.0112\n",
      "[1124/1762] D loss: 0.0092\n",
      "[1204/1762] D loss: 0.0023\n",
      "[1284/1762] D loss: 0.0065\n",
      "[1364/1762] D loss: 0.0369\n",
      "[1444/1762] D loss: 0.0041\n",
      "[1524/1762] D loss: 0.0033\n",
      "[1604/1762] D loss: 0.0078\n",
      "[1684/1762] D loss: 0.0097\n",
      "[1762/1762] D loss: 0.0086\n",
      "train error: \n",
      " D loss: 0.125784, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.126528, D accuracy: 99.9% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0194\n",
      "[84/1762] D loss: 0.0096\n",
      "[164/1762] D loss: 0.0117\n",
      "[244/1762] D loss: 0.0026\n",
      "[324/1762] D loss: 0.0079\n",
      "[404/1762] D loss: 0.0135\n",
      "[484/1762] D loss: 0.0306\n",
      "[564/1762] D loss: 0.0062\n",
      "[644/1762] D loss: 0.0156\n",
      "[724/1762] D loss: 0.0095\n",
      "[804/1762] D loss: 0.0622\n",
      "[884/1762] D loss: 0.0040\n",
      "[964/1762] D loss: 0.0136\n",
      "[1044/1762] D loss: 0.0029\n",
      "[1124/1762] D loss: 0.0025\n",
      "[1204/1762] D loss: 0.0098\n",
      "[1284/1762] D loss: 0.0024\n",
      "[1364/1762] D loss: 0.0100\n",
      "[1444/1762] D loss: 0.0039\n",
      "[1524/1762] D loss: 0.0063\n",
      "[1604/1762] D loss: 0.0143\n",
      "[1684/1762] D loss: 0.0067\n",
      "[1762/1762] D loss: 0.0122\n",
      "train error: \n",
      " D loss: 0.149550, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.149908, D accuracy: 99.9% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0036\n",
      "[84/1762] D loss: 0.0079\n",
      "[164/1762] D loss: 0.0074\n",
      "[244/1762] D loss: 0.0026\n",
      "[324/1762] D loss: 0.0124\n",
      "[404/1762] D loss: 0.0084\n",
      "[484/1762] D loss: 0.0022\n",
      "[564/1762] D loss: 0.0023\n",
      "[644/1762] D loss: 0.0077\n",
      "[724/1762] D loss: 0.0047\n",
      "[804/1762] D loss: 0.0050\n",
      "[884/1762] D loss: 0.0108\n",
      "[964/1762] D loss: 0.0053\n",
      "[1044/1762] D loss: 0.0022\n",
      "[1124/1762] D loss: 0.0020\n",
      "[1204/1762] D loss: 0.0099\n",
      "[1284/1762] D loss: 0.0090\n",
      "[1364/1762] D loss: 0.0025\n",
      "[1444/1762] D loss: 0.0026\n",
      "[1524/1762] D loss: 0.0036\n",
      "[1604/1762] D loss: 0.0041\n",
      "[1684/1762] D loss: 0.0024\n",
      "[1762/1762] D loss: 0.0086\n",
      "train error: \n",
      " D loss: 0.155288, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.161138, D accuracy: 99.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0112\n",
      "[84/1762] D loss: 0.0019\n",
      "[164/1762] D loss: 0.0033\n",
      "[244/1762] D loss: 0.0065\n",
      "[324/1762] D loss: 0.0036\n",
      "[404/1762] D loss: 0.0229\n",
      "[484/1762] D loss: 0.0037\n",
      "[564/1762] D loss: 0.0037\n",
      "[644/1762] D loss: 0.0058\n",
      "[724/1762] D loss: 0.0036\n",
      "[804/1762] D loss: 0.0058\n",
      "[884/1762] D loss: 0.0032\n",
      "[964/1762] D loss: 0.0048\n",
      "[1044/1762] D loss: 0.0072\n",
      "[1124/1762] D loss: 0.0070\n",
      "[1204/1762] D loss: 0.0098\n",
      "[1284/1762] D loss: 0.0108\n",
      "[1364/1762] D loss: 0.0044\n",
      "[1444/1762] D loss: 0.0119\n",
      "[1524/1762] D loss: 0.0034\n",
      "[1604/1762] D loss: 0.0044\n",
      "[1684/1762] D loss: 0.0149\n",
      "[1762/1762] D loss: 0.0060\n",
      "train error: \n",
      " D loss: 0.183978, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.189229, D accuracy: 99.8% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0026\n",
      "[84/1762] D loss: 0.0015\n",
      "[164/1762] D loss: 0.0022\n",
      "[244/1762] D loss: 0.0071\n",
      "[324/1762] D loss: 0.0034\n",
      "[404/1762] D loss: 0.0043\n",
      "[484/1762] D loss: 0.0037\n",
      "[564/1762] D loss: 0.0035\n",
      "[644/1762] D loss: 0.0043\n",
      "[724/1762] D loss: 0.0052\n",
      "[804/1762] D loss: 0.0031\n",
      "[884/1762] D loss: 0.0046\n",
      "[964/1762] D loss: 0.0054\n",
      "[1044/1762] D loss: 0.0104\n",
      "[1124/1762] D loss: 0.0041\n",
      "[1204/1762] D loss: 0.0031\n",
      "[1284/1762] D loss: 0.0567\n",
      "[1364/1762] D loss: 0.0119\n",
      "[1444/1762] D loss: 0.0023\n",
      "[1524/1762] D loss: 0.0070\n",
      "[1604/1762] D loss: 0.0038\n",
      "[1684/1762] D loss: 0.0026\n",
      "[1762/1762] D loss: 0.0034\n",
      "train error: \n",
      " D loss: 0.187045, D accuracy: 99.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.196892, D accuracy: 99.8% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3932\n",
      "[84/1762] D loss: 1.4015\n",
      "[164/1762] D loss: 1.4020\n",
      "[244/1762] D loss: 1.3967\n",
      "[324/1762] D loss: 1.3803\n",
      "[404/1762] D loss: 1.3804\n",
      "[484/1762] D loss: 1.4022\n",
      "[564/1762] D loss: 1.3973\n",
      "[644/1762] D loss: 1.3933\n",
      "[724/1762] D loss: 1.3773\n",
      "[804/1762] D loss: 1.3905\n",
      "[884/1762] D loss: 1.3934\n",
      "[964/1762] D loss: 1.3874\n",
      "[1044/1762] D loss: 1.3656\n",
      "[1124/1762] D loss: 1.3940\n",
      "[1204/1762] D loss: 1.3952\n",
      "[1284/1762] D loss: 1.3737\n",
      "[1364/1762] D loss: 1.4027\n",
      "[1444/1762] D loss: 1.3828\n",
      "[1524/1762] D loss: 1.3999\n",
      "[1604/1762] D loss: 1.3825\n",
      "[1684/1762] D loss: 1.4084\n",
      "[1762/1762] D loss: 1.3827\n",
      "train error: \n",
      " D loss: 1.382474, D accuracy: 51.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381860, D accuracy: 52.2% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917\n",
      "[84/1762] D loss: 1.3737\n",
      "[164/1762] D loss: 1.3835\n",
      "[244/1762] D loss: 1.3686\n",
      "[324/1762] D loss: 1.4036\n",
      "[404/1762] D loss: 1.3880\n",
      "[484/1762] D loss: 1.3870\n",
      "[564/1762] D loss: 1.4043\n",
      "[644/1762] D loss: 1.3847\n",
      "[724/1762] D loss: 1.4049\n",
      "[804/1762] D loss: 1.4117\n",
      "[884/1762] D loss: 1.3934\n",
      "[964/1762] D loss: 1.3883\n",
      "[1044/1762] D loss: 1.3797\n",
      "[1124/1762] D loss: 1.3931\n",
      "[1204/1762] D loss: 1.3756\n",
      "[1284/1762] D loss: 1.3633\n",
      "[1364/1762] D loss: 1.3866\n",
      "[1444/1762] D loss: 1.4054\n",
      "[1524/1762] D loss: 1.3647\n",
      "[1604/1762] D loss: 1.3948\n",
      "[1684/1762] D loss: 1.3766\n",
      "[1762/1762] D loss: 1.3598\n",
      "train error: \n",
      " D loss: 1.382139, D accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382755, D accuracy: 51.7% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3736\n",
      "[84/1762] D loss: 1.3833\n",
      "[164/1762] D loss: 1.3931\n",
      "[244/1762] D loss: 1.3889\n",
      "[324/1762] D loss: 1.3672\n",
      "[404/1762] D loss: 1.3653\n",
      "[484/1762] D loss: 1.4013\n",
      "[564/1762] D loss: 1.3916\n",
      "[644/1762] D loss: 1.3688\n",
      "[724/1762] D loss: 1.3909\n",
      "[804/1762] D loss: 1.3853\n",
      "[884/1762] D loss: 1.3854\n",
      "[964/1762] D loss: 1.3969\n",
      "[1044/1762] D loss: 1.3716\n",
      "[1124/1762] D loss: 1.3886\n",
      "[1204/1762] D loss: 1.3968\n",
      "[1284/1762] D loss: 1.3708\n",
      "[1364/1762] D loss: 1.3855\n",
      "[1444/1762] D loss: 1.3934\n",
      "[1524/1762] D loss: 1.3853\n",
      "[1604/1762] D loss: 1.3717\n",
      "[1684/1762] D loss: 1.3840\n",
      "[1762/1762] D loss: 1.3642\n",
      "train error: \n",
      " D loss: 1.380784, D accuracy: 52.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379376, D accuracy: 52.7% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3748\n",
      "[84/1762] D loss: 1.3902\n",
      "[164/1762] D loss: 1.3920\n",
      "[244/1762] D loss: 1.3958\n",
      "[324/1762] D loss: 1.3708\n",
      "[404/1762] D loss: 1.3886\n",
      "[484/1762] D loss: 1.3700\n",
      "[564/1762] D loss: 1.3847\n",
      "[644/1762] D loss: 1.3875\n",
      "[724/1762] D loss: 1.3547\n",
      "[804/1762] D loss: 1.3611\n",
      "[884/1762] D loss: 1.3592\n",
      "[964/1762] D loss: 1.3893\n",
      "[1044/1762] D loss: 1.3870\n",
      "[1124/1762] D loss: 1.3809\n",
      "[1204/1762] D loss: 1.3642\n",
      "[1284/1762] D loss: 1.3872\n",
      "[1364/1762] D loss: 1.3769\n",
      "[1444/1762] D loss: 1.3760\n",
      "[1524/1762] D loss: 1.3894\n",
      "[1604/1762] D loss: 1.3804\n",
      "[1684/1762] D loss: 1.4042\n",
      "[1762/1762] D loss: 1.4128\n",
      "train error: \n",
      " D loss: 1.378878, D accuracy: 52.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377534, D accuracy: 54.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3812\n",
      "[84/1762] D loss: 1.3736\n",
      "[164/1762] D loss: 1.3970\n",
      "[244/1762] D loss: 1.4053\n",
      "[324/1762] D loss: 1.3661\n",
      "[404/1762] D loss: 1.3723\n",
      "[484/1762] D loss: 1.3878\n",
      "[564/1762] D loss: 1.4020\n",
      "[644/1762] D loss: 1.3799\n",
      "[724/1762] D loss: 1.3872\n",
      "[804/1762] D loss: 1.3707\n",
      "[884/1762] D loss: 1.3879\n",
      "[964/1762] D loss: 1.3702\n",
      "[1044/1762] D loss: 1.3763\n",
      "[1124/1762] D loss: 1.3756\n",
      "[1204/1762] D loss: 1.3747\n",
      "[1284/1762] D loss: 1.4005\n",
      "[1364/1762] D loss: 1.3663\n",
      "[1444/1762] D loss: 1.3793\n",
      "[1524/1762] D loss: 1.3824\n",
      "[1604/1762] D loss: 1.3817\n",
      "[1684/1762] D loss: 1.3908\n",
      "[1762/1762] D loss: 1.3936\n",
      "train error: \n",
      " D loss: 1.379070, D accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379349, D accuracy: 53.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3930\n",
      "[84/1762] D loss: 1.3995\n",
      "[164/1762] D loss: 1.3857\n",
      "[244/1762] D loss: 1.3809\n",
      "[324/1762] D loss: 1.3780\n",
      "[404/1762] D loss: 1.3762\n",
      "[484/1762] D loss: 1.3832\n",
      "[564/1762] D loss: 1.3934\n",
      "[644/1762] D loss: 1.3940\n",
      "[724/1762] D loss: 1.3887\n",
      "[804/1762] D loss: 1.3834\n",
      "[884/1762] D loss: 1.3896\n",
      "[964/1762] D loss: 1.3867\n",
      "[1044/1762] D loss: 1.3706\n",
      "[1124/1762] D loss: 1.3829\n",
      "[1204/1762] D loss: 1.3972\n",
      "[1284/1762] D loss: 1.3781\n",
      "[1364/1762] D loss: 1.3768\n",
      "[1444/1762] D loss: 1.3586\n",
      "[1524/1762] D loss: 1.3830\n",
      "[1604/1762] D loss: 1.3730\n",
      "[1684/1762] D loss: 1.3783\n",
      "[1762/1762] D loss: 1.4050\n",
      "train error: \n",
      " D loss: 1.378267, D accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379672, D accuracy: 54.3% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3808\n",
      "[84/1762] D loss: 1.3882\n",
      "[164/1762] D loss: 1.3915\n",
      "[244/1762] D loss: 1.3832\n",
      "[324/1762] D loss: 1.3607\n",
      "[404/1762] D loss: 1.3790\n",
      "[484/1762] D loss: 1.3651\n",
      "[564/1762] D loss: 1.3455\n",
      "[644/1762] D loss: 1.3862\n",
      "[724/1762] D loss: 1.3832\n",
      "[804/1762] D loss: 1.3770\n",
      "[884/1762] D loss: 1.3720\n",
      "[964/1762] D loss: 1.3739\n",
      "[1044/1762] D loss: 1.3798\n",
      "[1124/1762] D loss: 1.3906\n",
      "[1204/1762] D loss: 1.3669\n",
      "[1284/1762] D loss: 1.3877\n",
      "[1364/1762] D loss: 1.3594\n",
      "[1444/1762] D loss: 1.3807\n",
      "[1524/1762] D loss: 1.3850\n",
      "[1604/1762] D loss: 1.3757\n",
      "[1684/1762] D loss: 1.3826\n",
      "[1762/1762] D loss: 1.3961\n",
      "train error: \n",
      " D loss: 1.376578, D accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377098, D accuracy: 54.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3712\n",
      "[84/1762] D loss: 1.3831\n",
      "[164/1762] D loss: 1.3637\n",
      "[244/1762] D loss: 1.3771\n",
      "[324/1762] D loss: 1.3852\n",
      "[404/1762] D loss: 1.3714\n",
      "[484/1762] D loss: 1.3816\n",
      "[564/1762] D loss: 1.3739\n",
      "[644/1762] D loss: 1.3753\n",
      "[724/1762] D loss: 1.3665\n",
      "[804/1762] D loss: 1.3643\n",
      "[884/1762] D loss: 1.3855\n",
      "[964/1762] D loss: 1.3737\n",
      "[1044/1762] D loss: 1.3870\n",
      "[1124/1762] D loss: 1.3635\n",
      "[1204/1762] D loss: 1.3571\n",
      "[1284/1762] D loss: 1.3756\n",
      "[1364/1762] D loss: 1.3595\n",
      "[1444/1762] D loss: 1.3764\n",
      "[1524/1762] D loss: 1.3708\n",
      "[1604/1762] D loss: 1.3587\n",
      "[1684/1762] D loss: 1.3724\n",
      "[1762/1762] D loss: 1.3512\n",
      "train error: \n",
      " D loss: 1.374436, D accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374675, D accuracy: 55.3% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3730\n",
      "[84/1762] D loss: 1.3663\n",
      "[164/1762] D loss: 1.3755\n",
      "[244/1762] D loss: 1.3643\n",
      "[324/1762] D loss: 1.3792\n",
      "[404/1762] D loss: 1.3831\n",
      "[484/1762] D loss: 1.3828\n",
      "[564/1762] D loss: 1.3831\n",
      "[644/1762] D loss: 1.3534\n",
      "[724/1762] D loss: 1.3588\n",
      "[804/1762] D loss: 1.3798\n",
      "[884/1762] D loss: 1.3731\n",
      "[964/1762] D loss: 1.3940\n",
      "[1044/1762] D loss: 1.3892\n",
      "[1124/1762] D loss: 1.3930\n",
      "[1204/1762] D loss: 1.3694\n",
      "[1284/1762] D loss: 1.3756\n",
      "[1364/1762] D loss: 1.3779\n",
      "[1444/1762] D loss: 1.3967\n",
      "[1524/1762] D loss: 1.3789\n",
      "[1604/1762] D loss: 1.3841\n",
      "[1684/1762] D loss: 1.3799\n",
      "[1762/1762] D loss: 1.3747\n",
      "train error: \n",
      " D loss: 1.373063, D accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373550, D accuracy: 56.2% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3724\n",
      "[84/1762] D loss: 1.3916\n",
      "[164/1762] D loss: 1.3940\n",
      "[244/1762] D loss: 1.3580\n",
      "[324/1762] D loss: 1.3819\n",
      "[404/1762] D loss: 1.3974\n",
      "[484/1762] D loss: 1.3847\n",
      "[564/1762] D loss: 1.3781\n",
      "[644/1762] D loss: 1.3895\n",
      "[724/1762] D loss: 1.3890\n",
      "[804/1762] D loss: 1.3608\n",
      "[884/1762] D loss: 1.3760\n",
      "[964/1762] D loss: 1.3930\n",
      "[1044/1762] D loss: 1.3703\n",
      "[1124/1762] D loss: 1.3758\n",
      "[1204/1762] D loss: 1.3892\n",
      "[1284/1762] D loss: 1.3779\n",
      "[1364/1762] D loss: 1.3782\n",
      "[1444/1762] D loss: 1.3810\n",
      "[1524/1762] D loss: 1.3763\n",
      "[1604/1762] D loss: 1.3752\n",
      "[1684/1762] D loss: 1.3704\n",
      "[1762/1762] D loss: 1.3436\n",
      "train error: \n",
      " D loss: 1.371431, D accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370360, D accuracy: 57.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3619\n",
      "[84/1762] D loss: 1.3757\n",
      "[164/1762] D loss: 1.3611\n",
      "[244/1762] D loss: 1.3747\n",
      "[324/1762] D loss: 1.3592\n",
      "[404/1762] D loss: 1.3650\n",
      "[484/1762] D loss: 1.3795\n",
      "[564/1762] D loss: 1.3746\n",
      "[644/1762] D loss: 1.3630\n",
      "[724/1762] D loss: 1.3722\n",
      "[804/1762] D loss: 1.3670\n",
      "[884/1762] D loss: 1.3619\n",
      "[964/1762] D loss: 1.3866\n",
      "[1044/1762] D loss: 1.3670\n",
      "[1124/1762] D loss: 1.3711\n",
      "[1204/1762] D loss: 1.3686\n",
      "[1284/1762] D loss: 1.3725\n",
      "[1364/1762] D loss: 1.3519\n",
      "[1444/1762] D loss: 1.3671\n",
      "[1524/1762] D loss: 1.3912\n",
      "[1604/1762] D loss: 1.3724\n",
      "[1684/1762] D loss: 1.3507\n",
      "[1762/1762] D loss: 1.3801\n",
      "train error: \n",
      " D loss: 1.369786, D accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370778, D accuracy: 58.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3956\n",
      "[84/1762] D loss: 1.3669\n",
      "[164/1762] D loss: 1.3621\n",
      "[244/1762] D loss: 1.3756\n",
      "[324/1762] D loss: 1.3872\n",
      "[404/1762] D loss: 1.3821\n",
      "[484/1762] D loss: 1.3695\n",
      "[564/1762] D loss: 1.3575\n",
      "[644/1762] D loss: 1.3892\n",
      "[724/1762] D loss: 1.3845\n",
      "[804/1762] D loss: 1.3668\n",
      "[884/1762] D loss: 1.3829\n",
      "[964/1762] D loss: 1.3655\n",
      "[1044/1762] D loss: 1.3810\n",
      "[1124/1762] D loss: 1.3597\n",
      "[1204/1762] D loss: 1.3825\n",
      "[1284/1762] D loss: 1.3632\n",
      "[1364/1762] D loss: 1.3740\n",
      "[1444/1762] D loss: 1.3574\n",
      "[1524/1762] D loss: 1.3820\n",
      "[1604/1762] D loss: 1.3917\n",
      "[1684/1762] D loss: 1.3758\n",
      "[1762/1762] D loss: 1.3567\n",
      "train error: \n",
      " D loss: 1.368495, D accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370500, D accuracy: 57.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3463\n",
      "[84/1762] D loss: 1.3658\n",
      "[164/1762] D loss: 1.3856\n",
      "[244/1762] D loss: 1.3630\n",
      "[324/1762] D loss: 1.3572\n",
      "[404/1762] D loss: 1.3820\n",
      "[484/1762] D loss: 1.3567\n",
      "[564/1762] D loss: 1.3814\n",
      "[644/1762] D loss: 1.3599\n",
      "[724/1762] D loss: 1.3747\n",
      "[804/1762] D loss: 1.3676\n",
      "[884/1762] D loss: 1.3682\n",
      "[964/1762] D loss: 1.3618\n",
      "[1044/1762] D loss: 1.3655\n",
      "[1124/1762] D loss: 1.3610\n",
      "[1204/1762] D loss: 1.3800\n",
      "[1284/1762] D loss: 1.3683\n",
      "[1364/1762] D loss: 1.3628\n",
      "[1444/1762] D loss: 1.3748\n",
      "[1524/1762] D loss: 1.3822\n",
      "[1604/1762] D loss: 1.3658\n",
      "[1684/1762] D loss: 1.3773\n",
      "[1762/1762] D loss: 1.3572\n",
      "train error: \n",
      " D loss: 1.364481, D accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366013, D accuracy: 58.1% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3827\n",
      "[84/1762] D loss: 1.3597\n",
      "[164/1762] D loss: 1.3566\n",
      "[244/1762] D loss: 1.3672\n",
      "[324/1762] D loss: 1.3874\n",
      "[404/1762] D loss: 1.3903\n",
      "[484/1762] D loss: 1.3892\n",
      "[564/1762] D loss: 1.3536\n",
      "[644/1762] D loss: 1.3394\n",
      "[724/1762] D loss: 1.3821\n",
      "[804/1762] D loss: 1.3713\n",
      "[884/1762] D loss: 1.3821\n",
      "[964/1762] D loss: 1.3682\n",
      "[1044/1762] D loss: 1.3875\n",
      "[1124/1762] D loss: 1.3453\n",
      "[1204/1762] D loss: 1.3583\n",
      "[1284/1762] D loss: 1.3452\n",
      "[1364/1762] D loss: 1.3763\n",
      "[1444/1762] D loss: 1.3563\n",
      "[1524/1762] D loss: 1.3642\n",
      "[1604/1762] D loss: 1.3634\n",
      "[1684/1762] D loss: 1.3538\n",
      "[1762/1762] D loss: 1.3489\n",
      "train error: \n",
      " D loss: 1.366031, D accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367132, D accuracy: 58.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3506\n",
      "[84/1762] D loss: 1.3674\n",
      "[164/1762] D loss: 1.3570\n",
      "[244/1762] D loss: 1.3495\n",
      "[324/1762] D loss: 1.3588\n",
      "[404/1762] D loss: 1.3589\n",
      "[484/1762] D loss: 1.3528\n",
      "[564/1762] D loss: 1.3918\n",
      "[644/1762] D loss: 1.3719\n",
      "[724/1762] D loss: 1.3883\n",
      "[804/1762] D loss: 1.3735\n",
      "[884/1762] D loss: 1.3707\n",
      "[964/1762] D loss: 1.3667\n",
      "[1044/1762] D loss: 1.3754\n",
      "[1124/1762] D loss: 1.3822\n",
      "[1204/1762] D loss: 1.3758\n",
      "[1284/1762] D loss: 1.3412\n",
      "[1364/1762] D loss: 1.3725\n",
      "[1444/1762] D loss: 1.3947\n",
      "[1524/1762] D loss: 1.3676\n",
      "[1604/1762] D loss: 1.3616\n",
      "[1684/1762] D loss: 1.3678\n",
      "[1762/1762] D loss: 1.3718\n",
      "train error: \n",
      " D loss: 1.363293, D accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366339, D accuracy: 59.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3666\n",
      "[84/1762] D loss: 1.3580\n",
      "[164/1762] D loss: 1.3737\n",
      "[244/1762] D loss: 1.3660\n",
      "[324/1762] D loss: 1.3394\n",
      "[404/1762] D loss: 1.3837\n",
      "[484/1762] D loss: 1.3460\n",
      "[564/1762] D loss: 1.3449\n",
      "[644/1762] D loss: 1.3516\n",
      "[724/1762] D loss: 1.3389\n",
      "[804/1762] D loss: 1.3629\n",
      "[884/1762] D loss: 1.3524\n",
      "[964/1762] D loss: 1.3707\n",
      "[1044/1762] D loss: 1.3687\n",
      "[1124/1762] D loss: 1.3729\n",
      "[1204/1762] D loss: 1.3727\n",
      "[1284/1762] D loss: 1.3690\n",
      "[1364/1762] D loss: 1.3646\n",
      "[1444/1762] D loss: 1.3619\n",
      "[1524/1762] D loss: 1.3560\n",
      "[1604/1762] D loss: 1.3431\n",
      "[1684/1762] D loss: 1.3686\n",
      "[1762/1762] D loss: 1.3901\n",
      "train error: \n",
      " D loss: 1.360988, D accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364075, D accuracy: 59.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3684\n",
      "[84/1762] D loss: 1.3814\n",
      "[164/1762] D loss: 1.3694\n",
      "[244/1762] D loss: 1.3789\n",
      "[324/1762] D loss: 1.3262\n",
      "[404/1762] D loss: 1.3511\n",
      "[484/1762] D loss: 1.3427\n",
      "[564/1762] D loss: 1.3772\n",
      "[644/1762] D loss: 1.3599\n",
      "[724/1762] D loss: 1.3587\n",
      "[804/1762] D loss: 1.4033\n",
      "[884/1762] D loss: 1.3688\n",
      "[964/1762] D loss: 1.3677\n",
      "[1044/1762] D loss: 1.3793\n",
      "[1124/1762] D loss: 1.3480\n",
      "[1204/1762] D loss: 1.3551\n",
      "[1284/1762] D loss: 1.3602\n",
      "[1364/1762] D loss: 1.4050\n",
      "[1444/1762] D loss: 1.3448\n",
      "[1524/1762] D loss: 1.3622\n",
      "[1604/1762] D loss: 1.3600\n",
      "[1684/1762] D loss: 1.3495\n",
      "[1762/1762] D loss: 1.3735\n",
      "train error: \n",
      " D loss: 1.363860, D accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364145, D accuracy: 59.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867\n",
      "[84/1762] D loss: 1.3638\n",
      "[164/1762] D loss: 1.3609\n",
      "[244/1762] D loss: 1.3394\n",
      "[324/1762] D loss: 1.3523\n",
      "[404/1762] D loss: 1.3667\n",
      "[484/1762] D loss: 1.3470\n",
      "[564/1762] D loss: 1.3660\n",
      "[644/1762] D loss: 1.3839\n",
      "[724/1762] D loss: 1.3683\n",
      "[804/1762] D loss: 1.3722\n",
      "[884/1762] D loss: 1.3559\n",
      "[964/1762] D loss: 1.3746\n",
      "[1044/1762] D loss: 1.3635\n",
      "[1124/1762] D loss: 1.3710\n",
      "[1204/1762] D loss: 1.3837\n",
      "[1284/1762] D loss: 1.3736\n",
      "[1364/1762] D loss: 1.3604\n",
      "[1444/1762] D loss: 1.3280\n",
      "[1524/1762] D loss: 1.3369\n",
      "[1604/1762] D loss: 1.3698\n",
      "[1684/1762] D loss: 1.3685\n",
      "[1762/1762] D loss: 1.3467\n",
      "train error: \n",
      " D loss: 1.359183, D accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361700, D accuracy: 61.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3739\n",
      "[84/1762] D loss: 1.3550\n",
      "[164/1762] D loss: 1.3487\n",
      "[244/1762] D loss: 1.3568\n",
      "[324/1762] D loss: 1.3430\n",
      "[404/1762] D loss: 1.3660\n",
      "[484/1762] D loss: 1.3532\n",
      "[564/1762] D loss: 1.3626\n",
      "[644/1762] D loss: 1.3714\n",
      "[724/1762] D loss: 1.3468\n",
      "[804/1762] D loss: 1.3599\n",
      "[884/1762] D loss: 1.3581\n",
      "[964/1762] D loss: 1.3680\n",
      "[1044/1762] D loss: 1.3473\n",
      "[1124/1762] D loss: 1.3393\n",
      "[1204/1762] D loss: 1.3680\n",
      "[1284/1762] D loss: 1.3644\n",
      "[1364/1762] D loss: 1.3416\n",
      "[1444/1762] D loss: 1.3169\n",
      "[1524/1762] D loss: 1.3478\n",
      "[1604/1762] D loss: 1.3561\n",
      "[1684/1762] D loss: 1.3808\n",
      "[1762/1762] D loss: 1.4038\n",
      "train error: \n",
      " D loss: 1.355924, D accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358916, D accuracy: 62.3% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3563\n",
      "[84/1762] D loss: 1.3618\n",
      "[164/1762] D loss: 1.3552\n",
      "[244/1762] D loss: 1.3435\n",
      "[324/1762] D loss: 1.3812\n",
      "[404/1762] D loss: 1.3714\n",
      "[484/1762] D loss: 1.3773\n",
      "[564/1762] D loss: 1.3760\n",
      "[644/1762] D loss: 1.3350\n",
      "[724/1762] D loss: 1.3665\n",
      "[804/1762] D loss: 1.3652\n",
      "[884/1762] D loss: 1.3650\n",
      "[964/1762] D loss: 1.3518\n",
      "[1044/1762] D loss: 1.3839\n",
      "[1124/1762] D loss: 1.3629\n",
      "[1204/1762] D loss: 1.3515\n",
      "[1284/1762] D loss: 1.3204\n",
      "[1364/1762] D loss: 1.3178\n",
      "[1444/1762] D loss: 1.3820\n",
      "[1524/1762] D loss: 1.3248\n",
      "[1604/1762] D loss: 1.3469\n",
      "[1684/1762] D loss: 1.3748\n",
      "[1762/1762] D loss: 1.3489\n",
      "train error: \n",
      " D loss: 1.351294, D accuracy: 61.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352350, D accuracy: 61.9% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4097\n",
      "[84/1762] D loss: 1.4161\n",
      "[164/1762] D loss: 1.4252\n",
      "[244/1762] D loss: 1.3917\n",
      "[324/1762] D loss: 1.4205\n",
      "[404/1762] D loss: 1.4251\n",
      "[484/1762] D loss: 1.4145\n",
      "[564/1762] D loss: 1.4292\n",
      "[644/1762] D loss: 1.4265\n",
      "[724/1762] D loss: 1.4022\n",
      "[804/1762] D loss: 1.4165\n",
      "[884/1762] D loss: 1.3890\n",
      "[964/1762] D loss: 1.3899\n",
      "[1044/1762] D loss: 1.4057\n",
      "[1124/1762] D loss: 1.4228\n",
      "[1204/1762] D loss: 1.4136\n",
      "[1284/1762] D loss: 1.4132\n",
      "[1364/1762] D loss: 1.4330\n",
      "[1444/1762] D loss: 1.4163\n",
      "[1524/1762] D loss: 1.4172\n",
      "[1604/1762] D loss: 1.4260\n",
      "[1684/1762] D loss: 1.4110\n",
      "[1762/1762] D loss: 1.3785\n",
      "train error: \n",
      " D loss: 1.407381, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409007, D accuracy: 50.1% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4248\n",
      "[84/1762] D loss: 1.4232\n",
      "[164/1762] D loss: 1.3775\n",
      "[244/1762] D loss: 1.3906\n",
      "[324/1762] D loss: 1.4151\n",
      "[404/1762] D loss: 1.4065\n",
      "[484/1762] D loss: 1.4024\n",
      "[564/1762] D loss: 1.4191\n",
      "[644/1762] D loss: 1.4153\n",
      "[724/1762] D loss: 1.4103\n",
      "[804/1762] D loss: 1.4173\n",
      "[884/1762] D loss: 1.4106\n",
      "[964/1762] D loss: 1.3964\n",
      "[1044/1762] D loss: 1.4041\n",
      "[1124/1762] D loss: 1.3982\n",
      "[1204/1762] D loss: 1.4116\n",
      "[1284/1762] D loss: 1.4044\n",
      "[1364/1762] D loss: 1.4035\n",
      "[1444/1762] D loss: 1.4156\n",
      "[1524/1762] D loss: 1.3901\n",
      "[1604/1762] D loss: 1.3990\n",
      "[1684/1762] D loss: 1.4138\n",
      "[1762/1762] D loss: 1.3698\n",
      "train error: \n",
      " D loss: 1.405413, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404452, D accuracy: 50.1% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3939\n",
      "[84/1762] D loss: 1.3794\n",
      "[164/1762] D loss: 1.4111\n",
      "[244/1762] D loss: 1.4077\n",
      "[324/1762] D loss: 1.3890\n",
      "[404/1762] D loss: 1.3961\n",
      "[484/1762] D loss: 1.3983\n",
      "[564/1762] D loss: 1.3860\n",
      "[644/1762] D loss: 1.4188\n",
      "[724/1762] D loss: 1.3977\n",
      "[804/1762] D loss: 1.4027\n",
      "[884/1762] D loss: 1.3902\n",
      "[964/1762] D loss: 1.4036\n",
      "[1044/1762] D loss: 1.4204\n",
      "[1124/1762] D loss: 1.4151\n",
      "[1204/1762] D loss: 1.4439\n",
      "[1284/1762] D loss: 1.4159\n",
      "[1364/1762] D loss: 1.3797\n",
      "[1444/1762] D loss: 1.4176\n",
      "[1524/1762] D loss: 1.4224\n",
      "[1604/1762] D loss: 1.4144\n",
      "[1684/1762] D loss: 1.4175\n",
      "[1762/1762] D loss: 1.3845\n",
      "train error: \n",
      " D loss: 1.403928, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402717, D accuracy: 50.2% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4241\n",
      "[84/1762] D loss: 1.4015\n",
      "[164/1762] D loss: 1.4194\n",
      "[244/1762] D loss: 1.3986\n",
      "[324/1762] D loss: 1.4040\n",
      "[404/1762] D loss: 1.4130\n",
      "[484/1762] D loss: 1.3982\n",
      "[564/1762] D loss: 1.3877\n",
      "[644/1762] D loss: 1.4274\n",
      "[724/1762] D loss: 1.3807\n",
      "[804/1762] D loss: 1.3875\n",
      "[884/1762] D loss: 1.4173\n",
      "[964/1762] D loss: 1.3900\n",
      "[1044/1762] D loss: 1.4285\n",
      "[1124/1762] D loss: 1.3871\n",
      "[1204/1762] D loss: 1.4005\n",
      "[1284/1762] D loss: 1.3948\n",
      "[1364/1762] D loss: 1.4018\n",
      "[1444/1762] D loss: 1.3814\n",
      "[1524/1762] D loss: 1.3972\n",
      "[1604/1762] D loss: 1.4044\n",
      "[1684/1762] D loss: 1.4202\n",
      "[1762/1762] D loss: 1.4098\n",
      "train error: \n",
      " D loss: 1.400538, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401301, D accuracy: 49.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3990\n",
      "[84/1762] D loss: 1.4217\n",
      "[164/1762] D loss: 1.3926\n",
      "[244/1762] D loss: 1.3958\n",
      "[324/1762] D loss: 1.3975\n",
      "[404/1762] D loss: 1.4213\n",
      "[484/1762] D loss: 1.4168\n",
      "[564/1762] D loss: 1.3927\n",
      "[644/1762] D loss: 1.4103\n",
      "[724/1762] D loss: 1.4008\n",
      "[804/1762] D loss: 1.3998\n",
      "[884/1762] D loss: 1.4089\n",
      "[964/1762] D loss: 1.3786\n",
      "[1044/1762] D loss: 1.3941\n",
      "[1124/1762] D loss: 1.4155\n",
      "[1204/1762] D loss: 1.3858\n",
      "[1284/1762] D loss: 1.4145\n",
      "[1364/1762] D loss: 1.3874\n",
      "[1444/1762] D loss: 1.4017\n",
      "[1524/1762] D loss: 1.4087\n",
      "[1604/1762] D loss: 1.3801\n",
      "[1684/1762] D loss: 1.3792\n",
      "[1762/1762] D loss: 1.4027\n",
      "train error: \n",
      " D loss: 1.398605, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397761, D accuracy: 49.9% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4016\n",
      "[84/1762] D loss: 1.3948\n",
      "[164/1762] D loss: 1.4068\n",
      "[244/1762] D loss: 1.4263\n",
      "[324/1762] D loss: 1.3951\n",
      "[404/1762] D loss: 1.3955\n",
      "[484/1762] D loss: 1.3915\n",
      "[564/1762] D loss: 1.4030\n",
      "[644/1762] D loss: 1.4149\n",
      "[724/1762] D loss: 1.4043\n",
      "[804/1762] D loss: 1.4025\n",
      "[884/1762] D loss: 1.4139\n",
      "[964/1762] D loss: 1.4041\n",
      "[1044/1762] D loss: 1.4121\n",
      "[1124/1762] D loss: 1.4017\n",
      "[1204/1762] D loss: 1.3912\n",
      "[1284/1762] D loss: 1.4058\n",
      "[1364/1762] D loss: 1.3792\n",
      "[1444/1762] D loss: 1.4102\n",
      "[1524/1762] D loss: 1.3956\n",
      "[1604/1762] D loss: 1.3931\n",
      "[1684/1762] D loss: 1.3855\n",
      "[1762/1762] D loss: 1.3933\n",
      "train error: \n",
      " D loss: 1.398749, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399016, D accuracy: 50.3% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4030\n",
      "[84/1762] D loss: 1.3950\n",
      "[164/1762] D loss: 1.4080\n",
      "[244/1762] D loss: 1.4072\n",
      "[324/1762] D loss: 1.4086\n",
      "[404/1762] D loss: 1.4070\n",
      "[484/1762] D loss: 1.4338\n",
      "[564/1762] D loss: 1.3897\n",
      "[644/1762] D loss: 1.4049\n",
      "[724/1762] D loss: 1.3995\n",
      "[804/1762] D loss: 1.4160\n",
      "[884/1762] D loss: 1.3992\n",
      "[964/1762] D loss: 1.4035\n",
      "[1044/1762] D loss: 1.3886\n",
      "[1124/1762] D loss: 1.3919\n",
      "[1204/1762] D loss: 1.4062\n",
      "[1284/1762] D loss: 1.4090\n",
      "[1364/1762] D loss: 1.3865\n",
      "[1444/1762] D loss: 1.3947\n",
      "[1524/1762] D loss: 1.4150\n",
      "[1604/1762] D loss: 1.4033\n",
      "[1684/1762] D loss: 1.3654\n",
      "[1762/1762] D loss: 1.4098\n",
      "train error: \n",
      " D loss: 1.397157, D accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396230, D accuracy: 50.6% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4182\n",
      "[84/1762] D loss: 1.4049\n",
      "[164/1762] D loss: 1.3901\n",
      "[244/1762] D loss: 1.4024\n",
      "[324/1762] D loss: 1.4017\n",
      "[404/1762] D loss: 1.4302\n",
      "[484/1762] D loss: 1.3868\n",
      "[564/1762] D loss: 1.3854\n",
      "[644/1762] D loss: 1.4100\n",
      "[724/1762] D loss: 1.3882\n",
      "[804/1762] D loss: 1.3998\n",
      "[884/1762] D loss: 1.4051\n",
      "[964/1762] D loss: 1.3805\n",
      "[1044/1762] D loss: 1.4237\n",
      "[1124/1762] D loss: 1.4145\n",
      "[1204/1762] D loss: 1.4069\n",
      "[1284/1762] D loss: 1.4026\n",
      "[1364/1762] D loss: 1.4042\n",
      "[1444/1762] D loss: 1.3876\n",
      "[1524/1762] D loss: 1.3901\n",
      "[1604/1762] D loss: 1.3875\n",
      "[1684/1762] D loss: 1.4014\n",
      "[1762/1762] D loss: 1.4014\n",
      "train error: \n",
      " D loss: 1.395869, D accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395953, D accuracy: 50.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4095\n",
      "[84/1762] D loss: 1.3963\n",
      "[164/1762] D loss: 1.3773\n",
      "[244/1762] D loss: 1.3994\n",
      "[324/1762] D loss: 1.3946\n",
      "[404/1762] D loss: 1.4011\n",
      "[484/1762] D loss: 1.4123\n",
      "[564/1762] D loss: 1.3771\n",
      "[644/1762] D loss: 1.3856\n",
      "[724/1762] D loss: 1.3898\n",
      "[804/1762] D loss: 1.3809\n",
      "[884/1762] D loss: 1.3909\n",
      "[964/1762] D loss: 1.3922\n",
      "[1044/1762] D loss: 1.4105\n",
      "[1124/1762] D loss: 1.3713\n",
      "[1204/1762] D loss: 1.4042\n",
      "[1284/1762] D loss: 1.3948\n",
      "[1364/1762] D loss: 1.4148\n",
      "[1444/1762] D loss: 1.4014\n",
      "[1524/1762] D loss: 1.3993\n",
      "[1604/1762] D loss: 1.4006\n",
      "[1684/1762] D loss: 1.3907\n",
      "[1762/1762] D loss: 1.3849\n",
      "train error: \n",
      " D loss: 1.395935, D accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396781, D accuracy: 50.3% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3987\n",
      "[84/1762] D loss: 1.3612\n",
      "[164/1762] D loss: 1.3800\n",
      "[244/1762] D loss: 1.4002\n",
      "[324/1762] D loss: 1.3902\n",
      "[404/1762] D loss: 1.3766\n",
      "[484/1762] D loss: 1.3987\n",
      "[564/1762] D loss: 1.4055\n",
      "[644/1762] D loss: 1.3944\n",
      "[724/1762] D loss: 1.4237\n",
      "[804/1762] D loss: 1.4096\n",
      "[884/1762] D loss: 1.4043\n",
      "[964/1762] D loss: 1.4187\n",
      "[1044/1762] D loss: 1.4076\n",
      "[1124/1762] D loss: 1.4227\n",
      "[1204/1762] D loss: 1.4059\n",
      "[1284/1762] D loss: 1.3938\n",
      "[1364/1762] D loss: 1.4102\n",
      "[1444/1762] D loss: 1.4115\n",
      "[1524/1762] D loss: 1.3965\n",
      "[1604/1762] D loss: 1.3914\n",
      "[1684/1762] D loss: 1.3888\n",
      "[1762/1762] D loss: 1.4230\n",
      "train error: \n",
      " D loss: 1.394204, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392958, D accuracy: 50.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4126\n",
      "[84/1762] D loss: 1.4134\n",
      "[164/1762] D loss: 1.3942\n",
      "[244/1762] D loss: 1.3855\n",
      "[324/1762] D loss: 1.3941\n",
      "[404/1762] D loss: 1.4080\n",
      "[484/1762] D loss: 1.4050\n",
      "[564/1762] D loss: 1.3895\n",
      "[644/1762] D loss: 1.3901\n",
      "[724/1762] D loss: 1.3894\n",
      "[804/1762] D loss: 1.3907\n",
      "[884/1762] D loss: 1.4133\n",
      "[964/1762] D loss: 1.4038\n",
      "[1044/1762] D loss: 1.3823\n",
      "[1124/1762] D loss: 1.4272\n",
      "[1204/1762] D loss: 1.3681\n",
      "[1284/1762] D loss: 1.3776\n",
      "[1364/1762] D loss: 1.4146\n",
      "[1444/1762] D loss: 1.3729\n",
      "[1524/1762] D loss: 1.3950\n",
      "[1604/1762] D loss: 1.3848\n",
      "[1684/1762] D loss: 1.3980\n",
      "[1762/1762] D loss: 1.3925\n",
      "train error: \n",
      " D loss: 1.393225, D accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394188, D accuracy: 50.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4014\n",
      "[84/1762] D loss: 1.3869\n",
      "[164/1762] D loss: 1.3956\n",
      "[244/1762] D loss: 1.3995\n",
      "[324/1762] D loss: 1.4039\n",
      "[404/1762] D loss: 1.3943\n",
      "[484/1762] D loss: 1.3781\n",
      "[564/1762] D loss: 1.3827\n",
      "[644/1762] D loss: 1.4048\n",
      "[724/1762] D loss: 1.3819\n",
      "[804/1762] D loss: 1.3887\n",
      "[884/1762] D loss: 1.3857\n",
      "[964/1762] D loss: 1.3884\n",
      "[1044/1762] D loss: 1.4004\n",
      "[1124/1762] D loss: 1.3824\n",
      "[1204/1762] D loss: 1.3844\n",
      "[1284/1762] D loss: 1.4027\n",
      "[1364/1762] D loss: 1.3807\n",
      "[1444/1762] D loss: 1.3931\n",
      "[1524/1762] D loss: 1.4017\n",
      "[1604/1762] D loss: 1.3976\n",
      "[1684/1762] D loss: 1.4048\n",
      "[1762/1762] D loss: 1.3936\n",
      "train error: \n",
      " D loss: 1.391517, D accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391273, D accuracy: 50.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3800\n",
      "[84/1762] D loss: 1.4034\n",
      "[164/1762] D loss: 1.3921\n",
      "[244/1762] D loss: 1.3777\n",
      "[324/1762] D loss: 1.4128\n",
      "[404/1762] D loss: 1.3840\n",
      "[484/1762] D loss: 1.4117\n",
      "[564/1762] D loss: 1.3880\n",
      "[644/1762] D loss: 1.3904\n",
      "[724/1762] D loss: 1.3810\n",
      "[804/1762] D loss: 1.3822\n",
      "[884/1762] D loss: 1.4151\n",
      "[964/1762] D loss: 1.3968\n",
      "[1044/1762] D loss: 1.4007\n",
      "[1124/1762] D loss: 1.3920\n",
      "[1204/1762] D loss: 1.4134\n",
      "[1284/1762] D loss: 1.3888\n",
      "[1364/1762] D loss: 1.3952\n",
      "[1444/1762] D loss: 1.3929\n",
      "[1524/1762] D loss: 1.3987\n",
      "[1604/1762] D loss: 1.3693\n",
      "[1684/1762] D loss: 1.4047\n",
      "[1762/1762] D loss: 1.3892\n",
      "train error: \n",
      " D loss: 1.391126, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392131, D accuracy: 51.1% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4150\n",
      "[84/1762] D loss: 1.3966\n",
      "[164/1762] D loss: 1.4035\n",
      "[244/1762] D loss: 1.3818\n",
      "[324/1762] D loss: 1.3927\n",
      "[404/1762] D loss: 1.4066\n",
      "[484/1762] D loss: 1.3890\n",
      "[564/1762] D loss: 1.3841\n",
      "[644/1762] D loss: 1.4016\n",
      "[724/1762] D loss: 1.3947\n",
      "[804/1762] D loss: 1.3801\n",
      "[884/1762] D loss: 1.3971\n",
      "[964/1762] D loss: 1.4123\n",
      "[1044/1762] D loss: 1.3978\n",
      "[1124/1762] D loss: 1.3976\n",
      "[1204/1762] D loss: 1.3944\n",
      "[1284/1762] D loss: 1.3803\n",
      "[1364/1762] D loss: 1.3990\n",
      "[1444/1762] D loss: 1.4159\n",
      "[1524/1762] D loss: 1.3883\n",
      "[1604/1762] D loss: 1.4000\n",
      "[1684/1762] D loss: 1.3978\n",
      "[1762/1762] D loss: 1.3895\n",
      "train error: \n",
      " D loss: 1.390094, D accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390268, D accuracy: 50.8% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872\n",
      "[84/1762] D loss: 1.3863\n",
      "[164/1762] D loss: 1.3970\n",
      "[244/1762] D loss: 1.3888\n",
      "[324/1762] D loss: 1.3844\n",
      "[404/1762] D loss: 1.3901\n",
      "[484/1762] D loss: 1.3980\n",
      "[564/1762] D loss: 1.4056\n",
      "[644/1762] D loss: 1.3936\n",
      "[724/1762] D loss: 1.3943\n",
      "[804/1762] D loss: 1.4086\n",
      "[884/1762] D loss: 1.3813\n",
      "[964/1762] D loss: 1.3748\n",
      "[1044/1762] D loss: 1.3954\n",
      "[1124/1762] D loss: 1.3906\n",
      "[1204/1762] D loss: 1.3857\n",
      "[1284/1762] D loss: 1.3820\n",
      "[1364/1762] D loss: 1.3782\n",
      "[1444/1762] D loss: 1.3971\n",
      "[1524/1762] D loss: 1.3980\n",
      "[1604/1762] D loss: 1.3901\n",
      "[1684/1762] D loss: 1.4006\n",
      "[1762/1762] D loss: 1.3970\n",
      "train error: \n",
      " D loss: 1.390043, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390185, D accuracy: 51.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904\n",
      "[84/1762] D loss: 1.3895\n",
      "[164/1762] D loss: 1.3786\n",
      "[244/1762] D loss: 1.3930\n",
      "[324/1762] D loss: 1.3931\n",
      "[404/1762] D loss: 1.3797\n",
      "[484/1762] D loss: 1.4017\n",
      "[564/1762] D loss: 1.4100\n",
      "[644/1762] D loss: 1.4100\n",
      "[724/1762] D loss: 1.3912\n",
      "[804/1762] D loss: 1.3938\n",
      "[884/1762] D loss: 1.4023\n",
      "[964/1762] D loss: 1.4133\n",
      "[1044/1762] D loss: 1.3970\n",
      "[1124/1762] D loss: 1.4008\n",
      "[1204/1762] D loss: 1.3871\n",
      "[1284/1762] D loss: 1.3794\n",
      "[1364/1762] D loss: 1.3822\n",
      "[1444/1762] D loss: 1.3790\n",
      "[1524/1762] D loss: 1.3964\n",
      "[1604/1762] D loss: 1.3979\n",
      "[1684/1762] D loss: 1.3744\n",
      "[1762/1762] D loss: 1.4043\n",
      "train error: \n",
      " D loss: 1.389007, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388107, D accuracy: 51.1% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886\n",
      "[84/1762] D loss: 1.3965\n",
      "[164/1762] D loss: 1.3890\n",
      "[244/1762] D loss: 1.3939\n",
      "[324/1762] D loss: 1.4038\n",
      "[404/1762] D loss: 1.3671\n",
      "[484/1762] D loss: 1.3923\n",
      "[564/1762] D loss: 1.3935\n",
      "[644/1762] D loss: 1.4038\n",
      "[724/1762] D loss: 1.4034\n",
      "[804/1762] D loss: 1.3879\n",
      "[884/1762] D loss: 1.3901\n",
      "[964/1762] D loss: 1.3711\n",
      "[1044/1762] D loss: 1.4000\n",
      "[1124/1762] D loss: 1.3792\n",
      "[1204/1762] D loss: 1.3839\n",
      "[1284/1762] D loss: 1.3993\n",
      "[1364/1762] D loss: 1.3937\n",
      "[1444/1762] D loss: 1.3862\n",
      "[1524/1762] D loss: 1.3675\n",
      "[1604/1762] D loss: 1.3871\n",
      "[1684/1762] D loss: 1.3742\n",
      "[1762/1762] D loss: 1.4075\n",
      "train error: \n",
      " D loss: 1.388077, D accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388651, D accuracy: 51.4% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3759\n",
      "[84/1762] D loss: 1.3919\n",
      "[164/1762] D loss: 1.3780\n",
      "[244/1762] D loss: 1.3860\n",
      "[324/1762] D loss: 1.4007\n",
      "[404/1762] D loss: 1.3927\n",
      "[484/1762] D loss: 1.3818\n",
      "[564/1762] D loss: 1.3784\n",
      "[644/1762] D loss: 1.3909\n",
      "[724/1762] D loss: 1.4036\n",
      "[804/1762] D loss: 1.4040\n",
      "[884/1762] D loss: 1.3943\n",
      "[964/1762] D loss: 1.4024\n",
      "[1044/1762] D loss: 1.3958\n",
      "[1124/1762] D loss: 1.4050\n",
      "[1204/1762] D loss: 1.3789\n",
      "[1284/1762] D loss: 1.3954\n",
      "[1364/1762] D loss: 1.3848\n",
      "[1444/1762] D loss: 1.4066\n",
      "[1524/1762] D loss: 1.3861\n",
      "[1604/1762] D loss: 1.3752\n",
      "[1684/1762] D loss: 1.4050\n",
      "[1762/1762] D loss: 1.3971\n",
      "train error: \n",
      " D loss: 1.387944, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387267, D accuracy: 51.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951\n",
      "[84/1762] D loss: 1.3904\n",
      "[164/1762] D loss: 1.4208\n",
      "[244/1762] D loss: 1.3995\n",
      "[324/1762] D loss: 1.3881\n",
      "[404/1762] D loss: 1.3816\n",
      "[484/1762] D loss: 1.3954\n",
      "[564/1762] D loss: 1.3762\n",
      "[644/1762] D loss: 1.3829\n",
      "[724/1762] D loss: 1.3821\n",
      "[804/1762] D loss: 1.3828\n",
      "[884/1762] D loss: 1.3877\n",
      "[964/1762] D loss: 1.3728\n",
      "[1044/1762] D loss: 1.3953\n",
      "[1124/1762] D loss: 1.3847\n",
      "[1204/1762] D loss: 1.4057\n",
      "[1284/1762] D loss: 1.3878\n",
      "[1364/1762] D loss: 1.4045\n",
      "[1444/1762] D loss: 1.4048\n",
      "[1524/1762] D loss: 1.3905\n",
      "[1604/1762] D loss: 1.3930\n",
      "[1684/1762] D loss: 1.3848\n",
      "[1762/1762] D loss: 1.3916\n",
      "train error: \n",
      " D loss: 1.386413, D accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384338, D accuracy: 51.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3779\n",
      "[84/1762] D loss: 1.3923\n",
      "[164/1762] D loss: 1.3864\n",
      "[244/1762] D loss: 1.3996\n",
      "[324/1762] D loss: 1.3962\n",
      "[404/1762] D loss: 1.3840\n",
      "[484/1762] D loss: 1.3953\n",
      "[564/1762] D loss: 1.4134\n",
      "[644/1762] D loss: 1.3714\n",
      "[724/1762] D loss: 1.3935\n",
      "[804/1762] D loss: 1.3861\n",
      "[884/1762] D loss: 1.4046\n",
      "[964/1762] D loss: 1.3698\n",
      "[1044/1762] D loss: 1.3834\n",
      "[1124/1762] D loss: 1.3604\n",
      "[1204/1762] D loss: 1.4013\n",
      "[1284/1762] D loss: 1.3685\n",
      "[1364/1762] D loss: 1.3890\n",
      "[1444/1762] D loss: 1.3732\n",
      "[1524/1762] D loss: 1.3906\n",
      "[1604/1762] D loss: 1.3970\n",
      "[1684/1762] D loss: 1.4167\n",
      "[1762/1762] D loss: 1.4332\n",
      "train error: \n",
      " D loss: 1.386364, D accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386031, D accuracy: 50.6% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3981\n",
      "[84/1762] D loss: 1.3935\n",
      "[164/1762] D loss: 1.4032\n",
      "[244/1762] D loss: 1.3767\n",
      "[324/1762] D loss: 1.4138\n",
      "[404/1762] D loss: 1.3895\n",
      "[484/1762] D loss: 1.4122\n",
      "[564/1762] D loss: 1.3797\n",
      "[644/1762] D loss: 1.3939\n",
      "[724/1762] D loss: 1.4003\n",
      "[804/1762] D loss: 1.4107\n",
      "[884/1762] D loss: 1.3817\n",
      "[964/1762] D loss: 1.3943\n",
      "[1044/1762] D loss: 1.4221\n",
      "[1124/1762] D loss: 1.4002\n",
      "[1204/1762] D loss: 1.4094\n",
      "[1284/1762] D loss: 1.4094\n",
      "[1364/1762] D loss: 1.3990\n",
      "[1444/1762] D loss: 1.4017\n",
      "[1524/1762] D loss: 1.3906\n",
      "[1604/1762] D loss: 1.4147\n",
      "[1684/1762] D loss: 1.3827\n",
      "[1762/1762] D loss: 1.4306\n",
      "train error: \n",
      " D loss: 1.393175, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394394, D accuracy: 50.3% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927\n",
      "[84/1762] D loss: 1.3939\n",
      "[164/1762] D loss: 1.3938\n",
      "[244/1762] D loss: 1.4229\n",
      "[324/1762] D loss: 1.3862\n",
      "[404/1762] D loss: 1.3826\n",
      "[484/1762] D loss: 1.4029\n",
      "[564/1762] D loss: 1.4110\n",
      "[644/1762] D loss: 1.3988\n",
      "[724/1762] D loss: 1.3863\n",
      "[804/1762] D loss: 1.4060\n",
      "[884/1762] D loss: 1.3969\n",
      "[964/1762] D loss: 1.4110\n",
      "[1044/1762] D loss: 1.3937\n",
      "[1124/1762] D loss: 1.4089\n",
      "[1204/1762] D loss: 1.4104\n",
      "[1284/1762] D loss: 1.4212\n",
      "[1364/1762] D loss: 1.3922\n",
      "[1444/1762] D loss: 1.4115\n",
      "[1524/1762] D loss: 1.3771\n",
      "[1604/1762] D loss: 1.4036\n",
      "[1684/1762] D loss: 1.4037\n",
      "[1762/1762] D loss: 1.4251\n",
      "train error: \n",
      " D loss: 1.395261, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395234, D accuracy: 49.7% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4041\n",
      "[84/1762] D loss: 1.3919\n",
      "[164/1762] D loss: 1.3893\n",
      "[244/1762] D loss: 1.3802\n",
      "[324/1762] D loss: 1.4053\n",
      "[404/1762] D loss: 1.4104\n",
      "[484/1762] D loss: 1.3925\n",
      "[564/1762] D loss: 1.3939\n",
      "[644/1762] D loss: 1.4190\n",
      "[724/1762] D loss: 1.4225\n",
      "[804/1762] D loss: 1.3960\n",
      "[884/1762] D loss: 1.3805\n",
      "[964/1762] D loss: 1.3881\n",
      "[1044/1762] D loss: 1.3967\n",
      "[1124/1762] D loss: 1.3885\n",
      "[1204/1762] D loss: 1.3913\n",
      "[1284/1762] D loss: 1.3850\n",
      "[1364/1762] D loss: 1.3989\n",
      "[1444/1762] D loss: 1.3975\n",
      "[1524/1762] D loss: 1.3966\n",
      "[1604/1762] D loss: 1.4007\n",
      "[1684/1762] D loss: 1.3976\n",
      "[1762/1762] D loss: 1.4007\n",
      "train error: \n",
      " D loss: 1.393661, D accuracy: 49.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395747, D accuracy: 50.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4212\n",
      "[84/1762] D loss: 1.3778\n",
      "[164/1762] D loss: 1.3987\n",
      "[244/1762] D loss: 1.4051\n",
      "[324/1762] D loss: 1.3964\n",
      "[404/1762] D loss: 1.4188\n",
      "[484/1762] D loss: 1.3842\n",
      "[564/1762] D loss: 1.3968\n",
      "[644/1762] D loss: 1.4080\n",
      "[724/1762] D loss: 1.4376\n",
      "[804/1762] D loss: 1.4171\n",
      "[884/1762] D loss: 1.4230\n",
      "[964/1762] D loss: 1.3948\n",
      "[1044/1762] D loss: 1.3890\n",
      "[1124/1762] D loss: 1.3975\n",
      "[1204/1762] D loss: 1.3999\n",
      "[1284/1762] D loss: 1.4027\n",
      "[1364/1762] D loss: 1.3850\n",
      "[1444/1762] D loss: 1.3867\n",
      "[1524/1762] D loss: 1.4024\n",
      "[1604/1762] D loss: 1.4112\n",
      "[1684/1762] D loss: 1.4104\n",
      "[1762/1762] D loss: 1.4197\n",
      "train error: \n",
      " D loss: 1.394675, D accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395650, D accuracy: 49.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3937\n",
      "[84/1762] D loss: 1.4161\n",
      "[164/1762] D loss: 1.4064\n",
      "[244/1762] D loss: 1.3746\n",
      "[324/1762] D loss: 1.3975\n",
      "[404/1762] D loss: 1.3904\n",
      "[484/1762] D loss: 1.3924\n",
      "[564/1762] D loss: 1.4209\n",
      "[644/1762] D loss: 1.3962\n",
      "[724/1762] D loss: 1.3755\n",
      "[804/1762] D loss: 1.3853\n",
      "[884/1762] D loss: 1.3964\n",
      "[964/1762] D loss: 1.4026\n",
      "[1044/1762] D loss: 1.3577\n",
      "[1124/1762] D loss: 1.3879\n",
      "[1204/1762] D loss: 1.4082\n",
      "[1284/1762] D loss: 1.3965\n",
      "[1364/1762] D loss: 1.4130\n",
      "[1444/1762] D loss: 1.4073\n",
      "[1524/1762] D loss: 1.3931\n",
      "[1604/1762] D loss: 1.3978\n",
      "[1684/1762] D loss: 1.4033\n",
      "[1762/1762] D loss: 1.3935\n",
      "train error: \n",
      " D loss: 1.393903, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393497, D accuracy: 50.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3937\n",
      "[84/1762] D loss: 1.4068\n",
      "[164/1762] D loss: 1.4079\n",
      "[244/1762] D loss: 1.3919\n",
      "[324/1762] D loss: 1.3960\n",
      "[404/1762] D loss: 1.3909\n",
      "[484/1762] D loss: 1.3998\n",
      "[564/1762] D loss: 1.3906\n",
      "[644/1762] D loss: 1.4042\n",
      "[724/1762] D loss: 1.3990\n",
      "[804/1762] D loss: 1.4381\n",
      "[884/1762] D loss: 1.4173\n",
      "[964/1762] D loss: 1.3925\n",
      "[1044/1762] D loss: 1.3890\n",
      "[1124/1762] D loss: 1.3979\n",
      "[1204/1762] D loss: 1.4095\n",
      "[1284/1762] D loss: 1.3992\n",
      "[1364/1762] D loss: 1.3926\n",
      "[1444/1762] D loss: 1.3953\n",
      "[1524/1762] D loss: 1.3971\n",
      "[1604/1762] D loss: 1.3907\n",
      "[1684/1762] D loss: 1.3974\n",
      "[1762/1762] D loss: 1.3990\n",
      "train error: \n",
      " D loss: 1.393059, D accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393279, D accuracy: 50.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909\n",
      "[84/1762] D loss: 1.4015\n",
      "[164/1762] D loss: 1.4084\n",
      "[244/1762] D loss: 1.4025\n",
      "[324/1762] D loss: 1.4033\n",
      "[404/1762] D loss: 1.4138\n",
      "[484/1762] D loss: 1.3961\n",
      "[564/1762] D loss: 1.3895\n",
      "[644/1762] D loss: 1.4008\n",
      "[724/1762] D loss: 1.3973\n",
      "[804/1762] D loss: 1.3931\n",
      "[884/1762] D loss: 1.3831\n",
      "[964/1762] D loss: 1.3923\n",
      "[1044/1762] D loss: 1.4152\n",
      "[1124/1762] D loss: 1.4166\n",
      "[1204/1762] D loss: 1.3661\n",
      "[1284/1762] D loss: 1.4031\n",
      "[1364/1762] D loss: 1.4095\n",
      "[1444/1762] D loss: 1.4169\n",
      "[1524/1762] D loss: 1.4014\n",
      "[1604/1762] D loss: 1.4094\n",
      "[1684/1762] D loss: 1.4483\n",
      "[1762/1762] D loss: 1.3913\n",
      "train error: \n",
      " D loss: 1.392610, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394822, D accuracy: 50.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915\n",
      "[84/1762] D loss: 1.4105\n",
      "[164/1762] D loss: 1.4029\n",
      "[244/1762] D loss: 1.3969\n",
      "[324/1762] D loss: 1.4202\n",
      "[404/1762] D loss: 1.3657\n",
      "[484/1762] D loss: 1.4053\n",
      "[564/1762] D loss: 1.3812\n",
      "[644/1762] D loss: 1.3865\n",
      "[724/1762] D loss: 1.3714\n",
      "[804/1762] D loss: 1.3972\n",
      "[884/1762] D loss: 1.3983\n",
      "[964/1762] D loss: 1.4021\n",
      "[1044/1762] D loss: 1.3757\n",
      "[1124/1762] D loss: 1.4111\n",
      "[1204/1762] D loss: 1.4136\n",
      "[1284/1762] D loss: 1.4162\n",
      "[1364/1762] D loss: 1.3795\n",
      "[1444/1762] D loss: 1.4171\n",
      "[1524/1762] D loss: 1.3996\n",
      "[1604/1762] D loss: 1.3771\n",
      "[1684/1762] D loss: 1.4044\n",
      "[1762/1762] D loss: 1.3887\n",
      "train error: \n",
      " D loss: 1.394663, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393759, D accuracy: 50.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915\n",
      "[84/1762] D loss: 1.3932\n",
      "[164/1762] D loss: 1.4169\n",
      "[244/1762] D loss: 1.4166\n",
      "[324/1762] D loss: 1.3929\n",
      "[404/1762] D loss: 1.4196\n",
      "[484/1762] D loss: 1.4006\n",
      "[564/1762] D loss: 1.4039\n",
      "[644/1762] D loss: 1.4041\n",
      "[724/1762] D loss: 1.3841\n",
      "[804/1762] D loss: 1.3938\n",
      "[884/1762] D loss: 1.4058\n",
      "[964/1762] D loss: 1.4083\n",
      "[1044/1762] D loss: 1.4002\n",
      "[1124/1762] D loss: 1.4127\n",
      "[1204/1762] D loss: 1.4287\n",
      "[1284/1762] D loss: 1.3875\n",
      "[1364/1762] D loss: 1.4202\n",
      "[1444/1762] D loss: 1.3955\n",
      "[1524/1762] D loss: 1.3915\n",
      "[1604/1762] D loss: 1.3940\n",
      "[1684/1762] D loss: 1.4005\n",
      "[1762/1762] D loss: 1.4117\n",
      "train error: \n",
      " D loss: 1.392961, D accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395163, D accuracy: 50.1% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860\n",
      "[84/1762] D loss: 1.3969\n",
      "[164/1762] D loss: 1.4022\n",
      "[244/1762] D loss: 1.4010\n",
      "[324/1762] D loss: 1.4126\n",
      "[404/1762] D loss: 1.3603\n",
      "[484/1762] D loss: 1.3951\n",
      "[564/1762] D loss: 1.3830\n",
      "[644/1762] D loss: 1.4052\n",
      "[724/1762] D loss: 1.4041\n",
      "[804/1762] D loss: 1.4024\n",
      "[884/1762] D loss: 1.4097\n",
      "[964/1762] D loss: 1.3992\n",
      "[1044/1762] D loss: 1.3771\n",
      "[1124/1762] D loss: 1.3996\n",
      "[1204/1762] D loss: 1.4100\n",
      "[1284/1762] D loss: 1.4101\n",
      "[1364/1762] D loss: 1.4069\n",
      "[1444/1762] D loss: 1.3983\n",
      "[1524/1762] D loss: 1.4065\n",
      "[1604/1762] D loss: 1.3858\n",
      "[1684/1762] D loss: 1.3992\n",
      "[1762/1762] D loss: 1.3861\n",
      "train error: \n",
      " D loss: 1.393343, D accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396246, D accuracy: 49.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962\n",
      "[84/1762] D loss: 1.4105\n",
      "[164/1762] D loss: 1.4121\n",
      "[244/1762] D loss: 1.3997\n",
      "[324/1762] D loss: 1.3798\n",
      "[404/1762] D loss: 1.4188\n",
      "[484/1762] D loss: 1.3999\n",
      "[564/1762] D loss: 1.4145\n",
      "[644/1762] D loss: 1.4088\n",
      "[724/1762] D loss: 1.4222\n",
      "[804/1762] D loss: 1.4044\n",
      "[884/1762] D loss: 1.3952\n",
      "[964/1762] D loss: 1.3961\n",
      "[1044/1762] D loss: 1.3674\n",
      "[1124/1762] D loss: 1.4014\n",
      "[1204/1762] D loss: 1.3654\n",
      "[1284/1762] D loss: 1.4100\n",
      "[1364/1762] D loss: 1.4105\n",
      "[1444/1762] D loss: 1.4003\n",
      "[1524/1762] D loss: 1.4279\n",
      "[1604/1762] D loss: 1.3938\n",
      "[1684/1762] D loss: 1.4022\n",
      "[1762/1762] D loss: 1.3983\n",
      "train error: \n",
      " D loss: 1.391110, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389793, D accuracy: 50.1% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4057\n",
      "[84/1762] D loss: 1.3966\n",
      "[164/1762] D loss: 1.4007\n",
      "[244/1762] D loss: 1.4120\n",
      "[324/1762] D loss: 1.3954\n",
      "[404/1762] D loss: 1.3929\n",
      "[484/1762] D loss: 1.4039\n",
      "[564/1762] D loss: 1.4059\n",
      "[644/1762] D loss: 1.3974\n",
      "[724/1762] D loss: 1.3947\n",
      "[804/1762] D loss: 1.3868\n",
      "[884/1762] D loss: 1.3908\n",
      "[964/1762] D loss: 1.3776\n",
      "[1044/1762] D loss: 1.4131\n",
      "[1124/1762] D loss: 1.4110\n",
      "[1204/1762] D loss: 1.3846\n",
      "[1284/1762] D loss: 1.4141\n",
      "[1364/1762] D loss: 1.4153\n",
      "[1444/1762] D loss: 1.4005\n",
      "[1524/1762] D loss: 1.3929\n",
      "[1604/1762] D loss: 1.4003\n",
      "[1684/1762] D loss: 1.3950\n",
      "[1762/1762] D loss: 1.3767\n",
      "train error: \n",
      " D loss: 1.391832, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394665, D accuracy: 50.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4078\n",
      "[84/1762] D loss: 1.4070\n",
      "[164/1762] D loss: 1.3937\n",
      "[244/1762] D loss: 1.3989\n",
      "[324/1762] D loss: 1.3825\n",
      "[404/1762] D loss: 1.4034\n",
      "[484/1762] D loss: 1.3892\n",
      "[564/1762] D loss: 1.3973\n",
      "[644/1762] D loss: 1.3860\n",
      "[724/1762] D loss: 1.3806\n",
      "[804/1762] D loss: 1.4039\n",
      "[884/1762] D loss: 1.4248\n",
      "[964/1762] D loss: 1.4055\n",
      "[1044/1762] D loss: 1.4147\n",
      "[1124/1762] D loss: 1.3966\n",
      "[1204/1762] D loss: 1.3979\n",
      "[1284/1762] D loss: 1.4090\n",
      "[1364/1762] D loss: 1.4100\n",
      "[1444/1762] D loss: 1.3965\n",
      "[1524/1762] D loss: 1.4073\n",
      "[1604/1762] D loss: 1.4106\n",
      "[1684/1762] D loss: 1.4174\n",
      "[1762/1762] D loss: 1.3908\n",
      "train error: \n",
      " D loss: 1.393820, D accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391280, D accuracy: 49.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4170\n",
      "[84/1762] D loss: 1.4132\n",
      "[164/1762] D loss: 1.3870\n",
      "[244/1762] D loss: 1.3737\n",
      "[324/1762] D loss: 1.4031\n",
      "[404/1762] D loss: 1.4040\n",
      "[484/1762] D loss: 1.3963\n",
      "[564/1762] D loss: 1.3880\n",
      "[644/1762] D loss: 1.3765\n",
      "[724/1762] D loss: 1.3844\n",
      "[804/1762] D loss: 1.4142\n",
      "[884/1762] D loss: 1.4151\n",
      "[964/1762] D loss: 1.4087\n",
      "[1044/1762] D loss: 1.4063\n",
      "[1124/1762] D loss: 1.4140\n",
      "[1204/1762] D loss: 1.3842\n",
      "[1284/1762] D loss: 1.4018\n",
      "[1364/1762] D loss: 1.4052\n",
      "[1444/1762] D loss: 1.4089\n",
      "[1524/1762] D loss: 1.3914\n",
      "[1604/1762] D loss: 1.3877\n",
      "[1684/1762] D loss: 1.3882\n",
      "[1762/1762] D loss: 1.3945\n",
      "train error: \n",
      " D loss: 1.394706, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396166, D accuracy: 49.7% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4049\n",
      "[84/1762] D loss: 1.3934\n",
      "[164/1762] D loss: 1.4253\n",
      "[244/1762] D loss: 1.4101\n",
      "[324/1762] D loss: 1.3758\n",
      "[404/1762] D loss: 1.4057\n",
      "[484/1762] D loss: 1.4149\n",
      "[564/1762] D loss: 1.4124\n",
      "[644/1762] D loss: 1.4068\n",
      "[724/1762] D loss: 1.4011\n",
      "[804/1762] D loss: 1.4044\n",
      "[884/1762] D loss: 1.4070\n",
      "[964/1762] D loss: 1.4079\n",
      "[1044/1762] D loss: 1.3983\n",
      "[1124/1762] D loss: 1.3901\n",
      "[1204/1762] D loss: 1.3724\n",
      "[1284/1762] D loss: 1.3885\n",
      "[1364/1762] D loss: 1.3966\n",
      "[1444/1762] D loss: 1.3879\n",
      "[1524/1762] D loss: 1.4212\n",
      "[1604/1762] D loss: 1.3996\n",
      "[1684/1762] D loss: 1.4063\n",
      "[1762/1762] D loss: 1.4356\n",
      "train error: \n",
      " D loss: 1.393369, D accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395407, D accuracy: 49.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3991\n",
      "[84/1762] D loss: 1.4096\n",
      "[164/1762] D loss: 1.4037\n",
      "[244/1762] D loss: 1.3986\n",
      "[324/1762] D loss: 1.4180\n",
      "[404/1762] D loss: 1.4218\n",
      "[484/1762] D loss: 1.4384\n",
      "[564/1762] D loss: 1.3891\n",
      "[644/1762] D loss: 1.4057\n",
      "[724/1762] D loss: 1.3951\n",
      "[804/1762] D loss: 1.3807\n",
      "[884/1762] D loss: 1.3985\n",
      "[964/1762] D loss: 1.3909\n",
      "[1044/1762] D loss: 1.3711\n",
      "[1124/1762] D loss: 1.4213\n",
      "[1204/1762] D loss: 1.3887\n",
      "[1284/1762] D loss: 1.4052\n",
      "[1364/1762] D loss: 1.3996\n",
      "[1444/1762] D loss: 1.4127\n",
      "[1524/1762] D loss: 1.4135\n",
      "[1604/1762] D loss: 1.3810\n",
      "[1684/1762] D loss: 1.4113\n",
      "[1762/1762] D loss: 1.4072\n",
      "train error: \n",
      " D loss: 1.391720, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393019, D accuracy: 50.2% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3984\n",
      "[84/1762] D loss: 1.4038\n",
      "[164/1762] D loss: 1.3910\n",
      "[244/1762] D loss: 1.3964\n",
      "[324/1762] D loss: 1.4448\n",
      "[404/1762] D loss: 1.4138\n",
      "[484/1762] D loss: 1.4085\n",
      "[564/1762] D loss: 1.3948\n",
      "[644/1762] D loss: 1.3994\n",
      "[724/1762] D loss: 1.3985\n",
      "[804/1762] D loss: 1.3879\n",
      "[884/1762] D loss: 1.4021\n",
      "[964/1762] D loss: 1.3957\n",
      "[1044/1762] D loss: 1.4050\n",
      "[1124/1762] D loss: 1.3916\n",
      "[1204/1762] D loss: 1.4130\n",
      "[1284/1762] D loss: 1.4137\n",
      "[1364/1762] D loss: 1.3877\n",
      "[1444/1762] D loss: 1.4102\n",
      "[1524/1762] D loss: 1.4050\n",
      "[1604/1762] D loss: 1.4080\n",
      "[1684/1762] D loss: 1.4019\n",
      "[1762/1762] D loss: 1.4203\n",
      "train error: \n",
      " D loss: 1.393787, D accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395978, D accuracy: 50.1% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895\n",
      "[84/1762] D loss: 1.4083\n",
      "[164/1762] D loss: 1.3748\n",
      "[244/1762] D loss: 1.4099\n",
      "[324/1762] D loss: 1.3936\n",
      "[404/1762] D loss: 1.4203\n",
      "[484/1762] D loss: 1.4195\n",
      "[564/1762] D loss: 1.4088\n",
      "[644/1762] D loss: 1.4150\n",
      "[724/1762] D loss: 1.3890\n",
      "[804/1762] D loss: 1.4071\n",
      "[884/1762] D loss: 1.4044\n",
      "[964/1762] D loss: 1.3804\n",
      "[1044/1762] D loss: 1.3799\n",
      "[1124/1762] D loss: 1.4031\n",
      "[1204/1762] D loss: 1.3931\n",
      "[1284/1762] D loss: 1.4052\n",
      "[1364/1762] D loss: 1.3957\n",
      "[1444/1762] D loss: 1.3980\n",
      "[1524/1762] D loss: 1.3892\n",
      "[1604/1762] D loss: 1.4196\n",
      "[1684/1762] D loss: 1.3756\n",
      "[1762/1762] D loss: 1.3800\n",
      "train error: \n",
      " D loss: 1.391641, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392928, D accuracy: 50.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4047\n",
      "[84/1762] D loss: 1.4070\n",
      "[164/1762] D loss: 1.3710\n",
      "[244/1762] D loss: 1.3946\n",
      "[324/1762] D loss: 1.4056\n",
      "[404/1762] D loss: 1.4116\n",
      "[484/1762] D loss: 1.4024\n",
      "[564/1762] D loss: 1.3994\n",
      "[644/1762] D loss: 1.4011\n",
      "[724/1762] D loss: 1.4066\n",
      "[804/1762] D loss: 1.3965\n",
      "[884/1762] D loss: 1.3986\n",
      "[964/1762] D loss: 1.3896\n",
      "[1044/1762] D loss: 1.3830\n",
      "[1124/1762] D loss: 1.3799\n",
      "[1204/1762] D loss: 1.4186\n",
      "[1284/1762] D loss: 1.3908\n",
      "[1364/1762] D loss: 1.3968\n",
      "[1444/1762] D loss: 1.3910\n",
      "[1524/1762] D loss: 1.4012\n",
      "[1604/1762] D loss: 1.4243\n",
      "[1684/1762] D loss: 1.4111\n",
      "[1762/1762] D loss: 1.4000\n",
      "train error: \n",
      " D loss: 1.391221, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391396, D accuracy: 49.7% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3999\n",
      "[84/1762] D loss: 1.3965\n",
      "[164/1762] D loss: 1.4245\n",
      "[244/1762] D loss: 1.3635\n",
      "[324/1762] D loss: 1.4064\n",
      "[404/1762] D loss: 1.3997\n",
      "[484/1762] D loss: 1.4042\n",
      "[564/1762] D loss: 1.3706\n",
      "[644/1762] D loss: 1.4136\n",
      "[724/1762] D loss: 1.3805\n",
      "[804/1762] D loss: 1.4013\n",
      "[884/1762] D loss: 1.3897\n",
      "[964/1762] D loss: 1.4052\n",
      "[1044/1762] D loss: 1.3798\n",
      "[1124/1762] D loss: 1.4018\n",
      "[1204/1762] D loss: 1.4001\n",
      "[1284/1762] D loss: 1.3945\n",
      "[1364/1762] D loss: 1.4016\n",
      "[1444/1762] D loss: 1.3762\n",
      "[1524/1762] D loss: 1.3748\n",
      "[1604/1762] D loss: 1.4130\n",
      "[1684/1762] D loss: 1.3872\n",
      "[1762/1762] D loss: 1.4175\n",
      "train error: \n",
      " D loss: 1.392050, D accuracy: 49.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392933, D accuracy: 49.7% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for learning_rate in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]:\n",
    "        run_name = f\"perturb_{4}_lr_\" + f\"{learning_rate:.0e}\".replace(\"-\", \"m\")\n",
    "        train(run_name=run_name, perturb_num=4, epochs=20, learning_rate=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1e-2 is unstable. 1e-3 reaches 99.9% accuracy within 10 epochs and remains stable, but doesn't get to 100% accuracy. 1e-4 shows signs of slow improvement, but needs more than 20 epochs to show real progress. 1e-5 and 1e-6 are too low - they barely show any progress.\n",
    "\n",
    "Let's repeat with more epochs and more learning rates, but discard those above 1e-3 or below 1e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3675\n",
      "[84/1762] D loss: 1.3865\n",
      "[164/1762] D loss: 1.3990\n",
      "[244/1762] D loss: 1.3828\n",
      "[324/1762] D loss: 1.3999\n",
      "[404/1762] D loss: 1.4003\n",
      "[484/1762] D loss: 1.3883\n",
      "[564/1762] D loss: 1.3942\n",
      "[644/1762] D loss: 1.3913\n",
      "[724/1762] D loss: 1.3857\n",
      "[804/1762] D loss: 1.3875\n",
      "[884/1762] D loss: 1.3704\n",
      "[964/1762] D loss: 1.3721\n",
      "[1044/1762] D loss: 1.3757\n",
      "[1124/1762] D loss: 1.3831\n",
      "[1204/1762] D loss: 1.3693\n",
      "[1284/1762] D loss: 1.3792\n",
      "[1364/1762] D loss: 1.3798\n",
      "[1444/1762] D loss: 1.3803\n",
      "[1524/1762] D loss: 1.3943\n",
      "[1604/1762] D loss: 1.3855\n",
      "[1684/1762] D loss: 1.3945\n",
      "[1762/1762] D loss: 1.3701\n",
      "train error: \n",
      " D loss: 1.385147, D accuracy: 51.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385340, D accuracy: 52.8% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3746\n",
      "[84/1762] D loss: 1.3766\n",
      "[164/1762] D loss: 1.3689\n",
      "[244/1762] D loss: 1.3883\n",
      "[324/1762] D loss: 1.3832\n",
      "[404/1762] D loss: 1.3798\n",
      "[484/1762] D loss: 1.3942\n",
      "[564/1762] D loss: 1.3729\n",
      "[644/1762] D loss: 1.3820\n",
      "[724/1762] D loss: 1.3969\n",
      "[804/1762] D loss: 1.3839\n",
      "[884/1762] D loss: 1.3959\n",
      "[964/1762] D loss: 1.3856\n",
      "[1044/1762] D loss: 1.3839\n",
      "[1124/1762] D loss: 1.3773\n",
      "[1204/1762] D loss: 1.3836\n",
      "[1284/1762] D loss: 1.3730\n",
      "[1364/1762] D loss: 1.3904\n",
      "[1444/1762] D loss: 1.3841\n",
      "[1524/1762] D loss: 1.3698\n",
      "[1604/1762] D loss: 1.3826\n",
      "[1684/1762] D loss: 1.3876\n",
      "[1762/1762] D loss: 1.3769\n",
      "train error: \n",
      " D loss: 1.383032, D accuracy: 53.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383098, D accuracy: 51.8% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909\n",
      "[84/1762] D loss: 1.3671\n",
      "[164/1762] D loss: 1.3925\n",
      "[244/1762] D loss: 1.3790\n",
      "[324/1762] D loss: 1.3852\n",
      "[404/1762] D loss: 1.3836\n",
      "[484/1762] D loss: 1.3728\n",
      "[564/1762] D loss: 1.3792\n",
      "[644/1762] D loss: 1.3745\n",
      "[724/1762] D loss: 1.3960\n",
      "[804/1762] D loss: 1.3737\n",
      "[884/1762] D loss: 1.3728\n",
      "[964/1762] D loss: 1.3880\n",
      "[1044/1762] D loss: 1.3782\n",
      "[1124/1762] D loss: 1.3675\n",
      "[1204/1762] D loss: 1.3758\n",
      "[1284/1762] D loss: 1.3693\n",
      "[1364/1762] D loss: 1.3796\n",
      "[1444/1762] D loss: 1.3805\n",
      "[1524/1762] D loss: 1.3645\n",
      "[1604/1762] D loss: 1.3713\n",
      "[1684/1762] D loss: 1.3814\n",
      "[1762/1762] D loss: 1.3952\n",
      "train error: \n",
      " D loss: 1.381790, D accuracy: 53.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381255, D accuracy: 52.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3703\n",
      "[84/1762] D loss: 1.3902\n",
      "[164/1762] D loss: 1.3876\n",
      "[244/1762] D loss: 1.3851\n",
      "[324/1762] D loss: 1.3558\n",
      "[404/1762] D loss: 1.3914\n",
      "[484/1762] D loss: 1.3808\n",
      "[564/1762] D loss: 1.3767\n",
      "[644/1762] D loss: 1.3951\n",
      "[724/1762] D loss: 1.3806\n",
      "[804/1762] D loss: 1.3923\n",
      "[884/1762] D loss: 1.3842\n",
      "[964/1762] D loss: 1.3765\n",
      "[1044/1762] D loss: 1.3872\n",
      "[1124/1762] D loss: 1.3773\n",
      "[1204/1762] D loss: 1.3700\n",
      "[1284/1762] D loss: 1.3780\n",
      "[1364/1762] D loss: 1.3740\n",
      "[1444/1762] D loss: 1.3794\n",
      "[1524/1762] D loss: 1.3760\n",
      "[1604/1762] D loss: 1.3881\n",
      "[1684/1762] D loss: 1.3517\n",
      "[1762/1762] D loss: 1.3887\n",
      "train error: \n",
      " D loss: 1.380131, D accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380960, D accuracy: 56.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887\n",
      "[84/1762] D loss: 1.3786\n",
      "[164/1762] D loss: 1.3618\n",
      "[244/1762] D loss: 1.3871\n",
      "[324/1762] D loss: 1.3773\n",
      "[404/1762] D loss: 1.3722\n",
      "[484/1762] D loss: 1.3862\n",
      "[564/1762] D loss: 1.3863\n",
      "[644/1762] D loss: 1.3829\n",
      "[724/1762] D loss: 1.3844\n",
      "[804/1762] D loss: 1.3719\n",
      "[884/1762] D loss: 1.3805\n",
      "[964/1762] D loss: 1.3730\n",
      "[1044/1762] D loss: 1.3826\n",
      "[1124/1762] D loss: 1.3745\n",
      "[1204/1762] D loss: 1.3735\n",
      "[1284/1762] D loss: 1.3894\n",
      "[1364/1762] D loss: 1.3772\n",
      "[1444/1762] D loss: 1.3805\n",
      "[1524/1762] D loss: 1.3899\n",
      "[1604/1762] D loss: 1.3845\n",
      "[1684/1762] D loss: 1.3890\n",
      "[1762/1762] D loss: 1.3753\n",
      "train error: \n",
      " D loss: 1.378344, D accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378643, D accuracy: 56.7% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3768\n",
      "[84/1762] D loss: 1.3630\n",
      "[164/1762] D loss: 1.3686\n",
      "[244/1762] D loss: 1.3703\n",
      "[324/1762] D loss: 1.3706\n",
      "[404/1762] D loss: 1.3773\n",
      "[484/1762] D loss: 1.3821\n",
      "[564/1762] D loss: 1.3835\n",
      "[644/1762] D loss: 1.3888\n",
      "[724/1762] D loss: 1.3770\n",
      "[804/1762] D loss: 1.3997\n",
      "[884/1762] D loss: 1.3515\n",
      "[964/1762] D loss: 1.3525\n",
      "[1044/1762] D loss: 1.3780\n",
      "[1124/1762] D loss: 1.3870\n",
      "[1204/1762] D loss: 1.3783\n",
      "[1284/1762] D loss: 1.3865\n",
      "[1364/1762] D loss: 1.3779\n",
      "[1444/1762] D loss: 1.3518\n",
      "[1524/1762] D loss: 1.3781\n",
      "[1604/1762] D loss: 1.3731\n",
      "[1684/1762] D loss: 1.3807\n",
      "[1762/1762] D loss: 1.3771\n",
      "train error: \n",
      " D loss: 1.376643, D accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377840, D accuracy: 56.4% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3739\n",
      "[84/1762] D loss: 1.3872\n",
      "[164/1762] D loss: 1.3632\n",
      "[244/1762] D loss: 1.3790\n",
      "[324/1762] D loss: 1.3918\n",
      "[404/1762] D loss: 1.3568\n",
      "[484/1762] D loss: 1.3518\n",
      "[564/1762] D loss: 1.3805\n",
      "[644/1762] D loss: 1.3713\n",
      "[724/1762] D loss: 1.3485\n",
      "[804/1762] D loss: 1.3598\n",
      "[884/1762] D loss: 1.3763\n",
      "[964/1762] D loss: 1.3870\n",
      "[1044/1762] D loss: 1.3785\n",
      "[1124/1762] D loss: 1.3594\n",
      "[1204/1762] D loss: 1.3700\n",
      "[1284/1762] D loss: 1.3611\n",
      "[1364/1762] D loss: 1.3718\n",
      "[1444/1762] D loss: 1.3648\n",
      "[1524/1762] D loss: 1.3745\n",
      "[1604/1762] D loss: 1.3559\n",
      "[1684/1762] D loss: 1.3820\n",
      "[1762/1762] D loss: 1.3409\n",
      "train error: \n",
      " D loss: 1.375476, D accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373761, D accuracy: 58.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3739\n",
      "[84/1762] D loss: 1.3758\n",
      "[164/1762] D loss: 1.3708\n",
      "[244/1762] D loss: 1.3556\n",
      "[324/1762] D loss: 1.3743\n",
      "[404/1762] D loss: 1.3675\n",
      "[484/1762] D loss: 1.3616\n",
      "[564/1762] D loss: 1.3810\n",
      "[644/1762] D loss: 1.3563\n",
      "[724/1762] D loss: 1.3651\n",
      "[804/1762] D loss: 1.3646\n",
      "[884/1762] D loss: 1.3577\n",
      "[964/1762] D loss: 1.3897\n",
      "[1044/1762] D loss: 1.3654\n",
      "[1124/1762] D loss: 1.3682\n",
      "[1204/1762] D loss: 1.3881\n",
      "[1284/1762] D loss: 1.3730\n",
      "[1364/1762] D loss: 1.3836\n",
      "[1444/1762] D loss: 1.3671\n",
      "[1524/1762] D loss: 1.3781\n",
      "[1604/1762] D loss: 1.3917\n",
      "[1684/1762] D loss: 1.3696\n",
      "[1762/1762] D loss: 1.3645\n",
      "train error: \n",
      " D loss: 1.372814, D accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372829, D accuracy: 58.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3576\n",
      "[84/1762] D loss: 1.3525\n",
      "[164/1762] D loss: 1.3658\n",
      "[244/1762] D loss: 1.3684\n",
      "[324/1762] D loss: 1.3791\n",
      "[404/1762] D loss: 1.3654\n",
      "[484/1762] D loss: 1.3499\n",
      "[564/1762] D loss: 1.3684\n",
      "[644/1762] D loss: 1.3656\n",
      "[724/1762] D loss: 1.3616\n",
      "[804/1762] D loss: 1.3818\n",
      "[884/1762] D loss: 1.3817\n",
      "[964/1762] D loss: 1.3631\n",
      "[1044/1762] D loss: 1.3713\n",
      "[1124/1762] D loss: 1.3702\n",
      "[1204/1762] D loss: 1.3554\n",
      "[1284/1762] D loss: 1.3715\n",
      "[1364/1762] D loss: 1.3519\n",
      "[1444/1762] D loss: 1.3414\n",
      "[1524/1762] D loss: 1.3629\n",
      "[1604/1762] D loss: 1.3637\n",
      "[1684/1762] D loss: 1.3716\n",
      "[1762/1762] D loss: 1.3830\n",
      "train error: \n",
      " D loss: 1.370433, D accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371131, D accuracy: 60.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3648\n",
      "[84/1762] D loss: 1.3752\n",
      "[164/1762] D loss: 1.3651\n",
      "[244/1762] D loss: 1.3775\n",
      "[324/1762] D loss: 1.3604\n",
      "[404/1762] D loss: 1.3544\n",
      "[484/1762] D loss: 1.3751\n",
      "[564/1762] D loss: 1.3920\n",
      "[644/1762] D loss: 1.3557\n",
      "[724/1762] D loss: 1.3850\n",
      "[804/1762] D loss: 1.3717\n",
      "[884/1762] D loss: 1.3632\n",
      "[964/1762] D loss: 1.3633\n",
      "[1044/1762] D loss: 1.3425\n",
      "[1124/1762] D loss: 1.3554\n",
      "[1204/1762] D loss: 1.3589\n",
      "[1284/1762] D loss: 1.3754\n",
      "[1364/1762] D loss: 1.3777\n",
      "[1444/1762] D loss: 1.3621\n",
      "[1524/1762] D loss: 1.3787\n",
      "[1604/1762] D loss: 1.3607\n",
      "[1684/1762] D loss: 1.3751\n",
      "[1762/1762] D loss: 1.3874\n",
      "train error: \n",
      " D loss: 1.369179, D accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368829, D accuracy: 58.3% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3838\n",
      "[84/1762] D loss: 1.3543\n",
      "[164/1762] D loss: 1.3541\n",
      "[244/1762] D loss: 1.3423\n",
      "[324/1762] D loss: 1.3789\n",
      "[404/1762] D loss: 1.3838\n",
      "[484/1762] D loss: 1.3720\n",
      "[564/1762] D loss: 1.3520\n",
      "[644/1762] D loss: 1.3880\n",
      "[724/1762] D loss: 1.3879\n",
      "[804/1762] D loss: 1.3681\n",
      "[884/1762] D loss: 1.3691\n",
      "[964/1762] D loss: 1.3846\n",
      "[1044/1762] D loss: 1.3545\n",
      "[1124/1762] D loss: 1.3591\n",
      "[1204/1762] D loss: 1.3646\n",
      "[1284/1762] D loss: 1.3576\n",
      "[1364/1762] D loss: 1.3712\n",
      "[1444/1762] D loss: 1.3739\n",
      "[1524/1762] D loss: 1.3791\n",
      "[1604/1762] D loss: 1.3679\n",
      "[1684/1762] D loss: 1.3428\n",
      "[1762/1762] D loss: 1.3707\n",
      "train error: \n",
      " D loss: 1.364960, D accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365490, D accuracy: 59.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3721\n",
      "[84/1762] D loss: 1.3709\n",
      "[164/1762] D loss: 1.3485\n",
      "[244/1762] D loss: 1.3393\n",
      "[324/1762] D loss: 1.3404\n",
      "[404/1762] D loss: 1.3825\n",
      "[484/1762] D loss: 1.3601\n",
      "[564/1762] D loss: 1.3614\n",
      "[644/1762] D loss: 1.3502\n",
      "[724/1762] D loss: 1.3604\n",
      "[804/1762] D loss: 1.3484\n",
      "[884/1762] D loss: 1.3446\n",
      "[964/1762] D loss: 1.3819\n",
      "[1044/1762] D loss: 1.3482\n",
      "[1124/1762] D loss: 1.3622\n",
      "[1204/1762] D loss: 1.3624\n",
      "[1284/1762] D loss: 1.3729\n",
      "[1364/1762] D loss: 1.3392\n",
      "[1444/1762] D loss: 1.3866\n",
      "[1524/1762] D loss: 1.3735\n",
      "[1604/1762] D loss: 1.3347\n",
      "[1684/1762] D loss: 1.3589\n",
      "[1762/1762] D loss: 1.3641\n",
      "train error: \n",
      " D loss: 1.365030, D accuracy: 60.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364378, D accuracy: 61.1% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3595\n",
      "[84/1762] D loss: 1.3321\n",
      "[164/1762] D loss: 1.3588\n",
      "[244/1762] D loss: 1.3673\n",
      "[324/1762] D loss: 1.3747\n",
      "[404/1762] D loss: 1.3812\n",
      "[484/1762] D loss: 1.3237\n",
      "[564/1762] D loss: 1.3691\n",
      "[644/1762] D loss: 1.3470\n",
      "[724/1762] D loss: 1.3672\n",
      "[804/1762] D loss: 1.3570\n",
      "[884/1762] D loss: 1.3590\n",
      "[964/1762] D loss: 1.3663\n",
      "[1044/1762] D loss: 1.3400\n",
      "[1124/1762] D loss: 1.3603\n",
      "[1204/1762] D loss: 1.3590\n",
      "[1284/1762] D loss: 1.3517\n",
      "[1364/1762] D loss: 1.3545\n",
      "[1444/1762] D loss: 1.3212\n",
      "[1524/1762] D loss: 1.3432\n",
      "[1604/1762] D loss: 1.3563\n",
      "[1684/1762] D loss: 1.3749\n",
      "[1762/1762] D loss: 1.3559\n",
      "train error: \n",
      " D loss: 1.359315, D accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358566, D accuracy: 63.4% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3168\n",
      "[84/1762] D loss: 1.3633\n",
      "[164/1762] D loss: 1.3049\n",
      "[244/1762] D loss: 1.3537\n",
      "[324/1762] D loss: 1.3652\n",
      "[404/1762] D loss: 1.3451\n",
      "[484/1762] D loss: 1.3375\n",
      "[564/1762] D loss: 1.3357\n",
      "[644/1762] D loss: 1.3704\n",
      "[724/1762] D loss: 1.3569\n",
      "[804/1762] D loss: 1.3430\n",
      "[884/1762] D loss: 1.3221\n",
      "[964/1762] D loss: 1.3567\n",
      "[1044/1762] D loss: 1.3493\n",
      "[1124/1762] D loss: 1.3281\n",
      "[1204/1762] D loss: 1.3521\n",
      "[1284/1762] D loss: 1.3714\n",
      "[1364/1762] D loss: 1.3010\n",
      "[1444/1762] D loss: 1.3508\n",
      "[1524/1762] D loss: 1.3386\n",
      "[1604/1762] D loss: 1.3260\n",
      "[1684/1762] D loss: 1.3000\n",
      "[1762/1762] D loss: 1.3555\n",
      "train error: \n",
      " D loss: 1.357349, D accuracy: 61.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354928, D accuracy: 61.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3635\n",
      "[84/1762] D loss: 1.3552\n",
      "[164/1762] D loss: 1.3370\n",
      "[244/1762] D loss: 1.3447\n",
      "[324/1762] D loss: 1.3594\n",
      "[404/1762] D loss: 1.3727\n",
      "[484/1762] D loss: 1.3259\n",
      "[564/1762] D loss: 1.3327\n",
      "[644/1762] D loss: 1.3560\n",
      "[724/1762] D loss: 1.3379\n",
      "[804/1762] D loss: 1.3743\n",
      "[884/1762] D loss: 1.3520\n",
      "[964/1762] D loss: 1.3465\n",
      "[1044/1762] D loss: 1.3597\n",
      "[1124/1762] D loss: 1.3496\n",
      "[1204/1762] D loss: 1.3394\n",
      "[1284/1762] D loss: 1.3021\n",
      "[1364/1762] D loss: 1.3404\n",
      "[1444/1762] D loss: 1.3639\n",
      "[1524/1762] D loss: 1.3475\n",
      "[1604/1762] D loss: 1.3201\n",
      "[1684/1762] D loss: 1.3370\n",
      "[1762/1762] D loss: 1.3383\n",
      "train error: \n",
      " D loss: 1.350146, D accuracy: 65.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352302, D accuracy: 64.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3083\n",
      "[84/1762] D loss: 1.3606\n",
      "[164/1762] D loss: 1.3469\n",
      "[244/1762] D loss: 1.3262\n",
      "[324/1762] D loss: 1.3448\n",
      "[404/1762] D loss: 1.3456\n",
      "[484/1762] D loss: 1.3195\n",
      "[564/1762] D loss: 1.3593\n",
      "[644/1762] D loss: 1.3818\n",
      "[724/1762] D loss: 1.3321\n",
      "[804/1762] D loss: 1.3370\n",
      "[884/1762] D loss: 1.3030\n",
      "[964/1762] D loss: 1.3536\n",
      "[1044/1762] D loss: 1.3293\n",
      "[1124/1762] D loss: 1.3482\n",
      "[1204/1762] D loss: 1.3552\n",
      "[1284/1762] D loss: 1.3454\n",
      "[1364/1762] D loss: 1.3608\n",
      "[1444/1762] D loss: 1.3489\n",
      "[1524/1762] D loss: 1.3026\n",
      "[1604/1762] D loss: 1.3385\n",
      "[1684/1762] D loss: 1.3575\n",
      "[1762/1762] D loss: 1.3073\n",
      "train error: \n",
      " D loss: 1.344945, D accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344744, D accuracy: 66.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3447\n",
      "[84/1762] D loss: 1.3311\n",
      "[164/1762] D loss: 1.3510\n",
      "[244/1762] D loss: 1.3656\n",
      "[324/1762] D loss: 1.3620\n",
      "[404/1762] D loss: 1.3372\n",
      "[484/1762] D loss: 1.3370\n",
      "[564/1762] D loss: 1.3311\n",
      "[644/1762] D loss: 1.3117\n",
      "[724/1762] D loss: 1.3269\n",
      "[804/1762] D loss: 1.3121\n",
      "[884/1762] D loss: 1.3165\n",
      "[964/1762] D loss: 1.3472\n",
      "[1044/1762] D loss: 1.3490\n",
      "[1124/1762] D loss: 1.3248\n",
      "[1204/1762] D loss: 1.3376\n",
      "[1284/1762] D loss: 1.3094\n",
      "[1364/1762] D loss: 1.3324\n",
      "[1444/1762] D loss: 1.3412\n",
      "[1524/1762] D loss: 1.3419\n",
      "[1604/1762] D loss: 1.3086\n",
      "[1684/1762] D loss: 1.3222\n",
      "[1762/1762] D loss: 1.3539\n",
      "train error: \n",
      " D loss: 1.336586, D accuracy: 68.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337426, D accuracy: 66.6% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3350\n",
      "[84/1762] D loss: 1.3522\n",
      "[164/1762] D loss: 1.3460\n",
      "[244/1762] D loss: 1.3281\n",
      "[324/1762] D loss: 1.3068\n",
      "[404/1762] D loss: 1.3198\n",
      "[484/1762] D loss: 1.2894\n",
      "[564/1762] D loss: 1.3151\n",
      "[644/1762] D loss: 1.2897\n",
      "[724/1762] D loss: 1.3002\n",
      "[804/1762] D loss: 1.3129\n",
      "[884/1762] D loss: 1.2956\n",
      "[964/1762] D loss: 1.3015\n",
      "[1044/1762] D loss: 1.3230\n",
      "[1124/1762] D loss: 1.3078\n",
      "[1204/1762] D loss: 1.2980\n",
      "[1284/1762] D loss: 1.2491\n",
      "[1364/1762] D loss: 1.3194\n",
      "[1444/1762] D loss: 1.3081\n",
      "[1524/1762] D loss: 1.3202\n",
      "[1604/1762] D loss: 1.3615\n",
      "[1684/1762] D loss: 1.3263\n",
      "[1762/1762] D loss: 1.2219\n",
      "train error: \n",
      " D loss: 1.324784, D accuracy: 69.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327169, D accuracy: 68.6% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3129\n",
      "[84/1762] D loss: 1.3015\n",
      "[164/1762] D loss: 1.3277\n",
      "[244/1762] D loss: 1.3175\n",
      "[324/1762] D loss: 1.2845\n",
      "[404/1762] D loss: 1.3638\n",
      "[484/1762] D loss: 1.3177\n",
      "[564/1762] D loss: 1.3300\n",
      "[644/1762] D loss: 1.2719\n",
      "[724/1762] D loss: 1.3610\n",
      "[804/1762] D loss: 1.3371\n",
      "[884/1762] D loss: 1.2176\n",
      "[964/1762] D loss: 1.3122\n",
      "[1044/1762] D loss: 1.3166\n",
      "[1124/1762] D loss: 1.2871\n",
      "[1204/1762] D loss: 1.2783\n",
      "[1284/1762] D loss: 1.3629\n",
      "[1364/1762] D loss: 1.2380\n",
      "[1444/1762] D loss: 1.2924\n",
      "[1524/1762] D loss: 1.2717\n",
      "[1604/1762] D loss: 1.2968\n",
      "[1684/1762] D loss: 1.3016\n",
      "[1762/1762] D loss: 1.3793\n",
      "train error: \n",
      " D loss: 1.315707, D accuracy: 70.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312273, D accuracy: 69.4% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3707\n",
      "[84/1762] D loss: 1.2648\n",
      "[164/1762] D loss: 1.3147\n",
      "[244/1762] D loss: 1.2947\n",
      "[324/1762] D loss: 1.3289\n",
      "[404/1762] D loss: 1.3436\n",
      "[484/1762] D loss: 1.3334\n",
      "[564/1762] D loss: 1.3117\n",
      "[644/1762] D loss: 1.2430\n",
      "[724/1762] D loss: 1.2664\n",
      "[804/1762] D loss: 1.2798\n",
      "[884/1762] D loss: 1.3812\n",
      "[964/1762] D loss: 1.2736\n",
      "[1044/1762] D loss: 1.3300\n",
      "[1124/1762] D loss: 1.2624\n",
      "[1204/1762] D loss: 1.2489\n",
      "[1284/1762] D loss: 1.2892\n",
      "[1364/1762] D loss: 1.3003\n",
      "[1444/1762] D loss: 1.3055\n",
      "[1524/1762] D loss: 1.2751\n",
      "[1604/1762] D loss: 1.2888\n",
      "[1684/1762] D loss: 1.2795\n",
      "[1762/1762] D loss: 1.2955\n",
      "train error: \n",
      " D loss: 1.296277, D accuracy: 72.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297232, D accuracy: 72.6% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3040\n",
      "[84/1762] D loss: 1.2902\n",
      "[164/1762] D loss: 1.2826\n",
      "[244/1762] D loss: 1.2579\n",
      "[324/1762] D loss: 1.2265\n",
      "[404/1762] D loss: 1.2678\n",
      "[484/1762] D loss: 1.2562\n",
      "[564/1762] D loss: 1.2734\n",
      "[644/1762] D loss: 1.2912\n",
      "[724/1762] D loss: 1.2517\n",
      "[804/1762] D loss: 1.3496\n",
      "[884/1762] D loss: 1.2884\n",
      "[964/1762] D loss: 1.3004\n",
      "[1044/1762] D loss: 1.3090\n",
      "[1124/1762] D loss: 1.2773\n",
      "[1204/1762] D loss: 1.3391\n",
      "[1284/1762] D loss: 1.2887\n",
      "[1364/1762] D loss: 1.2918\n",
      "[1444/1762] D loss: 1.3158\n",
      "[1524/1762] D loss: 1.3185\n",
      "[1604/1762] D loss: 1.1928\n",
      "[1684/1762] D loss: 1.2321\n",
      "[1762/1762] D loss: 1.2819\n",
      "train error: \n",
      " D loss: 1.284162, D accuracy: 71.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288677, D accuracy: 72.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2358\n",
      "[84/1762] D loss: 1.2500\n",
      "[164/1762] D loss: 1.2918\n",
      "[244/1762] D loss: 1.2276\n",
      "[324/1762] D loss: 1.2518\n",
      "[404/1762] D loss: 1.2286\n",
      "[484/1762] D loss: 1.3086\n",
      "[564/1762] D loss: 1.2902\n",
      "[644/1762] D loss: 1.2425\n",
      "[724/1762] D loss: 1.2488\n",
      "[804/1762] D loss: 1.3010\n",
      "[884/1762] D loss: 1.1727\n",
      "[964/1762] D loss: 1.3194\n",
      "[1044/1762] D loss: 1.2609\n",
      "[1124/1762] D loss: 1.2598\n",
      "[1204/1762] D loss: 1.2215\n",
      "[1284/1762] D loss: 1.1648\n",
      "[1364/1762] D loss: 1.2519\n",
      "[1444/1762] D loss: 1.2142\n",
      "[1524/1762] D loss: 1.1757\n",
      "[1604/1762] D loss: 1.2631\n",
      "[1684/1762] D loss: 1.2586\n",
      "[1762/1762] D loss: 1.2694\n",
      "train error: \n",
      " D loss: 1.256751, D accuracy: 76.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256449, D accuracy: 75.6% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2783\n",
      "[84/1762] D loss: 1.2129\n",
      "[164/1762] D loss: 1.1683\n",
      "[244/1762] D loss: 1.2759\n",
      "[324/1762] D loss: 1.2311\n",
      "[404/1762] D loss: 1.2474\n",
      "[484/1762] D loss: 1.2506\n",
      "[564/1762] D loss: 1.2676\n",
      "[644/1762] D loss: 1.2295\n",
      "[724/1762] D loss: 1.3167\n",
      "[804/1762] D loss: 1.2167\n",
      "[884/1762] D loss: 1.2706\n",
      "[964/1762] D loss: 1.3026\n",
      "[1044/1762] D loss: 1.2376\n",
      "[1124/1762] D loss: 1.1903\n",
      "[1204/1762] D loss: 1.2476\n",
      "[1284/1762] D loss: 1.2484\n",
      "[1364/1762] D loss: 1.2652\n",
      "[1444/1762] D loss: 1.2299\n",
      "[1524/1762] D loss: 1.0912\n",
      "[1604/1762] D loss: 1.2685\n",
      "[1684/1762] D loss: 1.2403\n",
      "[1762/1762] D loss: 1.2005\n",
      "train error: \n",
      " D loss: 1.216105, D accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.223058, D accuracy: 81.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1590\n",
      "[84/1762] D loss: 1.2435\n",
      "[164/1762] D loss: 1.1720\n",
      "[244/1762] D loss: 1.2567\n",
      "[324/1762] D loss: 1.1272\n",
      "[404/1762] D loss: 1.2219\n",
      "[484/1762] D loss: 1.2277\n",
      "[564/1762] D loss: 1.1537\n",
      "[644/1762] D loss: 1.1718\n",
      "[724/1762] D loss: 1.1235\n",
      "[804/1762] D loss: 1.2098\n",
      "[884/1762] D loss: 1.2623\n",
      "[964/1762] D loss: 1.1977\n",
      "[1044/1762] D loss: 1.0526\n",
      "[1124/1762] D loss: 1.2035\n",
      "[1204/1762] D loss: 1.1022\n",
      "[1284/1762] D loss: 1.1857\n",
      "[1364/1762] D loss: 1.0918\n",
      "[1444/1762] D loss: 1.2449\n",
      "[1524/1762] D loss: 1.0625\n",
      "[1604/1762] D loss: 1.1970\n",
      "[1684/1762] D loss: 1.2123\n",
      "[1762/1762] D loss: 1.2139\n",
      "train error: \n",
      " D loss: 1.171752, D accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.178533, D accuracy: 85.2% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1954\n",
      "[84/1762] D loss: 1.1701\n",
      "[164/1762] D loss: 1.2853\n",
      "[244/1762] D loss: 1.1781\n",
      "[324/1762] D loss: 1.0740\n",
      "[404/1762] D loss: 1.1579\n",
      "[484/1762] D loss: 1.1344\n",
      "[564/1762] D loss: 1.1432\n",
      "[644/1762] D loss: 1.1622\n",
      "[724/1762] D loss: 1.1697\n",
      "[804/1762] D loss: 1.0487\n",
      "[884/1762] D loss: 1.2295\n",
      "[964/1762] D loss: 0.9433\n",
      "[1044/1762] D loss: 1.1603\n",
      "[1124/1762] D loss: 1.0328\n",
      "[1204/1762] D loss: 1.1309\n",
      "[1284/1762] D loss: 1.0627\n",
      "[1364/1762] D loss: 0.9811\n",
      "[1444/1762] D loss: 1.2404\n",
      "[1524/1762] D loss: 1.0286\n",
      "[1604/1762] D loss: 1.1173\n",
      "[1684/1762] D loss: 1.0841\n",
      "[1762/1762] D loss: 1.2001\n",
      "train error: \n",
      " D loss: 1.134537, D accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.132722, D accuracy: 86.7% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1999\n",
      "[84/1762] D loss: 1.2189\n",
      "[164/1762] D loss: 0.8802\n",
      "[244/1762] D loss: 1.0365\n",
      "[324/1762] D loss: 1.1171\n",
      "[404/1762] D loss: 1.1172\n",
      "[484/1762] D loss: 1.0846\n",
      "[564/1762] D loss: 1.1573\n",
      "[644/1762] D loss: 1.1456\n",
      "[724/1762] D loss: 1.0831\n",
      "[804/1762] D loss: 1.0942\n",
      "[884/1762] D loss: 1.0201\n",
      "[964/1762] D loss: 0.8722\n",
      "[1044/1762] D loss: 1.1472\n",
      "[1124/1762] D loss: 0.9027\n",
      "[1204/1762] D loss: 1.0530\n",
      "[1284/1762] D loss: 0.9173\n",
      "[1364/1762] D loss: 0.9052\n",
      "[1444/1762] D loss: 1.2008\n",
      "[1524/1762] D loss: 1.0997\n",
      "[1604/1762] D loss: 0.8064\n",
      "[1684/1762] D loss: 0.9803\n",
      "[1762/1762] D loss: 1.1856\n",
      "train error: \n",
      " D loss: 1.029947, D accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.037388, D accuracy: 88.6% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1850\n",
      "[84/1762] D loss: 0.8170\n",
      "[164/1762] D loss: 0.9519\n",
      "[244/1762] D loss: 1.0817\n",
      "[324/1762] D loss: 1.0461\n",
      "[404/1762] D loss: 0.8152\n",
      "[484/1762] D loss: 0.9005\n",
      "[564/1762] D loss: 1.0256\n",
      "[644/1762] D loss: 0.9107\n",
      "[724/1762] D loss: 0.8031\n",
      "[804/1762] D loss: 0.9416\n",
      "[884/1762] D loss: 0.9914\n",
      "[964/1762] D loss: 0.8833\n",
      "[1044/1762] D loss: 0.9053\n",
      "[1124/1762] D loss: 0.9969\n",
      "[1204/1762] D loss: 0.9621\n",
      "[1284/1762] D loss: 0.8256\n",
      "[1364/1762] D loss: 0.9637\n",
      "[1444/1762] D loss: 0.9047\n",
      "[1524/1762] D loss: 0.7748\n",
      "[1604/1762] D loss: 0.9541\n",
      "[1684/1762] D loss: 0.9247\n",
      "[1762/1762] D loss: 0.8637\n",
      "train error: \n",
      " D loss: 0.913145, D accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.913642, D accuracy: 90.2% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0186\n",
      "[84/1762] D loss: 1.0206\n",
      "[164/1762] D loss: 1.0242\n",
      "[244/1762] D loss: 0.9093\n",
      "[324/1762] D loss: 1.1473\n",
      "[404/1762] D loss: 1.1080\n",
      "[484/1762] D loss: 0.7383\n",
      "[564/1762] D loss: 0.8245\n",
      "[644/1762] D loss: 0.9336\n",
      "[724/1762] D loss: 0.7140\n",
      "[804/1762] D loss: 0.8622\n",
      "[884/1762] D loss: 0.9365\n",
      "[964/1762] D loss: 0.6785\n",
      "[1044/1762] D loss: 1.1130\n",
      "[1124/1762] D loss: 0.7249\n",
      "[1204/1762] D loss: 0.6744\n",
      "[1284/1762] D loss: 0.6048\n",
      "[1364/1762] D loss: 0.9661\n",
      "[1444/1762] D loss: 0.6463\n",
      "[1524/1762] D loss: 0.9915\n",
      "[1604/1762] D loss: 0.8694\n",
      "[1684/1762] D loss: 0.7601\n",
      "[1762/1762] D loss: 0.9284\n",
      "train error: \n",
      " D loss: 0.800742, D accuracy: 93.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.822473, D accuracy: 92.7% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6277\n",
      "[84/1762] D loss: 0.7378\n",
      "[164/1762] D loss: 0.7459\n",
      "[244/1762] D loss: 0.6881\n",
      "[324/1762] D loss: 0.8197\n",
      "[404/1762] D loss: 0.6065\n",
      "[484/1762] D loss: 0.8002\n",
      "[564/1762] D loss: 0.6541\n",
      "[644/1762] D loss: 0.7811\n",
      "[724/1762] D loss: 0.5628\n",
      "[804/1762] D loss: 0.6688\n",
      "[884/1762] D loss: 0.7549\n",
      "[964/1762] D loss: 0.7608\n",
      "[1044/1762] D loss: 0.4006\n",
      "[1124/1762] D loss: 0.5643\n",
      "[1204/1762] D loss: 0.7096\n",
      "[1284/1762] D loss: 0.6182\n",
      "[1364/1762] D loss: 0.6581\n",
      "[1444/1762] D loss: 0.7141\n",
      "[1524/1762] D loss: 0.6922\n",
      "[1604/1762] D loss: 0.6056\n",
      "[1684/1762] D loss: 0.7767\n",
      "[1762/1762] D loss: 0.8130\n",
      "train error: \n",
      " D loss: 0.685500, D accuracy: 93.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.671452, D accuracy: 94.5% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5960\n",
      "[84/1762] D loss: 0.4623\n",
      "[164/1762] D loss: 0.7955\n",
      "[244/1762] D loss: 0.6800\n",
      "[324/1762] D loss: 0.6157\n",
      "[404/1762] D loss: 0.5678\n",
      "[484/1762] D loss: 0.6858\n",
      "[564/1762] D loss: 0.6139\n",
      "[644/1762] D loss: 0.4691\n",
      "[724/1762] D loss: 0.7596\n",
      "[804/1762] D loss: 0.5901\n",
      "[884/1762] D loss: 0.6479\n",
      "[964/1762] D loss: 0.7190\n",
      "[1044/1762] D loss: 0.6372\n",
      "[1124/1762] D loss: 0.4769\n",
      "[1204/1762] D loss: 0.5752\n",
      "[1284/1762] D loss: 0.5722\n",
      "[1364/1762] D loss: 0.5582\n",
      "[1444/1762] D loss: 0.5753\n",
      "[1524/1762] D loss: 0.3433\n",
      "[1604/1762] D loss: 0.4489\n",
      "[1684/1762] D loss: 0.4596\n",
      "[1762/1762] D loss: 0.3932\n",
      "train error: \n",
      " D loss: 0.585872, D accuracy: 94.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.612997, D accuracy: 93.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3671\n",
      "[84/1762] D loss: 0.4374\n",
      "[164/1762] D loss: 0.3233\n",
      "[244/1762] D loss: 0.4423\n",
      "[324/1762] D loss: 0.7453\n",
      "[404/1762] D loss: 0.7945\n",
      "[484/1762] D loss: 0.3999\n",
      "[564/1762] D loss: 0.3691\n",
      "[644/1762] D loss: 0.6354\n",
      "[724/1762] D loss: 0.8605\n",
      "[804/1762] D loss: 0.3220\n",
      "[884/1762] D loss: 0.3380\n",
      "[964/1762] D loss: 0.2693\n",
      "[1044/1762] D loss: 0.4341\n",
      "[1124/1762] D loss: 0.6359\n",
      "[1204/1762] D loss: 0.5066\n",
      "[1284/1762] D loss: 0.7661\n",
      "[1364/1762] D loss: 0.4549\n",
      "[1444/1762] D loss: 0.3684\n",
      "[1524/1762] D loss: 0.4699\n",
      "[1604/1762] D loss: 0.5079\n",
      "[1684/1762] D loss: 0.3171\n",
      "[1762/1762] D loss: 0.6695\n",
      "train error: \n",
      " D loss: 0.521658, D accuracy: 96.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.528720, D accuracy: 96.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5494\n",
      "[84/1762] D loss: 0.2966\n",
      "[164/1762] D loss: 0.3993\n",
      "[244/1762] D loss: 0.4105\n",
      "[324/1762] D loss: 0.2091\n",
      "[404/1762] D loss: 0.3989\n",
      "[484/1762] D loss: 0.2900\n",
      "[564/1762] D loss: 0.5046\n",
      "[644/1762] D loss: 0.4733\n",
      "[724/1762] D loss: 0.3712\n",
      "[804/1762] D loss: 0.2716\n",
      "[884/1762] D loss: 0.3058\n",
      "[964/1762] D loss: 0.3395\n",
      "[1044/1762] D loss: 0.5015\n",
      "[1124/1762] D loss: 0.3121\n",
      "[1204/1762] D loss: 0.4785\n",
      "[1284/1762] D loss: 0.5779\n",
      "[1364/1762] D loss: 0.1715\n",
      "[1444/1762] D loss: 0.2179\n",
      "[1524/1762] D loss: 0.3426\n",
      "[1604/1762] D loss: 0.5319\n",
      "[1684/1762] D loss: 0.3088\n",
      "[1762/1762] D loss: 0.6501\n",
      "train error: \n",
      " D loss: 0.459072, D accuracy: 97.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.474494, D accuracy: 97.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1294\n",
      "[84/1762] D loss: 0.3605\n",
      "[164/1762] D loss: 0.3429\n",
      "[244/1762] D loss: 0.2777\n",
      "[324/1762] D loss: 0.3328\n",
      "[404/1762] D loss: 0.2421\n",
      "[484/1762] D loss: 0.4196\n",
      "[564/1762] D loss: 0.1507\n",
      "[644/1762] D loss: 0.3305\n",
      "[724/1762] D loss: 0.2661\n",
      "[804/1762] D loss: 0.3953\n",
      "[884/1762] D loss: 0.5076\n",
      "[964/1762] D loss: 0.1973\n",
      "[1044/1762] D loss: 0.2022\n",
      "[1124/1762] D loss: 0.2814\n",
      "[1204/1762] D loss: 0.4202\n",
      "[1284/1762] D loss: 0.2293\n",
      "[1364/1762] D loss: 0.2546\n",
      "[1444/1762] D loss: 0.5273\n",
      "[1524/1762] D loss: 0.3132\n",
      "[1604/1762] D loss: 0.3661\n",
      "[1684/1762] D loss: 0.1328\n",
      "[1762/1762] D loss: 0.1757\n",
      "train error: \n",
      " D loss: 0.364784, D accuracy: 97.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.377822, D accuracy: 97.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2999\n",
      "[84/1762] D loss: 0.3371\n",
      "[164/1762] D loss: 0.3530\n",
      "[244/1762] D loss: 0.1174\n",
      "[324/1762] D loss: 0.1446\n",
      "[404/1762] D loss: 0.2633\n",
      "[484/1762] D loss: 0.1906\n",
      "[564/1762] D loss: 0.1500\n",
      "[644/1762] D loss: 0.2266\n",
      "[724/1762] D loss: 0.3194\n",
      "[804/1762] D loss: 0.2139\n",
      "[884/1762] D loss: 0.1212\n",
      "[964/1762] D loss: 0.3314\n",
      "[1044/1762] D loss: 0.1601\n",
      "[1124/1762] D loss: 0.2750\n",
      "[1204/1762] D loss: 0.2468\n",
      "[1284/1762] D loss: 0.1314\n",
      "[1364/1762] D loss: 0.1532\n",
      "[1444/1762] D loss: 0.2150\n",
      "[1524/1762] D loss: 0.3197\n",
      "[1604/1762] D loss: 0.1543\n",
      "[1684/1762] D loss: 0.2956\n",
      "[1762/1762] D loss: 0.0652\n",
      "train error: \n",
      " D loss: 0.322274, D accuracy: 96.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.318069, D accuracy: 97.3% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1730\n",
      "[84/1762] D loss: 0.1341\n",
      "[164/1762] D loss: 0.2277\n",
      "[244/1762] D loss: 0.1724\n",
      "[324/1762] D loss: 0.1410\n",
      "[404/1762] D loss: 0.1243\n",
      "[484/1762] D loss: 0.0652\n",
      "[564/1762] D loss: 0.0927\n",
      "[644/1762] D loss: 0.1374\n",
      "[724/1762] D loss: 0.3868\n",
      "[804/1762] D loss: 0.1367\n",
      "[884/1762] D loss: 0.1784\n",
      "[964/1762] D loss: 0.1378\n",
      "[1044/1762] D loss: 0.1546\n",
      "[1124/1762] D loss: 0.0862\n",
      "[1204/1762] D loss: 0.0809\n",
      "[1284/1762] D loss: 0.1478\n",
      "[1364/1762] D loss: 0.4162\n",
      "[1444/1762] D loss: 0.2027\n",
      "[1524/1762] D loss: 0.1046\n",
      "[1604/1762] D loss: 0.1053\n",
      "[1684/1762] D loss: 0.1333\n",
      "[1762/1762] D loss: 0.1064\n",
      "train error: \n",
      " D loss: 0.274004, D accuracy: 98.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.286348, D accuracy: 98.4% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0966\n",
      "[84/1762] D loss: 0.0818\n",
      "[164/1762] D loss: 0.4579\n",
      "[244/1762] D loss: 0.1222\n",
      "[324/1762] D loss: 0.4266\n",
      "[404/1762] D loss: 0.2510\n",
      "[484/1762] D loss: 0.2911\n",
      "[564/1762] D loss: 0.2390\n",
      "[644/1762] D loss: 0.1362\n",
      "[724/1762] D loss: 0.1093\n",
      "[804/1762] D loss: 0.0873\n",
      "[884/1762] D loss: 0.1481\n",
      "[964/1762] D loss: 0.0702\n",
      "[1044/1762] D loss: 0.0847\n",
      "[1124/1762] D loss: 0.1054\n",
      "[1204/1762] D loss: 0.0637\n",
      "[1284/1762] D loss: 0.1190\n",
      "[1364/1762] D loss: 0.0635\n",
      "[1444/1762] D loss: 0.0709\n",
      "[1524/1762] D loss: 0.0705\n",
      "[1604/1762] D loss: 0.0871\n",
      "[1684/1762] D loss: 0.0703\n",
      "[1762/1762] D loss: 0.2453\n",
      "train error: \n",
      " D loss: 0.258114, D accuracy: 98.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.268137, D accuracy: 98.3% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0455\n",
      "[84/1762] D loss: 0.2604\n",
      "[164/1762] D loss: 0.1423\n",
      "[244/1762] D loss: 0.2957\n",
      "[324/1762] D loss: 0.0353\n",
      "[404/1762] D loss: 0.0584\n",
      "[484/1762] D loss: 0.0862\n",
      "[564/1762] D loss: 0.1420\n",
      "[644/1762] D loss: 0.0735\n",
      "[724/1762] D loss: 0.1449\n",
      "[804/1762] D loss: 0.1566\n",
      "[884/1762] D loss: 0.0647\n",
      "[964/1762] D loss: 0.0404\n",
      "[1044/1762] D loss: 0.0642\n",
      "[1124/1762] D loss: 0.2484\n",
      "[1204/1762] D loss: 0.2093\n",
      "[1284/1762] D loss: 0.0596\n",
      "[1364/1762] D loss: 0.1281\n",
      "[1444/1762] D loss: 0.0678\n",
      "[1524/1762] D loss: 0.0470\n",
      "[1604/1762] D loss: 0.1041\n",
      "[1684/1762] D loss: 0.0574\n",
      "[1762/1762] D loss: 0.0428\n",
      "train error: \n",
      " D loss: 0.222340, D accuracy: 98.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.218402, D accuracy: 98.8% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0902\n",
      "[84/1762] D loss: 0.1241\n",
      "[164/1762] D loss: 0.1250\n",
      "[244/1762] D loss: 0.1244\n",
      "[324/1762] D loss: 0.0602\n",
      "[404/1762] D loss: 0.1562\n",
      "[484/1762] D loss: 0.1668\n",
      "[564/1762] D loss: 0.0795\n",
      "[644/1762] D loss: 0.0818\n",
      "[724/1762] D loss: 0.5654\n",
      "[804/1762] D loss: 0.0803\n",
      "[884/1762] D loss: 0.1499\n",
      "[964/1762] D loss: 0.1018\n",
      "[1044/1762] D loss: 0.0605\n",
      "[1124/1762] D loss: 0.0311\n",
      "[1204/1762] D loss: 0.2516\n",
      "[1284/1762] D loss: 0.0962\n",
      "[1364/1762] D loss: 0.1044\n",
      "[1444/1762] D loss: 0.2922\n",
      "[1524/1762] D loss: 0.3559\n",
      "[1604/1762] D loss: 0.0470\n",
      "[1684/1762] D loss: 0.0658\n",
      "[1762/1762] D loss: 0.0568\n",
      "train error: \n",
      " D loss: 0.209916, D accuracy: 99.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.202474, D accuracy: 99.8% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2559\n",
      "[84/1762] D loss: 0.0460\n",
      "[164/1762] D loss: 0.0436\n",
      "[244/1762] D loss: 0.1133\n",
      "[324/1762] D loss: 0.0546\n",
      "[404/1762] D loss: 0.0585\n",
      "[484/1762] D loss: 0.0647\n",
      "[564/1762] D loss: 0.0259\n",
      "[644/1762] D loss: 0.0504\n",
      "[724/1762] D loss: 0.0735\n",
      "[804/1762] D loss: 0.0606\n",
      "[884/1762] D loss: 0.1443\n",
      "[964/1762] D loss: 0.0508\n",
      "[1044/1762] D loss: 0.0865\n",
      "[1124/1762] D loss: 0.0954\n",
      "[1204/1762] D loss: 0.1276\n",
      "[1284/1762] D loss: 0.0565\n",
      "[1364/1762] D loss: 0.0681\n",
      "[1444/1762] D loss: 0.0341\n",
      "[1524/1762] D loss: 0.2547\n",
      "[1604/1762] D loss: 0.0275\n",
      "[1684/1762] D loss: 0.1111\n",
      "[1762/1762] D loss: 0.0338\n",
      "train error: \n",
      " D loss: 0.241966, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.254726, D accuracy: 99.4% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0906\n",
      "[84/1762] D loss: 0.1378\n",
      "[164/1762] D loss: 0.5364\n",
      "[244/1762] D loss: 0.0497\n",
      "[324/1762] D loss: 0.0769\n",
      "[404/1762] D loss: 0.0674\n",
      "[484/1762] D loss: 0.0758\n",
      "[564/1762] D loss: 0.0517\n",
      "[644/1762] D loss: 0.0241\n",
      "[724/1762] D loss: 0.1196\n",
      "[804/1762] D loss: 0.0231\n",
      "[884/1762] D loss: 0.1435\n",
      "[964/1762] D loss: 0.0341\n",
      "[1044/1762] D loss: 0.0252\n",
      "[1124/1762] D loss: 0.0707\n",
      "[1204/1762] D loss: 0.1008\n",
      "[1284/1762] D loss: 0.2467\n",
      "[1364/1762] D loss: 0.0483\n",
      "[1444/1762] D loss: 0.0693\n",
      "[1524/1762] D loss: 0.0274\n",
      "[1604/1762] D loss: 0.0656\n",
      "[1684/1762] D loss: 0.0738\n",
      "[1762/1762] D loss: 0.0146\n",
      "train error: \n",
      " D loss: 0.214086, D accuracy: 99.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.228603, D accuracy: 99.2% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0294\n",
      "[84/1762] D loss: 0.0244\n",
      "[164/1762] D loss: 0.1162\n",
      "[244/1762] D loss: 0.0457\n",
      "[324/1762] D loss: 0.0566\n",
      "[404/1762] D loss: 0.0689\n",
      "[484/1762] D loss: 0.0618\n",
      "[564/1762] D loss: 0.0444\n",
      "[644/1762] D loss: 0.0555\n",
      "[724/1762] D loss: 0.0327\n",
      "[804/1762] D loss: 0.0384\n",
      "[884/1762] D loss: 0.0279\n",
      "[964/1762] D loss: 0.0528\n",
      "[1044/1762] D loss: 0.0255\n",
      "[1124/1762] D loss: 0.0327\n",
      "[1204/1762] D loss: 0.0879\n",
      "[1284/1762] D loss: 0.0751\n",
      "[1364/1762] D loss: 0.0215\n",
      "[1444/1762] D loss: 0.0419\n",
      "[1524/1762] D loss: 0.0527\n",
      "[1604/1762] D loss: 0.0742\n",
      "[1684/1762] D loss: 0.0239\n",
      "[1762/1762] D loss: 0.0495\n",
      "train error: \n",
      " D loss: 0.187866, D accuracy: 99.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.182343, D accuracy: 99.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1216\n",
      "[84/1762] D loss: 0.0253\n",
      "[164/1762] D loss: 0.0104\n",
      "[244/1762] D loss: 0.0365\n",
      "[324/1762] D loss: 0.1569\n",
      "[404/1762] D loss: 0.1601\n",
      "[484/1762] D loss: 0.0202\n",
      "[564/1762] D loss: 0.1040\n",
      "[644/1762] D loss: 0.0382\n",
      "[724/1762] D loss: 0.1062\n",
      "[804/1762] D loss: 0.0304\n",
      "[884/1762] D loss: 0.0525\n",
      "[964/1762] D loss: 0.0808\n",
      "[1044/1762] D loss: 0.0543\n",
      "[1124/1762] D loss: 0.0403\n",
      "[1204/1762] D loss: 0.0281\n",
      "[1284/1762] D loss: 0.0550\n",
      "[1364/1762] D loss: 0.0202\n",
      "[1444/1762] D loss: 0.0561\n",
      "[1524/1762] D loss: 0.0702\n",
      "[1604/1762] D loss: 0.0887\n",
      "[1684/1762] D loss: 0.0231\n",
      "[1762/1762] D loss: 0.1313\n",
      "train error: \n",
      " D loss: 0.190971, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.202782, D accuracy: 99.9% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0848\n",
      "[84/1762] D loss: 0.0118\n",
      "[164/1762] D loss: 0.0359\n",
      "[244/1762] D loss: 0.0540\n",
      "[324/1762] D loss: 0.1003\n",
      "[404/1762] D loss: 0.1381\n",
      "[484/1762] D loss: 0.0303\n",
      "[564/1762] D loss: 0.0289\n",
      "[644/1762] D loss: 0.1847\n",
      "[724/1762] D loss: 0.2496\n",
      "[804/1762] D loss: 0.0143\n",
      "[884/1762] D loss: 0.0415\n",
      "[964/1762] D loss: 0.0279\n",
      "[1044/1762] D loss: 0.0240\n",
      "[1124/1762] D loss: 0.0111\n",
      "[1204/1762] D loss: 0.1255\n",
      "[1284/1762] D loss: 0.0560\n",
      "[1364/1762] D loss: 0.1175\n",
      "[1444/1762] D loss: 0.0198\n",
      "[1524/1762] D loss: 0.1479\n",
      "[1604/1762] D loss: 0.0149\n",
      "[1684/1762] D loss: 0.1679\n",
      "[1762/1762] D loss: 0.0352\n",
      "train error: \n",
      " D loss: 0.221041, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.231721, D accuracy: 99.7% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0250\n",
      "[84/1762] D loss: 0.0285\n",
      "[164/1762] D loss: 0.0256\n",
      "[244/1762] D loss: 0.0564\n",
      "[324/1762] D loss: 0.0481\n",
      "[404/1762] D loss: 0.1262\n",
      "[484/1762] D loss: 0.0272\n",
      "[564/1762] D loss: 0.1664\n",
      "[644/1762] D loss: 0.0191\n",
      "[724/1762] D loss: 0.1260\n",
      "[804/1762] D loss: 0.0265\n",
      "[884/1762] D loss: 0.0476\n",
      "[964/1762] D loss: 0.0269\n",
      "[1044/1762] D loss: 0.0609\n",
      "[1124/1762] D loss: 0.0202\n",
      "[1204/1762] D loss: 0.0248\n",
      "[1284/1762] D loss: 0.0097\n",
      "[1364/1762] D loss: 0.0273\n",
      "[1444/1762] D loss: 0.0407\n",
      "[1524/1762] D loss: 0.0348\n",
      "[1604/1762] D loss: 0.0609\n",
      "[1684/1762] D loss: 0.0175\n",
      "[1762/1762] D loss: 0.0502\n",
      "train error: \n",
      " D loss: 0.165302, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.173437, D accuracy: 99.4% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0161\n",
      "[84/1762] D loss: 0.0250\n",
      "[164/1762] D loss: 0.0137\n",
      "[244/1762] D loss: 0.0119\n",
      "[324/1762] D loss: 0.0197\n",
      "[404/1762] D loss: 0.0748\n",
      "[484/1762] D loss: 0.0204\n",
      "[564/1762] D loss: 0.0155\n",
      "[644/1762] D loss: 0.0603\n",
      "[724/1762] D loss: 0.0301\n",
      "[804/1762] D loss: 0.0193\n",
      "[884/1762] D loss: 0.0360\n",
      "[964/1762] D loss: 0.0389\n",
      "[1044/1762] D loss: 0.0459\n",
      "[1124/1762] D loss: 0.0353\n",
      "[1204/1762] D loss: 0.0211\n",
      "[1284/1762] D loss: 0.1672\n",
      "[1364/1762] D loss: 0.0316\n",
      "[1444/1762] D loss: 0.0164\n",
      "[1524/1762] D loss: 0.0212\n",
      "[1604/1762] D loss: 0.0288\n",
      "[1684/1762] D loss: 0.0230\n",
      "[1762/1762] D loss: 0.0312\n",
      "train error: \n",
      " D loss: 0.170497, D accuracy: 99.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.179566, D accuracy: 99.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0326\n",
      "[84/1762] D loss: 0.0100\n",
      "[164/1762] D loss: 0.0737\n",
      "[244/1762] D loss: 0.0199\n",
      "[324/1762] D loss: 0.0636\n",
      "[404/1762] D loss: 0.0248\n",
      "[484/1762] D loss: 0.0210\n",
      "[564/1762] D loss: 0.0207\n",
      "[644/1762] D loss: 0.0459\n",
      "[724/1762] D loss: 0.0477\n",
      "[804/1762] D loss: 0.0801\n",
      "[884/1762] D loss: 0.0199\n",
      "[964/1762] D loss: 0.0400\n",
      "[1044/1762] D loss: 0.0226\n",
      "[1124/1762] D loss: 0.0178\n",
      "[1204/1762] D loss: 0.0136\n",
      "[1284/1762] D loss: 0.0499\n",
      "[1364/1762] D loss: 0.0207\n",
      "[1444/1762] D loss: 0.1502\n",
      "[1524/1762] D loss: 0.0094\n",
      "[1604/1762] D loss: 0.0282\n",
      "[1684/1762] D loss: 0.0163\n",
      "[1762/1762] D loss: 0.0233\n",
      "train error: \n",
      " D loss: 0.158539, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.161334, D accuracy: 99.8% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0295\n",
      "[84/1762] D loss: 0.0489\n",
      "[164/1762] D loss: 0.0263\n",
      "[244/1762] D loss: 0.0157\n",
      "[324/1762] D loss: 0.0253\n",
      "[404/1762] D loss: 0.0071\n",
      "[484/1762] D loss: 0.0359\n",
      "[564/1762] D loss: 0.0235\n",
      "[644/1762] D loss: 0.0408\n",
      "[724/1762] D loss: 0.0122\n",
      "[804/1762] D loss: 0.0272\n",
      "[884/1762] D loss: 0.0278\n",
      "[964/1762] D loss: 0.0301\n",
      "[1044/1762] D loss: 0.0295\n",
      "[1124/1762] D loss: 0.3118\n",
      "[1204/1762] D loss: 0.1245\n",
      "[1284/1762] D loss: 0.0166\n",
      "[1364/1762] D loss: 0.0085\n",
      "[1444/1762] D loss: 0.0329\n",
      "[1524/1762] D loss: 0.0080\n",
      "[1604/1762] D loss: 0.0448\n",
      "[1684/1762] D loss: 0.0364\n",
      "[1762/1762] D loss: 0.0554\n",
      "train error: \n",
      " D loss: 0.152088, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.162827, D accuracy: 99.4% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0848\n",
      "[84/1762] D loss: 0.0134\n",
      "[164/1762] D loss: 0.0085\n",
      "[244/1762] D loss: 0.0462\n",
      "[324/1762] D loss: 0.0199\n",
      "[404/1762] D loss: 0.0198\n",
      "[484/1762] D loss: 0.0424\n",
      "[564/1762] D loss: 0.0378\n",
      "[644/1762] D loss: 0.0293\n",
      "[724/1762] D loss: 0.0149\n",
      "[804/1762] D loss: 0.0181\n",
      "[884/1762] D loss: 0.0171\n",
      "[964/1762] D loss: 0.0351\n",
      "[1044/1762] D loss: 0.0189\n",
      "[1124/1762] D loss: 0.0423\n",
      "[1204/1762] D loss: 0.0687\n",
      "[1284/1762] D loss: 0.0191\n",
      "[1364/1762] D loss: 0.0168\n",
      "[1444/1762] D loss: 0.0136\n",
      "[1524/1762] D loss: 0.0314\n",
      "[1604/1762] D loss: 0.0113\n",
      "[1684/1762] D loss: 0.0251\n",
      "[1762/1762] D loss: 0.0513\n",
      "train error: \n",
      " D loss: 0.165687, D accuracy: 99.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.179102, D accuracy: 100.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0183\n",
      "[84/1762] D loss: 0.0129\n",
      "[164/1762] D loss: 0.0067\n",
      "[244/1762] D loss: 0.0374\n",
      "[324/1762] D loss: 0.0168\n",
      "[404/1762] D loss: 0.0380\n",
      "[484/1762] D loss: 0.0398\n",
      "[564/1762] D loss: 0.0118\n",
      "[644/1762] D loss: 0.0059\n",
      "[724/1762] D loss: 0.0043\n",
      "[804/1762] D loss: 0.0143\n",
      "[884/1762] D loss: 0.0307\n",
      "[964/1762] D loss: 0.0122\n",
      "[1044/1762] D loss: 0.0148\n",
      "[1124/1762] D loss: 0.0569\n",
      "[1204/1762] D loss: 0.0182\n",
      "[1284/1762] D loss: 0.0330\n",
      "[1364/1762] D loss: 0.0552\n",
      "[1444/1762] D loss: 0.0214\n",
      "[1524/1762] D loss: 0.0140\n",
      "[1604/1762] D loss: 0.0366\n",
      "[1684/1762] D loss: 0.0085\n",
      "[1762/1762] D loss: 0.0316\n",
      "train error: \n",
      " D loss: 0.149340, D accuracy: 99.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.152964, D accuracy: 99.9% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0174\n",
      "[84/1762] D loss: 0.0098\n",
      "[164/1762] D loss: 0.0599\n",
      "[244/1762] D loss: 0.0581\n",
      "[324/1762] D loss: 0.0113\n",
      "[404/1762] D loss: 0.0383\n",
      "[484/1762] D loss: 0.0326\n",
      "[564/1762] D loss: 0.0427\n",
      "[644/1762] D loss: 0.0670\n",
      "[724/1762] D loss: 0.0117\n",
      "[804/1762] D loss: 0.0249\n",
      "[884/1762] D loss: 0.0168\n",
      "[964/1762] D loss: 0.0091\n",
      "[1044/1762] D loss: 0.0183\n",
      "[1124/1762] D loss: 0.0217\n",
      "[1204/1762] D loss: 0.0141\n",
      "[1284/1762] D loss: 0.0452\n",
      "[1364/1762] D loss: 0.0128\n",
      "[1444/1762] D loss: 0.0087\n",
      "[1524/1762] D loss: 0.0604\n",
      "[1604/1762] D loss: 0.0089\n",
      "[1684/1762] D loss: 0.0175\n",
      "[1762/1762] D loss: 0.0102\n",
      "train error: \n",
      " D loss: 0.177152, D accuracy: 99.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.183972, D accuracy: 100.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908\n",
      "[84/1762] D loss: 1.4085\n",
      "[164/1762] D loss: 1.4139\n",
      "[244/1762] D loss: 1.3815\n",
      "[324/1762] D loss: 1.4030\n",
      "[404/1762] D loss: 1.3886\n",
      "[484/1762] D loss: 1.3780\n",
      "[564/1762] D loss: 1.3984\n",
      "[644/1762] D loss: 1.3666\n",
      "[724/1762] D loss: 1.3842\n",
      "[804/1762] D loss: 1.3958\n",
      "[884/1762] D loss: 1.3818\n",
      "[964/1762] D loss: 1.3961\n",
      "[1044/1762] D loss: 1.3927\n",
      "[1124/1762] D loss: 1.3967\n",
      "[1204/1762] D loss: 1.3705\n",
      "[1284/1762] D loss: 1.3863\n",
      "[1364/1762] D loss: 1.3709\n",
      "[1444/1762] D loss: 1.3625\n",
      "[1524/1762] D loss: 1.3900\n",
      "[1604/1762] D loss: 1.3858\n",
      "[1684/1762] D loss: 1.3851\n",
      "[1762/1762] D loss: 1.3861\n",
      "train error: \n",
      " D loss: 1.383284, D accuracy: 51.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385848, D accuracy: 50.7% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905\n",
      "[84/1762] D loss: 1.3887\n",
      "[164/1762] D loss: 1.4025\n",
      "[244/1762] D loss: 1.3790\n",
      "[324/1762] D loss: 1.3945\n",
      "[404/1762] D loss: 1.3926\n",
      "[484/1762] D loss: 1.3613\n",
      "[564/1762] D loss: 1.3951\n",
      "[644/1762] D loss: 1.3786\n",
      "[724/1762] D loss: 1.3890\n",
      "[804/1762] D loss: 1.3915\n",
      "[884/1762] D loss: 1.3763\n",
      "[964/1762] D loss: 1.3671\n",
      "[1044/1762] D loss: 1.3737\n",
      "[1124/1762] D loss: 1.3827\n",
      "[1204/1762] D loss: 1.3839\n",
      "[1284/1762] D loss: 1.3748\n",
      "[1364/1762] D loss: 1.3836\n",
      "[1444/1762] D loss: 1.3775\n",
      "[1524/1762] D loss: 1.3609\n",
      "[1604/1762] D loss: 1.3849\n",
      "[1684/1762] D loss: 1.3792\n",
      "[1762/1762] D loss: 1.3664\n",
      "train error: \n",
      " D loss: 1.376672, D accuracy: 54.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377306, D accuracy: 53.3% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3793\n",
      "[84/1762] D loss: 1.3749\n",
      "[164/1762] D loss: 1.3667\n",
      "[244/1762] D loss: 1.3819\n",
      "[324/1762] D loss: 1.3755\n",
      "[404/1762] D loss: 1.3670\n",
      "[484/1762] D loss: 1.3659\n",
      "[564/1762] D loss: 1.3958\n",
      "[644/1762] D loss: 1.3687\n",
      "[724/1762] D loss: 1.3799\n",
      "[804/1762] D loss: 1.3839\n",
      "[884/1762] D loss: 1.3699\n",
      "[964/1762] D loss: 1.3636\n",
      "[1044/1762] D loss: 1.3667\n",
      "[1124/1762] D loss: 1.3865\n",
      "[1204/1762] D loss: 1.3593\n",
      "[1284/1762] D loss: 1.3770\n",
      "[1364/1762] D loss: 1.3792\n",
      "[1444/1762] D loss: 1.3819\n",
      "[1524/1762] D loss: 1.3697\n",
      "[1604/1762] D loss: 1.3754\n",
      "[1684/1762] D loss: 1.3925\n",
      "[1762/1762] D loss: 1.3866\n",
      "train error: \n",
      " D loss: 1.374491, D accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374352, D accuracy: 57.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3691\n",
      "[84/1762] D loss: 1.3758\n",
      "[164/1762] D loss: 1.3948\n",
      "[244/1762] D loss: 1.3812\n",
      "[324/1762] D loss: 1.3628\n",
      "[404/1762] D loss: 1.3821\n",
      "[484/1762] D loss: 1.3535\n",
      "[564/1762] D loss: 1.3761\n",
      "[644/1762] D loss: 1.3761\n",
      "[724/1762] D loss: 1.3876\n",
      "[804/1762] D loss: 1.3527\n",
      "[884/1762] D loss: 1.3748\n",
      "[964/1762] D loss: 1.3769\n",
      "[1044/1762] D loss: 1.3823\n",
      "[1124/1762] D loss: 1.3786\n",
      "[1204/1762] D loss: 1.3940\n",
      "[1284/1762] D loss: 1.3833\n",
      "[1364/1762] D loss: 1.3810\n",
      "[1444/1762] D loss: 1.3816\n",
      "[1524/1762] D loss: 1.3908\n",
      "[1604/1762] D loss: 1.3633\n",
      "[1684/1762] D loss: 1.3742\n",
      "[1762/1762] D loss: 1.3517\n",
      "train error: \n",
      " D loss: 1.371396, D accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371815, D accuracy: 60.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3822\n",
      "[84/1762] D loss: 1.3683\n",
      "[164/1762] D loss: 1.3932\n",
      "[244/1762] D loss: 1.3648\n",
      "[324/1762] D loss: 1.3956\n",
      "[404/1762] D loss: 1.3845\n",
      "[484/1762] D loss: 1.3756\n",
      "[564/1762] D loss: 1.3449\n",
      "[644/1762] D loss: 1.3831\n",
      "[724/1762] D loss: 1.3898\n",
      "[804/1762] D loss: 1.3899\n",
      "[884/1762] D loss: 1.3869\n",
      "[964/1762] D loss: 1.3751\n",
      "[1044/1762] D loss: 1.3897\n",
      "[1124/1762] D loss: 1.3693\n",
      "[1204/1762] D loss: 1.3766\n",
      "[1284/1762] D loss: 1.3582\n",
      "[1364/1762] D loss: 1.3714\n",
      "[1444/1762] D loss: 1.3913\n",
      "[1524/1762] D loss: 1.3671\n",
      "[1604/1762] D loss: 1.3691\n",
      "[1684/1762] D loss: 1.3909\n",
      "[1762/1762] D loss: 1.3823\n",
      "train error: \n",
      " D loss: 1.367967, D accuracy: 60.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369836, D accuracy: 62.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3744\n",
      "[84/1762] D loss: 1.3798\n",
      "[164/1762] D loss: 1.3796\n",
      "[244/1762] D loss: 1.3782\n",
      "[324/1762] D loss: 1.3890\n",
      "[404/1762] D loss: 1.3779\n",
      "[484/1762] D loss: 1.3601\n",
      "[564/1762] D loss: 1.3634\n",
      "[644/1762] D loss: 1.3536\n",
      "[724/1762] D loss: 1.3630\n",
      "[804/1762] D loss: 1.3818\n",
      "[884/1762] D loss: 1.3757\n",
      "[964/1762] D loss: 1.3467\n",
      "[1044/1762] D loss: 1.3798\n",
      "[1124/1762] D loss: 1.3852\n",
      "[1204/1762] D loss: 1.3823\n",
      "[1284/1762] D loss: 1.3677\n",
      "[1364/1762] D loss: 1.3657\n",
      "[1444/1762] D loss: 1.3787\n",
      "[1524/1762] D loss: 1.3767\n",
      "[1604/1762] D loss: 1.3721\n",
      "[1684/1762] D loss: 1.3702\n",
      "[1762/1762] D loss: 1.3824\n",
      "train error: \n",
      " D loss: 1.367183, D accuracy: 61.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366643, D accuracy: 62.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3653\n",
      "[84/1762] D loss: 1.3686\n",
      "[164/1762] D loss: 1.3672\n",
      "[244/1762] D loss: 1.3461\n",
      "[324/1762] D loss: 1.3668\n",
      "[404/1762] D loss: 1.3648\n",
      "[484/1762] D loss: 1.3643\n",
      "[564/1762] D loss: 1.3855\n",
      "[644/1762] D loss: 1.4039\n",
      "[724/1762] D loss: 1.3361\n",
      "[804/1762] D loss: 1.3759\n",
      "[884/1762] D loss: 1.3787\n",
      "[964/1762] D loss: 1.3780\n",
      "[1044/1762] D loss: 1.3784\n",
      "[1124/1762] D loss: 1.3652\n",
      "[1204/1762] D loss: 1.3615\n",
      "[1284/1762] D loss: 1.3935\n",
      "[1364/1762] D loss: 1.3588\n",
      "[1444/1762] D loss: 1.3792\n",
      "[1524/1762] D loss: 1.3692\n",
      "[1604/1762] D loss: 1.3663\n",
      "[1684/1762] D loss: 1.3789\n",
      "[1762/1762] D loss: 1.3628\n",
      "train error: \n",
      " D loss: 1.363193, D accuracy: 63.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364929, D accuracy: 62.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4079\n",
      "[84/1762] D loss: 1.3725\n",
      "[164/1762] D loss: 1.3676\n",
      "[244/1762] D loss: 1.3539\n",
      "[324/1762] D loss: 1.3918\n",
      "[404/1762] D loss: 1.3862\n",
      "[484/1762] D loss: 1.3723\n",
      "[564/1762] D loss: 1.3409\n",
      "[644/1762] D loss: 1.3662\n",
      "[724/1762] D loss: 1.3802\n",
      "[804/1762] D loss: 1.3634\n",
      "[884/1762] D loss: 1.3504\n",
      "[964/1762] D loss: 1.3552\n",
      "[1044/1762] D loss: 1.3729\n",
      "[1124/1762] D loss: 1.3774\n",
      "[1204/1762] D loss: 1.3646\n",
      "[1284/1762] D loss: 1.3461\n",
      "[1364/1762] D loss: 1.3598\n",
      "[1444/1762] D loss: 1.3492\n",
      "[1524/1762] D loss: 1.3438\n",
      "[1604/1762] D loss: 1.3651\n",
      "[1684/1762] D loss: 1.3878\n",
      "[1762/1762] D loss: 1.3498\n",
      "train error: \n",
      " D loss: 1.361635, D accuracy: 64.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360911, D accuracy: 64.1% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3597\n",
      "[84/1762] D loss: 1.3787\n",
      "[164/1762] D loss: 1.3837\n",
      "[244/1762] D loss: 1.3760\n",
      "[324/1762] D loss: 1.3685\n",
      "[404/1762] D loss: 1.3547\n",
      "[484/1762] D loss: 1.3436\n",
      "[564/1762] D loss: 1.3904\n",
      "[644/1762] D loss: 1.3666\n",
      "[724/1762] D loss: 1.3603\n",
      "[804/1762] D loss: 1.3476\n",
      "[884/1762] D loss: 1.3630\n",
      "[964/1762] D loss: 1.3703\n",
      "[1044/1762] D loss: 1.3765\n",
      "[1124/1762] D loss: 1.3439\n",
      "[1204/1762] D loss: 1.3683\n",
      "[1284/1762] D loss: 1.3627\n",
      "[1364/1762] D loss: 1.3648\n",
      "[1444/1762] D loss: 1.3687\n",
      "[1524/1762] D loss: 1.3589\n",
      "[1604/1762] D loss: 1.3581\n",
      "[1684/1762] D loss: 1.3534\n",
      "[1762/1762] D loss: 1.3813\n",
      "train error: \n",
      " D loss: 1.358728, D accuracy: 64.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359070, D accuracy: 64.9% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3433\n",
      "[84/1762] D loss: 1.3614\n",
      "[164/1762] D loss: 1.3749\n",
      "[244/1762] D loss: 1.3591\n",
      "[324/1762] D loss: 1.3734\n",
      "[404/1762] D loss: 1.3588\n",
      "[484/1762] D loss: 1.3585\n",
      "[564/1762] D loss: 1.3861\n",
      "[644/1762] D loss: 1.3655\n",
      "[724/1762] D loss: 1.3545\n",
      "[804/1762] D loss: 1.3813\n",
      "[884/1762] D loss: 1.3491\n",
      "[964/1762] D loss: 1.3775\n",
      "[1044/1762] D loss: 1.3688\n",
      "[1124/1762] D loss: 1.3866\n",
      "[1204/1762] D loss: 1.3531\n",
      "[1284/1762] D loss: 1.3725\n",
      "[1364/1762] D loss: 1.3616\n",
      "[1444/1762] D loss: 1.3512\n",
      "[1524/1762] D loss: 1.3686\n",
      "[1604/1762] D loss: 1.3624\n",
      "[1684/1762] D loss: 1.3679\n",
      "[1762/1762] D loss: 1.3620\n",
      "train error: \n",
      " D loss: 1.355132, D accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359148, D accuracy: 66.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3494\n",
      "[84/1762] D loss: 1.3819\n",
      "[164/1762] D loss: 1.3590\n",
      "[244/1762] D loss: 1.3578\n",
      "[324/1762] D loss: 1.3612\n",
      "[404/1762] D loss: 1.3642\n",
      "[484/1762] D loss: 1.3712\n",
      "[564/1762] D loss: 1.3289\n",
      "[644/1762] D loss: 1.3373\n",
      "[724/1762] D loss: 1.3210\n",
      "[804/1762] D loss: 1.3639\n",
      "[884/1762] D loss: 1.3836\n",
      "[964/1762] D loss: 1.3273\n",
      "[1044/1762] D loss: 1.3446\n",
      "[1124/1762] D loss: 1.3648\n",
      "[1204/1762] D loss: 1.3377\n",
      "[1284/1762] D loss: 1.3776\n",
      "[1364/1762] D loss: 1.3597\n",
      "[1444/1762] D loss: 1.3407\n",
      "[1524/1762] D loss: 1.3686\n",
      "[1604/1762] D loss: 1.3537\n",
      "[1684/1762] D loss: 1.3612\n",
      "[1762/1762] D loss: 1.3214\n",
      "train error: \n",
      " D loss: 1.351618, D accuracy: 66.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354206, D accuracy: 66.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3482\n",
      "[84/1762] D loss: 1.3377\n",
      "[164/1762] D loss: 1.3711\n",
      "[244/1762] D loss: 1.3725\n",
      "[324/1762] D loss: 1.3531\n",
      "[404/1762] D loss: 1.3875\n",
      "[484/1762] D loss: 1.3464\n",
      "[564/1762] D loss: 1.3588\n",
      "[644/1762] D loss: 1.3360\n",
      "[724/1762] D loss: 1.3667\n",
      "[804/1762] D loss: 1.3747\n",
      "[884/1762] D loss: 1.3826\n",
      "[964/1762] D loss: 1.3500\n",
      "[1044/1762] D loss: 1.3467\n",
      "[1124/1762] D loss: 1.3524\n",
      "[1204/1762] D loss: 1.3737\n",
      "[1284/1762] D loss: 1.3417\n",
      "[1364/1762] D loss: 1.3687\n",
      "[1444/1762] D loss: 1.3653\n",
      "[1524/1762] D loss: 1.3412\n",
      "[1604/1762] D loss: 1.3554\n",
      "[1684/1762] D loss: 1.3553\n",
      "[1762/1762] D loss: 1.3396\n",
      "train error: \n",
      " D loss: 1.349224, D accuracy: 66.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350685, D accuracy: 68.2% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3683\n",
      "[84/1762] D loss: 1.3483\n",
      "[164/1762] D loss: 1.3618\n",
      "[244/1762] D loss: 1.3762\n",
      "[324/1762] D loss: 1.3349\n",
      "[404/1762] D loss: 1.3601\n",
      "[484/1762] D loss: 1.3423\n",
      "[564/1762] D loss: 1.3528\n",
      "[644/1762] D loss: 1.3583\n",
      "[724/1762] D loss: 1.3636\n",
      "[804/1762] D loss: 1.3658\n",
      "[884/1762] D loss: 1.3350\n",
      "[964/1762] D loss: 1.3632\n",
      "[1044/1762] D loss: 1.3512\n",
      "[1124/1762] D loss: 1.3654\n",
      "[1204/1762] D loss: 1.3524\n",
      "[1284/1762] D loss: 1.3612\n",
      "[1364/1762] D loss: 1.3537\n",
      "[1444/1762] D loss: 1.3744\n",
      "[1524/1762] D loss: 1.3413\n",
      "[1604/1762] D loss: 1.3332\n",
      "[1684/1762] D loss: 1.3588\n",
      "[1762/1762] D loss: 1.3365\n",
      "train error: \n",
      " D loss: 1.344982, D accuracy: 68.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346399, D accuracy: 68.1% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3722\n",
      "[84/1762] D loss: 1.3727\n",
      "[164/1762] D loss: 1.3513\n",
      "[244/1762] D loss: 1.3789\n",
      "[324/1762] D loss: 1.3792\n",
      "[404/1762] D loss: 1.3331\n",
      "[484/1762] D loss: 1.3755\n",
      "[564/1762] D loss: 1.3260\n",
      "[644/1762] D loss: 1.3558\n",
      "[724/1762] D loss: 1.3752\n",
      "[804/1762] D loss: 1.3331\n",
      "[884/1762] D loss: 1.3827\n",
      "[964/1762] D loss: 1.3481\n",
      "[1044/1762] D loss: 1.3675\n",
      "[1124/1762] D loss: 1.3528\n",
      "[1204/1762] D loss: 1.3490\n",
      "[1284/1762] D loss: 1.3761\n",
      "[1364/1762] D loss: 1.3715\n",
      "[1444/1762] D loss: 1.3331\n",
      "[1524/1762] D loss: 1.3617\n",
      "[1604/1762] D loss: 1.3483\n",
      "[1684/1762] D loss: 1.3263\n",
      "[1762/1762] D loss: 1.3363\n",
      "train error: \n",
      " D loss: 1.341459, D accuracy: 68.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342498, D accuracy: 69.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3507\n",
      "[84/1762] D loss: 1.3697\n",
      "[164/1762] D loss: 1.3649\n",
      "[244/1762] D loss: 1.3485\n",
      "[324/1762] D loss: 1.3523\n",
      "[404/1762] D loss: 1.3514\n",
      "[484/1762] D loss: 1.3563\n",
      "[564/1762] D loss: 1.3630\n",
      "[644/1762] D loss: 1.3206\n",
      "[724/1762] D loss: 1.3643\n",
      "[804/1762] D loss: 1.3496\n",
      "[884/1762] D loss: 1.3385\n",
      "[964/1762] D loss: 1.3114\n",
      "[1044/1762] D loss: 1.3400\n",
      "[1124/1762] D loss: 1.3573\n",
      "[1204/1762] D loss: 1.3734\n",
      "[1284/1762] D loss: 1.3585\n",
      "[1364/1762] D loss: 1.3584\n",
      "[1444/1762] D loss: 1.3818\n",
      "[1524/1762] D loss: 1.3277\n",
      "[1604/1762] D loss: 1.3478\n",
      "[1684/1762] D loss: 1.3387\n",
      "[1762/1762] D loss: 1.3291\n",
      "train error: \n",
      " D loss: 1.339288, D accuracy: 68.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342136, D accuracy: 69.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3792\n",
      "[84/1762] D loss: 1.3507\n",
      "[164/1762] D loss: 1.3352\n",
      "[244/1762] D loss: 1.3727\n",
      "[324/1762] D loss: 1.3497\n",
      "[404/1762] D loss: 1.3305\n",
      "[484/1762] D loss: 1.3669\n",
      "[564/1762] D loss: 1.3360\n",
      "[644/1762] D loss: 1.3353\n",
      "[724/1762] D loss: 1.2963\n",
      "[804/1762] D loss: 1.3698\n",
      "[884/1762] D loss: 1.3530\n",
      "[964/1762] D loss: 1.3734\n",
      "[1044/1762] D loss: 1.3430\n",
      "[1124/1762] D loss: 1.3636\n",
      "[1204/1762] D loss: 1.3813\n",
      "[1284/1762] D loss: 1.3152\n",
      "[1364/1762] D loss: 1.3241\n",
      "[1444/1762] D loss: 1.3788\n",
      "[1524/1762] D loss: 1.3269\n",
      "[1604/1762] D loss: 1.3644\n",
      "[1684/1762] D loss: 1.3532\n",
      "[1762/1762] D loss: 1.3483\n",
      "train error: \n",
      " D loss: 1.333686, D accuracy: 69.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338379, D accuracy: 70.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3427\n",
      "[84/1762] D loss: 1.3679\n",
      "[164/1762] D loss: 1.3476\n",
      "[244/1762] D loss: 1.3559\n",
      "[324/1762] D loss: 1.3405\n",
      "[404/1762] D loss: 1.3308\n",
      "[484/1762] D loss: 1.3404\n",
      "[564/1762] D loss: 1.3515\n",
      "[644/1762] D loss: 1.3137\n",
      "[724/1762] D loss: 1.3461\n",
      "[804/1762] D loss: 1.3309\n",
      "[884/1762] D loss: 1.3358\n",
      "[964/1762] D loss: 1.3241\n",
      "[1044/1762] D loss: 1.3095\n",
      "[1124/1762] D loss: 1.3181\n",
      "[1204/1762] D loss: 1.3548\n",
      "[1284/1762] D loss: 1.3490\n",
      "[1364/1762] D loss: 1.3590\n",
      "[1444/1762] D loss: 1.3426\n",
      "[1524/1762] D loss: 1.3460\n",
      "[1604/1762] D loss: 1.3458\n",
      "[1684/1762] D loss: 1.3714\n",
      "[1762/1762] D loss: 1.3265\n",
      "train error: \n",
      " D loss: 1.329712, D accuracy: 70.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332422, D accuracy: 70.7% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3049\n",
      "[84/1762] D loss: 1.3702\n",
      "[164/1762] D loss: 1.3451\n",
      "[244/1762] D loss: 1.3385\n",
      "[324/1762] D loss: 1.3402\n",
      "[404/1762] D loss: 1.3592\n",
      "[484/1762] D loss: 1.3610\n",
      "[564/1762] D loss: 1.3443\n",
      "[644/1762] D loss: 1.2839\n",
      "[724/1762] D loss: 1.3179\n",
      "[804/1762] D loss: 1.3301\n",
      "[884/1762] D loss: 1.3510\n",
      "[964/1762] D loss: 1.3376\n",
      "[1044/1762] D loss: 1.3876\n",
      "[1124/1762] D loss: 1.3527\n",
      "[1204/1762] D loss: 1.3360\n",
      "[1284/1762] D loss: 1.3328\n",
      "[1364/1762] D loss: 1.3084\n",
      "[1444/1762] D loss: 1.3353\n",
      "[1524/1762] D loss: 1.3358\n",
      "[1604/1762] D loss: 1.3191\n",
      "[1684/1762] D loss: 1.3454\n",
      "[1762/1762] D loss: 1.3072\n",
      "train error: \n",
      " D loss: 1.327259, D accuracy: 70.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326527, D accuracy: 72.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3021\n",
      "[84/1762] D loss: 1.3507\n",
      "[164/1762] D loss: 1.3129\n",
      "[244/1762] D loss: 1.3361\n",
      "[324/1762] D loss: 1.3400\n",
      "[404/1762] D loss: 1.3285\n",
      "[484/1762] D loss: 1.3406\n",
      "[564/1762] D loss: 1.3312\n",
      "[644/1762] D loss: 1.3223\n",
      "[724/1762] D loss: 1.3382\n",
      "[804/1762] D loss: 1.3435\n",
      "[884/1762] D loss: 1.3265\n",
      "[964/1762] D loss: 1.3455\n",
      "[1044/1762] D loss: 1.3316\n",
      "[1124/1762] D loss: 1.3091\n",
      "[1204/1762] D loss: 1.3602\n",
      "[1284/1762] D loss: 1.3549\n",
      "[1364/1762] D loss: 1.3421\n",
      "[1444/1762] D loss: 1.3664\n",
      "[1524/1762] D loss: 1.3289\n",
      "[1604/1762] D loss: 1.3444\n",
      "[1684/1762] D loss: 1.3553\n",
      "[1762/1762] D loss: 1.2943\n",
      "train error: \n",
      " D loss: 1.320630, D accuracy: 71.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322208, D accuracy: 69.4% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3483\n",
      "[84/1762] D loss: 1.3260\n",
      "[164/1762] D loss: 1.3215\n",
      "[244/1762] D loss: 1.3565\n",
      "[324/1762] D loss: 1.3296\n",
      "[404/1762] D loss: 1.3290\n",
      "[484/1762] D loss: 1.3087\n",
      "[564/1762] D loss: 1.3837\n",
      "[644/1762] D loss: 1.3102\n",
      "[724/1762] D loss: 1.2994\n",
      "[804/1762] D loss: 1.3037\n",
      "[884/1762] D loss: 1.3611\n",
      "[964/1762] D loss: 1.3184\n",
      "[1044/1762] D loss: 1.3483\n",
      "[1124/1762] D loss: 1.3725\n",
      "[1204/1762] D loss: 1.3654\n",
      "[1284/1762] D loss: 1.3355\n",
      "[1364/1762] D loss: 1.3219\n",
      "[1444/1762] D loss: 1.3746\n",
      "[1524/1762] D loss: 1.3219\n",
      "[1604/1762] D loss: 1.3816\n",
      "[1684/1762] D loss: 1.3245\n",
      "[1762/1762] D loss: 1.2854\n",
      "train error: \n",
      " D loss: 1.318809, D accuracy: 72.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317184, D accuracy: 72.8% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3621\n",
      "[84/1762] D loss: 1.3654\n",
      "[164/1762] D loss: 1.3382\n",
      "[244/1762] D loss: 1.3308\n",
      "[324/1762] D loss: 1.3151\n",
      "[404/1762] D loss: 1.3668\n",
      "[484/1762] D loss: 1.3149\n",
      "[564/1762] D loss: 1.3351\n",
      "[644/1762] D loss: 1.3295\n",
      "[724/1762] D loss: 1.3599\n",
      "[804/1762] D loss: 1.3056\n",
      "[884/1762] D loss: 1.3176\n",
      "[964/1762] D loss: 1.3547\n",
      "[1044/1762] D loss: 1.3621\n",
      "[1124/1762] D loss: 1.3497\n",
      "[1204/1762] D loss: 1.3369\n",
      "[1284/1762] D loss: 1.3269\n",
      "[1364/1762] D loss: 1.2891\n",
      "[1444/1762] D loss: 1.3376\n",
      "[1524/1762] D loss: 1.3071\n",
      "[1604/1762] D loss: 1.3477\n",
      "[1684/1762] D loss: 1.3270\n",
      "[1762/1762] D loss: 1.3045\n",
      "train error: \n",
      " D loss: 1.309803, D accuracy: 72.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311369, D accuracy: 71.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2968\n",
      "[84/1762] D loss: 1.3016\n",
      "[164/1762] D loss: 1.3316\n",
      "[244/1762] D loss: 1.2876\n",
      "[324/1762] D loss: 1.3079\n",
      "[404/1762] D loss: 1.3283\n",
      "[484/1762] D loss: 1.3317\n",
      "[564/1762] D loss: 1.3357\n",
      "[644/1762] D loss: 1.2813\n",
      "[724/1762] D loss: 1.3110\n",
      "[804/1762] D loss: 1.2608\n",
      "[884/1762] D loss: 1.3201\n",
      "[964/1762] D loss: 1.3075\n",
      "[1044/1762] D loss: 1.3326\n",
      "[1124/1762] D loss: 1.2927\n",
      "[1204/1762] D loss: 1.3206\n",
      "[1284/1762] D loss: 1.3359\n",
      "[1364/1762] D loss: 1.3165\n",
      "[1444/1762] D loss: 1.3071\n",
      "[1524/1762] D loss: 1.3636\n",
      "[1604/1762] D loss: 1.2695\n",
      "[1684/1762] D loss: 1.3135\n",
      "[1762/1762] D loss: 1.2955\n",
      "train error: \n",
      " D loss: 1.305246, D accuracy: 72.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306857, D accuracy: 71.8% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3299\n",
      "[84/1762] D loss: 1.2987\n",
      "[164/1762] D loss: 1.3387\n",
      "[244/1762] D loss: 1.3467\n",
      "[324/1762] D loss: 1.2743\n",
      "[404/1762] D loss: 1.3481\n",
      "[484/1762] D loss: 1.3218\n",
      "[564/1762] D loss: 1.3174\n",
      "[644/1762] D loss: 1.3045\n",
      "[724/1762] D loss: 1.3037\n",
      "[804/1762] D loss: 1.2791\n",
      "[884/1762] D loss: 1.3302\n",
      "[964/1762] D loss: 1.3215\n",
      "[1044/1762] D loss: 1.3438\n",
      "[1124/1762] D loss: 1.2868\n",
      "[1204/1762] D loss: 1.3296\n",
      "[1284/1762] D loss: 1.3453\n",
      "[1364/1762] D loss: 1.3215\n",
      "[1444/1762] D loss: 1.3822\n",
      "[1524/1762] D loss: 1.3291\n",
      "[1604/1762] D loss: 1.3199\n",
      "[1684/1762] D loss: 1.2950\n",
      "[1762/1762] D loss: 1.3234\n",
      "train error: \n",
      " D loss: 1.299458, D accuracy: 73.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303045, D accuracy: 72.2% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2803\n",
      "[84/1762] D loss: 1.2833\n",
      "[164/1762] D loss: 1.3115\n",
      "[244/1762] D loss: 1.3280\n",
      "[324/1762] D loss: 1.2981\n",
      "[404/1762] D loss: 1.3248\n",
      "[484/1762] D loss: 1.3252\n",
      "[564/1762] D loss: 1.2961\n",
      "[644/1762] D loss: 1.2673\n",
      "[724/1762] D loss: 1.3353\n",
      "[804/1762] D loss: 1.3341\n",
      "[884/1762] D loss: 1.3282\n",
      "[964/1762] D loss: 1.3236\n",
      "[1044/1762] D loss: 1.3008\n",
      "[1124/1762] D loss: 1.3441\n",
      "[1204/1762] D loss: 1.3257\n",
      "[1284/1762] D loss: 1.3247\n",
      "[1364/1762] D loss: 1.3071\n",
      "[1444/1762] D loss: 1.3129\n",
      "[1524/1762] D loss: 1.3157\n",
      "[1604/1762] D loss: 1.2687\n",
      "[1684/1762] D loss: 1.2920\n",
      "[1762/1762] D loss: 1.3295\n",
      "train error: \n",
      " D loss: 1.297165, D accuracy: 74.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295539, D accuracy: 71.9% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2963\n",
      "[84/1762] D loss: 1.3484\n",
      "[164/1762] D loss: 1.3175\n",
      "[244/1762] D loss: 1.3242\n",
      "[324/1762] D loss: 1.3454\n",
      "[404/1762] D loss: 1.2885\n",
      "[484/1762] D loss: 1.3378\n",
      "[564/1762] D loss: 1.3252\n",
      "[644/1762] D loss: 1.3101\n",
      "[724/1762] D loss: 1.3642\n",
      "[804/1762] D loss: 1.2685\n",
      "[884/1762] D loss: 1.2771\n",
      "[964/1762] D loss: 1.3241\n",
      "[1044/1762] D loss: 1.3175\n",
      "[1124/1762] D loss: 1.3141\n",
      "[1204/1762] D loss: 1.3276\n",
      "[1284/1762] D loss: 1.2610\n",
      "[1364/1762] D loss: 1.3148\n",
      "[1444/1762] D loss: 1.3411\n",
      "[1524/1762] D loss: 1.3122\n",
      "[1604/1762] D loss: 1.3245\n",
      "[1684/1762] D loss: 1.3194\n",
      "[1762/1762] D loss: 1.2616\n",
      "train error: \n",
      " D loss: 1.286012, D accuracy: 75.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288366, D accuracy: 72.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2819\n",
      "[84/1762] D loss: 1.3592\n",
      "[164/1762] D loss: 1.2937\n",
      "[244/1762] D loss: 1.3355\n",
      "[324/1762] D loss: 1.2490\n",
      "[404/1762] D loss: 1.3132\n",
      "[484/1762] D loss: 1.3674\n",
      "[564/1762] D loss: 1.2737\n",
      "[644/1762] D loss: 1.3081\n",
      "[724/1762] D loss: 1.2804\n",
      "[804/1762] D loss: 1.2778\n",
      "[884/1762] D loss: 1.3056\n",
      "[964/1762] D loss: 1.3021\n",
      "[1044/1762] D loss: 1.2505\n",
      "[1124/1762] D loss: 1.3100\n",
      "[1204/1762] D loss: 1.3046\n",
      "[1284/1762] D loss: 1.2654\n",
      "[1364/1762] D loss: 1.2824\n",
      "[1444/1762] D loss: 1.2725\n",
      "[1524/1762] D loss: 1.3245\n",
      "[1604/1762] D loss: 1.3351\n",
      "[1684/1762] D loss: 1.2577\n",
      "[1762/1762] D loss: 1.3683\n",
      "train error: \n",
      " D loss: 1.274939, D accuracy: 76.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279393, D accuracy: 73.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3037\n",
      "[84/1762] D loss: 1.3421\n",
      "[164/1762] D loss: 1.2733\n",
      "[244/1762] D loss: 1.2397\n",
      "[324/1762] D loss: 1.3162\n",
      "[404/1762] D loss: 1.3372\n",
      "[484/1762] D loss: 1.3228\n",
      "[564/1762] D loss: 1.2621\n",
      "[644/1762] D loss: 1.2968\n",
      "[724/1762] D loss: 1.1705\n",
      "[804/1762] D loss: 1.3126\n",
      "[884/1762] D loss: 1.3231\n",
      "[964/1762] D loss: 1.3076\n",
      "[1044/1762] D loss: 1.2476\n",
      "[1124/1762] D loss: 1.2713\n",
      "[1204/1762] D loss: 1.2533\n",
      "[1284/1762] D loss: 1.3270\n",
      "[1364/1762] D loss: 1.2987\n",
      "[1444/1762] D loss: 1.3022\n",
      "[1524/1762] D loss: 1.2354\n",
      "[1604/1762] D loss: 1.3566\n",
      "[1684/1762] D loss: 1.2681\n",
      "[1762/1762] D loss: 1.2622\n",
      "train error: \n",
      " D loss: 1.269749, D accuracy: 76.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271580, D accuracy: 75.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2880\n",
      "[84/1762] D loss: 1.3242\n",
      "[164/1762] D loss: 1.2485\n",
      "[244/1762] D loss: 1.2563\n",
      "[324/1762] D loss: 1.3016\n",
      "[404/1762] D loss: 1.2995\n",
      "[484/1762] D loss: 1.2664\n",
      "[564/1762] D loss: 1.3158\n",
      "[644/1762] D loss: 1.2917\n",
      "[724/1762] D loss: 1.2859\n",
      "[804/1762] D loss: 1.2928\n",
      "[884/1762] D loss: 1.3324\n",
      "[964/1762] D loss: 1.2083\n",
      "[1044/1762] D loss: 1.2783\n",
      "[1124/1762] D loss: 1.2546\n",
      "[1204/1762] D loss: 1.2741\n",
      "[1284/1762] D loss: 1.3120\n",
      "[1364/1762] D loss: 1.3205\n",
      "[1444/1762] D loss: 1.2881\n",
      "[1524/1762] D loss: 1.2640\n",
      "[1604/1762] D loss: 1.2188\n",
      "[1684/1762] D loss: 1.2950\n",
      "[1762/1762] D loss: 1.2361\n",
      "train error: \n",
      " D loss: 1.260998, D accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266779, D accuracy: 74.9% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2435\n",
      "[84/1762] D loss: 1.3100\n",
      "[164/1762] D loss: 1.2663\n",
      "[244/1762] D loss: 1.2792\n",
      "[324/1762] D loss: 1.2573\n",
      "[404/1762] D loss: 1.2620\n",
      "[484/1762] D loss: 1.2588\n",
      "[564/1762] D loss: 1.2736\n",
      "[644/1762] D loss: 1.2105\n",
      "[724/1762] D loss: 1.2440\n",
      "[804/1762] D loss: 1.2951\n",
      "[884/1762] D loss: 1.3182\n",
      "[964/1762] D loss: 1.3126\n",
      "[1044/1762] D loss: 1.2873\n",
      "[1124/1762] D loss: 1.2509\n",
      "[1204/1762] D loss: 1.3364\n",
      "[1284/1762] D loss: 1.2618\n",
      "[1364/1762] D loss: 1.2985\n",
      "[1444/1762] D loss: 1.2803\n",
      "[1524/1762] D loss: 1.3157\n",
      "[1604/1762] D loss: 1.2689\n",
      "[1684/1762] D loss: 1.2954\n",
      "[1762/1762] D loss: 1.3093\n",
      "train error: \n",
      " D loss: 1.252462, D accuracy: 78.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253369, D accuracy: 78.6% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2999\n",
      "[84/1762] D loss: 1.2314\n",
      "[164/1762] D loss: 1.3125\n",
      "[244/1762] D loss: 1.2593\n",
      "[324/1762] D loss: 1.2974\n",
      "[404/1762] D loss: 1.2562\n",
      "[484/1762] D loss: 1.3155\n",
      "[564/1762] D loss: 1.2381\n",
      "[644/1762] D loss: 1.2527\n",
      "[724/1762] D loss: 1.2662\n",
      "[804/1762] D loss: 1.2905\n",
      "[884/1762] D loss: 1.2557\n",
      "[964/1762] D loss: 1.2429\n",
      "[1044/1762] D loss: 1.2487\n",
      "[1124/1762] D loss: 1.2739\n",
      "[1204/1762] D loss: 1.2394\n",
      "[1284/1762] D loss: 1.3017\n",
      "[1364/1762] D loss: 1.2796\n",
      "[1444/1762] D loss: 1.2788\n",
      "[1524/1762] D loss: 1.2562\n",
      "[1604/1762] D loss: 1.2286\n",
      "[1684/1762] D loss: 1.2923\n",
      "[1762/1762] D loss: 1.3252\n",
      "train error: \n",
      " D loss: 1.245349, D accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252279, D accuracy: 78.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2767\n",
      "[84/1762] D loss: 1.2323\n",
      "[164/1762] D loss: 1.2687\n",
      "[244/1762] D loss: 1.2667\n",
      "[324/1762] D loss: 1.2729\n",
      "[404/1762] D loss: 1.2856\n",
      "[484/1762] D loss: 1.1940\n",
      "[564/1762] D loss: 1.2255\n",
      "[644/1762] D loss: 1.2741\n",
      "[724/1762] D loss: 1.2757\n",
      "[804/1762] D loss: 1.2141\n",
      "[884/1762] D loss: 1.2782\n",
      "[964/1762] D loss: 1.3158\n",
      "[1044/1762] D loss: 1.2795\n",
      "[1124/1762] D loss: 1.2547\n",
      "[1204/1762] D loss: 1.1712\n",
      "[1284/1762] D loss: 1.2855\n",
      "[1364/1762] D loss: 1.1644\n",
      "[1444/1762] D loss: 1.2152\n",
      "[1524/1762] D loss: 1.2896\n",
      "[1604/1762] D loss: 1.2592\n",
      "[1684/1762] D loss: 1.3282\n",
      "[1762/1762] D loss: 1.3111\n",
      "train error: \n",
      " D loss: 1.231180, D accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.235548, D accuracy: 79.5% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2341\n",
      "[84/1762] D loss: 1.2779\n",
      "[164/1762] D loss: 1.2302\n",
      "[244/1762] D loss: 1.1597\n",
      "[324/1762] D loss: 1.1812\n",
      "[404/1762] D loss: 1.2853\n",
      "[484/1762] D loss: 1.2005\n",
      "[564/1762] D loss: 1.2599\n",
      "[644/1762] D loss: 1.1991\n",
      "[724/1762] D loss: 1.2293\n",
      "[804/1762] D loss: 1.1742\n",
      "[884/1762] D loss: 1.2117\n",
      "[964/1762] D loss: 1.2253\n",
      "[1044/1762] D loss: 1.2268\n",
      "[1124/1762] D loss: 1.2755\n",
      "[1204/1762] D loss: 1.2586\n",
      "[1284/1762] D loss: 1.2346\n",
      "[1364/1762] D loss: 1.2517\n",
      "[1444/1762] D loss: 1.2886\n",
      "[1524/1762] D loss: 1.2488\n",
      "[1604/1762] D loss: 1.2087\n",
      "[1684/1762] D loss: 1.2784\n",
      "[1762/1762] D loss: 1.1716\n",
      "train error: \n",
      " D loss: 1.206220, D accuracy: 81.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.211078, D accuracy: 80.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3145\n",
      "[84/1762] D loss: 1.2560\n",
      "[164/1762] D loss: 1.1994\n",
      "[244/1762] D loss: 1.2025\n",
      "[324/1762] D loss: 1.2500\n",
      "[404/1762] D loss: 1.2628\n",
      "[484/1762] D loss: 1.1996\n",
      "[564/1762] D loss: 1.2215\n",
      "[644/1762] D loss: 1.2401\n",
      "[724/1762] D loss: 1.2568\n",
      "[804/1762] D loss: 1.3026\n",
      "[884/1762] D loss: 1.2321\n",
      "[964/1762] D loss: 1.2766\n",
      "[1044/1762] D loss: 1.2781\n",
      "[1124/1762] D loss: 1.2208\n",
      "[1204/1762] D loss: 1.2969\n",
      "[1284/1762] D loss: 1.1929\n",
      "[1364/1762] D loss: 1.1890\n",
      "[1444/1762] D loss: 1.1589\n",
      "[1524/1762] D loss: 1.1907\n",
      "[1604/1762] D loss: 1.2516\n",
      "[1684/1762] D loss: 1.2034\n",
      "[1762/1762] D loss: 1.2693\n",
      "train error: \n",
      " D loss: 1.198448, D accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.202336, D accuracy: 83.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3123\n",
      "[84/1762] D loss: 1.2687\n",
      "[164/1762] D loss: 1.1982\n",
      "[244/1762] D loss: 1.1565\n",
      "[324/1762] D loss: 1.1741\n",
      "[404/1762] D loss: 1.2082\n",
      "[484/1762] D loss: 1.2519\n",
      "[564/1762] D loss: 1.1951\n",
      "[644/1762] D loss: 1.2290\n",
      "[724/1762] D loss: 1.1612\n",
      "[804/1762] D loss: 1.2389\n",
      "[884/1762] D loss: 1.2018\n",
      "[964/1762] D loss: 1.2768\n",
      "[1044/1762] D loss: 1.2286\n",
      "[1124/1762] D loss: 1.2319\n",
      "[1204/1762] D loss: 1.1216\n",
      "[1284/1762] D loss: 1.1830\n",
      "[1364/1762] D loss: 1.2211\n",
      "[1444/1762] D loss: 1.2093\n",
      "[1524/1762] D loss: 1.1767\n",
      "[1604/1762] D loss: 1.1319\n",
      "[1684/1762] D loss: 1.2567\n",
      "[1762/1762] D loss: 1.3278\n",
      "train error: \n",
      " D loss: 1.183173, D accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.180554, D accuracy: 83.4% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1701\n",
      "[84/1762] D loss: 1.1470\n",
      "[164/1762] D loss: 1.2260\n",
      "[244/1762] D loss: 1.1362\n",
      "[324/1762] D loss: 1.1677\n",
      "[404/1762] D loss: 1.2763\n",
      "[484/1762] D loss: 1.2094\n",
      "[564/1762] D loss: 1.1751\n",
      "[644/1762] D loss: 1.1986\n",
      "[724/1762] D loss: 1.2023\n",
      "[804/1762] D loss: 1.2432\n",
      "[884/1762] D loss: 1.2214\n",
      "[964/1762] D loss: 1.1792\n",
      "[1044/1762] D loss: 1.2258\n",
      "[1124/1762] D loss: 1.2171\n",
      "[1204/1762] D loss: 1.2379\n",
      "[1284/1762] D loss: 1.2790\n",
      "[1364/1762] D loss: 1.1803\n",
      "[1444/1762] D loss: 1.2880\n",
      "[1524/1762] D loss: 1.2636\n",
      "[1604/1762] D loss: 1.1532\n",
      "[1684/1762] D loss: 1.2769\n",
      "[1762/1762] D loss: 1.3277\n",
      "train error: \n",
      " D loss: 1.165292, D accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.165675, D accuracy: 85.3% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1556\n",
      "[84/1762] D loss: 1.2342\n",
      "[164/1762] D loss: 1.2148\n",
      "[244/1762] D loss: 1.2414\n",
      "[324/1762] D loss: 1.2706\n",
      "[404/1762] D loss: 1.0980\n",
      "[484/1762] D loss: 1.0969\n",
      "[564/1762] D loss: 1.1826\n",
      "[644/1762] D loss: 1.2518\n",
      "[724/1762] D loss: 1.2087\n",
      "[804/1762] D loss: 1.2305\n",
      "[884/1762] D loss: 1.1939\n",
      "[964/1762] D loss: 1.1979\n",
      "[1044/1762] D loss: 1.2044\n",
      "[1124/1762] D loss: 1.1796\n",
      "[1204/1762] D loss: 1.2356\n",
      "[1284/1762] D loss: 1.2411\n",
      "[1364/1762] D loss: 1.2329\n",
      "[1444/1762] D loss: 1.2335\n",
      "[1524/1762] D loss: 1.1735\n",
      "[1604/1762] D loss: 1.3181\n",
      "[1684/1762] D loss: 1.1971\n",
      "[1762/1762] D loss: 1.2280\n",
      "train error: \n",
      " D loss: 1.138391, D accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.137829, D accuracy: 87.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1904\n",
      "[84/1762] D loss: 1.1948\n",
      "[164/1762] D loss: 1.1906\n",
      "[244/1762] D loss: 1.0630\n",
      "[324/1762] D loss: 1.1877\n",
      "[404/1762] D loss: 1.1195\n",
      "[484/1762] D loss: 1.1163\n",
      "[564/1762] D loss: 1.1303\n",
      "[644/1762] D loss: 1.1245\n",
      "[724/1762] D loss: 1.1982\n",
      "[804/1762] D loss: 1.1199\n",
      "[884/1762] D loss: 1.0819\n",
      "[964/1762] D loss: 1.2444\n",
      "[1044/1762] D loss: 1.0587\n",
      "[1124/1762] D loss: 1.1001\n",
      "[1204/1762] D loss: 1.1176\n",
      "[1284/1762] D loss: 1.2397\n",
      "[1364/1762] D loss: 1.1226\n",
      "[1444/1762] D loss: 1.2358\n",
      "[1524/1762] D loss: 1.1136\n",
      "[1604/1762] D loss: 1.1908\n",
      "[1684/1762] D loss: 1.1843\n",
      "[1762/1762] D loss: 1.1584\n",
      "train error: \n",
      " D loss: 1.115030, D accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.119772, D accuracy: 86.9% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2930\n",
      "[84/1762] D loss: 1.1707\n",
      "[164/1762] D loss: 1.2216\n",
      "[244/1762] D loss: 1.1036\n",
      "[324/1762] D loss: 1.0909\n",
      "[404/1762] D loss: 1.1953\n",
      "[484/1762] D loss: 1.1176\n",
      "[564/1762] D loss: 1.0970\n",
      "[644/1762] D loss: 1.1572\n",
      "[724/1762] D loss: 0.9981\n",
      "[804/1762] D loss: 1.0415\n",
      "[884/1762] D loss: 1.1346\n",
      "[964/1762] D loss: 1.1178\n",
      "[1044/1762] D loss: 1.1159\n",
      "[1124/1762] D loss: 1.1423\n",
      "[1204/1762] D loss: 1.0933\n",
      "[1284/1762] D loss: 1.0414\n",
      "[1364/1762] D loss: 1.1937\n",
      "[1444/1762] D loss: 1.0232\n",
      "[1524/1762] D loss: 1.1052\n",
      "[1604/1762] D loss: 1.1747\n",
      "[1684/1762] D loss: 1.1803\n",
      "[1762/1762] D loss: 1.1131\n",
      "train error: \n",
      " D loss: 1.082522, D accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.074440, D accuracy: 87.8% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2372\n",
      "[84/1762] D loss: 1.2680\n",
      "[164/1762] D loss: 1.2046\n",
      "[244/1762] D loss: 1.0338\n",
      "[324/1762] D loss: 1.2037\n",
      "[404/1762] D loss: 1.1712\n",
      "[484/1762] D loss: 1.2153\n",
      "[564/1762] D loss: 1.2782\n",
      "[644/1762] D loss: 1.1171\n",
      "[724/1762] D loss: 1.1160\n",
      "[804/1762] D loss: 1.0736\n",
      "[884/1762] D loss: 1.0301\n",
      "[964/1762] D loss: 1.1185\n",
      "[1044/1762] D loss: 1.1016\n",
      "[1124/1762] D loss: 1.2073\n",
      "[1204/1762] D loss: 1.0821\n",
      "[1284/1762] D loss: 1.1551\n",
      "[1364/1762] D loss: 1.1633\n",
      "[1444/1762] D loss: 1.1207\n",
      "[1524/1762] D loss: 1.1030\n",
      "[1604/1762] D loss: 1.1153\n",
      "[1684/1762] D loss: 1.0538\n",
      "[1762/1762] D loss: 1.0850\n",
      "train error: \n",
      " D loss: 1.049798, D accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.050494, D accuracy: 88.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0702\n",
      "[84/1762] D loss: 1.1338\n",
      "[164/1762] D loss: 1.2440\n",
      "[244/1762] D loss: 1.0678\n",
      "[324/1762] D loss: 1.2153\n",
      "[404/1762] D loss: 1.2200\n",
      "[484/1762] D loss: 1.0371\n",
      "[564/1762] D loss: 1.1219\n",
      "[644/1762] D loss: 1.0496\n",
      "[724/1762] D loss: 1.0600\n",
      "[804/1762] D loss: 1.0999\n",
      "[884/1762] D loss: 1.2059\n",
      "[964/1762] D loss: 1.1607\n",
      "[1044/1762] D loss: 1.1079\n",
      "[1124/1762] D loss: 1.0883\n",
      "[1204/1762] D loss: 1.0697\n",
      "[1284/1762] D loss: 1.1427\n",
      "[1364/1762] D loss: 1.1008\n",
      "[1444/1762] D loss: 0.9146\n",
      "[1524/1762] D loss: 1.0780\n",
      "[1604/1762] D loss: 1.1106\n",
      "[1684/1762] D loss: 1.1216\n",
      "[1762/1762] D loss: 0.9437\n",
      "train error: \n",
      " D loss: 1.022518, D accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.029692, D accuracy: 89.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2590\n",
      "[84/1762] D loss: 1.1184\n",
      "[164/1762] D loss: 1.0527\n",
      "[244/1762] D loss: 1.1860\n",
      "[324/1762] D loss: 0.9127\n",
      "[404/1762] D loss: 1.1114\n",
      "[484/1762] D loss: 1.0359\n",
      "[564/1762] D loss: 1.0880\n",
      "[644/1762] D loss: 1.0848\n",
      "[724/1762] D loss: 1.0381\n",
      "[804/1762] D loss: 1.1328\n",
      "[884/1762] D loss: 1.1859\n",
      "[964/1762] D loss: 1.1620\n",
      "[1044/1762] D loss: 1.0254\n",
      "[1124/1762] D loss: 1.1449\n",
      "[1204/1762] D loss: 1.1856\n",
      "[1284/1762] D loss: 0.9142\n",
      "[1364/1762] D loss: 1.0520\n",
      "[1444/1762] D loss: 1.1150\n",
      "[1524/1762] D loss: 1.0211\n",
      "[1604/1762] D loss: 0.9468\n",
      "[1684/1762] D loss: 0.8961\n",
      "[1762/1762] D loss: 1.0473\n",
      "train error: \n",
      " D loss: 0.993323, D accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.005479, D accuracy: 90.9% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1143\n",
      "[84/1762] D loss: 1.1156\n",
      "[164/1762] D loss: 1.2500\n",
      "[244/1762] D loss: 1.0480\n",
      "[324/1762] D loss: 1.0192\n",
      "[404/1762] D loss: 0.9253\n",
      "[484/1762] D loss: 1.0134\n",
      "[564/1762] D loss: 0.9718\n",
      "[644/1762] D loss: 1.2256\n",
      "[724/1762] D loss: 1.0754\n",
      "[804/1762] D loss: 1.1371\n",
      "[884/1762] D loss: 0.9754\n",
      "[964/1762] D loss: 0.9863\n",
      "[1044/1762] D loss: 1.0897\n",
      "[1124/1762] D loss: 0.9945\n",
      "[1204/1762] D loss: 1.0157\n",
      "[1284/1762] D loss: 1.0847\n",
      "[1364/1762] D loss: 0.8977\n",
      "[1444/1762] D loss: 1.0663\n",
      "[1524/1762] D loss: 1.0149\n",
      "[1604/1762] D loss: 0.9234\n",
      "[1684/1762] D loss: 0.9760\n",
      "[1762/1762] D loss: 0.7972\n",
      "train error: \n",
      " D loss: 0.939372, D accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.953224, D accuracy: 91.9% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9734\n",
      "[84/1762] D loss: 1.0283\n",
      "[164/1762] D loss: 0.8361\n",
      "[244/1762] D loss: 1.0778\n",
      "[324/1762] D loss: 1.2475\n",
      "[404/1762] D loss: 1.0802\n",
      "[484/1762] D loss: 1.1467\n",
      "[564/1762] D loss: 1.0507\n",
      "[644/1762] D loss: 0.7400\n",
      "[724/1762] D loss: 1.1142\n",
      "[804/1762] D loss: 1.0383\n",
      "[884/1762] D loss: 1.0773\n",
      "[964/1762] D loss: 0.9927\n",
      "[1044/1762] D loss: 1.0086\n",
      "[1124/1762] D loss: 1.1025\n",
      "[1204/1762] D loss: 0.9334\n",
      "[1284/1762] D loss: 1.0546\n",
      "[1364/1762] D loss: 1.0855\n",
      "[1444/1762] D loss: 0.9309\n",
      "[1524/1762] D loss: 1.0112\n",
      "[1604/1762] D loss: 0.9460\n",
      "[1684/1762] D loss: 1.1355\n",
      "[1762/1762] D loss: 1.0909\n",
      "train error: \n",
      " D loss: 0.914427, D accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.926417, D accuracy: 91.6% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7812\n",
      "[84/1762] D loss: 1.0913\n",
      "[164/1762] D loss: 0.8691\n",
      "[244/1762] D loss: 0.8561\n",
      "[324/1762] D loss: 1.0039\n",
      "[404/1762] D loss: 1.0608\n",
      "[484/1762] D loss: 0.8999\n",
      "[564/1762] D loss: 0.9055\n",
      "[644/1762] D loss: 0.9335\n",
      "[724/1762] D loss: 0.9044\n",
      "[804/1762] D loss: 0.8692\n",
      "[884/1762] D loss: 0.9250\n",
      "[964/1762] D loss: 0.8756\n",
      "[1044/1762] D loss: 1.1585\n",
      "[1124/1762] D loss: 0.6704\n",
      "[1204/1762] D loss: 0.7648\n",
      "[1284/1762] D loss: 0.9341\n",
      "[1364/1762] D loss: 1.0414\n",
      "[1444/1762] D loss: 1.0627\n",
      "[1524/1762] D loss: 0.6775\n",
      "[1604/1762] D loss: 1.0836\n",
      "[1684/1762] D loss: 0.8948\n",
      "[1762/1762] D loss: 0.6843\n",
      "train error: \n",
      " D loss: 0.852983, D accuracy: 93.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.856173, D accuracy: 93.2% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8693\n",
      "[84/1762] D loss: 0.9871\n",
      "[164/1762] D loss: 0.9136\n",
      "[244/1762] D loss: 0.7925\n",
      "[324/1762] D loss: 0.7968\n",
      "[404/1762] D loss: 0.8737\n",
      "[484/1762] D loss: 0.9774\n",
      "[564/1762] D loss: 1.1552\n",
      "[644/1762] D loss: 1.0142\n",
      "[724/1762] D loss: 1.0923\n",
      "[804/1762] D loss: 1.0320\n",
      "[884/1762] D loss: 1.0136\n",
      "[964/1762] D loss: 0.9871\n",
      "[1044/1762] D loss: 0.8821\n",
      "[1124/1762] D loss: 0.8672\n",
      "[1204/1762] D loss: 0.9428\n",
      "[1284/1762] D loss: 0.9741\n",
      "[1364/1762] D loss: 0.8074\n",
      "[1444/1762] D loss: 0.9856\n",
      "[1524/1762] D loss: 0.7227\n",
      "[1604/1762] D loss: 0.8808\n",
      "[1684/1762] D loss: 1.0500\n",
      "[1762/1762] D loss: 1.0777\n",
      "train error: \n",
      " D loss: 0.814188, D accuracy: 93.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.816608, D accuracy: 94.4% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6219\n",
      "[84/1762] D loss: 0.8090\n",
      "[164/1762] D loss: 0.9495\n",
      "[244/1762] D loss: 0.7819\n",
      "[324/1762] D loss: 0.5658\n",
      "[404/1762] D loss: 0.9385\n",
      "[484/1762] D loss: 0.7711\n",
      "[564/1762] D loss: 0.7837\n",
      "[644/1762] D loss: 0.7826\n",
      "[724/1762] D loss: 0.8773\n",
      "[804/1762] D loss: 0.9168\n",
      "[884/1762] D loss: 0.8615\n",
      "[964/1762] D loss: 0.7291\n",
      "[1044/1762] D loss: 1.1015\n",
      "[1124/1762] D loss: 0.8977\n",
      "[1204/1762] D loss: 0.9299\n",
      "[1284/1762] D loss: 0.8918\n",
      "[1364/1762] D loss: 0.7240\n",
      "[1444/1762] D loss: 0.8899\n",
      "[1524/1762] D loss: 0.9354\n",
      "[1604/1762] D loss: 0.8539\n",
      "[1684/1762] D loss: 0.5221\n",
      "[1762/1762] D loss: 0.7001\n",
      "train error: \n",
      " D loss: 0.786539, D accuracy: 94.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.783226, D accuracy: 94.3% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5582\n",
      "[84/1762] D loss: 0.5757\n",
      "[164/1762] D loss: 0.9439\n",
      "[244/1762] D loss: 0.8181\n",
      "[324/1762] D loss: 0.7517\n",
      "[404/1762] D loss: 0.5797\n",
      "[484/1762] D loss: 0.7286\n",
      "[564/1762] D loss: 0.6816\n",
      "[644/1762] D loss: 0.8144\n",
      "[724/1762] D loss: 0.7136\n",
      "[804/1762] D loss: 0.6746\n",
      "[884/1762] D loss: 0.8644\n",
      "[964/1762] D loss: 0.7632\n",
      "[1044/1762] D loss: 0.8268\n",
      "[1124/1762] D loss: 0.6599\n",
      "[1204/1762] D loss: 0.7606\n",
      "[1284/1762] D loss: 0.8023\n",
      "[1364/1762] D loss: 0.6231\n",
      "[1444/1762] D loss: 0.8056\n",
      "[1524/1762] D loss: 0.7584\n",
      "[1604/1762] D loss: 0.5378\n",
      "[1684/1762] D loss: 0.6743\n",
      "[1762/1762] D loss: 0.6377\n",
      "train error: \n",
      " D loss: 0.730530, D accuracy: 94.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.746322, D accuracy: 94.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6843\n",
      "[84/1762] D loss: 0.7865\n",
      "[164/1762] D loss: 0.8252\n",
      "[244/1762] D loss: 1.0091\n",
      "[324/1762] D loss: 0.6562\n",
      "[404/1762] D loss: 0.8412\n",
      "[484/1762] D loss: 0.7720\n",
      "[564/1762] D loss: 0.7674\n",
      "[644/1762] D loss: 0.6617\n",
      "[724/1762] D loss: 0.8458\n",
      "[804/1762] D loss: 0.8563\n",
      "[884/1762] D loss: 0.6694\n",
      "[964/1762] D loss: 0.6852\n",
      "[1044/1762] D loss: 0.5133\n",
      "[1124/1762] D loss: 0.6389\n",
      "[1204/1762] D loss: 0.5873\n",
      "[1284/1762] D loss: 0.8939\n",
      "[1364/1762] D loss: 0.9021\n",
      "[1444/1762] D loss: 0.5560\n",
      "[1524/1762] D loss: 0.8068\n",
      "[1604/1762] D loss: 0.6164\n",
      "[1684/1762] D loss: 0.7639\n",
      "[1762/1762] D loss: 0.9322\n",
      "train error: \n",
      " D loss: 0.685202, D accuracy: 95.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.689369, D accuracy: 94.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7529\n",
      "[84/1762] D loss: 0.6497\n",
      "[164/1762] D loss: 0.6391\n",
      "[244/1762] D loss: 0.7665\n",
      "[324/1762] D loss: 0.8574\n",
      "[404/1762] D loss: 0.7043\n",
      "[484/1762] D loss: 0.7734\n",
      "[564/1762] D loss: 0.7875\n",
      "[644/1762] D loss: 0.8606\n",
      "[724/1762] D loss: 0.8013\n",
      "[804/1762] D loss: 0.9279\n",
      "[884/1762] D loss: 0.7358\n",
      "[964/1762] D loss: 0.7440\n",
      "[1044/1762] D loss: 0.7085\n",
      "[1124/1762] D loss: 0.4600\n",
      "[1204/1762] D loss: 0.7621\n",
      "[1284/1762] D loss: 0.4664\n",
      "[1364/1762] D loss: 1.0140\n",
      "[1444/1762] D loss: 0.8609\n",
      "[1524/1762] D loss: 0.7403\n",
      "[1604/1762] D loss: 0.4958\n",
      "[1684/1762] D loss: 0.7433\n",
      "[1762/1762] D loss: 0.5644\n",
      "train error: \n",
      " D loss: 0.643050, D accuracy: 95.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.645919, D accuracy: 95.3% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5825\n",
      "[84/1762] D loss: 0.6244\n",
      "[164/1762] D loss: 0.6102\n",
      "[244/1762] D loss: 0.7959\n",
      "[324/1762] D loss: 0.8461\n",
      "[404/1762] D loss: 0.7667\n",
      "[484/1762] D loss: 0.5776\n",
      "[564/1762] D loss: 0.6971\n",
      "[644/1762] D loss: 0.8047\n",
      "[724/1762] D loss: 0.8206\n",
      "[804/1762] D loss: 0.7306\n",
      "[884/1762] D loss: 0.7560\n",
      "[964/1762] D loss: 0.8092\n",
      "[1044/1762] D loss: 0.7334\n",
      "[1124/1762] D loss: 0.7328\n",
      "[1204/1762] D loss: 0.5310\n",
      "[1284/1762] D loss: 0.4951\n",
      "[1364/1762] D loss: 0.8264\n",
      "[1444/1762] D loss: 0.5156\n",
      "[1524/1762] D loss: 0.7476\n",
      "[1604/1762] D loss: 0.3835\n",
      "[1684/1762] D loss: 0.5885\n",
      "[1762/1762] D loss: 0.6751\n",
      "train error: \n",
      " D loss: 0.586615, D accuracy: 96.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603763, D accuracy: 95.9% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4265\n",
      "[84/1762] D loss: 1.3993\n",
      "[164/1762] D loss: 1.3914\n",
      "[244/1762] D loss: 1.4371\n",
      "[324/1762] D loss: 1.3671\n",
      "[404/1762] D loss: 1.3699\n",
      "[484/1762] D loss: 1.3842\n",
      "[564/1762] D loss: 1.4045\n",
      "[644/1762] D loss: 1.4214\n",
      "[724/1762] D loss: 1.3902\n",
      "[804/1762] D loss: 1.4013\n",
      "[884/1762] D loss: 1.3930\n",
      "[964/1762] D loss: 1.4101\n",
      "[1044/1762] D loss: 1.4112\n",
      "[1124/1762] D loss: 1.4230\n",
      "[1204/1762] D loss: 1.4029\n",
      "[1284/1762] D loss: 1.4098\n",
      "[1364/1762] D loss: 1.3598\n",
      "[1444/1762] D loss: 1.3945\n",
      "[1524/1762] D loss: 1.3753\n",
      "[1604/1762] D loss: 1.4210\n",
      "[1684/1762] D loss: 1.4124\n",
      "[1762/1762] D loss: 1.3692\n",
      "train error: \n",
      " D loss: 1.400112, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400767, D accuracy: 50.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3750\n",
      "[84/1762] D loss: 1.4205\n",
      "[164/1762] D loss: 1.4143\n",
      "[244/1762] D loss: 1.4041\n",
      "[324/1762] D loss: 1.3965\n",
      "[404/1762] D loss: 1.3627\n",
      "[484/1762] D loss: 1.3793\n",
      "[564/1762] D loss: 1.4121\n",
      "[644/1762] D loss: 1.4429\n",
      "[724/1762] D loss: 1.3708\n",
      "[804/1762] D loss: 1.4104\n",
      "[884/1762] D loss: 1.3911\n",
      "[964/1762] D loss: 1.4083\n",
      "[1044/1762] D loss: 1.3614\n",
      "[1124/1762] D loss: 1.4140\n",
      "[1204/1762] D loss: 1.3938\n",
      "[1284/1762] D loss: 1.3600\n",
      "[1364/1762] D loss: 1.4022\n",
      "[1444/1762] D loss: 1.4105\n",
      "[1524/1762] D loss: 1.4220\n",
      "[1604/1762] D loss: 1.4091\n",
      "[1684/1762] D loss: 1.3602\n",
      "[1762/1762] D loss: 1.3861\n",
      "train error: \n",
      " D loss: 1.394689, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393805, D accuracy: 49.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913\n",
      "[84/1762] D loss: 1.4002\n",
      "[164/1762] D loss: 1.3808\n",
      "[244/1762] D loss: 1.3694\n",
      "[324/1762] D loss: 1.3590\n",
      "[404/1762] D loss: 1.4055\n",
      "[484/1762] D loss: 1.3940\n",
      "[564/1762] D loss: 1.4060\n",
      "[644/1762] D loss: 1.3915\n",
      "[724/1762] D loss: 1.3725\n",
      "[804/1762] D loss: 1.3801\n",
      "[884/1762] D loss: 1.3992\n",
      "[964/1762] D loss: 1.3865\n",
      "[1044/1762] D loss: 1.3721\n",
      "[1124/1762] D loss: 1.4024\n",
      "[1204/1762] D loss: 1.3704\n",
      "[1284/1762] D loss: 1.3988\n",
      "[1364/1762] D loss: 1.3842\n",
      "[1444/1762] D loss: 1.3600\n",
      "[1524/1762] D loss: 1.3819\n",
      "[1604/1762] D loss: 1.3851\n",
      "[1684/1762] D loss: 1.3754\n",
      "[1762/1762] D loss: 1.3755\n",
      "train error: \n",
      " D loss: 1.391896, D accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392779, D accuracy: 49.2% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925\n",
      "[84/1762] D loss: 1.3612\n",
      "[164/1762] D loss: 1.4056\n",
      "[244/1762] D loss: 1.3941\n",
      "[324/1762] D loss: 1.3903\n",
      "[404/1762] D loss: 1.3848\n",
      "[484/1762] D loss: 1.3931\n",
      "[564/1762] D loss: 1.4137\n",
      "[644/1762] D loss: 1.3730\n",
      "[724/1762] D loss: 1.3866\n",
      "[804/1762] D loss: 1.3817\n",
      "[884/1762] D loss: 1.3769\n",
      "[964/1762] D loss: 1.3664\n",
      "[1044/1762] D loss: 1.3808\n",
      "[1124/1762] D loss: 1.3957\n",
      "[1204/1762] D loss: 1.3911\n",
      "[1284/1762] D loss: 1.3974\n",
      "[1364/1762] D loss: 1.3805\n",
      "[1444/1762] D loss: 1.3952\n",
      "[1524/1762] D loss: 1.3749\n",
      "[1604/1762] D loss: 1.3607\n",
      "[1684/1762] D loss: 1.3990\n",
      "[1762/1762] D loss: 1.3645\n",
      "train error: \n",
      " D loss: 1.390524, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391499, D accuracy: 48.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4030\n",
      "[84/1762] D loss: 1.3729\n",
      "[164/1762] D loss: 1.4018\n",
      "[244/1762] D loss: 1.3999\n",
      "[324/1762] D loss: 1.4009\n",
      "[404/1762] D loss: 1.3956\n",
      "[484/1762] D loss: 1.3907\n",
      "[564/1762] D loss: 1.3691\n",
      "[644/1762] D loss: 1.3930\n",
      "[724/1762] D loss: 1.3819\n",
      "[804/1762] D loss: 1.3650\n",
      "[884/1762] D loss: 1.3949\n",
      "[964/1762] D loss: 1.3887\n",
      "[1044/1762] D loss: 1.3714\n",
      "[1124/1762] D loss: 1.3874\n",
      "[1204/1762] D loss: 1.3787\n",
      "[1284/1762] D loss: 1.3656\n",
      "[1364/1762] D loss: 1.4010\n",
      "[1444/1762] D loss: 1.3730\n",
      "[1524/1762] D loss: 1.3574\n",
      "[1604/1762] D loss: 1.3890\n",
      "[1684/1762] D loss: 1.3850\n",
      "[1762/1762] D loss: 1.4040\n",
      "train error: \n",
      " D loss: 1.389649, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390559, D accuracy: 49.9% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3714\n",
      "[84/1762] D loss: 1.3841\n",
      "[164/1762] D loss: 1.3688\n",
      "[244/1762] D loss: 1.3558\n",
      "[324/1762] D loss: 1.3579\n",
      "[404/1762] D loss: 1.3859\n",
      "[484/1762] D loss: 1.3598\n",
      "[564/1762] D loss: 1.3658\n",
      "[644/1762] D loss: 1.3827\n",
      "[724/1762] D loss: 1.3858\n",
      "[804/1762] D loss: 1.3804\n",
      "[884/1762] D loss: 1.3823\n",
      "[964/1762] D loss: 1.3906\n",
      "[1044/1762] D loss: 1.3704\n",
      "[1124/1762] D loss: 1.3651\n",
      "[1204/1762] D loss: 1.3806\n",
      "[1284/1762] D loss: 1.3654\n",
      "[1364/1762] D loss: 1.3808\n",
      "[1444/1762] D loss: 1.4025\n",
      "[1524/1762] D loss: 1.3716\n",
      "[1604/1762] D loss: 1.3768\n",
      "[1684/1762] D loss: 1.3829\n",
      "[1762/1762] D loss: 1.3968\n",
      "train error: \n",
      " D loss: 1.387437, D accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389139, D accuracy: 49.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3687\n",
      "[84/1762] D loss: 1.3926\n",
      "[164/1762] D loss: 1.3697\n",
      "[244/1762] D loss: 1.3922\n",
      "[324/1762] D loss: 1.3942\n",
      "[404/1762] D loss: 1.3712\n",
      "[484/1762] D loss: 1.3931\n",
      "[564/1762] D loss: 1.3657\n",
      "[644/1762] D loss: 1.3844\n",
      "[724/1762] D loss: 1.3854\n",
      "[804/1762] D loss: 1.3838\n",
      "[884/1762] D loss: 1.3905\n",
      "[964/1762] D loss: 1.3940\n",
      "[1044/1762] D loss: 1.3773\n",
      "[1124/1762] D loss: 1.3905\n",
      "[1204/1762] D loss: 1.3479\n",
      "[1284/1762] D loss: 1.3693\n",
      "[1364/1762] D loss: 1.3421\n",
      "[1444/1762] D loss: 1.3695\n",
      "[1524/1762] D loss: 1.3743\n",
      "[1604/1762] D loss: 1.3596\n",
      "[1684/1762] D loss: 1.3876\n",
      "[1762/1762] D loss: 1.3891\n",
      "train error: \n",
      " D loss: 1.385586, D accuracy: 51.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387161, D accuracy: 50.6% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3507\n",
      "[84/1762] D loss: 1.3949\n",
      "[164/1762] D loss: 1.3692\n",
      "[244/1762] D loss: 1.3933\n",
      "[324/1762] D loss: 1.3695\n",
      "[404/1762] D loss: 1.3818\n",
      "[484/1762] D loss: 1.3758\n",
      "[564/1762] D loss: 1.3795\n",
      "[644/1762] D loss: 1.3592\n",
      "[724/1762] D loss: 1.3442\n",
      "[804/1762] D loss: 1.3692\n",
      "[884/1762] D loss: 1.3649\n",
      "[964/1762] D loss: 1.3633\n",
      "[1044/1762] D loss: 1.3995\n",
      "[1124/1762] D loss: 1.3885\n",
      "[1204/1762] D loss: 1.3829\n",
      "[1284/1762] D loss: 1.3746\n",
      "[1364/1762] D loss: 1.3570\n",
      "[1444/1762] D loss: 1.3895\n",
      "[1524/1762] D loss: 1.3749\n",
      "[1604/1762] D loss: 1.3624\n",
      "[1684/1762] D loss: 1.3769\n",
      "[1762/1762] D loss: 1.3739\n",
      "train error: \n",
      " D loss: 1.386349, D accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386334, D accuracy: 50.1% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3655\n",
      "[84/1762] D loss: 1.3908\n",
      "[164/1762] D loss: 1.3699\n",
      "[244/1762] D loss: 1.3566\n",
      "[324/1762] D loss: 1.3704\n",
      "[404/1762] D loss: 1.3738\n",
      "[484/1762] D loss: 1.3783\n",
      "[564/1762] D loss: 1.3716\n",
      "[644/1762] D loss: 1.3765\n",
      "[724/1762] D loss: 1.3818\n",
      "[804/1762] D loss: 1.3423\n",
      "[884/1762] D loss: 1.3625\n",
      "[964/1762] D loss: 1.3641\n",
      "[1044/1762] D loss: 1.3688\n",
      "[1124/1762] D loss: 1.3682\n",
      "[1204/1762] D loss: 1.3915\n",
      "[1284/1762] D loss: 1.3654\n",
      "[1364/1762] D loss: 1.3616\n",
      "[1444/1762] D loss: 1.3703\n",
      "[1524/1762] D loss: 1.3881\n",
      "[1604/1762] D loss: 1.3851\n",
      "[1684/1762] D loss: 1.3885\n",
      "[1762/1762] D loss: 1.3874\n",
      "train error: \n",
      " D loss: 1.385174, D accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387761, D accuracy: 50.1% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3586\n",
      "[84/1762] D loss: 1.3611\n",
      "[164/1762] D loss: 1.3690\n",
      "[244/1762] D loss: 1.3880\n",
      "[324/1762] D loss: 1.3967\n",
      "[404/1762] D loss: 1.3914\n",
      "[484/1762] D loss: 1.3837\n",
      "[564/1762] D loss: 1.3631\n",
      "[644/1762] D loss: 1.3923\n",
      "[724/1762] D loss: 1.3775\n",
      "[804/1762] D loss: 1.3922\n",
      "[884/1762] D loss: 1.3631\n",
      "[964/1762] D loss: 1.3583\n",
      "[1044/1762] D loss: 1.3652\n",
      "[1124/1762] D loss: 1.3588\n",
      "[1204/1762] D loss: 1.3740\n",
      "[1284/1762] D loss: 1.3863\n",
      "[1364/1762] D loss: 1.3551\n",
      "[1444/1762] D loss: 1.3466\n",
      "[1524/1762] D loss: 1.3807\n",
      "[1604/1762] D loss: 1.3786\n",
      "[1684/1762] D loss: 1.4158\n",
      "[1762/1762] D loss: 1.3577\n",
      "train error: \n",
      " D loss: 1.384439, D accuracy: 52.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387255, D accuracy: 51.2% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3370\n",
      "[84/1762] D loss: 1.3796\n",
      "[164/1762] D loss: 1.3791\n",
      "[244/1762] D loss: 1.3384\n",
      "[324/1762] D loss: 1.3859\n",
      "[404/1762] D loss: 1.3802\n",
      "[484/1762] D loss: 1.3955\n",
      "[564/1762] D loss: 1.3972\n",
      "[644/1762] D loss: 1.3968\n",
      "[724/1762] D loss: 1.3818\n",
      "[804/1762] D loss: 1.3632\n",
      "[884/1762] D loss: 1.3722\n",
      "[964/1762] D loss: 1.3679\n",
      "[1044/1762] D loss: 1.3747\n",
      "[1124/1762] D loss: 1.3687\n",
      "[1204/1762] D loss: 1.3418\n",
      "[1284/1762] D loss: 1.3704\n",
      "[1364/1762] D loss: 1.3886\n",
      "[1444/1762] D loss: 1.4030\n",
      "[1524/1762] D loss: 1.3743\n",
      "[1604/1762] D loss: 1.3842\n",
      "[1684/1762] D loss: 1.3637\n",
      "[1762/1762] D loss: 1.3859\n",
      "train error: \n",
      " D loss: 1.384607, D accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383758, D accuracy: 51.6% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883\n",
      "[84/1762] D loss: 1.4134\n",
      "[164/1762] D loss: 1.3680\n",
      "[244/1762] D loss: 1.3593\n",
      "[324/1762] D loss: 1.3767\n",
      "[404/1762] D loss: 1.3677\n",
      "[484/1762] D loss: 1.3891\n",
      "[564/1762] D loss: 1.3682\n",
      "[644/1762] D loss: 1.3544\n",
      "[724/1762] D loss: 1.3736\n",
      "[804/1762] D loss: 1.3810\n",
      "[884/1762] D loss: 1.3681\n",
      "[964/1762] D loss: 1.3793\n",
      "[1044/1762] D loss: 1.3961\n",
      "[1124/1762] D loss: 1.3929\n",
      "[1204/1762] D loss: 1.3500\n",
      "[1284/1762] D loss: 1.3831\n",
      "[1364/1762] D loss: 1.3705\n",
      "[1444/1762] D loss: 1.3799\n",
      "[1524/1762] D loss: 1.3934\n",
      "[1604/1762] D loss: 1.3495\n",
      "[1684/1762] D loss: 1.3640\n",
      "[1762/1762] D loss: 1.3356\n",
      "train error: \n",
      " D loss: 1.382594, D accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383160, D accuracy: 51.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3684\n",
      "[84/1762] D loss: 1.3831\n",
      "[164/1762] D loss: 1.3616\n",
      "[244/1762] D loss: 1.3651\n",
      "[324/1762] D loss: 1.3983\n",
      "[404/1762] D loss: 1.3476\n",
      "[484/1762] D loss: 1.3424\n",
      "[564/1762] D loss: 1.3573\n",
      "[644/1762] D loss: 1.3733\n",
      "[724/1762] D loss: 1.3602\n",
      "[804/1762] D loss: 1.3552\n",
      "[884/1762] D loss: 1.3550\n",
      "[964/1762] D loss: 1.3871\n",
      "[1044/1762] D loss: 1.3803\n",
      "[1124/1762] D loss: 1.3706\n",
      "[1204/1762] D loss: 1.3470\n",
      "[1284/1762] D loss: 1.3741\n",
      "[1364/1762] D loss: 1.3799\n",
      "[1444/1762] D loss: 1.3518\n",
      "[1524/1762] D loss: 1.3553\n",
      "[1604/1762] D loss: 1.3794\n",
      "[1684/1762] D loss: 1.3663\n",
      "[1762/1762] D loss: 1.3709\n",
      "train error: \n",
      " D loss: 1.381899, D accuracy: 53.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383387, D accuracy: 51.4% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3794\n",
      "[84/1762] D loss: 1.3567\n",
      "[164/1762] D loss: 1.3833\n",
      "[244/1762] D loss: 1.3672\n",
      "[324/1762] D loss: 1.3399\n",
      "[404/1762] D loss: 1.3517\n",
      "[484/1762] D loss: 1.3816\n",
      "[564/1762] D loss: 1.3551\n",
      "[644/1762] D loss: 1.3702\n",
      "[724/1762] D loss: 1.3768\n",
      "[804/1762] D loss: 1.3614\n",
      "[884/1762] D loss: 1.3457\n",
      "[964/1762] D loss: 1.3777\n",
      "[1044/1762] D loss: 1.3722\n",
      "[1124/1762] D loss: 1.3545\n",
      "[1204/1762] D loss: 1.3785\n",
      "[1284/1762] D loss: 1.3547\n",
      "[1364/1762] D loss: 1.3987\n",
      "[1444/1762] D loss: 1.3488\n",
      "[1524/1762] D loss: 1.3945\n",
      "[1604/1762] D loss: 1.3984\n",
      "[1684/1762] D loss: 1.3730\n",
      "[1762/1762] D loss: 1.3710\n",
      "train error: \n",
      " D loss: 1.382068, D accuracy: 52.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385318, D accuracy: 51.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3522\n",
      "[84/1762] D loss: 1.3506\n",
      "[164/1762] D loss: 1.3894\n",
      "[244/1762] D loss: 1.3600\n",
      "[324/1762] D loss: 1.3513\n",
      "[404/1762] D loss: 1.3763\n",
      "[484/1762] D loss: 1.3689\n",
      "[564/1762] D loss: 1.3640\n",
      "[644/1762] D loss: 1.3909\n",
      "[724/1762] D loss: 1.3752\n",
      "[804/1762] D loss: 1.3621\n",
      "[884/1762] D loss: 1.4046\n",
      "[964/1762] D loss: 1.3972\n",
      "[1044/1762] D loss: 1.3662\n",
      "[1124/1762] D loss: 1.3847\n",
      "[1204/1762] D loss: 1.3808\n",
      "[1284/1762] D loss: 1.3726\n",
      "[1364/1762] D loss: 1.3456\n",
      "[1444/1762] D loss: 1.3695\n",
      "[1524/1762] D loss: 1.4052\n",
      "[1604/1762] D loss: 1.3935\n",
      "[1684/1762] D loss: 1.3647\n",
      "[1762/1762] D loss: 1.3709\n",
      "train error: \n",
      " D loss: 1.380038, D accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381792, D accuracy: 52.7% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4113\n",
      "[84/1762] D loss: 1.3599\n",
      "[164/1762] D loss: 1.3652\n",
      "[244/1762] D loss: 1.3726\n",
      "[324/1762] D loss: 1.3720\n",
      "[404/1762] D loss: 1.3641\n",
      "[484/1762] D loss: 1.3798\n",
      "[564/1762] D loss: 1.3554\n",
      "[644/1762] D loss: 1.3777\n",
      "[724/1762] D loss: 1.3889\n",
      "[804/1762] D loss: 1.3641\n",
      "[884/1762] D loss: 1.3701\n",
      "[964/1762] D loss: 1.3549\n",
      "[1044/1762] D loss: 1.3659\n",
      "[1124/1762] D loss: 1.3577\n",
      "[1204/1762] D loss: 1.3714\n",
      "[1284/1762] D loss: 1.3846\n",
      "[1364/1762] D loss: 1.3687\n",
      "[1444/1762] D loss: 1.3675\n",
      "[1524/1762] D loss: 1.3691\n",
      "[1604/1762] D loss: 1.3324\n",
      "[1684/1762] D loss: 1.3748\n",
      "[1762/1762] D loss: 1.3676\n",
      "train error: \n",
      " D loss: 1.378393, D accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379725, D accuracy: 52.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892\n",
      "[84/1762] D loss: 1.3858\n",
      "[164/1762] D loss: 1.3644\n",
      "[244/1762] D loss: 1.3636\n",
      "[324/1762] D loss: 1.3614\n",
      "[404/1762] D loss: 1.3597\n",
      "[484/1762] D loss: 1.3893\n",
      "[564/1762] D loss: 1.3951\n",
      "[644/1762] D loss: 1.3702\n",
      "[724/1762] D loss: 1.3592\n",
      "[804/1762] D loss: 1.4343\n",
      "[884/1762] D loss: 1.3807\n",
      "[964/1762] D loss: 1.3966\n",
      "[1044/1762] D loss: 1.3782\n",
      "[1124/1762] D loss: 1.3793\n",
      "[1204/1762] D loss: 1.3764\n",
      "[1284/1762] D loss: 1.3905\n",
      "[1364/1762] D loss: 1.3825\n",
      "[1444/1762] D loss: 1.3576\n",
      "[1524/1762] D loss: 1.3508\n",
      "[1604/1762] D loss: 1.3639\n",
      "[1684/1762] D loss: 1.3755\n",
      "[1762/1762] D loss: 1.3746\n",
      "train error: \n",
      " D loss: 1.378738, D accuracy: 54.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378754, D accuracy: 52.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3630\n",
      "[84/1762] D loss: 1.3646\n",
      "[164/1762] D loss: 1.3478\n",
      "[244/1762] D loss: 1.3641\n",
      "[324/1762] D loss: 1.3553\n",
      "[404/1762] D loss: 1.3406\n",
      "[484/1762] D loss: 1.3700\n",
      "[564/1762] D loss: 1.3863\n",
      "[644/1762] D loss: 1.3711\n",
      "[724/1762] D loss: 1.3445\n",
      "[804/1762] D loss: 1.3651\n",
      "[884/1762] D loss: 1.3476\n",
      "[964/1762] D loss: 1.3786\n",
      "[1044/1762] D loss: 1.3632\n",
      "[1124/1762] D loss: 1.3480\n",
      "[1204/1762] D loss: 1.3531\n",
      "[1284/1762] D loss: 1.3762\n",
      "[1364/1762] D loss: 1.3593\n",
      "[1444/1762] D loss: 1.3678\n",
      "[1524/1762] D loss: 1.3703\n",
      "[1604/1762] D loss: 1.3818\n",
      "[1684/1762] D loss: 1.3697\n",
      "[1762/1762] D loss: 1.3919\n",
      "train error: \n",
      " D loss: 1.378341, D accuracy: 54.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378903, D accuracy: 53.6% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3778\n",
      "[84/1762] D loss: 1.3913\n",
      "[164/1762] D loss: 1.3596\n",
      "[244/1762] D loss: 1.3715\n",
      "[324/1762] D loss: 1.3757\n",
      "[404/1762] D loss: 1.3466\n",
      "[484/1762] D loss: 1.3825\n",
      "[564/1762] D loss: 1.3648\n",
      "[644/1762] D loss: 1.3852\n",
      "[724/1762] D loss: 1.3393\n",
      "[804/1762] D loss: 1.3844\n",
      "[884/1762] D loss: 1.3739\n",
      "[964/1762] D loss: 1.3418\n",
      "[1044/1762] D loss: 1.3600\n",
      "[1124/1762] D loss: 1.3597\n",
      "[1204/1762] D loss: 1.3484\n",
      "[1284/1762] D loss: 1.3557\n",
      "[1364/1762] D loss: 1.3731\n",
      "[1444/1762] D loss: 1.3607\n",
      "[1524/1762] D loss: 1.3511\n",
      "[1604/1762] D loss: 1.3773\n",
      "[1684/1762] D loss: 1.3916\n",
      "[1762/1762] D loss: 1.4172\n",
      "train error: \n",
      " D loss: 1.377624, D accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376953, D accuracy: 53.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3570\n",
      "[84/1762] D loss: 1.3612\n",
      "[164/1762] D loss: 1.3776\n",
      "[244/1762] D loss: 1.3700\n",
      "[324/1762] D loss: 1.3800\n",
      "[404/1762] D loss: 1.3337\n",
      "[484/1762] D loss: 1.3910\n",
      "[564/1762] D loss: 1.3726\n",
      "[644/1762] D loss: 1.3675\n",
      "[724/1762] D loss: 1.3691\n",
      "[804/1762] D loss: 1.3608\n",
      "[884/1762] D loss: 1.3776\n",
      "[964/1762] D loss: 1.3614\n",
      "[1044/1762] D loss: 1.3683\n",
      "[1124/1762] D loss: 1.3958\n",
      "[1204/1762] D loss: 1.3499\n",
      "[1284/1762] D loss: 1.3722\n",
      "[1364/1762] D loss: 1.3904\n",
      "[1444/1762] D loss: 1.3894\n",
      "[1524/1762] D loss: 1.3847\n",
      "[1604/1762] D loss: 1.3391\n",
      "[1684/1762] D loss: 1.3400\n",
      "[1762/1762] D loss: 1.3489\n",
      "train error: \n",
      " D loss: 1.376787, D accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376635, D accuracy: 54.4% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3725\n",
      "[84/1762] D loss: 1.3708\n",
      "[164/1762] D loss: 1.3666\n",
      "[244/1762] D loss: 1.3428\n",
      "[324/1762] D loss: 1.3570\n",
      "[404/1762] D loss: 1.3646\n",
      "[484/1762] D loss: 1.3814\n",
      "[564/1762] D loss: 1.3832\n",
      "[644/1762] D loss: 1.3948\n",
      "[724/1762] D loss: 1.3623\n",
      "[804/1762] D loss: 1.3532\n",
      "[884/1762] D loss: 1.3491\n",
      "[964/1762] D loss: 1.3443\n",
      "[1044/1762] D loss: 1.3753\n",
      "[1124/1762] D loss: 1.3691\n",
      "[1204/1762] D loss: 1.3859\n",
      "[1284/1762] D loss: 1.3523\n",
      "[1364/1762] D loss: 1.3441\n",
      "[1444/1762] D loss: 1.3628\n",
      "[1524/1762] D loss: 1.3919\n",
      "[1604/1762] D loss: 1.3766\n",
      "[1684/1762] D loss: 1.3926\n",
      "[1762/1762] D loss: 1.3289\n",
      "train error: \n",
      " D loss: 1.376101, D accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375580, D accuracy: 54.4% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898\n",
      "[84/1762] D loss: 1.3848\n",
      "[164/1762] D loss: 1.3688\n",
      "[244/1762] D loss: 1.3691\n",
      "[324/1762] D loss: 1.3404\n",
      "[404/1762] D loss: 1.3439\n",
      "[484/1762] D loss: 1.3631\n",
      "[564/1762] D loss: 1.3583\n",
      "[644/1762] D loss: 1.3784\n",
      "[724/1762] D loss: 1.3929\n",
      "[804/1762] D loss: 1.3979\n",
      "[884/1762] D loss: 1.3437\n",
      "[964/1762] D loss: 1.3708\n",
      "[1044/1762] D loss: 1.3446\n",
      "[1124/1762] D loss: 1.3814\n",
      "[1204/1762] D loss: 1.3757\n",
      "[1284/1762] D loss: 1.3688\n",
      "[1364/1762] D loss: 1.3621\n",
      "[1444/1762] D loss: 1.3962\n",
      "[1524/1762] D loss: 1.3466\n",
      "[1604/1762] D loss: 1.3645\n",
      "[1684/1762] D loss: 1.3808\n",
      "[1762/1762] D loss: 1.4145\n",
      "train error: \n",
      " D loss: 1.375510, D accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374594, D accuracy: 55.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3524\n",
      "[84/1762] D loss: 1.4137\n",
      "[164/1762] D loss: 1.3782\n",
      "[244/1762] D loss: 1.3792\n",
      "[324/1762] D loss: 1.4022\n",
      "[404/1762] D loss: 1.3417\n",
      "[484/1762] D loss: 1.3223\n",
      "[564/1762] D loss: 1.3740\n",
      "[644/1762] D loss: 1.3496\n",
      "[724/1762] D loss: 1.3675\n",
      "[804/1762] D loss: 1.3861\n",
      "[884/1762] D loss: 1.3756\n",
      "[964/1762] D loss: 1.3799\n",
      "[1044/1762] D loss: 1.3754\n",
      "[1124/1762] D loss: 1.3640\n",
      "[1204/1762] D loss: 1.3638\n",
      "[1284/1762] D loss: 1.3708\n",
      "[1364/1762] D loss: 1.3609\n",
      "[1444/1762] D loss: 1.3471\n",
      "[1524/1762] D loss: 1.3620\n",
      "[1604/1762] D loss: 1.3698\n",
      "[1684/1762] D loss: 1.3620\n",
      "[1762/1762] D loss: 1.3517\n",
      "train error: \n",
      " D loss: 1.376095, D accuracy: 55.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373459, D accuracy: 55.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3777\n",
      "[84/1762] D loss: 1.3798\n",
      "[164/1762] D loss: 1.3662\n",
      "[244/1762] D loss: 1.3694\n",
      "[324/1762] D loss: 1.4014\n",
      "[404/1762] D loss: 1.3758\n",
      "[484/1762] D loss: 1.3672\n",
      "[564/1762] D loss: 1.3361\n",
      "[644/1762] D loss: 1.3581\n",
      "[724/1762] D loss: 1.3764\n",
      "[804/1762] D loss: 1.3352\n",
      "[884/1762] D loss: 1.3535\n",
      "[964/1762] D loss: 1.3779\n",
      "[1044/1762] D loss: 1.3632\n",
      "[1124/1762] D loss: 1.3727\n",
      "[1204/1762] D loss: 1.3494\n",
      "[1284/1762] D loss: 1.3776\n",
      "[1364/1762] D loss: 1.3656\n",
      "[1444/1762] D loss: 1.4281\n",
      "[1524/1762] D loss: 1.3480\n",
      "[1604/1762] D loss: 1.3683\n",
      "[1684/1762] D loss: 1.3640\n",
      "[1762/1762] D loss: 1.3766\n",
      "train error: \n",
      " D loss: 1.373865, D accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374383, D accuracy: 54.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3681\n",
      "[84/1762] D loss: 1.3632\n",
      "[164/1762] D loss: 1.3894\n",
      "[244/1762] D loss: 1.3771\n",
      "[324/1762] D loss: 1.3854\n",
      "[404/1762] D loss: 1.3853\n",
      "[484/1762] D loss: 1.3633\n",
      "[564/1762] D loss: 1.3848\n",
      "[644/1762] D loss: 1.3623\n",
      "[724/1762] D loss: 1.3810\n",
      "[804/1762] D loss: 1.3674\n",
      "[884/1762] D loss: 1.3287\n",
      "[964/1762] D loss: 1.3763\n",
      "[1044/1762] D loss: 1.3668\n",
      "[1124/1762] D loss: 1.3496\n",
      "[1204/1762] D loss: 1.3608\n",
      "[1284/1762] D loss: 1.3675\n",
      "[1364/1762] D loss: 1.3467\n",
      "[1444/1762] D loss: 1.3756\n",
      "[1524/1762] D loss: 1.3549\n",
      "[1604/1762] D loss: 1.3495\n",
      "[1684/1762] D loss: 1.3798\n",
      "[1762/1762] D loss: 1.3612\n",
      "train error: \n",
      " D loss: 1.373745, D accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375760, D accuracy: 53.9% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3656\n",
      "[84/1762] D loss: 1.3865\n",
      "[164/1762] D loss: 1.3342\n",
      "[244/1762] D loss: 1.3453\n",
      "[324/1762] D loss: 1.3412\n",
      "[404/1762] D loss: 1.3618\n",
      "[484/1762] D loss: 1.3331\n",
      "[564/1762] D loss: 1.3940\n",
      "[644/1762] D loss: 1.3634\n",
      "[724/1762] D loss: 1.3754\n",
      "[804/1762] D loss: 1.3612\n",
      "[884/1762] D loss: 1.3623\n",
      "[964/1762] D loss: 1.3845\n",
      "[1044/1762] D loss: 1.3550\n",
      "[1124/1762] D loss: 1.3538\n",
      "[1204/1762] D loss: 1.3833\n",
      "[1284/1762] D loss: 1.3561\n",
      "[1364/1762] D loss: 1.3588\n",
      "[1444/1762] D loss: 1.3450\n",
      "[1524/1762] D loss: 1.3642\n",
      "[1604/1762] D loss: 1.3530\n",
      "[1684/1762] D loss: 1.3697\n",
      "[1762/1762] D loss: 1.3469\n",
      "train error: \n",
      " D loss: 1.371634, D accuracy: 55.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372008, D accuracy: 54.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3600\n",
      "[84/1762] D loss: 1.3528\n",
      "[164/1762] D loss: 1.3768\n",
      "[244/1762] D loss: 1.3731\n",
      "[324/1762] D loss: 1.3745\n",
      "[404/1762] D loss: 1.3715\n",
      "[484/1762] D loss: 1.3407\n",
      "[564/1762] D loss: 1.3526\n",
      "[644/1762] D loss: 1.3680\n",
      "[724/1762] D loss: 1.3828\n",
      "[804/1762] D loss: 1.3500\n",
      "[884/1762] D loss: 1.3450\n",
      "[964/1762] D loss: 1.3514\n",
      "[1044/1762] D loss: 1.3808\n",
      "[1124/1762] D loss: 1.3738\n",
      "[1204/1762] D loss: 1.3548\n",
      "[1284/1762] D loss: 1.3438\n",
      "[1364/1762] D loss: 1.3546\n",
      "[1444/1762] D loss: 1.3396\n",
      "[1524/1762] D loss: 1.3597\n",
      "[1604/1762] D loss: 1.3773\n",
      "[1684/1762] D loss: 1.3765\n",
      "[1762/1762] D loss: 1.3524\n",
      "train error: \n",
      " D loss: 1.372357, D accuracy: 55.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372610, D accuracy: 55.1% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3489\n",
      "[84/1762] D loss: 1.3260\n",
      "[164/1762] D loss: 1.3360\n",
      "[244/1762] D loss: 1.3536\n",
      "[324/1762] D loss: 1.3722\n",
      "[404/1762] D loss: 1.3660\n",
      "[484/1762] D loss: 1.3777\n",
      "[564/1762] D loss: 1.3609\n",
      "[644/1762] D loss: 1.3683\n",
      "[724/1762] D loss: 1.3959\n",
      "[804/1762] D loss: 1.3673\n",
      "[884/1762] D loss: 1.3214\n",
      "[964/1762] D loss: 1.3306\n",
      "[1044/1762] D loss: 1.3658\n",
      "[1124/1762] D loss: 1.3626\n",
      "[1204/1762] D loss: 1.3448\n",
      "[1284/1762] D loss: 1.3822\n",
      "[1364/1762] D loss: 1.3842\n",
      "[1444/1762] D loss: 1.3701\n",
      "[1524/1762] D loss: 1.3690\n",
      "[1604/1762] D loss: 1.3569\n",
      "[1684/1762] D loss: 1.3524\n",
      "[1762/1762] D loss: 1.3572\n",
      "train error: \n",
      " D loss: 1.371555, D accuracy: 56.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372332, D accuracy: 54.4% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3384\n",
      "[84/1762] D loss: 1.3788\n",
      "[164/1762] D loss: 1.3387\n",
      "[244/1762] D loss: 1.3490\n",
      "[324/1762] D loss: 1.3437\n",
      "[404/1762] D loss: 1.3798\n",
      "[484/1762] D loss: 1.3762\n",
      "[564/1762] D loss: 1.3496\n",
      "[644/1762] D loss: 1.3509\n",
      "[724/1762] D loss: 1.3871\n",
      "[804/1762] D loss: 1.3782\n",
      "[884/1762] D loss: 1.3485\n",
      "[964/1762] D loss: 1.3718\n",
      "[1044/1762] D loss: 1.3730\n",
      "[1124/1762] D loss: 1.3625\n",
      "[1204/1762] D loss: 1.3816\n",
      "[1284/1762] D loss: 1.3543\n",
      "[1364/1762] D loss: 1.3435\n",
      "[1444/1762] D loss: 1.3535\n",
      "[1524/1762] D loss: 1.3278\n",
      "[1604/1762] D loss: 1.3732\n",
      "[1684/1762] D loss: 1.3797\n",
      "[1762/1762] D loss: 1.3355\n",
      "train error: \n",
      " D loss: 1.370875, D accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371648, D accuracy: 54.7% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3249\n",
      "[84/1762] D loss: 1.3720\n",
      "[164/1762] D loss: 1.3411\n",
      "[244/1762] D loss: 1.3459\n",
      "[324/1762] D loss: 1.3453\n",
      "[404/1762] D loss: 1.3570\n",
      "[484/1762] D loss: 1.3222\n",
      "[564/1762] D loss: 1.3803\n",
      "[644/1762] D loss: 1.3507\n",
      "[724/1762] D loss: 1.3778\n",
      "[804/1762] D loss: 1.3666\n",
      "[884/1762] D loss: 1.3505\n",
      "[964/1762] D loss: 1.3513\n",
      "[1044/1762] D loss: 1.3675\n",
      "[1124/1762] D loss: 1.3677\n",
      "[1204/1762] D loss: 1.3515\n",
      "[1284/1762] D loss: 1.3243\n",
      "[1364/1762] D loss: 1.3309\n",
      "[1444/1762] D loss: 1.3741\n",
      "[1524/1762] D loss: 1.3486\n",
      "[1604/1762] D loss: 1.3664\n",
      "[1684/1762] D loss: 1.3549\n",
      "[1762/1762] D loss: 1.3764\n",
      "train error: \n",
      " D loss: 1.370554, D accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369432, D accuracy: 55.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3547\n",
      "[84/1762] D loss: 1.3708\n",
      "[164/1762] D loss: 1.3836\n",
      "[244/1762] D loss: 1.3604\n",
      "[324/1762] D loss: 1.3632\n",
      "[404/1762] D loss: 1.3239\n",
      "[484/1762] D loss: 1.3512\n",
      "[564/1762] D loss: 1.3632\n",
      "[644/1762] D loss: 1.3447\n",
      "[724/1762] D loss: 1.3539\n",
      "[804/1762] D loss: 1.3724\n",
      "[884/1762] D loss: 1.3542\n",
      "[964/1762] D loss: 1.3916\n",
      "[1044/1762] D loss: 1.3348\n",
      "[1124/1762] D loss: 1.3567\n",
      "[1204/1762] D loss: 1.3480\n",
      "[1284/1762] D loss: 1.3781\n",
      "[1364/1762] D loss: 1.3432\n",
      "[1444/1762] D loss: 1.3780\n",
      "[1524/1762] D loss: 1.3452\n",
      "[1604/1762] D loss: 1.3575\n",
      "[1684/1762] D loss: 1.3478\n",
      "[1762/1762] D loss: 1.3363\n",
      "train error: \n",
      " D loss: 1.370064, D accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367745, D accuracy: 55.3% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921\n",
      "[84/1762] D loss: 1.3625\n",
      "[164/1762] D loss: 1.3347\n",
      "[244/1762] D loss: 1.3598\n",
      "[324/1762] D loss: 1.3418\n",
      "[404/1762] D loss: 1.3537\n",
      "[484/1762] D loss: 1.3397\n",
      "[564/1762] D loss: 1.3721\n",
      "[644/1762] D loss: 1.3539\n",
      "[724/1762] D loss: 1.3707\n",
      "[804/1762] D loss: 1.3676\n",
      "[884/1762] D loss: 1.3340\n",
      "[964/1762] D loss: 1.3528\n",
      "[1044/1762] D loss: 1.3884\n",
      "[1124/1762] D loss: 1.3467\n",
      "[1204/1762] D loss: 1.3741\n",
      "[1284/1762] D loss: 1.3564\n",
      "[1364/1762] D loss: 1.3540\n",
      "[1444/1762] D loss: 1.3428\n",
      "[1524/1762] D loss: 1.3511\n",
      "[1604/1762] D loss: 1.3600\n",
      "[1684/1762] D loss: 1.3233\n",
      "[1762/1762] D loss: 1.3716\n",
      "train error: \n",
      " D loss: 1.368703, D accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369824, D accuracy: 55.3% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3489\n",
      "[84/1762] D loss: 1.3828\n",
      "[164/1762] D loss: 1.3518\n",
      "[244/1762] D loss: 1.3570\n",
      "[324/1762] D loss: 1.3861\n",
      "[404/1762] D loss: 1.3356\n",
      "[484/1762] D loss: 1.3590\n",
      "[564/1762] D loss: 1.3577\n",
      "[644/1762] D loss: 1.3808\n",
      "[724/1762] D loss: 1.3483\n",
      "[804/1762] D loss: 1.3620\n",
      "[884/1762] D loss: 1.3859\n",
      "[964/1762] D loss: 1.3897\n",
      "[1044/1762] D loss: 1.3571\n",
      "[1124/1762] D loss: 1.3579\n",
      "[1204/1762] D loss: 1.3774\n",
      "[1284/1762] D loss: 1.3537\n",
      "[1364/1762] D loss: 1.3760\n",
      "[1444/1762] D loss: 1.3522\n",
      "[1524/1762] D loss: 1.3555\n",
      "[1604/1762] D loss: 1.3225\n",
      "[1684/1762] D loss: 1.3833\n",
      "[1762/1762] D loss: 1.4031\n",
      "train error: \n",
      " D loss: 1.367501, D accuracy: 56.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367724, D accuracy: 56.1% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3248\n",
      "[84/1762] D loss: 1.3144\n",
      "[164/1762] D loss: 1.3302\n",
      "[244/1762] D loss: 1.3733\n",
      "[324/1762] D loss: 1.3467\n",
      "[404/1762] D loss: 1.3558\n",
      "[484/1762] D loss: 1.4039\n",
      "[564/1762] D loss: 1.3493\n",
      "[644/1762] D loss: 1.3764\n",
      "[724/1762] D loss: 1.3355\n",
      "[804/1762] D loss: 1.3449\n",
      "[884/1762] D loss: 1.3659\n",
      "[964/1762] D loss: 1.3807\n",
      "[1044/1762] D loss: 1.4213\n",
      "[1124/1762] D loss: 1.3495\n",
      "[1204/1762] D loss: 1.3658\n",
      "[1284/1762] D loss: 1.3623\n",
      "[1364/1762] D loss: 1.3654\n",
      "[1444/1762] D loss: 1.3789\n",
      "[1524/1762] D loss: 1.3599\n",
      "[1604/1762] D loss: 1.3603\n",
      "[1684/1762] D loss: 1.3795\n",
      "[1762/1762] D loss: 1.3781\n",
      "train error: \n",
      " D loss: 1.365739, D accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367204, D accuracy: 56.7% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3453\n",
      "[84/1762] D loss: 1.3521\n",
      "[164/1762] D loss: 1.3629\n",
      "[244/1762] D loss: 1.3754\n",
      "[324/1762] D loss: 1.3576\n",
      "[404/1762] D loss: 1.3250\n",
      "[484/1762] D loss: 1.3565\n",
      "[564/1762] D loss: 1.3395\n",
      "[644/1762] D loss: 1.3605\n",
      "[724/1762] D loss: 1.3559\n",
      "[804/1762] D loss: 1.3469\n",
      "[884/1762] D loss: 1.3311\n",
      "[964/1762] D loss: 1.3403\n",
      "[1044/1762] D loss: 1.3975\n",
      "[1124/1762] D loss: 1.3366\n",
      "[1204/1762] D loss: 1.3673\n",
      "[1284/1762] D loss: 1.3696\n",
      "[1364/1762] D loss: 1.3695\n",
      "[1444/1762] D loss: 1.3581\n",
      "[1524/1762] D loss: 1.3871\n",
      "[1604/1762] D loss: 1.3578\n",
      "[1684/1762] D loss: 1.3523\n",
      "[1762/1762] D loss: 1.3731\n",
      "train error: \n",
      " D loss: 1.365741, D accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368030, D accuracy: 55.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3181\n",
      "[84/1762] D loss: 1.3896\n",
      "[164/1762] D loss: 1.3613\n",
      "[244/1762] D loss: 1.3650\n",
      "[324/1762] D loss: 1.3828\n",
      "[404/1762] D loss: 1.3521\n",
      "[484/1762] D loss: 1.3617\n",
      "[564/1762] D loss: 1.3329\n",
      "[644/1762] D loss: 1.3664\n",
      "[724/1762] D loss: 1.3692\n",
      "[804/1762] D loss: 1.3828\n",
      "[884/1762] D loss: 1.3556\n",
      "[964/1762] D loss: 1.3333\n",
      "[1044/1762] D loss: 1.3413\n",
      "[1124/1762] D loss: 1.3403\n",
      "[1204/1762] D loss: 1.3896\n",
      "[1284/1762] D loss: 1.3493\n",
      "[1364/1762] D loss: 1.3202\n",
      "[1444/1762] D loss: 1.3452\n",
      "[1524/1762] D loss: 1.3859\n",
      "[1604/1762] D loss: 1.3423\n",
      "[1684/1762] D loss: 1.3427\n",
      "[1762/1762] D loss: 1.3606\n",
      "train error: \n",
      " D loss: 1.365133, D accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367116, D accuracy: 56.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3090\n",
      "[84/1762] D loss: 1.3415\n",
      "[164/1762] D loss: 1.3762\n",
      "[244/1762] D loss: 1.3362\n",
      "[324/1762] D loss: 1.3498\n",
      "[404/1762] D loss: 1.3440\n",
      "[484/1762] D loss: 1.3483\n",
      "[564/1762] D loss: 1.3653\n",
      "[644/1762] D loss: 1.3589\n",
      "[724/1762] D loss: 1.3241\n",
      "[804/1762] D loss: 1.3656\n",
      "[884/1762] D loss: 1.3622\n",
      "[964/1762] D loss: 1.3583\n",
      "[1044/1762] D loss: 1.3288\n",
      "[1124/1762] D loss: 1.3715\n",
      "[1204/1762] D loss: 1.3483\n",
      "[1284/1762] D loss: 1.3572\n",
      "[1364/1762] D loss: 1.3569\n",
      "[1444/1762] D loss: 1.3887\n",
      "[1524/1762] D loss: 1.3343\n",
      "[1604/1762] D loss: 1.3671\n",
      "[1684/1762] D loss: 1.3479\n",
      "[1762/1762] D loss: 1.3786\n",
      "train error: \n",
      " D loss: 1.364792, D accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366080, D accuracy: 56.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3366\n",
      "[84/1762] D loss: 1.3821\n",
      "[164/1762] D loss: 1.3635\n",
      "[244/1762] D loss: 1.3350\n",
      "[324/1762] D loss: 1.3602\n",
      "[404/1762] D loss: 1.2961\n",
      "[484/1762] D loss: 1.3251\n",
      "[564/1762] D loss: 1.3459\n",
      "[644/1762] D loss: 1.3708\n",
      "[724/1762] D loss: 1.3329\n",
      "[804/1762] D loss: 1.3670\n",
      "[884/1762] D loss: 1.3371\n",
      "[964/1762] D loss: 1.3786\n",
      "[1044/1762] D loss: 1.3879\n",
      "[1124/1762] D loss: 1.3429\n",
      "[1204/1762] D loss: 1.3443\n",
      "[1284/1762] D loss: 1.3187\n",
      "[1364/1762] D loss: 1.3713\n",
      "[1444/1762] D loss: 1.3612\n",
      "[1524/1762] D loss: 1.3297\n",
      "[1604/1762] D loss: 1.3428\n",
      "[1684/1762] D loss: 1.3405\n",
      "[1762/1762] D loss: 1.3782\n",
      "train error: \n",
      " D loss: 1.363542, D accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364160, D accuracy: 58.2% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3694\n",
      "[84/1762] D loss: 1.3727\n",
      "[164/1762] D loss: 1.3752\n",
      "[244/1762] D loss: 1.3616\n",
      "[324/1762] D loss: 1.3614\n",
      "[404/1762] D loss: 1.3750\n",
      "[484/1762] D loss: 1.3238\n",
      "[564/1762] D loss: 1.3704\n",
      "[644/1762] D loss: 1.2866\n",
      "[724/1762] D loss: 1.3195\n",
      "[804/1762] D loss: 1.3799\n",
      "[884/1762] D loss: 1.3482\n",
      "[964/1762] D loss: 1.3437\n",
      "[1044/1762] D loss: 1.3439\n",
      "[1124/1762] D loss: 1.3501\n",
      "[1204/1762] D loss: 1.3530\n",
      "[1284/1762] D loss: 1.3879\n",
      "[1364/1762] D loss: 1.3437\n",
      "[1444/1762] D loss: 1.3535\n",
      "[1524/1762] D loss: 1.3541\n",
      "[1604/1762] D loss: 1.3289\n",
      "[1684/1762] D loss: 1.3442\n",
      "[1762/1762] D loss: 1.3780\n",
      "train error: \n",
      " D loss: 1.362241, D accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363551, D accuracy: 55.6% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3766\n",
      "[84/1762] D loss: 1.3644\n",
      "[164/1762] D loss: 1.3424\n",
      "[244/1762] D loss: 1.3548\n",
      "[324/1762] D loss: 1.3711\n",
      "[404/1762] D loss: 1.3378\n",
      "[484/1762] D loss: 1.3280\n",
      "[564/1762] D loss: 1.3680\n",
      "[644/1762] D loss: 1.3367\n",
      "[724/1762] D loss: 1.3450\n",
      "[804/1762] D loss: 1.3525\n",
      "[884/1762] D loss: 1.3478\n",
      "[964/1762] D loss: 1.3404\n",
      "[1044/1762] D loss: 1.3231\n",
      "[1124/1762] D loss: 1.3779\n",
      "[1204/1762] D loss: 1.3243\n",
      "[1284/1762] D loss: 1.3544\n",
      "[1364/1762] D loss: 1.3676\n",
      "[1444/1762] D loss: 1.3684\n",
      "[1524/1762] D loss: 1.3915\n",
      "[1604/1762] D loss: 1.3688\n",
      "[1684/1762] D loss: 1.3556\n",
      "[1762/1762] D loss: 1.3436\n",
      "train error: \n",
      " D loss: 1.361260, D accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359119, D accuracy: 58.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3812\n",
      "[84/1762] D loss: 1.3264\n",
      "[164/1762] D loss: 1.3965\n",
      "[244/1762] D loss: 1.3840\n",
      "[324/1762] D loss: 1.3184\n",
      "[404/1762] D loss: 1.3546\n",
      "[484/1762] D loss: 1.3086\n",
      "[564/1762] D loss: 1.3529\n",
      "[644/1762] D loss: 1.3424\n",
      "[724/1762] D loss: 1.3483\n",
      "[804/1762] D loss: 1.3489\n",
      "[884/1762] D loss: 1.3722\n",
      "[964/1762] D loss: 1.3702\n",
      "[1044/1762] D loss: 1.3503\n",
      "[1124/1762] D loss: 1.3915\n",
      "[1204/1762] D loss: 1.3420\n",
      "[1284/1762] D loss: 1.3238\n",
      "[1364/1762] D loss: 1.3664\n",
      "[1444/1762] D loss: 1.3703\n",
      "[1524/1762] D loss: 1.3715\n",
      "[1604/1762] D loss: 1.3786\n",
      "[1684/1762] D loss: 1.3628\n",
      "[1762/1762] D loss: 1.3525\n",
      "train error: \n",
      " D loss: 1.359677, D accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362798, D accuracy: 57.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3560\n",
      "[84/1762] D loss: 1.3458\n",
      "[164/1762] D loss: 1.3207\n",
      "[244/1762] D loss: 1.3714\n",
      "[324/1762] D loss: 1.3254\n",
      "[404/1762] D loss: 1.3501\n",
      "[484/1762] D loss: 1.3489\n",
      "[564/1762] D loss: 1.3588\n",
      "[644/1762] D loss: 1.3346\n",
      "[724/1762] D loss: 1.3318\n",
      "[804/1762] D loss: 1.3620\n",
      "[884/1762] D loss: 1.3187\n",
      "[964/1762] D loss: 1.3415\n",
      "[1044/1762] D loss: 1.3321\n",
      "[1124/1762] D loss: 1.3484\n",
      "[1204/1762] D loss: 1.3515\n",
      "[1284/1762] D loss: 1.3642\n",
      "[1364/1762] D loss: 1.3477\n",
      "[1444/1762] D loss: 1.3477\n",
      "[1524/1762] D loss: 1.3520\n",
      "[1604/1762] D loss: 1.3364\n",
      "[1684/1762] D loss: 1.3215\n",
      "[1762/1762] D loss: 1.3053\n",
      "train error: \n",
      " D loss: 1.357761, D accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356541, D accuracy: 59.7% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863\n",
      "[84/1762] D loss: 1.3826\n",
      "[164/1762] D loss: 1.3510\n",
      "[244/1762] D loss: 1.3427\n",
      "[324/1762] D loss: 1.3396\n",
      "[404/1762] D loss: 1.3794\n",
      "[484/1762] D loss: 1.3245\n",
      "[564/1762] D loss: 1.3607\n",
      "[644/1762] D loss: 1.3076\n",
      "[724/1762] D loss: 1.3450\n",
      "[804/1762] D loss: 1.3211\n",
      "[884/1762] D loss: 1.3398\n",
      "[964/1762] D loss: 1.3238\n",
      "[1044/1762] D loss: 1.3515\n",
      "[1124/1762] D loss: 1.3184\n",
      "[1204/1762] D loss: 1.3662\n",
      "[1284/1762] D loss: 1.3171\n",
      "[1364/1762] D loss: 1.3518\n",
      "[1444/1762] D loss: 1.3579\n",
      "[1524/1762] D loss: 1.3427\n",
      "[1604/1762] D loss: 1.3843\n",
      "[1684/1762] D loss: 1.3683\n",
      "[1762/1762] D loss: 1.3221\n",
      "train error: \n",
      " D loss: 1.357389, D accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357026, D accuracy: 59.5% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3426\n",
      "[84/1762] D loss: 1.3520\n",
      "[164/1762] D loss: 1.3614\n",
      "[244/1762] D loss: 1.3804\n",
      "[324/1762] D loss: 1.3470\n",
      "[404/1762] D loss: 1.3413\n",
      "[484/1762] D loss: 1.3288\n",
      "[564/1762] D loss: 1.3196\n",
      "[644/1762] D loss: 1.3695\n",
      "[724/1762] D loss: 1.3430\n",
      "[804/1762] D loss: 1.3763\n",
      "[884/1762] D loss: 1.3477\n",
      "[964/1762] D loss: 1.3429\n",
      "[1044/1762] D loss: 1.3229\n",
      "[1124/1762] D loss: 1.3584\n",
      "[1204/1762] D loss: 1.3669\n",
      "[1284/1762] D loss: 1.3545\n",
      "[1364/1762] D loss: 1.3051\n",
      "[1444/1762] D loss: 1.3548\n",
      "[1524/1762] D loss: 1.3321\n",
      "[1604/1762] D loss: 1.2909\n",
      "[1684/1762] D loss: 1.3414\n",
      "[1762/1762] D loss: 1.3302\n",
      "train error: \n",
      " D loss: 1.353707, D accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355809, D accuracy: 58.6% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3502\n",
      "[84/1762] D loss: 1.3060\n",
      "[164/1762] D loss: 1.3312\n",
      "[244/1762] D loss: 1.3766\n",
      "[324/1762] D loss: 1.3651\n",
      "[404/1762] D loss: 1.3088\n",
      "[484/1762] D loss: 1.3335\n",
      "[564/1762] D loss: 1.2991\n",
      "[644/1762] D loss: 1.3455\n",
      "[724/1762] D loss: 1.3818\n",
      "[804/1762] D loss: 1.3477\n",
      "[884/1762] D loss: 1.2955\n",
      "[964/1762] D loss: 1.3433\n",
      "[1044/1762] D loss: 1.3356\n",
      "[1124/1762] D loss: 1.3532\n",
      "[1204/1762] D loss: 1.3511\n",
      "[1284/1762] D loss: 1.3602\n",
      "[1364/1762] D loss: 1.3395\n",
      "[1444/1762] D loss: 1.3094\n",
      "[1524/1762] D loss: 1.3742\n",
      "[1604/1762] D loss: 1.3734\n",
      "[1684/1762] D loss: 1.3720\n",
      "[1762/1762] D loss: 1.3406\n",
      "train error: \n",
      " D loss: 1.357972, D accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357817, D accuracy: 59.3% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3647\n",
      "[84/1762] D loss: 1.3408\n",
      "[164/1762] D loss: 1.3531\n",
      "[244/1762] D loss: 1.3470\n",
      "[324/1762] D loss: 1.3485\n",
      "[404/1762] D loss: 1.3833\n",
      "[484/1762] D loss: 1.3248\n",
      "[564/1762] D loss: 1.3445\n",
      "[644/1762] D loss: 1.3500\n",
      "[724/1762] D loss: 1.3539\n",
      "[804/1762] D loss: 1.3316\n",
      "[884/1762] D loss: 1.3894\n",
      "[964/1762] D loss: 1.3725\n",
      "[1044/1762] D loss: 1.3446\n",
      "[1124/1762] D loss: 1.3678\n",
      "[1204/1762] D loss: 1.3268\n",
      "[1284/1762] D loss: 1.3261\n",
      "[1364/1762] D loss: 1.3720\n",
      "[1444/1762] D loss: 1.3511\n",
      "[1524/1762] D loss: 1.3370\n",
      "[1604/1762] D loss: 1.3023\n",
      "[1684/1762] D loss: 1.3841\n",
      "[1762/1762] D loss: 1.3429\n",
      "train error: \n",
      " D loss: 1.355592, D accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360545, D accuracy: 59.1% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3168\n",
      "[84/1762] D loss: 1.3139\n",
      "[164/1762] D loss: 1.3353\n",
      "[244/1762] D loss: 1.3717\n",
      "[324/1762] D loss: 1.3271\n",
      "[404/1762] D loss: 1.3346\n",
      "[484/1762] D loss: 1.3042\n",
      "[564/1762] D loss: 1.3082\n",
      "[644/1762] D loss: 1.3505\n",
      "[724/1762] D loss: 1.3376\n",
      "[804/1762] D loss: 1.3661\n",
      "[884/1762] D loss: 1.3529\n",
      "[964/1762] D loss: 1.3036\n",
      "[1044/1762] D loss: 1.3227\n",
      "[1124/1762] D loss: 1.3746\n",
      "[1204/1762] D loss: 1.3294\n",
      "[1284/1762] D loss: 1.3210\n",
      "[1364/1762] D loss: 1.3377\n",
      "[1444/1762] D loss: 1.3634\n",
      "[1524/1762] D loss: 1.3734\n",
      "[1604/1762] D loss: 1.3174\n",
      "[1684/1762] D loss: 1.3558\n",
      "[1762/1762] D loss: 1.3134\n",
      "train error: \n",
      " D loss: 1.353952, D accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356526, D accuracy: 59.3% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3262\n",
      "[84/1762] D loss: 1.3267\n",
      "[164/1762] D loss: 1.3176\n",
      "[244/1762] D loss: 1.2899\n",
      "[324/1762] D loss: 1.3563\n",
      "[404/1762] D loss: 1.3430\n",
      "[484/1762] D loss: 1.3380\n",
      "[564/1762] D loss: 1.4111\n",
      "[644/1762] D loss: 1.3831\n",
      "[724/1762] D loss: 1.3606\n",
      "[804/1762] D loss: 1.3535\n",
      "[884/1762] D loss: 1.3350\n",
      "[964/1762] D loss: 1.3170\n",
      "[1044/1762] D loss: 1.3179\n",
      "[1124/1762] D loss: 1.3439\n",
      "[1204/1762] D loss: 1.3381\n",
      "[1284/1762] D loss: 1.3010\n",
      "[1364/1762] D loss: 1.3450\n",
      "[1444/1762] D loss: 1.3191\n",
      "[1524/1762] D loss: 1.2873\n",
      "[1604/1762] D loss: 1.3308\n",
      "[1684/1762] D loss: 1.3212\n",
      "[1762/1762] D loss: 1.3215\n",
      "train error: \n",
      " D loss: 1.353869, D accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355206, D accuracy: 58.3% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3530\n",
      "[84/1762] D loss: 1.3654\n",
      "[164/1762] D loss: 1.3632\n",
      "[244/1762] D loss: 1.3298\n",
      "[324/1762] D loss: 1.2872\n",
      "[404/1762] D loss: 1.3650\n",
      "[484/1762] D loss: 1.3596\n",
      "[564/1762] D loss: 1.3692\n",
      "[644/1762] D loss: 1.3517\n",
      "[724/1762] D loss: 1.3040\n",
      "[804/1762] D loss: 1.3769\n",
      "[884/1762] D loss: 1.3314\n",
      "[964/1762] D loss: 1.3380\n",
      "[1044/1762] D loss: 1.3031\n",
      "[1124/1762] D loss: 1.3408\n",
      "[1204/1762] D loss: 1.3441\n",
      "[1284/1762] D loss: 1.3904\n",
      "[1364/1762] D loss: 1.3706\n",
      "[1444/1762] D loss: 1.3535\n",
      "[1524/1762] D loss: 1.3685\n",
      "[1604/1762] D loss: 1.3757\n",
      "[1684/1762] D loss: 1.3619\n",
      "[1762/1762] D loss: 1.3280\n",
      "train error: \n",
      " D loss: 1.354110, D accuracy: 60.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353386, D accuracy: 60.2% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3014\n",
      "[84/1762] D loss: 1.3511\n",
      "[164/1762] D loss: 1.3188\n",
      "[244/1762] D loss: 1.3509\n",
      "[324/1762] D loss: 1.3114\n",
      "[404/1762] D loss: 1.3562\n",
      "[484/1762] D loss: 1.3192\n",
      "[564/1762] D loss: 1.3140\n",
      "[644/1762] D loss: 1.3375\n",
      "[724/1762] D loss: 1.3396\n",
      "[804/1762] D loss: 1.3461\n",
      "[884/1762] D loss: 1.3021\n",
      "[964/1762] D loss: 1.3191\n",
      "[1044/1762] D loss: 1.3479\n",
      "[1124/1762] D loss: 1.3086\n",
      "[1204/1762] D loss: 1.3748\n",
      "[1284/1762] D loss: 1.3555\n",
      "[1364/1762] D loss: 1.3172\n",
      "[1444/1762] D loss: 1.3651\n",
      "[1524/1762] D loss: 1.3431\n",
      "[1604/1762] D loss: 1.3631\n",
      "[1684/1762] D loss: 1.3262\n",
      "[1762/1762] D loss: 1.3927\n",
      "train error: \n",
      " D loss: 1.350675, D accuracy: 61.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355070, D accuracy: 59.7% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4103\n",
      "[84/1762] D loss: 1.4232\n",
      "[164/1762] D loss: 1.4018\n",
      "[244/1762] D loss: 1.4060\n",
      "[324/1762] D loss: 1.4344\n",
      "[404/1762] D loss: 1.4296\n",
      "[484/1762] D loss: 1.4109\n",
      "[564/1762] D loss: 1.4268\n",
      "[644/1762] D loss: 1.4254\n",
      "[724/1762] D loss: 1.4435\n",
      "[804/1762] D loss: 1.4431\n",
      "[884/1762] D loss: 1.4158\n",
      "[964/1762] D loss: 1.4175\n",
      "[1044/1762] D loss: 1.4187\n",
      "[1124/1762] D loss: 1.4320\n",
      "[1204/1762] D loss: 1.4481\n",
      "[1284/1762] D loss: 1.4117\n",
      "[1364/1762] D loss: 1.4090\n",
      "[1444/1762] D loss: 1.4178\n",
      "[1524/1762] D loss: 1.4266\n",
      "[1604/1762] D loss: 1.4155\n",
      "[1684/1762] D loss: 1.4293\n",
      "[1762/1762] D loss: 1.4080\n",
      "train error: \n",
      " D loss: 1.412951, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.413302, D accuracy: 50.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4260\n",
      "[84/1762] D loss: 1.3984\n",
      "[164/1762] D loss: 1.4265\n",
      "[244/1762] D loss: 1.3944\n",
      "[324/1762] D loss: 1.3966\n",
      "[404/1762] D loss: 1.4046\n",
      "[484/1762] D loss: 1.4197\n",
      "[564/1762] D loss: 1.4251\n",
      "[644/1762] D loss: 1.4192\n",
      "[724/1762] D loss: 1.4064\n",
      "[804/1762] D loss: 1.4045\n",
      "[884/1762] D loss: 1.4265\n",
      "[964/1762] D loss: 1.4122\n",
      "[1044/1762] D loss: 1.4096\n",
      "[1124/1762] D loss: 1.4197\n",
      "[1204/1762] D loss: 1.4077\n",
      "[1284/1762] D loss: 1.4087\n",
      "[1364/1762] D loss: 1.4071\n",
      "[1444/1762] D loss: 1.4081\n",
      "[1524/1762] D loss: 1.4290\n",
      "[1604/1762] D loss: 1.4140\n",
      "[1684/1762] D loss: 1.4194\n",
      "[1762/1762] D loss: 1.4099\n",
      "train error: \n",
      " D loss: 1.409427, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410798, D accuracy: 50.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4236\n",
      "[84/1762] D loss: 1.4082\n",
      "[164/1762] D loss: 1.4109\n",
      "[244/1762] D loss: 1.4271\n",
      "[324/1762] D loss: 1.4181\n",
      "[404/1762] D loss: 1.4228\n",
      "[484/1762] D loss: 1.3970\n",
      "[564/1762] D loss: 1.4099\n",
      "[644/1762] D loss: 1.4140\n",
      "[724/1762] D loss: 1.4082\n",
      "[804/1762] D loss: 1.3926\n",
      "[884/1762] D loss: 1.3977\n",
      "[964/1762] D loss: 1.4014\n",
      "[1044/1762] D loss: 1.4285\n",
      "[1124/1762] D loss: 1.4196\n",
      "[1204/1762] D loss: 1.4293\n",
      "[1284/1762] D loss: 1.4329\n",
      "[1364/1762] D loss: 1.3908\n",
      "[1444/1762] D loss: 1.3940\n",
      "[1524/1762] D loss: 1.3931\n",
      "[1604/1762] D loss: 1.4096\n",
      "[1684/1762] D loss: 1.4078\n",
      "[1762/1762] D loss: 1.4167\n",
      "train error: \n",
      " D loss: 1.407188, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.406180, D accuracy: 50.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4032\n",
      "[84/1762] D loss: 1.3974\n",
      "[164/1762] D loss: 1.4114\n",
      "[244/1762] D loss: 1.3862\n",
      "[324/1762] D loss: 1.4001\n",
      "[404/1762] D loss: 1.4093\n",
      "[484/1762] D loss: 1.4219\n",
      "[564/1762] D loss: 1.4094\n",
      "[644/1762] D loss: 1.4113\n",
      "[724/1762] D loss: 1.3964\n",
      "[804/1762] D loss: 1.4311\n",
      "[884/1762] D loss: 1.4415\n",
      "[964/1762] D loss: 1.4116\n",
      "[1044/1762] D loss: 1.4202\n",
      "[1124/1762] D loss: 1.4216\n",
      "[1204/1762] D loss: 1.4025\n",
      "[1284/1762] D loss: 1.4185\n",
      "[1364/1762] D loss: 1.3992\n",
      "[1444/1762] D loss: 1.3835\n",
      "[1524/1762] D loss: 1.4038\n",
      "[1604/1762] D loss: 1.3972\n",
      "[1684/1762] D loss: 1.3997\n",
      "[1762/1762] D loss: 1.4133\n",
      "train error: \n",
      " D loss: 1.404374, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.405225, D accuracy: 50.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4000\n",
      "[84/1762] D loss: 1.3877\n",
      "[164/1762] D loss: 1.4089\n",
      "[244/1762] D loss: 1.3944\n",
      "[324/1762] D loss: 1.4070\n",
      "[404/1762] D loss: 1.4030\n",
      "[484/1762] D loss: 1.3916\n",
      "[564/1762] D loss: 1.4157\n",
      "[644/1762] D loss: 1.4148\n",
      "[724/1762] D loss: 1.4128\n",
      "[804/1762] D loss: 1.4000\n",
      "[884/1762] D loss: 1.4186\n",
      "[964/1762] D loss: 1.3953\n",
      "[1044/1762] D loss: 1.3891\n",
      "[1124/1762] D loss: 1.4094\n",
      "[1204/1762] D loss: 1.3876\n",
      "[1284/1762] D loss: 1.4126\n",
      "[1364/1762] D loss: 1.4045\n",
      "[1444/1762] D loss: 1.4326\n",
      "[1524/1762] D loss: 1.4058\n",
      "[1604/1762] D loss: 1.3961\n",
      "[1684/1762] D loss: 1.3997\n",
      "[1762/1762] D loss: 1.4122\n",
      "train error: \n",
      " D loss: 1.402713, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401021, D accuracy: 50.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005\n",
      "[84/1762] D loss: 1.3953\n",
      "[164/1762] D loss: 1.4103\n",
      "[244/1762] D loss: 1.3973\n",
      "[324/1762] D loss: 1.4032\n",
      "[404/1762] D loss: 1.3964\n",
      "[484/1762] D loss: 1.3908\n",
      "[564/1762] D loss: 1.3972\n",
      "[644/1762] D loss: 1.3852\n",
      "[724/1762] D loss: 1.4207\n",
      "[804/1762] D loss: 1.3908\n",
      "[884/1762] D loss: 1.3922\n",
      "[964/1762] D loss: 1.4215\n",
      "[1044/1762] D loss: 1.4067\n",
      "[1124/1762] D loss: 1.4198\n",
      "[1204/1762] D loss: 1.4102\n",
      "[1284/1762] D loss: 1.4154\n",
      "[1364/1762] D loss: 1.4026\n",
      "[1444/1762] D loss: 1.3900\n",
      "[1524/1762] D loss: 1.4104\n",
      "[1604/1762] D loss: 1.3978\n",
      "[1684/1762] D loss: 1.4048\n",
      "[1762/1762] D loss: 1.4046\n",
      "train error: \n",
      " D loss: 1.400036, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399981, D accuracy: 50.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4047\n",
      "[84/1762] D loss: 1.3936\n",
      "[164/1762] D loss: 1.3941\n",
      "[244/1762] D loss: 1.4063\n",
      "[324/1762] D loss: 1.3971\n",
      "[404/1762] D loss: 1.4230\n",
      "[484/1762] D loss: 1.4005\n",
      "[564/1762] D loss: 1.4046\n",
      "[644/1762] D loss: 1.4060\n",
      "[724/1762] D loss: 1.3991\n",
      "[804/1762] D loss: 1.4094\n",
      "[884/1762] D loss: 1.4122\n",
      "[964/1762] D loss: 1.4073\n",
      "[1044/1762] D loss: 1.3923\n",
      "[1124/1762] D loss: 1.3927\n",
      "[1204/1762] D loss: 1.3796\n",
      "[1284/1762] D loss: 1.3989\n",
      "[1364/1762] D loss: 1.4048\n",
      "[1444/1762] D loss: 1.4072\n",
      "[1524/1762] D loss: 1.3849\n",
      "[1604/1762] D loss: 1.3941\n",
      "[1684/1762] D loss: 1.4025\n",
      "[1762/1762] D loss: 1.4383\n",
      "train error: \n",
      " D loss: 1.397878, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397439, D accuracy: 50.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4036\n",
      "[84/1762] D loss: 1.3986\n",
      "[164/1762] D loss: 1.4008\n",
      "[244/1762] D loss: 1.4176\n",
      "[324/1762] D loss: 1.4061\n",
      "[404/1762] D loss: 1.3972\n",
      "[484/1762] D loss: 1.3970\n",
      "[564/1762] D loss: 1.4099\n",
      "[644/1762] D loss: 1.4101\n",
      "[724/1762] D loss: 1.3968\n",
      "[804/1762] D loss: 1.3937\n",
      "[884/1762] D loss: 1.4083\n",
      "[964/1762] D loss: 1.3920\n",
      "[1044/1762] D loss: 1.4126\n",
      "[1124/1762] D loss: 1.3937\n",
      "[1204/1762] D loss: 1.4025\n",
      "[1284/1762] D loss: 1.4008\n",
      "[1364/1762] D loss: 1.3932\n",
      "[1444/1762] D loss: 1.3978\n",
      "[1524/1762] D loss: 1.3962\n",
      "[1604/1762] D loss: 1.3867\n",
      "[1684/1762] D loss: 1.4058\n",
      "[1762/1762] D loss: 1.3962\n",
      "train error: \n",
      " D loss: 1.396707, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397306, D accuracy: 50.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4033\n",
      "[84/1762] D loss: 1.3937\n",
      "[164/1762] D loss: 1.4040\n",
      "[244/1762] D loss: 1.3954\n",
      "[324/1762] D loss: 1.3955\n",
      "[404/1762] D loss: 1.3996\n",
      "[484/1762] D loss: 1.3803\n",
      "[564/1762] D loss: 1.4023\n",
      "[644/1762] D loss: 1.4030\n",
      "[724/1762] D loss: 1.3824\n",
      "[804/1762] D loss: 1.3868\n",
      "[884/1762] D loss: 1.3985\n",
      "[964/1762] D loss: 1.3847\n",
      "[1044/1762] D loss: 1.4018\n",
      "[1124/1762] D loss: 1.3973\n",
      "[1204/1762] D loss: 1.3869\n",
      "[1284/1762] D loss: 1.4127\n",
      "[1364/1762] D loss: 1.3992\n",
      "[1444/1762] D loss: 1.4137\n",
      "[1524/1762] D loss: 1.4066\n",
      "[1604/1762] D loss: 1.3836\n",
      "[1684/1762] D loss: 1.4127\n",
      "[1762/1762] D loss: 1.3910\n",
      "train error: \n",
      " D loss: 1.395412, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395983, D accuracy: 49.9% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951\n",
      "[84/1762] D loss: 1.4022\n",
      "[164/1762] D loss: 1.3943\n",
      "[244/1762] D loss: 1.3934\n",
      "[324/1762] D loss: 1.4026\n",
      "[404/1762] D loss: 1.4044\n",
      "[484/1762] D loss: 1.3885\n",
      "[564/1762] D loss: 1.3896\n",
      "[644/1762] D loss: 1.4067\n",
      "[724/1762] D loss: 1.3931\n",
      "[804/1762] D loss: 1.4036\n",
      "[884/1762] D loss: 1.4116\n",
      "[964/1762] D loss: 1.3920\n",
      "[1044/1762] D loss: 1.4084\n",
      "[1124/1762] D loss: 1.3954\n",
      "[1204/1762] D loss: 1.4023\n",
      "[1284/1762] D loss: 1.3925\n",
      "[1364/1762] D loss: 1.3984\n",
      "[1444/1762] D loss: 1.4006\n",
      "[1524/1762] D loss: 1.4193\n",
      "[1604/1762] D loss: 1.3938\n",
      "[1684/1762] D loss: 1.3875\n",
      "[1762/1762] D loss: 1.4006\n",
      "train error: \n",
      " D loss: 1.394779, D accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393743, D accuracy: 50.1% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3696\n",
      "[84/1762] D loss: 1.4002\n",
      "[164/1762] D loss: 1.4010\n",
      "[244/1762] D loss: 1.4047\n",
      "[324/1762] D loss: 1.4034\n",
      "[404/1762] D loss: 1.3910\n",
      "[484/1762] D loss: 1.3909\n",
      "[564/1762] D loss: 1.3896\n",
      "[644/1762] D loss: 1.3919\n",
      "[724/1762] D loss: 1.3989\n",
      "[804/1762] D loss: 1.3906\n",
      "[884/1762] D loss: 1.3861\n",
      "[964/1762] D loss: 1.3970\n",
      "[1044/1762] D loss: 1.3883\n",
      "[1124/1762] D loss: 1.4137\n",
      "[1204/1762] D loss: 1.3994\n",
      "[1284/1762] D loss: 1.4152\n",
      "[1364/1762] D loss: 1.3882\n",
      "[1444/1762] D loss: 1.3955\n",
      "[1524/1762] D loss: 1.4143\n",
      "[1604/1762] D loss: 1.3993\n",
      "[1684/1762] D loss: 1.3977\n",
      "[1762/1762] D loss: 1.3831\n",
      "train error: \n",
      " D loss: 1.393659, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394763, D accuracy: 50.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3757\n",
      "[84/1762] D loss: 1.3851\n",
      "[164/1762] D loss: 1.4009\n",
      "[244/1762] D loss: 1.4099\n",
      "[324/1762] D loss: 1.4167\n",
      "[404/1762] D loss: 1.4141\n",
      "[484/1762] D loss: 1.3940\n",
      "[564/1762] D loss: 1.3738\n",
      "[644/1762] D loss: 1.3890\n",
      "[724/1762] D loss: 1.4003\n",
      "[804/1762] D loss: 1.4119\n",
      "[884/1762] D loss: 1.3954\n",
      "[964/1762] D loss: 1.3966\n",
      "[1044/1762] D loss: 1.3897\n",
      "[1124/1762] D loss: 1.3982\n",
      "[1204/1762] D loss: 1.3957\n",
      "[1284/1762] D loss: 1.4068\n",
      "[1364/1762] D loss: 1.3862\n",
      "[1444/1762] D loss: 1.4045\n",
      "[1524/1762] D loss: 1.3981\n",
      "[1604/1762] D loss: 1.3961\n",
      "[1684/1762] D loss: 1.4126\n",
      "[1762/1762] D loss: 1.4084\n",
      "train error: \n",
      " D loss: 1.392753, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393307, D accuracy: 50.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3997\n",
      "[84/1762] D loss: 1.3745\n",
      "[164/1762] D loss: 1.3906\n",
      "[244/1762] D loss: 1.3879\n",
      "[324/1762] D loss: 1.3866\n",
      "[404/1762] D loss: 1.3755\n",
      "[484/1762] D loss: 1.3819\n",
      "[564/1762] D loss: 1.4017\n",
      "[644/1762] D loss: 1.4028\n",
      "[724/1762] D loss: 1.3932\n",
      "[804/1762] D loss: 1.3898\n",
      "[884/1762] D loss: 1.3740\n",
      "[964/1762] D loss: 1.3840\n",
      "[1044/1762] D loss: 1.4140\n",
      "[1124/1762] D loss: 1.3945\n",
      "[1204/1762] D loss: 1.3928\n",
      "[1284/1762] D loss: 1.3949\n",
      "[1364/1762] D loss: 1.3812\n",
      "[1444/1762] D loss: 1.3789\n",
      "[1524/1762] D loss: 1.3785\n",
      "[1604/1762] D loss: 1.3882\n",
      "[1684/1762] D loss: 1.3928\n",
      "[1762/1762] D loss: 1.3955\n",
      "train error: \n",
      " D loss: 1.392424, D accuracy: 49.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391270, D accuracy: 49.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3770\n",
      "[84/1762] D loss: 1.3866\n",
      "[164/1762] D loss: 1.3992\n",
      "[244/1762] D loss: 1.3962\n",
      "[324/1762] D loss: 1.3880\n",
      "[404/1762] D loss: 1.3951\n",
      "[484/1762] D loss: 1.3908\n",
      "[564/1762] D loss: 1.4142\n",
      "[644/1762] D loss: 1.4109\n",
      "[724/1762] D loss: 1.3909\n",
      "[804/1762] D loss: 1.4065\n",
      "[884/1762] D loss: 1.3901\n",
      "[964/1762] D loss: 1.3903\n",
      "[1044/1762] D loss: 1.3980\n",
      "[1124/1762] D loss: 1.3892\n",
      "[1204/1762] D loss: 1.3991\n",
      "[1284/1762] D loss: 1.3905\n",
      "[1364/1762] D loss: 1.3935\n",
      "[1444/1762] D loss: 1.4019\n",
      "[1524/1762] D loss: 1.3952\n",
      "[1604/1762] D loss: 1.3927\n",
      "[1684/1762] D loss: 1.3845\n",
      "[1762/1762] D loss: 1.3990\n",
      "train error: \n",
      " D loss: 1.390655, D accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389039, D accuracy: 50.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959\n",
      "[84/1762] D loss: 1.4086\n",
      "[164/1762] D loss: 1.3805\n",
      "[244/1762] D loss: 1.4062\n",
      "[324/1762] D loss: 1.3941\n",
      "[404/1762] D loss: 1.3805\n",
      "[484/1762] D loss: 1.3808\n",
      "[564/1762] D loss: 1.4005\n",
      "[644/1762] D loss: 1.4211\n",
      "[724/1762] D loss: 1.3854\n",
      "[804/1762] D loss: 1.4017\n",
      "[884/1762] D loss: 1.3803\n",
      "[964/1762] D loss: 1.3913\n",
      "[1044/1762] D loss: 1.4042\n",
      "[1124/1762] D loss: 1.4044\n",
      "[1204/1762] D loss: 1.3959\n",
      "[1284/1762] D loss: 1.3890\n",
      "[1364/1762] D loss: 1.3849\n",
      "[1444/1762] D loss: 1.3854\n",
      "[1524/1762] D loss: 1.3926\n",
      "[1604/1762] D loss: 1.3913\n",
      "[1684/1762] D loss: 1.4042\n",
      "[1762/1762] D loss: 1.3873\n",
      "train error: \n",
      " D loss: 1.390540, D accuracy: 49.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391636, D accuracy: 49.7% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953\n",
      "[84/1762] D loss: 1.3679\n",
      "[164/1762] D loss: 1.3797\n",
      "[244/1762] D loss: 1.3894\n",
      "[324/1762] D loss: 1.3769\n",
      "[404/1762] D loss: 1.3928\n",
      "[484/1762] D loss: 1.3895\n",
      "[564/1762] D loss: 1.3931\n",
      "[644/1762] D loss: 1.3892\n",
      "[724/1762] D loss: 1.3857\n",
      "[804/1762] D loss: 1.3921\n",
      "[884/1762] D loss: 1.3962\n",
      "[964/1762] D loss: 1.3956\n",
      "[1044/1762] D loss: 1.3762\n",
      "[1124/1762] D loss: 1.3989\n",
      "[1204/1762] D loss: 1.3818\n",
      "[1284/1762] D loss: 1.3890\n",
      "[1364/1762] D loss: 1.4065\n",
      "[1444/1762] D loss: 1.3671\n",
      "[1524/1762] D loss: 1.3960\n",
      "[1604/1762] D loss: 1.3875\n",
      "[1684/1762] D loss: 1.3917\n",
      "[1762/1762] D loss: 1.4030\n",
      "train error: \n",
      " D loss: 1.389762, D accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390024, D accuracy: 50.2% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4117\n",
      "[84/1762] D loss: 1.3947\n",
      "[164/1762] D loss: 1.3834\n",
      "[244/1762] D loss: 1.3907\n",
      "[324/1762] D loss: 1.3879\n",
      "[404/1762] D loss: 1.3936\n",
      "[484/1762] D loss: 1.3623\n",
      "[564/1762] D loss: 1.3960\n",
      "[644/1762] D loss: 1.3864\n",
      "[724/1762] D loss: 1.3844\n",
      "[804/1762] D loss: 1.3902\n",
      "[884/1762] D loss: 1.3804\n",
      "[964/1762] D loss: 1.3955\n",
      "[1044/1762] D loss: 1.4026\n",
      "[1124/1762] D loss: 1.3797\n",
      "[1204/1762] D loss: 1.3854\n",
      "[1284/1762] D loss: 1.3935\n",
      "[1364/1762] D loss: 1.3785\n",
      "[1444/1762] D loss: 1.3988\n",
      "[1524/1762] D loss: 1.3838\n",
      "[1604/1762] D loss: 1.3778\n",
      "[1684/1762] D loss: 1.3902\n",
      "[1762/1762] D loss: 1.3873\n",
      "train error: \n",
      " D loss: 1.389565, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388204, D accuracy: 50.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3851\n",
      "[84/1762] D loss: 1.4144\n",
      "[164/1762] D loss: 1.3809\n",
      "[244/1762] D loss: 1.3890\n",
      "[324/1762] D loss: 1.3974\n",
      "[404/1762] D loss: 1.3895\n",
      "[484/1762] D loss: 1.3801\n",
      "[564/1762] D loss: 1.3817\n",
      "[644/1762] D loss: 1.3786\n",
      "[724/1762] D loss: 1.3888\n",
      "[804/1762] D loss: 1.3975\n",
      "[884/1762] D loss: 1.3952\n",
      "[964/1762] D loss: 1.3932\n",
      "[1044/1762] D loss: 1.3851\n",
      "[1124/1762] D loss: 1.3831\n",
      "[1204/1762] D loss: 1.3842\n",
      "[1284/1762] D loss: 1.3689\n",
      "[1364/1762] D loss: 1.3843\n",
      "[1444/1762] D loss: 1.3869\n",
      "[1524/1762] D loss: 1.3853\n",
      "[1604/1762] D loss: 1.3856\n",
      "[1684/1762] D loss: 1.3916\n",
      "[1762/1762] D loss: 1.3713\n",
      "train error: \n",
      " D loss: 1.389165, D accuracy: 49.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388763, D accuracy: 50.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951\n",
      "[84/1762] D loss: 1.4078\n",
      "[164/1762] D loss: 1.3863\n",
      "[244/1762] D loss: 1.3948\n",
      "[324/1762] D loss: 1.3991\n",
      "[404/1762] D loss: 1.3763\n",
      "[484/1762] D loss: 1.4008\n",
      "[564/1762] D loss: 1.3810\n",
      "[644/1762] D loss: 1.4023\n",
      "[724/1762] D loss: 1.3799\n",
      "[804/1762] D loss: 1.3892\n",
      "[884/1762] D loss: 1.4003\n",
      "[964/1762] D loss: 1.3991\n",
      "[1044/1762] D loss: 1.3783\n",
      "[1124/1762] D loss: 1.3892\n",
      "[1204/1762] D loss: 1.3928\n",
      "[1284/1762] D loss: 1.3776\n",
      "[1364/1762] D loss: 1.3842\n",
      "[1444/1762] D loss: 1.4003\n",
      "[1524/1762] D loss: 1.3836\n",
      "[1604/1762] D loss: 1.4065\n",
      "[1684/1762] D loss: 1.4144\n",
      "[1762/1762] D loss: 1.3870\n",
      "train error: \n",
      " D loss: 1.388862, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388074, D accuracy: 50.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3926\n",
      "[84/1762] D loss: 1.3906\n",
      "[164/1762] D loss: 1.4025\n",
      "[244/1762] D loss: 1.3894\n",
      "[324/1762] D loss: 1.3987\n",
      "[404/1762] D loss: 1.3836\n",
      "[484/1762] D loss: 1.3823\n",
      "[564/1762] D loss: 1.3974\n",
      "[644/1762] D loss: 1.3925\n",
      "[724/1762] D loss: 1.3748\n",
      "[804/1762] D loss: 1.3918\n",
      "[884/1762] D loss: 1.3906\n",
      "[964/1762] D loss: 1.3858\n",
      "[1044/1762] D loss: 1.3880\n",
      "[1124/1762] D loss: 1.3879\n",
      "[1204/1762] D loss: 1.3979\n",
      "[1284/1762] D loss: 1.3801\n",
      "[1364/1762] D loss: 1.3954\n",
      "[1444/1762] D loss: 1.3744\n",
      "[1524/1762] D loss: 1.3758\n",
      "[1604/1762] D loss: 1.3827\n",
      "[1684/1762] D loss: 1.3787\n",
      "[1762/1762] D loss: 1.3706\n",
      "train error: \n",
      " D loss: 1.388477, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388842, D accuracy: 50.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3846\n",
      "[84/1762] D loss: 1.4007\n",
      "[164/1762] D loss: 1.3949\n",
      "[244/1762] D loss: 1.3973\n",
      "[324/1762] D loss: 1.3883\n",
      "[404/1762] D loss: 1.3939\n",
      "[484/1762] D loss: 1.4018\n",
      "[564/1762] D loss: 1.3960\n",
      "[644/1762] D loss: 1.3801\n",
      "[724/1762] D loss: 1.3934\n",
      "[804/1762] D loss: 1.3906\n",
      "[884/1762] D loss: 1.3822\n",
      "[964/1762] D loss: 1.3960\n",
      "[1044/1762] D loss: 1.3818\n",
      "[1124/1762] D loss: 1.3763\n",
      "[1204/1762] D loss: 1.3859\n",
      "[1284/1762] D loss: 1.3918\n",
      "[1364/1762] D loss: 1.3880\n",
      "[1444/1762] D loss: 1.3956\n",
      "[1524/1762] D loss: 1.3786\n",
      "[1604/1762] D loss: 1.3953\n",
      "[1684/1762] D loss: 1.3878\n",
      "[1762/1762] D loss: 1.3754\n",
      "train error: \n",
      " D loss: 1.387877, D accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386744, D accuracy: 50.2% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4034\n",
      "[84/1762] D loss: 1.3916\n",
      "[164/1762] D loss: 1.3689\n",
      "[244/1762] D loss: 1.3984\n",
      "[324/1762] D loss: 1.3900\n",
      "[404/1762] D loss: 1.4125\n",
      "[484/1762] D loss: 1.3778\n",
      "[564/1762] D loss: 1.3842\n",
      "[644/1762] D loss: 1.4037\n",
      "[724/1762] D loss: 1.3796\n",
      "[804/1762] D loss: 1.4010\n",
      "[884/1762] D loss: 1.3808\n",
      "[964/1762] D loss: 1.3869\n",
      "[1044/1762] D loss: 1.3907\n",
      "[1124/1762] D loss: 1.3803\n",
      "[1204/1762] D loss: 1.3786\n",
      "[1284/1762] D loss: 1.3949\n",
      "[1364/1762] D loss: 1.3795\n",
      "[1444/1762] D loss: 1.3949\n",
      "[1524/1762] D loss: 1.3788\n",
      "[1604/1762] D loss: 1.4033\n",
      "[1684/1762] D loss: 1.3801\n",
      "[1762/1762] D loss: 1.3884\n",
      "train error: \n",
      " D loss: 1.387889, D accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387631, D accuracy: 49.8% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3759\n",
      "[84/1762] D loss: 1.3883\n",
      "[164/1762] D loss: 1.3798\n",
      "[244/1762] D loss: 1.3897\n",
      "[324/1762] D loss: 1.3746\n",
      "[404/1762] D loss: 1.3838\n",
      "[484/1762] D loss: 1.3919\n",
      "[564/1762] D loss: 1.3850\n",
      "[644/1762] D loss: 1.4005\n",
      "[724/1762] D loss: 1.3913\n",
      "[804/1762] D loss: 1.3757\n",
      "[884/1762] D loss: 1.3900\n",
      "[964/1762] D loss: 1.3848\n",
      "[1044/1762] D loss: 1.4103\n",
      "[1124/1762] D loss: 1.3869\n",
      "[1204/1762] D loss: 1.3973\n",
      "[1284/1762] D loss: 1.3898\n",
      "[1364/1762] D loss: 1.3854\n",
      "[1444/1762] D loss: 1.3988\n",
      "[1524/1762] D loss: 1.3748\n",
      "[1604/1762] D loss: 1.3713\n",
      "[1684/1762] D loss: 1.4028\n",
      "[1762/1762] D loss: 1.3931\n",
      "train error: \n",
      " D loss: 1.387993, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387128, D accuracy: 50.2% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3711\n",
      "[84/1762] D loss: 1.4043\n",
      "[164/1762] D loss: 1.3776\n",
      "[244/1762] D loss: 1.3947\n",
      "[324/1762] D loss: 1.3692\n",
      "[404/1762] D loss: 1.3629\n",
      "[484/1762] D loss: 1.3825\n",
      "[564/1762] D loss: 1.3908\n",
      "[644/1762] D loss: 1.3969\n",
      "[724/1762] D loss: 1.3993\n",
      "[804/1762] D loss: 1.3875\n",
      "[884/1762] D loss: 1.3807\n",
      "[964/1762] D loss: 1.3952\n",
      "[1044/1762] D loss: 1.3895\n",
      "[1124/1762] D loss: 1.3975\n",
      "[1204/1762] D loss: 1.3843\n",
      "[1284/1762] D loss: 1.3894\n",
      "[1364/1762] D loss: 1.3862\n",
      "[1444/1762] D loss: 1.3810\n",
      "[1524/1762] D loss: 1.3980\n",
      "[1604/1762] D loss: 1.3776\n",
      "[1684/1762] D loss: 1.3821\n",
      "[1762/1762] D loss: 1.3875\n",
      "train error: \n",
      " D loss: 1.386849, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386960, D accuracy: 50.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3743\n",
      "[84/1762] D loss: 1.3874\n",
      "[164/1762] D loss: 1.3803\n",
      "[244/1762] D loss: 1.3837\n",
      "[324/1762] D loss: 1.3769\n",
      "[404/1762] D loss: 1.3652\n",
      "[484/1762] D loss: 1.3851\n",
      "[564/1762] D loss: 1.3761\n",
      "[644/1762] D loss: 1.3864\n",
      "[724/1762] D loss: 1.3770\n",
      "[804/1762] D loss: 1.3858\n",
      "[884/1762] D loss: 1.3716\n",
      "[964/1762] D loss: 1.3987\n",
      "[1044/1762] D loss: 1.3988\n",
      "[1124/1762] D loss: 1.3787\n",
      "[1204/1762] D loss: 1.3733\n",
      "[1284/1762] D loss: 1.3881\n",
      "[1364/1762] D loss: 1.3973\n",
      "[1444/1762] D loss: 1.3832\n",
      "[1524/1762] D loss: 1.4017\n",
      "[1604/1762] D loss: 1.3833\n",
      "[1684/1762] D loss: 1.3677\n",
      "[1762/1762] D loss: 1.3771\n",
      "train error: \n",
      " D loss: 1.387766, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386785, D accuracy: 49.7% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887\n",
      "[84/1762] D loss: 1.3734\n",
      "[164/1762] D loss: 1.3757\n",
      "[244/1762] D loss: 1.3818\n",
      "[324/1762] D loss: 1.3870\n",
      "[404/1762] D loss: 1.3970\n",
      "[484/1762] D loss: 1.3763\n",
      "[564/1762] D loss: 1.3929\n",
      "[644/1762] D loss: 1.3906\n",
      "[724/1762] D loss: 1.3904\n",
      "[804/1762] D loss: 1.3937\n",
      "[884/1762] D loss: 1.3962\n",
      "[964/1762] D loss: 1.3918\n",
      "[1044/1762] D loss: 1.4041\n",
      "[1124/1762] D loss: 1.3800\n",
      "[1204/1762] D loss: 1.3930\n",
      "[1284/1762] D loss: 1.3882\n",
      "[1364/1762] D loss: 1.3899\n",
      "[1444/1762] D loss: 1.3909\n",
      "[1524/1762] D loss: 1.3796\n",
      "[1604/1762] D loss: 1.3937\n",
      "[1684/1762] D loss: 1.3791\n",
      "[1762/1762] D loss: 1.3910\n",
      "train error: \n",
      " D loss: 1.387388, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385981, D accuracy: 52.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3763\n",
      "[84/1762] D loss: 1.3795\n",
      "[164/1762] D loss: 1.3924\n",
      "[244/1762] D loss: 1.3949\n",
      "[324/1762] D loss: 1.3894\n",
      "[404/1762] D loss: 1.3828\n",
      "[484/1762] D loss: 1.3839\n",
      "[564/1762] D loss: 1.3859\n",
      "[644/1762] D loss: 1.3930\n",
      "[724/1762] D loss: 1.3759\n",
      "[804/1762] D loss: 1.3643\n",
      "[884/1762] D loss: 1.3834\n",
      "[964/1762] D loss: 1.3638\n",
      "[1044/1762] D loss: 1.3895\n",
      "[1124/1762] D loss: 1.3837\n",
      "[1204/1762] D loss: 1.3816\n",
      "[1284/1762] D loss: 1.3759\n",
      "[1364/1762] D loss: 1.3815\n",
      "[1444/1762] D loss: 1.3896\n",
      "[1524/1762] D loss: 1.3979\n",
      "[1604/1762] D loss: 1.4028\n",
      "[1684/1762] D loss: 1.3801\n",
      "[1762/1762] D loss: 1.3999\n",
      "train error: \n",
      " D loss: 1.386545, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386798, D accuracy: 50.6% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3838\n",
      "[84/1762] D loss: 1.3833\n",
      "[164/1762] D loss: 1.3893\n",
      "[244/1762] D loss: 1.3827\n",
      "[324/1762] D loss: 1.3941\n",
      "[404/1762] D loss: 1.3982\n",
      "[484/1762] D loss: 1.3866\n",
      "[564/1762] D loss: 1.3773\n",
      "[644/1762] D loss: 1.3926\n",
      "[724/1762] D loss: 1.3824\n",
      "[804/1762] D loss: 1.3725\n",
      "[884/1762] D loss: 1.3937\n",
      "[964/1762] D loss: 1.3854\n",
      "[1044/1762] D loss: 1.3716\n",
      "[1124/1762] D loss: 1.3953\n",
      "[1204/1762] D loss: 1.3908\n",
      "[1284/1762] D loss: 1.3815\n",
      "[1364/1762] D loss: 1.3928\n",
      "[1444/1762] D loss: 1.3762\n",
      "[1524/1762] D loss: 1.3814\n",
      "[1604/1762] D loss: 1.3818\n",
      "[1684/1762] D loss: 1.3955\n",
      "[1762/1762] D loss: 1.3752\n",
      "train error: \n",
      " D loss: 1.386538, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385793, D accuracy: 51.1% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980\n",
      "[84/1762] D loss: 1.3921\n",
      "[164/1762] D loss: 1.3863\n",
      "[244/1762] D loss: 1.3825\n",
      "[324/1762] D loss: 1.3811\n",
      "[404/1762] D loss: 1.3924\n",
      "[484/1762] D loss: 1.3873\n",
      "[564/1762] D loss: 1.3794\n",
      "[644/1762] D loss: 1.3805\n",
      "[724/1762] D loss: 1.3844\n",
      "[804/1762] D loss: 1.3691\n",
      "[884/1762] D loss: 1.3921\n",
      "[964/1762] D loss: 1.3945\n",
      "[1044/1762] D loss: 1.4011\n",
      "[1124/1762] D loss: 1.3694\n",
      "[1204/1762] D loss: 1.3812\n",
      "[1284/1762] D loss: 1.3703\n",
      "[1364/1762] D loss: 1.3944\n",
      "[1444/1762] D loss: 1.3693\n",
      "[1524/1762] D loss: 1.3869\n",
      "[1604/1762] D loss: 1.3843\n",
      "[1684/1762] D loss: 1.3557\n",
      "[1762/1762] D loss: 1.3891\n",
      "train error: \n",
      " D loss: 1.386159, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386656, D accuracy: 50.5% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3757\n",
      "[84/1762] D loss: 1.3764\n",
      "[164/1762] D loss: 1.3813\n",
      "[244/1762] D loss: 1.3807\n",
      "[324/1762] D loss: 1.3846\n",
      "[404/1762] D loss: 1.3653\n",
      "[484/1762] D loss: 1.3861\n",
      "[564/1762] D loss: 1.3769\n",
      "[644/1762] D loss: 1.3867\n",
      "[724/1762] D loss: 1.3791\n",
      "[804/1762] D loss: 1.3723\n",
      "[884/1762] D loss: 1.3943\n",
      "[964/1762] D loss: 1.3769\n",
      "[1044/1762] D loss: 1.3920\n",
      "[1124/1762] D loss: 1.3763\n",
      "[1204/1762] D loss: 1.3788\n",
      "[1284/1762] D loss: 1.3928\n",
      "[1364/1762] D loss: 1.3731\n",
      "[1444/1762] D loss: 1.3867\n",
      "[1524/1762] D loss: 1.3796\n",
      "[1604/1762] D loss: 1.3938\n",
      "[1684/1762] D loss: 1.3753\n",
      "[1762/1762] D loss: 1.3841\n",
      "train error: \n",
      " D loss: 1.385688, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385644, D accuracy: 49.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3912\n",
      "[84/1762] D loss: 1.4108\n",
      "[164/1762] D loss: 1.3679\n",
      "[244/1762] D loss: 1.3646\n",
      "[324/1762] D loss: 1.3977\n",
      "[404/1762] D loss: 1.3897\n",
      "[484/1762] D loss: 1.3792\n",
      "[564/1762] D loss: 1.3784\n",
      "[644/1762] D loss: 1.3798\n",
      "[724/1762] D loss: 1.3910\n",
      "[804/1762] D loss: 1.3940\n",
      "[884/1762] D loss: 1.3857\n",
      "[964/1762] D loss: 1.3837\n",
      "[1044/1762] D loss: 1.3972\n",
      "[1124/1762] D loss: 1.3648\n",
      "[1204/1762] D loss: 1.3847\n",
      "[1284/1762] D loss: 1.3852\n",
      "[1364/1762] D loss: 1.3811\n",
      "[1444/1762] D loss: 1.3818\n",
      "[1524/1762] D loss: 1.3677\n",
      "[1604/1762] D loss: 1.3641\n",
      "[1684/1762] D loss: 1.3920\n",
      "[1762/1762] D loss: 1.4193\n",
      "train error: \n",
      " D loss: 1.387064, D accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385308, D accuracy: 51.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905\n",
      "[84/1762] D loss: 1.3738\n",
      "[164/1762] D loss: 1.4019\n",
      "[244/1762] D loss: 1.3871\n",
      "[324/1762] D loss: 1.3787\n",
      "[404/1762] D loss: 1.3841\n",
      "[484/1762] D loss: 1.3861\n",
      "[564/1762] D loss: 1.3764\n",
      "[644/1762] D loss: 1.3966\n",
      "[724/1762] D loss: 1.4040\n",
      "[804/1762] D loss: 1.3783\n",
      "[884/1762] D loss: 1.3894\n",
      "[964/1762] D loss: 1.3883\n",
      "[1044/1762] D loss: 1.3985\n",
      "[1124/1762] D loss: 1.3857\n",
      "[1204/1762] D loss: 1.3825\n",
      "[1284/1762] D loss: 1.3849\n",
      "[1364/1762] D loss: 1.3799\n",
      "[1444/1762] D loss: 1.3871\n",
      "[1524/1762] D loss: 1.3716\n",
      "[1604/1762] D loss: 1.3913\n",
      "[1684/1762] D loss: 1.3861\n",
      "[1762/1762] D loss: 1.3845\n",
      "train error: \n",
      " D loss: 1.386545, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385991, D accuracy: 51.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3826\n",
      "[84/1762] D loss: 1.3960\n",
      "[164/1762] D loss: 1.4001\n",
      "[244/1762] D loss: 1.4027\n",
      "[324/1762] D loss: 1.3795\n",
      "[404/1762] D loss: 1.3815\n",
      "[484/1762] D loss: 1.3774\n",
      "[564/1762] D loss: 1.3858\n",
      "[644/1762] D loss: 1.3762\n",
      "[724/1762] D loss: 1.3938\n",
      "[804/1762] D loss: 1.4025\n",
      "[884/1762] D loss: 1.3761\n",
      "[964/1762] D loss: 1.3776\n",
      "[1044/1762] D loss: 1.3704\n",
      "[1124/1762] D loss: 1.3849\n",
      "[1204/1762] D loss: 1.3939\n",
      "[1284/1762] D loss: 1.3907\n",
      "[1364/1762] D loss: 1.3872\n",
      "[1444/1762] D loss: 1.3801\n",
      "[1524/1762] D loss: 1.3973\n",
      "[1604/1762] D loss: 1.3849\n",
      "[1684/1762] D loss: 1.3744\n",
      "[1762/1762] D loss: 1.3682\n",
      "train error: \n",
      " D loss: 1.386487, D accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385825, D accuracy: 51.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3775\n",
      "[84/1762] D loss: 1.3784\n",
      "[164/1762] D loss: 1.3886\n",
      "[244/1762] D loss: 1.3841\n",
      "[324/1762] D loss: 1.3827\n",
      "[404/1762] D loss: 1.3917\n",
      "[484/1762] D loss: 1.3936\n",
      "[564/1762] D loss: 1.3871\n",
      "[644/1762] D loss: 1.3831\n",
      "[724/1762] D loss: 1.3926\n",
      "[804/1762] D loss: 1.3885\n",
      "[884/1762] D loss: 1.3908\n",
      "[964/1762] D loss: 1.3705\n",
      "[1044/1762] D loss: 1.3881\n",
      "[1124/1762] D loss: 1.3945\n",
      "[1204/1762] D loss: 1.4055\n",
      "[1284/1762] D loss: 1.3796\n",
      "[1364/1762] D loss: 1.3970\n",
      "[1444/1762] D loss: 1.3934\n",
      "[1524/1762] D loss: 1.3893\n",
      "[1604/1762] D loss: 1.3788\n",
      "[1684/1762] D loss: 1.3771\n",
      "[1762/1762] D loss: 1.3838\n",
      "train error: \n",
      " D loss: 1.385145, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385500, D accuracy: 50.5% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893\n",
      "[84/1762] D loss: 1.3897\n",
      "[164/1762] D loss: 1.3850\n",
      "[244/1762] D loss: 1.3810\n",
      "[324/1762] D loss: 1.3573\n",
      "[404/1762] D loss: 1.3780\n",
      "[484/1762] D loss: 1.3855\n",
      "[564/1762] D loss: 1.3776\n",
      "[644/1762] D loss: 1.3771\n",
      "[724/1762] D loss: 1.3835\n",
      "[804/1762] D loss: 1.3747\n",
      "[884/1762] D loss: 1.3784\n",
      "[964/1762] D loss: 1.3935\n",
      "[1044/1762] D loss: 1.3776\n",
      "[1124/1762] D loss: 1.3901\n",
      "[1204/1762] D loss: 1.3878\n",
      "[1284/1762] D loss: 1.3799\n",
      "[1364/1762] D loss: 1.3920\n",
      "[1444/1762] D loss: 1.3694\n",
      "[1524/1762] D loss: 1.3722\n",
      "[1604/1762] D loss: 1.3800\n",
      "[1684/1762] D loss: 1.3793\n",
      "[1762/1762] D loss: 1.3758\n",
      "train error: \n",
      " D loss: 1.385417, D accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384409, D accuracy: 52.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3982\n",
      "[84/1762] D loss: 1.3616\n",
      "[164/1762] D loss: 1.3838\n",
      "[244/1762] D loss: 1.3819\n",
      "[324/1762] D loss: 1.3720\n",
      "[404/1762] D loss: 1.3855\n",
      "[484/1762] D loss: 1.3766\n",
      "[564/1762] D loss: 1.3975\n",
      "[644/1762] D loss: 1.3881\n",
      "[724/1762] D loss: 1.3947\n",
      "[804/1762] D loss: 1.3869\n",
      "[884/1762] D loss: 1.3884\n",
      "[964/1762] D loss: 1.3733\n",
      "[1044/1762] D loss: 1.3716\n",
      "[1124/1762] D loss: 1.3830\n",
      "[1204/1762] D loss: 1.3815\n",
      "[1284/1762] D loss: 1.3734\n",
      "[1364/1762] D loss: 1.3736\n",
      "[1444/1762] D loss: 1.3767\n",
      "[1524/1762] D loss: 1.3921\n",
      "[1604/1762] D loss: 1.3882\n",
      "[1684/1762] D loss: 1.4062\n",
      "[1762/1762] D loss: 1.4215\n",
      "train error: \n",
      " D loss: 1.385834, D accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385664, D accuracy: 50.8% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3713\n",
      "[84/1762] D loss: 1.3893\n",
      "[164/1762] D loss: 1.3872\n",
      "[244/1762] D loss: 1.3902\n",
      "[324/1762] D loss: 1.3868\n",
      "[404/1762] D loss: 1.3744\n",
      "[484/1762] D loss: 1.3619\n",
      "[564/1762] D loss: 1.3970\n",
      "[644/1762] D loss: 1.3878\n",
      "[724/1762] D loss: 1.3797\n",
      "[804/1762] D loss: 1.3704\n",
      "[884/1762] D loss: 1.3930\n",
      "[964/1762] D loss: 1.3686\n",
      "[1044/1762] D loss: 1.3913\n",
      "[1124/1762] D loss: 1.3807\n",
      "[1204/1762] D loss: 1.3876\n",
      "[1284/1762] D loss: 1.3900\n",
      "[1364/1762] D loss: 1.4008\n",
      "[1444/1762] D loss: 1.3801\n",
      "[1524/1762] D loss: 1.3824\n",
      "[1604/1762] D loss: 1.3885\n",
      "[1684/1762] D loss: 1.3748\n",
      "[1762/1762] D loss: 1.3837\n",
      "train error: \n",
      " D loss: 1.384981, D accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385117, D accuracy: 50.9% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910\n",
      "[84/1762] D loss: 1.3873\n",
      "[164/1762] D loss: 1.3661\n",
      "[244/1762] D loss: 1.3852\n",
      "[324/1762] D loss: 1.3733\n",
      "[404/1762] D loss: 1.3813\n",
      "[484/1762] D loss: 1.3954\n",
      "[564/1762] D loss: 1.3868\n",
      "[644/1762] D loss: 1.3849\n",
      "[724/1762] D loss: 1.3981\n",
      "[804/1762] D loss: 1.3593\n",
      "[884/1762] D loss: 1.3787\n",
      "[964/1762] D loss: 1.3829\n",
      "[1044/1762] D loss: 1.3763\n",
      "[1124/1762] D loss: 1.3881\n",
      "[1204/1762] D loss: 1.3862\n",
      "[1284/1762] D loss: 1.3654\n",
      "[1364/1762] D loss: 1.3788\n",
      "[1444/1762] D loss: 1.3998\n",
      "[1524/1762] D loss: 1.3827\n",
      "[1604/1762] D loss: 1.3797\n",
      "[1684/1762] D loss: 1.3838\n",
      "[1762/1762] D loss: 1.3945\n",
      "train error: \n",
      " D loss: 1.384419, D accuracy: 51.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384759, D accuracy: 52.2% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959\n",
      "[84/1762] D loss: 1.3940\n",
      "[164/1762] D loss: 1.3944\n",
      "[244/1762] D loss: 1.3975\n",
      "[324/1762] D loss: 1.3888\n",
      "[404/1762] D loss: 1.3863\n",
      "[484/1762] D loss: 1.3859\n",
      "[564/1762] D loss: 1.3794\n",
      "[644/1762] D loss: 1.3859\n",
      "[724/1762] D loss: 1.3711\n",
      "[804/1762] D loss: 1.3860\n",
      "[884/1762] D loss: 1.3899\n",
      "[964/1762] D loss: 1.3831\n",
      "[1044/1762] D loss: 1.3879\n",
      "[1124/1762] D loss: 1.3894\n",
      "[1204/1762] D loss: 1.3780\n",
      "[1284/1762] D loss: 1.3916\n",
      "[1364/1762] D loss: 1.4019\n",
      "[1444/1762] D loss: 1.3773\n",
      "[1524/1762] D loss: 1.3758\n",
      "[1604/1762] D loss: 1.4046\n",
      "[1684/1762] D loss: 1.3855\n",
      "[1762/1762] D loss: 1.3829\n",
      "train error: \n",
      " D loss: 1.385826, D accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385102, D accuracy: 51.2% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3720\n",
      "[84/1762] D loss: 1.3766\n",
      "[164/1762] D loss: 1.3800\n",
      "[244/1762] D loss: 1.3889\n",
      "[324/1762] D loss: 1.3990\n",
      "[404/1762] D loss: 1.3854\n",
      "[484/1762] D loss: 1.4007\n",
      "[564/1762] D loss: 1.3777\n",
      "[644/1762] D loss: 1.3742\n",
      "[724/1762] D loss: 1.3834\n",
      "[804/1762] D loss: 1.3668\n",
      "[884/1762] D loss: 1.3988\n",
      "[964/1762] D loss: 1.3908\n",
      "[1044/1762] D loss: 1.3872\n",
      "[1124/1762] D loss: 1.3851\n",
      "[1204/1762] D loss: 1.3782\n",
      "[1284/1762] D loss: 1.3921\n",
      "[1364/1762] D loss: 1.4027\n",
      "[1444/1762] D loss: 1.3887\n",
      "[1524/1762] D loss: 1.3818\n",
      "[1604/1762] D loss: 1.3827\n",
      "[1684/1762] D loss: 1.3543\n",
      "[1762/1762] D loss: 1.3821\n",
      "train error: \n",
      " D loss: 1.384862, D accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384579, D accuracy: 51.4% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3832\n",
      "[84/1762] D loss: 1.3935\n",
      "[164/1762] D loss: 1.3720\n",
      "[244/1762] D loss: 1.3934\n",
      "[324/1762] D loss: 1.3768\n",
      "[404/1762] D loss: 1.3805\n",
      "[484/1762] D loss: 1.3854\n",
      "[564/1762] D loss: 1.3739\n",
      "[644/1762] D loss: 1.3968\n",
      "[724/1762] D loss: 1.3858\n",
      "[804/1762] D loss: 1.3855\n",
      "[884/1762] D loss: 1.4007\n",
      "[964/1762] D loss: 1.3735\n",
      "[1044/1762] D loss: 1.3682\n",
      "[1124/1762] D loss: 1.3938\n",
      "[1204/1762] D loss: 1.3833\n",
      "[1284/1762] D loss: 1.3871\n",
      "[1364/1762] D loss: 1.3921\n",
      "[1444/1762] D loss: 1.4137\n",
      "[1524/1762] D loss: 1.3992\n",
      "[1604/1762] D loss: 1.3958\n",
      "[1684/1762] D loss: 1.3734\n",
      "[1762/1762] D loss: 1.3560\n",
      "train error: \n",
      " D loss: 1.384582, D accuracy: 51.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383711, D accuracy: 52.2% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3734\n",
      "[84/1762] D loss: 1.3885\n",
      "[164/1762] D loss: 1.4058\n",
      "[244/1762] D loss: 1.4031\n",
      "[324/1762] D loss: 1.3758\n",
      "[404/1762] D loss: 1.4038\n",
      "[484/1762] D loss: 1.3886\n",
      "[564/1762] D loss: 1.3763\n",
      "[644/1762] D loss: 1.3806\n",
      "[724/1762] D loss: 1.3975\n",
      "[804/1762] D loss: 1.3987\n",
      "[884/1762] D loss: 1.3652\n",
      "[964/1762] D loss: 1.3960\n",
      "[1044/1762] D loss: 1.3930\n",
      "[1124/1762] D loss: 1.3737\n",
      "[1204/1762] D loss: 1.3979\n",
      "[1284/1762] D loss: 1.3939\n",
      "[1364/1762] D loss: 1.3749\n",
      "[1444/1762] D loss: 1.3824\n",
      "[1524/1762] D loss: 1.3880\n",
      "[1604/1762] D loss: 1.3863\n",
      "[1684/1762] D loss: 1.3876\n",
      "[1762/1762] D loss: 1.3586\n",
      "train error: \n",
      " D loss: 1.385303, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384571, D accuracy: 50.9% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3713\n",
      "[84/1762] D loss: 1.3951\n",
      "[164/1762] D loss: 1.3858\n",
      "[244/1762] D loss: 1.3778\n",
      "[324/1762] D loss: 1.3940\n",
      "[404/1762] D loss: 1.3838\n",
      "[484/1762] D loss: 1.3875\n",
      "[564/1762] D loss: 1.3888\n",
      "[644/1762] D loss: 1.3648\n",
      "[724/1762] D loss: 1.3880\n",
      "[804/1762] D loss: 1.3832\n",
      "[884/1762] D loss: 1.4003\n",
      "[964/1762] D loss: 1.3880\n",
      "[1044/1762] D loss: 1.3831\n",
      "[1124/1762] D loss: 1.3968\n",
      "[1204/1762] D loss: 1.3992\n",
      "[1284/1762] D loss: 1.3830\n",
      "[1364/1762] D loss: 1.3702\n",
      "[1444/1762] D loss: 1.3743\n",
      "[1524/1762] D loss: 1.3875\n",
      "[1604/1762] D loss: 1.3879\n",
      "[1684/1762] D loss: 1.3518\n",
      "[1762/1762] D loss: 1.3741\n",
      "train error: \n",
      " D loss: 1.383568, D accuracy: 51.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384647, D accuracy: 51.5% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3854\n",
      "[84/1762] D loss: 1.3903\n",
      "[164/1762] D loss: 1.3834\n",
      "[244/1762] D loss: 1.3789\n",
      "[324/1762] D loss: 1.3688\n",
      "[404/1762] D loss: 1.3632\n",
      "[484/1762] D loss: 1.3813\n",
      "[564/1762] D loss: 1.3908\n",
      "[644/1762] D loss: 1.3807\n",
      "[724/1762] D loss: 1.3975\n",
      "[804/1762] D loss: 1.3884\n",
      "[884/1762] D loss: 1.3839\n",
      "[964/1762] D loss: 1.3865\n",
      "[1044/1762] D loss: 1.3903\n",
      "[1124/1762] D loss: 1.3788\n",
      "[1204/1762] D loss: 1.3839\n",
      "[1284/1762] D loss: 1.3933\n",
      "[1364/1762] D loss: 1.3820\n",
      "[1444/1762] D loss: 1.3666\n",
      "[1524/1762] D loss: 1.3789\n",
      "[1604/1762] D loss: 1.3837\n",
      "[1684/1762] D loss: 1.3700\n",
      "[1762/1762] D loss: 1.4004\n",
      "train error: \n",
      " D loss: 1.384938, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383497, D accuracy: 50.7% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3978\n",
      "[84/1762] D loss: 1.3730\n",
      "[164/1762] D loss: 1.3939\n",
      "[244/1762] D loss: 1.3890\n",
      "[324/1762] D loss: 1.3967\n",
      "[404/1762] D loss: 1.3838\n",
      "[484/1762] D loss: 1.3683\n",
      "[564/1762] D loss: 1.3907\n",
      "[644/1762] D loss: 1.3735\n",
      "[724/1762] D loss: 1.3748\n",
      "[804/1762] D loss: 1.3865\n",
      "[884/1762] D loss: 1.3733\n",
      "[964/1762] D loss: 1.3883\n",
      "[1044/1762] D loss: 1.3748\n",
      "[1124/1762] D loss: 1.3774\n",
      "[1204/1762] D loss: 1.3748\n",
      "[1284/1762] D loss: 1.3844\n",
      "[1364/1762] D loss: 1.3892\n",
      "[1444/1762] D loss: 1.3879\n",
      "[1524/1762] D loss: 1.3754\n",
      "[1604/1762] D loss: 1.3784\n",
      "[1684/1762] D loss: 1.3861\n",
      "[1762/1762] D loss: 1.3935\n",
      "train error: \n",
      " D loss: 1.384100, D accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384385, D accuracy: 51.8% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3770\n",
      "[84/1762] D loss: 1.3914\n",
      "[164/1762] D loss: 1.3800\n",
      "[244/1762] D loss: 1.3941\n",
      "[324/1762] D loss: 1.3780\n",
      "[404/1762] D loss: 1.3782\n",
      "[484/1762] D loss: 1.3800\n",
      "[564/1762] D loss: 1.3925\n",
      "[644/1762] D loss: 1.3841\n",
      "[724/1762] D loss: 1.3779\n",
      "[804/1762] D loss: 1.3800\n",
      "[884/1762] D loss: 1.4108\n",
      "[964/1762] D loss: 1.3717\n",
      "[1044/1762] D loss: 1.3802\n",
      "[1124/1762] D loss: 1.3891\n",
      "[1204/1762] D loss: 1.3838\n",
      "[1284/1762] D loss: 1.3834\n",
      "[1364/1762] D loss: 1.3946\n",
      "[1444/1762] D loss: 1.3835\n",
      "[1524/1762] D loss: 1.3667\n",
      "[1604/1762] D loss: 1.3803\n",
      "[1684/1762] D loss: 1.3885\n",
      "[1762/1762] D loss: 1.4003\n",
      "train error: \n",
      " D loss: 1.384708, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383752, D accuracy: 50.8% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877\n",
      "[84/1762] D loss: 1.3781\n",
      "[164/1762] D loss: 1.4136\n",
      "[244/1762] D loss: 1.3883\n",
      "[324/1762] D loss: 1.3761\n",
      "[404/1762] D loss: 1.3848\n",
      "[484/1762] D loss: 1.3813\n",
      "[564/1762] D loss: 1.3702\n",
      "[644/1762] D loss: 1.3872\n",
      "[724/1762] D loss: 1.3629\n",
      "[804/1762] D loss: 1.3907\n",
      "[884/1762] D loss: 1.4082\n",
      "[964/1762] D loss: 1.3816\n",
      "[1044/1762] D loss: 1.3907\n",
      "[1124/1762] D loss: 1.3847\n",
      "[1204/1762] D loss: 1.3804\n",
      "[1284/1762] D loss: 1.3980\n",
      "[1364/1762] D loss: 1.3894\n",
      "[1444/1762] D loss: 1.3817\n",
      "[1524/1762] D loss: 1.3752\n",
      "[1604/1762] D loss: 1.3780\n",
      "[1684/1762] D loss: 1.3889\n",
      "[1762/1762] D loss: 1.3638\n",
      "train error: \n",
      " D loss: 1.383834, D accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384569, D accuracy: 50.7% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3847\n",
      "[84/1762] D loss: 1.3764\n",
      "[164/1762] D loss: 1.3921\n",
      "[244/1762] D loss: 1.3721\n",
      "[324/1762] D loss: 1.3882\n",
      "[404/1762] D loss: 1.3931\n",
      "[484/1762] D loss: 1.3801\n",
      "[564/1762] D loss: 1.3705\n",
      "[644/1762] D loss: 1.3932\n",
      "[724/1762] D loss: 1.3904\n",
      "[804/1762] D loss: 1.3848\n",
      "[884/1762] D loss: 1.3785\n",
      "[964/1762] D loss: 1.3879\n",
      "[1044/1762] D loss: 1.3889\n",
      "[1124/1762] D loss: 1.3704\n",
      "[1204/1762] D loss: 1.3855\n",
      "[1284/1762] D loss: 1.3850\n",
      "[1364/1762] D loss: 1.3911\n",
      "[1444/1762] D loss: 1.3699\n",
      "[1524/1762] D loss: 1.3847\n",
      "[1604/1762] D loss: 1.3886\n",
      "[1684/1762] D loss: 1.3874\n",
      "[1762/1762] D loss: 1.3722\n",
      "train error: \n",
      " D loss: 1.383071, D accuracy: 51.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384833, D accuracy: 51.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4010\n",
      "[84/1762] D loss: 1.3807\n",
      "[164/1762] D loss: 1.3894\n",
      "[244/1762] D loss: 1.3681\n",
      "[324/1762] D loss: 1.3927\n",
      "[404/1762] D loss: 1.3647\n",
      "[484/1762] D loss: 1.4023\n",
      "[564/1762] D loss: 1.3753\n",
      "[644/1762] D loss: 1.3848\n",
      "[724/1762] D loss: 1.3721\n",
      "[804/1762] D loss: 1.3797\n",
      "[884/1762] D loss: 1.3725\n",
      "[964/1762] D loss: 1.3915\n",
      "[1044/1762] D loss: 1.3847\n",
      "[1124/1762] D loss: 1.4086\n",
      "[1204/1762] D loss: 1.3818\n",
      "[1284/1762] D loss: 1.3765\n",
      "[1364/1762] D loss: 1.3701\n",
      "[1444/1762] D loss: 1.3795\n",
      "[1524/1762] D loss: 1.3778\n",
      "[1604/1762] D loss: 1.4005\n",
      "[1684/1762] D loss: 1.3786\n",
      "[1762/1762] D loss: 1.3918\n",
      "train error: \n",
      " D loss: 1.384511, D accuracy: 51.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381463, D accuracy: 51.9% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3932\n",
      "[84/1762] D loss: 1.3842\n",
      "[164/1762] D loss: 1.3854\n",
      "[244/1762] D loss: 1.3767\n",
      "[324/1762] D loss: 1.3755\n",
      "[404/1762] D loss: 1.3909\n",
      "[484/1762] D loss: 1.3697\n",
      "[564/1762] D loss: 1.3903\n",
      "[644/1762] D loss: 1.3777\n",
      "[724/1762] D loss: 1.3851\n",
      "[804/1762] D loss: 1.3679\n",
      "[884/1762] D loss: 1.3824\n",
      "[964/1762] D loss: 1.3733\n",
      "[1044/1762] D loss: 1.3876\n",
      "[1124/1762] D loss: 1.3895\n",
      "[1204/1762] D loss: 1.3886\n",
      "[1284/1762] D loss: 1.3733\n",
      "[1364/1762] D loss: 1.3942\n",
      "[1444/1762] D loss: 1.3797\n",
      "[1524/1762] D loss: 1.3909\n",
      "[1604/1762] D loss: 1.3901\n",
      "[1684/1762] D loss: 1.3960\n",
      "[1762/1762] D loss: 1.4011\n",
      "train error: \n",
      " D loss: 1.383728, D accuracy: 51.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383634, D accuracy: 51.6% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#for learning_rate in [1e-3, 3e-3, 1e-4, 3e-4, 1e-5]:\n",
    "for learning_rate in [3e-4, 1e-4, 3e-5, 1e-5]:\n",
    "    run_name = f\"perturb_{4}_lr_\" + f\"{learning_rate:.0e}\".replace(\"-\", \"m\")\n",
    "    train(run_name=run_name, perturb_num=4, epochs=50, learning_rate=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the learning rate from 1e-3 to 3e-4 or lower makes the training longer and stops the loss from eventually increasing. With 3e-4, the final accuracy seems slightly better than with 1e-3, but still not 100%.\n",
    "\n",
    "Now let's try the same set of learning rates while only perturbing 2 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3966\n",
      "[84/1762] D loss: 1.3859\n",
      "[164/1762] D loss: 1.3986\n",
      "[244/1762] D loss: 1.3897\n",
      "[324/1762] D loss: 1.3915\n",
      "[404/1762] D loss: 1.3832\n",
      "[484/1762] D loss: 1.3926\n",
      "[564/1762] D loss: 1.3858\n",
      "[644/1762] D loss: 1.3880\n",
      "[724/1762] D loss: 1.3840\n",
      "[804/1762] D loss: 1.3786\n",
      "[884/1762] D loss: 1.3793\n",
      "[964/1762] D loss: 1.3858\n",
      "[1044/1762] D loss: 1.3908\n",
      "[1124/1762] D loss: 1.3995\n",
      "[1204/1762] D loss: 1.3784\n",
      "[1284/1762] D loss: 1.3680\n",
      "[1364/1762] D loss: 1.3816\n",
      "[1444/1762] D loss: 1.3830\n",
      "[1524/1762] D loss: 1.3968\n",
      "[1604/1762] D loss: 1.3759\n",
      "[1684/1762] D loss: 1.3921\n",
      "[1762/1762] D loss: 1.3668\n",
      "train error: \n",
      " D loss: 1.384105, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384721, D accuracy: 50.3% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3749\n",
      "[84/1762] D loss: 1.3875\n",
      "[164/1762] D loss: 1.3831\n",
      "[244/1762] D loss: 1.3731\n",
      "[324/1762] D loss: 1.3900\n",
      "[404/1762] D loss: 1.3882\n",
      "[484/1762] D loss: 1.3881\n",
      "[564/1762] D loss: 1.3793\n",
      "[644/1762] D loss: 1.3870\n",
      "[724/1762] D loss: 1.3849\n",
      "[804/1762] D loss: 1.3794\n",
      "[884/1762] D loss: 1.3763\n",
      "[964/1762] D loss: 1.3872\n",
      "[1044/1762] D loss: 1.3758\n",
      "[1124/1762] D loss: 1.3808\n",
      "[1204/1762] D loss: 1.3832\n",
      "[1284/1762] D loss: 1.3846\n",
      "[1364/1762] D loss: 1.3739\n",
      "[1444/1762] D loss: 1.3820\n",
      "[1524/1762] D loss: 1.3965\n",
      "[1604/1762] D loss: 1.3880\n",
      "[1684/1762] D loss: 1.3841\n",
      "[1762/1762] D loss: 1.3621\n",
      "train error: \n",
      " D loss: 1.382253, D accuracy: 53.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380819, D accuracy: 53.8% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3949\n",
      "[84/1762] D loss: 1.3898\n",
      "[164/1762] D loss: 1.3903\n",
      "[244/1762] D loss: 1.3930\n",
      "[324/1762] D loss: 1.3778\n",
      "[404/1762] D loss: 1.3832\n",
      "[484/1762] D loss: 1.3939\n",
      "[564/1762] D loss: 1.3739\n",
      "[644/1762] D loss: 1.3897\n",
      "[724/1762] D loss: 1.3841\n",
      "[804/1762] D loss: 1.3925\n",
      "[884/1762] D loss: 1.3692\n",
      "[964/1762] D loss: 1.3739\n",
      "[1044/1762] D loss: 1.3911\n",
      "[1124/1762] D loss: 1.3809\n",
      "[1204/1762] D loss: 1.3761\n",
      "[1284/1762] D loss: 1.3800\n",
      "[1364/1762] D loss: 1.3716\n",
      "[1444/1762] D loss: 1.3822\n",
      "[1524/1762] D loss: 1.3880\n",
      "[1604/1762] D loss: 1.3718\n",
      "[1684/1762] D loss: 1.3793\n",
      "[1762/1762] D loss: 1.3896\n",
      "train error: \n",
      " D loss: 1.379441, D accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380681, D accuracy: 55.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3819\n",
      "[84/1762] D loss: 1.3693\n",
      "[164/1762] D loss: 1.3841\n",
      "[244/1762] D loss: 1.3893\n",
      "[324/1762] D loss: 1.3803\n",
      "[404/1762] D loss: 1.3736\n",
      "[484/1762] D loss: 1.3806\n",
      "[564/1762] D loss: 1.3641\n",
      "[644/1762] D loss: 1.3825\n",
      "[724/1762] D loss: 1.3730\n",
      "[804/1762] D loss: 1.3763\n",
      "[884/1762] D loss: 1.3838\n",
      "[964/1762] D loss: 1.3844\n",
      "[1044/1762] D loss: 1.3751\n",
      "[1124/1762] D loss: 1.3831\n",
      "[1204/1762] D loss: 1.3955\n",
      "[1284/1762] D loss: 1.3738\n",
      "[1364/1762] D loss: 1.3768\n",
      "[1444/1762] D loss: 1.3785\n",
      "[1524/1762] D loss: 1.3899\n",
      "[1604/1762] D loss: 1.3808\n",
      "[1684/1762] D loss: 1.3737\n",
      "[1762/1762] D loss: 1.3875\n",
      "train error: \n",
      " D loss: 1.376892, D accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377836, D accuracy: 55.8% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3744\n",
      "[84/1762] D loss: 1.3801\n",
      "[164/1762] D loss: 1.3802\n",
      "[244/1762] D loss: 1.3711\n",
      "[324/1762] D loss: 1.3748\n",
      "[404/1762] D loss: 1.3718\n",
      "[484/1762] D loss: 1.3785\n",
      "[564/1762] D loss: 1.3719\n",
      "[644/1762] D loss: 1.3641\n",
      "[724/1762] D loss: 1.3611\n",
      "[804/1762] D loss: 1.3761\n",
      "[884/1762] D loss: 1.3823\n",
      "[964/1762] D loss: 1.3680\n",
      "[1044/1762] D loss: 1.3724\n",
      "[1124/1762] D loss: 1.3711\n",
      "[1204/1762] D loss: 1.3835\n",
      "[1284/1762] D loss: 1.3754\n",
      "[1364/1762] D loss: 1.3821\n",
      "[1444/1762] D loss: 1.3744\n",
      "[1524/1762] D loss: 1.3770\n",
      "[1604/1762] D loss: 1.3934\n",
      "[1684/1762] D loss: 1.3604\n",
      "[1762/1762] D loss: 1.3978\n",
      "train error: \n",
      " D loss: 1.373751, D accuracy: 57.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372417, D accuracy: 58.9% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3808\n",
      "[84/1762] D loss: 1.3733\n",
      "[164/1762] D loss: 1.3869\n",
      "[244/1762] D loss: 1.3821\n",
      "[324/1762] D loss: 1.3605\n",
      "[404/1762] D loss: 1.3850\n",
      "[484/1762] D loss: 1.3794\n",
      "[564/1762] D loss: 1.3851\n",
      "[644/1762] D loss: 1.3724\n",
      "[724/1762] D loss: 1.3625\n",
      "[804/1762] D loss: 1.3966\n",
      "[884/1762] D loss: 1.3457\n",
      "[964/1762] D loss: 1.3393\n",
      "[1044/1762] D loss: 1.3636\n",
      "[1124/1762] D loss: 1.3518\n",
      "[1204/1762] D loss: 1.3709\n",
      "[1284/1762] D loss: 1.3756\n",
      "[1364/1762] D loss: 1.3775\n",
      "[1444/1762] D loss: 1.3574\n",
      "[1524/1762] D loss: 1.3765\n",
      "[1604/1762] D loss: 1.3829\n",
      "[1684/1762] D loss: 1.3759\n",
      "[1762/1762] D loss: 1.3740\n",
      "train error: \n",
      " D loss: 1.369841, D accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369310, D accuracy: 58.2% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3725\n",
      "[84/1762] D loss: 1.3680\n",
      "[164/1762] D loss: 1.3717\n",
      "[244/1762] D loss: 1.3607\n",
      "[324/1762] D loss: 1.3731\n",
      "[404/1762] D loss: 1.3733\n",
      "[484/1762] D loss: 1.3829\n",
      "[564/1762] D loss: 1.3816\n",
      "[644/1762] D loss: 1.3742\n",
      "[724/1762] D loss: 1.3737\n",
      "[804/1762] D loss: 1.3811\n",
      "[884/1762] D loss: 1.3742\n",
      "[964/1762] D loss: 1.3878\n",
      "[1044/1762] D loss: 1.3817\n",
      "[1124/1762] D loss: 1.3927\n",
      "[1204/1762] D loss: 1.3757\n",
      "[1284/1762] D loss: 1.3780\n",
      "[1364/1762] D loss: 1.3699\n",
      "[1444/1762] D loss: 1.3683\n",
      "[1524/1762] D loss: 1.3758\n",
      "[1604/1762] D loss: 1.3556\n",
      "[1684/1762] D loss: 1.3520\n",
      "[1762/1762] D loss: 1.3301\n",
      "train error: \n",
      " D loss: 1.359321, D accuracy: 61.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358873, D accuracy: 59.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3646\n",
      "[84/1762] D loss: 1.3622\n",
      "[164/1762] D loss: 1.3652\n",
      "[244/1762] D loss: 1.3704\n",
      "[324/1762] D loss: 1.3585\n",
      "[404/1762] D loss: 1.3789\n",
      "[484/1762] D loss: 1.3707\n",
      "[564/1762] D loss: 1.3629\n",
      "[644/1762] D loss: 1.3686\n",
      "[724/1762] D loss: 1.3613\n",
      "[804/1762] D loss: 1.3688\n",
      "[884/1762] D loss: 1.3442\n",
      "[964/1762] D loss: 1.3926\n",
      "[1044/1762] D loss: 1.3461\n",
      "[1124/1762] D loss: 1.3558\n",
      "[1204/1762] D loss: 1.3825\n",
      "[1284/1762] D loss: 1.3133\n",
      "[1364/1762] D loss: 1.3700\n",
      "[1444/1762] D loss: 1.3633\n",
      "[1524/1762] D loss: 1.3645\n",
      "[1604/1762] D loss: 1.3550\n",
      "[1684/1762] D loss: 1.3683\n",
      "[1762/1762] D loss: 1.3560\n",
      "train error: \n",
      " D loss: 1.351489, D accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351458, D accuracy: 60.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3506\n",
      "[84/1762] D loss: 1.3497\n",
      "[164/1762] D loss: 1.3639\n",
      "[244/1762] D loss: 1.3500\n",
      "[324/1762] D loss: 1.3597\n",
      "[404/1762] D loss: 1.3178\n",
      "[484/1762] D loss: 1.3336\n",
      "[564/1762] D loss: 1.3522\n",
      "[644/1762] D loss: 1.3454\n",
      "[724/1762] D loss: 1.3624\n",
      "[804/1762] D loss: 1.3514\n",
      "[884/1762] D loss: 1.3716\n",
      "[964/1762] D loss: 1.3614\n",
      "[1044/1762] D loss: 1.3419\n",
      "[1124/1762] D loss: 1.3621\n",
      "[1204/1762] D loss: 1.3415\n",
      "[1284/1762] D loss: 1.3451\n",
      "[1364/1762] D loss: 1.3725\n",
      "[1444/1762] D loss: 1.3389\n",
      "[1524/1762] D loss: 1.3493\n",
      "[1604/1762] D loss: 1.3313\n",
      "[1684/1762] D loss: 1.3521\n",
      "[1762/1762] D loss: 1.3454\n",
      "train error: \n",
      " D loss: 1.330055, D accuracy: 67.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332268, D accuracy: 63.4% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3462\n",
      "[84/1762] D loss: 1.3591\n",
      "[164/1762] D loss: 1.3214\n",
      "[244/1762] D loss: 1.3642\n",
      "[324/1762] D loss: 1.3263\n",
      "[404/1762] D loss: 1.2870\n",
      "[484/1762] D loss: 1.3506\n",
      "[564/1762] D loss: 1.2919\n",
      "[644/1762] D loss: 1.3252\n",
      "[724/1762] D loss: 1.3133\n",
      "[804/1762] D loss: 1.3268\n",
      "[884/1762] D loss: 1.3213\n",
      "[964/1762] D loss: 1.2939\n",
      "[1044/1762] D loss: 1.3088\n",
      "[1124/1762] D loss: 1.3374\n",
      "[1204/1762] D loss: 1.3113\n",
      "[1284/1762] D loss: 1.3487\n",
      "[1364/1762] D loss: 1.3426\n",
      "[1444/1762] D loss: 1.2954\n",
      "[1524/1762] D loss: 1.3419\n",
      "[1604/1762] D loss: 1.3369\n",
      "[1684/1762] D loss: 1.3605\n",
      "[1762/1762] D loss: 1.2995\n",
      "train error: \n",
      " D loss: 1.285752, D accuracy: 73.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296217, D accuracy: 70.1% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2224\n",
      "[84/1762] D loss: 1.3050\n",
      "[164/1762] D loss: 1.2390\n",
      "[244/1762] D loss: 1.3272\n",
      "[324/1762] D loss: 1.2491\n",
      "[404/1762] D loss: 1.2190\n",
      "[484/1762] D loss: 1.2334\n",
      "[564/1762] D loss: 1.2195\n",
      "[644/1762] D loss: 1.2624\n",
      "[724/1762] D loss: 1.3470\n",
      "[804/1762] D loss: 1.2471\n",
      "[884/1762] D loss: 1.2465\n",
      "[964/1762] D loss: 1.2592\n",
      "[1044/1762] D loss: 1.3478\n",
      "[1124/1762] D loss: 1.3376\n",
      "[1204/1762] D loss: 1.2533\n",
      "[1284/1762] D loss: 1.1507\n",
      "[1364/1762] D loss: 1.2190\n",
      "[1444/1762] D loss: 1.2249\n",
      "[1524/1762] D loss: 1.2607\n",
      "[1604/1762] D loss: 1.3075\n",
      "[1684/1762] D loss: 1.1831\n",
      "[1762/1762] D loss: 1.3337\n",
      "train error: \n",
      " D loss: 1.214575, D accuracy: 77.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.225943, D accuracy: 76.7% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2438\n",
      "[84/1762] D loss: 1.2098\n",
      "[164/1762] D loss: 1.2284\n",
      "[244/1762] D loss: 1.1908\n",
      "[324/1762] D loss: 1.2692\n",
      "[404/1762] D loss: 1.2252\n",
      "[484/1762] D loss: 1.3036\n",
      "[564/1762] D loss: 1.2836\n",
      "[644/1762] D loss: 1.1595\n",
      "[724/1762] D loss: 1.3068\n",
      "[804/1762] D loss: 1.3720\n",
      "[884/1762] D loss: 1.2193\n",
      "[964/1762] D loss: 1.1431\n",
      "[1044/1762] D loss: 1.0296\n",
      "[1124/1762] D loss: 1.1246\n",
      "[1204/1762] D loss: 1.2067\n",
      "[1284/1762] D loss: 1.1009\n",
      "[1364/1762] D loss: 1.1267\n",
      "[1444/1762] D loss: 1.2177\n",
      "[1524/1762] D loss: 1.1745\n",
      "[1604/1762] D loss: 1.0209\n",
      "[1684/1762] D loss: 0.9892\n",
      "[1762/1762] D loss: 0.7302\n",
      "train error: \n",
      " D loss: 1.034681, D accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.076282, D accuracy: 80.8% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9639\n",
      "[84/1762] D loss: 1.0092\n",
      "[164/1762] D loss: 1.1516\n",
      "[244/1762] D loss: 0.8963\n",
      "[324/1762] D loss: 1.0078\n",
      "[404/1762] D loss: 0.9538\n",
      "[484/1762] D loss: 1.0835\n",
      "[564/1762] D loss: 1.2487\n",
      "[644/1762] D loss: 1.0839\n",
      "[724/1762] D loss: 1.0123\n",
      "[804/1762] D loss: 1.0240\n",
      "[884/1762] D loss: 1.1909\n",
      "[964/1762] D loss: 0.7280\n",
      "[1044/1762] D loss: 0.8478\n",
      "[1124/1762] D loss: 0.9761\n",
      "[1204/1762] D loss: 0.9677\n",
      "[1284/1762] D loss: 0.7317\n",
      "[1364/1762] D loss: 0.8605\n",
      "[1444/1762] D loss: 0.7500\n",
      "[1524/1762] D loss: 0.7832\n",
      "[1604/1762] D loss: 0.7120\n",
      "[1684/1762] D loss: 0.6176\n",
      "[1762/1762] D loss: 0.5605\n",
      "train error: \n",
      " D loss: 0.793675, D accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.783851, D accuracy: 89.7% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5701\n",
      "[84/1762] D loss: 0.6292\n",
      "[164/1762] D loss: 0.6168\n",
      "[244/1762] D loss: 0.7474\n",
      "[324/1762] D loss: 0.7395\n",
      "[404/1762] D loss: 0.7891\n",
      "[484/1762] D loss: 0.7296\n",
      "[564/1762] D loss: 0.7298\n",
      "[644/1762] D loss: 1.1032\n",
      "[724/1762] D loss: 0.8576\n",
      "[804/1762] D loss: 0.7903\n",
      "[884/1762] D loss: 0.6216\n",
      "[964/1762] D loss: 0.5113\n",
      "[1044/1762] D loss: 0.3909\n",
      "[1124/1762] D loss: 0.5616\n",
      "[1204/1762] D loss: 0.5974\n",
      "[1284/1762] D loss: 0.8574\n",
      "[1364/1762] D loss: 0.2485\n",
      "[1444/1762] D loss: 0.4037\n",
      "[1524/1762] D loss: 0.1956\n",
      "[1604/1762] D loss: 0.4297\n",
      "[1684/1762] D loss: 0.5090\n",
      "[1762/1762] D loss: 0.6997\n",
      "train error: \n",
      " D loss: 0.559407, D accuracy: 94.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.569241, D accuracy: 93.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5342\n",
      "[84/1762] D loss: 0.6177\n",
      "[164/1762] D loss: 0.4425\n",
      "[244/1762] D loss: 0.1820\n",
      "[324/1762] D loss: 0.1322\n",
      "[404/1762] D loss: 0.1906\n",
      "[484/1762] D loss: 0.1179\n",
      "[564/1762] D loss: 0.3029\n",
      "[644/1762] D loss: 0.1529\n",
      "[724/1762] D loss: 0.4240\n",
      "[804/1762] D loss: 0.3098\n",
      "[884/1762] D loss: 0.3884\n",
      "[964/1762] D loss: 0.1162\n",
      "[1044/1762] D loss: 0.4045\n",
      "[1124/1762] D loss: 0.0763\n",
      "[1204/1762] D loss: 0.3032\n",
      "[1284/1762] D loss: 0.1875\n",
      "[1364/1762] D loss: 0.1014\n",
      "[1444/1762] D loss: 0.1163\n",
      "[1524/1762] D loss: 0.1411\n",
      "[1604/1762] D loss: 0.0525\n",
      "[1684/1762] D loss: 0.1801\n",
      "[1762/1762] D loss: 0.0570\n",
      "train error: \n",
      " D loss: 0.552433, D accuracy: 95.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.599194, D accuracy: 92.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1625\n",
      "[84/1762] D loss: 0.1976\n",
      "[164/1762] D loss: 0.0481\n",
      "[244/1762] D loss: 0.5598\n",
      "[324/1762] D loss: 0.2273\n",
      "[404/1762] D loss: 0.2736\n",
      "[484/1762] D loss: 0.0884\n",
      "[564/1762] D loss: 0.1466\n",
      "[644/1762] D loss: 0.1152\n",
      "[724/1762] D loss: 0.1955\n",
      "[804/1762] D loss: 0.4536\n",
      "[884/1762] D loss: 0.1270\n",
      "[964/1762] D loss: 0.0993\n",
      "[1044/1762] D loss: 0.1748\n",
      "[1124/1762] D loss: 0.0575\n",
      "[1204/1762] D loss: 0.0362\n",
      "[1284/1762] D loss: 0.5127\n",
      "[1364/1762] D loss: 0.0422\n",
      "[1444/1762] D loss: 0.3420\n",
      "[1524/1762] D loss: 0.1253\n",
      "[1604/1762] D loss: 0.1125\n",
      "[1684/1762] D loss: 0.1984\n",
      "[1762/1762] D loss: 0.0135\n",
      "train error: \n",
      " D loss: 0.571432, D accuracy: 94.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.607327, D accuracy: 91.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1290\n",
      "[84/1762] D loss: 0.0170\n",
      "[164/1762] D loss: 0.0759\n",
      "[244/1762] D loss: 0.0683\n",
      "[324/1762] D loss: 0.0830\n",
      "[404/1762] D loss: 0.0207\n",
      "[484/1762] D loss: 0.0197\n",
      "[564/1762] D loss: 0.0807\n",
      "[644/1762] D loss: 0.1726\n",
      "[724/1762] D loss: 0.0786\n",
      "[804/1762] D loss: 0.1127\n",
      "[884/1762] D loss: 0.2532\n",
      "[964/1762] D loss: 0.0735\n",
      "[1044/1762] D loss: 0.0422\n",
      "[1124/1762] D loss: 0.0314\n",
      "[1204/1762] D loss: 0.0327\n",
      "[1284/1762] D loss: 0.0368\n",
      "[1364/1762] D loss: 0.0235\n",
      "[1444/1762] D loss: 0.0342\n",
      "[1524/1762] D loss: 0.0337\n",
      "[1604/1762] D loss: 0.0621\n",
      "[1684/1762] D loss: 0.0176\n",
      "[1762/1762] D loss: 0.0066\n",
      "train error: \n",
      " D loss: 1.115089, D accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.154017, D accuracy: 52.6% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0273\n",
      "[84/1762] D loss: 0.0355\n",
      "[164/1762] D loss: 0.0233\n",
      "[244/1762] D loss: 0.0274\n",
      "[324/1762] D loss: 0.0124\n",
      "[404/1762] D loss: 0.1045\n",
      "[484/1762] D loss: 0.0197\n",
      "[564/1762] D loss: 0.0360\n",
      "[644/1762] D loss: 0.0122\n",
      "[724/1762] D loss: 0.0188\n",
      "[804/1762] D loss: 0.0399\n",
      "[884/1762] D loss: 0.0384\n",
      "[964/1762] D loss: 0.1584\n",
      "[1044/1762] D loss: 0.0513\n",
      "[1124/1762] D loss: 0.0102\n",
      "[1204/1762] D loss: 0.0169\n",
      "[1284/1762] D loss: 0.0094\n",
      "[1364/1762] D loss: 0.0157\n",
      "[1444/1762] D loss: 0.0098\n",
      "[1524/1762] D loss: 0.0100\n",
      "[1604/1762] D loss: 0.0378\n",
      "[1684/1762] D loss: 0.0276\n",
      "[1762/1762] D loss: 0.1553\n",
      "train error: \n",
      " D loss: 1.026364, D accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.057581, D accuracy: 55.9% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0728\n",
      "[84/1762] D loss: 0.0133\n",
      "[164/1762] D loss: 0.0385\n",
      "[244/1762] D loss: 0.0198\n",
      "[324/1762] D loss: 0.0342\n",
      "[404/1762] D loss: 0.0079\n",
      "[484/1762] D loss: 0.0985\n",
      "[564/1762] D loss: 0.0424\n",
      "[644/1762] D loss: 0.0211\n",
      "[724/1762] D loss: 0.0466\n",
      "[804/1762] D loss: 0.1501\n",
      "[884/1762] D loss: 0.2420\n",
      "[964/1762] D loss: 0.0080\n",
      "[1044/1762] D loss: 0.0176\n",
      "[1124/1762] D loss: 0.0150\n",
      "[1204/1762] D loss: 0.0103\n",
      "[1284/1762] D loss: 0.0140\n",
      "[1364/1762] D loss: 0.0088\n",
      "[1444/1762] D loss: 0.0108\n",
      "[1524/1762] D loss: 0.0185\n",
      "[1604/1762] D loss: 0.0071\n",
      "[1684/1762] D loss: 0.0085\n",
      "[1762/1762] D loss: 0.0401\n",
      "train error: \n",
      " D loss: 1.041621, D accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.080480, D accuracy: 55.3% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0095\n",
      "[84/1762] D loss: 0.0189\n",
      "[164/1762] D loss: 0.0502\n",
      "[244/1762] D loss: 0.0081\n",
      "[324/1762] D loss: 0.0094\n",
      "[404/1762] D loss: 0.0129\n",
      "[484/1762] D loss: 0.0186\n",
      "[564/1762] D loss: 0.0348\n",
      "[644/1762] D loss: 0.0090\n",
      "[724/1762] D loss: 0.0149\n",
      "[804/1762] D loss: 0.0137\n",
      "[884/1762] D loss: 0.0150\n",
      "[964/1762] D loss: 0.0042\n",
      "[1044/1762] D loss: 0.2148\n",
      "[1124/1762] D loss: 0.0081\n",
      "[1204/1762] D loss: 0.0471\n",
      "[1284/1762] D loss: 0.0337\n",
      "[1364/1762] D loss: 0.0036\n",
      "[1444/1762] D loss: 0.0679\n",
      "[1524/1762] D loss: 0.0470\n",
      "[1604/1762] D loss: 0.0287\n",
      "[1684/1762] D loss: 0.0109\n",
      "[1762/1762] D loss: 0.0039\n",
      "train error: \n",
      " D loss: 1.351239, D accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386533, D accuracy: 51.6% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0701\n",
      "[84/1762] D loss: 0.0247\n",
      "[164/1762] D loss: 0.0723\n",
      "[244/1762] D loss: 0.0308\n",
      "[324/1762] D loss: 0.0199\n",
      "[404/1762] D loss: 0.0126\n",
      "[484/1762] D loss: 0.0087\n",
      "[564/1762] D loss: 0.0090\n",
      "[644/1762] D loss: 0.0061\n",
      "[724/1762] D loss: 0.0624\n",
      "[804/1762] D loss: 0.0039\n",
      "[884/1762] D loss: 0.0452\n",
      "[964/1762] D loss: 0.0047\n",
      "[1044/1762] D loss: 0.0150\n",
      "[1124/1762] D loss: 0.0047\n",
      "[1204/1762] D loss: 0.0299\n",
      "[1284/1762] D loss: 0.0033\n",
      "[1364/1762] D loss: 0.0076\n",
      "[1444/1762] D loss: 0.0047\n",
      "[1524/1762] D loss: 0.0081\n",
      "[1604/1762] D loss: 0.0218\n",
      "[1684/1762] D loss: 0.0552\n",
      "[1762/1762] D loss: 0.0191\n",
      "train error: \n",
      " D loss: 1.746601, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.795148, D accuracy: 50.1% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0178\n",
      "[84/1762] D loss: 0.0080\n",
      "[164/1762] D loss: 0.0072\n",
      "[244/1762] D loss: 0.0317\n",
      "[324/1762] D loss: 0.0031\n",
      "[404/1762] D loss: 0.0106\n",
      "[484/1762] D loss: 0.0062\n",
      "[564/1762] D loss: 0.0082\n",
      "[644/1762] D loss: 0.0137\n",
      "[724/1762] D loss: 0.0024\n",
      "[804/1762] D loss: 0.0018\n",
      "[884/1762] D loss: 0.0052\n",
      "[964/1762] D loss: 0.0027\n",
      "[1044/1762] D loss: 0.0332\n",
      "[1124/1762] D loss: 0.0051\n",
      "[1204/1762] D loss: 0.0035\n",
      "[1284/1762] D loss: 0.0022\n",
      "[1364/1762] D loss: 0.0229\n",
      "[1444/1762] D loss: 0.0039\n",
      "[1524/1762] D loss: 0.0024\n",
      "[1604/1762] D loss: 0.0046\n",
      "[1684/1762] D loss: 0.0088\n",
      "[1762/1762] D loss: 0.0093\n",
      "train error: \n",
      " D loss: 1.683556, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.730510, D accuracy: 50.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0071\n",
      "[84/1762] D loss: 0.0042\n",
      "[164/1762] D loss: 0.0052\n",
      "[244/1762] D loss: 0.0030\n",
      "[324/1762] D loss: 0.0027\n",
      "[404/1762] D loss: 0.0020\n",
      "[484/1762] D loss: 0.0026\n",
      "[564/1762] D loss: 0.0115\n",
      "[644/1762] D loss: 0.0087\n",
      "[724/1762] D loss: 0.0025\n",
      "[804/1762] D loss: 0.0091\n",
      "[884/1762] D loss: 0.0057\n",
      "[964/1762] D loss: 0.0053\n",
      "[1044/1762] D loss: 0.0043\n",
      "[1124/1762] D loss: 0.0262\n",
      "[1204/1762] D loss: 0.0031\n",
      "[1284/1762] D loss: 0.0044\n",
      "[1364/1762] D loss: 0.0056\n",
      "[1444/1762] D loss: 0.0104\n",
      "[1524/1762] D loss: 0.0027\n",
      "[1604/1762] D loss: 0.0034\n",
      "[1684/1762] D loss: 0.0080\n",
      "[1762/1762] D loss: 0.0354\n",
      "train error: \n",
      " D loss: 1.804277, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.851517, D accuracy: 50.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0045\n",
      "[84/1762] D loss: 0.0063\n",
      "[164/1762] D loss: 0.0031\n",
      "[244/1762] D loss: 0.0025\n",
      "[324/1762] D loss: 0.0030\n",
      "[404/1762] D loss: 0.0067\n",
      "[484/1762] D loss: 0.0029\n",
      "[564/1762] D loss: 0.0079\n",
      "[644/1762] D loss: 0.0160\n",
      "[724/1762] D loss: 0.0199\n",
      "[804/1762] D loss: 0.0066\n",
      "[884/1762] D loss: 0.0068\n",
      "[964/1762] D loss: 0.0207\n",
      "[1044/1762] D loss: 0.0234\n",
      "[1124/1762] D loss: 0.0108\n",
      "[1204/1762] D loss: 0.0129\n",
      "[1284/1762] D loss: 0.0036\n",
      "[1364/1762] D loss: 0.0089\n",
      "[1444/1762] D loss: 0.0101\n",
      "[1524/1762] D loss: 0.0053\n",
      "[1604/1762] D loss: 0.0032\n",
      "[1684/1762] D loss: 0.0123\n",
      "[1762/1762] D loss: 0.0059\n",
      "train error: \n",
      " D loss: 1.868994, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.925975, D accuracy: 50.1% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0068\n",
      "[84/1762] D loss: 0.0133\n",
      "[164/1762] D loss: 0.0028\n",
      "[244/1762] D loss: 0.0087\n",
      "[324/1762] D loss: 0.0213\n",
      "[404/1762] D loss: 0.0077\n",
      "[484/1762] D loss: 0.0185\n",
      "[564/1762] D loss: 0.0022\n",
      "[644/1762] D loss: 0.0028\n",
      "[724/1762] D loss: 0.0033\n",
      "[804/1762] D loss: 0.0035\n",
      "[884/1762] D loss: 0.0016\n",
      "[964/1762] D loss: 0.0013\n",
      "[1044/1762] D loss: 0.0217\n",
      "[1124/1762] D loss: 0.0299\n",
      "[1204/1762] D loss: 0.0057\n",
      "[1284/1762] D loss: 0.0324\n",
      "[1364/1762] D loss: 0.0034\n",
      "[1444/1762] D loss: 0.0015\n",
      "[1524/1762] D loss: 0.0023\n",
      "[1604/1762] D loss: 0.0013\n",
      "[1684/1762] D loss: 0.0053\n",
      "[1762/1762] D loss: 0.0012\n",
      "train error: \n",
      " D loss: 2.244660, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.298515, D accuracy: 50.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0042\n",
      "[84/1762] D loss: 0.0046\n",
      "[164/1762] D loss: 0.0062\n",
      "[244/1762] D loss: 0.0078\n",
      "[324/1762] D loss: 0.0118\n",
      "[404/1762] D loss: 0.0022\n",
      "[484/1762] D loss: 0.0017\n",
      "[564/1762] D loss: 0.0092\n",
      "[644/1762] D loss: 0.0029\n",
      "[724/1762] D loss: 0.0062\n",
      "[804/1762] D loss: 0.0032\n",
      "[884/1762] D loss: 0.0043\n",
      "[964/1762] D loss: 0.0120\n",
      "[1044/1762] D loss: 0.0021\n",
      "[1124/1762] D loss: 0.0122\n",
      "[1204/1762] D loss: 0.0009\n",
      "[1284/1762] D loss: 0.0019\n",
      "[1364/1762] D loss: 0.0022\n",
      "[1444/1762] D loss: 0.0035\n",
      "[1524/1762] D loss: 0.0021\n",
      "[1604/1762] D loss: 0.0022\n",
      "[1684/1762] D loss: 0.0178\n",
      "[1762/1762] D loss: 0.0454\n",
      "train error: \n",
      " D loss: 2.288894, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.343924, D accuracy: 50.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0036\n",
      "[84/1762] D loss: 0.0017\n",
      "[164/1762] D loss: 0.0038\n",
      "[244/1762] D loss: 0.0017\n",
      "[324/1762] D loss: 0.0075\n",
      "[404/1762] D loss: 0.0015\n",
      "[484/1762] D loss: 0.0016\n",
      "[564/1762] D loss: 0.0036\n",
      "[644/1762] D loss: 0.0061\n",
      "[724/1762] D loss: 0.0011\n",
      "[804/1762] D loss: 0.0148\n",
      "[884/1762] D loss: 0.0173\n",
      "[964/1762] D loss: 0.0079\n",
      "[1044/1762] D loss: 0.0012\n",
      "[1124/1762] D loss: 0.0247\n",
      "[1204/1762] D loss: 0.0142\n",
      "[1284/1762] D loss: 0.0023\n",
      "[1364/1762] D loss: 0.0029\n",
      "[1444/1762] D loss: 0.0125\n",
      "[1524/1762] D loss: 0.0008\n",
      "[1604/1762] D loss: 0.0032\n",
      "[1684/1762] D loss: 0.0141\n",
      "[1762/1762] D loss: 0.0016\n",
      "train error: \n",
      " D loss: 2.429716, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.486723, D accuracy: 49.9% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0016\n",
      "[84/1762] D loss: 0.0038\n",
      "[164/1762] D loss: 0.0020\n",
      "[244/1762] D loss: 0.0125\n",
      "[324/1762] D loss: 0.0250\n",
      "[404/1762] D loss: 0.0021\n",
      "[484/1762] D loss: 0.0019\n",
      "[564/1762] D loss: 0.0232\n",
      "[644/1762] D loss: 0.0100\n",
      "[724/1762] D loss: 0.0010\n",
      "[804/1762] D loss: 0.0061\n",
      "[884/1762] D loss: 0.0034\n",
      "[964/1762] D loss: 0.0059\n",
      "[1044/1762] D loss: 0.0072\n",
      "[1124/1762] D loss: 0.0057\n",
      "[1204/1762] D loss: 0.0030\n",
      "[1284/1762] D loss: 0.0020\n",
      "[1364/1762] D loss: 0.0036\n",
      "[1444/1762] D loss: 0.0014\n",
      "[1524/1762] D loss: 0.0055\n",
      "[1604/1762] D loss: 0.0025\n",
      "[1684/1762] D loss: 0.0146\n",
      "[1762/1762] D loss: 0.0024\n",
      "train error: \n",
      " D loss: 1.951357, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.004431, D accuracy: 49.9% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0054\n",
      "[84/1762] D loss: 0.0044\n",
      "[164/1762] D loss: 0.0009\n",
      "[244/1762] D loss: 0.0019\n",
      "[324/1762] D loss: 0.0014\n",
      "[404/1762] D loss: 0.0008\n",
      "[484/1762] D loss: 0.0018\n",
      "[564/1762] D loss: 0.0015\n",
      "[644/1762] D loss: 0.0043\n",
      "[724/1762] D loss: 0.0010\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0124\n",
      "[964/1762] D loss: 0.0022\n",
      "[1044/1762] D loss: 0.0013\n",
      "[1124/1762] D loss: 0.0025\n",
      "[1204/1762] D loss: 0.0131\n",
      "[1284/1762] D loss: 0.0247\n",
      "[1364/1762] D loss: 0.0017\n",
      "[1444/1762] D loss: 0.0079\n",
      "[1524/1762] D loss: 0.0017\n",
      "[1604/1762] D loss: 0.0073\n",
      "[1684/1762] D loss: 0.0008\n",
      "[1762/1762] D loss: 0.0037\n",
      "train error: \n",
      " D loss: 2.416239, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.476056, D accuracy: 49.9% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0024\n",
      "[84/1762] D loss: 0.0023\n",
      "[164/1762] D loss: 0.0017\n",
      "[244/1762] D loss: 0.0028\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0037\n",
      "[484/1762] D loss: 0.0014\n",
      "[564/1762] D loss: 0.0027\n",
      "[644/1762] D loss: 0.0010\n",
      "[724/1762] D loss: 0.0027\n",
      "[804/1762] D loss: 0.0031\n",
      "[884/1762] D loss: 0.0009\n",
      "[964/1762] D loss: 0.0019\n",
      "[1044/1762] D loss: 0.0033\n",
      "[1124/1762] D loss: 0.0030\n",
      "[1204/1762] D loss: 0.0017\n",
      "[1284/1762] D loss: 0.0043\n",
      "[1364/1762] D loss: 0.0034\n",
      "[1444/1762] D loss: 0.0020\n",
      "[1524/1762] D loss: 0.0135\n",
      "[1604/1762] D loss: 0.0010\n",
      "[1684/1762] D loss: 0.0010\n",
      "[1762/1762] D loss: 0.0016\n",
      "train error: \n",
      " D loss: 2.657247, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.701990, D accuracy: 50.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0084\n",
      "[84/1762] D loss: 0.0047\n",
      "[164/1762] D loss: 0.0006\n",
      "[244/1762] D loss: 0.0038\n",
      "[324/1762] D loss: 0.0021\n",
      "[404/1762] D loss: 0.0222\n",
      "[484/1762] D loss: 0.0020\n",
      "[564/1762] D loss: 0.0029\n",
      "[644/1762] D loss: 0.0013\n",
      "[724/1762] D loss: 0.0007\n",
      "[804/1762] D loss: 0.0112\n",
      "[884/1762] D loss: 0.0018\n",
      "[964/1762] D loss: 0.0163\n",
      "[1044/1762] D loss: 0.0045\n",
      "[1124/1762] D loss: 0.0123\n",
      "[1204/1762] D loss: 0.0040\n",
      "[1284/1762] D loss: 0.0041\n",
      "[1364/1762] D loss: 0.0023\n",
      "[1444/1762] D loss: 0.0008\n",
      "[1524/1762] D loss: 0.0020\n",
      "[1604/1762] D loss: 0.0031\n",
      "[1684/1762] D loss: 0.0006\n",
      "[1762/1762] D loss: 0.0005\n",
      "train error: \n",
      " D loss: 2.976481, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.031651, D accuracy: 50.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0022\n",
      "[84/1762] D loss: 0.0068\n",
      "[164/1762] D loss: 0.0008\n",
      "[244/1762] D loss: 0.0021\n",
      "[324/1762] D loss: 0.0033\n",
      "[404/1762] D loss: 0.0010\n",
      "[484/1762] D loss: 0.0072\n",
      "[564/1762] D loss: 0.0015\n",
      "[644/1762] D loss: 0.0188\n",
      "[724/1762] D loss: 0.0038\n",
      "[804/1762] D loss: 0.0018\n",
      "[884/1762] D loss: 0.0019\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0013\n",
      "[1124/1762] D loss: 0.0023\n",
      "[1204/1762] D loss: 0.0019\n",
      "[1284/1762] D loss: 0.0035\n",
      "[1364/1762] D loss: 0.0011\n",
      "[1444/1762] D loss: 0.0014\n",
      "[1524/1762] D loss: 0.0008\n",
      "[1604/1762] D loss: 0.0015\n",
      "[1684/1762] D loss: 0.0157\n",
      "[1762/1762] D loss: 0.0144\n",
      "train error: \n",
      " D loss: 2.980842, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.040344, D accuracy: 50.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0021\n",
      "[84/1762] D loss: 0.0013\n",
      "[164/1762] D loss: 0.0020\n",
      "[244/1762] D loss: 0.0056\n",
      "[324/1762] D loss: 0.0024\n",
      "[404/1762] D loss: 0.0016\n",
      "[484/1762] D loss: 0.0021\n",
      "[564/1762] D loss: 0.0020\n",
      "[644/1762] D loss: 0.0023\n",
      "[724/1762] D loss: 0.0019\n",
      "[804/1762] D loss: 0.0010\n",
      "[884/1762] D loss: 0.0024\n",
      "[964/1762] D loss: 0.0010\n",
      "[1044/1762] D loss: 0.0023\n",
      "[1124/1762] D loss: 0.0044\n",
      "[1204/1762] D loss: 0.0008\n",
      "[1284/1762] D loss: 0.0007\n",
      "[1364/1762] D loss: 0.0062\n",
      "[1444/1762] D loss: 0.0026\n",
      "[1524/1762] D loss: 0.0019\n",
      "[1604/1762] D loss: 0.0009\n",
      "[1684/1762] D loss: 0.0041\n",
      "[1762/1762] D loss: 0.0063\n",
      "train error: \n",
      " D loss: 2.669745, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.728045, D accuracy: 50.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006\n",
      "[84/1762] D loss: 0.0035\n",
      "[164/1762] D loss: 0.0008\n",
      "[244/1762] D loss: 0.0006\n",
      "[324/1762] D loss: 0.0005\n",
      "[404/1762] D loss: 0.0556\n",
      "[484/1762] D loss: 0.0021\n",
      "[564/1762] D loss: 0.0008\n",
      "[644/1762] D loss: 0.0047\n",
      "[724/1762] D loss: 0.0011\n",
      "[804/1762] D loss: 0.0008\n",
      "[884/1762] D loss: 0.0011\n",
      "[964/1762] D loss: 0.0011\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0012\n",
      "[1284/1762] D loss: 0.0007\n",
      "[1364/1762] D loss: 0.0051\n",
      "[1444/1762] D loss: 0.0014\n",
      "[1524/1762] D loss: 0.0015\n",
      "[1604/1762] D loss: 0.0046\n",
      "[1684/1762] D loss: 0.0007\n",
      "[1762/1762] D loss: 0.0119\n",
      "train error: \n",
      " D loss: 2.776432, D accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.832332, D accuracy: 50.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0010\n",
      "[84/1762] D loss: 0.0047\n",
      "[164/1762] D loss: 0.0006\n",
      "[244/1762] D loss: 0.0009\n",
      "[324/1762] D loss: 0.0074\n",
      "[404/1762] D loss: 0.0008\n",
      "[484/1762] D loss: 0.0027\n",
      "[564/1762] D loss: 0.0017\n",
      "[644/1762] D loss: 0.0076\n",
      "[724/1762] D loss: 0.0009\n",
      "[804/1762] D loss: 0.0010\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0059\n",
      "[1044/1762] D loss: 0.0027\n",
      "[1124/1762] D loss: 0.0157\n",
      "[1204/1762] D loss: 0.0008\n",
      "[1284/1762] D loss: 0.0020\n",
      "[1364/1762] D loss: 0.0009\n",
      "[1444/1762] D loss: 0.0066\n",
      "[1524/1762] D loss: 0.0011\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0038\n",
      "[1762/1762] D loss: 0.0119\n",
      "train error: \n",
      " D loss: 2.958497, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.014393, D accuracy: 50.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0018\n",
      "[164/1762] D loss: 0.0021\n",
      "[244/1762] D loss: 0.0011\n",
      "[324/1762] D loss: 0.0019\n",
      "[404/1762] D loss: 0.0034\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0044\n",
      "[644/1762] D loss: 0.0020\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0005\n",
      "[884/1762] D loss: 0.0014\n",
      "[964/1762] D loss: 0.0112\n",
      "[1044/1762] D loss: 0.0021\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0007\n",
      "[1284/1762] D loss: 0.0008\n",
      "[1364/1762] D loss: 0.0100\n",
      "[1444/1762] D loss: 0.0078\n",
      "[1524/1762] D loss: 0.0012\n",
      "[1604/1762] D loss: 0.0024\n",
      "[1684/1762] D loss: 0.0006\n",
      "[1762/1762] D loss: 0.0016\n",
      "train error: \n",
      " D loss: 2.930388, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.986520, D accuracy: 50.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0025\n",
      "[84/1762] D loss: 0.0015\n",
      "[164/1762] D loss: 0.0057\n",
      "[244/1762] D loss: 0.0008\n",
      "[324/1762] D loss: 0.0048\n",
      "[404/1762] D loss: 0.0030\n",
      "[484/1762] D loss: 0.0016\n",
      "[564/1762] D loss: 0.0010\n",
      "[644/1762] D loss: 0.0016\n",
      "[724/1762] D loss: 0.0005\n",
      "[804/1762] D loss: 0.0015\n",
      "[884/1762] D loss: 0.0008\n",
      "[964/1762] D loss: 0.0007\n",
      "[1044/1762] D loss: 0.0010\n",
      "[1124/1762] D loss: 0.0007\n",
      "[1204/1762] D loss: 0.0018\n",
      "[1284/1762] D loss: 0.0038\n",
      "[1364/1762] D loss: 0.0017\n",
      "[1444/1762] D loss: 0.0019\n",
      "[1524/1762] D loss: 0.0004\n",
      "[1604/1762] D loss: 0.0010\n",
      "[1684/1762] D loss: 0.0042\n",
      "[1762/1762] D loss: 0.0017\n",
      "train error: \n",
      " D loss: 3.402521, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.456025, D accuracy: 50.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0010\n",
      "[84/1762] D loss: 0.0011\n",
      "[164/1762] D loss: 0.0004\n",
      "[244/1762] D loss: 0.0005\n",
      "[324/1762] D loss: 0.0006\n",
      "[404/1762] D loss: 0.0027\n",
      "[484/1762] D loss: 0.0034\n",
      "[564/1762] D loss: 0.0010\n",
      "[644/1762] D loss: 0.0024\n",
      "[724/1762] D loss: 0.0032\n",
      "[804/1762] D loss: 0.0009\n",
      "[884/1762] D loss: 0.0017\n",
      "[964/1762] D loss: 0.0008\n",
      "[1044/1762] D loss: 0.0017\n",
      "[1124/1762] D loss: 0.0022\n",
      "[1204/1762] D loss: 0.0028\n",
      "[1284/1762] D loss: 0.0017\n",
      "[1364/1762] D loss: 0.0011\n",
      "[1444/1762] D loss: 0.0041\n",
      "[1524/1762] D loss: 0.0072\n",
      "[1604/1762] D loss: 0.0127\n",
      "[1684/1762] D loss: 0.0007\n",
      "[1762/1762] D loss: 0.0020\n",
      "train error: \n",
      " D loss: 3.285413, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.345787, D accuracy: 50.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0023\n",
      "[84/1762] D loss: 0.0024\n",
      "[164/1762] D loss: 0.0048\n",
      "[244/1762] D loss: 0.0060\n",
      "[324/1762] D loss: 0.0008\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0013\n",
      "[564/1762] D loss: 0.0013\n",
      "[644/1762] D loss: 0.0017\n",
      "[724/1762] D loss: 0.0005\n",
      "[804/1762] D loss: 0.0009\n",
      "[884/1762] D loss: 0.0034\n",
      "[964/1762] D loss: 0.0016\n",
      "[1044/1762] D loss: 0.0038\n",
      "[1124/1762] D loss: 0.0009\n",
      "[1204/1762] D loss: 0.0015\n",
      "[1284/1762] D loss: 0.0042\n",
      "[1364/1762] D loss: 0.0005\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0016\n",
      "[1604/1762] D loss: 0.0007\n",
      "[1684/1762] D loss: 0.0007\n",
      "[1762/1762] D loss: 0.0006\n",
      "train error: \n",
      " D loss: 3.437152, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.491331, D accuracy: 50.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0016\n",
      "[84/1762] D loss: 0.0008\n",
      "[164/1762] D loss: 0.0010\n",
      "[244/1762] D loss: 0.0006\n",
      "[324/1762] D loss: 0.0012\n",
      "[404/1762] D loss: 0.0007\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0028\n",
      "[644/1762] D loss: 0.0010\n",
      "[724/1762] D loss: 0.0004\n",
      "[804/1762] D loss: 0.0015\n",
      "[884/1762] D loss: 0.0046\n",
      "[964/1762] D loss: 0.0012\n",
      "[1044/1762] D loss: 0.0003\n",
      "[1124/1762] D loss: 0.0006\n",
      "[1204/1762] D loss: 0.0025\n",
      "[1284/1762] D loss: 0.0026\n",
      "[1364/1762] D loss: 0.0012\n",
      "[1444/1762] D loss: 0.0006\n",
      "[1524/1762] D loss: 0.0012\n",
      "[1604/1762] D loss: 0.0013\n",
      "[1684/1762] D loss: 0.0007\n",
      "[1762/1762] D loss: 0.0003\n",
      "train error: \n",
      " D loss: 3.870613, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.927303, D accuracy: 50.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0010\n",
      "[84/1762] D loss: 0.0044\n",
      "[164/1762] D loss: 0.0010\n",
      "[244/1762] D loss: 0.0005\n",
      "[324/1762] D loss: 0.0011\n",
      "[404/1762] D loss: 0.0016\n",
      "[484/1762] D loss: 0.0009\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0005\n",
      "[724/1762] D loss: 0.0058\n",
      "[804/1762] D loss: 0.0062\n",
      "[884/1762] D loss: 0.0031\n",
      "[964/1762] D loss: 0.0017\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0013\n",
      "[1204/1762] D loss: 0.0014\n",
      "[1284/1762] D loss: 0.0004\n",
      "[1364/1762] D loss: 0.0154\n",
      "[1444/1762] D loss: 0.0018\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0007\n",
      "[1684/1762] D loss: 0.0009\n",
      "[1762/1762] D loss: 0.0008\n",
      "train error: \n",
      " D loss: 3.268275, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.328153, D accuracy: 49.9% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0020\n",
      "[84/1762] D loss: 0.0011\n",
      "[164/1762] D loss: 0.0007\n",
      "[244/1762] D loss: 0.0019\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0010\n",
      "[484/1762] D loss: 0.0009\n",
      "[564/1762] D loss: 0.0015\n",
      "[644/1762] D loss: 0.0010\n",
      "[724/1762] D loss: 0.0012\n",
      "[804/1762] D loss: 0.0004\n",
      "[884/1762] D loss: 0.0016\n",
      "[964/1762] D loss: 0.0010\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0008\n",
      "[1284/1762] D loss: 0.0020\n",
      "[1364/1762] D loss: 0.0013\n",
      "[1444/1762] D loss: 0.0004\n",
      "[1524/1762] D loss: 0.0055\n",
      "[1604/1762] D loss: 0.0024\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0508\n",
      "train error: \n",
      " D loss: 3.653542, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.716953, D accuracy: 50.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0037\n",
      "[84/1762] D loss: 0.0011\n",
      "[164/1762] D loss: 0.0009\n",
      "[244/1762] D loss: 0.0014\n",
      "[324/1762] D loss: 0.0008\n",
      "[404/1762] D loss: 0.0013\n",
      "[484/1762] D loss: 0.0008\n",
      "[564/1762] D loss: 0.0019\n",
      "[644/1762] D loss: 0.0014\n",
      "[724/1762] D loss: 0.0006\n",
      "[804/1762] D loss: 0.0007\n",
      "[884/1762] D loss: 0.0068\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0017\n",
      "[1124/1762] D loss: 0.0003\n",
      "[1204/1762] D loss: 0.0124\n",
      "[1284/1762] D loss: 0.0036\n",
      "[1364/1762] D loss: 0.0021\n",
      "[1444/1762] D loss: 0.0020\n",
      "[1524/1762] D loss: 0.0013\n",
      "[1604/1762] D loss: 0.0023\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0015\n",
      "train error: \n",
      " D loss: 4.064017, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.122667, D accuracy: 50.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0050\n",
      "[84/1762] D loss: 0.0024\n",
      "[164/1762] D loss: 0.0011\n",
      "[244/1762] D loss: 0.0022\n",
      "[324/1762] D loss: 0.0022\n",
      "[404/1762] D loss: 0.0009\n",
      "[484/1762] D loss: 0.0007\n",
      "[564/1762] D loss: 0.0007\n",
      "[644/1762] D loss: 0.0004\n",
      "[724/1762] D loss: 0.0006\n",
      "[804/1762] D loss: 0.0014\n",
      "[884/1762] D loss: 0.0029\n",
      "[964/1762] D loss: 0.0008\n",
      "[1044/1762] D loss: 0.0005\n",
      "[1124/1762] D loss: 0.0005\n",
      "[1204/1762] D loss: 0.0006\n",
      "[1284/1762] D loss: 0.0013\n",
      "[1364/1762] D loss: 0.0028\n",
      "[1444/1762] D loss: 0.0003\n",
      "[1524/1762] D loss: 0.0013\n",
      "[1604/1762] D loss: 0.0018\n",
      "[1684/1762] D loss: 0.0005\n",
      "[1762/1762] D loss: 0.0009\n",
      "train error: \n",
      " D loss: 3.498514, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.557070, D accuracy: 50.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0026\n",
      "[84/1762] D loss: 0.0035\n",
      "[164/1762] D loss: 0.0052\n",
      "[244/1762] D loss: 0.0003\n",
      "[324/1762] D loss: 0.0024\n",
      "[404/1762] D loss: 0.0003\n",
      "[484/1762] D loss: 0.0004\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0008\n",
      "[724/1762] D loss: 0.0010\n",
      "[804/1762] D loss: 0.0009\n",
      "[884/1762] D loss: 0.0012\n",
      "[964/1762] D loss: 0.0022\n",
      "[1044/1762] D loss: 0.0008\n",
      "[1124/1762] D loss: 0.0028\n",
      "[1204/1762] D loss: 0.0012\n",
      "[1284/1762] D loss: 0.0008\n",
      "[1364/1762] D loss: 0.0010\n",
      "[1444/1762] D loss: 0.0020\n",
      "[1524/1762] D loss: 0.0015\n",
      "[1604/1762] D loss: 0.0005\n",
      "[1684/1762] D loss: 0.0040\n",
      "[1762/1762] D loss: 0.0006\n",
      "train error: \n",
      " D loss: 3.715712, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.775202, D accuracy: 50.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002\n",
      "[84/1762] D loss: 0.0007\n",
      "[164/1762] D loss: 0.0003\n",
      "[244/1762] D loss: 0.0013\n",
      "[324/1762] D loss: 0.0012\n",
      "[404/1762] D loss: 0.0005\n",
      "[484/1762] D loss: 0.0003\n",
      "[564/1762] D loss: 0.0006\n",
      "[644/1762] D loss: 0.0056\n",
      "[724/1762] D loss: 0.0026\n",
      "[804/1762] D loss: 0.0023\n",
      "[884/1762] D loss: 0.0003\n",
      "[964/1762] D loss: 0.0011\n",
      "[1044/1762] D loss: 0.0002\n",
      "[1124/1762] D loss: 0.0011\n",
      "[1204/1762] D loss: 0.0018\n",
      "[1284/1762] D loss: 0.0040\n",
      "[1364/1762] D loss: 0.0010\n",
      "[1444/1762] D loss: 0.0010\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0032\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 3.697780, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.755320, D accuracy: 50.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0014\n",
      "[84/1762] D loss: 0.0012\n",
      "[164/1762] D loss: 0.0007\n",
      "[244/1762] D loss: 0.0016\n",
      "[324/1762] D loss: 0.0013\n",
      "[404/1762] D loss: 0.0004\n",
      "[484/1762] D loss: 0.0010\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0011\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0009\n",
      "[884/1762] D loss: 0.0007\n",
      "[964/1762] D loss: 0.0003\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0004\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0006\n",
      "[1364/1762] D loss: 0.0009\n",
      "[1444/1762] D loss: 0.0009\n",
      "[1524/1762] D loss: 0.0007\n",
      "[1604/1762] D loss: 0.0004\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0007\n",
      "train error: \n",
      " D loss: 4.692064, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.743113, D accuracy: 50.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0003\n",
      "[164/1762] D loss: 0.0010\n",
      "[244/1762] D loss: 0.0014\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0008\n",
      "[484/1762] D loss: 0.0002\n",
      "[564/1762] D loss: 0.0017\n",
      "[644/1762] D loss: 0.0008\n",
      "[724/1762] D loss: 0.0008\n",
      "[804/1762] D loss: 0.0018\n",
      "[884/1762] D loss: 0.0006\n",
      "[964/1762] D loss: 0.0004\n",
      "[1044/1762] D loss: 0.0009\n",
      "[1124/1762] D loss: 0.0012\n",
      "[1204/1762] D loss: 0.0169\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0029\n",
      "[1444/1762] D loss: 0.0009\n",
      "[1524/1762] D loss: 0.0048\n",
      "[1604/1762] D loss: 0.0031\n",
      "[1684/1762] D loss: 0.0003\n",
      "[1762/1762] D loss: 0.0034\n",
      "train error: \n",
      " D loss: 3.741027, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.800340, D accuracy: 50.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0052\n",
      "[84/1762] D loss: 0.0005\n",
      "[164/1762] D loss: 0.0002\n",
      "[244/1762] D loss: 0.0029\n",
      "[324/1762] D loss: 0.0004\n",
      "[404/1762] D loss: 0.0011\n",
      "[484/1762] D loss: 0.0013\n",
      "[564/1762] D loss: 0.0014\n",
      "[644/1762] D loss: 0.0007\n",
      "[724/1762] D loss: 0.0014\n",
      "[804/1762] D loss: 0.0003\n",
      "[884/1762] D loss: 0.0007\n",
      "[964/1762] D loss: 0.0014\n",
      "[1044/1762] D loss: 0.0006\n",
      "[1124/1762] D loss: 0.0001\n",
      "[1204/1762] D loss: 0.0003\n",
      "[1284/1762] D loss: 0.0002\n",
      "[1364/1762] D loss: 0.0011\n",
      "[1444/1762] D loss: 0.0016\n",
      "[1524/1762] D loss: 0.0024\n",
      "[1604/1762] D loss: 0.0020\n",
      "[1684/1762] D loss: 0.0009\n",
      "[1762/1762] D loss: 0.0025\n",
      "train error: \n",
      " D loss: 3.774701, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.833484, D accuracy: 50.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009\n",
      "[84/1762] D loss: 0.0004\n",
      "[164/1762] D loss: 0.0007\n",
      "[244/1762] D loss: 0.0006\n",
      "[324/1762] D loss: 0.0009\n",
      "[404/1762] D loss: 0.0016\n",
      "[484/1762] D loss: 0.0006\n",
      "[564/1762] D loss: 0.0005\n",
      "[644/1762] D loss: 0.0014\n",
      "[724/1762] D loss: 0.0002\n",
      "[804/1762] D loss: 0.0019\n",
      "[884/1762] D loss: 0.0004\n",
      "[964/1762] D loss: 0.0005\n",
      "[1044/1762] D loss: 0.0012\n",
      "[1124/1762] D loss: 0.0007\n",
      "[1204/1762] D loss: 0.0068\n",
      "[1284/1762] D loss: 0.0009\n",
      "[1364/1762] D loss: 0.0002\n",
      "[1444/1762] D loss: 0.0007\n",
      "[1524/1762] D loss: 0.0005\n",
      "[1604/1762] D loss: 0.0040\n",
      "[1684/1762] D loss: 0.0004\n",
      "[1762/1762] D loss: 0.0004\n",
      "train error: \n",
      " D loss: 4.147168, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.206067, D accuracy: 50.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4932\n",
      "[84/1762] D loss: 1.4962\n",
      "[164/1762] D loss: 1.4289\n",
      "[244/1762] D loss: 1.4179\n",
      "[324/1762] D loss: 1.4320\n",
      "[404/1762] D loss: 1.4073\n",
      "[484/1762] D loss: 1.3956\n",
      "[564/1762] D loss: 1.4058\n",
      "[644/1762] D loss: 1.3911\n",
      "[724/1762] D loss: 1.4061\n",
      "[804/1762] D loss: 1.4071\n",
      "[884/1762] D loss: 1.4013\n",
      "[964/1762] D loss: 1.3694\n",
      "[1044/1762] D loss: 1.3810\n",
      "[1124/1762] D loss: 1.4092\n",
      "[1204/1762] D loss: 1.3941\n",
      "[1284/1762] D loss: 1.3677\n",
      "[1364/1762] D loss: 1.3907\n",
      "[1444/1762] D loss: 1.3815\n",
      "[1524/1762] D loss: 1.3715\n",
      "[1604/1762] D loss: 1.4042\n",
      "[1684/1762] D loss: 1.3793\n",
      "[1762/1762] D loss: 1.3794\n",
      "train error: \n",
      " D loss: 1.386582, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387337, D accuracy: 51.5% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3685\n",
      "[84/1762] D loss: 1.3946\n",
      "[164/1762] D loss: 1.3879\n",
      "[244/1762] D loss: 1.3882\n",
      "[324/1762] D loss: 1.3748\n",
      "[404/1762] D loss: 1.3813\n",
      "[484/1762] D loss: 1.3871\n",
      "[564/1762] D loss: 1.3579\n",
      "[644/1762] D loss: 1.3748\n",
      "[724/1762] D loss: 1.3773\n",
      "[804/1762] D loss: 1.3946\n",
      "[884/1762] D loss: 1.3811\n",
      "[964/1762] D loss: 1.3891\n",
      "[1044/1762] D loss: 1.3909\n",
      "[1124/1762] D loss: 1.3871\n",
      "[1204/1762] D loss: 1.3831\n",
      "[1284/1762] D loss: 1.3866\n",
      "[1364/1762] D loss: 1.3705\n",
      "[1444/1762] D loss: 1.3637\n",
      "[1524/1762] D loss: 1.3580\n",
      "[1604/1762] D loss: 1.3821\n",
      "[1684/1762] D loss: 1.3759\n",
      "[1762/1762] D loss: 1.3736\n",
      "train error: \n",
      " D loss: 1.380861, D accuracy: 53.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382491, D accuracy: 52.3% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3835\n",
      "[84/1762] D loss: 1.3718\n",
      "[164/1762] D loss: 1.3512\n",
      "[244/1762] D loss: 1.3937\n",
      "[324/1762] D loss: 1.3642\n",
      "[404/1762] D loss: 1.3852\n",
      "[484/1762] D loss: 1.3961\n",
      "[564/1762] D loss: 1.3687\n",
      "[644/1762] D loss: 1.3828\n",
      "[724/1762] D loss: 1.3723\n",
      "[804/1762] D loss: 1.3786\n",
      "[884/1762] D loss: 1.3676\n",
      "[964/1762] D loss: 1.3704\n",
      "[1044/1762] D loss: 1.3870\n",
      "[1124/1762] D loss: 1.3678\n",
      "[1204/1762] D loss: 1.3827\n",
      "[1284/1762] D loss: 1.3923\n",
      "[1364/1762] D loss: 1.3742\n",
      "[1444/1762] D loss: 1.3886\n",
      "[1524/1762] D loss: 1.3768\n",
      "[1604/1762] D loss: 1.3590\n",
      "[1684/1762] D loss: 1.3767\n",
      "[1762/1762] D loss: 1.3782\n",
      "train error: \n",
      " D loss: 1.374617, D accuracy: 55.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375838, D accuracy: 55.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3724\n",
      "[84/1762] D loss: 1.3947\n",
      "[164/1762] D loss: 1.3967\n",
      "[244/1762] D loss: 1.3465\n",
      "[324/1762] D loss: 1.3772\n",
      "[404/1762] D loss: 1.3739\n",
      "[484/1762] D loss: 1.3887\n",
      "[564/1762] D loss: 1.3643\n",
      "[644/1762] D loss: 1.3829\n",
      "[724/1762] D loss: 1.3508\n",
      "[804/1762] D loss: 1.3761\n",
      "[884/1762] D loss: 1.3672\n",
      "[964/1762] D loss: 1.3571\n",
      "[1044/1762] D loss: 1.3451\n",
      "[1124/1762] D loss: 1.3885\n",
      "[1204/1762] D loss: 1.3814\n",
      "[1284/1762] D loss: 1.3706\n",
      "[1364/1762] D loss: 1.3836\n",
      "[1444/1762] D loss: 1.3724\n",
      "[1524/1762] D loss: 1.3685\n",
      "[1604/1762] D loss: 1.3640\n",
      "[1684/1762] D loss: 1.3631\n",
      "[1762/1762] D loss: 1.3614\n",
      "train error: \n",
      " D loss: 1.366772, D accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368230, D accuracy: 57.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3494\n",
      "[84/1762] D loss: 1.3497\n",
      "[164/1762] D loss: 1.3773\n",
      "[244/1762] D loss: 1.3350\n",
      "[324/1762] D loss: 1.3828\n",
      "[404/1762] D loss: 1.3672\n",
      "[484/1762] D loss: 1.3888\n",
      "[564/1762] D loss: 1.3505\n",
      "[644/1762] D loss: 1.3940\n",
      "[724/1762] D loss: 1.3603\n",
      "[804/1762] D loss: 1.3506\n",
      "[884/1762] D loss: 1.3600\n",
      "[964/1762] D loss: 1.3698\n",
      "[1044/1762] D loss: 1.3918\n",
      "[1124/1762] D loss: 1.3516\n",
      "[1204/1762] D loss: 1.3637\n",
      "[1284/1762] D loss: 1.3492\n",
      "[1364/1762] D loss: 1.3565\n",
      "[1444/1762] D loss: 1.3555\n",
      "[1524/1762] D loss: 1.3549\n",
      "[1604/1762] D loss: 1.3796\n",
      "[1684/1762] D loss: 1.3849\n",
      "[1762/1762] D loss: 1.3425\n",
      "train error: \n",
      " D loss: 1.364088, D accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363758, D accuracy: 58.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3746\n",
      "[84/1762] D loss: 1.3645\n",
      "[164/1762] D loss: 1.3457\n",
      "[244/1762] D loss: 1.3531\n",
      "[324/1762] D loss: 1.4015\n",
      "[404/1762] D loss: 1.3701\n",
      "[484/1762] D loss: 1.3494\n",
      "[564/1762] D loss: 1.3830\n",
      "[644/1762] D loss: 1.3777\n",
      "[724/1762] D loss: 1.3730\n",
      "[804/1762] D loss: 1.3568\n",
      "[884/1762] D loss: 1.3717\n",
      "[964/1762] D loss: 1.3574\n",
      "[1044/1762] D loss: 1.3903\n",
      "[1124/1762] D loss: 1.3444\n",
      "[1204/1762] D loss: 1.3437\n",
      "[1284/1762] D loss: 1.3532\n",
      "[1364/1762] D loss: 1.3420\n",
      "[1444/1762] D loss: 1.3660\n",
      "[1524/1762] D loss: 1.3678\n",
      "[1604/1762] D loss: 1.3392\n",
      "[1684/1762] D loss: 1.3746\n",
      "[1762/1762] D loss: 1.3858\n",
      "train error: \n",
      " D loss: 1.358182, D accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359834, D accuracy: 58.4% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3208\n",
      "[84/1762] D loss: 1.3375\n",
      "[164/1762] D loss: 1.3316\n",
      "[244/1762] D loss: 1.3349\n",
      "[324/1762] D loss: 1.3933\n",
      "[404/1762] D loss: 1.3505\n",
      "[484/1762] D loss: 1.3722\n",
      "[564/1762] D loss: 1.3445\n",
      "[644/1762] D loss: 1.3533\n",
      "[724/1762] D loss: 1.3571\n",
      "[804/1762] D loss: 1.3672\n",
      "[884/1762] D loss: 1.3641\n",
      "[964/1762] D loss: 1.3470\n",
      "[1044/1762] D loss: 1.3462\n",
      "[1124/1762] D loss: 1.3444\n",
      "[1204/1762] D loss: 1.3519\n",
      "[1284/1762] D loss: 1.3556\n",
      "[1364/1762] D loss: 1.3600\n",
      "[1444/1762] D loss: 1.3564\n",
      "[1524/1762] D loss: 1.3561\n",
      "[1604/1762] D loss: 1.3489\n",
      "[1684/1762] D loss: 1.3671\n",
      "[1762/1762] D loss: 1.3477\n",
      "train error: \n",
      " D loss: 1.350600, D accuracy: 62.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351470, D accuracy: 62.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3506\n",
      "[84/1762] D loss: 1.3557\n",
      "[164/1762] D loss: 1.3607\n",
      "[244/1762] D loss: 1.3599\n",
      "[324/1762] D loss: 1.3396\n",
      "[404/1762] D loss: 1.3503\n",
      "[484/1762] D loss: 1.3676\n",
      "[564/1762] D loss: 1.3502\n",
      "[644/1762] D loss: 1.3466\n",
      "[724/1762] D loss: 1.3461\n",
      "[804/1762] D loss: 1.3345\n",
      "[884/1762] D loss: 1.3666\n",
      "[964/1762] D loss: 1.3586\n",
      "[1044/1762] D loss: 1.3460\n",
      "[1124/1762] D loss: 1.3698\n",
      "[1204/1762] D loss: 1.3648\n",
      "[1284/1762] D loss: 1.3538\n",
      "[1364/1762] D loss: 1.3674\n",
      "[1444/1762] D loss: 1.3655\n",
      "[1524/1762] D loss: 1.3783\n",
      "[1604/1762] D loss: 1.3863\n",
      "[1684/1762] D loss: 1.3498\n",
      "[1762/1762] D loss: 1.3262\n",
      "train error: \n",
      " D loss: 1.343003, D accuracy: 63.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344309, D accuracy: 61.8% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3443\n",
      "[84/1762] D loss: 1.3175\n",
      "[164/1762] D loss: 1.3462\n",
      "[244/1762] D loss: 1.3489\n",
      "[324/1762] D loss: 1.3895\n",
      "[404/1762] D loss: 1.3332\n",
      "[484/1762] D loss: 1.3455\n",
      "[564/1762] D loss: 1.3601\n",
      "[644/1762] D loss: 1.3502\n",
      "[724/1762] D loss: 1.3264\n",
      "[804/1762] D loss: 1.3642\n",
      "[884/1762] D loss: 1.3133\n",
      "[964/1762] D loss: 1.3007\n",
      "[1044/1762] D loss: 1.3374\n",
      "[1124/1762] D loss: 1.3762\n",
      "[1204/1762] D loss: 1.3571\n",
      "[1284/1762] D loss: 1.3344\n",
      "[1364/1762] D loss: 1.3266\n",
      "[1444/1762] D loss: 1.3175\n",
      "[1524/1762] D loss: 1.3506\n",
      "[1604/1762] D loss: 1.3425\n",
      "[1684/1762] D loss: 1.3334\n",
      "[1762/1762] D loss: 1.3403\n",
      "train error: \n",
      " D loss: 1.333253, D accuracy: 65.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335898, D accuracy: 64.4% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3639\n",
      "[84/1762] D loss: 1.3749\n",
      "[164/1762] D loss: 1.3131\n",
      "[244/1762] D loss: 1.3472\n",
      "[324/1762] D loss: 1.3582\n",
      "[404/1762] D loss: 1.3141\n",
      "[484/1762] D loss: 1.2886\n",
      "[564/1762] D loss: 1.3377\n",
      "[644/1762] D loss: 1.3020\n",
      "[724/1762] D loss: 1.3611\n",
      "[804/1762] D loss: 1.3754\n",
      "[884/1762] D loss: 1.3284\n",
      "[964/1762] D loss: 1.3392\n",
      "[1044/1762] D loss: 1.3833\n",
      "[1124/1762] D loss: 1.3247\n",
      "[1204/1762] D loss: 1.3442\n",
      "[1284/1762] D loss: 1.3465\n",
      "[1364/1762] D loss: 1.2988\n",
      "[1444/1762] D loss: 1.3499\n",
      "[1524/1762] D loss: 1.3247\n",
      "[1604/1762] D loss: 1.3567\n",
      "[1684/1762] D loss: 1.3559\n",
      "[1762/1762] D loss: 1.3544\n",
      "train error: \n",
      " D loss: 1.322078, D accuracy: 66.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318350, D accuracy: 68.8% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2962\n",
      "[84/1762] D loss: 1.3361\n",
      "[164/1762] D loss: 1.3234\n",
      "[244/1762] D loss: 1.3464\n",
      "[324/1762] D loss: 1.3191\n",
      "[404/1762] D loss: 1.3098\n",
      "[484/1762] D loss: 1.3193\n",
      "[564/1762] D loss: 1.3543\n",
      "[644/1762] D loss: 1.3402\n",
      "[724/1762] D loss: 1.3429\n",
      "[804/1762] D loss: 1.3457\n",
      "[884/1762] D loss: 1.3232\n",
      "[964/1762] D loss: 1.3231\n",
      "[1044/1762] D loss: 1.3242\n",
      "[1124/1762] D loss: 1.3180\n",
      "[1204/1762] D loss: 1.3001\n",
      "[1284/1762] D loss: 1.2978\n",
      "[1364/1762] D loss: 1.3378\n",
      "[1444/1762] D loss: 1.3657\n",
      "[1524/1762] D loss: 1.3373\n",
      "[1604/1762] D loss: 1.3398\n",
      "[1684/1762] D loss: 1.3036\n",
      "[1762/1762] D loss: 1.2778\n",
      "train error: \n",
      " D loss: 1.308437, D accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306580, D accuracy: 69.4% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3007\n",
      "[84/1762] D loss: 1.3142\n",
      "[164/1762] D loss: 1.2918\n",
      "[244/1762] D loss: 1.3383\n",
      "[324/1762] D loss: 1.3093\n",
      "[404/1762] D loss: 1.2503\n",
      "[484/1762] D loss: 1.3493\n",
      "[564/1762] D loss: 1.3165\n",
      "[644/1762] D loss: 1.2760\n",
      "[724/1762] D loss: 1.2531\n",
      "[804/1762] D loss: 1.2981\n",
      "[884/1762] D loss: 1.2048\n",
      "[964/1762] D loss: 1.3341\n",
      "[1044/1762] D loss: 1.2898\n",
      "[1124/1762] D loss: 1.3036\n",
      "[1204/1762] D loss: 1.3066\n",
      "[1284/1762] D loss: 1.3030\n",
      "[1364/1762] D loss: 1.2876\n",
      "[1444/1762] D loss: 1.2504\n",
      "[1524/1762] D loss: 1.2877\n",
      "[1604/1762] D loss: 1.2314\n",
      "[1684/1762] D loss: 1.3583\n",
      "[1762/1762] D loss: 1.3227\n",
      "train error: \n",
      " D loss: 1.281638, D accuracy: 71.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290427, D accuracy: 69.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2904\n",
      "[84/1762] D loss: 1.2668\n",
      "[164/1762] D loss: 1.2959\n",
      "[244/1762] D loss: 1.3134\n",
      "[324/1762] D loss: 1.2873\n",
      "[404/1762] D loss: 1.2938\n",
      "[484/1762] D loss: 1.3045\n",
      "[564/1762] D loss: 1.2829\n",
      "[644/1762] D loss: 1.1865\n",
      "[724/1762] D loss: 1.2829\n",
      "[804/1762] D loss: 1.2554\n",
      "[884/1762] D loss: 1.2748\n",
      "[964/1762] D loss: 1.3385\n",
      "[1044/1762] D loss: 1.3065\n",
      "[1124/1762] D loss: 1.3243\n",
      "[1204/1762] D loss: 1.3056\n",
      "[1284/1762] D loss: 1.2607\n",
      "[1364/1762] D loss: 1.3174\n",
      "[1444/1762] D loss: 1.2690\n",
      "[1524/1762] D loss: 1.1745\n",
      "[1604/1762] D loss: 1.2661\n",
      "[1684/1762] D loss: 1.3084\n",
      "[1762/1762] D loss: 1.3345\n",
      "train error: \n",
      " D loss: 1.268247, D accuracy: 73.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270102, D accuracy: 71.7% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3274\n",
      "[84/1762] D loss: 1.2535\n",
      "[164/1762] D loss: 1.2091\n",
      "[244/1762] D loss: 1.3138\n",
      "[324/1762] D loss: 1.2303\n",
      "[404/1762] D loss: 1.3138\n",
      "[484/1762] D loss: 1.2807\n",
      "[564/1762] D loss: 1.2397\n",
      "[644/1762] D loss: 1.3308\n",
      "[724/1762] D loss: 1.2341\n",
      "[804/1762] D loss: 1.3298\n",
      "[884/1762] D loss: 1.3629\n",
      "[964/1762] D loss: 1.2352\n",
      "[1044/1762] D loss: 1.2650\n",
      "[1124/1762] D loss: 1.1807\n",
      "[1204/1762] D loss: 1.3074\n",
      "[1284/1762] D loss: 1.2409\n",
      "[1364/1762] D loss: 1.2617\n",
      "[1444/1762] D loss: 1.2764\n",
      "[1524/1762] D loss: 1.2866\n",
      "[1604/1762] D loss: 1.2830\n",
      "[1684/1762] D loss: 1.2400\n",
      "[1762/1762] D loss: 1.3110\n",
      "train error: \n",
      " D loss: 1.250373, D accuracy: 75.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249403, D accuracy: 75.6% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2851\n",
      "[84/1762] D loss: 1.3130\n",
      "[164/1762] D loss: 1.2726\n",
      "[244/1762] D loss: 1.2558\n",
      "[324/1762] D loss: 1.2803\n",
      "[404/1762] D loss: 1.2604\n",
      "[484/1762] D loss: 1.2087\n",
      "[564/1762] D loss: 1.2560\n",
      "[644/1762] D loss: 1.3065\n",
      "[724/1762] D loss: 1.2061\n",
      "[804/1762] D loss: 1.2273\n",
      "[884/1762] D loss: 1.2424\n",
      "[964/1762] D loss: 1.2511\n",
      "[1044/1762] D loss: 1.2690\n",
      "[1124/1762] D loss: 1.2757\n",
      "[1204/1762] D loss: 1.2804\n",
      "[1284/1762] D loss: 1.2097\n",
      "[1364/1762] D loss: 1.2034\n",
      "[1444/1762] D loss: 1.3255\n",
      "[1524/1762] D loss: 1.1772\n",
      "[1604/1762] D loss: 1.3260\n",
      "[1684/1762] D loss: 1.2666\n",
      "[1762/1762] D loss: 1.3075\n",
      "train error: \n",
      " D loss: 1.221711, D accuracy: 77.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.218979, D accuracy: 80.7% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3100\n",
      "[84/1762] D loss: 1.2079\n",
      "[164/1762] D loss: 1.2884\n",
      "[244/1762] D loss: 1.2172\n",
      "[324/1762] D loss: 1.2901\n",
      "[404/1762] D loss: 1.0413\n",
      "[484/1762] D loss: 1.3327\n",
      "[564/1762] D loss: 1.2026\n",
      "[644/1762] D loss: 1.2352\n",
      "[724/1762] D loss: 1.2518\n",
      "[804/1762] D loss: 1.2624\n",
      "[884/1762] D loss: 1.2987\n",
      "[964/1762] D loss: 1.1585\n",
      "[1044/1762] D loss: 1.3445\n",
      "[1124/1762] D loss: 1.1881\n",
      "[1204/1762] D loss: 1.2572\n",
      "[1284/1762] D loss: 1.2949\n",
      "[1364/1762] D loss: 1.2876\n",
      "[1444/1762] D loss: 1.3113\n",
      "[1524/1762] D loss: 1.2558\n",
      "[1604/1762] D loss: 1.2572\n",
      "[1684/1762] D loss: 1.2370\n",
      "[1762/1762] D loss: 1.1482\n",
      "train error: \n",
      " D loss: 1.184093, D accuracy: 80.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.193331, D accuracy: 81.1% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2545\n",
      "[84/1762] D loss: 1.1842\n",
      "[164/1762] D loss: 1.2021\n",
      "[244/1762] D loss: 1.1888\n",
      "[324/1762] D loss: 1.1614\n",
      "[404/1762] D loss: 1.2510\n",
      "[484/1762] D loss: 1.1591\n",
      "[564/1762] D loss: 1.3708\n",
      "[644/1762] D loss: 1.3254\n",
      "[724/1762] D loss: 1.0713\n",
      "[804/1762] D loss: 1.2664\n",
      "[884/1762] D loss: 1.2005\n",
      "[964/1762] D loss: 1.1748\n",
      "[1044/1762] D loss: 1.1692\n",
      "[1124/1762] D loss: 1.2212\n",
      "[1204/1762] D loss: 1.2165\n",
      "[1284/1762] D loss: 1.0988\n",
      "[1364/1762] D loss: 1.1702\n",
      "[1444/1762] D loss: 1.1402\n",
      "[1524/1762] D loss: 1.0300\n",
      "[1604/1762] D loss: 1.2548\n",
      "[1684/1762] D loss: 1.1517\n",
      "[1762/1762] D loss: 1.1698\n",
      "train error: \n",
      " D loss: 1.144724, D accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.146689, D accuracy: 82.8% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1800\n",
      "[84/1762] D loss: 1.1319\n",
      "[164/1762] D loss: 1.1281\n",
      "[244/1762] D loss: 1.1486\n",
      "[324/1762] D loss: 1.2409\n",
      "[404/1762] D loss: 1.1164\n",
      "[484/1762] D loss: 1.2399\n",
      "[564/1762] D loss: 1.1868\n",
      "[644/1762] D loss: 1.1874\n",
      "[724/1762] D loss: 1.1274\n",
      "[804/1762] D loss: 1.1518\n",
      "[884/1762] D loss: 1.0783\n",
      "[964/1762] D loss: 1.0927\n",
      "[1044/1762] D loss: 1.1270\n",
      "[1124/1762] D loss: 1.1648\n",
      "[1204/1762] D loss: 0.9827\n",
      "[1284/1762] D loss: 1.2731\n",
      "[1364/1762] D loss: 1.0116\n",
      "[1444/1762] D loss: 1.0816\n",
      "[1524/1762] D loss: 1.1978\n",
      "[1604/1762] D loss: 1.1909\n",
      "[1684/1762] D loss: 1.2352\n",
      "[1762/1762] D loss: 1.0931\n",
      "train error: \n",
      " D loss: 1.083316, D accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.093587, D accuracy: 82.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9420\n",
      "[84/1762] D loss: 1.0984\n",
      "[164/1762] D loss: 1.2035\n",
      "[244/1762] D loss: 1.1203\n",
      "[324/1762] D loss: 0.9118\n",
      "[404/1762] D loss: 1.0414\n",
      "[484/1762] D loss: 1.2270\n",
      "[564/1762] D loss: 1.0463\n",
      "[644/1762] D loss: 1.0191\n",
      "[724/1762] D loss: 0.8977\n",
      "[804/1762] D loss: 1.1638\n",
      "[884/1762] D loss: 1.1027\n",
      "[964/1762] D loss: 1.1043\n",
      "[1044/1762] D loss: 1.0310\n",
      "[1124/1762] D loss: 1.1249\n",
      "[1204/1762] D loss: 1.0357\n",
      "[1284/1762] D loss: 1.2074\n",
      "[1364/1762] D loss: 1.0823\n",
      "[1444/1762] D loss: 1.0362\n",
      "[1524/1762] D loss: 1.1131\n",
      "[1604/1762] D loss: 1.0006\n",
      "[1684/1762] D loss: 1.2795\n",
      "[1762/1762] D loss: 1.1667\n",
      "train error: \n",
      " D loss: 1.030093, D accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.037578, D accuracy: 85.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0270\n",
      "[84/1762] D loss: 1.0299\n",
      "[164/1762] D loss: 0.9185\n",
      "[244/1762] D loss: 0.9283\n",
      "[324/1762] D loss: 1.1212\n",
      "[404/1762] D loss: 1.0947\n",
      "[484/1762] D loss: 0.9817\n",
      "[564/1762] D loss: 1.1749\n",
      "[644/1762] D loss: 1.1142\n",
      "[724/1762] D loss: 1.0537\n",
      "[804/1762] D loss: 1.0435\n",
      "[884/1762] D loss: 1.0570\n",
      "[964/1762] D loss: 1.0941\n",
      "[1044/1762] D loss: 0.9217\n",
      "[1124/1762] D loss: 1.0544\n",
      "[1204/1762] D loss: 1.2105\n",
      "[1284/1762] D loss: 1.0291\n",
      "[1364/1762] D loss: 1.1630\n",
      "[1444/1762] D loss: 1.0197\n",
      "[1524/1762] D loss: 0.9412\n",
      "[1604/1762] D loss: 0.8880\n",
      "[1684/1762] D loss: 1.0035\n",
      "[1762/1762] D loss: 1.0441\n",
      "train error: \n",
      " D loss: 0.966196, D accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.988252, D accuracy: 86.6% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1081\n",
      "[84/1762] D loss: 0.9203\n",
      "[164/1762] D loss: 1.0538\n",
      "[244/1762] D loss: 0.7127\n",
      "[324/1762] D loss: 0.9034\n",
      "[404/1762] D loss: 1.1695\n",
      "[484/1762] D loss: 0.9261\n",
      "[564/1762] D loss: 1.1081\n",
      "[644/1762] D loss: 1.1067\n",
      "[724/1762] D loss: 1.1107\n",
      "[804/1762] D loss: 1.0881\n",
      "[884/1762] D loss: 0.8996\n",
      "[964/1762] D loss: 1.0935\n",
      "[1044/1762] D loss: 1.1329\n",
      "[1124/1762] D loss: 0.9853\n",
      "[1204/1762] D loss: 1.1216\n",
      "[1284/1762] D loss: 0.9527\n",
      "[1364/1762] D loss: 0.9096\n",
      "[1444/1762] D loss: 0.9604\n",
      "[1524/1762] D loss: 1.0799\n",
      "[1604/1762] D loss: 0.9696\n",
      "[1684/1762] D loss: 0.7946\n",
      "[1762/1762] D loss: 0.8591\n",
      "train error: \n",
      " D loss: 0.906487, D accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.932392, D accuracy: 85.3% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7938\n",
      "[84/1762] D loss: 0.9027\n",
      "[164/1762] D loss: 1.1885\n",
      "[244/1762] D loss: 0.8407\n",
      "[324/1762] D loss: 1.0133\n",
      "[404/1762] D loss: 0.9755\n",
      "[484/1762] D loss: 1.0753\n",
      "[564/1762] D loss: 0.8962\n",
      "[644/1762] D loss: 0.8174\n",
      "[724/1762] D loss: 0.6397\n",
      "[804/1762] D loss: 1.0520\n",
      "[884/1762] D loss: 0.9626\n",
      "[964/1762] D loss: 0.9081\n",
      "[1044/1762] D loss: 0.9544\n",
      "[1124/1762] D loss: 0.9316\n",
      "[1204/1762] D loss: 1.0139\n",
      "[1284/1762] D loss: 0.8814\n",
      "[1364/1762] D loss: 1.1308\n",
      "[1444/1762] D loss: 0.8720\n",
      "[1524/1762] D loss: 0.9659\n",
      "[1604/1762] D loss: 0.7616\n",
      "[1684/1762] D loss: 0.7928\n",
      "[1762/1762] D loss: 0.7011\n",
      "train error: \n",
      " D loss: 0.828245, D accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.836546, D accuracy: 89.4% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1989\n",
      "[84/1762] D loss: 0.8753\n",
      "[164/1762] D loss: 0.7429\n",
      "[244/1762] D loss: 0.6051\n",
      "[324/1762] D loss: 0.8767\n",
      "[404/1762] D loss: 1.1283\n",
      "[484/1762] D loss: 0.8937\n",
      "[564/1762] D loss: 0.9295\n",
      "[644/1762] D loss: 0.8099\n",
      "[724/1762] D loss: 0.9264\n",
      "[804/1762] D loss: 0.7547\n",
      "[884/1762] D loss: 0.7757\n",
      "[964/1762] D loss: 0.7578\n",
      "[1044/1762] D loss: 0.6111\n",
      "[1124/1762] D loss: 0.8106\n",
      "[1204/1762] D loss: 0.5791\n",
      "[1284/1762] D loss: 0.7125\n",
      "[1364/1762] D loss: 0.8072\n",
      "[1444/1762] D loss: 0.7665\n",
      "[1524/1762] D loss: 0.6904\n",
      "[1604/1762] D loss: 1.0515\n",
      "[1684/1762] D loss: 0.6457\n",
      "[1762/1762] D loss: 0.6538\n",
      "train error: \n",
      " D loss: 0.730635, D accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.741765, D accuracy: 90.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7422\n",
      "[84/1762] D loss: 0.7781\n",
      "[164/1762] D loss: 0.7239\n",
      "[244/1762] D loss: 0.7031\n",
      "[324/1762] D loss: 0.9923\n",
      "[404/1762] D loss: 0.7632\n",
      "[484/1762] D loss: 0.5623\n",
      "[564/1762] D loss: 0.7763\n",
      "[644/1762] D loss: 0.6766\n",
      "[724/1762] D loss: 0.6467\n",
      "[804/1762] D loss: 0.9397\n",
      "[884/1762] D loss: 0.7254\n",
      "[964/1762] D loss: 0.9372\n",
      "[1044/1762] D loss: 0.7939\n",
      "[1124/1762] D loss: 0.7449\n",
      "[1204/1762] D loss: 1.0416\n",
      "[1284/1762] D loss: 0.5427\n",
      "[1364/1762] D loss: 0.7103\n",
      "[1444/1762] D loss: 0.8495\n",
      "[1524/1762] D loss: 0.5548\n",
      "[1604/1762] D loss: 0.9246\n",
      "[1684/1762] D loss: 0.7330\n",
      "[1762/1762] D loss: 0.2919\n",
      "train error: \n",
      " D loss: 0.673668, D accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.676858, D accuracy: 90.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4459\n",
      "[84/1762] D loss: 0.5987\n",
      "[164/1762] D loss: 0.5727\n",
      "[244/1762] D loss: 0.5159\n",
      "[324/1762] D loss: 1.1109\n",
      "[404/1762] D loss: 0.5380\n",
      "[484/1762] D loss: 0.7712\n",
      "[564/1762] D loss: 0.6652\n",
      "[644/1762] D loss: 1.0486\n",
      "[724/1762] D loss: 0.8374\n",
      "[804/1762] D loss: 1.0564\n",
      "[884/1762] D loss: 0.7138\n",
      "[964/1762] D loss: 0.5062\n",
      "[1044/1762] D loss: 0.4940\n",
      "[1124/1762] D loss: 0.4890\n",
      "[1204/1762] D loss: 0.8012\n",
      "[1284/1762] D loss: 0.5781\n",
      "[1364/1762] D loss: 0.3758\n",
      "[1444/1762] D loss: 0.3734\n",
      "[1524/1762] D loss: 0.5630\n",
      "[1604/1762] D loss: 0.5254\n",
      "[1684/1762] D loss: 0.6984\n",
      "[1762/1762] D loss: 0.6090\n",
      "train error: \n",
      " D loss: 0.615234, D accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.618153, D accuracy: 91.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5901\n",
      "[84/1762] D loss: 0.7799\n",
      "[164/1762] D loss: 0.8553\n",
      "[244/1762] D loss: 0.8549\n",
      "[324/1762] D loss: 0.7516\n",
      "[404/1762] D loss: 0.3867\n",
      "[484/1762] D loss: 0.5655\n",
      "[564/1762] D loss: 0.4773\n",
      "[644/1762] D loss: 0.4965\n",
      "[724/1762] D loss: 0.7046\n",
      "[804/1762] D loss: 0.3760\n",
      "[884/1762] D loss: 0.5186\n",
      "[964/1762] D loss: 0.7167\n",
      "[1044/1762] D loss: 0.4721\n",
      "[1124/1762] D loss: 0.5410\n",
      "[1204/1762] D loss: 0.4946\n",
      "[1284/1762] D loss: 0.7436\n",
      "[1364/1762] D loss: 0.7796\n",
      "[1444/1762] D loss: 0.3721\n",
      "[1524/1762] D loss: 1.0142\n",
      "[1604/1762] D loss: 0.6103\n",
      "[1684/1762] D loss: 0.3976\n",
      "[1762/1762] D loss: 0.4916\n",
      "train error: \n",
      " D loss: 0.564423, D accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.601487, D accuracy: 90.3% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3881\n",
      "[84/1762] D loss: 0.2778\n",
      "[164/1762] D loss: 0.6235\n",
      "[244/1762] D loss: 0.5233\n",
      "[324/1762] D loss: 0.3360\n",
      "[404/1762] D loss: 0.4207\n",
      "[484/1762] D loss: 0.5955\n",
      "[564/1762] D loss: 0.5990\n",
      "[644/1762] D loss: 0.4313\n",
      "[724/1762] D loss: 0.5190\n",
      "[804/1762] D loss: 0.4637\n",
      "[884/1762] D loss: 0.4571\n",
      "[964/1762] D loss: 0.3753\n",
      "[1044/1762] D loss: 0.2154\n",
      "[1124/1762] D loss: 0.2307\n",
      "[1204/1762] D loss: 0.5901\n",
      "[1284/1762] D loss: 0.4460\n",
      "[1364/1762] D loss: 0.5661\n",
      "[1444/1762] D loss: 0.3072\n",
      "[1524/1762] D loss: 0.5579\n",
      "[1604/1762] D loss: 0.4392\n",
      "[1684/1762] D loss: 0.6318\n",
      "[1762/1762] D loss: 0.2907\n",
      "train error: \n",
      " D loss: 0.493803, D accuracy: 94.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.483550, D accuracy: 94.9% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4230\n",
      "[84/1762] D loss: 0.2976\n",
      "[164/1762] D loss: 0.6127\n",
      "[244/1762] D loss: 0.7416\n",
      "[324/1762] D loss: 0.3571\n",
      "[404/1762] D loss: 0.2375\n",
      "[484/1762] D loss: 0.6379\n",
      "[564/1762] D loss: 0.5147\n",
      "[644/1762] D loss: 0.2218\n",
      "[724/1762] D loss: 0.2603\n",
      "[804/1762] D loss: 0.2188\n",
      "[884/1762] D loss: 0.4496\n",
      "[964/1762] D loss: 0.9659\n",
      "[1044/1762] D loss: 0.7301\n",
      "[1124/1762] D loss: 0.3045\n",
      "[1204/1762] D loss: 0.3091\n",
      "[1284/1762] D loss: 0.4111\n",
      "[1364/1762] D loss: 0.5067\n",
      "[1444/1762] D loss: 0.3227\n",
      "[1524/1762] D loss: 0.5057\n",
      "[1604/1762] D loss: 0.5691\n",
      "[1684/1762] D loss: 0.4660\n",
      "[1762/1762] D loss: 0.1489\n",
      "train error: \n",
      " D loss: 0.410400, D accuracy: 96.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.425222, D accuracy: 95.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1550\n",
      "[84/1762] D loss: 0.1446\n",
      "[164/1762] D loss: 0.3252\n",
      "[244/1762] D loss: 0.2387\n",
      "[324/1762] D loss: 0.2339\n",
      "[404/1762] D loss: 0.3299\n",
      "[484/1762] D loss: 0.5001\n",
      "[564/1762] D loss: 0.4685\n",
      "[644/1762] D loss: 0.2511\n",
      "[724/1762] D loss: 0.2674\n",
      "[804/1762] D loss: 0.3217\n",
      "[884/1762] D loss: 0.2074\n",
      "[964/1762] D loss: 0.4160\n",
      "[1044/1762] D loss: 0.2956\n",
      "[1124/1762] D loss: 0.3075\n",
      "[1204/1762] D loss: 0.2633\n",
      "[1284/1762] D loss: 0.2212\n",
      "[1364/1762] D loss: 0.1242\n",
      "[1444/1762] D loss: 0.4698\n",
      "[1524/1762] D loss: 0.2017\n",
      "[1604/1762] D loss: 0.2974\n",
      "[1684/1762] D loss: 0.3088\n",
      "[1762/1762] D loss: 1.0384\n",
      "train error: \n",
      " D loss: 0.394214, D accuracy: 96.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.376213, D accuracy: 97.4% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3089\n",
      "[84/1762] D loss: 0.3148\n",
      "[164/1762] D loss: 0.4473\n",
      "[244/1762] D loss: 0.3327\n",
      "[324/1762] D loss: 0.3235\n",
      "[404/1762] D loss: 0.5232\n",
      "[484/1762] D loss: 0.1793\n",
      "[564/1762] D loss: 0.3587\n",
      "[644/1762] D loss: 0.1652\n",
      "[724/1762] D loss: 0.4793\n",
      "[804/1762] D loss: 0.1318\n",
      "[884/1762] D loss: 0.3456\n",
      "[964/1762] D loss: 0.1164\n",
      "[1044/1762] D loss: 0.4012\n",
      "[1124/1762] D loss: 0.4313\n",
      "[1204/1762] D loss: 0.2694\n",
      "[1284/1762] D loss: 0.2637\n",
      "[1364/1762] D loss: 0.2540\n",
      "[1444/1762] D loss: 0.5186\n",
      "[1524/1762] D loss: 0.2155\n",
      "[1604/1762] D loss: 0.5286\n",
      "[1684/1762] D loss: 0.4784\n",
      "[1762/1762] D loss: 0.0592\n",
      "train error: \n",
      " D loss: 0.365912, D accuracy: 95.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.351966, D accuracy: 95.7% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1757\n",
      "[84/1762] D loss: 0.2231\n",
      "[164/1762] D loss: 0.6118\n",
      "[244/1762] D loss: 0.5477\n",
      "[324/1762] D loss: 0.3413\n",
      "[404/1762] D loss: 0.2142\n",
      "[484/1762] D loss: 0.2355\n",
      "[564/1762] D loss: 0.2728\n",
      "[644/1762] D loss: 0.2815\n",
      "[724/1762] D loss: 0.3318\n",
      "[804/1762] D loss: 0.3693\n",
      "[884/1762] D loss: 0.4025\n",
      "[964/1762] D loss: 0.3282\n",
      "[1044/1762] D loss: 0.3040\n",
      "[1124/1762] D loss: 0.3661\n",
      "[1204/1762] D loss: 0.1308\n",
      "[1284/1762] D loss: 0.1940\n",
      "[1364/1762] D loss: 0.2072\n",
      "[1444/1762] D loss: 0.1433\n",
      "[1524/1762] D loss: 0.1446\n",
      "[1604/1762] D loss: 0.4323\n",
      "[1684/1762] D loss: 0.2395\n",
      "[1762/1762] D loss: 0.1375\n",
      "train error: \n",
      " D loss: 0.324999, D accuracy: 97.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.333157, D accuracy: 96.9% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2202\n",
      "[84/1762] D loss: 0.1755\n",
      "[164/1762] D loss: 0.3863\n",
      "[244/1762] D loss: 0.4260\n",
      "[324/1762] D loss: 0.1490\n",
      "[404/1762] D loss: 0.1146\n",
      "[484/1762] D loss: 0.0967\n",
      "[564/1762] D loss: 0.1172\n",
      "[644/1762] D loss: 0.5348\n",
      "[724/1762] D loss: 0.0664\n",
      "[804/1762] D loss: 0.5525\n",
      "[884/1762] D loss: 0.1724\n",
      "[964/1762] D loss: 0.2036\n",
      "[1044/1762] D loss: 0.0845\n",
      "[1124/1762] D loss: 0.1073\n",
      "[1204/1762] D loss: 0.2803\n",
      "[1284/1762] D loss: 0.3015\n",
      "[1364/1762] D loss: 0.3089\n",
      "[1444/1762] D loss: 0.0743\n",
      "[1524/1762] D loss: 0.0953\n",
      "[1604/1762] D loss: 0.0834\n",
      "[1684/1762] D loss: 0.0814\n",
      "[1762/1762] D loss: 0.2806\n",
      "train error: \n",
      " D loss: 0.318429, D accuracy: 97.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.323403, D accuracy: 97.4% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1409\n",
      "[84/1762] D loss: 0.1151\n",
      "[164/1762] D loss: 0.4615\n",
      "[244/1762] D loss: 0.2105\n",
      "[324/1762] D loss: 0.0759\n",
      "[404/1762] D loss: 0.3490\n",
      "[484/1762] D loss: 0.1278\n",
      "[564/1762] D loss: 0.2180\n",
      "[644/1762] D loss: 0.6924\n",
      "[724/1762] D loss: 0.1652\n",
      "[804/1762] D loss: 0.1090\n",
      "[884/1762] D loss: 0.0625\n",
      "[964/1762] D loss: 0.2312\n",
      "[1044/1762] D loss: 0.0823\n",
      "[1124/1762] D loss: 0.1330\n",
      "[1204/1762] D loss: 0.1713\n",
      "[1284/1762] D loss: 0.1903\n",
      "[1364/1762] D loss: 0.2524\n",
      "[1444/1762] D loss: 0.0571\n",
      "[1524/1762] D loss: 0.1082\n",
      "[1604/1762] D loss: 0.3374\n",
      "[1684/1762] D loss: 0.1073\n",
      "[1762/1762] D loss: 0.1605\n",
      "train error: \n",
      " D loss: 0.272288, D accuracy: 97.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.291642, D accuracy: 97.6% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0804\n",
      "[84/1762] D loss: 0.2194\n",
      "[164/1762] D loss: 0.0719\n",
      "[244/1762] D loss: 0.1296\n",
      "[324/1762] D loss: 0.0802\n",
      "[404/1762] D loss: 0.0571\n",
      "[484/1762] D loss: 0.1667\n",
      "[564/1762] D loss: 0.0658\n",
      "[644/1762] D loss: 0.4537\n",
      "[724/1762] D loss: 0.2620\n",
      "[804/1762] D loss: 0.1328\n",
      "[884/1762] D loss: 0.0327\n",
      "[964/1762] D loss: 0.2259\n",
      "[1044/1762] D loss: 0.1115\n",
      "[1124/1762] D loss: 0.1096\n",
      "[1204/1762] D loss: 0.1163\n",
      "[1284/1762] D loss: 0.1302\n",
      "[1364/1762] D loss: 0.2830\n",
      "[1444/1762] D loss: 0.1033\n",
      "[1524/1762] D loss: 0.0855\n",
      "[1604/1762] D loss: 0.1431\n",
      "[1684/1762] D loss: 0.0992\n",
      "[1762/1762] D loss: 0.1349\n",
      "train error: \n",
      " D loss: 0.265770, D accuracy: 97.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.269173, D accuracy: 97.7% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0992\n",
      "[84/1762] D loss: 0.0471\n",
      "[164/1762] D loss: 0.0738\n",
      "[244/1762] D loss: 0.0733\n",
      "[324/1762] D loss: 0.1753\n",
      "[404/1762] D loss: 0.1566\n",
      "[484/1762] D loss: 0.1401\n",
      "[564/1762] D loss: 0.2640\n",
      "[644/1762] D loss: 0.0951\n",
      "[724/1762] D loss: 0.0341\n",
      "[804/1762] D loss: 0.0432\n",
      "[884/1762] D loss: 0.1311\n",
      "[964/1762] D loss: 0.1957\n",
      "[1044/1762] D loss: 0.2658\n",
      "[1124/1762] D loss: 0.0545\n",
      "[1204/1762] D loss: 0.0739\n",
      "[1284/1762] D loss: 0.1799\n",
      "[1364/1762] D loss: 0.0374\n",
      "[1444/1762] D loss: 0.1616\n",
      "[1524/1762] D loss: 0.0464\n",
      "[1604/1762] D loss: 0.1200\n",
      "[1684/1762] D loss: 0.0619\n",
      "[1762/1762] D loss: 0.2463\n",
      "train error: \n",
      " D loss: 0.278899, D accuracy: 98.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.293806, D accuracy: 97.6% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1141\n",
      "[84/1762] D loss: 0.0513\n",
      "[164/1762] D loss: 0.1879\n",
      "[244/1762] D loss: 0.1151\n",
      "[324/1762] D loss: 0.1208\n",
      "[404/1762] D loss: 0.0291\n",
      "[484/1762] D loss: 0.0966\n",
      "[564/1762] D loss: 0.0345\n",
      "[644/1762] D loss: 0.0694\n",
      "[724/1762] D loss: 0.4543\n",
      "[804/1762] D loss: 0.0372\n",
      "[884/1762] D loss: 0.1550\n",
      "[964/1762] D loss: 0.3935\n",
      "[1044/1762] D loss: 0.0927\n",
      "[1124/1762] D loss: 0.0595\n",
      "[1204/1762] D loss: 0.0537\n",
      "[1284/1762] D loss: 0.3114\n",
      "[1364/1762] D loss: 0.0854\n",
      "[1444/1762] D loss: 0.1084\n",
      "[1524/1762] D loss: 0.4300\n",
      "[1604/1762] D loss: 0.0244\n",
      "[1684/1762] D loss: 0.1499\n",
      "[1762/1762] D loss: 0.0191\n",
      "train error: \n",
      " D loss: 0.262288, D accuracy: 99.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.284688, D accuracy: 98.1% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0506\n",
      "[84/1762] D loss: 0.0337\n",
      "[164/1762] D loss: 0.1021\n",
      "[244/1762] D loss: 0.0475\n",
      "[324/1762] D loss: 0.1225\n",
      "[404/1762] D loss: 0.0808\n",
      "[484/1762] D loss: 0.0512\n",
      "[564/1762] D loss: 0.1053\n",
      "[644/1762] D loss: 0.0392\n",
      "[724/1762] D loss: 0.0367\n",
      "[804/1762] D loss: 0.2182\n",
      "[884/1762] D loss: 0.0207\n",
      "[964/1762] D loss: 0.0962\n",
      "[1044/1762] D loss: 0.1843\n",
      "[1124/1762] D loss: 0.1443\n",
      "[1204/1762] D loss: 0.0270\n",
      "[1284/1762] D loss: 0.0206\n",
      "[1364/1762] D loss: 0.0468\n",
      "[1444/1762] D loss: 0.0941\n",
      "[1524/1762] D loss: 0.0372\n",
      "[1604/1762] D loss: 0.0440\n",
      "[1684/1762] D loss: 0.0990\n",
      "[1762/1762] D loss: 0.0242\n",
      "train error: \n",
      " D loss: 0.263861, D accuracy: 98.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.270607, D accuracy: 99.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0718\n",
      "[84/1762] D loss: 0.0504\n",
      "[164/1762] D loss: 0.0451\n",
      "[244/1762] D loss: 0.0627\n",
      "[324/1762] D loss: 0.0541\n",
      "[404/1762] D loss: 0.0280\n",
      "[484/1762] D loss: 0.0689\n",
      "[564/1762] D loss: 0.0434\n",
      "[644/1762] D loss: 0.0231\n",
      "[724/1762] D loss: 0.0544\n",
      "[804/1762] D loss: 0.0274\n",
      "[884/1762] D loss: 0.0702\n",
      "[964/1762] D loss: 0.0926\n",
      "[1044/1762] D loss: 0.0265\n",
      "[1124/1762] D loss: 0.0442\n",
      "[1204/1762] D loss: 0.0679\n",
      "[1284/1762] D loss: 0.0759\n",
      "[1364/1762] D loss: 0.0535\n",
      "[1444/1762] D loss: 0.0247\n",
      "[1524/1762] D loss: 0.1296\n",
      "[1604/1762] D loss: 0.1277\n",
      "[1684/1762] D loss: 0.0309\n",
      "[1762/1762] D loss: 0.0277\n",
      "train error: \n",
      " D loss: 0.280057, D accuracy: 99.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.297060, D accuracy: 98.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0298\n",
      "[84/1762] D loss: 0.0808\n",
      "[164/1762] D loss: 0.0658\n",
      "[244/1762] D loss: 0.0856\n",
      "[324/1762] D loss: 0.0842\n",
      "[404/1762] D loss: 0.0246\n",
      "[484/1762] D loss: 0.0708\n",
      "[564/1762] D loss: 0.0269\n",
      "[644/1762] D loss: 0.2001\n",
      "[724/1762] D loss: 0.0194\n",
      "[804/1762] D loss: 0.0444\n",
      "[884/1762] D loss: 0.1028\n",
      "[964/1762] D loss: 0.1131\n",
      "[1044/1762] D loss: 0.0159\n",
      "[1124/1762] D loss: 0.1284\n",
      "[1204/1762] D loss: 0.0919\n",
      "[1284/1762] D loss: 0.0309\n",
      "[1364/1762] D loss: 0.0404\n",
      "[1444/1762] D loss: 0.0827\n",
      "[1524/1762] D loss: 0.0343\n",
      "[1604/1762] D loss: 0.0540\n",
      "[1684/1762] D loss: 0.0376\n",
      "[1762/1762] D loss: 0.0618\n",
      "train error: \n",
      " D loss: 0.231630, D accuracy: 98.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.240395, D accuracy: 99.1% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1441\n",
      "[84/1762] D loss: 0.0989\n",
      "[164/1762] D loss: 0.1151\n",
      "[244/1762] D loss: 0.0529\n",
      "[324/1762] D loss: 0.0352\n",
      "[404/1762] D loss: 0.1291\n",
      "[484/1762] D loss: 0.0926\n",
      "[564/1762] D loss: 0.0202\n",
      "[644/1762] D loss: 0.0225\n",
      "[724/1762] D loss: 0.0487\n",
      "[804/1762] D loss: 0.2169\n",
      "[884/1762] D loss: 0.0240\n",
      "[964/1762] D loss: 0.0349\n",
      "[1044/1762] D loss: 0.1348\n",
      "[1124/1762] D loss: 0.0121\n",
      "[1204/1762] D loss: 0.0855\n",
      "[1284/1762] D loss: 0.0427\n",
      "[1364/1762] D loss: 0.0146\n",
      "[1444/1762] D loss: 0.1114\n",
      "[1524/1762] D loss: 0.1537\n",
      "[1604/1762] D loss: 0.1797\n",
      "[1684/1762] D loss: 0.0820\n",
      "[1762/1762] D loss: 0.0981\n",
      "train error: \n",
      " D loss: 0.314678, D accuracy: 98.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.336776, D accuracy: 97.8% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0616\n",
      "[84/1762] D loss: 0.0150\n",
      "[164/1762] D loss: 0.0755\n",
      "[244/1762] D loss: 0.1046\n",
      "[324/1762] D loss: 0.0201\n",
      "[404/1762] D loss: 0.0137\n",
      "[484/1762] D loss: 0.0351\n",
      "[564/1762] D loss: 0.0413\n",
      "[644/1762] D loss: 0.0273\n",
      "[724/1762] D loss: 0.0135\n",
      "[804/1762] D loss: 0.0458\n",
      "[884/1762] D loss: 0.0085\n",
      "[964/1762] D loss: 0.1212\n",
      "[1044/1762] D loss: 0.0286\n",
      "[1124/1762] D loss: 0.0959\n",
      "[1204/1762] D loss: 0.1169\n",
      "[1284/1762] D loss: 0.0379\n",
      "[1364/1762] D loss: 0.0811\n",
      "[1444/1762] D loss: 0.0485\n",
      "[1524/1762] D loss: 0.0464\n",
      "[1604/1762] D loss: 0.0331\n",
      "[1684/1762] D loss: 0.0279\n",
      "[1762/1762] D loss: 0.1997\n",
      "train error: \n",
      " D loss: 0.291542, D accuracy: 99.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.296581, D accuracy: 99.2% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0298\n",
      "[84/1762] D loss: 0.3494\n",
      "[164/1762] D loss: 0.0370\n",
      "[244/1762] D loss: 0.0354\n",
      "[324/1762] D loss: 0.0437\n",
      "[404/1762] D loss: 0.0156\n",
      "[484/1762] D loss: 0.0287\n",
      "[564/1762] D loss: 0.0228\n",
      "[644/1762] D loss: 0.0486\n",
      "[724/1762] D loss: 0.0200\n",
      "[804/1762] D loss: 0.0924\n",
      "[884/1762] D loss: 0.0065\n",
      "[964/1762] D loss: 0.0086\n",
      "[1044/1762] D loss: 0.0440\n",
      "[1124/1762] D loss: 0.0219\n",
      "[1204/1762] D loss: 0.0345\n",
      "[1284/1762] D loss: 0.0223\n",
      "[1364/1762] D loss: 0.0316\n",
      "[1444/1762] D loss: 0.0088\n",
      "[1524/1762] D loss: 0.1633\n",
      "[1604/1762] D loss: 0.0492\n",
      "[1684/1762] D loss: 0.0407\n",
      "[1762/1762] D loss: 0.0067\n",
      "train error: \n",
      " D loss: 0.274376, D accuracy: 99.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.291973, D accuracy: 98.8% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0242\n",
      "[84/1762] D loss: 0.0134\n",
      "[164/1762] D loss: 0.0212\n",
      "[244/1762] D loss: 0.0150\n",
      "[324/1762] D loss: 0.0290\n",
      "[404/1762] D loss: 0.0284\n",
      "[484/1762] D loss: 0.0455\n",
      "[564/1762] D loss: 0.2521\n",
      "[644/1762] D loss: 0.0183\n",
      "[724/1762] D loss: 0.0272\n",
      "[804/1762] D loss: 0.0590\n",
      "[884/1762] D loss: 0.0260\n",
      "[964/1762] D loss: 0.0315\n",
      "[1044/1762] D loss: 0.0225\n",
      "[1124/1762] D loss: 0.0207\n",
      "[1204/1762] D loss: 0.0773\n",
      "[1284/1762] D loss: 0.0638\n",
      "[1364/1762] D loss: 0.0080\n",
      "[1444/1762] D loss: 0.1056\n",
      "[1524/1762] D loss: 0.0399\n",
      "[1604/1762] D loss: 0.0138\n",
      "[1684/1762] D loss: 0.0079\n",
      "[1762/1762] D loss: 0.1014\n",
      "train error: \n",
      " D loss: 0.292564, D accuracy: 99.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.318957, D accuracy: 98.3% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0171\n",
      "[84/1762] D loss: 0.0115\n",
      "[164/1762] D loss: 0.0112\n",
      "[244/1762] D loss: 0.0223\n",
      "[324/1762] D loss: 0.0331\n",
      "[404/1762] D loss: 0.0262\n",
      "[484/1762] D loss: 0.0081\n",
      "[564/1762] D loss: 0.0515\n",
      "[644/1762] D loss: 0.0076\n",
      "[724/1762] D loss: 0.0134\n",
      "[804/1762] D loss: 0.0244\n",
      "[884/1762] D loss: 0.0079\n",
      "[964/1762] D loss: 0.0214\n",
      "[1044/1762] D loss: 0.0467\n",
      "[1124/1762] D loss: 0.0360\n",
      "[1204/1762] D loss: 0.0237\n",
      "[1284/1762] D loss: 0.0306\n",
      "[1364/1762] D loss: 0.2018\n",
      "[1444/1762] D loss: 0.2118\n",
      "[1524/1762] D loss: 0.0319\n",
      "[1604/1762] D loss: 0.0070\n",
      "[1684/1762] D loss: 0.0495\n",
      "[1762/1762] D loss: 0.0329\n",
      "train error: \n",
      " D loss: 0.284346, D accuracy: 99.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.289193, D accuracy: 99.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0084\n",
      "[84/1762] D loss: 0.0739\n",
      "[164/1762] D loss: 0.0279\n",
      "[244/1762] D loss: 0.0080\n",
      "[324/1762] D loss: 0.0182\n",
      "[404/1762] D loss: 0.1130\n",
      "[484/1762] D loss: 0.0873\n",
      "[564/1762] D loss: 0.0124\n",
      "[644/1762] D loss: 0.0179\n",
      "[724/1762] D loss: 0.0246\n",
      "[804/1762] D loss: 0.0187\n",
      "[884/1762] D loss: 0.0107\n",
      "[964/1762] D loss: 0.0602\n",
      "[1044/1762] D loss: 0.0504\n",
      "[1124/1762] D loss: 0.0169\n",
      "[1204/1762] D loss: 0.1009\n",
      "[1284/1762] D loss: 0.0181\n",
      "[1364/1762] D loss: 0.0039\n",
      "[1444/1762] D loss: 0.0279\n",
      "[1524/1762] D loss: 0.0755\n",
      "[1604/1762] D loss: 0.0174\n",
      "[1684/1762] D loss: 0.0722\n",
      "[1762/1762] D loss: 0.0093\n",
      "train error: \n",
      " D loss: 0.324986, D accuracy: 99.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.345640, D accuracy: 98.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1120\n",
      "[84/1762] D loss: 0.0337\n",
      "[164/1762] D loss: 0.1509\n",
      "[244/1762] D loss: 0.0535\n",
      "[324/1762] D loss: 0.0410\n",
      "[404/1762] D loss: 0.0124\n",
      "[484/1762] D loss: 0.0321\n",
      "[564/1762] D loss: 0.0154\n",
      "[644/1762] D loss: 0.0388\n",
      "[724/1762] D loss: 0.0414\n",
      "[804/1762] D loss: 0.0062\n",
      "[884/1762] D loss: 0.0079\n",
      "[964/1762] D loss: 0.4792\n",
      "[1044/1762] D loss: 0.1392\n",
      "[1124/1762] D loss: 0.0969\n",
      "[1204/1762] D loss: 0.0227\n",
      "[1284/1762] D loss: 0.0227\n",
      "[1364/1762] D loss: 0.0195\n",
      "[1444/1762] D loss: 0.0668\n",
      "[1524/1762] D loss: 0.1031\n",
      "[1604/1762] D loss: 0.0099\n",
      "[1684/1762] D loss: 0.0058\n",
      "[1762/1762] D loss: 0.1446\n",
      "train error: \n",
      " D loss: 0.553232, D accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.590411, D accuracy: 86.9% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0379\n",
      "[84/1762] D loss: 0.0114\n",
      "[164/1762] D loss: 0.0068\n",
      "[244/1762] D loss: 0.0300\n",
      "[324/1762] D loss: 0.0188\n",
      "[404/1762] D loss: 0.0056\n",
      "[484/1762] D loss: 0.0234\n",
      "[564/1762] D loss: 0.0213\n",
      "[644/1762] D loss: 0.0188\n",
      "[724/1762] D loss: 0.2544\n",
      "[804/1762] D loss: 0.0117\n",
      "[884/1762] D loss: 0.0153\n",
      "[964/1762] D loss: 0.0081\n",
      "[1044/1762] D loss: 0.0906\n",
      "[1124/1762] D loss: 0.0755\n",
      "[1204/1762] D loss: 0.0467\n",
      "[1284/1762] D loss: 0.0055\n",
      "[1364/1762] D loss: 0.0098\n",
      "[1444/1762] D loss: 0.0907\n",
      "[1524/1762] D loss: 0.0176\n",
      "[1604/1762] D loss: 0.0176\n",
      "[1684/1762] D loss: 0.0050\n",
      "[1762/1762] D loss: 0.0110\n",
      "train error: \n",
      " D loss: 0.320369, D accuracy: 99.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.335654, D accuracy: 99.1% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0142\n",
      "[84/1762] D loss: 0.0156\n",
      "[164/1762] D loss: 0.0070\n",
      "[244/1762] D loss: 0.0252\n",
      "[324/1762] D loss: 0.0218\n",
      "[404/1762] D loss: 0.0118\n",
      "[484/1762] D loss: 0.0550\n",
      "[564/1762] D loss: 0.0321\n",
      "[644/1762] D loss: 0.1664\n",
      "[724/1762] D loss: 0.0055\n",
      "[804/1762] D loss: 0.0230\n",
      "[884/1762] D loss: 0.1144\n",
      "[964/1762] D loss: 0.0268\n",
      "[1044/1762] D loss: 0.0176\n",
      "[1124/1762] D loss: 0.0042\n",
      "[1204/1762] D loss: 0.0450\n",
      "[1284/1762] D loss: 0.0518\n",
      "[1364/1762] D loss: 0.0087\n",
      "[1444/1762] D loss: 0.0032\n",
      "[1524/1762] D loss: 0.0127\n",
      "[1604/1762] D loss: 0.0040\n",
      "[1684/1762] D loss: 0.0180\n",
      "[1762/1762] D loss: 0.0116\n",
      "train error: \n",
      " D loss: 0.305386, D accuracy: 99.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.329081, D accuracy: 98.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0054\n",
      "[84/1762] D loss: 0.0082\n",
      "[164/1762] D loss: 0.0130\n",
      "[244/1762] D loss: 0.0087\n",
      "[324/1762] D loss: 0.0069\n",
      "[404/1762] D loss: 0.0273\n",
      "[484/1762] D loss: 0.0172\n",
      "[564/1762] D loss: 0.0034\n",
      "[644/1762] D loss: 0.0104\n",
      "[724/1762] D loss: 0.0177\n",
      "[804/1762] D loss: 0.0075\n",
      "[884/1762] D loss: 0.0766\n",
      "[964/1762] D loss: 0.0100\n",
      "[1044/1762] D loss: 0.0075\n",
      "[1124/1762] D loss: 0.0056\n",
      "[1204/1762] D loss: 0.0372\n",
      "[1284/1762] D loss: 0.0292\n",
      "[1364/1762] D loss: 0.0166\n",
      "[1444/1762] D loss: 0.0063\n",
      "[1524/1762] D loss: 0.0031\n",
      "[1604/1762] D loss: 0.0196\n",
      "[1684/1762] D loss: 0.0144\n",
      "[1762/1762] D loss: 0.0073\n",
      "train error: \n",
      " D loss: 0.399483, D accuracy: 98.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.426385, D accuracy: 97.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2659\n",
      "[84/1762] D loss: 0.0369\n",
      "[164/1762] D loss: 0.0081\n",
      "[244/1762] D loss: 0.0063\n",
      "[324/1762] D loss: 0.0230\n",
      "[404/1762] D loss: 0.0836\n",
      "[484/1762] D loss: 0.0374\n",
      "[564/1762] D loss: 0.0039\n",
      "[644/1762] D loss: 0.0422\n",
      "[724/1762] D loss: 0.0179\n",
      "[804/1762] D loss: 0.0097\n",
      "[884/1762] D loss: 0.0197\n",
      "[964/1762] D loss: 0.0193\n",
      "[1044/1762] D loss: 0.0180\n",
      "[1124/1762] D loss: 0.0040\n",
      "[1204/1762] D loss: 0.0300\n",
      "[1284/1762] D loss: 0.0048\n",
      "[1364/1762] D loss: 0.0361\n",
      "[1444/1762] D loss: 0.0471\n",
      "[1524/1762] D loss: 0.0132\n",
      "[1604/1762] D loss: 0.0221\n",
      "[1684/1762] D loss: 0.0248\n",
      "[1762/1762] D loss: 0.0059\n",
      "train error: \n",
      " D loss: 0.299000, D accuracy: 99.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.312030, D accuracy: 98.6% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4086\n",
      "[84/1762] D loss: 1.4410\n",
      "[164/1762] D loss: 1.4026\n",
      "[244/1762] D loss: 1.3974\n",
      "[324/1762] D loss: 1.4259\n",
      "[404/1762] D loss: 1.4303\n",
      "[484/1762] D loss: 1.4151\n",
      "[564/1762] D loss: 1.4203\n",
      "[644/1762] D loss: 1.4048\n",
      "[724/1762] D loss: 1.4041\n",
      "[804/1762] D loss: 1.4051\n",
      "[884/1762] D loss: 1.3841\n",
      "[964/1762] D loss: 1.4212\n",
      "[1044/1762] D loss: 1.4018\n",
      "[1124/1762] D loss: 1.3905\n",
      "[1204/1762] D loss: 1.3834\n",
      "[1284/1762] D loss: 1.3947\n",
      "[1364/1762] D loss: 1.4000\n",
      "[1444/1762] D loss: 1.3967\n",
      "[1524/1762] D loss: 1.3876\n",
      "[1604/1762] D loss: 1.3970\n",
      "[1684/1762] D loss: 1.3891\n",
      "[1762/1762] D loss: 1.3973\n",
      "train error: \n",
      " D loss: 1.390615, D accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389801, D accuracy: 53.1% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883\n",
      "[84/1762] D loss: 1.3922\n",
      "[164/1762] D loss: 1.3927\n",
      "[244/1762] D loss: 1.3963\n",
      "[324/1762] D loss: 1.3866\n",
      "[404/1762] D loss: 1.3935\n",
      "[484/1762] D loss: 1.3887\n",
      "[564/1762] D loss: 1.3763\n",
      "[644/1762] D loss: 1.3951\n",
      "[724/1762] D loss: 1.3972\n",
      "[804/1762] D loss: 1.3984\n",
      "[884/1762] D loss: 1.4037\n",
      "[964/1762] D loss: 1.3946\n",
      "[1044/1762] D loss: 1.3718\n",
      "[1124/1762] D loss: 1.3977\n",
      "[1204/1762] D loss: 1.3802\n",
      "[1284/1762] D loss: 1.4130\n",
      "[1364/1762] D loss: 1.3762\n",
      "[1444/1762] D loss: 1.4003\n",
      "[1524/1762] D loss: 1.4083\n",
      "[1604/1762] D loss: 1.3843\n",
      "[1684/1762] D loss: 1.3790\n",
      "[1762/1762] D loss: 1.3577\n",
      "train error: \n",
      " D loss: 1.388774, D accuracy: 51.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387818, D accuracy: 52.4% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4067\n",
      "[84/1762] D loss: 1.3720\n",
      "[164/1762] D loss: 1.3792\n",
      "[244/1762] D loss: 1.4047\n",
      "[324/1762] D loss: 1.3761\n",
      "[404/1762] D loss: 1.4055\n",
      "[484/1762] D loss: 1.3715\n",
      "[564/1762] D loss: 1.3859\n",
      "[644/1762] D loss: 1.4034\n",
      "[724/1762] D loss: 1.4194\n",
      "[804/1762] D loss: 1.4115\n",
      "[884/1762] D loss: 1.3787\n",
      "[964/1762] D loss: 1.3767\n",
      "[1044/1762] D loss: 1.3799\n",
      "[1124/1762] D loss: 1.3903\n",
      "[1204/1762] D loss: 1.4003\n",
      "[1284/1762] D loss: 1.3867\n",
      "[1364/1762] D loss: 1.4024\n",
      "[1444/1762] D loss: 1.3819\n",
      "[1524/1762] D loss: 1.4055\n",
      "[1604/1762] D loss: 1.3718\n",
      "[1684/1762] D loss: 1.3784\n",
      "[1762/1762] D loss: 1.4060\n",
      "train error: \n",
      " D loss: 1.387158, D accuracy: 51.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384311, D accuracy: 51.6% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3907\n",
      "[84/1762] D loss: 1.3781\n",
      "[164/1762] D loss: 1.3848\n",
      "[244/1762] D loss: 1.3967\n",
      "[324/1762] D loss: 1.3751\n",
      "[404/1762] D loss: 1.3860\n",
      "[484/1762] D loss: 1.3963\n",
      "[564/1762] D loss: 1.3873\n",
      "[644/1762] D loss: 1.3760\n",
      "[724/1762] D loss: 1.3940\n",
      "[804/1762] D loss: 1.3898\n",
      "[884/1762] D loss: 1.3864\n",
      "[964/1762] D loss: 1.3970\n",
      "[1044/1762] D loss: 1.3817\n",
      "[1124/1762] D loss: 1.3891\n",
      "[1204/1762] D loss: 1.3805\n",
      "[1284/1762] D loss: 1.3761\n",
      "[1364/1762] D loss: 1.3971\n",
      "[1444/1762] D loss: 1.3836\n",
      "[1524/1762] D loss: 1.3844\n",
      "[1604/1762] D loss: 1.3971\n",
      "[1684/1762] D loss: 1.3742\n",
      "[1762/1762] D loss: 1.4047\n",
      "train error: \n",
      " D loss: 1.384524, D accuracy: 52.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386227, D accuracy: 51.2% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862\n",
      "[84/1762] D loss: 1.3955\n",
      "[164/1762] D loss: 1.3755\n",
      "[244/1762] D loss: 1.4016\n",
      "[324/1762] D loss: 1.3978\n",
      "[404/1762] D loss: 1.4085\n",
      "[484/1762] D loss: 1.3928\n",
      "[564/1762] D loss: 1.4007\n",
      "[644/1762] D loss: 1.4020\n",
      "[724/1762] D loss: 1.3725\n",
      "[804/1762] D loss: 1.3812\n",
      "[884/1762] D loss: 1.4031\n",
      "[964/1762] D loss: 1.3934\n",
      "[1044/1762] D loss: 1.4030\n",
      "[1124/1762] D loss: 1.3700\n",
      "[1204/1762] D loss: 1.3759\n",
      "[1284/1762] D loss: 1.3844\n",
      "[1364/1762] D loss: 1.3663\n",
      "[1444/1762] D loss: 1.3976\n",
      "[1524/1762] D loss: 1.3948\n",
      "[1604/1762] D loss: 1.4029\n",
      "[1684/1762] D loss: 1.3579\n",
      "[1762/1762] D loss: 1.4150\n",
      "train error: \n",
      " D loss: 1.383571, D accuracy: 52.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385398, D accuracy: 51.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3831\n",
      "[84/1762] D loss: 1.3573\n",
      "[164/1762] D loss: 1.3765\n",
      "[244/1762] D loss: 1.3864\n",
      "[324/1762] D loss: 1.3853\n",
      "[404/1762] D loss: 1.3716\n",
      "[484/1762] D loss: 1.3872\n",
      "[564/1762] D loss: 1.3794\n",
      "[644/1762] D loss: 1.3831\n",
      "[724/1762] D loss: 1.3766\n",
      "[804/1762] D loss: 1.3721\n",
      "[884/1762] D loss: 1.4016\n",
      "[964/1762] D loss: 1.3828\n",
      "[1044/1762] D loss: 1.3916\n",
      "[1124/1762] D loss: 1.3778\n",
      "[1204/1762] D loss: 1.3861\n",
      "[1284/1762] D loss: 1.3963\n",
      "[1364/1762] D loss: 1.3728\n",
      "[1444/1762] D loss: 1.3854\n",
      "[1524/1762] D loss: 1.3875\n",
      "[1604/1762] D loss: 1.3796\n",
      "[1684/1762] D loss: 1.3749\n",
      "[1762/1762] D loss: 1.3895\n",
      "train error: \n",
      " D loss: 1.382777, D accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385268, D accuracy: 51.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868\n",
      "[84/1762] D loss: 1.3814\n",
      "[164/1762] D loss: 1.3734\n",
      "[244/1762] D loss: 1.3874\n",
      "[324/1762] D loss: 1.3802\n",
      "[404/1762] D loss: 1.4066\n",
      "[484/1762] D loss: 1.4081\n",
      "[564/1762] D loss: 1.3711\n",
      "[644/1762] D loss: 1.3733\n",
      "[724/1762] D loss: 1.3803\n",
      "[804/1762] D loss: 1.3960\n",
      "[884/1762] D loss: 1.3912\n",
      "[964/1762] D loss: 1.3827\n",
      "[1044/1762] D loss: 1.3966\n",
      "[1124/1762] D loss: 1.3795\n",
      "[1204/1762] D loss: 1.3763\n",
      "[1284/1762] D loss: 1.3748\n",
      "[1364/1762] D loss: 1.3909\n",
      "[1444/1762] D loss: 1.3826\n",
      "[1524/1762] D loss: 1.3884\n",
      "[1604/1762] D loss: 1.3775\n",
      "[1684/1762] D loss: 1.3722\n",
      "[1762/1762] D loss: 1.3699\n",
      "train error: \n",
      " D loss: 1.382121, D accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380701, D accuracy: 50.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3830\n",
      "[84/1762] D loss: 1.3724\n",
      "[164/1762] D loss: 1.3668\n",
      "[244/1762] D loss: 1.4086\n",
      "[324/1762] D loss: 1.3998\n",
      "[404/1762] D loss: 1.3956\n",
      "[484/1762] D loss: 1.3924\n",
      "[564/1762] D loss: 1.3917\n",
      "[644/1762] D loss: 1.3726\n",
      "[724/1762] D loss: 1.3968\n",
      "[804/1762] D loss: 1.3835\n",
      "[884/1762] D loss: 1.3543\n",
      "[964/1762] D loss: 1.3894\n",
      "[1044/1762] D loss: 1.3831\n",
      "[1124/1762] D loss: 1.3642\n",
      "[1204/1762] D loss: 1.3620\n",
      "[1284/1762] D loss: 1.3932\n",
      "[1364/1762] D loss: 1.3914\n",
      "[1444/1762] D loss: 1.3938\n",
      "[1524/1762] D loss: 1.3912\n",
      "[1604/1762] D loss: 1.3692\n",
      "[1684/1762] D loss: 1.3859\n",
      "[1762/1762] D loss: 1.3613\n",
      "train error: \n",
      " D loss: 1.381345, D accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381349, D accuracy: 52.4% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3833\n",
      "[84/1762] D loss: 1.3891\n",
      "[164/1762] D loss: 1.3858\n",
      "[244/1762] D loss: 1.3760\n",
      "[324/1762] D loss: 1.3984\n",
      "[404/1762] D loss: 1.3972\n",
      "[484/1762] D loss: 1.3805\n",
      "[564/1762] D loss: 1.3764\n",
      "[644/1762] D loss: 1.3894\n",
      "[724/1762] D loss: 1.3599\n",
      "[804/1762] D loss: 1.3688\n",
      "[884/1762] D loss: 1.3825\n",
      "[964/1762] D loss: 1.3838\n",
      "[1044/1762] D loss: 1.4007\n",
      "[1124/1762] D loss: 1.4034\n",
      "[1204/1762] D loss: 1.3829\n",
      "[1284/1762] D loss: 1.3940\n",
      "[1364/1762] D loss: 1.4004\n",
      "[1444/1762] D loss: 1.3814\n",
      "[1524/1762] D loss: 1.3960\n",
      "[1604/1762] D loss: 1.3924\n",
      "[1684/1762] D loss: 1.3692\n",
      "[1762/1762] D loss: 1.3601\n",
      "train error: \n",
      " D loss: 1.378423, D accuracy: 53.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381130, D accuracy: 52.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924\n",
      "[84/1762] D loss: 1.3906\n",
      "[164/1762] D loss: 1.3988\n",
      "[244/1762] D loss: 1.3857\n",
      "[324/1762] D loss: 1.3897\n",
      "[404/1762] D loss: 1.3473\n",
      "[484/1762] D loss: 1.3818\n",
      "[564/1762] D loss: 1.3867\n",
      "[644/1762] D loss: 1.3619\n",
      "[724/1762] D loss: 1.3788\n",
      "[804/1762] D loss: 1.3902\n",
      "[884/1762] D loss: 1.3906\n",
      "[964/1762] D loss: 1.3719\n",
      "[1044/1762] D loss: 1.3647\n",
      "[1124/1762] D loss: 1.3945\n",
      "[1204/1762] D loss: 1.4073\n",
      "[1284/1762] D loss: 1.3671\n",
      "[1364/1762] D loss: 1.3855\n",
      "[1444/1762] D loss: 1.3599\n",
      "[1524/1762] D loss: 1.3817\n",
      "[1604/1762] D loss: 1.3815\n",
      "[1684/1762] D loss: 1.3713\n",
      "[1762/1762] D loss: 1.3523\n",
      "train error: \n",
      " D loss: 1.377646, D accuracy: 54.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377884, D accuracy: 53.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3539\n",
      "[84/1762] D loss: 1.3880\n",
      "[164/1762] D loss: 1.3830\n",
      "[244/1762] D loss: 1.3783\n",
      "[324/1762] D loss: 1.4015\n",
      "[404/1762] D loss: 1.4055\n",
      "[484/1762] D loss: 1.3769\n",
      "[564/1762] D loss: 1.3571\n",
      "[644/1762] D loss: 1.3671\n",
      "[724/1762] D loss: 1.3959\n",
      "[804/1762] D loss: 1.3764\n",
      "[884/1762] D loss: 1.4110\n",
      "[964/1762] D loss: 1.3953\n",
      "[1044/1762] D loss: 1.3705\n",
      "[1124/1762] D loss: 1.3597\n",
      "[1204/1762] D loss: 1.3760\n",
      "[1284/1762] D loss: 1.3750\n",
      "[1364/1762] D loss: 1.3777\n",
      "[1444/1762] D loss: 1.3765\n",
      "[1524/1762] D loss: 1.3866\n",
      "[1604/1762] D loss: 1.3723\n",
      "[1684/1762] D loss: 1.4057\n",
      "[1762/1762] D loss: 1.4096\n",
      "train error: \n",
      " D loss: 1.377108, D accuracy: 54.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378988, D accuracy: 53.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4069\n",
      "[84/1762] D loss: 1.3888\n",
      "[164/1762] D loss: 1.3633\n",
      "[244/1762] D loss: 1.3812\n",
      "[324/1762] D loss: 1.3952\n",
      "[404/1762] D loss: 1.4115\n",
      "[484/1762] D loss: 1.3713\n",
      "[564/1762] D loss: 1.3687\n",
      "[644/1762] D loss: 1.3842\n",
      "[724/1762] D loss: 1.3942\n",
      "[804/1762] D loss: 1.3791\n",
      "[884/1762] D loss: 1.3794\n",
      "[964/1762] D loss: 1.3625\n",
      "[1044/1762] D loss: 1.3964\n",
      "[1124/1762] D loss: 1.3823\n",
      "[1204/1762] D loss: 1.3753\n",
      "[1284/1762] D loss: 1.3706\n",
      "[1364/1762] D loss: 1.3780\n",
      "[1444/1762] D loss: 1.3694\n",
      "[1524/1762] D loss: 1.3893\n",
      "[1604/1762] D loss: 1.3981\n",
      "[1684/1762] D loss: 1.3724\n",
      "[1762/1762] D loss: 1.3910\n",
      "train error: \n",
      " D loss: 1.376800, D accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377298, D accuracy: 54.1% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3685\n",
      "[84/1762] D loss: 1.3824\n",
      "[164/1762] D loss: 1.3957\n",
      "[244/1762] D loss: 1.3769\n",
      "[324/1762] D loss: 1.3880\n",
      "[404/1762] D loss: 1.3847\n",
      "[484/1762] D loss: 1.3717\n",
      "[564/1762] D loss: 1.3489\n",
      "[644/1762] D loss: 1.3685\n",
      "[724/1762] D loss: 1.3620\n",
      "[804/1762] D loss: 1.3889\n",
      "[884/1762] D loss: 1.3816\n",
      "[964/1762] D loss: 1.3883\n",
      "[1044/1762] D loss: 1.3817\n",
      "[1124/1762] D loss: 1.3443\n",
      "[1204/1762] D loss: 1.3600\n",
      "[1284/1762] D loss: 1.3808\n",
      "[1364/1762] D loss: 1.3821\n",
      "[1444/1762] D loss: 1.3792\n",
      "[1524/1762] D loss: 1.3828\n",
      "[1604/1762] D loss: 1.3522\n",
      "[1684/1762] D loss: 1.3624\n",
      "[1762/1762] D loss: 1.3703\n",
      "train error: \n",
      " D loss: 1.374836, D accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374578, D accuracy: 56.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3753\n",
      "[84/1762] D loss: 1.3292\n",
      "[164/1762] D loss: 1.3846\n",
      "[244/1762] D loss: 1.3723\n",
      "[324/1762] D loss: 1.3739\n",
      "[404/1762] D loss: 1.3530\n",
      "[484/1762] D loss: 1.3473\n",
      "[564/1762] D loss: 1.3808\n",
      "[644/1762] D loss: 1.3992\n",
      "[724/1762] D loss: 1.3679\n",
      "[804/1762] D loss: 1.3939\n",
      "[884/1762] D loss: 1.3744\n",
      "[964/1762] D loss: 1.3840\n",
      "[1044/1762] D loss: 1.3639\n",
      "[1124/1762] D loss: 1.3472\n",
      "[1204/1762] D loss: 1.3413\n",
      "[1284/1762] D loss: 1.3952\n",
      "[1364/1762] D loss: 1.3909\n",
      "[1444/1762] D loss: 1.3697\n",
      "[1524/1762] D loss: 1.3838\n",
      "[1604/1762] D loss: 1.3559\n",
      "[1684/1762] D loss: 1.3865\n",
      "[1762/1762] D loss: 1.4347\n",
      "train error: \n",
      " D loss: 1.374585, D accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374078, D accuracy: 56.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3741\n",
      "[84/1762] D loss: 1.3760\n",
      "[164/1762] D loss: 1.3986\n",
      "[244/1762] D loss: 1.3964\n",
      "[324/1762] D loss: 1.3884\n",
      "[404/1762] D loss: 1.3629\n",
      "[484/1762] D loss: 1.3790\n",
      "[564/1762] D loss: 1.3962\n",
      "[644/1762] D loss: 1.3639\n",
      "[724/1762] D loss: 1.3801\n",
      "[804/1762] D loss: 1.3667\n",
      "[884/1762] D loss: 1.3721\n",
      "[964/1762] D loss: 1.3774\n",
      "[1044/1762] D loss: 1.3799\n",
      "[1124/1762] D loss: 1.3850\n",
      "[1204/1762] D loss: 1.3587\n",
      "[1284/1762] D loss: 1.3839\n",
      "[1364/1762] D loss: 1.3986\n",
      "[1444/1762] D loss: 1.3642\n",
      "[1524/1762] D loss: 1.3945\n",
      "[1604/1762] D loss: 1.3830\n",
      "[1684/1762] D loss: 1.3714\n",
      "[1762/1762] D loss: 1.3923\n",
      "train error: \n",
      " D loss: 1.373866, D accuracy: 55.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375228, D accuracy: 56.2% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3888\n",
      "[84/1762] D loss: 1.3955\n",
      "[164/1762] D loss: 1.3869\n",
      "[244/1762] D loss: 1.3878\n",
      "[324/1762] D loss: 1.3798\n",
      "[404/1762] D loss: 1.3693\n",
      "[484/1762] D loss: 1.3933\n",
      "[564/1762] D loss: 1.3810\n",
      "[644/1762] D loss: 1.3887\n",
      "[724/1762] D loss: 1.3716\n",
      "[804/1762] D loss: 1.3543\n",
      "[884/1762] D loss: 1.4056\n",
      "[964/1762] D loss: 1.3723\n",
      "[1044/1762] D loss: 1.3502\n",
      "[1124/1762] D loss: 1.3528\n",
      "[1204/1762] D loss: 1.3834\n",
      "[1284/1762] D loss: 1.3685\n",
      "[1364/1762] D loss: 1.3719\n",
      "[1444/1762] D loss: 1.3510\n",
      "[1524/1762] D loss: 1.3889\n",
      "[1604/1762] D loss: 1.3787\n",
      "[1684/1762] D loss: 1.3742\n",
      "[1762/1762] D loss: 1.3717\n",
      "train error: \n",
      " D loss: 1.373349, D accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371716, D accuracy: 56.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3636\n",
      "[84/1762] D loss: 1.3803\n",
      "[164/1762] D loss: 1.3843\n",
      "[244/1762] D loss: 1.3595\n",
      "[324/1762] D loss: 1.3888\n",
      "[404/1762] D loss: 1.3321\n",
      "[484/1762] D loss: 1.3704\n",
      "[564/1762] D loss: 1.3722\n",
      "[644/1762] D loss: 1.3967\n",
      "[724/1762] D loss: 1.3834\n",
      "[804/1762] D loss: 1.3727\n",
      "[884/1762] D loss: 1.3823\n",
      "[964/1762] D loss: 1.4151\n",
      "[1044/1762] D loss: 1.3805\n",
      "[1124/1762] D loss: 1.3272\n",
      "[1204/1762] D loss: 1.3703\n",
      "[1284/1762] D loss: 1.3661\n",
      "[1364/1762] D loss: 1.3501\n",
      "[1444/1762] D loss: 1.3775\n",
      "[1524/1762] D loss: 1.3659\n",
      "[1604/1762] D loss: 1.3498\n",
      "[1684/1762] D loss: 1.3842\n",
      "[1762/1762] D loss: 1.3995\n",
      "train error: \n",
      " D loss: 1.372297, D accuracy: 55.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372496, D accuracy: 56.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3767\n",
      "[84/1762] D loss: 1.3657\n",
      "[164/1762] D loss: 1.3801\n",
      "[244/1762] D loss: 1.3758\n",
      "[324/1762] D loss: 1.3574\n",
      "[404/1762] D loss: 1.3816\n",
      "[484/1762] D loss: 1.3797\n",
      "[564/1762] D loss: 1.3740\n",
      "[644/1762] D loss: 1.3827\n",
      "[724/1762] D loss: 1.3536\n",
      "[804/1762] D loss: 1.3733\n",
      "[884/1762] D loss: 1.3725\n",
      "[964/1762] D loss: 1.3752\n",
      "[1044/1762] D loss: 1.3698\n",
      "[1124/1762] D loss: 1.3782\n",
      "[1204/1762] D loss: 1.4144\n",
      "[1284/1762] D loss: 1.3579\n",
      "[1364/1762] D loss: 1.3553\n",
      "[1444/1762] D loss: 1.3564\n",
      "[1524/1762] D loss: 1.3370\n",
      "[1604/1762] D loss: 1.3877\n",
      "[1684/1762] D loss: 1.3798\n",
      "[1762/1762] D loss: 1.3831\n",
      "train error: \n",
      " D loss: 1.371258, D accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369498, D accuracy: 56.7% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3618\n",
      "[84/1762] D loss: 1.3799\n",
      "[164/1762] D loss: 1.3855\n",
      "[244/1762] D loss: 1.3714\n",
      "[324/1762] D loss: 1.3850\n",
      "[404/1762] D loss: 1.3730\n",
      "[484/1762] D loss: 1.3752\n",
      "[564/1762] D loss: 1.3870\n",
      "[644/1762] D loss: 1.3449\n",
      "[724/1762] D loss: 1.3613\n",
      "[804/1762] D loss: 1.3513\n",
      "[884/1762] D loss: 1.4073\n",
      "[964/1762] D loss: 1.3843\n",
      "[1044/1762] D loss: 1.3542\n",
      "[1124/1762] D loss: 1.3253\n",
      "[1204/1762] D loss: 1.4016\n",
      "[1284/1762] D loss: 1.3269\n",
      "[1364/1762] D loss: 1.3698\n",
      "[1444/1762] D loss: 1.3809\n",
      "[1524/1762] D loss: 1.3845\n",
      "[1604/1762] D loss: 1.3937\n",
      "[1684/1762] D loss: 1.3687\n",
      "[1762/1762] D loss: 1.3537\n",
      "train error: \n",
      " D loss: 1.369277, D accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369040, D accuracy: 57.6% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3668\n",
      "[84/1762] D loss: 1.3879\n",
      "[164/1762] D loss: 1.3661\n",
      "[244/1762] D loss: 1.3646\n",
      "[324/1762] D loss: 1.3720\n",
      "[404/1762] D loss: 1.3504\n",
      "[484/1762] D loss: 1.3732\n",
      "[564/1762] D loss: 1.3754\n",
      "[644/1762] D loss: 1.3423\n",
      "[724/1762] D loss: 1.3462\n",
      "[804/1762] D loss: 1.3852\n",
      "[884/1762] D loss: 1.3708\n",
      "[964/1762] D loss: 1.3784\n",
      "[1044/1762] D loss: 1.3519\n",
      "[1124/1762] D loss: 1.3772\n",
      "[1204/1762] D loss: 1.3863\n",
      "[1284/1762] D loss: 1.3532\n",
      "[1364/1762] D loss: 1.3634\n",
      "[1444/1762] D loss: 1.3756\n",
      "[1524/1762] D loss: 1.3366\n",
      "[1604/1762] D loss: 1.3962\n",
      "[1684/1762] D loss: 1.3648\n",
      "[1762/1762] D loss: 1.3465\n",
      "train error: \n",
      " D loss: 1.367942, D accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365613, D accuracy: 57.3% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3773\n",
      "[84/1762] D loss: 1.4027\n",
      "[164/1762] D loss: 1.3806\n",
      "[244/1762] D loss: 1.3633\n",
      "[324/1762] D loss: 1.3686\n",
      "[404/1762] D loss: 1.3693\n",
      "[484/1762] D loss: 1.3740\n",
      "[564/1762] D loss: 1.3933\n",
      "[644/1762] D loss: 1.3732\n",
      "[724/1762] D loss: 1.3542\n",
      "[804/1762] D loss: 1.3591\n",
      "[884/1762] D loss: 1.3685\n",
      "[964/1762] D loss: 1.3361\n",
      "[1044/1762] D loss: 1.3435\n",
      "[1124/1762] D loss: 1.3770\n",
      "[1204/1762] D loss: 1.3927\n",
      "[1284/1762] D loss: 1.3726\n",
      "[1364/1762] D loss: 1.3802\n",
      "[1444/1762] D loss: 1.3825\n",
      "[1524/1762] D loss: 1.3728\n",
      "[1604/1762] D loss: 1.3787\n",
      "[1684/1762] D loss: 1.3889\n",
      "[1762/1762] D loss: 1.3912\n",
      "train error: \n",
      " D loss: 1.367351, D accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366039, D accuracy: 57.3% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3850\n",
      "[84/1762] D loss: 1.3755\n",
      "[164/1762] D loss: 1.3663\n",
      "[244/1762] D loss: 1.3577\n",
      "[324/1762] D loss: 1.3630\n",
      "[404/1762] D loss: 1.3680\n",
      "[484/1762] D loss: 1.3585\n",
      "[564/1762] D loss: 1.3705\n",
      "[644/1762] D loss: 1.3499\n",
      "[724/1762] D loss: 1.3871\n",
      "[804/1762] D loss: 1.3523\n",
      "[884/1762] D loss: 1.3748\n",
      "[964/1762] D loss: 1.3779\n",
      "[1044/1762] D loss: 1.3712\n",
      "[1124/1762] D loss: 1.3552\n",
      "[1204/1762] D loss: 1.3868\n",
      "[1284/1762] D loss: 1.3703\n",
      "[1364/1762] D loss: 1.4128\n",
      "[1444/1762] D loss: 1.3608\n",
      "[1524/1762] D loss: 1.3700\n",
      "[1604/1762] D loss: 1.3705\n",
      "[1684/1762] D loss: 1.3803\n",
      "[1762/1762] D loss: 1.3933\n",
      "train error: \n",
      " D loss: 1.362959, D accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363193, D accuracy: 58.4% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3828\n",
      "[84/1762] D loss: 1.4005\n",
      "[164/1762] D loss: 1.3667\n",
      "[244/1762] D loss: 1.3514\n",
      "[324/1762] D loss: 1.4054\n",
      "[404/1762] D loss: 1.3423\n",
      "[484/1762] D loss: 1.3769\n",
      "[564/1762] D loss: 1.3418\n",
      "[644/1762] D loss: 1.3720\n",
      "[724/1762] D loss: 1.3662\n",
      "[804/1762] D loss: 1.3619\n",
      "[884/1762] D loss: 1.3827\n",
      "[964/1762] D loss: 1.3532\n",
      "[1044/1762] D loss: 1.3384\n",
      "[1124/1762] D loss: 1.3913\n",
      "[1204/1762] D loss: 1.3574\n",
      "[1284/1762] D loss: 1.3831\n",
      "[1364/1762] D loss: 1.3279\n",
      "[1444/1762] D loss: 1.3815\n",
      "[1524/1762] D loss: 1.3817\n",
      "[1604/1762] D loss: 1.3589\n",
      "[1684/1762] D loss: 1.3563\n",
      "[1762/1762] D loss: 1.3455\n",
      "train error: \n",
      " D loss: 1.361884, D accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365628, D accuracy: 58.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3974\n",
      "[84/1762] D loss: 1.3848\n",
      "[164/1762] D loss: 1.3467\n",
      "[244/1762] D loss: 1.3566\n",
      "[324/1762] D loss: 1.3597\n",
      "[404/1762] D loss: 1.3857\n",
      "[484/1762] D loss: 1.3194\n",
      "[564/1762] D loss: 1.3727\n",
      "[644/1762] D loss: 1.3675\n",
      "[724/1762] D loss: 1.3674\n",
      "[804/1762] D loss: 1.3699\n",
      "[884/1762] D loss: 1.3492\n",
      "[964/1762] D loss: 1.3467\n",
      "[1044/1762] D loss: 1.3673\n",
      "[1124/1762] D loss: 1.3759\n",
      "[1204/1762] D loss: 1.3433\n",
      "[1284/1762] D loss: 1.3883\n",
      "[1364/1762] D loss: 1.3569\n",
      "[1444/1762] D loss: 1.3790\n",
      "[1524/1762] D loss: 1.3556\n",
      "[1604/1762] D loss: 1.3596\n",
      "[1684/1762] D loss: 1.3573\n",
      "[1762/1762] D loss: 1.3880\n",
      "train error: \n",
      " D loss: 1.361981, D accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363275, D accuracy: 59.8% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3514\n",
      "[84/1762] D loss: 1.3764\n",
      "[164/1762] D loss: 1.3156\n",
      "[244/1762] D loss: 1.3574\n",
      "[324/1762] D loss: 1.3696\n",
      "[404/1762] D loss: 1.3212\n",
      "[484/1762] D loss: 1.3886\n",
      "[564/1762] D loss: 1.3823\n",
      "[644/1762] D loss: 1.3890\n",
      "[724/1762] D loss: 1.3703\n",
      "[804/1762] D loss: 1.3294\n",
      "[884/1762] D loss: 1.3226\n",
      "[964/1762] D loss: 1.3654\n",
      "[1044/1762] D loss: 1.3854\n",
      "[1124/1762] D loss: 1.3565\n",
      "[1204/1762] D loss: 1.3476\n",
      "[1284/1762] D loss: 1.3703\n",
      "[1364/1762] D loss: 1.3750\n",
      "[1444/1762] D loss: 1.3391\n",
      "[1524/1762] D loss: 1.3893\n",
      "[1604/1762] D loss: 1.3486\n",
      "[1684/1762] D loss: 1.3581\n",
      "[1762/1762] D loss: 1.3068\n",
      "train error: \n",
      " D loss: 1.356075, D accuracy: 60.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356485, D accuracy: 59.7% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3842\n",
      "[84/1762] D loss: 1.3394\n",
      "[164/1762] D loss: 1.3866\n",
      "[244/1762] D loss: 1.3868\n",
      "[324/1762] D loss: 1.3825\n",
      "[404/1762] D loss: 1.3773\n",
      "[484/1762] D loss: 1.3039\n",
      "[564/1762] D loss: 1.3612\n",
      "[644/1762] D loss: 1.3522\n",
      "[724/1762] D loss: 1.3870\n",
      "[804/1762] D loss: 1.3368\n",
      "[884/1762] D loss: 1.3906\n",
      "[964/1762] D loss: 1.3400\n",
      "[1044/1762] D loss: 1.3879\n",
      "[1124/1762] D loss: 1.3581\n",
      "[1204/1762] D loss: 1.3555\n",
      "[1284/1762] D loss: 1.3755\n",
      "[1364/1762] D loss: 1.3634\n",
      "[1444/1762] D loss: 1.3568\n",
      "[1524/1762] D loss: 1.3880\n",
      "[1604/1762] D loss: 1.3458\n",
      "[1684/1762] D loss: 1.3638\n",
      "[1762/1762] D loss: 1.3282\n",
      "train error: \n",
      " D loss: 1.356111, D accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358550, D accuracy: 59.4% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3975\n",
      "[84/1762] D loss: 1.3235\n",
      "[164/1762] D loss: 1.3685\n",
      "[244/1762] D loss: 1.3753\n",
      "[324/1762] D loss: 1.3830\n",
      "[404/1762] D loss: 1.3245\n",
      "[484/1762] D loss: 1.3375\n",
      "[564/1762] D loss: 1.3895\n",
      "[644/1762] D loss: 1.3595\n",
      "[724/1762] D loss: 1.3944\n",
      "[804/1762] D loss: 1.3755\n",
      "[884/1762] D loss: 1.3912\n",
      "[964/1762] D loss: 1.3729\n",
      "[1044/1762] D loss: 1.3621\n",
      "[1124/1762] D loss: 1.3759\n",
      "[1204/1762] D loss: 1.3957\n",
      "[1284/1762] D loss: 1.3568\n",
      "[1364/1762] D loss: 1.3577\n",
      "[1444/1762] D loss: 1.3727\n",
      "[1524/1762] D loss: 1.3504\n",
      "[1604/1762] D loss: 1.3272\n",
      "[1684/1762] D loss: 1.3286\n",
      "[1762/1762] D loss: 1.3518\n",
      "train error: \n",
      " D loss: 1.355870, D accuracy: 60.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356946, D accuracy: 58.8% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3342\n",
      "[84/1762] D loss: 1.3662\n",
      "[164/1762] D loss: 1.3639\n",
      "[244/1762] D loss: 1.3695\n",
      "[324/1762] D loss: 1.3412\n",
      "[404/1762] D loss: 1.3826\n",
      "[484/1762] D loss: 1.3408\n",
      "[564/1762] D loss: 1.3814\n",
      "[644/1762] D loss: 1.3425\n",
      "[724/1762] D loss: 1.3447\n",
      "[804/1762] D loss: 1.3456\n",
      "[884/1762] D loss: 1.3749\n",
      "[964/1762] D loss: 1.3540\n",
      "[1044/1762] D loss: 1.3621\n",
      "[1124/1762] D loss: 1.3631\n",
      "[1204/1762] D loss: 1.3601\n",
      "[1284/1762] D loss: 1.3439\n",
      "[1364/1762] D loss: 1.3827\n",
      "[1444/1762] D loss: 1.3418\n",
      "[1524/1762] D loss: 1.3320\n",
      "[1604/1762] D loss: 1.3026\n",
      "[1684/1762] D loss: 1.3406\n",
      "[1762/1762] D loss: 1.3963\n",
      "train error: \n",
      " D loss: 1.353474, D accuracy: 60.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352885, D accuracy: 60.1% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3517\n",
      "[84/1762] D loss: 1.3546\n",
      "[164/1762] D loss: 1.3770\n",
      "[244/1762] D loss: 1.3483\n",
      "[324/1762] D loss: 1.3569\n",
      "[404/1762] D loss: 1.3283\n",
      "[484/1762] D loss: 1.3679\n",
      "[564/1762] D loss: 1.3675\n",
      "[644/1762] D loss: 1.3580\n",
      "[724/1762] D loss: 1.3565\n",
      "[804/1762] D loss: 1.3870\n",
      "[884/1762] D loss: 1.3877\n",
      "[964/1762] D loss: 1.3782\n",
      "[1044/1762] D loss: 1.3680\n",
      "[1124/1762] D loss: 1.3440\n",
      "[1204/1762] D loss: 1.3415\n",
      "[1284/1762] D loss: 1.3294\n",
      "[1364/1762] D loss: 1.3791\n",
      "[1444/1762] D loss: 1.3713\n",
      "[1524/1762] D loss: 1.3479\n",
      "[1604/1762] D loss: 1.3556\n",
      "[1684/1762] D loss: 1.3935\n",
      "[1762/1762] D loss: 1.3787\n",
      "train error: \n",
      " D loss: 1.353311, D accuracy: 60.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353051, D accuracy: 60.1% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3529\n",
      "[84/1762] D loss: 1.3868\n",
      "[164/1762] D loss: 1.3548\n",
      "[244/1762] D loss: 1.3736\n",
      "[324/1762] D loss: 1.3832\n",
      "[404/1762] D loss: 1.3551\n",
      "[484/1762] D loss: 1.3333\n",
      "[564/1762] D loss: 1.3823\n",
      "[644/1762] D loss: 1.3567\n",
      "[724/1762] D loss: 1.3701\n",
      "[804/1762] D loss: 1.3545\n",
      "[884/1762] D loss: 1.3501\n",
      "[964/1762] D loss: 1.3465\n",
      "[1044/1762] D loss: 1.3523\n",
      "[1124/1762] D loss: 1.3480\n",
      "[1204/1762] D loss: 1.3618\n",
      "[1284/1762] D loss: 1.3873\n",
      "[1364/1762] D loss: 1.3099\n",
      "[1444/1762] D loss: 1.3406\n",
      "[1524/1762] D loss: 1.3578\n",
      "[1604/1762] D loss: 1.3603\n",
      "[1684/1762] D loss: 1.3759\n",
      "[1762/1762] D loss: 1.3866\n",
      "train error: \n",
      " D loss: 1.348563, D accuracy: 61.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350094, D accuracy: 60.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3653\n",
      "[84/1762] D loss: 1.3340\n",
      "[164/1762] D loss: 1.3481\n",
      "[244/1762] D loss: 1.3722\n",
      "[324/1762] D loss: 1.3194\n",
      "[404/1762] D loss: 1.3646\n",
      "[484/1762] D loss: 1.3566\n",
      "[564/1762] D loss: 1.3743\n",
      "[644/1762] D loss: 1.3325\n",
      "[724/1762] D loss: 1.3970\n",
      "[804/1762] D loss: 1.3836\n",
      "[884/1762] D loss: 1.3459\n",
      "[964/1762] D loss: 1.3586\n",
      "[1044/1762] D loss: 1.3659\n",
      "[1124/1762] D loss: 1.3475\n",
      "[1204/1762] D loss: 1.3301\n",
      "[1284/1762] D loss: 1.3306\n",
      "[1364/1762] D loss: 1.3755\n",
      "[1444/1762] D loss: 1.3124\n",
      "[1524/1762] D loss: 1.3247\n",
      "[1604/1762] D loss: 1.3641\n",
      "[1684/1762] D loss: 1.3179\n",
      "[1762/1762] D loss: 1.4153\n",
      "train error: \n",
      " D loss: 1.346999, D accuracy: 62.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350982, D accuracy: 61.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3549\n",
      "[84/1762] D loss: 1.3653\n",
      "[164/1762] D loss: 1.3692\n",
      "[244/1762] D loss: 1.3621\n",
      "[324/1762] D loss: 1.3100\n",
      "[404/1762] D loss: 1.3578\n",
      "[484/1762] D loss: 1.3670\n",
      "[564/1762] D loss: 1.3395\n",
      "[644/1762] D loss: 1.3361\n",
      "[724/1762] D loss: 1.3329\n",
      "[804/1762] D loss: 1.3530\n",
      "[884/1762] D loss: 1.3230\n",
      "[964/1762] D loss: 1.3279\n",
      "[1044/1762] D loss: 1.3194\n",
      "[1124/1762] D loss: 1.4077\n",
      "[1204/1762] D loss: 1.3652\n",
      "[1284/1762] D loss: 1.3720\n",
      "[1364/1762] D loss: 1.3217\n",
      "[1444/1762] D loss: 1.3354\n",
      "[1524/1762] D loss: 1.4017\n",
      "[1604/1762] D loss: 1.3044\n",
      "[1684/1762] D loss: 1.3584\n",
      "[1762/1762] D loss: 1.3068\n",
      "train error: \n",
      " D loss: 1.344688, D accuracy: 62.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347372, D accuracy: 61.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3674\n",
      "[84/1762] D loss: 1.3485\n",
      "[164/1762] D loss: 1.3091\n",
      "[244/1762] D loss: 1.3029\n",
      "[324/1762] D loss: 1.3727\n",
      "[404/1762] D loss: 1.2564\n",
      "[484/1762] D loss: 1.3568\n",
      "[564/1762] D loss: 1.3534\n",
      "[644/1762] D loss: 1.3714\n",
      "[724/1762] D loss: 1.3706\n",
      "[804/1762] D loss: 1.3584\n",
      "[884/1762] D loss: 1.3721\n",
      "[964/1762] D loss: 1.3220\n",
      "[1044/1762] D loss: 1.3674\n",
      "[1124/1762] D loss: 1.2909\n",
      "[1204/1762] D loss: 1.3267\n",
      "[1284/1762] D loss: 1.3083\n",
      "[1364/1762] D loss: 1.3354\n",
      "[1444/1762] D loss: 1.3861\n",
      "[1524/1762] D loss: 1.3426\n",
      "[1604/1762] D loss: 1.3567\n",
      "[1684/1762] D loss: 1.3248\n",
      "[1762/1762] D loss: 1.3334\n",
      "train error: \n",
      " D loss: 1.344333, D accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343931, D accuracy: 62.3% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3252\n",
      "[84/1762] D loss: 1.3083\n",
      "[164/1762] D loss: 1.3435\n",
      "[244/1762] D loss: 1.3714\n",
      "[324/1762] D loss: 1.3390\n",
      "[404/1762] D loss: 1.3364\n",
      "[484/1762] D loss: 1.3336\n",
      "[564/1762] D loss: 1.3237\n",
      "[644/1762] D loss: 1.3052\n",
      "[724/1762] D loss: 1.3517\n",
      "[804/1762] D loss: 1.3677\n",
      "[884/1762] D loss: 1.3206\n",
      "[964/1762] D loss: 1.3126\n",
      "[1044/1762] D loss: 1.2884\n",
      "[1124/1762] D loss: 1.3720\n",
      "[1204/1762] D loss: 1.3749\n",
      "[1284/1762] D loss: 1.3338\n",
      "[1364/1762] D loss: 1.3730\n",
      "[1444/1762] D loss: 1.3188\n",
      "[1524/1762] D loss: 1.2903\n",
      "[1604/1762] D loss: 1.3650\n",
      "[1684/1762] D loss: 1.3340\n",
      "[1762/1762] D loss: 1.3496\n",
      "train error: \n",
      " D loss: 1.342918, D accuracy: 62.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346618, D accuracy: 63.1% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3406\n",
      "[84/1762] D loss: 1.3582\n",
      "[164/1762] D loss: 1.3480\n",
      "[244/1762] D loss: 1.3361\n",
      "[324/1762] D loss: 1.3745\n",
      "[404/1762] D loss: 1.3744\n",
      "[484/1762] D loss: 1.3234\n",
      "[564/1762] D loss: 1.3326\n",
      "[644/1762] D loss: 1.3686\n",
      "[724/1762] D loss: 1.3265\n",
      "[804/1762] D loss: 1.3071\n",
      "[884/1762] D loss: 1.3529\n",
      "[964/1762] D loss: 1.3532\n",
      "[1044/1762] D loss: 1.3095\n",
      "[1124/1762] D loss: 1.3478\n",
      "[1204/1762] D loss: 1.3578\n",
      "[1284/1762] D loss: 1.3211\n",
      "[1364/1762] D loss: 1.3439\n",
      "[1444/1762] D loss: 1.3098\n",
      "[1524/1762] D loss: 1.2843\n",
      "[1604/1762] D loss: 1.3345\n",
      "[1684/1762] D loss: 1.3910\n",
      "[1762/1762] D loss: 1.3665\n",
      "train error: \n",
      " D loss: 1.340560, D accuracy: 62.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337335, D accuracy: 65.3% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877\n",
      "[84/1762] D loss: 1.3697\n",
      "[164/1762] D loss: 1.3536\n",
      "[244/1762] D loss: 1.3927\n",
      "[324/1762] D loss: 1.3447\n",
      "[404/1762] D loss: 1.3097\n",
      "[484/1762] D loss: 1.3948\n",
      "[564/1762] D loss: 1.3618\n",
      "[644/1762] D loss: 1.3399\n",
      "[724/1762] D loss: 1.2701\n",
      "[804/1762] D loss: 1.3742\n",
      "[884/1762] D loss: 1.3376\n",
      "[964/1762] D loss: 1.3858\n",
      "[1044/1762] D loss: 1.2675\n",
      "[1124/1762] D loss: 1.3487\n",
      "[1204/1762] D loss: 1.3735\n",
      "[1284/1762] D loss: 1.3308\n",
      "[1364/1762] D loss: 1.3512\n",
      "[1444/1762] D loss: 1.3410\n",
      "[1524/1762] D loss: 1.3141\n",
      "[1604/1762] D loss: 1.3185\n",
      "[1684/1762] D loss: 1.3536\n",
      "[1762/1762] D loss: 1.3850\n",
      "train error: \n",
      " D loss: 1.337913, D accuracy: 63.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339975, D accuracy: 63.5% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2880\n",
      "[84/1762] D loss: 1.3466\n",
      "[164/1762] D loss: 1.3376\n",
      "[244/1762] D loss: 1.3157\n",
      "[324/1762] D loss: 1.2760\n",
      "[404/1762] D loss: 1.3606\n",
      "[484/1762] D loss: 1.3306\n",
      "[564/1762] D loss: 1.3419\n",
      "[644/1762] D loss: 1.3488\n",
      "[724/1762] D loss: 1.3361\n",
      "[804/1762] D loss: 1.3304\n",
      "[884/1762] D loss: 1.3155\n",
      "[964/1762] D loss: 1.3307\n",
      "[1044/1762] D loss: 1.3590\n",
      "[1124/1762] D loss: 1.3646\n",
      "[1204/1762] D loss: 1.3583\n",
      "[1284/1762] D loss: 1.3621\n",
      "[1364/1762] D loss: 1.3451\n",
      "[1444/1762] D loss: 1.3184\n",
      "[1524/1762] D loss: 1.3285\n",
      "[1604/1762] D loss: 1.3341\n",
      "[1684/1762] D loss: 1.3643\n",
      "[1762/1762] D loss: 1.3420\n",
      "train error: \n",
      " D loss: 1.332456, D accuracy: 64.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333521, D accuracy: 64.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3067\n",
      "[84/1762] D loss: 1.3491\n",
      "[164/1762] D loss: 1.3147\n",
      "[244/1762] D loss: 1.3184\n",
      "[324/1762] D loss: 1.3478\n",
      "[404/1762] D loss: 1.3547\n",
      "[484/1762] D loss: 1.3426\n",
      "[564/1762] D loss: 1.3712\n",
      "[644/1762] D loss: 1.3701\n",
      "[724/1762] D loss: 1.3749\n",
      "[804/1762] D loss: 1.3640\n",
      "[884/1762] D loss: 1.3599\n",
      "[964/1762] D loss: 1.3505\n",
      "[1044/1762] D loss: 1.3389\n",
      "[1124/1762] D loss: 1.3482\n",
      "[1204/1762] D loss: 1.3254\n",
      "[1284/1762] D loss: 1.2658\n",
      "[1364/1762] D loss: 1.3446\n",
      "[1444/1762] D loss: 1.2877\n",
      "[1524/1762] D loss: 1.3475\n",
      "[1604/1762] D loss: 1.3910\n",
      "[1684/1762] D loss: 1.3320\n",
      "[1762/1762] D loss: 1.3733\n",
      "train error: \n",
      " D loss: 1.329579, D accuracy: 64.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329353, D accuracy: 66.1% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3399\n",
      "[84/1762] D loss: 1.3738\n",
      "[164/1762] D loss: 1.3399\n",
      "[244/1762] D loss: 1.3367\n",
      "[324/1762] D loss: 1.3283\n",
      "[404/1762] D loss: 1.3553\n",
      "[484/1762] D loss: 1.3441\n",
      "[564/1762] D loss: 1.3152\n",
      "[644/1762] D loss: 1.3021\n",
      "[724/1762] D loss: 1.2942\n",
      "[804/1762] D loss: 1.3246\n",
      "[884/1762] D loss: 1.3209\n",
      "[964/1762] D loss: 1.3315\n",
      "[1044/1762] D loss: 1.3486\n",
      "[1124/1762] D loss: 1.3109\n",
      "[1204/1762] D loss: 1.3203\n",
      "[1284/1762] D loss: 1.3724\n",
      "[1364/1762] D loss: 1.3461\n",
      "[1444/1762] D loss: 1.3494\n",
      "[1524/1762] D loss: 1.3368\n",
      "[1604/1762] D loss: 1.3513\n",
      "[1684/1762] D loss: 1.3449\n",
      "[1762/1762] D loss: 1.3335\n",
      "train error: \n",
      " D loss: 1.321077, D accuracy: 66.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325793, D accuracy: 65.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3176\n",
      "[84/1762] D loss: 1.3530\n",
      "[164/1762] D loss: 1.3070\n",
      "[244/1762] D loss: 1.2435\n",
      "[324/1762] D loss: 1.2984\n",
      "[404/1762] D loss: 1.3269\n",
      "[484/1762] D loss: 1.3490\n",
      "[564/1762] D loss: 1.3821\n",
      "[644/1762] D loss: 1.2978\n",
      "[724/1762] D loss: 1.3857\n",
      "[804/1762] D loss: 1.3114\n",
      "[884/1762] D loss: 1.3268\n",
      "[964/1762] D loss: 1.3028\n",
      "[1044/1762] D loss: 1.3479\n",
      "[1124/1762] D loss: 1.3594\n",
      "[1204/1762] D loss: 1.2808\n",
      "[1284/1762] D loss: 1.3582\n",
      "[1364/1762] D loss: 1.2928\n",
      "[1444/1762] D loss: 1.3459\n",
      "[1524/1762] D loss: 1.3533\n",
      "[1604/1762] D loss: 1.3403\n",
      "[1684/1762] D loss: 1.3149\n",
      "[1762/1762] D loss: 1.2532\n",
      "train error: \n",
      " D loss: 1.320906, D accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323441, D accuracy: 66.4% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3078\n",
      "[84/1762] D loss: 1.3097\n",
      "[164/1762] D loss: 1.2731\n",
      "[244/1762] D loss: 1.3162\n",
      "[324/1762] D loss: 1.2918\n",
      "[404/1762] D loss: 1.2972\n",
      "[484/1762] D loss: 1.3687\n",
      "[564/1762] D loss: 1.3200\n",
      "[644/1762] D loss: 1.3088\n",
      "[724/1762] D loss: 1.3369\n",
      "[804/1762] D loss: 1.3068\n",
      "[884/1762] D loss: 1.3034\n",
      "[964/1762] D loss: 1.3007\n",
      "[1044/1762] D loss: 1.3074\n",
      "[1124/1762] D loss: 1.3131\n",
      "[1204/1762] D loss: 1.3741\n",
      "[1284/1762] D loss: 1.2932\n",
      "[1364/1762] D loss: 1.3446\n",
      "[1444/1762] D loss: 1.3358\n",
      "[1524/1762] D loss: 1.3053\n",
      "[1604/1762] D loss: 1.3385\n",
      "[1684/1762] D loss: 1.3369\n",
      "[1762/1762] D loss: 1.1829\n",
      "train error: \n",
      " D loss: 1.315785, D accuracy: 67.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313728, D accuracy: 68.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3290\n",
      "[84/1762] D loss: 1.3309\n",
      "[164/1762] D loss: 1.3434\n",
      "[244/1762] D loss: 1.2873\n",
      "[324/1762] D loss: 1.2860\n",
      "[404/1762] D loss: 1.2748\n",
      "[484/1762] D loss: 1.3220\n",
      "[564/1762] D loss: 1.3292\n",
      "[644/1762] D loss: 1.2919\n",
      "[724/1762] D loss: 1.3129\n",
      "[804/1762] D loss: 1.3102\n",
      "[884/1762] D loss: 1.3443\n",
      "[964/1762] D loss: 1.2644\n",
      "[1044/1762] D loss: 1.3030\n",
      "[1124/1762] D loss: 1.3046\n",
      "[1204/1762] D loss: 1.2413\n",
      "[1284/1762] D loss: 1.3565\n",
      "[1364/1762] D loss: 1.3227\n",
      "[1444/1762] D loss: 1.2702\n",
      "[1524/1762] D loss: 1.2670\n",
      "[1604/1762] D loss: 1.2612\n",
      "[1684/1762] D loss: 1.3174\n",
      "[1762/1762] D loss: 1.3462\n",
      "train error: \n",
      " D loss: 1.309237, D accuracy: 68.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307654, D accuracy: 68.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3830\n",
      "[84/1762] D loss: 1.3574\n",
      "[164/1762] D loss: 1.3029\n",
      "[244/1762] D loss: 1.3286\n",
      "[324/1762] D loss: 1.3057\n",
      "[404/1762] D loss: 1.3665\n",
      "[484/1762] D loss: 1.3387\n",
      "[564/1762] D loss: 1.3313\n",
      "[644/1762] D loss: 1.3693\n",
      "[724/1762] D loss: 1.3180\n",
      "[804/1762] D loss: 1.2723\n",
      "[884/1762] D loss: 1.2774\n",
      "[964/1762] D loss: 1.3171\n",
      "[1044/1762] D loss: 1.3017\n",
      "[1124/1762] D loss: 1.3167\n",
      "[1204/1762] D loss: 1.3684\n",
      "[1284/1762] D loss: 1.2822\n",
      "[1364/1762] D loss: 1.2535\n",
      "[1444/1762] D loss: 1.3301\n",
      "[1524/1762] D loss: 1.2984\n",
      "[1604/1762] D loss: 1.2959\n",
      "[1684/1762] D loss: 1.3532\n",
      "[1762/1762] D loss: 1.3113\n",
      "train error: \n",
      " D loss: 1.309038, D accuracy: 67.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305729, D accuracy: 68.8% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3370\n",
      "[84/1762] D loss: 1.3137\n",
      "[164/1762] D loss: 1.3522\n",
      "[244/1762] D loss: 1.3443\n",
      "[324/1762] D loss: 1.3346\n",
      "[404/1762] D loss: 1.3122\n",
      "[484/1762] D loss: 1.3864\n",
      "[564/1762] D loss: 1.3051\n",
      "[644/1762] D loss: 1.3205\n",
      "[724/1762] D loss: 1.2694\n",
      "[804/1762] D loss: 1.3499\n",
      "[884/1762] D loss: 1.2970\n",
      "[964/1762] D loss: 1.3533\n",
      "[1044/1762] D loss: 1.2704\n",
      "[1124/1762] D loss: 1.3305\n",
      "[1204/1762] D loss: 1.3539\n",
      "[1284/1762] D loss: 1.3174\n",
      "[1364/1762] D loss: 1.3333\n",
      "[1444/1762] D loss: 1.2630\n",
      "[1524/1762] D loss: 1.2991\n",
      "[1604/1762] D loss: 1.3265\n",
      "[1684/1762] D loss: 1.3385\n",
      "[1762/1762] D loss: 1.2043\n",
      "train error: \n",
      " D loss: 1.294830, D accuracy: 69.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298172, D accuracy: 67.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3251\n",
      "[84/1762] D loss: 1.3252\n",
      "[164/1762] D loss: 1.3199\n",
      "[244/1762] D loss: 1.3127\n",
      "[324/1762] D loss: 1.2964\n",
      "[404/1762] D loss: 1.3115\n",
      "[484/1762] D loss: 1.3575\n",
      "[564/1762] D loss: 1.3865\n",
      "[644/1762] D loss: 1.2969\n",
      "[724/1762] D loss: 1.1951\n",
      "[804/1762] D loss: 1.2835\n",
      "[884/1762] D loss: 1.3682\n",
      "[964/1762] D loss: 1.2791\n",
      "[1044/1762] D loss: 1.3597\n",
      "[1124/1762] D loss: 1.2556\n",
      "[1204/1762] D loss: 1.2759\n",
      "[1284/1762] D loss: 1.3165\n",
      "[1364/1762] D loss: 1.2952\n",
      "[1444/1762] D loss: 1.2125\n",
      "[1524/1762] D loss: 1.2920\n",
      "[1604/1762] D loss: 1.3568\n",
      "[1684/1762] D loss: 1.3304\n",
      "[1762/1762] D loss: 1.2894\n",
      "train error: \n",
      " D loss: 1.293036, D accuracy: 70.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290042, D accuracy: 71.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3558\n",
      "[84/1762] D loss: 1.2777\n",
      "[164/1762] D loss: 1.3287\n",
      "[244/1762] D loss: 1.3188\n",
      "[324/1762] D loss: 1.2789\n",
      "[404/1762] D loss: 1.3615\n",
      "[484/1762] D loss: 1.3546\n",
      "[564/1762] D loss: 1.3790\n",
      "[644/1762] D loss: 1.2981\n",
      "[724/1762] D loss: 1.2796\n",
      "[804/1762] D loss: 1.2824\n",
      "[884/1762] D loss: 1.2932\n",
      "[964/1762] D loss: 1.3230\n",
      "[1044/1762] D loss: 1.2349\n",
      "[1124/1762] D loss: 1.3046\n",
      "[1204/1762] D loss: 1.2804\n",
      "[1284/1762] D loss: 1.3055\n",
      "[1364/1762] D loss: 1.2197\n",
      "[1444/1762] D loss: 1.3055\n",
      "[1524/1762] D loss: 1.2910\n",
      "[1604/1762] D loss: 1.3289\n",
      "[1684/1762] D loss: 1.2689\n",
      "[1762/1762] D loss: 1.3059\n",
      "train error: \n",
      " D loss: 1.285877, D accuracy: 70.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299280, D accuracy: 68.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3218\n",
      "[84/1762] D loss: 1.3236\n",
      "[164/1762] D loss: 1.3488\n",
      "[244/1762] D loss: 1.2934\n",
      "[324/1762] D loss: 1.3233\n",
      "[404/1762] D loss: 1.3191\n",
      "[484/1762] D loss: 1.2253\n",
      "[564/1762] D loss: 1.2260\n",
      "[644/1762] D loss: 1.2805\n",
      "[724/1762] D loss: 1.3492\n",
      "[804/1762] D loss: 1.3038\n",
      "[884/1762] D loss: 1.2972\n",
      "[964/1762] D loss: 1.2339\n",
      "[1044/1762] D loss: 1.3248\n",
      "[1124/1762] D loss: 1.3384\n",
      "[1204/1762] D loss: 1.2862\n",
      "[1284/1762] D loss: 1.3539\n",
      "[1364/1762] D loss: 1.1770\n",
      "[1444/1762] D loss: 1.2325\n",
      "[1524/1762] D loss: 1.3411\n",
      "[1604/1762] D loss: 1.3591\n",
      "[1684/1762] D loss: 1.3324\n",
      "[1762/1762] D loss: 1.2688\n",
      "train error: \n",
      " D loss: 1.277393, D accuracy: 71.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285357, D accuracy: 71.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3138\n",
      "[84/1762] D loss: 1.3116\n",
      "[164/1762] D loss: 1.2827\n",
      "[244/1762] D loss: 1.2645\n",
      "[324/1762] D loss: 1.2979\n",
      "[404/1762] D loss: 1.3497\n",
      "[484/1762] D loss: 1.2348\n",
      "[564/1762] D loss: 1.2962\n",
      "[644/1762] D loss: 1.3051\n",
      "[724/1762] D loss: 1.3193\n",
      "[804/1762] D loss: 1.2272\n",
      "[884/1762] D loss: 1.2687\n",
      "[964/1762] D loss: 1.2992\n",
      "[1044/1762] D loss: 1.2427\n",
      "[1124/1762] D loss: 1.2882\n",
      "[1204/1762] D loss: 1.2690\n",
      "[1284/1762] D loss: 1.2662\n",
      "[1364/1762] D loss: 1.3053\n",
      "[1444/1762] D loss: 1.1785\n",
      "[1524/1762] D loss: 1.1501\n",
      "[1604/1762] D loss: 1.2815\n",
      "[1684/1762] D loss: 1.2442\n",
      "[1762/1762] D loss: 1.2240\n",
      "train error: \n",
      " D loss: 1.272612, D accuracy: 72.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271243, D accuracy: 74.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2999\n",
      "[84/1762] D loss: 1.3440\n",
      "[164/1762] D loss: 1.3488\n",
      "[244/1762] D loss: 1.3183\n",
      "[324/1762] D loss: 1.3156\n",
      "[404/1762] D loss: 1.3165\n",
      "[484/1762] D loss: 1.2677\n",
      "[564/1762] D loss: 1.2826\n",
      "[644/1762] D loss: 1.2212\n",
      "[724/1762] D loss: 1.2645\n",
      "[804/1762] D loss: 1.1560\n",
      "[884/1762] D loss: 1.3057\n",
      "[964/1762] D loss: 1.3268\n",
      "[1044/1762] D loss: 1.2773\n",
      "[1124/1762] D loss: 1.3146\n",
      "[1204/1762] D loss: 1.3211\n",
      "[1284/1762] D loss: 1.2151\n",
      "[1364/1762] D loss: 1.2214\n",
      "[1444/1762] D loss: 1.2422\n",
      "[1524/1762] D loss: 1.2588\n",
      "[1604/1762] D loss: 1.3521\n",
      "[1684/1762] D loss: 1.3520\n",
      "[1762/1762] D loss: 1.2678\n",
      "train error: \n",
      " D loss: 1.266053, D accuracy: 72.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265036, D accuracy: 72.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3419\n",
      "[84/1762] D loss: 1.2777\n",
      "[164/1762] D loss: 1.2963\n",
      "[244/1762] D loss: 1.2098\n",
      "[324/1762] D loss: 1.2550\n",
      "[404/1762] D loss: 1.2854\n",
      "[484/1762] D loss: 1.3288\n",
      "[564/1762] D loss: 1.2534\n",
      "[644/1762] D loss: 1.2373\n",
      "[724/1762] D loss: 1.1841\n",
      "[804/1762] D loss: 1.3929\n",
      "[884/1762] D loss: 1.3813\n",
      "[964/1762] D loss: 1.2519\n",
      "[1044/1762] D loss: 1.2750\n",
      "[1124/1762] D loss: 1.2491\n",
      "[1204/1762] D loss: 1.2618\n",
      "[1284/1762] D loss: 1.2337\n",
      "[1364/1762] D loss: 1.2685\n",
      "[1444/1762] D loss: 1.3746\n",
      "[1524/1762] D loss: 1.3086\n",
      "[1604/1762] D loss: 1.2813\n",
      "[1684/1762] D loss: 1.1460\n",
      "[1762/1762] D loss: 1.2454\n",
      "train error: \n",
      " D loss: 1.252769, D accuracy: 74.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257249, D accuracy: 74.1% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878\n",
      "[84/1762] D loss: 1.3836\n",
      "[164/1762] D loss: 1.3907\n",
      "[244/1762] D loss: 1.3849\n",
      "[324/1762] D loss: 1.3619\n",
      "[404/1762] D loss: 1.3781\n",
      "[484/1762] D loss: 1.3789\n",
      "[564/1762] D loss: 1.4161\n",
      "[644/1762] D loss: 1.3755\n",
      "[724/1762] D loss: 1.3895\n",
      "[804/1762] D loss: 1.3955\n",
      "[884/1762] D loss: 1.3790\n",
      "[964/1762] D loss: 1.4077\n",
      "[1044/1762] D loss: 1.3840\n",
      "[1124/1762] D loss: 1.3900\n",
      "[1204/1762] D loss: 1.3935\n",
      "[1284/1762] D loss: 1.3867\n",
      "[1364/1762] D loss: 1.4159\n",
      "[1444/1762] D loss: 1.3970\n",
      "[1524/1762] D loss: 1.3802\n",
      "[1604/1762] D loss: 1.3918\n",
      "[1684/1762] D loss: 1.4000\n",
      "[1762/1762] D loss: 1.3781\n",
      "train error: \n",
      " D loss: 1.387897, D accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389365, D accuracy: 49.9% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3769\n",
      "[84/1762] D loss: 1.3713\n",
      "[164/1762] D loss: 1.3945\n",
      "[244/1762] D loss: 1.3701\n",
      "[324/1762] D loss: 1.3982\n",
      "[404/1762] D loss: 1.3915\n",
      "[484/1762] D loss: 1.3884\n",
      "[564/1762] D loss: 1.3810\n",
      "[644/1762] D loss: 1.3934\n",
      "[724/1762] D loss: 1.3921\n",
      "[804/1762] D loss: 1.3553\n",
      "[884/1762] D loss: 1.3861\n",
      "[964/1762] D loss: 1.3834\n",
      "[1044/1762] D loss: 1.3974\n",
      "[1124/1762] D loss: 1.3938\n",
      "[1204/1762] D loss: 1.3727\n",
      "[1284/1762] D loss: 1.3879\n",
      "[1364/1762] D loss: 1.3978\n",
      "[1444/1762] D loss: 1.3934\n",
      "[1524/1762] D loss: 1.3748\n",
      "[1604/1762] D loss: 1.3863\n",
      "[1684/1762] D loss: 1.3848\n",
      "[1762/1762] D loss: 1.3890\n",
      "train error: \n",
      " D loss: 1.387443, D accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388457, D accuracy: 49.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3669\n",
      "[84/1762] D loss: 1.3836\n",
      "[164/1762] D loss: 1.3911\n",
      "[244/1762] D loss: 1.3629\n",
      "[324/1762] D loss: 1.3925\n",
      "[404/1762] D loss: 1.3950\n",
      "[484/1762] D loss: 1.3874\n",
      "[564/1762] D loss: 1.3908\n",
      "[644/1762] D loss: 1.3910\n",
      "[724/1762] D loss: 1.3935\n",
      "[804/1762] D loss: 1.3993\n",
      "[884/1762] D loss: 1.3906\n",
      "[964/1762] D loss: 1.3752\n",
      "[1044/1762] D loss: 1.3975\n",
      "[1124/1762] D loss: 1.3818\n",
      "[1204/1762] D loss: 1.3825\n",
      "[1284/1762] D loss: 1.3689\n",
      "[1364/1762] D loss: 1.3884\n",
      "[1444/1762] D loss: 1.3916\n",
      "[1524/1762] D loss: 1.3777\n",
      "[1604/1762] D loss: 1.3746\n",
      "[1684/1762] D loss: 1.3736\n",
      "[1762/1762] D loss: 1.4038\n",
      "train error: \n",
      " D loss: 1.387975, D accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386116, D accuracy: 51.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914\n",
      "[84/1762] D loss: 1.3909\n",
      "[164/1762] D loss: 1.3692\n",
      "[244/1762] D loss: 1.3999\n",
      "[324/1762] D loss: 1.3865\n",
      "[404/1762] D loss: 1.3721\n",
      "[484/1762] D loss: 1.3751\n",
      "[564/1762] D loss: 1.3770\n",
      "[644/1762] D loss: 1.3914\n",
      "[724/1762] D loss: 1.4028\n",
      "[804/1762] D loss: 1.3879\n",
      "[884/1762] D loss: 1.3931\n",
      "[964/1762] D loss: 1.3870\n",
      "[1044/1762] D loss: 1.3656\n",
      "[1124/1762] D loss: 1.3860\n",
      "[1204/1762] D loss: 1.3810\n",
      "[1284/1762] D loss: 1.3932\n",
      "[1364/1762] D loss: 1.3683\n",
      "[1444/1762] D loss: 1.3968\n",
      "[1524/1762] D loss: 1.3819\n",
      "[1604/1762] D loss: 1.3683\n",
      "[1684/1762] D loss: 1.3898\n",
      "[1762/1762] D loss: 1.3530\n",
      "train error: \n",
      " D loss: 1.386817, D accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387672, D accuracy: 50.3% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923\n",
      "[84/1762] D loss: 1.3910\n",
      "[164/1762] D loss: 1.3819\n",
      "[244/1762] D loss: 1.3709\n",
      "[324/1762] D loss: 1.3763\n",
      "[404/1762] D loss: 1.3861\n",
      "[484/1762] D loss: 1.3870\n",
      "[564/1762] D loss: 1.3716\n",
      "[644/1762] D loss: 1.3825\n",
      "[724/1762] D loss: 1.3690\n",
      "[804/1762] D loss: 1.3905\n",
      "[884/1762] D loss: 1.3818\n",
      "[964/1762] D loss: 1.3911\n",
      "[1044/1762] D loss: 1.3903\n",
      "[1124/1762] D loss: 1.3565\n",
      "[1204/1762] D loss: 1.3773\n",
      "[1284/1762] D loss: 1.3806\n",
      "[1364/1762] D loss: 1.3545\n",
      "[1444/1762] D loss: 1.3786\n",
      "[1524/1762] D loss: 1.4017\n",
      "[1604/1762] D loss: 1.3778\n",
      "[1684/1762] D loss: 1.3778\n",
      "[1762/1762] D loss: 1.3693\n",
      "train error: \n",
      " D loss: 1.386447, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386891, D accuracy: 51.8% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3570\n",
      "[84/1762] D loss: 1.3775\n",
      "[164/1762] D loss: 1.3673\n",
      "[244/1762] D loss: 1.3964\n",
      "[324/1762] D loss: 1.3717\n",
      "[404/1762] D loss: 1.4061\n",
      "[484/1762] D loss: 1.3918\n",
      "[564/1762] D loss: 1.3968\n",
      "[644/1762] D loss: 1.3813\n",
      "[724/1762] D loss: 1.3748\n",
      "[804/1762] D loss: 1.3697\n",
      "[884/1762] D loss: 1.3981\n",
      "[964/1762] D loss: 1.3816\n",
      "[1044/1762] D loss: 1.3855\n",
      "[1124/1762] D loss: 1.3827\n",
      "[1204/1762] D loss: 1.3919\n",
      "[1284/1762] D loss: 1.3822\n",
      "[1364/1762] D loss: 1.4017\n",
      "[1444/1762] D loss: 1.3917\n",
      "[1524/1762] D loss: 1.3937\n",
      "[1604/1762] D loss: 1.3938\n",
      "[1684/1762] D loss: 1.3755\n",
      "[1762/1762] D loss: 1.3843\n",
      "train error: \n",
      " D loss: 1.386799, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386352, D accuracy: 49.2% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893\n",
      "[84/1762] D loss: 1.3822\n",
      "[164/1762] D loss: 1.3692\n",
      "[244/1762] D loss: 1.3780\n",
      "[324/1762] D loss: 1.3815\n",
      "[404/1762] D loss: 1.3855\n",
      "[484/1762] D loss: 1.3980\n",
      "[564/1762] D loss: 1.3912\n",
      "[644/1762] D loss: 1.3738\n",
      "[724/1762] D loss: 1.3937\n",
      "[804/1762] D loss: 1.3804\n",
      "[884/1762] D loss: 1.3851\n",
      "[964/1762] D loss: 1.3883\n",
      "[1044/1762] D loss: 1.3779\n",
      "[1124/1762] D loss: 1.3756\n",
      "[1204/1762] D loss: 1.3876\n",
      "[1284/1762] D loss: 1.3918\n",
      "[1364/1762] D loss: 1.3592\n",
      "[1444/1762] D loss: 1.3919\n",
      "[1524/1762] D loss: 1.3573\n",
      "[1604/1762] D loss: 1.3910\n",
      "[1684/1762] D loss: 1.3677\n",
      "[1762/1762] D loss: 1.3978\n",
      "train error: \n",
      " D loss: 1.386521, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386736, D accuracy: 49.2% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916\n",
      "[84/1762] D loss: 1.3817\n",
      "[164/1762] D loss: 1.3788\n",
      "[244/1762] D loss: 1.3861\n",
      "[324/1762] D loss: 1.3801\n",
      "[404/1762] D loss: 1.3806\n",
      "[484/1762] D loss: 1.3829\n",
      "[564/1762] D loss: 1.3748\n",
      "[644/1762] D loss: 1.3825\n",
      "[724/1762] D loss: 1.3847\n",
      "[804/1762] D loss: 1.3884\n",
      "[884/1762] D loss: 1.3716\n",
      "[964/1762] D loss: 1.3876\n",
      "[1044/1762] D loss: 1.3905\n",
      "[1124/1762] D loss: 1.3995\n",
      "[1204/1762] D loss: 1.4008\n",
      "[1284/1762] D loss: 1.3941\n",
      "[1364/1762] D loss: 1.3734\n",
      "[1444/1762] D loss: 1.3952\n",
      "[1524/1762] D loss: 1.3919\n",
      "[1604/1762] D loss: 1.3766\n",
      "[1684/1762] D loss: 1.3936\n",
      "[1762/1762] D loss: 1.3644\n",
      "train error: \n",
      " D loss: 1.386520, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386582, D accuracy: 51.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980\n",
      "[84/1762] D loss: 1.3835\n",
      "[164/1762] D loss: 1.3871\n",
      "[244/1762] D loss: 1.3871\n",
      "[324/1762] D loss: 1.3790\n",
      "[404/1762] D loss: 1.3666\n",
      "[484/1762] D loss: 1.3940\n",
      "[564/1762] D loss: 1.3731\n",
      "[644/1762] D loss: 1.3980\n",
      "[724/1762] D loss: 1.3909\n",
      "[804/1762] D loss: 1.3814\n",
      "[884/1762] D loss: 1.3824\n",
      "[964/1762] D loss: 1.3727\n",
      "[1044/1762] D loss: 1.3850\n",
      "[1124/1762] D loss: 1.3505\n",
      "[1204/1762] D loss: 1.4038\n",
      "[1284/1762] D loss: 1.3989\n",
      "[1364/1762] D loss: 1.3808\n",
      "[1444/1762] D loss: 1.3686\n",
      "[1524/1762] D loss: 1.3728\n",
      "[1604/1762] D loss: 1.3917\n",
      "[1684/1762] D loss: 1.3843\n",
      "[1762/1762] D loss: 1.3910\n",
      "train error: \n",
      " D loss: 1.387165, D accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386443, D accuracy: 51.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3848\n",
      "[84/1762] D loss: 1.3852\n",
      "[164/1762] D loss: 1.3809\n",
      "[244/1762] D loss: 1.3729\n",
      "[324/1762] D loss: 1.3779\n",
      "[404/1762] D loss: 1.3672\n",
      "[484/1762] D loss: 1.3759\n",
      "[564/1762] D loss: 1.3677\n",
      "[644/1762] D loss: 1.3892\n",
      "[724/1762] D loss: 1.4041\n",
      "[804/1762] D loss: 1.3932\n",
      "[884/1762] D loss: 1.3690\n",
      "[964/1762] D loss: 1.3529\n",
      "[1044/1762] D loss: 1.3705\n",
      "[1124/1762] D loss: 1.3773\n",
      "[1204/1762] D loss: 1.3932\n",
      "[1284/1762] D loss: 1.3949\n",
      "[1364/1762] D loss: 1.3614\n",
      "[1444/1762] D loss: 1.3805\n",
      "[1524/1762] D loss: 1.3672\n",
      "[1604/1762] D loss: 1.3990\n",
      "[1684/1762] D loss: 1.3858\n",
      "[1762/1762] D loss: 1.3983\n",
      "train error: \n",
      " D loss: 1.385918, D accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385967, D accuracy: 51.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4108\n",
      "[84/1762] D loss: 1.3817\n",
      "[164/1762] D loss: 1.3858\n",
      "[244/1762] D loss: 1.3818\n",
      "[324/1762] D loss: 1.3740\n",
      "[404/1762] D loss: 1.3772\n",
      "[484/1762] D loss: 1.3908\n",
      "[564/1762] D loss: 1.3904\n",
      "[644/1762] D loss: 1.3856\n",
      "[724/1762] D loss: 1.3799\n",
      "[804/1762] D loss: 1.3852\n",
      "[884/1762] D loss: 1.3719\n",
      "[964/1762] D loss: 1.3681\n",
      "[1044/1762] D loss: 1.3747\n",
      "[1124/1762] D loss: 1.3924\n",
      "[1204/1762] D loss: 1.3920\n",
      "[1284/1762] D loss: 1.3865\n",
      "[1364/1762] D loss: 1.3954\n",
      "[1444/1762] D loss: 1.3635\n",
      "[1524/1762] D loss: 1.3950\n",
      "[1604/1762] D loss: 1.3692\n",
      "[1684/1762] D loss: 1.3830\n",
      "[1762/1762] D loss: 1.3671\n",
      "train error: \n",
      " D loss: 1.385834, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386323, D accuracy: 50.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3947\n",
      "[84/1762] D loss: 1.4019\n",
      "[164/1762] D loss: 1.3859\n",
      "[244/1762] D loss: 1.3959\n",
      "[324/1762] D loss: 1.3855\n",
      "[404/1762] D loss: 1.4101\n",
      "[484/1762] D loss: 1.3821\n",
      "[564/1762] D loss: 1.3850\n",
      "[644/1762] D loss: 1.3859\n",
      "[724/1762] D loss: 1.3883\n",
      "[804/1762] D loss: 1.3789\n",
      "[884/1762] D loss: 1.3854\n",
      "[964/1762] D loss: 1.3911\n",
      "[1044/1762] D loss: 1.3819\n",
      "[1124/1762] D loss: 1.3706\n",
      "[1204/1762] D loss: 1.3742\n",
      "[1284/1762] D loss: 1.3953\n",
      "[1364/1762] D loss: 1.3923\n",
      "[1444/1762] D loss: 1.3730\n",
      "[1524/1762] D loss: 1.3824\n",
      "[1604/1762] D loss: 1.3835\n",
      "[1684/1762] D loss: 1.3696\n",
      "[1762/1762] D loss: 1.3589\n",
      "train error: \n",
      " D loss: 1.385937, D accuracy: 51.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384503, D accuracy: 51.2% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3752\n",
      "[84/1762] D loss: 1.3889\n",
      "[164/1762] D loss: 1.3689\n",
      "[244/1762] D loss: 1.3737\n",
      "[324/1762] D loss: 1.3787\n",
      "[404/1762] D loss: 1.3727\n",
      "[484/1762] D loss: 1.3794\n",
      "[564/1762] D loss: 1.3779\n",
      "[644/1762] D loss: 1.3846\n",
      "[724/1762] D loss: 1.3771\n",
      "[804/1762] D loss: 1.3857\n",
      "[884/1762] D loss: 1.3723\n",
      "[964/1762] D loss: 1.3778\n",
      "[1044/1762] D loss: 1.3738\n",
      "[1124/1762] D loss: 1.3830\n",
      "[1204/1762] D loss: 1.3726\n",
      "[1284/1762] D loss: 1.3927\n",
      "[1364/1762] D loss: 1.3966\n",
      "[1444/1762] D loss: 1.3759\n",
      "[1524/1762] D loss: 1.4074\n",
      "[1604/1762] D loss: 1.3841\n",
      "[1684/1762] D loss: 1.3683\n",
      "[1762/1762] D loss: 1.3938\n",
      "train error: \n",
      " D loss: 1.385634, D accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384132, D accuracy: 51.1% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3625\n",
      "[84/1762] D loss: 1.3987\n",
      "[164/1762] D loss: 1.3755\n",
      "[244/1762] D loss: 1.3775\n",
      "[324/1762] D loss: 1.3800\n",
      "[404/1762] D loss: 1.3636\n",
      "[484/1762] D loss: 1.3821\n",
      "[564/1762] D loss: 1.3811\n",
      "[644/1762] D loss: 1.3950\n",
      "[724/1762] D loss: 1.3891\n",
      "[804/1762] D loss: 1.3992\n",
      "[884/1762] D loss: 1.4030\n",
      "[964/1762] D loss: 1.3838\n",
      "[1044/1762] D loss: 1.3650\n",
      "[1124/1762] D loss: 1.3855\n",
      "[1204/1762] D loss: 1.3689\n",
      "[1284/1762] D loss: 1.3957\n",
      "[1364/1762] D loss: 1.3887\n",
      "[1444/1762] D loss: 1.3790\n",
      "[1524/1762] D loss: 1.3905\n",
      "[1604/1762] D loss: 1.3776\n",
      "[1684/1762] D loss: 1.3845\n",
      "[1762/1762] D loss: 1.3744\n",
      "train error: \n",
      " D loss: 1.384340, D accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384390, D accuracy: 53.3% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3800\n",
      "[84/1762] D loss: 1.3944\n",
      "[164/1762] D loss: 1.3664\n",
      "[244/1762] D loss: 1.3814\n",
      "[324/1762] D loss: 1.3953\n",
      "[404/1762] D loss: 1.3731\n",
      "[484/1762] D loss: 1.3797\n",
      "[564/1762] D loss: 1.4078\n",
      "[644/1762] D loss: 1.3920\n",
      "[724/1762] D loss: 1.3801\n",
      "[804/1762] D loss: 1.3761\n",
      "[884/1762] D loss: 1.3560\n",
      "[964/1762] D loss: 1.3896\n",
      "[1044/1762] D loss: 1.3830\n",
      "[1124/1762] D loss: 1.3866\n",
      "[1204/1762] D loss: 1.3765\n",
      "[1284/1762] D loss: 1.3845\n",
      "[1364/1762] D loss: 1.3777\n",
      "[1444/1762] D loss: 1.3945\n",
      "[1524/1762] D loss: 1.3949\n",
      "[1604/1762] D loss: 1.3810\n",
      "[1684/1762] D loss: 1.3748\n",
      "[1762/1762] D loss: 1.3685\n",
      "train error: \n",
      " D loss: 1.384686, D accuracy: 51.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382922, D accuracy: 52.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935\n",
      "[84/1762] D loss: 1.3506\n",
      "[164/1762] D loss: 1.3924\n",
      "[244/1762] D loss: 1.3822\n",
      "[324/1762] D loss: 1.4004\n",
      "[404/1762] D loss: 1.3962\n",
      "[484/1762] D loss: 1.3509\n",
      "[564/1762] D loss: 1.3597\n",
      "[644/1762] D loss: 1.3870\n",
      "[724/1762] D loss: 1.3629\n",
      "[804/1762] D loss: 1.3728\n",
      "[884/1762] D loss: 1.3827\n",
      "[964/1762] D loss: 1.3817\n",
      "[1044/1762] D loss: 1.3885\n",
      "[1124/1762] D loss: 1.3549\n",
      "[1204/1762] D loss: 1.3824\n",
      "[1284/1762] D loss: 1.3756\n",
      "[1364/1762] D loss: 1.3689\n",
      "[1444/1762] D loss: 1.3856\n",
      "[1524/1762] D loss: 1.3951\n",
      "[1604/1762] D loss: 1.3829\n",
      "[1684/1762] D loss: 1.3701\n",
      "[1762/1762] D loss: 1.3732\n",
      "train error: \n",
      " D loss: 1.383793, D accuracy: 52.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385787, D accuracy: 49.9% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3818\n",
      "[84/1762] D loss: 1.3863\n",
      "[164/1762] D loss: 1.3947\n",
      "[244/1762] D loss: 1.3771\n",
      "[324/1762] D loss: 1.3801\n",
      "[404/1762] D loss: 1.3808\n",
      "[484/1762] D loss: 1.3529\n",
      "[564/1762] D loss: 1.3747\n",
      "[644/1762] D loss: 1.3740\n",
      "[724/1762] D loss: 1.3886\n",
      "[804/1762] D loss: 1.3978\n",
      "[884/1762] D loss: 1.3848\n",
      "[964/1762] D loss: 1.3977\n",
      "[1044/1762] D loss: 1.3905\n",
      "[1124/1762] D loss: 1.3801\n",
      "[1204/1762] D loss: 1.3863\n",
      "[1284/1762] D loss: 1.3677\n",
      "[1364/1762] D loss: 1.3808\n",
      "[1444/1762] D loss: 1.3625\n",
      "[1524/1762] D loss: 1.3798\n",
      "[1604/1762] D loss: 1.3683\n",
      "[1684/1762] D loss: 1.3795\n",
      "[1762/1762] D loss: 1.4001\n",
      "train error: \n",
      " D loss: 1.384545, D accuracy: 51.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383973, D accuracy: 51.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3730\n",
      "[84/1762] D loss: 1.3807\n",
      "[164/1762] D loss: 1.3860\n",
      "[244/1762] D loss: 1.3785\n",
      "[324/1762] D loss: 1.3702\n",
      "[404/1762] D loss: 1.3808\n",
      "[484/1762] D loss: 1.4056\n",
      "[564/1762] D loss: 1.3955\n",
      "[644/1762] D loss: 1.3916\n",
      "[724/1762] D loss: 1.3674\n",
      "[804/1762] D loss: 1.4009\n",
      "[884/1762] D loss: 1.3586\n",
      "[964/1762] D loss: 1.3908\n",
      "[1044/1762] D loss: 1.3640\n",
      "[1124/1762] D loss: 1.3910\n",
      "[1204/1762] D loss: 1.3724\n",
      "[1284/1762] D loss: 1.3730\n",
      "[1364/1762] D loss: 1.3647\n",
      "[1444/1762] D loss: 1.3908\n",
      "[1524/1762] D loss: 1.3755\n",
      "[1604/1762] D loss: 1.3858\n",
      "[1684/1762] D loss: 1.3765\n",
      "[1762/1762] D loss: 1.3840\n",
      "train error: \n",
      " D loss: 1.383561, D accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383324, D accuracy: 53.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927\n",
      "[84/1762] D loss: 1.3885\n",
      "[164/1762] D loss: 1.3887\n",
      "[244/1762] D loss: 1.3638\n",
      "[324/1762] D loss: 1.3656\n",
      "[404/1762] D loss: 1.3912\n",
      "[484/1762] D loss: 1.3838\n",
      "[564/1762] D loss: 1.3840\n",
      "[644/1762] D loss: 1.3843\n",
      "[724/1762] D loss: 1.3709\n",
      "[804/1762] D loss: 1.3463\n",
      "[884/1762] D loss: 1.3984\n",
      "[964/1762] D loss: 1.3613\n",
      "[1044/1762] D loss: 1.3811\n",
      "[1124/1762] D loss: 1.3769\n",
      "[1204/1762] D loss: 1.3769\n",
      "[1284/1762] D loss: 1.3692\n",
      "[1364/1762] D loss: 1.3911\n",
      "[1444/1762] D loss: 1.3955\n",
      "[1524/1762] D loss: 1.3787\n",
      "[1604/1762] D loss: 1.4039\n",
      "[1684/1762] D loss: 1.3880\n",
      "[1762/1762] D loss: 1.3890\n",
      "train error: \n",
      " D loss: 1.383791, D accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383263, D accuracy: 52.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3651\n",
      "[84/1762] D loss: 1.3638\n",
      "[164/1762] D loss: 1.3807\n",
      "[244/1762] D loss: 1.3862\n",
      "[324/1762] D loss: 1.3812\n",
      "[404/1762] D loss: 1.3841\n",
      "[484/1762] D loss: 1.3767\n",
      "[564/1762] D loss: 1.3879\n",
      "[644/1762] D loss: 1.3645\n",
      "[724/1762] D loss: 1.3796\n",
      "[804/1762] D loss: 1.3796\n",
      "[884/1762] D loss: 1.3994\n",
      "[964/1762] D loss: 1.3871\n",
      "[1044/1762] D loss: 1.3798\n",
      "[1124/1762] D loss: 1.3725\n",
      "[1204/1762] D loss: 1.3807\n",
      "[1284/1762] D loss: 1.3642\n",
      "[1364/1762] D loss: 1.3905\n",
      "[1444/1762] D loss: 1.3525\n",
      "[1524/1762] D loss: 1.3875\n",
      "[1604/1762] D loss: 1.3931\n",
      "[1684/1762] D loss: 1.3868\n",
      "[1762/1762] D loss: 1.3974\n",
      "train error: \n",
      " D loss: 1.383882, D accuracy: 51.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382636, D accuracy: 51.1% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3686\n",
      "[84/1762] D loss: 1.3797\n",
      "[164/1762] D loss: 1.3907\n",
      "[244/1762] D loss: 1.3708\n",
      "[324/1762] D loss: 1.3646\n",
      "[404/1762] D loss: 1.3802\n",
      "[484/1762] D loss: 1.3745\n",
      "[564/1762] D loss: 1.3912\n",
      "[644/1762] D loss: 1.3686\n",
      "[724/1762] D loss: 1.3836\n",
      "[804/1762] D loss: 1.3971\n",
      "[884/1762] D loss: 1.3836\n",
      "[964/1762] D loss: 1.3623\n",
      "[1044/1762] D loss: 1.3826\n",
      "[1124/1762] D loss: 1.3750\n",
      "[1204/1762] D loss: 1.3862\n",
      "[1284/1762] D loss: 1.3692\n",
      "[1364/1762] D loss: 1.3959\n",
      "[1444/1762] D loss: 1.3862\n",
      "[1524/1762] D loss: 1.3798\n",
      "[1604/1762] D loss: 1.3545\n",
      "[1684/1762] D loss: 1.3944\n",
      "[1762/1762] D loss: 1.3847\n",
      "train error: \n",
      " D loss: 1.383459, D accuracy: 52.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383139, D accuracy: 51.9% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3992\n",
      "[84/1762] D loss: 1.3844\n",
      "[164/1762] D loss: 1.3745\n",
      "[244/1762] D loss: 1.3777\n",
      "[324/1762] D loss: 1.3719\n",
      "[404/1762] D loss: 1.3772\n",
      "[484/1762] D loss: 1.4148\n",
      "[564/1762] D loss: 1.3676\n",
      "[644/1762] D loss: 1.3852\n",
      "[724/1762] D loss: 1.3846\n",
      "[804/1762] D loss: 1.3916\n",
      "[884/1762] D loss: 1.3772\n",
      "[964/1762] D loss: 1.3947\n",
      "[1044/1762] D loss: 1.3749\n",
      "[1124/1762] D loss: 1.3909\n",
      "[1204/1762] D loss: 1.3757\n",
      "[1284/1762] D loss: 1.3801\n",
      "[1364/1762] D loss: 1.3741\n",
      "[1444/1762] D loss: 1.3905\n",
      "[1524/1762] D loss: 1.3693\n",
      "[1604/1762] D loss: 1.3896\n",
      "[1684/1762] D loss: 1.3714\n",
      "[1762/1762] D loss: 1.3887\n",
      "train error: \n",
      " D loss: 1.383188, D accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383981, D accuracy: 51.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872\n",
      "[84/1762] D loss: 1.3779\n",
      "[164/1762] D loss: 1.3708\n",
      "[244/1762] D loss: 1.3720\n",
      "[324/1762] D loss: 1.3702\n",
      "[404/1762] D loss: 1.3906\n",
      "[484/1762] D loss: 1.3634\n",
      "[564/1762] D loss: 1.3697\n",
      "[644/1762] D loss: 1.3892\n",
      "[724/1762] D loss: 1.3720\n",
      "[804/1762] D loss: 1.3522\n",
      "[884/1762] D loss: 1.3578\n",
      "[964/1762] D loss: 1.3874\n",
      "[1044/1762] D loss: 1.3584\n",
      "[1124/1762] D loss: 1.3553\n",
      "[1204/1762] D loss: 1.3912\n",
      "[1284/1762] D loss: 1.3664\n",
      "[1364/1762] D loss: 1.4018\n",
      "[1444/1762] D loss: 1.3836\n",
      "[1524/1762] D loss: 1.3823\n",
      "[1604/1762] D loss: 1.3727\n",
      "[1684/1762] D loss: 1.3683\n",
      "[1762/1762] D loss: 1.3514\n",
      "train error: \n",
      " D loss: 1.382644, D accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382976, D accuracy: 51.2% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3643\n",
      "[84/1762] D loss: 1.3877\n",
      "[164/1762] D loss: 1.4079\n",
      "[244/1762] D loss: 1.3751\n",
      "[324/1762] D loss: 1.3936\n",
      "[404/1762] D loss: 1.3785\n",
      "[484/1762] D loss: 1.3823\n",
      "[564/1762] D loss: 1.3779\n",
      "[644/1762] D loss: 1.3813\n",
      "[724/1762] D loss: 1.3734\n",
      "[804/1762] D loss: 1.3680\n",
      "[884/1762] D loss: 1.3469\n",
      "[964/1762] D loss: 1.3762\n",
      "[1044/1762] D loss: 1.3556\n",
      "[1124/1762] D loss: 1.3569\n",
      "[1204/1762] D loss: 1.3780\n",
      "[1284/1762] D loss: 1.3777\n",
      "[1364/1762] D loss: 1.3911\n",
      "[1444/1762] D loss: 1.3657\n",
      "[1524/1762] D loss: 1.3811\n",
      "[1604/1762] D loss: 1.3715\n",
      "[1684/1762] D loss: 1.3904\n",
      "[1762/1762] D loss: 1.3409\n",
      "train error: \n",
      " D loss: 1.383144, D accuracy: 52.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382702, D accuracy: 53.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3792\n",
      "[84/1762] D loss: 1.3354\n",
      "[164/1762] D loss: 1.3844\n",
      "[244/1762] D loss: 1.3975\n",
      "[324/1762] D loss: 1.3743\n",
      "[404/1762] D loss: 1.3789\n",
      "[484/1762] D loss: 1.3853\n",
      "[564/1762] D loss: 1.3703\n",
      "[644/1762] D loss: 1.3831\n",
      "[724/1762] D loss: 1.3955\n",
      "[804/1762] D loss: 1.3648\n",
      "[884/1762] D loss: 1.3588\n",
      "[964/1762] D loss: 1.3772\n",
      "[1044/1762] D loss: 1.3682\n",
      "[1124/1762] D loss: 1.3694\n",
      "[1204/1762] D loss: 1.3771\n",
      "[1284/1762] D loss: 1.3703\n",
      "[1364/1762] D loss: 1.3835\n",
      "[1444/1762] D loss: 1.3773\n",
      "[1524/1762] D loss: 1.3931\n",
      "[1604/1762] D loss: 1.3763\n",
      "[1684/1762] D loss: 1.3638\n",
      "[1762/1762] D loss: 1.4103\n",
      "train error: \n",
      " D loss: 1.382612, D accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385026, D accuracy: 51.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3776\n",
      "[84/1762] D loss: 1.3646\n",
      "[164/1762] D loss: 1.3754\n",
      "[244/1762] D loss: 1.3846\n",
      "[324/1762] D loss: 1.3793\n",
      "[404/1762] D loss: 1.3821\n",
      "[484/1762] D loss: 1.4001\n",
      "[564/1762] D loss: 1.3964\n",
      "[644/1762] D loss: 1.3870\n",
      "[724/1762] D loss: 1.3753\n",
      "[804/1762] D loss: 1.3832\n",
      "[884/1762] D loss: 1.3965\n",
      "[964/1762] D loss: 1.3886\n",
      "[1044/1762] D loss: 1.3870\n",
      "[1124/1762] D loss: 1.3868\n",
      "[1204/1762] D loss: 1.4041\n",
      "[1284/1762] D loss: 1.3722\n",
      "[1364/1762] D loss: 1.4000\n",
      "[1444/1762] D loss: 1.3770\n",
      "[1524/1762] D loss: 1.3975\n",
      "[1604/1762] D loss: 1.3824\n",
      "[1684/1762] D loss: 1.3985\n",
      "[1762/1762] D loss: 1.3939\n",
      "train error: \n",
      " D loss: 1.382537, D accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383189, D accuracy: 52.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3832\n",
      "[84/1762] D loss: 1.3455\n",
      "[164/1762] D loss: 1.3852\n",
      "[244/1762] D loss: 1.3665\n",
      "[324/1762] D loss: 1.3746\n",
      "[404/1762] D loss: 1.3785\n",
      "[484/1762] D loss: 1.3743\n",
      "[564/1762] D loss: 1.3733\n",
      "[644/1762] D loss: 1.3671\n",
      "[724/1762] D loss: 1.3461\n",
      "[804/1762] D loss: 1.3847\n",
      "[884/1762] D loss: 1.3757\n",
      "[964/1762] D loss: 1.3837\n",
      "[1044/1762] D loss: 1.3913\n",
      "[1124/1762] D loss: 1.3768\n",
      "[1204/1762] D loss: 1.3839\n",
      "[1284/1762] D loss: 1.3915\n",
      "[1364/1762] D loss: 1.3665\n",
      "[1444/1762] D loss: 1.3735\n",
      "[1524/1762] D loss: 1.4119\n",
      "[1604/1762] D loss: 1.3681\n",
      "[1684/1762] D loss: 1.3781\n",
      "[1762/1762] D loss: 1.4079\n",
      "train error: \n",
      " D loss: 1.381873, D accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382794, D accuracy: 51.7% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3774\n",
      "[84/1762] D loss: 1.3984\n",
      "[164/1762] D loss: 1.3841\n",
      "[244/1762] D loss: 1.3770\n",
      "[324/1762] D loss: 1.3793\n",
      "[404/1762] D loss: 1.3832\n",
      "[484/1762] D loss: 1.3882\n",
      "[564/1762] D loss: 1.3661\n",
      "[644/1762] D loss: 1.3895\n",
      "[724/1762] D loss: 1.3744\n",
      "[804/1762] D loss: 1.3722\n",
      "[884/1762] D loss: 1.3846\n",
      "[964/1762] D loss: 1.3770\n",
      "[1044/1762] D loss: 1.3891\n",
      "[1124/1762] D loss: 1.3710\n",
      "[1204/1762] D loss: 1.3834\n",
      "[1284/1762] D loss: 1.3937\n",
      "[1364/1762] D loss: 1.3764\n",
      "[1444/1762] D loss: 1.3901\n",
      "[1524/1762] D loss: 1.3998\n",
      "[1604/1762] D loss: 1.3792\n",
      "[1684/1762] D loss: 1.3799\n",
      "[1762/1762] D loss: 1.3804\n",
      "train error: \n",
      " D loss: 1.381312, D accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382956, D accuracy: 52.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3767\n",
      "[84/1762] D loss: 1.3690\n",
      "[164/1762] D loss: 1.3639\n",
      "[244/1762] D loss: 1.3724\n",
      "[324/1762] D loss: 1.3826\n",
      "[404/1762] D loss: 1.3773\n",
      "[484/1762] D loss: 1.3818\n",
      "[564/1762] D loss: 1.3479\n",
      "[644/1762] D loss: 1.3811\n",
      "[724/1762] D loss: 1.3839\n",
      "[804/1762] D loss: 1.3582\n",
      "[884/1762] D loss: 1.3597\n",
      "[964/1762] D loss: 1.3660\n",
      "[1044/1762] D loss: 1.3813\n",
      "[1124/1762] D loss: 1.3832\n",
      "[1204/1762] D loss: 1.3902\n",
      "[1284/1762] D loss: 1.3591\n",
      "[1364/1762] D loss: 1.3959\n",
      "[1444/1762] D loss: 1.3732\n",
      "[1524/1762] D loss: 1.3776\n",
      "[1604/1762] D loss: 1.3653\n",
      "[1684/1762] D loss: 1.3772\n",
      "[1762/1762] D loss: 1.3946\n",
      "train error: \n",
      " D loss: 1.382057, D accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382098, D accuracy: 51.1% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3542\n",
      "[84/1762] D loss: 1.3819\n",
      "[164/1762] D loss: 1.3779\n",
      "[244/1762] D loss: 1.3818\n",
      "[324/1762] D loss: 1.3707\n",
      "[404/1762] D loss: 1.3823\n",
      "[484/1762] D loss: 1.3860\n",
      "[564/1762] D loss: 1.3721\n",
      "[644/1762] D loss: 1.3888\n",
      "[724/1762] D loss: 1.3773\n",
      "[804/1762] D loss: 1.3853\n",
      "[884/1762] D loss: 1.3742\n",
      "[964/1762] D loss: 1.3643\n",
      "[1044/1762] D loss: 1.3954\n",
      "[1124/1762] D loss: 1.3894\n",
      "[1204/1762] D loss: 1.3851\n",
      "[1284/1762] D loss: 1.3731\n",
      "[1364/1762] D loss: 1.3691\n",
      "[1444/1762] D loss: 1.3818\n",
      "[1524/1762] D loss: 1.3705\n",
      "[1604/1762] D loss: 1.3844\n",
      "[1684/1762] D loss: 1.3910\n",
      "[1762/1762] D loss: 1.3560\n",
      "train error: \n",
      " D loss: 1.381591, D accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380656, D accuracy: 53.8% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869\n",
      "[84/1762] D loss: 1.3780\n",
      "[164/1762] D loss: 1.3669\n",
      "[244/1762] D loss: 1.3834\n",
      "[324/1762] D loss: 1.3576\n",
      "[404/1762] D loss: 1.3908\n",
      "[484/1762] D loss: 1.3831\n",
      "[564/1762] D loss: 1.3805\n",
      "[644/1762] D loss: 1.3853\n",
      "[724/1762] D loss: 1.3835\n",
      "[804/1762] D loss: 1.3911\n",
      "[884/1762] D loss: 1.4044\n",
      "[964/1762] D loss: 1.3744\n",
      "[1044/1762] D loss: 1.4079\n",
      "[1124/1762] D loss: 1.3631\n",
      "[1204/1762] D loss: 1.3842\n",
      "[1284/1762] D loss: 1.3727\n",
      "[1364/1762] D loss: 1.3789\n",
      "[1444/1762] D loss: 1.3642\n",
      "[1524/1762] D loss: 1.3814\n",
      "[1604/1762] D loss: 1.3728\n",
      "[1684/1762] D loss: 1.3948\n",
      "[1762/1762] D loss: 1.3874\n",
      "train error: \n",
      " D loss: 1.380492, D accuracy: 53.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381425, D accuracy: 51.8% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3644\n",
      "[84/1762] D loss: 1.3796\n",
      "[164/1762] D loss: 1.3630\n",
      "[244/1762] D loss: 1.3695\n",
      "[324/1762] D loss: 1.3988\n",
      "[404/1762] D loss: 1.3797\n",
      "[484/1762] D loss: 1.3731\n",
      "[564/1762] D loss: 1.3578\n",
      "[644/1762] D loss: 1.3829\n",
      "[724/1762] D loss: 1.3894\n",
      "[804/1762] D loss: 1.3710\n",
      "[884/1762] D loss: 1.3890\n",
      "[964/1762] D loss: 1.3574\n",
      "[1044/1762] D loss: 1.3653\n",
      "[1124/1762] D loss: 1.3416\n",
      "[1204/1762] D loss: 1.3776\n",
      "[1284/1762] D loss: 1.3692\n",
      "[1364/1762] D loss: 1.4033\n",
      "[1444/1762] D loss: 1.3825\n",
      "[1524/1762] D loss: 1.3504\n",
      "[1604/1762] D loss: 1.3486\n",
      "[1684/1762] D loss: 1.3651\n",
      "[1762/1762] D loss: 1.3717\n",
      "train error: \n",
      " D loss: 1.380150, D accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381653, D accuracy: 53.3% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3851\n",
      "[84/1762] D loss: 1.3801\n",
      "[164/1762] D loss: 1.3795\n",
      "[244/1762] D loss: 1.3738\n",
      "[324/1762] D loss: 1.3689\n",
      "[404/1762] D loss: 1.3775\n",
      "[484/1762] D loss: 1.3851\n",
      "[564/1762] D loss: 1.3752\n",
      "[644/1762] D loss: 1.3773\n",
      "[724/1762] D loss: 1.3987\n",
      "[804/1762] D loss: 1.3815\n",
      "[884/1762] D loss: 1.3753\n",
      "[964/1762] D loss: 1.3763\n",
      "[1044/1762] D loss: 1.3811\n",
      "[1124/1762] D loss: 1.3868\n",
      "[1204/1762] D loss: 1.3646\n",
      "[1284/1762] D loss: 1.3741\n",
      "[1364/1762] D loss: 1.3666\n",
      "[1444/1762] D loss: 1.3722\n",
      "[1524/1762] D loss: 1.3713\n",
      "[1604/1762] D loss: 1.3789\n",
      "[1684/1762] D loss: 1.3808\n",
      "[1762/1762] D loss: 1.3750\n",
      "train error: \n",
      " D loss: 1.381516, D accuracy: 53.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380437, D accuracy: 53.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863\n",
      "[84/1762] D loss: 1.3836\n",
      "[164/1762] D loss: 1.3874\n",
      "[244/1762] D loss: 1.3613\n",
      "[324/1762] D loss: 1.3976\n",
      "[404/1762] D loss: 1.3877\n",
      "[484/1762] D loss: 1.3755\n",
      "[564/1762] D loss: 1.3607\n",
      "[644/1762] D loss: 1.3838\n",
      "[724/1762] D loss: 1.3879\n",
      "[804/1762] D loss: 1.3738\n",
      "[884/1762] D loss: 1.3849\n",
      "[964/1762] D loss: 1.3717\n",
      "[1044/1762] D loss: 1.3621\n",
      "[1124/1762] D loss: 1.3949\n",
      "[1204/1762] D loss: 1.3798\n",
      "[1284/1762] D loss: 1.3725\n",
      "[1364/1762] D loss: 1.3936\n",
      "[1444/1762] D loss: 1.3721\n",
      "[1524/1762] D loss: 1.3506\n",
      "[1604/1762] D loss: 1.3773\n",
      "[1684/1762] D loss: 1.3649\n",
      "[1762/1762] D loss: 1.3871\n",
      "train error: \n",
      " D loss: 1.380542, D accuracy: 52.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379360, D accuracy: 53.3% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917\n",
      "[84/1762] D loss: 1.3797\n",
      "[164/1762] D loss: 1.3594\n",
      "[244/1762] D loss: 1.3831\n",
      "[324/1762] D loss: 1.3892\n",
      "[404/1762] D loss: 1.3757\n",
      "[484/1762] D loss: 1.3967\n",
      "[564/1762] D loss: 1.3815\n",
      "[644/1762] D loss: 1.3703\n",
      "[724/1762] D loss: 1.3817\n",
      "[804/1762] D loss: 1.3994\n",
      "[884/1762] D loss: 1.3881\n",
      "[964/1762] D loss: 1.3821\n",
      "[1044/1762] D loss: 1.3766\n",
      "[1124/1762] D loss: 1.3630\n",
      "[1204/1762] D loss: 1.3627\n",
      "[1284/1762] D loss: 1.3684\n",
      "[1364/1762] D loss: 1.3816\n",
      "[1444/1762] D loss: 1.3720\n",
      "[1524/1762] D loss: 1.3648\n",
      "[1604/1762] D loss: 1.3721\n",
      "[1684/1762] D loss: 1.3773\n",
      "[1762/1762] D loss: 1.3346\n",
      "train error: \n",
      " D loss: 1.379581, D accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378265, D accuracy: 53.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3714\n",
      "[84/1762] D loss: 1.3794\n",
      "[164/1762] D loss: 1.3729\n",
      "[244/1762] D loss: 1.3670\n",
      "[324/1762] D loss: 1.3762\n",
      "[404/1762] D loss: 1.3608\n",
      "[484/1762] D loss: 1.3786\n",
      "[564/1762] D loss: 1.3763\n",
      "[644/1762] D loss: 1.3779\n",
      "[724/1762] D loss: 1.3844\n",
      "[804/1762] D loss: 1.3988\n",
      "[884/1762] D loss: 1.3700\n",
      "[964/1762] D loss: 1.3618\n",
      "[1044/1762] D loss: 1.3766\n",
      "[1124/1762] D loss: 1.3899\n",
      "[1204/1762] D loss: 1.3876\n",
      "[1284/1762] D loss: 1.3813\n",
      "[1364/1762] D loss: 1.3717\n",
      "[1444/1762] D loss: 1.3696\n",
      "[1524/1762] D loss: 1.3957\n",
      "[1604/1762] D loss: 1.3721\n",
      "[1684/1762] D loss: 1.3631\n",
      "[1762/1762] D loss: 1.3900\n",
      "train error: \n",
      " D loss: 1.380641, D accuracy: 52.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379142, D accuracy: 53.9% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3628\n",
      "[84/1762] D loss: 1.3887\n",
      "[164/1762] D loss: 1.3552\n",
      "[244/1762] D loss: 1.3946\n",
      "[324/1762] D loss: 1.3543\n",
      "[404/1762] D loss: 1.3972\n",
      "[484/1762] D loss: 1.3453\n",
      "[564/1762] D loss: 1.3774\n",
      "[644/1762] D loss: 1.3471\n",
      "[724/1762] D loss: 1.3669\n",
      "[804/1762] D loss: 1.3532\n",
      "[884/1762] D loss: 1.3999\n",
      "[964/1762] D loss: 1.3740\n",
      "[1044/1762] D loss: 1.3580\n",
      "[1124/1762] D loss: 1.3768\n",
      "[1204/1762] D loss: 1.3648\n",
      "[1284/1762] D loss: 1.3670\n",
      "[1364/1762] D loss: 1.3559\n",
      "[1444/1762] D loss: 1.3719\n",
      "[1524/1762] D loss: 1.3670\n",
      "[1604/1762] D loss: 1.3637\n",
      "[1684/1762] D loss: 1.3620\n",
      "[1762/1762] D loss: 1.3901\n",
      "train error: \n",
      " D loss: 1.379512, D accuracy: 54.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378451, D accuracy: 54.7% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3691\n",
      "[84/1762] D loss: 1.3829\n",
      "[164/1762] D loss: 1.3917\n",
      "[244/1762] D loss: 1.3880\n",
      "[324/1762] D loss: 1.3784\n",
      "[404/1762] D loss: 1.3790\n",
      "[484/1762] D loss: 1.3790\n",
      "[564/1762] D loss: 1.3752\n",
      "[644/1762] D loss: 1.3794\n",
      "[724/1762] D loss: 1.3806\n",
      "[804/1762] D loss: 1.3497\n",
      "[884/1762] D loss: 1.3766\n",
      "[964/1762] D loss: 1.3552\n",
      "[1044/1762] D loss: 1.3771\n",
      "[1124/1762] D loss: 1.3625\n",
      "[1204/1762] D loss: 1.3803\n",
      "[1284/1762] D loss: 1.3708\n",
      "[1364/1762] D loss: 1.3500\n",
      "[1444/1762] D loss: 1.3834\n",
      "[1524/1762] D loss: 1.3814\n",
      "[1604/1762] D loss: 1.3708\n",
      "[1684/1762] D loss: 1.3700\n",
      "[1762/1762] D loss: 1.3801\n",
      "train error: \n",
      " D loss: 1.378914, D accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378289, D accuracy: 53.4% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3936\n",
      "[84/1762] D loss: 1.3904\n",
      "[164/1762] D loss: 1.3905\n",
      "[244/1762] D loss: 1.3916\n",
      "[324/1762] D loss: 1.3941\n",
      "[404/1762] D loss: 1.3735\n",
      "[484/1762] D loss: 1.3650\n",
      "[564/1762] D loss: 1.3630\n",
      "[644/1762] D loss: 1.3709\n",
      "[724/1762] D loss: 1.3814\n",
      "[804/1762] D loss: 1.3807\n",
      "[884/1762] D loss: 1.3565\n",
      "[964/1762] D loss: 1.3483\n",
      "[1044/1762] D loss: 1.3665\n",
      "[1124/1762] D loss: 1.3673\n",
      "[1204/1762] D loss: 1.3891\n",
      "[1284/1762] D loss: 1.3767\n",
      "[1364/1762] D loss: 1.3812\n",
      "[1444/1762] D loss: 1.3825\n",
      "[1524/1762] D loss: 1.3710\n",
      "[1604/1762] D loss: 1.3663\n",
      "[1684/1762] D loss: 1.3461\n",
      "[1762/1762] D loss: 1.3668\n",
      "train error: \n",
      " D loss: 1.379206, D accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378622, D accuracy: 53.8% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3726\n",
      "[84/1762] D loss: 1.3897\n",
      "[164/1762] D loss: 1.3911\n",
      "[244/1762] D loss: 1.3620\n",
      "[324/1762] D loss: 1.3944\n",
      "[404/1762] D loss: 1.3696\n",
      "[484/1762] D loss: 1.3684\n",
      "[564/1762] D loss: 1.3806\n",
      "[644/1762] D loss: 1.3573\n",
      "[724/1762] D loss: 1.3898\n",
      "[804/1762] D loss: 1.3782\n",
      "[884/1762] D loss: 1.3732\n",
      "[964/1762] D loss: 1.3389\n",
      "[1044/1762] D loss: 1.3729\n",
      "[1124/1762] D loss: 1.3891\n",
      "[1204/1762] D loss: 1.3763\n",
      "[1284/1762] D loss: 1.3880\n",
      "[1364/1762] D loss: 1.3812\n",
      "[1444/1762] D loss: 1.3667\n",
      "[1524/1762] D loss: 1.3975\n",
      "[1604/1762] D loss: 1.3749\n",
      "[1684/1762] D loss: 1.3572\n",
      "[1762/1762] D loss: 1.3487\n",
      "train error: \n",
      " D loss: 1.378704, D accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377501, D accuracy: 53.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886\n",
      "[84/1762] D loss: 1.3925\n",
      "[164/1762] D loss: 1.3900\n",
      "[244/1762] D loss: 1.3851\n",
      "[324/1762] D loss: 1.3588\n",
      "[404/1762] D loss: 1.3695\n",
      "[484/1762] D loss: 1.3620\n",
      "[564/1762] D loss: 1.3614\n",
      "[644/1762] D loss: 1.3684\n",
      "[724/1762] D loss: 1.3587\n",
      "[804/1762] D loss: 1.3776\n",
      "[884/1762] D loss: 1.3474\n",
      "[964/1762] D loss: 1.3674\n",
      "[1044/1762] D loss: 1.3668\n",
      "[1124/1762] D loss: 1.3612\n",
      "[1204/1762] D loss: 1.3882\n",
      "[1284/1762] D loss: 1.3675\n",
      "[1364/1762] D loss: 1.3902\n",
      "[1444/1762] D loss: 1.3650\n",
      "[1524/1762] D loss: 1.3418\n",
      "[1604/1762] D loss: 1.3719\n",
      "[1684/1762] D loss: 1.3570\n",
      "[1762/1762] D loss: 1.3552\n",
      "train error: \n",
      " D loss: 1.378490, D accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378392, D accuracy: 53.8% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891\n",
      "[84/1762] D loss: 1.3839\n",
      "[164/1762] D loss: 1.3607\n",
      "[244/1762] D loss: 1.3693\n",
      "[324/1762] D loss: 1.3556\n",
      "[404/1762] D loss: 1.3686\n",
      "[484/1762] D loss: 1.3724\n",
      "[564/1762] D loss: 1.3574\n",
      "[644/1762] D loss: 1.3875\n",
      "[724/1762] D loss: 1.3924\n",
      "[804/1762] D loss: 1.3906\n",
      "[884/1762] D loss: 1.3824\n",
      "[964/1762] D loss: 1.3773\n",
      "[1044/1762] D loss: 1.3726\n",
      "[1124/1762] D loss: 1.3539\n",
      "[1204/1762] D loss: 1.3578\n",
      "[1284/1762] D loss: 1.3824\n",
      "[1364/1762] D loss: 1.3715\n",
      "[1444/1762] D loss: 1.3843\n",
      "[1524/1762] D loss: 1.3485\n",
      "[1604/1762] D loss: 1.4025\n",
      "[1684/1762] D loss: 1.4055\n",
      "[1762/1762] D loss: 1.3233\n",
      "train error: \n",
      " D loss: 1.378168, D accuracy: 53.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378866, D accuracy: 52.8% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3729\n",
      "[84/1762] D loss: 1.3850\n",
      "[164/1762] D loss: 1.3597\n",
      "[244/1762] D loss: 1.3720\n",
      "[324/1762] D loss: 1.3790\n",
      "[404/1762] D loss: 1.3873\n",
      "[484/1762] D loss: 1.3858\n",
      "[564/1762] D loss: 1.3728\n",
      "[644/1762] D loss: 1.3464\n",
      "[724/1762] D loss: 1.3873\n",
      "[804/1762] D loss: 1.3620\n",
      "[884/1762] D loss: 1.3788\n",
      "[964/1762] D loss: 1.3679\n",
      "[1044/1762] D loss: 1.3651\n",
      "[1124/1762] D loss: 1.3675\n",
      "[1204/1762] D loss: 1.3771\n",
      "[1284/1762] D loss: 1.3618\n",
      "[1364/1762] D loss: 1.3876\n",
      "[1444/1762] D loss: 1.3844\n",
      "[1524/1762] D loss: 1.3570\n",
      "[1604/1762] D loss: 1.3718\n",
      "[1684/1762] D loss: 1.3799\n",
      "[1762/1762] D loss: 1.3745\n",
      "train error: \n",
      " D loss: 1.378930, D accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376534, D accuracy: 54.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874\n",
      "[84/1762] D loss: 1.3805\n",
      "[164/1762] D loss: 1.3715\n",
      "[244/1762] D loss: 1.3808\n",
      "[324/1762] D loss: 1.3590\n",
      "[404/1762] D loss: 1.3710\n",
      "[484/1762] D loss: 1.3690\n",
      "[564/1762] D loss: 1.3985\n",
      "[644/1762] D loss: 1.3392\n",
      "[724/1762] D loss: 1.3678\n",
      "[804/1762] D loss: 1.3922\n",
      "[884/1762] D loss: 1.3758\n",
      "[964/1762] D loss: 1.3950\n",
      "[1044/1762] D loss: 1.3670\n",
      "[1124/1762] D loss: 1.3589\n",
      "[1204/1762] D loss: 1.3675\n",
      "[1284/1762] D loss: 1.3889\n",
      "[1364/1762] D loss: 1.3618\n",
      "[1444/1762] D loss: 1.3706\n",
      "[1524/1762] D loss: 1.3539\n",
      "[1604/1762] D loss: 1.3840\n",
      "[1684/1762] D loss: 1.3995\n",
      "[1762/1762] D loss: 1.3752\n",
      "train error: \n",
      " D loss: 1.378048, D accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376727, D accuracy: 54.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909\n",
      "[84/1762] D loss: 1.3745\n",
      "[164/1762] D loss: 1.3935\n",
      "[244/1762] D loss: 1.3681\n",
      "[324/1762] D loss: 1.3766\n",
      "[404/1762] D loss: 1.3525\n",
      "[484/1762] D loss: 1.3690\n",
      "[564/1762] D loss: 1.3775\n",
      "[644/1762] D loss: 1.3763\n",
      "[724/1762] D loss: 1.3712\n",
      "[804/1762] D loss: 1.3619\n",
      "[884/1762] D loss: 1.3557\n",
      "[964/1762] D loss: 1.3880\n",
      "[1044/1762] D loss: 1.3690\n",
      "[1124/1762] D loss: 1.3746\n",
      "[1204/1762] D loss: 1.3622\n",
      "[1284/1762] D loss: 1.3489\n",
      "[1364/1762] D loss: 1.3720\n",
      "[1444/1762] D loss: 1.3581\n",
      "[1524/1762] D loss: 1.3786\n",
      "[1604/1762] D loss: 1.3945\n",
      "[1684/1762] D loss: 1.3602\n",
      "[1762/1762] D loss: 1.3667\n",
      "train error: \n",
      " D loss: 1.376543, D accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377319, D accuracy: 54.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3551\n",
      "[84/1762] D loss: 1.3748\n",
      "[164/1762] D loss: 1.3817\n",
      "[244/1762] D loss: 1.3390\n",
      "[324/1762] D loss: 1.3686\n",
      "[404/1762] D loss: 1.3732\n",
      "[484/1762] D loss: 1.3398\n",
      "[564/1762] D loss: 1.3450\n",
      "[644/1762] D loss: 1.3751\n",
      "[724/1762] D loss: 1.3791\n",
      "[804/1762] D loss: 1.3780\n",
      "[884/1762] D loss: 1.4035\n",
      "[964/1762] D loss: 1.3636\n",
      "[1044/1762] D loss: 1.3558\n",
      "[1124/1762] D loss: 1.3672\n",
      "[1204/1762] D loss: 1.3738\n",
      "[1284/1762] D loss: 1.3801\n",
      "[1364/1762] D loss: 1.3692\n",
      "[1444/1762] D loss: 1.3728\n",
      "[1524/1762] D loss: 1.3449\n",
      "[1604/1762] D loss: 1.3748\n",
      "[1684/1762] D loss: 1.3689\n",
      "[1762/1762] D loss: 1.3116\n",
      "train error: \n",
      " D loss: 1.376905, D accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378348, D accuracy: 55.9% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3783\n",
      "[84/1762] D loss: 1.3694\n",
      "[164/1762] D loss: 1.3689\n",
      "[244/1762] D loss: 1.3457\n",
      "[324/1762] D loss: 1.3943\n",
      "[404/1762] D loss: 1.3767\n",
      "[484/1762] D loss: 1.3588\n",
      "[564/1762] D loss: 1.3660\n",
      "[644/1762] D loss: 1.3929\n",
      "[724/1762] D loss: 1.3755\n",
      "[804/1762] D loss: 1.3843\n",
      "[884/1762] D loss: 1.3840\n",
      "[964/1762] D loss: 1.3685\n",
      "[1044/1762] D loss: 1.3659\n",
      "[1124/1762] D loss: 1.3767\n",
      "[1204/1762] D loss: 1.3744\n",
      "[1284/1762] D loss: 1.3506\n",
      "[1364/1762] D loss: 1.3644\n",
      "[1444/1762] D loss: 1.3841\n",
      "[1524/1762] D loss: 1.3496\n",
      "[1604/1762] D loss: 1.3392\n",
      "[1684/1762] D loss: 1.3926\n",
      "[1762/1762] D loss: 1.3986\n",
      "train error: \n",
      " D loss: 1.376928, D accuracy: 55.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375611, D accuracy: 55.9% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3793\n",
      "[84/1762] D loss: 1.3978\n",
      "[164/1762] D loss: 1.3523\n",
      "[244/1762] D loss: 1.3809\n",
      "[324/1762] D loss: 1.3793\n",
      "[404/1762] D loss: 1.3749\n",
      "[484/1762] D loss: 1.3844\n",
      "[564/1762] D loss: 1.3621\n",
      "[644/1762] D loss: 1.3548\n",
      "[724/1762] D loss: 1.3603\n",
      "[804/1762] D loss: 1.3585\n",
      "[884/1762] D loss: 1.3852\n",
      "[964/1762] D loss: 1.3908\n",
      "[1044/1762] D loss: 1.3928\n",
      "[1124/1762] D loss: 1.3770\n",
      "[1204/1762] D loss: 1.4148\n",
      "[1284/1762] D loss: 1.3924\n",
      "[1364/1762] D loss: 1.3939\n",
      "[1444/1762] D loss: 1.3886\n",
      "[1524/1762] D loss: 1.3949\n",
      "[1604/1762] D loss: 1.3966\n",
      "[1684/1762] D loss: 1.3816\n",
      "[1762/1762] D loss: 1.3654\n",
      "train error: \n",
      " D loss: 1.377759, D accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375500, D accuracy: 54.3% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4080\n",
      "[84/1762] D loss: 1.3756\n",
      "[164/1762] D loss: 1.3782\n",
      "[244/1762] D loss: 1.3974\n",
      "[324/1762] D loss: 1.3568\n",
      "[404/1762] D loss: 1.3496\n",
      "[484/1762] D loss: 1.3562\n",
      "[564/1762] D loss: 1.3487\n",
      "[644/1762] D loss: 1.3910\n",
      "[724/1762] D loss: 1.3976\n",
      "[804/1762] D loss: 1.3586\n",
      "[884/1762] D loss: 1.3795\n",
      "[964/1762] D loss: 1.3615\n",
      "[1044/1762] D loss: 1.3802\n",
      "[1124/1762] D loss: 1.3658\n",
      "[1204/1762] D loss: 1.3806\n",
      "[1284/1762] D loss: 1.3265\n",
      "[1364/1762] D loss: 1.3750\n",
      "[1444/1762] D loss: 1.3906\n",
      "[1524/1762] D loss: 1.3538\n",
      "[1604/1762] D loss: 1.3693\n",
      "[1684/1762] D loss: 1.3727\n",
      "[1762/1762] D loss: 1.3834\n",
      "train error: \n",
      " D loss: 1.377074, D accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375521, D accuracy: 55.2% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3551\n",
      "[84/1762] D loss: 1.3858\n",
      "[164/1762] D loss: 1.3335\n",
      "[244/1762] D loss: 1.3913\n",
      "[324/1762] D loss: 1.3780\n",
      "[404/1762] D loss: 1.3751\n",
      "[484/1762] D loss: 1.3634\n",
      "[564/1762] D loss: 1.3867\n",
      "[644/1762] D loss: 1.3666\n",
      "[724/1762] D loss: 1.3699\n",
      "[804/1762] D loss: 1.3749\n",
      "[884/1762] D loss: 1.3528\n",
      "[964/1762] D loss: 1.3496\n",
      "[1044/1762] D loss: 1.3521\n",
      "[1124/1762] D loss: 1.3633\n",
      "[1204/1762] D loss: 1.3674\n",
      "[1284/1762] D loss: 1.3626\n",
      "[1364/1762] D loss: 1.3724\n",
      "[1444/1762] D loss: 1.3566\n",
      "[1524/1762] D loss: 1.3696\n",
      "[1604/1762] D loss: 1.3534\n",
      "[1684/1762] D loss: 1.3969\n",
      "[1762/1762] D loss: 1.4175\n",
      "train error: \n",
      " D loss: 1.377661, D accuracy: 53.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376182, D accuracy: 54.1% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4183\n",
      "[84/1762] D loss: 1.4122\n",
      "[164/1762] D loss: 1.4109\n",
      "[244/1762] D loss: 1.4202\n",
      "[324/1762] D loss: 1.4204\n",
      "[404/1762] D loss: 1.4277\n",
      "[484/1762] D loss: 1.3932\n",
      "[564/1762] D loss: 1.4020\n",
      "[644/1762] D loss: 1.4337\n",
      "[724/1762] D loss: 1.4090\n",
      "[804/1762] D loss: 1.4022\n",
      "[884/1762] D loss: 1.4135\n",
      "[964/1762] D loss: 1.4191\n",
      "[1044/1762] D loss: 1.4163\n",
      "[1124/1762] D loss: 1.4126\n",
      "[1204/1762] D loss: 1.4012\n",
      "[1284/1762] D loss: 1.3993\n",
      "[1364/1762] D loss: 1.4003\n",
      "[1444/1762] D loss: 1.4202\n",
      "[1524/1762] D loss: 1.4153\n",
      "[1604/1762] D loss: 1.4114\n",
      "[1684/1762] D loss: 1.4201\n",
      "[1762/1762] D loss: 1.4033\n",
      "train error: \n",
      " D loss: 1.413445, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.414795, D accuracy: 50.1% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4033\n",
      "[84/1762] D loss: 1.4129\n",
      "[164/1762] D loss: 1.4202\n",
      "[244/1762] D loss: 1.4218\n",
      "[324/1762] D loss: 1.4106\n",
      "[404/1762] D loss: 1.4182\n",
      "[484/1762] D loss: 1.4082\n",
      "[564/1762] D loss: 1.4148\n",
      "[644/1762] D loss: 1.4053\n",
      "[724/1762] D loss: 1.4221\n",
      "[804/1762] D loss: 1.4232\n",
      "[884/1762] D loss: 1.4207\n",
      "[964/1762] D loss: 1.3851\n",
      "[1044/1762] D loss: 1.4109\n",
      "[1124/1762] D loss: 1.3910\n",
      "[1204/1762] D loss: 1.4037\n",
      "[1284/1762] D loss: 1.4122\n",
      "[1364/1762] D loss: 1.4260\n",
      "[1444/1762] D loss: 1.4030\n",
      "[1524/1762] D loss: 1.4214\n",
      "[1604/1762] D loss: 1.4151\n",
      "[1684/1762] D loss: 1.4040\n",
      "[1762/1762] D loss: 1.4069\n",
      "train error: \n",
      " D loss: 1.408414, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408809, D accuracy: 50.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3992\n",
      "[84/1762] D loss: 1.3940\n",
      "[164/1762] D loss: 1.4079\n",
      "[244/1762] D loss: 1.3876\n",
      "[324/1762] D loss: 1.4135\n",
      "[404/1762] D loss: 1.4124\n",
      "[484/1762] D loss: 1.3875\n",
      "[564/1762] D loss: 1.4094\n",
      "[644/1762] D loss: 1.4204\n",
      "[724/1762] D loss: 1.3994\n",
      "[804/1762] D loss: 1.4090\n",
      "[884/1762] D loss: 1.4100\n",
      "[964/1762] D loss: 1.3974\n",
      "[1044/1762] D loss: 1.4231\n",
      "[1124/1762] D loss: 1.4076\n",
      "[1204/1762] D loss: 1.4063\n",
      "[1284/1762] D loss: 1.3948\n",
      "[1364/1762] D loss: 1.3816\n",
      "[1444/1762] D loss: 1.3727\n",
      "[1524/1762] D loss: 1.4052\n",
      "[1604/1762] D loss: 1.3882\n",
      "[1684/1762] D loss: 1.4012\n",
      "[1762/1762] D loss: 1.4269\n",
      "train error: \n",
      " D loss: 1.403069, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402686, D accuracy: 50.1% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4162\n",
      "[84/1762] D loss: 1.4118\n",
      "[164/1762] D loss: 1.4237\n",
      "[244/1762] D loss: 1.3996\n",
      "[324/1762] D loss: 1.4153\n",
      "[404/1762] D loss: 1.4045\n",
      "[484/1762] D loss: 1.4047\n",
      "[564/1762] D loss: 1.3949\n",
      "[644/1762] D loss: 1.4019\n",
      "[724/1762] D loss: 1.4144\n",
      "[804/1762] D loss: 1.3986\n",
      "[884/1762] D loss: 1.4076\n",
      "[964/1762] D loss: 1.4084\n",
      "[1044/1762] D loss: 1.4061\n",
      "[1124/1762] D loss: 1.4080\n",
      "[1204/1762] D loss: 1.4058\n",
      "[1284/1762] D loss: 1.4083\n",
      "[1364/1762] D loss: 1.4085\n",
      "[1444/1762] D loss: 1.4016\n",
      "[1524/1762] D loss: 1.4118\n",
      "[1604/1762] D loss: 1.4019\n",
      "[1684/1762] D loss: 1.3938\n",
      "[1762/1762] D loss: 1.3986\n",
      "train error: \n",
      " D loss: 1.400431, D accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402094, D accuracy: 50.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4000\n",
      "[84/1762] D loss: 1.3810\n",
      "[164/1762] D loss: 1.4020\n",
      "[244/1762] D loss: 1.3928\n",
      "[324/1762] D loss: 1.4002\n",
      "[404/1762] D loss: 1.4083\n",
      "[484/1762] D loss: 1.4106\n",
      "[564/1762] D loss: 1.4032\n",
      "[644/1762] D loss: 1.4057\n",
      "[724/1762] D loss: 1.4082\n",
      "[804/1762] D loss: 1.4010\n",
      "[884/1762] D loss: 1.3954\n",
      "[964/1762] D loss: 1.3977\n",
      "[1044/1762] D loss: 1.4220\n",
      "[1124/1762] D loss: 1.4007\n",
      "[1204/1762] D loss: 1.4084\n",
      "[1284/1762] D loss: 1.3978\n",
      "[1364/1762] D loss: 1.4024\n",
      "[1444/1762] D loss: 1.4172\n",
      "[1524/1762] D loss: 1.4100\n",
      "[1604/1762] D loss: 1.4035\n",
      "[1684/1762] D loss: 1.4107\n",
      "[1762/1762] D loss: 1.3904\n",
      "train error: \n",
      " D loss: 1.399160, D accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400358, D accuracy: 50.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899\n",
      "[84/1762] D loss: 1.4036\n",
      "[164/1762] D loss: 1.3832\n",
      "[244/1762] D loss: 1.3867\n",
      "[324/1762] D loss: 1.3995\n",
      "[404/1762] D loss: 1.4192\n",
      "[484/1762] D loss: 1.3888\n",
      "[564/1762] D loss: 1.3982\n",
      "[644/1762] D loss: 1.4028\n",
      "[724/1762] D loss: 1.4028\n",
      "[804/1762] D loss: 1.3949\n",
      "[884/1762] D loss: 1.3762\n",
      "[964/1762] D loss: 1.4093\n",
      "[1044/1762] D loss: 1.3920\n",
      "[1124/1762] D loss: 1.4117\n",
      "[1204/1762] D loss: 1.4023\n",
      "[1284/1762] D loss: 1.3925\n",
      "[1364/1762] D loss: 1.3902\n",
      "[1444/1762] D loss: 1.4107\n",
      "[1524/1762] D loss: 1.4020\n",
      "[1604/1762] D loss: 1.3910\n",
      "[1684/1762] D loss: 1.3985\n",
      "[1762/1762] D loss: 1.3711\n",
      "train error: \n",
      " D loss: 1.399110, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400570, D accuracy: 50.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3989\n",
      "[84/1762] D loss: 1.3824\n",
      "[164/1762] D loss: 1.4044\n",
      "[244/1762] D loss: 1.3953\n",
      "[324/1762] D loss: 1.3860\n",
      "[404/1762] D loss: 1.4057\n",
      "[484/1762] D loss: 1.4033\n",
      "[564/1762] D loss: 1.3937\n",
      "[644/1762] D loss: 1.3826\n",
      "[724/1762] D loss: 1.3859\n",
      "[804/1762] D loss: 1.3785\n",
      "[884/1762] D loss: 1.4053\n",
      "[964/1762] D loss: 1.4227\n",
      "[1044/1762] D loss: 1.3960\n",
      "[1124/1762] D loss: 1.4051\n",
      "[1204/1762] D loss: 1.3950\n",
      "[1284/1762] D loss: 1.3968\n",
      "[1364/1762] D loss: 1.3914\n",
      "[1444/1762] D loss: 1.3947\n",
      "[1524/1762] D loss: 1.4009\n",
      "[1604/1762] D loss: 1.3878\n",
      "[1684/1762] D loss: 1.3906\n",
      "[1762/1762] D loss: 1.3942\n",
      "train error: \n",
      " D loss: 1.397762, D accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398751, D accuracy: 50.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958\n",
      "[84/1762] D loss: 1.3927\n",
      "[164/1762] D loss: 1.4019\n",
      "[244/1762] D loss: 1.3922\n",
      "[324/1762] D loss: 1.3949\n",
      "[404/1762] D loss: 1.3965\n",
      "[484/1762] D loss: 1.4006\n",
      "[564/1762] D loss: 1.3783\n",
      "[644/1762] D loss: 1.3911\n",
      "[724/1762] D loss: 1.3777\n",
      "[804/1762] D loss: 1.4057\n",
      "[884/1762] D loss: 1.3884\n",
      "[964/1762] D loss: 1.3901\n",
      "[1044/1762] D loss: 1.3950\n",
      "[1124/1762] D loss: 1.3818\n",
      "[1204/1762] D loss: 1.3744\n",
      "[1284/1762] D loss: 1.3987\n",
      "[1364/1762] D loss: 1.3846\n",
      "[1444/1762] D loss: 1.3706\n",
      "[1524/1762] D loss: 1.3874\n",
      "[1604/1762] D loss: 1.4095\n",
      "[1684/1762] D loss: 1.3963\n",
      "[1762/1762] D loss: 1.3752\n",
      "train error: \n",
      " D loss: 1.396475, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396978, D accuracy: 50.1% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4112\n",
      "[84/1762] D loss: 1.4027\n",
      "[164/1762] D loss: 1.4049\n",
      "[244/1762] D loss: 1.4033\n",
      "[324/1762] D loss: 1.3936\n",
      "[404/1762] D loss: 1.3988\n",
      "[484/1762] D loss: 1.3955\n",
      "[564/1762] D loss: 1.3909\n",
      "[644/1762] D loss: 1.4157\n",
      "[724/1762] D loss: 1.3942\n",
      "[804/1762] D loss: 1.3781\n",
      "[884/1762] D loss: 1.3929\n",
      "[964/1762] D loss: 1.4007\n",
      "[1044/1762] D loss: 1.3809\n",
      "[1124/1762] D loss: 1.3801\n",
      "[1204/1762] D loss: 1.4074\n",
      "[1284/1762] D loss: 1.4063\n",
      "[1364/1762] D loss: 1.3931\n",
      "[1444/1762] D loss: 1.4130\n",
      "[1524/1762] D loss: 1.3900\n",
      "[1604/1762] D loss: 1.3985\n",
      "[1684/1762] D loss: 1.3965\n",
      "[1762/1762] D loss: 1.3923\n",
      "train error: \n",
      " D loss: 1.394144, D accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394729, D accuracy: 50.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931\n",
      "[84/1762] D loss: 1.3956\n",
      "[164/1762] D loss: 1.3752\n",
      "[244/1762] D loss: 1.3972\n",
      "[324/1762] D loss: 1.3987\n",
      "[404/1762] D loss: 1.4054\n",
      "[484/1762] D loss: 1.4048\n",
      "[564/1762] D loss: 1.4039\n",
      "[644/1762] D loss: 1.3883\n",
      "[724/1762] D loss: 1.3835\n",
      "[804/1762] D loss: 1.4049\n",
      "[884/1762] D loss: 1.4000\n",
      "[964/1762] D loss: 1.4020\n",
      "[1044/1762] D loss: 1.3934\n",
      "[1124/1762] D loss: 1.4010\n",
      "[1204/1762] D loss: 1.3980\n",
      "[1284/1762] D loss: 1.3911\n",
      "[1364/1762] D loss: 1.3979\n",
      "[1444/1762] D loss: 1.4059\n",
      "[1524/1762] D loss: 1.4064\n",
      "[1604/1762] D loss: 1.3833\n",
      "[1684/1762] D loss: 1.4038\n",
      "[1762/1762] D loss: 1.3695\n",
      "train error: \n",
      " D loss: 1.392362, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393825, D accuracy: 50.3% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3785\n",
      "[84/1762] D loss: 1.4041\n",
      "[164/1762] D loss: 1.4006\n",
      "[244/1762] D loss: 1.3926\n",
      "[324/1762] D loss: 1.3919\n",
      "[404/1762] D loss: 1.3988\n",
      "[484/1762] D loss: 1.3906\n",
      "[564/1762] D loss: 1.3905\n",
      "[644/1762] D loss: 1.4231\n",
      "[724/1762] D loss: 1.4004\n",
      "[804/1762] D loss: 1.3926\n",
      "[884/1762] D loss: 1.3861\n",
      "[964/1762] D loss: 1.4004\n",
      "[1044/1762] D loss: 1.3815\n",
      "[1124/1762] D loss: 1.3818\n",
      "[1204/1762] D loss: 1.3998\n",
      "[1284/1762] D loss: 1.3845\n",
      "[1364/1762] D loss: 1.4064\n",
      "[1444/1762] D loss: 1.3981\n",
      "[1524/1762] D loss: 1.3846\n",
      "[1604/1762] D loss: 1.3992\n",
      "[1684/1762] D loss: 1.3830\n",
      "[1762/1762] D loss: 1.3823\n",
      "train error: \n",
      " D loss: 1.391182, D accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391781, D accuracy: 50.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951\n",
      "[84/1762] D loss: 1.3913\n",
      "[164/1762] D loss: 1.3916\n",
      "[244/1762] D loss: 1.3918\n",
      "[324/1762] D loss: 1.3951\n",
      "[404/1762] D loss: 1.3992\n",
      "[484/1762] D loss: 1.3925\n",
      "[564/1762] D loss: 1.3713\n",
      "[644/1762] D loss: 1.3927\n",
      "[724/1762] D loss: 1.3830\n",
      "[804/1762] D loss: 1.4009\n",
      "[884/1762] D loss: 1.3988\n",
      "[964/1762] D loss: 1.3915\n",
      "[1044/1762] D loss: 1.3955\n",
      "[1124/1762] D loss: 1.3903\n",
      "[1204/1762] D loss: 1.3881\n",
      "[1284/1762] D loss: 1.3868\n",
      "[1364/1762] D loss: 1.3921\n",
      "[1444/1762] D loss: 1.3915\n",
      "[1524/1762] D loss: 1.4030\n",
      "[1604/1762] D loss: 1.3778\n",
      "[1684/1762] D loss: 1.3899\n",
      "[1762/1762] D loss: 1.3865\n",
      "train error: \n",
      " D loss: 1.391988, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392593, D accuracy: 50.1% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891\n",
      "[84/1762] D loss: 1.3826\n",
      "[164/1762] D loss: 1.3995\n",
      "[244/1762] D loss: 1.3964\n",
      "[324/1762] D loss: 1.3780\n",
      "[404/1762] D loss: 1.3930\n",
      "[484/1762] D loss: 1.3774\n",
      "[564/1762] D loss: 1.3943\n",
      "[644/1762] D loss: 1.3942\n",
      "[724/1762] D loss: 1.3698\n",
      "[804/1762] D loss: 1.3979\n",
      "[884/1762] D loss: 1.3854\n",
      "[964/1762] D loss: 1.3959\n",
      "[1044/1762] D loss: 1.3912\n",
      "[1124/1762] D loss: 1.3944\n",
      "[1204/1762] D loss: 1.4001\n",
      "[1284/1762] D loss: 1.3916\n",
      "[1364/1762] D loss: 1.3888\n",
      "[1444/1762] D loss: 1.4129\n",
      "[1524/1762] D loss: 1.3822\n",
      "[1604/1762] D loss: 1.3952\n",
      "[1684/1762] D loss: 1.3909\n",
      "[1762/1762] D loss: 1.3913\n",
      "train error: \n",
      " D loss: 1.389899, D accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390051, D accuracy: 50.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3967\n",
      "[84/1762] D loss: 1.3812\n",
      "[164/1762] D loss: 1.3977\n",
      "[244/1762] D loss: 1.4016\n",
      "[324/1762] D loss: 1.3747\n",
      "[404/1762] D loss: 1.4025\n",
      "[484/1762] D loss: 1.3990\n",
      "[564/1762] D loss: 1.3939\n",
      "[644/1762] D loss: 1.3798\n",
      "[724/1762] D loss: 1.3892\n",
      "[804/1762] D loss: 1.4014\n",
      "[884/1762] D loss: 1.3960\n",
      "[964/1762] D loss: 1.3921\n",
      "[1044/1762] D loss: 1.3869\n",
      "[1124/1762] D loss: 1.4044\n",
      "[1204/1762] D loss: 1.3911\n",
      "[1284/1762] D loss: 1.3926\n",
      "[1364/1762] D loss: 1.4005\n",
      "[1444/1762] D loss: 1.4006\n",
      "[1524/1762] D loss: 1.3881\n",
      "[1604/1762] D loss: 1.3951\n",
      "[1684/1762] D loss: 1.3875\n",
      "[1762/1762] D loss: 1.3747\n",
      "train error: \n",
      " D loss: 1.390271, D accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391485, D accuracy: 50.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903\n",
      "[84/1762] D loss: 1.3901\n",
      "[164/1762] D loss: 1.3952\n",
      "[244/1762] D loss: 1.3757\n",
      "[324/1762] D loss: 1.3785\n",
      "[404/1762] D loss: 1.3906\n",
      "[484/1762] D loss: 1.4122\n",
      "[564/1762] D loss: 1.3746\n",
      "[644/1762] D loss: 1.3761\n",
      "[724/1762] D loss: 1.3937\n",
      "[804/1762] D loss: 1.3752\n",
      "[884/1762] D loss: 1.3977\n",
      "[964/1762] D loss: 1.3834\n",
      "[1044/1762] D loss: 1.3628\n",
      "[1124/1762] D loss: 1.3891\n",
      "[1204/1762] D loss: 1.3993\n",
      "[1284/1762] D loss: 1.3758\n",
      "[1364/1762] D loss: 1.3849\n",
      "[1444/1762] D loss: 1.3784\n",
      "[1524/1762] D loss: 1.3886\n",
      "[1604/1762] D loss: 1.3954\n",
      "[1684/1762] D loss: 1.3920\n",
      "[1762/1762] D loss: 1.3861\n",
      "train error: \n",
      " D loss: 1.389131, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390066, D accuracy: 50.7% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951\n",
      "[84/1762] D loss: 1.3762\n",
      "[164/1762] D loss: 1.3779\n",
      "[244/1762] D loss: 1.3945\n",
      "[324/1762] D loss: 1.3890\n",
      "[404/1762] D loss: 1.3823\n",
      "[484/1762] D loss: 1.3887\n",
      "[564/1762] D loss: 1.3990\n",
      "[644/1762] D loss: 1.3774\n",
      "[724/1762] D loss: 1.3976\n",
      "[804/1762] D loss: 1.3750\n",
      "[884/1762] D loss: 1.3881\n",
      "[964/1762] D loss: 1.3746\n",
      "[1044/1762] D loss: 1.4048\n",
      "[1124/1762] D loss: 1.4049\n",
      "[1204/1762] D loss: 1.3847\n",
      "[1284/1762] D loss: 1.3994\n",
      "[1364/1762] D loss: 1.4031\n",
      "[1444/1762] D loss: 1.3932\n",
      "[1524/1762] D loss: 1.3832\n",
      "[1604/1762] D loss: 1.3970\n",
      "[1684/1762] D loss: 1.3815\n",
      "[1762/1762] D loss: 1.3830\n",
      "train error: \n",
      " D loss: 1.389109, D accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388716, D accuracy: 50.8% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929\n",
      "[84/1762] D loss: 1.3829\n",
      "[164/1762] D loss: 1.3916\n",
      "[244/1762] D loss: 1.3810\n",
      "[324/1762] D loss: 1.3842\n",
      "[404/1762] D loss: 1.3820\n",
      "[484/1762] D loss: 1.3770\n",
      "[564/1762] D loss: 1.3875\n",
      "[644/1762] D loss: 1.3802\n",
      "[724/1762] D loss: 1.3923\n",
      "[804/1762] D loss: 1.3848\n",
      "[884/1762] D loss: 1.3953\n",
      "[964/1762] D loss: 1.3773\n",
      "[1044/1762] D loss: 1.3853\n",
      "[1124/1762] D loss: 1.3941\n",
      "[1204/1762] D loss: 1.3926\n",
      "[1284/1762] D loss: 1.3957\n",
      "[1364/1762] D loss: 1.3890\n",
      "[1444/1762] D loss: 1.3885\n",
      "[1524/1762] D loss: 1.3848\n",
      "[1604/1762] D loss: 1.3611\n",
      "[1684/1762] D loss: 1.3804\n",
      "[1762/1762] D loss: 1.3838\n",
      "train error: \n",
      " D loss: 1.387678, D accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388209, D accuracy: 49.9% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931\n",
      "[84/1762] D loss: 1.3761\n",
      "[164/1762] D loss: 1.3886\n",
      "[244/1762] D loss: 1.3824\n",
      "[324/1762] D loss: 1.3945\n",
      "[404/1762] D loss: 1.3887\n",
      "[484/1762] D loss: 1.3828\n",
      "[564/1762] D loss: 1.3990\n",
      "[644/1762] D loss: 1.3983\n",
      "[724/1762] D loss: 1.4034\n",
      "[804/1762] D loss: 1.3916\n",
      "[884/1762] D loss: 1.3835\n",
      "[964/1762] D loss: 1.3982\n",
      "[1044/1762] D loss: 1.3636\n",
      "[1124/1762] D loss: 1.3916\n",
      "[1204/1762] D loss: 1.3915\n",
      "[1284/1762] D loss: 1.3707\n",
      "[1364/1762] D loss: 1.3943\n",
      "[1444/1762] D loss: 1.3971\n",
      "[1524/1762] D loss: 1.3917\n",
      "[1604/1762] D loss: 1.3906\n",
      "[1684/1762] D loss: 1.3800\n",
      "[1762/1762] D loss: 1.3889\n",
      "train error: \n",
      " D loss: 1.386846, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388062, D accuracy: 49.9% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3797\n",
      "[84/1762] D loss: 1.3874\n",
      "[164/1762] D loss: 1.4016\n",
      "[244/1762] D loss: 1.3716\n",
      "[324/1762] D loss: 1.3922\n",
      "[404/1762] D loss: 1.3641\n",
      "[484/1762] D loss: 1.3869\n",
      "[564/1762] D loss: 1.3954\n",
      "[644/1762] D loss: 1.3899\n",
      "[724/1762] D loss: 1.3800\n",
      "[804/1762] D loss: 1.3788\n",
      "[884/1762] D loss: 1.3782\n",
      "[964/1762] D loss: 1.3924\n",
      "[1044/1762] D loss: 1.3999\n",
      "[1124/1762] D loss: 1.3653\n",
      "[1204/1762] D loss: 1.3918\n",
      "[1284/1762] D loss: 1.3873\n",
      "[1364/1762] D loss: 1.3824\n",
      "[1444/1762] D loss: 1.3819\n",
      "[1524/1762] D loss: 1.3744\n",
      "[1604/1762] D loss: 1.3830\n",
      "[1684/1762] D loss: 1.3803\n",
      "[1762/1762] D loss: 1.3893\n",
      "train error: \n",
      " D loss: 1.386588, D accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387226, D accuracy: 50.1% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4025\n",
      "[84/1762] D loss: 1.3985\n",
      "[164/1762] D loss: 1.3809\n",
      "[244/1762] D loss: 1.3792\n",
      "[324/1762] D loss: 1.3853\n",
      "[404/1762] D loss: 1.3934\n",
      "[484/1762] D loss: 1.3896\n",
      "[564/1762] D loss: 1.3968\n",
      "[644/1762] D loss: 1.3931\n",
      "[724/1762] D loss: 1.3807\n",
      "[804/1762] D loss: 1.4026\n",
      "[884/1762] D loss: 1.4030\n",
      "[964/1762] D loss: 1.3721\n",
      "[1044/1762] D loss: 1.3802\n",
      "[1124/1762] D loss: 1.3761\n",
      "[1204/1762] D loss: 1.3836\n",
      "[1284/1762] D loss: 1.3883\n",
      "[1364/1762] D loss: 1.3755\n",
      "[1444/1762] D loss: 1.3817\n",
      "[1524/1762] D loss: 1.3747\n",
      "[1604/1762] D loss: 1.3949\n",
      "[1684/1762] D loss: 1.3888\n",
      "[1762/1762] D loss: 1.4161\n",
      "train error: \n",
      " D loss: 1.386587, D accuracy: 50.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387174, D accuracy: 50.8% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891\n",
      "[84/1762] D loss: 1.3803\n",
      "[164/1762] D loss: 1.3896\n",
      "[244/1762] D loss: 1.3925\n",
      "[324/1762] D loss: 1.3795\n",
      "[404/1762] D loss: 1.3830\n",
      "[484/1762] D loss: 1.3765\n",
      "[564/1762] D loss: 1.4005\n",
      "[644/1762] D loss: 1.3929\n",
      "[724/1762] D loss: 1.3814\n",
      "[804/1762] D loss: 1.3763\n",
      "[884/1762] D loss: 1.3868\n",
      "[964/1762] D loss: 1.3904\n",
      "[1044/1762] D loss: 1.3896\n",
      "[1124/1762] D loss: 1.3908\n",
      "[1204/1762] D loss: 1.3899\n",
      "[1284/1762] D loss: 1.3865\n",
      "[1364/1762] D loss: 1.3626\n",
      "[1444/1762] D loss: 1.3933\n",
      "[1524/1762] D loss: 1.4018\n",
      "[1604/1762] D loss: 1.3907\n",
      "[1684/1762] D loss: 1.3865\n",
      "[1762/1762] D loss: 1.3845\n",
      "train error: \n",
      " D loss: 1.385757, D accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387564, D accuracy: 51.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3888\n",
      "[84/1762] D loss: 1.3873\n",
      "[164/1762] D loss: 1.3950\n",
      "[244/1762] D loss: 1.3999\n",
      "[324/1762] D loss: 1.3896\n",
      "[404/1762] D loss: 1.3797\n",
      "[484/1762] D loss: 1.3859\n",
      "[564/1762] D loss: 1.3914\n",
      "[644/1762] D loss: 1.3855\n",
      "[724/1762] D loss: 1.3889\n",
      "[804/1762] D loss: 1.3965\n",
      "[884/1762] D loss: 1.3951\n",
      "[964/1762] D loss: 1.3924\n",
      "[1044/1762] D loss: 1.3866\n",
      "[1124/1762] D loss: 1.3970\n",
      "[1204/1762] D loss: 1.3880\n",
      "[1284/1762] D loss: 1.3894\n",
      "[1364/1762] D loss: 1.3821\n",
      "[1444/1762] D loss: 1.3835\n",
      "[1524/1762] D loss: 1.3924\n",
      "[1604/1762] D loss: 1.4101\n",
      "[1684/1762] D loss: 1.3944\n",
      "[1762/1762] D loss: 1.4075\n",
      "train error: \n",
      " D loss: 1.386161, D accuracy: 50.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386378, D accuracy: 50.7% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886\n",
      "[84/1762] D loss: 1.3877\n",
      "[164/1762] D loss: 1.3833\n",
      "[244/1762] D loss: 1.3876\n",
      "[324/1762] D loss: 1.3992\n",
      "[404/1762] D loss: 1.3823\n",
      "[484/1762] D loss: 1.3820\n",
      "[564/1762] D loss: 1.3931\n",
      "[644/1762] D loss: 1.3961\n",
      "[724/1762] D loss: 1.3922\n",
      "[804/1762] D loss: 1.3620\n",
      "[884/1762] D loss: 1.3975\n",
      "[964/1762] D loss: 1.3687\n",
      "[1044/1762] D loss: 1.3887\n",
      "[1124/1762] D loss: 1.3962\n",
      "[1204/1762] D loss: 1.3970\n",
      "[1284/1762] D loss: 1.3885\n",
      "[1364/1762] D loss: 1.3769\n",
      "[1444/1762] D loss: 1.3827\n",
      "[1524/1762] D loss: 1.3752\n",
      "[1604/1762] D loss: 1.3973\n",
      "[1684/1762] D loss: 1.3634\n",
      "[1762/1762] D loss: 1.4236\n",
      "train error: \n",
      " D loss: 1.385818, D accuracy: 51.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387396, D accuracy: 50.7% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880\n",
      "[84/1762] D loss: 1.4021\n",
      "[164/1762] D loss: 1.3833\n",
      "[244/1762] D loss: 1.3834\n",
      "[324/1762] D loss: 1.3930\n",
      "[404/1762] D loss: 1.3846\n",
      "[484/1762] D loss: 1.3830\n",
      "[564/1762] D loss: 1.3983\n",
      "[644/1762] D loss: 1.3866\n",
      "[724/1762] D loss: 1.4032\n",
      "[804/1762] D loss: 1.3854\n",
      "[884/1762] D loss: 1.3759\n",
      "[964/1762] D loss: 1.4024\n",
      "[1044/1762] D loss: 1.3840\n",
      "[1124/1762] D loss: 1.3909\n",
      "[1204/1762] D loss: 1.3872\n",
      "[1284/1762] D loss: 1.3841\n",
      "[1364/1762] D loss: 1.3692\n",
      "[1444/1762] D loss: 1.3979\n",
      "[1524/1762] D loss: 1.3882\n",
      "[1604/1762] D loss: 1.4079\n",
      "[1684/1762] D loss: 1.3840\n",
      "[1762/1762] D loss: 1.3805\n",
      "train error: \n",
      " D loss: 1.386086, D accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387511, D accuracy: 50.3% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3859\n",
      "[84/1762] D loss: 1.3932\n",
      "[164/1762] D loss: 1.3923\n",
      "[244/1762] D loss: 1.3926\n",
      "[324/1762] D loss: 1.3800\n",
      "[404/1762] D loss: 1.3970\n",
      "[484/1762] D loss: 1.3837\n",
      "[564/1762] D loss: 1.3847\n",
      "[644/1762] D loss: 1.3807\n",
      "[724/1762] D loss: 1.3899\n",
      "[804/1762] D loss: 1.3910\n",
      "[884/1762] D loss: 1.3998\n",
      "[964/1762] D loss: 1.3861\n",
      "[1044/1762] D loss: 1.3751\n",
      "[1124/1762] D loss: 1.3854\n",
      "[1204/1762] D loss: 1.3865\n",
      "[1284/1762] D loss: 1.3913\n",
      "[1364/1762] D loss: 1.3871\n",
      "[1444/1762] D loss: 1.3862\n",
      "[1524/1762] D loss: 1.3697\n",
      "[1604/1762] D loss: 1.3623\n",
      "[1684/1762] D loss: 1.3786\n",
      "[1762/1762] D loss: 1.3820\n",
      "train error: \n",
      " D loss: 1.385070, D accuracy: 51.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385642, D accuracy: 51.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890\n",
      "[84/1762] D loss: 1.3922\n",
      "[164/1762] D loss: 1.3791\n",
      "[244/1762] D loss: 1.4105\n",
      "[324/1762] D loss: 1.3867\n",
      "[404/1762] D loss: 1.3775\n",
      "[484/1762] D loss: 1.3928\n",
      "[564/1762] D loss: 1.3780\n",
      "[644/1762] D loss: 1.3957\n",
      "[724/1762] D loss: 1.4010\n",
      "[804/1762] D loss: 1.3860\n",
      "[884/1762] D loss: 1.3653\n",
      "[964/1762] D loss: 1.3960\n",
      "[1044/1762] D loss: 1.3903\n",
      "[1124/1762] D loss: 1.3912\n",
      "[1204/1762] D loss: 1.3978\n",
      "[1284/1762] D loss: 1.3849\n",
      "[1364/1762] D loss: 1.3917\n",
      "[1444/1762] D loss: 1.3826\n",
      "[1524/1762] D loss: 1.3932\n",
      "[1604/1762] D loss: 1.3883\n",
      "[1684/1762] D loss: 1.3947\n",
      "[1762/1762] D loss: 1.3787\n",
      "train error: \n",
      " D loss: 1.383895, D accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385342, D accuracy: 51.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845\n",
      "[84/1762] D loss: 1.3870\n",
      "[164/1762] D loss: 1.3984\n",
      "[244/1762] D loss: 1.3825\n",
      "[324/1762] D loss: 1.3797\n",
      "[404/1762] D loss: 1.3845\n",
      "[484/1762] D loss: 1.3970\n",
      "[564/1762] D loss: 1.3879\n",
      "[644/1762] D loss: 1.3803\n",
      "[724/1762] D loss: 1.3686\n",
      "[804/1762] D loss: 1.3709\n",
      "[884/1762] D loss: 1.3809\n",
      "[964/1762] D loss: 1.3856\n",
      "[1044/1762] D loss: 1.3885\n",
      "[1124/1762] D loss: 1.3980\n",
      "[1204/1762] D loss: 1.3833\n",
      "[1284/1762] D loss: 1.3976\n",
      "[1364/1762] D loss: 1.3776\n",
      "[1444/1762] D loss: 1.3949\n",
      "[1524/1762] D loss: 1.3759\n",
      "[1604/1762] D loss: 1.3795\n",
      "[1684/1762] D loss: 1.4012\n",
      "[1762/1762] D loss: 1.3820\n",
      "train error: \n",
      " D loss: 1.384213, D accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385262, D accuracy: 50.9% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3656\n",
      "[84/1762] D loss: 1.3904\n",
      "[164/1762] D loss: 1.3830\n",
      "[244/1762] D loss: 1.3821\n",
      "[324/1762] D loss: 1.3857\n",
      "[404/1762] D loss: 1.3818\n",
      "[484/1762] D loss: 1.3806\n",
      "[564/1762] D loss: 1.3856\n",
      "[644/1762] D loss: 1.3891\n",
      "[724/1762] D loss: 1.4008\n",
      "[804/1762] D loss: 1.3901\n",
      "[884/1762] D loss: 1.3848\n",
      "[964/1762] D loss: 1.3949\n",
      "[1044/1762] D loss: 1.3866\n",
      "[1124/1762] D loss: 1.3977\n",
      "[1204/1762] D loss: 1.3916\n",
      "[1284/1762] D loss: 1.3860\n",
      "[1364/1762] D loss: 1.3825\n",
      "[1444/1762] D loss: 1.3725\n",
      "[1524/1762] D loss: 1.3957\n",
      "[1604/1762] D loss: 1.3839\n",
      "[1684/1762] D loss: 1.3975\n",
      "[1762/1762] D loss: 1.4086\n",
      "train error: \n",
      " D loss: 1.384821, D accuracy: 51.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384528, D accuracy: 51.9% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882\n",
      "[84/1762] D loss: 1.3797\n",
      "[164/1762] D loss: 1.3846\n",
      "[244/1762] D loss: 1.3941\n",
      "[324/1762] D loss: 1.3753\n",
      "[404/1762] D loss: 1.3856\n",
      "[484/1762] D loss: 1.3916\n",
      "[564/1762] D loss: 1.3859\n",
      "[644/1762] D loss: 1.3935\n",
      "[724/1762] D loss: 1.3841\n",
      "[804/1762] D loss: 1.3717\n",
      "[884/1762] D loss: 1.3933\n",
      "[964/1762] D loss: 1.4025\n",
      "[1044/1762] D loss: 1.3777\n",
      "[1124/1762] D loss: 1.3941\n",
      "[1204/1762] D loss: 1.3851\n",
      "[1284/1762] D loss: 1.3655\n",
      "[1364/1762] D loss: 1.3901\n",
      "[1444/1762] D loss: 1.3946\n",
      "[1524/1762] D loss: 1.3908\n",
      "[1604/1762] D loss: 1.3841\n",
      "[1684/1762] D loss: 1.3908\n",
      "[1762/1762] D loss: 1.4075\n",
      "train error: \n",
      " D loss: 1.384404, D accuracy: 51.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384445, D accuracy: 51.5% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862\n",
      "[84/1762] D loss: 1.3890\n",
      "[164/1762] D loss: 1.3975\n",
      "[244/1762] D loss: 1.3770\n",
      "[324/1762] D loss: 1.3850\n",
      "[404/1762] D loss: 1.3869\n",
      "[484/1762] D loss: 1.3851\n",
      "[564/1762] D loss: 1.4047\n",
      "[644/1762] D loss: 1.3725\n",
      "[724/1762] D loss: 1.3862\n",
      "[804/1762] D loss: 1.3887\n",
      "[884/1762] D loss: 1.3877\n",
      "[964/1762] D loss: 1.3883\n",
      "[1044/1762] D loss: 1.3821\n",
      "[1124/1762] D loss: 1.3982\n",
      "[1204/1762] D loss: 1.3836\n",
      "[1284/1762] D loss: 1.3805\n",
      "[1364/1762] D loss: 1.3846\n",
      "[1444/1762] D loss: 1.3707\n",
      "[1524/1762] D loss: 1.3885\n",
      "[1604/1762] D loss: 1.3704\n",
      "[1684/1762] D loss: 1.3826\n",
      "[1762/1762] D loss: 1.3850\n",
      "train error: \n",
      " D loss: 1.384708, D accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385744, D accuracy: 51.2% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4003\n",
      "[84/1762] D loss: 1.3855\n",
      "[164/1762] D loss: 1.3864\n",
      "[244/1762] D loss: 1.3865\n",
      "[324/1762] D loss: 1.3966\n",
      "[404/1762] D loss: 1.3886\n",
      "[484/1762] D loss: 1.3928\n",
      "[564/1762] D loss: 1.3962\n",
      "[644/1762] D loss: 1.3933\n",
      "[724/1762] D loss: 1.3770\n",
      "[804/1762] D loss: 1.3983\n",
      "[884/1762] D loss: 1.3686\n",
      "[964/1762] D loss: 1.3600\n",
      "[1044/1762] D loss: 1.3752\n",
      "[1124/1762] D loss: 1.3886\n",
      "[1204/1762] D loss: 1.3912\n",
      "[1284/1762] D loss: 1.3935\n",
      "[1364/1762] D loss: 1.3910\n",
      "[1444/1762] D loss: 1.3824\n",
      "[1524/1762] D loss: 1.4059\n",
      "[1604/1762] D loss: 1.3851\n",
      "[1684/1762] D loss: 1.3798\n",
      "[1762/1762] D loss: 1.3743\n",
      "train error: \n",
      " D loss: 1.383336, D accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384018, D accuracy: 53.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914\n",
      "[84/1762] D loss: 1.3697\n",
      "[164/1762] D loss: 1.3845\n",
      "[244/1762] D loss: 1.3814\n",
      "[324/1762] D loss: 1.4028\n",
      "[404/1762] D loss: 1.3955\n",
      "[484/1762] D loss: 1.3980\n",
      "[564/1762] D loss: 1.4014\n",
      "[644/1762] D loss: 1.3855\n",
      "[724/1762] D loss: 1.3963\n",
      "[804/1762] D loss: 1.3738\n",
      "[884/1762] D loss: 1.4023\n",
      "[964/1762] D loss: 1.3845\n",
      "[1044/1762] D loss: 1.3751\n",
      "[1124/1762] D loss: 1.3726\n",
      "[1204/1762] D loss: 1.3717\n",
      "[1284/1762] D loss: 1.3849\n",
      "[1364/1762] D loss: 1.3797\n",
      "[1444/1762] D loss: 1.3945\n",
      "[1524/1762] D loss: 1.3845\n",
      "[1604/1762] D loss: 1.3940\n",
      "[1684/1762] D loss: 1.3765\n",
      "[1762/1762] D loss: 1.3921\n",
      "train error: \n",
      " D loss: 1.383742, D accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383928, D accuracy: 52.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905\n",
      "[84/1762] D loss: 1.3855\n",
      "[164/1762] D loss: 1.3854\n",
      "[244/1762] D loss: 1.3929\n",
      "[324/1762] D loss: 1.3900\n",
      "[404/1762] D loss: 1.3903\n",
      "[484/1762] D loss: 1.3850\n",
      "[564/1762] D loss: 1.3833\n",
      "[644/1762] D loss: 1.3945\n",
      "[724/1762] D loss: 1.3630\n",
      "[804/1762] D loss: 1.3841\n",
      "[884/1762] D loss: 1.3798\n",
      "[964/1762] D loss: 1.3908\n",
      "[1044/1762] D loss: 1.3983\n",
      "[1124/1762] D loss: 1.3753\n",
      "[1204/1762] D loss: 1.3873\n",
      "[1284/1762] D loss: 1.3877\n",
      "[1364/1762] D loss: 1.3862\n",
      "[1444/1762] D loss: 1.3876\n",
      "[1524/1762] D loss: 1.3966\n",
      "[1604/1762] D loss: 1.3849\n",
      "[1684/1762] D loss: 1.3864\n",
      "[1762/1762] D loss: 1.3626\n",
      "train error: \n",
      " D loss: 1.384445, D accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383833, D accuracy: 52.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3827\n",
      "[84/1762] D loss: 1.3989\n",
      "[164/1762] D loss: 1.3839\n",
      "[244/1762] D loss: 1.3722\n",
      "[324/1762] D loss: 1.3704\n",
      "[404/1762] D loss: 1.3743\n",
      "[484/1762] D loss: 1.3708\n",
      "[564/1762] D loss: 1.3832\n",
      "[644/1762] D loss: 1.3896\n",
      "[724/1762] D loss: 1.3790\n",
      "[804/1762] D loss: 1.3827\n",
      "[884/1762] D loss: 1.3845\n",
      "[964/1762] D loss: 1.3612\n",
      "[1044/1762] D loss: 1.3933\n",
      "[1124/1762] D loss: 1.3971\n",
      "[1204/1762] D loss: 1.3893\n",
      "[1284/1762] D loss: 1.3760\n",
      "[1364/1762] D loss: 1.3818\n",
      "[1444/1762] D loss: 1.3815\n",
      "[1524/1762] D loss: 1.4040\n",
      "[1604/1762] D loss: 1.3910\n",
      "[1684/1762] D loss: 1.3875\n",
      "[1762/1762] D loss: 1.3950\n",
      "train error: \n",
      " D loss: 1.384507, D accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383750, D accuracy: 51.5% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913\n",
      "[84/1762] D loss: 1.4066\n",
      "[164/1762] D loss: 1.3715\n",
      "[244/1762] D loss: 1.3580\n",
      "[324/1762] D loss: 1.3781\n",
      "[404/1762] D loss: 1.3800\n",
      "[484/1762] D loss: 1.3817\n",
      "[564/1762] D loss: 1.3918\n",
      "[644/1762] D loss: 1.3712\n",
      "[724/1762] D loss: 1.3933\n",
      "[804/1762] D loss: 1.4007\n",
      "[884/1762] D loss: 1.3876\n",
      "[964/1762] D loss: 1.3699\n",
      "[1044/1762] D loss: 1.3824\n",
      "[1124/1762] D loss: 1.3804\n",
      "[1204/1762] D loss: 1.3838\n",
      "[1284/1762] D loss: 1.3770\n",
      "[1364/1762] D loss: 1.3757\n",
      "[1444/1762] D loss: 1.3767\n",
      "[1524/1762] D loss: 1.3814\n",
      "[1604/1762] D loss: 1.3924\n",
      "[1684/1762] D loss: 1.3803\n",
      "[1762/1762] D loss: 1.3970\n",
      "train error: \n",
      " D loss: 1.383701, D accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383302, D accuracy: 52.4% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4002\n",
      "[84/1762] D loss: 1.3704\n",
      "[164/1762] D loss: 1.3779\n",
      "[244/1762] D loss: 1.3779\n",
      "[324/1762] D loss: 1.3821\n",
      "[404/1762] D loss: 1.4005\n",
      "[484/1762] D loss: 1.3851\n",
      "[564/1762] D loss: 1.3872\n",
      "[644/1762] D loss: 1.3851\n",
      "[724/1762] D loss: 1.3823\n",
      "[804/1762] D loss: 1.3902\n",
      "[884/1762] D loss: 1.3928\n",
      "[964/1762] D loss: 1.3962\n",
      "[1044/1762] D loss: 1.3976\n",
      "[1124/1762] D loss: 1.3857\n",
      "[1204/1762] D loss: 1.3733\n",
      "[1284/1762] D loss: 1.3868\n",
      "[1364/1762] D loss: 1.3769\n",
      "[1444/1762] D loss: 1.3876\n",
      "[1524/1762] D loss: 1.3876\n",
      "[1604/1762] D loss: 1.3720\n",
      "[1684/1762] D loss: 1.3943\n",
      "[1762/1762] D loss: 1.3904\n",
      "train error: \n",
      " D loss: 1.384246, D accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384089, D accuracy: 52.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3918\n",
      "[84/1762] D loss: 1.3735\n",
      "[164/1762] D loss: 1.3666\n",
      "[244/1762] D loss: 1.3943\n",
      "[324/1762] D loss: 1.3826\n",
      "[404/1762] D loss: 1.3911\n",
      "[484/1762] D loss: 1.3949\n",
      "[564/1762] D loss: 1.3827\n",
      "[644/1762] D loss: 1.3903\n",
      "[724/1762] D loss: 1.3846\n",
      "[804/1762] D loss: 1.3848\n",
      "[884/1762] D loss: 1.3743\n",
      "[964/1762] D loss: 1.3702\n",
      "[1044/1762] D loss: 1.3888\n",
      "[1124/1762] D loss: 1.3852\n",
      "[1204/1762] D loss: 1.4018\n",
      "[1284/1762] D loss: 1.3638\n",
      "[1364/1762] D loss: 1.3831\n",
      "[1444/1762] D loss: 1.3906\n",
      "[1524/1762] D loss: 1.3878\n",
      "[1604/1762] D loss: 1.4019\n",
      "[1684/1762] D loss: 1.3769\n",
      "[1762/1762] D loss: 1.3812\n",
      "train error: \n",
      " D loss: 1.383574, D accuracy: 52.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383725, D accuracy: 51.1% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3807\n",
      "[84/1762] D loss: 1.3764\n",
      "[164/1762] D loss: 1.3917\n",
      "[244/1762] D loss: 1.3743\n",
      "[324/1762] D loss: 1.3727\n",
      "[404/1762] D loss: 1.3688\n",
      "[484/1762] D loss: 1.3754\n",
      "[564/1762] D loss: 1.3859\n",
      "[644/1762] D loss: 1.3894\n",
      "[724/1762] D loss: 1.3837\n",
      "[804/1762] D loss: 1.3737\n",
      "[884/1762] D loss: 1.3883\n",
      "[964/1762] D loss: 1.3847\n",
      "[1044/1762] D loss: 1.3829\n",
      "[1124/1762] D loss: 1.3890\n",
      "[1204/1762] D loss: 1.3718\n",
      "[1284/1762] D loss: 1.3815\n",
      "[1364/1762] D loss: 1.3864\n",
      "[1444/1762] D loss: 1.3776\n",
      "[1524/1762] D loss: 1.3840\n",
      "[1604/1762] D loss: 1.3772\n",
      "[1684/1762] D loss: 1.3876\n",
      "[1762/1762] D loss: 1.3893\n",
      "train error: \n",
      " D loss: 1.383799, D accuracy: 52.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383820, D accuracy: 51.6% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3851\n",
      "[84/1762] D loss: 1.3915\n",
      "[164/1762] D loss: 1.3977\n",
      "[244/1762] D loss: 1.3805\n",
      "[324/1762] D loss: 1.3904\n",
      "[404/1762] D loss: 1.4033\n",
      "[484/1762] D loss: 1.3800\n",
      "[564/1762] D loss: 1.3929\n",
      "[644/1762] D loss: 1.3794\n",
      "[724/1762] D loss: 1.3706\n",
      "[804/1762] D loss: 1.3909\n",
      "[884/1762] D loss: 1.3852\n",
      "[964/1762] D loss: 1.3822\n",
      "[1044/1762] D loss: 1.3746\n",
      "[1124/1762] D loss: 1.3857\n",
      "[1204/1762] D loss: 1.3956\n",
      "[1284/1762] D loss: 1.3840\n",
      "[1364/1762] D loss: 1.3765\n",
      "[1444/1762] D loss: 1.3815\n",
      "[1524/1762] D loss: 1.3944\n",
      "[1604/1762] D loss: 1.3840\n",
      "[1684/1762] D loss: 1.4036\n",
      "[1762/1762] D loss: 1.3672\n",
      "train error: \n",
      " D loss: 1.382927, D accuracy: 51.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384461, D accuracy: 50.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958\n",
      "[84/1762] D loss: 1.3867\n",
      "[164/1762] D loss: 1.3792\n",
      "[244/1762] D loss: 1.3861\n",
      "[324/1762] D loss: 1.3800\n",
      "[404/1762] D loss: 1.3886\n",
      "[484/1762] D loss: 1.3681\n",
      "[564/1762] D loss: 1.3863\n",
      "[644/1762] D loss: 1.3829\n",
      "[724/1762] D loss: 1.3804\n",
      "[804/1762] D loss: 1.3864\n",
      "[884/1762] D loss: 1.3767\n",
      "[964/1762] D loss: 1.3797\n",
      "[1044/1762] D loss: 1.3842\n",
      "[1124/1762] D loss: 1.3814\n",
      "[1204/1762] D loss: 1.3970\n",
      "[1284/1762] D loss: 1.3929\n",
      "[1364/1762] D loss: 1.3733\n",
      "[1444/1762] D loss: 1.3878\n",
      "[1524/1762] D loss: 1.3873\n",
      "[1604/1762] D loss: 1.3893\n",
      "[1684/1762] D loss: 1.3692\n",
      "[1762/1762] D loss: 1.3861\n",
      "train error: \n",
      " D loss: 1.383242, D accuracy: 52.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382587, D accuracy: 51.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3716\n",
      "[84/1762] D loss: 1.3644\n",
      "[164/1762] D loss: 1.3944\n",
      "[244/1762] D loss: 1.3993\n",
      "[324/1762] D loss: 1.3967\n",
      "[404/1762] D loss: 1.3726\n",
      "[484/1762] D loss: 1.3755\n",
      "[564/1762] D loss: 1.3783\n",
      "[644/1762] D loss: 1.3899\n",
      "[724/1762] D loss: 1.3863\n",
      "[804/1762] D loss: 1.3831\n",
      "[884/1762] D loss: 1.3822\n",
      "[964/1762] D loss: 1.3804\n",
      "[1044/1762] D loss: 1.3932\n",
      "[1124/1762] D loss: 1.3908\n",
      "[1204/1762] D loss: 1.3990\n",
      "[1284/1762] D loss: 1.3862\n",
      "[1364/1762] D loss: 1.3625\n",
      "[1444/1762] D loss: 1.3877\n",
      "[1524/1762] D loss: 1.3811\n",
      "[1604/1762] D loss: 1.3622\n",
      "[1684/1762] D loss: 1.3766\n",
      "[1762/1762] D loss: 1.3877\n",
      "train error: \n",
      " D loss: 1.383141, D accuracy: 52.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381947, D accuracy: 52.6% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3774\n",
      "[84/1762] D loss: 1.3885\n",
      "[164/1762] D loss: 1.3911\n",
      "[244/1762] D loss: 1.3795\n",
      "[324/1762] D loss: 1.3822\n",
      "[404/1762] D loss: 1.3605\n",
      "[484/1762] D loss: 1.3806\n",
      "[564/1762] D loss: 1.3852\n",
      "[644/1762] D loss: 1.3948\n",
      "[724/1762] D loss: 1.3814\n",
      "[804/1762] D loss: 1.4093\n",
      "[884/1762] D loss: 1.3912\n",
      "[964/1762] D loss: 1.3908\n",
      "[1044/1762] D loss: 1.3919\n",
      "[1124/1762] D loss: 1.3984\n",
      "[1204/1762] D loss: 1.3675\n",
      "[1284/1762] D loss: 1.3799\n",
      "[1364/1762] D loss: 1.3952\n",
      "[1444/1762] D loss: 1.3986\n",
      "[1524/1762] D loss: 1.3859\n",
      "[1604/1762] D loss: 1.3879\n",
      "[1684/1762] D loss: 1.3792\n",
      "[1762/1762] D loss: 1.3738\n",
      "train error: \n",
      " D loss: 1.383187, D accuracy: 53.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382619, D accuracy: 52.4% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3920\n",
      "[84/1762] D loss: 1.3759\n",
      "[164/1762] D loss: 1.3887\n",
      "[244/1762] D loss: 1.3843\n",
      "[324/1762] D loss: 1.3890\n",
      "[404/1762] D loss: 1.3979\n",
      "[484/1762] D loss: 1.3765\n",
      "[564/1762] D loss: 1.3827\n",
      "[644/1762] D loss: 1.4062\n",
      "[724/1762] D loss: 1.3687\n",
      "[804/1762] D loss: 1.3930\n",
      "[884/1762] D loss: 1.3647\n",
      "[964/1762] D loss: 1.3819\n",
      "[1044/1762] D loss: 1.3794\n",
      "[1124/1762] D loss: 1.3840\n",
      "[1204/1762] D loss: 1.3811\n",
      "[1284/1762] D loss: 1.3800\n",
      "[1364/1762] D loss: 1.3917\n",
      "[1444/1762] D loss: 1.3929\n",
      "[1524/1762] D loss: 1.3742\n",
      "[1604/1762] D loss: 1.3864\n",
      "[1684/1762] D loss: 1.3862\n",
      "[1762/1762] D loss: 1.3958\n",
      "train error: \n",
      " D loss: 1.383504, D accuracy: 52.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382677, D accuracy: 51.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3979\n",
      "[84/1762] D loss: 1.3985\n",
      "[164/1762] D loss: 1.4029\n",
      "[244/1762] D loss: 1.3880\n",
      "[324/1762] D loss: 1.3857\n",
      "[404/1762] D loss: 1.3862\n",
      "[484/1762] D loss: 1.3808\n",
      "[564/1762] D loss: 1.3813\n",
      "[644/1762] D loss: 1.3857\n",
      "[724/1762] D loss: 1.3914\n",
      "[804/1762] D loss: 1.3880\n",
      "[884/1762] D loss: 1.3731\n",
      "[964/1762] D loss: 1.3747\n",
      "[1044/1762] D loss: 1.3869\n",
      "[1124/1762] D loss: 1.3713\n",
      "[1204/1762] D loss: 1.3629\n",
      "[1284/1762] D loss: 1.3917\n",
      "[1364/1762] D loss: 1.3897\n",
      "[1444/1762] D loss: 1.3860\n",
      "[1524/1762] D loss: 1.3926\n",
      "[1604/1762] D loss: 1.3739\n",
      "[1684/1762] D loss: 1.3642\n",
      "[1762/1762] D loss: 1.4029\n",
      "train error: \n",
      " D loss: 1.382348, D accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383350, D accuracy: 51.7% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3964\n",
      "[84/1762] D loss: 1.3914\n",
      "[164/1762] D loss: 1.3919\n",
      "[244/1762] D loss: 1.3895\n",
      "[324/1762] D loss: 1.3829\n",
      "[404/1762] D loss: 1.3882\n",
      "[484/1762] D loss: 1.3869\n",
      "[564/1762] D loss: 1.3749\n",
      "[644/1762] D loss: 1.3846\n",
      "[724/1762] D loss: 1.3708\n",
      "[804/1762] D loss: 1.3917\n",
      "[884/1762] D loss: 1.3989\n",
      "[964/1762] D loss: 1.3945\n",
      "[1044/1762] D loss: 1.3900\n",
      "[1124/1762] D loss: 1.3773\n",
      "[1204/1762] D loss: 1.3788\n",
      "[1284/1762] D loss: 1.3893\n",
      "[1364/1762] D loss: 1.3783\n",
      "[1444/1762] D loss: 1.3851\n",
      "[1524/1762] D loss: 1.3788\n",
      "[1604/1762] D loss: 1.3943\n",
      "[1684/1762] D loss: 1.4057\n",
      "[1762/1762] D loss: 1.3729\n",
      "train error: \n",
      " D loss: 1.382512, D accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384500, D accuracy: 52.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892\n",
      "[84/1762] D loss: 1.3860\n",
      "[164/1762] D loss: 1.3828\n",
      "[244/1762] D loss: 1.4033\n",
      "[324/1762] D loss: 1.3754\n",
      "[404/1762] D loss: 1.3782\n",
      "[484/1762] D loss: 1.3770\n",
      "[564/1762] D loss: 1.3791\n",
      "[644/1762] D loss: 1.3804\n",
      "[724/1762] D loss: 1.3925\n",
      "[804/1762] D loss: 1.3950\n",
      "[884/1762] D loss: 1.3685\n",
      "[964/1762] D loss: 1.3822\n",
      "[1044/1762] D loss: 1.3772\n",
      "[1124/1762] D loss: 1.3814\n",
      "[1204/1762] D loss: 1.3840\n",
      "[1284/1762] D loss: 1.3879\n",
      "[1364/1762] D loss: 1.3739\n",
      "[1444/1762] D loss: 1.3789\n",
      "[1524/1762] D loss: 1.3883\n",
      "[1604/1762] D loss: 1.3930\n",
      "[1684/1762] D loss: 1.3777\n",
      "[1762/1762] D loss: 1.3779\n",
      "train error: \n",
      " D loss: 1.382471, D accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383748, D accuracy: 51.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863\n",
      "[84/1762] D loss: 1.3851\n",
      "[164/1762] D loss: 1.3710\n",
      "[244/1762] D loss: 1.3878\n",
      "[324/1762] D loss: 1.3869\n",
      "[404/1762] D loss: 1.3889\n",
      "[484/1762] D loss: 1.3810\n",
      "[564/1762] D loss: 1.3791\n",
      "[644/1762] D loss: 1.3789\n",
      "[724/1762] D loss: 1.3848\n",
      "[804/1762] D loss: 1.4038\n",
      "[884/1762] D loss: 1.3577\n",
      "[964/1762] D loss: 1.3967\n",
      "[1044/1762] D loss: 1.3778\n",
      "[1124/1762] D loss: 1.3903\n",
      "[1204/1762] D loss: 1.3784\n",
      "[1284/1762] D loss: 1.3717\n",
      "[1364/1762] D loss: 1.3985\n",
      "[1444/1762] D loss: 1.3843\n",
      "[1524/1762] D loss: 1.4071\n",
      "[1604/1762] D loss: 1.3823\n",
      "[1684/1762] D loss: 1.3885\n",
      "[1762/1762] D loss: 1.3748\n",
      "train error: \n",
      " D loss: 1.382454, D accuracy: 52.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382577, D accuracy: 52.6% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3665\n",
      "[84/1762] D loss: 1.3668\n",
      "[164/1762] D loss: 1.3943\n",
      "[244/1762] D loss: 1.3743\n",
      "[324/1762] D loss: 1.3705\n",
      "[404/1762] D loss: 1.3846\n",
      "[484/1762] D loss: 1.3819\n",
      "[564/1762] D loss: 1.3632\n",
      "[644/1762] D loss: 1.3761\n",
      "[724/1762] D loss: 1.3855\n",
      "[804/1762] D loss: 1.3633\n",
      "[884/1762] D loss: 1.3816\n",
      "[964/1762] D loss: 1.3741\n",
      "[1044/1762] D loss: 1.3800\n",
      "[1124/1762] D loss: 1.3994\n",
      "[1204/1762] D loss: 1.3867\n",
      "[1284/1762] D loss: 1.3777\n",
      "[1364/1762] D loss: 1.3926\n",
      "[1444/1762] D loss: 1.3830\n",
      "[1524/1762] D loss: 1.3699\n",
      "[1604/1762] D loss: 1.3885\n",
      "[1684/1762] D loss: 1.3825\n",
      "[1762/1762] D loss: 1.3776\n",
      "train error: \n",
      " D loss: 1.382501, D accuracy: 53.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380287, D accuracy: 52.8% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3780\n",
      "[84/1762] D loss: 1.3815\n",
      "[164/1762] D loss: 1.3814\n",
      "[244/1762] D loss: 1.3841\n",
      "[324/1762] D loss: 1.3890\n",
      "[404/1762] D loss: 1.3706\n",
      "[484/1762] D loss: 1.3738\n",
      "[564/1762] D loss: 1.3987\n",
      "[644/1762] D loss: 1.3955\n",
      "[724/1762] D loss: 1.3885\n",
      "[804/1762] D loss: 1.3924\n",
      "[884/1762] D loss: 1.3942\n",
      "[964/1762] D loss: 1.3778\n",
      "[1044/1762] D loss: 1.3837\n",
      "[1124/1762] D loss: 1.3827\n",
      "[1204/1762] D loss: 1.3831\n",
      "[1284/1762] D loss: 1.3772\n",
      "[1364/1762] D loss: 1.3971\n",
      "[1444/1762] D loss: 1.3784\n",
      "[1524/1762] D loss: 1.3726\n",
      "[1604/1762] D loss: 1.3720\n",
      "[1684/1762] D loss: 1.3696\n",
      "[1762/1762] D loss: 1.3855\n",
      "train error: \n",
      " D loss: 1.382565, D accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381727, D accuracy: 52.3% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910\n",
      "[84/1762] D loss: 1.3810\n",
      "[164/1762] D loss: 1.3920\n",
      "[244/1762] D loss: 1.3805\n",
      "[324/1762] D loss: 1.3851\n",
      "[404/1762] D loss: 1.3897\n",
      "[484/1762] D loss: 1.3926\n",
      "[564/1762] D loss: 1.3799\n",
      "[644/1762] D loss: 1.3668\n",
      "[724/1762] D loss: 1.3758\n",
      "[804/1762] D loss: 1.3875\n",
      "[884/1762] D loss: 1.3783\n",
      "[964/1762] D loss: 1.3973\n",
      "[1044/1762] D loss: 1.4036\n",
      "[1124/1762] D loss: 1.3822\n",
      "[1204/1762] D loss: 1.3896\n",
      "[1284/1762] D loss: 1.3852\n",
      "[1364/1762] D loss: 1.3857\n",
      "[1444/1762] D loss: 1.3922\n",
      "[1524/1762] D loss: 1.3990\n",
      "[1604/1762] D loss: 1.3573\n",
      "[1684/1762] D loss: 1.3890\n",
      "[1762/1762] D loss: 1.4105\n",
      "train error: \n",
      " D loss: 1.382911, D accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381564, D accuracy: 53.2% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in [1e-3, 3e-4, 1e-4, 3e-5, 1e-5]:\n",
    "    run_name = f\"perturb_{2}_lr_\" + f\"{learning_rate:.0e}\".replace(\"-\", \"m\")\n",
    "    train(run_name=run_name, perturb_num=2, epochs=50, learning_rate=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, when there are fewer perturbations, the model learns more slowly with a given learning rate. 1e-3 now becomes unstable. 3e-4 actually learns a bit faster but starts becoming a bit unstable towards the end. 1e-4 shows promise but doesn't significantly converge within 50 epochs. 3e-5 is much too slow.\n",
    "\n",
    "So, we have demonstrated that the discriminator architecture can learn to distinguish even small bits of random noise from the real frames, but the original learning rate of 1e-2 may be too high for the GAN training. However, the discriminator cannot achieve 100% training accuracy on the perturbation task, so there may be improvements that can be made to the architecture.\n",
    "\n",
    "The first thing we should try is reducing the learning rate on the GAN training and see if that improves the situation.\n",
    "\n",
    "Later, we can experiment more with the perturbation task and see if we can find an architecture that works better for it, and see how that architecture fares as a discriminator in the GAN training."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reinstate the original training functions, with some additional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(X, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        z = torch.rand(batch_size, 4, device=device)\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(X, z)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(X, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(X, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 20 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "    spawn_recall = 0.0\n",
    "    num_spawns = 0.0\n",
    "    spawn_precision = 0.0\n",
    "    num_predicted_spawns = 0.0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for X, y in dataloader:\n",
    "            batch_size = X.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(X, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            z = torch.rand(batch_size, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            output_fake = disc(X, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_X = torch.argmax(X, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy += (classes_y_fake == classes_y).type(torch.float).mean().item()\n",
    "            board_accuracy += (classes_y_fake == classes_y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "            actual_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y[:, 0, :] == 1).any(-1)\n",
    "            predicted_spawns = (classes_y_fake[:, 0, :] == 1).any(-1)\n",
    "            num_true_positives = (actual_spawns & predicted_spawns).type(torch.float).sum().item()\n",
    "            spawn_recall += num_true_positives\n",
    "            num_spawns += actual_spawns.type(torch.float).sum().item()\n",
    "            spawn_precision += num_true_positives\n",
    "            num_predicted_spawns += predicted_spawns.type(torch.float).sum().item()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    spawn_recall /= num_spawns\n",
    "    spawn_precision = np.nan if (num_predicted_spawns == 0.0) else (spawn_precision / num_predicted_spawns)\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(100*cell_accuracy):>0.1f}%, board accuracy: {(100*board_accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(examples):\n",
    "            X, y = X.unsqueeze(0), y.unsqueeze(0)\n",
    "            z = torch.rand(1, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            X, y, y_fake = X.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            X, y, y_fake = X.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(X, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch, dataformats=\"HW\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", disc_cls=TetrisDiscriminator, learning_rate=1e-2, epochs=50):\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = disc_cls().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.SGD(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.SGD(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_017\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3827, G loss: 0.5689\n",
      "[84/1762] D loss: 1.3852, G loss: 0.5811\n",
      "[164/1762] D loss: 1.3851, G loss: 0.5866\n",
      "[244/1762] D loss: 1.3726, G loss: 0.5936\n",
      "[324/1762] D loss: 1.3878, G loss: 0.5953\n",
      "[404/1762] D loss: 1.3623, G loss: 0.5950\n",
      "[484/1762] D loss: 1.3455, G loss: 0.6294\n",
      "[564/1762] D loss: 1.3457, G loss: 0.6200\n",
      "[644/1762] D loss: 1.3526, G loss: 0.6451\n",
      "[724/1762] D loss: 1.3516, G loss: 0.6097\n",
      "[804/1762] D loss: 1.3483, G loss: 0.6067\n",
      "[884/1762] D loss: 1.3292, G loss: 0.6407\n",
      "[964/1762] D loss: 1.3156, G loss: 0.6322\n",
      "[1044/1762] D loss: 1.3471, G loss: 0.6470\n",
      "[1124/1762] D loss: 1.2974, G loss: 0.6559\n",
      "[1204/1762] D loss: 1.3176, G loss: 0.6646\n",
      "[1284/1762] D loss: 1.2836, G loss: 0.6769\n",
      "[1364/1762] D loss: 1.2902, G loss: 0.6682\n",
      "[1444/1762] D loss: 1.2838, G loss: 0.6974\n",
      "[1524/1762] D loss: 1.2555, G loss: 0.6862\n",
      "[1604/1762] D loss: 1.2554, G loss: 0.7219\n",
      "[1684/1762] D loss: 1.2838, G loss: 0.6889\n",
      "[1762/1762] D loss: 1.2894, G loss: 0.7090\n",
      "train error: \n",
      " D loss: 1.256304, G loss: 0.709275, D accuracy: 82.3%, cell accuracy: 32.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257181, G loss: 0.706708, D accuracy: 80.0%, cell accuracy: 31.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2151, G loss: 0.7345\n",
      "[84/1762] D loss: 1.2393, G loss: 0.7234\n",
      "[164/1762] D loss: 1.2220, G loss: 0.6992\n",
      "[244/1762] D loss: 1.2137, G loss: 0.7560\n",
      "[324/1762] D loss: 1.2373, G loss: 0.7370\n",
      "[404/1762] D loss: 1.1757, G loss: 0.7407\n",
      "[484/1762] D loss: 1.2318, G loss: 0.7511\n",
      "[564/1762] D loss: 1.1918, G loss: 0.7415\n",
      "[644/1762] D loss: 1.2060, G loss: 0.7601\n",
      "[724/1762] D loss: 1.1533, G loss: 0.7855\n",
      "[804/1762] D loss: 1.1715, G loss: 0.7911\n",
      "[884/1762] D loss: 1.1292, G loss: 0.7668\n",
      "[964/1762] D loss: 1.1496, G loss: 0.7604\n",
      "[1044/1762] D loss: 1.1113, G loss: 0.8210\n",
      "[1124/1762] D loss: 1.1069, G loss: 0.7627\n",
      "[1204/1762] D loss: 1.0844, G loss: 0.8208\n",
      "[1284/1762] D loss: 1.0538, G loss: 0.8593\n",
      "[1364/1762] D loss: 1.0799, G loss: 0.8462\n",
      "[1444/1762] D loss: 1.0755, G loss: 0.8563\n",
      "[1524/1762] D loss: 1.1062, G loss: 0.8431\n",
      "[1604/1762] D loss: 1.0477, G loss: 0.8128\n",
      "[1684/1762] D loss: 1.0253, G loss: 0.8452\n",
      "[1762/1762] D loss: 1.0045, G loss: 0.8820\n",
      "train error: \n",
      " D loss: 1.013097, G loss: 0.882496, D accuracy: 99.7%, cell accuracy: 39.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.012141, G loss: 0.880867, D accuracy: 99.7%, cell accuracy: 38.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9618, G loss: 0.9134\n",
      "[84/1762] D loss: 1.0457, G loss: 0.9093\n",
      "[164/1762] D loss: 0.9629, G loss: 0.9020\n",
      "[244/1762] D loss: 0.9531, G loss: 0.9651\n",
      "[324/1762] D loss: 0.9814, G loss: 0.9550\n",
      "[404/1762] D loss: 0.9763, G loss: 0.8855\n",
      "[484/1762] D loss: 0.9463, G loss: 0.9568\n",
      "[564/1762] D loss: 0.9278, G loss: 0.9742\n",
      "[644/1762] D loss: 0.8662, G loss: 0.9414\n",
      "[724/1762] D loss: 0.8920, G loss: 0.9670\n",
      "[804/1762] D loss: 0.8383, G loss: 0.9829\n",
      "[884/1762] D loss: 0.7568, G loss: 1.0297\n",
      "[964/1762] D loss: 0.7683, G loss: 1.1120\n",
      "[1044/1762] D loss: 0.7850, G loss: 1.0735\n",
      "[1124/1762] D loss: 0.7967, G loss: 1.0974\n",
      "[1204/1762] D loss: 0.7139, G loss: 1.1148\n",
      "[1284/1762] D loss: 0.7862, G loss: 1.1004\n",
      "[1364/1762] D loss: 0.7232, G loss: 1.0747\n",
      "[1444/1762] D loss: 0.7557, G loss: 1.1115\n",
      "[1524/1762] D loss: 0.6627, G loss: 1.1338\n",
      "[1604/1762] D loss: 0.7804, G loss: 1.0817\n",
      "[1684/1762] D loss: 0.6839, G loss: 1.2005\n",
      "[1762/1762] D loss: 0.7169, G loss: 1.2096\n",
      "train error: \n",
      " D loss: 0.695628, G loss: 1.212392, D accuracy: 100.0%, cell accuracy: 61.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.693435, G loss: 1.214105, D accuracy: 99.8%, cell accuracy: 59.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6509, G loss: 1.2266\n",
      "[84/1762] D loss: 0.7231, G loss: 1.2347\n",
      "[164/1762] D loss: 0.7107, G loss: 1.1545\n",
      "[244/1762] D loss: 0.6939, G loss: 1.2502\n",
      "[324/1762] D loss: 0.6540, G loss: 1.1832\n",
      "[404/1762] D loss: 0.5957, G loss: 1.2083\n",
      "[484/1762] D loss: 0.6129, G loss: 1.2700\n",
      "[564/1762] D loss: 0.6425, G loss: 1.2825\n",
      "[644/1762] D loss: 0.7200, G loss: 1.1581\n",
      "[724/1762] D loss: 0.5696, G loss: 1.3320\n",
      "[804/1762] D loss: 0.6376, G loss: 1.3970\n",
      "[884/1762] D loss: 0.5523, G loss: 1.4166\n",
      "[964/1762] D loss: 0.5565, G loss: 1.3442\n",
      "[1044/1762] D loss: 0.5762, G loss: 1.4135\n",
      "[1124/1762] D loss: 0.4869, G loss: 1.4616\n",
      "[1204/1762] D loss: 0.5960, G loss: 1.5136\n",
      "[1284/1762] D loss: 0.6278, G loss: 1.1248\n",
      "[1364/1762] D loss: 0.6120, G loss: 1.4556\n",
      "[1444/1762] D loss: 0.6360, G loss: 1.3020\n",
      "[1524/1762] D loss: 0.5626, G loss: 1.3609\n",
      "[1604/1762] D loss: 0.5302, G loss: 1.5179\n",
      "[1684/1762] D loss: 0.4635, G loss: 1.4369\n",
      "[1762/1762] D loss: 0.5767, G loss: 1.2106\n",
      "train error: \n",
      " D loss: 0.600448, G loss: 1.450667, D accuracy: 95.7%, cell accuracy: 79.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.589880, G loss: 1.466254, D accuracy: 96.4%, cell accuracy: 79.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5130, G loss: 1.4184\n",
      "[84/1762] D loss: 0.6236, G loss: 1.3870\n",
      "[164/1762] D loss: 0.4959, G loss: 1.5364\n",
      "[244/1762] D loss: 0.5687, G loss: 1.4558\n",
      "[324/1762] D loss: 0.4704, G loss: 1.5404\n",
      "[404/1762] D loss: 0.5307, G loss: 1.4928\n",
      "[484/1762] D loss: 0.5065, G loss: 1.5482\n",
      "[564/1762] D loss: 0.4917, G loss: 1.5648\n",
      "[644/1762] D loss: 0.6008, G loss: 1.2249\n",
      "[724/1762] D loss: 0.5048, G loss: 1.6203\n",
      "[804/1762] D loss: 0.5030, G loss: 1.4511\n",
      "[884/1762] D loss: 0.5233, G loss: 1.4192\n",
      "[964/1762] D loss: 0.5468, G loss: 1.6529\n",
      "[1044/1762] D loss: 0.4317, G loss: 1.5376\n",
      "[1124/1762] D loss: 0.4694, G loss: 1.5586\n",
      "[1204/1762] D loss: 0.4943, G loss: 1.6512\n",
      "[1284/1762] D loss: 0.4638, G loss: 1.7004\n",
      "[1364/1762] D loss: 0.5255, G loss: 1.6310\n",
      "[1444/1762] D loss: 0.5309, G loss: 1.7002\n",
      "[1524/1762] D loss: 0.4892, G loss: 1.5770\n",
      "[1604/1762] D loss: 0.4489, G loss: 1.7843\n",
      "[1684/1762] D loss: 0.4806, G loss: 1.6232\n",
      "[1762/1762] D loss: 0.3891, G loss: 1.6474\n",
      "train error: \n",
      " D loss: 0.673950, G loss: 1.637026, D accuracy: 98.2%, cell accuracy: 80.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658504, G loss: 1.703109, D accuracy: 98.2%, cell accuracy: 78.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5004, G loss: 1.6049\n",
      "[84/1762] D loss: 0.4429, G loss: 1.8390\n",
      "[164/1762] D loss: 0.3559, G loss: 1.8546\n",
      "[244/1762] D loss: 0.3824, G loss: 1.6645\n",
      "[324/1762] D loss: 0.3792, G loss: 1.8206\n",
      "[404/1762] D loss: 0.4593, G loss: 1.6585\n",
      "[484/1762] D loss: 0.4878, G loss: 1.6470\n",
      "[564/1762] D loss: 0.3670, G loss: 1.8542\n",
      "[644/1762] D loss: 0.4260, G loss: 1.7484\n",
      "[724/1762] D loss: 0.3688, G loss: 1.8367\n",
      "[804/1762] D loss: 0.3786, G loss: 1.6304\n",
      "[884/1762] D loss: 0.4030, G loss: 1.9639\n",
      "[964/1762] D loss: 0.3691, G loss: 1.9103\n",
      "[1044/1762] D loss: 0.4201, G loss: 1.8925\n",
      "[1124/1762] D loss: 0.3763, G loss: 1.7867\n",
      "[1204/1762] D loss: 0.3669, G loss: 1.8872\n",
      "[1284/1762] D loss: 0.4581, G loss: 1.6408\n",
      "[1364/1762] D loss: 0.3634, G loss: 1.5690\n",
      "[1444/1762] D loss: 0.3742, G loss: 1.6456\n",
      "[1524/1762] D loss: 0.3340, G loss: 1.7622\n",
      "[1604/1762] D loss: 0.3281, G loss: 1.8326\n",
      "[1684/1762] D loss: 0.3236, G loss: 1.9377\n",
      "[1762/1762] D loss: 0.3680, G loss: 1.8018\n",
      "train error: \n",
      " D loss: 0.934715, G loss: 1.474529, D accuracy: 83.0%, cell accuracy: 82.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.946998, G loss: 1.445163, D accuracy: 82.8%, cell accuracy: 81.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3328, G loss: 1.6362\n",
      "[84/1762] D loss: 0.3545, G loss: 1.8533\n",
      "[164/1762] D loss: 0.3267, G loss: 2.0296\n",
      "[244/1762] D loss: 0.4327, G loss: 1.6010\n",
      "[324/1762] D loss: 0.3446, G loss: 1.6605\n",
      "[404/1762] D loss: 0.3840, G loss: 1.6771\n",
      "[484/1762] D loss: 0.3199, G loss: 1.9054\n",
      "[564/1762] D loss: 0.3998, G loss: 1.6334\n",
      "[644/1762] D loss: 0.4960, G loss: 1.5787\n",
      "[724/1762] D loss: 0.3954, G loss: 1.6661\n",
      "[804/1762] D loss: 0.3829, G loss: 1.7724\n",
      "[884/1762] D loss: 0.4642, G loss: 1.3731\n",
      "[964/1762] D loss: 0.3900, G loss: 1.8345\n",
      "[1044/1762] D loss: 0.5862, G loss: 1.3691\n",
      "[1124/1762] D loss: 0.4658, G loss: 1.5278\n",
      "[1204/1762] D loss: 0.3856, G loss: 1.8908\n",
      "[1284/1762] D loss: 0.5028, G loss: 1.4714\n",
      "[1364/1762] D loss: 0.4731, G loss: 1.5899\n",
      "[1444/1762] D loss: 0.4342, G loss: 1.6119\n",
      "[1524/1762] D loss: 0.3784, G loss: 1.7715\n",
      "[1604/1762] D loss: 0.4650, G loss: 1.6254\n",
      "[1684/1762] D loss: 0.4343, G loss: 1.8850\n",
      "[1762/1762] D loss: 0.6735, G loss: 1.2844\n",
      "train error: \n",
      " D loss: 0.755357, G loss: 1.473605, D accuracy: 93.2%, cell accuracy: 95.0%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.772145, G loss: 1.466371, D accuracy: 92.5%, cell accuracy: 94.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4597, G loss: 1.5357\n",
      "[84/1762] D loss: 0.4449, G loss: 1.6522\n",
      "[164/1762] D loss: 0.6398, G loss: 1.8298\n",
      "[244/1762] D loss: 0.7450, G loss: 1.3055\n",
      "[324/1762] D loss: 0.5556, G loss: 1.4121\n",
      "[404/1762] D loss: 0.6510, G loss: 1.6915\n",
      "[484/1762] D loss: 0.7398, G loss: 1.2300\n",
      "[564/1762] D loss: 0.5217, G loss: 1.7331\n",
      "[644/1762] D loss: 0.7888, G loss: 1.3191\n",
      "[724/1762] D loss: 0.5810, G loss: 1.5666\n",
      "[804/1762] D loss: 0.7056, G loss: 1.3824\n",
      "[884/1762] D loss: 0.6643, G loss: 1.5487\n",
      "[964/1762] D loss: 0.4839, G loss: 1.8356\n",
      "[1044/1762] D loss: 0.6341, G loss: 1.4634\n",
      "[1124/1762] D loss: 0.9433, G loss: 1.3954\n",
      "[1204/1762] D loss: 0.5336, G loss: 1.5230\n",
      "[1284/1762] D loss: 0.8010, G loss: 1.2770\n",
      "[1364/1762] D loss: 0.7394, G loss: 1.5964\n",
      "[1444/1762] D loss: 0.6150, G loss: 1.6862\n",
      "[1524/1762] D loss: 0.4848, G loss: 1.6693\n",
      "[1604/1762] D loss: 0.5922, G loss: 1.5199\n",
      "[1684/1762] D loss: 0.7129, G loss: 1.5706\n",
      "[1762/1762] D loss: 0.9059, G loss: 1.2632\n",
      "train error: \n",
      " D loss: 0.827216, G loss: 1.290332, D accuracy: 90.4%, cell accuracy: 97.0%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.842616, G loss: 1.283309, D accuracy: 89.4%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6456, G loss: 1.3957\n",
      "[84/1762] D loss: 0.9519, G loss: 1.5387\n",
      "[164/1762] D loss: 0.6661, G loss: 1.2705\n",
      "[244/1762] D loss: 0.6989, G loss: 1.3208\n",
      "[324/1762] D loss: 0.7120, G loss: 1.5370\n",
      "[404/1762] D loss: 0.8914, G loss: 1.4150\n",
      "[484/1762] D loss: 0.8808, G loss: 1.3298\n",
      "[564/1762] D loss: 0.6218, G loss: 1.3182\n",
      "[644/1762] D loss: 0.5643, G loss: 1.7898\n",
      "[724/1762] D loss: 0.8690, G loss: 1.1890\n",
      "[804/1762] D loss: 0.7071, G loss: 1.5704\n",
      "[884/1762] D loss: 0.5868, G loss: 1.7609\n",
      "[964/1762] D loss: 0.6642, G loss: 1.2402\n",
      "[1044/1762] D loss: 0.5500, G loss: 1.6251\n",
      "[1124/1762] D loss: 0.4801, G loss: 1.6577\n",
      "[1204/1762] D loss: 0.6255, G loss: 1.3697\n",
      "[1284/1762] D loss: 0.6595, G loss: 1.8272\n",
      "[1364/1762] D loss: 0.9802, G loss: 0.9839\n",
      "[1444/1762] D loss: 1.0785, G loss: 1.1490\n",
      "[1524/1762] D loss: 0.6746, G loss: 1.4662\n",
      "[1604/1762] D loss: 0.4178, G loss: 1.5844\n",
      "[1684/1762] D loss: 0.8661, G loss: 0.7517\n",
      "[1762/1762] D loss: 0.6533, G loss: 1.7417\n",
      "train error: \n",
      " D loss: 1.109210, G loss: 1.810990, D accuracy: 67.2%, cell accuracy: 97.7%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.133894, G loss: 1.824661, D accuracy: 67.8%, cell accuracy: 97.7%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8501, G loss: 0.7515\n",
      "[84/1762] D loss: 0.6688, G loss: 1.3358\n",
      "[164/1762] D loss: 0.7284, G loss: 1.3366\n",
      "[244/1762] D loss: 0.4957, G loss: 1.6148\n",
      "[324/1762] D loss: 0.6031, G loss: 1.8261\n",
      "[404/1762] D loss: 0.7161, G loss: 1.4606\n",
      "[484/1762] D loss: 0.4378, G loss: 1.7284\n",
      "[564/1762] D loss: 0.7590, G loss: 1.9038\n",
      "[644/1762] D loss: 0.6919, G loss: 1.1646\n",
      "[724/1762] D loss: 0.8614, G loss: 0.9272\n",
      "[804/1762] D loss: 0.8543, G loss: 1.0992\n",
      "[884/1762] D loss: 0.9064, G loss: 0.8565\n",
      "[964/1762] D loss: 0.7370, G loss: 1.4749\n",
      "[1044/1762] D loss: 0.8744, G loss: 1.3340\n",
      "[1124/1762] D loss: 0.6936, G loss: 1.3564\n",
      "[1204/1762] D loss: 0.5646, G loss: 1.6010\n",
      "[1284/1762] D loss: 0.9340, G loss: 1.3534\n",
      "[1364/1762] D loss: 0.9237, G loss: 1.4772\n",
      "[1444/1762] D loss: 0.8446, G loss: 1.3459\n",
      "[1524/1762] D loss: 0.7736, G loss: 1.4496\n",
      "[1604/1762] D loss: 1.3106, G loss: 1.1090\n",
      "[1684/1762] D loss: 1.4043, G loss: 1.0411\n",
      "[1762/1762] D loss: 1.0901, G loss: 1.3402\n",
      "train error: \n",
      " D loss: 1.094474, G loss: 1.381917, D accuracy: 72.0%, cell accuracy: 98.8%, board accuracy: 13.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.097961, G loss: 1.424676, D accuracy: 73.1%, cell accuracy: 98.7%, board accuracy: 12.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3232, G loss: 0.6694\n",
      "[84/1762] D loss: 0.9481, G loss: 0.9395\n",
      "[164/1762] D loss: 0.9115, G loss: 1.1067\n",
      "[244/1762] D loss: 0.6302, G loss: 1.6452\n",
      "[324/1762] D loss: 1.0505, G loss: 1.2075\n",
      "[404/1762] D loss: 0.9281, G loss: 0.9838\n",
      "[484/1762] D loss: 1.0345, G loss: 0.9668\n",
      "[564/1762] D loss: 1.0570, G loss: 1.0690\n",
      "[644/1762] D loss: 0.9062, G loss: 0.8239\n",
      "[724/1762] D loss: 0.8535, G loss: 1.2009\n",
      "[804/1762] D loss: 1.0895, G loss: 1.1350\n",
      "[884/1762] D loss: 1.0028, G loss: 0.9788\n",
      "[964/1762] D loss: 1.1597, G loss: 0.9913\n",
      "[1044/1762] D loss: 1.0233, G loss: 0.8485\n",
      "[1124/1762] D loss: 1.7803, G loss: 0.3502\n",
      "[1204/1762] D loss: 1.3089, G loss: 1.2213\n",
      "[1284/1762] D loss: 0.8612, G loss: 1.0127\n",
      "[1364/1762] D loss: 1.1489, G loss: 1.1319\n",
      "[1444/1762] D loss: 0.6014, G loss: 1.5635\n",
      "[1524/1762] D loss: 1.1893, G loss: 0.9632\n",
      "[1604/1762] D loss: 1.1665, G loss: 0.6499\n",
      "[1684/1762] D loss: 0.9430, G loss: 1.2028\n",
      "[1762/1762] D loss: 1.1349, G loss: 1.2625\n",
      "train error: \n",
      " D loss: 1.365557, G loss: 1.641467, D accuracy: 56.1%, cell accuracy: 99.4%, board accuracy: 48.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366487, G loss: 1.683839, D accuracy: 56.6%, cell accuracy: 99.3%, board accuracy: 48.6% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1150, G loss: 0.4817\n",
      "[84/1762] D loss: 1.3199, G loss: 1.1250\n",
      "[164/1762] D loss: 1.0185, G loss: 0.9326\n",
      "[244/1762] D loss: 0.8511, G loss: 1.1809\n",
      "[324/1762] D loss: 1.2536, G loss: 0.6516\n",
      "[404/1762] D loss: 0.9873, G loss: 0.9727\n",
      "[484/1762] D loss: 1.0757, G loss: 0.8194\n",
      "[564/1762] D loss: 1.0089, G loss: 1.3594\n",
      "[644/1762] D loss: 1.4837, G loss: 0.8162\n",
      "[724/1762] D loss: 1.2395, G loss: 1.3074\n",
      "[804/1762] D loss: 1.2319, G loss: 1.0129\n",
      "[884/1762] D loss: 0.7964, G loss: 1.7984\n",
      "[964/1762] D loss: 1.1399, G loss: 1.3558\n",
      "[1044/1762] D loss: 1.1545, G loss: 1.5322\n",
      "[1124/1762] D loss: 1.0767, G loss: 0.7327\n",
      "[1204/1762] D loss: 0.9248, G loss: 0.8833\n",
      "[1284/1762] D loss: 1.1283, G loss: 0.8342\n",
      "[1364/1762] D loss: 1.0953, G loss: 1.4610\n",
      "[1444/1762] D loss: 1.0340, G loss: 1.2329\n",
      "[1524/1762] D loss: 1.0310, G loss: 1.1036\n",
      "[1604/1762] D loss: 1.1896, G loss: 1.2888\n",
      "[1684/1762] D loss: 1.3683, G loss: 0.5085\n",
      "[1762/1762] D loss: 1.2741, G loss: 1.7220\n",
      "train error: \n",
      " D loss: 1.266506, G loss: 1.344387, D accuracy: 62.3%, cell accuracy: 99.5%, board accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264017, G loss: 1.380197, D accuracy: 61.7%, cell accuracy: 99.5%, board accuracy: 57.3% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0638, G loss: 0.7227\n",
      "[84/1762] D loss: 1.1778, G loss: 0.7483\n",
      "[164/1762] D loss: 1.1472, G loss: 0.7431\n",
      "[244/1762] D loss: 1.2566, G loss: 0.8901\n",
      "[324/1762] D loss: 1.3615, G loss: 0.5544\n",
      "[404/1762] D loss: 0.9582, G loss: 1.1629\n",
      "[484/1762] D loss: 0.9999, G loss: 1.3649\n",
      "[564/1762] D loss: 1.0245, G loss: 1.0525\n",
      "[644/1762] D loss: 1.4460, G loss: 0.5053\n",
      "[724/1762] D loss: 1.1178, G loss: 0.8572\n",
      "[804/1762] D loss: 1.4263, G loss: 0.9111\n",
      "[884/1762] D loss: 1.2650, G loss: 0.9219\n",
      "[964/1762] D loss: 1.3366, G loss: 1.0877\n",
      "[1044/1762] D loss: 1.3681, G loss: 0.7641\n",
      "[1124/1762] D loss: 1.1459, G loss: 0.7673\n",
      "[1204/1762] D loss: 1.0625, G loss: 0.9222\n",
      "[1284/1762] D loss: 1.1656, G loss: 0.7489\n",
      "[1364/1762] D loss: 1.3001, G loss: 0.8098\n",
      "[1444/1762] D loss: 1.0400, G loss: 1.0131\n",
      "[1524/1762] D loss: 1.1834, G loss: 0.8651\n",
      "[1604/1762] D loss: 1.1448, G loss: 0.8645\n",
      "[1684/1762] D loss: 1.1687, G loss: 0.9188\n",
      "[1762/1762] D loss: 1.0858, G loss: 0.7625\n",
      "train error: \n",
      " D loss: 1.344019, G loss: 0.526321, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327614, G loss: 0.545631, D accuracy: 58.1%, cell accuracy: 99.6%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4604, G loss: 0.9639\n",
      "[84/1762] D loss: 0.8460, G loss: 1.0945\n",
      "[164/1762] D loss: 1.1094, G loss: 1.3333\n",
      "[244/1762] D loss: 1.1322, G loss: 1.0067\n",
      "[324/1762] D loss: 1.3261, G loss: 1.1238\n",
      "[404/1762] D loss: 1.4033, G loss: 0.7671\n",
      "[484/1762] D loss: 1.2220, G loss: 0.7811\n",
      "[564/1762] D loss: 1.3681, G loss: 0.8994\n",
      "[644/1762] D loss: 1.3707, G loss: 1.0092\n",
      "[724/1762] D loss: 1.0054, G loss: 1.0512\n",
      "[804/1762] D loss: 1.3156, G loss: 0.9155\n",
      "[884/1762] D loss: 1.2167, G loss: 1.2085\n",
      "[964/1762] D loss: 0.8866, G loss: 1.1636\n",
      "[1044/1762] D loss: 1.1072, G loss: 1.3173\n",
      "[1124/1762] D loss: 1.1839, G loss: 0.7880\n",
      "[1204/1762] D loss: 1.0971, G loss: 1.1270\n",
      "[1284/1762] D loss: 1.2900, G loss: 0.7558\n",
      "[1364/1762] D loss: 1.0790, G loss: 1.3289\n",
      "[1444/1762] D loss: 1.1652, G loss: 0.7533\n",
      "[1524/1762] D loss: 1.3158, G loss: 0.9591\n",
      "[1604/1762] D loss: 1.3078, G loss: 0.5044\n",
      "[1684/1762] D loss: 0.7579, G loss: 1.2498\n",
      "[1762/1762] D loss: 0.8156, G loss: 1.3379\n",
      "train error: \n",
      " D loss: 1.267792, G loss: 0.966703, D accuracy: 62.2%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257283, G loss: 0.993430, D accuracy: 62.3%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3475, G loss: 0.7204\n",
      "[84/1762] D loss: 1.0464, G loss: 1.0315\n",
      "[164/1762] D loss: 1.0756, G loss: 0.8906\n",
      "[244/1762] D loss: 1.3067, G loss: 0.8269\n",
      "[324/1762] D loss: 1.2464, G loss: 0.7864\n",
      "[404/1762] D loss: 1.3213, G loss: 0.8485\n",
      "[484/1762] D loss: 1.0282, G loss: 0.8954\n",
      "[564/1762] D loss: 1.1190, G loss: 0.8225\n",
      "[644/1762] D loss: 1.0557, G loss: 0.9592\n",
      "[724/1762] D loss: 1.6217, G loss: 0.8000\n",
      "[804/1762] D loss: 1.3912, G loss: 1.4176\n",
      "[884/1762] D loss: 1.0307, G loss: 1.0199\n",
      "[964/1762] D loss: 1.1380, G loss: 0.9495\n",
      "[1044/1762] D loss: 1.1731, G loss: 0.7370\n",
      "[1124/1762] D loss: 1.3788, G loss: 0.8720\n",
      "[1204/1762] D loss: 1.0523, G loss: 0.9717\n",
      "[1284/1762] D loss: 1.3417, G loss: 0.6727\n",
      "[1364/1762] D loss: 1.3770, G loss: 0.8683\n",
      "[1444/1762] D loss: 1.0502, G loss: 1.0944\n",
      "[1524/1762] D loss: 1.2540, G loss: 0.7461\n",
      "[1604/1762] D loss: 1.1327, G loss: 0.7219\n",
      "[1684/1762] D loss: 0.9806, G loss: 1.2319\n",
      "[1762/1762] D loss: 0.6955, G loss: 1.3758\n",
      "train error: \n",
      " D loss: 1.278176, G loss: 0.888827, D accuracy: 61.1%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260861, G loss: 0.908547, D accuracy: 61.3%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9889, G loss: 1.0843\n",
      "[84/1762] D loss: 1.5141, G loss: 0.7351\n",
      "[164/1762] D loss: 1.0621, G loss: 0.8211\n",
      "[244/1762] D loss: 1.2775, G loss: 0.5688\n",
      "[324/1762] D loss: 1.1182, G loss: 1.0514\n",
      "[404/1762] D loss: 1.1510, G loss: 0.9149\n",
      "[484/1762] D loss: 1.0626, G loss: 0.9974\n",
      "[564/1762] D loss: 1.3621, G loss: 0.9238\n",
      "[644/1762] D loss: 1.2120, G loss: 0.7457\n",
      "[724/1762] D loss: 1.3274, G loss: 0.8404\n",
      "[804/1762] D loss: 1.3084, G loss: 0.7520\n",
      "[884/1762] D loss: 1.3121, G loss: 0.7880\n",
      "[964/1762] D loss: 1.3852, G loss: 0.7800\n",
      "[1044/1762] D loss: 1.4174, G loss: 0.8449\n",
      "[1124/1762] D loss: 1.2746, G loss: 0.7344\n",
      "[1204/1762] D loss: 1.1075, G loss: 0.8784\n",
      "[1284/1762] D loss: 1.4074, G loss: 0.5694\n",
      "[1364/1762] D loss: 1.0077, G loss: 1.2323\n",
      "[1444/1762] D loss: 1.3249, G loss: 0.7741\n",
      "[1524/1762] D loss: 0.7228, G loss: 1.4055\n",
      "[1604/1762] D loss: 1.2367, G loss: 1.0022\n",
      "[1684/1762] D loss: 0.8200, G loss: 1.2441\n",
      "[1762/1762] D loss: 1.3240, G loss: 0.7133\n",
      "train error: \n",
      " D loss: 1.302940, G loss: 0.618159, D accuracy: 58.8%, cell accuracy: 99.7%, board accuracy: 79.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288558, G loss: 0.632140, D accuracy: 60.2%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0279, G loss: 1.4957\n",
      "[84/1762] D loss: 1.2985, G loss: 0.8132\n",
      "[164/1762] D loss: 1.3296, G loss: 0.7248\n",
      "[244/1762] D loss: 1.4793, G loss: 0.5053\n",
      "[324/1762] D loss: 1.0776, G loss: 0.8492\n",
      "[404/1762] D loss: 1.4264, G loss: 0.9474\n",
      "[484/1762] D loss: 0.9360, G loss: 1.1253\n",
      "[564/1762] D loss: 1.3241, G loss: 0.8114\n",
      "[644/1762] D loss: 1.3790, G loss: 0.7542\n",
      "[724/1762] D loss: 1.2077, G loss: 0.8302\n",
      "[804/1762] D loss: 1.1922, G loss: 0.9011\n",
      "[884/1762] D loss: 0.7073, G loss: 1.4434\n",
      "[964/1762] D loss: 1.3529, G loss: 0.7290\n",
      "[1044/1762] D loss: 1.3933, G loss: 0.6075\n",
      "[1124/1762] D loss: 1.3973, G loss: 0.7317\n",
      "[1204/1762] D loss: 1.3259, G loss: 0.8212\n",
      "[1284/1762] D loss: 1.2300, G loss: 0.7715\n",
      "[1364/1762] D loss: 0.7404, G loss: 1.3619\n",
      "[1444/1762] D loss: 1.4037, G loss: 0.8781\n",
      "[1524/1762] D loss: 1.2959, G loss: 0.7440\n",
      "[1604/1762] D loss: 1.3350, G loss: 0.7148\n",
      "[1684/1762] D loss: 1.3199, G loss: 0.7721\n",
      "[1762/1762] D loss: 1.2197, G loss: 0.6747\n",
      "train error: \n",
      " D loss: 1.299095, G loss: 0.636655, D accuracy: 59.6%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280985, G loss: 0.654120, D accuracy: 62.4%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4306, G loss: 0.8940\n",
      "[84/1762] D loss: 1.3854, G loss: 0.6864\n",
      "[164/1762] D loss: 1.3554, G loss: 0.5678\n",
      "[244/1762] D loss: 1.3365, G loss: 0.8134\n",
      "[324/1762] D loss: 1.3635, G loss: 0.5629\n",
      "[404/1762] D loss: 1.0082, G loss: 0.7247\n",
      "[484/1762] D loss: 1.3205, G loss: 0.7156\n",
      "[564/1762] D loss: 1.4334, G loss: 0.5031\n",
      "[644/1762] D loss: 1.4649, G loss: 0.8747\n",
      "[724/1762] D loss: 1.2312, G loss: 0.9755\n",
      "[804/1762] D loss: 1.0597, G loss: 0.9822\n",
      "[884/1762] D loss: 0.9395, G loss: 0.9484\n",
      "[964/1762] D loss: 1.2450, G loss: 1.1255\n",
      "[1044/1762] D loss: 1.3056, G loss: 0.7663\n",
      "[1124/1762] D loss: 1.3592, G loss: 0.6966\n",
      "[1204/1762] D loss: 1.3172, G loss: 0.8162\n",
      "[1284/1762] D loss: 1.2643, G loss: 0.7143\n",
      "[1364/1762] D loss: 1.3809, G loss: 0.8427\n",
      "[1444/1762] D loss: 0.9171, G loss: 1.0827\n",
      "[1524/1762] D loss: 0.9021, G loss: 1.1192\n",
      "[1604/1762] D loss: 1.3571, G loss: 0.7209\n",
      "[1684/1762] D loss: 0.8538, G loss: 1.5067\n",
      "[1762/1762] D loss: 1.3942, G loss: 0.8119\n",
      "train error: \n",
      " D loss: 1.282643, G loss: 0.853395, D accuracy: 63.2%, cell accuracy: 99.8%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269971, G loss: 0.863283, D accuracy: 62.7%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3836, G loss: 0.6336\n",
      "[84/1762] D loss: 1.3103, G loss: 0.7529\n",
      "[164/1762] D loss: 1.0296, G loss: 1.0120\n",
      "[244/1762] D loss: 1.2223, G loss: 0.5456\n",
      "[324/1762] D loss: 1.4164, G loss: 0.5236\n",
      "[404/1762] D loss: 1.3069, G loss: 0.5446\n",
      "[484/1762] D loss: 1.3861, G loss: 0.8375\n",
      "[564/1762] D loss: 1.3000, G loss: 1.0424\n",
      "[644/1762] D loss: 1.2945, G loss: 0.7748\n",
      "[724/1762] D loss: 0.6886, G loss: 1.3476\n",
      "[804/1762] D loss: 1.3333, G loss: 0.7659\n",
      "[884/1762] D loss: 1.3486, G loss: 0.7500\n",
      "[964/1762] D loss: 0.9100, G loss: 1.1480\n",
      "[1044/1762] D loss: 1.3514, G loss: 0.7228\n",
      "[1124/1762] D loss: 1.3264, G loss: 0.5539\n",
      "[1204/1762] D loss: 1.4432, G loss: 0.7558\n",
      "[1284/1762] D loss: 0.9974, G loss: 1.0860\n",
      "[1364/1762] D loss: 1.3827, G loss: 0.7834\n",
      "[1444/1762] D loss: 1.3644, G loss: 0.7006\n",
      "[1524/1762] D loss: 1.0008, G loss: 1.2050\n",
      "[1604/1762] D loss: 1.3490, G loss: 0.7460\n",
      "[1684/1762] D loss: 1.4068, G loss: 0.4676\n",
      "[1762/1762] D loss: 1.2954, G loss: 0.8251\n",
      "train error: \n",
      " D loss: 1.330550, G loss: 1.025968, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318825, G loss: 1.038741, D accuracy: 57.2%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4399, G loss: 0.5697\n",
      "[84/1762] D loss: 1.4323, G loss: 0.5265\n",
      "[164/1762] D loss: 0.8970, G loss: 1.1741\n",
      "[244/1762] D loss: 0.8918, G loss: 1.1751\n",
      "[324/1762] D loss: 1.4178, G loss: 0.7939\n",
      "[404/1762] D loss: 1.4058, G loss: 0.6445\n",
      "[484/1762] D loss: 1.4317, G loss: 0.5429\n",
      "[564/1762] D loss: 1.4180, G loss: 1.0416\n",
      "[644/1762] D loss: 1.3789, G loss: 0.7705\n",
      "[724/1762] D loss: 1.3743, G loss: 0.7332\n",
      "[804/1762] D loss: 1.3754, G loss: 0.7759\n",
      "[884/1762] D loss: 0.8140, G loss: 1.2629\n",
      "[964/1762] D loss: 1.4012, G loss: 0.8932\n",
      "[1044/1762] D loss: 1.4033, G loss: 0.6507\n",
      "[1124/1762] D loss: 1.3266, G loss: 0.9511\n",
      "[1204/1762] D loss: 1.3380, G loss: 0.8706\n",
      "[1284/1762] D loss: 0.9942, G loss: 1.2518\n",
      "[1364/1762] D loss: 1.0013, G loss: 1.0209\n",
      "[1444/1762] D loss: 1.4320, G loss: 0.6795\n",
      "[1524/1762] D loss: 1.3412, G loss: 0.7109\n",
      "[1604/1762] D loss: 0.7999, G loss: 1.2903\n",
      "[1684/1762] D loss: 1.2793, G loss: 0.8917\n",
      "[1762/1762] D loss: 1.6323, G loss: 0.9386\n",
      "train error: \n",
      " D loss: 1.360693, G loss: 1.060753, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 77.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344903, G loss: 1.076592, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4241, G loss: 0.5813\n",
      "[84/1762] D loss: 1.2868, G loss: 0.7413\n",
      "[164/1762] D loss: 1.0885, G loss: 0.9721\n",
      "[244/1762] D loss: 1.3900, G loss: 0.6267\n",
      "[324/1762] D loss: 1.4316, G loss: 0.6513\n",
      "[404/1762] D loss: 0.7509, G loss: 1.4770\n",
      "[484/1762] D loss: 1.3087, G loss: 0.7884\n",
      "[564/1762] D loss: 1.3039, G loss: 0.7696\n",
      "[644/1762] D loss: 1.2730, G loss: 0.8265\n",
      "[724/1762] D loss: 0.8971, G loss: 1.1252\n",
      "[804/1762] D loss: 0.8501, G loss: 1.2862\n",
      "[884/1762] D loss: 1.2930, G loss: 0.8589\n",
      "[964/1762] D loss: 1.1031, G loss: 0.8788\n",
      "[1044/1762] D loss: 1.1646, G loss: 0.5837\n",
      "[1124/1762] D loss: 0.9340, G loss: 1.0086\n",
      "[1204/1762] D loss: 0.9783, G loss: 1.2366\n",
      "[1284/1762] D loss: 1.2156, G loss: 1.0888\n",
      "[1364/1762] D loss: 1.0562, G loss: 0.9340\n",
      "[1444/1762] D loss: 1.3362, G loss: 0.7496\n",
      "[1524/1762] D loss: 1.0072, G loss: 1.1358\n",
      "[1604/1762] D loss: 1.3713, G loss: 0.7722\n",
      "[1684/1762] D loss: 0.8031, G loss: 1.3824\n",
      "[1762/1762] D loss: 1.3329, G loss: 0.6641\n",
      "train error: \n",
      " D loss: 1.334788, G loss: 0.585460, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328213, G loss: 0.586485, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3531, G loss: 0.7284\n",
      "[84/1762] D loss: 1.2968, G loss: 0.7608\n",
      "[164/1762] D loss: 1.3800, G loss: 0.7198\n",
      "[244/1762] D loss: 1.3257, G loss: 0.7815\n",
      "[324/1762] D loss: 1.3740, G loss: 0.6852\n",
      "[404/1762] D loss: 1.3328, G loss: 0.7372\n",
      "[484/1762] D loss: 1.2339, G loss: 0.7562\n",
      "[564/1762] D loss: 0.9353, G loss: 0.9828\n",
      "[644/1762] D loss: 1.4183, G loss: 0.5126\n",
      "[724/1762] D loss: 1.3378, G loss: 0.7057\n",
      "[804/1762] D loss: 1.3536, G loss: 0.7198\n",
      "[884/1762] D loss: 0.8929, G loss: 1.2919\n",
      "[964/1762] D loss: 0.8108, G loss: 1.1860\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.7202\n",
      "[1124/1762] D loss: 1.4389, G loss: 0.7400\n",
      "[1204/1762] D loss: 1.3059, G loss: 0.6793\n",
      "[1284/1762] D loss: 1.2731, G loss: 0.7419\n",
      "[1364/1762] D loss: 1.3430, G loss: 0.7159\n",
      "[1444/1762] D loss: 1.2731, G loss: 0.9042\n",
      "[1524/1762] D loss: 1.4543, G loss: 0.4606\n",
      "[1604/1762] D loss: 1.4358, G loss: 0.5144\n",
      "[1684/1762] D loss: 1.3705, G loss: 0.7115\n",
      "[1762/1762] D loss: 1.0579, G loss: 0.7626\n",
      "train error: \n",
      " D loss: 1.394069, G loss: 0.495621, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 77.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393101, G loss: 0.492683, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5109, G loss: 0.8310\n",
      "[84/1762] D loss: 1.3732, G loss: 0.6538\n",
      "[164/1762] D loss: 1.3555, G loss: 0.7224\n",
      "[244/1762] D loss: 1.3677, G loss: 0.6342\n",
      "[324/1762] D loss: 1.2834, G loss: 0.7202\n",
      "[404/1762] D loss: 1.3187, G loss: 0.7518\n",
      "[484/1762] D loss: 0.8073, G loss: 1.2264\n",
      "[564/1762] D loss: 1.3535, G loss: 0.7101\n",
      "[644/1762] D loss: 1.3422, G loss: 0.7262\n",
      "[724/1762] D loss: 1.4309, G loss: 0.5708\n",
      "[804/1762] D loss: 1.3203, G loss: 0.7371\n",
      "[884/1762] D loss: 1.3635, G loss: 0.7217\n",
      "[964/1762] D loss: 0.8390, G loss: 1.1827\n",
      "[1044/1762] D loss: 1.3646, G loss: 0.6981\n",
      "[1124/1762] D loss: 1.0888, G loss: 0.9717\n",
      "[1204/1762] D loss: 1.3745, G loss: 0.7234\n",
      "[1284/1762] D loss: 1.2783, G loss: 0.8145\n",
      "[1364/1762] D loss: 1.3486, G loss: 0.8072\n",
      "[1444/1762] D loss: 1.3542, G loss: 0.7562\n",
      "[1524/1762] D loss: 1.3369, G loss: 0.7560\n",
      "[1604/1762] D loss: 1.4278, G loss: 0.7366\n",
      "[1684/1762] D loss: 1.3187, G loss: 0.7692\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7050\n",
      "train error: \n",
      " D loss: 1.308177, G loss: 0.770370, D accuracy: 59.0%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294303, G loss: 0.787106, D accuracy: 61.1%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8138, G loss: 1.3697\n",
      "[84/1762] D loss: 1.3511, G loss: 0.6607\n",
      "[164/1762] D loss: 1.4348, G loss: 0.7002\n",
      "[244/1762] D loss: 0.7022, G loss: 1.3720\n",
      "[324/1762] D loss: 1.3460, G loss: 0.7216\n",
      "[404/1762] D loss: 1.3348, G loss: 0.6974\n",
      "[484/1762] D loss: 1.3087, G loss: 0.7604\n",
      "[564/1762] D loss: 1.2904, G loss: 0.8126\n",
      "[644/1762] D loss: 1.6498, G loss: 0.5759\n",
      "[724/1762] D loss: 1.3298, G loss: 0.7411\n",
      "[804/1762] D loss: 1.3858, G loss: 0.7187\n",
      "[884/1762] D loss: 0.8931, G loss: 1.2514\n",
      "[964/1762] D loss: 1.3495, G loss: 0.7464\n",
      "[1044/1762] D loss: 1.3842, G loss: 0.7300\n",
      "[1124/1762] D loss: 0.8287, G loss: 1.1838\n",
      "[1204/1762] D loss: 1.2930, G loss: 0.7744\n",
      "[1284/1762] D loss: 1.4040, G loss: 0.7367\n",
      "[1364/1762] D loss: 0.6293, G loss: 1.3835\n",
      "[1444/1762] D loss: 1.0554, G loss: 0.9804\n",
      "[1524/1762] D loss: 1.3578, G loss: 0.7525\n",
      "[1604/1762] D loss: 1.5267, G loss: 0.3613\n",
      "[1684/1762] D loss: 1.4466, G loss: 0.6545\n",
      "[1762/1762] D loss: 1.4965, G loss: 0.5971\n",
      "train error: \n",
      " D loss: 1.330299, G loss: 0.589183, D accuracy: 58.2%, cell accuracy: 99.7%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312110, G loss: 0.602390, D accuracy: 59.9%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2388, G loss: 0.8277\n",
      "[84/1762] D loss: 1.2256, G loss: 0.8556\n",
      "[164/1762] D loss: 1.2162, G loss: 1.0205\n",
      "[244/1762] D loss: 0.5659, G loss: 1.4814\n",
      "[324/1762] D loss: 0.9739, G loss: 1.0602\n",
      "[404/1762] D loss: 1.1834, G loss: 1.0227\n",
      "[484/1762] D loss: 1.3603, G loss: 0.7433\n",
      "[564/1762] D loss: 1.3978, G loss: 0.7309\n",
      "[644/1762] D loss: 0.7258, G loss: 1.4411\n",
      "[724/1762] D loss: 1.4331, G loss: 0.7644\n",
      "[804/1762] D loss: 1.3006, G loss: 0.6598\n",
      "[884/1762] D loss: 1.3340, G loss: 0.7086\n",
      "[964/1762] D loss: 1.3937, G loss: 0.7713\n",
      "[1044/1762] D loss: 1.3615, G loss: 0.7898\n",
      "[1124/1762] D loss: 0.8259, G loss: 1.3116\n",
      "[1204/1762] D loss: 1.3626, G loss: 0.7316\n",
      "[1284/1762] D loss: 1.3785, G loss: 0.7500\n",
      "[1364/1762] D loss: 1.3258, G loss: 0.7966\n",
      "[1444/1762] D loss: 1.2684, G loss: 0.7915\n",
      "[1524/1762] D loss: 1.4251, G loss: 0.6365\n",
      "[1604/1762] D loss: 1.2575, G loss: 0.7845\n",
      "[1684/1762] D loss: 1.3799, G loss: 0.7167\n",
      "[1762/1762] D loss: 1.3335, G loss: 0.7200\n",
      "train error: \n",
      " D loss: 1.314133, G loss: 0.742376, D accuracy: 58.2%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303352, G loss: 0.747197, D accuracy: 59.1%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8786, G loss: 1.0854\n",
      "[84/1762] D loss: 1.3436, G loss: 0.7470\n",
      "[164/1762] D loss: 1.2381, G loss: 0.7852\n",
      "[244/1762] D loss: 0.8048, G loss: 1.2010\n",
      "[324/1762] D loss: 1.3240, G loss: 0.7247\n",
      "[404/1762] D loss: 1.3947, G loss: 0.6537\n",
      "[484/1762] D loss: 1.3996, G loss: 0.6978\n",
      "[564/1762] D loss: 0.7958, G loss: 1.3684\n",
      "[644/1762] D loss: 1.4308, G loss: 0.5352\n",
      "[724/1762] D loss: 1.3841, G loss: 0.8091\n",
      "[804/1762] D loss: 1.3620, G loss: 0.7322\n",
      "[884/1762] D loss: 1.2619, G loss: 0.8575\n",
      "[964/1762] D loss: 1.3240, G loss: 0.8219\n",
      "[1044/1762] D loss: 1.4265, G loss: 0.7493\n",
      "[1124/1762] D loss: 1.3606, G loss: 0.7081\n",
      "[1204/1762] D loss: 1.3525, G loss: 0.7201\n",
      "[1284/1762] D loss: 0.8713, G loss: 1.2266\n",
      "[1364/1762] D loss: 1.3721, G loss: 0.7488\n",
      "[1444/1762] D loss: 1.2888, G loss: 0.7649\n",
      "[1524/1762] D loss: 1.4510, G loss: 0.6661\n",
      "[1604/1762] D loss: 0.8797, G loss: 1.2364\n",
      "[1684/1762] D loss: 1.4427, G loss: 0.7008\n",
      "[1762/1762] D loss: 1.2678, G loss: 0.6967\n",
      "train error: \n",
      " D loss: 1.333434, G loss: 0.570423, D accuracy: 60.3%, cell accuracy: 99.5%, board accuracy: 66.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324884, G loss: 0.578792, D accuracy: 60.1%, cell accuracy: 99.5%, board accuracy: 64.1% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4590, G loss: 0.7193\n",
      "[84/1762] D loss: 1.4937, G loss: 1.2654\n",
      "[164/1762] D loss: 1.3923, G loss: 0.8914\n",
      "[244/1762] D loss: 1.1082, G loss: 1.1465\n",
      "[324/1762] D loss: 1.2985, G loss: 0.9230\n",
      "[404/1762] D loss: 0.9030, G loss: 1.0159\n",
      "[484/1762] D loss: 1.3681, G loss: 0.7035\n",
      "[564/1762] D loss: 0.8662, G loss: 1.1179\n",
      "[644/1762] D loss: 1.3387, G loss: 0.8015\n",
      "[724/1762] D loss: 1.3752, G loss: 0.7319\n",
      "[804/1762] D loss: 0.9661, G loss: 1.2039\n",
      "[884/1762] D loss: 1.3294, G loss: 0.7651\n",
      "[964/1762] D loss: 0.9891, G loss: 1.0657\n",
      "[1044/1762] D loss: 1.3827, G loss: 0.7178\n",
      "[1124/1762] D loss: 1.4268, G loss: 0.7143\n",
      "[1204/1762] D loss: 1.3751, G loss: 0.7026\n",
      "[1284/1762] D loss: 0.8268, G loss: 1.1831\n",
      "[1364/1762] D loss: 1.4830, G loss: 0.6151\n",
      "[1444/1762] D loss: 1.3721, G loss: 0.7002\n",
      "[1524/1762] D loss: 1.4103, G loss: 0.7680\n",
      "[1604/1762] D loss: 0.5931, G loss: 1.4537\n",
      "[1684/1762] D loss: 0.9033, G loss: 1.0754\n",
      "[1762/1762] D loss: 1.2753, G loss: 0.7778\n",
      "train error: \n",
      " D loss: 1.327286, G loss: 0.614875, D accuracy: 58.6%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322908, G loss: 0.613653, D accuracy: 59.0%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7069\n",
      "[84/1762] D loss: 0.8263, G loss: 1.2538\n",
      "[164/1762] D loss: 0.4800, G loss: 1.9569\n",
      "[244/1762] D loss: 1.4391, G loss: 0.7210\n",
      "[324/1762] D loss: 0.9202, G loss: 1.5008\n",
      "[404/1762] D loss: 1.3521, G loss: 0.7283\n",
      "[484/1762] D loss: 1.3429, G loss: 0.7072\n",
      "[564/1762] D loss: 1.3545, G loss: 0.5707\n",
      "[644/1762] D loss: 1.4276, G loss: 0.7161\n",
      "[724/1762] D loss: 1.4559, G loss: 0.6557\n",
      "[804/1762] D loss: 1.3819, G loss: 0.7768\n",
      "[884/1762] D loss: 1.3007, G loss: 0.6704\n",
      "[964/1762] D loss: 0.8904, G loss: 1.1645\n",
      "[1044/1762] D loss: 1.4262, G loss: 0.7437\n",
      "[1124/1762] D loss: 1.4037, G loss: 0.7248\n",
      "[1204/1762] D loss: 1.4262, G loss: 0.7147\n",
      "[1284/1762] D loss: 1.4142, G loss: 0.6839\n",
      "[1364/1762] D loss: 1.4561, G loss: 0.6801\n",
      "[1444/1762] D loss: 1.4615, G loss: 0.5846\n",
      "[1524/1762] D loss: 1.4083, G loss: 0.7797\n",
      "[1604/1762] D loss: 1.4199, G loss: 0.7849\n",
      "[1684/1762] D loss: 1.4624, G loss: 0.7034\n",
      "[1762/1762] D loss: 0.6444, G loss: 2.4006\n",
      "train error: \n",
      " D loss: 1.427884, G loss: 1.169763, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 80.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.418499, G loss: 1.184567, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9946, G loss: 0.5394\n",
      "[84/1762] D loss: 1.3508, G loss: 0.6417\n",
      "[164/1762] D loss: 1.4154, G loss: 0.7349\n",
      "[244/1762] D loss: 0.7487, G loss: 1.1784\n",
      "[324/1762] D loss: 1.2698, G loss: 0.8700\n",
      "[404/1762] D loss: 1.0307, G loss: 1.0147\n",
      "[484/1762] D loss: 1.5068, G loss: 0.6671\n",
      "[564/1762] D loss: 0.8827, G loss: 1.1675\n",
      "[644/1762] D loss: 1.0140, G loss: 1.0144\n",
      "[724/1762] D loss: 1.3741, G loss: 0.7288\n",
      "[804/1762] D loss: 1.3841, G loss: 0.7125\n",
      "[884/1762] D loss: 1.3963, G loss: 0.7121\n",
      "[964/1762] D loss: 1.3470, G loss: 0.8141\n",
      "[1044/1762] D loss: 1.4161, G loss: 0.7049\n",
      "[1124/1762] D loss: 1.3303, G loss: 0.7253\n",
      "[1204/1762] D loss: 0.8654, G loss: 1.2114\n",
      "[1284/1762] D loss: 1.4245, G loss: 0.6605\n",
      "[1364/1762] D loss: 1.3433, G loss: 0.6895\n",
      "[1444/1762] D loss: 1.3519, G loss: 0.7460\n",
      "[1524/1762] D loss: 1.4374, G loss: 0.7220\n",
      "[1604/1762] D loss: 1.3957, G loss: 0.7061\n",
      "[1684/1762] D loss: 1.4243, G loss: 0.7206\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7197\n",
      "train error: \n",
      " D loss: 1.324808, G loss: 0.842314, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313795, G loss: 0.852586, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8454, G loss: 1.1605\n",
      "[84/1762] D loss: 0.6783, G loss: 1.3608\n",
      "[164/1762] D loss: 1.1606, G loss: 0.9234\n",
      "[244/1762] D loss: 0.4352, G loss: 1.7522\n",
      "[324/1762] D loss: 1.4018, G loss: 0.7193\n",
      "[404/1762] D loss: 1.4198, G loss: 0.7333\n",
      "[484/1762] D loss: 1.4340, G loss: 0.7090\n",
      "[564/1762] D loss: 1.3371, G loss: 0.7262\n",
      "[644/1762] D loss: 1.3129, G loss: 0.7786\n",
      "[724/1762] D loss: 1.4274, G loss: 0.8430\n",
      "[804/1762] D loss: 0.7369, G loss: 1.2855\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6456\n",
      "[964/1762] D loss: 0.4381, G loss: 1.6916\n",
      "[1044/1762] D loss: 1.4402, G loss: 0.7294\n",
      "[1124/1762] D loss: 0.9202, G loss: 1.2621\n",
      "[1204/1762] D loss: 0.7727, G loss: 1.2181\n",
      "[1284/1762] D loss: 1.4439, G loss: 0.7233\n",
      "[1364/1762] D loss: 1.3670, G loss: 0.7244\n",
      "[1444/1762] D loss: 1.0854, G loss: 1.0625\n",
      "[1524/1762] D loss: 0.6468, G loss: 1.4689\n",
      "[1604/1762] D loss: 1.4577, G loss: 0.7236\n",
      "[1684/1762] D loss: 1.4276, G loss: 0.6929\n",
      "[1762/1762] D loss: 1.3664, G loss: 0.7173\n",
      "train error: \n",
      " D loss: 1.319570, G loss: 0.686818, D accuracy: 58.1%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298397, G loss: 0.707764, D accuracy: 59.4%, cell accuracy: 99.8%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9653, G loss: 1.0018\n",
      "[84/1762] D loss: 1.3964, G loss: 0.7230\n",
      "[164/1762] D loss: 1.3758, G loss: 0.6997\n",
      "[244/1762] D loss: 0.7658, G loss: 1.2777\n",
      "[324/1762] D loss: 0.7140, G loss: 1.2254\n",
      "[404/1762] D loss: 1.3806, G loss: 0.7041\n",
      "[484/1762] D loss: 1.3963, G loss: 0.7264\n",
      "[564/1762] D loss: 1.3936, G loss: 0.6944\n",
      "[644/1762] D loss: 0.3875, G loss: 1.8934\n",
      "[724/1762] D loss: 1.4090, G loss: 0.7206\n",
      "[804/1762] D loss: 1.4594, G loss: 0.6970\n",
      "[884/1762] D loss: 1.3253, G loss: 0.7227\n",
      "[964/1762] D loss: 1.4178, G loss: 0.6304\n",
      "[1044/1762] D loss: 1.4300, G loss: 0.7354\n",
      "[1124/1762] D loss: 1.3981, G loss: 0.6888\n",
      "[1204/1762] D loss: 1.4233, G loss: 0.9259\n",
      "[1284/1762] D loss: 1.3340, G loss: 0.8719\n",
      "[1364/1762] D loss: 0.8548, G loss: 1.1852\n",
      "[1444/1762] D loss: 1.3735, G loss: 0.7011\n",
      "[1524/1762] D loss: 1.3994, G loss: 0.7208\n",
      "[1604/1762] D loss: 1.4178, G loss: 0.7143\n",
      "[1684/1762] D loss: 1.4460, G loss: 0.7200\n",
      "[1762/1762] D loss: 1.4203, G loss: 0.7481\n",
      "train error: \n",
      " D loss: 1.334629, G loss: 0.700467, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323836, G loss: 0.709223, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3030, G loss: 0.7727\n",
      "[84/1762] D loss: 1.3683, G loss: 0.7087\n",
      "[164/1762] D loss: 1.3721, G loss: 0.7057\n",
      "[244/1762] D loss: 1.3695, G loss: 0.7465\n",
      "[324/1762] D loss: 1.4755, G loss: 0.7297\n",
      "[404/1762] D loss: 1.3577, G loss: 0.7029\n",
      "[484/1762] D loss: 1.4412, G loss: 0.7137\n",
      "[564/1762] D loss: 1.3570, G loss: 0.7749\n",
      "[644/1762] D loss: 0.6860, G loss: 1.3968\n",
      "[724/1762] D loss: 1.3368, G loss: 0.6975\n",
      "[804/1762] D loss: 1.4125, G loss: 0.6897\n",
      "[884/1762] D loss: 1.5783, G loss: 0.7748\n",
      "[964/1762] D loss: 1.5491, G loss: 0.6961\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6904\n",
      "[1124/1762] D loss: 1.6323, G loss: 0.6682\n",
      "[1204/1762] D loss: 0.7754, G loss: 1.2790\n",
      "[1284/1762] D loss: 0.8534, G loss: 1.1279\n",
      "[1364/1762] D loss: 1.5266, G loss: 0.5311\n",
      "[1444/1762] D loss: 1.4069, G loss: 0.7070\n",
      "[1524/1762] D loss: 1.5148, G loss: 0.6725\n",
      "[1604/1762] D loss: 1.4259, G loss: 0.7373\n",
      "[1684/1762] D loss: 0.8693, G loss: 1.3064\n",
      "[1762/1762] D loss: 1.1845, G loss: 0.7398\n",
      "train error: \n",
      " D loss: 1.346461, G loss: 0.600159, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335411, G loss: 0.608631, D accuracy: 58.1%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4819, G loss: 0.6992\n",
      "[84/1762] D loss: 1.3798, G loss: 0.6947\n",
      "[164/1762] D loss: 1.4548, G loss: 0.6994\n",
      "[244/1762] D loss: 1.3420, G loss: 0.7188\n",
      "[324/1762] D loss: 1.3536, G loss: 0.7075\n",
      "[404/1762] D loss: 0.7613, G loss: 1.1716\n",
      "[484/1762] D loss: 1.3576, G loss: 0.7854\n",
      "[564/1762] D loss: 0.8149, G loss: 1.1856\n",
      "[644/1762] D loss: 1.4810, G loss: 0.7772\n",
      "[724/1762] D loss: 0.7058, G loss: 1.4244\n",
      "[804/1762] D loss: 1.3266, G loss: 0.8012\n",
      "[884/1762] D loss: 1.3653, G loss: 0.6069\n",
      "[964/1762] D loss: 1.1953, G loss: 0.7785\n",
      "[1044/1762] D loss: 1.3802, G loss: 0.7271\n",
      "[1124/1762] D loss: 1.3753, G loss: 0.8032\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.7025\n",
      "[1284/1762] D loss: 1.4149, G loss: 0.6913\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6791\n",
      "[1444/1762] D loss: 0.7420, G loss: 1.2399\n",
      "[1524/1762] D loss: 1.4104, G loss: 0.6029\n",
      "[1604/1762] D loss: 1.3945, G loss: 0.7165\n",
      "[1684/1762] D loss: 1.4772, G loss: 0.6483\n",
      "[1762/1762] D loss: 1.3836, G loss: 0.7040\n",
      "train error: \n",
      " D loss: 1.332226, G loss: 0.877300, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316794, G loss: 0.897162, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4231, G loss: 0.7165\n",
      "[84/1762] D loss: 1.3489, G loss: 0.7188\n",
      "[164/1762] D loss: 0.7353, G loss: 1.2680\n",
      "[244/1762] D loss: 1.3857, G loss: 0.6980\n",
      "[324/1762] D loss: 1.4199, G loss: 0.6498\n",
      "[404/1762] D loss: 0.6918, G loss: 1.3609\n",
      "[484/1762] D loss: 1.4095, G loss: 0.7196\n",
      "[564/1762] D loss: 1.4643, G loss: 0.7007\n",
      "[644/1762] D loss: 0.7856, G loss: 1.2715\n",
      "[724/1762] D loss: 1.4041, G loss: 0.6955\n",
      "[804/1762] D loss: 1.3786, G loss: 0.7074\n",
      "[884/1762] D loss: 1.3717, G loss: 0.7315\n",
      "[964/1762] D loss: 1.3827, G loss: 0.7137\n",
      "[1044/1762] D loss: 1.3658, G loss: 0.7089\n",
      "[1124/1762] D loss: 1.3857, G loss: 0.7154\n",
      "[1204/1762] D loss: 1.3677, G loss: 0.7148\n",
      "[1284/1762] D loss: 1.3590, G loss: 0.7597\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.6794\n",
      "[1444/1762] D loss: 1.3422, G loss: 0.7191\n",
      "[1524/1762] D loss: 1.3903, G loss: 0.7578\n",
      "[1604/1762] D loss: 1.4092, G loss: 0.7283\n",
      "[1684/1762] D loss: 0.8169, G loss: 1.2630\n",
      "[1762/1762] D loss: 1.3744, G loss: 0.6374\n",
      "train error: \n",
      " D loss: 1.323035, G loss: 0.722352, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303900, G loss: 0.746385, D accuracy: 58.6%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.7190\n",
      "[84/1762] D loss: 1.4123, G loss: 0.6874\n",
      "[164/1762] D loss: 0.6563, G loss: 1.4010\n",
      "[244/1762] D loss: 0.6598, G loss: 1.4362\n",
      "[324/1762] D loss: 1.4131, G loss: 0.7291\n",
      "[404/1762] D loss: 1.3735, G loss: 0.7169\n",
      "[484/1762] D loss: 0.7172, G loss: 1.3058\n",
      "[564/1762] D loss: 1.3125, G loss: 0.7937\n",
      "[644/1762] D loss: 1.3656, G loss: 0.7917\n",
      "[724/1762] D loss: 1.3258, G loss: 0.7796\n",
      "[804/1762] D loss: 1.2020, G loss: 0.9317\n",
      "[884/1762] D loss: 1.1702, G loss: 0.9407\n",
      "[964/1762] D loss: 1.3078, G loss: 0.7349\n",
      "[1044/1762] D loss: 1.4083, G loss: 0.6928\n",
      "[1124/1762] D loss: 0.6203, G loss: 1.4771\n",
      "[1204/1762] D loss: 1.4368, G loss: 0.7308\n",
      "[1284/1762] D loss: 1.4385, G loss: 0.6916\n",
      "[1364/1762] D loss: 1.3928, G loss: 0.7782\n",
      "[1444/1762] D loss: 1.3694, G loss: 0.6763\n",
      "[1524/1762] D loss: 1.4036, G loss: 0.7025\n",
      "[1604/1762] D loss: 1.4298, G loss: 0.6777\n",
      "[1684/1762] D loss: 1.3731, G loss: 0.7414\n",
      "[1762/1762] D loss: 1.2533, G loss: 0.8782\n",
      "train error: \n",
      " D loss: 1.348730, G loss: 0.902841, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340528, G loss: 0.912776, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4484, G loss: 0.6237\n",
      "[84/1762] D loss: 0.6935, G loss: 1.2420\n",
      "[164/1762] D loss: 1.6366, G loss: 0.6031\n",
      "[244/1762] D loss: 1.4203, G loss: 0.7269\n",
      "[324/1762] D loss: 1.3910, G loss: 0.6842\n",
      "[404/1762] D loss: 1.3500, G loss: 0.7024\n",
      "[484/1762] D loss: 0.5930, G loss: 1.4636\n",
      "[564/1762] D loss: 1.3957, G loss: 0.7214\n",
      "[644/1762] D loss: 1.3786, G loss: 0.7018\n",
      "[724/1762] D loss: 1.3971, G loss: 0.7164\n",
      "[804/1762] D loss: 1.3492, G loss: 0.7719\n",
      "[884/1762] D loss: 1.4267, G loss: 0.6995\n",
      "[964/1762] D loss: 1.4468, G loss: 0.6535\n",
      "[1044/1762] D loss: 1.3216, G loss: 0.6707\n",
      "[1124/1762] D loss: 1.4835, G loss: 0.7242\n",
      "[1204/1762] D loss: 1.4029, G loss: 0.7554\n",
      "[1284/1762] D loss: 1.4119, G loss: 0.7221\n",
      "[1364/1762] D loss: 1.4002, G loss: 0.7219\n",
      "[1444/1762] D loss: 1.3805, G loss: 0.7002\n",
      "[1524/1762] D loss: 1.3807, G loss: 0.6887\n",
      "[1604/1762] D loss: 1.3414, G loss: 0.7440\n",
      "[1684/1762] D loss: 1.4948, G loss: 0.6734\n",
      "[1762/1762] D loss: 1.4288, G loss: 0.6686\n",
      "train error: \n",
      " D loss: 1.322167, G loss: 0.724948, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306712, G loss: 0.735888, D accuracy: 57.6%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7148, G loss: 1.3261\n",
      "[84/1762] D loss: 1.3558, G loss: 0.7148\n",
      "[164/1762] D loss: 0.5515, G loss: 1.4590\n",
      "[244/1762] D loss: 1.4151, G loss: 0.7321\n",
      "[324/1762] D loss: 1.3884, G loss: 0.6926\n",
      "[404/1762] D loss: 1.3766, G loss: 0.6947\n",
      "[484/1762] D loss: 1.4167, G loss: 0.7064\n",
      "[564/1762] D loss: 1.3971, G loss: 0.6971\n",
      "[644/1762] D loss: 0.2519, G loss: 2.1609\n",
      "[724/1762] D loss: 1.3627, G loss: 0.7393\n",
      "[804/1762] D loss: 1.3571, G loss: 0.6516\n",
      "[884/1762] D loss: 1.4374, G loss: 0.7375\n",
      "[964/1762] D loss: 1.3806, G loss: 0.6893\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.7276\n",
      "[1124/1762] D loss: 1.3158, G loss: 0.7797\n",
      "[1204/1762] D loss: 1.4084, G loss: 0.7122\n",
      "[1284/1762] D loss: 1.3561, G loss: 0.7164\n",
      "[1364/1762] D loss: 1.3832, G loss: 0.7170\n",
      "[1444/1762] D loss: 1.3420, G loss: 0.7368\n",
      "[1524/1762] D loss: 1.3937, G loss: 0.7434\n",
      "[1604/1762] D loss: 0.6583, G loss: 1.3766\n",
      "[1684/1762] D loss: 0.6446, G loss: 1.3899\n",
      "[1762/1762] D loss: 1.4288, G loss: 0.6481\n",
      "train error: \n",
      " D loss: 1.323720, G loss: 0.652285, D accuracy: 57.7%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313186, G loss: 0.654972, D accuracy: 59.0%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4120, G loss: 0.7096\n",
      "[84/1762] D loss: 0.5761, G loss: 1.8778\n",
      "[164/1762] D loss: 1.3374, G loss: 0.8660\n",
      "[244/1762] D loss: 1.3487, G loss: 0.7476\n",
      "[324/1762] D loss: 1.3737, G loss: 0.7204\n",
      "[404/1762] D loss: 1.4336, G loss: 0.7169\n",
      "[484/1762] D loss: 1.2220, G loss: 0.9205\n",
      "[564/1762] D loss: 1.3589, G loss: 0.7382\n",
      "[644/1762] D loss: 1.2483, G loss: 0.8844\n",
      "[724/1762] D loss: 1.4035, G loss: 0.5675\n",
      "[804/1762] D loss: 1.3289, G loss: 0.8199\n",
      "[884/1762] D loss: 1.3822, G loss: 0.7247\n",
      "[964/1762] D loss: 0.6961, G loss: 1.2854\n",
      "[1044/1762] D loss: 1.3829, G loss: 0.7210\n",
      "[1124/1762] D loss: 1.3935, G loss: 0.7186\n",
      "[1204/1762] D loss: 0.3378, G loss: 1.7797\n",
      "[1284/1762] D loss: 1.1480, G loss: 0.9185\n",
      "[1364/1762] D loss: 1.4541, G loss: 0.7195\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.7141\n",
      "[1524/1762] D loss: 1.3799, G loss: 0.6813\n",
      "[1604/1762] D loss: 0.9388, G loss: 1.0864\n",
      "[1684/1762] D loss: 1.4066, G loss: 0.8539\n",
      "[1762/1762] D loss: 1.4462, G loss: 0.7043\n",
      "train error: \n",
      " D loss: 1.339660, G loss: 0.799071, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324308, G loss: 0.818617, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3723, G loss: 0.7121\n",
      "[84/1762] D loss: 1.3530, G loss: 0.7880\n",
      "[164/1762] D loss: 0.7363, G loss: 1.2775\n",
      "[244/1762] D loss: 1.3441, G loss: 0.7171\n",
      "[324/1762] D loss: 1.3568, G loss: 0.7217\n",
      "[404/1762] D loss: 1.3670, G loss: 0.7004\n",
      "[484/1762] D loss: 0.6509, G loss: 1.3447\n",
      "[564/1762] D loss: 0.8800, G loss: 1.1421\n",
      "[644/1762] D loss: 1.3139, G loss: 0.7481\n",
      "[724/1762] D loss: 1.3488, G loss: 0.7805\n",
      "[804/1762] D loss: 1.3787, G loss: 0.6873\n",
      "[884/1762] D loss: 1.4158, G loss: 0.6685\n",
      "[964/1762] D loss: 0.7827, G loss: 1.2286\n",
      "[1044/1762] D loss: 1.3766, G loss: 0.6952\n",
      "[1124/1762] D loss: 1.4305, G loss: 0.7331\n",
      "[1204/1762] D loss: 1.4635, G loss: 0.7720\n",
      "[1284/1762] D loss: 1.4165, G loss: 0.7042\n",
      "[1364/1762] D loss: 0.5851, G loss: 1.4422\n",
      "[1444/1762] D loss: 1.4019, G loss: 0.6945\n",
      "[1524/1762] D loss: 1.5005, G loss: 0.7307\n",
      "[1604/1762] D loss: 1.4062, G loss: 0.7167\n",
      "[1684/1762] D loss: 1.2967, G loss: 0.7214\n",
      "[1762/1762] D loss: 1.4157, G loss: 0.6095\n",
      "train error: \n",
      " D loss: 1.335983, G loss: 0.696117, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320067, G loss: 0.710639, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4010, G loss: 0.7186\n",
      "[84/1762] D loss: 1.3955, G loss: 0.6871\n",
      "[164/1762] D loss: 1.3643, G loss: 0.7554\n",
      "[244/1762] D loss: 1.5161, G loss: 0.7866\n",
      "[324/1762] D loss: 1.5362, G loss: 0.7011\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6924\n",
      "[484/1762] D loss: 0.5212, G loss: 1.4489\n",
      "[564/1762] D loss: 0.4507, G loss: 1.7531\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6986\n",
      "[724/1762] D loss: 1.3729, G loss: 0.7104\n",
      "[804/1762] D loss: 1.4016, G loss: 0.7187\n",
      "[884/1762] D loss: 1.3798, G loss: 0.7242\n",
      "[964/1762] D loss: 1.3764, G loss: 0.7087\n",
      "[1044/1762] D loss: 0.6381, G loss: 1.4439\n",
      "[1124/1762] D loss: 1.4509, G loss: 0.7388\n",
      "[1204/1762] D loss: 0.2193, G loss: 2.3343\n",
      "[1284/1762] D loss: 0.5558, G loss: 1.5365\n",
      "[1364/1762] D loss: 0.5173, G loss: 1.4856\n",
      "[1444/1762] D loss: 1.3744, G loss: 0.7015\n",
      "[1524/1762] D loss: 1.5200, G loss: 0.7527\n",
      "[1604/1762] D loss: 1.4248, G loss: 0.7148\n",
      "[1684/1762] D loss: 1.4224, G loss: 0.7749\n",
      "[1762/1762] D loss: 0.3470, G loss: 2.0197\n",
      "train error: \n",
      " D loss: 1.311209, G loss: 0.710327, D accuracy: 58.0%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276105, G loss: 0.749451, D accuracy: 60.6%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4039, G loss: 0.5427\n",
      "[84/1762] D loss: 1.3804, G loss: 0.7031\n",
      "[164/1762] D loss: 1.5225, G loss: 0.7649\n",
      "[244/1762] D loss: 0.8191, G loss: 1.2321\n",
      "[324/1762] D loss: 0.8292, G loss: 1.3794\n",
      "[404/1762] D loss: 1.3924, G loss: 0.6934\n",
      "[484/1762] D loss: 0.3266, G loss: 2.0454\n",
      "[564/1762] D loss: 1.3670, G loss: 0.7087\n",
      "[644/1762] D loss: 0.5129, G loss: 1.5435\n",
      "[724/1762] D loss: 1.4020, G loss: 0.7479\n",
      "[804/1762] D loss: 1.3856, G loss: 0.7073\n",
      "[884/1762] D loss: 0.5924, G loss: 1.4760\n",
      "[964/1762] D loss: 1.4295, G loss: 0.6885\n",
      "[1044/1762] D loss: 1.3668, G loss: 0.6832\n",
      "[1124/1762] D loss: 1.4851, G loss: 0.7244\n",
      "[1204/1762] D loss: 0.6924, G loss: 1.3179\n",
      "[1284/1762] D loss: 0.5579, G loss: 1.4747\n",
      "[1364/1762] D loss: 1.3760, G loss: 0.7147\n",
      "[1444/1762] D loss: 1.5377, G loss: 0.6552\n",
      "[1524/1762] D loss: 1.3305, G loss: 0.7849\n",
      "[1604/1762] D loss: 1.3800, G loss: 0.6999\n",
      "[1684/1762] D loss: 1.4288, G loss: 0.6900\n",
      "[1762/1762] D loss: 1.4286, G loss: 0.7681\n",
      "train error: \n",
      " D loss: 1.321655, G loss: 0.909288, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306158, G loss: 0.946996, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4468, G loss: 0.6834\n",
      "[84/1762] D loss: 1.1127, G loss: 0.9520\n",
      "[164/1762] D loss: 1.4546, G loss: 0.6600\n",
      "[244/1762] D loss: 1.3757, G loss: 0.6897\n",
      "[324/1762] D loss: 1.4020, G loss: 0.7389\n",
      "[404/1762] D loss: 0.6409, G loss: 1.3124\n",
      "[484/1762] D loss: 0.4708, G loss: 1.6263\n",
      "[564/1762] D loss: 1.3801, G loss: 0.7094\n",
      "[644/1762] D loss: 1.4407, G loss: 0.7180\n",
      "[724/1762] D loss: 1.4917, G loss: 0.7119\n",
      "[804/1762] D loss: 1.3801, G loss: 0.6988\n",
      "[884/1762] D loss: 1.4397, G loss: 0.6927\n",
      "[964/1762] D loss: 0.7302, G loss: 1.3730\n",
      "[1044/1762] D loss: 0.6373, G loss: 1.3588\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.7315\n",
      "[1204/1762] D loss: 1.4174, G loss: 0.6928\n",
      "[1284/1762] D loss: 0.5181, G loss: 1.4193\n",
      "[1364/1762] D loss: 1.3943, G loss: 0.6882\n",
      "[1444/1762] D loss: 1.4754, G loss: 0.7083\n",
      "[1524/1762] D loss: 1.3669, G loss: 0.7079\n",
      "[1604/1762] D loss: 1.5649, G loss: 0.7881\n",
      "[1684/1762] D loss: 0.3822, G loss: 1.7554\n",
      "[1762/1762] D loss: 1.4447, G loss: 0.6329\n",
      "train error: \n",
      " D loss: 1.344102, G loss: 0.685938, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330910, G loss: 0.698310, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3975, G loss: 0.7200\n",
      "[84/1762] D loss: 0.4803, G loss: 1.5528\n",
      "[164/1762] D loss: 1.4349, G loss: 0.7207\n",
      "[244/1762] D loss: 1.2479, G loss: 0.8139\n",
      "[324/1762] D loss: 1.3676, G loss: 0.7881\n",
      "[404/1762] D loss: 0.5129, G loss: 1.5868\n",
      "[484/1762] D loss: 1.3375, G loss: 0.7796\n",
      "[564/1762] D loss: 1.4087, G loss: 0.6963\n",
      "[644/1762] D loss: 1.4066, G loss: 0.6991\n",
      "[724/1762] D loss: 1.3822, G loss: 0.6987\n",
      "[804/1762] D loss: 1.6141, G loss: 0.8938\n",
      "[884/1762] D loss: 1.4020, G loss: 0.7270\n",
      "[964/1762] D loss: 0.5255, G loss: 1.4379\n",
      "[1044/1762] D loss: 1.6139, G loss: 0.7632\n",
      "[1124/1762] D loss: 0.1525, G loss: 2.4781\n",
      "[1204/1762] D loss: 0.8309, G loss: 1.0717\n",
      "[1284/1762] D loss: 1.3687, G loss: 0.7103\n",
      "[1364/1762] D loss: 1.5167, G loss: 0.6525\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.7212\n",
      "[1524/1762] D loss: 1.5176, G loss: 0.3444\n",
      "[1604/1762] D loss: 1.3239, G loss: 0.7349\n",
      "[1684/1762] D loss: 1.3475, G loss: 0.7431\n",
      "[1762/1762] D loss: 1.3680, G loss: 0.7293\n",
      "train error: \n",
      " D loss: 1.346917, G loss: 0.737336, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336059, G loss: 0.748127, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3722, G loss: 0.7004\n",
      "[84/1762] D loss: 1.3856, G loss: 0.6915\n",
      "[164/1762] D loss: 1.4128, G loss: 0.7534\n",
      "[244/1762] D loss: 1.4178, G loss: 0.6745\n",
      "[324/1762] D loss: 1.3811, G loss: 0.7026\n",
      "[404/1762] D loss: 1.3825, G loss: 0.6854\n",
      "[484/1762] D loss: 1.3943, G loss: 0.6930\n",
      "[564/1762] D loss: 1.1060, G loss: 1.0487\n",
      "[644/1762] D loss: 1.5560, G loss: 0.8132\n",
      "[724/1762] D loss: 1.3621, G loss: 0.6964\n",
      "[804/1762] D loss: 1.3547, G loss: 0.6886\n",
      "[884/1762] D loss: 1.4028, G loss: 0.6900\n",
      "[964/1762] D loss: 1.3798, G loss: 0.6932\n",
      "[1044/1762] D loss: 1.4201, G loss: 0.6882\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.6909\n",
      "[1204/1762] D loss: 1.3999, G loss: 0.7298\n",
      "[1284/1762] D loss: 1.4191, G loss: 0.6835\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.7036\n",
      "[1444/1762] D loss: 1.3843, G loss: 0.7197\n",
      "[1524/1762] D loss: 0.4051, G loss: 1.7375\n",
      "[1604/1762] D loss: 0.4992, G loss: 1.5957\n",
      "[1684/1762] D loss: 1.3705, G loss: 0.7072\n",
      "[1762/1762] D loss: 1.3992, G loss: 0.6790\n",
      "train error: \n",
      " D loss: 1.346721, G loss: 0.653765, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334118, G loss: 0.668574, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3942, G loss: 0.7007\n",
      "[84/1762] D loss: 1.4088, G loss: 0.7244\n",
      "[164/1762] D loss: 0.5289, G loss: 1.4916\n",
      "[244/1762] D loss: 1.3753, G loss: 0.6809\n",
      "[324/1762] D loss: 1.4048, G loss: 0.6953\n",
      "[404/1762] D loss: 1.4440, G loss: 0.7192\n",
      "[484/1762] D loss: 1.4009, G loss: 0.7409\n",
      "[564/1762] D loss: 0.5673, G loss: 1.4455\n",
      "[644/1762] D loss: 1.3792, G loss: 0.7043\n",
      "[724/1762] D loss: 0.5181, G loss: 1.4888\n",
      "[804/1762] D loss: 1.4378, G loss: 0.6399\n",
      "[884/1762] D loss: 0.5869, G loss: 1.4247\n",
      "[964/1762] D loss: 0.5346, G loss: 1.4258\n",
      "[1044/1762] D loss: 1.3212, G loss: 0.7050\n",
      "[1124/1762] D loss: 1.3784, G loss: 0.7734\n",
      "[1204/1762] D loss: 0.5596, G loss: 1.5415\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.6958\n",
      "[1364/1762] D loss: 1.3621, G loss: 0.7279\n",
      "[1444/1762] D loss: 1.3762, G loss: 0.7122\n",
      "[1524/1762] D loss: 1.4162, G loss: 0.7043\n",
      "[1604/1762] D loss: 1.4335, G loss: 0.7538\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.6992\n",
      "[1762/1762] D loss: 1.4246, G loss: 0.6594\n",
      "train error: \n",
      " D loss: 1.362326, G loss: 0.671536, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347991, G loss: 0.692937, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4497, G loss: 0.7063\n",
      "[84/1762] D loss: 1.3807, G loss: 0.6941\n",
      "[164/1762] D loss: 1.4122, G loss: 0.7410\n",
      "[244/1762] D loss: 1.3908, G loss: 0.6984\n",
      "[324/1762] D loss: 1.4341, G loss: 0.7465\n",
      "[404/1762] D loss: 1.4868, G loss: 0.7092\n",
      "[484/1762] D loss: 0.2870, G loss: 1.8481\n",
      "[564/1762] D loss: 1.4147, G loss: 0.6950\n",
      "[644/1762] D loss: 1.4801, G loss: 0.6240\n",
      "[724/1762] D loss: 1.3949, G loss: 0.7193\n",
      "[804/1762] D loss: 1.3835, G loss: 0.7103\n",
      "[884/1762] D loss: 0.4351, G loss: 1.5869\n",
      "[964/1762] D loss: 1.3928, G loss: 0.6957\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.6938\n",
      "[1124/1762] D loss: 1.3564, G loss: 0.7091\n",
      "[1204/1762] D loss: 1.4033, G loss: 0.7212\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6836\n",
      "[1364/1762] D loss: 1.4184, G loss: 0.7284\n",
      "[1444/1762] D loss: 1.3967, G loss: 0.6736\n",
      "[1524/1762] D loss: 1.4278, G loss: 0.7629\n",
      "[1604/1762] D loss: 1.3818, G loss: 0.6880\n",
      "[1684/1762] D loss: 0.6240, G loss: 1.3161\n",
      "[1762/1762] D loss: 1.5142, G loss: 0.7517\n",
      "train error: \n",
      " D loss: 1.377804, G loss: 0.577427, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359530, G loss: 0.594851, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3918, G loss: 0.6755\n",
      "[84/1762] D loss: 1.3898, G loss: 0.6833\n",
      "[164/1762] D loss: 1.4960, G loss: 0.7837\n",
      "[244/1762] D loss: 1.4513, G loss: 0.7845\n",
      "[324/1762] D loss: 1.4518, G loss: 0.7352\n",
      "[404/1762] D loss: 1.4031, G loss: 0.6812\n",
      "[484/1762] D loss: 0.5602, G loss: 1.4058\n",
      "[564/1762] D loss: 1.3861, G loss: 0.6916\n",
      "[644/1762] D loss: 1.3366, G loss: 0.7187\n",
      "[724/1762] D loss: 1.4021, G loss: 0.7346\n",
      "[804/1762] D loss: 1.3975, G loss: 0.7076\n",
      "[884/1762] D loss: 1.3928, G loss: 0.6840\n",
      "[964/1762] D loss: 1.3973, G loss: 0.7031\n",
      "[1044/1762] D loss: 1.4111, G loss: 0.7089\n",
      "[1124/1762] D loss: 0.4543, G loss: 1.5222\n",
      "[1204/1762] D loss: 0.5274, G loss: 1.4191\n",
      "[1284/1762] D loss: 1.3831, G loss: 0.6872\n",
      "[1364/1762] D loss: 1.3720, G loss: 0.7140\n",
      "[1444/1762] D loss: 0.5612, G loss: 1.4145\n",
      "[1524/1762] D loss: 0.2157, G loss: 2.0391\n",
      "[1604/1762] D loss: 0.3952, G loss: 1.6388\n",
      "[1684/1762] D loss: 1.4007, G loss: 0.7164\n",
      "[1762/1762] D loss: 1.3925, G loss: 0.6841\n",
      "train error: \n",
      " D loss: 1.350091, G loss: 0.696678, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338371, G loss: 0.710152, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4121, G loss: 0.7708\n",
      "[84/1762] D loss: 1.4003, G loss: 0.7251\n",
      "[164/1762] D loss: 1.4009, G loss: 0.7118\n",
      "[244/1762] D loss: 1.4789, G loss: 0.6354\n",
      "[324/1762] D loss: 1.4366, G loss: 0.6607\n",
      "[404/1762] D loss: 1.3809, G loss: 0.6857\n",
      "[484/1762] D loss: 1.3985, G loss: 0.6847\n",
      "[564/1762] D loss: 0.6244, G loss: 1.3360\n",
      "[644/1762] D loss: 1.3893, G loss: 0.7245\n",
      "[724/1762] D loss: 1.3960, G loss: 0.6837\n",
      "[804/1762] D loss: 1.3841, G loss: 0.7028\n",
      "[884/1762] D loss: 1.3861, G loss: 0.7022\n",
      "[964/1762] D loss: 1.3766, G loss: 0.6870\n",
      "[1044/1762] D loss: 1.4384, G loss: 0.7517\n",
      "[1124/1762] D loss: 1.3680, G loss: 0.7103\n",
      "[1204/1762] D loss: 1.4284, G loss: 0.7547\n",
      "[1284/1762] D loss: 0.4909, G loss: 1.5212\n",
      "[1364/1762] D loss: 1.4027, G loss: 0.7360\n",
      "[1444/1762] D loss: 0.3247, G loss: 1.7525\n",
      "[1524/1762] D loss: 1.3931, G loss: 0.6896\n",
      "[1604/1762] D loss: 1.3230, G loss: 0.8580\n",
      "[1684/1762] D loss: 1.3094, G loss: 0.8068\n",
      "[1762/1762] D loss: 0.1355, G loss: 2.6111\n",
      "train error: \n",
      " D loss: 1.473034, G loss: 0.474822, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.449298, G loss: 0.496115, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2165, G loss: 2.4383\n",
      "[84/1762] D loss: 1.3800, G loss: 0.7346\n",
      "[164/1762] D loss: 0.4937, G loss: 1.5216\n",
      "[244/1762] D loss: 1.3742, G loss: 0.7073\n",
      "[324/1762] D loss: 0.3922, G loss: 1.6466\n",
      "[404/1762] D loss: 1.3693, G loss: 0.6896\n",
      "[484/1762] D loss: 1.3930, G loss: 0.6828\n",
      "[564/1762] D loss: 0.4332, G loss: 1.4393\n",
      "[644/1762] D loss: 1.3926, G loss: 0.7151\n",
      "[724/1762] D loss: 1.3923, G loss: 0.7174\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7120\n",
      "[884/1762] D loss: 0.4811, G loss: 1.5615\n",
      "[964/1762] D loss: 1.3795, G loss: 0.6996\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.6938\n",
      "[1124/1762] D loss: 1.3821, G loss: 0.7087\n",
      "[1204/1762] D loss: 1.4137, G loss: 0.6737\n",
      "[1284/1762] D loss: 1.4044, G loss: 0.7408\n",
      "[1364/1762] D loss: 1.3678, G loss: 0.7029\n",
      "[1444/1762] D loss: 1.4057, G loss: 0.6723\n",
      "[1524/1762] D loss: 1.3850, G loss: 0.6886\n",
      "[1604/1762] D loss: 0.4551, G loss: 1.5218\n",
      "[1684/1762] D loss: 0.4249, G loss: 1.5643\n",
      "[1762/1762] D loss: 1.3928, G loss: 0.6811\n",
      "train error: \n",
      " D loss: 1.358849, G loss: 0.746205, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350721, G loss: 0.767024, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5256, G loss: 1.4698\n",
      "[84/1762] D loss: 0.4400, G loss: 1.5859\n",
      "[164/1762] D loss: 1.3829, G loss: 0.6943\n",
      "[244/1762] D loss: 1.4558, G loss: 0.7661\n",
      "[324/1762] D loss: 1.3985, G loss: 0.6731\n",
      "[404/1762] D loss: 0.4353, G loss: 1.5755\n",
      "[484/1762] D loss: 1.4201, G loss: 0.7027\n",
      "[564/1762] D loss: 1.4171, G loss: 0.6850\n",
      "[644/1762] D loss: 1.4292, G loss: 0.6687\n",
      "[724/1762] D loss: 1.5118, G loss: 0.7793\n",
      "[804/1762] D loss: 1.7618, G loss: 0.8242\n",
      "[884/1762] D loss: 0.3388, G loss: 1.7756\n",
      "[964/1762] D loss: 1.4098, G loss: 0.8965\n",
      "[1044/1762] D loss: 1.3266, G loss: 0.7835\n",
      "[1124/1762] D loss: 0.5344, G loss: 1.5939\n",
      "[1204/1762] D loss: 1.4420, G loss: 0.6438\n",
      "[1284/1762] D loss: 1.3995, G loss: 0.7039\n",
      "[1364/1762] D loss: 0.5183, G loss: 1.5303\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7029\n",
      "[1524/1762] D loss: 1.4050, G loss: 0.7035\n",
      "[1604/1762] D loss: 1.3788, G loss: 0.7264\n",
      "[1684/1762] D loss: 0.3572, G loss: 1.7572\n",
      "[1762/1762] D loss: 1.3570, G loss: 0.7284\n",
      "train error: \n",
      " D loss: 1.351469, G loss: 0.678001, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347525, G loss: 0.682191, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4076, G loss: 0.7348\n",
      "[84/1762] D loss: 1.3887, G loss: 0.7396\n",
      "[164/1762] D loss: 1.4125, G loss: 0.7137\n",
      "[244/1762] D loss: 1.3708, G loss: 0.7677\n",
      "[324/1762] D loss: 1.3659, G loss: 0.7269\n",
      "[404/1762] D loss: 0.5137, G loss: 1.4383\n",
      "[484/1762] D loss: 1.2508, G loss: 0.7911\n",
      "[564/1762] D loss: 1.3311, G loss: 0.7442\n",
      "[644/1762] D loss: 1.3807, G loss: 0.7173\n",
      "[724/1762] D loss: 1.3781, G loss: 0.6863\n",
      "[804/1762] D loss: 0.2074, G loss: 2.1409\n",
      "[884/1762] D loss: 1.3934, G loss: 0.7149\n",
      "[964/1762] D loss: 1.3959, G loss: 0.6932\n",
      "[1044/1762] D loss: 0.3972, G loss: 1.6732\n",
      "[1124/1762] D loss: 0.3780, G loss: 1.6581\n",
      "[1204/1762] D loss: 1.4037, G loss: 0.6800\n",
      "[1284/1762] D loss: 1.4862, G loss: 0.6349\n",
      "[1364/1762] D loss: 0.3499, G loss: 1.6718\n",
      "[1444/1762] D loss: 1.3984, G loss: 0.7074\n",
      "[1524/1762] D loss: 1.3655, G loss: 0.7031\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.7028\n",
      "[1684/1762] D loss: 1.3947, G loss: 0.7157\n",
      "[1762/1762] D loss: 1.3800, G loss: 0.6812\n",
      "train error: \n",
      " D loss: 1.348047, G loss: 0.757657, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341778, G loss: 0.769583, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3759, G loss: 0.7068\n",
      "[84/1762] D loss: 0.3469, G loss: 1.7051\n",
      "[164/1762] D loss: 1.4394, G loss: 0.7538\n",
      "[244/1762] D loss: 1.3710, G loss: 0.7014\n",
      "[324/1762] D loss: 0.3482, G loss: 1.7034\n",
      "[404/1762] D loss: 1.4007, G loss: 0.7019\n",
      "[484/1762] D loss: 1.4537, G loss: 0.7923\n",
      "[564/1762] D loss: 1.3900, G loss: 0.6878\n",
      "[644/1762] D loss: 0.4655, G loss: 1.7454\n",
      "[724/1762] D loss: 1.5131, G loss: 0.7604\n",
      "[804/1762] D loss: 1.4082, G loss: 0.6909\n",
      "[884/1762] D loss: 1.3978, G loss: 0.7382\n",
      "[964/1762] D loss: 1.4562, G loss: 0.6705\n",
      "[1044/1762] D loss: 1.4752, G loss: 0.7360\n",
      "[1124/1762] D loss: 1.3227, G loss: 0.7643\n",
      "[1204/1762] D loss: 1.3797, G loss: 0.7045\n",
      "[1284/1762] D loss: 1.3751, G loss: 0.7115\n",
      "[1364/1762] D loss: 1.6357, G loss: 0.8281\n",
      "[1444/1762] D loss: 1.3917, G loss: 0.7153\n",
      "[1524/1762] D loss: 1.3706, G loss: 0.7428\n",
      "[1604/1762] D loss: 0.1272, G loss: 2.5154\n",
      "[1684/1762] D loss: 0.1964, G loss: 2.2773\n",
      "[1762/1762] D loss: 1.4056, G loss: 0.6994\n",
      "train error: \n",
      " D loss: 1.364011, G loss: 0.636813, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349210, G loss: 0.653312, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2095, G loss: 0.9205\n",
      "[84/1762] D loss: 0.5314, G loss: 1.5494\n",
      "[164/1762] D loss: 1.3685, G loss: 0.7023\n",
      "[244/1762] D loss: 1.3815, G loss: 0.6782\n",
      "[324/1762] D loss: 1.3995, G loss: 0.6807\n",
      "[404/1762] D loss: 1.5976, G loss: 0.7300\n",
      "[484/1762] D loss: 1.4652, G loss: 0.7576\n",
      "[564/1762] D loss: 1.4386, G loss: 0.7879\n",
      "[644/1762] D loss: 1.2534, G loss: 0.8535\n",
      "[724/1762] D loss: 1.3828, G loss: 0.7307\n",
      "[804/1762] D loss: 0.0500, G loss: 3.6325\n",
      "[884/1762] D loss: 1.5188, G loss: 0.7008\n",
      "[964/1762] D loss: 1.5190, G loss: 0.7502\n",
      "[1044/1762] D loss: 0.5502, G loss: 1.4912\n",
      "[1124/1762] D loss: 1.4995, G loss: 0.6566\n",
      "[1204/1762] D loss: 1.3620, G loss: 0.7076\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.6953\n",
      "[1364/1762] D loss: 1.4665, G loss: 0.7272\n",
      "[1444/1762] D loss: 1.4072, G loss: 0.7111\n",
      "[1524/1762] D loss: 1.4099, G loss: 0.7219\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7227\n",
      "[1684/1762] D loss: 0.4094, G loss: 1.6758\n",
      "[1762/1762] D loss: 1.4753, G loss: 0.6246\n",
      "train error: \n",
      " D loss: 1.396896, G loss: 0.550652, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384598, G loss: 0.569265, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.6984\n",
      "[84/1762] D loss: 1.3663, G loss: 0.7252\n",
      "[164/1762] D loss: 1.3595, G loss: 0.7129\n",
      "[244/1762] D loss: 0.3841, G loss: 1.7891\n",
      "[324/1762] D loss: 0.3558, G loss: 1.7640\n",
      "[404/1762] D loss: 2.5673, G loss: 0.3798\n",
      "[484/1762] D loss: 0.9627, G loss: 0.9955\n",
      "[564/1762] D loss: 0.5535, G loss: 1.6197\n",
      "[644/1762] D loss: 0.3346, G loss: 1.7609\n",
      "[724/1762] D loss: 0.8475, G loss: 1.8990\n",
      "[804/1762] D loss: 1.5640, G loss: 0.8486\n",
      "[884/1762] D loss: 1.0506, G loss: 1.3783\n",
      "[964/1762] D loss: 1.5222, G loss: 0.9620\n",
      "[1044/1762] D loss: 1.4186, G loss: 0.8205\n",
      "[1124/1762] D loss: 1.3482, G loss: 0.8134\n",
      "[1204/1762] D loss: 1.3194, G loss: 0.6305\n",
      "[1284/1762] D loss: 1.4511, G loss: 0.5652\n",
      "[1364/1762] D loss: 1.4209, G loss: 0.6967\n",
      "[1444/1762] D loss: 1.4030, G loss: 0.6829\n",
      "[1524/1762] D loss: 0.6160, G loss: 1.4518\n",
      "[1604/1762] D loss: 0.3489, G loss: 1.8310\n",
      "[1684/1762] D loss: 1.4957, G loss: 0.7228\n",
      "[1762/1762] D loss: 1.5850, G loss: 0.7550\n",
      "train error: \n",
      " D loss: 1.420978, G loss: 0.837240, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.431167, G loss: 0.824626, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5022, G loss: 0.6894\n",
      "[84/1762] D loss: 1.3767, G loss: 0.7167\n",
      "[164/1762] D loss: 0.5010, G loss: 1.6746\n",
      "[244/1762] D loss: 1.3847, G loss: 0.7244\n",
      "[324/1762] D loss: 1.4294, G loss: 0.6436\n",
      "[404/1762] D loss: 1.4076, G loss: 0.7354\n",
      "[484/1762] D loss: 1.4976, G loss: 0.7070\n",
      "[564/1762] D loss: 1.4273, G loss: 0.7009\n",
      "[644/1762] D loss: 1.4639, G loss: 0.7481\n",
      "[724/1762] D loss: 1.5899, G loss: 0.5859\n",
      "[804/1762] D loss: 1.5799, G loss: 0.6431\n",
      "[884/1762] D loss: 1.3502, G loss: 0.7131\n",
      "[964/1762] D loss: 1.3862, G loss: 0.7008\n",
      "[1044/1762] D loss: 1.3551, G loss: 0.6966\n",
      "[1124/1762] D loss: 1.4573, G loss: 0.7179\n",
      "[1204/1762] D loss: 1.4019, G loss: 0.6883\n",
      "[1284/1762] D loss: 1.4091, G loss: 0.7270\n",
      "[1364/1762] D loss: 1.4136, G loss: 0.7374\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.7033\n",
      "[1524/1762] D loss: 1.4197, G loss: 0.6333\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.6897\n",
      "[1684/1762] D loss: 0.4710, G loss: 1.5108\n",
      "[1762/1762] D loss: 1.3899, G loss: 0.6735\n",
      "train error: \n",
      " D loss: 1.375561, G loss: 0.632730, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372114, G loss: 0.645072, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6981\n",
      "[84/1762] D loss: 1.3974, G loss: 0.6702\n",
      "[164/1762] D loss: 1.4251, G loss: 0.7458\n",
      "[244/1762] D loss: 1.3531, G loss: 0.7134\n",
      "[324/1762] D loss: 1.4044, G loss: 0.7318\n",
      "[404/1762] D loss: 1.3983, G loss: 0.7025\n",
      "[484/1762] D loss: 1.3993, G loss: 0.6740\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6928\n",
      "[644/1762] D loss: 0.5757, G loss: 1.3477\n",
      "[724/1762] D loss: 0.4905, G loss: 1.5718\n",
      "[804/1762] D loss: 1.3411, G loss: 0.7731\n",
      "[884/1762] D loss: 0.6319, G loss: 1.3963\n",
      "[964/1762] D loss: 1.3864, G loss: 0.7008\n",
      "[1044/1762] D loss: 0.4276, G loss: 1.5072\n",
      "[1124/1762] D loss: 1.4018, G loss: 0.7395\n",
      "[1204/1762] D loss: 0.4024, G loss: 1.5874\n",
      "[1284/1762] D loss: 1.3664, G loss: 0.7266\n",
      "[1364/1762] D loss: 1.4154, G loss: 0.7240\n",
      "[1444/1762] D loss: 1.4134, G loss: 0.7077\n",
      "[1524/1762] D loss: 1.4036, G loss: 0.7390\n",
      "[1604/1762] D loss: 1.4211, G loss: 0.7489\n",
      "[1684/1762] D loss: 1.3756, G loss: 0.7286\n",
      "[1762/1762] D loss: 1.6418, G loss: 0.5345\n",
      "train error: \n",
      " D loss: 1.391819, G loss: 0.552629, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372238, G loss: 0.570137, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4846, G loss: 1.3749\n",
      "[84/1762] D loss: 1.3544, G loss: 0.7327\n",
      "[164/1762] D loss: 1.4002, G loss: 0.6966\n",
      "[244/1762] D loss: 1.3144, G loss: 0.7514\n",
      "[324/1762] D loss: 0.4620, G loss: 1.4857\n",
      "[404/1762] D loss: 1.3995, G loss: 0.7266\n",
      "[484/1762] D loss: 1.3652, G loss: 0.6948\n",
      "[564/1762] D loss: 1.3707, G loss: 0.6981\n",
      "[644/1762] D loss: 1.3759, G loss: 0.7343\n",
      "[724/1762] D loss: 1.4012, G loss: 0.7282\n",
      "[804/1762] D loss: 1.3978, G loss: 0.6797\n",
      "[884/1762] D loss: 0.4841, G loss: 1.6297\n",
      "[964/1762] D loss: 1.4307, G loss: 0.7738\n",
      "[1044/1762] D loss: 1.3994, G loss: 0.6861\n",
      "[1124/1762] D loss: 0.3395, G loss: 1.7605\n",
      "[1204/1762] D loss: 0.5189, G loss: 1.4851\n",
      "[1284/1762] D loss: 0.4069, G loss: 1.6101\n",
      "[1364/1762] D loss: 0.3912, G loss: 1.5658\n",
      "[1444/1762] D loss: 0.3351, G loss: 1.7663\n",
      "[1524/1762] D loss: 0.4709, G loss: 1.4326\n",
      "[1604/1762] D loss: 1.4632, G loss: 0.6895\n",
      "[1684/1762] D loss: 1.2905, G loss: 0.7871\n",
      "[1762/1762] D loss: 0.1459, G loss: 2.3638\n",
      "train error: \n",
      " D loss: 1.427029, G loss: 0.472230, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401918, G loss: 0.492623, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4754, G loss: 0.7656\n",
      "[84/1762] D loss: 0.5099, G loss: 1.4309\n",
      "[164/1762] D loss: 1.3272, G loss: 0.7427\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6821\n",
      "[324/1762] D loss: 0.3085, G loss: 1.8605\n",
      "[404/1762] D loss: 1.3853, G loss: 0.7007\n",
      "[484/1762] D loss: 1.4407, G loss: 0.6586\n",
      "[564/1762] D loss: 0.1558, G loss: 2.4212\n",
      "[644/1762] D loss: 1.4377, G loss: 0.6391\n",
      "[724/1762] D loss: 1.4613, G loss: 0.7619\n",
      "[804/1762] D loss: 1.3908, G loss: 0.7056\n",
      "[884/1762] D loss: 0.2786, G loss: 1.9741\n",
      "[964/1762] D loss: 1.3929, G loss: 0.6970\n",
      "[1044/1762] D loss: 1.4279, G loss: 0.7024\n",
      "[1124/1762] D loss: 1.5233, G loss: 0.8308\n",
      "[1204/1762] D loss: 0.0687, G loss: 3.6171\n",
      "[1284/1762] D loss: 1.4064, G loss: 0.7330\n",
      "[1364/1762] D loss: 0.4387, G loss: 1.5024\n",
      "[1444/1762] D loss: 1.3927, G loss: 0.6984\n",
      "[1524/1762] D loss: 0.4470, G loss: 1.5896\n",
      "[1604/1762] D loss: 1.6004, G loss: 0.6484\n",
      "[1684/1762] D loss: 1.4273, G loss: 0.7203\n",
      "[1762/1762] D loss: 0.1706, G loss: 2.2158\n",
      "train error: \n",
      " D loss: 1.385775, G loss: 0.543854, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368126, G loss: 0.556313, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3653, G loss: 0.7284\n",
      "[84/1762] D loss: 1.3970, G loss: 0.6724\n",
      "[164/1762] D loss: 0.5266, G loss: 1.3746\n",
      "[244/1762] D loss: 1.4218, G loss: 0.6950\n",
      "[324/1762] D loss: 1.3848, G loss: 0.6866\n",
      "[404/1762] D loss: 0.5642, G loss: 1.3341\n",
      "[484/1762] D loss: 1.4568, G loss: 0.6573\n",
      "[564/1762] D loss: 1.5181, G loss: 0.7569\n",
      "[644/1762] D loss: 1.4172, G loss: 0.6503\n",
      "[724/1762] D loss: 1.4012, G loss: 0.7086\n",
      "[804/1762] D loss: 0.4074, G loss: 1.5158\n",
      "[884/1762] D loss: 1.4257, G loss: 0.7253\n",
      "[964/1762] D loss: 1.4467, G loss: 0.7739\n",
      "[1044/1762] D loss: 1.4827, G loss: 0.7210\n",
      "[1124/1762] D loss: 1.3563, G loss: 0.7250\n",
      "[1204/1762] D loss: 1.3802, G loss: 0.7787\n",
      "[1284/1762] D loss: 0.1489, G loss: 2.7073\n",
      "[1364/1762] D loss: 1.4399, G loss: 0.6844\n",
      "[1444/1762] D loss: 1.4465, G loss: 0.6910\n",
      "[1524/1762] D loss: 0.4169, G loss: 1.5730\n",
      "[1604/1762] D loss: 1.3294, G loss: 0.7421\n",
      "[1684/1762] D loss: 1.3291, G loss: 0.7417\n",
      "[1762/1762] D loss: 1.3956, G loss: 0.7004\n",
      "train error: \n",
      " D loss: 1.332210, G loss: 0.761226, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330071, G loss: 0.783991, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4175, G loss: 0.7421\n",
      "[84/1762] D loss: 1.4424, G loss: 0.6999\n",
      "[164/1762] D loss: 1.4601, G loss: 0.7087\n",
      "[244/1762] D loss: 1.3987, G loss: 0.6724\n",
      "[324/1762] D loss: 1.4093, G loss: 0.7304\n",
      "[404/1762] D loss: 1.4333, G loss: 0.8157\n",
      "[484/1762] D loss: 1.3846, G loss: 0.7300\n",
      "[564/1762] D loss: 1.2930, G loss: 0.8399\n",
      "[644/1762] D loss: 1.4868, G loss: 0.7576\n",
      "[724/1762] D loss: 1.3580, G loss: 0.7057\n",
      "[804/1762] D loss: 1.4005, G loss: 0.7144\n",
      "[884/1762] D loss: 1.4088, G loss: 0.7300\n",
      "[964/1762] D loss: 0.4852, G loss: 1.5469\n",
      "[1044/1762] D loss: 1.3712, G loss: 0.7427\n",
      "[1124/1762] D loss: 1.4526, G loss: 0.7656\n",
      "[1204/1762] D loss: 1.4046, G loss: 0.7043\n",
      "[1284/1762] D loss: 0.4673, G loss: 1.5013\n",
      "[1364/1762] D loss: 1.3305, G loss: 0.7290\n",
      "[1444/1762] D loss: 1.3529, G loss: 0.7319\n",
      "[1524/1762] D loss: 1.4421, G loss: 0.6589\n",
      "[1604/1762] D loss: 1.3467, G loss: 0.7195\n",
      "[1684/1762] D loss: 1.4694, G loss: 0.7115\n",
      "[1762/1762] D loss: 1.4084, G loss: 0.6444\n",
      "train error: \n",
      " D loss: 1.364243, G loss: 0.645946, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358331, G loss: 0.662705, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4052, G loss: 0.7088\n",
      "[84/1762] D loss: 1.4023, G loss: 0.7100\n",
      "[164/1762] D loss: 1.4297, G loss: 0.6967\n",
      "[244/1762] D loss: 0.3849, G loss: 1.6280\n",
      "[324/1762] D loss: 1.3674, G loss: 0.7337\n",
      "[404/1762] D loss: 0.3716, G loss: 1.6546\n",
      "[484/1762] D loss: 1.3735, G loss: 0.7119\n",
      "[564/1762] D loss: 0.2067, G loss: 2.3087\n",
      "[644/1762] D loss: 1.4195, G loss: 0.7258\n",
      "[724/1762] D loss: 1.3782, G loss: 0.6883\n",
      "[804/1762] D loss: 1.4656, G loss: 0.7157\n",
      "[884/1762] D loss: 1.3925, G loss: 0.7037\n",
      "[964/1762] D loss: 1.3446, G loss: 0.7010\n",
      "[1044/1762] D loss: 1.3471, G loss: 0.7122\n",
      "[1124/1762] D loss: 1.4874, G loss: 0.6835\n",
      "[1204/1762] D loss: 1.4058, G loss: 0.6929\n",
      "[1284/1762] D loss: 1.5781, G loss: 0.6493\n",
      "[1364/1762] D loss: 0.2525, G loss: 2.0905\n",
      "[1444/1762] D loss: 1.3972, G loss: 0.6884\n",
      "[1524/1762] D loss: 1.3813, G loss: 0.6980\n",
      "[1604/1762] D loss: 0.3027, G loss: 1.8115\n",
      "[1684/1762] D loss: 1.4050, G loss: 0.7433\n",
      "[1762/1762] D loss: 1.4020, G loss: 0.7135\n",
      "train error: \n",
      " D loss: 1.358448, G loss: 0.639414, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348036, G loss: 0.655736, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3993, G loss: 0.6916\n",
      "[84/1762] D loss: 1.3932, G loss: 0.7808\n",
      "[164/1762] D loss: 0.4609, G loss: 1.4678\n",
      "[244/1762] D loss: 0.3672, G loss: 1.7534\n",
      "[324/1762] D loss: 1.3804, G loss: 0.7034\n",
      "[404/1762] D loss: 1.4191, G loss: 0.7182\n",
      "[484/1762] D loss: 1.4347, G loss: 0.7522\n",
      "[564/1762] D loss: 0.3148, G loss: 1.8634\n",
      "[644/1762] D loss: 1.6780, G loss: 0.7885\n",
      "[724/1762] D loss: 1.4614, G loss: 0.7294\n",
      "[804/1762] D loss: 1.5043, G loss: 0.7074\n",
      "[884/1762] D loss: 1.3795, G loss: 0.7070\n",
      "[964/1762] D loss: 0.4035, G loss: 1.5460\n",
      "[1044/1762] D loss: 1.4952, G loss: 0.7134\n",
      "[1124/1762] D loss: 1.4886, G loss: 0.7475\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7092\n",
      "[1284/1762] D loss: 1.7453, G loss: 0.8272\n",
      "[1364/1762] D loss: 1.4163, G loss: 0.6544\n",
      "[1444/1762] D loss: 1.4167, G loss: 0.7392\n",
      "[1524/1762] D loss: 1.4180, G loss: 0.7049\n",
      "[1604/1762] D loss: 1.3996, G loss: 0.6955\n",
      "[1684/1762] D loss: 0.3537, G loss: 1.6975\n",
      "[1762/1762] D loss: 1.3385, G loss: 0.7582\n",
      "train error: \n",
      " D loss: 1.350956, G loss: 0.763656, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343398, G loss: 0.775545, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4462, G loss: 0.7327\n",
      "[84/1762] D loss: 0.3388, G loss: 1.6835\n",
      "[164/1762] D loss: 0.2352, G loss: 2.0192\n",
      "[244/1762] D loss: 1.4333, G loss: 0.6605\n",
      "[324/1762] D loss: 1.3834, G loss: 0.7283\n",
      "[404/1762] D loss: 1.3840, G loss: 0.6934\n",
      "[484/1762] D loss: 1.5032, G loss: 0.7320\n",
      "[564/1762] D loss: 0.3393, G loss: 2.0176\n",
      "[644/1762] D loss: 1.2889, G loss: 0.7781\n",
      "[724/1762] D loss: 1.3697, G loss: 0.7449\n",
      "[804/1762] D loss: 1.3924, G loss: 0.7290\n",
      "[884/1762] D loss: 1.4149, G loss: 0.7138\n",
      "[964/1762] D loss: 0.6833, G loss: 1.5378\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.7005\n",
      "[1124/1762] D loss: 1.4277, G loss: 0.7121\n",
      "[1204/1762] D loss: 1.3718, G loss: 0.7120\n",
      "[1284/1762] D loss: 1.3774, G loss: 0.7381\n",
      "[1364/1762] D loss: 0.2855, G loss: 1.8316\n",
      "[1444/1762] D loss: 1.4449, G loss: 0.7618\n",
      "[1524/1762] D loss: 1.4144, G loss: 0.7214\n",
      "[1604/1762] D loss: 1.4009, G loss: 0.7024\n",
      "[1684/1762] D loss: 1.6113, G loss: 0.6648\n",
      "[1762/1762] D loss: 0.0876, G loss: 2.8088\n",
      "train error: \n",
      " D loss: 1.435098, G loss: 0.472440, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.421049, G loss: 0.482595, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4256, G loss: 0.6797\n",
      "[84/1762] D loss: 1.3667, G loss: 0.7699\n",
      "[164/1762] D loss: 0.1809, G loss: 2.1688\n",
      "[244/1762] D loss: 1.3807, G loss: 0.7021\n",
      "[324/1762] D loss: 1.4077, G loss: 0.7346\n",
      "[404/1762] D loss: 1.3685, G loss: 0.7356\n",
      "[484/1762] D loss: 1.5598, G loss: 0.6096\n",
      "[564/1762] D loss: 1.3970, G loss: 0.7022\n",
      "[644/1762] D loss: 1.3449, G loss: 0.7413\n",
      "[724/1762] D loss: 0.4484, G loss: 1.5845\n",
      "[804/1762] D loss: 1.3816, G loss: 0.7174\n",
      "[884/1762] D loss: 1.4603, G loss: 0.6768\n",
      "[964/1762] D loss: 1.3154, G loss: 0.7724\n",
      "[1044/1762] D loss: 0.4818, G loss: 1.3903\n",
      "[1124/1762] D loss: 1.3435, G loss: 0.7341\n",
      "[1204/1762] D loss: 1.3718, G loss: 0.7429\n",
      "[1284/1762] D loss: 0.3503, G loss: 1.6853\n",
      "[1364/1762] D loss: 1.4294, G loss: 0.7544\n",
      "[1444/1762] D loss: 1.3658, G loss: 0.7307\n",
      "[1524/1762] D loss: 1.5169, G loss: 0.7630\n",
      "[1604/1762] D loss: 1.4228, G loss: 0.7050\n",
      "[1684/1762] D loss: 0.1000, G loss: 3.0361\n",
      "[1762/1762] D loss: 1.3964, G loss: 0.7021\n",
      "train error: \n",
      " D loss: 1.388703, G loss: 0.578187, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378403, G loss: 0.591593, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3853, G loss: 0.6909\n",
      "[84/1762] D loss: 1.3856, G loss: 0.7408\n",
      "[164/1762] D loss: 1.4400, G loss: 0.7359\n",
      "[244/1762] D loss: 0.5061, G loss: 1.4827\n",
      "[324/1762] D loss: 1.3074, G loss: 0.9414\n",
      "[404/1762] D loss: 1.5950, G loss: 0.7246\n",
      "[484/1762] D loss: 0.9431, G loss: 0.9617\n",
      "[564/1762] D loss: 0.6536, G loss: 1.5646\n",
      "[644/1762] D loss: 1.4240, G loss: 0.6450\n",
      "[724/1762] D loss: 1.3873, G loss: 0.7122\n",
      "[804/1762] D loss: 1.4024, G loss: 0.6683\n",
      "[884/1762] D loss: 1.3771, G loss: 0.7094\n",
      "[964/1762] D loss: 1.3904, G loss: 0.7054\n",
      "[1044/1762] D loss: 0.2643, G loss: 1.9493\n",
      "[1124/1762] D loss: 1.3732, G loss: 0.7129\n",
      "[1204/1762] D loss: 0.2327, G loss: 2.0697\n",
      "[1284/1762] D loss: 1.4320, G loss: 0.6992\n",
      "[1364/1762] D loss: 0.4283, G loss: 1.7496\n",
      "[1444/1762] D loss: 1.4347, G loss: 0.6699\n",
      "[1524/1762] D loss: 1.5195, G loss: 0.7184\n",
      "[1604/1762] D loss: 1.4526, G loss: 0.7540\n",
      "[1684/1762] D loss: 1.4225, G loss: 0.6695\n",
      "[1762/1762] D loss: 1.4275, G loss: 0.6446\n",
      "train error: \n",
      " D loss: 1.366026, G loss: 0.673625, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366725, G loss: 0.682057, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4010, G loss: 0.6920\n",
      "[84/1762] D loss: 1.4132, G loss: 0.7248\n",
      "[164/1762] D loss: 0.3803, G loss: 1.6091\n",
      "[244/1762] D loss: 1.5438, G loss: 0.6341\n",
      "[324/1762] D loss: 1.4475, G loss: 0.7738\n",
      "[404/1762] D loss: 1.4498, G loss: 0.6925\n",
      "[484/1762] D loss: 0.4779, G loss: 1.5304\n",
      "[564/1762] D loss: 1.4006, G loss: 0.7057\n",
      "[644/1762] D loss: 0.0537, G loss: 3.2305\n",
      "[724/1762] D loss: 1.2577, G loss: 0.8568\n",
      "[804/1762] D loss: 1.3486, G loss: 0.7077\n",
      "[884/1762] D loss: 0.3619, G loss: 1.7387\n",
      "[964/1762] D loss: 1.2347, G loss: 0.7825\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6970\n",
      "[1124/1762] D loss: 1.4208, G loss: 0.6956\n",
      "[1204/1762] D loss: 1.4045, G loss: 0.6842\n",
      "[1284/1762] D loss: 0.5149, G loss: 1.4525\n",
      "[1364/1762] D loss: 0.3263, G loss: 1.7016\n",
      "[1444/1762] D loss: 1.4125, G loss: 0.6924\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7050\n",
      "[1604/1762] D loss: 0.4595, G loss: 1.3990\n",
      "[1684/1762] D loss: 0.3278, G loss: 1.8453\n",
      "[1762/1762] D loss: 1.5914, G loss: 0.7326\n",
      "train error: \n",
      " D loss: 1.356948, G loss: 0.671740, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351798, G loss: 0.682171, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4408, G loss: 0.6370\n",
      "[84/1762] D loss: 0.4835, G loss: 1.6470\n",
      "[164/1762] D loss: 1.4153, G loss: 0.6775\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7068\n",
      "[324/1762] D loss: 1.4138, G loss: 0.7173\n",
      "[404/1762] D loss: 0.4151, G loss: 1.6462\n",
      "[484/1762] D loss: 1.4158, G loss: 0.7425\n",
      "[564/1762] D loss: 0.4255, G loss: 1.5535\n",
      "[644/1762] D loss: 1.3914, G loss: 0.6961\n",
      "[724/1762] D loss: 1.4127, G loss: 0.6815\n",
      "[804/1762] D loss: 1.5039, G loss: 0.7163\n",
      "[884/1762] D loss: 0.3867, G loss: 1.8081\n",
      "[964/1762] D loss: 1.3078, G loss: 0.7783\n",
      "[1044/1762] D loss: 1.2172, G loss: 0.8854\n",
      "[1124/1762] D loss: 1.5717, G loss: 0.6513\n",
      "[1204/1762] D loss: 1.4301, G loss: 0.7010\n",
      "[1284/1762] D loss: 1.5347, G loss: 0.7047\n",
      "[1364/1762] D loss: 1.3165, G loss: 0.7829\n",
      "[1444/1762] D loss: 1.2935, G loss: 0.7931\n",
      "[1524/1762] D loss: 1.3577, G loss: 0.8276\n",
      "[1604/1762] D loss: 1.3073, G loss: 0.7465\n",
      "[1684/1762] D loss: 0.2306, G loss: 2.1007\n",
      "[1762/1762] D loss: 0.0665, G loss: 3.2488\n",
      "train error: \n",
      " D loss: 1.476289, G loss: 0.427294, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.464831, G loss: 0.435497, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5716, G loss: 0.8058\n",
      "[84/1762] D loss: 1.3821, G loss: 0.7184\n",
      "[164/1762] D loss: 1.4087, G loss: 0.7230\n",
      "[244/1762] D loss: 0.3258, G loss: 1.7652\n",
      "[324/1762] D loss: 1.3899, G loss: 0.7288\n",
      "[404/1762] D loss: 1.4005, G loss: 0.7169\n",
      "[484/1762] D loss: 0.6019, G loss: 1.2660\n",
      "[564/1762] D loss: 0.3000, G loss: 1.7959\n",
      "[644/1762] D loss: 1.6871, G loss: 0.6705\n",
      "[724/1762] D loss: 1.3981, G loss: 0.6918\n",
      "[804/1762] D loss: 1.4098, G loss: 0.6940\n",
      "[884/1762] D loss: 1.4082, G loss: 0.7246\n",
      "[964/1762] D loss: 0.4265, G loss: 1.6231\n",
      "[1044/1762] D loss: 0.1730, G loss: 2.1916\n",
      "[1124/1762] D loss: 0.4957, G loss: 1.4928\n",
      "[1204/1762] D loss: 1.4215, G loss: 0.6980\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.6958\n",
      "[1364/1762] D loss: 1.4535, G loss: 0.7742\n",
      "[1444/1762] D loss: 1.3663, G loss: 0.7009\n",
      "[1524/1762] D loss: 0.3686, G loss: 1.7280\n",
      "[1604/1762] D loss: 0.3290, G loss: 1.7271\n",
      "[1684/1762] D loss: 1.6490, G loss: 0.8484\n",
      "[1762/1762] D loss: 1.4448, G loss: 0.6755\n",
      "train error: \n",
      " D loss: 1.416001, G loss: 0.494165, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408473, G loss: 0.503051, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4277, G loss: 0.6769\n",
      "[84/1762] D loss: 0.3327, G loss: 1.8761\n",
      "[164/1762] D loss: 1.3824, G loss: 0.6903\n",
      "[244/1762] D loss: 1.3942, G loss: 0.6792\n",
      "[324/1762] D loss: 1.5813, G loss: 0.7125\n",
      "[404/1762] D loss: 1.4053, G loss: 0.6854\n",
      "[484/1762] D loss: 1.3269, G loss: 0.7923\n",
      "[564/1762] D loss: 1.3982, G loss: 0.8229\n",
      "[644/1762] D loss: 1.4023, G loss: 0.7349\n",
      "[724/1762] D loss: 0.5414, G loss: 1.3674\n",
      "[804/1762] D loss: 0.1287, G loss: 2.5633\n",
      "[884/1762] D loss: 1.4896, G loss: 0.7421\n",
      "[964/1762] D loss: 1.3841, G loss: 0.7108\n",
      "[1044/1762] D loss: 1.3744, G loss: 0.7481\n",
      "[1124/1762] D loss: 1.3112, G loss: 0.7745\n",
      "[1204/1762] D loss: 0.3848, G loss: 1.6158\n",
      "[1284/1762] D loss: 0.4586, G loss: 1.4522\n",
      "[1364/1762] D loss: 1.7574, G loss: 0.6869\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.7277\n",
      "[1524/1762] D loss: 0.1962, G loss: 2.1397\n",
      "[1604/1762] D loss: 1.4156, G loss: 0.7252\n",
      "[1684/1762] D loss: 1.3954, G loss: 0.6679\n",
      "[1762/1762] D loss: 1.3281, G loss: 0.8466\n",
      "train error: \n",
      " D loss: 1.359403, G loss: 0.621535, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349307, G loss: 0.632308, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4024, G loss: 0.7297\n",
      "[84/1762] D loss: 1.3735, G loss: 0.7009\n",
      "[164/1762] D loss: 1.3976, G loss: 0.6982\n",
      "[244/1762] D loss: 1.2596, G loss: 0.8528\n",
      "[324/1762] D loss: 1.3870, G loss: 0.7036\n",
      "[404/1762] D loss: 0.0979, G loss: 2.6293\n",
      "[484/1762] D loss: 1.4331, G loss: 0.7733\n",
      "[564/1762] D loss: 1.4990, G loss: 0.4916\n",
      "[644/1762] D loss: 1.3581, G loss: 0.7354\n",
      "[724/1762] D loss: 0.3662, G loss: 1.7076\n",
      "[804/1762] D loss: 0.2745, G loss: 1.8838\n",
      "[884/1762] D loss: 1.4481, G loss: 0.7676\n",
      "[964/1762] D loss: 1.4290, G loss: 0.7568\n",
      "[1044/1762] D loss: 1.3819, G loss: 0.7151\n",
      "[1124/1762] D loss: 1.1291, G loss: 0.6443\n",
      "[1204/1762] D loss: 0.3671, G loss: 1.9880\n",
      "[1284/1762] D loss: 1.5735, G loss: 0.3854\n",
      "[1364/1762] D loss: 1.4205, G loss: 0.9670\n",
      "[1444/1762] D loss: 0.7110, G loss: 1.6848\n",
      "[1524/1762] D loss: 1.7404, G loss: 0.4469\n",
      "[1604/1762] D loss: 1.3923, G loss: 0.6860\n",
      "[1684/1762] D loss: 1.3568, G loss: 0.8485\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.6884\n",
      "train error: \n",
      " D loss: 1.374246, G loss: 0.668256, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375993, G loss: 0.671620, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4249, G loss: 0.6977\n",
      "[84/1762] D loss: 1.6294, G loss: 0.7270\n",
      "[164/1762] D loss: 1.3781, G loss: 0.7264\n",
      "[244/1762] D loss: 1.4092, G loss: 0.6977\n",
      "[324/1762] D loss: 0.1806, G loss: 2.2834\n",
      "[404/1762] D loss: 1.4407, G loss: 0.7395\n",
      "[484/1762] D loss: 1.4282, G loss: 0.7101\n",
      "[564/1762] D loss: 1.4834, G loss: 0.7407\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6916\n",
      "[724/1762] D loss: 1.3738, G loss: 0.7042\n",
      "[804/1762] D loss: 1.3827, G loss: 0.6985\n",
      "[884/1762] D loss: 1.3931, G loss: 0.7024\n",
      "[964/1762] D loss: 1.3833, G loss: 0.7022\n",
      "[1044/1762] D loss: 1.4062, G loss: 0.6722\n",
      "[1124/1762] D loss: 1.4178, G loss: 0.6903\n",
      "[1204/1762] D loss: 1.3768, G loss: 0.7155\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.7067\n",
      "[1364/1762] D loss: 0.1636, G loss: 2.2578\n",
      "[1444/1762] D loss: 0.3868, G loss: 1.6524\n",
      "[1524/1762] D loss: 1.4208, G loss: 0.7260\n",
      "[1604/1762] D loss: 0.3912, G loss: 1.6350\n",
      "[1684/1762] D loss: 1.4333, G loss: 0.7535\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.7070\n",
      "train error: \n",
      " D loss: 1.449036, G loss: 0.468154, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.435547, G loss: 0.484574, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903, G loss: 0.6851\n",
      "[84/1762] D loss: 1.3807, G loss: 0.7065\n",
      "[164/1762] D loss: 1.3993, G loss: 0.7083\n",
      "[244/1762] D loss: 1.3763, G loss: 0.7041\n",
      "[324/1762] D loss: 1.3932, G loss: 0.6969\n",
      "[404/1762] D loss: 0.3146, G loss: 1.9809\n",
      "[484/1762] D loss: 0.3807, G loss: 1.7406\n",
      "[564/1762] D loss: 1.4093, G loss: 0.7212\n",
      "[644/1762] D loss: 0.4909, G loss: 1.4615\n",
      "[724/1762] D loss: 0.2454, G loss: 2.0227\n",
      "[804/1762] D loss: 1.3912, G loss: 0.7111\n",
      "[884/1762] D loss: 1.3964, G loss: 0.7043\n",
      "[964/1762] D loss: 0.3569, G loss: 1.6448\n",
      "[1044/1762] D loss: 0.1330, G loss: 2.4541\n",
      "[1124/1762] D loss: 1.5311, G loss: 0.7146\n",
      "[1204/1762] D loss: 1.4873, G loss: 0.6744\n",
      "[1284/1762] D loss: 1.3588, G loss: 0.7424\n",
      "[1364/1762] D loss: 1.3923, G loss: 0.7219\n",
      "[1444/1762] D loss: 1.4238, G loss: 0.6753\n",
      "[1524/1762] D loss: 1.3750, G loss: 0.6871\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.6864\n",
      "[1684/1762] D loss: 1.4077, G loss: 0.7081\n",
      "[1762/1762] D loss: 0.0423, G loss: 3.4915\n",
      "train error: \n",
      " D loss: 1.536549, G loss: 0.373310, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.519939, G loss: 0.383376, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3981, G loss: 0.7188\n",
      "[84/1762] D loss: 0.3751, G loss: 1.5689\n",
      "[164/1762] D loss: 0.3452, G loss: 1.7030\n",
      "[244/1762] D loss: 1.4117, G loss: 0.7310\n",
      "[324/1762] D loss: 1.4081, G loss: 0.6842\n",
      "[404/1762] D loss: 1.3929, G loss: 0.7163\n",
      "[484/1762] D loss: 1.4038, G loss: 0.8249\n",
      "[564/1762] D loss: 1.2298, G loss: 0.8550\n",
      "[644/1762] D loss: 1.3404, G loss: 0.7695\n",
      "[724/1762] D loss: 0.3578, G loss: 1.7201\n",
      "[804/1762] D loss: 1.1834, G loss: 0.8537\n",
      "[884/1762] D loss: 0.3640, G loss: 1.6778\n",
      "[964/1762] D loss: 0.3451, G loss: 1.6267\n",
      "[1044/1762] D loss: 0.3678, G loss: 1.6734\n",
      "[1124/1762] D loss: 0.0954, G loss: 2.7582\n",
      "[1204/1762] D loss: 1.4087, G loss: 0.7262\n",
      "[1284/1762] D loss: 0.3378, G loss: 1.7041\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.6958\n",
      "[1444/1762] D loss: 1.3922, G loss: 0.6706\n",
      "[1524/1762] D loss: 1.4019, G loss: 0.7142\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6925\n",
      "[1684/1762] D loss: 1.5171, G loss: 0.6634\n",
      "[1762/1762] D loss: 1.4144, G loss: 0.7119\n",
      "train error: \n",
      " D loss: 1.366726, G loss: 0.681504, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365238, G loss: 0.691719, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3987, G loss: 0.7014\n",
      "[84/1762] D loss: 0.1589, G loss: 2.2470\n",
      "[164/1762] D loss: 0.3530, G loss: 1.6859\n",
      "[244/1762] D loss: 1.3842, G loss: 0.7085\n",
      "[324/1762] D loss: 1.3880, G loss: 0.7001\n",
      "[404/1762] D loss: 0.3442, G loss: 1.7548\n",
      "[484/1762] D loss: 1.3972, G loss: 0.6959\n",
      "[564/1762] D loss: 0.3509, G loss: 1.6752\n",
      "[644/1762] D loss: 1.4080, G loss: 0.7040\n",
      "[724/1762] D loss: 1.3837, G loss: 0.7120\n",
      "[804/1762] D loss: 0.3036, G loss: 1.8430\n",
      "[884/1762] D loss: 0.0807, G loss: 2.8128\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7006\n",
      "[1044/1762] D loss: 1.3402, G loss: 0.7309\n",
      "[1124/1762] D loss: 0.2990, G loss: 1.7852\n",
      "[1204/1762] D loss: 0.3562, G loss: 1.7052\n",
      "[1284/1762] D loss: 0.2934, G loss: 1.8643\n",
      "[1364/1762] D loss: 1.4243, G loss: 0.6948\n",
      "[1444/1762] D loss: 0.3346, G loss: 1.7637\n",
      "[1524/1762] D loss: 1.3844, G loss: 0.7203\n",
      "[1604/1762] D loss: 1.3921, G loss: 0.6938\n",
      "[1684/1762] D loss: 1.4160, G loss: 0.6845\n",
      "[1762/1762] D loss: 1.4240, G loss: 0.6028\n",
      "train error: \n",
      " D loss: 1.391858, G loss: 0.669778, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395321, G loss: 0.682191, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4022, G loss: 0.7081\n",
      "[84/1762] D loss: 0.3120, G loss: 1.7140\n",
      "[164/1762] D loss: 1.3846, G loss: 0.6790\n",
      "[244/1762] D loss: 0.3842, G loss: 1.6313\n",
      "[324/1762] D loss: 1.3915, G loss: 0.6833\n",
      "[404/1762] D loss: 1.4080, G loss: 0.7203\n",
      "[484/1762] D loss: 0.3920, G loss: 1.6197\n",
      "[564/1762] D loss: 1.6034, G loss: 0.5988\n",
      "[644/1762] D loss: 1.4149, G loss: 0.7345\n",
      "[724/1762] D loss: 0.4267, G loss: 1.4938\n",
      "[804/1762] D loss: 0.3412, G loss: 1.7137\n",
      "[884/1762] D loss: 1.4047, G loss: 0.7166\n",
      "[964/1762] D loss: 1.4174, G loss: 0.6907\n",
      "[1044/1762] D loss: 1.4283, G loss: 0.6888\n",
      "[1124/1762] D loss: 1.4862, G loss: 0.7526\n",
      "[1204/1762] D loss: 0.3277, G loss: 1.7419\n",
      "[1284/1762] D loss: 1.4347, G loss: 0.7074\n",
      "[1364/1762] D loss: 0.3974, G loss: 1.5434\n",
      "[1444/1762] D loss: 1.5750, G loss: 0.6491\n",
      "[1524/1762] D loss: 1.8941, G loss: 0.8416\n",
      "[1604/1762] D loss: 1.0273, G loss: 1.2660\n",
      "[1684/1762] D loss: 1.4164, G loss: 0.7101\n",
      "[1762/1762] D loss: 1.4026, G loss: 0.6758\n",
      "train error: \n",
      " D loss: 1.718799, G loss: 0.492424, D accuracy: 49.6%, cell accuracy: 99.8%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.808047, G loss: 0.489551, D accuracy: 47.8%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6305, G loss: 0.6466\n",
      "[84/1762] D loss: 1.4463, G loss: 0.6762\n",
      "[164/1762] D loss: 1.4374, G loss: 0.7289\n",
      "[244/1762] D loss: 1.3025, G loss: 0.7960\n",
      "[324/1762] D loss: 1.3712, G loss: 0.7357\n",
      "[404/1762] D loss: 1.2883, G loss: 0.7726\n",
      "[484/1762] D loss: 0.4736, G loss: 1.4821\n",
      "[564/1762] D loss: 1.4346, G loss: 0.7062\n",
      "[644/1762] D loss: 1.4314, G loss: 0.7114\n",
      "[724/1762] D loss: 1.4243, G loss: 0.7000\n",
      "[804/1762] D loss: 1.3884, G loss: 0.6983\n",
      "[884/1762] D loss: 1.4717, G loss: 0.7309\n",
      "[964/1762] D loss: 1.4029, G loss: 0.7420\n",
      "[1044/1762] D loss: 0.3907, G loss: 1.6444\n",
      "[1124/1762] D loss: 1.4233, G loss: 0.7290\n",
      "[1204/1762] D loss: 0.4560, G loss: 1.5388\n",
      "[1284/1762] D loss: 1.8384, G loss: 0.7213\n",
      "[1364/1762] D loss: 1.2288, G loss: 0.8839\n",
      "[1444/1762] D loss: 0.4861, G loss: 1.5537\n",
      "[1524/1762] D loss: 1.1739, G loss: 0.9899\n",
      "[1604/1762] D loss: 1.4396, G loss: 0.7546\n",
      "[1684/1762] D loss: 1.4166, G loss: 0.7208\n",
      "[1762/1762] D loss: 0.1677, G loss: 2.3907\n",
      "train error: \n",
      " D loss: 1.391943, G loss: 0.641564, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.415181, G loss: 0.637431, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1249, G loss: 0.9117\n",
      "[84/1762] D loss: 1.4602, G loss: 0.7696\n",
      "[164/1762] D loss: 0.4026, G loss: 1.6692\n",
      "[244/1762] D loss: 0.2912, G loss: 1.9679\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6934\n",
      "[404/1762] D loss: 1.3304, G loss: 0.7921\n",
      "[484/1762] D loss: 1.2905, G loss: 0.7804\n",
      "[564/1762] D loss: 1.6232, G loss: 0.8154\n",
      "[644/1762] D loss: 1.3087, G loss: 0.8287\n",
      "[724/1762] D loss: 1.3286, G loss: 0.7773\n",
      "[804/1762] D loss: 1.3849, G loss: 0.7093\n",
      "[884/1762] D loss: 1.3686, G loss: 0.7402\n",
      "[964/1762] D loss: 1.4439, G loss: 0.6860\n",
      "[1044/1762] D loss: 0.4021, G loss: 1.6832\n",
      "[1124/1762] D loss: 1.6038, G loss: 0.7876\n",
      "[1204/1762] D loss: 1.3362, G loss: 0.7828\n",
      "[1284/1762] D loss: 1.3402, G loss: 0.7786\n",
      "[1364/1762] D loss: 0.4404, G loss: 1.6109\n",
      "[1444/1762] D loss: 1.4047, G loss: 0.6692\n",
      "[1524/1762] D loss: 1.3649, G loss: 0.7063\n",
      "[1604/1762] D loss: 0.4935, G loss: 1.4471\n",
      "[1684/1762] D loss: 0.5444, G loss: 1.4625\n",
      "[1762/1762] D loss: 1.3803, G loss: 0.7192\n",
      "train error: \n",
      " D loss: 1.369676, G loss: 0.756227, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387272, G loss: 0.765190, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2913, G loss: 1.9061\n",
      "[84/1762] D loss: 1.3661, G loss: 0.7775\n",
      "[164/1762] D loss: 1.3907, G loss: 0.7089\n",
      "[244/1762] D loss: 1.5155, G loss: 0.8380\n",
      "[324/1762] D loss: 1.4036, G loss: 0.7137\n",
      "[404/1762] D loss: 1.4309, G loss: 0.7127\n",
      "[484/1762] D loss: 1.3991, G loss: 0.6979\n",
      "[564/1762] D loss: 1.3904, G loss: 0.7238\n",
      "[644/1762] D loss: 1.3995, G loss: 0.7054\n",
      "[724/1762] D loss: 1.3831, G loss: 0.7053\n",
      "[804/1762] D loss: 1.4167, G loss: 0.6492\n",
      "[884/1762] D loss: 1.3988, G loss: 0.7492\n",
      "[964/1762] D loss: 0.5898, G loss: 1.5139\n",
      "[1044/1762] D loss: 1.4643, G loss: 0.6573\n",
      "[1124/1762] D loss: 1.4137, G loss: 0.6824\n",
      "[1204/1762] D loss: 0.5991, G loss: 1.4544\n",
      "[1284/1762] D loss: 1.3242, G loss: 0.8582\n",
      "[1364/1762] D loss: 0.2124, G loss: 2.4802\n",
      "[1444/1762] D loss: 1.4330, G loss: 0.7629\n",
      "[1524/1762] D loss: 1.3217, G loss: 0.7273\n",
      "[1604/1762] D loss: 1.1252, G loss: 0.6524\n",
      "[1684/1762] D loss: 0.5700, G loss: 1.4736\n",
      "[1762/1762] D loss: 1.1921, G loss: 2.1139\n",
      "train error: \n",
      " D loss: 1.370090, G loss: 0.803456, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380925, G loss: 0.804856, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6591, G loss: 0.5075\n",
      "[84/1762] D loss: 1.0681, G loss: 1.0640\n",
      "[164/1762] D loss: 0.4995, G loss: 1.5776\n",
      "[244/1762] D loss: 1.0149, G loss: 1.0464\n",
      "[324/1762] D loss: 0.8640, G loss: 1.2170\n",
      "[404/1762] D loss: 1.1643, G loss: 1.4131\n",
      "[484/1762] D loss: 0.9317, G loss: 1.2708\n",
      "[564/1762] D loss: 1.3974, G loss: 0.6622\n",
      "[644/1762] D loss: 1.4552, G loss: 0.7042\n",
      "[724/1762] D loss: 1.3919, G loss: 0.6962\n",
      "[804/1762] D loss: 1.4251, G loss: 0.6760\n",
      "[884/1762] D loss: 1.3681, G loss: 0.8634\n",
      "[964/1762] D loss: 1.4238, G loss: 0.7034\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7001\n",
      "[1124/1762] D loss: 0.4267, G loss: 1.7393\n",
      "[1204/1762] D loss: 1.4038, G loss: 0.7162\n",
      "[1284/1762] D loss: 1.3758, G loss: 0.8299\n",
      "[1364/1762] D loss: 1.4239, G loss: 0.7774\n",
      "[1444/1762] D loss: 1.3613, G loss: 0.8393\n",
      "[1524/1762] D loss: 1.3967, G loss: 0.6841\n",
      "[1604/1762] D loss: 1.4053, G loss: 0.6820\n",
      "[1684/1762] D loss: 1.3596, G loss: 0.6663\n",
      "[1762/1762] D loss: 1.3995, G loss: 0.8137\n",
      "train error: \n",
      " D loss: 1.409054, G loss: 0.858173, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.428756, G loss: 0.862763, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3955, G loss: 0.6704\n",
      "[84/1762] D loss: 1.3861, G loss: 0.7132\n",
      "[164/1762] D loss: 1.3852, G loss: 0.6804\n",
      "[244/1762] D loss: 1.3801, G loss: 0.7021\n",
      "[324/1762] D loss: 0.1053, G loss: 2.7161\n",
      "[404/1762] D loss: 1.3325, G loss: 0.7416\n",
      "[484/1762] D loss: 1.3763, G loss: 0.6927\n",
      "[564/1762] D loss: 1.3990, G loss: 0.7068\n",
      "[644/1762] D loss: 1.4364, G loss: 0.7059\n",
      "[724/1762] D loss: 0.4719, G loss: 1.4923\n",
      "[804/1762] D loss: 0.3471, G loss: 1.7111\n",
      "[884/1762] D loss: 1.5511, G loss: 0.7049\n",
      "[964/1762] D loss: 1.4187, G loss: 0.7498\n",
      "[1044/1762] D loss: 1.4982, G loss: 0.8181\n",
      "[1124/1762] D loss: 0.3485, G loss: 1.7042\n",
      "[1204/1762] D loss: 1.4529, G loss: 0.7353\n",
      "[1284/1762] D loss: 1.3736, G loss: 0.6964\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.7063\n",
      "[1444/1762] D loss: 0.3889, G loss: 1.6896\n",
      "[1524/1762] D loss: 1.4385, G loss: 0.7554\n",
      "[1604/1762] D loss: 1.3849, G loss: 0.7062\n",
      "[1684/1762] D loss: 0.4427, G loss: 1.4291\n",
      "[1762/1762] D loss: 1.4460, G loss: 0.6854\n",
      "train error: \n",
      " D loss: 1.416414, G loss: 0.555478, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417527, G loss: 0.564370, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3800, G loss: 0.7060\n",
      "[84/1762] D loss: 0.6263, G loss: 1.4304\n",
      "[164/1762] D loss: 0.5261, G loss: 1.4131\n",
      "[244/1762] D loss: 1.3998, G loss: 0.7265\n",
      "[324/1762] D loss: 0.3265, G loss: 1.7221\n",
      "[404/1762] D loss: 1.3844, G loss: 0.6986\n",
      "[484/1762] D loss: 1.4051, G loss: 0.7379\n",
      "[564/1762] D loss: 1.3910, G loss: 0.7176\n",
      "[644/1762] D loss: 0.3293, G loss: 1.8337\n",
      "[724/1762] D loss: 1.5885, G loss: 0.7955\n",
      "[804/1762] D loss: 1.3858, G loss: 0.7469\n",
      "[884/1762] D loss: 1.4356, G loss: 0.7710\n",
      "[964/1762] D loss: 1.4279, G loss: 0.7073\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7078\n",
      "[1124/1762] D loss: 1.1552, G loss: 0.8540\n",
      "[1204/1762] D loss: 1.4702, G loss: 0.6962\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7092\n",
      "[1364/1762] D loss: 1.3984, G loss: 0.7094\n",
      "[1444/1762] D loss: 1.4339, G loss: 0.6515\n",
      "[1524/1762] D loss: 1.3670, G loss: 0.7692\n",
      "[1604/1762] D loss: 0.3378, G loss: 1.6931\n",
      "[1684/1762] D loss: 1.2926, G loss: 0.8972\n",
      "[1762/1762] D loss: 1.4082, G loss: 0.7754\n",
      "train error: \n",
      " D loss: 1.382760, G loss: 0.682467, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385703, G loss: 0.699302, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4360, G loss: 0.7413\n",
      "[84/1762] D loss: 1.3888, G loss: 0.6860\n",
      "[164/1762] D loss: 1.4548, G loss: 0.7011\n",
      "[244/1762] D loss: 1.3962, G loss: 0.6954\n",
      "[324/1762] D loss: 1.7399, G loss: 0.7705\n",
      "[404/1762] D loss: 1.4064, G loss: 0.6990\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7027\n",
      "[564/1762] D loss: 1.4247, G loss: 0.7262\n",
      "[644/1762] D loss: 1.3640, G loss: 0.7284\n",
      "[724/1762] D loss: 1.6211, G loss: 0.8248\n",
      "[804/1762] D loss: 1.5079, G loss: 0.7165\n",
      "[884/1762] D loss: 1.5577, G loss: 0.7302\n",
      "[964/1762] D loss: 1.4328, G loss: 0.7030\n",
      "[1044/1762] D loss: 1.4530, G loss: 0.6903\n",
      "[1124/1762] D loss: 0.3174, G loss: 1.9105\n",
      "[1204/1762] D loss: 1.3932, G loss: 0.7230\n",
      "[1284/1762] D loss: 1.4093, G loss: 0.7219\n",
      "[1364/1762] D loss: 0.3244, G loss: 1.7120\n",
      "[1444/1762] D loss: 0.3568, G loss: 1.7006\n",
      "[1524/1762] D loss: 0.2578, G loss: 1.8667\n",
      "[1604/1762] D loss: 1.3130, G loss: 0.8006\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6994\n",
      "[1762/1762] D loss: 1.6998, G loss: 0.4793\n",
      "train error: \n",
      " D loss: 1.374756, G loss: 0.680981, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373678, G loss: 0.695933, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903, G loss: 0.7127\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6826\n",
      "[164/1762] D loss: 0.2983, G loss: 1.9272\n",
      "[244/1762] D loss: 1.5605, G loss: 0.8285\n",
      "[324/1762] D loss: 1.3043, G loss: 0.7824\n",
      "[404/1762] D loss: 1.4106, G loss: 0.7022\n",
      "[484/1762] D loss: 0.2231, G loss: 2.0851\n",
      "[564/1762] D loss: 1.3819, G loss: 0.6863\n",
      "[644/1762] D loss: 1.4055, G loss: 0.7297\n",
      "[724/1762] D loss: 1.4234, G loss: 0.7135\n",
      "[804/1762] D loss: 1.4037, G loss: 0.7015\n",
      "[884/1762] D loss: 1.3737, G loss: 0.6965\n",
      "[964/1762] D loss: 0.2358, G loss: 1.9800\n",
      "[1044/1762] D loss: 0.3150, G loss: 1.7465\n",
      "[1124/1762] D loss: 1.4129, G loss: 0.7003\n",
      "[1204/1762] D loss: 1.6722, G loss: 0.7438\n",
      "[1284/1762] D loss: 0.2915, G loss: 1.8628\n",
      "[1364/1762] D loss: 1.4553, G loss: 0.7402\n",
      "[1444/1762] D loss: 1.3926, G loss: 0.6975\n",
      "[1524/1762] D loss: 0.1183, G loss: 2.5866\n",
      "[1604/1762] D loss: 1.4012, G loss: 0.7125\n",
      "[1684/1762] D loss: 1.4108, G loss: 0.6873\n",
      "[1762/1762] D loss: 1.4379, G loss: 0.6810\n",
      "train error: \n",
      " D loss: 1.396874, G loss: 0.848409, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403255, G loss: 0.864426, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0934, G loss: 2.7269\n",
      "[84/1762] D loss: 0.2035, G loss: 2.0660\n",
      "[164/1762] D loss: 1.4010, G loss: 0.7344\n",
      "[244/1762] D loss: 1.4282, G loss: 0.6993\n",
      "[324/1762] D loss: 0.0922, G loss: 2.7441\n",
      "[404/1762] D loss: 1.3810, G loss: 0.7132\n",
      "[484/1762] D loss: 0.0784, G loss: 2.8767\n",
      "[564/1762] D loss: 1.3813, G loss: 0.6985\n",
      "[644/1762] D loss: 0.2162, G loss: 2.0818\n",
      "[724/1762] D loss: 1.3780, G loss: 0.6937\n",
      "[804/1762] D loss: 0.3057, G loss: 1.7702\n",
      "[884/1762] D loss: 1.4191, G loss: 0.6954\n",
      "[964/1762] D loss: 1.3778, G loss: 0.7052\n",
      "[1044/1762] D loss: 1.4207, G loss: 0.7155\n",
      "[1124/1762] D loss: 1.4595, G loss: 0.7324\n",
      "[1204/1762] D loss: 1.4250, G loss: 0.6426\n",
      "[1284/1762] D loss: 0.3216, G loss: 1.9372\n",
      "[1364/1762] D loss: 1.4057, G loss: 0.7153\n",
      "[1444/1762] D loss: 1.4048, G loss: 0.7008\n",
      "[1524/1762] D loss: 1.4005, G loss: 0.7114\n",
      "[1604/1762] D loss: 1.4367, G loss: 0.7559\n",
      "[1684/1762] D loss: 0.3144, G loss: 1.9143\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7051\n",
      "train error: \n",
      " D loss: 1.438331, G loss: 0.491792, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.436567, G loss: 0.503119, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3960, G loss: 0.7035\n",
      "[84/1762] D loss: 1.5139, G loss: 0.7557\n",
      "[164/1762] D loss: 1.4116, G loss: 0.6969\n",
      "[244/1762] D loss: 1.4187, G loss: 0.6801\n",
      "[324/1762] D loss: 1.4030, G loss: 0.7238\n",
      "[404/1762] D loss: 1.3083, G loss: 0.7853\n",
      "[484/1762] D loss: 1.3503, G loss: 0.7594\n",
      "[564/1762] D loss: 1.4132, G loss: 0.7231\n",
      "[644/1762] D loss: 1.4029, G loss: 0.6963\n",
      "[724/1762] D loss: 0.0563, G loss: 3.2463\n",
      "[804/1762] D loss: 1.4022, G loss: 0.6905\n",
      "[884/1762] D loss: 1.4140, G loss: 0.7267\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7025\n",
      "[1044/1762] D loss: 1.4653, G loss: 0.6398\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.7111\n",
      "[1204/1762] D loss: 1.3810, G loss: 0.7019\n",
      "[1284/1762] D loss: 0.0922, G loss: 2.7322\n",
      "[1364/1762] D loss: 1.4408, G loss: 0.7284\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.6909\n",
      "[1524/1762] D loss: 1.4150, G loss: 0.6810\n",
      "[1604/1762] D loss: 1.3958, G loss: 0.6936\n",
      "[1684/1762] D loss: 0.2606, G loss: 1.8732\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.6669\n",
      "train error: \n",
      " D loss: 1.382614, G loss: 0.679403, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384472, G loss: 0.691282, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4066, G loss: 0.7338\n",
      "[84/1762] D loss: 1.4175, G loss: 0.6919\n",
      "[164/1762] D loss: 1.3876, G loss: 0.7126\n",
      "[244/1762] D loss: 1.3599, G loss: 0.6948\n",
      "[324/1762] D loss: 1.4084, G loss: 0.6837\n",
      "[404/1762] D loss: 1.3708, G loss: 0.7272\n",
      "[484/1762] D loss: 0.1875, G loss: 2.2636\n",
      "[564/1762] D loss: 1.4005, G loss: 0.7157\n",
      "[644/1762] D loss: 1.3899, G loss: 0.7136\n",
      "[724/1762] D loss: 1.4338, G loss: 0.7109\n",
      "[804/1762] D loss: 0.2203, G loss: 2.1053\n",
      "[884/1762] D loss: 1.4213, G loss: 0.7003\n",
      "[964/1762] D loss: 1.3180, G loss: 0.7582\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.6995\n",
      "[1124/1762] D loss: 1.4311, G loss: 0.7103\n",
      "[1204/1762] D loss: 1.3539, G loss: 0.7411\n",
      "[1284/1762] D loss: 0.0980, G loss: 2.7164\n",
      "[1364/1762] D loss: 1.3831, G loss: 0.7013\n",
      "[1444/1762] D loss: 1.3890, G loss: 0.6874\n",
      "[1524/1762] D loss: 1.3853, G loss: 0.6947\n",
      "[1604/1762] D loss: 1.4103, G loss: 0.6728\n",
      "[1684/1762] D loss: 1.3956, G loss: 0.7169\n",
      "[1762/1762] D loss: 1.3992, G loss: 0.6966\n",
      "train error: \n",
      " D loss: 1.386703, G loss: 0.655581, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389662, G loss: 0.667093, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3469, G loss: 0.7375\n",
      "[84/1762] D loss: 0.3076, G loss: 1.8047\n",
      "[164/1762] D loss: 1.4068, G loss: 0.7034\n",
      "[244/1762] D loss: 1.4135, G loss: 0.7108\n",
      "[324/1762] D loss: 1.3770, G loss: 0.6999\n",
      "[404/1762] D loss: 1.4016, G loss: 0.7372\n",
      "[484/1762] D loss: 1.4162, G loss: 0.7258\n",
      "[564/1762] D loss: 0.0702, G loss: 2.9585\n",
      "[644/1762] D loss: 1.4063, G loss: 0.7079\n",
      "[724/1762] D loss: 1.4707, G loss: 0.6825\n",
      "[804/1762] D loss: 0.1728, G loss: 2.2502\n",
      "[884/1762] D loss: 1.4647, G loss: 0.7036\n",
      "[964/1762] D loss: 1.3916, G loss: 0.6894\n",
      "[1044/1762] D loss: 0.2712, G loss: 1.8942\n",
      "[1124/1762] D loss: 1.4265, G loss: 0.7002\n",
      "[1204/1762] D loss: 1.4372, G loss: 0.6923\n",
      "[1284/1762] D loss: 0.3498, G loss: 1.7024\n",
      "[1364/1762] D loss: 0.2283, G loss: 2.0966\n",
      "[1444/1762] D loss: 1.4016, G loss: 0.6941\n",
      "[1524/1762] D loss: 1.4320, G loss: 0.6902\n",
      "[1604/1762] D loss: 1.3825, G loss: 0.7067\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.6978\n",
      "[1762/1762] D loss: 1.3973, G loss: 0.7139\n",
      "train error: \n",
      " D loss: 1.390629, G loss: 0.742962, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397991, G loss: 0.754516, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.7062\n",
      "[84/1762] D loss: 0.2066, G loss: 2.1488\n",
      "[164/1762] D loss: 1.3852, G loss: 0.7090\n",
      "[244/1762] D loss: 1.5042, G loss: 0.6782\n",
      "[324/1762] D loss: 1.4091, G loss: 0.7793\n",
      "[404/1762] D loss: 1.4015, G loss: 0.6991\n",
      "[484/1762] D loss: 1.4785, G loss: 0.7288\n",
      "[564/1762] D loss: 1.3910, G loss: 0.6956\n",
      "[644/1762] D loss: 0.3102, G loss: 1.8083\n",
      "[724/1762] D loss: 1.4210, G loss: 0.7077\n",
      "[804/1762] D loss: 1.4010, G loss: 0.7185\n",
      "[884/1762] D loss: 0.2354, G loss: 1.9730\n",
      "[964/1762] D loss: 1.4147, G loss: 0.7159\n",
      "[1044/1762] D loss: 1.3975, G loss: 0.6819\n",
      "[1124/1762] D loss: 1.4655, G loss: 0.6829\n",
      "[1204/1762] D loss: 0.2315, G loss: 2.1006\n",
      "[1284/1762] D loss: 1.3949, G loss: 0.6992\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7002\n",
      "[1444/1762] D loss: 1.3775, G loss: 0.7329\n",
      "[1524/1762] D loss: 1.4048, G loss: 0.7026\n",
      "[1604/1762] D loss: 1.4240, G loss: 0.6878\n",
      "[1684/1762] D loss: 1.3914, G loss: 0.7032\n",
      "[1762/1762] D loss: 1.1021, G loss: 1.6718\n",
      "train error: \n",
      " D loss: 1.384184, G loss: 0.817403, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389187, G loss: 0.830304, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6875, G loss: 0.6292\n",
      "[84/1762] D loss: 1.3907, G loss: 0.7078\n",
      "[164/1762] D loss: 1.3884, G loss: 0.6906\n",
      "[244/1762] D loss: 1.3857, G loss: 0.7409\n",
      "[324/1762] D loss: 0.3023, G loss: 1.7806\n",
      "[404/1762] D loss: 1.4688, G loss: 0.7156\n",
      "[484/1762] D loss: 0.3703, G loss: 1.6111\n",
      "[564/1762] D loss: 1.5089, G loss: 0.7470\n",
      "[644/1762] D loss: 0.3010, G loss: 1.7608\n",
      "[724/1762] D loss: 0.2783, G loss: 1.8238\n",
      "[804/1762] D loss: 1.4076, G loss: 0.6912\n",
      "[884/1762] D loss: 1.4583, G loss: 0.4455\n",
      "[964/1762] D loss: 1.3886, G loss: 0.7226\n",
      "[1044/1762] D loss: 0.2226, G loss: 2.0154\n",
      "[1124/1762] D loss: 0.2748, G loss: 1.8941\n",
      "[1204/1762] D loss: 0.2610, G loss: 1.8244\n",
      "[1284/1762] D loss: 1.4360, G loss: 0.6729\n",
      "[1364/1762] D loss: 0.3249, G loss: 1.7514\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.7005\n",
      "[1524/1762] D loss: 0.3088, G loss: 1.8180\n",
      "[1604/1762] D loss: 0.3510, G loss: 1.7807\n",
      "[1684/1762] D loss: 0.2387, G loss: 2.0492\n",
      "[1762/1762] D loss: 1.4069, G loss: 0.6663\n",
      "train error: \n",
      " D loss: 1.366669, G loss: 0.673587, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370345, G loss: 0.683733, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3166, G loss: 1.7888\n",
      "[84/1762] D loss: 1.7274, G loss: 0.5954\n",
      "[164/1762] D loss: 1.3957, G loss: 0.6774\n",
      "[244/1762] D loss: 1.3709, G loss: 0.6972\n",
      "[324/1762] D loss: 1.3951, G loss: 0.7006\n",
      "[404/1762] D loss: 1.3545, G loss: 0.7284\n",
      "[484/1762] D loss: 0.2787, G loss: 1.8501\n",
      "[564/1762] D loss: 0.3464, G loss: 1.6750\n",
      "[644/1762] D loss: 1.4398, G loss: 0.6380\n",
      "[724/1762] D loss: 1.3958, G loss: 0.7129\n",
      "[804/1762] D loss: 1.3840, G loss: 0.6886\n",
      "[884/1762] D loss: 0.2379, G loss: 1.9714\n",
      "[964/1762] D loss: 1.4661, G loss: 0.7279\n",
      "[1044/1762] D loss: 0.2197, G loss: 2.0179\n",
      "[1124/1762] D loss: 1.3714, G loss: 0.7078\n",
      "[1204/1762] D loss: 1.4113, G loss: 0.7077\n",
      "[1284/1762] D loss: 1.4453, G loss: 0.7250\n",
      "[1364/1762] D loss: 1.4877, G loss: 0.6720\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.7029\n",
      "[1524/1762] D loss: 1.3851, G loss: 0.7248\n",
      "[1604/1762] D loss: 1.3992, G loss: 0.7022\n",
      "[1684/1762] D loss: 1.4056, G loss: 0.7162\n",
      "[1762/1762] D loss: 1.4673, G loss: 0.7259\n",
      "train error: \n",
      " D loss: 1.378925, G loss: 0.686177, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384690, G loss: 0.696505, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4046, G loss: 0.7310\n",
      "[84/1762] D loss: 1.4025, G loss: 0.7007\n",
      "[164/1762] D loss: 1.3853, G loss: 0.7270\n",
      "[244/1762] D loss: 0.3209, G loss: 1.7325\n",
      "[324/1762] D loss: 2.2651, G loss: 0.9175\n",
      "[404/1762] D loss: 0.3284, G loss: 1.7346\n",
      "[484/1762] D loss: 1.3951, G loss: 0.7107\n",
      "[564/1762] D loss: 1.4080, G loss: 0.6912\n",
      "[644/1762] D loss: 0.2464, G loss: 1.9085\n",
      "[724/1762] D loss: 0.2467, G loss: 1.9635\n",
      "[804/1762] D loss: 1.3823, G loss: 0.6911\n",
      "[884/1762] D loss: 1.4714, G loss: 0.6742\n",
      "[964/1762] D loss: 1.3976, G loss: 0.7104\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7056\n",
      "[1124/1762] D loss: 1.4094, G loss: 0.6689\n",
      "[1204/1762] D loss: 0.1778, G loss: 2.2619\n",
      "[1284/1762] D loss: 1.4032, G loss: 0.7098\n",
      "[1364/1762] D loss: 0.3419, G loss: 1.7770\n",
      "[1444/1762] D loss: 1.3828, G loss: 0.6920\n",
      "[1524/1762] D loss: 1.4058, G loss: 0.6894\n",
      "[1604/1762] D loss: 1.4590, G loss: 0.7004\n",
      "[1684/1762] D loss: 1.3906, G loss: 0.7015\n",
      "[1762/1762] D loss: 0.1327, G loss: 2.3495\n",
      "train error: \n",
      " D loss: 1.612652, G loss: 0.325449, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.598172, G loss: 0.335781, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3156, G loss: 1.6738\n",
      "[84/1762] D loss: 1.3923, G loss: 0.7034\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7038\n",
      "[244/1762] D loss: 0.0590, G loss: 3.0584\n",
      "[324/1762] D loss: 1.3877, G loss: 0.7008\n",
      "[404/1762] D loss: 1.4746, G loss: 0.6791\n",
      "[484/1762] D loss: 1.3921, G loss: 0.7007\n",
      "[564/1762] D loss: 1.3942, G loss: 0.6962\n",
      "[644/1762] D loss: 1.3901, G loss: 0.7008\n",
      "[724/1762] D loss: 1.3964, G loss: 0.7115\n",
      "[804/1762] D loss: 0.5009, G loss: 1.4579\n",
      "[884/1762] D loss: 1.3845, G loss: 0.7309\n",
      "[964/1762] D loss: 1.3643, G loss: 0.7663\n",
      "[1044/1762] D loss: 1.3472, G loss: 0.7461\n",
      "[1124/1762] D loss: 1.4909, G loss: 0.7697\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.7323\n",
      "[1284/1762] D loss: 0.2691, G loss: 1.9665\n",
      "[1364/1762] D loss: 1.3992, G loss: 0.7037\n",
      "[1444/1762] D loss: 1.4243, G loss: 0.6706\n",
      "[1524/1762] D loss: 1.3928, G loss: 0.7237\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7019\n",
      "[1684/1762] D loss: 1.3954, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.4064, G loss: 0.7673\n",
      "train error: \n",
      " D loss: 1.392873, G loss: 0.684171, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400970, G loss: 0.694895, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903, G loss: 0.6969\n",
      "[84/1762] D loss: 0.2408, G loss: 1.9540\n",
      "[164/1762] D loss: 1.3905, G loss: 0.7106\n",
      "[244/1762] D loss: 0.2168, G loss: 2.0392\n",
      "[324/1762] D loss: 1.4283, G loss: 0.7521\n",
      "[404/1762] D loss: 1.4992, G loss: 0.6924\n",
      "[484/1762] D loss: 1.5293, G loss: 0.7957\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6981\n",
      "[644/1762] D loss: 1.3979, G loss: 0.7095\n",
      "[724/1762] D loss: 0.0570, G loss: 3.0974\n",
      "[804/1762] D loss: 1.3885, G loss: 0.7063\n",
      "[884/1762] D loss: 0.2810, G loss: 1.9317\n",
      "[964/1762] D loss: 1.3975, G loss: 0.6935\n",
      "[1044/1762] D loss: 0.3437, G loss: 1.7267\n",
      "[1124/1762] D loss: 1.3989, G loss: 0.7048\n",
      "[1204/1762] D loss: 1.3912, G loss: 0.7130\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.7450\n",
      "[1364/1762] D loss: 1.4107, G loss: 0.6941\n",
      "[1444/1762] D loss: 1.3971, G loss: 0.7022\n",
      "[1524/1762] D loss: 0.2860, G loss: 1.8014\n",
      "[1604/1762] D loss: 0.2653, G loss: 1.8636\n",
      "[1684/1762] D loss: 1.3816, G loss: 0.7095\n",
      "[1762/1762] D loss: 1.3953, G loss: 0.6972\n",
      "train error: \n",
      " D loss: 1.396189, G loss: 0.626954, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403039, G loss: 0.641688, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4319, G loss: 0.6967\n",
      "[84/1762] D loss: 1.3898, G loss: 0.6851\n",
      "[164/1762] D loss: 1.3920, G loss: 0.6889\n",
      "[244/1762] D loss: 1.4361, G loss: 0.7120\n",
      "[324/1762] D loss: 0.2483, G loss: 2.0046\n",
      "[404/1762] D loss: 1.4036, G loss: 0.6910\n",
      "[484/1762] D loss: 1.3873, G loss: 0.6919\n",
      "[564/1762] D loss: 1.4001, G loss: 0.6970\n",
      "[644/1762] D loss: 1.3993, G loss: 0.6903\n",
      "[724/1762] D loss: 1.3238, G loss: 0.7675\n",
      "[804/1762] D loss: 1.3889, G loss: 0.7092\n",
      "[884/1762] D loss: 1.3884, G loss: 0.6941\n",
      "[964/1762] D loss: 0.3491, G loss: 1.8071\n",
      "[1044/1762] D loss: 1.3985, G loss: 0.7157\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.6939\n",
      "[1204/1762] D loss: 1.3975, G loss: 0.7080\n",
      "[1284/1762] D loss: 1.3957, G loss: 0.6984\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.7123\n",
      "[1444/1762] D loss: 0.3098, G loss: 1.7233\n",
      "[1524/1762] D loss: 1.3839, G loss: 0.6986\n",
      "[1604/1762] D loss: 0.2583, G loss: 1.9659\n",
      "[1684/1762] D loss: 1.4012, G loss: 0.7059\n",
      "[1762/1762] D loss: 1.2928, G loss: 0.7829\n",
      "train error: \n",
      " D loss: 1.373650, G loss: 0.774772, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376089, G loss: 0.789992, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3301, G loss: 1.7695\n",
      "[84/1762] D loss: 0.2129, G loss: 2.1240\n",
      "[164/1762] D loss: 0.1842, G loss: 2.2026\n",
      "[244/1762] D loss: 1.2929, G loss: 0.7749\n",
      "[324/1762] D loss: 1.5053, G loss: 0.7384\n",
      "[404/1762] D loss: 1.4960, G loss: 0.7447\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6967\n",
      "[564/1762] D loss: 0.1885, G loss: 2.2254\n",
      "[644/1762] D loss: 1.3920, G loss: 0.7101\n",
      "[724/1762] D loss: 1.4229, G loss: 0.6915\n",
      "[804/1762] D loss: 0.2241, G loss: 1.9374\n",
      "[884/1762] D loss: 1.3741, G loss: 0.7126\n",
      "[964/1762] D loss: 0.2872, G loss: 1.9261\n",
      "[1044/1762] D loss: 1.3652, G loss: 0.7254\n",
      "[1124/1762] D loss: 1.4333, G loss: 0.7126\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.6984\n",
      "[1284/1762] D loss: 1.4545, G loss: 0.6575\n",
      "[1364/1762] D loss: 1.4697, G loss: 0.7116\n",
      "[1444/1762] D loss: 0.2828, G loss: 1.7992\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6889\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.6908\n",
      "[1684/1762] D loss: 1.4374, G loss: 0.6838\n",
      "[1762/1762] D loss: 0.0583, G loss: 3.0612\n",
      "train error: \n",
      " D loss: 1.520013, G loss: 0.396269, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.516746, G loss: 0.403522, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2593, G loss: 1.8644\n",
      "[84/1762] D loss: 1.5805, G loss: 0.6666\n",
      "[164/1762] D loss: 1.4023, G loss: 0.7075\n",
      "[244/1762] D loss: 1.4039, G loss: 0.7388\n",
      "[324/1762] D loss: 1.3747, G loss: 0.7169\n",
      "[404/1762] D loss: 1.4585, G loss: 0.6255\n",
      "[484/1762] D loss: 1.3973, G loss: 0.7060\n",
      "[564/1762] D loss: 1.6031, G loss: 0.7564\n",
      "[644/1762] D loss: 1.3478, G loss: 0.7614\n",
      "[724/1762] D loss: 1.4022, G loss: 0.6906\n",
      "[804/1762] D loss: 0.3565, G loss: 1.7456\n",
      "[884/1762] D loss: 1.3521, G loss: 0.7116\n",
      "[964/1762] D loss: 0.2475, G loss: 1.9269\n",
      "[1044/1762] D loss: 1.4131, G loss: 0.7139\n",
      "[1124/1762] D loss: 0.0626, G loss: 3.1895\n",
      "[1204/1762] D loss: 0.1873, G loss: 2.1612\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6907\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.7106\n",
      "[1444/1762] D loss: 1.4202, G loss: 0.6990\n",
      "[1524/1762] D loss: 1.5097, G loss: 0.6060\n",
      "[1604/1762] D loss: 1.3252, G loss: 0.7221\n",
      "[1684/1762] D loss: 1.3508, G loss: 0.8019\n",
      "[1762/1762] D loss: 1.4304, G loss: 0.7333\n",
      "train error: \n",
      " D loss: 1.387592, G loss: 0.674940, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395722, G loss: 0.684782, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4699, G loss: 0.6813\n",
      "[84/1762] D loss: 0.0550, G loss: 3.2426\n",
      "[164/1762] D loss: 1.2581, G loss: 0.7569\n",
      "[244/1762] D loss: 1.3766, G loss: 0.7324\n",
      "[324/1762] D loss: 1.3968, G loss: 0.7252\n",
      "[404/1762] D loss: 1.4118, G loss: 0.7206\n",
      "[484/1762] D loss: 1.4681, G loss: 0.6231\n",
      "[564/1762] D loss: 1.4713, G loss: 0.6640\n",
      "[644/1762] D loss: 1.4204, G loss: 0.7186\n",
      "[724/1762] D loss: 1.4188, G loss: 0.7007\n",
      "[804/1762] D loss: 1.4246, G loss: 0.6970\n",
      "[884/1762] D loss: 1.0462, G loss: 1.1202\n",
      "[964/1762] D loss: 1.3941, G loss: 0.7217\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.6923\n",
      "[1124/1762] D loss: 1.3277, G loss: 0.7567\n",
      "[1204/1762] D loss: 1.4112, G loss: 0.6965\n",
      "[1284/1762] D loss: 1.4028, G loss: 0.7052\n",
      "[1364/1762] D loss: 1.4017, G loss: 0.7065\n",
      "[1444/1762] D loss: 1.4001, G loss: 0.6940\n",
      "[1524/1762] D loss: 1.3850, G loss: 0.7119\n",
      "[1604/1762] D loss: 1.3921, G loss: 0.7102\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.6958\n",
      "[1762/1762] D loss: 2.1712, G loss: 0.8432\n",
      "train error: \n",
      " D loss: 1.449847, G loss: 1.037844, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.443353, G loss: 1.042252, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4673, G loss: 0.9888\n",
      "[84/1762] D loss: 1.4259, G loss: 0.6550\n",
      "[164/1762] D loss: 1.3999, G loss: 0.6942\n",
      "[244/1762] D loss: 1.4357, G loss: 0.7408\n",
      "[324/1762] D loss: 1.4108, G loss: 0.7191\n",
      "[404/1762] D loss: 1.4019, G loss: 0.6852\n",
      "[484/1762] D loss: 0.1987, G loss: 2.1135\n",
      "[564/1762] D loss: 1.1821, G loss: 0.8646\n",
      "[644/1762] D loss: 1.3840, G loss: 0.7525\n",
      "[724/1762] D loss: 0.2039, G loss: 2.2120\n",
      "[804/1762] D loss: 1.2620, G loss: 0.9113\n",
      "[884/1762] D loss: 0.3872, G loss: 1.7439\n",
      "[964/1762] D loss: 0.0510, G loss: 3.2288\n",
      "[1044/1762] D loss: 1.3755, G loss: 0.6861\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.7056\n",
      "[1204/1762] D loss: 1.3753, G loss: 0.6897\n",
      "[1284/1762] D loss: 1.4039, G loss: 0.7058\n",
      "[1364/1762] D loss: 1.4050, G loss: 0.6890\n",
      "[1444/1762] D loss: 0.1821, G loss: 2.1430\n",
      "[1524/1762] D loss: 1.4669, G loss: 0.7458\n",
      "[1604/1762] D loss: 1.3966, G loss: 0.7040\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.6105\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6855\n",
      "train error: \n",
      " D loss: 1.403798, G loss: 0.626490, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.420899, G loss: 0.625530, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2334, G loss: 2.0152\n",
      "[84/1762] D loss: 1.4262, G loss: 0.7050\n",
      "[164/1762] D loss: 1.4485, G loss: 0.7101\n",
      "[244/1762] D loss: 0.0487, G loss: 3.3114\n",
      "[324/1762] D loss: 1.4643, G loss: 0.6898\n",
      "[404/1762] D loss: 0.2552, G loss: 1.8682\n",
      "[484/1762] D loss: 1.3949, G loss: 0.7006\n",
      "[564/1762] D loss: 0.2135, G loss: 2.0486\n",
      "[644/1762] D loss: 1.3985, G loss: 0.7381\n",
      "[724/1762] D loss: 1.3927, G loss: 0.6995\n",
      "[804/1762] D loss: 1.4370, G loss: 0.6973\n",
      "[884/1762] D loss: 0.2275, G loss: 2.0325\n",
      "[964/1762] D loss: 1.4035, G loss: 0.6879\n",
      "[1044/1762] D loss: 0.2212, G loss: 2.0868\n",
      "[1124/1762] D loss: 0.2613, G loss: 1.9193\n",
      "[1204/1762] D loss: 0.2303, G loss: 1.9772\n",
      "[1284/1762] D loss: 0.1768, G loss: 2.2672\n",
      "[1364/1762] D loss: 1.3107, G loss: 0.7484\n",
      "[1444/1762] D loss: 1.4205, G loss: 0.6738\n",
      "[1524/1762] D loss: 1.3702, G loss: 0.7296\n",
      "[1604/1762] D loss: 1.4000, G loss: 0.7092\n",
      "[1684/1762] D loss: 1.4086, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.5096, G loss: 0.5129\n",
      "train error: \n",
      " D loss: 1.393529, G loss: 0.714551, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403339, G loss: 0.725457, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4200, G loss: 0.6682\n",
      "[84/1762] D loss: 0.2529, G loss: 1.9131\n",
      "[164/1762] D loss: 1.4192, G loss: 0.6873\n",
      "[244/1762] D loss: 0.2070, G loss: 2.0446\n",
      "[324/1762] D loss: 1.4036, G loss: 0.6881\n",
      "[404/1762] D loss: 1.4099, G loss: 0.7149\n",
      "[484/1762] D loss: 1.3959, G loss: 0.7421\n",
      "[564/1762] D loss: 1.3907, G loss: 0.7220\n",
      "[644/1762] D loss: 0.0507, G loss: 3.2257\n",
      "[724/1762] D loss: 1.4413, G loss: 0.7257\n",
      "[804/1762] D loss: 1.4560, G loss: 0.5699\n",
      "[884/1762] D loss: 1.3889, G loss: 0.7149\n",
      "[964/1762] D loss: 1.3940, G loss: 0.6938\n",
      "[1044/1762] D loss: 1.4101, G loss: 0.6803\n",
      "[1124/1762] D loss: 0.2327, G loss: 1.9452\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.7056\n",
      "[1284/1762] D loss: 1.3910, G loss: 0.6944\n",
      "[1364/1762] D loss: 0.1226, G loss: 2.5329\n",
      "[1444/1762] D loss: 0.2499, G loss: 1.8955\n",
      "[1524/1762] D loss: 1.4408, G loss: 0.7479\n",
      "[1604/1762] D loss: 1.5909, G loss: 0.7866\n",
      "[1684/1762] D loss: 0.2082, G loss: 2.0027\n",
      "[1762/1762] D loss: 1.5130, G loss: 0.6814\n",
      "train error: \n",
      " D loss: 1.408673, G loss: 0.612606, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410684, G loss: 0.623057, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4031, G loss: 0.6490\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6446\n",
      "[164/1762] D loss: 1.3667, G loss: 0.6593\n",
      "[244/1762] D loss: 1.3709, G loss: 0.6456\n",
      "[324/1762] D loss: 1.3601, G loss: 0.6703\n",
      "[404/1762] D loss: 1.3367, G loss: 0.6696\n",
      "[484/1762] D loss: 1.3490, G loss: 0.6518\n",
      "[564/1762] D loss: 1.3573, G loss: 0.6868\n",
      "[644/1762] D loss: 1.3560, G loss: 0.6647\n",
      "[724/1762] D loss: 1.3201, G loss: 0.6884\n",
      "[804/1762] D loss: 1.3084, G loss: 0.7131\n",
      "[884/1762] D loss: 1.3224, G loss: 0.6799\n",
      "[964/1762] D loss: 1.2837, G loss: 0.7193\n",
      "[1044/1762] D loss: 1.3050, G loss: 0.6876\n",
      "[1124/1762] D loss: 1.3100, G loss: 0.7123\n",
      "[1204/1762] D loss: 1.2993, G loss: 0.6877\n",
      "[1284/1762] D loss: 1.2819, G loss: 0.6795\n",
      "[1364/1762] D loss: 1.2666, G loss: 0.7079\n",
      "[1444/1762] D loss: 1.2811, G loss: 0.7227\n",
      "[1524/1762] D loss: 1.2672, G loss: 0.7043\n",
      "[1604/1762] D loss: 1.2656, G loss: 0.7532\n",
      "[1684/1762] D loss: 1.2288, G loss: 0.7522\n",
      "[1762/1762] D loss: 1.1784, G loss: 0.7565\n",
      "train error: \n",
      " D loss: 1.213890, G loss: 0.719341, D accuracy: 86.6%, cell accuracy: 82.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.218569, G loss: 0.718402, D accuracy: 85.6%, cell accuracy: 82.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1907, G loss: 0.7539\n",
      "[84/1762] D loss: 1.1775, G loss: 0.7718\n",
      "[164/1762] D loss: 1.1708, G loss: 0.7541\n",
      "[244/1762] D loss: 1.2474, G loss: 0.7533\n",
      "[324/1762] D loss: 1.1505, G loss: 0.7687\n",
      "[404/1762] D loss: 1.1340, G loss: 0.7681\n",
      "[484/1762] D loss: 1.1765, G loss: 0.7628\n",
      "[564/1762] D loss: 1.0983, G loss: 0.8195\n",
      "[644/1762] D loss: 1.1320, G loss: 0.7903\n",
      "[724/1762] D loss: 1.1113, G loss: 0.7828\n",
      "[804/1762] D loss: 1.1459, G loss: 0.7934\n",
      "[884/1762] D loss: 1.1105, G loss: 0.7541\n",
      "[964/1762] D loss: 1.1096, G loss: 0.8142\n",
      "[1044/1762] D loss: 1.0820, G loss: 0.8355\n",
      "[1124/1762] D loss: 1.0631, G loss: 0.8530\n",
      "[1204/1762] D loss: 1.0641, G loss: 0.8670\n",
      "[1284/1762] D loss: 1.0144, G loss: 0.9136\n",
      "[1364/1762] D loss: 1.0119, G loss: 0.8612\n",
      "[1444/1762] D loss: 1.0602, G loss: 0.8325\n",
      "[1524/1762] D loss: 1.0701, G loss: 0.7853\n",
      "[1604/1762] D loss: 0.9792, G loss: 0.9314\n",
      "[1684/1762] D loss: 1.0663, G loss: 0.8560\n",
      "[1762/1762] D loss: 0.9657, G loss: 0.9633\n",
      "train error: \n",
      " D loss: 0.978301, G loss: 0.846038, D accuracy: 97.4%, cell accuracy: 87.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.982198, G loss: 0.846158, D accuracy: 96.6%, cell accuracy: 87.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9802, G loss: 0.8799\n",
      "[84/1762] D loss: 0.9686, G loss: 0.8583\n",
      "[164/1762] D loss: 0.9590, G loss: 0.8744\n",
      "[244/1762] D loss: 0.9141, G loss: 0.9522\n",
      "[324/1762] D loss: 0.9093, G loss: 0.9438\n",
      "[404/1762] D loss: 0.9495, G loss: 0.9103\n",
      "[484/1762] D loss: 0.8685, G loss: 1.0100\n",
      "[564/1762] D loss: 0.8718, G loss: 0.9903\n",
      "[644/1762] D loss: 0.8876, G loss: 0.9345\n",
      "[724/1762] D loss: 0.8798, G loss: 0.9882\n",
      "[804/1762] D loss: 0.8225, G loss: 1.0073\n",
      "[884/1762] D loss: 0.7925, G loss: 1.0782\n",
      "[964/1762] D loss: 0.8468, G loss: 0.9939\n",
      "[1044/1762] D loss: 0.8391, G loss: 1.0815\n",
      "[1124/1762] D loss: 0.8008, G loss: 1.0491\n",
      "[1204/1762] D loss: 0.7248, G loss: 1.1918\n",
      "[1284/1762] D loss: 0.7589, G loss: 1.1113\n",
      "[1364/1762] D loss: 0.7685, G loss: 1.1119\n",
      "[1444/1762] D loss: 0.7618, G loss: 1.0805\n",
      "[1524/1762] D loss: 0.7393, G loss: 1.1210\n",
      "[1604/1762] D loss: 0.7132, G loss: 1.1683\n",
      "[1684/1762] D loss: 0.7247, G loss: 1.1334\n",
      "[1762/1762] D loss: 0.6572, G loss: 1.1429\n",
      "train error: \n",
      " D loss: 0.730810, G loss: 1.083222, D accuracy: 97.4%, cell accuracy: 92.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.727113, G loss: 1.091205, D accuracy: 98.3%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7120, G loss: 1.1421\n",
      "[84/1762] D loss: 0.7396, G loss: 1.0825\n",
      "[164/1762] D loss: 0.7156, G loss: 1.1114\n",
      "[244/1762] D loss: 0.6796, G loss: 1.2628\n",
      "[324/1762] D loss: 0.6307, G loss: 1.3155\n",
      "[404/1762] D loss: 0.6473, G loss: 1.1773\n",
      "[484/1762] D loss: 0.7131, G loss: 1.2042\n",
      "[564/1762] D loss: 0.6778, G loss: 1.2515\n",
      "[644/1762] D loss: 0.6615, G loss: 1.1962\n",
      "[724/1762] D loss: 0.6715, G loss: 1.2028\n",
      "[804/1762] D loss: 0.5768, G loss: 1.3642\n",
      "[884/1762] D loss: 0.6230, G loss: 1.4385\n",
      "[964/1762] D loss: 0.6025, G loss: 1.2510\n",
      "[1044/1762] D loss: 0.5898, G loss: 1.4290\n",
      "[1124/1762] D loss: 0.6175, G loss: 1.3146\n",
      "[1204/1762] D loss: 0.5450, G loss: 1.4387\n",
      "[1284/1762] D loss: 0.6048, G loss: 1.3523\n",
      "[1364/1762] D loss: 0.6574, G loss: 1.4660\n",
      "[1444/1762] D loss: 0.5094, G loss: 1.5016\n",
      "[1524/1762] D loss: 0.6851, G loss: 1.3074\n",
      "[1604/1762] D loss: 0.6643, G loss: 1.2128\n",
      "[1684/1762] D loss: 0.6561, G loss: 1.2931\n",
      "[1762/1762] D loss: 0.6333, G loss: 1.3281\n",
      "train error: \n",
      " D loss: 0.651611, G loss: 1.373505, D accuracy: 97.4%, cell accuracy: 94.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.654261, G loss: 1.368667, D accuracy: 97.4%, cell accuracy: 94.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6193, G loss: 1.2725\n",
      "[84/1762] D loss: 0.5995, G loss: 1.2133\n",
      "[164/1762] D loss: 0.6616, G loss: 1.5290\n",
      "[244/1762] D loss: 0.5650, G loss: 1.3510\n",
      "[324/1762] D loss: 0.5140, G loss: 1.4884\n",
      "[404/1762] D loss: 0.5901, G loss: 1.5045\n",
      "[484/1762] D loss: 0.4772, G loss: 1.5423\n",
      "[564/1762] D loss: 0.5296, G loss: 1.4584\n",
      "[644/1762] D loss: 0.5128, G loss: 1.5499\n",
      "[724/1762] D loss: 0.5330, G loss: 1.5182\n",
      "[804/1762] D loss: 0.4707, G loss: 1.5784\n",
      "[884/1762] D loss: 0.5486, G loss: 1.4435\n",
      "[964/1762] D loss: 0.5752, G loss: 1.5598\n",
      "[1044/1762] D loss: 0.5322, G loss: 1.5042\n",
      "[1124/1762] D loss: 0.5842, G loss: 1.4450\n",
      "[1204/1762] D loss: 0.5858, G loss: 1.4865\n",
      "[1284/1762] D loss: 0.5979, G loss: 1.2673\n",
      "[1364/1762] D loss: 0.4427, G loss: 1.5782\n",
      "[1444/1762] D loss: 0.4411, G loss: 1.6037\n",
      "[1524/1762] D loss: 0.4849, G loss: 1.5845\n",
      "[1604/1762] D loss: 0.5008, G loss: 1.4140\n",
      "[1684/1762] D loss: 0.4191, G loss: 1.6414\n",
      "[1762/1762] D loss: 0.4696, G loss: 1.6239\n",
      "train error: \n",
      " D loss: 0.777883, G loss: 1.354502, D accuracy: 96.6%, cell accuracy: 94.3%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.775134, G loss: 1.365062, D accuracy: 97.3%, cell accuracy: 94.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4514, G loss: 1.7000\n",
      "[84/1762] D loss: 0.5088, G loss: 1.4819\n",
      "[164/1762] D loss: 0.4778, G loss: 1.5212\n",
      "[244/1762] D loss: 0.4667, G loss: 1.7516\n",
      "[324/1762] D loss: 0.4534, G loss: 1.4911\n",
      "[404/1762] D loss: 0.5236, G loss: 1.6589\n",
      "[484/1762] D loss: 0.5262, G loss: 1.4179\n",
      "[564/1762] D loss: 0.4363, G loss: 1.4977\n",
      "[644/1762] D loss: 0.4240, G loss: 1.6324\n",
      "[724/1762] D loss: 0.5666, G loss: 1.6967\n",
      "[804/1762] D loss: 0.4789, G loss: 1.6750\n",
      "[884/1762] D loss: 0.5437, G loss: 1.6601\n",
      "[964/1762] D loss: 0.4238, G loss: 1.8019\n",
      "[1044/1762] D loss: 0.4515, G loss: 1.5458\n",
      "[1124/1762] D loss: 0.5701, G loss: 1.3494\n",
      "[1204/1762] D loss: 0.5391, G loss: 1.3753\n",
      "[1284/1762] D loss: 0.5420, G loss: 1.4613\n",
      "[1364/1762] D loss: 0.4205, G loss: 1.5767\n",
      "[1444/1762] D loss: 0.3961, G loss: 1.8856\n",
      "[1524/1762] D loss: 0.4505, G loss: 1.6592\n",
      "[1604/1762] D loss: 0.4831, G loss: 1.4893\n",
      "[1684/1762] D loss: 0.4549, G loss: 1.5004\n",
      "[1762/1762] D loss: 0.4130, G loss: 1.7849\n",
      "train error: \n",
      " D loss: 0.584588, G loss: 1.619070, D accuracy: 99.0%, cell accuracy: 93.0%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.581071, G loss: 1.629589, D accuracy: 99.0%, cell accuracy: 92.8%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4783, G loss: 1.5358\n",
      "[84/1762] D loss: 0.5007, G loss: 1.5904\n",
      "[164/1762] D loss: 0.5045, G loss: 1.6402\n",
      "[244/1762] D loss: 0.5579, G loss: 1.6119\n",
      "[324/1762] D loss: 0.4647, G loss: 1.8419\n",
      "[404/1762] D loss: 0.5252, G loss: 1.4680\n",
      "[484/1762] D loss: 0.4992, G loss: 1.7850\n",
      "[564/1762] D loss: 0.5337, G loss: 1.6298\n",
      "[644/1762] D loss: 0.5091, G loss: 1.5413\n",
      "[724/1762] D loss: 0.4328, G loss: 1.8658\n",
      "[804/1762] D loss: 0.4808, G loss: 1.7009\n",
      "[884/1762] D loss: 0.5236, G loss: 1.5708\n",
      "[964/1762] D loss: 0.4379, G loss: 1.6593\n",
      "[1044/1762] D loss: 0.4823, G loss: 1.6574\n",
      "[1124/1762] D loss: 0.5309, G loss: 1.7986\n",
      "[1204/1762] D loss: 0.4588, G loss: 1.6659\n",
      "[1284/1762] D loss: 0.5896, G loss: 1.8075\n",
      "[1364/1762] D loss: 0.4918, G loss: 1.6661\n",
      "[1444/1762] D loss: 0.5118, G loss: 1.6574\n",
      "[1524/1762] D loss: 0.5016, G loss: 1.5334\n",
      "[1604/1762] D loss: 0.6284, G loss: 1.4139\n",
      "[1684/1762] D loss: 0.3923, G loss: 1.8090\n",
      "[1762/1762] D loss: 0.5303, G loss: 1.3549\n",
      "train error: \n",
      " D loss: 0.673185, G loss: 1.149135, D accuracy: 93.3%, cell accuracy: 97.2%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.669725, G loss: 1.151273, D accuracy: 91.8%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8439, G loss: 1.8809\n",
      "[84/1762] D loss: 0.5856, G loss: 1.5794\n",
      "[164/1762] D loss: 0.6784, G loss: 1.3065\n",
      "[244/1762] D loss: 0.5918, G loss: 1.4451\n",
      "[324/1762] D loss: 0.5856, G loss: 1.3875\n",
      "[404/1762] D loss: 0.6197, G loss: 1.2299\n",
      "[484/1762] D loss: 0.6539, G loss: 1.6368\n",
      "[564/1762] D loss: 1.1274, G loss: 2.2265\n",
      "[644/1762] D loss: 0.7184, G loss: 0.8599\n",
      "[724/1762] D loss: 1.2162, G loss: 2.1168\n",
      "[804/1762] D loss: 1.2870, G loss: 2.4430\n",
      "[884/1762] D loss: 0.6870, G loss: 1.5501\n",
      "[964/1762] D loss: 1.1092, G loss: 0.3508\n",
      "[1044/1762] D loss: 1.5004, G loss: 1.6839\n",
      "[1124/1762] D loss: 0.8316, G loss: 1.4079\n",
      "[1204/1762] D loss: 1.1063, G loss: 0.7535\n",
      "[1284/1762] D loss: 0.8735, G loss: 1.5770\n",
      "[1364/1762] D loss: 1.2059, G loss: 1.5638\n",
      "[1444/1762] D loss: 0.7644, G loss: 1.6742\n",
      "[1524/1762] D loss: 0.7032, G loss: 1.0863\n",
      "[1604/1762] D loss: 1.0047, G loss: 1.7121\n",
      "[1684/1762] D loss: 0.8070, G loss: 1.5084\n",
      "[1762/1762] D loss: 1.0185, G loss: 1.9097\n",
      "train error: \n",
      " D loss: 1.264463, G loss: 2.258398, D accuracy: 53.6%, cell accuracy: 98.4%, board accuracy: 4.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284404, G loss: 2.328535, D accuracy: 53.9%, cell accuracy: 98.3%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9080, G loss: 0.4526\n",
      "[84/1762] D loss: 0.9645, G loss: 0.9642\n",
      "[164/1762] D loss: 0.9373, G loss: 0.6554\n",
      "[244/1762] D loss: 0.9203, G loss: 0.4721\n",
      "[324/1762] D loss: 0.8944, G loss: 0.6181\n",
      "[404/1762] D loss: 0.9461, G loss: 1.6806\n",
      "[484/1762] D loss: 0.8347, G loss: 0.8237\n",
      "[564/1762] D loss: 0.8941, G loss: 1.8176\n",
      "[644/1762] D loss: 0.9693, G loss: 0.4720\n",
      "[724/1762] D loss: 1.7494, G loss: 0.9495\n",
      "[804/1762] D loss: 0.9644, G loss: 0.9995\n",
      "[884/1762] D loss: 0.9244, G loss: 1.4697\n",
      "[964/1762] D loss: 1.0651, G loss: 1.7489\n",
      "[1044/1762] D loss: 0.8674, G loss: 1.0377\n",
      "[1124/1762] D loss: 0.8321, G loss: 1.2423\n",
      "[1204/1762] D loss: 1.0754, G loss: 1.7205\n",
      "[1284/1762] D loss: 0.9719, G loss: 1.5340\n",
      "[1364/1762] D loss: 0.9374, G loss: 1.4270\n",
      "[1444/1762] D loss: 1.2488, G loss: 0.4055\n",
      "[1524/1762] D loss: 1.1046, G loss: 0.9097\n",
      "[1604/1762] D loss: 1.4340, G loss: 0.4492\n",
      "[1684/1762] D loss: 1.0273, G loss: 0.6455\n",
      "[1762/1762] D loss: 0.8989, G loss: 0.8970\n",
      "train error: \n",
      " D loss: 1.148820, G loss: 0.596726, D accuracy: 63.5%, cell accuracy: 99.2%, board accuracy: 20.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.131014, G loss: 0.616377, D accuracy: 64.5%, cell accuracy: 99.2%, board accuracy: 20.7% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7278, G loss: 1.6759\n",
      "[84/1762] D loss: 1.2379, G loss: 0.4959\n",
      "[164/1762] D loss: 0.9293, G loss: 0.8848\n",
      "[244/1762] D loss: 0.9826, G loss: 0.8740\n",
      "[324/1762] D loss: 0.9912, G loss: 2.0577\n",
      "[404/1762] D loss: 1.3023, G loss: 0.4441\n",
      "[484/1762] D loss: 0.9816, G loss: 0.9080\n",
      "[564/1762] D loss: 0.9247, G loss: 1.9464\n",
      "[644/1762] D loss: 1.2529, G loss: 1.3603\n",
      "[724/1762] D loss: 1.1292, G loss: 0.6569\n",
      "[804/1762] D loss: 1.2404, G loss: 1.3966\n",
      "[884/1762] D loss: 1.0592, G loss: 1.2610\n",
      "[964/1762] D loss: 1.4222, G loss: 1.4312\n",
      "[1044/1762] D loss: 1.1311, G loss: 1.3451\n",
      "[1124/1762] D loss: 0.9281, G loss: 1.3888\n",
      "[1204/1762] D loss: 0.9084, G loss: 1.0691\n",
      "[1284/1762] D loss: 1.2544, G loss: 1.2591\n",
      "[1364/1762] D loss: 1.1379, G loss: 1.0423\n",
      "[1444/1762] D loss: 0.9891, G loss: 1.2158\n",
      "[1524/1762] D loss: 0.8501, G loss: 1.1553\n",
      "[1604/1762] D loss: 1.1584, G loss: 0.7094\n",
      "[1684/1762] D loss: 1.1921, G loss: 0.7057\n",
      "[1762/1762] D loss: 0.7938, G loss: 2.4591\n",
      "train error: \n",
      " D loss: 1.380062, G loss: 1.657041, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 62.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397384, G loss: 1.681703, D accuracy: 54.1%, cell accuracy: 99.5%, board accuracy: 59.3% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4144, G loss: 0.3668\n",
      "[84/1762] D loss: 1.0125, G loss: 1.0166\n",
      "[164/1762] D loss: 1.0787, G loss: 1.2318\n",
      "[244/1762] D loss: 1.1336, G loss: 1.1280\n",
      "[324/1762] D loss: 1.2828, G loss: 1.4150\n",
      "[404/1762] D loss: 0.9935, G loss: 1.1729\n",
      "[484/1762] D loss: 1.2451, G loss: 0.7719\n",
      "[564/1762] D loss: 1.1934, G loss: 1.0490\n",
      "[644/1762] D loss: 1.4524, G loss: 1.3111\n",
      "[724/1762] D loss: 0.9989, G loss: 1.1797\n",
      "[804/1762] D loss: 1.0303, G loss: 1.2468\n",
      "[884/1762] D loss: 0.9394, G loss: 1.2772\n",
      "[964/1762] D loss: 1.1850, G loss: 1.1081\n",
      "[1044/1762] D loss: 0.8776, G loss: 1.0403\n",
      "[1124/1762] D loss: 1.6872, G loss: 1.3515\n",
      "[1204/1762] D loss: 1.0816, G loss: 1.3197\n",
      "[1284/1762] D loss: 0.9044, G loss: 1.1373\n",
      "[1364/1762] D loss: 1.0337, G loss: 1.0152\n",
      "[1444/1762] D loss: 1.5916, G loss: 1.3496\n",
      "[1524/1762] D loss: 1.1598, G loss: 1.0170\n",
      "[1604/1762] D loss: 1.1931, G loss: 0.6078\n",
      "[1684/1762] D loss: 1.1856, G loss: 0.8905\n",
      "[1762/1762] D loss: 1.2434, G loss: 0.2918\n",
      "train error: \n",
      " D loss: 1.518621, G loss: 0.356819, D accuracy: 51.4%, cell accuracy: 99.6%, board accuracy: 74.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.498814, G loss: 0.369033, D accuracy: 52.2%, cell accuracy: 99.6%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4215, G loss: 1.0488\n",
      "[84/1762] D loss: 1.2775, G loss: 0.8061\n",
      "[164/1762] D loss: 1.2755, G loss: 1.0110\n",
      "[244/1762] D loss: 1.2163, G loss: 0.9585\n",
      "[324/1762] D loss: 1.3119, G loss: 0.5716\n",
      "[404/1762] D loss: 1.0687, G loss: 0.7861\n",
      "[484/1762] D loss: 1.2373, G loss: 1.0135\n",
      "[564/1762] D loss: 0.9396, G loss: 1.2199\n",
      "[644/1762] D loss: 1.0813, G loss: 1.2103\n",
      "[724/1762] D loss: 1.1988, G loss: 0.6072\n",
      "[804/1762] D loss: 1.3455, G loss: 1.1294\n",
      "[884/1762] D loss: 1.3633, G loss: 1.5321\n",
      "[964/1762] D loss: 1.1086, G loss: 0.6866\n",
      "[1044/1762] D loss: 1.0458, G loss: 1.0733\n",
      "[1124/1762] D loss: 1.1794, G loss: 0.8081\n",
      "[1204/1762] D loss: 1.2697, G loss: 0.9730\n",
      "[1284/1762] D loss: 1.0888, G loss: 1.6645\n",
      "[1364/1762] D loss: 1.2796, G loss: 0.7244\n",
      "[1444/1762] D loss: 1.2782, G loss: 0.8124\n",
      "[1524/1762] D loss: 1.3558, G loss: 0.4965\n",
      "[1604/1762] D loss: 1.2550, G loss: 1.2452\n",
      "[1684/1762] D loss: 0.9372, G loss: 1.5864\n",
      "[1762/1762] D loss: 1.5072, G loss: 1.2662\n",
      "train error: \n",
      " D loss: 1.545400, G loss: 1.656709, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 76.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.553628, G loss: 1.687701, D accuracy: 50.8%, cell accuracy: 99.6%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6327, G loss: 0.5164\n",
      "[84/1762] D loss: 1.2067, G loss: 1.1450\n",
      "[164/1762] D loss: 1.1079, G loss: 0.8618\n",
      "[244/1762] D loss: 1.1103, G loss: 1.0183\n",
      "[324/1762] D loss: 1.1720, G loss: 1.1045\n",
      "[404/1762] D loss: 1.0112, G loss: 0.9713\n",
      "[484/1762] D loss: 1.4796, G loss: 1.4764\n",
      "[564/1762] D loss: 1.1983, G loss: 0.3508\n",
      "[644/1762] D loss: 1.2787, G loss: 0.6853\n",
      "[724/1762] D loss: 1.3580, G loss: 1.1298\n",
      "[804/1762] D loss: 1.3016, G loss: 0.4380\n",
      "[884/1762] D loss: 1.2166, G loss: 0.7934\n",
      "[964/1762] D loss: 1.4259, G loss: 0.5020\n",
      "[1044/1762] D loss: 1.4307, G loss: 0.3198\n",
      "[1124/1762] D loss: 1.2567, G loss: 0.6322\n",
      "[1204/1762] D loss: 1.2640, G loss: 0.6814\n",
      "[1284/1762] D loss: 1.2941, G loss: 0.7251\n",
      "[1364/1762] D loss: 1.1839, G loss: 0.7177\n",
      "[1444/1762] D loss: 1.2955, G loss: 0.8575\n",
      "[1524/1762] D loss: 1.2350, G loss: 0.8469\n",
      "[1604/1762] D loss: 1.3164, G loss: 0.8213\n",
      "[1684/1762] D loss: 1.2159, G loss: 0.9179\n",
      "[1762/1762] D loss: 1.2878, G loss: 0.8465\n",
      "train error: \n",
      " D loss: 1.265093, G loss: 0.965355, D accuracy: 62.7%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264912, G loss: 0.991824, D accuracy: 61.8%, cell accuracy: 99.6%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2386, G loss: 0.5235\n",
      "[84/1762] D loss: 1.3579, G loss: 0.9999\n",
      "[164/1762] D loss: 0.8368, G loss: 1.3719\n",
      "[244/1762] D loss: 1.1732, G loss: 0.8633\n",
      "[324/1762] D loss: 1.1479, G loss: 0.8590\n",
      "[404/1762] D loss: 1.3141, G loss: 1.0405\n",
      "[484/1762] D loss: 1.4001, G loss: 0.6636\n",
      "[564/1762] D loss: 1.2917, G loss: 0.9885\n",
      "[644/1762] D loss: 1.2706, G loss: 0.9163\n",
      "[724/1762] D loss: 1.1402, G loss: 0.7111\n",
      "[804/1762] D loss: 0.9030, G loss: 1.1093\n",
      "[884/1762] D loss: 1.3377, G loss: 0.5302\n",
      "[964/1762] D loss: 1.1164, G loss: 1.1456\n",
      "[1044/1762] D loss: 1.0462, G loss: 1.2522\n",
      "[1124/1762] D loss: 1.2220, G loss: 1.1265\n",
      "[1204/1762] D loss: 1.2625, G loss: 0.7636\n",
      "[1284/1762] D loss: 1.2273, G loss: 0.8320\n",
      "[1364/1762] D loss: 1.2121, G loss: 0.7212\n",
      "[1444/1762] D loss: 1.0826, G loss: 0.7715\n",
      "[1524/1762] D loss: 1.0003, G loss: 0.9490\n",
      "[1604/1762] D loss: 1.0438, G loss: 1.2220\n",
      "[1684/1762] D loss: 0.8306, G loss: 1.3189\n",
      "[1762/1762] D loss: 1.2532, G loss: 1.1158\n",
      "train error: \n",
      " D loss: 1.279193, G loss: 0.983304, D accuracy: 60.7%, cell accuracy: 99.7%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274990, G loss: 1.009206, D accuracy: 60.8%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1249, G loss: 0.7887\n",
      "[84/1762] D loss: 1.3447, G loss: 0.5899\n",
      "[164/1762] D loss: 1.2637, G loss: 0.8531\n",
      "[244/1762] D loss: 1.1440, G loss: 0.8588\n",
      "[324/1762] D loss: 1.3361, G loss: 0.6210\n",
      "[404/1762] D loss: 1.1011, G loss: 0.9482\n",
      "[484/1762] D loss: 0.9466, G loss: 1.1200\n",
      "[564/1762] D loss: 1.6653, G loss: 1.3459\n",
      "[644/1762] D loss: 1.3291, G loss: 0.5556\n",
      "[724/1762] D loss: 1.1401, G loss: 0.9763\n",
      "[804/1762] D loss: 1.0442, G loss: 1.0577\n",
      "[884/1762] D loss: 1.3583, G loss: 0.9116\n",
      "[964/1762] D loss: 1.3360, G loss: 0.6931\n",
      "[1044/1762] D loss: 1.0544, G loss: 1.1293\n",
      "[1124/1762] D loss: 1.3050, G loss: 0.8353\n",
      "[1204/1762] D loss: 1.2161, G loss: 1.1678\n",
      "[1284/1762] D loss: 1.1833, G loss: 0.9071\n",
      "[1364/1762] D loss: 1.1422, G loss: 1.0622\n",
      "[1444/1762] D loss: 1.4751, G loss: 1.0873\n",
      "[1524/1762] D loss: 0.9811, G loss: 1.1015\n",
      "[1604/1762] D loss: 1.2029, G loss: 0.8156\n",
      "[1684/1762] D loss: 1.3530, G loss: 0.7623\n",
      "[1762/1762] D loss: 1.4263, G loss: 0.3979\n",
      "train error: \n",
      " D loss: 1.363795, G loss: 0.506225, D accuracy: 56.3%, cell accuracy: 99.7%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345061, G loss: 0.526796, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5184, G loss: 1.0574\n",
      "[84/1762] D loss: 1.3655, G loss: 1.0841\n",
      "[164/1762] D loss: 1.3470, G loss: 0.5096\n",
      "[244/1762] D loss: 1.3566, G loss: 0.8403\n",
      "[324/1762] D loss: 1.4342, G loss: 0.9049\n",
      "[404/1762] D loss: 1.1386, G loss: 1.0064\n",
      "[484/1762] D loss: 1.1754, G loss: 0.9613\n",
      "[564/1762] D loss: 0.8780, G loss: 1.2954\n",
      "[644/1762] D loss: 1.2313, G loss: 0.6974\n",
      "[724/1762] D loss: 1.0097, G loss: 0.9794\n",
      "[804/1762] D loss: 1.2235, G loss: 0.6400\n",
      "[884/1762] D loss: 1.0971, G loss: 0.7932\n",
      "[964/1762] D loss: 0.9271, G loss: 1.1096\n",
      "[1044/1762] D loss: 1.2167, G loss: 1.1039\n",
      "[1124/1762] D loss: 1.5292, G loss: 0.3917\n",
      "[1204/1762] D loss: 1.1229, G loss: 1.1817\n",
      "[1284/1762] D loss: 1.3930, G loss: 0.5357\n",
      "[1364/1762] D loss: 1.2202, G loss: 0.9905\n",
      "[1444/1762] D loss: 1.1426, G loss: 0.8149\n",
      "[1524/1762] D loss: 1.3251, G loss: 0.8137\n",
      "[1604/1762] D loss: 1.4667, G loss: 0.4025\n",
      "[1684/1762] D loss: 1.1732, G loss: 1.3019\n",
      "[1762/1762] D loss: 1.1723, G loss: 1.4784\n",
      "train error: \n",
      " D loss: 1.391706, G loss: 1.254254, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390601, G loss: 1.286367, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1616, G loss: 0.9739\n",
      "[84/1762] D loss: 1.3421, G loss: 0.8026\n",
      "[164/1762] D loss: 1.2508, G loss: 1.0520\n",
      "[244/1762] D loss: 1.3131, G loss: 0.7065\n",
      "[324/1762] D loss: 1.2217, G loss: 0.6971\n",
      "[404/1762] D loss: 1.3024, G loss: 0.7602\n",
      "[484/1762] D loss: 0.7162, G loss: 1.1432\n",
      "[564/1762] D loss: 1.2921, G loss: 0.5927\n",
      "[644/1762] D loss: 1.3435, G loss: 0.8564\n",
      "[724/1762] D loss: 1.1707, G loss: 0.7375\n",
      "[804/1762] D loss: 1.0211, G loss: 1.0073\n",
      "[884/1762] D loss: 1.3400, G loss: 0.6953\n",
      "[964/1762] D loss: 1.1649, G loss: 1.0152\n",
      "[1044/1762] D loss: 1.0890, G loss: 1.1143\n",
      "[1124/1762] D loss: 1.3650, G loss: 0.5263\n",
      "[1204/1762] D loss: 1.2270, G loss: 0.8106\n",
      "[1284/1762] D loss: 1.3419, G loss: 0.6894\n",
      "[1364/1762] D loss: 1.1972, G loss: 0.9379\n",
      "[1444/1762] D loss: 1.1093, G loss: 1.0053\n",
      "[1524/1762] D loss: 1.0538, G loss: 1.2300\n",
      "[1604/1762] D loss: 1.2966, G loss: 0.6071\n",
      "[1684/1762] D loss: 1.3406, G loss: 0.6238\n",
      "[1762/1762] D loss: 1.3789, G loss: 0.8906\n",
      "train error: \n",
      " D loss: 1.347333, G loss: 1.158733, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344451, G loss: 1.193778, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4203, G loss: 0.5657\n",
      "[84/1762] D loss: 1.3052, G loss: 1.0673\n",
      "[164/1762] D loss: 1.3664, G loss: 0.7407\n",
      "[244/1762] D loss: 0.9719, G loss: 1.0417\n",
      "[324/1762] D loss: 1.1876, G loss: 1.2101\n",
      "[404/1762] D loss: 1.3360, G loss: 0.9069\n",
      "[484/1762] D loss: 1.1175, G loss: 0.7433\n",
      "[564/1762] D loss: 0.7330, G loss: 1.7438\n",
      "[644/1762] D loss: 1.3523, G loss: 0.6354\n",
      "[724/1762] D loss: 1.3159, G loss: 0.6476\n",
      "[804/1762] D loss: 1.3733, G loss: 0.4669\n",
      "[884/1762] D loss: 1.3618, G loss: 0.5171\n",
      "[964/1762] D loss: 1.3038, G loss: 0.6808\n",
      "[1044/1762] D loss: 0.7235, G loss: 1.4932\n",
      "[1124/1762] D loss: 0.9346, G loss: 1.0941\n",
      "[1204/1762] D loss: 1.3323, G loss: 0.4485\n",
      "[1284/1762] D loss: 1.4305, G loss: 0.3096\n",
      "[1364/1762] D loss: 1.2907, G loss: 0.9246\n",
      "[1444/1762] D loss: 0.9125, G loss: 1.2747\n",
      "[1524/1762] D loss: 1.0883, G loss: 0.9291\n",
      "[1604/1762] D loss: 1.1039, G loss: 0.7740\n",
      "[1684/1762] D loss: 1.2446, G loss: 0.8433\n",
      "[1762/1762] D loss: 1.2062, G loss: 1.0370\n",
      "train error: \n",
      " D loss: 1.330093, G loss: 1.058136, D accuracy: 56.5%, cell accuracy: 99.6%, board accuracy: 75.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328948, G loss: 1.090818, D accuracy: 57.3%, cell accuracy: 99.6%, board accuracy: 71.4% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3763, G loss: 0.6839\n",
      "[84/1762] D loss: 1.3776, G loss: 0.5836\n",
      "[164/1762] D loss: 1.3017, G loss: 0.7539\n",
      "[244/1762] D loss: 1.4972, G loss: 0.6156\n",
      "[324/1762] D loss: 1.1858, G loss: 0.7376\n",
      "[404/1762] D loss: 1.2957, G loss: 0.9960\n",
      "[484/1762] D loss: 1.3560, G loss: 0.6673\n",
      "[564/1762] D loss: 1.2360, G loss: 0.8475\n",
      "[644/1762] D loss: 1.2337, G loss: 0.6695\n",
      "[724/1762] D loss: 1.3858, G loss: 0.6667\n",
      "[804/1762] D loss: 1.3291, G loss: 0.8201\n",
      "[884/1762] D loss: 1.3412, G loss: 0.8495\n",
      "[964/1762] D loss: 1.1594, G loss: 0.8378\n",
      "[1044/1762] D loss: 1.4188, G loss: 0.5210\n",
      "[1124/1762] D loss: 1.1735, G loss: 0.8567\n",
      "[1204/1762] D loss: 1.4466, G loss: 0.9712\n",
      "[1284/1762] D loss: 1.5882, G loss: 1.2848\n",
      "[1364/1762] D loss: 1.3304, G loss: 0.9048\n",
      "[1444/1762] D loss: 1.2240, G loss: 0.6378\n",
      "[1524/1762] D loss: 1.2485, G loss: 0.7083\n",
      "[1604/1762] D loss: 1.1205, G loss: 1.0056\n",
      "[1684/1762] D loss: 1.0934, G loss: 0.8208\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6776\n",
      "train error: \n",
      " D loss: 1.273668, G loss: 0.753329, D accuracy: 62.8%, cell accuracy: 99.7%, board accuracy: 78.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263575, G loss: 0.779306, D accuracy: 63.3%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2671, G loss: 0.7840\n",
      "[84/1762] D loss: 1.2475, G loss: 0.5668\n",
      "[164/1762] D loss: 1.3381, G loss: 0.8034\n",
      "[244/1762] D loss: 1.1800, G loss: 1.0560\n",
      "[324/1762] D loss: 1.3763, G loss: 0.9486\n",
      "[404/1762] D loss: 1.2028, G loss: 0.8688\n",
      "[484/1762] D loss: 0.9830, G loss: 0.8770\n",
      "[564/1762] D loss: 1.3449, G loss: 0.5755\n",
      "[644/1762] D loss: 0.8991, G loss: 1.1995\n",
      "[724/1762] D loss: 1.4090, G loss: 0.9834\n",
      "[804/1762] D loss: 1.3697, G loss: 0.7759\n",
      "[884/1762] D loss: 1.2623, G loss: 0.8119\n",
      "[964/1762] D loss: 1.1401, G loss: 1.0329\n",
      "[1044/1762] D loss: 1.2966, G loss: 0.7888\n",
      "[1124/1762] D loss: 1.0195, G loss: 1.1293\n",
      "[1204/1762] D loss: 1.3821, G loss: 0.7587\n",
      "[1284/1762] D loss: 1.3734, G loss: 0.9366\n",
      "[1364/1762] D loss: 1.3126, G loss: 0.5070\n",
      "[1444/1762] D loss: 1.1516, G loss: 0.8543\n",
      "[1524/1762] D loss: 1.3480, G loss: 0.6343\n",
      "[1604/1762] D loss: 1.4672, G loss: 0.5790\n",
      "[1684/1762] D loss: 1.4405, G loss: 0.8090\n",
      "[1762/1762] D loss: 1.5036, G loss: 1.0019\n",
      "train error: \n",
      " D loss: 1.484271, G loss: 1.367574, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.482795, G loss: 1.405588, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5294, G loss: 0.6441\n",
      "[84/1762] D loss: 1.0319, G loss: 1.2952\n",
      "[164/1762] D loss: 1.1812, G loss: 0.6068\n",
      "[244/1762] D loss: 1.3276, G loss: 0.8119\n",
      "[324/1762] D loss: 1.2388, G loss: 0.9450\n",
      "[404/1762] D loss: 1.4442, G loss: 0.7194\n",
      "[484/1762] D loss: 1.1396, G loss: 0.9362\n",
      "[564/1762] D loss: 1.3804, G loss: 0.6526\n",
      "[644/1762] D loss: 1.1958, G loss: 0.8573\n",
      "[724/1762] D loss: 1.0270, G loss: 0.9377\n",
      "[804/1762] D loss: 1.2796, G loss: 0.7229\n",
      "[884/1762] D loss: 1.3295, G loss: 0.8139\n",
      "[964/1762] D loss: 1.3376, G loss: 0.7553\n",
      "[1044/1762] D loss: 1.2247, G loss: 0.9155\n",
      "[1124/1762] D loss: 1.3715, G loss: 0.5422\n",
      "[1204/1762] D loss: 1.3638, G loss: 0.7743\n",
      "[1284/1762] D loss: 1.4909, G loss: 1.2857\n",
      "[1364/1762] D loss: 1.2303, G loss: 0.5944\n",
      "[1444/1762] D loss: 1.1626, G loss: 1.0664\n",
      "[1524/1762] D loss: 1.0721, G loss: 0.9348\n",
      "[1604/1762] D loss: 1.2670, G loss: 0.8880\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.5673\n",
      "[1762/1762] D loss: 1.4621, G loss: 0.3841\n",
      "train error: \n",
      " D loss: 1.357659, G loss: 0.555431, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350851, G loss: 0.565779, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0858, G loss: 1.1278\n",
      "[84/1762] D loss: 1.0576, G loss: 1.1451\n",
      "[164/1762] D loss: 1.4035, G loss: 0.8767\n",
      "[244/1762] D loss: 1.3124, G loss: 0.5437\n",
      "[324/1762] D loss: 1.3376, G loss: 0.7233\n",
      "[404/1762] D loss: 0.7630, G loss: 1.2962\n",
      "[484/1762] D loss: 0.9589, G loss: 1.0572\n",
      "[564/1762] D loss: 1.3518, G loss: 0.7435\n",
      "[644/1762] D loss: 0.9619, G loss: 1.0695\n",
      "[724/1762] D loss: 1.0375, G loss: 1.1635\n",
      "[804/1762] D loss: 1.1317, G loss: 0.9782\n",
      "[884/1762] D loss: 1.3765, G loss: 0.6669\n",
      "[964/1762] D loss: 1.3294, G loss: 0.8096\n",
      "[1044/1762] D loss: 1.1798, G loss: 0.7510\n",
      "[1124/1762] D loss: 1.3442, G loss: 0.6119\n",
      "[1204/1762] D loss: 1.7069, G loss: 0.6388\n",
      "[1284/1762] D loss: 1.3179, G loss: 0.7369\n",
      "[1364/1762] D loss: 1.3831, G loss: 0.6579\n",
      "[1444/1762] D loss: 1.3456, G loss: 0.8137\n",
      "[1524/1762] D loss: 1.4784, G loss: 0.6195\n",
      "[1604/1762] D loss: 1.3065, G loss: 0.7835\n",
      "[1684/1762] D loss: 1.2954, G loss: 0.7092\n",
      "[1762/1762] D loss: 1.4233, G loss: 0.6102\n",
      "train error: \n",
      " D loss: 1.373054, G loss: 0.519362, D accuracy: 55.6%, cell accuracy: 99.5%, board accuracy: 72.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368912, G loss: 0.528894, D accuracy: 56.4%, cell accuracy: 99.5%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927, G loss: 1.0887\n",
      "[84/1762] D loss: 1.4108, G loss: 0.9615\n",
      "[164/1762] D loss: 0.9737, G loss: 1.1292\n",
      "[244/1762] D loss: 1.3149, G loss: 0.7936\n",
      "[324/1762] D loss: 1.0643, G loss: 0.9318\n",
      "[404/1762] D loss: 1.5097, G loss: 0.6249\n",
      "[484/1762] D loss: 1.3573, G loss: 0.7065\n",
      "[564/1762] D loss: 1.4556, G loss: 1.0088\n",
      "[644/1762] D loss: 1.2352, G loss: 0.8683\n",
      "[724/1762] D loss: 1.3691, G loss: 0.7263\n",
      "[804/1762] D loss: 1.1287, G loss: 0.9501\n",
      "[884/1762] D loss: 1.3403, G loss: 0.6317\n",
      "[964/1762] D loss: 1.4351, G loss: 1.0377\n",
      "[1044/1762] D loss: 1.4027, G loss: 0.6363\n",
      "[1124/1762] D loss: 1.2482, G loss: 0.8956\n",
      "[1204/1762] D loss: 1.1593, G loss: 0.8549\n",
      "[1284/1762] D loss: 0.9717, G loss: 1.0763\n",
      "[1364/1762] D loss: 1.3502, G loss: 0.6097\n",
      "[1444/1762] D loss: 1.3367, G loss: 0.8865\n",
      "[1524/1762] D loss: 1.3219, G loss: 0.7214\n",
      "[1604/1762] D loss: 1.2929, G loss: 0.7687\n",
      "[1684/1762] D loss: 1.3652, G loss: 0.6821\n",
      "[1762/1762] D loss: 1.3836, G loss: 0.9039\n",
      "train error: \n",
      " D loss: 1.325065, G loss: 0.904777, D accuracy: 58.0%, cell accuracy: 99.6%, board accuracy: 75.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331775, G loss: 0.921317, D accuracy: 56.8%, cell accuracy: 99.5%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3207, G loss: 0.5474\n",
      "[84/1762] D loss: 1.2901, G loss: 0.7868\n",
      "[164/1762] D loss: 1.3095, G loss: 0.6699\n",
      "[244/1762] D loss: 1.4045, G loss: 0.7574\n",
      "[324/1762] D loss: 1.4800, G loss: 0.7358\n",
      "[404/1762] D loss: 1.3395, G loss: 0.7236\n",
      "[484/1762] D loss: 1.4204, G loss: 0.5193\n",
      "[564/1762] D loss: 1.4086, G loss: 0.8173\n",
      "[644/1762] D loss: 1.4866, G loss: 0.5482\n",
      "[724/1762] D loss: 1.1635, G loss: 0.8045\n",
      "[804/1762] D loss: 1.0922, G loss: 0.8456\n",
      "[884/1762] D loss: 1.2252, G loss: 0.7053\n",
      "[964/1762] D loss: 1.3284, G loss: 0.7496\n",
      "[1044/1762] D loss: 1.1096, G loss: 1.0644\n",
      "[1124/1762] D loss: 1.3633, G loss: 0.6962\n",
      "[1204/1762] D loss: 1.2902, G loss: 0.6705\n",
      "[1284/1762] D loss: 1.4112, G loss: 0.4711\n",
      "[1364/1762] D loss: 1.3644, G loss: 0.7055\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.5983\n",
      "[1524/1762] D loss: 1.5240, G loss: 0.9998\n",
      "[1604/1762] D loss: 1.2063, G loss: 0.7073\n",
      "[1684/1762] D loss: 1.4215, G loss: 0.6546\n",
      "[1762/1762] D loss: 1.0266, G loss: 0.9946\n",
      "train error: \n",
      " D loss: 1.311776, G loss: 0.746754, D accuracy: 60.4%, cell accuracy: 99.4%, board accuracy: 70.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306161, G loss: 0.764645, D accuracy: 59.5%, cell accuracy: 99.4%, board accuracy: 68.4% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3830, G loss: 0.6576\n",
      "[84/1762] D loss: 1.2214, G loss: 1.0187\n",
      "[164/1762] D loss: 1.3320, G loss: 0.7511\n",
      "[244/1762] D loss: 1.4758, G loss: 0.3040\n",
      "[324/1762] D loss: 1.2249, G loss: 0.9192\n",
      "[404/1762] D loss: 1.4342, G loss: 0.6023\n",
      "[484/1762] D loss: 1.2968, G loss: 0.6511\n",
      "[564/1762] D loss: 1.3221, G loss: 0.7117\n",
      "[644/1762] D loss: 1.3083, G loss: 0.7795\n",
      "[724/1762] D loss: 1.3595, G loss: 0.6928\n",
      "[804/1762] D loss: 1.3801, G loss: 0.6403\n",
      "[884/1762] D loss: 1.1979, G loss: 0.8784\n",
      "[964/1762] D loss: 1.3901, G loss: 0.6820\n",
      "[1044/1762] D loss: 1.3712, G loss: 0.5830\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.8419\n",
      "[1204/1762] D loss: 1.2259, G loss: 1.1732\n",
      "[1284/1762] D loss: 1.3098, G loss: 0.6458\n",
      "[1364/1762] D loss: 1.5497, G loss: 0.9270\n",
      "[1444/1762] D loss: 1.4377, G loss: 0.6348\n",
      "[1524/1762] D loss: 1.3434, G loss: 0.7132\n",
      "[1604/1762] D loss: 1.0628, G loss: 0.9559\n",
      "[1684/1762] D loss: 1.3171, G loss: 0.8245\n",
      "[1762/1762] D loss: 1.3633, G loss: 0.7340\n",
      "train error: \n",
      " D loss: 1.351086, G loss: 0.957019, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354257, G loss: 0.982538, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3041, G loss: 0.7094\n",
      "[84/1762] D loss: 1.1504, G loss: 0.9214\n",
      "[164/1762] D loss: 1.1499, G loss: 0.9634\n",
      "[244/1762] D loss: 1.3776, G loss: 0.6973\n",
      "[324/1762] D loss: 1.2743, G loss: 1.0182\n",
      "[404/1762] D loss: 1.2959, G loss: 0.5445\n",
      "[484/1762] D loss: 1.2930, G loss: 0.7082\n",
      "[564/1762] D loss: 1.4297, G loss: 0.3750\n",
      "[644/1762] D loss: 1.3759, G loss: 0.7276\n",
      "[724/1762] D loss: 1.3467, G loss: 0.8120\n",
      "[804/1762] D loss: 1.1820, G loss: 0.8061\n",
      "[884/1762] D loss: 1.4337, G loss: 0.9951\n",
      "[964/1762] D loss: 1.1757, G loss: 0.8814\n",
      "[1044/1762] D loss: 1.1869, G loss: 1.0448\n",
      "[1124/1762] D loss: 1.3663, G loss: 0.7253\n",
      "[1204/1762] D loss: 1.3823, G loss: 0.7421\n",
      "[1284/1762] D loss: 1.4176, G loss: 0.5539\n",
      "[1364/1762] D loss: 1.4499, G loss: 0.6022\n",
      "[1444/1762] D loss: 1.3776, G loss: 0.8123\n",
      "[1524/1762] D loss: 1.0960, G loss: 1.0389\n",
      "[1604/1762] D loss: 1.2924, G loss: 0.8439\n",
      "[1684/1762] D loss: 1.4146, G loss: 0.7605\n",
      "[1762/1762] D loss: 1.3614, G loss: 0.7571\n",
      "train error: \n",
      " D loss: 1.320393, G loss: 0.822739, D accuracy: 58.8%, cell accuracy: 99.7%, board accuracy: 79.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320782, G loss: 0.842093, D accuracy: 58.5%, cell accuracy: 99.6%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7763, G loss: 1.2510\n",
      "[84/1762] D loss: 1.4006, G loss: 0.7801\n",
      "[164/1762] D loss: 1.4039, G loss: 0.5325\n",
      "[244/1762] D loss: 1.3386, G loss: 0.7709\n",
      "[324/1762] D loss: 1.3971, G loss: 0.8434\n",
      "[404/1762] D loss: 1.3728, G loss: 0.7650\n",
      "[484/1762] D loss: 1.4057, G loss: 0.6364\n",
      "[564/1762] D loss: 1.3503, G loss: 0.6142\n",
      "[644/1762] D loss: 1.3226, G loss: 0.7500\n",
      "[724/1762] D loss: 1.3696, G loss: 0.7097\n",
      "[804/1762] D loss: 1.3412, G loss: 0.5118\n",
      "[884/1762] D loss: 1.3718, G loss: 0.7245\n",
      "[964/1762] D loss: 1.1205, G loss: 0.9048\n",
      "[1044/1762] D loss: 1.0413, G loss: 0.9922\n",
      "[1124/1762] D loss: 1.1734, G loss: 0.7959\n",
      "[1204/1762] D loss: 1.4864, G loss: 0.5479\n",
      "[1284/1762] D loss: 1.3808, G loss: 0.6453\n",
      "[1364/1762] D loss: 1.2988, G loss: 0.7118\n",
      "[1444/1762] D loss: 1.3707, G loss: 0.7139\n",
      "[1524/1762] D loss: 1.2943, G loss: 0.9357\n",
      "[1604/1762] D loss: 1.3764, G loss: 0.7072\n",
      "[1684/1762] D loss: 1.2641, G loss: 0.6698\n",
      "[1762/1762] D loss: 1.4679, G loss: 0.7765\n",
      "train error: \n",
      " D loss: 1.342375, G loss: 0.918474, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352860, G loss: 0.933805, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2569, G loss: 0.6681\n",
      "[84/1762] D loss: 1.4084, G loss: 0.4981\n",
      "[164/1762] D loss: 1.4487, G loss: 0.5263\n",
      "[244/1762] D loss: 1.2442, G loss: 0.6916\n",
      "[324/1762] D loss: 1.4690, G loss: 0.9467\n",
      "[404/1762] D loss: 1.3567, G loss: 0.7774\n",
      "[484/1762] D loss: 1.3652, G loss: 0.6866\n",
      "[564/1762] D loss: 1.0272, G loss: 0.9758\n",
      "[644/1762] D loss: 1.1663, G loss: 0.7668\n",
      "[724/1762] D loss: 1.2402, G loss: 0.9767\n",
      "[804/1762] D loss: 1.2772, G loss: 0.8949\n",
      "[884/1762] D loss: 1.2120, G loss: 0.6973\n",
      "[964/1762] D loss: 1.1131, G loss: 1.0675\n",
      "[1044/1762] D loss: 1.3289, G loss: 0.7199\n",
      "[1124/1762] D loss: 1.3698, G loss: 0.7237\n",
      "[1204/1762] D loss: 1.4444, G loss: 0.4928\n",
      "[1284/1762] D loss: 1.3481, G loss: 0.4635\n",
      "[1364/1762] D loss: 1.0165, G loss: 0.9746\n",
      "[1444/1762] D loss: 1.0030, G loss: 0.9112\n",
      "[1524/1762] D loss: 1.2612, G loss: 0.6165\n",
      "[1604/1762] D loss: 1.2630, G loss: 0.9680\n",
      "[1684/1762] D loss: 1.1223, G loss: 0.9807\n",
      "[1762/1762] D loss: 0.7160, G loss: 1.4435\n",
      "train error: \n",
      " D loss: 1.324296, G loss: 0.765362, D accuracy: 57.9%, cell accuracy: 99.7%, board accuracy: 79.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327952, G loss: 0.773208, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0320, G loss: 0.9861\n",
      "[84/1762] D loss: 1.3151, G loss: 0.6911\n",
      "[164/1762] D loss: 1.5070, G loss: 0.9464\n",
      "[244/1762] D loss: 1.3482, G loss: 0.8024\n",
      "[324/1762] D loss: 1.0643, G loss: 0.9030\n",
      "[404/1762] D loss: 1.2216, G loss: 0.8272\n",
      "[484/1762] D loss: 1.3281, G loss: 0.6676\n",
      "[564/1762] D loss: 1.3706, G loss: 0.7318\n",
      "[644/1762] D loss: 1.2202, G loss: 0.9113\n",
      "[724/1762] D loss: 1.2221, G loss: 0.6993\n",
      "[804/1762] D loss: 1.3481, G loss: 0.6941\n",
      "[884/1762] D loss: 1.5007, G loss: 1.1953\n",
      "[964/1762] D loss: 1.3498, G loss: 0.7905\n",
      "[1044/1762] D loss: 1.3071, G loss: 0.7353\n",
      "[1124/1762] D loss: 1.5278, G loss: 1.0502\n",
      "[1204/1762] D loss: 1.3320, G loss: 0.7747\n",
      "[1284/1762] D loss: 1.3442, G loss: 1.2438\n",
      "[1364/1762] D loss: 1.3393, G loss: 0.6728\n",
      "[1444/1762] D loss: 1.4479, G loss: 0.9346\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7882\n",
      "[1604/1762] D loss: 1.1316, G loss: 0.9089\n",
      "[1684/1762] D loss: 1.3517, G loss: 0.7805\n",
      "[1762/1762] D loss: 1.2158, G loss: 0.4517\n",
      "train error: \n",
      " D loss: 1.496885, G loss: 0.400836, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 83.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.490867, G loss: 0.409323, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6239, G loss: 0.9166\n",
      "[84/1762] D loss: 1.3951, G loss: 0.7106\n",
      "[164/1762] D loss: 1.3780, G loss: 0.7415\n",
      "[244/1762] D loss: 1.4943, G loss: 0.8892\n",
      "[324/1762] D loss: 1.3966, G loss: 0.6856\n",
      "[404/1762] D loss: 1.4051, G loss: 0.7346\n",
      "[484/1762] D loss: 1.3943, G loss: 0.5578\n",
      "[564/1762] D loss: 1.2939, G loss: 0.6839\n",
      "[644/1762] D loss: 1.3090, G loss: 0.7636\n",
      "[724/1762] D loss: 1.4274, G loss: 0.9167\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7328\n",
      "[884/1762] D loss: 1.2206, G loss: 0.7832\n",
      "[964/1762] D loss: 1.2524, G loss: 0.7066\n",
      "[1044/1762] D loss: 1.4303, G loss: 0.7203\n",
      "[1124/1762] D loss: 1.3750, G loss: 0.6131\n",
      "[1204/1762] D loss: 1.4052, G loss: 0.9098\n",
      "[1284/1762] D loss: 1.2710, G loss: 0.7850\n",
      "[1364/1762] D loss: 1.2549, G loss: 1.1156\n",
      "[1444/1762] D loss: 1.2218, G loss: 1.0860\n",
      "[1524/1762] D loss: 1.3760, G loss: 0.6795\n",
      "[1604/1762] D loss: 1.3686, G loss: 0.8494\n",
      "[1684/1762] D loss: 1.3739, G loss: 0.7554\n",
      "[1762/1762] D loss: 1.3741, G loss: 0.7341\n",
      "train error: \n",
      " D loss: 1.363388, G loss: 0.946015, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367373, G loss: 0.970513, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4535, G loss: 0.6288\n",
      "[84/1762] D loss: 1.3200, G loss: 0.7280\n",
      "[164/1762] D loss: 1.3439, G loss: 0.6778\n",
      "[244/1762] D loss: 1.1865, G loss: 0.8856\n",
      "[324/1762] D loss: 1.2609, G loss: 0.7679\n",
      "[404/1762] D loss: 1.1144, G loss: 0.9249\n",
      "[484/1762] D loss: 1.3788, G loss: 0.6520\n",
      "[564/1762] D loss: 1.3335, G loss: 0.6941\n",
      "[644/1762] D loss: 1.2968, G loss: 0.8359\n",
      "[724/1762] D loss: 1.3584, G loss: 0.8153\n",
      "[804/1762] D loss: 1.5052, G loss: 1.1712\n",
      "[884/1762] D loss: 1.2080, G loss: 0.8299\n",
      "[964/1762] D loss: 0.9002, G loss: 1.1498\n",
      "[1044/1762] D loss: 1.2779, G loss: 0.6828\n",
      "[1124/1762] D loss: 1.3139, G loss: 0.9444\n",
      "[1204/1762] D loss: 1.3134, G loss: 0.8069\n",
      "[1284/1762] D loss: 1.4031, G loss: 0.8457\n",
      "[1364/1762] D loss: 1.3655, G loss: 0.6951\n",
      "[1444/1762] D loss: 1.3826, G loss: 0.6750\n",
      "[1524/1762] D loss: 1.1572, G loss: 0.8679\n",
      "[1604/1762] D loss: 1.2853, G loss: 0.7756\n",
      "[1684/1762] D loss: 1.3604, G loss: 0.7152\n",
      "[1762/1762] D loss: 1.4920, G loss: 0.7546\n",
      "train error: \n",
      " D loss: 1.331229, G loss: 0.792880, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325101, G loss: 0.817317, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4527, G loss: 0.6828\n",
      "[84/1762] D loss: 0.8193, G loss: 1.2299\n",
      "[164/1762] D loss: 1.2502, G loss: 0.7155\n",
      "[244/1762] D loss: 0.9802, G loss: 1.0715\n",
      "[324/1762] D loss: 1.4499, G loss: 0.5860\n",
      "[404/1762] D loss: 1.0246, G loss: 0.7758\n",
      "[484/1762] D loss: 1.3889, G loss: 0.7485\n",
      "[564/1762] D loss: 1.3744, G loss: 0.9336\n",
      "[644/1762] D loss: 1.1335, G loss: 0.8845\n",
      "[724/1762] D loss: 1.1598, G loss: 0.7598\n",
      "[804/1762] D loss: 1.3291, G loss: 0.7416\n",
      "[884/1762] D loss: 1.3469, G loss: 1.0192\n",
      "[964/1762] D loss: 1.3017, G loss: 0.8975\n",
      "[1044/1762] D loss: 1.1539, G loss: 0.8311\n",
      "[1124/1762] D loss: 1.4818, G loss: 0.6959\n",
      "[1204/1762] D loss: 1.3297, G loss: 0.5843\n",
      "[1284/1762] D loss: 1.2154, G loss: 0.8689\n",
      "[1364/1762] D loss: 1.3482, G loss: 0.7754\n",
      "[1444/1762] D loss: 1.3331, G loss: 0.7837\n",
      "[1524/1762] D loss: 1.2794, G loss: 0.7573\n",
      "[1604/1762] D loss: 1.1434, G loss: 0.8362\n",
      "[1684/1762] D loss: 1.3659, G loss: 0.7033\n",
      "[1762/1762] D loss: 0.5411, G loss: 1.4861\n",
      "train error: \n",
      " D loss: 1.329397, G loss: 0.685217, D accuracy: 58.6%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327982, G loss: 0.696290, D accuracy: 59.5%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9489, G loss: 1.1335\n",
      "[84/1762] D loss: 1.3824, G loss: 0.7123\n",
      "[164/1762] D loss: 1.3712, G loss: 0.7835\n",
      "[244/1762] D loss: 1.3419, G loss: 0.7093\n",
      "[324/1762] D loss: 1.3354, G loss: 0.8035\n",
      "[404/1762] D loss: 1.3924, G loss: 0.6241\n",
      "[484/1762] D loss: 1.0119, G loss: 1.0533\n",
      "[564/1762] D loss: 1.4238, G loss: 0.7562\n",
      "[644/1762] D loss: 1.0415, G loss: 0.9343\n",
      "[724/1762] D loss: 1.0311, G loss: 1.0131\n",
      "[804/1762] D loss: 1.3220, G loss: 0.7421\n",
      "[884/1762] D loss: 1.4441, G loss: 0.6944\n",
      "[964/1762] D loss: 1.4823, G loss: 0.6757\n",
      "[1044/1762] D loss: 1.4066, G loss: 0.6423\n",
      "[1124/1762] D loss: 1.2121, G loss: 0.8171\n",
      "[1204/1762] D loss: 1.2259, G loss: 0.8566\n",
      "[1284/1762] D loss: 1.1889, G loss: 0.8449\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.6527\n",
      "[1444/1762] D loss: 1.2720, G loss: 0.8300\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.7786\n",
      "[1604/1762] D loss: 1.2728, G loss: 0.7100\n",
      "[1684/1762] D loss: 1.3977, G loss: 0.6668\n",
      "[1762/1762] D loss: 1.4202, G loss: 0.7231\n",
      "train error: \n",
      " D loss: 1.342318, G loss: 0.858088, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340533, G loss: 0.882457, D accuracy: 56.8%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933, G loss: 0.6050\n",
      "[84/1762] D loss: 1.3184, G loss: 0.7356\n",
      "[164/1762] D loss: 1.3518, G loss: 0.6966\n",
      "[244/1762] D loss: 1.1061, G loss: 0.9681\n",
      "[324/1762] D loss: 1.2888, G loss: 0.7110\n",
      "[404/1762] D loss: 1.3645, G loss: 0.7032\n",
      "[484/1762] D loss: 1.1814, G loss: 0.9683\n",
      "[564/1762] D loss: 1.3260, G loss: 0.7322\n",
      "[644/1762] D loss: 1.0796, G loss: 0.8751\n",
      "[724/1762] D loss: 1.3259, G loss: 0.7961\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6160\n",
      "[884/1762] D loss: 1.3354, G loss: 0.7297\n",
      "[964/1762] D loss: 1.2180, G loss: 0.8877\n",
      "[1044/1762] D loss: 1.1019, G loss: 1.1186\n",
      "[1124/1762] D loss: 1.3983, G loss: 0.7297\n",
      "[1204/1762] D loss: 1.2899, G loss: 0.9550\n",
      "[1284/1762] D loss: 1.1305, G loss: 0.8949\n",
      "[1364/1762] D loss: 1.3801, G loss: 0.7122\n",
      "[1444/1762] D loss: 1.3598, G loss: 0.6519\n",
      "[1524/1762] D loss: 1.2221, G loss: 0.9577\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.6643\n",
      "[1684/1762] D loss: 1.3658, G loss: 0.7636\n",
      "[1762/1762] D loss: 1.3798, G loss: 0.8887\n",
      "train error: \n",
      " D loss: 1.372039, G loss: 1.035374, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 74.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378041, G loss: 1.049499, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3730, G loss: 0.6396\n",
      "[84/1762] D loss: 1.2448, G loss: 0.7532\n",
      "[164/1762] D loss: 1.1397, G loss: 0.8076\n",
      "[244/1762] D loss: 1.3910, G loss: 0.6720\n",
      "[324/1762] D loss: 1.3056, G loss: 0.7550\n",
      "[404/1762] D loss: 1.3717, G loss: 0.6442\n",
      "[484/1762] D loss: 1.3956, G loss: 0.6215\n",
      "[564/1762] D loss: 1.2388, G loss: 0.7429\n",
      "[644/1762] D loss: 1.3805, G loss: 0.8502\n",
      "[724/1762] D loss: 1.3005, G loss: 0.7642\n",
      "[804/1762] D loss: 1.3740, G loss: 0.8587\n",
      "[884/1762] D loss: 1.3732, G loss: 0.6968\n",
      "[964/1762] D loss: 1.3180, G loss: 0.7228\n",
      "[1044/1762] D loss: 1.3778, G loss: 0.7177\n",
      "[1124/1762] D loss: 1.2386, G loss: 0.6592\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.6475\n",
      "[1284/1762] D loss: 1.2535, G loss: 0.8155\n",
      "[1364/1762] D loss: 1.3756, G loss: 0.7491\n",
      "[1444/1762] D loss: 1.1909, G loss: 0.8594\n",
      "[1524/1762] D loss: 1.4357, G loss: 0.6337\n",
      "[1604/1762] D loss: 1.0905, G loss: 0.9081\n",
      "[1684/1762] D loss: 1.1674, G loss: 0.8978\n",
      "[1762/1762] D loss: 1.3057, G loss: 0.7463\n",
      "train error: \n",
      " D loss: 1.330475, G loss: 0.775811, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328580, G loss: 0.792818, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3777, G loss: 0.7119\n",
      "[84/1762] D loss: 1.3538, G loss: 0.6368\n",
      "[164/1762] D loss: 1.3804, G loss: 0.6644\n",
      "[244/1762] D loss: 1.3877, G loss: 0.8637\n",
      "[324/1762] D loss: 1.3785, G loss: 0.7891\n",
      "[404/1762] D loss: 1.4083, G loss: 0.7439\n",
      "[484/1762] D loss: 1.1344, G loss: 0.8955\n",
      "[564/1762] D loss: 1.4142, G loss: 0.7151\n",
      "[644/1762] D loss: 1.0406, G loss: 0.9967\n",
      "[724/1762] D loss: 1.0761, G loss: 1.0069\n",
      "[804/1762] D loss: 1.0072, G loss: 1.0302\n",
      "[884/1762] D loss: 1.3668, G loss: 0.7352\n",
      "[964/1762] D loss: 1.1307, G loss: 1.2420\n",
      "[1044/1762] D loss: 1.3140, G loss: 0.7267\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.7514\n",
      "[1204/1762] D loss: 1.3278, G loss: 0.8335\n",
      "[1284/1762] D loss: 1.4321, G loss: 0.9628\n",
      "[1364/1762] D loss: 1.4214, G loss: 0.6637\n",
      "[1444/1762] D loss: 1.1619, G loss: 0.9078\n",
      "[1524/1762] D loss: 1.2464, G loss: 0.8099\n",
      "[1604/1762] D loss: 1.5563, G loss: 0.8395\n",
      "[1684/1762] D loss: 1.4841, G loss: 0.5366\n",
      "[1762/1762] D loss: 1.3757, G loss: 0.7249\n",
      "train error: \n",
      " D loss: 1.333107, G loss: 0.668904, D accuracy: 58.2%, cell accuracy: 99.7%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326645, G loss: 0.693018, D accuracy: 60.7%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4156, G loss: 0.7574\n",
      "[84/1762] D loss: 1.3106, G loss: 0.9015\n",
      "[164/1762] D loss: 1.1927, G loss: 0.8635\n",
      "[244/1762] D loss: 1.4434, G loss: 0.8318\n",
      "[324/1762] D loss: 1.1409, G loss: 0.9391\n",
      "[404/1762] D loss: 1.3453, G loss: 0.7053\n",
      "[484/1762] D loss: 1.3677, G loss: 0.8358\n",
      "[564/1762] D loss: 1.3105, G loss: 0.7971\n",
      "[644/1762] D loss: 1.0385, G loss: 0.9507\n",
      "[724/1762] D loss: 1.3825, G loss: 0.6449\n",
      "[804/1762] D loss: 1.1173, G loss: 0.9812\n",
      "[884/1762] D loss: 1.5281, G loss: 0.5674\n",
      "[964/1762] D loss: 1.4119, G loss: 0.3756\n",
      "[1044/1762] D loss: 1.2310, G loss: 0.7719\n",
      "[1124/1762] D loss: 1.2648, G loss: 0.7608\n",
      "[1204/1762] D loss: 1.4505, G loss: 0.6185\n",
      "[1284/1762] D loss: 1.4420, G loss: 0.7398\n",
      "[1364/1762] D loss: 1.4094, G loss: 0.6420\n",
      "[1444/1762] D loss: 1.3727, G loss: 0.7886\n",
      "[1524/1762] D loss: 1.3409, G loss: 0.7623\n",
      "[1604/1762] D loss: 1.2220, G loss: 1.0381\n",
      "[1684/1762] D loss: 1.2676, G loss: 0.6596\n",
      "[1762/1762] D loss: 1.1842, G loss: 1.2575\n",
      "train error: \n",
      " D loss: 1.324981, G loss: 0.850610, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326216, G loss: 0.869349, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1984, G loss: 0.8580\n",
      "[84/1762] D loss: 1.3628, G loss: 0.6415\n",
      "[164/1762] D loss: 1.3771, G loss: 0.6577\n",
      "[244/1762] D loss: 1.4750, G loss: 0.5188\n",
      "[324/1762] D loss: 1.4624, G loss: 0.5844\n",
      "[404/1762] D loss: 1.3968, G loss: 0.7274\n",
      "[484/1762] D loss: 1.3772, G loss: 0.8324\n",
      "[564/1762] D loss: 1.0909, G loss: 0.9810\n",
      "[644/1762] D loss: 1.1944, G loss: 0.7466\n",
      "[724/1762] D loss: 1.4918, G loss: 0.6335\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6947\n",
      "[884/1762] D loss: 1.3931, G loss: 0.6476\n",
      "[964/1762] D loss: 1.3981, G loss: 0.8830\n",
      "[1044/1762] D loss: 1.4301, G loss: 0.5803\n",
      "[1124/1762] D loss: 0.9487, G loss: 1.0331\n",
      "[1204/1762] D loss: 1.4474, G loss: 0.6314\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.7719\n",
      "[1364/1762] D loss: 0.8245, G loss: 1.1381\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.7661\n",
      "[1524/1762] D loss: 1.5456, G loss: 0.7420\n",
      "[1604/1762] D loss: 1.2276, G loss: 0.8674\n",
      "[1684/1762] D loss: 1.3073, G loss: 0.7255\n",
      "[1762/1762] D loss: 1.5740, G loss: 0.6310\n",
      "train error: \n",
      " D loss: 1.339513, G loss: 0.647836, D accuracy: 58.0%, cell accuracy: 99.6%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326682, G loss: 0.669874, D accuracy: 59.3%, cell accuracy: 99.6%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1036, G loss: 0.9484\n",
      "[84/1762] D loss: 1.3509, G loss: 0.7025\n",
      "[164/1762] D loss: 1.0492, G loss: 1.0286\n",
      "[244/1762] D loss: 1.3688, G loss: 0.6815\n",
      "[324/1762] D loss: 1.5304, G loss: 0.8680\n",
      "[404/1762] D loss: 1.2432, G loss: 0.7068\n",
      "[484/1762] D loss: 1.3694, G loss: 0.5875\n",
      "[564/1762] D loss: 1.3106, G loss: 0.6891\n",
      "[644/1762] D loss: 1.4884, G loss: 0.8493\n",
      "[724/1762] D loss: 1.3768, G loss: 0.7226\n",
      "[804/1762] D loss: 1.3586, G loss: 0.7675\n",
      "[884/1762] D loss: 1.3784, G loss: 0.6725\n",
      "[964/1762] D loss: 1.3736, G loss: 0.7440\n",
      "[1044/1762] D loss: 1.2101, G loss: 0.7829\n",
      "[1124/1762] D loss: 1.3851, G loss: 0.8593\n",
      "[1204/1762] D loss: 1.3641, G loss: 0.7101\n",
      "[1284/1762] D loss: 1.2991, G loss: 0.7562\n",
      "[1364/1762] D loss: 1.2282, G loss: 0.7187\n",
      "[1444/1762] D loss: 1.5145, G loss: 0.8849\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.8060\n",
      "[1604/1762] D loss: 1.3734, G loss: 0.6596\n",
      "[1684/1762] D loss: 1.1838, G loss: 1.1917\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.7664\n",
      "train error: \n",
      " D loss: 1.320985, G loss: 0.871101, D accuracy: 56.3%, cell accuracy: 99.6%, board accuracy: 78.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315361, G loss: 0.901097, D accuracy: 56.4%, cell accuracy: 99.6%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3585, G loss: 0.7449\n",
      "[84/1762] D loss: 1.3201, G loss: 0.7601\n",
      "[164/1762] D loss: 1.3834, G loss: 0.6823\n",
      "[244/1762] D loss: 1.4431, G loss: 0.7550\n",
      "[324/1762] D loss: 1.1352, G loss: 0.8727\n",
      "[404/1762] D loss: 1.2221, G loss: 0.8044\n",
      "[484/1762] D loss: 1.3818, G loss: 0.6802\n",
      "[564/1762] D loss: 1.1417, G loss: 0.9538\n",
      "[644/1762] D loss: 1.3466, G loss: 0.7711\n",
      "[724/1762] D loss: 1.4853, G loss: 0.8591\n",
      "[804/1762] D loss: 1.2985, G loss: 0.9873\n",
      "[884/1762] D loss: 1.4092, G loss: 0.6626\n",
      "[964/1762] D loss: 1.3758, G loss: 0.6814\n",
      "[1044/1762] D loss: 1.3115, G loss: 0.6918\n",
      "[1124/1762] D loss: 1.3387, G loss: 0.9431\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.7908\n",
      "[1284/1762] D loss: 1.3795, G loss: 0.7020\n",
      "[1364/1762] D loss: 1.3671, G loss: 0.5808\n",
      "[1444/1762] D loss: 1.3160, G loss: 0.7377\n",
      "[1524/1762] D loss: 1.3797, G loss: 0.7119\n",
      "[1604/1762] D loss: 1.3985, G loss: 0.6739\n",
      "[1684/1762] D loss: 1.3639, G loss: 0.7230\n",
      "[1762/1762] D loss: 1.3570, G loss: 0.7604\n",
      "train error: \n",
      " D loss: 1.334067, G loss: 0.893679, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325955, G loss: 0.919779, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4192, G loss: 0.6490\n",
      "[84/1762] D loss: 1.3655, G loss: 0.7108\n",
      "[164/1762] D loss: 1.3859, G loss: 0.6820\n",
      "[244/1762] D loss: 1.3790, G loss: 0.6684\n",
      "[324/1762] D loss: 1.3624, G loss: 0.8541\n",
      "[404/1762] D loss: 0.9601, G loss: 0.8807\n",
      "[484/1762] D loss: 1.4145, G loss: 0.7544\n",
      "[564/1762] D loss: 1.4886, G loss: 0.5785\n",
      "[644/1762] D loss: 1.3854, G loss: 0.6932\n",
      "[724/1762] D loss: 1.7789, G loss: 0.8291\n",
      "[804/1762] D loss: 1.3614, G loss: 0.7032\n",
      "[884/1762] D loss: 1.0986, G loss: 1.1699\n",
      "[964/1762] D loss: 1.3502, G loss: 0.7201\n",
      "[1044/1762] D loss: 1.2717, G loss: 0.8222\n",
      "[1124/1762] D loss: 1.3532, G loss: 0.7253\n",
      "[1204/1762] D loss: 1.0921, G loss: 0.9738\n",
      "[1284/1762] D loss: 1.3926, G loss: 0.7257\n",
      "[1364/1762] D loss: 1.0527, G loss: 0.9241\n",
      "[1444/1762] D loss: 1.4682, G loss: 0.6674\n",
      "[1524/1762] D loss: 1.2816, G loss: 0.6751\n",
      "[1604/1762] D loss: 0.8629, G loss: 1.2431\n",
      "[1684/1762] D loss: 1.3567, G loss: 0.7042\n",
      "[1762/1762] D loss: 0.8862, G loss: 1.2006\n",
      "train error: \n",
      " D loss: 1.328458, G loss: 0.876975, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335706, G loss: 0.885831, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3588, G loss: 0.7337\n",
      "[84/1762] D loss: 1.3038, G loss: 0.6209\n",
      "[164/1762] D loss: 1.3784, G loss: 0.7120\n",
      "[244/1762] D loss: 1.4015, G loss: 0.9343\n",
      "[324/1762] D loss: 1.3578, G loss: 0.6838\n",
      "[404/1762] D loss: 1.3959, G loss: 0.7156\n",
      "[484/1762] D loss: 1.0914, G loss: 0.8859\n",
      "[564/1762] D loss: 1.3564, G loss: 0.7236\n",
      "[644/1762] D loss: 1.4053, G loss: 0.8890\n",
      "[724/1762] D loss: 1.1825, G loss: 0.9762\n",
      "[804/1762] D loss: 1.3762, G loss: 0.6673\n",
      "[884/1762] D loss: 1.0325, G loss: 0.9554\n",
      "[964/1762] D loss: 0.8411, G loss: 1.1353\n",
      "[1044/1762] D loss: 1.0324, G loss: 0.8535\n",
      "[1124/1762] D loss: 1.5737, G loss: 0.4152\n",
      "[1204/1762] D loss: 0.8801, G loss: 0.9734\n",
      "[1284/1762] D loss: 1.3317, G loss: 0.7287\n",
      "[1364/1762] D loss: 1.3208, G loss: 0.8006\n",
      "[1444/1762] D loss: 1.3660, G loss: 0.8022\n",
      "[1524/1762] D loss: 1.3815, G loss: 0.6835\n",
      "[1604/1762] D loss: 1.4302, G loss: 0.6633\n",
      "[1684/1762] D loss: 1.3473, G loss: 0.6704\n",
      "[1762/1762] D loss: 1.3626, G loss: 0.7035\n",
      "train error: \n",
      " D loss: 1.331768, G loss: 0.716508, D accuracy: 57.6%, cell accuracy: 99.7%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321441, G loss: 0.740736, D accuracy: 59.4%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3737, G loss: 0.7003\n",
      "[84/1762] D loss: 1.1610, G loss: 0.9686\n",
      "[164/1762] D loss: 1.1782, G loss: 0.7399\n",
      "[244/1762] D loss: 1.1223, G loss: 0.9927\n",
      "[324/1762] D loss: 1.4418, G loss: 0.8533\n",
      "[404/1762] D loss: 1.3998, G loss: 0.7038\n",
      "[484/1762] D loss: 1.4249, G loss: 0.6844\n",
      "[564/1762] D loss: 1.2881, G loss: 0.8220\n",
      "[644/1762] D loss: 1.3805, G loss: 0.7061\n",
      "[724/1762] D loss: 1.3044, G loss: 0.6865\n",
      "[804/1762] D loss: 1.1825, G loss: 1.0446\n",
      "[884/1762] D loss: 1.3272, G loss: 0.7429\n",
      "[964/1762] D loss: 1.1596, G loss: 0.8877\n",
      "[1044/1762] D loss: 1.3201, G loss: 0.7225\n",
      "[1124/1762] D loss: 1.4174, G loss: 0.7210\n",
      "[1204/1762] D loss: 1.3156, G loss: 0.7836\n",
      "[1284/1762] D loss: 1.3689, G loss: 0.9041\n",
      "[1364/1762] D loss: 1.3836, G loss: 0.6766\n",
      "[1444/1762] D loss: 0.9262, G loss: 1.1307\n",
      "[1524/1762] D loss: 1.5182, G loss: 0.9089\n",
      "[1604/1762] D loss: 1.3828, G loss: 0.6450\n",
      "[1684/1762] D loss: 1.0758, G loss: 0.9296\n",
      "[1762/1762] D loss: 1.3775, G loss: 0.6399\n",
      "train error: \n",
      " D loss: 1.344479, G loss: 0.614046, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338747, G loss: 0.629830, D accuracy: 58.1%, cell accuracy: 99.5%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1694, G loss: 0.9811\n",
      "[84/1762] D loss: 1.1741, G loss: 0.8775\n",
      "[164/1762] D loss: 1.2859, G loss: 0.8614\n",
      "[244/1762] D loss: 1.3311, G loss: 0.4191\n",
      "[324/1762] D loss: 1.3823, G loss: 0.7227\n",
      "[404/1762] D loss: 1.3734, G loss: 0.5798\n",
      "[484/1762] D loss: 1.4109, G loss: 0.7779\n",
      "[564/1762] D loss: 1.4195, G loss: 0.5632\n",
      "[644/1762] D loss: 1.5093, G loss: 0.7316\n",
      "[724/1762] D loss: 1.3936, G loss: 0.7645\n",
      "[804/1762] D loss: 1.3690, G loss: 0.7582\n",
      "[884/1762] D loss: 1.3768, G loss: 0.6435\n",
      "[964/1762] D loss: 1.3764, G loss: 0.6704\n",
      "[1044/1762] D loss: 0.9673, G loss: 1.2290\n",
      "[1124/1762] D loss: 1.3668, G loss: 0.6635\n",
      "[1204/1762] D loss: 1.2360, G loss: 0.7178\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7935\n",
      "[1364/1762] D loss: 1.3971, G loss: 0.8478\n",
      "[1444/1762] D loss: 1.3799, G loss: 0.6522\n",
      "[1524/1762] D loss: 1.3092, G loss: 0.8596\n",
      "[1604/1762] D loss: 1.3980, G loss: 0.5942\n",
      "[1684/1762] D loss: 1.3846, G loss: 0.7795\n",
      "[1762/1762] D loss: 1.3678, G loss: 0.6749\n",
      "train error: \n",
      " D loss: 1.325296, G loss: 0.706828, D accuracy: 58.7%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320438, G loss: 0.725021, D accuracy: 59.9%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3844, G loss: 0.7089\n",
      "[84/1762] D loss: 1.3773, G loss: 0.7311\n",
      "[164/1762] D loss: 1.3892, G loss: 0.7460\n",
      "[244/1762] D loss: 1.3888, G loss: 0.7212\n",
      "[324/1762] D loss: 1.4785, G loss: 0.8165\n",
      "[404/1762] D loss: 1.3039, G loss: 0.5735\n",
      "[484/1762] D loss: 1.4151, G loss: 0.8185\n",
      "[564/1762] D loss: 1.3961, G loss: 0.7632\n",
      "[644/1762] D loss: 1.3871, G loss: 0.7531\n",
      "[724/1762] D loss: 1.3837, G loss: 0.7410\n",
      "[804/1762] D loss: 1.3648, G loss: 0.9048\n",
      "[884/1762] D loss: 1.4634, G loss: 0.7004\n",
      "[964/1762] D loss: 1.3117, G loss: 0.8270\n",
      "[1044/1762] D loss: 1.1326, G loss: 0.8780\n",
      "[1124/1762] D loss: 1.1489, G loss: 0.9482\n",
      "[1204/1762] D loss: 1.3812, G loss: 0.7296\n",
      "[1284/1762] D loss: 1.0447, G loss: 1.0162\n",
      "[1364/1762] D loss: 1.0863, G loss: 0.9435\n",
      "[1444/1762] D loss: 1.3708, G loss: 0.6924\n",
      "[1524/1762] D loss: 1.2628, G loss: 0.8210\n",
      "[1604/1762] D loss: 1.4957, G loss: 0.6771\n",
      "[1684/1762] D loss: 1.4149, G loss: 0.6728\n",
      "[1762/1762] D loss: 1.2145, G loss: 1.1586\n",
      "train error: \n",
      " D loss: 1.320410, G loss: 0.750726, D accuracy: 58.3%, cell accuracy: 99.8%, board accuracy: 83.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320192, G loss: 0.771884, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.7187\n",
      "[84/1762] D loss: 1.1000, G loss: 0.9254\n",
      "[164/1762] D loss: 1.4113, G loss: 0.6964\n",
      "[244/1762] D loss: 1.1715, G loss: 0.8145\n",
      "[324/1762] D loss: 1.3762, G loss: 0.6883\n",
      "[404/1762] D loss: 1.1231, G loss: 1.0071\n",
      "[484/1762] D loss: 1.4047, G loss: 0.6995\n",
      "[564/1762] D loss: 1.3929, G loss: 0.6206\n",
      "[644/1762] D loss: 1.3724, G loss: 0.7137\n",
      "[724/1762] D loss: 1.3777, G loss: 0.7108\n",
      "[804/1762] D loss: 1.3835, G loss: 0.6428\n",
      "[884/1762] D loss: 1.3590, G loss: 0.7761\n",
      "[964/1762] D loss: 1.4268, G loss: 0.5537\n",
      "[1044/1762] D loss: 1.4158, G loss: 0.8717\n",
      "[1124/1762] D loss: 1.3699, G loss: 0.6477\n",
      "[1204/1762] D loss: 1.0503, G loss: 1.0415\n",
      "[1284/1762] D loss: 1.0695, G loss: 1.0109\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.6662\n",
      "[1444/1762] D loss: 1.0649, G loss: 0.9307\n",
      "[1524/1762] D loss: 0.7167, G loss: 1.3582\n",
      "[1604/1762] D loss: 1.3826, G loss: 0.6539\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.7335\n",
      "[1762/1762] D loss: 1.4136, G loss: 0.6643\n",
      "train error: \n",
      " D loss: 1.329064, G loss: 0.697420, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317671, G loss: 0.713478, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3759, G loss: 0.7172\n",
      "[84/1762] D loss: 0.9496, G loss: 1.0380\n",
      "[164/1762] D loss: 1.3806, G loss: 0.6785\n",
      "[244/1762] D loss: 0.6069, G loss: 1.4742\n",
      "[324/1762] D loss: 1.0339, G loss: 1.0124\n",
      "[404/1762] D loss: 1.3568, G loss: 0.7597\n",
      "[484/1762] D loss: 1.0472, G loss: 1.0878\n",
      "[564/1762] D loss: 1.0570, G loss: 1.1516\n",
      "[644/1762] D loss: 1.3852, G loss: 0.6556\n",
      "[724/1762] D loss: 1.2271, G loss: 0.7202\n",
      "[804/1762] D loss: 1.3754, G loss: 0.6975\n",
      "[884/1762] D loss: 1.2022, G loss: 0.9107\n",
      "[964/1762] D loss: 1.3833, G loss: 0.6728\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.6459\n",
      "[1124/1762] D loss: 1.3480, G loss: 0.7433\n",
      "[1204/1762] D loss: 1.4584, G loss: 0.7037\n",
      "[1284/1762] D loss: 1.2432, G loss: 0.7939\n",
      "[1364/1762] D loss: 1.3611, G loss: 0.6615\n",
      "[1444/1762] D loss: 1.2250, G loss: 0.7139\n",
      "[1524/1762] D loss: 1.6030, G loss: 0.8212\n",
      "[1604/1762] D loss: 1.1168, G loss: 0.9566\n",
      "[1684/1762] D loss: 1.3722, G loss: 0.7031\n",
      "[1762/1762] D loss: 1.3807, G loss: 0.6710\n",
      "train error: \n",
      " D loss: 1.332577, G loss: 0.834307, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339500, G loss: 0.846745, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2279, G loss: 0.7573\n",
      "[84/1762] D loss: 1.4607, G loss: 0.7865\n",
      "[164/1762] D loss: 1.4050, G loss: 0.7446\n",
      "[244/1762] D loss: 1.2328, G loss: 0.7979\n",
      "[324/1762] D loss: 1.0902, G loss: 0.9728\n",
      "[404/1762] D loss: 1.3820, G loss: 0.7101\n",
      "[484/1762] D loss: 1.3438, G loss: 0.7688\n",
      "[564/1762] D loss: 1.1288, G loss: 0.9527\n",
      "[644/1762] D loss: 1.4017, G loss: 0.6231\n",
      "[724/1762] D loss: 1.3766, G loss: 0.7384\n",
      "[804/1762] D loss: 1.0259, G loss: 0.9789\n",
      "[884/1762] D loss: 1.3597, G loss: 0.6815\n",
      "[964/1762] D loss: 1.4547, G loss: 0.7854\n",
      "[1044/1762] D loss: 1.0891, G loss: 0.9199\n",
      "[1124/1762] D loss: 1.6474, G loss: 0.6352\n",
      "[1204/1762] D loss: 1.0238, G loss: 1.0177\n",
      "[1284/1762] D loss: 1.3854, G loss: 0.7576\n",
      "[1364/1762] D loss: 1.1467, G loss: 0.8556\n",
      "[1444/1762] D loss: 0.9644, G loss: 1.0153\n",
      "[1524/1762] D loss: 1.0394, G loss: 0.9084\n",
      "[1604/1762] D loss: 0.8990, G loss: 1.1219\n",
      "[1684/1762] D loss: 1.4482, G loss: 0.6483\n",
      "[1762/1762] D loss: 1.3668, G loss: 0.6856\n",
      "train error: \n",
      " D loss: 1.321743, G loss: 0.726865, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312923, G loss: 0.742287, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3665, G loss: 0.7017\n",
      "[84/1762] D loss: 1.6551, G loss: 0.6132\n",
      "[164/1762] D loss: 1.4066, G loss: 0.6564\n",
      "[244/1762] D loss: 1.3568, G loss: 0.6895\n",
      "[324/1762] D loss: 1.3762, G loss: 0.6971\n",
      "[404/1762] D loss: 1.3793, G loss: 0.7420\n",
      "[484/1762] D loss: 0.8315, G loss: 1.1238\n",
      "[564/1762] D loss: 0.9207, G loss: 1.0889\n",
      "[644/1762] D loss: 1.0636, G loss: 1.2280\n",
      "[724/1762] D loss: 1.5733, G loss: 0.5812\n",
      "[804/1762] D loss: 1.5240, G loss: 0.6502\n",
      "[884/1762] D loss: 1.3755, G loss: 0.6936\n",
      "[964/1762] D loss: 1.3587, G loss: 0.7314\n",
      "[1044/1762] D loss: 1.2004, G loss: 0.7523\n",
      "[1124/1762] D loss: 1.4287, G loss: 0.8119\n",
      "[1204/1762] D loss: 1.2742, G loss: 0.9636\n",
      "[1284/1762] D loss: 1.2906, G loss: 0.8706\n",
      "[1364/1762] D loss: 1.4383, G loss: 0.7182\n",
      "[1444/1762] D loss: 1.3273, G loss: 0.7655\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.6387\n",
      "[1604/1762] D loss: 1.3516, G loss: 0.7666\n",
      "[1684/1762] D loss: 1.1447, G loss: 0.8353\n",
      "[1762/1762] D loss: 1.4095, G loss: 0.6255\n",
      "train error: \n",
      " D loss: 1.314359, G loss: 0.688853, D accuracy: 60.1%, cell accuracy: 99.7%, board accuracy: 78.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311200, G loss: 0.698743, D accuracy: 61.4%, cell accuracy: 99.6%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1736, G loss: 0.8261\n",
      "[84/1762] D loss: 1.3800, G loss: 0.7133\n",
      "[164/1762] D loss: 1.0730, G loss: 0.9454\n",
      "[244/1762] D loss: 1.3891, G loss: 0.6653\n",
      "[324/1762] D loss: 1.3812, G loss: 0.7163\n",
      "[404/1762] D loss: 1.3899, G loss: 0.6497\n",
      "[484/1762] D loss: 1.3720, G loss: 0.7242\n",
      "[564/1762] D loss: 1.3901, G loss: 0.7143\n",
      "[644/1762] D loss: 1.0552, G loss: 0.9049\n",
      "[724/1762] D loss: 1.3799, G loss: 0.7144\n",
      "[804/1762] D loss: 1.4695, G loss: 0.6159\n",
      "[884/1762] D loss: 1.3762, G loss: 0.6483\n",
      "[964/1762] D loss: 1.3904, G loss: 0.6927\n",
      "[1044/1762] D loss: 1.3819, G loss: 0.6718\n",
      "[1124/1762] D loss: 1.4503, G loss: 0.8322\n",
      "[1204/1762] D loss: 0.9895, G loss: 0.9991\n",
      "[1284/1762] D loss: 1.3834, G loss: 0.7269\n",
      "[1364/1762] D loss: 1.6113, G loss: 0.7113\n",
      "[1444/1762] D loss: 0.9719, G loss: 0.9633\n",
      "[1524/1762] D loss: 0.9912, G loss: 0.9591\n",
      "[1604/1762] D loss: 1.4030, G loss: 0.7200\n",
      "[1684/1762] D loss: 1.4914, G loss: 0.6945\n",
      "[1762/1762] D loss: 1.0616, G loss: 1.1903\n",
      "train error: \n",
      " D loss: 1.478275, G loss: 1.234535, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.474237, G loss: 1.265736, D accuracy: 51.8%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4784, G loss: 0.6723\n",
      "[84/1762] D loss: 1.3854, G loss: 0.7482\n",
      "[164/1762] D loss: 1.4953, G loss: 0.6102\n",
      "[244/1762] D loss: 1.2320, G loss: 0.8069\n",
      "[324/1762] D loss: 1.4874, G loss: 1.0582\n",
      "[404/1762] D loss: 1.4802, G loss: 0.6756\n",
      "[484/1762] D loss: 1.2151, G loss: 0.8044\n",
      "[564/1762] D loss: 1.5694, G loss: 0.6052\n",
      "[644/1762] D loss: 1.2316, G loss: 0.7816\n",
      "[724/1762] D loss: 1.3891, G loss: 0.7262\n",
      "[804/1762] D loss: 1.0683, G loss: 0.9596\n",
      "[884/1762] D loss: 1.2766, G loss: 0.7313\n",
      "[964/1762] D loss: 1.4179, G loss: 0.6515\n",
      "[1044/1762] D loss: 0.9596, G loss: 1.0734\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.6483\n",
      "[1204/1762] D loss: 1.0382, G loss: 0.9899\n",
      "[1284/1762] D loss: 1.1164, G loss: 0.8699\n",
      "[1364/1762] D loss: 1.3458, G loss: 0.7715\n",
      "[1444/1762] D loss: 1.4235, G loss: 0.6715\n",
      "[1524/1762] D loss: 1.0430, G loss: 0.9961\n",
      "[1604/1762] D loss: 1.2270, G loss: 0.8269\n",
      "[1684/1762] D loss: 1.4018, G loss: 0.7193\n",
      "[1762/1762] D loss: 1.3529, G loss: 0.7249\n",
      "train error: \n",
      " D loss: 1.329751, G loss: 0.670558, D accuracy: 58.4%, cell accuracy: 99.7%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320398, G loss: 0.692762, D accuracy: 59.3%, cell accuracy: 99.6%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1334, G loss: 0.9140\n",
      "[84/1762] D loss: 1.3240, G loss: 0.7627\n",
      "[164/1762] D loss: 1.1006, G loss: 0.9164\n",
      "[244/1762] D loss: 1.3346, G loss: 0.8203\n",
      "[324/1762] D loss: 1.1680, G loss: 0.8363\n",
      "[404/1762] D loss: 1.3796, G loss: 0.6995\n",
      "[484/1762] D loss: 1.4159, G loss: 0.8113\n",
      "[564/1762] D loss: 1.3895, G loss: 0.7210\n",
      "[644/1762] D loss: 1.2149, G loss: 0.8640\n",
      "[724/1762] D loss: 1.2990, G loss: 0.6984\n",
      "[804/1762] D loss: 1.3939, G loss: 0.6570\n",
      "[884/1762] D loss: 1.4074, G loss: 0.7176\n",
      "[964/1762] D loss: 1.4041, G loss: 0.7347\n",
      "[1044/1762] D loss: 1.3788, G loss: 0.7919\n",
      "[1124/1762] D loss: 1.3946, G loss: 0.6906\n",
      "[1204/1762] D loss: 1.4016, G loss: 0.6714\n",
      "[1284/1762] D loss: 1.4067, G loss: 0.7134\n",
      "[1364/1762] D loss: 1.3945, G loss: 0.6647\n",
      "[1444/1762] D loss: 1.2563, G loss: 0.8142\n",
      "[1524/1762] D loss: 1.3797, G loss: 0.7256\n",
      "[1604/1762] D loss: 0.9121, G loss: 1.1195\n",
      "[1684/1762] D loss: 1.4165, G loss: 0.6912\n",
      "[1762/1762] D loss: 1.3712, G loss: 0.7015\n",
      "train error: \n",
      " D loss: 1.341791, G loss: 0.717673, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331604, G loss: 0.726981, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5192, G loss: 0.7885\n",
      "[84/1762] D loss: 1.3929, G loss: 0.7691\n",
      "[164/1762] D loss: 1.5229, G loss: 0.5758\n",
      "[244/1762] D loss: 1.3812, G loss: 0.6426\n",
      "[324/1762] D loss: 1.3793, G loss: 0.6156\n",
      "[404/1762] D loss: 1.3915, G loss: 0.6577\n",
      "[484/1762] D loss: 1.3964, G loss: 0.7095\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6882\n",
      "[644/1762] D loss: 1.3994, G loss: 0.6277\n",
      "[724/1762] D loss: 1.3926, G loss: 0.7162\n",
      "[804/1762] D loss: 1.2618, G loss: 0.7996\n",
      "[884/1762] D loss: 1.5059, G loss: 0.6983\n",
      "[964/1762] D loss: 1.3881, G loss: 0.7229\n",
      "[1044/1762] D loss: 1.3783, G loss: 0.7081\n",
      "[1124/1762] D loss: 1.3975, G loss: 0.7196\n",
      "[1204/1762] D loss: 1.4135, G loss: 0.6645\n",
      "[1284/1762] D loss: 1.3754, G loss: 0.7135\n",
      "[1364/1762] D loss: 1.3752, G loss: 0.7400\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.5825\n",
      "[1524/1762] D loss: 0.7508, G loss: 1.3476\n",
      "[1604/1762] D loss: 1.5015, G loss: 0.7063\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6991\n",
      "[1762/1762] D loss: 0.7635, G loss: 1.2806\n",
      "train error: \n",
      " D loss: 1.337780, G loss: 0.815704, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328309, G loss: 0.838816, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5819, G loss: 0.3639\n",
      "[84/1762] D loss: 1.1560, G loss: 0.8463\n",
      "[164/1762] D loss: 1.5742, G loss: 0.6526\n",
      "[244/1762] D loss: 1.3550, G loss: 0.7183\n",
      "[324/1762] D loss: 1.1904, G loss: 0.7730\n",
      "[404/1762] D loss: 1.3590, G loss: 0.7115\n",
      "[484/1762] D loss: 0.8840, G loss: 1.1936\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6383\n",
      "[644/1762] D loss: 1.3908, G loss: 0.6745\n",
      "[724/1762] D loss: 1.3808, G loss: 0.7533\n",
      "[804/1762] D loss: 1.5067, G loss: 0.7600\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6963\n",
      "[964/1762] D loss: 1.6579, G loss: 0.7205\n",
      "[1044/1762] D loss: 1.6220, G loss: 0.6183\n",
      "[1124/1762] D loss: 1.3804, G loss: 0.6788\n",
      "[1204/1762] D loss: 1.1676, G loss: 0.7839\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.6649\n",
      "[1364/1762] D loss: 1.3935, G loss: 0.7337\n",
      "[1444/1762] D loss: 0.9677, G loss: 1.0672\n",
      "[1524/1762] D loss: 1.8583, G loss: 0.8194\n",
      "[1604/1762] D loss: 1.3177, G loss: 0.8203\n",
      "[1684/1762] D loss: 1.4035, G loss: 0.7389\n",
      "[1762/1762] D loss: 1.0737, G loss: 1.0760\n",
      "train error: \n",
      " D loss: 1.325243, G loss: 0.871348, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 78.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309326, G loss: 0.897480, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4092, G loss: 0.7172\n",
      "[84/1762] D loss: 1.4333, G loss: 0.7263\n",
      "[164/1762] D loss: 1.2367, G loss: 0.7806\n",
      "[244/1762] D loss: 1.2533, G loss: 0.8380\n",
      "[324/1762] D loss: 1.3954, G loss: 0.7083\n",
      "[404/1762] D loss: 1.1550, G loss: 0.8718\n",
      "[484/1762] D loss: 1.3842, G loss: 0.7956\n",
      "[564/1762] D loss: 1.5173, G loss: 0.7014\n",
      "[644/1762] D loss: 0.9458, G loss: 1.1035\n",
      "[724/1762] D loss: 1.2023, G loss: 0.8169\n",
      "[804/1762] D loss: 1.2461, G loss: 0.7746\n",
      "[884/1762] D loss: 1.2968, G loss: 0.7259\n",
      "[964/1762] D loss: 1.3745, G loss: 0.7061\n",
      "[1044/1762] D loss: 1.3949, G loss: 0.7285\n",
      "[1124/1762] D loss: 1.4186, G loss: 0.7590\n",
      "[1204/1762] D loss: 1.2670, G loss: 0.8997\n",
      "[1284/1762] D loss: 1.2271, G loss: 0.8618\n",
      "[1364/1762] D loss: 1.3802, G loss: 0.7631\n",
      "[1444/1762] D loss: 1.0175, G loss: 1.0307\n",
      "[1524/1762] D loss: 1.4215, G loss: 0.7463\n",
      "[1604/1762] D loss: 1.3739, G loss: 0.7140\n",
      "[1684/1762] D loss: 1.3735, G loss: 0.6586\n",
      "[1762/1762] D loss: 1.4544, G loss: 0.7240\n",
      "train error: \n",
      " D loss: 1.327353, G loss: 0.815747, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320024, G loss: 0.820258, D accuracy: 57.7%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3501, G loss: 0.7064\n",
      "[84/1762] D loss: 0.9603, G loss: 1.0662\n",
      "[164/1762] D loss: 1.3836, G loss: 0.6794\n",
      "[244/1762] D loss: 1.3591, G loss: 0.7660\n",
      "[324/1762] D loss: 1.3795, G loss: 0.7093\n",
      "[404/1762] D loss: 0.8495, G loss: 1.1600\n",
      "[484/1762] D loss: 1.2010, G loss: 1.0553\n",
      "[564/1762] D loss: 1.4628, G loss: 0.5542\n",
      "[644/1762] D loss: 1.3810, G loss: 0.6943\n",
      "[724/1762] D loss: 1.4318, G loss: 0.6629\n",
      "[804/1762] D loss: 1.4415, G loss: 0.7088\n",
      "[884/1762] D loss: 1.3567, G loss: 0.6133\n",
      "[964/1762] D loss: 1.3154, G loss: 0.7169\n",
      "[1044/1762] D loss: 1.4751, G loss: 0.6396\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.7262\n",
      "[1204/1762] D loss: 1.1216, G loss: 1.1415\n",
      "[1284/1762] D loss: 1.2928, G loss: 0.7351\n",
      "[1364/1762] D loss: 1.3655, G loss: 0.6836\n",
      "[1444/1762] D loss: 1.3435, G loss: 0.9915\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.6652\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.6402\n",
      "[1684/1762] D loss: 1.5332, G loss: 0.6142\n",
      "[1762/1762] D loss: 0.7148, G loss: 1.4084\n",
      "train error: \n",
      " D loss: 1.288989, G loss: 0.793854, D accuracy: 60.7%, cell accuracy: 99.6%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290583, G loss: 0.794873, D accuracy: 60.1%, cell accuracy: 99.6%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3970, G loss: 0.7636\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6818\n",
      "[164/1762] D loss: 1.0454, G loss: 0.9199\n",
      "[244/1762] D loss: 1.3789, G loss: 0.7366\n",
      "[324/1762] D loss: 1.2801, G loss: 0.8237\n",
      "[404/1762] D loss: 1.1615, G loss: 0.8238\n",
      "[484/1762] D loss: 1.1906, G loss: 0.8486\n",
      "[564/1762] D loss: 1.3813, G loss: 0.6771\n",
      "[644/1762] D loss: 1.3748, G loss: 0.6751\n",
      "[724/1762] D loss: 1.0424, G loss: 1.0064\n",
      "[804/1762] D loss: 1.4073, G loss: 0.7169\n",
      "[884/1762] D loss: 1.0204, G loss: 1.0014\n",
      "[964/1762] D loss: 1.3948, G loss: 0.7445\n",
      "[1044/1762] D loss: 1.3814, G loss: 0.7221\n",
      "[1124/1762] D loss: 1.3852, G loss: 0.7243\n",
      "[1204/1762] D loss: 1.3787, G loss: 0.7478\n",
      "[1284/1762] D loss: 1.3855, G loss: 0.6994\n",
      "[1364/1762] D loss: 1.3850, G loss: 0.7027\n",
      "[1444/1762] D loss: 1.3598, G loss: 0.7034\n",
      "[1524/1762] D loss: 1.3734, G loss: 0.7721\n",
      "[1604/1762] D loss: 1.4093, G loss: 0.6789\n",
      "[1684/1762] D loss: 1.3780, G loss: 0.6820\n",
      "[1762/1762] D loss: 1.1103, G loss: 1.0288\n",
      "train error: \n",
      " D loss: 1.257630, G loss: 0.809226, D accuracy: 63.8%, cell accuracy: 99.5%, board accuracy: 69.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.240734, G loss: 0.834417, D accuracy: 64.8%, cell accuracy: 99.4%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2115, G loss: 0.9414\n",
      "[84/1762] D loss: 1.2980, G loss: 0.7070\n",
      "[164/1762] D loss: 1.4004, G loss: 0.6717\n",
      "[244/1762] D loss: 1.1893, G loss: 0.7940\n",
      "[324/1762] D loss: 1.4137, G loss: 0.7367\n",
      "[404/1762] D loss: 1.3836, G loss: 0.6829\n",
      "[484/1762] D loss: 1.4356, G loss: 0.5938\n",
      "[564/1762] D loss: 1.4017, G loss: 0.7311\n",
      "[644/1762] D loss: 1.4860, G loss: 0.5928\n",
      "[724/1762] D loss: 1.3858, G loss: 0.6719\n",
      "[804/1762] D loss: 1.4012, G loss: 0.6181\n",
      "[884/1762] D loss: 1.4090, G loss: 0.7080\n",
      "[964/1762] D loss: 1.3983, G loss: 0.7662\n",
      "[1044/1762] D loss: 1.3112, G loss: 0.8177\n",
      "[1124/1762] D loss: 1.3996, G loss: 0.7031\n",
      "[1204/1762] D loss: 1.0559, G loss: 0.9181\n",
      "[1284/1762] D loss: 1.3681, G loss: 0.7488\n",
      "[1364/1762] D loss: 1.2377, G loss: 0.8096\n",
      "[1444/1762] D loss: 1.3540, G loss: 0.7540\n",
      "[1524/1762] D loss: 1.4054, G loss: 0.6537\n",
      "[1604/1762] D loss: 1.4016, G loss: 0.7072\n",
      "[1684/1762] D loss: 1.0143, G loss: 0.9490\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.6773\n",
      "train error: \n",
      " D loss: 1.334860, G loss: 0.698904, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318992, G loss: 0.718527, D accuracy: 58.5%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.7108\n",
      "[84/1762] D loss: 1.1135, G loss: 0.8651\n",
      "[164/1762] D loss: 1.0143, G loss: 0.8971\n",
      "[244/1762] D loss: 1.4045, G loss: 0.6225\n",
      "[324/1762] D loss: 1.4407, G loss: 0.6666\n",
      "[404/1762] D loss: 1.4073, G loss: 0.6834\n",
      "[484/1762] D loss: 1.3863, G loss: 0.7037\n",
      "[564/1762] D loss: 1.3950, G loss: 0.7013\n",
      "[644/1762] D loss: 1.4153, G loss: 0.6783\n",
      "[724/1762] D loss: 0.8454, G loss: 1.1166\n",
      "[804/1762] D loss: 1.4145, G loss: 0.6778\n",
      "[884/1762] D loss: 1.3805, G loss: 0.6929\n",
      "[964/1762] D loss: 1.3876, G loss: 0.7030\n",
      "[1044/1762] D loss: 1.3721, G loss: 0.6730\n",
      "[1124/1762] D loss: 1.0051, G loss: 0.9895\n",
      "[1204/1762] D loss: 1.4366, G loss: 0.7108\n",
      "[1284/1762] D loss: 1.3569, G loss: 0.7294\n",
      "[1364/1762] D loss: 1.3933, G loss: 0.7193\n",
      "[1444/1762] D loss: 1.5198, G loss: 0.6560\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6668\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.6913\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.7043\n",
      "[1762/1762] D loss: 1.4859, G loss: 0.6396\n",
      "train error: \n",
      " D loss: 1.337817, G loss: 0.628406, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322658, G loss: 0.641822, D accuracy: 59.3%, cell accuracy: 99.6%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3996, G loss: 0.7201\n",
      "[84/1762] D loss: 1.4212, G loss: 0.6371\n",
      "[164/1762] D loss: 1.4028, G loss: 0.8407\n",
      "[244/1762] D loss: 1.4661, G loss: 0.5471\n",
      "[324/1762] D loss: 1.0415, G loss: 0.9903\n",
      "[404/1762] D loss: 1.3919, G loss: 0.6697\n",
      "[484/1762] D loss: 1.5016, G loss: 0.6745\n",
      "[564/1762] D loss: 1.4416, G loss: 0.6926\n",
      "[644/1762] D loss: 1.4028, G loss: 0.6972\n",
      "[724/1762] D loss: 1.3759, G loss: 0.7472\n",
      "[804/1762] D loss: 1.3841, G loss: 0.6540\n",
      "[884/1762] D loss: 1.3850, G loss: 0.7160\n",
      "[964/1762] D loss: 0.5704, G loss: 1.5176\n",
      "[1044/1762] D loss: 1.3959, G loss: 0.7291\n",
      "[1124/1762] D loss: 1.0863, G loss: 1.0404\n",
      "[1204/1762] D loss: 1.3943, G loss: 0.6478\n",
      "[1284/1762] D loss: 1.1177, G loss: 0.9443\n",
      "[1364/1762] D loss: 1.0383, G loss: 1.0048\n",
      "[1444/1762] D loss: 1.1555, G loss: 0.8175\n",
      "[1524/1762] D loss: 1.4342, G loss: 0.6850\n",
      "[1604/1762] D loss: 1.3468, G loss: 0.7052\n",
      "[1684/1762] D loss: 1.3974, G loss: 0.6706\n",
      "[1762/1762] D loss: 0.6433, G loss: 1.3969\n",
      "train error: \n",
      " D loss: 1.327118, G loss: 0.770789, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313302, G loss: 0.782394, D accuracy: 58.0%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3955, G loss: 0.6928\n",
      "[84/1762] D loss: 1.3976, G loss: 0.6848\n",
      "[164/1762] D loss: 1.0940, G loss: 0.6809\n",
      "[244/1762] D loss: 1.4514, G loss: 0.6725\n",
      "[324/1762] D loss: 1.6855, G loss: 0.7299\n",
      "[404/1762] D loss: 1.1296, G loss: 0.8616\n",
      "[484/1762] D loss: 1.5399, G loss: 0.6738\n",
      "[564/1762] D loss: 1.4325, G loss: 0.8120\n",
      "[644/1762] D loss: 1.3930, G loss: 0.6582\n",
      "[724/1762] D loss: 1.3445, G loss: 0.6992\n",
      "[804/1762] D loss: 1.0139, G loss: 0.9472\n",
      "[884/1762] D loss: 1.3845, G loss: 0.7114\n",
      "[964/1762] D loss: 1.2460, G loss: 0.8226\n",
      "[1044/1762] D loss: 1.0766, G loss: 1.1262\n",
      "[1124/1762] D loss: 1.3945, G loss: 0.7376\n",
      "[1204/1762] D loss: 1.3462, G loss: 0.8463\n",
      "[1284/1762] D loss: 1.4010, G loss: 0.6215\n",
      "[1364/1762] D loss: 1.4023, G loss: 0.7287\n",
      "[1444/1762] D loss: 1.4187, G loss: 0.7077\n",
      "[1524/1762] D loss: 1.4029, G loss: 0.7763\n",
      "[1604/1762] D loss: 1.4004, G loss: 0.7963\n",
      "[1684/1762] D loss: 1.3672, G loss: 0.7109\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.7786\n",
      "train error: \n",
      " D loss: 1.320009, G loss: 0.801771, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309994, G loss: 0.807882, D accuracy: 56.5%, cell accuracy: 99.6%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0036, G loss: 0.9686\n",
      "[84/1762] D loss: 1.1346, G loss: 0.9009\n",
      "[164/1762] D loss: 1.3682, G loss: 0.7289\n",
      "[244/1762] D loss: 1.1812, G loss: 0.8511\n",
      "[324/1762] D loss: 1.3922, G loss: 0.7093\n",
      "[404/1762] D loss: 0.9193, G loss: 1.0873\n",
      "[484/1762] D loss: 1.1312, G loss: 0.9450\n",
      "[564/1762] D loss: 1.3793, G loss: 0.6937\n",
      "[644/1762] D loss: 1.3754, G loss: 0.7263\n",
      "[724/1762] D loss: 1.2045, G loss: 0.8004\n",
      "[804/1762] D loss: 1.2975, G loss: 0.6183\n",
      "[884/1762] D loss: 1.3310, G loss: 0.7682\n",
      "[964/1762] D loss: 1.4022, G loss: 0.6673\n",
      "[1044/1762] D loss: 1.3024, G loss: 0.6738\n",
      "[1124/1762] D loss: 1.3542, G loss: 0.7462\n",
      "[1204/1762] D loss: 1.3176, G loss: 0.8315\n",
      "[1284/1762] D loss: 1.3413, G loss: 0.7823\n",
      "[1364/1762] D loss: 1.2669, G loss: 0.9073\n",
      "[1444/1762] D loss: 1.2912, G loss: 0.7583\n",
      "[1524/1762] D loss: 1.3793, G loss: 0.6678\n",
      "[1604/1762] D loss: 1.4158, G loss: 0.7291\n",
      "[1684/1762] D loss: 1.4135, G loss: 0.7201\n",
      "[1762/1762] D loss: 1.5247, G loss: 0.7876\n",
      "train error: \n",
      " D loss: 1.434310, G loss: 1.144626, D accuracy: 51.8%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.427924, G loss: 1.157055, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1627, G loss: 0.8927\n",
      "[84/1762] D loss: 1.0497, G loss: 0.9838\n",
      "[164/1762] D loss: 1.3688, G loss: 0.7592\n",
      "[244/1762] D loss: 1.0827, G loss: 0.8823\n",
      "[324/1762] D loss: 1.3903, G loss: 0.6783\n",
      "[404/1762] D loss: 1.3998, G loss: 0.7248\n",
      "[484/1762] D loss: 1.1299, G loss: 0.9126\n",
      "[564/1762] D loss: 1.3408, G loss: 0.6990\n",
      "[644/1762] D loss: 1.4511, G loss: 0.6095\n",
      "[724/1762] D loss: 1.6472, G loss: 0.7027\n",
      "[804/1762] D loss: 1.3799, G loss: 0.6609\n",
      "[884/1762] D loss: 1.4050, G loss: 0.7375\n",
      "[964/1762] D loss: 1.4332, G loss: 0.8209\n",
      "[1044/1762] D loss: 1.3766, G loss: 0.7327\n",
      "[1124/1762] D loss: 1.2586, G loss: 0.7121\n",
      "[1204/1762] D loss: 1.3945, G loss: 0.7021\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.7461\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6475\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.7611\n",
      "[1524/1762] D loss: 1.3802, G loss: 0.7194\n",
      "[1604/1762] D loss: 1.1719, G loss: 1.0204\n",
      "[1684/1762] D loss: 1.3760, G loss: 0.6982\n",
      "[1762/1762] D loss: 1.0273, G loss: 0.9390\n",
      "train error: \n",
      " D loss: 1.339994, G loss: 0.776958, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331736, G loss: 0.789193, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3502, G loss: 0.7711\n",
      "[84/1762] D loss: 1.4144, G loss: 0.6461\n",
      "[164/1762] D loss: 1.3909, G loss: 0.6680\n",
      "[244/1762] D loss: 1.3915, G loss: 0.6864\n",
      "[324/1762] D loss: 1.3801, G loss: 0.7185\n",
      "[404/1762] D loss: 1.3593, G loss: 0.7168\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6595\n",
      "[564/1762] D loss: 1.3793, G loss: 0.6456\n",
      "[644/1762] D loss: 1.4105, G loss: 0.6428\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6920\n",
      "[804/1762] D loss: 1.3236, G loss: 0.7963\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6775\n",
      "[964/1762] D loss: 1.3815, G loss: 0.6995\n",
      "[1044/1762] D loss: 1.4020, G loss: 0.6535\n",
      "[1124/1762] D loss: 1.0568, G loss: 0.9947\n",
      "[1204/1762] D loss: 1.3782, G loss: 0.6696\n",
      "[1284/1762] D loss: 1.5282, G loss: 0.6411\n",
      "[1364/1762] D loss: 1.4576, G loss: 0.6820\n",
      "[1444/1762] D loss: 1.2146, G loss: 0.7773\n",
      "[1524/1762] D loss: 1.3522, G loss: 0.8258\n",
      "[1604/1762] D loss: 1.4095, G loss: 0.6604\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.7471\n",
      "[1762/1762] D loss: 1.3445, G loss: 0.7252\n",
      "train error: \n",
      " D loss: 1.357117, G loss: 0.869122, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350156, G loss: 0.881845, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3829, G loss: 0.6406\n",
      "[84/1762] D loss: 1.1862, G loss: 0.8895\n",
      "[164/1762] D loss: 1.3821, G loss: 0.8349\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7215\n",
      "[324/1762] D loss: 1.2520, G loss: 0.9326\n",
      "[404/1762] D loss: 1.3811, G loss: 0.6306\n",
      "[484/1762] D loss: 1.4074, G loss: 0.7382\n",
      "[564/1762] D loss: 1.0526, G loss: 0.9270\n",
      "[644/1762] D loss: 1.3905, G loss: 0.6684\n",
      "[724/1762] D loss: 1.4289, G loss: 0.7678\n",
      "[804/1762] D loss: 1.3838, G loss: 0.6209\n",
      "[884/1762] D loss: 1.3963, G loss: 0.6983\n",
      "[964/1762] D loss: 1.0188, G loss: 1.0477\n",
      "[1044/1762] D loss: 0.9632, G loss: 1.2849\n",
      "[1124/1762] D loss: 1.1053, G loss: 1.0475\n",
      "[1204/1762] D loss: 1.4762, G loss: 0.6791\n",
      "[1284/1762] D loss: 1.6013, G loss: 0.5933\n",
      "[1364/1762] D loss: 1.4084, G loss: 0.6793\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.7098\n",
      "[1524/1762] D loss: 1.3722, G loss: 0.7295\n",
      "[1604/1762] D loss: 1.3987, G loss: 0.6680\n",
      "[1684/1762] D loss: 1.6475, G loss: 0.6460\n",
      "[1762/1762] D loss: 1.4579, G loss: 0.7388\n",
      "train error: \n",
      " D loss: 1.311087, G loss: 0.745707, D accuracy: 58.5%, cell accuracy: 99.7%, board accuracy: 79.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291849, G loss: 0.775980, D accuracy: 59.4%, cell accuracy: 99.6%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4335, G loss: 0.7434\n",
      "[84/1762] D loss: 0.9416, G loss: 1.2683\n",
      "[164/1762] D loss: 1.3430, G loss: 0.7367\n",
      "[244/1762] D loss: 0.8221, G loss: 1.2513\n",
      "[324/1762] D loss: 1.3771, G loss: 0.7489\n",
      "[404/1762] D loss: 1.1583, G loss: 0.8420\n",
      "[484/1762] D loss: 1.3686, G loss: 0.7162\n",
      "[564/1762] D loss: 1.3399, G loss: 0.6488\n",
      "[644/1762] D loss: 1.3390, G loss: 0.7512\n",
      "[724/1762] D loss: 1.3804, G loss: 0.6834\n",
      "[804/1762] D loss: 1.1434, G loss: 0.7575\n",
      "[884/1762] D loss: 1.2598, G loss: 0.7696\n",
      "[964/1762] D loss: 1.3450, G loss: 0.7352\n",
      "[1044/1762] D loss: 1.3380, G loss: 0.7180\n",
      "[1124/1762] D loss: 1.3949, G loss: 0.6402\n",
      "[1204/1762] D loss: 1.3852, G loss: 0.7177\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.7064\n",
      "[1364/1762] D loss: 1.3921, G loss: 0.7028\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.6963\n",
      "[1524/1762] D loss: 1.4088, G loss: 0.6474\n",
      "[1604/1762] D loss: 1.3970, G loss: 0.6351\n",
      "[1684/1762] D loss: 1.4209, G loss: 0.6034\n",
      "[1762/1762] D loss: 1.3567, G loss: 0.8485\n",
      "train error: \n",
      " D loss: 1.316290, G loss: 0.869920, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305800, G loss: 0.885354, D accuracy: 55.9%, cell accuracy: 99.6%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3808, G loss: 0.6717\n",
      "[84/1762] D loss: 1.4004, G loss: 0.7683\n",
      "[164/1762] D loss: 1.4000, G loss: 0.7823\n",
      "[244/1762] D loss: 1.3927, G loss: 0.6611\n",
      "[324/1762] D loss: 1.3942, G loss: 0.6507\n",
      "[404/1762] D loss: 1.3888, G loss: 0.7134\n",
      "[484/1762] D loss: 1.6976, G loss: 1.1321\n",
      "[564/1762] D loss: 1.3843, G loss: 0.7244\n",
      "[644/1762] D loss: 1.2774, G loss: 1.0193\n",
      "[724/1762] D loss: 1.3857, G loss: 0.7142\n",
      "[804/1762] D loss: 1.3445, G loss: 0.8549\n",
      "[884/1762] D loss: 1.1243, G loss: 0.8895\n",
      "[964/1762] D loss: 1.3248, G loss: 0.9095\n",
      "[1044/1762] D loss: 1.5135, G loss: 0.5501\n",
      "[1124/1762] D loss: 1.4214, G loss: 0.6817\n",
      "[1204/1762] D loss: 1.2155, G loss: 0.8586\n",
      "[1284/1762] D loss: 1.2949, G loss: 0.8502\n",
      "[1364/1762] D loss: 1.1638, G loss: 0.9181\n",
      "[1444/1762] D loss: 1.4116, G loss: 0.8111\n",
      "[1524/1762] D loss: 0.9584, G loss: 1.0389\n",
      "[1604/1762] D loss: 1.4010, G loss: 0.6562\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6534\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.7471\n",
      "train error: \n",
      " D loss: 1.328359, G loss: 0.798532, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314790, G loss: 0.816844, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4117, G loss: 0.6249\n",
      "[84/1762] D loss: 1.4961, G loss: 0.7696\n",
      "[164/1762] D loss: 1.3802, G loss: 0.7167\n",
      "[244/1762] D loss: 1.1725, G loss: 0.7966\n",
      "[324/1762] D loss: 1.2552, G loss: 0.8163\n",
      "[404/1762] D loss: 1.3886, G loss: 0.6121\n",
      "[484/1762] D loss: 1.3917, G loss: 0.7037\n",
      "[564/1762] D loss: 1.4179, G loss: 0.9154\n",
      "[644/1762] D loss: 1.4338, G loss: 0.5868\n",
      "[724/1762] D loss: 1.3300, G loss: 0.7539\n",
      "[804/1762] D loss: 1.4103, G loss: 0.6052\n",
      "[884/1762] D loss: 1.4626, G loss: 0.5824\n",
      "[964/1762] D loss: 1.4699, G loss: 0.7917\n",
      "[1044/1762] D loss: 1.0966, G loss: 0.9504\n",
      "[1124/1762] D loss: 1.2978, G loss: 0.7467\n",
      "[1204/1762] D loss: 1.3170, G loss: 0.7095\n",
      "[1284/1762] D loss: 1.4093, G loss: 0.6390\n",
      "[1364/1762] D loss: 1.4031, G loss: 0.6983\n",
      "[1444/1762] D loss: 1.4450, G loss: 0.6098\n",
      "[1524/1762] D loss: 1.0965, G loss: 0.9481\n",
      "[1604/1762] D loss: 1.1886, G loss: 0.8933\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.6988\n",
      "[1762/1762] D loss: 1.3808, G loss: 0.6835\n",
      "train error: \n",
      " D loss: 1.342685, G loss: 0.889962, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331809, G loss: 0.916056, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4032, G loss: 0.6054\n",
      "[84/1762] D loss: 1.3787, G loss: 0.6823\n",
      "[164/1762] D loss: 1.3742, G loss: 0.7870\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6765\n",
      "[324/1762] D loss: 1.1929, G loss: 0.8009\n",
      "[404/1762] D loss: 1.1885, G loss: 0.8160\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7145\n",
      "[564/1762] D loss: 1.0707, G loss: 0.9804\n",
      "[644/1762] D loss: 1.3163, G loss: 0.6515\n",
      "[724/1762] D loss: 1.3832, G loss: 0.7137\n",
      "[804/1762] D loss: 1.1217, G loss: 1.0403\n",
      "[884/1762] D loss: 1.3886, G loss: 0.6838\n",
      "[964/1762] D loss: 1.2971, G loss: 0.8243\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.6656\n",
      "[1124/1762] D loss: 1.1498, G loss: 0.8838\n",
      "[1204/1762] D loss: 1.3276, G loss: 0.7269\n",
      "[1284/1762] D loss: 1.2205, G loss: 0.7939\n",
      "[1364/1762] D loss: 1.5119, G loss: 0.6648\n",
      "[1444/1762] D loss: 1.4172, G loss: 0.8100\n",
      "[1524/1762] D loss: 1.3506, G loss: 0.7959\n",
      "[1604/1762] D loss: 1.4119, G loss: 0.7613\n",
      "[1684/1762] D loss: 1.3824, G loss: 0.6508\n",
      "[1762/1762] D loss: 1.4359, G loss: 0.7673\n",
      "train error: \n",
      " D loss: 1.385396, G loss: 1.182891, D accuracy: 50.5%, cell accuracy: 99.5%, board accuracy: 71.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379291, G loss: 1.221789, D accuracy: 50.8%, cell accuracy: 99.4%, board accuracy: 68.2% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3196, G loss: 0.6772\n",
      "[84/1762] D loss: 1.3847, G loss: 0.7014\n",
      "[164/1762] D loss: 1.4300, G loss: 0.8409\n",
      "[244/1762] D loss: 1.2362, G loss: 0.8506\n",
      "[324/1762] D loss: 1.3381, G loss: 0.7609\n",
      "[404/1762] D loss: 1.3245, G loss: 0.8695\n",
      "[484/1762] D loss: 1.3967, G loss: 0.7583\n",
      "[564/1762] D loss: 1.3443, G loss: 0.8175\n",
      "[644/1762] D loss: 1.0832, G loss: 0.8725\n",
      "[724/1762] D loss: 1.3895, G loss: 0.7913\n",
      "[804/1762] D loss: 1.4040, G loss: 0.5982\n",
      "[884/1762] D loss: 1.4829, G loss: 0.6333\n",
      "[964/1762] D loss: 1.1493, G loss: 0.8772\n",
      "[1044/1762] D loss: 1.3978, G loss: 0.7260\n",
      "[1124/1762] D loss: 1.3851, G loss: 0.7045\n",
      "[1204/1762] D loss: 0.9783, G loss: 1.0176\n",
      "[1284/1762] D loss: 1.4290, G loss: 0.6543\n",
      "[1364/1762] D loss: 1.2697, G loss: 0.9146\n",
      "[1444/1762] D loss: 1.3849, G loss: 0.6822\n",
      "[1524/1762] D loss: 1.3065, G loss: 0.8132\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.7083\n",
      "[1684/1762] D loss: 0.7762, G loss: 1.2677\n",
      "[1762/1762] D loss: 1.3854, G loss: 0.6836\n",
      "train error: \n",
      " D loss: 1.338158, G loss: 0.775706, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332704, G loss: 0.781661, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1486, G loss: 0.8314\n",
      "[84/1762] D loss: 1.3945, G loss: 0.6915\n",
      "[164/1762] D loss: 1.2798, G loss: 0.8043\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6952\n",
      "[324/1762] D loss: 1.4438, G loss: 0.6972\n",
      "[404/1762] D loss: 0.9685, G loss: 1.0458\n",
      "[484/1762] D loss: 1.4060, G loss: 0.7098\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[644/1762] D loss: 1.2077, G loss: 0.8396\n",
      "[724/1762] D loss: 1.3833, G loss: 0.7303\n",
      "[804/1762] D loss: 0.9628, G loss: 1.0668\n",
      "[884/1762] D loss: 1.3729, G loss: 0.6967\n",
      "[964/1762] D loss: 1.3828, G loss: 0.7048\n",
      "[1044/1762] D loss: 1.0261, G loss: 0.9297\n",
      "[1124/1762] D loss: 1.3797, G loss: 0.7695\n",
      "[1204/1762] D loss: 1.3771, G loss: 0.7516\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6837\n",
      "[1364/1762] D loss: 1.4011, G loss: 0.6951\n",
      "[1444/1762] D loss: 1.4870, G loss: 0.8938\n",
      "[1524/1762] D loss: 1.3849, G loss: 0.7106\n",
      "[1604/1762] D loss: 1.4016, G loss: 0.6880\n",
      "[1684/1762] D loss: 0.9193, G loss: 1.0929\n",
      "[1762/1762] D loss: 1.0445, G loss: 0.9596\n",
      "train error: \n",
      " D loss: 1.453802, G loss: 0.446847, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.435995, G loss: 0.463193, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4458, G loss: 0.8059\n",
      "[84/1762] D loss: 1.4160, G loss: 0.6736\n",
      "[164/1762] D loss: 1.2893, G loss: 0.8249\n",
      "[244/1762] D loss: 1.3183, G loss: 0.9611\n",
      "[324/1762] D loss: 1.3804, G loss: 0.8698\n",
      "[404/1762] D loss: 1.4308, G loss: 0.7238\n",
      "[484/1762] D loss: 1.1015, G loss: 0.9559\n",
      "[564/1762] D loss: 1.1567, G loss: 0.8422\n",
      "[644/1762] D loss: 1.3983, G loss: 0.6756\n",
      "[724/1762] D loss: 1.3811, G loss: 0.7050\n",
      "[804/1762] D loss: 1.3717, G loss: 0.8266\n",
      "[884/1762] D loss: 1.3199, G loss: 0.7639\n",
      "[964/1762] D loss: 1.4269, G loss: 0.7192\n",
      "[1044/1762] D loss: 1.1180, G loss: 1.0008\n",
      "[1124/1762] D loss: 1.3608, G loss: 0.8164\n",
      "[1204/1762] D loss: 1.2385, G loss: 0.9160\n",
      "[1284/1762] D loss: 1.4035, G loss: 0.7488\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.6811\n",
      "[1444/1762] D loss: 1.4063, G loss: 0.6237\n",
      "[1524/1762] D loss: 1.3931, G loss: 0.7828\n",
      "[1604/1762] D loss: 1.3733, G loss: 0.7370\n",
      "[1684/1762] D loss: 1.3931, G loss: 0.7173\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.6795\n",
      "train error: \n",
      " D loss: 1.317931, G loss: 0.704243, D accuracy: 58.6%, cell accuracy: 99.7%, board accuracy: 82.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308628, G loss: 0.715062, D accuracy: 59.0%, cell accuracy: 99.6%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3972, G loss: 0.7248\n",
      "[84/1762] D loss: 1.5245, G loss: 1.0337\n",
      "[164/1762] D loss: 1.3989, G loss: 0.5954\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6716\n",
      "[324/1762] D loss: 1.4081, G loss: 0.8164\n",
      "[404/1762] D loss: 1.3981, G loss: 0.8273\n",
      "[484/1762] D loss: 1.0975, G loss: 0.9043\n",
      "[564/1762] D loss: 1.3945, G loss: 0.7007\n",
      "[644/1762] D loss: 1.2063, G loss: 0.8577\n",
      "[724/1762] D loss: 1.0825, G loss: 0.9343\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6202\n",
      "[884/1762] D loss: 1.3944, G loss: 0.7611\n",
      "[964/1762] D loss: 1.4725, G loss: 0.6459\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6708\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7252\n",
      "[1204/1762] D loss: 1.0276, G loss: 0.9981\n",
      "[1284/1762] D loss: 1.4045, G loss: 0.6921\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7209\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.6577\n",
      "[1524/1762] D loss: 1.3829, G loss: 0.6986\n",
      "[1604/1762] D loss: 0.7707, G loss: 1.2733\n",
      "[1684/1762] D loss: 0.9791, G loss: 1.1527\n",
      "[1762/1762] D loss: 1.4440, G loss: 0.5856\n",
      "train error: \n",
      " D loss: 1.396366, G loss: 0.531301, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369555, G loss: 0.557090, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4619, G loss: 0.7745\n",
      "[84/1762] D loss: 1.4383, G loss: 0.7161\n",
      "[164/1762] D loss: 1.4109, G loss: 0.6907\n",
      "[244/1762] D loss: 1.4049, G loss: 0.6802\n",
      "[324/1762] D loss: 1.1030, G loss: 0.8594\n",
      "[404/1762] D loss: 1.3829, G loss: 0.7094\n",
      "[484/1762] D loss: 1.2763, G loss: 0.8426\n",
      "[564/1762] D loss: 0.9392, G loss: 1.1003\n",
      "[644/1762] D loss: 1.2086, G loss: 0.7669\n",
      "[724/1762] D loss: 1.6646, G loss: 0.6141\n",
      "[804/1762] D loss: 1.4020, G loss: 0.8134\n",
      "[884/1762] D loss: 1.3863, G loss: 0.7162\n",
      "[964/1762] D loss: 1.3919, G loss: 0.7004\n",
      "[1044/1762] D loss: 1.3694, G loss: 0.4868\n",
      "[1124/1762] D loss: 1.3729, G loss: 0.7562\n",
      "[1204/1762] D loss: 1.4321, G loss: 0.6778\n",
      "[1284/1762] D loss: 1.2462, G loss: 0.8453\n",
      "[1364/1762] D loss: 1.1604, G loss: 0.9049\n",
      "[1444/1762] D loss: 1.3391, G loss: 0.7231\n",
      "[1524/1762] D loss: 1.3978, G loss: 0.7492\n",
      "[1604/1762] D loss: 1.4474, G loss: 0.6749\n",
      "[1684/1762] D loss: 1.3772, G loss: 0.6888\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.7102\n",
      "train error: \n",
      " D loss: 1.321588, G loss: 0.729256, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313551, G loss: 0.744108, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6970\n",
      "[84/1762] D loss: 1.3940, G loss: 0.6776\n",
      "[164/1762] D loss: 1.4905, G loss: 0.5714\n",
      "[244/1762] D loss: 1.4183, G loss: 0.6514\n",
      "[324/1762] D loss: 1.3935, G loss: 0.7822\n",
      "[404/1762] D loss: 1.4740, G loss: 0.7461\n",
      "[484/1762] D loss: 1.1808, G loss: 0.7786\n",
      "[564/1762] D loss: 1.4235, G loss: 0.6995\n",
      "[644/1762] D loss: 1.4364, G loss: 0.7815\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7016\n",
      "[804/1762] D loss: 1.1848, G loss: 0.8935\n",
      "[884/1762] D loss: 1.2318, G loss: 0.9235\n",
      "[964/1762] D loss: 1.3956, G loss: 0.7907\n",
      "[1044/1762] D loss: 1.3980, G loss: 0.5920\n",
      "[1124/1762] D loss: 1.3690, G loss: 0.9214\n",
      "[1204/1762] D loss: 1.1831, G loss: 1.0989\n",
      "[1284/1762] D loss: 1.4034, G loss: 0.7247\n",
      "[1364/1762] D loss: 1.0385, G loss: 1.0414\n",
      "[1444/1762] D loss: 1.1975, G loss: 0.8057\n",
      "[1524/1762] D loss: 1.2780, G loss: 0.7581\n",
      "[1604/1762] D loss: 1.1377, G loss: 0.7980\n",
      "[1684/1762] D loss: 1.3235, G loss: 0.8414\n",
      "[1762/1762] D loss: 1.3841, G loss: 0.7286\n",
      "train error: \n",
      " D loss: 1.306799, G loss: 0.823854, D accuracy: 59.3%, cell accuracy: 99.5%, board accuracy: 72.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311527, G loss: 0.842894, D accuracy: 57.3%, cell accuracy: 99.6%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3510, G loss: 0.7873\n",
      "[84/1762] D loss: 1.0375, G loss: 1.0745\n",
      "[164/1762] D loss: 1.3929, G loss: 0.7013\n",
      "[244/1762] D loss: 1.3794, G loss: 0.6608\n",
      "[324/1762] D loss: 1.2731, G loss: 0.8522\n",
      "[404/1762] D loss: 1.4013, G loss: 0.7199\n",
      "[484/1762] D loss: 1.1486, G loss: 0.8332\n",
      "[564/1762] D loss: 1.3821, G loss: 0.6899\n",
      "[644/1762] D loss: 1.3826, G loss: 0.7159\n",
      "[724/1762] D loss: 1.3890, G loss: 0.6401\n",
      "[804/1762] D loss: 1.3932, G loss: 0.6507\n",
      "[884/1762] D loss: 1.4041, G loss: 0.7594\n",
      "[964/1762] D loss: 1.4061, G loss: 0.6974\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.7328\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.7073\n",
      "[1204/1762] D loss: 1.3911, G loss: 0.6835\n",
      "[1284/1762] D loss: 1.4774, G loss: 0.8003\n",
      "[1364/1762] D loss: 1.3810, G loss: 0.6712\n",
      "[1444/1762] D loss: 1.3144, G loss: 0.8596\n",
      "[1524/1762] D loss: 1.3449, G loss: 0.8839\n",
      "[1604/1762] D loss: 1.1586, G loss: 1.2271\n",
      "[1684/1762] D loss: 1.4240, G loss: 0.6578\n",
      "[1762/1762] D loss: 0.7514, G loss: 1.3492\n",
      "train error: \n",
      " D loss: 1.348822, G loss: 0.972275, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340638, G loss: 0.989079, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3275, G loss: 0.6790\n",
      "[84/1762] D loss: 1.2420, G loss: 0.8759\n",
      "[164/1762] D loss: 1.1146, G loss: 0.8817\n",
      "[244/1762] D loss: 1.2535, G loss: 0.7868\n",
      "[324/1762] D loss: 1.3793, G loss: 0.7199\n",
      "[404/1762] D loss: 1.4126, G loss: 0.7296\n",
      "[484/1762] D loss: 1.4221, G loss: 0.7198\n",
      "[564/1762] D loss: 1.3194, G loss: 0.7807\n",
      "[644/1762] D loss: 1.3724, G loss: 0.6863\n",
      "[724/1762] D loss: 1.3950, G loss: 0.6970\n",
      "[804/1762] D loss: 1.3966, G loss: 0.7078\n",
      "[884/1762] D loss: 1.3930, G loss: 0.6886\n",
      "[964/1762] D loss: 1.0471, G loss: 0.9577\n",
      "[1044/1762] D loss: 1.3601, G loss: 0.7523\n",
      "[1124/1762] D loss: 1.3959, G loss: 0.6884\n",
      "[1204/1762] D loss: 1.4591, G loss: 0.7247\n",
      "[1284/1762] D loss: 1.4144, G loss: 0.7259\n",
      "[1364/1762] D loss: 1.3790, G loss: 0.7230\n",
      "[1444/1762] D loss: 1.0378, G loss: 1.0183\n",
      "[1524/1762] D loss: 1.4706, G loss: 0.7381\n",
      "[1604/1762] D loss: 1.4852, G loss: 0.7039\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.5811\n",
      "[1762/1762] D loss: 1.3921, G loss: 0.7328\n",
      "train error: \n",
      " D loss: 1.323529, G loss: 0.741698, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306858, G loss: 0.767849, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2484, G loss: 0.7970\n",
      "[84/1762] D loss: 1.2026, G loss: 0.8950\n",
      "[164/1762] D loss: 1.3432, G loss: 0.7230\n",
      "[244/1762] D loss: 1.3883, G loss: 0.6711\n",
      "[324/1762] D loss: 1.0473, G loss: 1.0122\n",
      "[404/1762] D loss: 1.3850, G loss: 0.6879\n",
      "[484/1762] D loss: 1.4263, G loss: 0.6921\n",
      "[564/1762] D loss: 0.9987, G loss: 0.9877\n",
      "[644/1762] D loss: 1.2483, G loss: 0.8134\n",
      "[724/1762] D loss: 1.4289, G loss: 0.6948\n",
      "[804/1762] D loss: 0.9919, G loss: 1.1231\n",
      "[884/1762] D loss: 1.3840, G loss: 0.7282\n",
      "[964/1762] D loss: 1.3853, G loss: 0.6917\n",
      "[1044/1762] D loss: 1.3923, G loss: 0.7817\n",
      "[1124/1762] D loss: 0.8074, G loss: 1.1620\n",
      "[1204/1762] D loss: 1.3859, G loss: 0.6777\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.6996\n",
      "[1364/1762] D loss: 1.3905, G loss: 0.6797\n",
      "[1444/1762] D loss: 1.3169, G loss: 0.6780\n",
      "[1524/1762] D loss: 1.4056, G loss: 0.6188\n",
      "[1604/1762] D loss: 1.2655, G loss: 0.7295\n",
      "[1684/1762] D loss: 1.4330, G loss: 0.6447\n",
      "[1762/1762] D loss: 1.3929, G loss: 0.7311\n",
      "train error: \n",
      " D loss: 1.305723, G loss: 0.820732, D accuracy: 57.9%, cell accuracy: 99.7%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290606, G loss: 0.850094, D accuracy: 58.5%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.7010\n",
      "[84/1762] D loss: 1.3933, G loss: 0.7213\n",
      "[164/1762] D loss: 1.3914, G loss: 0.7119\n",
      "[244/1762] D loss: 1.3997, G loss: 0.5988\n",
      "[324/1762] D loss: 1.3505, G loss: 0.7735\n",
      "[404/1762] D loss: 1.4180, G loss: 0.6389\n",
      "[484/1762] D loss: 1.4048, G loss: 0.6682\n",
      "[564/1762] D loss: 1.3994, G loss: 0.6879\n",
      "[644/1762] D loss: 0.6333, G loss: 1.5566\n",
      "[724/1762] D loss: 1.4440, G loss: 0.6877\n",
      "[804/1762] D loss: 0.9986, G loss: 1.1220\n",
      "[884/1762] D loss: 0.9868, G loss: 1.0660\n",
      "[964/1762] D loss: 1.4479, G loss: 0.7383\n",
      "[1044/1762] D loss: 1.4534, G loss: 0.7188\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.7153\n",
      "[1204/1762] D loss: 1.3827, G loss: 0.7074\n",
      "[1284/1762] D loss: 1.4189, G loss: 0.7811\n",
      "[1364/1762] D loss: 1.5012, G loss: 0.8353\n",
      "[1444/1762] D loss: 1.4278, G loss: 0.6605\n",
      "[1524/1762] D loss: 1.0255, G loss: 1.0733\n",
      "[1604/1762] D loss: 1.3805, G loss: 0.7825\n",
      "[1684/1762] D loss: 1.3855, G loss: 0.7502\n",
      "[1762/1762] D loss: 1.3942, G loss: 0.6725\n",
      "train error: \n",
      " D loss: 1.319681, G loss: 0.670196, D accuracy: 57.2%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304234, G loss: 0.684305, D accuracy: 58.0%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3673, G loss: 0.7331\n",
      "[84/1762] D loss: 1.3699, G loss: 0.7496\n",
      "[164/1762] D loss: 0.8687, G loss: 1.2249\n",
      "[244/1762] D loss: 1.4127, G loss: 0.6478\n",
      "[324/1762] D loss: 0.6264, G loss: 1.5040\n",
      "[404/1762] D loss: 1.3493, G loss: 0.7491\n",
      "[484/1762] D loss: 0.8242, G loss: 1.5344\n",
      "[564/1762] D loss: 1.4061, G loss: 0.6600\n",
      "[644/1762] D loss: 1.3886, G loss: 0.7032\n",
      "[724/1762] D loss: 1.0068, G loss: 0.9545\n",
      "[804/1762] D loss: 1.4118, G loss: 0.7414\n",
      "[884/1762] D loss: 1.4499, G loss: 0.7752\n",
      "[964/1762] D loss: 1.4095, G loss: 0.7917\n",
      "[1044/1762] D loss: 1.3821, G loss: 0.7520\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.6942\n",
      "[1204/1762] D loss: 0.8789, G loss: 1.5950\n",
      "[1284/1762] D loss: 1.4258, G loss: 0.7370\n",
      "[1364/1762] D loss: 0.8777, G loss: 1.1292\n",
      "[1444/1762] D loss: 1.4073, G loss: 0.6486\n",
      "[1524/1762] D loss: 0.9715, G loss: 1.0504\n",
      "[1604/1762] D loss: 1.4697, G loss: 0.7221\n",
      "[1684/1762] D loss: 1.3826, G loss: 0.7073\n",
      "[1762/1762] D loss: 1.3924, G loss: 0.7403\n",
      "train error: \n",
      " D loss: 1.334395, G loss: 0.643720, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317993, G loss: 0.659219, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4019, G loss: 0.7734\n",
      "[84/1762] D loss: 1.1395, G loss: 0.8525\n",
      "[164/1762] D loss: 1.0301, G loss: 0.9528\n",
      "[244/1762] D loss: 0.5930, G loss: 1.6401\n",
      "[324/1762] D loss: 0.8842, G loss: 1.1149\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6998\n",
      "[484/1762] D loss: 0.9151, G loss: 1.1276\n",
      "[564/1762] D loss: 1.4057, G loss: 0.6910\n",
      "[644/1762] D loss: 1.3905, G loss: 0.6825\n",
      "[724/1762] D loss: 0.9681, G loss: 1.0595\n",
      "[804/1762] D loss: 1.3992, G loss: 0.7110\n",
      "[884/1762] D loss: 1.3774, G loss: 0.7423\n",
      "[964/1762] D loss: 1.3873, G loss: 0.7128\n",
      "[1044/1762] D loss: 0.4665, G loss: 1.7726\n",
      "[1124/1762] D loss: 1.3822, G loss: 0.7263\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6401\n",
      "[1284/1762] D loss: 1.4175, G loss: 0.7097\n",
      "[1364/1762] D loss: 1.3815, G loss: 0.6945\n",
      "[1444/1762] D loss: 0.9498, G loss: 1.0737\n",
      "[1524/1762] D loss: 1.3858, G loss: 0.5927\n",
      "[1604/1762] D loss: 1.4249, G loss: 0.8519\n",
      "[1684/1762] D loss: 1.3934, G loss: 0.6923\n",
      "[1762/1762] D loss: 1.3825, G loss: 0.7056\n",
      "train error: \n",
      " D loss: 1.315198, G loss: 0.773672, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305593, G loss: 0.781914, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.7035\n",
      "[84/1762] D loss: 0.8891, G loss: 1.2527\n",
      "[164/1762] D loss: 0.9259, G loss: 1.1148\n",
      "[244/1762] D loss: 1.3748, G loss: 0.7539\n",
      "[324/1762] D loss: 1.4007, G loss: 0.6969\n",
      "[404/1762] D loss: 1.3881, G loss: 0.7051\n",
      "[484/1762] D loss: 1.3846, G loss: 0.6928\n",
      "[564/1762] D loss: 1.4336, G loss: 0.7007\n",
      "[644/1762] D loss: 1.5003, G loss: 0.5639\n",
      "[724/1762] D loss: 1.5193, G loss: 0.7454\n",
      "[804/1762] D loss: 1.4015, G loss: 0.8036\n",
      "[884/1762] D loss: 1.3158, G loss: 0.8341\n",
      "[964/1762] D loss: 1.3701, G loss: 0.7117\n",
      "[1044/1762] D loss: 1.3374, G loss: 0.9222\n",
      "[1124/1762] D loss: 1.3556, G loss: 0.7317\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.6994\n",
      "[1284/1762] D loss: 1.4518, G loss: 0.6513\n",
      "[1364/1762] D loss: 1.3819, G loss: 0.8725\n",
      "[1444/1762] D loss: 1.3819, G loss: 0.5858\n",
      "[1524/1762] D loss: 1.0249, G loss: 1.0512\n",
      "[1604/1762] D loss: 1.0679, G loss: 0.9310\n",
      "[1684/1762] D loss: 1.4074, G loss: 0.6747\n",
      "[1762/1762] D loss: 1.4014, G loss: 0.8214\n",
      "train error: \n",
      " D loss: 1.329025, G loss: 0.793166, D accuracy: 56.3%, cell accuracy: 99.7%, board accuracy: 83.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306806, G loss: 0.831399, D accuracy: 57.6%, cell accuracy: 99.6%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3620, G loss: 0.7610\n",
      "[84/1762] D loss: 1.0382, G loss: 1.0037\n",
      "[164/1762] D loss: 1.3579, G loss: 0.7357\n",
      "[244/1762] D loss: 1.3843, G loss: 0.7116\n",
      "[324/1762] D loss: 0.9333, G loss: 1.0427\n",
      "[404/1762] D loss: 1.4290, G loss: 0.7280\n",
      "[484/1762] D loss: 1.4152, G loss: 0.7222\n",
      "[564/1762] D loss: 1.3947, G loss: 0.6973\n",
      "[644/1762] D loss: 1.3927, G loss: 0.7011\n",
      "[724/1762] D loss: 0.9890, G loss: 1.0348\n",
      "[804/1762] D loss: 1.5809, G loss: 0.6888\n",
      "[884/1762] D loss: 1.3898, G loss: 0.6934\n",
      "[964/1762] D loss: 1.4614, G loss: 0.7534\n",
      "[1044/1762] D loss: 1.3162, G loss: 0.7007\n",
      "[1124/1762] D loss: 1.3827, G loss: 0.6873\n",
      "[1204/1762] D loss: 1.3718, G loss: 0.7168\n",
      "[1284/1762] D loss: 1.3921, G loss: 0.7611\n",
      "[1364/1762] D loss: 1.0172, G loss: 1.0546\n",
      "[1444/1762] D loss: 1.0710, G loss: 1.2561\n",
      "[1524/1762] D loss: 1.3668, G loss: 0.9319\n",
      "[1604/1762] D loss: 1.1656, G loss: 0.8747\n",
      "[1684/1762] D loss: 1.4087, G loss: 0.6901\n",
      "[1762/1762] D loss: 1.3701, G loss: 0.6977\n",
      "train error: \n",
      " D loss: 1.290294, G loss: 1.039489, D accuracy: 56.6%, cell accuracy: 99.3%, board accuracy: 72.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294303, G loss: 1.028990, D accuracy: 56.8%, cell accuracy: 99.3%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0289, G loss: 1.3291\n",
      "[84/1762] D loss: 1.2381, G loss: 0.8967\n",
      "[164/1762] D loss: 1.1868, G loss: 0.9627\n",
      "[244/1762] D loss: 1.3545, G loss: 0.6494\n",
      "[324/1762] D loss: 1.4846, G loss: 0.6688\n",
      "[404/1762] D loss: 1.4078, G loss: 0.7651\n",
      "[484/1762] D loss: 1.0123, G loss: 1.0506\n",
      "[564/1762] D loss: 1.5994, G loss: 0.5574\n",
      "[644/1762] D loss: 1.3733, G loss: 0.7015\n",
      "[724/1762] D loss: 0.9887, G loss: 1.1144\n",
      "[804/1762] D loss: 1.3962, G loss: 0.6942\n",
      "[884/1762] D loss: 1.6410, G loss: 0.6481\n",
      "[964/1762] D loss: 1.4145, G loss: 0.6971\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6726\n",
      "[1124/1762] D loss: 0.9250, G loss: 1.1001\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.6755\n",
      "[1284/1762] D loss: 1.3991, G loss: 0.6602\n",
      "[1364/1762] D loss: 1.3849, G loss: 0.6965\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7137\n",
      "[1524/1762] D loss: 0.9223, G loss: 1.1545\n",
      "[1604/1762] D loss: 1.4131, G loss: 0.7368\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.7091\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7668\n",
      "train error: \n",
      " D loss: 1.348322, G loss: 0.950778, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329306, G loss: 0.973594, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4459, G loss: 0.7105\n",
      "[84/1762] D loss: 1.4203, G loss: 0.6600\n",
      "[164/1762] D loss: 1.3916, G loss: 0.6926\n",
      "[244/1762] D loss: 1.3977, G loss: 0.6492\n",
      "[324/1762] D loss: 1.3802, G loss: 0.6679\n",
      "[404/1762] D loss: 1.4051, G loss: 0.6881\n",
      "[484/1762] D loss: 1.4028, G loss: 0.6813\n",
      "[564/1762] D loss: 1.3878, G loss: 0.6771\n",
      "[644/1762] D loss: 1.7140, G loss: 0.5599\n",
      "[724/1762] D loss: 1.4403, G loss: 0.6776\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6723\n",
      "[884/1762] D loss: 1.3839, G loss: 0.6982\n",
      "[964/1762] D loss: 1.3594, G loss: 0.7379\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.7101\n",
      "[1124/1762] D loss: 0.6055, G loss: 1.5848\n",
      "[1204/1762] D loss: 1.4379, G loss: 0.6923\n",
      "[1284/1762] D loss: 1.3814, G loss: 0.7058\n",
      "[1364/1762] D loss: 1.3918, G loss: 0.7047\n",
      "[1444/1762] D loss: 1.3187, G loss: 0.8685\n",
      "[1524/1762] D loss: 0.9508, G loss: 1.1266\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6994\n",
      "[1684/1762] D loss: 1.3854, G loss: 0.6786\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.7451\n",
      "train error: \n",
      " D loss: 1.326613, G loss: 0.705061, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302731, G loss: 0.723558, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8695, G loss: 1.1177\n",
      "[84/1762] D loss: 0.8718, G loss: 1.1473\n",
      "[164/1762] D loss: 0.8394, G loss: 1.2483\n",
      "[244/1762] D loss: 1.4427, G loss: 0.6820\n",
      "[324/1762] D loss: 0.8959, G loss: 1.1311\n",
      "[404/1762] D loss: 1.3876, G loss: 0.7232\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7005\n",
      "[564/1762] D loss: 1.8417, G loss: 0.5885\n",
      "[644/1762] D loss: 1.4179, G loss: 0.6591\n",
      "[724/1762] D loss: 1.4170, G loss: 0.6834\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6915\n",
      "[884/1762] D loss: 1.3471, G loss: 0.7698\n",
      "[964/1762] D loss: 1.3367, G loss: 0.7971\n",
      "[1044/1762] D loss: 1.3851, G loss: 0.7089\n",
      "[1124/1762] D loss: 1.3784, G loss: 0.7077\n",
      "[1204/1762] D loss: 0.8616, G loss: 1.1541\n",
      "[1284/1762] D loss: 1.3122, G loss: 0.7881\n",
      "[1364/1762] D loss: 0.7906, G loss: 1.3414\n",
      "[1444/1762] D loss: 1.4133, G loss: 0.6930\n",
      "[1524/1762] D loss: 0.9593, G loss: 1.0893\n",
      "[1604/1762] D loss: 1.4645, G loss: 0.6105\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.7304\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.7138\n",
      "train error: \n",
      " D loss: 1.331446, G loss: 0.939234, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307957, G loss: 0.973510, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7785, G loss: 1.4071\n",
      "[84/1762] D loss: 1.3934, G loss: 0.6948\n",
      "[164/1762] D loss: 1.3999, G loss: 0.7409\n",
      "[244/1762] D loss: 1.4068, G loss: 0.7167\n",
      "[324/1762] D loss: 0.8235, G loss: 1.2954\n",
      "[404/1762] D loss: 0.7492, G loss: 1.5259\n",
      "[484/1762] D loss: 0.8824, G loss: 1.1075\n",
      "[564/1762] D loss: 1.4391, G loss: 0.6445\n",
      "[644/1762] D loss: 1.3993, G loss: 0.7271\n",
      "[724/1762] D loss: 1.4182, G loss: 0.6970\n",
      "[804/1762] D loss: 1.3749, G loss: 0.7388\n",
      "[884/1762] D loss: 1.4248, G loss: 0.6742\n",
      "[964/1762] D loss: 1.3989, G loss: 0.7075\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.7114\n",
      "[1124/1762] D loss: 1.5805, G loss: 0.6386\n",
      "[1204/1762] D loss: 0.7835, G loss: 1.2113\n",
      "[1284/1762] D loss: 0.8267, G loss: 1.2111\n",
      "[1364/1762] D loss: 1.5008, G loss: 0.7345\n",
      "[1444/1762] D loss: 1.3118, G loss: 0.7377\n",
      "[1524/1762] D loss: 0.5864, G loss: 1.5243\n",
      "[1604/1762] D loss: 1.4189, G loss: 0.6856\n",
      "[1684/1762] D loss: 1.8118, G loss: 0.5830\n",
      "[1762/1762] D loss: 1.5310, G loss: 0.7437\n",
      "train error: \n",
      " D loss: 1.335959, G loss: 0.714416, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 77.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316567, G loss: 0.752068, D accuracy: 58.6%, cell accuracy: 99.5%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4122, G loss: 0.6954\n",
      "[84/1762] D loss: 1.4069, G loss: 0.6809\n",
      "[164/1762] D loss: 1.3325, G loss: 0.7517\n",
      "[244/1762] D loss: 1.3526, G loss: 0.7457\n",
      "[324/1762] D loss: 1.5436, G loss: 0.7501\n",
      "[404/1762] D loss: 1.3164, G loss: 0.7930\n",
      "[484/1762] D loss: 1.5915, G loss: 0.6706\n",
      "[564/1762] D loss: 1.3201, G loss: 0.7625\n",
      "[644/1762] D loss: 1.5873, G loss: 0.6770\n",
      "[724/1762] D loss: 1.4136, G loss: 0.7003\n",
      "[804/1762] D loss: 1.3585, G loss: 0.7247\n",
      "[884/1762] D loss: 0.9883, G loss: 1.0189\n",
      "[964/1762] D loss: 1.4086, G loss: 0.7544\n",
      "[1044/1762] D loss: 1.3123, G loss: 0.8692\n",
      "[1124/1762] D loss: 1.3993, G loss: 0.7154\n",
      "[1204/1762] D loss: 1.5605, G loss: 0.6408\n",
      "[1284/1762] D loss: 1.4206, G loss: 0.7130\n",
      "[1364/1762] D loss: 1.1458, G loss: 0.9302\n",
      "[1444/1762] D loss: 1.4036, G loss: 0.6480\n",
      "[1524/1762] D loss: 0.8609, G loss: 1.0932\n",
      "[1604/1762] D loss: 1.2659, G loss: 0.8761\n",
      "[1684/1762] D loss: 1.4073, G loss: 0.6298\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6663\n",
      "train error: \n",
      " D loss: 1.328358, G loss: 0.691996, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306162, G loss: 0.711742, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.7091\n",
      "[84/1762] D loss: 0.7540, G loss: 1.3708\n",
      "[164/1762] D loss: 1.4146, G loss: 0.6665\n",
      "[244/1762] D loss: 1.3472, G loss: 0.7175\n",
      "[324/1762] D loss: 1.4558, G loss: 0.6481\n",
      "[404/1762] D loss: 1.5426, G loss: 0.8870\n",
      "[484/1762] D loss: 1.3901, G loss: 0.6848\n",
      "[564/1762] D loss: 1.3736, G loss: 0.6863\n",
      "[644/1762] D loss: 1.8534, G loss: 0.5999\n",
      "[724/1762] D loss: 1.4016, G loss: 0.6688\n",
      "[804/1762] D loss: 1.4662, G loss: 0.6358\n",
      "[884/1762] D loss: 0.9843, G loss: 0.9508\n",
      "[964/1762] D loss: 1.4450, G loss: 0.6564\n",
      "[1044/1762] D loss: 1.4322, G loss: 0.7422\n",
      "[1124/1762] D loss: 1.1586, G loss: 0.8592\n",
      "[1204/1762] D loss: 1.3565, G loss: 0.6945\n",
      "[1284/1762] D loss: 0.9706, G loss: 1.0115\n",
      "[1364/1762] D loss: 1.4404, G loss: 0.7651\n",
      "[1444/1762] D loss: 1.0331, G loss: 0.9845\n",
      "[1524/1762] D loss: 1.4259, G loss: 0.7014\n",
      "[1604/1762] D loss: 1.3997, G loss: 0.7068\n",
      "[1684/1762] D loss: 1.1475, G loss: 0.9152\n",
      "[1762/1762] D loss: 1.5142, G loss: 0.6867\n",
      "train error: \n",
      " D loss: 1.369323, G loss: 1.003336, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359126, G loss: 1.036964, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4360, G loss: 0.6907\n",
      "[84/1762] D loss: 0.6991, G loss: 1.2810\n",
      "[164/1762] D loss: 1.4656, G loss: 0.6874\n",
      "[244/1762] D loss: 1.5105, G loss: 0.7890\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6906\n",
      "[404/1762] D loss: 1.4220, G loss: 0.7878\n",
      "[484/1762] D loss: 1.1608, G loss: 0.8248\n",
      "[564/1762] D loss: 1.4126, G loss: 0.7003\n",
      "[644/1762] D loss: 1.3899, G loss: 0.7462\n",
      "[724/1762] D loss: 1.2927, G loss: 0.8770\n",
      "[804/1762] D loss: 1.4645, G loss: 0.6280\n",
      "[884/1762] D loss: 1.3912, G loss: 0.6862\n",
      "[964/1762] D loss: 1.2362, G loss: 0.8443\n",
      "[1044/1762] D loss: 1.3381, G loss: 0.8499\n",
      "[1124/1762] D loss: 1.4060, G loss: 0.7158\n",
      "[1204/1762] D loss: 0.7226, G loss: 1.1959\n",
      "[1284/1762] D loss: 1.3965, G loss: 0.7107\n",
      "[1364/1762] D loss: 1.3954, G loss: 0.7028\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.7321\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.7536\n",
      "[1604/1762] D loss: 0.7949, G loss: 1.1674\n",
      "[1684/1762] D loss: 1.1582, G loss: 0.9222\n",
      "[1762/1762] D loss: 1.4761, G loss: 0.7456\n",
      "train error: \n",
      " D loss: 1.313339, G loss: 0.700971, D accuracy: 58.4%, cell accuracy: 99.5%, board accuracy: 75.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298122, G loss: 0.723706, D accuracy: 60.1%, cell accuracy: 99.5%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4179, G loss: 0.7053\n",
      "[84/1762] D loss: 1.5000, G loss: 0.6821\n",
      "[164/1762] D loss: 1.3851, G loss: 0.6953\n",
      "[244/1762] D loss: 1.3690, G loss: 0.8217\n",
      "[324/1762] D loss: 1.1858, G loss: 0.9387\n",
      "[404/1762] D loss: 0.6816, G loss: 1.3514\n",
      "[484/1762] D loss: 1.3255, G loss: 0.7852\n",
      "[564/1762] D loss: 1.4486, G loss: 0.6834\n",
      "[644/1762] D loss: 1.2157, G loss: 0.9335\n",
      "[724/1762] D loss: 1.3639, G loss: 0.7086\n",
      "[804/1762] D loss: 1.4012, G loss: 0.6590\n",
      "[884/1762] D loss: 1.5015, G loss: 0.7315\n",
      "[964/1762] D loss: 0.9724, G loss: 0.9619\n",
      "[1044/1762] D loss: 1.1157, G loss: 0.9588\n",
      "[1124/1762] D loss: 1.3790, G loss: 0.7201\n",
      "[1204/1762] D loss: 1.3797, G loss: 0.7506\n",
      "[1284/1762] D loss: 1.4180, G loss: 0.7109\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.7003\n",
      "[1444/1762] D loss: 1.4338, G loss: 0.6730\n",
      "[1524/1762] D loss: 1.3834, G loss: 0.7143\n",
      "[1604/1762] D loss: 1.3310, G loss: 0.7791\n",
      "[1684/1762] D loss: 1.4138, G loss: 0.7062\n",
      "[1762/1762] D loss: 0.7142, G loss: 1.4801\n",
      "train error: \n",
      " D loss: 1.408086, G loss: 1.290244, D accuracy: 52.1%, cell accuracy: 99.5%, board accuracy: 74.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.406959, G loss: 1.321102, D accuracy: 52.7%, cell accuracy: 99.5%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4308, G loss: 0.7506\n",
      "[84/1762] D loss: 1.3611, G loss: 0.6423\n",
      "[164/1762] D loss: 1.3449, G loss: 0.7584\n",
      "[244/1762] D loss: 1.2552, G loss: 0.7910\n",
      "[324/1762] D loss: 1.3977, G loss: 0.6986\n",
      "[404/1762] D loss: 1.3785, G loss: 0.7086\n",
      "[484/1762] D loss: 1.0270, G loss: 1.0787\n",
      "[564/1762] D loss: 1.2998, G loss: 0.6962\n",
      "[644/1762] D loss: 1.3893, G loss: 0.6987\n",
      "[724/1762] D loss: 0.9389, G loss: 1.2198\n",
      "[804/1762] D loss: 0.9355, G loss: 1.0262\n",
      "[884/1762] D loss: 1.0241, G loss: 1.0794\n",
      "[964/1762] D loss: 1.3934, G loss: 0.6941\n",
      "[1044/1762] D loss: 1.4296, G loss: 0.6943\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7254\n",
      "[1204/1762] D loss: 1.4622, G loss: 0.7675\n",
      "[1284/1762] D loss: 0.9564, G loss: 0.9798\n",
      "[1364/1762] D loss: 1.3486, G loss: 0.6795\n",
      "[1444/1762] D loss: 1.3416, G loss: 0.7292\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.7008\n",
      "[1604/1762] D loss: 1.3820, G loss: 0.7027\n",
      "[1684/1762] D loss: 0.9786, G loss: 1.1277\n",
      "[1762/1762] D loss: 1.4067, G loss: 0.7322\n",
      "train error: \n",
      " D loss: 1.353400, G loss: 0.616829, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337033, G loss: 0.636190, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0852, G loss: 1.0249\n",
      "[84/1762] D loss: 1.3261, G loss: 0.8238\n",
      "[164/1762] D loss: 1.3978, G loss: 0.7045\n",
      "[244/1762] D loss: 1.4095, G loss: 0.7509\n",
      "[324/1762] D loss: 1.3944, G loss: 0.7003\n",
      "[404/1762] D loss: 1.4024, G loss: 0.6991\n",
      "[484/1762] D loss: 1.3863, G loss: 0.7186\n",
      "[564/1762] D loss: 1.4107, G loss: 0.6945\n",
      "[644/1762] D loss: 1.3971, G loss: 0.6920\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6882\n",
      "[804/1762] D loss: 1.4174, G loss: 0.6860\n",
      "[884/1762] D loss: 1.4046, G loss: 0.7241\n",
      "[964/1762] D loss: 0.8906, G loss: 1.1823\n",
      "[1044/1762] D loss: 1.4162, G loss: 0.6476\n",
      "[1124/1762] D loss: 1.3971, G loss: 0.6866\n",
      "[1204/1762] D loss: 1.2819, G loss: 0.8025\n",
      "[1284/1762] D loss: 1.1144, G loss: 0.8943\n",
      "[1364/1762] D loss: 0.9899, G loss: 1.0320\n",
      "[1444/1762] D loss: 1.3831, G loss: 0.7105\n",
      "[1524/1762] D loss: 1.4189, G loss: 0.7412\n",
      "[1604/1762] D loss: 0.8357, G loss: 1.2275\n",
      "[1684/1762] D loss: 1.3716, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.4091, G loss: 0.7005\n",
      "train error: \n",
      " D loss: 1.324702, G loss: 0.812086, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320234, G loss: 0.836139, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3705, G loss: 0.7058\n",
      "[84/1762] D loss: 0.9854, G loss: 1.0565\n",
      "[164/1762] D loss: 1.8799, G loss: 0.6317\n",
      "[244/1762] D loss: 0.8003, G loss: 1.2704\n",
      "[324/1762] D loss: 1.3182, G loss: 0.7505\n",
      "[404/1762] D loss: 1.4287, G loss: 0.7165\n",
      "[484/1762] D loss: 1.4033, G loss: 0.7318\n",
      "[564/1762] D loss: 1.4070, G loss: 0.7067\n",
      "[644/1762] D loss: 1.4508, G loss: 0.7350\n",
      "[724/1762] D loss: 1.3769, G loss: 0.7256\n",
      "[804/1762] D loss: 1.3515, G loss: 0.7219\n",
      "[884/1762] D loss: 1.4286, G loss: 0.6861\n",
      "[964/1762] D loss: 1.3950, G loss: 0.6962\n",
      "[1044/1762] D loss: 1.4080, G loss: 0.7173\n",
      "[1124/1762] D loss: 0.7498, G loss: 1.2613\n",
      "[1204/1762] D loss: 0.6937, G loss: 1.4369\n",
      "[1284/1762] D loss: 1.3305, G loss: 0.7361\n",
      "[1364/1762] D loss: 1.3944, G loss: 0.7124\n",
      "[1444/1762] D loss: 1.3921, G loss: 0.6900\n",
      "[1524/1762] D loss: 1.4659, G loss: 0.6860\n",
      "[1604/1762] D loss: 1.4056, G loss: 0.7636\n",
      "[1684/1762] D loss: 1.3674, G loss: 0.7000\n",
      "[1762/1762] D loss: 1.2577, G loss: 0.8036\n",
      "train error: \n",
      " D loss: 1.331890, G loss: 0.695037, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320006, G loss: 0.715231, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9741, G loss: 0.9745\n",
      "[84/1762] D loss: 0.9752, G loss: 0.9949\n",
      "[164/1762] D loss: 1.7302, G loss: 0.5388\n",
      "[244/1762] D loss: 1.3841, G loss: 0.7052\n",
      "[324/1762] D loss: 1.4701, G loss: 0.7811\n",
      "[404/1762] D loss: 1.4175, G loss: 0.6991\n",
      "[484/1762] D loss: 0.7076, G loss: 1.2972\n",
      "[564/1762] D loss: 1.3838, G loss: 0.6931\n",
      "[644/1762] D loss: 1.4205, G loss: 0.7045\n",
      "[724/1762] D loss: 1.3887, G loss: 0.6952\n",
      "[804/1762] D loss: 1.4629, G loss: 0.7292\n",
      "[884/1762] D loss: 1.3956, G loss: 0.6986\n",
      "[964/1762] D loss: 1.4111, G loss: 0.7024\n",
      "[1044/1762] D loss: 1.4919, G loss: 0.6893\n",
      "[1124/1762] D loss: 1.2608, G loss: 0.7684\n",
      "[1204/1762] D loss: 1.3781, G loss: 0.7018\n",
      "[1284/1762] D loss: 1.4015, G loss: 0.7164\n",
      "[1364/1762] D loss: 1.4184, G loss: 0.6482\n",
      "[1444/1762] D loss: 1.3159, G loss: 0.7733\n",
      "[1524/1762] D loss: 1.3657, G loss: 0.7220\n",
      "[1604/1762] D loss: 1.2602, G loss: 0.8657\n",
      "[1684/1762] D loss: 1.3812, G loss: 0.6966\n",
      "[1762/1762] D loss: 1.3155, G loss: 0.7207\n",
      "train error: \n",
      " D loss: 1.305701, G loss: 0.982306, D accuracy: 55.6%, cell accuracy: 99.6%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317722, G loss: 0.959782, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3999, G loss: 0.7042\n",
      "[84/1762] D loss: 1.3644, G loss: 0.7137\n",
      "[164/1762] D loss: 1.3897, G loss: 0.6980\n",
      "[244/1762] D loss: 1.4103, G loss: 0.7217\n",
      "[324/1762] D loss: 1.3817, G loss: 0.7327\n",
      "[404/1762] D loss: 1.4015, G loss: 0.7247\n",
      "[484/1762] D loss: 1.3904, G loss: 0.7599\n",
      "[564/1762] D loss: 1.3441, G loss: 0.9934\n",
      "[644/1762] D loss: 1.3134, G loss: 0.8298\n",
      "[724/1762] D loss: 1.3716, G loss: 0.7635\n",
      "[804/1762] D loss: 1.5465, G loss: 0.6472\n",
      "[884/1762] D loss: 1.4601, G loss: 0.7586\n",
      "[964/1762] D loss: 1.4043, G loss: 0.6938\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6508\n",
      "[1124/1762] D loss: 1.3977, G loss: 0.6793\n",
      "[1204/1762] D loss: 1.4497, G loss: 0.7165\n",
      "[1284/1762] D loss: 1.3713, G loss: 0.7023\n",
      "[1364/1762] D loss: 1.4090, G loss: 0.7716\n",
      "[1444/1762] D loss: 1.2409, G loss: 0.9890\n",
      "[1524/1762] D loss: 1.1586, G loss: 0.8037\n",
      "[1604/1762] D loss: 1.3351, G loss: 0.7656\n",
      "[1684/1762] D loss: 1.3812, G loss: 0.7472\n",
      "[1762/1762] D loss: 1.3757, G loss: 0.7203\n",
      "train error: \n",
      " D loss: 1.329535, G loss: 0.839646, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323894, G loss: 0.828879, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3987, G loss: 0.7025\n",
      "[84/1762] D loss: 1.4488, G loss: 0.7240\n",
      "[164/1762] D loss: 1.3144, G loss: 0.7686\n",
      "[244/1762] D loss: 1.3686, G loss: 0.6952\n",
      "[324/1762] D loss: 1.3918, G loss: 0.7007\n",
      "[404/1762] D loss: 1.2471, G loss: 0.9385\n",
      "[484/1762] D loss: 1.3347, G loss: 0.7901\n",
      "[564/1762] D loss: 1.4490, G loss: 0.6376\n",
      "[644/1762] D loss: 1.3837, G loss: 0.7158\n",
      "[724/1762] D loss: 1.4036, G loss: 0.6435\n",
      "[804/1762] D loss: 1.2191, G loss: 0.8512\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6942\n",
      "[964/1762] D loss: 1.4364, G loss: 0.6279\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.7183\n",
      "[1124/1762] D loss: 1.4207, G loss: 0.7651\n",
      "[1204/1762] D loss: 1.3174, G loss: 0.7341\n",
      "[1284/1762] D loss: 1.1045, G loss: 0.9034\n",
      "[1364/1762] D loss: 1.3616, G loss: 0.6581\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.7137\n",
      "[1524/1762] D loss: 1.5030, G loss: 0.7969\n",
      "[1604/1762] D loss: 1.3836, G loss: 0.6816\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.7082\n",
      "[1762/1762] D loss: 1.3840, G loss: 0.6986\n",
      "train error: \n",
      " D loss: 1.322222, G loss: 0.724331, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312233, G loss: 0.731587, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3564, G loss: 0.7495\n",
      "[84/1762] D loss: 1.3804, G loss: 0.7000\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6987\n",
      "[244/1762] D loss: 1.3398, G loss: 0.7238\n",
      "[324/1762] D loss: 1.3538, G loss: 0.7337\n",
      "[404/1762] D loss: 1.3771, G loss: 0.7104\n",
      "[484/1762] D loss: 1.3388, G loss: 0.7700\n",
      "[564/1762] D loss: 1.0372, G loss: 0.9961\n",
      "[644/1762] D loss: 1.3935, G loss: 0.7877\n",
      "[724/1762] D loss: 1.4086, G loss: 0.6996\n",
      "[804/1762] D loss: 1.0574, G loss: 1.0151\n",
      "[884/1762] D loss: 1.2777, G loss: 0.8809\n",
      "[964/1762] D loss: 1.3930, G loss: 0.6993\n",
      "[1044/1762] D loss: 1.4118, G loss: 0.7363\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.8192\n",
      "[1204/1762] D loss: 1.4070, G loss: 0.6399\n",
      "[1284/1762] D loss: 1.4270, G loss: 0.6620\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6868\n",
      "[1444/1762] D loss: 1.4337, G loss: 0.7081\n",
      "[1524/1762] D loss: 1.3926, G loss: 0.7567\n",
      "[1604/1762] D loss: 1.4200, G loss: 0.6961\n",
      "[1684/1762] D loss: 1.3704, G loss: 0.7582\n",
      "[1762/1762] D loss: 1.2144, G loss: 0.8903\n",
      "train error: \n",
      " D loss: 1.288873, G loss: 0.809584, D accuracy: 59.8%, cell accuracy: 99.5%, board accuracy: 76.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282130, G loss: 0.819707, D accuracy: 60.6%, cell accuracy: 99.5%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1360, G loss: 0.8725\n",
      "[84/1762] D loss: 1.1764, G loss: 0.9212\n",
      "[164/1762] D loss: 1.5040, G loss: 0.7385\n",
      "[244/1762] D loss: 1.3897, G loss: 0.7802\n",
      "[324/1762] D loss: 1.2085, G loss: 0.9660\n",
      "[404/1762] D loss: 1.4200, G loss: 0.7041\n",
      "[484/1762] D loss: 1.3822, G loss: 0.7463\n",
      "[564/1762] D loss: 1.3977, G loss: 0.5731\n",
      "[644/1762] D loss: 1.1304, G loss: 0.9153\n",
      "[724/1762] D loss: 1.3316, G loss: 0.7589\n",
      "[804/1762] D loss: 1.3963, G loss: 0.7025\n",
      "[884/1762] D loss: 1.3979, G loss: 0.6837\n",
      "[964/1762] D loss: 0.7473, G loss: 1.3324\n",
      "[1044/1762] D loss: 1.3888, G loss: 0.7012\n",
      "[1124/1762] D loss: 1.1445, G loss: 0.9535\n",
      "[1204/1762] D loss: 1.4182, G loss: 0.7806\n",
      "[1284/1762] D loss: 1.5204, G loss: 0.6828\n",
      "[1364/1762] D loss: 1.4537, G loss: 0.7194\n",
      "[1444/1762] D loss: 1.3706, G loss: 0.7018\n",
      "[1524/1762] D loss: 1.2923, G loss: 0.7456\n",
      "[1604/1762] D loss: 1.5111, G loss: 0.7406\n",
      "[1684/1762] D loss: 1.3708, G loss: 0.7196\n",
      "[1762/1762] D loss: 1.3708, G loss: 0.7200\n",
      "train error: \n",
      " D loss: 1.336179, G loss: 0.688033, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315865, G loss: 0.716920, D accuracy: 57.2%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3322, G loss: 0.7337\n",
      "[84/1762] D loss: 1.3707, G loss: 0.7127\n",
      "[164/1762] D loss: 1.4033, G loss: 0.7200\n",
      "[244/1762] D loss: 1.4803, G loss: 0.7184\n",
      "[324/1762] D loss: 1.3401, G loss: 0.8112\n",
      "[404/1762] D loss: 1.0657, G loss: 0.9437\n",
      "[484/1762] D loss: 1.3745, G loss: 0.7549\n",
      "[564/1762] D loss: 0.9153, G loss: 1.1289\n",
      "[644/1762] D loss: 1.3851, G loss: 0.6929\n",
      "[724/1762] D loss: 1.4048, G loss: 0.7533\n",
      "[804/1762] D loss: 1.4065, G loss: 0.6898\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7033\n",
      "[964/1762] D loss: 1.7941, G loss: 0.5973\n",
      "[1044/1762] D loss: 1.3671, G loss: 0.7077\n",
      "[1124/1762] D loss: 0.9463, G loss: 1.0930\n",
      "[1204/1762] D loss: 0.9542, G loss: 1.1040\n",
      "[1284/1762] D loss: 0.7838, G loss: 1.3405\n",
      "[1364/1762] D loss: 1.7128, G loss: 0.6215\n",
      "[1444/1762] D loss: 1.4064, G loss: 0.7047\n",
      "[1524/1762] D loss: 1.3956, G loss: 0.6768\n",
      "[1604/1762] D loss: 1.3960, G loss: 0.7063\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.6872\n",
      "[1762/1762] D loss: 1.3845, G loss: 0.6955\n",
      "train error: \n",
      " D loss: 1.338899, G loss: 0.760961, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315124, G loss: 0.789716, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    #for learning_rate in [1e-2, 3e-3, 1e-3, 3e-3, 1e-4]:\n",
    "    for learning_rate in [3e-4]:\n",
    "        run_name=f\"lr_{learning_rate:.0e}\".replace(\"-\", \"m\")\n",
    "        train(run_name=run_name, learning_rate=learning_rate, epochs=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like varying the learning rate isn't enough to solve the board accuracy or instability issues. All the learning rates attempted here show instability and none of them result in a training accuracy consistently above 90%. Reducing the learning rate to 1e-4 slows down the training and makes the final board accuracy siginificantly worse (around 80% instead of around 90%)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this experiment, we were not able to improve the board accuracy of the generator. However, we confirmed that the discriminator architecture is reasonable for the task, since the discriminator can be independently trained to distinguish `y` from `y_fake` when `y_fake` is `y` but with a small number of cells randomly flipped.\n",
    "\n",
    "We note that even for this \"perturbation\" task, we didn't find any model architectures which trained to 100% accuracy when the number of flips was small. This could be for one of two reasons:\n",
    "* Maybe the task is impossible to get 100% accuracy in, because in some cases the cell flips could transform one block spawn type into another. It's unclear how often this would happen.\n",
    "* Maybe the model is not capable of learning to 100% with the given architecture and/or hyperparameters, so these should be changed.\n",
    "\n",
    "An alternative task would be to fix a version of the generator and just train the discriminator to score highly against this fixed generator. Let's call this the \"fixed generator\" task.\n",
    "\n",
    "The next step is to experiment with training a discriminator on either the perturbation task or the fixed generator task, and find a discriminator architecture and hyperparameters that give significantly better performance. There are some \"GAN hacks\" we could try here: https://github.com/soumith/ganhacks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
