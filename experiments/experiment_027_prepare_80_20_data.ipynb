{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Tetris emulator data - 80/20\n",
    "\n",
    "The data recorded while playing the game needs to be checked and cleaned before being used to train a model. In addition, we will ensure that the data is about 80% block falls and 20% block spawns.\n",
    "\n",
    "For expedience, we will merge the `tetris_emulator` and `balanced` datasets and selectively remove examples until we get the desired ratio. We will also ensure that training (test) examples stay as training (test) examples, to allow validation between datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from recording import RecordingDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import recording\n",
    "from importlib import reload\n",
    "recording = reload(recording)\n",
    "from recording import RecordingDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy data from existing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\tetris_emulator\\train has 1778 examples\n",
      "data\\tetris_emulator\\test has 444 examples\n",
      "data\\balanced\\train has 1778 examples\n",
      "data\\balanced\\test has 444 examples\n"
     ]
    }
   ],
   "source": [
    "# Initialise existing databases\n",
    "\n",
    "train_unb = RecordingDatabase(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_unb = RecordingDatabase(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "train_bal = RecordingDatabase(os.path.join(\"data\", \"balanced\", \"train\"))\n",
    "test_bal = RecordingDatabase(os.path.join(\"data\", \"balanced\", \"test\"))\n",
    "\n",
    "for db in [train_unb, test_unb, train_bal, test_bal]:\n",
    "    print(f\"{db.path} has {len(db)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folders\n",
    "\n",
    "os.mkdir(os.path.join(\"data\", \"80_20\", \"train\"))\n",
    "os.mkdir(os.path.join(\"data\", \"80_20\", \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and populate new databases\n",
    "\n",
    "train_db = RecordingDatabase(os.path.join(\"data\", \"80_20\", \"train\"))\n",
    "test_db = RecordingDatabase(os.path.join(\"data\", \"80_20\", \"test\"))\n",
    "\n",
    "for train_source in [train_unb, train_bal]:\n",
    "    for train_example in train_source:\n",
    "        train_db.insert(train_example)\n",
    "\n",
    "for test_source in [test_unb, test_bal]:\n",
    "    for test_example in test_source:\n",
    "        test_db.insert(test_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_block_spawn(boards):\n",
    "    return (boards[-2, 0, :] == 0).all() and (boards[-1, 0, :] == 1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_falls_and_spawns(db):\n",
    "    spawn_count = sum(1 for x in db if is_block_spawn(x))\n",
    "    fall_count = len(db) - spawn_count\n",
    "    return fall_count, spawn_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 2526 (71.03%) falls and 1030 (28.97%) spawns.\n",
      "Test set has 622 (70.05%) falls and 266 (29.95%) spawns.\n"
     ]
    }
   ],
   "source": [
    "train_falls, train_spawns = count_falls_and_spawns(train_db)\n",
    "test_falls, test_spawns = count_falls_and_spawns(test_db)\n",
    "\n",
    "print(f\"Training set has {train_falls} ({train_falls / len(train_db):.2%}) falls and {train_spawns} ({train_spawns / len(train_db):.2%}) spawns.\")\n",
    "print(f\"Test set has {test_falls} ({test_falls / len(test_db):.2%}) falls and {test_spawns} ({test_spawns / len(test_db):.2%}) spawns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_falls_and_spawns(target_size, target_spawn_split):\n",
    "    target_spawns = round(target_size * target_spawn_split)\n",
    "    target_falls = target_size - target_spawns\n",
    "    return target_falls, target_spawns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target train count: 1778\n",
      "Target test count: 444\n",
      "Target spawn proportion: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Match size of original datasets\n",
    "target_train = len(train_unb)\n",
    "target_test = len(test_unb)\n",
    "target_spawn_split = 0.2\n",
    "print(f\"Target train count: {target_train}\")\n",
    "print(f\"Target test count: {target_test}\")\n",
    "print(f\"Target spawn proportion: {target_spawn_split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target train falls: 1422\n",
      "Target train spawns: 356\n",
      "Target test falls: 355\n",
      "Target test spawns: 89\n"
     ]
    }
   ],
   "source": [
    "# Get targets for each type of example\n",
    "target_train_falls, target_train_spawns = get_target_falls_and_spawns(target_train, target_spawn_split)\n",
    "print(f\"Target train falls: {target_train_falls}\")\n",
    "print(f\"Target train spawns: {target_train_spawns}\")\n",
    "\n",
    "target_test_falls, target_test_spawns = get_target_falls_and_spawns(target_test, target_spawn_split)\n",
    "print(f\"Target test falls: {target_test_falls}\")\n",
    "print(f\"Target test spawns: {target_test_spawns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(db, target_falls, target_spawns):\n",
    "    falls, spawns = count_falls_and_spawns(db)\n",
    "    fall_excess = falls - target_falls\n",
    "    spawn_excess = spawns - target_spawns\n",
    "    assert fall_excess >= 0, \"Not enough falls\"\n",
    "    assert spawn_excess >= 0, \"Not enough spawns\"\n",
    "\n",
    "    falls_counted = 0\n",
    "    spawns_counted = 0\n",
    "    delete_idxs = []\n",
    "\n",
    "    for idx, example in enumerate(db):\n",
    "        if (falls_counted == fall_excess) and (spawns_counted == spawn_excess):\n",
    "            break\n",
    "        if is_block_spawn(example):\n",
    "            if spawns_counted < spawn_excess:\n",
    "                delete_idxs.append(idx)\n",
    "                spawns_counted += 1\n",
    "        else:\n",
    "            if falls_counted < fall_excess:\n",
    "                delete_idxs.append(idx)\n",
    "                falls_counted += 1\n",
    "\n",
    "    print(f\"Removing {fall_excess} falls and {spawn_excess} spawns\")\n",
    "    db.delete_batch(delete_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning training dataset\n",
      "Removing 1104 falls and 674 spawns\n",
      "Pruning test dataset\n",
      "Removing 267 falls and 177 spawns\n"
     ]
    }
   ],
   "source": [
    "print(\"Pruning training dataset\")\n",
    "prune(train_db, target_train_falls, target_train_spawns)\n",
    "\n",
    "print(\"Pruning test dataset\")\n",
    "prune(test_db, target_test_falls, target_test_spawns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 1422 (79.98%) falls and 356 (20.02%) spawns.\n",
      "Test set has 355 (79.95%) falls and 89 (20.05%) spawns.\n"
     ]
    }
   ],
   "source": [
    "train_falls, train_spawns = count_falls_and_spawns(train_db)\n",
    "test_falls, test_spawns = count_falls_and_spawns(test_db)\n",
    "\n",
    "print(f\"Training set has {train_falls} ({train_falls / len(train_db):.2%}) falls and {train_spawns} ({train_spawns / len(train_db):.2%}) spawns.\")\n",
    "print(f\"Test set has {test_falls} ({test_falls / len(test_db):.2%}) falls and {test_spawns} ({test_spawns / len(test_db):.2%}) spawns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final checks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the number of each type of block spawn in both the training and test folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, db: RecordingDatabase):\n",
    "        self.db = db\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        boards = self.db[idx]\n",
    "        x = torch.tensor(boards[-2]) # Ignore all boards except the last two\n",
    "        y = torch.tensor(boards[-1], dtype=torch.long)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describing training dataset...\n",
      "{'I': 54, 'O': 51, 'T': 43, 'Z': 40, 'S': 54, 'J': 58, 'L': 56}\n",
      "Dataset has 356 block spawns.\n",
      "\n",
      "Describing test dataset...\n",
      "{'I': 13, 'O': 7, 'T': 18, 'Z': 13, 'S': 11, 'J': 14, 'L': 13}\n",
      "Dataset has 89 block spawns.\n"
     ]
    }
   ],
   "source": [
    "class BlockType:\n",
    "    I = \"I\"\n",
    "    O = \"O\"\n",
    "    T = \"T\"\n",
    "    Z = \"Z\"\n",
    "    S = \"S\"\n",
    "    J = \"J\"\n",
    "    L = \"L\"\n",
    "    All = [I, O, T, Z, S, J, L]\n",
    "    \n",
    "def get_block_spawn_type(example):\n",
    "    x, y = example\n",
    "    if (x[0, :] == 1).any() | (y[0, :] == 0).all():\n",
    "        return None\n",
    "    if (y[1, :] == 0).all():\n",
    "        return BlockType.I\n",
    "    if y[0, 3] == 1:\n",
    "        if y[1, 3] == 1:\n",
    "            return BlockType.J\n",
    "        else:\n",
    "            if y[0, 5] == 1:\n",
    "                return BlockType.T\n",
    "            else:\n",
    "                return BlockType.Z\n",
    "    else:\n",
    "        if y[1, 3] == 1:\n",
    "            if y[0, 4] == 1:\n",
    "                return BlockType.S\n",
    "            else:\n",
    "                return BlockType.L\n",
    "        else:\n",
    "            return BlockType.O\n",
    "\n",
    "\n",
    "def count_block_spawns_by_type(dataset):\n",
    "    spawns_by_type = {block_type: 0 for block_type in BlockType.All}\n",
    "    for example in dataset:\n",
    "        spawn_type = get_block_spawn_type(example)\n",
    "        if spawn_type is not None:\n",
    "            spawns_by_type[spawn_type] += 1\n",
    "    return spawns_by_type\n",
    "\n",
    "\n",
    "def describe_block_spawns(dataset):\n",
    "    spawns_by_type = count_block_spawns_by_type(dataset)\n",
    "    print(spawns_by_type)\n",
    "    \n",
    "    num_block_spawns = sum(val for key, val in spawns_by_type.items() if key is not None)\n",
    "    frac_block_spawns = num_block_spawns / len(dataset)\n",
    "    print(f\"Dataset has {num_block_spawns} block spawns.\")\n",
    "\n",
    "\n",
    "train_dataset = RecordingDataset(train_db)\n",
    "test_dataset = RecordingDataset(test_db)\n",
    "\n",
    "print(\"Describing training dataset...\")\n",
    "describe_block_spawns(train_dataset)\n",
    "print()\n",
    "print(\"Describing test dataset...\")\n",
    "describe_block_spawns(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
