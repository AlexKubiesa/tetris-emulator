{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 021\n",
    "\n",
    "In this experiment, we will use a learning rate of 1e-4 for both the generator and discriminator and will try out different architectures for the discriminator with more capacity. This will hopefully enable the discriminator to learn faster, so the generator doesn't get \"stuck\" learning only block falling but actually learns about block spawns as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError()\n",
    "        with os.scandir(self.path) as it:\n",
    "            entry: os.DirEntry = next(iter(it))\n",
    "            _, self.ext = os.path.splitext(entry.name)\n",
    "            self.highest_index = max((int(Path(file.path).stem) for file in it), default=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.highest_index + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = os.path.join(self.path, f\"{idx}{self.ext}\")\n",
    "        if not os.path.exists(file):\n",
    "            raise IndexError()\n",
    "        boards = np.load(file)\n",
    "\n",
    "        def transform(board):\n",
    "            board = torch.tensor(board, dtype=torch.long)\n",
    "            board = F.one_hot(board, 2) # One-hot encode the cell types\n",
    "            board = board.type(torch.float) # Convert to floating-point\n",
    "            board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "            return board\n",
    "\n",
    "        x = transform(boards[-2]) # Ignore all boards except the last two\n",
    "        y = transform(boards[-1])\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 22, 10]) torch.float32\n",
      "torch.Size([4, 2, 22, 10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisModel(nn.Module):\n",
    "    \"\"\"Predicts the next state of the cells.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        z: Tensor of float32 of shape (batch_size, 4). The entries should be random numbers sampled from a uniform distribution.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, height, width), logits for the new cells. Probabilities close to 0 (negative logits)\n",
    "             correspond to empty cells, and probabilities close to 1 (positive logits) correspond to filled cells.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        z = z[:, :, None, None] # Expand dims to match x\n",
    "        z = z.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        x_glob = self.glob(x)\n",
    "        x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "        x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisDiscriminator(nn.Module):\n",
    "    \"\"\"A discriminator for the cell state predictions. Assesses the output of the generator.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        y: Tensor of float32 of shape (batch_size, channels, height, width), as with x. This should be either the output of the\n",
    "           generator (with exp applied) or the one-hot encoding of the ground truth of the next cell states.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, 1), decisions on whether the data are real or fake. Probabilities close to 0 (negative logits)\n",
    "             correspond to fake data, and probabilities close to 1 (positive logits) correspond to real data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def check_disc(disc):\n",
    "    with torch.no_grad():\n",
    "        X, y = next(iter(train_dataloader))\n",
    "        pred_on_real = F.sigmoid(disc(X, y)[0])\n",
    "        print(f\"Number of discriminator parameters: {count_parameters(disc)}\")\n",
    "        print(f\"Predicted label for real data: {pred_on_real}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generator parameters: 17996\n",
      "Number of discriminator parameters: 7057\n",
      "Predicted label for real data: 0.5369366407394409\n",
      "Predicted label for fake data: 0.5354960560798645\n"
     ]
    }
   ],
   "source": [
    "gen = TetrisModel().to(device)\n",
    "disc = TetrisDiscriminator().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X, y = next(iter(train_dataloader))\n",
    "    z = torch.rand(batch_size, 4)\n",
    "    y_gen = gen(X, z)\n",
    "    pred_on_real = F.sigmoid(disc(X, y)[0])\n",
    "    pred_on_fake = F.sigmoid(disc(X, y_gen)[0])\n",
    "    print(f\"Number of generator parameters: {count_parameters(gen)}\")\n",
    "    print(f\"Number of discriminator parameters: {count_parameters(disc)}\")\n",
    "    print(f\"Predicted label for real data: {pred_on_real}\")\n",
    "    print(f\"Predicted label for fake data: {pred_on_fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_interesting_examples(dataset, num=3):\n",
    "    num_spawns = num\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "\n",
    "        for x, y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (x.argmax(0)[0] == 0).all() & (y.argmax(0)[0] == 1).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield x, y\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prediction(x, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        x: Tensor of shape (height, width), the model input.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the target.\n",
    "    \"\"\"\n",
    "    assert len(x.shape) == 2, f\"Expected tensors of shape (width, height) but got {x.shape}\"\n",
    "    assert x.shape == pred.shape, f\"Shapes do not match: {x.shape} != {pred.shape}\"\n",
    "    assert x.shape == y.shape, f\"Shapes do not match: {x.shape} != {y.shape}\"\n",
    "    height, width = x.shape\n",
    "    with torch.no_grad():\n",
    "        separator = torch.ones(height, 1, dtype=x.dtype)\n",
    "        return torch.cat((x, separator, pred, separator, y), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # I\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # O\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # J\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # T\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # S\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # L\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int) # Z\n",
    "]\n",
    "\n",
    "def get_valid_block_spawns(classes_X, classes_y_fake):\n",
    "    \"\"\"Determines whether predicted block spawns have a valid shape.\n",
    "    \n",
    "    Inputs:\n",
    "        classes_X: Tensor of int32 of shape (batch_size, height, width), the first time step (with argmax applied on cell types).\n",
    "        classes_y_fake: Tensor of int32 of shape (batch_size, height, width), the model's prediction (with argmax applied on cell types).\n",
    "\n",
    "    Returns: Tensor of bool of shape (batch_size,), whether the items are predicted block spawns AND valid.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = classes_X.size(0)\n",
    "        ret = torch.full((batch_size,), False)\n",
    "\n",
    "        # Take difference to see which cells are full but weren't before.\n",
    "        diff = classes_y_fake - classes_X\n",
    "\n",
    "        # It's only a valid block spawn if the change in the first 3 rows matches\n",
    "        # one of the valid configurations.\n",
    "        for block in blocks:\n",
    "            ret |= (diff[:, :3, :] == block).all(-1).all(-1)\n",
    "        \n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(X, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        z = torch.rand(batch_size, 4, device=device)\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(X, z)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(X, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(X, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 20 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "    spawn_recall = 0.0\n",
    "    num_spawns = 0.0\n",
    "    spawn_validity = 0.0\n",
    "    num_predicted_spawns = 0.0\n",
    "    spawn_precision = 0.0\n",
    "    scores_real = np.zeros(len(dataloader.dataset))\n",
    "    scores_fake = np.zeros(len(dataloader.dataset))\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            batch_size = X.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(X, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            z = torch.rand(batch_size, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            output_fake = disc(X, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_X = torch.argmax(X, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy += (classes_y_fake == classes_y).type(torch.float).mean().item()\n",
    "            board_accuracy += (classes_y_fake == classes_y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "            actual_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y[:, 0, :] == 1).any(-1)\n",
    "            predicted_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y_fake[:, 0, :] == 1).any(-1)\n",
    "            num_true_positives = (actual_spawns & predicted_spawns).type(torch.float).sum().item()\n",
    "            spawn_recall += num_true_positives\n",
    "            spawn_precision += num_true_positives\n",
    "            num_spawns += actual_spawns.type(torch.float).sum().item()\n",
    "            valid_spawns = get_valid_block_spawns(classes_X, classes_y_fake)\n",
    "            spawn_validity += valid_spawns.type(torch.float).sum().item()\n",
    "            num_predicted_spawns += predicted_spawns.type(torch.float).sum().item()\n",
    "\n",
    "            start_index = dataloader.batch_size * batch\n",
    "            end_index = start_index + batch_size\n",
    "            scores_real[start_index:end_index] = torch.sigmoid(output_real).numpy()\n",
    "            scores_fake[start_index:end_index] = torch.sigmoid(output_fake).numpy()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    spawn_recall /= num_spawns\n",
    "    spawn_precision = np.nan if (num_predicted_spawns == 0.0) else spawn_precision / num_predicted_spawns\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "    spawn_validity = np.nan if (num_predicted_spawns == 0.0) else spawn_validity / num_predicted_spawns\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(100*cell_accuracy):>0.1f}%, board accuracy: {(100*board_accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn precision/{split_name}\", spawn_precision, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn validity/{split_name}\", spawn_validity, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(examples):\n",
    "            X, y = X.unsqueeze(0), y.unsqueeze(0)\n",
    "            z = torch.rand(1, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            X, y, y_fake = X.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            X, y, y_fake = X.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(X, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch, dataformats=\"HW\")\n",
    "    \n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/real\", scores_real, epoch)\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/fake\", scores_fake, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", disc_cls=TetrisDiscriminator, learning_rate=1e-4, epochs=100):\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = disc_cls().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_021\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        gen_zero_grads = 0\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "            gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "        tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "        disc_zero_grads = 0\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "            disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "        tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 9377\n",
      "Predicted label for real data: 0.5684567093849182\n"
     ]
    }
   ],
   "source": [
    "class DiscWithExtraPaddedConvAfterPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithExtraPaddedConvAfterPool().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 9377\n",
      "Predicted label for real data: 0.5029851198196411\n"
     ]
    }
   ],
   "source": [
    "class DiscWithExtraPaddedConvBeforePool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithExtraPaddedConvBeforePool().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 7057\n",
      "Predicted label for real data: 0.48209959268569946\n"
     ]
    }
   ],
   "source": [
    "class DiscWithStridedConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential( # Input = (batch, 4, 22, 10)\n",
    "                nn.Conv2d(4, 16, 3, stride=2, padding=1), # (batch, 16, 11, 5)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3), # (batch, 16, 9, 3)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3), # (batch, 16, 7, 1)\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithStridedConv().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discriminator parameters: 7297\n",
      "Predicted label for real data: 0.5613160729408264\n"
     ]
    }
   ],
   "source": [
    "class DiscWith2x2Conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential( # Input = (batch, 4, 22, 10)\n",
    "                nn.Conv2d(4, 16, kernel_size=2, padding=1), # (batch, 16, 23, 11)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, kernel_size=2), # (batch, 16, 22, 10)\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2), # (batch, 16, 11, 5)\n",
    "                nn.Conv2d(16, 16, kernel_size=2), # (batch, 16, 10, 4)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, kernel_size=2), # (batch, 16, 9, 3)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, kernel_size=2), # (batch, 16, 8, 2)\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, kernel_size=2), # (batch, 16, 7, 1)\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWith2x2Conv().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3948, G loss: 0.6064\n",
      "[84/1762] D loss: 1.3908, G loss: 0.6129\n",
      "[164/1762] D loss: 1.3851, G loss: 0.6189\n",
      "[244/1762] D loss: 1.3703, G loss: 0.6188\n",
      "[324/1762] D loss: 1.3537, G loss: 0.6300\n",
      "[404/1762] D loss: 1.3312, G loss: 0.6328\n",
      "[484/1762] D loss: 1.2939, G loss: 0.6547\n",
      "[564/1762] D loss: 1.2336, G loss: 0.6851\n",
      "[644/1762] D loss: 1.0954, G loss: 0.7581\n",
      "[724/1762] D loss: 1.1137, G loss: 0.8374\n",
      "[804/1762] D loss: 0.8369, G loss: 1.0726\n",
      "[884/1762] D loss: 0.6942, G loss: 1.3732\n",
      "[964/1762] D loss: 0.5070, G loss: 1.5776\n",
      "[1044/1762] D loss: 0.3901, G loss: 1.8424\n",
      "[1124/1762] D loss: 0.2664, G loss: 2.2254\n",
      "[1204/1762] D loss: 0.2091, G loss: 2.6314\n",
      "[1284/1762] D loss: 0.1719, G loss: 3.0401\n",
      "[1364/1762] D loss: 0.1628, G loss: 3.0700\n",
      "[1444/1762] D loss: 0.1875, G loss: 3.2569\n",
      "[1524/1762] D loss: 0.1217, G loss: 3.4364\n",
      "[1604/1762] D loss: 0.4429, G loss: 3.5748\n",
      "[1684/1762] D loss: 0.1394, G loss: 3.7527\n",
      "[1762/1762] D loss: 0.1236, G loss: 4.0433\n",
      "train error: \n",
      " D loss: 0.164853, G loss: 3.861118, D accuracy: 100.0%, cell accuracy: 86.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.164612, G loss: 3.874051, D accuracy: 100.0%, cell accuracy: 86.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1548, G loss: 3.6844\n",
      "[84/1762] D loss: 0.1515, G loss: 3.7140\n",
      "[164/1762] D loss: 0.3322, G loss: 4.6971\n",
      "[244/1762] D loss: 0.1563, G loss: 4.4816\n",
      "[324/1762] D loss: 0.1516, G loss: 4.1898\n",
      "[404/1762] D loss: 0.1345, G loss: 3.9642\n",
      "[484/1762] D loss: 0.1113, G loss: 4.5652\n",
      "[564/1762] D loss: 0.2956, G loss: 3.6930\n",
      "[644/1762] D loss: 0.1412, G loss: 4.5947\n",
      "[724/1762] D loss: 0.1180, G loss: 5.0697\n",
      "[804/1762] D loss: 0.4297, G loss: 4.2095\n",
      "[884/1762] D loss: 0.1912, G loss: 4.2353\n",
      "[964/1762] D loss: 0.1736, G loss: 4.8007\n",
      "[1044/1762] D loss: 0.4105, G loss: 3.8122\n",
      "[1124/1762] D loss: 0.2179, G loss: 4.9810\n",
      "[1204/1762] D loss: 0.1129, G loss: 4.5053\n",
      "[1284/1762] D loss: 0.2254, G loss: 5.2766\n",
      "[1364/1762] D loss: 0.1618, G loss: 5.4378\n",
      "[1444/1762] D loss: 0.5882, G loss: 4.8150\n",
      "[1524/1762] D loss: 0.1288, G loss: 4.4745\n",
      "[1604/1762] D loss: 0.1108, G loss: 4.2404\n",
      "[1684/1762] D loss: 0.0688, G loss: 3.4839\n",
      "[1762/1762] D loss: 0.0811, G loss: 2.9528\n",
      "train error: \n",
      " D loss: 0.112322, G loss: 4.407163, D accuracy: 99.8%, cell accuracy: 95.6%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.112252, G loss: 4.399642, D accuracy: 100.0%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1052, G loss: 3.7632\n",
      "[84/1762] D loss: 0.1770, G loss: 3.0873\n",
      "[164/1762] D loss: 0.0850, G loss: 3.4200\n",
      "[244/1762] D loss: 0.1980, G loss: 3.3521\n",
      "[324/1762] D loss: 0.1580, G loss: 2.3313\n",
      "[404/1762] D loss: 0.3679, G loss: 2.6266\n",
      "[484/1762] D loss: 0.2803, G loss: 2.6949\n",
      "[564/1762] D loss: 0.1610, G loss: 2.4166\n",
      "[644/1762] D loss: 0.3930, G loss: 2.9584\n",
      "[724/1762] D loss: 0.3705, G loss: 3.5506\n",
      "[804/1762] D loss: 0.1839, G loss: 2.1498\n",
      "[884/1762] D loss: 0.2208, G loss: 3.0391\n",
      "[964/1762] D loss: 0.3048, G loss: 1.9604\n",
      "[1044/1762] D loss: 0.1485, G loss: 2.6695\n",
      "[1124/1762] D loss: 0.4036, G loss: 1.8099\n",
      "[1204/1762] D loss: 0.2870, G loss: 2.1181\n",
      "[1284/1762] D loss: 0.3081, G loss: 2.0408\n",
      "[1364/1762] D loss: 0.4275, G loss: 2.2524\n",
      "[1444/1762] D loss: 0.4312, G loss: 1.2970\n",
      "[1524/1762] D loss: 0.2630, G loss: 2.6372\n",
      "[1604/1762] D loss: 0.2992, G loss: 1.8632\n",
      "[1684/1762] D loss: 0.2883, G loss: 1.9758\n",
      "[1762/1762] D loss: 0.8225, G loss: 1.3230\n",
      "train error: \n",
      " D loss: 0.425220, G loss: 2.143924, D accuracy: 96.2%, cell accuracy: 97.5%, board accuracy: 3.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.428652, G loss: 2.142359, D accuracy: 97.2%, cell accuracy: 97.4%, board accuracy: 2.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5774, G loss: 1.9502\n",
      "[84/1762] D loss: 0.5249, G loss: 1.2982\n",
      "[164/1762] D loss: 0.2573, G loss: 1.7378\n",
      "[244/1762] D loss: 0.3696, G loss: 1.6599\n",
      "[324/1762] D loss: 0.6389, G loss: 1.5031\n",
      "[404/1762] D loss: 0.4573, G loss: 1.5359\n",
      "[484/1762] D loss: 1.4618, G loss: 1.1065\n",
      "[564/1762] D loss: 0.4703, G loss: 1.4578\n",
      "[644/1762] D loss: 0.3722, G loss: 2.0098\n",
      "[724/1762] D loss: 0.5499, G loss: 1.4470\n",
      "[804/1762] D loss: 0.4416, G loss: 1.7613\n",
      "[884/1762] D loss: 0.5257, G loss: 1.9608\n",
      "[964/1762] D loss: 0.4847, G loss: 2.0670\n",
      "[1044/1762] D loss: 0.7810, G loss: 0.9070\n",
      "[1124/1762] D loss: 0.5767, G loss: 1.5947\n",
      "[1204/1762] D loss: 0.4810, G loss: 1.2749\n",
      "[1284/1762] D loss: 0.8720, G loss: 0.6937\n",
      "[1364/1762] D loss: 0.8141, G loss: 0.9153\n",
      "[1444/1762] D loss: 0.3782, G loss: 1.8632\n",
      "[1524/1762] D loss: 0.9893, G loss: 0.9701\n",
      "[1604/1762] D loss: 1.2346, G loss: 1.6993\n",
      "[1684/1762] D loss: 0.6121, G loss: 1.8673\n",
      "[1762/1762] D loss: 0.4995, G loss: 1.7261\n",
      "train error: \n",
      " D loss: 0.682257, G loss: 1.910679, D accuracy: 88.9%, cell accuracy: 98.0%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.722989, G loss: 1.885494, D accuracy: 87.5%, cell accuracy: 97.9%, board accuracy: 4.1% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4461, G loss: 2.2566\n",
      "[84/1762] D loss: 0.6882, G loss: 2.3638\n",
      "[164/1762] D loss: 0.6423, G loss: 1.3575\n",
      "[244/1762] D loss: 1.0649, G loss: 1.1839\n",
      "[324/1762] D loss: 0.7736, G loss: 1.4969\n",
      "[404/1762] D loss: 0.7591, G loss: 1.0589\n",
      "[484/1762] D loss: 0.5432, G loss: 1.5056\n",
      "[564/1762] D loss: 1.4194, G loss: 2.6712\n",
      "[644/1762] D loss: 0.6143, G loss: 1.7424\n",
      "[724/1762] D loss: 1.3024, G loss: 1.6012\n",
      "[804/1762] D loss: 0.5140, G loss: 1.9189\n",
      "[884/1762] D loss: 0.9617, G loss: 1.9836\n",
      "[964/1762] D loss: 0.4964, G loss: 2.3120\n",
      "[1044/1762] D loss: 0.6926, G loss: 0.9187\n",
      "[1124/1762] D loss: 0.9976, G loss: 0.7184\n",
      "[1204/1762] D loss: 1.3435, G loss: 1.4118\n",
      "[1284/1762] D loss: 1.2404, G loss: 1.7025\n",
      "[1364/1762] D loss: 0.9628, G loss: 1.4752\n",
      "[1444/1762] D loss: 0.6110, G loss: 0.9904\n",
      "[1524/1762] D loss: 0.7934, G loss: 1.4117\n",
      "[1604/1762] D loss: 1.3428, G loss: 0.9750\n",
      "[1684/1762] D loss: 0.6060, G loss: 1.8779\n",
      "[1762/1762] D loss: 0.7246, G loss: 1.1099\n",
      "train error: \n",
      " D loss: 0.841794, G loss: 1.488522, D accuracy: 83.5%, cell accuracy: 98.1%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.877568, G loss: 1.473220, D accuracy: 82.4%, cell accuracy: 98.1%, board accuracy: 3.9% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9404, G loss: 1.8563\n",
      "[84/1762] D loss: 0.5520, G loss: 1.5908\n",
      "[164/1762] D loss: 0.6230, G loss: 1.5187\n",
      "[244/1762] D loss: 0.6830, G loss: 1.0668\n",
      "[324/1762] D loss: 0.8250, G loss: 0.8248\n",
      "[404/1762] D loss: 0.9148, G loss: 1.1079\n",
      "[484/1762] D loss: 0.4958, G loss: 1.4657\n",
      "[564/1762] D loss: 0.6393, G loss: 1.7898\n",
      "[644/1762] D loss: 0.6049, G loss: 1.3985\n",
      "[724/1762] D loss: 1.1858, G loss: 0.7230\n",
      "[804/1762] D loss: 0.9961, G loss: 1.4323\n",
      "[884/1762] D loss: 0.7320, G loss: 1.1815\n",
      "[964/1762] D loss: 0.6082, G loss: 1.4577\n",
      "[1044/1762] D loss: 0.7412, G loss: 1.7590\n",
      "[1124/1762] D loss: 1.3318, G loss: 0.9452\n",
      "[1204/1762] D loss: 1.4879, G loss: 0.5699\n",
      "[1284/1762] D loss: 1.1484, G loss: 1.3927\n",
      "[1364/1762] D loss: 1.5551, G loss: 0.4510\n",
      "[1444/1762] D loss: 1.0623, G loss: 0.7788\n",
      "[1524/1762] D loss: 0.9460, G loss: 1.5828\n",
      "[1604/1762] D loss: 1.2695, G loss: 0.5144\n",
      "[1684/1762] D loss: 0.8019, G loss: 1.7477\n",
      "[1762/1762] D loss: 1.7673, G loss: 0.5474\n",
      "train error: \n",
      " D loss: 1.284351, G loss: 1.428606, D accuracy: 65.1%, cell accuracy: 98.8%, board accuracy: 18.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330064, G loss: 1.493086, D accuracy: 62.6%, cell accuracy: 98.7%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2834, G loss: 1.0461\n",
      "[84/1762] D loss: 1.2559, G loss: 1.6140\n",
      "[164/1762] D loss: 0.9541, G loss: 1.0963\n",
      "[244/1762] D loss: 1.1617, G loss: 1.1514\n",
      "[324/1762] D loss: 1.1689, G loss: 0.8479\n",
      "[404/1762] D loss: 1.1570, G loss: 0.8995\n",
      "[484/1762] D loss: 1.0996, G loss: 1.2321\n",
      "[564/1762] D loss: 1.3231, G loss: 0.7772\n",
      "[644/1762] D loss: 0.9441, G loss: 0.9560\n",
      "[724/1762] D loss: 1.1088, G loss: 0.7884\n",
      "[804/1762] D loss: 1.2472, G loss: 0.9162\n",
      "[884/1762] D loss: 1.2795, G loss: 0.6589\n",
      "[964/1762] D loss: 1.2709, G loss: 0.7612\n",
      "[1044/1762] D loss: 1.4740, G loss: 0.4607\n",
      "[1124/1762] D loss: 1.1276, G loss: 0.4811\n",
      "[1204/1762] D loss: 1.6968, G loss: 1.7588\n",
      "[1284/1762] D loss: 1.1656, G loss: 0.6706\n",
      "[1364/1762] D loss: 1.1240, G loss: 1.0320\n",
      "[1444/1762] D loss: 1.2443, G loss: 1.1453\n",
      "[1524/1762] D loss: 1.1126, G loss: 0.7601\n",
      "[1604/1762] D loss: 1.2144, G loss: 1.1840\n",
      "[1684/1762] D loss: 1.2469, G loss: 0.7100\n",
      "[1762/1762] D loss: 1.9913, G loss: 0.9258\n",
      "train error: \n",
      " D loss: 1.260053, G loss: 0.932601, D accuracy: 67.1%, cell accuracy: 99.1%, board accuracy: 25.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270741, G loss: 0.967496, D accuracy: 65.5%, cell accuracy: 99.0%, board accuracy: 22.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4192, G loss: 0.9086\n",
      "[84/1762] D loss: 1.1059, G loss: 1.0228\n",
      "[164/1762] D loss: 0.9438, G loss: 0.9654\n",
      "[244/1762] D loss: 1.3256, G loss: 0.7565\n",
      "[324/1762] D loss: 1.2465, G loss: 0.8071\n",
      "[404/1762] D loss: 1.2843, G loss: 0.6570\n",
      "[484/1762] D loss: 1.4338, G loss: 1.1432\n",
      "[564/1762] D loss: 1.1576, G loss: 1.1829\n",
      "[644/1762] D loss: 1.1290, G loss: 1.2739\n",
      "[724/1762] D loss: 1.4968, G loss: 0.6251\n",
      "[804/1762] D loss: 1.3874, G loss: 1.0239\n",
      "[884/1762] D loss: 1.6002, G loss: 0.5601\n",
      "[964/1762] D loss: 1.4445, G loss: 0.6185\n",
      "[1044/1762] D loss: 1.4221, G loss: 0.5419\n",
      "[1124/1762] D loss: 1.1915, G loss: 0.9182\n",
      "[1204/1762] D loss: 1.2706, G loss: 1.0078\n",
      "[1284/1762] D loss: 1.0849, G loss: 1.0501\n",
      "[1364/1762] D loss: 1.2964, G loss: 0.7328\n",
      "[1444/1762] D loss: 1.1460, G loss: 1.0027\n",
      "[1524/1762] D loss: 1.3347, G loss: 0.5905\n",
      "[1604/1762] D loss: 1.2313, G loss: 0.9660\n",
      "[1684/1762] D loss: 1.2918, G loss: 1.6507\n",
      "[1762/1762] D loss: 1.1923, G loss: 0.7742\n",
      "train error: \n",
      " D loss: 1.303592, G loss: 0.746285, D accuracy: 63.3%, cell accuracy: 99.1%, board accuracy: 23.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305723, G loss: 0.774819, D accuracy: 63.3%, cell accuracy: 99.0%, board accuracy: 20.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5583, G loss: 0.8493\n",
      "[84/1762] D loss: 1.3075, G loss: 0.7116\n",
      "[164/1762] D loss: 1.2197, G loss: 0.6426\n",
      "[244/1762] D loss: 1.5598, G loss: 0.5163\n",
      "[324/1762] D loss: 1.2648, G loss: 1.0529\n",
      "[404/1762] D loss: 1.3379, G loss: 0.5718\n",
      "[484/1762] D loss: 1.2999, G loss: 0.7784\n",
      "[564/1762] D loss: 1.5615, G loss: 0.5457\n",
      "[644/1762] D loss: 1.1645, G loss: 0.5005\n",
      "[724/1762] D loss: 1.1975, G loss: 0.9525\n",
      "[804/1762] D loss: 1.1639, G loss: 0.8408\n",
      "[884/1762] D loss: 1.2087, G loss: 0.8443\n",
      "[964/1762] D loss: 1.3473, G loss: 1.1843\n",
      "[1044/1762] D loss: 1.4137, G loss: 0.7462\n",
      "[1124/1762] D loss: 1.4110, G loss: 0.8925\n",
      "[1204/1762] D loss: 1.3455, G loss: 0.3953\n",
      "[1284/1762] D loss: 1.2610, G loss: 0.7187\n",
      "[1364/1762] D loss: 1.2347, G loss: 0.8030\n",
      "[1444/1762] D loss: 1.3533, G loss: 0.5611\n",
      "[1524/1762] D loss: 1.5275, G loss: 1.0352\n",
      "[1604/1762] D loss: 1.5903, G loss: 0.8310\n",
      "[1684/1762] D loss: 1.2981, G loss: 0.5153\n",
      "[1762/1762] D loss: 1.5246, G loss: 0.8015\n",
      "train error: \n",
      " D loss: 1.312580, G loss: 0.958938, D accuracy: 64.4%, cell accuracy: 99.1%, board accuracy: 22.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322672, G loss: 0.986324, D accuracy: 63.5%, cell accuracy: 99.0%, board accuracy: 19.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4550, G loss: 0.9485\n",
      "[84/1762] D loss: 1.4230, G loss: 0.8516\n",
      "[164/1762] D loss: 1.2556, G loss: 0.9624\n",
      "[244/1762] D loss: 1.3178, G loss: 0.9707\n",
      "[324/1762] D loss: 1.2392, G loss: 1.0778\n",
      "[404/1762] D loss: 1.1768, G loss: 0.7365\n",
      "[484/1762] D loss: 1.5574, G loss: 0.9975\n",
      "[564/1762] D loss: 1.2986, G loss: 0.6692\n",
      "[644/1762] D loss: 1.1342, G loss: 1.0640\n",
      "[724/1762] D loss: 1.1491, G loss: 0.8015\n",
      "[804/1762] D loss: 1.1742, G loss: 1.4574\n",
      "[884/1762] D loss: 1.1735, G loss: 0.8271\n",
      "[964/1762] D loss: 1.1730, G loss: 0.9175\n",
      "[1044/1762] D loss: 1.2709, G loss: 0.9372\n",
      "[1124/1762] D loss: 1.1261, G loss: 1.2754\n",
      "[1204/1762] D loss: 1.2608, G loss: 0.7698\n",
      "[1284/1762] D loss: 1.5162, G loss: 1.0015\n",
      "[1364/1762] D loss: 1.4365, G loss: 0.7653\n",
      "[1444/1762] D loss: 1.3931, G loss: 1.3052\n",
      "[1524/1762] D loss: 1.2663, G loss: 0.9171\n",
      "[1604/1762] D loss: 1.0696, G loss: 0.9717\n",
      "[1684/1762] D loss: 1.3641, G loss: 0.7336\n",
      "[1762/1762] D loss: 1.1781, G loss: 0.6695\n",
      "train error: \n",
      " D loss: 1.354312, G loss: 0.597245, D accuracy: 57.7%, cell accuracy: 99.1%, board accuracy: 25.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355696, G loss: 0.609318, D accuracy: 58.0%, cell accuracy: 99.0%, board accuracy: 22.3% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1783, G loss: 0.7420\n",
      "[84/1762] D loss: 1.2553, G loss: 1.0447\n",
      "[164/1762] D loss: 1.1268, G loss: 1.1144\n",
      "[244/1762] D loss: 1.4100, G loss: 0.5649\n",
      "[324/1762] D loss: 1.2891, G loss: 0.8910\n",
      "[404/1762] D loss: 1.3632, G loss: 0.6096\n",
      "[484/1762] D loss: 1.1023, G loss: 0.8743\n",
      "[564/1762] D loss: 1.3271, G loss: 0.8021\n",
      "[644/1762] D loss: 1.2005, G loss: 1.0366\n",
      "[724/1762] D loss: 1.4081, G loss: 0.6012\n",
      "[804/1762] D loss: 1.0576, G loss: 1.1368\n",
      "[884/1762] D loss: 1.3402, G loss: 0.9249\n",
      "[964/1762] D loss: 1.3602, G loss: 0.7121\n",
      "[1044/1762] D loss: 1.0137, G loss: 1.1776\n",
      "[1124/1762] D loss: 1.4017, G loss: 0.6273\n",
      "[1204/1762] D loss: 1.3539, G loss: 0.7016\n",
      "[1284/1762] D loss: 1.3616, G loss: 0.5184\n",
      "[1364/1762] D loss: 1.2589, G loss: 0.7339\n",
      "[1444/1762] D loss: 1.1737, G loss: 1.1883\n",
      "[1524/1762] D loss: 1.0010, G loss: 1.1041\n",
      "[1604/1762] D loss: 1.4203, G loss: 0.6918\n",
      "[1684/1762] D loss: 1.3639, G loss: 0.7261\n",
      "[1762/1762] D loss: 1.3976, G loss: 0.6124\n",
      "train error: \n",
      " D loss: 1.328844, G loss: 0.713782, D accuracy: 61.3%, cell accuracy: 99.1%, board accuracy: 29.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321317, G loss: 0.737041, D accuracy: 59.8%, cell accuracy: 99.0%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2503, G loss: 0.7682\n",
      "[84/1762] D loss: 1.1600, G loss: 0.5853\n",
      "[164/1762] D loss: 1.4343, G loss: 0.8044\n",
      "[244/1762] D loss: 1.2960, G loss: 0.7122\n",
      "[324/1762] D loss: 1.3433, G loss: 1.6940\n",
      "[404/1762] D loss: 1.6017, G loss: 0.5046\n",
      "[484/1762] D loss: 1.5018, G loss: 0.9049\n",
      "[564/1762] D loss: 1.4298, G loss: 0.6208\n",
      "[644/1762] D loss: 1.4397, G loss: 1.3206\n",
      "[724/1762] D loss: 1.2973, G loss: 0.8060\n",
      "[804/1762] D loss: 1.3601, G loss: 0.6618\n",
      "[884/1762] D loss: 1.0936, G loss: 0.9634\n",
      "[964/1762] D loss: 1.3054, G loss: 0.7323\n",
      "[1044/1762] D loss: 1.3515, G loss: 0.7270\n",
      "[1124/1762] D loss: 1.5669, G loss: 0.4069\n",
      "[1204/1762] D loss: 0.9923, G loss: 0.9210\n",
      "[1284/1762] D loss: 1.1245, G loss: 1.0180\n",
      "[1364/1762] D loss: 1.3400, G loss: 0.6869\n",
      "[1444/1762] D loss: 1.3722, G loss: 0.5868\n",
      "[1524/1762] D loss: 1.2778, G loss: 0.8466\n",
      "[1604/1762] D loss: 1.2796, G loss: 0.9253\n",
      "[1684/1762] D loss: 1.3311, G loss: 0.6561\n",
      "[1762/1762] D loss: 1.0911, G loss: 0.8256\n",
      "train error: \n",
      " D loss: 1.345509, G loss: 1.071478, D accuracy: 61.5%, cell accuracy: 99.2%, board accuracy: 35.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355145, G loss: 1.087165, D accuracy: 61.3%, cell accuracy: 99.1%, board accuracy: 30.7% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4420, G loss: 0.9262\n",
      "[84/1762] D loss: 1.3279, G loss: 0.7606\n",
      "[164/1762] D loss: 1.3460, G loss: 0.9143\n",
      "[244/1762] D loss: 1.2721, G loss: 0.8312\n",
      "[324/1762] D loss: 1.6716, G loss: 0.9191\n",
      "[404/1762] D loss: 1.4753, G loss: 0.8034\n",
      "[484/1762] D loss: 1.1671, G loss: 0.8070\n",
      "[564/1762] D loss: 1.2294, G loss: 0.9070\n",
      "[644/1762] D loss: 1.2220, G loss: 0.7653\n",
      "[724/1762] D loss: 1.5268, G loss: 0.8046\n",
      "[804/1762] D loss: 1.3437, G loss: 0.5833\n",
      "[884/1762] D loss: 1.4914, G loss: 1.4224\n",
      "[964/1762] D loss: 1.3126, G loss: 0.7161\n",
      "[1044/1762] D loss: 1.4268, G loss: 0.6666\n",
      "[1124/1762] D loss: 1.1950, G loss: 0.9792\n",
      "[1204/1762] D loss: 1.3166, G loss: 0.6746\n",
      "[1284/1762] D loss: 1.3683, G loss: 0.6600\n",
      "[1364/1762] D loss: 1.3408, G loss: 1.0754\n",
      "[1444/1762] D loss: 1.3416, G loss: 0.8812\n",
      "[1524/1762] D loss: 1.3218, G loss: 0.6429\n",
      "[1604/1762] D loss: 1.4135, G loss: 0.7446\n",
      "[1684/1762] D loss: 1.5314, G loss: 0.4819\n",
      "[1762/1762] D loss: 1.4655, G loss: 0.8281\n",
      "train error: \n",
      " D loss: 1.387677, G loss: 0.673379, D accuracy: 57.5%, cell accuracy: 99.3%, board accuracy: 44.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379746, G loss: 0.683543, D accuracy: 56.5%, cell accuracy: 99.2%, board accuracy: 38.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4006, G loss: 0.5348\n",
      "[84/1762] D loss: 1.3747, G loss: 0.6060\n",
      "[164/1762] D loss: 1.2665, G loss: 0.8765\n",
      "[244/1762] D loss: 1.4052, G loss: 0.8840\n",
      "[324/1762] D loss: 1.4216, G loss: 0.6438\n",
      "[404/1762] D loss: 1.7249, G loss: 1.2540\n",
      "[484/1762] D loss: 1.2286, G loss: 1.0699\n",
      "[564/1762] D loss: 1.4153, G loss: 0.7644\n",
      "[644/1762] D loss: 1.4728, G loss: 0.5632\n",
      "[724/1762] D loss: 1.3256, G loss: 0.7652\n",
      "[804/1762] D loss: 1.2418, G loss: 0.8022\n",
      "[884/1762] D loss: 1.5661, G loss: 0.7325\n",
      "[964/1762] D loss: 1.3047, G loss: 0.9670\n",
      "[1044/1762] D loss: 1.3142, G loss: 1.0131\n",
      "[1124/1762] D loss: 1.3243, G loss: 0.9542\n",
      "[1204/1762] D loss: 1.3404, G loss: 0.7867\n",
      "[1284/1762] D loss: 1.4199, G loss: 0.7078\n",
      "[1364/1762] D loss: 1.3840, G loss: 0.8054\n",
      "[1444/1762] D loss: 1.3477, G loss: 1.0119\n",
      "[1524/1762] D loss: 1.4363, G loss: 0.6010\n",
      "[1604/1762] D loss: 1.4225, G loss: 0.5335\n",
      "[1684/1762] D loss: 1.4129, G loss: 0.7394\n",
      "[1762/1762] D loss: 1.3045, G loss: 0.6600\n",
      "train error: \n",
      " D loss: 1.380430, G loss: 0.885181, D accuracy: 56.1%, cell accuracy: 99.4%, board accuracy: 51.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376283, G loss: 0.895184, D accuracy: 54.7%, cell accuracy: 99.3%, board accuracy: 43.6% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3749, G loss: 0.9117\n",
      "[84/1762] D loss: 1.2368, G loss: 0.6863\n",
      "[164/1762] D loss: 1.3758, G loss: 0.5941\n",
      "[244/1762] D loss: 1.3222, G loss: 1.0723\n",
      "[324/1762] D loss: 1.4817, G loss: 0.9391\n",
      "[404/1762] D loss: 1.2834, G loss: 0.5916\n",
      "[484/1762] D loss: 1.2799, G loss: 0.7927\n",
      "[564/1762] D loss: 1.3922, G loss: 0.7089\n",
      "[644/1762] D loss: 1.3763, G loss: 0.8013\n",
      "[724/1762] D loss: 1.3891, G loss: 0.7101\n",
      "[804/1762] D loss: 1.3630, G loss: 0.7371\n",
      "[884/1762] D loss: 1.5203, G loss: 0.6025\n",
      "[964/1762] D loss: 1.3207, G loss: 0.7662\n",
      "[1044/1762] D loss: 1.2985, G loss: 0.7818\n",
      "[1124/1762] D loss: 1.3616, G loss: 0.6097\n",
      "[1204/1762] D loss: 1.3018, G loss: 0.6979\n",
      "[1284/1762] D loss: 1.3775, G loss: 0.9099\n",
      "[1364/1762] D loss: 1.3494, G loss: 0.8159\n",
      "[1444/1762] D loss: 1.4178, G loss: 0.7001\n",
      "[1524/1762] D loss: 1.3598, G loss: 0.5257\n",
      "[1604/1762] D loss: 1.3128, G loss: 0.7482\n",
      "[1684/1762] D loss: 1.4171, G loss: 0.5496\n",
      "[1762/1762] D loss: 1.3127, G loss: 0.6483\n",
      "train error: \n",
      " D loss: 1.381325, G loss: 0.809096, D accuracy: 56.4%, cell accuracy: 99.5%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377795, G loss: 0.816948, D accuracy: 55.3%, cell accuracy: 99.4%, board accuracy: 53.6% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4269, G loss: 0.9234\n",
      "[84/1762] D loss: 1.3004, G loss: 0.8522\n",
      "[164/1762] D loss: 1.4740, G loss: 0.5609\n",
      "[244/1762] D loss: 1.3998, G loss: 0.5764\n",
      "[324/1762] D loss: 1.3463, G loss: 0.6745\n",
      "[404/1762] D loss: 1.2949, G loss: 0.7642\n",
      "[484/1762] D loss: 1.4675, G loss: 1.0456\n",
      "[564/1762] D loss: 1.4659, G loss: 1.1632\n",
      "[644/1762] D loss: 1.5027, G loss: 0.5429\n",
      "[724/1762] D loss: 1.3902, G loss: 0.5646\n",
      "[804/1762] D loss: 1.3439, G loss: 0.6458\n",
      "[884/1762] D loss: 1.3464, G loss: 0.5504\n",
      "[964/1762] D loss: 1.4148, G loss: 0.6367\n",
      "[1044/1762] D loss: 1.3644, G loss: 0.4883\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.5990\n",
      "[1204/1762] D loss: 1.2257, G loss: 0.7987\n",
      "[1284/1762] D loss: 1.3735, G loss: 0.5842\n",
      "[1364/1762] D loss: 1.2536, G loss: 0.9295\n",
      "[1444/1762] D loss: 1.4040, G loss: 0.6429\n",
      "[1524/1762] D loss: 1.4022, G loss: 0.6521\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.9017\n",
      "[1684/1762] D loss: 1.4924, G loss: 0.8199\n",
      "[1762/1762] D loss: 1.3532, G loss: 0.8489\n",
      "train error: \n",
      " D loss: 1.403884, G loss: 0.928989, D accuracy: 52.3%, cell accuracy: 99.5%, board accuracy: 61.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399846, G loss: 0.936458, D accuracy: 52.5%, cell accuracy: 99.4%, board accuracy: 55.9% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3125, G loss: 0.9070\n",
      "[84/1762] D loss: 1.3236, G loss: 0.8297\n",
      "[164/1762] D loss: 1.4651, G loss: 0.5952\n",
      "[244/1762] D loss: 1.4261, G loss: 0.9173\n",
      "[324/1762] D loss: 1.3866, G loss: 0.5793\n",
      "[404/1762] D loss: 1.3836, G loss: 0.7755\n",
      "[484/1762] D loss: 1.4677, G loss: 0.8112\n",
      "[564/1762] D loss: 1.3852, G loss: 0.8355\n",
      "[644/1762] D loss: 1.3183, G loss: 0.7835\n",
      "[724/1762] D loss: 1.4016, G loss: 0.5945\n",
      "[804/1762] D loss: 1.2770, G loss: 0.8485\n",
      "[884/1762] D loss: 1.3193, G loss: 0.7428\n",
      "[964/1762] D loss: 1.4997, G loss: 1.1485\n",
      "[1044/1762] D loss: 1.3665, G loss: 0.6156\n",
      "[1124/1762] D loss: 1.3585, G loss: 0.7445\n",
      "[1204/1762] D loss: 1.4044, G loss: 0.6656\n",
      "[1284/1762] D loss: 1.4288, G loss: 0.6787\n",
      "[1364/1762] D loss: 1.5146, G loss: 0.5615\n",
      "[1444/1762] D loss: 1.3723, G loss: 0.7669\n",
      "[1524/1762] D loss: 1.2952, G loss: 0.8136\n",
      "[1604/1762] D loss: 1.3344, G loss: 0.6496\n",
      "[1684/1762] D loss: 1.3938, G loss: 0.6713\n",
      "[1762/1762] D loss: 1.5377, G loss: 0.5215\n",
      "train error: \n",
      " D loss: 1.396466, G loss: 0.788740, D accuracy: 53.2%, cell accuracy: 99.6%, board accuracy: 62.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384777, G loss: 0.804841, D accuracy: 53.1%, cell accuracy: 99.5%, board accuracy: 56.6% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3255, G loss: 0.9915\n",
      "[84/1762] D loss: 1.5140, G loss: 0.7432\n",
      "[164/1762] D loss: 1.3989, G loss: 0.8596\n",
      "[244/1762] D loss: 1.4581, G loss: 0.6025\n",
      "[324/1762] D loss: 1.4457, G loss: 0.9043\n",
      "[404/1762] D loss: 1.3433, G loss: 0.7598\n",
      "[484/1762] D loss: 1.3502, G loss: 0.7328\n",
      "[564/1762] D loss: 1.4174, G loss: 0.6252\n",
      "[644/1762] D loss: 1.4664, G loss: 0.5192\n",
      "[724/1762] D loss: 1.4824, G loss: 0.5364\n",
      "[804/1762] D loss: 1.3971, G loss: 0.5261\n",
      "[884/1762] D loss: 1.3312, G loss: 0.6240\n",
      "[964/1762] D loss: 1.3105, G loss: 0.7301\n",
      "[1044/1762] D loss: 1.3773, G loss: 0.6903\n",
      "[1124/1762] D loss: 1.3645, G loss: 0.7333\n",
      "[1204/1762] D loss: 1.4128, G loss: 0.6272\n",
      "[1284/1762] D loss: 1.4074, G loss: 0.8002\n",
      "[1364/1762] D loss: 1.3664, G loss: 0.7633\n",
      "[1444/1762] D loss: 1.5652, G loss: 1.0298\n",
      "[1524/1762] D loss: 1.4041, G loss: 0.5640\n",
      "[1604/1762] D loss: 1.4117, G loss: 0.7086\n",
      "[1684/1762] D loss: 1.4555, G loss: 0.6930\n",
      "[1762/1762] D loss: 1.2928, G loss: 0.8848\n",
      "train error: \n",
      " D loss: 1.399019, G loss: 0.743800, D accuracy: 53.4%, cell accuracy: 99.6%, board accuracy: 67.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389870, G loss: 0.758741, D accuracy: 54.8%, cell accuracy: 99.5%, board accuracy: 64.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3773, G loss: 0.8707\n",
      "[84/1762] D loss: 1.4198, G loss: 0.6205\n",
      "[164/1762] D loss: 1.3643, G loss: 0.6006\n",
      "[244/1762] D loss: 1.4005, G loss: 0.6210\n",
      "[324/1762] D loss: 1.3856, G loss: 0.5749\n",
      "[404/1762] D loss: 1.3280, G loss: 0.7219\n",
      "[484/1762] D loss: 1.4323, G loss: 0.5840\n",
      "[564/1762] D loss: 1.3412, G loss: 0.8220\n",
      "[644/1762] D loss: 1.4878, G loss: 0.5381\n",
      "[724/1762] D loss: 1.4411, G loss: 0.7987\n",
      "[804/1762] D loss: 1.3749, G loss: 0.7368\n",
      "[884/1762] D loss: 1.3770, G loss: 1.1109\n",
      "[964/1762] D loss: 1.3801, G loss: 0.7260\n",
      "[1044/1762] D loss: 1.4760, G loss: 0.9188\n",
      "[1124/1762] D loss: 1.3464, G loss: 0.6229\n",
      "[1204/1762] D loss: 1.3846, G loss: 0.7059\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.6385\n",
      "[1364/1762] D loss: 1.3796, G loss: 0.7203\n",
      "[1444/1762] D loss: 1.4345, G loss: 0.6320\n",
      "[1524/1762] D loss: 1.3902, G loss: 0.5881\n",
      "[1604/1762] D loss: 1.4364, G loss: 0.5432\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.7020\n",
      "[1762/1762] D loss: 1.3760, G loss: 0.7021\n",
      "train error: \n",
      " D loss: 1.397187, G loss: 0.665475, D accuracy: 52.8%, cell accuracy: 99.6%, board accuracy: 67.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386549, G loss: 0.680446, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 65.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5307, G loss: 0.6263\n",
      "[84/1762] D loss: 1.4540, G loss: 0.5976\n",
      "[164/1762] D loss: 1.4590, G loss: 0.7788\n",
      "[244/1762] D loss: 1.3622, G loss: 0.7318\n",
      "[324/1762] D loss: 1.3662, G loss: 0.6717\n",
      "[404/1762] D loss: 1.4412, G loss: 0.8698\n",
      "[484/1762] D loss: 1.3806, G loss: 0.6595\n",
      "[564/1762] D loss: 1.5427, G loss: 1.2189\n",
      "[644/1762] D loss: 1.3792, G loss: 0.8658\n",
      "[724/1762] D loss: 1.4313, G loss: 0.6165\n",
      "[804/1762] D loss: 1.3952, G loss: 0.8120\n",
      "[884/1762] D loss: 1.4364, G loss: 0.8190\n",
      "[964/1762] D loss: 1.3717, G loss: 0.9530\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.5901\n",
      "[1124/1762] D loss: 1.3692, G loss: 0.7534\n",
      "[1204/1762] D loss: 1.4232, G loss: 0.7509\n",
      "[1284/1762] D loss: 1.3343, G loss: 0.8152\n",
      "[1364/1762] D loss: 1.3296, G loss: 0.7630\n",
      "[1444/1762] D loss: 1.4312, G loss: 0.6787\n",
      "[1524/1762] D loss: 1.3943, G loss: 0.6022\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.5603\n",
      "[1684/1762] D loss: 1.4991, G loss: 0.5897\n",
      "[1762/1762] D loss: 1.3319, G loss: 0.6511\n",
      "train error: \n",
      " D loss: 1.392886, G loss: 0.662999, D accuracy: 53.4%, cell accuracy: 99.6%, board accuracy: 66.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382516, G loss: 0.675025, D accuracy: 53.8%, cell accuracy: 99.5%, board accuracy: 62.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3820, G loss: 0.6170\n",
      "[84/1762] D loss: 1.4224, G loss: 0.9152\n",
      "[164/1762] D loss: 1.3468, G loss: 0.7456\n",
      "[244/1762] D loss: 1.4124, G loss: 0.5614\n",
      "[324/1762] D loss: 1.3723, G loss: 0.7748\n",
      "[404/1762] D loss: 1.3709, G loss: 0.9522\n",
      "[484/1762] D loss: 1.4550, G loss: 0.5698\n",
      "[564/1762] D loss: 1.3433, G loss: 0.7814\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7702\n",
      "[724/1762] D loss: 1.3713, G loss: 0.7164\n",
      "[804/1762] D loss: 1.4288, G loss: 0.6444\n",
      "[884/1762] D loss: 1.3635, G loss: 0.6006\n",
      "[964/1762] D loss: 1.3813, G loss: 0.6582\n",
      "[1044/1762] D loss: 1.4971, G loss: 0.8678\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.6342\n",
      "[1204/1762] D loss: 1.4029, G loss: 0.8935\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.7586\n",
      "[1364/1762] D loss: 1.4033, G loss: 0.7298\n",
      "[1444/1762] D loss: 1.5237, G loss: 0.5064\n",
      "[1524/1762] D loss: 1.3670, G loss: 0.7190\n",
      "[1604/1762] D loss: 1.3623, G loss: 0.7221\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.7184\n",
      "[1762/1762] D loss: 1.3600, G loss: 0.7292\n",
      "train error: \n",
      " D loss: 1.386243, G loss: 0.675689, D accuracy: 53.3%, cell accuracy: 99.6%, board accuracy: 66.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379230, G loss: 0.684163, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 63.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2955, G loss: 0.7344\n",
      "[84/1762] D loss: 1.4184, G loss: 0.6105\n",
      "[164/1762] D loss: 1.3516, G loss: 0.6290\n",
      "[244/1762] D loss: 1.4274, G loss: 0.6052\n",
      "[324/1762] D loss: 1.3875, G loss: 0.5521\n",
      "[404/1762] D loss: 1.4388, G loss: 0.6895\n",
      "[484/1762] D loss: 1.5898, G loss: 0.9988\n",
      "[564/1762] D loss: 1.4280, G loss: 0.8739\n",
      "[644/1762] D loss: 1.4298, G loss: 0.7235\n",
      "[724/1762] D loss: 1.4703, G loss: 0.5714\n",
      "[804/1762] D loss: 1.4595, G loss: 0.5001\n",
      "[884/1762] D loss: 1.3911, G loss: 0.6630\n",
      "[964/1762] D loss: 1.3995, G loss: 0.7008\n",
      "[1044/1762] D loss: 1.4073, G loss: 0.6358\n",
      "[1124/1762] D loss: 1.4372, G loss: 0.6097\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.6714\n",
      "[1284/1762] D loss: 1.2848, G loss: 0.7711\n",
      "[1364/1762] D loss: 1.4183, G loss: 0.6156\n",
      "[1444/1762] D loss: 1.3092, G loss: 0.8815\n",
      "[1524/1762] D loss: 1.3995, G loss: 0.6988\n",
      "[1604/1762] D loss: 1.4118, G loss: 0.7199\n",
      "[1684/1762] D loss: 1.3517, G loss: 0.7933\n",
      "[1762/1762] D loss: 1.4053, G loss: 0.8731\n",
      "train error: \n",
      " D loss: 1.396657, G loss: 0.832242, D accuracy: 50.8%, cell accuracy: 99.6%, board accuracy: 70.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397390, G loss: 0.845506, D accuracy: 51.2%, cell accuracy: 99.6%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4155, G loss: 0.8237\n",
      "[84/1762] D loss: 1.3718, G loss: 0.6929\n",
      "[164/1762] D loss: 1.3458, G loss: 0.6949\n",
      "[244/1762] D loss: 1.3989, G loss: 0.8213\n",
      "[324/1762] D loss: 1.3514, G loss: 0.6730\n",
      "[404/1762] D loss: 1.3988, G loss: 0.7336\n",
      "[484/1762] D loss: 1.3804, G loss: 0.8004\n",
      "[564/1762] D loss: 1.3581, G loss: 0.7779\n",
      "[644/1762] D loss: 1.4068, G loss: 0.7017\n",
      "[724/1762] D loss: 1.4296, G loss: 0.5984\n",
      "[804/1762] D loss: 1.2561, G loss: 0.8236\n",
      "[884/1762] D loss: 1.3412, G loss: 0.7730\n",
      "[964/1762] D loss: 1.4425, G loss: 0.6917\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7375\n",
      "[1124/1762] D loss: 1.3965, G loss: 0.8274\n",
      "[1204/1762] D loss: 1.4259, G loss: 0.8107\n",
      "[1284/1762] D loss: 1.3681, G loss: 0.7141\n",
      "[1364/1762] D loss: 1.3764, G loss: 0.7218\n",
      "[1444/1762] D loss: 1.3482, G loss: 0.8020\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.6974\n",
      "[1604/1762] D loss: 1.3849, G loss: 0.7226\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.6117\n",
      "[1762/1762] D loss: 1.4373, G loss: 0.8362\n",
      "train error: \n",
      " D loss: 1.386262, G loss: 0.636959, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 70.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380705, G loss: 0.648964, D accuracy: 53.3%, cell accuracy: 99.6%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.5805\n",
      "[84/1762] D loss: 1.3921, G loss: 0.7330\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7916\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6447\n",
      "[324/1762] D loss: 1.4253, G loss: 0.6277\n",
      "[404/1762] D loss: 1.4248, G loss: 0.6239\n",
      "[484/1762] D loss: 1.3879, G loss: 0.7073\n",
      "[564/1762] D loss: 1.4105, G loss: 0.7553\n",
      "[644/1762] D loss: 1.3401, G loss: 0.8115\n",
      "[724/1762] D loss: 1.4300, G loss: 0.5845\n",
      "[804/1762] D loss: 1.3837, G loss: 0.7387\n",
      "[884/1762] D loss: 1.4206, G loss: 0.5567\n",
      "[964/1762] D loss: 1.4101, G loss: 0.7491\n",
      "[1044/1762] D loss: 1.3964, G loss: 0.7487\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.7813\n",
      "[1204/1762] D loss: 1.4045, G loss: 0.6717\n",
      "[1284/1762] D loss: 1.4027, G loss: 0.6450\n",
      "[1364/1762] D loss: 1.3046, G loss: 0.6110\n",
      "[1444/1762] D loss: 1.4410, G loss: 0.6466\n",
      "[1524/1762] D loss: 1.4157, G loss: 0.6651\n",
      "[1604/1762] D loss: 1.4260, G loss: 0.7166\n",
      "[1684/1762] D loss: 1.4696, G loss: 0.7823\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6899\n",
      "train error: \n",
      " D loss: 1.385846, G loss: 0.763139, D accuracy: 52.0%, cell accuracy: 99.7%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384032, G loss: 0.777826, D accuracy: 52.0%, cell accuracy: 99.6%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3849, G loss: 0.7031\n",
      "[84/1762] D loss: 1.3899, G loss: 0.7626\n",
      "[164/1762] D loss: 1.3905, G loss: 0.7317\n",
      "[244/1762] D loss: 1.4267, G loss: 0.5903\n",
      "[324/1762] D loss: 1.4053, G loss: 0.6943\n",
      "[404/1762] D loss: 1.3902, G loss: 0.6620\n",
      "[484/1762] D loss: 1.3739, G loss: 0.6922\n",
      "[564/1762] D loss: 1.4379, G loss: 0.8697\n",
      "[644/1762] D loss: 1.3633, G loss: 0.6982\n",
      "[724/1762] D loss: 1.3796, G loss: 0.6469\n",
      "[804/1762] D loss: 1.3860, G loss: 0.7676\n",
      "[884/1762] D loss: 1.3886, G loss: 0.7005\n",
      "[964/1762] D loss: 1.4144, G loss: 0.5778\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6328\n",
      "[1124/1762] D loss: 1.3798, G loss: 0.6967\n",
      "[1204/1762] D loss: 1.3712, G loss: 0.7269\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7396\n",
      "[1364/1762] D loss: 1.3425, G loss: 0.7307\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.7040\n",
      "[1524/1762] D loss: 1.3992, G loss: 0.6775\n",
      "[1604/1762] D loss: 1.4224, G loss: 0.5921\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7103\n",
      "[1762/1762] D loss: 1.3790, G loss: 0.7692\n",
      "train error: \n",
      " D loss: 1.397115, G loss: 0.864998, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 73.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395886, G loss: 0.877889, D accuracy: 50.9%, cell accuracy: 99.6%, board accuracy: 69.3% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3934, G loss: 0.8302\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7130\n",
      "[164/1762] D loss: 1.3230, G loss: 0.7983\n",
      "[244/1762] D loss: 1.4151, G loss: 0.6693\n",
      "[324/1762] D loss: 1.4760, G loss: 0.6178\n",
      "[404/1762] D loss: 1.3829, G loss: 0.7118\n",
      "[484/1762] D loss: 1.3863, G loss: 0.7346\n",
      "[564/1762] D loss: 1.3916, G loss: 0.7028\n",
      "[644/1762] D loss: 1.4221, G loss: 0.7184\n",
      "[724/1762] D loss: 1.3600, G loss: 0.7215\n",
      "[804/1762] D loss: 1.3595, G loss: 0.7997\n",
      "[884/1762] D loss: 1.3271, G loss: 0.7771\n",
      "[964/1762] D loss: 1.3820, G loss: 0.7170\n",
      "[1044/1762] D loss: 1.4485, G loss: 0.6393\n",
      "[1124/1762] D loss: 1.3847, G loss: 0.6802\n",
      "[1204/1762] D loss: 1.4163, G loss: 0.6997\n",
      "[1284/1762] D loss: 1.3782, G loss: 0.6200\n",
      "[1364/1762] D loss: 1.4186, G loss: 0.5486\n",
      "[1444/1762] D loss: 1.3520, G loss: 0.7294\n",
      "[1524/1762] D loss: 1.2376, G loss: 0.6643\n",
      "[1604/1762] D loss: 1.3281, G loss: 0.6867\n",
      "[1684/1762] D loss: 1.2106, G loss: 0.7227\n",
      "[1762/1762] D loss: 1.3797, G loss: 0.7395\n",
      "train error: \n",
      " D loss: 1.395870, G loss: 0.762856, D accuracy: 50.5%, cell accuracy: 99.7%, board accuracy: 70.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398631, G loss: 0.779340, D accuracy: 51.0%, cell accuracy: 99.6%, board accuracy: 67.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3240, G loss: 0.7503\n",
      "[84/1762] D loss: 1.3819, G loss: 0.6975\n",
      "[164/1762] D loss: 1.3929, G loss: 0.6476\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7326\n",
      "[324/1762] D loss: 1.3845, G loss: 0.7366\n",
      "[404/1762] D loss: 1.4076, G loss: 0.6323\n",
      "[484/1762] D loss: 1.4106, G loss: 0.5280\n",
      "[564/1762] D loss: 1.3685, G loss: 0.7030\n",
      "[644/1762] D loss: 1.4115, G loss: 0.8764\n",
      "[724/1762] D loss: 1.4001, G loss: 0.7180\n",
      "[804/1762] D loss: 1.3808, G loss: 0.7631\n",
      "[884/1762] D loss: 1.3775, G loss: 0.7833\n",
      "[964/1762] D loss: 1.4363, G loss: 0.6139\n",
      "[1044/1762] D loss: 1.3421, G loss: 0.6806\n",
      "[1124/1762] D loss: 1.4225, G loss: 0.8359\n",
      "[1204/1762] D loss: 1.4545, G loss: 0.6657\n",
      "[1284/1762] D loss: 1.3849, G loss: 0.6564\n",
      "[1364/1762] D loss: 1.4799, G loss: 0.5148\n",
      "[1444/1762] D loss: 1.3687, G loss: 0.7055\n",
      "[1524/1762] D loss: 1.3923, G loss: 0.6307\n",
      "[1604/1762] D loss: 1.3947, G loss: 0.6338\n",
      "[1684/1762] D loss: 1.3765, G loss: 0.8051\n",
      "[1762/1762] D loss: 1.3510, G loss: 0.7340\n",
      "train error: \n",
      " D loss: 1.377909, G loss: 0.661818, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377645, G loss: 0.669022, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3679, G loss: 0.6335\n",
      "[84/1762] D loss: 1.3853, G loss: 0.6360\n",
      "[164/1762] D loss: 1.3522, G loss: 0.7100\n",
      "[244/1762] D loss: 1.3935, G loss: 0.7097\n",
      "[324/1762] D loss: 1.3299, G loss: 0.7615\n",
      "[404/1762] D loss: 1.3962, G loss: 0.7200\n",
      "[484/1762] D loss: 1.3849, G loss: 0.7041\n",
      "[564/1762] D loss: 1.3577, G loss: 0.7182\n",
      "[644/1762] D loss: 1.4058, G loss: 0.5971\n",
      "[724/1762] D loss: 1.4057, G loss: 0.5479\n",
      "[804/1762] D loss: 1.3605, G loss: 0.6702\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6888\n",
      "[964/1762] D loss: 1.3722, G loss: 0.6688\n",
      "[1044/1762] D loss: 1.3981, G loss: 0.8124\n",
      "[1124/1762] D loss: 1.4098, G loss: 0.5504\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6769\n",
      "[1284/1762] D loss: 1.3413, G loss: 0.6945\n",
      "[1364/1762] D loss: 1.3787, G loss: 0.7609\n",
      "[1444/1762] D loss: 1.3972, G loss: 0.7135\n",
      "[1524/1762] D loss: 1.3821, G loss: 0.6649\n",
      "[1604/1762] D loss: 1.3659, G loss: 0.6800\n",
      "[1684/1762] D loss: 1.3006, G loss: 0.7379\n",
      "[1762/1762] D loss: 1.2724, G loss: 0.8069\n",
      "train error: \n",
      " D loss: 1.372032, G loss: 0.732523, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368636, G loss: 0.742269, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.7670\n",
      "[84/1762] D loss: 1.3080, G loss: 0.7834\n",
      "[164/1762] D loss: 1.3665, G loss: 0.6753\n",
      "[244/1762] D loss: 1.3466, G loss: 0.8013\n",
      "[324/1762] D loss: 1.3366, G loss: 0.7560\n",
      "[404/1762] D loss: 1.4613, G loss: 0.6337\n",
      "[484/1762] D loss: 1.3409, G loss: 0.7160\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6834\n",
      "[644/1762] D loss: 1.2775, G loss: 0.7558\n",
      "[724/1762] D loss: 1.3624, G loss: 0.6799\n",
      "[804/1762] D loss: 1.4658, G loss: 0.6251\n",
      "[884/1762] D loss: 1.3627, G loss: 0.6894\n",
      "[964/1762] D loss: 1.3490, G loss: 0.7334\n",
      "[1044/1762] D loss: 1.3261, G loss: 0.7232\n",
      "[1124/1762] D loss: 1.2457, G loss: 0.8623\n",
      "[1204/1762] D loss: 1.2539, G loss: 0.9106\n",
      "[1284/1762] D loss: 1.4286, G loss: 0.6075\n",
      "[1364/1762] D loss: 1.3836, G loss: 0.7083\n",
      "[1444/1762] D loss: 1.3817, G loss: 0.7946\n",
      "[1524/1762] D loss: 1.4228, G loss: 0.7449\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.6717\n",
      "[1684/1762] D loss: 1.4114, G loss: 0.5982\n",
      "[1762/1762] D loss: 1.1937, G loss: 0.7481\n",
      "train error: \n",
      " D loss: 1.392443, G loss: 0.796180, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 73.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394994, G loss: 0.807097, D accuracy: 51.4%, cell accuracy: 99.6%, board accuracy: 70.2% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4041, G loss: 0.8658\n",
      "[84/1762] D loss: 1.3874, G loss: 0.7506\n",
      "[164/1762] D loss: 1.3987, G loss: 0.7045\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6644\n",
      "[324/1762] D loss: 1.4058, G loss: 0.5896\n",
      "[404/1762] D loss: 1.3483, G loss: 0.8157\n",
      "[484/1762] D loss: 1.3908, G loss: 0.6249\n",
      "[564/1762] D loss: 1.3962, G loss: 0.6761\n",
      "[644/1762] D loss: 1.3829, G loss: 0.6612\n",
      "[724/1762] D loss: 1.3996, G loss: 0.8270\n",
      "[804/1762] D loss: 1.4158, G loss: 0.9097\n",
      "[884/1762] D loss: 1.3787, G loss: 0.7060\n",
      "[964/1762] D loss: 1.3222, G loss: 0.8229\n",
      "[1044/1762] D loss: 1.3157, G loss: 0.9080\n",
      "[1124/1762] D loss: 1.3744, G loss: 0.5898\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.6364\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7690\n",
      "[1364/1762] D loss: 1.3951, G loss: 0.7192\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6432\n",
      "[1524/1762] D loss: 1.3681, G loss: 0.6983\n",
      "[1604/1762] D loss: 1.3390, G loss: 0.7644\n",
      "[1684/1762] D loss: 1.3363, G loss: 0.7823\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.7274\n",
      "train error: \n",
      " D loss: 1.377322, G loss: 0.757012, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378178, G loss: 0.763815, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3970, G loss: 0.7140\n",
      "[84/1762] D loss: 1.3506, G loss: 0.7431\n",
      "[164/1762] D loss: 1.2886, G loss: 0.7295\n",
      "[244/1762] D loss: 1.3381, G loss: 0.8034\n",
      "[324/1762] D loss: 1.3697, G loss: 0.7051\n",
      "[404/1762] D loss: 1.3393, G loss: 0.7433\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6028\n",
      "[564/1762] D loss: 1.3772, G loss: 0.6503\n",
      "[644/1762] D loss: 1.3626, G loss: 0.7066\n",
      "[724/1762] D loss: 1.3641, G loss: 0.7160\n",
      "[804/1762] D loss: 1.3700, G loss: 0.6720\n",
      "[884/1762] D loss: 1.3945, G loss: 0.7440\n",
      "[964/1762] D loss: 1.3979, G loss: 0.7926\n",
      "[1044/1762] D loss: 1.3789, G loss: 0.7856\n",
      "[1124/1762] D loss: 1.3829, G loss: 0.7585\n",
      "[1204/1762] D loss: 1.4151, G loss: 0.6137\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.6760\n",
      "[1364/1762] D loss: 1.4109, G loss: 0.7800\n",
      "[1444/1762] D loss: 1.4321, G loss: 0.8070\n",
      "[1524/1762] D loss: 1.3967, G loss: 0.6773\n",
      "[1604/1762] D loss: 1.3582, G loss: 0.7227\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6335\n",
      "[1762/1762] D loss: 1.3139, G loss: 0.8320\n",
      "train error: \n",
      " D loss: 1.373059, G loss: 0.677358, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370352, G loss: 0.684022, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3726, G loss: 0.6765\n",
      "[84/1762] D loss: 1.2730, G loss: 0.7707\n",
      "[164/1762] D loss: 1.3777, G loss: 0.6636\n",
      "[244/1762] D loss: 1.3682, G loss: 0.7295\n",
      "[324/1762] D loss: 1.4180, G loss: 0.6348\n",
      "[404/1762] D loss: 1.3967, G loss: 0.7202\n",
      "[484/1762] D loss: 1.3745, G loss: 0.6804\n",
      "[564/1762] D loss: 1.3748, G loss: 0.8842\n",
      "[644/1762] D loss: 1.3998, G loss: 0.7611\n",
      "[724/1762] D loss: 1.3371, G loss: 0.7518\n",
      "[804/1762] D loss: 1.4144, G loss: 0.8328\n",
      "[884/1762] D loss: 1.3882, G loss: 0.7451\n",
      "[964/1762] D loss: 1.3786, G loss: 0.6851\n",
      "[1044/1762] D loss: 1.3938, G loss: 0.7199\n",
      "[1124/1762] D loss: 1.3420, G loss: 0.7468\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.8472\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.8124\n",
      "[1364/1762] D loss: 1.3635, G loss: 0.7401\n",
      "[1444/1762] D loss: 1.2439, G loss: 0.9361\n",
      "[1524/1762] D loss: 1.4068, G loss: 0.7109\n",
      "[1604/1762] D loss: 1.4459, G loss: 0.5837\n",
      "[1684/1762] D loss: 1.3801, G loss: 0.6892\n",
      "[1762/1762] D loss: 1.1628, G loss: 0.7767\n",
      "train error: \n",
      " D loss: 1.369786, G loss: 0.697261, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365258, G loss: 0.705409, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3896, G loss: 0.7238\n",
      "[84/1762] D loss: 1.3171, G loss: 0.7598\n",
      "[164/1762] D loss: 1.4108, G loss: 0.6199\n",
      "[244/1762] D loss: 1.3974, G loss: 0.6713\n",
      "[324/1762] D loss: 1.3354, G loss: 0.8642\n",
      "[404/1762] D loss: 1.3813, G loss: 0.6622\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7305\n",
      "[564/1762] D loss: 1.3102, G loss: 0.7164\n",
      "[644/1762] D loss: 1.3912, G loss: 0.7267\n",
      "[724/1762] D loss: 1.3043, G loss: 0.7236\n",
      "[804/1762] D loss: 1.3955, G loss: 0.6914\n",
      "[884/1762] D loss: 1.4609, G loss: 0.5126\n",
      "[964/1762] D loss: 1.3203, G loss: 0.6491\n",
      "[1044/1762] D loss: 1.3102, G loss: 0.6957\n",
      "[1124/1762] D loss: 1.3442, G loss: 0.6083\n",
      "[1204/1762] D loss: 1.4174, G loss: 0.7582\n",
      "[1284/1762] D loss: 1.3960, G loss: 0.6271\n",
      "[1364/1762] D loss: 1.3802, G loss: 0.7516\n",
      "[1444/1762] D loss: 1.2977, G loss: 0.7781\n",
      "[1524/1762] D loss: 1.3461, G loss: 0.6554\n",
      "[1604/1762] D loss: 1.3726, G loss: 0.7321\n",
      "[1684/1762] D loss: 1.3970, G loss: 0.7096\n",
      "[1762/1762] D loss: 1.3387, G loss: 0.6676\n",
      "train error: \n",
      " D loss: 1.342312, G loss: 0.748758, D accuracy: 60.7%, cell accuracy: 99.0%, board accuracy: 25.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340508, G loss: 0.759136, D accuracy: 61.7%, cell accuracy: 99.0%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3552, G loss: 0.7287\n",
      "[84/1762] D loss: 1.2786, G loss: 0.6424\n",
      "[164/1762] D loss: 1.3690, G loss: 0.7783\n",
      "[244/1762] D loss: 1.3442, G loss: 0.7193\n",
      "[324/1762] D loss: 1.3052, G loss: 0.8195\n",
      "[404/1762] D loss: 1.4076, G loss: 0.6160\n",
      "[484/1762] D loss: 1.4157, G loss: 0.7311\n",
      "[564/1762] D loss: 1.3954, G loss: 0.7903\n",
      "[644/1762] D loss: 1.3920, G loss: 0.6457\n",
      "[724/1762] D loss: 1.4010, G loss: 0.5923\n",
      "[804/1762] D loss: 1.4486, G loss: 0.5359\n",
      "[884/1762] D loss: 1.3555, G loss: 0.7712\n",
      "[964/1762] D loss: 1.4127, G loss: 0.7862\n",
      "[1044/1762] D loss: 1.3563, G loss: 0.7625\n",
      "[1124/1762] D loss: 1.3965, G loss: 0.7365\n",
      "[1204/1762] D loss: 1.3841, G loss: 0.6663\n",
      "[1284/1762] D loss: 1.3908, G loss: 0.6683\n",
      "[1364/1762] D loss: 1.3172, G loss: 0.6888\n",
      "[1444/1762] D loss: 1.4024, G loss: 0.7219\n",
      "[1524/1762] D loss: 1.3499, G loss: 0.7085\n",
      "[1604/1762] D loss: 1.3207, G loss: 0.8842\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.7568\n",
      "[1762/1762] D loss: 1.3779, G loss: 0.6665\n",
      "train error: \n",
      " D loss: 1.368512, G loss: 0.743821, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 79.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365064, G loss: 0.751229, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4490, G loss: 0.6425\n",
      "[84/1762] D loss: 1.1861, G loss: 0.7531\n",
      "[164/1762] D loss: 1.3199, G loss: 0.7012\n",
      "[244/1762] D loss: 1.2850, G loss: 0.7729\n",
      "[324/1762] D loss: 1.3126, G loss: 0.7458\n",
      "[404/1762] D loss: 1.3899, G loss: 0.6970\n",
      "[484/1762] D loss: 1.3853, G loss: 0.7077\n",
      "[564/1762] D loss: 1.4023, G loss: 0.8024\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7043\n",
      "[724/1762] D loss: 1.3780, G loss: 0.8702\n",
      "[804/1762] D loss: 1.3933, G loss: 0.7628\n",
      "[884/1762] D loss: 1.4087, G loss: 0.6998\n",
      "[964/1762] D loss: 1.4018, G loss: 0.7722\n",
      "[1044/1762] D loss: 1.3098, G loss: 0.8205\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.7005\n",
      "[1204/1762] D loss: 1.3960, G loss: 0.7354\n",
      "[1284/1762] D loss: 1.3206, G loss: 0.7485\n",
      "[1364/1762] D loss: 1.3941, G loss: 0.6625\n",
      "[1444/1762] D loss: 1.2417, G loss: 0.9439\n",
      "[1524/1762] D loss: 1.3931, G loss: 0.6584\n",
      "[1604/1762] D loss: 1.4024, G loss: 0.8028\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.7164\n",
      "[1762/1762] D loss: 1.4016, G loss: 0.5836\n",
      "train error: \n",
      " D loss: 1.359374, G loss: 0.691991, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354938, G loss: 0.697053, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3641, G loss: 0.7011\n",
      "[84/1762] D loss: 1.3070, G loss: 0.7295\n",
      "[164/1762] D loss: 1.4003, G loss: 0.8938\n",
      "[244/1762] D loss: 1.4292, G loss: 0.7758\n",
      "[324/1762] D loss: 1.2832, G loss: 0.7200\n",
      "[404/1762] D loss: 1.3980, G loss: 0.6907\n",
      "[484/1762] D loss: 1.3623, G loss: 0.7184\n",
      "[564/1762] D loss: 1.2955, G loss: 0.6100\n",
      "[644/1762] D loss: 1.3934, G loss: 0.7577\n",
      "[724/1762] D loss: 1.3372, G loss: 0.7068\n",
      "[804/1762] D loss: 1.3295, G loss: 0.7581\n",
      "[884/1762] D loss: 1.4040, G loss: 0.6522\n",
      "[964/1762] D loss: 1.3943, G loss: 0.6689\n",
      "[1044/1762] D loss: 1.4073, G loss: 0.7678\n",
      "[1124/1762] D loss: 1.4005, G loss: 0.6249\n",
      "[1204/1762] D loss: 1.1675, G loss: 0.8621\n",
      "[1284/1762] D loss: 1.3971, G loss: 0.6980\n",
      "[1364/1762] D loss: 1.3934, G loss: 0.6861\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.6555\n",
      "[1524/1762] D loss: 1.3719, G loss: 0.6855\n",
      "[1604/1762] D loss: 1.3499, G loss: 0.7282\n",
      "[1684/1762] D loss: 1.3720, G loss: 0.6882\n",
      "[1762/1762] D loss: 1.4103, G loss: 0.6423\n",
      "train error: \n",
      " D loss: 1.317287, G loss: 0.730759, D accuracy: 59.6%, cell accuracy: 99.4%, board accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314057, G loss: 0.733880, D accuracy: 59.3%, cell accuracy: 99.4%, board accuracy: 55.9% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2432, G loss: 0.8221\n",
      "[84/1762] D loss: 1.3902, G loss: 0.7504\n",
      "[164/1762] D loss: 1.3258, G loss: 0.7924\n",
      "[244/1762] D loss: 1.1765, G loss: 0.7525\n",
      "[324/1762] D loss: 1.3869, G loss: 0.8254\n",
      "[404/1762] D loss: 1.3773, G loss: 1.0273\n",
      "[484/1762] D loss: 1.3926, G loss: 0.6853\n",
      "[564/1762] D loss: 1.2978, G loss: 0.8388\n",
      "[644/1762] D loss: 1.4105, G loss: 0.8017\n",
      "[724/1762] D loss: 1.3176, G loss: 0.8028\n",
      "[804/1762] D loss: 1.3931, G loss: 0.7110\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6271\n",
      "[964/1762] D loss: 1.3903, G loss: 0.6738\n",
      "[1044/1762] D loss: 1.4181, G loss: 0.5538\n",
      "[1124/1762] D loss: 1.1302, G loss: 0.6680\n",
      "[1204/1762] D loss: 1.3707, G loss: 0.5723\n",
      "[1284/1762] D loss: 1.4107, G loss: 0.5920\n",
      "[1364/1762] D loss: 1.4030, G loss: 0.7003\n",
      "[1444/1762] D loss: 1.4009, G loss: 0.7622\n",
      "[1524/1762] D loss: 1.2721, G loss: 0.7932\n",
      "[1604/1762] D loss: 1.3746, G loss: 0.7860\n",
      "[1684/1762] D loss: 1.4061, G loss: 0.8076\n",
      "[1762/1762] D loss: 1.4682, G loss: 0.7311\n",
      "train error: \n",
      " D loss: 1.376340, G loss: 0.872473, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369202, G loss: 0.879777, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4319, G loss: 0.8180\n",
      "[84/1762] D loss: 1.2778, G loss: 0.8503\n",
      "[164/1762] D loss: 1.4033, G loss: 0.7374\n",
      "[244/1762] D loss: 1.4065, G loss: 0.6902\n",
      "[324/1762] D loss: 1.4305, G loss: 0.5874\n",
      "[404/1762] D loss: 1.2778, G loss: 0.7006\n",
      "[484/1762] D loss: 1.3901, G loss: 0.5499\n",
      "[564/1762] D loss: 1.3836, G loss: 0.6170\n",
      "[644/1762] D loss: 1.3750, G loss: 0.7245\n",
      "[724/1762] D loss: 1.4810, G loss: 0.7126\n",
      "[804/1762] D loss: 1.4247, G loss: 0.9283\n",
      "[884/1762] D loss: 1.2769, G loss: 1.0022\n",
      "[964/1762] D loss: 1.1941, G loss: 0.8431\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.5921\n",
      "[1124/1762] D loss: 1.3996, G loss: 0.6378\n",
      "[1204/1762] D loss: 1.3631, G loss: 0.6716\n",
      "[1284/1762] D loss: 1.4183, G loss: 0.8278\n",
      "[1364/1762] D loss: 1.3790, G loss: 0.7602\n",
      "[1444/1762] D loss: 1.3666, G loss: 0.7085\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.6383\n",
      "[1604/1762] D loss: 1.3343, G loss: 0.5683\n",
      "[1684/1762] D loss: 1.3176, G loss: 0.5934\n",
      "[1762/1762] D loss: 1.3755, G loss: 0.7552\n",
      "train error: \n",
      " D loss: 1.352014, G loss: 0.748335, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 62.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351915, G loss: 0.748465, D accuracy: 56.5%, cell accuracy: 99.5%, board accuracy: 59.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3271, G loss: 0.7708\n",
      "[84/1762] D loss: 1.3898, G loss: 0.7531\n",
      "[164/1762] D loss: 1.3920, G loss: 0.7565\n",
      "[244/1762] D loss: 1.3950, G loss: 0.6394\n",
      "[324/1762] D loss: 1.2500, G loss: 0.7405\n",
      "[404/1762] D loss: 1.3489, G loss: 0.7678\n",
      "[484/1762] D loss: 1.3448, G loss: 0.7462\n",
      "[564/1762] D loss: 1.3495, G loss: 0.8298\n",
      "[644/1762] D loss: 1.3166, G loss: 0.7412\n",
      "[724/1762] D loss: 1.3327, G loss: 0.6359\n",
      "[804/1762] D loss: 1.4731, G loss: 0.6498\n",
      "[884/1762] D loss: 1.4003, G loss: 0.8274\n",
      "[964/1762] D loss: 1.2758, G loss: 0.7546\n",
      "[1044/1762] D loss: 1.3977, G loss: 0.5855\n",
      "[1124/1762] D loss: 1.4125, G loss: 0.6617\n",
      "[1204/1762] D loss: 1.3475, G loss: 0.6913\n",
      "[1284/1762] D loss: 1.3327, G loss: 0.9113\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.6458\n",
      "[1444/1762] D loss: 1.4167, G loss: 0.6713\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6433\n",
      "[1604/1762] D loss: 1.4018, G loss: 0.6307\n",
      "[1684/1762] D loss: 1.2945, G loss: 0.6426\n",
      "[1762/1762] D loss: 1.2436, G loss: 0.7645\n",
      "train error: \n",
      " D loss: 1.357120, G loss: 0.732613, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 76.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348740, G loss: 0.742883, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 71.1% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903, G loss: 0.7329\n",
      "[84/1762] D loss: 1.3923, G loss: 0.5656\n",
      "[164/1762] D loss: 1.4317, G loss: 0.8506\n",
      "[244/1762] D loss: 1.2636, G loss: 0.9511\n",
      "[324/1762] D loss: 1.3820, G loss: 0.7022\n",
      "[404/1762] D loss: 1.3793, G loss: 0.6990\n",
      "[484/1762] D loss: 1.4037, G loss: 0.6694\n",
      "[564/1762] D loss: 1.3800, G loss: 0.6701\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6362\n",
      "[724/1762] D loss: 1.3197, G loss: 0.6188\n",
      "[804/1762] D loss: 1.3984, G loss: 0.5949\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7001\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7140\n",
      "[1044/1762] D loss: 1.4152, G loss: 0.7259\n",
      "[1124/1762] D loss: 1.4465, G loss: 0.6930\n",
      "[1204/1762] D loss: 1.4116, G loss: 0.5549\n",
      "[1284/1762] D loss: 1.3449, G loss: 0.6665\n",
      "[1364/1762] D loss: 1.3148, G loss: 0.6003\n",
      "[1444/1762] D loss: 1.3923, G loss: 0.7865\n",
      "[1524/1762] D loss: 1.4232, G loss: 0.5385\n",
      "[1604/1762] D loss: 1.3603, G loss: 0.6515\n",
      "[1684/1762] D loss: 1.4121, G loss: 0.7482\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7193\n",
      "train error: \n",
      " D loss: 1.354194, G loss: 0.701423, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345346, G loss: 0.709442, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.7375\n",
      "[84/1762] D loss: 1.4011, G loss: 0.7793\n",
      "[164/1762] D loss: 1.3674, G loss: 0.7298\n",
      "[244/1762] D loss: 1.3918, G loss: 0.7601\n",
      "[324/1762] D loss: 1.3975, G loss: 0.7683\n",
      "[404/1762] D loss: 1.2824, G loss: 0.7161\n",
      "[484/1762] D loss: 1.3798, G loss: 0.8560\n",
      "[564/1762] D loss: 1.4091, G loss: 0.5931\n",
      "[644/1762] D loss: 1.4137, G loss: 0.5474\n",
      "[724/1762] D loss: 1.2194, G loss: 0.8576\n",
      "[804/1762] D loss: 1.2769, G loss: 0.6873\n",
      "[884/1762] D loss: 1.3960, G loss: 0.7227\n",
      "[964/1762] D loss: 1.4048, G loss: 0.7301\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.7153\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.7495\n",
      "[1204/1762] D loss: 1.2242, G loss: 0.7389\n",
      "[1284/1762] D loss: 1.4012, G loss: 0.6497\n",
      "[1364/1762] D loss: 1.3998, G loss: 0.8089\n",
      "[1444/1762] D loss: 1.2217, G loss: 0.9044\n",
      "[1524/1762] D loss: 1.3811, G loss: 0.6464\n",
      "[1604/1762] D loss: 1.4030, G loss: 0.6050\n",
      "[1684/1762] D loss: 1.3959, G loss: 0.6985\n",
      "[1762/1762] D loss: 1.3932, G loss: 0.6553\n",
      "train error: \n",
      " D loss: 1.349873, G loss: 0.729456, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340356, G loss: 0.738537, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2092, G loss: 0.8546\n",
      "[84/1762] D loss: 1.3839, G loss: 0.7172\n",
      "[164/1762] D loss: 1.2103, G loss: 0.7765\n",
      "[244/1762] D loss: 1.3969, G loss: 0.6587\n",
      "[324/1762] D loss: 1.3945, G loss: 0.6661\n",
      "[404/1762] D loss: 1.3913, G loss: 0.6691\n",
      "[484/1762] D loss: 1.3982, G loss: 0.6962\n",
      "[564/1762] D loss: 2.1141, G loss: 0.3813\n",
      "[644/1762] D loss: 1.8807, G loss: 0.6237\n",
      "[724/1762] D loss: 1.5601, G loss: 0.6551\n",
      "[804/1762] D loss: 1.3510, G loss: 0.7389\n",
      "[884/1762] D loss: 1.3716, G loss: 0.6380\n",
      "[964/1762] D loss: 1.3726, G loss: 0.7441\n",
      "[1044/1762] D loss: 1.2757, G loss: 0.7682\n",
      "[1124/1762] D loss: 1.2518, G loss: 0.6771\n",
      "[1204/1762] D loss: 1.2341, G loss: 0.7339\n",
      "[1284/1762] D loss: 1.1307, G loss: 0.8948\n",
      "[1364/1762] D loss: 1.1812, G loss: 0.9597\n",
      "[1444/1762] D loss: 1.4187, G loss: 0.6295\n",
      "[1524/1762] D loss: 1.4874, G loss: 0.6279\n",
      "[1604/1762] D loss: 1.4389, G loss: 0.7747\n",
      "[1684/1762] D loss: 1.4255, G loss: 0.7861\n",
      "[1762/1762] D loss: 1.4300, G loss: 0.8265\n",
      "train error: \n",
      " D loss: 1.414520, G loss: 0.701529, D accuracy: 48.3%, cell accuracy: 99.8%, board accuracy: 83.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.420122, G loss: 0.706399, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4190, G loss: 0.7757\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6654\n",
      "[164/1762] D loss: 1.4136, G loss: 0.8029\n",
      "[244/1762] D loss: 1.4311, G loss: 0.5920\n",
      "[324/1762] D loss: 1.4004, G loss: 0.5899\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6389\n",
      "[484/1762] D loss: 1.4030, G loss: 0.6709\n",
      "[564/1762] D loss: 1.3831, G loss: 0.6406\n",
      "[644/1762] D loss: 1.3848, G loss: 0.6684\n",
      "[724/1762] D loss: 1.4047, G loss: 0.6960\n",
      "[804/1762] D loss: 1.3988, G loss: 0.6553\n",
      "[884/1762] D loss: 1.3912, G loss: 0.6352\n",
      "[964/1762] D loss: 1.4025, G loss: 0.6108\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7123\n",
      "[1124/1762] D loss: 1.3193, G loss: 0.7104\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6299\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6745\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.6290\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7172\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.7539\n",
      "[1604/1762] D loss: 1.4061, G loss: 0.5991\n",
      "[1684/1762] D loss: 1.3905, G loss: 0.6715\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7609\n",
      "train error: \n",
      " D loss: 1.392705, G loss: 0.780630, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394520, G loss: 0.781406, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.7706\n",
      "[84/1762] D loss: 1.3905, G loss: 0.6200\n",
      "[164/1762] D loss: 1.3951, G loss: 0.8058\n",
      "[244/1762] D loss: 1.3919, G loss: 0.6766\n",
      "[324/1762] D loss: 1.3718, G loss: 0.6673\n",
      "[404/1762] D loss: 1.3920, G loss: 0.7015\n",
      "[484/1762] D loss: 1.3637, G loss: 0.7346\n",
      "[564/1762] D loss: 1.3497, G loss: 0.7083\n",
      "[644/1762] D loss: 1.3872, G loss: 0.7189\n",
      "[724/1762] D loss: 1.3907, G loss: 0.6701\n",
      "[804/1762] D loss: 1.3860, G loss: 0.7289\n",
      "[884/1762] D loss: 1.3904, G loss: 0.7426\n",
      "[964/1762] D loss: 1.3957, G loss: 0.7516\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.7645\n",
      "[1124/1762] D loss: 1.4045, G loss: 0.6764\n",
      "[1204/1762] D loss: 1.3724, G loss: 0.6863\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6654\n",
      "[1364/1762] D loss: 1.3931, G loss: 0.6899\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.6617\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.7418\n",
      "[1604/1762] D loss: 1.2985, G loss: 0.8251\n",
      "[1684/1762] D loss: 1.2972, G loss: 0.7594\n",
      "[1762/1762] D loss: 1.3919, G loss: 0.7556\n",
      "train error: \n",
      " D loss: 1.373224, G loss: 0.742168, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370446, G loss: 0.742554, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.7168\n",
      "[84/1762] D loss: 1.3191, G loss: 0.7176\n",
      "[164/1762] D loss: 1.3337, G loss: 0.7231\n",
      "[244/1762] D loss: 1.3923, G loss: 0.7473\n",
      "[324/1762] D loss: 1.3037, G loss: 0.7429\n",
      "[404/1762] D loss: 1.3887, G loss: 0.7299\n",
      "[484/1762] D loss: 1.3260, G loss: 0.7483\n",
      "[564/1762] D loss: 1.3925, G loss: 0.7688\n",
      "[644/1762] D loss: 1.3900, G loss: 0.6471\n",
      "[724/1762] D loss: 1.3898, G loss: 0.7152\n",
      "[804/1762] D loss: 1.3999, G loss: 0.7608\n",
      "[884/1762] D loss: 1.3920, G loss: 0.7467\n",
      "[964/1762] D loss: 1.3899, G loss: 0.6111\n",
      "[1044/1762] D loss: 1.3906, G loss: 0.7048\n",
      "[1124/1762] D loss: 1.3945, G loss: 0.7942\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6980\n",
      "[1284/1762] D loss: 1.3330, G loss: 0.6801\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7419\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.7273\n",
      "[1524/1762] D loss: 1.3381, G loss: 0.6619\n",
      "[1604/1762] D loss: 1.2640, G loss: 0.7726\n",
      "[1684/1762] D loss: 1.2591, G loss: 0.7474\n",
      "[1762/1762] D loss: 1.3698, G loss: 0.7485\n",
      "train error: \n",
      " D loss: 1.362570, G loss: 0.721718, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356573, G loss: 0.722509, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2756, G loss: 0.7296\n",
      "[84/1762] D loss: 1.3941, G loss: 0.6834\n",
      "[164/1762] D loss: 1.3922, G loss: 0.7528\n",
      "[244/1762] D loss: 1.3820, G loss: 0.6726\n",
      "[324/1762] D loss: 1.3116, G loss: 0.7404\n",
      "[404/1762] D loss: 1.3984, G loss: 0.6286\n",
      "[484/1762] D loss: 1.3917, G loss: 0.6408\n",
      "[564/1762] D loss: 1.3123, G loss: 0.6907\n",
      "[644/1762] D loss: 1.2471, G loss: 0.7256\n",
      "[724/1762] D loss: 1.4048, G loss: 0.6291\n",
      "[804/1762] D loss: 1.3926, G loss: 0.7009\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6929\n",
      "[964/1762] D loss: 1.3939, G loss: 0.7975\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.7519\n",
      "[1124/1762] D loss: 1.3774, G loss: 0.7296\n",
      "[1204/1762] D loss: 1.3746, G loss: 0.7013\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6328\n",
      "[1364/1762] D loss: 1.2386, G loss: 0.7764\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7284\n",
      "[1524/1762] D loss: 1.3953, G loss: 0.7541\n",
      "[1604/1762] D loss: 1.4364, G loss: 0.8684\n",
      "[1684/1762] D loss: 1.3960, G loss: 0.6427\n",
      "[1762/1762] D loss: 1.3997, G loss: 0.8110\n",
      "train error: \n",
      " D loss: 1.360760, G loss: 0.810053, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351647, G loss: 0.811473, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4046, G loss: 0.7688\n",
      "[84/1762] D loss: 1.4014, G loss: 0.6640\n",
      "[164/1762] D loss: 1.4014, G loss: 0.6785\n",
      "[244/1762] D loss: 1.3931, G loss: 0.6185\n",
      "[324/1762] D loss: 1.2963, G loss: 0.7602\n",
      "[404/1762] D loss: 1.2591, G loss: 0.7426\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7073\n",
      "[564/1762] D loss: 1.1096, G loss: 0.7826\n",
      "[644/1762] D loss: 1.3828, G loss: 0.5975\n",
      "[724/1762] D loss: 1.3965, G loss: 0.7018\n",
      "[804/1762] D loss: 1.3896, G loss: 0.6323\n",
      "[884/1762] D loss: 1.3942, G loss: 0.6834\n",
      "[964/1762] D loss: 1.0619, G loss: 0.8369\n",
      "[1044/1762] D loss: 1.3931, G loss: 0.6609\n",
      "[1124/1762] D loss: 1.4141, G loss: 0.6285\n",
      "[1204/1762] D loss: 1.3957, G loss: 0.6358\n",
      "[1284/1762] D loss: 1.3919, G loss: 0.6202\n",
      "[1364/1762] D loss: 1.4032, G loss: 0.8216\n",
      "[1444/1762] D loss: 1.2930, G loss: 0.8689\n",
      "[1524/1762] D loss: 1.5531, G loss: 0.7367\n",
      "[1604/1762] D loss: 1.2831, G loss: 0.8254\n",
      "[1684/1762] D loss: 1.2649, G loss: 0.7850\n",
      "[1762/1762] D loss: 1.4274, G loss: 0.6360\n",
      "train error: \n",
      " D loss: 1.371584, G loss: 0.712601, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372865, G loss: 0.719516, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3948, G loss: 0.7466\n",
      "[84/1762] D loss: 1.3407, G loss: 0.6618\n",
      "[164/1762] D loss: 1.4000, G loss: 0.7150\n",
      "[244/1762] D loss: 1.3150, G loss: 0.6459\n",
      "[324/1762] D loss: 1.3935, G loss: 0.6384\n",
      "[404/1762] D loss: 1.3801, G loss: 0.7121\n",
      "[484/1762] D loss: 1.4073, G loss: 0.6631\n",
      "[564/1762] D loss: 1.3086, G loss: 0.7511\n",
      "[644/1762] D loss: 1.2865, G loss: 0.6707\n",
      "[724/1762] D loss: 1.3929, G loss: 0.6727\n",
      "[804/1762] D loss: 1.3156, G loss: 0.7143\n",
      "[884/1762] D loss: 1.3963, G loss: 0.6277\n",
      "[964/1762] D loss: 1.4302, G loss: 0.6009\n",
      "[1044/1762] D loss: 1.3376, G loss: 0.7218\n",
      "[1124/1762] D loss: 1.1924, G loss: 0.7715\n",
      "[1204/1762] D loss: 1.3957, G loss: 0.7502\n",
      "[1284/1762] D loss: 1.3681, G loss: 0.6955\n",
      "[1364/1762] D loss: 1.3856, G loss: 0.7000\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7472\n",
      "[1524/1762] D loss: 1.3859, G loss: 0.6826\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.6577\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6589\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6228\n",
      "train error: \n",
      " D loss: 1.355032, G loss: 0.658015, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 79.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348297, G loss: 0.661603, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3968, G loss: 0.6077\n",
      "[84/1762] D loss: 1.3541, G loss: 0.7034\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6890\n",
      "[244/1762] D loss: 1.3888, G loss: 0.6400\n",
      "[324/1762] D loss: 1.3874, G loss: 0.6372\n",
      "[404/1762] D loss: 1.3779, G loss: 0.8023\n",
      "[484/1762] D loss: 1.2853, G loss: 0.7913\n",
      "[564/1762] D loss: 1.3891, G loss: 0.7105\n",
      "[644/1762] D loss: 1.2892, G loss: 0.7775\n",
      "[724/1762] D loss: 1.3910, G loss: 0.6598\n",
      "[804/1762] D loss: 1.4197, G loss: 0.7901\n",
      "[884/1762] D loss: 1.1060, G loss: 0.8887\n",
      "[964/1762] D loss: 1.3904, G loss: 0.6306\n",
      "[1044/1762] D loss: 1.3961, G loss: 0.6876\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.5862\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6458\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.7644\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.6691\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6511\n",
      "[1524/1762] D loss: 1.3936, G loss: 0.7211\n",
      "[1604/1762] D loss: 1.3931, G loss: 0.7460\n",
      "[1684/1762] D loss: 1.2550, G loss: 0.7379\n",
      "[1762/1762] D loss: 1.5105, G loss: 0.7871\n",
      "train error: \n",
      " D loss: 1.478464, G loss: 0.756488, D accuracy: 33.9%, cell accuracy: 99.2%, board accuracy: 24.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.462642, G loss: 0.768362, D accuracy: 36.5%, cell accuracy: 99.2%, board accuracy: 22.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6156, G loss: 0.7105\n",
      "[84/1762] D loss: 1.3858, G loss: 0.8629\n",
      "[164/1762] D loss: 1.1076, G loss: 0.8494\n",
      "[244/1762] D loss: 1.1299, G loss: 0.8700\n",
      "[324/1762] D loss: 1.1308, G loss: 0.8256\n",
      "[404/1762] D loss: 1.3426, G loss: 0.6912\n",
      "[484/1762] D loss: 1.3123, G loss: 0.8194\n",
      "[564/1762] D loss: 1.4018, G loss: 0.7186\n",
      "[644/1762] D loss: 1.3391, G loss: 0.7777\n",
      "[724/1762] D loss: 1.4411, G loss: 0.7669\n",
      "[804/1762] D loss: 1.3922, G loss: 0.7346\n",
      "[884/1762] D loss: 1.2761, G loss: 0.8284\n",
      "[964/1762] D loss: 1.3899, G loss: 0.7230\n",
      "[1044/1762] D loss: 1.3554, G loss: 0.6903\n",
      "[1124/1762] D loss: 1.3230, G loss: 0.6534\n",
      "[1204/1762] D loss: 1.4023, G loss: 0.6984\n",
      "[1284/1762] D loss: 1.3914, G loss: 0.7450\n",
      "[1364/1762] D loss: 1.3971, G loss: 0.7582\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.6382\n",
      "[1524/1762] D loss: 1.2847, G loss: 0.8165\n",
      "[1604/1762] D loss: 1.3939, G loss: 0.6238\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.7031\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7386\n",
      "train error: \n",
      " D loss: 1.361849, G loss: 0.765848, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356374, G loss: 0.773676, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3325, G loss: 0.8412\n",
      "[84/1762] D loss: 1.3890, G loss: 0.8490\n",
      "[164/1762] D loss: 1.2581, G loss: 0.8348\n",
      "[244/1762] D loss: 1.4105, G loss: 0.5798\n",
      "[324/1762] D loss: 1.2534, G loss: 0.6670\n",
      "[404/1762] D loss: 1.3902, G loss: 0.7197\n",
      "[484/1762] D loss: 1.3856, G loss: 0.7691\n",
      "[564/1762] D loss: 1.3884, G loss: 0.6853\n",
      "[644/1762] D loss: 1.3950, G loss: 0.6395\n",
      "[724/1762] D loss: 1.4220, G loss: 0.5985\n",
      "[804/1762] D loss: 1.3919, G loss: 0.7842\n",
      "[884/1762] D loss: 1.3910, G loss: 0.7832\n",
      "[964/1762] D loss: 1.3849, G loss: 0.7120\n",
      "[1044/1762] D loss: 1.4204, G loss: 0.5728\n",
      "[1124/1762] D loss: 1.2257, G loss: 0.7427\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.6590\n",
      "[1284/1762] D loss: 1.3940, G loss: 0.6156\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6666\n",
      "[1444/1762] D loss: 1.4142, G loss: 0.7756\n",
      "[1524/1762] D loss: 1.2218, G loss: 0.9984\n",
      "[1604/1762] D loss: 1.3972, G loss: 0.8102\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7186\n",
      "[1762/1762] D loss: 1.4137, G loss: 0.7020\n",
      "train error: \n",
      " D loss: 1.344134, G loss: 0.734963, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 84.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333695, G loss: 0.742312, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3758, G loss: 0.7290\n",
      "[84/1762] D loss: 1.3892, G loss: 0.7317\n",
      "[164/1762] D loss: 1.4064, G loss: 0.7766\n",
      "[244/1762] D loss: 1.2162, G loss: 0.8528\n",
      "[324/1762] D loss: 1.4157, G loss: 0.7493\n",
      "[404/1762] D loss: 1.4021, G loss: 0.7417\n",
      "[484/1762] D loss: 1.3883, G loss: 0.7412\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7790\n",
      "[644/1762] D loss: 1.4054, G loss: 0.6465\n",
      "[724/1762] D loss: 1.4439, G loss: 0.5021\n",
      "[804/1762] D loss: 1.3981, G loss: 0.7730\n",
      "[884/1762] D loss: 1.4004, G loss: 0.6202\n",
      "[964/1762] D loss: 1.4026, G loss: 0.7744\n",
      "[1044/1762] D loss: 1.4181, G loss: 0.8427\n",
      "[1124/1762] D loss: 1.3758, G loss: 0.6806\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.6855\n",
      "[1284/1762] D loss: 1.3982, G loss: 0.6881\n",
      "[1364/1762] D loss: 1.3949, G loss: 0.6688\n",
      "[1444/1762] D loss: 1.2089, G loss: 0.7721\n",
      "[1524/1762] D loss: 1.1874, G loss: 0.7577\n",
      "[1604/1762] D loss: 1.4031, G loss: 0.6252\n",
      "[1684/1762] D loss: 1.2418, G loss: 0.8660\n",
      "[1762/1762] D loss: 1.3809, G loss: 0.8771\n",
      "train error: \n",
      " D loss: 1.352795, G loss: 0.773005, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337585, G loss: 0.784879, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4316, G loss: 0.7647\n",
      "[84/1762] D loss: 1.3910, G loss: 0.6942\n",
      "[164/1762] D loss: 1.1929, G loss: 0.7821\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7177\n",
      "[324/1762] D loss: 1.3947, G loss: 0.6760\n",
      "[404/1762] D loss: 1.3899, G loss: 0.7048\n",
      "[484/1762] D loss: 1.2003, G loss: 0.7817\n",
      "[564/1762] D loss: 1.3898, G loss: 0.6776\n",
      "[644/1762] D loss: 1.4225, G loss: 0.6588\n",
      "[724/1762] D loss: 1.1885, G loss: 0.7433\n",
      "[804/1762] D loss: 1.3947, G loss: 0.6596\n",
      "[884/1762] D loss: 1.4822, G loss: 0.7017\n",
      "[964/1762] D loss: 1.3915, G loss: 0.7931\n",
      "[1044/1762] D loss: 1.3847, G loss: 0.8792\n",
      "[1124/1762] D loss: 2.8277, G loss: 0.4198\n",
      "[1204/1762] D loss: 1.7321, G loss: 0.6876\n",
      "[1284/1762] D loss: 1.4186, G loss: 0.8363\n",
      "[1364/1762] D loss: 1.3102, G loss: 0.8296\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.7288\n",
      "[1524/1762] D loss: 1.4948, G loss: 0.6976\n",
      "[1604/1762] D loss: 1.4297, G loss: 0.6198\n",
      "[1684/1762] D loss: 1.4039, G loss: 0.6702\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6764\n",
      "train error: \n",
      " D loss: 1.382981, G loss: 0.665873, D accuracy: 53.1%, cell accuracy: 99.5%, board accuracy: 53.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384757, G loss: 0.672700, D accuracy: 54.2%, cell accuracy: 99.5%, board accuracy: 47.7% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6960\n",
      "[84/1762] D loss: 1.4151, G loss: 0.7438\n",
      "[164/1762] D loss: 1.4022, G loss: 0.8072\n",
      "[244/1762] D loss: 1.4435, G loss: 0.6756\n",
      "[324/1762] D loss: 1.3153, G loss: 0.7361\n",
      "[404/1762] D loss: 1.3164, G loss: 0.7870\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6675\n",
      "[564/1762] D loss: 1.2667, G loss: 0.7720\n",
      "[644/1762] D loss: 1.5361, G loss: 0.6393\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6855\n",
      "[804/1762] D loss: 1.4355, G loss: 0.6201\n",
      "[884/1762] D loss: 1.4257, G loss: 0.7216\n",
      "[964/1762] D loss: 1.4070, G loss: 0.6244\n",
      "[1044/1762] D loss: 1.3852, G loss: 0.7192\n",
      "[1124/1762] D loss: 1.3912, G loss: 0.7066\n",
      "[1204/1762] D loss: 1.3145, G loss: 0.6668\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7518\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7203\n",
      "[1444/1762] D loss: 1.3825, G loss: 0.7157\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.6777\n",
      "[1604/1762] D loss: 1.3922, G loss: 0.6512\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.6668\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.7257\n",
      "train error: \n",
      " D loss: 1.378004, G loss: 0.754750, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376795, G loss: 0.755756, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4338, G loss: 0.7323\n",
      "[84/1762] D loss: 1.3880, G loss: 0.7632\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6954\n",
      "[244/1762] D loss: 1.3890, G loss: 0.6482\n",
      "[324/1762] D loss: 1.2458, G loss: 0.7011\n",
      "[404/1762] D loss: 1.3908, G loss: 0.6688\n",
      "[484/1762] D loss: 1.2848, G loss: 0.6737\n",
      "[564/1762] D loss: 1.3923, G loss: 0.7421\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6951\n",
      "[724/1762] D loss: 1.5734, G loss: 0.5909\n",
      "[804/1762] D loss: 1.2639, G loss: 0.7006\n",
      "[884/1762] D loss: 1.3125, G loss: 0.7548\n",
      "[964/1762] D loss: 1.1699, G loss: 0.8466\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6361\n",
      "[1124/1762] D loss: 1.3906, G loss: 0.7562\n",
      "[1204/1762] D loss: 1.3201, G loss: 0.7284\n",
      "[1284/1762] D loss: 1.2247, G loss: 0.7930\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6775\n",
      "[1444/1762] D loss: 1.5582, G loss: 0.5953\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.7535\n",
      "[1604/1762] D loss: 1.5565, G loss: 0.6124\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.7399\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6832\n",
      "train error: \n",
      " D loss: 1.367686, G loss: 0.677628, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362714, G loss: 0.679409, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3942, G loss: 0.6250\n",
      "[84/1762] D loss: 1.3897, G loss: 0.6609\n",
      "[164/1762] D loss: 1.3929, G loss: 0.7226\n",
      "[244/1762] D loss: 1.3889, G loss: 0.7233\n",
      "[324/1762] D loss: 1.4027, G loss: 0.8069\n",
      "[404/1762] D loss: 1.0909, G loss: 0.8266\n",
      "[484/1762] D loss: 1.3906, G loss: 0.6675\n",
      "[564/1762] D loss: 1.3920, G loss: 0.7396\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6723\n",
      "[724/1762] D loss: 1.2502, G loss: 0.7828\n",
      "[804/1762] D loss: 1.3920, G loss: 0.6313\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7252\n",
      "[964/1762] D loss: 1.3877, G loss: 0.7328\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6805\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.7382\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6588\n",
      "[1284/1762] D loss: 1.5564, G loss: 0.6521\n",
      "[1364/1762] D loss: 1.3952, G loss: 0.6528\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.7684\n",
      "[1524/1762] D loss: 1.2473, G loss: 0.7442\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.6955\n",
      "[1684/1762] D loss: 1.3925, G loss: 0.7712\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.7334\n",
      "train error: \n",
      " D loss: 1.359530, G loss: 0.719859, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352476, G loss: 0.722349, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3912, G loss: 0.6864\n",
      "[84/1762] D loss: 1.2749, G loss: 0.6776\n",
      "[164/1762] D loss: 1.3985, G loss: 0.7443\n",
      "[244/1762] D loss: 1.3808, G loss: 0.7529\n",
      "[324/1762] D loss: 1.2141, G loss: 0.7318\n",
      "[404/1762] D loss: 1.3986, G loss: 0.7724\n",
      "[484/1762] D loss: 1.2740, G loss: 0.7328\n",
      "[564/1762] D loss: 1.3909, G loss: 0.7642\n",
      "[644/1762] D loss: 1.3975, G loss: 0.6170\n",
      "[724/1762] D loss: 1.3991, G loss: 0.7134\n",
      "[804/1762] D loss: 1.2439, G loss: 0.7278\n",
      "[884/1762] D loss: 1.3938, G loss: 0.6589\n",
      "[964/1762] D loss: 1.3889, G loss: 0.6976\n",
      "[1044/1762] D loss: 1.3944, G loss: 0.7168\n",
      "[1124/1762] D loss: 1.4004, G loss: 0.7900\n",
      "[1204/1762] D loss: 1.4330, G loss: 0.7272\n",
      "[1284/1762] D loss: 1.2679, G loss: 0.6852\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.7292\n",
      "[1444/1762] D loss: 1.5272, G loss: 0.6355\n",
      "[1524/1762] D loss: 1.5411, G loss: 0.6616\n",
      "[1604/1762] D loss: 1.6771, G loss: 0.6217\n",
      "[1684/1762] D loss: 1.4773, G loss: 0.6693\n",
      "[1762/1762] D loss: 1.3313, G loss: 0.6929\n",
      "train error: \n",
      " D loss: 1.280386, G loss: 0.775816, D accuracy: 75.7%, cell accuracy: 98.9%, board accuracy: 11.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280868, G loss: 0.788094, D accuracy: 76.7%, cell accuracy: 98.8%, board accuracy: 9.8% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3827, G loss: 0.6952\n",
      "[84/1762] D loss: 1.3843, G loss: 0.8278\n",
      "[164/1762] D loss: 1.3939, G loss: 0.6749\n",
      "[244/1762] D loss: 1.3915, G loss: 0.6971\n",
      "[324/1762] D loss: 1.2526, G loss: 0.9001\n",
      "[404/1762] D loss: 1.3902, G loss: 0.7305\n",
      "[484/1762] D loss: 1.3927, G loss: 0.7587\n",
      "[564/1762] D loss: 1.3894, G loss: 0.7009\n",
      "[644/1762] D loss: 1.3878, G loss: 0.7099\n",
      "[724/1762] D loss: 1.4683, G loss: 0.6478\n",
      "[804/1762] D loss: 1.3603, G loss: 0.7592\n",
      "[884/1762] D loss: 1.2627, G loss: 0.7695\n",
      "[964/1762] D loss: 1.3611, G loss: 0.7613\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7037\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7132\n",
      "[1204/1762] D loss: 1.3424, G loss: 0.6322\n",
      "[1284/1762] D loss: 1.3941, G loss: 0.6541\n",
      "[1364/1762] D loss: 1.3956, G loss: 0.6795\n",
      "[1444/1762] D loss: 1.3902, G loss: 0.7333\n",
      "[1524/1762] D loss: 1.2621, G loss: 0.7475\n",
      "[1604/1762] D loss: 1.3921, G loss: 0.6609\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.7306\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6914\n",
      "train error: \n",
      " D loss: 1.359983, G loss: 0.732614, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353710, G loss: 0.742897, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.7339\n",
      "[84/1762] D loss: 1.3936, G loss: 0.7658\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6882\n",
      "[244/1762] D loss: 1.3896, G loss: 0.7103\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6934\n",
      "[404/1762] D loss: 1.3920, G loss: 0.7220\n",
      "[484/1762] D loss: 1.2561, G loss: 0.8421\n",
      "[564/1762] D loss: 1.0991, G loss: 0.8541\n",
      "[644/1762] D loss: 1.3952, G loss: 0.7455\n",
      "[724/1762] D loss: 1.2333, G loss: 0.7913\n",
      "[804/1762] D loss: 1.3878, G loss: 0.6978\n",
      "[884/1762] D loss: 1.3903, G loss: 0.7098\n",
      "[964/1762] D loss: 1.4684, G loss: 0.6743\n",
      "[1044/1762] D loss: 1.4848, G loss: 0.7197\n",
      "[1124/1762] D loss: 1.3968, G loss: 0.7591\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.7828\n",
      "[1284/1762] D loss: 1.3966, G loss: 0.8409\n",
      "[1364/1762] D loss: 1.3935, G loss: 0.7816\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6604\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6579\n",
      "[1604/1762] D loss: 1.4613, G loss: 0.6892\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6602\n",
      "[1762/1762] D loss: 1.0736, G loss: 0.8479\n",
      "train error: \n",
      " D loss: 1.347013, G loss: 0.718625, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336837, G loss: 0.728131, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.6788\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6400\n",
      "[164/1762] D loss: 1.1924, G loss: 0.7675\n",
      "[244/1762] D loss: 1.3902, G loss: 0.6754\n",
      "[324/1762] D loss: 1.3912, G loss: 0.7285\n",
      "[404/1762] D loss: 1.3951, G loss: 0.6196\n",
      "[484/1762] D loss: 1.3863, G loss: 0.7265\n",
      "[564/1762] D loss: 1.2737, G loss: 0.7642\n",
      "[644/1762] D loss: 1.0310, G loss: 0.8679\n",
      "[724/1762] D loss: 1.3956, G loss: 0.8266\n",
      "[804/1762] D loss: 1.3935, G loss: 0.6696\n",
      "[884/1762] D loss: 1.3929, G loss: 0.6566\n",
      "[964/1762] D loss: 1.3961, G loss: 0.6081\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.6515\n",
      "[1124/1762] D loss: 1.2227, G loss: 0.7818\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.6727\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.6358\n",
      "[1364/1762] D loss: 1.2206, G loss: 0.7611\n",
      "[1444/1762] D loss: 1.4477, G loss: 0.5880\n",
      "[1524/1762] D loss: 1.4465, G loss: 0.7522\n",
      "[1604/1762] D loss: 1.3953, G loss: 0.6578\n",
      "[1684/1762] D loss: 0.9889, G loss: 0.9171\n",
      "[1762/1762] D loss: 1.3924, G loss: 0.7376\n",
      "train error: \n",
      " D loss: 1.337330, G loss: 0.714353, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 83.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324206, G loss: 0.725584, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3828, G loss: 0.6203\n",
      "[84/1762] D loss: 1.3914, G loss: 0.6470\n",
      "[164/1762] D loss: 1.2267, G loss: 0.6601\n",
      "[244/1762] D loss: 1.3923, G loss: 0.7302\n",
      "[324/1762] D loss: 1.3887, G loss: 0.7208\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6858\n",
      "[484/1762] D loss: 0.9386, G loss: 0.9629\n",
      "[564/1762] D loss: 0.9267, G loss: 1.2183\n",
      "[644/1762] D loss: 1.1418, G loss: 0.9579\n",
      "[724/1762] D loss: 1.3968, G loss: 0.7118\n",
      "[804/1762] D loss: 1.3977, G loss: 0.6121\n",
      "[884/1762] D loss: 1.3952, G loss: 0.5922\n",
      "[964/1762] D loss: 1.3937, G loss: 0.6856\n",
      "[1044/1762] D loss: 1.4042, G loss: 0.7134\n",
      "[1124/1762] D loss: 1.4181, G loss: 0.7714\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.7697\n",
      "[1284/1762] D loss: 1.1569, G loss: 0.8568\n",
      "[1364/1762] D loss: 1.1891, G loss: 0.7557\n",
      "[1444/1762] D loss: 1.1694, G loss: 0.8784\n",
      "[1524/1762] D loss: 1.4165, G loss: 0.5504\n",
      "[1604/1762] D loss: 1.4084, G loss: 0.7519\n",
      "[1684/1762] D loss: 1.3901, G loss: 0.7590\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.6916\n",
      "train error: \n",
      " D loss: 1.329181, G loss: 0.740264, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313439, G loss: 0.753630, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3961, G loss: 0.7395\n",
      "[84/1762] D loss: 1.3829, G loss: 0.7417\n",
      "[164/1762] D loss: 1.3913, G loss: 0.7363\n",
      "[244/1762] D loss: 1.3912, G loss: 0.6350\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6702\n",
      "[404/1762] D loss: 1.3904, G loss: 0.6391\n",
      "[484/1762] D loss: 1.3928, G loss: 0.7108\n",
      "[564/1762] D loss: 1.3969, G loss: 0.7017\n",
      "[644/1762] D loss: 1.1785, G loss: 0.9736\n",
      "[724/1762] D loss: 1.4027, G loss: 0.6593\n",
      "[804/1762] D loss: 1.3817, G loss: 0.7268\n",
      "[884/1762] D loss: 1.1414, G loss: 0.9664\n",
      "[964/1762] D loss: 1.3943, G loss: 0.5726\n",
      "[1044/1762] D loss: 1.3888, G loss: 0.7907\n",
      "[1124/1762] D loss: 1.3732, G loss: 0.7053\n",
      "[1204/1762] D loss: 1.4002, G loss: 0.7422\n",
      "[1284/1762] D loss: 0.9306, G loss: 1.0821\n",
      "[1364/1762] D loss: 1.3949, G loss: 0.7425\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.6688\n",
      "[1524/1762] D loss: 1.3997, G loss: 0.7800\n",
      "[1604/1762] D loss: 1.4047, G loss: 0.6707\n",
      "[1684/1762] D loss: 1.3999, G loss: 0.6205\n",
      "[1762/1762] D loss: 1.3967, G loss: 0.7035\n",
      "train error: \n",
      " D loss: 1.325047, G loss: 0.701916, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307040, G loss: 0.716798, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4030, G loss: 0.5982\n",
      "[84/1762] D loss: 0.9040, G loss: 0.9609\n",
      "[164/1762] D loss: 1.3937, G loss: 0.6583\n",
      "[244/1762] D loss: 1.5236, G loss: 0.6289\n",
      "[324/1762] D loss: 1.3957, G loss: 0.7117\n",
      "[404/1762] D loss: 1.3911, G loss: 0.6774\n",
      "[484/1762] D loss: 1.3953, G loss: 0.6484\n",
      "[564/1762] D loss: 1.4058, G loss: 0.6851\n",
      "[644/1762] D loss: 1.3933, G loss: 0.7405\n",
      "[724/1762] D loss: 0.9489, G loss: 0.9421\n",
      "[804/1762] D loss: 1.1971, G loss: 0.7611\n",
      "[884/1762] D loss: 1.1595, G loss: 0.7923\n",
      "[964/1762] D loss: 1.3639, G loss: 0.7179\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.7891\n",
      "[1124/1762] D loss: 1.1621, G loss: 0.8291\n",
      "[1204/1762] D loss: 1.3739, G loss: 0.6605\n",
      "[1284/1762] D loss: 1.1674, G loss: 0.7724\n",
      "[1364/1762] D loss: 1.3572, G loss: 0.7459\n",
      "[1444/1762] D loss: 1.4866, G loss: 1.0001\n",
      "[1524/1762] D loss: 1.1655, G loss: 0.9802\n",
      "[1604/1762] D loss: 1.5145, G loss: 0.7202\n",
      "[1684/1762] D loss: 1.7814, G loss: 0.5609\n",
      "[1762/1762] D loss: 1.2556, G loss: 0.8861\n",
      "train error: \n",
      " D loss: 1.240202, G loss: 0.949488, D accuracy: 65.0%, cell accuracy: 98.9%, board accuracy: 16.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.235497, G loss: 0.966883, D accuracy: 63.2%, cell accuracy: 98.9%, board accuracy: 16.4% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2769, G loss: 0.9421\n",
      "[84/1762] D loss: 1.3075, G loss: 0.8734\n",
      "[164/1762] D loss: 1.4018, G loss: 0.8770\n",
      "[244/1762] D loss: 1.4224, G loss: 0.6749\n",
      "[324/1762] D loss: 1.3175, G loss: 0.9125\n",
      "[404/1762] D loss: 1.4223, G loss: 0.8771\n",
      "[484/1762] D loss: 1.3945, G loss: 0.6732\n",
      "[564/1762] D loss: 1.1033, G loss: 0.7244\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6625\n",
      "[724/1762] D loss: 1.3927, G loss: 0.6668\n",
      "[804/1762] D loss: 1.2415, G loss: 0.6602\n",
      "[884/1762] D loss: 1.2364, G loss: 0.7282\n",
      "[964/1762] D loss: 1.3909, G loss: 0.6155\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.7066\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.6196\n",
      "[1204/1762] D loss: 1.2838, G loss: 0.8050\n",
      "[1284/1762] D loss: 1.3817, G loss: 0.8005\n",
      "[1364/1762] D loss: 1.2682, G loss: 0.7549\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.7271\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.7339\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7667\n",
      "[1684/1762] D loss: 1.3956, G loss: 0.8114\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7194\n",
      "train error: \n",
      " D loss: 1.337287, G loss: 0.775325, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324781, G loss: 0.789487, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.7724\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7227\n",
      "[164/1762] D loss: 1.3911, G loss: 0.7146\n",
      "[244/1762] D loss: 1.2076, G loss: 0.7428\n",
      "[324/1762] D loss: 1.3889, G loss: 0.6974\n",
      "[404/1762] D loss: 1.1920, G loss: 0.8361\n",
      "[484/1762] D loss: 1.3986, G loss: 0.7073\n",
      "[564/1762] D loss: 1.4035, G loss: 0.7390\n",
      "[644/1762] D loss: 1.2037, G loss: 0.8030\n",
      "[724/1762] D loss: 1.3911, G loss: 0.7214\n",
      "[804/1762] D loss: 0.9742, G loss: 0.8567\n",
      "[884/1762] D loss: 1.4100, G loss: 0.7843\n",
      "[964/1762] D loss: 1.3862, G loss: 0.7855\n",
      "[1044/1762] D loss: 1.1939, G loss: 0.8861\n",
      "[1124/1762] D loss: 1.3338, G loss: 0.7676\n",
      "[1204/1762] D loss: 1.3798, G loss: 0.6722\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.7148\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.7409\n",
      "[1444/1762] D loss: 1.3946, G loss: 0.7053\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7727\n",
      "[1604/1762] D loss: 1.3922, G loss: 0.6665\n",
      "[1684/1762] D loss: 1.3746, G loss: 0.6276\n",
      "[1762/1762] D loss: 1.3176, G loss: 0.8925\n",
      "train error: \n",
      " D loss: 1.324992, G loss: 0.743556, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308331, G loss: 0.755872, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1580, G loss: 0.8049\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6828\n",
      "[164/1762] D loss: 1.1561, G loss: 0.8647\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6908\n",
      "[324/1762] D loss: 1.3911, G loss: 0.7272\n",
      "[404/1762] D loss: 1.1707, G loss: 0.8059\n",
      "[484/1762] D loss: 1.3903, G loss: 0.6495\n",
      "[564/1762] D loss: 1.4223, G loss: 0.8688\n",
      "[644/1762] D loss: 0.9506, G loss: 0.9486\n",
      "[724/1762] D loss: 1.1520, G loss: 0.8333\n",
      "[804/1762] D loss: 1.3938, G loss: 0.6794\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6879\n",
      "[964/1762] D loss: 1.3905, G loss: 0.6878\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7304\n",
      "[1124/1762] D loss: 1.4112, G loss: 0.7986\n",
      "[1204/1762] D loss: 1.3966, G loss: 0.7731\n",
      "[1284/1762] D loss: 1.1610, G loss: 0.9515\n",
      "[1364/1762] D loss: 1.3647, G loss: 0.7118\n",
      "[1444/1762] D loss: 0.9477, G loss: 0.8641\n",
      "[1524/1762] D loss: 1.1461, G loss: 0.9190\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.7436\n",
      "[1684/1762] D loss: 1.1669, G loss: 0.7398\n",
      "[1762/1762] D loss: 1.4079, G loss: 0.6675\n",
      "train error: \n",
      " D loss: 1.326323, G loss: 0.689235, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306702, G loss: 0.706292, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.6280\n",
      "[84/1762] D loss: 1.4022, G loss: 0.5534\n",
      "[164/1762] D loss: 0.8704, G loss: 0.9802\n",
      "[244/1762] D loss: 1.4139, G loss: 0.8000\n",
      "[324/1762] D loss: 1.3898, G loss: 0.8144\n",
      "[404/1762] D loss: 1.3897, G loss: 0.7263\n",
      "[484/1762] D loss: 1.4435, G loss: 0.9323\n",
      "[564/1762] D loss: 0.8727, G loss: 1.1586\n",
      "[644/1762] D loss: 0.9093, G loss: 1.0283\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7205\n",
      "[804/1762] D loss: 1.3930, G loss: 0.6362\n",
      "[884/1762] D loss: 1.4479, G loss: 0.7886\n",
      "[964/1762] D loss: 1.4121, G loss: 0.7940\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7119\n",
      "[1124/1762] D loss: 1.3725, G loss: 0.6562\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6635\n",
      "[1284/1762] D loss: 0.8736, G loss: 1.1068\n",
      "[1364/1762] D loss: 1.5019, G loss: 0.6394\n",
      "[1444/1762] D loss: 1.4080, G loss: 0.6192\n",
      "[1524/1762] D loss: 1.1517, G loss: 0.7806\n",
      "[1604/1762] D loss: 1.4145, G loss: 0.8291\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6748\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.7104\n",
      "train error: \n",
      " D loss: 1.326046, G loss: 0.693097, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305761, G loss: 0.709784, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3825, G loss: 0.6518\n",
      "[84/1762] D loss: 1.3938, G loss: 0.7331\n",
      "[164/1762] D loss: 1.3953, G loss: 0.7052\n",
      "[244/1762] D loss: 1.3809, G loss: 0.8166\n",
      "[324/1762] D loss: 1.4004, G loss: 0.7064\n",
      "[404/1762] D loss: 1.9458, G loss: 0.5200\n",
      "[484/1762] D loss: 2.8567, G loss: 0.3110\n",
      "[564/1762] D loss: 1.7331, G loss: 0.6088\n",
      "[644/1762] D loss: 1.3436, G loss: 0.6550\n",
      "[724/1762] D loss: 1.0992, G loss: 0.8439\n",
      "[804/1762] D loss: 1.3959, G loss: 0.7340\n",
      "[884/1762] D loss: 1.4045, G loss: 0.8087\n",
      "[964/1762] D loss: 1.4165, G loss: 0.6302\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7712\n",
      "[1124/1762] D loss: 1.4086, G loss: 0.6052\n",
      "[1204/1762] D loss: 1.2930, G loss: 0.7726\n",
      "[1284/1762] D loss: 1.3984, G loss: 0.6644\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6869\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6604\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7095\n",
      "[1604/1762] D loss: 1.3689, G loss: 0.7219\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.6486\n",
      "[1762/1762] D loss: 1.3062, G loss: 0.8334\n",
      "train error: \n",
      " D loss: 1.375038, G loss: 0.737847, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378680, G loss: 0.746257, D accuracy: 52.2%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6976\n",
      "[84/1762] D loss: 1.3859, G loss: 0.6956\n",
      "[164/1762] D loss: 1.4282, G loss: 0.6861\n",
      "[244/1762] D loss: 1.3950, G loss: 0.7081\n",
      "[324/1762] D loss: 1.3993, G loss: 0.6314\n",
      "[404/1762] D loss: 1.3881, G loss: 0.7115\n",
      "[484/1762] D loss: 1.3908, G loss: 0.7241\n",
      "[564/1762] D loss: 1.3182, G loss: 0.6870\n",
      "[644/1762] D loss: 1.3747, G loss: 0.7332\n",
      "[724/1762] D loss: 1.2909, G loss: 0.7707\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6807\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7353\n",
      "[964/1762] D loss: 1.3921, G loss: 0.6776\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.7410\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.7144\n",
      "[1204/1762] D loss: 1.3922, G loss: 0.6405\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.7163\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6732\n",
      "[1444/1762] D loss: 1.3907, G loss: 0.6931\n",
      "[1524/1762] D loss: 1.1475, G loss: 0.7560\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.7276\n",
      "[1684/1762] D loss: 1.4057, G loss: 0.7955\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.7011\n",
      "train error: \n",
      " D loss: 1.348654, G loss: 0.721394, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342796, G loss: 0.727953, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3950, G loss: 0.7086\n",
      "[84/1762] D loss: 1.3819, G loss: 0.6444\n",
      "[164/1762] D loss: 1.2313, G loss: 0.8257\n",
      "[244/1762] D loss: 1.3979, G loss: 0.7310\n",
      "[324/1762] D loss: 1.3941, G loss: 0.7173\n",
      "[404/1762] D loss: 1.2277, G loss: 0.8585\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7008\n",
      "[564/1762] D loss: 1.3899, G loss: 0.7176\n",
      "[644/1762] D loss: 1.1962, G loss: 0.7787\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6901\n",
      "[804/1762] D loss: 1.3903, G loss: 0.6692\n",
      "[884/1762] D loss: 1.2216, G loss: 0.8294\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6988\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.6444\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.6691\n",
      "[1204/1762] D loss: 1.0362, G loss: 0.9341\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7200\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6948\n",
      "[1444/1762] D loss: 1.3907, G loss: 0.6887\n",
      "[1524/1762] D loss: 1.3759, G loss: 0.6167\n",
      "[1604/1762] D loss: 1.3769, G loss: 0.7381\n",
      "[1684/1762] D loss: 1.3821, G loss: 0.6899\n",
      "[1762/1762] D loss: 1.4067, G loss: 0.6463\n",
      "train error: \n",
      " D loss: 1.335794, G loss: 0.703544, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324552, G loss: 0.711419, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.6107\n",
      "[84/1762] D loss: 1.3878, G loss: 0.7105\n",
      "[164/1762] D loss: 1.3787, G loss: 0.7767\n",
      "[244/1762] D loss: 1.1648, G loss: 0.8504\n",
      "[324/1762] D loss: 1.3574, G loss: 0.7432\n",
      "[404/1762] D loss: 0.9912, G loss: 0.9505\n",
      "[484/1762] D loss: 1.3898, G loss: 0.7026\n",
      "[564/1762] D loss: 1.3901, G loss: 0.7165\n",
      "[644/1762] D loss: 1.3893, G loss: 0.7065\n",
      "[724/1762] D loss: 1.3873, G loss: 0.7061\n",
      "[804/1762] D loss: 1.3891, G loss: 0.7773\n",
      "[884/1762] D loss: 1.0433, G loss: 0.9539\n",
      "[964/1762] D loss: 1.3911, G loss: 0.6477\n",
      "[1044/1762] D loss: 1.1822, G loss: 0.7644\n",
      "[1124/1762] D loss: 1.3964, G loss: 0.6938\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7177\n",
      "[1284/1762] D loss: 1.1716, G loss: 0.8730\n",
      "[1364/1762] D loss: 1.3929, G loss: 0.6231\n",
      "[1444/1762] D loss: 1.3994, G loss: 0.6014\n",
      "[1524/1762] D loss: 1.3809, G loss: 0.7535\n",
      "[1604/1762] D loss: 1.3748, G loss: 0.6908\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6578\n",
      "[1762/1762] D loss: 1.0264, G loss: 0.9145\n",
      "train error: \n",
      " D loss: 1.356507, G loss: 0.605227, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345991, G loss: 0.614998, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3988, G loss: 0.6379\n",
      "[84/1762] D loss: 0.8958, G loss: 1.0686\n",
      "[164/1762] D loss: 1.3897, G loss: 0.7151\n",
      "[244/1762] D loss: 1.4242, G loss: 0.7458\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6644\n",
      "[404/1762] D loss: 1.4009, G loss: 0.7066\n",
      "[484/1762] D loss: 1.3956, G loss: 0.7743\n",
      "[564/1762] D loss: 1.1828, G loss: 0.8595\n",
      "[644/1762] D loss: 1.3888, G loss: 0.6245\n",
      "[724/1762] D loss: 1.4058, G loss: 0.6929\n",
      "[804/1762] D loss: 1.4048, G loss: 0.6806\n",
      "[884/1762] D loss: 1.3960, G loss: 0.7257\n",
      "[964/1762] D loss: 1.3986, G loss: 0.7411\n",
      "[1044/1762] D loss: 1.3959, G loss: 0.7276\n",
      "[1124/1762] D loss: 1.3947, G loss: 0.6317\n",
      "[1204/1762] D loss: 1.4095, G loss: 0.5754\n",
      "[1284/1762] D loss: 1.2113, G loss: 0.7439\n",
      "[1364/1762] D loss: 1.1964, G loss: 0.7707\n",
      "[1444/1762] D loss: 1.4106, G loss: 0.7523\n",
      "[1524/1762] D loss: 1.1430, G loss: 0.8466\n",
      "[1604/1762] D loss: 0.9833, G loss: 0.7975\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6673\n",
      "[1762/1762] D loss: 0.9276, G loss: 1.1371\n",
      "train error: \n",
      " D loss: 1.334941, G loss: 0.848710, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320733, G loss: 0.869091, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.9179\n",
      "[84/1762] D loss: 1.3942, G loss: 0.7481\n",
      "[164/1762] D loss: 1.4034, G loss: 0.8005\n",
      "[244/1762] D loss: 1.3888, G loss: 0.7746\n",
      "[324/1762] D loss: 1.3938, G loss: 0.7469\n",
      "[404/1762] D loss: 1.1465, G loss: 1.0504\n",
      "[484/1762] D loss: 1.3911, G loss: 0.7882\n",
      "[564/1762] D loss: 1.1795, G loss: 0.8134\n",
      "[644/1762] D loss: 1.1500, G loss: 0.7956\n",
      "[724/1762] D loss: 1.1306, G loss: 0.8894\n",
      "[804/1762] D loss: 1.3955, G loss: 0.7835\n",
      "[884/1762] D loss: 1.3751, G loss: 0.7135\n",
      "[964/1762] D loss: 1.3958, G loss: 0.7172\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.7771\n",
      "[1124/1762] D loss: 1.4014, G loss: 0.6908\n",
      "[1204/1762] D loss: 1.4376, G loss: 0.5592\n",
      "[1284/1762] D loss: 1.1668, G loss: 0.8567\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.7172\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7012\n",
      "[1524/1762] D loss: 1.4051, G loss: 0.8059\n",
      "[1604/1762] D loss: 1.3628, G loss: 0.6888\n",
      "[1684/1762] D loss: 1.4098, G loss: 0.7112\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.7585\n",
      "train error: \n",
      " D loss: 1.331293, G loss: 0.866862, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315019, G loss: 0.888832, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1817, G loss: 0.9773\n",
      "[84/1762] D loss: 1.4248, G loss: 0.7269\n",
      "[164/1762] D loss: 1.3877, G loss: 0.6741\n",
      "[244/1762] D loss: 1.4106, G loss: 0.6808\n",
      "[324/1762] D loss: 1.3993, G loss: 0.7273\n",
      "[404/1762] D loss: 1.3917, G loss: 0.7331\n",
      "[484/1762] D loss: 1.3484, G loss: 0.6626\n",
      "[564/1762] D loss: 1.3294, G loss: 0.7420\n",
      "[644/1762] D loss: 1.3838, G loss: 0.6654\n",
      "[724/1762] D loss: 1.4239, G loss: 0.8635\n",
      "[804/1762] D loss: 1.2150, G loss: 0.7898\n",
      "[884/1762] D loss: 1.4158, G loss: 0.6790\n",
      "[964/1762] D loss: 1.3083, G loss: 0.8193\n",
      "[1044/1762] D loss: 1.3925, G loss: 0.7082\n",
      "[1124/1762] D loss: 1.2939, G loss: 0.7009\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.8254\n",
      "[1284/1762] D loss: 1.3965, G loss: 0.6441\n",
      "[1364/1762] D loss: 1.3001, G loss: 0.8428\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.6810\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.7543\n",
      "[1604/1762] D loss: 1.4132, G loss: 0.6273\n",
      "[1684/1762] D loss: 1.6358, G loss: 0.7097\n",
      "[1762/1762] D loss: 1.1542, G loss: 0.8792\n",
      "train error: \n",
      " D loss: 1.154464, G loss: 0.760837, D accuracy: 72.5%, cell accuracy: 98.4%, board accuracy: 12.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.152115, G loss: 0.785484, D accuracy: 74.0%, cell accuracy: 98.4%, board accuracy: 12.7% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1769, G loss: 0.6921\n",
      "[84/1762] D loss: 1.0006, G loss: 0.8682\n",
      "[164/1762] D loss: 1.4086, G loss: 0.6713\n",
      "[244/1762] D loss: 1.3922, G loss: 0.5786\n",
      "[324/1762] D loss: 1.4062, G loss: 0.7950\n",
      "[404/1762] D loss: 1.3956, G loss: 0.7298\n",
      "[484/1762] D loss: 1.4038, G loss: 0.7195\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6838\n",
      "[644/1762] D loss: 1.3909, G loss: 0.6163\n",
      "[724/1762] D loss: 1.2843, G loss: 0.6652\n",
      "[804/1762] D loss: 1.3707, G loss: 0.6694\n",
      "[884/1762] D loss: 1.2192, G loss: 0.7816\n",
      "[964/1762] D loss: 1.3984, G loss: 0.7609\n",
      "[1044/1762] D loss: 1.3930, G loss: 0.6731\n",
      "[1124/1762] D loss: 1.2436, G loss: 0.7696\n",
      "[1204/1762] D loss: 1.1911, G loss: 0.7975\n",
      "[1284/1762] D loss: 1.3657, G loss: 0.7109\n",
      "[1364/1762] D loss: 1.3905, G loss: 0.7259\n",
      "[1444/1762] D loss: 1.3802, G loss: 0.7432\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.6802\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.6398\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.6590\n",
      "[1762/1762] D loss: 1.4037, G loss: 0.7726\n",
      "train error: \n",
      " D loss: 1.332734, G loss: 0.752219, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320285, G loss: 0.764127, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2263, G loss: 0.7694\n",
      "[84/1762] D loss: 1.3886, G loss: 0.6643\n",
      "[164/1762] D loss: 1.3919, G loss: 0.6663\n",
      "[244/1762] D loss: 1.3649, G loss: 0.6392\n",
      "[324/1762] D loss: 1.3892, G loss: 0.5870\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6828\n",
      "[484/1762] D loss: 1.3917, G loss: 0.7243\n",
      "[564/1762] D loss: 1.2042, G loss: 0.8004\n",
      "[644/1762] D loss: 1.4030, G loss: 0.8171\n",
      "[724/1762] D loss: 1.3893, G loss: 0.7019\n",
      "[804/1762] D loss: 1.3875, G loss: 0.7730\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7090\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7033\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.7726\n",
      "[1124/1762] D loss: 1.1489, G loss: 0.8697\n",
      "[1204/1762] D loss: 1.4009, G loss: 0.6192\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6912\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6029\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6784\n",
      "[1524/1762] D loss: 1.1570, G loss: 0.8433\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.8105\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.7117\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.6547\n",
      "train error: \n",
      " D loss: 1.322681, G loss: 0.755740, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306034, G loss: 0.772124, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3969, G loss: 0.7526\n",
      "[84/1762] D loss: 1.1227, G loss: 0.8738\n",
      "[164/1762] D loss: 1.3851, G loss: 0.7264\n",
      "[244/1762] D loss: 0.8827, G loss: 1.1610\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6594\n",
      "[404/1762] D loss: 1.3963, G loss: 0.7353\n",
      "[484/1762] D loss: 1.3905, G loss: 0.6430\n",
      "[564/1762] D loss: 1.3923, G loss: 0.6425\n",
      "[644/1762] D loss: 1.4016, G loss: 0.6176\n",
      "[724/1762] D loss: 1.3935, G loss: 0.6695\n",
      "[804/1762] D loss: 1.1411, G loss: 0.8158\n",
      "[884/1762] D loss: 1.1844, G loss: 0.7865\n",
      "[964/1762] D loss: 1.4695, G loss: 0.6096\n",
      "[1044/1762] D loss: 1.3951, G loss: 0.6910\n",
      "[1124/1762] D loss: 1.3574, G loss: 0.7872\n",
      "[1204/1762] D loss: 1.3894, G loss: 0.6599\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.7093\n",
      "[1364/1762] D loss: 1.1560, G loss: 0.9759\n",
      "[1444/1762] D loss: 1.3777, G loss: 0.7152\n",
      "[1524/1762] D loss: 1.4058, G loss: 0.7588\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.5799\n",
      "[1684/1762] D loss: 1.4005, G loss: 0.7332\n",
      "[1762/1762] D loss: 1.3976, G loss: 0.7395\n",
      "train error: \n",
      " D loss: 1.320342, G loss: 0.772041, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300661, G loss: 0.792086, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3926, G loss: 0.6290\n",
      "[84/1762] D loss: 1.1336, G loss: 0.8168\n",
      "[164/1762] D loss: 1.3998, G loss: 0.7985\n",
      "[244/1762] D loss: 1.3814, G loss: 0.7416\n",
      "[324/1762] D loss: 1.1155, G loss: 0.9306\n",
      "[404/1762] D loss: 1.3918, G loss: 0.6293\n",
      "[484/1762] D loss: 1.3879, G loss: 0.6663\n",
      "[564/1762] D loss: 1.1486, G loss: 0.8703\n",
      "[644/1762] D loss: 1.3962, G loss: 0.7313\n",
      "[724/1762] D loss: 1.3700, G loss: 0.7029\n",
      "[804/1762] D loss: 1.3909, G loss: 0.7320\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6678\n",
      "[964/1762] D loss: 1.4164, G loss: 0.7333\n",
      "[1044/1762] D loss: 1.3964, G loss: 0.7106\n",
      "[1124/1762] D loss: 1.4015, G loss: 0.7689\n",
      "[1204/1762] D loss: 1.3983, G loss: 0.7580\n",
      "[1284/1762] D loss: 1.3950, G loss: 0.6388\n",
      "[1364/1762] D loss: 1.1212, G loss: 0.9569\n",
      "[1444/1762] D loss: 1.4023, G loss: 0.6490\n",
      "[1524/1762] D loss: 1.1181, G loss: 0.9105\n",
      "[1604/1762] D loss: 1.3996, G loss: 0.7347\n",
      "[1684/1762] D loss: 1.4121, G loss: 0.6329\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6845\n",
      "train error: \n",
      " D loss: 1.317923, G loss: 0.739821, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297726, G loss: 0.759611, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0786, G loss: 1.0367\n",
      "[84/1762] D loss: 1.1347, G loss: 0.8927\n",
      "[164/1762] D loss: 1.3955, G loss: 0.6914\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7390\n",
      "[324/1762] D loss: 1.3931, G loss: 0.6545\n",
      "[404/1762] D loss: 1.3948, G loss: 0.8074\n",
      "[484/1762] D loss: 1.4125, G loss: 0.5507\n",
      "[564/1762] D loss: 1.3917, G loss: 0.6585\n",
      "[644/1762] D loss: 1.1673, G loss: 0.8988\n",
      "[724/1762] D loss: 1.3975, G loss: 0.5825\n",
      "[804/1762] D loss: 1.3891, G loss: 0.7286\n",
      "[884/1762] D loss: 1.3776, G loss: 0.6166\n",
      "[964/1762] D loss: 1.1621, G loss: 0.7601\n",
      "[1044/1762] D loss: 1.1135, G loss: 0.8830\n",
      "[1124/1762] D loss: 1.4060, G loss: 0.8016\n",
      "[1204/1762] D loss: 1.4055, G loss: 0.7393\n",
      "[1284/1762] D loss: 1.3777, G loss: 0.6800\n",
      "[1364/1762] D loss: 1.1175, G loss: 0.8544\n",
      "[1444/1762] D loss: 1.3929, G loss: 0.6890\n",
      "[1524/1762] D loss: 1.4017, G loss: 0.5771\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6576\n",
      "[1684/1762] D loss: 1.1262, G loss: 0.8405\n",
      "[1762/1762] D loss: 1.4071, G loss: 0.5492\n",
      "train error: \n",
      " D loss: 1.330374, G loss: 0.647477, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308351, G loss: 0.667515, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8751, G loss: 0.9881\n",
      "[84/1762] D loss: 1.3885, G loss: 0.7103\n",
      "[164/1762] D loss: 1.3910, G loss: 0.6202\n",
      "[244/1762] D loss: 1.4123, G loss: 0.5839\n",
      "[324/1762] D loss: 1.3665, G loss: 0.6700\n",
      "[404/1762] D loss: 1.3924, G loss: 0.6657\n",
      "[484/1762] D loss: 1.0419, G loss: 0.8911\n",
      "[564/1762] D loss: 1.3833, G loss: 0.7088\n",
      "[644/1762] D loss: 1.3892, G loss: 0.6193\n",
      "[724/1762] D loss: 1.3975, G loss: 0.7093\n",
      "[804/1762] D loss: 1.1363, G loss: 0.8926\n",
      "[884/1762] D loss: 0.8424, G loss: 1.2279\n",
      "[964/1762] D loss: 1.3877, G loss: 0.7348\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.6754\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.6916\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.6776\n",
      "[1284/1762] D loss: 1.1245, G loss: 0.9210\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.7462\n",
      "[1444/1762] D loss: 1.1306, G loss: 0.8753\n",
      "[1524/1762] D loss: 1.4004, G loss: 0.7553\n",
      "[1604/1762] D loss: 1.3913, G loss: 0.6000\n",
      "[1684/1762] D loss: 1.4003, G loss: 0.5698\n",
      "[1762/1762] D loss: 1.3851, G loss: 0.6514\n",
      "train error: \n",
      " D loss: 1.322644, G loss: 0.694651, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299817, G loss: 0.716975, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4191, G loss: 0.6391\n",
      "[84/1762] D loss: 1.3952, G loss: 0.7029\n",
      "[164/1762] D loss: 1.3684, G loss: 0.7384\n",
      "[244/1762] D loss: 1.3949, G loss: 0.6555\n",
      "[324/1762] D loss: 1.1437, G loss: 0.7696\n",
      "[404/1762] D loss: 1.3581, G loss: 0.6808\n",
      "[484/1762] D loss: 1.1255, G loss: 0.8508\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6950\n",
      "[644/1762] D loss: 1.4017, G loss: 0.6396\n",
      "[724/1762] D loss: 1.5205, G loss: 0.5974\n",
      "[804/1762] D loss: 1.3992, G loss: 0.5979\n",
      "[884/1762] D loss: 1.3947, G loss: 0.6540\n",
      "[964/1762] D loss: 1.3914, G loss: 0.6773\n",
      "[1044/1762] D loss: 0.8573, G loss: 1.1073\n",
      "[1124/1762] D loss: 1.3765, G loss: 0.7911\n",
      "[1204/1762] D loss: 1.4562, G loss: 0.5046\n",
      "[1284/1762] D loss: 1.1072, G loss: 0.8828\n",
      "[1364/1762] D loss: 1.4048, G loss: 0.7406\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.6472\n",
      "[1524/1762] D loss: 1.4082, G loss: 0.5689\n",
      "[1604/1762] D loss: 1.1369, G loss: 0.7815\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.8095\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7414\n",
      "train error: \n",
      " D loss: 1.323966, G loss: 0.867258, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303230, G loss: 0.889327, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.7666\n",
      "[84/1762] D loss: 1.3962, G loss: 0.7895\n",
      "[164/1762] D loss: 1.3893, G loss: 0.6863\n",
      "[244/1762] D loss: 1.1350, G loss: 0.8855\n",
      "[324/1762] D loss: 1.3836, G loss: 0.7362\n",
      "[404/1762] D loss: 1.3928, G loss: 0.6553\n",
      "[484/1762] D loss: 1.3968, G loss: 0.7635\n",
      "[564/1762] D loss: 1.3991, G loss: 0.7519\n",
      "[644/1762] D loss: 1.1050, G loss: 0.8714\n",
      "[724/1762] D loss: 1.4060, G loss: 0.6225\n",
      "[804/1762] D loss: 1.1330, G loss: 0.7774\n",
      "[884/1762] D loss: 1.4017, G loss: 0.6464\n",
      "[964/1762] D loss: 1.1231, G loss: 0.8507\n",
      "[1044/1762] D loss: 1.1345, G loss: 0.7542\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.7169\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.7360\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.6012\n",
      "[1364/1762] D loss: 1.4000, G loss: 0.6407\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.6426\n",
      "[1524/1762] D loss: 1.3941, G loss: 0.7257\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.7570\n",
      "[1684/1762] D loss: 1.4113, G loss: 0.8345\n",
      "[1762/1762] D loss: 1.3978, G loss: 0.6845\n",
      "train error: \n",
      " D loss: 1.314487, G loss: 0.780231, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294064, G loss: 0.802774, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7777\n",
      "[84/1762] D loss: 1.3989, G loss: 0.7060\n",
      "[164/1762] D loss: 1.1036, G loss: 0.8982\n",
      "[244/1762] D loss: 1.1090, G loss: 0.8813\n",
      "[324/1762] D loss: 1.1154, G loss: 1.0415\n",
      "[404/1762] D loss: 1.3985, G loss: 0.7551\n",
      "[484/1762] D loss: 1.3858, G loss: 0.7723\n",
      "[564/1762] D loss: 1.3604, G loss: 0.7722\n",
      "[644/1762] D loss: 1.3739, G loss: 0.9098\n",
      "[724/1762] D loss: 1.2716, G loss: 0.8833\n",
      "[804/1762] D loss: 1.2365, G loss: 0.7163\n",
      "[884/1762] D loss: 0.8758, G loss: 1.1107\n",
      "[964/1762] D loss: 1.3904, G loss: 0.5979\n",
      "[1044/1762] D loss: 1.2811, G loss: 0.8201\n",
      "[1124/1762] D loss: 1.2446, G loss: 0.6938\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.5704\n",
      "[1284/1762] D loss: 1.4146, G loss: 0.9340\n",
      "[1364/1762] D loss: 1.3745, G loss: 0.8634\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.7100\n",
      "[1524/1762] D loss: 1.3326, G loss: 0.6654\n",
      "[1604/1762] D loss: 0.9943, G loss: 0.7932\n",
      "[1684/1762] D loss: 1.4011, G loss: 0.7899\n",
      "[1762/1762] D loss: 1.3947, G loss: 0.8097\n",
      "train error: \n",
      " D loss: 1.334369, G loss: 0.763910, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324321, G loss: 0.776313, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3988, G loss: 0.7643\n",
      "[84/1762] D loss: 1.2129, G loss: 0.8604\n",
      "[164/1762] D loss: 1.3940, G loss: 0.7596\n",
      "[244/1762] D loss: 1.3911, G loss: 0.6956\n",
      "[324/1762] D loss: 1.1865, G loss: 0.8809\n",
      "[404/1762] D loss: 1.3816, G loss: 0.9252\n",
      "[484/1762] D loss: 1.3918, G loss: 0.7696\n",
      "[564/1762] D loss: 0.9618, G loss: 0.9040\n",
      "[644/1762] D loss: 1.1745, G loss: 0.8795\n",
      "[724/1762] D loss: 1.4016, G loss: 0.8153\n",
      "[804/1762] D loss: 1.1766, G loss: 0.8970\n",
      "[884/1762] D loss: 1.2034, G loss: 0.7240\n",
      "[964/1762] D loss: 1.3566, G loss: 0.6564\n",
      "[1044/1762] D loss: 1.3926, G loss: 0.7532\n",
      "[1124/1762] D loss: 1.1833, G loss: 0.7542\n",
      "[1204/1762] D loss: 1.3993, G loss: 0.7001\n",
      "[1284/1762] D loss: 1.3641, G loss: 0.7633\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7091\n",
      "[1444/1762] D loss: 1.1835, G loss: 0.8388\n",
      "[1524/1762] D loss: 1.1255, G loss: 0.9400\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.7130\n",
      "[1684/1762] D loss: 1.4673, G loss: 0.4698\n",
      "[1762/1762] D loss: 1.3466, G loss: 0.7469\n",
      "train error: \n",
      " D loss: 1.326682, G loss: 0.817058, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310581, G loss: 0.835114, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4048, G loss: 0.7262\n",
      "[84/1762] D loss: 1.4010, G loss: 0.7538\n",
      "[164/1762] D loss: 1.3893, G loss: 0.7542\n",
      "[244/1762] D loss: 1.1136, G loss: 0.9141\n",
      "[324/1762] D loss: 1.3938, G loss: 0.7141\n",
      "[404/1762] D loss: 1.1564, G loss: 0.7767\n",
      "[484/1762] D loss: 1.1292, G loss: 0.8863\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6758\n",
      "[644/1762] D loss: 1.3923, G loss: 0.7099\n",
      "[724/1762] D loss: 0.9257, G loss: 0.9636\n",
      "[804/1762] D loss: 1.3909, G loss: 0.7356\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7190\n",
      "[964/1762] D loss: 1.3922, G loss: 0.6912\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6915\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6446\n",
      "[1204/1762] D loss: 1.4292, G loss: 0.8898\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.7353\n",
      "[1364/1762] D loss: 1.3905, G loss: 0.6885\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.7085\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.6804\n",
      "[1604/1762] D loss: 1.3962, G loss: 0.5918\n",
      "[1684/1762] D loss: 1.3922, G loss: 0.6613\n",
      "[1762/1762] D loss: 1.4130, G loss: 0.6452\n",
      "train error: \n",
      " D loss: 1.320283, G loss: 0.705462, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299949, G loss: 0.727876, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1578, G loss: 0.7546\n",
      "[84/1762] D loss: 1.1425, G loss: 0.8097\n",
      "[164/1762] D loss: 1.4309, G loss: 0.8589\n",
      "[244/1762] D loss: 1.3983, G loss: 0.7991\n",
      "[324/1762] D loss: 1.1480, G loss: 0.9719\n",
      "[404/1762] D loss: 1.3896, G loss: 0.7610\n",
      "[484/1762] D loss: 1.3811, G loss: 0.7325\n",
      "[564/1762] D loss: 1.3937, G loss: 0.7230\n",
      "[644/1762] D loss: 1.3821, G loss: 0.7352\n",
      "[724/1762] D loss: 1.4440, G loss: 0.9273\n",
      "[804/1762] D loss: 1.4042, G loss: 0.7522\n",
      "[884/1762] D loss: 1.3876, G loss: 0.7437\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6510\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.6171\n",
      "[1124/1762] D loss: 1.0955, G loss: 0.9004\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.5695\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.6691\n",
      "[1364/1762] D loss: 1.4156, G loss: 0.8101\n",
      "[1444/1762] D loss: 1.1139, G loss: 0.9224\n",
      "[1524/1762] D loss: 1.4221, G loss: 0.5897\n",
      "[1604/1762] D loss: 1.3926, G loss: 0.6791\n",
      "[1684/1762] D loss: 1.4018, G loss: 0.7884\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.7434\n",
      "train error: \n",
      " D loss: 1.319213, G loss: 0.828939, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298698, G loss: 0.855546, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908, G loss: 0.7498\n",
      "[84/1762] D loss: 1.4135, G loss: 0.8088\n",
      "[164/1762] D loss: 1.3912, G loss: 0.7764\n",
      "[244/1762] D loss: 1.4010, G loss: 0.5698\n",
      "[324/1762] D loss: 1.3994, G loss: 0.5801\n",
      "[404/1762] D loss: 1.3892, G loss: 0.7032\n",
      "[484/1762] D loss: 1.3629, G loss: 0.7466\n",
      "[564/1762] D loss: 1.1263, G loss: 0.8986\n",
      "[644/1762] D loss: 1.3779, G loss: 0.6096\n",
      "[724/1762] D loss: 1.1153, G loss: 0.9524\n",
      "[804/1762] D loss: 1.4016, G loss: 0.7282\n",
      "[884/1762] D loss: 1.3948, G loss: 0.7552\n",
      "[964/1762] D loss: 1.4137, G loss: 0.8069\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.7585\n",
      "[1124/1762] D loss: 1.3966, G loss: 0.7000\n",
      "[1204/1762] D loss: 1.4036, G loss: 0.6501\n",
      "[1284/1762] D loss: 0.8844, G loss: 1.0196\n",
      "[1364/1762] D loss: 1.3976, G loss: 0.7197\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.6776\n",
      "[1524/1762] D loss: 1.4003, G loss: 0.6338\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6610\n",
      "[1684/1762] D loss: 1.1613, G loss: 0.7330\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.6612\n",
      "train error: \n",
      " D loss: 1.355572, G loss: 0.568306, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332075, G loss: 0.590200, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4055, G loss: 0.5395\n",
      "[84/1762] D loss: 1.3890, G loss: 0.6033\n",
      "[164/1762] D loss: 1.3967, G loss: 0.7663\n",
      "[244/1762] D loss: 1.0885, G loss: 0.9880\n",
      "[324/1762] D loss: 1.1121, G loss: 0.8993\n",
      "[404/1762] D loss: 1.3878, G loss: 0.6745\n",
      "[484/1762] D loss: 1.3899, G loss: 0.7427\n",
      "[564/1762] D loss: 1.3911, G loss: 0.6207\n",
      "[644/1762] D loss: 1.3885, G loss: 0.5953\n",
      "[724/1762] D loss: 1.3925, G loss: 0.6954\n",
      "[804/1762] D loss: 1.4334, G loss: 0.8018\n",
      "[884/1762] D loss: 1.4782, G loss: 0.8656\n",
      "[964/1762] D loss: 1.1527, G loss: 1.0529\n",
      "[1044/1762] D loss: 1.3924, G loss: 0.6552\n",
      "[1124/1762] D loss: 1.3981, G loss: 0.7710\n",
      "[1204/1762] D loss: 1.4149, G loss: 0.7616\n",
      "[1284/1762] D loss: 1.0917, G loss: 1.1452\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6739\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6491\n",
      "[1524/1762] D loss: 1.4393, G loss: 0.7541\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.6400\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.7255\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7259\n",
      "train error: \n",
      " D loss: 1.315027, G loss: 0.801102, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293742, G loss: 0.828017, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.7261\n",
      "[84/1762] D loss: 1.3885, G loss: 0.6825\n",
      "[164/1762] D loss: 1.1210, G loss: 0.9244\n",
      "[244/1762] D loss: 1.1190, G loss: 0.9245\n",
      "[324/1762] D loss: 1.3963, G loss: 0.8108\n",
      "[404/1762] D loss: 1.3894, G loss: 0.7041\n",
      "[484/1762] D loss: 1.1171, G loss: 0.8966\n",
      "[564/1762] D loss: 1.3699, G loss: 0.6260\n",
      "[644/1762] D loss: 1.1210, G loss: 0.7679\n",
      "[724/1762] D loss: 1.4197, G loss: 0.7859\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7462\n",
      "[884/1762] D loss: 1.4070, G loss: 0.6119\n",
      "[964/1762] D loss: 1.4199, G loss: 0.7672\n",
      "[1044/1762] D loss: 1.3966, G loss: 0.6568\n",
      "[1124/1762] D loss: 1.1545, G loss: 0.9172\n",
      "[1204/1762] D loss: 1.4393, G loss: 0.9828\n",
      "[1284/1762] D loss: 1.4173, G loss: 0.7617\n",
      "[1364/1762] D loss: 0.9674, G loss: 1.0240\n",
      "[1444/1762] D loss: 1.3069, G loss: 0.8575\n",
      "[1524/1762] D loss: 1.3494, G loss: 0.7422\n",
      "[1604/1762] D loss: 1.4207, G loss: 0.9589\n",
      "[1684/1762] D loss: 1.0885, G loss: 0.8248\n",
      "[1762/1762] D loss: 1.2939, G loss: 0.7611\n",
      "train error: \n",
      " D loss: 1.312830, G loss: 0.704047, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292334, G loss: 0.723280, D accuracy: 58.2%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.5959\n",
      "[84/1762] D loss: 1.1450, G loss: 0.7438\n",
      "[164/1762] D loss: 1.3930, G loss: 0.5918\n",
      "[244/1762] D loss: 1.1634, G loss: 0.8101\n",
      "[324/1762] D loss: 1.1627, G loss: 1.0544\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7280\n",
      "[484/1762] D loss: 1.4004, G loss: 0.5375\n",
      "[564/1762] D loss: 1.4009, G loss: 0.8149\n",
      "[644/1762] D loss: 1.1570, G loss: 0.7993\n",
      "[724/1762] D loss: 1.3908, G loss: 0.7556\n",
      "[804/1762] D loss: 1.4860, G loss: 0.6771\n",
      "[884/1762] D loss: 1.1151, G loss: 0.9814\n",
      "[964/1762] D loss: 1.3887, G loss: 0.8152\n",
      "[1044/1762] D loss: 1.3926, G loss: 0.6207\n",
      "[1124/1762] D loss: 1.4022, G loss: 0.8118\n",
      "[1204/1762] D loss: 1.3787, G loss: 0.7551\n",
      "[1284/1762] D loss: 1.1380, G loss: 0.8451\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7037\n",
      "[1444/1762] D loss: 1.3903, G loss: 0.7089\n",
      "[1524/1762] D loss: 1.4270, G loss: 0.8912\n",
      "[1604/1762] D loss: 1.3693, G loss: 0.8030\n",
      "[1684/1762] D loss: 1.3846, G loss: 0.7905\n",
      "[1762/1762] D loss: 1.4151, G loss: 0.7699\n",
      "train error: \n",
      " D loss: 1.313309, G loss: 0.772908, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291541, G loss: 0.795290, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.6937\n",
      "[84/1762] D loss: 1.1087, G loss: 0.9262\n",
      "[164/1762] D loss: 1.3790, G loss: 0.7220\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6736\n",
      "[324/1762] D loss: 1.4216, G loss: 0.7781\n",
      "[404/1762] D loss: 1.4111, G loss: 0.8228\n",
      "[484/1762] D loss: 1.3939, G loss: 0.7653\n",
      "[564/1762] D loss: 1.1465, G loss: 0.7491\n",
      "[644/1762] D loss: 1.1014, G loss: 0.9030\n",
      "[724/1762] D loss: 1.4006, G loss: 0.5916\n",
      "[804/1762] D loss: 1.3913, G loss: 0.6990\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7160\n",
      "[964/1762] D loss: 1.3998, G loss: 0.6717\n",
      "[1044/1762] D loss: 1.1002, G loss: 0.9318\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.6753\n",
      "[1204/1762] D loss: 0.8519, G loss: 1.0931\n",
      "[1284/1762] D loss: 1.1508, G loss: 0.7395\n",
      "[1364/1762] D loss: 1.0973, G loss: 0.7691\n",
      "[1444/1762] D loss: 1.3937, G loss: 0.7153\n",
      "[1524/1762] D loss: 1.1095, G loss: 0.9247\n",
      "[1604/1762] D loss: 1.3982, G loss: 0.7876\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7418\n",
      "[1762/1762] D loss: 1.3923, G loss: 0.6489\n",
      "train error: \n",
      " D loss: 1.315087, G loss: 0.756275, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294254, G loss: 0.779854, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3989, G loss: 0.7753\n",
      "[84/1762] D loss: 1.3996, G loss: 0.8340\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6781\n",
      "[244/1762] D loss: 1.1114, G loss: 1.0163\n",
      "[324/1762] D loss: 1.3888, G loss: 0.6092\n",
      "[404/1762] D loss: 1.3887, G loss: 0.6906\n",
      "[484/1762] D loss: 1.3979, G loss: 0.6936\n",
      "[564/1762] D loss: 1.3942, G loss: 0.6844\n",
      "[644/1762] D loss: 1.3911, G loss: 0.6911\n",
      "[724/1762] D loss: 1.3952, G loss: 0.6863\n",
      "[804/1762] D loss: 1.3971, G loss: 0.5640\n",
      "[884/1762] D loss: 1.3972, G loss: 0.6905\n",
      "[964/1762] D loss: 1.0918, G loss: 1.0310\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.7400\n",
      "[1124/1762] D loss: 1.1162, G loss: 0.8874\n",
      "[1204/1762] D loss: 1.3960, G loss: 0.7055\n",
      "[1284/1762] D loss: 1.3914, G loss: 0.5911\n",
      "[1364/1762] D loss: 1.3914, G loss: 0.6331\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7019\n",
      "[1524/1762] D loss: 1.1249, G loss: 0.8678\n",
      "[1604/1762] D loss: 1.1416, G loss: 0.7943\n",
      "[1684/1762] D loss: 1.4106, G loss: 0.5526\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.6490\n",
      "train error: \n",
      " D loss: 1.316972, G loss: 0.705667, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294549, G loss: 0.731683, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958, G loss: 0.6318\n",
      "[84/1762] D loss: 1.3877, G loss: 0.7176\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7194\n",
      "[244/1762] D loss: 1.3979, G loss: 0.5944\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6988\n",
      "[404/1762] D loss: 1.3831, G loss: 0.7513\n",
      "[484/1762] D loss: 1.1291, G loss: 0.8031\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7132\n",
      "[644/1762] D loss: 1.0957, G loss: 1.0410\n",
      "[724/1762] D loss: 1.4020, G loss: 0.7811\n",
      "[804/1762] D loss: 1.4382, G loss: 0.8368\n",
      "[884/1762] D loss: 1.3908, G loss: 0.6278\n",
      "[964/1762] D loss: 1.4453, G loss: 0.8749\n",
      "[1044/1762] D loss: 1.3949, G loss: 0.7558\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7137\n",
      "[1204/1762] D loss: 1.3954, G loss: 0.7785\n",
      "[1284/1762] D loss: 1.3932, G loss: 0.6899\n",
      "[1364/1762] D loss: 1.1146, G loss: 0.8738\n",
      "[1444/1762] D loss: 1.1089, G loss: 0.8778\n",
      "[1524/1762] D loss: 1.0966, G loss: 0.8010\n",
      "[1604/1762] D loss: 1.2291, G loss: 0.8067\n",
      "[1684/1762] D loss: 1.3718, G loss: 0.6638\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.6331\n",
      "train error: \n",
      " D loss: 1.325060, G loss: 0.725742, D accuracy: 55.7%, cell accuracy: 99.3%, board accuracy: 53.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310383, G loss: 0.748266, D accuracy: 56.5%, cell accuracy: 99.2%, board accuracy: 49.1% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1016, G loss: 0.9536\n",
      "[84/1762] D loss: 1.4221, G loss: 0.5928\n",
      "[164/1762] D loss: 1.0933, G loss: 0.9467\n",
      "[244/1762] D loss: 1.3315, G loss: 0.6767\n",
      "[324/1762] D loss: 1.4232, G loss: 0.5450\n",
      "[404/1762] D loss: 1.3773, G loss: 0.6204\n",
      "[484/1762] D loss: 1.4058, G loss: 0.6745\n",
      "[564/1762] D loss: 1.3967, G loss: 0.7489\n",
      "[644/1762] D loss: 1.1367, G loss: 0.8618\n",
      "[724/1762] D loss: 1.3342, G loss: 0.6700\n",
      "[804/1762] D loss: 1.4008, G loss: 0.7010\n",
      "[884/1762] D loss: 1.1361, G loss: 0.8639\n",
      "[964/1762] D loss: 1.3937, G loss: 0.7528\n",
      "[1044/1762] D loss: 1.1148, G loss: 0.9813\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.6335\n",
      "[1204/1762] D loss: 1.4152, G loss: 0.8109\n",
      "[1284/1762] D loss: 0.8774, G loss: 0.9765\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.8151\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.7332\n",
      "[1524/1762] D loss: 1.3731, G loss: 0.7877\n",
      "[1604/1762] D loss: 1.4056, G loss: 0.7693\n",
      "[1684/1762] D loss: 1.3958, G loss: 0.6565\n",
      "[1762/1762] D loss: 1.4138, G loss: 0.6649\n",
      "train error: \n",
      " D loss: 1.321275, G loss: 0.828364, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301720, G loss: 0.849828, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4038, G loss: 0.8606\n",
      "[84/1762] D loss: 1.3312, G loss: 0.6856\n",
      "[164/1762] D loss: 1.4134, G loss: 0.7772\n",
      "[244/1762] D loss: 1.3756, G loss: 0.7615\n",
      "[324/1762] D loss: 1.4263, G loss: 0.5707\n",
      "[404/1762] D loss: 1.3337, G loss: 0.7745\n",
      "[484/1762] D loss: 1.4127, G loss: 0.8810\n",
      "[564/1762] D loss: 1.1086, G loss: 1.0406\n",
      "[644/1762] D loss: 1.3765, G loss: 0.7777\n",
      "[724/1762] D loss: 1.4034, G loss: 0.6885\n",
      "[804/1762] D loss: 1.4044, G loss: 0.6347\n",
      "[884/1762] D loss: 1.3958, G loss: 0.7332\n",
      "[964/1762] D loss: 1.2586, G loss: 0.8424\n",
      "[1044/1762] D loss: 1.4415, G loss: 0.7907\n",
      "[1124/1762] D loss: 1.3984, G loss: 0.6438\n",
      "[1204/1762] D loss: 1.3301, G loss: 0.7409\n",
      "[1284/1762] D loss: 1.3761, G loss: 0.7585\n",
      "[1364/1762] D loss: 1.4132, G loss: 0.9086\n",
      "[1444/1762] D loss: 1.1245, G loss: 0.9154\n",
      "[1524/1762] D loss: 1.3902, G loss: 0.6701\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6762\n",
      "[1684/1762] D loss: 1.4037, G loss: 0.7609\n",
      "[1762/1762] D loss: 0.8631, G loss: 1.0747\n",
      "train error: \n",
      " D loss: 1.324992, G loss: 0.858847, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303422, G loss: 0.883789, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1206, G loss: 1.0665\n",
      "[84/1762] D loss: 0.8926, G loss: 0.9708\n",
      "[164/1762] D loss: 1.3981, G loss: 0.6849\n",
      "[244/1762] D loss: 1.1408, G loss: 0.7849\n",
      "[324/1762] D loss: 1.4110, G loss: 0.7760\n",
      "[404/1762] D loss: 1.1433, G loss: 1.1553\n",
      "[484/1762] D loss: 1.1348, G loss: 0.9318\n",
      "[564/1762] D loss: 1.4023, G loss: 0.8156\n",
      "[644/1762] D loss: 1.3996, G loss: 0.7966\n",
      "[724/1762] D loss: 1.3856, G loss: 0.7444\n",
      "[804/1762] D loss: 1.3902, G loss: 0.7498\n",
      "[884/1762] D loss: 1.3940, G loss: 0.7479\n",
      "[964/1762] D loss: 1.4133, G loss: 0.6715\n",
      "[1044/1762] D loss: 1.4531, G loss: 0.9744\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7563\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.7068\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7084\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.6802\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.6950\n",
      "[1524/1762] D loss: 1.3956, G loss: 0.7071\n",
      "[1604/1762] D loss: 1.4060, G loss: 0.6625\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.7861\n",
      "[1762/1762] D loss: 1.3911, G loss: 0.7690\n",
      "train error: \n",
      " D loss: 1.313448, G loss: 0.782163, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292186, G loss: 0.808799, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4162, G loss: 0.7741\n",
      "[84/1762] D loss: 1.1103, G loss: 1.1035\n",
      "[164/1762] D loss: 1.3931, G loss: 0.7773\n",
      "[244/1762] D loss: 1.4009, G loss: 0.8469\n",
      "[324/1762] D loss: 1.3962, G loss: 0.8010\n",
      "[404/1762] D loss: 1.3929, G loss: 0.6600\n",
      "[484/1762] D loss: 1.4135, G loss: 0.5973\n",
      "[564/1762] D loss: 1.4010, G loss: 0.6874\n",
      "[644/1762] D loss: 1.3931, G loss: 0.6660\n",
      "[724/1762] D loss: 1.3938, G loss: 0.7473\n",
      "[804/1762] D loss: 1.4007, G loss: 0.6264\n",
      "[884/1762] D loss: 1.4112, G loss: 0.7038\n",
      "[964/1762] D loss: 1.3075, G loss: 0.6430\n",
      "[1044/1762] D loss: 1.0930, G loss: 0.9634\n",
      "[1124/1762] D loss: 1.4052, G loss: 0.7400\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6385\n",
      "[1284/1762] D loss: 1.0883, G loss: 0.9359\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.7017\n",
      "[1444/1762] D loss: 1.1097, G loss: 1.0203\n",
      "[1524/1762] D loss: 1.4296, G loss: 0.8850\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.7794\n",
      "[1684/1762] D loss: 1.7592, G loss: 0.5713\n",
      "[1762/1762] D loss: 1.3827, G loss: 0.7329\n",
      "train error: \n",
      " D loss: 1.342944, G loss: 0.776056, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324814, G loss: 0.800615, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3713, G loss: 0.7404\n",
      "[84/1762] D loss: 1.6260, G loss: 0.5857\n",
      "[164/1762] D loss: 1.1623, G loss: 1.0198\n",
      "[244/1762] D loss: 1.1151, G loss: 0.9480\n",
      "[324/1762] D loss: 1.7475, G loss: 0.6480\n",
      "[404/1762] D loss: 1.2188, G loss: 1.0476\n",
      "[484/1762] D loss: 1.2162, G loss: 0.9893\n",
      "[564/1762] D loss: 1.3118, G loss: 0.6966\n",
      "[644/1762] D loss: 1.3188, G loss: 0.7864\n",
      "[724/1762] D loss: 1.3821, G loss: 0.8059\n",
      "[804/1762] D loss: 1.5455, G loss: 0.7111\n",
      "[884/1762] D loss: 1.3211, G loss: 0.8445\n",
      "[964/1762] D loss: 1.2799, G loss: 0.7211\n",
      "[1044/1762] D loss: 1.5450, G loss: 0.4990\n",
      "[1124/1762] D loss: 1.7232, G loss: 0.8454\n",
      "[1204/1762] D loss: 1.3371, G loss: 0.9004\n",
      "[1284/1762] D loss: 1.3658, G loss: 0.8563\n",
      "[1364/1762] D loss: 1.7013, G loss: 0.4522\n",
      "[1444/1762] D loss: 1.4247, G loss: 0.7358\n",
      "[1524/1762] D loss: 1.4315, G loss: 0.5307\n",
      "[1604/1762] D loss: 1.3959, G loss: 0.6063\n",
      "[1684/1762] D loss: 1.3067, G loss: 0.9511\n",
      "[1762/1762] D loss: 1.2362, G loss: 0.7471\n",
      "train error: \n",
      " D loss: 1.404991, G loss: 0.745237, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 72.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.419657, G loss: 0.775683, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3666, G loss: 0.7282\n",
      "[84/1762] D loss: 1.3497, G loss: 0.7007\n",
      "[164/1762] D loss: 1.2873, G loss: 0.7933\n",
      "[244/1762] D loss: 1.5681, G loss: 0.4084\n",
      "[324/1762] D loss: 1.6346, G loss: 0.8184\n",
      "[404/1762] D loss: 1.2751, G loss: 0.7618\n",
      "[484/1762] D loss: 1.3685, G loss: 0.6549\n",
      "[564/1762] D loss: 1.3485, G loss: 0.7858\n",
      "[644/1762] D loss: 1.4175, G loss: 0.8023\n",
      "[724/1762] D loss: 1.4053, G loss: 0.6542\n",
      "[804/1762] D loss: 1.6979, G loss: 0.6592\n",
      "[884/1762] D loss: 1.3947, G loss: 0.6547\n",
      "[964/1762] D loss: 1.5185, G loss: 0.7612\n",
      "[1044/1762] D loss: 1.2627, G loss: 0.8931\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7435\n",
      "[1204/1762] D loss: 1.4037, G loss: 0.5629\n",
      "[1284/1762] D loss: 1.6191, G loss: 0.7509\n",
      "[1364/1762] D loss: 1.6356, G loss: 0.6409\n",
      "[1444/1762] D loss: 1.3707, G loss: 0.6824\n",
      "[1524/1762] D loss: 1.3726, G loss: 0.6950\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.6362\n",
      "[1684/1762] D loss: 1.3743, G loss: 0.6450\n",
      "[1762/1762] D loss: 1.3993, G loss: 0.7739\n",
      "train error: \n",
      " D loss: 1.399092, G loss: 0.681881, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410204, G loss: 0.692792, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.6433\n",
      "[84/1762] D loss: 1.3929, G loss: 0.7556\n",
      "[164/1762] D loss: 1.4959, G loss: 0.8695\n",
      "[244/1762] D loss: 1.3973, G loss: 0.6155\n",
      "[324/1762] D loss: 1.3931, G loss: 0.7451\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6982\n",
      "[484/1762] D loss: 1.3895, G loss: 0.6938\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6109\n",
      "[644/1762] D loss: 1.2690, G loss: 0.8303\n",
      "[724/1762] D loss: 1.3933, G loss: 0.6104\n",
      "[804/1762] D loss: 1.3807, G loss: 0.6323\n",
      "[884/1762] D loss: 1.3927, G loss: 0.7497\n",
      "[964/1762] D loss: 1.3931, G loss: 0.6006\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.6667\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.6712\n",
      "[1204/1762] D loss: 1.2364, G loss: 0.7701\n",
      "[1284/1762] D loss: 1.4392, G loss: 0.7180\n",
      "[1364/1762] D loss: 1.3047, G loss: 0.7544\n",
      "[1444/1762] D loss: 1.3911, G loss: 0.7147\n",
      "[1524/1762] D loss: 1.2653, G loss: 0.8460\n",
      "[1604/1762] D loss: 1.3368, G loss: 0.7609\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6704\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6858\n",
      "train error: \n",
      " D loss: 1.358619, G loss: 0.760364, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359815, G loss: 0.767567, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3928, G loss: 0.6205\n",
      "[84/1762] D loss: 1.3910, G loss: 0.6257\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6301\n",
      "[244/1762] D loss: 1.3834, G loss: 0.6363\n",
      "[324/1762] D loss: 1.3736, G loss: 0.6475\n",
      "[404/1762] D loss: 1.3493, G loss: 0.6662\n",
      "[484/1762] D loss: 1.2765, G loss: 0.7163\n",
      "[564/1762] D loss: 1.1138, G loss: 0.8695\n",
      "[644/1762] D loss: 0.8840, G loss: 1.0822\n",
      "[724/1762] D loss: 0.6574, G loss: 1.5102\n",
      "[804/1762] D loss: 0.5168, G loss: 1.7793\n",
      "[884/1762] D loss: 0.2729, G loss: 2.4728\n",
      "[964/1762] D loss: 0.1994, G loss: 2.7558\n",
      "[1044/1762] D loss: 0.1530, G loss: 2.8798\n",
      "[1124/1762] D loss: 0.1569, G loss: 2.9711\n",
      "[1204/1762] D loss: 0.0862, G loss: 3.5741\n",
      "[1284/1762] D loss: 0.0657, G loss: 3.7488\n",
      "[1364/1762] D loss: 0.1052, G loss: 4.3700\n",
      "[1444/1762] D loss: 0.0762, G loss: 3.7851\n",
      "[1524/1762] D loss: 0.1128, G loss: 3.4605\n",
      "[1604/1762] D loss: 0.1058, G loss: 3.8444\n",
      "[1684/1762] D loss: 0.0549, G loss: 3.6260\n",
      "[1762/1762] D loss: 0.0859, G loss: 3.2270\n",
      "train error: \n",
      " D loss: 0.131428, G loss: 2.810636, D accuracy: 99.7%, cell accuracy: 89.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.135203, G loss: 2.781104, D accuracy: 100.0%, cell accuracy: 89.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2075, G loss: 2.7008\n",
      "[84/1762] D loss: 0.0570, G loss: 3.6645\n",
      "[164/1762] D loss: 0.1424, G loss: 4.9815\n",
      "[244/1762] D loss: 0.0702, G loss: 4.1532\n",
      "[324/1762] D loss: 0.0736, G loss: 3.7572\n",
      "[404/1762] D loss: 0.1917, G loss: 3.5360\n",
      "[484/1762] D loss: 0.2556, G loss: 3.4808\n",
      "[564/1762] D loss: 0.0799, G loss: 3.9034\n",
      "[644/1762] D loss: 0.1218, G loss: 4.2407\n",
      "[724/1762] D loss: 0.0826, G loss: 4.2986\n",
      "[804/1762] D loss: 0.1100, G loss: 4.4906\n",
      "[884/1762] D loss: 0.0997, G loss: 4.0183\n",
      "[964/1762] D loss: 0.1217, G loss: 3.5302\n",
      "[1044/1762] D loss: 0.1214, G loss: 3.9006\n",
      "[1124/1762] D loss: 0.1532, G loss: 2.3106\n",
      "[1204/1762] D loss: 0.0957, G loss: 4.2623\n",
      "[1284/1762] D loss: 0.1445, G loss: 3.0982\n",
      "[1364/1762] D loss: 0.0506, G loss: 4.1989\n",
      "[1444/1762] D loss: 0.0487, G loss: 3.5487\n",
      "[1524/1762] D loss: 0.1611, G loss: 4.2135\n",
      "[1604/1762] D loss: 0.1507, G loss: 3.5727\n",
      "[1684/1762] D loss: 0.2271, G loss: 3.7166\n",
      "[1762/1762] D loss: 0.2579, G loss: 2.1457\n",
      "train error: \n",
      " D loss: 0.226088, G loss: 2.771860, D accuracy: 97.7%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.219161, G loss: 2.781189, D accuracy: 98.1%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3144, G loss: 2.4404\n",
      "[84/1762] D loss: 0.2800, G loss: 2.7206\n",
      "[164/1762] D loss: 0.3534, G loss: 2.6835\n",
      "[244/1762] D loss: 0.1658, G loss: 3.8212\n",
      "[324/1762] D loss: 0.0870, G loss: 3.1243\n",
      "[404/1762] D loss: 1.6046, G loss: 3.8547\n",
      "[484/1762] D loss: 0.3712, G loss: 3.3594\n",
      "[564/1762] D loss: 0.2522, G loss: 2.1665\n",
      "[644/1762] D loss: 0.2497, G loss: 1.6297\n",
      "[724/1762] D loss: 0.2659, G loss: 1.9963\n",
      "[804/1762] D loss: 0.5554, G loss: 4.5193\n",
      "[884/1762] D loss: 0.3548, G loss: 1.7121\n",
      "[964/1762] D loss: 0.2414, G loss: 2.3451\n",
      "[1044/1762] D loss: 0.4845, G loss: 3.1307\n",
      "[1124/1762] D loss: 0.8575, G loss: 1.7155\n",
      "[1204/1762] D loss: 0.5402, G loss: 1.6887\n",
      "[1284/1762] D loss: 1.3755, G loss: 0.6407\n",
      "[1364/1762] D loss: 1.5700, G loss: 0.7677\n",
      "[1444/1762] D loss: 1.1754, G loss: 2.6375\n",
      "[1524/1762] D loss: 0.3038, G loss: 3.3776\n",
      "[1604/1762] D loss: 0.5704, G loss: 2.6487\n",
      "[1684/1762] D loss: 0.4380, G loss: 1.5285\n",
      "[1762/1762] D loss: 0.6681, G loss: 1.3113\n",
      "train error: \n",
      " D loss: 0.538047, G loss: 1.795502, D accuracy: 92.1%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.540448, G loss: 1.740589, D accuracy: 93.2%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5408, G loss: 1.4202\n",
      "[84/1762] D loss: 0.6231, G loss: 1.3592\n",
      "[164/1762] D loss: 0.2487, G loss: 2.3974\n",
      "[244/1762] D loss: 0.4661, G loss: 1.8515\n",
      "[324/1762] D loss: 0.1997, G loss: 1.5197\n",
      "[404/1762] D loss: 0.5587, G loss: 2.3664\n",
      "[484/1762] D loss: 0.3637, G loss: 1.2488\n",
      "[564/1762] D loss: 0.4946, G loss: 3.1305\n",
      "[644/1762] D loss: 0.5452, G loss: 3.7634\n",
      "[724/1762] D loss: 0.5862, G loss: 1.9480\n",
      "[804/1762] D loss: 0.4324, G loss: 2.0088\n",
      "[884/1762] D loss: 0.1984, G loss: 2.3662\n",
      "[964/1762] D loss: 0.3351, G loss: 2.1853\n",
      "[1044/1762] D loss: 1.1700, G loss: 1.8699\n",
      "[1124/1762] D loss: 0.5591, G loss: 1.3596\n",
      "[1204/1762] D loss: 0.4867, G loss: 3.1262\n",
      "[1284/1762] D loss: 0.6266, G loss: 1.5124\n",
      "[1364/1762] D loss: 0.3515, G loss: 2.0111\n",
      "[1444/1762] D loss: 0.2086, G loss: 2.2640\n",
      "[1524/1762] D loss: 0.3544, G loss: 1.6105\n",
      "[1604/1762] D loss: 0.5721, G loss: 1.3312\n",
      "[1684/1762] D loss: 0.6695, G loss: 2.1681\n",
      "[1762/1762] D loss: 0.4799, G loss: 1.7673\n",
      "train error: \n",
      " D loss: 0.691043, G loss: 1.194418, D accuracy: 86.1%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.694949, G loss: 1.176799, D accuracy: 85.1%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6012, G loss: 1.4008\n",
      "[84/1762] D loss: 0.5395, G loss: 1.6626\n",
      "[164/1762] D loss: 0.1377, G loss: 3.3265\n",
      "[244/1762] D loss: 0.8309, G loss: 2.9502\n",
      "[324/1762] D loss: 1.1206, G loss: 1.9351\n",
      "[404/1762] D loss: 0.6148, G loss: 1.5421\n",
      "[484/1762] D loss: 0.5564, G loss: 2.5272\n",
      "[564/1762] D loss: 1.3747, G loss: 1.5324\n",
      "[644/1762] D loss: 1.9048, G loss: 2.5085\n",
      "[724/1762] D loss: 1.1653, G loss: 1.9650\n",
      "[804/1762] D loss: 1.3733, G loss: 0.6265\n",
      "[884/1762] D loss: 1.3931, G loss: 0.6140\n",
      "[964/1762] D loss: 0.8853, G loss: 0.8042\n",
      "[1044/1762] D loss: 0.8640, G loss: 0.9654\n",
      "[1124/1762] D loss: 1.2076, G loss: 0.6183\n",
      "[1204/1762] D loss: 1.6734, G loss: 0.2477\n",
      "[1284/1762] D loss: 1.0867, G loss: 0.6630\n",
      "[1364/1762] D loss: 1.0625, G loss: 1.3853\n",
      "[1444/1762] D loss: 1.1138, G loss: 1.0052\n",
      "[1524/1762] D loss: 1.2177, G loss: 1.5996\n",
      "[1604/1762] D loss: 1.0256, G loss: 1.3779\n",
      "[1684/1762] D loss: 0.9389, G loss: 2.2239\n",
      "[1762/1762] D loss: 1.8332, G loss: 0.4250\n",
      "train error: \n",
      " D loss: 1.177176, G loss: 1.601071, D accuracy: 68.9%, cell accuracy: 98.0%, board accuracy: 14.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.163779, G loss: 1.616051, D accuracy: 67.4%, cell accuracy: 97.8%, board accuracy: 14.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9893, G loss: 1.6432\n",
      "[84/1762] D loss: 1.0962, G loss: 1.1953\n",
      "[164/1762] D loss: 1.3831, G loss: 0.9756\n",
      "[244/1762] D loss: 1.2623, G loss: 0.6317\n",
      "[324/1762] D loss: 0.9699, G loss: 1.0699\n",
      "[404/1762] D loss: 0.9037, G loss: 1.3637\n",
      "[484/1762] D loss: 2.2450, G loss: 2.9426\n",
      "[564/1762] D loss: 0.9568, G loss: 1.7525\n",
      "[644/1762] D loss: 0.9298, G loss: 1.2141\n",
      "[724/1762] D loss: 1.1359, G loss: 0.8427\n",
      "[804/1762] D loss: 1.0078, G loss: 0.8200\n",
      "[884/1762] D loss: 1.4843, G loss: 1.1433\n",
      "[964/1762] D loss: 1.0468, G loss: 0.7451\n",
      "[1044/1762] D loss: 1.1873, G loss: 1.6117\n",
      "[1124/1762] D loss: 1.0680, G loss: 1.6241\n",
      "[1204/1762] D loss: 0.9487, G loss: 1.0100\n",
      "[1284/1762] D loss: 1.3102, G loss: 0.5239\n",
      "[1364/1762] D loss: 1.7170, G loss: 0.4618\n",
      "[1444/1762] D loss: 1.0398, G loss: 0.8643\n",
      "[1524/1762] D loss: 1.0482, G loss: 0.7482\n",
      "[1604/1762] D loss: 1.1640, G loss: 0.8010\n",
      "[1684/1762] D loss: 1.2859, G loss: 0.9326\n",
      "[1762/1762] D loss: 1.3271, G loss: 0.6643\n",
      "train error: \n",
      " D loss: 1.198139, G loss: 0.892028, D accuracy: 67.8%, cell accuracy: 98.6%, board accuracy: 17.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.162702, G loss: 0.892924, D accuracy: 69.1%, cell accuracy: 98.5%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9585, G loss: 1.3036\n",
      "[84/1762] D loss: 1.4758, G loss: 0.6862\n",
      "[164/1762] D loss: 0.9818, G loss: 1.0974\n",
      "[244/1762] D loss: 1.4731, G loss: 0.6725\n",
      "[324/1762] D loss: 1.3575, G loss: 1.0443\n",
      "[404/1762] D loss: 1.0718, G loss: 0.8128\n",
      "[484/1762] D loss: 0.9342, G loss: 1.3849\n",
      "[564/1762] D loss: 1.2941, G loss: 0.7573\n",
      "[644/1762] D loss: 1.3708, G loss: 0.6437\n",
      "[724/1762] D loss: 1.0176, G loss: 0.8338\n",
      "[804/1762] D loss: 1.3985, G loss: 0.8819\n",
      "[884/1762] D loss: 1.0794, G loss: 1.2322\n",
      "[964/1762] D loss: 1.3724, G loss: 0.8601\n",
      "[1044/1762] D loss: 1.1456, G loss: 0.9200\n",
      "[1124/1762] D loss: 1.3177, G loss: 0.8153\n",
      "[1204/1762] D loss: 1.7246, G loss: 1.7958\n",
      "[1284/1762] D loss: 1.3321, G loss: 0.6250\n",
      "[1364/1762] D loss: 1.5853, G loss: 0.8054\n",
      "[1444/1762] D loss: 1.1784, G loss: 1.3433\n",
      "[1524/1762] D loss: 1.2278, G loss: 0.9345\n",
      "[1604/1762] D loss: 1.2981, G loss: 0.9815\n",
      "[1684/1762] D loss: 1.0427, G loss: 1.3693\n",
      "[1762/1762] D loss: 1.5245, G loss: 0.8129\n",
      "train error: \n",
      " D loss: 1.286532, G loss: 0.716028, D accuracy: 63.4%, cell accuracy: 98.6%, board accuracy: 19.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257880, G loss: 0.715247, D accuracy: 66.0%, cell accuracy: 98.5%, board accuracy: 18.6% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3245, G loss: 0.8606\n",
      "[84/1762] D loss: 1.2195, G loss: 1.0635\n",
      "[164/1762] D loss: 0.7339, G loss: 1.4570\n",
      "[244/1762] D loss: 1.1519, G loss: 0.8515\n",
      "[324/1762] D loss: 1.2754, G loss: 0.7008\n",
      "[404/1762] D loss: 1.3864, G loss: 0.5449\n",
      "[484/1762] D loss: 1.3630, G loss: 0.8260\n",
      "[564/1762] D loss: 1.2659, G loss: 0.7980\n",
      "[644/1762] D loss: 0.9675, G loss: 1.4572\n",
      "[724/1762] D loss: 1.5654, G loss: 0.7989\n",
      "[804/1762] D loss: 1.0481, G loss: 0.8627\n",
      "[884/1762] D loss: 1.3638, G loss: 0.5147\n",
      "[964/1762] D loss: 1.3771, G loss: 0.5567\n",
      "[1044/1762] D loss: 1.2073, G loss: 0.9286\n",
      "[1124/1762] D loss: 1.1264, G loss: 1.3760\n",
      "[1204/1762] D loss: 1.6265, G loss: 0.5791\n",
      "[1284/1762] D loss: 1.2370, G loss: 1.0307\n",
      "[1364/1762] D loss: 1.4222, G loss: 0.8708\n",
      "[1444/1762] D loss: 1.2283, G loss: 1.0459\n",
      "[1524/1762] D loss: 1.2202, G loss: 0.6024\n",
      "[1604/1762] D loss: 1.3382, G loss: 0.5985\n",
      "[1684/1762] D loss: 1.2965, G loss: 1.0062\n",
      "[1762/1762] D loss: 1.1811, G loss: 1.0616\n",
      "train error: \n",
      " D loss: 1.289474, G loss: 1.075044, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 21.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273511, G loss: 1.080994, D accuracy: 62.5%, cell accuracy: 98.7%, board accuracy: 20.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3279, G loss: 1.0221\n",
      "[84/1762] D loss: 1.2139, G loss: 1.1599\n",
      "[164/1762] D loss: 1.2207, G loss: 0.7340\n",
      "[244/1762] D loss: 1.5108, G loss: 0.5634\n",
      "[324/1762] D loss: 1.0730, G loss: 0.9815\n",
      "[404/1762] D loss: 1.1796, G loss: 0.8702\n",
      "[484/1762] D loss: 1.2090, G loss: 0.6782\n",
      "[564/1762] D loss: 1.2700, G loss: 0.5672\n",
      "[644/1762] D loss: 1.2026, G loss: 0.7939\n",
      "[724/1762] D loss: 1.0274, G loss: 0.8719\n",
      "[804/1762] D loss: 1.0969, G loss: 1.0065\n",
      "[884/1762] D loss: 1.4418, G loss: 0.6418\n",
      "[964/1762] D loss: 1.2678, G loss: 0.8274\n",
      "[1044/1762] D loss: 1.1687, G loss: 0.7218\n",
      "[1124/1762] D loss: 1.6515, G loss: 1.9407\n",
      "[1204/1762] D loss: 1.4975, G loss: 1.0234\n",
      "[1284/1762] D loss: 1.1982, G loss: 0.9692\n",
      "[1364/1762] D loss: 1.1701, G loss: 0.6846\n",
      "[1444/1762] D loss: 1.1564, G loss: 1.0522\n",
      "[1524/1762] D loss: 1.3944, G loss: 1.0072\n",
      "[1604/1762] D loss: 1.0934, G loss: 1.2304\n",
      "[1684/1762] D loss: 1.2058, G loss: 0.9549\n",
      "[1762/1762] D loss: 1.0117, G loss: 1.3497\n",
      "train error: \n",
      " D loss: 1.341884, G loss: 1.176120, D accuracy: 58.4%, cell accuracy: 98.9%, board accuracy: 27.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333985, G loss: 1.179531, D accuracy: 58.6%, cell accuracy: 98.8%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1252, G loss: 1.3455\n",
      "[84/1762] D loss: 1.1678, G loss: 0.7723\n",
      "[164/1762] D loss: 0.9345, G loss: 1.0911\n",
      "[244/1762] D loss: 1.1777, G loss: 0.9915\n",
      "[324/1762] D loss: 1.2074, G loss: 0.7144\n",
      "[404/1762] D loss: 1.2828, G loss: 0.8568\n",
      "[484/1762] D loss: 1.5855, G loss: 0.5325\n",
      "[564/1762] D loss: 1.2682, G loss: 0.5457\n",
      "[644/1762] D loss: 1.4117, G loss: 0.4415\n",
      "[724/1762] D loss: 1.4665, G loss: 1.0250\n",
      "[804/1762] D loss: 1.4767, G loss: 0.8392\n",
      "[884/1762] D loss: 1.4203, G loss: 1.0530\n",
      "[964/1762] D loss: 1.4014, G loss: 0.5488\n",
      "[1044/1762] D loss: 1.2513, G loss: 0.8728\n",
      "[1124/1762] D loss: 1.2857, G loss: 0.8264\n",
      "[1204/1762] D loss: 1.3915, G loss: 1.4189\n",
      "[1284/1762] D loss: 1.2270, G loss: 0.7910\n",
      "[1364/1762] D loss: 1.1527, G loss: 0.7779\n",
      "[1444/1762] D loss: 1.1037, G loss: 1.4057\n",
      "[1524/1762] D loss: 1.1731, G loss: 0.6301\n",
      "[1604/1762] D loss: 1.3135, G loss: 0.7104\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.5136\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.6105\n",
      "train error: \n",
      " D loss: 1.296397, G loss: 0.764870, D accuracy: 63.3%, cell accuracy: 98.9%, board accuracy: 31.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287777, G loss: 0.761884, D accuracy: 63.9%, cell accuracy: 98.9%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2462, G loss: 0.9184\n",
      "[84/1762] D loss: 1.2766, G loss: 0.8441\n",
      "[164/1762] D loss: 1.3043, G loss: 0.7363\n",
      "[244/1762] D loss: 1.0623, G loss: 0.9502\n",
      "[324/1762] D loss: 1.1985, G loss: 0.6699\n",
      "[404/1762] D loss: 1.4896, G loss: 0.4898\n",
      "[484/1762] D loss: 1.3179, G loss: 0.9749\n",
      "[564/1762] D loss: 1.2230, G loss: 0.7592\n",
      "[644/1762] D loss: 1.3584, G loss: 0.9359\n",
      "[724/1762] D loss: 1.2868, G loss: 0.9036\n",
      "[804/1762] D loss: 1.3189, G loss: 0.9588\n",
      "[884/1762] D loss: 1.2198, G loss: 0.8005\n",
      "[964/1762] D loss: 1.3618, G loss: 0.4886\n",
      "[1044/1762] D loss: 1.3401, G loss: 1.0417\n",
      "[1124/1762] D loss: 1.2863, G loss: 0.5559\n",
      "[1204/1762] D loss: 1.1518, G loss: 1.0275\n",
      "[1284/1762] D loss: 1.1730, G loss: 1.0615\n",
      "[1364/1762] D loss: 1.5123, G loss: 0.9931\n",
      "[1444/1762] D loss: 1.2589, G loss: 0.8418\n",
      "[1524/1762] D loss: 1.3821, G loss: 0.7334\n",
      "[1604/1762] D loss: 1.3826, G loss: 0.6926\n",
      "[1684/1762] D loss: 1.3600, G loss: 0.5382\n",
      "[1762/1762] D loss: 1.3246, G loss: 0.8917\n",
      "train error: \n",
      " D loss: 1.322840, G loss: 0.708681, D accuracy: 60.9%, cell accuracy: 99.0%, board accuracy: 33.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323586, G loss: 0.691602, D accuracy: 61.1%, cell accuracy: 99.0%, board accuracy: 32.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3190, G loss: 0.6490\n",
      "[84/1762] D loss: 1.2232, G loss: 0.9351\n",
      "[164/1762] D loss: 1.1139, G loss: 1.0188\n",
      "[244/1762] D loss: 1.1535, G loss: 0.8814\n",
      "[324/1762] D loss: 1.2585, G loss: 0.6735\n",
      "[404/1762] D loss: 1.4051, G loss: 1.2065\n",
      "[484/1762] D loss: 1.3255, G loss: 0.4766\n",
      "[564/1762] D loss: 1.3649, G loss: 0.6858\n",
      "[644/1762] D loss: 1.2922, G loss: 0.9227\n",
      "[724/1762] D loss: 1.3441, G loss: 1.0526\n",
      "[804/1762] D loss: 1.2852, G loss: 0.9862\n",
      "[884/1762] D loss: 1.2884, G loss: 0.5934\n",
      "[964/1762] D loss: 1.1679, G loss: 1.0088\n",
      "[1044/1762] D loss: 1.4693, G loss: 0.7776\n",
      "[1124/1762] D loss: 1.2623, G loss: 0.9580\n",
      "[1204/1762] D loss: 1.4324, G loss: 0.8361\n",
      "[1284/1762] D loss: 1.2384, G loss: 0.8263\n",
      "[1364/1762] D loss: 1.1252, G loss: 0.8431\n",
      "[1444/1762] D loss: 1.3400, G loss: 0.8327\n",
      "[1524/1762] D loss: 1.5025, G loss: 0.9062\n",
      "[1604/1762] D loss: 1.2633, G loss: 0.8226\n",
      "[1684/1762] D loss: 1.3658, G loss: 0.6590\n",
      "[1762/1762] D loss: 1.1139, G loss: 0.8004\n",
      "train error: \n",
      " D loss: 1.365615, G loss: 0.972549, D accuracy: 54.0%, cell accuracy: 99.1%, board accuracy: 37.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365151, G loss: 0.961288, D accuracy: 53.9%, cell accuracy: 99.1%, board accuracy: 38.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3453, G loss: 1.0943\n",
      "[84/1762] D loss: 1.3160, G loss: 0.7122\n",
      "[164/1762] D loss: 1.3769, G loss: 0.7458\n",
      "[244/1762] D loss: 1.4683, G loss: 0.5593\n",
      "[324/1762] D loss: 1.3633, G loss: 0.9236\n",
      "[404/1762] D loss: 1.3304, G loss: 0.7197\n",
      "[484/1762] D loss: 1.3260, G loss: 1.0289\n",
      "[564/1762] D loss: 1.2934, G loss: 0.8174\n",
      "[644/1762] D loss: 1.4787, G loss: 1.1157\n",
      "[724/1762] D loss: 1.3230, G loss: 0.7733\n",
      "[804/1762] D loss: 1.1953, G loss: 0.7480\n",
      "[884/1762] D loss: 1.3029, G loss: 0.8214\n",
      "[964/1762] D loss: 1.4494, G loss: 0.8901\n",
      "[1044/1762] D loss: 1.1843, G loss: 0.9030\n",
      "[1124/1762] D loss: 1.2926, G loss: 0.8724\n",
      "[1204/1762] D loss: 1.3219, G loss: 0.7537\n",
      "[1284/1762] D loss: 1.3849, G loss: 0.6436\n",
      "[1364/1762] D loss: 1.3149, G loss: 0.7767\n",
      "[1444/1762] D loss: 1.3178, G loss: 0.7100\n",
      "[1524/1762] D loss: 1.2733, G loss: 1.1407\n",
      "[1604/1762] D loss: 1.3931, G loss: 1.0804\n",
      "[1684/1762] D loss: 1.1571, G loss: 0.8906\n",
      "[1762/1762] D loss: 1.3472, G loss: 0.6731\n",
      "train error: \n",
      " D loss: 1.330844, G loss: 0.766757, D accuracy: 60.0%, cell accuracy: 99.2%, board accuracy: 41.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330160, G loss: 0.762248, D accuracy: 59.0%, cell accuracy: 99.1%, board accuracy: 40.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3806, G loss: 0.7403\n",
      "[84/1762] D loss: 1.3366, G loss: 0.7340\n",
      "[164/1762] D loss: 1.3062, G loss: 0.6248\n",
      "[244/1762] D loss: 1.3706, G loss: 0.5295\n",
      "[324/1762] D loss: 1.3430, G loss: 1.0578\n",
      "[404/1762] D loss: 1.2920, G loss: 0.9820\n",
      "[484/1762] D loss: 1.3003, G loss: 0.9472\n",
      "[564/1762] D loss: 1.3506, G loss: 0.6965\n",
      "[644/1762] D loss: 1.4671, G loss: 0.6976\n",
      "[724/1762] D loss: 1.3452, G loss: 0.6382\n",
      "[804/1762] D loss: 1.3708, G loss: 0.8529\n",
      "[884/1762] D loss: 1.2934, G loss: 0.7240\n",
      "[964/1762] D loss: 1.3533, G loss: 0.7817\n",
      "[1044/1762] D loss: 1.3330, G loss: 0.7208\n",
      "[1124/1762] D loss: 1.3387, G loss: 0.5822\n",
      "[1204/1762] D loss: 1.3505, G loss: 0.4864\n",
      "[1284/1762] D loss: 1.2683, G loss: 0.9537\n",
      "[1364/1762] D loss: 1.3053, G loss: 0.9818\n",
      "[1444/1762] D loss: 1.3185, G loss: 0.9358\n",
      "[1524/1762] D loss: 1.3084, G loss: 1.1357\n",
      "[1604/1762] D loss: 1.3845, G loss: 0.6262\n",
      "[1684/1762] D loss: 1.3286, G loss: 0.6027\n",
      "[1762/1762] D loss: 1.3794, G loss: 0.6069\n",
      "train error: \n",
      " D loss: 1.334227, G loss: 0.664029, D accuracy: 60.2%, cell accuracy: 99.2%, board accuracy: 43.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333422, G loss: 0.663867, D accuracy: 59.7%, cell accuracy: 99.2%, board accuracy: 41.6% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3420, G loss: 0.6956\n",
      "[84/1762] D loss: 1.3987, G loss: 0.5726\n",
      "[164/1762] D loss: 1.3214, G loss: 0.5791\n",
      "[244/1762] D loss: 1.4011, G loss: 0.7707\n",
      "[324/1762] D loss: 1.2667, G loss: 0.7216\n",
      "[404/1762] D loss: 1.3142, G loss: 0.7401\n",
      "[484/1762] D loss: 1.3912, G loss: 1.3081\n",
      "[564/1762] D loss: 1.3432, G loss: 0.9109\n",
      "[644/1762] D loss: 1.2658, G loss: 1.0289\n",
      "[724/1762] D loss: 1.3604, G loss: 0.8021\n",
      "[804/1762] D loss: 1.1253, G loss: 1.1308\n",
      "[884/1762] D loss: 1.4493, G loss: 0.6515\n",
      "[964/1762] D loss: 1.3922, G loss: 0.5142\n",
      "[1044/1762] D loss: 1.5014, G loss: 0.7898\n",
      "[1124/1762] D loss: 1.3167, G loss: 0.7238\n",
      "[1204/1762] D loss: 1.3189, G loss: 0.7714\n",
      "[1284/1762] D loss: 1.2647, G loss: 0.9362\n",
      "[1364/1762] D loss: 1.3525, G loss: 0.8269\n",
      "[1444/1762] D loss: 1.3418, G loss: 0.8081\n",
      "[1524/1762] D loss: 1.3936, G loss: 0.5767\n",
      "[1604/1762] D loss: 1.4073, G loss: 0.7078\n",
      "[1684/1762] D loss: 1.3773, G loss: 0.8299\n",
      "[1762/1762] D loss: 1.3797, G loss: 0.7977\n",
      "train error: \n",
      " D loss: 1.381619, G loss: 0.900942, D accuracy: 54.3%, cell accuracy: 99.4%, board accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382924, G loss: 0.904059, D accuracy: 54.3%, cell accuracy: 99.4%, board accuracy: 48.6% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5044, G loss: 1.1281\n",
      "[84/1762] D loss: 1.3376, G loss: 0.8017\n",
      "[164/1762] D loss: 1.4711, G loss: 0.4826\n",
      "[244/1762] D loss: 1.3188, G loss: 0.6842\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6943\n",
      "[404/1762] D loss: 1.4328, G loss: 0.7491\n",
      "[484/1762] D loss: 1.2558, G loss: 0.9123\n",
      "[564/1762] D loss: 1.4265, G loss: 0.6525\n",
      "[644/1762] D loss: 1.3839, G loss: 0.6934\n",
      "[724/1762] D loss: 1.3965, G loss: 0.5633\n",
      "[804/1762] D loss: 1.3534, G loss: 0.6746\n",
      "[884/1762] D loss: 1.3100, G loss: 0.8067\n",
      "[964/1762] D loss: 1.4176, G loss: 0.6195\n",
      "[1044/1762] D loss: 1.3766, G loss: 0.7613\n",
      "[1124/1762] D loss: 1.4468, G loss: 0.4719\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.7627\n",
      "[1284/1762] D loss: 1.3200, G loss: 0.5533\n",
      "[1364/1762] D loss: 1.3463, G loss: 0.7643\n",
      "[1444/1762] D loss: 1.3326, G loss: 0.7534\n",
      "[1524/1762] D loss: 1.3960, G loss: 0.6360\n",
      "[1604/1762] D loss: 1.3131, G loss: 0.8373\n",
      "[1684/1762] D loss: 1.3810, G loss: 0.9176\n",
      "[1762/1762] D loss: 1.2800, G loss: 1.1051\n",
      "train error: \n",
      " D loss: 1.439553, G loss: 1.106224, D accuracy: 51.4%, cell accuracy: 99.4%, board accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.437447, G loss: 1.115425, D accuracy: 51.7%, cell accuracy: 99.3%, board accuracy: 47.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4580, G loss: 0.9995\n",
      "[84/1762] D loss: 1.3805, G loss: 0.7479\n",
      "[164/1762] D loss: 1.4693, G loss: 0.9327\n",
      "[244/1762] D loss: 1.4568, G loss: 0.5060\n",
      "[324/1762] D loss: 1.4056, G loss: 0.8898\n",
      "[404/1762] D loss: 1.4225, G loss: 0.6442\n",
      "[484/1762] D loss: 1.3941, G loss: 0.6698\n",
      "[564/1762] D loss: 1.3746, G loss: 0.6675\n",
      "[644/1762] D loss: 1.2421, G loss: 0.8439\n",
      "[724/1762] D loss: 1.3980, G loss: 0.7449\n",
      "[804/1762] D loss: 1.3491, G loss: 0.8225\n",
      "[884/1762] D loss: 1.2568, G loss: 0.9024\n",
      "[964/1762] D loss: 1.3615, G loss: 0.6888\n",
      "[1044/1762] D loss: 1.4365, G loss: 0.7513\n",
      "[1124/1762] D loss: 1.3991, G loss: 0.5294\n",
      "[1204/1762] D loss: 1.1352, G loss: 0.6609\n",
      "[1284/1762] D loss: 1.4206, G loss: 0.6534\n",
      "[1364/1762] D loss: 1.4220, G loss: 0.9569\n",
      "[1444/1762] D loss: 1.3025, G loss: 1.0432\n",
      "[1524/1762] D loss: 1.2671, G loss: 0.8212\n",
      "[1604/1762] D loss: 1.4385, G loss: 0.6773\n",
      "[1684/1762] D loss: 1.3657, G loss: 0.8974\n",
      "[1762/1762] D loss: 1.3797, G loss: 0.6635\n",
      "train error: \n",
      " D loss: 1.347017, G loss: 0.897207, D accuracy: 56.2%, cell accuracy: 99.4%, board accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344724, G loss: 0.897645, D accuracy: 56.1%, cell accuracy: 99.4%, board accuracy: 49.3% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3813, G loss: 0.7159\n",
      "[84/1762] D loss: 1.2256, G loss: 0.6962\n",
      "[164/1762] D loss: 1.4256, G loss: 0.6647\n",
      "[244/1762] D loss: 1.3813, G loss: 0.7175\n",
      "[324/1762] D loss: 1.3377, G loss: 0.9190\n",
      "[404/1762] D loss: 1.4116, G loss: 0.6499\n",
      "[484/1762] D loss: 1.2507, G loss: 0.6553\n",
      "[564/1762] D loss: 1.2257, G loss: 0.7828\n",
      "[644/1762] D loss: 1.3814, G loss: 0.6190\n",
      "[724/1762] D loss: 1.4562, G loss: 0.7631\n",
      "[804/1762] D loss: 1.3607, G loss: 0.6907\n",
      "[884/1762] D loss: 1.1324, G loss: 0.8004\n",
      "[964/1762] D loss: 1.3345, G loss: 0.6719\n",
      "[1044/1762] D loss: 1.4167, G loss: 0.6215\n",
      "[1124/1762] D loss: 1.4670, G loss: 0.5740\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7785\n",
      "[1284/1762] D loss: 1.2703, G loss: 0.8355\n",
      "[1364/1762] D loss: 1.3171, G loss: 0.7027\n",
      "[1444/1762] D loss: 1.3153, G loss: 0.6985\n",
      "[1524/1762] D loss: 1.1954, G loss: 0.9064\n",
      "[1604/1762] D loss: 1.1777, G loss: 0.9262\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.6978\n",
      "[1762/1762] D loss: 1.0834, G loss: 1.1985\n",
      "train error: \n",
      " D loss: 1.394698, G loss: 1.041127, D accuracy: 52.4%, cell accuracy: 99.4%, board accuracy: 53.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390835, G loss: 1.054427, D accuracy: 52.2%, cell accuracy: 99.3%, board accuracy: 51.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4103, G loss: 0.8709\n",
      "[84/1762] D loss: 1.3808, G loss: 0.7339\n",
      "[164/1762] D loss: 1.4768, G loss: 0.6683\n",
      "[244/1762] D loss: 1.3129, G loss: 0.7664\n",
      "[324/1762] D loss: 1.3957, G loss: 0.7421\n",
      "[404/1762] D loss: 1.4735, G loss: 0.7866\n",
      "[484/1762] D loss: 1.4119, G loss: 0.7212\n",
      "[564/1762] D loss: 1.3996, G loss: 0.6048\n",
      "[644/1762] D loss: 1.2390, G loss: 0.9229\n",
      "[724/1762] D loss: 1.1669, G loss: 0.8394\n",
      "[804/1762] D loss: 1.2967, G loss: 0.6903\n",
      "[884/1762] D loss: 1.3943, G loss: 0.7974\n",
      "[964/1762] D loss: 1.2101, G loss: 0.6899\n",
      "[1044/1762] D loss: 1.3744, G loss: 0.8596\n",
      "[1124/1762] D loss: 1.3557, G loss: 0.8063\n",
      "[1204/1762] D loss: 1.2929, G loss: 0.7888\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.5902\n",
      "[1364/1762] D loss: 1.4624, G loss: 0.5427\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.7224\n",
      "[1524/1762] D loss: 1.2494, G loss: 0.9952\n",
      "[1604/1762] D loss: 1.3269, G loss: 0.6717\n",
      "[1684/1762] D loss: 1.2546, G loss: 0.7182\n",
      "[1762/1762] D loss: 1.1548, G loss: 0.7837\n",
      "train error: \n",
      " D loss: 1.342078, G loss: 0.669631, D accuracy: 58.0%, cell accuracy: 99.4%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335062, G loss: 0.676792, D accuracy: 58.9%, cell accuracy: 99.3%, board accuracy: 52.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2932, G loss: 0.7363\n",
      "[84/1762] D loss: 1.2703, G loss: 0.7686\n",
      "[164/1762] D loss: 1.2232, G loss: 1.0053\n",
      "[244/1762] D loss: 1.4209, G loss: 0.9396\n",
      "[324/1762] D loss: 1.3346, G loss: 0.6707\n",
      "[404/1762] D loss: 1.3203, G loss: 0.8314\n",
      "[484/1762] D loss: 1.4043, G loss: 1.0679\n",
      "[564/1762] D loss: 1.2742, G loss: 0.7327\n",
      "[644/1762] D loss: 1.1762, G loss: 0.7934\n",
      "[724/1762] D loss: 1.1968, G loss: 0.7578\n",
      "[804/1762] D loss: 1.3378, G loss: 0.7707\n",
      "[884/1762] D loss: 1.2181, G loss: 0.9366\n",
      "[964/1762] D loss: 1.3953, G loss: 0.7451\n",
      "[1044/1762] D loss: 1.3987, G loss: 0.7786\n",
      "[1124/1762] D loss: 1.4017, G loss: 0.7107\n",
      "[1204/1762] D loss: 1.3531, G loss: 0.5429\n",
      "[1284/1762] D loss: 1.2101, G loss: 0.8106\n",
      "[1364/1762] D loss: 1.3134, G loss: 0.6045\n",
      "[1444/1762] D loss: 1.4015, G loss: 1.1155\n",
      "[1524/1762] D loss: 1.3374, G loss: 0.6288\n",
      "[1604/1762] D loss: 1.2513, G loss: 0.8009\n",
      "[1684/1762] D loss: 1.3635, G loss: 0.7919\n",
      "[1762/1762] D loss: 1.5389, G loss: 0.5469\n",
      "train error: \n",
      " D loss: 1.322437, G loss: 0.791634, D accuracy: 57.9%, cell accuracy: 99.4%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316609, G loss: 0.799033, D accuracy: 59.4%, cell accuracy: 99.4%, board accuracy: 54.3% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4206, G loss: 0.7810\n",
      "[84/1762] D loss: 1.4011, G loss: 0.6473\n",
      "[164/1762] D loss: 1.4782, G loss: 0.5260\n",
      "[244/1762] D loss: 1.3912, G loss: 0.8489\n",
      "[324/1762] D loss: 1.3973, G loss: 0.5911\n",
      "[404/1762] D loss: 1.2136, G loss: 0.9220\n",
      "[484/1762] D loss: 1.2880, G loss: 0.7912\n",
      "[564/1762] D loss: 1.0706, G loss: 1.1050\n",
      "[644/1762] D loss: 1.2597, G loss: 0.7711\n",
      "[724/1762] D loss: 1.3355, G loss: 0.7770\n",
      "[804/1762] D loss: 1.4792, G loss: 0.6396\n",
      "[884/1762] D loss: 1.2799, G loss: 0.7004\n",
      "[964/1762] D loss: 1.2352, G loss: 0.8628\n",
      "[1044/1762] D loss: 1.0121, G loss: 0.9719\n",
      "[1124/1762] D loss: 1.4252, G loss: 0.6732\n",
      "[1204/1762] D loss: 1.3683, G loss: 0.7723\n",
      "[1284/1762] D loss: 1.3128, G loss: 0.9064\n",
      "[1364/1762] D loss: 1.3791, G loss: 0.5986\n",
      "[1444/1762] D loss: 1.2357, G loss: 0.7977\n",
      "[1524/1762] D loss: 1.3979, G loss: 0.7295\n",
      "[1604/1762] D loss: 1.3840, G loss: 0.7796\n",
      "[1684/1762] D loss: 1.3576, G loss: 0.6501\n",
      "[1762/1762] D loss: 1.0950, G loss: 0.8398\n",
      "train error: \n",
      " D loss: 1.428734, G loss: 0.503646, D accuracy: 52.8%, cell accuracy: 99.5%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.418032, G loss: 0.510508, D accuracy: 53.0%, cell accuracy: 99.5%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4174, G loss: 0.6203\n",
      "[84/1762] D loss: 1.3931, G loss: 0.5257\n",
      "[164/1762] D loss: 1.3516, G loss: 0.6406\n",
      "[244/1762] D loss: 1.4881, G loss: 0.5204\n",
      "[324/1762] D loss: 1.4224, G loss: 0.6184\n",
      "[404/1762] D loss: 1.3720, G loss: 0.6416\n",
      "[484/1762] D loss: 1.3985, G loss: 0.5185\n",
      "[564/1762] D loss: 1.4257, G loss: 0.9357\n",
      "[644/1762] D loss: 1.4312, G loss: 1.0284\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6953\n",
      "[804/1762] D loss: 1.4311, G loss: 0.7749\n",
      "[884/1762] D loss: 1.3170, G loss: 0.6236\n",
      "[964/1762] D loss: 1.3305, G loss: 0.5934\n",
      "[1044/1762] D loss: 1.4249, G loss: 0.8933\n",
      "[1124/1762] D loss: 1.3657, G loss: 0.9079\n",
      "[1204/1762] D loss: 1.3743, G loss: 0.6099\n",
      "[1284/1762] D loss: 1.2170, G loss: 0.8356\n",
      "[1364/1762] D loss: 1.3964, G loss: 0.7607\n",
      "[1444/1762] D loss: 1.4166, G loss: 0.9144\n",
      "[1524/1762] D loss: 1.3683, G loss: 0.7422\n",
      "[1604/1762] D loss: 1.4055, G loss: 0.6705\n",
      "[1684/1762] D loss: 1.3843, G loss: 0.7500\n",
      "[1762/1762] D loss: 1.4343, G loss: 0.7401\n",
      "train error: \n",
      " D loss: 1.360317, G loss: 0.790842, D accuracy: 55.0%, cell accuracy: 99.5%, board accuracy: 62.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352341, G loss: 0.799952, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 59.3% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3804, G loss: 0.6226\n",
      "[84/1762] D loss: 1.4008, G loss: 0.7130\n",
      "[164/1762] D loss: 1.3940, G loss: 0.7825\n",
      "[244/1762] D loss: 1.2744, G loss: 0.6208\n",
      "[324/1762] D loss: 1.4158, G loss: 0.5061\n",
      "[404/1762] D loss: 1.4480, G loss: 0.6006\n",
      "[484/1762] D loss: 1.2556, G loss: 0.9234\n",
      "[564/1762] D loss: 1.4266, G loss: 0.8167\n",
      "[644/1762] D loss: 1.4080, G loss: 0.7259\n",
      "[724/1762] D loss: 1.4243, G loss: 0.7794\n",
      "[804/1762] D loss: 1.3461, G loss: 0.9081\n",
      "[884/1762] D loss: 1.3637, G loss: 0.5792\n",
      "[964/1762] D loss: 1.3748, G loss: 0.7420\n",
      "[1044/1762] D loss: 1.4492, G loss: 0.5693\n",
      "[1124/1762] D loss: 1.3949, G loss: 0.7284\n",
      "[1204/1762] D loss: 1.4055, G loss: 0.7581\n",
      "[1284/1762] D loss: 1.3476, G loss: 0.7735\n",
      "[1364/1762] D loss: 1.4143, G loss: 0.5801\n",
      "[1444/1762] D loss: 1.3149, G loss: 0.7562\n",
      "[1524/1762] D loss: 1.4805, G loss: 0.5245\n",
      "[1604/1762] D loss: 1.4013, G loss: 0.6219\n",
      "[1684/1762] D loss: 1.3983, G loss: 0.7702\n",
      "[1762/1762] D loss: 1.2042, G loss: 0.7923\n",
      "train error: \n",
      " D loss: 1.366755, G loss: 0.618997, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363002, G loss: 0.621855, D accuracy: 56.1%, cell accuracy: 99.5%, board accuracy: 64.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3040, G loss: 0.6657\n",
      "[84/1762] D loss: 1.1502, G loss: 0.8132\n",
      "[164/1762] D loss: 1.3973, G loss: 0.6857\n",
      "[244/1762] D loss: 1.2121, G loss: 0.8182\n",
      "[324/1762] D loss: 1.3943, G loss: 0.7456\n",
      "[404/1762] D loss: 1.3151, G loss: 0.8398\n",
      "[484/1762] D loss: 1.2892, G loss: 0.6639\n",
      "[564/1762] D loss: 1.3678, G loss: 0.8299\n",
      "[644/1762] D loss: 1.3745, G loss: 0.8923\n",
      "[724/1762] D loss: 1.3980, G loss: 0.7562\n",
      "[804/1762] D loss: 1.3684, G loss: 0.7748\n",
      "[884/1762] D loss: 1.4192, G loss: 0.7738\n",
      "[964/1762] D loss: 1.4282, G loss: 0.5848\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.8631\n",
      "[1124/1762] D loss: 1.2423, G loss: 0.8769\n",
      "[1204/1762] D loss: 1.2146, G loss: 0.8705\n",
      "[1284/1762] D loss: 1.4049, G loss: 0.6737\n",
      "[1364/1762] D loss: 1.3482, G loss: 0.6871\n",
      "[1444/1762] D loss: 1.2407, G loss: 0.8546\n",
      "[1524/1762] D loss: 1.4295, G loss: 0.6143\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6394\n",
      "[1684/1762] D loss: 1.2316, G loss: 1.0446\n",
      "[1762/1762] D loss: 1.2456, G loss: 0.8393\n",
      "train error: \n",
      " D loss: 1.368411, G loss: 0.756177, D accuracy: 53.3%, cell accuracy: 99.6%, board accuracy: 65.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371291, G loss: 0.753975, D accuracy: 52.2%, cell accuracy: 99.5%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2754, G loss: 0.7983\n",
      "[84/1762] D loss: 1.4435, G loss: 0.5233\n",
      "[164/1762] D loss: 1.3906, G loss: 0.7333\n",
      "[244/1762] D loss: 1.3898, G loss: 0.8484\n",
      "[324/1762] D loss: 1.4415, G loss: 0.8089\n",
      "[404/1762] D loss: 1.3303, G loss: 0.8135\n",
      "[484/1762] D loss: 1.3837, G loss: 0.7070\n",
      "[564/1762] D loss: 1.4403, G loss: 0.7019\n",
      "[644/1762] D loss: 1.3768, G loss: 0.7201\n",
      "[724/1762] D loss: 1.3701, G loss: 0.7267\n",
      "[804/1762] D loss: 1.3600, G loss: 0.7624\n",
      "[884/1762] D loss: 1.3828, G loss: 0.7048\n",
      "[964/1762] D loss: 1.3880, G loss: 0.7302\n",
      "[1044/1762] D loss: 1.2579, G loss: 0.9133\n",
      "[1124/1762] D loss: 1.4357, G loss: 0.5904\n",
      "[1204/1762] D loss: 1.4271, G loss: 0.5481\n",
      "[1284/1762] D loss: 1.2440, G loss: 0.8615\n",
      "[1364/1762] D loss: 1.2519, G loss: 0.9592\n",
      "[1444/1762] D loss: 1.4154, G loss: 0.7380\n",
      "[1524/1762] D loss: 1.4350, G loss: 0.6941\n",
      "[1604/1762] D loss: 1.1970, G loss: 0.7988\n",
      "[1684/1762] D loss: 1.3746, G loss: 0.5888\n",
      "[1762/1762] D loss: 1.4029, G loss: 0.6833\n",
      "train error: \n",
      " D loss: 1.362716, G loss: 0.780918, D accuracy: 53.0%, cell accuracy: 99.6%, board accuracy: 60.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356680, G loss: 0.785420, D accuracy: 54.7%, cell accuracy: 99.5%, board accuracy: 56.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3992, G loss: 0.9197\n",
      "[84/1762] D loss: 1.4271, G loss: 0.7842\n",
      "[164/1762] D loss: 1.4051, G loss: 0.7600\n",
      "[244/1762] D loss: 1.1795, G loss: 1.0635\n",
      "[324/1762] D loss: 1.4123, G loss: 0.7390\n",
      "[404/1762] D loss: 1.4178, G loss: 0.6168\n",
      "[484/1762] D loss: 1.3425, G loss: 0.7732\n",
      "[564/1762] D loss: 1.3643, G loss: 0.7484\n",
      "[644/1762] D loss: 1.2796, G loss: 0.6878\n",
      "[724/1762] D loss: 1.3269, G loss: 0.7152\n",
      "[804/1762] D loss: 1.4359, G loss: 0.6872\n",
      "[884/1762] D loss: 1.3749, G loss: 0.6982\n",
      "[964/1762] D loss: 1.3402, G loss: 0.7841\n",
      "[1044/1762] D loss: 1.3671, G loss: 0.7009\n",
      "[1124/1762] D loss: 1.2992, G loss: 0.7155\n",
      "[1204/1762] D loss: 1.3931, G loss: 0.7297\n",
      "[1284/1762] D loss: 1.3458, G loss: 0.6453\n",
      "[1364/1762] D loss: 1.3041, G loss: 0.9081\n",
      "[1444/1762] D loss: 1.3806, G loss: 0.6800\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.7220\n",
      "[1604/1762] D loss: 1.2911, G loss: 0.7852\n",
      "[1684/1762] D loss: 1.4099, G loss: 0.7053\n",
      "[1762/1762] D loss: 1.4978, G loss: 0.8826\n",
      "train error: \n",
      " D loss: 1.357485, G loss: 0.830938, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 69.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354504, G loss: 0.828420, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 63.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4027, G loss: 0.6347\n",
      "[84/1762] D loss: 1.2885, G loss: 0.6938\n",
      "[164/1762] D loss: 1.3117, G loss: 0.8902\n",
      "[244/1762] D loss: 1.4666, G loss: 0.8216\n",
      "[324/1762] D loss: 1.2150, G loss: 0.7606\n",
      "[404/1762] D loss: 1.3752, G loss: 0.8881\n",
      "[484/1762] D loss: 1.2981, G loss: 0.6422\n",
      "[564/1762] D loss: 1.3955, G loss: 0.6916\n",
      "[644/1762] D loss: 1.3923, G loss: 0.7620\n",
      "[724/1762] D loss: 1.4113, G loss: 0.7474\n",
      "[804/1762] D loss: 1.2469, G loss: 0.9270\n",
      "[884/1762] D loss: 1.4071, G loss: 0.7924\n",
      "[964/1762] D loss: 1.3924, G loss: 0.6734\n",
      "[1044/1762] D loss: 1.3559, G loss: 0.5216\n",
      "[1124/1762] D loss: 1.3939, G loss: 0.5627\n",
      "[1204/1762] D loss: 1.3178, G loss: 0.7163\n",
      "[1284/1762] D loss: 1.2816, G loss: 0.7925\n",
      "[1364/1762] D loss: 1.4784, G loss: 0.6020\n",
      "[1444/1762] D loss: 1.3828, G loss: 0.6636\n",
      "[1524/1762] D loss: 1.2303, G loss: 0.7474\n",
      "[1604/1762] D loss: 1.3968, G loss: 0.8364\n",
      "[1684/1762] D loss: 1.3855, G loss: 0.6842\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.6782\n",
      "train error: \n",
      " D loss: 1.353812, G loss: 0.657550, D accuracy: 56.2%, cell accuracy: 99.6%, board accuracy: 67.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344322, G loss: 0.666146, D accuracy: 57.3%, cell accuracy: 99.6%, board accuracy: 59.8% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.5367\n",
      "[84/1762] D loss: 1.4244, G loss: 0.8321\n",
      "[164/1762] D loss: 1.2698, G loss: 0.6282\n",
      "[244/1762] D loss: 1.3826, G loss: 0.8503\n",
      "[324/1762] D loss: 1.3749, G loss: 0.6324\n",
      "[404/1762] D loss: 1.2981, G loss: 0.6768\n",
      "[484/1762] D loss: 1.3689, G loss: 0.9153\n",
      "[564/1762] D loss: 1.3441, G loss: 0.7037\n",
      "[644/1762] D loss: 1.4092, G loss: 0.6230\n",
      "[724/1762] D loss: 1.3161, G loss: 0.9397\n",
      "[804/1762] D loss: 1.3747, G loss: 0.6658\n",
      "[884/1762] D loss: 1.5081, G loss: 1.0797\n",
      "[964/1762] D loss: 1.3677, G loss: 0.5564\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.5924\n",
      "[1124/1762] D loss: 1.2027, G loss: 0.9437\n",
      "[1204/1762] D loss: 1.2861, G loss: 0.7558\n",
      "[1284/1762] D loss: 1.2563, G loss: 0.8656\n",
      "[1364/1762] D loss: 1.4243, G loss: 0.6683\n",
      "[1444/1762] D loss: 1.4100, G loss: 0.5116\n",
      "[1524/1762] D loss: 1.3438, G loss: 0.7573\n",
      "[1604/1762] D loss: 1.2003, G loss: 0.8996\n",
      "[1684/1762] D loss: 1.4430, G loss: 0.5178\n",
      "[1762/1762] D loss: 1.1393, G loss: 0.8824\n",
      "train error: \n",
      " D loss: 1.363777, G loss: 0.892897, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 73.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358208, G loss: 0.893624, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2199, G loss: 1.0199\n",
      "[84/1762] D loss: 1.3932, G loss: 0.6648\n",
      "[164/1762] D loss: 1.3998, G loss: 0.5237\n",
      "[244/1762] D loss: 1.2945, G loss: 0.6295\n",
      "[324/1762] D loss: 1.3044, G loss: 0.8125\n",
      "[404/1762] D loss: 1.3942, G loss: 0.9612\n",
      "[484/1762] D loss: 1.3103, G loss: 0.8078\n",
      "[564/1762] D loss: 1.3384, G loss: 0.7542\n",
      "[644/1762] D loss: 1.3875, G loss: 0.7076\n",
      "[724/1762] D loss: 1.3599, G loss: 0.9948\n",
      "[804/1762] D loss: 1.3759, G loss: 0.7495\n",
      "[884/1762] D loss: 1.3729, G loss: 0.9762\n",
      "[964/1762] D loss: 1.3748, G loss: 0.7585\n",
      "[1044/1762] D loss: 1.2424, G loss: 0.9742\n",
      "[1124/1762] D loss: 1.3671, G loss: 0.5210\n",
      "[1204/1762] D loss: 1.2321, G loss: 0.8256\n",
      "[1284/1762] D loss: 1.2920, G loss: 0.6892\n",
      "[1364/1762] D loss: 1.2404, G loss: 0.6316\n",
      "[1444/1762] D loss: 1.3948, G loss: 0.7562\n",
      "[1524/1762] D loss: 1.4388, G loss: 0.7684\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6460\n",
      "[1684/1762] D loss: 1.3736, G loss: 0.7600\n",
      "[1762/1762] D loss: 1.4074, G loss: 0.7862\n",
      "train error: \n",
      " D loss: 1.346651, G loss: 0.664385, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 73.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344537, G loss: 0.662649, D accuracy: 57.8%, cell accuracy: 99.6%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4332, G loss: 0.5749\n",
      "[84/1762] D loss: 1.3884, G loss: 0.6586\n",
      "[164/1762] D loss: 1.1967, G loss: 0.9480\n",
      "[244/1762] D loss: 1.2802, G loss: 0.8770\n",
      "[324/1762] D loss: 1.2964, G loss: 0.7156\n",
      "[404/1762] D loss: 1.3974, G loss: 0.5926\n",
      "[484/1762] D loss: 1.3447, G loss: 0.9466\n",
      "[564/1762] D loss: 1.3286, G loss: 0.5777\n",
      "[644/1762] D loss: 1.4825, G loss: 0.5100\n",
      "[724/1762] D loss: 1.3920, G loss: 0.6655\n",
      "[804/1762] D loss: 1.4612, G loss: 0.6685\n",
      "[884/1762] D loss: 1.1745, G loss: 0.9000\n",
      "[964/1762] D loss: 1.3966, G loss: 0.8984\n",
      "[1044/1762] D loss: 1.4145, G loss: 0.7336\n",
      "[1124/1762] D loss: 1.4337, G loss: 0.7689\n",
      "[1204/1762] D loss: 1.1986, G loss: 1.0039\n",
      "[1284/1762] D loss: 1.2665, G loss: 0.9246\n",
      "[1364/1762] D loss: 1.3983, G loss: 1.0453\n",
      "[1444/1762] D loss: 1.2813, G loss: 0.7123\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.6383\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.7131\n",
      "[1684/1762] D loss: 1.2767, G loss: 0.8470\n",
      "[1762/1762] D loss: 1.4615, G loss: 0.7610\n",
      "train error: \n",
      " D loss: 1.368216, G loss: 0.603509, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360162, G loss: 0.608687, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2444, G loss: 0.7004\n",
      "[84/1762] D loss: 1.2315, G loss: 0.8709\n",
      "[164/1762] D loss: 1.3841, G loss: 0.7062\n",
      "[244/1762] D loss: 1.3098, G loss: 0.6719\n",
      "[324/1762] D loss: 1.3988, G loss: 0.6731\n",
      "[404/1762] D loss: 1.2381, G loss: 0.8090\n",
      "[484/1762] D loss: 1.3162, G loss: 0.7026\n",
      "[564/1762] D loss: 1.3105, G loss: 0.7710\n",
      "[644/1762] D loss: 1.3988, G loss: 0.6619\n",
      "[724/1762] D loss: 1.3854, G loss: 0.6516\n",
      "[804/1762] D loss: 1.3954, G loss: 0.5760\n",
      "[884/1762] D loss: 1.4002, G loss: 0.7241\n",
      "[964/1762] D loss: 1.3884, G loss: 0.7919\n",
      "[1044/1762] D loss: 1.4016, G loss: 0.7857\n",
      "[1124/1762] D loss: 1.3855, G loss: 0.6941\n",
      "[1204/1762] D loss: 1.3243, G loss: 0.6513\n",
      "[1284/1762] D loss: 1.2973, G loss: 0.8232\n",
      "[1364/1762] D loss: 1.1075, G loss: 0.8467\n",
      "[1444/1762] D loss: 1.4195, G loss: 0.6714\n",
      "[1524/1762] D loss: 1.3641, G loss: 0.8645\n",
      "[1604/1762] D loss: 1.3973, G loss: 0.6536\n",
      "[1684/1762] D loss: 1.2542, G loss: 0.7799\n",
      "[1762/1762] D loss: 1.5356, G loss: 1.0381\n",
      "train error: \n",
      " D loss: 1.444924, G loss: 1.128926, D accuracy: 52.1%, cell accuracy: 99.7%, board accuracy: 79.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.435482, G loss: 1.137956, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3001, G loss: 0.9324\n",
      "[84/1762] D loss: 1.3932, G loss: 0.5233\n",
      "[164/1762] D loss: 1.4306, G loss: 0.5106\n",
      "[244/1762] D loss: 1.0593, G loss: 0.7949\n",
      "[324/1762] D loss: 1.4472, G loss: 0.5343\n",
      "[404/1762] D loss: 1.2475, G loss: 0.7307\n",
      "[484/1762] D loss: 1.4332, G loss: 0.6346\n",
      "[564/1762] D loss: 1.3977, G loss: 0.6290\n",
      "[644/1762] D loss: 1.2199, G loss: 0.7638\n",
      "[724/1762] D loss: 1.3971, G loss: 0.6594\n",
      "[804/1762] D loss: 1.4380, G loss: 0.4567\n",
      "[884/1762] D loss: 1.4295, G loss: 0.5413\n",
      "[964/1762] D loss: 1.3864, G loss: 0.5139\n",
      "[1044/1762] D loss: 1.4095, G loss: 0.6639\n",
      "[1124/1762] D loss: 1.4071, G loss: 0.6695\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.7626\n",
      "[1284/1762] D loss: 1.3991, G loss: 0.6856\n",
      "[1364/1762] D loss: 1.3021, G loss: 0.7502\n",
      "[1444/1762] D loss: 1.4081, G loss: 0.8671\n",
      "[1524/1762] D loss: 1.4309, G loss: 0.9072\n",
      "[1604/1762] D loss: 1.4381, G loss: 0.8319\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6821\n",
      "[1762/1762] D loss: 1.3974, G loss: 0.7424\n",
      "train error: \n",
      " D loss: 1.339621, G loss: 0.766002, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 79.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331394, G loss: 0.774566, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4224, G loss: 0.6490\n",
      "[84/1762] D loss: 1.4217, G loss: 0.6881\n",
      "[164/1762] D loss: 1.4091, G loss: 0.8248\n",
      "[244/1762] D loss: 1.3997, G loss: 0.7143\n",
      "[324/1762] D loss: 1.3195, G loss: 0.9709\n",
      "[404/1762] D loss: 1.3815, G loss: 0.9240\n",
      "[484/1762] D loss: 1.2906, G loss: 0.7967\n",
      "[564/1762] D loss: 1.3939, G loss: 0.6221\n",
      "[644/1762] D loss: 1.3857, G loss: 0.6799\n",
      "[724/1762] D loss: 1.4159, G loss: 0.8750\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7489\n",
      "[884/1762] D loss: 1.3860, G loss: 0.7680\n",
      "[964/1762] D loss: 1.4166, G loss: 0.5135\n",
      "[1044/1762] D loss: 1.4127, G loss: 0.6479\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.6805\n",
      "[1204/1762] D loss: 1.4379, G loss: 0.7127\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.7133\n",
      "[1364/1762] D loss: 1.2887, G loss: 0.8927\n",
      "[1444/1762] D loss: 1.4159, G loss: 0.6242\n",
      "[1524/1762] D loss: 1.2919, G loss: 0.7217\n",
      "[1604/1762] D loss: 1.3465, G loss: 0.7071\n",
      "[1684/1762] D loss: 1.4247, G loss: 0.5018\n",
      "[1762/1762] D loss: 1.4124, G loss: 0.6025\n",
      "train error: \n",
      " D loss: 1.343585, G loss: 0.733769, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 79.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332688, G loss: 0.746102, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3841, G loss: 0.7794\n",
      "[84/1762] D loss: 1.4261, G loss: 0.9345\n",
      "[164/1762] D loss: 1.2422, G loss: 0.9153\n",
      "[244/1762] D loss: 1.3661, G loss: 0.9920\n",
      "[324/1762] D loss: 1.3874, G loss: 0.6938\n",
      "[404/1762] D loss: 1.3446, G loss: 0.7202\n",
      "[484/1762] D loss: 1.4406, G loss: 0.5413\n",
      "[564/1762] D loss: 1.2502, G loss: 0.6665\n",
      "[644/1762] D loss: 1.3715, G loss: 0.6183\n",
      "[724/1762] D loss: 1.3983, G loss: 0.8187\n",
      "[804/1762] D loss: 1.4178, G loss: 0.7546\n",
      "[884/1762] D loss: 1.3955, G loss: 0.8335\n",
      "[964/1762] D loss: 1.2576, G loss: 0.9216\n",
      "[1044/1762] D loss: 1.3846, G loss: 0.6771\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7608\n",
      "[1204/1762] D loss: 1.4094, G loss: 0.7434\n",
      "[1284/1762] D loss: 1.4646, G loss: 0.7283\n",
      "[1364/1762] D loss: 1.3047, G loss: 0.8347\n",
      "[1444/1762] D loss: 1.3972, G loss: 0.7040\n",
      "[1524/1762] D loss: 1.4078, G loss: 0.6794\n",
      "[1604/1762] D loss: 1.4205, G loss: 0.7322\n",
      "[1684/1762] D loss: 1.4188, G loss: 0.7388\n",
      "[1762/1762] D loss: 1.3606, G loss: 0.6548\n",
      "train error: \n",
      " D loss: 1.348181, G loss: 0.741468, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336158, G loss: 0.750582, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4021, G loss: 0.7393\n",
      "[84/1762] D loss: 1.0950, G loss: 0.9483\n",
      "[164/1762] D loss: 1.3217, G loss: 0.5993\n",
      "[244/1762] D loss: 1.3385, G loss: 0.6848\n",
      "[324/1762] D loss: 1.3939, G loss: 0.8642\n",
      "[404/1762] D loss: 1.3853, G loss: 0.7192\n",
      "[484/1762] D loss: 1.0609, G loss: 1.0304\n",
      "[564/1762] D loss: 1.2355, G loss: 0.9206\n",
      "[644/1762] D loss: 1.2181, G loss: 0.9170\n",
      "[724/1762] D loss: 1.2428, G loss: 0.7594\n",
      "[804/1762] D loss: 1.4079, G loss: 0.6323\n",
      "[884/1762] D loss: 1.4001, G loss: 0.6374\n",
      "[964/1762] D loss: 1.3888, G loss: 0.6828\n",
      "[1044/1762] D loss: 1.4131, G loss: 0.5979\n",
      "[1124/1762] D loss: 1.3569, G loss: 0.8504\n",
      "[1204/1762] D loss: 1.2900, G loss: 0.7479\n",
      "[1284/1762] D loss: 1.3538, G loss: 0.7886\n",
      "[1364/1762] D loss: 1.4293, G loss: 0.5786\n",
      "[1444/1762] D loss: 1.2804, G loss: 0.6487\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7699\n",
      "[1604/1762] D loss: 1.3893, G loss: 0.7478\n",
      "[1684/1762] D loss: 1.2737, G loss: 0.6988\n",
      "[1762/1762] D loss: 1.0684, G loss: 1.1862\n",
      "train error: \n",
      " D loss: 1.374223, G loss: 0.940193, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 77.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363545, G loss: 0.947903, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3078, G loss: 1.0734\n",
      "[84/1762] D loss: 1.3131, G loss: 0.8011\n",
      "[164/1762] D loss: 1.3577, G loss: 0.6842\n",
      "[244/1762] D loss: 1.1726, G loss: 0.8569\n",
      "[324/1762] D loss: 1.2580, G loss: 0.6739\n",
      "[404/1762] D loss: 1.3794, G loss: 0.9076\n",
      "[484/1762] D loss: 1.4139, G loss: 0.7316\n",
      "[564/1762] D loss: 1.3916, G loss: 0.7052\n",
      "[644/1762] D loss: 1.4524, G loss: 0.7810\n",
      "[724/1762] D loss: 1.3573, G loss: 0.8314\n",
      "[804/1762] D loss: 1.2428, G loss: 0.7486\n",
      "[884/1762] D loss: 1.3307, G loss: 0.8133\n",
      "[964/1762] D loss: 1.2275, G loss: 0.7539\n",
      "[1044/1762] D loss: 1.2450, G loss: 0.6752\n",
      "[1124/1762] D loss: 1.1994, G loss: 0.8991\n",
      "[1204/1762] D loss: 1.3251, G loss: 0.7818\n",
      "[1284/1762] D loss: 1.2136, G loss: 0.7713\n",
      "[1364/1762] D loss: 1.3981, G loss: 0.7896\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.7839\n",
      "[1524/1762] D loss: 1.2627, G loss: 0.7373\n",
      "[1604/1762] D loss: 1.3714, G loss: 0.7647\n",
      "[1684/1762] D loss: 1.2426, G loss: 0.7815\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.6955\n",
      "train error: \n",
      " D loss: 1.348482, G loss: 0.717106, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338035, G loss: 0.723290, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3496, G loss: 0.8151\n",
      "[84/1762] D loss: 1.4504, G loss: 0.8618\n",
      "[164/1762] D loss: 1.3927, G loss: 0.6728\n",
      "[244/1762] D loss: 1.2181, G loss: 0.7933\n",
      "[324/1762] D loss: 1.3999, G loss: 0.6574\n",
      "[404/1762] D loss: 1.3954, G loss: 0.6043\n",
      "[484/1762] D loss: 1.1226, G loss: 0.9179\n",
      "[564/1762] D loss: 1.2141, G loss: 0.8263\n",
      "[644/1762] D loss: 1.4033, G loss: 0.8224\n",
      "[724/1762] D loss: 1.3940, G loss: 0.7254\n",
      "[804/1762] D loss: 1.3922, G loss: 0.6646\n",
      "[884/1762] D loss: 1.3974, G loss: 0.7708\n",
      "[964/1762] D loss: 1.3558, G loss: 0.8698\n",
      "[1044/1762] D loss: 1.4171, G loss: 0.7152\n",
      "[1124/1762] D loss: 1.4343, G loss: 0.8157\n",
      "[1204/1762] D loss: 1.4465, G loss: 0.9360\n",
      "[1284/1762] D loss: 1.3316, G loss: 0.8705\n",
      "[1364/1762] D loss: 1.4332, G loss: 0.7771\n",
      "[1444/1762] D loss: 1.3667, G loss: 0.8119\n",
      "[1524/1762] D loss: 1.3647, G loss: 0.7166\n",
      "[1604/1762] D loss: 1.4268, G loss: 0.8388\n",
      "[1684/1762] D loss: 1.3826, G loss: 0.8385\n",
      "[1762/1762] D loss: 1.3934, G loss: 0.7344\n",
      "train error: \n",
      " D loss: 1.344792, G loss: 0.797158, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332273, G loss: 0.805154, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3998, G loss: 0.8720\n",
      "[84/1762] D loss: 1.1318, G loss: 1.1310\n",
      "[164/1762] D loss: 1.4914, G loss: 0.8317\n",
      "[244/1762] D loss: 1.3582, G loss: 0.8387\n",
      "[324/1762] D loss: 1.3757, G loss: 1.0345\n",
      "[404/1762] D loss: 1.3647, G loss: 0.7324\n",
      "[484/1762] D loss: 1.2320, G loss: 0.7603\n",
      "[564/1762] D loss: 1.2322, G loss: 0.6671\n",
      "[644/1762] D loss: 1.4097, G loss: 0.5410\n",
      "[724/1762] D loss: 1.4113, G loss: 0.5848\n",
      "[804/1762] D loss: 1.4276, G loss: 0.7924\n",
      "[884/1762] D loss: 1.2498, G loss: 0.8859\n",
      "[964/1762] D loss: 1.4023, G loss: 0.7105\n",
      "[1044/1762] D loss: 1.4081, G loss: 0.7107\n",
      "[1124/1762] D loss: 1.2046, G loss: 0.8076\n",
      "[1204/1762] D loss: 1.3935, G loss: 0.7429\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.6541\n",
      "[1364/1762] D loss: 1.3699, G loss: 0.7864\n",
      "[1444/1762] D loss: 1.4219, G loss: 0.7092\n",
      "[1524/1762] D loss: 1.4176, G loss: 0.6324\n",
      "[1604/1762] D loss: 1.4394, G loss: 0.6548\n",
      "[1684/1762] D loss: 1.2976, G loss: 0.8650\n",
      "[1762/1762] D loss: 1.3857, G loss: 0.7138\n",
      "train error: \n",
      " D loss: 1.351946, G loss: 0.647944, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 76.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342740, G loss: 0.652345, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.6560\n",
      "[84/1762] D loss: 1.3923, G loss: 0.7423\n",
      "[164/1762] D loss: 1.3798, G loss: 0.7216\n",
      "[244/1762] D loss: 1.2210, G loss: 1.1276\n",
      "[324/1762] D loss: 1.2097, G loss: 0.8592\n",
      "[404/1762] D loss: 1.4100, G loss: 0.7515\n",
      "[484/1762] D loss: 1.3935, G loss: 0.7460\n",
      "[564/1762] D loss: 1.4267, G loss: 0.6441\n",
      "[644/1762] D loss: 1.2135, G loss: 0.8709\n",
      "[724/1762] D loss: 1.4163, G loss: 0.8799\n",
      "[804/1762] D loss: 1.4200, G loss: 0.6517\n",
      "[884/1762] D loss: 1.1079, G loss: 0.9268\n",
      "[964/1762] D loss: 1.2735, G loss: 0.6668\n",
      "[1044/1762] D loss: 1.3896, G loss: 0.7657\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.6090\n",
      "[1204/1762] D loss: 1.4173, G loss: 0.5478\n",
      "[1284/1762] D loss: 1.1917, G loss: 0.7694\n",
      "[1364/1762] D loss: 1.2457, G loss: 0.7409\n",
      "[1444/1762] D loss: 1.3648, G loss: 0.8399\n",
      "[1524/1762] D loss: 1.3393, G loss: 0.7131\n",
      "[1604/1762] D loss: 1.4001, G loss: 0.6905\n",
      "[1684/1762] D loss: 1.4117, G loss: 0.7824\n",
      "[1762/1762] D loss: 1.4299, G loss: 0.7239\n",
      "train error: \n",
      " D loss: 1.354746, G loss: 0.636016, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 79.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344961, G loss: 0.642087, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.4939\n",
      "[84/1762] D loss: 1.3907, G loss: 0.6251\n",
      "[164/1762] D loss: 1.3921, G loss: 0.6417\n",
      "[244/1762] D loss: 1.4076, G loss: 0.7360\n",
      "[324/1762] D loss: 1.3904, G loss: 0.7182\n",
      "[404/1762] D loss: 1.4068, G loss: 0.5852\n",
      "[484/1762] D loss: 1.4049, G loss: 0.7205\n",
      "[564/1762] D loss: 1.3906, G loss: 0.6357\n",
      "[644/1762] D loss: 1.2245, G loss: 0.8466\n",
      "[724/1762] D loss: 1.2562, G loss: 0.7338\n",
      "[804/1762] D loss: 1.3999, G loss: 0.7192\n",
      "[884/1762] D loss: 1.2320, G loss: 0.7805\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6656\n",
      "[1044/1762] D loss: 1.1998, G loss: 0.8440\n",
      "[1124/1762] D loss: 1.4045, G loss: 0.7719\n",
      "[1204/1762] D loss: 1.4148, G loss: 0.6578\n",
      "[1284/1762] D loss: 1.3679, G loss: 0.6313\n",
      "[1364/1762] D loss: 1.4003, G loss: 0.6425\n",
      "[1444/1762] D loss: 1.2295, G loss: 0.7321\n",
      "[1524/1762] D loss: 1.1886, G loss: 0.8815\n",
      "[1604/1762] D loss: 1.3807, G loss: 0.7845\n",
      "[1684/1762] D loss: 1.4179, G loss: 0.8471\n",
      "[1762/1762] D loss: 0.9808, G loss: 1.0120\n",
      "train error: \n",
      " D loss: 1.348314, G loss: 0.830619, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334249, G loss: 0.843351, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3982, G loss: 0.7931\n",
      "[84/1762] D loss: 1.3820, G loss: 0.6189\n",
      "[164/1762] D loss: 1.3842, G loss: 0.6566\n",
      "[244/1762] D loss: 1.2366, G loss: 0.6091\n",
      "[324/1762] D loss: 1.3877, G loss: 0.6902\n",
      "[404/1762] D loss: 1.1780, G loss: 0.9346\n",
      "[484/1762] D loss: 1.4091, G loss: 0.6169\n",
      "[564/1762] D loss: 1.3899, G loss: 0.6365\n",
      "[644/1762] D loss: 1.3979, G loss: 0.6036\n",
      "[724/1762] D loss: 1.4379, G loss: 0.6389\n",
      "[804/1762] D loss: 1.4059, G loss: 0.6862\n",
      "[884/1762] D loss: 1.4060, G loss: 0.7808\n",
      "[964/1762] D loss: 1.3980, G loss: 0.7234\n",
      "[1044/1762] D loss: 1.4016, G loss: 0.6846\n",
      "[1124/1762] D loss: 1.3936, G loss: 0.7327\n",
      "[1204/1762] D loss: 1.3911, G loss: 0.6481\n",
      "[1284/1762] D loss: 1.1561, G loss: 0.8853\n",
      "[1364/1762] D loss: 1.3932, G loss: 0.6658\n",
      "[1444/1762] D loss: 1.4069, G loss: 0.6257\n",
      "[1524/1762] D loss: 1.3706, G loss: 0.7826\n",
      "[1604/1762] D loss: 1.1836, G loss: 0.8275\n",
      "[1684/1762] D loss: 1.1861, G loss: 0.7996\n",
      "[1762/1762] D loss: 1.3745, G loss: 0.6723\n",
      "train error: \n",
      " D loss: 1.339630, G loss: 0.650576, D accuracy: 56.3%, cell accuracy: 99.5%, board accuracy: 65.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324859, G loss: 0.662753, D accuracy: 57.5%, cell accuracy: 99.5%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2286, G loss: 0.6498\n",
      "[84/1762] D loss: 1.3632, G loss: 0.6867\n",
      "[164/1762] D loss: 1.3986, G loss: 0.6769\n",
      "[244/1762] D loss: 1.4121, G loss: 0.7518\n",
      "[324/1762] D loss: 1.3802, G loss: 0.6621\n",
      "[404/1762] D loss: 1.2097, G loss: 0.7381\n",
      "[484/1762] D loss: 1.1818, G loss: 0.8391\n",
      "[564/1762] D loss: 1.3928, G loss: 0.5229\n",
      "[644/1762] D loss: 1.3941, G loss: 0.6350\n",
      "[724/1762] D loss: 1.3920, G loss: 0.6143\n",
      "[804/1762] D loss: 1.3668, G loss: 0.6056\n",
      "[884/1762] D loss: 1.3850, G loss: 0.6170\n",
      "[964/1762] D loss: 0.9746, G loss: 1.0729\n",
      "[1044/1762] D loss: 1.4043, G loss: 0.6700\n",
      "[1124/1762] D loss: 1.3968, G loss: 0.8236\n",
      "[1204/1762] D loss: 1.4131, G loss: 0.7571\n",
      "[1284/1762] D loss: 1.2451, G loss: 0.7642\n",
      "[1364/1762] D loss: 1.4116, G loss: 0.8130\n",
      "[1444/1762] D loss: 1.3706, G loss: 0.7891\n",
      "[1524/1762] D loss: 1.2006, G loss: 0.8973\n",
      "[1604/1762] D loss: 1.3922, G loss: 0.8233\n",
      "[1684/1762] D loss: 1.4185, G loss: 0.5796\n",
      "[1762/1762] D loss: 1.3964, G loss: 0.7718\n",
      "train error: \n",
      " D loss: 1.350001, G loss: 0.656772, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332628, G loss: 0.669721, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4120, G loss: 0.5744\n",
      "[84/1762] D loss: 1.3926, G loss: 0.7865\n",
      "[164/1762] D loss: 1.3896, G loss: 0.7141\n",
      "[244/1762] D loss: 1.4035, G loss: 0.7413\n",
      "[324/1762] D loss: 1.2590, G loss: 0.7564\n",
      "[404/1762] D loss: 1.4027, G loss: 0.7731\n",
      "[484/1762] D loss: 1.3834, G loss: 0.7237\n",
      "[564/1762] D loss: 1.3920, G loss: 0.7506\n",
      "[644/1762] D loss: 1.3926, G loss: 0.6704\n",
      "[724/1762] D loss: 1.1556, G loss: 0.7709\n",
      "[804/1762] D loss: 1.4338, G loss: 0.4737\n",
      "[884/1762] D loss: 1.2200, G loss: 0.7191\n",
      "[964/1762] D loss: 1.4015, G loss: 0.6215\n",
      "[1044/1762] D loss: 1.3938, G loss: 0.7395\n",
      "[1124/1762] D loss: 1.4536, G loss: 0.6625\n",
      "[1204/1762] D loss: 1.2160, G loss: 0.7863\n",
      "[1284/1762] D loss: 1.4501, G loss: 1.0085\n",
      "[1364/1762] D loss: 1.4068, G loss: 0.7282\n",
      "[1444/1762] D loss: 1.2115, G loss: 0.6998\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.6846\n",
      "[1604/1762] D loss: 1.1952, G loss: 0.8234\n",
      "[1684/1762] D loss: 1.1963, G loss: 0.7584\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.5944\n",
      "train error: \n",
      " D loss: 1.364487, G loss: 0.606985, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346608, G loss: 0.618354, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4358, G loss: 0.5406\n",
      "[84/1762] D loss: 1.2151, G loss: 0.7481\n",
      "[164/1762] D loss: 1.3821, G loss: 0.7106\n",
      "[244/1762] D loss: 1.3848, G loss: 0.7266\n",
      "[324/1762] D loss: 1.4148, G loss: 0.7718\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6521\n",
      "[484/1762] D loss: 1.3888, G loss: 0.6482\n",
      "[564/1762] D loss: 1.2323, G loss: 0.6771\n",
      "[644/1762] D loss: 1.4395, G loss: 0.9290\n",
      "[724/1762] D loss: 1.4026, G loss: 0.8408\n",
      "[804/1762] D loss: 1.1713, G loss: 0.7937\n",
      "[884/1762] D loss: 1.4086, G loss: 0.5830\n",
      "[964/1762] D loss: 1.4208, G loss: 0.6283\n",
      "[1044/1762] D loss: 1.4181, G loss: 0.6381\n",
      "[1124/1762] D loss: 1.4245, G loss: 0.7173\n",
      "[1204/1762] D loss: 1.3975, G loss: 0.6561\n",
      "[1284/1762] D loss: 1.4025, G loss: 0.5393\n",
      "[1364/1762] D loss: 1.2237, G loss: 0.6840\n",
      "[1444/1762] D loss: 1.4287, G loss: 0.7900\n",
      "[1524/1762] D loss: 1.4056, G loss: 0.7664\n",
      "[1604/1762] D loss: 1.3267, G loss: 0.9670\n",
      "[1684/1762] D loss: 1.1963, G loss: 0.9296\n",
      "[1762/1762] D loss: 1.3940, G loss: 0.6092\n",
      "train error: \n",
      " D loss: 1.353622, G loss: 0.634327, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 76.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332644, G loss: 0.650470, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 72.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4254, G loss: 0.6259\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7295\n",
      "[164/1762] D loss: 1.2134, G loss: 0.7403\n",
      "[244/1762] D loss: 1.3383, G loss: 0.7660\n",
      "[324/1762] D loss: 1.3897, G loss: 0.6889\n",
      "[404/1762] D loss: 1.3801, G loss: 0.7809\n",
      "[484/1762] D loss: 1.3818, G loss: 0.6375\n",
      "[564/1762] D loss: 1.4266, G loss: 0.6247\n",
      "[644/1762] D loss: 1.4026, G loss: 0.7850\n",
      "[724/1762] D loss: 1.2030, G loss: 0.7438\n",
      "[804/1762] D loss: 1.2128, G loss: 0.7696\n",
      "[884/1762] D loss: 1.3503, G loss: 0.7446\n",
      "[964/1762] D loss: 1.6912, G loss: 0.4440\n",
      "[1044/1762] D loss: 1.2688, G loss: 0.8330\n",
      "[1124/1762] D loss: 1.3965, G loss: 0.8371\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.7442\n",
      "[1284/1762] D loss: 1.3666, G loss: 0.6664\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.6782\n",
      "[1444/1762] D loss: 1.3916, G loss: 0.6748\n",
      "[1524/1762] D loss: 1.3072, G loss: 0.7342\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6629\n",
      "[1684/1762] D loss: 1.4120, G loss: 0.5976\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6759\n",
      "train error: \n",
      " D loss: 1.354618, G loss: 0.720068, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344812, G loss: 0.723784, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.7345\n",
      "[84/1762] D loss: 1.3774, G loss: 0.6781\n",
      "[164/1762] D loss: 1.4010, G loss: 0.6471\n",
      "[244/1762] D loss: 1.3329, G loss: 0.6816\n",
      "[324/1762] D loss: 1.3974, G loss: 0.7696\n",
      "[404/1762] D loss: 1.3742, G loss: 0.6935\n",
      "[484/1762] D loss: 1.3897, G loss: 0.7258\n",
      "[564/1762] D loss: 1.3890, G loss: 0.7807\n",
      "[644/1762] D loss: 1.2461, G loss: 0.6772\n",
      "[724/1762] D loss: 1.3947, G loss: 0.7183\n",
      "[804/1762] D loss: 1.2172, G loss: 0.8412\n",
      "[884/1762] D loss: 1.3862, G loss: 0.7239\n",
      "[964/1762] D loss: 1.3224, G loss: 0.7557\n",
      "[1044/1762] D loss: 1.3727, G loss: 0.8075\n",
      "[1124/1762] D loss: 1.3913, G loss: 0.6390\n",
      "[1204/1762] D loss: 1.3818, G loss: 0.7022\n",
      "[1284/1762] D loss: 1.3727, G loss: 0.7185\n",
      "[1364/1762] D loss: 1.2143, G loss: 0.7817\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7133\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.7128\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.7841\n",
      "[1684/1762] D loss: 1.2426, G loss: 0.8513\n",
      "[1762/1762] D loss: 1.4012, G loss: 0.7443\n",
      "train error: \n",
      " D loss: 1.343711, G loss: 0.759557, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328266, G loss: 0.769443, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4136, G loss: 0.7237\n",
      "[84/1762] D loss: 1.3933, G loss: 0.6946\n",
      "[164/1762] D loss: 1.3976, G loss: 0.7708\n",
      "[244/1762] D loss: 1.4090, G loss: 0.7632\n",
      "[324/1762] D loss: 1.3794, G loss: 0.7132\n",
      "[404/1762] D loss: 1.3923, G loss: 0.6551\n",
      "[484/1762] D loss: 1.4623, G loss: 1.0241\n",
      "[564/1762] D loss: 1.4400, G loss: 0.5793\n",
      "[644/1762] D loss: 1.2770, G loss: 0.7875\n",
      "[724/1762] D loss: 1.0453, G loss: 1.0080\n",
      "[804/1762] D loss: 0.9599, G loss: 1.0759\n",
      "[884/1762] D loss: 1.4980, G loss: 0.8098\n",
      "[964/1762] D loss: 1.5167, G loss: 0.5811\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.7396\n",
      "[1124/1762] D loss: 1.4552, G loss: 0.7202\n",
      "[1204/1762] D loss: 1.4635, G loss: 0.6993\n",
      "[1284/1762] D loss: 1.4030, G loss: 0.6732\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6563\n",
      "[1444/1762] D loss: 1.4110, G loss: 0.5778\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.7570\n",
      "[1604/1762] D loss: 1.3993, G loss: 0.5756\n",
      "[1684/1762] D loss: 1.3975, G loss: 0.7406\n",
      "[1762/1762] D loss: 1.3927, G loss: 0.7664\n",
      "train error: \n",
      " D loss: 1.375759, G loss: 0.671906, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 79.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373844, G loss: 0.674625, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4293, G loss: 0.7205\n",
      "[84/1762] D loss: 1.3910, G loss: 0.6501\n",
      "[164/1762] D loss: 1.3961, G loss: 0.6732\n",
      "[244/1762] D loss: 1.4009, G loss: 0.6658\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6784\n",
      "[404/1762] D loss: 1.4160, G loss: 0.8175\n",
      "[484/1762] D loss: 1.3789, G loss: 0.6675\n",
      "[564/1762] D loss: 1.3917, G loss: 0.6723\n",
      "[644/1762] D loss: 1.3786, G loss: 0.7574\n",
      "[724/1762] D loss: 1.3601, G loss: 0.7319\n",
      "[804/1762] D loss: 1.2265, G loss: 0.8181\n",
      "[884/1762] D loss: 1.3902, G loss: 0.6586\n",
      "[964/1762] D loss: 1.2607, G loss: 0.8090\n",
      "[1044/1762] D loss: 1.3952, G loss: 0.7077\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.6815\n",
      "[1204/1762] D loss: 1.4069, G loss: 0.6653\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.7070\n",
      "[1364/1762] D loss: 1.2201, G loss: 0.8349\n",
      "[1444/1762] D loss: 1.3964, G loss: 0.6311\n",
      "[1524/1762] D loss: 1.3489, G loss: 0.8019\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7509\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.7026\n",
      "[1762/1762] D loss: 1.4364, G loss: 0.5694\n",
      "train error: \n",
      " D loss: 1.347954, G loss: 0.637408, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335559, G loss: 0.641991, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4004, G loss: 0.6732\n",
      "[84/1762] D loss: 1.3911, G loss: 0.6867\n",
      "[164/1762] D loss: 1.3717, G loss: 0.6588\n",
      "[244/1762] D loss: 1.3910, G loss: 0.7332\n",
      "[324/1762] D loss: 1.3790, G loss: 0.7374\n",
      "[404/1762] D loss: 1.3971, G loss: 0.8102\n",
      "[484/1762] D loss: 1.2036, G loss: 0.8603\n",
      "[564/1762] D loss: 1.3948, G loss: 0.6488\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6898\n",
      "[724/1762] D loss: 1.3823, G loss: 0.6456\n",
      "[804/1762] D loss: 1.1584, G loss: 0.8317\n",
      "[884/1762] D loss: 1.3845, G loss: 0.7866\n",
      "[964/1762] D loss: 1.2128, G loss: 0.7248\n",
      "[1044/1762] D loss: 1.3852, G loss: 0.7409\n",
      "[1124/1762] D loss: 1.1883, G loss: 1.0404\n",
      "[1204/1762] D loss: 1.2127, G loss: 0.8063\n",
      "[1284/1762] D loss: 1.4169, G loss: 0.6902\n",
      "[1364/1762] D loss: 1.3734, G loss: 0.6779\n",
      "[1444/1762] D loss: 1.4097, G loss: 0.7953\n",
      "[1524/1762] D loss: 1.3984, G loss: 0.6396\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.6114\n",
      "[1684/1762] D loss: 1.3785, G loss: 0.7030\n",
      "[1762/1762] D loss: 1.4520, G loss: 0.8271\n",
      "train error: \n",
      " D loss: 1.336339, G loss: 0.756626, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 80.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317481, G loss: 0.770994, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1413, G loss: 0.7771\n",
      "[84/1762] D loss: 1.1961, G loss: 0.8302\n",
      "[164/1762] D loss: 1.2135, G loss: 0.8066\n",
      "[244/1762] D loss: 1.3802, G loss: 0.6271\n",
      "[324/1762] D loss: 1.1749, G loss: 0.8548\n",
      "[404/1762] D loss: 1.3750, G loss: 0.6022\n",
      "[484/1762] D loss: 1.5507, G loss: 1.0740\n",
      "[564/1762] D loss: 1.0761, G loss: 0.9891\n",
      "[644/1762] D loss: 1.1151, G loss: 1.0011\n",
      "[724/1762] D loss: 1.3952, G loss: 0.7739\n",
      "[804/1762] D loss: 1.4309, G loss: 0.5976\n",
      "[884/1762] D loss: 1.4212, G loss: 0.7649\n",
      "[964/1762] D loss: 1.3964, G loss: 0.6191\n",
      "[1044/1762] D loss: 1.3777, G loss: 0.7221\n",
      "[1124/1762] D loss: 1.4181, G loss: 0.6762\n",
      "[1204/1762] D loss: 1.3808, G loss: 0.6403\n",
      "[1284/1762] D loss: 1.3678, G loss: 0.7394\n",
      "[1364/1762] D loss: 1.3721, G loss: 0.7002\n",
      "[1444/1762] D loss: 1.3857, G loss: 0.6403\n",
      "[1524/1762] D loss: 1.3574, G loss: 0.7858\n",
      "[1604/1762] D loss: 1.3660, G loss: 0.7763\n",
      "[1684/1762] D loss: 1.4679, G loss: 0.8157\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6759\n",
      "train error: \n",
      " D loss: 1.376727, G loss: 0.658386, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376161, G loss: 0.658190, D accuracy: 53.2%, cell accuracy: 99.6%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3996, G loss: 0.6539\n",
      "[84/1762] D loss: 1.3504, G loss: 0.6718\n",
      "[164/1762] D loss: 1.3949, G loss: 0.7308\n",
      "[244/1762] D loss: 1.3876, G loss: 0.7242\n",
      "[324/1762] D loss: 1.3913, G loss: 0.6314\n",
      "[404/1762] D loss: 1.3209, G loss: 0.7046\n",
      "[484/1762] D loss: 1.4667, G loss: 0.9124\n",
      "[564/1762] D loss: 1.3802, G loss: 0.7060\n",
      "[644/1762] D loss: 1.3754, G loss: 0.7547\n",
      "[724/1762] D loss: 1.3746, G loss: 0.6213\n",
      "[804/1762] D loss: 1.3141, G loss: 0.6626\n",
      "[884/1762] D loss: 1.4135, G loss: 0.5830\n",
      "[964/1762] D loss: 1.3253, G loss: 0.7703\n",
      "[1044/1762] D loss: 1.4027, G loss: 0.7783\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.6838\n",
      "[1204/1762] D loss: 1.3730, G loss: 0.6337\n",
      "[1284/1762] D loss: 1.3079, G loss: 0.7399\n",
      "[1364/1762] D loss: 1.3111, G loss: 0.8755\n",
      "[1444/1762] D loss: 1.3956, G loss: 0.6482\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7094\n",
      "[1604/1762] D loss: 1.3916, G loss: 0.6652\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.7882\n",
      "[1762/1762] D loss: 1.2936, G loss: 0.6469\n",
      "train error: \n",
      " D loss: 1.335796, G loss: 0.702915, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 74.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329107, G loss: 0.701791, D accuracy: 56.5%, cell accuracy: 99.6%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2909, G loss: 0.7430\n",
      "[84/1762] D loss: 1.3995, G loss: 0.7197\n",
      "[164/1762] D loss: 1.2247, G loss: 0.7932\n",
      "[244/1762] D loss: 1.4191, G loss: 0.5624\n",
      "[324/1762] D loss: 1.4093, G loss: 0.8254\n",
      "[404/1762] D loss: 1.4153, G loss: 0.6991\n",
      "[484/1762] D loss: 1.4017, G loss: 0.7217\n",
      "[564/1762] D loss: 1.2548, G loss: 0.7917\n",
      "[644/1762] D loss: 1.3936, G loss: 0.6278\n",
      "[724/1762] D loss: 1.2505, G loss: 0.7591\n",
      "[804/1762] D loss: 1.3920, G loss: 0.7283\n",
      "[884/1762] D loss: 1.3861, G loss: 0.7002\n",
      "[964/1762] D loss: 1.2596, G loss: 0.7237\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.7014\n",
      "[1124/1762] D loss: 1.3787, G loss: 0.7599\n",
      "[1204/1762] D loss: 1.3684, G loss: 0.7657\n",
      "[1284/1762] D loss: 1.2749, G loss: 0.7988\n",
      "[1364/1762] D loss: 1.4042, G loss: 0.8404\n",
      "[1444/1762] D loss: 1.4037, G loss: 0.6286\n",
      "[1524/1762] D loss: 1.3978, G loss: 0.7416\n",
      "[1604/1762] D loss: 1.3922, G loss: 0.7844\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.7184\n",
      "[1762/1762] D loss: 1.1442, G loss: 0.7429\n",
      "train error: \n",
      " D loss: 1.352918, G loss: 0.696523, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343308, G loss: 0.695476, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.7377\n",
      "[84/1762] D loss: 1.3986, G loss: 0.6747\n",
      "[164/1762] D loss: 1.3965, G loss: 0.6443\n",
      "[244/1762] D loss: 1.2612, G loss: 0.7809\n",
      "[324/1762] D loss: 1.3855, G loss: 0.7122\n",
      "[404/1762] D loss: 1.4175, G loss: 0.6117\n",
      "[484/1762] D loss: 1.2700, G loss: 0.7589\n",
      "[564/1762] D loss: 1.3979, G loss: 0.6753\n",
      "[644/1762] D loss: 1.2571, G loss: 0.7134\n",
      "[724/1762] D loss: 1.3922, G loss: 0.7466\n",
      "[804/1762] D loss: 1.4064, G loss: 0.6253\n",
      "[884/1762] D loss: 1.2309, G loss: 0.7894\n",
      "[964/1762] D loss: 1.2529, G loss: 0.7080\n",
      "[1044/1762] D loss: 1.4004, G loss: 0.7875\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.6533\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.6104\n",
      "[1284/1762] D loss: 1.3950, G loss: 0.7191\n",
      "[1364/1762] D loss: 1.2839, G loss: 0.7574\n",
      "[1444/1762] D loss: 1.2737, G loss: 0.8175\n",
      "[1524/1762] D loss: 1.3848, G loss: 0.6651\n",
      "[1604/1762] D loss: 1.3992, G loss: 0.7631\n",
      "[1684/1762] D loss: 1.3840, G loss: 0.7237\n",
      "[1762/1762] D loss: 1.0216, G loss: 0.9752\n",
      "train error: \n",
      " D loss: 1.360382, G loss: 0.893160, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347640, G loss: 0.889518, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2140, G loss: 0.9059\n",
      "[84/1762] D loss: 1.3988, G loss: 0.7633\n",
      "[164/1762] D loss: 1.4013, G loss: 0.7084\n",
      "[244/1762] D loss: 1.3906, G loss: 0.7178\n",
      "[324/1762] D loss: 1.2222, G loss: 0.7661\n",
      "[404/1762] D loss: 1.4176, G loss: 0.7936\n",
      "[484/1762] D loss: 1.3927, G loss: 0.7720\n",
      "[564/1762] D loss: 1.3932, G loss: 0.6469\n",
      "[644/1762] D loss: 1.4009, G loss: 0.6087\n",
      "[724/1762] D loss: 1.2225, G loss: 0.7515\n",
      "[804/1762] D loss: 1.2230, G loss: 0.7833\n",
      "[884/1762] D loss: 1.3911, G loss: 0.7561\n",
      "[964/1762] D loss: 1.3976, G loss: 0.6994\n",
      "[1044/1762] D loss: 1.4259, G loss: 0.5593\n",
      "[1124/1762] D loss: 1.2248, G loss: 0.7747\n",
      "[1204/1762] D loss: 1.3977, G loss: 0.7153\n",
      "[1284/1762] D loss: 1.3924, G loss: 0.6988\n",
      "[1364/1762] D loss: 1.2044, G loss: 0.7651\n",
      "[1444/1762] D loss: 1.1998, G loss: 0.8328\n",
      "[1524/1762] D loss: 1.4048, G loss: 0.7632\n",
      "[1604/1762] D loss: 1.4104, G loss: 0.8201\n",
      "[1684/1762] D loss: 1.3942, G loss: 0.7469\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6310\n",
      "train error: \n",
      " D loss: 1.359389, G loss: 0.594684, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350262, G loss: 0.592952, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4243, G loss: 0.5411\n",
      "[84/1762] D loss: 1.2360, G loss: 0.9021\n",
      "[164/1762] D loss: 1.4031, G loss: 0.7305\n",
      "[244/1762] D loss: 1.3883, G loss: 0.6939\n",
      "[324/1762] D loss: 1.3899, G loss: 0.6525\n",
      "[404/1762] D loss: 1.4082, G loss: 0.7702\n",
      "[484/1762] D loss: 1.3988, G loss: 0.6613\n",
      "[564/1762] D loss: 1.3989, G loss: 0.8132\n",
      "[644/1762] D loss: 1.3758, G loss: 0.7469\n",
      "[724/1762] D loss: 1.2052, G loss: 0.7930\n",
      "[804/1762] D loss: 1.4084, G loss: 0.8630\n",
      "[884/1762] D loss: 1.3905, G loss: 0.7188\n",
      "[964/1762] D loss: 1.3941, G loss: 0.6278\n",
      "[1044/1762] D loss: 1.1925, G loss: 0.8330\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.6566\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.7364\n",
      "[1284/1762] D loss: 1.1996, G loss: 0.8175\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.7482\n",
      "[1444/1762] D loss: 1.2063, G loss: 0.8464\n",
      "[1524/1762] D loss: 1.3035, G loss: 0.8274\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.7023\n",
      "[1684/1762] D loss: 1.4156, G loss: 0.7014\n",
      "[1762/1762] D loss: 1.0421, G loss: 0.8221\n",
      "train error: \n",
      " D loss: 1.337730, G loss: 0.696782, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325453, G loss: 0.694620, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3952, G loss: 0.6663\n",
      "[84/1762] D loss: 1.3918, G loss: 0.7582\n",
      "[164/1762] D loss: 1.3943, G loss: 0.6895\n",
      "[244/1762] D loss: 1.4265, G loss: 0.8730\n",
      "[324/1762] D loss: 1.3948, G loss: 0.6692\n",
      "[404/1762] D loss: 1.3970, G loss: 0.5170\n",
      "[484/1762] D loss: 1.4173, G loss: 0.8101\n",
      "[564/1762] D loss: 1.2055, G loss: 0.9283\n",
      "[644/1762] D loss: 1.4033, G loss: 0.5750\n",
      "[724/1762] D loss: 1.2460, G loss: 0.8285\n",
      "[804/1762] D loss: 1.3919, G loss: 0.7407\n",
      "[884/1762] D loss: 1.3918, G loss: 0.7317\n",
      "[964/1762] D loss: 1.2441, G loss: 0.6755\n",
      "[1044/1762] D loss: 1.4103, G loss: 0.6285\n",
      "[1124/1762] D loss: 1.1977, G loss: 0.8999\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7240\n",
      "[1284/1762] D loss: 1.4091, G loss: 0.6637\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.7674\n",
      "[1444/1762] D loss: 1.2003, G loss: 0.7698\n",
      "[1524/1762] D loss: 1.4094, G loss: 0.6266\n",
      "[1604/1762] D loss: 1.4083, G loss: 0.6669\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.6300\n",
      "[1762/1762] D loss: 0.9681, G loss: 0.8687\n",
      "train error: \n",
      " D loss: 1.341525, G loss: 0.766926, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 77.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326352, G loss: 0.765856, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9802, G loss: 1.0368\n",
      "[84/1762] D loss: 1.4064, G loss: 0.5826\n",
      "[164/1762] D loss: 1.4075, G loss: 0.6498\n",
      "[244/1762] D loss: 1.3984, G loss: 0.7215\n",
      "[324/1762] D loss: 1.3952, G loss: 0.8496\n",
      "[404/1762] D loss: 1.3858, G loss: 0.7068\n",
      "[484/1762] D loss: 1.4017, G loss: 0.7732\n",
      "[564/1762] D loss: 1.4018, G loss: 0.8380\n",
      "[644/1762] D loss: 1.4188, G loss: 0.6461\n",
      "[724/1762] D loss: 1.4117, G loss: 0.6752\n",
      "[804/1762] D loss: 1.4016, G loss: 0.8071\n",
      "[884/1762] D loss: 1.1989, G loss: 0.7883\n",
      "[964/1762] D loss: 1.3969, G loss: 0.6960\n",
      "[1044/1762] D loss: 1.4094, G loss: 0.7721\n",
      "[1124/1762] D loss: 1.1778, G loss: 0.7713\n",
      "[1204/1762] D loss: 1.1954, G loss: 0.7472\n",
      "[1284/1762] D loss: 1.3961, G loss: 0.8024\n",
      "[1364/1762] D loss: 1.2055, G loss: 0.8567\n",
      "[1444/1762] D loss: 1.3983, G loss: 0.7148\n",
      "[1524/1762] D loss: 1.3988, G loss: 0.6786\n",
      "[1604/1762] D loss: 1.3973, G loss: 0.6969\n",
      "[1684/1762] D loss: 1.1880, G loss: 0.8151\n",
      "[1762/1762] D loss: 1.3921, G loss: 0.7615\n",
      "train error: \n",
      " D loss: 1.341357, G loss: 0.800469, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324143, G loss: 0.799033, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959, G loss: 0.7529\n",
      "[84/1762] D loss: 1.2269, G loss: 0.6750\n",
      "[164/1762] D loss: 1.2324, G loss: 0.7281\n",
      "[244/1762] D loss: 1.3913, G loss: 0.6238\n",
      "[324/1762] D loss: 1.3950, G loss: 0.7440\n",
      "[404/1762] D loss: 1.4009, G loss: 0.6847\n",
      "[484/1762] D loss: 1.4104, G loss: 0.6783\n",
      "[564/1762] D loss: 1.4077, G loss: 0.6789\n",
      "[644/1762] D loss: 0.9574, G loss: 0.9335\n",
      "[724/1762] D loss: 1.3933, G loss: 0.7679\n",
      "[804/1762] D loss: 1.1759, G loss: 0.7304\n",
      "[884/1762] D loss: 1.1941, G loss: 0.7518\n",
      "[964/1762] D loss: 0.9457, G loss: 0.9599\n",
      "[1044/1762] D loss: 1.3958, G loss: 0.7473\n",
      "[1124/1762] D loss: 1.3952, G loss: 0.6760\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.7726\n",
      "[1284/1762] D loss: 1.4008, G loss: 0.6993\n",
      "[1364/1762] D loss: 1.3910, G loss: 0.6195\n",
      "[1444/1762] D loss: 1.4408, G loss: 0.9260\n",
      "[1524/1762] D loss: 1.1966, G loss: 0.8922\n",
      "[1604/1762] D loss: 1.1997, G loss: 0.8135\n",
      "[1684/1762] D loss: 1.1901, G loss: 0.7967\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7166\n",
      "train error: \n",
      " D loss: 1.336037, G loss: 0.751861, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319027, G loss: 0.751986, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1847, G loss: 0.8052\n",
      "[84/1762] D loss: 1.3952, G loss: 0.6515\n",
      "[164/1762] D loss: 1.2030, G loss: 0.6993\n",
      "[244/1762] D loss: 1.3923, G loss: 0.7555\n",
      "[324/1762] D loss: 1.3809, G loss: 0.6759\n",
      "[404/1762] D loss: 1.4025, G loss: 0.6777\n",
      "[484/1762] D loss: 1.4085, G loss: 0.8099\n",
      "[564/1762] D loss: 1.4024, G loss: 0.6715\n",
      "[644/1762] D loss: 1.1640, G loss: 0.9690\n",
      "[724/1762] D loss: 1.4055, G loss: 0.6426\n",
      "[804/1762] D loss: 1.1727, G loss: 0.8954\n",
      "[884/1762] D loss: 1.1884, G loss: 0.7187\n",
      "[964/1762] D loss: 1.4028, G loss: 0.7331\n",
      "[1044/1762] D loss: 1.1785, G loss: 0.8445\n",
      "[1124/1762] D loss: 1.3961, G loss: 0.5682\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6796\n",
      "[1284/1762] D loss: 1.0055, G loss: 0.9510\n",
      "[1364/1762] D loss: 1.4087, G loss: 0.5788\n",
      "[1444/1762] D loss: 1.4081, G loss: 0.7485\n",
      "[1524/1762] D loss: 1.4010, G loss: 0.7433\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.6745\n",
      "[1684/1762] D loss: 1.4007, G loss: 0.7374\n",
      "[1762/1762] D loss: 1.4003, G loss: 0.7959\n",
      "train error: \n",
      " D loss: 1.341664, G loss: 0.831446, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322771, G loss: 0.831054, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4149, G loss: 0.8684\n",
      "[84/1762] D loss: 1.3859, G loss: 0.6971\n",
      "[164/1762] D loss: 1.4665, G loss: 0.8088\n",
      "[244/1762] D loss: 1.4146, G loss: 0.8961\n",
      "[324/1762] D loss: 1.1823, G loss: 0.7272\n",
      "[404/1762] D loss: 1.3892, G loss: 0.7327\n",
      "[484/1762] D loss: 1.4065, G loss: 0.6038\n",
      "[564/1762] D loss: 0.9824, G loss: 0.8296\n",
      "[644/1762] D loss: 1.1591, G loss: 0.8026\n",
      "[724/1762] D loss: 1.3896, G loss: 0.7098\n",
      "[804/1762] D loss: 1.3808, G loss: 0.7338\n",
      "[884/1762] D loss: 1.4110, G loss: 0.7968\n",
      "[964/1762] D loss: 1.3903, G loss: 0.7473\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.6811\n",
      "[1124/1762] D loss: 1.3759, G loss: 0.7251\n",
      "[1204/1762] D loss: 1.3860, G loss: 0.7496\n",
      "[1284/1762] D loss: 1.4026, G loss: 0.6237\n",
      "[1364/1762] D loss: 1.1564, G loss: 0.9123\n",
      "[1444/1762] D loss: 1.4170, G loss: 0.5838\n",
      "[1524/1762] D loss: 1.1494, G loss: 0.8907\n",
      "[1604/1762] D loss: 1.4010, G loss: 0.7555\n",
      "[1684/1762] D loss: 1.3966, G loss: 0.6641\n",
      "[1762/1762] D loss: 0.9676, G loss: 0.8855\n",
      "train error: \n",
      " D loss: 1.332104, G loss: 0.744644, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314969, G loss: 0.746156, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6947\n",
      "[84/1762] D loss: 1.4072, G loss: 0.7835\n",
      "[164/1762] D loss: 1.3998, G loss: 0.6497\n",
      "[244/1762] D loss: 2.0804, G loss: 0.4412\n",
      "[324/1762] D loss: 1.7037, G loss: 0.5639\n",
      "[404/1762] D loss: 1.2160, G loss: 1.0983\n",
      "[484/1762] D loss: 1.0027, G loss: 0.9200\n",
      "[564/1762] D loss: 1.0756, G loss: 1.0228\n",
      "[644/1762] D loss: 1.4162, G loss: 0.6291\n",
      "[724/1762] D loss: 1.4306, G loss: 0.6762\n",
      "[804/1762] D loss: 1.4527, G loss: 0.6028\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6874\n",
      "[964/1762] D loss: 1.4365, G loss: 0.9368\n",
      "[1044/1762] D loss: 1.4011, G loss: 0.6444\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.7079\n",
      "[1204/1762] D loss: 1.4043, G loss: 0.6351\n",
      "[1284/1762] D loss: 1.3888, G loss: 0.6703\n",
      "[1364/1762] D loss: 1.3750, G loss: 0.7153\n",
      "[1444/1762] D loss: 1.3685, G loss: 0.6739\n",
      "[1524/1762] D loss: 1.3988, G loss: 0.6306\n",
      "[1604/1762] D loss: 1.3949, G loss: 0.6336\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.7384\n",
      "[1762/1762] D loss: 1.2766, G loss: 0.7860\n",
      "train error: \n",
      " D loss: 1.374774, G loss: 0.724660, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374773, G loss: 0.722258, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6757\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6646\n",
      "[164/1762] D loss: 1.3879, G loss: 0.7110\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7081\n",
      "[324/1762] D loss: 1.3963, G loss: 0.7915\n",
      "[404/1762] D loss: 1.2873, G loss: 0.7072\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6616\n",
      "[564/1762] D loss: 1.3910, G loss: 0.6939\n",
      "[644/1762] D loss: 1.3903, G loss: 0.6812\n",
      "[724/1762] D loss: 1.3888, G loss: 0.7151\n",
      "[804/1762] D loss: 1.2113, G loss: 0.7186\n",
      "[884/1762] D loss: 1.3945, G loss: 0.6416\n",
      "[964/1762] D loss: 1.3895, G loss: 0.7297\n",
      "[1044/1762] D loss: 1.3952, G loss: 0.7869\n",
      "[1124/1762] D loss: 1.2725, G loss: 0.6655\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6858\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.7082\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.6688\n",
      "[1444/1762] D loss: 1.2742, G loss: 0.7955\n",
      "[1524/1762] D loss: 1.1669, G loss: 0.7501\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.7347\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.6408\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.6839\n",
      "train error: \n",
      " D loss: 1.359026, G loss: 0.658998, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 80.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352653, G loss: 0.658107, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.6639\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7003\n",
      "[164/1762] D loss: 1.3919, G loss: 0.7561\n",
      "[244/1762] D loss: 1.4024, G loss: 0.7788\n",
      "[324/1762] D loss: 1.2749, G loss: 0.7581\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6553\n",
      "[484/1762] D loss: 1.3405, G loss: 0.7287\n",
      "[564/1762] D loss: 1.0861, G loss: 0.8380\n",
      "[644/1762] D loss: 1.3877, G loss: 0.6613\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7048\n",
      "[804/1762] D loss: 1.0786, G loss: 0.8035\n",
      "[884/1762] D loss: 1.3951, G loss: 0.7606\n",
      "[964/1762] D loss: 1.3957, G loss: 0.6700\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.6683\n",
      "[1124/1762] D loss: 1.3951, G loss: 0.6214\n",
      "[1204/1762] D loss: 1.4079, G loss: 0.6603\n",
      "[1284/1762] D loss: 1.3989, G loss: 0.7474\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.7375\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.7328\n",
      "[1524/1762] D loss: 1.3889, G loss: 0.6655\n",
      "[1604/1762] D loss: 1.2249, G loss: 0.7833\n",
      "[1684/1762] D loss: 1.4101, G loss: 0.7161\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7214\n",
      "train error: \n",
      " D loss: 1.346161, G loss: 0.708196, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 83.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335741, G loss: 0.707575, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3829, G loss: 0.6691\n",
      "[84/1762] D loss: 1.3923, G loss: 0.7626\n",
      "[164/1762] D loss: 1.3918, G loss: 0.7308\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6955\n",
      "[324/1762] D loss: 1.3914, G loss: 0.7495\n",
      "[404/1762] D loss: 1.2181, G loss: 0.8369\n",
      "[484/1762] D loss: 1.3892, G loss: 0.7265\n",
      "[564/1762] D loss: 1.2221, G loss: 0.7464\n",
      "[644/1762] D loss: 1.3882, G loss: 0.7443\n",
      "[724/1762] D loss: 1.2039, G loss: 0.8723\n",
      "[804/1762] D loss: 1.3994, G loss: 0.6330\n",
      "[884/1762] D loss: 1.4137, G loss: 0.8245\n",
      "[964/1762] D loss: 1.4001, G loss: 0.6644\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.6837\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.6475\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.6819\n",
      "[1284/1762] D loss: 1.3848, G loss: 0.6872\n",
      "[1364/1762] D loss: 1.3989, G loss: 0.7092\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6931\n",
      "[1524/1762] D loss: 1.4001, G loss: 0.6560\n",
      "[1604/1762] D loss: 1.1959, G loss: 0.8072\n",
      "[1684/1762] D loss: 1.3985, G loss: 0.7459\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.7168\n",
      "train error: \n",
      " D loss: 1.342703, G loss: 0.674060, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331053, G loss: 0.673048, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2247, G loss: 0.7536\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6935\n",
      "[164/1762] D loss: 1.2010, G loss: 0.7923\n",
      "[244/1762] D loss: 1.1925, G loss: 0.9033\n",
      "[324/1762] D loss: 1.3980, G loss: 0.6034\n",
      "[404/1762] D loss: 1.4007, G loss: 0.7348\n",
      "[484/1762] D loss: 1.3921, G loss: 0.6838\n",
      "[564/1762] D loss: 1.1925, G loss: 0.7171\n",
      "[644/1762] D loss: 1.3926, G loss: 0.6649\n",
      "[724/1762] D loss: 1.1863, G loss: 0.8064\n",
      "[804/1762] D loss: 1.3884, G loss: 0.7256\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7627\n",
      "[964/1762] D loss: 1.3898, G loss: 0.6619\n",
      "[1044/1762] D loss: 1.4222, G loss: 0.7384\n",
      "[1124/1762] D loss: 1.2084, G loss: 0.8033\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.7233\n",
      "[1284/1762] D loss: 1.2109, G loss: 0.7304\n",
      "[1364/1762] D loss: 1.3990, G loss: 0.5475\n",
      "[1444/1762] D loss: 1.4224, G loss: 0.8238\n",
      "[1524/1762] D loss: 1.1915, G loss: 0.8080\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.7057\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.6426\n",
      "[1762/1762] D loss: 1.4872, G loss: 0.5913\n",
      "train error: \n",
      " D loss: 1.342005, G loss: 0.663160, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 83.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329590, G loss: 0.661424, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.7004\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7211\n",
      "[164/1762] D loss: 1.3895, G loss: 0.6551\n",
      "[244/1762] D loss: 1.2606, G loss: 0.7989\n",
      "[324/1762] D loss: 1.3926, G loss: 0.7515\n",
      "[404/1762] D loss: 1.3897, G loss: 0.6661\n",
      "[484/1762] D loss: 1.3998, G loss: 0.8285\n",
      "[564/1762] D loss: 1.4093, G loss: 0.5575\n",
      "[644/1762] D loss: 1.3923, G loss: 0.7286\n",
      "[724/1762] D loss: 1.2047, G loss: 0.6649\n",
      "[804/1762] D loss: 0.9617, G loss: 0.9824\n",
      "[884/1762] D loss: 1.3911, G loss: 0.6907\n",
      "[964/1762] D loss: 1.3994, G loss: 0.6770\n",
      "[1044/1762] D loss: 1.3976, G loss: 0.7019\n",
      "[1124/1762] D loss: 0.9480, G loss: 1.0330\n",
      "[1204/1762] D loss: 1.4223, G loss: 0.8320\n",
      "[1284/1762] D loss: 1.3976, G loss: 0.6433\n",
      "[1364/1762] D loss: 1.1434, G loss: 0.9901\n",
      "[1444/1762] D loss: 1.4522, G loss: 0.9450\n",
      "[1524/1762] D loss: 1.4051, G loss: 0.7584\n",
      "[1604/1762] D loss: 1.3975, G loss: 0.7361\n",
      "[1684/1762] D loss: 1.4013, G loss: 0.6524\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6986\n",
      "train error: \n",
      " D loss: 1.337494, G loss: 0.672623, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 75.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324551, G loss: 0.672416, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3985, G loss: 0.6085\n",
      "[84/1762] D loss: 1.3903, G loss: 0.7607\n",
      "[164/1762] D loss: 1.3810, G loss: 0.7174\n",
      "[244/1762] D loss: 1.4016, G loss: 0.6035\n",
      "[324/1762] D loss: 1.3884, G loss: 0.6760\n",
      "[404/1762] D loss: 1.4037, G loss: 0.7477\n",
      "[484/1762] D loss: 1.3948, G loss: 0.7699\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7510\n",
      "[644/1762] D loss: 1.1961, G loss: 0.8753\n",
      "[724/1762] D loss: 1.3955, G loss: 0.7596\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7589\n",
      "[884/1762] D loss: 1.1701, G loss: 0.8070\n",
      "[964/1762] D loss: 1.3865, G loss: 0.8070\n",
      "[1044/1762] D loss: 1.0385, G loss: 0.8032\n",
      "[1124/1762] D loss: 1.3122, G loss: 0.7074\n",
      "[1204/1762] D loss: 1.4802, G loss: 0.8411\n",
      "[1284/1762] D loss: 1.3921, G loss: 0.7085\n",
      "[1364/1762] D loss: 1.4115, G loss: 0.8019\n",
      "[1444/1762] D loss: 1.3944, G loss: 0.7449\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6951\n",
      "[1604/1762] D loss: 1.2051, G loss: 0.8942\n",
      "[1684/1762] D loss: 1.3730, G loss: 0.6675\n",
      "[1762/1762] D loss: 1.3827, G loss: 0.6904\n",
      "train error: \n",
      " D loss: 1.338427, G loss: 0.716376, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 62.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326602, G loss: 0.719369, D accuracy: 56.0%, cell accuracy: 99.5%, board accuracy: 58.4% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3761, G loss: 0.7271\n",
      "[84/1762] D loss: 1.3981, G loss: 0.7640\n",
      "[164/1762] D loss: 1.4097, G loss: 0.5947\n",
      "[244/1762] D loss: 1.3959, G loss: 0.7618\n",
      "[324/1762] D loss: 1.3944, G loss: 0.7675\n",
      "[404/1762] D loss: 1.4037, G loss: 0.8048\n",
      "[484/1762] D loss: 1.3748, G loss: 0.6419\n",
      "[564/1762] D loss: 1.3969, G loss: 0.7672\n",
      "[644/1762] D loss: 1.3924, G loss: 0.6803\n",
      "[724/1762] D loss: 1.1959, G loss: 0.8092\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6603\n",
      "[884/1762] D loss: 1.1894, G loss: 0.8038\n",
      "[964/1762] D loss: 1.2161, G loss: 0.7046\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.7348\n",
      "[1124/1762] D loss: 1.3946, G loss: 0.7680\n",
      "[1204/1762] D loss: 1.3907, G loss: 0.7927\n",
      "[1284/1762] D loss: 1.1981, G loss: 0.7790\n",
      "[1364/1762] D loss: 1.4014, G loss: 0.7553\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.7018\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.7511\n",
      "[1604/1762] D loss: 1.3852, G loss: 0.7181\n",
      "[1684/1762] D loss: 1.3965, G loss: 0.7276\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.7389\n",
      "train error: \n",
      " D loss: 1.337024, G loss: 0.663147, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323925, G loss: 0.663739, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905, G loss: 0.6334\n",
      "[84/1762] D loss: 1.3796, G loss: 0.6916\n",
      "[164/1762] D loss: 1.3841, G loss: 0.7121\n",
      "[244/1762] D loss: 1.3915, G loss: 0.7410\n",
      "[324/1762] D loss: 1.3784, G loss: 0.6874\n",
      "[404/1762] D loss: 1.3948, G loss: 0.7845\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6915\n",
      "[564/1762] D loss: 1.1726, G loss: 0.8619\n",
      "[644/1762] D loss: 1.3916, G loss: 0.6219\n",
      "[724/1762] D loss: 1.1734, G loss: 0.8396\n",
      "[804/1762] D loss: 1.3985, G loss: 0.7043\n",
      "[884/1762] D loss: 1.1791, G loss: 0.7837\n",
      "[964/1762] D loss: 1.4020, G loss: 0.7984\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.6864\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.6694\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.7225\n",
      "[1284/1762] D loss: 0.9621, G loss: 0.7926\n",
      "[1364/1762] D loss: 1.3961, G loss: 0.7538\n",
      "[1444/1762] D loss: 1.4022, G loss: 0.6643\n",
      "[1524/1762] D loss: 1.1664, G loss: 0.7738\n",
      "[1604/1762] D loss: 1.3981, G loss: 0.5836\n",
      "[1684/1762] D loss: 1.3949, G loss: 0.7237\n",
      "[1762/1762] D loss: 1.3952, G loss: 0.7614\n",
      "train error: \n",
      " D loss: 1.329828, G loss: 0.730599, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314075, G loss: 0.733162, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.7036\n",
      "[84/1762] D loss: 1.1687, G loss: 0.8276\n",
      "[164/1762] D loss: 1.3963, G loss: 0.7590\n",
      "[244/1762] D loss: 1.1527, G loss: 0.7909\n",
      "[324/1762] D loss: 1.1750, G loss: 0.8807\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6069\n",
      "[484/1762] D loss: 1.1617, G loss: 0.8102\n",
      "[564/1762] D loss: 1.4012, G loss: 0.7372\n",
      "[644/1762] D loss: 1.3913, G loss: 0.7079\n",
      "[724/1762] D loss: 1.3964, G loss: 0.7453\n",
      "[804/1762] D loss: 1.4013, G loss: 0.6940\n",
      "[884/1762] D loss: 1.3858, G loss: 0.6936\n",
      "[964/1762] D loss: 1.3939, G loss: 0.7852\n",
      "[1044/1762] D loss: 1.1711, G loss: 0.7994\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.6442\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7297\n",
      "[1284/1762] D loss: 1.3982, G loss: 0.6248\n",
      "[1364/1762] D loss: 1.3921, G loss: 0.7513\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.6422\n",
      "[1524/1762] D loss: 1.3969, G loss: 0.7495\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.7255\n",
      "[1684/1762] D loss: 1.3940, G loss: 0.6247\n",
      "[1762/1762] D loss: 0.9117, G loss: 0.9918\n",
      "train error: \n",
      " D loss: 1.329127, G loss: 0.771154, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312163, G loss: 0.772886, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4027, G loss: 0.7674\n",
      "[84/1762] D loss: 1.3913, G loss: 0.7481\n",
      "[164/1762] D loss: 1.3903, G loss: 0.6971\n",
      "[244/1762] D loss: 1.1997, G loss: 0.6602\n",
      "[324/1762] D loss: 1.3908, G loss: 0.6746\n",
      "[404/1762] D loss: 1.4003, G loss: 0.7437\n",
      "[484/1762] D loss: 1.4079, G loss: 0.6450\n",
      "[564/1762] D loss: 1.1473, G loss: 0.9446\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6973\n",
      "[724/1762] D loss: 1.3946, G loss: 0.6732\n",
      "[804/1762] D loss: 1.4022, G loss: 0.7322\n",
      "[884/1762] D loss: 1.4012, G loss: 0.7184\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7014\n",
      "[1044/1762] D loss: 1.1982, G loss: 0.7367\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.7181\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.7168\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.6533\n",
      "[1364/1762] D loss: 0.9653, G loss: 0.8308\n",
      "[1444/1762] D loss: 1.3846, G loss: 0.7628\n",
      "[1524/1762] D loss: 1.3928, G loss: 0.6870\n",
      "[1604/1762] D loss: 1.3999, G loss: 0.7453\n",
      "[1684/1762] D loss: 1.1661, G loss: 0.9762\n",
      "[1762/1762] D loss: 0.9650, G loss: 0.7874\n",
      "train error: \n",
      " D loss: 1.329679, G loss: 0.699460, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312803, G loss: 0.704744, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980, G loss: 0.6895\n",
      "[84/1762] D loss: 1.1614, G loss: 0.8114\n",
      "[164/1762] D loss: 1.3993, G loss: 0.6626\n",
      "[244/1762] D loss: 1.3974, G loss: 0.6762\n",
      "[324/1762] D loss: 1.3946, G loss: 0.6691\n",
      "[404/1762] D loss: 1.4068, G loss: 0.7663\n",
      "[484/1762] D loss: 1.1310, G loss: 0.8459\n",
      "[564/1762] D loss: 1.3890, G loss: 0.6901\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6984\n",
      "[724/1762] D loss: 0.9515, G loss: 0.9308\n",
      "[804/1762] D loss: 1.3893, G loss: 0.7296\n",
      "[884/1762] D loss: 1.4002, G loss: 0.7645\n",
      "[964/1762] D loss: 1.3908, G loss: 0.6880\n",
      "[1044/1762] D loss: 1.3833, G loss: 0.7162\n",
      "[1124/1762] D loss: 1.4219, G loss: 0.8680\n",
      "[1204/1762] D loss: 1.3892, G loss: 0.8356\n",
      "[1284/1762] D loss: 1.1663, G loss: 0.8300\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7396\n",
      "[1444/1762] D loss: 1.1673, G loss: 0.7409\n",
      "[1524/1762] D loss: 1.3915, G loss: 0.6733\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.7903\n",
      "[1684/1762] D loss: 1.3954, G loss: 0.6480\n",
      "[1762/1762] D loss: 1.4219, G loss: 0.8564\n",
      "train error: \n",
      " D loss: 1.328873, G loss: 0.694596, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 74.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311828, G loss: 0.700125, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3918, G loss: 0.6018\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7248\n",
      "[164/1762] D loss: 1.4205, G loss: 0.6043\n",
      "[244/1762] D loss: 1.1281, G loss: 0.9376\n",
      "[324/1762] D loss: 1.3913, G loss: 0.7021\n",
      "[404/1762] D loss: 1.3966, G loss: 0.7544\n",
      "[484/1762] D loss: 1.3852, G loss: 0.7088\n",
      "[564/1762] D loss: 1.3971, G loss: 0.7009\n",
      "[644/1762] D loss: 1.4019, G loss: 0.8305\n",
      "[724/1762] D loss: 1.3891, G loss: 0.7428\n",
      "[804/1762] D loss: 1.3911, G loss: 0.6955\n",
      "[884/1762] D loss: 0.9198, G loss: 0.9688\n",
      "[964/1762] D loss: 1.3914, G loss: 0.6424\n",
      "[1044/1762] D loss: 1.4124, G loss: 0.6546\n",
      "[1124/1762] D loss: 0.9015, G loss: 0.9642\n",
      "[1204/1762] D loss: 1.1485, G loss: 0.7232\n",
      "[1284/1762] D loss: 1.3997, G loss: 0.8152\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.7087\n",
      "[1444/1762] D loss: 1.4029, G loss: 0.6203\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7140\n",
      "[1604/1762] D loss: 1.1239, G loss: 0.8770\n",
      "[1684/1762] D loss: 1.2106, G loss: 1.1505\n",
      "[1762/1762] D loss: 1.4102, G loss: 0.6526\n",
      "train error: \n",
      " D loss: 1.326316, G loss: 0.789566, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 75.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306572, G loss: 0.798007, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.7157\n",
      "[84/1762] D loss: 1.3892, G loss: 0.5838\n",
      "[164/1762] D loss: 1.3855, G loss: 0.7871\n",
      "[244/1762] D loss: 1.1374, G loss: 0.7801\n",
      "[324/1762] D loss: 1.3549, G loss: 0.6950\n",
      "[404/1762] D loss: 1.1778, G loss: 0.8568\n",
      "[484/1762] D loss: 1.3742, G loss: 0.7051\n",
      "[564/1762] D loss: 1.1692, G loss: 0.7952\n",
      "[644/1762] D loss: 1.3848, G loss: 0.8646\n",
      "[724/1762] D loss: 1.3783, G loss: 0.6814\n",
      "[804/1762] D loss: 1.3468, G loss: 0.7116\n",
      "[884/1762] D loss: 1.3971, G loss: 0.6551\n",
      "[964/1762] D loss: 1.4188, G loss: 0.6107\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7428\n",
      "[1124/1762] D loss: 1.4185, G loss: 0.8310\n",
      "[1204/1762] D loss: 1.4017, G loss: 0.6651\n",
      "[1284/1762] D loss: 1.1786, G loss: 0.8514\n",
      "[1364/1762] D loss: 1.3953, G loss: 0.6242\n",
      "[1444/1762] D loss: 1.3937, G loss: 0.6395\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.7793\n",
      "[1604/1762] D loss: 1.1411, G loss: 0.8396\n",
      "[1684/1762] D loss: 1.4721, G loss: 0.6664\n",
      "[1762/1762] D loss: 2.0264, G loss: 0.3870\n",
      "train error: \n",
      " D loss: 1.725565, G loss: 0.622591, D accuracy: 40.4%, cell accuracy: 98.4%, board accuracy: 10.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.711160, G loss: 0.631086, D accuracy: 40.6%, cell accuracy: 98.4%, board accuracy: 9.8% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7699, G loss: 0.6716\n",
      "[84/1762] D loss: 1.5773, G loss: 1.1534\n",
      "[164/1762] D loss: 1.4417, G loss: 0.7445\n",
      "[244/1762] D loss: 1.4123, G loss: 0.7560\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6908\n",
      "[404/1762] D loss: 1.4493, G loss: 0.7603\n",
      "[484/1762] D loss: 1.3895, G loss: 0.6435\n",
      "[564/1762] D loss: 1.3904, G loss: 0.6422\n",
      "[644/1762] D loss: 1.4108, G loss: 0.7142\n",
      "[724/1762] D loss: 1.3283, G loss: 0.6207\n",
      "[804/1762] D loss: 1.4206, G loss: 0.7321\n",
      "[884/1762] D loss: 1.3944, G loss: 0.7808\n",
      "[964/1762] D loss: 1.3995, G loss: 0.6304\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.7008\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.7309\n",
      "[1204/1762] D loss: 1.1727, G loss: 0.7901\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.6906\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.7204\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.6963\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6917\n",
      "[1604/1762] D loss: 1.2530, G loss: 0.7747\n",
      "[1684/1762] D loss: 1.3922, G loss: 0.7477\n",
      "[1762/1762] D loss: 1.0903, G loss: 0.7424\n",
      "train error: \n",
      " D loss: 1.350332, G loss: 0.738015, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343527, G loss: 0.737376, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7344\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6926\n",
      "[164/1762] D loss: 1.3462, G loss: 0.7499\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7430\n",
      "[324/1762] D loss: 1.3890, G loss: 0.7397\n",
      "[404/1762] D loss: 1.3810, G loss: 0.6932\n",
      "[484/1762] D loss: 1.2710, G loss: 0.7428\n",
      "[564/1762] D loss: 1.3900, G loss: 0.6919\n",
      "[644/1762] D loss: 1.3205, G loss: 0.7859\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6810\n",
      "[804/1762] D loss: 1.3796, G loss: 0.6712\n",
      "[884/1762] D loss: 1.1694, G loss: 0.8185\n",
      "[964/1762] D loss: 1.3887, G loss: 0.6813\n",
      "[1044/1762] D loss: 1.1453, G loss: 0.7778\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6938\n",
      "[1204/1762] D loss: 1.3423, G loss: 0.8229\n",
      "[1284/1762] D loss: 1.3898, G loss: 0.7184\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.7235\n",
      "[1444/1762] D loss: 1.2208, G loss: 0.7129\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.6851\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6999\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.7060\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6628\n",
      "train error: \n",
      " D loss: 1.335442, G loss: 0.736766, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324102, G loss: 0.738784, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7091\n",
      "[84/1762] D loss: 1.4123, G loss: 0.8595\n",
      "[164/1762] D loss: 1.3884, G loss: 0.7246\n",
      "[244/1762] D loss: 1.3834, G loss: 0.6935\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6418\n",
      "[404/1762] D loss: 1.3874, G loss: 0.7165\n",
      "[484/1762] D loss: 1.1983, G loss: 0.7642\n",
      "[564/1762] D loss: 1.3849, G loss: 0.6835\n",
      "[644/1762] D loss: 1.3919, G loss: 0.6781\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7076\n",
      "[804/1762] D loss: 1.1976, G loss: 0.6821\n",
      "[884/1762] D loss: 0.8129, G loss: 0.8325\n",
      "[964/1762] D loss: 1.3912, G loss: 0.7394\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.7536\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7242\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.6742\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.7060\n",
      "[1364/1762] D loss: 1.0155, G loss: 0.8075\n",
      "[1444/1762] D loss: 1.2030, G loss: 0.8922\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.7246\n",
      "[1604/1762] D loss: 1.2634, G loss: 0.7219\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6727\n",
      "[1762/1762] D loss: 1.3942, G loss: 0.6354\n",
      "train error: \n",
      " D loss: 1.335380, G loss: 0.692708, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320650, G loss: 0.697046, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1991, G loss: 0.7642\n",
      "[84/1762] D loss: 1.1441, G loss: 0.8690\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7273\n",
      "[244/1762] D loss: 1.2617, G loss: 0.8294\n",
      "[324/1762] D loss: 1.3855, G loss: 0.7282\n",
      "[404/1762] D loss: 1.3913, G loss: 0.6834\n",
      "[484/1762] D loss: 1.5069, G loss: 0.6593\n",
      "[564/1762] D loss: 1.4007, G loss: 0.7464\n",
      "[644/1762] D loss: 1.4030, G loss: 0.7699\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6673\n",
      "[804/1762] D loss: 1.2030, G loss: 0.7842\n",
      "[884/1762] D loss: 1.3922, G loss: 0.6419\n",
      "[964/1762] D loss: 1.6871, G loss: 0.6179\n",
      "[1044/1762] D loss: 1.5471, G loss: 0.6481\n",
      "[1124/1762] D loss: 1.1687, G loss: 1.0126\n",
      "[1204/1762] D loss: 1.1898, G loss: 0.7747\n",
      "[1284/1762] D loss: 1.4132, G loss: 0.8156\n",
      "[1364/1762] D loss: 1.3364, G loss: 0.6773\n",
      "[1444/1762] D loss: 1.2880, G loss: 0.6658\n",
      "[1524/1762] D loss: 1.3316, G loss: 0.7203\n",
      "[1604/1762] D loss: 1.3609, G loss: 0.7360\n",
      "[1684/1762] D loss: 1.3710, G loss: 0.7518\n",
      "[1762/1762] D loss: 1.3251, G loss: 0.7258\n",
      "train error: \n",
      " D loss: 1.335128, G loss: 0.730473, D accuracy: 59.4%, cell accuracy: 98.6%, board accuracy: 24.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330675, G loss: 0.728181, D accuracy: 58.1%, cell accuracy: 98.5%, board accuracy: 23.4% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2351, G loss: 0.7196\n",
      "[84/1762] D loss: 1.3586, G loss: 0.7421\n",
      "[164/1762] D loss: 1.3365, G loss: 0.7669\n",
      "[244/1762] D loss: 1.3669, G loss: 0.6526\n",
      "[324/1762] D loss: 1.2154, G loss: 0.6700\n",
      "[404/1762] D loss: 1.4273, G loss: 0.8906\n",
      "[484/1762] D loss: 1.2658, G loss: 0.6889\n",
      "[564/1762] D loss: 1.2330, G loss: 0.7547\n",
      "[644/1762] D loss: 1.3904, G loss: 0.7477\n",
      "[724/1762] D loss: 1.3925, G loss: 0.6852\n",
      "[804/1762] D loss: 1.4014, G loss: 0.7558\n",
      "[884/1762] D loss: 1.4021, G loss: 0.6505\n",
      "[964/1762] D loss: 1.2374, G loss: 0.7295\n",
      "[1044/1762] D loss: 1.3976, G loss: 0.7018\n",
      "[1124/1762] D loss: 1.3046, G loss: 0.7838\n",
      "[1204/1762] D loss: 1.3357, G loss: 0.8743\n",
      "[1284/1762] D loss: 1.2181, G loss: 0.7689\n",
      "[1364/1762] D loss: 1.2214, G loss: 0.6931\n",
      "[1444/1762] D loss: 1.3841, G loss: 0.6387\n",
      "[1524/1762] D loss: 1.4715, G loss: 0.7262\n",
      "[1604/1762] D loss: 1.3968, G loss: 0.7999\n",
      "[1684/1762] D loss: 1.3405, G loss: 0.6990\n",
      "[1762/1762] D loss: 1.3587, G loss: 0.7893\n",
      "train error: \n",
      " D loss: 1.346963, G loss: 0.777077, D accuracy: 49.7%, cell accuracy: 99.1%, board accuracy: 25.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340995, G loss: 0.772329, D accuracy: 51.8%, cell accuracy: 99.0%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3932, G loss: 0.7579\n",
      "[84/1762] D loss: 1.3992, G loss: 0.6947\n",
      "[164/1762] D loss: 1.4033, G loss: 0.8008\n",
      "[244/1762] D loss: 1.2115, G loss: 0.8572\n",
      "[324/1762] D loss: 1.3704, G loss: 0.6109\n",
      "[404/1762] D loss: 1.4052, G loss: 0.8088\n",
      "[484/1762] D loss: 1.2005, G loss: 0.7789\n",
      "[564/1762] D loss: 1.2096, G loss: 0.7276\n",
      "[644/1762] D loss: 1.3962, G loss: 0.6656\n",
      "[724/1762] D loss: 1.4011, G loss: 0.7890\n",
      "[804/1762] D loss: 1.4726, G loss: 0.6220\n",
      "[884/1762] D loss: 1.4171, G loss: 1.0741\n",
      "[964/1762] D loss: 1.1415, G loss: 0.7597\n",
      "[1044/1762] D loss: 0.9542, G loss: 0.9485\n",
      "[1124/1762] D loss: 1.2560, G loss: 0.7345\n",
      "[1204/1762] D loss: 1.4889, G loss: 0.8866\n",
      "[1284/1762] D loss: 1.5399, G loss: 0.7390\n",
      "[1364/1762] D loss: 1.3854, G loss: 0.6847\n",
      "[1444/1762] D loss: 1.3966, G loss: 0.7293\n",
      "[1524/1762] D loss: 1.4066, G loss: 0.8105\n",
      "[1604/1762] D loss: 1.3952, G loss: 0.7456\n",
      "[1684/1762] D loss: 1.4076, G loss: 0.6610\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7311\n",
      "train error: \n",
      " D loss: 1.392191, G loss: 0.720642, D accuracy: 51.3%, cell accuracy: 99.5%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396468, G loss: 0.720957, D accuracy: 52.4%, cell accuracy: 99.4%, board accuracy: 48.0% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3832, G loss: 0.7096\n",
      "[84/1762] D loss: 1.4009, G loss: 0.6913\n",
      "[164/1762] D loss: 1.3850, G loss: 0.7028\n",
      "[244/1762] D loss: 1.3908, G loss: 0.7039\n",
      "[324/1762] D loss: 1.3920, G loss: 0.6582\n",
      "[404/1762] D loss: 1.3613, G loss: 0.7153\n",
      "[484/1762] D loss: 1.3266, G loss: 0.6637\n",
      "[564/1762] D loss: 1.3859, G loss: 0.7088\n",
      "[644/1762] D loss: 1.3898, G loss: 0.6897\n",
      "[724/1762] D loss: 1.3894, G loss: 0.6757\n",
      "[804/1762] D loss: 1.3829, G loss: 0.7007\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6896\n",
      "[964/1762] D loss: 1.3784, G loss: 0.6739\n",
      "[1044/1762] D loss: 1.3213, G loss: 0.7093\n",
      "[1124/1762] D loss: 1.3912, G loss: 0.7093\n",
      "[1204/1762] D loss: 1.2860, G loss: 0.7395\n",
      "[1284/1762] D loss: 1.3801, G loss: 0.7486\n",
      "[1364/1762] D loss: 1.3954, G loss: 0.7562\n",
      "[1444/1762] D loss: 1.1700, G loss: 0.7968\n",
      "[1524/1762] D loss: 1.2896, G loss: 0.7430\n",
      "[1604/1762] D loss: 1.3854, G loss: 0.6776\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6993\n",
      "[1762/1762] D loss: 1.3927, G loss: 0.7815\n",
      "train error: \n",
      " D loss: 1.352573, G loss: 0.752064, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346273, G loss: 0.752548, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.7732\n",
      "[84/1762] D loss: 1.2237, G loss: 0.7375\n",
      "[164/1762] D loss: 1.3595, G loss: 0.7902\n",
      "[244/1762] D loss: 1.3395, G loss: 0.7633\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6834\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6629\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7509\n",
      "[564/1762] D loss: 1.3982, G loss: 0.7696\n",
      "[644/1762] D loss: 1.3906, G loss: 0.7347\n",
      "[724/1762] D loss: 1.0678, G loss: 0.8157\n",
      "[804/1762] D loss: 1.3923, G loss: 0.7609\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7455\n",
      "[964/1762] D loss: 1.3913, G loss: 0.7700\n",
      "[1044/1762] D loss: 1.3961, G loss: 0.8205\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.7580\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.7155\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6813\n",
      "[1364/1762] D loss: 1.0159, G loss: 0.8314\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.7055\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.6550\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.6802\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7045\n",
      "train error: \n",
      " D loss: 1.337694, G loss: 0.746534, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326535, G loss: 0.746534, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7109\n",
      "[84/1762] D loss: 1.3892, G loss: 0.7222\n",
      "[164/1762] D loss: 1.3909, G loss: 0.7455\n",
      "[244/1762] D loss: 1.3876, G loss: 0.7124\n",
      "[324/1762] D loss: 1.3862, G loss: 0.7241\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6830\n",
      "[484/1762] D loss: 1.3870, G loss: 0.7028\n",
      "[564/1762] D loss: 1.2042, G loss: 0.7131\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6978\n",
      "[724/1762] D loss: 1.1879, G loss: 0.8484\n",
      "[804/1762] D loss: 1.3921, G loss: 0.7788\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7258\n",
      "[964/1762] D loss: 1.4074, G loss: 0.7456\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.7730\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.6381\n",
      "[1204/1762] D loss: 1.1739, G loss: 0.8047\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.7479\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.7184\n",
      "[1444/1762] D loss: 1.1730, G loss: 0.8700\n",
      "[1524/1762] D loss: 1.4002, G loss: 0.8351\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.6070\n",
      "[1684/1762] D loss: 1.2597, G loss: 0.8549\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.7457\n",
      "train error: \n",
      " D loss: 1.331874, G loss: 0.702727, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317659, G loss: 0.705047, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7351\n",
      "[84/1762] D loss: 1.3925, G loss: 0.6234\n",
      "[164/1762] D loss: 1.4037, G loss: 0.7808\n",
      "[244/1762] D loss: 1.1598, G loss: 0.8911\n",
      "[324/1762] D loss: 1.3902, G loss: 0.7593\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6632\n",
      "[484/1762] D loss: 1.3908, G loss: 0.7773\n",
      "[564/1762] D loss: 1.3896, G loss: 0.7329\n",
      "[644/1762] D loss: 1.3886, G loss: 0.7246\n",
      "[724/1762] D loss: 1.3932, G loss: 0.6799\n",
      "[804/1762] D loss: 1.3881, G loss: 0.7138\n",
      "[884/1762] D loss: 1.3894, G loss: 0.6916\n",
      "[964/1762] D loss: 1.3997, G loss: 0.6022\n",
      "[1044/1762] D loss: 1.3984, G loss: 0.8064\n",
      "[1124/1762] D loss: 1.1699, G loss: 0.7731\n",
      "[1204/1762] D loss: 1.1390, G loss: 0.9978\n",
      "[1284/1762] D loss: 1.3920, G loss: 0.5973\n",
      "[1364/1762] D loss: 1.4129, G loss: 0.8669\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.6846\n",
      "[1524/1762] D loss: 1.3931, G loss: 0.6903\n",
      "[1604/1762] D loss: 1.1667, G loss: 0.8515\n",
      "[1684/1762] D loss: 1.1716, G loss: 0.9266\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6310\n",
      "train error: \n",
      " D loss: 1.328592, G loss: 0.716226, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313172, G loss: 0.720414, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3971, G loss: 0.6743\n",
      "[84/1762] D loss: 0.9097, G loss: 0.9895\n",
      "[164/1762] D loss: 1.3886, G loss: 0.7012\n",
      "[244/1762] D loss: 1.3878, G loss: 0.7130\n",
      "[324/1762] D loss: 1.3919, G loss: 0.7260\n",
      "[404/1762] D loss: 1.3969, G loss: 0.7418\n",
      "[484/1762] D loss: 1.4162, G loss: 0.8398\n",
      "[564/1762] D loss: 1.1580, G loss: 0.8626\n",
      "[644/1762] D loss: 1.3907, G loss: 0.6450\n",
      "[724/1762] D loss: 1.4001, G loss: 0.6098\n",
      "[804/1762] D loss: 1.3907, G loss: 0.7504\n",
      "[884/1762] D loss: 1.4001, G loss: 0.8779\n",
      "[964/1762] D loss: 1.4096, G loss: 0.8075\n",
      "[1044/1762] D loss: 1.4042, G loss: 0.7218\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.6863\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.7091\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.6972\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.7133\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6927\n",
      "[1524/1762] D loss: 1.4052, G loss: 0.7331\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.7627\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.6768\n",
      "[1762/1762] D loss: 1.4020, G loss: 0.8079\n",
      "train error: \n",
      " D loss: 1.329880, G loss: 0.807597, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312551, G loss: 0.811774, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.7143\n",
      "[84/1762] D loss: 1.1610, G loss: 0.7994\n",
      "[164/1762] D loss: 1.4011, G loss: 0.7973\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7514\n",
      "[324/1762] D loss: 1.4148, G loss: 0.7065\n",
      "[404/1762] D loss: 1.3920, G loss: 0.7397\n",
      "[484/1762] D loss: 1.3906, G loss: 0.7945\n",
      "[564/1762] D loss: 1.3856, G loss: 0.7183\n",
      "[644/1762] D loss: 1.4175, G loss: 0.7173\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[804/1762] D loss: 1.3946, G loss: 0.7205\n",
      "[884/1762] D loss: 1.1539, G loss: 0.8668\n",
      "[964/1762] D loss: 1.3956, G loss: 0.6094\n",
      "[1044/1762] D loss: 1.4333, G loss: 0.8536\n",
      "[1124/1762] D loss: 1.3961, G loss: 0.7048\n",
      "[1204/1762] D loss: 1.4039, G loss: 0.6920\n",
      "[1284/1762] D loss: 1.4690, G loss: 0.5951\n",
      "[1364/1762] D loss: 1.3653, G loss: 0.7547\n",
      "[1444/1762] D loss: 1.3964, G loss: 0.7379\n",
      "[1524/1762] D loss: 1.4079, G loss: 0.7971\n",
      "[1604/1762] D loss: 1.1878, G loss: 0.7498\n",
      "[1684/1762] D loss: 1.3963, G loss: 0.7553\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.7160\n",
      "train error: \n",
      " D loss: 1.328566, G loss: 0.709414, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 67.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312639, G loss: 0.713940, D accuracy: 53.8%, cell accuracy: 99.5%, board accuracy: 62.5% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4121, G loss: 0.6433\n",
      "[84/1762] D loss: 1.4171, G loss: 0.7991\n",
      "[164/1762] D loss: 1.3807, G loss: 0.6946\n",
      "[244/1762] D loss: 1.3585, G loss: 0.6651\n",
      "[324/1762] D loss: 1.1560, G loss: 0.8441\n",
      "[404/1762] D loss: 1.4051, G loss: 0.7472\n",
      "[484/1762] D loss: 1.3955, G loss: 0.6252\n",
      "[564/1762] D loss: 1.1713, G loss: 0.7532\n",
      "[644/1762] D loss: 1.1372, G loss: 0.7628\n",
      "[724/1762] D loss: 1.1464, G loss: 0.8942\n",
      "[804/1762] D loss: 1.3833, G loss: 0.7576\n",
      "[884/1762] D loss: 1.3836, G loss: 0.6758\n",
      "[964/1762] D loss: 1.1612, G loss: 0.9097\n",
      "[1044/1762] D loss: 1.3930, G loss: 0.6899\n",
      "[1124/1762] D loss: 1.1592, G loss: 0.8064\n",
      "[1204/1762] D loss: 1.3944, G loss: 0.6319\n",
      "[1284/1762] D loss: 1.1666, G loss: 0.8222\n",
      "[1364/1762] D loss: 1.4007, G loss: 0.7980\n",
      "[1444/1762] D loss: 1.3979, G loss: 0.6355\n",
      "[1524/1762] D loss: 1.1552, G loss: 0.9467\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.5951\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.7566\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6457\n",
      "train error: \n",
      " D loss: 1.331998, G loss: 0.704090, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314663, G loss: 0.711053, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3759, G loss: 0.7044\n",
      "[84/1762] D loss: 1.1694, G loss: 0.7307\n",
      "[164/1762] D loss: 1.3964, G loss: 0.8891\n",
      "[244/1762] D loss: 1.4059, G loss: 0.7962\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6334\n",
      "[404/1762] D loss: 1.3905, G loss: 0.6490\n",
      "[484/1762] D loss: 1.3886, G loss: 0.7596\n",
      "[564/1762] D loss: 1.3890, G loss: 0.6375\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7101\n",
      "[724/1762] D loss: 1.3924, G loss: 0.7436\n",
      "[804/1762] D loss: 1.3933, G loss: 0.6309\n",
      "[884/1762] D loss: 1.4405, G loss: 0.6933\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6667\n",
      "[1044/1762] D loss: 1.3917, G loss: 0.6769\n",
      "[1124/1762] D loss: 1.1732, G loss: 0.7512\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6856\n",
      "[1284/1762] D loss: 1.4046, G loss: 0.8059\n",
      "[1364/1762] D loss: 1.3923, G loss: 0.6862\n",
      "[1444/1762] D loss: 1.1476, G loss: 0.8741\n",
      "[1524/1762] D loss: 1.3917, G loss: 0.7148\n",
      "[1604/1762] D loss: 1.3897, G loss: 0.7832\n",
      "[1684/1762] D loss: 1.4014, G loss: 0.7330\n",
      "[1762/1762] D loss: 1.4049, G loss: 0.7382\n",
      "train error: \n",
      " D loss: 1.328031, G loss: 0.707014, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311189, G loss: 0.714461, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.6298\n",
      "[84/1762] D loss: 1.3906, G loss: 0.7531\n",
      "[164/1762] D loss: 1.3916, G loss: 0.7305\n",
      "[244/1762] D loss: 1.1682, G loss: 0.7555\n",
      "[324/1762] D loss: 1.3805, G loss: 0.7546\n",
      "[404/1762] D loss: 1.3954, G loss: 0.7711\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7288\n",
      "[564/1762] D loss: 1.3956, G loss: 0.6920\n",
      "[644/1762] D loss: 1.4044, G loss: 0.6957\n",
      "[724/1762] D loss: 1.3882, G loss: 0.7156\n",
      "[804/1762] D loss: 1.2113, G loss: 0.9681\n",
      "[884/1762] D loss: 1.1577, G loss: 0.7815\n",
      "[964/1762] D loss: 1.2047, G loss: 0.8424\n",
      "[1044/1762] D loss: 1.3582, G loss: 0.6539\n",
      "[1124/1762] D loss: 1.3952, G loss: 0.8562\n",
      "[1204/1762] D loss: 1.3892, G loss: 0.6481\n",
      "[1284/1762] D loss: 1.1487, G loss: 0.9276\n",
      "[1364/1762] D loss: 1.3959, G loss: 0.7191\n",
      "[1444/1762] D loss: 1.3900, G loss: 0.7222\n",
      "[1524/1762] D loss: 1.4064, G loss: 0.5984\n",
      "[1604/1762] D loss: 1.3897, G loss: 0.7458\n",
      "[1684/1762] D loss: 1.3668, G loss: 0.6670\n",
      "[1762/1762] D loss: 1.3620, G loss: 0.6159\n",
      "train error: \n",
      " D loss: 1.326108, G loss: 0.675693, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310447, G loss: 0.684008, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1320, G loss: 0.7937\n",
      "[84/1762] D loss: 1.1244, G loss: 0.7828\n",
      "[164/1762] D loss: 1.4128, G loss: 0.8113\n",
      "[244/1762] D loss: 1.4162, G loss: 0.7928\n",
      "[324/1762] D loss: 1.3366, G loss: 0.6747\n",
      "[404/1762] D loss: 1.1610, G loss: 0.7303\n",
      "[484/1762] D loss: 1.3746, G loss: 0.7592\n",
      "[564/1762] D loss: 1.1618, G loss: 0.8158\n",
      "[644/1762] D loss: 1.3257, G loss: 0.7685\n",
      "[724/1762] D loss: 1.3921, G loss: 0.7479\n",
      "[804/1762] D loss: 1.3887, G loss: 0.6525\n",
      "[884/1762] D loss: 1.3883, G loss: 0.7748\n",
      "[964/1762] D loss: 1.4034, G loss: 0.6922\n",
      "[1044/1762] D loss: 1.3740, G loss: 0.7463\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.7521\n",
      "[1204/1762] D loss: 1.3979, G loss: 0.6309\n",
      "[1284/1762] D loss: 1.3930, G loss: 0.7691\n",
      "[1364/1762] D loss: 1.1075, G loss: 0.9769\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.7267\n",
      "[1524/1762] D loss: 1.3742, G loss: 0.7053\n",
      "[1604/1762] D loss: 1.1130, G loss: 0.8630\n",
      "[1684/1762] D loss: 1.4272, G loss: 0.8339\n",
      "[1762/1762] D loss: 1.3902, G loss: 0.7110\n",
      "train error: \n",
      " D loss: 1.317702, G loss: 0.766988, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300132, G loss: 0.776773, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1484, G loss: 0.7957\n",
      "[84/1762] D loss: 1.3947, G loss: 0.7575\n",
      "[164/1762] D loss: 1.3779, G loss: 0.6522\n",
      "[244/1762] D loss: 1.1475, G loss: 0.8598\n",
      "[324/1762] D loss: 1.3538, G loss: 0.7509\n",
      "[404/1762] D loss: 1.1181, G loss: 0.8248\n",
      "[484/1762] D loss: 1.3927, G loss: 0.7041\n",
      "[564/1762] D loss: 1.3919, G loss: 0.6199\n",
      "[644/1762] D loss: 1.3987, G loss: 0.7785\n",
      "[724/1762] D loss: 1.1623, G loss: 0.8046\n",
      "[804/1762] D loss: 1.3930, G loss: 0.7066\n",
      "[884/1762] D loss: 0.9316, G loss: 0.9235\n",
      "[964/1762] D loss: 1.1356, G loss: 0.9309\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.6168\n",
      "[1124/1762] D loss: 1.4043, G loss: 0.8213\n",
      "[1204/1762] D loss: 1.4123, G loss: 0.8065\n",
      "[1284/1762] D loss: 1.3982, G loss: 0.7376\n",
      "[1364/1762] D loss: 1.4053, G loss: 0.7900\n",
      "[1444/1762] D loss: 1.0931, G loss: 0.9718\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.6373\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6985\n",
      "[1684/1762] D loss: 1.4035, G loss: 0.6770\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.6865\n",
      "train error: \n",
      " D loss: 1.323686, G loss: 0.720789, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305838, G loss: 0.732120, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1620, G loss: 0.7522\n",
      "[84/1762] D loss: 1.3934, G loss: 0.6942\n",
      "[164/1762] D loss: 1.3691, G loss: 0.7608\n",
      "[244/1762] D loss: 1.1643, G loss: 0.7879\n",
      "[324/1762] D loss: 1.3910, G loss: 0.7502\n",
      "[404/1762] D loss: 1.1640, G loss: 0.8051\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6472\n",
      "[564/1762] D loss: 1.3887, G loss: 0.7305\n",
      "[644/1762] D loss: 1.3969, G loss: 0.7579\n",
      "[724/1762] D loss: 1.3714, G loss: 0.6883\n",
      "[804/1762] D loss: 1.4087, G loss: 0.9578\n",
      "[884/1762] D loss: 1.7183, G loss: 0.3064\n",
      "[964/1762] D loss: 1.2875, G loss: 0.7348\n",
      "[1044/1762] D loss: 1.4172, G loss: 0.8168\n",
      "[1124/1762] D loss: 1.4751, G loss: 0.6078\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.6362\n",
      "[1284/1762] D loss: 1.3914, G loss: 0.6175\n",
      "[1364/1762] D loss: 1.3951, G loss: 0.7762\n",
      "[1444/1762] D loss: 1.3842, G loss: 0.7336\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.6717\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6487\n",
      "[1684/1762] D loss: 1.3965, G loss: 0.7702\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7232\n",
      "train error: \n",
      " D loss: 1.360674, G loss: 0.729192, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358172, G loss: 0.732198, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3596, G loss: 0.6732\n",
      "[84/1762] D loss: 1.3949, G loss: 0.6465\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6891\n",
      "[244/1762] D loss: 1.2586, G loss: 0.7413\n",
      "[324/1762] D loss: 1.3830, G loss: 0.6831\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7236\n",
      "[484/1762] D loss: 1.2326, G loss: 0.7762\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6534\n",
      "[644/1762] D loss: 1.3889, G loss: 0.7215\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6736\n",
      "[804/1762] D loss: 1.3998, G loss: 0.8119\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6722\n",
      "[964/1762] D loss: 1.3903, G loss: 0.7512\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.6496\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6922\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.7240\n",
      "[1284/1762] D loss: 1.3964, G loss: 0.7878\n",
      "[1364/1762] D loss: 1.3760, G loss: 0.7247\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6991\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6991\n",
      "[1604/1762] D loss: 0.7564, G loss: 1.0115\n",
      "[1684/1762] D loss: 1.4021, G loss: 0.7883\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6359\n",
      "train error: \n",
      " D loss: 1.334365, G loss: 0.648850, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319695, G loss: 0.656866, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3996, G loss: 0.6576\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6896\n",
      "[164/1762] D loss: 1.1984, G loss: 0.8451\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7068\n",
      "[324/1762] D loss: 1.3800, G loss: 0.6849\n",
      "[404/1762] D loss: 1.1584, G loss: 0.8518\n",
      "[484/1762] D loss: 1.1381, G loss: 0.8502\n",
      "[564/1762] D loss: 1.3963, G loss: 0.7834\n",
      "[644/1762] D loss: 1.1573, G loss: 0.7489\n",
      "[724/1762] D loss: 1.3907, G loss: 0.7056\n",
      "[804/1762] D loss: 1.1665, G loss: 0.8353\n",
      "[884/1762] D loss: 1.1651, G loss: 0.7927\n",
      "[964/1762] D loss: 1.1655, G loss: 0.7450\n",
      "[1044/1762] D loss: 1.4019, G loss: 0.6029\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6656\n",
      "[1204/1762] D loss: 1.1848, G loss: 0.6977\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.7113\n",
      "[1364/1762] D loss: 1.3966, G loss: 0.6731\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7060\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7799\n",
      "[1604/1762] D loss: 1.1585, G loss: 0.8254\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.7481\n",
      "[1762/1762] D loss: 1.3949, G loss: 0.6385\n",
      "train error: \n",
      " D loss: 1.324080, G loss: 0.714094, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307691, G loss: 0.723436, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3963, G loss: 0.6872\n",
      "[84/1762] D loss: 1.3893, G loss: 0.7378\n",
      "[164/1762] D loss: 1.4132, G loss: 0.8260\n",
      "[244/1762] D loss: 1.1618, G loss: 0.9211\n",
      "[324/1762] D loss: 1.4149, G loss: 0.5954\n",
      "[404/1762] D loss: 1.3940, G loss: 0.7798\n",
      "[484/1762] D loss: 1.3982, G loss: 0.6277\n",
      "[564/1762] D loss: 1.3972, G loss: 0.8355\n",
      "[644/1762] D loss: 1.3998, G loss: 0.5958\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6699\n",
      "[804/1762] D loss: 1.1531, G loss: 0.8162\n",
      "[884/1762] D loss: 1.3960, G loss: 0.6826\n",
      "[964/1762] D loss: 1.1322, G loss: 0.7871\n",
      "[1044/1762] D loss: 1.3801, G loss: 0.7728\n",
      "[1124/1762] D loss: 1.4032, G loss: 0.8565\n",
      "[1204/1762] D loss: 1.3944, G loss: 0.6808\n",
      "[1284/1762] D loss: 1.3948, G loss: 0.7496\n",
      "[1364/1762] D loss: 1.3931, G loss: 0.6730\n",
      "[1444/1762] D loss: 1.4162, G loss: 0.8670\n",
      "[1524/1762] D loss: 1.1738, G loss: 0.8600\n",
      "[1604/1762] D loss: 1.3828, G loss: 0.7121\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.7329\n",
      "[1762/1762] D loss: 1.3940, G loss: 0.7396\n",
      "train error: \n",
      " D loss: 1.321472, G loss: 0.745089, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303197, G loss: 0.758158, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933, G loss: 0.7484\n",
      "[84/1762] D loss: 1.3976, G loss: 0.7771\n",
      "[164/1762] D loss: 1.1256, G loss: 0.8254\n",
      "[244/1762] D loss: 1.3894, G loss: 0.7042\n",
      "[324/1762] D loss: 1.3850, G loss: 0.6764\n",
      "[404/1762] D loss: 1.3944, G loss: 0.6766\n",
      "[484/1762] D loss: 1.3877, G loss: 0.7343\n",
      "[564/1762] D loss: 1.1586, G loss: 0.7705\n",
      "[644/1762] D loss: 1.4002, G loss: 0.8017\n",
      "[724/1762] D loss: 1.3819, G loss: 0.7091\n",
      "[804/1762] D loss: 1.3908, G loss: 0.7274\n",
      "[884/1762] D loss: 0.9104, G loss: 0.9767\n",
      "[964/1762] D loss: 1.0789, G loss: 1.1539\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.7917\n",
      "[1124/1762] D loss: 1.3962, G loss: 0.7948\n",
      "[1204/1762] D loss: 1.3914, G loss: 0.7488\n",
      "[1284/1762] D loss: 1.4050, G loss: 0.7452\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.6995\n",
      "[1444/1762] D loss: 1.4099, G loss: 0.8345\n",
      "[1524/1762] D loss: 1.1165, G loss: 0.8458\n",
      "[1604/1762] D loss: 1.1561, G loss: 0.7548\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.6442\n",
      "[1762/1762] D loss: 1.3996, G loss: 0.8037\n",
      "train error: \n",
      " D loss: 1.338493, G loss: 0.908259, D accuracy: 53.4%, cell accuracy: 99.6%, board accuracy: 73.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318046, G loss: 0.921677, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1496, G loss: 0.9868\n",
      "[84/1762] D loss: 1.4156, G loss: 0.7937\n",
      "[164/1762] D loss: 1.1279, G loss: 0.9556\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6647\n",
      "[324/1762] D loss: 1.1015, G loss: 0.9979\n",
      "[404/1762] D loss: 1.1571, G loss: 0.7723\n",
      "[484/1762] D loss: 1.8060, G loss: 1.0914\n",
      "[564/1762] D loss: 0.9451, G loss: 0.8602\n",
      "[644/1762] D loss: 1.5107, G loss: 0.7415\n",
      "[724/1762] D loss: 1.4193, G loss: 0.6092\n",
      "[804/1762] D loss: 1.3975, G loss: 0.7614\n",
      "[884/1762] D loss: 1.3977, G loss: 0.7544\n",
      "[964/1762] D loss: 1.2897, G loss: 0.7735\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6797\n",
      "[1124/1762] D loss: 1.3595, G loss: 0.7163\n",
      "[1204/1762] D loss: 1.2902, G loss: 0.7858\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6940\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.7048\n",
      "[1444/1762] D loss: 1.3833, G loss: 0.6693\n",
      "[1524/1762] D loss: 1.3954, G loss: 0.7061\n",
      "[1604/1762] D loss: 1.3709, G loss: 0.6985\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6979\n",
      "[1762/1762] D loss: 1.0228, G loss: 0.7355\n",
      "train error: \n",
      " D loss: 1.343741, G loss: 0.699261, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336749, G loss: 0.705770, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6933\n",
      "[84/1762] D loss: 1.3930, G loss: 0.7734\n",
      "[164/1762] D loss: 1.3851, G loss: 0.6773\n",
      "[244/1762] D loss: 1.3914, G loss: 0.6689\n",
      "[324/1762] D loss: 1.3906, G loss: 0.7084\n",
      "[404/1762] D loss: 1.3985, G loss: 0.7881\n",
      "[484/1762] D loss: 1.3932, G loss: 0.8123\n",
      "[564/1762] D loss: 1.4165, G loss: 0.8214\n",
      "[644/1762] D loss: 1.3980, G loss: 0.7999\n",
      "[724/1762] D loss: 1.4086, G loss: 0.7996\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6808\n",
      "[884/1762] D loss: 1.3913, G loss: 0.6642\n",
      "[964/1762] D loss: 1.2054, G loss: 0.6843\n",
      "[1044/1762] D loss: 1.2049, G loss: 0.7614\n",
      "[1124/1762] D loss: 1.3922, G loss: 0.7651\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.7277\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7558\n",
      "[1364/1762] D loss: 1.3732, G loss: 0.6958\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.7085\n",
      "[1524/1762] D loss: 1.1763, G loss: 0.8319\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.7836\n",
      "[1684/1762] D loss: 1.4567, G loss: 0.6636\n",
      "[1762/1762] D loss: 0.9624, G loss: 0.7989\n",
      "train error: \n",
      " D loss: 1.331514, G loss: 0.711079, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 77.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316871, G loss: 0.719683, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3531, G loss: 0.7127\n",
      "[84/1762] D loss: 1.3889, G loss: 0.6781\n",
      "[164/1762] D loss: 1.3923, G loss: 0.7630\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6204\n",
      "[324/1762] D loss: 0.9610, G loss: 0.9522\n",
      "[404/1762] D loss: 1.3825, G loss: 0.7091\n",
      "[484/1762] D loss: 1.1607, G loss: 0.7718\n",
      "[564/1762] D loss: 1.3840, G loss: 0.7403\n",
      "[644/1762] D loss: 1.1609, G loss: 0.7600\n",
      "[724/1762] D loss: 1.3965, G loss: 0.7613\n",
      "[804/1762] D loss: 1.1989, G loss: 0.8509\n",
      "[884/1762] D loss: 1.4035, G loss: 0.6532\n",
      "[964/1762] D loss: 1.3961, G loss: 0.6922\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.6885\n",
      "[1124/1762] D loss: 1.1481, G loss: 0.8034\n",
      "[1204/1762] D loss: 1.4302, G loss: 0.6498\n",
      "[1284/1762] D loss: 1.3902, G loss: 0.6785\n",
      "[1364/1762] D loss: 1.1284, G loss: 0.8717\n",
      "[1444/1762] D loss: 1.3380, G loss: 0.8234\n",
      "[1524/1762] D loss: 1.4058, G loss: 0.5681\n",
      "[1604/1762] D loss: 1.2657, G loss: 0.9194\n",
      "[1684/1762] D loss: 1.3979, G loss: 0.6573\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6935\n",
      "train error: \n",
      " D loss: 1.332110, G loss: 0.668191, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312119, G loss: 0.681615, D accuracy: 55.8%, cell accuracy: 99.5%, board accuracy: 62.0% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9591, G loss: 0.8270\n",
      "[84/1762] D loss: 1.3947, G loss: 0.7792\n",
      "[164/1762] D loss: 1.3760, G loss: 0.7209\n",
      "[244/1762] D loss: 1.3651, G loss: 0.6708\n",
      "[324/1762] D loss: 1.3884, G loss: 0.7036\n",
      "[404/1762] D loss: 1.3859, G loss: 0.7459\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7048\n",
      "[564/1762] D loss: 1.0932, G loss: 0.9518\n",
      "[644/1762] D loss: 1.3856, G loss: 0.7155\n",
      "[724/1762] D loss: 1.3821, G loss: 0.7203\n",
      "[804/1762] D loss: 1.3933, G loss: 0.7879\n",
      "[884/1762] D loss: 1.1458, G loss: 0.8588\n",
      "[964/1762] D loss: 1.3914, G loss: 0.7211\n",
      "[1044/1762] D loss: 1.3655, G loss: 0.6797\n",
      "[1124/1762] D loss: 1.3967, G loss: 0.8734\n",
      "[1204/1762] D loss: 1.3781, G loss: 0.6586\n",
      "[1284/1762] D loss: 1.3924, G loss: 0.7431\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7614\n",
      "[1444/1762] D loss: 1.4159, G loss: 0.7983\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.6480\n",
      "[1604/1762] D loss: 0.9524, G loss: 0.9143\n",
      "[1684/1762] D loss: 1.4068, G loss: 0.7718\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6949\n",
      "train error: \n",
      " D loss: 1.343476, G loss: 0.628749, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321906, G loss: 0.640786, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.7587\n",
      "[84/1762] D loss: 1.3854, G loss: 0.7516\n",
      "[164/1762] D loss: 1.3743, G loss: 0.7467\n",
      "[244/1762] D loss: 1.3430, G loss: 0.7419\n",
      "[324/1762] D loss: 1.2954, G loss: 0.7380\n",
      "[404/1762] D loss: 1.2077, G loss: 0.7196\n",
      "[484/1762] D loss: 1.0771, G loss: 0.7175\n",
      "[564/1762] D loss: 1.0495, G loss: 0.6970\n",
      "[644/1762] D loss: 1.0068, G loss: 0.7570\n",
      "[724/1762] D loss: 0.8197, G loss: 0.9629\n",
      "[804/1762] D loss: 0.7568, G loss: 1.0501\n",
      "[884/1762] D loss: 0.6410, G loss: 1.3451\n",
      "[964/1762] D loss: 0.5088, G loss: 1.5981\n",
      "[1044/1762] D loss: 0.4324, G loss: 1.7655\n",
      "[1124/1762] D loss: 0.2879, G loss: 2.1533\n",
      "[1204/1762] D loss: 0.3044, G loss: 2.3028\n",
      "[1284/1762] D loss: 0.4085, G loss: 2.7985\n",
      "[1364/1762] D loss: 0.2615, G loss: 3.0500\n",
      "[1444/1762] D loss: 0.3046, G loss: 3.0386\n",
      "[1524/1762] D loss: 0.4209, G loss: 2.8537\n",
      "[1604/1762] D loss: 0.1966, G loss: 3.5432\n",
      "[1684/1762] D loss: 0.2673, G loss: 3.7573\n",
      "[1762/1762] D loss: 0.6661, G loss: 3.1990\n",
      "train error: \n",
      " D loss: 0.327396, G loss: 3.279561, D accuracy: 92.6%, cell accuracy: 72.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.336678, G loss: 3.334133, D accuracy: 92.3%, cell accuracy: 71.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4341, G loss: 3.5709\n",
      "[84/1762] D loss: 0.3801, G loss: 3.4270\n",
      "[164/1762] D loss: 0.2649, G loss: 3.4216\n",
      "[244/1762] D loss: 0.3025, G loss: 3.8348\n",
      "[324/1762] D loss: 0.4157, G loss: 3.7748\n",
      "[404/1762] D loss: 0.2228, G loss: 3.9855\n",
      "[484/1762] D loss: 0.2689, G loss: 3.5548\n",
      "[564/1762] D loss: 0.4505, G loss: 4.5672\n",
      "[644/1762] D loss: 0.3843, G loss: 4.1115\n",
      "[724/1762] D loss: 0.4952, G loss: 4.7348\n",
      "[804/1762] D loss: 0.4623, G loss: 3.9100\n",
      "[884/1762] D loss: 0.4775, G loss: 4.4592\n",
      "[964/1762] D loss: 0.2189, G loss: 3.9750\n",
      "[1044/1762] D loss: 0.5568, G loss: 4.0607\n",
      "[1124/1762] D loss: 0.2557, G loss: 4.3138\n",
      "[1204/1762] D loss: 0.3707, G loss: 3.6398\n",
      "[1284/1762] D loss: 0.4524, G loss: 4.2167\n",
      "[1364/1762] D loss: 0.1621, G loss: 4.0626\n",
      "[1444/1762] D loss: 0.1854, G loss: 3.9788\n",
      "[1524/1762] D loss: 0.4181, G loss: 4.2159\n",
      "[1604/1762] D loss: 0.4136, G loss: 4.2271\n",
      "[1684/1762] D loss: 0.4299, G loss: 4.5377\n",
      "[1762/1762] D loss: 0.5505, G loss: 4.4761\n",
      "train error: \n",
      " D loss: 0.327536, G loss: 4.118317, D accuracy: 99.2%, cell accuracy: 75.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.308881, G loss: 4.288599, D accuracy: 99.2%, cell accuracy: 76.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5973, G loss: 4.5540\n",
      "[84/1762] D loss: 0.2470, G loss: 3.7618\n",
      "[164/1762] D loss: 0.7045, G loss: 4.3542\n",
      "[244/1762] D loss: 0.4347, G loss: 4.8284\n",
      "[324/1762] D loss: 0.4687, G loss: 4.4576\n",
      "[404/1762] D loss: 0.4842, G loss: 4.1890\n",
      "[484/1762] D loss: 0.2979, G loss: 4.1086\n",
      "[564/1762] D loss: 0.2423, G loss: 3.4590\n",
      "[644/1762] D loss: 0.4588, G loss: 3.1477\n",
      "[724/1762] D loss: 0.2301, G loss: 4.2064\n",
      "[804/1762] D loss: 0.2313, G loss: 3.8387\n",
      "[884/1762] D loss: 0.4047, G loss: 3.9911\n",
      "[964/1762] D loss: 0.4501, G loss: 3.9698\n",
      "[1044/1762] D loss: 0.3976, G loss: 3.8723\n",
      "[1124/1762] D loss: 0.8448, G loss: 3.6552\n",
      "[1204/1762] D loss: 0.6433, G loss: 3.2846\n",
      "[1284/1762] D loss: 0.3605, G loss: 3.7725\n",
      "[1364/1762] D loss: 0.4924, G loss: 3.7862\n",
      "[1444/1762] D loss: 0.4404, G loss: 3.5752\n",
      "[1524/1762] D loss: 0.5526, G loss: 3.8173\n",
      "[1604/1762] D loss: 0.2773, G loss: 3.4056\n",
      "[1684/1762] D loss: 0.3338, G loss: 3.8929\n",
      "[1762/1762] D loss: 0.7964, G loss: 5.4358\n",
      "train error: \n",
      " D loss: 0.503851, G loss: 4.083675, D accuracy: 94.7%, cell accuracy: 82.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.527310, G loss: 4.094406, D accuracy: 93.4%, cell accuracy: 80.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3318, G loss: 4.1623\n",
      "[84/1762] D loss: 0.4558, G loss: 3.3420\n",
      "[164/1762] D loss: 0.2972, G loss: 4.1400\n",
      "[244/1762] D loss: 0.4462, G loss: 4.4979\n",
      "[324/1762] D loss: 0.4296, G loss: 3.4297\n",
      "[404/1762] D loss: 0.6012, G loss: 3.6075\n",
      "[484/1762] D loss: 0.5527, G loss: 3.4634\n",
      "[564/1762] D loss: 0.5190, G loss: 3.4893\n",
      "[644/1762] D loss: 0.3185, G loss: 3.8275\n",
      "[724/1762] D loss: 0.6426, G loss: 3.7079\n",
      "[804/1762] D loss: 0.7137, G loss: 3.8465\n",
      "[884/1762] D loss: 0.7127, G loss: 4.0485\n",
      "[964/1762] D loss: 0.4055, G loss: 3.9997\n",
      "[1044/1762] D loss: 0.6044, G loss: 3.4681\n",
      "[1124/1762] D loss: 0.3241, G loss: 3.8953\n",
      "[1204/1762] D loss: 0.5423, G loss: 3.3524\n",
      "[1284/1762] D loss: 1.7514, G loss: 4.7037\n",
      "[1364/1762] D loss: 0.2706, G loss: 3.6225\n",
      "[1444/1762] D loss: 0.5961, G loss: 3.6155\n",
      "[1524/1762] D loss: 0.5433, G loss: 3.6296\n",
      "[1604/1762] D loss: 0.5103, G loss: 3.4615\n",
      "[1684/1762] D loss: 0.3709, G loss: 3.6430\n",
      "[1762/1762] D loss: 0.5709, G loss: 5.6238\n",
      "train error: \n",
      " D loss: 0.713470, G loss: 3.826469, D accuracy: 86.7%, cell accuracy: 82.7%, board accuracy: 1.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.775429, G loss: 3.907127, D accuracy: 84.9%, cell accuracy: 83.1%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6668, G loss: 4.5243\n",
      "[84/1762] D loss: 0.5489, G loss: 3.4935\n",
      "[164/1762] D loss: 0.2730, G loss: 3.8480\n",
      "[244/1762] D loss: 0.5784, G loss: 3.8923\n",
      "[324/1762] D loss: 0.6245, G loss: 3.6768\n",
      "[404/1762] D loss: 1.0815, G loss: 3.0604\n",
      "[484/1762] D loss: 0.7884, G loss: 3.4662\n",
      "[564/1762] D loss: 0.4874, G loss: 3.3851\n",
      "[644/1762] D loss: 0.7096, G loss: 3.2121\n",
      "[724/1762] D loss: 0.6435, G loss: 2.9490\n",
      "[804/1762] D loss: 1.1138, G loss: 4.2356\n",
      "[884/1762] D loss: 0.8203, G loss: 2.7756\n",
      "[964/1762] D loss: 0.7978, G loss: 3.5554\n",
      "[1044/1762] D loss: 0.6488, G loss: 2.8922\n",
      "[1124/1762] D loss: 0.8023, G loss: 2.9965\n",
      "[1204/1762] D loss: 0.7271, G loss: 3.4157\n",
      "[1284/1762] D loss: 0.7859, G loss: 3.3146\n",
      "[1364/1762] D loss: 0.7572, G loss: 3.2738\n",
      "[1444/1762] D loss: 0.6490, G loss: 3.3440\n",
      "[1524/1762] D loss: 0.4661, G loss: 3.4384\n",
      "[1604/1762] D loss: 0.7209, G loss: 3.2310\n",
      "[1684/1762] D loss: 0.6389, G loss: 3.4626\n",
      "[1762/1762] D loss: 0.1951, G loss: 3.1967\n",
      "train error: \n",
      " D loss: 0.652711, G loss: 3.826446, D accuracy: 82.3%, cell accuracy: 72.3%, board accuracy: 8.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.673116, G loss: 3.610341, D accuracy: 81.0%, cell accuracy: 74.5%, board accuracy: 7.3% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7850, G loss: 2.7841\n",
      "[84/1762] D loss: 0.7016, G loss: 4.0359\n",
      "[164/1762] D loss: 0.5949, G loss: 4.3719\n",
      "[244/1762] D loss: 0.8430, G loss: 3.4824\n",
      "[324/1762] D loss: 0.8717, G loss: 3.7596\n",
      "[404/1762] D loss: 0.7722, G loss: 3.3453\n",
      "[484/1762] D loss: 0.7827, G loss: 3.6169\n",
      "[564/1762] D loss: 0.8214, G loss: 3.6157\n",
      "[644/1762] D loss: 0.7536, G loss: 3.9027\n",
      "[724/1762] D loss: 0.7405, G loss: 3.6484\n",
      "[804/1762] D loss: 0.9037, G loss: 2.9942\n",
      "[884/1762] D loss: 0.7426, G loss: 4.4907\n",
      "[964/1762] D loss: 0.8020, G loss: 3.5853\n",
      "[1044/1762] D loss: 0.5004, G loss: 3.9751\n",
      "[1124/1762] D loss: 1.4453, G loss: 3.4148\n",
      "[1204/1762] D loss: 0.8547, G loss: 3.6582\n",
      "[1284/1762] D loss: 0.8621, G loss: 3.2066\n",
      "[1364/1762] D loss: 0.8426, G loss: 2.9839\n",
      "[1444/1762] D loss: 1.1001, G loss: 3.0736\n",
      "[1524/1762] D loss: 0.9894, G loss: 4.1842\n",
      "[1604/1762] D loss: 0.5013, G loss: 3.6188\n",
      "[1684/1762] D loss: 1.3991, G loss: 3.0973\n",
      "[1762/1762] D loss: 0.7566, G loss: 3.6733\n",
      "train error: \n",
      " D loss: 1.267631, G loss: 2.527733, D accuracy: 64.9%, cell accuracy: 82.6%, board accuracy: 18.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.185374, G loss: 2.757576, D accuracy: 66.0%, cell accuracy: 80.6%, board accuracy: 11.6% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4259, G loss: 2.7974\n",
      "[84/1762] D loss: 1.2269, G loss: 3.1295\n",
      "[164/1762] D loss: 1.2078, G loss: 2.6499\n",
      "[244/1762] D loss: 1.1284, G loss: 3.8473\n",
      "[324/1762] D loss: 1.3425, G loss: 2.8386\n",
      "[404/1762] D loss: 1.3947, G loss: 2.9319\n",
      "[484/1762] D loss: 0.8379, G loss: 3.4049\n",
      "[564/1762] D loss: 0.6870, G loss: 2.4597\n",
      "[644/1762] D loss: 0.5877, G loss: 2.3964\n",
      "[724/1762] D loss: 0.7671, G loss: 2.4761\n",
      "[804/1762] D loss: 0.9962, G loss: 1.6447\n",
      "[884/1762] D loss: 0.6706, G loss: 1.9595\n",
      "[964/1762] D loss: 0.9201, G loss: 1.9144\n",
      "[1044/1762] D loss: 0.9644, G loss: 1.5299\n",
      "[1124/1762] D loss: 0.7393, G loss: 1.9492\n",
      "[1204/1762] D loss: 1.0755, G loss: 1.3041\n",
      "[1284/1762] D loss: 0.6487, G loss: 1.9781\n",
      "[1364/1762] D loss: 0.8026, G loss: 1.0006\n",
      "[1444/1762] D loss: 0.6416, G loss: 2.3868\n",
      "[1524/1762] D loss: 0.8948, G loss: 1.3254\n",
      "[1604/1762] D loss: 0.9754, G loss: 0.8797\n",
      "[1684/1762] D loss: 1.2652, G loss: 1.6308\n",
      "[1762/1762] D loss: 0.9004, G loss: 1.1180\n",
      "train error: \n",
      " D loss: 0.879679, G loss: 1.239123, D accuracy: 86.9%, cell accuracy: 99.1%, board accuracy: 31.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.871065, G loss: 1.304532, D accuracy: 87.5%, cell accuracy: 98.9%, board accuracy: 29.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8096, G loss: 1.2238\n",
      "[84/1762] D loss: 1.0732, G loss: 1.4348\n",
      "[164/1762] D loss: 0.7635, G loss: 1.5920\n",
      "[244/1762] D loss: 0.8420, G loss: 1.4840\n",
      "[324/1762] D loss: 1.2940, G loss: 1.4383\n",
      "[404/1762] D loss: 1.0359, G loss: 1.7329\n",
      "[484/1762] D loss: 1.0968, G loss: 0.5908\n",
      "[564/1762] D loss: 0.8430, G loss: 1.5022\n",
      "[644/1762] D loss: 0.9129, G loss: 1.4159\n",
      "[724/1762] D loss: 0.9979, G loss: 1.1864\n",
      "[804/1762] D loss: 0.9628, G loss: 0.8322\n",
      "[884/1762] D loss: 0.9259, G loss: 1.4010\n",
      "[964/1762] D loss: 1.0475, G loss: 1.5171\n",
      "[1044/1762] D loss: 0.9899, G loss: 1.3393\n",
      "[1124/1762] D loss: 0.9736, G loss: 1.4176\n",
      "[1204/1762] D loss: 0.8811, G loss: 1.2083\n",
      "[1284/1762] D loss: 1.3211, G loss: 0.7563\n",
      "[1364/1762] D loss: 1.0420, G loss: 1.2116\n",
      "[1444/1762] D loss: 1.2294, G loss: 1.2067\n",
      "[1524/1762] D loss: 1.0441, G loss: 0.7975\n",
      "[1604/1762] D loss: 1.0539, G loss: 1.1718\n",
      "[1684/1762] D loss: 1.4643, G loss: 0.6445\n",
      "[1762/1762] D loss: 1.0319, G loss: 1.0676\n",
      "train error: \n",
      " D loss: 1.186640, G loss: 1.519402, D accuracy: 64.9%, cell accuracy: 98.8%, board accuracy: 47.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.191010, G loss: 1.508001, D accuracy: 65.3%, cell accuracy: 98.8%, board accuracy: 44.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1649, G loss: 1.5606\n",
      "[84/1762] D loss: 0.9649, G loss: 1.3872\n",
      "[164/1762] D loss: 1.5688, G loss: 0.3404\n",
      "[244/1762] D loss: 1.1974, G loss: 1.0595\n",
      "[324/1762] D loss: 1.2809, G loss: 0.7687\n",
      "[404/1762] D loss: 1.6880, G loss: 1.3228\n",
      "[484/1762] D loss: 1.4310, G loss: 0.9078\n",
      "[564/1762] D loss: 1.3711, G loss: 0.4614\n",
      "[644/1762] D loss: 1.2039, G loss: 0.7834\n",
      "[724/1762] D loss: 1.1369, G loss: 0.8106\n",
      "[804/1762] D loss: 1.2792, G loss: 0.6370\n",
      "[884/1762] D loss: 1.2971, G loss: 1.2178\n",
      "[964/1762] D loss: 1.3275, G loss: 0.9396\n",
      "[1044/1762] D loss: 1.1941, G loss: 0.6933\n",
      "[1124/1762] D loss: 1.1480, G loss: 0.7495\n",
      "[1204/1762] D loss: 1.3417, G loss: 0.9090\n",
      "[1284/1762] D loss: 1.4166, G loss: 0.6497\n",
      "[1364/1762] D loss: 1.2957, G loss: 0.5719\n",
      "[1444/1762] D loss: 1.1838, G loss: 0.7722\n",
      "[1524/1762] D loss: 0.9040, G loss: 1.1276\n",
      "[1604/1762] D loss: 1.1332, G loss: 1.0510\n",
      "[1684/1762] D loss: 1.1440, G loss: 0.9239\n",
      "[1762/1762] D loss: 1.2020, G loss: 1.0040\n",
      "train error: \n",
      " D loss: 1.279929, G loss: 0.922831, D accuracy: 64.7%, cell accuracy: 99.5%, board accuracy: 55.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292720, G loss: 0.914569, D accuracy: 63.7%, cell accuracy: 99.5%, board accuracy: 52.3% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1379, G loss: 1.2653\n",
      "[84/1762] D loss: 1.3780, G loss: 1.1911\n",
      "[164/1762] D loss: 1.0032, G loss: 0.9364\n",
      "[244/1762] D loss: 1.6123, G loss: 0.7998\n",
      "[324/1762] D loss: 1.3073, G loss: 0.5941\n",
      "[404/1762] D loss: 1.1937, G loss: 1.2240\n",
      "[484/1762] D loss: 1.4119, G loss: 0.8474\n",
      "[564/1762] D loss: 1.3788, G loss: 0.7129\n",
      "[644/1762] D loss: 1.3369, G loss: 0.9386\n",
      "[724/1762] D loss: 1.2988, G loss: 0.8133\n",
      "[804/1762] D loss: 1.6701, G loss: 1.0760\n",
      "[884/1762] D loss: 1.2314, G loss: 1.2138\n",
      "[964/1762] D loss: 1.1491, G loss: 0.8525\n",
      "[1044/1762] D loss: 1.4225, G loss: 0.5175\n",
      "[1124/1762] D loss: 1.3024, G loss: 0.6875\n",
      "[1204/1762] D loss: 1.3326, G loss: 1.0086\n",
      "[1284/1762] D loss: 1.3263, G loss: 1.0208\n",
      "[1364/1762] D loss: 1.4198, G loss: 0.5666\n",
      "[1444/1762] D loss: 1.3532, G loss: 0.9939\n",
      "[1524/1762] D loss: 1.4817, G loss: 0.8429\n",
      "[1604/1762] D loss: 1.4765, G loss: 0.3110\n",
      "[1684/1762] D loss: 1.5594, G loss: 1.0892\n",
      "[1762/1762] D loss: 0.9876, G loss: 0.7650\n",
      "train error: \n",
      " D loss: 1.506264, G loss: 0.505727, D accuracy: 54.4%, cell accuracy: 99.3%, board accuracy: 52.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.526256, G loss: 0.524423, D accuracy: 54.4%, cell accuracy: 99.1%, board accuracy: 50.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8893, G loss: 0.3327\n",
      "[84/1762] D loss: 1.2369, G loss: 0.6934\n",
      "[164/1762] D loss: 1.3219, G loss: 0.8651\n",
      "[244/1762] D loss: 1.3009, G loss: 0.9676\n",
      "[324/1762] D loss: 1.0911, G loss: 0.8359\n",
      "[404/1762] D loss: 1.2706, G loss: 0.6142\n",
      "[484/1762] D loss: 1.5247, G loss: 0.5004\n",
      "[564/1762] D loss: 1.2505, G loss: 0.9749\n",
      "[644/1762] D loss: 1.3446, G loss: 0.5566\n",
      "[724/1762] D loss: 1.2970, G loss: 0.7252\n",
      "[804/1762] D loss: 1.3075, G loss: 0.6695\n",
      "[884/1762] D loss: 1.3179, G loss: 0.5201\n",
      "[964/1762] D loss: 1.3146, G loss: 0.9223\n",
      "[1044/1762] D loss: 1.3593, G loss: 0.6626\n",
      "[1124/1762] D loss: 1.6209, G loss: 0.8656\n",
      "[1204/1762] D loss: 0.9475, G loss: 0.9379\n",
      "[1284/1762] D loss: 1.6404, G loss: 1.3741\n",
      "[1364/1762] D loss: 1.3165, G loss: 0.5679\n",
      "[1444/1762] D loss: 1.2882, G loss: 0.6509\n",
      "[1524/1762] D loss: 1.3622, G loss: 0.7141\n",
      "[1604/1762] D loss: 1.2549, G loss: 0.6599\n",
      "[1684/1762] D loss: 1.5040, G loss: 0.5859\n",
      "[1762/1762] D loss: 1.1289, G loss: 1.2908\n",
      "train error: \n",
      " D loss: 1.316507, G loss: 0.935776, D accuracy: 59.5%, cell accuracy: 99.4%, board accuracy: 55.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327748, G loss: 0.936058, D accuracy: 57.4%, cell accuracy: 99.3%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3811, G loss: 0.5334\n",
      "[84/1762] D loss: 1.2190, G loss: 0.6092\n",
      "[164/1762] D loss: 1.2639, G loss: 0.8498\n",
      "[244/1762] D loss: 1.4036, G loss: 0.7385\n",
      "[324/1762] D loss: 1.4137, G loss: 0.5938\n",
      "[404/1762] D loss: 1.4535, G loss: 0.5048\n",
      "[484/1762] D loss: 1.5464, G loss: 0.9153\n",
      "[564/1762] D loss: 1.4140, G loss: 0.4514\n",
      "[644/1762] D loss: 1.3587, G loss: 0.9168\n",
      "[724/1762] D loss: 1.2862, G loss: 0.8694\n",
      "[804/1762] D loss: 1.3215, G loss: 0.7337\n",
      "[884/1762] D loss: 1.3063, G loss: 0.8100\n",
      "[964/1762] D loss: 1.3517, G loss: 0.6154\n",
      "[1044/1762] D loss: 1.3827, G loss: 0.7854\n",
      "[1124/1762] D loss: 1.4064, G loss: 0.7771\n",
      "[1204/1762] D loss: 1.3045, G loss: 0.5845\n",
      "[1284/1762] D loss: 1.4313, G loss: 1.2264\n",
      "[1364/1762] D loss: 1.4325, G loss: 0.8805\n",
      "[1444/1762] D loss: 1.3733, G loss: 0.6509\n",
      "[1524/1762] D loss: 1.3618, G loss: 0.8772\n",
      "[1604/1762] D loss: 1.3267, G loss: 0.8783\n",
      "[1684/1762] D loss: 1.4809, G loss: 0.5697\n",
      "[1762/1762] D loss: 1.2990, G loss: 0.8239\n",
      "train error: \n",
      " D loss: 1.284737, G loss: 1.102010, D accuracy: 61.0%, cell accuracy: 98.9%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307293, G loss: 1.059646, D accuracy: 58.5%, cell accuracy: 98.9%, board accuracy: 51.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3654, G loss: 0.7286\n",
      "[84/1762] D loss: 1.3548, G loss: 0.6648\n",
      "[164/1762] D loss: 1.4139, G loss: 1.0477\n",
      "[244/1762] D loss: 1.3929, G loss: 0.5798\n",
      "[324/1762] D loss: 1.3611, G loss: 0.8284\n",
      "[404/1762] D loss: 1.3972, G loss: 0.7467\n",
      "[484/1762] D loss: 1.4802, G loss: 0.5665\n",
      "[564/1762] D loss: 1.4062, G loss: 0.4949\n",
      "[644/1762] D loss: 1.3228, G loss: 0.6857\n",
      "[724/1762] D loss: 1.3946, G loss: 1.0572\n",
      "[804/1762] D loss: 1.2047, G loss: 0.8593\n",
      "[884/1762] D loss: 1.2863, G loss: 0.5432\n",
      "[964/1762] D loss: 1.4718, G loss: 0.9712\n",
      "[1044/1762] D loss: 1.1899, G loss: 0.8731\n",
      "[1124/1762] D loss: 1.4694, G loss: 0.6673\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.6644\n",
      "[1284/1762] D loss: 1.3194, G loss: 0.7421\n",
      "[1364/1762] D loss: 1.4376, G loss: 0.7754\n",
      "[1444/1762] D loss: 1.4928, G loss: 0.5455\n",
      "[1524/1762] D loss: 1.2117, G loss: 0.6812\n",
      "[1604/1762] D loss: 1.4844, G loss: 0.6391\n",
      "[1684/1762] D loss: 1.2527, G loss: 0.8868\n",
      "[1762/1762] D loss: 1.8164, G loss: 0.4068\n",
      "train error: \n",
      " D loss: 1.309151, G loss: 0.865561, D accuracy: 56.8%, cell accuracy: 99.2%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316097, G loss: 0.877447, D accuracy: 56.2%, cell accuracy: 99.2%, board accuracy: 53.6% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2964, G loss: 0.9019\n",
      "[84/1762] D loss: 1.2934, G loss: 0.8013\n",
      "[164/1762] D loss: 1.2915, G loss: 0.7971\n",
      "[244/1762] D loss: 1.3737, G loss: 0.6741\n",
      "[324/1762] D loss: 1.3993, G loss: 0.5072\n",
      "[404/1762] D loss: 1.3991, G loss: 0.8215\n",
      "[484/1762] D loss: 1.2316, G loss: 0.6362\n",
      "[564/1762] D loss: 1.3508, G loss: 0.6033\n",
      "[644/1762] D loss: 1.3004, G loss: 0.8929\n",
      "[724/1762] D loss: 1.2426, G loss: 0.8551\n",
      "[804/1762] D loss: 1.3474, G loss: 0.5315\n",
      "[884/1762] D loss: 1.2862, G loss: 0.7348\n",
      "[964/1762] D loss: 1.4172, G loss: 0.6635\n",
      "[1044/1762] D loss: 1.4915, G loss: 0.7506\n",
      "[1124/1762] D loss: 1.3629, G loss: 0.7006\n",
      "[1204/1762] D loss: 1.4062, G loss: 0.5394\n",
      "[1284/1762] D loss: 1.2874, G loss: 0.8503\n",
      "[1364/1762] D loss: 1.2659, G loss: 0.5850\n",
      "[1444/1762] D loss: 1.3666, G loss: 0.7194\n",
      "[1524/1762] D loss: 1.4264, G loss: 0.9830\n",
      "[1604/1762] D loss: 1.4475, G loss: 0.7488\n",
      "[1684/1762] D loss: 1.3533, G loss: 0.5163\n",
      "[1762/1762] D loss: 1.2791, G loss: 0.9028\n",
      "train error: \n",
      " D loss: 1.329756, G loss: 0.950183, D accuracy: 56.1%, cell accuracy: 99.4%, board accuracy: 60.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347670, G loss: 0.938960, D accuracy: 55.0%, cell accuracy: 99.3%, board accuracy: 59.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3025, G loss: 0.6522\n",
      "[84/1762] D loss: 1.3677, G loss: 0.6105\n",
      "[164/1762] D loss: 1.3487, G loss: 0.7566\n",
      "[244/1762] D loss: 1.4869, G loss: 0.5231\n",
      "[324/1762] D loss: 1.4068, G loss: 0.6455\n",
      "[404/1762] D loss: 1.4640, G loss: 0.5796\n",
      "[484/1762] D loss: 1.3361, G loss: 0.6928\n",
      "[564/1762] D loss: 1.3224, G loss: 0.7815\n",
      "[644/1762] D loss: 1.4280, G loss: 0.7835\n",
      "[724/1762] D loss: 1.3272, G loss: 0.6636\n",
      "[804/1762] D loss: 1.4586, G loss: 0.9733\n",
      "[884/1762] D loss: 1.2999, G loss: 1.0485\n",
      "[964/1762] D loss: 1.3447, G loss: 0.9426\n",
      "[1044/1762] D loss: 1.2410, G loss: 0.8424\n",
      "[1124/1762] D loss: 1.3982, G loss: 0.8707\n",
      "[1204/1762] D loss: 1.3718, G loss: 0.6556\n",
      "[1284/1762] D loss: 1.4574, G loss: 0.6092\n",
      "[1364/1762] D loss: 1.3548, G loss: 0.8219\n",
      "[1444/1762] D loss: 1.3745, G loss: 0.5302\n",
      "[1524/1762] D loss: 1.4097, G loss: 0.9847\n",
      "[1604/1762] D loss: 1.3619, G loss: 0.8422\n",
      "[1684/1762] D loss: 1.4538, G loss: 0.7171\n",
      "[1762/1762] D loss: 1.3517, G loss: 0.6537\n",
      "train error: \n",
      " D loss: 1.342127, G loss: 0.809950, D accuracy: 56.1%, cell accuracy: 99.5%, board accuracy: 68.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347445, G loss: 0.811942, D accuracy: 56.2%, cell accuracy: 99.5%, board accuracy: 64.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3264, G loss: 0.5966\n",
      "[84/1762] D loss: 1.4311, G loss: 0.6495\n",
      "[164/1762] D loss: 1.3640, G loss: 0.5700\n",
      "[244/1762] D loss: 1.4195, G loss: 0.6651\n",
      "[324/1762] D loss: 1.4062, G loss: 0.7503\n",
      "[404/1762] D loss: 1.3579, G loss: 0.6321\n",
      "[484/1762] D loss: 1.2699, G loss: 0.6950\n",
      "[564/1762] D loss: 1.3844, G loss: 0.6033\n",
      "[644/1762] D loss: 1.4592, G loss: 0.7427\n",
      "[724/1762] D loss: 1.3012, G loss: 0.6848\n",
      "[804/1762] D loss: 1.3883, G loss: 0.6624\n",
      "[884/1762] D loss: 1.3778, G loss: 0.6938\n",
      "[964/1762] D loss: 1.3757, G loss: 0.7262\n",
      "[1044/1762] D loss: 1.4091, G loss: 0.6171\n",
      "[1124/1762] D loss: 1.4129, G loss: 0.8009\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.9699\n",
      "[1284/1762] D loss: 1.3924, G loss: 0.6770\n",
      "[1364/1762] D loss: 1.4025, G loss: 0.5150\n",
      "[1444/1762] D loss: 1.3468, G loss: 0.6702\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.6134\n",
      "[1604/1762] D loss: 1.3967, G loss: 0.6503\n",
      "[1684/1762] D loss: 1.4660, G loss: 0.6359\n",
      "[1762/1762] D loss: 1.3458, G loss: 0.7102\n",
      "train error: \n",
      " D loss: 1.378528, G loss: 0.948902, D accuracy: 52.2%, cell accuracy: 99.6%, board accuracy: 69.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389317, G loss: 0.946580, D accuracy: 51.4%, cell accuracy: 99.5%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3423, G loss: 0.7864\n",
      "[84/1762] D loss: 1.3846, G loss: 0.7083\n",
      "[164/1762] D loss: 1.3784, G loss: 0.6725\n",
      "[244/1762] D loss: 1.3675, G loss: 0.5372\n",
      "[324/1762] D loss: 1.3743, G loss: 0.8848\n",
      "[404/1762] D loss: 1.3888, G loss: 0.8526\n",
      "[484/1762] D loss: 1.4008, G loss: 0.7777\n",
      "[564/1762] D loss: 1.3504, G loss: 0.6521\n",
      "[644/1762] D loss: 1.3990, G loss: 0.7222\n",
      "[724/1762] D loss: 1.4606, G loss: 0.6273\n",
      "[804/1762] D loss: 1.4389, G loss: 0.6106\n",
      "[884/1762] D loss: 1.3751, G loss: 0.9766\n",
      "[964/1762] D loss: 1.4684, G loss: 0.7775\n",
      "[1044/1762] D loss: 1.4039, G loss: 0.9129\n",
      "[1124/1762] D loss: 1.4556, G loss: 0.7155\n",
      "[1204/1762] D loss: 1.3262, G loss: 0.8624\n",
      "[1284/1762] D loss: 1.4456, G loss: 0.4844\n",
      "[1364/1762] D loss: 1.4316, G loss: 0.5896\n",
      "[1444/1762] D loss: 1.4387, G loss: 0.7151\n",
      "[1524/1762] D loss: 1.3543, G loss: 0.6331\n",
      "[1604/1762] D loss: 1.4022, G loss: 0.4918\n",
      "[1684/1762] D loss: 1.4128, G loss: 0.6638\n",
      "[1762/1762] D loss: 1.4596, G loss: 1.0032\n",
      "train error: \n",
      " D loss: 1.398610, G loss: 0.964906, D accuracy: 50.9%, cell accuracy: 99.6%, board accuracy: 72.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.407907, G loss: 0.958585, D accuracy: 50.3%, cell accuracy: 99.6%, board accuracy: 71.1% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4217, G loss: 0.8322\n",
      "[84/1762] D loss: 1.3803, G loss: 0.8835\n",
      "[164/1762] D loss: 1.4275, G loss: 0.6133\n",
      "[244/1762] D loss: 1.3889, G loss: 0.5950\n",
      "[324/1762] D loss: 1.3751, G loss: 0.5464\n",
      "[404/1762] D loss: 1.3567, G loss: 0.6082\n",
      "[484/1762] D loss: 1.3925, G loss: 1.0064\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6827\n",
      "[644/1762] D loss: 1.2975, G loss: 0.5977\n",
      "[724/1762] D loss: 1.3771, G loss: 0.7306\n",
      "[804/1762] D loss: 1.3815, G loss: 0.8334\n",
      "[884/1762] D loss: 1.2612, G loss: 0.9371\n",
      "[964/1762] D loss: 1.3711, G loss: 0.5645\n",
      "[1044/1762] D loss: 1.4182, G loss: 0.6754\n",
      "[1124/1762] D loss: 1.3299, G loss: 0.8016\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.6570\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.7282\n",
      "[1364/1762] D loss: 1.3815, G loss: 0.6096\n",
      "[1444/1762] D loss: 1.4086, G loss: 0.6743\n",
      "[1524/1762] D loss: 1.3746, G loss: 0.5334\n",
      "[1604/1762] D loss: 1.4386, G loss: 0.9976\n",
      "[1684/1762] D loss: 1.3784, G loss: 0.9203\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.7361\n",
      "train error: \n",
      " D loss: 1.371625, G loss: 0.652241, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375391, G loss: 0.646712, D accuracy: 53.2%, cell accuracy: 99.6%, board accuracy: 71.4% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3782, G loss: 0.5999\n",
      "[84/1762] D loss: 1.4623, G loss: 0.6817\n",
      "[164/1762] D loss: 1.3982, G loss: 0.8204\n",
      "[244/1762] D loss: 1.3600, G loss: 0.7155\n",
      "[324/1762] D loss: 1.4488, G loss: 0.6824\n",
      "[404/1762] D loss: 1.3715, G loss: 0.7365\n",
      "[484/1762] D loss: 1.4448, G loss: 0.4790\n",
      "[564/1762] D loss: 1.3249, G loss: 0.7314\n",
      "[644/1762] D loss: 1.3921, G loss: 0.7667\n",
      "[724/1762] D loss: 1.4897, G loss: 0.7483\n",
      "[804/1762] D loss: 1.3732, G loss: 0.6973\n",
      "[884/1762] D loss: 1.3976, G loss: 0.5475\n",
      "[964/1762] D loss: 1.3819, G loss: 0.5764\n",
      "[1044/1762] D loss: 1.3712, G loss: 0.8750\n",
      "[1124/1762] D loss: 1.3717, G loss: 0.9430\n",
      "[1204/1762] D loss: 1.4309, G loss: 0.7155\n",
      "[1284/1762] D loss: 1.4021, G loss: 0.7631\n",
      "[1364/1762] D loss: 1.4050, G loss: 0.8856\n",
      "[1444/1762] D loss: 1.3835, G loss: 0.8470\n",
      "[1524/1762] D loss: 1.3217, G loss: 0.7222\n",
      "[1604/1762] D loss: 1.4745, G loss: 0.6927\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.8754\n",
      "[1762/1762] D loss: 1.1225, G loss: 0.6637\n",
      "train error: \n",
      " D loss: 1.410161, G loss: 0.543679, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.414734, G loss: 0.543844, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4262, G loss: 0.5865\n",
      "[84/1762] D loss: 1.3855, G loss: 0.7112\n",
      "[164/1762] D loss: 1.4485, G loss: 1.0511\n",
      "[244/1762] D loss: 1.4125, G loss: 0.8043\n",
      "[324/1762] D loss: 1.3722, G loss: 0.8947\n",
      "[404/1762] D loss: 1.3733, G loss: 0.7809\n",
      "[484/1762] D loss: 1.4317, G loss: 0.7686\n",
      "[564/1762] D loss: 1.3359, G loss: 0.6891\n",
      "[644/1762] D loss: 1.4006, G loss: 0.7674\n",
      "[724/1762] D loss: 1.4052, G loss: 0.8074\n",
      "[804/1762] D loss: 1.3782, G loss: 0.6884\n",
      "[884/1762] D loss: 1.4332, G loss: 0.8294\n",
      "[964/1762] D loss: 1.3517, G loss: 0.8695\n",
      "[1044/1762] D loss: 1.4306, G loss: 0.8096\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.8935\n",
      "[1204/1762] D loss: 1.3815, G loss: 0.6993\n",
      "[1284/1762] D loss: 1.3806, G loss: 0.7118\n",
      "[1364/1762] D loss: 1.4256, G loss: 0.5654\n",
      "[1444/1762] D loss: 1.3213, G loss: 0.6951\n",
      "[1524/1762] D loss: 1.4198, G loss: 0.5863\n",
      "[1604/1762] D loss: 1.4217, G loss: 0.6081\n",
      "[1684/1762] D loss: 1.3260, G loss: 0.6331\n",
      "[1762/1762] D loss: 1.3967, G loss: 0.8146\n",
      "train error: \n",
      " D loss: 1.384839, G loss: 0.827031, D accuracy: 51.8%, cell accuracy: 99.7%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388205, G loss: 0.832448, D accuracy: 51.7%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4493, G loss: 0.7346\n",
      "[84/1762] D loss: 1.3801, G loss: 0.9231\n",
      "[164/1762] D loss: 1.4321, G loss: 0.7170\n",
      "[244/1762] D loss: 1.2816, G loss: 0.6223\n",
      "[324/1762] D loss: 1.4162, G loss: 0.7186\n",
      "[404/1762] D loss: 1.3265, G loss: 0.7794\n",
      "[484/1762] D loss: 1.3565, G loss: 0.7506\n",
      "[564/1762] D loss: 1.4013, G loss: 0.6739\n",
      "[644/1762] D loss: 1.4004, G loss: 0.7159\n",
      "[724/1762] D loss: 1.4237, G loss: 0.7215\n",
      "[804/1762] D loss: 1.3823, G loss: 0.6633\n",
      "[884/1762] D loss: 1.4062, G loss: 0.6864\n",
      "[964/1762] D loss: 1.3970, G loss: 0.6471\n",
      "[1044/1762] D loss: 1.3888, G loss: 0.7812\n",
      "[1124/1762] D loss: 1.3455, G loss: 0.8109\n",
      "[1204/1762] D loss: 1.4544, G loss: 0.9401\n",
      "[1284/1762] D loss: 1.4071, G loss: 0.7938\n",
      "[1364/1762] D loss: 1.3568, G loss: 0.7526\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.6318\n",
      "[1524/1762] D loss: 1.3826, G loss: 0.7576\n",
      "[1604/1762] D loss: 1.3506, G loss: 0.7436\n",
      "[1684/1762] D loss: 1.3657, G loss: 0.8270\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.7475\n",
      "train error: \n",
      " D loss: 1.371094, G loss: 0.762199, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372995, G loss: 0.765888, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3825, G loss: 0.7025\n",
      "[84/1762] D loss: 1.4084, G loss: 0.8083\n",
      "[164/1762] D loss: 1.3945, G loss: 0.8490\n",
      "[244/1762] D loss: 1.3614, G loss: 0.8106\n",
      "[324/1762] D loss: 1.3922, G loss: 0.8412\n",
      "[404/1762] D loss: 1.4037, G loss: 0.7276\n",
      "[484/1762] D loss: 1.3244, G loss: 0.7623\n",
      "[564/1762] D loss: 1.4171, G loss: 0.7705\n",
      "[644/1762] D loss: 1.3847, G loss: 0.6850\n",
      "[724/1762] D loss: 1.3637, G loss: 0.9272\n",
      "[804/1762] D loss: 1.3934, G loss: 0.7949\n",
      "[884/1762] D loss: 1.3910, G loss: 0.7935\n",
      "[964/1762] D loss: 1.3843, G loss: 0.7249\n",
      "[1044/1762] D loss: 1.3943, G loss: 0.7421\n",
      "[1124/1762] D loss: 1.3953, G loss: 0.7468\n",
      "[1204/1762] D loss: 1.3813, G loss: 0.6257\n",
      "[1284/1762] D loss: 1.3679, G loss: 0.7282\n",
      "[1364/1762] D loss: 1.4056, G loss: 0.7796\n",
      "[1444/1762] D loss: 1.4752, G loss: 0.5579\n",
      "[1524/1762] D loss: 1.3814, G loss: 0.7449\n",
      "[1604/1762] D loss: 1.4052, G loss: 0.8354\n",
      "[1684/1762] D loss: 1.3824, G loss: 0.6826\n",
      "[1762/1762] D loss: 1.3777, G loss: 0.7574\n",
      "train error: \n",
      " D loss: 1.324793, G loss: 1.050658, D accuracy: 52.4%, cell accuracy: 99.1%, board accuracy: 71.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326961, G loss: 1.054766, D accuracy: 52.7%, cell accuracy: 99.1%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3991, G loss: 0.8612\n",
      "[84/1762] D loss: 1.3416, G loss: 0.6137\n",
      "[164/1762] D loss: 1.4249, G loss: 0.5200\n",
      "[244/1762] D loss: 1.3652, G loss: 0.6367\n",
      "[324/1762] D loss: 1.3561, G loss: 0.7287\n",
      "[404/1762] D loss: 1.3985, G loss: 0.8117\n",
      "[484/1762] D loss: 1.3250, G loss: 0.6678\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7893\n",
      "[644/1762] D loss: 1.4269, G loss: 0.6021\n",
      "[724/1762] D loss: 1.3995, G loss: 0.7360\n",
      "[804/1762] D loss: 1.3745, G loss: 0.8092\n",
      "[884/1762] D loss: 1.2946, G loss: 0.7558\n",
      "[964/1762] D loss: 1.3845, G loss: 0.7661\n",
      "[1044/1762] D loss: 1.4005, G loss: 0.6714\n",
      "[1124/1762] D loss: 1.2355, G loss: 0.6710\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.6638\n",
      "[1284/1762] D loss: 1.3637, G loss: 0.6806\n",
      "[1364/1762] D loss: 1.3561, G loss: 0.7265\n",
      "[1444/1762] D loss: 1.4026, G loss: 0.7074\n",
      "[1524/1762] D loss: 1.2511, G loss: 0.6200\n",
      "[1604/1762] D loss: 1.4000, G loss: 0.8909\n",
      "[1684/1762] D loss: 1.4029, G loss: 0.7400\n",
      "[1762/1762] D loss: 1.3731, G loss: 0.7604\n",
      "train error: \n",
      " D loss: 1.351909, G loss: 0.812304, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 78.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352826, G loss: 0.819478, D accuracy: 54.2%, cell accuracy: 99.5%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4050, G loss: 0.6935\n",
      "[84/1762] D loss: 1.4048, G loss: 0.7663\n",
      "[164/1762] D loss: 1.4555, G loss: 0.8480\n",
      "[244/1762] D loss: 1.3223, G loss: 0.7917\n",
      "[324/1762] D loss: 1.3979, G loss: 0.7921\n",
      "[404/1762] D loss: 1.4327, G loss: 0.6741\n",
      "[484/1762] D loss: 1.4021, G loss: 0.6726\n",
      "[564/1762] D loss: 1.4510, G loss: 0.5725\n",
      "[644/1762] D loss: 1.3908, G loss: 0.7392\n",
      "[724/1762] D loss: 1.3169, G loss: 0.8111\n",
      "[804/1762] D loss: 1.4361, G loss: 0.5475\n",
      "[884/1762] D loss: 1.3945, G loss: 0.6976\n",
      "[964/1762] D loss: 1.3966, G loss: 0.6627\n",
      "[1044/1762] D loss: 1.4362, G loss: 0.7666\n",
      "[1124/1762] D loss: 1.3890, G loss: 0.7429\n",
      "[1204/1762] D loss: 1.2727, G loss: 1.0195\n",
      "[1284/1762] D loss: 1.3996, G loss: 0.8058\n",
      "[1364/1762] D loss: 1.4290, G loss: 0.7143\n",
      "[1444/1762] D loss: 1.4360, G loss: 0.8077\n",
      "[1524/1762] D loss: 1.3969, G loss: 0.7610\n",
      "[1604/1762] D loss: 1.4220, G loss: 0.5643\n",
      "[1684/1762] D loss: 1.3642, G loss: 0.6830\n",
      "[1762/1762] D loss: 1.3358, G loss: 0.7322\n",
      "train error: \n",
      " D loss: 1.379663, G loss: 0.595362, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379032, G loss: 0.597553, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4287, G loss: 0.6551\n",
      "[84/1762] D loss: 1.4008, G loss: 0.8473\n",
      "[164/1762] D loss: 1.3412, G loss: 0.6861\n",
      "[244/1762] D loss: 1.3569, G loss: 0.5717\n",
      "[324/1762] D loss: 1.3789, G loss: 0.5443\n",
      "[404/1762] D loss: 1.3839, G loss: 0.7354\n",
      "[484/1762] D loss: 1.3632, G loss: 0.6478\n",
      "[564/1762] D loss: 1.3226, G loss: 0.7146\n",
      "[644/1762] D loss: 1.3298, G loss: 0.8853\n",
      "[724/1762] D loss: 1.4015, G loss: 0.8179\n",
      "[804/1762] D loss: 1.3758, G loss: 0.6416\n",
      "[884/1762] D loss: 1.3911, G loss: 0.8011\n",
      "[964/1762] D loss: 1.3922, G loss: 0.8333\n",
      "[1044/1762] D loss: 1.4035, G loss: 0.7691\n",
      "[1124/1762] D loss: 1.4036, G loss: 0.5830\n",
      "[1204/1762] D loss: 1.4088, G loss: 0.5739\n",
      "[1284/1762] D loss: 1.3573, G loss: 0.8349\n",
      "[1364/1762] D loss: 1.4095, G loss: 0.8608\n",
      "[1444/1762] D loss: 1.4016, G loss: 0.7941\n",
      "[1524/1762] D loss: 1.3790, G loss: 0.7843\n",
      "[1604/1762] D loss: 1.3988, G loss: 0.6114\n",
      "[1684/1762] D loss: 1.4145, G loss: 0.8333\n",
      "[1762/1762] D loss: 1.3811, G loss: 0.7279\n",
      "train error: \n",
      " D loss: 1.356951, G loss: 0.864449, D accuracy: 52.4%, cell accuracy: 99.6%, board accuracy: 79.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363162, G loss: 0.856891, D accuracy: 51.9%, cell accuracy: 99.6%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.7003\n",
      "[84/1762] D loss: 1.4943, G loss: 0.8271\n",
      "[164/1762] D loss: 1.4040, G loss: 0.6285\n",
      "[244/1762] D loss: 1.3945, G loss: 0.8148\n",
      "[324/1762] D loss: 1.3443, G loss: 0.8878\n",
      "[404/1762] D loss: 1.3922, G loss: 0.6621\n",
      "[484/1762] D loss: 1.4076, G loss: 0.5924\n",
      "[564/1762] D loss: 1.3914, G loss: 0.5033\n",
      "[644/1762] D loss: 1.3928, G loss: 0.5750\n",
      "[724/1762] D loss: 1.3302, G loss: 0.6930\n",
      "[804/1762] D loss: 1.3918, G loss: 0.5468\n",
      "[884/1762] D loss: 1.3819, G loss: 0.7040\n",
      "[964/1762] D loss: 1.4141, G loss: 0.7925\n",
      "[1044/1762] D loss: 1.3552, G loss: 0.7247\n",
      "[1124/1762] D loss: 1.4145, G loss: 0.7797\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.6850\n",
      "[1284/1762] D loss: 1.3164, G loss: 0.6555\n",
      "[1364/1762] D loss: 1.3993, G loss: 0.6860\n",
      "[1444/1762] D loss: 1.3989, G loss: 0.7414\n",
      "[1524/1762] D loss: 1.3858, G loss: 0.7201\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.8330\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.6617\n",
      "[1762/1762] D loss: 1.4108, G loss: 0.6037\n",
      "train error: \n",
      " D loss: 1.346932, G loss: 0.693066, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342346, G loss: 0.716534, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3301, G loss: 0.5815\n",
      "[84/1762] D loss: 1.3029, G loss: 0.7371\n",
      "[164/1762] D loss: 1.3118, G loss: 0.8193\n",
      "[244/1762] D loss: 1.3510, G loss: 0.6681\n",
      "[324/1762] D loss: 1.3986, G loss: 0.6971\n",
      "[404/1762] D loss: 1.3850, G loss: 0.7067\n",
      "[484/1762] D loss: 1.3360, G loss: 0.6613\n",
      "[564/1762] D loss: 1.4219, G loss: 0.6217\n",
      "[644/1762] D loss: 1.4061, G loss: 0.5587\n",
      "[724/1762] D loss: 1.4020, G loss: 0.7866\n",
      "[804/1762] D loss: 1.3981, G loss: 0.6386\n",
      "[884/1762] D loss: 1.3840, G loss: 0.6969\n",
      "[964/1762] D loss: 1.4274, G loss: 0.7390\n",
      "[1044/1762] D loss: 1.3598, G loss: 0.6907\n",
      "[1124/1762] D loss: 1.4153, G loss: 0.7683\n",
      "[1204/1762] D loss: 1.3923, G loss: 0.7545\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.7299\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.6171\n",
      "[1444/1762] D loss: 1.3903, G loss: 0.6911\n",
      "[1524/1762] D loss: 1.3695, G loss: 0.7082\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.7578\n",
      "[1684/1762] D loss: 1.4023, G loss: 0.5480\n",
      "[1762/1762] D loss: 1.3986, G loss: 0.6993\n",
      "train error: \n",
      " D loss: 1.346714, G loss: 0.804983, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 76.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344302, G loss: 0.807009, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 71.8% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3642, G loss: 0.7080\n",
      "[84/1762] D loss: 1.3901, G loss: 0.6347\n",
      "[164/1762] D loss: 1.3890, G loss: 0.5668\n",
      "[244/1762] D loss: 1.3891, G loss: 0.7019\n",
      "[324/1762] D loss: 1.3367, G loss: 0.6574\n",
      "[404/1762] D loss: 1.3402, G loss: 0.8041\n",
      "[484/1762] D loss: 1.4040, G loss: 0.6076\n",
      "[564/1762] D loss: 1.4142, G loss: 0.8553\n",
      "[644/1762] D loss: 1.4341, G loss: 0.8502\n",
      "[724/1762] D loss: 1.4025, G loss: 0.7706\n",
      "[804/1762] D loss: 1.3760, G loss: 0.7314\n",
      "[884/1762] D loss: 1.3937, G loss: 0.5418\n",
      "[964/1762] D loss: 1.3970, G loss: 0.6284\n",
      "[1044/1762] D loss: 1.4026, G loss: 0.6998\n",
      "[1124/1762] D loss: 1.3572, G loss: 0.7824\n",
      "[1204/1762] D loss: 1.3615, G loss: 0.7457\n",
      "[1284/1762] D loss: 1.3918, G loss: 0.7902\n",
      "[1364/1762] D loss: 1.3647, G loss: 0.8755\n",
      "[1444/1762] D loss: 1.3623, G loss: 0.8769\n",
      "[1524/1762] D loss: 1.3493, G loss: 0.7452\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.7237\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6769\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.7061\n",
      "train error: \n",
      " D loss: 1.348799, G loss: 0.811464, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350566, G loss: 0.796893, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.6979\n",
      "[84/1762] D loss: 1.3988, G loss: 0.7502\n",
      "[164/1762] D loss: 1.3819, G loss: 0.6913\n",
      "[244/1762] D loss: 1.3791, G loss: 0.8162\n",
      "[324/1762] D loss: 1.3838, G loss: 0.6596\n",
      "[404/1762] D loss: 1.3969, G loss: 0.7380\n",
      "[484/1762] D loss: 1.4105, G loss: 0.6773\n",
      "[564/1762] D loss: 1.3284, G loss: 0.5712\n",
      "[644/1762] D loss: 1.3607, G loss: 0.8150\n",
      "[724/1762] D loss: 1.3931, G loss: 0.8283\n",
      "[804/1762] D loss: 1.3086, G loss: 0.7655\n",
      "[884/1762] D loss: 1.3887, G loss: 0.6620\n",
      "[964/1762] D loss: 1.3634, G loss: 0.6399\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.6531\n",
      "[1124/1762] D loss: 1.4088, G loss: 0.7320\n",
      "[1204/1762] D loss: 1.3457, G loss: 0.8103\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6612\n",
      "[1364/1762] D loss: 1.3802, G loss: 0.6095\n",
      "[1444/1762] D loss: 1.4038, G loss: 0.6045\n",
      "[1524/1762] D loss: 1.3366, G loss: 0.6899\n",
      "[1604/1762] D loss: 1.3058, G loss: 0.7846\n",
      "[1684/1762] D loss: 1.3984, G loss: 0.8224\n",
      "[1762/1762] D loss: 1.4228, G loss: 0.9495\n",
      "train error: \n",
      " D loss: 1.414197, G loss: 0.984406, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 83.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409561, G loss: 0.994583, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4308, G loss: 0.7487\n",
      "[84/1762] D loss: 1.3660, G loss: 0.7883\n",
      "[164/1762] D loss: 1.3532, G loss: 0.6838\n",
      "[244/1762] D loss: 1.3570, G loss: 0.6356\n",
      "[324/1762] D loss: 1.3947, G loss: 0.7910\n",
      "[404/1762] D loss: 1.2920, G loss: 0.7558\n",
      "[484/1762] D loss: 1.3323, G loss: 0.7928\n",
      "[564/1762] D loss: 1.3834, G loss: 0.6906\n",
      "[644/1762] D loss: 1.3527, G loss: 0.8703\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6767\n",
      "[804/1762] D loss: 1.3645, G loss: 0.6383\n",
      "[884/1762] D loss: 1.4027, G loss: 0.6964\n",
      "[964/1762] D loss: 1.3798, G loss: 0.6892\n",
      "[1044/1762] D loss: 1.2944, G loss: 0.6608\n",
      "[1124/1762] D loss: 1.3777, G loss: 0.6359\n",
      "[1204/1762] D loss: 1.4080, G loss: 0.6410\n",
      "[1284/1762] D loss: 1.3117, G loss: 0.6718\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6611\n",
      "[1444/1762] D loss: 1.3720, G loss: 0.7165\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.7353\n",
      "[1604/1762] D loss: 1.3830, G loss: 0.7861\n",
      "[1684/1762] D loss: 1.3813, G loss: 0.6302\n",
      "[1762/1762] D loss: 1.3856, G loss: 1.0674\n",
      "train error: \n",
      " D loss: 1.475279, G loss: 1.116912, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.472779, G loss: 1.131191, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4721, G loss: 0.9189\n",
      "[84/1762] D loss: 1.3734, G loss: 0.8955\n",
      "[164/1762] D loss: 1.3996, G loss: 0.9825\n",
      "[244/1762] D loss: 1.3737, G loss: 0.8157\n",
      "[324/1762] D loss: 1.3951, G loss: 0.6124\n",
      "[404/1762] D loss: 1.3916, G loss: 0.6437\n",
      "[484/1762] D loss: 1.3641, G loss: 0.7134\n",
      "[564/1762] D loss: 1.3432, G loss: 0.5631\n",
      "[644/1762] D loss: 1.3879, G loss: 0.7066\n",
      "[724/1762] D loss: 1.3650, G loss: 0.5988\n",
      "[804/1762] D loss: 1.3978, G loss: 0.6663\n",
      "[884/1762] D loss: 1.3413, G loss: 0.7786\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6086\n",
      "[1044/1762] D loss: 1.3960, G loss: 0.5831\n",
      "[1124/1762] D loss: 1.3604, G loss: 0.8145\n",
      "[1204/1762] D loss: 1.3238, G loss: 0.7506\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.6200\n",
      "[1364/1762] D loss: 1.4042, G loss: 0.5887\n",
      "[1444/1762] D loss: 1.4123, G loss: 0.5988\n",
      "[1524/1762] D loss: 1.4541, G loss: 0.5296\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.6285\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.6631\n",
      "[1762/1762] D loss: 1.3656, G loss: 0.6432\n",
      "train error: \n",
      " D loss: 1.342100, G loss: 0.704762, D accuracy: 57.7%, cell accuracy: 99.6%, board accuracy: 78.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343209, G loss: 0.695811, D accuracy: 57.4%, cell accuracy: 99.6%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4091, G loss: 0.5955\n",
      "[84/1762] D loss: 1.3987, G loss: 0.8636\n",
      "[164/1762] D loss: 1.3893, G loss: 0.7282\n",
      "[244/1762] D loss: 1.3934, G loss: 0.6064\n",
      "[324/1762] D loss: 1.3983, G loss: 0.7399\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7585\n",
      "[484/1762] D loss: 1.2932, G loss: 0.8833\n",
      "[564/1762] D loss: 1.4098, G loss: 0.7756\n",
      "[644/1762] D loss: 1.3452, G loss: 0.8398\n",
      "[724/1762] D loss: 1.4155, G loss: 0.6256\n",
      "[804/1762] D loss: 1.3932, G loss: 0.6807\n",
      "[884/1762] D loss: 1.4072, G loss: 0.7000\n",
      "[964/1762] D loss: 1.3564, G loss: 0.8011\n",
      "[1044/1762] D loss: 1.4130, G loss: 0.5386\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.7416\n",
      "[1204/1762] D loss: 1.4180, G loss: 0.7848\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.6321\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6033\n",
      "[1444/1762] D loss: 1.3954, G loss: 0.8127\n",
      "[1524/1762] D loss: 1.3532, G loss: 0.7301\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6989\n",
      "[1684/1762] D loss: 1.3854, G loss: 0.8391\n",
      "[1762/1762] D loss: 1.4508, G loss: 0.5794\n",
      "train error: \n",
      " D loss: 1.363509, G loss: 0.674204, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359521, G loss: 0.676463, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.7944\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6752\n",
      "[164/1762] D loss: 1.3482, G loss: 0.7047\n",
      "[244/1762] D loss: 1.3248, G loss: 0.6881\n",
      "[324/1762] D loss: 1.4171, G loss: 0.7062\n",
      "[404/1762] D loss: 1.3447, G loss: 0.6512\n",
      "[484/1762] D loss: 1.3860, G loss: 0.7087\n",
      "[564/1762] D loss: 1.4423, G loss: 0.7758\n",
      "[644/1762] D loss: 1.4247, G loss: 0.7632\n",
      "[724/1762] D loss: 1.3716, G loss: 0.7928\n",
      "[804/1762] D loss: 1.3423, G loss: 0.7296\n",
      "[884/1762] D loss: 1.3318, G loss: 0.7721\n",
      "[964/1762] D loss: 1.3950, G loss: 0.6667\n",
      "[1044/1762] D loss: 1.3432, G loss: 0.6669\n",
      "[1124/1762] D loss: 1.3823, G loss: 0.6575\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6735\n",
      "[1284/1762] D loss: 1.3229, G loss: 0.8167\n",
      "[1364/1762] D loss: 1.3976, G loss: 0.8158\n",
      "[1444/1762] D loss: 1.2413, G loss: 0.9489\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.7708\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.8116\n",
      "[1684/1762] D loss: 1.3543, G loss: 0.8944\n",
      "[1762/1762] D loss: 1.3814, G loss: 0.7040\n",
      "train error: \n",
      " D loss: 1.339099, G loss: 0.758229, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337330, G loss: 0.753523, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3971, G loss: 0.7310\n",
      "[84/1762] D loss: 1.3237, G loss: 0.7810\n",
      "[164/1762] D loss: 1.3945, G loss: 0.6080\n",
      "[244/1762] D loss: 1.3928, G loss: 0.6768\n",
      "[324/1762] D loss: 1.3886, G loss: 0.6253\n",
      "[404/1762] D loss: 1.3734, G loss: 0.7894\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6567\n",
      "[564/1762] D loss: 1.3885, G loss: 0.7556\n",
      "[644/1762] D loss: 1.3954, G loss: 0.7120\n",
      "[724/1762] D loss: 1.3266, G loss: 0.6876\n",
      "[804/1762] D loss: 1.3469, G loss: 0.5651\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6173\n",
      "[964/1762] D loss: 1.3767, G loss: 0.6543\n",
      "[1044/1762] D loss: 1.4024, G loss: 0.7024\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.7335\n",
      "[1204/1762] D loss: 1.3965, G loss: 0.6853\n",
      "[1284/1762] D loss: 1.3907, G loss: 0.5910\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.6087\n",
      "[1444/1762] D loss: 1.3907, G loss: 0.6831\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7550\n",
      "[1604/1762] D loss: 1.4102, G loss: 0.7162\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.7247\n",
      "[1762/1762] D loss: 1.2722, G loss: 0.8586\n",
      "train error: \n",
      " D loss: 1.382028, G loss: 0.866168, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378348, G loss: 0.869300, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3088, G loss: 0.7516\n",
      "[84/1762] D loss: 1.3621, G loss: 0.8481\n",
      "[164/1762] D loss: 1.3886, G loss: 0.7112\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6771\n",
      "[324/1762] D loss: 1.4226, G loss: 0.6326\n",
      "[404/1762] D loss: 1.3557, G loss: 0.6613\n",
      "[484/1762] D loss: 1.3495, G loss: 0.6315\n",
      "[564/1762] D loss: 1.2298, G loss: 0.6952\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6398\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7076\n",
      "[804/1762] D loss: 1.3153, G loss: 0.7377\n",
      "[884/1762] D loss: 1.3956, G loss: 0.6457\n",
      "[964/1762] D loss: 1.3924, G loss: 0.7401\n",
      "[1044/1762] D loss: 1.3222, G loss: 0.7285\n",
      "[1124/1762] D loss: 1.3800, G loss: 0.7662\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6255\n",
      "[1284/1762] D loss: 1.3603, G loss: 0.7971\n",
      "[1364/1762] D loss: 1.3896, G loss: 0.7177\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.7257\n",
      "[1524/1762] D loss: 1.4091, G loss: 0.7621\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7451\n",
      "[1684/1762] D loss: 1.3821, G loss: 0.7011\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6317\n",
      "train error: \n",
      " D loss: 1.364732, G loss: 0.608263, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366450, G loss: 0.598941, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3624, G loss: 0.6498\n",
      "[84/1762] D loss: 1.4271, G loss: 0.6015\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6491\n",
      "[244/1762] D loss: 1.3922, G loss: 0.5885\n",
      "[324/1762] D loss: 1.4175, G loss: 0.8505\n",
      "[404/1762] D loss: 1.3909, G loss: 0.6669\n",
      "[484/1762] D loss: 1.2834, G loss: 0.7916\n",
      "[564/1762] D loss: 1.3947, G loss: 0.7035\n",
      "[644/1762] D loss: 1.3967, G loss: 0.6445\n",
      "[724/1762] D loss: 1.3934, G loss: 0.7908\n",
      "[804/1762] D loss: 1.3379, G loss: 0.7470\n",
      "[884/1762] D loss: 1.3463, G loss: 0.7592\n",
      "[964/1762] D loss: 1.3986, G loss: 0.7610\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.7669\n",
      "[1124/1762] D loss: 1.2390, G loss: 0.8597\n",
      "[1204/1762] D loss: 1.2520, G loss: 0.6824\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.5076\n",
      "[1364/1762] D loss: 1.3943, G loss: 0.7303\n",
      "[1444/1762] D loss: 1.3905, G loss: 0.7332\n",
      "[1524/1762] D loss: 1.4069, G loss: 0.8348\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.8388\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6396\n",
      "[1762/1762] D loss: 1.4019, G loss: 0.7943\n",
      "train error: \n",
      " D loss: 1.372638, G loss: 0.853693, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365675, G loss: 0.858339, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4178, G loss: 0.7006\n",
      "[84/1762] D loss: 1.3511, G loss: 0.8378\n",
      "[164/1762] D loss: 1.3907, G loss: 0.8409\n",
      "[244/1762] D loss: 1.3874, G loss: 0.8000\n",
      "[324/1762] D loss: 1.3119, G loss: 0.8508\n",
      "[404/1762] D loss: 1.2431, G loss: 0.9833\n",
      "[484/1762] D loss: 1.4116, G loss: 0.7753\n",
      "[564/1762] D loss: 1.4013, G loss: 0.6650\n",
      "[644/1762] D loss: 1.3884, G loss: 0.8525\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6190\n",
      "[804/1762] D loss: 1.2485, G loss: 0.8526\n",
      "[884/1762] D loss: 1.4058, G loss: 0.7114\n",
      "[964/1762] D loss: 1.3899, G loss: 0.7522\n",
      "[1044/1762] D loss: 1.3990, G loss: 0.6730\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.7026\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7614\n",
      "[1284/1762] D loss: 1.4030, G loss: 0.5981\n",
      "[1364/1762] D loss: 1.4005, G loss: 0.4935\n",
      "[1444/1762] D loss: 1.3930, G loss: 0.6392\n",
      "[1524/1762] D loss: 1.3936, G loss: 0.7656\n",
      "[1604/1762] D loss: 1.3282, G loss: 0.9487\n",
      "[1684/1762] D loss: 1.4214, G loss: 0.7986\n",
      "[1762/1762] D loss: 1.3826, G loss: 0.6087\n",
      "train error: \n",
      " D loss: 1.353129, G loss: 0.647118, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346608, G loss: 0.653180, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3932, G loss: 0.6000\n",
      "[84/1762] D loss: 1.4006, G loss: 0.6838\n",
      "[164/1762] D loss: 1.3068, G loss: 0.8706\n",
      "[244/1762] D loss: 1.2978, G loss: 0.6837\n",
      "[324/1762] D loss: 1.4214, G loss: 0.5849\n",
      "[404/1762] D loss: 1.4238, G loss: 0.6020\n",
      "[484/1762] D loss: 1.2070, G loss: 0.6953\n",
      "[564/1762] D loss: 1.2835, G loss: 0.6468\n",
      "[644/1762] D loss: 1.4018, G loss: 0.5868\n",
      "[724/1762] D loss: 1.3968, G loss: 0.6401\n",
      "[804/1762] D loss: 1.3179, G loss: 0.6647\n",
      "[884/1762] D loss: 1.3968, G loss: 0.7069\n",
      "[964/1762] D loss: 1.2896, G loss: 0.8883\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.7423\n",
      "[1124/1762] D loss: 1.2652, G loss: 0.8422\n",
      "[1204/1762] D loss: 1.3923, G loss: 0.6930\n",
      "[1284/1762] D loss: 1.3590, G loss: 0.7042\n",
      "[1364/1762] D loss: 1.1708, G loss: 0.8305\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.8400\n",
      "[1524/1762] D loss: 1.4249, G loss: 0.7027\n",
      "[1604/1762] D loss: 1.3851, G loss: 0.6990\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.8624\n",
      "[1762/1762] D loss: 1.1798, G loss: 0.8380\n",
      "train error: \n",
      " D loss: 1.357818, G loss: 0.768943, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350426, G loss: 0.776520, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959, G loss: 0.8070\n",
      "[84/1762] D loss: 1.4101, G loss: 0.7024\n",
      "[164/1762] D loss: 1.3784, G loss: 0.7013\n",
      "[244/1762] D loss: 1.4158, G loss: 0.7366\n",
      "[324/1762] D loss: 1.4090, G loss: 0.7346\n",
      "[404/1762] D loss: 1.0545, G loss: 0.9628\n",
      "[484/1762] D loss: 1.3597, G loss: 0.8022\n",
      "[564/1762] D loss: 1.3928, G loss: 0.6195\n",
      "[644/1762] D loss: 1.3941, G loss: 0.6865\n",
      "[724/1762] D loss: 1.3961, G loss: 0.6521\n",
      "[804/1762] D loss: 1.3956, G loss: 0.6949\n",
      "[884/1762] D loss: 1.4087, G loss: 0.8301\n",
      "[964/1762] D loss: 1.3956, G loss: 0.9094\n",
      "[1044/1762] D loss: 1.4093, G loss: 0.6686\n",
      "[1124/1762] D loss: 1.4340, G loss: 0.5509\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.6449\n",
      "[1284/1762] D loss: 1.3924, G loss: 0.6888\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.6412\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.6734\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.8146\n",
      "[1604/1762] D loss: 1.3055, G loss: 0.7370\n",
      "[1684/1762] D loss: 1.3899, G loss: 0.6690\n",
      "[1762/1762] D loss: 1.2009, G loss: 0.7547\n",
      "train error: \n",
      " D loss: 1.372389, G loss: 0.584089, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364168, G loss: 0.592222, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4260, G loss: 0.5564\n",
      "[84/1762] D loss: 1.2803, G loss: 0.7484\n",
      "[164/1762] D loss: 1.3897, G loss: 0.7596\n",
      "[244/1762] D loss: 1.3899, G loss: 0.8699\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7170\n",
      "[404/1762] D loss: 1.2801, G loss: 0.7122\n",
      "[484/1762] D loss: 1.3190, G loss: 0.8733\n",
      "[564/1762] D loss: 1.3995, G loss: 0.6596\n",
      "[644/1762] D loss: 1.3944, G loss: 0.8576\n",
      "[724/1762] D loss: 1.3931, G loss: 0.8017\n",
      "[804/1762] D loss: 1.3963, G loss: 0.7701\n",
      "[884/1762] D loss: 1.2714, G loss: 0.8652\n",
      "[964/1762] D loss: 1.4468, G loss: 0.6013\n",
      "[1044/1762] D loss: 1.4227, G loss: 0.5405\n",
      "[1124/1762] D loss: 1.3822, G loss: 0.5745\n",
      "[1204/1762] D loss: 1.2919, G loss: 0.8960\n",
      "[1284/1762] D loss: 1.4131, G loss: 0.8319\n",
      "[1364/1762] D loss: 1.1741, G loss: 0.8565\n",
      "[1444/1762] D loss: 1.2922, G loss: 0.8409\n",
      "[1524/1762] D loss: 1.1827, G loss: 0.8728\n",
      "[1604/1762] D loss: 1.3306, G loss: 0.8048\n",
      "[1684/1762] D loss: 1.3408, G loss: 0.7538\n",
      "[1762/1762] D loss: 1.4736, G loss: 0.8286\n",
      "train error: \n",
      " D loss: 1.336595, G loss: 0.732913, D accuracy: 57.5%, cell accuracy: 99.5%, board accuracy: 64.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330739, G loss: 0.729067, D accuracy: 58.3%, cell accuracy: 99.5%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2824, G loss: 0.6408\n",
      "[84/1762] D loss: 1.4101, G loss: 0.5849\n",
      "[164/1762] D loss: 1.4785, G loss: 0.7665\n",
      "[244/1762] D loss: 1.4020, G loss: 0.8100\n",
      "[324/1762] D loss: 1.4053, G loss: 0.7037\n",
      "[404/1762] D loss: 1.4012, G loss: 0.7578\n",
      "[484/1762] D loss: 1.4636, G loss: 0.6733\n",
      "[564/1762] D loss: 1.3907, G loss: 0.6353\n",
      "[644/1762] D loss: 1.3383, G loss: 0.8050\n",
      "[724/1762] D loss: 1.3952, G loss: 0.8344\n",
      "[804/1762] D loss: 1.4005, G loss: 0.7435\n",
      "[884/1762] D loss: 1.3933, G loss: 0.7123\n",
      "[964/1762] D loss: 1.4680, G loss: 0.4918\n",
      "[1044/1762] D loss: 1.4001, G loss: 0.7343\n",
      "[1124/1762] D loss: 1.4171, G loss: 0.7861\n",
      "[1204/1762] D loss: 1.3770, G loss: 0.7293\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6327\n",
      "[1364/1762] D loss: 1.2700, G loss: 0.8630\n",
      "[1444/1762] D loss: 1.4059, G loss: 0.7046\n",
      "[1524/1762] D loss: 1.3001, G loss: 0.8449\n",
      "[1604/1762] D loss: 1.4001, G loss: 0.7762\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6772\n",
      "[1762/1762] D loss: 1.3962, G loss: 0.6751\n",
      "train error: \n",
      " D loss: 1.355581, G loss: 0.687465, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344636, G loss: 0.699032, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958, G loss: 0.7461\n",
      "[84/1762] D loss: 1.1622, G loss: 0.7168\n",
      "[164/1762] D loss: 1.2899, G loss: 0.8117\n",
      "[244/1762] D loss: 1.4267, G loss: 0.9142\n",
      "[324/1762] D loss: 1.4036, G loss: 0.7208\n",
      "[404/1762] D loss: 1.2686, G loss: 0.7003\n",
      "[484/1762] D loss: 1.2790, G loss: 0.8894\n",
      "[564/1762] D loss: 1.4239, G loss: 0.6073\n",
      "[644/1762] D loss: 1.3921, G loss: 0.7015\n",
      "[724/1762] D loss: 1.2292, G loss: 0.7311\n",
      "[804/1762] D loss: 1.2914, G loss: 0.8276\n",
      "[884/1762] D loss: 1.3883, G loss: 0.6771\n",
      "[964/1762] D loss: 1.2528, G loss: 0.7511\n",
      "[1044/1762] D loss: 1.4098, G loss: 0.8103\n",
      "[1124/1762] D loss: 1.2282, G loss: 1.0458\n",
      "[1204/1762] D loss: 1.3929, G loss: 0.7445\n",
      "[1284/1762] D loss: 1.2601, G loss: 0.8432\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.7637\n",
      "[1444/1762] D loss: 1.2586, G loss: 0.9249\n",
      "[1524/1762] D loss: 1.3951, G loss: 0.6624\n",
      "[1604/1762] D loss: 1.3982, G loss: 0.5744\n",
      "[1684/1762] D loss: 1.4362, G loss: 0.7980\n",
      "[1762/1762] D loss: 1.3472, G loss: 0.8233\n",
      "train error: \n",
      " D loss: 1.355222, G loss: 0.713924, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344697, G loss: 0.721377, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3986, G loss: 0.7108\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6260\n",
      "[164/1762] D loss: 1.4074, G loss: 0.7449\n",
      "[244/1762] D loss: 1.2383, G loss: 0.9666\n",
      "[324/1762] D loss: 1.3233, G loss: 0.9229\n",
      "[404/1762] D loss: 1.2602, G loss: 0.7019\n",
      "[484/1762] D loss: 1.2939, G loss: 0.7652\n",
      "[564/1762] D loss: 1.4070, G loss: 0.6503\n",
      "[644/1762] D loss: 1.3909, G loss: 0.6900\n",
      "[724/1762] D loss: 1.4187, G loss: 0.6483\n",
      "[804/1762] D loss: 1.3940, G loss: 0.6700\n",
      "[884/1762] D loss: 1.3878, G loss: 0.9573\n",
      "[964/1762] D loss: 1.3860, G loss: 0.7497\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.6394\n",
      "[1124/1762] D loss: 1.4417, G loss: 0.9119\n",
      "[1204/1762] D loss: 1.3916, G loss: 0.7861\n",
      "[1284/1762] D loss: 1.2674, G loss: 0.7900\n",
      "[1364/1762] D loss: 1.4056, G loss: 0.7863\n",
      "[1444/1762] D loss: 1.5181, G loss: 0.8214\n",
      "[1524/1762] D loss: 1.4810, G loss: 0.6782\n",
      "[1604/1762] D loss: 1.4944, G loss: 0.6737\n",
      "[1684/1762] D loss: 1.3337, G loss: 0.5971\n",
      "[1762/1762] D loss: 1.3391, G loss: 0.7659\n",
      "train error: \n",
      " D loss: 1.325544, G loss: 0.659693, D accuracy: 60.3%, cell accuracy: 97.2%, board accuracy: 9.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320679, G loss: 0.668272, D accuracy: 60.8%, cell accuracy: 97.2%, board accuracy: 8.6% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3060, G loss: 0.5923\n",
      "[84/1762] D loss: 1.2253, G loss: 0.8305\n",
      "[164/1762] D loss: 1.4484, G loss: 0.7599\n",
      "[244/1762] D loss: 1.4018, G loss: 0.6201\n",
      "[324/1762] D loss: 1.4513, G loss: 0.8595\n",
      "[404/1762] D loss: 1.4384, G loss: 0.4454\n",
      "[484/1762] D loss: 1.3960, G loss: 0.7899\n",
      "[564/1762] D loss: 1.3966, G loss: 0.5862\n",
      "[644/1762] D loss: 1.4266, G loss: 0.7613\n",
      "[724/1762] D loss: 1.4020, G loss: 0.7574\n",
      "[804/1762] D loss: 1.4137, G loss: 0.7494\n",
      "[884/1762] D loss: 1.4006, G loss: 0.7284\n",
      "[964/1762] D loss: 1.3223, G loss: 0.6327\n",
      "[1044/1762] D loss: 1.4095, G loss: 0.7327\n",
      "[1124/1762] D loss: 1.3603, G loss: 0.7897\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7237\n",
      "[1284/1762] D loss: 1.3236, G loss: 0.6348\n",
      "[1364/1762] D loss: 1.3725, G loss: 0.7264\n",
      "[1444/1762] D loss: 1.3943, G loss: 0.7266\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.7035\n",
      "[1604/1762] D loss: 1.3019, G loss: 0.8149\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.7262\n",
      "[1762/1762] D loss: 1.1860, G loss: 0.8631\n",
      "train error: \n",
      " D loss: 1.364096, G loss: 0.653014, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 83.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356098, G loss: 0.659726, D accuracy: 56.4%, cell accuracy: 99.6%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.6765\n",
      "[84/1762] D loss: 1.3534, G loss: 0.9227\n",
      "[164/1762] D loss: 1.3987, G loss: 0.6319\n",
      "[244/1762] D loss: 1.3964, G loss: 0.6866\n",
      "[324/1762] D loss: 1.2162, G loss: 0.8209\n",
      "[404/1762] D loss: 1.3305, G loss: 0.7087\n",
      "[484/1762] D loss: 1.3946, G loss: 0.6839\n",
      "[564/1762] D loss: 1.3906, G loss: 0.6692\n",
      "[644/1762] D loss: 1.3949, G loss: 0.8010\n",
      "[724/1762] D loss: 1.4305, G loss: 0.6340\n",
      "[804/1762] D loss: 1.3943, G loss: 0.6007\n",
      "[884/1762] D loss: 1.4626, G loss: 0.7026\n",
      "[964/1762] D loss: 1.3520, G loss: 0.7273\n",
      "[1044/1762] D loss: 1.4005, G loss: 0.7268\n",
      "[1124/1762] D loss: 1.4743, G loss: 0.7232\n",
      "[1204/1762] D loss: 1.3679, G loss: 0.7543\n",
      "[1284/1762] D loss: 1.3784, G loss: 0.6987\n",
      "[1364/1762] D loss: 1.3332, G loss: 0.6713\n",
      "[1444/1762] D loss: 1.3743, G loss: 0.6365\n",
      "[1524/1762] D loss: 1.4127, G loss: 0.8261\n",
      "[1604/1762] D loss: 1.4068, G loss: 0.7764\n",
      "[1684/1762] D loss: 1.4747, G loss: 0.6933\n",
      "[1762/1762] D loss: 1.3765, G loss: 0.6644\n",
      "train error: \n",
      " D loss: 1.383372, G loss: 0.648175, D accuracy: 55.0%, cell accuracy: 98.5%, board accuracy: 47.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385538, G loss: 0.647569, D accuracy: 54.0%, cell accuracy: 98.5%, board accuracy: 45.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2619, G loss: 0.7186\n",
      "[84/1762] D loss: 1.3752, G loss: 0.8204\n",
      "[164/1762] D loss: 1.3954, G loss: 0.6692\n",
      "[244/1762] D loss: 1.3856, G loss: 0.6283\n",
      "[324/1762] D loss: 1.3341, G loss: 0.7486\n",
      "[404/1762] D loss: 1.3939, G loss: 0.7351\n",
      "[484/1762] D loss: 1.5123, G loss: 0.5976\n",
      "[564/1762] D loss: 1.4344, G loss: 0.6064\n",
      "[644/1762] D loss: 1.3448, G loss: 0.8163\n",
      "[724/1762] D loss: 1.5977, G loss: 0.6026\n",
      "[804/1762] D loss: 1.4859, G loss: 0.5952\n",
      "[884/1762] D loss: 1.4248, G loss: 0.6077\n",
      "[964/1762] D loss: 1.3608, G loss: 0.6790\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.8166\n",
      "[1124/1762] D loss: 1.3985, G loss: 0.6409\n",
      "[1204/1762] D loss: 1.4008, G loss: 0.9408\n",
      "[1284/1762] D loss: 1.4085, G loss: 0.5638\n",
      "[1364/1762] D loss: 1.4449, G loss: 0.8463\n",
      "[1444/1762] D loss: 1.3980, G loss: 0.8757\n",
      "[1524/1762] D loss: 1.3818, G loss: 0.7709\n",
      "[1604/1762] D loss: 1.4048, G loss: 0.5681\n",
      "[1684/1762] D loss: 1.3860, G loss: 0.7783\n",
      "[1762/1762] D loss: 1.3967, G loss: 0.5443\n",
      "train error: \n",
      " D loss: 1.386766, G loss: 0.616913, D accuracy: 53.3%, cell accuracy: 99.5%, board accuracy: 67.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386481, G loss: 0.620060, D accuracy: 53.4%, cell accuracy: 99.5%, board accuracy: 64.3% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4057, G loss: 0.6286\n",
      "[84/1762] D loss: 1.4617, G loss: 0.7976\n",
      "[164/1762] D loss: 1.4007, G loss: 0.6334\n",
      "[244/1762] D loss: 1.3528, G loss: 0.7891\n",
      "[324/1762] D loss: 1.3684, G loss: 0.7139\n",
      "[404/1762] D loss: 1.3582, G loss: 0.7743\n",
      "[484/1762] D loss: 1.2730, G loss: 0.8608\n",
      "[564/1762] D loss: 1.3907, G loss: 0.7852\n",
      "[644/1762] D loss: 1.3771, G loss: 0.7295\n",
      "[724/1762] D loss: 1.4413, G loss: 0.5408\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6985\n",
      "[884/1762] D loss: 1.3829, G loss: 0.6976\n",
      "[964/1762] D loss: 1.3899, G loss: 0.6268\n",
      "[1044/1762] D loss: 1.3753, G loss: 0.6811\n",
      "[1124/1762] D loss: 1.4079, G loss: 0.7521\n",
      "[1204/1762] D loss: 1.4015, G loss: 0.6973\n",
      "[1284/1762] D loss: 1.4227, G loss: 0.7206\n",
      "[1364/1762] D loss: 1.3756, G loss: 0.6301\n",
      "[1444/1762] D loss: 1.3953, G loss: 0.6814\n",
      "[1524/1762] D loss: 1.3903, G loss: 0.7527\n",
      "[1604/1762] D loss: 1.4424, G loss: 0.7304\n",
      "[1684/1762] D loss: 1.4122, G loss: 0.5426\n",
      "[1762/1762] D loss: 1.3981, G loss: 0.7234\n",
      "train error: \n",
      " D loss: 1.384580, G loss: 0.668342, D accuracy: 52.2%, cell accuracy: 99.5%, board accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379949, G loss: 0.676047, D accuracy: 54.4%, cell accuracy: 99.5%, board accuracy: 65.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3543, G loss: 0.6328\n",
      "[84/1762] D loss: 1.3901, G loss: 0.7442\n",
      "[164/1762] D loss: 1.3196, G loss: 0.7308\n",
      "[244/1762] D loss: 1.3597, G loss: 0.7276\n",
      "[324/1762] D loss: 1.3595, G loss: 0.7612\n",
      "[404/1762] D loss: 1.3593, G loss: 0.7251\n",
      "[484/1762] D loss: 1.3855, G loss: 0.6750\n",
      "[564/1762] D loss: 1.3047, G loss: 0.7955\n",
      "[644/1762] D loss: 1.3658, G loss: 0.8002\n",
      "[724/1762] D loss: 1.3956, G loss: 0.7702\n",
      "[804/1762] D loss: 1.3813, G loss: 0.6084\n",
      "[884/1762] D loss: 1.3997, G loss: 0.7444\n",
      "[964/1762] D loss: 1.3663, G loss: 0.6983\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.6820\n",
      "[1124/1762] D loss: 1.4051, G loss: 0.7109\n",
      "[1204/1762] D loss: 1.3466, G loss: 0.5893\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.7179\n",
      "[1364/1762] D loss: 1.4143, G loss: 0.7662\n",
      "[1444/1762] D loss: 1.3719, G loss: 0.6521\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7544\n",
      "[1604/1762] D loss: 1.4167, G loss: 0.7987\n",
      "[1684/1762] D loss: 1.3492, G loss: 0.7362\n",
      "[1762/1762] D loss: 1.4005, G loss: 0.8119\n",
      "train error: \n",
      " D loss: 1.372415, G loss: 0.762710, D accuracy: 52.0%, cell accuracy: 99.5%, board accuracy: 72.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372929, G loss: 0.767966, D accuracy: 53.1%, cell accuracy: 99.5%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3652, G loss: 0.6382\n",
      "[84/1762] D loss: 1.3397, G loss: 0.6896\n",
      "[164/1762] D loss: 1.3663, G loss: 0.7233\n",
      "[244/1762] D loss: 1.3913, G loss: 0.7795\n",
      "[324/1762] D loss: 1.4122, G loss: 0.5753\n",
      "[404/1762] D loss: 1.4140, G loss: 0.7717\n",
      "[484/1762] D loss: 1.2467, G loss: 0.8454\n",
      "[564/1762] D loss: 1.3726, G loss: 0.7047\n",
      "[644/1762] D loss: 1.3427, G loss: 0.8222\n",
      "[724/1762] D loss: 1.3597, G loss: 0.8221\n",
      "[804/1762] D loss: 1.3914, G loss: 0.7003\n",
      "[884/1762] D loss: 1.3911, G loss: 0.7685\n",
      "[964/1762] D loss: 1.3815, G loss: 0.7195\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.6660\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6758\n",
      "[1204/1762] D loss: 1.3783, G loss: 0.7869\n",
      "[1284/1762] D loss: 1.3650, G loss: 0.7238\n",
      "[1364/1762] D loss: 1.3650, G loss: 0.8099\n",
      "[1444/1762] D loss: 1.3986, G loss: 0.6792\n",
      "[1524/1762] D loss: 1.4047, G loss: 0.8420\n",
      "[1604/1762] D loss: 1.3636, G loss: 0.6623\n",
      "[1684/1762] D loss: 1.4059, G loss: 0.6652\n",
      "[1762/1762] D loss: 1.3923, G loss: 0.6095\n",
      "train error: \n",
      " D loss: 1.371894, G loss: 0.641503, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 74.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363330, G loss: 0.651045, D accuracy: 57.2%, cell accuracy: 99.5%, board accuracy: 69.3% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3698, G loss: 0.6543\n",
      "[84/1762] D loss: 1.3830, G loss: 0.6703\n",
      "[164/1762] D loss: 1.3887, G loss: 0.7049\n",
      "[244/1762] D loss: 1.3639, G loss: 0.7274\n",
      "[324/1762] D loss: 1.3028, G loss: 0.7215\n",
      "[404/1762] D loss: 1.3869, G loss: 0.8627\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6855\n",
      "[564/1762] D loss: 1.3901, G loss: 0.7063\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6989\n",
      "[724/1762] D loss: 1.3527, G loss: 0.5995\n",
      "[804/1762] D loss: 1.3759, G loss: 0.6551\n",
      "[884/1762] D loss: 1.3783, G loss: 0.6503\n",
      "[964/1762] D loss: 1.3878, G loss: 0.5865\n",
      "[1044/1762] D loss: 1.3906, G loss: 0.6323\n",
      "[1124/1762] D loss: 1.3790, G loss: 0.6681\n",
      "[1204/1762] D loss: 1.3977, G loss: 0.6744\n",
      "[1284/1762] D loss: 1.3510, G loss: 0.6578\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6985\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6770\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.7071\n",
      "[1604/1762] D loss: 1.4052, G loss: 0.6558\n",
      "[1684/1762] D loss: 1.3455, G loss: 0.7857\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.6386\n",
      "train error: \n",
      " D loss: 1.375696, G loss: 0.645978, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372577, G loss: 0.650287, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2674, G loss: 0.7112\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6500\n",
      "[164/1762] D loss: 1.3877, G loss: 0.7004\n",
      "[244/1762] D loss: 1.3895, G loss: 0.6947\n",
      "[324/1762] D loss: 1.3877, G loss: 0.7263\n",
      "[404/1762] D loss: 1.3802, G loss: 0.6762\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6597\n",
      "[564/1762] D loss: 1.3875, G loss: 0.7331\n",
      "[644/1762] D loss: 1.3938, G loss: 0.6606\n",
      "[724/1762] D loss: 1.3932, G loss: 0.7695\n",
      "[804/1762] D loss: 1.3820, G loss: 0.7026\n",
      "[884/1762] D loss: 1.3808, G loss: 0.5946\n",
      "[964/1762] D loss: 1.4161, G loss: 0.8428\n",
      "[1044/1762] D loss: 1.3597, G loss: 0.7881\n",
      "[1124/1762] D loss: 1.4345, G loss: 0.5152\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.6111\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.6230\n",
      "[1364/1762] D loss: 1.3100, G loss: 0.6759\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.7759\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6521\n",
      "[1604/1762] D loss: 1.3943, G loss: 0.6811\n",
      "[1684/1762] D loss: 1.3151, G loss: 0.7586\n",
      "[1762/1762] D loss: 1.4274, G loss: 0.7359\n",
      "train error: \n",
      " D loss: 1.364292, G loss: 0.779004, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356253, G loss: 0.790961, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2915, G loss: 0.7974\n",
      "[84/1762] D loss: 1.3145, G loss: 0.7396\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6123\n",
      "[244/1762] D loss: 1.4044, G loss: 0.7018\n",
      "[324/1762] D loss: 1.3944, G loss: 0.7138\n",
      "[404/1762] D loss: 1.3889, G loss: 0.6791\n",
      "[484/1762] D loss: 1.3661, G loss: 0.6752\n",
      "[564/1762] D loss: 1.3191, G loss: 0.7157\n",
      "[644/1762] D loss: 1.3887, G loss: 0.7402\n",
      "[724/1762] D loss: 1.2949, G loss: 0.8689\n",
      "[804/1762] D loss: 1.3846, G loss: 0.7356\n",
      "[884/1762] D loss: 1.3931, G loss: 0.6784\n",
      "[964/1762] D loss: 1.4045, G loss: 0.6601\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.7890\n",
      "[1124/1762] D loss: 1.3111, G loss: 0.6687\n",
      "[1204/1762] D loss: 1.3493, G loss: 0.6896\n",
      "[1284/1762] D loss: 1.4079, G loss: 0.6844\n",
      "[1364/1762] D loss: 1.4433, G loss: 0.6228\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.7370\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.6188\n",
      "[1604/1762] D loss: 1.3778, G loss: 0.7084\n",
      "[1684/1762] D loss: 1.4630, G loss: 0.6659\n",
      "[1762/1762] D loss: 1.3593, G loss: 0.6556\n",
      "train error: \n",
      " D loss: 1.373643, G loss: 0.589696, D accuracy: 53.7%, cell accuracy: 99.5%, board accuracy: 73.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371547, G loss: 0.600446, D accuracy: 54.3%, cell accuracy: 99.4%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4297, G loss: 0.5896\n",
      "[84/1762] D loss: 1.3933, G loss: 0.7174\n",
      "[164/1762] D loss: 1.3986, G loss: 0.6733\n",
      "[244/1762] D loss: 1.3795, G loss: 0.6556\n",
      "[324/1762] D loss: 1.3298, G loss: 0.7377\n",
      "[404/1762] D loss: 1.3880, G loss: 0.7593\n",
      "[484/1762] D loss: 1.3914, G loss: 0.6790\n",
      "[564/1762] D loss: 1.3325, G loss: 0.8213\n",
      "[644/1762] D loss: 1.3392, G loss: 0.7311\n",
      "[724/1762] D loss: 1.4619, G loss: 0.6629\n",
      "[804/1762] D loss: 1.4010, G loss: 0.7096\n",
      "[884/1762] D loss: 1.4442, G loss: 0.6503\n",
      "[964/1762] D loss: 1.4239, G loss: 0.6711\n",
      "[1044/1762] D loss: 1.3610, G loss: 0.6582\n",
      "[1124/1762] D loss: 1.3915, G loss: 0.5847\n",
      "[1204/1762] D loss: 1.3902, G loss: 0.7305\n",
      "[1284/1762] D loss: 1.3712, G loss: 0.6927\n",
      "[1364/1762] D loss: 1.3544, G loss: 0.5623\n",
      "[1444/1762] D loss: 1.3721, G loss: 0.6855\n",
      "[1524/1762] D loss: 1.3748, G loss: 0.6648\n",
      "[1604/1762] D loss: 1.3713, G loss: 0.6000\n",
      "[1684/1762] D loss: 1.3611, G loss: 0.7544\n",
      "[1762/1762] D loss: 1.3990, G loss: 0.7342\n",
      "train error: \n",
      " D loss: 1.377313, G loss: 0.716915, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382777, G loss: 0.715429, D accuracy: 51.7%, cell accuracy: 99.6%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3359, G loss: 0.6642\n",
      "[84/1762] D loss: 1.3681, G loss: 0.6849\n",
      "[164/1762] D loss: 1.3922, G loss: 0.7352\n",
      "[244/1762] D loss: 1.3960, G loss: 0.6253\n",
      "[324/1762] D loss: 1.3739, G loss: 0.7029\n",
      "[404/1762] D loss: 1.3196, G loss: 0.7176\n",
      "[484/1762] D loss: 1.3550, G loss: 0.7901\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6069\n",
      "[644/1762] D loss: 1.3630, G loss: 0.6914\n",
      "[724/1762] D loss: 1.3590, G loss: 0.7725\n",
      "[804/1762] D loss: 1.3903, G loss: 0.7087\n",
      "[884/1762] D loss: 1.3611, G loss: 0.7489\n",
      "[964/1762] D loss: 1.3905, G loss: 0.6785\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.6949\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.7732\n",
      "[1204/1762] D loss: 1.3931, G loss: 0.6720\n",
      "[1284/1762] D loss: 1.3959, G loss: 0.7285\n",
      "[1364/1762] D loss: 1.3792, G loss: 0.6992\n",
      "[1444/1762] D loss: 1.3854, G loss: 0.7521\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6650\n",
      "[1604/1762] D loss: 1.3506, G loss: 0.8183\n",
      "[1684/1762] D loss: 1.2107, G loss: 0.9453\n",
      "[1762/1762] D loss: 1.3985, G loss: 0.8030\n",
      "train error: \n",
      " D loss: 1.385393, G loss: 0.842052, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380350, G loss: 0.845254, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3355, G loss: 0.7896\n",
      "[84/1762] D loss: 1.3906, G loss: 0.7611\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7559\n",
      "[244/1762] D loss: 1.4349, G loss: 0.6381\n",
      "[324/1762] D loss: 1.3457, G loss: 0.7711\n",
      "[404/1762] D loss: 1.2136, G loss: 0.8175\n",
      "[484/1762] D loss: 1.3121, G loss: 0.7233\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6395\n",
      "[644/1762] D loss: 1.3964, G loss: 0.6354\n",
      "[724/1762] D loss: 1.3958, G loss: 0.7113\n",
      "[804/1762] D loss: 1.3143, G loss: 0.6544\n",
      "[884/1762] D loss: 1.2287, G loss: 0.8066\n",
      "[964/1762] D loss: 1.3921, G loss: 0.6695\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.6624\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.6573\n",
      "[1204/1762] D loss: 1.3591, G loss: 0.7108\n",
      "[1284/1762] D loss: 1.2997, G loss: 0.7727\n",
      "[1364/1762] D loss: 1.3972, G loss: 0.7692\n",
      "[1444/1762] D loss: 1.3917, G loss: 0.7193\n",
      "[1524/1762] D loss: 1.3110, G loss: 0.7340\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.6068\n",
      "[1684/1762] D loss: 1.3443, G loss: 0.7710\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7087\n",
      "train error: \n",
      " D loss: 1.365915, G loss: 0.702713, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359332, G loss: 0.708380, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.7090\n",
      "[84/1762] D loss: 1.4075, G loss: 0.6804\n",
      "[164/1762] D loss: 1.4138, G loss: 0.6139\n",
      "[244/1762] D loss: 1.3650, G loss: 0.7189\n",
      "[324/1762] D loss: 1.3927, G loss: 0.7615\n",
      "[404/1762] D loss: 1.3644, G loss: 0.6943\n",
      "[484/1762] D loss: 1.3080, G loss: 0.7648\n",
      "[564/1762] D loss: 1.3850, G loss: 0.7487\n",
      "[644/1762] D loss: 1.3915, G loss: 0.6752\n",
      "[724/1762] D loss: 1.3882, G loss: 0.6022\n",
      "[804/1762] D loss: 1.3937, G loss: 0.6260\n",
      "[884/1762] D loss: 1.3960, G loss: 0.7075\n",
      "[964/1762] D loss: 1.3908, G loss: 0.8055\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.6796\n",
      "[1124/1762] D loss: 1.3949, G loss: 0.7314\n",
      "[1204/1762] D loss: 1.2666, G loss: 0.7966\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.7310\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7244\n",
      "[1444/1762] D loss: 1.4251, G loss: 0.6745\n",
      "[1524/1762] D loss: 1.4050, G loss: 0.6098\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6816\n",
      "[1684/1762] D loss: 1.4109, G loss: 0.6269\n",
      "[1762/1762] D loss: 1.3934, G loss: 0.6074\n",
      "train error: \n",
      " D loss: 1.361330, G loss: 0.671983, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355028, G loss: 0.677889, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3302, G loss: 0.7046\n",
      "[84/1762] D loss: 1.3959, G loss: 0.6788\n",
      "[164/1762] D loss: 1.3890, G loss: 0.7409\n",
      "[244/1762] D loss: 1.2558, G loss: 0.7805\n",
      "[324/1762] D loss: 1.4023, G loss: 0.6128\n",
      "[404/1762] D loss: 1.3630, G loss: 0.7553\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7263\n",
      "[564/1762] D loss: 1.4175, G loss: 0.6313\n",
      "[644/1762] D loss: 1.3994, G loss: 0.6626\n",
      "[724/1762] D loss: 1.3900, G loss: 0.7127\n",
      "[804/1762] D loss: 1.3915, G loss: 0.6627\n",
      "[884/1762] D loss: 1.3943, G loss: 0.7574\n",
      "[964/1762] D loss: 1.4068, G loss: 0.5979\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.7361\n",
      "[1124/1762] D loss: 1.2682, G loss: 0.7354\n",
      "[1204/1762] D loss: 1.2629, G loss: 0.8201\n",
      "[1284/1762] D loss: 1.3976, G loss: 0.6667\n",
      "[1364/1762] D loss: 1.3914, G loss: 0.6849\n",
      "[1444/1762] D loss: 1.3845, G loss: 0.5975\n",
      "[1524/1762] D loss: 1.4054, G loss: 0.6713\n",
      "[1604/1762] D loss: 1.3134, G loss: 0.7310\n",
      "[1684/1762] D loss: 1.3939, G loss: 0.6369\n",
      "[1762/1762] D loss: 1.4133, G loss: 0.7928\n",
      "train error: \n",
      " D loss: 1.366930, G loss: 0.852556, D accuracy: 51.8%, cell accuracy: 99.6%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356892, G loss: 0.862005, D accuracy: 52.6%, cell accuracy: 99.6%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1901, G loss: 0.9435\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6898\n",
      "[164/1762] D loss: 1.3898, G loss: 0.6608\n",
      "[244/1762] D loss: 1.2587, G loss: 0.6468\n",
      "[324/1762] D loss: 1.4048, G loss: 0.6676\n",
      "[404/1762] D loss: 1.3853, G loss: 0.7392\n",
      "[484/1762] D loss: 1.2759, G loss: 0.9549\n",
      "[564/1762] D loss: 1.3906, G loss: 0.8442\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6490\n",
      "[724/1762] D loss: 1.2968, G loss: 0.7990\n",
      "[804/1762] D loss: 1.4116, G loss: 0.9157\n",
      "[884/1762] D loss: 1.3934, G loss: 0.7155\n",
      "[964/1762] D loss: 1.4083, G loss: 0.7340\n",
      "[1044/1762] D loss: 1.4072, G loss: 0.7223\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.7448\n",
      "[1204/1762] D loss: 1.4003, G loss: 0.6988\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.6878\n",
      "[1364/1762] D loss: 1.2333, G loss: 0.8072\n",
      "[1444/1762] D loss: 1.4007, G loss: 0.7161\n",
      "[1524/1762] D loss: 1.2349, G loss: 0.8611\n",
      "[1604/1762] D loss: 1.5335, G loss: 0.6803\n",
      "[1684/1762] D loss: 1.6156, G loss: 0.7850\n",
      "[1762/1762] D loss: 1.4457, G loss: 0.6286\n",
      "train error: \n",
      " D loss: 1.423210, G loss: 0.736545, D accuracy: 48.6%, cell accuracy: 99.1%, board accuracy: 71.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412741, G loss: 0.751235, D accuracy: 48.9%, cell accuracy: 99.0%, board accuracy: 65.9% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5234, G loss: 0.6664\n",
      "[84/1762] D loss: 1.5286, G loss: 0.7187\n",
      "[164/1762] D loss: 1.3576, G loss: 0.7023\n",
      "[244/1762] D loss: 1.4631, G loss: 0.8985\n",
      "[324/1762] D loss: 1.4008, G loss: 0.5830\n",
      "[404/1762] D loss: 1.4304, G loss: 0.6013\n",
      "[484/1762] D loss: 1.4235, G loss: 0.8667\n",
      "[564/1762] D loss: 1.4203, G loss: 0.6710\n",
      "[644/1762] D loss: 1.3955, G loss: 0.6367\n",
      "[724/1762] D loss: 1.3874, G loss: 0.5457\n",
      "[804/1762] D loss: 1.3767, G loss: 0.7107\n",
      "[884/1762] D loss: 1.4033, G loss: 0.6698\n",
      "[964/1762] D loss: 1.3749, G loss: 0.6903\n",
      "[1044/1762] D loss: 1.3529, G loss: 0.7934\n",
      "[1124/1762] D loss: 1.3849, G loss: 0.6802\n",
      "[1204/1762] D loss: 1.3596, G loss: 0.5982\n",
      "[1284/1762] D loss: 1.3766, G loss: 0.7820\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.7304\n",
      "[1444/1762] D loss: 1.3035, G loss: 0.8368\n",
      "[1524/1762] D loss: 1.3995, G loss: 0.8105\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.9697\n",
      "[1684/1762] D loss: 1.3969, G loss: 0.6731\n",
      "[1762/1762] D loss: 1.3814, G loss: 0.7100\n",
      "train error: \n",
      " D loss: 1.395035, G loss: 0.681798, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398611, G loss: 0.684971, D accuracy: 48.2%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4110, G loss: 0.6826\n",
      "[84/1762] D loss: 1.4259, G loss: 0.5807\n",
      "[164/1762] D loss: 1.4276, G loss: 0.6222\n",
      "[244/1762] D loss: 1.4076, G loss: 0.7271\n",
      "[324/1762] D loss: 1.3953, G loss: 0.7007\n",
      "[404/1762] D loss: 1.3936, G loss: 0.6610\n",
      "[484/1762] D loss: 1.3931, G loss: 0.7369\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6570\n",
      "[644/1762] D loss: 1.3958, G loss: 0.7240\n",
      "[724/1762] D loss: 1.3914, G loss: 0.6195\n",
      "[804/1762] D loss: 1.3939, G loss: 0.6607\n",
      "[884/1762] D loss: 1.4025, G loss: 0.6860\n",
      "[964/1762] D loss: 1.3884, G loss: 0.7404\n",
      "[1044/1762] D loss: 1.4023, G loss: 0.6316\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7168\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.6464\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6681\n",
      "[1364/1762] D loss: 1.3887, G loss: 0.6781\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.7562\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.6565\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.6811\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6664\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.7039\n",
      "train error: \n",
      " D loss: 1.386352, G loss: 0.610868, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384122, G loss: 0.613123, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962, G loss: 0.6296\n",
      "[84/1762] D loss: 1.3886, G loss: 0.6983\n",
      "[164/1762] D loss: 1.4017, G loss: 0.7964\n",
      "[244/1762] D loss: 1.3891, G loss: 0.7028\n",
      "[324/1762] D loss: 1.2945, G loss: 0.7650\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7147\n",
      "[484/1762] D loss: 1.3879, G loss: 0.6962\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6736\n",
      "[644/1762] D loss: 1.3811, G loss: 0.6835\n",
      "[724/1762] D loss: 1.3445, G loss: 0.6903\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6819\n",
      "[884/1762] D loss: 1.3889, G loss: 0.6752\n",
      "[964/1762] D loss: 1.3385, G loss: 0.7824\n",
      "[1044/1762] D loss: 1.3209, G loss: 0.6993\n",
      "[1124/1762] D loss: 1.3512, G loss: 0.7721\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.6465\n",
      "[1284/1762] D loss: 1.3722, G loss: 0.6920\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.6641\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.7046\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6963\n",
      "[1604/1762] D loss: 1.3137, G loss: 0.6897\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.7744\n",
      "[1762/1762] D loss: 1.3986, G loss: 0.6268\n",
      "train error: \n",
      " D loss: 1.372677, G loss: 0.644941, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365719, G loss: 0.650504, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951, G loss: 0.6312\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6878\n",
      "[164/1762] D loss: 1.3921, G loss: 0.7403\n",
      "[244/1762] D loss: 1.2920, G loss: 0.6982\n",
      "[324/1762] D loss: 1.3923, G loss: 0.7108\n",
      "[404/1762] D loss: 1.3767, G loss: 0.6990\n",
      "[484/1762] D loss: 1.3873, G loss: 0.6778\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6432\n",
      "[644/1762] D loss: 1.3979, G loss: 0.8145\n",
      "[724/1762] D loss: 1.3934, G loss: 0.6560\n",
      "[804/1762] D loss: 1.3972, G loss: 0.6063\n",
      "[884/1762] D loss: 1.3912, G loss: 0.6910\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6700\n",
      "[1044/1762] D loss: 1.4020, G loss: 0.6216\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.7824\n",
      "[1204/1762] D loss: 1.2666, G loss: 0.7313\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.6922\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.8048\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.7277\n",
      "[1524/1762] D loss: 1.3946, G loss: 0.6097\n",
      "[1604/1762] D loss: 1.4486, G loss: 0.7077\n",
      "[1684/1762] D loss: 1.4176, G loss: 0.7146\n",
      "[1762/1762] D loss: 1.6102, G loss: 0.6061\n",
      "train error: \n",
      " D loss: 1.433193, G loss: 0.748741, D accuracy: 45.0%, cell accuracy: 99.2%, board accuracy: 69.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.423861, G loss: 0.758371, D accuracy: 46.0%, cell accuracy: 99.3%, board accuracy: 70.2% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4061, G loss: 0.7981\n",
      "[84/1762] D loss: 1.5061, G loss: 0.7469\n",
      "[164/1762] D loss: 1.4294, G loss: 0.6333\n",
      "[244/1762] D loss: 1.4111, G loss: 0.6240\n",
      "[324/1762] D loss: 1.3458, G loss: 0.7352\n",
      "[404/1762] D loss: 1.3446, G loss: 0.7779\n",
      "[484/1762] D loss: 1.3602, G loss: 0.6837\n",
      "[564/1762] D loss: 1.3410, G loss: 0.8298\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6748\n",
      "[724/1762] D loss: 1.3925, G loss: 0.7316\n",
      "[804/1762] D loss: 1.4236, G loss: 0.5685\n",
      "[884/1762] D loss: 1.3976, G loss: 0.6278\n",
      "[964/1762] D loss: 1.4748, G loss: 0.7521\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.6880\n",
      "[1124/1762] D loss: 1.4051, G loss: 0.5661\n",
      "[1204/1762] D loss: 1.4249, G loss: 0.5656\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.6848\n",
      "[1364/1762] D loss: 1.4096, G loss: 0.6365\n",
      "[1444/1762] D loss: 1.4047, G loss: 0.6691\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7564\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6963\n",
      "[1684/1762] D loss: 1.3954, G loss: 0.6502\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6758\n",
      "train error: \n",
      " D loss: 1.386011, G loss: 0.642447, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384255, G loss: 0.645301, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3650, G loss: 0.6330\n",
      "[84/1762] D loss: 1.3895, G loss: 0.6545\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6501\n",
      "[244/1762] D loss: 1.3609, G loss: 0.7295\n",
      "[324/1762] D loss: 1.3928, G loss: 0.7205\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6886\n",
      "[484/1762] D loss: 1.3883, G loss: 0.7074\n",
      "[564/1762] D loss: 1.3842, G loss: 0.6749\n",
      "[644/1762] D loss: 1.3934, G loss: 0.6508\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6915\n",
      "[804/1762] D loss: 1.3854, G loss: 0.6914\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6977\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6457\n",
      "[1044/1762] D loss: 1.3414, G loss: 0.7230\n",
      "[1124/1762] D loss: 1.3140, G loss: 0.7495\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.6943\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6867\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6936\n",
      "[1444/1762] D loss: 1.3918, G loss: 0.7442\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.6986\n",
      "[1604/1762] D loss: 1.3432, G loss: 0.7427\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.6657\n",
      "[1762/1762] D loss: 1.3937, G loss: 0.7671\n",
      "train error: \n",
      " D loss: 1.366450, G loss: 0.745630, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360225, G loss: 0.748940, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2894, G loss: 0.7631\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6848\n",
      "[164/1762] D loss: 1.3819, G loss: 0.7196\n",
      "[244/1762] D loss: 1.3900, G loss: 0.6836\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7677\n",
      "[404/1762] D loss: 1.4132, G loss: 0.6775\n",
      "[484/1762] D loss: 1.4032, G loss: 0.7224\n",
      "[564/1762] D loss: 1.4087, G loss: 0.7840\n",
      "[644/1762] D loss: 1.2967, G loss: 0.6971\n",
      "[724/1762] D loss: 1.3977, G loss: 0.6183\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6734\n",
      "[884/1762] D loss: 1.3953, G loss: 0.7138\n",
      "[964/1762] D loss: 1.5120, G loss: 0.5647\n",
      "[1044/1762] D loss: 1.4371, G loss: 0.7843\n",
      "[1124/1762] D loss: 1.4101, G loss: 0.7879\n",
      "[1204/1762] D loss: 1.4104, G loss: 0.7659\n",
      "[1284/1762] D loss: 1.3484, G loss: 0.6794\n",
      "[1364/1762] D loss: 1.3082, G loss: 0.7501\n",
      "[1444/1762] D loss: 1.4077, G loss: 0.5895\n",
      "[1524/1762] D loss: 1.3974, G loss: 0.7488\n",
      "[1604/1762] D loss: 1.4638, G loss: 0.7907\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.6254\n",
      "[1762/1762] D loss: 1.4354, G loss: 0.6495\n",
      "train error: \n",
      " D loss: 1.404370, G loss: 0.773668, D accuracy: 49.0%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.406859, G loss: 0.776989, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4179, G loss: 0.8092\n",
      "[84/1762] D loss: 1.4525, G loss: 0.6277\n",
      "[164/1762] D loss: 1.4069, G loss: 0.6188\n",
      "[244/1762] D loss: 1.3887, G loss: 0.6765\n",
      "[324/1762] D loss: 1.3910, G loss: 0.7347\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7015\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6803\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7199\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6656\n",
      "[724/1762] D loss: 1.3904, G loss: 0.6287\n",
      "[804/1762] D loss: 1.3880, G loss: 0.7324\n",
      "[884/1762] D loss: 1.3667, G loss: 0.6739\n",
      "[964/1762] D loss: 1.3891, G loss: 0.7075\n",
      "[1044/1762] D loss: 1.3573, G loss: 0.7312\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6472\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.7656\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.6557\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.7016\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6902\n",
      "[1524/1762] D loss: 1.3036, G loss: 0.7371\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6823\n",
      "[1684/1762] D loss: 1.3240, G loss: 0.7477\n",
      "[1762/1762] D loss: 1.2650, G loss: 0.8037\n",
      "train error: \n",
      " D loss: 1.375329, G loss: 0.767339, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372180, G loss: 0.768327, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.7397\n",
      "[84/1762] D loss: 1.3330, G loss: 0.6951\n",
      "[164/1762] D loss: 1.3894, G loss: 0.6945\n",
      "[244/1762] D loss: 1.3886, G loss: 0.7343\n",
      "[324/1762] D loss: 1.3108, G loss: 0.6950\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6974\n",
      "[484/1762] D loss: 1.3471, G loss: 0.6804\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6784\n",
      "[644/1762] D loss: 1.3912, G loss: 0.8169\n",
      "[724/1762] D loss: 1.3892, G loss: 0.6458\n",
      "[804/1762] D loss: 1.3889, G loss: 0.6446\n",
      "[884/1762] D loss: 1.2835, G loss: 0.7439\n",
      "[964/1762] D loss: 1.3876, G loss: 0.7108\n",
      "[1044/1762] D loss: 1.2725, G loss: 0.7310\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.7150\n",
      "[1204/1762] D loss: 1.2764, G loss: 0.7489\n",
      "[1284/1762] D loss: 1.2803, G loss: 0.7669\n",
      "[1364/1762] D loss: 1.3955, G loss: 0.7708\n",
      "[1444/1762] D loss: 1.3788, G loss: 0.6858\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.6928\n",
      "[1604/1762] D loss: 1.2799, G loss: 0.7607\n",
      "[1684/1762] D loss: 1.5272, G loss: 0.7186\n",
      "[1762/1762] D loss: 1.5886, G loss: 0.6016\n",
      "train error: \n",
      " D loss: 1.434292, G loss: 0.750038, D accuracy: 40.9%, cell accuracy: 98.1%, board accuracy: 29.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.436443, G loss: 0.749099, D accuracy: 41.0%, cell accuracy: 98.1%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4970, G loss: 0.7381\n",
      "[84/1762] D loss: 1.3776, G loss: 0.6586\n",
      "[164/1762] D loss: 1.3162, G loss: 0.6678\n",
      "[244/1762] D loss: 1.2514, G loss: 0.8664\n",
      "[324/1762] D loss: 1.3820, G loss: 0.7736\n",
      "[404/1762] D loss: 1.3896, G loss: 0.7153\n",
      "[484/1762] D loss: 1.4676, G loss: 0.6020\n",
      "[564/1762] D loss: 1.3953, G loss: 0.5952\n",
      "[644/1762] D loss: 1.3901, G loss: 0.7077\n",
      "[724/1762] D loss: 1.3945, G loss: 0.8497\n",
      "[804/1762] D loss: 1.3941, G loss: 0.6637\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6322\n",
      "[964/1762] D loss: 1.3944, G loss: 0.6687\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6640\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6620\n",
      "[1204/1762] D loss: 1.3904, G loss: 0.6260\n",
      "[1284/1762] D loss: 1.4007, G loss: 0.6648\n",
      "[1364/1762] D loss: 1.3941, G loss: 0.6220\n",
      "[1444/1762] D loss: 1.3805, G loss: 0.7122\n",
      "[1524/1762] D loss: 1.3721, G loss: 0.7052\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.6834\n",
      "[1684/1762] D loss: 1.3830, G loss: 0.7355\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6900\n",
      "train error: \n",
      " D loss: 1.379898, G loss: 0.676393, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377319, G loss: 0.679335, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3752, G loss: 0.6620\n",
      "[84/1762] D loss: 1.3523, G loss: 0.6927\n",
      "[164/1762] D loss: 1.3894, G loss: 0.7631\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6968\n",
      "[324/1762] D loss: 1.3875, G loss: 0.7103\n",
      "[404/1762] D loss: 1.3333, G loss: 0.7006\n",
      "[484/1762] D loss: 1.3880, G loss: 0.7091\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7462\n",
      "[644/1762] D loss: 1.3879, G loss: 0.6992\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6787\n",
      "[804/1762] D loss: 1.3273, G loss: 0.7134\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7196\n",
      "[964/1762] D loss: 1.4080, G loss: 0.7244\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6870\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.7308\n",
      "[1204/1762] D loss: 1.3806, G loss: 0.7223\n",
      "[1284/1762] D loss: 1.3986, G loss: 0.7144\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6422\n",
      "[1444/1762] D loss: 1.3839, G loss: 0.7080\n",
      "[1524/1762] D loss: 1.3814, G loss: 0.7245\n",
      "[1604/1762] D loss: 1.3893, G loss: 0.6634\n",
      "[1684/1762] D loss: 1.3915, G loss: 0.6971\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6899\n",
      "train error: \n",
      " D loss: 1.366645, G loss: 0.687479, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359534, G loss: 0.691455, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915, G loss: 0.6440\n",
      "[84/1762] D loss: 1.3145, G loss: 0.7232\n",
      "[164/1762] D loss: 1.3863, G loss: 0.7075\n",
      "[244/1762] D loss: 1.4476, G loss: 0.6235\n",
      "[324/1762] D loss: 1.4242, G loss: 0.7234\n",
      "[404/1762] D loss: 1.3933, G loss: 0.7294\n",
      "[484/1762] D loss: 1.3509, G loss: 0.5609\n",
      "[564/1762] D loss: 1.3309, G loss: 0.7787\n",
      "[644/1762] D loss: 1.4193, G loss: 0.6479\n",
      "[724/1762] D loss: 1.3823, G loss: 0.7307\n",
      "[804/1762] D loss: 1.3759, G loss: 0.6703\n",
      "[884/1762] D loss: 1.3794, G loss: 0.6505\n",
      "[964/1762] D loss: 1.3850, G loss: 0.7529\n",
      "[1044/1762] D loss: 1.3998, G loss: 0.7216\n",
      "[1124/1762] D loss: 1.4047, G loss: 0.5942\n",
      "[1204/1762] D loss: 1.3889, G loss: 0.6922\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.6599\n",
      "[1364/1762] D loss: 1.3810, G loss: 0.6876\n",
      "[1444/1762] D loss: 1.3745, G loss: 0.7750\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.6957\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.7047\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6945\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6658\n",
      "train error: \n",
      " D loss: 1.379511, G loss: 0.680686, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377528, G loss: 0.682255, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7032\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6430\n",
      "[164/1762] D loss: 1.3449, G loss: 0.6924\n",
      "[244/1762] D loss: 1.3595, G loss: 0.7558\n",
      "[324/1762] D loss: 1.3816, G loss: 0.7021\n",
      "[404/1762] D loss: 1.3096, G loss: 0.7604\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6613\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7043\n",
      "[644/1762] D loss: 1.3614, G loss: 0.7373\n",
      "[724/1762] D loss: 1.4026, G loss: 0.6144\n",
      "[804/1762] D loss: 1.3345, G loss: 0.8236\n",
      "[884/1762] D loss: 1.3897, G loss: 0.7090\n",
      "[964/1762] D loss: 1.3916, G loss: 0.6138\n",
      "[1044/1762] D loss: 1.3323, G loss: 0.7290\n",
      "[1124/1762] D loss: 1.3528, G loss: 0.7819\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6765\n",
      "[1284/1762] D loss: 1.0932, G loss: 0.8977\n",
      "[1364/1762] D loss: 1.2827, G loss: 0.6456\n",
      "[1444/1762] D loss: 1.3933, G loss: 0.6861\n",
      "[1524/1762] D loss: 1.3799, G loss: 0.7664\n",
      "[1604/1762] D loss: 1.4351, G loss: 0.5677\n",
      "[1684/1762] D loss: 1.2929, G loss: 0.6765\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.7214\n",
      "train error: \n",
      " D loss: 1.360147, G loss: 0.718737, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352896, G loss: 0.721932, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2688, G loss: 0.7154\n",
      "[84/1762] D loss: 1.3902, G loss: 0.6058\n",
      "[164/1762] D loss: 1.2981, G loss: 0.7926\n",
      "[244/1762] D loss: 1.3925, G loss: 0.7338\n",
      "[324/1762] D loss: 1.3990, G loss: 0.6796\n",
      "[404/1762] D loss: 1.3998, G loss: 0.6437\n",
      "[484/1762] D loss: 1.4007, G loss: 0.7602\n",
      "[564/1762] D loss: 1.4073, G loss: 0.6311\n",
      "[644/1762] D loss: 1.3946, G loss: 0.6940\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6801\n",
      "[804/1762] D loss: 1.3010, G loss: 0.7366\n",
      "[884/1762] D loss: 1.3975, G loss: 0.7943\n",
      "[964/1762] D loss: 1.4982, G loss: 0.5209\n",
      "[1044/1762] D loss: 1.4852, G loss: 0.6232\n",
      "[1124/1762] D loss: 1.4696, G loss: 0.7034\n",
      "[1204/1762] D loss: 1.3628, G loss: 0.7822\n",
      "[1284/1762] D loss: 1.2778, G loss: 0.7407\n",
      "[1364/1762] D loss: 1.2583, G loss: 0.7394\n",
      "[1444/1762] D loss: 1.4585, G loss: 0.7079\n",
      "[1524/1762] D loss: 1.4265, G loss: 0.7242\n",
      "[1604/1762] D loss: 1.3620, G loss: 0.8106\n",
      "[1684/1762] D loss: 1.4018, G loss: 0.7662\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7105\n",
      "train error: \n",
      " D loss: 1.400874, G loss: 0.683391, D accuracy: 47.8%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404437, G loss: 0.684283, D accuracy: 46.5%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3778, G loss: 0.7092\n",
      "[84/1762] D loss: 1.4052, G loss: 0.6072\n",
      "[164/1762] D loss: 1.3940, G loss: 0.7166\n",
      "[244/1762] D loss: 1.4217, G loss: 0.6723\n",
      "[324/1762] D loss: 1.3916, G loss: 0.6939\n",
      "[404/1762] D loss: 1.3856, G loss: 0.6627\n",
      "[484/1762] D loss: 1.3911, G loss: 0.6666\n",
      "[564/1762] D loss: 1.3759, G loss: 0.7268\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6867\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6838\n",
      "[804/1762] D loss: 1.3744, G loss: 0.6854\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7052\n",
      "[964/1762] D loss: 1.3492, G loss: 0.7023\n",
      "[1044/1762] D loss: 1.3531, G loss: 0.6998\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.7071\n",
      "[1204/1762] D loss: 1.3834, G loss: 0.6693\n",
      "[1284/1762] D loss: 1.3352, G loss: 0.7009\n",
      "[1364/1762] D loss: 1.3850, G loss: 0.6558\n",
      "[1444/1762] D loss: 1.3116, G loss: 0.7922\n",
      "[1524/1762] D loss: 1.3956, G loss: 0.7501\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.7061\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6911\n",
      "[1762/1762] D loss: 1.3930, G loss: 0.6418\n",
      "train error: \n",
      " D loss: 1.363977, G loss: 0.688726, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357375, G loss: 0.691711, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3000, G loss: 0.7102\n",
      "[84/1762] D loss: 1.3931, G loss: 0.6143\n",
      "[164/1762] D loss: 1.3351, G loss: 0.7426\n",
      "[244/1762] D loss: 1.3777, G loss: 0.7412\n",
      "[324/1762] D loss: 1.3893, G loss: 0.7723\n",
      "[404/1762] D loss: 1.3918, G loss: 0.7005\n",
      "[484/1762] D loss: 1.2654, G loss: 0.7590\n",
      "[564/1762] D loss: 1.4031, G loss: 0.8170\n",
      "[644/1762] D loss: 1.3975, G loss: 0.6164\n",
      "[724/1762] D loss: 1.3789, G loss: 0.6606\n",
      "[804/1762] D loss: 1.4641, G loss: 0.7819\n",
      "[884/1762] D loss: 1.3923, G loss: 0.8476\n",
      "[964/1762] D loss: 1.3227, G loss: 0.7950\n",
      "[1044/1762] D loss: 1.3849, G loss: 0.6730\n",
      "[1124/1762] D loss: 1.3019, G loss: 0.7288\n",
      "[1204/1762] D loss: 1.4028, G loss: 0.5838\n",
      "[1284/1762] D loss: 1.3769, G loss: 0.6572\n",
      "[1364/1762] D loss: 1.3810, G loss: 0.6530\n",
      "[1444/1762] D loss: 1.3591, G loss: 0.7263\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.6976\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6541\n",
      "[1684/1762] D loss: 1.3949, G loss: 0.6509\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.7217\n",
      "train error: \n",
      " D loss: 1.396214, G loss: 0.790212, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395782, G loss: 0.791497, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.8237\n",
      "[84/1762] D loss: 1.3938, G loss: 0.7412\n",
      "[164/1762] D loss: 1.3898, G loss: 0.6720\n",
      "[244/1762] D loss: 1.3855, G loss: 0.6776\n",
      "[324/1762] D loss: 1.3924, G loss: 0.6365\n",
      "[404/1762] D loss: 1.3910, G loss: 0.6515\n",
      "[484/1762] D loss: 1.3957, G loss: 0.6836\n",
      "[564/1762] D loss: 1.3827, G loss: 0.6680\n",
      "[644/1762] D loss: 1.3276, G loss: 0.7954\n",
      "[724/1762] D loss: 1.3904, G loss: 0.7213\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6904\n",
      "[884/1762] D loss: 1.3178, G loss: 0.7121\n",
      "[964/1762] D loss: 1.3890, G loss: 0.7648\n",
      "[1044/1762] D loss: 1.2678, G loss: 0.8730\n",
      "[1124/1762] D loss: 1.2848, G loss: 0.7096\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6986\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6038\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.7599\n",
      "[1444/1762] D loss: 1.3686, G loss: 0.8799\n",
      "[1524/1762] D loss: 1.3945, G loss: 0.8328\n",
      "[1604/1762] D loss: 1.3367, G loss: 0.7915\n",
      "[1684/1762] D loss: 1.3794, G loss: 0.6869\n",
      "[1762/1762] D loss: 1.4021, G loss: 0.6240\n",
      "train error: \n",
      " D loss: 1.357760, G loss: 0.722766, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350286, G loss: 0.723393, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.7383\n",
      "[84/1762] D loss: 1.3960, G loss: 0.7833\n",
      "[164/1762] D loss: 1.4020, G loss: 0.7318\n",
      "[244/1762] D loss: 1.4673, G loss: 0.5962\n",
      "[324/1762] D loss: 1.3676, G loss: 0.7347\n",
      "[404/1762] D loss: 1.3863, G loss: 0.8314\n",
      "[484/1762] D loss: 1.3734, G loss: 0.8065\n",
      "[564/1762] D loss: 1.3140, G loss: 0.7254\n",
      "[644/1762] D loss: 1.3915, G loss: 0.6391\n",
      "[724/1762] D loss: 1.3727, G loss: 0.7410\n",
      "[804/1762] D loss: 1.3938, G loss: 0.7458\n",
      "[884/1762] D loss: 1.3763, G loss: 0.7120\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7080\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.7387\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.7347\n",
      "[1204/1762] D loss: 1.3206, G loss: 0.7270\n",
      "[1284/1762] D loss: 1.3821, G loss: 0.6702\n",
      "[1364/1762] D loss: 1.4050, G loss: 0.6030\n",
      "[1444/1762] D loss: 1.3781, G loss: 0.7425\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.6850\n",
      "[1604/1762] D loss: 1.3947, G loss: 0.7537\n",
      "[1684/1762] D loss: 1.2679, G loss: 0.7748\n",
      "[1762/1762] D loss: 1.2813, G loss: 0.7438\n",
      "train error: \n",
      " D loss: 1.387933, G loss: 0.546004, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 85.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384072, G loss: 0.544323, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4311, G loss: 0.5627\n",
      "[84/1762] D loss: 1.3949, G loss: 0.7458\n",
      "[164/1762] D loss: 1.0516, G loss: 0.9577\n",
      "[244/1762] D loss: 1.3800, G loss: 0.7695\n",
      "[324/1762] D loss: 1.3805, G loss: 0.7107\n",
      "[404/1762] D loss: 1.3984, G loss: 0.7145\n",
      "[484/1762] D loss: 1.3924, G loss: 0.7102\n",
      "[564/1762] D loss: 1.3860, G loss: 0.6558\n",
      "[644/1762] D loss: 1.3901, G loss: 0.7578\n",
      "[724/1762] D loss: 1.2132, G loss: 0.8994\n",
      "[804/1762] D loss: 1.3925, G loss: 0.5349\n",
      "[884/1762] D loss: 1.1586, G loss: 0.7754\n",
      "[964/1762] D loss: 1.3544, G loss: 0.8249\n",
      "[1044/1762] D loss: 1.2227, G loss: 0.8473\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.6836\n",
      "[1204/1762] D loss: 1.3839, G loss: 0.7416\n",
      "[1284/1762] D loss: 1.3962, G loss: 0.6336\n",
      "[1364/1762] D loss: 1.2700, G loss: 0.7137\n",
      "[1444/1762] D loss: 1.4085, G loss: 0.7716\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.6704\n",
      "[1604/1762] D loss: 1.4020, G loss: 0.8023\n",
      "[1684/1762] D loss: 1.3990, G loss: 0.4970\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.7107\n",
      "train error: \n",
      " D loss: 1.346512, G loss: 0.695691, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336862, G loss: 0.695855, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6627\n",
      "[84/1762] D loss: 1.2280, G loss: 0.7662\n",
      "[164/1762] D loss: 1.3969, G loss: 0.6612\n",
      "[244/1762] D loss: 1.3839, G loss: 0.8132\n",
      "[324/1762] D loss: 1.4154, G loss: 0.8368\n",
      "[404/1762] D loss: 1.4076, G loss: 0.6849\n",
      "[484/1762] D loss: 1.3964, G loss: 0.7787\n",
      "[564/1762] D loss: 1.3939, G loss: 0.7006\n",
      "[644/1762] D loss: 1.3828, G loss: 0.7077\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6937\n",
      "[804/1762] D loss: 1.2232, G loss: 0.8113\n",
      "[884/1762] D loss: 1.3907, G loss: 0.7808\n",
      "[964/1762] D loss: 1.2180, G loss: 0.7905\n",
      "[1044/1762] D loss: 1.4084, G loss: 0.8393\n",
      "[1124/1762] D loss: 1.2258, G loss: 0.8335\n",
      "[1204/1762] D loss: 1.3924, G loss: 0.5837\n",
      "[1284/1762] D loss: 1.4045, G loss: 0.7706\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.6113\n",
      "[1444/1762] D loss: 1.3774, G loss: 0.6751\n",
      "[1524/1762] D loss: 1.6027, G loss: 0.6589\n",
      "[1604/1762] D loss: 1.4726, G loss: 0.6872\n",
      "[1684/1762] D loss: 1.3465, G loss: 0.7765\n",
      "[1762/1762] D loss: 1.2462, G loss: 0.7727\n",
      "train error: \n",
      " D loss: 1.241066, G loss: 0.722747, D accuracy: 65.2%, cell accuracy: 98.4%, board accuracy: 21.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.239735, G loss: 0.737002, D accuracy: 66.9%, cell accuracy: 98.4%, board accuracy: 19.5% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1968, G loss: 0.7570\n",
      "[84/1762] D loss: 1.2501, G loss: 0.7296\n",
      "[164/1762] D loss: 1.4926, G loss: 0.6549\n",
      "[244/1762] D loss: 1.4005, G loss: 0.6305\n",
      "[324/1762] D loss: 1.3932, G loss: 0.5391\n",
      "[404/1762] D loss: 1.4253, G loss: 0.7854\n",
      "[484/1762] D loss: 1.4347, G loss: 0.7123\n",
      "[564/1762] D loss: 1.4057, G loss: 0.6297\n",
      "[644/1762] D loss: 1.4004, G loss: 0.6774\n",
      "[724/1762] D loss: 1.4057, G loss: 0.8375\n",
      "[804/1762] D loss: 1.3905, G loss: 0.7019\n",
      "[884/1762] D loss: 1.3888, G loss: 0.7016\n",
      "[964/1762] D loss: 1.3920, G loss: 0.6807\n",
      "[1044/1762] D loss: 1.3955, G loss: 0.7091\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.6981\n",
      "[1204/1762] D loss: 1.3786, G loss: 0.6190\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.7595\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.7117\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7021\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.7325\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.6958\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6962\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.7041\n",
      "train error: \n",
      " D loss: 1.377589, G loss: 0.707525, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377255, G loss: 0.705754, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6964\n",
      "[84/1762] D loss: 1.3904, G loss: 0.7098\n",
      "[164/1762] D loss: 1.3355, G loss: 0.7406\n",
      "[244/1762] D loss: 1.3477, G loss: 0.7300\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6796\n",
      "[404/1762] D loss: 1.3610, G loss: 0.6986\n",
      "[484/1762] D loss: 1.3741, G loss: 0.6501\n",
      "[564/1762] D loss: 1.3328, G loss: 0.7324\n",
      "[644/1762] D loss: 1.3067, G loss: 0.7467\n",
      "[724/1762] D loss: 1.2678, G loss: 0.7272\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6769\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6957\n",
      "[964/1762] D loss: 1.3913, G loss: 0.7576\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7283\n",
      "[1124/1762] D loss: 1.3080, G loss: 0.8117\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7158\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7355\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6893\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6847\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.7254\n",
      "[1604/1762] D loss: 1.3208, G loss: 0.6891\n",
      "[1684/1762] D loss: 1.3983, G loss: 0.7046\n",
      "[1762/1762] D loss: 1.3420, G loss: 0.7554\n",
      "train error: \n",
      " D loss: 1.362346, G loss: 0.805358, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353328, G loss: 0.807037, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4018, G loss: 0.7761\n",
      "[84/1762] D loss: 1.3895, G loss: 0.7023\n",
      "[164/1762] D loss: 1.2690, G loss: 0.7925\n",
      "[244/1762] D loss: 1.3935, G loss: 0.7533\n",
      "[324/1762] D loss: 1.4012, G loss: 0.7469\n",
      "[404/1762] D loss: 1.3699, G loss: 0.7185\n",
      "[484/1762] D loss: 1.4461, G loss: 0.6591\n",
      "[564/1762] D loss: 1.4487, G loss: 0.6488\n",
      "[644/1762] D loss: 1.5266, G loss: 0.7058\n",
      "[724/1762] D loss: 1.4357, G loss: 0.8480\n",
      "[804/1762] D loss: 1.1341, G loss: 0.9562\n",
      "[884/1762] D loss: 1.3158, G loss: 0.7001\n",
      "[964/1762] D loss: 1.4159, G loss: 0.8427\n",
      "[1044/1762] D loss: 1.3963, G loss: 0.6895\n",
      "[1124/1762] D loss: 1.3841, G loss: 0.7260\n",
      "[1204/1762] D loss: 1.4437, G loss: 0.7133\n",
      "[1284/1762] D loss: 1.4020, G loss: 0.7373\n",
      "[1364/1762] D loss: 1.4258, G loss: 0.7285\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6749\n",
      "[1524/1762] D loss: 1.3854, G loss: 0.7356\n",
      "[1604/1762] D loss: 1.3925, G loss: 0.7206\n",
      "[1684/1762] D loss: 1.3852, G loss: 0.6923\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7076\n",
      "train error: \n",
      " D loss: 1.383598, G loss: 0.690081, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384439, G loss: 0.689167, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6989\n",
      "[84/1762] D loss: 1.3893, G loss: 0.7006\n",
      "[164/1762] D loss: 1.3885, G loss: 0.6636\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7054\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6867\n",
      "[404/1762] D loss: 1.3846, G loss: 0.6886\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6942\n",
      "[564/1762] D loss: 1.3916, G loss: 0.6833\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6740\n",
      "[724/1762] D loss: 1.3159, G loss: 0.6938\n",
      "[804/1762] D loss: 1.3893, G loss: 0.7057\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6374\n",
      "[964/1762] D loss: 1.3860, G loss: 0.6755\n",
      "[1044/1762] D loss: 1.2773, G loss: 0.7336\n",
      "[1124/1762] D loss: 1.3973, G loss: 0.6303\n",
      "[1204/1762] D loss: 1.3850, G loss: 0.7000\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.7546\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.6373\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.6909\n",
      "[1524/1762] D loss: 1.1283, G loss: 0.7932\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6977\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.6786\n",
      "[1762/1762] D loss: 1.1162, G loss: 0.9312\n",
      "train error: \n",
      " D loss: 1.355320, G loss: 0.795750, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346199, G loss: 0.798320, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2445, G loss: 0.8032\n",
      "[84/1762] D loss: 1.3896, G loss: 0.7109\n",
      "[164/1762] D loss: 1.3970, G loss: 0.6847\n",
      "[244/1762] D loss: 1.3977, G loss: 0.6645\n",
      "[324/1762] D loss: 1.2305, G loss: 0.6651\n",
      "[404/1762] D loss: 1.3895, G loss: 0.7807\n",
      "[484/1762] D loss: 1.3988, G loss: 0.7533\n",
      "[564/1762] D loss: 1.3914, G loss: 0.7296\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6853\n",
      "[724/1762] D loss: 1.3936, G loss: 0.7258\n",
      "[804/1762] D loss: 1.2123, G loss: 0.7815\n",
      "[884/1762] D loss: 1.4002, G loss: 0.6671\n",
      "[964/1762] D loss: 1.4009, G loss: 0.7939\n",
      "[1044/1762] D loss: 1.3925, G loss: 0.6663\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.6517\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.7269\n",
      "[1284/1762] D loss: 1.4002, G loss: 0.7538\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.7597\n",
      "[1444/1762] D loss: 1.3929, G loss: 0.6012\n",
      "[1524/1762] D loss: 1.4243, G loss: 0.5613\n",
      "[1604/1762] D loss: 1.0953, G loss: 0.7981\n",
      "[1684/1762] D loss: 1.4111, G loss: 0.6267\n",
      "[1762/1762] D loss: 1.3975, G loss: 0.6589\n",
      "train error: \n",
      " D loss: 1.340704, G loss: 0.746760, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328081, G loss: 0.750377, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3974, G loss: 0.7230\n",
      "[84/1762] D loss: 1.3974, G loss: 0.7635\n",
      "[164/1762] D loss: 1.4130, G loss: 0.7355\n",
      "[244/1762] D loss: 1.3928, G loss: 0.7008\n",
      "[324/1762] D loss: 1.3995, G loss: 0.7166\n",
      "[404/1762] D loss: 1.1974, G loss: 0.7959\n",
      "[484/1762] D loss: 1.3701, G loss: 0.6575\n",
      "[564/1762] D loss: 1.3994, G loss: 0.7141\n",
      "[644/1762] D loss: 1.3968, G loss: 0.8336\n",
      "[724/1762] D loss: 1.7588, G loss: 0.6960\n",
      "[804/1762] D loss: 1.3894, G loss: 0.8039\n",
      "[884/1762] D loss: 1.3844, G loss: 1.0024\n",
      "[964/1762] D loss: 1.2115, G loss: 0.7854\n",
      "[1044/1762] D loss: 1.5081, G loss: 0.7913\n",
      "[1124/1762] D loss: 1.5271, G loss: 0.6040\n",
      "[1204/1762] D loss: 1.5497, G loss: 0.5787\n",
      "[1284/1762] D loss: 1.3996, G loss: 0.7432\n",
      "[1364/1762] D loss: 1.4540, G loss: 0.6323\n",
      "[1444/1762] D loss: 1.4393, G loss: 0.9699\n",
      "[1524/1762] D loss: 1.3778, G loss: 0.7077\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.6756\n",
      "[1684/1762] D loss: 1.4455, G loss: 0.7310\n",
      "[1762/1762] D loss: 1.3954, G loss: 0.6005\n",
      "train error: \n",
      " D loss: 1.396519, G loss: 0.693471, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399287, G loss: 0.692196, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.7305\n",
      "[84/1762] D loss: 1.3874, G loss: 0.7059\n",
      "[164/1762] D loss: 1.4116, G loss: 0.7071\n",
      "[244/1762] D loss: 1.3818, G loss: 0.6730\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6904\n",
      "[404/1762] D loss: 1.4026, G loss: 0.5996\n",
      "[484/1762] D loss: 1.3894, G loss: 0.7423\n",
      "[564/1762] D loss: 1.3601, G loss: 0.7428\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6849\n",
      "[724/1762] D loss: 1.3905, G loss: 0.6826\n",
      "[804/1762] D loss: 1.3941, G loss: 0.6935\n",
      "[884/1762] D loss: 1.3886, G loss: 0.7227\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7058\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7204\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7106\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.7343\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6989\n",
      "[1364/1762] D loss: 1.3973, G loss: 0.6283\n",
      "[1444/1762] D loss: 1.3162, G loss: 0.8042\n",
      "[1524/1762] D loss: 1.3926, G loss: 0.6836\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.6576\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.7043\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.7611\n",
      "train error: \n",
      " D loss: 1.362268, G loss: 0.744850, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355476, G loss: 0.747058, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.7257\n",
      "[84/1762] D loss: 1.2828, G loss: 0.7717\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6893\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6607\n",
      "[324/1762] D loss: 1.3986, G loss: 0.7789\n",
      "[404/1762] D loss: 1.3919, G loss: 0.6107\n",
      "[484/1762] D loss: 1.3903, G loss: 0.7638\n",
      "[564/1762] D loss: 1.3934, G loss: 0.6449\n",
      "[644/1762] D loss: 1.3913, G loss: 0.7482\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7130\n",
      "[804/1762] D loss: 1.3896, G loss: 0.7509\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6726\n",
      "[964/1762] D loss: 1.3945, G loss: 0.7472\n",
      "[1044/1762] D loss: 1.3928, G loss: 0.7711\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7414\n",
      "[1204/1762] D loss: 1.3971, G loss: 0.7949\n",
      "[1284/1762] D loss: 1.3649, G loss: 0.7375\n",
      "[1364/1762] D loss: 1.3928, G loss: 0.7754\n",
      "[1444/1762] D loss: 1.3914, G loss: 0.7252\n",
      "[1524/1762] D loss: 1.2251, G loss: 0.8428\n",
      "[1604/1762] D loss: 1.2342, G loss: 0.6836\n",
      "[1684/1762] D loss: 1.2150, G loss: 0.7528\n",
      "[1762/1762] D loss: 1.3986, G loss: 0.6459\n",
      "train error: \n",
      " D loss: 1.345561, G loss: 0.728259, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334430, G loss: 0.729622, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.7673\n",
      "[84/1762] D loss: 1.4147, G loss: 0.8573\n",
      "[164/1762] D loss: 1.3752, G loss: 0.7404\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7455\n",
      "[324/1762] D loss: 1.2107, G loss: 0.7425\n",
      "[404/1762] D loss: 1.3931, G loss: 0.6639\n",
      "[484/1762] D loss: 1.3989, G loss: 0.7350\n",
      "[564/1762] D loss: 1.2185, G loss: 0.6877\n",
      "[644/1762] D loss: 1.3930, G loss: 0.7434\n",
      "[724/1762] D loss: 1.4053, G loss: 0.8268\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6907\n",
      "[884/1762] D loss: 1.3936, G loss: 0.6705\n",
      "[964/1762] D loss: 1.4269, G loss: 0.8480\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.7925\n",
      "[1124/1762] D loss: 1.3992, G loss: 0.7973\n",
      "[1204/1762] D loss: 1.3966, G loss: 0.7088\n",
      "[1284/1762] D loss: 1.2476, G loss: 0.7845\n",
      "[1364/1762] D loss: 1.3494, G loss: 0.6881\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.6977\n",
      "[1524/1762] D loss: 1.2083, G loss: 0.7525\n",
      "[1604/1762] D loss: 1.5071, G loss: 0.5846\n",
      "[1684/1762] D loss: 1.3198, G loss: 0.9468\n",
      "[1762/1762] D loss: 1.1945, G loss: 0.8971\n",
      "train error: \n",
      " D loss: 1.248611, G loss: 0.872337, D accuracy: 73.0%, cell accuracy: 99.4%, board accuracy: 38.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.238862, G loss: 0.894681, D accuracy: 74.7%, cell accuracy: 99.3%, board accuracy: 34.3% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2259, G loss: 0.8705\n",
      "[84/1762] D loss: 1.3987, G loss: 0.7175\n",
      "[164/1762] D loss: 1.3357, G loss: 0.6650\n",
      "[244/1762] D loss: 1.3169, G loss: 0.6549\n",
      "[324/1762] D loss: 1.3830, G loss: 0.7782\n",
      "[404/1762] D loss: 1.3437, G loss: 0.7818\n",
      "[484/1762] D loss: 1.3620, G loss: 0.7613\n",
      "[564/1762] D loss: 1.3915, G loss: 0.6663\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6521\n",
      "[724/1762] D loss: 1.3856, G loss: 0.6574\n",
      "[804/1762] D loss: 1.2486, G loss: 0.7401\n",
      "[884/1762] D loss: 1.4012, G loss: 0.8111\n",
      "[964/1762] D loss: 1.3888, G loss: 0.6965\n",
      "[1044/1762] D loss: 1.3387, G loss: 0.7325\n",
      "[1124/1762] D loss: 1.3796, G loss: 0.8172\n",
      "[1204/1762] D loss: 1.2029, G loss: 0.8357\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.6382\n",
      "[1364/1762] D loss: 1.4030, G loss: 0.7830\n",
      "[1444/1762] D loss: 1.2026, G loss: 0.8357\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.6334\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.6494\n",
      "[1684/1762] D loss: 1.4003, G loss: 0.8314\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7453\n",
      "train error: \n",
      " D loss: 1.336998, G loss: 0.728080, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324965, G loss: 0.726228, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.7144\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6840\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6820\n",
      "[244/1762] D loss: 1.3795, G loss: 0.8541\n",
      "[324/1762] D loss: 1.3913, G loss: 0.7408\n",
      "[404/1762] D loss: 1.3891, G loss: 0.7322\n",
      "[484/1762] D loss: 1.3894, G loss: 0.6804\n",
      "[564/1762] D loss: 1.3928, G loss: 0.7370\n",
      "[644/1762] D loss: 1.3933, G loss: 0.7398\n",
      "[724/1762] D loss: 1.3925, G loss: 0.6885\n",
      "[804/1762] D loss: 1.2424, G loss: 0.9658\n",
      "[884/1762] D loss: 1.4030, G loss: 0.8260\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6843\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.7718\n",
      "[1124/1762] D loss: 1.3950, G loss: 0.7921\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6303\n",
      "[1284/1762] D loss: 1.3888, G loss: 0.7032\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.7287\n",
      "[1444/1762] D loss: 1.4080, G loss: 0.7980\n",
      "[1524/1762] D loss: 1.4067, G loss: 0.8153\n",
      "[1604/1762] D loss: 1.4042, G loss: 0.7157\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6449\n",
      "[1762/1762] D loss: 1.4176, G loss: 0.8106\n",
      "train error: \n",
      " D loss: 1.338734, G loss: 0.821652, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325148, G loss: 0.819401, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3988, G loss: 0.6819\n",
      "[84/1762] D loss: 1.3984, G loss: 0.6955\n",
      "[164/1762] D loss: 1.3804, G loss: 0.7160\n",
      "[244/1762] D loss: 1.1802, G loss: 0.7388\n",
      "[324/1762] D loss: 1.3903, G loss: 0.6841\n",
      "[404/1762] D loss: 1.3832, G loss: 0.7426\n",
      "[484/1762] D loss: 1.5384, G loss: 0.8071\n",
      "[564/1762] D loss: 1.6070, G loss: 0.6991\n",
      "[644/1762] D loss: 1.4540, G loss: 0.8689\n",
      "[724/1762] D loss: 1.3544, G loss: 0.9979\n",
      "[804/1762] D loss: 1.3967, G loss: 0.7096\n",
      "[884/1762] D loss: 1.3358, G loss: 0.8170\n",
      "[964/1762] D loss: 1.3266, G loss: 0.6869\n",
      "[1044/1762] D loss: 1.4045, G loss: 0.7140\n",
      "[1124/1762] D loss: 1.4125, G loss: 0.8013\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.5914\n",
      "[1284/1762] D loss: 1.4003, G loss: 0.7600\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.6623\n",
      "[1444/1762] D loss: 1.3996, G loss: 0.7492\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6938\n",
      "[1604/1762] D loss: 1.2770, G loss: 0.7562\n",
      "[1684/1762] D loss: 1.3255, G loss: 0.7076\n",
      "[1762/1762] D loss: 1.3947, G loss: 0.7603\n",
      "train error: \n",
      " D loss: 1.362172, G loss: 0.721458, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358753, G loss: 0.721015, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6616\n",
      "[84/1762] D loss: 1.3949, G loss: 0.6583\n",
      "[164/1762] D loss: 1.3968, G loss: 0.7937\n",
      "[244/1762] D loss: 1.3892, G loss: 0.6538\n",
      "[324/1762] D loss: 1.2340, G loss: 0.8098\n",
      "[404/1762] D loss: 1.3935, G loss: 0.6612\n",
      "[484/1762] D loss: 1.3889, G loss: 0.6770\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7389\n",
      "[644/1762] D loss: 1.2119, G loss: 0.7597\n",
      "[724/1762] D loss: 1.3960, G loss: 0.7621\n",
      "[804/1762] D loss: 1.3900, G loss: 0.6893\n",
      "[884/1762] D loss: 1.3935, G loss: 0.7194\n",
      "[964/1762] D loss: 1.3964, G loss: 0.6924\n",
      "[1044/1762] D loss: 1.1854, G loss: 0.8033\n",
      "[1124/1762] D loss: 1.3844, G loss: 0.6893\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7451\n",
      "[1284/1762] D loss: 1.3970, G loss: 0.6305\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.7276\n",
      "[1444/1762] D loss: 1.3984, G loss: 0.7691\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7449\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6336\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.7063\n",
      "[1762/1762] D loss: 0.9803, G loss: 0.8285\n",
      "train error: \n",
      " D loss: 1.331258, G loss: 0.750887, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316761, G loss: 0.751189, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.7401\n",
      "[84/1762] D loss: 1.3889, G loss: 0.6766\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6314\n",
      "[244/1762] D loss: 1.3906, G loss: 0.6996\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6807\n",
      "[404/1762] D loss: 1.3969, G loss: 0.6946\n",
      "[484/1762] D loss: 1.3915, G loss: 0.7414\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6510\n",
      "[644/1762] D loss: 1.4011, G loss: 0.7318\n",
      "[724/1762] D loss: 1.4033, G loss: 0.8192\n",
      "[804/1762] D loss: 1.0393, G loss: 0.8682\n",
      "[884/1762] D loss: 1.3923, G loss: 0.5917\n",
      "[964/1762] D loss: 1.2528, G loss: 1.0524\n",
      "[1044/1762] D loss: 1.4776, G loss: 0.5971\n",
      "[1124/1762] D loss: 1.3063, G loss: 0.7475\n",
      "[1204/1762] D loss: 1.2187, G loss: 0.8102\n",
      "[1284/1762] D loss: 1.3570, G loss: 0.8789\n",
      "[1364/1762] D loss: 1.3701, G loss: 0.6706\n",
      "[1444/1762] D loss: 1.3838, G loss: 0.7599\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6786\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6897\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7191\n",
      "train error: \n",
      " D loss: 1.392143, G loss: 0.697930, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394639, G loss: 0.698209, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4092, G loss: 0.7290\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6849\n",
      "[164/1762] D loss: 1.3850, G loss: 0.6826\n",
      "[244/1762] D loss: 1.3904, G loss: 0.6594\n",
      "[324/1762] D loss: 1.3877, G loss: 0.6882\n",
      "[404/1762] D loss: 1.3905, G loss: 0.6852\n",
      "[484/1762] D loss: 1.3889, G loss: 0.7326\n",
      "[564/1762] D loss: 1.3899, G loss: 0.6747\n",
      "[644/1762] D loss: 1.3695, G loss: 0.7479\n",
      "[724/1762] D loss: 1.2911, G loss: 0.7120\n",
      "[804/1762] D loss: 1.3685, G loss: 0.7295\n",
      "[884/1762] D loss: 1.3935, G loss: 0.7105\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6946\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6860\n",
      "[1124/1762] D loss: 1.3616, G loss: 0.7611\n",
      "[1204/1762] D loss: 1.3923, G loss: 0.6367\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7130\n",
      "[1364/1762] D loss: 1.2695, G loss: 0.7789\n",
      "[1444/1762] D loss: 1.3680, G loss: 0.6968\n",
      "[1524/1762] D loss: 1.2374, G loss: 0.7667\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.6800\n",
      "[1684/1762] D loss: 1.3860, G loss: 0.7199\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6797\n",
      "train error: \n",
      " D loss: 1.340850, G loss: 0.714921, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330243, G loss: 0.716553, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2150, G loss: 0.7611\n",
      "[84/1762] D loss: 1.3909, G loss: 0.6402\n",
      "[164/1762] D loss: 1.2412, G loss: 0.7503\n",
      "[244/1762] D loss: 1.3927, G loss: 0.7729\n",
      "[324/1762] D loss: 1.0406, G loss: 0.7915\n",
      "[404/1762] D loss: 1.3935, G loss: 0.7839\n",
      "[484/1762] D loss: 1.1791, G loss: 0.8643\n",
      "[564/1762] D loss: 1.0333, G loss: 0.8110\n",
      "[644/1762] D loss: 1.4301, G loss: 0.5943\n",
      "[724/1762] D loss: 1.4090, G loss: 0.7183\n",
      "[804/1762] D loss: 1.1949, G loss: 0.7786\n",
      "[884/1762] D loss: 1.3842, G loss: 0.7583\n",
      "[964/1762] D loss: 1.3831, G loss: 0.7572\n",
      "[1044/1762] D loss: 1.2377, G loss: 0.7101\n",
      "[1124/1762] D loss: 1.1862, G loss: 0.8893\n",
      "[1204/1762] D loss: 1.3718, G loss: 0.6788\n",
      "[1284/1762] D loss: 1.3854, G loss: 0.7322\n",
      "[1364/1762] D loss: 1.2231, G loss: 0.7355\n",
      "[1444/1762] D loss: 1.3396, G loss: 0.7178\n",
      "[1524/1762] D loss: 1.3772, G loss: 0.7360\n",
      "[1604/1762] D loss: 1.1323, G loss: 0.8454\n",
      "[1684/1762] D loss: 1.3528, G loss: 0.7723\n",
      "[1762/1762] D loss: 0.9928, G loss: 0.9063\n",
      "train error: \n",
      " D loss: 1.307199, G loss: 0.806818, D accuracy: 57.5%, cell accuracy: 98.8%, board accuracy: 32.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289125, G loss: 0.809053, D accuracy: 59.8%, cell accuracy: 98.7%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1638, G loss: 0.9275\n",
      "[84/1762] D loss: 1.4002, G loss: 0.8118\n",
      "[164/1762] D loss: 1.1094, G loss: 0.8681\n",
      "[244/1762] D loss: 1.3783, G loss: 0.7425\n",
      "[324/1762] D loss: 1.3883, G loss: 0.7855\n",
      "[404/1762] D loss: 1.3886, G loss: 0.7111\n",
      "[484/1762] D loss: 1.1802, G loss: 0.8224\n",
      "[564/1762] D loss: 1.3813, G loss: 0.7808\n",
      "[644/1762] D loss: 1.3955, G loss: 0.6999\n",
      "[724/1762] D loss: 1.1609, G loss: 0.8252\n",
      "[804/1762] D loss: 1.4014, G loss: 0.7807\n",
      "[884/1762] D loss: 1.3922, G loss: 0.7098\n",
      "[964/1762] D loss: 1.1426, G loss: 0.8062\n",
      "[1044/1762] D loss: 1.1722, G loss: 0.7980\n",
      "[1124/1762] D loss: 1.4069, G loss: 0.6184\n",
      "[1204/1762] D loss: 1.3997, G loss: 0.8121\n",
      "[1284/1762] D loss: 1.4794, G loss: 0.6827\n",
      "[1364/1762] D loss: 1.6449, G loss: 0.6930\n",
      "[1444/1762] D loss: 1.5569, G loss: 0.6125\n",
      "[1524/1762] D loss: 1.2207, G loss: 0.8529\n",
      "[1604/1762] D loss: 1.3782, G loss: 0.7976\n",
      "[1684/1762] D loss: 1.2331, G loss: 0.7963\n",
      "[1762/1762] D loss: 1.3810, G loss: 0.6306\n",
      "train error: \n",
      " D loss: 1.384094, G loss: 0.682195, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 75.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391293, G loss: 0.685853, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3975, G loss: 0.6594\n",
      "[84/1762] D loss: 1.3971, G loss: 0.7582\n",
      "[164/1762] D loss: 1.3464, G loss: 0.8026\n",
      "[244/1762] D loss: 1.3965, G loss: 0.6166\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6715\n",
      "[404/1762] D loss: 1.4298, G loss: 0.6337\n",
      "[484/1762] D loss: 1.3894, G loss: 0.7274\n",
      "[564/1762] D loss: 1.3736, G loss: 0.7205\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6918\n",
      "[724/1762] D loss: 1.3875, G loss: 0.7295\n",
      "[804/1762] D loss: 1.4013, G loss: 0.7065\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7038\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6706\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.6572\n",
      "[1124/1762] D loss: 1.4351, G loss: 0.7062\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6634\n",
      "[1284/1762] D loss: 1.3751, G loss: 0.7128\n",
      "[1364/1762] D loss: 1.3725, G loss: 0.7177\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7055\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7242\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.7366\n",
      "[1684/1762] D loss: 1.3799, G loss: 0.6960\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6734\n",
      "train error: \n",
      " D loss: 1.366974, G loss: 0.701533, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362754, G loss: 0.702690, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3762, G loss: 0.6786\n",
      "[84/1762] D loss: 1.3885, G loss: 0.7286\n",
      "[164/1762] D loss: 1.3895, G loss: 0.6811\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6548\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6880\n",
      "[404/1762] D loss: 1.3879, G loss: 0.7357\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6588\n",
      "[564/1762] D loss: 1.2724, G loss: 0.7339\n",
      "[644/1762] D loss: 1.2619, G loss: 0.7466\n",
      "[724/1762] D loss: 1.2541, G loss: 0.8380\n",
      "[804/1762] D loss: 1.2987, G loss: 0.6330\n",
      "[884/1762] D loss: 1.3988, G loss: 0.7695\n",
      "[964/1762] D loss: 1.3980, G loss: 0.6908\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.7217\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.6563\n",
      "[1204/1762] D loss: 1.2172, G loss: 0.8179\n",
      "[1284/1762] D loss: 1.0854, G loss: 0.8046\n",
      "[1364/1762] D loss: 1.3956, G loss: 0.7694\n",
      "[1444/1762] D loss: 1.4019, G loss: 0.7447\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.7414\n",
      "[1604/1762] D loss: 1.2484, G loss: 0.8644\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.7536\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.7480\n",
      "train error: \n",
      " D loss: 1.343105, G loss: 0.802519, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328860, G loss: 0.805506, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3946, G loss: 0.7626\n",
      "[84/1762] D loss: 1.3959, G loss: 0.7777\n",
      "[164/1762] D loss: 1.1222, G loss: 0.7672\n",
      "[244/1762] D loss: 1.3950, G loss: 0.7645\n",
      "[324/1762] D loss: 1.1842, G loss: 0.8237\n",
      "[404/1762] D loss: 1.3994, G loss: 0.6768\n",
      "[484/1762] D loss: 1.4366, G loss: 0.8040\n",
      "[564/1762] D loss: 1.3976, G loss: 0.6387\n",
      "[644/1762] D loss: 1.3914, G loss: 0.6988\n",
      "[724/1762] D loss: 1.3870, G loss: 0.7107\n",
      "[804/1762] D loss: 1.3947, G loss: 0.7790\n",
      "[884/1762] D loss: 0.9643, G loss: 0.9305\n",
      "[964/1762] D loss: 1.3918, G loss: 0.6916\n",
      "[1044/1762] D loss: 1.4006, G loss: 0.6625\n",
      "[1124/1762] D loss: 1.4028, G loss: 0.5792\n",
      "[1204/1762] D loss: 1.2093, G loss: 0.7059\n",
      "[1284/1762] D loss: 1.4031, G loss: 0.6030\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.7045\n",
      "[1444/1762] D loss: 1.3972, G loss: 0.7813\n",
      "[1524/1762] D loss: 1.1685, G loss: 0.7884\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6512\n",
      "[1684/1762] D loss: 1.1768, G loss: 0.9167\n",
      "[1762/1762] D loss: 1.4074, G loss: 0.6085\n",
      "train error: \n",
      " D loss: 1.352428, G loss: 0.594746, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337286, G loss: 0.598649, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4135, G loss: 0.6401\n",
      "[84/1762] D loss: 1.3883, G loss: 0.6806\n",
      "[164/1762] D loss: 1.1775, G loss: 0.7852\n",
      "[244/1762] D loss: 1.4000, G loss: 0.8087\n",
      "[324/1762] D loss: 1.3903, G loss: 0.7094\n",
      "[404/1762] D loss: 1.3897, G loss: 0.6669\n",
      "[484/1762] D loss: 1.3953, G loss: 0.7946\n",
      "[564/1762] D loss: 1.3932, G loss: 0.6931\n",
      "[644/1762] D loss: 1.4000, G loss: 0.6180\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7084\n",
      "[804/1762] D loss: 1.1690, G loss: 0.8571\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7128\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7533\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.7978\n",
      "[1124/1762] D loss: 1.3849, G loss: 0.6244\n",
      "[1204/1762] D loss: 1.4013, G loss: 0.7101\n",
      "[1284/1762] D loss: 2.2124, G loss: 0.6605\n",
      "[1364/1762] D loss: 1.4352, G loss: 1.0613\n",
      "[1444/1762] D loss: 1.3008, G loss: 0.7682\n",
      "[1524/1762] D loss: 1.3255, G loss: 0.6733\n",
      "[1604/1762] D loss: 1.3462, G loss: 0.7978\n",
      "[1684/1762] D loss: 1.4321, G loss: 0.8030\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6669\n",
      "train error: \n",
      " D loss: 1.413640, G loss: 0.695705, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.423930, G loss: 0.696805, D accuracy: 48.9%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7402\n",
      "[84/1762] D loss: 1.3945, G loss: 0.7056\n",
      "[164/1762] D loss: 1.4539, G loss: 0.6592\n",
      "[244/1762] D loss: 1.4618, G loss: 0.6462\n",
      "[324/1762] D loss: 1.3961, G loss: 0.7382\n",
      "[404/1762] D loss: 1.4633, G loss: 0.7369\n",
      "[484/1762] D loss: 1.3882, G loss: 0.7422\n",
      "[564/1762] D loss: 1.3629, G loss: 0.7490\n",
      "[644/1762] D loss: 1.3850, G loss: 0.7879\n",
      "[724/1762] D loss: 1.3921, G loss: 0.6365\n",
      "[804/1762] D loss: 1.3455, G loss: 0.7365\n",
      "[884/1762] D loss: 1.3325, G loss: 0.7146\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6835\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6720\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.7563\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.6987\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7149\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.6425\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.7439\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6692\n",
      "[1604/1762] D loss: 1.3793, G loss: 0.7497\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.7339\n",
      "[1762/1762] D loss: 1.3923, G loss: 0.6268\n",
      "train error: \n",
      " D loss: 1.353210, G loss: 0.669227, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345210, G loss: 0.669487, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.6364\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6437\n",
      "[164/1762] D loss: 1.3820, G loss: 0.6497\n",
      "[244/1762] D loss: 1.3736, G loss: 0.6570\n",
      "[324/1762] D loss: 1.3605, G loss: 0.6679\n",
      "[404/1762] D loss: 1.3311, G loss: 0.6792\n",
      "[484/1762] D loss: 1.2753, G loss: 0.7072\n",
      "[564/1762] D loss: 1.2275, G loss: 0.7335\n",
      "[644/1762] D loss: 1.0952, G loss: 0.8223\n",
      "[724/1762] D loss: 0.9417, G loss: 1.0556\n",
      "[804/1762] D loss: 0.6956, G loss: 1.2715\n",
      "[884/1762] D loss: 0.6683, G loss: 1.5758\n",
      "[964/1762] D loss: 0.4675, G loss: 1.9782\n",
      "[1044/1762] D loss: 0.3611, G loss: 2.3018\n",
      "[1124/1762] D loss: 0.2420, G loss: 2.4965\n",
      "[1204/1762] D loss: 0.1505, G loss: 3.1335\n",
      "[1284/1762] D loss: 0.1931, G loss: 2.9854\n",
      "[1364/1762] D loss: 0.1473, G loss: 3.6477\n",
      "[1444/1762] D loss: 0.1180, G loss: 3.6742\n",
      "[1524/1762] D loss: 0.0918, G loss: 3.9002\n",
      "[1604/1762] D loss: 0.0913, G loss: 4.0138\n",
      "[1684/1762] D loss: 0.0807, G loss: 4.5064\n",
      "[1762/1762] D loss: 0.0495, G loss: 4.7106\n",
      "train error: \n",
      " D loss: 0.058619, G loss: 5.744555, D accuracy: 100.0%, cell accuracy: 86.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.057662, G loss: 5.670727, D accuracy: 100.0%, cell accuracy: 86.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0599, G loss: 4.3763\n",
      "[84/1762] D loss: 0.0506, G loss: 4.8705\n",
      "[164/1762] D loss: 0.1266, G loss: 4.4044\n",
      "[244/1762] D loss: 0.1317, G loss: 5.4551\n",
      "[324/1762] D loss: 0.0959, G loss: 5.0687\n",
      "[404/1762] D loss: 0.0730, G loss: 4.7754\n",
      "[484/1762] D loss: 0.0327, G loss: 5.2551\n",
      "[564/1762] D loss: 0.0249, G loss: 5.8110\n",
      "[644/1762] D loss: 0.0519, G loss: 4.8370\n",
      "[724/1762] D loss: 0.0299, G loss: 5.1297\n",
      "[804/1762] D loss: 0.0659, G loss: 4.4643\n",
      "[884/1762] D loss: 0.0292, G loss: 5.1358\n",
      "[964/1762] D loss: 0.0376, G loss: 4.8340\n",
      "[1044/1762] D loss: 0.0571, G loss: 4.2570\n",
      "[1124/1762] D loss: 0.0671, G loss: 4.7725\n",
      "[1204/1762] D loss: 0.0397, G loss: 4.7235\n",
      "[1284/1762] D loss: 0.0341, G loss: 3.9549\n",
      "[1364/1762] D loss: 0.0761, G loss: 3.8883\n",
      "[1444/1762] D loss: 0.0603, G loss: 4.4552\n",
      "[1524/1762] D loss: 0.0153, G loss: 5.7276\n",
      "[1604/1762] D loss: 0.0392, G loss: 4.4565\n",
      "[1684/1762] D loss: 0.0454, G loss: 4.0056\n",
      "[1762/1762] D loss: 0.0293, G loss: 4.9017\n",
      "train error: \n",
      " D loss: 0.028534, G loss: 5.142011, D accuracy: 100.0%, cell accuracy: 95.3%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.028525, G loss: 5.130602, D accuracy: 100.0%, cell accuracy: 95.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0225, G loss: 4.8939\n",
      "[84/1762] D loss: 0.0298, G loss: 5.1064\n",
      "[164/1762] D loss: 0.0444, G loss: 3.6242\n",
      "[244/1762] D loss: 0.0390, G loss: 4.2439\n",
      "[324/1762] D loss: 0.0495, G loss: 3.9010\n",
      "[404/1762] D loss: 0.0224, G loss: 5.0007\n",
      "[484/1762] D loss: 0.0565, G loss: 3.6829\n",
      "[564/1762] D loss: 0.0338, G loss: 4.6328\n",
      "[644/1762] D loss: 0.0722, G loss: 3.6669\n",
      "[724/1762] D loss: 0.0595, G loss: 4.7535\n",
      "[804/1762] D loss: 0.0385, G loss: 3.7052\n",
      "[884/1762] D loss: 0.0364, G loss: 3.9257\n",
      "[964/1762] D loss: 0.0393, G loss: 4.1918\n",
      "[1044/1762] D loss: 0.0675, G loss: 3.8157\n",
      "[1124/1762] D loss: 0.0764, G loss: 3.4588\n",
      "[1204/1762] D loss: 0.0297, G loss: 3.8520\n",
      "[1284/1762] D loss: 0.0397, G loss: 3.7218\n",
      "[1364/1762] D loss: 0.0505, G loss: 3.6497\n",
      "[1444/1762] D loss: 0.0173, G loss: 4.8949\n",
      "[1524/1762] D loss: 0.0415, G loss: 4.2596\n",
      "[1604/1762] D loss: 0.0347, G loss: 4.6846\n",
      "[1684/1762] D loss: 0.0700, G loss: 4.5754\n",
      "[1762/1762] D loss: 0.0174, G loss: 4.7923\n",
      "train error: \n",
      " D loss: 0.041256, G loss: 4.216908, D accuracy: 100.0%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.044610, G loss: 4.179830, D accuracy: 100.0%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0168, G loss: 5.3329\n",
      "[84/1762] D loss: 0.0209, G loss: 4.5182\n",
      "[164/1762] D loss: 0.0616, G loss: 3.3028\n",
      "[244/1762] D loss: 0.0631, G loss: 2.7825\n",
      "[324/1762] D loss: 0.0959, G loss: 2.9046\n",
      "[404/1762] D loss: 0.0400, G loss: 5.2329\n",
      "[484/1762] D loss: 0.1053, G loss: 4.6213\n",
      "[564/1762] D loss: 0.1230, G loss: 4.4469\n",
      "[644/1762] D loss: 0.0384, G loss: 4.5627\n",
      "[724/1762] D loss: 0.0566, G loss: 3.6029\n",
      "[804/1762] D loss: 0.0161, G loss: 5.0576\n",
      "[884/1762] D loss: 0.0286, G loss: 4.7772\n",
      "[964/1762] D loss: 0.0716, G loss: 3.9203\n",
      "[1044/1762] D loss: 0.1041, G loss: 3.6159\n",
      "[1124/1762] D loss: 0.1767, G loss: 2.3138\n",
      "[1204/1762] D loss: 0.0799, G loss: 4.0772\n",
      "[1284/1762] D loss: 0.0489, G loss: 3.7813\n",
      "[1364/1762] D loss: 0.0444, G loss: 4.1955\n",
      "[1444/1762] D loss: 0.0247, G loss: 4.2828\n",
      "[1524/1762] D loss: 0.0340, G loss: 4.6487\n",
      "[1604/1762] D loss: 0.0545, G loss: 4.1540\n",
      "[1684/1762] D loss: 0.0475, G loss: 3.5576\n",
      "[1762/1762] D loss: 0.0844, G loss: 6.1637\n",
      "train error: \n",
      " D loss: 0.194954, G loss: 6.001365, D accuracy: 98.2%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.213074, G loss: 5.988703, D accuracy: 97.2%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5122, G loss: 5.2500\n",
      "[84/1762] D loss: 0.0372, G loss: 3.9073\n",
      "[164/1762] D loss: 0.2077, G loss: 2.7360\n",
      "[244/1762] D loss: 0.0876, G loss: 3.6506\n",
      "[324/1762] D loss: 0.0413, G loss: 4.8095\n",
      "[404/1762] D loss: 0.0634, G loss: 3.5369\n",
      "[484/1762] D loss: 0.0460, G loss: 3.4556\n",
      "[564/1762] D loss: 0.0553, G loss: 3.3282\n",
      "[644/1762] D loss: 0.0152, G loss: 5.5507\n",
      "[724/1762] D loss: 0.2199, G loss: 2.0919\n",
      "[804/1762] D loss: 0.0878, G loss: 3.3023\n",
      "[884/1762] D loss: 0.0445, G loss: 3.6874\n",
      "[964/1762] D loss: 0.1159, G loss: 3.9325\n",
      "[1044/1762] D loss: 0.0918, G loss: 2.9311\n",
      "[1124/1762] D loss: 0.0976, G loss: 3.6251\n",
      "[1204/1762] D loss: 0.1461, G loss: 3.3084\n",
      "[1284/1762] D loss: 0.0528, G loss: 3.9124\n",
      "[1364/1762] D loss: 0.1520, G loss: 2.7675\n",
      "[1444/1762] D loss: 0.4594, G loss: 1.8445\n",
      "[1524/1762] D loss: 0.0932, G loss: 2.6430\n",
      "[1604/1762] D loss: 0.0966, G loss: 2.6187\n",
      "[1684/1762] D loss: 0.2586, G loss: 1.9959\n",
      "[1762/1762] D loss: 0.0979, G loss: 3.8265\n",
      "train error: \n",
      " D loss: 0.128341, G loss: 3.310142, D accuracy: 99.4%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.137799, G loss: 3.289660, D accuracy: 99.3%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0707, G loss: 3.3257\n",
      "[84/1762] D loss: 0.1222, G loss: 3.0596\n",
      "[164/1762] D loss: 0.1327, G loss: 2.6646\n",
      "[244/1762] D loss: 0.2982, G loss: 3.1493\n",
      "[324/1762] D loss: 0.1411, G loss: 3.3559\n",
      "[404/1762] D loss: 0.2714, G loss: 1.9472\n",
      "[484/1762] D loss: 0.1778, G loss: 2.1790\n",
      "[564/1762] D loss: 0.0882, G loss: 4.2671\n",
      "[644/1762] D loss: 0.1535, G loss: 2.0763\n",
      "[724/1762] D loss: 0.1547, G loss: 3.9908\n",
      "[804/1762] D loss: 0.1875, G loss: 2.5370\n",
      "[884/1762] D loss: 0.1685, G loss: 3.2692\n",
      "[964/1762] D loss: 0.2328, G loss: 2.4350\n",
      "[1044/1762] D loss: 0.0664, G loss: 3.6638\n",
      "[1124/1762] D loss: 0.1531, G loss: 3.8199\n",
      "[1204/1762] D loss: 0.0929, G loss: 3.5229\n",
      "[1284/1762] D loss: 0.5266, G loss: 2.9138\n",
      "[1364/1762] D loss: 0.2383, G loss: 3.7312\n",
      "[1444/1762] D loss: 0.5355, G loss: 2.5229\n",
      "[1524/1762] D loss: 0.2586, G loss: 2.1679\n",
      "[1604/1762] D loss: 0.3753, G loss: 2.2326\n",
      "[1684/1762] D loss: 0.3004, G loss: 2.6952\n",
      "[1762/1762] D loss: 0.2689, G loss: 1.6135\n",
      "train error: \n",
      " D loss: 0.292913, G loss: 2.395101, D accuracy: 97.8%, cell accuracy: 96.6%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.318671, G loss: 2.412468, D accuracy: 96.1%, cell accuracy: 96.5%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4001, G loss: 1.6593\n",
      "[84/1762] D loss: 0.2037, G loss: 1.8673\n",
      "[164/1762] D loss: 0.5398, G loss: 2.8793\n",
      "[244/1762] D loss: 0.4178, G loss: 2.3615\n",
      "[324/1762] D loss: 0.2842, G loss: 1.6054\n",
      "[404/1762] D loss: 0.2234, G loss: 3.2866\n",
      "[484/1762] D loss: 0.3677, G loss: 2.5786\n",
      "[564/1762] D loss: 1.0433, G loss: 1.6538\n",
      "[644/1762] D loss: 0.1615, G loss: 2.9086\n",
      "[724/1762] D loss: 0.1635, G loss: 2.2070\n",
      "[804/1762] D loss: 0.5281, G loss: 1.5200\n",
      "[884/1762] D loss: 0.4179, G loss: 2.1573\n",
      "[964/1762] D loss: 0.2427, G loss: 1.9742\n",
      "[1044/1762] D loss: 0.2128, G loss: 2.3981\n",
      "[1124/1762] D loss: 0.2590, G loss: 2.9134\n",
      "[1204/1762] D loss: 0.4449, G loss: 2.3401\n",
      "[1284/1762] D loss: 0.1747, G loss: 2.2891\n",
      "[1364/1762] D loss: 0.6142, G loss: 1.9428\n",
      "[1444/1762] D loss: 0.5939, G loss: 2.0536\n",
      "[1524/1762] D loss: 0.5795, G loss: 1.1502\n",
      "[1604/1762] D loss: 0.4607, G loss: 2.3528\n",
      "[1684/1762] D loss: 0.5036, G loss: 1.6926\n",
      "[1762/1762] D loss: 0.6284, G loss: 0.8389\n",
      "train error: \n",
      " D loss: 1.093042, G loss: 0.617198, D accuracy: 64.4%, cell accuracy: 96.8%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.109131, G loss: 0.636586, D accuracy: 63.9%, cell accuracy: 96.7%, board accuracy: 2.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1327, G loss: 0.7352\n",
      "[84/1762] D loss: 0.6601, G loss: 2.5450\n",
      "[164/1762] D loss: 0.8862, G loss: 1.2313\n",
      "[244/1762] D loss: 0.8415, G loss: 1.6750\n",
      "[324/1762] D loss: 0.4351, G loss: 2.6112\n",
      "[404/1762] D loss: 0.6378, G loss: 1.8474\n",
      "[484/1762] D loss: 0.7199, G loss: 0.9490\n",
      "[564/1762] D loss: 0.7732, G loss: 0.9310\n",
      "[644/1762] D loss: 1.0321, G loss: 2.0454\n",
      "[724/1762] D loss: 0.7545, G loss: 1.6900\n",
      "[804/1762] D loss: 0.9924, G loss: 1.6822\n",
      "[884/1762] D loss: 0.4629, G loss: 2.0357\n",
      "[964/1762] D loss: 0.5460, G loss: 1.9537\n",
      "[1044/1762] D loss: 1.5408, G loss: 0.8333\n",
      "[1124/1762] D loss: 0.9780, G loss: 1.5131\n",
      "[1204/1762] D loss: 1.0357, G loss: 1.5039\n",
      "[1284/1762] D loss: 1.1138, G loss: 0.7507\n",
      "[1364/1762] D loss: 0.8949, G loss: 1.8929\n",
      "[1444/1762] D loss: 0.8752, G loss: 1.1378\n",
      "[1524/1762] D loss: 0.6512, G loss: 1.1804\n",
      "[1604/1762] D loss: 0.7314, G loss: 1.4568\n",
      "[1684/1762] D loss: 1.0650, G loss: 0.9799\n",
      "[1762/1762] D loss: 1.0641, G loss: 1.6988\n",
      "train error: \n",
      " D loss: 0.847472, G loss: 1.768499, D accuracy: 84.9%, cell accuracy: 96.9%, board accuracy: 2.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.890711, G loss: 1.821146, D accuracy: 83.5%, cell accuracy: 96.9%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7619, G loss: 1.8709\n",
      "[84/1762] D loss: 0.6005, G loss: 1.9607\n",
      "[164/1762] D loss: 0.6627, G loss: 1.0112\n",
      "[244/1762] D loss: 0.4941, G loss: 2.1423\n",
      "[324/1762] D loss: 0.6777, G loss: 1.7318\n",
      "[404/1762] D loss: 0.6620, G loss: 1.7857\n",
      "[484/1762] D loss: 0.6618, G loss: 1.4854\n",
      "[564/1762] D loss: 0.8979, G loss: 1.5827\n",
      "[644/1762] D loss: 1.0914, G loss: 0.8284\n",
      "[724/1762] D loss: 0.5695, G loss: 1.6831\n",
      "[804/1762] D loss: 1.2492, G loss: 1.3658\n",
      "[884/1762] D loss: 0.5672, G loss: 1.1899\n",
      "[964/1762] D loss: 0.6321, G loss: 1.7716\n",
      "[1044/1762] D loss: 1.1371, G loss: 2.4041\n",
      "[1124/1762] D loss: 0.8540, G loss: 1.3967\n",
      "[1204/1762] D loss: 0.9088, G loss: 1.2133\n",
      "[1284/1762] D loss: 0.7402, G loss: 1.3188\n",
      "[1364/1762] D loss: 0.8216, G loss: 0.8967\n",
      "[1444/1762] D loss: 0.7728, G loss: 0.9469\n",
      "[1524/1762] D loss: 0.7775, G loss: 1.0390\n",
      "[1604/1762] D loss: 0.9121, G loss: 1.3027\n",
      "[1684/1762] D loss: 1.1950, G loss: 1.1364\n",
      "[1762/1762] D loss: 0.8515, G loss: 1.1957\n",
      "train error: \n",
      " D loss: 0.944718, G loss: 1.443549, D accuracy: 80.9%, cell accuracy: 97.1%, board accuracy: 2.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.961635, G loss: 1.493309, D accuracy: 80.0%, cell accuracy: 97.0%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0232, G loss: 1.8168\n",
      "[84/1762] D loss: 1.1088, G loss: 0.6306\n",
      "[164/1762] D loss: 1.2805, G loss: 0.6672\n",
      "[244/1762] D loss: 0.6894, G loss: 1.2575\n",
      "[324/1762] D loss: 0.7523, G loss: 1.4922\n",
      "[404/1762] D loss: 0.9417, G loss: 1.1006\n",
      "[484/1762] D loss: 1.0819, G loss: 0.6440\n",
      "[564/1762] D loss: 0.8096, G loss: 1.0930\n",
      "[644/1762] D loss: 0.7036, G loss: 1.4010\n",
      "[724/1762] D loss: 0.9175, G loss: 1.4695\n",
      "[804/1762] D loss: 0.7489, G loss: 1.6868\n",
      "[884/1762] D loss: 0.7582, G loss: 1.1315\n",
      "[964/1762] D loss: 1.1263, G loss: 1.8460\n",
      "[1044/1762] D loss: 1.1279, G loss: 0.7202\n",
      "[1124/1762] D loss: 0.9423, G loss: 1.3022\n",
      "[1204/1762] D loss: 0.9057, G loss: 0.9298\n",
      "[1284/1762] D loss: 0.8132, G loss: 1.2765\n",
      "[1364/1762] D loss: 1.0207, G loss: 0.8542\n",
      "[1444/1762] D loss: 1.0549, G loss: 0.7410\n",
      "[1524/1762] D loss: 0.7573, G loss: 0.9735\n",
      "[1604/1762] D loss: 1.0300, G loss: 0.9469\n",
      "[1684/1762] D loss: 0.9259, G loss: 1.0330\n",
      "[1762/1762] D loss: 1.0294, G loss: 1.6795\n",
      "train error: \n",
      " D loss: 0.902656, G loss: 1.045723, D accuracy: 87.1%, cell accuracy: 98.0%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.897136, G loss: 1.092784, D accuracy: 86.2%, cell accuracy: 97.9%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0264, G loss: 0.6786\n",
      "[84/1762] D loss: 0.9676, G loss: 0.8993\n",
      "[164/1762] D loss: 1.0096, G loss: 0.8914\n",
      "[244/1762] D loss: 0.7557, G loss: 1.2922\n",
      "[324/1762] D loss: 0.9471, G loss: 1.0030\n",
      "[404/1762] D loss: 0.9299, G loss: 1.1512\n",
      "[484/1762] D loss: 0.8639, G loss: 1.0211\n",
      "[564/1762] D loss: 0.9233, G loss: 0.8036\n",
      "[644/1762] D loss: 0.6701, G loss: 1.2033\n",
      "[724/1762] D loss: 0.8950, G loss: 1.2522\n",
      "[804/1762] D loss: 1.0727, G loss: 1.1157\n",
      "[884/1762] D loss: 0.8129, G loss: 2.5227\n",
      "[964/1762] D loss: 1.2088, G loss: 1.5073\n",
      "[1044/1762] D loss: 1.0095, G loss: 1.0261\n",
      "[1124/1762] D loss: 0.9801, G loss: 0.8013\n",
      "[1204/1762] D loss: 1.3590, G loss: 0.5946\n",
      "[1284/1762] D loss: 0.9564, G loss: 1.1292\n",
      "[1364/1762] D loss: 0.9235, G loss: 0.6544\n",
      "[1444/1762] D loss: 0.9336, G loss: 1.0128\n",
      "[1524/1762] D loss: 0.8271, G loss: 1.3284\n",
      "[1604/1762] D loss: 0.9316, G loss: 0.9542\n",
      "[1684/1762] D loss: 0.6835, G loss: 1.3360\n",
      "[1762/1762] D loss: 0.7410, G loss: 1.4340\n",
      "train error: \n",
      " D loss: 0.975073, G loss: 0.996463, D accuracy: 79.4%, cell accuracy: 98.4%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.959608, G loss: 1.046174, D accuracy: 79.9%, cell accuracy: 98.2%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3053, G loss: 0.9928\n",
      "[84/1762] D loss: 0.8309, G loss: 1.1813\n",
      "[164/1762] D loss: 1.1389, G loss: 1.9977\n",
      "[244/1762] D loss: 0.7121, G loss: 1.1973\n",
      "[324/1762] D loss: 0.8229, G loss: 1.4468\n",
      "[404/1762] D loss: 0.9082, G loss: 0.9574\n",
      "[484/1762] D loss: 0.8623, G loss: 1.6923\n",
      "[564/1762] D loss: 1.2965, G loss: 1.5874\n",
      "[644/1762] D loss: 0.8139, G loss: 0.7522\n",
      "[724/1762] D loss: 0.9618, G loss: 0.7810\n",
      "[804/1762] D loss: 0.8803, G loss: 1.2996\n",
      "[884/1762] D loss: 0.8558, G loss: 1.6113\n",
      "[964/1762] D loss: 0.9384, G loss: 1.3833\n",
      "[1044/1762] D loss: 1.1178, G loss: 1.4574\n",
      "[1124/1762] D loss: 0.9031, G loss: 1.0791\n",
      "[1204/1762] D loss: 0.9617, G loss: 1.2046\n",
      "[1284/1762] D loss: 0.9698, G loss: 1.1775\n",
      "[1364/1762] D loss: 1.0939, G loss: 0.8851\n",
      "[1444/1762] D loss: 0.6802, G loss: 1.6614\n",
      "[1524/1762] D loss: 1.0368, G loss: 0.7213\n",
      "[1604/1762] D loss: 1.5529, G loss: 1.8869\n",
      "[1684/1762] D loss: 1.1148, G loss: 0.8937\n",
      "[1762/1762] D loss: 1.0602, G loss: 0.8807\n",
      "train error: \n",
      " D loss: 1.122157, G loss: 0.666185, D accuracy: 66.9%, cell accuracy: 98.6%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.117714, G loss: 0.688653, D accuracy: 67.6%, cell accuracy: 98.4%, board accuracy: 7.7% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8478, G loss: 0.8220\n",
      "[84/1762] D loss: 0.8305, G loss: 1.2372\n",
      "[164/1762] D loss: 1.2594, G loss: 1.0919\n",
      "[244/1762] D loss: 1.3037, G loss: 0.4810\n",
      "[324/1762] D loss: 1.1056, G loss: 0.7509\n",
      "[404/1762] D loss: 1.3509, G loss: 0.9308\n",
      "[484/1762] D loss: 1.0176, G loss: 1.0113\n",
      "[564/1762] D loss: 0.9208, G loss: 1.1475\n",
      "[644/1762] D loss: 1.1621, G loss: 0.9795\n",
      "[724/1762] D loss: 1.0421, G loss: 1.2915\n",
      "[804/1762] D loss: 1.1859, G loss: 0.5817\n",
      "[884/1762] D loss: 0.9986, G loss: 1.2921\n",
      "[964/1762] D loss: 1.3386, G loss: 0.7099\n",
      "[1044/1762] D loss: 1.1060, G loss: 0.8702\n",
      "[1124/1762] D loss: 0.8646, G loss: 0.9928\n",
      "[1204/1762] D loss: 1.2682, G loss: 0.9707\n",
      "[1284/1762] D loss: 1.3789, G loss: 0.5050\n",
      "[1364/1762] D loss: 1.5859, G loss: 0.9717\n",
      "[1444/1762] D loss: 1.2822, G loss: 0.6955\n",
      "[1524/1762] D loss: 1.0900, G loss: 1.2842\n",
      "[1604/1762] D loss: 1.1679, G loss: 0.5469\n",
      "[1684/1762] D loss: 1.1775, G loss: 0.7187\n",
      "[1762/1762] D loss: 1.0583, G loss: 1.1747\n",
      "train error: \n",
      " D loss: 1.330597, G loss: 1.546435, D accuracy: 55.4%, cell accuracy: 98.8%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317119, G loss: 1.550837, D accuracy: 55.2%, cell accuracy: 98.6%, board accuracy: 11.1% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5957, G loss: 1.5487\n",
      "[84/1762] D loss: 1.2710, G loss: 0.5650\n",
      "[164/1762] D loss: 1.0979, G loss: 1.3596\n",
      "[244/1762] D loss: 1.3549, G loss: 0.5604\n",
      "[324/1762] D loss: 0.9491, G loss: 1.0005\n",
      "[404/1762] D loss: 1.1876, G loss: 0.8612\n",
      "[484/1762] D loss: 1.4285, G loss: 0.5267\n",
      "[564/1762] D loss: 1.1849, G loss: 0.9405\n",
      "[644/1762] D loss: 0.9914, G loss: 1.0891\n",
      "[724/1762] D loss: 1.4957, G loss: 1.1570\n",
      "[804/1762] D loss: 1.0596, G loss: 0.9086\n",
      "[884/1762] D loss: 1.1053, G loss: 0.7430\n",
      "[964/1762] D loss: 1.1824, G loss: 1.1645\n",
      "[1044/1762] D loss: 1.2570, G loss: 0.6774\n",
      "[1124/1762] D loss: 1.1874, G loss: 1.3490\n",
      "[1204/1762] D loss: 1.3373, G loss: 1.4863\n",
      "[1284/1762] D loss: 1.1327, G loss: 0.7578\n",
      "[1364/1762] D loss: 1.2923, G loss: 1.2460\n",
      "[1444/1762] D loss: 1.4491, G loss: 0.7441\n",
      "[1524/1762] D loss: 1.3116, G loss: 1.2314\n",
      "[1604/1762] D loss: 1.5484, G loss: 0.2794\n",
      "[1684/1762] D loss: 1.2508, G loss: 1.0023\n",
      "[1762/1762] D loss: 1.0954, G loss: 0.7415\n",
      "train error: \n",
      " D loss: 1.218014, G loss: 0.762624, D accuracy: 63.2%, cell accuracy: 98.7%, board accuracy: 16.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.211585, G loss: 0.762151, D accuracy: 63.3%, cell accuracy: 98.6%, board accuracy: 14.8% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1718, G loss: 0.5728\n",
      "[84/1762] D loss: 1.2044, G loss: 0.9594\n",
      "[164/1762] D loss: 1.2095, G loss: 1.2946\n",
      "[244/1762] D loss: 1.0719, G loss: 1.1060\n",
      "[324/1762] D loss: 1.2278, G loss: 0.7504\n",
      "[404/1762] D loss: 1.2236, G loss: 0.8745\n",
      "[484/1762] D loss: 1.2356, G loss: 1.0295\n",
      "[564/1762] D loss: 1.2651, G loss: 1.2358\n",
      "[644/1762] D loss: 1.2689, G loss: 0.6858\n",
      "[724/1762] D loss: 1.0998, G loss: 1.3098\n",
      "[804/1762] D loss: 1.2238, G loss: 0.5558\n",
      "[884/1762] D loss: 1.0326, G loss: 1.1327\n",
      "[964/1762] D loss: 1.2897, G loss: 0.8447\n",
      "[1044/1762] D loss: 1.2769, G loss: 1.0585\n",
      "[1124/1762] D loss: 1.3460, G loss: 0.4538\n",
      "[1204/1762] D loss: 1.2122, G loss: 1.0400\n",
      "[1284/1762] D loss: 1.1272, G loss: 0.7710\n",
      "[1364/1762] D loss: 1.0767, G loss: 0.9078\n",
      "[1444/1762] D loss: 1.4389, G loss: 0.5175\n",
      "[1524/1762] D loss: 1.3273, G loss: 1.8683\n",
      "[1604/1762] D loss: 1.3940, G loss: 0.9379\n",
      "[1684/1762] D loss: 1.2216, G loss: 0.6126\n",
      "[1762/1762] D loss: 1.0701, G loss: 1.0236\n",
      "train error: \n",
      " D loss: 1.297615, G loss: 0.589469, D accuracy: 60.1%, cell accuracy: 98.5%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309205, G loss: 0.588273, D accuracy: 61.8%, cell accuracy: 98.4%, board accuracy: 13.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4664, G loss: 0.5230\n",
      "[84/1762] D loss: 1.3093, G loss: 0.7596\n",
      "[164/1762] D loss: 1.3173, G loss: 0.9415\n",
      "[244/1762] D loss: 1.3353, G loss: 0.7832\n",
      "[324/1762] D loss: 1.2679, G loss: 1.0627\n",
      "[404/1762] D loss: 1.2343, G loss: 0.8675\n",
      "[484/1762] D loss: 1.4628, G loss: 0.4839\n",
      "[564/1762] D loss: 1.4858, G loss: 0.8711\n",
      "[644/1762] D loss: 1.2408, G loss: 0.8596\n",
      "[724/1762] D loss: 1.2792, G loss: 0.9932\n",
      "[804/1762] D loss: 1.3303, G loss: 0.9810\n",
      "[884/1762] D loss: 1.0450, G loss: 0.8872\n",
      "[964/1762] D loss: 1.0172, G loss: 1.0116\n",
      "[1044/1762] D loss: 1.2682, G loss: 0.5460\n",
      "[1124/1762] D loss: 1.1779, G loss: 0.6285\n",
      "[1204/1762] D loss: 1.2748, G loss: 0.6409\n",
      "[1284/1762] D loss: 1.2023, G loss: 1.2178\n",
      "[1364/1762] D loss: 1.1734, G loss: 1.0764\n",
      "[1444/1762] D loss: 1.2154, G loss: 0.7775\n",
      "[1524/1762] D loss: 1.1796, G loss: 1.0926\n",
      "[1604/1762] D loss: 1.3078, G loss: 0.4785\n",
      "[1684/1762] D loss: 1.3218, G loss: 0.7127\n",
      "[1762/1762] D loss: 1.4869, G loss: 1.3508\n",
      "train error: \n",
      " D loss: 1.259895, G loss: 0.812059, D accuracy: 67.4%, cell accuracy: 98.5%, board accuracy: 12.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261457, G loss: 0.817680, D accuracy: 68.5%, cell accuracy: 98.4%, board accuracy: 11.6% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2095, G loss: 0.6239\n",
      "[84/1762] D loss: 1.3838, G loss: 0.7223\n",
      "[164/1762] D loss: 1.2999, G loss: 0.9478\n",
      "[244/1762] D loss: 1.4148, G loss: 0.9306\n",
      "[324/1762] D loss: 1.1834, G loss: 0.9347\n",
      "[404/1762] D loss: 1.2511, G loss: 0.7814\n",
      "[484/1762] D loss: 1.2553, G loss: 0.7525\n",
      "[564/1762] D loss: 1.4876, G loss: 0.9681\n",
      "[644/1762] D loss: 1.2974, G loss: 0.9137\n",
      "[724/1762] D loss: 1.2496, G loss: 0.7033\n",
      "[804/1762] D loss: 1.1568, G loss: 0.9182\n",
      "[884/1762] D loss: 1.2650, G loss: 0.7474\n",
      "[964/1762] D loss: 1.3315, G loss: 0.7997\n",
      "[1044/1762] D loss: 1.3339, G loss: 0.8073\n",
      "[1124/1762] D loss: 1.2483, G loss: 0.6683\n",
      "[1204/1762] D loss: 1.3060, G loss: 0.8837\n",
      "[1284/1762] D loss: 1.2729, G loss: 0.8708\n",
      "[1364/1762] D loss: 1.5657, G loss: 0.4413\n",
      "[1444/1762] D loss: 1.3317, G loss: 1.3831\n",
      "[1524/1762] D loss: 1.4614, G loss: 1.0505\n",
      "[1604/1762] D loss: 1.3480, G loss: 0.5942\n",
      "[1684/1762] D loss: 1.2532, G loss: 0.9770\n",
      "[1762/1762] D loss: 0.9930, G loss: 0.9547\n",
      "train error: \n",
      " D loss: 1.312922, G loss: 0.755661, D accuracy: 62.3%, cell accuracy: 99.1%, board accuracy: 29.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324326, G loss: 0.746204, D accuracy: 62.3%, cell accuracy: 99.1%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1230, G loss: 0.8138\n",
      "[84/1762] D loss: 1.4342, G loss: 0.7878\n",
      "[164/1762] D loss: 1.3577, G loss: 1.4191\n",
      "[244/1762] D loss: 1.3154, G loss: 0.6102\n",
      "[324/1762] D loss: 1.3066, G loss: 1.1152\n",
      "[404/1762] D loss: 1.2056, G loss: 0.8047\n",
      "[484/1762] D loss: 1.3489, G loss: 1.0095\n",
      "[564/1762] D loss: 1.3127, G loss: 0.7296\n",
      "[644/1762] D loss: 1.2392, G loss: 1.1193\n",
      "[724/1762] D loss: 1.2658, G loss: 0.6333\n",
      "[804/1762] D loss: 1.3147, G loss: 1.2317\n",
      "[884/1762] D loss: 1.3976, G loss: 0.9959\n",
      "[964/1762] D loss: 1.3433, G loss: 0.8347\n",
      "[1044/1762] D loss: 1.3379, G loss: 0.7039\n",
      "[1124/1762] D loss: 1.3611, G loss: 0.9560\n",
      "[1204/1762] D loss: 1.4075, G loss: 0.4987\n",
      "[1284/1762] D loss: 1.4238, G loss: 1.1187\n",
      "[1364/1762] D loss: 1.3130, G loss: 0.6271\n",
      "[1444/1762] D loss: 1.2666, G loss: 0.4951\n",
      "[1524/1762] D loss: 1.3928, G loss: 1.0343\n",
      "[1604/1762] D loss: 1.4634, G loss: 0.7197\n",
      "[1684/1762] D loss: 1.4011, G loss: 0.9217\n",
      "[1762/1762] D loss: 1.4658, G loss: 0.3853\n",
      "train error: \n",
      " D loss: 1.495007, G loss: 0.453036, D accuracy: 52.9%, cell accuracy: 99.1%, board accuracy: 27.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.496748, G loss: 0.456790, D accuracy: 54.5%, cell accuracy: 99.0%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6220, G loss: 0.5110\n",
      "[84/1762] D loss: 1.3403, G loss: 0.6754\n",
      "[164/1762] D loss: 1.5059, G loss: 0.8304\n",
      "[244/1762] D loss: 1.3378, G loss: 0.8376\n",
      "[324/1762] D loss: 1.4106, G loss: 0.5411\n",
      "[404/1762] D loss: 1.3365, G loss: 1.0462\n",
      "[484/1762] D loss: 1.4012, G loss: 0.6505\n",
      "[564/1762] D loss: 1.5118, G loss: 0.7897\n",
      "[644/1762] D loss: 1.3486, G loss: 0.7935\n",
      "[724/1762] D loss: 1.4480, G loss: 0.8564\n",
      "[804/1762] D loss: 1.3155, G loss: 0.7545\n",
      "[884/1762] D loss: 1.4130, G loss: 0.5601\n",
      "[964/1762] D loss: 1.2042, G loss: 0.7677\n",
      "[1044/1762] D loss: 1.3679, G loss: 0.8006\n",
      "[1124/1762] D loss: 1.3206, G loss: 0.6725\n",
      "[1204/1762] D loss: 1.3430, G loss: 0.9224\n",
      "[1284/1762] D loss: 1.5748, G loss: 0.9565\n",
      "[1364/1762] D loss: 1.4718, G loss: 0.8306\n",
      "[1444/1762] D loss: 1.3653, G loss: 0.8977\n",
      "[1524/1762] D loss: 1.3345, G loss: 0.5900\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.9272\n",
      "[1684/1762] D loss: 1.2894, G loss: 0.8160\n",
      "[1762/1762] D loss: 1.4066, G loss: 0.4808\n",
      "train error: \n",
      " D loss: 1.413325, G loss: 0.519416, D accuracy: 52.7%, cell accuracy: 99.2%, board accuracy: 36.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.421687, G loss: 0.519753, D accuracy: 52.7%, cell accuracy: 99.1%, board accuracy: 35.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4444, G loss: 0.4705\n",
      "[84/1762] D loss: 1.4861, G loss: 0.6877\n",
      "[164/1762] D loss: 1.2971, G loss: 0.8056\n",
      "[244/1762] D loss: 1.4366, G loss: 1.0472\n",
      "[324/1762] D loss: 1.5394, G loss: 0.5722\n",
      "[404/1762] D loss: 1.6444, G loss: 1.4865\n",
      "[484/1762] D loss: 1.7057, G loss: 0.4711\n",
      "[564/1762] D loss: 1.3775, G loss: 0.7572\n",
      "[644/1762] D loss: 1.3761, G loss: 1.2317\n",
      "[724/1762] D loss: 1.4930, G loss: 0.7109\n",
      "[804/1762] D loss: 1.3043, G loss: 0.8214\n",
      "[884/1762] D loss: 1.3448, G loss: 0.8888\n",
      "[964/1762] D loss: 1.2579, G loss: 0.8042\n",
      "[1044/1762] D loss: 1.2427, G loss: 0.6025\n",
      "[1124/1762] D loss: 1.2892, G loss: 0.6818\n",
      "[1204/1762] D loss: 1.2461, G loss: 1.0406\n",
      "[1284/1762] D loss: 1.3641, G loss: 0.5923\n",
      "[1364/1762] D loss: 1.3325, G loss: 0.6498\n",
      "[1444/1762] D loss: 1.4209, G loss: 0.6469\n",
      "[1524/1762] D loss: 1.3282, G loss: 0.8538\n",
      "[1604/1762] D loss: 1.3475, G loss: 0.9646\n",
      "[1684/1762] D loss: 1.3482, G loss: 0.7037\n",
      "[1762/1762] D loss: 1.3436, G loss: 0.6679\n",
      "train error: \n",
      " D loss: 1.348474, G loss: 0.728073, D accuracy: 56.3%, cell accuracy: 99.3%, board accuracy: 40.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350252, G loss: 0.729552, D accuracy: 57.2%, cell accuracy: 99.3%, board accuracy: 40.7% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3206, G loss: 0.6640\n",
      "[84/1762] D loss: 1.5526, G loss: 1.2072\n",
      "[164/1762] D loss: 1.2967, G loss: 0.5675\n",
      "[244/1762] D loss: 1.2687, G loss: 0.8318\n",
      "[324/1762] D loss: 1.4956, G loss: 0.7627\n",
      "[404/1762] D loss: 1.3168, G loss: 0.7569\n",
      "[484/1762] D loss: 1.4206, G loss: 1.2282\n",
      "[564/1762] D loss: 1.3781, G loss: 0.4224\n",
      "[644/1762] D loss: 1.3401, G loss: 0.9731\n",
      "[724/1762] D loss: 1.3474, G loss: 0.7359\n",
      "[804/1762] D loss: 1.5102, G loss: 0.8531\n",
      "[884/1762] D loss: 1.4531, G loss: 0.9850\n",
      "[964/1762] D loss: 1.4581, G loss: 0.7557\n",
      "[1044/1762] D loss: 1.4071, G loss: 0.6199\n",
      "[1124/1762] D loss: 1.6784, G loss: 1.3501\n",
      "[1204/1762] D loss: 1.4644, G loss: 0.4573\n",
      "[1284/1762] D loss: 1.3673, G loss: 0.6478\n",
      "[1364/1762] D loss: 1.4011, G loss: 0.6006\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6482\n",
      "[1524/1762] D loss: 1.4157, G loss: 0.8296\n",
      "[1604/1762] D loss: 1.4608, G loss: 0.7477\n",
      "[1684/1762] D loss: 1.3465, G loss: 0.8108\n",
      "[1762/1762] D loss: 1.1550, G loss: 0.9133\n",
      "train error: \n",
      " D loss: 1.357718, G loss: 0.743312, D accuracy: 57.9%, cell accuracy: 99.3%, board accuracy: 35.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363983, G loss: 0.739279, D accuracy: 57.0%, cell accuracy: 99.3%, board accuracy: 35.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3500, G loss: 0.6427\n",
      "[84/1762] D loss: 1.3951, G loss: 0.6562\n",
      "[164/1762] D loss: 1.3585, G loss: 0.6366\n",
      "[244/1762] D loss: 1.3298, G loss: 1.0192\n",
      "[324/1762] D loss: 1.4251, G loss: 0.6491\n",
      "[404/1762] D loss: 1.3927, G loss: 1.1431\n",
      "[484/1762] D loss: 1.3401, G loss: 0.6541\n",
      "[564/1762] D loss: 1.3663, G loss: 0.6148\n",
      "[644/1762] D loss: 1.2886, G loss: 0.6675\n",
      "[724/1762] D loss: 1.5272, G loss: 1.3574\n",
      "[804/1762] D loss: 1.4031, G loss: 0.4946\n",
      "[884/1762] D loss: 1.3392, G loss: 0.9091\n",
      "[964/1762] D loss: 1.2089, G loss: 0.9084\n",
      "[1044/1762] D loss: 1.3433, G loss: 0.6347\n",
      "[1124/1762] D loss: 1.2776, G loss: 0.8774\n",
      "[1204/1762] D loss: 1.4278, G loss: 0.7132\n",
      "[1284/1762] D loss: 1.3598, G loss: 1.1413\n",
      "[1364/1762] D loss: 1.3606, G loss: 0.4505\n",
      "[1444/1762] D loss: 1.5073, G loss: 0.4762\n",
      "[1524/1762] D loss: 1.2794, G loss: 0.7875\n",
      "[1604/1762] D loss: 1.2687, G loss: 1.3583\n",
      "[1684/1762] D loss: 1.4744, G loss: 0.6824\n",
      "[1762/1762] D loss: 1.4676, G loss: 0.8396\n",
      "train error: \n",
      " D loss: 1.409458, G loss: 1.007753, D accuracy: 54.0%, cell accuracy: 99.4%, board accuracy: 39.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399836, G loss: 1.014959, D accuracy: 53.5%, cell accuracy: 99.3%, board accuracy: 40.7% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4306, G loss: 1.1061\n",
      "[84/1762] D loss: 1.3322, G loss: 0.6930\n",
      "[164/1762] D loss: 1.4952, G loss: 1.0102\n",
      "[244/1762] D loss: 1.5111, G loss: 0.3895\n",
      "[324/1762] D loss: 1.2675, G loss: 1.0116\n",
      "[404/1762] D loss: 1.4053, G loss: 0.6901\n",
      "[484/1762] D loss: 1.3198, G loss: 0.9517\n",
      "[564/1762] D loss: 1.2062, G loss: 0.8180\n",
      "[644/1762] D loss: 1.3587, G loss: 0.7306\n",
      "[724/1762] D loss: 1.2965, G loss: 0.6231\n",
      "[804/1762] D loss: 1.3041, G loss: 0.6628\n",
      "[884/1762] D loss: 1.3416, G loss: 0.6814\n",
      "[964/1762] D loss: 1.3820, G loss: 0.8978\n",
      "[1044/1762] D loss: 1.1659, G loss: 0.9240\n",
      "[1124/1762] D loss: 1.3261, G loss: 0.6677\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.8327\n",
      "[1284/1762] D loss: 1.5342, G loss: 0.5183\n",
      "[1364/1762] D loss: 1.4277, G loss: 0.9233\n",
      "[1444/1762] D loss: 1.3789, G loss: 0.6469\n",
      "[1524/1762] D loss: 1.5557, G loss: 0.6663\n",
      "[1604/1762] D loss: 1.4163, G loss: 0.7291\n",
      "[1684/1762] D loss: 1.4205, G loss: 0.8645\n",
      "[1762/1762] D loss: 1.3311, G loss: 0.6182\n",
      "train error: \n",
      " D loss: 1.372264, G loss: 0.649596, D accuracy: 55.6%, cell accuracy: 99.3%, board accuracy: 35.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375392, G loss: 0.648363, D accuracy: 56.9%, cell accuracy: 99.2%, board accuracy: 33.9% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4083, G loss: 0.7205\n",
      "[84/1762] D loss: 1.3556, G loss: 0.6991\n",
      "[164/1762] D loss: 1.3734, G loss: 0.6828\n",
      "[244/1762] D loss: 1.6779, G loss: 0.6889\n",
      "[324/1762] D loss: 1.3193, G loss: 0.6253\n",
      "[404/1762] D loss: 1.4546, G loss: 0.7235\n",
      "[484/1762] D loss: 1.3699, G loss: 0.9410\n",
      "[564/1762] D loss: 1.5769, G loss: 0.4657\n",
      "[644/1762] D loss: 1.4035, G loss: 0.6159\n",
      "[724/1762] D loss: 1.1813, G loss: 1.1053\n",
      "[804/1762] D loss: 1.1636, G loss: 1.0153\n",
      "[884/1762] D loss: 1.4485, G loss: 0.8435\n",
      "[964/1762] D loss: 1.4901, G loss: 0.5745\n",
      "[1044/1762] D loss: 1.3035, G loss: 0.6088\n",
      "[1124/1762] D loss: 1.4976, G loss: 0.9067\n",
      "[1204/1762] D loss: 1.3799, G loss: 0.5882\n",
      "[1284/1762] D loss: 1.4092, G loss: 1.2171\n",
      "[1364/1762] D loss: 1.4091, G loss: 0.7308\n",
      "[1444/1762] D loss: 1.4306, G loss: 0.7656\n",
      "[1524/1762] D loss: 1.5259, G loss: 0.5339\n",
      "[1604/1762] D loss: 1.4548, G loss: 0.6747\n",
      "[1684/1762] D loss: 1.4891, G loss: 0.4169\n",
      "[1762/1762] D loss: 1.4031, G loss: 0.6317\n",
      "train error: \n",
      " D loss: 1.368109, G loss: 0.714339, D accuracy: 53.7%, cell accuracy: 99.3%, board accuracy: 39.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367620, G loss: 0.710777, D accuracy: 54.3%, cell accuracy: 99.3%, board accuracy: 38.4% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3788, G loss: 0.6292\n",
      "[84/1762] D loss: 1.4036, G loss: 0.6124\n",
      "[164/1762] D loss: 1.4088, G loss: 0.6615\n",
      "[244/1762] D loss: 1.3484, G loss: 0.6443\n",
      "[324/1762] D loss: 1.3409, G loss: 0.6136\n",
      "[404/1762] D loss: 1.2857, G loss: 1.0629\n",
      "[484/1762] D loss: 1.2854, G loss: 0.7952\n",
      "[564/1762] D loss: 1.3513, G loss: 0.7507\n",
      "[644/1762] D loss: 1.1359, G loss: 0.9587\n",
      "[724/1762] D loss: 1.4879, G loss: 0.6607\n",
      "[804/1762] D loss: 1.5366, G loss: 0.5036\n",
      "[884/1762] D loss: 1.2195, G loss: 1.0567\n",
      "[964/1762] D loss: 1.5256, G loss: 0.4507\n",
      "[1044/1762] D loss: 1.1977, G loss: 0.9794\n",
      "[1124/1762] D loss: 1.3372, G loss: 0.8444\n",
      "[1204/1762] D loss: 1.3434, G loss: 0.6689\n",
      "[1284/1762] D loss: 1.3799, G loss: 0.6931\n",
      "[1364/1762] D loss: 1.3782, G loss: 0.8823\n",
      "[1444/1762] D loss: 1.3775, G loss: 0.6728\n",
      "[1524/1762] D loss: 1.4389, G loss: 0.8547\n",
      "[1604/1762] D loss: 1.2835, G loss: 0.6318\n",
      "[1684/1762] D loss: 1.3953, G loss: 0.8213\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.6102\n",
      "train error: \n",
      " D loss: 1.376645, G loss: 0.652863, D accuracy: 53.2%, cell accuracy: 99.4%, board accuracy: 41.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379976, G loss: 0.644415, D accuracy: 54.2%, cell accuracy: 99.3%, board accuracy: 40.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3399, G loss: 0.7740\n",
      "[84/1762] D loss: 1.4072, G loss: 1.0021\n",
      "[164/1762] D loss: 1.4389, G loss: 0.7218\n",
      "[244/1762] D loss: 1.4024, G loss: 0.5790\n",
      "[324/1762] D loss: 1.4989, G loss: 0.8696\n",
      "[404/1762] D loss: 1.3892, G loss: 0.6039\n",
      "[484/1762] D loss: 1.4323, G loss: 0.9713\n",
      "[564/1762] D loss: 1.3998, G loss: 0.6401\n",
      "[644/1762] D loss: 1.3849, G loss: 0.8781\n",
      "[724/1762] D loss: 1.2023, G loss: 0.7685\n",
      "[804/1762] D loss: 1.4434, G loss: 0.5251\n",
      "[884/1762] D loss: 1.3718, G loss: 0.8511\n",
      "[964/1762] D loss: 1.4297, G loss: 0.6991\n",
      "[1044/1762] D loss: 1.4492, G loss: 0.4297\n",
      "[1124/1762] D loss: 1.4258, G loss: 0.9723\n",
      "[1204/1762] D loss: 1.3737, G loss: 0.8402\n",
      "[1284/1762] D loss: 1.2225, G loss: 0.6634\n",
      "[1364/1762] D loss: 1.3758, G loss: 0.9901\n",
      "[1444/1762] D loss: 1.4307, G loss: 0.8209\n",
      "[1524/1762] D loss: 1.4825, G loss: 0.6929\n",
      "[1604/1762] D loss: 1.5825, G loss: 0.5637\n",
      "[1684/1762] D loss: 1.4759, G loss: 0.7220\n",
      "[1762/1762] D loss: 1.3639, G loss: 0.7210\n",
      "train error: \n",
      " D loss: 1.413044, G loss: 0.541577, D accuracy: 53.1%, cell accuracy: 99.4%, board accuracy: 39.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.420240, G loss: 0.534724, D accuracy: 53.9%, cell accuracy: 99.3%, board accuracy: 40.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3964, G loss: 0.6379\n",
      "[84/1762] D loss: 1.3531, G loss: 0.6901\n",
      "[164/1762] D loss: 1.4737, G loss: 0.4466\n",
      "[244/1762] D loss: 1.3908, G loss: 0.9882\n",
      "[324/1762] D loss: 1.3512, G loss: 0.5616\n",
      "[404/1762] D loss: 1.4386, G loss: 0.9914\n",
      "[484/1762] D loss: 1.4104, G loss: 0.4591\n",
      "[564/1762] D loss: 1.4470, G loss: 1.2447\n",
      "[644/1762] D loss: 1.3852, G loss: 0.7753\n",
      "[724/1762] D loss: 1.0944, G loss: 0.9329\n",
      "[804/1762] D loss: 1.3652, G loss: 0.6888\n",
      "[884/1762] D loss: 1.4428, G loss: 0.5889\n",
      "[964/1762] D loss: 1.4961, G loss: 0.9476\n",
      "[1044/1762] D loss: 1.3540, G loss: 0.6047\n",
      "[1124/1762] D loss: 1.2831, G loss: 0.8861\n",
      "[1204/1762] D loss: 1.3275, G loss: 1.0221\n",
      "[1284/1762] D loss: 1.4236, G loss: 0.6413\n",
      "[1364/1762] D loss: 1.3212, G loss: 0.7068\n",
      "[1444/1762] D loss: 1.2650, G loss: 0.8415\n",
      "[1524/1762] D loss: 1.3132, G loss: 0.7617\n",
      "[1604/1762] D loss: 1.4247, G loss: 0.6963\n",
      "[1684/1762] D loss: 1.4328, G loss: 0.7454\n",
      "[1762/1762] D loss: 1.4328, G loss: 0.9563\n",
      "train error: \n",
      " D loss: 1.450887, G loss: 1.088624, D accuracy: 52.7%, cell accuracy: 99.3%, board accuracy: 35.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.439603, G loss: 1.085855, D accuracy: 53.3%, cell accuracy: 99.3%, board accuracy: 35.7% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4242, G loss: 1.0705\n",
      "[84/1762] D loss: 1.4357, G loss: 0.6699\n",
      "[164/1762] D loss: 1.3944, G loss: 0.6686\n",
      "[244/1762] D loss: 1.3675, G loss: 0.6476\n",
      "[324/1762] D loss: 1.5760, G loss: 1.1769\n",
      "[404/1762] D loss: 1.4138, G loss: 0.6513\n",
      "[484/1762] D loss: 1.3733, G loss: 0.7683\n",
      "[564/1762] D loss: 1.4730, G loss: 1.0506\n",
      "[644/1762] D loss: 1.3128, G loss: 0.8949\n",
      "[724/1762] D loss: 1.3448, G loss: 0.7443\n",
      "[804/1762] D loss: 1.4928, G loss: 0.7105\n",
      "[884/1762] D loss: 1.3047, G loss: 0.5505\n",
      "[964/1762] D loss: 1.4211, G loss: 1.2538\n",
      "[1044/1762] D loss: 1.4562, G loss: 0.7952\n",
      "[1124/1762] D loss: 1.4127, G loss: 0.5754\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.8441\n",
      "[1284/1762] D loss: 1.3223, G loss: 0.6926\n",
      "[1364/1762] D loss: 1.3006, G loss: 1.1260\n",
      "[1444/1762] D loss: 1.3288, G loss: 0.5403\n",
      "[1524/1762] D loss: 1.3446, G loss: 0.6139\n",
      "[1604/1762] D loss: 1.4216, G loss: 0.6847\n",
      "[1684/1762] D loss: 1.4445, G loss: 0.4776\n",
      "[1762/1762] D loss: 1.4344, G loss: 0.7348\n",
      "train error: \n",
      " D loss: 1.366339, G loss: 0.810859, D accuracy: 54.8%, cell accuracy: 99.3%, board accuracy: 38.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361699, G loss: 0.801786, D accuracy: 54.2%, cell accuracy: 99.2%, board accuracy: 37.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4223, G loss: 0.8530\n",
      "[84/1762] D loss: 1.3465, G loss: 0.6658\n",
      "[164/1762] D loss: 1.4385, G loss: 0.7366\n",
      "[244/1762] D loss: 1.2967, G loss: 0.7800\n",
      "[324/1762] D loss: 1.3694, G loss: 0.6769\n",
      "[404/1762] D loss: 1.4470, G loss: 0.5015\n",
      "[484/1762] D loss: 1.3933, G loss: 1.0901\n",
      "[564/1762] D loss: 1.4028, G loss: 0.6677\n",
      "[644/1762] D loss: 1.4527, G loss: 0.6845\n",
      "[724/1762] D loss: 1.0932, G loss: 0.7401\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6338\n",
      "[884/1762] D loss: 1.3610, G loss: 0.9418\n",
      "[964/1762] D loss: 1.3799, G loss: 0.7457\n",
      "[1044/1762] D loss: 1.4862, G loss: 0.4312\n",
      "[1124/1762] D loss: 1.2834, G loss: 0.7419\n",
      "[1204/1762] D loss: 1.1982, G loss: 0.8435\n",
      "[1284/1762] D loss: 1.3615, G loss: 0.7165\n",
      "[1364/1762] D loss: 1.4018, G loss: 0.6588\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.5672\n",
      "[1524/1762] D loss: 1.3174, G loss: 0.6750\n",
      "[1604/1762] D loss: 1.3418, G loss: 0.7003\n",
      "[1684/1762] D loss: 1.3404, G loss: 1.0111\n",
      "[1762/1762] D loss: 1.4493, G loss: 0.5854\n",
      "train error: \n",
      " D loss: 1.397699, G loss: 0.548793, D accuracy: 52.7%, cell accuracy: 99.2%, board accuracy: 26.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398755, G loss: 0.547733, D accuracy: 54.3%, cell accuracy: 99.1%, board accuracy: 26.1% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4364, G loss: 0.6156\n",
      "[84/1762] D loss: 1.4503, G loss: 1.0769\n",
      "[164/1762] D loss: 1.3992, G loss: 0.6165\n",
      "[244/1762] D loss: 1.4208, G loss: 0.6972\n",
      "[324/1762] D loss: 1.3911, G loss: 0.7429\n",
      "[404/1762] D loss: 1.4483, G loss: 0.8622\n",
      "[484/1762] D loss: 1.3412, G loss: 0.7990\n",
      "[564/1762] D loss: 1.4728, G loss: 1.0645\n",
      "[644/1762] D loss: 1.3392, G loss: 0.4540\n",
      "[724/1762] D loss: 1.2783, G loss: 0.9127\n",
      "[804/1762] D loss: 1.2290, G loss: 0.7921\n",
      "[884/1762] D loss: 1.2048, G loss: 0.8724\n",
      "[964/1762] D loss: 1.4734, G loss: 0.4408\n",
      "[1044/1762] D loss: 1.3166, G loss: 0.6846\n",
      "[1124/1762] D loss: 1.1963, G loss: 1.1250\n",
      "[1204/1762] D loss: 1.3789, G loss: 0.5677\n",
      "[1284/1762] D loss: 1.3489, G loss: 0.8928\n",
      "[1364/1762] D loss: 1.3195, G loss: 0.7844\n",
      "[1444/1762] D loss: 1.3218, G loss: 0.9195\n",
      "[1524/1762] D loss: 1.3429, G loss: 0.6898\n",
      "[1604/1762] D loss: 1.2139, G loss: 0.8163\n",
      "[1684/1762] D loss: 1.2459, G loss: 0.8979\n",
      "[1762/1762] D loss: 1.3755, G loss: 0.7404\n",
      "train error: \n",
      " D loss: 1.353638, G loss: 0.754443, D accuracy: 54.5%, cell accuracy: 99.3%, board accuracy: 35.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352708, G loss: 0.747078, D accuracy: 54.8%, cell accuracy: 99.3%, board accuracy: 34.8% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.7194\n",
      "[84/1762] D loss: 1.4059, G loss: 0.5744\n",
      "[164/1762] D loss: 1.4235, G loss: 0.8644\n",
      "[244/1762] D loss: 1.3937, G loss: 0.6994\n",
      "[324/1762] D loss: 1.3027, G loss: 0.8152\n",
      "[404/1762] D loss: 1.5543, G loss: 0.7756\n",
      "[484/1762] D loss: 1.3181, G loss: 0.5395\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6648\n",
      "[644/1762] D loss: 1.4338, G loss: 0.6230\n",
      "[724/1762] D loss: 1.3490, G loss: 1.1221\n",
      "[804/1762] D loss: 1.3864, G loss: 1.0060\n",
      "[884/1762] D loss: 1.4703, G loss: 0.5433\n",
      "[964/1762] D loss: 1.3665, G loss: 0.6511\n",
      "[1044/1762] D loss: 1.4209, G loss: 0.6448\n",
      "[1124/1762] D loss: 1.4318, G loss: 0.6331\n",
      "[1204/1762] D loss: 1.4359, G loss: 0.7563\n",
      "[1284/1762] D loss: 1.4427, G loss: 1.0486\n",
      "[1364/1762] D loss: 1.3945, G loss: 0.5031\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6395\n",
      "[1524/1762] D loss: 1.1987, G loss: 0.6778\n",
      "[1604/1762] D loss: 1.1751, G loss: 0.9161\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.8178\n",
      "[1762/1762] D loss: 1.4334, G loss: 0.7751\n",
      "train error: \n",
      " D loss: 1.358677, G loss: 0.888901, D accuracy: 54.8%, cell accuracy: 99.2%, board accuracy: 34.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348967, G loss: 0.886438, D accuracy: 56.0%, cell accuracy: 99.1%, board accuracy: 31.8% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3746, G loss: 0.7811\n",
      "[84/1762] D loss: 1.2948, G loss: 0.8608\n",
      "[164/1762] D loss: 1.3444, G loss: 0.7924\n",
      "[244/1762] D loss: 1.2303, G loss: 0.8199\n",
      "[324/1762] D loss: 1.3814, G loss: 0.5632\n",
      "[404/1762] D loss: 1.4221, G loss: 0.8052\n",
      "[484/1762] D loss: 1.4891, G loss: 0.7777\n",
      "[564/1762] D loss: 1.3812, G loss: 0.8582\n",
      "[644/1762] D loss: 1.4376, G loss: 0.5682\n",
      "[724/1762] D loss: 1.3443, G loss: 0.6711\n",
      "[804/1762] D loss: 1.2521, G loss: 0.9809\n",
      "[884/1762] D loss: 1.3649, G loss: 0.8127\n",
      "[964/1762] D loss: 1.1097, G loss: 0.9885\n",
      "[1044/1762] D loss: 1.4613, G loss: 0.6816\n",
      "[1124/1762] D loss: 1.3625, G loss: 0.5523\n",
      "[1204/1762] D loss: 1.4816, G loss: 0.8756\n",
      "[1284/1762] D loss: 1.5036, G loss: 0.7596\n",
      "[1364/1762] D loss: 1.4396, G loss: 0.8189\n",
      "[1444/1762] D loss: 1.5543, G loss: 0.5449\n",
      "[1524/1762] D loss: 1.3665, G loss: 0.9974\n",
      "[1604/1762] D loss: 1.4410, G loss: 0.9791\n",
      "[1684/1762] D loss: 1.5439, G loss: 0.5490\n",
      "[1762/1762] D loss: 1.3683, G loss: 0.5505\n",
      "train error: \n",
      " D loss: 1.470063, G loss: 0.488232, D accuracy: 52.3%, cell accuracy: 99.0%, board accuracy: 25.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.468936, G loss: 0.497548, D accuracy: 54.0%, cell accuracy: 98.9%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4867, G loss: 0.4830\n",
      "[84/1762] D loss: 1.3596, G loss: 0.9116\n",
      "[164/1762] D loss: 1.3502, G loss: 0.6175\n",
      "[244/1762] D loss: 1.3462, G loss: 0.7443\n",
      "[324/1762] D loss: 1.3614, G loss: 0.5157\n",
      "[404/1762] D loss: 1.4147, G loss: 0.7321\n",
      "[484/1762] D loss: 1.4607, G loss: 0.8174\n",
      "[564/1762] D loss: 1.4500, G loss: 0.8645\n",
      "[644/1762] D loss: 1.5295, G loss: 0.5866\n",
      "[724/1762] D loss: 1.5557, G loss: 0.9635\n",
      "[804/1762] D loss: 1.3189, G loss: 0.7512\n",
      "[884/1762] D loss: 1.3382, G loss: 0.6823\n",
      "[964/1762] D loss: 1.3964, G loss: 0.7072\n",
      "[1044/1762] D loss: 1.3638, G loss: 0.9404\n",
      "[1124/1762] D loss: 1.4636, G loss: 0.5689\n",
      "[1204/1762] D loss: 1.4075, G loss: 0.7494\n",
      "[1284/1762] D loss: 1.6642, G loss: 0.4349\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.9110\n",
      "[1444/1762] D loss: 1.2804, G loss: 0.8802\n",
      "[1524/1762] D loss: 1.4231, G loss: 0.6181\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.8249\n",
      "[1684/1762] D loss: 1.3949, G loss: 0.6732\n",
      "[1762/1762] D loss: 1.4900, G loss: 0.6097\n",
      "train error: \n",
      " D loss: 1.394820, G loss: 0.694007, D accuracy: 52.1%, cell accuracy: 99.1%, board accuracy: 32.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395600, G loss: 0.697279, D accuracy: 52.5%, cell accuracy: 99.0%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3710, G loss: 0.7850\n",
      "[84/1762] D loss: 1.4749, G loss: 0.5628\n",
      "[164/1762] D loss: 1.3538, G loss: 0.7255\n",
      "[244/1762] D loss: 1.4984, G loss: 0.8936\n",
      "[324/1762] D loss: 1.3944, G loss: 0.6774\n",
      "[404/1762] D loss: 1.3830, G loss: 0.4789\n",
      "[484/1762] D loss: 1.3727, G loss: 0.7770\n",
      "[564/1762] D loss: 1.4225, G loss: 0.6700\n",
      "[644/1762] D loss: 1.4554, G loss: 0.7340\n",
      "[724/1762] D loss: 1.4001, G loss: 0.6736\n",
      "[804/1762] D loss: 1.3954, G loss: 0.6098\n",
      "[884/1762] D loss: 1.4928, G loss: 1.0265\n",
      "[964/1762] D loss: 1.3356, G loss: 1.0105\n",
      "[1044/1762] D loss: 1.4054, G loss: 0.5246\n",
      "[1124/1762] D loss: 1.5083, G loss: 0.7469\n",
      "[1204/1762] D loss: 1.3491, G loss: 0.8642\n",
      "[1284/1762] D loss: 1.4007, G loss: 0.5954\n",
      "[1364/1762] D loss: 1.5199, G loss: 0.7603\n",
      "[1444/1762] D loss: 1.4175, G loss: 0.4983\n",
      "[1524/1762] D loss: 1.4397, G loss: 0.7637\n",
      "[1604/1762] D loss: 1.4727, G loss: 0.6484\n",
      "[1684/1762] D loss: 1.4179, G loss: 0.6751\n",
      "[1762/1762] D loss: 1.4305, G loss: 0.8095\n",
      "train error: \n",
      " D loss: 1.376895, G loss: 0.744844, D accuracy: 52.7%, cell accuracy: 99.2%, board accuracy: 42.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373454, G loss: 0.745720, D accuracy: 53.6%, cell accuracy: 99.1%, board accuracy: 40.5% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3618, G loss: 0.6057\n",
      "[84/1762] D loss: 1.3987, G loss: 0.8353\n",
      "[164/1762] D loss: 1.2666, G loss: 0.9476\n",
      "[244/1762] D loss: 1.3626, G loss: 0.6761\n",
      "[324/1762] D loss: 1.3209, G loss: 0.6422\n",
      "[404/1762] D loss: 1.2921, G loss: 0.8765\n",
      "[484/1762] D loss: 1.3872, G loss: 0.8568\n",
      "[564/1762] D loss: 1.3543, G loss: 0.7407\n",
      "[644/1762] D loss: 1.3901, G loss: 0.5051\n",
      "[724/1762] D loss: 1.3646, G loss: 0.7179\n",
      "[804/1762] D loss: 1.3577, G loss: 0.7270\n",
      "[884/1762] D loss: 1.3546, G loss: 0.6249\n",
      "[964/1762] D loss: 1.4027, G loss: 0.5592\n",
      "[1044/1762] D loss: 1.3800, G loss: 0.8089\n",
      "[1124/1762] D loss: 1.2431, G loss: 0.8944\n",
      "[1204/1762] D loss: 1.3569, G loss: 0.6529\n",
      "[1284/1762] D loss: 1.4949, G loss: 0.8351\n",
      "[1364/1762] D loss: 1.2814, G loss: 0.8359\n",
      "[1444/1762] D loss: 1.4338, G loss: 0.8126\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6972\n",
      "[1604/1762] D loss: 1.4042, G loss: 0.7396\n",
      "[1684/1762] D loss: 1.3253, G loss: 0.5912\n",
      "[1762/1762] D loss: 1.4018, G loss: 0.6587\n",
      "train error: \n",
      " D loss: 1.386316, G loss: 0.749917, D accuracy: 53.4%, cell accuracy: 99.3%, board accuracy: 43.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388043, G loss: 0.748488, D accuracy: 52.2%, cell accuracy: 99.2%, board accuracy: 41.8% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3761, G loss: 0.7771\n",
      "[84/1762] D loss: 1.3948, G loss: 0.7039\n",
      "[164/1762] D loss: 1.3748, G loss: 0.6159\n",
      "[244/1762] D loss: 1.3852, G loss: 1.0732\n",
      "[324/1762] D loss: 1.3584, G loss: 0.7447\n",
      "[404/1762] D loss: 1.3877, G loss: 0.7476\n",
      "[484/1762] D loss: 1.2901, G loss: 0.8182\n",
      "[564/1762] D loss: 1.4051, G loss: 0.7311\n",
      "[644/1762] D loss: 1.3203, G loss: 0.6206\n",
      "[724/1762] D loss: 1.3674, G loss: 0.9696\n",
      "[804/1762] D loss: 1.3933, G loss: 0.5975\n",
      "[884/1762] D loss: 1.3290, G loss: 0.6671\n",
      "[964/1762] D loss: 1.3720, G loss: 0.6886\n",
      "[1044/1762] D loss: 1.3681, G loss: 0.6095\n",
      "[1124/1762] D loss: 1.4376, G loss: 0.8890\n",
      "[1204/1762] D loss: 1.4050, G loss: 0.7363\n",
      "[1284/1762] D loss: 1.3762, G loss: 0.9062\n",
      "[1364/1762] D loss: 1.4121, G loss: 0.6995\n",
      "[1444/1762] D loss: 1.3969, G loss: 0.6678\n",
      "[1524/1762] D loss: 1.3085, G loss: 0.6465\n",
      "[1604/1762] D loss: 1.4456, G loss: 0.6162\n",
      "[1684/1762] D loss: 1.3969, G loss: 0.6677\n",
      "[1762/1762] D loss: 1.3740, G loss: 0.6486\n",
      "train error: \n",
      " D loss: 1.368981, G loss: 0.679715, D accuracy: 55.2%, cell accuracy: 99.4%, board accuracy: 51.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371336, G loss: 0.674922, D accuracy: 54.5%, cell accuracy: 99.3%, board accuracy: 49.5% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4376, G loss: 0.5845\n",
      "[84/1762] D loss: 1.4038, G loss: 0.7939\n",
      "[164/1762] D loss: 1.3370, G loss: 0.7369\n",
      "[244/1762] D loss: 1.4548, G loss: 0.4804\n",
      "[324/1762] D loss: 1.3920, G loss: 0.5811\n",
      "[404/1762] D loss: 1.3796, G loss: 0.7458\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6126\n",
      "[564/1762] D loss: 1.3962, G loss: 0.6516\n",
      "[644/1762] D loss: 1.4015, G loss: 0.5547\n",
      "[724/1762] D loss: 1.3773, G loss: 0.6624\n",
      "[804/1762] D loss: 1.4840, G loss: 0.5717\n",
      "[884/1762] D loss: 1.4100, G loss: 0.5835\n",
      "[964/1762] D loss: 1.3428, G loss: 1.0131\n",
      "[1044/1762] D loss: 1.3562, G loss: 0.7188\n",
      "[1124/1762] D loss: 1.3440, G loss: 0.9568\n",
      "[1204/1762] D loss: 1.2928, G loss: 0.7183\n",
      "[1284/1762] D loss: 1.3705, G loss: 0.9155\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.8126\n",
      "[1444/1762] D loss: 1.3583, G loss: 0.6069\n",
      "[1524/1762] D loss: 1.3606, G loss: 0.8378\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.7458\n",
      "[1684/1762] D loss: 1.3488, G loss: 0.8843\n",
      "[1762/1762] D loss: 1.3756, G loss: 0.6980\n",
      "train error: \n",
      " D loss: 1.362595, G loss: 0.697567, D accuracy: 56.7%, cell accuracy: 99.4%, board accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366684, G loss: 0.690049, D accuracy: 56.0%, cell accuracy: 99.3%, board accuracy: 48.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3946, G loss: 0.7001\n",
      "[84/1762] D loss: 1.4235, G loss: 0.8295\n",
      "[164/1762] D loss: 1.4208, G loss: 0.7020\n",
      "[244/1762] D loss: 1.3441, G loss: 0.6745\n",
      "[324/1762] D loss: 1.3093, G loss: 0.7441\n",
      "[404/1762] D loss: 1.3733, G loss: 0.7759\n",
      "[484/1762] D loss: 1.4019, G loss: 0.5779\n",
      "[564/1762] D loss: 1.2967, G loss: 0.7228\n",
      "[644/1762] D loss: 1.3737, G loss: 0.6925\n",
      "[724/1762] D loss: 1.2650, G loss: 0.6958\n",
      "[804/1762] D loss: 1.2915, G loss: 0.6669\n",
      "[884/1762] D loss: 1.3551, G loss: 0.8940\n",
      "[964/1762] D loss: 1.3073, G loss: 0.9007\n",
      "[1044/1762] D loss: 1.3407, G loss: 0.7923\n",
      "[1124/1762] D loss: 1.3762, G loss: 0.6896\n",
      "[1204/1762] D loss: 1.3825, G loss: 0.8133\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.6170\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.7366\n",
      "[1444/1762] D loss: 1.1967, G loss: 0.7236\n",
      "[1524/1762] D loss: 1.4115, G loss: 0.6528\n",
      "[1604/1762] D loss: 1.3700, G loss: 0.6975\n",
      "[1684/1762] D loss: 1.3727, G loss: 0.7081\n",
      "[1762/1762] D loss: 1.2969, G loss: 0.6559\n",
      "train error: \n",
      " D loss: 1.355887, G loss: 0.798431, D accuracy: 55.5%, cell accuracy: 99.4%, board accuracy: 43.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357775, G loss: 0.788007, D accuracy: 55.2%, cell accuracy: 99.3%, board accuracy: 39.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3086, G loss: 0.8269\n",
      "[84/1762] D loss: 1.3315, G loss: 1.0287\n",
      "[164/1762] D loss: 1.4508, G loss: 0.5063\n",
      "[244/1762] D loss: 1.2941, G loss: 0.7848\n",
      "[324/1762] D loss: 1.3629, G loss: 0.6452\n",
      "[404/1762] D loss: 1.3112, G loss: 0.8933\n",
      "[484/1762] D loss: 1.2089, G loss: 0.8137\n",
      "[564/1762] D loss: 1.4224, G loss: 0.5955\n",
      "[644/1762] D loss: 1.3748, G loss: 0.8164\n",
      "[724/1762] D loss: 1.3197, G loss: 0.6679\n",
      "[804/1762] D loss: 1.3941, G loss: 0.6660\n",
      "[884/1762] D loss: 1.3935, G loss: 0.6340\n",
      "[964/1762] D loss: 1.3988, G loss: 0.7831\n",
      "[1044/1762] D loss: 1.3824, G loss: 0.6849\n",
      "[1124/1762] D loss: 1.4260, G loss: 0.7235\n",
      "[1204/1762] D loss: 1.4691, G loss: 0.4944\n",
      "[1284/1762] D loss: 1.2000, G loss: 0.8551\n",
      "[1364/1762] D loss: 1.4945, G loss: 0.9631\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.7097\n",
      "[1524/1762] D loss: 1.3792, G loss: 0.7078\n",
      "[1604/1762] D loss: 1.3376, G loss: 0.6845\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.7753\n",
      "[1762/1762] D loss: 1.3288, G loss: 0.8992\n",
      "train error: \n",
      " D loss: 1.381450, G loss: 0.887210, D accuracy: 51.6%, cell accuracy: 99.3%, board accuracy: 30.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378049, G loss: 0.884926, D accuracy: 52.3%, cell accuracy: 99.2%, board accuracy: 28.4% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5208, G loss: 0.9882\n",
      "[84/1762] D loss: 1.3464, G loss: 0.6983\n",
      "[164/1762] D loss: 1.3989, G loss: 0.6414\n",
      "[244/1762] D loss: 1.3843, G loss: 0.7533\n",
      "[324/1762] D loss: 1.3761, G loss: 0.5159\n",
      "[404/1762] D loss: 1.3602, G loss: 0.9628\n",
      "[484/1762] D loss: 1.5372, G loss: 0.5097\n",
      "[564/1762] D loss: 1.4032, G loss: 0.8364\n",
      "[644/1762] D loss: 1.4342, G loss: 0.6818\n",
      "[724/1762] D loss: 1.3942, G loss: 0.7281\n",
      "[804/1762] D loss: 1.3983, G loss: 0.6415\n",
      "[884/1762] D loss: 1.3840, G loss: 0.8283\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7393\n",
      "[1044/1762] D loss: 1.3819, G loss: 0.6842\n",
      "[1124/1762] D loss: 1.3759, G loss: 0.7344\n",
      "[1204/1762] D loss: 1.3781, G loss: 0.6508\n",
      "[1284/1762] D loss: 1.3409, G loss: 0.7255\n",
      "[1364/1762] D loss: 1.4009, G loss: 0.7413\n",
      "[1444/1762] D loss: 1.3566, G loss: 0.6390\n",
      "[1524/1762] D loss: 1.4094, G loss: 0.7475\n",
      "[1604/1762] D loss: 1.3977, G loss: 0.6881\n",
      "[1684/1762] D loss: 1.4038, G loss: 0.6711\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.6721\n",
      "train error: \n",
      " D loss: 1.364309, G loss: 0.691715, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359542, G loss: 0.691109, D accuracy: 55.5%, cell accuracy: 99.5%, board accuracy: 47.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4003, G loss: 0.6486\n",
      "[84/1762] D loss: 1.3373, G loss: 0.7673\n",
      "[164/1762] D loss: 1.4072, G loss: 0.8354\n",
      "[244/1762] D loss: 1.3779, G loss: 0.7801\n",
      "[324/1762] D loss: 1.4089, G loss: 0.8127\n",
      "[404/1762] D loss: 1.3308, G loss: 0.7601\n",
      "[484/1762] D loss: 1.2331, G loss: 0.7133\n",
      "[564/1762] D loss: 1.4001, G loss: 0.7854\n",
      "[644/1762] D loss: 1.4524, G loss: 0.6407\n",
      "[724/1762] D loss: 1.4227, G loss: 0.6619\n",
      "[804/1762] D loss: 1.3157, G loss: 0.6330\n",
      "[884/1762] D loss: 1.4157, G loss: 0.8423\n",
      "[964/1762] D loss: 1.2607, G loss: 0.8258\n",
      "[1044/1762] D loss: 1.2436, G loss: 0.8653\n",
      "[1124/1762] D loss: 1.3857, G loss: 0.7598\n",
      "[1204/1762] D loss: 1.3958, G loss: 0.6024\n",
      "[1284/1762] D loss: 1.3955, G loss: 0.7424\n",
      "[1364/1762] D loss: 1.4714, G loss: 0.7240\n",
      "[1444/1762] D loss: 1.3097, G loss: 1.1940\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.8366\n",
      "[1604/1762] D loss: 1.2600, G loss: 0.9102\n",
      "[1684/1762] D loss: 1.3118, G loss: 0.6639\n",
      "[1762/1762] D loss: 1.4236, G loss: 0.6411\n",
      "train error: \n",
      " D loss: 1.354187, G loss: 0.762376, D accuracy: 53.7%, cell accuracy: 99.5%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353770, G loss: 0.753997, D accuracy: 54.2%, cell accuracy: 99.5%, board accuracy: 57.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2654, G loss: 0.9031\n",
      "[84/1762] D loss: 1.2202, G loss: 0.8843\n",
      "[164/1762] D loss: 1.4135, G loss: 0.8119\n",
      "[244/1762] D loss: 1.4221, G loss: 0.6356\n",
      "[324/1762] D loss: 1.4044, G loss: 0.6616\n",
      "[404/1762] D loss: 1.3079, G loss: 0.8330\n",
      "[484/1762] D loss: 1.4164, G loss: 0.9630\n",
      "[564/1762] D loss: 1.3033, G loss: 0.7745\n",
      "[644/1762] D loss: 1.4512, G loss: 0.6027\n",
      "[724/1762] D loss: 1.3782, G loss: 0.8019\n",
      "[804/1762] D loss: 1.3740, G loss: 0.5446\n",
      "[884/1762] D loss: 1.4056, G loss: 0.6816\n",
      "[964/1762] D loss: 1.4569, G loss: 0.6829\n",
      "[1044/1762] D loss: 1.4068, G loss: 0.6339\n",
      "[1124/1762] D loss: 1.4063, G loss: 0.6205\n",
      "[1204/1762] D loss: 1.4146, G loss: 0.7788\n",
      "[1284/1762] D loss: 1.3774, G loss: 0.7044\n",
      "[1364/1762] D loss: 1.2947, G loss: 0.6855\n",
      "[1444/1762] D loss: 1.5454, G loss: 0.5489\n",
      "[1524/1762] D loss: 1.2264, G loss: 0.6329\n",
      "[1604/1762] D loss: 1.4252, G loss: 0.9358\n",
      "[1684/1762] D loss: 1.4162, G loss: 0.6418\n",
      "[1762/1762] D loss: 1.3850, G loss: 0.8702\n",
      "train error: \n",
      " D loss: 1.391102, G loss: 0.928856, D accuracy: 52.5%, cell accuracy: 99.6%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382141, G loss: 0.925706, D accuracy: 53.1%, cell accuracy: 99.5%, board accuracy: 54.3% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4149, G loss: 0.8420\n",
      "[84/1762] D loss: 1.2445, G loss: 0.6552\n",
      "[164/1762] D loss: 1.4402, G loss: 0.7444\n",
      "[244/1762] D loss: 1.2645, G loss: 0.6564\n",
      "[324/1762] D loss: 1.3990, G loss: 0.6723\n",
      "[404/1762] D loss: 1.3558, G loss: 0.9716\n",
      "[484/1762] D loss: 1.2867, G loss: 0.8059\n",
      "[564/1762] D loss: 1.3824, G loss: 0.7038\n",
      "[644/1762] D loss: 1.4266, G loss: 0.7968\n",
      "[724/1762] D loss: 1.4194, G loss: 0.6219\n",
      "[804/1762] D loss: 1.3593, G loss: 0.9951\n",
      "[884/1762] D loss: 1.3777, G loss: 0.8256\n",
      "[964/1762] D loss: 1.2546, G loss: 0.7386\n",
      "[1044/1762] D loss: 1.4186, G loss: 0.6781\n",
      "[1124/1762] D loss: 1.3077, G loss: 0.7936\n",
      "[1204/1762] D loss: 1.4778, G loss: 0.5708\n",
      "[1284/1762] D loss: 1.3781, G loss: 0.6494\n",
      "[1364/1762] D loss: 1.2625, G loss: 0.7326\n",
      "[1444/1762] D loss: 1.1588, G loss: 0.6746\n",
      "[1524/1762] D loss: 1.3924, G loss: 0.6519\n",
      "[1604/1762] D loss: 1.4230, G loss: 0.8254\n",
      "[1684/1762] D loss: 1.4139, G loss: 0.8411\n",
      "[1762/1762] D loss: 1.3968, G loss: 0.8012\n",
      "train error: \n",
      " D loss: 1.380349, G loss: 0.886767, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370609, G loss: 0.885532, D accuracy: 52.2%, cell accuracy: 99.5%, board accuracy: 57.3% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2501, G loss: 0.8888\n",
      "[84/1762] D loss: 1.3505, G loss: 0.7974\n",
      "[164/1762] D loss: 1.4189, G loss: 0.7750\n",
      "[244/1762] D loss: 1.3466, G loss: 0.8201\n",
      "[324/1762] D loss: 1.3981, G loss: 0.5706\n",
      "[404/1762] D loss: 1.3331, G loss: 0.9537\n",
      "[484/1762] D loss: 1.2546, G loss: 0.8347\n",
      "[564/1762] D loss: 1.3770, G loss: 0.6879\n",
      "[644/1762] D loss: 1.4081, G loss: 0.8243\n",
      "[724/1762] D loss: 1.4399, G loss: 0.7482\n",
      "[804/1762] D loss: 1.2608, G loss: 0.8795\n",
      "[884/1762] D loss: 1.3959, G loss: 0.6136\n",
      "[964/1762] D loss: 1.3558, G loss: 0.6108\n",
      "[1044/1762] D loss: 1.4627, G loss: 0.6607\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.6720\n",
      "[1204/1762] D loss: 1.3780, G loss: 0.5879\n",
      "[1284/1762] D loss: 1.4722, G loss: 0.8064\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.8255\n",
      "[1444/1762] D loss: 1.3907, G loss: 0.8747\n",
      "[1524/1762] D loss: 1.4386, G loss: 0.8030\n",
      "[1604/1762] D loss: 1.4140, G loss: 0.7061\n",
      "[1684/1762] D loss: 1.3953, G loss: 0.6949\n",
      "[1762/1762] D loss: 1.3857, G loss: 0.6236\n",
      "train error: \n",
      " D loss: 1.361642, G loss: 0.664553, D accuracy: 54.9%, cell accuracy: 99.4%, board accuracy: 41.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355701, G loss: 0.666830, D accuracy: 55.2%, cell accuracy: 99.3%, board accuracy: 36.8% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4091, G loss: 0.6038\n",
      "[84/1762] D loss: 1.2772, G loss: 0.9015\n",
      "[164/1762] D loss: 1.3175, G loss: 0.6065\n",
      "[244/1762] D loss: 1.4050, G loss: 0.5776\n",
      "[324/1762] D loss: 1.3945, G loss: 0.6199\n",
      "[404/1762] D loss: 1.4136, G loss: 0.7783\n",
      "[484/1762] D loss: 1.4663, G loss: 0.5459\n",
      "[564/1762] D loss: 1.4685, G loss: 0.5987\n",
      "[644/1762] D loss: 1.3856, G loss: 0.7166\n",
      "[724/1762] D loss: 1.1293, G loss: 0.9460\n",
      "[804/1762] D loss: 1.4155, G loss: 0.6567\n",
      "[884/1762] D loss: 1.3287, G loss: 0.6797\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7887\n",
      "[1044/1762] D loss: 1.1864, G loss: 0.8839\n",
      "[1124/1762] D loss: 1.4338, G loss: 0.4978\n",
      "[1204/1762] D loss: 1.4076, G loss: 0.7328\n",
      "[1284/1762] D loss: 1.2786, G loss: 0.7816\n",
      "[1364/1762] D loss: 1.3932, G loss: 0.7163\n",
      "[1444/1762] D loss: 1.4009, G loss: 0.5952\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6370\n",
      "[1604/1762] D loss: 1.5215, G loss: 0.5777\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.8337\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.6921\n",
      "train error: \n",
      " D loss: 1.357131, G loss: 0.677735, D accuracy: 54.3%, cell accuracy: 99.5%, board accuracy: 53.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354799, G loss: 0.674642, D accuracy: 54.4%, cell accuracy: 99.5%, board accuracy: 50.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2309, G loss: 0.7709\n",
      "[84/1762] D loss: 1.2603, G loss: 0.6839\n",
      "[164/1762] D loss: 1.2912, G loss: 0.9450\n",
      "[244/1762] D loss: 1.4819, G loss: 0.3948\n",
      "[324/1762] D loss: 1.3894, G loss: 0.7634\n",
      "[404/1762] D loss: 1.3130, G loss: 0.7566\n",
      "[484/1762] D loss: 1.3911, G loss: 0.6926\n",
      "[564/1762] D loss: 1.4660, G loss: 0.6480\n",
      "[644/1762] D loss: 1.4087, G loss: 0.7945\n",
      "[724/1762] D loss: 1.4242, G loss: 0.5916\n",
      "[804/1762] D loss: 1.4059, G loss: 0.6401\n",
      "[884/1762] D loss: 1.3513, G loss: 0.7872\n",
      "[964/1762] D loss: 1.4085, G loss: 0.7161\n",
      "[1044/1762] D loss: 1.3297, G loss: 0.7683\n",
      "[1124/1762] D loss: 1.3635, G loss: 0.7423\n",
      "[1204/1762] D loss: 1.3390, G loss: 1.0931\n",
      "[1284/1762] D loss: 1.4169, G loss: 0.7015\n",
      "[1364/1762] D loss: 1.3056, G loss: 0.6534\n",
      "[1444/1762] D loss: 1.4292, G loss: 0.6379\n",
      "[1524/1762] D loss: 1.3968, G loss: 0.5074\n",
      "[1604/1762] D loss: 1.4287, G loss: 0.6478\n",
      "[1684/1762] D loss: 1.4048, G loss: 0.8774\n",
      "[1762/1762] D loss: 1.4485, G loss: 0.5209\n",
      "train error: \n",
      " D loss: 1.365281, G loss: 0.611002, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 52.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359773, G loss: 0.609662, D accuracy: 55.3%, cell accuracy: 99.5%, board accuracy: 49.8% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2623, G loss: 0.8043\n",
      "[84/1762] D loss: 1.2507, G loss: 0.6635\n",
      "[164/1762] D loss: 1.2039, G loss: 0.6892\n",
      "[244/1762] D loss: 1.4906, G loss: 0.8243\n",
      "[324/1762] D loss: 1.2250, G loss: 0.7828\n",
      "[404/1762] D loss: 1.4166, G loss: 0.8257\n",
      "[484/1762] D loss: 1.3741, G loss: 0.6564\n",
      "[564/1762] D loss: 1.2337, G loss: 0.7509\n",
      "[644/1762] D loss: 1.5099, G loss: 0.7721\n",
      "[724/1762] D loss: 1.4177, G loss: 0.7229\n",
      "[804/1762] D loss: 1.4159, G loss: 0.5721\n",
      "[884/1762] D loss: 1.3890, G loss: 0.6802\n",
      "[964/1762] D loss: 1.4554, G loss: 0.5927\n",
      "[1044/1762] D loss: 1.4206, G loss: 0.6415\n",
      "[1124/1762] D loss: 1.3833, G loss: 0.7380\n",
      "[1204/1762] D loss: 1.3278, G loss: 0.8621\n",
      "[1284/1762] D loss: 1.3928, G loss: 0.6086\n",
      "[1364/1762] D loss: 1.4243, G loss: 0.8019\n",
      "[1444/1762] D loss: 1.4606, G loss: 0.7967\n",
      "[1524/1762] D loss: 1.4170, G loss: 0.5784\n",
      "[1604/1762] D loss: 1.4067, G loss: 0.6482\n",
      "[1684/1762] D loss: 1.2683, G loss: 0.7527\n",
      "[1762/1762] D loss: 1.5211, G loss: 0.8044\n",
      "train error: \n",
      " D loss: 1.370228, G loss: 0.612308, D accuracy: 54.6%, cell accuracy: 99.6%, board accuracy: 61.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365929, G loss: 0.613171, D accuracy: 54.8%, cell accuracy: 99.5%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4919, G loss: 0.4059\n",
      "[84/1762] D loss: 1.3378, G loss: 0.6956\n",
      "[164/1762] D loss: 1.3849, G loss: 0.7421\n",
      "[244/1762] D loss: 1.4026, G loss: 0.8431\n",
      "[324/1762] D loss: 1.4015, G loss: 0.5694\n",
      "[404/1762] D loss: 1.3949, G loss: 0.8463\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6505\n",
      "[564/1762] D loss: 1.4023, G loss: 0.7541\n",
      "[644/1762] D loss: 1.3430, G loss: 0.7431\n",
      "[724/1762] D loss: 1.4307, G loss: 0.7450\n",
      "[804/1762] D loss: 1.4131, G loss: 0.6665\n",
      "[884/1762] D loss: 1.3676, G loss: 0.6029\n",
      "[964/1762] D loss: 1.3807, G loss: 1.0562\n",
      "[1044/1762] D loss: 1.3750, G loss: 0.6159\n",
      "[1124/1762] D loss: 1.2449, G loss: 0.8031\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.5951\n",
      "[1284/1762] D loss: 1.4247, G loss: 0.9999\n",
      "[1364/1762] D loss: 1.2104, G loss: 0.8462\n",
      "[1444/1762] D loss: 1.1889, G loss: 0.8586\n",
      "[1524/1762] D loss: 1.3941, G loss: 0.7124\n",
      "[1604/1762] D loss: 1.2265, G loss: 0.8037\n",
      "[1684/1762] D loss: 1.2288, G loss: 1.0647\n",
      "[1762/1762] D loss: 1.2419, G loss: 0.8204\n",
      "train error: \n",
      " D loss: 1.358716, G loss: 0.644391, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349584, G loss: 0.652350, D accuracy: 55.8%, cell accuracy: 99.5%, board accuracy: 56.6% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4334, G loss: 0.6371\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6813\n",
      "[164/1762] D loss: 1.4185, G loss: 0.8818\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7197\n",
      "[324/1762] D loss: 1.4078, G loss: 0.6946\n",
      "[404/1762] D loss: 1.3415, G loss: 0.6950\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7401\n",
      "[564/1762] D loss: 1.2724, G loss: 0.5971\n",
      "[644/1762] D loss: 1.4280, G loss: 0.8625\n",
      "[724/1762] D loss: 1.4245, G loss: 0.5482\n",
      "[804/1762] D loss: 1.4590, G loss: 0.9470\n",
      "[884/1762] D loss: 1.3894, G loss: 0.6301\n",
      "[964/1762] D loss: 1.2439, G loss: 0.9401\n",
      "[1044/1762] D loss: 1.2218, G loss: 0.9565\n",
      "[1124/1762] D loss: 1.2402, G loss: 0.6587\n",
      "[1204/1762] D loss: 1.2665, G loss: 0.6178\n",
      "[1284/1762] D loss: 1.4228, G loss: 0.8862\n",
      "[1364/1762] D loss: 1.4025, G loss: 0.5759\n",
      "[1444/1762] D loss: 1.3986, G loss: 0.5774\n",
      "[1524/1762] D loss: 1.4055, G loss: 0.8599\n",
      "[1604/1762] D loss: 1.4463, G loss: 0.8471\n",
      "[1684/1762] D loss: 1.4520, G loss: 0.5417\n",
      "[1762/1762] D loss: 1.4303, G loss: 0.7829\n",
      "train error: \n",
      " D loss: 1.385749, G loss: 0.931065, D accuracy: 52.2%, cell accuracy: 99.5%, board accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379103, G loss: 0.933421, D accuracy: 52.7%, cell accuracy: 99.5%, board accuracy: 48.6% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2828, G loss: 0.8401\n",
      "[84/1762] D loss: 1.4290, G loss: 0.7297\n",
      "[164/1762] D loss: 1.4029, G loss: 0.8477\n",
      "[244/1762] D loss: 1.4327, G loss: 0.5701\n",
      "[324/1762] D loss: 1.3398, G loss: 0.6754\n",
      "[404/1762] D loss: 1.3588, G loss: 0.7794\n",
      "[484/1762] D loss: 1.2571, G loss: 0.7885\n",
      "[564/1762] D loss: 1.4150, G loss: 0.7033\n",
      "[644/1762] D loss: 1.3806, G loss: 0.7192\n",
      "[724/1762] D loss: 1.4770, G loss: 0.5317\n",
      "[804/1762] D loss: 1.3965, G loss: 0.6698\n",
      "[884/1762] D loss: 1.4346, G loss: 0.8060\n",
      "[964/1762] D loss: 1.4309, G loss: 0.6423\n",
      "[1044/1762] D loss: 1.2892, G loss: 0.8460\n",
      "[1124/1762] D loss: 1.3980, G loss: 0.6567\n",
      "[1204/1762] D loss: 1.3901, G loss: 0.6971\n",
      "[1284/1762] D loss: 1.1681, G loss: 1.0328\n",
      "[1364/1762] D loss: 1.3437, G loss: 0.7083\n",
      "[1444/1762] D loss: 1.4353, G loss: 0.5607\n",
      "[1524/1762] D loss: 1.4826, G loss: 0.8144\n",
      "[1604/1762] D loss: 1.2253, G loss: 0.9827\n",
      "[1684/1762] D loss: 1.4633, G loss: 0.5780\n",
      "[1762/1762] D loss: 1.4366, G loss: 0.7617\n",
      "train error: \n",
      " D loss: 1.406882, G loss: 1.008521, D accuracy: 52.5%, cell accuracy: 99.5%, board accuracy: 48.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397799, G loss: 1.006090, D accuracy: 53.1%, cell accuracy: 99.4%, board accuracy: 46.4% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4738, G loss: 0.8454\n",
      "[84/1762] D loss: 1.2423, G loss: 0.6176\n",
      "[164/1762] D loss: 1.3101, G loss: 0.8372\n",
      "[244/1762] D loss: 1.4354, G loss: 0.7894\n",
      "[324/1762] D loss: 1.3833, G loss: 0.6284\n",
      "[404/1762] D loss: 1.3978, G loss: 0.8642\n",
      "[484/1762] D loss: 1.4520, G loss: 0.6342\n",
      "[564/1762] D loss: 1.2325, G loss: 0.7616\n",
      "[644/1762] D loss: 1.2725, G loss: 0.7235\n",
      "[724/1762] D loss: 1.3984, G loss: 0.6901\n",
      "[804/1762] D loss: 1.3955, G loss: 0.7126\n",
      "[884/1762] D loss: 1.3939, G loss: 0.6258\n",
      "[964/1762] D loss: 1.4074, G loss: 0.8118\n",
      "[1044/1762] D loss: 1.4014, G loss: 0.6982\n",
      "[1124/1762] D loss: 1.3814, G loss: 0.5201\n",
      "[1204/1762] D loss: 1.4320, G loss: 0.6676\n",
      "[1284/1762] D loss: 1.3701, G loss: 0.7327\n",
      "[1364/1762] D loss: 0.8632, G loss: 1.1579\n",
      "[1444/1762] D loss: 1.4028, G loss: 0.5586\n",
      "[1524/1762] D loss: 1.4150, G loss: 0.8304\n",
      "[1604/1762] D loss: 1.4524, G loss: 0.7281\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.6078\n",
      "[1762/1762] D loss: 1.0286, G loss: 1.0023\n",
      "train error: \n",
      " D loss: 1.363692, G loss: 0.849709, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 51.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356519, G loss: 0.848166, D accuracy: 53.6%, cell accuracy: 99.5%, board accuracy: 51.8% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2197, G loss: 0.9518\n",
      "[84/1762] D loss: 1.4177, G loss: 0.6238\n",
      "[164/1762] D loss: 1.4005, G loss: 0.7323\n",
      "[244/1762] D loss: 1.4297, G loss: 0.7531\n",
      "[324/1762] D loss: 1.3948, G loss: 0.8208\n",
      "[404/1762] D loss: 1.3879, G loss: 0.8804\n",
      "[484/1762] D loss: 1.0533, G loss: 0.9204\n",
      "[564/1762] D loss: 1.4333, G loss: 0.7108\n",
      "[644/1762] D loss: 1.4060, G loss: 0.5136\n",
      "[724/1762] D loss: 1.2039, G loss: 1.2353\n",
      "[804/1762] D loss: 1.3981, G loss: 0.6484\n",
      "[884/1762] D loss: 1.4229, G loss: 0.7835\n",
      "[964/1762] D loss: 1.3964, G loss: 0.8487\n",
      "[1044/1762] D loss: 1.3795, G loss: 0.6775\n",
      "[1124/1762] D loss: 1.3995, G loss: 0.7349\n",
      "[1204/1762] D loss: 1.4008, G loss: 0.5834\n",
      "[1284/1762] D loss: 1.2287, G loss: 0.7862\n",
      "[1364/1762] D loss: 1.3228, G loss: 0.7940\n",
      "[1444/1762] D loss: 1.2344, G loss: 0.8230\n",
      "[1524/1762] D loss: 1.1855, G loss: 0.7932\n",
      "[1604/1762] D loss: 1.4298, G loss: 0.7407\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.7459\n",
      "[1762/1762] D loss: 1.4621, G loss: 0.7575\n",
      "train error: \n",
      " D loss: 1.358896, G loss: 0.660710, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350357, G loss: 0.667723, D accuracy: 54.4%, cell accuracy: 99.5%, board accuracy: 51.4% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2085, G loss: 0.6616\n",
      "[84/1762] D loss: 1.3645, G loss: 0.8975\n",
      "[164/1762] D loss: 1.4047, G loss: 0.6594\n",
      "[244/1762] D loss: 1.2757, G loss: 0.8965\n",
      "[324/1762] D loss: 1.3985, G loss: 0.6965\n",
      "[404/1762] D loss: 1.2355, G loss: 1.1184\n",
      "[484/1762] D loss: 1.3909, G loss: 0.6566\n",
      "[564/1762] D loss: 1.1420, G loss: 0.8759\n",
      "[644/1762] D loss: 1.4154, G loss: 0.6291\n",
      "[724/1762] D loss: 1.3243, G loss: 0.7364\n",
      "[804/1762] D loss: 1.2514, G loss: 0.8654\n",
      "[884/1762] D loss: 1.3755, G loss: 0.7028\n",
      "[964/1762] D loss: 1.3953, G loss: 0.7767\n",
      "[1044/1762] D loss: 1.4705, G loss: 0.5574\n",
      "[1124/1762] D loss: 1.2135, G loss: 0.8959\n",
      "[1204/1762] D loss: 1.4091, G loss: 0.7490\n",
      "[1284/1762] D loss: 1.3540, G loss: 0.7187\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7683\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.7080\n",
      "[1524/1762] D loss: 1.4074, G loss: 0.8180\n",
      "[1604/1762] D loss: 1.2904, G loss: 0.9865\n",
      "[1684/1762] D loss: 1.3154, G loss: 0.6784\n",
      "[1762/1762] D loss: 1.4331, G loss: 0.9113\n",
      "train error: \n",
      " D loss: 1.374718, G loss: 0.904096, D accuracy: 52.7%, cell accuracy: 99.5%, board accuracy: 53.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362638, G loss: 0.907610, D accuracy: 53.8%, cell accuracy: 99.5%, board accuracy: 49.5% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1776, G loss: 0.9046\n",
      "[84/1762] D loss: 1.3688, G loss: 0.8811\n",
      "[164/1762] D loss: 1.3856, G loss: 0.7088\n",
      "[244/1762] D loss: 1.4060, G loss: 0.7840\n",
      "[324/1762] D loss: 1.4148, G loss: 0.7439\n",
      "[404/1762] D loss: 1.4794, G loss: 0.7462\n",
      "[484/1762] D loss: 1.1971, G loss: 0.8912\n",
      "[564/1762] D loss: 1.3751, G loss: 0.7833\n",
      "[644/1762] D loss: 1.3996, G loss: 0.7215\n",
      "[724/1762] D loss: 1.3692, G loss: 0.6728\n",
      "[804/1762] D loss: 1.2263, G loss: 0.9393\n",
      "[884/1762] D loss: 1.3557, G loss: 0.7711\n",
      "[964/1762] D loss: 1.4356, G loss: 0.6420\n",
      "[1044/1762] D loss: 1.2328, G loss: 0.8633\n",
      "[1124/1762] D loss: 1.3489, G loss: 0.7294\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6900\n",
      "[1284/1762] D loss: 1.2329, G loss: 0.7835\n",
      "[1364/1762] D loss: 1.4101, G loss: 0.6301\n",
      "[1444/1762] D loss: 1.4524, G loss: 0.8279\n",
      "[1524/1762] D loss: 1.1697, G loss: 0.9281\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.6902\n",
      "[1684/1762] D loss: 1.2989, G loss: 0.6697\n",
      "[1762/1762] D loss: 1.4070, G loss: 0.7513\n",
      "train error: \n",
      " D loss: 1.353006, G loss: 0.819784, D accuracy: 52.7%, cell accuracy: 99.6%, board accuracy: 60.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341120, G loss: 0.823306, D accuracy: 54.2%, cell accuracy: 99.5%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0445, G loss: 0.9464\n",
      "[84/1762] D loss: 1.3771, G loss: 0.7449\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6432\n",
      "[244/1762] D loss: 1.4027, G loss: 0.9043\n",
      "[324/1762] D loss: 1.2343, G loss: 0.7179\n",
      "[404/1762] D loss: 1.4288, G loss: 0.8107\n",
      "[484/1762] D loss: 1.1103, G loss: 0.9854\n",
      "[564/1762] D loss: 1.4042, G loss: 0.6977\n",
      "[644/1762] D loss: 1.3944, G loss: 0.5480\n",
      "[724/1762] D loss: 1.3857, G loss: 0.7813\n",
      "[804/1762] D loss: 1.4277, G loss: 0.5822\n",
      "[884/1762] D loss: 1.0847, G loss: 0.8357\n",
      "[964/1762] D loss: 1.3968, G loss: 0.6965\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6054\n",
      "[1124/1762] D loss: 1.3123, G loss: 0.7706\n",
      "[1204/1762] D loss: 1.0749, G loss: 0.9052\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.7077\n",
      "[1364/1762] D loss: 1.2911, G loss: 0.5920\n",
      "[1444/1762] D loss: 1.4102, G loss: 0.5598\n",
      "[1524/1762] D loss: 1.0517, G loss: 1.1150\n",
      "[1604/1762] D loss: 1.3784, G loss: 0.7243\n",
      "[1684/1762] D loss: 1.4243, G loss: 0.9680\n",
      "[1762/1762] D loss: 1.0698, G loss: 0.8323\n",
      "train error: \n",
      " D loss: 1.353157, G loss: 0.658219, D accuracy: 54.6%, cell accuracy: 99.5%, board accuracy: 52.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343860, G loss: 0.661227, D accuracy: 55.2%, cell accuracy: 99.4%, board accuracy: 50.2% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3900, G loss: 0.7043\n",
      "[84/1762] D loss: 1.3909, G loss: 0.8714\n",
      "[164/1762] D loss: 1.4024, G loss: 0.7574\n",
      "[244/1762] D loss: 1.3619, G loss: 0.7037\n",
      "[324/1762] D loss: 1.4208, G loss: 0.5611\n",
      "[404/1762] D loss: 1.3858, G loss: 0.8549\n",
      "[484/1762] D loss: 1.2769, G loss: 0.5597\n",
      "[564/1762] D loss: 1.3697, G loss: 0.7287\n",
      "[644/1762] D loss: 1.4009, G loss: 0.7701\n",
      "[724/1762] D loss: 1.3447, G loss: 0.6521\n",
      "[804/1762] D loss: 1.3558, G loss: 0.7224\n",
      "[884/1762] D loss: 1.2563, G loss: 0.7868\n",
      "[964/1762] D loss: 1.4413, G loss: 0.8035\n",
      "[1044/1762] D loss: 1.3956, G loss: 0.7501\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7183\n",
      "[1204/1762] D loss: 1.4270, G loss: 0.6897\n",
      "[1284/1762] D loss: 1.4661, G loss: 0.7271\n",
      "[1364/1762] D loss: 1.2363, G loss: 0.7762\n",
      "[1444/1762] D loss: 1.4096, G loss: 0.6645\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.7886\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.8650\n",
      "[1684/1762] D loss: 1.2255, G loss: 0.8366\n",
      "[1762/1762] D loss: 1.4025, G loss: 0.5952\n",
      "train error: \n",
      " D loss: 1.363599, G loss: 0.591543, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351830, G loss: 0.598154, D accuracy: 56.8%, cell accuracy: 99.5%, board accuracy: 56.1% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3284, G loss: 0.7085\n",
      "[84/1762] D loss: 1.0188, G loss: 0.9834\n",
      "[164/1762] D loss: 1.3966, G loss: 0.6023\n",
      "[244/1762] D loss: 1.3936, G loss: 0.7631\n",
      "[324/1762] D loss: 1.3844, G loss: 0.5515\n",
      "[404/1762] D loss: 1.3710, G loss: 0.9302\n",
      "[484/1762] D loss: 1.4137, G loss: 0.5740\n",
      "[564/1762] D loss: 1.2188, G loss: 0.8223\n",
      "[644/1762] D loss: 1.2113, G loss: 0.8984\n",
      "[724/1762] D loss: 1.4237, G loss: 0.6030\n",
      "[804/1762] D loss: 1.0137, G loss: 0.9052\n",
      "[884/1762] D loss: 1.4019, G loss: 0.6524\n",
      "[964/1762] D loss: 1.4816, G loss: 0.5351\n",
      "[1044/1762] D loss: 1.4106, G loss: 0.7685\n",
      "[1124/1762] D loss: 1.4124, G loss: 0.5790\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.6417\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.7744\n",
      "[1364/1762] D loss: 1.3951, G loss: 0.5991\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.6867\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.9210\n",
      "[1604/1762] D loss: 1.2747, G loss: 0.7216\n",
      "[1684/1762] D loss: 1.4551, G loss: 0.8593\n",
      "[1762/1762] D loss: 1.4139, G loss: 0.6844\n",
      "train error: \n",
      " D loss: 1.340692, G loss: 0.746568, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 62.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329435, G loss: 0.749235, D accuracy: 55.1%, cell accuracy: 99.5%, board accuracy: 61.4% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3781, G loss: 0.7209\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6366\n",
      "[164/1762] D loss: 1.3804, G loss: 0.8250\n",
      "[244/1762] D loss: 1.1639, G loss: 0.9764\n",
      "[324/1762] D loss: 1.4011, G loss: 0.7200\n",
      "[404/1762] D loss: 1.2640, G loss: 0.9346\n",
      "[484/1762] D loss: 1.3961, G loss: 0.6902\n",
      "[564/1762] D loss: 1.4252, G loss: 0.5495\n",
      "[644/1762] D loss: 1.4059, G loss: 0.6431\n",
      "[724/1762] D loss: 1.3485, G loss: 0.7045\n",
      "[804/1762] D loss: 1.3902, G loss: 0.7369\n",
      "[884/1762] D loss: 1.4073, G loss: 0.7452\n",
      "[964/1762] D loss: 1.2154, G loss: 0.9301\n",
      "[1044/1762] D loss: 1.3468, G loss: 0.7544\n",
      "[1124/1762] D loss: 1.3859, G loss: 0.5924\n",
      "[1204/1762] D loss: 1.1970, G loss: 0.8619\n",
      "[1284/1762] D loss: 1.4089, G loss: 0.7785\n",
      "[1364/1762] D loss: 1.4176, G loss: 0.6626\n",
      "[1444/1762] D loss: 1.4278, G loss: 0.6916\n",
      "[1524/1762] D loss: 1.2170, G loss: 0.9678\n",
      "[1604/1762] D loss: 1.0264, G loss: 0.8492\n",
      "[1684/1762] D loss: 1.4337, G loss: 0.7576\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.7653\n",
      "train error: \n",
      " D loss: 1.338879, G loss: 0.789367, D accuracy: 54.6%, cell accuracy: 99.5%, board accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324496, G loss: 0.793623, D accuracy: 56.2%, cell accuracy: 99.5%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3956, G loss: 0.7029\n",
      "[84/1762] D loss: 1.3447, G loss: 0.7831\n",
      "[164/1762] D loss: 1.3210, G loss: 0.7034\n",
      "[244/1762] D loss: 1.0633, G loss: 1.0483\n",
      "[324/1762] D loss: 1.3375, G loss: 0.8446\n",
      "[404/1762] D loss: 1.4351, G loss: 0.8515\n",
      "[484/1762] D loss: 1.1123, G loss: 0.7899\n",
      "[564/1762] D loss: 1.0057, G loss: 1.0039\n",
      "[644/1762] D loss: 1.4063, G loss: 0.7788\n",
      "[724/1762] D loss: 1.3497, G loss: 0.7943\n",
      "[804/1762] D loss: 1.4186, G loss: 0.8889\n",
      "[884/1762] D loss: 1.4025, G loss: 0.6252\n",
      "[964/1762] D loss: 1.3937, G loss: 0.7822\n",
      "[1044/1762] D loss: 1.2991, G loss: 0.7135\n",
      "[1124/1762] D loss: 1.3245, G loss: 0.6093\n",
      "[1204/1762] D loss: 1.4205, G loss: 0.7061\n",
      "[1284/1762] D loss: 1.3784, G loss: 0.7177\n",
      "[1364/1762] D loss: 1.2040, G loss: 0.9467\n",
      "[1444/1762] D loss: 1.3145, G loss: 0.6829\n",
      "[1524/1762] D loss: 1.3648, G loss: 0.8790\n",
      "[1604/1762] D loss: 1.3983, G loss: 0.7592\n",
      "[1684/1762] D loss: 1.4013, G loss: 0.6463\n",
      "[1762/1762] D loss: 1.3435, G loss: 0.9075\n",
      "train error: \n",
      " D loss: 1.345253, G loss: 0.772881, D accuracy: 53.3%, cell accuracy: 99.6%, board accuracy: 66.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331849, G loss: 0.780130, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 63.4% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4229, G loss: 0.6232\n",
      "[84/1762] D loss: 1.4008, G loss: 0.6679\n",
      "[164/1762] D loss: 1.3935, G loss: 0.7040\n",
      "[244/1762] D loss: 1.4059, G loss: 0.8017\n",
      "[324/1762] D loss: 1.3838, G loss: 0.6408\n",
      "[404/1762] D loss: 1.3322, G loss: 0.8790\n",
      "[484/1762] D loss: 1.3359, G loss: 0.6344\n",
      "[564/1762] D loss: 1.2060, G loss: 0.8619\n",
      "[644/1762] D loss: 1.3902, G loss: 0.8031\n",
      "[724/1762] D loss: 1.3532, G loss: 0.7764\n",
      "[804/1762] D loss: 1.1819, G loss: 0.7411\n",
      "[884/1762] D loss: 1.3918, G loss: 0.6821\n",
      "[964/1762] D loss: 1.3722, G loss: 0.7808\n",
      "[1044/1762] D loss: 1.4589, G loss: 0.6383\n",
      "[1124/1762] D loss: 1.3833, G loss: 0.6893\n",
      "[1204/1762] D loss: 1.4038, G loss: 0.5729\n",
      "[1284/1762] D loss: 1.4531, G loss: 0.5763\n",
      "[1364/1762] D loss: 1.4683, G loss: 0.7934\n",
      "[1444/1762] D loss: 1.2729, G loss: 0.5651\n",
      "[1524/1762] D loss: 1.3938, G loss: 0.8130\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6252\n",
      "[1684/1762] D loss: 1.4176, G loss: 0.6103\n",
      "[1762/1762] D loss: 1.4025, G loss: 0.7007\n",
      "train error: \n",
      " D loss: 1.343391, G loss: 0.799332, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331100, G loss: 0.804396, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.8359\n",
      "[84/1762] D loss: 1.4273, G loss: 0.8402\n",
      "[164/1762] D loss: 1.4369, G loss: 0.6314\n",
      "[244/1762] D loss: 1.3904, G loss: 0.7345\n",
      "[324/1762] D loss: 1.4184, G loss: 0.7046\n",
      "[404/1762] D loss: 1.3942, G loss: 0.7336\n",
      "[484/1762] D loss: 1.4246, G loss: 0.7709\n",
      "[564/1762] D loss: 1.4050, G loss: 0.7645\n",
      "[644/1762] D loss: 1.4235, G loss: 0.6355\n",
      "[724/1762] D loss: 1.2123, G loss: 0.8856\n",
      "[804/1762] D loss: 1.2791, G loss: 0.7790\n",
      "[884/1762] D loss: 1.3680, G loss: 0.7531\n",
      "[964/1762] D loss: 1.2089, G loss: 0.6921\n",
      "[1044/1762] D loss: 1.2039, G loss: 0.8061\n",
      "[1124/1762] D loss: 1.4092, G loss: 0.7086\n",
      "[1204/1762] D loss: 1.4711, G loss: 0.4936\n",
      "[1284/1762] D loss: 1.1492, G loss: 0.9424\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.8658\n",
      "[1444/1762] D loss: 1.1861, G loss: 0.8976\n",
      "[1524/1762] D loss: 1.3527, G loss: 0.6019\n",
      "[1604/1762] D loss: 1.4256, G loss: 0.8451\n",
      "[1684/1762] D loss: 1.1834, G loss: 0.9144\n",
      "[1762/1762] D loss: 1.4456, G loss: 0.4725\n",
      "train error: \n",
      " D loss: 1.370710, G loss: 0.569409, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 71.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362787, G loss: 0.570894, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3805, G loss: 0.5341\n",
      "[84/1762] D loss: 1.3959, G loss: 0.7262\n",
      "[164/1762] D loss: 1.3846, G loss: 0.7888\n",
      "[244/1762] D loss: 1.3961, G loss: 0.6803\n",
      "[324/1762] D loss: 1.3911, G loss: 0.7372\n",
      "[404/1762] D loss: 1.2031, G loss: 0.9216\n",
      "[484/1762] D loss: 1.4084, G loss: 0.6399\n",
      "[564/1762] D loss: 1.1971, G loss: 0.8674\n",
      "[644/1762] D loss: 1.4709, G loss: 0.5164\n",
      "[724/1762] D loss: 1.4278, G loss: 1.0930\n",
      "[804/1762] D loss: 1.4655, G loss: 0.4494\n",
      "[884/1762] D loss: 1.4033, G loss: 0.7082\n",
      "[964/1762] D loss: 1.3980, G loss: 0.8368\n",
      "[1044/1762] D loss: 1.3922, G loss: 0.5723\n",
      "[1124/1762] D loss: 1.0378, G loss: 1.0495\n",
      "[1204/1762] D loss: 1.4203, G loss: 0.6791\n",
      "[1284/1762] D loss: 1.3812, G loss: 0.7787\n",
      "[1364/1762] D loss: 1.4241, G loss: 0.5773\n",
      "[1444/1762] D loss: 1.4094, G loss: 0.6580\n",
      "[1524/1762] D loss: 1.3980, G loss: 0.6967\n",
      "[1604/1762] D loss: 1.1877, G loss: 1.0008\n",
      "[1684/1762] D loss: 1.4215, G loss: 0.7828\n",
      "[1762/1762] D loss: 1.3995, G loss: 0.6426\n",
      "train error: \n",
      " D loss: 1.341121, G loss: 0.685670, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 69.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328793, G loss: 0.691572, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4060, G loss: 0.7103\n",
      "[84/1762] D loss: 1.3740, G loss: 0.6957\n",
      "[164/1762] D loss: 1.3816, G loss: 0.7999\n",
      "[244/1762] D loss: 1.4050, G loss: 0.6906\n",
      "[324/1762] D loss: 1.4414, G loss: 0.8537\n",
      "[404/1762] D loss: 1.4221, G loss: 0.5972\n",
      "[484/1762] D loss: 0.9935, G loss: 0.9879\n",
      "[564/1762] D loss: 1.3991, G loss: 0.4985\n",
      "[644/1762] D loss: 1.3897, G loss: 0.7673\n",
      "[724/1762] D loss: 1.1968, G loss: 0.8737\n",
      "[804/1762] D loss: 1.3545, G loss: 0.6947\n",
      "[884/1762] D loss: 1.4062, G loss: 0.6064\n",
      "[964/1762] D loss: 1.4039, G loss: 0.6777\n",
      "[1044/1762] D loss: 1.3873, G loss: 1.0613\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.6717\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.7551\n",
      "[1284/1762] D loss: 1.2018, G loss: 0.7216\n",
      "[1364/1762] D loss: 1.3978, G loss: 0.9124\n",
      "[1444/1762] D loss: 1.4133, G loss: 0.6463\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.6899\n",
      "[1604/1762] D loss: 1.4234, G loss: 0.9078\n",
      "[1684/1762] D loss: 1.0084, G loss: 0.9178\n",
      "[1762/1762] D loss: 1.2670, G loss: 0.8768\n",
      "train error: \n",
      " D loss: 1.345933, G loss: 0.844771, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331230, G loss: 0.853041, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 65.2% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2631, G loss: 0.9071\n",
      "[84/1762] D loss: 1.3749, G loss: 0.6388\n",
      "[164/1762] D loss: 1.2315, G loss: 1.1457\n",
      "[244/1762] D loss: 1.0280, G loss: 1.0081\n",
      "[324/1762] D loss: 1.4121, G loss: 0.6601\n",
      "[404/1762] D loss: 1.4520, G loss: 0.5807\n",
      "[484/1762] D loss: 1.3995, G loss: 0.7513\n",
      "[564/1762] D loss: 1.2018, G loss: 0.9981\n",
      "[644/1762] D loss: 1.4507, G loss: 0.6066\n",
      "[724/1762] D loss: 1.3829, G loss: 0.7602\n",
      "[804/1762] D loss: 1.3963, G loss: 0.6926\n",
      "[884/1762] D loss: 1.3251, G loss: 0.6952\n",
      "[964/1762] D loss: 1.5500, G loss: 0.9120\n",
      "[1044/1762] D loss: 1.4436, G loss: 0.4736\n",
      "[1124/1762] D loss: 1.1932, G loss: 0.8101\n",
      "[1204/1762] D loss: 1.3330, G loss: 0.8447\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7124\n",
      "[1364/1762] D loss: 1.3495, G loss: 0.6630\n",
      "[1444/1762] D loss: 1.4407, G loss: 0.6978\n",
      "[1524/1762] D loss: 1.4271, G loss: 0.8794\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.6261\n",
      "[1684/1762] D loss: 1.3935, G loss: 0.7803\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.7143\n",
      "train error: \n",
      " D loss: 1.341959, G loss: 0.814118, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 73.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327180, G loss: 0.821018, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4548, G loss: 0.7870\n",
      "[84/1762] D loss: 1.3932, G loss: 0.6310\n",
      "[164/1762] D loss: 1.4038, G loss: 0.6747\n",
      "[244/1762] D loss: 1.2213, G loss: 0.6974\n",
      "[324/1762] D loss: 1.3789, G loss: 0.6536\n",
      "[404/1762] D loss: 1.3968, G loss: 0.5566\n",
      "[484/1762] D loss: 1.4255, G loss: 0.6720\n",
      "[564/1762] D loss: 1.2272, G loss: 0.7764\n",
      "[644/1762] D loss: 1.4098, G loss: 0.7469\n",
      "[724/1762] D loss: 1.4054, G loss: 0.7015\n",
      "[804/1762] D loss: 1.3980, G loss: 0.8209\n",
      "[884/1762] D loss: 1.4100, G loss: 0.5938\n",
      "[964/1762] D loss: 1.4180, G loss: 0.6418\n",
      "[1044/1762] D loss: 1.3584, G loss: 0.6981\n",
      "[1124/1762] D loss: 1.4270, G loss: 0.6334\n",
      "[1204/1762] D loss: 1.3464, G loss: 0.6960\n",
      "[1284/1762] D loss: 1.4227, G loss: 0.7634\n",
      "[1364/1762] D loss: 1.3599, G loss: 0.8327\n",
      "[1444/1762] D loss: 1.4316, G loss: 0.7765\n",
      "[1524/1762] D loss: 1.4060, G loss: 0.6730\n",
      "[1604/1762] D loss: 1.4477, G loss: 0.7666\n",
      "[1684/1762] D loss: 1.3720, G loss: 0.5874\n",
      "[1762/1762] D loss: 1.2256, G loss: 0.9245\n",
      "train error: \n",
      " D loss: 1.338052, G loss: 0.673466, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325584, G loss: 0.677520, D accuracy: 56.6%, cell accuracy: 99.5%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1891, G loss: 0.7763\n",
      "[84/1762] D loss: 1.4313, G loss: 0.5728\n",
      "[164/1762] D loss: 1.3857, G loss: 0.7041\n",
      "[244/1762] D loss: 1.2313, G loss: 0.9335\n",
      "[324/1762] D loss: 1.4392, G loss: 0.5808\n",
      "[404/1762] D loss: 1.2175, G loss: 0.9524\n",
      "[484/1762] D loss: 1.3897, G loss: 0.5353\n",
      "[564/1762] D loss: 1.3758, G loss: 0.6230\n",
      "[644/1762] D loss: 1.4053, G loss: 0.5624\n",
      "[724/1762] D loss: 1.4482, G loss: 0.5974\n",
      "[804/1762] D loss: 1.5818, G loss: 0.7338\n",
      "[884/1762] D loss: 1.3694, G loss: 0.6708\n",
      "[964/1762] D loss: 1.4372, G loss: 0.5342\n",
      "[1044/1762] D loss: 1.2094, G loss: 0.8107\n",
      "[1124/1762] D loss: 1.4047, G loss: 0.6642\n",
      "[1204/1762] D loss: 1.1815, G loss: 1.0900\n",
      "[1284/1762] D loss: 1.4109, G loss: 0.7641\n",
      "[1364/1762] D loss: 1.3657, G loss: 0.7402\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.7633\n",
      "[1524/1762] D loss: 1.4545, G loss: 0.6590\n",
      "[1604/1762] D loss: 1.2765, G loss: 0.6558\n",
      "[1684/1762] D loss: 1.4237, G loss: 0.8361\n",
      "[1762/1762] D loss: 1.2408, G loss: 0.7163\n",
      "train error: \n",
      " D loss: 1.403607, G loss: 0.505202, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 68.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395726, G loss: 0.508184, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 64.8% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4322, G loss: 0.4241\n",
      "[84/1762] D loss: 1.3660, G loss: 0.6993\n",
      "[164/1762] D loss: 1.3721, G loss: 0.7873\n",
      "[244/1762] D loss: 1.4137, G loss: 0.9483\n",
      "[324/1762] D loss: 1.4361, G loss: 0.8622\n",
      "[404/1762] D loss: 1.3801, G loss: 0.6013\n",
      "[484/1762] D loss: 1.1748, G loss: 0.8175\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6979\n",
      "[644/1762] D loss: 1.4084, G loss: 0.8265\n",
      "[724/1762] D loss: 1.4122, G loss: 0.7628\n",
      "[804/1762] D loss: 0.9645, G loss: 1.0555\n",
      "[884/1762] D loss: 1.3827, G loss: 0.7573\n",
      "[964/1762] D loss: 1.2687, G loss: 0.7989\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6850\n",
      "[1124/1762] D loss: 1.4144, G loss: 0.5662\n",
      "[1204/1762] D loss: 1.4114, G loss: 0.7644\n",
      "[1284/1762] D loss: 1.4092, G loss: 0.5628\n",
      "[1364/1762] D loss: 1.3522, G loss: 0.9085\n",
      "[1444/1762] D loss: 1.3475, G loss: 0.7345\n",
      "[1524/1762] D loss: 1.1774, G loss: 0.9885\n",
      "[1604/1762] D loss: 1.4910, G loss: 0.5019\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6860\n",
      "[1762/1762] D loss: 1.3562, G loss: 0.7263\n",
      "train error: \n",
      " D loss: 1.337707, G loss: 0.737279, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 69.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326019, G loss: 0.742928, D accuracy: 53.9%, cell accuracy: 99.6%, board accuracy: 65.7% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2134, G loss: 0.6958\n",
      "[84/1762] D loss: 1.4345, G loss: 0.6393\n",
      "[164/1762] D loss: 1.1563, G loss: 0.9253\n",
      "[244/1762] D loss: 1.3932, G loss: 0.6185\n",
      "[324/1762] D loss: 1.3901, G loss: 0.7547\n",
      "[404/1762] D loss: 1.4075, G loss: 0.7846\n",
      "[484/1762] D loss: 1.2127, G loss: 0.9376\n",
      "[564/1762] D loss: 1.2275, G loss: 0.6805\n",
      "[644/1762] D loss: 1.3446, G loss: 0.7671\n",
      "[724/1762] D loss: 1.3728, G loss: 0.6753\n",
      "[804/1762] D loss: 1.4038, G loss: 0.7022\n",
      "[884/1762] D loss: 1.7726, G loss: 0.5137\n",
      "[964/1762] D loss: 1.8337, G loss: 0.6889\n",
      "[1044/1762] D loss: 1.9616, G loss: 1.1442\n",
      "[1124/1762] D loss: 1.5729, G loss: 0.3085\n",
      "[1204/1762] D loss: 1.4935, G loss: 0.5855\n",
      "[1284/1762] D loss: 1.3761, G loss: 0.5673\n",
      "[1364/1762] D loss: 1.4711, G loss: 0.9637\n",
      "[1444/1762] D loss: 1.5405, G loss: 0.4112\n",
      "[1524/1762] D loss: 1.3718, G loss: 0.8252\n",
      "[1604/1762] D loss: 1.4453, G loss: 0.5465\n",
      "[1684/1762] D loss: 1.4047, G loss: 0.7369\n",
      "[1762/1762] D loss: 1.2425, G loss: 0.7504\n",
      "train error: \n",
      " D loss: 1.376015, G loss: 0.738163, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372008, G loss: 0.737048, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4079, G loss: 0.8907\n",
      "[84/1762] D loss: 1.3951, G loss: 0.7273\n",
      "[164/1762] D loss: 1.4249, G loss: 0.8326\n",
      "[244/1762] D loss: 1.4775, G loss: 0.8787\n",
      "[324/1762] D loss: 1.4168, G loss: 0.8226\n",
      "[404/1762] D loss: 1.3920, G loss: 0.6924\n",
      "[484/1762] D loss: 1.4278, G loss: 0.8579\n",
      "[564/1762] D loss: 1.4074, G loss: 0.8372\n",
      "[644/1762] D loss: 1.4039, G loss: 0.7207\n",
      "[724/1762] D loss: 1.3210, G loss: 0.8144\n",
      "[804/1762] D loss: 1.3937, G loss: 0.6066\n",
      "[884/1762] D loss: 1.3965, G loss: 0.7047\n",
      "[964/1762] D loss: 1.2753, G loss: 0.8383\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6345\n",
      "[1124/1762] D loss: 1.3997, G loss: 0.6803\n",
      "[1204/1762] D loss: 1.3757, G loss: 0.7216\n",
      "[1284/1762] D loss: 1.4113, G loss: 0.7824\n",
      "[1364/1762] D loss: 1.3843, G loss: 0.6903\n",
      "[1444/1762] D loss: 1.3639, G loss: 0.7732\n",
      "[1524/1762] D loss: 1.4365, G loss: 0.9022\n",
      "[1604/1762] D loss: 1.2413, G loss: 0.8583\n",
      "[1684/1762] D loss: 1.3995, G loss: 0.6289\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.8048\n",
      "train error: \n",
      " D loss: 1.357715, G loss: 0.828647, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 68.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346479, G loss: 0.830704, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 65.7% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4245, G loss: 0.8214\n",
      "[84/1762] D loss: 1.4566, G loss: 0.8526\n",
      "[164/1762] D loss: 1.3950, G loss: 0.6534\n",
      "[244/1762] D loss: 1.3593, G loss: 0.6599\n",
      "[324/1762] D loss: 1.3632, G loss: 0.7473\n",
      "[404/1762] D loss: 1.3939, G loss: 0.7186\n",
      "[484/1762] D loss: 1.2220, G loss: 0.8207\n",
      "[564/1762] D loss: 1.2300, G loss: 0.8613\n",
      "[644/1762] D loss: 1.4815, G loss: 0.7268\n",
      "[724/1762] D loss: 1.2719, G loss: 0.7575\n",
      "[804/1762] D loss: 1.3936, G loss: 0.6891\n",
      "[884/1762] D loss: 1.3993, G loss: 0.6702\n",
      "[964/1762] D loss: 1.3203, G loss: 0.7944\n",
      "[1044/1762] D loss: 1.2308, G loss: 0.8116\n",
      "[1124/1762] D loss: 1.4018, G loss: 0.6771\n",
      "[1204/1762] D loss: 1.4118, G loss: 0.6844\n",
      "[1284/1762] D loss: 1.3731, G loss: 0.7140\n",
      "[1364/1762] D loss: 1.4254, G loss: 0.6845\n",
      "[1444/1762] D loss: 1.2596, G loss: 0.7692\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.7760\n",
      "[1604/1762] D loss: 1.3562, G loss: 0.7242\n",
      "[1684/1762] D loss: 1.3913, G loss: 0.8723\n",
      "[1762/1762] D loss: 1.3391, G loss: 0.6642\n",
      "train error: \n",
      " D loss: 1.351862, G loss: 0.708479, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346078, G loss: 0.716600, D accuracy: 56.4%, cell accuracy: 99.5%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2734, G loss: 0.7345\n",
      "[84/1762] D loss: 1.3733, G loss: 0.7191\n",
      "[164/1762] D loss: 1.3654, G loss: 0.7242\n",
      "[244/1762] D loss: 1.2187, G loss: 0.8991\n",
      "[324/1762] D loss: 1.3415, G loss: 0.8131\n",
      "[404/1762] D loss: 1.3911, G loss: 0.5804\n",
      "[484/1762] D loss: 1.3655, G loss: 0.7834\n",
      "[564/1762] D loss: 1.3547, G loss: 0.6835\n",
      "[644/1762] D loss: 1.3014, G loss: 0.9396\n",
      "[724/1762] D loss: 1.2635, G loss: 0.6703\n",
      "[804/1762] D loss: 1.4009, G loss: 0.5914\n",
      "[884/1762] D loss: 1.3806, G loss: 0.7200\n",
      "[964/1762] D loss: 1.3895, G loss: 0.6337\n",
      "[1044/1762] D loss: 1.3960, G loss: 0.7354\n",
      "[1124/1762] D loss: 1.3736, G loss: 0.7710\n",
      "[1204/1762] D loss: 1.2293, G loss: 0.9041\n",
      "[1284/1762] D loss: 1.2487, G loss: 0.7685\n",
      "[1364/1762] D loss: 1.4180, G loss: 0.8264\n",
      "[1444/1762] D loss: 1.3973, G loss: 0.7849\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6826\n",
      "[1604/1762] D loss: 1.3992, G loss: 0.8237\n",
      "[1684/1762] D loss: 1.2120, G loss: 0.8021\n",
      "[1762/1762] D loss: 1.4227, G loss: 0.7030\n",
      "train error: \n",
      " D loss: 1.352258, G loss: 0.726686, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 68.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341605, G loss: 0.728146, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4040, G loss: 0.7147\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6057\n",
      "[164/1762] D loss: 1.4498, G loss: 0.5521\n",
      "[244/1762] D loss: 1.2881, G loss: 0.7246\n",
      "[324/1762] D loss: 1.3984, G loss: 0.7389\n",
      "[404/1762] D loss: 1.3603, G loss: 0.7131\n",
      "[484/1762] D loss: 1.3895, G loss: 0.7783\n",
      "[564/1762] D loss: 1.4952, G loss: 0.5971\n",
      "[644/1762] D loss: 1.3690, G loss: 0.7219\n",
      "[724/1762] D loss: 2.2143, G loss: 0.3825\n",
      "[804/1762] D loss: 1.4447, G loss: 0.5890\n",
      "[884/1762] D loss: 1.2249, G loss: 0.9923\n",
      "[964/1762] D loss: 1.5049, G loss: 0.9128\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.9933\n",
      "[1124/1762] D loss: 1.5003, G loss: 0.7009\n",
      "[1204/1762] D loss: 1.5022, G loss: 0.7299\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.5863\n",
      "[1364/1762] D loss: 1.4405, G loss: 0.6213\n",
      "[1444/1762] D loss: 1.3779, G loss: 0.7659\n",
      "[1524/1762] D loss: 1.3531, G loss: 0.6894\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.6794\n",
      "[1684/1762] D loss: 1.3966, G loss: 0.7381\n",
      "[1762/1762] D loss: 1.3927, G loss: 0.7045\n",
      "train error: \n",
      " D loss: 1.370741, G loss: 0.754687, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 66.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362895, G loss: 0.765688, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3780, G loss: 0.8829\n",
      "[84/1762] D loss: 1.3837, G loss: 0.7347\n",
      "[164/1762] D loss: 1.1269, G loss: 0.8409\n",
      "[244/1762] D loss: 1.3740, G loss: 0.7020\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[404/1762] D loss: 1.4288, G loss: 0.6136\n",
      "[484/1762] D loss: 1.3009, G loss: 0.8495\n",
      "[564/1762] D loss: 1.3492, G loss: 0.7911\n",
      "[644/1762] D loss: 1.4294, G loss: 0.7289\n",
      "[724/1762] D loss: 1.4135, G loss: 0.5889\n",
      "[804/1762] D loss: 1.3390, G loss: 0.6986\n",
      "[884/1762] D loss: 1.3915, G loss: 0.6797\n",
      "[964/1762] D loss: 1.4096, G loss: 0.7199\n",
      "[1044/1762] D loss: 1.3806, G loss: 0.6702\n",
      "[1124/1762] D loss: 1.3949, G loss: 0.6144\n",
      "[1204/1762] D loss: 1.3643, G loss: 0.6991\n",
      "[1284/1762] D loss: 1.4212, G loss: 0.7973\n",
      "[1364/1762] D loss: 1.2761, G loss: 0.7262\n",
      "[1444/1762] D loss: 1.3823, G loss: 0.7769\n",
      "[1524/1762] D loss: 1.2373, G loss: 0.7994\n",
      "[1604/1762] D loss: 1.3724, G loss: 0.7575\n",
      "[1684/1762] D loss: 1.3143, G loss: 0.7144\n",
      "[1762/1762] D loss: 1.0605, G loss: 0.8716\n",
      "train error: \n",
      " D loss: 1.345711, G loss: 0.739333, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 69.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337185, G loss: 0.741856, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 66.1% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7196\n",
      "[84/1762] D loss: 1.3995, G loss: 0.6925\n",
      "[164/1762] D loss: 1.4042, G loss: 0.6889\n",
      "[244/1762] D loss: 1.2417, G loss: 0.7125\n",
      "[324/1762] D loss: 1.3956, G loss: 0.7172\n",
      "[404/1762] D loss: 1.4351, G loss: 0.6267\n",
      "[484/1762] D loss: 1.3799, G loss: 0.7050\n",
      "[564/1762] D loss: 1.4378, G loss: 0.7554\n",
      "[644/1762] D loss: 1.3702, G loss: 0.6619\n",
      "[724/1762] D loss: 1.4176, G loss: 0.6119\n",
      "[804/1762] D loss: 1.3967, G loss: 0.6780\n",
      "[884/1762] D loss: 1.2061, G loss: 0.7929\n",
      "[964/1762] D loss: 1.4603, G loss: 0.7583\n",
      "[1044/1762] D loss: 1.2065, G loss: 0.9640\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.5873\n",
      "[1204/1762] D loss: 1.3631, G loss: 0.7456\n",
      "[1284/1762] D loss: 1.4091, G loss: 0.6166\n",
      "[1364/1762] D loss: 1.2341, G loss: 0.8173\n",
      "[1444/1762] D loss: 1.1869, G loss: 0.6902\n",
      "[1524/1762] D loss: 1.4567, G loss: 0.7816\n",
      "[1604/1762] D loss: 1.4207, G loss: 0.6443\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.7117\n",
      "[1762/1762] D loss: 1.3840, G loss: 0.7924\n",
      "train error: \n",
      " D loss: 1.342732, G loss: 0.780740, D accuracy: 53.7%, cell accuracy: 99.6%, board accuracy: 64.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328661, G loss: 0.786299, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 63.2% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3808, G loss: 0.7592\n",
      "[84/1762] D loss: 1.4223, G loss: 0.8173\n",
      "[164/1762] D loss: 1.4060, G loss: 0.5553\n",
      "[244/1762] D loss: 1.4239, G loss: 0.7937\n",
      "[324/1762] D loss: 1.3772, G loss: 0.6616\n",
      "[404/1762] D loss: 1.3931, G loss: 0.6982\n",
      "[484/1762] D loss: 1.3856, G loss: 0.7488\n",
      "[564/1762] D loss: 1.4003, G loss: 0.7322\n",
      "[644/1762] D loss: 1.0309, G loss: 0.8036\n",
      "[724/1762] D loss: 1.3976, G loss: 0.6378\n",
      "[804/1762] D loss: 1.4016, G loss: 0.7151\n",
      "[884/1762] D loss: 1.3764, G loss: 0.8110\n",
      "[964/1762] D loss: 1.2251, G loss: 0.6160\n",
      "[1044/1762] D loss: 1.4057, G loss: 0.6647\n",
      "[1124/1762] D loss: 1.3825, G loss: 0.7159\n",
      "[1204/1762] D loss: 1.2298, G loss: 0.6887\n",
      "[1284/1762] D loss: 1.4088, G loss: 0.8490\n",
      "[1364/1762] D loss: 1.4870, G loss: 0.4967\n",
      "[1444/1762] D loss: 1.3604, G loss: 0.7990\n",
      "[1524/1762] D loss: 1.4208, G loss: 0.5528\n",
      "[1604/1762] D loss: 1.1989, G loss: 0.9796\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6545\n",
      "[1762/1762] D loss: 1.3928, G loss: 0.7433\n",
      "train error: \n",
      " D loss: 1.329739, G loss: 0.803730, D accuracy: 55.9%, cell accuracy: 99.5%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311331, G loss: 0.814443, D accuracy: 57.8%, cell accuracy: 99.4%, board accuracy: 55.9% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2847, G loss: 0.8375\n",
      "[84/1762] D loss: 1.4225, G loss: 0.7083\n",
      "[164/1762] D loss: 1.3622, G loss: 0.7482\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6269\n",
      "[324/1762] D loss: 1.3916, G loss: 0.6543\n",
      "[404/1762] D loss: 1.4276, G loss: 0.6237\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6865\n",
      "[564/1762] D loss: 1.5909, G loss: 0.5572\n",
      "[644/1762] D loss: 1.5567, G loss: 0.6047\n",
      "[724/1762] D loss: 1.6054, G loss: 0.9686\n",
      "[804/1762] D loss: 1.2981, G loss: 0.6958\n",
      "[884/1762] D loss: 1.3786, G loss: 0.6282\n",
      "[964/1762] D loss: 1.4273, G loss: 0.7380\n",
      "[1044/1762] D loss: 1.5097, G loss: 0.5127\n",
      "[1124/1762] D loss: 1.4909, G loss: 0.5560\n",
      "[1204/1762] D loss: 1.4856, G loss: 0.8763\n",
      "[1284/1762] D loss: 1.5523, G loss: 0.9463\n",
      "[1364/1762] D loss: 1.3971, G loss: 0.5999\n",
      "[1444/1762] D loss: 1.4119, G loss: 0.7797\n",
      "[1524/1762] D loss: 1.4065, G loss: 0.6363\n",
      "[1604/1762] D loss: 1.4100, G loss: 0.8666\n",
      "[1684/1762] D loss: 1.3340, G loss: 0.7243\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.6517\n",
      "train error: \n",
      " D loss: 1.377138, G loss: 0.639823, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 64.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374890, G loss: 0.639243, D accuracy: 52.4%, cell accuracy: 99.6%, board accuracy: 63.9% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.6141\n",
      "[84/1762] D loss: 1.3873, G loss: 0.7705\n",
      "[164/1762] D loss: 1.3835, G loss: 0.7198\n",
      "[244/1762] D loss: 1.4096, G loss: 0.7927\n",
      "[324/1762] D loss: 1.3920, G loss: 0.7349\n",
      "[404/1762] D loss: 1.3976, G loss: 0.6424\n",
      "[484/1762] D loss: 1.3926, G loss: 0.5997\n",
      "[564/1762] D loss: 1.2238, G loss: 0.7804\n",
      "[644/1762] D loss: 1.3936, G loss: 0.6449\n",
      "[724/1762] D loss: 1.2945, G loss: 0.6997\n",
      "[804/1762] D loss: 1.1729, G loss: 0.7877\n",
      "[884/1762] D loss: 1.3918, G loss: 0.6759\n",
      "[964/1762] D loss: 1.3011, G loss: 0.6740\n",
      "[1044/1762] D loss: 1.4004, G loss: 0.7992\n",
      "[1124/1762] D loss: 1.3604, G loss: 0.7018\n",
      "[1204/1762] D loss: 1.3911, G loss: 0.7618\n",
      "[1284/1762] D loss: 1.3840, G loss: 0.6990\n",
      "[1364/1762] D loss: 1.4241, G loss: 0.6244\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.7187\n",
      "[1524/1762] D loss: 1.3795, G loss: 0.6712\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.6629\n",
      "[1684/1762] D loss: 1.3983, G loss: 0.5661\n",
      "[1762/1762] D loss: 1.4043, G loss: 0.6361\n",
      "train error: \n",
      " D loss: 1.369621, G loss: 0.597885, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362258, G loss: 0.599255, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3998, G loss: 0.6883\n",
      "[84/1762] D loss: 1.4013, G loss: 0.8258\n",
      "[164/1762] D loss: 1.4096, G loss: 0.8035\n",
      "[244/1762] D loss: 1.4126, G loss: 0.6038\n",
      "[324/1762] D loss: 1.4077, G loss: 0.7292\n",
      "[404/1762] D loss: 1.2333, G loss: 0.7089\n",
      "[484/1762] D loss: 1.2146, G loss: 0.8503\n",
      "[564/1762] D loss: 1.4196, G loss: 0.7499\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7535\n",
      "[724/1762] D loss: 1.3995, G loss: 0.6666\n",
      "[804/1762] D loss: 1.3385, G loss: 0.7251\n",
      "[884/1762] D loss: 1.2308, G loss: 0.7578\n",
      "[964/1762] D loss: 1.3758, G loss: 0.6970\n",
      "[1044/1762] D loss: 1.2567, G loss: 0.8975\n",
      "[1124/1762] D loss: 1.3525, G loss: 0.6556\n",
      "[1204/1762] D loss: 1.3477, G loss: 0.7742\n",
      "[1284/1762] D loss: 1.3025, G loss: 0.8450\n",
      "[1364/1762] D loss: 1.4054, G loss: 0.5641\n",
      "[1444/1762] D loss: 1.3479, G loss: 0.6888\n",
      "[1524/1762] D loss: 1.3594, G loss: 0.6820\n",
      "[1604/1762] D loss: 1.4053, G loss: 0.7487\n",
      "[1684/1762] D loss: 1.4228, G loss: 0.6321\n",
      "[1762/1762] D loss: 1.4215, G loss: 0.6353\n",
      "train error: \n",
      " D loss: 1.342418, G loss: 0.743433, D accuracy: 54.9%, cell accuracy: 99.5%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329906, G loss: 0.752427, D accuracy: 56.1%, cell accuracy: 99.5%, board accuracy: 56.6% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3383, G loss: 0.6955\n",
      "[84/1762] D loss: 1.3780, G loss: 0.7174\n",
      "[164/1762] D loss: 1.3970, G loss: 0.6692\n",
      "[244/1762] D loss: 1.3892, G loss: 0.6739\n",
      "[324/1762] D loss: 1.3842, G loss: 0.5895\n",
      "[404/1762] D loss: 1.3814, G loss: 0.7654\n",
      "[484/1762] D loss: 1.3605, G loss: 0.6352\n",
      "[564/1762] D loss: 1.3909, G loss: 0.7320\n",
      "[644/1762] D loss: 1.4158, G loss: 0.8120\n",
      "[724/1762] D loss: 1.3961, G loss: 0.5846\n",
      "[804/1762] D loss: 1.3997, G loss: 0.7350\n",
      "[884/1762] D loss: 1.2016, G loss: 0.7308\n",
      "[964/1762] D loss: 1.3881, G loss: 0.7688\n",
      "[1044/1762] D loss: 1.2434, G loss: 0.8729\n",
      "[1124/1762] D loss: 1.3956, G loss: 0.7717\n",
      "[1204/1762] D loss: 1.3819, G loss: 0.6776\n",
      "[1284/1762] D loss: 1.3855, G loss: 0.6714\n",
      "[1364/1762] D loss: 1.4165, G loss: 0.5396\n",
      "[1444/1762] D loss: 1.2237, G loss: 0.7932\n",
      "[1524/1762] D loss: 1.4219, G loss: 0.8420\n",
      "[1604/1762] D loss: 1.4044, G loss: 0.6398\n",
      "[1684/1762] D loss: 1.3828, G loss: 0.5928\n",
      "[1762/1762] D loss: 1.4123, G loss: 0.7385\n",
      "train error: \n",
      " D loss: 1.348323, G loss: 0.750443, D accuracy: 53.2%, cell accuracy: 99.5%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335558, G loss: 0.750307, D accuracy: 54.0%, cell accuracy: 99.5%, board accuracy: 48.9% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4073, G loss: 0.7219\n",
      "[84/1762] D loss: 1.2281, G loss: 0.6642\n",
      "[164/1762] D loss: 1.3135, G loss: 0.6281\n",
      "[244/1762] D loss: 1.3952, G loss: 0.6499\n",
      "[324/1762] D loss: 1.3954, G loss: 0.6199\n",
      "[404/1762] D loss: 1.2094, G loss: 0.8447\n",
      "[484/1762] D loss: 1.3936, G loss: 0.6207\n",
      "[564/1762] D loss: 1.4125, G loss: 0.8309\n",
      "[644/1762] D loss: 1.4036, G loss: 0.5907\n",
      "[724/1762] D loss: 1.3674, G loss: 0.7902\n",
      "[804/1762] D loss: 1.4051, G loss: 0.6692\n",
      "[884/1762] D loss: 1.3999, G loss: 0.7273\n",
      "[964/1762] D loss: 1.3717, G loss: 0.7852\n",
      "[1044/1762] D loss: 1.4134, G loss: 0.6159\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7267\n",
      "[1204/1762] D loss: 1.1975, G loss: 0.7694\n",
      "[1284/1762] D loss: 1.3916, G loss: 0.9052\n",
      "[1364/1762] D loss: 1.3973, G loss: 0.7321\n",
      "[1444/1762] D loss: 1.5286, G loss: 0.8934\n",
      "[1524/1762] D loss: 1.2389, G loss: 0.6426\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.9031\n",
      "[1684/1762] D loss: 1.5187, G loss: 1.1596\n",
      "[1762/1762] D loss: 1.5256, G loss: 0.4869\n",
      "train error: \n",
      " D loss: 1.439177, G loss: 0.682442, D accuracy: 49.8%, cell accuracy: 99.7%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.442143, G loss: 0.690022, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 64.1% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4377, G loss: 0.7132\n",
      "[84/1762] D loss: 1.3931, G loss: 0.6960\n",
      "[164/1762] D loss: 1.4194, G loss: 0.7983\n",
      "[244/1762] D loss: 1.3967, G loss: 0.7614\n",
      "[324/1762] D loss: 1.3698, G loss: 0.7836\n",
      "[404/1762] D loss: 1.4347, G loss: 0.5909\n",
      "[484/1762] D loss: 1.2956, G loss: 0.6794\n",
      "[564/1762] D loss: 1.2681, G loss: 0.7859\n",
      "[644/1762] D loss: 1.2984, G loss: 0.7508\n",
      "[724/1762] D loss: 1.3819, G loss: 0.7698\n",
      "[804/1762] D loss: 1.4037, G loss: 0.7194\n",
      "[884/1762] D loss: 1.2741, G loss: 0.6280\n",
      "[964/1762] D loss: 1.2745, G loss: 0.7399\n",
      "[1044/1762] D loss: 1.2842, G loss: 0.6967\n",
      "[1124/1762] D loss: 1.3979, G loss: 0.6578\n",
      "[1204/1762] D loss: 1.3999, G loss: 0.5638\n",
      "[1284/1762] D loss: 1.3977, G loss: 0.8310\n",
      "[1364/1762] D loss: 1.0817, G loss: 0.8374\n",
      "[1444/1762] D loss: 1.3427, G loss: 0.7277\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.7413\n",
      "[1604/1762] D loss: 1.3941, G loss: 0.6881\n",
      "[1684/1762] D loss: 1.1917, G loss: 0.7521\n",
      "[1762/1762] D loss: 1.3966, G loss: 0.7481\n",
      "train error: \n",
      " D loss: 1.346928, G loss: 0.809437, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 65.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335836, G loss: 0.807889, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 65.2% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3974, G loss: 0.7268\n",
      "[84/1762] D loss: 1.3935, G loss: 0.6641\n",
      "[164/1762] D loss: 1.3763, G loss: 0.7689\n",
      "[244/1762] D loss: 1.2206, G loss: 0.7595\n",
      "[324/1762] D loss: 1.3897, G loss: 0.6579\n",
      "[404/1762] D loss: 1.3757, G loss: 0.6173\n",
      "[484/1762] D loss: 1.3930, G loss: 0.7423\n",
      "[564/1762] D loss: 1.2920, G loss: 0.7993\n",
      "[644/1762] D loss: 1.3279, G loss: 0.7541\n",
      "[724/1762] D loss: 1.3887, G loss: 0.7967\n",
      "[804/1762] D loss: 1.3930, G loss: 0.7657\n",
      "[884/1762] D loss: 1.2209, G loss: 0.8548\n",
      "[964/1762] D loss: 1.4094, G loss: 0.6018\n",
      "[1044/1762] D loss: 1.3994, G loss: 0.6972\n",
      "[1124/1762] D loss: 1.4380, G loss: 0.8438\n",
      "[1204/1762] D loss: 1.3994, G loss: 0.7106\n",
      "[1284/1762] D loss: 1.3894, G loss: 0.6672\n",
      "[1364/1762] D loss: 1.4000, G loss: 0.7795\n",
      "[1444/1762] D loss: 1.3614, G loss: 0.7083\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.6326\n",
      "[1604/1762] D loss: 1.1953, G loss: 0.8821\n",
      "[1684/1762] D loss: 1.1892, G loss: 0.9381\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.5327\n",
      "train error: \n",
      " D loss: 1.388561, G loss: 0.538235, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381897, G loss: 0.539299, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4947, G loss: 0.4717\n",
      "[84/1762] D loss: 1.3888, G loss: 0.7802\n",
      "[164/1762] D loss: 1.4087, G loss: 0.6837\n",
      "[244/1762] D loss: 1.3908, G loss: 0.6714\n",
      "[324/1762] D loss: 1.3887, G loss: 0.7420\n",
      "[404/1762] D loss: 1.1975, G loss: 0.7772\n",
      "[484/1762] D loss: 1.3804, G loss: 0.6802\n",
      "[564/1762] D loss: 1.2451, G loss: 0.8677\n",
      "[644/1762] D loss: 1.3954, G loss: 0.6351\n",
      "[724/1762] D loss: 1.4139, G loss: 0.7931\n",
      "[804/1762] D loss: 1.1430, G loss: 0.7839\n",
      "[884/1762] D loss: 1.3689, G loss: 0.8331\n",
      "[964/1762] D loss: 1.3892, G loss: 0.6984\n",
      "[1044/1762] D loss: 1.4081, G loss: 0.6550\n",
      "[1124/1762] D loss: 1.4266, G loss: 0.7907\n",
      "[1204/1762] D loss: 1.2249, G loss: 0.8769\n",
      "[1284/1762] D loss: 1.2547, G loss: 0.6992\n",
      "[1364/1762] D loss: 1.4078, G loss: 0.7762\n",
      "[1444/1762] D loss: 1.4026, G loss: 0.5993\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.6618\n",
      "[1604/1762] D loss: 1.4062, G loss: 0.7354\n",
      "[1684/1762] D loss: 1.4817, G loss: 0.9506\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6290\n",
      "train error: \n",
      " D loss: 1.347382, G loss: 0.712909, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 70.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335078, G loss: 0.720221, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4413, G loss: 0.6269\n",
      "[84/1762] D loss: 1.4040, G loss: 0.5295\n",
      "[164/1762] D loss: 1.4295, G loss: 0.9101\n",
      "[244/1762] D loss: 1.3472, G loss: 0.7692\n",
      "[324/1762] D loss: 1.4249, G loss: 0.5554\n",
      "[404/1762] D loss: 1.5223, G loss: 0.4964\n",
      "[484/1762] D loss: 1.3982, G loss: 0.9165\n",
      "[564/1762] D loss: 1.2049, G loss: 0.9095\n",
      "[644/1762] D loss: 2.0470, G loss: 0.3625\n",
      "[724/1762] D loss: 1.5520, G loss: 0.5345\n",
      "[804/1762] D loss: 1.1448, G loss: 0.9124\n",
      "[884/1762] D loss: 0.7068, G loss: 1.3661\n",
      "[964/1762] D loss: 1.7224, G loss: 1.0919\n",
      "[1044/1762] D loss: 1.5967, G loss: 0.3906\n",
      "[1124/1762] D loss: 1.6038, G loss: 0.2438\n",
      "[1204/1762] D loss: 1.5507, G loss: 0.4449\n",
      "[1284/1762] D loss: 1.4458, G loss: 0.8900\n",
      "[1364/1762] D loss: 1.4436, G loss: 0.7447\n",
      "[1444/1762] D loss: 1.4917, G loss: 0.6075\n",
      "[1524/1762] D loss: 1.3951, G loss: 0.6539\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.6582\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.8383\n",
      "[1762/1762] D loss: 1.4322, G loss: 0.7097\n",
      "train error: \n",
      " D loss: 1.388239, G loss: 0.658702, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 68.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387960, G loss: 0.666454, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 69.5% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4262, G loss: 0.5577\n",
      "[84/1762] D loss: 1.4062, G loss: 0.6909\n",
      "[164/1762] D loss: 1.4209, G loss: 0.6455\n",
      "[244/1762] D loss: 1.4027, G loss: 0.8700\n",
      "[324/1762] D loss: 1.3987, G loss: 0.7538\n",
      "[404/1762] D loss: 1.3696, G loss: 0.7739\n",
      "[484/1762] D loss: 1.4250, G loss: 0.7373\n",
      "[564/1762] D loss: 1.3920, G loss: 0.7766\n",
      "[644/1762] D loss: 1.3600, G loss: 0.6569\n",
      "[724/1762] D loss: 1.3899, G loss: 0.7601\n",
      "[804/1762] D loss: 1.4093, G loss: 0.6264\n",
      "[884/1762] D loss: 1.3634, G loss: 0.7050\n",
      "[964/1762] D loss: 1.3636, G loss: 0.7837\n",
      "[1044/1762] D loss: 1.3802, G loss: 0.7515\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.6567\n",
      "[1204/1762] D loss: 1.4319, G loss: 0.6565\n",
      "[1284/1762] D loss: 1.3921, G loss: 0.6920\n",
      "[1364/1762] D loss: 1.3750, G loss: 0.7060\n",
      "[1444/1762] D loss: 1.3537, G loss: 0.7955\n",
      "[1524/1762] D loss: 1.3850, G loss: 0.6884\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6926\n",
      "[1684/1762] D loss: 1.3539, G loss: 0.7350\n",
      "[1762/1762] D loss: 1.4009, G loss: 0.7532\n",
      "train error: \n",
      " D loss: 1.354807, G loss: 0.756799, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347104, G loss: 0.760291, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4213, G loss: 0.6712\n",
      "[84/1762] D loss: 1.3831, G loss: 0.6730\n",
      "[164/1762] D loss: 1.3826, G loss: 0.7264\n",
      "[244/1762] D loss: 1.3956, G loss: 0.7072\n",
      "[324/1762] D loss: 1.3613, G loss: 0.7090\n",
      "[404/1762] D loss: 1.2651, G loss: 0.6798\n",
      "[484/1762] D loss: 1.2603, G loss: 0.8000\n",
      "[564/1762] D loss: 1.4115, G loss: 0.7592\n",
      "[644/1762] D loss: 1.3965, G loss: 0.7481\n",
      "[724/1762] D loss: 1.3858, G loss: 0.8085\n",
      "[804/1762] D loss: 1.3636, G loss: 0.8012\n",
      "[884/1762] D loss: 1.2421, G loss: 0.7667\n",
      "[964/1762] D loss: 1.2316, G loss: 0.7225\n",
      "[1044/1762] D loss: 1.2223, G loss: 0.7339\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.7161\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6708\n",
      "[1284/1762] D loss: 1.4018, G loss: 0.7495\n",
      "[1364/1762] D loss: 1.3994, G loss: 0.8327\n",
      "[1444/1762] D loss: 1.4193, G loss: 0.5940\n",
      "[1524/1762] D loss: 1.3999, G loss: 0.6000\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.7327\n",
      "[1684/1762] D loss: 1.4014, G loss: 0.6857\n",
      "[1762/1762] D loss: 1.3723, G loss: 0.6091\n",
      "train error: \n",
      " D loss: 1.363364, G loss: 0.597278, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 77.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355921, G loss: 0.598446, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1797, G loss: 0.7413\n",
      "[84/1762] D loss: 1.2450, G loss: 0.7596\n",
      "[164/1762] D loss: 1.2030, G loss: 0.8872\n",
      "[244/1762] D loss: 1.3971, G loss: 0.5974\n",
      "[324/1762] D loss: 1.3852, G loss: 0.7994\n",
      "[404/1762] D loss: 1.4018, G loss: 0.7725\n",
      "[484/1762] D loss: 1.4145, G loss: 0.7025\n",
      "[564/1762] D loss: 1.4204, G loss: 0.6940\n",
      "[644/1762] D loss: 1.2345, G loss: 0.7387\n",
      "[724/1762] D loss: 1.4037, G loss: 0.6163\n",
      "[804/1762] D loss: 1.2244, G loss: 0.7521\n",
      "[884/1762] D loss: 1.3922, G loss: 0.6385\n",
      "[964/1762] D loss: 1.3958, G loss: 0.7059\n",
      "[1044/1762] D loss: 1.2016, G loss: 0.8513\n",
      "[1124/1762] D loss: 1.3909, G loss: 0.7113\n",
      "[1204/1762] D loss: 1.2222, G loss: 0.7447\n",
      "[1284/1762] D loss: 1.4265, G loss: 0.8986\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.7272\n",
      "[1444/1762] D loss: 1.4214, G loss: 0.7452\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.6023\n",
      "[1604/1762] D loss: 1.4065, G loss: 0.6217\n",
      "[1684/1762] D loss: 1.2367, G loss: 0.8397\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6695\n",
      "train error: \n",
      " D loss: 1.347882, G loss: 0.644219, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339287, G loss: 0.644605, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4076, G loss: 0.5864\n",
      "[84/1762] D loss: 1.3919, G loss: 0.7312\n",
      "[164/1762] D loss: 1.0476, G loss: 0.9213\n",
      "[244/1762] D loss: 1.3964, G loss: 0.6998\n",
      "[324/1762] D loss: 1.3957, G loss: 0.7167\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7771\n",
      "[484/1762] D loss: 1.3529, G loss: 0.7421\n",
      "[564/1762] D loss: 1.3667, G loss: 0.7340\n",
      "[644/1762] D loss: 1.4084, G loss: 0.6802\n",
      "[724/1762] D loss: 1.4242, G loss: 0.6039\n",
      "[804/1762] D loss: 1.1664, G loss: 0.7394\n",
      "[884/1762] D loss: 1.2210, G loss: 0.7463\n",
      "[964/1762] D loss: 1.2265, G loss: 0.9013\n",
      "[1044/1762] D loss: 1.4148, G loss: 0.8486\n",
      "[1124/1762] D loss: 1.3977, G loss: 0.7167\n",
      "[1204/1762] D loss: 1.1765, G loss: 0.8944\n",
      "[1284/1762] D loss: 1.0121, G loss: 0.9066\n",
      "[1364/1762] D loss: 1.3762, G loss: 0.6583\n",
      "[1444/1762] D loss: 1.3903, G loss: 0.7568\n",
      "[1524/1762] D loss: 1.3847, G loss: 0.7442\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.6450\n",
      "[1684/1762] D loss: 1.3918, G loss: 0.6501\n",
      "[1762/1762] D loss: 1.3998, G loss: 0.6880\n",
      "train error: \n",
      " D loss: 1.333556, G loss: 0.731100, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321914, G loss: 0.730954, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4003, G loss: 0.6592\n",
      "[84/1762] D loss: 1.2051, G loss: 0.7342\n",
      "[164/1762] D loss: 1.3927, G loss: 0.6888\n",
      "[244/1762] D loss: 1.3944, G loss: 0.7115\n",
      "[324/1762] D loss: 1.4280, G loss: 0.7326\n",
      "[404/1762] D loss: 1.3972, G loss: 0.7214\n",
      "[484/1762] D loss: 1.1714, G loss: 0.8120\n",
      "[564/1762] D loss: 1.3702, G loss: 0.6223\n",
      "[644/1762] D loss: 1.3921, G loss: 0.6785\n",
      "[724/1762] D loss: 1.4017, G loss: 0.5272\n",
      "[804/1762] D loss: 1.3905, G loss: 0.6904\n",
      "[884/1762] D loss: 1.4033, G loss: 0.8691\n",
      "[964/1762] D loss: 1.3895, G loss: 0.6159\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.7145\n",
      "[1124/1762] D loss: 1.4580, G loss: 0.7160\n",
      "[1204/1762] D loss: 2.4596, G loss: 0.2823\n",
      "[1284/1762] D loss: 1.5491, G loss: 0.9167\n",
      "[1364/1762] D loss: 1.7378, G loss: 0.3531\n",
      "[1444/1762] D loss: 1.4953, G loss: 0.7601\n",
      "[1524/1762] D loss: 1.4219, G loss: 0.5868\n",
      "[1604/1762] D loss: 1.4011, G loss: 0.7853\n",
      "[1684/1762] D loss: 1.4411, G loss: 0.6142\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.8737\n",
      "train error: \n",
      " D loss: 1.434501, G loss: 0.920595, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 71.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.439717, G loss: 0.923947, D accuracy: 50.9%, cell accuracy: 99.6%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4338, G loss: 0.9368\n",
      "[84/1762] D loss: 1.3742, G loss: 0.7080\n",
      "[164/1762] D loss: 1.4049, G loss: 0.8929\n",
      "[244/1762] D loss: 1.4175, G loss: 0.6974\n",
      "[324/1762] D loss: 1.4025, G loss: 0.6135\n",
      "[404/1762] D loss: 1.3912, G loss: 0.7311\n",
      "[484/1762] D loss: 1.3681, G loss: 0.6405\n",
      "[564/1762] D loss: 1.3973, G loss: 0.7195\n",
      "[644/1762] D loss: 1.3929, G loss: 0.7441\n",
      "[724/1762] D loss: 1.3883, G loss: 0.7099\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6926\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6921\n",
      "[964/1762] D loss: 1.1383, G loss: 0.8591\n",
      "[1044/1762] D loss: 1.3795, G loss: 0.7294\n",
      "[1124/1762] D loss: 1.3407, G loss: 0.6297\n",
      "[1204/1762] D loss: 1.3570, G loss: 0.6916\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7651\n",
      "[1364/1762] D loss: 1.2584, G loss: 0.7522\n",
      "[1444/1762] D loss: 1.4202, G loss: 0.5952\n",
      "[1524/1762] D loss: 1.3930, G loss: 0.6858\n",
      "[1604/1762] D loss: 1.2332, G loss: 0.7873\n",
      "[1684/1762] D loss: 1.4158, G loss: 0.7242\n",
      "[1762/1762] D loss: 1.4071, G loss: 0.6120\n",
      "train error: \n",
      " D loss: 1.350078, G loss: 0.679531, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 76.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341519, G loss: 0.680774, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3936, G loss: 0.6938\n",
      "[84/1762] D loss: 1.3916, G loss: 0.6523\n",
      "[164/1762] D loss: 1.2256, G loss: 0.7833\n",
      "[244/1762] D loss: 1.4001, G loss: 0.7088\n",
      "[324/1762] D loss: 1.4000, G loss: 0.7932\n",
      "[404/1762] D loss: 1.2220, G loss: 0.7794\n",
      "[484/1762] D loss: 1.3903, G loss: 0.7178\n",
      "[564/1762] D loss: 1.4042, G loss: 0.7060\n",
      "[644/1762] D loss: 1.4017, G loss: 0.5641\n",
      "[724/1762] D loss: 1.3790, G loss: 0.7164\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6509\n",
      "[884/1762] D loss: 1.3996, G loss: 0.7799\n",
      "[964/1762] D loss: 1.3960, G loss: 0.7781\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.6852\n",
      "[1124/1762] D loss: 1.4016, G loss: 0.6010\n",
      "[1204/1762] D loss: 1.3753, G loss: 0.7037\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.6930\n",
      "[1364/1762] D loss: 1.2083, G loss: 0.8392\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6711\n",
      "[1524/1762] D loss: 1.2699, G loss: 0.7701\n",
      "[1604/1762] D loss: 1.3832, G loss: 0.7496\n",
      "[1684/1762] D loss: 1.3832, G loss: 0.6898\n",
      "[1762/1762] D loss: 1.7845, G loss: 0.5352\n",
      "train error: \n",
      " D loss: 1.784602, G loss: 0.608138, D accuracy: 19.4%, cell accuracy: 98.7%, board accuracy: 15.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.765234, G loss: 0.608706, D accuracy: 20.7%, cell accuracy: 98.7%, board accuracy: 15.0% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8729, G loss: 0.5291\n",
      "[84/1762] D loss: 1.3025, G loss: 0.9134\n",
      "[164/1762] D loss: 1.5472, G loss: 1.0352\n",
      "[244/1762] D loss: 1.5463, G loss: 0.7914\n",
      "[324/1762] D loss: 1.5902, G loss: 0.5464\n",
      "[404/1762] D loss: 1.4806, G loss: 0.7188\n",
      "[484/1762] D loss: 1.4495, G loss: 0.8758\n",
      "[564/1762] D loss: 1.4702, G loss: 0.8950\n",
      "[644/1762] D loss: 1.2299, G loss: 0.7864\n",
      "[724/1762] D loss: 1.3927, G loss: 0.6549\n",
      "[804/1762] D loss: 1.4058, G loss: 0.8317\n",
      "[884/1762] D loss: 1.3960, G loss: 0.7974\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6981\n",
      "[1044/1762] D loss: 1.3983, G loss: 0.7378\n",
      "[1124/1762] D loss: 1.3063, G loss: 0.7207\n",
      "[1204/1762] D loss: 1.3953, G loss: 0.6291\n",
      "[1284/1762] D loss: 1.4195, G loss: 0.6475\n",
      "[1364/1762] D loss: 1.3767, G loss: 0.7025\n",
      "[1444/1762] D loss: 1.3471, G loss: 0.6924\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.7558\n",
      "[1604/1762] D loss: 1.3970, G loss: 0.7797\n",
      "[1684/1762] D loss: 1.1185, G loss: 0.9036\n",
      "[1762/1762] D loss: 1.3935, G loss: 0.7173\n",
      "train error: \n",
      " D loss: 1.354634, G loss: 0.707019, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345459, G loss: 0.709702, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4188, G loss: 0.6118\n",
      "[84/1762] D loss: 1.4110, G loss: 0.6656\n",
      "[164/1762] D loss: 1.4134, G loss: 0.6132\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7375\n",
      "[324/1762] D loss: 1.3423, G loss: 0.7779\n",
      "[404/1762] D loss: 1.3897, G loss: 0.7555\n",
      "[484/1762] D loss: 1.3027, G loss: 0.8913\n",
      "[564/1762] D loss: 1.3926, G loss: 0.6675\n",
      "[644/1762] D loss: 1.3919, G loss: 0.6956\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6777\n",
      "[804/1762] D loss: 1.3880, G loss: 0.7478\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7310\n",
      "[964/1762] D loss: 1.3904, G loss: 0.7693\n",
      "[1044/1762] D loss: 1.3637, G loss: 0.7365\n",
      "[1124/1762] D loss: 1.4088, G loss: 0.5790\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.7630\n",
      "[1284/1762] D loss: 1.6292, G loss: 0.6434\n",
      "[1364/1762] D loss: 1.9669, G loss: 0.5139\n",
      "[1444/1762] D loss: 1.5344, G loss: 0.6581\n",
      "[1524/1762] D loss: 1.2704, G loss: 1.0375\n",
      "[1604/1762] D loss: 1.0320, G loss: 1.0209\n",
      "[1684/1762] D loss: 1.2200, G loss: 1.3622\n",
      "[1762/1762] D loss: 1.6065, G loss: 0.6248\n",
      "train error: \n",
      " D loss: 1.006295, G loss: 0.894230, D accuracy: 76.8%, cell accuracy: 98.9%, board accuracy: 17.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.013537, G loss: 0.924986, D accuracy: 77.3%, cell accuracy: 98.8%, board accuracy: 14.5% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3484, G loss: 0.8720\n",
      "[84/1762] D loss: 1.8295, G loss: 0.4905\n",
      "[164/1762] D loss: 1.4196, G loss: 0.7214\n",
      "[244/1762] D loss: 1.4107, G loss: 0.5446\n",
      "[324/1762] D loss: 1.3994, G loss: 0.7387\n",
      "[404/1762] D loss: 1.4280, G loss: 0.8484\n",
      "[484/1762] D loss: 1.4136, G loss: 0.8333\n",
      "[564/1762] D loss: 1.3990, G loss: 0.7411\n",
      "[644/1762] D loss: 1.3997, G loss: 0.6708\n",
      "[724/1762] D loss: 1.4978, G loss: 0.7458\n",
      "[804/1762] D loss: 1.3974, G loss: 0.6223\n",
      "[884/1762] D loss: 1.4044, G loss: 0.6320\n",
      "[964/1762] D loss: 1.3473, G loss: 0.6508\n",
      "[1044/1762] D loss: 1.3685, G loss: 0.6721\n",
      "[1124/1762] D loss: 1.4240, G loss: 0.6727\n",
      "[1204/1762] D loss: 1.3479, G loss: 0.8065\n",
      "[1284/1762] D loss: 1.4810, G loss: 0.7228\n",
      "[1364/1762] D loss: 1.4147, G loss: 0.7255\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.6445\n",
      "[1524/1762] D loss: 1.3573, G loss: 0.6813\n",
      "[1604/1762] D loss: 1.3068, G loss: 0.7685\n",
      "[1684/1762] D loss: 1.3720, G loss: 0.7335\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6857\n",
      "train error: \n",
      " D loss: 1.371298, G loss: 0.667666, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 65.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373467, G loss: 0.665363, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959, G loss: 0.6938\n",
      "[84/1762] D loss: 1.2601, G loss: 0.9124\n",
      "[164/1762] D loss: 1.3546, G loss: 0.7035\n",
      "[244/1762] D loss: 1.4036, G loss: 0.5986\n",
      "[324/1762] D loss: 1.3635, G loss: 0.6223\n",
      "[404/1762] D loss: 1.4345, G loss: 0.7529\n",
      "[484/1762] D loss: 1.3756, G loss: 0.8007\n",
      "[564/1762] D loss: 1.3742, G loss: 0.7452\n",
      "[644/1762] D loss: 1.3924, G loss: 0.7154\n",
      "[724/1762] D loss: 1.4135, G loss: 0.7311\n",
      "[804/1762] D loss: 1.3990, G loss: 0.7558\n",
      "[884/1762] D loss: 1.3993, G loss: 0.7427\n",
      "[964/1762] D loss: 1.2996, G loss: 0.7671\n",
      "[1044/1762] D loss: 1.3860, G loss: 0.6634\n",
      "[1124/1762] D loss: 1.3812, G loss: 0.6974\n",
      "[1204/1762] D loss: 1.4066, G loss: 0.6839\n",
      "[1284/1762] D loss: 1.3475, G loss: 0.7617\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.8061\n",
      "[1444/1762] D loss: 1.3601, G loss: 0.9261\n",
      "[1524/1762] D loss: 1.3979, G loss: 0.7349\n",
      "[1604/1762] D loss: 1.3025, G loss: 0.6419\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.6357\n",
      "[1762/1762] D loss: 1.3107, G loss: 0.6907\n",
      "train error: \n",
      " D loss: 1.365568, G loss: 0.649143, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 78.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361586, G loss: 0.643372, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3919, G loss: 0.6523\n",
      "[84/1762] D loss: 1.3934, G loss: 0.7669\n",
      "[164/1762] D loss: 1.3513, G loss: 0.6956\n",
      "[244/1762] D loss: 1.2872, G loss: 0.8965\n",
      "[324/1762] D loss: 1.4215, G loss: 0.8473\n",
      "[404/1762] D loss: 1.2986, G loss: 0.6375\n",
      "[484/1762] D loss: 1.4132, G loss: 0.6424\n",
      "[564/1762] D loss: 1.3920, G loss: 0.8612\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6698\n",
      "[724/1762] D loss: 1.3971, G loss: 0.7076\n",
      "[804/1762] D loss: 1.4075, G loss: 0.6283\n",
      "[884/1762] D loss: 1.3943, G loss: 0.7502\n",
      "[964/1762] D loss: 1.3921, G loss: 0.7178\n",
      "[1044/1762] D loss: 1.1374, G loss: 0.7434\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.6384\n",
      "[1204/1762] D loss: 1.4411, G loss: 0.5677\n",
      "[1284/1762] D loss: 1.3961, G loss: 0.6426\n",
      "[1364/1762] D loss: 1.3940, G loss: 0.7688\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.6839\n",
      "[1524/1762] D loss: 1.3965, G loss: 0.6584\n",
      "[1604/1762] D loss: 1.4131, G loss: 0.6720\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.7374\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.6362\n",
      "train error: \n",
      " D loss: 1.352281, G loss: 0.670126, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346288, G loss: 0.667146, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3946, G loss: 0.6720\n",
      "[84/1762] D loss: 1.2405, G loss: 0.8469\n",
      "[164/1762] D loss: 1.2385, G loss: 0.7949\n",
      "[244/1762] D loss: 1.3817, G loss: 0.7072\n",
      "[324/1762] D loss: 1.4062, G loss: 0.7262\n",
      "[404/1762] D loss: 1.4234, G loss: 0.6433\n",
      "[484/1762] D loss: 1.4411, G loss: 0.5673\n",
      "[564/1762] D loss: 1.3925, G loss: 0.7855\n",
      "[644/1762] D loss: 1.2558, G loss: 0.7345\n",
      "[724/1762] D loss: 1.3938, G loss: 0.7684\n",
      "[804/1762] D loss: 1.3920, G loss: 0.7346\n",
      "[884/1762] D loss: 1.3892, G loss: 0.6818\n",
      "[964/1762] D loss: 1.3910, G loss: 0.6926\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.7450\n",
      "[1124/1762] D loss: 1.3846, G loss: 0.6796\n",
      "[1204/1762] D loss: 1.4171, G loss: 0.6728\n",
      "[1284/1762] D loss: 1.3692, G loss: 0.8002\n",
      "[1364/1762] D loss: 1.4030, G loss: 0.7683\n",
      "[1444/1762] D loss: 1.3927, G loss: 0.6961\n",
      "[1524/1762] D loss: 1.3967, G loss: 0.6579\n",
      "[1604/1762] D loss: 1.3717, G loss: 0.6623\n",
      "[1684/1762] D loss: 1.4387, G loss: 0.6214\n",
      "[1762/1762] D loss: 1.3947, G loss: 0.7311\n",
      "train error: \n",
      " D loss: 1.345971, G loss: 0.772809, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335205, G loss: 0.771323, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7324\n",
      "[84/1762] D loss: 1.4032, G loss: 0.7737\n",
      "[164/1762] D loss: 1.3966, G loss: 0.6476\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6638\n",
      "[324/1762] D loss: 1.2208, G loss: 0.7515\n",
      "[404/1762] D loss: 1.2121, G loss: 0.8728\n",
      "[484/1762] D loss: 1.4179, G loss: 0.7077\n",
      "[564/1762] D loss: 1.3750, G loss: 0.7611\n",
      "[644/1762] D loss: 1.3609, G loss: 0.7913\n",
      "[724/1762] D loss: 1.4005, G loss: 0.7397\n",
      "[804/1762] D loss: 1.4055, G loss: 0.7904\n",
      "[884/1762] D loss: 1.4149, G loss: 0.7401\n",
      "[964/1762] D loss: 1.3906, G loss: 0.6918\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.6655\n",
      "[1124/1762] D loss: 1.3909, G loss: 0.7873\n",
      "[1204/1762] D loss: 1.3905, G loss: 0.6926\n",
      "[1284/1762] D loss: 1.0399, G loss: 0.8703\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7795\n",
      "[1444/1762] D loss: 1.3969, G loss: 0.6459\n",
      "[1524/1762] D loss: 1.4122, G loss: 0.6702\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.6563\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.6925\n",
      "[1762/1762] D loss: 1.3955, G loss: 0.7411\n",
      "train error: \n",
      " D loss: 1.344557, G loss: 0.801626, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 75.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330315, G loss: 0.804725, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3995, G loss: 0.7251\n",
      "[84/1762] D loss: 1.1734, G loss: 0.7616\n",
      "[164/1762] D loss: 1.3967, G loss: 0.7398\n",
      "[244/1762] D loss: 1.2070, G loss: 0.7509\n",
      "[324/1762] D loss: 1.3893, G loss: 0.6837\n",
      "[404/1762] D loss: 1.7519, G loss: 0.5772\n",
      "[484/1762] D loss: 1.8114, G loss: 1.0834\n",
      "[564/1762] D loss: 1.1884, G loss: 0.8301\n",
      "[644/1762] D loss: 1.1579, G loss: 0.8995\n",
      "[724/1762] D loss: 1.6760, G loss: 0.8473\n",
      "[804/1762] D loss: 1.4292, G loss: 0.4643\n",
      "[884/1762] D loss: 1.4094, G loss: 0.7654\n",
      "[964/1762] D loss: 1.4054, G loss: 0.5550\n",
      "[1044/1762] D loss: 1.5213, G loss: 0.6451\n",
      "[1124/1762] D loss: 1.5559, G loss: 1.1384\n",
      "[1204/1762] D loss: 1.4133, G loss: 0.6959\n",
      "[1284/1762] D loss: 1.4091, G loss: 0.7415\n",
      "[1364/1762] D loss: 1.4251, G loss: 0.5674\n",
      "[1444/1762] D loss: 1.2231, G loss: 0.7612\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.7014\n",
      "[1604/1762] D loss: 1.4097, G loss: 0.8320\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.7115\n",
      "[1762/1762] D loss: 1.3926, G loss: 0.7403\n",
      "train error: \n",
      " D loss: 1.371633, G loss: 0.685108, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 63.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366565, G loss: 0.687019, D accuracy: 53.3%, cell accuracy: 99.6%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4149, G loss: 0.6316\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6176\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6702\n",
      "[244/1762] D loss: 1.3941, G loss: 0.7495\n",
      "[324/1762] D loss: 1.2235, G loss: 0.8045\n",
      "[404/1762] D loss: 1.3811, G loss: 0.6968\n",
      "[484/1762] D loss: 1.3827, G loss: 0.6439\n",
      "[564/1762] D loss: 1.1270, G loss: 0.8879\n",
      "[644/1762] D loss: 1.3880, G loss: 0.7116\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6519\n",
      "[804/1762] D loss: 1.1791, G loss: 0.7416\n",
      "[884/1762] D loss: 1.3739, G loss: 0.6027\n",
      "[964/1762] D loss: 1.3859, G loss: 0.7218\n",
      "[1044/1762] D loss: 1.2460, G loss: 0.7506\n",
      "[1124/1762] D loss: 1.3972, G loss: 0.6256\n",
      "[1204/1762] D loss: 1.8623, G loss: 0.5409\n",
      "[1284/1762] D loss: 1.5986, G loss: 0.6785\n",
      "[1364/1762] D loss: 1.3128, G loss: 0.7776\n",
      "[1444/1762] D loss: 1.2672, G loss: 0.5698\n",
      "[1524/1762] D loss: 1.4592, G loss: 0.8817\n",
      "[1604/1762] D loss: 1.4270, G loss: 0.7547\n",
      "[1684/1762] D loss: 1.5975, G loss: 0.7788\n",
      "[1762/1762] D loss: 1.5405, G loss: 1.0783\n",
      "train error: \n",
      " D loss: 1.492783, G loss: 0.956284, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.511468, G loss: 0.970359, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7309\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7249\n",
      "[164/1762] D loss: 1.3858, G loss: 0.7198\n",
      "[244/1762] D loss: 1.3845, G loss: 0.7156\n",
      "[324/1762] D loss: 1.3824, G loss: 0.7117\n",
      "[404/1762] D loss: 1.3778, G loss: 0.7096\n",
      "[484/1762] D loss: 1.3680, G loss: 0.7138\n",
      "[564/1762] D loss: 1.3428, G loss: 0.7126\n",
      "[644/1762] D loss: 1.3239, G loss: 0.7128\n",
      "[724/1762] D loss: 1.2962, G loss: 0.7259\n",
      "[804/1762] D loss: 1.2539, G loss: 0.7325\n",
      "[884/1762] D loss: 1.2194, G loss: 0.6910\n",
      "[964/1762] D loss: 1.1675, G loss: 0.6874\n",
      "[1044/1762] D loss: 1.0771, G loss: 0.7285\n",
      "[1124/1762] D loss: 0.9711, G loss: 0.7628\n",
      "[1204/1762] D loss: 0.8837, G loss: 0.8483\n",
      "[1284/1762] D loss: 0.8725, G loss: 0.9494\n",
      "[1364/1762] D loss: 0.7621, G loss: 0.9113\n",
      "[1444/1762] D loss: 0.6725, G loss: 1.0834\n",
      "[1524/1762] D loss: 0.6361, G loss: 1.3087\n",
      "[1604/1762] D loss: 0.7422, G loss: 1.3591\n",
      "[1684/1762] D loss: 0.4339, G loss: 1.6982\n",
      "[1762/1762] D loss: 0.4933, G loss: 1.9738\n",
      "train error: \n",
      " D loss: 0.540738, G loss: 1.647195, D accuracy: 93.9%, cell accuracy: 64.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.519135, G loss: 1.700375, D accuracy: 95.5%, cell accuracy: 63.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5367, G loss: 1.6576\n",
      "[84/1762] D loss: 0.6414, G loss: 1.7608\n",
      "[164/1762] D loss: 0.3823, G loss: 1.6917\n",
      "[244/1762] D loss: 0.3176, G loss: 1.8982\n",
      "[324/1762] D loss: 0.5073, G loss: 2.5712\n",
      "[404/1762] D loss: 0.5989, G loss: 2.2396\n",
      "[484/1762] D loss: 0.2338, G loss: 2.4132\n",
      "[564/1762] D loss: 0.3549, G loss: 2.4432\n",
      "[644/1762] D loss: 0.3308, G loss: 2.5443\n",
      "[724/1762] D loss: 0.1860, G loss: 2.6504\n",
      "[804/1762] D loss: 0.4633, G loss: 2.5031\n",
      "[884/1762] D loss: 0.5327, G loss: 2.4189\n",
      "[964/1762] D loss: 0.4723, G loss: 3.0674\n",
      "[1044/1762] D loss: 0.2120, G loss: 3.0385\n",
      "[1124/1762] D loss: 0.1784, G loss: 2.7525\n",
      "[1204/1762] D loss: 0.4539, G loss: 2.4462\n",
      "[1284/1762] D loss: 0.1622, G loss: 3.0861\n",
      "[1364/1762] D loss: 0.3296, G loss: 3.0184\n",
      "[1444/1762] D loss: 0.2685, G loss: 3.5527\n",
      "[1524/1762] D loss: 0.3103, G loss: 2.7278\n",
      "[1604/1762] D loss: 0.1349, G loss: 2.9023\n",
      "[1684/1762] D loss: 0.1473, G loss: 3.7283\n",
      "[1762/1762] D loss: 0.1074, G loss: 3.1616\n",
      "train error: \n",
      " D loss: 0.359458, G loss: 2.218356, D accuracy: 92.8%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.372301, G loss: 2.106140, D accuracy: 93.1%, cell accuracy: 94.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3655, G loss: 2.1643\n",
      "[84/1762] D loss: 0.3563, G loss: 3.1037\n",
      "[164/1762] D loss: 0.2238, G loss: 3.3432\n",
      "[244/1762] D loss: 0.6515, G loss: 3.5868\n",
      "[324/1762] D loss: 0.4325, G loss: 3.4239\n",
      "[404/1762] D loss: 0.1734, G loss: 2.3467\n",
      "[484/1762] D loss: 0.1867, G loss: 2.9026\n",
      "[564/1762] D loss: 0.3768, G loss: 3.5483\n",
      "[644/1762] D loss: 0.1874, G loss: 3.8284\n",
      "[724/1762] D loss: 0.0872, G loss: 3.3222\n",
      "[804/1762] D loss: 0.0820, G loss: 3.4969\n",
      "[884/1762] D loss: 0.2408, G loss: 2.6183\n",
      "[964/1762] D loss: 0.0879, G loss: 3.8367\n",
      "[1044/1762] D loss: 0.8299, G loss: 3.0081\n",
      "[1124/1762] D loss: 0.8412, G loss: 2.9489\n",
      "[1204/1762] D loss: 0.1248, G loss: 3.4761\n",
      "[1284/1762] D loss: 0.6523, G loss: 3.4900\n",
      "[1364/1762] D loss: 0.2574, G loss: 2.4227\n",
      "[1444/1762] D loss: 0.2638, G loss: 2.8992\n",
      "[1524/1762] D loss: 0.5296, G loss: 2.7309\n",
      "[1604/1762] D loss: 0.1606, G loss: 2.8596\n",
      "[1684/1762] D loss: 1.0241, G loss: 3.0961\n",
      "[1762/1762] D loss: 0.7288, G loss: 3.2923\n",
      "train error: \n",
      " D loss: 1.268243, G loss: 1.712359, D accuracy: 73.0%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346384, G loss: 1.725262, D accuracy: 73.3%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9015, G loss: 1.7416\n",
      "[84/1762] D loss: 0.5132, G loss: 2.7680\n",
      "[164/1762] D loss: 0.2873, G loss: 2.9590\n",
      "[244/1762] D loss: 1.0328, G loss: 1.5581\n",
      "[324/1762] D loss: 0.8404, G loss: 2.4486\n",
      "[404/1762] D loss: 0.4333, G loss: 1.7614\n",
      "[484/1762] D loss: 1.4848, G loss: 1.6520\n",
      "[564/1762] D loss: 1.0758, G loss: 1.5020\n",
      "[644/1762] D loss: 0.7332, G loss: 2.4044\n",
      "[724/1762] D loss: 0.7862, G loss: 1.2165\n",
      "[804/1762] D loss: 0.7483, G loss: 1.6649\n",
      "[884/1762] D loss: 0.7573, G loss: 1.1728\n",
      "[964/1762] D loss: 0.9878, G loss: 2.2346\n",
      "[1044/1762] D loss: 0.9459, G loss: 1.9180\n",
      "[1124/1762] D loss: 1.6367, G loss: 2.1183\n",
      "[1204/1762] D loss: 1.2449, G loss: 1.3817\n",
      "[1284/1762] D loss: 0.6830, G loss: 1.2455\n",
      "[1364/1762] D loss: 0.9044, G loss: 0.7442\n",
      "[1444/1762] D loss: 0.7911, G loss: 1.0556\n",
      "[1524/1762] D loss: 1.3871, G loss: 1.0652\n",
      "[1604/1762] D loss: 0.8532, G loss: 0.5877\n",
      "[1684/1762] D loss: 1.2542, G loss: 0.6349\n",
      "[1762/1762] D loss: 1.2273, G loss: 1.1188\n",
      "train error: \n",
      " D loss: 1.084626, G loss: 1.243758, D accuracy: 76.5%, cell accuracy: 99.2%, board accuracy: 39.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.098621, G loss: 1.290284, D accuracy: 74.5%, cell accuracy: 99.1%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0295, G loss: 1.2559\n",
      "[84/1762] D loss: 1.2558, G loss: 0.8257\n",
      "[164/1762] D loss: 1.1956, G loss: 2.2122\n",
      "[244/1762] D loss: 1.0963, G loss: 1.2126\n",
      "[324/1762] D loss: 1.1453, G loss: 0.5068\n",
      "[404/1762] D loss: 0.8465, G loss: 1.1882\n",
      "[484/1762] D loss: 1.2668, G loss: 1.3337\n",
      "[564/1762] D loss: 1.0362, G loss: 0.8024\n",
      "[644/1762] D loss: 0.9603, G loss: 1.2254\n",
      "[724/1762] D loss: 1.3221, G loss: 0.9944\n",
      "[804/1762] D loss: 1.1611, G loss: 1.7673\n",
      "[884/1762] D loss: 1.2563, G loss: 1.3530\n",
      "[964/1762] D loss: 1.0756, G loss: 0.5929\n",
      "[1044/1762] D loss: 1.1121, G loss: 0.6788\n",
      "[1124/1762] D loss: 1.1733, G loss: 1.4896\n",
      "[1204/1762] D loss: 1.1974, G loss: 1.0643\n",
      "[1284/1762] D loss: 1.3006, G loss: 0.6951\n",
      "[1364/1762] D loss: 1.1737, G loss: 1.3400\n",
      "[1444/1762] D loss: 1.2406, G loss: 0.9823\n",
      "[1524/1762] D loss: 0.9613, G loss: 0.8407\n",
      "[1604/1762] D loss: 1.0757, G loss: 1.0522\n",
      "[1684/1762] D loss: 0.9599, G loss: 1.2569\n",
      "[1762/1762] D loss: 1.3003, G loss: 0.8954\n",
      "train error: \n",
      " D loss: 1.213689, G loss: 1.058797, D accuracy: 67.8%, cell accuracy: 99.5%, board accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.222728, G loss: 1.048576, D accuracy: 66.1%, cell accuracy: 99.4%, board accuracy: 48.6% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1831, G loss: 0.6738\n",
      "[84/1762] D loss: 1.3651, G loss: 1.0911\n",
      "[164/1762] D loss: 1.2077, G loss: 0.9131\n",
      "[244/1762] D loss: 1.2342, G loss: 1.1723\n",
      "[324/1762] D loss: 1.3350, G loss: 0.7776\n",
      "[404/1762] D loss: 1.1564, G loss: 0.7128\n",
      "[484/1762] D loss: 1.1469, G loss: 0.5528\n",
      "[564/1762] D loss: 1.1903, G loss: 1.1999\n",
      "[644/1762] D loss: 1.4415, G loss: 0.5975\n",
      "[724/1762] D loss: 1.2322, G loss: 0.6747\n",
      "[804/1762] D loss: 0.9905, G loss: 1.0709\n",
      "[884/1762] D loss: 1.3950, G loss: 2.2988\n",
      "[964/1762] D loss: 1.5092, G loss: 1.4901\n",
      "[1044/1762] D loss: 1.2504, G loss: 0.5434\n",
      "[1124/1762] D loss: 1.3472, G loss: 0.6180\n",
      "[1204/1762] D loss: 1.4201, G loss: 0.4098\n",
      "[1284/1762] D loss: 1.2718, G loss: 0.9177\n",
      "[1364/1762] D loss: 1.0373, G loss: 1.1602\n",
      "[1444/1762] D loss: 1.2941, G loss: 0.7562\n",
      "[1524/1762] D loss: 1.4473, G loss: 1.4443\n",
      "[1604/1762] D loss: 1.4121, G loss: 0.9556\n",
      "[1684/1762] D loss: 1.1791, G loss: 1.4219\n",
      "[1762/1762] D loss: 1.1161, G loss: 1.0705\n",
      "train error: \n",
      " D loss: 1.332612, G loss: 1.220096, D accuracy: 58.5%, cell accuracy: 99.6%, board accuracy: 68.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344504, G loss: 1.226534, D accuracy: 57.7%, cell accuracy: 99.6%, board accuracy: 63.4% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1675, G loss: 1.3677\n",
      "[84/1762] D loss: 1.4218, G loss: 1.2640\n",
      "[164/1762] D loss: 1.2955, G loss: 0.7133\n",
      "[244/1762] D loss: 1.1888, G loss: 1.0169\n",
      "[324/1762] D loss: 1.0759, G loss: 1.0646\n",
      "[404/1762] D loss: 1.2208, G loss: 1.2110\n",
      "[484/1762] D loss: 1.2301, G loss: 0.7158\n",
      "[564/1762] D loss: 1.1703, G loss: 1.5041\n",
      "[644/1762] D loss: 1.2171, G loss: 0.9597\n",
      "[724/1762] D loss: 1.2871, G loss: 0.4461\n",
      "[804/1762] D loss: 1.3186, G loss: 0.6510\n",
      "[884/1762] D loss: 0.9818, G loss: 0.9127\n",
      "[964/1762] D loss: 1.2226, G loss: 0.8814\n",
      "[1044/1762] D loss: 1.5280, G loss: 1.0456\n",
      "[1124/1762] D loss: 1.3678, G loss: 0.9093\n",
      "[1204/1762] D loss: 1.3127, G loss: 0.6398\n",
      "[1284/1762] D loss: 1.1046, G loss: 1.0861\n",
      "[1364/1762] D loss: 1.2645, G loss: 1.0032\n",
      "[1444/1762] D loss: 1.4056, G loss: 0.7786\n",
      "[1524/1762] D loss: 1.4757, G loss: 0.6069\n",
      "[1604/1762] D loss: 1.2127, G loss: 0.7399\n",
      "[1684/1762] D loss: 1.2454, G loss: 0.5150\n",
      "[1762/1762] D loss: 0.9051, G loss: 1.2994\n",
      "train error: \n",
      " D loss: 1.288627, G loss: 0.931213, D accuracy: 62.9%, cell accuracy: 99.6%, board accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297012, G loss: 0.931248, D accuracy: 62.7%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1049, G loss: 1.2566\n",
      "[84/1762] D loss: 1.3358, G loss: 0.6802\n",
      "[164/1762] D loss: 1.3738, G loss: 0.6654\n",
      "[244/1762] D loss: 1.2839, G loss: 0.7078\n",
      "[324/1762] D loss: 1.3135, G loss: 0.7317\n",
      "[404/1762] D loss: 1.1184, G loss: 0.8292\n",
      "[484/1762] D loss: 1.1800, G loss: 0.8102\n",
      "[564/1762] D loss: 1.4793, G loss: 0.9512\n",
      "[644/1762] D loss: 1.3783, G loss: 0.6872\n",
      "[724/1762] D loss: 1.4251, G loss: 0.7977\n",
      "[804/1762] D loss: 1.3107, G loss: 0.5825\n",
      "[884/1762] D loss: 1.3719, G loss: 0.6261\n",
      "[964/1762] D loss: 1.3072, G loss: 0.6969\n",
      "[1044/1762] D loss: 1.5069, G loss: 0.5121\n",
      "[1124/1762] D loss: 1.4829, G loss: 1.0047\n",
      "[1204/1762] D loss: 1.4242, G loss: 0.8403\n",
      "[1284/1762] D loss: 1.0714, G loss: 0.9393\n",
      "[1364/1762] D loss: 1.5257, G loss: 0.6917\n",
      "[1444/1762] D loss: 1.3665, G loss: 0.8625\n",
      "[1524/1762] D loss: 1.5241, G loss: 1.1749\n",
      "[1604/1762] D loss: 1.3049, G loss: 1.0438\n",
      "[1684/1762] D loss: 1.3979, G loss: 0.8009\n",
      "[1762/1762] D loss: 1.3211, G loss: 0.7535\n",
      "train error: \n",
      " D loss: 1.388956, G loss: 0.534489, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 63.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403510, G loss: 0.527485, D accuracy: 57.6%, cell accuracy: 99.5%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3475, G loss: 0.8466\n",
      "[84/1762] D loss: 1.4844, G loss: 0.5103\n",
      "[164/1762] D loss: 1.3235, G loss: 1.0575\n",
      "[244/1762] D loss: 1.4006, G loss: 0.7783\n",
      "[324/1762] D loss: 1.1972, G loss: 1.2572\n",
      "[404/1762] D loss: 1.3621, G loss: 0.7960\n",
      "[484/1762] D loss: 1.2883, G loss: 1.1299\n",
      "[564/1762] D loss: 1.4014, G loss: 1.4033\n",
      "[644/1762] D loss: 1.1343, G loss: 0.6940\n",
      "[724/1762] D loss: 1.2660, G loss: 0.9041\n",
      "[804/1762] D loss: 1.3620, G loss: 1.0014\n",
      "[884/1762] D loss: 1.3890, G loss: 0.7855\n",
      "[964/1762] D loss: 1.2083, G loss: 1.0753\n",
      "[1044/1762] D loss: 1.3539, G loss: 0.5787\n",
      "[1124/1762] D loss: 1.1860, G loss: 1.2188\n",
      "[1204/1762] D loss: 0.9658, G loss: 0.6758\n",
      "[1284/1762] D loss: 1.3187, G loss: 0.7649\n",
      "[1364/1762] D loss: 1.2912, G loss: 0.7272\n",
      "[1444/1762] D loss: 1.4755, G loss: 0.6398\n",
      "[1524/1762] D loss: 1.3369, G loss: 0.8850\n",
      "[1604/1762] D loss: 1.4008, G loss: 1.3763\n",
      "[1684/1762] D loss: 0.8836, G loss: 1.1206\n",
      "[1762/1762] D loss: 1.3564, G loss: 0.5664\n",
      "train error: \n",
      " D loss: 1.293539, G loss: 0.705649, D accuracy: 60.9%, cell accuracy: 99.6%, board accuracy: 62.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297656, G loss: 0.703559, D accuracy: 61.1%, cell accuracy: 99.5%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2468, G loss: 0.7709\n",
      "[84/1762] D loss: 1.1921, G loss: 0.8566\n",
      "[164/1762] D loss: 1.4271, G loss: 1.1748\n",
      "[244/1762] D loss: 1.3538, G loss: 0.7410\n",
      "[324/1762] D loss: 1.3000, G loss: 0.6686\n",
      "[404/1762] D loss: 1.1860, G loss: 0.8842\n",
      "[484/1762] D loss: 1.2933, G loss: 0.6427\n",
      "[564/1762] D loss: 1.2530, G loss: 0.5879\n",
      "[644/1762] D loss: 1.3816, G loss: 0.6350\n",
      "[724/1762] D loss: 1.2789, G loss: 0.9986\n",
      "[804/1762] D loss: 1.2417, G loss: 0.8238\n",
      "[884/1762] D loss: 1.1443, G loss: 0.7488\n",
      "[964/1762] D loss: 1.3908, G loss: 0.7852\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.8107\n",
      "[1124/1762] D loss: 1.1609, G loss: 1.0435\n",
      "[1204/1762] D loss: 1.2499, G loss: 1.0124\n",
      "[1284/1762] D loss: 1.4807, G loss: 0.5327\n",
      "[1364/1762] D loss: 1.1536, G loss: 0.8282\n",
      "[1444/1762] D loss: 1.4335, G loss: 0.7521\n",
      "[1524/1762] D loss: 1.2683, G loss: 1.3986\n",
      "[1604/1762] D loss: 1.3469, G loss: 0.5328\n",
      "[1684/1762] D loss: 1.4789, G loss: 0.6064\n",
      "[1762/1762] D loss: 1.3787, G loss: 0.7520\n",
      "train error: \n",
      " D loss: 1.274029, G loss: 0.926860, D accuracy: 61.8%, cell accuracy: 99.6%, board accuracy: 63.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267601, G loss: 0.926676, D accuracy: 61.4%, cell accuracy: 99.5%, board accuracy: 56.1% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3574, G loss: 0.9447\n",
      "[84/1762] D loss: 1.2782, G loss: 0.9600\n",
      "[164/1762] D loss: 1.0859, G loss: 0.7584\n",
      "[244/1762] D loss: 1.5418, G loss: 0.3538\n",
      "[324/1762] D loss: 1.3436, G loss: 1.0094\n",
      "[404/1762] D loss: 1.1189, G loss: 1.0418\n",
      "[484/1762] D loss: 1.2670, G loss: 0.6797\n",
      "[564/1762] D loss: 1.1480, G loss: 0.8843\n",
      "[644/1762] D loss: 1.1779, G loss: 0.9619\n",
      "[724/1762] D loss: 1.4047, G loss: 0.9109\n",
      "[804/1762] D loss: 1.4920, G loss: 0.5202\n",
      "[884/1762] D loss: 1.2212, G loss: 0.7293\n",
      "[964/1762] D loss: 1.3896, G loss: 0.6068\n",
      "[1044/1762] D loss: 1.2683, G loss: 0.8007\n",
      "[1124/1762] D loss: 1.3763, G loss: 0.8490\n",
      "[1204/1762] D loss: 1.2933, G loss: 1.2558\n",
      "[1284/1762] D loss: 1.1963, G loss: 1.2697\n",
      "[1364/1762] D loss: 1.2008, G loss: 0.6311\n",
      "[1444/1762] D loss: 1.4430, G loss: 0.9720\n",
      "[1524/1762] D loss: 1.3845, G loss: 0.6321\n",
      "[1604/1762] D loss: 1.1873, G loss: 1.2908\n",
      "[1684/1762] D loss: 1.1289, G loss: 0.7414\n",
      "[1762/1762] D loss: 1.0576, G loss: 0.8114\n",
      "train error: \n",
      " D loss: 1.271669, G loss: 0.710324, D accuracy: 61.3%, cell accuracy: 99.6%, board accuracy: 64.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267097, G loss: 0.710057, D accuracy: 61.7%, cell accuracy: 99.5%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1949, G loss: 0.8658\n",
      "[84/1762] D loss: 1.2922, G loss: 0.6905\n",
      "[164/1762] D loss: 1.2342, G loss: 0.8044\n",
      "[244/1762] D loss: 1.1683, G loss: 0.7700\n",
      "[324/1762] D loss: 1.4026, G loss: 0.9003\n",
      "[404/1762] D loss: 1.2457, G loss: 0.7470\n",
      "[484/1762] D loss: 1.4134, G loss: 0.7050\n",
      "[564/1762] D loss: 1.2583, G loss: 0.9954\n",
      "[644/1762] D loss: 1.4554, G loss: 0.4486\n",
      "[724/1762] D loss: 1.1697, G loss: 1.3257\n",
      "[804/1762] D loss: 1.1756, G loss: 0.8186\n",
      "[884/1762] D loss: 1.2542, G loss: 0.7138\n",
      "[964/1762] D loss: 1.3331, G loss: 1.1557\n",
      "[1044/1762] D loss: 1.2810, G loss: 0.7875\n",
      "[1124/1762] D loss: 1.1911, G loss: 0.9310\n",
      "[1204/1762] D loss: 1.5336, G loss: 0.3992\n",
      "[1284/1762] D loss: 1.1789, G loss: 0.8772\n",
      "[1364/1762] D loss: 1.4484, G loss: 1.2310\n",
      "[1444/1762] D loss: 1.3722, G loss: 0.6432\n",
      "[1524/1762] D loss: 1.1570, G loss: 1.1570\n",
      "[1604/1762] D loss: 1.3624, G loss: 0.6667\n",
      "[1684/1762] D loss: 1.3763, G loss: 1.0629\n",
      "[1762/1762] D loss: 1.3956, G loss: 0.7811\n",
      "train error: \n",
      " D loss: 1.260288, G loss: 0.810715, D accuracy: 61.4%, cell accuracy: 99.6%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259314, G loss: 0.803503, D accuracy: 61.6%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4654, G loss: 0.5564\n",
      "[84/1762] D loss: 1.6061, G loss: 0.8828\n",
      "[164/1762] D loss: 1.4630, G loss: 0.5273\n",
      "[244/1762] D loss: 1.1401, G loss: 1.2968\n",
      "[324/1762] D loss: 1.3392, G loss: 0.6863\n",
      "[404/1762] D loss: 1.2026, G loss: 0.7246\n",
      "[484/1762] D loss: 1.4070, G loss: 0.8136\n",
      "[564/1762] D loss: 1.1759, G loss: 0.8732\n",
      "[644/1762] D loss: 1.2108, G loss: 1.1548\n",
      "[724/1762] D loss: 1.4061, G loss: 0.8858\n",
      "[804/1762] D loss: 0.8539, G loss: 1.6885\n",
      "[884/1762] D loss: 1.0150, G loss: 1.0690\n",
      "[964/1762] D loss: 1.5127, G loss: 0.8103\n",
      "[1044/1762] D loss: 1.2475, G loss: 1.0306\n",
      "[1124/1762] D loss: 1.3410, G loss: 0.7899\n",
      "[1204/1762] D loss: 1.1051, G loss: 1.0432\n",
      "[1284/1762] D loss: 1.5081, G loss: 1.1761\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7277\n",
      "[1444/1762] D loss: 1.4617, G loss: 0.4870\n",
      "[1524/1762] D loss: 1.3620, G loss: 0.9137\n",
      "[1604/1762] D loss: 1.9710, G loss: 0.3966\n",
      "[1684/1762] D loss: 1.6338, G loss: 1.5007\n",
      "[1762/1762] D loss: 1.6457, G loss: 0.3076\n",
      "train error: \n",
      " D loss: 1.440705, G loss: 0.553246, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.450773, G loss: 0.535983, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4791, G loss: 0.5381\n",
      "[84/1762] D loss: 1.1592, G loss: 1.3188\n",
      "[164/1762] D loss: 1.4362, G loss: 1.2185\n",
      "[244/1762] D loss: 1.4457, G loss: 0.8237\n",
      "[324/1762] D loss: 1.5669, G loss: 0.4155\n",
      "[404/1762] D loss: 1.4461, G loss: 0.5624\n",
      "[484/1762] D loss: 1.1607, G loss: 1.0640\n",
      "[564/1762] D loss: 1.5168, G loss: 0.6830\n",
      "[644/1762] D loss: 1.5297, G loss: 0.9497\n",
      "[724/1762] D loss: 1.2595, G loss: 0.9962\n",
      "[804/1762] D loss: 1.1835, G loss: 0.8575\n",
      "[884/1762] D loss: 1.4811, G loss: 0.3952\n",
      "[964/1762] D loss: 1.3102, G loss: 0.6680\n",
      "[1044/1762] D loss: 1.1479, G loss: 0.8215\n",
      "[1124/1762] D loss: 1.3983, G loss: 0.8922\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.8419\n",
      "[1284/1762] D loss: 1.3091, G loss: 1.0656\n",
      "[1364/1762] D loss: 1.4706, G loss: 0.4809\n",
      "[1444/1762] D loss: 1.1645, G loss: 0.7686\n",
      "[1524/1762] D loss: 1.0991, G loss: 1.1168\n",
      "[1604/1762] D loss: 1.4483, G loss: 0.6295\n",
      "[1684/1762] D loss: 1.4163, G loss: 0.7409\n",
      "[1762/1762] D loss: 1.2715, G loss: 0.8858\n",
      "train error: \n",
      " D loss: 1.345892, G loss: 0.802766, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353582, G loss: 0.784729, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4516, G loss: 0.8699\n",
      "[84/1762] D loss: 1.2797, G loss: 0.8832\n",
      "[164/1762] D loss: 1.1723, G loss: 0.8578\n",
      "[244/1762] D loss: 1.3247, G loss: 0.6774\n",
      "[324/1762] D loss: 1.2373, G loss: 0.5414\n",
      "[404/1762] D loss: 1.3768, G loss: 0.6098\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6821\n",
      "[564/1762] D loss: 1.3820, G loss: 0.7638\n",
      "[644/1762] D loss: 1.3651, G loss: 0.8686\n",
      "[724/1762] D loss: 1.3857, G loss: 0.8069\n",
      "[804/1762] D loss: 1.3560, G loss: 0.7754\n",
      "[884/1762] D loss: 1.3419, G loss: 0.7887\n",
      "[964/1762] D loss: 1.5658, G loss: 1.3302\n",
      "[1044/1762] D loss: 1.3787, G loss: 0.9422\n",
      "[1124/1762] D loss: 1.4134, G loss: 1.0135\n",
      "[1204/1762] D loss: 1.3642, G loss: 0.8009\n",
      "[1284/1762] D loss: 1.4246, G loss: 0.6167\n",
      "[1364/1762] D loss: 1.2749, G loss: 1.0506\n",
      "[1444/1762] D loss: 1.4541, G loss: 1.0263\n",
      "[1524/1762] D loss: 1.4363, G loss: 0.8755\n",
      "[1604/1762] D loss: 1.3694, G loss: 0.6216\n",
      "[1684/1762] D loss: 1.4227, G loss: 0.7049\n",
      "[1762/1762] D loss: 1.4911, G loss: 0.7140\n",
      "train error: \n",
      " D loss: 1.350701, G loss: 0.811481, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351261, G loss: 0.809280, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3906, G loss: 0.6454\n",
      "[84/1762] D loss: 1.3938, G loss: 0.5900\n",
      "[164/1762] D loss: 1.3775, G loss: 0.6817\n",
      "[244/1762] D loss: 1.4030, G loss: 0.6689\n",
      "[324/1762] D loss: 1.3974, G loss: 0.7155\n",
      "[404/1762] D loss: 1.4214, G loss: 0.9560\n",
      "[484/1762] D loss: 1.4904, G loss: 0.7861\n",
      "[564/1762] D loss: 1.3799, G loss: 0.6813\n",
      "[644/1762] D loss: 1.4055, G loss: 0.7288\n",
      "[724/1762] D loss: 1.3817, G loss: 0.6804\n",
      "[804/1762] D loss: 1.3750, G loss: 0.8330\n",
      "[884/1762] D loss: 1.4341, G loss: 0.6408\n",
      "[964/1762] D loss: 1.4074, G loss: 0.5532\n",
      "[1044/1762] D loss: 1.3680, G loss: 0.6208\n",
      "[1124/1762] D loss: 1.3217, G loss: 0.8292\n",
      "[1204/1762] D loss: 1.4297, G loss: 0.6466\n",
      "[1284/1762] D loss: 1.3668, G loss: 0.7261\n",
      "[1364/1762] D loss: 1.3289, G loss: 0.8226\n",
      "[1444/1762] D loss: 1.4284, G loss: 0.6065\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7704\n",
      "[1604/1762] D loss: 1.3505, G loss: 0.8077\n",
      "[1684/1762] D loss: 1.4483, G loss: 0.8940\n",
      "[1762/1762] D loss: 1.2434, G loss: 0.7297\n",
      "train error: \n",
      " D loss: 1.359532, G loss: 0.713323, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368996, G loss: 0.707473, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3678, G loss: 0.7227\n",
      "[84/1762] D loss: 1.2752, G loss: 1.0487\n",
      "[164/1762] D loss: 1.4118, G loss: 0.8044\n",
      "[244/1762] D loss: 1.4173, G loss: 0.6235\n",
      "[324/1762] D loss: 1.3607, G loss: 0.7474\n",
      "[404/1762] D loss: 1.3942, G loss: 0.6956\n",
      "[484/1762] D loss: 1.3818, G loss: 0.7863\n",
      "[564/1762] D loss: 1.1740, G loss: 0.8449\n",
      "[644/1762] D loss: 1.3924, G loss: 0.5864\n",
      "[724/1762] D loss: 1.3824, G loss: 0.8355\n",
      "[804/1762] D loss: 1.3334, G loss: 0.7727\n",
      "[884/1762] D loss: 1.3956, G loss: 0.8223\n",
      "[964/1762] D loss: 1.3694, G loss: 0.5219\n",
      "[1044/1762] D loss: 1.4011, G loss: 0.6482\n",
      "[1124/1762] D loss: 1.3970, G loss: 0.8558\n",
      "[1204/1762] D loss: 1.3686, G loss: 0.7924\n",
      "[1284/1762] D loss: 1.6063, G loss: 0.7249\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.6576\n",
      "[1444/1762] D loss: 1.4421, G loss: 0.6307\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.7011\n",
      "[1604/1762] D loss: 1.3204, G loss: 0.8441\n",
      "[1684/1762] D loss: 1.3960, G loss: 0.6804\n",
      "[1762/1762] D loss: 1.3761, G loss: 0.5896\n",
      "train error: \n",
      " D loss: 1.429921, G loss: 0.550263, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 74.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.438717, G loss: 0.549571, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980, G loss: 0.5710\n",
      "[84/1762] D loss: 1.3881, G loss: 0.9478\n",
      "[164/1762] D loss: 1.3907, G loss: 0.7278\n",
      "[244/1762] D loss: 1.3854, G loss: 0.6999\n",
      "[324/1762] D loss: 1.4334, G loss: 0.5588\n",
      "[404/1762] D loss: 1.6780, G loss: 0.5662\n",
      "[484/1762] D loss: 1.4711, G loss: 0.5082\n",
      "[564/1762] D loss: 1.4703, G loss: 0.6376\n",
      "[644/1762] D loss: 1.3855, G loss: 0.7727\n",
      "[724/1762] D loss: 1.2512, G loss: 0.8611\n",
      "[804/1762] D loss: 1.4118, G loss: 0.5513\n",
      "[884/1762] D loss: 1.3826, G loss: 0.6337\n",
      "[964/1762] D loss: 1.5850, G loss: 0.7088\n",
      "[1044/1762] D loss: 1.4023, G loss: 0.7582\n",
      "[1124/1762] D loss: 1.3063, G loss: 0.7908\n",
      "[1204/1762] D loss: 1.3072, G loss: 0.8345\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6512\n",
      "[1364/1762] D loss: 1.4331, G loss: 0.8818\n",
      "[1444/1762] D loss: 1.3306, G loss: 0.7352\n",
      "[1524/1762] D loss: 1.4021, G loss: 0.7683\n",
      "[1604/1762] D loss: 1.3996, G loss: 0.7673\n",
      "[1684/1762] D loss: 1.4079, G loss: 0.6269\n",
      "[1762/1762] D loss: 0.9512, G loss: 0.9927\n",
      "train error: \n",
      " D loss: 1.382698, G loss: 0.756482, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394497, G loss: 0.750267, D accuracy: 53.2%, cell accuracy: 99.6%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3592, G loss: 0.7429\n",
      "[84/1762] D loss: 1.3924, G loss: 0.7087\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6893\n",
      "[244/1762] D loss: 1.4341, G loss: 0.7408\n",
      "[324/1762] D loss: 1.4516, G loss: 0.7315\n",
      "[404/1762] D loss: 1.3872, G loss: 0.5688\n",
      "[484/1762] D loss: 1.3926, G loss: 0.7608\n",
      "[564/1762] D loss: 1.4208, G loss: 0.5982\n",
      "[644/1762] D loss: 1.2156, G loss: 0.7772\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7614\n",
      "[804/1762] D loss: 1.3978, G loss: 0.6184\n",
      "[884/1762] D loss: 1.3220, G loss: 0.6684\n",
      "[964/1762] D loss: 1.4097, G loss: 0.5977\n",
      "[1044/1762] D loss: 1.3977, G loss: 0.5594\n",
      "[1124/1762] D loss: 1.3703, G loss: 0.6168\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.5865\n",
      "[1284/1762] D loss: 1.2915, G loss: 0.8535\n",
      "[1364/1762] D loss: 1.4403, G loss: 0.7506\n",
      "[1444/1762] D loss: 1.3968, G loss: 0.6544\n",
      "[1524/1762] D loss: 1.3996, G loss: 0.5861\n",
      "[1604/1762] D loss: 1.2999, G loss: 0.7978\n",
      "[1684/1762] D loss: 1.3578, G loss: 0.6735\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.6489\n",
      "train error: \n",
      " D loss: 1.374192, G loss: 0.635471, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381355, G loss: 0.631397, D accuracy: 53.9%, cell accuracy: 99.6%, board accuracy: 70.2% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3595, G loss: 0.5715\n",
      "[84/1762] D loss: 1.3791, G loss: 0.6298\n",
      "[164/1762] D loss: 1.3449, G loss: 0.7237\n",
      "[244/1762] D loss: 1.3311, G loss: 0.7882\n",
      "[324/1762] D loss: 1.1574, G loss: 0.8302\n",
      "[404/1762] D loss: 1.3905, G loss: 0.6873\n",
      "[484/1762] D loss: 1.4113, G loss: 0.7995\n",
      "[564/1762] D loss: 1.4157, G loss: 0.6376\n",
      "[644/1762] D loss: 1.4299, G loss: 0.6466\n",
      "[724/1762] D loss: 1.4616, G loss: 0.6192\n",
      "[804/1762] D loss: 1.4212, G loss: 0.7448\n",
      "[884/1762] D loss: 1.3532, G loss: 0.9129\n",
      "[964/1762] D loss: 1.2676, G loss: 0.8674\n",
      "[1044/1762] D loss: 1.3230, G loss: 0.6291\n",
      "[1124/1762] D loss: 1.4237, G loss: 0.5797\n",
      "[1204/1762] D loss: 1.3692, G loss: 0.6749\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7346\n",
      "[1364/1762] D loss: 1.4662, G loss: 0.9291\n",
      "[1444/1762] D loss: 1.2727, G loss: 0.7907\n",
      "[1524/1762] D loss: 1.2575, G loss: 0.7951\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.6488\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.6824\n",
      "[1762/1762] D loss: 1.3432, G loss: 0.7797\n",
      "train error: \n",
      " D loss: 1.360264, G loss: 0.769512, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 75.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361705, G loss: 0.767581, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 70.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.7640\n",
      "[84/1762] D loss: 1.3838, G loss: 0.6524\n",
      "[164/1762] D loss: 1.3418, G loss: 0.7650\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6952\n",
      "[324/1762] D loss: 1.4133, G loss: 0.5592\n",
      "[404/1762] D loss: 1.2447, G loss: 0.7885\n",
      "[484/1762] D loss: 1.3115, G loss: 0.7951\n",
      "[564/1762] D loss: 1.3919, G loss: 0.9451\n",
      "[644/1762] D loss: 1.3881, G loss: 0.7927\n",
      "[724/1762] D loss: 1.3753, G loss: 0.6325\n",
      "[804/1762] D loss: 1.3909, G loss: 0.9200\n",
      "[884/1762] D loss: 1.3636, G loss: 0.7185\n",
      "[964/1762] D loss: 1.3964, G loss: 0.5840\n",
      "[1044/1762] D loss: 1.2909, G loss: 0.7330\n",
      "[1124/1762] D loss: 1.3191, G loss: 0.7780\n",
      "[1204/1762] D loss: 1.3214, G loss: 0.7395\n",
      "[1284/1762] D loss: 1.3702, G loss: 0.7919\n",
      "[1364/1762] D loss: 1.2990, G loss: 0.5585\n",
      "[1444/1762] D loss: 1.3856, G loss: 0.7101\n",
      "[1524/1762] D loss: 1.3663, G loss: 0.6346\n",
      "[1604/1762] D loss: 1.2222, G loss: 0.9464\n",
      "[1684/1762] D loss: 1.4102, G loss: 0.7962\n",
      "[1762/1762] D loss: 1.3835, G loss: 0.4608\n",
      "train error: \n",
      " D loss: 1.391556, G loss: 0.541961, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391831, G loss: 0.540741, D accuracy: 52.6%, cell accuracy: 99.6%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3221, G loss: 0.6071\n",
      "[84/1762] D loss: 1.2373, G loss: 0.9646\n",
      "[164/1762] D loss: 1.3433, G loss: 0.5984\n",
      "[244/1762] D loss: 1.2449, G loss: 0.9623\n",
      "[324/1762] D loss: 1.4169, G loss: 0.6653\n",
      "[404/1762] D loss: 1.3166, G loss: 0.7249\n",
      "[484/1762] D loss: 1.3841, G loss: 0.7582\n",
      "[564/1762] D loss: 1.2687, G loss: 0.8162\n",
      "[644/1762] D loss: 1.3773, G loss: 0.5732\n",
      "[724/1762] D loss: 1.3696, G loss: 0.6488\n",
      "[804/1762] D loss: 1.3577, G loss: 0.6299\n",
      "[884/1762] D loss: 1.1485, G loss: 1.0512\n",
      "[964/1762] D loss: 1.4088, G loss: 0.7430\n",
      "[1044/1762] D loss: 1.4114, G loss: 0.6344\n",
      "[1124/1762] D loss: 1.3951, G loss: 0.6508\n",
      "[1204/1762] D loss: 1.4398, G loss: 0.5378\n",
      "[1284/1762] D loss: 1.4510, G loss: 0.9638\n",
      "[1364/1762] D loss: 1.4010, G loss: 0.6542\n",
      "[1444/1762] D loss: 1.3533, G loss: 0.4789\n",
      "[1524/1762] D loss: 1.4093, G loss: 0.7940\n",
      "[1604/1762] D loss: 1.3947, G loss: 0.6737\n",
      "[1684/1762] D loss: 1.3240, G loss: 0.6798\n",
      "[1762/1762] D loss: 1.3990, G loss: 0.8013\n",
      "train error: \n",
      " D loss: 1.344145, G loss: 0.839018, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 75.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340665, G loss: 0.839505, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 70.7% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3640, G loss: 0.6924\n",
      "[84/1762] D loss: 1.3266, G loss: 0.7585\n",
      "[164/1762] D loss: 1.3928, G loss: 0.6999\n",
      "[244/1762] D loss: 1.4184, G loss: 0.6059\n",
      "[324/1762] D loss: 1.3224, G loss: 0.8523\n",
      "[404/1762] D loss: 0.9428, G loss: 1.2979\n",
      "[484/1762] D loss: 1.3958, G loss: 0.6816\n",
      "[564/1762] D loss: 1.2428, G loss: 0.6903\n",
      "[644/1762] D loss: 1.3489, G loss: 0.6293\n",
      "[724/1762] D loss: 1.0477, G loss: 1.0774\n",
      "[804/1762] D loss: 1.3574, G loss: 0.8453\n",
      "[884/1762] D loss: 1.4439, G loss: 0.7617\n",
      "[964/1762] D loss: 1.3948, G loss: 0.5587\n",
      "[1044/1762] D loss: 1.3061, G loss: 0.9605\n",
      "[1124/1762] D loss: 1.3139, G loss: 0.7033\n",
      "[1204/1762] D loss: 1.3462, G loss: 0.5767\n",
      "[1284/1762] D loss: 1.3980, G loss: 1.0015\n",
      "[1364/1762] D loss: 1.4092, G loss: 0.7950\n",
      "[1444/1762] D loss: 1.3138, G loss: 0.7773\n",
      "[1524/1762] D loss: 1.3826, G loss: 0.6908\n",
      "[1604/1762] D loss: 1.3131, G loss: 0.7465\n",
      "[1684/1762] D loss: 1.4016, G loss: 0.6219\n",
      "[1762/1762] D loss: 1.2088, G loss: 0.9858\n",
      "train error: \n",
      " D loss: 1.338659, G loss: 0.657064, D accuracy: 57.1%, cell accuracy: 99.7%, board accuracy: 75.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332555, G loss: 0.659131, D accuracy: 58.1%, cell accuracy: 99.6%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3850, G loss: 0.5524\n",
      "[84/1762] D loss: 1.3877, G loss: 0.8266\n",
      "[164/1762] D loss: 1.4140, G loss: 0.4817\n",
      "[244/1762] D loss: 1.3127, G loss: 1.0049\n",
      "[324/1762] D loss: 1.2904, G loss: 0.6693\n",
      "[404/1762] D loss: 1.4203, G loss: 0.8005\n",
      "[484/1762] D loss: 1.0836, G loss: 1.0054\n",
      "[564/1762] D loss: 1.3726, G loss: 0.7431\n",
      "[644/1762] D loss: 1.3566, G loss: 0.8495\n",
      "[724/1762] D loss: 1.2744, G loss: 0.7683\n",
      "[804/1762] D loss: 1.3877, G loss: 0.8263\n",
      "[884/1762] D loss: 1.2899, G loss: 0.7280\n",
      "[964/1762] D loss: 1.3973, G loss: 0.7401\n",
      "[1044/1762] D loss: 1.4554, G loss: 0.8283\n",
      "[1124/1762] D loss: 1.3816, G loss: 0.6447\n",
      "[1204/1762] D loss: 1.3800, G loss: 0.5840\n",
      "[1284/1762] D loss: 1.4027, G loss: 0.7663\n",
      "[1364/1762] D loss: 1.4120, G loss: 0.7817\n",
      "[1444/1762] D loss: 1.4558, G loss: 0.4815\n",
      "[1524/1762] D loss: 1.3088, G loss: 0.7633\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.7202\n",
      "[1684/1762] D loss: 1.2951, G loss: 0.8666\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6976\n",
      "train error: \n",
      " D loss: 1.361254, G loss: 0.804098, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 73.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358245, G loss: 0.805722, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4055, G loss: 0.6790\n",
      "[84/1762] D loss: 1.3200, G loss: 1.0158\n",
      "[164/1762] D loss: 1.3333, G loss: 0.7518\n",
      "[244/1762] D loss: 1.4123, G loss: 0.5812\n",
      "[324/1762] D loss: 1.5106, G loss: 0.6384\n",
      "[404/1762] D loss: 1.2951, G loss: 1.0137\n",
      "[484/1762] D loss: 1.4102, G loss: 0.7691\n",
      "[564/1762] D loss: 1.3995, G loss: 0.7475\n",
      "[644/1762] D loss: 1.2950, G loss: 0.7685\n",
      "[724/1762] D loss: 1.2680, G loss: 0.6193\n",
      "[804/1762] D loss: 1.3061, G loss: 0.7422\n",
      "[884/1762] D loss: 1.2894, G loss: 0.9034\n",
      "[964/1762] D loss: 1.3622, G loss: 0.9112\n",
      "[1044/1762] D loss: 1.3625, G loss: 0.9430\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.7087\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.7143\n",
      "[1284/1762] D loss: 1.4023, G loss: 0.6510\n",
      "[1364/1762] D loss: 1.4128, G loss: 0.6825\n",
      "[1444/1762] D loss: 1.3046, G loss: 1.0060\n",
      "[1524/1762] D loss: 1.3975, G loss: 0.7885\n",
      "[1604/1762] D loss: 1.3129, G loss: 0.7168\n",
      "[1684/1762] D loss: 1.3735, G loss: 0.7316\n",
      "[1762/1762] D loss: 1.1474, G loss: 0.8006\n",
      "train error: \n",
      " D loss: 1.393628, G loss: 0.523301, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 73.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384650, G loss: 0.528774, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4682, G loss: 0.4509\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7983\n",
      "[164/1762] D loss: 1.2573, G loss: 0.8595\n",
      "[244/1762] D loss: 1.4158, G loss: 0.8426\n",
      "[324/1762] D loss: 1.4230, G loss: 0.8449\n",
      "[404/1762] D loss: 1.3840, G loss: 0.7560\n",
      "[484/1762] D loss: 1.4988, G loss: 0.4942\n",
      "[564/1762] D loss: 1.3515, G loss: 0.8415\n",
      "[644/1762] D loss: 1.4048, G loss: 0.5671\n",
      "[724/1762] D loss: 1.3161, G loss: 0.7938\n",
      "[804/1762] D loss: 1.3903, G loss: 0.7855\n",
      "[884/1762] D loss: 1.3705, G loss: 0.8326\n",
      "[964/1762] D loss: 1.3107, G loss: 0.7055\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.8218\n",
      "[1124/1762] D loss: 1.3723, G loss: 0.5502\n",
      "[1204/1762] D loss: 1.1233, G loss: 0.8217\n",
      "[1284/1762] D loss: 1.2716, G loss: 0.7591\n",
      "[1364/1762] D loss: 1.3835, G loss: 0.7284\n",
      "[1444/1762] D loss: 1.3813, G loss: 0.6574\n",
      "[1524/1762] D loss: 1.4309, G loss: 0.6529\n",
      "[1604/1762] D loss: 1.2866, G loss: 0.7150\n",
      "[1684/1762] D loss: 1.2720, G loss: 1.0522\n",
      "[1762/1762] D loss: 1.2626, G loss: 0.7821\n",
      "train error: \n",
      " D loss: 1.360500, G loss: 0.605385, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355472, G loss: 0.601351, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2857, G loss: 0.6028\n",
      "[84/1762] D loss: 1.2667, G loss: 0.9099\n",
      "[164/1762] D loss: 1.3583, G loss: 0.7526\n",
      "[244/1762] D loss: 1.2924, G loss: 0.8408\n",
      "[324/1762] D loss: 1.1881, G loss: 0.8857\n",
      "[404/1762] D loss: 1.3812, G loss: 0.6906\n",
      "[484/1762] D loss: 1.3439, G loss: 0.7483\n",
      "[564/1762] D loss: 1.3968, G loss: 0.6732\n",
      "[644/1762] D loss: 1.3337, G loss: 0.6039\n",
      "[724/1762] D loss: 1.3882, G loss: 0.6770\n",
      "[804/1762] D loss: 1.3991, G loss: 0.7456\n",
      "[884/1762] D loss: 1.3271, G loss: 0.7441\n",
      "[964/1762] D loss: 1.2996, G loss: 0.8310\n",
      "[1044/1762] D loss: 1.3075, G loss: 0.7247\n",
      "[1124/1762] D loss: 1.2909, G loss: 0.8487\n",
      "[1204/1762] D loss: 1.4127, G loss: 0.6361\n",
      "[1284/1762] D loss: 1.4180, G loss: 0.7451\n",
      "[1364/1762] D loss: 1.2116, G loss: 0.6807\n",
      "[1444/1762] D loss: 1.2971, G loss: 0.7646\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.6918\n",
      "[1604/1762] D loss: 1.3555, G loss: 0.7620\n",
      "[1684/1762] D loss: 1.3853, G loss: 0.6451\n",
      "[1762/1762] D loss: 1.3748, G loss: 0.7076\n",
      "train error: \n",
      " D loss: 1.372133, G loss: 0.594354, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369530, G loss: 0.592489, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.6524\n",
      "[84/1762] D loss: 1.2997, G loss: 0.9480\n",
      "[164/1762] D loss: 1.3605, G loss: 0.7666\n",
      "[244/1762] D loss: 1.3420, G loss: 0.5869\n",
      "[324/1762] D loss: 1.4023, G loss: 0.8713\n",
      "[404/1762] D loss: 1.4251, G loss: 0.7113\n",
      "[484/1762] D loss: 1.4653, G loss: 0.5685\n",
      "[564/1762] D loss: 1.4232, G loss: 0.8163\n",
      "[644/1762] D loss: 1.4385, G loss: 0.7128\n",
      "[724/1762] D loss: 1.3670, G loss: 0.7116\n",
      "[804/1762] D loss: 1.3643, G loss: 0.8177\n",
      "[884/1762] D loss: 1.4158, G loss: 0.6254\n",
      "[964/1762] D loss: 1.3940, G loss: 0.7030\n",
      "[1044/1762] D loss: 1.3998, G loss: 0.9390\n",
      "[1124/1762] D loss: 1.4160, G loss: 0.7088\n",
      "[1204/1762] D loss: 1.2205, G loss: 0.9501\n",
      "[1284/1762] D loss: 1.3106, G loss: 0.8542\n",
      "[1364/1762] D loss: 1.3497, G loss: 0.8967\n",
      "[1444/1762] D loss: 1.3108, G loss: 0.7408\n",
      "[1524/1762] D loss: 1.4400, G loss: 0.8773\n",
      "[1604/1762] D loss: 1.4457, G loss: 1.0217\n",
      "[1684/1762] D loss: 1.3982, G loss: 0.7378\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7142\n",
      "train error: \n",
      " D loss: 1.368509, G loss: 0.746437, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367690, G loss: 0.744746, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921, G loss: 0.7044\n",
      "[84/1762] D loss: 1.4106, G loss: 0.5960\n",
      "[164/1762] D loss: 1.3274, G loss: 0.7354\n",
      "[244/1762] D loss: 1.3619, G loss: 0.7995\n",
      "[324/1762] D loss: 1.4335, G loss: 0.7606\n",
      "[404/1762] D loss: 1.3918, G loss: 0.6895\n",
      "[484/1762] D loss: 1.4487, G loss: 0.9632\n",
      "[564/1762] D loss: 1.3884, G loss: 0.6404\n",
      "[644/1762] D loss: 1.4413, G loss: 0.5120\n",
      "[724/1762] D loss: 1.2984, G loss: 0.6872\n",
      "[804/1762] D loss: 1.4073, G loss: 0.8246\n",
      "[884/1762] D loss: 1.4373, G loss: 0.8254\n",
      "[964/1762] D loss: 1.3328, G loss: 0.9048\n",
      "[1044/1762] D loss: 1.3858, G loss: 0.6834\n",
      "[1124/1762] D loss: 1.4165, G loss: 0.5645\n",
      "[1204/1762] D loss: 1.3932, G loss: 0.6634\n",
      "[1284/1762] D loss: 1.3200, G loss: 0.7650\n",
      "[1364/1762] D loss: 1.2268, G loss: 0.7880\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.6882\n",
      "[1524/1762] D loss: 1.1998, G loss: 0.7429\n",
      "[1604/1762] D loss: 1.3118, G loss: 0.7839\n",
      "[1684/1762] D loss: 1.2954, G loss: 0.7236\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.7289\n",
      "train error: \n",
      " D loss: 1.363049, G loss: 0.833554, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355930, G loss: 0.838960, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4063, G loss: 0.8615\n",
      "[84/1762] D loss: 1.2304, G loss: 0.7747\n",
      "[164/1762] D loss: 1.2784, G loss: 0.8195\n",
      "[244/1762] D loss: 1.3856, G loss: 0.9150\n",
      "[324/1762] D loss: 1.3997, G loss: 0.7390\n",
      "[404/1762] D loss: 1.3905, G loss: 0.5310\n",
      "[484/1762] D loss: 1.3947, G loss: 0.7150\n",
      "[564/1762] D loss: 1.2686, G loss: 0.8369\n",
      "[644/1762] D loss: 1.3938, G loss: 0.6507\n",
      "[724/1762] D loss: 1.3898, G loss: 0.7208\n",
      "[804/1762] D loss: 1.3049, G loss: 0.8263\n",
      "[884/1762] D loss: 1.2986, G loss: 0.9413\n",
      "[964/1762] D loss: 1.4146, G loss: 0.6293\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.6617\n",
      "[1124/1762] D loss: 1.2921, G loss: 0.7026\n",
      "[1204/1762] D loss: 1.3964, G loss: 0.5741\n",
      "[1284/1762] D loss: 1.3945, G loss: 0.7442\n",
      "[1364/1762] D loss: 1.4077, G loss: 0.6649\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.7449\n",
      "[1524/1762] D loss: 1.3932, G loss: 0.7818\n",
      "[1604/1762] D loss: 1.3916, G loss: 0.6353\n",
      "[1684/1762] D loss: 1.3905, G loss: 0.6437\n",
      "[1762/1762] D loss: 1.1391, G loss: 0.8902\n",
      "train error: \n",
      " D loss: 1.350494, G loss: 0.697153, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339819, G loss: 0.704483, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6931\n",
      "[84/1762] D loss: 1.4265, G loss: 0.7830\n",
      "[164/1762] D loss: 1.3707, G loss: 0.6833\n",
      "[244/1762] D loss: 1.4065, G loss: 0.6871\n",
      "[324/1762] D loss: 1.2609, G loss: 0.7917\n",
      "[404/1762] D loss: 1.2796, G loss: 0.8632\n",
      "[484/1762] D loss: 1.4059, G loss: 0.6192\n",
      "[564/1762] D loss: 1.3742, G loss: 0.7263\n",
      "[644/1762] D loss: 1.3921, G loss: 0.7621\n",
      "[724/1762] D loss: 1.4275, G loss: 0.5860\n",
      "[804/1762] D loss: 1.3989, G loss: 0.6666\n",
      "[884/1762] D loss: 1.4346, G loss: 0.5256\n",
      "[964/1762] D loss: 1.4016, G loss: 0.7344\n",
      "[1044/1762] D loss: 1.3923, G loss: 0.7897\n",
      "[1124/1762] D loss: 1.3266, G loss: 0.7289\n",
      "[1204/1762] D loss: 1.2612, G loss: 0.8986\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.7527\n",
      "[1364/1762] D loss: 1.3933, G loss: 0.7095\n",
      "[1444/1762] D loss: 1.4086, G loss: 0.7652\n",
      "[1524/1762] D loss: 1.3923, G loss: 0.7377\n",
      "[1604/1762] D loss: 1.2580, G loss: 0.8191\n",
      "[1684/1762] D loss: 1.3994, G loss: 0.8243\n",
      "[1762/1762] D loss: 1.4196, G loss: 0.7146\n",
      "train error: \n",
      " D loss: 1.343480, G loss: 0.728299, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334873, G loss: 0.736001, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2429, G loss: 0.9142\n",
      "[84/1762] D loss: 1.3923, G loss: 0.5726\n",
      "[164/1762] D loss: 1.4021, G loss: 0.7498\n",
      "[244/1762] D loss: 1.4042, G loss: 0.6997\n",
      "[324/1762] D loss: 1.3897, G loss: 0.8022\n",
      "[404/1762] D loss: 1.3364, G loss: 0.7077\n",
      "[484/1762] D loss: 1.3993, G loss: 0.7621\n",
      "[564/1762] D loss: 1.2793, G loss: 0.8350\n",
      "[644/1762] D loss: 1.2899, G loss: 0.6925\n",
      "[724/1762] D loss: 1.1425, G loss: 0.9478\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6407\n",
      "[884/1762] D loss: 1.3685, G loss: 0.6533\n",
      "[964/1762] D loss: 1.3994, G loss: 0.6184\n",
      "[1044/1762] D loss: 1.3632, G loss: 0.7326\n",
      "[1124/1762] D loss: 1.2784, G loss: 1.1229\n",
      "[1204/1762] D loss: 1.3507, G loss: 0.6391\n",
      "[1284/1762] D loss: 1.3567, G loss: 0.7483\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.7781\n",
      "[1444/1762] D loss: 1.3645, G loss: 0.7191\n",
      "[1524/1762] D loss: 1.2375, G loss: 0.7962\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.7741\n",
      "[1684/1762] D loss: 1.3608, G loss: 0.6897\n",
      "[1762/1762] D loss: 1.4188, G loss: 0.5024\n",
      "train error: \n",
      " D loss: 1.360132, G loss: 0.598407, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350819, G loss: 0.604305, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4528, G loss: 0.5662\n",
      "[84/1762] D loss: 1.4068, G loss: 0.6908\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6745\n",
      "[244/1762] D loss: 1.3913, G loss: 0.5874\n",
      "[324/1762] D loss: 1.4056, G loss: 0.7213\n",
      "[404/1762] D loss: 1.2297, G loss: 0.8210\n",
      "[484/1762] D loss: 1.4133, G loss: 0.7292\n",
      "[564/1762] D loss: 1.3986, G loss: 0.7161\n",
      "[644/1762] D loss: 1.1655, G loss: 0.8937\n",
      "[724/1762] D loss: 1.3951, G loss: 0.7781\n",
      "[804/1762] D loss: 1.3996, G loss: 0.7184\n",
      "[884/1762] D loss: 1.0571, G loss: 1.0411\n",
      "[964/1762] D loss: 1.3743, G loss: 0.6597\n",
      "[1044/1762] D loss: 1.4103, G loss: 0.7316\n",
      "[1124/1762] D loss: 1.3852, G loss: 0.6906\n",
      "[1204/1762] D loss: 1.0746, G loss: 1.0158\n",
      "[1284/1762] D loss: 1.2717, G loss: 0.8896\n",
      "[1364/1762] D loss: 1.4117, G loss: 0.5621\n",
      "[1444/1762] D loss: 1.3008, G loss: 0.6746\n",
      "[1524/1762] D loss: 1.2346, G loss: 0.8291\n",
      "[1604/1762] D loss: 1.3118, G loss: 0.7883\n",
      "[1684/1762] D loss: 1.4146, G loss: 0.8105\n",
      "[1762/1762] D loss: 1.0608, G loss: 0.7482\n",
      "train error: \n",
      " D loss: 1.355003, G loss: 0.600902, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345726, G loss: 0.606304, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904, G loss: 0.6029\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6920\n",
      "[164/1762] D loss: 1.4079, G loss: 0.7712\n",
      "[244/1762] D loss: 1.3900, G loss: 0.6411\n",
      "[324/1762] D loss: 1.3854, G loss: 0.7070\n",
      "[404/1762] D loss: 1.0937, G loss: 0.8903\n",
      "[484/1762] D loss: 1.2550, G loss: 0.8722\n",
      "[564/1762] D loss: 1.3893, G loss: 0.7486\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6552\n",
      "[724/1762] D loss: 1.3946, G loss: 0.6679\n",
      "[804/1762] D loss: 1.2390, G loss: 0.7598\n",
      "[884/1762] D loss: 1.4475, G loss: 0.8463\n",
      "[964/1762] D loss: 1.2245, G loss: 0.8044\n",
      "[1044/1762] D loss: 1.4036, G loss: 0.6543\n",
      "[1124/1762] D loss: 1.2080, G loss: 0.8403\n",
      "[1204/1762] D loss: 1.4041, G loss: 0.5902\n",
      "[1284/1762] D loss: 1.1450, G loss: 0.9622\n",
      "[1364/1762] D loss: 1.3921, G loss: 0.6951\n",
      "[1444/1762] D loss: 1.2178, G loss: 0.8228\n",
      "[1524/1762] D loss: 1.2823, G loss: 0.9519\n",
      "[1604/1762] D loss: 1.4029, G loss: 0.6688\n",
      "[1684/1762] D loss: 1.2723, G loss: 0.8506\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.6945\n",
      "train error: \n",
      " D loss: 1.332915, G loss: 0.761319, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323521, G loss: 0.767714, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005, G loss: 0.7480\n",
      "[84/1762] D loss: 1.0764, G loss: 0.9951\n",
      "[164/1762] D loss: 1.1224, G loss: 0.8111\n",
      "[244/1762] D loss: 1.3026, G loss: 0.9700\n",
      "[324/1762] D loss: 1.4064, G loss: 0.8114\n",
      "[404/1762] D loss: 1.3450, G loss: 0.9058\n",
      "[484/1762] D loss: 1.3330, G loss: 0.9416\n",
      "[564/1762] D loss: 1.4091, G loss: 0.5626\n",
      "[644/1762] D loss: 1.4084, G loss: 0.7475\n",
      "[724/1762] D loss: 1.3869, G loss: 0.5312\n",
      "[804/1762] D loss: 1.4044, G loss: 0.7031\n",
      "[884/1762] D loss: 0.9343, G loss: 1.0405\n",
      "[964/1762] D loss: 1.4124, G loss: 0.5859\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.8112\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7316\n",
      "[1204/1762] D loss: 1.3953, G loss: 0.6320\n",
      "[1284/1762] D loss: 1.4059, G loss: 0.7324\n",
      "[1364/1762] D loss: 1.4020, G loss: 0.7221\n",
      "[1444/1762] D loss: 1.3948, G loss: 0.6641\n",
      "[1524/1762] D loss: 1.1942, G loss: 0.8301\n",
      "[1604/1762] D loss: 1.3543, G loss: 0.7950\n",
      "[1684/1762] D loss: 1.2101, G loss: 0.6427\n",
      "[1762/1762] D loss: 1.4240, G loss: 0.7957\n",
      "train error: \n",
      " D loss: 1.336069, G loss: 0.764066, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324260, G loss: 0.777076, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2204, G loss: 0.8665\n",
      "[84/1762] D loss: 1.3935, G loss: 0.6407\n",
      "[164/1762] D loss: 1.4007, G loss: 0.7379\n",
      "[244/1762] D loss: 1.3830, G loss: 0.6536\n",
      "[324/1762] D loss: 1.3635, G loss: 0.8051\n",
      "[404/1762] D loss: 1.2149, G loss: 0.6501\n",
      "[484/1762] D loss: 1.3849, G loss: 0.8025\n",
      "[564/1762] D loss: 1.4089, G loss: 0.7384\n",
      "[644/1762] D loss: 1.4028, G loss: 0.7587\n",
      "[724/1762] D loss: 1.3898, G loss: 0.6429\n",
      "[804/1762] D loss: 1.1552, G loss: 0.9226\n",
      "[884/1762] D loss: 1.2161, G loss: 0.8599\n",
      "[964/1762] D loss: 1.4089, G loss: 0.8637\n",
      "[1044/1762] D loss: 1.1520, G loss: 0.8876\n",
      "[1124/1762] D loss: 1.4045, G loss: 0.7178\n",
      "[1204/1762] D loss: 1.3960, G loss: 0.7282\n",
      "[1284/1762] D loss: 1.1042, G loss: 1.4111\n",
      "[1364/1762] D loss: 1.2048, G loss: 0.8550\n",
      "[1444/1762] D loss: 1.4028, G loss: 0.5189\n",
      "[1524/1762] D loss: 1.0273, G loss: 0.9399\n",
      "[1604/1762] D loss: 1.2309, G loss: 0.8520\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6710\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6186\n",
      "train error: \n",
      " D loss: 1.330018, G loss: 0.704670, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322809, G loss: 0.707170, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3005, G loss: 0.7350\n",
      "[84/1762] D loss: 1.3906, G loss: 0.7487\n",
      "[164/1762] D loss: 1.4236, G loss: 0.8793\n",
      "[244/1762] D loss: 1.3911, G loss: 0.6622\n",
      "[324/1762] D loss: 1.2044, G loss: 0.7375\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7724\n",
      "[484/1762] D loss: 1.4095, G loss: 0.8471\n",
      "[564/1762] D loss: 1.4104, G loss: 0.7272\n",
      "[644/1762] D loss: 1.2139, G loss: 0.8080\n",
      "[724/1762] D loss: 1.4541, G loss: 0.9832\n",
      "[804/1762] D loss: 1.4319, G loss: 0.9102\n",
      "[884/1762] D loss: 1.3524, G loss: 0.6465\n",
      "[964/1762] D loss: 1.1945, G loss: 0.9630\n",
      "[1044/1762] D loss: 1.2094, G loss: 0.8493\n",
      "[1124/1762] D loss: 1.4018, G loss: 0.7453\n",
      "[1204/1762] D loss: 1.3904, G loss: 0.7736\n",
      "[1284/1762] D loss: 1.2140, G loss: 0.6452\n",
      "[1364/1762] D loss: 1.4325, G loss: 0.5541\n",
      "[1444/1762] D loss: 1.2490, G loss: 0.8148\n",
      "[1524/1762] D loss: 1.3233, G loss: 0.7951\n",
      "[1604/1762] D loss: 1.1896, G loss: 0.9223\n",
      "[1684/1762] D loss: 1.3982, G loss: 0.7275\n",
      "[1762/1762] D loss: 0.9740, G loss: 0.9890\n",
      "train error: \n",
      " D loss: 1.322927, G loss: 0.821318, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 73.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310359, G loss: 0.832696, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1542, G loss: 0.8810\n",
      "[84/1762] D loss: 1.3917, G loss: 0.5881\n",
      "[164/1762] D loss: 1.3947, G loss: 0.9095\n",
      "[244/1762] D loss: 1.3911, G loss: 0.6990\n",
      "[324/1762] D loss: 1.3372, G loss: 0.8188\n",
      "[404/1762] D loss: 1.2405, G loss: 0.9061\n",
      "[484/1762] D loss: 1.1508, G loss: 0.7324\n",
      "[564/1762] D loss: 1.3335, G loss: 0.6940\n",
      "[644/1762] D loss: 1.3971, G loss: 0.6055\n",
      "[724/1762] D loss: 1.3328, G loss: 0.7822\n",
      "[804/1762] D loss: 1.3896, G loss: 0.8047\n",
      "[884/1762] D loss: 1.4433, G loss: 0.7225\n",
      "[964/1762] D loss: 1.4392, G loss: 0.5301\n",
      "[1044/1762] D loss: 1.3994, G loss: 0.9171\n",
      "[1124/1762] D loss: 1.3490, G loss: 0.9495\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.7741\n",
      "[1284/1762] D loss: 1.2322, G loss: 0.6263\n",
      "[1364/1762] D loss: 1.2942, G loss: 0.8870\n",
      "[1444/1762] D loss: 1.4235, G loss: 0.5725\n",
      "[1524/1762] D loss: 1.0440, G loss: 0.8217\n",
      "[1604/1762] D loss: 1.3212, G loss: 0.8590\n",
      "[1684/1762] D loss: 1.2375, G loss: 0.8150\n",
      "[1762/1762] D loss: 1.4812, G loss: 0.5937\n",
      "train error: \n",
      " D loss: 1.321885, G loss: 0.848392, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307221, G loss: 0.856714, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4101, G loss: 0.9560\n",
      "[84/1762] D loss: 1.3897, G loss: 0.6257\n",
      "[164/1762] D loss: 1.1789, G loss: 0.8321\n",
      "[244/1762] D loss: 1.2714, G loss: 0.6908\n",
      "[324/1762] D loss: 1.1270, G loss: 0.8219\n",
      "[404/1762] D loss: 1.4007, G loss: 0.8068\n",
      "[484/1762] D loss: 1.3940, G loss: 0.6553\n",
      "[564/1762] D loss: 1.3812, G loss: 0.6861\n",
      "[644/1762] D loss: 1.3870, G loss: 0.8609\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6566\n",
      "[804/1762] D loss: 1.2001, G loss: 0.8744\n",
      "[884/1762] D loss: 1.3886, G loss: 0.5820\n",
      "[964/1762] D loss: 1.3984, G loss: 0.6931\n",
      "[1044/1762] D loss: 1.3947, G loss: 0.5904\n",
      "[1124/1762] D loss: 1.2069, G loss: 0.7932\n",
      "[1204/1762] D loss: 1.4400, G loss: 1.0380\n",
      "[1284/1762] D loss: 1.1828, G loss: 0.9847\n",
      "[1364/1762] D loss: 1.4181, G loss: 0.7412\n",
      "[1444/1762] D loss: 1.1762, G loss: 1.0142\n",
      "[1524/1762] D loss: 1.4833, G loss: 0.8452\n",
      "[1604/1762] D loss: 1.4382, G loss: 0.4718\n",
      "[1684/1762] D loss: 1.3138, G loss: 0.7115\n",
      "[1762/1762] D loss: 1.4268, G loss: 0.8158\n",
      "train error: \n",
      " D loss: 1.350913, G loss: 0.964469, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336614, G loss: 0.974934, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2948, G loss: 0.8327\n",
      "[84/1762] D loss: 1.3051, G loss: 0.9701\n",
      "[164/1762] D loss: 1.4056, G loss: 0.7386\n",
      "[244/1762] D loss: 1.3989, G loss: 0.6554\n",
      "[324/1762] D loss: 1.2997, G loss: 0.7124\n",
      "[404/1762] D loss: 1.4028, G loss: 0.6476\n",
      "[484/1762] D loss: 1.4040, G loss: 0.6404\n",
      "[564/1762] D loss: 1.1708, G loss: 0.9904\n",
      "[644/1762] D loss: 1.4185, G loss: 0.8001\n",
      "[724/1762] D loss: 1.2703, G loss: 0.6646\n",
      "[804/1762] D loss: 1.3951, G loss: 0.6911\n",
      "[884/1762] D loss: 1.3650, G loss: 0.8605\n",
      "[964/1762] D loss: 1.1897, G loss: 0.7895\n",
      "[1044/1762] D loss: 1.1798, G loss: 1.0933\n",
      "[1124/1762] D loss: 1.3000, G loss: 0.6608\n",
      "[1204/1762] D loss: 1.1894, G loss: 0.8192\n",
      "[1284/1762] D loss: 1.4946, G loss: 0.4848\n",
      "[1364/1762] D loss: 1.4374, G loss: 0.8093\n",
      "[1444/1762] D loss: 1.1674, G loss: 0.7994\n",
      "[1524/1762] D loss: 1.3104, G loss: 0.8400\n",
      "[1604/1762] D loss: 1.1704, G loss: 0.9363\n",
      "[1684/1762] D loss: 1.4000, G loss: 0.5925\n",
      "[1762/1762] D loss: 1.3855, G loss: 0.7950\n",
      "train error: \n",
      " D loss: 1.322727, G loss: 0.752592, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304430, G loss: 0.767404, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2282, G loss: 1.0381\n",
      "[84/1762] D loss: 1.4058, G loss: 0.5660\n",
      "[164/1762] D loss: 1.2074, G loss: 0.7010\n",
      "[244/1762] D loss: 1.3953, G loss: 0.7339\n",
      "[324/1762] D loss: 1.3905, G loss: 0.6064\n",
      "[404/1762] D loss: 1.1659, G loss: 0.8602\n",
      "[484/1762] D loss: 1.4008, G loss: 0.6466\n",
      "[564/1762] D loss: 1.2767, G loss: 0.8731\n",
      "[644/1762] D loss: 1.4070, G loss: 0.8149\n",
      "[724/1762] D loss: 1.3977, G loss: 0.7017\n",
      "[804/1762] D loss: 1.3395, G loss: 1.0947\n",
      "[884/1762] D loss: 1.1891, G loss: 0.7909\n",
      "[964/1762] D loss: 1.3947, G loss: 0.5397\n",
      "[1044/1762] D loss: 1.4073, G loss: 0.8075\n",
      "[1124/1762] D loss: 1.3549, G loss: 0.6245\n",
      "[1204/1762] D loss: 1.4242, G loss: 0.8278\n",
      "[1284/1762] D loss: 1.4151, G loss: 0.8178\n",
      "[1364/1762] D loss: 1.4124, G loss: 0.5724\n",
      "[1444/1762] D loss: 1.3958, G loss: 0.8170\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.6149\n",
      "[1604/1762] D loss: 1.4384, G loss: 0.8015\n",
      "[1684/1762] D loss: 1.4044, G loss: 0.8280\n",
      "[1762/1762] D loss: 1.3784, G loss: 0.6666\n",
      "train error: \n",
      " D loss: 1.328829, G loss: 0.689397, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314228, G loss: 0.702112, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1707, G loss: 0.6874\n",
      "[84/1762] D loss: 1.1957, G loss: 1.1538\n",
      "[164/1762] D loss: 1.0609, G loss: 0.6140\n",
      "[244/1762] D loss: 1.4206, G loss: 0.5858\n",
      "[324/1762] D loss: 1.3794, G loss: 0.8440\n",
      "[404/1762] D loss: 1.3885, G loss: 0.7557\n",
      "[484/1762] D loss: 1.3871, G loss: 0.7075\n",
      "[564/1762] D loss: 1.4004, G loss: 0.7525\n",
      "[644/1762] D loss: 1.1586, G loss: 0.8099\n",
      "[724/1762] D loss: 1.4840, G loss: 0.4710\n",
      "[804/1762] D loss: 1.3859, G loss: 0.6277\n",
      "[884/1762] D loss: 1.4238, G loss: 0.6767\n",
      "[964/1762] D loss: 1.3922, G loss: 0.6735\n",
      "[1044/1762] D loss: 1.4069, G loss: 0.8612\n",
      "[1124/1762] D loss: 1.3849, G loss: 0.6501\n",
      "[1204/1762] D loss: 1.2977, G loss: 0.9843\n",
      "[1284/1762] D loss: 1.2856, G loss: 0.8333\n",
      "[1364/1762] D loss: 1.4515, G loss: 0.7437\n",
      "[1444/1762] D loss: 1.4010, G loss: 0.7272\n",
      "[1524/1762] D loss: 1.3456, G loss: 0.7757\n",
      "[1604/1762] D loss: 1.0893, G loss: 0.9050\n",
      "[1684/1762] D loss: 1.3845, G loss: 0.5781\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6978\n",
      "train error: \n",
      " D loss: 1.320049, G loss: 0.745145, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302265, G loss: 0.763747, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3667, G loss: 0.7315\n",
      "[84/1762] D loss: 1.3952, G loss: 0.6662\n",
      "[164/1762] D loss: 1.3957, G loss: 0.5988\n",
      "[244/1762] D loss: 1.4011, G loss: 0.6318\n",
      "[324/1762] D loss: 1.3954, G loss: 0.6564\n",
      "[404/1762] D loss: 1.4078, G loss: 0.6876\n",
      "[484/1762] D loss: 1.3881, G loss: 0.9248\n",
      "[564/1762] D loss: 1.4008, G loss: 0.6093\n",
      "[644/1762] D loss: 1.2893, G loss: 0.9562\n",
      "[724/1762] D loss: 1.3961, G loss: 0.7119\n",
      "[804/1762] D loss: 1.4057, G loss: 0.6948\n",
      "[884/1762] D loss: 1.3961, G loss: 0.8015\n",
      "[964/1762] D loss: 1.1880, G loss: 0.9423\n",
      "[1044/1762] D loss: 1.4442, G loss: 0.5204\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.6843\n",
      "[1204/1762] D loss: 1.3957, G loss: 0.7096\n",
      "[1284/1762] D loss: 0.8900, G loss: 1.1747\n",
      "[1364/1762] D loss: 1.1514, G loss: 0.9225\n",
      "[1444/1762] D loss: 1.4207, G loss: 0.7197\n",
      "[1524/1762] D loss: 1.1724, G loss: 0.8565\n",
      "[1604/1762] D loss: 1.3973, G loss: 0.6118\n",
      "[1684/1762] D loss: 1.4030, G loss: 0.6324\n",
      "[1762/1762] D loss: 1.4025, G loss: 0.6946\n",
      "train error: \n",
      " D loss: 1.325213, G loss: 0.762055, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302046, G loss: 0.781588, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3989, G loss: 0.6269\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6680\n",
      "[164/1762] D loss: 1.2576, G loss: 0.7326\n",
      "[244/1762] D loss: 1.3931, G loss: 0.6973\n",
      "[324/1762] D loss: 1.1750, G loss: 0.8893\n",
      "[404/1762] D loss: 1.4269, G loss: 0.9237\n",
      "[484/1762] D loss: 1.1431, G loss: 0.9466\n",
      "[564/1762] D loss: 1.4080, G loss: 0.8718\n",
      "[644/1762] D loss: 1.4198, G loss: 0.5700\n",
      "[724/1762] D loss: 1.4540, G loss: 0.9318\n",
      "[804/1762] D loss: 1.4065, G loss: 0.7584\n",
      "[884/1762] D loss: 1.4377, G loss: 0.5884\n",
      "[964/1762] D loss: 1.4033, G loss: 0.7286\n",
      "[1044/1762] D loss: 1.1651, G loss: 0.8389\n",
      "[1124/1762] D loss: 1.1547, G loss: 0.9707\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7500\n",
      "[1284/1762] D loss: 1.4024, G loss: 0.6117\n",
      "[1364/1762] D loss: 1.3964, G loss: 0.5852\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7676\n",
      "[1524/1762] D loss: 1.1693, G loss: 0.7639\n",
      "[1604/1762] D loss: 1.4219, G loss: 0.6215\n",
      "[1684/1762] D loss: 1.4126, G loss: 0.7564\n",
      "[1762/1762] D loss: 1.4727, G loss: 0.5122\n",
      "train error: \n",
      " D loss: 1.339713, G loss: 0.636585, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322250, G loss: 0.650586, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4394, G loss: 0.6644\n",
      "[84/1762] D loss: 1.4006, G loss: 0.9036\n",
      "[164/1762] D loss: 1.4058, G loss: 0.7789\n",
      "[244/1762] D loss: 1.4058, G loss: 0.7854\n",
      "[324/1762] D loss: 1.1436, G loss: 0.9425\n",
      "[404/1762] D loss: 1.3968, G loss: 0.7417\n",
      "[484/1762] D loss: 1.4132, G loss: 0.8909\n",
      "[564/1762] D loss: 1.4178, G loss: 0.6982\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6577\n",
      "[724/1762] D loss: 1.2513, G loss: 0.8380\n",
      "[804/1762] D loss: 1.4388, G loss: 0.5735\n",
      "[884/1762] D loss: 1.3949, G loss: 0.7217\n",
      "[964/1762] D loss: 1.4018, G loss: 0.7343\n",
      "[1044/1762] D loss: 1.4174, G loss: 0.6838\n",
      "[1124/1762] D loss: 1.4004, G loss: 0.8525\n",
      "[1204/1762] D loss: 1.4272, G loss: 0.5627\n",
      "[1284/1762] D loss: 1.2459, G loss: 0.8668\n",
      "[1364/1762] D loss: 1.3993, G loss: 0.7723\n",
      "[1444/1762] D loss: 1.3913, G loss: 0.7550\n",
      "[1524/1762] D loss: 1.3830, G loss: 0.7337\n",
      "[1604/1762] D loss: 1.3744, G loss: 0.5997\n",
      "[1684/1762] D loss: 1.1587, G loss: 0.8820\n",
      "[1762/1762] D loss: 1.0621, G loss: 1.1265\n",
      "train error: \n",
      " D loss: 1.376290, G loss: 1.037916, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359096, G loss: 1.056367, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2111, G loss: 1.1579\n",
      "[84/1762] D loss: 1.3979, G loss: 0.8252\n",
      "[164/1762] D loss: 1.3924, G loss: 0.6701\n",
      "[244/1762] D loss: 1.2392, G loss: 0.9706\n",
      "[324/1762] D loss: 1.4060, G loss: 0.7489\n",
      "[404/1762] D loss: 1.4274, G loss: 0.6841\n",
      "[484/1762] D loss: 1.3493, G loss: 0.8958\n",
      "[564/1762] D loss: 1.2650, G loss: 0.7669\n",
      "[644/1762] D loss: 1.3721, G loss: 0.7002\n",
      "[724/1762] D loss: 1.3942, G loss: 0.7923\n",
      "[804/1762] D loss: 0.8891, G loss: 1.2443\n",
      "[884/1762] D loss: 1.4443, G loss: 0.7559\n",
      "[964/1762] D loss: 1.1665, G loss: 0.8035\n",
      "[1044/1762] D loss: 1.4446, G loss: 0.8953\n",
      "[1124/1762] D loss: 1.4419, G loss: 0.6340\n",
      "[1204/1762] D loss: 0.9594, G loss: 0.9248\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.7316\n",
      "[1364/1762] D loss: 1.1892, G loss: 0.8539\n",
      "[1444/1762] D loss: 1.5354, G loss: 0.4853\n",
      "[1524/1762] D loss: 1.4012, G loss: 0.8535\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.6810\n",
      "[1684/1762] D loss: 1.3834, G loss: 0.7069\n",
      "[1762/1762] D loss: 1.3683, G loss: 0.7589\n",
      "train error: \n",
      " D loss: 1.328974, G loss: 0.845750, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311390, G loss: 0.856793, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.8050\n",
      "[84/1762] D loss: 1.4263, G loss: 0.8441\n",
      "[164/1762] D loss: 1.2645, G loss: 0.7588\n",
      "[244/1762] D loss: 1.4029, G loss: 0.6578\n",
      "[324/1762] D loss: 1.3941, G loss: 0.8320\n",
      "[404/1762] D loss: 1.3979, G loss: 0.6510\n",
      "[484/1762] D loss: 1.4123, G loss: 0.5447\n",
      "[564/1762] D loss: 1.4016, G loss: 0.8789\n",
      "[644/1762] D loss: 1.3859, G loss: 0.8101\n",
      "[724/1762] D loss: 1.1407, G loss: 1.0334\n",
      "[804/1762] D loss: 1.1464, G loss: 1.0544\n",
      "[884/1762] D loss: 1.3920, G loss: 0.5993\n",
      "[964/1762] D loss: 1.4270, G loss: 0.5874\n",
      "[1044/1762] D loss: 1.3525, G loss: 0.6896\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7949\n",
      "[1204/1762] D loss: 1.3946, G loss: 0.7150\n",
      "[1284/1762] D loss: 1.3417, G loss: 0.6894\n",
      "[1364/1762] D loss: 1.2525, G loss: 0.7582\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.7187\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6631\n",
      "[1604/1762] D loss: 1.3980, G loss: 0.7068\n",
      "[1684/1762] D loss: 1.4195, G loss: 0.8624\n",
      "[1762/1762] D loss: 1.2765, G loss: 0.7592\n",
      "train error: \n",
      " D loss: 1.315766, G loss: 0.729105, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297917, G loss: 0.742411, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4019, G loss: 0.5946\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7281\n",
      "[164/1762] D loss: 1.3054, G loss: 0.7710\n",
      "[244/1762] D loss: 1.4135, G loss: 0.7512\n",
      "[324/1762] D loss: 1.4083, G loss: 0.8335\n",
      "[404/1762] D loss: 1.3941, G loss: 0.7223\n",
      "[484/1762] D loss: 1.3918, G loss: 0.6977\n",
      "[564/1762] D loss: 1.3901, G loss: 0.7720\n",
      "[644/1762] D loss: 0.9102, G loss: 0.8927\n",
      "[724/1762] D loss: 1.3937, G loss: 0.6250\n",
      "[804/1762] D loss: 1.3886, G loss: 0.7292\n",
      "[884/1762] D loss: 1.4459, G loss: 0.6039\n",
      "[964/1762] D loss: 1.4028, G loss: 0.8437\n",
      "[1044/1762] D loss: 1.3919, G loss: 0.6242\n",
      "[1124/1762] D loss: 1.4055, G loss: 0.6478\n",
      "[1204/1762] D loss: 1.3959, G loss: 0.6336\n",
      "[1284/1762] D loss: 1.3974, G loss: 0.7157\n",
      "[1364/1762] D loss: 1.2167, G loss: 0.5729\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7763\n",
      "[1524/1762] D loss: 1.2708, G loss: 0.9504\n",
      "[1604/1762] D loss: 1.1219, G loss: 0.9027\n",
      "[1684/1762] D loss: 1.3775, G loss: 0.6608\n",
      "[1762/1762] D loss: 1.4015, G loss: 0.6336\n",
      "train error: \n",
      " D loss: 1.305952, G loss: 0.794145, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293414, G loss: 0.800010, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905, G loss: 0.7443\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6936\n",
      "[164/1762] D loss: 1.4127, G loss: 0.6173\n",
      "[244/1762] D loss: 0.9061, G loss: 1.3156\n",
      "[324/1762] D loss: 1.4163, G loss: 0.7859\n",
      "[404/1762] D loss: 1.4564, G loss: 0.8377\n",
      "[484/1762] D loss: 1.3963, G loss: 0.8423\n",
      "[564/1762] D loss: 1.4041, G loss: 0.6601\n",
      "[644/1762] D loss: 1.3997, G loss: 0.6651\n",
      "[724/1762] D loss: 1.3827, G loss: 0.7303\n",
      "[804/1762] D loss: 1.4905, G loss: 0.6002\n",
      "[884/1762] D loss: 1.1165, G loss: 0.8181\n",
      "[964/1762] D loss: 1.4454, G loss: 0.9179\n",
      "[1044/1762] D loss: 1.4824, G loss: 0.7066\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.6438\n",
      "[1204/1762] D loss: 0.9428, G loss: 1.2571\n",
      "[1284/1762] D loss: 1.4145, G loss: 0.7955\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.7411\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.7800\n",
      "[1524/1762] D loss: 1.3963, G loss: 0.8018\n",
      "[1604/1762] D loss: 1.1556, G loss: 0.8964\n",
      "[1684/1762] D loss: 1.2320, G loss: 0.7136\n",
      "[1762/1762] D loss: 0.9274, G loss: 1.0700\n",
      "train error: \n",
      " D loss: 1.323016, G loss: 0.716948, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308879, G loss: 0.725224, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.7520\n",
      "[84/1762] D loss: 1.4038, G loss: 0.6568\n",
      "[164/1762] D loss: 1.1484, G loss: 0.8756\n",
      "[244/1762] D loss: 1.3953, G loss: 0.7243\n",
      "[324/1762] D loss: 1.3910, G loss: 0.8291\n",
      "[404/1762] D loss: 1.1405, G loss: 1.0457\n",
      "[484/1762] D loss: 1.1334, G loss: 0.9968\n",
      "[564/1762] D loss: 1.4298, G loss: 0.8721\n",
      "[644/1762] D loss: 1.3890, G loss: 0.5859\n",
      "[724/1762] D loss: 1.4012, G loss: 0.6179\n",
      "[804/1762] D loss: 1.3965, G loss: 0.7403\n",
      "[884/1762] D loss: 1.1885, G loss: 0.7147\n",
      "[964/1762] D loss: 1.3955, G loss: 0.8053\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.6891\n",
      "[1124/1762] D loss: 1.1544, G loss: 0.9859\n",
      "[1204/1762] D loss: 1.3992, G loss: 0.8210\n",
      "[1284/1762] D loss: 1.1098, G loss: 0.9940\n",
      "[1364/1762] D loss: 1.1514, G loss: 0.7422\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.7081\n",
      "[1524/1762] D loss: 1.1277, G loss: 0.9992\n",
      "[1604/1762] D loss: 1.3916, G loss: 0.6546\n",
      "[1684/1762] D loss: 1.4421, G loss: 0.8766\n",
      "[1762/1762] D loss: 1.3977, G loss: 0.6417\n",
      "train error: \n",
      " D loss: 1.323861, G loss: 0.697263, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302912, G loss: 0.710441, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9752, G loss: 0.9438\n",
      "[84/1762] D loss: 1.3880, G loss: 0.7696\n",
      "[164/1762] D loss: 1.3947, G loss: 0.6925\n",
      "[244/1762] D loss: 1.4110, G loss: 0.8108\n",
      "[324/1762] D loss: 1.1796, G loss: 0.8090\n",
      "[404/1762] D loss: 1.0545, G loss: 0.9424\n",
      "[484/1762] D loss: 1.4222, G loss: 0.7248\n",
      "[564/1762] D loss: 1.3914, G loss: 0.6622\n",
      "[644/1762] D loss: 1.3923, G loss: 0.6008\n",
      "[724/1762] D loss: 1.3905, G loss: 0.7367\n",
      "[804/1762] D loss: 1.4222, G loss: 0.8359\n",
      "[884/1762] D loss: 1.3809, G loss: 0.6044\n",
      "[964/1762] D loss: 1.4262, G loss: 0.7725\n",
      "[1044/1762] D loss: 1.4093, G loss: 0.7666\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.6652\n",
      "[1204/1762] D loss: 1.4022, G loss: 0.6777\n",
      "[1284/1762] D loss: 1.4035, G loss: 0.9371\n",
      "[1364/1762] D loss: 1.3997, G loss: 0.7967\n",
      "[1444/1762] D loss: 1.1571, G loss: 0.7906\n",
      "[1524/1762] D loss: 1.4140, G loss: 0.8574\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.6764\n",
      "[1684/1762] D loss: 1.3949, G loss: 0.6203\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.7875\n",
      "train error: \n",
      " D loss: 1.315714, G loss: 0.861366, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299603, G loss: 0.871956, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1295, G loss: 0.9939\n",
      "[84/1762] D loss: 1.3596, G loss: 0.9974\n",
      "[164/1762] D loss: 1.4010, G loss: 0.5559\n",
      "[244/1762] D loss: 1.3722, G loss: 0.5756\n",
      "[324/1762] D loss: 1.4001, G loss: 0.6649\n",
      "[404/1762] D loss: 1.3545, G loss: 0.7348\n",
      "[484/1762] D loss: 1.1784, G loss: 0.9256\n",
      "[564/1762] D loss: 1.1645, G loss: 0.8269\n",
      "[644/1762] D loss: 0.7724, G loss: 1.1539\n",
      "[724/1762] D loss: 1.3038, G loss: 0.7259\n",
      "[804/1762] D loss: 1.3168, G loss: 0.6291\n",
      "[884/1762] D loss: 1.2962, G loss: 0.7036\n",
      "[964/1762] D loss: 0.9344, G loss: 1.1888\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.6046\n",
      "[1124/1762] D loss: 1.1515, G loss: 0.6972\n",
      "[1204/1762] D loss: 1.4183, G loss: 0.5801\n",
      "[1284/1762] D loss: 1.0611, G loss: 1.0655\n",
      "[1364/1762] D loss: 1.4522, G loss: 0.8808\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6101\n",
      "[1524/1762] D loss: 1.4477, G loss: 0.5781\n",
      "[1604/1762] D loss: 1.4095, G loss: 0.7996\n",
      "[1684/1762] D loss: 1.2018, G loss: 0.7847\n",
      "[1762/1762] D loss: 1.2718, G loss: 0.6468\n",
      "train error: \n",
      " D loss: 1.300599, G loss: 0.668075, D accuracy: 59.5%, cell accuracy: 99.5%, board accuracy: 62.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277976, G loss: 0.687456, D accuracy: 60.3%, cell accuracy: 99.4%, board accuracy: 59.8% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3688, G loss: 0.6618\n",
      "[84/1762] D loss: 1.1090, G loss: 1.1235\n",
      "[164/1762] D loss: 1.3253, G loss: 0.7838\n",
      "[244/1762] D loss: 1.4291, G loss: 0.8020\n",
      "[324/1762] D loss: 1.3902, G loss: 0.6449\n",
      "[404/1762] D loss: 1.4054, G loss: 0.6324\n",
      "[484/1762] D loss: 0.9297, G loss: 1.0835\n",
      "[564/1762] D loss: 1.3901, G loss: 0.8128\n",
      "[644/1762] D loss: 1.4409, G loss: 0.8315\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6433\n",
      "[804/1762] D loss: 1.1286, G loss: 0.9421\n",
      "[884/1762] D loss: 1.3915, G loss: 0.6877\n",
      "[964/1762] D loss: 1.3953, G loss: 0.6755\n",
      "[1044/1762] D loss: 1.4041, G loss: 0.6824\n",
      "[1124/1762] D loss: 1.4083, G loss: 0.6749\n",
      "[1204/1762] D loss: 1.4196, G loss: 0.5872\n",
      "[1284/1762] D loss: 1.4208, G loss: 0.5543\n",
      "[1364/1762] D loss: 1.3977, G loss: 0.7567\n",
      "[1444/1762] D loss: 1.3708, G loss: 0.7718\n",
      "[1524/1762] D loss: 1.3981, G loss: 0.5166\n",
      "[1604/1762] D loss: 1.3936, G loss: 0.6719\n",
      "[1684/1762] D loss: 1.1311, G loss: 1.1840\n",
      "[1762/1762] D loss: 0.8871, G loss: 1.0963\n",
      "train error: \n",
      " D loss: 1.321197, G loss: 0.706827, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297719, G loss: 0.724639, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.6325\n",
      "[84/1762] D loss: 1.3640, G loss: 0.6841\n",
      "[164/1762] D loss: 1.1498, G loss: 0.8273\n",
      "[244/1762] D loss: 1.4032, G loss: 0.8000\n",
      "[324/1762] D loss: 1.3936, G loss: 0.5719\n",
      "[404/1762] D loss: 1.3584, G loss: 0.7157\n",
      "[484/1762] D loss: 1.4125, G loss: 0.6714\n",
      "[564/1762] D loss: 1.3939, G loss: 0.6182\n",
      "[644/1762] D loss: 1.3948, G loss: 0.7354\n",
      "[724/1762] D loss: 1.2671, G loss: 0.9726\n",
      "[804/1762] D loss: 1.4019, G loss: 0.7271\n",
      "[884/1762] D loss: 1.3597, G loss: 0.6573\n",
      "[964/1762] D loss: 1.3918, G loss: 0.6399\n",
      "[1044/1762] D loss: 1.4058, G loss: 0.7362\n",
      "[1124/1762] D loss: 1.4023, G loss: 0.7136\n",
      "[1204/1762] D loss: 1.4046, G loss: 0.9552\n",
      "[1284/1762] D loss: 1.3654, G loss: 0.6610\n",
      "[1364/1762] D loss: 1.2007, G loss: 0.6547\n",
      "[1444/1762] D loss: 1.3937, G loss: 0.6237\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6083\n",
      "[1604/1762] D loss: 1.1543, G loss: 0.8280\n",
      "[1684/1762] D loss: 1.4122, G loss: 0.8063\n",
      "[1762/1762] D loss: 1.4095, G loss: 0.5011\n",
      "train error: \n",
      " D loss: 1.350105, G loss: 0.593456, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326690, G loss: 0.612569, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1356, G loss: 0.7557\n",
      "[84/1762] D loss: 1.4316, G loss: 0.6375\n",
      "[164/1762] D loss: 1.4416, G loss: 0.6782\n",
      "[244/1762] D loss: 1.2061, G loss: 1.1548\n",
      "[324/1762] D loss: 1.4219, G loss: 0.7711\n",
      "[404/1762] D loss: 1.1398, G loss: 0.7986\n",
      "[484/1762] D loss: 1.3988, G loss: 0.6651\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6659\n",
      "[644/1762] D loss: 1.4103, G loss: 0.8234\n",
      "[724/1762] D loss: 1.3959, G loss: 0.7679\n",
      "[804/1762] D loss: 1.1359, G loss: 0.8667\n",
      "[884/1762] D loss: 1.1363, G loss: 0.8412\n",
      "[964/1762] D loss: 1.2704, G loss: 0.8195\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.7368\n",
      "[1124/1762] D loss: 1.4118, G loss: 0.7289\n",
      "[1204/1762] D loss: 1.4310, G loss: 0.5085\n",
      "[1284/1762] D loss: 1.4078, G loss: 0.6636\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.6830\n",
      "[1444/1762] D loss: 1.3695, G loss: 0.5562\n",
      "[1524/1762] D loss: 1.4053, G loss: 0.6043\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.6778\n",
      "[1684/1762] D loss: 1.4204, G loss: 0.7607\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.6936\n",
      "train error: \n",
      " D loss: 1.318762, G loss: 0.820729, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296443, G loss: 0.841214, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4014, G loss: 0.7956\n",
      "[84/1762] D loss: 1.3973, G loss: 0.8406\n",
      "[164/1762] D loss: 1.4050, G loss: 0.7458\n",
      "[244/1762] D loss: 1.3913, G loss: 0.6767\n",
      "[324/1762] D loss: 1.3914, G loss: 0.7431\n",
      "[404/1762] D loss: 1.4095, G loss: 0.7659\n",
      "[484/1762] D loss: 1.1097, G loss: 0.8481\n",
      "[564/1762] D loss: 1.3997, G loss: 0.6202\n",
      "[644/1762] D loss: 1.1218, G loss: 0.9596\n",
      "[724/1762] D loss: 1.4176, G loss: 0.6554\n",
      "[804/1762] D loss: 1.3967, G loss: 0.8075\n",
      "[884/1762] D loss: 1.4233, G loss: 0.7279\n",
      "[964/1762] D loss: 1.4203, G loss: 0.7157\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.8268\n",
      "[1124/1762] D loss: 1.1685, G loss: 0.8350\n",
      "[1204/1762] D loss: 1.1397, G loss: 0.8168\n",
      "[1284/1762] D loss: 1.1367, G loss: 1.0584\n",
      "[1364/1762] D loss: 1.4724, G loss: 1.0072\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.5967\n",
      "[1524/1762] D loss: 1.4147, G loss: 0.8310\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.6334\n",
      "[1684/1762] D loss: 1.4046, G loss: 0.8491\n",
      "[1762/1762] D loss: 1.3955, G loss: 0.7493\n",
      "train error: \n",
      " D loss: 1.317952, G loss: 0.810467, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295598, G loss: 0.832563, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4073, G loss: 0.8291\n",
      "[84/1762] D loss: 1.1088, G loss: 0.9263\n",
      "[164/1762] D loss: 1.4252, G loss: 0.7004\n",
      "[244/1762] D loss: 1.4209, G loss: 0.7073\n",
      "[324/1762] D loss: 1.3953, G loss: 0.5477\n",
      "[404/1762] D loss: 1.1415, G loss: 0.8703\n",
      "[484/1762] D loss: 1.3915, G loss: 0.6665\n",
      "[564/1762] D loss: 1.3982, G loss: 0.6980\n",
      "[644/1762] D loss: 1.3987, G loss: 0.5759\n",
      "[724/1762] D loss: 1.3906, G loss: 0.7566\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6868\n",
      "[884/1762] D loss: 1.4092, G loss: 0.5617\n",
      "[964/1762] D loss: 1.3899, G loss: 0.7298\n",
      "[1044/1762] D loss: 1.3826, G loss: 0.7597\n",
      "[1124/1762] D loss: 1.3969, G loss: 0.7767\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6208\n",
      "[1284/1762] D loss: 1.1179, G loss: 0.9723\n",
      "[1364/1762] D loss: 1.4120, G loss: 0.5796\n",
      "[1444/1762] D loss: 1.4075, G loss: 0.7847\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.6475\n",
      "[1604/1762] D loss: 1.3977, G loss: 0.8008\n",
      "[1684/1762] D loss: 1.4265, G loss: 0.5555\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6520\n",
      "train error: \n",
      " D loss: 1.300918, G loss: 0.827767, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279386, G loss: 0.845798, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3386, G loss: 0.7876\n",
      "[84/1762] D loss: 1.1061, G loss: 0.9318\n",
      "[164/1762] D loss: 1.4318, G loss: 0.7261\n",
      "[244/1762] D loss: 1.1163, G loss: 0.8646\n",
      "[324/1762] D loss: 1.1264, G loss: 0.9359\n",
      "[404/1762] D loss: 1.3889, G loss: 0.6803\n",
      "[484/1762] D loss: 1.3732, G loss: 0.6716\n",
      "[564/1762] D loss: 1.3890, G loss: 0.7413\n",
      "[644/1762] D loss: 1.3946, G loss: 0.5605\n",
      "[724/1762] D loss: 1.4136, G loss: 0.6658\n",
      "[804/1762] D loss: 1.1165, G loss: 0.9386\n",
      "[884/1762] D loss: 1.3931, G loss: 0.6665\n",
      "[964/1762] D loss: 1.2540, G loss: 0.9277\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.6570\n",
      "[1124/1762] D loss: 1.1101, G loss: 1.0150\n",
      "[1204/1762] D loss: 1.4512, G loss: 0.8538\n",
      "[1284/1762] D loss: 1.4238, G loss: 0.6155\n",
      "[1364/1762] D loss: 1.4069, G loss: 0.7814\n",
      "[1444/1762] D loss: 1.1224, G loss: 1.0268\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.6467\n",
      "[1604/1762] D loss: 1.1497, G loss: 0.8290\n",
      "[1684/1762] D loss: 1.1196, G loss: 0.8086\n",
      "[1762/1762] D loss: 1.3930, G loss: 0.6439\n",
      "train error: \n",
      " D loss: 1.314611, G loss: 0.748984, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293066, G loss: 0.767560, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1236, G loss: 0.8320\n",
      "[84/1762] D loss: 1.1110, G loss: 0.9238\n",
      "[164/1762] D loss: 1.2986, G loss: 0.7809\n",
      "[244/1762] D loss: 1.4019, G loss: 0.7780\n",
      "[324/1762] D loss: 1.3985, G loss: 0.7395\n",
      "[404/1762] D loss: 0.8299, G loss: 1.3112\n",
      "[484/1762] D loss: 1.4169, G loss: 0.7442\n",
      "[564/1762] D loss: 1.3900, G loss: 0.6691\n",
      "[644/1762] D loss: 1.4261, G loss: 0.5610\n",
      "[724/1762] D loss: 1.3816, G loss: 0.5929\n",
      "[804/1762] D loss: 1.1255, G loss: 0.8774\n",
      "[884/1762] D loss: 1.1234, G loss: 0.8918\n",
      "[964/1762] D loss: 1.3949, G loss: 0.5463\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.7148\n",
      "[1124/1762] D loss: 1.0965, G loss: 0.9477\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6539\n",
      "[1284/1762] D loss: 1.4407, G loss: 0.6917\n",
      "[1364/1762] D loss: 1.3786, G loss: 0.7202\n",
      "[1444/1762] D loss: 1.3414, G loss: 0.7712\n",
      "[1524/1762] D loss: 1.1260, G loss: 1.1750\n",
      "[1604/1762] D loss: 1.3989, G loss: 0.5476\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.7409\n",
      "[1762/1762] D loss: 1.3929, G loss: 0.7024\n",
      "train error: \n",
      " D loss: 1.315891, G loss: 0.761393, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292690, G loss: 0.780737, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1355, G loss: 0.9395\n",
      "[84/1762] D loss: 1.4337, G loss: 0.7809\n",
      "[164/1762] D loss: 1.3576, G loss: 0.6992\n",
      "[244/1762] D loss: 1.1461, G loss: 0.9966\n",
      "[324/1762] D loss: 1.4178, G loss: 0.6386\n",
      "[404/1762] D loss: 1.3930, G loss: 0.7773\n",
      "[484/1762] D loss: 0.8738, G loss: 0.9467\n",
      "[564/1762] D loss: 1.3913, G loss: 0.6482\n",
      "[644/1762] D loss: 1.4030, G loss: 0.6699\n",
      "[724/1762] D loss: 1.3641, G loss: 0.6852\n",
      "[804/1762] D loss: 1.3956, G loss: 0.8596\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6826\n",
      "[964/1762] D loss: 1.4022, G loss: 0.7357\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.6735\n",
      "[1124/1762] D loss: 1.4213, G loss: 0.6634\n",
      "[1204/1762] D loss: 1.3769, G loss: 0.7012\n",
      "[1284/1762] D loss: 1.1340, G loss: 1.0004\n",
      "[1364/1762] D loss: 1.3774, G loss: 0.6191\n",
      "[1444/1762] D loss: 1.4140, G loss: 0.7081\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.7048\n",
      "[1604/1762] D loss: 1.1100, G loss: 0.9479\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.6696\n",
      "[1762/1762] D loss: 1.4172, G loss: 0.5794\n",
      "train error: \n",
      " D loss: 1.317142, G loss: 0.733637, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293781, G loss: 0.756259, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3594, G loss: 0.7306\n",
      "[84/1762] D loss: 1.3926, G loss: 0.7749\n",
      "[164/1762] D loss: 1.4028, G loss: 0.5990\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7339\n",
      "[324/1762] D loss: 1.4028, G loss: 0.6910\n",
      "[404/1762] D loss: 1.3571, G loss: 0.8334\n",
      "[484/1762] D loss: 1.4425, G loss: 0.7720\n",
      "[564/1762] D loss: 1.2419, G loss: 0.7502\n",
      "[644/1762] D loss: 1.2010, G loss: 0.9024\n",
      "[724/1762] D loss: 1.3153, G loss: 0.7412\n",
      "[804/1762] D loss: 0.8471, G loss: 1.2070\n",
      "[884/1762] D loss: 1.3791, G loss: 0.6675\n",
      "[964/1762] D loss: 0.8664, G loss: 1.2160\n",
      "[1044/1762] D loss: 1.4042, G loss: 0.7448\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7129\n",
      "[1204/1762] D loss: 1.3968, G loss: 0.7015\n",
      "[1284/1762] D loss: 1.4073, G loss: 0.6130\n",
      "[1364/1762] D loss: 1.4012, G loss: 0.9256\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.5827\n",
      "[1524/1762] D loss: 1.4300, G loss: 0.5587\n",
      "[1604/1762] D loss: 1.3539, G loss: 0.6763\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.5930\n",
      "[1762/1762] D loss: 1.4184, G loss: 0.6544\n",
      "train error: \n",
      " D loss: 1.315293, G loss: 0.798064, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295040, G loss: 0.811890, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3922, G loss: 0.7990\n",
      "[84/1762] D loss: 1.4056, G loss: 0.7475\n",
      "[164/1762] D loss: 1.5867, G loss: 0.4910\n",
      "[244/1762] D loss: 1.4022, G loss: 0.6810\n",
      "[324/1762] D loss: 1.4009, G loss: 0.5750\n",
      "[404/1762] D loss: 1.4048, G loss: 0.7531\n",
      "[484/1762] D loss: 1.3889, G loss: 0.6773\n",
      "[564/1762] D loss: 1.1367, G loss: 0.7679\n",
      "[644/1762] D loss: 1.3924, G loss: 0.8836\n",
      "[724/1762] D loss: 1.4147, G loss: 0.8219\n",
      "[804/1762] D loss: 0.8305, G loss: 1.1797\n",
      "[884/1762] D loss: 1.3594, G loss: 0.6725\n",
      "[964/1762] D loss: 1.1276, G loss: 0.8862\n",
      "[1044/1762] D loss: 1.4619, G loss: 0.8670\n",
      "[1124/1762] D loss: 1.4349, G loss: 0.7707\n",
      "[1204/1762] D loss: 1.4195, G loss: 0.5365\n",
      "[1284/1762] D loss: 1.3761, G loss: 0.7903\n",
      "[1364/1762] D loss: 1.4342, G loss: 0.8259\n",
      "[1444/1762] D loss: 1.1553, G loss: 0.7579\n",
      "[1524/1762] D loss: 1.1546, G loss: 0.9242\n",
      "[1604/1762] D loss: 1.4133, G loss: 0.6115\n",
      "[1684/1762] D loss: 1.1638, G loss: 0.9058\n",
      "[1762/1762] D loss: 1.3940, G loss: 0.7557\n",
      "train error: \n",
      " D loss: 1.326015, G loss: 0.872159, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306470, G loss: 0.886397, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1213, G loss: 0.9554\n",
      "[84/1762] D loss: 1.4126, G loss: 0.6482\n",
      "[164/1762] D loss: 1.3856, G loss: 0.6404\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7371\n",
      "[324/1762] D loss: 1.3972, G loss: 0.6738\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6652\n",
      "[484/1762] D loss: 1.3893, G loss: 0.6332\n",
      "[564/1762] D loss: 1.3356, G loss: 0.7231\n",
      "[644/1762] D loss: 1.3921, G loss: 0.7383\n",
      "[724/1762] D loss: 1.1187, G loss: 0.8623\n",
      "[804/1762] D loss: 1.3924, G loss: 0.7177\n",
      "[884/1762] D loss: 1.4093, G loss: 0.8314\n",
      "[964/1762] D loss: 1.2587, G loss: 0.8547\n",
      "[1044/1762] D loss: 1.3991, G loss: 0.6285\n",
      "[1124/1762] D loss: 1.4241, G loss: 0.6421\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.6548\n",
      "[1284/1762] D loss: 1.1100, G loss: 0.9909\n",
      "[1364/1762] D loss: 1.4053, G loss: 0.8295\n",
      "[1444/1762] D loss: 1.4394, G loss: 0.9197\n",
      "[1524/1762] D loss: 1.3853, G loss: 0.6066\n",
      "[1604/1762] D loss: 1.4005, G loss: 0.7564\n",
      "[1684/1762] D loss: 1.1751, G loss: 1.1131\n",
      "[1762/1762] D loss: 1.4338, G loss: 0.5145\n",
      "train error: \n",
      " D loss: 1.353489, G loss: 0.576831, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325407, G loss: 0.596647, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4021, G loss: 0.6600\n",
      "[84/1762] D loss: 1.3796, G loss: 0.7828\n",
      "[164/1762] D loss: 1.4190, G loss: 0.7706\n",
      "[244/1762] D loss: 1.3571, G loss: 0.7466\n",
      "[324/1762] D loss: 1.4022, G loss: 0.6536\n",
      "[404/1762] D loss: 1.1423, G loss: 0.9247\n",
      "[484/1762] D loss: 1.3997, G loss: 0.6703\n",
      "[564/1762] D loss: 1.4639, G loss: 0.8772\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6677\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6740\n",
      "[804/1762] D loss: 1.4294, G loss: 0.7523\n",
      "[884/1762] D loss: 1.4557, G loss: 0.5653\n",
      "[964/1762] D loss: 1.3656, G loss: 0.7774\n",
      "[1044/1762] D loss: 1.3817, G loss: 0.7648\n",
      "[1124/1762] D loss: 1.3915, G loss: 0.8499\n",
      "[1204/1762] D loss: 1.4225, G loss: 0.8172\n",
      "[1284/1762] D loss: 1.3036, G loss: 0.6227\n",
      "[1364/1762] D loss: 1.4312, G loss: 0.6009\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.7469\n",
      "[1524/1762] D loss: 1.1381, G loss: 0.9111\n",
      "[1604/1762] D loss: 1.4061, G loss: 0.5899\n",
      "[1684/1762] D loss: 1.1142, G loss: 1.0824\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6715\n",
      "train error: \n",
      " D loss: 1.316106, G loss: 0.796228, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290803, G loss: 0.818242, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4200, G loss: 0.7292\n",
      "[84/1762] D loss: 1.4039, G loss: 0.7315\n",
      "[164/1762] D loss: 1.1144, G loss: 0.9230\n",
      "[244/1762] D loss: 1.3617, G loss: 0.8495\n",
      "[324/1762] D loss: 1.3907, G loss: 0.6345\n",
      "[404/1762] D loss: 1.4579, G loss: 0.8455\n",
      "[484/1762] D loss: 1.3999, G loss: 0.5980\n",
      "[564/1762] D loss: 1.4123, G loss: 0.5828\n",
      "[644/1762] D loss: 1.4155, G loss: 0.6054\n",
      "[724/1762] D loss: 1.3931, G loss: 0.7409\n",
      "[804/1762] D loss: 1.1617, G loss: 0.8560\n",
      "[884/1762] D loss: 1.4042, G loss: 0.8596\n",
      "[964/1762] D loss: 1.3984, G loss: 0.6498\n",
      "[1044/1762] D loss: 1.4041, G loss: 0.6147\n",
      "[1124/1762] D loss: 1.3973, G loss: 0.7282\n",
      "[1204/1762] D loss: 1.3756, G loss: 0.6563\n",
      "[1284/1762] D loss: 1.4594, G loss: 0.8711\n",
      "[1364/1762] D loss: 1.0705, G loss: 0.8967\n",
      "[1444/1762] D loss: 1.4176, G loss: 0.9399\n",
      "[1524/1762] D loss: 1.1049, G loss: 0.9482\n",
      "[1604/1762] D loss: 1.3945, G loss: 0.6296\n",
      "[1684/1762] D loss: 1.4220, G loss: 0.9030\n",
      "[1762/1762] D loss: 1.3842, G loss: 0.5860\n",
      "train error: \n",
      " D loss: 1.332182, G loss: 0.655033, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 84.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310583, G loss: 0.667390, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1426, G loss: 0.7604\n",
      "[84/1762] D loss: 1.3710, G loss: 0.7587\n",
      "[164/1762] D loss: 1.3550, G loss: 0.7926\n",
      "[244/1762] D loss: 1.1490, G loss: 0.9542\n",
      "[324/1762] D loss: 1.4087, G loss: 0.8888\n",
      "[404/1762] D loss: 1.4255, G loss: 0.8016\n",
      "[484/1762] D loss: 1.1128, G loss: 0.9697\n",
      "[564/1762] D loss: 2.0586, G loss: 0.8078\n",
      "[644/1762] D loss: 1.2824, G loss: 0.9698\n",
      "[724/1762] D loss: 0.4571, G loss: 1.7739\n",
      "[804/1762] D loss: 0.9205, G loss: 1.5717\n",
      "[884/1762] D loss: 1.3701, G loss: 1.1244\n",
      "[964/1762] D loss: 1.4280, G loss: 0.6557\n",
      "[1044/1762] D loss: 1.4835, G loss: 1.2217\n",
      "[1124/1762] D loss: 1.7155, G loss: 1.2597\n",
      "[1204/1762] D loss: 1.3961, G loss: 0.7830\n",
      "[1284/1762] D loss: 1.2639, G loss: 0.7758\n",
      "[1364/1762] D loss: 1.4994, G loss: 0.8477\n",
      "[1444/1762] D loss: 1.2274, G loss: 1.0091\n",
      "[1524/1762] D loss: 1.5617, G loss: 0.9213\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6906\n",
      "[1684/1762] D loss: 1.4538, G loss: 0.9932\n",
      "[1762/1762] D loss: 1.4120, G loss: 0.5998\n",
      "train error: \n",
      " D loss: 1.360939, G loss: 0.667527, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346761, G loss: 0.674753, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7038\n",
      "[84/1762] D loss: 1.4212, G loss: 0.8775\n",
      "[164/1762] D loss: 1.4538, G loss: 0.8726\n",
      "[244/1762] D loss: 1.1822, G loss: 0.8430\n",
      "[324/1762] D loss: 1.3356, G loss: 0.7221\n",
      "[404/1762] D loss: 1.4065, G loss: 0.5956\n",
      "[484/1762] D loss: 1.3898, G loss: 0.6448\n",
      "[564/1762] D loss: 1.2159, G loss: 0.7238\n",
      "[644/1762] D loss: 1.2159, G loss: 0.7101\n",
      "[724/1762] D loss: 1.3901, G loss: 0.7214\n",
      "[804/1762] D loss: 1.3931, G loss: 0.6805\n",
      "[884/1762] D loss: 1.3900, G loss: 0.6728\n",
      "[964/1762] D loss: 1.3336, G loss: 0.8222\n",
      "[1044/1762] D loss: 1.1983, G loss: 0.9915\n",
      "[1124/1762] D loss: 1.2019, G loss: 0.8445\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.6243\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.6767\n",
      "[1364/1762] D loss: 1.2001, G loss: 0.8154\n",
      "[1444/1762] D loss: 1.1612, G loss: 0.7828\n",
      "[1524/1762] D loss: 1.4153, G loss: 0.7328\n",
      "[1604/1762] D loss: 1.4487, G loss: 0.8607\n",
      "[1684/1762] D loss: 1.3941, G loss: 0.6289\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6589\n",
      "train error: \n",
      " D loss: 1.334780, G loss: 0.757399, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318905, G loss: 0.770122, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.7702\n",
      "[84/1762] D loss: 1.3004, G loss: 0.8220\n",
      "[164/1762] D loss: 1.4131, G loss: 0.7125\n",
      "[244/1762] D loss: 1.3893, G loss: 0.6821\n",
      "[324/1762] D loss: 1.0053, G loss: 0.9344\n",
      "[404/1762] D loss: 1.3920, G loss: 0.7040\n",
      "[484/1762] D loss: 1.1868, G loss: 0.7746\n",
      "[564/1762] D loss: 1.3843, G loss: 0.6752\n",
      "[644/1762] D loss: 1.3989, G loss: 0.6158\n",
      "[724/1762] D loss: 1.3986, G loss: 0.7674\n",
      "[804/1762] D loss: 1.3909, G loss: 0.7005\n",
      "[884/1762] D loss: 1.3836, G loss: 0.6791\n",
      "[964/1762] D loss: 1.4438, G loss: 0.5344\n",
      "[1044/1762] D loss: 1.3917, G loss: 0.6147\n",
      "[1124/1762] D loss: 1.3847, G loss: 0.6458\n",
      "[1204/1762] D loss: 1.4069, G loss: 0.7628\n",
      "[1284/1762] D loss: 1.3982, G loss: 0.7324\n",
      "[1364/1762] D loss: 1.3818, G loss: 0.6897\n",
      "[1444/1762] D loss: 1.3650, G loss: 0.6617\n",
      "[1524/1762] D loss: 1.1707, G loss: 0.7667\n",
      "[1604/1762] D loss: 1.4090, G loss: 0.5680\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.7409\n",
      "[1762/1762] D loss: 1.3688, G loss: 0.6583\n",
      "train error: \n",
      " D loss: 1.332631, G loss: 0.682564, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315653, G loss: 0.694601, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.5821\n",
      "[84/1762] D loss: 1.4046, G loss: 0.8294\n",
      "[164/1762] D loss: 1.4015, G loss: 0.8060\n",
      "[244/1762] D loss: 1.3950, G loss: 0.8113\n",
      "[324/1762] D loss: 1.4037, G loss: 0.8288\n",
      "[404/1762] D loss: 1.1699, G loss: 0.9120\n",
      "[484/1762] D loss: 1.3164, G loss: 0.7625\n",
      "[564/1762] D loss: 1.4005, G loss: 0.7587\n",
      "[644/1762] D loss: 1.4008, G loss: 0.7767\n",
      "[724/1762] D loss: 1.3783, G loss: 0.7927\n",
      "[804/1762] D loss: 1.3908, G loss: 0.7167\n",
      "[884/1762] D loss: 1.3848, G loss: 0.6678\n",
      "[964/1762] D loss: 1.4008, G loss: 0.7175\n",
      "[1044/1762] D loss: 1.4023, G loss: 0.7732\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.6915\n",
      "[1204/1762] D loss: 1.4047, G loss: 0.6673\n",
      "[1284/1762] D loss: 1.3570, G loss: 0.7214\n",
      "[1364/1762] D loss: 1.1546, G loss: 0.9110\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7241\n",
      "[1524/1762] D loss: 1.3912, G loss: 0.7220\n",
      "[1604/1762] D loss: 1.1464, G loss: 0.8665\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.6381\n",
      "[1762/1762] D loss: 1.4477, G loss: 0.6042\n",
      "train error: \n",
      " D loss: 1.330527, G loss: 0.669785, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 75.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308671, G loss: 0.684540, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1458, G loss: 0.7515\n",
      "[84/1762] D loss: 1.3546, G loss: 0.6965\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6520\n",
      "[244/1762] D loss: 1.3991, G loss: 0.5836\n",
      "[324/1762] D loss: 1.4027, G loss: 0.6120\n",
      "[404/1762] D loss: 1.2906, G loss: 0.8043\n",
      "[484/1762] D loss: 1.3959, G loss: 0.6509\n",
      "[564/1762] D loss: 1.3887, G loss: 0.7236\n",
      "[644/1762] D loss: 1.3930, G loss: 0.5901\n",
      "[724/1762] D loss: 1.3842, G loss: 0.6482\n",
      "[804/1762] D loss: 1.4241, G loss: 0.8945\n",
      "[884/1762] D loss: 1.1888, G loss: 1.0507\n",
      "[964/1762] D loss: 1.4202, G loss: 0.8783\n",
      "[1044/1762] D loss: 1.4431, G loss: 0.6751\n",
      "[1124/1762] D loss: 1.4115, G loss: 0.7374\n",
      "[1204/1762] D loss: 1.1906, G loss: 0.8498\n",
      "[1284/1762] D loss: 1.3937, G loss: 0.7136\n",
      "[1364/1762] D loss: 1.3953, G loss: 0.6099\n",
      "[1444/1762] D loss: 1.4112, G loss: 0.8507\n",
      "[1524/1762] D loss: 1.4087, G loss: 0.6002\n",
      "[1604/1762] D loss: 1.0836, G loss: 0.9735\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6385\n",
      "[1762/1762] D loss: 0.9038, G loss: 0.9465\n",
      "train error: \n",
      " D loss: 1.321924, G loss: 0.775105, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 79.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301221, G loss: 0.788400, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1572, G loss: 0.9056\n",
      "[84/1762] D loss: 1.3890, G loss: 0.6292\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7306\n",
      "[244/1762] D loss: 1.1646, G loss: 0.8435\n",
      "[324/1762] D loss: 1.3888, G loss: 0.8147\n",
      "[404/1762] D loss: 1.3865, G loss: 0.5306\n",
      "[484/1762] D loss: 1.4382, G loss: 0.6837\n",
      "[564/1762] D loss: 1.1702, G loss: 0.9911\n",
      "[644/1762] D loss: 1.3929, G loss: 0.6194\n",
      "[724/1762] D loss: 1.3902, G loss: 0.7142\n",
      "[804/1762] D loss: 1.3653, G loss: 0.7086\n",
      "[884/1762] D loss: 1.3855, G loss: 0.6463\n",
      "[964/1762] D loss: 1.3833, G loss: 0.6675\n",
      "[1044/1762] D loss: 1.3690, G loss: 0.8450\n",
      "[1124/1762] D loss: 1.3492, G loss: 0.7563\n",
      "[1204/1762] D loss: 1.4275, G loss: 0.8451\n",
      "[1284/1762] D loss: 1.4023, G loss: 0.5973\n",
      "[1364/1762] D loss: 1.1659, G loss: 0.7213\n",
      "[1444/1762] D loss: 1.0989, G loss: 1.1282\n",
      "[1524/1762] D loss: 1.4069, G loss: 0.7989\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.7823\n",
      "[1684/1762] D loss: 1.3587, G loss: 0.6354\n",
      "[1762/1762] D loss: 1.2841, G loss: 0.7982\n",
      "train error: \n",
      " D loss: 1.315279, G loss: 0.758396, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 69.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290521, G loss: 0.777789, D accuracy: 57.0%, cell accuracy: 99.6%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1927, G loss: 0.8703\n",
      "[84/1762] D loss: 1.2077, G loss: 0.6723\n",
      "[164/1762] D loss: 1.3696, G loss: 0.7220\n",
      "[244/1762] D loss: 1.4069, G loss: 0.6500\n",
      "[324/1762] D loss: 1.2818, G loss: 0.8307\n",
      "[404/1762] D loss: 1.3412, G loss: 0.7119\n",
      "[484/1762] D loss: 1.0747, G loss: 0.9571\n",
      "[564/1762] D loss: 1.3959, G loss: 0.8084\n",
      "[644/1762] D loss: 1.0776, G loss: 1.2012\n",
      "[724/1762] D loss: 1.3518, G loss: 0.6647\n",
      "[804/1762] D loss: 1.3049, G loss: 0.5929\n",
      "[884/1762] D loss: 1.4292, G loss: 0.5764\n",
      "[964/1762] D loss: 1.3955, G loss: 0.6472\n",
      "[1044/1762] D loss: 1.1535, G loss: 0.6609\n",
      "[1124/1762] D loss: 1.4398, G loss: 0.6171\n",
      "[1204/1762] D loss: 1.1613, G loss: 0.9548\n",
      "[1284/1762] D loss: 1.4222, G loss: 0.8416\n",
      "[1364/1762] D loss: 1.3432, G loss: 0.7058\n",
      "[1444/1762] D loss: 1.3710, G loss: 0.6862\n",
      "[1524/1762] D loss: 1.4676, G loss: 0.9205\n",
      "[1604/1762] D loss: 1.4172, G loss: 0.7083\n",
      "[1684/1762] D loss: 1.3731, G loss: 0.6941\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.7561\n",
      "train error: \n",
      " D loss: 1.313876, G loss: 0.796570, D accuracy: 56.3%, cell accuracy: 99.7%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293886, G loss: 0.810117, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4051, G loss: 0.8062\n",
      "[84/1762] D loss: 1.4196, G loss: 0.8626\n",
      "[164/1762] D loss: 1.3970, G loss: 0.6241\n",
      "[244/1762] D loss: 1.3766, G loss: 0.6796\n",
      "[324/1762] D loss: 1.4316, G loss: 0.4707\n",
      "[404/1762] D loss: 1.3980, G loss: 0.7117\n",
      "[484/1762] D loss: 1.3872, G loss: 0.8621\n",
      "[564/1762] D loss: 1.3894, G loss: 0.7513\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7092\n",
      "[724/1762] D loss: 1.4104, G loss: 0.7889\n",
      "[804/1762] D loss: 1.3260, G loss: 0.7819\n",
      "[884/1762] D loss: 1.3946, G loss: 0.6792\n",
      "[964/1762] D loss: 1.3903, G loss: 0.7294\n",
      "[1044/1762] D loss: 0.8660, G loss: 1.4112\n",
      "[1124/1762] D loss: 1.1568, G loss: 1.0105\n",
      "[1204/1762] D loss: 1.4313, G loss: 0.7569\n",
      "[1284/1762] D loss: 1.3683, G loss: 0.6213\n",
      "[1364/1762] D loss: 1.4452, G loss: 0.8943\n",
      "[1444/1762] D loss: 1.3966, G loss: 0.6543\n",
      "[1524/1762] D loss: 1.4005, G loss: 0.6454\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.7713\n",
      "[1684/1762] D loss: 1.3609, G loss: 0.6105\n",
      "[1762/1762] D loss: 1.3546, G loss: 0.6682\n",
      "train error: \n",
      " D loss: 1.325549, G loss: 0.668714, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304731, G loss: 0.679871, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1538, G loss: 0.8432\n",
      "[84/1762] D loss: 1.3901, G loss: 0.7036\n",
      "[164/1762] D loss: 1.3993, G loss: 0.7963\n",
      "[244/1762] D loss: 1.3798, G loss: 0.6523\n",
      "[324/1762] D loss: 1.4055, G loss: 0.7766\n",
      "[404/1762] D loss: 1.3853, G loss: 0.8108\n",
      "[484/1762] D loss: 1.3857, G loss: 0.7649\n",
      "[564/1762] D loss: 1.1391, G loss: 0.8398\n",
      "[644/1762] D loss: 1.4214, G loss: 0.9304\n",
      "[724/1762] D loss: 1.4147, G loss: 0.8279\n",
      "[804/1762] D loss: 1.1595, G loss: 0.7498\n",
      "[884/1762] D loss: 1.3919, G loss: 0.6998\n",
      "[964/1762] D loss: 1.3912, G loss: 0.6663\n",
      "[1044/1762] D loss: 1.4334, G loss: 0.7831\n",
      "[1124/1762] D loss: 1.1388, G loss: 1.0038\n",
      "[1204/1762] D loss: 1.4117, G loss: 0.6908\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.6811\n",
      "[1364/1762] D loss: 1.3963, G loss: 0.6885\n",
      "[1444/1762] D loss: 1.3830, G loss: 0.6246\n",
      "[1524/1762] D loss: 1.4069, G loss: 0.6242\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.6955\n",
      "[1684/1762] D loss: 1.3926, G loss: 0.6205\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7563\n",
      "train error: \n",
      " D loss: 1.319124, G loss: 0.770004, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 83.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300750, G loss: 0.777833, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4124, G loss: 0.7776\n",
      "[84/1762] D loss: 1.1438, G loss: 0.7740\n",
      "[164/1762] D loss: 1.3877, G loss: 0.8536\n",
      "[244/1762] D loss: 1.4124, G loss: 0.5712\n",
      "[324/1762] D loss: 1.4409, G loss: 0.6044\n",
      "[404/1762] D loss: 1.4005, G loss: 0.6869\n",
      "[484/1762] D loss: 1.3983, G loss: 0.8181\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6895\n",
      "[644/1762] D loss: 1.3998, G loss: 0.7055\n",
      "[724/1762] D loss: 1.2410, G loss: 1.1285\n",
      "[804/1762] D loss: 1.3893, G loss: 0.7538\n",
      "[884/1762] D loss: 1.4459, G loss: 0.9242\n",
      "[964/1762] D loss: 1.3854, G loss: 0.6611\n",
      "[1044/1762] D loss: 1.4251, G loss: 0.8812\n",
      "[1124/1762] D loss: 1.0457, G loss: 1.0492\n",
      "[1204/1762] D loss: 1.4152, G loss: 0.7604\n",
      "[1284/1762] D loss: 1.4287, G loss: 0.6020\n",
      "[1364/1762] D loss: 1.2185, G loss: 0.8021\n",
      "[1444/1762] D loss: 1.1468, G loss: 0.9773\n",
      "[1524/1762] D loss: 1.1396, G loss: 0.9333\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.6869\n",
      "[1684/1762] D loss: 1.3975, G loss: 0.6573\n",
      "[1762/1762] D loss: 1.4018, G loss: 0.5617\n",
      "train error: \n",
      " D loss: 1.328674, G loss: 0.652112, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309467, G loss: 0.667522, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927, G loss: 0.6328\n",
      "[84/1762] D loss: 1.1426, G loss: 0.8364\n",
      "[164/1762] D loss: 1.4042, G loss: 0.7444\n",
      "[244/1762] D loss: 1.3301, G loss: 0.6636\n",
      "[324/1762] D loss: 1.0338, G loss: 0.8557\n",
      "[404/1762] D loss: 1.4596, G loss: 0.9086\n",
      "[484/1762] D loss: 1.4175, G loss: 0.8118\n",
      "[564/1762] D loss: 1.3854, G loss: 0.7181\n",
      "[644/1762] D loss: 1.3926, G loss: 0.6079\n",
      "[724/1762] D loss: 1.3916, G loss: 0.5522\n",
      "[804/1762] D loss: 1.3985, G loss: 0.5574\n",
      "[884/1762] D loss: 1.3924, G loss: 0.6050\n",
      "[964/1762] D loss: 1.3943, G loss: 0.5937\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.6472\n",
      "[1124/1762] D loss: 1.4049, G loss: 0.5620\n",
      "[1204/1762] D loss: 1.4020, G loss: 0.5772\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7311\n",
      "[1364/1762] D loss: 1.4031, G loss: 0.7017\n",
      "[1444/1762] D loss: 1.1376, G loss: 0.7991\n",
      "[1524/1762] D loss: 1.1452, G loss: 0.8211\n",
      "[1604/1762] D loss: 1.4043, G loss: 0.6434\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.8306\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.7285\n",
      "train error: \n",
      " D loss: 1.318928, G loss: 0.768637, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300461, G loss: 0.777122, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6716\n",
      "[84/1762] D loss: 1.3958, G loss: 0.5408\n",
      "[164/1762] D loss: 1.4104, G loss: 0.7849\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7026\n",
      "[324/1762] D loss: 1.1718, G loss: 0.8291\n",
      "[404/1762] D loss: 1.1412, G loss: 0.9572\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7124\n",
      "[564/1762] D loss: 1.3735, G loss: 0.7246\n",
      "[644/1762] D loss: 1.1293, G loss: 0.8972\n",
      "[724/1762] D loss: 1.3951, G loss: 0.7361\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6597\n",
      "[884/1762] D loss: 1.4338, G loss: 0.8408\n",
      "[964/1762] D loss: 1.1430, G loss: 0.8775\n",
      "[1044/1762] D loss: 1.1355, G loss: 0.7934\n",
      "[1124/1762] D loss: 1.3912, G loss: 0.6978\n",
      "[1204/1762] D loss: 1.4029, G loss: 0.6164\n",
      "[1284/1762] D loss: 0.8248, G loss: 1.3486\n",
      "[1364/1762] D loss: 1.4037, G loss: 0.6666\n",
      "[1444/1762] D loss: 1.4359, G loss: 0.8068\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.6264\n",
      "[1604/1762] D loss: 1.3598, G loss: 0.7629\n",
      "[1684/1762] D loss: 1.1408, G loss: 0.8067\n",
      "[1762/1762] D loss: 1.4119, G loss: 0.8333\n",
      "train error: \n",
      " D loss: 1.317128, G loss: 0.722463, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296393, G loss: 0.734918, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3761, G loss: 0.6420\n",
      "[84/1762] D loss: 1.4046, G loss: 0.7063\n",
      "[164/1762] D loss: 1.3978, G loss: 0.7337\n",
      "[244/1762] D loss: 1.5272, G loss: 0.5936\n",
      "[324/1762] D loss: 1.1260, G loss: 0.9288\n",
      "[404/1762] D loss: 1.3968, G loss: 0.7413\n",
      "[484/1762] D loss: 1.3920, G loss: 0.6467\n",
      "[564/1762] D loss: 1.4052, G loss: 0.8004\n",
      "[644/1762] D loss: 1.1328, G loss: 0.8185\n",
      "[724/1762] D loss: 1.3849, G loss: 0.7285\n",
      "[804/1762] D loss: 1.3884, G loss: 0.7358\n",
      "[884/1762] D loss: 1.3781, G loss: 0.7689\n",
      "[964/1762] D loss: 1.3982, G loss: 0.5874\n",
      "[1044/1762] D loss: 1.3947, G loss: 0.7385\n",
      "[1124/1762] D loss: 1.3829, G loss: 0.8159\n",
      "[1204/1762] D loss: 1.4192, G loss: 0.8788\n",
      "[1284/1762] D loss: 1.4267, G loss: 0.8176\n",
      "[1364/1762] D loss: 1.1193, G loss: 0.9344\n",
      "[1444/1762] D loss: 1.4057, G loss: 0.6795\n",
      "[1524/1762] D loss: 1.4347, G loss: 0.6408\n",
      "[1604/1762] D loss: 1.3987, G loss: 0.8402\n",
      "[1684/1762] D loss: 1.1085, G loss: 1.0220\n",
      "[1762/1762] D loss: 1.3496, G loss: 0.7109\n",
      "train error: \n",
      " D loss: 1.320572, G loss: 0.793776, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 77.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299067, G loss: 0.809895, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.7598\n",
      "[84/1762] D loss: 1.1237, G loss: 0.9091\n",
      "[164/1762] D loss: 1.1563, G loss: 0.8303\n",
      "[244/1762] D loss: 1.1489, G loss: 1.2125\n",
      "[324/1762] D loss: 1.4578, G loss: 0.9341\n",
      "[404/1762] D loss: 1.4289, G loss: 0.6003\n",
      "[484/1762] D loss: 1.3985, G loss: 0.6700\n",
      "[564/1762] D loss: 1.3933, G loss: 0.6388\n",
      "[644/1762] D loss: 0.8762, G loss: 0.9558\n",
      "[724/1762] D loss: 1.3976, G loss: 0.7148\n",
      "[804/1762] D loss: 1.1065, G loss: 0.9001\n",
      "[884/1762] D loss: 1.3348, G loss: 0.7772\n",
      "[964/1762] D loss: 0.8450, G loss: 1.0380\n",
      "[1044/1762] D loss: 1.1757, G loss: 0.8816\n",
      "[1124/1762] D loss: 1.1437, G loss: 1.0496\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6967\n",
      "[1284/1762] D loss: 1.3812, G loss: 0.6712\n",
      "[1364/1762] D loss: 1.1899, G loss: 0.7330\n",
      "[1444/1762] D loss: 1.3677, G loss: 0.7670\n",
      "[1524/1762] D loss: 1.3962, G loss: 0.7416\n",
      "[1604/1762] D loss: 1.4358, G loss: 0.6203\n",
      "[1684/1762] D loss: 1.1436, G loss: 0.9150\n",
      "[1762/1762] D loss: 1.4259, G loss: 0.6716\n",
      "train error: \n",
      " D loss: 1.314848, G loss: 0.779154, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294510, G loss: 0.792351, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3967, G loss: 0.8734\n",
      "[84/1762] D loss: 1.3780, G loss: 0.8518\n",
      "[164/1762] D loss: 1.1541, G loss: 1.0569\n",
      "[244/1762] D loss: 1.4020, G loss: 0.7127\n",
      "[324/1762] D loss: 1.3638, G loss: 0.6988\n",
      "[404/1762] D loss: 1.1702, G loss: 0.7036\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6626\n",
      "[564/1762] D loss: 1.3981, G loss: 0.7150\n",
      "[644/1762] D loss: 1.1130, G loss: 1.1054\n",
      "[724/1762] D loss: 1.1444, G loss: 0.7989\n",
      "[804/1762] D loss: 1.3836, G loss: 0.8073\n",
      "[884/1762] D loss: 1.3986, G loss: 0.7625\n",
      "[964/1762] D loss: 1.3750, G loss: 0.7175\n",
      "[1044/1762] D loss: 1.3398, G loss: 0.7398\n",
      "[1124/1762] D loss: 1.3975, G loss: 0.7067\n",
      "[1204/1762] D loss: 1.3715, G loss: 0.6298\n",
      "[1284/1762] D loss: 1.4061, G loss: 0.6086\n",
      "[1364/1762] D loss: 1.3820, G loss: 0.6667\n",
      "[1444/1762] D loss: 1.0772, G loss: 1.1346\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6556\n",
      "[1604/1762] D loss: 1.3919, G loss: 0.5914\n",
      "[1684/1762] D loss: 1.3932, G loss: 0.6570\n",
      "[1762/1762] D loss: 1.4078, G loss: 0.6949\n",
      "train error: \n",
      " D loss: 1.322743, G loss: 0.682682, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301600, G loss: 0.698670, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4090, G loss: 0.5594\n",
      "[84/1762] D loss: 1.1296, G loss: 0.8648\n",
      "[164/1762] D loss: 1.4138, G loss: 0.8014\n",
      "[244/1762] D loss: 1.1025, G loss: 0.8634\n",
      "[324/1762] D loss: 1.0700, G loss: 1.1917\n",
      "[404/1762] D loss: 1.1406, G loss: 1.1302\n",
      "[484/1762] D loss: 1.1154, G loss: 0.9352\n",
      "[564/1762] D loss: 1.4003, G loss: 0.7038\n",
      "[644/1762] D loss: 1.1339, G loss: 1.0412\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6674\n",
      "[804/1762] D loss: 1.1542, G loss: 0.8762\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6837\n",
      "[964/1762] D loss: 1.3886, G loss: 0.6788\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6847\n",
      "[1124/1762] D loss: 1.4171, G loss: 0.6938\n",
      "[1204/1762] D loss: 1.2841, G loss: 0.7129\n",
      "[1284/1762] D loss: 1.4990, G loss: 1.0536\n",
      "[1364/1762] D loss: 1.2446, G loss: 1.2559\n",
      "[1444/1762] D loss: 1.4854, G loss: 0.5410\n",
      "[1524/1762] D loss: 1.5134, G loss: 0.8497\n",
      "[1604/1762] D loss: 1.2153, G loss: 0.8396\n",
      "[1684/1762] D loss: 1.2985, G loss: 0.6210\n",
      "[1762/1762] D loss: 0.9592, G loss: 0.7661\n",
      "train error: \n",
      " D loss: 1.340393, G loss: 0.708833, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325933, G loss: 0.715142, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6395\n",
      "[84/1762] D loss: 1.4593, G loss: 0.9026\n",
      "[164/1762] D loss: 1.3894, G loss: 0.7118\n",
      "[244/1762] D loss: 1.2120, G loss: 0.8609\n",
      "[324/1762] D loss: 1.4094, G loss: 0.7653\n",
      "[404/1762] D loss: 1.0683, G loss: 0.9016\n",
      "[484/1762] D loss: 1.4011, G loss: 0.8494\n",
      "[564/1762] D loss: 1.3012, G loss: 0.8460\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6599\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6343\n",
      "[804/1762] D loss: 1.3763, G loss: 0.7587\n",
      "[884/1762] D loss: 1.0965, G loss: 1.1525\n",
      "[964/1762] D loss: 1.3937, G loss: 0.7102\n",
      "[1044/1762] D loss: 1.1313, G loss: 1.1698\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.6895\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.6536\n",
      "[1284/1762] D loss: 1.1394, G loss: 0.8959\n",
      "[1364/1762] D loss: 1.4128, G loss: 0.7735\n",
      "[1444/1762] D loss: 1.4047, G loss: 0.6260\n",
      "[1524/1762] D loss: 1.1645, G loss: 0.8015\n",
      "[1604/1762] D loss: 1.3959, G loss: 0.6627\n",
      "[1684/1762] D loss: 1.4032, G loss: 0.6787\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.6659\n",
      "train error: \n",
      " D loss: 1.322154, G loss: 0.724772, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304687, G loss: 0.738118, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6490\n",
      "[84/1762] D loss: 1.1387, G loss: 0.8601\n",
      "[164/1762] D loss: 1.1456, G loss: 0.8790\n",
      "[244/1762] D loss: 1.1494, G loss: 0.7246\n",
      "[324/1762] D loss: 1.3889, G loss: 0.7336\n",
      "[404/1762] D loss: 1.3937, G loss: 0.6650\n",
      "[484/1762] D loss: 1.1186, G loss: 0.8854\n",
      "[564/1762] D loss: 1.1270, G loss: 0.8719\n",
      "[644/1762] D loss: 1.1545, G loss: 0.9591\n",
      "[724/1762] D loss: 1.3887, G loss: 0.7589\n",
      "[804/1762] D loss: 1.4088, G loss: 0.8426\n",
      "[884/1762] D loss: 1.3994, G loss: 0.7233\n",
      "[964/1762] D loss: 1.3916, G loss: 0.6862\n",
      "[1044/1762] D loss: 1.4021, G loss: 0.7351\n",
      "[1124/1762] D loss: 1.4021, G loss: 0.7993\n",
      "[1204/1762] D loss: 1.3776, G loss: 0.7912\n",
      "[1284/1762] D loss: 1.4189, G loss: 0.7266\n",
      "[1364/1762] D loss: 1.1872, G loss: 1.0000\n",
      "[1444/1762] D loss: 1.1376, G loss: 0.8981\n",
      "[1524/1762] D loss: 1.4188, G loss: 0.8436\n",
      "[1604/1762] D loss: 1.1029, G loss: 0.9495\n",
      "[1684/1762] D loss: 1.2979, G loss: 0.8338\n",
      "[1762/1762] D loss: 1.4064, G loss: 0.8268\n",
      "train error: \n",
      " D loss: 1.307243, G loss: 0.871954, D accuracy: 53.7%, cell accuracy: 99.4%, board accuracy: 62.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284034, G loss: 0.900866, D accuracy: 54.5%, cell accuracy: 99.3%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2866, G loss: 0.8361\n",
      "[84/1762] D loss: 1.2318, G loss: 0.9100\n",
      "[164/1762] D loss: 1.3423, G loss: 0.7714\n",
      "[244/1762] D loss: 1.3967, G loss: 0.6359\n",
      "[324/1762] D loss: 1.3877, G loss: 0.5640\n",
      "[404/1762] D loss: 1.4130, G loss: 0.7614\n",
      "[484/1762] D loss: 1.4034, G loss: 0.7845\n",
      "[564/1762] D loss: 1.4009, G loss: 0.7434\n",
      "[644/1762] D loss: 1.3699, G loss: 0.6331\n",
      "[724/1762] D loss: 1.4041, G loss: 0.7927\n",
      "[804/1762] D loss: 0.9699, G loss: 0.8072\n",
      "[884/1762] D loss: 1.3878, G loss: 0.7231\n",
      "[964/1762] D loss: 1.1276, G loss: 0.9673\n",
      "[1044/1762] D loss: 1.4064, G loss: 0.6276\n",
      "[1124/1762] D loss: 1.4258, G loss: 0.6368\n",
      "[1204/1762] D loss: 1.0191, G loss: 1.0231\n",
      "[1284/1762] D loss: 1.4390, G loss: 0.8192\n",
      "[1364/1762] D loss: 1.4034, G loss: 0.6572\n",
      "[1444/1762] D loss: 0.8905, G loss: 1.1058\n",
      "[1524/1762] D loss: 1.4215, G loss: 0.7795\n",
      "[1604/1762] D loss: 1.4255, G loss: 0.7180\n",
      "[1684/1762] D loss: 1.1228, G loss: 0.8502\n",
      "[1762/1762] D loss: 1.3797, G loss: 0.6841\n",
      "train error: \n",
      " D loss: 1.320028, G loss: 0.714532, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296812, G loss: 0.739581, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3857, G loss: 0.6962\n",
      "[84/1762] D loss: 1.1142, G loss: 0.9828\n",
      "[164/1762] D loss: 1.3576, G loss: 0.7249\n",
      "[244/1762] D loss: 1.4082, G loss: 0.7784\n",
      "[324/1762] D loss: 1.3918, G loss: 0.6835\n",
      "[404/1762] D loss: 1.3690, G loss: 0.6993\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7330\n",
      "[564/1762] D loss: 1.3385, G loss: 0.8452\n",
      "[644/1762] D loss: 1.1798, G loss: 0.6831\n",
      "[724/1762] D loss: 1.3990, G loss: 0.7143\n",
      "[804/1762] D loss: 1.3727, G loss: 0.6480\n",
      "[884/1762] D loss: 1.1320, G loss: 1.1318\n",
      "[964/1762] D loss: 1.4699, G loss: 0.9056\n",
      "[1044/1762] D loss: 1.1262, G loss: 0.9048\n",
      "[1124/1762] D loss: 1.4216, G loss: 0.8415\n",
      "[1204/1762] D loss: 1.3817, G loss: 0.7616\n",
      "[1284/1762] D loss: 1.1366, G loss: 1.1037\n",
      "[1364/1762] D loss: 1.3853, G loss: 0.8002\n",
      "[1444/1762] D loss: 1.1409, G loss: 0.8192\n",
      "[1524/1762] D loss: 1.4022, G loss: 0.7521\n",
      "[1604/1762] D loss: 1.1083, G loss: 1.0372\n",
      "[1684/1762] D loss: 1.4275, G loss: 0.8779\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.7060\n",
      "train error: \n",
      " D loss: 1.316023, G loss: 0.743797, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295272, G loss: 0.763318, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6409\n",
      "[84/1762] D loss: 1.3823, G loss: 0.8030\n",
      "[164/1762] D loss: 1.3885, G loss: 0.8619\n",
      "[244/1762] D loss: 1.4180, G loss: 0.7690\n",
      "[324/1762] D loss: 1.1453, G loss: 0.7914\n",
      "[404/1762] D loss: 1.3928, G loss: 0.5566\n",
      "[484/1762] D loss: 1.3902, G loss: 0.6701\n",
      "[564/1762] D loss: 1.3935, G loss: 0.6508\n",
      "[644/1762] D loss: 1.0758, G loss: 1.0690\n",
      "[724/1762] D loss: 1.4116, G loss: 0.7721\n",
      "[804/1762] D loss: 1.3960, G loss: 0.6160\n",
      "[884/1762] D loss: 1.4112, G loss: 0.5794\n",
      "[964/1762] D loss: 1.1468, G loss: 0.8038\n",
      "[1044/1762] D loss: 1.3955, G loss: 0.6900\n",
      "[1124/1762] D loss: 1.1327, G loss: 0.9108\n",
      "[1204/1762] D loss: 1.4692, G loss: 0.6127\n",
      "[1284/1762] D loss: 1.1441, G loss: 0.8955\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.6892\n",
      "[1444/1762] D loss: 1.1416, G loss: 0.8772\n",
      "[1524/1762] D loss: 1.1141, G loss: 0.8381\n",
      "[1604/1762] D loss: 1.3928, G loss: 0.6004\n",
      "[1684/1762] D loss: 1.1292, G loss: 0.9822\n",
      "[1762/1762] D loss: 1.3387, G loss: 0.7325\n",
      "train error: \n",
      " D loss: 1.369216, G loss: 0.763358, D accuracy: 50.2%, cell accuracy: 99.6%, board accuracy: 72.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346735, G loss: 0.785102, D accuracy: 51.6%, cell accuracy: 99.6%, board accuracy: 71.1% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6257, G loss: 0.5946\n",
      "[84/1762] D loss: 1.2682, G loss: 0.7468\n",
      "[164/1762] D loss: 1.3639, G loss: 0.7526\n",
      "[244/1762] D loss: 1.3953, G loss: 0.7759\n",
      "[324/1762] D loss: 1.3957, G loss: 0.7728\n",
      "[404/1762] D loss: 1.4729, G loss: 0.6340\n",
      "[484/1762] D loss: 1.5029, G loss: 0.7206\n",
      "[564/1762] D loss: 1.5093, G loss: 0.5926\n",
      "[644/1762] D loss: 1.4095, G loss: 0.6325\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6737\n",
      "[804/1762] D loss: 1.2214, G loss: 0.8638\n",
      "[884/1762] D loss: 1.4726, G loss: 0.5730\n",
      "[964/1762] D loss: 1.4680, G loss: 0.6812\n",
      "[1044/1762] D loss: 1.3833, G loss: 0.7751\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7249\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.7790\n",
      "[1284/1762] D loss: 1.4609, G loss: 0.6243\n",
      "[1364/1762] D loss: 1.4727, G loss: 0.7052\n",
      "[1444/1762] D loss: 1.4117, G loss: 0.7377\n",
      "[1524/1762] D loss: 0.9668, G loss: 0.9174\n",
      "[1604/1762] D loss: 1.1874, G loss: 0.8024\n",
      "[1684/1762] D loss: 1.3735, G loss: 0.6446\n",
      "[1762/1762] D loss: 1.3928, G loss: 0.8188\n",
      "train error: \n",
      " D loss: 1.335705, G loss: 0.687998, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 70.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323610, G loss: 0.702027, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2522, G loss: 0.5929\n",
      "[84/1762] D loss: 1.2892, G loss: 0.5803\n",
      "[164/1762] D loss: 1.4058, G loss: 0.5725\n",
      "[244/1762] D loss: 1.1990, G loss: 0.7539\n",
      "[324/1762] D loss: 1.3973, G loss: 0.6849\n",
      "[404/1762] D loss: 1.3997, G loss: 0.7419\n",
      "[484/1762] D loss: 1.3888, G loss: 0.6274\n",
      "[564/1762] D loss: 1.3950, G loss: 0.6624\n",
      "[644/1762] D loss: 1.3935, G loss: 0.7261\n",
      "[724/1762] D loss: 1.1594, G loss: 0.7410\n",
      "[804/1762] D loss: 1.0119, G loss: 0.9593\n",
      "[884/1762] D loss: 1.3625, G loss: 0.7645\n",
      "[964/1762] D loss: 1.0686, G loss: 1.0062\n",
      "[1044/1762] D loss: 1.2092, G loss: 0.7068\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6736\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6972\n",
      "[1284/1762] D loss: 1.1444, G loss: 0.9365\n",
      "[1364/1762] D loss: 1.3737, G loss: 0.6188\n",
      "[1444/1762] D loss: 1.3262, G loss: 0.6763\n",
      "[1524/1762] D loss: 1.3447, G loss: 0.6921\n",
      "[1604/1762] D loss: 1.4242, G loss: 0.6772\n",
      "[1684/1762] D loss: 1.4019, G loss: 0.7758\n",
      "[1762/1762] D loss: 1.0493, G loss: 1.0246\n",
      "train error: \n",
      " D loss: 1.321005, G loss: 0.767374, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301945, G loss: 0.788686, D accuracy: 57.0%, cell accuracy: 99.6%, board accuracy: 70.9% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3841, G loss: 0.6258\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6409\n",
      "[164/1762] D loss: 1.3776, G loss: 0.6145\n",
      "[244/1762] D loss: 1.1618, G loss: 0.8047\n",
      "[324/1762] D loss: 1.0594, G loss: 0.9291\n",
      "[404/1762] D loss: 1.3859, G loss: 0.5960\n",
      "[484/1762] D loss: 1.1565, G loss: 0.7608\n",
      "[564/1762] D loss: 1.3317, G loss: 0.8884\n",
      "[644/1762] D loss: 1.3140, G loss: 0.8329\n",
      "[724/1762] D loss: 1.1720, G loss: 0.8570\n",
      "[804/1762] D loss: 1.3913, G loss: 0.7148\n",
      "[884/1762] D loss: 1.3793, G loss: 0.7638\n",
      "[964/1762] D loss: 1.2073, G loss: 0.9948\n",
      "[1044/1762] D loss: 1.3778, G loss: 0.6699\n",
      "[1124/1762] D loss: 1.1650, G loss: 0.8595\n",
      "[1204/1762] D loss: 1.4007, G loss: 0.7794\n",
      "[1284/1762] D loss: 1.3942, G loss: 0.6910\n",
      "[1364/1762] D loss: 1.3636, G loss: 0.7229\n",
      "[1444/1762] D loss: 1.3973, G loss: 0.7617\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.6206\n",
      "[1604/1762] D loss: 1.3709, G loss: 0.6686\n",
      "[1684/1762] D loss: 1.1598, G loss: 1.0658\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.6881\n",
      "train error: \n",
      " D loss: 1.320919, G loss: 0.798436, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305448, G loss: 0.817827, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3967, G loss: 0.7315\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6157\n",
      "[164/1762] D loss: 1.4056, G loss: 0.6983\n",
      "[244/1762] D loss: 1.4327, G loss: 0.7296\n",
      "[324/1762] D loss: 1.3957, G loss: 0.7128\n",
      "[404/1762] D loss: 1.4028, G loss: 0.6758\n",
      "[484/1762] D loss: 1.4218, G loss: 0.7901\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6913\n",
      "[644/1762] D loss: 1.1398, G loss: 0.8786\n",
      "[724/1762] D loss: 1.3760, G loss: 0.7899\n",
      "[804/1762] D loss: 1.4114, G loss: 0.7549\n",
      "[884/1762] D loss: 1.4031, G loss: 0.6748\n",
      "[964/1762] D loss: 1.1398, G loss: 0.8843\n",
      "[1044/1762] D loss: 1.4057, G loss: 0.6290\n",
      "[1124/1762] D loss: 0.8727, G loss: 1.0856\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.6179\n",
      "[1284/1762] D loss: 1.1635, G loss: 0.7118\n",
      "[1364/1762] D loss: 1.4019, G loss: 0.6056\n",
      "[1444/1762] D loss: 1.3493, G loss: 0.6897\n",
      "[1524/1762] D loss: 1.2910, G loss: 0.8061\n",
      "[1604/1762] D loss: 1.1431, G loss: 0.8708\n",
      "[1684/1762] D loss: 1.3741, G loss: 0.6498\n",
      "[1762/1762] D loss: 1.3784, G loss: 0.6034\n",
      "train error: \n",
      " D loss: 1.379721, G loss: 0.524898, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358728, G loss: 0.544629, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4569, G loss: 0.4810\n",
      "[84/1762] D loss: 1.3985, G loss: 0.6364\n",
      "[164/1762] D loss: 1.1446, G loss: 0.9589\n",
      "[244/1762] D loss: 1.1302, G loss: 0.8850\n",
      "[324/1762] D loss: 1.4223, G loss: 0.8615\n",
      "[404/1762] D loss: 1.3989, G loss: 0.6470\n",
      "[484/1762] D loss: 1.0140, G loss: 0.9490\n",
      "[564/1762] D loss: 1.3615, G loss: 0.6390\n",
      "[644/1762] D loss: 1.4851, G loss: 0.6050\n",
      "[724/1762] D loss: 1.2928, G loss: 0.7510\n",
      "[804/1762] D loss: 1.3675, G loss: 0.6787\n",
      "[884/1762] D loss: 1.4108, G loss: 0.5824\n",
      "[964/1762] D loss: 1.3692, G loss: 0.6606\n",
      "[1044/1762] D loss: 1.4201, G loss: 0.8786\n",
      "[1124/1762] D loss: 1.4152, G loss: 0.8622\n",
      "[1204/1762] D loss: 1.4784, G loss: 0.9450\n",
      "[1284/1762] D loss: 1.4007, G loss: 0.7400\n",
      "[1364/1762] D loss: 1.4422, G loss: 0.4956\n",
      "[1444/1762] D loss: 1.4063, G loss: 0.7212\n",
      "[1524/1762] D loss: 0.9250, G loss: 0.9325\n",
      "[1604/1762] D loss: 1.1461, G loss: 0.8534\n",
      "[1684/1762] D loss: 1.4001, G loss: 0.5883\n",
      "[1762/1762] D loss: 0.7337, G loss: 1.4979\n",
      "train error: \n",
      " D loss: 1.327523, G loss: 0.633410, D accuracy: 55.4%, cell accuracy: 99.6%, board accuracy: 80.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304842, G loss: 0.657169, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3769, G loss: 0.6848\n",
      "[84/1762] D loss: 1.3824, G loss: 0.5993\n",
      "[164/1762] D loss: 1.0927, G loss: 1.0924\n",
      "[244/1762] D loss: 1.4080, G loss: 0.5717\n",
      "[324/1762] D loss: 1.3392, G loss: 0.5929\n",
      "[404/1762] D loss: 1.4872, G loss: 0.9537\n",
      "[484/1762] D loss: 1.3258, G loss: 0.8172\n",
      "[564/1762] D loss: 1.3934, G loss: 0.6697\n",
      "[644/1762] D loss: 1.3607, G loss: 0.7978\n",
      "[724/1762] D loss: 1.4509, G loss: 0.7556\n",
      "[804/1762] D loss: 1.1446, G loss: 0.7910\n",
      "[884/1762] D loss: 1.3818, G loss: 0.7589\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6403\n",
      "[1044/1762] D loss: 1.4097, G loss: 0.6158\n",
      "[1124/1762] D loss: 1.3911, G loss: 0.7459\n",
      "[1204/1762] D loss: 1.3902, G loss: 0.7288\n",
      "[1284/1762] D loss: 1.4172, G loss: 0.7457\n",
      "[1364/1762] D loss: 1.3108, G loss: 0.8005\n",
      "[1444/1762] D loss: 1.4166, G loss: 0.7046\n",
      "[1524/1762] D loss: 1.3741, G loss: 0.6549\n",
      "[1604/1762] D loss: 1.4028, G loss: 0.6233\n",
      "[1684/1762] D loss: 1.3925, G loss: 0.5888\n",
      "[1762/1762] D loss: 1.4103, G loss: 0.7294\n",
      "train error: \n",
      " D loss: 1.323088, G loss: 0.763256, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304597, G loss: 0.785161, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6011\n",
      "[84/1762] D loss: 1.1684, G loss: 0.8732\n",
      "[164/1762] D loss: 1.1100, G loss: 0.9725\n",
      "[244/1762] D loss: 1.1283, G loss: 1.0549\n",
      "[324/1762] D loss: 1.4167, G loss: 0.7424\n",
      "[404/1762] D loss: 1.3894, G loss: 0.7214\n",
      "[484/1762] D loss: 1.4010, G loss: 0.6831\n",
      "[564/1762] D loss: 1.3933, G loss: 0.6990\n",
      "[644/1762] D loss: 1.1504, G loss: 0.8206\n",
      "[724/1762] D loss: 0.9153, G loss: 1.1367\n",
      "[804/1762] D loss: 1.4071, G loss: 0.7736\n",
      "[884/1762] D loss: 1.1497, G loss: 0.7985\n",
      "[964/1762] D loss: 1.1618, G loss: 0.8446\n",
      "[1044/1762] D loss: 1.3935, G loss: 0.6434\n",
      "[1124/1762] D loss: 1.3319, G loss: 0.8268\n",
      "[1204/1762] D loss: 0.9089, G loss: 0.9183\n",
      "[1284/1762] D loss: 1.3525, G loss: 0.6726\n",
      "[1364/1762] D loss: 1.4015, G loss: 0.7678\n",
      "[1444/1762] D loss: 1.4046, G loss: 0.9103\n",
      "[1524/1762] D loss: 1.1052, G loss: 1.0254\n",
      "[1604/1762] D loss: 0.8521, G loss: 1.2856\n",
      "[1684/1762] D loss: 1.1221, G loss: 0.9477\n",
      "[1762/1762] D loss: 1.4067, G loss: 0.6842\n",
      "train error: \n",
      " D loss: 1.288701, G loss: 0.779732, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 79.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275005, G loss: 0.799235, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933, G loss: 0.7411\n",
      "[84/1762] D loss: 1.2060, G loss: 0.8308\n",
      "[164/1762] D loss: 1.4017, G loss: 0.6814\n",
      "[244/1762] D loss: 1.1089, G loss: 0.8529\n",
      "[324/1762] D loss: 1.4003, G loss: 0.6595\n",
      "[404/1762] D loss: 1.3921, G loss: 0.6914\n",
      "[484/1762] D loss: 1.3685, G loss: 0.8732\n",
      "[564/1762] D loss: 1.1330, G loss: 0.8382\n",
      "[644/1762] D loss: 1.3843, G loss: 0.7536\n",
      "[724/1762] D loss: 1.1488, G loss: 0.9132\n",
      "[804/1762] D loss: 1.4077, G loss: 0.7627\n",
      "[884/1762] D loss: 1.0568, G loss: 1.0290\n",
      "[964/1762] D loss: 1.4006, G loss: 0.7067\n",
      "[1044/1762] D loss: 1.4296, G loss: 0.6984\n",
      "[1124/1762] D loss: 1.2494, G loss: 0.8944\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.8028\n",
      "[1284/1762] D loss: 1.3953, G loss: 0.6255\n",
      "[1364/1762] D loss: 1.1339, G loss: 0.8481\n",
      "[1444/1762] D loss: 1.1488, G loss: 1.0608\n",
      "[1524/1762] D loss: 1.1036, G loss: 0.8623\n",
      "[1604/1762] D loss: 1.1063, G loss: 0.9292\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.6511\n",
      "[1762/1762] D loss: 0.8446, G loss: 1.1922\n",
      "train error: \n",
      " D loss: 1.322793, G loss: 0.835831, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304081, G loss: 0.858648, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4127, G loss: 0.9128\n",
      "[84/1762] D loss: 1.4306, G loss: 0.8545\n",
      "[164/1762] D loss: 1.0985, G loss: 0.8949\n",
      "[244/1762] D loss: 1.4750, G loss: 0.8332\n",
      "[324/1762] D loss: 1.3114, G loss: 0.9691\n",
      "[404/1762] D loss: 1.1380, G loss: 0.8078\n",
      "[484/1762] D loss: 1.3629, G loss: 0.7452\n",
      "[564/1762] D loss: 1.1696, G loss: 0.8430\n",
      "[644/1762] D loss: 1.1379, G loss: 0.8290\n",
      "[724/1762] D loss: 1.3113, G loss: 0.7903\n",
      "[804/1762] D loss: 1.1551, G loss: 1.1141\n",
      "[884/1762] D loss: 1.3441, G loss: 0.6225\n",
      "[964/1762] D loss: 1.3901, G loss: 0.6624\n",
      "[1044/1762] D loss: 1.1505, G loss: 0.9305\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.9657\n",
      "[1204/1762] D loss: 1.4015, G loss: 0.5664\n",
      "[1284/1762] D loss: 1.3587, G loss: 0.7791\n",
      "[1364/1762] D loss: 1.1414, G loss: 0.8880\n",
      "[1444/1762] D loss: 0.8774, G loss: 1.1340\n",
      "[1524/1762] D loss: 1.3799, G loss: 0.8497\n",
      "[1604/1762] D loss: 1.4591, G loss: 0.8532\n",
      "[1684/1762] D loss: 1.1250, G loss: 0.7857\n",
      "[1762/1762] D loss: 0.8809, G loss: 1.0004\n",
      "train error: \n",
      " D loss: 1.296817, G loss: 0.745077, D accuracy: 56.8%, cell accuracy: 99.8%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283175, G loss: 0.766659, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1268, G loss: 0.9415\n",
      "[84/1762] D loss: 1.3959, G loss: 0.7365\n",
      "[164/1762] D loss: 1.2882, G loss: 0.9685\n",
      "[244/1762] D loss: 1.1639, G loss: 0.7823\n",
      "[324/1762] D loss: 1.3879, G loss: 0.5828\n",
      "[404/1762] D loss: 1.3916, G loss: 0.7590\n",
      "[484/1762] D loss: 1.3957, G loss: 0.7533\n",
      "[564/1762] D loss: 1.4219, G loss: 0.7750\n",
      "[644/1762] D loss: 1.1204, G loss: 0.8062\n",
      "[724/1762] D loss: 1.3898, G loss: 0.7330\n",
      "[804/1762] D loss: 1.3951, G loss: 0.6853\n",
      "[884/1762] D loss: 1.1493, G loss: 1.0926\n",
      "[964/1762] D loss: 1.3832, G loss: 0.8397\n",
      "[1044/1762] D loss: 1.4463, G loss: 0.9036\n",
      "[1124/1762] D loss: 1.1223, G loss: 1.0800\n",
      "[1204/1762] D loss: 1.4081, G loss: 0.8246\n",
      "[1284/1762] D loss: 1.4089, G loss: 0.7975\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7210\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.6993\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.6957\n",
      "[1604/1762] D loss: 1.3947, G loss: 0.7399\n",
      "[1684/1762] D loss: 1.3566, G loss: 0.6458\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.6076\n",
      "train error: \n",
      " D loss: 1.319353, G loss: 0.688599, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301858, G loss: 0.708268, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4058, G loss: 0.5992\n",
      "[84/1762] D loss: 1.1042, G loss: 0.9484\n",
      "[164/1762] D loss: 1.4065, G loss: 0.7439\n",
      "[244/1762] D loss: 1.1141, G loss: 0.8946\n",
      "[324/1762] D loss: 1.1137, G loss: 0.9683\n",
      "[404/1762] D loss: 1.1203, G loss: 0.8106\n",
      "[484/1762] D loss: 1.4195, G loss: 0.5737\n",
      "[564/1762] D loss: 1.1670, G loss: 0.6963\n",
      "[644/1762] D loss: 1.3936, G loss: 0.6134\n",
      "[724/1762] D loss: 1.1210, G loss: 1.1290\n",
      "[804/1762] D loss: 1.3928, G loss: 0.8172\n",
      "[884/1762] D loss: 1.3889, G loss: 0.7408\n",
      "[964/1762] D loss: 1.1038, G loss: 0.9371\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.7000\n",
      "[1124/1762] D loss: 1.0968, G loss: 0.9167\n",
      "[1204/1762] D loss: 1.1145, G loss: 0.8628\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6356\n",
      "[1364/1762] D loss: 1.3969, G loss: 0.6252\n",
      "[1444/1762] D loss: 1.3917, G loss: 0.6610\n",
      "[1524/1762] D loss: 1.4059, G loss: 0.7150\n",
      "[1604/1762] D loss: 1.1027, G loss: 0.8603\n",
      "[1684/1762] D loss: 1.4417, G loss: 0.5566\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.7557\n",
      "train error: \n",
      " D loss: 1.315597, G loss: 0.727816, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291719, G loss: 0.756299, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3888, G loss: 0.6941\n",
      "[84/1762] D loss: 1.1167, G loss: 1.0113\n",
      "[164/1762] D loss: 1.4065, G loss: 0.7012\n",
      "[244/1762] D loss: 1.3970, G loss: 0.6401\n",
      "[324/1762] D loss: 1.3893, G loss: 0.7110\n",
      "[404/1762] D loss: 1.1129, G loss: 1.0289\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7088\n",
      "[564/1762] D loss: 1.4045, G loss: 0.7601\n",
      "[644/1762] D loss: 1.3948, G loss: 0.6239\n",
      "[724/1762] D loss: 1.3900, G loss: 0.7420\n",
      "[804/1762] D loss: 1.3907, G loss: 0.7294\n",
      "[884/1762] D loss: 1.3933, G loss: 0.6730\n",
      "[964/1762] D loss: 1.3294, G loss: 0.8748\n",
      "[1044/1762] D loss: 1.4290, G loss: 0.5239\n",
      "[1124/1762] D loss: 1.0914, G loss: 1.0454\n",
      "[1204/1762] D loss: 1.3803, G loss: 0.8781\n",
      "[1284/1762] D loss: 1.1104, G loss: 0.9668\n",
      "[1364/1762] D loss: 1.1187, G loss: 0.7864\n",
      "[1444/1762] D loss: 1.0650, G loss: 1.3232\n",
      "[1524/1762] D loss: 1.1370, G loss: 0.8741\n",
      "[1604/1762] D loss: 1.0990, G loss: 1.0006\n",
      "[1684/1762] D loss: 1.0976, G loss: 1.0526\n",
      "[1762/1762] D loss: 1.4171, G loss: 0.5352\n",
      "train error: \n",
      " D loss: 1.298195, G loss: 0.696249, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282362, G loss: 0.713169, D accuracy: 57.2%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3162, G loss: 0.7238\n",
      "[84/1762] D loss: 1.3991, G loss: 0.7211\n",
      "[164/1762] D loss: 1.4029, G loss: 0.6505\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7547\n",
      "[324/1762] D loss: 1.3950, G loss: 0.6851\n",
      "[404/1762] D loss: 1.3966, G loss: 0.5945\n",
      "[484/1762] D loss: 1.4126, G loss: 0.6074\n",
      "[564/1762] D loss: 1.4137, G loss: 0.6685\n",
      "[644/1762] D loss: 1.4047, G loss: 0.9116\n",
      "[724/1762] D loss: 1.4144, G loss: 0.8292\n",
      "[804/1762] D loss: 1.4020, G loss: 0.7303\n",
      "[884/1762] D loss: 1.4177, G loss: 0.9021\n",
      "[964/1762] D loss: 0.8231, G loss: 1.2111\n",
      "[1044/1762] D loss: 1.3990, G loss: 0.7928\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.7738\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.7287\n",
      "[1284/1762] D loss: 1.3954, G loss: 0.8085\n",
      "[1364/1762] D loss: 1.3914, G loss: 0.6200\n",
      "[1444/1762] D loss: 1.0961, G loss: 0.9448\n",
      "[1524/1762] D loss: 1.4013, G loss: 0.7719\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.6497\n",
      "[1684/1762] D loss: 1.4015, G loss: 0.6336\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7164\n",
      "train error: \n",
      " D loss: 1.311708, G loss: 0.834614, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293863, G loss: 0.855017, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4003, G loss: 0.7757\n",
      "[84/1762] D loss: 1.4024, G loss: 0.5820\n",
      "[164/1762] D loss: 1.4040, G loss: 0.6050\n",
      "[244/1762] D loss: 1.3811, G loss: 0.7327\n",
      "[324/1762] D loss: 1.1020, G loss: 0.9718\n",
      "[404/1762] D loss: 1.1063, G loss: 0.9031\n",
      "[484/1762] D loss: 1.1866, G loss: 0.7726\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6863\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6509\n",
      "[724/1762] D loss: 1.3911, G loss: 0.6499\n",
      "[804/1762] D loss: 1.3919, G loss: 0.6483\n",
      "[884/1762] D loss: 1.4109, G loss: 0.7767\n",
      "[964/1762] D loss: 1.1180, G loss: 0.8661\n",
      "[1044/1762] D loss: 1.3601, G loss: 0.6450\n",
      "[1124/1762] D loss: 1.3088, G loss: 0.8488\n",
      "[1204/1762] D loss: 1.1184, G loss: 0.9797\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.5731\n",
      "[1364/1762] D loss: 1.3859, G loss: 0.6625\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.7713\n",
      "[1524/1762] D loss: 1.4021, G loss: 0.6881\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7712\n",
      "[1684/1762] D loss: 1.1238, G loss: 1.1024\n",
      "[1762/1762] D loss: 0.8076, G loss: 1.4005\n",
      "train error: \n",
      " D loss: 1.382427, G loss: 1.099578, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362472, G loss: 1.123653, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 76.1% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6947\n",
      "[84/1762] D loss: 1.3846, G loss: 0.6931\n",
      "[164/1762] D loss: 1.3784, G loss: 0.6953\n",
      "[244/1762] D loss: 1.3687, G loss: 0.6969\n",
      "[324/1762] D loss: 1.3466, G loss: 0.6948\n",
      "[404/1762] D loss: 1.3198, G loss: 0.6991\n",
      "[484/1762] D loss: 1.2513, G loss: 0.7127\n",
      "[564/1762] D loss: 1.1777, G loss: 0.7037\n",
      "[644/1762] D loss: 1.0938, G loss: 0.7297\n",
      "[724/1762] D loss: 1.0980, G loss: 0.7165\n",
      "[804/1762] D loss: 1.0224, G loss: 0.7594\n",
      "[884/1762] D loss: 0.9062, G loss: 0.9670\n",
      "[964/1762] D loss: 0.7464, G loss: 1.2057\n",
      "[1044/1762] D loss: 0.6616, G loss: 1.3659\n",
      "[1124/1762] D loss: 0.5313, G loss: 1.7080\n",
      "[1204/1762] D loss: 0.5484, G loss: 1.6556\n",
      "[1284/1762] D loss: 0.4240, G loss: 2.0102\n",
      "[1364/1762] D loss: 0.5634, G loss: 2.3023\n",
      "[1444/1762] D loss: 0.3877, G loss: 2.4943\n",
      "[1524/1762] D loss: 0.5612, G loss: 2.6526\n",
      "[1604/1762] D loss: 0.3181, G loss: 2.4069\n",
      "[1684/1762] D loss: 0.3442, G loss: 2.4784\n",
      "[1762/1762] D loss: 0.2768, G loss: 3.3576\n",
      "train error: \n",
      " D loss: 0.321264, G loss: 3.100963, D accuracy: 100.0%, cell accuracy: 92.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.323706, G loss: 3.027976, D accuracy: 100.0%, cell accuracy: 92.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3039, G loss: 2.9770\n",
      "[84/1762] D loss: 0.2798, G loss: 2.8063\n",
      "[164/1762] D loss: 0.2604, G loss: 3.4973\n",
      "[244/1762] D loss: 0.2132, G loss: 3.3551\n",
      "[324/1762] D loss: 0.2838, G loss: 2.9447\n",
      "[404/1762] D loss: 0.3135, G loss: 2.8003\n",
      "[484/1762] D loss: 0.3863, G loss: 3.3034\n",
      "[564/1762] D loss: 0.5451, G loss: 3.9938\n",
      "[644/1762] D loss: 0.4550, G loss: 2.9140\n",
      "[724/1762] D loss: 0.2872, G loss: 4.3088\n",
      "[804/1762] D loss: 0.3558, G loss: 2.9643\n",
      "[884/1762] D loss: 0.3425, G loss: 3.3326\n",
      "[964/1762] D loss: 0.1187, G loss: 3.8477\n",
      "[1044/1762] D loss: 0.2542, G loss: 3.4835\n",
      "[1124/1762] D loss: 0.3130, G loss: 3.3858\n",
      "[1204/1762] D loss: 0.3778, G loss: 3.3052\n",
      "[1284/1762] D loss: 0.4629, G loss: 4.6165\n",
      "[1364/1762] D loss: 0.4574, G loss: 3.3251\n",
      "[1444/1762] D loss: 0.3189, G loss: 4.7099\n",
      "[1524/1762] D loss: 0.3181, G loss: 3.9504\n",
      "[1604/1762] D loss: 0.3191, G loss: 3.8466\n",
      "[1684/1762] D loss: 0.4836, G loss: 3.5700\n",
      "[1762/1762] D loss: 0.8737, G loss: 4.8979\n",
      "train error: \n",
      " D loss: 0.473821, G loss: 3.680433, D accuracy: 97.9%, cell accuracy: 94.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.480261, G loss: 3.654778, D accuracy: 97.7%, cell accuracy: 94.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4336, G loss: 3.8036\n",
      "[84/1762] D loss: 0.4576, G loss: 4.5768\n",
      "[164/1762] D loss: 0.4562, G loss: 3.4382\n",
      "[244/1762] D loss: 0.6134, G loss: 3.2466\n",
      "[324/1762] D loss: 0.3889, G loss: 4.2502\n",
      "[404/1762] D loss: 0.5294, G loss: 3.5210\n",
      "[484/1762] D loss: 0.6269, G loss: 3.6015\n",
      "[564/1762] D loss: 0.3492, G loss: 4.2458\n",
      "[644/1762] D loss: 0.7184, G loss: 4.1442\n",
      "[724/1762] D loss: 0.3779, G loss: 4.2731\n",
      "[804/1762] D loss: 0.4510, G loss: 3.7624\n",
      "[884/1762] D loss: 0.4009, G loss: 3.6012\n",
      "[964/1762] D loss: 0.3143, G loss: 3.7385\n",
      "[1044/1762] D loss: 0.3593, G loss: 4.1250\n",
      "[1124/1762] D loss: 0.3402, G loss: 4.0329\n",
      "[1204/1762] D loss: 0.7397, G loss: 2.8952\n",
      "[1284/1762] D loss: 0.4181, G loss: 4.3604\n",
      "[1364/1762] D loss: 0.3545, G loss: 3.4136\n",
      "[1444/1762] D loss: 0.3924, G loss: 3.3878\n",
      "[1524/1762] D loss: 0.2557, G loss: 3.3168\n",
      "[1604/1762] D loss: 0.5366, G loss: 2.8672\n",
      "[1684/1762] D loss: 0.4635, G loss: 2.6883\n",
      "[1762/1762] D loss: 0.2604, G loss: 2.3994\n",
      "train error: \n",
      " D loss: 0.427408, G loss: 2.938963, D accuracy: 97.1%, cell accuracy: 95.6%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.437348, G loss: 2.997469, D accuracy: 96.6%, cell accuracy: 95.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3642, G loss: 3.1216\n",
      "[84/1762] D loss: 0.6799, G loss: 2.3270\n",
      "[164/1762] D loss: 0.1823, G loss: 2.6294\n",
      "[244/1762] D loss: 0.3494, G loss: 2.7158\n",
      "[324/1762] D loss: 0.6244, G loss: 2.5577\n",
      "[404/1762] D loss: 0.5505, G loss: 2.3790\n",
      "[484/1762] D loss: 0.3814, G loss: 3.0418\n",
      "[564/1762] D loss: 0.4934, G loss: 2.6470\n",
      "[644/1762] D loss: 0.7095, G loss: 3.1927\n",
      "[724/1762] D loss: 0.4936, G loss: 1.7907\n",
      "[804/1762] D loss: 0.5424, G loss: 2.5208\n",
      "[884/1762] D loss: 0.3496, G loss: 2.5717\n",
      "[964/1762] D loss: 0.6187, G loss: 1.3018\n",
      "[1044/1762] D loss: 0.2531, G loss: 2.6368\n",
      "[1124/1762] D loss: 0.4129, G loss: 2.0560\n",
      "[1204/1762] D loss: 0.4113, G loss: 2.5311\n",
      "[1284/1762] D loss: 0.7067, G loss: 2.6743\n",
      "[1364/1762] D loss: 0.3198, G loss: 2.2003\n",
      "[1444/1762] D loss: 0.4715, G loss: 1.5854\n",
      "[1524/1762] D loss: 0.4398, G loss: 1.7347\n",
      "[1604/1762] D loss: 0.5082, G loss: 1.4778\n",
      "[1684/1762] D loss: 0.4849, G loss: 1.5044\n",
      "[1762/1762] D loss: 0.6897, G loss: 0.8889\n",
      "train error: \n",
      " D loss: 0.616183, G loss: 1.529908, D accuracy: 91.5%, cell accuracy: 96.4%, board accuracy: 3.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.648296, G loss: 1.450038, D accuracy: 90.3%, cell accuracy: 96.2%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6334, G loss: 1.5395\n",
      "[84/1762] D loss: 0.7204, G loss: 1.5200\n",
      "[164/1762] D loss: 1.0710, G loss: 0.7096\n",
      "[244/1762] D loss: 1.0422, G loss: 1.3949\n",
      "[324/1762] D loss: 0.7733, G loss: 1.5552\n",
      "[404/1762] D loss: 1.0395, G loss: 1.9881\n",
      "[484/1762] D loss: 0.8050, G loss: 1.7773\n",
      "[564/1762] D loss: 0.6062, G loss: 1.4133\n",
      "[644/1762] D loss: 0.8744, G loss: 1.7604\n",
      "[724/1762] D loss: 0.8442, G loss: 1.6817\n",
      "[804/1762] D loss: 0.4978, G loss: 2.0202\n",
      "[884/1762] D loss: 0.9893, G loss: 1.0985\n",
      "[964/1762] D loss: 0.6366, G loss: 1.6434\n",
      "[1044/1762] D loss: 0.4961, G loss: 2.7777\n",
      "[1124/1762] D loss: 0.7965, G loss: 1.2449\n",
      "[1204/1762] D loss: 0.5111, G loss: 1.5023\n",
      "[1284/1762] D loss: 1.0333, G loss: 1.4694\n",
      "[1364/1762] D loss: 0.6818, G loss: 1.9516\n",
      "[1444/1762] D loss: 0.5488, G loss: 2.1586\n",
      "[1524/1762] D loss: 0.8383, G loss: 1.0258\n",
      "[1604/1762] D loss: 0.6326, G loss: 1.1659\n",
      "[1684/1762] D loss: 0.7039, G loss: 1.3408\n",
      "[1762/1762] D loss: 1.4030, G loss: 2.8056\n",
      "train error: \n",
      " D loss: 0.854902, G loss: 1.575756, D accuracy: 83.5%, cell accuracy: 97.7%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.830235, G loss: 1.647749, D accuracy: 83.1%, cell accuracy: 97.5%, board accuracy: 3.9% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9340, G loss: 0.8044\n",
      "[84/1762] D loss: 0.8400, G loss: 0.8996\n",
      "[164/1762] D loss: 0.9697, G loss: 1.3632\n",
      "[244/1762] D loss: 0.6900, G loss: 1.5652\n",
      "[324/1762] D loss: 0.7025, G loss: 1.2312\n",
      "[404/1762] D loss: 0.7864, G loss: 0.9241\n",
      "[484/1762] D loss: 0.8748, G loss: 1.2513\n",
      "[564/1762] D loss: 1.0592, G loss: 2.1875\n",
      "[644/1762] D loss: 0.9841, G loss: 1.5628\n",
      "[724/1762] D loss: 0.9231, G loss: 0.7479\n",
      "[804/1762] D loss: 0.8096, G loss: 1.1359\n",
      "[884/1762] D loss: 1.0150, G loss: 0.6847\n",
      "[964/1762] D loss: 0.7532, G loss: 0.9978\n",
      "[1044/1762] D loss: 0.9982, G loss: 1.3937\n",
      "[1124/1762] D loss: 0.8559, G loss: 2.0931\n",
      "[1204/1762] D loss: 1.0029, G loss: 0.7997\n",
      "[1284/1762] D loss: 1.0860, G loss: 0.5958\n",
      "[1364/1762] D loss: 0.6924, G loss: 1.3432\n",
      "[1444/1762] D loss: 0.5175, G loss: 2.5959\n",
      "[1524/1762] D loss: 1.0084, G loss: 1.0059\n",
      "[1604/1762] D loss: 1.2952, G loss: 0.6268\n",
      "[1684/1762] D loss: 0.9845, G loss: 1.3887\n",
      "[1762/1762] D loss: 1.1449, G loss: 0.9361\n",
      "train error: \n",
      " D loss: 1.027283, G loss: 1.409376, D accuracy: 77.3%, cell accuracy: 98.4%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.009043, G loss: 1.472815, D accuracy: 78.6%, cell accuracy: 98.3%, board accuracy: 5.7% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9856, G loss: 1.1625\n",
      "[84/1762] D loss: 1.4179, G loss: 0.3966\n",
      "[164/1762] D loss: 1.0711, G loss: 0.9826\n",
      "[244/1762] D loss: 0.8925, G loss: 1.4186\n",
      "[324/1762] D loss: 0.8433, G loss: 2.4822\n",
      "[404/1762] D loss: 1.2404, G loss: 1.3142\n",
      "[484/1762] D loss: 1.3478, G loss: 0.6504\n",
      "[564/1762] D loss: 1.1136, G loss: 0.7482\n",
      "[644/1762] D loss: 1.0485, G loss: 1.7388\n",
      "[724/1762] D loss: 0.9162, G loss: 1.4885\n",
      "[804/1762] D loss: 1.2190, G loss: 1.2517\n",
      "[884/1762] D loss: 1.2753, G loss: 0.7112\n",
      "[964/1762] D loss: 1.0947, G loss: 0.6332\n",
      "[1044/1762] D loss: 1.3240, G loss: 1.6915\n",
      "[1124/1762] D loss: 1.1930, G loss: 0.9362\n",
      "[1204/1762] D loss: 1.3286, G loss: 1.0507\n",
      "[1284/1762] D loss: 1.0277, G loss: 0.7320\n",
      "[1364/1762] D loss: 1.1332, G loss: 1.3689\n",
      "[1444/1762] D loss: 1.0636, G loss: 1.2678\n",
      "[1524/1762] D loss: 1.8488, G loss: 0.2888\n",
      "[1604/1762] D loss: 1.0055, G loss: 1.4471\n",
      "[1684/1762] D loss: 1.1462, G loss: 1.0905\n",
      "[1762/1762] D loss: 0.8626, G loss: 1.4694\n",
      "train error: \n",
      " D loss: 1.182777, G loss: 0.888418, D accuracy: 70.7%, cell accuracy: 99.2%, board accuracy: 26.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.200172, G loss: 0.871873, D accuracy: 68.8%, cell accuracy: 99.1%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9881, G loss: 0.9676\n",
      "[84/1762] D loss: 1.0080, G loss: 1.2238\n",
      "[164/1762] D loss: 1.2962, G loss: 1.5170\n",
      "[244/1762] D loss: 1.2102, G loss: 0.8740\n",
      "[324/1762] D loss: 1.3583, G loss: 1.1541\n",
      "[404/1762] D loss: 1.6078, G loss: 0.6167\n",
      "[484/1762] D loss: 1.5830, G loss: 1.8044\n",
      "[564/1762] D loss: 1.4178, G loss: 1.7959\n",
      "[644/1762] D loss: 1.3235, G loss: 0.5503\n",
      "[724/1762] D loss: 1.3253, G loss: 1.2104\n",
      "[804/1762] D loss: 1.7889, G loss: 1.6542\n",
      "[884/1762] D loss: 0.8339, G loss: 1.3916\n",
      "[964/1762] D loss: 1.4656, G loss: 1.0520\n",
      "[1044/1762] D loss: 1.2674, G loss: 1.0325\n",
      "[1124/1762] D loss: 1.2565, G loss: 1.0672\n",
      "[1204/1762] D loss: 1.4808, G loss: 0.9539\n",
      "[1284/1762] D loss: 1.2604, G loss: 0.8996\n",
      "[1364/1762] D loss: 1.2749, G loss: 1.4140\n",
      "[1444/1762] D loss: 1.3000, G loss: 1.1385\n",
      "[1524/1762] D loss: 1.2999, G loss: 0.9589\n",
      "[1604/1762] D loss: 1.2761, G loss: 0.8499\n",
      "[1684/1762] D loss: 1.3095, G loss: 1.0684\n",
      "[1762/1762] D loss: 1.8827, G loss: 1.7608\n",
      "train error: \n",
      " D loss: 1.306400, G loss: 1.026969, D accuracy: 62.9%, cell accuracy: 99.5%, board accuracy: 53.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318206, G loss: 1.005378, D accuracy: 63.4%, cell accuracy: 99.4%, board accuracy: 51.4% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2229, G loss: 0.8738\n",
      "[84/1762] D loss: 1.3676, G loss: 1.0276\n",
      "[164/1762] D loss: 1.3705, G loss: 0.6055\n",
      "[244/1762] D loss: 1.3569, G loss: 0.5937\n",
      "[324/1762] D loss: 1.2431, G loss: 0.9506\n",
      "[404/1762] D loss: 1.3125, G loss: 0.8038\n",
      "[484/1762] D loss: 1.1383, G loss: 0.7772\n",
      "[564/1762] D loss: 1.4622, G loss: 1.0538\n",
      "[644/1762] D loss: 1.2580, G loss: 1.0760\n",
      "[724/1762] D loss: 1.3635, G loss: 0.7876\n",
      "[804/1762] D loss: 1.2382, G loss: 0.9871\n",
      "[884/1762] D loss: 1.0966, G loss: 1.0239\n",
      "[964/1762] D loss: 1.2887, G loss: 0.6226\n",
      "[1044/1762] D loss: 1.2939, G loss: 0.9463\n",
      "[1124/1762] D loss: 1.3838, G loss: 0.7629\n",
      "[1204/1762] D loss: 1.4794, G loss: 0.6664\n",
      "[1284/1762] D loss: 1.4769, G loss: 0.3718\n",
      "[1364/1762] D loss: 1.7499, G loss: 1.2639\n",
      "[1444/1762] D loss: 1.3106, G loss: 0.9061\n",
      "[1524/1762] D loss: 1.3426, G loss: 0.8336\n",
      "[1604/1762] D loss: 1.3239, G loss: 0.6868\n",
      "[1684/1762] D loss: 1.3935, G loss: 0.8143\n",
      "[1762/1762] D loss: 1.1059, G loss: 0.9016\n",
      "train error: \n",
      " D loss: 1.316356, G loss: 0.813253, D accuracy: 61.9%, cell accuracy: 99.6%, board accuracy: 68.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324877, G loss: 0.813847, D accuracy: 60.8%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4953, G loss: 0.6987\n",
      "[84/1762] D loss: 1.2724, G loss: 0.9546\n",
      "[164/1762] D loss: 1.3769, G loss: 0.7948\n",
      "[244/1762] D loss: 1.4890, G loss: 1.0912\n",
      "[324/1762] D loss: 1.4915, G loss: 1.1520\n",
      "[404/1762] D loss: 1.2856, G loss: 0.6461\n",
      "[484/1762] D loss: 1.4074, G loss: 0.5176\n",
      "[564/1762] D loss: 1.3148, G loss: 0.5976\n",
      "[644/1762] D loss: 1.2406, G loss: 0.9416\n",
      "[724/1762] D loss: 1.4521, G loss: 0.4988\n",
      "[804/1762] D loss: 1.3580, G loss: 1.1182\n",
      "[884/1762] D loss: 1.2481, G loss: 0.7550\n",
      "[964/1762] D loss: 1.4288, G loss: 1.0103\n",
      "[1044/1762] D loss: 1.0811, G loss: 0.9377\n",
      "[1124/1762] D loss: 1.3507, G loss: 0.7790\n",
      "[1204/1762] D loss: 1.3455, G loss: 0.8727\n",
      "[1284/1762] D loss: 1.5469, G loss: 1.0809\n",
      "[1364/1762] D loss: 1.2732, G loss: 0.6221\n",
      "[1444/1762] D loss: 1.3502, G loss: 0.6780\n",
      "[1524/1762] D loss: 1.3450, G loss: 0.7297\n",
      "[1604/1762] D loss: 1.2960, G loss: 0.7799\n",
      "[1684/1762] D loss: 1.1264, G loss: 0.7649\n",
      "[1762/1762] D loss: 1.3765, G loss: 0.6641\n",
      "train error: \n",
      " D loss: 1.332157, G loss: 0.810082, D accuracy: 60.3%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339712, G loss: 0.812469, D accuracy: 59.8%, cell accuracy: 99.6%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3280, G loss: 0.8670\n",
      "[84/1762] D loss: 1.2761, G loss: 0.7082\n",
      "[164/1762] D loss: 1.3093, G loss: 0.7596\n",
      "[244/1762] D loss: 1.3602, G loss: 0.7970\n",
      "[324/1762] D loss: 1.4143, G loss: 0.6781\n",
      "[404/1762] D loss: 1.3824, G loss: 1.0047\n",
      "[484/1762] D loss: 1.3580, G loss: 0.6485\n",
      "[564/1762] D loss: 1.1441, G loss: 1.4050\n",
      "[644/1762] D loss: 1.3422, G loss: 0.7949\n",
      "[724/1762] D loss: 1.3174, G loss: 0.6708\n",
      "[804/1762] D loss: 1.4203, G loss: 0.8449\n",
      "[884/1762] D loss: 1.2874, G loss: 0.7555\n",
      "[964/1762] D loss: 1.3787, G loss: 0.9044\n",
      "[1044/1762] D loss: 1.3133, G loss: 0.5959\n",
      "[1124/1762] D loss: 1.3531, G loss: 0.7312\n",
      "[1204/1762] D loss: 1.4015, G loss: 0.5087\n",
      "[1284/1762] D loss: 1.3349, G loss: 1.0258\n",
      "[1364/1762] D loss: 1.3679, G loss: 0.9173\n",
      "[1444/1762] D loss: 1.1860, G loss: 1.2353\n",
      "[1524/1762] D loss: 1.3266, G loss: 0.7493\n",
      "[1604/1762] D loss: 1.3224, G loss: 0.6731\n",
      "[1684/1762] D loss: 1.3532, G loss: 0.5312\n",
      "[1762/1762] D loss: 1.3437, G loss: 0.5500\n",
      "train error: \n",
      " D loss: 1.375105, G loss: 0.616320, D accuracy: 56.3%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382582, G loss: 0.615362, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6354, G loss: 0.4455\n",
      "[84/1762] D loss: 1.1462, G loss: 0.9130\n",
      "[164/1762] D loss: 1.3712, G loss: 0.6834\n",
      "[244/1762] D loss: 1.3510, G loss: 0.7948\n",
      "[324/1762] D loss: 1.3521, G loss: 0.9134\n",
      "[404/1762] D loss: 1.2835, G loss: 0.8225\n",
      "[484/1762] D loss: 1.6446, G loss: 0.4967\n",
      "[564/1762] D loss: 1.3505, G loss: 1.0101\n",
      "[644/1762] D loss: 1.2885, G loss: 0.7158\n",
      "[724/1762] D loss: 1.3676, G loss: 0.8877\n",
      "[804/1762] D loss: 1.3604, G loss: 0.6899\n",
      "[884/1762] D loss: 1.3096, G loss: 0.7472\n",
      "[964/1762] D loss: 1.3706, G loss: 0.6224\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.5663\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.6813\n",
      "[1204/1762] D loss: 1.2583, G loss: 1.0043\n",
      "[1284/1762] D loss: 1.3534, G loss: 0.7673\n",
      "[1364/1762] D loss: 1.4485, G loss: 0.5875\n",
      "[1444/1762] D loss: 1.1727, G loss: 0.9880\n",
      "[1524/1762] D loss: 1.6176, G loss: 0.6921\n",
      "[1604/1762] D loss: 1.2812, G loss: 1.0064\n",
      "[1684/1762] D loss: 1.4708, G loss: 1.0664\n",
      "[1762/1762] D loss: 1.2514, G loss: 0.6629\n",
      "train error: \n",
      " D loss: 1.344311, G loss: 0.773457, D accuracy: 57.7%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350490, G loss: 0.780609, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3428, G loss: 0.6877\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6642\n",
      "[164/1762] D loss: 1.3736, G loss: 0.8584\n",
      "[244/1762] D loss: 1.4418, G loss: 0.8832\n",
      "[324/1762] D loss: 1.3678, G loss: 0.9015\n",
      "[404/1762] D loss: 1.0564, G loss: 1.2171\n",
      "[484/1762] D loss: 1.3937, G loss: 0.8214\n",
      "[564/1762] D loss: 1.3452, G loss: 0.6681\n",
      "[644/1762] D loss: 1.3152, G loss: 0.6815\n",
      "[724/1762] D loss: 1.3046, G loss: 0.7995\n",
      "[804/1762] D loss: 1.1897, G loss: 0.8343\n",
      "[884/1762] D loss: 1.2297, G loss: 1.0104\n",
      "[964/1762] D loss: 1.2843, G loss: 0.9137\n",
      "[1044/1762] D loss: 1.2683, G loss: 0.7472\n",
      "[1124/1762] D loss: 1.4824, G loss: 0.7322\n",
      "[1204/1762] D loss: 1.3693, G loss: 0.7637\n",
      "[1284/1762] D loss: 1.3097, G loss: 0.6144\n",
      "[1364/1762] D loss: 1.4147, G loss: 0.7734\n",
      "[1444/1762] D loss: 1.3517, G loss: 0.7060\n",
      "[1524/1762] D loss: 1.3530, G loss: 0.7793\n",
      "[1604/1762] D loss: 1.2211, G loss: 0.9983\n",
      "[1684/1762] D loss: 1.4199, G loss: 0.8492\n",
      "[1762/1762] D loss: 1.4256, G loss: 0.6154\n",
      "train error: \n",
      " D loss: 1.361876, G loss: 0.880207, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363454, G loss: 0.889484, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3710, G loss: 0.8241\n",
      "[84/1762] D loss: 1.5665, G loss: 0.4814\n",
      "[164/1762] D loss: 1.4910, G loss: 0.4372\n",
      "[244/1762] D loss: 1.3222, G loss: 1.0923\n",
      "[324/1762] D loss: 1.5758, G loss: 0.4700\n",
      "[404/1762] D loss: 1.4411, G loss: 0.5903\n",
      "[484/1762] D loss: 1.3881, G loss: 0.5779\n",
      "[564/1762] D loss: 1.3259, G loss: 0.8560\n",
      "[644/1762] D loss: 1.4766, G loss: 1.0242\n",
      "[724/1762] D loss: 1.1350, G loss: 0.9706\n",
      "[804/1762] D loss: 1.3926, G loss: 0.6708\n",
      "[884/1762] D loss: 1.3837, G loss: 0.5890\n",
      "[964/1762] D loss: 1.4423, G loss: 0.5563\n",
      "[1044/1762] D loss: 1.5668, G loss: 0.4332\n",
      "[1124/1762] D loss: 1.3042, G loss: 0.7982\n",
      "[1204/1762] D loss: 1.3752, G loss: 0.7294\n",
      "[1284/1762] D loss: 1.3175, G loss: 0.7089\n",
      "[1364/1762] D loss: 1.3303, G loss: 0.6101\n",
      "[1444/1762] D loss: 1.4393, G loss: 0.6700\n",
      "[1524/1762] D loss: 1.3848, G loss: 0.6515\n",
      "[1604/1762] D loss: 1.3698, G loss: 0.5962\n",
      "[1684/1762] D loss: 1.3320, G loss: 0.8018\n",
      "[1762/1762] D loss: 0.9619, G loss: 1.2938\n",
      "train error: \n",
      " D loss: 1.348666, G loss: 0.738774, D accuracy: 57.1%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354565, G loss: 0.742815, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3762, G loss: 0.8292\n",
      "[84/1762] D loss: 1.3380, G loss: 0.7841\n",
      "[164/1762] D loss: 1.3182, G loss: 0.6581\n",
      "[244/1762] D loss: 1.3310, G loss: 0.6522\n",
      "[324/1762] D loss: 1.4168, G loss: 0.5944\n",
      "[404/1762] D loss: 1.3855, G loss: 0.6647\n",
      "[484/1762] D loss: 1.3936, G loss: 0.7674\n",
      "[564/1762] D loss: 1.1111, G loss: 1.1011\n",
      "[644/1762] D loss: 1.3078, G loss: 0.5522\n",
      "[724/1762] D loss: 1.3400, G loss: 0.6109\n",
      "[804/1762] D loss: 1.3783, G loss: 0.5431\n",
      "[884/1762] D loss: 1.3657, G loss: 0.7572\n",
      "[964/1762] D loss: 1.5178, G loss: 0.5103\n",
      "[1044/1762] D loss: 1.2597, G loss: 0.7627\n",
      "[1124/1762] D loss: 1.4394, G loss: 0.5297\n",
      "[1204/1762] D loss: 1.3137, G loss: 0.7509\n",
      "[1284/1762] D loss: 1.2058, G loss: 0.7825\n",
      "[1364/1762] D loss: 1.3854, G loss: 0.6450\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.5671\n",
      "[1524/1762] D loss: 1.4197, G loss: 0.7808\n",
      "[1604/1762] D loss: 1.2870, G loss: 0.7842\n",
      "[1684/1762] D loss: 1.3027, G loss: 0.8306\n",
      "[1762/1762] D loss: 1.4628, G loss: 0.5647\n",
      "train error: \n",
      " D loss: 1.399245, G loss: 1.017704, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395907, G loss: 1.026599, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4498, G loss: 1.2416\n",
      "[84/1762] D loss: 1.3780, G loss: 0.7743\n",
      "[164/1762] D loss: 1.4422, G loss: 0.6543\n",
      "[244/1762] D loss: 1.3849, G loss: 0.6228\n",
      "[324/1762] D loss: 1.4080, G loss: 0.8049\n",
      "[404/1762] D loss: 1.3752, G loss: 0.8415\n",
      "[484/1762] D loss: 1.1363, G loss: 0.7941\n",
      "[564/1762] D loss: 1.4044, G loss: 0.6456\n",
      "[644/1762] D loss: 1.2804, G loss: 0.7452\n",
      "[724/1762] D loss: 1.2844, G loss: 0.8314\n",
      "[804/1762] D loss: 1.3962, G loss: 0.9678\n",
      "[884/1762] D loss: 1.4258, G loss: 0.5274\n",
      "[964/1762] D loss: 1.3844, G loss: 0.8303\n",
      "[1044/1762] D loss: 1.4037, G loss: 0.6935\n",
      "[1124/1762] D loss: 1.3973, G loss: 0.6993\n",
      "[1204/1762] D loss: 1.4932, G loss: 0.5817\n",
      "[1284/1762] D loss: 1.3006, G loss: 0.6930\n",
      "[1364/1762] D loss: 1.2379, G loss: 0.8259\n",
      "[1444/1762] D loss: 1.5351, G loss: 0.4247\n",
      "[1524/1762] D loss: 1.3393, G loss: 0.6216\n",
      "[1604/1762] D loss: 1.4313, G loss: 0.6980\n",
      "[1684/1762] D loss: 1.3813, G loss: 0.8209\n",
      "[1762/1762] D loss: 1.4213, G loss: 0.6010\n",
      "train error: \n",
      " D loss: 1.347907, G loss: 0.741844, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350770, G loss: 0.747459, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3888, G loss: 0.7466\n",
      "[84/1762] D loss: 1.3946, G loss: 0.6946\n",
      "[164/1762] D loss: 1.4169, G loss: 0.7283\n",
      "[244/1762] D loss: 1.3913, G loss: 0.7590\n",
      "[324/1762] D loss: 1.4086, G loss: 0.6342\n",
      "[404/1762] D loss: 1.3803, G loss: 0.7196\n",
      "[484/1762] D loss: 1.3770, G loss: 0.7439\n",
      "[564/1762] D loss: 1.4375, G loss: 0.8449\n",
      "[644/1762] D loss: 1.3738, G loss: 0.6803\n",
      "[724/1762] D loss: 1.5686, G loss: 1.0730\n",
      "[804/1762] D loss: 1.5126, G loss: 0.8875\n",
      "[884/1762] D loss: 1.4048, G loss: 0.6617\n",
      "[964/1762] D loss: 1.4049, G loss: 0.6627\n",
      "[1044/1762] D loss: 1.4433, G loss: 0.7452\n",
      "[1124/1762] D loss: 1.4237, G loss: 0.5438\n",
      "[1204/1762] D loss: 1.2968, G loss: 0.7875\n",
      "[1284/1762] D loss: 1.2882, G loss: 0.6484\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.6335\n",
      "[1444/1762] D loss: 1.4227, G loss: 0.6283\n",
      "[1524/1762] D loss: 1.4137, G loss: 0.8562\n",
      "[1604/1762] D loss: 1.2663, G loss: 0.7418\n",
      "[1684/1762] D loss: 1.4031, G loss: 0.6402\n",
      "[1762/1762] D loss: 1.3946, G loss: 0.7529\n",
      "train error: \n",
      " D loss: 1.353168, G loss: 0.705169, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353518, G loss: 0.708036, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.5632\n",
      "[84/1762] D loss: 1.3961, G loss: 1.0347\n",
      "[164/1762] D loss: 1.4000, G loss: 0.8794\n",
      "[244/1762] D loss: 1.4146, G loss: 0.7252\n",
      "[324/1762] D loss: 1.4944, G loss: 0.4793\n",
      "[404/1762] D loss: 1.3974, G loss: 0.5316\n",
      "[484/1762] D loss: 1.4114, G loss: 0.6520\n",
      "[564/1762] D loss: 1.3905, G loss: 0.5958\n",
      "[644/1762] D loss: 1.3800, G loss: 0.5913\n",
      "[724/1762] D loss: 1.0551, G loss: 0.9003\n",
      "[804/1762] D loss: 1.3640, G loss: 0.5633\n",
      "[884/1762] D loss: 1.4169, G loss: 0.5773\n",
      "[964/1762] D loss: 1.3212, G loss: 1.0492\n",
      "[1044/1762] D loss: 1.4313, G loss: 0.8682\n",
      "[1124/1762] D loss: 1.3131, G loss: 0.7471\n",
      "[1204/1762] D loss: 1.3793, G loss: 0.6557\n",
      "[1284/1762] D loss: 1.4873, G loss: 0.9717\n",
      "[1364/1762] D loss: 1.3638, G loss: 0.8534\n",
      "[1444/1762] D loss: 1.4721, G loss: 0.9758\n",
      "[1524/1762] D loss: 1.4349, G loss: 0.6926\n",
      "[1604/1762] D loss: 1.4050, G loss: 0.5605\n",
      "[1684/1762] D loss: 1.2465, G loss: 0.6836\n",
      "[1762/1762] D loss: 1.0843, G loss: 1.1191\n",
      "train error: \n",
      " D loss: 1.369936, G loss: 0.893194, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371192, G loss: 0.891929, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2621, G loss: 0.9411\n",
      "[84/1762] D loss: 1.3937, G loss: 1.1219\n",
      "[164/1762] D loss: 1.4203, G loss: 0.7637\n",
      "[244/1762] D loss: 1.4765, G loss: 0.6125\n",
      "[324/1762] D loss: 1.3786, G loss: 0.7016\n",
      "[404/1762] D loss: 1.3005, G loss: 0.8884\n",
      "[484/1762] D loss: 1.3199, G loss: 0.6556\n",
      "[564/1762] D loss: 1.3291, G loss: 0.8435\n",
      "[644/1762] D loss: 1.4020, G loss: 0.5417\n",
      "[724/1762] D loss: 1.2983, G loss: 0.8600\n",
      "[804/1762] D loss: 1.2839, G loss: 1.0017\n",
      "[884/1762] D loss: 1.3326, G loss: 0.7217\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7778\n",
      "[1044/1762] D loss: 1.2850, G loss: 0.7597\n",
      "[1124/1762] D loss: 1.3180, G loss: 0.7985\n",
      "[1204/1762] D loss: 1.3160, G loss: 0.8356\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.6867\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.7213\n",
      "[1444/1762] D loss: 1.4791, G loss: 0.7672\n",
      "[1524/1762] D loss: 1.3977, G loss: 0.6389\n",
      "[1604/1762] D loss: 1.3838, G loss: 0.7759\n",
      "[1684/1762] D loss: 1.2504, G loss: 0.6547\n",
      "[1762/1762] D loss: 1.4394, G loss: 0.7541\n",
      "train error: \n",
      " D loss: 1.347626, G loss: 0.721049, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348442, G loss: 0.726454, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3475, G loss: 0.7665\n",
      "[84/1762] D loss: 1.2640, G loss: 0.6956\n",
      "[164/1762] D loss: 1.3893, G loss: 0.9494\n",
      "[244/1762] D loss: 1.4021, G loss: 0.5762\n",
      "[324/1762] D loss: 1.3878, G loss: 0.7296\n",
      "[404/1762] D loss: 1.3270, G loss: 0.9861\n",
      "[484/1762] D loss: 1.3858, G loss: 0.6763\n",
      "[564/1762] D loss: 1.4560, G loss: 0.5094\n",
      "[644/1762] D loss: 1.3883, G loss: 0.7231\n",
      "[724/1762] D loss: 1.3810, G loss: 0.7526\n",
      "[804/1762] D loss: 1.4442, G loss: 0.7796\n",
      "[884/1762] D loss: 1.4079, G loss: 0.6954\n",
      "[964/1762] D loss: 1.3345, G loss: 0.7586\n",
      "[1044/1762] D loss: 1.4294, G loss: 0.7483\n",
      "[1124/1762] D loss: 1.3901, G loss: 0.7723\n",
      "[1204/1762] D loss: 1.4586, G loss: 0.5974\n",
      "[1284/1762] D loss: 1.3647, G loss: 0.9068\n",
      "[1364/1762] D loss: 1.3573, G loss: 0.7501\n",
      "[1444/1762] D loss: 1.4033, G loss: 0.7509\n",
      "[1524/1762] D loss: 1.4119, G loss: 0.7701\n",
      "[1604/1762] D loss: 1.4793, G loss: 0.4804\n",
      "[1684/1762] D loss: 1.2786, G loss: 0.7840\n",
      "[1762/1762] D loss: 1.4259, G loss: 0.5605\n",
      "train error: \n",
      " D loss: 1.349019, G loss: 0.759376, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348842, G loss: 0.759955, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4086, G loss: 0.8123\n",
      "[84/1762] D loss: 1.3773, G loss: 0.5872\n",
      "[164/1762] D loss: 1.2642, G loss: 0.9556\n",
      "[244/1762] D loss: 1.3964, G loss: 0.8330\n",
      "[324/1762] D loss: 1.3153, G loss: 0.7044\n",
      "[404/1762] D loss: 1.3903, G loss: 0.6227\n",
      "[484/1762] D loss: 1.0237, G loss: 1.0000\n",
      "[564/1762] D loss: 1.4092, G loss: 0.8392\n",
      "[644/1762] D loss: 1.3131, G loss: 0.6982\n",
      "[724/1762] D loss: 1.0990, G loss: 0.9220\n",
      "[804/1762] D loss: 1.4096, G loss: 0.8428\n",
      "[884/1762] D loss: 1.3821, G loss: 0.8131\n",
      "[964/1762] D loss: 1.2402, G loss: 0.7706\n",
      "[1044/1762] D loss: 1.1091, G loss: 1.0444\n",
      "[1124/1762] D loss: 1.4602, G loss: 0.7763\n",
      "[1204/1762] D loss: 1.5128, G loss: 1.1726\n",
      "[1284/1762] D loss: 1.4409, G loss: 0.6034\n",
      "[1364/1762] D loss: 1.4552, G loss: 0.4992\n",
      "[1444/1762] D loss: 1.0919, G loss: 1.1074\n",
      "[1524/1762] D loss: 1.5106, G loss: 0.5885\n",
      "[1604/1762] D loss: 1.2608, G loss: 0.8753\n",
      "[1684/1762] D loss: 1.4137, G loss: 0.7032\n",
      "[1762/1762] D loss: 1.4264, G loss: 0.5089\n",
      "train error: \n",
      " D loss: 1.362880, G loss: 0.623276, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 80.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364968, G loss: 0.622528, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3008, G loss: 0.6859\n",
      "[84/1762] D loss: 1.4699, G loss: 0.7034\n",
      "[164/1762] D loss: 1.1987, G loss: 0.7949\n",
      "[244/1762] D loss: 1.3027, G loss: 0.8928\n",
      "[324/1762] D loss: 1.3993, G loss: 0.9246\n",
      "[404/1762] D loss: 1.3907, G loss: 0.7308\n",
      "[484/1762] D loss: 1.3842, G loss: 0.6769\n",
      "[564/1762] D loss: 1.4298, G loss: 0.5305\n",
      "[644/1762] D loss: 1.1839, G loss: 0.8972\n",
      "[724/1762] D loss: 1.4509, G loss: 0.6134\n",
      "[804/1762] D loss: 1.4273, G loss: 0.6231\n",
      "[884/1762] D loss: 1.3945, G loss: 0.5973\n",
      "[964/1762] D loss: 1.4605, G loss: 0.5164\n",
      "[1044/1762] D loss: 1.2610, G loss: 0.7107\n",
      "[1124/1762] D loss: 1.2997, G loss: 0.6638\n",
      "[1204/1762] D loss: 1.4128, G loss: 0.8151\n",
      "[1284/1762] D loss: 1.5083, G loss: 0.4545\n",
      "[1364/1762] D loss: 1.2463, G loss: 0.8482\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.5712\n",
      "[1524/1762] D loss: 1.3819, G loss: 0.6383\n",
      "[1604/1762] D loss: 1.1611, G loss: 0.7307\n",
      "[1684/1762] D loss: 1.4001, G loss: 0.6819\n",
      "[1762/1762] D loss: 1.0845, G loss: 1.3664\n",
      "train error: \n",
      " D loss: 1.477489, G loss: 1.183599, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.465698, G loss: 1.181353, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2912, G loss: 0.9029\n",
      "[84/1762] D loss: 1.2690, G loss: 0.7324\n",
      "[164/1762] D loss: 1.3730, G loss: 0.6728\n",
      "[244/1762] D loss: 1.2181, G loss: 0.8689\n",
      "[324/1762] D loss: 1.4391, G loss: 0.6084\n",
      "[404/1762] D loss: 1.3707, G loss: 0.6298\n",
      "[484/1762] D loss: 1.2154, G loss: 0.5472\n",
      "[564/1762] D loss: 1.4150, G loss: 0.7899\n",
      "[644/1762] D loss: 1.4169, G loss: 0.6203\n",
      "[724/1762] D loss: 1.4497, G loss: 0.5449\n",
      "[804/1762] D loss: 1.2858, G loss: 0.9541\n",
      "[884/1762] D loss: 1.4643, G loss: 0.6357\n",
      "[964/1762] D loss: 1.4034, G loss: 0.7018\n",
      "[1044/1762] D loss: 1.4064, G loss: 0.6275\n",
      "[1124/1762] D loss: 1.3980, G loss: 0.5933\n",
      "[1204/1762] D loss: 1.3224, G loss: 0.7831\n",
      "[1284/1762] D loss: 1.4027, G loss: 0.7377\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.6815\n",
      "[1444/1762] D loss: 1.1846, G loss: 0.8199\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.5993\n",
      "[1604/1762] D loss: 1.3966, G loss: 0.6696\n",
      "[1684/1762] D loss: 1.4031, G loss: 0.8620\n",
      "[1762/1762] D loss: 1.4058, G loss: 0.7379\n",
      "train error: \n",
      " D loss: 1.345284, G loss: 0.729281, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342130, G loss: 0.732624, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.6144\n",
      "[84/1762] D loss: 1.4579, G loss: 0.9250\n",
      "[164/1762] D loss: 1.3241, G loss: 1.3039\n",
      "[244/1762] D loss: 1.2115, G loss: 1.0662\n",
      "[324/1762] D loss: 1.4172, G loss: 0.6398\n",
      "[404/1762] D loss: 1.1891, G loss: 0.8073\n",
      "[484/1762] D loss: 1.3833, G loss: 0.6463\n",
      "[564/1762] D loss: 1.3467, G loss: 0.8981\n",
      "[644/1762] D loss: 1.2245, G loss: 0.8785\n",
      "[724/1762] D loss: 1.3955, G loss: 0.6678\n",
      "[804/1762] D loss: 1.2681, G loss: 1.0776\n",
      "[884/1762] D loss: 1.3727, G loss: 0.6631\n",
      "[964/1762] D loss: 1.2837, G loss: 1.0623\n",
      "[1044/1762] D loss: 1.4113, G loss: 0.8896\n",
      "[1124/1762] D loss: 1.2309, G loss: 0.8946\n",
      "[1204/1762] D loss: 1.3692, G loss: 0.7966\n",
      "[1284/1762] D loss: 1.3592, G loss: 0.7008\n",
      "[1364/1762] D loss: 1.3630, G loss: 0.8338\n",
      "[1444/1762] D loss: 1.1728, G loss: 0.7589\n",
      "[1524/1762] D loss: 1.1948, G loss: 0.7322\n",
      "[1604/1762] D loss: 1.3960, G loss: 0.5600\n",
      "[1684/1762] D loss: 1.4172, G loss: 0.7172\n",
      "[1762/1762] D loss: 1.4252, G loss: 0.8499\n",
      "train error: \n",
      " D loss: 1.344126, G loss: 0.767664, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343963, G loss: 0.762391, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2867, G loss: 1.0045\n",
      "[84/1762] D loss: 1.4894, G loss: 0.9008\n",
      "[164/1762] D loss: 1.4463, G loss: 1.0440\n",
      "[244/1762] D loss: 1.3954, G loss: 0.8917\n",
      "[324/1762] D loss: 1.0480, G loss: 1.0136\n",
      "[404/1762] D loss: 1.4239, G loss: 0.5798\n",
      "[484/1762] D loss: 1.3823, G loss: 0.9815\n",
      "[564/1762] D loss: 1.1962, G loss: 0.9215\n",
      "[644/1762] D loss: 1.4006, G loss: 0.7425\n",
      "[724/1762] D loss: 1.3985, G loss: 0.7234\n",
      "[804/1762] D loss: 1.0220, G loss: 0.8937\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7337\n",
      "[964/1762] D loss: 1.0484, G loss: 0.8247\n",
      "[1044/1762] D loss: 1.3994, G loss: 0.7122\n",
      "[1124/1762] D loss: 1.4087, G loss: 0.6456\n",
      "[1204/1762] D loss: 1.4473, G loss: 0.5234\n",
      "[1284/1762] D loss: 1.4007, G loss: 0.5719\n",
      "[1364/1762] D loss: 1.4381, G loss: 0.9097\n",
      "[1444/1762] D loss: 1.4579, G loss: 0.9072\n",
      "[1524/1762] D loss: 1.2362, G loss: 0.8095\n",
      "[1604/1762] D loss: 1.1882, G loss: 0.7714\n",
      "[1684/1762] D loss: 1.2163, G loss: 0.7622\n",
      "[1762/1762] D loss: 1.3558, G loss: 0.9736\n",
      "train error: \n",
      " D loss: 1.368947, G loss: 0.597361, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366338, G loss: 0.601542, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4255, G loss: 0.4816\n",
      "[84/1762] D loss: 1.3965, G loss: 0.7844\n",
      "[164/1762] D loss: 1.3966, G loss: 0.8303\n",
      "[244/1762] D loss: 1.2630, G loss: 0.7712\n",
      "[324/1762] D loss: 1.4469, G loss: 0.9307\n",
      "[404/1762] D loss: 1.5311, G loss: 0.9410\n",
      "[484/1762] D loss: 1.3823, G loss: 0.7953\n",
      "[564/1762] D loss: 1.4306, G loss: 0.6114\n",
      "[644/1762] D loss: 1.4262, G loss: 0.5626\n",
      "[724/1762] D loss: 1.4901, G loss: 0.5375\n",
      "[804/1762] D loss: 1.3710, G loss: 0.6408\n",
      "[884/1762] D loss: 1.3930, G loss: 0.5929\n",
      "[964/1762] D loss: 1.4140, G loss: 0.6544\n",
      "[1044/1762] D loss: 1.4119, G loss: 0.8199\n",
      "[1124/1762] D loss: 1.5099, G loss: 0.7764\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.8745\n",
      "[1284/1762] D loss: 1.4208, G loss: 0.7159\n",
      "[1364/1762] D loss: 1.1200, G loss: 0.9202\n",
      "[1444/1762] D loss: 1.4059, G loss: 0.8204\n",
      "[1524/1762] D loss: 1.3915, G loss: 0.6511\n",
      "[1604/1762] D loss: 1.1759, G loss: 0.7852\n",
      "[1684/1762] D loss: 1.4008, G loss: 0.6328\n",
      "[1762/1762] D loss: 1.4193, G loss: 0.6147\n",
      "train error: \n",
      " D loss: 1.342825, G loss: 0.719602, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334642, G loss: 0.722515, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4350, G loss: 0.7866\n",
      "[84/1762] D loss: 1.3787, G loss: 0.7438\n",
      "[164/1762] D loss: 1.2276, G loss: 0.7122\n",
      "[244/1762] D loss: 1.2265, G loss: 0.7543\n",
      "[324/1762] D loss: 1.2620, G loss: 0.8071\n",
      "[404/1762] D loss: 1.4000, G loss: 0.7223\n",
      "[484/1762] D loss: 1.3800, G loss: 0.7399\n",
      "[564/1762] D loss: 1.2341, G loss: 0.7863\n",
      "[644/1762] D loss: 1.3892, G loss: 0.6737\n",
      "[724/1762] D loss: 1.5208, G loss: 0.5959\n",
      "[804/1762] D loss: 1.3991, G loss: 0.6905\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7991\n",
      "[964/1762] D loss: 1.3964, G loss: 0.8051\n",
      "[1044/1762] D loss: 1.4716, G loss: 0.5831\n",
      "[1124/1762] D loss: 1.1949, G loss: 0.8102\n",
      "[1204/1762] D loss: 1.2029, G loss: 0.9270\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.7760\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.7321\n",
      "[1444/1762] D loss: 1.4131, G loss: 0.6815\n",
      "[1524/1762] D loss: 1.4006, G loss: 0.7593\n",
      "[1604/1762] D loss: 1.4621, G loss: 0.7191\n",
      "[1684/1762] D loss: 1.4553, G loss: 0.8907\n",
      "[1762/1762] D loss: 1.5201, G loss: 0.8886\n",
      "train error: \n",
      " D loss: 1.416045, G loss: 0.892735, D accuracy: 50.5%, cell accuracy: 99.5%, board accuracy: 62.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410380, G loss: 0.903941, D accuracy: 50.9%, cell accuracy: 99.5%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3721, G loss: 0.9094\n",
      "[84/1762] D loss: 1.3983, G loss: 0.7558\n",
      "[164/1762] D loss: 1.4251, G loss: 0.6073\n",
      "[244/1762] D loss: 1.4244, G loss: 0.5428\n",
      "[324/1762] D loss: 1.2815, G loss: 0.7261\n",
      "[404/1762] D loss: 1.4042, G loss: 0.7220\n",
      "[484/1762] D loss: 1.4609, G loss: 0.6751\n",
      "[564/1762] D loss: 1.4665, G loss: 0.6730\n",
      "[644/1762] D loss: 1.4484, G loss: 0.7534\n",
      "[724/1762] D loss: 1.3714, G loss: 0.6641\n",
      "[804/1762] D loss: 1.3594, G loss: 0.7111\n",
      "[884/1762] D loss: 1.3769, G loss: 0.7428\n",
      "[964/1762] D loss: 1.3892, G loss: 0.6825\n",
      "[1044/1762] D loss: 1.3767, G loss: 0.7020\n",
      "[1124/1762] D loss: 1.3991, G loss: 0.7479\n",
      "[1204/1762] D loss: 1.4018, G loss: 0.6793\n",
      "[1284/1762] D loss: 1.4001, G loss: 0.6403\n",
      "[1364/1762] D loss: 1.4198, G loss: 0.5851\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.8043\n",
      "[1524/1762] D loss: 1.4095, G loss: 0.8727\n",
      "[1604/1762] D loss: 1.3925, G loss: 0.6925\n",
      "[1684/1762] D loss: 1.4100, G loss: 0.7691\n",
      "[1762/1762] D loss: 1.3710, G loss: 0.7077\n",
      "train error: \n",
      " D loss: 1.367151, G loss: 0.676577, D accuracy: 55.1%, cell accuracy: 99.5%, board accuracy: 66.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360669, G loss: 0.687760, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 63.6% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3184, G loss: 0.7434\n",
      "[84/1762] D loss: 1.2974, G loss: 0.7705\n",
      "[164/1762] D loss: 1.3997, G loss: 0.6805\n",
      "[244/1762] D loss: 1.4285, G loss: 0.4908\n",
      "[324/1762] D loss: 1.4070, G loss: 0.6539\n",
      "[404/1762] D loss: 1.4546, G loss: 0.5250\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7656\n",
      "[564/1762] D loss: 1.1878, G loss: 0.8919\n",
      "[644/1762] D loss: 1.3810, G loss: 0.7163\n",
      "[724/1762] D loss: 1.2671, G loss: 0.6983\n",
      "[804/1762] D loss: 1.4755, G loss: 0.5607\n",
      "[884/1762] D loss: 1.2032, G loss: 0.8535\n",
      "[964/1762] D loss: 1.4080, G loss: 0.7316\n",
      "[1044/1762] D loss: 1.3683, G loss: 0.7711\n",
      "[1124/1762] D loss: 1.3946, G loss: 0.6864\n",
      "[1204/1762] D loss: 1.3701, G loss: 0.7041\n",
      "[1284/1762] D loss: 1.2754, G loss: 0.6505\n",
      "[1364/1762] D loss: 1.4145, G loss: 0.7953\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.6964\n",
      "[1524/1762] D loss: 1.4272, G loss: 0.7841\n",
      "[1604/1762] D loss: 1.4139, G loss: 0.8096\n",
      "[1684/1762] D loss: 1.4158, G loss: 0.7040\n",
      "[1762/1762] D loss: 1.4513, G loss: 0.7633\n",
      "train error: \n",
      " D loss: 1.359682, G loss: 0.728018, D accuracy: 55.0%, cell accuracy: 99.6%, board accuracy: 69.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349541, G loss: 0.738876, D accuracy: 56.6%, cell accuracy: 99.6%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3773, G loss: 0.7132\n",
      "[84/1762] D loss: 1.2767, G loss: 0.6219\n",
      "[164/1762] D loss: 1.2081, G loss: 0.6730\n",
      "[244/1762] D loss: 1.3944, G loss: 0.6408\n",
      "[324/1762] D loss: 1.3534, G loss: 0.6635\n",
      "[404/1762] D loss: 1.3942, G loss: 0.8680\n",
      "[484/1762] D loss: 1.4147, G loss: 0.7691\n",
      "[564/1762] D loss: 1.3786, G loss: 0.6959\n",
      "[644/1762] D loss: 1.2881, G loss: 0.7382\n",
      "[724/1762] D loss: 1.3756, G loss: 0.6419\n",
      "[804/1762] D loss: 1.3762, G loss: 0.6792\n",
      "[884/1762] D loss: 1.3916, G loss: 0.6352\n",
      "[964/1762] D loss: 1.2791, G loss: 0.7298\n",
      "[1044/1762] D loss: 1.3998, G loss: 0.7484\n",
      "[1124/1762] D loss: 1.4110, G loss: 0.5885\n",
      "[1204/1762] D loss: 1.3153, G loss: 0.8659\n",
      "[1284/1762] D loss: 1.3828, G loss: 0.6856\n",
      "[1364/1762] D loss: 1.2358, G loss: 0.7936\n",
      "[1444/1762] D loss: 1.2265, G loss: 0.8557\n",
      "[1524/1762] D loss: 1.2977, G loss: 0.8572\n",
      "[1604/1762] D loss: 1.4095, G loss: 0.8562\n",
      "[1684/1762] D loss: 1.3926, G loss: 0.7147\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.7155\n",
      "train error: \n",
      " D loss: 1.358618, G loss: 0.713741, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 75.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347503, G loss: 0.719018, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.6337\n",
      "[84/1762] D loss: 1.3976, G loss: 0.8140\n",
      "[164/1762] D loss: 1.2633, G loss: 0.7348\n",
      "[244/1762] D loss: 1.4008, G loss: 0.7056\n",
      "[324/1762] D loss: 1.4406, G loss: 0.8169\n",
      "[404/1762] D loss: 1.0458, G loss: 1.0754\n",
      "[484/1762] D loss: 1.2736, G loss: 0.7405\n",
      "[564/1762] D loss: 1.4120, G loss: 0.6394\n",
      "[644/1762] D loss: 1.3747, G loss: 0.9758\n",
      "[724/1762] D loss: 1.3822, G loss: 0.7609\n",
      "[804/1762] D loss: 1.3510, G loss: 0.6337\n",
      "[884/1762] D loss: 1.3768, G loss: 0.7610\n",
      "[964/1762] D loss: 1.4016, G loss: 0.7344\n",
      "[1044/1762] D loss: 1.2288, G loss: 0.7505\n",
      "[1124/1762] D loss: 1.4535, G loss: 0.9745\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.8547\n",
      "[1284/1762] D loss: 1.3745, G loss: 0.7846\n",
      "[1364/1762] D loss: 1.2192, G loss: 0.7005\n",
      "[1444/1762] D loss: 1.4078, G loss: 0.5860\n",
      "[1524/1762] D loss: 1.3561, G loss: 0.7593\n",
      "[1604/1762] D loss: 1.3669, G loss: 0.7292\n",
      "[1684/1762] D loss: 1.5050, G loss: 0.5975\n",
      "[1762/1762] D loss: 1.4089, G loss: 0.7277\n",
      "train error: \n",
      " D loss: 1.354696, G loss: 0.744094, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343341, G loss: 0.748961, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 70.9% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.8682\n",
      "[84/1762] D loss: 1.3907, G loss: 0.7384\n",
      "[164/1762] D loss: 1.3861, G loss: 0.7014\n",
      "[244/1762] D loss: 1.4704, G loss: 0.5258\n",
      "[324/1762] D loss: 1.2065, G loss: 0.9319\n",
      "[404/1762] D loss: 1.4500, G loss: 0.5752\n",
      "[484/1762] D loss: 1.3930, G loss: 0.6176\n",
      "[564/1762] D loss: 1.2898, G loss: 0.6882\n",
      "[644/1762] D loss: 1.3458, G loss: 0.7438\n",
      "[724/1762] D loss: 1.4385, G loss: 0.6068\n",
      "[804/1762] D loss: 1.2559, G loss: 0.5920\n",
      "[884/1762] D loss: 1.3197, G loss: 0.7614\n",
      "[964/1762] D loss: 1.2353, G loss: 0.7737\n",
      "[1044/1762] D loss: 1.4058, G loss: 0.5755\n",
      "[1124/1762] D loss: 1.3537, G loss: 0.6336\n",
      "[1204/1762] D loss: 1.3973, G loss: 0.6090\n",
      "[1284/1762] D loss: 1.3577, G loss: 0.8294\n",
      "[1364/1762] D loss: 1.2101, G loss: 0.9000\n",
      "[1444/1762] D loss: 1.3950, G loss: 0.6800\n",
      "[1524/1762] D loss: 1.3305, G loss: 0.7077\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.7880\n",
      "[1684/1762] D loss: 1.3906, G loss: 0.7153\n",
      "[1762/1762] D loss: 1.4020, G loss: 0.6076\n",
      "train error: \n",
      " D loss: 1.345150, G loss: 0.771104, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335596, G loss: 0.772386, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3573, G loss: 0.7554\n",
      "[84/1762] D loss: 1.3954, G loss: 0.7305\n",
      "[164/1762] D loss: 1.3906, G loss: 0.5962\n",
      "[244/1762] D loss: 1.3993, G loss: 0.6954\n",
      "[324/1762] D loss: 1.3962, G loss: 0.8090\n",
      "[404/1762] D loss: 1.3978, G loss: 0.7936\n",
      "[484/1762] D loss: 1.3874, G loss: 0.5891\n",
      "[564/1762] D loss: 1.4023, G loss: 0.7116\n",
      "[644/1762] D loss: 1.4080, G loss: 0.6621\n",
      "[724/1762] D loss: 1.4140, G loss: 0.7408\n",
      "[804/1762] D loss: 1.3912, G loss: 0.6575\n",
      "[884/1762] D loss: 1.2509, G loss: 0.6295\n",
      "[964/1762] D loss: 1.3619, G loss: 0.6308\n",
      "[1044/1762] D loss: 1.4038, G loss: 0.7099\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.6942\n",
      "[1204/1762] D loss: 1.4441, G loss: 0.7561\n",
      "[1284/1762] D loss: 1.4336, G loss: 0.8774\n",
      "[1364/1762] D loss: 1.3455, G loss: 0.6124\n",
      "[1444/1762] D loss: 1.3689, G loss: 0.7368\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.7466\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.7043\n",
      "[1684/1762] D loss: 1.3147, G loss: 0.9134\n",
      "[1762/1762] D loss: 0.9681, G loss: 0.8189\n",
      "train error: \n",
      " D loss: 1.390192, G loss: 0.533841, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 77.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378854, G loss: 0.537880, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4423, G loss: 0.4915\n",
      "[84/1762] D loss: 1.2502, G loss: 0.7089\n",
      "[164/1762] D loss: 1.2505, G loss: 0.7459\n",
      "[244/1762] D loss: 1.4953, G loss: 0.6334\n",
      "[324/1762] D loss: 1.4084, G loss: 0.5534\n",
      "[404/1762] D loss: 1.4008, G loss: 0.6934\n",
      "[484/1762] D loss: 1.2489, G loss: 0.7307\n",
      "[564/1762] D loss: 1.2697, G loss: 0.7101\n",
      "[644/1762] D loss: 1.2309, G loss: 1.0846\n",
      "[724/1762] D loss: 1.4347, G loss: 0.9209\n",
      "[804/1762] D loss: 1.3672, G loss: 0.7854\n",
      "[884/1762] D loss: 1.3876, G loss: 0.7350\n",
      "[964/1762] D loss: 1.2841, G loss: 0.8622\n",
      "[1044/1762] D loss: 1.4134, G loss: 0.8509\n",
      "[1124/1762] D loss: 1.4416, G loss: 0.5012\n",
      "[1204/1762] D loss: 1.3181, G loss: 0.7044\n",
      "[1284/1762] D loss: 1.4030, G loss: 0.5721\n",
      "[1364/1762] D loss: 1.2604, G loss: 0.9335\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.7392\n",
      "[1524/1762] D loss: 1.1486, G loss: 0.9371\n",
      "[1604/1762] D loss: 1.4009, G loss: 0.6390\n",
      "[1684/1762] D loss: 1.4101, G loss: 0.6800\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.5829\n",
      "train error: \n",
      " D loss: 1.340325, G loss: 0.676500, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327588, G loss: 0.681883, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4197, G loss: 0.6405\n",
      "[84/1762] D loss: 1.3968, G loss: 0.5334\n",
      "[164/1762] D loss: 1.4110, G loss: 0.5851\n",
      "[244/1762] D loss: 1.2893, G loss: 0.8820\n",
      "[324/1762] D loss: 1.1615, G loss: 0.8892\n",
      "[404/1762] D loss: 1.2004, G loss: 0.8951\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7570\n",
      "[564/1762] D loss: 1.3835, G loss: 0.7459\n",
      "[644/1762] D loss: 1.3698, G loss: 0.7457\n",
      "[724/1762] D loss: 1.4224, G loss: 0.9244\n",
      "[804/1762] D loss: 1.3980, G loss: 0.6983\n",
      "[884/1762] D loss: 1.2118, G loss: 0.7370\n",
      "[964/1762] D loss: 1.3929, G loss: 0.7499\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.8333\n",
      "[1124/1762] D loss: 1.2065, G loss: 0.7961\n",
      "[1204/1762] D loss: 1.2051, G loss: 0.9307\n",
      "[1284/1762] D loss: 1.4055, G loss: 0.5847\n",
      "[1364/1762] D loss: 1.1601, G loss: 0.7353\n",
      "[1444/1762] D loss: 1.2214, G loss: 0.8531\n",
      "[1524/1762] D loss: 1.4009, G loss: 0.8336\n",
      "[1604/1762] D loss: 1.1173, G loss: 0.8867\n",
      "[1684/1762] D loss: 1.3931, G loss: 0.6856\n",
      "[1762/1762] D loss: 1.0657, G loss: 1.1373\n",
      "train error: \n",
      " D loss: 1.350353, G loss: 0.883223, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329065, G loss: 0.900314, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2483, G loss: 0.9065\n",
      "[84/1762] D loss: 1.4367, G loss: 0.8911\n",
      "[164/1762] D loss: 1.4334, G loss: 0.8261\n",
      "[244/1762] D loss: 1.1885, G loss: 0.9537\n",
      "[324/1762] D loss: 1.4704, G loss: 0.9623\n",
      "[404/1762] D loss: 1.3135, G loss: 1.0715\n",
      "[484/1762] D loss: 1.4130, G loss: 0.7667\n",
      "[564/1762] D loss: 1.3984, G loss: 0.6106\n",
      "[644/1762] D loss: 1.1885, G loss: 0.8640\n",
      "[724/1762] D loss: 1.3587, G loss: 0.6434\n",
      "[804/1762] D loss: 1.1773, G loss: 0.8247\n",
      "[884/1762] D loss: 1.3892, G loss: 0.6817\n",
      "[964/1762] D loss: 1.3826, G loss: 0.9112\n",
      "[1044/1762] D loss: 1.4387, G loss: 0.8026\n",
      "[1124/1762] D loss: 1.0040, G loss: 0.9523\n",
      "[1204/1762] D loss: 1.0700, G loss: 0.9177\n",
      "[1284/1762] D loss: 1.4028, G loss: 0.8231\n",
      "[1364/1762] D loss: 1.3945, G loss: 0.8269\n",
      "[1444/1762] D loss: 1.4032, G loss: 0.6994\n",
      "[1524/1762] D loss: 1.4014, G loss: 0.6332\n",
      "[1604/1762] D loss: 1.4020, G loss: 0.7396\n",
      "[1684/1762] D loss: 1.1789, G loss: 0.8356\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6510\n",
      "train error: \n",
      " D loss: 1.337125, G loss: 0.790747, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323165, G loss: 0.795326, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4025, G loss: 0.6953\n",
      "[84/1762] D loss: 1.4187, G loss: 0.5985\n",
      "[164/1762] D loss: 1.4064, G loss: 0.7136\n",
      "[244/1762] D loss: 1.1981, G loss: 0.7598\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6510\n",
      "[404/1762] D loss: 1.4417, G loss: 0.6081\n",
      "[484/1762] D loss: 1.4003, G loss: 0.6280\n",
      "[564/1762] D loss: 1.4687, G loss: 0.8689\n",
      "[644/1762] D loss: 1.4085, G loss: 0.7127\n",
      "[724/1762] D loss: 1.2510, G loss: 0.7361\n",
      "[804/1762] D loss: 1.4181, G loss: 0.7729\n",
      "[884/1762] D loss: 1.3754, G loss: 0.7530\n",
      "[964/1762] D loss: 1.2030, G loss: 0.7356\n",
      "[1044/1762] D loss: 1.4035, G loss: 0.7238\n",
      "[1124/1762] D loss: 1.4068, G loss: 0.9600\n",
      "[1204/1762] D loss: 1.4108, G loss: 0.7909\n",
      "[1284/1762] D loss: 1.4007, G loss: 0.8158\n",
      "[1364/1762] D loss: 1.3951, G loss: 0.6423\n",
      "[1444/1762] D loss: 1.1445, G loss: 0.8332\n",
      "[1524/1762] D loss: 1.4079, G loss: 0.7577\n",
      "[1604/1762] D loss: 1.3558, G loss: 0.8516\n",
      "[1684/1762] D loss: 1.4042, G loss: 0.7264\n",
      "[1762/1762] D loss: 1.4393, G loss: 0.6837\n",
      "train error: \n",
      " D loss: 1.391126, G loss: 0.533348, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381053, G loss: 0.539483, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4032, G loss: 0.5219\n",
      "[84/1762] D loss: 1.4101, G loss: 0.5393\n",
      "[164/1762] D loss: 1.4553, G loss: 0.8963\n",
      "[244/1762] D loss: 1.4084, G loss: 0.6360\n",
      "[324/1762] D loss: 1.3910, G loss: 0.7094\n",
      "[404/1762] D loss: 1.4043, G loss: 0.6104\n",
      "[484/1762] D loss: 1.3934, G loss: 0.7395\n",
      "[564/1762] D loss: 1.3895, G loss: 0.7078\n",
      "[644/1762] D loss: 1.4255, G loss: 0.8206\n",
      "[724/1762] D loss: 1.4279, G loss: 0.9592\n",
      "[804/1762] D loss: 1.2092, G loss: 1.0696\n",
      "[884/1762] D loss: 1.1826, G loss: 0.8993\n",
      "[964/1762] D loss: 1.4816, G loss: 0.5657\n",
      "[1044/1762] D loss: 1.4325, G loss: 0.9146\n",
      "[1124/1762] D loss: 1.4228, G loss: 0.6134\n",
      "[1204/1762] D loss: 1.3943, G loss: 0.6744\n",
      "[1284/1762] D loss: 1.4227, G loss: 0.7466\n",
      "[1364/1762] D loss: 1.3845, G loss: 0.7485\n",
      "[1444/1762] D loss: 1.3452, G loss: 0.7397\n",
      "[1524/1762] D loss: 1.1560, G loss: 0.9959\n",
      "[1604/1762] D loss: 1.3751, G loss: 0.6630\n",
      "[1684/1762] D loss: 1.4155, G loss: 0.6437\n",
      "[1762/1762] D loss: 1.4198, G loss: 0.8920\n",
      "train error: \n",
      " D loss: 1.355720, G loss: 0.910755, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337853, G loss: 0.915761, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3984, G loss: 0.7774\n",
      "[84/1762] D loss: 1.3880, G loss: 0.7147\n",
      "[164/1762] D loss: 1.4024, G loss: 0.7379\n",
      "[244/1762] D loss: 1.4735, G loss: 0.5342\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6600\n",
      "[404/1762] D loss: 1.3619, G loss: 0.6422\n",
      "[484/1762] D loss: 1.2320, G loss: 0.9208\n",
      "[564/1762] D loss: 1.4054, G loss: 0.7724\n",
      "[644/1762] D loss: 1.4446, G loss: 0.5776\n",
      "[724/1762] D loss: 1.5031, G loss: 0.5023\n",
      "[804/1762] D loss: 1.4298, G loss: 0.5280\n",
      "[884/1762] D loss: 1.0706, G loss: 0.8292\n",
      "[964/1762] D loss: 1.4527, G loss: 0.5975\n",
      "[1044/1762] D loss: 1.3752, G loss: 0.7006\n",
      "[1124/1762] D loss: 1.3529, G loss: 0.6950\n",
      "[1204/1762] D loss: 1.1736, G loss: 0.8606\n",
      "[1284/1762] D loss: 1.3983, G loss: 0.8359\n",
      "[1364/1762] D loss: 1.4196, G loss: 0.5054\n",
      "[1444/1762] D loss: 1.3670, G loss: 0.5799\n",
      "[1524/1762] D loss: 1.4534, G loss: 0.8983\n",
      "[1604/1762] D loss: 1.1496, G loss: 0.8806\n",
      "[1684/1762] D loss: 1.3495, G loss: 0.7679\n",
      "[1762/1762] D loss: 0.6220, G loss: 1.1288\n",
      "train error: \n",
      " D loss: 1.341182, G loss: 0.666818, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327904, G loss: 0.671998, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1892, G loss: 0.7452\n",
      "[84/1762] D loss: 1.3732, G loss: 0.8544\n",
      "[164/1762] D loss: 1.4271, G loss: 0.7645\n",
      "[244/1762] D loss: 1.3940, G loss: 0.7293\n",
      "[324/1762] D loss: 1.4028, G loss: 0.6129\n",
      "[404/1762] D loss: 1.4178, G loss: 0.8018\n",
      "[484/1762] D loss: 1.4046, G loss: 0.8057\n",
      "[564/1762] D loss: 1.4138, G loss: 0.6342\n",
      "[644/1762] D loss: 1.4391, G loss: 0.5447\n",
      "[724/1762] D loss: 1.4030, G loss: 0.7261\n",
      "[804/1762] D loss: 1.3955, G loss: 0.6632\n",
      "[884/1762] D loss: 1.3987, G loss: 0.7865\n",
      "[964/1762] D loss: 1.1079, G loss: 0.9695\n",
      "[1044/1762] D loss: 1.4039, G loss: 0.7029\n",
      "[1124/1762] D loss: 1.4752, G loss: 0.9042\n",
      "[1204/1762] D loss: 1.1354, G loss: 0.9458\n",
      "[1284/1762] D loss: 1.4030, G loss: 0.6143\n",
      "[1364/1762] D loss: 1.3943, G loss: 0.7571\n",
      "[1444/1762] D loss: 1.4099, G loss: 0.8422\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.7342\n",
      "[1604/1762] D loss: 1.4306, G loss: 0.7861\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.7499\n",
      "[1762/1762] D loss: 1.3926, G loss: 0.7659\n",
      "train error: \n",
      " D loss: 1.331613, G loss: 0.697783, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316225, G loss: 0.708465, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3794, G loss: 0.6816\n",
      "[84/1762] D loss: 1.3715, G loss: 0.6461\n",
      "[164/1762] D loss: 1.4234, G loss: 0.4888\n",
      "[244/1762] D loss: 1.2220, G loss: 0.7925\n",
      "[324/1762] D loss: 1.4160, G loss: 0.7645\n",
      "[404/1762] D loss: 1.4114, G loss: 0.8361\n",
      "[484/1762] D loss: 1.2542, G loss: 0.8109\n",
      "[564/1762] D loss: 1.4126, G loss: 0.8591\n",
      "[644/1762] D loss: 1.1534, G loss: 0.8550\n",
      "[724/1762] D loss: 1.3370, G loss: 0.7122\n",
      "[804/1762] D loss: 1.2653, G loss: 0.5664\n",
      "[884/1762] D loss: 1.4368, G loss: 0.6545\n",
      "[964/1762] D loss: 1.3554, G loss: 0.7761\n",
      "[1044/1762] D loss: 1.3996, G loss: 0.5871\n",
      "[1124/1762] D loss: 1.1728, G loss: 0.6384\n",
      "[1204/1762] D loss: 1.1671, G loss: 0.7522\n",
      "[1284/1762] D loss: 1.3958, G loss: 0.6552\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.7609\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7399\n",
      "[1524/1762] D loss: 1.1543, G loss: 0.9351\n",
      "[1604/1762] D loss: 1.3991, G loss: 0.7486\n",
      "[1684/1762] D loss: 1.4533, G loss: 0.7996\n",
      "[1762/1762] D loss: 1.4160, G loss: 0.6864\n",
      "train error: \n",
      " D loss: 1.325936, G loss: 0.735012, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312042, G loss: 0.741347, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.5888\n",
      "[84/1762] D loss: 1.2476, G loss: 0.6093\n",
      "[164/1762] D loss: 1.1214, G loss: 0.9047\n",
      "[244/1762] D loss: 1.1007, G loss: 0.8117\n",
      "[324/1762] D loss: 1.3896, G loss: 0.7528\n",
      "[404/1762] D loss: 1.3071, G loss: 0.7255\n",
      "[484/1762] D loss: 1.3417, G loss: 0.6144\n",
      "[564/1762] D loss: 1.4019, G loss: 0.7116\n",
      "[644/1762] D loss: 1.4130, G loss: 0.8593\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6699\n",
      "[804/1762] D loss: 1.4054, G loss: 0.6713\n",
      "[884/1762] D loss: 0.9200, G loss: 0.9400\n",
      "[964/1762] D loss: 1.3982, G loss: 0.6516\n",
      "[1044/1762] D loss: 1.1615, G loss: 0.8435\n",
      "[1124/1762] D loss: 1.1402, G loss: 1.0369\n",
      "[1204/1762] D loss: 1.3969, G loss: 0.7848\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6634\n",
      "[1364/1762] D loss: 1.3959, G loss: 0.7839\n",
      "[1444/1762] D loss: 1.4311, G loss: 0.5782\n",
      "[1524/1762] D loss: 1.4020, G loss: 0.7162\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.6388\n",
      "[1684/1762] D loss: 1.1455, G loss: 0.8661\n",
      "[1762/1762] D loss: 1.3945, G loss: 0.7895\n",
      "train error: \n",
      " D loss: 1.332131, G loss: 0.848476, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314221, G loss: 0.858428, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4677, G loss: 0.9594\n",
      "[84/1762] D loss: 1.4290, G loss: 0.6698\n",
      "[164/1762] D loss: 1.1166, G loss: 0.9008\n",
      "[244/1762] D loss: 1.4090, G loss: 0.5444\n",
      "[324/1762] D loss: 1.1865, G loss: 0.8712\n",
      "[404/1762] D loss: 1.1502, G loss: 0.7625\n",
      "[484/1762] D loss: 1.0651, G loss: 0.9361\n",
      "[564/1762] D loss: 1.1341, G loss: 0.9979\n",
      "[644/1762] D loss: 1.4470, G loss: 0.8671\n",
      "[724/1762] D loss: 1.4017, G loss: 0.8245\n",
      "[804/1762] D loss: 1.4412, G loss: 1.0587\n",
      "[884/1762] D loss: 1.3912, G loss: 0.6751\n",
      "[964/1762] D loss: 1.4129, G loss: 0.5517\n",
      "[1044/1762] D loss: 1.4077, G loss: 0.6319\n",
      "[1124/1762] D loss: 1.1406, G loss: 0.9362\n",
      "[1204/1762] D loss: 1.4053, G loss: 0.6821\n",
      "[1284/1762] D loss: 1.4128, G loss: 0.6296\n",
      "[1364/1762] D loss: 1.3965, G loss: 0.6083\n",
      "[1444/1762] D loss: 1.4020, G loss: 0.6469\n",
      "[1524/1762] D loss: 1.4241, G loss: 0.8084\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.6211\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.7048\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.6536\n",
      "train error: \n",
      " D loss: 1.326411, G loss: 0.796834, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310867, G loss: 0.807258, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4390, G loss: 0.8334\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6880\n",
      "[164/1762] D loss: 1.3974, G loss: 0.7093\n",
      "[244/1762] D loss: 1.4584, G loss: 0.5630\n",
      "[324/1762] D loss: 1.4257, G loss: 0.5916\n",
      "[404/1762] D loss: 1.1228, G loss: 0.8804\n",
      "[484/1762] D loss: 1.3980, G loss: 0.7704\n",
      "[564/1762] D loss: 1.3933, G loss: 0.7356\n",
      "[644/1762] D loss: 1.1478, G loss: 0.8995\n",
      "[724/1762] D loss: 1.4550, G loss: 0.8900\n",
      "[804/1762] D loss: 1.4683, G loss: 0.7487\n",
      "[884/1762] D loss: 1.4148, G loss: 0.6365\n",
      "[964/1762] D loss: 1.3993, G loss: 0.7123\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6599\n",
      "[1124/1762] D loss: 1.3933, G loss: 0.7297\n",
      "[1204/1762] D loss: 1.3939, G loss: 0.7640\n",
      "[1284/1762] D loss: 1.2743, G loss: 0.8428\n",
      "[1364/1762] D loss: 1.1603, G loss: 0.8350\n",
      "[1444/1762] D loss: 1.2302, G loss: 0.7860\n",
      "[1524/1762] D loss: 1.4075, G loss: 0.8492\n",
      "[1604/1762] D loss: 1.4787, G loss: 1.0162\n",
      "[1684/1762] D loss: 1.3566, G loss: 0.8857\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7159\n",
      "train error: \n",
      " D loss: 1.328863, G loss: 0.759446, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314197, G loss: 0.771783, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1470, G loss: 0.8718\n",
      "[84/1762] D loss: 1.3750, G loss: 0.7320\n",
      "[164/1762] D loss: 1.4163, G loss: 0.5787\n",
      "[244/1762] D loss: 1.3930, G loss: 0.6412\n",
      "[324/1762] D loss: 1.4037, G loss: 0.6994\n",
      "[404/1762] D loss: 1.3997, G loss: 0.7522\n",
      "[484/1762] D loss: 1.4079, G loss: 0.7146\n",
      "[564/1762] D loss: 1.3891, G loss: 0.6445\n",
      "[644/1762] D loss: 1.1553, G loss: 0.8277\n",
      "[724/1762] D loss: 1.3919, G loss: 0.7090\n",
      "[804/1762] D loss: 0.9053, G loss: 1.0240\n",
      "[884/1762] D loss: 1.1621, G loss: 0.8403\n",
      "[964/1762] D loss: 1.4361, G loss: 0.5715\n",
      "[1044/1762] D loss: 1.1683, G loss: 0.7373\n",
      "[1124/1762] D loss: 0.9232, G loss: 0.8875\n",
      "[1204/1762] D loss: 1.4040, G loss: 0.7529\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.8056\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.8045\n",
      "[1444/1762] D loss: 1.2197, G loss: 0.9120\n",
      "[1524/1762] D loss: 1.4101, G loss: 0.5484\n",
      "[1604/1762] D loss: 1.1764, G loss: 0.9480\n",
      "[1684/1762] D loss: 1.3220, G loss: 0.7377\n",
      "[1762/1762] D loss: 1.3899, G loss: 0.6075\n",
      "train error: \n",
      " D loss: 1.336637, G loss: 0.662928, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323365, G loss: 0.673738, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1265, G loss: 0.8141\n",
      "[84/1762] D loss: 1.2301, G loss: 0.8027\n",
      "[164/1762] D loss: 1.3804, G loss: 0.7170\n",
      "[244/1762] D loss: 1.4532, G loss: 0.4810\n",
      "[324/1762] D loss: 1.4586, G loss: 0.5622\n",
      "[404/1762] D loss: 1.1390, G loss: 0.7353\n",
      "[484/1762] D loss: 0.8926, G loss: 1.1638\n",
      "[564/1762] D loss: 1.3922, G loss: 0.7949\n",
      "[644/1762] D loss: 1.4141, G loss: 0.7635\n",
      "[724/1762] D loss: 1.1634, G loss: 0.7668\n",
      "[804/1762] D loss: 1.3443, G loss: 0.6968\n",
      "[884/1762] D loss: 1.3568, G loss: 0.7281\n",
      "[964/1762] D loss: 1.4108, G loss: 0.6582\n",
      "[1044/1762] D loss: 1.4114, G loss: 0.7849\n",
      "[1124/1762] D loss: 1.3968, G loss: 0.6274\n",
      "[1204/1762] D loss: 1.4508, G loss: 0.5623\n",
      "[1284/1762] D loss: 1.4316, G loss: 0.5836\n",
      "[1364/1762] D loss: 1.3920, G loss: 0.6563\n",
      "[1444/1762] D loss: 1.3921, G loss: 0.6828\n",
      "[1524/1762] D loss: 1.4128, G loss: 0.5886\n",
      "[1604/1762] D loss: 1.4265, G loss: 0.5865\n",
      "[1684/1762] D loss: 1.4082, G loss: 0.5641\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6137\n",
      "train error: \n",
      " D loss: 1.336570, G loss: 0.646506, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322421, G loss: 0.658487, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2000, G loss: 0.6897\n",
      "[84/1762] D loss: 1.4141, G loss: 0.6772\n",
      "[164/1762] D loss: 1.3934, G loss: 0.6525\n",
      "[244/1762] D loss: 1.4099, G loss: 0.6380\n",
      "[324/1762] D loss: 1.1422, G loss: 0.9927\n",
      "[404/1762] D loss: 1.3928, G loss: 0.7994\n",
      "[484/1762] D loss: 1.4211, G loss: 0.7108\n",
      "[564/1762] D loss: 1.4079, G loss: 0.8520\n",
      "[644/1762] D loss: 1.4107, G loss: 0.9062\n",
      "[724/1762] D loss: 1.4210, G loss: 0.6943\n",
      "[804/1762] D loss: 1.3943, G loss: 0.6724\n",
      "[884/1762] D loss: 1.4284, G loss: 0.6922\n",
      "[964/1762] D loss: 1.3967, G loss: 0.6591\n",
      "[1044/1762] D loss: 0.7546, G loss: 1.2540\n",
      "[1124/1762] D loss: 1.3390, G loss: 0.9105\n",
      "[1204/1762] D loss: 1.4007, G loss: 0.7913\n",
      "[1284/1762] D loss: 1.1461, G loss: 0.8761\n",
      "[1364/1762] D loss: 1.3565, G loss: 0.6616\n",
      "[1444/1762] D loss: 1.4345, G loss: 0.5920\n",
      "[1524/1762] D loss: 1.1207, G loss: 0.9179\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.7293\n",
      "[1684/1762] D loss: 1.1487, G loss: 0.7878\n",
      "[1762/1762] D loss: 1.3976, G loss: 0.7253\n",
      "train error: \n",
      " D loss: 1.320942, G loss: 0.768522, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302155, G loss: 0.784601, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7097\n",
      "[84/1762] D loss: 1.3939, G loss: 0.6291\n",
      "[164/1762] D loss: 1.3959, G loss: 0.6540\n",
      "[244/1762] D loss: 1.1831, G loss: 0.8067\n",
      "[324/1762] D loss: 1.4763, G loss: 0.5860\n",
      "[404/1762] D loss: 1.4132, G loss: 0.6319\n",
      "[484/1762] D loss: 1.4249, G loss: 0.5404\n",
      "[564/1762] D loss: 0.9884, G loss: 0.8006\n",
      "[644/1762] D loss: 1.3928, G loss: 0.5668\n",
      "[724/1762] D loss: 1.4052, G loss: 0.7632\n",
      "[804/1762] D loss: 1.3993, G loss: 0.6935\n",
      "[884/1762] D loss: 1.3895, G loss: 0.7230\n",
      "[964/1762] D loss: 1.3913, G loss: 0.6442\n",
      "[1044/1762] D loss: 1.1178, G loss: 0.9454\n",
      "[1124/1762] D loss: 1.4176, G loss: 0.8306\n",
      "[1204/1762] D loss: 1.1498, G loss: 0.9757\n",
      "[1284/1762] D loss: 1.1390, G loss: 0.9387\n",
      "[1364/1762] D loss: 1.4016, G loss: 0.6509\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.6312\n",
      "[1524/1762] D loss: 1.1140, G loss: 0.9569\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.6922\n",
      "[1684/1762] D loss: 1.4020, G loss: 0.7771\n",
      "[1762/1762] D loss: 1.3981, G loss: 0.6221\n",
      "train error: \n",
      " D loss: 1.320953, G loss: 0.737686, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302744, G loss: 0.751837, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3944, G loss: 0.6557\n",
      "[84/1762] D loss: 1.3980, G loss: 0.6496\n",
      "[164/1762] D loss: 1.4031, G loss: 0.7569\n",
      "[244/1762] D loss: 1.3742, G loss: 0.8133\n",
      "[324/1762] D loss: 1.1121, G loss: 1.0768\n",
      "[404/1762] D loss: 1.1001, G loss: 0.9936\n",
      "[484/1762] D loss: 1.3907, G loss: 0.7625\n",
      "[564/1762] D loss: 1.1396, G loss: 0.8800\n",
      "[644/1762] D loss: 1.4128, G loss: 0.7777\n",
      "[724/1762] D loss: 1.3977, G loss: 0.7231\n",
      "[804/1762] D loss: 1.3911, G loss: 0.7324\n",
      "[884/1762] D loss: 1.3988, G loss: 0.6685\n",
      "[964/1762] D loss: 1.1360, G loss: 0.8381\n",
      "[1044/1762] D loss: 1.4121, G loss: 0.5805\n",
      "[1124/1762] D loss: 1.4011, G loss: 0.6762\n",
      "[1204/1762] D loss: 1.1165, G loss: 1.0050\n",
      "[1284/1762] D loss: 1.4769, G loss: 0.8089\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6159\n",
      "[1444/1762] D loss: 1.4003, G loss: 0.6491\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.7221\n",
      "[1604/1762] D loss: 1.3928, G loss: 0.7533\n",
      "[1684/1762] D loss: 1.0984, G loss: 1.0697\n",
      "[1762/1762] D loss: 1.3999, G loss: 0.6436\n",
      "train error: \n",
      " D loss: 1.319511, G loss: 0.725133, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302371, G loss: 0.739161, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.7486\n",
      "[84/1762] D loss: 1.4232, G loss: 0.6552\n",
      "[164/1762] D loss: 1.1240, G loss: 0.9010\n",
      "[244/1762] D loss: 1.3905, G loss: 0.6618\n",
      "[324/1762] D loss: 1.3958, G loss: 0.7362\n",
      "[404/1762] D loss: 1.3900, G loss: 0.6672\n",
      "[484/1762] D loss: 1.4405, G loss: 0.8323\n",
      "[564/1762] D loss: 1.1631, G loss: 0.6971\n",
      "[644/1762] D loss: 1.3869, G loss: 0.7227\n",
      "[724/1762] D loss: 1.1170, G loss: 0.9935\n",
      "[804/1762] D loss: 1.3835, G loss: 0.7658\n",
      "[884/1762] D loss: 1.3888, G loss: 0.6705\n",
      "[964/1762] D loss: 1.3984, G loss: 0.6081\n",
      "[1044/1762] D loss: 1.1333, G loss: 0.9130\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.7721\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.6957\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.8078\n",
      "[1364/1762] D loss: 1.3597, G loss: 0.7583\n",
      "[1444/1762] D loss: 1.1639, G loss: 1.1933\n",
      "[1524/1762] D loss: 1.1257, G loss: 1.1348\n",
      "[1604/1762] D loss: 1.2100, G loss: 0.8239\n",
      "[1684/1762] D loss: 1.1030, G loss: 1.2803\n",
      "[1762/1762] D loss: 1.3425, G loss: 0.8973\n",
      "train error: \n",
      " D loss: 1.296694, G loss: 0.813086, D accuracy: 57.6%, cell accuracy: 99.0%, board accuracy: 36.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278548, G loss: 0.824635, D accuracy: 59.5%, cell accuracy: 98.9%, board accuracy: 33.2% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2864, G loss: 1.0083\n",
      "[84/1762] D loss: 1.3142, G loss: 0.8865\n",
      "[164/1762] D loss: 1.4324, G loss: 0.6585\n",
      "[244/1762] D loss: 1.1697, G loss: 0.7207\n",
      "[324/1762] D loss: 1.1315, G loss: 0.8410\n",
      "[404/1762] D loss: 1.4193, G loss: 0.6479\n",
      "[484/1762] D loss: 1.4167, G loss: 0.7880\n",
      "[564/1762] D loss: 1.5667, G loss: 0.4912\n",
      "[644/1762] D loss: 1.3496, G loss: 0.9889\n",
      "[724/1762] D loss: 1.3835, G loss: 0.6961\n",
      "[804/1762] D loss: 1.5350, G loss: 0.5466\n",
      "[884/1762] D loss: 1.1570, G loss: 0.7297\n",
      "[964/1762] D loss: 1.4229, G loss: 0.6602\n",
      "[1044/1762] D loss: 1.1230, G loss: 0.8173\n",
      "[1124/1762] D loss: 1.3103, G loss: 0.7974\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.7722\n",
      "[1284/1762] D loss: 1.4021, G loss: 0.6711\n",
      "[1364/1762] D loss: 1.4635, G loss: 0.6661\n",
      "[1444/1762] D loss: 1.4006, G loss: 0.7784\n",
      "[1524/1762] D loss: 1.1901, G loss: 0.8433\n",
      "[1604/1762] D loss: 1.2065, G loss: 0.7271\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.4146, G loss: 0.7785\n",
      "train error: \n",
      " D loss: 1.332858, G loss: 0.874866, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315148, G loss: 0.896952, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1325, G loss: 0.9683\n",
      "[84/1762] D loss: 1.1465, G loss: 1.1025\n",
      "[164/1762] D loss: 1.3977, G loss: 0.5724\n",
      "[244/1762] D loss: 1.1423, G loss: 0.9548\n",
      "[324/1762] D loss: 1.4102, G loss: 0.8385\n",
      "[404/1762] D loss: 1.3827, G loss: 0.7451\n",
      "[484/1762] D loss: 1.1364, G loss: 1.0370\n",
      "[564/1762] D loss: 0.9123, G loss: 0.9859\n",
      "[644/1762] D loss: 1.3899, G loss: 0.6989\n",
      "[724/1762] D loss: 1.3768, G loss: 0.6524\n",
      "[804/1762] D loss: 1.1151, G loss: 0.9741\n",
      "[884/1762] D loss: 1.1019, G loss: 0.9225\n",
      "[964/1762] D loss: 1.4318, G loss: 0.5424\n",
      "[1044/1762] D loss: 1.4011, G loss: 0.6659\n",
      "[1124/1762] D loss: 1.3759, G loss: 0.6651\n",
      "[1204/1762] D loss: 1.5043, G loss: 0.9740\n",
      "[1284/1762] D loss: 1.4045, G loss: 0.7900\n",
      "[1364/1762] D loss: 1.1233, G loss: 0.9206\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.7039\n",
      "[1524/1762] D loss: 1.1456, G loss: 0.9946\n",
      "[1604/1762] D loss: 1.4229, G loss: 0.7518\n",
      "[1684/1762] D loss: 1.4019, G loss: 0.7292\n",
      "[1762/1762] D loss: 1.4631, G loss: 0.7393\n",
      "train error: \n",
      " D loss: 1.317852, G loss: 0.740849, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300544, G loss: 0.759246, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1162, G loss: 0.8613\n",
      "[84/1762] D loss: 0.8632, G loss: 1.0511\n",
      "[164/1762] D loss: 1.1432, G loss: 0.9122\n",
      "[244/1762] D loss: 1.4135, G loss: 0.6916\n",
      "[324/1762] D loss: 1.1790, G loss: 0.7601\n",
      "[404/1762] D loss: 1.3883, G loss: 0.6216\n",
      "[484/1762] D loss: 1.4002, G loss: 0.5788\n",
      "[564/1762] D loss: 1.3881, G loss: 0.6948\n",
      "[644/1762] D loss: 1.1492, G loss: 0.8402\n",
      "[724/1762] D loss: 1.3901, G loss: 0.6869\n",
      "[804/1762] D loss: 1.4111, G loss: 0.7867\n",
      "[884/1762] D loss: 1.1271, G loss: 0.9621\n",
      "[964/1762] D loss: 1.3940, G loss: 0.6968\n",
      "[1044/1762] D loss: 1.3987, G loss: 0.7269\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.7072\n",
      "[1204/1762] D loss: 1.3895, G loss: 0.7099\n",
      "[1284/1762] D loss: 1.3929, G loss: 0.7224\n",
      "[1364/1762] D loss: 1.1489, G loss: 0.7856\n",
      "[1444/1762] D loss: 0.8248, G loss: 1.1559\n",
      "[1524/1762] D loss: 1.4095, G loss: 0.8334\n",
      "[1604/1762] D loss: 1.4031, G loss: 0.5523\n",
      "[1684/1762] D loss: 1.1378, G loss: 0.8984\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.6605\n",
      "train error: \n",
      " D loss: 1.316243, G loss: 0.743168, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298073, G loss: 0.761560, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4086, G loss: 0.6457\n",
      "[84/1762] D loss: 1.3907, G loss: 0.7136\n",
      "[164/1762] D loss: 1.1109, G loss: 0.9463\n",
      "[244/1762] D loss: 1.3943, G loss: 0.6467\n",
      "[324/1762] D loss: 1.3994, G loss: 0.7770\n",
      "[404/1762] D loss: 1.3917, G loss: 0.7600\n",
      "[484/1762] D loss: 1.3925, G loss: 0.7807\n",
      "[564/1762] D loss: 1.3968, G loss: 0.7919\n",
      "[644/1762] D loss: 1.3979, G loss: 0.7544\n",
      "[724/1762] D loss: 1.3889, G loss: 0.6623\n",
      "[804/1762] D loss: 1.1628, G loss: 0.7117\n",
      "[884/1762] D loss: 1.4083, G loss: 0.7217\n",
      "[964/1762] D loss: 1.1455, G loss: 0.8351\n",
      "[1044/1762] D loss: 1.3931, G loss: 0.6742\n",
      "[1124/1762] D loss: 1.1302, G loss: 0.8418\n",
      "[1204/1762] D loss: 1.1562, G loss: 0.7276\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.6738\n",
      "[1364/1762] D loss: 1.1125, G loss: 0.9369\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.6300\n",
      "[1524/1762] D loss: 1.3966, G loss: 0.7096\n",
      "[1604/1762] D loss: 1.4199, G loss: 0.8888\n",
      "[1684/1762] D loss: 1.0844, G loss: 1.2123\n",
      "[1762/1762] D loss: 1.3448, G loss: 0.8229\n",
      "train error: \n",
      " D loss: 1.326946, G loss: 0.865777, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305020, G loss: 0.894197, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1213, G loss: 0.9751\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6993\n",
      "[164/1762] D loss: 1.3945, G loss: 0.8052\n",
      "[244/1762] D loss: 1.1485, G loss: 0.9208\n",
      "[324/1762] D loss: 1.1514, G loss: 0.7652\n",
      "[404/1762] D loss: 1.4143, G loss: 0.6503\n",
      "[484/1762] D loss: 1.3926, G loss: 0.6226\n",
      "[564/1762] D loss: 1.4192, G loss: 0.5267\n",
      "[644/1762] D loss: 1.3884, G loss: 0.5914\n",
      "[724/1762] D loss: 1.3956, G loss: 0.7031\n",
      "[804/1762] D loss: 1.3650, G loss: 0.6945\n",
      "[884/1762] D loss: 1.3897, G loss: 0.6384\n",
      "[964/1762] D loss: 1.4337, G loss: 0.8096\n",
      "[1044/1762] D loss: 1.4049, G loss: 0.5276\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.7152\n",
      "[1204/1762] D loss: 1.1234, G loss: 0.8508\n",
      "[1284/1762] D loss: 1.3984, G loss: 0.6287\n",
      "[1364/1762] D loss: 1.4337, G loss: 0.7964\n",
      "[1444/1762] D loss: 1.4277, G loss: 0.6016\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.6118\n",
      "[1604/1762] D loss: 1.4637, G loss: 0.5070\n",
      "[1684/1762] D loss: 1.1358, G loss: 0.8268\n",
      "[1762/1762] D loss: 0.8134, G loss: 1.2089\n",
      "train error: \n",
      " D loss: 1.321298, G loss: 0.828750, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301151, G loss: 0.850628, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.7691\n",
      "[84/1762] D loss: 1.1132, G loss: 1.0120\n",
      "[164/1762] D loss: 1.3909, G loss: 0.7502\n",
      "[244/1762] D loss: 1.4054, G loss: 0.5755\n",
      "[324/1762] D loss: 1.3983, G loss: 0.6004\n",
      "[404/1762] D loss: 1.3210, G loss: 0.8361\n",
      "[484/1762] D loss: 1.3931, G loss: 0.7071\n",
      "[564/1762] D loss: 1.4003, G loss: 0.7289\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6216\n",
      "[724/1762] D loss: 1.3858, G loss: 0.7842\n",
      "[804/1762] D loss: 1.4018, G loss: 0.5633\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7535\n",
      "[964/1762] D loss: 1.1193, G loss: 0.9462\n",
      "[1044/1762] D loss: 1.3850, G loss: 0.6450\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6622\n",
      "[1204/1762] D loss: 1.3966, G loss: 0.5440\n",
      "[1284/1762] D loss: 1.1307, G loss: 0.7306\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7063\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6992\n",
      "[1524/1762] D loss: 1.4278, G loss: 0.6666\n",
      "[1604/1762] D loss: 1.3845, G loss: 0.5551\n",
      "[1684/1762] D loss: 1.1287, G loss: 0.8377\n",
      "[1762/1762] D loss: 0.8854, G loss: 1.0866\n",
      "train error: \n",
      " D loss: 1.320771, G loss: 0.838866, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299751, G loss: 0.862470, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3950, G loss: 0.7404\n",
      "[84/1762] D loss: 1.4034, G loss: 0.6989\n",
      "[164/1762] D loss: 1.3887, G loss: 0.6532\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6922\n",
      "[324/1762] D loss: 1.3923, G loss: 0.7072\n",
      "[404/1762] D loss: 1.3975, G loss: 0.5906\n",
      "[484/1762] D loss: 1.0857, G loss: 0.9833\n",
      "[564/1762] D loss: 1.4746, G loss: 0.8140\n",
      "[644/1762] D loss: 1.4687, G loss: 0.8668\n",
      "[724/1762] D loss: 1.1058, G loss: 1.0888\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6982\n",
      "[884/1762] D loss: 1.3897, G loss: 0.6827\n",
      "[964/1762] D loss: 1.4104, G loss: 0.5713\n",
      "[1044/1762] D loss: 0.8652, G loss: 1.0066\n",
      "[1124/1762] D loss: 0.8681, G loss: 1.0792\n",
      "[1204/1762] D loss: 1.3620, G loss: 0.6397\n",
      "[1284/1762] D loss: 1.3928, G loss: 0.6925\n",
      "[1364/1762] D loss: 1.1370, G loss: 0.8202\n",
      "[1444/1762] D loss: 1.4085, G loss: 0.5867\n",
      "[1524/1762] D loss: 1.1306, G loss: 0.9258\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7247\n",
      "[1684/1762] D loss: 1.1327, G loss: 0.9081\n",
      "[1762/1762] D loss: 1.4115, G loss: 0.5938\n",
      "train error: \n",
      " D loss: 1.326347, G loss: 0.682943, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304307, G loss: 0.708830, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3992, G loss: 0.6653\n",
      "[84/1762] D loss: 1.3937, G loss: 0.6420\n",
      "[164/1762] D loss: 1.1306, G loss: 0.8143\n",
      "[244/1762] D loss: 1.4145, G loss: 0.6176\n",
      "[324/1762] D loss: 1.3979, G loss: 0.7576\n",
      "[404/1762] D loss: 1.4055, G loss: 0.7476\n",
      "[484/1762] D loss: 1.1421, G loss: 1.0547\n",
      "[564/1762] D loss: 1.3938, G loss: 0.7412\n",
      "[644/1762] D loss: 1.3875, G loss: 0.7043\n",
      "[724/1762] D loss: 1.1239, G loss: 0.8364\n",
      "[804/1762] D loss: 1.4069, G loss: 0.6063\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6487\n",
      "[964/1762] D loss: 1.3892, G loss: 0.6389\n",
      "[1044/1762] D loss: 1.3931, G loss: 0.7205\n",
      "[1124/1762] D loss: 1.3623, G loss: 0.6818\n",
      "[1204/1762] D loss: 1.3935, G loss: 0.6828\n",
      "[1284/1762] D loss: 1.3929, G loss: 0.6285\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.5897\n",
      "[1444/1762] D loss: 1.4612, G loss: 0.9238\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.7328\n",
      "[1604/1762] D loss: 1.4066, G loss: 0.5751\n",
      "[1684/1762] D loss: 1.3938, G loss: 0.6488\n",
      "[1762/1762] D loss: 0.8674, G loss: 1.2172\n",
      "train error: \n",
      " D loss: 1.328980, G loss: 0.924476, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308939, G loss: 0.951260, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3983, G loss: 0.7977\n",
      "[84/1762] D loss: 1.3997, G loss: 0.8121\n",
      "[164/1762] D loss: 1.3934, G loss: 0.7982\n",
      "[244/1762] D loss: 1.4525, G loss: 0.5289\n",
      "[324/1762] D loss: 1.3908, G loss: 0.6637\n",
      "[404/1762] D loss: 1.3911, G loss: 0.7003\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6548\n",
      "[564/1762] D loss: 1.4045, G loss: 0.7884\n",
      "[644/1762] D loss: 1.1020, G loss: 0.9692\n",
      "[724/1762] D loss: 1.3893, G loss: 0.7425\n",
      "[804/1762] D loss: 1.3813, G loss: 0.7890\n",
      "[884/1762] D loss: 1.1119, G loss: 0.8571\n",
      "[964/1762] D loss: 1.1121, G loss: 0.8641\n",
      "[1044/1762] D loss: 0.8221, G loss: 1.1586\n",
      "[1124/1762] D loss: 1.3657, G loss: 0.8516\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.6977\n",
      "[1284/1762] D loss: 1.4033, G loss: 0.7362\n",
      "[1364/1762] D loss: 1.4150, G loss: 0.8511\n",
      "[1444/1762] D loss: 1.0987, G loss: 1.1134\n",
      "[1524/1762] D loss: 1.1883, G loss: 0.9797\n",
      "[1604/1762] D loss: 1.3984, G loss: 0.7621\n",
      "[1684/1762] D loss: 1.1413, G loss: 0.7118\n",
      "[1762/1762] D loss: 0.8908, G loss: 0.9292\n",
      "train error: \n",
      " D loss: 1.314547, G loss: 0.757488, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 69.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295100, G loss: 0.781473, D accuracy: 56.1%, cell accuracy: 99.5%, board accuracy: 66.1% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4031, G loss: 0.7326\n",
      "[84/1762] D loss: 1.3625, G loss: 0.7258\n",
      "[164/1762] D loss: 1.5005, G loss: 0.7133\n",
      "[244/1762] D loss: 0.8463, G loss: 1.1241\n",
      "[324/1762] D loss: 1.1201, G loss: 0.9109\n",
      "[404/1762] D loss: 0.7493, G loss: 1.3454\n",
      "[484/1762] D loss: 1.4068, G loss: 0.6099\n",
      "[564/1762] D loss: 1.3583, G loss: 0.5880\n",
      "[644/1762] D loss: 1.1103, G loss: 0.8757\n",
      "[724/1762] D loss: 1.1338, G loss: 0.9078\n",
      "[804/1762] D loss: 1.1399, G loss: 0.8249\n",
      "[884/1762] D loss: 1.4338, G loss: 0.7787\n",
      "[964/1762] D loss: 1.4316, G loss: 0.8168\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.7361\n",
      "[1124/1762] D loss: 1.1094, G loss: 1.1300\n",
      "[1204/1762] D loss: 1.1031, G loss: 1.0848\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.7147\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.6415\n",
      "[1444/1762] D loss: 1.3515, G loss: 0.6990\n",
      "[1524/1762] D loss: 1.1113, G loss: 1.0167\n",
      "[1604/1762] D loss: 1.3927, G loss: 0.7787\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.7527\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.7448\n",
      "train error: \n",
      " D loss: 1.317996, G loss: 0.821117, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296920, G loss: 0.843304, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3628, G loss: 0.6883\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6898\n",
      "[164/1762] D loss: 1.1472, G loss: 0.8136\n",
      "[244/1762] D loss: 1.4330, G loss: 0.6123\n",
      "[324/1762] D loss: 1.4044, G loss: 0.7382\n",
      "[404/1762] D loss: 1.3983, G loss: 0.7306\n",
      "[484/1762] D loss: 1.3899, G loss: 0.6601\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7071\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6489\n",
      "[724/1762] D loss: 1.4058, G loss: 0.8657\n",
      "[804/1762] D loss: 1.3901, G loss: 0.7021\n",
      "[884/1762] D loss: 1.3895, G loss: 0.7214\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6809\n",
      "[1044/1762] D loss: 1.3894, G loss: 0.7019\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6973\n",
      "[1204/1762] D loss: 1.4121, G loss: 0.5684\n",
      "[1284/1762] D loss: 0.8226, G loss: 1.1819\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7263\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.7122\n",
      "[1524/1762] D loss: 1.3976, G loss: 0.6092\n",
      "[1604/1762] D loss: 1.4024, G loss: 0.7047\n",
      "[1684/1762] D loss: 1.4765, G loss: 0.6534\n",
      "[1762/1762] D loss: 1.3926, G loss: 0.7967\n",
      "train error: \n",
      " D loss: 1.319039, G loss: 0.856818, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299886, G loss: 0.879899, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.7937\n",
      "[84/1762] D loss: 1.3931, G loss: 0.6864\n",
      "[164/1762] D loss: 1.4056, G loss: 0.7218\n",
      "[244/1762] D loss: 1.1247, G loss: 0.9340\n",
      "[324/1762] D loss: 1.3905, G loss: 0.6993\n",
      "[404/1762] D loss: 1.0967, G loss: 0.9117\n",
      "[484/1762] D loss: 1.1299, G loss: 0.7973\n",
      "[564/1762] D loss: 1.3884, G loss: 0.6343\n",
      "[644/1762] D loss: 1.4000, G loss: 0.6266\n",
      "[724/1762] D loss: 1.0971, G loss: 0.9225\n",
      "[804/1762] D loss: 1.0821, G loss: 0.9627\n",
      "[884/1762] D loss: 1.1071, G loss: 0.8969\n",
      "[964/1762] D loss: 1.3720, G loss: 0.7640\n",
      "[1044/1762] D loss: 1.4043, G loss: 0.7597\n",
      "[1124/1762] D loss: 0.8161, G loss: 1.1673\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.7008\n",
      "[1284/1762] D loss: 1.0806, G loss: 1.1004\n",
      "[1364/1762] D loss: 0.8088, G loss: 1.4739\n",
      "[1444/1762] D loss: 1.4250, G loss: 0.6022\n",
      "[1524/1762] D loss: 1.0987, G loss: 0.9528\n",
      "[1604/1762] D loss: 1.0209, G loss: 1.0639\n",
      "[1684/1762] D loss: 1.1121, G loss: 0.9638\n",
      "[1762/1762] D loss: 0.7834, G loss: 1.1585\n",
      "train error: \n",
      " D loss: 1.313212, G loss: 0.823999, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 74.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294051, G loss: 0.837992, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4403, G loss: 0.9418\n",
      "[84/1762] D loss: 1.3809, G loss: 0.7657\n",
      "[164/1762] D loss: 1.3869, G loss: 0.5925\n",
      "[244/1762] D loss: 1.3842, G loss: 0.7434\n",
      "[324/1762] D loss: 1.4047, G loss: 0.7726\n",
      "[404/1762] D loss: 1.4085, G loss: 0.8059\n",
      "[484/1762] D loss: 1.1217, G loss: 1.0452\n",
      "[564/1762] D loss: 1.1127, G loss: 0.8770\n",
      "[644/1762] D loss: 1.3957, G loss: 0.7427\n",
      "[724/1762] D loss: 1.1247, G loss: 0.8712\n",
      "[804/1762] D loss: 1.3946, G loss: 0.5707\n",
      "[884/1762] D loss: 1.3905, G loss: 0.7038\n",
      "[964/1762] D loss: 1.3931, G loss: 0.7743\n",
      "[1044/1762] D loss: 1.4435, G loss: 0.6217\n",
      "[1124/1762] D loss: 1.4235, G loss: 0.7121\n",
      "[1204/1762] D loss: 1.3931, G loss: 0.6383\n",
      "[1284/1762] D loss: 1.1254, G loss: 0.9053\n",
      "[1364/1762] D loss: 1.4005, G loss: 0.6899\n",
      "[1444/1762] D loss: 1.1475, G loss: 1.0792\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.6985\n",
      "[1604/1762] D loss: 1.1230, G loss: 1.0080\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.6928\n",
      "[1762/1762] D loss: 0.8922, G loss: 1.0156\n",
      "train error: \n",
      " D loss: 1.327609, G loss: 0.889150, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306324, G loss: 0.908890, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4112, G loss: 0.8624\n",
      "[84/1762] D loss: 1.4101, G loss: 0.7940\n",
      "[164/1762] D loss: 1.1879, G loss: 0.7186\n",
      "[244/1762] D loss: 1.1036, G loss: 0.8740\n",
      "[324/1762] D loss: 1.3821, G loss: 0.6612\n",
      "[404/1762] D loss: 1.4090, G loss: 0.8058\n",
      "[484/1762] D loss: 1.1281, G loss: 0.8455\n",
      "[564/1762] D loss: 1.1248, G loss: 1.0065\n",
      "[644/1762] D loss: 1.3977, G loss: 0.7660\n",
      "[724/1762] D loss: 1.4089, G loss: 0.8260\n",
      "[804/1762] D loss: 1.3956, G loss: 0.7019\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6264\n",
      "[964/1762] D loss: 1.1046, G loss: 0.8417\n",
      "[1044/1762] D loss: 0.8137, G loss: 1.0820\n",
      "[1124/1762] D loss: 1.3334, G loss: 0.7611\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.6220\n",
      "[1284/1762] D loss: 1.4030, G loss: 0.6434\n",
      "[1364/1762] D loss: 1.1065, G loss: 0.9565\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.6062\n",
      "[1524/1762] D loss: 1.1400, G loss: 0.7670\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.6983\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.6816\n",
      "[1762/1762] D loss: 0.8737, G loss: 0.9749\n",
      "train error: \n",
      " D loss: 1.317240, G loss: 0.799491, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295163, G loss: 0.821282, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1209, G loss: 0.9488\n",
      "[84/1762] D loss: 0.8565, G loss: 1.2245\n",
      "[164/1762] D loss: 1.1427, G loss: 0.9276\n",
      "[244/1762] D loss: 1.4119, G loss: 0.6979\n",
      "[324/1762] D loss: 1.4020, G loss: 0.5526\n",
      "[404/1762] D loss: 1.3819, G loss: 0.6426\n",
      "[484/1762] D loss: 1.4156, G loss: 0.5401\n",
      "[564/1762] D loss: 1.3594, G loss: 0.6114\n",
      "[644/1762] D loss: 1.3904, G loss: 0.6516\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6797\n",
      "[804/1762] D loss: 1.3978, G loss: 0.6819\n",
      "[884/1762] D loss: 1.3964, G loss: 0.6950\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6890\n",
      "[1044/1762] D loss: 1.1194, G loss: 0.8224\n",
      "[1124/1762] D loss: 1.4046, G loss: 0.6917\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7554\n",
      "[1284/1762] D loss: 1.4049, G loss: 0.6088\n",
      "[1364/1762] D loss: 1.4202, G loss: 0.7932\n",
      "[1444/1762] D loss: 1.3950, G loss: 0.7494\n",
      "[1524/1762] D loss: 1.3964, G loss: 0.8070\n",
      "[1604/1762] D loss: 0.5675, G loss: 1.4683\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.7529\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.6897\n",
      "train error: \n",
      " D loss: 1.314592, G loss: 0.749714, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292376, G loss: 0.774236, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6376\n",
      "[84/1762] D loss: 1.3983, G loss: 0.7230\n",
      "[164/1762] D loss: 1.4044, G loss: 0.6058\n",
      "[244/1762] D loss: 0.8296, G loss: 1.2148\n",
      "[324/1762] D loss: 1.3903, G loss: 0.7366\n",
      "[404/1762] D loss: 1.3947, G loss: 0.8140\n",
      "[484/1762] D loss: 1.1133, G loss: 0.9022\n",
      "[564/1762] D loss: 1.3913, G loss: 0.7067\n",
      "[644/1762] D loss: 1.3910, G loss: 0.7056\n",
      "[724/1762] D loss: 1.3804, G loss: 0.6478\n",
      "[804/1762] D loss: 1.3972, G loss: 0.7163\n",
      "[884/1762] D loss: 1.4280, G loss: 0.8308\n",
      "[964/1762] D loss: 1.3886, G loss: 0.7532\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.7264\n",
      "[1124/1762] D loss: 1.4109, G loss: 0.7677\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.6818\n",
      "[1284/1762] D loss: 1.4366, G loss: 0.7203\n",
      "[1364/1762] D loss: 1.4259, G loss: 0.8591\n",
      "[1444/1762] D loss: 1.4147, G loss: 0.6755\n",
      "[1524/1762] D loss: 1.5878, G loss: 0.5373\n",
      "[1604/1762] D loss: 1.5317, G loss: 0.8710\n",
      "[1684/1762] D loss: 1.1821, G loss: 1.0031\n",
      "[1762/1762] D loss: 1.3943, G loss: 0.7173\n",
      "train error: \n",
      " D loss: 1.331257, G loss: 0.740046, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311964, G loss: 0.757648, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.7473\n",
      "[84/1762] D loss: 1.1606, G loss: 0.8974\n",
      "[164/1762] D loss: 1.3934, G loss: 0.7641\n",
      "[244/1762] D loss: 1.3896, G loss: 0.6411\n",
      "[324/1762] D loss: 1.0656, G loss: 1.0234\n",
      "[404/1762] D loss: 1.3917, G loss: 0.6800\n",
      "[484/1762] D loss: 1.1434, G loss: 0.8577\n",
      "[564/1762] D loss: 1.1715, G loss: 0.7457\n",
      "[644/1762] D loss: 1.3818, G loss: 0.7142\n",
      "[724/1762] D loss: 1.1424, G loss: 0.8307\n",
      "[804/1762] D loss: 1.3766, G loss: 0.6135\n",
      "[884/1762] D loss: 1.1336, G loss: 0.9282\n",
      "[964/1762] D loss: 1.4040, G loss: 0.7278\n",
      "[1044/1762] D loss: 1.4029, G loss: 0.6796\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.7262\n",
      "[1204/1762] D loss: 1.3966, G loss: 0.5971\n",
      "[1284/1762] D loss: 1.4032, G loss: 0.7691\n",
      "[1364/1762] D loss: 1.1492, G loss: 0.7921\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7289\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.7492\n",
      "[1604/1762] D loss: 1.3843, G loss: 0.7236\n",
      "[1684/1762] D loss: 1.1304, G loss: 0.8016\n",
      "[1762/1762] D loss: 0.8959, G loss: 1.0054\n",
      "train error: \n",
      " D loss: 1.319657, G loss: 0.699154, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300510, G loss: 0.713671, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.6870\n",
      "[84/1762] D loss: 1.3909, G loss: 0.6772\n",
      "[164/1762] D loss: 1.3880, G loss: 0.7096\n",
      "[244/1762] D loss: 1.3936, G loss: 0.8522\n",
      "[324/1762] D loss: 1.3975, G loss: 0.7235\n",
      "[404/1762] D loss: 1.1337, G loss: 0.9330\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6743\n",
      "[564/1762] D loss: 1.4142, G loss: 0.7679\n",
      "[644/1762] D loss: 0.8472, G loss: 1.1486\n",
      "[724/1762] D loss: 1.3913, G loss: 0.6867\n",
      "[804/1762] D loss: 1.3900, G loss: 0.6582\n",
      "[884/1762] D loss: 1.0884, G loss: 0.9870\n",
      "[964/1762] D loss: 0.8604, G loss: 1.0511\n",
      "[1044/1762] D loss: 1.4084, G loss: 0.8250\n",
      "[1124/1762] D loss: 0.8432, G loss: 1.0854\n",
      "[1204/1762] D loss: 1.4366, G loss: 0.7981\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.7068\n",
      "[1364/1762] D loss: 1.4055, G loss: 0.7992\n",
      "[1444/1762] D loss: 1.1479, G loss: 0.7527\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.7511\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.6288\n",
      "[1684/1762] D loss: 1.1295, G loss: 0.9798\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.6325\n",
      "train error: \n",
      " D loss: 1.295926, G loss: 0.892804, D accuracy: 61.3%, cell accuracy: 98.4%, board accuracy: 21.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265536, G loss: 0.938728, D accuracy: 64.8%, cell accuracy: 98.3%, board accuracy: 18.9% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3563, G loss: 1.1544\n",
      "[84/1762] D loss: 1.2308, G loss: 0.6672\n",
      "[164/1762] D loss: 0.9482, G loss: 1.0270\n",
      "[244/1762] D loss: 1.3939, G loss: 0.8949\n",
      "[324/1762] D loss: 1.4263, G loss: 0.6664\n",
      "[404/1762] D loss: 1.3683, G loss: 0.7629\n",
      "[484/1762] D loss: 1.1464, G loss: 0.9668\n",
      "[564/1762] D loss: 1.4464, G loss: 0.9103\n",
      "[644/1762] D loss: 1.4113, G loss: 0.7625\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6894\n",
      "[804/1762] D loss: 1.3915, G loss: 0.7137\n",
      "[884/1762] D loss: 1.1790, G loss: 0.7662\n",
      "[964/1762] D loss: 1.3821, G loss: 0.7459\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.7319\n",
      "[1124/1762] D loss: 1.3946, G loss: 0.7876\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.7012\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6562\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.6621\n",
      "[1444/1762] D loss: 1.4007, G loss: 0.7356\n",
      "[1524/1762] D loss: 1.3643, G loss: 0.8373\n",
      "[1604/1762] D loss: 1.1656, G loss: 0.7636\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.6928\n",
      "[1762/1762] D loss: 1.4713, G loss: 0.7714\n",
      "train error: \n",
      " D loss: 1.324532, G loss: 0.840090, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304216, G loss: 0.851685, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.7450\n",
      "[84/1762] D loss: 1.3940, G loss: 0.6252\n",
      "[164/1762] D loss: 1.3570, G loss: 0.6907\n",
      "[244/1762] D loss: 1.1271, G loss: 0.8190\n",
      "[324/1762] D loss: 1.3911, G loss: 0.7012\n",
      "[404/1762] D loss: 1.3890, G loss: 0.6046\n",
      "[484/1762] D loss: 1.3880, G loss: 0.7373\n",
      "[564/1762] D loss: 1.1536, G loss: 0.8793\n",
      "[644/1762] D loss: 1.3688, G loss: 0.6679\n",
      "[724/1762] D loss: 1.3937, G loss: 0.6888\n",
      "[804/1762] D loss: 1.3939, G loss: 0.6980\n",
      "[884/1762] D loss: 1.3999, G loss: 0.6060\n",
      "[964/1762] D loss: 1.3996, G loss: 0.5639\n",
      "[1044/1762] D loss: 1.4107, G loss: 0.7557\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.8069\n",
      "[1204/1762] D loss: 1.1643, G loss: 0.7682\n",
      "[1284/1762] D loss: 1.3934, G loss: 0.7977\n",
      "[1364/1762] D loss: 1.4017, G loss: 0.7860\n",
      "[1444/1762] D loss: 1.0996, G loss: 0.9752\n",
      "[1524/1762] D loss: 1.3237, G loss: 0.6748\n",
      "[1604/1762] D loss: 1.1222, G loss: 0.7931\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.7060\n",
      "[1762/1762] D loss: 0.8191, G loss: 1.1277\n",
      "train error: \n",
      " D loss: 1.313143, G loss: 0.788767, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293084, G loss: 0.807064, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1271, G loss: 0.8361\n",
      "[84/1762] D loss: 1.1255, G loss: 0.9128\n",
      "[164/1762] D loss: 1.1261, G loss: 0.9267\n",
      "[244/1762] D loss: 1.3417, G loss: 0.7751\n",
      "[324/1762] D loss: 1.3858, G loss: 0.7580\n",
      "[404/1762] D loss: 1.4024, G loss: 0.7027\n",
      "[484/1762] D loss: 1.3889, G loss: 0.6503\n",
      "[564/1762] D loss: 1.4053, G loss: 0.6912\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6666\n",
      "[724/1762] D loss: 1.3978, G loss: 0.7429\n",
      "[804/1762] D loss: 1.3921, G loss: 0.6983\n",
      "[884/1762] D loss: 1.4067, G loss: 0.6055\n",
      "[964/1762] D loss: 1.0579, G loss: 1.0525\n",
      "[1044/1762] D loss: 1.3989, G loss: 0.8131\n",
      "[1124/1762] D loss: 1.3954, G loss: 0.7185\n",
      "[1204/1762] D loss: 1.1305, G loss: 0.8674\n",
      "[1284/1762] D loss: 1.3905, G loss: 0.7180\n",
      "[1364/1762] D loss: 1.3934, G loss: 0.6754\n",
      "[1444/1762] D loss: 1.3809, G loss: 0.6746\n",
      "[1524/1762] D loss: 1.4030, G loss: 0.5747\n",
      "[1604/1762] D loss: 1.3919, G loss: 0.7483\n",
      "[1684/1762] D loss: 1.3975, G loss: 0.6326\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.7047\n",
      "train error: \n",
      " D loss: 1.319442, G loss: 0.686083, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302468, G loss: 0.702170, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4057, G loss: 0.6582\n",
      "[84/1762] D loss: 1.3908, G loss: 0.6665\n",
      "[164/1762] D loss: 1.1043, G loss: 0.9853\n",
      "[244/1762] D loss: 1.3935, G loss: 0.7397\n",
      "[324/1762] D loss: 1.1355, G loss: 1.0261\n",
      "[404/1762] D loss: 1.1546, G loss: 0.8351\n",
      "[484/1762] D loss: 1.1143, G loss: 0.8777\n",
      "[564/1762] D loss: 1.3923, G loss: 0.7364\n",
      "[644/1762] D loss: 1.4177, G loss: 0.7412\n",
      "[724/1762] D loss: 1.4211, G loss: 0.7664\n",
      "[804/1762] D loss: 1.3816, G loss: 0.7676\n",
      "[884/1762] D loss: 1.3999, G loss: 0.7866\n",
      "[964/1762] D loss: 1.3564, G loss: 0.8356\n",
      "[1044/1762] D loss: 1.4251, G loss: 0.8504\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7389\n",
      "[1204/1762] D loss: 1.4009, G loss: 0.7738\n",
      "[1284/1762] D loss: 1.3949, G loss: 0.6475\n",
      "[1364/1762] D loss: 1.0984, G loss: 0.9403\n",
      "[1444/1762] D loss: 1.3582, G loss: 0.6779\n",
      "[1524/1762] D loss: 1.3962, G loss: 0.6721\n",
      "[1604/1762] D loss: 1.3284, G loss: 0.6628\n",
      "[1684/1762] D loss: 1.3940, G loss: 0.7497\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.6240\n",
      "train error: \n",
      " D loss: 1.315666, G loss: 0.689978, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292441, G loss: 0.710062, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3817, G loss: 0.6542\n",
      "[84/1762] D loss: 1.3847, G loss: 0.7088\n",
      "[164/1762] D loss: 1.1356, G loss: 0.8224\n",
      "[244/1762] D loss: 1.3965, G loss: 0.7752\n",
      "[324/1762] D loss: 1.1044, G loss: 1.0604\n",
      "[404/1762] D loss: 1.3924, G loss: 0.7260\n",
      "[484/1762] D loss: 1.3883, G loss: 0.6585\n",
      "[564/1762] D loss: 1.3712, G loss: 0.6530\n",
      "[644/1762] D loss: 1.1301, G loss: 0.8177\n",
      "[724/1762] D loss: 1.3949, G loss: 0.6187\n",
      "[804/1762] D loss: 1.3607, G loss: 0.7231\n",
      "[884/1762] D loss: 1.3734, G loss: 0.7071\n",
      "[964/1762] D loss: 1.4040, G loss: 0.5478\n",
      "[1044/1762] D loss: 1.1232, G loss: 1.1182\n",
      "[1124/1762] D loss: 1.4010, G loss: 0.8124\n",
      "[1204/1762] D loss: 1.3927, G loss: 0.6623\n",
      "[1284/1762] D loss: 1.3966, G loss: 0.6225\n",
      "[1364/1762] D loss: 1.4045, G loss: 0.7953\n",
      "[1444/1762] D loss: 1.4210, G loss: 0.8264\n",
      "[1524/1762] D loss: 1.1244, G loss: 1.0223\n",
      "[1604/1762] D loss: 1.3993, G loss: 0.6702\n",
      "[1684/1762] D loss: 1.3957, G loss: 0.7214\n",
      "[1762/1762] D loss: 1.4007, G loss: 0.7640\n",
      "train error: \n",
      " D loss: 1.312202, G loss: 0.802186, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291163, G loss: 0.824868, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6509\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7128\n",
      "[164/1762] D loss: 1.1065, G loss: 1.0967\n",
      "[244/1762] D loss: 0.8218, G loss: 1.3174\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7903\n",
      "[404/1762] D loss: 1.3962, G loss: 0.6503\n",
      "[484/1762] D loss: 1.3925, G loss: 0.7505\n",
      "[564/1762] D loss: 1.3530, G loss: 0.8287\n",
      "[644/1762] D loss: 1.3887, G loss: 0.7624\n",
      "[724/1762] D loss: 1.3896, G loss: 0.7468\n",
      "[804/1762] D loss: 1.4069, G loss: 0.7719\n",
      "[884/1762] D loss: 1.3943, G loss: 0.7900\n",
      "[964/1762] D loss: 1.1426, G loss: 0.8056\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.6563\n",
      "[1124/1762] D loss: 1.3979, G loss: 0.6170\n",
      "[1204/1762] D loss: 1.4095, G loss: 0.7730\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.6579\n",
      "[1364/1762] D loss: 1.3757, G loss: 0.7080\n",
      "[1444/1762] D loss: 0.8488, G loss: 0.9946\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.7691\n",
      "[1604/1762] D loss: 1.3994, G loss: 0.7011\n",
      "[1684/1762] D loss: 1.1691, G loss: 0.7863\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6854\n",
      "train error: \n",
      " D loss: 1.316471, G loss: 0.711557, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296460, G loss: 0.734614, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4157, G loss: 0.6547\n",
      "[84/1762] D loss: 1.3958, G loss: 0.6695\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7153\n",
      "[244/1762] D loss: 1.3907, G loss: 0.6662\n",
      "[324/1762] D loss: 1.3883, G loss: 0.6579\n",
      "[404/1762] D loss: 1.4139, G loss: 0.7285\n",
      "[484/1762] D loss: 1.4086, G loss: 0.7277\n",
      "[564/1762] D loss: 1.3992, G loss: 0.7924\n",
      "[644/1762] D loss: 1.1136, G loss: 0.9905\n",
      "[724/1762] D loss: 1.3883, G loss: 0.7037\n",
      "[804/1762] D loss: 1.3930, G loss: 0.6880\n",
      "[884/1762] D loss: 1.4062, G loss: 0.8042\n",
      "[964/1762] D loss: 0.8497, G loss: 1.2177\n",
      "[1044/1762] D loss: 1.1205, G loss: 0.9511\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.6604\n",
      "[1204/1762] D loss: 1.1785, G loss: 0.8665\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.6424\n",
      "[1364/1762] D loss: 1.3067, G loss: 0.7436\n",
      "[1444/1762] D loss: 1.4042, G loss: 0.8315\n",
      "[1524/1762] D loss: 1.3703, G loss: 0.8214\n",
      "[1604/1762] D loss: 1.4291, G loss: 0.5566\n",
      "[1684/1762] D loss: 1.3780, G loss: 0.5838\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.7105\n",
      "train error: \n",
      " D loss: 1.310523, G loss: 0.744167, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 68.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294806, G loss: 0.758208, D accuracy: 56.2%, cell accuracy: 99.6%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3964, G loss: 0.6557\n",
      "[84/1762] D loss: 1.1233, G loss: 0.7803\n",
      "[164/1762] D loss: 1.3921, G loss: 0.6156\n",
      "[244/1762] D loss: 1.4046, G loss: 0.6651\n",
      "[324/1762] D loss: 1.3912, G loss: 0.8162\n",
      "[404/1762] D loss: 1.3948, G loss: 0.7465\n",
      "[484/1762] D loss: 1.1203, G loss: 1.0892\n",
      "[564/1762] D loss: 1.3932, G loss: 0.6314\n",
      "[644/1762] D loss: 1.4296, G loss: 0.9300\n",
      "[724/1762] D loss: 0.4619, G loss: 1.5783\n",
      "[804/1762] D loss: 1.3893, G loss: 0.7493\n",
      "[884/1762] D loss: 1.4020, G loss: 0.6291\n",
      "[964/1762] D loss: 1.4111, G loss: 0.5285\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.6046\n",
      "[1124/1762] D loss: 1.4354, G loss: 0.8813\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.7831\n",
      "[1284/1762] D loss: 1.3970, G loss: 0.8284\n",
      "[1364/1762] D loss: 0.7659, G loss: 1.2062\n",
      "[1444/1762] D loss: 1.4026, G loss: 0.7028\n",
      "[1524/1762] D loss: 1.3997, G loss: 0.7010\n",
      "[1604/1762] D loss: 1.1466, G loss: 0.8622\n",
      "[1684/1762] D loss: 1.3473, G loss: 0.7889\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6841\n",
      "train error: \n",
      " D loss: 1.314802, G loss: 0.716517, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293661, G loss: 0.735253, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.6452\n",
      "[84/1762] D loss: 1.4304, G loss: 0.8749\n",
      "[164/1762] D loss: 1.1434, G loss: 0.8142\n",
      "[244/1762] D loss: 1.3967, G loss: 0.8153\n",
      "[324/1762] D loss: 1.3938, G loss: 0.7308\n",
      "[404/1762] D loss: 1.1436, G loss: 0.8150\n",
      "[484/1762] D loss: 1.3920, G loss: 0.7158\n",
      "[564/1762] D loss: 1.0914, G loss: 0.9758\n",
      "[644/1762] D loss: 1.3905, G loss: 0.7112\n",
      "[724/1762] D loss: 1.3972, G loss: 0.6933\n",
      "[804/1762] D loss: 1.3926, G loss: 0.7255\n",
      "[884/1762] D loss: 1.4229, G loss: 0.5803\n",
      "[964/1762] D loss: 1.4147, G loss: 0.5550\n",
      "[1044/1762] D loss: 1.1011, G loss: 0.9710\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.7756\n",
      "[1204/1762] D loss: 1.3978, G loss: 0.7376\n",
      "[1284/1762] D loss: 1.3833, G loss: 0.7227\n",
      "[1364/1762] D loss: 1.4151, G loss: 0.7992\n",
      "[1444/1762] D loss: 1.4408, G loss: 0.8818\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6964\n",
      "[1604/1762] D loss: 0.7869, G loss: 1.3115\n",
      "[1684/1762] D loss: 1.1004, G loss: 0.9937\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6823\n",
      "train error: \n",
      " D loss: 1.313611, G loss: 0.745232, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293061, G loss: 0.767711, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7024\n",
      "[84/1762] D loss: 1.3904, G loss: 0.6358\n",
      "[164/1762] D loss: 1.3921, G loss: 0.7143\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7785\n",
      "[324/1762] D loss: 1.4028, G loss: 0.7314\n",
      "[404/1762] D loss: 1.3891, G loss: 0.6795\n",
      "[484/1762] D loss: 1.3528, G loss: 0.7180\n",
      "[564/1762] D loss: 1.3903, G loss: 0.7487\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6932\n",
      "[724/1762] D loss: 1.3855, G loss: 0.7138\n",
      "[804/1762] D loss: 1.1711, G loss: 0.8451\n",
      "[884/1762] D loss: 1.0803, G loss: 1.0442\n",
      "[964/1762] D loss: 1.4047, G loss: 0.6591\n",
      "[1044/1762] D loss: 1.1283, G loss: 1.1646\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7279\n",
      "[1204/1762] D loss: 1.3992, G loss: 0.7892\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.7434\n",
      "[1364/1762] D loss: 1.3903, G loss: 0.6825\n",
      "[1444/1762] D loss: 1.1383, G loss: 0.8654\n",
      "[1524/1762] D loss: 1.1391, G loss: 0.9338\n",
      "[1604/1762] D loss: 1.4054, G loss: 0.6712\n",
      "[1684/1762] D loss: 1.3627, G loss: 0.7752\n",
      "[1762/1762] D loss: 1.4295, G loss: 0.5605\n",
      "train error: \n",
      " D loss: 1.319244, G loss: 0.689016, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298126, G loss: 0.712286, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4172, G loss: 0.7487\n",
      "[84/1762] D loss: 1.3906, G loss: 0.7447\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6329\n",
      "[244/1762] D loss: 1.4054, G loss: 0.7331\n",
      "[324/1762] D loss: 1.3954, G loss: 0.8406\n",
      "[404/1762] D loss: 1.3986, G loss: 0.7910\n",
      "[484/1762] D loss: 1.4019, G loss: 0.6429\n",
      "[564/1762] D loss: 1.3904, G loss: 0.6220\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6400\n",
      "[724/1762] D loss: 1.1182, G loss: 1.0531\n",
      "[804/1762] D loss: 1.3860, G loss: 0.7205\n",
      "[884/1762] D loss: 1.1249, G loss: 0.8443\n",
      "[964/1762] D loss: 1.3948, G loss: 0.6251\n",
      "[1044/1762] D loss: 1.3923, G loss: 0.6246\n",
      "[1124/1762] D loss: 1.4036, G loss: 0.7267\n",
      "[1204/1762] D loss: 1.1183, G loss: 0.8438\n",
      "[1284/1762] D loss: 1.1213, G loss: 0.9953\n",
      "[1364/1762] D loss: 1.3651, G loss: 0.7056\n",
      "[1444/1762] D loss: 1.3950, G loss: 0.7828\n",
      "[1524/1762] D loss: 1.4089, G loss: 0.8161\n",
      "[1604/1762] D loss: 1.4082, G loss: 0.6750\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.7643\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7055\n",
      "train error: \n",
      " D loss: 1.310770, G loss: 0.774280, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287623, G loss: 0.803990, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0939, G loss: 0.9721\n",
      "[84/1762] D loss: 1.0744, G loss: 1.0883\n",
      "[164/1762] D loss: 1.3899, G loss: 0.6608\n",
      "[244/1762] D loss: 1.4077, G loss: 0.8429\n",
      "[324/1762] D loss: 1.4077, G loss: 0.7482\n",
      "[404/1762] D loss: 1.4132, G loss: 0.6502\n",
      "[484/1762] D loss: 1.4098, G loss: 0.5906\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6786\n",
      "[644/1762] D loss: 1.1303, G loss: 1.0501\n",
      "[724/1762] D loss: 1.3937, G loss: 0.7260\n",
      "[804/1762] D loss: 1.3924, G loss: 0.6431\n",
      "[884/1762] D loss: 1.3955, G loss: 0.7886\n",
      "[964/1762] D loss: 1.3956, G loss: 0.7562\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.7230\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.7761\n",
      "[1204/1762] D loss: 1.4037, G loss: 0.7193\n",
      "[1284/1762] D loss: 1.0877, G loss: 1.1533\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.7642\n",
      "[1444/1762] D loss: 1.3588, G loss: 0.7394\n",
      "[1524/1762] D loss: 1.3972, G loss: 0.6349\n",
      "[1604/1762] D loss: 1.4062, G loss: 0.5626\n",
      "[1684/1762] D loss: 1.1082, G loss: 0.9429\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.6494\n",
      "train error: \n",
      " D loss: 1.324496, G loss: 0.657574, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304121, G loss: 0.681866, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4184, G loss: 0.5790\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7720\n",
      "[164/1762] D loss: 1.4013, G loss: 0.7401\n",
      "[244/1762] D loss: 1.3595, G loss: 0.6943\n",
      "[324/1762] D loss: 1.4035, G loss: 0.5234\n",
      "[404/1762] D loss: 1.1062, G loss: 0.9339\n",
      "[484/1762] D loss: 1.3979, G loss: 0.6177\n",
      "[564/1762] D loss: 1.3912, G loss: 0.6633\n",
      "[644/1762] D loss: 1.3929, G loss: 0.6139\n",
      "[724/1762] D loss: 1.3925, G loss: 0.6167\n",
      "[804/1762] D loss: 1.3967, G loss: 0.7120\n",
      "[884/1762] D loss: 1.1312, G loss: 1.0126\n",
      "[964/1762] D loss: 1.4010, G loss: 0.7002\n",
      "[1044/1762] D loss: 1.1296, G loss: 0.8773\n",
      "[1124/1762] D loss: 1.4104, G loss: 0.8720\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.7116\n",
      "[1284/1762] D loss: 1.3496, G loss: 0.7865\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.6649\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.6569\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.7932\n",
      "[1604/1762] D loss: 1.3924, G loss: 0.7571\n",
      "[1684/1762] D loss: 1.4730, G loss: 0.8399\n",
      "[1762/1762] D loss: 1.3956, G loss: 0.7259\n",
      "train error: \n",
      " D loss: 1.317460, G loss: 0.861515, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297125, G loss: 0.889668, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4142, G loss: 0.7479\n",
      "[84/1762] D loss: 1.3626, G loss: 0.7481\n",
      "[164/1762] D loss: 1.1074, G loss: 0.9672\n",
      "[244/1762] D loss: 1.3846, G loss: 0.6420\n",
      "[324/1762] D loss: 0.8327, G loss: 1.1021\n",
      "[404/1762] D loss: 1.3904, G loss: 0.6583\n",
      "[484/1762] D loss: 1.0907, G loss: 0.9524\n",
      "[564/1762] D loss: 1.3970, G loss: 0.8068\n",
      "[644/1762] D loss: 1.0979, G loss: 0.9773\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6926\n",
      "[804/1762] D loss: 1.4355, G loss: 0.7989\n",
      "[884/1762] D loss: 1.3442, G loss: 0.7108\n",
      "[964/1762] D loss: 1.0515, G loss: 0.9493\n",
      "[1044/1762] D loss: 1.3517, G loss: 0.7768\n",
      "[1124/1762] D loss: 1.3790, G loss: 0.7327\n",
      "[1204/1762] D loss: 1.3961, G loss: 0.6955\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6840\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.6719\n",
      "[1444/1762] D loss: 1.3593, G loss: 0.7254\n",
      "[1524/1762] D loss: 1.4087, G loss: 0.9297\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.7561\n",
      "[1684/1762] D loss: 1.3934, G loss: 0.7145\n",
      "[1762/1762] D loss: 1.4008, G loss: 0.7812\n",
      "train error: \n",
      " D loss: 1.319807, G loss: 0.885385, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299278, G loss: 0.910894, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1173, G loss: 0.9513\n",
      "[84/1762] D loss: 1.4186, G loss: 0.6999\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6909\n",
      "[244/1762] D loss: 1.3850, G loss: 0.7348\n",
      "[324/1762] D loss: 1.4284, G loss: 0.9188\n",
      "[404/1762] D loss: 1.1303, G loss: 0.8670\n",
      "[484/1762] D loss: 1.1337, G loss: 0.8415\n",
      "[564/1762] D loss: 1.3899, G loss: 0.7120\n",
      "[644/1762] D loss: 1.3908, G loss: 0.7220\n",
      "[724/1762] D loss: 1.3958, G loss: 0.7693\n",
      "[804/1762] D loss: 1.4127, G loss: 0.6282\n",
      "[884/1762] D loss: 1.3894, G loss: 0.6750\n",
      "[964/1762] D loss: 1.3886, G loss: 0.7667\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.6646\n",
      "[1124/1762] D loss: 1.3720, G loss: 0.5768\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6799\n",
      "[1284/1762] D loss: 1.3941, G loss: 0.6981\n",
      "[1364/1762] D loss: 1.4051, G loss: 0.8247\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6669\n",
      "[1524/1762] D loss: 1.1345, G loss: 0.8505\n",
      "[1604/1762] D loss: 1.4049, G loss: 0.6391\n",
      "[1684/1762] D loss: 1.4287, G loss: 0.6505\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6901\n",
      "train error: \n",
      " D loss: 1.303839, G loss: 0.702977, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 79.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277129, G loss: 0.731998, D accuracy: 59.0%, cell accuracy: 99.6%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3538, G loss: 0.6082\n",
      "[84/1762] D loss: 1.3587, G loss: 0.6615\n",
      "[164/1762] D loss: 1.3695, G loss: 0.7267\n",
      "[244/1762] D loss: 1.4497, G loss: 0.9092\n",
      "[324/1762] D loss: 1.3331, G loss: 0.7231\n",
      "[404/1762] D loss: 1.4298, G loss: 0.7485\n",
      "[484/1762] D loss: 1.3895, G loss: 0.6724\n",
      "[564/1762] D loss: 1.3510, G loss: 0.7530\n",
      "[644/1762] D loss: 1.3917, G loss: 0.6558\n",
      "[724/1762] D loss: 1.3395, G loss: 0.8229\n",
      "[804/1762] D loss: 1.3966, G loss: 0.7684\n",
      "[884/1762] D loss: 1.3565, G loss: 0.7009\n",
      "[964/1762] D loss: 1.3939, G loss: 0.7002\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.6164\n",
      "[1124/1762] D loss: 1.1439, G loss: 0.7184\n",
      "[1204/1762] D loss: 1.1088, G loss: 0.9127\n",
      "[1284/1762] D loss: 1.1286, G loss: 0.9666\n",
      "[1364/1762] D loss: 1.4369, G loss: 0.5694\n",
      "[1444/1762] D loss: 1.4040, G loss: 0.5379\n",
      "[1524/1762] D loss: 1.4377, G loss: 0.8612\n",
      "[1604/1762] D loss: 1.1086, G loss: 1.0391\n",
      "[1684/1762] D loss: 1.4095, G loss: 0.7505\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6887\n",
      "train error: \n",
      " D loss: 1.312492, G loss: 0.747401, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293670, G loss: 0.767280, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3854, G loss: 0.6857\n",
      "[84/1762] D loss: 1.3934, G loss: 0.7361\n",
      "[164/1762] D loss: 1.3907, G loss: 0.7258\n",
      "[244/1762] D loss: 1.1438, G loss: 0.7490\n",
      "[324/1762] D loss: 1.3908, G loss: 0.6954\n",
      "[404/1762] D loss: 1.4066, G loss: 0.8181\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6882\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7014\n",
      "[644/1762] D loss: 1.4052, G loss: 0.7693\n",
      "[724/1762] D loss: 1.3925, G loss: 0.7811\n",
      "[804/1762] D loss: 1.3973, G loss: 0.6775\n",
      "[884/1762] D loss: 1.1129, G loss: 0.8440\n",
      "[964/1762] D loss: 1.3967, G loss: 0.5818\n",
      "[1044/1762] D loss: 1.1235, G loss: 0.8837\n",
      "[1124/1762] D loss: 1.4096, G loss: 0.5819\n",
      "[1204/1762] D loss: 1.4567, G loss: 0.6812\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.6662\n",
      "[1364/1762] D loss: 1.4042, G loss: 0.7976\n",
      "[1444/1762] D loss: 1.1138, G loss: 0.9699\n",
      "[1524/1762] D loss: 1.4062, G loss: 0.8159\n",
      "[1604/1762] D loss: 1.1170, G loss: 1.0179\n",
      "[1684/1762] D loss: 1.4737, G loss: 0.9959\n",
      "[1762/1762] D loss: 0.8378, G loss: 1.1765\n",
      "train error: \n",
      " D loss: 1.311526, G loss: 0.812951, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291465, G loss: 0.838239, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4055, G loss: 0.8100\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6399\n",
      "[164/1762] D loss: 1.3960, G loss: 0.6827\n",
      "[244/1762] D loss: 1.0840, G loss: 0.8903\n",
      "[324/1762] D loss: 1.4277, G loss: 0.7937\n",
      "[404/1762] D loss: 1.3983, G loss: 0.6543\n",
      "[484/1762] D loss: 1.3909, G loss: 0.6935\n",
      "[564/1762] D loss: 1.4201, G loss: 0.5347\n",
      "[644/1762] D loss: 0.8196, G loss: 1.1607\n",
      "[724/1762] D loss: 1.1499, G loss: 1.0169\n",
      "[804/1762] D loss: 1.3883, G loss: 0.7346\n",
      "[884/1762] D loss: 1.1091, G loss: 0.9625\n",
      "[964/1762] D loss: 1.1175, G loss: 0.7890\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.7356\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.7487\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.7200\n",
      "[1284/1762] D loss: 1.3962, G loss: 0.6275\n",
      "[1364/1762] D loss: 1.1522, G loss: 0.7158\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.7073\n",
      "[1524/1762] D loss: 1.3926, G loss: 0.7593\n",
      "[1604/1762] D loss: 1.4117, G loss: 0.5994\n",
      "[1684/1762] D loss: 1.0970, G loss: 0.9669\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.6808\n",
      "train error: \n",
      " D loss: 1.309270, G loss: 0.764436, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287205, G loss: 0.794782, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.7310\n",
      "[84/1762] D loss: 1.3890, G loss: 0.6507\n",
      "[164/1762] D loss: 1.3624, G loss: 0.7622\n",
      "[244/1762] D loss: 1.4003, G loss: 0.5600\n",
      "[324/1762] D loss: 1.3950, G loss: 0.6859\n",
      "[404/1762] D loss: 1.3706, G loss: 0.6995\n",
      "[484/1762] D loss: 1.3894, G loss: 0.6862\n",
      "[564/1762] D loss: 0.7992, G loss: 1.2853\n",
      "[644/1762] D loss: 1.1175, G loss: 0.8042\n",
      "[724/1762] D loss: 1.3403, G loss: 0.6300\n",
      "[804/1762] D loss: 1.3937, G loss: 0.7076\n",
      "[884/1762] D loss: 1.3877, G loss: 0.6702\n",
      "[964/1762] D loss: 1.3898, G loss: 0.6815\n",
      "[1044/1762] D loss: 1.1272, G loss: 0.8869\n",
      "[1124/1762] D loss: 1.1272, G loss: 0.8636\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.6494\n",
      "[1284/1762] D loss: 1.1115, G loss: 0.9710\n",
      "[1364/1762] D loss: 1.1104, G loss: 1.0207\n",
      "[1444/1762] D loss: 1.4023, G loss: 0.7977\n",
      "[1524/1762] D loss: 1.0676, G loss: 1.2340\n",
      "[1604/1762] D loss: 1.2217, G loss: 1.2414\n",
      "[1684/1762] D loss: 1.4697, G loss: 0.6411\n",
      "[1762/1762] D loss: 1.3649, G loss: 0.7446\n",
      "train error: \n",
      " D loss: 1.339988, G loss: 0.764571, D accuracy: 50.8%, cell accuracy: 99.5%, board accuracy: 30.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314569, G loss: 0.799597, D accuracy: 52.8%, cell accuracy: 99.4%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3979, G loss: 0.6882\n",
      "[84/1762] D loss: 1.4330, G loss: 0.8517\n",
      "[164/1762] D loss: 1.4254, G loss: 0.7998\n",
      "[244/1762] D loss: 1.4295, G loss: 0.7901\n",
      "[324/1762] D loss: 1.0613, G loss: 1.1117\n",
      "[404/1762] D loss: 1.4047, G loss: 0.5775\n",
      "[484/1762] D loss: 1.3992, G loss: 0.7291\n",
      "[564/1762] D loss: 1.4063, G loss: 0.7065\n",
      "[644/1762] D loss: 1.3896, G loss: 0.6766\n",
      "[724/1762] D loss: 1.4132, G loss: 0.7814\n",
      "[804/1762] D loss: 1.3979, G loss: 0.7370\n",
      "[884/1762] D loss: 1.4031, G loss: 0.8139\n",
      "[964/1762] D loss: 1.3946, G loss: 0.7233\n",
      "[1044/1762] D loss: 1.1034, G loss: 0.9731\n",
      "[1124/1762] D loss: 1.3553, G loss: 0.8821\n",
      "[1204/1762] D loss: 1.4106, G loss: 0.8171\n",
      "[1284/1762] D loss: 1.1244, G loss: 1.0118\n",
      "[1364/1762] D loss: 1.3947, G loss: 0.8117\n",
      "[1444/1762] D loss: 1.1384, G loss: 0.8076\n",
      "[1524/1762] D loss: 1.1672, G loss: 0.9949\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.6319\n",
      "[1684/1762] D loss: 1.4032, G loss: 0.7966\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.6754\n",
      "train error: \n",
      " D loss: 1.315092, G loss: 0.715870, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293398, G loss: 0.746748, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.6951\n",
      "[84/1762] D loss: 1.1202, G loss: 0.8786\n",
      "[164/1762] D loss: 1.4208, G loss: 0.6038\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6791\n",
      "[324/1762] D loss: 1.3899, G loss: 0.6653\n",
      "[404/1762] D loss: 1.3901, G loss: 0.7125\n",
      "[484/1762] D loss: 1.3893, G loss: 0.6919\n",
      "[564/1762] D loss: 1.3897, G loss: 0.6908\n",
      "[644/1762] D loss: 1.4364, G loss: 0.5994\n",
      "[724/1762] D loss: 1.3927, G loss: 0.6601\n",
      "[804/1762] D loss: 1.3922, G loss: 0.7335\n",
      "[884/1762] D loss: 1.3970, G loss: 0.7623\n",
      "[964/1762] D loss: 1.4233, G loss: 0.7047\n",
      "[1044/1762] D loss: 1.4007, G loss: 0.5511\n",
      "[1124/1762] D loss: 1.4036, G loss: 0.7096\n",
      "[1204/1762] D loss: 1.1125, G loss: 0.9527\n",
      "[1284/1762] D loss: 1.4202, G loss: 0.7394\n",
      "[1364/1762] D loss: 1.4242, G loss: 0.7902\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.6791\n",
      "[1524/1762] D loss: 1.3990, G loss: 0.7161\n",
      "[1604/1762] D loss: 1.1016, G loss: 0.9271\n",
      "[1684/1762] D loss: 1.1037, G loss: 1.0527\n",
      "[1762/1762] D loss: 0.7824, G loss: 1.3420\n",
      "train error: \n",
      " D loss: 1.311597, G loss: 0.792022, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290511, G loss: 0.822188, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7480\n",
      "[84/1762] D loss: 1.3903, G loss: 0.7129\n",
      "[164/1762] D loss: 1.1406, G loss: 0.8051\n",
      "[244/1762] D loss: 1.3949, G loss: 0.6527\n",
      "[324/1762] D loss: 1.1056, G loss: 0.9618\n",
      "[404/1762] D loss: 1.3482, G loss: 0.6850\n",
      "[484/1762] D loss: 1.4123, G loss: 0.6423\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6826\n",
      "[644/1762] D loss: 1.3890, G loss: 0.7562\n",
      "[724/1762] D loss: 1.4063, G loss: 0.8129\n",
      "[804/1762] D loss: 1.3917, G loss: 0.7113\n",
      "[884/1762] D loss: 1.1182, G loss: 0.9415\n",
      "[964/1762] D loss: 0.8179, G loss: 1.0539\n",
      "[1044/1762] D loss: 0.8043, G loss: 1.2550\n",
      "[1124/1762] D loss: 1.4247, G loss: 0.6099\n",
      "[1204/1762] D loss: 1.4092, G loss: 0.6461\n",
      "[1284/1762] D loss: 1.4128, G loss: 0.6978\n",
      "[1364/1762] D loss: 1.3931, G loss: 0.6632\n",
      "[1444/1762] D loss: 1.1139, G loss: 0.8951\n",
      "[1524/1762] D loss: 1.3984, G loss: 0.6135\n",
      "[1604/1762] D loss: 1.4006, G loss: 0.7049\n",
      "[1684/1762] D loss: 1.3938, G loss: 0.7462\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7291\n",
      "train error: \n",
      " D loss: 1.311343, G loss: 0.805102, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289620, G loss: 0.835306, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915, G loss: 0.7694\n",
      "[84/1762] D loss: 1.1263, G loss: 0.9350\n",
      "[164/1762] D loss: 1.0967, G loss: 1.0382\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7025\n",
      "[324/1762] D loss: 1.1151, G loss: 1.1433\n",
      "[404/1762] D loss: 1.3916, G loss: 0.7915\n",
      "[484/1762] D loss: 1.3948, G loss: 0.7123\n",
      "[564/1762] D loss: 1.3934, G loss: 0.6738\n",
      "[644/1762] D loss: 1.3961, G loss: 0.6369\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6926\n",
      "[804/1762] D loss: 1.4201, G loss: 0.7667\n",
      "[884/1762] D loss: 1.3964, G loss: 0.8092\n",
      "[964/1762] D loss: 1.3973, G loss: 0.6045\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.7235\n",
      "[1124/1762] D loss: 1.3951, G loss: 0.7406\n",
      "[1204/1762] D loss: 1.1153, G loss: 0.8932\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.6841\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.6312\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.6985\n",
      "[1524/1762] D loss: 1.3962, G loss: 0.6431\n",
      "[1604/1762] D loss: 1.0994, G loss: 1.0685\n",
      "[1684/1762] D loss: 1.3972, G loss: 0.8032\n",
      "[1762/1762] D loss: 1.3966, G loss: 0.7700\n",
      "train error: \n",
      " D loss: 1.312743, G loss: 0.728354, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290226, G loss: 0.758725, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903, G loss: 0.6923\n",
      "[84/1762] D loss: 1.0912, G loss: 1.0105\n",
      "[164/1762] D loss: 1.4074, G loss: 0.7341\n",
      "[244/1762] D loss: 1.1159, G loss: 0.8763\n",
      "[324/1762] D loss: 1.3921, G loss: 0.7374\n",
      "[404/1762] D loss: 1.4140, G loss: 0.5706\n",
      "[484/1762] D loss: 1.3977, G loss: 0.6948\n",
      "[564/1762] D loss: 1.3908, G loss: 0.7507\n",
      "[644/1762] D loss: 1.4127, G loss: 0.8421\n",
      "[724/1762] D loss: 1.3936, G loss: 0.7805\n",
      "[804/1762] D loss: 1.3941, G loss: 0.6580\n",
      "[884/1762] D loss: 1.4186, G loss: 0.7979\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6960\n",
      "[1044/1762] D loss: 1.3989, G loss: 0.8489\n",
      "[1124/1762] D loss: 1.1022, G loss: 1.0839\n",
      "[1204/1762] D loss: 1.4073, G loss: 0.5899\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.6734\n",
      "[1364/1762] D loss: 1.1046, G loss: 0.8765\n",
      "[1444/1762] D loss: 1.4099, G loss: 0.7902\n",
      "[1524/1762] D loss: 1.3387, G loss: 0.6679\n",
      "[1604/1762] D loss: 1.4176, G loss: 0.7375\n",
      "[1684/1762] D loss: 1.1001, G loss: 0.9739\n",
      "[1762/1762] D loss: 1.4004, G loss: 0.7637\n",
      "train error: \n",
      " D loss: 1.312846, G loss: 0.838275, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291366, G loss: 0.869682, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4445, G loss: 0.8039\n",
      "[84/1762] D loss: 1.5690, G loss: 1.1193\n",
      "[164/1762] D loss: 1.3974, G loss: 0.6222\n",
      "[244/1762] D loss: 1.4016, G loss: 0.6397\n",
      "[324/1762] D loss: 1.3919, G loss: 0.7328\n",
      "[404/1762] D loss: 1.3905, G loss: 0.7447\n",
      "[484/1762] D loss: 1.1605, G loss: 0.8946\n",
      "[564/1762] D loss: 1.3882, G loss: 0.7049\n",
      "[644/1762] D loss: 1.0764, G loss: 1.1069\n",
      "[724/1762] D loss: 1.3932, G loss: 0.7130\n",
      "[804/1762] D loss: 1.1072, G loss: 0.9153\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6940\n",
      "[964/1762] D loss: 1.3942, G loss: 0.7358\n",
      "[1044/1762] D loss: 1.4261, G loss: 0.7028\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7451\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.7469\n",
      "[1284/1762] D loss: 1.3379, G loss: 0.7972\n",
      "[1364/1762] D loss: 1.3936, G loss: 0.7662\n",
      "[1444/1762] D loss: 1.4069, G loss: 0.6754\n",
      "[1524/1762] D loss: 1.1116, G loss: 0.9697\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.7240\n",
      "[1684/1762] D loss: 1.3901, G loss: 0.7508\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.6553\n",
      "train error: \n",
      " D loss: 1.307515, G loss: 0.765731, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287521, G loss: 0.790777, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.6814\n",
      "[84/1762] D loss: 1.3858, G loss: 0.7473\n",
      "[164/1762] D loss: 1.3900, G loss: 0.6763\n",
      "[244/1762] D loss: 1.1080, G loss: 0.9662\n",
      "[324/1762] D loss: 1.3943, G loss: 0.7445\n",
      "[404/1762] D loss: 1.3541, G loss: 0.6684\n",
      "[484/1762] D loss: 1.3772, G loss: 0.6188\n",
      "[564/1762] D loss: 1.3927, G loss: 0.6399\n",
      "[644/1762] D loss: 1.3932, G loss: 0.6980\n",
      "[724/1762] D loss: 1.0751, G loss: 1.0210\n",
      "[804/1762] D loss: 1.3919, G loss: 0.6712\n",
      "[884/1762] D loss: 1.1105, G loss: 0.8703\n",
      "[964/1762] D loss: 1.3893, G loss: 0.7159\n",
      "[1044/1762] D loss: 1.4057, G loss: 0.8319\n",
      "[1124/1762] D loss: 1.4015, G loss: 0.8050\n",
      "[1204/1762] D loss: 1.3889, G loss: 0.7090\n",
      "[1284/1762] D loss: 1.0821, G loss: 0.9817\n",
      "[1364/1762] D loss: 1.2998, G loss: 0.7276\n",
      "[1444/1762] D loss: 1.4014, G loss: 0.7206\n",
      "[1524/1762] D loss: 1.3705, G loss: 0.8335\n",
      "[1604/1762] D loss: 1.3924, G loss: 0.6537\n",
      "[1684/1762] D loss: 1.4012, G loss: 0.8571\n",
      "[1762/1762] D loss: 0.8208, G loss: 1.1733\n",
      "train error: \n",
      " D loss: 1.315865, G loss: 0.872807, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296662, G loss: 0.898853, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4259, G loss: 0.8757\n",
      "[84/1762] D loss: 1.3775, G loss: 0.7696\n",
      "[164/1762] D loss: 1.1050, G loss: 0.9434\n",
      "[244/1762] D loss: 1.3349, G loss: 1.1655\n",
      "[324/1762] D loss: 1.0067, G loss: 0.9935\n",
      "[404/1762] D loss: 1.4244, G loss: 0.7935\n",
      "[484/1762] D loss: 1.4020, G loss: 0.6032\n",
      "[564/1762] D loss: 1.4443, G loss: 0.8999\n",
      "[644/1762] D loss: 1.4010, G loss: 0.8477\n",
      "[724/1762] D loss: 1.1969, G loss: 0.9905\n",
      "[804/1762] D loss: 1.4626, G loss: 0.5378\n",
      "[884/1762] D loss: 1.4143, G loss: 0.5738\n",
      "[964/1762] D loss: 1.1775, G loss: 0.6667\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.6299\n",
      "[1124/1762] D loss: 1.1842, G loss: 0.9115\n",
      "[1204/1762] D loss: 1.4026, G loss: 0.5981\n",
      "[1284/1762] D loss: 1.3261, G loss: 0.7441\n",
      "[1364/1762] D loss: 1.3943, G loss: 0.7498\n",
      "[1444/1762] D loss: 1.1193, G loss: 0.9470\n",
      "[1524/1762] D loss: 1.3970, G loss: 0.6180\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.6937\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.6831\n",
      "[1762/1762] D loss: 1.4058, G loss: 0.6869\n",
      "train error: \n",
      " D loss: 1.318358, G loss: 0.716392, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300124, G loss: 0.734589, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3928, G loss: 0.6391\n",
      "[84/1762] D loss: 1.3976, G loss: 0.7806\n",
      "[164/1762] D loss: 1.3990, G loss: 0.7686\n",
      "[244/1762] D loss: 1.3873, G loss: 0.7377\n",
      "[324/1762] D loss: 1.1131, G loss: 0.8552\n",
      "[404/1762] D loss: 0.8888, G loss: 1.1718\n",
      "[484/1762] D loss: 1.1460, G loss: 0.8562\n",
      "[564/1762] D loss: 1.3956, G loss: 0.6531\n",
      "[644/1762] D loss: 1.3918, G loss: 0.6710\n",
      "[724/1762] D loss: 1.3922, G loss: 0.7461\n",
      "[804/1762] D loss: 1.4029, G loss: 0.6272\n",
      "[884/1762] D loss: 1.4075, G loss: 0.6562\n",
      "[964/1762] D loss: 1.4066, G loss: 0.8297\n",
      "[1044/1762] D loss: 1.4058, G loss: 0.6249\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.7174\n",
      "[1204/1762] D loss: 0.8407, G loss: 1.2544\n",
      "[1284/1762] D loss: 1.3971, G loss: 0.6294\n",
      "[1364/1762] D loss: 1.1511, G loss: 0.7483\n",
      "[1444/1762] D loss: 1.1257, G loss: 0.8276\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.7451\n",
      "[1604/1762] D loss: 1.1167, G loss: 0.8167\n",
      "[1684/1762] D loss: 1.3943, G loss: 0.7063\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6640\n",
      "train error: \n",
      " D loss: 1.310850, G loss: 0.768104, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291355, G loss: 0.788867, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6885\n",
      "[84/1762] D loss: 1.1349, G loss: 0.9022\n",
      "[164/1762] D loss: 1.4107, G loss: 0.6361\n",
      "[244/1762] D loss: 1.3908, G loss: 0.6323\n",
      "[324/1762] D loss: 1.4012, G loss: 0.7614\n",
      "[404/1762] D loss: 1.3929, G loss: 0.7463\n",
      "[484/1762] D loss: 1.3917, G loss: 0.7822\n",
      "[564/1762] D loss: 1.1321, G loss: 0.7796\n",
      "[644/1762] D loss: 1.4042, G loss: 0.7548\n",
      "[724/1762] D loss: 1.3960, G loss: 0.6844\n",
      "[804/1762] D loss: 1.4182, G loss: 0.8276\n",
      "[884/1762] D loss: 1.4004, G loss: 0.8345\n",
      "[964/1762] D loss: 1.3915, G loss: 0.7587\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7438\n",
      "[1124/1762] D loss: 1.4020, G loss: 0.5920\n",
      "[1204/1762] D loss: 1.1003, G loss: 0.8946\n",
      "[1284/1762] D loss: 1.3990, G loss: 0.7318\n",
      "[1364/1762] D loss: 1.3928, G loss: 0.7705\n",
      "[1444/1762] D loss: 1.3933, G loss: 0.7599\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.6837\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6557\n",
      "[1684/1762] D loss: 1.1056, G loss: 0.9898\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.7551\n",
      "train error: \n",
      " D loss: 1.309543, G loss: 0.762566, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288280, G loss: 0.788819, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905, G loss: 0.6918\n",
      "[84/1762] D loss: 1.4017, G loss: 0.5786\n",
      "[164/1762] D loss: 1.0938, G loss: 0.9902\n",
      "[244/1762] D loss: 1.3995, G loss: 0.6190\n",
      "[324/1762] D loss: 1.4126, G loss: 0.8240\n",
      "[404/1762] D loss: 1.3890, G loss: 0.7044\n",
      "[484/1762] D loss: 1.1209, G loss: 1.0659\n",
      "[564/1762] D loss: 1.0897, G loss: 1.0097\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6900\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6841\n",
      "[804/1762] D loss: 1.4257, G loss: 0.7186\n",
      "[884/1762] D loss: 1.3796, G loss: 0.6612\n",
      "[964/1762] D loss: 1.3860, G loss: 0.6881\n",
      "[1044/1762] D loss: 1.0929, G loss: 1.0062\n",
      "[1124/1762] D loss: 1.1041, G loss: 0.9029\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.6508\n",
      "[1284/1762] D loss: 1.1543, G loss: 0.8242\n",
      "[1364/1762] D loss: 1.4468, G loss: 0.8206\n",
      "[1444/1762] D loss: 0.8061, G loss: 1.1657\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.7107\n",
      "[1604/1762] D loss: 1.3983, G loss: 0.8646\n",
      "[1684/1762] D loss: 1.4047, G loss: 0.7331\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7588\n",
      "train error: \n",
      " D loss: 1.317165, G loss: 0.893002, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296360, G loss: 0.916357, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005, G loss: 0.8080\n",
      "[84/1762] D loss: 1.3969, G loss: 0.6530\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6948\n",
      "[244/1762] D loss: 1.4105, G loss: 0.7629\n",
      "[324/1762] D loss: 0.5159, G loss: 1.4939\n",
      "[404/1762] D loss: 1.3888, G loss: 0.7424\n",
      "[484/1762] D loss: 1.1131, G loss: 0.8761\n",
      "[564/1762] D loss: 0.8149, G loss: 1.1273\n",
      "[644/1762] D loss: 1.4403, G loss: 0.9291\n",
      "[724/1762] D loss: 1.4110, G loss: 0.8075\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6606\n",
      "[884/1762] D loss: 1.4017, G loss: 0.7658\n",
      "[964/1762] D loss: 1.4098, G loss: 0.6330\n",
      "[1044/1762] D loss: 1.3362, G loss: 0.7875\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6999\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.7595\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6599\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6609\n",
      "[1444/1762] D loss: 1.3798, G loss: 0.5531\n",
      "[1524/1762] D loss: 1.3696, G loss: 0.6779\n",
      "[1604/1762] D loss: 1.3743, G loss: 0.6014\n",
      "[1684/1762] D loss: 1.0874, G loss: 0.9596\n",
      "[1762/1762] D loss: 1.4039, G loss: 0.7811\n",
      "train error: \n",
      " D loss: 1.308695, G loss: 0.770900, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288011, G loss: 0.794158, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0773, G loss: 1.0430\n",
      "[84/1762] D loss: 1.3965, G loss: 0.7268\n",
      "[164/1762] D loss: 1.1065, G loss: 0.9953\n",
      "[244/1762] D loss: 1.3979, G loss: 0.6935\n",
      "[324/1762] D loss: 1.3895, G loss: 0.7135\n",
      "[404/1762] D loss: 1.4034, G loss: 0.6022\n",
      "[484/1762] D loss: 1.1112, G loss: 0.8491\n",
      "[564/1762] D loss: 1.4527, G loss: 0.8846\n",
      "[644/1762] D loss: 1.3257, G loss: 0.6374\n",
      "[724/1762] D loss: 1.4037, G loss: 0.7345\n",
      "[804/1762] D loss: 1.4494, G loss: 0.6862\n",
      "[884/1762] D loss: 1.3883, G loss: 0.7292\n",
      "[964/1762] D loss: 1.3912, G loss: 0.7551\n",
      "[1044/1762] D loss: 1.4029, G loss: 0.6129\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.6238\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7131\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.6617\n",
      "[1364/1762] D loss: 1.3372, G loss: 0.6831\n",
      "[1444/1762] D loss: 0.9675, G loss: 1.1350\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.7580\n",
      "[1604/1762] D loss: 1.1406, G loss: 0.8438\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.5964\n",
      "[1762/1762] D loss: 1.3999, G loss: 0.6332\n",
      "train error: \n",
      " D loss: 1.313689, G loss: 0.769445, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293493, G loss: 0.789708, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.6192\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6232\n",
      "[164/1762] D loss: 1.3810, G loss: 0.6276\n",
      "[244/1762] D loss: 1.3700, G loss: 0.6324\n",
      "[324/1762] D loss: 1.3489, G loss: 0.6418\n",
      "[404/1762] D loss: 1.3204, G loss: 0.6597\n",
      "[484/1762] D loss: 1.2632, G loss: 0.6868\n",
      "[564/1762] D loss: 1.1012, G loss: 0.7849\n",
      "[644/1762] D loss: 0.8967, G loss: 0.9073\n",
      "[724/1762] D loss: 0.5691, G loss: 1.3806\n",
      "[804/1762] D loss: 0.4289, G loss: 2.1435\n",
      "[884/1762] D loss: 0.2063, G loss: 2.5459\n",
      "[964/1762] D loss: 0.2355, G loss: 3.2593\n",
      "[1044/1762] D loss: 0.3714, G loss: 3.8847\n",
      "[1124/1762] D loss: 0.1033, G loss: 3.8190\n",
      "[1204/1762] D loss: 0.1268, G loss: 4.1230\n",
      "[1284/1762] D loss: 0.1166, G loss: 4.5982\n",
      "[1364/1762] D loss: 0.0539, G loss: 4.3762\n",
      "[1444/1762] D loss: 0.0543, G loss: 4.9904\n",
      "[1524/1762] D loss: 0.0724, G loss: 5.2174\n",
      "[1604/1762] D loss: 0.0739, G loss: 5.3090\n",
      "[1684/1762] D loss: 0.1668, G loss: 5.4356\n",
      "[1762/1762] D loss: 0.2242, G loss: 4.9319\n",
      "train error: \n",
      " D loss: 0.227614, G loss: 4.568867, D accuracy: 97.6%, cell accuracy: 58.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.239437, G loss: 4.559057, D accuracy: 96.9%, cell accuracy: 58.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4131, G loss: 6.3542\n",
      "[84/1762] D loss: 0.1772, G loss: 6.0025\n",
      "[164/1762] D loss: 0.1583, G loss: 5.7823\n",
      "[244/1762] D loss: 0.0735, G loss: 6.0831\n",
      "[324/1762] D loss: 0.1703, G loss: 6.4623\n",
      "[404/1762] D loss: 0.2488, G loss: 5.9517\n",
      "[484/1762] D loss: 0.0551, G loss: 6.5519\n",
      "[564/1762] D loss: 0.0309, G loss: 6.7537\n",
      "[644/1762] D loss: 0.1510, G loss: 6.9452\n",
      "[724/1762] D loss: 0.1330, G loss: 6.8566\n",
      "[804/1762] D loss: 0.0240, G loss: 6.9220\n",
      "[884/1762] D loss: 0.1683, G loss: 7.3791\n",
      "[964/1762] D loss: 0.3063, G loss: 6.7766\n",
      "[1044/1762] D loss: 0.0148, G loss: 6.8232\n",
      "[1124/1762] D loss: 0.5669, G loss: 6.9604\n",
      "[1204/1762] D loss: 0.0238, G loss: 6.5596\n",
      "[1284/1762] D loss: 0.2790, G loss: 7.9306\n",
      "[1364/1762] D loss: 0.0606, G loss: 6.5951\n",
      "[1444/1762] D loss: 0.0904, G loss: 7.5524\n",
      "[1524/1762] D loss: 0.1280, G loss: 6.1605\n",
      "[1604/1762] D loss: 0.1978, G loss: 7.0616\n",
      "[1684/1762] D loss: 0.0718, G loss: 6.5506\n",
      "[1762/1762] D loss: 0.5786, G loss: 7.1251\n",
      "train error: \n",
      " D loss: 0.187248, G loss: 5.637256, D accuracy: 97.9%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.172109, G loss: 5.812715, D accuracy: 98.9%, cell accuracy: 92.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0311, G loss: 6.5819\n",
      "[84/1762] D loss: 0.2004, G loss: 7.8732\n",
      "[164/1762] D loss: 0.4516, G loss: 5.9106\n",
      "[244/1762] D loss: 0.2597, G loss: 6.5086\n",
      "[324/1762] D loss: 0.0958, G loss: 6.0587\n",
      "[404/1762] D loss: 0.1870, G loss: 6.2431\n",
      "[484/1762] D loss: 0.4541, G loss: 6.1544\n",
      "[564/1762] D loss: 0.3440, G loss: 6.6417\n",
      "[644/1762] D loss: 0.2993, G loss: 6.9614\n",
      "[724/1762] D loss: 0.3220, G loss: 7.2234\n",
      "[804/1762] D loss: 0.2252, G loss: 6.2984\n",
      "[884/1762] D loss: 0.2308, G loss: 6.6169\n",
      "[964/1762] D loss: 0.1727, G loss: 5.8474\n",
      "[1044/1762] D loss: 0.2491, G loss: 6.0541\n",
      "[1124/1762] D loss: 0.1276, G loss: 5.9075\n",
      "[1204/1762] D loss: 0.0937, G loss: 5.6548\n",
      "[1284/1762] D loss: 0.1785, G loss: 6.0646\n",
      "[1364/1762] D loss: 0.3352, G loss: 6.1195\n",
      "[1444/1762] D loss: 0.0689, G loss: 6.2438\n",
      "[1524/1762] D loss: 0.5140, G loss: 6.1587\n",
      "[1604/1762] D loss: 0.3518, G loss: 5.3066\n",
      "[1684/1762] D loss: 0.4080, G loss: 5.1561\n",
      "[1762/1762] D loss: 0.1011, G loss: 6.5964\n",
      "train error: \n",
      " D loss: 0.178809, G loss: 6.423341, D accuracy: 99.3%, cell accuracy: 89.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.173238, G loss: 6.953788, D accuracy: 99.1%, cell accuracy: 88.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1795, G loss: 6.0732\n",
      "[84/1762] D loss: 0.1577, G loss: 4.9670\n",
      "[164/1762] D loss: 0.2004, G loss: 6.5137\n",
      "[244/1762] D loss: 0.2490, G loss: 5.8274\n",
      "[324/1762] D loss: 0.1015, G loss: 5.2706\n",
      "[404/1762] D loss: 0.0906, G loss: 5.3914\n",
      "[484/1762] D loss: 0.0651, G loss: 4.6441\n",
      "[564/1762] D loss: 0.1638, G loss: 2.8228\n",
      "[644/1762] D loss: 0.0573, G loss: 3.6400\n",
      "[724/1762] D loss: 0.0901, G loss: 2.7242\n",
      "[804/1762] D loss: 0.0929, G loss: 3.7935\n",
      "[884/1762] D loss: 0.2519, G loss: 2.4297\n",
      "[964/1762] D loss: 0.4626, G loss: 2.6208\n",
      "[1044/1762] D loss: 0.0910, G loss: 2.6643\n",
      "[1124/1762] D loss: 0.3835, G loss: 3.0104\n",
      "[1204/1762] D loss: 0.7202, G loss: 2.0792\n",
      "[1284/1762] D loss: 0.2076, G loss: 2.7089\n",
      "[1364/1762] D loss: 0.2369, G loss: 1.4971\n",
      "[1444/1762] D loss: 0.1761, G loss: 4.6412\n",
      "[1524/1762] D loss: 0.5368, G loss: 1.4015\n",
      "[1604/1762] D loss: 0.1765, G loss: 3.2021\n",
      "[1684/1762] D loss: 0.4915, G loss: 3.3088\n",
      "[1762/1762] D loss: 0.0383, G loss: 2.7054\n",
      "train error: \n",
      " D loss: 0.859919, G loss: 1.080976, D accuracy: 79.4%, cell accuracy: 97.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.789228, G loss: 1.157826, D accuracy: 80.6%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5215, G loss: 1.1084\n",
      "[84/1762] D loss: 0.1417, G loss: 2.8024\n",
      "[164/1762] D loss: 0.3214, G loss: 1.5703\n",
      "[244/1762] D loss: 0.2847, G loss: 3.1890\n",
      "[324/1762] D loss: 1.2629, G loss: 1.6624\n",
      "[404/1762] D loss: 0.5142, G loss: 3.7588\n",
      "[484/1762] D loss: 1.3629, G loss: 1.3602\n",
      "[564/1762] D loss: 1.0605, G loss: 5.2153\n",
      "[644/1762] D loss: 0.3187, G loss: 4.1687\n",
      "[724/1762] D loss: 0.4516, G loss: 1.6577\n",
      "[804/1762] D loss: 0.7909, G loss: 2.1490\n",
      "[884/1762] D loss: 1.0844, G loss: 1.1895\n",
      "[964/1762] D loss: 0.7065, G loss: 1.5633\n",
      "[1044/1762] D loss: 0.5717, G loss: 1.9263\n",
      "[1124/1762] D loss: 0.6021, G loss: 2.4362\n",
      "[1204/1762] D loss: 0.5610, G loss: 1.7082\n",
      "[1284/1762] D loss: 0.8822, G loss: 1.2598\n",
      "[1364/1762] D loss: 0.7304, G loss: 2.1220\n",
      "[1444/1762] D loss: 0.3477, G loss: 2.1077\n",
      "[1524/1762] D loss: 0.5798, G loss: 1.2510\n",
      "[1604/1762] D loss: 0.3520, G loss: 2.1267\n",
      "[1684/1762] D loss: 0.3858, G loss: 3.0628\n",
      "[1762/1762] D loss: 1.3241, G loss: 2.3766\n",
      "train error: \n",
      " D loss: 0.623451, G loss: 2.155619, D accuracy: 86.1%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626330, G loss: 2.197319, D accuracy: 86.8%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5678, G loss: 1.2884\n",
      "[84/1762] D loss: 0.6436, G loss: 1.9168\n",
      "[164/1762] D loss: 0.8986, G loss: 1.2616\n",
      "[244/1762] D loss: 0.4500, G loss: 1.4404\n",
      "[324/1762] D loss: 0.8361, G loss: 1.0524\n",
      "[404/1762] D loss: 1.0483, G loss: 1.3298\n",
      "[484/1762] D loss: 1.0212, G loss: 2.0480\n",
      "[564/1762] D loss: 0.4726, G loss: 2.6555\n",
      "[644/1762] D loss: 0.7605, G loss: 1.9353\n",
      "[724/1762] D loss: 0.3623, G loss: 3.4286\n",
      "[804/1762] D loss: 1.3563, G loss: 1.8711\n",
      "[884/1762] D loss: 0.1328, G loss: 4.0146\n",
      "[964/1762] D loss: 1.7512, G loss: 1.1198\n",
      "[1044/1762] D loss: 0.6789, G loss: 1.6401\n",
      "[1124/1762] D loss: 0.8305, G loss: 0.7798\n",
      "[1204/1762] D loss: 0.7202, G loss: 1.7272\n",
      "[1284/1762] D loss: 0.2814, G loss: 2.6060\n",
      "[1364/1762] D loss: 0.1787, G loss: 2.4151\n",
      "[1444/1762] D loss: 1.3925, G loss: 1.4147\n",
      "[1524/1762] D loss: 0.6657, G loss: 1.0173\n",
      "[1604/1762] D loss: 0.6855, G loss: 1.9601\n",
      "[1684/1762] D loss: 0.7215, G loss: 1.7205\n",
      "[1762/1762] D loss: 0.2373, G loss: 3.4042\n",
      "train error: \n",
      " D loss: 0.809807, G loss: 2.741414, D accuracy: 80.2%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.832182, G loss: 2.758599, D accuracy: 80.5%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4809, G loss: 2.1276\n",
      "[84/1762] D loss: 0.4092, G loss: 1.8757\n",
      "[164/1762] D loss: 0.7468, G loss: 2.3636\n",
      "[244/1762] D loss: 0.9281, G loss: 3.2367\n",
      "[324/1762] D loss: 0.2970, G loss: 3.3167\n",
      "[404/1762] D loss: 0.8498, G loss: 1.0775\n",
      "[484/1762] D loss: 1.2411, G loss: 1.0410\n",
      "[564/1762] D loss: 1.1117, G loss: 0.7957\n",
      "[644/1762] D loss: 0.6707, G loss: 1.4864\n",
      "[724/1762] D loss: 1.0046, G loss: 3.6974\n",
      "[804/1762] D loss: 0.8841, G loss: 1.7767\n",
      "[884/1762] D loss: 0.3690, G loss: 3.5153\n",
      "[964/1762] D loss: 1.0438, G loss: 1.5453\n",
      "[1044/1762] D loss: 0.7079, G loss: 1.6328\n",
      "[1124/1762] D loss: 0.6240, G loss: 1.2156\n",
      "[1204/1762] D loss: 1.0442, G loss: 2.1337\n",
      "[1284/1762] D loss: 0.5102, G loss: 2.7908\n",
      "[1364/1762] D loss: 0.7856, G loss: 1.5419\n",
      "[1444/1762] D loss: 0.3868, G loss: 1.6711\n",
      "[1524/1762] D loss: 0.5376, G loss: 1.6060\n",
      "[1604/1762] D loss: 0.1230, G loss: 2.3933\n",
      "[1684/1762] D loss: 1.0315, G loss: 1.7180\n",
      "[1762/1762] D loss: 0.2781, G loss: 3.5148\n",
      "train error: \n",
      " D loss: 0.750177, G loss: 3.030824, D accuracy: 82.8%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.787150, G loss: 3.017687, D accuracy: 82.4%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5016, G loss: 2.6578\n",
      "[84/1762] D loss: 0.6776, G loss: 2.2147\n",
      "[164/1762] D loss: 0.6188, G loss: 2.3211\n",
      "[244/1762] D loss: 0.5533, G loss: 2.6851\n",
      "[324/1762] D loss: 0.9134, G loss: 1.3751\n",
      "[404/1762] D loss: 0.6567, G loss: 2.2187\n",
      "[484/1762] D loss: 0.7502, G loss: 1.1274\n",
      "[564/1762] D loss: 0.2838, G loss: 2.7572\n",
      "[644/1762] D loss: 0.5259, G loss: 2.4177\n",
      "[724/1762] D loss: 0.7036, G loss: 1.0791\n",
      "[804/1762] D loss: 0.3520, G loss: 1.8220\n",
      "[884/1762] D loss: 1.6689, G loss: 1.0861\n",
      "[964/1762] D loss: 0.3807, G loss: 1.7374\n",
      "[1044/1762] D loss: 1.2864, G loss: 1.2049\n",
      "[1124/1762] D loss: 0.6218, G loss: 2.1551\n",
      "[1204/1762] D loss: 1.2746, G loss: 2.0550\n",
      "[1284/1762] D loss: 0.7786, G loss: 2.8858\n",
      "[1364/1762] D loss: 1.1363, G loss: 1.7992\n",
      "[1444/1762] D loss: 0.8952, G loss: 1.7145\n",
      "[1524/1762] D loss: 0.1844, G loss: 2.2881\n",
      "[1604/1762] D loss: 0.5972, G loss: 2.0103\n",
      "[1684/1762] D loss: 0.3433, G loss: 1.9925\n",
      "[1762/1762] D loss: 0.1425, G loss: 2.1525\n",
      "train error: \n",
      " D loss: 0.762958, G loss: 1.315497, D accuracy: 83.6%, cell accuracy: 98.1%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.783595, G loss: 1.283075, D accuracy: 84.0%, cell accuracy: 98.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7236, G loss: 1.3280\n",
      "[84/1762] D loss: 0.7528, G loss: 1.5459\n",
      "[164/1762] D loss: 0.7296, G loss: 1.5778\n",
      "[244/1762] D loss: 0.2656, G loss: 1.1708\n",
      "[324/1762] D loss: 1.4122, G loss: 0.7079\n",
      "[404/1762] D loss: 0.6061, G loss: 2.8423\n",
      "[484/1762] D loss: 0.5576, G loss: 1.4897\n",
      "[564/1762] D loss: 1.0010, G loss: 1.3189\n",
      "[644/1762] D loss: 0.5475, G loss: 2.1706\n",
      "[724/1762] D loss: 0.6726, G loss: 2.1379\n",
      "[804/1762] D loss: 0.9811, G loss: 1.3649\n",
      "[884/1762] D loss: 0.6022, G loss: 1.1667\n",
      "[964/1762] D loss: 0.0836, G loss: 2.8355\n",
      "[1044/1762] D loss: 1.0457, G loss: 0.9259\n",
      "[1124/1762] D loss: 0.7945, G loss: 1.1672\n",
      "[1204/1762] D loss: 0.2685, G loss: 1.7916\n",
      "[1284/1762] D loss: 0.4457, G loss: 2.1061\n",
      "[1364/1762] D loss: 0.2535, G loss: 2.0501\n",
      "[1444/1762] D loss: 1.1289, G loss: 1.6991\n",
      "[1524/1762] D loss: 0.1820, G loss: 3.0395\n",
      "[1604/1762] D loss: 0.1729, G loss: 2.3686\n",
      "[1684/1762] D loss: 0.5075, G loss: 3.2590\n",
      "[1762/1762] D loss: 1.4126, G loss: 1.8596\n",
      "train error: \n",
      " D loss: 0.632602, G loss: 1.921770, D accuracy: 86.9%, cell accuracy: 98.1%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.652708, G loss: 1.886177, D accuracy: 86.5%, cell accuracy: 98.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2189, G loss: 2.1183\n",
      "[84/1762] D loss: 0.3642, G loss: 2.4010\n",
      "[164/1762] D loss: 0.9721, G loss: 2.3791\n",
      "[244/1762] D loss: 0.7456, G loss: 1.5279\n",
      "[324/1762] D loss: 1.3360, G loss: 1.7756\n",
      "[404/1762] D loss: 0.5004, G loss: 1.8969\n",
      "[484/1762] D loss: 0.3077, G loss: 2.4449\n",
      "[564/1762] D loss: 0.5046, G loss: 1.6285\n",
      "[644/1762] D loss: 0.4744, G loss: 1.8152\n",
      "[724/1762] D loss: 0.6380, G loss: 2.8796\n",
      "[804/1762] D loss: 0.5152, G loss: 1.8539\n",
      "[884/1762] D loss: 0.5374, G loss: 1.8425\n",
      "[964/1762] D loss: 0.3292, G loss: 2.3904\n",
      "[1044/1762] D loss: 0.3748, G loss: 1.9302\n",
      "[1124/1762] D loss: 0.8017, G loss: 1.2863\n",
      "[1204/1762] D loss: 0.7281, G loss: 2.3592\n",
      "[1284/1762] D loss: 1.3951, G loss: 1.4045\n",
      "[1364/1762] D loss: 0.6076, G loss: 2.6981\n",
      "[1444/1762] D loss: 0.1921, G loss: 2.1858\n",
      "[1524/1762] D loss: 1.2000, G loss: 2.1804\n",
      "[1604/1762] D loss: 0.1692, G loss: 4.3339\n",
      "[1684/1762] D loss: 0.2928, G loss: 1.9781\n",
      "[1762/1762] D loss: 0.8627, G loss: 2.0105\n",
      "train error: \n",
      " D loss: 0.562236, G loss: 2.306797, D accuracy: 89.4%, cell accuracy: 98.1%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.600547, G loss: 2.257062, D accuracy: 88.6%, cell accuracy: 98.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2550, G loss: 2.0486\n",
      "[84/1762] D loss: 0.1244, G loss: 2.1280\n",
      "[164/1762] D loss: 0.9496, G loss: 1.6184\n",
      "[244/1762] D loss: 0.6446, G loss: 2.7278\n",
      "[324/1762] D loss: 0.1010, G loss: 3.4737\n",
      "[404/1762] D loss: 0.9259, G loss: 1.1613\n",
      "[484/1762] D loss: 0.0861, G loss: 3.6328\n",
      "[564/1762] D loss: 0.6433, G loss: 1.4632\n",
      "[644/1762] D loss: 1.2823, G loss: 0.8753\n",
      "[724/1762] D loss: 0.2149, G loss: 4.0898\n",
      "[804/1762] D loss: 0.3638, G loss: 2.4333\n",
      "[884/1762] D loss: 0.1949, G loss: 1.4962\n",
      "[964/1762] D loss: 1.4117, G loss: 2.1048\n",
      "[1044/1762] D loss: 0.3873, G loss: 2.3689\n",
      "[1124/1762] D loss: 0.9680, G loss: 2.5934\n",
      "[1204/1762] D loss: 1.1014, G loss: 2.4008\n",
      "[1284/1762] D loss: 1.0449, G loss: 2.5215\n",
      "[1364/1762] D loss: 0.6626, G loss: 2.0413\n",
      "[1444/1762] D loss: 1.6014, G loss: 0.9515\n",
      "[1524/1762] D loss: 0.5935, G loss: 1.3820\n",
      "[1604/1762] D loss: 0.9768, G loss: 1.3073\n",
      "[1684/1762] D loss: 1.4330, G loss: 3.4686\n",
      "[1762/1762] D loss: 0.9720, G loss: 0.8044\n",
      "train error: \n",
      " D loss: 0.827666, G loss: 1.675298, D accuracy: 81.4%, cell accuracy: 98.1%, board accuracy: 1.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.868014, G loss: 1.670380, D accuracy: 80.7%, cell accuracy: 98.0%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6336, G loss: 1.9771\n",
      "[84/1762] D loss: 1.1698, G loss: 2.7192\n",
      "[164/1762] D loss: 1.2780, G loss: 1.1343\n",
      "[244/1762] D loss: 0.7339, G loss: 1.4022\n",
      "[324/1762] D loss: 0.6410, G loss: 1.4946\n",
      "[404/1762] D loss: 2.0477, G loss: 1.0787\n",
      "[484/1762] D loss: 2.0583, G loss: 1.4145\n",
      "[564/1762] D loss: 2.8172, G loss: 0.4494\n",
      "[644/1762] D loss: 2.9038, G loss: 0.5724\n",
      "[724/1762] D loss: 2.7232, G loss: 0.5096\n",
      "[804/1762] D loss: 1.6381, G loss: 0.4919\n",
      "[884/1762] D loss: 1.3354, G loss: 0.9825\n",
      "[964/1762] D loss: 2.1850, G loss: 0.5586\n",
      "[1044/1762] D loss: 1.9105, G loss: 0.5692\n",
      "[1124/1762] D loss: 1.7030, G loss: 0.6396\n",
      "[1204/1762] D loss: 1.5858, G loss: 0.7776\n",
      "[1284/1762] D loss: 1.6371, G loss: 0.8082\n",
      "[1364/1762] D loss: 1.5154, G loss: 0.6277\n",
      "[1444/1762] D loss: 1.3830, G loss: 0.8054\n",
      "[1524/1762] D loss: 1.5488, G loss: 0.4354\n",
      "[1604/1762] D loss: 1.2449, G loss: 0.9088\n",
      "[1684/1762] D loss: 1.6861, G loss: 0.7062\n",
      "[1762/1762] D loss: 1.5173, G loss: 0.6815\n",
      "train error: \n",
      " D loss: 1.383425, G loss: 0.696486, D accuracy: 60.1%, cell accuracy: 98.2%, board accuracy: 11.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389581, G loss: 0.666958, D accuracy: 59.5%, cell accuracy: 98.1%, board accuracy: 11.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3308, G loss: 0.5926\n",
      "[84/1762] D loss: 1.2769, G loss: 1.2210\n",
      "[164/1762] D loss: 1.4237, G loss: 0.8171\n",
      "[244/1762] D loss: 1.3495, G loss: 1.4415\n",
      "[324/1762] D loss: 1.3734, G loss: 0.9127\n",
      "[404/1762] D loss: 1.2746, G loss: 0.6273\n",
      "[484/1762] D loss: 1.5233, G loss: 1.0169\n",
      "[564/1762] D loss: 1.3331, G loss: 0.5711\n",
      "[644/1762] D loss: 1.1992, G loss: 0.8153\n",
      "[724/1762] D loss: 1.7330, G loss: 0.6093\n",
      "[804/1762] D loss: 1.3635, G loss: 0.6481\n",
      "[884/1762] D loss: 1.4452, G loss: 0.8677\n",
      "[964/1762] D loss: 1.4175, G loss: 0.4783\n",
      "[1044/1762] D loss: 1.3237, G loss: 0.9211\n",
      "[1124/1762] D loss: 1.7420, G loss: 0.6053\n",
      "[1204/1762] D loss: 1.3297, G loss: 0.8421\n",
      "[1284/1762] D loss: 1.2648, G loss: 0.6138\n",
      "[1364/1762] D loss: 1.3662, G loss: 1.0091\n",
      "[1444/1762] D loss: 1.3511, G loss: 0.5628\n",
      "[1524/1762] D loss: 1.2640, G loss: 1.1498\n",
      "[1604/1762] D loss: 1.2394, G loss: 0.7680\n",
      "[1684/1762] D loss: 1.3412, G loss: 1.1889\n",
      "[1762/1762] D loss: 1.2666, G loss: 0.8486\n",
      "train error: \n",
      " D loss: 1.359925, G loss: 0.760955, D accuracy: 59.1%, cell accuracy: 98.7%, board accuracy: 11.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369867, G loss: 0.747841, D accuracy: 58.1%, cell accuracy: 98.6%, board accuracy: 11.8% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3137, G loss: 0.7636\n",
      "[84/1762] D loss: 1.3860, G loss: 0.7903\n",
      "[164/1762] D loss: 1.4900, G loss: 0.4065\n",
      "[244/1762] D loss: 1.1972, G loss: 0.9013\n",
      "[324/1762] D loss: 1.3973, G loss: 0.6974\n",
      "[404/1762] D loss: 1.2985, G loss: 0.8046\n",
      "[484/1762] D loss: 1.4202, G loss: 0.9788\n",
      "[564/1762] D loss: 1.2264, G loss: 0.7777\n",
      "[644/1762] D loss: 1.4303, G loss: 0.6589\n",
      "[724/1762] D loss: 1.3026, G loss: 1.0041\n",
      "[804/1762] D loss: 1.3685, G loss: 0.7153\n",
      "[884/1762] D loss: 1.4102, G loss: 0.9246\n",
      "[964/1762] D loss: 1.2816, G loss: 0.9187\n",
      "[1044/1762] D loss: 1.3606, G loss: 0.5801\n",
      "[1124/1762] D loss: 1.4381, G loss: 0.9490\n",
      "[1204/1762] D loss: 1.3013, G loss: 0.7856\n",
      "[1284/1762] D loss: 1.3242, G loss: 0.7907\n",
      "[1364/1762] D loss: 1.2958, G loss: 0.6928\n",
      "[1444/1762] D loss: 1.4094, G loss: 0.6887\n",
      "[1524/1762] D loss: 1.1573, G loss: 0.9262\n",
      "[1604/1762] D loss: 1.2378, G loss: 0.8116\n",
      "[1684/1762] D loss: 1.3423, G loss: 1.1854\n",
      "[1762/1762] D loss: 1.2136, G loss: 0.7747\n",
      "train error: \n",
      " D loss: 1.375366, G loss: 0.616545, D accuracy: 56.5%, cell accuracy: 99.2%, board accuracy: 21.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379481, G loss: 0.605077, D accuracy: 56.4%, cell accuracy: 99.1%, board accuracy: 20.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5230, G loss: 0.7272\n",
      "[84/1762] D loss: 1.0752, G loss: 0.8125\n",
      "[164/1762] D loss: 1.3526, G loss: 0.7059\n",
      "[244/1762] D loss: 1.2658, G loss: 0.6417\n",
      "[324/1762] D loss: 1.4046, G loss: 0.8273\n",
      "[404/1762] D loss: 1.2384, G loss: 1.3748\n",
      "[484/1762] D loss: 1.2680, G loss: 0.8114\n",
      "[564/1762] D loss: 1.4950, G loss: 0.7194\n",
      "[644/1762] D loss: 1.3420, G loss: 0.8269\n",
      "[724/1762] D loss: 1.2024, G loss: 0.8423\n",
      "[804/1762] D loss: 1.3009, G loss: 0.6482\n",
      "[884/1762] D loss: 1.3651, G loss: 0.7078\n",
      "[964/1762] D loss: 1.2495, G loss: 0.9138\n",
      "[1044/1762] D loss: 1.3006, G loss: 0.7038\n",
      "[1124/1762] D loss: 1.4447, G loss: 0.7282\n",
      "[1204/1762] D loss: 1.3186, G loss: 0.7565\n",
      "[1284/1762] D loss: 1.4433, G loss: 0.5456\n",
      "[1364/1762] D loss: 1.5393, G loss: 0.6214\n",
      "[1444/1762] D loss: 1.3313, G loss: 0.8017\n",
      "[1524/1762] D loss: 1.4377, G loss: 0.7105\n",
      "[1604/1762] D loss: 1.3598, G loss: 0.6935\n",
      "[1684/1762] D loss: 1.2784, G loss: 0.7435\n",
      "[1762/1762] D loss: 1.3354, G loss: 0.8768\n",
      "train error: \n",
      " D loss: 1.381494, G loss: 0.684336, D accuracy: 54.1%, cell accuracy: 99.5%, board accuracy: 45.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387854, G loss: 0.664361, D accuracy: 52.3%, cell accuracy: 99.4%, board accuracy: 42.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3681, G loss: 0.6795\n",
      "[84/1762] D loss: 1.3683, G loss: 0.6579\n",
      "[164/1762] D loss: 1.5242, G loss: 0.4862\n",
      "[244/1762] D loss: 1.3662, G loss: 1.0294\n",
      "[324/1762] D loss: 1.3984, G loss: 0.7235\n",
      "[404/1762] D loss: 1.2479, G loss: 0.9094\n",
      "[484/1762] D loss: 1.4209, G loss: 0.5418\n",
      "[564/1762] D loss: 1.2535, G loss: 1.2041\n",
      "[644/1762] D loss: 1.3969, G loss: 0.8263\n",
      "[724/1762] D loss: 1.3617, G loss: 0.6784\n",
      "[804/1762] D loss: 1.3689, G loss: 0.7246\n",
      "[884/1762] D loss: 1.4449, G loss: 0.7397\n",
      "[964/1762] D loss: 1.3799, G loss: 0.5791\n",
      "[1044/1762] D loss: 1.5253, G loss: 1.0442\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7447\n",
      "[1204/1762] D loss: 1.4483, G loss: 0.6903\n",
      "[1284/1762] D loss: 1.3818, G loss: 0.7987\n",
      "[1364/1762] D loss: 1.4059, G loss: 0.6143\n",
      "[1444/1762] D loss: 1.3489, G loss: 0.6752\n",
      "[1524/1762] D loss: 1.4156, G loss: 0.6469\n",
      "[1604/1762] D loss: 1.3595, G loss: 0.6746\n",
      "[1684/1762] D loss: 1.4745, G loss: 0.8015\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.8219\n",
      "train error: \n",
      " D loss: 1.390933, G loss: 0.644591, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394218, G loss: 0.635549, D accuracy: 51.8%, cell accuracy: 99.5%, board accuracy: 48.2% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3368, G loss: 0.5946\n",
      "[84/1762] D loss: 1.4186, G loss: 0.6175\n",
      "[164/1762] D loss: 1.3717, G loss: 0.6608\n",
      "[244/1762] D loss: 1.3262, G loss: 0.7934\n",
      "[324/1762] D loss: 1.3369, G loss: 0.8652\n",
      "[404/1762] D loss: 1.3536, G loss: 0.7462\n",
      "[484/1762] D loss: 1.4238, G loss: 0.6493\n",
      "[564/1762] D loss: 1.3611, G loss: 0.6782\n",
      "[644/1762] D loss: 1.4017, G loss: 0.8178\n",
      "[724/1762] D loss: 1.3779, G loss: 0.7916\n",
      "[804/1762] D loss: 1.3045, G loss: 0.7005\n",
      "[884/1762] D loss: 1.4878, G loss: 0.6023\n",
      "[964/1762] D loss: 1.3403, G loss: 0.5937\n",
      "[1044/1762] D loss: 1.4187, G loss: 0.8485\n",
      "[1124/1762] D loss: 1.3687, G loss: 0.6232\n",
      "[1204/1762] D loss: 1.3825, G loss: 0.5583\n",
      "[1284/1762] D loss: 1.4215, G loss: 0.7015\n",
      "[1364/1762] D loss: 1.3672, G loss: 0.6707\n",
      "[1444/1762] D loss: 1.4129, G loss: 0.5828\n",
      "[1524/1762] D loss: 1.4091, G loss: 0.7387\n",
      "[1604/1762] D loss: 1.3333, G loss: 0.7197\n",
      "[1684/1762] D loss: 1.4168, G loss: 0.7161\n",
      "[1762/1762] D loss: 1.3722, G loss: 0.6370\n",
      "train error: \n",
      " D loss: 1.385785, G loss: 0.685909, D accuracy: 52.4%, cell accuracy: 99.6%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387733, G loss: 0.678094, D accuracy: 51.8%, cell accuracy: 99.5%, board accuracy: 48.9% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3703, G loss: 0.6574\n",
      "[84/1762] D loss: 1.3698, G loss: 0.6945\n",
      "[164/1762] D loss: 1.3537, G loss: 0.7478\n",
      "[244/1762] D loss: 1.3508, G loss: 0.6697\n",
      "[324/1762] D loss: 1.3488, G loss: 0.8538\n",
      "[404/1762] D loss: 1.3681, G loss: 0.6897\n",
      "[484/1762] D loss: 1.3537, G loss: 0.7581\n",
      "[564/1762] D loss: 1.3912, G loss: 0.5702\n",
      "[644/1762] D loss: 1.3368, G loss: 0.6987\n",
      "[724/1762] D loss: 1.2742, G loss: 0.8566\n",
      "[804/1762] D loss: 1.3418, G loss: 0.7159\n",
      "[884/1762] D loss: 1.4368, G loss: 0.5236\n",
      "[964/1762] D loss: 1.4026, G loss: 0.6596\n",
      "[1044/1762] D loss: 1.4035, G loss: 0.6399\n",
      "[1124/1762] D loss: 1.3998, G loss: 0.7824\n",
      "[1204/1762] D loss: 1.3175, G loss: 0.8737\n",
      "[1284/1762] D loss: 1.4325, G loss: 0.9849\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.6624\n",
      "[1444/1762] D loss: 1.3443, G loss: 0.7439\n",
      "[1524/1762] D loss: 1.3697, G loss: 0.7397\n",
      "[1604/1762] D loss: 1.3795, G loss: 0.7601\n",
      "[1684/1762] D loss: 1.2858, G loss: 0.7820\n",
      "[1762/1762] D loss: 1.3419, G loss: 0.8932\n",
      "train error: \n",
      " D loss: 1.377839, G loss: 0.779693, D accuracy: 52.8%, cell accuracy: 99.6%, board accuracy: 51.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378261, G loss: 0.772641, D accuracy: 53.0%, cell accuracy: 99.5%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3750, G loss: 0.6757\n",
      "[84/1762] D loss: 1.3727, G loss: 0.6860\n",
      "[164/1762] D loss: 1.4019, G loss: 0.8137\n",
      "[244/1762] D loss: 1.3978, G loss: 0.5984\n",
      "[324/1762] D loss: 1.4175, G loss: 0.6328\n",
      "[404/1762] D loss: 1.3949, G loss: 0.6445\n",
      "[484/1762] D loss: 1.3911, G loss: 0.6908\n",
      "[564/1762] D loss: 1.3945, G loss: 0.6786\n",
      "[644/1762] D loss: 1.3835, G loss: 0.7451\n",
      "[724/1762] D loss: 1.3728, G loss: 0.7203\n",
      "[804/1762] D loss: 1.4012, G loss: 0.5929\n",
      "[884/1762] D loss: 1.3559, G loss: 0.8129\n",
      "[964/1762] D loss: 1.3533, G loss: 0.7074\n",
      "[1044/1762] D loss: 1.3388, G loss: 0.8231\n",
      "[1124/1762] D loss: 1.3532, G loss: 0.5922\n",
      "[1204/1762] D loss: 1.4149, G loss: 0.8302\n",
      "[1284/1762] D loss: 1.4348, G loss: 0.6373\n",
      "[1364/1762] D loss: 1.3149, G loss: 0.7734\n",
      "[1444/1762] D loss: 1.4134, G loss: 0.5647\n",
      "[1524/1762] D loss: 1.3325, G loss: 0.7754\n",
      "[1604/1762] D loss: 1.3057, G loss: 0.9627\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.7056\n",
      "[1762/1762] D loss: 1.3847, G loss: 0.5508\n",
      "train error: \n",
      " D loss: 1.359359, G loss: 0.729012, D accuracy: 55.4%, cell accuracy: 99.6%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361266, G loss: 0.720359, D accuracy: 55.6%, cell accuracy: 99.5%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3729, G loss: 0.7170\n",
      "[84/1762] D loss: 1.4085, G loss: 0.9535\n",
      "[164/1762] D loss: 1.4394, G loss: 0.5598\n",
      "[244/1762] D loss: 1.4479, G loss: 0.7612\n",
      "[324/1762] D loss: 1.4404, G loss: 0.6512\n",
      "[404/1762] D loss: 1.3941, G loss: 0.6968\n",
      "[484/1762] D loss: 1.3767, G loss: 0.6793\n",
      "[564/1762] D loss: 1.3728, G loss: 0.8829\n",
      "[644/1762] D loss: 1.3411, G loss: 0.7720\n",
      "[724/1762] D loss: 1.4109, G loss: 0.6859\n",
      "[804/1762] D loss: 1.3997, G loss: 0.6514\n",
      "[884/1762] D loss: 1.3060, G loss: 0.8757\n",
      "[964/1762] D loss: 1.3702, G loss: 0.8048\n",
      "[1044/1762] D loss: 1.3843, G loss: 0.6231\n",
      "[1124/1762] D loss: 1.3989, G loss: 0.6872\n",
      "[1204/1762] D loss: 1.3766, G loss: 0.7003\n",
      "[1284/1762] D loss: 1.3114, G loss: 0.8937\n",
      "[1364/1762] D loss: 1.3796, G loss: 0.6981\n",
      "[1444/1762] D loss: 1.3831, G loss: 0.7137\n",
      "[1524/1762] D loss: 1.3767, G loss: 0.7102\n",
      "[1604/1762] D loss: 1.3806, G loss: 0.6784\n",
      "[1684/1762] D loss: 1.4000, G loss: 0.5450\n",
      "[1762/1762] D loss: 1.4450, G loss: 0.5604\n",
      "train error: \n",
      " D loss: 1.366669, G loss: 0.734538, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367396, G loss: 0.729335, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3433, G loss: 0.8098\n",
      "[84/1762] D loss: 1.4417, G loss: 0.4943\n",
      "[164/1762] D loss: 1.3898, G loss: 0.6503\n",
      "[244/1762] D loss: 1.3642, G loss: 0.7040\n",
      "[324/1762] D loss: 1.3662, G loss: 0.6424\n",
      "[404/1762] D loss: 1.3988, G loss: 0.6036\n",
      "[484/1762] D loss: 1.3299, G loss: 0.6914\n",
      "[564/1762] D loss: 1.3797, G loss: 0.6973\n",
      "[644/1762] D loss: 1.3903, G loss: 0.7912\n",
      "[724/1762] D loss: 1.3510, G loss: 0.6939\n",
      "[804/1762] D loss: 1.3788, G loss: 0.6497\n",
      "[884/1762] D loss: 1.3482, G loss: 0.9723\n",
      "[964/1762] D loss: 1.3857, G loss: 0.5490\n",
      "[1044/1762] D loss: 1.3821, G loss: 0.5977\n",
      "[1124/1762] D loss: 1.3842, G loss: 0.7193\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.8153\n",
      "[1284/1762] D loss: 1.3983, G loss: 0.6122\n",
      "[1364/1762] D loss: 1.3963, G loss: 0.5771\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6136\n",
      "[1524/1762] D loss: 1.3440, G loss: 0.5856\n",
      "[1604/1762] D loss: 1.4214, G loss: 0.6906\n",
      "[1684/1762] D loss: 1.3831, G loss: 0.7229\n",
      "[1762/1762] D loss: 1.3712, G loss: 0.5948\n",
      "train error: \n",
      " D loss: 1.376951, G loss: 0.661913, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 65.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370564, G loss: 0.667719, D accuracy: 56.2%, cell accuracy: 99.6%, board accuracy: 60.7% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3668, G loss: 0.6427\n",
      "[84/1762] D loss: 1.3738, G loss: 0.7286\n",
      "[164/1762] D loss: 1.3301, G loss: 0.7477\n",
      "[244/1762] D loss: 1.4308, G loss: 0.7073\n",
      "[324/1762] D loss: 1.3914, G loss: 0.8135\n",
      "[404/1762] D loss: 1.4123, G loss: 0.6445\n",
      "[484/1762] D loss: 1.3683, G loss: 0.6618\n",
      "[564/1762] D loss: 1.4216, G loss: 0.8441\n",
      "[644/1762] D loss: 1.3907, G loss: 0.8174\n",
      "[724/1762] D loss: 1.3552, G loss: 0.7739\n",
      "[804/1762] D loss: 1.4053, G loss: 0.5778\n",
      "[884/1762] D loss: 1.3455, G loss: 0.6376\n",
      "[964/1762] D loss: 1.3798, G loss: 0.6974\n",
      "[1044/1762] D loss: 1.3501, G loss: 0.6750\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.7912\n",
      "[1204/1762] D loss: 1.3498, G loss: 0.6989\n",
      "[1284/1762] D loss: 1.3678, G loss: 0.6257\n",
      "[1364/1762] D loss: 1.3046, G loss: 0.6961\n",
      "[1444/1762] D loss: 1.3828, G loss: 0.5981\n",
      "[1524/1762] D loss: 1.3402, G loss: 0.6807\n",
      "[1604/1762] D loss: 1.3807, G loss: 0.7407\n",
      "[1684/1762] D loss: 1.3130, G loss: 0.6689\n",
      "[1762/1762] D loss: 1.3690, G loss: 0.7699\n",
      "train error: \n",
      " D loss: 1.374988, G loss: 0.830059, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 65.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367618, G loss: 0.837757, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 59.3% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3678, G loss: 0.8411\n",
      "[84/1762] D loss: 1.4005, G loss: 0.7182\n",
      "[164/1762] D loss: 1.3067, G loss: 0.8071\n",
      "[244/1762] D loss: 1.3903, G loss: 0.6742\n",
      "[324/1762] D loss: 1.3644, G loss: 0.5725\n",
      "[404/1762] D loss: 1.3620, G loss: 0.5968\n",
      "[484/1762] D loss: 1.3243, G loss: 0.6444\n",
      "[564/1762] D loss: 1.3342, G loss: 0.8318\n",
      "[644/1762] D loss: 1.3855, G loss: 0.7386\n",
      "[724/1762] D loss: 1.3310, G loss: 0.8881\n",
      "[804/1762] D loss: 1.3880, G loss: 0.8333\n",
      "[884/1762] D loss: 1.3624, G loss: 0.6673\n",
      "[964/1762] D loss: 1.3650, G loss: 0.7291\n",
      "[1044/1762] D loss: 1.3107, G loss: 0.7750\n",
      "[1124/1762] D loss: 1.3760, G loss: 0.7218\n",
      "[1204/1762] D loss: 1.3526, G loss: 0.6697\n",
      "[1284/1762] D loss: 1.3506, G loss: 0.6921\n",
      "[1364/1762] D loss: 1.3332, G loss: 0.7523\n",
      "[1444/1762] D loss: 1.3730, G loss: 0.8208\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.7349\n",
      "[1604/1762] D loss: 1.3768, G loss: 0.6950\n",
      "[1684/1762] D loss: 1.3831, G loss: 0.7228\n",
      "[1762/1762] D loss: 1.4398, G loss: 0.8199\n",
      "train error: \n",
      " D loss: 1.365961, G loss: 0.696764, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 69.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362045, G loss: 0.700570, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 64.3% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3282, G loss: 0.6236\n",
      "[84/1762] D loss: 1.2844, G loss: 0.8973\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6541\n",
      "[244/1762] D loss: 1.2639, G loss: 0.7108\n",
      "[324/1762] D loss: 1.3871, G loss: 0.7076\n",
      "[404/1762] D loss: 1.4153, G loss: 0.8219\n",
      "[484/1762] D loss: 1.3691, G loss: 0.7130\n",
      "[564/1762] D loss: 1.4293, G loss: 0.5701\n",
      "[644/1762] D loss: 1.3462, G loss: 0.7950\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6679\n",
      "[804/1762] D loss: 1.3324, G loss: 0.7535\n",
      "[884/1762] D loss: 1.3535, G loss: 0.7902\n",
      "[964/1762] D loss: 1.3651, G loss: 0.7839\n",
      "[1044/1762] D loss: 1.3262, G loss: 0.9052\n",
      "[1124/1762] D loss: 1.3982, G loss: 0.6948\n",
      "[1204/1762] D loss: 1.3839, G loss: 0.7907\n",
      "[1284/1762] D loss: 1.3924, G loss: 0.8317\n",
      "[1364/1762] D loss: 1.3467, G loss: 0.6598\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.5914\n",
      "[1524/1762] D loss: 1.3471, G loss: 0.6609\n",
      "[1604/1762] D loss: 1.3622, G loss: 0.8588\n",
      "[1684/1762] D loss: 1.3659, G loss: 0.7232\n",
      "[1762/1762] D loss: 1.3497, G loss: 0.7564\n",
      "train error: \n",
      " D loss: 1.362859, G loss: 0.773799, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 67.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358780, G loss: 0.777333, D accuracy: 57.0%, cell accuracy: 99.6%, board accuracy: 63.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3128, G loss: 0.8547\n",
      "[84/1762] D loss: 1.3385, G loss: 0.7879\n",
      "[164/1762] D loss: 1.3694, G loss: 0.7789\n",
      "[244/1762] D loss: 1.3556, G loss: 0.7452\n",
      "[324/1762] D loss: 1.3902, G loss: 0.5644\n",
      "[404/1762] D loss: 1.3644, G loss: 0.7405\n",
      "[484/1762] D loss: 1.3988, G loss: 0.7132\n",
      "[564/1762] D loss: 1.3168, G loss: 0.7462\n",
      "[644/1762] D loss: 1.2826, G loss: 0.7232\n",
      "[724/1762] D loss: 1.3922, G loss: 0.7740\n",
      "[804/1762] D loss: 1.3470, G loss: 0.8096\n",
      "[884/1762] D loss: 1.3914, G loss: 0.7113\n",
      "[964/1762] D loss: 1.3422, G loss: 0.6626\n",
      "[1044/1762] D loss: 1.3558, G loss: 0.7478\n",
      "[1124/1762] D loss: 1.3718, G loss: 0.7424\n",
      "[1204/1762] D loss: 1.3846, G loss: 0.7140\n",
      "[1284/1762] D loss: 1.3623, G loss: 0.6876\n",
      "[1364/1762] D loss: 1.3935, G loss: 0.7569\n",
      "[1444/1762] D loss: 1.4351, G loss: 0.4545\n",
      "[1524/1762] D loss: 1.4342, G loss: 0.4986\n",
      "[1604/1762] D loss: 1.4101, G loss: 0.5106\n",
      "[1684/1762] D loss: 1.3856, G loss: 0.7397\n",
      "[1762/1762] D loss: 1.3639, G loss: 0.6897\n",
      "train error: \n",
      " D loss: 1.377955, G loss: 0.644308, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 77.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372916, G loss: 0.648244, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3439, G loss: 0.7548\n",
      "[84/1762] D loss: 1.3831, G loss: 0.8535\n",
      "[164/1762] D loss: 1.3188, G loss: 0.6883\n",
      "[244/1762] D loss: 1.4047, G loss: 0.5664\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6085\n",
      "[404/1762] D loss: 1.3572, G loss: 0.7167\n",
      "[484/1762] D loss: 1.3873, G loss: 0.6793\n",
      "[564/1762] D loss: 1.3650, G loss: 0.8197\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6806\n",
      "[724/1762] D loss: 1.3845, G loss: 0.7459\n",
      "[804/1762] D loss: 1.4315, G loss: 0.9279\n",
      "[884/1762] D loss: 1.3968, G loss: 0.6697\n",
      "[964/1762] D loss: 1.2819, G loss: 0.9488\n",
      "[1044/1762] D loss: 1.3626, G loss: 0.7251\n",
      "[1124/1762] D loss: 1.3857, G loss: 0.6726\n",
      "[1204/1762] D loss: 1.4176, G loss: 0.5711\n",
      "[1284/1762] D loss: 1.3627, G loss: 0.5765\n",
      "[1364/1762] D loss: 1.4167, G loss: 0.5782\n",
      "[1444/1762] D loss: 1.3753, G loss: 0.6900\n",
      "[1524/1762] D loss: 1.3363, G loss: 0.7801\n",
      "[1604/1762] D loss: 1.3784, G loss: 0.7571\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.7934\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6272\n",
      "train error: \n",
      " D loss: 1.380819, G loss: 0.614547, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376500, G loss: 0.617809, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3938, G loss: 0.6614\n",
      "[84/1762] D loss: 1.4127, G loss: 0.6220\n",
      "[164/1762] D loss: 1.4065, G loss: 0.6528\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6893\n",
      "[324/1762] D loss: 1.3332, G loss: 0.6814\n",
      "[404/1762] D loss: 1.4020, G loss: 0.6254\n",
      "[484/1762] D loss: 1.2680, G loss: 0.8961\n",
      "[564/1762] D loss: 1.2500, G loss: 0.9417\n",
      "[644/1762] D loss: 1.3921, G loss: 0.6322\n",
      "[724/1762] D loss: 1.4001, G loss: 0.7655\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7183\n",
      "[884/1762] D loss: 1.3621, G loss: 0.7609\n",
      "[964/1762] D loss: 1.3815, G loss: 0.6408\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.6522\n",
      "[1124/1762] D loss: 1.3398, G loss: 0.8366\n",
      "[1204/1762] D loss: 1.3462, G loss: 0.9239\n",
      "[1284/1762] D loss: 1.3922, G loss: 0.6773\n",
      "[1364/1762] D loss: 1.4043, G loss: 0.5697\n",
      "[1444/1762] D loss: 1.3947, G loss: 0.6398\n",
      "[1524/1762] D loss: 1.3733, G loss: 0.6653\n",
      "[1604/1762] D loss: 1.3732, G loss: 0.7164\n",
      "[1684/1762] D loss: 1.2058, G loss: 1.0039\n",
      "[1762/1762] D loss: 1.3565, G loss: 0.5625\n",
      "train error: \n",
      " D loss: 1.402821, G loss: 0.529914, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 73.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399928, G loss: 0.532565, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 70.9% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4276, G loss: 0.5048\n",
      "[84/1762] D loss: 1.3153, G loss: 0.8281\n",
      "[164/1762] D loss: 1.3065, G loss: 0.7851\n",
      "[244/1762] D loss: 1.2962, G loss: 0.8470\n",
      "[324/1762] D loss: 1.2811, G loss: 0.9206\n",
      "[404/1762] D loss: 1.3651, G loss: 0.8269\n",
      "[484/1762] D loss: 1.3834, G loss: 0.6978\n",
      "[564/1762] D loss: 1.4290, G loss: 0.5318\n",
      "[644/1762] D loss: 1.3921, G loss: 0.5271\n",
      "[724/1762] D loss: 1.4391, G loss: 0.9313\n",
      "[804/1762] D loss: 1.3579, G loss: 0.6457\n",
      "[884/1762] D loss: 1.3368, G loss: 0.7807\n",
      "[964/1762] D loss: 1.2846, G loss: 0.8013\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.7773\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6474\n",
      "[1204/1762] D loss: 1.4054, G loss: 0.8241\n",
      "[1284/1762] D loss: 1.3648, G loss: 0.6582\n",
      "[1364/1762] D loss: 1.3454, G loss: 0.7412\n",
      "[1444/1762] D loss: 1.3400, G loss: 0.7142\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7431\n",
      "[1604/1762] D loss: 1.3419, G loss: 0.6629\n",
      "[1684/1762] D loss: 1.4082, G loss: 0.6551\n",
      "[1762/1762] D loss: 1.3846, G loss: 0.7698\n",
      "train error: \n",
      " D loss: 1.376909, G loss: 0.821294, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369632, G loss: 0.834035, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3839, G loss: 0.8181\n",
      "[84/1762] D loss: 1.3316, G loss: 0.8950\n",
      "[164/1762] D loss: 1.3373, G loss: 0.7251\n",
      "[244/1762] D loss: 1.4038, G loss: 0.5665\n",
      "[324/1762] D loss: 1.3886, G loss: 0.7035\n",
      "[404/1762] D loss: 1.4001, G loss: 0.8058\n",
      "[484/1762] D loss: 1.3707, G loss: 0.6480\n",
      "[564/1762] D loss: 1.4346, G loss: 0.5866\n",
      "[644/1762] D loss: 1.3530, G loss: 0.7160\n",
      "[724/1762] D loss: 1.4269, G loss: 0.7823\n",
      "[804/1762] D loss: 1.3806, G loss: 0.6932\n",
      "[884/1762] D loss: 1.3166, G loss: 0.8380\n",
      "[964/1762] D loss: 1.3646, G loss: 0.6749\n",
      "[1044/1762] D loss: 1.3305, G loss: 0.8581\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.7526\n",
      "[1204/1762] D loss: 1.3593, G loss: 0.6925\n",
      "[1284/1762] D loss: 1.2964, G loss: 0.7360\n",
      "[1364/1762] D loss: 1.3801, G loss: 0.6253\n",
      "[1444/1762] D loss: 1.3890, G loss: 0.6668\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6666\n",
      "[1604/1762] D loss: 1.2261, G loss: 1.3094\n",
      "[1684/1762] D loss: 1.3330, G loss: 0.7827\n",
      "[1762/1762] D loss: 1.2992, G loss: 0.8586\n",
      "train error: \n",
      " D loss: 1.366833, G loss: 0.657209, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360855, G loss: 0.663605, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3832, G loss: 0.6636\n",
      "[84/1762] D loss: 1.4185, G loss: 0.5629\n",
      "[164/1762] D loss: 1.2841, G loss: 0.7636\n",
      "[244/1762] D loss: 1.3170, G loss: 0.8957\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6857\n",
      "[404/1762] D loss: 1.3857, G loss: 0.6914\n",
      "[484/1762] D loss: 1.3795, G loss: 0.7265\n",
      "[564/1762] D loss: 1.3859, G loss: 0.7731\n",
      "[644/1762] D loss: 1.4082, G loss: 0.5889\n",
      "[724/1762] D loss: 1.3929, G loss: 0.6343\n",
      "[804/1762] D loss: 1.3240, G loss: 0.6691\n",
      "[884/1762] D loss: 1.3943, G loss: 0.5933\n",
      "[964/1762] D loss: 1.2952, G loss: 0.8332\n",
      "[1044/1762] D loss: 1.4066, G loss: 0.6841\n",
      "[1124/1762] D loss: 1.4072, G loss: 0.6119\n",
      "[1204/1762] D loss: 1.2749, G loss: 0.7184\n",
      "[1284/1762] D loss: 1.2939, G loss: 0.9029\n",
      "[1364/1762] D loss: 1.4017, G loss: 0.8545\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7488\n",
      "[1524/1762] D loss: 1.3951, G loss: 0.6329\n",
      "[1604/1762] D loss: 1.3009, G loss: 0.7919\n",
      "[1684/1762] D loss: 1.3047, G loss: 1.0025\n",
      "[1762/1762] D loss: 1.3712, G loss: 0.8687\n",
      "train error: \n",
      " D loss: 1.396273, G loss: 0.939564, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390149, G loss: 0.949870, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3121, G loss: 1.0255\n",
      "[84/1762] D loss: 1.3942, G loss: 0.7840\n",
      "[164/1762] D loss: 1.3857, G loss: 1.0284\n",
      "[244/1762] D loss: 1.2778, G loss: 0.9953\n",
      "[324/1762] D loss: 1.3828, G loss: 0.7538\n",
      "[404/1762] D loss: 1.3968, G loss: 0.6207\n",
      "[484/1762] D loss: 1.3429, G loss: 0.6408\n",
      "[564/1762] D loss: 1.3904, G loss: 0.7224\n",
      "[644/1762] D loss: 1.3715, G loss: 0.7359\n",
      "[724/1762] D loss: 1.2749, G loss: 0.8787\n",
      "[804/1762] D loss: 1.4085, G loss: 0.5997\n",
      "[884/1762] D loss: 1.3845, G loss: 0.6817\n",
      "[964/1762] D loss: 1.3349, G loss: 0.6853\n",
      "[1044/1762] D loss: 1.2942, G loss: 0.7565\n",
      "[1124/1762] D loss: 1.4141, G loss: 0.6953\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.6475\n",
      "[1284/1762] D loss: 1.3939, G loss: 0.6391\n",
      "[1364/1762] D loss: 1.4327, G loss: 0.7222\n",
      "[1444/1762] D loss: 1.3440, G loss: 0.7034\n",
      "[1524/1762] D loss: 1.2849, G loss: 0.7847\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.7229\n",
      "[1684/1762] D loss: 1.3501, G loss: 0.7195\n",
      "[1762/1762] D loss: 1.4049, G loss: 0.6841\n",
      "train error: \n",
      " D loss: 1.359769, G loss: 0.792081, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353680, G loss: 0.807711, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2921, G loss: 0.9311\n",
      "[84/1762] D loss: 1.4011, G loss: 0.6260\n",
      "[164/1762] D loss: 1.3826, G loss: 0.7017\n",
      "[244/1762] D loss: 1.3895, G loss: 0.7092\n",
      "[324/1762] D loss: 1.2735, G loss: 0.8596\n",
      "[404/1762] D loss: 1.3863, G loss: 0.7190\n",
      "[484/1762] D loss: 1.3878, G loss: 0.7204\n",
      "[564/1762] D loss: 1.3197, G loss: 0.6413\n",
      "[644/1762] D loss: 1.4033, G loss: 0.7247\n",
      "[724/1762] D loss: 1.3109, G loss: 0.8973\n",
      "[804/1762] D loss: 1.3882, G loss: 0.7345\n",
      "[884/1762] D loss: 1.3804, G loss: 0.6886\n",
      "[964/1762] D loss: 1.2505, G loss: 0.8800\n",
      "[1044/1762] D loss: 1.3993, G loss: 0.6486\n",
      "[1124/1762] D loss: 1.3102, G loss: 0.7239\n",
      "[1204/1762] D loss: 1.3302, G loss: 0.7171\n",
      "[1284/1762] D loss: 1.2758, G loss: 1.0112\n",
      "[1364/1762] D loss: 1.4065, G loss: 0.5533\n",
      "[1444/1762] D loss: 1.2802, G loss: 0.9724\n",
      "[1524/1762] D loss: 1.3740, G loss: 0.6408\n",
      "[1604/1762] D loss: 1.3789, G loss: 0.6833\n",
      "[1684/1762] D loss: 1.3925, G loss: 0.6664\n",
      "[1762/1762] D loss: 1.3841, G loss: 0.7516\n",
      "train error: \n",
      " D loss: 1.391055, G loss: 0.922732, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 71.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381529, G loss: 0.947603, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4001, G loss: 0.8445\n",
      "[84/1762] D loss: 1.4121, G loss: 0.5421\n",
      "[164/1762] D loss: 1.3796, G loss: 0.6948\n",
      "[244/1762] D loss: 1.3876, G loss: 0.8110\n",
      "[324/1762] D loss: 1.3001, G loss: 0.7864\n",
      "[404/1762] D loss: 1.4127, G loss: 0.6958\n",
      "[484/1762] D loss: 1.4256, G loss: 0.6690\n",
      "[564/1762] D loss: 1.5084, G loss: 0.8414\n",
      "[644/1762] D loss: 1.2911, G loss: 0.7852\n",
      "[724/1762] D loss: 1.3490, G loss: 0.7041\n",
      "[804/1762] D loss: 1.4141, G loss: 0.7521\n",
      "[884/1762] D loss: 1.3508, G loss: 0.5771\n",
      "[964/1762] D loss: 1.3924, G loss: 0.5757\n",
      "[1044/1762] D loss: 1.3408, G loss: 0.6293\n",
      "[1124/1762] D loss: 1.4041, G loss: 0.5721\n",
      "[1204/1762] D loss: 1.2450, G loss: 0.8938\n",
      "[1284/1762] D loss: 1.3827, G loss: 0.7408\n",
      "[1364/1762] D loss: 1.4015, G loss: 0.6584\n",
      "[1444/1762] D loss: 1.5249, G loss: 0.8360\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7051\n",
      "[1604/1762] D loss: 1.4008, G loss: 0.6964\n",
      "[1684/1762] D loss: 1.4002, G loss: 0.5606\n",
      "[1762/1762] D loss: 1.4080, G loss: 0.5473\n",
      "train error: \n",
      " D loss: 1.388386, G loss: 0.586025, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 72.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381924, G loss: 0.590339, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3446, G loss: 0.5785\n",
      "[84/1762] D loss: 1.3970, G loss: 0.7766\n",
      "[164/1762] D loss: 1.3660, G loss: 0.6789\n",
      "[244/1762] D loss: 1.4037, G loss: 0.6871\n",
      "[324/1762] D loss: 1.4098, G loss: 0.6468\n",
      "[404/1762] D loss: 1.4323, G loss: 0.8367\n",
      "[484/1762] D loss: 1.4682, G loss: 0.5770\n",
      "[564/1762] D loss: 1.3900, G loss: 0.6421\n",
      "[644/1762] D loss: 1.4291, G loss: 0.9915\n",
      "[724/1762] D loss: 1.4160, G loss: 0.6560\n",
      "[804/1762] D loss: 1.3952, G loss: 0.6020\n",
      "[884/1762] D loss: 1.3741, G loss: 1.0049\n",
      "[964/1762] D loss: 1.4021, G loss: 0.6225\n",
      "[1044/1762] D loss: 1.3307, G loss: 0.7225\n",
      "[1124/1762] D loss: 1.3906, G loss: 0.7507\n",
      "[1204/1762] D loss: 1.3595, G loss: 0.7130\n",
      "[1284/1762] D loss: 1.3402, G loss: 0.7067\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.7250\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.7339\n",
      "[1524/1762] D loss: 1.4157, G loss: 0.6022\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.7823\n",
      "[1684/1762] D loss: 1.2711, G loss: 0.7986\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.6552\n",
      "train error: \n",
      " D loss: 1.364864, G loss: 0.673279, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354166, G loss: 0.683446, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 59.3% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.6550\n",
      "[84/1762] D loss: 1.4145, G loss: 0.6837\n",
      "[164/1762] D loss: 1.3183, G loss: 0.6589\n",
      "[244/1762] D loss: 1.3905, G loss: 0.6601\n",
      "[324/1762] D loss: 1.3853, G loss: 0.7450\n",
      "[404/1762] D loss: 1.4015, G loss: 0.6165\n",
      "[484/1762] D loss: 1.3961, G loss: 0.7297\n",
      "[564/1762] D loss: 1.3831, G loss: 0.6296\n",
      "[644/1762] D loss: 1.3314, G loss: 0.7477\n",
      "[724/1762] D loss: 1.3910, G loss: 0.6820\n",
      "[804/1762] D loss: 1.3829, G loss: 0.6291\n",
      "[884/1762] D loss: 1.4833, G loss: 0.6818\n",
      "[964/1762] D loss: 1.3990, G loss: 0.5957\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.6540\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.7520\n",
      "[1204/1762] D loss: 1.3334, G loss: 0.7104\n",
      "[1284/1762] D loss: 1.3816, G loss: 0.6571\n",
      "[1364/1762] D loss: 1.3646, G loss: 0.7485\n",
      "[1444/1762] D loss: 1.3599, G loss: 0.7883\n",
      "[1524/1762] D loss: 1.3617, G loss: 0.6715\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.7088\n",
      "[1684/1762] D loss: 1.3755, G loss: 0.6998\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7180\n",
      "train error: \n",
      " D loss: 1.379603, G loss: 0.691641, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 62.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376610, G loss: 0.691907, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 63.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3926, G loss: 0.6794\n",
      "[84/1762] D loss: 1.3423, G loss: 0.7317\n",
      "[164/1762] D loss: 1.3920, G loss: 0.7019\n",
      "[244/1762] D loss: 1.3942, G loss: 0.6507\n",
      "[324/1762] D loss: 1.3542, G loss: 0.6869\n",
      "[404/1762] D loss: 1.3517, G loss: 0.6592\n",
      "[484/1762] D loss: 1.3399, G loss: 0.6988\n",
      "[564/1762] D loss: 1.3927, G loss: 0.6419\n",
      "[644/1762] D loss: 1.3813, G loss: 0.7128\n",
      "[724/1762] D loss: 1.3923, G loss: 0.6813\n",
      "[804/1762] D loss: 1.3606, G loss: 0.7018\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7025\n",
      "[964/1762] D loss: 1.3888, G loss: 0.7491\n",
      "[1044/1762] D loss: 1.3922, G loss: 0.6886\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.6786\n",
      "[1204/1762] D loss: 1.4002, G loss: 0.6908\n",
      "[1284/1762] D loss: 1.3806, G loss: 0.7134\n",
      "[1364/1762] D loss: 1.3783, G loss: 0.6710\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6728\n",
      "[1524/1762] D loss: 1.3840, G loss: 0.7061\n",
      "[1604/1762] D loss: 1.3813, G loss: 0.6842\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.6931\n",
      "[1762/1762] D loss: 1.2858, G loss: 0.7426\n",
      "train error: \n",
      " D loss: 1.375267, G loss: 0.701642, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 68.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371032, G loss: 0.702828, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6714\n",
      "[84/1762] D loss: 1.3882, G loss: 0.6988\n",
      "[164/1762] D loss: 1.4016, G loss: 0.6175\n",
      "[244/1762] D loss: 1.3385, G loss: 0.7325\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7274\n",
      "[404/1762] D loss: 1.3299, G loss: 0.7296\n",
      "[484/1762] D loss: 1.3196, G loss: 0.7351\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7085\n",
      "[644/1762] D loss: 1.3914, G loss: 0.6912\n",
      "[724/1762] D loss: 1.3278, G loss: 0.6989\n",
      "[804/1762] D loss: 1.3885, G loss: 0.7185\n",
      "[884/1762] D loss: 1.3189, G loss: 0.7109\n",
      "[964/1762] D loss: 1.3917, G loss: 0.6767\n",
      "[1044/1762] D loss: 1.3546, G loss: 0.6860\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.7268\n",
      "[1204/1762] D loss: 1.3327, G loss: 0.7169\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6889\n",
      "[1364/1762] D loss: 1.3710, G loss: 0.7154\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.6726\n",
      "[1524/1762] D loss: 1.3286, G loss: 0.7039\n",
      "[1604/1762] D loss: 1.3923, G loss: 0.6994\n",
      "[1684/1762] D loss: 1.3841, G loss: 0.6869\n",
      "[1762/1762] D loss: 1.3650, G loss: 0.7243\n",
      "train error: \n",
      " D loss: 1.371229, G loss: 0.682630, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 70.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365584, G loss: 0.685794, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3831, G loss: 0.7005\n",
      "[84/1762] D loss: 1.3906, G loss: 0.6803\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6735\n",
      "[244/1762] D loss: 1.3925, G loss: 0.6743\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6923\n",
      "[404/1762] D loss: 1.3085, G loss: 0.7082\n",
      "[484/1762] D loss: 1.3888, G loss: 0.6788\n",
      "[564/1762] D loss: 1.3958, G loss: 0.7060\n",
      "[644/1762] D loss: 1.3930, G loss: 0.6713\n",
      "[724/1762] D loss: 1.3852, G loss: 0.6800\n",
      "[804/1762] D loss: 1.3944, G loss: 0.6945\n",
      "[884/1762] D loss: 1.3372, G loss: 0.7254\n",
      "[964/1762] D loss: 1.3272, G loss: 0.6980\n",
      "[1044/1762] D loss: 1.2287, G loss: 0.8032\n",
      "[1124/1762] D loss: 1.2743, G loss: 0.8334\n",
      "[1204/1762] D loss: 1.4013, G loss: 0.7280\n",
      "[1284/1762] D loss: 1.4107, G loss: 0.6251\n",
      "[1364/1762] D loss: 1.3910, G loss: 0.7305\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.7399\n",
      "[1524/1762] D loss: 1.3684, G loss: 0.6678\n",
      "[1604/1762] D loss: 1.4059, G loss: 0.5930\n",
      "[1684/1762] D loss: 1.4000, G loss: 0.6879\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6895\n",
      "train error: \n",
      " D loss: 1.365781, G loss: 0.748218, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358465, G loss: 0.754308, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3101, G loss: 0.8202\n",
      "[84/1762] D loss: 1.1971, G loss: 0.8200\n",
      "[164/1762] D loss: 1.3078, G loss: 0.7273\n",
      "[244/1762] D loss: 1.3694, G loss: 0.7234\n",
      "[324/1762] D loss: 1.4026, G loss: 0.6264\n",
      "[404/1762] D loss: 1.3848, G loss: 0.7645\n",
      "[484/1762] D loss: 1.3948, G loss: 0.7146\n",
      "[564/1762] D loss: 1.2900, G loss: 0.7681\n",
      "[644/1762] D loss: 1.3987, G loss: 0.6433\n",
      "[724/1762] D loss: 1.3969, G loss: 0.7941\n",
      "[804/1762] D loss: 1.4270, G loss: 0.7075\n",
      "[884/1762] D loss: 1.4359, G loss: 0.6741\n",
      "[964/1762] D loss: 1.4008, G loss: 0.7349\n",
      "[1044/1762] D loss: 1.3732, G loss: 0.8045\n",
      "[1124/1762] D loss: 1.3104, G loss: 0.6772\n",
      "[1204/1762] D loss: 1.2876, G loss: 0.7194\n",
      "[1284/1762] D loss: 1.4126, G loss: 0.6059\n",
      "[1364/1762] D loss: 1.3950, G loss: 0.6670\n",
      "[1444/1762] D loss: 1.4493, G loss: 0.9006\n",
      "[1524/1762] D loss: 1.3963, G loss: 0.7075\n",
      "[1604/1762] D loss: 1.3927, G loss: 0.7092\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6979\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.7225\n",
      "train error: \n",
      " D loss: 1.378006, G loss: 0.736078, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375141, G loss: 0.738015, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3973, G loss: 0.7394\n",
      "[84/1762] D loss: 1.3943, G loss: 0.6481\n",
      "[164/1762] D loss: 1.3889, G loss: 0.6711\n",
      "[244/1762] D loss: 1.3886, G loss: 0.6931\n",
      "[324/1762] D loss: 1.3894, G loss: 0.6600\n",
      "[404/1762] D loss: 1.3842, G loss: 0.6898\n",
      "[484/1762] D loss: 1.3971, G loss: 0.6414\n",
      "[564/1762] D loss: 1.3854, G loss: 0.6544\n",
      "[644/1762] D loss: 1.3897, G loss: 0.7704\n",
      "[724/1762] D loss: 1.3932, G loss: 0.7287\n",
      "[804/1762] D loss: 1.2979, G loss: 0.7794\n",
      "[884/1762] D loss: 1.3934, G loss: 0.7769\n",
      "[964/1762] D loss: 1.2959, G loss: 0.7248\n",
      "[1044/1762] D loss: 1.3923, G loss: 0.7839\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.7028\n",
      "[1204/1762] D loss: 1.3944, G loss: 0.7811\n",
      "[1284/1762] D loss: 1.1697, G loss: 0.9254\n",
      "[1364/1762] D loss: 1.4012, G loss: 0.8634\n",
      "[1444/1762] D loss: 1.3921, G loss: 0.6519\n",
      "[1524/1762] D loss: 1.1853, G loss: 0.8960\n",
      "[1604/1762] D loss: 1.3634, G loss: 0.6586\n",
      "[1684/1762] D loss: 1.3959, G loss: 0.7510\n",
      "[1762/1762] D loss: 1.3930, G loss: 0.7448\n",
      "train error: \n",
      " D loss: 1.359577, G loss: 0.685658, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351082, G loss: 0.690890, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3992, G loss: 0.6500\n",
      "[84/1762] D loss: 1.4030, G loss: 0.7076\n",
      "[164/1762] D loss: 1.2472, G loss: 0.7815\n",
      "[244/1762] D loss: 1.3832, G loss: 0.6242\n",
      "[324/1762] D loss: 1.2637, G loss: 0.8438\n",
      "[404/1762] D loss: 1.4219, G loss: 0.6668\n",
      "[484/1762] D loss: 1.2926, G loss: 0.8336\n",
      "[564/1762] D loss: 1.2832, G loss: 0.8296\n",
      "[644/1762] D loss: 1.1287, G loss: 0.9324\n",
      "[724/1762] D loss: 1.0457, G loss: 1.0564\n",
      "[804/1762] D loss: 0.8467, G loss: 1.3410\n",
      "[884/1762] D loss: 1.4461, G loss: 0.5927\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7710\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.7099\n",
      "[1124/1762] D loss: 1.3767, G loss: 0.5884\n",
      "[1204/1762] D loss: 1.4127, G loss: 0.6427\n",
      "[1284/1762] D loss: 1.4257, G loss: 0.7594\n",
      "[1364/1762] D loss: 1.4144, G loss: 0.7203\n",
      "[1444/1762] D loss: 1.4214, G loss: 0.6124\n",
      "[1524/1762] D loss: 1.4254, G loss: 0.6853\n",
      "[1604/1762] D loss: 1.3396, G loss: 0.7364\n",
      "[1684/1762] D loss: 1.4464, G loss: 0.6248\n",
      "[1762/1762] D loss: 1.3993, G loss: 0.6975\n",
      "train error: \n",
      " D loss: 1.412587, G loss: 0.643259, D accuracy: 41.9%, cell accuracy: 96.9%, board accuracy: 1.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411368, G loss: 0.642401, D accuracy: 40.1%, cell accuracy: 96.8%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4010, G loss: 0.6245\n",
      "[84/1762] D loss: 1.4474, G loss: 0.6376\n",
      "[164/1762] D loss: 1.4071, G loss: 0.6642\n",
      "[244/1762] D loss: 1.4725, G loss: 0.6336\n",
      "[324/1762] D loss: 1.3043, G loss: 0.7255\n",
      "[404/1762] D loss: 1.4841, G loss: 0.6172\n",
      "[484/1762] D loss: 1.3827, G loss: 0.5880\n",
      "[564/1762] D loss: 1.2604, G loss: 0.7449\n",
      "[644/1762] D loss: 1.3613, G loss: 0.7113\n",
      "[724/1762] D loss: 1.3710, G loss: 0.6901\n",
      "[804/1762] D loss: 1.3919, G loss: 0.6832\n",
      "[884/1762] D loss: 1.3834, G loss: 0.6717\n",
      "[964/1762] D loss: 1.4142, G loss: 0.6215\n",
      "[1044/1762] D loss: 1.3332, G loss: 0.7824\n",
      "[1124/1762] D loss: 1.3187, G loss: 0.7722\n",
      "[1204/1762] D loss: 1.3318, G loss: 0.6756\n",
      "[1284/1762] D loss: 1.3985, G loss: 0.6408\n",
      "[1364/1762] D loss: 1.3556, G loss: 0.6439\n",
      "[1444/1762] D loss: 1.3853, G loss: 0.7295\n",
      "[1524/1762] D loss: 1.3098, G loss: 0.6985\n",
      "[1604/1762] D loss: 1.4133, G loss: 0.7577\n",
      "[1684/1762] D loss: 1.3779, G loss: 0.7530\n",
      "[1762/1762] D loss: 1.3948, G loss: 0.6796\n",
      "train error: \n",
      " D loss: 1.361752, G loss: 0.723486, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351927, G loss: 0.729255, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2805, G loss: 0.8018\n",
      "[84/1762] D loss: 1.4275, G loss: 0.8957\n",
      "[164/1762] D loss: 1.3825, G loss: 0.6961\n",
      "[244/1762] D loss: 1.3997, G loss: 0.6420\n",
      "[324/1762] D loss: 1.4158, G loss: 0.7229\n",
      "[404/1762] D loss: 1.3807, G loss: 0.6611\n",
      "[484/1762] D loss: 1.3855, G loss: 0.6621\n",
      "[564/1762] D loss: 1.3396, G loss: 0.6876\n",
      "[644/1762] D loss: 1.0921, G loss: 1.0541\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7242\n",
      "[804/1762] D loss: 1.3956, G loss: 0.6408\n",
      "[884/1762] D loss: 1.3901, G loss: 0.6636\n",
      "[964/1762] D loss: 1.3889, G loss: 0.6777\n",
      "[1044/1762] D loss: 1.1517, G loss: 0.9265\n",
      "[1124/1762] D loss: 1.2944, G loss: 0.6359\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.7129\n",
      "[1284/1762] D loss: 1.3461, G loss: 0.6913\n",
      "[1364/1762] D loss: 1.3951, G loss: 0.6362\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.6763\n",
      "[1524/1762] D loss: 1.3257, G loss: 0.7016\n",
      "[1604/1762] D loss: 1.4153, G loss: 0.7024\n",
      "[1684/1762] D loss: 1.0948, G loss: 1.1170\n",
      "[1762/1762] D loss: 1.3978, G loss: 0.6470\n",
      "train error: \n",
      " D loss: 1.350786, G loss: 0.740670, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 71.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340078, G loss: 0.751744, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 70.7% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3826, G loss: 0.7600\n",
      "[84/1762] D loss: 1.3777, G loss: 0.7746\n",
      "[164/1762] D loss: 1.4182, G loss: 0.8695\n",
      "[244/1762] D loss: 1.2614, G loss: 0.8404\n",
      "[324/1762] D loss: 1.3822, G loss: 0.5796\n",
      "[404/1762] D loss: 1.3965, G loss: 0.6537\n",
      "[484/1762] D loss: 1.2537, G loss: 0.9647\n",
      "[564/1762] D loss: 1.4050, G loss: 0.5803\n",
      "[644/1762] D loss: 1.4214, G loss: 0.6972\n",
      "[724/1762] D loss: 1.3942, G loss: 0.7230\n",
      "[804/1762] D loss: 1.3989, G loss: 0.5915\n",
      "[884/1762] D loss: 1.3997, G loss: 0.7993\n",
      "[964/1762] D loss: 1.2206, G loss: 0.8886\n",
      "[1044/1762] D loss: 1.2483, G loss: 0.8213\n",
      "[1124/1762] D loss: 1.3454, G loss: 0.6285\n",
      "[1204/1762] D loss: 1.4006, G loss: 0.6246\n",
      "[1284/1762] D loss: 1.0578, G loss: 1.1074\n",
      "[1364/1762] D loss: 1.3848, G loss: 0.6963\n",
      "[1444/1762] D loss: 1.2434, G loss: 0.8530\n",
      "[1524/1762] D loss: 1.4094, G loss: 0.6477\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.7091\n",
      "[1684/1762] D loss: 1.3719, G loss: 0.6737\n",
      "[1762/1762] D loss: 1.1024, G loss: 1.0834\n",
      "train error: \n",
      " D loss: 1.351579, G loss: 0.826710, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 70.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337365, G loss: 0.838664, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 71.8% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.7340\n",
      "[84/1762] D loss: 1.4046, G loss: 0.6010\n",
      "[164/1762] D loss: 1.3814, G loss: 0.7831\n",
      "[244/1762] D loss: 1.2567, G loss: 0.8020\n",
      "[324/1762] D loss: 1.2256, G loss: 0.7594\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6224\n",
      "[484/1762] D loss: 1.3811, G loss: 0.6548\n",
      "[564/1762] D loss: 1.3929, G loss: 0.6351\n",
      "[644/1762] D loss: 1.4027, G loss: 0.8146\n",
      "[724/1762] D loss: 1.4094, G loss: 0.7491\n",
      "[804/1762] D loss: 1.2286, G loss: 0.9749\n",
      "[884/1762] D loss: 1.3921, G loss: 0.7041\n",
      "[964/1762] D loss: 1.3907, G loss: 0.6674\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.6548\n",
      "[1124/1762] D loss: 1.2045, G loss: 0.8927\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.6519\n",
      "[1284/1762] D loss: 1.3837, G loss: 0.6462\n",
      "[1364/1762] D loss: 1.3848, G loss: 0.5240\n",
      "[1444/1762] D loss: 1.4246, G loss: 0.5819\n",
      "[1524/1762] D loss: 1.3563, G loss: 0.6747\n",
      "[1604/1762] D loss: 1.0926, G loss: 0.8581\n",
      "[1684/1762] D loss: 1.4278, G loss: 0.8101\n",
      "[1762/1762] D loss: 1.3541, G loss: 0.7344\n",
      "train error: \n",
      " D loss: 1.339229, G loss: 0.781668, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 77.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324446, G loss: 0.792872, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2438, G loss: 0.9504\n",
      "[84/1762] D loss: 0.9933, G loss: 0.9274\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6650\n",
      "[244/1762] D loss: 1.3705, G loss: 0.7741\n",
      "[324/1762] D loss: 1.3798, G loss: 0.6678\n",
      "[404/1762] D loss: 1.3915, G loss: 0.6623\n",
      "[484/1762] D loss: 1.4291, G loss: 0.7564\n",
      "[564/1762] D loss: 1.3859, G loss: 0.6921\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6211\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6955\n",
      "[804/1762] D loss: 1.3915, G loss: 0.6670\n",
      "[884/1762] D loss: 1.2508, G loss: 0.5825\n",
      "[964/1762] D loss: 1.1469, G loss: 0.8561\n",
      "[1044/1762] D loss: 1.3090, G loss: 0.8155\n",
      "[1124/1762] D loss: 1.1602, G loss: 0.9299\n",
      "[1204/1762] D loss: 1.4205, G loss: 0.7743\n",
      "[1284/1762] D loss: 1.3757, G loss: 0.9503\n",
      "[1364/1762] D loss: 1.1468, G loss: 0.7419\n",
      "[1444/1762] D loss: 1.3680, G loss: 0.7588\n",
      "[1524/1762] D loss: 1.1695, G loss: 0.7306\n",
      "[1604/1762] D loss: 1.3656, G loss: 0.7228\n",
      "[1684/1762] D loss: 1.3959, G loss: 0.7374\n",
      "[1762/1762] D loss: 1.3620, G loss: 0.7417\n",
      "train error: \n",
      " D loss: 1.343055, G loss: 0.805971, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328734, G loss: 0.817856, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4448, G loss: 0.7105\n",
      "[84/1762] D loss: 1.3952, G loss: 0.7156\n",
      "[164/1762] D loss: 1.3982, G loss: 0.6549\n",
      "[244/1762] D loss: 1.4347, G loss: 0.7003\n",
      "[324/1762] D loss: 1.4052, G loss: 0.7746\n",
      "[404/1762] D loss: 1.4129, G loss: 0.5515\n",
      "[484/1762] D loss: 1.1674, G loss: 0.9677\n",
      "[564/1762] D loss: 1.2308, G loss: 0.9797\n",
      "[644/1762] D loss: 1.3799, G loss: 0.6167\n",
      "[724/1762] D loss: 1.3968, G loss: 0.6018\n",
      "[804/1762] D loss: 1.3840, G loss: 0.7283\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6292\n",
      "[964/1762] D loss: 1.1801, G loss: 0.9414\n",
      "[1044/1762] D loss: 1.1718, G loss: 0.8542\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6614\n",
      "[1204/1762] D loss: 1.3907, G loss: 0.6346\n",
      "[1284/1762] D loss: 1.1730, G loss: 0.8036\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.6358\n",
      "[1444/1762] D loss: 1.4180, G loss: 0.8546\n",
      "[1524/1762] D loss: 1.3949, G loss: 0.5522\n",
      "[1604/1762] D loss: 1.3564, G loss: 0.6033\n",
      "[1684/1762] D loss: 1.4557, G loss: 0.6150\n",
      "[1762/1762] D loss: 1.4155, G loss: 0.8288\n",
      "train error: \n",
      " D loss: 1.328939, G loss: 0.793656, D accuracy: 54.6%, cell accuracy: 99.6%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311705, G loss: 0.805922, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3712, G loss: 0.6239\n",
      "[84/1762] D loss: 1.3773, G loss: 0.7563\n",
      "[164/1762] D loss: 1.4178, G loss: 0.6455\n",
      "[244/1762] D loss: 1.6472, G loss: 0.5451\n",
      "[324/1762] D loss: 1.1182, G loss: 1.2384\n",
      "[404/1762] D loss: 0.9392, G loss: 0.9254\n",
      "[484/1762] D loss: 1.7645, G loss: 0.2727\n",
      "[564/1762] D loss: 1.4015, G loss: 0.8517\n",
      "[644/1762] D loss: 1.4105, G loss: 0.5882\n",
      "[724/1762] D loss: 1.3818, G loss: 0.6717\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6898\n",
      "[884/1762] D loss: 1.3598, G loss: 0.7011\n",
      "[964/1762] D loss: 1.3930, G loss: 0.6798\n",
      "[1044/1762] D loss: 1.3635, G loss: 0.6115\n",
      "[1124/1762] D loss: 1.3778, G loss: 0.6778\n",
      "[1204/1762] D loss: 1.3584, G loss: 0.6716\n",
      "[1284/1762] D loss: 1.3716, G loss: 0.6360\n",
      "[1364/1762] D loss: 1.3924, G loss: 0.7375\n",
      "[1444/1762] D loss: 1.3913, G loss: 0.6428\n",
      "[1524/1762] D loss: 1.3645, G loss: 0.6631\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6819\n",
      "[1684/1762] D loss: 1.3518, G loss: 0.6478\n",
      "[1762/1762] D loss: 1.2689, G loss: 0.7406\n",
      "train error: \n",
      " D loss: 1.383076, G loss: 0.669664, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380167, G loss: 0.668202, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4029, G loss: 0.6855\n",
      "[84/1762] D loss: 1.3885, G loss: 0.6795\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7418\n",
      "[244/1762] D loss: 1.3958, G loss: 0.7175\n",
      "[324/1762] D loss: 1.3935, G loss: 0.6849\n",
      "[404/1762] D loss: 1.3943, G loss: 0.6988\n",
      "[484/1762] D loss: 1.3908, G loss: 0.6965\n",
      "[564/1762] D loss: 1.3461, G loss: 0.7002\n",
      "[644/1762] D loss: 1.3861, G loss: 0.7167\n",
      "[724/1762] D loss: 1.4012, G loss: 0.6427\n",
      "[804/1762] D loss: 1.3951, G loss: 0.6399\n",
      "[884/1762] D loss: 1.3842, G loss: 0.7387\n",
      "[964/1762] D loss: 1.3423, G loss: 0.7254\n",
      "[1044/1762] D loss: 1.3837, G loss: 0.6827\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.7091\n",
      "[1204/1762] D loss: 1.3460, G loss: 0.6734\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.6676\n",
      "[1444/1762] D loss: 1.3344, G loss: 0.7133\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.6868\n",
      "[1604/1762] D loss: 1.4073, G loss: 0.7097\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.6755\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.7284\n",
      "train error: \n",
      " D loss: 1.375197, G loss: 0.706928, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370326, G loss: 0.707706, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7262\n",
      "[84/1762] D loss: 1.3922, G loss: 0.7021\n",
      "[164/1762] D loss: 1.3942, G loss: 0.7022\n",
      "[244/1762] D loss: 1.3813, G loss: 0.7480\n",
      "[324/1762] D loss: 1.3893, G loss: 0.6641\n",
      "[404/1762] D loss: 1.3369, G loss: 0.7115\n",
      "[484/1762] D loss: 1.3102, G loss: 0.6833\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7110\n",
      "[644/1762] D loss: 1.3765, G loss: 0.7418\n",
      "[724/1762] D loss: 1.3897, G loss: 0.6725\n",
      "[804/1762] D loss: 1.3766, G loss: 0.7272\n",
      "[884/1762] D loss: 1.3031, G loss: 0.7159\n",
      "[964/1762] D loss: 1.3731, G loss: 0.6422\n",
      "[1044/1762] D loss: 1.3675, G loss: 0.7056\n",
      "[1124/1762] D loss: 1.3901, G loss: 0.7046\n",
      "[1204/1762] D loss: 1.2932, G loss: 0.6956\n",
      "[1284/1762] D loss: 1.4028, G loss: 0.5884\n",
      "[1364/1762] D loss: 1.2990, G loss: 0.6598\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.6652\n",
      "[1524/1762] D loss: 1.3958, G loss: 0.7122\n",
      "[1604/1762] D loss: 1.4072, G loss: 0.7042\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6687\n",
      "[1762/1762] D loss: 1.3756, G loss: 0.7888\n",
      "train error: \n",
      " D loss: 1.358003, G loss: 0.752619, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 70.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348272, G loss: 0.757081, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1092, G loss: 0.7621\n",
      "[84/1762] D loss: 1.3918, G loss: 0.7291\n",
      "[164/1762] D loss: 1.2667, G loss: 0.7006\n",
      "[244/1762] D loss: 1.3998, G loss: 0.6447\n",
      "[324/1762] D loss: 1.2491, G loss: 0.6660\n",
      "[404/1762] D loss: 1.3884, G loss: 0.7433\n",
      "[484/1762] D loss: 1.2240, G loss: 0.7598\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6613\n",
      "[644/1762] D loss: 1.3805, G loss: 0.7076\n",
      "[724/1762] D loss: 1.3974, G loss: 0.8580\n",
      "[804/1762] D loss: 1.3146, G loss: 0.5596\n",
      "[884/1762] D loss: 1.3916, G loss: 0.8109\n",
      "[964/1762] D loss: 1.2228, G loss: 0.8831\n",
      "[1044/1762] D loss: 1.1895, G loss: 0.7979\n",
      "[1124/1762] D loss: 1.4013, G loss: 0.7502\n",
      "[1204/1762] D loss: 1.1555, G loss: 0.9657\n",
      "[1284/1762] D loss: 1.4656, G loss: 0.9107\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7805\n",
      "[1444/1762] D loss: 1.4059, G loss: 0.5427\n",
      "[1524/1762] D loss: 1.4107, G loss: 0.8306\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.7043\n",
      "[1684/1762] D loss: 1.4076, G loss: 0.7096\n",
      "[1762/1762] D loss: 0.9788, G loss: 0.9451\n",
      "train error: \n",
      " D loss: 1.332729, G loss: 0.813208, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 75.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315130, G loss: 0.830040, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1563, G loss: 0.9526\n",
      "[84/1762] D loss: 1.3965, G loss: 0.6531\n",
      "[164/1762] D loss: 1.3980, G loss: 0.6039\n",
      "[244/1762] D loss: 1.3689, G loss: 0.7714\n",
      "[324/1762] D loss: 1.3915, G loss: 0.7708\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7126\n",
      "[484/1762] D loss: 1.1562, G loss: 0.9170\n",
      "[564/1762] D loss: 1.1515, G loss: 0.9025\n",
      "[644/1762] D loss: 1.3919, G loss: 0.6748\n",
      "[724/1762] D loss: 1.4127, G loss: 0.7862\n",
      "[804/1762] D loss: 1.3977, G loss: 0.8720\n",
      "[884/1762] D loss: 1.4121, G loss: 0.6186\n",
      "[964/1762] D loss: 1.0866, G loss: 0.9143\n",
      "[1044/1762] D loss: 1.3944, G loss: 0.6485\n",
      "[1124/1762] D loss: 1.1833, G loss: 1.0286\n",
      "[1204/1762] D loss: 1.3948, G loss: 0.7100\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7111\n",
      "[1364/1762] D loss: 1.2218, G loss: 0.8327\n",
      "[1444/1762] D loss: 1.3925, G loss: 0.6494\n",
      "[1524/1762] D loss: 1.4208, G loss: 0.7147\n",
      "[1604/1762] D loss: 1.4388, G loss: 0.6468\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.7675\n",
      "[1762/1762] D loss: 1.1284, G loss: 0.7895\n",
      "train error: \n",
      " D loss: 1.328589, G loss: 0.695422, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307452, G loss: 0.717735, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1456, G loss: 0.9645\n",
      "[84/1762] D loss: 1.1510, G loss: 0.8144\n",
      "[164/1762] D loss: 1.4026, G loss: 0.8156\n",
      "[244/1762] D loss: 1.3916, G loss: 0.5954\n",
      "[324/1762] D loss: 1.2412, G loss: 0.7367\n",
      "[404/1762] D loss: 1.3910, G loss: 0.7622\n",
      "[484/1762] D loss: 1.3422, G loss: 0.6567\n",
      "[564/1762] D loss: 1.6211, G loss: 0.5347\n",
      "[644/1762] D loss: 1.2897, G loss: 0.9909\n",
      "[724/1762] D loss: 1.6116, G loss: 1.0539\n",
      "[804/1762] D loss: 1.3083, G loss: 0.6766\n",
      "[884/1762] D loss: 1.3736, G loss: 0.6992\n",
      "[964/1762] D loss: 1.3836, G loss: 0.6617\n",
      "[1044/1762] D loss: 1.2674, G loss: 0.6985\n",
      "[1124/1762] D loss: 1.2669, G loss: 0.7721\n",
      "[1204/1762] D loss: 1.3959, G loss: 0.7274\n",
      "[1284/1762] D loss: 1.3804, G loss: 0.7516\n",
      "[1364/1762] D loss: 1.3846, G loss: 0.7379\n",
      "[1444/1762] D loss: 1.2519, G loss: 0.7855\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.6763\n",
      "[1604/1762] D loss: 1.3847, G loss: 0.6993\n",
      "[1684/1762] D loss: 1.2477, G loss: 0.7288\n",
      "[1762/1762] D loss: 1.3834, G loss: 0.7291\n",
      "train error: \n",
      " D loss: 1.350833, G loss: 0.729432, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 66.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340979, G loss: 0.727471, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.6843\n",
      "[84/1762] D loss: 1.3688, G loss: 0.7559\n",
      "[164/1762] D loss: 1.3852, G loss: 0.7471\n",
      "[244/1762] D loss: 1.3879, G loss: 0.7491\n",
      "[324/1762] D loss: 1.2337, G loss: 0.7851\n",
      "[404/1762] D loss: 1.3977, G loss: 0.6890\n",
      "[484/1762] D loss: 1.3844, G loss: 0.7149\n",
      "[564/1762] D loss: 1.4002, G loss: 0.7449\n",
      "[644/1762] D loss: 1.3968, G loss: 0.6938\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6848\n",
      "[804/1762] D loss: 1.3908, G loss: 0.7203\n",
      "[884/1762] D loss: 1.3933, G loss: 0.6773\n",
      "[964/1762] D loss: 1.3928, G loss: 0.7150\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.7296\n",
      "[1124/1762] D loss: 1.2133, G loss: 0.7278\n",
      "[1204/1762] D loss: 1.2057, G loss: 0.7382\n",
      "[1284/1762] D loss: 1.3930, G loss: 0.7934\n",
      "[1364/1762] D loss: 1.3811, G loss: 0.7200\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.7313\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.7493\n",
      "[1604/1762] D loss: 1.1996, G loss: 0.8113\n",
      "[1684/1762] D loss: 1.4313, G loss: 0.7883\n",
      "[1762/1762] D loss: 1.5085, G loss: 0.6592\n",
      "train error: \n",
      " D loss: 1.343570, G loss: 0.749256, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329657, G loss: 0.751446, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4999, G loss: 0.6623\n",
      "[84/1762] D loss: 1.4546, G loss: 0.6659\n",
      "[164/1762] D loss: 1.3282, G loss: 0.9573\n",
      "[244/1762] D loss: 1.4896, G loss: 0.6949\n",
      "[324/1762] D loss: 1.4747, G loss: 0.6068\n",
      "[404/1762] D loss: 1.3397, G loss: 0.8670\n",
      "[484/1762] D loss: 1.4308, G loss: 0.9318\n",
      "[564/1762] D loss: 1.4104, G loss: 0.8341\n",
      "[644/1762] D loss: 1.3981, G loss: 0.7459\n",
      "[724/1762] D loss: 1.3421, G loss: 0.6795\n",
      "[804/1762] D loss: 1.3474, G loss: 0.7180\n",
      "[884/1762] D loss: 1.3929, G loss: 0.7227\n",
      "[964/1762] D loss: 1.3922, G loss: 0.6933\n",
      "[1044/1762] D loss: 1.2715, G loss: 0.7148\n",
      "[1124/1762] D loss: 1.4098, G loss: 0.6532\n",
      "[1204/1762] D loss: 1.3889, G loss: 0.7394\n",
      "[1284/1762] D loss: 1.2694, G loss: 0.7175\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7562\n",
      "[1444/1762] D loss: 1.2515, G loss: 0.7338\n",
      "[1524/1762] D loss: 1.3848, G loss: 0.7505\n",
      "[1604/1762] D loss: 1.3781, G loss: 0.6668\n",
      "[1684/1762] D loss: 1.3775, G loss: 0.7065\n",
      "[1762/1762] D loss: 1.1045, G loss: 0.6992\n",
      "train error: \n",
      " D loss: 1.356201, G loss: 0.705160, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349069, G loss: 0.700901, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3783, G loss: 0.6686\n",
      "[84/1762] D loss: 1.3847, G loss: 0.7045\n",
      "[164/1762] D loss: 1.4137, G loss: 0.6523\n",
      "[244/1762] D loss: 1.1145, G loss: 0.7348\n",
      "[324/1762] D loss: 1.2397, G loss: 0.7110\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7074\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7301\n",
      "[564/1762] D loss: 1.2414, G loss: 0.6601\n",
      "[644/1762] D loss: 1.2286, G loss: 0.8101\n",
      "[724/1762] D loss: 1.3843, G loss: 0.7190\n",
      "[804/1762] D loss: 1.4516, G loss: 0.6444\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7202\n",
      "[964/1762] D loss: 1.3934, G loss: 0.7947\n",
      "[1044/1762] D loss: 1.2174, G loss: 0.7394\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6870\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.7244\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.7233\n",
      "[1364/1762] D loss: 1.3970, G loss: 0.6402\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.7134\n",
      "[1524/1762] D loss: 1.3817, G loss: 0.7567\n",
      "[1604/1762] D loss: 1.2187, G loss: 0.7887\n",
      "[1684/1762] D loss: 1.2321, G loss: 0.8075\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6900\n",
      "train error: \n",
      " D loss: 1.349319, G loss: 0.744347, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339863, G loss: 0.743333, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4061, G loss: 0.6870\n",
      "[84/1762] D loss: 1.3631, G loss: 0.7023\n",
      "[164/1762] D loss: 1.4012, G loss: 0.5935\n",
      "[244/1762] D loss: 1.4645, G loss: 0.7327\n",
      "[324/1762] D loss: 1.2751, G loss: 0.7704\n",
      "[404/1762] D loss: 1.3696, G loss: 0.7060\n",
      "[484/1762] D loss: 1.3840, G loss: 0.6299\n",
      "[564/1762] D loss: 1.2585, G loss: 0.7659\n",
      "[644/1762] D loss: 1.3829, G loss: 0.7051\n",
      "[724/1762] D loss: 1.3618, G loss: 0.7359\n",
      "[804/1762] D loss: 1.3817, G loss: 0.6590\n",
      "[884/1762] D loss: 1.3714, G loss: 0.6990\n",
      "[964/1762] D loss: 1.3818, G loss: 0.7720\n",
      "[1044/1762] D loss: 1.2176, G loss: 0.7157\n",
      "[1124/1762] D loss: 1.3808, G loss: 0.7406\n",
      "[1204/1762] D loss: 1.4133, G loss: 0.8917\n",
      "[1284/1762] D loss: 1.2619, G loss: 0.7203\n",
      "[1364/1762] D loss: 1.3797, G loss: 0.6998\n",
      "[1444/1762] D loss: 1.3856, G loss: 0.7063\n",
      "[1524/1762] D loss: 1.3306, G loss: 0.7422\n",
      "[1604/1762] D loss: 1.3302, G loss: 0.8185\n",
      "[1684/1762] D loss: 1.3906, G loss: 0.8157\n",
      "[1762/1762] D loss: 1.4383, G loss: 0.5311\n",
      "train error: \n",
      " D loss: 1.339405, G loss: 0.649213, D accuracy: 56.0%, cell accuracy: 99.4%, board accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326401, G loss: 0.654469, D accuracy: 57.5%, cell accuracy: 99.4%, board accuracy: 52.5% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3685, G loss: 0.7904\n",
      "[84/1762] D loss: 1.3695, G loss: 0.6789\n",
      "[164/1762] D loss: 1.3834, G loss: 0.7652\n",
      "[244/1762] D loss: 1.2523, G loss: 0.6289\n",
      "[324/1762] D loss: 1.3397, G loss: 0.7221\n",
      "[404/1762] D loss: 1.3529, G loss: 0.7676\n",
      "[484/1762] D loss: 1.2582, G loss: 0.9769\n",
      "[564/1762] D loss: 0.9256, G loss: 0.8650\n",
      "[644/1762] D loss: 1.2878, G loss: 1.0132\n",
      "[724/1762] D loss: 1.0559, G loss: 0.8692\n",
      "[804/1762] D loss: 1.3300, G loss: 0.7434\n",
      "[884/1762] D loss: 1.3230, G loss: 0.7720\n",
      "[964/1762] D loss: 1.2618, G loss: 0.6697\n",
      "[1044/1762] D loss: 1.4089, G loss: 0.6124\n",
      "[1124/1762] D loss: 1.3752, G loss: 0.7333\n",
      "[1204/1762] D loss: 1.4199, G loss: 0.8618\n",
      "[1284/1762] D loss: 1.4094, G loss: 0.8630\n",
      "[1364/1762] D loss: 1.0995, G loss: 0.7702\n",
      "[1444/1762] D loss: 1.4109, G loss: 0.6176\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.6907\n",
      "[1604/1762] D loss: 1.3812, G loss: 0.7021\n",
      "[1684/1762] D loss: 1.4075, G loss: 0.7548\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6714\n",
      "train error: \n",
      " D loss: 1.346243, G loss: 0.731555, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 79.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335565, G loss: 0.736630, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3818, G loss: 0.7015\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6842\n",
      "[164/1762] D loss: 1.3897, G loss: 0.7163\n",
      "[244/1762] D loss: 1.2284, G loss: 0.7859\n",
      "[324/1762] D loss: 1.2119, G loss: 0.8101\n",
      "[404/1762] D loss: 1.4021, G loss: 0.7778\n",
      "[484/1762] D loss: 1.3831, G loss: 0.7371\n",
      "[564/1762] D loss: 1.3974, G loss: 0.8240\n",
      "[644/1762] D loss: 1.0138, G loss: 0.7295\n",
      "[724/1762] D loss: 1.4004, G loss: 0.8241\n",
      "[804/1762] D loss: 1.3859, G loss: 0.7113\n",
      "[884/1762] D loss: 1.3887, G loss: 0.7226\n",
      "[964/1762] D loss: 1.4224, G loss: 0.5833\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7132\n",
      "[1124/1762] D loss: 1.2208, G loss: 0.6486\n",
      "[1204/1762] D loss: 1.3960, G loss: 0.7464\n",
      "[1284/1762] D loss: 1.1907, G loss: 0.8561\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.7622\n",
      "[1444/1762] D loss: 1.3908, G loss: 0.7482\n",
      "[1524/1762] D loss: 1.4632, G loss: 0.7508\n",
      "[1604/1762] D loss: 1.3695, G loss: 0.7460\n",
      "[1684/1762] D loss: 1.1940, G loss: 0.7263\n",
      "[1762/1762] D loss: 1.3544, G loss: 0.6957\n",
      "train error: \n",
      " D loss: 1.328574, G loss: 0.728979, D accuracy: 64.6%, cell accuracy: 99.4%, board accuracy: 24.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318266, G loss: 0.732040, D accuracy: 66.4%, cell accuracy: 99.4%, board accuracy: 23.6% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1229, G loss: 0.7568\n",
      "[84/1762] D loss: 1.3571, G loss: 0.6694\n",
      "[164/1762] D loss: 1.0780, G loss: 0.7534\n",
      "[244/1762] D loss: 1.3773, G loss: 0.6681\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6797\n",
      "[404/1762] D loss: 1.3782, G loss: 0.7735\n",
      "[484/1762] D loss: 1.3874, G loss: 0.7176\n",
      "[564/1762] D loss: 1.3427, G loss: 0.7335\n",
      "[644/1762] D loss: 1.3871, G loss: 0.7023\n",
      "[724/1762] D loss: 1.3901, G loss: 0.8006\n",
      "[804/1762] D loss: 1.1883, G loss: 0.7206\n",
      "[884/1762] D loss: 1.3876, G loss: 0.7349\n",
      "[964/1762] D loss: 1.3956, G loss: 0.7916\n",
      "[1044/1762] D loss: 1.3837, G loss: 0.8185\n",
      "[1124/1762] D loss: 1.1776, G loss: 0.8238\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.6848\n",
      "[1284/1762] D loss: 1.4092, G loss: 0.5768\n",
      "[1364/1762] D loss: 1.3987, G loss: 0.8199\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.7683\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.7592\n",
      "[1604/1762] D loss: 1.2110, G loss: 0.7201\n",
      "[1684/1762] D loss: 1.4499, G loss: 0.7089\n",
      "[1762/1762] D loss: 1.3737, G loss: 0.6683\n",
      "train error: \n",
      " D loss: 1.333893, G loss: 0.722846, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 78.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319829, G loss: 0.732454, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.6896\n",
      "[84/1762] D loss: 1.4307, G loss: 0.8071\n",
      "[164/1762] D loss: 1.1330, G loss: 0.8847\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7969\n",
      "[324/1762] D loss: 1.3886, G loss: 0.7265\n",
      "[404/1762] D loss: 1.1735, G loss: 0.9717\n",
      "[484/1762] D loss: 1.4129, G loss: 0.7017\n",
      "[564/1762] D loss: 1.3939, G loss: 0.6804\n",
      "[644/1762] D loss: 1.3343, G loss: 0.7287\n",
      "[724/1762] D loss: 1.3838, G loss: 0.6399\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6726\n",
      "[884/1762] D loss: 1.1395, G loss: 0.9193\n",
      "[964/1762] D loss: 1.3921, G loss: 0.7569\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.7450\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6946\n",
      "[1204/1762] D loss: 1.1478, G loss: 0.7922\n",
      "[1284/1762] D loss: 1.4057, G loss: 0.5989\n",
      "[1364/1762] D loss: 1.4173, G loss: 0.7504\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.6554\n",
      "[1524/1762] D loss: 1.2310, G loss: 0.6417\n",
      "[1604/1762] D loss: 1.4066, G loss: 0.6647\n",
      "[1684/1762] D loss: 0.9421, G loss: 0.9849\n",
      "[1762/1762] D loss: 1.3517, G loss: 0.8013\n",
      "train error: \n",
      " D loss: 1.335505, G loss: 0.864823, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 80.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316324, G loss: 0.879477, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4006, G loss: 0.8132\n",
      "[84/1762] D loss: 1.3935, G loss: 0.7197\n",
      "[164/1762] D loss: 1.4088, G loss: 0.9170\n",
      "[244/1762] D loss: 1.3844, G loss: 0.6746\n",
      "[324/1762] D loss: 1.4042, G loss: 0.5726\n",
      "[404/1762] D loss: 1.1694, G loss: 0.9773\n",
      "[484/1762] D loss: 1.1700, G loss: 0.8899\n",
      "[564/1762] D loss: 1.3847, G loss: 0.7838\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6819\n",
      "[724/1762] D loss: 1.1781, G loss: 0.7620\n",
      "[804/1762] D loss: 1.3599, G loss: 0.6488\n",
      "[884/1762] D loss: 1.0981, G loss: 0.9949\n",
      "[964/1762] D loss: 1.3973, G loss: 0.8831\n",
      "[1044/1762] D loss: 1.3823, G loss: 0.6276\n",
      "[1124/1762] D loss: 1.1839, G loss: 0.7461\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6460\n",
      "[1284/1762] D loss: 1.3946, G loss: 0.6848\n",
      "[1364/1762] D loss: 1.3973, G loss: 0.6584\n",
      "[1444/1762] D loss: 1.2138, G loss: 0.9070\n",
      "[1524/1762] D loss: 1.3775, G loss: 0.6306\n",
      "[1604/1762] D loss: 1.3670, G loss: 0.8117\n",
      "[1684/1762] D loss: 0.8669, G loss: 1.0226\n",
      "[1762/1762] D loss: 0.8388, G loss: 1.1528\n",
      "train error: \n",
      " D loss: 1.317873, G loss: 0.724771, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 78.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298347, G loss: 0.746189, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1292, G loss: 0.9019\n",
      "[84/1762] D loss: 1.3925, G loss: 0.5719\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6897\n",
      "[244/1762] D loss: 1.4857, G loss: 0.8012\n",
      "[324/1762] D loss: 1.4650, G loss: 0.5716\n",
      "[404/1762] D loss: 1.4414, G loss: 0.6550\n",
      "[484/1762] D loss: 1.3750, G loss: 0.6656\n",
      "[564/1762] D loss: 1.3881, G loss: 0.8523\n",
      "[644/1762] D loss: 1.1570, G loss: 0.8270\n",
      "[724/1762] D loss: 1.3573, G loss: 0.7780\n",
      "[804/1762] D loss: 1.3328, G loss: 0.7211\n",
      "[884/1762] D loss: 1.1142, G loss: 0.9286\n",
      "[964/1762] D loss: 1.1560, G loss: 1.0024\n",
      "[1044/1762] D loss: 1.4225, G loss: 0.5419\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.6536\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1284/1762] D loss: 1.4031, G loss: 0.6856\n",
      "[1364/1762] D loss: 1.1310, G loss: 0.9021\n",
      "[1444/1762] D loss: 1.3930, G loss: 0.6553\n",
      "[1524/1762] D loss: 1.0773, G loss: 1.1527\n",
      "[1604/1762] D loss: 1.4101, G loss: 0.7692\n",
      "[1684/1762] D loss: 0.9834, G loss: 0.7849\n",
      "[1762/1762] D loss: 0.9015, G loss: 1.0283\n",
      "train error: \n",
      " D loss: 1.325884, G loss: 0.679322, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305042, G loss: 0.699099, D accuracy: 56.5%, cell accuracy: 99.6%, board accuracy: 56.1% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3991, G loss: 0.6441\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6988\n",
      "[164/1762] D loss: 1.5269, G loss: 0.6769\n",
      "[244/1762] D loss: 1.4004, G loss: 0.6448\n",
      "[324/1762] D loss: 1.3990, G loss: 0.6731\n",
      "[404/1762] D loss: 1.3917, G loss: 0.7729\n",
      "[484/1762] D loss: 1.3961, G loss: 0.7492\n",
      "[564/1762] D loss: 1.4070, G loss: 0.5820\n",
      "[644/1762] D loss: 1.1342, G loss: 0.8889\n",
      "[724/1762] D loss: 1.3777, G loss: 0.7044\n",
      "[804/1762] D loss: 0.6009, G loss: 1.4250\n",
      "[884/1762] D loss: 1.3774, G loss: 0.6744\n",
      "[964/1762] D loss: 1.1559, G loss: 0.9308\n",
      "[1044/1762] D loss: 1.1478, G loss: 0.8224\n",
      "[1124/1762] D loss: 1.3911, G loss: 0.8005\n",
      "[1204/1762] D loss: 1.3511, G loss: 0.6893\n",
      "[1284/1762] D loss: 1.3849, G loss: 0.6754\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7636\n",
      "[1444/1762] D loss: 1.3825, G loss: 0.6859\n",
      "[1524/1762] D loss: 0.9902, G loss: 0.7783\n",
      "[1604/1762] D loss: 1.2268, G loss: 0.8049\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.6516\n",
      "[1762/1762] D loss: 1.2934, G loss: 0.9768\n",
      "train error: \n",
      " D loss: 1.320748, G loss: 0.862488, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 78.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299621, G loss: 0.895798, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4135, G loss: 0.9505\n",
      "[84/1762] D loss: 1.1527, G loss: 0.8076\n",
      "[164/1762] D loss: 1.3942, G loss: 0.6851\n",
      "[244/1762] D loss: 1.1010, G loss: 0.9777\n",
      "[324/1762] D loss: 1.1081, G loss: 1.0089\n",
      "[404/1762] D loss: 1.1525, G loss: 0.9840\n",
      "[484/1762] D loss: 1.4116, G loss: 0.7635\n",
      "[564/1762] D loss: 0.7923, G loss: 1.4278\n",
      "[644/1762] D loss: 1.3913, G loss: 0.7178\n",
      "[724/1762] D loss: 1.4244, G loss: 0.5210\n",
      "[804/1762] D loss: 1.3927, G loss: 0.7081\n",
      "[884/1762] D loss: 1.3685, G loss: 0.8033\n",
      "[964/1762] D loss: 1.3937, G loss: 0.7151\n",
      "[1044/1762] D loss: 1.3646, G loss: 0.7777\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.7531\n",
      "[1204/1762] D loss: 1.4034, G loss: 0.6998\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6474\n",
      "[1364/1762] D loss: 1.1212, G loss: 0.7970\n",
      "[1444/1762] D loss: 1.4104, G loss: 0.7545\n",
      "[1524/1762] D loss: 1.1008, G loss: 1.1804\n",
      "[1604/1762] D loss: 1.2921, G loss: 0.8311\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.7086\n",
      "[1762/1762] D loss: 0.7981, G loss: 1.2931\n",
      "train error: \n",
      " D loss: 1.308200, G loss: 0.805071, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 68.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285860, G loss: 0.845888, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 64.3% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0811, G loss: 1.1888\n",
      "[84/1762] D loss: 1.0621, G loss: 1.0261\n",
      "[164/1762] D loss: 1.3395, G loss: 0.6655\n",
      "[244/1762] D loss: 1.3802, G loss: 0.6781\n",
      "[324/1762] D loss: 1.3948, G loss: 0.6377\n",
      "[404/1762] D loss: 1.5629, G loss: 0.5778\n",
      "[484/1762] D loss: 1.4677, G loss: 0.8293\n",
      "[564/1762] D loss: 1.1927, G loss: 0.6840\n",
      "[644/1762] D loss: 1.3929, G loss: 0.7109\n",
      "[724/1762] D loss: 1.1090, G loss: 0.9580\n",
      "[804/1762] D loss: 1.3312, G loss: 0.7979\n",
      "[884/1762] D loss: 1.3956, G loss: 0.6768\n",
      "[964/1762] D loss: 1.1061, G loss: 1.0446\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.9609\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.7807\n",
      "[1204/1762] D loss: 1.3914, G loss: 0.6582\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6704\n",
      "[1364/1762] D loss: 1.4227, G loss: 0.8047\n",
      "[1444/1762] D loss: 1.3970, G loss: 0.7526\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.6857\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.6244\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6849\n",
      "[1762/1762] D loss: 1.4083, G loss: 0.5719\n",
      "train error: \n",
      " D loss: 1.308120, G loss: 0.770476, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280392, G loss: 0.818841, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7113\n",
      "[84/1762] D loss: 1.3966, G loss: 0.7827\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7068\n",
      "[244/1762] D loss: 1.3896, G loss: 0.7296\n",
      "[324/1762] D loss: 1.3970, G loss: 0.6906\n",
      "[404/1762] D loss: 1.3903, G loss: 0.7001\n",
      "[484/1762] D loss: 1.0884, G loss: 0.9961\n",
      "[564/1762] D loss: 1.3938, G loss: 0.6021\n",
      "[644/1762] D loss: 1.4004, G loss: 0.5697\n",
      "[724/1762] D loss: 1.0544, G loss: 1.3610\n",
      "[804/1762] D loss: 1.0817, G loss: 1.0869\n",
      "[884/1762] D loss: 1.0703, G loss: 1.0983\n",
      "[964/1762] D loss: 1.0603, G loss: 1.5754\n",
      "[1044/1762] D loss: 1.3733, G loss: 0.6485\n",
      "[1124/1762] D loss: 1.3385, G loss: 0.6226\n",
      "[1204/1762] D loss: 1.3923, G loss: 0.7105\n",
      "[1284/1762] D loss: 1.4896, G loss: 0.4270\n",
      "[1364/1762] D loss: 1.3918, G loss: 0.6693\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6754\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.6252\n",
      "[1604/1762] D loss: 1.4220, G loss: 0.5177\n",
      "[1684/1762] D loss: 1.3947, G loss: 0.8292\n",
      "[1762/1762] D loss: 1.3961, G loss: 0.7016\n",
      "train error: \n",
      " D loss: 1.305818, G loss: 0.827606, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 76.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276112, G loss: 0.883150, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 72.5% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0639, G loss: 1.2630\n",
      "[84/1762] D loss: 1.0562, G loss: 1.4798\n",
      "[164/1762] D loss: 1.1325, G loss: 0.7836\n",
      "[244/1762] D loss: 1.1241, G loss: 0.8627\n",
      "[324/1762] D loss: 1.3835, G loss: 0.6828\n",
      "[404/1762] D loss: 1.3814, G loss: 0.7332\n",
      "[484/1762] D loss: 1.0758, G loss: 1.0624\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6445\n",
      "[644/1762] D loss: 1.3897, G loss: 0.7253\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6788\n",
      "[804/1762] D loss: 1.0918, G loss: 1.1502\n",
      "[884/1762] D loss: 1.3896, G loss: 0.7631\n",
      "[964/1762] D loss: 1.3483, G loss: 0.8273\n",
      "[1044/1762] D loss: 1.1092, G loss: 1.0259\n",
      "[1124/1762] D loss: 1.1651, G loss: 0.8057\n",
      "[1204/1762] D loss: 1.3918, G loss: 0.7593\n",
      "[1284/1762] D loss: 1.4270, G loss: 0.8780\n",
      "[1364/1762] D loss: 1.2927, G loss: 0.8081\n",
      "[1444/1762] D loss: 1.2453, G loss: 0.9923\n",
      "[1524/1762] D loss: 1.3689, G loss: 0.7190\n",
      "[1604/1762] D loss: 1.3954, G loss: 0.7408\n",
      "[1684/1762] D loss: 1.0621, G loss: 1.5320\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.6041\n",
      "train error: \n",
      " D loss: 1.325305, G loss: 0.697258, D accuracy: 54.5%, cell accuracy: 99.5%, board accuracy: 44.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299837, G loss: 0.732196, D accuracy: 55.8%, cell accuracy: 99.4%, board accuracy: 42.3% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3759, G loss: 0.6693\n",
      "[84/1762] D loss: 1.4097, G loss: 0.5577\n",
      "[164/1762] D loss: 1.4022, G loss: 0.8336\n",
      "[244/1762] D loss: 1.3952, G loss: 0.7947\n",
      "[324/1762] D loss: 1.3948, G loss: 0.7191\n",
      "[404/1762] D loss: 1.4581, G loss: 0.7696\n",
      "[484/1762] D loss: 1.3971, G loss: 0.6076\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6519\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6481\n",
      "[724/1762] D loss: 1.1138, G loss: 0.8835\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7665\n",
      "[884/1762] D loss: 1.3884, G loss: 0.7089\n",
      "[964/1762] D loss: 1.3074, G loss: 0.8851\n",
      "[1044/1762] D loss: 1.3847, G loss: 0.7694\n",
      "[1124/1762] D loss: 1.4375, G loss: 0.5803\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.7797\n",
      "[1284/1762] D loss: 1.1249, G loss: 1.0596\n",
      "[1364/1762] D loss: 1.1573, G loss: 0.8054\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.6262\n",
      "[1524/1762] D loss: 1.4201, G loss: 0.8161\n",
      "[1604/1762] D loss: 1.3852, G loss: 0.7086\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6994\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.6021\n",
      "train error: \n",
      " D loss: 1.313767, G loss: 0.727416, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289627, G loss: 0.765676, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3849, G loss: 0.6619\n",
      "[84/1762] D loss: 1.3588, G loss: 0.6500\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6861\n",
      "[244/1762] D loss: 0.9274, G loss: 1.0587\n",
      "[324/1762] D loss: 1.0898, G loss: 1.1745\n",
      "[404/1762] D loss: 1.3911, G loss: 0.6819\n",
      "[484/1762] D loss: 1.1772, G loss: 0.7691\n",
      "[564/1762] D loss: 1.4223, G loss: 0.6130\n",
      "[644/1762] D loss: 1.1016, G loss: 0.8186\n",
      "[724/1762] D loss: 1.4123, G loss: 0.7066\n",
      "[804/1762] D loss: 1.4396, G loss: 0.5919\n",
      "[884/1762] D loss: 1.3899, G loss: 0.7362\n",
      "[964/1762] D loss: 1.3923, G loss: 0.7251\n",
      "[1044/1762] D loss: 1.4058, G loss: 0.6673\n",
      "[1124/1762] D loss: 1.3979, G loss: 0.7345\n",
      "[1204/1762] D loss: 1.3946, G loss: 0.6867\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.6539\n",
      "[1364/1762] D loss: 1.0809, G loss: 1.1403\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.6575\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.6741\n",
      "[1604/1762] D loss: 1.2333, G loss: 0.6318\n",
      "[1684/1762] D loss: 1.3624, G loss: 0.7290\n",
      "[1762/1762] D loss: 1.3787, G loss: 0.6766\n",
      "train error: \n",
      " D loss: 1.299223, G loss: 0.824827, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272590, G loss: 0.895053, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 52.3% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3602, G loss: 0.6757\n",
      "[84/1762] D loss: 1.4163, G loss: 0.9094\n",
      "[164/1762] D loss: 1.1032, G loss: 1.0424\n",
      "[244/1762] D loss: 1.4005, G loss: 0.5997\n",
      "[324/1762] D loss: 1.3939, G loss: 0.7199\n",
      "[404/1762] D loss: 1.3907, G loss: 0.6132\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6867\n",
      "[564/1762] D loss: 1.3762, G loss: 0.8501\n",
      "[644/1762] D loss: 1.3917, G loss: 0.7494\n",
      "[724/1762] D loss: 1.3950, G loss: 0.7038\n",
      "[804/1762] D loss: 1.3870, G loss: 0.7295\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[964/1762] D loss: 1.1052, G loss: 2.0539\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.7117\n",
      "[1124/1762] D loss: 1.2952, G loss: 0.5416\n",
      "[1204/1762] D loss: 1.3542, G loss: 0.7456\n",
      "[1284/1762] D loss: 1.0871, G loss: 1.5352\n",
      "[1364/1762] D loss: 1.3905, G loss: 0.7961\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6943\n",
      "[1524/1762] D loss: 1.4562, G loss: 0.8176\n",
      "[1604/1762] D loss: 1.1197, G loss: 0.8116\n",
      "[1684/1762] D loss: 1.1333, G loss: 0.8280\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6252\n",
      "train error: \n",
      " D loss: 1.345622, G loss: 0.624175, D accuracy: 52.1%, cell accuracy: 99.7%, board accuracy: 69.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323672, G loss: 0.644474, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 63.9% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3859, G loss: 0.6917\n",
      "[84/1762] D loss: 1.0662, G loss: 1.9618\n",
      "[164/1762] D loss: 1.4553, G loss: 0.8991\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6695\n",
      "[324/1762] D loss: 1.1874, G loss: 0.7606\n",
      "[404/1762] D loss: 1.3843, G loss: 0.6886\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6832\n",
      "[564/1762] D loss: 1.3961, G loss: 0.6429\n",
      "[644/1762] D loss: 1.3802, G loss: 1.1246\n",
      "[724/1762] D loss: 1.3882, G loss: 0.6661\n",
      "[804/1762] D loss: 1.0719, G loss: 1.1669\n",
      "[884/1762] D loss: 1.4503, G loss: 0.6080\n",
      "[964/1762] D loss: 1.2292, G loss: 0.9099\n",
      "[1044/1762] D loss: 1.3975, G loss: 0.8026\n",
      "[1124/1762] D loss: 1.1846, G loss: 0.7650\n",
      "[1204/1762] D loss: 1.4013, G loss: 0.6272\n",
      "[1284/1762] D loss: 1.3520, G loss: 0.8382\n",
      "[1364/1762] D loss: 1.4030, G loss: 0.5916\n",
      "[1444/1762] D loss: 1.3820, G loss: 0.7191\n",
      "[1524/1762] D loss: 1.4051, G loss: 0.7216\n",
      "[1604/1762] D loss: 1.2308, G loss: 0.6936\n",
      "[1684/1762] D loss: 1.3841, G loss: 0.7561\n",
      "[1762/1762] D loss: 1.4226, G loss: 0.5269\n",
      "train error: \n",
      " D loss: 1.316150, G loss: 0.730213, D accuracy: 56.3%, cell accuracy: 98.8%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301468, G loss: 0.748901, D accuracy: 55.3%, cell accuracy: 98.7%, board accuracy: 14.8% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3765, G loss: 0.6227\n",
      "[84/1762] D loss: 1.3857, G loss: 0.6602\n",
      "[164/1762] D loss: 1.3797, G loss: 0.6324\n",
      "[244/1762] D loss: 1.3906, G loss: 0.6786\n",
      "[324/1762] D loss: 1.3308, G loss: 0.7621\n",
      "[404/1762] D loss: 1.3927, G loss: 0.7295\n",
      "[484/1762] D loss: 1.3770, G loss: 0.7181\n",
      "[564/1762] D loss: 1.3927, G loss: 0.7155\n",
      "[644/1762] D loss: 1.3572, G loss: 0.7567\n",
      "[724/1762] D loss: 1.3555, G loss: 0.6747\n",
      "[804/1762] D loss: 1.3763, G loss: 0.7325\n",
      "[884/1762] D loss: 1.0319, G loss: 1.4520\n",
      "[964/1762] D loss: 1.3543, G loss: 0.7205\n",
      "[1044/1762] D loss: 1.1617, G loss: 0.6847\n",
      "[1124/1762] D loss: 1.4072, G loss: 0.5818\n",
      "[1204/1762] D loss: 1.4128, G loss: 1.0307\n",
      "[1284/1762] D loss: 1.0844, G loss: 1.0767\n",
      "[1364/1762] D loss: 1.3529, G loss: 0.6700\n",
      "[1444/1762] D loss: 1.3810, G loss: 0.6952\n",
      "[1524/1762] D loss: 1.3604, G loss: 0.8634\n",
      "[1604/1762] D loss: 1.3822, G loss: 0.6894\n",
      "[1684/1762] D loss: 1.2568, G loss: 0.6673\n",
      "[1762/1762] D loss: 1.4279, G loss: 0.7623\n",
      "train error: \n",
      " D loss: 1.346598, G loss: 0.695443, D accuracy: 51.9%, cell accuracy: 99.4%, board accuracy: 40.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337626, G loss: 0.702199, D accuracy: 52.2%, cell accuracy: 99.3%, board accuracy: 40.5% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.7598\n",
      "[84/1762] D loss: 1.1604, G loss: 0.8846\n",
      "[164/1762] D loss: 1.1349, G loss: 0.9026\n",
      "[244/1762] D loss: 1.3961, G loss: 0.5545\n",
      "[324/1762] D loss: 1.6750, G loss: 0.6813\n",
      "[404/1762] D loss: 1.3893, G loss: 0.8829\n",
      "[484/1762] D loss: 1.1768, G loss: 0.7933\n",
      "[564/1762] D loss: 1.2672, G loss: 0.8739\n",
      "[644/1762] D loss: 1.1549, G loss: 0.8876\n",
      "[724/1762] D loss: 1.1485, G loss: 0.8965\n",
      "[804/1762] D loss: 1.3671, G loss: 0.7778\n",
      "[884/1762] D loss: 1.3722, G loss: 0.8266\n",
      "[964/1762] D loss: 1.4150, G loss: 0.5960\n",
      "[1044/1762] D loss: 1.4087, G loss: 0.5895\n",
      "[1124/1762] D loss: 1.3976, G loss: 0.7558\n",
      "[1204/1762] D loss: 1.4281, G loss: 0.8752\n",
      "[1284/1762] D loss: 1.3803, G loss: 0.7004\n",
      "[1364/1762] D loss: 1.2495, G loss: 0.6751\n",
      "[1444/1762] D loss: 1.2712, G loss: 0.7682\n",
      "[1524/1762] D loss: 1.3859, G loss: 0.7293\n",
      "[1604/1762] D loss: 1.3981, G loss: 0.8015\n",
      "[1684/1762] D loss: 1.4181, G loss: 0.6994\n",
      "[1762/1762] D loss: 1.4867, G loss: 0.6173\n",
      "train error: \n",
      " D loss: 1.350432, G loss: 0.731402, D accuracy: 53.0%, cell accuracy: 99.6%, board accuracy: 53.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343485, G loss: 0.730437, D accuracy: 53.6%, cell accuracy: 99.5%, board accuracy: 51.6% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.7137\n",
      "[84/1762] D loss: 1.3905, G loss: 0.7449\n",
      "[164/1762] D loss: 1.2309, G loss: 0.7883\n",
      "[244/1762] D loss: 1.3862, G loss: 0.7122\n",
      "[324/1762] D loss: 1.3828, G loss: 0.6841\n",
      "[404/1762] D loss: 1.3858, G loss: 0.6937\n",
      "[484/1762] D loss: 1.0341, G loss: 0.7869\n",
      "[564/1762] D loss: 1.4087, G loss: 0.6189\n",
      "[644/1762] D loss: 1.3745, G loss: 0.7503\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6639\n",
      "[804/1762] D loss: 1.3790, G loss: 0.6594\n",
      "[884/1762] D loss: 1.1590, G loss: 0.7691\n",
      "[964/1762] D loss: 1.3834, G loss: 0.6764\n",
      "[1044/1762] D loss: 1.3850, G loss: 0.6733\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7082\n",
      "[1204/1762] D loss: 1.4159, G loss: 0.6174\n",
      "[1284/1762] D loss: 1.3844, G loss: 0.7251\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6390\n",
      "[1444/1762] D loss: 1.4281, G loss: 0.8245\n",
      "[1524/1762] D loss: 1.4329, G loss: 0.7842\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.7525\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.7349\n",
      "[1762/1762] D loss: 1.1177, G loss: 0.6605\n",
      "train error: \n",
      " D loss: 1.335913, G loss: 0.736336, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325522, G loss: 0.743718, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 59.8% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.7750\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6770\n",
      "[164/1762] D loss: 1.3895, G loss: 0.7181\n",
      "[244/1762] D loss: 1.3761, G loss: 0.7567\n",
      "[324/1762] D loss: 0.9927, G loss: 0.7880\n",
      "[404/1762] D loss: 1.1905, G loss: 0.7595\n",
      "[484/1762] D loss: 1.3889, G loss: 0.7244\n",
      "[564/1762] D loss: 1.3829, G loss: 0.7191\n",
      "[644/1762] D loss: 1.3846, G loss: 0.6645\n",
      "[724/1762] D loss: 1.3906, G loss: 0.6774\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6740\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6521\n",
      "[964/1762] D loss: 1.2409, G loss: 0.6923\n",
      "[1044/1762] D loss: 1.1740, G loss: 0.7563\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.7615\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.6898\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.6584\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.6743\n",
      "[1444/1762] D loss: 1.3954, G loss: 0.7066\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.7075\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.6881\n",
      "[1684/1762] D loss: 1.3832, G loss: 0.7157\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6650\n",
      "train error: \n",
      " D loss: 1.328434, G loss: 0.702411, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 71.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316276, G loss: 0.709853, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3848, G loss: 0.7242\n",
      "[84/1762] D loss: 1.0612, G loss: 0.7628\n",
      "[164/1762] D loss: 1.3998, G loss: 0.7902\n",
      "[244/1762] D loss: 1.3992, G loss: 0.7509\n",
      "[324/1762] D loss: 1.4023, G loss: 0.5685\n",
      "[404/1762] D loss: 1.3298, G loss: 0.6803\n",
      "[484/1762] D loss: 1.3697, G loss: 0.7629\n",
      "[564/1762] D loss: 1.1370, G loss: 0.7305\n",
      "[644/1762] D loss: 1.2166, G loss: 0.7343\n",
      "[724/1762] D loss: 0.9475, G loss: 0.8472\n",
      "[804/1762] D loss: 1.3642, G loss: 0.7354\n",
      "[884/1762] D loss: 1.3638, G loss: 0.6493\n",
      "[964/1762] D loss: 1.3980, G loss: 0.7231\n",
      "[1044/1762] D loss: 1.3592, G loss: 0.7868\n",
      "[1124/1762] D loss: 1.3640, G loss: 0.6924\n",
      "[1204/1762] D loss: 1.1677, G loss: 0.7913\n",
      "[1284/1762] D loss: 1.1940, G loss: 0.8585\n",
      "[1364/1762] D loss: 1.3987, G loss: 0.7773\n",
      "[1444/1762] D loss: 1.3926, G loss: 0.7030\n",
      "[1524/1762] D loss: 1.4166, G loss: 0.8631\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.6482\n",
      "[1684/1762] D loss: 1.2154, G loss: 0.7579\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7577\n",
      "train error: \n",
      " D loss: 1.323014, G loss: 0.737602, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308021, G loss: 0.748923, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3800, G loss: 0.6904\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6964\n",
      "[164/1762] D loss: 1.4004, G loss: 0.6897\n",
      "[244/1762] D loss: 1.3860, G loss: 0.6250\n",
      "[324/1762] D loss: 1.3380, G loss: 0.8414\n",
      "[404/1762] D loss: 1.2090, G loss: 0.6944\n",
      "[484/1762] D loss: 1.1490, G loss: 0.8706\n",
      "[564/1762] D loss: 1.3925, G loss: 0.6343\n",
      "[644/1762] D loss: 1.3821, G loss: 0.6373\n",
      "[724/1762] D loss: 1.3650, G loss: 0.8230\n",
      "[804/1762] D loss: 1.1819, G loss: 0.7074\n",
      "[884/1762] D loss: 1.1652, G loss: 0.8070\n",
      "[964/1762] D loss: 1.1525, G loss: 0.8997\n",
      "[1044/1762] D loss: 1.1970, G loss: 0.7117\n",
      "[1124/1762] D loss: 1.3565, G loss: 0.7613\n",
      "[1204/1762] D loss: 1.3889, G loss: 0.6180\n",
      "[1284/1762] D loss: 1.1648, G loss: 0.8593\n",
      "[1364/1762] D loss: 1.3938, G loss: 0.8236\n",
      "[1444/1762] D loss: 1.3890, G loss: 0.6237\n",
      "[1524/1762] D loss: 1.3844, G loss: 0.7840\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.7406\n",
      "[1684/1762] D loss: 1.1520, G loss: 0.7284\n",
      "[1762/1762] D loss: 1.3623, G loss: 0.7830\n",
      "train error: \n",
      " D loss: 1.317939, G loss: 0.817997, D accuracy: 55.7%, cell accuracy: 99.5%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300639, G loss: 0.832577, D accuracy: 56.7%, cell accuracy: 99.5%, board accuracy: 52.0% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3837, G loss: 0.8007\n",
      "[84/1762] D loss: 1.3710, G loss: 0.6870\n",
      "[164/1762] D loss: 0.7216, G loss: 1.0159\n",
      "[244/1762] D loss: 1.3071, G loss: 0.7801\n",
      "[324/1762] D loss: 0.9506, G loss: 0.8190\n",
      "[404/1762] D loss: 1.4066, G loss: 0.6473\n",
      "[484/1762] D loss: 1.4175, G loss: 0.8571\n",
      "[564/1762] D loss: 1.3799, G loss: 0.6324\n",
      "[644/1762] D loss: 1.3928, G loss: 0.6409\n",
      "[724/1762] D loss: 1.4192, G loss: 0.8916\n",
      "[804/1762] D loss: 1.3994, G loss: 0.7615\n",
      "[884/1762] D loss: 1.4105, G loss: 0.5676\n",
      "[964/1762] D loss: 1.4116, G loss: 0.8996\n",
      "[1044/1762] D loss: 1.1620, G loss: 0.7597\n",
      "[1124/1762] D loss: 1.1769, G loss: 0.8597\n",
      "[1204/1762] D loss: 1.4096, G loss: 0.7125\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.7324\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.6947\n",
      "[1444/1762] D loss: 1.3958, G loss: 0.8180\n",
      "[1524/1762] D loss: 1.3838, G loss: 0.6101\n",
      "[1604/1762] D loss: 1.3982, G loss: 0.7114\n",
      "[1684/1762] D loss: 1.4173, G loss: 0.7307\n",
      "[1762/1762] D loss: 0.9137, G loss: 0.8943\n",
      "train error: \n",
      " D loss: 1.322001, G loss: 0.811180, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 74.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306121, G loss: 0.823890, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.8022\n",
      "[84/1762] D loss: 1.3820, G loss: 0.7162\n",
      "[164/1762] D loss: 1.3829, G loss: 0.7277\n",
      "[244/1762] D loss: 1.4026, G loss: 0.6591\n",
      "[324/1762] D loss: 1.4011, G loss: 0.7336\n",
      "[404/1762] D loss: 1.3858, G loss: 0.7200\n",
      "[484/1762] D loss: 1.1704, G loss: 0.8569\n",
      "[564/1762] D loss: 1.1512, G loss: 0.8390\n",
      "[644/1762] D loss: 1.4351, G loss: 0.6980\n",
      "[724/1762] D loss: 1.4959, G loss: 0.9569\n",
      "[804/1762] D loss: 1.3822, G loss: 0.7957\n",
      "[884/1762] D loss: 1.4255, G loss: 0.5904\n",
      "[964/1762] D loss: 1.0668, G loss: 0.9477\n",
      "[1044/1762] D loss: 1.4265, G loss: 0.7422\n",
      "[1124/1762] D loss: 1.3701, G loss: 0.6833\n",
      "[1204/1762] D loss: 1.4310, G loss: 0.6066\n",
      "[1284/1762] D loss: 1.4123, G loss: 0.6485\n",
      "[1364/1762] D loss: 1.1537, G loss: 0.8347\n",
      "[1444/1762] D loss: 1.3573, G loss: 0.8954\n",
      "[1524/1762] D loss: 1.3692, G loss: 0.7418\n",
      "[1604/1762] D loss: 1.3549, G loss: 0.8500\n",
      "[1684/1762] D loss: 1.3928, G loss: 0.7042\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.6614\n",
      "train error: \n",
      " D loss: 1.315928, G loss: 0.717109, D accuracy: 56.6%, cell accuracy: 99.4%, board accuracy: 36.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297917, G loss: 0.731311, D accuracy: 57.3%, cell accuracy: 99.4%, board accuracy: 36.8% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1839, G loss: 0.7950\n",
      "[84/1762] D loss: 1.3750, G loss: 0.7731\n",
      "[164/1762] D loss: 1.3861, G loss: 0.7092\n",
      "[244/1762] D loss: 1.1994, G loss: 0.9797\n",
      "[324/1762] D loss: 1.3967, G loss: 0.7034\n",
      "[404/1762] D loss: 1.4196, G loss: 0.8278\n",
      "[484/1762] D loss: 1.4344, G loss: 0.8809\n",
      "[564/1762] D loss: 1.1570, G loss: 0.9147\n",
      "[644/1762] D loss: 1.3996, G loss: 0.7293\n",
      "[724/1762] D loss: 1.1382, G loss: 0.8572\n",
      "[804/1762] D loss: 1.1478, G loss: 0.7441\n",
      "[884/1762] D loss: 1.5315, G loss: 0.6561\n",
      "[964/1762] D loss: 1.4085, G loss: 0.6564\n",
      "[1044/1762] D loss: 1.3952, G loss: 0.8597\n",
      "[1124/1762] D loss: 1.4286, G loss: 0.7810\n",
      "[1204/1762] D loss: 1.4084, G loss: 0.6991\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.7791\n",
      "[1364/1762] D loss: 1.1402, G loss: 0.8627\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.7182\n",
      "[1524/1762] D loss: 1.4009, G loss: 0.7442\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6908\n",
      "[1684/1762] D loss: 1.1493, G loss: 0.7902\n",
      "[1762/1762] D loss: 0.9192, G loss: 0.9508\n",
      "train error: \n",
      " D loss: 1.327099, G loss: 0.748274, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307947, G loss: 0.766690, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9195, G loss: 0.9382\n",
      "[84/1762] D loss: 1.1684, G loss: 0.7320\n",
      "[164/1762] D loss: 1.4218, G loss: 0.8288\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7275\n",
      "[324/1762] D loss: 1.4017, G loss: 0.8038\n",
      "[404/1762] D loss: 1.1559, G loss: 0.7861\n",
      "[484/1762] D loss: 1.3972, G loss: 0.7280\n",
      "[564/1762] D loss: 1.1981, G loss: 0.9548\n",
      "[644/1762] D loss: 1.3936, G loss: 0.6374\n",
      "[724/1762] D loss: 1.3856, G loss: 0.6704\n",
      "[804/1762] D loss: 1.4036, G loss: 0.8013\n",
      "[884/1762] D loss: 1.3700, G loss: 0.7184\n",
      "[964/1762] D loss: 1.1563, G loss: 0.8135\n",
      "[1044/1762] D loss: 1.1428, G loss: 0.7494\n",
      "[1124/1762] D loss: 1.1511, G loss: 0.8364\n",
      "[1204/1762] D loss: 1.1426, G loss: 0.9358\n",
      "[1284/1762] D loss: 1.3752, G loss: 0.7681\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.6921\n",
      "[1444/1762] D loss: 1.3986, G loss: 0.7718\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.7223\n",
      "[1604/1762] D loss: 1.1220, G loss: 0.8567\n",
      "[1684/1762] D loss: 1.4059, G loss: 0.6357\n",
      "[1762/1762] D loss: 1.4265, G loss: 0.8533\n",
      "train error: \n",
      " D loss: 1.323841, G loss: 0.772590, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305026, G loss: 0.789397, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4130, G loss: 0.7155\n",
      "[84/1762] D loss: 1.1591, G loss: 0.7403\n",
      "[164/1762] D loss: 1.1257, G loss: 0.9123\n",
      "[244/1762] D loss: 1.4248, G loss: 0.5779\n",
      "[324/1762] D loss: 1.3889, G loss: 0.7265\n",
      "[404/1762] D loss: 1.4079, G loss: 0.6168\n",
      "[484/1762] D loss: 1.4019, G loss: 0.6713\n",
      "[564/1762] D loss: 1.1554, G loss: 0.7143\n",
      "[644/1762] D loss: 1.3119, G loss: 0.6247\n",
      "[724/1762] D loss: 1.4014, G loss: 0.7781\n",
      "[804/1762] D loss: 1.3942, G loss: 0.7184\n",
      "[884/1762] D loss: 1.3955, G loss: 0.7634\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7011\n",
      "[1044/1762] D loss: 1.3959, G loss: 0.7807\n",
      "[1124/1762] D loss: 1.1913, G loss: 0.8171\n",
      "[1204/1762] D loss: 1.3895, G loss: 0.7171\n",
      "[1284/1762] D loss: 1.3930, G loss: 0.7129\n",
      "[1364/1762] D loss: 1.3746, G loss: 0.7331\n",
      "[1444/1762] D loss: 1.5212, G loss: 0.7151\n",
      "[1524/1762] D loss: 1.4053, G loss: 0.6604\n",
      "[1604/1762] D loss: 1.4050, G loss: 0.7875\n",
      "[1684/1762] D loss: 1.4179, G loss: 0.7960\n",
      "[1762/1762] D loss: 1.9556, G loss: 0.8875\n",
      "train error: \n",
      " D loss: 1.691234, G loss: 1.290279, D accuracy: 52.4%, cell accuracy: 98.5%, board accuracy: 13.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.698147, G loss: 1.293321, D accuracy: 53.3%, cell accuracy: 98.5%, board accuracy: 17.3% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2867, G loss: 1.5790\n",
      "[84/1762] D loss: 1.0986, G loss: 0.7654\n",
      "[164/1762] D loss: 1.1544, G loss: 0.8132\n",
      "[244/1762] D loss: 1.4032, G loss: 0.6159\n",
      "[324/1762] D loss: 1.3715, G loss: 0.7045\n",
      "[404/1762] D loss: 1.4146, G loss: 0.6560\n",
      "[484/1762] D loss: 1.3843, G loss: 0.7093\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7156\n",
      "[644/1762] D loss: 1.3877, G loss: 0.6956\n",
      "[724/1762] D loss: 1.3909, G loss: 0.7208\n",
      "[804/1762] D loss: 1.4213, G loss: 0.7718\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7841\n",
      "[964/1762] D loss: 1.3901, G loss: 0.6819\n",
      "[1044/1762] D loss: 1.1998, G loss: 0.6650\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7336\n",
      "[1204/1762] D loss: 1.4073, G loss: 0.8037\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7289\n",
      "[1364/1762] D loss: 1.3840, G loss: 0.7673\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7190\n",
      "[1524/1762] D loss: 1.1564, G loss: 0.7766\n",
      "[1604/1762] D loss: 1.3919, G loss: 0.7641\n",
      "[1684/1762] D loss: 1.1801, G loss: 0.7380\n",
      "[1762/1762] D loss: 1.4053, G loss: 0.6476\n",
      "train error: \n",
      " D loss: 1.332756, G loss: 0.690787, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318686, G loss: 0.701037, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.6887\n",
      "[84/1762] D loss: 0.9566, G loss: 0.8118\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7921\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6680\n",
      "[324/1762] D loss: 1.3899, G loss: 0.6569\n",
      "[404/1762] D loss: 1.3992, G loss: 0.7900\n",
      "[484/1762] D loss: 1.1760, G loss: 0.8667\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6814\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6723\n",
      "[724/1762] D loss: 1.3988, G loss: 0.7128\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7212\n",
      "[884/1762] D loss: 1.3941, G loss: 0.7562\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6911\n",
      "[1044/1762] D loss: 1.2542, G loss: 0.7581\n",
      "[1124/1762] D loss: 1.4068, G loss: 0.6127\n",
      "[1204/1762] D loss: 1.1507, G loss: 0.8631\n",
      "[1284/1762] D loss: 1.3856, G loss: 0.6712\n",
      "[1364/1762] D loss: 1.1333, G loss: 0.9489\n",
      "[1444/1762] D loss: 1.4064, G loss: 0.8190\n",
      "[1524/1762] D loss: 1.3844, G loss: 0.6179\n",
      "[1604/1762] D loss: 1.3983, G loss: 0.6575\n",
      "[1684/1762] D loss: 1.4181, G loss: 0.7984\n",
      "[1762/1762] D loss: 1.3968, G loss: 0.6345\n",
      "train error: \n",
      " D loss: 1.328551, G loss: 0.715432, D accuracy: 54.1%, cell accuracy: 99.5%, board accuracy: 66.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308567, G loss: 0.727792, D accuracy: 55.6%, cell accuracy: 99.5%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1489, G loss: 0.7704\n",
      "[84/1762] D loss: 1.1621, G loss: 0.7814\n",
      "[164/1762] D loss: 1.3494, G loss: 0.7032\n",
      "[244/1762] D loss: 1.1500, G loss: 0.8737\n",
      "[324/1762] D loss: 1.3912, G loss: 0.6199\n",
      "[404/1762] D loss: 1.1423, G loss: 0.8615\n",
      "[484/1762] D loss: 1.3851, G loss: 0.7448\n",
      "[564/1762] D loss: 1.3738, G loss: 0.6792\n",
      "[644/1762] D loss: 1.3888, G loss: 0.7100\n",
      "[724/1762] D loss: 1.3740, G loss: 0.6419\n",
      "[804/1762] D loss: 1.3857, G loss: 0.8622\n",
      "[884/1762] D loss: 1.3905, G loss: 0.6191\n",
      "[964/1762] D loss: 1.3774, G loss: 0.7238\n",
      "[1044/1762] D loss: 1.3958, G loss: 0.7523\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.6714\n",
      "[1204/1762] D loss: 1.3955, G loss: 0.6704\n",
      "[1284/1762] D loss: 1.1900, G loss: 0.7538\n",
      "[1364/1762] D loss: 1.1174, G loss: 0.9387\n",
      "[1444/1762] D loss: 1.1528, G loss: 0.7323\n",
      "[1524/1762] D loss: 1.1566, G loss: 0.7664\n",
      "[1604/1762] D loss: 1.4034, G loss: 0.7838\n",
      "[1684/1762] D loss: 1.1660, G loss: 0.7751\n",
      "[1762/1762] D loss: 1.3912, G loss: 0.7202\n",
      "train error: \n",
      " D loss: 1.324594, G loss: 0.748721, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304907, G loss: 0.761070, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.6914\n",
      "[84/1762] D loss: 1.3903, G loss: 0.6205\n",
      "[164/1762] D loss: 1.3957, G loss: 0.7886\n",
      "[244/1762] D loss: 1.3919, G loss: 0.6393\n",
      "[324/1762] D loss: 1.3916, G loss: 0.7894\n",
      "[404/1762] D loss: 1.2242, G loss: 0.7442\n",
      "[484/1762] D loss: 1.4057, G loss: 0.7255\n",
      "[564/1762] D loss: 1.4202, G loss: 0.8136\n",
      "[644/1762] D loss: 1.1538, G loss: 0.7905\n",
      "[724/1762] D loss: 1.4030, G loss: 0.7460\n",
      "[804/1762] D loss: 1.3837, G loss: 0.7321\n",
      "[884/1762] D loss: 1.4074, G loss: 0.8269\n",
      "[964/1762] D loss: 1.3987, G loss: 0.7128\n",
      "[1044/1762] D loss: 1.3938, G loss: 0.7176\n",
      "[1124/1762] D loss: 1.3848, G loss: 0.7175\n",
      "[1204/1762] D loss: 1.3892, G loss: 0.6589\n",
      "[1284/1762] D loss: 1.4011, G loss: 0.7359\n",
      "[1364/1762] D loss: 1.3982, G loss: 0.7541\n",
      "[1444/1762] D loss: 1.3948, G loss: 0.7590\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.6957\n",
      "[1604/1762] D loss: 1.3792, G loss: 0.6874\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7276\n",
      "[1762/1762] D loss: 1.3839, G loss: 0.7772\n",
      "train error: \n",
      " D loss: 1.320334, G loss: 0.708046, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 71.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302214, G loss: 0.720254, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904, G loss: 0.6885\n",
      "[84/1762] D loss: 1.3947, G loss: 0.6439\n",
      "[164/1762] D loss: 1.4014, G loss: 0.7716\n",
      "[244/1762] D loss: 1.3898, G loss: 0.7168\n",
      "[324/1762] D loss: 1.4111, G loss: 0.7521\n",
      "[404/1762] D loss: 1.3993, G loss: 0.7734\n",
      "[484/1762] D loss: 1.3995, G loss: 0.8112\n",
      "[564/1762] D loss: 1.3937, G loss: 0.7500\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6984\n",
      "[724/1762] D loss: 1.3919, G loss: 0.7214\n",
      "[804/1762] D loss: 1.3926, G loss: 0.7474\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6716\n",
      "[964/1762] D loss: 1.3948, G loss: 0.7136\n",
      "[1044/1762] D loss: 1.3906, G loss: 0.7448\n",
      "[1124/1762] D loss: 1.4137, G loss: 0.7050\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.7117\n",
      "[1284/1762] D loss: 1.3935, G loss: 0.7916\n",
      "[1364/1762] D loss: 1.3922, G loss: 0.6438\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.7292\n",
      "[1524/1762] D loss: 1.4122, G loss: 0.5592\n",
      "[1604/1762] D loss: 1.3988, G loss: 0.8281\n",
      "[1684/1762] D loss: 1.4022, G loss: 0.6846\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6944\n",
      "train error: \n",
      " D loss: 1.321617, G loss: 0.757816, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300970, G loss: 0.776134, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7115\n",
      "[84/1762] D loss: 1.3982, G loss: 0.6195\n",
      "[164/1762] D loss: 1.3898, G loss: 0.6872\n",
      "[244/1762] D loss: 1.1939, G loss: 0.9733\n",
      "[324/1762] D loss: 1.4419, G loss: 0.8608\n",
      "[404/1762] D loss: 1.3988, G loss: 0.7024\n",
      "[484/1762] D loss: 1.4046, G loss: 0.8275\n",
      "[564/1762] D loss: 1.3931, G loss: 0.7643\n",
      "[644/1762] D loss: 1.4040, G loss: 0.7734\n",
      "[724/1762] D loss: 1.1264, G loss: 0.8666\n",
      "[804/1762] D loss: 1.4186, G loss: 0.8433\n",
      "[884/1762] D loss: 1.4160, G loss: 0.8375\n",
      "[964/1762] D loss: 1.4019, G loss: 0.7744\n",
      "[1044/1762] D loss: 1.4011, G loss: 0.6195\n",
      "[1124/1762] D loss: 1.3990, G loss: 0.8121\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.6977\n",
      "[1284/1762] D loss: 1.4424, G loss: 0.7911\n",
      "[1364/1762] D loss: 1.3903, G loss: 0.6961\n",
      "[1444/1762] D loss: 1.3841, G loss: 0.6874\n",
      "[1524/1762] D loss: 1.1227, G loss: 1.0420\n",
      "[1604/1762] D loss: 1.2416, G loss: 0.7532\n",
      "[1684/1762] D loss: 1.3914, G loss: 0.6349\n",
      "[1762/1762] D loss: 1.4500, G loss: 0.8149\n",
      "train error: \n",
      " D loss: 1.319261, G loss: 0.761053, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 83.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298982, G loss: 0.780004, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1221, G loss: 0.8141\n",
      "[84/1762] D loss: 1.3960, G loss: 0.6966\n",
      "[164/1762] D loss: 1.3888, G loss: 0.7362\n",
      "[244/1762] D loss: 1.2908, G loss: 0.6625\n",
      "[324/1762] D loss: 1.3943, G loss: 0.7876\n",
      "[404/1762] D loss: 1.1679, G loss: 0.8950\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7420\n",
      "[564/1762] D loss: 1.4322, G loss: 0.8609\n",
      "[644/1762] D loss: 1.4117, G loss: 0.5802\n",
      "[724/1762] D loss: 1.4337, G loss: 0.6502\n",
      "[804/1762] D loss: 1.4027, G loss: 0.6527\n",
      "[884/1762] D loss: 1.4040, G loss: 0.5699\n",
      "[964/1762] D loss: 1.3896, G loss: 0.6693\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.7527\n",
      "[1124/1762] D loss: 1.3945, G loss: 0.6164\n",
      "[1204/1762] D loss: 1.1338, G loss: 0.8511\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7441\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6840\n",
      "[1444/1762] D loss: 1.4789, G loss: 0.8733\n",
      "[1524/1762] D loss: 1.3934, G loss: 0.7343\n",
      "[1604/1762] D loss: 1.4002, G loss: 0.7339\n",
      "[1684/1762] D loss: 1.3897, G loss: 0.7317\n",
      "[1762/1762] D loss: 1.3989, G loss: 0.8148\n",
      "train error: \n",
      " D loss: 1.325175, G loss: 0.838325, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306437, G loss: 0.859077, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.8306\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7270\n",
      "[164/1762] D loss: 1.4035, G loss: 0.7396\n",
      "[244/1762] D loss: 1.1350, G loss: 0.9201\n",
      "[324/1762] D loss: 1.3926, G loss: 0.6648\n",
      "[404/1762] D loss: 1.1377, G loss: 0.9718\n",
      "[484/1762] D loss: 1.3796, G loss: 0.6747\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6913\n",
      "[644/1762] D loss: 1.3809, G loss: 0.6715\n",
      "[724/1762] D loss: 1.3961, G loss: 0.7975\n",
      "[804/1762] D loss: 1.3734, G loss: 0.6797\n",
      "[884/1762] D loss: 1.4023, G loss: 0.7847\n",
      "[964/1762] D loss: 1.3902, G loss: 0.7043\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.6411\n",
      "[1124/1762] D loss: 0.8771, G loss: 1.1119\n",
      "[1204/1762] D loss: 1.3944, G loss: 0.7219\n",
      "[1284/1762] D loss: 1.4344, G loss: 0.8848\n",
      "[1364/1762] D loss: 1.3827, G loss: 0.5493\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.7421\n",
      "[1524/1762] D loss: 1.1322, G loss: 0.8099\n",
      "[1604/1762] D loss: 1.3956, G loss: 0.7829\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.6844\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6858\n",
      "train error: \n",
      " D loss: 1.316187, G loss: 0.775944, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294900, G loss: 0.800163, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8634, G loss: 1.0242\n",
      "[84/1762] D loss: 1.3602, G loss: 0.7972\n",
      "[164/1762] D loss: 1.0988, G loss: 0.9054\n",
      "[244/1762] D loss: 1.0992, G loss: 0.9197\n",
      "[324/1762] D loss: 1.3909, G loss: 0.5993\n",
      "[404/1762] D loss: 1.4196, G loss: 0.7010\n",
      "[484/1762] D loss: 1.1335, G loss: 0.9226\n",
      "[564/1762] D loss: 1.4081, G loss: 0.7953\n",
      "[644/1762] D loss: 1.1202, G loss: 0.7302\n",
      "[724/1762] D loss: 1.1193, G loss: 0.8676\n",
      "[804/1762] D loss: 1.3911, G loss: 0.7444\n",
      "[884/1762] D loss: 1.0990, G loss: 0.9866\n",
      "[964/1762] D loss: 1.3894, G loss: 0.6962\n",
      "[1044/1762] D loss: 1.3972, G loss: 0.6334\n",
      "[1124/1762] D loss: 1.3961, G loss: 0.7934\n",
      "[1204/1762] D loss: 1.3932, G loss: 0.5938\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.7157\n",
      "[1364/1762] D loss: 1.1304, G loss: 0.8603\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.6339\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.7830\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.6831\n",
      "[1684/1762] D loss: 1.1606, G loss: 0.9963\n",
      "[1762/1762] D loss: 0.8506, G loss: 1.0761\n",
      "train error: \n",
      " D loss: 1.321281, G loss: 0.818009, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299874, G loss: 0.840864, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3986, G loss: 0.8007\n",
      "[84/1762] D loss: 1.3932, G loss: 0.7505\n",
      "[164/1762] D loss: 1.3889, G loss: 0.6676\n",
      "[244/1762] D loss: 1.4084, G loss: 0.7539\n",
      "[324/1762] D loss: 1.3984, G loss: 0.7606\n",
      "[404/1762] D loss: 1.3906, G loss: 0.6576\n",
      "[484/1762] D loss: 1.3996, G loss: 0.6045\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6989\n",
      "[644/1762] D loss: 1.3967, G loss: 0.7601\n",
      "[724/1762] D loss: 0.8112, G loss: 1.1506\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6875\n",
      "[884/1762] D loss: 0.8226, G loss: 1.1565\n",
      "[964/1762] D loss: 1.1232, G loss: 0.8474\n",
      "[1044/1762] D loss: 1.4113, G loss: 0.8201\n",
      "[1124/1762] D loss: 1.4070, G loss: 0.6976\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.7341\n",
      "[1284/1762] D loss: 1.1298, G loss: 0.9647\n",
      "[1364/1762] D loss: 1.4030, G loss: 0.7601\n",
      "[1444/1762] D loss: 1.1090, G loss: 0.9912\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.5892\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.6853\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.6343\n",
      "[1762/1762] D loss: 1.3946, G loss: 0.7801\n",
      "train error: \n",
      " D loss: 1.330632, G loss: 0.891860, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309130, G loss: 0.921272, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8681, G loss: 1.2287\n",
      "[84/1762] D loss: 1.4089, G loss: 0.7753\n",
      "[164/1762] D loss: 1.4069, G loss: 0.6295\n",
      "[244/1762] D loss: 0.8224, G loss: 1.3205\n",
      "[324/1762] D loss: 1.4095, G loss: 0.6686\n",
      "[404/1762] D loss: 0.8368, G loss: 1.0713\n",
      "[484/1762] D loss: 1.1135, G loss: 0.8806\n",
      "[564/1762] D loss: 1.3940, G loss: 0.7987\n",
      "[644/1762] D loss: 1.1152, G loss: 0.8854\n",
      "[724/1762] D loss: 1.4048, G loss: 0.7025\n",
      "[804/1762] D loss: 1.3954, G loss: 0.6920\n",
      "[884/1762] D loss: 1.1261, G loss: 0.9799\n",
      "[964/1762] D loss: 1.4163, G loss: 0.5703\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.7384\n",
      "[1124/1762] D loss: 1.4119, G loss: 0.8104\n",
      "[1204/1762] D loss: 1.1295, G loss: 0.9720\n",
      "[1284/1762] D loss: 1.3714, G loss: 0.7052\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6602\n",
      "[1444/1762] D loss: 1.1214, G loss: 0.8680\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.7185\n",
      "[1604/1762] D loss: 1.3822, G loss: 0.7336\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6815\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6768\n",
      "train error: \n",
      " D loss: 1.313855, G loss: 0.742696, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291026, G loss: 0.771963, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1238, G loss: 0.8627\n",
      "[84/1762] D loss: 1.4231, G loss: 0.6773\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6712\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7109\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6595\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7067\n",
      "[484/1762] D loss: 1.1145, G loss: 0.8882\n",
      "[564/1762] D loss: 1.4095, G loss: 0.7392\n",
      "[644/1762] D loss: 1.4012, G loss: 0.7176\n",
      "[724/1762] D loss: 1.1127, G loss: 0.8959\n",
      "[804/1762] D loss: 1.3931, G loss: 0.6305\n",
      "[884/1762] D loss: 1.4059, G loss: 0.8376\n",
      "[964/1762] D loss: 1.3924, G loss: 0.6308\n",
      "[1044/1762] D loss: 1.4073, G loss: 0.6302\n",
      "[1124/1762] D loss: 1.3774, G loss: 0.7722\n",
      "[1204/1762] D loss: 1.4338, G loss: 0.7166\n",
      "[1284/1762] D loss: 1.4349, G loss: 0.8192\n",
      "[1364/1762] D loss: 1.3887, G loss: 0.6232\n",
      "[1444/1762] D loss: 1.4033, G loss: 0.7032\n",
      "[1524/1762] D loss: 1.1426, G loss: 1.0822\n",
      "[1604/1762] D loss: 1.4209, G loss: 0.6568\n",
      "[1684/1762] D loss: 1.4252, G loss: 0.6771\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.7072\n",
      "train error: \n",
      " D loss: 1.321626, G loss: 0.747261, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293503, G loss: 0.777928, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3726, G loss: 0.6764\n",
      "[84/1762] D loss: 1.4076, G loss: 0.7653\n",
      "[164/1762] D loss: 1.4218, G loss: 0.8514\n",
      "[244/1762] D loss: 1.1845, G loss: 1.1012\n",
      "[324/1762] D loss: 1.3824, G loss: 0.7007\n",
      "[404/1762] D loss: 1.4015, G loss: 0.6320\n",
      "[484/1762] D loss: 1.1339, G loss: 0.8379\n",
      "[564/1762] D loss: 1.1463, G loss: 0.7592\n",
      "[644/1762] D loss: 1.4070, G loss: 0.7665\n",
      "[724/1762] D loss: 1.1779, G loss: 0.7286\n",
      "[804/1762] D loss: 1.4024, G loss: 0.7036\n",
      "[884/1762] D loss: 0.9420, G loss: 0.8044\n",
      "[964/1762] D loss: 1.4176, G loss: 0.6595\n",
      "[1044/1762] D loss: 1.4033, G loss: 0.6519\n",
      "[1124/1762] D loss: 1.4062, G loss: 0.6700\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.7294\n",
      "[1284/1762] D loss: 1.3937, G loss: 0.7018\n",
      "[1364/1762] D loss: 1.3710, G loss: 0.7544\n",
      "[1444/1762] D loss: 1.3537, G loss: 0.8556\n",
      "[1524/1762] D loss: 1.3964, G loss: 0.7090\n",
      "[1604/1762] D loss: 1.3639, G loss: 0.6455\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.7078\n",
      "[1762/1762] D loss: 1.3985, G loss: 0.7963\n",
      "train error: \n",
      " D loss: 1.322331, G loss: 0.849480, D accuracy: 53.8%, cell accuracy: 99.4%, board accuracy: 45.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304479, G loss: 0.862514, D accuracy: 54.2%, cell accuracy: 99.3%, board accuracy: 45.5% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4017, G loss: 0.7887\n",
      "[84/1762] D loss: 1.3860, G loss: 0.7181\n",
      "[164/1762] D loss: 1.3903, G loss: 0.7198\n",
      "[244/1762] D loss: 1.1257, G loss: 0.8171\n",
      "[324/1762] D loss: 1.3848, G loss: 0.7220\n",
      "[404/1762] D loss: 1.3803, G loss: 0.6978\n",
      "[484/1762] D loss: 1.3291, G loss: 0.7545\n",
      "[564/1762] D loss: 1.3655, G loss: 0.7541\n",
      "[644/1762] D loss: 1.0794, G loss: 0.8423\n",
      "[724/1762] D loss: 1.4477, G loss: 0.8207\n",
      "[804/1762] D loss: 1.1553, G loss: 0.9166\n",
      "[884/1762] D loss: 1.3301, G loss: 0.8104\n",
      "[964/1762] D loss: 1.3185, G loss: 0.8809\n",
      "[1044/1762] D loss: 1.1230, G loss: 0.9567\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.6939\n",
      "[1204/1762] D loss: 1.1208, G loss: 0.9521\n",
      "[1284/1762] D loss: 1.1344, G loss: 1.0437\n",
      "[1364/1762] D loss: 1.0886, G loss: 0.7979\n",
      "[1444/1762] D loss: 1.3761, G loss: 0.7445\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.6908\n",
      "[1604/1762] D loss: 0.8773, G loss: 1.1758\n",
      "[1684/1762] D loss: 1.3968, G loss: 0.7810\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6301\n",
      "train error: \n",
      " D loss: 1.323569, G loss: 0.678194, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300618, G loss: 0.699028, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4280, G loss: 0.5423\n",
      "[84/1762] D loss: 1.4275, G loss: 0.8555\n",
      "[164/1762] D loss: 1.3921, G loss: 0.6237\n",
      "[244/1762] D loss: 1.3965, G loss: 0.7840\n",
      "[324/1762] D loss: 1.2819, G loss: 0.9023\n",
      "[404/1762] D loss: 1.1537, G loss: 0.8386\n",
      "[484/1762] D loss: 1.3908, G loss: 0.6600\n",
      "[564/1762] D loss: 1.3945, G loss: 0.6923\n",
      "[644/1762] D loss: 1.3945, G loss: 0.6385\n",
      "[724/1762] D loss: 1.3700, G loss: 0.7578\n",
      "[804/1762] D loss: 1.3942, G loss: 0.6225\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7391\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6762\n",
      "[1044/1762] D loss: 1.3987, G loss: 0.7819\n",
      "[1124/1762] D loss: 1.4138, G loss: 0.6058\n",
      "[1204/1762] D loss: 0.8674, G loss: 1.0029\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.7247\n",
      "[1364/1762] D loss: 1.1154, G loss: 0.8784\n",
      "[1444/1762] D loss: 0.5896, G loss: 1.1229\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.6281\n",
      "[1604/1762] D loss: 1.3854, G loss: 0.7485\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.7510\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.7138\n",
      "train error: \n",
      " D loss: 1.315144, G loss: 0.835647, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292818, G loss: 0.865923, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3939, G loss: 0.7098\n",
      "[84/1762] D loss: 1.3937, G loss: 0.6097\n",
      "[164/1762] D loss: 1.3894, G loss: 0.7731\n",
      "[244/1762] D loss: 1.0911, G loss: 0.9701\n",
      "[324/1762] D loss: 1.1122, G loss: 0.8622\n",
      "[404/1762] D loss: 1.3653, G loss: 0.7236\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7437\n",
      "[564/1762] D loss: 1.3712, G loss: 0.7570\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6636\n",
      "[724/1762] D loss: 1.4186, G loss: 0.8300\n",
      "[804/1762] D loss: 1.3930, G loss: 0.6952\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7140\n",
      "[964/1762] D loss: 1.3930, G loss: 0.6916\n",
      "[1044/1762] D loss: 1.3923, G loss: 0.7694\n",
      "[1124/1762] D loss: 1.4066, G loss: 0.5910\n",
      "[1204/1762] D loss: 1.4064, G loss: 0.6751\n",
      "[1284/1762] D loss: 1.3814, G loss: 0.7186\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.6704\n",
      "[1444/1762] D loss: 1.1245, G loss: 0.9356\n",
      "[1524/1762] D loss: 1.0650, G loss: 1.0145\n",
      "[1604/1762] D loss: 1.3604, G loss: 0.7022\n",
      "[1684/1762] D loss: 1.1495, G loss: 0.8126\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.7146\n",
      "train error: \n",
      " D loss: 1.311140, G loss: 0.815153, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 76.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289690, G loss: 0.842311, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6798\n",
      "[84/1762] D loss: 1.3745, G loss: 0.7297\n",
      "[164/1762] D loss: 1.1612, G loss: 1.0363\n",
      "[244/1762] D loss: 1.3892, G loss: 0.6643\n",
      "[324/1762] D loss: 1.3881, G loss: 0.7882\n",
      "[404/1762] D loss: 1.4197, G loss: 0.5316\n",
      "[484/1762] D loss: 1.4082, G loss: 0.8061\n",
      "[564/1762] D loss: 1.0902, G loss: 0.9823\n",
      "[644/1762] D loss: 1.4096, G loss: 0.7013\n",
      "[724/1762] D loss: 1.3367, G loss: 0.8468\n",
      "[804/1762] D loss: 1.1549, G loss: 0.7660\n",
      "[884/1762] D loss: 1.3852, G loss: 0.6422\n",
      "[964/1762] D loss: 1.3853, G loss: 0.7126\n",
      "[1044/1762] D loss: 1.4134, G loss: 0.5790\n",
      "[1124/1762] D loss: 1.3945, G loss: 0.6776\n",
      "[1204/1762] D loss: 1.1649, G loss: 0.8276\n",
      "[1284/1762] D loss: 1.3785, G loss: 0.6941\n",
      "[1364/1762] D loss: 1.4044, G loss: 0.6270\n",
      "[1444/1762] D loss: 1.3759, G loss: 0.7730\n",
      "[1524/1762] D loss: 1.4175, G loss: 0.6937\n",
      "[1604/1762] D loss: 1.3796, G loss: 0.6780\n",
      "[1684/1762] D loss: 0.5315, G loss: 1.4744\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.6659\n",
      "train error: \n",
      " D loss: 1.318243, G loss: 0.706695, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293106, G loss: 0.730035, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 72.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4017, G loss: 0.8240\n",
      "[84/1762] D loss: 1.3956, G loss: 0.8096\n",
      "[164/1762] D loss: 1.3901, G loss: 0.8032\n",
      "[244/1762] D loss: 1.3775, G loss: 0.7975\n",
      "[324/1762] D loss: 1.3515, G loss: 0.8027\n",
      "[404/1762] D loss: 1.3092, G loss: 0.8304\n",
      "[484/1762] D loss: 1.2383, G loss: 0.8851\n",
      "[564/1762] D loss: 1.1182, G loss: 0.9269\n",
      "[644/1762] D loss: 0.9933, G loss: 0.9829\n",
      "[724/1762] D loss: 0.7101, G loss: 1.2689\n",
      "[804/1762] D loss: 0.5621, G loss: 1.7374\n",
      "[884/1762] D loss: 0.3098, G loss: 2.2895\n",
      "[964/1762] D loss: 0.3044, G loss: 2.9282\n",
      "[1044/1762] D loss: 0.0994, G loss: 3.3186\n",
      "[1124/1762] D loss: 0.1497, G loss: 3.9720\n",
      "[1204/1762] D loss: 0.1701, G loss: 3.5481\n",
      "[1284/1762] D loss: 0.2486, G loss: 5.2170\n",
      "[1364/1762] D loss: 0.1097, G loss: 4.6080\n",
      "[1444/1762] D loss: 0.0692, G loss: 4.9539\n",
      "[1524/1762] D loss: 0.0744, G loss: 4.9198\n",
      "[1604/1762] D loss: 0.2105, G loss: 6.2482\n",
      "[1684/1762] D loss: 0.1306, G loss: 5.3128\n",
      "[1762/1762] D loss: 0.0512, G loss: 5.1424\n",
      "train error: \n",
      " D loss: 0.080991, G loss: 5.774039, D accuracy: 100.0%, cell accuracy: 92.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.076216, G loss: 5.844930, D accuracy: 100.0%, cell accuracy: 91.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1666, G loss: 5.2910\n",
      "[84/1762] D loss: 0.1040, G loss: 5.6748\n",
      "[164/1762] D loss: 0.0965, G loss: 6.0052\n",
      "[244/1762] D loss: 0.1030, G loss: 5.5100\n",
      "[324/1762] D loss: 0.0250, G loss: 4.8379\n",
      "[404/1762] D loss: 0.0343, G loss: 5.5125\n",
      "[484/1762] D loss: 0.0171, G loss: 5.6424\n",
      "[564/1762] D loss: 0.0424, G loss: 3.8226\n",
      "[644/1762] D loss: 0.0381, G loss: 4.3501\n",
      "[724/1762] D loss: 0.0380, G loss: 5.0091\n",
      "[804/1762] D loss: 0.0195, G loss: 5.3281\n",
      "[884/1762] D loss: 0.0599, G loss: 5.0006\n",
      "[964/1762] D loss: 0.0468, G loss: 4.3447\n",
      "[1044/1762] D loss: 0.0460, G loss: 4.4128\n",
      "[1124/1762] D loss: 0.0295, G loss: 5.6971\n",
      "[1204/1762] D loss: 0.0632, G loss: 4.7228\n",
      "[1284/1762] D loss: 0.0674, G loss: 3.4810\n",
      "[1364/1762] D loss: 0.0712, G loss: 3.4284\n",
      "[1444/1762] D loss: 0.0269, G loss: 5.3012\n",
      "[1524/1762] D loss: 0.0494, G loss: 4.7081\n",
      "[1604/1762] D loss: 0.0530, G loss: 4.6899\n",
      "[1684/1762] D loss: 0.1455, G loss: 4.3140\n",
      "[1762/1762] D loss: 0.1060, G loss: 2.8661\n",
      "train error: \n",
      " D loss: 0.049887, G loss: 4.293579, D accuracy: 100.0%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.047467, G loss: 4.311409, D accuracy: 100.0%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0641, G loss: 3.7439\n",
      "[84/1762] D loss: 0.1065, G loss: 4.2359\n",
      "[164/1762] D loss: 0.0235, G loss: 4.2542\n",
      "[244/1762] D loss: 0.0588, G loss: 3.2764\n",
      "[324/1762] D loss: 0.0474, G loss: 4.2370\n",
      "[404/1762] D loss: 0.0650, G loss: 3.1128\n",
      "[484/1762] D loss: 0.0616, G loss: 4.5392\n",
      "[564/1762] D loss: 0.0268, G loss: 5.8854\n",
      "[644/1762] D loss: 0.0638, G loss: 4.5143\n",
      "[724/1762] D loss: 0.0583, G loss: 4.8794\n",
      "[804/1762] D loss: 0.0687, G loss: 4.6003\n",
      "[884/1762] D loss: 0.1061, G loss: 5.3914\n",
      "[964/1762] D loss: 0.0375, G loss: 4.6184\n",
      "[1044/1762] D loss: 0.0643, G loss: 5.8102\n",
      "[1124/1762] D loss: 0.0470, G loss: 4.9588\n",
      "[1204/1762] D loss: 0.0243, G loss: 4.7461\n",
      "[1284/1762] D loss: 0.0352, G loss: 4.9197\n",
      "[1364/1762] D loss: 0.0475, G loss: 5.2167\n",
      "[1444/1762] D loss: 0.0461, G loss: 4.4861\n",
      "[1524/1762] D loss: 0.0257, G loss: 4.1774\n",
      "[1604/1762] D loss: 0.0356, G loss: 4.3894\n",
      "[1684/1762] D loss: 0.0253, G loss: 4.9435\n",
      "[1762/1762] D loss: 0.0908, G loss: 2.8665\n",
      "train error: \n",
      " D loss: 0.037803, G loss: 4.204639, D accuracy: 100.0%, cell accuracy: 97.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.036643, G loss: 4.213497, D accuracy: 100.0%, cell accuracy: 97.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0333, G loss: 4.7353\n",
      "[84/1762] D loss: 0.0214, G loss: 5.6532\n",
      "[164/1762] D loss: 0.0215, G loss: 6.0251\n",
      "[244/1762] D loss: 0.0688, G loss: 6.4234\n",
      "[324/1762] D loss: 0.0498, G loss: 4.8512\n",
      "[404/1762] D loss: 0.0879, G loss: 3.8302\n",
      "[484/1762] D loss: 0.0973, G loss: 3.9899\n",
      "[564/1762] D loss: 0.0189, G loss: 5.4650\n",
      "[644/1762] D loss: 0.0169, G loss: 5.5437\n",
      "[724/1762] D loss: 0.0987, G loss: 5.1553\n",
      "[804/1762] D loss: 0.0681, G loss: 3.9303\n",
      "[884/1762] D loss: 0.0150, G loss: 7.0139\n",
      "[964/1762] D loss: 0.0931, G loss: 3.3008\n",
      "[1044/1762] D loss: 0.0544, G loss: 4.0429\n",
      "[1124/1762] D loss: 0.0262, G loss: 4.8699\n",
      "[1204/1762] D loss: 0.0215, G loss: 4.9741\n",
      "[1284/1762] D loss: 0.0292, G loss: 3.8111\n",
      "[1364/1762] D loss: 0.0326, G loss: 5.0233\n",
      "[1444/1762] D loss: 0.0513, G loss: 5.0789\n",
      "[1524/1762] D loss: 0.0135, G loss: 4.9404\n",
      "[1604/1762] D loss: 0.0698, G loss: 5.8081\n",
      "[1684/1762] D loss: 0.0156, G loss: 4.8217\n",
      "[1762/1762] D loss: 0.0122, G loss: 5.3631\n",
      "train error: \n",
      " D loss: 0.024667, G loss: 5.309105, D accuracy: 100.0%, cell accuracy: 96.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.025064, G loss: 5.293588, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0090, G loss: 5.5523\n",
      "[84/1762] D loss: 0.0529, G loss: 3.9222\n",
      "[164/1762] D loss: 0.0415, G loss: 3.6422\n",
      "[244/1762] D loss: 0.0082, G loss: 6.4820\n",
      "[324/1762] D loss: 0.0064, G loss: 6.6023\n",
      "[404/1762] D loss: 0.0404, G loss: 4.7259\n",
      "[484/1762] D loss: 0.0061, G loss: 5.6666\n",
      "[564/1762] D loss: 0.0421, G loss: 5.0936\n",
      "[644/1762] D loss: 0.0116, G loss: 6.4661\n",
      "[724/1762] D loss: 0.0193, G loss: 5.6870\n",
      "[804/1762] D loss: 0.0368, G loss: 4.6919\n",
      "[884/1762] D loss: 0.0165, G loss: 5.1092\n",
      "[964/1762] D loss: 0.0254, G loss: 3.4365\n",
      "[1044/1762] D loss: 0.0320, G loss: 7.3059\n",
      "[1124/1762] D loss: 0.1264, G loss: 7.5820\n",
      "[1204/1762] D loss: 0.0200, G loss: 5.4116\n",
      "[1284/1762] D loss: 0.0301, G loss: 5.1719\n",
      "[1364/1762] D loss: 0.0080, G loss: 6.2014\n",
      "[1444/1762] D loss: 0.0272, G loss: 4.3745\n",
      "[1524/1762] D loss: 0.0040, G loss: 5.9795\n",
      "[1604/1762] D loss: 0.0403, G loss: 4.3391\n",
      "[1684/1762] D loss: 0.0765, G loss: 3.9251\n",
      "[1762/1762] D loss: 0.2546, G loss: 4.5573\n",
      "train error: \n",
      " D loss: 0.308928, G loss: 4.650280, D accuracy: 95.2%, cell accuracy: 96.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.326940, G loss: 4.592299, D accuracy: 95.1%, cell accuracy: 96.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4786, G loss: 2.0537\n",
      "[84/1762] D loss: 0.4398, G loss: 1.4171\n",
      "[164/1762] D loss: 0.6473, G loss: 3.7762\n",
      "[244/1762] D loss: 0.7816, G loss: 1.9150\n",
      "[324/1762] D loss: 0.5217, G loss: 4.1455\n",
      "[404/1762] D loss: 0.4825, G loss: 1.5469\n",
      "[484/1762] D loss: 0.8014, G loss: 0.9332\n",
      "[564/1762] D loss: 0.3138, G loss: 2.2500\n",
      "[644/1762] D loss: 0.6861, G loss: 1.6356\n",
      "[724/1762] D loss: 0.2233, G loss: 1.6420\n",
      "[804/1762] D loss: 0.5975, G loss: 2.0992\n",
      "[884/1762] D loss: 0.0829, G loss: 3.5597\n",
      "[964/1762] D loss: 0.1045, G loss: 3.0115\n",
      "[1044/1762] D loss: 0.8864, G loss: 1.4332\n",
      "[1124/1762] D loss: 0.2556, G loss: 4.6208\n",
      "[1204/1762] D loss: 0.5471, G loss: 1.5802\n",
      "[1284/1762] D loss: 0.1981, G loss: 2.6746\n",
      "[1364/1762] D loss: 0.7145, G loss: 0.9780\n",
      "[1444/1762] D loss: 0.1596, G loss: 2.1258\n",
      "[1524/1762] D loss: 0.5329, G loss: 2.8739\n",
      "[1604/1762] D loss: 2.1897, G loss: 1.2731\n",
      "[1684/1762] D loss: 2.3063, G loss: 0.2102\n",
      "[1762/1762] D loss: 0.4679, G loss: 1.6512\n",
      "train error: \n",
      " D loss: 0.909504, G loss: 1.367760, D accuracy: 79.0%, cell accuracy: 96.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.896152, G loss: 1.367301, D accuracy: 78.4%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6437, G loss: 1.9054\n",
      "[84/1762] D loss: 0.8952, G loss: 2.2816\n",
      "[164/1762] D loss: 0.5163, G loss: 3.3740\n",
      "[244/1762] D loss: 0.8545, G loss: 0.9809\n",
      "[324/1762] D loss: 1.1502, G loss: 0.6557\n",
      "[404/1762] D loss: 1.2744, G loss: 0.9922\n",
      "[484/1762] D loss: 0.7142, G loss: 0.8926\n",
      "[564/1762] D loss: 0.6509, G loss: 1.9999\n",
      "[644/1762] D loss: 0.2501, G loss: 3.4500\n",
      "[724/1762] D loss: 0.6859, G loss: 1.2647\n",
      "[804/1762] D loss: 0.6414, G loss: 1.1763\n",
      "[884/1762] D loss: 1.0853, G loss: 0.6940\n",
      "[964/1762] D loss: 0.5784, G loss: 1.9821\n",
      "[1044/1762] D loss: 0.7995, G loss: 2.9122\n",
      "[1124/1762] D loss: 0.6332, G loss: 1.8335\n",
      "[1204/1762] D loss: 0.5289, G loss: 1.8740\n",
      "[1284/1762] D loss: 0.5784, G loss: 1.9575\n",
      "[1364/1762] D loss: 1.0738, G loss: 1.9753\n",
      "[1444/1762] D loss: 0.4475, G loss: 1.5515\n",
      "[1524/1762] D loss: 0.1744, G loss: 3.5860\n",
      "[1604/1762] D loss: 0.3807, G loss: 3.1511\n",
      "[1684/1762] D loss: 0.9242, G loss: 0.8774\n",
      "[1762/1762] D loss: 0.9400, G loss: 1.6579\n",
      "train error: \n",
      " D loss: 0.867204, G loss: 1.544970, D accuracy: 81.6%, cell accuracy: 96.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.828686, G loss: 1.615669, D accuracy: 83.6%, cell accuracy: 96.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7616, G loss: 2.3304\n",
      "[84/1762] D loss: 1.1899, G loss: 0.6316\n",
      "[164/1762] D loss: 0.5764, G loss: 2.4590\n",
      "[244/1762] D loss: 1.1443, G loss: 0.9043\n",
      "[324/1762] D loss: 0.8200, G loss: 2.0320\n",
      "[404/1762] D loss: 0.9626, G loss: 2.6894\n",
      "[484/1762] D loss: 1.1248, G loss: 1.4448\n",
      "[564/1762] D loss: 0.6693, G loss: 1.2644\n",
      "[644/1762] D loss: 0.9548, G loss: 1.8262\n",
      "[724/1762] D loss: 1.0723, G loss: 2.4061\n",
      "[804/1762] D loss: 1.0158, G loss: 1.0077\n",
      "[884/1762] D loss: 1.2318, G loss: 0.8521\n",
      "[964/1762] D loss: 0.8287, G loss: 1.2705\n",
      "[1044/1762] D loss: 1.0446, G loss: 0.8230\n",
      "[1124/1762] D loss: 0.6809, G loss: 1.4503\n",
      "[1204/1762] D loss: 0.3383, G loss: 1.7463\n",
      "[1284/1762] D loss: 0.7381, G loss: 1.2704\n",
      "[1364/1762] D loss: 1.1152, G loss: 2.4366\n",
      "[1444/1762] D loss: 0.6462, G loss: 0.7694\n",
      "[1524/1762] D loss: 0.9619, G loss: 1.6452\n",
      "[1604/1762] D loss: 0.6941, G loss: 1.5169\n",
      "[1684/1762] D loss: 0.7140, G loss: 1.7483\n",
      "[1762/1762] D loss: 0.1251, G loss: 3.3982\n",
      "train error: \n",
      " D loss: 0.691225, G loss: 1.402295, D accuracy: 89.1%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.682232, G loss: 1.409602, D accuracy: 89.1%, cell accuracy: 97.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5156, G loss: 1.7131\n",
      "[84/1762] D loss: 0.3267, G loss: 2.5737\n",
      "[164/1762] D loss: 0.9823, G loss: 1.3996\n",
      "[244/1762] D loss: 0.5486, G loss: 1.3925\n",
      "[324/1762] D loss: 0.6284, G loss: 1.4008\n",
      "[404/1762] D loss: 0.8748, G loss: 1.3050\n",
      "[484/1762] D loss: 0.6410, G loss: 1.7882\n",
      "[564/1762] D loss: 0.7254, G loss: 1.5005\n",
      "[644/1762] D loss: 0.6035, G loss: 1.5078\n",
      "[724/1762] D loss: 0.7080, G loss: 2.1127\n",
      "[804/1762] D loss: 0.8639, G loss: 2.1542\n",
      "[884/1762] D loss: 0.5781, G loss: 1.8755\n",
      "[964/1762] D loss: 0.7802, G loss: 1.4858\n",
      "[1044/1762] D loss: 0.8726, G loss: 0.7386\n",
      "[1124/1762] D loss: 1.4432, G loss: 2.5415\n",
      "[1204/1762] D loss: 0.6445, G loss: 3.4791\n",
      "[1284/1762] D loss: 0.5661, G loss: 1.3396\n",
      "[1364/1762] D loss: 0.7940, G loss: 1.4811\n",
      "[1444/1762] D loss: 0.7852, G loss: 1.3872\n",
      "[1524/1762] D loss: 0.6932, G loss: 1.0858\n",
      "[1604/1762] D loss: 0.6727, G loss: 1.1744\n",
      "[1684/1762] D loss: 0.7129, G loss: 0.8689\n",
      "[1762/1762] D loss: 0.5111, G loss: 2.8831\n",
      "train error: \n",
      " D loss: 0.922303, G loss: 2.068331, D accuracy: 74.1%, cell accuracy: 98.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.920214, G loss: 2.072667, D accuracy: 74.3%, cell accuracy: 98.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7967, G loss: 1.8547\n",
      "[84/1762] D loss: 0.6758, G loss: 1.3463\n",
      "[164/1762] D loss: 0.8980, G loss: 0.8314\n",
      "[244/1762] D loss: 1.0480, G loss: 2.7073\n",
      "[324/1762] D loss: 0.6536, G loss: 1.6784\n",
      "[404/1762] D loss: 1.2681, G loss: 1.3343\n",
      "[484/1762] D loss: 1.4995, G loss: 1.5087\n",
      "[564/1762] D loss: 1.7499, G loss: 0.4169\n",
      "[644/1762] D loss: 1.1057, G loss: 1.1990\n",
      "[724/1762] D loss: 1.0264, G loss: 1.5142\n",
      "[804/1762] D loss: 2.0262, G loss: 0.5249\n",
      "[884/1762] D loss: 1.7119, G loss: 0.4663\n",
      "[964/1762] D loss: 1.3208, G loss: 1.5674\n",
      "[1044/1762] D loss: 1.5389, G loss: 0.8395\n",
      "[1124/1762] D loss: 1.3807, G loss: 1.2219\n",
      "[1204/1762] D loss: 1.1945, G loss: 0.7674\n",
      "[1284/1762] D loss: 1.1538, G loss: 0.7716\n",
      "[1364/1762] D loss: 0.9048, G loss: 1.0757\n",
      "[1444/1762] D loss: 1.4851, G loss: 0.9363\n",
      "[1524/1762] D loss: 1.3669, G loss: 0.4912\n",
      "[1604/1762] D loss: 1.3322, G loss: 0.8348\n",
      "[1684/1762] D loss: 0.8474, G loss: 0.7436\n",
      "[1762/1762] D loss: 0.6143, G loss: 2.0098\n",
      "train error: \n",
      " D loss: 1.235923, G loss: 1.078457, D accuracy: 65.4%, cell accuracy: 99.3%, board accuracy: 42.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.242820, G loss: 1.046620, D accuracy: 65.8%, cell accuracy: 99.2%, board accuracy: 39.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2650, G loss: 1.4235\n",
      "[84/1762] D loss: 1.2064, G loss: 0.7898\n",
      "[164/1762] D loss: 1.3000, G loss: 1.3808\n",
      "[244/1762] D loss: 1.8618, G loss: 0.4801\n",
      "[324/1762] D loss: 1.1579, G loss: 1.4458\n",
      "[404/1762] D loss: 1.3646, G loss: 0.6570\n",
      "[484/1762] D loss: 1.5170, G loss: 0.6415\n",
      "[564/1762] D loss: 1.9371, G loss: 1.1400\n",
      "[644/1762] D loss: 1.0129, G loss: 1.2162\n",
      "[724/1762] D loss: 1.4661, G loss: 1.6330\n",
      "[804/1762] D loss: 1.3756, G loss: 0.6376\n",
      "[884/1762] D loss: 1.3907, G loss: 1.4620\n",
      "[964/1762] D loss: 1.5090, G loss: 0.9080\n",
      "[1044/1762] D loss: 1.3699, G loss: 0.8195\n",
      "[1124/1762] D loss: 1.9026, G loss: 0.5567\n",
      "[1204/1762] D loss: 1.3395, G loss: 0.6787\n",
      "[1284/1762] D loss: 1.9554, G loss: 0.3292\n",
      "[1364/1762] D loss: 1.1766, G loss: 1.0689\n",
      "[1444/1762] D loss: 1.0407, G loss: 1.3408\n",
      "[1524/1762] D loss: 1.1547, G loss: 1.4394\n",
      "[1604/1762] D loss: 1.0642, G loss: 1.1584\n",
      "[1684/1762] D loss: 1.3366, G loss: 0.7037\n",
      "[1762/1762] D loss: 0.9967, G loss: 0.8632\n",
      "train error: \n",
      " D loss: 1.305908, G loss: 0.668363, D accuracy: 63.1%, cell accuracy: 99.2%, board accuracy: 41.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333236, G loss: 0.630094, D accuracy: 61.1%, cell accuracy: 99.2%, board accuracy: 37.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3183, G loss: 0.8603\n",
      "[84/1762] D loss: 1.5097, G loss: 2.2426\n",
      "[164/1762] D loss: 0.8788, G loss: 0.9527\n",
      "[244/1762] D loss: 1.1855, G loss: 0.6608\n",
      "[324/1762] D loss: 1.1830, G loss: 1.1314\n",
      "[404/1762] D loss: 1.0842, G loss: 1.3650\n",
      "[484/1762] D loss: 1.3951, G loss: 0.6810\n",
      "[564/1762] D loss: 1.1567, G loss: 1.2557\n",
      "[644/1762] D loss: 1.0079, G loss: 1.0489\n",
      "[724/1762] D loss: 0.9990, G loss: 1.2503\n",
      "[804/1762] D loss: 1.4690, G loss: 0.5078\n",
      "[884/1762] D loss: 1.0904, G loss: 2.2802\n",
      "[964/1762] D loss: 1.1487, G loss: 0.9511\n",
      "[1044/1762] D loss: 1.2426, G loss: 0.9691\n",
      "[1124/1762] D loss: 1.1479, G loss: 0.8739\n",
      "[1204/1762] D loss: 1.1920, G loss: 1.3524\n",
      "[1284/1762] D loss: 1.2776, G loss: 0.9361\n",
      "[1364/1762] D loss: 1.3058, G loss: 1.2754\n",
      "[1444/1762] D loss: 1.3817, G loss: 0.7773\n",
      "[1524/1762] D loss: 1.2422, G loss: 0.5969\n",
      "[1604/1762] D loss: 1.1718, G loss: 1.0089\n",
      "[1684/1762] D loss: 0.9997, G loss: 2.3061\n",
      "[1762/1762] D loss: 0.9712, G loss: 1.3492\n",
      "train error: \n",
      " D loss: 1.225511, G loss: 0.967457, D accuracy: 64.2%, cell accuracy: 99.4%, board accuracy: 48.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.231200, G loss: 0.943649, D accuracy: 64.4%, cell accuracy: 99.3%, board accuracy: 43.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3141, G loss: 0.6114\n",
      "[84/1762] D loss: 1.2835, G loss: 0.7448\n",
      "[164/1762] D loss: 1.4023, G loss: 0.6836\n",
      "[244/1762] D loss: 1.0349, G loss: 1.2988\n",
      "[324/1762] D loss: 1.5195, G loss: 0.6418\n",
      "[404/1762] D loss: 1.2298, G loss: 1.0587\n",
      "[484/1762] D loss: 1.2800, G loss: 1.3792\n",
      "[564/1762] D loss: 1.5398, G loss: 0.4754\n",
      "[644/1762] D loss: 1.1676, G loss: 0.7407\n",
      "[724/1762] D loss: 1.2139, G loss: 1.0319\n",
      "[804/1762] D loss: 1.5388, G loss: 0.9935\n",
      "[884/1762] D loss: 1.3722, G loss: 0.7272\n",
      "[964/1762] D loss: 1.0568, G loss: 0.6949\n",
      "[1044/1762] D loss: 1.3673, G loss: 0.8919\n",
      "[1124/1762] D loss: 1.3773, G loss: 0.5592\n",
      "[1204/1762] D loss: 1.5098, G loss: 1.4101\n",
      "[1284/1762] D loss: 1.3190, G loss: 1.0160\n",
      "[1364/1762] D loss: 0.9202, G loss: 1.5189\n",
      "[1444/1762] D loss: 1.3196, G loss: 0.7877\n",
      "[1524/1762] D loss: 1.2366, G loss: 1.6031\n",
      "[1604/1762] D loss: 1.3638, G loss: 1.2898\n",
      "[1684/1762] D loss: 1.0729, G loss: 1.0453\n",
      "[1762/1762] D loss: 1.4931, G loss: 1.0832\n",
      "train error: \n",
      " D loss: 1.387740, G loss: 1.554876, D accuracy: 56.9%, cell accuracy: 99.3%, board accuracy: 45.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377509, G loss: 1.531537, D accuracy: 57.2%, cell accuracy: 99.2%, board accuracy: 40.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3004, G loss: 0.9959\n",
      "[84/1762] D loss: 1.1630, G loss: 0.9797\n",
      "[164/1762] D loss: 1.0472, G loss: 0.7543\n",
      "[244/1762] D loss: 1.2821, G loss: 1.7416\n",
      "[324/1762] D loss: 1.4124, G loss: 1.0096\n",
      "[404/1762] D loss: 1.6751, G loss: 0.4865\n",
      "[484/1762] D loss: 1.3375, G loss: 0.9329\n",
      "[564/1762] D loss: 1.2554, G loss: 1.1212\n",
      "[644/1762] D loss: 1.1978, G loss: 0.7641\n",
      "[724/1762] D loss: 1.4951, G loss: 0.7026\n",
      "[804/1762] D loss: 0.9520, G loss: 1.3919\n",
      "[884/1762] D loss: 1.4431, G loss: 0.6276\n",
      "[964/1762] D loss: 1.3522, G loss: 0.6428\n",
      "[1044/1762] D loss: 1.0231, G loss: 1.5111\n",
      "[1124/1762] D loss: 1.6087, G loss: 1.8136\n",
      "[1204/1762] D loss: 1.2925, G loss: 0.8454\n",
      "[1284/1762] D loss: 1.3777, G loss: 0.9617\n",
      "[1364/1762] D loss: 1.2243, G loss: 1.1497\n",
      "[1444/1762] D loss: 1.3935, G loss: 0.7452\n",
      "[1524/1762] D loss: 1.1742, G loss: 1.9082\n",
      "[1604/1762] D loss: 1.2532, G loss: 0.6273\n",
      "[1684/1762] D loss: 1.4228, G loss: 0.5636\n",
      "[1762/1762] D loss: 1.1192, G loss: 0.9329\n",
      "train error: \n",
      " D loss: 1.329534, G loss: 0.634114, D accuracy: 61.6%, cell accuracy: 99.3%, board accuracy: 47.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336943, G loss: 0.601548, D accuracy: 60.6%, cell accuracy: 99.3%, board accuracy: 43.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7365, G loss: 0.4899\n",
      "[84/1762] D loss: 1.3580, G loss: 0.6154\n",
      "[164/1762] D loss: 1.0915, G loss: 0.9359\n",
      "[244/1762] D loss: 1.3574, G loss: 0.9587\n",
      "[324/1762] D loss: 1.3489, G loss: 0.7222\n",
      "[404/1762] D loss: 1.3175, G loss: 1.4314\n",
      "[484/1762] D loss: 1.1340, G loss: 0.7751\n",
      "[564/1762] D loss: 0.5859, G loss: 2.9122\n",
      "[644/1762] D loss: 1.0071, G loss: 1.1567\n",
      "[724/1762] D loss: 1.3071, G loss: 1.1308\n",
      "[804/1762] D loss: 1.2126, G loss: 0.7145\n",
      "[884/1762] D loss: 0.9812, G loss: 1.2965\n",
      "[964/1762] D loss: 0.9253, G loss: 1.2653\n",
      "[1044/1762] D loss: 1.2144, G loss: 0.8088\n",
      "[1124/1762] D loss: 0.9762, G loss: 0.9495\n",
      "[1204/1762] D loss: 1.1201, G loss: 1.4573\n",
      "[1284/1762] D loss: 1.1248, G loss: 0.7097\n",
      "[1364/1762] D loss: 1.2863, G loss: 1.1758\n",
      "[1444/1762] D loss: 1.3369, G loss: 0.7306\n",
      "[1524/1762] D loss: 1.5449, G loss: 0.6960\n",
      "[1604/1762] D loss: 1.3017, G loss: 0.7898\n",
      "[1684/1762] D loss: 0.9677, G loss: 1.1358\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.7764\n",
      "train error: \n",
      " D loss: 1.286686, G loss: 0.682846, D accuracy: 62.9%, cell accuracy: 99.3%, board accuracy: 45.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300288, G loss: 0.640613, D accuracy: 61.8%, cell accuracy: 99.3%, board accuracy: 42.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0507, G loss: 0.8760\n",
      "[84/1762] D loss: 1.0782, G loss: 0.9815\n",
      "[164/1762] D loss: 1.2590, G loss: 1.0244\n",
      "[244/1762] D loss: 1.6262, G loss: 1.0733\n",
      "[324/1762] D loss: 1.1672, G loss: 1.1046\n",
      "[404/1762] D loss: 1.0906, G loss: 1.2162\n",
      "[484/1762] D loss: 1.9220, G loss: 1.3614\n",
      "[564/1762] D loss: 1.1823, G loss: 1.0164\n",
      "[644/1762] D loss: 1.3613, G loss: 1.0792\n",
      "[724/1762] D loss: 1.3277, G loss: 0.7165\n",
      "[804/1762] D loss: 1.2441, G loss: 0.6135\n",
      "[884/1762] D loss: 1.0239, G loss: 1.0937\n",
      "[964/1762] D loss: 1.3066, G loss: 1.0328\n",
      "[1044/1762] D loss: 0.8695, G loss: 1.5755\n",
      "[1124/1762] D loss: 1.5348, G loss: 1.3509\n",
      "[1204/1762] D loss: 0.9944, G loss: 1.5415\n",
      "[1284/1762] D loss: 1.2196, G loss: 0.8238\n",
      "[1364/1762] D loss: 1.2556, G loss: 1.3986\n",
      "[1444/1762] D loss: 1.3951, G loss: 0.9291\n",
      "[1524/1762] D loss: 1.6519, G loss: 0.4802\n",
      "[1604/1762] D loss: 1.0328, G loss: 0.5683\n",
      "[1684/1762] D loss: 1.2338, G loss: 1.5511\n",
      "[1762/1762] D loss: 1.5149, G loss: 0.6286\n",
      "train error: \n",
      " D loss: 1.193074, G loss: 0.954501, D accuracy: 65.4%, cell accuracy: 99.3%, board accuracy: 47.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.191016, G loss: 0.917839, D accuracy: 65.8%, cell accuracy: 99.3%, board accuracy: 42.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4450, G loss: 0.6546\n",
      "[84/1762] D loss: 1.1263, G loss: 1.2342\n",
      "[164/1762] D loss: 1.1153, G loss: 1.1868\n",
      "[244/1762] D loss: 1.3141, G loss: 0.6594\n",
      "[324/1762] D loss: 1.0147, G loss: 1.2295\n",
      "[404/1762] D loss: 1.2109, G loss: 0.6253\n",
      "[484/1762] D loss: 1.1759, G loss: 1.0648\n",
      "[564/1762] D loss: 0.8427, G loss: 1.2737\n",
      "[644/1762] D loss: 0.9691, G loss: 2.3191\n",
      "[724/1762] D loss: 1.3084, G loss: 0.6247\n",
      "[804/1762] D loss: 1.2630, G loss: 1.1348\n",
      "[884/1762] D loss: 1.1944, G loss: 1.0773\n",
      "[964/1762] D loss: 1.2286, G loss: 1.3113\n",
      "[1044/1762] D loss: 1.3595, G loss: 0.5577\n",
      "[1124/1762] D loss: 1.4122, G loss: 1.1757\n",
      "[1204/1762] D loss: 1.5860, G loss: 0.7722\n",
      "[1284/1762] D loss: 1.2390, G loss: 1.2010\n",
      "[1364/1762] D loss: 1.1576, G loss: 1.2738\n",
      "[1444/1762] D loss: 1.3541, G loss: 0.7365\n",
      "[1524/1762] D loss: 1.0916, G loss: 1.4423\n",
      "[1604/1762] D loss: 1.3610, G loss: 0.7230\n",
      "[1684/1762] D loss: 0.9999, G loss: 1.0667\n",
      "[1762/1762] D loss: 1.2700, G loss: 0.5882\n",
      "train error: \n",
      " D loss: 1.206700, G loss: 0.813687, D accuracy: 64.4%, cell accuracy: 99.4%, board accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.200643, G loss: 0.781026, D accuracy: 64.4%, cell accuracy: 99.3%, board accuracy: 45.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0760, G loss: 1.1298\n",
      "[84/1762] D loss: 0.9827, G loss: 1.6494\n",
      "[164/1762] D loss: 1.6406, G loss: 1.2823\n",
      "[244/1762] D loss: 1.5718, G loss: 0.6046\n",
      "[324/1762] D loss: 1.2779, G loss: 0.9914\n",
      "[404/1762] D loss: 0.9199, G loss: 1.5282\n",
      "[484/1762] D loss: 1.1466, G loss: 1.1029\n",
      "[564/1762] D loss: 1.0454, G loss: 1.0677\n",
      "[644/1762] D loss: 0.9291, G loss: 1.2111\n",
      "[724/1762] D loss: 1.2397, G loss: 0.9624\n",
      "[804/1762] D loss: 1.3952, G loss: 0.6350\n",
      "[884/1762] D loss: 1.1867, G loss: 1.4243\n",
      "[964/1762] D loss: 1.4681, G loss: 0.6483\n",
      "[1044/1762] D loss: 1.3195, G loss: 0.6318\n",
      "[1124/1762] D loss: 1.4431, G loss: 0.8226\n",
      "[1204/1762] D loss: 0.9817, G loss: 1.3412\n",
      "[1284/1762] D loss: 1.3670, G loss: 0.7431\n",
      "[1364/1762] D loss: 1.1824, G loss: 1.4310\n",
      "[1444/1762] D loss: 1.1983, G loss: 0.7063\n",
      "[1524/1762] D loss: 0.9370, G loss: 1.2048\n",
      "[1604/1762] D loss: 1.4423, G loss: 1.2309\n",
      "[1684/1762] D loss: 1.2119, G loss: 1.3930\n",
      "[1762/1762] D loss: 0.7659, G loss: 0.9529\n",
      "train error: \n",
      " D loss: 1.170577, G loss: 1.147269, D accuracy: 65.8%, cell accuracy: 99.3%, board accuracy: 49.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.164703, G loss: 1.112272, D accuracy: 66.7%, cell accuracy: 99.3%, board accuracy: 45.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2253, G loss: 0.8213\n",
      "[84/1762] D loss: 1.2980, G loss: 1.0852\n",
      "[164/1762] D loss: 1.3650, G loss: 0.9745\n",
      "[244/1762] D loss: 1.3817, G loss: 0.8881\n",
      "[324/1762] D loss: 1.3549, G loss: 0.3881\n",
      "[404/1762] D loss: 1.1624, G loss: 0.6871\n",
      "[484/1762] D loss: 1.0517, G loss: 1.3889\n",
      "[564/1762] D loss: 0.6983, G loss: 1.3277\n",
      "[644/1762] D loss: 0.6488, G loss: 2.1720\n",
      "[724/1762] D loss: 1.8148, G loss: 0.9968\n",
      "[804/1762] D loss: 1.3463, G loss: 0.7690\n",
      "[884/1762] D loss: 1.3210, G loss: 0.8344\n",
      "[964/1762] D loss: 1.1179, G loss: 1.3174\n",
      "[1044/1762] D loss: 1.2166, G loss: 1.5090\n",
      "[1124/1762] D loss: 1.4148, G loss: 0.5443\n",
      "[1204/1762] D loss: 0.9313, G loss: 1.2790\n",
      "[1284/1762] D loss: 1.1851, G loss: 1.0533\n",
      "[1364/1762] D loss: 1.0056, G loss: 1.7099\n",
      "[1444/1762] D loss: 1.3798, G loss: 0.9066\n",
      "[1524/1762] D loss: 1.0294, G loss: 0.9765\n",
      "[1604/1762] D loss: 1.3069, G loss: 0.6268\n",
      "[1684/1762] D loss: 1.3292, G loss: 0.5569\n",
      "[1762/1762] D loss: 1.3719, G loss: 0.7497\n",
      "train error: \n",
      " D loss: 1.190364, G loss: 0.900343, D accuracy: 64.6%, cell accuracy: 99.4%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.187084, G loss: 0.860061, D accuracy: 65.1%, cell accuracy: 99.4%, board accuracy: 49.3% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0276, G loss: 0.9764\n",
      "[84/1762] D loss: 1.0362, G loss: 2.2418\n",
      "[164/1762] D loss: 1.0735, G loss: 1.8274\n",
      "[244/1762] D loss: 1.6678, G loss: 0.9450\n",
      "[324/1762] D loss: 1.3256, G loss: 0.4168\n",
      "[404/1762] D loss: 1.2166, G loss: 2.3908\n",
      "[484/1762] D loss: 1.2018, G loss: 1.3289\n",
      "[564/1762] D loss: 1.3728, G loss: 0.5759\n",
      "[644/1762] D loss: 1.5977, G loss: 0.4846\n",
      "[724/1762] D loss: 1.1659, G loss: 1.3305\n",
      "[804/1762] D loss: 1.0000, G loss: 1.4075\n",
      "[884/1762] D loss: 1.2725, G loss: 0.8268\n",
      "[964/1762] D loss: 0.9329, G loss: 1.7168\n",
      "[1044/1762] D loss: 1.2618, G loss: 0.7988\n",
      "[1124/1762] D loss: 1.1030, G loss: 1.3955\n",
      "[1204/1762] D loss: 1.0706, G loss: 0.9396\n",
      "[1284/1762] D loss: 1.1937, G loss: 0.8969\n",
      "[1364/1762] D loss: 1.2650, G loss: 1.0416\n",
      "[1444/1762] D loss: 1.0382, G loss: 0.5738\n",
      "[1524/1762] D loss: 1.1130, G loss: 1.5254\n",
      "[1604/1762] D loss: 1.3716, G loss: 0.7194\n",
      "[1684/1762] D loss: 1.0429, G loss: 1.8967\n",
      "[1762/1762] D loss: 1.5055, G loss: 0.3605\n",
      "train error: \n",
      " D loss: 1.256135, G loss: 0.806231, D accuracy: 60.6%, cell accuracy: 99.5%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254338, G loss: 0.754777, D accuracy: 60.7%, cell accuracy: 99.4%, board accuracy: 52.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9173, G loss: 1.7633\n",
      "[84/1762] D loss: 1.3118, G loss: 0.6581\n",
      "[164/1762] D loss: 1.4529, G loss: 0.9159\n",
      "[244/1762] D loss: 1.1675, G loss: 0.8094\n",
      "[324/1762] D loss: 1.0182, G loss: 1.3073\n",
      "[404/1762] D loss: 1.2541, G loss: 0.4365\n",
      "[484/1762] D loss: 1.3208, G loss: 0.9785\n",
      "[564/1762] D loss: 1.4645, G loss: 1.9493\n",
      "[644/1762] D loss: 0.8374, G loss: 1.3106\n",
      "[724/1762] D loss: 1.0252, G loss: 1.5819\n",
      "[804/1762] D loss: 1.1698, G loss: 0.7420\n",
      "[884/1762] D loss: 1.0882, G loss: 1.2075\n",
      "[964/1762] D loss: 1.2564, G loss: 1.2373\n",
      "[1044/1762] D loss: 0.9826, G loss: 0.8710\n",
      "[1124/1762] D loss: 1.2283, G loss: 1.3557\n",
      "[1204/1762] D loss: 0.9813, G loss: 0.8052\n",
      "[1284/1762] D loss: 1.3377, G loss: 0.6932\n",
      "[1364/1762] D loss: 1.1967, G loss: 1.0902\n",
      "[1444/1762] D loss: 1.2077, G loss: 0.8853\n",
      "[1524/1762] D loss: 1.2324, G loss: 1.1240\n",
      "[1604/1762] D loss: 1.3000, G loss: 0.7732\n",
      "[1684/1762] D loss: 0.9504, G loss: 1.0211\n",
      "[1762/1762] D loss: 1.4363, G loss: 0.8977\n",
      "train error: \n",
      " D loss: 1.249857, G loss: 0.849182, D accuracy: 61.1%, cell accuracy: 99.5%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.248077, G loss: 0.828565, D accuracy: 60.8%, cell accuracy: 99.4%, board accuracy: 53.6% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1573, G loss: 0.9047\n",
      "[84/1762] D loss: 1.3287, G loss: 1.2603\n",
      "[164/1762] D loss: 1.1348, G loss: 0.8789\n",
      "[244/1762] D loss: 1.4095, G loss: 0.8886\n",
      "[324/1762] D loss: 1.6091, G loss: 0.3933\n",
      "[404/1762] D loss: 1.5480, G loss: 0.8509\n",
      "[484/1762] D loss: 0.8387, G loss: 1.3585\n",
      "[564/1762] D loss: 1.3861, G loss: 0.6187\n",
      "[644/1762] D loss: 0.6991, G loss: 1.8204\n",
      "[724/1762] D loss: 1.1038, G loss: 1.1294\n",
      "[804/1762] D loss: 0.7717, G loss: 2.0298\n",
      "[884/1762] D loss: 1.4486, G loss: 0.5945\n",
      "[964/1762] D loss: 1.4573, G loss: 0.6637\n",
      "[1044/1762] D loss: 1.2709, G loss: 1.2367\n",
      "[1124/1762] D loss: 1.4330, G loss: 0.8002\n",
      "[1204/1762] D loss: 1.2645, G loss: 1.4273\n",
      "[1284/1762] D loss: 1.4625, G loss: 0.4423\n",
      "[1364/1762] D loss: 1.5112, G loss: 1.0759\n",
      "[1444/1762] D loss: 1.4944, G loss: 0.8704\n",
      "[1524/1762] D loss: 1.4628, G loss: 0.6186\n",
      "[1604/1762] D loss: 1.5408, G loss: 0.7946\n",
      "[1684/1762] D loss: 1.6513, G loss: 1.0612\n",
      "[1762/1762] D loss: 0.9572, G loss: 0.8181\n",
      "train error: \n",
      " D loss: 1.360484, G loss: 0.566905, D accuracy: 58.4%, cell accuracy: 99.5%, board accuracy: 61.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366425, G loss: 0.544429, D accuracy: 58.1%, cell accuracy: 99.4%, board accuracy: 53.9% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3220, G loss: 0.5506\n",
      "[84/1762] D loss: 1.3824, G loss: 0.8770\n",
      "[164/1762] D loss: 1.2337, G loss: 0.7414\n",
      "[244/1762] D loss: 1.4668, G loss: 0.6593\n",
      "[324/1762] D loss: 1.4621, G loss: 1.6745\n",
      "[404/1762] D loss: 1.0684, G loss: 0.6684\n",
      "[484/1762] D loss: 1.8281, G loss: 0.3749\n",
      "[564/1762] D loss: 1.3787, G loss: 0.4949\n",
      "[644/1762] D loss: 1.3602, G loss: 0.9262\n",
      "[724/1762] D loss: 1.2198, G loss: 0.7778\n",
      "[804/1762] D loss: 1.3423, G loss: 0.9323\n",
      "[884/1762] D loss: 1.3660, G loss: 1.1981\n",
      "[964/1762] D loss: 1.4602, G loss: 0.4366\n",
      "[1044/1762] D loss: 1.6128, G loss: 1.0981\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.7333\n",
      "[1204/1762] D loss: 1.1317, G loss: 0.8273\n",
      "[1284/1762] D loss: 1.5749, G loss: 0.9375\n",
      "[1364/1762] D loss: 1.2199, G loss: 0.7089\n",
      "[1444/1762] D loss: 1.4015, G loss: 0.5432\n",
      "[1524/1762] D loss: 1.2355, G loss: 0.7264\n",
      "[1604/1762] D loss: 1.4150, G loss: 0.9559\n",
      "[1684/1762] D loss: 1.2402, G loss: 0.5891\n",
      "[1762/1762] D loss: 1.4015, G loss: 0.6510\n",
      "train error: \n",
      " D loss: 1.359521, G loss: 0.637726, D accuracy: 56.2%, cell accuracy: 99.6%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348568, G loss: 0.652732, D accuracy: 56.8%, cell accuracy: 99.5%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3247, G loss: 0.8050\n",
      "[84/1762] D loss: 1.2239, G loss: 1.0028\n",
      "[164/1762] D loss: 1.3235, G loss: 0.7134\n",
      "[244/1762] D loss: 1.2691, G loss: 0.7221\n",
      "[324/1762] D loss: 1.1976, G loss: 0.9824\n",
      "[404/1762] D loss: 1.4336, G loss: 0.6942\n",
      "[484/1762] D loss: 1.2681, G loss: 0.8835\n",
      "[564/1762] D loss: 1.2854, G loss: 0.6135\n",
      "[644/1762] D loss: 1.1401, G loss: 1.1954\n",
      "[724/1762] D loss: 1.4109, G loss: 0.5843\n",
      "[804/1762] D loss: 1.3924, G loss: 0.9190\n",
      "[884/1762] D loss: 1.4154, G loss: 0.7898\n",
      "[964/1762] D loss: 1.3309, G loss: 0.7476\n",
      "[1044/1762] D loss: 0.9999, G loss: 1.0318\n",
      "[1124/1762] D loss: 1.4662, G loss: 0.6939\n",
      "[1204/1762] D loss: 1.3760, G loss: 0.6037\n",
      "[1284/1762] D loss: 1.4193, G loss: 0.9640\n",
      "[1364/1762] D loss: 1.3565, G loss: 0.6081\n",
      "[1444/1762] D loss: 1.3729, G loss: 0.8195\n",
      "[1524/1762] D loss: 1.4962, G loss: 0.5525\n",
      "[1604/1762] D loss: 1.5646, G loss: 0.9064\n",
      "[1684/1762] D loss: 1.4048, G loss: 0.4674\n",
      "[1762/1762] D loss: 1.2296, G loss: 1.0439\n",
      "train error: \n",
      " D loss: 1.352421, G loss: 0.649379, D accuracy: 56.3%, cell accuracy: 99.5%, board accuracy: 53.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344122, G loss: 0.659375, D accuracy: 57.0%, cell accuracy: 99.5%, board accuracy: 49.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4576, G loss: 0.7499\n",
      "[84/1762] D loss: 1.4219, G loss: 0.8600\n",
      "[164/1762] D loss: 1.1698, G loss: 0.7741\n",
      "[244/1762] D loss: 1.2665, G loss: 0.8060\n",
      "[324/1762] D loss: 1.2988, G loss: 0.6676\n",
      "[404/1762] D loss: 1.7540, G loss: 1.3778\n",
      "[484/1762] D loss: 1.4147, G loss: 0.5638\n",
      "[564/1762] D loss: 1.2653, G loss: 0.8328\n",
      "[644/1762] D loss: 1.3902, G loss: 0.5178\n",
      "[724/1762] D loss: 1.5024, G loss: 0.9988\n",
      "[804/1762] D loss: 1.3335, G loss: 0.8048\n",
      "[884/1762] D loss: 1.3576, G loss: 0.6340\n",
      "[964/1762] D loss: 1.4924, G loss: 0.7819\n",
      "[1044/1762] D loss: 1.4065, G loss: 0.6859\n",
      "[1124/1762] D loss: 1.5259, G loss: 0.4843\n",
      "[1204/1762] D loss: 1.3076, G loss: 0.9662\n",
      "[1284/1762] D loss: 1.4148, G loss: 0.6777\n",
      "[1364/1762] D loss: 1.3773, G loss: 0.7220\n",
      "[1444/1762] D loss: 1.5229, G loss: 1.0682\n",
      "[1524/1762] D loss: 1.4197, G loss: 0.5569\n",
      "[1604/1762] D loss: 1.1684, G loss: 0.7984\n",
      "[1684/1762] D loss: 1.3696, G loss: 0.8024\n",
      "[1762/1762] D loss: 1.0106, G loss: 0.9239\n",
      "train error: \n",
      " D loss: 1.336741, G loss: 0.859920, D accuracy: 55.9%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326360, G loss: 0.869510, D accuracy: 57.4%, cell accuracy: 99.6%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2310, G loss: 0.8505\n",
      "[84/1762] D loss: 1.2119, G loss: 1.1101\n",
      "[164/1762] D loss: 1.4370, G loss: 0.6200\n",
      "[244/1762] D loss: 1.0453, G loss: 0.8937\n",
      "[324/1762] D loss: 1.2071, G loss: 1.0061\n",
      "[404/1762] D loss: 1.3993, G loss: 0.6158\n",
      "[484/1762] D loss: 1.3313, G loss: 0.7170\n",
      "[564/1762] D loss: 1.5259, G loss: 0.5063\n",
      "[644/1762] D loss: 1.6143, G loss: 1.0989\n",
      "[724/1762] D loss: 1.4059, G loss: 0.8162\n",
      "[804/1762] D loss: 1.4018, G loss: 0.7262\n",
      "[884/1762] D loss: 1.2100, G loss: 0.9964\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6352\n",
      "[1044/1762] D loss: 1.2614, G loss: 0.8964\n",
      "[1124/1762] D loss: 1.2909, G loss: 0.5494\n",
      "[1204/1762] D loss: 1.3781, G loss: 1.2141\n",
      "[1284/1762] D loss: 1.4132, G loss: 0.8867\n",
      "[1364/1762] D loss: 1.4340, G loss: 0.7197\n",
      "[1444/1762] D loss: 1.1960, G loss: 0.9579\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.6262\n",
      "[1604/1762] D loss: 1.3290, G loss: 0.7137\n",
      "[1684/1762] D loss: 1.3982, G loss: 0.6849\n",
      "[1762/1762] D loss: 1.0560, G loss: 1.0034\n",
      "train error: \n",
      " D loss: 1.336824, G loss: 0.856087, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 68.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320513, G loss: 0.863797, D accuracy: 57.8%, cell accuracy: 99.6%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2330, G loss: 0.9564\n",
      "[84/1762] D loss: 1.5730, G loss: 0.4364\n",
      "[164/1762] D loss: 1.5806, G loss: 1.0970\n",
      "[244/1762] D loss: 1.1029, G loss: 0.9617\n",
      "[324/1762] D loss: 1.1861, G loss: 0.8379\n",
      "[404/1762] D loss: 1.1803, G loss: 0.6499\n",
      "[484/1762] D loss: 1.2564, G loss: 0.6654\n",
      "[564/1762] D loss: 1.4355, G loss: 0.9427\n",
      "[644/1762] D loss: 1.4032, G loss: 0.5356\n",
      "[724/1762] D loss: 1.3993, G loss: 0.5833\n",
      "[804/1762] D loss: 1.5058, G loss: 0.9286\n",
      "[884/1762] D loss: 1.3672, G loss: 0.4578\n",
      "[964/1762] D loss: 1.3972, G loss: 0.7553\n",
      "[1044/1762] D loss: 1.4093, G loss: 0.7085\n",
      "[1124/1762] D loss: 1.3583, G loss: 0.4882\n",
      "[1204/1762] D loss: 1.4153, G loss: 0.7440\n",
      "[1284/1762] D loss: 1.3994, G loss: 0.7646\n",
      "[1364/1762] D loss: 1.1964, G loss: 0.8806\n",
      "[1444/1762] D loss: 1.5068, G loss: 0.9927\n",
      "[1524/1762] D loss: 1.3986, G loss: 0.6544\n",
      "[1604/1762] D loss: 1.1813, G loss: 0.9662\n",
      "[1684/1762] D loss: 1.2576, G loss: 0.6615\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.7607\n",
      "train error: \n",
      " D loss: 1.322986, G loss: 0.765967, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 68.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308978, G loss: 0.774740, D accuracy: 58.2%, cell accuracy: 99.6%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4608, G loss: 0.7240\n",
      "[84/1762] D loss: 1.1739, G loss: 0.7929\n",
      "[164/1762] D loss: 1.3988, G loss: 0.6456\n",
      "[244/1762] D loss: 1.4485, G loss: 0.6883\n",
      "[324/1762] D loss: 1.3439, G loss: 0.6773\n",
      "[404/1762] D loss: 1.3959, G loss: 0.7854\n",
      "[484/1762] D loss: 1.5271, G loss: 0.8801\n",
      "[564/1762] D loss: 1.2034, G loss: 0.9584\n",
      "[644/1762] D loss: 1.2000, G loss: 0.8667\n",
      "[724/1762] D loss: 1.3996, G loss: 0.6088\n",
      "[804/1762] D loss: 1.4265, G loss: 0.8254\n",
      "[884/1762] D loss: 1.3638, G loss: 0.6801\n",
      "[964/1762] D loss: 1.5310, G loss: 0.6634\n",
      "[1044/1762] D loss: 1.4017, G loss: 0.7959\n",
      "[1124/1762] D loss: 1.1615, G loss: 1.0420\n",
      "[1204/1762] D loss: 1.3831, G loss: 0.7662\n",
      "[1284/1762] D loss: 1.3192, G loss: 0.8719\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6115\n",
      "[1444/1762] D loss: 1.4200, G loss: 0.7927\n",
      "[1524/1762] D loss: 1.4293, G loss: 0.5847\n",
      "[1604/1762] D loss: 1.2815, G loss: 0.8595\n",
      "[1684/1762] D loss: 1.3991, G loss: 0.4968\n",
      "[1762/1762] D loss: 1.4051, G loss: 0.7300\n",
      "train error: \n",
      " D loss: 1.316850, G loss: 0.831312, D accuracy: 56.9%, cell accuracy: 99.6%, board accuracy: 63.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298040, G loss: 0.838032, D accuracy: 58.3%, cell accuracy: 99.5%, board accuracy: 55.9% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4694, G loss: 0.9799\n",
      "[84/1762] D loss: 1.1792, G loss: 1.0325\n",
      "[164/1762] D loss: 1.3840, G loss: 0.6561\n",
      "[244/1762] D loss: 1.4173, G loss: 0.6746\n",
      "[324/1762] D loss: 1.1561, G loss: 0.7909\n",
      "[404/1762] D loss: 0.9818, G loss: 1.7204\n",
      "[484/1762] D loss: 1.4754, G loss: 0.8736\n",
      "[564/1762] D loss: 1.2889, G loss: 0.6141\n",
      "[644/1762] D loss: 1.2107, G loss: 1.0130\n",
      "[724/1762] D loss: 1.3695, G loss: 0.6542\n",
      "[804/1762] D loss: 1.2767, G loss: 0.6525\n",
      "[884/1762] D loss: 1.3973, G loss: 0.5968\n",
      "[964/1762] D loss: 1.4083, G loss: 0.9230\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.6721\n",
      "[1124/1762] D loss: 1.4622, G loss: 0.4284\n",
      "[1204/1762] D loss: 1.3966, G loss: 0.5567\n",
      "[1284/1762] D loss: 1.2194, G loss: 0.9845\n",
      "[1364/1762] D loss: 1.4002, G loss: 0.6121\n",
      "[1444/1762] D loss: 1.2300, G loss: 0.9674\n",
      "[1524/1762] D loss: 1.3287, G loss: 0.6128\n",
      "[1604/1762] D loss: 1.3967, G loss: 0.7863\n",
      "[1684/1762] D loss: 1.4073, G loss: 0.8340\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7173\n",
      "train error: \n",
      " D loss: 1.319524, G loss: 0.729786, D accuracy: 56.3%, cell accuracy: 99.7%, board accuracy: 71.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296158, G loss: 0.745277, D accuracy: 58.6%, cell accuracy: 99.6%, board accuracy: 63.2% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4038, G loss: 0.6729\n",
      "[84/1762] D loss: 1.1827, G loss: 1.0052\n",
      "[164/1762] D loss: 1.2246, G loss: 0.7710\n",
      "[244/1762] D loss: 1.4683, G loss: 0.8735\n",
      "[324/1762] D loss: 1.4316, G loss: 0.4970\n",
      "[404/1762] D loss: 1.3086, G loss: 0.9780\n",
      "[484/1762] D loss: 1.2506, G loss: 0.5319\n",
      "[564/1762] D loss: 1.4398, G loss: 0.5319\n",
      "[644/1762] D loss: 1.3681, G loss: 0.6522\n",
      "[724/1762] D loss: 1.0943, G loss: 0.9309\n",
      "[804/1762] D loss: 1.1865, G loss: 1.0903\n",
      "[884/1762] D loss: 1.3976, G loss: 0.6901\n",
      "[964/1762] D loss: 1.4054, G loss: 0.7519\n",
      "[1044/1762] D loss: 1.5325, G loss: 0.9189\n",
      "[1124/1762] D loss: 1.5039, G loss: 0.6301\n",
      "[1204/1762] D loss: 1.4192, G loss: 0.6693\n",
      "[1284/1762] D loss: 1.4458, G loss: 0.8860\n",
      "[1364/1762] D loss: 1.4011, G loss: 0.8628\n",
      "[1444/1762] D loss: 1.3845, G loss: 0.6167\n",
      "[1524/1762] D loss: 1.4123, G loss: 0.6157\n",
      "[1604/1762] D loss: 1.4009, G loss: 0.7010\n",
      "[1684/1762] D loss: 1.2078, G loss: 0.9562\n",
      "[1762/1762] D loss: 1.4611, G loss: 0.5282\n",
      "train error: \n",
      " D loss: 1.328417, G loss: 0.665253, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 74.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310107, G loss: 0.674467, D accuracy: 58.5%, cell accuracy: 99.7%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3574, G loss: 0.7352\n",
      "[84/1762] D loss: 1.4702, G loss: 0.8622\n",
      "[164/1762] D loss: 1.4137, G loss: 0.7874\n",
      "[244/1762] D loss: 1.4132, G loss: 0.6376\n",
      "[324/1762] D loss: 1.4702, G loss: 0.6115\n",
      "[404/1762] D loss: 0.9334, G loss: 1.1919\n",
      "[484/1762] D loss: 1.5060, G loss: 1.0030\n",
      "[564/1762] D loss: 1.1201, G loss: 0.6412\n",
      "[644/1762] D loss: 1.1915, G loss: 0.9674\n",
      "[724/1762] D loss: 1.3970, G loss: 0.6221\n",
      "[804/1762] D loss: 1.4087, G loss: 0.8185\n",
      "[884/1762] D loss: 1.4552, G loss: 0.4764\n",
      "[964/1762] D loss: 1.1656, G loss: 1.1505\n",
      "[1044/1762] D loss: 1.3959, G loss: 0.6510\n",
      "[1124/1762] D loss: 1.2159, G loss: 0.8343\n",
      "[1204/1762] D loss: 1.4148, G loss: 0.6872\n",
      "[1284/1762] D loss: 1.4041, G loss: 0.7433\n",
      "[1364/1762] D loss: 1.4174, G loss: 0.7816\n",
      "[1444/1762] D loss: 1.4808, G loss: 0.5301\n",
      "[1524/1762] D loss: 1.2063, G loss: 1.0169\n",
      "[1604/1762] D loss: 1.2180, G loss: 0.6747\n",
      "[1684/1762] D loss: 1.5330, G loss: 0.9336\n",
      "[1762/1762] D loss: 1.3138, G loss: 0.5639\n",
      "train error: \n",
      " D loss: 1.372081, G loss: 0.549608, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353176, G loss: 0.556121, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4413, G loss: 0.7207\n",
      "[84/1762] D loss: 1.1801, G loss: 0.8313\n",
      "[164/1762] D loss: 1.4406, G loss: 0.6234\n",
      "[244/1762] D loss: 1.2827, G loss: 0.8333\n",
      "[324/1762] D loss: 1.4246, G loss: 0.6846\n",
      "[404/1762] D loss: 1.4117, G loss: 0.6806\n",
      "[484/1762] D loss: 1.3951, G loss: 0.5735\n",
      "[564/1762] D loss: 1.3974, G loss: 0.7530\n",
      "[644/1762] D loss: 1.4784, G loss: 0.9029\n",
      "[724/1762] D loss: 1.1596, G loss: 1.1707\n",
      "[804/1762] D loss: 1.1941, G loss: 1.0868\n",
      "[884/1762] D loss: 1.3991, G loss: 0.7040\n",
      "[964/1762] D loss: 1.3743, G loss: 0.8124\n",
      "[1044/1762] D loss: 1.3683, G loss: 0.7054\n",
      "[1124/1762] D loss: 1.4114, G loss: 0.7624\n",
      "[1204/1762] D loss: 1.4058, G loss: 0.7196\n",
      "[1284/1762] D loss: 1.4187, G loss: 0.6772\n",
      "[1364/1762] D loss: 1.1555, G loss: 0.7673\n",
      "[1444/1762] D loss: 1.3129, G loss: 0.7687\n",
      "[1524/1762] D loss: 1.3773, G loss: 0.8783\n",
      "[1604/1762] D loss: 1.4740, G loss: 0.4966\n",
      "[1684/1762] D loss: 1.2345, G loss: 0.7845\n",
      "[1762/1762] D loss: 1.5077, G loss: 1.0458\n",
      "train error: \n",
      " D loss: 1.407004, G loss: 1.159474, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384487, G loss: 1.170738, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4715, G loss: 0.7865\n",
      "[84/1762] D loss: 1.3860, G loss: 0.7759\n",
      "[164/1762] D loss: 1.3786, G loss: 0.5739\n",
      "[244/1762] D loss: 1.4205, G loss: 0.8344\n",
      "[324/1762] D loss: 1.3971, G loss: 0.6244\n",
      "[404/1762] D loss: 1.4721, G loss: 1.1279\n",
      "[484/1762] D loss: 1.4224, G loss: 0.5029\n",
      "[564/1762] D loss: 1.3723, G loss: 0.9619\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6797\n",
      "[724/1762] D loss: 1.3897, G loss: 0.6470\n",
      "[804/1762] D loss: 1.3954, G loss: 0.6356\n",
      "[884/1762] D loss: 1.3939, G loss: 0.7900\n",
      "[964/1762] D loss: 1.4096, G loss: 0.7391\n",
      "[1044/1762] D loss: 1.1880, G loss: 0.9238\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.5930\n",
      "[1204/1762] D loss: 1.1720, G loss: 0.9095\n",
      "[1284/1762] D loss: 1.3415, G loss: 1.0044\n",
      "[1364/1762] D loss: 1.2000, G loss: 0.8411\n",
      "[1444/1762] D loss: 1.2242, G loss: 0.7540\n",
      "[1524/1762] D loss: 1.1576, G loss: 1.5422\n",
      "[1604/1762] D loss: 1.1959, G loss: 0.6521\n",
      "[1684/1762] D loss: 1.4135, G loss: 0.8417\n",
      "[1762/1762] D loss: 1.0428, G loss: 1.5066\n",
      "train error: \n",
      " D loss: 1.346589, G loss: 1.006717, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 75.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326306, G loss: 1.017299, D accuracy: 55.9%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4411, G loss: 0.8201\n",
      "[84/1762] D loss: 1.4211, G loss: 0.6338\n",
      "[164/1762] D loss: 1.1620, G loss: 0.8403\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6773\n",
      "[324/1762] D loss: 1.4713, G loss: 1.0136\n",
      "[404/1762] D loss: 1.1686, G loss: 0.9754\n",
      "[484/1762] D loss: 1.4021, G loss: 0.6812\n",
      "[564/1762] D loss: 1.1918, G loss: 0.7644\n",
      "[644/1762] D loss: 1.3871, G loss: 0.8749\n",
      "[724/1762] D loss: 1.4834, G loss: 0.7821\n",
      "[804/1762] D loss: 1.4059, G loss: 0.9368\n",
      "[884/1762] D loss: 1.4067, G loss: 0.8605\n",
      "[964/1762] D loss: 1.3965, G loss: 0.9732\n",
      "[1044/1762] D loss: 1.3504, G loss: 0.6711\n",
      "[1124/1762] D loss: 1.1770, G loss: 1.0047\n",
      "[1204/1762] D loss: 1.1366, G loss: 0.9019\n",
      "[1284/1762] D loss: 1.1762, G loss: 0.8458\n",
      "[1364/1762] D loss: 1.4126, G loss: 0.5739\n",
      "[1444/1762] D loss: 1.5300, G loss: 0.6070\n",
      "[1524/1762] D loss: 1.1933, G loss: 0.7458\n",
      "[1604/1762] D loss: 1.1537, G loss: 0.9264\n",
      "[1684/1762] D loss: 1.1863, G loss: 0.9892\n",
      "[1762/1762] D loss: 1.4143, G loss: 0.7455\n",
      "train error: \n",
      " D loss: 1.333676, G loss: 0.721109, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 69.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318487, G loss: 0.730890, D accuracy: 55.7%, cell accuracy: 99.5%, board accuracy: 66.1% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3996, G loss: 0.5690\n",
      "[84/1762] D loss: 1.1996, G loss: 1.1022\n",
      "[164/1762] D loss: 1.4034, G loss: 0.7437\n",
      "[244/1762] D loss: 1.1673, G loss: 0.7382\n",
      "[324/1762] D loss: 1.4284, G loss: 0.6756\n",
      "[404/1762] D loss: 1.4767, G loss: 0.8131\n",
      "[484/1762] D loss: 1.3901, G loss: 0.6203\n",
      "[564/1762] D loss: 1.4502, G loss: 0.5211\n",
      "[644/1762] D loss: 1.4147, G loss: 0.8501\n",
      "[724/1762] D loss: 1.4487, G loss: 0.8784\n",
      "[804/1762] D loss: 1.1230, G loss: 0.6808\n",
      "[884/1762] D loss: 1.3686, G loss: 0.5980\n",
      "[964/1762] D loss: 1.3825, G loss: 0.6319\n",
      "[1044/1762] D loss: 1.4460, G loss: 0.7985\n",
      "[1124/1762] D loss: 1.4390, G loss: 0.8103\n",
      "[1204/1762] D loss: 1.4355, G loss: 0.6555\n",
      "[1284/1762] D loss: 1.1814, G loss: 1.0019\n",
      "[1364/1762] D loss: 1.4585, G loss: 0.6166\n",
      "[1444/1762] D loss: 1.2404, G loss: 0.7541\n",
      "[1524/1762] D loss: 1.3664, G loss: 0.6723\n",
      "[1604/1762] D loss: 1.4459, G loss: 0.7797\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7271\n",
      "[1762/1762] D loss: 1.3064, G loss: 0.8374\n",
      "train error: \n",
      " D loss: 1.319921, G loss: 0.886234, D accuracy: 56.4%, cell accuracy: 99.6%, board accuracy: 69.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301806, G loss: 0.897723, D accuracy: 57.6%, cell accuracy: 99.5%, board accuracy: 64.1% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2333, G loss: 0.9985\n",
      "[84/1762] D loss: 1.1872, G loss: 0.8773\n",
      "[164/1762] D loss: 1.2479, G loss: 0.8772\n",
      "[244/1762] D loss: 1.4755, G loss: 0.4154\n",
      "[324/1762] D loss: 1.4143, G loss: 0.8093\n",
      "[404/1762] D loss: 1.5501, G loss: 1.0005\n",
      "[484/1762] D loss: 1.2753, G loss: 1.1129\n",
      "[564/1762] D loss: 1.3597, G loss: 0.8735\n",
      "[644/1762] D loss: 1.4263, G loss: 0.9490\n",
      "[724/1762] D loss: 1.3929, G loss: 0.5891\n",
      "[804/1762] D loss: 1.3975, G loss: 0.7430\n",
      "[884/1762] D loss: 1.3479, G loss: 0.8849\n",
      "[964/1762] D loss: 1.3963, G loss: 0.5548\n",
      "[1044/1762] D loss: 1.2035, G loss: 1.1476\n",
      "[1124/1762] D loss: 1.4449, G loss: 0.9283\n",
      "[1204/1762] D loss: 1.4103, G loss: 0.8061\n",
      "[1284/1762] D loss: 1.3668, G loss: 0.6600\n",
      "[1364/1762] D loss: 1.1528, G loss: 0.9580\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7846\n",
      "[1524/1762] D loss: 1.4586, G loss: 0.8062\n",
      "[1604/1762] D loss: 1.2766, G loss: 0.8230\n",
      "[1684/1762] D loss: 1.2472, G loss: 0.8226\n",
      "[1762/1762] D loss: 1.4113, G loss: 0.8062\n",
      "train error: \n",
      " D loss: 1.324761, G loss: 0.758379, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 76.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303515, G loss: 0.782192, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1884, G loss: 0.7378\n",
      "[84/1762] D loss: 1.3542, G loss: 0.6276\n",
      "[164/1762] D loss: 1.4412, G loss: 0.7564\n",
      "[244/1762] D loss: 1.3660, G loss: 0.7002\n",
      "[324/1762] D loss: 1.4359, G loss: 0.7460\n",
      "[404/1762] D loss: 1.2360, G loss: 0.9220\n",
      "[484/1762] D loss: 1.2263, G loss: 0.6753\n",
      "[564/1762] D loss: 1.1833, G loss: 0.6628\n",
      "[644/1762] D loss: 1.4110, G loss: 0.8203\n",
      "[724/1762] D loss: 1.3264, G loss: 0.6554\n",
      "[804/1762] D loss: 1.3952, G loss: 0.8080\n",
      "[884/1762] D loss: 1.4575, G loss: 0.8772\n",
      "[964/1762] D loss: 1.3939, G loss: 0.6603\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.7175\n",
      "[1124/1762] D loss: 1.3428, G loss: 0.6669\n",
      "[1204/1762] D loss: 1.4585, G loss: 0.7690\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7082\n",
      "[1364/1762] D loss: 1.0210, G loss: 0.8939\n",
      "[1444/1762] D loss: 1.4199, G loss: 0.7647\n",
      "[1524/1762] D loss: 1.3766, G loss: 0.7492\n",
      "[1604/1762] D loss: 1.3618, G loss: 0.8192\n",
      "[1684/1762] D loss: 1.2660, G loss: 0.9651\n",
      "[1762/1762] D loss: 0.9560, G loss: 1.0447\n",
      "train error: \n",
      " D loss: 1.345904, G loss: 0.884933, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 76.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331941, G loss: 0.891518, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.8497\n",
      "[84/1762] D loss: 1.4074, G loss: 0.6875\n",
      "[164/1762] D loss: 1.4177, G loss: 0.8230\n",
      "[244/1762] D loss: 1.2076, G loss: 0.8094\n",
      "[324/1762] D loss: 1.3971, G loss: 0.6288\n",
      "[404/1762] D loss: 1.4263, G loss: 1.0123\n",
      "[484/1762] D loss: 1.3337, G loss: 0.5933\n",
      "[564/1762] D loss: 1.4575, G loss: 1.0471\n",
      "[644/1762] D loss: 1.3937, G loss: 0.6532\n",
      "[724/1762] D loss: 1.3939, G loss: 0.8521\n",
      "[804/1762] D loss: 1.1792, G loss: 0.6941\n",
      "[884/1762] D loss: 1.4200, G loss: 0.9247\n",
      "[964/1762] D loss: 1.3515, G loss: 0.8339\n",
      "[1044/1762] D loss: 1.1845, G loss: 0.8987\n",
      "[1124/1762] D loss: 1.4216, G loss: 0.6315\n",
      "[1204/1762] D loss: 1.3965, G loss: 0.7265\n",
      "[1284/1762] D loss: 1.4586, G loss: 0.6475\n",
      "[1364/1762] D loss: 1.3745, G loss: 0.6548\n",
      "[1444/1762] D loss: 1.3937, G loss: 0.5673\n",
      "[1524/1762] D loss: 1.3793, G loss: 0.7043\n",
      "[1604/1762] D loss: 1.1884, G loss: 0.8603\n",
      "[1684/1762] D loss: 1.2975, G loss: 0.5512\n",
      "[1762/1762] D loss: 1.4145, G loss: 0.8031\n",
      "train error: \n",
      " D loss: 1.342900, G loss: 0.815618, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326352, G loss: 0.829288, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3947, G loss: 0.6888\n",
      "[84/1762] D loss: 1.0446, G loss: 0.8450\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7206\n",
      "[244/1762] D loss: 1.3999, G loss: 0.6309\n",
      "[324/1762] D loss: 1.3904, G loss: 0.8767\n",
      "[404/1762] D loss: 1.3947, G loss: 0.6939\n",
      "[484/1762] D loss: 1.3942, G loss: 0.6074\n",
      "[564/1762] D loss: 1.4680, G loss: 0.9415\n",
      "[644/1762] D loss: 1.2092, G loss: 0.8783\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7626\n",
      "[804/1762] D loss: 1.4635, G loss: 0.9605\n",
      "[884/1762] D loss: 1.4680, G loss: 0.4834\n",
      "[964/1762] D loss: 1.4236, G loss: 0.8551\n",
      "[1044/1762] D loss: 1.1993, G loss: 0.8652\n",
      "[1124/1762] D loss: 1.3969, G loss: 0.8240\n",
      "[1204/1762] D loss: 1.3901, G loss: 0.6448\n",
      "[1284/1762] D loss: 1.4606, G loss: 1.0048\n",
      "[1364/1762] D loss: 1.4029, G loss: 0.6347\n",
      "[1444/1762] D loss: 1.0506, G loss: 0.9223\n",
      "[1524/1762] D loss: 1.2281, G loss: 0.6441\n",
      "[1604/1762] D loss: 1.4338, G loss: 0.6505\n",
      "[1684/1762] D loss: 1.2591, G loss: 0.7840\n",
      "[1762/1762] D loss: 1.4199, G loss: 0.8076\n",
      "train error: \n",
      " D loss: 1.336991, G loss: 0.783719, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323916, G loss: 0.793631, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4362, G loss: 0.7038\n",
      "[84/1762] D loss: 1.3645, G loss: 0.6792\n",
      "[164/1762] D loss: 1.2520, G loss: 0.8101\n",
      "[244/1762] D loss: 1.4187, G loss: 0.7695\n",
      "[324/1762] D loss: 1.3909, G loss: 0.6519\n",
      "[404/1762] D loss: 1.3872, G loss: 0.8198\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7102\n",
      "[564/1762] D loss: 1.3929, G loss: 0.6920\n",
      "[644/1762] D loss: 1.3917, G loss: 0.7772\n",
      "[724/1762] D loss: 1.1918, G loss: 0.6919\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6963\n",
      "[884/1762] D loss: 1.1610, G loss: 0.8333\n",
      "[964/1762] D loss: 1.4073, G loss: 0.5803\n",
      "[1044/1762] D loss: 1.3770, G loss: 0.6395\n",
      "[1124/1762] D loss: 1.2835, G loss: 0.6892\n",
      "[1204/1762] D loss: 1.3501, G loss: 0.7307\n",
      "[1284/1762] D loss: 1.3999, G loss: 0.7209\n",
      "[1364/1762] D loss: 1.3944, G loss: 0.6182\n",
      "[1444/1762] D loss: 1.1947, G loss: 0.7381\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6838\n",
      "[1604/1762] D loss: 1.4101, G loss: 0.7482\n",
      "[1684/1762] D loss: 1.4529, G loss: 0.8615\n",
      "[1762/1762] D loss: 1.4078, G loss: 0.6985\n",
      "train error: \n",
      " D loss: 1.341460, G loss: 0.676992, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328327, G loss: 0.684714, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915, G loss: 0.6183\n",
      "[84/1762] D loss: 1.3894, G loss: 0.8393\n",
      "[164/1762] D loss: 1.3927, G loss: 0.5910\n",
      "[244/1762] D loss: 1.4043, G loss: 0.7517\n",
      "[324/1762] D loss: 1.4616, G loss: 0.7609\n",
      "[404/1762] D loss: 1.3566, G loss: 0.6196\n",
      "[484/1762] D loss: 1.4033, G loss: 0.9464\n",
      "[564/1762] D loss: 1.1915, G loss: 0.9232\n",
      "[644/1762] D loss: 1.3916, G loss: 0.6795\n",
      "[724/1762] D loss: 1.4148, G loss: 0.6310\n",
      "[804/1762] D loss: 1.1605, G loss: 0.7975\n",
      "[884/1762] D loss: 1.1765, G loss: 1.0131\n",
      "[964/1762] D loss: 1.3581, G loss: 0.7034\n",
      "[1044/1762] D loss: 1.1169, G loss: 1.0320\n",
      "[1124/1762] D loss: 1.1935, G loss: 0.8356\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.7431\n",
      "[1284/1762] D loss: 1.3678, G loss: 0.7381\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.7809\n",
      "[1444/1762] D loss: 1.4288, G loss: 0.5296\n",
      "[1524/1762] D loss: 1.4389, G loss: 0.8026\n",
      "[1604/1762] D loss: 1.1680, G loss: 0.7664\n",
      "[1684/1762] D loss: 1.4212, G loss: 0.6144\n",
      "[1762/1762] D loss: 1.5256, G loss: 0.9759\n",
      "train error: \n",
      " D loss: 1.334643, G loss: 0.715563, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318183, G loss: 0.725472, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3919, G loss: 0.6379\n",
      "[84/1762] D loss: 1.4213, G loss: 0.5999\n",
      "[164/1762] D loss: 1.3783, G loss: 0.6927\n",
      "[244/1762] D loss: 1.4261, G loss: 0.7455\n",
      "[324/1762] D loss: 1.4047, G loss: 0.7482\n",
      "[404/1762] D loss: 1.1566, G loss: 0.8408\n",
      "[484/1762] D loss: 1.1765, G loss: 0.9965\n",
      "[564/1762] D loss: 1.3921, G loss: 0.6782\n",
      "[644/1762] D loss: 1.3965, G loss: 0.6810\n",
      "[724/1762] D loss: 1.3817, G loss: 0.8161\n",
      "[804/1762] D loss: 1.4267, G loss: 0.5874\n",
      "[884/1762] D loss: 1.3753, G loss: 0.7028\n",
      "[964/1762] D loss: 1.4263, G loss: 0.7092\n",
      "[1044/1762] D loss: 1.3616, G loss: 0.7297\n",
      "[1124/1762] D loss: 1.4342, G loss: 0.7518\n",
      "[1204/1762] D loss: 1.4223, G loss: 0.7640\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.7953\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.7207\n",
      "[1444/1762] D loss: 1.1597, G loss: 0.9424\n",
      "[1524/1762] D loss: 1.4244, G loss: 0.7326\n",
      "[1604/1762] D loss: 1.4092, G loss: 0.6464\n",
      "[1684/1762] D loss: 1.1972, G loss: 0.7583\n",
      "[1762/1762] D loss: 0.9040, G loss: 1.1054\n",
      "train error: \n",
      " D loss: 1.348658, G loss: 0.886920, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329483, G loss: 0.898796, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4061, G loss: 0.8053\n",
      "[84/1762] D loss: 1.4062, G loss: 0.6915\n",
      "[164/1762] D loss: 1.3979, G loss: 0.6505\n",
      "[244/1762] D loss: 1.4319, G loss: 0.8142\n",
      "[324/1762] D loss: 1.4234, G loss: 0.9748\n",
      "[404/1762] D loss: 0.9307, G loss: 1.0510\n",
      "[484/1762] D loss: 1.1839, G loss: 0.8101\n",
      "[564/1762] D loss: 1.1626, G loss: 0.8741\n",
      "[644/1762] D loss: 1.3880, G loss: 0.7678\n",
      "[724/1762] D loss: 1.4051, G loss: 0.8109\n",
      "[804/1762] D loss: 1.4057, G loss: 0.6013\n",
      "[884/1762] D loss: 1.4279, G loss: 0.7537\n",
      "[964/1762] D loss: 1.3900, G loss: 0.6510\n",
      "[1044/1762] D loss: 1.4069, G loss: 0.5246\n",
      "[1124/1762] D loss: 1.2102, G loss: 0.7554\n",
      "[1204/1762] D loss: 1.1552, G loss: 0.9518\n",
      "[1284/1762] D loss: 1.4181, G loss: 0.9057\n",
      "[1364/1762] D loss: 1.4016, G loss: 0.6568\n",
      "[1444/1762] D loss: 1.1421, G loss: 0.9503\n",
      "[1524/1762] D loss: 1.1427, G loss: 0.9619\n",
      "[1604/1762] D loss: 1.4218, G loss: 0.5972\n",
      "[1684/1762] D loss: 1.1967, G loss: 0.9365\n",
      "[1762/1762] D loss: 1.4052, G loss: 0.6037\n",
      "train error: \n",
      " D loss: 1.329424, G loss: 0.717817, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311751, G loss: 0.726436, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1525, G loss: 0.8835\n",
      "[84/1762] D loss: 1.4051, G loss: 0.8126\n",
      "[164/1762] D loss: 1.1462, G loss: 0.9185\n",
      "[244/1762] D loss: 1.1985, G loss: 0.8074\n",
      "[324/1762] D loss: 1.3949, G loss: 0.5739\n",
      "[404/1762] D loss: 1.3916, G loss: 0.7917\n",
      "[484/1762] D loss: 1.3972, G loss: 0.6810\n",
      "[564/1762] D loss: 1.4023, G loss: 0.7233\n",
      "[644/1762] D loss: 1.4034, G loss: 0.5934\n",
      "[724/1762] D loss: 1.3908, G loss: 0.7597\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6590\n",
      "[884/1762] D loss: 1.4962, G loss: 1.0758\n",
      "[964/1762] D loss: 1.4338, G loss: 0.5814\n",
      "[1044/1762] D loss: 1.3036, G loss: 0.7774\n",
      "[1124/1762] D loss: 1.1188, G loss: 0.9512\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.5586\n",
      "[1284/1762] D loss: 1.4152, G loss: 0.9171\n",
      "[1364/1762] D loss: 1.1666, G loss: 0.8279\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.7360\n",
      "[1524/1762] D loss: 1.4249, G loss: 0.7749\n",
      "[1604/1762] D loss: 1.1621, G loss: 0.7647\n",
      "[1684/1762] D loss: 1.4256, G loss: 0.7934\n",
      "[1762/1762] D loss: 0.9671, G loss: 0.9368\n",
      "train error: \n",
      " D loss: 1.324049, G loss: 0.756582, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305717, G loss: 0.763967, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4188, G loss: 0.8435\n",
      "[84/1762] D loss: 1.1463, G loss: 0.9536\n",
      "[164/1762] D loss: 1.3918, G loss: 0.7616\n",
      "[244/1762] D loss: 1.3853, G loss: 0.6213\n",
      "[324/1762] D loss: 1.4055, G loss: 0.7075\n",
      "[404/1762] D loss: 1.4023, G loss: 0.5707\n",
      "[484/1762] D loss: 1.4542, G loss: 0.8928\n",
      "[564/1762] D loss: 1.3969, G loss: 0.6736\n",
      "[644/1762] D loss: 1.3381, G loss: 0.7724\n",
      "[724/1762] D loss: 1.4007, G loss: 0.6006\n",
      "[804/1762] D loss: 1.3793, G loss: 0.6391\n",
      "[884/1762] D loss: 1.4404, G loss: 0.7485\n",
      "[964/1762] D loss: 1.3908, G loss: 0.7002\n",
      "[1044/1762] D loss: 1.1516, G loss: 1.0213\n",
      "[1124/1762] D loss: 1.1469, G loss: 0.8498\n",
      "[1204/1762] D loss: 1.1511, G loss: 0.8118\n",
      "[1284/1762] D loss: 1.4191, G loss: 0.6575\n",
      "[1364/1762] D loss: 1.3977, G loss: 0.8060\n",
      "[1444/1762] D loss: 1.3931, G loss: 0.7094\n",
      "[1524/1762] D loss: 1.3975, G loss: 0.6212\n",
      "[1604/1762] D loss: 0.9960, G loss: 0.8847\n",
      "[1684/1762] D loss: 1.3897, G loss: 0.6093\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.5403\n",
      "train error: \n",
      " D loss: 1.343610, G loss: 0.615487, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 75.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325318, G loss: 0.624788, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 70.9% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.5262\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6522\n",
      "[164/1762] D loss: 1.1753, G loss: 0.6773\n",
      "[244/1762] D loss: 1.4182, G loss: 0.7988\n",
      "[324/1762] D loss: 1.3958, G loss: 0.6549\n",
      "[404/1762] D loss: 1.4578, G loss: 0.8396\n",
      "[484/1762] D loss: 1.1045, G loss: 0.8045\n",
      "[564/1762] D loss: 1.3447, G loss: 0.7922\n",
      "[644/1762] D loss: 1.3903, G loss: 0.7772\n",
      "[724/1762] D loss: 1.4157, G loss: 0.8108\n",
      "[804/1762] D loss: 1.3748, G loss: 0.6937\n",
      "[884/1762] D loss: 1.4113, G loss: 0.6753\n",
      "[964/1762] D loss: 1.1499, G loss: 0.8578\n",
      "[1044/1762] D loss: 1.4527, G loss: 0.8333\n",
      "[1124/1762] D loss: 1.4159, G loss: 0.6526\n",
      "[1204/1762] D loss: 1.1672, G loss: 0.6775\n",
      "[1284/1762] D loss: 1.3759, G loss: 0.6460\n",
      "[1364/1762] D loss: 1.4158, G loss: 0.7781\n",
      "[1444/1762] D loss: 1.1625, G loss: 0.8118\n",
      "[1524/1762] D loss: 1.3777, G loss: 0.6679\n",
      "[1604/1762] D loss: 1.1649, G loss: 1.0066\n",
      "[1684/1762] D loss: 1.1379, G loss: 0.9638\n",
      "[1762/1762] D loss: 0.9105, G loss: 0.8697\n",
      "train error: \n",
      " D loss: 1.347261, G loss: 0.625627, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326196, G loss: 0.635906, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4118, G loss: 0.6475\n",
      "[84/1762] D loss: 1.1524, G loss: 0.8370\n",
      "[164/1762] D loss: 1.2725, G loss: 0.5939\n",
      "[244/1762] D loss: 1.5488, G loss: 0.7984\n",
      "[324/1762] D loss: 1.3949, G loss: 0.5570\n",
      "[404/1762] D loss: 1.4131, G loss: 0.9053\n",
      "[484/1762] D loss: 1.3903, G loss: 0.6602\n",
      "[564/1762] D loss: 1.3952, G loss: 0.6447\n",
      "[644/1762] D loss: 1.3967, G loss: 0.6737\n",
      "[724/1762] D loss: 1.3975, G loss: 0.6291\n",
      "[804/1762] D loss: 1.1494, G loss: 1.0148\n",
      "[884/1762] D loss: 1.4328, G loss: 0.7913\n",
      "[964/1762] D loss: 0.9390, G loss: 1.1272\n",
      "[1044/1762] D loss: 1.4009, G loss: 0.7690\n",
      "[1124/1762] D loss: 1.1448, G loss: 0.9284\n",
      "[1204/1762] D loss: 1.2183, G loss: 0.7549\n",
      "[1284/1762] D loss: 1.4236, G loss: 0.7139\n",
      "[1364/1762] D loss: 1.4275, G loss: 0.7875\n",
      "[1444/1762] D loss: 1.1443, G loss: 0.8470\n",
      "[1524/1762] D loss: 1.3738, G loss: 0.6484\n",
      "[1604/1762] D loss: 1.4159, G loss: 0.6797\n",
      "[1684/1762] D loss: 1.3962, G loss: 0.7764\n",
      "[1762/1762] D loss: 0.9036, G loss: 1.0689\n",
      "train error: \n",
      " D loss: 1.351897, G loss: 0.922988, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330373, G loss: 0.935096, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4033, G loss: 0.8238\n",
      "[84/1762] D loss: 1.4050, G loss: 0.7927\n",
      "[164/1762] D loss: 1.3843, G loss: 0.5293\n",
      "[244/1762] D loss: 1.1496, G loss: 0.8335\n",
      "[324/1762] D loss: 1.3900, G loss: 0.8353\n",
      "[404/1762] D loss: 1.4036, G loss: 0.7818\n",
      "[484/1762] D loss: 1.1367, G loss: 0.7806\n",
      "[564/1762] D loss: 1.3806, G loss: 0.7028\n",
      "[644/1762] D loss: 1.3924, G loss: 0.7159\n",
      "[724/1762] D loss: 1.3908, G loss: 0.6338\n",
      "[804/1762] D loss: 1.3908, G loss: 0.8663\n",
      "[884/1762] D loss: 1.4229, G loss: 0.7581\n",
      "[964/1762] D loss: 1.4245, G loss: 0.8154\n",
      "[1044/1762] D loss: 1.3935, G loss: 0.6713\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.6791\n",
      "[1204/1762] D loss: 1.3916, G loss: 0.6302\n",
      "[1284/1762] D loss: 1.4489, G loss: 0.8805\n",
      "[1364/1762] D loss: 1.4211, G loss: 0.5554\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.7507\n",
      "[1524/1762] D loss: 1.1859, G loss: 0.6764\n",
      "[1604/1762] D loss: 1.3299, G loss: 0.7641\n",
      "[1684/1762] D loss: 1.1658, G loss: 0.8165\n",
      "[1762/1762] D loss: 1.3645, G loss: 0.8279\n",
      "train error: \n",
      " D loss: 1.334193, G loss: 0.649501, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317030, G loss: 0.660965, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4081, G loss: 0.5737\n",
      "[84/1762] D loss: 1.3842, G loss: 0.7856\n",
      "[164/1762] D loss: 1.1871, G loss: 0.7915\n",
      "[244/1762] D loss: 1.4150, G loss: 0.5802\n",
      "[324/1762] D loss: 1.3340, G loss: 0.7957\n",
      "[404/1762] D loss: 1.3914, G loss: 0.7085\n",
      "[484/1762] D loss: 1.0263, G loss: 0.8713\n",
      "[564/1762] D loss: 1.4165, G loss: 0.5319\n",
      "[644/1762] D loss: 1.4111, G loss: 0.6847\n",
      "[724/1762] D loss: 1.1701, G loss: 0.8946\n",
      "[804/1762] D loss: 0.9271, G loss: 1.0845\n",
      "[884/1762] D loss: 1.3717, G loss: 0.6056\n",
      "[964/1762] D loss: 1.1501, G loss: 0.9990\n",
      "[1044/1762] D loss: 1.1729, G loss: 0.8113\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.7030\n",
      "[1204/1762] D loss: 1.0849, G loss: 0.8035\n",
      "[1284/1762] D loss: 1.4489, G loss: 0.8848\n",
      "[1364/1762] D loss: 1.3974, G loss: 0.6497\n",
      "[1444/1762] D loss: 1.3041, G loss: 0.6916\n",
      "[1524/1762] D loss: 1.3826, G loss: 0.8265\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6190\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.6811\n",
      "[1762/1762] D loss: 1.4237, G loss: 0.8556\n",
      "train error: \n",
      " D loss: 1.321989, G loss: 0.761847, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303463, G loss: 0.773336, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4207, G loss: 0.6308\n",
      "[84/1762] D loss: 1.3858, G loss: 0.6561\n",
      "[164/1762] D loss: 1.3292, G loss: 0.7299\n",
      "[244/1762] D loss: 1.1794, G loss: 0.7608\n",
      "[324/1762] D loss: 1.3829, G loss: 0.7763\n",
      "[404/1762] D loss: 1.3893, G loss: 0.7098\n",
      "[484/1762] D loss: 1.1869, G loss: 1.1006\n",
      "[564/1762] D loss: 1.3429, G loss: 0.6124\n",
      "[644/1762] D loss: 1.4664, G loss: 0.7076\n",
      "[724/1762] D loss: 1.4047, G loss: 0.6377\n",
      "[804/1762] D loss: 1.4232, G loss: 0.8212\n",
      "[884/1762] D loss: 1.3948, G loss: 0.5934\n",
      "[964/1762] D loss: 1.4952, G loss: 1.0902\n",
      "[1044/1762] D loss: 1.1900, G loss: 0.9426\n",
      "[1124/1762] D loss: 1.4011, G loss: 0.7842\n",
      "[1204/1762] D loss: 1.4563, G loss: 0.6079\n",
      "[1284/1762] D loss: 1.4025, G loss: 0.6696\n",
      "[1364/1762] D loss: 1.2449, G loss: 0.7913\n",
      "[1444/1762] D loss: 1.4120, G loss: 0.6981\n",
      "[1524/1762] D loss: 1.3748, G loss: 0.7675\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.6239\n",
      "[1684/1762] D loss: 1.1839, G loss: 0.6907\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7482\n",
      "train error: \n",
      " D loss: 1.335885, G loss: 0.841178, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 71.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315079, G loss: 0.853759, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 65.9% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2215, G loss: 1.0325\n",
      "[84/1762] D loss: 1.3908, G loss: 0.7682\n",
      "[164/1762] D loss: 1.1588, G loss: 0.9900\n",
      "[244/1762] D loss: 1.4037, G loss: 0.6176\n",
      "[324/1762] D loss: 1.4028, G loss: 0.6620\n",
      "[404/1762] D loss: 1.3960, G loss: 0.5804\n",
      "[484/1762] D loss: 1.4215, G loss: 0.8375\n",
      "[564/1762] D loss: 1.4079, G loss: 0.6263\n",
      "[644/1762] D loss: 1.3768, G loss: 0.7815\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6405\n",
      "[804/1762] D loss: 1.3920, G loss: 0.7119\n",
      "[884/1762] D loss: 1.4037, G loss: 0.6461\n",
      "[964/1762] D loss: 1.1492, G loss: 0.8415\n",
      "[1044/1762] D loss: 1.4028, G loss: 0.7472\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.7501\n",
      "[1204/1762] D loss: 1.3950, G loss: 0.6051\n",
      "[1284/1762] D loss: 1.1628, G loss: 1.0616\n",
      "[1364/1762] D loss: 1.1505, G loss: 0.8093\n",
      "[1444/1762] D loss: 1.3921, G loss: 0.6653\n",
      "[1524/1762] D loss: 1.1664, G loss: 0.8610\n",
      "[1604/1762] D loss: 1.4062, G loss: 0.7848\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.7206\n",
      "[1762/1762] D loss: 1.4343, G loss: 0.7569\n",
      "train error: \n",
      " D loss: 1.325810, G loss: 0.696434, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307526, G loss: 0.705513, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1596, G loss: 0.7351\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6907\n",
      "[164/1762] D loss: 1.3521, G loss: 0.6229\n",
      "[244/1762] D loss: 1.3966, G loss: 0.8253\n",
      "[324/1762] D loss: 1.3939, G loss: 0.6921\n",
      "[404/1762] D loss: 1.3859, G loss: 0.6149\n",
      "[484/1762] D loss: 1.3956, G loss: 0.6875\n",
      "[564/1762] D loss: 1.3992, G loss: 0.7618\n",
      "[644/1762] D loss: 1.4162, G loss: 0.6635\n",
      "[724/1762] D loss: 1.1489, G loss: 0.7438\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7119\n",
      "[884/1762] D loss: 1.4060, G loss: 0.8139\n",
      "[964/1762] D loss: 1.3440, G loss: 0.7877\n",
      "[1044/1762] D loss: 1.3942, G loss: 0.8209\n",
      "[1124/1762] D loss: 1.3969, G loss: 0.7509\n",
      "[1204/1762] D loss: 1.4250, G loss: 0.7413\n",
      "[1284/1762] D loss: 1.4120, G loss: 0.8446\n",
      "[1364/1762] D loss: 1.1278, G loss: 1.0206\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6124\n",
      "[1524/1762] D loss: 1.3769, G loss: 0.7345\n",
      "[1604/1762] D loss: 0.9240, G loss: 1.0929\n",
      "[1684/1762] D loss: 1.1625, G loss: 0.9667\n",
      "[1762/1762] D loss: 0.9470, G loss: 0.8456\n",
      "train error: \n",
      " D loss: 1.328742, G loss: 0.664331, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310663, G loss: 0.674150, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3784, G loss: 0.7890\n",
      "[84/1762] D loss: 1.4139, G loss: 0.6820\n",
      "[164/1762] D loss: 1.3680, G loss: 0.6809\n",
      "[244/1762] D loss: 1.1350, G loss: 0.9577\n",
      "[324/1762] D loss: 1.3910, G loss: 0.6300\n",
      "[404/1762] D loss: 1.1503, G loss: 1.0173\n",
      "[484/1762] D loss: 1.3801, G loss: 0.6835\n",
      "[564/1762] D loss: 1.3920, G loss: 0.6766\n",
      "[644/1762] D loss: 1.3888, G loss: 0.7458\n",
      "[724/1762] D loss: 1.3949, G loss: 0.7006\n",
      "[804/1762] D loss: 1.1426, G loss: 1.1081\n",
      "[884/1762] D loss: 1.3955, G loss: 0.5910\n",
      "[964/1762] D loss: 1.4017, G loss: 0.7151\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.5626\n",
      "[1124/1762] D loss: 0.6698, G loss: 1.2834\n",
      "[1204/1762] D loss: 0.6185, G loss: 1.2501\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.5978\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7183\n",
      "[1444/1762] D loss: 1.3964, G loss: 0.5825\n",
      "[1524/1762] D loss: 1.3605, G loss: 0.8060\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.5765\n",
      "[1684/1762] D loss: 1.1427, G loss: 1.1614\n",
      "[1762/1762] D loss: 1.3667, G loss: 0.5948\n",
      "train error: \n",
      " D loss: 1.334479, G loss: 0.641026, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315751, G loss: 0.652442, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1357, G loss: 0.7430\n",
      "[84/1762] D loss: 1.1122, G loss: 0.7907\n",
      "[164/1762] D loss: 1.4399, G loss: 0.5789\n",
      "[244/1762] D loss: 1.3542, G loss: 0.8791\n",
      "[324/1762] D loss: 1.3910, G loss: 0.8517\n",
      "[404/1762] D loss: 1.3845, G loss: 0.6789\n",
      "[484/1762] D loss: 1.1052, G loss: 1.0106\n",
      "[564/1762] D loss: 1.1341, G loss: 0.8884\n",
      "[644/1762] D loss: 1.3901, G loss: 0.8376\n",
      "[724/1762] D loss: 1.3699, G loss: 0.6596\n",
      "[804/1762] D loss: 1.4057, G loss: 0.7813\n",
      "[884/1762] D loss: 1.3679, G loss: 0.6322\n",
      "[964/1762] D loss: 1.3957, G loss: 0.8049\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.8213\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.5515\n",
      "[1204/1762] D loss: 1.4161, G loss: 0.8817\n",
      "[1284/1762] D loss: 1.3781, G loss: 0.6304\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.5897\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.7135\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.7547\n",
      "[1604/1762] D loss: 1.1452, G loss: 0.8745\n",
      "[1684/1762] D loss: 1.4381, G loss: 0.6479\n",
      "[1762/1762] D loss: 1.4143, G loss: 0.6390\n",
      "train error: \n",
      " D loss: 1.352852, G loss: 0.602112, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333324, G loss: 0.615452, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4109, G loss: 0.6024\n",
      "[84/1762] D loss: 1.1426, G loss: 0.9980\n",
      "[164/1762] D loss: 1.3941, G loss: 0.7048\n",
      "[244/1762] D loss: 1.3720, G loss: 0.6450\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6520\n",
      "[404/1762] D loss: 1.3813, G loss: 0.7761\n",
      "[484/1762] D loss: 1.4226, G loss: 0.7862\n",
      "[564/1762] D loss: 1.4071, G loss: 0.5900\n",
      "[644/1762] D loss: 1.3940, G loss: 0.7139\n",
      "[724/1762] D loss: 1.3897, G loss: 0.6848\n",
      "[804/1762] D loss: 1.3942, G loss: 0.8616\n",
      "[884/1762] D loss: 1.3950, G loss: 0.6024\n",
      "[964/1762] D loss: 1.4114, G loss: 0.5760\n",
      "[1044/1762] D loss: 1.1191, G loss: 1.1383\n",
      "[1124/1762] D loss: 1.4377, G loss: 0.7201\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6473\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.6832\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7966\n",
      "[1444/1762] D loss: 1.3955, G loss: 0.7423\n",
      "[1524/1762] D loss: 1.4067, G loss: 0.6156\n",
      "[1604/1762] D loss: 1.1361, G loss: 0.9206\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.6200\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6970\n",
      "train error: \n",
      " D loss: 1.326556, G loss: 0.725660, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306778, G loss: 0.735753, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4286, G loss: 0.6685\n",
      "[84/1762] D loss: 1.3964, G loss: 0.6601\n",
      "[164/1762] D loss: 1.4039, G loss: 0.6333\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7148\n",
      "[324/1762] D loss: 1.3894, G loss: 0.6455\n",
      "[404/1762] D loss: 1.4100, G loss: 0.5592\n",
      "[484/1762] D loss: 1.4269, G loss: 0.8972\n",
      "[564/1762] D loss: 1.2117, G loss: 0.6153\n",
      "[644/1762] D loss: 1.4317, G loss: 0.7528\n",
      "[724/1762] D loss: 1.4014, G loss: 0.6275\n",
      "[804/1762] D loss: 1.3924, G loss: 0.7957\n",
      "[884/1762] D loss: 1.4106, G loss: 0.7828\n",
      "[964/1762] D loss: 1.1354, G loss: 0.8501\n",
      "[1044/1762] D loss: 1.1662, G loss: 0.7315\n",
      "[1124/1762] D loss: 1.3906, G loss: 0.8274\n",
      "[1204/1762] D loss: 0.8889, G loss: 0.9670\n",
      "[1284/1762] D loss: 0.8995, G loss: 1.0888\n",
      "[1364/1762] D loss: 1.4252, G loss: 0.6791\n",
      "[1444/1762] D loss: 1.3816, G loss: 0.6051\n",
      "[1524/1762] D loss: 1.4215, G loss: 0.8030\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.6193\n",
      "[1684/1762] D loss: 1.4771, G loss: 0.7521\n",
      "[1762/1762] D loss: 0.8907, G loss: 1.1621\n",
      "train error: \n",
      " D loss: 1.366420, G loss: 1.008353, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341081, G loss: 1.026356, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4582, G loss: 0.9454\n",
      "[84/1762] D loss: 1.4547, G loss: 0.7859\n",
      "[164/1762] D loss: 1.4034, G loss: 0.7568\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6999\n",
      "[324/1762] D loss: 1.1869, G loss: 0.9100\n",
      "[404/1762] D loss: 1.4039, G loss: 0.6837\n",
      "[484/1762] D loss: 1.4265, G loss: 0.7608\n",
      "[564/1762] D loss: 1.3948, G loss: 0.8174\n",
      "[644/1762] D loss: 1.3934, G loss: 0.5668\n",
      "[724/1762] D loss: 1.3896, G loss: 0.7805\n",
      "[804/1762] D loss: 1.1576, G loss: 0.9552\n",
      "[884/1762] D loss: 1.4094, G loss: 0.6064\n",
      "[964/1762] D loss: 1.3845, G loss: 0.6905\n",
      "[1044/1762] D loss: 1.4209, G loss: 0.5807\n",
      "[1124/1762] D loss: 1.1171, G loss: 1.1965\n",
      "[1204/1762] D loss: 1.1303, G loss: 0.8845\n",
      "[1284/1762] D loss: 1.4023, G loss: 0.7804\n",
      "[1364/1762] D loss: 1.4106, G loss: 0.7317\n",
      "[1444/1762] D loss: 1.3949, G loss: 0.6054\n",
      "[1524/1762] D loss: 1.1518, G loss: 0.9103\n",
      "[1604/1762] D loss: 1.4104, G loss: 0.9658\n",
      "[1684/1762] D loss: 1.3997, G loss: 0.7212\n",
      "[1762/1762] D loss: 1.4052, G loss: 0.5746\n",
      "train error: \n",
      " D loss: 1.333212, G loss: 0.637931, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312699, G loss: 0.648961, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4031, G loss: 0.6868\n",
      "[84/1762] D loss: 1.3931, G loss: 0.6901\n",
      "[164/1762] D loss: 1.3914, G loss: 0.7329\n",
      "[244/1762] D loss: 1.1513, G loss: 1.0976\n",
      "[324/1762] D loss: 1.3850, G loss: 0.7023\n",
      "[404/1762] D loss: 1.4176, G loss: 0.6834\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6257\n",
      "[564/1762] D loss: 1.1555, G loss: 0.8197\n",
      "[644/1762] D loss: 1.3897, G loss: 0.7293\n",
      "[724/1762] D loss: 1.4071, G loss: 0.7514\n",
      "[804/1762] D loss: 1.3852, G loss: 0.7499\n",
      "[884/1762] D loss: 1.1721, G loss: 0.7111\n",
      "[964/1762] D loss: 1.3912, G loss: 0.6654\n",
      "[1044/1762] D loss: 1.4527, G loss: 0.5906\n",
      "[1124/1762] D loss: 1.3954, G loss: 0.8368\n",
      "[1204/1762] D loss: 1.4448, G loss: 0.7646\n",
      "[1284/1762] D loss: 1.3916, G loss: 0.6462\n",
      "[1364/1762] D loss: 1.4000, G loss: 0.7315\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.6764\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.8884\n",
      "[1604/1762] D loss: 1.3944, G loss: 0.6669\n",
      "[1684/1762] D loss: 1.3849, G loss: 0.7153\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6261\n",
      "train error: \n",
      " D loss: 1.321903, G loss: 0.711400, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300815, G loss: 0.725427, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1391, G loss: 0.8310\n",
      "[84/1762] D loss: 1.3829, G loss: 0.6243\n",
      "[164/1762] D loss: 1.3898, G loss: 0.8336\n",
      "[244/1762] D loss: 1.1491, G loss: 0.9896\n",
      "[324/1762] D loss: 1.4461, G loss: 0.8470\n",
      "[404/1762] D loss: 1.4851, G loss: 0.8118\n",
      "[484/1762] D loss: 1.3929, G loss: 0.6386\n",
      "[564/1762] D loss: 1.3900, G loss: 0.7025\n",
      "[644/1762] D loss: 1.1348, G loss: 0.8557\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7757\n",
      "[804/1762] D loss: 1.3919, G loss: 0.7376\n",
      "[884/1762] D loss: 1.3902, G loss: 0.7154\n",
      "[964/1762] D loss: 1.4074, G loss: 0.6365\n",
      "[1044/1762] D loss: 1.4351, G loss: 0.7265\n",
      "[1124/1762] D loss: 1.3963, G loss: 0.7340\n",
      "[1204/1762] D loss: 1.1318, G loss: 0.7728\n",
      "[1284/1762] D loss: 1.3731, G loss: 0.7249\n",
      "[1364/1762] D loss: 1.4119, G loss: 0.7203\n",
      "[1444/1762] D loss: 1.4092, G loss: 0.6566\n",
      "[1524/1762] D loss: 1.3787, G loss: 0.7693\n",
      "[1604/1762] D loss: 1.3796, G loss: 0.8281\n",
      "[1684/1762] D loss: 1.4037, G loss: 0.7975\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6449\n",
      "train error: \n",
      " D loss: 1.322636, G loss: 0.717199, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302129, G loss: 0.730077, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6734\n",
      "[84/1762] D loss: 1.4020, G loss: 0.7506\n",
      "[164/1762] D loss: 1.4036, G loss: 0.6796\n",
      "[244/1762] D loss: 1.4219, G loss: 0.5925\n",
      "[324/1762] D loss: 1.4444, G loss: 0.9300\n",
      "[404/1762] D loss: 1.3504, G loss: 0.7530\n",
      "[484/1762] D loss: 1.4762, G loss: 0.5495\n",
      "[564/1762] D loss: 1.3925, G loss: 0.8112\n",
      "[644/1762] D loss: 1.3912, G loss: 0.8471\n",
      "[724/1762] D loss: 1.4112, G loss: 0.8137\n",
      "[804/1762] D loss: 1.3827, G loss: 0.6027\n",
      "[884/1762] D loss: 1.4118, G loss: 0.7911\n",
      "[964/1762] D loss: 1.4331, G loss: 0.7956\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.6396\n",
      "[1124/1762] D loss: 1.1282, G loss: 1.0380\n",
      "[1204/1762] D loss: 1.4801, G loss: 0.8023\n",
      "[1284/1762] D loss: 1.4040, G loss: 0.6222\n",
      "[1364/1762] D loss: 1.4025, G loss: 0.7838\n",
      "[1444/1762] D loss: 1.4121, G loss: 0.5330\n",
      "[1524/1762] D loss: 1.4029, G loss: 0.6765\n",
      "[1604/1762] D loss: 1.4207, G loss: 0.8291\n",
      "[1684/1762] D loss: 1.1327, G loss: 0.8526\n",
      "[1762/1762] D loss: 1.3985, G loss: 0.6580\n",
      "train error: \n",
      " D loss: 1.328304, G loss: 0.665444, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308096, G loss: 0.679294, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3919, G loss: 0.5612\n",
      "[84/1762] D loss: 1.3893, G loss: 0.7084\n",
      "[164/1762] D loss: 1.1971, G loss: 0.9481\n",
      "[244/1762] D loss: 1.4016, G loss: 0.6078\n",
      "[324/1762] D loss: 1.1192, G loss: 0.8872\n",
      "[404/1762] D loss: 1.3906, G loss: 0.8154\n",
      "[484/1762] D loss: 1.3976, G loss: 0.6134\n",
      "[564/1762] D loss: 1.3911, G loss: 0.7591\n",
      "[644/1762] D loss: 1.3785, G loss: 0.6096\n",
      "[724/1762] D loss: 1.4078, G loss: 0.5660\n",
      "[804/1762] D loss: 1.4152, G loss: 0.6935\n",
      "[884/1762] D loss: 1.3949, G loss: 0.6633\n",
      "[964/1762] D loss: 1.1223, G loss: 1.0973\n",
      "[1044/1762] D loss: 1.1707, G loss: 0.7912\n",
      "[1124/1762] D loss: 1.3920, G loss: 0.6489\n",
      "[1204/1762] D loss: 1.3692, G loss: 0.6643\n",
      "[1284/1762] D loss: 1.1303, G loss: 0.8243\n",
      "[1364/1762] D loss: 1.1139, G loss: 0.8198\n",
      "[1444/1762] D loss: 1.1291, G loss: 1.0362\n",
      "[1524/1762] D loss: 1.3897, G loss: 0.6337\n",
      "[1604/1762] D loss: 1.4479, G loss: 0.9135\n",
      "[1684/1762] D loss: 1.3963, G loss: 0.5577\n",
      "[1762/1762] D loss: 1.3955, G loss: 0.6636\n",
      "train error: \n",
      " D loss: 1.323768, G loss: 0.712648, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 76.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302026, G loss: 0.728481, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3741, G loss: 0.7359\n",
      "[84/1762] D loss: 1.4439, G loss: 0.5535\n",
      "[164/1762] D loss: 1.1688, G loss: 0.8040\n",
      "[244/1762] D loss: 1.3789, G loss: 0.7408\n",
      "[324/1762] D loss: 1.3936, G loss: 0.7029\n",
      "[404/1762] D loss: 1.1561, G loss: 1.1782\n",
      "[484/1762] D loss: 1.4051, G loss: 0.7575\n",
      "[564/1762] D loss: 1.4040, G loss: 0.6181\n",
      "[644/1762] D loss: 1.3963, G loss: 0.7757\n",
      "[724/1762] D loss: 1.4083, G loss: 0.7425\n",
      "[804/1762] D loss: 1.4132, G loss: 0.5803\n",
      "[884/1762] D loss: 1.1488, G loss: 0.7535\n",
      "[964/1762] D loss: 0.8132, G loss: 1.2500\n",
      "[1044/1762] D loss: 1.4044, G loss: 0.7106\n",
      "[1124/1762] D loss: 1.3984, G loss: 0.7329\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.7133\n",
      "[1284/1762] D loss: 1.4023, G loss: 0.7604\n",
      "[1364/1762] D loss: 1.1316, G loss: 0.8284\n",
      "[1444/1762] D loss: 1.4010, G loss: 0.7189\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6889\n",
      "[1604/1762] D loss: 1.4131, G loss: 0.7900\n",
      "[1684/1762] D loss: 1.4014, G loss: 0.7249\n",
      "[1762/1762] D loss: 0.8938, G loss: 1.0722\n",
      "train error: \n",
      " D loss: 1.334269, G loss: 0.884841, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 77.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312429, G loss: 0.900655, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4076, G loss: 0.8056\n",
      "[84/1762] D loss: 1.1288, G loss: 0.8736\n",
      "[164/1762] D loss: 1.1406, G loss: 0.7737\n",
      "[244/1762] D loss: 1.4046, G loss: 0.6099\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6731\n",
      "[404/1762] D loss: 1.3891, G loss: 0.8244\n",
      "[484/1762] D loss: 1.1472, G loss: 0.9125\n",
      "[564/1762] D loss: 1.3967, G loss: 0.7051\n",
      "[644/1762] D loss: 1.1670, G loss: 0.7039\n",
      "[724/1762] D loss: 1.3790, G loss: 0.6802\n",
      "[804/1762] D loss: 1.1754, G loss: 0.8371\n",
      "[884/1762] D loss: 1.1703, G loss: 1.0708\n",
      "[964/1762] D loss: 1.4133, G loss: 0.8068\n",
      "[1044/1762] D loss: 1.4196, G loss: 0.6940\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.7153\n",
      "[1204/1762] D loss: 1.1065, G loss: 0.8531\n",
      "[1284/1762] D loss: 1.3955, G loss: 0.6302\n",
      "[1364/1762] D loss: 1.3682, G loss: 0.6570\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.7642\n",
      "[1524/1762] D loss: 1.1681, G loss: 0.7647\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.7172\n",
      "[1684/1762] D loss: 1.3940, G loss: 0.6126\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6788\n",
      "train error: \n",
      " D loss: 1.321017, G loss: 0.762771, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299619, G loss: 0.778751, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1435, G loss: 0.8738\n",
      "[84/1762] D loss: 1.5046, G loss: 0.8219\n",
      "[164/1762] D loss: 1.4220, G loss: 0.7263\n",
      "[244/1762] D loss: 1.3718, G loss: 0.7607\n",
      "[324/1762] D loss: 1.3804, G loss: 0.7264\n",
      "[404/1762] D loss: 1.3884, G loss: 0.6991\n",
      "[484/1762] D loss: 1.4470, G loss: 0.7703\n",
      "[564/1762] D loss: 1.1304, G loss: 0.7610\n",
      "[644/1762] D loss: 1.3963, G loss: 0.7793\n",
      "[724/1762] D loss: 1.0953, G loss: 0.9181\n",
      "[804/1762] D loss: 1.3889, G loss: 0.6821\n",
      "[884/1762] D loss: 1.1547, G loss: 0.8561\n",
      "[964/1762] D loss: 1.3895, G loss: 0.6852\n",
      "[1044/1762] D loss: 1.4161, G loss: 0.5994\n",
      "[1124/1762] D loss: 1.1297, G loss: 0.8837\n",
      "[1204/1762] D loss: 1.4085, G loss: 0.6622\n",
      "[1284/1762] D loss: 1.3784, G loss: 0.6892\n",
      "[1364/1762] D loss: 1.1097, G loss: 1.0140\n",
      "[1444/1762] D loss: 1.4026, G loss: 0.7163\n",
      "[1524/1762] D loss: 1.4357, G loss: 0.5747\n",
      "[1604/1762] D loss: 1.3695, G loss: 0.8079\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6930\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.7415\n",
      "train error: \n",
      " D loss: 1.318940, G loss: 0.781616, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299272, G loss: 0.794412, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7261\n",
      "[84/1762] D loss: 1.3755, G loss: 0.6683\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7002\n",
      "[244/1762] D loss: 0.8469, G loss: 1.0629\n",
      "[324/1762] D loss: 1.1340, G loss: 0.9138\n",
      "[404/1762] D loss: 1.5378, G loss: 0.8198\n",
      "[484/1762] D loss: 1.4119, G loss: 0.7128\n",
      "[564/1762] D loss: 1.3901, G loss: 0.5333\n",
      "[644/1762] D loss: 1.3981, G loss: 0.7842\n",
      "[724/1762] D loss: 1.1409, G loss: 1.0373\n",
      "[804/1762] D loss: 1.1274, G loss: 0.8948\n",
      "[884/1762] D loss: 1.4159, G loss: 0.5488\n",
      "[964/1762] D loss: 1.4228, G loss: 0.7239\n",
      "[1044/1762] D loss: 1.0880, G loss: 0.9648\n",
      "[1124/1762] D loss: 1.4065, G loss: 0.6964\n",
      "[1204/1762] D loss: 1.3964, G loss: 0.6061\n",
      "[1284/1762] D loss: 1.3944, G loss: 0.7104\n",
      "[1364/1762] D loss: 1.4208, G loss: 0.8955\n",
      "[1444/1762] D loss: 1.1216, G loss: 0.9352\n",
      "[1524/1762] D loss: 1.3944, G loss: 0.7717\n",
      "[1604/1762] D loss: 1.3648, G loss: 0.7241\n",
      "[1684/1762] D loss: 1.3746, G loss: 0.6437\n",
      "[1762/1762] D loss: 1.4243, G loss: 0.5358\n",
      "train error: \n",
      " D loss: 1.351992, G loss: 0.574615, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334542, G loss: 0.586125, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1887, G loss: 0.7689\n",
      "[84/1762] D loss: 1.3873, G loss: 0.7251\n",
      "[164/1762] D loss: 1.3934, G loss: 0.8085\n",
      "[244/1762] D loss: 1.3938, G loss: 0.6106\n",
      "[324/1762] D loss: 1.1206, G loss: 0.9299\n",
      "[404/1762] D loss: 1.1069, G loss: 0.8430\n",
      "[484/1762] D loss: 1.1129, G loss: 0.9062\n",
      "[564/1762] D loss: 1.1344, G loss: 0.8785\n",
      "[644/1762] D loss: 1.3879, G loss: 0.7429\n",
      "[724/1762] D loss: 1.1061, G loss: 1.0574\n",
      "[804/1762] D loss: 1.3890, G loss: 0.5821\n",
      "[884/1762] D loss: 1.1430, G loss: 0.7746\n",
      "[964/1762] D loss: 1.4222, G loss: 0.7709\n",
      "[1044/1762] D loss: 1.1287, G loss: 0.8980\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.6160\n",
      "[1204/1762] D loss: 1.3939, G loss: 0.6457\n",
      "[1284/1762] D loss: 1.3676, G loss: 0.6769\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.6257\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.5831\n",
      "[1524/1762] D loss: 1.4000, G loss: 0.6582\n",
      "[1604/1762] D loss: 1.4040, G loss: 0.7450\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6196\n",
      "[1762/1762] D loss: 0.8373, G loss: 1.1262\n",
      "train error: \n",
      " D loss: 1.330443, G loss: 0.883620, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309616, G loss: 0.896346, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4294, G loss: 0.8456\n",
      "[84/1762] D loss: 1.1592, G loss: 0.9565\n",
      "[164/1762] D loss: 1.4034, G loss: 0.5978\n",
      "[244/1762] D loss: 1.1401, G loss: 0.9418\n",
      "[324/1762] D loss: 0.8350, G loss: 1.3116\n",
      "[404/1762] D loss: 1.3689, G loss: 0.6997\n",
      "[484/1762] D loss: 1.3825, G loss: 0.7661\n",
      "[564/1762] D loss: 1.4088, G loss: 0.7297\n",
      "[644/1762] D loss: 1.3909, G loss: 0.7327\n",
      "[724/1762] D loss: 1.1712, G loss: 0.6738\n",
      "[804/1762] D loss: 1.3912, G loss: 0.7540\n",
      "[884/1762] D loss: 1.4272, G loss: 0.8436\n",
      "[964/1762] D loss: 1.4000, G loss: 0.5501\n",
      "[1044/1762] D loss: 1.4150, G loss: 0.7904\n",
      "[1124/1762] D loss: 1.4016, G loss: 0.7016\n",
      "[1204/1762] D loss: 1.1983, G loss: 0.8353\n",
      "[1284/1762] D loss: 1.1262, G loss: 0.9872\n",
      "[1364/1762] D loss: 1.0296, G loss: 0.8465\n",
      "[1444/1762] D loss: 1.4428, G loss: 0.9047\n",
      "[1524/1762] D loss: 1.1212, G loss: 1.1117\n",
      "[1604/1762] D loss: 1.4418, G loss: 0.8460\n",
      "[1684/1762] D loss: 1.4217, G loss: 0.7181\n",
      "[1762/1762] D loss: 1.3142, G loss: 0.9056\n",
      "train error: \n",
      " D loss: 1.349142, G loss: 0.887942, D accuracy: 50.7%, cell accuracy: 99.3%, board accuracy: 38.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323920, G loss: 0.899200, D accuracy: 52.7%, cell accuracy: 99.3%, board accuracy: 43.4% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4060, G loss: 0.7684\n",
      "[84/1762] D loss: 1.3930, G loss: 0.7382\n",
      "[164/1762] D loss: 1.1746, G loss: 0.7937\n",
      "[244/1762] D loss: 1.3982, G loss: 0.6902\n",
      "[324/1762] D loss: 1.4093, G loss: 0.7319\n",
      "[404/1762] D loss: 1.3890, G loss: 0.6501\n",
      "[484/1762] D loss: 1.1323, G loss: 0.8813\n",
      "[564/1762] D loss: 1.2302, G loss: 1.0142\n",
      "[644/1762] D loss: 1.1372, G loss: 0.8324\n",
      "[724/1762] D loss: 1.4007, G loss: 0.5720\n",
      "[804/1762] D loss: 1.4778, G loss: 0.6060\n",
      "[884/1762] D loss: 1.4073, G loss: 0.7664\n",
      "[964/1762] D loss: 1.3952, G loss: 0.6889\n",
      "[1044/1762] D loss: 1.1411, G loss: 0.8360\n",
      "[1124/1762] D loss: 1.3732, G loss: 0.7782\n",
      "[1204/1762] D loss: 1.4162, G loss: 0.8951\n",
      "[1284/1762] D loss: 1.1393, G loss: 0.9840\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.8152\n",
      "[1444/1762] D loss: 1.4015, G loss: 0.6937\n",
      "[1524/1762] D loss: 1.4524, G loss: 0.8396\n",
      "[1604/1762] D loss: 1.4290, G loss: 0.5466\n",
      "[1684/1762] D loss: 1.3518, G loss: 0.7062\n",
      "[1762/1762] D loss: 1.3807, G loss: 0.6100\n",
      "train error: \n",
      " D loss: 1.315645, G loss: 0.749404, D accuracy: 56.3%, cell accuracy: 99.6%, board accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298590, G loss: 0.755962, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 67.7% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2711, G loss: 0.8557\n",
      "[84/1762] D loss: 1.1552, G loss: 0.6204\n",
      "[164/1762] D loss: 1.1756, G loss: 0.8610\n",
      "[244/1762] D loss: 1.4173, G loss: 0.7073\n",
      "[324/1762] D loss: 1.3860, G loss: 0.7247\n",
      "[404/1762] D loss: 1.4079, G loss: 0.6086\n",
      "[484/1762] D loss: 1.3635, G loss: 0.7752\n",
      "[564/1762] D loss: 1.3822, G loss: 0.7282\n",
      "[644/1762] D loss: 1.1481, G loss: 0.9429\n",
      "[724/1762] D loss: 1.3625, G loss: 0.9455\n",
      "[804/1762] D loss: 1.3903, G loss: 0.7030\n",
      "[884/1762] D loss: 1.3465, G loss: 0.7352\n",
      "[964/1762] D loss: 1.1755, G loss: 0.7705\n",
      "[1044/1762] D loss: 1.4055, G loss: 0.8495\n",
      "[1124/1762] D loss: 1.1392, G loss: 0.9896\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.8125\n",
      "[1284/1762] D loss: 1.3918, G loss: 0.6313\n",
      "[1364/1762] D loss: 1.4247, G loss: 0.7306\n",
      "[1444/1762] D loss: 1.3998, G loss: 0.5493\n",
      "[1524/1762] D loss: 1.3725, G loss: 0.7024\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6024\n",
      "[1684/1762] D loss: 1.4004, G loss: 0.7012\n",
      "[1762/1762] D loss: 1.3939, G loss: 0.6383\n",
      "train error: \n",
      " D loss: 1.320736, G loss: 0.699164, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302936, G loss: 0.705734, D accuracy: 56.2%, cell accuracy: 99.6%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3920, G loss: 0.6980\n",
      "[84/1762] D loss: 1.3883, G loss: 0.8531\n",
      "[164/1762] D loss: 1.4018, G loss: 0.7242\n",
      "[244/1762] D loss: 1.3961, G loss: 0.5768\n",
      "[324/1762] D loss: 1.3927, G loss: 0.6570\n",
      "[404/1762] D loss: 1.4060, G loss: 0.5744\n",
      "[484/1762] D loss: 1.4481, G loss: 0.5589\n",
      "[564/1762] D loss: 1.3969, G loss: 0.6794\n",
      "[644/1762] D loss: 1.3903, G loss: 0.7680\n",
      "[724/1762] D loss: 0.8624, G loss: 1.3128\n",
      "[804/1762] D loss: 1.3834, G loss: 0.7425\n",
      "[884/1762] D loss: 1.4044, G loss: 0.7341\n",
      "[964/1762] D loss: 1.3920, G loss: 0.7236\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7116\n",
      "[1124/1762] D loss: 1.3805, G loss: 0.7680\n",
      "[1204/1762] D loss: 1.4780, G loss: 0.8639\n",
      "[1284/1762] D loss: 1.1478, G loss: 0.7320\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.6396\n",
      "[1444/1762] D loss: 1.3713, G loss: 0.7233\n",
      "[1524/1762] D loss: 1.3946, G loss: 0.6831\n",
      "[1604/1762] D loss: 1.3971, G loss: 0.7385\n",
      "[1684/1762] D loss: 1.3770, G loss: 0.8592\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.7323\n",
      "train error: \n",
      " D loss: 1.319571, G loss: 0.743939, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300879, G loss: 0.754096, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6934\n",
      "[84/1762] D loss: 1.1758, G loss: 0.8958\n",
      "[164/1762] D loss: 1.3882, G loss: 0.6702\n",
      "[244/1762] D loss: 1.4098, G loss: 0.6249\n",
      "[324/1762] D loss: 1.2031, G loss: 0.6797\n",
      "[404/1762] D loss: 1.3970, G loss: 0.6398\n",
      "[484/1762] D loss: 1.1398, G loss: 0.8770\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6514\n",
      "[644/1762] D loss: 1.1493, G loss: 0.8523\n",
      "[724/1762] D loss: 1.4124, G loss: 0.7622\n",
      "[804/1762] D loss: 1.3821, G loss: 0.6117\n",
      "[884/1762] D loss: 1.3883, G loss: 0.5938\n",
      "[964/1762] D loss: 1.1513, G loss: 0.8080\n",
      "[1044/1762] D loss: 1.2419, G loss: 0.9055\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6961\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.6804\n",
      "[1284/1762] D loss: 1.3858, G loss: 0.7407\n",
      "[1364/1762] D loss: 1.1423, G loss: 0.9964\n",
      "[1444/1762] D loss: 1.1629, G loss: 0.9331\n",
      "[1524/1762] D loss: 1.4033, G loss: 0.6744\n",
      "[1604/1762] D loss: 1.1989, G loss: 0.6634\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.7832\n",
      "[1762/1762] D loss: 0.8619, G loss: 1.2110\n",
      "train error: \n",
      " D loss: 1.330346, G loss: 0.877411, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309301, G loss: 0.894439, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4008, G loss: 0.8638\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6657\n",
      "[164/1762] D loss: 1.3864, G loss: 0.7292\n",
      "[244/1762] D loss: 1.1406, G loss: 0.9163\n",
      "[324/1762] D loss: 1.1153, G loss: 1.0258\n",
      "[404/1762] D loss: 1.3971, G loss: 0.6881\n",
      "[484/1762] D loss: 1.3746, G loss: 0.7213\n",
      "[564/1762] D loss: 1.3988, G loss: 0.7187\n",
      "[644/1762] D loss: 1.3958, G loss: 0.6835\n",
      "[724/1762] D loss: 1.3920, G loss: 0.6659\n",
      "[804/1762] D loss: 1.1213, G loss: 0.9622\n",
      "[884/1762] D loss: 1.3940, G loss: 0.6388\n",
      "[964/1762] D loss: 1.4024, G loss: 0.8055\n",
      "[1044/1762] D loss: 0.9285, G loss: 0.9427\n",
      "[1124/1762] D loss: 1.4062, G loss: 0.8313\n",
      "[1204/1762] D loss: 1.4233, G loss: 0.8608\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.8772\n",
      "[1364/1762] D loss: 1.4136, G loss: 0.8126\n",
      "[1444/1762] D loss: 1.4318, G loss: 0.8429\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.6586\n",
      "[1604/1762] D loss: 1.3814, G loss: 0.6736\n",
      "[1684/1762] D loss: 1.4038, G loss: 0.6705\n",
      "[1762/1762] D loss: 1.4058, G loss: 0.5603\n",
      "train error: \n",
      " D loss: 1.347048, G loss: 0.593643, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328201, G loss: 0.606262, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4160, G loss: 0.6181\n",
      "[84/1762] D loss: 1.4184, G loss: 0.6409\n",
      "[164/1762] D loss: 1.4261, G loss: 0.8917\n",
      "[244/1762] D loss: 1.3898, G loss: 0.7024\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6343\n",
      "[404/1762] D loss: 1.3983, G loss: 0.5999\n",
      "[484/1762] D loss: 1.3942, G loss: 0.6252\n",
      "[564/1762] D loss: 1.4021, G loss: 0.8071\n",
      "[644/1762] D loss: 1.3837, G loss: 0.7486\n",
      "[724/1762] D loss: 1.4039, G loss: 0.5896\n",
      "[804/1762] D loss: 1.3922, G loss: 0.9016\n",
      "[884/1762] D loss: 1.3909, G loss: 0.7315\n",
      "[964/1762] D loss: 1.4105, G loss: 0.7371\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7110\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7474\n",
      "[1204/1762] D loss: 1.3994, G loss: 0.6424\n",
      "[1284/1762] D loss: 1.4149, G loss: 0.7161\n",
      "[1364/1762] D loss: 1.1624, G loss: 0.7762\n",
      "[1444/1762] D loss: 1.3984, G loss: 0.7717\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.7731\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.7267\n",
      "[1684/1762] D loss: 1.4336, G loss: 0.5366\n",
      "[1762/1762] D loss: 1.3919, G loss: 0.8095\n",
      "train error: \n",
      " D loss: 1.343230, G loss: 0.956175, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322248, G loss: 0.971291, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4203, G loss: 0.8315\n",
      "[84/1762] D loss: 1.3949, G loss: 0.5665\n",
      "[164/1762] D loss: 1.3551, G loss: 0.7723\n",
      "[244/1762] D loss: 1.1196, G loss: 0.9225\n",
      "[324/1762] D loss: 0.9072, G loss: 1.0013\n",
      "[404/1762] D loss: 1.1131, G loss: 0.9937\n",
      "[484/1762] D loss: 1.3654, G loss: 0.6204\n",
      "[564/1762] D loss: 1.1330, G loss: 0.8928\n",
      "[644/1762] D loss: 1.3518, G loss: 0.7261\n",
      "[724/1762] D loss: 1.4182, G loss: 0.8747\n",
      "[804/1762] D loss: 1.1428, G loss: 0.8047\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7203\n",
      "[964/1762] D loss: 1.3925, G loss: 0.6670\n",
      "[1044/1762] D loss: 1.1472, G loss: 0.9168\n",
      "[1124/1762] D loss: 1.4128, G loss: 0.6216\n",
      "[1204/1762] D loss: 1.3840, G loss: 0.7448\n",
      "[1284/1762] D loss: 1.3839, G loss: 0.6730\n",
      "[1364/1762] D loss: 1.1680, G loss: 0.9800\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.6896\n",
      "[1524/1762] D loss: 1.4007, G loss: 0.7282\n",
      "[1604/1762] D loss: 1.3847, G loss: 0.6912\n",
      "[1684/1762] D loss: 1.1555, G loss: 0.9270\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7767\n",
      "train error: \n",
      " D loss: 1.336622, G loss: 0.916272, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314387, G loss: 0.931111, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1324, G loss: 1.0457\n",
      "[84/1762] D loss: 1.4170, G loss: 0.7949\n",
      "[164/1762] D loss: 1.3971, G loss: 0.6193\n",
      "[244/1762] D loss: 1.1508, G loss: 0.8690\n",
      "[324/1762] D loss: 1.3899, G loss: 0.7380\n",
      "[404/1762] D loss: 1.1503, G loss: 1.2208\n",
      "[484/1762] D loss: 1.4376, G loss: 0.8247\n",
      "[564/1762] D loss: 1.1387, G loss: 0.7890\n",
      "[644/1762] D loss: 1.1188, G loss: 0.8137\n",
      "[724/1762] D loss: 1.3902, G loss: 0.7293\n",
      "[804/1762] D loss: 1.3931, G loss: 0.7892\n",
      "[884/1762] D loss: 1.3907, G loss: 0.7015\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6903\n",
      "[1044/1762] D loss: 1.1486, G loss: 0.9334\n",
      "[1124/1762] D loss: 1.3793, G loss: 0.6707\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.5850\n",
      "[1284/1762] D loss: 1.3978, G loss: 0.7139\n",
      "[1364/1762] D loss: 1.3968, G loss: 0.6597\n",
      "[1444/1762] D loss: 1.4187, G loss: 0.5784\n",
      "[1524/1762] D loss: 1.1247, G loss: 0.8892\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.7126\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6917\n",
      "[1762/1762] D loss: 1.3779, G loss: 0.6200\n",
      "train error: \n",
      " D loss: 1.315310, G loss: 0.704525, D accuracy: 56.5%, cell accuracy: 99.4%, board accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298182, G loss: 0.712477, D accuracy: 56.8%, cell accuracy: 99.3%, board accuracy: 52.3% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4415, G loss: 0.5863\n",
      "[84/1762] D loss: 1.3936, G loss: 0.6837\n",
      "[164/1762] D loss: 1.4071, G loss: 0.7309\n",
      "[244/1762] D loss: 1.1316, G loss: 0.9265\n",
      "[324/1762] D loss: 1.4218, G loss: 0.8787\n",
      "[404/1762] D loss: 1.4010, G loss: 0.7258\n",
      "[484/1762] D loss: 1.3814, G loss: 0.6533\n",
      "[564/1762] D loss: 1.4018, G loss: 0.7563\n",
      "[644/1762] D loss: 1.1650, G loss: 0.7649\n",
      "[724/1762] D loss: 1.3917, G loss: 0.6198\n",
      "[804/1762] D loss: 1.3982, G loss: 0.8081\n",
      "[884/1762] D loss: 1.4270, G loss: 0.7825\n",
      "[964/1762] D loss: 1.1407, G loss: 0.8384\n",
      "[1044/1762] D loss: 1.4210, G loss: 0.7659\n",
      "[1124/1762] D loss: 1.3828, G loss: 0.7191\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6974\n",
      "[1284/1762] D loss: 1.3937, G loss: 0.7711\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.7408\n",
      "[1444/1762] D loss: 1.4608, G loss: 0.5810\n",
      "[1524/1762] D loss: 1.1306, G loss: 0.8800\n",
      "[1604/1762] D loss: 1.3979, G loss: 0.6940\n",
      "[1684/1762] D loss: 1.4291, G loss: 0.8993\n",
      "[1762/1762] D loss: 1.4087, G loss: 0.6830\n",
      "train error: \n",
      " D loss: 1.328870, G loss: 0.639486, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 72.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308313, G loss: 0.653429, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4059, G loss: 0.5797\n",
      "[84/1762] D loss: 1.3853, G loss: 0.7294\n",
      "[164/1762] D loss: 1.1401, G loss: 0.8761\n",
      "[244/1762] D loss: 1.3641, G loss: 0.6467\n",
      "[324/1762] D loss: 1.3872, G loss: 0.5649\n",
      "[404/1762] D loss: 1.3971, G loss: 0.6901\n",
      "[484/1762] D loss: 1.3915, G loss: 0.7422\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6382\n",
      "[644/1762] D loss: 1.1164, G loss: 0.9230\n",
      "[724/1762] D loss: 1.1171, G loss: 1.0412\n",
      "[804/1762] D loss: 1.3791, G loss: 0.7313\n",
      "[884/1762] D loss: 1.3925, G loss: 0.6511\n",
      "[964/1762] D loss: 1.3916, G loss: 0.7898\n",
      "[1044/1762] D loss: 1.1194, G loss: 1.0130\n",
      "[1124/1762] D loss: 1.1338, G loss: 1.0635\n",
      "[1204/1762] D loss: 1.1286, G loss: 0.9090\n",
      "[1284/1762] D loss: 1.1238, G loss: 0.9725\n",
      "[1364/1762] D loss: 1.4015, G loss: 0.6161\n",
      "[1444/1762] D loss: 1.1748, G loss: 0.7646\n",
      "[1524/1762] D loss: 1.1316, G loss: 0.8803\n",
      "[1604/1762] D loss: 1.4928, G loss: 1.0210\n",
      "[1684/1762] D loss: 1.4091, G loss: 0.7892\n",
      "[1762/1762] D loss: 1.4146, G loss: 0.7469\n",
      "train error: \n",
      " D loss: 1.341941, G loss: 0.941224, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320456, G loss: 0.956158, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3991, G loss: 0.7531\n",
      "[84/1762] D loss: 1.3835, G loss: 0.7090\n",
      "[164/1762] D loss: 1.3898, G loss: 0.7334\n",
      "[244/1762] D loss: 1.1287, G loss: 0.9494\n",
      "[324/1762] D loss: 0.8593, G loss: 1.1145\n",
      "[404/1762] D loss: 1.3902, G loss: 0.7220\n",
      "[484/1762] D loss: 1.3191, G loss: 0.6961\n",
      "[564/1762] D loss: 1.4002, G loss: 0.8025\n",
      "[644/1762] D loss: 1.3892, G loss: 0.7758\n",
      "[724/1762] D loss: 1.1364, G loss: 0.9881\n",
      "[804/1762] D loss: 1.3890, G loss: 0.7019\n",
      "[884/1762] D loss: 1.3934, G loss: 0.7572\n",
      "[964/1762] D loss: 1.3928, G loss: 0.7952\n",
      "[1044/1762] D loss: 1.1382, G loss: 0.9684\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.5872\n",
      "[1204/1762] D loss: 1.4446, G loss: 0.5299\n",
      "[1284/1762] D loss: 1.3946, G loss: 0.7200\n",
      "[1364/1762] D loss: 1.3910, G loss: 0.6829\n",
      "[1444/1762] D loss: 1.1869, G loss: 0.7017\n",
      "[1524/1762] D loss: 1.4043, G loss: 0.5370\n",
      "[1604/1762] D loss: 1.4078, G loss: 0.6700\n",
      "[1684/1762] D loss: 1.3245, G loss: 0.7292\n",
      "[1762/1762] D loss: 1.4460, G loss: 1.1308\n",
      "train error: \n",
      " D loss: 1.344853, G loss: 0.960091, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322743, G loss: 0.975620, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1363, G loss: 1.0623\n",
      "[84/1762] D loss: 1.4446, G loss: 0.7943\n",
      "[164/1762] D loss: 1.3914, G loss: 0.6982\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7287\n",
      "[324/1762] D loss: 1.1171, G loss: 1.0268\n",
      "[404/1762] D loss: 1.1303, G loss: 0.8697\n",
      "[484/1762] D loss: 1.4149, G loss: 0.8021\n",
      "[564/1762] D loss: 1.3969, G loss: 0.5915\n",
      "[644/1762] D loss: 1.0923, G loss: 1.0234\n",
      "[724/1762] D loss: 1.4109, G loss: 0.8696\n",
      "[804/1762] D loss: 1.4022, G loss: 0.6075\n",
      "[884/1762] D loss: 1.3898, G loss: 0.6822\n",
      "[964/1762] D loss: 1.1499, G loss: 0.8021\n",
      "[1044/1762] D loss: 1.3939, G loss: 0.7152\n",
      "[1124/1762] D loss: 1.4038, G loss: 0.8568\n",
      "[1204/1762] D loss: 0.8579, G loss: 1.1009\n",
      "[1284/1762] D loss: 1.3985, G loss: 0.6505\n",
      "[1364/1762] D loss: 1.3823, G loss: 0.8672\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.8083\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.7782\n",
      "[1604/1762] D loss: 1.1165, G loss: 0.9263\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.8130\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.7018\n",
      "train error: \n",
      " D loss: 1.314305, G loss: 0.780564, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294513, G loss: 0.796763, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3979, G loss: 0.7806\n",
      "[84/1762] D loss: 1.3458, G loss: 0.8970\n",
      "[164/1762] D loss: 0.8223, G loss: 1.2410\n",
      "[244/1762] D loss: 1.3940, G loss: 0.7968\n",
      "[324/1762] D loss: 1.1231, G loss: 1.1570\n",
      "[404/1762] D loss: 1.4077, G loss: 0.7617\n",
      "[484/1762] D loss: 1.1049, G loss: 0.9106\n",
      "[564/1762] D loss: 1.4248, G loss: 0.7361\n",
      "[644/1762] D loss: 1.4116, G loss: 0.6043\n",
      "[724/1762] D loss: 1.4059, G loss: 0.6442\n",
      "[804/1762] D loss: 1.4486, G loss: 0.7769\n",
      "[884/1762] D loss: 1.4751, G loss: 0.7919\n",
      "[964/1762] D loss: 1.4126, G loss: 0.6503\n",
      "[1044/1762] D loss: 1.3503, G loss: 0.7657\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.8038\n",
      "[1204/1762] D loss: 1.3470, G loss: 0.6660\n",
      "[1284/1762] D loss: 1.3995, G loss: 0.7375\n",
      "[1364/1762] D loss: 1.3858, G loss: 0.7301\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.7385\n",
      "[1524/1762] D loss: 1.4153, G loss: 0.6456\n",
      "[1604/1762] D loss: 1.1344, G loss: 0.8710\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.6907\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.7552\n",
      "train error: \n",
      " D loss: 1.325841, G loss: 0.832564, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 75.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306750, G loss: 0.853786, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3994, G loss: 0.8700\n",
      "[84/1762] D loss: 1.4030, G loss: 0.6867\n",
      "[164/1762] D loss: 1.3947, G loss: 0.6900\n",
      "[244/1762] D loss: 1.3907, G loss: 0.6950\n",
      "[324/1762] D loss: 1.1627, G loss: 0.7563\n",
      "[404/1762] D loss: 1.3955, G loss: 0.8321\n",
      "[484/1762] D loss: 1.3994, G loss: 0.7949\n",
      "[564/1762] D loss: 1.3898, G loss: 0.6636\n",
      "[644/1762] D loss: 1.3951, G loss: 0.6840\n",
      "[724/1762] D loss: 0.5959, G loss: 1.2076\n",
      "[804/1762] D loss: 1.1346, G loss: 1.0020\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7374\n",
      "[964/1762] D loss: 1.1158, G loss: 0.9662\n",
      "[1044/1762] D loss: 1.1152, G loss: 0.9825\n",
      "[1124/1762] D loss: 1.3786, G loss: 0.7777\n",
      "[1204/1762] D loss: 1.1284, G loss: 0.8368\n",
      "[1284/1762] D loss: 1.1438, G loss: 0.7850\n",
      "[1364/1762] D loss: 1.1286, G loss: 0.9510\n",
      "[1444/1762] D loss: 1.1279, G loss: 0.8770\n",
      "[1524/1762] D loss: 1.3990, G loss: 0.6154\n",
      "[1604/1762] D loss: 1.4071, G loss: 0.6248\n",
      "[1684/1762] D loss: 1.4017, G loss: 0.7685\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.7912\n",
      "train error: \n",
      " D loss: 1.319293, G loss: 0.807564, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 80.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299873, G loss: 0.822291, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1371, G loss: 0.9560\n",
      "[84/1762] D loss: 1.3908, G loss: 0.7702\n",
      "[164/1762] D loss: 1.3889, G loss: 0.7300\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6742\n",
      "[324/1762] D loss: 1.3968, G loss: 0.7319\n",
      "[404/1762] D loss: 1.3972, G loss: 0.7379\n",
      "[484/1762] D loss: 1.4028, G loss: 0.7280\n",
      "[564/1762] D loss: 1.3913, G loss: 0.6060\n",
      "[644/1762] D loss: 1.3948, G loss: 0.6215\n",
      "[724/1762] D loss: 1.4091, G loss: 0.5663\n",
      "[804/1762] D loss: 1.3995, G loss: 0.7545\n",
      "[884/1762] D loss: 1.4037, G loss: 0.5892\n",
      "[964/1762] D loss: 1.3582, G loss: 0.7425\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.7643\n",
      "[1124/1762] D loss: 1.3839, G loss: 0.6874\n",
      "[1204/1762] D loss: 1.1197, G loss: 0.8753\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.6878\n",
      "[1364/1762] D loss: 1.3977, G loss: 0.7563\n",
      "[1444/1762] D loss: 1.1259, G loss: 0.9799\n",
      "[1524/1762] D loss: 1.4300, G loss: 0.6864\n",
      "[1604/1762] D loss: 1.1035, G loss: 0.8590\n",
      "[1684/1762] D loss: 1.3905, G loss: 0.7070\n",
      "[1762/1762] D loss: 1.3848, G loss: 0.6223\n",
      "train error: \n",
      " D loss: 1.326665, G loss: 0.658696, D accuracy: 57.1%, cell accuracy: 98.7%, board accuracy: 25.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310215, G loss: 0.669031, D accuracy: 57.6%, cell accuracy: 98.6%, board accuracy: 26.1% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3793, G loss: 0.6586\n",
      "[84/1762] D loss: 1.1833, G loss: 0.8359\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6007\n",
      "[244/1762] D loss: 0.6293, G loss: 1.2715\n",
      "[324/1762] D loss: 1.3818, G loss: 0.6850\n",
      "[404/1762] D loss: 0.9571, G loss: 0.8750\n",
      "[484/1762] D loss: 1.3368, G loss: 0.9704\n",
      "[564/1762] D loss: 1.3253, G loss: 0.8391\n",
      "[644/1762] D loss: 1.3781, G loss: 0.8458\n",
      "[724/1762] D loss: 1.1529, G loss: 0.7596\n",
      "[804/1762] D loss: 1.4134, G loss: 0.6972\n",
      "[884/1762] D loss: 1.3857, G loss: 0.7707\n",
      "[964/1762] D loss: 1.3950, G loss: 0.5377\n",
      "[1044/1762] D loss: 1.4214, G loss: 0.5869\n",
      "[1124/1762] D loss: 0.9697, G loss: 0.8344\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.8979\n",
      "[1284/1762] D loss: 1.1302, G loss: 1.0516\n",
      "[1364/1762] D loss: 1.3849, G loss: 0.7924\n",
      "[1444/1762] D loss: 1.3787, G loss: 0.6544\n",
      "[1524/1762] D loss: 1.1363, G loss: 0.8447\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.7864\n",
      "[1684/1762] D loss: 1.4340, G loss: 0.6221\n",
      "[1762/1762] D loss: 0.8156, G loss: 1.2349\n",
      "train error: \n",
      " D loss: 1.320323, G loss: 0.770429, D accuracy: 54.6%, cell accuracy: 99.6%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298044, G loss: 0.785526, D accuracy: 55.6%, cell accuracy: 99.6%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3434, G loss: 0.7304\n",
      "[84/1762] D loss: 1.3932, G loss: 0.7355\n",
      "[164/1762] D loss: 1.4407, G loss: 0.6473\n",
      "[244/1762] D loss: 1.4282, G loss: 0.5792\n",
      "[324/1762] D loss: 1.1379, G loss: 0.8832\n",
      "[404/1762] D loss: 1.3926, G loss: 0.9029\n",
      "[484/1762] D loss: 1.3984, G loss: 0.7524\n",
      "[564/1762] D loss: 1.3884, G loss: 0.7620\n",
      "[644/1762] D loss: 1.3893, G loss: 0.7962\n",
      "[724/1762] D loss: 1.4503, G loss: 0.8740\n",
      "[804/1762] D loss: 1.3758, G loss: 0.6342\n",
      "[884/1762] D loss: 1.4185, G loss: 0.5719\n",
      "[964/1762] D loss: 1.3796, G loss: 0.6927\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.7176\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.6265\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.7177\n",
      "[1284/1762] D loss: 1.4117, G loss: 0.7944\n",
      "[1364/1762] D loss: 1.3769, G loss: 0.7020\n",
      "[1444/1762] D loss: 1.3795, G loss: 0.8383\n",
      "[1524/1762] D loss: 1.3981, G loss: 0.7311\n",
      "[1604/1762] D loss: 1.1316, G loss: 0.8668\n",
      "[1684/1762] D loss: 0.9118, G loss: 1.0116\n",
      "[1762/1762] D loss: 0.9416, G loss: 0.9386\n",
      "train error: \n",
      " D loss: 1.320849, G loss: 0.831466, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301262, G loss: 0.844779, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3988, G loss: 0.9809\n",
      "[84/1762] D loss: 1.4165, G loss: 0.7141\n",
      "[164/1762] D loss: 0.9219, G loss: 0.9033\n",
      "[244/1762] D loss: 1.3967, G loss: 0.6321\n",
      "[324/1762] D loss: 1.4073, G loss: 0.7734\n",
      "[404/1762] D loss: 1.3934, G loss: 0.7757\n",
      "[484/1762] D loss: 1.3905, G loss: 0.6569\n",
      "[564/1762] D loss: 1.3941, G loss: 0.7825\n",
      "[644/1762] D loss: 1.1646, G loss: 0.8098\n",
      "[724/1762] D loss: 1.1540, G loss: 0.8339\n",
      "[804/1762] D loss: 1.1303, G loss: 0.8220\n",
      "[884/1762] D loss: 1.3951, G loss: 0.6061\n",
      "[964/1762] D loss: 1.3907, G loss: 0.6826\n",
      "[1044/1762] D loss: 1.4072, G loss: 0.8290\n",
      "[1124/1762] D loss: 1.3904, G loss: 0.7513\n",
      "[1204/1762] D loss: 1.1271, G loss: 0.8980\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.7061\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.7164\n",
      "[1444/1762] D loss: 1.1275, G loss: 0.9737\n",
      "[1524/1762] D loss: 1.1078, G loss: 0.8954\n",
      "[1604/1762] D loss: 1.4132, G loss: 0.5581\n",
      "[1684/1762] D loss: 1.4372, G loss: 0.8193\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7949\n",
      "train error: \n",
      " D loss: 1.329870, G loss: 0.865527, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309342, G loss: 0.879978, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4105, G loss: 0.8204\n",
      "[84/1762] D loss: 1.3888, G loss: 0.6554\n",
      "[164/1762] D loss: 1.3895, G loss: 0.6602\n",
      "[244/1762] D loss: 1.1533, G loss: 0.8197\n",
      "[324/1762] D loss: 1.3964, G loss: 0.7567\n",
      "[404/1762] D loss: 1.3922, G loss: 0.7993\n",
      "[484/1762] D loss: 1.1918, G loss: 1.0444\n",
      "[564/1762] D loss: 1.1528, G loss: 0.8006\n",
      "[644/1762] D loss: 1.3935, G loss: 0.8363\n",
      "[724/1762] D loss: 1.3922, G loss: 0.6829\n",
      "[804/1762] D loss: 1.3926, G loss: 0.7086\n",
      "[884/1762] D loss: 1.1436, G loss: 0.8396\n",
      "[964/1762] D loss: 1.3936, G loss: 0.7485\n",
      "[1044/1762] D loss: 1.1164, G loss: 0.9049\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.6572\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6734\n",
      "[1284/1762] D loss: 1.4021, G loss: 0.8228\n",
      "[1364/1762] D loss: 1.4105, G loss: 0.7804\n",
      "[1444/1762] D loss: 0.8978, G loss: 0.9356\n",
      "[1524/1762] D loss: 1.1227, G loss: 0.9344\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.6075\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.7454\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7509\n",
      "train error: \n",
      " D loss: 1.316415, G loss: 0.807849, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295006, G loss: 0.827201, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8645, G loss: 1.1209\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6089\n",
      "[164/1762] D loss: 1.1100, G loss: 0.9275\n",
      "[244/1762] D loss: 1.1233, G loss: 1.0164\n",
      "[324/1762] D loss: 1.3909, G loss: 0.7431\n",
      "[404/1762] D loss: 1.4134, G loss: 0.7669\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6492\n",
      "[564/1762] D loss: 1.3965, G loss: 0.7040\n",
      "[644/1762] D loss: 1.4052, G loss: 0.7168\n",
      "[724/1762] D loss: 1.4094, G loss: 0.8546\n",
      "[804/1762] D loss: 1.4038, G loss: 0.6015\n",
      "[884/1762] D loss: 1.4043, G loss: 0.7130\n",
      "[964/1762] D loss: 1.4045, G loss: 0.8598\n",
      "[1044/1762] D loss: 1.3900, G loss: 0.6338\n",
      "[1124/1762] D loss: 1.1008, G loss: 1.0706\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.6838\n",
      "[1284/1762] D loss: 1.3723, G loss: 0.6707\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7105\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.6901\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6809\n",
      "[1604/1762] D loss: 1.4010, G loss: 0.7664\n",
      "[1684/1762] D loss: 1.3955, G loss: 0.6522\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.7167\n",
      "train error: \n",
      " D loss: 1.322417, G loss: 0.666634, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302005, G loss: 0.684930, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.6067\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7394\n",
      "[164/1762] D loss: 1.4004, G loss: 0.8908\n",
      "[244/1762] D loss: 1.3996, G loss: 0.7187\n",
      "[324/1762] D loss: 1.4048, G loss: 0.6418\n",
      "[404/1762] D loss: 1.4267, G loss: 0.7659\n",
      "[484/1762] D loss: 1.1116, G loss: 0.9328\n",
      "[564/1762] D loss: 1.1224, G loss: 0.8521\n",
      "[644/1762] D loss: 1.3911, G loss: 0.7814\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7163\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6133\n",
      "[884/1762] D loss: 1.3905, G loss: 0.7516\n",
      "[964/1762] D loss: 1.3992, G loss: 0.8149\n",
      "[1044/1762] D loss: 1.3935, G loss: 0.7152\n",
      "[1124/1762] D loss: 1.4090, G loss: 0.7031\n",
      "[1204/1762] D loss: 1.3980, G loss: 0.6388\n",
      "[1284/1762] D loss: 1.3827, G loss: 0.6950\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.6391\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.7258\n",
      "[1524/1762] D loss: 1.3912, G loss: 0.7475\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.6569\n",
      "[1684/1762] D loss: 1.1251, G loss: 0.8151\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.7833\n",
      "train error: \n",
      " D loss: 1.318073, G loss: 0.860457, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298113, G loss: 0.882037, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8216, G loss: 1.2804\n",
      "[84/1762] D loss: 1.1181, G loss: 0.8557\n",
      "[164/1762] D loss: 1.1441, G loss: 0.7782\n",
      "[244/1762] D loss: 1.3939, G loss: 0.7219\n",
      "[324/1762] D loss: 1.4151, G loss: 0.8270\n",
      "[404/1762] D loss: 0.8128, G loss: 1.2992\n",
      "[484/1762] D loss: 1.4497, G loss: 0.8191\n",
      "[564/1762] D loss: 1.4150, G loss: 0.4991\n",
      "[644/1762] D loss: 1.4616, G loss: 0.5449\n",
      "[724/1762] D loss: 1.4140, G loss: 0.8358\n",
      "[804/1762] D loss: 1.1039, G loss: 0.8883\n",
      "[884/1762] D loss: 1.3896, G loss: 0.7485\n",
      "[964/1762] D loss: 1.1116, G loss: 0.9175\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7259\n",
      "[1124/1762] D loss: 1.3913, G loss: 0.5871\n",
      "[1204/1762] D loss: 1.4242, G loss: 0.6240\n",
      "[1284/1762] D loss: 1.0893, G loss: 1.0514\n",
      "[1364/1762] D loss: 1.4573, G loss: 0.7623\n",
      "[1444/1762] D loss: 1.3970, G loss: 0.6765\n",
      "[1524/1762] D loss: 0.8106, G loss: 1.2850\n",
      "[1604/1762] D loss: 1.0948, G loss: 0.9844\n",
      "[1684/1762] D loss: 1.3931, G loss: 0.6615\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6457\n",
      "train error: \n",
      " D loss: 1.315422, G loss: 0.708704, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294506, G loss: 0.729639, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3979, G loss: 0.6078\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6731\n",
      "[164/1762] D loss: 1.0842, G loss: 1.0797\n",
      "[244/1762] D loss: 1.4596, G loss: 0.6325\n",
      "[324/1762] D loss: 1.3905, G loss: 0.7748\n",
      "[404/1762] D loss: 1.0912, G loss: 0.9597\n",
      "[484/1762] D loss: 1.3914, G loss: 0.6124\n",
      "[564/1762] D loss: 1.4052, G loss: 0.7187\n",
      "[644/1762] D loss: 1.4383, G loss: 0.6995\n",
      "[724/1762] D loss: 2.4468, G loss: 0.5934\n",
      "[804/1762] D loss: 0.6697, G loss: 1.8973\n",
      "[884/1762] D loss: 1.6991, G loss: 0.6777\n",
      "[964/1762] D loss: 1.4474, G loss: 0.8780\n",
      "[1044/1762] D loss: 1.5291, G loss: 0.6944\n",
      "[1124/1762] D loss: 1.4235, G loss: 0.4743\n",
      "[1204/1762] D loss: 1.2516, G loss: 0.5741\n",
      "[1284/1762] D loss: 1.1907, G loss: 0.8600\n",
      "[1364/1762] D loss: 1.3782, G loss: 0.7072\n",
      "[1444/1762] D loss: 1.4037, G loss: 0.6279\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.6423\n",
      "[1604/1762] D loss: 1.3919, G loss: 0.6490\n",
      "[1684/1762] D loss: 1.2574, G loss: 0.7614\n",
      "[1762/1762] D loss: 1.4098, G loss: 0.7169\n",
      "train error: \n",
      " D loss: 1.336145, G loss: 0.786552, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320381, G loss: 0.791804, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4535, G loss: 0.9075\n",
      "[84/1762] D loss: 1.1790, G loss: 0.8849\n",
      "[164/1762] D loss: 1.4129, G loss: 0.8549\n",
      "[244/1762] D loss: 1.0566, G loss: 1.0052\n",
      "[324/1762] D loss: 1.3959, G loss: 0.7456\n",
      "[404/1762] D loss: 1.1601, G loss: 0.8668\n",
      "[484/1762] D loss: 1.3878, G loss: 0.7110\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6841\n",
      "[644/1762] D loss: 1.3964, G loss: 0.6639\n",
      "[724/1762] D loss: 1.1954, G loss: 0.7192\n",
      "[804/1762] D loss: 0.9917, G loss: 0.7712\n",
      "[884/1762] D loss: 1.3956, G loss: 0.7062\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6836\n",
      "[1044/1762] D loss: 0.8726, G loss: 1.0739\n",
      "[1124/1762] D loss: 1.1490, G loss: 0.9075\n",
      "[1204/1762] D loss: 1.3889, G loss: 0.7020\n",
      "[1284/1762] D loss: 1.1573, G loss: 0.7509\n",
      "[1364/1762] D loss: 0.9445, G loss: 1.1839\n",
      "[1444/1762] D loss: 1.1522, G loss: 0.8531\n",
      "[1524/1762] D loss: 1.3965, G loss: 0.7011\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.6587\n",
      "[1684/1762] D loss: 0.8966, G loss: 0.9891\n",
      "[1762/1762] D loss: 1.4076, G loss: 0.6232\n",
      "train error: \n",
      " D loss: 1.331031, G loss: 0.660107, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314241, G loss: 0.670860, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6267\n",
      "[84/1762] D loss: 1.1586, G loss: 0.7833\n",
      "[164/1762] D loss: 1.3888, G loss: 0.7028\n",
      "[244/1762] D loss: 1.3870, G loss: 0.7568\n",
      "[324/1762] D loss: 1.3913, G loss: 0.7760\n",
      "[404/1762] D loss: 1.1412, G loss: 0.9653\n",
      "[484/1762] D loss: 1.3919, G loss: 0.7329\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6628\n",
      "[644/1762] D loss: 1.3913, G loss: 0.6359\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6214\n",
      "[804/1762] D loss: 1.1374, G loss: 0.8295\n",
      "[884/1762] D loss: 1.4038, G loss: 0.8161\n",
      "[964/1762] D loss: 1.4148, G loss: 0.8189\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.7770\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7417\n",
      "[1204/1762] D loss: 1.1661, G loss: 0.7192\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.6656\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6907\n",
      "[1444/1762] D loss: 1.1546, G loss: 0.8844\n",
      "[1524/1762] D loss: 1.4010, G loss: 0.7306\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.7515\n",
      "[1684/1762] D loss: 1.1304, G loss: 0.9456\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7281\n",
      "train error: \n",
      " D loss: 1.316712, G loss: 0.748119, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297283, G loss: 0.764959, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.7449\n",
      "[84/1762] D loss: 1.3959, G loss: 0.5566\n",
      "[164/1762] D loss: 1.4213, G loss: 0.6086\n",
      "[244/1762] D loss: 1.4246, G loss: 0.5280\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6852\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6409\n",
      "[484/1762] D loss: 1.3789, G loss: 0.7005\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7158\n",
      "[644/1762] D loss: 1.0797, G loss: 0.9035\n",
      "[724/1762] D loss: 1.1730, G loss: 1.0419\n",
      "[804/1762] D loss: 1.4524, G loss: 0.8118\n",
      "[884/1762] D loss: 1.3933, G loss: 0.6549\n",
      "[964/1762] D loss: 1.3944, G loss: 0.6167\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.5758\n",
      "[1124/1762] D loss: 1.1634, G loss: 0.7812\n",
      "[1204/1762] D loss: 1.1024, G loss: 0.9731\n",
      "[1284/1762] D loss: 1.1685, G loss: 0.7824\n",
      "[1364/1762] D loss: 1.1336, G loss: 0.9403\n",
      "[1444/1762] D loss: 1.3325, G loss: 0.7357\n",
      "[1524/1762] D loss: 1.4107, G loss: 0.5155\n",
      "[1604/1762] D loss: 1.3998, G loss: 0.6608\n",
      "[1684/1762] D loss: 1.3293, G loss: 0.6324\n",
      "[1762/1762] D loss: 0.5431, G loss: 0.9805\n",
      "train error: \n",
      " D loss: 1.283686, G loss: 0.702626, D accuracy: 62.8%, cell accuracy: 98.6%, board accuracy: 22.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275177, G loss: 0.703134, D accuracy: 61.9%, cell accuracy: 98.5%, board accuracy: 21.4% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3289, G loss: 0.7675\n",
      "[84/1762] D loss: 1.3700, G loss: 0.7075\n",
      "[164/1762] D loss: 1.1946, G loss: 0.6576\n",
      "[244/1762] D loss: 1.3962, G loss: 0.5606\n",
      "[324/1762] D loss: 1.3141, G loss: 0.7738\n",
      "[404/1762] D loss: 1.0953, G loss: 1.1694\n",
      "[484/1762] D loss: 1.2917, G loss: 0.7477\n",
      "[564/1762] D loss: 1.3465, G loss: 0.6021\n",
      "[644/1762] D loss: 1.3401, G loss: 0.6562\n",
      "[724/1762] D loss: 1.3351, G loss: 0.6700\n",
      "[804/1762] D loss: 1.3633, G loss: 0.5413\n",
      "[884/1762] D loss: 1.1563, G loss: 0.8204\n",
      "[964/1762] D loss: 1.3894, G loss: 0.6848\n",
      "[1044/1762] D loss: 1.4295, G loss: 0.8532\n",
      "[1124/1762] D loss: 1.5389, G loss: 0.9827\n",
      "[1204/1762] D loss: 3.0257, G loss: 0.6943\n",
      "[1284/1762] D loss: 1.1108, G loss: 1.3920\n",
      "[1364/1762] D loss: 0.5446, G loss: 1.4224\n",
      "[1444/1762] D loss: 1.6287, G loss: 1.1157\n",
      "[1524/1762] D loss: 1.4853, G loss: 0.7456\n",
      "[1604/1762] D loss: 1.4834, G loss: 0.7715\n",
      "[1684/1762] D loss: 1.4655, G loss: 0.5137\n",
      "[1762/1762] D loss: 1.4754, G loss: 0.5067\n",
      "train error: \n",
      " D loss: 1.416884, G loss: 0.738894, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.420666, G loss: 0.742211, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980, G loss: 0.7609\n",
      "[84/1762] D loss: 1.4031, G loss: 0.6690\n",
      "[164/1762] D loss: 1.4347, G loss: 0.6345\n",
      "[244/1762] D loss: 1.3991, G loss: 0.6505\n",
      "[324/1762] D loss: 1.2261, G loss: 0.7299\n",
      "[404/1762] D loss: 1.3109, G loss: 0.7609\n",
      "[484/1762] D loss: 1.3909, G loss: 0.6384\n",
      "[564/1762] D loss: 1.3962, G loss: 0.7566\n",
      "[644/1762] D loss: 1.3694, G loss: 0.6877\n",
      "[724/1762] D loss: 1.1598, G loss: 0.7841\n",
      "[804/1762] D loss: 1.3540, G loss: 0.6612\n",
      "[884/1762] D loss: 1.3921, G loss: 0.7274\n",
      "[964/1762] D loss: 1.4084, G loss: 0.6121\n",
      "[1044/1762] D loss: 1.2669, G loss: 0.6826\n",
      "[1124/1762] D loss: 1.2510, G loss: 0.7045\n",
      "[1204/1762] D loss: 1.3988, G loss: 0.8300\n",
      "[1284/1762] D loss: 1.3942, G loss: 0.7364\n",
      "[1364/1762] D loss: 1.3967, G loss: 0.7599\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.6906\n",
      "[1524/1762] D loss: 1.0505, G loss: 0.8384\n",
      "[1604/1762] D loss: 1.2102, G loss: 0.7286\n",
      "[1684/1762] D loss: 1.2042, G loss: 0.7728\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6998\n",
      "train error: \n",
      " D loss: 1.341776, G loss: 0.743983, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327879, G loss: 0.752618, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2225, G loss: 0.8013\n",
      "[84/1762] D loss: 1.3990, G loss: 0.8085\n",
      "[164/1762] D loss: 1.3914, G loss: 0.6993\n",
      "[244/1762] D loss: 1.3909, G loss: 0.7357\n",
      "[324/1762] D loss: 1.4422, G loss: 0.8587\n",
      "[404/1762] D loss: 1.3939, G loss: 0.7542\n",
      "[484/1762] D loss: 1.3994, G loss: 0.6355\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6775\n",
      "[644/1762] D loss: 1.3758, G loss: 0.7117\n",
      "[724/1762] D loss: 1.3924, G loss: 0.7475\n",
      "[804/1762] D loss: 1.3905, G loss: 0.6627\n",
      "[884/1762] D loss: 1.3881, G loss: 0.7179\n",
      "[964/1762] D loss: 1.4134, G loss: 0.6411\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.7118\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.6955\n",
      "[1204/1762] D loss: 1.4005, G loss: 0.5605\n",
      "[1284/1762] D loss: 1.1754, G loss: 0.8698\n",
      "[1364/1762] D loss: 0.9655, G loss: 0.8710\n",
      "[1444/1762] D loss: 1.1523, G loss: 0.8818\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.6180\n",
      "[1604/1762] D loss: 1.1800, G loss: 0.7572\n",
      "[1684/1762] D loss: 1.2406, G loss: 0.6754\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.7770\n",
      "train error: \n",
      " D loss: 1.336371, G loss: 0.826164, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319856, G loss: 0.836726, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3968, G loss: 0.7754\n",
      "[84/1762] D loss: 1.3886, G loss: 0.6627\n",
      "[164/1762] D loss: 1.3899, G loss: 0.7200\n",
      "[244/1762] D loss: 1.3903, G loss: 0.7022\n",
      "[324/1762] D loss: 1.3908, G loss: 0.7296\n",
      "[404/1762] D loss: 1.3940, G loss: 0.6352\n",
      "[484/1762] D loss: 1.1571, G loss: 0.8914\n",
      "[564/1762] D loss: 1.3911, G loss: 0.7404\n",
      "[644/1762] D loss: 1.3968, G loss: 0.7779\n",
      "[724/1762] D loss: 1.3966, G loss: 0.7456\n",
      "[804/1762] D loss: 1.3976, G loss: 0.8627\n",
      "[884/1762] D loss: 1.3974, G loss: 0.6603\n",
      "[964/1762] D loss: 1.4426, G loss: 0.8078\n",
      "[1044/1762] D loss: 1.3968, G loss: 0.8380\n",
      "[1124/1762] D loss: 1.3915, G loss: 0.6326\n",
      "[1204/1762] D loss: 1.1607, G loss: 1.0053\n",
      "[1284/1762] D loss: 1.1993, G loss: 0.7024\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6686\n",
      "[1444/1762] D loss: 1.3939, G loss: 0.8119\n",
      "[1524/1762] D loss: 1.3931, G loss: 0.6223\n",
      "[1604/1762] D loss: 1.1480, G loss: 0.8579\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.6794\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.7437\n",
      "train error: \n",
      " D loss: 1.327755, G loss: 0.768770, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309442, G loss: 0.782467, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6945\n",
      "[84/1762] D loss: 1.3878, G loss: 0.7479\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6032\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6923\n",
      "[324/1762] D loss: 1.1639, G loss: 0.7451\n",
      "[404/1762] D loss: 1.3876, G loss: 0.7453\n",
      "[484/1762] D loss: 1.3960, G loss: 0.6007\n",
      "[564/1762] D loss: 1.3926, G loss: 0.6532\n",
      "[644/1762] D loss: 1.1592, G loss: 0.8428\n",
      "[724/1762] D loss: 1.1535, G loss: 0.9311\n",
      "[804/1762] D loss: 1.3936, G loss: 0.6685\n",
      "[884/1762] D loss: 1.3923, G loss: 0.6237\n",
      "[964/1762] D loss: 1.3921, G loss: 0.7085\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6875\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.6477\n",
      "[1204/1762] D loss: 1.1476, G loss: 0.9036\n",
      "[1284/1762] D loss: 1.1335, G loss: 0.8411\n",
      "[1364/1762] D loss: 1.1922, G loss: 0.6558\n",
      "[1444/1762] D loss: 1.3890, G loss: 0.7329\n",
      "[1524/1762] D loss: 1.3753, G loss: 0.8308\n",
      "[1604/1762] D loss: 1.3928, G loss: 0.7048\n",
      "[1684/1762] D loss: 1.4335, G loss: 0.7449\n",
      "[1762/1762] D loss: 1.3760, G loss: 0.7369\n",
      "train error: \n",
      " D loss: 1.323238, G loss: 0.757590, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 66.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304990, G loss: 0.770085, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 62.0% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.7025\n",
      "[84/1762] D loss: 1.1146, G loss: 0.9518\n",
      "[164/1762] D loss: 1.3777, G loss: 0.6856\n",
      "[244/1762] D loss: 1.3827, G loss: 0.6194\n",
      "[324/1762] D loss: 1.3836, G loss: 0.7637\n",
      "[404/1762] D loss: 1.3679, G loss: 0.7014\n",
      "[484/1762] D loss: 1.3562, G loss: 0.6690\n",
      "[564/1762] D loss: 1.3979, G loss: 0.7175\n",
      "[644/1762] D loss: 1.3688, G loss: 0.6751\n",
      "[724/1762] D loss: 1.4022, G loss: 0.7649\n",
      "[804/1762] D loss: 0.8839, G loss: 1.0840\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7754\n",
      "[964/1762] D loss: 1.3910, G loss: 0.6462\n",
      "[1044/1762] D loss: 1.3772, G loss: 0.6763\n",
      "[1124/1762] D loss: 1.3773, G loss: 0.7637\n",
      "[1204/1762] D loss: 1.4020, G loss: 0.6460\n",
      "[1284/1762] D loss: 1.1887, G loss: 0.7914\n",
      "[1364/1762] D loss: 1.1344, G loss: 0.8943\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.7054\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.7072\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.7484\n",
      "[1684/1762] D loss: 1.1806, G loss: 0.7107\n",
      "[1762/1762] D loss: 1.3993, G loss: 0.6591\n",
      "train error: \n",
      " D loss: 1.370833, G loss: 0.687244, D accuracy: 51.7%, cell accuracy: 99.7%, board accuracy: 74.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355436, G loss: 0.696774, D accuracy: 51.2%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1872, G loss: 0.6759\n",
      "[84/1762] D loss: 1.5142, G loss: 0.6434\n",
      "[164/1762] D loss: 1.2507, G loss: 0.6212\n",
      "[244/1762] D loss: 1.3925, G loss: 0.6916\n",
      "[324/1762] D loss: 1.0596, G loss: 0.8504\n",
      "[404/1762] D loss: 1.3749, G loss: 0.7688\n",
      "[484/1762] D loss: 1.3765, G loss: 0.6396\n",
      "[564/1762] D loss: 1.3913, G loss: 0.7137\n",
      "[644/1762] D loss: 1.3881, G loss: 0.7218\n",
      "[724/1762] D loss: 1.3948, G loss: 0.6441\n",
      "[804/1762] D loss: 1.3975, G loss: 0.6212\n",
      "[884/1762] D loss: 1.4149, G loss: 0.6931\n",
      "[964/1762] D loss: 1.3934, G loss: 0.6296\n",
      "[1044/1762] D loss: 1.1758, G loss: 0.8066\n",
      "[1124/1762] D loss: 1.1940, G loss: 0.7445\n",
      "[1204/1762] D loss: 1.3642, G loss: 0.5850\n",
      "[1284/1762] D loss: 1.3905, G loss: 0.8658\n",
      "[1364/1762] D loss: 1.1140, G loss: 0.8480\n",
      "[1444/1762] D loss: 1.3333, G loss: 0.7337\n",
      "[1524/1762] D loss: 1.2285, G loss: 0.7429\n",
      "[1604/1762] D loss: 1.4232, G loss: 0.8303\n",
      "[1684/1762] D loss: 1.1667, G loss: 0.8311\n",
      "[1762/1762] D loss: 1.4490, G loss: 0.8865\n",
      "train error: \n",
      " D loss: 1.330689, G loss: 0.746407, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315086, G loss: 0.756694, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6868\n",
      "[84/1762] D loss: 1.3828, G loss: 0.6884\n",
      "[164/1762] D loss: 1.3802, G loss: 0.6894\n",
      "[244/1762] D loss: 1.3770, G loss: 0.6934\n",
      "[324/1762] D loss: 1.3685, G loss: 0.6999\n",
      "[404/1762] D loss: 1.3591, G loss: 0.7060\n",
      "[484/1762] D loss: 1.3525, G loss: 0.7118\n",
      "[564/1762] D loss: 1.3338, G loss: 0.7233\n",
      "[644/1762] D loss: 1.3180, G loss: 0.7326\n",
      "[724/1762] D loss: 1.2892, G loss: 0.7582\n",
      "[804/1762] D loss: 1.2535, G loss: 0.7999\n",
      "[884/1762] D loss: 1.1655, G loss: 0.8887\n",
      "[964/1762] D loss: 1.1580, G loss: 0.8967\n",
      "[1044/1762] D loss: 1.1277, G loss: 0.9519\n",
      "[1124/1762] D loss: 0.9919, G loss: 1.1193\n",
      "[1204/1762] D loss: 0.9163, G loss: 1.0905\n",
      "[1284/1762] D loss: 0.9533, G loss: 1.2403\n",
      "[1364/1762] D loss: 0.8967, G loss: 1.0273\n",
      "[1444/1762] D loss: 0.7296, G loss: 1.3474\n",
      "[1524/1762] D loss: 0.6718, G loss: 1.3067\n",
      "[1604/1762] D loss: 0.7866, G loss: 1.2900\n",
      "[1684/1762] D loss: 0.6125, G loss: 1.5700\n",
      "[1762/1762] D loss: 0.6497, G loss: 1.1698\n",
      "train error: \n",
      " D loss: 0.584173, G loss: 1.464689, D accuracy: 99.8%, cell accuracy: 90.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.587104, G loss: 1.456494, D accuracy: 99.9%, cell accuracy: 90.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5198, G loss: 1.6193\n",
      "[84/1762] D loss: 0.3682, G loss: 1.9979\n",
      "[164/1762] D loss: 0.5016, G loss: 1.4826\n",
      "[244/1762] D loss: 0.3674, G loss: 1.8799\n",
      "[324/1762] D loss: 0.4188, G loss: 1.8722\n",
      "[404/1762] D loss: 0.3919, G loss: 1.5520\n",
      "[484/1762] D loss: 0.3961, G loss: 1.9036\n",
      "[564/1762] D loss: 0.4197, G loss: 1.5968\n",
      "[644/1762] D loss: 0.3976, G loss: 1.7429\n",
      "[724/1762] D loss: 0.3977, G loss: 2.1692\n",
      "[804/1762] D loss: 0.3423, G loss: 2.3346\n",
      "[884/1762] D loss: 0.2779, G loss: 2.2157\n",
      "[964/1762] D loss: 0.3526, G loss: 1.7031\n",
      "[1044/1762] D loss: 0.4428, G loss: 1.4814\n",
      "[1124/1762] D loss: 0.4458, G loss: 1.6668\n",
      "[1204/1762] D loss: 0.3587, G loss: 2.6695\n",
      "[1284/1762] D loss: 0.2979, G loss: 2.3311\n",
      "[1364/1762] D loss: 0.3166, G loss: 2.3262\n",
      "[1444/1762] D loss: 0.2721, G loss: 2.5027\n",
      "[1524/1762] D loss: 0.2746, G loss: 2.9572\n",
      "[1604/1762] D loss: 0.5826, G loss: 2.1467\n",
      "[1684/1762] D loss: 0.4079, G loss: 1.6967\n",
      "[1762/1762] D loss: 0.5442, G loss: 2.4519\n",
      "train error: \n",
      " D loss: 0.549289, G loss: 2.381855, D accuracy: 92.7%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.563793, G loss: 2.364594, D accuracy: 92.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7327, G loss: 2.0606\n",
      "[84/1762] D loss: 0.4795, G loss: 1.5049\n",
      "[164/1762] D loss: 0.5460, G loss: 1.0112\n",
      "[244/1762] D loss: 0.5696, G loss: 3.0530\n",
      "[324/1762] D loss: 0.5363, G loss: 1.4056\n",
      "[404/1762] D loss: 0.4573, G loss: 2.4938\n",
      "[484/1762] D loss: 0.5681, G loss: 1.5513\n",
      "[564/1762] D loss: 0.8113, G loss: 0.9510\n",
      "[644/1762] D loss: 0.3558, G loss: 1.7580\n",
      "[724/1762] D loss: 0.7313, G loss: 1.2964\n",
      "[804/1762] D loss: 0.5218, G loss: 2.0578\n",
      "[884/1762] D loss: 0.3940, G loss: 2.0113\n",
      "[964/1762] D loss: 0.6715, G loss: 1.1307\n",
      "[1044/1762] D loss: 0.7144, G loss: 1.0762\n",
      "[1124/1762] D loss: 0.5064, G loss: 2.0471\n",
      "[1204/1762] D loss: 0.5276, G loss: 2.8725\n",
      "[1284/1762] D loss: 0.6298, G loss: 1.0890\n",
      "[1364/1762] D loss: 0.7649, G loss: 1.0667\n",
      "[1444/1762] D loss: 0.6401, G loss: 2.0985\n",
      "[1524/1762] D loss: 0.5682, G loss: 1.4389\n",
      "[1604/1762] D loss: 0.8081, G loss: 1.1677\n",
      "[1684/1762] D loss: 0.3767, G loss: 1.4669\n",
      "[1762/1762] D loss: 0.9278, G loss: 2.0853\n",
      "train error: \n",
      " D loss: 0.764335, G loss: 1.897757, D accuracy: 86.5%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.801728, G loss: 1.915391, D accuracy: 85.3%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7182, G loss: 1.8928\n",
      "[84/1762] D loss: 0.6972, G loss: 1.4730\n",
      "[164/1762] D loss: 0.8437, G loss: 1.2425\n",
      "[244/1762] D loss: 0.7672, G loss: 1.1321\n",
      "[324/1762] D loss: 0.6513, G loss: 1.2125\n",
      "[404/1762] D loss: 0.6652, G loss: 1.2899\n",
      "[484/1762] D loss: 0.5779, G loss: 1.8963\n",
      "[564/1762] D loss: 0.5431, G loss: 1.9017\n",
      "[644/1762] D loss: 0.6143, G loss: 1.0837\n",
      "[724/1762] D loss: 0.7252, G loss: 1.8438\n",
      "[804/1762] D loss: 0.9068, G loss: 0.9535\n",
      "[884/1762] D loss: 0.8059, G loss: 1.1942\n",
      "[964/1762] D loss: 0.8787, G loss: 1.3361\n",
      "[1044/1762] D loss: 0.7317, G loss: 1.1540\n",
      "[1124/1762] D loss: 1.0037, G loss: 1.6282\n",
      "[1204/1762] D loss: 1.0840, G loss: 1.3130\n",
      "[1284/1762] D loss: 1.0039, G loss: 0.9723\n",
      "[1364/1762] D loss: 0.7750, G loss: 0.8575\n",
      "[1444/1762] D loss: 0.6086, G loss: 1.4894\n",
      "[1524/1762] D loss: 0.8306, G loss: 1.5999\n",
      "[1604/1762] D loss: 0.7577, G loss: 1.1242\n",
      "[1684/1762] D loss: 0.8396, G loss: 0.9053\n",
      "[1762/1762] D loss: 0.8715, G loss: 0.8039\n",
      "train error: \n",
      " D loss: 0.942820, G loss: 0.756378, D accuracy: 74.5%, cell accuracy: 96.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.938525, G loss: 0.794767, D accuracy: 74.8%, cell accuracy: 96.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9895, G loss: 0.8538\n",
      "[84/1762] D loss: 1.1034, G loss: 1.3918\n",
      "[164/1762] D loss: 0.9290, G loss: 1.6221\n",
      "[244/1762] D loss: 0.8118, G loss: 1.2188\n",
      "[324/1762] D loss: 0.5546, G loss: 1.6177\n",
      "[404/1762] D loss: 0.7066, G loss: 1.1810\n",
      "[484/1762] D loss: 0.8806, G loss: 1.3039\n",
      "[564/1762] D loss: 0.7383, G loss: 1.1653\n",
      "[644/1762] D loss: 1.0208, G loss: 0.9774\n",
      "[724/1762] D loss: 0.9119, G loss: 0.7790\n",
      "[804/1762] D loss: 0.8663, G loss: 0.7286\n",
      "[884/1762] D loss: 1.0543, G loss: 1.6694\n",
      "[964/1762] D loss: 1.0195, G loss: 1.5447\n",
      "[1044/1762] D loss: 0.9504, G loss: 0.8702\n",
      "[1124/1762] D loss: 0.8106, G loss: 1.2962\n",
      "[1204/1762] D loss: 0.9233, G loss: 1.4474\n",
      "[1284/1762] D loss: 0.8071, G loss: 2.1341\n",
      "[1364/1762] D loss: 1.0044, G loss: 1.2476\n",
      "[1444/1762] D loss: 1.2125, G loss: 0.8489\n",
      "[1524/1762] D loss: 1.0886, G loss: 0.6199\n",
      "[1604/1762] D loss: 1.1550, G loss: 0.7043\n",
      "[1684/1762] D loss: 0.8333, G loss: 1.0280\n",
      "[1762/1762] D loss: 0.8282, G loss: 1.7163\n",
      "train error: \n",
      " D loss: 0.919739, G loss: 1.120390, D accuracy: 83.4%, cell accuracy: 96.6%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.938602, G loss: 1.163013, D accuracy: 84.3%, cell accuracy: 96.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6786, G loss: 1.2515\n",
      "[84/1762] D loss: 1.0288, G loss: 0.6602\n",
      "[164/1762] D loss: 1.1829, G loss: 1.3137\n",
      "[244/1762] D loss: 0.7648, G loss: 1.4769\n",
      "[324/1762] D loss: 0.8142, G loss: 1.1044\n",
      "[404/1762] D loss: 1.0224, G loss: 2.7150\n",
      "[484/1762] D loss: 1.1470, G loss: 1.0445\n",
      "[564/1762] D loss: 0.8078, G loss: 1.2077\n",
      "[644/1762] D loss: 0.7277, G loss: 1.1455\n",
      "[724/1762] D loss: 1.3313, G loss: 0.8827\n",
      "[804/1762] D loss: 1.2224, G loss: 0.9344\n",
      "[884/1762] D loss: 1.3892, G loss: 0.4752\n",
      "[964/1762] D loss: 0.9578, G loss: 1.0042\n",
      "[1044/1762] D loss: 1.3932, G loss: 1.4502\n",
      "[1124/1762] D loss: 0.9101, G loss: 0.9397\n",
      "[1204/1762] D loss: 0.9367, G loss: 1.2198\n",
      "[1284/1762] D loss: 0.8649, G loss: 1.0442\n",
      "[1364/1762] D loss: 1.2754, G loss: 1.2530\n",
      "[1444/1762] D loss: 1.0821, G loss: 1.6747\n",
      "[1524/1762] D loss: 0.8719, G loss: 1.1804\n",
      "[1604/1762] D loss: 1.6944, G loss: 1.3116\n",
      "[1684/1762] D loss: 1.3537, G loss: 0.6546\n",
      "[1762/1762] D loss: 1.1161, G loss: 0.6365\n",
      "train error: \n",
      " D loss: 1.232442, G loss: 0.677313, D accuracy: 65.5%, cell accuracy: 97.1%, board accuracy: 4.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.224703, G loss: 0.704493, D accuracy: 65.7%, cell accuracy: 97.0%, board accuracy: 4.3% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2178, G loss: 1.0038\n",
      "[84/1762] D loss: 1.1893, G loss: 0.7960\n",
      "[164/1762] D loss: 1.5134, G loss: 1.1417\n",
      "[244/1762] D loss: 1.2614, G loss: 0.6872\n",
      "[324/1762] D loss: 1.4722, G loss: 0.7614\n",
      "[404/1762] D loss: 1.5859, G loss: 0.6968\n",
      "[484/1762] D loss: 1.0100, G loss: 1.2683\n",
      "[564/1762] D loss: 1.2181, G loss: 0.6678\n",
      "[644/1762] D loss: 1.1398, G loss: 0.9885\n",
      "[724/1762] D loss: 1.0284, G loss: 0.8865\n",
      "[804/1762] D loss: 1.0990, G loss: 0.8546\n",
      "[884/1762] D loss: 1.2395, G loss: 0.7585\n",
      "[964/1762] D loss: 1.1248, G loss: 1.1352\n",
      "[1044/1762] D loss: 1.0077, G loss: 0.8855\n",
      "[1124/1762] D loss: 1.3935, G loss: 0.5402\n",
      "[1204/1762] D loss: 0.9144, G loss: 0.9073\n",
      "[1284/1762] D loss: 1.1649, G loss: 0.8610\n",
      "[1364/1762] D loss: 1.1805, G loss: 0.5880\n",
      "[1444/1762] D loss: 1.2142, G loss: 0.6720\n",
      "[1524/1762] D loss: 1.1841, G loss: 0.6629\n",
      "[1604/1762] D loss: 0.9975, G loss: 0.9692\n",
      "[1684/1762] D loss: 1.0467, G loss: 1.2198\n",
      "[1762/1762] D loss: 1.0912, G loss: 0.8462\n",
      "train error: \n",
      " D loss: 1.159598, G loss: 0.880115, D accuracy: 72.7%, cell accuracy: 97.4%, board accuracy: 5.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.163188, G loss: 0.899220, D accuracy: 72.4%, cell accuracy: 97.3%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2969, G loss: 0.7505\n",
      "[84/1762] D loss: 1.1768, G loss: 1.4717\n",
      "[164/1762] D loss: 1.3063, G loss: 0.9451\n",
      "[244/1762] D loss: 1.0179, G loss: 1.5887\n",
      "[324/1762] D loss: 0.9553, G loss: 1.2290\n",
      "[404/1762] D loss: 1.2536, G loss: 0.5721\n",
      "[484/1762] D loss: 0.9158, G loss: 1.0706\n",
      "[564/1762] D loss: 1.3158, G loss: 1.0787\n",
      "[644/1762] D loss: 1.8123, G loss: 0.6881\n",
      "[724/1762] D loss: 1.3984, G loss: 0.9969\n",
      "[804/1762] D loss: 1.1639, G loss: 0.9043\n",
      "[884/1762] D loss: 1.3313, G loss: 0.5926\n",
      "[964/1762] D loss: 1.1706, G loss: 0.6396\n",
      "[1044/1762] D loss: 1.2344, G loss: 1.5412\n",
      "[1124/1762] D loss: 1.1085, G loss: 1.0472\n",
      "[1204/1762] D loss: 1.2395, G loss: 0.7903\n",
      "[1284/1762] D loss: 1.1939, G loss: 1.2676\n",
      "[1364/1762] D loss: 1.2310, G loss: 0.6871\n",
      "[1444/1762] D loss: 1.1023, G loss: 0.9940\n",
      "[1524/1762] D loss: 1.3236, G loss: 1.2025\n",
      "[1604/1762] D loss: 1.1006, G loss: 0.8456\n",
      "[1684/1762] D loss: 1.1904, G loss: 0.7305\n",
      "[1762/1762] D loss: 0.6727, G loss: 1.2379\n",
      "train error: \n",
      " D loss: 1.289608, G loss: 0.618070, D accuracy: 64.7%, cell accuracy: 97.6%, board accuracy: 5.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279244, G loss: 0.618751, D accuracy: 64.9%, cell accuracy: 97.5%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0445, G loss: 0.5775\n",
      "[84/1762] D loss: 1.2362, G loss: 1.1224\n",
      "[164/1762] D loss: 1.2604, G loss: 0.9201\n",
      "[244/1762] D loss: 1.3093, G loss: 0.9152\n",
      "[324/1762] D loss: 1.1167, G loss: 1.3764\n",
      "[404/1762] D loss: 1.1531, G loss: 0.8804\n",
      "[484/1762] D loss: 1.5660, G loss: 1.0015\n",
      "[564/1762] D loss: 1.2281, G loss: 0.8395\n",
      "[644/1762] D loss: 1.0278, G loss: 0.7727\n",
      "[724/1762] D loss: 1.1457, G loss: 1.2055\n",
      "[804/1762] D loss: 1.1216, G loss: 1.1575\n",
      "[884/1762] D loss: 1.2969, G loss: 0.9682\n",
      "[964/1762] D loss: 0.8517, G loss: 1.1406\n",
      "[1044/1762] D loss: 1.2563, G loss: 0.7187\n",
      "[1124/1762] D loss: 1.0260, G loss: 1.1078\n",
      "[1204/1762] D loss: 1.2672, G loss: 0.8903\n",
      "[1284/1762] D loss: 1.4434, G loss: 0.6808\n",
      "[1364/1762] D loss: 0.6554, G loss: 1.4485\n",
      "[1444/1762] D loss: 1.3734, G loss: 0.7508\n",
      "[1524/1762] D loss: 1.3422, G loss: 1.3901\n",
      "[1604/1762] D loss: 1.2220, G loss: 0.8128\n",
      "[1684/1762] D loss: 1.2470, G loss: 1.0142\n",
      "[1762/1762] D loss: 1.6215, G loss: 0.7747\n",
      "train error: \n",
      " D loss: 1.270241, G loss: 1.060555, D accuracy: 62.4%, cell accuracy: 98.0%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266516, G loss: 1.091823, D accuracy: 62.8%, cell accuracy: 97.7%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2521, G loss: 1.4884\n",
      "[84/1762] D loss: 1.2702, G loss: 0.9858\n",
      "[164/1762] D loss: 1.3626, G loss: 0.8163\n",
      "[244/1762] D loss: 1.3422, G loss: 0.9145\n",
      "[324/1762] D loss: 1.2681, G loss: 1.0561\n",
      "[404/1762] D loss: 1.1832, G loss: 0.6835\n",
      "[484/1762] D loss: 0.8584, G loss: 0.9393\n",
      "[564/1762] D loss: 1.0336, G loss: 1.4581\n",
      "[644/1762] D loss: 1.1471, G loss: 0.9350\n",
      "[724/1762] D loss: 1.4120, G loss: 1.2333\n",
      "[804/1762] D loss: 1.4655, G loss: 0.5113\n",
      "[884/1762] D loss: 1.4068, G loss: 0.5952\n",
      "[964/1762] D loss: 1.1597, G loss: 0.9268\n",
      "[1044/1762] D loss: 1.3988, G loss: 0.7023\n",
      "[1124/1762] D loss: 1.3467, G loss: 0.8711\n",
      "[1204/1762] D loss: 1.5255, G loss: 0.8826\n",
      "[1284/1762] D loss: 1.1798, G loss: 0.7810\n",
      "[1364/1762] D loss: 1.0614, G loss: 0.9876\n",
      "[1444/1762] D loss: 1.2688, G loss: 0.8338\n",
      "[1524/1762] D loss: 1.1796, G loss: 0.5248\n",
      "[1604/1762] D loss: 1.2434, G loss: 1.0537\n",
      "[1684/1762] D loss: 1.2263, G loss: 1.0028\n",
      "[1762/1762] D loss: 1.2416, G loss: 0.6244\n",
      "train error: \n",
      " D loss: 1.252495, G loss: 0.848228, D accuracy: 67.3%, cell accuracy: 98.2%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.236218, G loss: 0.879954, D accuracy: 69.9%, cell accuracy: 98.0%, board accuracy: 6.4% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1709, G loss: 0.8196\n",
      "[84/1762] D loss: 1.1208, G loss: 1.1215\n",
      "[164/1762] D loss: 1.1307, G loss: 0.9018\n",
      "[244/1762] D loss: 1.1907, G loss: 0.8507\n",
      "[324/1762] D loss: 1.3763, G loss: 0.8967\n",
      "[404/1762] D loss: 1.0583, G loss: 1.2105\n",
      "[484/1762] D loss: 1.2616, G loss: 0.6175\n",
      "[564/1762] D loss: 1.3533, G loss: 1.2810\n",
      "[644/1762] D loss: 1.0613, G loss: 1.1343\n",
      "[724/1762] D loss: 1.4815, G loss: 0.4470\n",
      "[804/1762] D loss: 1.5331, G loss: 0.4497\n",
      "[884/1762] D loss: 0.9380, G loss: 0.7259\n",
      "[964/1762] D loss: 1.3302, G loss: 0.5623\n",
      "[1044/1762] D loss: 1.3341, G loss: 0.6055\n",
      "[1124/1762] D loss: 1.0399, G loss: 1.0013\n",
      "[1204/1762] D loss: 1.0430, G loss: 1.0084\n",
      "[1284/1762] D loss: 1.0497, G loss: 0.8535\n",
      "[1364/1762] D loss: 1.0681, G loss: 1.0825\n",
      "[1444/1762] D loss: 1.3427, G loss: 0.5240\n",
      "[1524/1762] D loss: 1.3025, G loss: 0.6834\n",
      "[1604/1762] D loss: 1.0946, G loss: 1.2819\n",
      "[1684/1762] D loss: 1.2356, G loss: 0.7790\n",
      "[1762/1762] D loss: 1.0314, G loss: 1.1248\n",
      "train error: \n",
      " D loss: 1.309140, G loss: 0.703939, D accuracy: 62.4%, cell accuracy: 98.3%, board accuracy: 9.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297873, G loss: 0.709005, D accuracy: 61.7%, cell accuracy: 98.1%, board accuracy: 7.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2809, G loss: 0.9379\n",
      "[84/1762] D loss: 1.3765, G loss: 1.0462\n",
      "[164/1762] D loss: 1.2103, G loss: 0.9702\n",
      "[244/1762] D loss: 1.1631, G loss: 0.6639\n",
      "[324/1762] D loss: 1.4363, G loss: 0.7666\n",
      "[404/1762] D loss: 1.1403, G loss: 0.8949\n",
      "[484/1762] D loss: 1.3202, G loss: 1.1814\n",
      "[564/1762] D loss: 1.2954, G loss: 0.7721\n",
      "[644/1762] D loss: 1.0784, G loss: 0.6817\n",
      "[724/1762] D loss: 1.4505, G loss: 0.7368\n",
      "[804/1762] D loss: 1.5968, G loss: 0.7617\n",
      "[884/1762] D loss: 1.2653, G loss: 0.7750\n",
      "[964/1762] D loss: 1.3596, G loss: 0.8560\n",
      "[1044/1762] D loss: 1.3444, G loss: 0.8552\n",
      "[1124/1762] D loss: 1.2703, G loss: 0.7360\n",
      "[1204/1762] D loss: 1.4289, G loss: 0.5317\n",
      "[1284/1762] D loss: 1.2718, G loss: 0.7880\n",
      "[1364/1762] D loss: 1.2701, G loss: 0.9836\n",
      "[1444/1762] D loss: 1.5323, G loss: 0.4400\n",
      "[1524/1762] D loss: 1.5263, G loss: 0.6487\n",
      "[1604/1762] D loss: 1.4764, G loss: 0.6629\n",
      "[1684/1762] D loss: 1.5617, G loss: 0.5015\n",
      "[1762/1762] D loss: 1.9899, G loss: 0.3336\n",
      "train error: \n",
      " D loss: 1.417111, G loss: 0.508457, D accuracy: 55.2%, cell accuracy: 98.5%, board accuracy: 12.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389749, G loss: 0.529537, D accuracy: 54.3%, cell accuracy: 98.3%, board accuracy: 8.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5696, G loss: 0.5332\n",
      "[84/1762] D loss: 1.2792, G loss: 0.7342\n",
      "[164/1762] D loss: 1.3261, G loss: 0.6360\n",
      "[244/1762] D loss: 1.4470, G loss: 0.5786\n",
      "[324/1762] D loss: 1.3075, G loss: 0.7843\n",
      "[404/1762] D loss: 1.3588, G loss: 1.0402\n",
      "[484/1762] D loss: 1.3398, G loss: 0.7786\n",
      "[564/1762] D loss: 1.6797, G loss: 1.0680\n",
      "[644/1762] D loss: 1.3701, G loss: 0.9149\n",
      "[724/1762] D loss: 1.6316, G loss: 0.4757\n",
      "[804/1762] D loss: 1.1682, G loss: 0.6224\n",
      "[884/1762] D loss: 1.4300, G loss: 0.7876\n",
      "[964/1762] D loss: 1.2670, G loss: 0.8484\n",
      "[1044/1762] D loss: 1.6298, G loss: 1.0053\n",
      "[1124/1762] D loss: 1.2147, G loss: 1.0137\n",
      "[1204/1762] D loss: 1.4285, G loss: 0.5002\n",
      "[1284/1762] D loss: 1.4467, G loss: 0.5486\n",
      "[1364/1762] D loss: 1.4256, G loss: 0.7942\n",
      "[1444/1762] D loss: 1.3992, G loss: 0.7416\n",
      "[1524/1762] D loss: 1.3565, G loss: 1.4217\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.5491\n",
      "[1684/1762] D loss: 1.5070, G loss: 0.8447\n",
      "[1762/1762] D loss: 1.3711, G loss: 0.6821\n",
      "train error: \n",
      " D loss: 1.334268, G loss: 0.741277, D accuracy: 60.4%, cell accuracy: 98.6%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315541, G loss: 0.753309, D accuracy: 61.7%, cell accuracy: 98.4%, board accuracy: 12.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3524, G loss: 0.6636\n",
      "[84/1762] D loss: 1.3996, G loss: 0.6379\n",
      "[164/1762] D loss: 1.2774, G loss: 0.8010\n",
      "[244/1762] D loss: 1.4923, G loss: 1.0098\n",
      "[324/1762] D loss: 1.4304, G loss: 0.9449\n",
      "[404/1762] D loss: 1.2335, G loss: 0.9763\n",
      "[484/1762] D loss: 1.3067, G loss: 1.1052\n",
      "[564/1762] D loss: 1.2429, G loss: 1.0182\n",
      "[644/1762] D loss: 1.1957, G loss: 0.9885\n",
      "[724/1762] D loss: 1.3441, G loss: 0.8234\n",
      "[804/1762] D loss: 1.2982, G loss: 0.6214\n",
      "[884/1762] D loss: 1.3076, G loss: 0.8005\n",
      "[964/1762] D loss: 1.1498, G loss: 1.0764\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.8271\n",
      "[1124/1762] D loss: 1.1669, G loss: 0.6978\n",
      "[1204/1762] D loss: 1.3533, G loss: 0.8392\n",
      "[1284/1762] D loss: 1.3622, G loss: 0.9112\n",
      "[1364/1762] D loss: 1.2353, G loss: 0.8512\n",
      "[1444/1762] D loss: 1.3177, G loss: 1.1059\n",
      "[1524/1762] D loss: 1.2579, G loss: 0.7852\n",
      "[1604/1762] D loss: 1.5615, G loss: 0.5425\n",
      "[1684/1762] D loss: 1.4620, G loss: 0.5257\n",
      "[1762/1762] D loss: 1.2845, G loss: 0.6995\n",
      "train error: \n",
      " D loss: 1.347936, G loss: 0.690741, D accuracy: 59.0%, cell accuracy: 98.7%, board accuracy: 24.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327468, G loss: 0.701789, D accuracy: 58.6%, cell accuracy: 98.5%, board accuracy: 18.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3725, G loss: 0.7358\n",
      "[84/1762] D loss: 1.5208, G loss: 0.6688\n",
      "[164/1762] D loss: 1.3301, G loss: 0.7334\n",
      "[244/1762] D loss: 1.3072, G loss: 0.9011\n",
      "[324/1762] D loss: 1.3499, G loss: 0.7708\n",
      "[404/1762] D loss: 1.3104, G loss: 0.8450\n",
      "[484/1762] D loss: 1.3855, G loss: 0.6035\n",
      "[564/1762] D loss: 1.2738, G loss: 0.6994\n",
      "[644/1762] D loss: 1.4063, G loss: 0.5894\n",
      "[724/1762] D loss: 1.2137, G loss: 0.7628\n",
      "[804/1762] D loss: 1.3116, G loss: 0.7972\n",
      "[884/1762] D loss: 1.4056, G loss: 1.0618\n",
      "[964/1762] D loss: 1.3735, G loss: 0.7460\n",
      "[1044/1762] D loss: 1.4629, G loss: 0.4349\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.6727\n",
      "[1204/1762] D loss: 1.2887, G loss: 0.7790\n",
      "[1284/1762] D loss: 1.4146, G loss: 0.5404\n",
      "[1364/1762] D loss: 1.3694, G loss: 0.6531\n",
      "[1444/1762] D loss: 1.3688, G loss: 0.8421\n",
      "[1524/1762] D loss: 1.1816, G loss: 0.9253\n",
      "[1604/1762] D loss: 1.3433, G loss: 0.7448\n",
      "[1684/1762] D loss: 1.3447, G loss: 0.4897\n",
      "[1762/1762] D loss: 1.2835, G loss: 1.2290\n",
      "train error: \n",
      " D loss: 1.346420, G loss: 0.816673, D accuracy: 58.6%, cell accuracy: 98.9%, board accuracy: 26.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331533, G loss: 0.832487, D accuracy: 59.5%, cell accuracy: 98.7%, board accuracy: 20.2% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4671, G loss: 0.9141\n",
      "[84/1762] D loss: 1.3468, G loss: 0.8152\n",
      "[164/1762] D loss: 1.3202, G loss: 0.8262\n",
      "[244/1762] D loss: 1.5629, G loss: 0.8220\n",
      "[324/1762] D loss: 1.5342, G loss: 0.7120\n",
      "[404/1762] D loss: 1.1628, G loss: 0.7830\n",
      "[484/1762] D loss: 1.2507, G loss: 0.7042\n",
      "[564/1762] D loss: 1.4942, G loss: 1.1408\n",
      "[644/1762] D loss: 1.4115, G loss: 0.7785\n",
      "[724/1762] D loss: 1.2512, G loss: 0.6136\n",
      "[804/1762] D loss: 1.2323, G loss: 0.7876\n",
      "[884/1762] D loss: 1.3736, G loss: 0.6204\n",
      "[964/1762] D loss: 1.4265, G loss: 0.8398\n",
      "[1044/1762] D loss: 1.4150, G loss: 0.9253\n",
      "[1124/1762] D loss: 1.4170, G loss: 0.7615\n",
      "[1204/1762] D loss: 1.3476, G loss: 0.7372\n",
      "[1284/1762] D loss: 1.3069, G loss: 0.7968\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.5694\n",
      "[1444/1762] D loss: 1.4171, G loss: 0.5794\n",
      "[1524/1762] D loss: 1.3341, G loss: 0.7152\n",
      "[1604/1762] D loss: 1.3483, G loss: 0.5701\n",
      "[1684/1762] D loss: 1.3334, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.6287, G loss: 0.7634\n",
      "train error: \n",
      " D loss: 1.349033, G loss: 0.774594, D accuracy: 58.6%, cell accuracy: 99.0%, board accuracy: 29.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325452, G loss: 0.794784, D accuracy: 59.7%, cell accuracy: 98.8%, board accuracy: 22.3% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2405, G loss: 0.7246\n",
      "[84/1762] D loss: 1.3101, G loss: 0.7861\n",
      "[164/1762] D loss: 1.3737, G loss: 0.7009\n",
      "[244/1762] D loss: 1.4160, G loss: 0.5432\n",
      "[324/1762] D loss: 1.3687, G loss: 0.7186\n",
      "[404/1762] D loss: 1.3648, G loss: 0.8175\n",
      "[484/1762] D loss: 1.3419, G loss: 0.7942\n",
      "[564/1762] D loss: 1.3693, G loss: 0.7218\n",
      "[644/1762] D loss: 1.4303, G loss: 0.4674\n",
      "[724/1762] D loss: 1.3954, G loss: 0.6085\n",
      "[804/1762] D loss: 1.5153, G loss: 1.2722\n",
      "[884/1762] D loss: 1.4587, G loss: 0.8398\n",
      "[964/1762] D loss: 1.2983, G loss: 0.9381\n",
      "[1044/1762] D loss: 1.3419, G loss: 0.4828\n",
      "[1124/1762] D loss: 1.2979, G loss: 0.6757\n",
      "[1204/1762] D loss: 1.4588, G loss: 0.9023\n",
      "[1284/1762] D loss: 1.3384, G loss: 1.0317\n",
      "[1364/1762] D loss: 1.4840, G loss: 1.2198\n",
      "[1444/1762] D loss: 1.4089, G loss: 0.7898\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7033\n",
      "[1604/1762] D loss: 1.3486, G loss: 0.7526\n",
      "[1684/1762] D loss: 1.4530, G loss: 0.4324\n",
      "[1762/1762] D loss: 1.4758, G loss: 0.7877\n",
      "train error: \n",
      " D loss: 1.353142, G loss: 0.676270, D accuracy: 58.1%, cell accuracy: 99.1%, board accuracy: 34.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329141, G loss: 0.694032, D accuracy: 58.9%, cell accuracy: 99.0%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2663, G loss: 0.5189\n",
      "[84/1762] D loss: 1.4053, G loss: 0.7250\n",
      "[164/1762] D loss: 1.3347, G loss: 0.7801\n",
      "[244/1762] D loss: 1.3334, G loss: 0.6685\n",
      "[324/1762] D loss: 1.3715, G loss: 0.8390\n",
      "[404/1762] D loss: 1.3713, G loss: 0.8215\n",
      "[484/1762] D loss: 1.3726, G loss: 0.6563\n",
      "[564/1762] D loss: 1.2661, G loss: 0.8352\n",
      "[644/1762] D loss: 1.2606, G loss: 1.0121\n",
      "[724/1762] D loss: 1.3462, G loss: 0.6049\n",
      "[804/1762] D loss: 1.4166, G loss: 0.5398\n",
      "[884/1762] D loss: 1.3885, G loss: 0.8169\n",
      "[964/1762] D loss: 1.3042, G loss: 0.7352\n",
      "[1044/1762] D loss: 1.2957, G loss: 0.9849\n",
      "[1124/1762] D loss: 1.2508, G loss: 1.0032\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.8868\n",
      "[1284/1762] D loss: 1.3693, G loss: 0.7671\n",
      "[1364/1762] D loss: 1.1664, G loss: 0.7228\n",
      "[1444/1762] D loss: 1.3564, G loss: 0.5908\n",
      "[1524/1762] D loss: 1.3738, G loss: 0.8299\n",
      "[1604/1762] D loss: 1.3276, G loss: 0.9334\n",
      "[1684/1762] D loss: 1.2042, G loss: 0.9093\n",
      "[1762/1762] D loss: 1.4085, G loss: 0.4876\n",
      "train error: \n",
      " D loss: 1.369279, G loss: 0.580427, D accuracy: 54.6%, cell accuracy: 99.0%, board accuracy: 33.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344081, G loss: 0.594170, D accuracy: 54.4%, cell accuracy: 98.8%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3151, G loss: 0.7305\n",
      "[84/1762] D loss: 1.3330, G loss: 0.6582\n",
      "[164/1762] D loss: 1.2520, G loss: 0.8585\n",
      "[244/1762] D loss: 1.3424, G loss: 0.7333\n",
      "[324/1762] D loss: 1.5122, G loss: 0.9589\n",
      "[404/1762] D loss: 1.2149, G loss: 0.9153\n",
      "[484/1762] D loss: 1.4664, G loss: 0.7391\n",
      "[564/1762] D loss: 1.4336, G loss: 0.7507\n",
      "[644/1762] D loss: 1.2949, G loss: 0.8571\n",
      "[724/1762] D loss: 1.2796, G loss: 0.7634\n",
      "[804/1762] D loss: 1.5033, G loss: 0.9028\n",
      "[884/1762] D loss: 1.2279, G loss: 0.7687\n",
      "[964/1762] D loss: 1.4325, G loss: 0.7220\n",
      "[1044/1762] D loss: 1.4043, G loss: 0.8997\n",
      "[1124/1762] D loss: 1.2867, G loss: 1.0533\n",
      "[1204/1762] D loss: 1.4689, G loss: 0.6246\n",
      "[1284/1762] D loss: 1.4301, G loss: 0.5713\n",
      "[1364/1762] D loss: 1.4265, G loss: 0.9101\n",
      "[1444/1762] D loss: 1.3360, G loss: 0.7131\n",
      "[1524/1762] D loss: 1.5192, G loss: 0.5631\n",
      "[1604/1762] D loss: 1.2594, G loss: 0.7894\n",
      "[1684/1762] D loss: 1.3757, G loss: 0.8484\n",
      "[1762/1762] D loss: 1.6271, G loss: 1.0890\n",
      "train error: \n",
      " D loss: 1.375628, G loss: 0.863472, D accuracy: 55.3%, cell accuracy: 98.9%, board accuracy: 22.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357092, G loss: 0.866217, D accuracy: 56.7%, cell accuracy: 98.8%, board accuracy: 18.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6836\n",
      "[84/1762] D loss: 1.4439, G loss: 0.8183\n",
      "[164/1762] D loss: 1.3177, G loss: 0.6770\n",
      "[244/1762] D loss: 1.2488, G loss: 0.8156\n",
      "[324/1762] D loss: 1.4932, G loss: 0.7067\n",
      "[404/1762] D loss: 1.3272, G loss: 0.6717\n",
      "[484/1762] D loss: 1.4098, G loss: 0.7297\n",
      "[564/1762] D loss: 1.1159, G loss: 0.8297\n",
      "[644/1762] D loss: 1.1782, G loss: 0.7219\n",
      "[724/1762] D loss: 1.3704, G loss: 0.7183\n",
      "[804/1762] D loss: 1.3185, G loss: 0.7688\n",
      "[884/1762] D loss: 1.2927, G loss: 0.8546\n",
      "[964/1762] D loss: 1.3132, G loss: 0.8754\n",
      "[1044/1762] D loss: 1.3459, G loss: 0.6139\n",
      "[1124/1762] D loss: 1.4213, G loss: 0.6424\n",
      "[1204/1762] D loss: 1.4048, G loss: 0.8693\n",
      "[1284/1762] D loss: 1.3495, G loss: 0.6728\n",
      "[1364/1762] D loss: 1.3097, G loss: 0.7535\n",
      "[1444/1762] D loss: 1.2772, G loss: 0.6862\n",
      "[1524/1762] D loss: 1.3603, G loss: 0.8471\n",
      "[1604/1762] D loss: 1.4427, G loss: 0.6378\n",
      "[1684/1762] D loss: 1.3650, G loss: 0.6470\n",
      "[1762/1762] D loss: 1.3617, G loss: 0.6577\n",
      "train error: \n",
      " D loss: 1.350405, G loss: 0.758852, D accuracy: 57.4%, cell accuracy: 98.9%, board accuracy: 25.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330638, G loss: 0.769377, D accuracy: 58.2%, cell accuracy: 98.8%, board accuracy: 20.9% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2644, G loss: 0.7683\n",
      "[84/1762] D loss: 1.3986, G loss: 0.7279\n",
      "[164/1762] D loss: 1.2621, G loss: 0.8317\n",
      "[244/1762] D loss: 1.3857, G loss: 0.6294\n",
      "[324/1762] D loss: 1.4412, G loss: 0.6890\n",
      "[404/1762] D loss: 1.3009, G loss: 0.9282\n",
      "[484/1762] D loss: 1.3038, G loss: 0.7659\n",
      "[564/1762] D loss: 1.4338, G loss: 0.9541\n",
      "[644/1762] D loss: 1.1272, G loss: 0.8568\n",
      "[724/1762] D loss: 1.3175, G loss: 0.7124\n",
      "[804/1762] D loss: 1.3739, G loss: 0.8273\n",
      "[884/1762] D loss: 1.4426, G loss: 1.0136\n",
      "[964/1762] D loss: 1.3519, G loss: 0.7861\n",
      "[1044/1762] D loss: 1.3798, G loss: 0.7735\n",
      "[1124/1762] D loss: 1.3222, G loss: 0.7673\n",
      "[1204/1762] D loss: 1.4550, G loss: 0.6827\n",
      "[1284/1762] D loss: 1.3325, G loss: 0.7024\n",
      "[1364/1762] D loss: 1.2884, G loss: 0.9157\n",
      "[1444/1762] D loss: 1.4246, G loss: 0.6535\n",
      "[1524/1762] D loss: 1.4977, G loss: 0.6057\n",
      "[1604/1762] D loss: 1.3228, G loss: 0.6745\n",
      "[1684/1762] D loss: 1.3286, G loss: 0.6527\n",
      "[1762/1762] D loss: 1.5621, G loss: 0.7978\n",
      "train error: \n",
      " D loss: 1.373851, G loss: 0.701989, D accuracy: 54.4%, cell accuracy: 99.2%, board accuracy: 33.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371315, G loss: 0.699795, D accuracy: 54.4%, cell accuracy: 99.1%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3137, G loss: 0.6791\n",
      "[84/1762] D loss: 1.3436, G loss: 0.7734\n",
      "[164/1762] D loss: 1.4072, G loss: 0.7867\n",
      "[244/1762] D loss: 1.3779, G loss: 0.6754\n",
      "[324/1762] D loss: 1.3644, G loss: 0.6506\n",
      "[404/1762] D loss: 1.3493, G loss: 0.8810\n",
      "[484/1762] D loss: 1.3845, G loss: 0.9117\n",
      "[564/1762] D loss: 1.3616, G loss: 0.8560\n",
      "[644/1762] D loss: 1.3801, G loss: 0.6718\n",
      "[724/1762] D loss: 1.4880, G loss: 0.5383\n",
      "[804/1762] D loss: 1.4088, G loss: 0.5857\n",
      "[884/1762] D loss: 1.4323, G loss: 0.5093\n",
      "[964/1762] D loss: 1.4710, G loss: 0.8267\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.5977\n",
      "[1124/1762] D loss: 1.4620, G loss: 0.6458\n",
      "[1204/1762] D loss: 1.4615, G loss: 0.8517\n",
      "[1284/1762] D loss: 1.4415, G loss: 0.7072\n",
      "[1364/1762] D loss: 1.2770, G loss: 0.6366\n",
      "[1444/1762] D loss: 1.2818, G loss: 0.8548\n",
      "[1524/1762] D loss: 1.4974, G loss: 0.5495\n",
      "[1604/1762] D loss: 1.4459, G loss: 0.7910\n",
      "[1684/1762] D loss: 1.4085, G loss: 0.6473\n",
      "[1762/1762] D loss: 1.4890, G loss: 0.5804\n",
      "train error: \n",
      " D loss: 1.396966, G loss: 0.795685, D accuracy: 52.1%, cell accuracy: 99.3%, board accuracy: 46.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394586, G loss: 0.795052, D accuracy: 51.9%, cell accuracy: 99.3%, board accuracy: 40.7% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3723, G loss: 0.8514\n",
      "[84/1762] D loss: 1.4041, G loss: 0.8764\n",
      "[164/1762] D loss: 1.3765, G loss: 0.9149\n",
      "[244/1762] D loss: 1.4013, G loss: 0.6439\n",
      "[324/1762] D loss: 1.3203, G loss: 0.8792\n",
      "[404/1762] D loss: 1.3748, G loss: 0.7833\n",
      "[484/1762] D loss: 1.3987, G loss: 0.7678\n",
      "[564/1762] D loss: 1.4500, G loss: 0.5746\n",
      "[644/1762] D loss: 1.3976, G loss: 0.6494\n",
      "[724/1762] D loss: 1.4138, G loss: 0.5908\n",
      "[804/1762] D loss: 1.4790, G loss: 0.8202\n",
      "[884/1762] D loss: 1.3838, G loss: 0.6388\n",
      "[964/1762] D loss: 1.4742, G loss: 0.9039\n",
      "[1044/1762] D loss: 1.4157, G loss: 0.5616\n",
      "[1124/1762] D loss: 1.4635, G loss: 0.8066\n",
      "[1204/1762] D loss: 1.4916, G loss: 0.7559\n",
      "[1284/1762] D loss: 1.4099, G loss: 0.6254\n",
      "[1364/1762] D loss: 1.4202, G loss: 0.6568\n",
      "[1444/1762] D loss: 1.4643, G loss: 0.6433\n",
      "[1524/1762] D loss: 1.4180, G loss: 0.7061\n",
      "[1604/1762] D loss: 1.2865, G loss: 0.8286\n",
      "[1684/1762] D loss: 1.3648, G loss: 0.6398\n",
      "[1762/1762] D loss: 1.4425, G loss: 0.8846\n",
      "train error: \n",
      " D loss: 1.378716, G loss: 0.771176, D accuracy: 53.8%, cell accuracy: 99.3%, board accuracy: 44.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373669, G loss: 0.776328, D accuracy: 54.7%, cell accuracy: 99.3%, board accuracy: 40.7% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3068, G loss: 0.6980\n",
      "[84/1762] D loss: 1.3996, G loss: 0.6495\n",
      "[164/1762] D loss: 1.3475, G loss: 0.8619\n",
      "[244/1762] D loss: 1.3226, G loss: 0.8587\n",
      "[324/1762] D loss: 1.3286, G loss: 0.7657\n",
      "[404/1762] D loss: 1.2950, G loss: 0.8178\n",
      "[484/1762] D loss: 1.4193, G loss: 0.5768\n",
      "[564/1762] D loss: 1.4247, G loss: 0.6422\n",
      "[644/1762] D loss: 1.4261, G loss: 0.5767\n",
      "[724/1762] D loss: 1.3880, G loss: 0.8056\n",
      "[804/1762] D loss: 1.3590, G loss: 0.7123\n",
      "[884/1762] D loss: 1.3497, G loss: 0.8482\n",
      "[964/1762] D loss: 1.2640, G loss: 0.7422\n",
      "[1044/1762] D loss: 1.3785, G loss: 0.7501\n",
      "[1124/1762] D loss: 1.4559, G loss: 0.5484\n",
      "[1204/1762] D loss: 1.2944, G loss: 0.6538\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.7339\n",
      "[1364/1762] D loss: 1.4083, G loss: 0.5376\n",
      "[1444/1762] D loss: 1.3667, G loss: 0.6758\n",
      "[1524/1762] D loss: 1.3254, G loss: 0.7104\n",
      "[1604/1762] D loss: 1.3743, G loss: 0.7524\n",
      "[1684/1762] D loss: 1.4338, G loss: 0.5420\n",
      "[1762/1762] D loss: 1.3952, G loss: 0.6201\n",
      "train error: \n",
      " D loss: 1.376438, G loss: 0.621421, D accuracy: 53.6%, cell accuracy: 99.3%, board accuracy: 40.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368763, G loss: 0.625931, D accuracy: 53.6%, cell accuracy: 99.2%, board accuracy: 34.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3064, G loss: 0.7243\n",
      "[84/1762] D loss: 1.3784, G loss: 0.8009\n",
      "[164/1762] D loss: 1.4356, G loss: 0.6244\n",
      "[244/1762] D loss: 1.3948, G loss: 0.8125\n",
      "[324/1762] D loss: 1.3080, G loss: 0.7901\n",
      "[404/1762] D loss: 1.4039, G loss: 0.7789\n",
      "[484/1762] D loss: 1.3627, G loss: 0.6495\n",
      "[564/1762] D loss: 1.3623, G loss: 0.5907\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6017\n",
      "[724/1762] D loss: 1.3556, G loss: 0.7006\n",
      "[804/1762] D loss: 1.3909, G loss: 0.6577\n",
      "[884/1762] D loss: 1.3980, G loss: 0.7670\n",
      "[964/1762] D loss: 1.4478, G loss: 0.9592\n",
      "[1044/1762] D loss: 1.3956, G loss: 0.6842\n",
      "[1124/1762] D loss: 1.4570, G loss: 0.5773\n",
      "[1204/1762] D loss: 1.3966, G loss: 0.8115\n",
      "[1284/1762] D loss: 1.4517, G loss: 0.9211\n",
      "[1364/1762] D loss: 1.2793, G loss: 0.6602\n",
      "[1444/1762] D loss: 1.4312, G loss: 0.7525\n",
      "[1524/1762] D loss: 1.4422, G loss: 0.6973\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.7018\n",
      "[1684/1762] D loss: 1.4716, G loss: 0.6262\n",
      "[1762/1762] D loss: 1.4213, G loss: 0.6175\n",
      "train error: \n",
      " D loss: 1.392302, G loss: 0.765087, D accuracy: 52.4%, cell accuracy: 99.2%, board accuracy: 35.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386523, G loss: 0.769993, D accuracy: 53.1%, cell accuracy: 99.2%, board accuracy: 32.7% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.8527\n",
      "[84/1762] D loss: 1.3904, G loss: 0.7573\n",
      "[164/1762] D loss: 1.3505, G loss: 0.6927\n",
      "[244/1762] D loss: 1.4135, G loss: 0.6914\n",
      "[324/1762] D loss: 1.4114, G loss: 0.7059\n",
      "[404/1762] D loss: 1.3823, G loss: 0.6986\n",
      "[484/1762] D loss: 1.4106, G loss: 0.7845\n",
      "[564/1762] D loss: 1.4851, G loss: 0.5494\n",
      "[644/1762] D loss: 1.3742, G loss: 0.6644\n",
      "[724/1762] D loss: 1.3765, G loss: 0.7134\n",
      "[804/1762] D loss: 1.3959, G loss: 0.6861\n",
      "[884/1762] D loss: 1.3987, G loss: 0.7222\n",
      "[964/1762] D loss: 1.3828, G loss: 0.7181\n",
      "[1044/1762] D loss: 1.4270, G loss: 0.6798\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.6715\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.6350\n",
      "[1284/1762] D loss: 1.3247, G loss: 0.7420\n",
      "[1364/1762] D loss: 1.4465, G loss: 0.7159\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.6412\n",
      "[1524/1762] D loss: 1.4361, G loss: 0.5856\n",
      "[1604/1762] D loss: 1.3752, G loss: 0.7302\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.7071\n",
      "[1762/1762] D loss: 1.4028, G loss: 0.8723\n",
      "train error: \n",
      " D loss: 1.389844, G loss: 0.851524, D accuracy: 52.8%, cell accuracy: 99.3%, board accuracy: 39.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381486, G loss: 0.854538, D accuracy: 52.6%, cell accuracy: 99.2%, board accuracy: 35.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3698, G loss: 0.8028\n",
      "[84/1762] D loss: 1.3763, G loss: 0.7245\n",
      "[164/1762] D loss: 1.3874, G loss: 0.8262\n",
      "[244/1762] D loss: 1.4597, G loss: 0.6984\n",
      "[324/1762] D loss: 1.4196, G loss: 0.8888\n",
      "[404/1762] D loss: 1.3900, G loss: 0.7221\n",
      "[484/1762] D loss: 1.4156, G loss: 0.7379\n",
      "[564/1762] D loss: 1.4125, G loss: 0.6871\n",
      "[644/1762] D loss: 1.4120, G loss: 0.7023\n",
      "[724/1762] D loss: 1.3087, G loss: 0.6303\n",
      "[804/1762] D loss: 1.3801, G loss: 0.7775\n",
      "[884/1762] D loss: 1.3765, G loss: 0.7481\n",
      "[964/1762] D loss: 1.3536, G loss: 0.8054\n",
      "[1044/1762] D loss: 1.4211, G loss: 0.7839\n",
      "[1124/1762] D loss: 1.2663, G loss: 0.7740\n",
      "[1204/1762] D loss: 1.3394, G loss: 0.6347\n",
      "[1284/1762] D loss: 1.3905, G loss: 0.6284\n",
      "[1364/1762] D loss: 1.3936, G loss: 0.6083\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.6624\n",
      "[1524/1762] D loss: 1.3536, G loss: 0.7064\n",
      "[1604/1762] D loss: 1.3816, G loss: 0.6735\n",
      "[1684/1762] D loss: 1.3231, G loss: 0.7096\n",
      "[1762/1762] D loss: 1.3981, G loss: 0.6298\n",
      "train error: \n",
      " D loss: 1.377035, G loss: 0.719496, D accuracy: 52.9%, cell accuracy: 99.4%, board accuracy: 49.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371449, G loss: 0.720564, D accuracy: 54.2%, cell accuracy: 99.4%, board accuracy: 44.3% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3524, G loss: 0.6932\n",
      "[84/1762] D loss: 1.4088, G loss: 0.5670\n",
      "[164/1762] D loss: 1.4095, G loss: 0.6683\n",
      "[244/1762] D loss: 1.3549, G loss: 0.7175\n",
      "[324/1762] D loss: 1.3148, G loss: 0.7117\n",
      "[404/1762] D loss: 1.3331, G loss: 0.6013\n",
      "[484/1762] D loss: 1.4262, G loss: 0.6314\n",
      "[564/1762] D loss: 1.3965, G loss: 0.7734\n",
      "[644/1762] D loss: 1.4257, G loss: 0.7976\n",
      "[724/1762] D loss: 1.4319, G loss: 0.6404\n",
      "[804/1762] D loss: 1.3779, G loss: 0.7260\n",
      "[884/1762] D loss: 1.3189, G loss: 0.7751\n",
      "[964/1762] D loss: 1.3782, G loss: 0.8207\n",
      "[1044/1762] D loss: 1.3237, G loss: 0.7086\n",
      "[1124/1762] D loss: 1.3998, G loss: 0.7114\n",
      "[1204/1762] D loss: 1.3939, G loss: 0.7484\n",
      "[1284/1762] D loss: 1.3949, G loss: 0.6729\n",
      "[1364/1762] D loss: 1.3619, G loss: 0.6803\n",
      "[1444/1762] D loss: 1.3732, G loss: 0.5544\n",
      "[1524/1762] D loss: 1.4123, G loss: 0.7239\n",
      "[1604/1762] D loss: 1.4024, G loss: 0.6507\n",
      "[1684/1762] D loss: 1.4128, G loss: 0.6383\n",
      "[1762/1762] D loss: 1.2935, G loss: 0.8313\n",
      "train error: \n",
      " D loss: 1.381728, G loss: 0.810851, D accuracy: 53.0%, cell accuracy: 99.5%, board accuracy: 51.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379283, G loss: 0.810187, D accuracy: 52.8%, cell accuracy: 99.4%, board accuracy: 47.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.8473\n",
      "[84/1762] D loss: 1.4245, G loss: 0.7425\n",
      "[164/1762] D loss: 1.2545, G loss: 0.8255\n",
      "[244/1762] D loss: 1.2846, G loss: 0.7164\n",
      "[324/1762] D loss: 1.3856, G loss: 0.7996\n",
      "[404/1762] D loss: 1.4004, G loss: 0.7833\n",
      "[484/1762] D loss: 1.3923, G loss: 0.6129\n",
      "[564/1762] D loss: 1.3301, G loss: 0.6741\n",
      "[644/1762] D loss: 1.3860, G loss: 0.7784\n",
      "[724/1762] D loss: 1.3449, G loss: 0.6719\n",
      "[804/1762] D loss: 1.3471, G loss: 0.7949\n",
      "[884/1762] D loss: 1.3937, G loss: 0.6570\n",
      "[964/1762] D loss: 1.3070, G loss: 0.6762\n",
      "[1044/1762] D loss: 1.3977, G loss: 0.5868\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.6169\n",
      "[1204/1762] D loss: 1.4303, G loss: 0.5462\n",
      "[1284/1762] D loss: 1.4461, G loss: 0.5796\n",
      "[1364/1762] D loss: 1.4142, G loss: 0.7527\n",
      "[1444/1762] D loss: 1.4034, G loss: 0.8097\n",
      "[1524/1762] D loss: 1.3792, G loss: 0.8232\n",
      "[1604/1762] D loss: 1.3425, G loss: 0.9093\n",
      "[1684/1762] D loss: 1.3206, G loss: 0.7128\n",
      "[1762/1762] D loss: 1.2801, G loss: 0.7069\n",
      "train error: \n",
      " D loss: 1.392927, G loss: 0.584847, D accuracy: 52.4%, cell accuracy: 99.6%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390370, G loss: 0.584891, D accuracy: 52.5%, cell accuracy: 99.5%, board accuracy: 56.6% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.5977\n",
      "[84/1762] D loss: 1.3928, G loss: 0.6613\n",
      "[164/1762] D loss: 1.3944, G loss: 0.7633\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7294\n",
      "[324/1762] D loss: 1.2991, G loss: 0.7266\n",
      "[404/1762] D loss: 1.3458, G loss: 0.8528\n",
      "[484/1762] D loss: 1.4063, G loss: 0.7399\n",
      "[564/1762] D loss: 1.3491, G loss: 0.7923\n",
      "[644/1762] D loss: 1.3458, G loss: 0.8168\n",
      "[724/1762] D loss: 1.4078, G loss: 0.8534\n",
      "[804/1762] D loss: 1.2988, G loss: 0.7016\n",
      "[884/1762] D loss: 1.3925, G loss: 0.7374\n",
      "[964/1762] D loss: 1.4116, G loss: 0.6600\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7571\n",
      "[1124/1762] D loss: 1.4371, G loss: 0.6717\n",
      "[1204/1762] D loss: 1.3992, G loss: 0.5672\n",
      "[1284/1762] D loss: 1.4129, G loss: 0.6043\n",
      "[1364/1762] D loss: 1.3920, G loss: 0.6050\n",
      "[1444/1762] D loss: 1.4006, G loss: 0.6466\n",
      "[1524/1762] D loss: 1.4220, G loss: 0.7812\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.7036\n",
      "[1684/1762] D loss: 1.4300, G loss: 0.6020\n",
      "[1762/1762] D loss: 1.3751, G loss: 0.8354\n",
      "train error: \n",
      " D loss: 1.385496, G loss: 0.828930, D accuracy: 52.2%, cell accuracy: 99.6%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377691, G loss: 0.832277, D accuracy: 52.6%, cell accuracy: 99.5%, board accuracy: 52.3% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3055, G loss: 0.8765\n",
      "[84/1762] D loss: 1.4152, G loss: 0.8278\n",
      "[164/1762] D loss: 1.3793, G loss: 0.6798\n",
      "[244/1762] D loss: 1.3915, G loss: 0.7807\n",
      "[324/1762] D loss: 1.4014, G loss: 0.8009\n",
      "[404/1762] D loss: 1.4034, G loss: 0.6945\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6755\n",
      "[564/1762] D loss: 1.3284, G loss: 0.5882\n",
      "[644/1762] D loss: 1.3570, G loss: 0.8128\n",
      "[724/1762] D loss: 1.2992, G loss: 0.8447\n",
      "[804/1762] D loss: 1.3119, G loss: 0.7172\n",
      "[884/1762] D loss: 1.3897, G loss: 0.7375\n",
      "[964/1762] D loss: 1.3948, G loss: 0.8576\n",
      "[1044/1762] D loss: 1.3429, G loss: 0.6730\n",
      "[1124/1762] D loss: 1.3239, G loss: 0.7473\n",
      "[1204/1762] D loss: 1.4266, G loss: 0.7343\n",
      "[1284/1762] D loss: 1.3894, G loss: 0.7450\n",
      "[1364/1762] D loss: 1.2441, G loss: 0.7838\n",
      "[1444/1762] D loss: 1.3106, G loss: 0.7084\n",
      "[1524/1762] D loss: 1.3724, G loss: 0.7286\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7210\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.6987\n",
      "[1762/1762] D loss: 1.4229, G loss: 0.5638\n",
      "train error: \n",
      " D loss: 1.370429, G loss: 0.731764, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 65.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365781, G loss: 0.732648, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 62.7% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3177, G loss: 0.8657\n",
      "[84/1762] D loss: 1.4120, G loss: 0.8417\n",
      "[164/1762] D loss: 1.3297, G loss: 0.7732\n",
      "[244/1762] D loss: 1.3362, G loss: 0.6001\n",
      "[324/1762] D loss: 1.3288, G loss: 0.6829\n",
      "[404/1762] D loss: 1.3583, G loss: 0.7787\n",
      "[484/1762] D loss: 1.3832, G loss: 0.7184\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7200\n",
      "[644/1762] D loss: 1.4044, G loss: 0.7626\n",
      "[724/1762] D loss: 1.3656, G loss: 0.7571\n",
      "[804/1762] D loss: 1.4289, G loss: 0.6442\n",
      "[884/1762] D loss: 1.3852, G loss: 0.9313\n",
      "[964/1762] D loss: 1.4133, G loss: 0.7994\n",
      "[1044/1762] D loss: 1.4169, G loss: 0.7390\n",
      "[1124/1762] D loss: 1.3705, G loss: 0.7096\n",
      "[1204/1762] D loss: 1.4812, G loss: 0.9448\n",
      "[1284/1762] D loss: 1.3508, G loss: 0.7045\n",
      "[1364/1762] D loss: 1.4041, G loss: 0.8830\n",
      "[1444/1762] D loss: 1.3326, G loss: 0.9041\n",
      "[1524/1762] D loss: 1.4561, G loss: 0.5997\n",
      "[1604/1762] D loss: 1.3666, G loss: 0.7742\n",
      "[1684/1762] D loss: 1.4103, G loss: 0.7246\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.7597\n",
      "train error: \n",
      " D loss: 1.372758, G loss: 0.741688, D accuracy: 53.2%, cell accuracy: 99.6%, board accuracy: 61.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367468, G loss: 0.742839, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 57.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921, G loss: 0.6944\n",
      "[84/1762] D loss: 1.3007, G loss: 0.7708\n",
      "[164/1762] D loss: 1.2805, G loss: 0.8416\n",
      "[244/1762] D loss: 1.2390, G loss: 0.9121\n",
      "[324/1762] D loss: 1.1885, G loss: 0.8524\n",
      "[404/1762] D loss: 1.2354, G loss: 0.7109\n",
      "[484/1762] D loss: 1.3901, G loss: 0.6505\n",
      "[564/1762] D loss: 1.3814, G loss: 0.7695\n",
      "[644/1762] D loss: 1.3257, G loss: 0.7398\n",
      "[724/1762] D loss: 1.2245, G loss: 0.7808\n",
      "[804/1762] D loss: 1.3981, G loss: 0.7705\n",
      "[884/1762] D loss: 1.3945, G loss: 0.6721\n",
      "[964/1762] D loss: 1.4028, G loss: 0.5512\n",
      "[1044/1762] D loss: 1.3198, G loss: 0.6399\n",
      "[1124/1762] D loss: 1.4492, G loss: 0.5836\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.7862\n",
      "[1284/1762] D loss: 1.3061, G loss: 0.8381\n",
      "[1364/1762] D loss: 1.4100, G loss: 0.6646\n",
      "[1444/1762] D loss: 1.3935, G loss: 0.7650\n",
      "[1524/1762] D loss: 1.4350, G loss: 0.8377\n",
      "[1604/1762] D loss: 1.3695, G loss: 0.7027\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.5617\n",
      "[1762/1762] D loss: 1.2881, G loss: 0.7574\n",
      "train error: \n",
      " D loss: 1.365681, G loss: 0.695056, D accuracy: 53.7%, cell accuracy: 99.6%, board accuracy: 65.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362004, G loss: 0.693987, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 63.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4063, G loss: 0.6244\n",
      "[84/1762] D loss: 1.3945, G loss: 0.7593\n",
      "[164/1762] D loss: 1.3517, G loss: 0.7164\n",
      "[244/1762] D loss: 1.3982, G loss: 0.6500\n",
      "[324/1762] D loss: 1.3992, G loss: 0.7021\n",
      "[404/1762] D loss: 1.3970, G loss: 0.7426\n",
      "[484/1762] D loss: 1.3029, G loss: 0.7570\n",
      "[564/1762] D loss: 1.3980, G loss: 0.7832\n",
      "[644/1762] D loss: 1.3987, G loss: 0.6734\n",
      "[724/1762] D loss: 1.4153, G loss: 0.6110\n",
      "[804/1762] D loss: 1.3729, G loss: 0.8021\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6649\n",
      "[964/1762] D loss: 1.4087, G loss: 0.5917\n",
      "[1044/1762] D loss: 1.3802, G loss: 0.7107\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.7443\n",
      "[1204/1762] D loss: 1.3334, G loss: 0.6837\n",
      "[1284/1762] D loss: 1.4246, G loss: 0.7755\n",
      "[1364/1762] D loss: 1.4041, G loss: 0.7699\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.6504\n",
      "[1524/1762] D loss: 1.3023, G loss: 0.7449\n",
      "[1604/1762] D loss: 1.4235, G loss: 0.7751\n",
      "[1684/1762] D loss: 1.4598, G loss: 0.6869\n",
      "[1762/1762] D loss: 1.4271, G loss: 0.5661\n",
      "train error: \n",
      " D loss: 1.371891, G loss: 0.657420, D accuracy: 53.4%, cell accuracy: 99.6%, board accuracy: 63.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368171, G loss: 0.656741, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 62.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4368, G loss: 0.6408\n",
      "[84/1762] D loss: 1.3910, G loss: 0.8021\n",
      "[164/1762] D loss: 1.4117, G loss: 0.8084\n",
      "[244/1762] D loss: 1.3891, G loss: 0.6748\n",
      "[324/1762] D loss: 1.3971, G loss: 0.7240\n",
      "[404/1762] D loss: 1.3838, G loss: 0.6782\n",
      "[484/1762] D loss: 1.3923, G loss: 0.7591\n",
      "[564/1762] D loss: 1.3650, G loss: 0.7354\n",
      "[644/1762] D loss: 1.3834, G loss: 0.7289\n",
      "[724/1762] D loss: 1.3652, G loss: 0.6889\n",
      "[804/1762] D loss: 1.4055, G loss: 0.6548\n",
      "[884/1762] D loss: 1.2925, G loss: 0.7868\n",
      "[964/1762] D loss: 1.4127, G loss: 0.5516\n",
      "[1044/1762] D loss: 1.4136, G loss: 0.6200\n",
      "[1124/1762] D loss: 1.4189, G loss: 0.5714\n",
      "[1204/1762] D loss: 1.4338, G loss: 0.7553\n",
      "[1284/1762] D loss: 1.4024, G loss: 0.8597\n",
      "[1364/1762] D loss: 1.3723, G loss: 0.7383\n",
      "[1444/1762] D loss: 1.4066, G loss: 0.7802\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.7558\n",
      "[1604/1762] D loss: 1.3940, G loss: 0.6633\n",
      "[1684/1762] D loss: 1.3362, G loss: 0.7296\n",
      "[1762/1762] D loss: 1.2232, G loss: 0.9448\n",
      "train error: \n",
      " D loss: 1.372154, G loss: 0.792539, D accuracy: 53.0%, cell accuracy: 99.6%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364974, G loss: 0.795723, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.7407\n",
      "[84/1762] D loss: 1.2983, G loss: 0.7646\n",
      "[164/1762] D loss: 1.3917, G loss: 0.6660\n",
      "[244/1762] D loss: 1.3715, G loss: 0.7046\n",
      "[324/1762] D loss: 1.3754, G loss: 0.6721\n",
      "[404/1762] D loss: 1.3772, G loss: 0.6957\n",
      "[484/1762] D loss: 1.4627, G loss: 0.6950\n",
      "[564/1762] D loss: 1.3927, G loss: 0.7778\n",
      "[644/1762] D loss: 1.4015, G loss: 0.7196\n",
      "[724/1762] D loss: 1.2723, G loss: 0.7430\n",
      "[804/1762] D loss: 1.3941, G loss: 0.7181\n",
      "[884/1762] D loss: 1.2468, G loss: 0.7721\n",
      "[964/1762] D loss: 1.4100, G loss: 0.6476\n",
      "[1044/1762] D loss: 1.4059, G loss: 0.6039\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.6760\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.6242\n",
      "[1284/1762] D loss: 1.4070, G loss: 0.7176\n",
      "[1364/1762] D loss: 1.3843, G loss: 0.6643\n",
      "[1444/1762] D loss: 1.3715, G loss: 0.6913\n",
      "[1524/1762] D loss: 1.3847, G loss: 0.7626\n",
      "[1604/1762] D loss: 1.4138, G loss: 0.5864\n",
      "[1684/1762] D loss: 1.1658, G loss: 0.8314\n",
      "[1762/1762] D loss: 1.3843, G loss: 0.6793\n",
      "train error: \n",
      " D loss: 1.363629, G loss: 0.730078, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 66.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357367, G loss: 0.730554, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 63.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3963, G loss: 0.6988\n",
      "[84/1762] D loss: 1.3974, G loss: 0.7564\n",
      "[164/1762] D loss: 1.3929, G loss: 0.6860\n",
      "[244/1762] D loss: 1.3888, G loss: 0.6874\n",
      "[324/1762] D loss: 1.3109, G loss: 0.6605\n",
      "[404/1762] D loss: 1.4398, G loss: 0.5819\n",
      "[484/1762] D loss: 1.3053, G loss: 0.9221\n",
      "[564/1762] D loss: 1.3846, G loss: 0.6679\n",
      "[644/1762] D loss: 1.3816, G loss: 0.6750\n",
      "[724/1762] D loss: 1.3856, G loss: 0.7221\n",
      "[804/1762] D loss: 1.4190, G loss: 0.7743\n",
      "[884/1762] D loss: 1.4839, G loss: 0.8380\n",
      "[964/1762] D loss: 1.3523, G loss: 0.6975\n",
      "[1044/1762] D loss: 1.3777, G loss: 0.6823\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6872\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.8263\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.6847\n",
      "[1364/1762] D loss: 1.4097, G loss: 0.6878\n",
      "[1444/1762] D loss: 1.4003, G loss: 0.7743\n",
      "[1524/1762] D loss: 1.4113, G loss: 0.6695\n",
      "[1604/1762] D loss: 1.4315, G loss: 0.8271\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.6458\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7688\n",
      "train error: \n",
      " D loss: 1.366371, G loss: 0.758967, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 60.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361183, G loss: 0.757949, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4054, G loss: 0.7725\n",
      "[84/1762] D loss: 1.4106, G loss: 0.7143\n",
      "[164/1762] D loss: 1.3880, G loss: 0.6974\n",
      "[244/1762] D loss: 1.3940, G loss: 0.7106\n",
      "[324/1762] D loss: 1.3989, G loss: 0.6306\n",
      "[404/1762] D loss: 1.3971, G loss: 0.6227\n",
      "[484/1762] D loss: 1.3080, G loss: 0.8457\n",
      "[564/1762] D loss: 1.4502, G loss: 0.8391\n",
      "[644/1762] D loss: 1.3959, G loss: 0.6240\n",
      "[724/1762] D loss: 1.4035, G loss: 0.6904\n",
      "[804/1762] D loss: 1.2821, G loss: 0.7738\n",
      "[884/1762] D loss: 1.4019, G loss: 0.7090\n",
      "[964/1762] D loss: 1.3916, G loss: 0.7197\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6638\n",
      "[1124/1762] D loss: 1.2618, G loss: 0.7945\n",
      "[1204/1762] D loss: 1.4012, G loss: 0.6819\n",
      "[1284/1762] D loss: 1.4288, G loss: 0.8868\n",
      "[1364/1762] D loss: 1.4057, G loss: 0.6358\n",
      "[1444/1762] D loss: 1.2721, G loss: 0.6903\n",
      "[1524/1762] D loss: 1.3822, G loss: 0.6841\n",
      "[1604/1762] D loss: 1.3927, G loss: 0.7548\n",
      "[1684/1762] D loss: 1.4136, G loss: 0.7669\n",
      "[1762/1762] D loss: 1.3924, G loss: 0.6527\n",
      "train error: \n",
      " D loss: 1.361774, G loss: 0.690437, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353510, G loss: 0.694273, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3912, G loss: 0.6826\n",
      "[84/1762] D loss: 1.4038, G loss: 0.6967\n",
      "[164/1762] D loss: 1.3900, G loss: 0.6871\n",
      "[244/1762] D loss: 1.3854, G loss: 0.8190\n",
      "[324/1762] D loss: 1.2859, G loss: 0.9775\n",
      "[404/1762] D loss: 1.2712, G loss: 0.6920\n",
      "[484/1762] D loss: 1.2802, G loss: 0.7575\n",
      "[564/1762] D loss: 1.4243, G loss: 0.8198\n",
      "[644/1762] D loss: 1.3915, G loss: 0.6500\n",
      "[724/1762] D loss: 1.1975, G loss: 0.7278\n",
      "[804/1762] D loss: 1.4045, G loss: 0.6513\n",
      "[884/1762] D loss: 1.3713, G loss: 0.7819\n",
      "[964/1762] D loss: 1.3893, G loss: 0.6919\n",
      "[1044/1762] D loss: 1.1551, G loss: 0.7973\n",
      "[1124/1762] D loss: 1.2630, G loss: 0.8504\n",
      "[1204/1762] D loss: 1.2454, G loss: 0.7069\n",
      "[1284/1762] D loss: 1.4136, G loss: 0.6038\n",
      "[1364/1762] D loss: 1.2643, G loss: 0.7021\n",
      "[1444/1762] D loss: 1.3793, G loss: 0.7261\n",
      "[1524/1762] D loss: 1.3052, G loss: 0.7183\n",
      "[1604/1762] D loss: 1.4020, G loss: 0.8090\n",
      "[1684/1762] D loss: 1.3739, G loss: 0.8683\n",
      "[1762/1762] D loss: 1.4050, G loss: 0.7602\n",
      "train error: \n",
      " D loss: 1.362555, G loss: 0.797953, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 64.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352585, G loss: 0.803468, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 59.8% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2597, G loss: 0.7589\n",
      "[84/1762] D loss: 1.2473, G loss: 0.8227\n",
      "[164/1762] D loss: 1.3966, G loss: 0.6370\n",
      "[244/1762] D loss: 1.3829, G loss: 0.7163\n",
      "[324/1762] D loss: 1.4018, G loss: 0.8019\n",
      "[404/1762] D loss: 1.3584, G loss: 0.7076\n",
      "[484/1762] D loss: 1.3841, G loss: 0.7696\n",
      "[564/1762] D loss: 1.3137, G loss: 0.7399\n",
      "[644/1762] D loss: 1.3935, G loss: 0.7385\n",
      "[724/1762] D loss: 1.4198, G loss: 0.7990\n",
      "[804/1762] D loss: 1.4328, G loss: 0.9390\n",
      "[884/1762] D loss: 1.3931, G loss: 0.7840\n",
      "[964/1762] D loss: 1.3918, G loss: 0.7047\n",
      "[1044/1762] D loss: 1.2896, G loss: 0.7138\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6803\n",
      "[1204/1762] D loss: 1.3980, G loss: 0.6272\n",
      "[1284/1762] D loss: 1.2775, G loss: 0.7147\n",
      "[1364/1762] D loss: 1.3848, G loss: 0.7282\n",
      "[1444/1762] D loss: 1.3271, G loss: 0.7506\n",
      "[1524/1762] D loss: 1.4071, G loss: 0.9656\n",
      "[1604/1762] D loss: 1.3736, G loss: 0.7571\n",
      "[1684/1762] D loss: 1.4226, G loss: 0.9166\n",
      "[1762/1762] D loss: 1.3988, G loss: 0.7441\n",
      "train error: \n",
      " D loss: 1.361664, G loss: 0.828426, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354515, G loss: 0.825723, D accuracy: 55.0%, cell accuracy: 99.5%, board accuracy: 55.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3715, G loss: 0.7411\n",
      "[84/1762] D loss: 1.3794, G loss: 0.7776\n",
      "[164/1762] D loss: 1.3790, G loss: 0.7111\n",
      "[244/1762] D loss: 1.4017, G loss: 0.6302\n",
      "[324/1762] D loss: 1.3828, G loss: 0.6382\n",
      "[404/1762] D loss: 1.4410, G loss: 0.5025\n",
      "[484/1762] D loss: 1.4073, G loss: 0.5421\n",
      "[564/1762] D loss: 1.2076, G loss: 0.7633\n",
      "[644/1762] D loss: 1.3963, G loss: 0.6961\n",
      "[724/1762] D loss: 1.4107, G loss: 0.7989\n",
      "[804/1762] D loss: 1.4304, G loss: 0.9034\n",
      "[884/1762] D loss: 1.4072, G loss: 0.8242\n",
      "[964/1762] D loss: 1.2952, G loss: 0.8025\n",
      "[1044/1762] D loss: 1.2433, G loss: 0.8419\n",
      "[1124/1762] D loss: 1.4091, G loss: 0.8287\n",
      "[1204/1762] D loss: 1.3664, G loss: 0.8216\n",
      "[1284/1762] D loss: 1.3948, G loss: 0.7287\n",
      "[1364/1762] D loss: 1.3962, G loss: 0.8069\n",
      "[1444/1762] D loss: 1.3024, G loss: 0.8525\n",
      "[1524/1762] D loss: 1.3931, G loss: 0.7589\n",
      "[1604/1762] D loss: 1.1095, G loss: 0.8396\n",
      "[1684/1762] D loss: 1.4083, G loss: 0.6633\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6719\n",
      "train error: \n",
      " D loss: 1.359787, G loss: 0.663961, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 68.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351690, G loss: 0.665508, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4106, G loss: 0.6793\n",
      "[84/1762] D loss: 1.2553, G loss: 0.7413\n",
      "[164/1762] D loss: 1.3894, G loss: 0.6118\n",
      "[244/1762] D loss: 1.2393, G loss: 0.7860\n",
      "[324/1762] D loss: 1.3893, G loss: 0.6715\n",
      "[404/1762] D loss: 1.4086, G loss: 0.6011\n",
      "[484/1762] D loss: 1.4191, G loss: 0.5779\n",
      "[564/1762] D loss: 1.4168, G loss: 0.6141\n",
      "[644/1762] D loss: 1.3927, G loss: 0.6312\n",
      "[724/1762] D loss: 1.4055, G loss: 0.7466\n",
      "[804/1762] D loss: 1.4006, G loss: 0.6046\n",
      "[884/1762] D loss: 1.4401, G loss: 0.5435\n",
      "[964/1762] D loss: 1.2972, G loss: 0.6959\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6862\n",
      "[1124/1762] D loss: 1.2532, G loss: 0.7558\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.7872\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.7089\n",
      "[1364/1762] D loss: 1.4347, G loss: 0.5592\n",
      "[1444/1762] D loss: 1.3917, G loss: 0.6310\n",
      "[1524/1762] D loss: 1.2455, G loss: 0.8232\n",
      "[1604/1762] D loss: 1.4003, G loss: 0.7341\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6329\n",
      "[1762/1762] D loss: 1.0858, G loss: 0.8306\n",
      "train error: \n",
      " D loss: 1.354402, G loss: 0.713860, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346620, G loss: 0.712869, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 66.6% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4003, G loss: 0.6399\n",
      "[84/1762] D loss: 1.3918, G loss: 0.6432\n",
      "[164/1762] D loss: 1.2434, G loss: 0.7839\n",
      "[244/1762] D loss: 1.2381, G loss: 0.9385\n",
      "[324/1762] D loss: 1.3844, G loss: 0.7532\n",
      "[404/1762] D loss: 1.3789, G loss: 0.7443\n",
      "[484/1762] D loss: 1.1419, G loss: 1.0512\n",
      "[564/1762] D loss: 1.3979, G loss: 0.6997\n",
      "[644/1762] D loss: 1.3846, G loss: 0.7987\n",
      "[724/1762] D loss: 1.4028, G loss: 0.6726\n",
      "[804/1762] D loss: 1.3812, G loss: 0.6898\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7080\n",
      "[964/1762] D loss: 1.3941, G loss: 0.7480\n",
      "[1044/1762] D loss: 1.3634, G loss: 0.6972\n",
      "[1124/1762] D loss: 1.3959, G loss: 0.6922\n",
      "[1204/1762] D loss: 1.3892, G loss: 0.6620\n",
      "[1284/1762] D loss: 1.1279, G loss: 0.7818\n",
      "[1364/1762] D loss: 1.3735, G loss: 0.7447\n",
      "[1444/1762] D loss: 1.4019, G loss: 0.6319\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.6274\n",
      "[1604/1762] D loss: 1.3757, G loss: 0.6942\n",
      "[1684/1762] D loss: 1.4019, G loss: 0.6446\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6714\n",
      "train error: \n",
      " D loss: 1.353303, G loss: 0.679693, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 64.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344632, G loss: 0.683422, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 61.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3605, G loss: 0.7828\n",
      "[84/1762] D loss: 1.3992, G loss: 0.6212\n",
      "[164/1762] D loss: 1.3884, G loss: 0.6760\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7161\n",
      "[324/1762] D loss: 1.4054, G loss: 0.7200\n",
      "[404/1762] D loss: 1.3892, G loss: 0.7228\n",
      "[484/1762] D loss: 1.4245, G loss: 0.6031\n",
      "[564/1762] D loss: 1.4114, G loss: 0.6716\n",
      "[644/1762] D loss: 1.4126, G loss: 0.5493\n",
      "[724/1762] D loss: 1.3986, G loss: 0.7000\n",
      "[804/1762] D loss: 1.2475, G loss: 0.8036\n",
      "[884/1762] D loss: 1.4072, G loss: 0.6843\n",
      "[964/1762] D loss: 1.3986, G loss: 0.7059\n",
      "[1044/1762] D loss: 1.3964, G loss: 0.8122\n",
      "[1124/1762] D loss: 1.3996, G loss: 0.7772\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.7151\n",
      "[1284/1762] D loss: 1.3948, G loss: 0.6835\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7342\n",
      "[1444/1762] D loss: 1.4186, G loss: 0.6127\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.7634\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.7694\n",
      "[1684/1762] D loss: 1.4140, G loss: 0.8431\n",
      "[1762/1762] D loss: 1.3598, G loss: 0.8538\n",
      "train error: \n",
      " D loss: 1.354479, G loss: 0.674645, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 70.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345874, G loss: 0.678317, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 68.2% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4028, G loss: 0.6276\n",
      "[84/1762] D loss: 1.3886, G loss: 0.7185\n",
      "[164/1762] D loss: 1.3923, G loss: 0.6536\n",
      "[244/1762] D loss: 1.4101, G loss: 0.7009\n",
      "[324/1762] D loss: 1.3956, G loss: 0.6758\n",
      "[404/1762] D loss: 1.3962, G loss: 0.5936\n",
      "[484/1762] D loss: 1.4048, G loss: 0.7105\n",
      "[564/1762] D loss: 1.3968, G loss: 0.7181\n",
      "[644/1762] D loss: 1.2466, G loss: 0.7552\n",
      "[724/1762] D loss: 1.4068, G loss: 0.7428\n",
      "[804/1762] D loss: 1.1945, G loss: 0.8162\n",
      "[884/1762] D loss: 1.0954, G loss: 0.7079\n",
      "[964/1762] D loss: 1.3953, G loss: 0.5871\n",
      "[1044/1762] D loss: 1.4191, G loss: 0.7082\n",
      "[1124/1762] D loss: 1.3890, G loss: 0.7713\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6639\n",
      "[1284/1762] D loss: 1.3787, G loss: 0.8274\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6010\n",
      "[1444/1762] D loss: 1.3925, G loss: 0.5988\n",
      "[1524/1762] D loss: 1.2258, G loss: 0.6629\n",
      "[1604/1762] D loss: 1.4408, G loss: 0.7759\n",
      "[1684/1762] D loss: 1.8327, G loss: 0.4950\n",
      "[1762/1762] D loss: 1.7337, G loss: 0.4687\n",
      "train error: \n",
      " D loss: 1.664031, G loss: 0.486587, D accuracy: 32.9%, cell accuracy: 97.9%, board accuracy: 6.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.654453, G loss: 0.490774, D accuracy: 31.1%, cell accuracy: 97.8%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7473, G loss: 0.4922\n",
      "[84/1762] D loss: 1.5073, G loss: 0.5439\n",
      "[164/1762] D loss: 1.4679, G loss: 0.6509\n",
      "[244/1762] D loss: 1.4922, G loss: 0.5417\n",
      "[324/1762] D loss: 1.4098, G loss: 0.6588\n",
      "[404/1762] D loss: 1.4202, G loss: 0.7056\n",
      "[484/1762] D loss: 1.4321, G loss: 0.5908\n",
      "[564/1762] D loss: 1.3396, G loss: 0.6095\n",
      "[644/1762] D loss: 1.4089, G loss: 0.7503\n",
      "[724/1762] D loss: 1.3954, G loss: 0.7694\n",
      "[804/1762] D loss: 1.3869, G loss: 0.7259\n",
      "[884/1762] D loss: 1.3924, G loss: 0.7011\n",
      "[964/1762] D loss: 1.4301, G loss: 0.6954\n",
      "[1044/1762] D loss: 1.3983, G loss: 0.6061\n",
      "[1124/1762] D loss: 1.3244, G loss: 0.7195\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.6965\n",
      "[1284/1762] D loss: 1.4078, G loss: 0.6319\n",
      "[1364/1762] D loss: 1.3974, G loss: 0.6806\n",
      "[1444/1762] D loss: 1.4178, G loss: 0.9250\n",
      "[1524/1762] D loss: 1.2933, G loss: 0.6980\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.6752\n",
      "[1684/1762] D loss: 1.4011, G loss: 0.7388\n",
      "[1762/1762] D loss: 1.3936, G loss: 0.7260\n",
      "train error: \n",
      " D loss: 1.375101, G loss: 0.682145, D accuracy: 52.8%, cell accuracy: 99.6%, board accuracy: 61.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370750, G loss: 0.686014, D accuracy: 52.7%, cell accuracy: 99.6%, board accuracy: 57.7% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2332, G loss: 0.7737\n",
      "[84/1762] D loss: 1.3840, G loss: 0.6641\n",
      "[164/1762] D loss: 1.3776, G loss: 0.7395\n",
      "[244/1762] D loss: 1.3098, G loss: 0.6764\n",
      "[324/1762] D loss: 1.3835, G loss: 0.6801\n",
      "[404/1762] D loss: 1.3938, G loss: 0.6779\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7502\n",
      "[564/1762] D loss: 1.3950, G loss: 0.7212\n",
      "[644/1762] D loss: 1.4214, G loss: 0.7267\n",
      "[724/1762] D loss: 1.3503, G loss: 0.6873\n",
      "[804/1762] D loss: 1.3964, G loss: 0.7374\n",
      "[884/1762] D loss: 1.3907, G loss: 0.6532\n",
      "[964/1762] D loss: 1.4028, G loss: 0.7948\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.6564\n",
      "[1124/1762] D loss: 1.2985, G loss: 0.7450\n",
      "[1204/1762] D loss: 1.2929, G loss: 0.7272\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6829\n",
      "[1364/1762] D loss: 1.2864, G loss: 0.8111\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.7323\n",
      "[1524/1762] D loss: 1.3917, G loss: 0.7765\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6711\n",
      "[1684/1762] D loss: 1.3057, G loss: 0.7120\n",
      "[1762/1762] D loss: 1.3929, G loss: 0.6554\n",
      "train error: \n",
      " D loss: 1.367323, G loss: 0.682285, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 69.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362619, G loss: 0.682500, D accuracy: 53.9%, cell accuracy: 99.6%, board accuracy: 65.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.7176\n",
      "[84/1762] D loss: 1.4079, G loss: 0.5449\n",
      "[164/1762] D loss: 1.2820, G loss: 0.6806\n",
      "[244/1762] D loss: 1.2826, G loss: 0.6769\n",
      "[324/1762] D loss: 1.3923, G loss: 0.6957\n",
      "[404/1762] D loss: 1.2639, G loss: 0.7995\n",
      "[484/1762] D loss: 1.3990, G loss: 0.6164\n",
      "[564/1762] D loss: 1.3974, G loss: 0.6010\n",
      "[644/1762] D loss: 1.4562, G loss: 0.6675\n",
      "[724/1762] D loss: 1.3700, G loss: 0.6779\n",
      "[804/1762] D loss: 1.3986, G loss: 0.7365\n",
      "[884/1762] D loss: 1.3152, G loss: 0.8170\n",
      "[964/1762] D loss: 1.3747, G loss: 0.6517\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.6008\n",
      "[1124/1762] D loss: 1.3960, G loss: 0.6247\n",
      "[1204/1762] D loss: 1.3927, G loss: 0.6544\n",
      "[1284/1762] D loss: 1.3845, G loss: 0.7403\n",
      "[1364/1762] D loss: 1.4076, G loss: 0.7622\n",
      "[1444/1762] D loss: 1.2820, G loss: 0.6830\n",
      "[1524/1762] D loss: 1.2839, G loss: 0.8111\n",
      "[1604/1762] D loss: 1.2948, G loss: 0.6610\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.7667\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.7459\n",
      "train error: \n",
      " D loss: 1.362171, G loss: 0.720089, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 79.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356832, G loss: 0.719131, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3996, G loss: 0.6592\n",
      "[84/1762] D loss: 1.3911, G loss: 0.7011\n",
      "[164/1762] D loss: 1.2893, G loss: 0.8074\n",
      "[244/1762] D loss: 1.3232, G loss: 0.8038\n",
      "[324/1762] D loss: 1.1935, G loss: 0.8277\n",
      "[404/1762] D loss: 1.3995, G loss: 0.7455\n",
      "[484/1762] D loss: 1.4154, G loss: 0.6892\n",
      "[564/1762] D loss: 1.1721, G loss: 0.7043\n",
      "[644/1762] D loss: 1.2739, G loss: 0.8637\n",
      "[724/1762] D loss: 1.3683, G loss: 0.7798\n",
      "[804/1762] D loss: 1.3843, G loss: 0.7184\n",
      "[884/1762] D loss: 1.4214, G loss: 0.6461\n",
      "[964/1762] D loss: 1.4241, G loss: 0.6659\n",
      "[1044/1762] D loss: 1.2689, G loss: 0.7824\n",
      "[1124/1762] D loss: 1.3971, G loss: 0.7574\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6977\n",
      "[1284/1762] D loss: 1.3686, G loss: 0.7914\n",
      "[1364/1762] D loss: 1.3741, G loss: 0.7723\n",
      "[1444/1762] D loss: 1.2712, G loss: 0.7677\n",
      "[1524/1762] D loss: 1.3999, G loss: 0.6381\n",
      "[1604/1762] D loss: 1.2886, G loss: 0.7764\n",
      "[1684/1762] D loss: 1.4008, G loss: 0.8002\n",
      "[1762/1762] D loss: 1.1602, G loss: 0.7347\n",
      "train error: \n",
      " D loss: 1.363108, G loss: 0.679286, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 74.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354636, G loss: 0.681758, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2767, G loss: 0.7569\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6971\n",
      "[164/1762] D loss: 1.3916, G loss: 0.6398\n",
      "[244/1762] D loss: 1.3935, G loss: 0.7538\n",
      "[324/1762] D loss: 1.2774, G loss: 0.7060\n",
      "[404/1762] D loss: 1.3994, G loss: 0.6521\n",
      "[484/1762] D loss: 1.3931, G loss: 0.7255\n",
      "[564/1762] D loss: 1.2911, G loss: 0.7214\n",
      "[644/1762] D loss: 1.3972, G loss: 0.5932\n",
      "[724/1762] D loss: 1.3917, G loss: 0.6222\n",
      "[804/1762] D loss: 1.3854, G loss: 0.6795\n",
      "[884/1762] D loss: 1.4069, G loss: 0.8070\n",
      "[964/1762] D loss: 1.4091, G loss: 0.8035\n",
      "[1044/1762] D loss: 1.2763, G loss: 0.6862\n",
      "[1124/1762] D loss: 1.4013, G loss: 0.7552\n",
      "[1204/1762] D loss: 1.2507, G loss: 0.8332\n",
      "[1284/1762] D loss: 1.2790, G loss: 0.7565\n",
      "[1364/1762] D loss: 1.4222, G loss: 0.6101\n",
      "[1444/1762] D loss: 1.2774, G loss: 0.6762\n",
      "[1524/1762] D loss: 1.3269, G loss: 0.6796\n",
      "[1604/1762] D loss: 1.3851, G loss: 0.8842\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.6877\n",
      "[1762/1762] D loss: 1.1278, G loss: 0.8708\n",
      "train error: \n",
      " D loss: 1.367242, G loss: 0.732414, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 78.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361332, G loss: 0.733062, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2718, G loss: 0.8001\n",
      "[84/1762] D loss: 1.2145, G loss: 0.8585\n",
      "[164/1762] D loss: 1.3855, G loss: 0.6703\n",
      "[244/1762] D loss: 1.3922, G loss: 0.6816\n",
      "[324/1762] D loss: 1.2839, G loss: 0.7919\n",
      "[404/1762] D loss: 1.3952, G loss: 0.8135\n",
      "[484/1762] D loss: 1.3198, G loss: 0.7541\n",
      "[564/1762] D loss: 1.3927, G loss: 0.6461\n",
      "[644/1762] D loss: 1.4091, G loss: 0.6574\n",
      "[724/1762] D loss: 1.3932, G loss: 0.6807\n",
      "[804/1762] D loss: 1.3823, G loss: 0.6593\n",
      "[884/1762] D loss: 1.3846, G loss: 0.6513\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6818\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.6772\n",
      "[1124/1762] D loss: 1.4276, G loss: 0.8098\n",
      "[1204/1762] D loss: 1.4031, G loss: 0.7230\n",
      "[1284/1762] D loss: 1.4030, G loss: 0.6746\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7039\n",
      "[1444/1762] D loss: 1.4060, G loss: 0.6401\n",
      "[1524/1762] D loss: 1.3920, G loss: 0.7546\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.7242\n",
      "[1684/1762] D loss: 1.2121, G loss: 0.7703\n",
      "[1762/1762] D loss: 1.4010, G loss: 0.7113\n",
      "train error: \n",
      " D loss: 1.358995, G loss: 0.810253, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348966, G loss: 0.811575, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4134, G loss: 0.8137\n",
      "[84/1762] D loss: 1.3859, G loss: 0.7383\n",
      "[164/1762] D loss: 1.2343, G loss: 0.7854\n",
      "[244/1762] D loss: 1.3944, G loss: 0.6981\n",
      "[324/1762] D loss: 1.3879, G loss: 0.7329\n",
      "[404/1762] D loss: 1.4282, G loss: 0.6778\n",
      "[484/1762] D loss: 1.2677, G loss: 0.6999\n",
      "[564/1762] D loss: 1.4064, G loss: 0.6271\n",
      "[644/1762] D loss: 1.3947, G loss: 0.8404\n",
      "[724/1762] D loss: 1.3472, G loss: 0.8059\n",
      "[804/1762] D loss: 1.3965, G loss: 0.8027\n",
      "[884/1762] D loss: 1.3895, G loss: 0.6755\n",
      "[964/1762] D loss: 1.2723, G loss: 0.7558\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7850\n",
      "[1124/1762] D loss: 1.4898, G loss: 0.6910\n",
      "[1204/1762] D loss: 1.2942, G loss: 0.7785\n",
      "[1284/1762] D loss: 1.4055, G loss: 0.6381\n",
      "[1364/1762] D loss: 1.3942, G loss: 0.6824\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7653\n",
      "[1524/1762] D loss: 1.2437, G loss: 0.7241\n",
      "[1604/1762] D loss: 1.3980, G loss: 0.7439\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.8285\n",
      "[1762/1762] D loss: 1.3542, G loss: 0.8844\n",
      "train error: \n",
      " D loss: 1.359357, G loss: 0.795849, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350931, G loss: 0.798617, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 66.1% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4176, G loss: 0.8095\n",
      "[84/1762] D loss: 1.2716, G loss: 0.7321\n",
      "[164/1762] D loss: 1.3032, G loss: 0.8584\n",
      "[244/1762] D loss: 1.3957, G loss: 0.7542\n",
      "[324/1762] D loss: 1.3914, G loss: 0.7391\n",
      "[404/1762] D loss: 1.3896, G loss: 0.8180\n",
      "[484/1762] D loss: 1.3947, G loss: 0.6796\n",
      "[564/1762] D loss: 1.3957, G loss: 0.6689\n",
      "[644/1762] D loss: 1.3878, G loss: 0.7123\n",
      "[724/1762] D loss: 1.3747, G loss: 0.7103\n",
      "[804/1762] D loss: 1.3930, G loss: 0.6685\n",
      "[884/1762] D loss: 1.4004, G loss: 0.6157\n",
      "[964/1762] D loss: 1.3942, G loss: 0.6678\n",
      "[1044/1762] D loss: 1.4048, G loss: 0.8042\n",
      "[1124/1762] D loss: 1.4004, G loss: 0.7298\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.6660\n",
      "[1284/1762] D loss: 1.1232, G loss: 0.7681\n",
      "[1364/1762] D loss: 1.3995, G loss: 0.6656\n",
      "[1444/1762] D loss: 1.0900, G loss: 0.7665\n",
      "[1524/1762] D loss: 1.2220, G loss: 0.6662\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.7188\n",
      "[1684/1762] D loss: 1.4205, G loss: 0.5517\n",
      "[1762/1762] D loss: 1.4002, G loss: 0.5430\n",
      "train error: \n",
      " D loss: 1.368630, G loss: 0.603686, D accuracy: 54.0%, cell accuracy: 99.4%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360841, G loss: 0.607962, D accuracy: 55.3%, cell accuracy: 99.3%, board accuracy: 50.5% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3994, G loss: 0.6307\n",
      "[84/1762] D loss: 1.3404, G loss: 0.6682\n",
      "[164/1762] D loss: 1.3806, G loss: 0.7552\n",
      "[244/1762] D loss: 1.3904, G loss: 0.7463\n",
      "[324/1762] D loss: 1.3944, G loss: 0.6600\n",
      "[404/1762] D loss: 1.3977, G loss: 0.6227\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6758\n",
      "[564/1762] D loss: 1.2387, G loss: 0.7198\n",
      "[644/1762] D loss: 1.3974, G loss: 0.8061\n",
      "[724/1762] D loss: 1.3780, G loss: 0.7289\n",
      "[804/1762] D loss: 1.2284, G loss: 0.8651\n",
      "[884/1762] D loss: 1.3203, G loss: 1.0222\n",
      "[964/1762] D loss: 1.4020, G loss: 0.7812\n",
      "[1044/1762] D loss: 1.3959, G loss: 0.7288\n",
      "[1124/1762] D loss: 1.2236, G loss: 0.7777\n",
      "[1204/1762] D loss: 1.3853, G loss: 0.7113\n",
      "[1284/1762] D loss: 1.2155, G loss: 0.9821\n",
      "[1364/1762] D loss: 1.3910, G loss: 0.7042\n",
      "[1444/1762] D loss: 1.4162, G loss: 0.8368\n",
      "[1524/1762] D loss: 1.4581, G loss: 0.8095\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.8410\n",
      "[1684/1762] D loss: 1.4001, G loss: 0.8438\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.6474\n",
      "train error: \n",
      " D loss: 1.358009, G loss: 0.665989, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349685, G loss: 0.667211, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2562, G loss: 0.8264\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6516\n",
      "[164/1762] D loss: 1.3802, G loss: 0.7557\n",
      "[244/1762] D loss: 1.3958, G loss: 0.7140\n",
      "[324/1762] D loss: 1.3837, G loss: 0.8555\n",
      "[404/1762] D loss: 1.3959, G loss: 0.6928\n",
      "[484/1762] D loss: 1.2428, G loss: 0.8464\n",
      "[564/1762] D loss: 1.3470, G loss: 0.7077\n",
      "[644/1762] D loss: 1.3585, G loss: 0.7530\n",
      "[724/1762] D loss: 1.3936, G loss: 0.7838\n",
      "[804/1762] D loss: 1.3885, G loss: 0.7776\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6634\n",
      "[964/1762] D loss: 1.2651, G loss: 0.7132\n",
      "[1044/1762] D loss: 1.3617, G loss: 0.7705\n",
      "[1124/1762] D loss: 1.2052, G loss: 0.8670\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.7229\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6634\n",
      "[1364/1762] D loss: 1.2534, G loss: 0.8687\n",
      "[1444/1762] D loss: 1.2270, G loss: 0.7955\n",
      "[1524/1762] D loss: 1.3214, G loss: 0.7028\n",
      "[1604/1762] D loss: 1.3835, G loss: 0.6656\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.6865\n",
      "[1762/1762] D loss: 0.7726, G loss: 0.9794\n",
      "train error: \n",
      " D loss: 1.345445, G loss: 0.772004, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338993, G loss: 0.773833, D accuracy: 56.1%, cell accuracy: 99.4%, board accuracy: 51.4% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3026, G loss: 0.9184\n",
      "[84/1762] D loss: 1.3652, G loss: 0.7614\n",
      "[164/1762] D loss: 1.3975, G loss: 0.6714\n",
      "[244/1762] D loss: 1.3914, G loss: 0.7221\n",
      "[324/1762] D loss: 1.3828, G loss: 0.7712\n",
      "[404/1762] D loss: 1.2351, G loss: 0.7812\n",
      "[484/1762] D loss: 1.3955, G loss: 0.7078\n",
      "[564/1762] D loss: 1.1130, G loss: 0.7739\n",
      "[644/1762] D loss: 1.3561, G loss: 0.7614\n",
      "[724/1762] D loss: 1.3822, G loss: 0.6441\n",
      "[804/1762] D loss: 1.2425, G loss: 0.6879\n",
      "[884/1762] D loss: 1.3795, G loss: 0.6603\n",
      "[964/1762] D loss: 1.4057, G loss: 0.7060\n",
      "[1044/1762] D loss: 1.3949, G loss: 0.6342\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6714\n",
      "[1204/1762] D loss: 1.3966, G loss: 0.6382\n",
      "[1284/1762] D loss: 1.3937, G loss: 0.7107\n",
      "[1364/1762] D loss: 1.3819, G loss: 0.7736\n",
      "[1444/1762] D loss: 1.3805, G loss: 0.6868\n",
      "[1524/1762] D loss: 1.2465, G loss: 0.7482\n",
      "[1604/1762] D loss: 1.4096, G loss: 0.5468\n",
      "[1684/1762] D loss: 1.3829, G loss: 0.6509\n",
      "[1762/1762] D loss: 1.4089, G loss: 0.7535\n",
      "train error: \n",
      " D loss: 1.350479, G loss: 0.690053, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 79.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340517, G loss: 0.694963, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2323, G loss: 0.6876\n",
      "[84/1762] D loss: 1.3987, G loss: 0.6351\n",
      "[164/1762] D loss: 1.4114, G loss: 0.8611\n",
      "[244/1762] D loss: 1.2168, G loss: 0.7927\n",
      "[324/1762] D loss: 1.2255, G loss: 0.7309\n",
      "[404/1762] D loss: 1.4015, G loss: 0.7755\n",
      "[484/1762] D loss: 1.2425, G loss: 0.8651\n",
      "[564/1762] D loss: 1.3930, G loss: 0.7653\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6631\n",
      "[724/1762] D loss: 1.4030, G loss: 0.6326\n",
      "[804/1762] D loss: 1.3946, G loss: 0.7192\n",
      "[884/1762] D loss: 1.2446, G loss: 0.7871\n",
      "[964/1762] D loss: 1.4372, G loss: 0.5218\n",
      "[1044/1762] D loss: 1.4133, G loss: 0.5843\n",
      "[1124/1762] D loss: 1.3955, G loss: 0.7451\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.6454\n",
      "[1284/1762] D loss: 1.4013, G loss: 0.5787\n",
      "[1364/1762] D loss: 1.3152, G loss: 0.6816\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.8009\n",
      "[1524/1762] D loss: 1.4133, G loss: 0.6211\n",
      "[1604/1762] D loss: 1.3333, G loss: 0.6659\n",
      "[1684/1762] D loss: 1.4163, G loss: 0.8351\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7669\n",
      "train error: \n",
      " D loss: 1.364574, G loss: 0.858643, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 72.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352124, G loss: 0.864718, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4388, G loss: 0.9753\n",
      "[84/1762] D loss: 1.1898, G loss: 0.8291\n",
      "[164/1762] D loss: 1.3919, G loss: 0.6034\n",
      "[244/1762] D loss: 1.3750, G loss: 0.6640\n",
      "[324/1762] D loss: 1.5201, G loss: 0.6711\n",
      "[404/1762] D loss: 1.5070, G loss: 0.6462\n",
      "[484/1762] D loss: 1.4622, G loss: 0.9506\n",
      "[564/1762] D loss: 1.4032, G loss: 0.6893\n",
      "[644/1762] D loss: 1.4405, G loss: 0.6295\n",
      "[724/1762] D loss: 1.4013, G loss: 0.6045\n",
      "[804/1762] D loss: 1.4102, G loss: 0.5816\n",
      "[884/1762] D loss: 1.3974, G loss: 0.6534\n",
      "[964/1762] D loss: 1.3808, G loss: 0.6790\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.5992\n",
      "[1124/1762] D loss: 1.2160, G loss: 0.7330\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.7185\n",
      "[1284/1762] D loss: 1.3927, G loss: 0.7535\n",
      "[1364/1762] D loss: 1.3825, G loss: 0.6987\n",
      "[1444/1762] D loss: 1.4115, G loss: 0.8400\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6942\n",
      "[1604/1762] D loss: 1.3834, G loss: 0.6311\n",
      "[1684/1762] D loss: 1.2345, G loss: 0.8202\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6495\n",
      "train error: \n",
      " D loss: 1.353336, G loss: 0.669667, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 78.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342528, G loss: 0.675835, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3988, G loss: 0.6593\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7056\n",
      "[164/1762] D loss: 1.3891, G loss: 0.6765\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6678\n",
      "[324/1762] D loss: 1.3994, G loss: 0.8050\n",
      "[404/1762] D loss: 1.3455, G loss: 0.7784\n",
      "[484/1762] D loss: 1.3983, G loss: 0.7704\n",
      "[564/1762] D loss: 1.4008, G loss: 0.6065\n",
      "[644/1762] D loss: 1.3949, G loss: 0.7340\n",
      "[724/1762] D loss: 1.3922, G loss: 0.7219\n",
      "[804/1762] D loss: 1.3956, G loss: 0.7520\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7143\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6907\n",
      "[1044/1762] D loss: 1.3931, G loss: 0.6703\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.7182\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.8007\n",
      "[1284/1762] D loss: 1.3916, G loss: 0.6713\n",
      "[1364/1762] D loss: 1.4004, G loss: 0.6310\n",
      "[1444/1762] D loss: 1.3939, G loss: 0.6200\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.7310\n",
      "[1604/1762] D loss: 1.3375, G loss: 0.8118\n",
      "[1684/1762] D loss: 1.3998, G loss: 0.6787\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.6507\n",
      "train error: \n",
      " D loss: 1.347894, G loss: 0.765288, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334053, G loss: 0.775000, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915, G loss: 0.7372\n",
      "[84/1762] D loss: 1.3939, G loss: 0.7069\n",
      "[164/1762] D loss: 1.4002, G loss: 0.6108\n",
      "[244/1762] D loss: 1.1872, G loss: 0.7979\n",
      "[324/1762] D loss: 1.2127, G loss: 0.8731\n",
      "[404/1762] D loss: 1.4121, G loss: 0.6298\n",
      "[484/1762] D loss: 1.4058, G loss: 0.6751\n",
      "[564/1762] D loss: 1.1917, G loss: 0.8872\n",
      "[644/1762] D loss: 1.3917, G loss: 0.7453\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6934\n",
      "[804/1762] D loss: 1.3930, G loss: 0.6526\n",
      "[884/1762] D loss: 1.2299, G loss: 0.7604\n",
      "[964/1762] D loss: 1.2156, G loss: 0.8609\n",
      "[1044/1762] D loss: 1.4515, G loss: 0.8571\n",
      "[1124/1762] D loss: 1.2011, G loss: 0.7880\n",
      "[1204/1762] D loss: 1.3783, G loss: 0.6571\n",
      "[1284/1762] D loss: 1.1959, G loss: 0.8481\n",
      "[1364/1762] D loss: 1.7934, G loss: 0.8739\n",
      "[1444/1762] D loss: 1.2253, G loss: 0.8475\n",
      "[1524/1762] D loss: 1.2648, G loss: 0.6389\n",
      "[1604/1762] D loss: 1.5901, G loss: 0.6517\n",
      "[1684/1762] D loss: 1.5425, G loss: 0.6399\n",
      "[1762/1762] D loss: 1.3337, G loss: 0.6679\n",
      "train error: \n",
      " D loss: 1.473415, G loss: 0.542218, D accuracy: 48.0%, cell accuracy: 98.0%, board accuracy: 22.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.473187, G loss: 0.558536, D accuracy: 47.2%, cell accuracy: 97.9%, board accuracy: 21.8% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4410, G loss: 0.5237\n",
      "[84/1762] D loss: 1.4146, G loss: 0.7988\n",
      "[164/1762] D loss: 1.3798, G loss: 0.8586\n",
      "[244/1762] D loss: 1.4458, G loss: 0.6338\n",
      "[324/1762] D loss: 1.3996, G loss: 0.6138\n",
      "[404/1762] D loss: 1.4064, G loss: 0.7736\n",
      "[484/1762] D loss: 1.4491, G loss: 0.6829\n",
      "[564/1762] D loss: 1.3947, G loss: 0.6864\n",
      "[644/1762] D loss: 1.3935, G loss: 0.7118\n",
      "[724/1762] D loss: 1.4890, G loss: 0.8656\n",
      "[804/1762] D loss: 1.3993, G loss: 0.6960\n",
      "[884/1762] D loss: 1.4095, G loss: 0.7210\n",
      "[964/1762] D loss: 1.3519, G loss: 0.6855\n",
      "[1044/1762] D loss: 1.3952, G loss: 0.6111\n",
      "[1124/1762] D loss: 1.3711, G loss: 0.7552\n",
      "[1204/1762] D loss: 1.4205, G loss: 0.6274\n",
      "[1284/1762] D loss: 1.3814, G loss: 0.7668\n",
      "[1364/1762] D loss: 1.3803, G loss: 0.7531\n",
      "[1444/1762] D loss: 1.3006, G loss: 0.8892\n",
      "[1524/1762] D loss: 1.4039, G loss: 0.6182\n",
      "[1604/1762] D loss: 1.4022, G loss: 0.6822\n",
      "[1684/1762] D loss: 1.3901, G loss: 0.6905\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6932\n",
      "train error: \n",
      " D loss: 1.379107, G loss: 0.728582, D accuracy: 52.9%, cell accuracy: 99.5%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373074, G loss: 0.741345, D accuracy: 54.7%, cell accuracy: 99.4%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3819, G loss: 0.6844\n",
      "[84/1762] D loss: 1.3512, G loss: 0.6149\n",
      "[164/1762] D loss: 1.3858, G loss: 0.7727\n",
      "[244/1762] D loss: 1.3943, G loss: 0.7830\n",
      "[324/1762] D loss: 1.3892, G loss: 0.6522\n",
      "[404/1762] D loss: 1.3892, G loss: 0.7666\n",
      "[484/1762] D loss: 1.3706, G loss: 0.6588\n",
      "[564/1762] D loss: 1.3852, G loss: 0.6695\n",
      "[644/1762] D loss: 1.3903, G loss: 0.7684\n",
      "[724/1762] D loss: 1.3731, G loss: 0.7458\n",
      "[804/1762] D loss: 1.2992, G loss: 0.7236\n",
      "[884/1762] D loss: 1.3973, G loss: 0.6476\n",
      "[964/1762] D loss: 1.3894, G loss: 0.6706\n",
      "[1044/1762] D loss: 1.3746, G loss: 0.7012\n",
      "[1124/1762] D loss: 1.3731, G loss: 0.6970\n",
      "[1204/1762] D loss: 1.4104, G loss: 0.6354\n",
      "[1284/1762] D loss: 1.3959, G loss: 0.7546\n",
      "[1364/1762] D loss: 1.3772, G loss: 0.7178\n",
      "[1444/1762] D loss: 1.3994, G loss: 0.6471\n",
      "[1524/1762] D loss: 1.2994, G loss: 0.6830\n",
      "[1604/1762] D loss: 1.4163, G loss: 0.8602\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.7085\n",
      "[1762/1762] D loss: 1.3959, G loss: 0.6488\n",
      "train error: \n",
      " D loss: 1.368956, G loss: 0.671842, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364820, G loss: 0.677153, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6502\n",
      "[84/1762] D loss: 1.2757, G loss: 0.7894\n",
      "[164/1762] D loss: 1.2911, G loss: 0.7572\n",
      "[244/1762] D loss: 1.3839, G loss: 0.6762\n",
      "[324/1762] D loss: 1.2878, G loss: 0.7138\n",
      "[404/1762] D loss: 1.3966, G loss: 0.5808\n",
      "[484/1762] D loss: 1.2332, G loss: 0.7823\n",
      "[564/1762] D loss: 1.3908, G loss: 0.6945\n",
      "[644/1762] D loss: 1.2540, G loss: 0.7652\n",
      "[724/1762] D loss: 1.3843, G loss: 0.6456\n",
      "[804/1762] D loss: 1.3962, G loss: 0.6350\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6999\n",
      "[964/1762] D loss: 1.2536, G loss: 0.7103\n",
      "[1044/1762] D loss: 1.3744, G loss: 0.6945\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.6574\n",
      "[1204/1762] D loss: 1.4175, G loss: 0.8295\n",
      "[1284/1762] D loss: 1.3761, G loss: 0.7137\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.7255\n",
      "[1444/1762] D loss: 1.4329, G loss: 0.6263\n",
      "[1524/1762] D loss: 1.3218, G loss: 0.7252\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.7529\n",
      "[1684/1762] D loss: 1.3834, G loss: 0.7152\n",
      "[1762/1762] D loss: 1.4134, G loss: 0.5804\n",
      "train error: \n",
      " D loss: 1.364053, G loss: 0.674981, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 72.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356602, G loss: 0.682170, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 67.0% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2570, G loss: 0.7448\n",
      "[84/1762] D loss: 1.3188, G loss: 0.6656\n",
      "[164/1762] D loss: 1.3919, G loss: 0.6177\n",
      "[244/1762] D loss: 1.3900, G loss: 0.7364\n",
      "[324/1762] D loss: 1.2440, G loss: 0.8451\n",
      "[404/1762] D loss: 1.3897, G loss: 0.6683\n",
      "[484/1762] D loss: 1.3921, G loss: 0.7018\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6528\n",
      "[644/1762] D loss: 1.2682, G loss: 0.7516\n",
      "[724/1762] D loss: 1.3772, G loss: 0.6312\n",
      "[804/1762] D loss: 1.4632, G loss: 0.6348\n",
      "[884/1762] D loss: 1.4066, G loss: 0.5989\n",
      "[964/1762] D loss: 1.4303, G loss: 0.7996\n",
      "[1044/1762] D loss: 1.3978, G loss: 0.7539\n",
      "[1124/1762] D loss: 1.3994, G loss: 0.8351\n",
      "[1204/1762] D loss: 1.3036, G loss: 0.7361\n",
      "[1284/1762] D loss: 1.2557, G loss: 0.6625\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.6893\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.8276\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6936\n",
      "[1604/1762] D loss: 1.2606, G loss: 0.6980\n",
      "[1684/1762] D loss: 1.2968, G loss: 0.7617\n",
      "[1762/1762] D loss: 1.4197, G loss: 0.5862\n",
      "train error: \n",
      " D loss: 1.364694, G loss: 0.683318, D accuracy: 55.0%, cell accuracy: 98.6%, board accuracy: 6.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363254, G loss: 0.686372, D accuracy: 55.0%, cell accuracy: 98.6%, board accuracy: 7.7% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3442, G loss: 0.7234\n",
      "[84/1762] D loss: 1.2950, G loss: 0.7444\n",
      "[164/1762] D loss: 1.5546, G loss: 0.6413\n",
      "[244/1762] D loss: 1.1974, G loss: 1.0881\n",
      "[324/1762] D loss: 1.3362, G loss: 0.6414\n",
      "[404/1762] D loss: 1.4165, G loss: 0.6577\n",
      "[484/1762] D loss: 1.4578, G loss: 0.4976\n",
      "[564/1762] D loss: 1.5066, G loss: 0.8137\n",
      "[644/1762] D loss: 1.4462, G loss: 0.6165\n",
      "[724/1762] D loss: 1.3847, G loss: 0.7724\n",
      "[804/1762] D loss: 1.5567, G loss: 0.5661\n",
      "[884/1762] D loss: 1.3973, G loss: 0.6748\n",
      "[964/1762] D loss: 1.4186, G loss: 0.6488\n",
      "[1044/1762] D loss: 1.4068, G loss: 0.6691\n",
      "[1124/1762] D loss: 1.4000, G loss: 0.7167\n",
      "[1204/1762] D loss: 1.3968, G loss: 0.7409\n",
      "[1284/1762] D loss: 1.4609, G loss: 0.7277\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.7017\n",
      "[1444/1762] D loss: 1.3953, G loss: 0.5938\n",
      "[1524/1762] D loss: 1.3589, G loss: 0.8291\n",
      "[1604/1762] D loss: 1.2674, G loss: 0.7779\n",
      "[1684/1762] D loss: 1.4064, G loss: 0.6930\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6969\n",
      "train error: \n",
      " D loss: 1.371490, G loss: 0.719652, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365892, G loss: 0.726043, D accuracy: 53.4%, cell accuracy: 99.6%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4078, G loss: 0.7212\n",
      "[84/1762] D loss: 1.3905, G loss: 0.7367\n",
      "[164/1762] D loss: 1.2163, G loss: 0.8391\n",
      "[244/1762] D loss: 1.3945, G loss: 0.7190\n",
      "[324/1762] D loss: 1.3884, G loss: 0.6413\n",
      "[404/1762] D loss: 1.4062, G loss: 0.7729\n",
      "[484/1762] D loss: 1.2838, G loss: 0.7679\n",
      "[564/1762] D loss: 1.3930, G loss: 0.7039\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6970\n",
      "[724/1762] D loss: 1.4019, G loss: 0.8100\n",
      "[804/1762] D loss: 1.3958, G loss: 0.6910\n",
      "[884/1762] D loss: 1.2673, G loss: 0.6888\n",
      "[964/1762] D loss: 1.3887, G loss: 0.7482\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.7555\n",
      "[1124/1762] D loss: 1.4078, G loss: 0.6322\n",
      "[1204/1762] D loss: 1.1313, G loss: 0.7532\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.7333\n",
      "[1364/1762] D loss: 1.3994, G loss: 0.7728\n",
      "[1444/1762] D loss: 1.3855, G loss: 0.6752\n",
      "[1524/1762] D loss: 1.2713, G loss: 0.7385\n",
      "[1604/1762] D loss: 1.4008, G loss: 0.6774\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.6861\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7159\n",
      "train error: \n",
      " D loss: 1.356503, G loss: 0.676123, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 74.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348547, G loss: 0.678286, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 68.2% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927, G loss: 0.6621\n",
      "[84/1762] D loss: 1.4183, G loss: 0.5756\n",
      "[164/1762] D loss: 1.4010, G loss: 0.6096\n",
      "[244/1762] D loss: 1.3651, G loss: 0.7023\n",
      "[324/1762] D loss: 1.2561, G loss: 0.8351\n",
      "[404/1762] D loss: 1.4185, G loss: 0.6072\n",
      "[484/1762] D loss: 1.3858, G loss: 0.6232\n",
      "[564/1762] D loss: 1.3828, G loss: 0.6943\n",
      "[644/1762] D loss: 1.3285, G loss: 0.7400\n",
      "[724/1762] D loss: 1.3897, G loss: 0.7454\n",
      "[804/1762] D loss: 1.3934, G loss: 0.7543\n",
      "[884/1762] D loss: 1.4170, G loss: 0.7946\n",
      "[964/1762] D loss: 1.2413, G loss: 0.8095\n",
      "[1044/1762] D loss: 1.3806, G loss: 0.7095\n",
      "[1124/1762] D loss: 1.4071, G loss: 0.6707\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.7049\n",
      "[1284/1762] D loss: 1.3921, G loss: 0.7840\n",
      "[1364/1762] D loss: 1.3425, G loss: 0.6366\n",
      "[1444/1762] D loss: 1.4039, G loss: 0.7446\n",
      "[1524/1762] D loss: 1.3897, G loss: 0.7561\n",
      "[1604/1762] D loss: 1.6154, G loss: 0.5262\n",
      "[1684/1762] D loss: 1.5004, G loss: 0.6308\n",
      "[1762/1762] D loss: 1.1505, G loss: 0.7366\n",
      "train error: \n",
      " D loss: 1.265589, G loss: 0.876113, D accuracy: 70.3%, cell accuracy: 97.8%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261499, G loss: 0.904883, D accuracy: 70.6%, cell accuracy: 97.7%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1771, G loss: 0.7980\n",
      "[84/1762] D loss: 1.1817, G loss: 0.9235\n",
      "[164/1762] D loss: 1.3670, G loss: 0.6041\n",
      "[244/1762] D loss: 1.5260, G loss: 0.5499\n",
      "[324/1762] D loss: 1.3840, G loss: 0.7496\n",
      "[404/1762] D loss: 1.4290, G loss: 0.7027\n",
      "[484/1762] D loss: 1.3857, G loss: 0.7481\n",
      "[564/1762] D loss: 1.3690, G loss: 0.7269\n",
      "[644/1762] D loss: 1.3500, G loss: 0.7287\n",
      "[724/1762] D loss: 1.4025, G loss: 0.6349\n",
      "[804/1762] D loss: 1.4070, G loss: 0.8157\n",
      "[884/1762] D loss: 1.4399, G loss: 0.6249\n",
      "[964/1762] D loss: 1.3842, G loss: 0.7863\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7182\n",
      "[1124/1762] D loss: 1.3920, G loss: 0.6468\n",
      "[1204/1762] D loss: 1.3974, G loss: 0.6920\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.6541\n",
      "[1364/1762] D loss: 1.3749, G loss: 0.7316\n",
      "[1444/1762] D loss: 1.4161, G loss: 0.5943\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.7259\n",
      "[1604/1762] D loss: 1.3682, G loss: 0.7273\n",
      "[1684/1762] D loss: 1.3664, G loss: 0.6916\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.7024\n",
      "train error: \n",
      " D loss: 1.369557, G loss: 0.679497, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 70.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365807, G loss: 0.686576, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.6441\n",
      "[84/1762] D loss: 1.3279, G loss: 0.7178\n",
      "[164/1762] D loss: 1.3157, G loss: 0.6700\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7237\n",
      "[324/1762] D loss: 1.3875, G loss: 0.6944\n",
      "[404/1762] D loss: 1.2713, G loss: 0.6981\n",
      "[484/1762] D loss: 1.3991, G loss: 0.6409\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6905\n",
      "[644/1762] D loss: 1.3913, G loss: 0.6890\n",
      "[724/1762] D loss: 1.3807, G loss: 0.6770\n",
      "[804/1762] D loss: 1.3881, G loss: 0.7387\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6686\n",
      "[964/1762] D loss: 1.3904, G loss: 0.6401\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.6960\n",
      "[1124/1762] D loss: 1.3754, G loss: 0.6670\n",
      "[1204/1762] D loss: 1.3173, G loss: 0.7427\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.6789\n",
      "[1364/1762] D loss: 1.3386, G loss: 0.7895\n",
      "[1444/1762] D loss: 1.4091, G loss: 0.6525\n",
      "[1524/1762] D loss: 1.4315, G loss: 0.6044\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6460\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.7101\n",
      "[1762/1762] D loss: 1.3749, G loss: 0.5940\n",
      "train error: \n",
      " D loss: 1.380751, G loss: 0.614307, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 68.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376021, G loss: 0.618691, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2815, G loss: 0.7064\n",
      "[84/1762] D loss: 1.3791, G loss: 0.7546\n",
      "[164/1762] D loss: 1.6272, G loss: 0.6252\n",
      "[244/1762] D loss: 1.4858, G loss: 0.6081\n",
      "[324/1762] D loss: 1.2978, G loss: 0.6548\n",
      "[404/1762] D loss: 1.3716, G loss: 0.9318\n",
      "[484/1762] D loss: 1.0962, G loss: 0.8118\n",
      "[564/1762] D loss: 1.4416, G loss: 0.5378\n",
      "[644/1762] D loss: 1.3801, G loss: 0.7391\n",
      "[724/1762] D loss: 1.4359, G loss: 0.6506\n",
      "[804/1762] D loss: 1.4068, G loss: 0.7738\n",
      "[884/1762] D loss: 1.3965, G loss: 0.6453\n",
      "[964/1762] D loss: 1.3977, G loss: 0.7684\n",
      "[1044/1762] D loss: 1.3931, G loss: 0.7514\n",
      "[1124/1762] D loss: 1.3828, G loss: 0.6797\n",
      "[1204/1762] D loss: 1.3976, G loss: 0.7344\n",
      "[1284/1762] D loss: 1.3894, G loss: 0.6913\n",
      "[1364/1762] D loss: 1.3929, G loss: 0.7279\n",
      "[1444/1762] D loss: 1.3766, G loss: 0.6625\n",
      "[1524/1762] D loss: 1.4044, G loss: 0.6841\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.6095\n",
      "[1684/1762] D loss: 1.3846, G loss: 0.7679\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7042\n",
      "train error: \n",
      " D loss: 1.379846, G loss: 0.699544, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 73.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374616, G loss: 0.712754, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4033, G loss: 0.7169\n",
      "[84/1762] D loss: 1.4013, G loss: 0.6735\n",
      "[164/1762] D loss: 1.3959, G loss: 0.7346\n",
      "[244/1762] D loss: 1.3696, G loss: 0.7191\n",
      "[324/1762] D loss: 1.3936, G loss: 0.6124\n",
      "[404/1762] D loss: 1.3635, G loss: 0.7223\n",
      "[484/1762] D loss: 1.3849, G loss: 0.7067\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6648\n",
      "[644/1762] D loss: 1.4142, G loss: 0.6491\n",
      "[724/1762] D loss: 1.3854, G loss: 0.7538\n",
      "[804/1762] D loss: 1.3881, G loss: 0.6874\n",
      "[884/1762] D loss: 1.3106, G loss: 0.6757\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7415\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.7180\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.6614\n",
      "[1204/1762] D loss: 1.3922, G loss: 0.7474\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.6854\n",
      "[1364/1762] D loss: 1.4088, G loss: 0.7656\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.6732\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.7001\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.6376\n",
      "[1684/1762] D loss: 1.3543, G loss: 0.7578\n",
      "[1762/1762] D loss: 1.3820, G loss: 0.6879\n",
      "train error: \n",
      " D loss: 1.373089, G loss: 0.697680, D accuracy: 52.8%, cell accuracy: 99.6%, board accuracy: 65.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366609, G loss: 0.704128, D accuracy: 53.8%, cell accuracy: 99.5%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3991, G loss: 0.6728\n",
      "[84/1762] D loss: 1.3884, G loss: 0.6494\n",
      "[164/1762] D loss: 1.3612, G loss: 0.6676\n",
      "[244/1762] D loss: 1.4021, G loss: 0.7515\n",
      "[324/1762] D loss: 1.3431, G loss: 0.7751\n",
      "[404/1762] D loss: 1.3911, G loss: 0.7546\n",
      "[484/1762] D loss: 1.3909, G loss: 0.7029\n",
      "[564/1762] D loss: 1.3819, G loss: 0.7042\n",
      "[644/1762] D loss: 1.4165, G loss: 0.7059\n",
      "[724/1762] D loss: 1.2726, G loss: 0.7310\n",
      "[804/1762] D loss: 1.4010, G loss: 0.6780\n",
      "[884/1762] D loss: 1.3805, G loss: 0.6681\n",
      "[964/1762] D loss: 1.2965, G loss: 0.7059\n",
      "[1044/1762] D loss: 1.3970, G loss: 0.6122\n",
      "[1124/1762] D loss: 1.3967, G loss: 0.7448\n",
      "[1204/1762] D loss: 1.3935, G loss: 0.7469\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.7455\n",
      "[1364/1762] D loss: 1.3943, G loss: 0.6310\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.6445\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.6902\n",
      "[1604/1762] D loss: 1.3893, G loss: 0.7329\n",
      "[1684/1762] D loss: 1.2825, G loss: 0.7566\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7419\n",
      "train error: \n",
      " D loss: 1.366570, G loss: 0.748893, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 74.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359843, G loss: 0.752946, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2790, G loss: 0.7860\n",
      "[84/1762] D loss: 1.3995, G loss: 0.7909\n",
      "[164/1762] D loss: 1.3910, G loss: 0.7485\n",
      "[244/1762] D loss: 1.3337, G loss: 0.7538\n",
      "[324/1762] D loss: 1.3633, G loss: 0.6954\n",
      "[404/1762] D loss: 1.3946, G loss: 0.6705\n",
      "[484/1762] D loss: 1.3932, G loss: 0.7764\n",
      "[564/1762] D loss: 1.3921, G loss: 0.7719\n",
      "[644/1762] D loss: 1.3945, G loss: 0.7546\n",
      "[724/1762] D loss: 1.3917, G loss: 0.7866\n",
      "[804/1762] D loss: 1.1039, G loss: 0.9764\n",
      "[884/1762] D loss: 1.3891, G loss: 0.7239\n",
      "[964/1762] D loss: 1.3907, G loss: 0.6803\n",
      "[1044/1762] D loss: 1.2520, G loss: 0.7330\n",
      "[1124/1762] D loss: 1.3826, G loss: 0.7218\n",
      "[1204/1762] D loss: 1.3708, G loss: 0.7595\n",
      "[1284/1762] D loss: 1.3803, G loss: 0.8110\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6675\n",
      "[1444/1762] D loss: 1.3053, G loss: 0.8758\n",
      "[1524/1762] D loss: 1.4410, G loss: 0.7741\n",
      "[1604/1762] D loss: 1.3805, G loss: 0.7703\n",
      "[1684/1762] D loss: 1.2883, G loss: 0.7357\n",
      "[1762/1762] D loss: 1.4193, G loss: 0.6345\n",
      "train error: \n",
      " D loss: 1.367606, G loss: 0.679921, D accuracy: 51.4%, cell accuracy: 99.5%, board accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356511, G loss: 0.687478, D accuracy: 52.3%, cell accuracy: 99.5%, board accuracy: 46.6% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4019, G loss: 0.6806\n",
      "[84/1762] D loss: 1.3731, G loss: 0.6785\n",
      "[164/1762] D loss: 1.2509, G loss: 0.7792\n",
      "[244/1762] D loss: 1.3048, G loss: 0.7069\n",
      "[324/1762] D loss: 1.3900, G loss: 0.7066\n",
      "[404/1762] D loss: 1.3926, G loss: 0.7382\n",
      "[484/1762] D loss: 1.3936, G loss: 0.7043\n",
      "[564/1762] D loss: 1.3844, G loss: 0.7600\n",
      "[644/1762] D loss: 1.3984, G loss: 0.7627\n",
      "[724/1762] D loss: 1.3530, G loss: 0.6818\n",
      "[804/1762] D loss: 1.2582, G loss: 0.7756\n",
      "[884/1762] D loss: 1.3174, G loss: 0.6796\n",
      "[964/1762] D loss: 1.3103, G loss: 0.7231\n",
      "[1044/1762] D loss: 1.3957, G loss: 0.6411\n",
      "[1124/1762] D loss: 1.3999, G loss: 0.6082\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.7348\n",
      "[1284/1762] D loss: 1.4159, G loss: 0.7373\n",
      "[1364/1762] D loss: 1.9397, G loss: 0.3814\n",
      "[1444/1762] D loss: 1.7636, G loss: 0.4032\n",
      "[1524/1762] D loss: 1.2474, G loss: 0.7274\n",
      "[1604/1762] D loss: 1.0825, G loss: 0.8235\n",
      "[1684/1762] D loss: 1.1595, G loss: 0.8121\n",
      "[1762/1762] D loss: 1.3995, G loss: 0.8329\n",
      "train error: \n",
      " D loss: 1.456934, G loss: 0.739788, D accuracy: 49.7%, cell accuracy: 99.6%, board accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.466963, G loss: 0.754660, D accuracy: 49.1%, cell accuracy: 99.5%, board accuracy: 48.4% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3956, G loss: 0.7553\n",
      "[84/1762] D loss: 1.4747, G loss: 0.9435\n",
      "[164/1762] D loss: 1.4981, G loss: 0.6785\n",
      "[244/1762] D loss: 1.4018, G loss: 0.7280\n",
      "[324/1762] D loss: 1.4081, G loss: 0.7423\n",
      "[404/1762] D loss: 1.3925, G loss: 0.6662\n",
      "[484/1762] D loss: 1.4634, G loss: 0.6281\n",
      "[564/1762] D loss: 1.3987, G loss: 0.6484\n",
      "[644/1762] D loss: 1.4166, G loss: 0.6828\n",
      "[724/1762] D loss: 1.3983, G loss: 0.6906\n",
      "[804/1762] D loss: 1.3836, G loss: 0.6699\n",
      "[884/1762] D loss: 1.3987, G loss: 0.6270\n",
      "[964/1762] D loss: 1.3854, G loss: 0.6918\n",
      "[1044/1762] D loss: 1.3491, G loss: 0.6794\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.7037\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7046\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.6464\n",
      "[1364/1762] D loss: 1.3929, G loss: 0.7569\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.6888\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6802\n",
      "[1604/1762] D loss: 1.3829, G loss: 0.6564\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.7409\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6999\n",
      "train error: \n",
      " D loss: 1.361173, G loss: 0.694041, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 75.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353859, G loss: 0.700618, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6470\n",
      "[84/1762] D loss: 1.3912, G loss: 0.7673\n",
      "[164/1762] D loss: 1.3204, G loss: 0.7580\n",
      "[244/1762] D loss: 1.3036, G loss: 0.6795\n",
      "[324/1762] D loss: 1.3498, G loss: 0.7142\n",
      "[404/1762] D loss: 1.3897, G loss: 0.7142\n",
      "[484/1762] D loss: 1.2271, G loss: 0.7634\n",
      "[564/1762] D loss: 1.3296, G loss: 0.6994\n",
      "[644/1762] D loss: 1.3953, G loss: 0.6561\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6513\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6959\n",
      "[884/1762] D loss: 1.3590, G loss: 0.7787\n",
      "[964/1762] D loss: 1.3946, G loss: 0.7289\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.7658\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.6879\n",
      "[1204/1762] D loss: 1.3854, G loss: 0.7243\n",
      "[1284/1762] D loss: 1.3761, G loss: 0.6955\n",
      "[1364/1762] D loss: 1.4012, G loss: 0.8411\n",
      "[1444/1762] D loss: 1.4045, G loss: 0.5709\n",
      "[1524/1762] D loss: 1.1230, G loss: 0.8659\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.6318\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6856\n",
      "[1762/1762] D loss: 1.2913, G loss: 0.7536\n",
      "train error: \n",
      " D loss: 1.354650, G loss: 0.731723, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 73.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344725, G loss: 0.736651, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2608, G loss: 0.7809\n",
      "[84/1762] D loss: 1.3902, G loss: 0.8322\n",
      "[164/1762] D loss: 1.3928, G loss: 0.6212\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7332\n",
      "[324/1762] D loss: 1.3896, G loss: 0.7293\n",
      "[404/1762] D loss: 1.3927, G loss: 0.7057\n",
      "[484/1762] D loss: 1.2520, G loss: 0.7541\n",
      "[564/1762] D loss: 1.3875, G loss: 0.7267\n",
      "[644/1762] D loss: 1.2304, G loss: 0.7612\n",
      "[724/1762] D loss: 1.3841, G loss: 0.6759\n",
      "[804/1762] D loss: 1.2059, G loss: 0.8206\n",
      "[884/1762] D loss: 1.2188, G loss: 0.6781\n",
      "[964/1762] D loss: 1.3917, G loss: 0.6199\n",
      "[1044/1762] D loss: 1.2332, G loss: 0.7364\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.7886\n",
      "[1204/1762] D loss: 1.4015, G loss: 0.6013\n",
      "[1284/1762] D loss: 1.3726, G loss: 0.6909\n",
      "[1364/1762] D loss: 1.2280, G loss: 0.7293\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6844\n",
      "[1524/1762] D loss: 1.3609, G loss: 0.6500\n",
      "[1604/1762] D loss: 1.5448, G loss: 0.5095\n",
      "[1684/1762] D loss: 1.6320, G loss: 0.6841\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.7033\n",
      "train error: \n",
      " D loss: 1.375919, G loss: 0.629565, D accuracy: 53.0%, cell accuracy: 97.6%, board accuracy: 9.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365496, G loss: 0.647242, D accuracy: 54.1%, cell accuracy: 97.6%, board accuracy: 8.9% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3629, G loss: 0.5892\n",
      "[84/1762] D loss: 1.2458, G loss: 0.8787\n",
      "[164/1762] D loss: 0.9938, G loss: 0.9150\n",
      "[244/1762] D loss: 1.0584, G loss: 0.9786\n",
      "[324/1762] D loss: 1.4181, G loss: 0.8415\n",
      "[404/1762] D loss: 1.4097, G loss: 0.7339\n",
      "[484/1762] D loss: 1.4415, G loss: 0.6636\n",
      "[564/1762] D loss: 1.3082, G loss: 0.6899\n",
      "[644/1762] D loss: 1.4083, G loss: 0.5688\n",
      "[724/1762] D loss: 1.3817, G loss: 0.7020\n",
      "[804/1762] D loss: 1.3911, G loss: 0.7005\n",
      "[884/1762] D loss: 1.4931, G loss: 0.8341\n",
      "[964/1762] D loss: 1.3790, G loss: 0.6565\n",
      "[1044/1762] D loss: 1.4458, G loss: 0.7436\n",
      "[1124/1762] D loss: 1.4310, G loss: 0.7714\n",
      "[1204/1762] D loss: 1.3824, G loss: 0.6894\n",
      "[1284/1762] D loss: 1.3846, G loss: 0.6976\n",
      "[1364/1762] D loss: 1.4044, G loss: 0.6572\n",
      "[1444/1762] D loss: 1.4041, G loss: 0.7006\n",
      "[1524/1762] D loss: 1.3941, G loss: 0.6921\n",
      "[1604/1762] D loss: 1.3970, G loss: 0.6886\n",
      "[1684/1762] D loss: 1.3995, G loss: 0.6823\n",
      "[1762/1762] D loss: 1.3991, G loss: 0.7009\n",
      "train error: \n",
      " D loss: 1.395875, G loss: 0.705716, D accuracy: 48.3%, cell accuracy: 99.6%, board accuracy: 53.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400311, G loss: 0.710506, D accuracy: 47.2%, cell accuracy: 99.5%, board accuracy: 50.9% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.7354\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6943\n",
      "[164/1762] D loss: 1.3748, G loss: 0.7825\n",
      "[244/1762] D loss: 1.3816, G loss: 0.6670\n",
      "[324/1762] D loss: 1.3942, G loss: 0.6954\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7114\n",
      "[484/1762] D loss: 1.3846, G loss: 0.7382\n",
      "[564/1762] D loss: 1.3850, G loss: 0.6849\n",
      "[644/1762] D loss: 1.4152, G loss: 0.6657\n",
      "[724/1762] D loss: 1.3616, G loss: 0.6746\n",
      "[804/1762] D loss: 1.3510, G loss: 0.6483\n",
      "[884/1762] D loss: 1.3445, G loss: 0.6909\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6943\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.7317\n",
      "[1124/1762] D loss: 1.3952, G loss: 0.6427\n",
      "[1204/1762] D loss: 1.2905, G loss: 0.7378\n",
      "[1284/1762] D loss: 1.3819, G loss: 0.7321\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.6338\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.6831\n",
      "[1524/1762] D loss: 1.3153, G loss: 0.7370\n",
      "[1604/1762] D loss: 1.3853, G loss: 0.6867\n",
      "[1684/1762] D loss: 1.3851, G loss: 0.7838\n",
      "[1762/1762] D loss: 1.3568, G loss: 0.6808\n",
      "train error: \n",
      " D loss: 1.373644, G loss: 0.707337, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 72.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372264, G loss: 0.707658, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 67.7% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6889\n",
      "[84/1762] D loss: 1.3272, G loss: 0.7777\n",
      "[164/1762] D loss: 1.3876, G loss: 0.7073\n",
      "[244/1762] D loss: 1.4325, G loss: 0.6331\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6680\n",
      "[404/1762] D loss: 1.3892, G loss: 0.7135\n",
      "[484/1762] D loss: 1.3910, G loss: 0.7354\n",
      "[564/1762] D loss: 1.3812, G loss: 0.7292\n",
      "[644/1762] D loss: 1.2730, G loss: 0.7048\n",
      "[724/1762] D loss: 1.3915, G loss: 0.7619\n",
      "[804/1762] D loss: 1.3917, G loss: 0.6484\n",
      "[884/1762] D loss: 1.4210, G loss: 0.7048\n",
      "[964/1762] D loss: 1.3913, G loss: 0.6969\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.7062\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.6977\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.6799\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6674\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.7449\n",
      "[1444/1762] D loss: 1.3918, G loss: 0.6860\n",
      "[1524/1762] D loss: 1.2705, G loss: 0.7810\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6810\n",
      "[1684/1762] D loss: 1.2839, G loss: 0.7700\n",
      "[1762/1762] D loss: 1.3961, G loss: 0.6427\n",
      "train error: \n",
      " D loss: 1.365307, G loss: 0.652794, D accuracy: 53.6%, cell accuracy: 99.5%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358935, G loss: 0.654986, D accuracy: 55.2%, cell accuracy: 99.4%, board accuracy: 52.7% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2787, G loss: 0.6740\n",
      "[84/1762] D loss: 1.3948, G loss: 0.7151\n",
      "[164/1762] D loss: 1.3798, G loss: 0.6520\n",
      "[244/1762] D loss: 1.3860, G loss: 0.7157\n",
      "[324/1762] D loss: 1.3753, G loss: 0.6977\n",
      "[404/1762] D loss: 1.3909, G loss: 0.6756\n",
      "[484/1762] D loss: 1.4247, G loss: 0.7269\n",
      "[564/1762] D loss: 1.2597, G loss: 0.7554\n",
      "[644/1762] D loss: 1.3748, G loss: 0.6947\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6960\n",
      "[804/1762] D loss: 1.2540, G loss: 0.7795\n",
      "[884/1762] D loss: 1.3877, G loss: 0.6944\n",
      "[964/1762] D loss: 1.3855, G loss: 0.6986\n",
      "[1044/1762] D loss: 1.3915, G loss: 0.7194\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.7176\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.6486\n",
      "[1284/1762] D loss: 1.4134, G loss: 0.7804\n",
      "[1364/1762] D loss: 1.4060, G loss: 0.5795\n",
      "[1444/1762] D loss: 1.1198, G loss: 0.9862\n",
      "[1524/1762] D loss: 1.1073, G loss: 0.8136\n",
      "[1604/1762] D loss: 1.3353, G loss: 0.7719\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7134\n",
      "[1762/1762] D loss: 1.4087, G loss: 0.8377\n",
      "train error: \n",
      " D loss: 1.357931, G loss: 0.768238, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348857, G loss: 0.768005, D accuracy: 54.3%, cell accuracy: 99.5%, board accuracy: 53.6% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3771, G loss: 0.7540\n",
      "[84/1762] D loss: 1.3605, G loss: 0.7855\n",
      "[164/1762] D loss: 1.2484, G loss: 0.7452\n",
      "[244/1762] D loss: 1.4190, G loss: 0.6373\n",
      "[324/1762] D loss: 1.3929, G loss: 0.7315\n",
      "[404/1762] D loss: 1.3989, G loss: 0.7034\n",
      "[484/1762] D loss: 1.4118, G loss: 0.6621\n",
      "[564/1762] D loss: 1.7556, G loss: 0.6424\n",
      "[644/1762] D loss: 1.5034, G loss: 0.5589\n",
      "[724/1762] D loss: 1.2665, G loss: 0.9258\n",
      "[804/1762] D loss: 1.1362, G loss: 0.8925\n",
      "[884/1762] D loss: 0.9094, G loss: 1.2822\n",
      "[964/1762] D loss: 1.4328, G loss: 0.7098\n",
      "[1044/1762] D loss: 1.6163, G loss: 0.7058\n",
      "[1124/1762] D loss: 1.4549, G loss: 0.9011\n",
      "[1204/1762] D loss: 1.4699, G loss: 0.6376\n",
      "[1284/1762] D loss: 1.5519, G loss: 0.7165\n",
      "[1364/1762] D loss: 1.4133, G loss: 0.6369\n",
      "[1444/1762] D loss: 1.4139, G loss: 0.5770\n",
      "[1524/1762] D loss: 1.4395, G loss: 0.6328\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.7252\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6644\n",
      "[1762/1762] D loss: 1.3964, G loss: 0.6758\n",
      "train error: \n",
      " D loss: 1.403516, G loss: 0.653592, D accuracy: 48.1%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408360, G loss: 0.655761, D accuracy: 47.4%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3749, G loss: 0.6918\n",
      "[84/1762] D loss: 1.4006, G loss: 0.7699\n",
      "[164/1762] D loss: 1.3930, G loss: 0.6718\n",
      "[244/1762] D loss: 1.3922, G loss: 0.6532\n",
      "[324/1762] D loss: 1.3573, G loss: 0.7793\n",
      "[404/1762] D loss: 1.3859, G loss: 0.6949\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7047\n",
      "[564/1762] D loss: 1.3934, G loss: 0.7753\n",
      "[644/1762] D loss: 1.3892, G loss: 0.6772\n",
      "[724/1762] D loss: 1.4088, G loss: 0.6753\n",
      "[804/1762] D loss: 1.3828, G loss: 0.7065\n",
      "[884/1762] D loss: 1.3839, G loss: 0.7114\n",
      "[964/1762] D loss: 1.4003, G loss: 0.8055\n",
      "[1044/1762] D loss: 1.3421, G loss: 0.7214\n",
      "[1124/1762] D loss: 1.3466, G loss: 0.6996\n",
      "[1204/1762] D loss: 1.3445, G loss: 0.7393\n",
      "[1284/1762] D loss: 1.3843, G loss: 0.7438\n",
      "[1364/1762] D loss: 1.3987, G loss: 0.6191\n",
      "[1444/1762] D loss: 1.3415, G loss: 0.7005\n",
      "[1524/1762] D loss: 1.3008, G loss: 0.7310\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.7371\n",
      "[1684/1762] D loss: 1.3415, G loss: 0.7162\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.7327\n",
      "train error: \n",
      " D loss: 1.371815, G loss: 0.729952, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 76.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369056, G loss: 0.729951, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 71.8% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904, G loss: 0.7383\n",
      "[84/1762] D loss: 1.3897, G loss: 0.6651\n",
      "[164/1762] D loss: 1.2797, G loss: 0.7707\n",
      "[244/1762] D loss: 1.3876, G loss: 0.7008\n",
      "[324/1762] D loss: 1.3207, G loss: 0.7280\n",
      "[404/1762] D loss: 1.2876, G loss: 0.7536\n",
      "[484/1762] D loss: 1.2895, G loss: 0.7000\n",
      "[564/1762] D loss: 1.3848, G loss: 0.6912\n",
      "[644/1762] D loss: 1.3947, G loss: 0.6473\n",
      "[724/1762] D loss: 1.3924, G loss: 0.6386\n",
      "[804/1762] D loss: 1.3770, G loss: 0.7138\n",
      "[884/1762] D loss: 1.3834, G loss: 0.7266\n",
      "[964/1762] D loss: 1.3835, G loss: 0.7109\n",
      "[1044/1762] D loss: 1.3826, G loss: 0.7499\n",
      "[1124/1762] D loss: 1.2772, G loss: 0.7869\n",
      "[1204/1762] D loss: 1.2569, G loss: 0.7070\n",
      "[1284/1762] D loss: 1.4116, G loss: 0.7581\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.7256\n",
      "[1444/1762] D loss: 1.2511, G loss: 0.7543\n",
      "[1524/1762] D loss: 1.3846, G loss: 0.7119\n",
      "[1604/1762] D loss: 1.3184, G loss: 0.7971\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6573\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7383\n",
      "train error: \n",
      " D loss: 1.359361, G loss: 0.749422, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351394, G loss: 0.749952, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.7448\n",
      "[84/1762] D loss: 1.3903, G loss: 0.6303\n",
      "[164/1762] D loss: 1.3914, G loss: 0.7416\n",
      "[244/1762] D loss: 1.3903, G loss: 0.6729\n",
      "[324/1762] D loss: 1.3960, G loss: 0.7991\n",
      "[404/1762] D loss: 1.4084, G loss: 0.6893\n",
      "[484/1762] D loss: 1.4245, G loss: 0.8638\n",
      "[564/1762] D loss: 1.3884, G loss: 0.6529\n",
      "[644/1762] D loss: 1.3892, G loss: 0.6910\n",
      "[724/1762] D loss: 1.3993, G loss: 0.7328\n",
      "[804/1762] D loss: 1.3924, G loss: 0.6375\n",
      "[884/1762] D loss: 1.3784, G loss: 0.7246\n",
      "[964/1762] D loss: 1.2336, G loss: 0.7026\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.7665\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6529\n",
      "[1204/1762] D loss: 1.3930, G loss: 0.7577\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.7381\n",
      "[1364/1762] D loss: 1.3923, G loss: 0.7608\n",
      "[1444/1762] D loss: 1.2488, G loss: 0.7922\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.7228\n",
      "[1604/1762] D loss: 1.3949, G loss: 0.7692\n",
      "[1684/1762] D loss: 1.4069, G loss: 0.6174\n",
      "[1762/1762] D loss: 1.4013, G loss: 0.7155\n",
      "train error: \n",
      " D loss: 1.352710, G loss: 0.655373, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343538, G loss: 0.652984, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2378, G loss: 0.6650\n",
      "[84/1762] D loss: 1.2215, G loss: 0.7593\n",
      "[164/1762] D loss: 1.3975, G loss: 0.7271\n",
      "[244/1762] D loss: 1.3890, G loss: 0.6762\n",
      "[324/1762] D loss: 1.3937, G loss: 0.6186\n",
      "[404/1762] D loss: 1.2028, G loss: 0.7711\n",
      "[484/1762] D loss: 1.4792, G loss: 0.5349\n",
      "[564/1762] D loss: 1.3906, G loss: 0.7425\n",
      "[644/1762] D loss: 1.3914, G loss: 0.6114\n",
      "[724/1762] D loss: 1.0624, G loss: 0.8418\n",
      "[804/1762] D loss: 1.4299, G loss: 0.8796\n",
      "[884/1762] D loss: 1.4054, G loss: 0.5962\n",
      "[964/1762] D loss: 1.3920, G loss: 0.7802\n",
      "[1044/1762] D loss: 1.2236, G loss: 0.9375\n",
      "[1124/1762] D loss: 1.3942, G loss: 0.6977\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.7751\n",
      "[1284/1762] D loss: 1.1832, G loss: 0.7903\n",
      "[1364/1762] D loss: 1.2975, G loss: 0.7392\n",
      "[1444/1762] D loss: 1.3788, G loss: 0.7042\n",
      "[1524/1762] D loss: 1.3582, G loss: 0.8638\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.7336\n",
      "[1684/1762] D loss: 1.2037, G loss: 0.7678\n",
      "[1762/1762] D loss: 1.3853, G loss: 0.7172\n",
      "train error: \n",
      " D loss: 1.321042, G loss: 0.746549, D accuracy: 59.1%, cell accuracy: 99.0%, board accuracy: 20.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307168, G loss: 0.750139, D accuracy: 59.3%, cell accuracy: 98.9%, board accuracy: 21.1% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3592, G loss: 0.6810\n",
      "[84/1762] D loss: 1.2031, G loss: 0.7451\n",
      "[164/1762] D loss: 1.4159, G loss: 0.9247\n",
      "[244/1762] D loss: 1.2869, G loss: 0.7375\n",
      "[324/1762] D loss: 1.3964, G loss: 0.6098\n",
      "[404/1762] D loss: 1.4088, G loss: 0.7086\n",
      "[484/1762] D loss: 1.3781, G loss: 0.7309\n",
      "[564/1762] D loss: 1.2046, G loss: 0.7231\n",
      "[644/1762] D loss: 1.2266, G loss: 0.7702\n",
      "[724/1762] D loss: 1.3953, G loss: 0.7203\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6963\n",
      "[884/1762] D loss: 1.4015, G loss: 0.7851\n",
      "[964/1762] D loss: 1.2100, G loss: 0.6945\n",
      "[1044/1762] D loss: 1.3957, G loss: 0.6963\n",
      "[1124/1762] D loss: 1.3822, G loss: 0.7106\n",
      "[1204/1762] D loss: 1.4033, G loss: 0.8123\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.6833\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.7182\n",
      "[1444/1762] D loss: 1.2554, G loss: 0.7351\n",
      "[1524/1762] D loss: 1.2337, G loss: 0.6599\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6977\n",
      "[1684/1762] D loss: 1.3901, G loss: 0.7019\n",
      "[1762/1762] D loss: 1.3545, G loss: 0.6524\n",
      "train error: \n",
      " D loss: 1.358892, G loss: 0.852767, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 72.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340700, G loss: 0.856887, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 66.1% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4234, G loss: 0.9009\n",
      "[84/1762] D loss: 1.5322, G loss: 0.5792\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7452\n",
      "[244/1762] D loss: 1.2246, G loss: 0.6833\n",
      "[324/1762] D loss: 1.4193, G loss: 0.5425\n",
      "[404/1762] D loss: 1.2140, G loss: 0.8286\n",
      "[484/1762] D loss: 1.2610, G loss: 0.7114\n",
      "[564/1762] D loss: 1.2227, G loss: 0.9077\n",
      "[644/1762] D loss: 1.4028, G loss: 0.7443\n",
      "[724/1762] D loss: 1.3916, G loss: 0.7054\n",
      "[804/1762] D loss: 1.0357, G loss: 0.7895\n",
      "[884/1762] D loss: 1.3990, G loss: 0.7317\n",
      "[964/1762] D loss: 1.3959, G loss: 0.7009\n",
      "[1044/1762] D loss: 1.4025, G loss: 0.7741\n",
      "[1124/1762] D loss: 1.5940, G loss: 0.4391\n",
      "[1204/1762] D loss: 1.5643, G loss: 0.7476\n",
      "[1284/1762] D loss: 1.5731, G loss: 0.7308\n",
      "[1364/1762] D loss: 1.2839, G loss: 1.0635\n",
      "[1444/1762] D loss: 1.4293, G loss: 0.8905\n",
      "[1524/1762] D loss: 1.1442, G loss: 0.6762\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7097\n",
      "[1684/1762] D loss: 1.4759, G loss: 0.8695\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.6598\n",
      "train error: \n",
      " D loss: 1.444731, G loss: 0.684630, D accuracy: 48.9%, cell accuracy: 99.8%, board accuracy: 82.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.452944, G loss: 0.697829, D accuracy: 49.2%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3993, G loss: 0.6404\n",
      "[84/1762] D loss: 1.3855, G loss: 0.7805\n",
      "[164/1762] D loss: 1.5383, G loss: 0.8951\n",
      "[244/1762] D loss: 1.4623, G loss: 0.7060\n",
      "[324/1762] D loss: 1.3937, G loss: 0.6326\n",
      "[404/1762] D loss: 1.3896, G loss: 0.6790\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6863\n",
      "[564/1762] D loss: 1.4997, G loss: 0.5995\n",
      "[644/1762] D loss: 1.4004, G loss: 0.6873\n",
      "[724/1762] D loss: 1.4274, G loss: 0.7734\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7046\n",
      "[884/1762] D loss: 1.3815, G loss: 0.6999\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6767\n",
      "[1044/1762] D loss: 1.3906, G loss: 0.6592\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.6502\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.6708\n",
      "[1284/1762] D loss: 1.3960, G loss: 0.5966\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6954\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.7657\n",
      "[1524/1762] D loss: 1.3945, G loss: 0.7526\n",
      "[1604/1762] D loss: 1.3541, G loss: 0.7230\n",
      "[1684/1762] D loss: 1.3886, G loss: 0.7323\n",
      "[1762/1762] D loss: 1.3839, G loss: 0.6959\n",
      "train error: \n",
      " D loss: 1.381287, G loss: 0.751519, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378673, G loss: 0.757723, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3407, G loss: 0.7720\n",
      "[84/1762] D loss: 1.3211, G loss: 0.6921\n",
      "[164/1762] D loss: 1.3981, G loss: 0.6454\n",
      "[244/1762] D loss: 1.3076, G loss: 0.7525\n",
      "[324/1762] D loss: 1.3077, G loss: 0.7768\n",
      "[404/1762] D loss: 1.3831, G loss: 0.7497\n",
      "[484/1762] D loss: 1.3949, G loss: 0.6653\n",
      "[564/1762] D loss: 1.3884, G loss: 0.6847\n",
      "[644/1762] D loss: 1.3977, G loss: 0.7057\n",
      "[724/1762] D loss: 1.4169, G loss: 0.7018\n",
      "[804/1762] D loss: 1.3916, G loss: 0.6949\n",
      "[884/1762] D loss: 1.3904, G loss: 0.6916\n",
      "[964/1762] D loss: 1.2788, G loss: 0.7554\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6860\n",
      "[1124/1762] D loss: 1.2750, G loss: 0.7126\n",
      "[1204/1762] D loss: 1.3783, G loss: 0.7091\n",
      "[1284/1762] D loss: 1.3907, G loss: 0.7296\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.7590\n",
      "[1444/1762] D loss: 1.3587, G loss: 0.7833\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.7274\n",
      "[1604/1762] D loss: 1.3815, G loss: 0.6757\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.7150\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7149\n",
      "train error: \n",
      " D loss: 1.364910, G loss: 0.729444, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 82.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358555, G loss: 0.734461, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3306, G loss: 0.7471\n",
      "[84/1762] D loss: 1.3929, G loss: 0.7221\n",
      "[164/1762] D loss: 1.2642, G loss: 0.7058\n",
      "[244/1762] D loss: 1.3720, G loss: 0.7335\n",
      "[324/1762] D loss: 1.3182, G loss: 0.7236\n",
      "[404/1762] D loss: 1.2588, G loss: 0.7394\n",
      "[484/1762] D loss: 1.2779, G loss: 0.7048\n",
      "[564/1762] D loss: 1.3990, G loss: 0.7109\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6772\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6994\n",
      "[804/1762] D loss: 1.3861, G loss: 0.7135\n",
      "[884/1762] D loss: 1.4093, G loss: 0.7975\n",
      "[964/1762] D loss: 1.3870, G loss: 0.7498\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.6657\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.6314\n",
      "[1204/1762] D loss: 1.2693, G loss: 0.8624\n",
      "[1284/1762] D loss: 1.3919, G loss: 0.6660\n",
      "[1364/1762] D loss: 1.3896, G loss: 0.7153\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7038\n",
      "[1524/1762] D loss: 1.3558, G loss: 0.8037\n",
      "[1604/1762] D loss: 1.4029, G loss: 0.6252\n",
      "[1684/1762] D loss: 1.3938, G loss: 0.6575\n",
      "[1762/1762] D loss: 1.4074, G loss: 0.5948\n",
      "train error: \n",
      " D loss: 1.353701, G loss: 0.747834, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343546, G loss: 0.751264, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.7658\n",
      "[84/1762] D loss: 1.2268, G loss: 0.8285\n",
      "[164/1762] D loss: 1.3942, G loss: 0.6569\n",
      "[244/1762] D loss: 1.3700, G loss: 0.7478\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6690\n",
      "[404/1762] D loss: 1.3834, G loss: 0.7258\n",
      "[484/1762] D loss: 1.2566, G loss: 0.7296\n",
      "[564/1762] D loss: 1.1835, G loss: 0.9050\n",
      "[644/1762] D loss: 1.3965, G loss: 0.5888\n",
      "[724/1762] D loss: 1.4007, G loss: 0.6776\n",
      "[804/1762] D loss: 1.2384, G loss: 0.7903\n",
      "[884/1762] D loss: 1.3969, G loss: 0.8033\n",
      "[964/1762] D loss: 1.3881, G loss: 0.6486\n",
      "[1044/1762] D loss: 1.3985, G loss: 0.7465\n",
      "[1124/1762] D loss: 1.2450, G loss: 0.6751\n",
      "[1204/1762] D loss: 1.3548, G loss: 0.7892\n",
      "[1284/1762] D loss: 1.3510, G loss: 0.6772\n",
      "[1364/1762] D loss: 1.1516, G loss: 0.8324\n",
      "[1444/1762] D loss: 1.4139, G loss: 0.7862\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.6601\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.6804\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.7497\n",
      "[1762/1762] D loss: 1.4127, G loss: 0.6211\n",
      "train error: \n",
      " D loss: 1.353092, G loss: 0.676678, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 73.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340042, G loss: 0.683132, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2502, G loss: 0.6819\n",
      "[84/1762] D loss: 1.3907, G loss: 0.7472\n",
      "[164/1762] D loss: 1.3963, G loss: 0.6618\n",
      "[244/1762] D loss: 1.3891, G loss: 0.7078\n",
      "[324/1762] D loss: 1.2503, G loss: 0.7874\n",
      "[404/1762] D loss: 1.3602, G loss: 0.7304\n",
      "[484/1762] D loss: 1.3852, G loss: 0.7475\n",
      "[564/1762] D loss: 1.4047, G loss: 0.6947\n",
      "[644/1762] D loss: 1.4050, G loss: 0.8087\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6806\n",
      "[804/1762] D loss: 1.2199, G loss: 0.7720\n",
      "[884/1762] D loss: 1.4068, G loss: 0.8071\n",
      "[964/1762] D loss: 1.2598, G loss: 0.6026\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.7463\n",
      "[1124/1762] D loss: 1.3790, G loss: 0.7087\n",
      "[1204/1762] D loss: 1.5139, G loss: 0.6369\n",
      "[1284/1762] D loss: 1.2135, G loss: 0.9062\n",
      "[1364/1762] D loss: 2.1287, G loss: 0.5334\n",
      "[1444/1762] D loss: 1.6799, G loss: 0.5404\n",
      "[1524/1762] D loss: 1.4074, G loss: 0.8668\n",
      "[1604/1762] D loss: 1.1016, G loss: 0.7801\n",
      "[1684/1762] D loss: 1.1012, G loss: 0.8646\n",
      "[1762/1762] D loss: 0.9617, G loss: 0.8621\n",
      "train error: \n",
      " D loss: 1.152567, G loss: 0.837308, D accuracy: 74.4%, cell accuracy: 99.0%, board accuracy: 21.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.166752, G loss: 0.845429, D accuracy: 74.1%, cell accuracy: 98.9%, board accuracy: 23.0% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9495, G loss: 0.9797\n",
      "[84/1762] D loss: 1.4124, G loss: 0.6032\n",
      "[164/1762] D loss: 1.3753, G loss: 0.8955\n",
      "[244/1762] D loss: 1.4165, G loss: 0.7541\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7004\n",
      "[404/1762] D loss: 1.3741, G loss: 0.6591\n",
      "[484/1762] D loss: 1.4006, G loss: 0.6191\n",
      "[564/1762] D loss: 1.3953, G loss: 0.6588\n",
      "[644/1762] D loss: 1.4114, G loss: 0.7359\n",
      "[724/1762] D loss: 1.4059, G loss: 0.6316\n",
      "[804/1762] D loss: 1.3745, G loss: 0.6776\n",
      "[884/1762] D loss: 1.3382, G loss: 0.7218\n",
      "[964/1762] D loss: 1.4091, G loss: 0.7732\n",
      "[1044/1762] D loss: 1.3894, G loss: 0.6604\n",
      "[1124/1762] D loss: 1.4054, G loss: 0.6924\n",
      "[1204/1762] D loss: 1.3954, G loss: 0.7454\n",
      "[1284/1762] D loss: 1.3362, G loss: 0.7608\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6769\n",
      "[1444/1762] D loss: 1.3003, G loss: 0.7661\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.6316\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7454\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.6503\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.6529\n",
      "train error: \n",
      " D loss: 1.369160, G loss: 0.679822, D accuracy: 53.9%, cell accuracy: 99.6%, board accuracy: 54.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365483, G loss: 0.680770, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 49.8% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.6525\n",
      "[84/1762] D loss: 1.3959, G loss: 0.8011\n",
      "[164/1762] D loss: 1.4163, G loss: 0.7602\n",
      "[244/1762] D loss: 1.3908, G loss: 0.7385\n",
      "[324/1762] D loss: 1.3673, G loss: 0.6850\n",
      "[404/1762] D loss: 1.3255, G loss: 0.7357\n",
      "[484/1762] D loss: 1.3513, G loss: 0.7192\n",
      "[564/1762] D loss: 1.3266, G loss: 0.7274\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6968\n",
      "[724/1762] D loss: 1.3911, G loss: 0.7319\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6665\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6941\n",
      "[964/1762] D loss: 1.3899, G loss: 0.7528\n",
      "[1044/1762] D loss: 1.2783, G loss: 0.7447\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.6931\n",
      "[1204/1762] D loss: 1.2787, G loss: 0.7389\n",
      "[1284/1762] D loss: 1.3942, G loss: 0.6588\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.7467\n",
      "[1444/1762] D loss: 1.3809, G loss: 0.6825\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.7347\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6722\n",
      "[1684/1762] D loss: 1.2373, G loss: 0.7641\n",
      "[1762/1762] D loss: 1.3945, G loss: 0.7219\n",
      "train error: \n",
      " D loss: 1.355331, G loss: 0.773928, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 80.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344846, G loss: 0.772283, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3970, G loss: 0.7864\n",
      "[84/1762] D loss: 1.2506, G loss: 0.7984\n",
      "[164/1762] D loss: 1.2393, G loss: 0.7741\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6945\n",
      "[324/1762] D loss: 1.3799, G loss: 0.7050\n",
      "[404/1762] D loss: 1.3887, G loss: 0.7619\n",
      "[484/1762] D loss: 1.2023, G loss: 0.7665\n",
      "[564/1762] D loss: 1.4014, G loss: 0.7917\n",
      "[644/1762] D loss: 1.3967, G loss: 0.6162\n",
      "[724/1762] D loss: 1.3884, G loss: 0.7087\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6346\n",
      "[884/1762] D loss: 1.4026, G loss: 0.6368\n",
      "[964/1762] D loss: 1.5188, G loss: 0.5900\n",
      "[1044/1762] D loss: 1.5577, G loss: 0.5224\n",
      "[1124/1762] D loss: 1.4437, G loss: 0.6341\n",
      "[1204/1762] D loss: 1.3782, G loss: 0.6424\n",
      "[1284/1762] D loss: 1.3599, G loss: 0.8113\n",
      "[1364/1762] D loss: 1.4172, G loss: 0.6294\n",
      "[1444/1762] D loss: 1.4732, G loss: 0.6009\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7395\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.6915\n",
      "[1684/1762] D loss: 1.4472, G loss: 0.6991\n",
      "[1762/1762] D loss: 1.3541, G loss: 0.7168\n",
      "train error: \n",
      " D loss: 1.383641, G loss: 0.706163, D accuracy: 53.2%, cell accuracy: 98.9%, board accuracy: 33.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383567, G loss: 0.708947, D accuracy: 53.3%, cell accuracy: 98.8%, board accuracy: 31.4% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3636, G loss: 0.7003\n",
      "[84/1762] D loss: 1.4057, G loss: 0.6028\n",
      "[164/1762] D loss: 1.3741, G loss: 0.7029\n",
      "[244/1762] D loss: 1.3702, G loss: 0.7098\n",
      "[324/1762] D loss: 1.4145, G loss: 0.6987\n",
      "[404/1762] D loss: 1.3538, G loss: 0.6829\n",
      "[484/1762] D loss: 1.3828, G loss: 0.6540\n",
      "[564/1762] D loss: 1.4017, G loss: 0.6104\n",
      "[644/1762] D loss: 1.3863, G loss: 0.7066\n",
      "[724/1762] D loss: 1.3301, G loss: 0.7360\n",
      "[804/1762] D loss: 1.3969, G loss: 0.6676\n",
      "[884/1762] D loss: 1.3807, G loss: 0.6760\n",
      "[964/1762] D loss: 1.3396, G loss: 0.6950\n",
      "[1044/1762] D loss: 1.3510, G loss: 0.6576\n",
      "[1124/1762] D loss: 1.3530, G loss: 0.6613\n",
      "[1204/1762] D loss: 1.3929, G loss: 0.6784\n",
      "[1284/1762] D loss: 1.4028, G loss: 0.6084\n",
      "[1364/1762] D loss: 1.3058, G loss: 0.8355\n",
      "[1444/1762] D loss: 1.2201, G loss: 0.8102\n",
      "[1524/1762] D loss: 1.3613, G loss: 0.7365\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6960\n",
      "[1684/1762] D loss: 1.3200, G loss: 0.7881\n",
      "[1762/1762] D loss: 1.3831, G loss: 0.6590\n",
      "train error: \n",
      " D loss: 1.364458, G loss: 0.672772, D accuracy: 53.3%, cell accuracy: 99.5%, board accuracy: 47.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359052, G loss: 0.672172, D accuracy: 53.6%, cell accuracy: 99.4%, board accuracy: 43.2% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3074, G loss: 0.7182\n",
      "[84/1762] D loss: 1.3919, G loss: 0.7757\n",
      "[164/1762] D loss: 1.3797, G loss: 0.6660\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7024\n",
      "[324/1762] D loss: 1.3844, G loss: 0.7069\n",
      "[404/1762] D loss: 1.1072, G loss: 0.8154\n",
      "[484/1762] D loss: 1.2457, G loss: 0.8093\n",
      "[564/1762] D loss: 1.2461, G loss: 0.6781\n",
      "[644/1762] D loss: 1.3835, G loss: 0.7396\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6626\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6853\n",
      "[884/1762] D loss: 1.2544, G loss: 0.7892\n",
      "[964/1762] D loss: 1.3987, G loss: 0.7755\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6909\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.7504\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.7190\n",
      "[1284/1762] D loss: 1.3636, G loss: 0.7268\n",
      "[1364/1762] D loss: 1.3758, G loss: 0.7251\n",
      "[1444/1762] D loss: 1.2307, G loss: 0.7946\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6719\n",
      "[1604/1762] D loss: 1.3941, G loss: 0.6447\n",
      "[1684/1762] D loss: 1.2484, G loss: 0.7916\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6184\n",
      "train error: \n",
      " D loss: 1.357552, G loss: 0.643028, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 80.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349153, G loss: 0.641303, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6533\n",
      "[84/1762] D loss: 1.2424, G loss: 0.7150\n",
      "[164/1762] D loss: 1.3959, G loss: 0.7609\n",
      "[244/1762] D loss: 1.3876, G loss: 0.7216\n",
      "[324/1762] D loss: 1.2481, G loss: 0.7214\n",
      "[404/1762] D loss: 1.3953, G loss: 0.6670\n",
      "[484/1762] D loss: 1.2529, G loss: 0.7186\n",
      "[564/1762] D loss: 1.3849, G loss: 0.7181\n",
      "[644/1762] D loss: 1.3945, G loss: 0.7648\n",
      "[724/1762] D loss: 1.4046, G loss: 0.6231\n",
      "[804/1762] D loss: 1.3897, G loss: 0.7095\n",
      "[884/1762] D loss: 1.4418, G loss: 0.6773\n",
      "[964/1762] D loss: 1.6353, G loss: 0.5605\n",
      "[1044/1762] D loss: 1.4241, G loss: 0.6095\n",
      "[1124/1762] D loss: 1.2362, G loss: 0.6814\n",
      "[1204/1762] D loss: 1.2344, G loss: 0.8252\n",
      "[1284/1762] D loss: 1.1933, G loss: 0.8319\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7150\n",
      "[1444/1762] D loss: 1.3158, G loss: 0.7587\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.7026\n",
      "[1604/1762] D loss: 1.3897, G loss: 0.6071\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.7401\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6399\n",
      "train error: \n",
      " D loss: 1.372277, G loss: 0.640778, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 78.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367531, G loss: 0.640207, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3939, G loss: 0.6071\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7171\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6344\n",
      "[244/1762] D loss: 1.3968, G loss: 0.6876\n",
      "[324/1762] D loss: 1.3911, G loss: 0.7654\n",
      "[404/1762] D loss: 1.3883, G loss: 0.7120\n",
      "[484/1762] D loss: 1.2565, G loss: 0.8109\n",
      "[564/1762] D loss: 1.3912, G loss: 0.7092\n",
      "[644/1762] D loss: 1.3891, G loss: 0.7037\n",
      "[724/1762] D loss: 1.2388, G loss: 0.6865\n",
      "[804/1762] D loss: 1.4053, G loss: 0.7863\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7260\n",
      "[964/1762] D loss: 1.4191, G loss: 0.5491\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6706\n",
      "[1124/1762] D loss: 1.3796, G loss: 0.7114\n",
      "[1204/1762] D loss: 1.3820, G loss: 0.6603\n",
      "[1284/1762] D loss: 1.4268, G loss: 0.8218\n",
      "[1364/1762] D loss: 1.3817, G loss: 0.7467\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6786\n",
      "[1524/1762] D loss: 1.3994, G loss: 0.6677\n",
      "[1604/1762] D loss: 1.2078, G loss: 0.8399\n",
      "[1684/1762] D loss: 1.3368, G loss: 0.6497\n",
      "[1762/1762] D loss: 1.4183, G loss: 0.9087\n",
      "train error: \n",
      " D loss: 1.391794, G loss: 0.946247, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 77.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379547, G loss: 0.940615, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.7179\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7103\n",
      "[164/1762] D loss: 1.3862, G loss: 0.7037\n",
      "[244/1762] D loss: 1.3859, G loss: 0.6984\n",
      "[324/1762] D loss: 1.3851, G loss: 0.6942\n",
      "[404/1762] D loss: 1.3834, G loss: 0.6926\n",
      "[484/1762] D loss: 1.3802, G loss: 0.6918\n",
      "[564/1762] D loss: 1.3740, G loss: 0.6933\n",
      "[644/1762] D loss: 1.3624, G loss: 0.6983\n",
      "[724/1762] D loss: 1.3446, G loss: 0.7061\n",
      "[804/1762] D loss: 1.3079, G loss: 0.7260\n",
      "[884/1762] D loss: 1.2604, G loss: 0.7430\n",
      "[964/1762] D loss: 1.1990, G loss: 0.7636\n",
      "[1044/1762] D loss: 1.1717, G loss: 0.7557\n",
      "[1124/1762] D loss: 1.1048, G loss: 0.7766\n",
      "[1204/1762] D loss: 1.0494, G loss: 0.7682\n",
      "[1284/1762] D loss: 0.9775, G loss: 0.7793\n",
      "[1364/1762] D loss: 0.8747, G loss: 0.8968\n",
      "[1444/1762] D loss: 0.7799, G loss: 1.0238\n",
      "[1524/1762] D loss: 0.7053, G loss: 1.3469\n",
      "[1604/1762] D loss: 0.7399, G loss: 1.4079\n",
      "[1684/1762] D loss: 0.4707, G loss: 1.8844\n",
      "[1762/1762] D loss: 0.5134, G loss: 1.9113\n",
      "train error: \n",
      " D loss: 0.417633, G loss: 2.083860, D accuracy: 94.5%, cell accuracy: 68.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.402810, G loss: 2.137476, D accuracy: 94.7%, cell accuracy: 67.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3385, G loss: 1.8468\n",
      "[84/1762] D loss: 0.3280, G loss: 2.2464\n",
      "[164/1762] D loss: 0.3123, G loss: 2.5778\n",
      "[244/1762] D loss: 0.3476, G loss: 2.8789\n",
      "[324/1762] D loss: 0.3754, G loss: 2.7611\n",
      "[404/1762] D loss: 0.4699, G loss: 3.5783\n",
      "[484/1762] D loss: 0.3917, G loss: 3.2034\n",
      "[564/1762] D loss: 0.2696, G loss: 3.4683\n",
      "[644/1762] D loss: 0.4069, G loss: 3.7110\n",
      "[724/1762] D loss: 0.4205, G loss: 4.4317\n",
      "[804/1762] D loss: 0.3293, G loss: 3.3082\n",
      "[884/1762] D loss: 0.2595, G loss: 3.8189\n",
      "[964/1762] D loss: 0.1305, G loss: 4.0223\n",
      "[1044/1762] D loss: 0.2904, G loss: 4.6912\n",
      "[1124/1762] D loss: 0.1365, G loss: 3.9021\n",
      "[1204/1762] D loss: 0.2892, G loss: 3.7831\n",
      "[1284/1762] D loss: 0.3447, G loss: 5.0830\n",
      "[1364/1762] D loss: 0.1352, G loss: 5.5689\n",
      "[1444/1762] D loss: 0.2614, G loss: 4.7665\n",
      "[1524/1762] D loss: 0.0527, G loss: 3.6170\n",
      "[1604/1762] D loss: 0.1087, G loss: 3.8652\n",
      "[1684/1762] D loss: 0.0583, G loss: 3.2490\n",
      "[1762/1762] D loss: 0.0414, G loss: 4.0612\n",
      "train error: \n",
      " D loss: 0.114192, G loss: 3.485291, D accuracy: 99.9%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.122428, G loss: 3.396579, D accuracy: 99.9%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0599, G loss: 3.4314\n",
      "[84/1762] D loss: 0.1817, G loss: 3.3698\n",
      "[164/1762] D loss: 0.0725, G loss: 3.6364\n",
      "[244/1762] D loss: 0.0537, G loss: 3.0830\n",
      "[324/1762] D loss: 0.0744, G loss: 4.0728\n",
      "[404/1762] D loss: 0.1079, G loss: 2.1971\n",
      "[484/1762] D loss: 0.1171, G loss: 4.5300\n",
      "[564/1762] D loss: 0.3265, G loss: 2.3902\n",
      "[644/1762] D loss: 0.0662, G loss: 3.2104\n",
      "[724/1762] D loss: 0.0972, G loss: 3.0415\n",
      "[804/1762] D loss: 0.0818, G loss: 3.2811\n",
      "[884/1762] D loss: 0.0928, G loss: 3.5512\n",
      "[964/1762] D loss: 0.1013, G loss: 3.0016\n",
      "[1044/1762] D loss: 0.1243, G loss: 3.2918\n",
      "[1124/1762] D loss: 0.3506, G loss: 2.5413\n",
      "[1204/1762] D loss: 0.1155, G loss: 1.2897\n",
      "[1284/1762] D loss: 0.4682, G loss: 4.2779\n",
      "[1364/1762] D loss: 0.0493, G loss: 3.7621\n",
      "[1444/1762] D loss: 0.0294, G loss: 4.3457\n",
      "[1524/1762] D loss: 0.3147, G loss: 2.7437\n",
      "[1604/1762] D loss: 0.1745, G loss: 2.8004\n",
      "[1684/1762] D loss: 0.1371, G loss: 3.3218\n",
      "[1762/1762] D loss: 0.0215, G loss: 4.5698\n",
      "train error: \n",
      " D loss: 0.117006, G loss: 3.391049, D accuracy: 99.3%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.134007, G loss: 3.315621, D accuracy: 98.9%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0372, G loss: 4.1868\n",
      "[84/1762] D loss: 0.0313, G loss: 3.6745\n",
      "[164/1762] D loss: 0.1070, G loss: 3.8573\n",
      "[244/1762] D loss: 0.1100, G loss: 3.4190\n",
      "[324/1762] D loss: 0.0529, G loss: 3.3387\n",
      "[404/1762] D loss: 0.2207, G loss: 3.1989\n",
      "[484/1762] D loss: 0.3555, G loss: 4.0042\n",
      "[564/1762] D loss: 0.0834, G loss: 3.1144\n",
      "[644/1762] D loss: 0.0628, G loss: 3.2354\n",
      "[724/1762] D loss: 0.1467, G loss: 3.0718\n",
      "[804/1762] D loss: 0.2601, G loss: 2.9824\n",
      "[884/1762] D loss: 0.3299, G loss: 5.5710\n",
      "[964/1762] D loss: 0.2277, G loss: 3.4985\n",
      "[1044/1762] D loss: 0.0575, G loss: 2.9740\n",
      "[1124/1762] D loss: 0.0243, G loss: 4.1924\n",
      "[1204/1762] D loss: 0.0565, G loss: 4.0855\n",
      "[1284/1762] D loss: 0.0500, G loss: 3.5229\n",
      "[1364/1762] D loss: 0.2621, G loss: 3.4967\n",
      "[1444/1762] D loss: 0.1251, G loss: 3.3872\n",
      "[1524/1762] D loss: 0.3727, G loss: 5.1681\n",
      "[1604/1762] D loss: 0.1270, G loss: 3.0318\n",
      "[1684/1762] D loss: 0.0451, G loss: 3.8183\n",
      "[1762/1762] D loss: 0.0179, G loss: 4.9181\n",
      "train error: \n",
      " D loss: 0.111051, G loss: 3.787249, D accuracy: 99.0%, cell accuracy: 97.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.127047, G loss: 3.702683, D accuracy: 98.9%, cell accuracy: 97.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0177, G loss: 5.0064\n",
      "[84/1762] D loss: 0.0414, G loss: 4.1240\n",
      "[164/1762] D loss: 0.0780, G loss: 3.9448\n",
      "[244/1762] D loss: 0.0325, G loss: 4.4438\n",
      "[324/1762] D loss: 0.1725, G loss: 2.3707\n",
      "[404/1762] D loss: 0.4323, G loss: 3.0827\n",
      "[484/1762] D loss: 0.0299, G loss: 4.6472\n",
      "[564/1762] D loss: 0.0491, G loss: 5.2728\n",
      "[644/1762] D loss: 0.1092, G loss: 3.8960\n",
      "[724/1762] D loss: 0.1009, G loss: 5.2124\n",
      "[804/1762] D loss: 0.1582, G loss: 4.2824\n",
      "[884/1762] D loss: 0.0646, G loss: 3.5510\n",
      "[964/1762] D loss: 0.9950, G loss: 3.3860\n",
      "[1044/1762] D loss: 0.0924, G loss: 3.5383\n",
      "[1124/1762] D loss: 0.2419, G loss: 3.8443\n",
      "[1204/1762] D loss: 0.2283, G loss: 1.8811\n",
      "[1284/1762] D loss: 0.1228, G loss: 4.5914\n",
      "[1364/1762] D loss: 0.0728, G loss: 3.2963\n",
      "[1444/1762] D loss: 0.6591, G loss: 5.2148\n",
      "[1524/1762] D loss: 0.0515, G loss: 4.1897\n",
      "[1604/1762] D loss: 0.1146, G loss: 3.4827\n",
      "[1684/1762] D loss: 0.0075, G loss: 5.4413\n",
      "[1762/1762] D loss: 0.2210, G loss: 2.3607\n",
      "train error: \n",
      " D loss: 0.116836, G loss: 3.348836, D accuracy: 99.3%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.124945, G loss: 3.267327, D accuracy: 99.3%, cell accuracy: 97.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1476, G loss: 3.3064\n",
      "[84/1762] D loss: 0.0249, G loss: 4.4170\n",
      "[164/1762] D loss: 0.0361, G loss: 3.8039\n",
      "[244/1762] D loss: 0.0234, G loss: 5.3579\n",
      "[324/1762] D loss: 0.0330, G loss: 5.2685\n",
      "[404/1762] D loss: 0.2647, G loss: 3.1159\n",
      "[484/1762] D loss: 0.0036, G loss: 5.9718\n",
      "[564/1762] D loss: 0.0134, G loss: 4.1661\n",
      "[644/1762] D loss: 0.1187, G loss: 4.3187\n",
      "[724/1762] D loss: 0.0196, G loss: 4.9026\n",
      "[804/1762] D loss: 0.0106, G loss: 6.5591\n",
      "[884/1762] D loss: 0.6995, G loss: 3.5472\n",
      "[964/1762] D loss: 0.0175, G loss: 5.2813\n",
      "[1044/1762] D loss: 0.0505, G loss: 3.8547\n",
      "[1124/1762] D loss: 0.1390, G loss: 4.9987\n",
      "[1204/1762] D loss: 0.0772, G loss: 4.6027\n",
      "[1284/1762] D loss: 0.0839, G loss: 5.1069\n",
      "[1364/1762] D loss: 0.2185, G loss: 6.6859\n",
      "[1444/1762] D loss: 0.2320, G loss: 4.0209\n",
      "[1524/1762] D loss: 0.0085, G loss: 5.4724\n",
      "[1604/1762] D loss: 0.1865, G loss: 3.0171\n",
      "[1684/1762] D loss: 0.0373, G loss: 4.5538\n",
      "[1762/1762] D loss: 0.0117, G loss: 5.3236\n",
      "train error: \n",
      " D loss: 0.068369, G loss: 5.065129, D accuracy: 99.0%, cell accuracy: 97.1%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.084798, G loss: 5.004178, D accuracy: 98.5%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0680, G loss: 5.7813\n",
      "[84/1762] D loss: 0.2214, G loss: 5.0535\n",
      "[164/1762] D loss: 0.0636, G loss: 4.6358\n",
      "[244/1762] D loss: 0.1953, G loss: 3.7611\n",
      "[324/1762] D loss: 0.1153, G loss: 4.1073\n",
      "[404/1762] D loss: 0.0755, G loss: 3.6336\n",
      "[484/1762] D loss: 0.3596, G loss: 4.8413\n",
      "[564/1762] D loss: 0.1930, G loss: 4.4116\n",
      "[644/1762] D loss: 0.0480, G loss: 3.6520\n",
      "[724/1762] D loss: 0.0361, G loss: 4.6832\n",
      "[804/1762] D loss: 0.2727, G loss: 5.3586\n",
      "[884/1762] D loss: 0.0252, G loss: 4.8249\n",
      "[964/1762] D loss: 0.1370, G loss: 3.6280\n",
      "[1044/1762] D loss: 0.0515, G loss: 2.8577\n",
      "[1124/1762] D loss: 0.1537, G loss: 4.4382\n",
      "[1204/1762] D loss: 0.1038, G loss: 3.9723\n",
      "[1284/1762] D loss: 0.0104, G loss: 4.9370\n",
      "[1364/1762] D loss: 0.1272, G loss: 4.1595\n",
      "[1444/1762] D loss: 0.0909, G loss: 5.5361\n",
      "[1524/1762] D loss: 0.1275, G loss: 4.9362\n",
      "[1604/1762] D loss: 0.1293, G loss: 5.3829\n",
      "[1684/1762] D loss: 0.0208, G loss: 4.5401\n",
      "[1762/1762] D loss: 0.1012, G loss: 4.0107\n",
      "train error: \n",
      " D loss: 0.054297, G loss: 4.585439, D accuracy: 99.9%, cell accuracy: 97.4%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.066302, G loss: 4.479195, D accuracy: 99.7%, cell accuracy: 97.3%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0134, G loss: 4.7545\n",
      "[84/1762] D loss: 0.0656, G loss: 5.9342\n",
      "[164/1762] D loss: 0.3866, G loss: 6.7372\n",
      "[244/1762] D loss: 0.0086, G loss: 5.2265\n",
      "[324/1762] D loss: 0.0433, G loss: 4.8687\n",
      "[404/1762] D loss: 0.0131, G loss: 6.5890\n",
      "[484/1762] D loss: 0.0831, G loss: 5.2560\n",
      "[564/1762] D loss: 0.0056, G loss: 5.9646\n",
      "[644/1762] D loss: 0.0075, G loss: 5.0008\n",
      "[724/1762] D loss: 0.2102, G loss: 4.0471\n",
      "[804/1762] D loss: 0.0278, G loss: 4.7971\n",
      "[884/1762] D loss: 0.0056, G loss: 5.4687\n",
      "[964/1762] D loss: 0.0627, G loss: 3.9982\n",
      "[1044/1762] D loss: 0.1570, G loss: 6.7088\n",
      "[1124/1762] D loss: 0.3013, G loss: 6.5211\n",
      "[1204/1762] D loss: 0.0077, G loss: 4.6144\n",
      "[1284/1762] D loss: 0.0082, G loss: 5.4835\n",
      "[1364/1762] D loss: 0.0034, G loss: 7.3367\n",
      "[1444/1762] D loss: 0.1018, G loss: 4.5351\n",
      "[1524/1762] D loss: 0.0936, G loss: 6.1498\n",
      "[1604/1762] D loss: 0.2488, G loss: 3.4235\n",
      "[1684/1762] D loss: 0.0207, G loss: 5.7296\n",
      "[1762/1762] D loss: 0.0097, G loss: 5.9118\n",
      "train error: \n",
      " D loss: 0.045381, G loss: 6.027027, D accuracy: 99.5%, cell accuracy: 97.4%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.061015, G loss: 5.919546, D accuracy: 99.1%, cell accuracy: 97.3%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0018, G loss: 6.7564\n",
      "[84/1762] D loss: 0.0446, G loss: 4.2244\n",
      "[164/1762] D loss: 0.0536, G loss: 4.8166\n",
      "[244/1762] D loss: 0.0040, G loss: 6.5931\n",
      "[324/1762] D loss: 0.0074, G loss: 6.4445\n",
      "[404/1762] D loss: 0.0141, G loss: 5.2748\n",
      "[484/1762] D loss: 0.0056, G loss: 6.6982\n",
      "[564/1762] D loss: 0.0027, G loss: 6.0177\n",
      "[644/1762] D loss: 0.1724, G loss: 3.1638\n",
      "[724/1762] D loss: 0.0130, G loss: 6.8057\n",
      "[804/1762] D loss: 0.0042, G loss: 5.8184\n",
      "[884/1762] D loss: 0.0394, G loss: 6.1720\n",
      "[964/1762] D loss: 0.0230, G loss: 4.6963\n",
      "[1044/1762] D loss: 0.0099, G loss: 6.5959\n",
      "[1124/1762] D loss: 0.0270, G loss: 5.1653\n",
      "[1204/1762] D loss: 0.0058, G loss: 6.5763\n",
      "[1284/1762] D loss: 0.0301, G loss: 5.1946\n",
      "[1364/1762] D loss: 0.0337, G loss: 4.8921\n",
      "[1444/1762] D loss: 0.0960, G loss: 6.2615\n",
      "[1524/1762] D loss: 0.0656, G loss: 4.5672\n",
      "[1604/1762] D loss: 0.0055, G loss: 5.5339\n",
      "[1684/1762] D loss: 0.0016, G loss: 6.4205\n",
      "[1762/1762] D loss: 0.0174, G loss: 3.5734\n",
      "train error: \n",
      " D loss: 0.142476, G loss: 3.275545, D accuracy: 97.6%, cell accuracy: 97.4%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.157099, G loss: 3.160925, D accuracy: 97.5%, cell accuracy: 97.3%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0580, G loss: 3.3500\n",
      "[84/1762] D loss: 0.0360, G loss: 4.5168\n",
      "[164/1762] D loss: 0.0023, G loss: 6.4333\n",
      "[244/1762] D loss: 0.1071, G loss: 3.6644\n",
      "[324/1762] D loss: 0.0037, G loss: 6.6284\n",
      "[404/1762] D loss: 0.0059, G loss: 6.5291\n",
      "[484/1762] D loss: 0.0015, G loss: 7.4602\n",
      "[564/1762] D loss: 0.0027, G loss: 6.7666\n",
      "[644/1762] D loss: 0.0400, G loss: 5.4753\n",
      "[724/1762] D loss: 0.0084, G loss: 6.0263\n",
      "[804/1762] D loss: 0.0187, G loss: 5.5873\n",
      "[884/1762] D loss: 0.0984, G loss: 4.7244\n",
      "[964/1762] D loss: 0.0116, G loss: 6.2484\n",
      "[1044/1762] D loss: 0.0164, G loss: 4.5273\n",
      "[1124/1762] D loss: 0.0476, G loss: 6.1044\n",
      "[1204/1762] D loss: 0.0024, G loss: 6.7344\n",
      "[1284/1762] D loss: 0.0125, G loss: 6.3390\n",
      "[1364/1762] D loss: 0.0018, G loss: 6.4516\n",
      "[1444/1762] D loss: 0.0028, G loss: 6.2824\n",
      "[1524/1762] D loss: 0.0896, G loss: 6.9380\n",
      "[1604/1762] D loss: 0.0345, G loss: 4.4847\n",
      "[1684/1762] D loss: 0.0025, G loss: 6.5126\n",
      "[1762/1762] D loss: 0.0088, G loss: 4.5938\n",
      "train error: \n",
      " D loss: 0.037711, G loss: 4.718506, D accuracy: 99.9%, cell accuracy: 97.4%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.044045, G loss: 4.615966, D accuracy: 99.9%, cell accuracy: 97.3%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1077, G loss: 3.1803\n",
      "[84/1762] D loss: 0.0013, G loss: 6.7541\n",
      "[164/1762] D loss: 0.0111, G loss: 5.2706\n",
      "[244/1762] D loss: 0.0449, G loss: 5.8650\n",
      "[324/1762] D loss: 0.0016, G loss: 7.5321\n",
      "[404/1762] D loss: 0.0690, G loss: 7.3489\n",
      "[484/1762] D loss: 0.0043, G loss: 6.3061\n",
      "[564/1762] D loss: 0.0030, G loss: 6.3358\n",
      "[644/1762] D loss: 0.0196, G loss: 6.5892\n",
      "[724/1762] D loss: 0.0016, G loss: 6.6890\n",
      "[804/1762] D loss: 0.0096, G loss: 6.6834\n",
      "[884/1762] D loss: 0.0304, G loss: 4.5121\n",
      "[964/1762] D loss: 0.2207, G loss: 4.6789\n",
      "[1044/1762] D loss: 0.0197, G loss: 5.4110\n",
      "[1124/1762] D loss: 0.0099, G loss: 7.6329\n",
      "[1204/1762] D loss: 0.3020, G loss: 7.2729\n",
      "[1284/1762] D loss: 0.0150, G loss: 4.0081\n",
      "[1364/1762] D loss: 0.0119, G loss: 6.9569\n",
      "[1444/1762] D loss: 0.9243, G loss: 6.9348\n",
      "[1524/1762] D loss: 0.0013, G loss: 7.4363\n",
      "[1604/1762] D loss: 0.0071, G loss: 8.4585\n",
      "[1684/1762] D loss: 0.0165, G loss: 5.7398\n",
      "[1762/1762] D loss: 0.0264, G loss: 4.0165\n",
      "train error: \n",
      " D loss: 0.023546, G loss: 5.214646, D accuracy: 99.9%, cell accuracy: 97.4%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.029144, G loss: 5.111363, D accuracy: 99.9%, cell accuracy: 97.3%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0399, G loss: 4.9263\n",
      "[84/1762] D loss: 0.0133, G loss: 6.4607\n",
      "[164/1762] D loss: 0.0218, G loss: 5.3579\n",
      "[244/1762] D loss: 0.0018, G loss: 7.1800\n",
      "[324/1762] D loss: 0.0166, G loss: 5.6322\n",
      "[404/1762] D loss: 0.0058, G loss: 6.0813\n",
      "[484/1762] D loss: 0.0022, G loss: 6.8246\n",
      "[564/1762] D loss: 0.0087, G loss: 5.9015\n",
      "[644/1762] D loss: 0.0140, G loss: 6.0892\n",
      "[724/1762] D loss: 0.0863, G loss: 5.2260\n",
      "[804/1762] D loss: 0.1255, G loss: 6.0750\n",
      "[884/1762] D loss: 0.1099, G loss: 4.6632\n",
      "[964/1762] D loss: 0.0120, G loss: 4.8486\n",
      "[1044/1762] D loss: 0.0055, G loss: 5.1224\n",
      "[1124/1762] D loss: 0.0142, G loss: 5.6856\n",
      "[1204/1762] D loss: 0.0015, G loss: 7.0467\n",
      "[1284/1762] D loss: 0.1913, G loss: 5.3502\n",
      "[1364/1762] D loss: 0.0126, G loss: 4.9394\n",
      "[1444/1762] D loss: 0.0114, G loss: 6.1473\n",
      "[1524/1762] D loss: 0.0300, G loss: 5.2241\n",
      "[1604/1762] D loss: 0.0028, G loss: 6.1280\n",
      "[1684/1762] D loss: 0.0291, G loss: 6.7345\n",
      "[1762/1762] D loss: 0.0012, G loss: 6.8031\n",
      "train error: \n",
      " D loss: 0.011212, G loss: 6.564696, D accuracy: 100.0%, cell accuracy: 97.4%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.015257, G loss: 6.458707, D accuracy: 100.0%, cell accuracy: 97.3%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0111, G loss: 6.6252\n",
      "[84/1762] D loss: 0.0086, G loss: 5.7731\n",
      "[164/1762] D loss: 0.0121, G loss: 5.9856\n",
      "[244/1762] D loss: 0.0341, G loss: 3.9852\n",
      "[324/1762] D loss: 0.0012, G loss: 6.6744\n",
      "[404/1762] D loss: 0.0211, G loss: 6.0212\n",
      "[484/1762] D loss: 0.0184, G loss: 5.8263\n",
      "[564/1762] D loss: 0.0266, G loss: 5.9008\n",
      "[644/1762] D loss: 0.0055, G loss: 5.5823\n",
      "[724/1762] D loss: 0.0132, G loss: 6.8189\n",
      "[804/1762] D loss: 0.0120, G loss: 6.4436\n",
      "[884/1762] D loss: 0.0211, G loss: 6.4164\n",
      "[964/1762] D loss: 0.0428, G loss: 6.1655\n",
      "[1044/1762] D loss: 0.0021, G loss: 6.3195\n",
      "[1124/1762] D loss: 0.0057, G loss: 5.9925\n",
      "[1204/1762] D loss: 0.0021, G loss: 6.4638\n",
      "[1284/1762] D loss: 0.0393, G loss: 6.7554\n",
      "[1364/1762] D loss: 0.0024, G loss: 7.6564\n",
      "[1444/1762] D loss: 0.0023, G loss: 7.0716\n",
      "[1524/1762] D loss: 0.0113, G loss: 8.3708\n",
      "[1604/1762] D loss: 0.0159, G loss: 6.1210\n",
      "[1684/1762] D loss: 0.0523, G loss: 4.2661\n",
      "[1762/1762] D loss: 0.0431, G loss: 5.2817\n",
      "train error: \n",
      " D loss: 0.019286, G loss: 5.365619, D accuracy: 100.0%, cell accuracy: 97.1%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.024665, G loss: 5.296195, D accuracy: 99.9%, cell accuracy: 97.1%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0237, G loss: 4.4417\n",
      "[84/1762] D loss: 0.0196, G loss: 5.3186\n",
      "[164/1762] D loss: 0.0065, G loss: 5.6821\n",
      "[244/1762] D loss: 0.0694, G loss: 7.3509\n",
      "[324/1762] D loss: 0.1181, G loss: 2.4765\n",
      "[404/1762] D loss: 0.0554, G loss: 6.0174\n",
      "[484/1762] D loss: 0.0559, G loss: 5.6086\n",
      "[564/1762] D loss: 0.1596, G loss: 3.8460\n",
      "[644/1762] D loss: 0.1011, G loss: 3.5654\n",
      "[724/1762] D loss: 0.5360, G loss: 4.5548\n",
      "[804/1762] D loss: 0.1791, G loss: 5.1638\n",
      "[884/1762] D loss: 1.0698, G loss: 2.5829\n",
      "[964/1762] D loss: 0.1894, G loss: 3.3932\n",
      "[1044/1762] D loss: 0.3393, G loss: 5.8559\n",
      "[1124/1762] D loss: 0.1216, G loss: 2.0758\n",
      "[1204/1762] D loss: 0.3441, G loss: 4.4732\n",
      "[1284/1762] D loss: 1.2654, G loss: 1.4127\n",
      "[1364/1762] D loss: 0.2629, G loss: 1.9986\n",
      "[1444/1762] D loss: 0.0141, G loss: 5.9706\n",
      "[1524/1762] D loss: 0.8243, G loss: 2.4762\n",
      "[1604/1762] D loss: 0.4678, G loss: 3.9271\n",
      "[1684/1762] D loss: 0.4602, G loss: 1.9985\n",
      "[1762/1762] D loss: 0.3125, G loss: 2.0582\n",
      "train error: \n",
      " D loss: 0.369923, G loss: 3.336947, D accuracy: 91.8%, cell accuracy: 96.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.410955, G loss: 3.250778, D accuracy: 91.2%, cell accuracy: 96.7%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1539, G loss: 4.6117\n",
      "[84/1762] D loss: 0.1481, G loss: 2.9015\n",
      "[164/1762] D loss: 0.0779, G loss: 4.6045\n",
      "[244/1762] D loss: 0.1123, G loss: 3.1839\n",
      "[324/1762] D loss: 0.0970, G loss: 2.9691\n",
      "[404/1762] D loss: 0.5206, G loss: 2.8578\n",
      "[484/1762] D loss: 0.0758, G loss: 6.9511\n",
      "[564/1762] D loss: 0.3641, G loss: 2.3162\n",
      "[644/1762] D loss: 1.1907, G loss: 2.8773\n",
      "[724/1762] D loss: 1.4625, G loss: 4.0328\n",
      "[804/1762] D loss: 0.2079, G loss: 3.4999\n",
      "[884/1762] D loss: 0.2131, G loss: 4.4662\n",
      "[964/1762] D loss: 0.0381, G loss: 6.2501\n",
      "[1044/1762] D loss: 0.2669, G loss: 4.4372\n",
      "[1124/1762] D loss: 0.5456, G loss: 1.5600\n",
      "[1204/1762] D loss: 0.0826, G loss: 2.6821\n",
      "[1284/1762] D loss: 0.0152, G loss: 5.8917\n",
      "[1364/1762] D loss: 0.4035, G loss: 5.7451\n",
      "[1444/1762] D loss: 0.1900, G loss: 5.4960\n",
      "[1524/1762] D loss: 0.3280, G loss: 3.2699\n",
      "[1604/1762] D loss: 0.0355, G loss: 4.6938\n",
      "[1684/1762] D loss: 0.1467, G loss: 5.2336\n",
      "[1762/1762] D loss: 0.1455, G loss: 4.0456\n",
      "train error: \n",
      " D loss: 0.324167, G loss: 5.203622, D accuracy: 94.2%, cell accuracy: 96.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.392730, G loss: 5.145449, D accuracy: 92.5%, cell accuracy: 96.7%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0893, G loss: 6.3288\n",
      "[84/1762] D loss: 0.3488, G loss: 4.9310\n",
      "[164/1762] D loss: 0.1737, G loss: 5.2106\n",
      "[244/1762] D loss: 0.0081, G loss: 6.4344\n",
      "[324/1762] D loss: 0.0708, G loss: 4.6626\n",
      "[404/1762] D loss: 0.2582, G loss: 3.2257\n",
      "[484/1762] D loss: 0.3274, G loss: 4.2906\n",
      "[564/1762] D loss: 0.7666, G loss: 2.5798\n",
      "[644/1762] D loss: 0.0481, G loss: 4.6604\n",
      "[724/1762] D loss: 0.0318, G loss: 4.9731\n",
      "[804/1762] D loss: 0.0064, G loss: 6.1171\n",
      "[884/1762] D loss: 0.2366, G loss: 5.2095\n",
      "[964/1762] D loss: 0.4752, G loss: 4.0669\n",
      "[1044/1762] D loss: 0.0555, G loss: 6.4690\n",
      "[1124/1762] D loss: 0.1120, G loss: 3.8257\n",
      "[1204/1762] D loss: 0.1777, G loss: 5.2541\n",
      "[1284/1762] D loss: 0.1656, G loss: 5.6318\n",
      "[1364/1762] D loss: 0.4276, G loss: 2.7320\n",
      "[1444/1762] D loss: 0.7982, G loss: 4.7462\n",
      "[1524/1762] D loss: 1.9298, G loss: 1.9096\n",
      "[1604/1762] D loss: 0.8881, G loss: 1.8980\n",
      "[1684/1762] D loss: 0.3941, G loss: 1.5372\n",
      "[1762/1762] D loss: 2.5001, G loss: 2.1423\n",
      "train error: \n",
      " D loss: 2.158330, G loss: 2.169542, D accuracy: 55.5%, cell accuracy: 96.2%, board accuracy: 3.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.234274, G loss: 2.144763, D accuracy: 54.4%, cell accuracy: 96.0%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4751, G loss: 1.2694\n",
      "[84/1762] D loss: 3.1485, G loss: 1.0414\n",
      "[164/1762] D loss: 1.9919, G loss: 0.7353\n",
      "[244/1762] D loss: 1.5272, G loss: 0.6905\n",
      "[324/1762] D loss: 1.9850, G loss: 0.8142\n",
      "[404/1762] D loss: 1.2789, G loss: 1.1846\n",
      "[484/1762] D loss: 1.5502, G loss: 1.1554\n",
      "[564/1762] D loss: 1.7178, G loss: 1.4149\n",
      "[644/1762] D loss: 1.2561, G loss: 1.1174\n",
      "[724/1762] D loss: 1.2636, G loss: 1.2563\n",
      "[804/1762] D loss: 1.0113, G loss: 1.0196\n",
      "[884/1762] D loss: 0.8676, G loss: 1.2917\n",
      "[964/1762] D loss: 1.2345, G loss: 3.6260\n",
      "[1044/1762] D loss: 0.5769, G loss: 1.7819\n",
      "[1124/1762] D loss: 1.0429, G loss: 1.0192\n",
      "[1204/1762] D loss: 1.0111, G loss: 1.0620\n",
      "[1284/1762] D loss: 1.1100, G loss: 0.7499\n",
      "[1364/1762] D loss: 0.9161, G loss: 1.5066\n",
      "[1444/1762] D loss: 1.0711, G loss: 1.0116\n",
      "[1524/1762] D loss: 0.6573, G loss: 1.9046\n",
      "[1604/1762] D loss: 1.2975, G loss: 1.5027\n",
      "[1684/1762] D loss: 0.6851, G loss: 2.2751\n",
      "[1762/1762] D loss: 0.4644, G loss: 2.9004\n",
      "train error: \n",
      " D loss: 0.810203, G loss: 2.085489, D accuracy: 79.3%, cell accuracy: 95.6%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.777758, G loss: 2.039728, D accuracy: 80.9%, cell accuracy: 95.5%, board accuracy: 13.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9247, G loss: 1.5786\n",
      "[84/1762] D loss: 0.4613, G loss: 3.1785\n",
      "[164/1762] D loss: 0.8640, G loss: 1.5127\n",
      "[244/1762] D loss: 0.2486, G loss: 2.8756\n",
      "[324/1762] D loss: 0.9238, G loss: 1.0243\n",
      "[404/1762] D loss: 1.2304, G loss: 2.0621\n",
      "[484/1762] D loss: 1.3617, G loss: 1.7936\n",
      "[564/1762] D loss: 0.6833, G loss: 2.4250\n",
      "[644/1762] D loss: 0.4628, G loss: 2.2411\n",
      "[724/1762] D loss: 0.6664, G loss: 2.7667\n",
      "[804/1762] D loss: 0.0498, G loss: 4.1010\n",
      "[884/1762] D loss: 0.6546, G loss: 1.9755\n",
      "[964/1762] D loss: 0.1836, G loss: 3.8079\n",
      "[1044/1762] D loss: 0.3801, G loss: 2.2439\n",
      "[1124/1762] D loss: 0.2874, G loss: 2.9365\n",
      "[1204/1762] D loss: 0.2580, G loss: 2.9186\n",
      "[1284/1762] D loss: 0.1914, G loss: 3.4889\n",
      "[1364/1762] D loss: 0.5548, G loss: 2.0903\n",
      "[1444/1762] D loss: 0.1752, G loss: 3.0006\n",
      "[1524/1762] D loss: 0.6706, G loss: 2.9890\n",
      "[1604/1762] D loss: 0.4664, G loss: 2.0678\n",
      "[1684/1762] D loss: 0.2034, G loss: 3.6136\n",
      "[1762/1762] D loss: 0.8622, G loss: 1.8815\n",
      "train error: \n",
      " D loss: 0.646638, G loss: 2.916940, D accuracy: 83.2%, cell accuracy: 95.7%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.611327, G loss: 2.897597, D accuracy: 84.4%, cell accuracy: 95.5%, board accuracy: 13.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6193, G loss: 2.9925\n",
      "[84/1762] D loss: 0.8010, G loss: 3.6501\n",
      "[164/1762] D loss: 0.4373, G loss: 1.6811\n",
      "[244/1762] D loss: 0.4466, G loss: 2.4391\n",
      "[324/1762] D loss: 0.8042, G loss: 1.6163\n",
      "[404/1762] D loss: 0.6616, G loss: 3.4350\n",
      "[484/1762] D loss: 0.6632, G loss: 1.7180\n",
      "[564/1762] D loss: 0.8962, G loss: 3.7078\n",
      "[644/1762] D loss: 0.2902, G loss: 3.7698\n",
      "[724/1762] D loss: 0.7452, G loss: 2.4035\n",
      "[804/1762] D loss: 1.2164, G loss: 1.0824\n",
      "[884/1762] D loss: 0.2011, G loss: 2.7552\n",
      "[964/1762] D loss: 0.7447, G loss: 2.9608\n",
      "[1044/1762] D loss: 0.5969, G loss: 4.2686\n",
      "[1124/1762] D loss: 1.0654, G loss: 2.2729\n",
      "[1204/1762] D loss: 0.3841, G loss: 5.7438\n",
      "[1284/1762] D loss: 1.2825, G loss: 2.4626\n",
      "[1364/1762] D loss: 1.0937, G loss: 2.2584\n",
      "[1444/1762] D loss: 1.6548, G loss: 0.2800\n",
      "[1524/1762] D loss: 2.2510, G loss: 0.4637\n",
      "[1604/1762] D loss: 1.3282, G loss: 1.0356\n",
      "[1684/1762] D loss: 0.8847, G loss: 1.3102\n",
      "[1762/1762] D loss: 1.6228, G loss: 0.2803\n",
      "train error: \n",
      " D loss: 1.089026, G loss: 1.137507, D accuracy: 74.1%, cell accuracy: 98.1%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.112939, G loss: 1.119291, D accuracy: 73.1%, cell accuracy: 98.0%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1119, G loss: 0.5966\n",
      "[84/1762] D loss: 1.5974, G loss: 0.7751\n",
      "[164/1762] D loss: 0.9136, G loss: 1.4526\n",
      "[244/1762] D loss: 1.0886, G loss: 2.1409\n",
      "[324/1762] D loss: 0.7352, G loss: 1.0548\n",
      "[404/1762] D loss: 0.3900, G loss: 2.5141\n",
      "[484/1762] D loss: 0.9086, G loss: 1.7660\n",
      "[564/1762] D loss: 0.3108, G loss: 2.6341\n",
      "[644/1762] D loss: 0.7695, G loss: 0.8807\n",
      "[724/1762] D loss: 0.4277, G loss: 1.4613\n",
      "[804/1762] D loss: 0.5544, G loss: 2.1196\n",
      "[884/1762] D loss: 0.4585, G loss: 1.8526\n",
      "[964/1762] D loss: 0.4866, G loss: 3.1477\n",
      "[1044/1762] D loss: 0.2896, G loss: 1.8828\n",
      "[1124/1762] D loss: 0.6231, G loss: 2.5164\n",
      "[1204/1762] D loss: 0.2496, G loss: 3.1560\n",
      "[1284/1762] D loss: 0.1128, G loss: 2.8414\n",
      "[1364/1762] D loss: 0.1744, G loss: 2.9683\n",
      "[1444/1762] D loss: 0.3206, G loss: 2.3223\n",
      "[1524/1762] D loss: 0.2281, G loss: 2.2199\n",
      "[1604/1762] D loss: 0.4502, G loss: 2.7728\n",
      "[1684/1762] D loss: 0.4778, G loss: 4.3939\n",
      "[1762/1762] D loss: 0.2368, G loss: 3.0778\n",
      "train error: \n",
      " D loss: 0.419356, G loss: 2.385980, D accuracy: 92.9%, cell accuracy: 97.7%, board accuracy: 1.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.443310, G loss: 2.379001, D accuracy: 92.7%, cell accuracy: 97.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1118, G loss: 3.1694\n",
      "[84/1762] D loss: 0.9008, G loss: 1.2348\n",
      "[164/1762] D loss: 0.7393, G loss: 2.0273\n",
      "[244/1762] D loss: 0.3791, G loss: 2.3232\n",
      "[324/1762] D loss: 0.3691, G loss: 2.5088\n",
      "[404/1762] D loss: 0.7744, G loss: 3.2969\n",
      "[484/1762] D loss: 0.2551, G loss: 3.1728\n",
      "[564/1762] D loss: 0.7428, G loss: 1.2738\n",
      "[644/1762] D loss: 0.1295, G loss: 2.7309\n",
      "[724/1762] D loss: 0.5164, G loss: 1.3866\n",
      "[804/1762] D loss: 1.2723, G loss: 2.7793\n",
      "[884/1762] D loss: 0.5386, G loss: 1.2631\n",
      "[964/1762] D loss: 0.9545, G loss: 3.3551\n",
      "[1044/1762] D loss: 0.3585, G loss: 3.6727\n",
      "[1124/1762] D loss: 0.5272, G loss: 3.0257\n",
      "[1204/1762] D loss: 0.4820, G loss: 1.3235\n",
      "[1284/1762] D loss: 0.1661, G loss: 2.6682\n",
      "[1364/1762] D loss: 1.0205, G loss: 1.3545\n",
      "[1444/1762] D loss: 0.1579, G loss: 3.7390\n",
      "[1524/1762] D loss: 0.1371, G loss: 2.6119\n",
      "[1604/1762] D loss: 0.9028, G loss: 4.3222\n",
      "[1684/1762] D loss: 0.0538, G loss: 5.0156\n",
      "[1762/1762] D loss: 0.0322, G loss: 3.6875\n",
      "train error: \n",
      " D loss: 0.472148, G loss: 1.931952, D accuracy: 91.8%, cell accuracy: 97.8%, board accuracy: 2.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.491306, G loss: 1.903446, D accuracy: 92.5%, cell accuracy: 97.8%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8592, G loss: 1.6571\n",
      "[84/1762] D loss: 0.8433, G loss: 2.4042\n",
      "[164/1762] D loss: 0.1804, G loss: 3.3860\n",
      "[244/1762] D loss: 0.0487, G loss: 4.1482\n",
      "[324/1762] D loss: 0.2079, G loss: 3.2488\n",
      "[404/1762] D loss: 0.3816, G loss: 3.3236\n",
      "[484/1762] D loss: 0.4142, G loss: 2.0574\n",
      "[564/1762] D loss: 0.9904, G loss: 1.5530\n",
      "[644/1762] D loss: 0.4186, G loss: 3.7313\n",
      "[724/1762] D loss: 0.7707, G loss: 2.4202\n",
      "[804/1762] D loss: 0.2115, G loss: 2.7375\n",
      "[884/1762] D loss: 0.5200, G loss: 3.5868\n",
      "[964/1762] D loss: 0.1194, G loss: 2.2747\n",
      "[1044/1762] D loss: 0.7371, G loss: 1.3113\n",
      "[1124/1762] D loss: 0.1286, G loss: 3.2765\n",
      "[1204/1762] D loss: 0.3746, G loss: 2.6390\n",
      "[1284/1762] D loss: 0.1616, G loss: 3.4187\n",
      "[1364/1762] D loss: 0.1845, G loss: 3.8151\n",
      "[1444/1762] D loss: 0.0402, G loss: 5.1762\n",
      "[1524/1762] D loss: 0.3974, G loss: 2.6305\n",
      "[1604/1762] D loss: 1.0921, G loss: 3.4942\n",
      "[1684/1762] D loss: 0.0551, G loss: 2.9517\n",
      "[1762/1762] D loss: 1.3963, G loss: 4.0030\n",
      "train error: \n",
      " D loss: 0.330587, G loss: 3.812923, D accuracy: 92.4%, cell accuracy: 97.9%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.360213, G loss: 3.780488, D accuracy: 91.9%, cell accuracy: 97.9%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0822, G loss: 4.0683\n",
      "[84/1762] D loss: 0.0240, G loss: 4.3156\n",
      "[164/1762] D loss: 0.9177, G loss: 2.8697\n",
      "[244/1762] D loss: 0.2698, G loss: 4.2599\n",
      "[324/1762] D loss: 0.5655, G loss: 2.5998\n",
      "[404/1762] D loss: 0.2378, G loss: 1.9905\n",
      "[484/1762] D loss: 0.7281, G loss: 6.1006\n",
      "[564/1762] D loss: 0.0815, G loss: 3.1063\n",
      "[644/1762] D loss: 0.2070, G loss: 4.4153\n",
      "[724/1762] D loss: 0.0341, G loss: 5.1299\n",
      "[804/1762] D loss: 0.1484, G loss: 3.1549\n",
      "[884/1762] D loss: 0.6121, G loss: 3.8440\n",
      "[964/1762] D loss: 0.3042, G loss: 2.4095\n",
      "[1044/1762] D loss: 0.2399, G loss: 2.9584\n",
      "[1124/1762] D loss: 1.1967, G loss: 2.7315\n",
      "[1204/1762] D loss: 0.3274, G loss: 3.8541\n",
      "[1284/1762] D loss: 0.4190, G loss: 4.8261\n",
      "[1364/1762] D loss: 0.5770, G loss: 2.3392\n",
      "[1444/1762] D loss: 0.5933, G loss: 3.5106\n",
      "[1524/1762] D loss: 0.0283, G loss: 3.5532\n",
      "[1604/1762] D loss: 0.2922, G loss: 4.8855\n",
      "[1684/1762] D loss: 0.1136, G loss: 3.7086\n",
      "[1762/1762] D loss: 0.1692, G loss: 5.3272\n",
      "train error: \n",
      " D loss: 0.654152, G loss: 5.714165, D accuracy: 86.8%, cell accuracy: 97.9%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.712939, G loss: 5.688856, D accuracy: 84.8%, cell accuracy: 97.9%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9421, G loss: 4.6987\n",
      "[84/1762] D loss: 0.2215, G loss: 2.1457\n",
      "[164/1762] D loss: 0.3852, G loss: 3.0282\n",
      "[244/1762] D loss: 0.0881, G loss: 3.3679\n",
      "[324/1762] D loss: 0.9691, G loss: 5.9763\n",
      "[404/1762] D loss: 0.0863, G loss: 3.1150\n",
      "[484/1762] D loss: 0.1365, G loss: 4.1730\n",
      "[564/1762] D loss: 0.4232, G loss: 3.2730\n",
      "[644/1762] D loss: 0.3696, G loss: 3.4577\n",
      "[724/1762] D loss: 0.0501, G loss: 3.9700\n",
      "[804/1762] D loss: 0.0487, G loss: 3.9379\n",
      "[884/1762] D loss: 0.2938, G loss: 2.5375\n",
      "[964/1762] D loss: 1.1852, G loss: 4.1113\n",
      "[1044/1762] D loss: 0.1874, G loss: 2.9480\n",
      "[1124/1762] D loss: 0.4394, G loss: 3.4888\n",
      "[1204/1762] D loss: 0.0568, G loss: 2.9916\n",
      "[1284/1762] D loss: 0.1315, G loss: 5.7610\n",
      "[1364/1762] D loss: 0.1423, G loss: 3.2664\n",
      "[1444/1762] D loss: 0.2792, G loss: 5.0063\n",
      "[1524/1762] D loss: 0.7749, G loss: 2.2318\n",
      "[1604/1762] D loss: 0.1377, G loss: 5.4284\n",
      "[1684/1762] D loss: 0.0600, G loss: 2.9567\n",
      "[1762/1762] D loss: 0.4268, G loss: 1.8957\n",
      "train error: \n",
      " D loss: 0.277026, G loss: 3.315444, D accuracy: 93.9%, cell accuracy: 98.0%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.279162, G loss: 3.261791, D accuracy: 94.2%, cell accuracy: 98.0%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0258, G loss: 4.3543\n",
      "[84/1762] D loss: 0.0352, G loss: 5.7158\n",
      "[164/1762] D loss: 0.4917, G loss: 2.3216\n",
      "[244/1762] D loss: 0.1783, G loss: 5.0336\n",
      "[324/1762] D loss: 0.1728, G loss: 4.7548\n",
      "[404/1762] D loss: 0.1123, G loss: 5.3907\n",
      "[484/1762] D loss: 1.1131, G loss: 2.2895\n",
      "[564/1762] D loss: 0.3845, G loss: 3.9783\n",
      "[644/1762] D loss: 0.0484, G loss: 3.4439\n",
      "[724/1762] D loss: 0.1904, G loss: 2.8366\n",
      "[804/1762] D loss: 0.0299, G loss: 4.4198\n",
      "[884/1762] D loss: 0.1166, G loss: 5.3988\n",
      "[964/1762] D loss: 0.4191, G loss: 4.5794\n",
      "[1044/1762] D loss: 0.0688, G loss: 4.3585\n",
      "[1124/1762] D loss: 0.1350, G loss: 4.7530\n",
      "[1204/1762] D loss: 1.2054, G loss: 3.0780\n",
      "[1284/1762] D loss: 0.1590, G loss: 1.7740\n",
      "[1364/1762] D loss: 0.0158, G loss: 6.3892\n",
      "[1444/1762] D loss: 0.6152, G loss: 1.8759\n",
      "[1524/1762] D loss: 0.0936, G loss: 3.6141\n",
      "[1604/1762] D loss: 0.2140, G loss: 3.6370\n",
      "[1684/1762] D loss: 0.0723, G loss: 4.2594\n",
      "[1762/1762] D loss: 0.6860, G loss: 3.2213\n",
      "train error: \n",
      " D loss: 0.255934, G loss: 3.483718, D accuracy: 94.6%, cell accuracy: 97.9%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.253645, G loss: 3.453458, D accuracy: 94.9%, cell accuracy: 97.9%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5723, G loss: 3.3633\n",
      "[84/1762] D loss: 0.0803, G loss: 6.3978\n",
      "[164/1762] D loss: 0.0458, G loss: 4.8340\n",
      "[244/1762] D loss: 0.1542, G loss: 3.2492\n",
      "[324/1762] D loss: 0.0189, G loss: 5.3449\n",
      "[404/1762] D loss: 0.0099, G loss: 5.5115\n",
      "[484/1762] D loss: 0.5375, G loss: 2.9611\n",
      "[564/1762] D loss: 0.2952, G loss: 3.6401\n",
      "[644/1762] D loss: 0.0837, G loss: 5.8340\n",
      "[724/1762] D loss: 0.4448, G loss: 2.6522\n",
      "[804/1762] D loss: 0.4174, G loss: 3.5636\n",
      "[884/1762] D loss: 0.0448, G loss: 5.4880\n",
      "[964/1762] D loss: 0.0842, G loss: 3.2558\n",
      "[1044/1762] D loss: 0.2718, G loss: 3.5283\n",
      "[1124/1762] D loss: 0.0710, G loss: 4.2951\n",
      "[1204/1762] D loss: 0.0188, G loss: 4.7027\n",
      "[1284/1762] D loss: 0.1675, G loss: 5.2654\n",
      "[1364/1762] D loss: 0.8383, G loss: 3.6001\n",
      "[1444/1762] D loss: 0.1158, G loss: 4.4413\n",
      "[1524/1762] D loss: 0.3478, G loss: 3.3530\n",
      "[1604/1762] D loss: 0.0413, G loss: 5.0094\n",
      "[1684/1762] D loss: 0.0333, G loss: 5.1879\n",
      "[1762/1762] D loss: 0.1566, G loss: 3.1423\n",
      "train error: \n",
      " D loss: 0.217877, G loss: 3.938772, D accuracy: 95.3%, cell accuracy: 97.9%, board accuracy: 3.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.211456, G loss: 3.917373, D accuracy: 95.8%, cell accuracy: 97.9%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1579, G loss: 3.8010\n",
      "[84/1762] D loss: 0.0776, G loss: 5.5108\n",
      "[164/1762] D loss: 0.1009, G loss: 1.7105\n",
      "[244/1762] D loss: 0.4452, G loss: 3.4395\n",
      "[324/1762] D loss: 0.1581, G loss: 4.0845\n",
      "[404/1762] D loss: 0.0852, G loss: 4.9904\n",
      "[484/1762] D loss: 0.1194, G loss: 3.9553\n",
      "[564/1762] D loss: 0.0993, G loss: 3.5123\n",
      "[644/1762] D loss: 0.4193, G loss: 4.4686\n",
      "[724/1762] D loss: 0.1387, G loss: 3.9357\n",
      "[804/1762] D loss: 0.3978, G loss: 1.4391\n",
      "[884/1762] D loss: 0.4703, G loss: 6.9194\n",
      "[964/1762] D loss: 0.0157, G loss: 4.5570\n",
      "[1044/1762] D loss: 0.1469, G loss: 4.2942\n",
      "[1124/1762] D loss: 0.2282, G loss: 3.7916\n",
      "[1204/1762] D loss: 0.5643, G loss: 4.3172\n",
      "[1284/1762] D loss: 0.3209, G loss: 3.7945\n",
      "[1364/1762] D loss: 0.1173, G loss: 6.8269\n",
      "[1444/1762] D loss: 0.0176, G loss: 5.6650\n",
      "[1524/1762] D loss: 0.7812, G loss: 2.3725\n",
      "[1604/1762] D loss: 0.0793, G loss: 5.7193\n",
      "[1684/1762] D loss: 0.0231, G loss: 5.9423\n",
      "[1762/1762] D loss: 0.1897, G loss: 3.8593\n",
      "train error: \n",
      " D loss: 0.207294, G loss: 4.726517, D accuracy: 95.5%, cell accuracy: 97.9%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.206126, G loss: 4.722855, D accuracy: 95.8%, cell accuracy: 97.9%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0083, G loss: 6.2385\n",
      "[84/1762] D loss: 0.1151, G loss: 2.3240\n",
      "[164/1762] D loss: 0.0205, G loss: 4.3923\n",
      "[244/1762] D loss: 0.1026, G loss: 4.6329\n",
      "[324/1762] D loss: 0.0045, G loss: 5.3275\n",
      "[404/1762] D loss: 0.8035, G loss: 3.2527\n",
      "[484/1762] D loss: 0.0530, G loss: 4.8303\n",
      "[564/1762] D loss: 0.0094, G loss: 5.4718\n",
      "[644/1762] D loss: 0.0144, G loss: 4.6168\n",
      "[724/1762] D loss: 0.5381, G loss: 3.7299\n",
      "[804/1762] D loss: 0.2838, G loss: 2.8882\n",
      "[884/1762] D loss: 0.0314, G loss: 4.5415\n",
      "[964/1762] D loss: 0.1501, G loss: 4.4327\n",
      "[1044/1762] D loss: 0.0631, G loss: 3.8918\n",
      "[1124/1762] D loss: 0.6906, G loss: 4.7353\n",
      "[1204/1762] D loss: 0.7780, G loss: 2.3334\n",
      "[1284/1762] D loss: 0.1469, G loss: 3.5815\n",
      "[1364/1762] D loss: 1.5324, G loss: 3.2828\n",
      "[1444/1762] D loss: 0.0476, G loss: 5.7248\n",
      "[1524/1762] D loss: 0.1459, G loss: 5.1801\n",
      "[1604/1762] D loss: 0.0615, G loss: 3.6993\n",
      "[1684/1762] D loss: 0.0106, G loss: 5.0503\n",
      "[1762/1762] D loss: 0.0093, G loss: 6.3574\n",
      "train error: \n",
      " D loss: 0.239549, G loss: 4.430824, D accuracy: 94.3%, cell accuracy: 97.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.222962, G loss: 4.419225, D accuracy: 95.3%, cell accuracy: 97.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0731, G loss: 5.0814\n",
      "[84/1762] D loss: 0.0413, G loss: 3.3717\n",
      "[164/1762] D loss: 0.1397, G loss: 5.4951\n",
      "[244/1762] D loss: 0.0293, G loss: 3.8636\n",
      "[324/1762] D loss: 0.4101, G loss: 3.0916\n",
      "[404/1762] D loss: 0.2665, G loss: 3.2000\n",
      "[484/1762] D loss: 0.0236, G loss: 4.8605\n",
      "[564/1762] D loss: 0.1064, G loss: 4.5228\n",
      "[644/1762] D loss: 0.4629, G loss: 4.0644\n",
      "[724/1762] D loss: 0.0143, G loss: 7.0758\n",
      "[804/1762] D loss: 0.1762, G loss: 3.9030\n",
      "[884/1762] D loss: 0.4017, G loss: 3.8461\n",
      "[964/1762] D loss: 0.1854, G loss: 5.0628\n",
      "[1044/1762] D loss: 0.6118, G loss: 2.1189\n",
      "[1124/1762] D loss: 0.0248, G loss: 4.7034\n",
      "[1204/1762] D loss: 0.3445, G loss: 4.3236\n",
      "[1284/1762] D loss: 0.4279, G loss: 5.5018\n",
      "[1364/1762] D loss: 0.2896, G loss: 2.7595\n",
      "[1444/1762] D loss: 0.0087, G loss: 5.6019\n",
      "[1524/1762] D loss: 0.6931, G loss: 2.8361\n",
      "[1604/1762] D loss: 0.6279, G loss: 2.5206\n",
      "[1684/1762] D loss: 0.0225, G loss: 5.4945\n",
      "[1762/1762] D loss: 0.9490, G loss: 3.4033\n",
      "train error: \n",
      " D loss: 0.262805, G loss: 5.223775, D accuracy: 94.0%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.267669, G loss: 5.245822, D accuracy: 94.3%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6240, G loss: 2.7781\n",
      "[84/1762] D loss: 0.0641, G loss: 4.0706\n",
      "[164/1762] D loss: 0.8213, G loss: 4.0617\n",
      "[244/1762] D loss: 0.0133, G loss: 5.0416\n",
      "[324/1762] D loss: 0.7257, G loss: 2.0673\n",
      "[404/1762] D loss: 0.2443, G loss: 4.3257\n",
      "[484/1762] D loss: 0.3974, G loss: 4.9228\n",
      "[564/1762] D loss: 0.0412, G loss: 3.1857\n",
      "[644/1762] D loss: 0.2749, G loss: 4.0314\n",
      "[724/1762] D loss: 0.0876, G loss: 3.5638\n",
      "[804/1762] D loss: 0.9782, G loss: 2.3323\n",
      "[884/1762] D loss: 0.1987, G loss: 7.1337\n",
      "[964/1762] D loss: 0.1507, G loss: 2.8902\n",
      "[1044/1762] D loss: 0.0093, G loss: 6.1783\n",
      "[1124/1762] D loss: 0.2463, G loss: 3.0863\n",
      "[1204/1762] D loss: 0.0112, G loss: 6.2198\n",
      "[1284/1762] D loss: 0.0989, G loss: 4.5022\n",
      "[1364/1762] D loss: 0.0893, G loss: 3.6785\n",
      "[1444/1762] D loss: 0.0260, G loss: 5.4607\n",
      "[1524/1762] D loss: 0.0085, G loss: 6.4659\n",
      "[1604/1762] D loss: 0.0312, G loss: 2.9216\n",
      "[1684/1762] D loss: 0.7911, G loss: 3.0468\n",
      "[1762/1762] D loss: 0.0045, G loss: 5.7399\n",
      "train error: \n",
      " D loss: 0.251448, G loss: 3.762551, D accuracy: 95.0%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.226798, G loss: 3.750353, D accuracy: 96.0%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3550, G loss: 3.6467\n",
      "[84/1762] D loss: 0.0153, G loss: 5.2491\n",
      "[164/1762] D loss: 0.0074, G loss: 4.6417\n",
      "[244/1762] D loss: 0.0275, G loss: 6.7822\n",
      "[324/1762] D loss: 0.0368, G loss: 4.0068\n",
      "[404/1762] D loss: 0.1694, G loss: 4.1631\n",
      "[484/1762] D loss: 0.4887, G loss: 4.4806\n",
      "[564/1762] D loss: 0.0055, G loss: 6.3373\n",
      "[644/1762] D loss: 0.0197, G loss: 4.4671\n",
      "[724/1762] D loss: 0.3624, G loss: 4.4760\n",
      "[804/1762] D loss: 0.0024, G loss: 6.9646\n",
      "[884/1762] D loss: 0.0913, G loss: 5.1313\n",
      "[964/1762] D loss: 0.1082, G loss: 4.3845\n",
      "[1044/1762] D loss: 0.0054, G loss: 6.2141\n",
      "[1124/1762] D loss: 0.4877, G loss: 3.3125\n",
      "[1204/1762] D loss: 0.4357, G loss: 5.0905\n",
      "[1284/1762] D loss: 0.0132, G loss: 4.8339\n",
      "[1364/1762] D loss: 0.0178, G loss: 5.8944\n",
      "[1444/1762] D loss: 2.0304, G loss: 1.1105\n",
      "[1524/1762] D loss: 0.0631, G loss: 7.7494\n",
      "[1604/1762] D loss: 0.2477, G loss: 2.1583\n",
      "[1684/1762] D loss: 0.0944, G loss: 4.2824\n",
      "[1762/1762] D loss: 0.0372, G loss: 4.0918\n",
      "train error: \n",
      " D loss: 0.273773, G loss: 3.542640, D accuracy: 94.6%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.240487, G loss: 3.511528, D accuracy: 95.7%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0393, G loss: 5.6713\n",
      "[84/1762] D loss: 0.0380, G loss: 6.4287\n",
      "[164/1762] D loss: 0.2047, G loss: 5.5589\n",
      "[244/1762] D loss: 0.1093, G loss: 3.4649\n",
      "[324/1762] D loss: 0.0252, G loss: 5.1279\n",
      "[404/1762] D loss: 0.7026, G loss: 5.4016\n",
      "[484/1762] D loss: 0.0209, G loss: 5.3244\n",
      "[564/1762] D loss: 0.0901, G loss: 3.6153\n",
      "[644/1762] D loss: 0.0266, G loss: 4.2196\n",
      "[724/1762] D loss: 0.3759, G loss: 6.4959\n",
      "[804/1762] D loss: 0.0789, G loss: 5.2707\n",
      "[884/1762] D loss: 0.6505, G loss: 2.5501\n",
      "[964/1762] D loss: 0.9146, G loss: 4.8152\n",
      "[1044/1762] D loss: 0.6475, G loss: 5.3183\n",
      "[1124/1762] D loss: 2.9766, G loss: 2.9567\n",
      "[1204/1762] D loss: 3.6081, G loss: 1.0756\n",
      "[1284/1762] D loss: 1.5742, G loss: 1.1376\n",
      "[1364/1762] D loss: 1.9934, G loss: 1.4499\n",
      "[1444/1762] D loss: 3.7242, G loss: 0.3037\n",
      "[1524/1762] D loss: 1.6905, G loss: 1.9123\n",
      "[1604/1762] D loss: 0.7925, G loss: 1.4973\n",
      "[1684/1762] D loss: 0.5026, G loss: 3.6706\n",
      "[1762/1762] D loss: 0.8296, G loss: 1.2666\n",
      "train error: \n",
      " D loss: 0.589066, G loss: 2.074051, D accuracy: 88.1%, cell accuracy: 93.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.570320, G loss: 2.203012, D accuracy: 89.0%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7644, G loss: 0.7720\n",
      "[84/1762] D loss: 0.7017, G loss: 1.8101\n",
      "[164/1762] D loss: 1.4194, G loss: 1.6977\n",
      "[244/1762] D loss: 2.3499, G loss: 1.6905\n",
      "[324/1762] D loss: 0.5189, G loss: 2.3122\n",
      "[404/1762] D loss: 1.9406, G loss: 0.9615\n",
      "[484/1762] D loss: 0.9461, G loss: 1.4381\n",
      "[564/1762] D loss: 1.4081, G loss: 0.9336\n",
      "[644/1762] D loss: 1.1445, G loss: 1.2036\n",
      "[724/1762] D loss: 1.1337, G loss: 0.6427\n",
      "[804/1762] D loss: 1.6352, G loss: 0.6202\n",
      "[884/1762] D loss: 0.8392, G loss: 2.4380\n",
      "[964/1762] D loss: 0.9444, G loss: 1.2329\n",
      "[1044/1762] D loss: 1.5012, G loss: 1.5376\n",
      "[1124/1762] D loss: 0.6326, G loss: 2.6031\n",
      "[1204/1762] D loss: 1.5658, G loss: 0.6008\n",
      "[1284/1762] D loss: 1.1994, G loss: 1.1632\n",
      "[1364/1762] D loss: 1.2263, G loss: 0.7350\n",
      "[1444/1762] D loss: 0.6127, G loss: 1.6100\n",
      "[1524/1762] D loss: 1.2254, G loss: 0.6987\n",
      "[1604/1762] D loss: 0.8678, G loss: 2.1202\n",
      "[1684/1762] D loss: 0.7063, G loss: 2.1935\n",
      "[1762/1762] D loss: 0.8014, G loss: 0.9572\n",
      "train error: \n",
      " D loss: 0.966903, G loss: 1.386866, D accuracy: 73.1%, cell accuracy: 96.8%, board accuracy: 12.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.927179, G loss: 1.428026, D accuracy: 74.4%, cell accuracy: 96.7%, board accuracy: 12.5% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6297, G loss: 1.7086\n",
      "[84/1762] D loss: 1.0083, G loss: 1.1404\n",
      "[164/1762] D loss: 1.2321, G loss: 0.9252\n",
      "[244/1762] D loss: 1.2429, G loss: 1.2979\n",
      "[324/1762] D loss: 1.6813, G loss: 1.1182\n",
      "[404/1762] D loss: 0.8320, G loss: 1.1637\n",
      "[484/1762] D loss: 1.5028, G loss: 1.0476\n",
      "[564/1762] D loss: 1.2418, G loss: 1.3679\n",
      "[644/1762] D loss: 1.3286, G loss: 1.0952\n",
      "[724/1762] D loss: 1.0030, G loss: 2.0015\n",
      "[804/1762] D loss: 1.1553, G loss: 1.2032\n",
      "[884/1762] D loss: 1.4845, G loss: 1.3475\n",
      "[964/1762] D loss: 1.3675, G loss: 0.8474\n",
      "[1044/1762] D loss: 1.5422, G loss: 0.6343\n",
      "[1124/1762] D loss: 1.4361, G loss: 0.6257\n",
      "[1204/1762] D loss: 1.2796, G loss: 0.9846\n",
      "[1284/1762] D loss: 1.1137, G loss: 0.7915\n",
      "[1364/1762] D loss: 1.1745, G loss: 0.9451\n",
      "[1444/1762] D loss: 1.3473, G loss: 0.6596\n",
      "[1524/1762] D loss: 2.2162, G loss: 1.6569\n",
      "[1604/1762] D loss: 1.3711, G loss: 1.3739\n",
      "[1684/1762] D loss: 1.2244, G loss: 1.1768\n",
      "[1762/1762] D loss: 1.0841, G loss: 0.7362\n",
      "train error: \n",
      " D loss: 1.277018, G loss: 1.010231, D accuracy: 61.4%, cell accuracy: 98.8%, board accuracy: 15.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281135, G loss: 0.981394, D accuracy: 60.9%, cell accuracy: 98.7%, board accuracy: 15.7% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2702, G loss: 0.9728\n",
      "[84/1762] D loss: 0.8895, G loss: 0.9889\n",
      "[164/1762] D loss: 1.2849, G loss: 0.7425\n",
      "[244/1762] D loss: 1.3308, G loss: 0.6566\n",
      "[324/1762] D loss: 1.4995, G loss: 0.7977\n",
      "[404/1762] D loss: 1.2539, G loss: 0.7883\n",
      "[484/1762] D loss: 1.5333, G loss: 0.5232\n",
      "[564/1762] D loss: 1.0907, G loss: 1.1408\n",
      "[644/1762] D loss: 1.2958, G loss: 0.5436\n",
      "[724/1762] D loss: 1.3072, G loss: 0.9340\n",
      "[804/1762] D loss: 1.3531, G loss: 0.6948\n",
      "[884/1762] D loss: 1.4642, G loss: 0.9048\n",
      "[964/1762] D loss: 1.5337, G loss: 0.7889\n",
      "[1044/1762] D loss: 1.5234, G loss: 1.0664\n",
      "[1124/1762] D loss: 1.5870, G loss: 0.8480\n",
      "[1204/1762] D loss: 0.9966, G loss: 0.8305\n",
      "[1284/1762] D loss: 1.0611, G loss: 0.8658\n",
      "[1364/1762] D loss: 1.4898, G loss: 0.8019\n",
      "[1444/1762] D loss: 0.8508, G loss: 1.4203\n",
      "[1524/1762] D loss: 1.4459, G loss: 0.9751\n",
      "[1604/1762] D loss: 1.2748, G loss: 0.6898\n",
      "[1684/1762] D loss: 1.4249, G loss: 0.7815\n",
      "[1762/1762] D loss: 0.4727, G loss: 2.4769\n",
      "train error: \n",
      " D loss: 1.425732, G loss: 0.511329, D accuracy: 56.9%, cell accuracy: 98.8%, board accuracy: 19.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396185, G loss: 0.533405, D accuracy: 57.8%, cell accuracy: 98.7%, board accuracy: 19.3% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2143, G loss: 0.6302\n",
      "[84/1762] D loss: 1.3711, G loss: 1.6188\n",
      "[164/1762] D loss: 1.2442, G loss: 0.9328\n",
      "[244/1762] D loss: 1.2273, G loss: 0.5257\n",
      "[324/1762] D loss: 1.0697, G loss: 1.3682\n",
      "[404/1762] D loss: 1.3963, G loss: 1.0348\n",
      "[484/1762] D loss: 1.2582, G loss: 0.9991\n",
      "[564/1762] D loss: 1.3368, G loss: 0.7289\n",
      "[644/1762] D loss: 1.3886, G loss: 0.6217\n",
      "[724/1762] D loss: 1.3533, G loss: 0.7824\n",
      "[804/1762] D loss: 1.4350, G loss: 0.7788\n",
      "[884/1762] D loss: 1.1848, G loss: 0.7919\n",
      "[964/1762] D loss: 1.3866, G loss: 0.8617\n",
      "[1044/1762] D loss: 1.1844, G loss: 1.1471\n",
      "[1124/1762] D loss: 1.1726, G loss: 0.8955\n",
      "[1204/1762] D loss: 1.4281, G loss: 0.8900\n",
      "[1284/1762] D loss: 1.4464, G loss: 0.5942\n",
      "[1364/1762] D loss: 1.4517, G loss: 0.5582\n",
      "[1444/1762] D loss: 1.0940, G loss: 1.0244\n",
      "[1524/1762] D loss: 0.9915, G loss: 1.0042\n",
      "[1604/1762] D loss: 1.4464, G loss: 0.6465\n",
      "[1684/1762] D loss: 1.2916, G loss: 0.9480\n",
      "[1762/1762] D loss: 1.4639, G loss: 0.5346\n",
      "train error: \n",
      " D loss: 1.339360, G loss: 0.679351, D accuracy: 56.3%, cell accuracy: 99.1%, board accuracy: 27.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342193, G loss: 0.660706, D accuracy: 56.6%, cell accuracy: 99.0%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3599, G loss: 0.8250\n",
      "[84/1762] D loss: 1.3987, G loss: 0.6067\n",
      "[164/1762] D loss: 1.3940, G loss: 0.7045\n",
      "[244/1762] D loss: 1.6513, G loss: 1.3908\n",
      "[324/1762] D loss: 1.4675, G loss: 0.8301\n",
      "[404/1762] D loss: 1.2997, G loss: 0.6000\n",
      "[484/1762] D loss: 1.3171, G loss: 0.6532\n",
      "[564/1762] D loss: 1.1870, G loss: 1.0210\n",
      "[644/1762] D loss: 1.3541, G loss: 0.6482\n",
      "[724/1762] D loss: 1.3469, G loss: 1.1607\n",
      "[804/1762] D loss: 1.2345, G loss: 0.8206\n",
      "[884/1762] D loss: 1.4429, G loss: 0.5283\n",
      "[964/1762] D loss: 1.3213, G loss: 0.5208\n",
      "[1044/1762] D loss: 1.4013, G loss: 0.5370\n",
      "[1124/1762] D loss: 1.3059, G loss: 1.0327\n",
      "[1204/1762] D loss: 1.3523, G loss: 0.8633\n",
      "[1284/1762] D loss: 1.1423, G loss: 0.7738\n",
      "[1364/1762] D loss: 0.7431, G loss: 1.1863\n",
      "[1444/1762] D loss: 0.9733, G loss: 1.1325\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.5641\n",
      "[1604/1762] D loss: 1.2457, G loss: 0.7758\n",
      "[1684/1762] D loss: 1.3513, G loss: 0.7904\n",
      "[1762/1762] D loss: 1.0382, G loss: 1.3944\n",
      "train error: \n",
      " D loss: 1.486373, G loss: 1.335763, D accuracy: 53.8%, cell accuracy: 99.1%, board accuracy: 28.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.470104, G loss: 1.330143, D accuracy: 54.0%, cell accuracy: 99.0%, board accuracy: 27.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5930, G loss: 1.2569\n",
      "[84/1762] D loss: 1.4250, G loss: 0.6630\n",
      "[164/1762] D loss: 1.2036, G loss: 0.5701\n",
      "[244/1762] D loss: 1.4558, G loss: 0.5448\n",
      "[324/1762] D loss: 1.1576, G loss: 0.9890\n",
      "[404/1762] D loss: 1.4905, G loss: 0.4574\n",
      "[484/1762] D loss: 1.2693, G loss: 0.8479\n",
      "[564/1762] D loss: 1.2109, G loss: 0.7966\n",
      "[644/1762] D loss: 1.5196, G loss: 1.1001\n",
      "[724/1762] D loss: 1.1890, G loss: 1.3809\n",
      "[804/1762] D loss: 1.3112, G loss: 0.8605\n",
      "[884/1762] D loss: 1.3127, G loss: 0.8572\n",
      "[964/1762] D loss: 1.4215, G loss: 0.6780\n",
      "[1044/1762] D loss: 1.4624, G loss: 0.5048\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.7063\n",
      "[1204/1762] D loss: 1.3613, G loss: 0.7055\n",
      "[1284/1762] D loss: 1.3921, G loss: 0.8180\n",
      "[1364/1762] D loss: 1.4223, G loss: 0.6737\n",
      "[1444/1762] D loss: 1.3944, G loss: 0.7743\n",
      "[1524/1762] D loss: 1.4232, G loss: 0.6293\n",
      "[1604/1762] D loss: 1.4248, G loss: 0.9150\n",
      "[1684/1762] D loss: 1.3481, G loss: 1.0046\n",
      "[1762/1762] D loss: 1.3751, G loss: 0.7126\n",
      "train error: \n",
      " D loss: 1.333290, G loss: 0.901483, D accuracy: 56.2%, cell accuracy: 99.2%, board accuracy: 30.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326399, G loss: 0.893791, D accuracy: 56.9%, cell accuracy: 99.1%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3961, G loss: 0.7902\n",
      "[84/1762] D loss: 1.4156, G loss: 0.9154\n",
      "[164/1762] D loss: 1.4092, G loss: 0.8504\n",
      "[244/1762] D loss: 1.1634, G loss: 0.8166\n",
      "[324/1762] D loss: 1.1737, G loss: 0.9271\n",
      "[404/1762] D loss: 1.3029, G loss: 0.8822\n",
      "[484/1762] D loss: 1.4089, G loss: 0.9277\n",
      "[564/1762] D loss: 1.4244, G loss: 0.8906\n",
      "[644/1762] D loss: 1.3789, G loss: 0.8227\n",
      "[724/1762] D loss: 1.2246, G loss: 0.8441\n",
      "[804/1762] D loss: 1.4070, G loss: 0.8180\n",
      "[884/1762] D loss: 1.3355, G loss: 0.6602\n",
      "[964/1762] D loss: 1.4003, G loss: 0.5702\n",
      "[1044/1762] D loss: 1.4040, G loss: 0.6166\n",
      "[1124/1762] D loss: 1.2295, G loss: 0.7710\n",
      "[1204/1762] D loss: 1.2001, G loss: 0.7967\n",
      "[1284/1762] D loss: 1.4035, G loss: 0.6776\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.7378\n",
      "[1444/1762] D loss: 1.0722, G loss: 1.2087\n",
      "[1524/1762] D loss: 1.2098, G loss: 0.8772\n",
      "[1604/1762] D loss: 1.2352, G loss: 0.9547\n",
      "[1684/1762] D loss: 1.1279, G loss: 0.9826\n",
      "[1762/1762] D loss: 0.8739, G loss: 0.9033\n",
      "train error: \n",
      " D loss: 1.341591, G loss: 0.638064, D accuracy: 56.5%, cell accuracy: 99.3%, board accuracy: 37.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337710, G loss: 0.635397, D accuracy: 57.8%, cell accuracy: 99.2%, board accuracy: 33.2% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3475, G loss: 0.6882\n",
      "[84/1762] D loss: 1.4526, G loss: 0.9032\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6874\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6980\n",
      "[324/1762] D loss: 1.4078, G loss: 1.3809\n",
      "[404/1762] D loss: 1.2026, G loss: 0.9035\n",
      "[484/1762] D loss: 1.3648, G loss: 1.2076\n",
      "[564/1762] D loss: 1.4012, G loss: 0.8401\n",
      "[644/1762] D loss: 1.3207, G loss: 1.0073\n",
      "[724/1762] D loss: 1.4143, G loss: 0.8972\n",
      "[804/1762] D loss: 1.3935, G loss: 0.7082\n",
      "[884/1762] D loss: 1.4489, G loss: 0.9521\n",
      "[964/1762] D loss: 1.1961, G loss: 1.1502\n",
      "[1044/1762] D loss: 1.4313, G loss: 0.6051\n",
      "[1124/1762] D loss: 1.3287, G loss: 0.5660\n",
      "[1204/1762] D loss: 1.3458, G loss: 0.6109\n",
      "[1284/1762] D loss: 1.4581, G loss: 0.5710\n",
      "[1364/1762] D loss: 1.2267, G loss: 0.7243\n",
      "[1444/1762] D loss: 1.3621, G loss: 0.7815\n",
      "[1524/1762] D loss: 1.2442, G loss: 0.9125\n",
      "[1604/1762] D loss: 1.3848, G loss: 0.7531\n",
      "[1684/1762] D loss: 1.3710, G loss: 0.5638\n",
      "[1762/1762] D loss: 1.5308, G loss: 0.3937\n",
      "train error: \n",
      " D loss: 1.441983, G loss: 0.541218, D accuracy: 54.6%, cell accuracy: 99.0%, board accuracy: 23.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.451305, G loss: 0.536246, D accuracy: 54.9%, cell accuracy: 98.8%, board accuracy: 20.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5710, G loss: 0.5018\n",
      "[84/1762] D loss: 1.4010, G loss: 0.8480\n",
      "[164/1762] D loss: 1.3340, G loss: 0.7515\n",
      "[244/1762] D loss: 1.3785, G loss: 0.8950\n",
      "[324/1762] D loss: 1.3512, G loss: 0.6610\n",
      "[404/1762] D loss: 1.2690, G loss: 0.9211\n",
      "[484/1762] D loss: 1.3966, G loss: 0.8425\n",
      "[564/1762] D loss: 1.4069, G loss: 0.6376\n",
      "[644/1762] D loss: 1.2785, G loss: 0.7220\n",
      "[724/1762] D loss: 1.4067, G loss: 0.8246\n",
      "[804/1762] D loss: 1.3739, G loss: 0.7068\n",
      "[884/1762] D loss: 1.2183, G loss: 0.6404\n",
      "[964/1762] D loss: 1.4473, G loss: 0.4765\n",
      "[1044/1762] D loss: 1.4452, G loss: 0.5254\n",
      "[1124/1762] D loss: 1.0721, G loss: 0.8444\n",
      "[1204/1762] D loss: 1.2977, G loss: 0.9108\n",
      "[1284/1762] D loss: 1.4256, G loss: 0.6095\n",
      "[1364/1762] D loss: 1.5195, G loss: 0.4739\n",
      "[1444/1762] D loss: 1.1795, G loss: 0.9019\n",
      "[1524/1762] D loss: 1.3315, G loss: 0.5235\n",
      "[1604/1762] D loss: 1.3977, G loss: 0.6818\n",
      "[1684/1762] D loss: 1.3742, G loss: 0.7306\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6484\n",
      "train error: \n",
      " D loss: 1.342220, G loss: 0.626858, D accuracy: 56.1%, cell accuracy: 99.4%, board accuracy: 52.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339871, G loss: 0.623777, D accuracy: 55.9%, cell accuracy: 99.4%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4982, G loss: 0.4650\n",
      "[84/1762] D loss: 1.4243, G loss: 0.6821\n",
      "[164/1762] D loss: 1.4425, G loss: 0.5781\n",
      "[244/1762] D loss: 1.2277, G loss: 0.8389\n",
      "[324/1762] D loss: 1.0452, G loss: 0.8470\n",
      "[404/1762] D loss: 1.4699, G loss: 1.0119\n",
      "[484/1762] D loss: 1.3916, G loss: 0.8167\n",
      "[564/1762] D loss: 1.3906, G loss: 0.7932\n",
      "[644/1762] D loss: 1.4152, G loss: 0.7254\n",
      "[724/1762] D loss: 1.3787, G loss: 0.6697\n",
      "[804/1762] D loss: 1.4089, G loss: 0.6024\n",
      "[884/1762] D loss: 1.3626, G loss: 0.7438\n",
      "[964/1762] D loss: 1.0537, G loss: 0.8334\n",
      "[1044/1762] D loss: 1.4278, G loss: 0.5732\n",
      "[1124/1762] D loss: 1.3805, G loss: 0.6562\n",
      "[1204/1762] D loss: 1.2069, G loss: 0.8188\n",
      "[1284/1762] D loss: 1.4369, G loss: 0.6633\n",
      "[1364/1762] D loss: 1.4440, G loss: 0.8531\n",
      "[1444/1762] D loss: 1.2066, G loss: 0.7933\n",
      "[1524/1762] D loss: 1.3393, G loss: 0.8876\n",
      "[1604/1762] D loss: 1.3572, G loss: 0.5310\n",
      "[1684/1762] D loss: 1.4001, G loss: 0.6476\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.6645\n",
      "train error: \n",
      " D loss: 1.320488, G loss: 0.796152, D accuracy: 56.2%, cell accuracy: 99.5%, board accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313636, G loss: 0.789637, D accuracy: 56.5%, cell accuracy: 99.5%, board accuracy: 53.6% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4316, G loss: 0.6606\n",
      "[84/1762] D loss: 1.4174, G loss: 0.7454\n",
      "[164/1762] D loss: 1.4103, G loss: 0.9354\n",
      "[244/1762] D loss: 1.1925, G loss: 1.0332\n",
      "[324/1762] D loss: 1.3980, G loss: 0.8958\n",
      "[404/1762] D loss: 1.6611, G loss: 1.3441\n",
      "[484/1762] D loss: 1.2209, G loss: 0.7387\n",
      "[564/1762] D loss: 1.1450, G loss: 0.8959\n",
      "[644/1762] D loss: 1.3225, G loss: 0.6259\n",
      "[724/1762] D loss: 1.2256, G loss: 0.7749\n",
      "[804/1762] D loss: 1.3835, G loss: 0.8265\n",
      "[884/1762] D loss: 1.3997, G loss: 0.7839\n",
      "[964/1762] D loss: 1.1914, G loss: 0.9720\n",
      "[1044/1762] D loss: 1.1436, G loss: 1.4481\n",
      "[1124/1762] D loss: 1.2307, G loss: 0.7236\n",
      "[1204/1762] D loss: 1.4275, G loss: 0.7030\n",
      "[1284/1762] D loss: 1.5722, G loss: 0.9085\n",
      "[1364/1762] D loss: 1.4037, G loss: 0.7019\n",
      "[1444/1762] D loss: 1.2305, G loss: 0.9580\n",
      "[1524/1762] D loss: 1.4070, G loss: 0.6005\n",
      "[1604/1762] D loss: 1.4018, G loss: 0.7246\n",
      "[1684/1762] D loss: 1.2748, G loss: 0.6455\n",
      "[1762/1762] D loss: 1.4244, G loss: 0.9232\n",
      "train error: \n",
      " D loss: 1.328578, G loss: 0.800553, D accuracy: 55.8%, cell accuracy: 99.5%, board accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316100, G loss: 0.806296, D accuracy: 57.0%, cell accuracy: 99.5%, board accuracy: 56.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4008, G loss: 0.7120\n",
      "[84/1762] D loss: 1.4205, G loss: 0.4994\n",
      "[164/1762] D loss: 1.4264, G loss: 0.5383\n",
      "[244/1762] D loss: 1.3889, G loss: 0.5797\n",
      "[324/1762] D loss: 1.4635, G loss: 1.0923\n",
      "[404/1762] D loss: 1.4093, G loss: 0.6468\n",
      "[484/1762] D loss: 1.1939, G loss: 0.6574\n",
      "[564/1762] D loss: 1.4324, G loss: 0.6020\n",
      "[644/1762] D loss: 1.3657, G loss: 0.7653\n",
      "[724/1762] D loss: 1.3930, G loss: 0.5604\n",
      "[804/1762] D loss: 1.1569, G loss: 1.0467\n",
      "[884/1762] D loss: 1.3048, G loss: 1.4288\n",
      "[964/1762] D loss: 1.3909, G loss: 0.6372\n",
      "[1044/1762] D loss: 1.1907, G loss: 0.7999\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.6953\n",
      "[1204/1762] D loss: 1.3914, G loss: 0.6942\n",
      "[1284/1762] D loss: 1.3712, G loss: 0.8820\n",
      "[1364/1762] D loss: 1.4377, G loss: 1.0262\n",
      "[1444/1762] D loss: 1.1460, G loss: 0.7624\n",
      "[1524/1762] D loss: 1.2058, G loss: 0.8911\n",
      "[1604/1762] D loss: 1.1831, G loss: 0.6980\n",
      "[1684/1762] D loss: 1.1378, G loss: 0.8321\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6880\n",
      "train error: \n",
      " D loss: 1.303985, G loss: 0.797330, D accuracy: 55.9%, cell accuracy: 99.5%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293465, G loss: 0.800421, D accuracy: 56.6%, cell accuracy: 99.5%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3803, G loss: 0.7182\n",
      "[84/1762] D loss: 1.3351, G loss: 0.9129\n",
      "[164/1762] D loss: 1.1322, G loss: 0.8833\n",
      "[244/1762] D loss: 1.1819, G loss: 0.9838\n",
      "[324/1762] D loss: 1.4194, G loss: 0.6335\n",
      "[404/1762] D loss: 1.0568, G loss: 1.0356\n",
      "[484/1762] D loss: 1.2567, G loss: 0.7065\n",
      "[564/1762] D loss: 1.4445, G loss: 0.5381\n",
      "[644/1762] D loss: 1.2052, G loss: 0.9245\n",
      "[724/1762] D loss: 1.4440, G loss: 0.5209\n",
      "[804/1762] D loss: 1.1706, G loss: 0.8321\n",
      "[884/1762] D loss: 1.4184, G loss: 0.6570\n",
      "[964/1762] D loss: 1.3447, G loss: 0.7530\n",
      "[1044/1762] D loss: 1.3841, G loss: 0.5410\n",
      "[1124/1762] D loss: 1.1915, G loss: 0.9348\n",
      "[1204/1762] D loss: 1.4040, G loss: 0.8384\n",
      "[1284/1762] D loss: 1.3720, G loss: 0.5086\n",
      "[1364/1762] D loss: 1.4854, G loss: 0.8466\n",
      "[1444/1762] D loss: 1.3733, G loss: 0.6653\n",
      "[1524/1762] D loss: 1.1823, G loss: 0.8796\n",
      "[1604/1762] D loss: 1.3442, G loss: 0.7492\n",
      "[1684/1762] D loss: 1.2001, G loss: 0.8810\n",
      "[1762/1762] D loss: 1.3855, G loss: 0.6337\n",
      "train error: \n",
      " D loss: 1.316154, G loss: 0.807880, D accuracy: 55.9%, cell accuracy: 99.6%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300153, G loss: 0.819299, D accuracy: 57.5%, cell accuracy: 99.5%, board accuracy: 56.4% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.6343\n",
      "[84/1762] D loss: 1.3997, G loss: 0.7717\n",
      "[164/1762] D loss: 1.3824, G loss: 0.8793\n",
      "[244/1762] D loss: 1.3582, G loss: 0.7774\n",
      "[324/1762] D loss: 1.3967, G loss: 0.7159\n",
      "[404/1762] D loss: 1.3911, G loss: 0.7962\n",
      "[484/1762] D loss: 1.1377, G loss: 0.8723\n",
      "[564/1762] D loss: 1.2006, G loss: 0.7692\n",
      "[644/1762] D loss: 1.4126, G loss: 0.6686\n",
      "[724/1762] D loss: 1.1286, G loss: 0.9254\n",
      "[804/1762] D loss: 1.4078, G loss: 0.6913\n",
      "[884/1762] D loss: 1.1410, G loss: 0.9402\n",
      "[964/1762] D loss: 1.4544, G loss: 0.8667\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.6405\n",
      "[1124/1762] D loss: 1.3805, G loss: 1.1485\n",
      "[1204/1762] D loss: 1.3480, G loss: 0.6766\n",
      "[1284/1762] D loss: 1.4011, G loss: 0.6080\n",
      "[1364/1762] D loss: 1.4148, G loss: 0.7180\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6848\n",
      "[1524/1762] D loss: 1.1866, G loss: 1.0722\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.8900\n",
      "[1684/1762] D loss: 1.4048, G loss: 0.6899\n",
      "[1762/1762] D loss: 1.3613, G loss: 0.5855\n",
      "train error: \n",
      " D loss: 1.325242, G loss: 0.680817, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310145, G loss: 0.696024, D accuracy: 56.0%, cell accuracy: 99.5%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4133, G loss: 0.6153\n",
      "[84/1762] D loss: 1.4083, G loss: 0.7154\n",
      "[164/1762] D loss: 1.3959, G loss: 0.8225\n",
      "[244/1762] D loss: 0.8533, G loss: 1.1423\n",
      "[324/1762] D loss: 1.1529, G loss: 1.0286\n",
      "[404/1762] D loss: 1.3017, G loss: 0.8296\n",
      "[484/1762] D loss: 0.9629, G loss: 1.1198\n",
      "[564/1762] D loss: 1.3693, G loss: 0.6356\n",
      "[644/1762] D loss: 1.3985, G loss: 0.5665\n",
      "[724/1762] D loss: 1.3922, G loss: 0.6398\n",
      "[804/1762] D loss: 1.3453, G loss: 0.9201\n",
      "[884/1762] D loss: 1.4037, G loss: 0.6820\n",
      "[964/1762] D loss: 1.3920, G loss: 0.5459\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.6074\n",
      "[1124/1762] D loss: 0.7501, G loss: 0.9527\n",
      "[1204/1762] D loss: 1.4041, G loss: 0.7157\n",
      "[1284/1762] D loss: 1.5000, G loss: 0.9524\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.7940\n",
      "[1444/1762] D loss: 1.4071, G loss: 0.7378\n",
      "[1524/1762] D loss: 1.1731, G loss: 0.7920\n",
      "[1604/1762] D loss: 1.4022, G loss: 0.7430\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.8073\n",
      "[1762/1762] D loss: 1.3625, G loss: 0.7920\n",
      "train error: \n",
      " D loss: 1.308504, G loss: 0.870464, D accuracy: 56.3%, cell accuracy: 99.5%, board accuracy: 53.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293168, G loss: 0.885426, D accuracy: 57.4%, cell accuracy: 99.5%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4124, G loss: 0.8071\n",
      "[84/1762] D loss: 1.5317, G loss: 1.0641\n",
      "[164/1762] D loss: 1.1078, G loss: 1.1100\n",
      "[244/1762] D loss: 1.4166, G loss: 0.7765\n",
      "[324/1762] D loss: 1.4089, G loss: 0.6000\n",
      "[404/1762] D loss: 1.2114, G loss: 1.0759\n",
      "[484/1762] D loss: 1.4035, G loss: 0.6258\n",
      "[564/1762] D loss: 1.1564, G loss: 0.8756\n",
      "[644/1762] D loss: 1.1889, G loss: 1.4027\n",
      "[724/1762] D loss: 1.1962, G loss: 0.8221\n",
      "[804/1762] D loss: 1.3614, G loss: 0.7433\n",
      "[884/1762] D loss: 1.3689, G loss: 0.6223\n",
      "[964/1762] D loss: 0.9228, G loss: 0.9100\n",
      "[1044/1762] D loss: 1.1941, G loss: 0.8301\n",
      "[1124/1762] D loss: 1.4092, G loss: 0.8434\n",
      "[1204/1762] D loss: 1.4012, G loss: 0.7115\n",
      "[1284/1762] D loss: 1.6020, G loss: 0.7858\n",
      "[1364/1762] D loss: 1.4080, G loss: 0.7522\n",
      "[1444/1762] D loss: 1.3622, G loss: 0.7248\n",
      "[1524/1762] D loss: 1.1973, G loss: 0.7216\n",
      "[1604/1762] D loss: 1.4177, G loss: 0.6694\n",
      "[1684/1762] D loss: 1.4017, G loss: 0.6603\n",
      "[1762/1762] D loss: 1.0294, G loss: 0.9697\n",
      "train error: \n",
      " D loss: 1.300529, G loss: 0.713488, D accuracy: 57.7%, cell accuracy: 99.6%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286354, G loss: 0.718749, D accuracy: 59.7%, cell accuracy: 99.6%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4176, G loss: 0.6051\n",
      "[84/1762] D loss: 1.4095, G loss: 0.6384\n",
      "[164/1762] D loss: 1.4210, G loss: 0.5665\n",
      "[244/1762] D loss: 1.1777, G loss: 1.2029\n",
      "[324/1762] D loss: 1.4024, G loss: 0.6838\n",
      "[404/1762] D loss: 1.4137, G loss: 0.5261\n",
      "[484/1762] D loss: 1.2715, G loss: 0.7676\n",
      "[564/1762] D loss: 1.4772, G loss: 1.0411\n",
      "[644/1762] D loss: 1.2323, G loss: 1.1350\n",
      "[724/1762] D loss: 1.4176, G loss: 0.5009\n",
      "[804/1762] D loss: 1.3823, G loss: 0.6850\n",
      "[884/1762] D loss: 1.3954, G loss: 0.7319\n",
      "[964/1762] D loss: 1.2055, G loss: 0.8296\n",
      "[1044/1762] D loss: 1.4009, G loss: 0.8314\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.7483\n",
      "[1204/1762] D loss: 1.3651, G loss: 0.8046\n",
      "[1284/1762] D loss: 1.3956, G loss: 0.8237\n",
      "[1364/1762] D loss: 1.3984, G loss: 0.8797\n",
      "[1444/1762] D loss: 1.4019, G loss: 0.7459\n",
      "[1524/1762] D loss: 0.8750, G loss: 1.4689\n",
      "[1604/1762] D loss: 1.4060, G loss: 0.6031\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.7826\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.5375\n",
      "train error: \n",
      " D loss: 1.315710, G loss: 0.682096, D accuracy: 55.6%, cell accuracy: 99.6%, board accuracy: 60.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297508, G loss: 0.696776, D accuracy: 57.2%, cell accuracy: 99.5%, board accuracy: 58.6% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1820, G loss: 0.7282\n",
      "[84/1762] D loss: 1.4200, G loss: 0.8201\n",
      "[164/1762] D loss: 1.3634, G loss: 0.7345\n",
      "[244/1762] D loss: 1.1198, G loss: 0.9898\n",
      "[324/1762] D loss: 1.4097, G loss: 0.5826\n",
      "[404/1762] D loss: 1.3946, G loss: 0.7342\n",
      "[484/1762] D loss: 1.3383, G loss: 0.7121\n",
      "[564/1762] D loss: 1.1359, G loss: 0.7864\n",
      "[644/1762] D loss: 1.3948, G loss: 0.7635\n",
      "[724/1762] D loss: 1.1384, G loss: 0.8186\n",
      "[804/1762] D loss: 1.3536, G loss: 0.6687\n",
      "[884/1762] D loss: 1.3474, G loss: 0.6760\n",
      "[964/1762] D loss: 1.4042, G loss: 0.7446\n",
      "[1044/1762] D loss: 1.3842, G loss: 0.7237\n",
      "[1124/1762] D loss: 1.3763, G loss: 0.7210\n",
      "[1204/1762] D loss: 1.1394, G loss: 1.1628\n",
      "[1284/1762] D loss: 1.1277, G loss: 1.1668\n",
      "[1364/1762] D loss: 1.4105, G loss: 0.9800\n",
      "[1444/1762] D loss: 1.3843, G loss: 0.7780\n",
      "[1524/1762] D loss: 1.4001, G loss: 0.5892\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.6392\n",
      "[1684/1762] D loss: 1.3984, G loss: 0.8233\n",
      "[1762/1762] D loss: 0.8741, G loss: 1.1991\n",
      "train error: \n",
      " D loss: 1.342565, G loss: 0.993482, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320745, G loss: 1.016303, D accuracy: 55.8%, cell accuracy: 99.5%, board accuracy: 63.9% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4154, G loss: 0.8226\n",
      "[84/1762] D loss: 1.3845, G loss: 0.6804\n",
      "[164/1762] D loss: 1.4064, G loss: 0.6082\n",
      "[244/1762] D loss: 1.4421, G loss: 0.8093\n",
      "[324/1762] D loss: 1.1558, G loss: 0.8744\n",
      "[404/1762] D loss: 1.3907, G loss: 0.7029\n",
      "[484/1762] D loss: 1.3677, G loss: 0.7995\n",
      "[564/1762] D loss: 1.4361, G loss: 0.9423\n",
      "[644/1762] D loss: 1.1744, G loss: 0.9580\n",
      "[724/1762] D loss: 1.4581, G loss: 0.8838\n",
      "[804/1762] D loss: 1.3835, G loss: 0.7283\n",
      "[884/1762] D loss: 1.4292, G loss: 0.8137\n",
      "[964/1762] D loss: 1.3992, G loss: 0.7587\n",
      "[1044/1762] D loss: 0.6703, G loss: 1.2533\n",
      "[1124/1762] D loss: 1.1140, G loss: 0.9219\n",
      "[1204/1762] D loss: 1.4165, G loss: 0.5282\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.5447\n",
      "[1364/1762] D loss: 1.3228, G loss: 0.6624\n",
      "[1444/1762] D loss: 1.4090, G loss: 0.7589\n",
      "[1524/1762] D loss: 1.4169, G loss: 0.7373\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.7775\n",
      "[1684/1762] D loss: 1.1541, G loss: 1.0147\n",
      "[1762/1762] D loss: 1.4326, G loss: 0.8720\n",
      "train error: \n",
      " D loss: 1.303532, G loss: 0.806789, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281331, G loss: 0.833657, D accuracy: 57.4%, cell accuracy: 99.6%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.7202\n",
      "[84/1762] D loss: 1.3723, G loss: 0.6653\n",
      "[164/1762] D loss: 1.4074, G loss: 0.5805\n",
      "[244/1762] D loss: 1.1950, G loss: 1.1052\n",
      "[324/1762] D loss: 1.4178, G loss: 0.5899\n",
      "[404/1762] D loss: 1.1545, G loss: 0.7480\n",
      "[484/1762] D loss: 1.4119, G loss: 0.5796\n",
      "[564/1762] D loss: 1.3928, G loss: 0.6373\n",
      "[644/1762] D loss: 1.3933, G loss: 0.6130\n",
      "[724/1762] D loss: 1.4211, G loss: 0.5354\n",
      "[804/1762] D loss: 1.4042, G loss: 0.5401\n",
      "[884/1762] D loss: 1.2309, G loss: 0.7979\n",
      "[964/1762] D loss: 1.0910, G loss: 1.0542\n",
      "[1044/1762] D loss: 1.4210, G loss: 0.5685\n",
      "[1124/1762] D loss: 1.4113, G loss: 0.5440\n",
      "[1204/1762] D loss: 1.4027, G loss: 0.7717\n",
      "[1284/1762] D loss: 1.1276, G loss: 0.8605\n",
      "[1364/1762] D loss: 1.1946, G loss: 0.6976\n",
      "[1444/1762] D loss: 1.2065, G loss: 0.8150\n",
      "[1524/1762] D loss: 1.4100, G loss: 0.5015\n",
      "[1604/1762] D loss: 1.4369, G loss: 0.4786\n",
      "[1684/1762] D loss: 0.8668, G loss: 1.2601\n",
      "[1762/1762] D loss: 1.3989, G loss: 0.6416\n",
      "train error: \n",
      " D loss: 1.304380, G loss: 0.726009, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279750, G loss: 0.752793, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0464, G loss: 0.8511\n",
      "[84/1762] D loss: 1.1716, G loss: 0.7683\n",
      "[164/1762] D loss: 1.4197, G loss: 0.6681\n",
      "[244/1762] D loss: 1.4252, G loss: 0.5978\n",
      "[324/1762] D loss: 1.3939, G loss: 0.6962\n",
      "[404/1762] D loss: 1.4009, G loss: 0.5270\n",
      "[484/1762] D loss: 1.3255, G loss: 0.6607\n",
      "[564/1762] D loss: 1.1220, G loss: 0.9056\n",
      "[644/1762] D loss: 1.1660, G loss: 1.0824\n",
      "[724/1762] D loss: 1.4319, G loss: 0.8436\n",
      "[804/1762] D loss: 1.3954, G loss: 0.7911\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7675\n",
      "[964/1762] D loss: 1.4018, G loss: 0.7724\n",
      "[1044/1762] D loss: 1.3953, G loss: 0.7383\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.7476\n",
      "[1204/1762] D loss: 0.8055, G loss: 1.5349\n",
      "[1284/1762] D loss: 1.4193, G loss: 0.7701\n",
      "[1364/1762] D loss: 1.3996, G loss: 0.8538\n",
      "[1444/1762] D loss: 1.1229, G loss: 0.9218\n",
      "[1524/1762] D loss: 1.1871, G loss: 0.7676\n",
      "[1604/1762] D loss: 1.4177, G loss: 0.6134\n",
      "[1684/1762] D loss: 1.3236, G loss: 0.6412\n",
      "[1762/1762] D loss: 1.4112, G loss: 0.8661\n",
      "train error: \n",
      " D loss: 1.309288, G loss: 0.908113, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 75.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288956, G loss: 0.935659, D accuracy: 56.7%, cell accuracy: 99.6%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3258, G loss: 0.8173\n",
      "[84/1762] D loss: 1.1426, G loss: 0.7089\n",
      "[164/1762] D loss: 1.3967, G loss: 0.8079\n",
      "[244/1762] D loss: 1.3992, G loss: 0.6281\n",
      "[324/1762] D loss: 1.4017, G loss: 0.5990\n",
      "[404/1762] D loss: 1.3971, G loss: 0.5600\n",
      "[484/1762] D loss: 1.4091, G loss: 0.6305\n",
      "[564/1762] D loss: 1.4156, G loss: 0.7135\n",
      "[644/1762] D loss: 1.4156, G loss: 0.7289\n",
      "[724/1762] D loss: 1.1290, G loss: 0.7832\n",
      "[804/1762] D loss: 1.2196, G loss: 0.5821\n",
      "[884/1762] D loss: 1.2361, G loss: 0.9688\n",
      "[964/1762] D loss: 1.4274, G loss: 0.7902\n",
      "[1044/1762] D loss: 0.8359, G loss: 1.1826\n",
      "[1124/1762] D loss: 1.4172, G loss: 0.7918\n",
      "[1204/1762] D loss: 1.4210, G loss: 0.6487\n",
      "[1284/1762] D loss: 1.3851, G loss: 0.6627\n",
      "[1364/1762] D loss: 0.8553, G loss: 1.0781\n",
      "[1444/1762] D loss: 1.1450, G loss: 0.9556\n",
      "[1524/1762] D loss: 1.3365, G loss: 0.7039\n",
      "[1604/1762] D loss: 1.1802, G loss: 0.7490\n",
      "[1684/1762] D loss: 1.1917, G loss: 0.8159\n",
      "[1762/1762] D loss: 1.4262, G loss: 0.8345\n",
      "train error: \n",
      " D loss: 1.289124, G loss: 0.832315, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268232, G loss: 0.863750, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1751, G loss: 0.8817\n",
      "[84/1762] D loss: 1.4105, G loss: 0.5668\n",
      "[164/1762] D loss: 1.4271, G loss: 0.4710\n",
      "[244/1762] D loss: 1.4358, G loss: 0.5183\n",
      "[324/1762] D loss: 1.1542, G loss: 0.7707\n",
      "[404/1762] D loss: 1.3970, G loss: 0.4913\n",
      "[484/1762] D loss: 3.2632, G loss: 0.3191\n",
      "[564/1762] D loss: 0.8685, G loss: 0.8978\n",
      "[644/1762] D loss: 0.6915, G loss: 2.9649\n",
      "[724/1762] D loss: 0.2627, G loss: 2.1744\n",
      "[804/1762] D loss: 0.2072, G loss: 2.7094\n",
      "[884/1762] D loss: 0.1792, G loss: 3.3911\n",
      "[964/1762] D loss: 1.5454, G loss: 1.0313\n",
      "[1044/1762] D loss: 1.8285, G loss: 0.2378\n",
      "[1124/1762] D loss: 1.5122, G loss: 0.8578\n",
      "[1204/1762] D loss: 1.4797, G loss: 1.0104\n",
      "[1284/1762] D loss: 1.4902, G loss: 0.8559\n",
      "[1364/1762] D loss: 1.6024, G loss: 1.0714\n",
      "[1444/1762] D loss: 1.4577, G loss: 0.8575\n",
      "[1524/1762] D loss: 1.4221, G loss: 0.8334\n",
      "[1604/1762] D loss: 1.3278, G loss: 0.7500\n",
      "[1684/1762] D loss: 1.4176, G loss: 0.6899\n",
      "[1762/1762] D loss: 1.0491, G loss: 1.3799\n",
      "train error: \n",
      " D loss: 1.357332, G loss: 0.612676, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350199, G loss: 0.625183, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4160, G loss: 0.4752\n",
      "[84/1762] D loss: 1.1662, G loss: 0.9390\n",
      "[164/1762] D loss: 1.3193, G loss: 0.7533\n",
      "[244/1762] D loss: 1.3239, G loss: 0.8918\n",
      "[324/1762] D loss: 1.2012, G loss: 0.7900\n",
      "[404/1762] D loss: 1.2756, G loss: 0.7382\n",
      "[484/1762] D loss: 1.4006, G loss: 0.5701\n",
      "[564/1762] D loss: 1.3927, G loss: 0.5443\n",
      "[644/1762] D loss: 1.3622, G loss: 0.5933\n",
      "[724/1762] D loss: 1.2887, G loss: 0.8572\n",
      "[804/1762] D loss: 1.4366, G loss: 0.7770\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7038\n",
      "[964/1762] D loss: 1.1320, G loss: 0.8563\n",
      "[1044/1762] D loss: 1.5630, G loss: 0.4914\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.6556\n",
      "[1204/1762] D loss: 1.3946, G loss: 0.6021\n",
      "[1284/1762] D loss: 1.3498, G loss: 0.9053\n",
      "[1364/1762] D loss: 1.1519, G loss: 0.8400\n",
      "[1444/1762] D loss: 1.4050, G loss: 0.7502\n",
      "[1524/1762] D loss: 0.8018, G loss: 1.5078\n",
      "[1604/1762] D loss: 1.3980, G loss: 0.7639\n",
      "[1684/1762] D loss: 1.4324, G loss: 0.7946\n",
      "[1762/1762] D loss: 0.9445, G loss: 0.9967\n",
      "train error: \n",
      " D loss: 1.305019, G loss: 0.815044, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283617, G loss: 0.853791, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1411, G loss: 0.9605\n",
      "[84/1762] D loss: 1.4008, G loss: 0.7589\n",
      "[164/1762] D loss: 1.3147, G loss: 0.8559\n",
      "[244/1762] D loss: 1.1791, G loss: 0.8724\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6480\n",
      "[404/1762] D loss: 1.3963, G loss: 0.8185\n",
      "[484/1762] D loss: 1.3663, G loss: 0.7418\n",
      "[564/1762] D loss: 1.1681, G loss: 0.8765\n",
      "[644/1762] D loss: 1.4071, G loss: 0.7375\n",
      "[724/1762] D loss: 1.3906, G loss: 0.7873\n",
      "[804/1762] D loss: 1.3634, G loss: 0.7989\n",
      "[884/1762] D loss: 0.9423, G loss: 0.9423\n",
      "[964/1762] D loss: 1.3709, G loss: 0.7630\n",
      "[1044/1762] D loss: 1.4257, G loss: 0.5878\n",
      "[1124/1762] D loss: 1.3835, G loss: 0.7496\n",
      "[1204/1762] D loss: 1.3312, G loss: 1.2170\n",
      "[1284/1762] D loss: 1.1549, G loss: 0.9461\n",
      "[1364/1762] D loss: 1.4097, G loss: 0.8806\n",
      "[1444/1762] D loss: 1.0849, G loss: 0.7589\n",
      "[1524/1762] D loss: 1.4766, G loss: 0.5721\n",
      "[1604/1762] D loss: 1.4001, G loss: 0.6025\n",
      "[1684/1762] D loss: 1.3978, G loss: 0.6714\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.7954\n",
      "train error: \n",
      " D loss: 1.315880, G loss: 0.793379, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301889, G loss: 0.813755, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1144, G loss: 0.9294\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6167\n",
      "[164/1762] D loss: 1.4072, G loss: 0.6670\n",
      "[244/1762] D loss: 1.1595, G loss: 0.7888\n",
      "[324/1762] D loss: 1.3836, G loss: 0.6570\n",
      "[404/1762] D loss: 1.1261, G loss: 1.0726\n",
      "[484/1762] D loss: 1.4045, G loss: 0.6329\n",
      "[564/1762] D loss: 1.0899, G loss: 1.1654\n",
      "[644/1762] D loss: 1.1581, G loss: 0.9802\n",
      "[724/1762] D loss: 1.3912, G loss: 0.6536\n",
      "[804/1762] D loss: 1.3968, G loss: 0.6653\n",
      "[884/1762] D loss: 1.4160, G loss: 0.5760\n",
      "[964/1762] D loss: 1.4072, G loss: 0.8925\n",
      "[1044/1762] D loss: 1.4006, G loss: 0.7782\n",
      "[1124/1762] D loss: 1.4454, G loss: 0.5955\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.7730\n",
      "[1284/1762] D loss: 0.9968, G loss: 1.0700\n",
      "[1364/1762] D loss: 1.4098, G loss: 0.6910\n",
      "[1444/1762] D loss: 1.3974, G loss: 0.7084\n",
      "[1524/1762] D loss: 1.1687, G loss: 0.9399\n",
      "[1604/1762] D loss: 1.1258, G loss: 0.8471\n",
      "[1684/1762] D loss: 1.3368, G loss: 0.6468\n",
      "[1762/1762] D loss: 1.4123, G loss: 0.5650\n",
      "train error: \n",
      " D loss: 1.311741, G loss: 0.713638, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294322, G loss: 0.738647, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1790, G loss: 0.8109\n",
      "[84/1762] D loss: 1.4283, G loss: 0.6125\n",
      "[164/1762] D loss: 0.9823, G loss: 1.2252\n",
      "[244/1762] D loss: 1.4069, G loss: 0.5945\n",
      "[324/1762] D loss: 1.3594, G loss: 0.8625\n",
      "[404/1762] D loss: 1.1658, G loss: 1.1588\n",
      "[484/1762] D loss: 1.4101, G loss: 0.6343\n",
      "[564/1762] D loss: 0.9869, G loss: 0.9619\n",
      "[644/1762] D loss: 1.1539, G loss: 0.7467\n",
      "[724/1762] D loss: 1.4219, G loss: 0.5496\n",
      "[804/1762] D loss: 1.3958, G loss: 0.7117\n",
      "[884/1762] D loss: 1.4325, G loss: 0.7732\n",
      "[964/1762] D loss: 1.3914, G loss: 0.7052\n",
      "[1044/1762] D loss: 1.4151, G loss: 0.7653\n",
      "[1124/1762] D loss: 1.4004, G loss: 0.7016\n",
      "[1204/1762] D loss: 1.4171, G loss: 0.9032\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6393\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.5970\n",
      "[1444/1762] D loss: 1.1889, G loss: 0.8565\n",
      "[1524/1762] D loss: 1.3926, G loss: 0.6238\n",
      "[1604/1762] D loss: 1.4287, G loss: 0.5936\n",
      "[1684/1762] D loss: 1.3700, G loss: 0.7484\n",
      "[1762/1762] D loss: 1.3819, G loss: 0.8316\n",
      "train error: \n",
      " D loss: 1.318505, G loss: 0.801589, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298206, G loss: 0.824010, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4217, G loss: 0.7116\n",
      "[84/1762] D loss: 1.4193, G loss: 0.7315\n",
      "[164/1762] D loss: 1.4500, G loss: 0.9298\n",
      "[244/1762] D loss: 1.4029, G loss: 0.8507\n",
      "[324/1762] D loss: 1.3960, G loss: 0.6090\n",
      "[404/1762] D loss: 1.4057, G loss: 0.7978\n",
      "[484/1762] D loss: 1.4163, G loss: 0.8481\n",
      "[564/1762] D loss: 1.3923, G loss: 0.7014\n",
      "[644/1762] D loss: 1.3709, G loss: 0.7307\n",
      "[724/1762] D loss: 1.4279, G loss: 0.5955\n",
      "[804/1762] D loss: 1.1187, G loss: 0.7993\n",
      "[884/1762] D loss: 1.0058, G loss: 1.0718\n",
      "[964/1762] D loss: 1.1245, G loss: 0.9759\n",
      "[1044/1762] D loss: 1.3993, G loss: 0.7547\n",
      "[1124/1762] D loss: 1.4287, G loss: 0.7864\n",
      "[1204/1762] D loss: 1.1268, G loss: 0.9942\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.6981\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.6596\n",
      "[1444/1762] D loss: 1.3977, G loss: 0.7798\n",
      "[1524/1762] D loss: 1.4476, G loss: 0.5108\n",
      "[1604/1762] D loss: 1.1141, G loss: 0.8540\n",
      "[1684/1762] D loss: 1.3940, G loss: 0.6419\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.7348\n",
      "train error: \n",
      " D loss: 1.310408, G loss: 0.808338, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292637, G loss: 0.827131, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3972, G loss: 0.6466\n",
      "[84/1762] D loss: 1.1576, G loss: 1.0043\n",
      "[164/1762] D loss: 1.3195, G loss: 0.7464\n",
      "[244/1762] D loss: 1.4216, G loss: 0.4812\n",
      "[324/1762] D loss: 1.1850, G loss: 0.6706\n",
      "[404/1762] D loss: 1.1302, G loss: 0.9184\n",
      "[484/1762] D loss: 1.3904, G loss: 0.6193\n",
      "[564/1762] D loss: 1.3986, G loss: 0.7105\n",
      "[644/1762] D loss: 1.1552, G loss: 0.8535\n",
      "[724/1762] D loss: 1.3933, G loss: 0.6928\n",
      "[804/1762] D loss: 1.3197, G loss: 0.7673\n",
      "[884/1762] D loss: 1.3927, G loss: 0.6658\n",
      "[964/1762] D loss: 1.4171, G loss: 0.4945\n",
      "[1044/1762] D loss: 1.4038, G loss: 0.7634\n",
      "[1124/1762] D loss: 1.4067, G loss: 0.7239\n",
      "[1204/1762] D loss: 1.4033, G loss: 0.6307\n",
      "[1284/1762] D loss: 1.4145, G loss: 0.5575\n",
      "[1364/1762] D loss: 1.1650, G loss: 0.7705\n",
      "[1444/1762] D loss: 1.3670, G loss: 0.6749\n",
      "[1524/1762] D loss: 1.3975, G loss: 0.7120\n",
      "[1604/1762] D loss: 1.3941, G loss: 0.6712\n",
      "[1684/1762] D loss: 1.4020, G loss: 0.7148\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.7129\n",
      "train error: \n",
      " D loss: 1.329110, G loss: 0.929500, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309287, G loss: 0.955557, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1642, G loss: 0.9750\n",
      "[84/1762] D loss: 1.4499, G loss: 0.7240\n",
      "[164/1762] D loss: 1.3973, G loss: 0.6762\n",
      "[244/1762] D loss: 1.2372, G loss: 0.6775\n",
      "[324/1762] D loss: 1.4051, G loss: 0.7274\n",
      "[404/1762] D loss: 1.4628, G loss: 0.7964\n",
      "[484/1762] D loss: 1.3977, G loss: 0.8033\n",
      "[564/1762] D loss: 1.1509, G loss: 0.8797\n",
      "[644/1762] D loss: 1.1648, G loss: 0.7626\n",
      "[724/1762] D loss: 1.4060, G loss: 0.7769\n",
      "[804/1762] D loss: 0.9355, G loss: 1.2677\n",
      "[884/1762] D loss: 1.3887, G loss: 0.7279\n",
      "[964/1762] D loss: 1.1240, G loss: 0.9833\n",
      "[1044/1762] D loss: 1.3585, G loss: 0.8366\n",
      "[1124/1762] D loss: 1.4120, G loss: 0.7686\n",
      "[1204/1762] D loss: 1.3569, G loss: 0.8618\n",
      "[1284/1762] D loss: 1.4091, G loss: 0.7829\n",
      "[1364/1762] D loss: 1.3974, G loss: 0.6895\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.6644\n",
      "[1524/1762] D loss: 1.1011, G loss: 1.0687\n",
      "[1604/1762] D loss: 1.4226, G loss: 0.5425\n",
      "[1684/1762] D loss: 1.2448, G loss: 0.7165\n",
      "[1762/1762] D loss: 1.4087, G loss: 0.7278\n",
      "train error: \n",
      " D loss: 1.310282, G loss: 0.792442, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287395, G loss: 0.812792, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4183, G loss: 0.6352\n",
      "[84/1762] D loss: 1.4008, G loss: 0.6779\n",
      "[164/1762] D loss: 1.1621, G loss: 0.6902\n",
      "[244/1762] D loss: 1.0833, G loss: 0.9979\n",
      "[324/1762] D loss: 1.4421, G loss: 0.5976\n",
      "[404/1762] D loss: 1.3977, G loss: 0.7180\n",
      "[484/1762] D loss: 1.3941, G loss: 0.6883\n",
      "[564/1762] D loss: 1.4202, G loss: 0.8840\n",
      "[644/1762] D loss: 1.4116, G loss: 0.8899\n",
      "[724/1762] D loss: 1.1953, G loss: 0.9673\n",
      "[804/1762] D loss: 1.1226, G loss: 1.0082\n",
      "[884/1762] D loss: 1.4432, G loss: 0.8102\n",
      "[964/1762] D loss: 1.0759, G loss: 0.9341\n",
      "[1044/1762] D loss: 1.4033, G loss: 0.5596\n",
      "[1124/1762] D loss: 1.1770, G loss: 0.8517\n",
      "[1204/1762] D loss: 0.9817, G loss: 0.8048\n",
      "[1284/1762] D loss: 1.3244, G loss: 0.7705\n",
      "[1364/1762] D loss: 1.3596, G loss: 0.7385\n",
      "[1444/1762] D loss: 1.4029, G loss: 0.6777\n",
      "[1524/1762] D loss: 1.1531, G loss: 0.9949\n",
      "[1604/1762] D loss: 1.1794, G loss: 0.8806\n",
      "[1684/1762] D loss: 1.4143, G loss: 0.7645\n",
      "[1762/1762] D loss: 1.4021, G loss: 0.6000\n",
      "train error: \n",
      " D loss: 1.297915, G loss: 0.860336, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274288, G loss: 0.891294, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3983, G loss: 0.7885\n",
      "[84/1762] D loss: 1.3918, G loss: 0.6071\n",
      "[164/1762] D loss: 1.1553, G loss: 1.0590\n",
      "[244/1762] D loss: 1.3473, G loss: 0.8654\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6124\n",
      "[404/1762] D loss: 1.4178, G loss: 0.6124\n",
      "[484/1762] D loss: 1.1301, G loss: 0.8430\n",
      "[564/1762] D loss: 1.4029, G loss: 0.6511\n",
      "[644/1762] D loss: 1.3913, G loss: 0.5948\n",
      "[724/1762] D loss: 1.3402, G loss: 0.7108\n",
      "[804/1762] D loss: 1.3938, G loss: 0.7191\n",
      "[884/1762] D loss: 1.3970, G loss: 0.7126\n",
      "[964/1762] D loss: 1.4169, G loss: 0.5923\n",
      "[1044/1762] D loss: 1.0186, G loss: 1.2613\n",
      "[1124/1762] D loss: 1.3972, G loss: 0.7683\n",
      "[1204/1762] D loss: 1.1651, G loss: 1.2880\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.6743\n",
      "[1364/1762] D loss: 1.4178, G loss: 0.8206\n",
      "[1444/1762] D loss: 1.4060, G loss: 0.7384\n",
      "[1524/1762] D loss: 1.4104, G loss: 0.6161\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.7988\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.8247\n",
      "[1762/1762] D loss: 1.2370, G loss: 0.7927\n",
      "train error: \n",
      " D loss: 1.315249, G loss: 0.884316, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295653, G loss: 0.909912, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3971, G loss: 0.7376\n",
      "[84/1762] D loss: 1.4252, G loss: 0.7508\n",
      "[164/1762] D loss: 1.3913, G loss: 0.6630\n",
      "[244/1762] D loss: 1.1291, G loss: 0.8746\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7165\n",
      "[404/1762] D loss: 1.3889, G loss: 0.7066\n",
      "[484/1762] D loss: 1.4228, G loss: 0.8098\n",
      "[564/1762] D loss: 1.3952, G loss: 0.7422\n",
      "[644/1762] D loss: 1.4050, G loss: 0.6955\n",
      "[724/1762] D loss: 1.4023, G loss: 0.7291\n",
      "[804/1762] D loss: 1.1149, G loss: 0.9331\n",
      "[884/1762] D loss: 1.1187, G loss: 1.0526\n",
      "[964/1762] D loss: 1.4250, G loss: 0.8277\n",
      "[1044/1762] D loss: 1.1263, G loss: 0.9904\n",
      "[1124/1762] D loss: 1.3769, G loss: 0.8150\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.7745\n",
      "[1284/1762] D loss: 1.4184, G loss: 0.6423\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.7385\n",
      "[1444/1762] D loss: 1.1070, G loss: 1.0872\n",
      "[1524/1762] D loss: 1.2988, G loss: 0.8304\n",
      "[1604/1762] D loss: 1.1500, G loss: 0.9454\n",
      "[1684/1762] D loss: 1.3673, G loss: 0.6328\n",
      "[1762/1762] D loss: 1.3714, G loss: 0.6693\n",
      "train error: \n",
      " D loss: 1.351694, G loss: 0.567542, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 75.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340571, G loss: 0.576673, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4157, G loss: 0.5551\n",
      "[84/1762] D loss: 1.1613, G loss: 0.7354\n",
      "[164/1762] D loss: 1.3894, G loss: 0.7524\n",
      "[244/1762] D loss: 1.1511, G loss: 0.7559\n",
      "[324/1762] D loss: 1.4702, G loss: 0.5951\n",
      "[404/1762] D loss: 1.4241, G loss: 0.8153\n",
      "[484/1762] D loss: 1.4157, G loss: 0.7237\n",
      "[564/1762] D loss: 1.3999, G loss: 0.7803\n",
      "[644/1762] D loss: 1.4063, G loss: 0.6311\n",
      "[724/1762] D loss: 0.8830, G loss: 1.8907\n",
      "[804/1762] D loss: 1.3010, G loss: 0.6042\n",
      "[884/1762] D loss: 1.3958, G loss: 0.5989\n",
      "[964/1762] D loss: 1.3961, G loss: 0.7151\n",
      "[1044/1762] D loss: 1.5105, G loss: 0.6593\n",
      "[1124/1762] D loss: 1.2506, G loss: 0.9353\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.7566\n",
      "[1284/1762] D loss: 1.2427, G loss: 1.0818\n",
      "[1364/1762] D loss: 1.4124, G loss: 0.6203\n",
      "[1444/1762] D loss: 1.3946, G loss: 0.7777\n",
      "[1524/1762] D loss: 1.1462, G loss: 0.9005\n",
      "[1604/1762] D loss: 1.2587, G loss: 1.0811\n",
      "[1684/1762] D loss: 1.1646, G loss: 0.7593\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.6001\n",
      "train error: \n",
      " D loss: 1.348056, G loss: 0.592673, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332362, G loss: 0.607426, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4193, G loss: 0.5501\n",
      "[84/1762] D loss: 1.4019, G loss: 0.5888\n",
      "[164/1762] D loss: 1.3992, G loss: 0.6960\n",
      "[244/1762] D loss: 1.0860, G loss: 1.1839\n",
      "[324/1762] D loss: 1.1424, G loss: 0.7249\n",
      "[404/1762] D loss: 1.1466, G loss: 0.9079\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6691\n",
      "[564/1762] D loss: 1.4243, G loss: 0.8463\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6864\n",
      "[724/1762] D loss: 1.1603, G loss: 1.0324\n",
      "[804/1762] D loss: 1.4044, G loss: 0.8081\n",
      "[884/1762] D loss: 1.4036, G loss: 0.8048\n",
      "[964/1762] D loss: 0.8482, G loss: 1.0814\n",
      "[1044/1762] D loss: 1.4210, G loss: 0.8003\n",
      "[1124/1762] D loss: 1.4287, G loss: 0.8249\n",
      "[1204/1762] D loss: 1.1361, G loss: 0.9449\n",
      "[1284/1762] D loss: 1.4067, G loss: 0.6140\n",
      "[1364/1762] D loss: 1.3996, G loss: 0.7542\n",
      "[1444/1762] D loss: 1.3825, G loss: 0.7991\n",
      "[1524/1762] D loss: 0.8419, G loss: 1.1974\n",
      "[1604/1762] D loss: 1.2748, G loss: 0.8108\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.7194\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.7662\n",
      "train error: \n",
      " D loss: 1.314294, G loss: 0.854891, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296768, G loss: 0.869198, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1361, G loss: 0.9760\n",
      "[84/1762] D loss: 1.3960, G loss: 0.8225\n",
      "[164/1762] D loss: 1.4240, G loss: 0.5515\n",
      "[244/1762] D loss: 1.3890, G loss: 0.6989\n",
      "[324/1762] D loss: 1.3973, G loss: 0.6675\n",
      "[404/1762] D loss: 1.3945, G loss: 0.7483\n",
      "[484/1762] D loss: 1.1217, G loss: 0.9275\n",
      "[564/1762] D loss: 1.1393, G loss: 0.9103\n",
      "[644/1762] D loss: 1.1927, G loss: 0.7825\n",
      "[724/1762] D loss: 1.3916, G loss: 0.6498\n",
      "[804/1762] D loss: 1.3899, G loss: 0.7949\n",
      "[884/1762] D loss: 1.3957, G loss: 0.6783\n",
      "[964/1762] D loss: 1.3881, G loss: 0.6167\n",
      "[1044/1762] D loss: 1.3934, G loss: 0.6854\n",
      "[1124/1762] D loss: 1.1071, G loss: 0.8577\n",
      "[1204/1762] D loss: 1.3979, G loss: 0.7942\n",
      "[1284/1762] D loss: 1.4093, G loss: 0.7705\n",
      "[1364/1762] D loss: 1.3969, G loss: 0.7602\n",
      "[1444/1762] D loss: 1.3800, G loss: 0.6603\n",
      "[1524/1762] D loss: 1.4185, G loss: 0.6440\n",
      "[1604/1762] D loss: 0.8374, G loss: 1.0592\n",
      "[1684/1762] D loss: 1.3925, G loss: 0.6142\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6438\n",
      "train error: \n",
      " D loss: 1.312018, G loss: 0.755495, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291521, G loss: 0.779249, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.6470\n",
      "[84/1762] D loss: 1.1438, G loss: 0.8864\n",
      "[164/1762] D loss: 1.3957, G loss: 0.7078\n",
      "[244/1762] D loss: 1.4034, G loss: 0.5785\n",
      "[324/1762] D loss: 1.4385, G loss: 0.9048\n",
      "[404/1762] D loss: 1.4216, G loss: 0.7241\n",
      "[484/1762] D loss: 1.1012, G loss: 0.8850\n",
      "[564/1762] D loss: 1.1793, G loss: 0.7704\n",
      "[644/1762] D loss: 1.3969, G loss: 0.7116\n",
      "[724/1762] D loss: 1.3982, G loss: 0.6473\n",
      "[804/1762] D loss: 1.1310, G loss: 1.0306\n",
      "[884/1762] D loss: 1.3909, G loss: 0.6793\n",
      "[964/1762] D loss: 1.3966, G loss: 0.6797\n",
      "[1044/1762] D loss: 1.4017, G loss: 0.5921\n",
      "[1124/1762] D loss: 1.3960, G loss: 0.6379\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.7083\n",
      "[1284/1762] D loss: 1.4143, G loss: 0.7618\n",
      "[1364/1762] D loss: 1.2974, G loss: 1.0416\n",
      "[1444/1762] D loss: 1.3949, G loss: 0.7466\n",
      "[1524/1762] D loss: 1.1164, G loss: 0.8910\n",
      "[1604/1762] D loss: 1.2263, G loss: 1.0667\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.8095\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.8279\n",
      "train error: \n",
      " D loss: 1.329012, G loss: 0.937866, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309051, G loss: 0.964584, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1136, G loss: 1.1084\n",
      "[84/1762] D loss: 1.4017, G loss: 0.8653\n",
      "[164/1762] D loss: 1.3940, G loss: 0.7711\n",
      "[244/1762] D loss: 1.0948, G loss: 1.0366\n",
      "[324/1762] D loss: 1.4136, G loss: 0.7950\n",
      "[404/1762] D loss: 1.4009, G loss: 0.7445\n",
      "[484/1762] D loss: 1.4142, G loss: 0.6190\n",
      "[564/1762] D loss: 1.3953, G loss: 0.6537\n",
      "[644/1762] D loss: 1.4012, G loss: 0.6914\n",
      "[724/1762] D loss: 1.4020, G loss: 0.5749\n",
      "[804/1762] D loss: 1.3945, G loss: 0.6396\n",
      "[884/1762] D loss: 1.4038, G loss: 0.7006\n",
      "[964/1762] D loss: 1.4191, G loss: 0.7286\n",
      "[1044/1762] D loss: 1.3697, G loss: 1.1424\n",
      "[1124/1762] D loss: 1.2638, G loss: 0.8332\n",
      "[1204/1762] D loss: 1.4183, G loss: 0.7618\n",
      "[1284/1762] D loss: 1.4150, G loss: 0.7524\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.7206\n",
      "[1444/1762] D loss: 1.3925, G loss: 0.6525\n",
      "[1524/1762] D loss: 1.1955, G loss: 1.0417\n",
      "[1604/1762] D loss: 1.3959, G loss: 0.6297\n",
      "[1684/1762] D loss: 0.8153, G loss: 1.2550\n",
      "[1762/1762] D loss: 1.4438, G loss: 0.9196\n",
      "train error: \n",
      " D loss: 1.339830, G loss: 0.977065, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319125, G loss: 1.006906, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1334, G loss: 0.9960\n",
      "[84/1762] D loss: 1.3971, G loss: 0.6604\n",
      "[164/1762] D loss: 1.1008, G loss: 1.0468\n",
      "[244/1762] D loss: 1.3951, G loss: 0.7543\n",
      "[324/1762] D loss: 1.3893, G loss: 0.7297\n",
      "[404/1762] D loss: 1.4644, G loss: 0.9177\n",
      "[484/1762] D loss: 1.3940, G loss: 0.7054\n",
      "[564/1762] D loss: 1.3825, G loss: 0.5978\n",
      "[644/1762] D loss: 1.0936, G loss: 0.9230\n",
      "[724/1762] D loss: 1.3957, G loss: 0.6610\n",
      "[804/1762] D loss: 1.0861, G loss: 0.8688\n",
      "[884/1762] D loss: 1.4002, G loss: 0.6227\n",
      "[964/1762] D loss: 1.4099, G loss: 0.6010\n",
      "[1044/1762] D loss: 1.3750, G loss: 0.6912\n",
      "[1124/1762] D loss: 1.4737, G loss: 0.4440\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7134\n",
      "[1284/1762] D loss: 1.4279, G loss: 0.8099\n",
      "[1364/1762] D loss: 1.3595, G loss: 0.7198\n",
      "[1444/1762] D loss: 1.3956, G loss: 0.7459\n",
      "[1524/1762] D loss: 1.3954, G loss: 0.7368\n",
      "[1604/1762] D loss: 1.4021, G loss: 0.8326\n",
      "[1684/1762] D loss: 1.4261, G loss: 0.8813\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.7237\n",
      "train error: \n",
      " D loss: 1.301924, G loss: 0.738589, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283580, G loss: 0.759801, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3992, G loss: 0.6807\n",
      "[84/1762] D loss: 1.1209, G loss: 0.8913\n",
      "[164/1762] D loss: 1.3959, G loss: 0.7118\n",
      "[244/1762] D loss: 0.6658, G loss: 1.6007\n",
      "[324/1762] D loss: 0.6031, G loss: 1.3582\n",
      "[404/1762] D loss: 1.3958, G loss: 0.7881\n",
      "[484/1762] D loss: 1.3949, G loss: 0.6218\n",
      "[564/1762] D loss: 1.4127, G loss: 0.5978\n",
      "[644/1762] D loss: 1.1333, G loss: 0.7623\n",
      "[724/1762] D loss: 1.3237, G loss: 0.7729\n",
      "[804/1762] D loss: 1.4221, G loss: 0.7481\n",
      "[884/1762] D loss: 1.1299, G loss: 0.8381\n",
      "[964/1762] D loss: 1.1287, G loss: 0.9618\n",
      "[1044/1762] D loss: 1.4322, G loss: 0.9043\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.7333\n",
      "[1204/1762] D loss: 1.3918, G loss: 0.6691\n",
      "[1284/1762] D loss: 1.4033, G loss: 0.8417\n",
      "[1364/1762] D loss: 1.4487, G loss: 0.7463\n",
      "[1444/1762] D loss: 1.3774, G loss: 0.6348\n",
      "[1524/1762] D loss: 0.9205, G loss: 0.9914\n",
      "[1604/1762] D loss: 1.3099, G loss: 0.8463\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.6639\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7786\n",
      "train error: \n",
      " D loss: 1.319885, G loss: 0.935311, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298186, G loss: 0.956006, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1664, G loss: 1.0351\n",
      "[84/1762] D loss: 1.3400, G loss: 0.6542\n",
      "[164/1762] D loss: 1.3643, G loss: 0.6203\n",
      "[244/1762] D loss: 1.3901, G loss: 0.6557\n",
      "[324/1762] D loss: 1.3989, G loss: 0.6168\n",
      "[404/1762] D loss: 1.1553, G loss: 0.7866\n",
      "[484/1762] D loss: 1.3907, G loss: 0.6418\n",
      "[564/1762] D loss: 1.1527, G loss: 0.7500\n",
      "[644/1762] D loss: 1.4113, G loss: 0.8809\n",
      "[724/1762] D loss: 1.3855, G loss: 0.7797\n",
      "[804/1762] D loss: 1.4093, G loss: 0.7839\n",
      "[884/1762] D loss: 1.3945, G loss: 0.7666\n",
      "[964/1762] D loss: 1.3952, G loss: 0.7622\n",
      "[1044/1762] D loss: 1.3952, G loss: 0.7420\n",
      "[1124/1762] D loss: 1.3901, G loss: 0.7229\n",
      "[1204/1762] D loss: 1.3892, G loss: 0.8178\n",
      "[1284/1762] D loss: 1.4060, G loss: 0.6406\n",
      "[1364/1762] D loss: 1.3244, G loss: 0.7380\n",
      "[1444/1762] D loss: 1.1441, G loss: 1.2004\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.7784\n",
      "[1604/1762] D loss: 1.1583, G loss: 1.0249\n",
      "[1684/1762] D loss: 1.3982, G loss: 0.8262\n",
      "[1762/1762] D loss: 1.3930, G loss: 0.5367\n",
      "train error: \n",
      " D loss: 1.311715, G loss: 0.697629, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295655, G loss: 0.711569, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3167, G loss: 0.6560\n",
      "[84/1762] D loss: 1.4049, G loss: 0.6115\n",
      "[164/1762] D loss: 1.3985, G loss: 0.7053\n",
      "[244/1762] D loss: 1.3974, G loss: 0.6313\n",
      "[324/1762] D loss: 1.1265, G loss: 0.8590\n",
      "[404/1762] D loss: 1.4384, G loss: 0.5621\n",
      "[484/1762] D loss: 1.1066, G loss: 0.8997\n",
      "[564/1762] D loss: 1.1377, G loss: 0.7482\n",
      "[644/1762] D loss: 1.1165, G loss: 0.8631\n",
      "[724/1762] D loss: 1.4120, G loss: 0.9146\n",
      "[804/1762] D loss: 1.4032, G loss: 0.7708\n",
      "[884/1762] D loss: 1.3948, G loss: 0.6924\n",
      "[964/1762] D loss: 1.4564, G loss: 0.9162\n",
      "[1044/1762] D loss: 1.4070, G loss: 0.7271\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.7129\n",
      "[1204/1762] D loss: 1.3858, G loss: 0.6947\n",
      "[1284/1762] D loss: 1.3828, G loss: 0.8134\n",
      "[1364/1762] D loss: 1.3463, G loss: 0.7944\n",
      "[1444/1762] D loss: 1.2993, G loss: 0.8291\n",
      "[1524/1762] D loss: 1.3420, G loss: 0.8552\n",
      "[1604/1762] D loss: 1.4174, G loss: 0.6902\n",
      "[1684/1762] D loss: 1.1896, G loss: 0.8015\n",
      "[1762/1762] D loss: 1.3545, G loss: 0.6476\n",
      "train error: \n",
      " D loss: 1.308917, G loss: 0.701482, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296704, G loss: 0.707374, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4254, G loss: 0.7230\n",
      "[84/1762] D loss: 1.3929, G loss: 0.6212\n",
      "[164/1762] D loss: 1.4271, G loss: 0.5537\n",
      "[244/1762] D loss: 1.3815, G loss: 0.7073\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6066\n",
      "[404/1762] D loss: 0.9388, G loss: 1.2761\n",
      "[484/1762] D loss: 1.1124, G loss: 1.0246\n",
      "[564/1762] D loss: 1.3020, G loss: 0.8882\n",
      "[644/1762] D loss: 1.1425, G loss: 0.8247\n",
      "[724/1762] D loss: 1.3914, G loss: 0.6117\n",
      "[804/1762] D loss: 1.3902, G loss: 0.7640\n",
      "[884/1762] D loss: 1.4083, G loss: 0.8552\n",
      "[964/1762] D loss: 1.4361, G loss: 0.8937\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.7971\n",
      "[1124/1762] D loss: 1.4002, G loss: 0.6125\n",
      "[1204/1762] D loss: 1.3700, G loss: 0.8104\n",
      "[1284/1762] D loss: 1.1169, G loss: 0.9950\n",
      "[1364/1762] D loss: 1.1549, G loss: 0.7469\n",
      "[1444/1762] D loss: 1.4100, G loss: 0.5723\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.5451\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.6866\n",
      "[1684/1762] D loss: 1.1166, G loss: 1.0301\n",
      "[1762/1762] D loss: 0.8448, G loss: 1.1684\n",
      "train error: \n",
      " D loss: 1.314966, G loss: 0.829407, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295963, G loss: 0.849765, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7858\n",
      "[84/1762] D loss: 1.4030, G loss: 0.7565\n",
      "[164/1762] D loss: 1.1140, G loss: 0.8825\n",
      "[244/1762] D loss: 1.4203, G loss: 0.7870\n",
      "[324/1762] D loss: 1.3031, G loss: 0.8568\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6560\n",
      "[484/1762] D loss: 1.4073, G loss: 0.7980\n",
      "[564/1762] D loss: 1.3888, G loss: 0.6315\n",
      "[644/1762] D loss: 1.3919, G loss: 0.5937\n",
      "[724/1762] D loss: 1.4114, G loss: 0.7371\n",
      "[804/1762] D loss: 1.4273, G loss: 0.7125\n",
      "[884/1762] D loss: 1.3860, G loss: 0.6103\n",
      "[964/1762] D loss: 1.1334, G loss: 1.0625\n",
      "[1044/1762] D loss: 1.3894, G loss: 0.7919\n",
      "[1124/1762] D loss: 1.1118, G loss: 0.9706\n",
      "[1204/1762] D loss: 1.1218, G loss: 1.0283\n",
      "[1284/1762] D loss: 1.3820, G loss: 0.7562\n",
      "[1364/1762] D loss: 1.4018, G loss: 0.5970\n",
      "[1444/1762] D loss: 1.4225, G loss: 0.8787\n",
      "[1524/1762] D loss: 1.3938, G loss: 0.7961\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6802\n",
      "[1684/1762] D loss: 1.3693, G loss: 0.6642\n",
      "[1762/1762] D loss: 1.4032, G loss: 0.6510\n",
      "train error: \n",
      " D loss: 1.312933, G loss: 0.857725, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290747, G loss: 0.892048, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0309, G loss: 1.1923\n",
      "[84/1762] D loss: 1.3997, G loss: 0.7803\n",
      "[164/1762] D loss: 1.3918, G loss: 0.8133\n",
      "[244/1762] D loss: 1.1298, G loss: 1.1059\n",
      "[324/1762] D loss: 1.1030, G loss: 1.1001\n",
      "[404/1762] D loss: 1.1004, G loss: 0.9291\n",
      "[484/1762] D loss: 1.1278, G loss: 0.9116\n",
      "[564/1762] D loss: 1.3964, G loss: 0.6801\n",
      "[644/1762] D loss: 1.3966, G loss: 0.6153\n",
      "[724/1762] D loss: 1.4048, G loss: 0.7484\n",
      "[804/1762] D loss: 1.4120, G loss: 0.7654\n",
      "[884/1762] D loss: 1.4101, G loss: 0.8724\n",
      "[964/1762] D loss: 1.3968, G loss: 0.7346\n",
      "[1044/1762] D loss: 1.1189, G loss: 1.0457\n",
      "[1124/1762] D loss: 1.1150, G loss: 0.8937\n",
      "[1204/1762] D loss: 1.4042, G loss: 0.8139\n",
      "[1284/1762] D loss: 1.4186, G loss: 0.7873\n",
      "[1364/1762] D loss: 1.4039, G loss: 0.7976\n",
      "[1444/1762] D loss: 1.4087, G loss: 0.6208\n",
      "[1524/1762] D loss: 1.3989, G loss: 0.6806\n",
      "[1604/1762] D loss: 1.4106, G loss: 0.6000\n",
      "[1684/1762] D loss: 1.1388, G loss: 0.8050\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.7650\n",
      "train error: \n",
      " D loss: 1.312355, G loss: 0.828222, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292084, G loss: 0.853355, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0929, G loss: 1.0687\n",
      "[84/1762] D loss: 1.3885, G loss: 0.7090\n",
      "[164/1762] D loss: 0.8194, G loss: 1.1859\n",
      "[244/1762] D loss: 1.1024, G loss: 0.9132\n",
      "[324/1762] D loss: 0.9070, G loss: 1.6021\n",
      "[404/1762] D loss: 1.3898, G loss: 0.6425\n",
      "[484/1762] D loss: 1.4019, G loss: 0.6865\n",
      "[564/1762] D loss: 1.4241, G loss: 0.8654\n",
      "[644/1762] D loss: 1.3964, G loss: 0.7992\n",
      "[724/1762] D loss: 1.3549, G loss: 0.7481\n",
      "[804/1762] D loss: 1.3759, G loss: 0.7222\n",
      "[884/1762] D loss: 1.3470, G loss: 0.7995\n",
      "[964/1762] D loss: 1.1838, G loss: 0.8192\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.7134\n",
      "[1124/1762] D loss: 1.1308, G loss: 0.9170\n",
      "[1204/1762] D loss: 0.7110, G loss: 1.6581\n",
      "[1284/1762] D loss: 1.0179, G loss: 1.2020\n",
      "[1364/1762] D loss: 1.2902, G loss: 0.8224\n",
      "[1444/1762] D loss: 1.3480, G loss: 0.6865\n",
      "[1524/1762] D loss: 1.4594, G loss: 0.8084\n",
      "[1604/1762] D loss: 1.3999, G loss: 0.6974\n",
      "[1684/1762] D loss: 1.3993, G loss: 0.6665\n",
      "[1762/1762] D loss: 1.3986, G loss: 0.5315\n",
      "train error: \n",
      " D loss: 1.334002, G loss: 0.579154, D accuracy: 56.4%, cell accuracy: 99.5%, board accuracy: 72.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318571, G loss: 0.592513, D accuracy: 57.3%, cell accuracy: 99.6%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1921, G loss: 0.6600\n",
      "[84/1762] D loss: 1.3728, G loss: 0.7040\n",
      "[164/1762] D loss: 1.3282, G loss: 0.7283\n",
      "[244/1762] D loss: 1.1041, G loss: 0.7558\n",
      "[324/1762] D loss: 1.3932, G loss: 0.7433\n",
      "[404/1762] D loss: 1.4708, G loss: 0.7429\n",
      "[484/1762] D loss: 1.4290, G loss: 0.8786\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7301\n",
      "[644/1762] D loss: 1.3916, G loss: 0.7113\n",
      "[724/1762] D loss: 1.3813, G loss: 0.8914\n",
      "[804/1762] D loss: 1.0889, G loss: 1.1653\n",
      "[884/1762] D loss: 1.4158, G loss: 0.6142\n",
      "[964/1762] D loss: 1.3978, G loss: 0.7033\n",
      "[1044/1762] D loss: 1.4019, G loss: 0.8002\n",
      "[1124/1762] D loss: 1.1305, G loss: 0.8743\n",
      "[1204/1762] D loss: 1.4039, G loss: 0.7021\n",
      "[1284/1762] D loss: 1.2980, G loss: 0.9291\n",
      "[1364/1762] D loss: 0.9731, G loss: 1.0064\n",
      "[1444/1762] D loss: 1.1124, G loss: 0.9024\n",
      "[1524/1762] D loss: 1.3859, G loss: 0.6819\n",
      "[1604/1762] D loss: 1.3948, G loss: 0.7692\n",
      "[1684/1762] D loss: 1.3711, G loss: 0.6965\n",
      "[1762/1762] D loss: 1.2880, G loss: 0.7047\n",
      "train error: \n",
      " D loss: 1.305006, G loss: 0.697921, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290408, G loss: 0.709386, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3128, G loss: 0.6014\n",
      "[84/1762] D loss: 1.3844, G loss: 0.6360\n",
      "[164/1762] D loss: 1.3568, G loss: 0.6274\n",
      "[244/1762] D loss: 1.3985, G loss: 0.7348\n",
      "[324/1762] D loss: 1.1085, G loss: 0.9210\n",
      "[404/1762] D loss: 1.3000, G loss: 0.8207\n",
      "[484/1762] D loss: 1.0542, G loss: 0.9540\n",
      "[564/1762] D loss: 1.3238, G loss: 0.7694\n",
      "[644/1762] D loss: 1.3948, G loss: 0.5148\n",
      "[724/1762] D loss: 1.3912, G loss: 0.5778\n",
      "[804/1762] D loss: 1.3275, G loss: 0.7364\n",
      "[884/1762] D loss: 1.0734, G loss: 0.8102\n",
      "[964/1762] D loss: 1.1462, G loss: 0.8537\n",
      "[1044/1762] D loss: 1.3969, G loss: 0.5804\n",
      "[1124/1762] D loss: 0.8170, G loss: 1.1869\n",
      "[1204/1762] D loss: 1.4074, G loss: 0.7796\n",
      "[1284/1762] D loss: 1.4054, G loss: 0.7692\n",
      "[1364/1762] D loss: 1.3959, G loss: 0.7828\n",
      "[1444/1762] D loss: 1.3698, G loss: 0.8383\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.6713\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.7483\n",
      "[1684/1762] D loss: 1.3685, G loss: 0.7120\n",
      "[1762/1762] D loss: 1.3831, G loss: 0.7366\n",
      "train error: \n",
      " D loss: 1.315482, G loss: 0.825838, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295913, G loss: 0.845251, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3964, G loss: 0.7127\n",
      "[84/1762] D loss: 1.3925, G loss: 0.8128\n",
      "[164/1762] D loss: 1.1329, G loss: 1.1040\n",
      "[244/1762] D loss: 1.3790, G loss: 0.6552\n",
      "[324/1762] D loss: 1.1114, G loss: 0.8312\n",
      "[404/1762] D loss: 1.3359, G loss: 0.6377\n",
      "[484/1762] D loss: 1.4711, G loss: 0.4966\n",
      "[564/1762] D loss: 0.8562, G loss: 0.9868\n",
      "[644/1762] D loss: 1.3980, G loss: 0.8091\n",
      "[724/1762] D loss: 1.3932, G loss: 0.7609\n",
      "[804/1762] D loss: 1.3945, G loss: 0.8102\n",
      "[884/1762] D loss: 1.1375, G loss: 0.9834\n",
      "[964/1762] D loss: 1.1338, G loss: 1.0166\n",
      "[1044/1762] D loss: 1.4374, G loss: 0.8504\n",
      "[1124/1762] D loss: 1.4101, G loss: 0.8433\n",
      "[1204/1762] D loss: 1.4024, G loss: 0.8587\n",
      "[1284/1762] D loss: 1.3965, G loss: 0.6792\n",
      "[1364/1762] D loss: 1.4072, G loss: 0.7591\n",
      "[1444/1762] D loss: 1.4036, G loss: 0.5685\n",
      "[1524/1762] D loss: 1.4149, G loss: 0.5515\n",
      "[1604/1762] D loss: 1.4002, G loss: 0.7083\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6884\n",
      "[1762/1762] D loss: 1.3949, G loss: 0.7440\n",
      "train error: \n",
      " D loss: 1.323185, G loss: 0.659782, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303577, G loss: 0.678691, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6123\n",
      "[84/1762] D loss: 1.3975, G loss: 0.6449\n",
      "[164/1762] D loss: 1.1116, G loss: 0.8526\n",
      "[244/1762] D loss: 1.4322, G loss: 0.8753\n",
      "[324/1762] D loss: 1.3687, G loss: 1.1422\n",
      "[404/1762] D loss: 1.3891, G loss: 0.8516\n",
      "[484/1762] D loss: 1.3925, G loss: 0.6703\n",
      "[564/1762] D loss: 1.3968, G loss: 0.6115\n",
      "[644/1762] D loss: 1.3920, G loss: 0.6342\n",
      "[724/1762] D loss: 1.3953, G loss: 0.7405\n",
      "[804/1762] D loss: 1.4172, G loss: 0.6849\n",
      "[884/1762] D loss: 1.4246, G loss: 0.8687\n",
      "[964/1762] D loss: 1.1369, G loss: 0.8373\n",
      "[1044/1762] D loss: 1.4095, G loss: 0.6071\n",
      "[1124/1762] D loss: 1.4080, G loss: 0.6667\n",
      "[1204/1762] D loss: 1.2769, G loss: 0.9066\n",
      "[1284/1762] D loss: 1.4013, G loss: 0.6549\n",
      "[1364/1762] D loss: 1.4083, G loss: 0.6701\n",
      "[1444/1762] D loss: 1.1122, G loss: 0.9054\n",
      "[1524/1762] D loss: 1.1065, G loss: 1.0233\n",
      "[1604/1762] D loss: 0.8748, G loss: 0.9385\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6505\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6840\n",
      "train error: \n",
      " D loss: 1.311657, G loss: 0.850761, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294595, G loss: 0.866026, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.7284\n",
      "[84/1762] D loss: 1.3892, G loss: 0.7453\n",
      "[164/1762] D loss: 1.3929, G loss: 0.6844\n",
      "[244/1762] D loss: 1.4160, G loss: 0.8011\n",
      "[324/1762] D loss: 1.4063, G loss: 0.7964\n",
      "[404/1762] D loss: 1.3914, G loss: 0.6661\n",
      "[484/1762] D loss: 1.4076, G loss: 0.7018\n",
      "[564/1762] D loss: 1.3944, G loss: 0.6099\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6816\n",
      "[724/1762] D loss: 1.3926, G loss: 0.7048\n",
      "[804/1762] D loss: 1.1359, G loss: 0.8350\n",
      "[884/1762] D loss: 0.8599, G loss: 1.0362\n",
      "[964/1762] D loss: 1.3976, G loss: 0.6255\n",
      "[1044/1762] D loss: 1.1907, G loss: 1.2138\n",
      "[1124/1762] D loss: 1.4000, G loss: 0.6307\n",
      "[1204/1762] D loss: 1.1230, G loss: 0.8285\n",
      "[1284/1762] D loss: 1.2132, G loss: 0.9042\n",
      "[1364/1762] D loss: 1.1261, G loss: 0.8731\n",
      "[1444/1762] D loss: 1.1048, G loss: 0.9896\n",
      "[1524/1762] D loss: 1.1170, G loss: 0.8115\n",
      "[1604/1762] D loss: 1.4113, G loss: 0.7127\n",
      "[1684/1762] D loss: 1.4206, G loss: 0.6239\n",
      "[1762/1762] D loss: 1.4137, G loss: 0.5560\n",
      "train error: \n",
      " D loss: 1.319713, G loss: 0.675227, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304832, G loss: 0.691078, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4342, G loss: 0.6040\n",
      "[84/1762] D loss: 1.3520, G loss: 0.6968\n",
      "[164/1762] D loss: 1.4013, G loss: 0.7432\n",
      "[244/1762] D loss: 0.8360, G loss: 1.1884\n",
      "[324/1762] D loss: 1.3925, G loss: 0.6919\n",
      "[404/1762] D loss: 1.4138, G loss: 0.8181\n",
      "[484/1762] D loss: 1.3900, G loss: 0.6961\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6948\n",
      "[644/1762] D loss: 1.1289, G loss: 0.8241\n",
      "[724/1762] D loss: 1.4272, G loss: 0.6428\n",
      "[804/1762] D loss: 1.4480, G loss: 0.5093\n",
      "[884/1762] D loss: 1.3931, G loss: 0.6426\n",
      "[964/1762] D loss: 1.3900, G loss: 0.6682\n",
      "[1044/1762] D loss: 1.4141, G loss: 0.8272\n",
      "[1124/1762] D loss: 1.4013, G loss: 0.7929\n",
      "[1204/1762] D loss: 1.3202, G loss: 0.7419\n",
      "[1284/1762] D loss: 1.0439, G loss: 0.9836\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.7385\n",
      "[1444/1762] D loss: 1.0962, G loss: 1.0920\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7586\n",
      "[1604/1762] D loss: 1.3958, G loss: 0.6540\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7141\n",
      "[1762/1762] D loss: 1.2198, G loss: 1.2415\n",
      "train error: \n",
      " D loss: 1.312043, G loss: 0.850956, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291853, G loss: 0.877453, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1030, G loss: 0.9757\n",
      "[84/1762] D loss: 1.3411, G loss: 0.8449\n",
      "[164/1762] D loss: 1.5426, G loss: 0.5476\n",
      "[244/1762] D loss: 1.4064, G loss: 0.6961\n",
      "[324/1762] D loss: 1.3854, G loss: 0.7539\n",
      "[404/1762] D loss: 1.1033, G loss: 0.9674\n",
      "[484/1762] D loss: 1.3936, G loss: 0.6679\n",
      "[564/1762] D loss: 1.3898, G loss: 0.7084\n",
      "[644/1762] D loss: 1.3932, G loss: 0.7241\n",
      "[724/1762] D loss: 1.3881, G loss: 0.7172\n",
      "[804/1762] D loss: 1.3980, G loss: 0.7365\n",
      "[884/1762] D loss: 0.8160, G loss: 1.2051\n",
      "[964/1762] D loss: 1.3180, G loss: 0.9150\n",
      "[1044/1762] D loss: 1.4391, G loss: 0.6984\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7599\n",
      "[1204/1762] D loss: 1.4076, G loss: 0.6790\n",
      "[1284/1762] D loss: 1.4083, G loss: 0.6613\n",
      "[1364/1762] D loss: 1.4058, G loss: 0.6506\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6711\n",
      "[1524/1762] D loss: 0.8351, G loss: 1.0680\n",
      "[1604/1762] D loss: 1.2359, G loss: 0.8762\n",
      "[1684/1762] D loss: 1.4187, G loss: 0.8088\n",
      "[1762/1762] D loss: 1.3967, G loss: 0.7591\n",
      "train error: \n",
      " D loss: 1.316162, G loss: 0.884538, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293170, G loss: 0.914911, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4122, G loss: 0.7566\n",
      "[84/1762] D loss: 1.4420, G loss: 0.8096\n",
      "[164/1762] D loss: 1.3393, G loss: 0.8541\n",
      "[244/1762] D loss: 0.8378, G loss: 1.1718\n",
      "[324/1762] D loss: 1.0900, G loss: 0.9850\n",
      "[404/1762] D loss: 1.1300, G loss: 0.8997\n",
      "[484/1762] D loss: 1.3929, G loss: 0.6442\n",
      "[564/1762] D loss: 1.1459, G loss: 0.9834\n",
      "[644/1762] D loss: 1.4172, G loss: 0.9075\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6947\n",
      "[804/1762] D loss: 1.4866, G loss: 0.6711\n",
      "[884/1762] D loss: 1.4771, G loss: 0.6325\n",
      "[964/1762] D loss: 1.3931, G loss: 0.7212\n",
      "[1044/1762] D loss: 1.3986, G loss: 0.5940\n",
      "[1124/1762] D loss: 1.0977, G loss: 0.9348\n",
      "[1204/1762] D loss: 1.4018, G loss: 0.5561\n",
      "[1284/1762] D loss: 1.4070, G loss: 0.7747\n",
      "[1364/1762] D loss: 1.1336, G loss: 0.8346\n",
      "[1444/1762] D loss: 1.1092, G loss: 0.8718\n",
      "[1524/1762] D loss: 1.1031, G loss: 0.8616\n",
      "[1604/1762] D loss: 1.4083, G loss: 0.8075\n",
      "[1684/1762] D loss: 1.1331, G loss: 0.8285\n",
      "[1762/1762] D loss: 1.4033, G loss: 0.7160\n",
      "train error: \n",
      " D loss: 1.293705, G loss: 0.783816, D accuracy: 56.5%, cell accuracy: 99.6%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285716, G loss: 0.802576, D accuracy: 56.2%, cell accuracy: 99.5%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4773, G loss: 0.5884\n",
      "[84/1762] D loss: 1.3065, G loss: 0.8988\n",
      "[164/1762] D loss: 1.3995, G loss: 0.6315\n",
      "[244/1762] D loss: 1.4130, G loss: 0.7295\n",
      "[324/1762] D loss: 1.4185, G loss: 0.5396\n",
      "[404/1762] D loss: 1.4026, G loss: 0.7991\n",
      "[484/1762] D loss: 1.0750, G loss: 1.1386\n",
      "[564/1762] D loss: 1.0800, G loss: 0.9342\n",
      "[644/1762] D loss: 1.3917, G loss: 0.6326\n",
      "[724/1762] D loss: 1.3584, G loss: 0.7668\n",
      "[804/1762] D loss: 1.4063, G loss: 0.7311\n",
      "[884/1762] D loss: 1.3926, G loss: 0.6744\n",
      "[964/1762] D loss: 1.1203, G loss: 0.9256\n",
      "[1044/1762] D loss: 1.0996, G loss: 0.9491\n",
      "[1124/1762] D loss: 1.1210, G loss: 0.8970\n",
      "[1204/1762] D loss: 1.1365, G loss: 0.8062\n",
      "[1284/1762] D loss: 1.4028, G loss: 0.8187\n",
      "[1364/1762] D loss: 1.3326, G loss: 0.6738\n",
      "[1444/1762] D loss: 1.0770, G loss: 1.1456\n",
      "[1524/1762] D loss: 0.8222, G loss: 1.1952\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.7530\n",
      "[1684/1762] D loss: 1.3899, G loss: 0.7859\n",
      "[1762/1762] D loss: 1.4048, G loss: 0.6484\n",
      "train error: \n",
      " D loss: 1.304575, G loss: 0.778133, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284408, G loss: 0.796033, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951, G loss: 0.7597\n",
      "[84/1762] D loss: 1.3838, G loss: 0.6555\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6947\n",
      "[244/1762] D loss: 1.1048, G loss: 0.9045\n",
      "[324/1762] D loss: 1.3903, G loss: 0.6985\n",
      "[404/1762] D loss: 1.4066, G loss: 0.7331\n",
      "[484/1762] D loss: 1.4056, G loss: 0.6187\n",
      "[564/1762] D loss: 1.3904, G loss: 0.7312\n",
      "[644/1762] D loss: 1.0283, G loss: 1.1850\n",
      "[724/1762] D loss: 1.0877, G loss: 1.0019\n",
      "[804/1762] D loss: 1.3895, G loss: 0.7402\n",
      "[884/1762] D loss: 1.0961, G loss: 1.0040\n",
      "[964/1762] D loss: 1.0638, G loss: 1.3228\n",
      "[1044/1762] D loss: 1.5025, G loss: 0.9048\n",
      "[1124/1762] D loss: 1.2357, G loss: 0.7230\n",
      "[1204/1762] D loss: 1.2691, G loss: 0.6245\n",
      "[1284/1762] D loss: 1.4356, G loss: 0.5072\n",
      "[1364/1762] D loss: 1.2738, G loss: 1.0270\n",
      "[1444/1762] D loss: 1.4090, G loss: 0.9325\n",
      "[1524/1762] D loss: 1.3679, G loss: 0.7615\n",
      "[1604/1762] D loss: 1.3428, G loss: 0.6170\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6323\n",
      "[1762/1762] D loss: 1.4131, G loss: 0.5511\n",
      "train error: \n",
      " D loss: 1.331787, G loss: 0.606814, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316043, G loss: 0.615996, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4124, G loss: 0.6043\n",
      "[84/1762] D loss: 1.2216, G loss: 0.9313\n",
      "[164/1762] D loss: 1.4104, G loss: 0.7074\n",
      "[244/1762] D loss: 1.3790, G loss: 0.6857\n",
      "[324/1762] D loss: 1.4153, G loss: 0.6058\n",
      "[404/1762] D loss: 1.3853, G loss: 0.7219\n",
      "[484/1762] D loss: 1.4014, G loss: 0.7362\n",
      "[564/1762] D loss: 1.3929, G loss: 0.7034\n",
      "[644/1762] D loss: 1.4145, G loss: 0.7826\n",
      "[724/1762] D loss: 1.4588, G loss: 0.5798\n",
      "[804/1762] D loss: 1.3915, G loss: 0.6813\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6596\n",
      "[964/1762] D loss: 1.3928, G loss: 0.6429\n",
      "[1044/1762] D loss: 1.1389, G loss: 0.9065\n",
      "[1124/1762] D loss: 1.3476, G loss: 0.7378\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6416\n",
      "[1284/1762] D loss: 1.1542, G loss: 0.7715\n",
      "[1364/1762] D loss: 1.3264, G loss: 0.6439\n",
      "[1444/1762] D loss: 1.3922, G loss: 0.7438\n",
      "[1524/1762] D loss: 1.1030, G loss: 1.0158\n",
      "[1604/1762] D loss: 1.3989, G loss: 0.6390\n",
      "[1684/1762] D loss: 1.3804, G loss: 0.5711\n",
      "[1762/1762] D loss: 0.9318, G loss: 0.7782\n",
      "train error: \n",
      " D loss: 1.336596, G loss: 0.609332, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313313, G loss: 0.630324, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4372, G loss: 0.5721\n",
      "[84/1762] D loss: 1.3983, G loss: 0.6016\n",
      "[164/1762] D loss: 1.1345, G loss: 0.8144\n",
      "[244/1762] D loss: 1.3944, G loss: 0.6749\n",
      "[324/1762] D loss: 1.1361, G loss: 0.7752\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6727\n",
      "[484/1762] D loss: 1.1412, G loss: 1.1019\n",
      "[564/1762] D loss: 1.1402, G loss: 0.8954\n",
      "[644/1762] D loss: 1.4327, G loss: 0.8400\n",
      "[724/1762] D loss: 1.1468, G loss: 0.7260\n",
      "[804/1762] D loss: 1.1074, G loss: 0.8989\n",
      "[884/1762] D loss: 1.4852, G loss: 0.9248\n",
      "[964/1762] D loss: 1.1237, G loss: 0.8927\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.6860\n",
      "[1124/1762] D loss: 1.3988, G loss: 0.5820\n",
      "[1204/1762] D loss: 1.4048, G loss: 0.6221\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.6133\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6937\n",
      "[1444/1762] D loss: 1.1127, G loss: 0.9221\n",
      "[1524/1762] D loss: 1.4847, G loss: 0.6555\n",
      "[1604/1762] D loss: 1.3953, G loss: 0.7873\n",
      "[1684/1762] D loss: 1.4102, G loss: 0.7546\n",
      "[1762/1762] D loss: 1.3902, G loss: 0.6762\n",
      "train error: \n",
      " D loss: 1.310091, G loss: 0.840745, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288517, G loss: 0.864960, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1086, G loss: 1.0143\n",
      "[84/1762] D loss: 1.3886, G loss: 0.6885\n",
      "[164/1762] D loss: 1.3924, G loss: 0.6718\n",
      "[244/1762] D loss: 1.3906, G loss: 0.6697\n",
      "[324/1762] D loss: 1.3782, G loss: 0.6647\n",
      "[404/1762] D loss: 1.1376, G loss: 0.7623\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6636\n",
      "[564/1762] D loss: 1.3969, G loss: 0.6336\n",
      "[644/1762] D loss: 1.4006, G loss: 0.7791\n",
      "[724/1762] D loss: 1.0937, G loss: 0.9337\n",
      "[804/1762] D loss: 1.1082, G loss: 0.8908\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7036\n",
      "[964/1762] D loss: 1.4055, G loss: 0.7995\n",
      "[1044/1762] D loss: 1.3939, G loss: 0.7791\n",
      "[1124/1762] D loss: 1.1204, G loss: 0.9596\n",
      "[1204/1762] D loss: 1.4201, G loss: 0.6928\n",
      "[1284/1762] D loss: 1.3919, G loss: 0.7591\n",
      "[1364/1762] D loss: 1.1027, G loss: 1.0625\n",
      "[1444/1762] D loss: 1.1063, G loss: 0.9293\n",
      "[1524/1762] D loss: 1.1247, G loss: 0.9233\n",
      "[1604/1762] D loss: 1.4444, G loss: 0.7168\n",
      "[1684/1762] D loss: 1.0964, G loss: 0.9942\n",
      "[1762/1762] D loss: 1.1743, G loss: 1.1036\n",
      "train error: \n",
      " D loss: 1.299362, G loss: 0.809111, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276899, G loss: 0.840758, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3473, G loss: 0.6950\n",
      "[84/1762] D loss: 1.3954, G loss: 0.6712\n",
      "[164/1762] D loss: 1.0911, G loss: 0.9252\n",
      "[244/1762] D loss: 1.3949, G loss: 0.6257\n",
      "[324/1762] D loss: 1.3881, G loss: 0.7237\n",
      "[404/1762] D loss: 1.0089, G loss: 1.0517\n",
      "[484/1762] D loss: 1.1367, G loss: 0.9056\n",
      "[564/1762] D loss: 1.3926, G loss: 0.7780\n",
      "[644/1762] D loss: 1.4091, G loss: 0.8406\n",
      "[724/1762] D loss: 1.3914, G loss: 0.6983\n",
      "[804/1762] D loss: 1.3394, G loss: 0.7245\n",
      "[884/1762] D loss: 1.3969, G loss: 0.6466\n",
      "[964/1762] D loss: 1.2959, G loss: 1.0449\n",
      "[1044/1762] D loss: 1.3448, G loss: 0.6478\n",
      "[1124/1762] D loss: 1.3976, G loss: 0.5917\n",
      "[1204/1762] D loss: 1.4180, G loss: 0.5741\n",
      "[1284/1762] D loss: 1.2962, G loss: 0.9332\n",
      "[1364/1762] D loss: 1.3934, G loss: 0.7919\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6768\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.7085\n",
      "[1604/1762] D loss: 1.2878, G loss: 0.9299\n",
      "[1684/1762] D loss: 1.1101, G loss: 0.9794\n",
      "[1762/1762] D loss: 0.8825, G loss: 1.0597\n",
      "train error: \n",
      " D loss: 1.308602, G loss: 0.728205, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287214, G loss: 0.753633, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1209, G loss: 1.0017\n",
      "[84/1762] D loss: 1.3944, G loss: 0.7111\n",
      "[164/1762] D loss: 1.4106, G loss: 0.6309\n",
      "[244/1762] D loss: 1.3908, G loss: 0.6612\n",
      "[324/1762] D loss: 1.4020, G loss: 0.6986\n",
      "[404/1762] D loss: 1.0908, G loss: 0.9529\n",
      "[484/1762] D loss: 1.3902, G loss: 0.6666\n",
      "[564/1762] D loss: 1.4480, G loss: 0.5453\n",
      "[644/1762] D loss: 1.1956, G loss: 1.2258\n",
      "[724/1762] D loss: 1.3989, G loss: 0.8027\n",
      "[804/1762] D loss: 1.4290, G loss: 0.6463\n",
      "[884/1762] D loss: 1.1172, G loss: 0.8937\n",
      "[964/1762] D loss: 1.4029, G loss: 0.6056\n",
      "[1044/1762] D loss: 1.1092, G loss: 0.9396\n",
      "[1124/1762] D loss: 1.3190, G loss: 0.6817\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.7250\n",
      "[1284/1762] D loss: 1.3271, G loss: 0.8411\n",
      "[1364/1762] D loss: 1.4205, G loss: 0.4857\n",
      "[1444/1762] D loss: 1.3991, G loss: 0.6468\n",
      "[1524/1762] D loss: 1.0422, G loss: 1.2328\n",
      "[1604/1762] D loss: 1.3922, G loss: 0.7345\n",
      "[1684/1762] D loss: 1.3939, G loss: 0.7502\n",
      "[1762/1762] D loss: 0.8096, G loss: 1.2415\n",
      "train error: \n",
      " D loss: 1.301296, G loss: 0.765620, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276387, G loss: 0.800967, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.7637\n",
      "[84/1762] D loss: 1.4017, G loss: 0.8051\n",
      "[164/1762] D loss: 1.3897, G loss: 0.6341\n",
      "[244/1762] D loss: 1.3891, G loss: 0.6480\n",
      "[324/1762] D loss: 1.1107, G loss: 0.8237\n",
      "[404/1762] D loss: 1.2883, G loss: 0.8061\n",
      "[484/1762] D loss: 1.3951, G loss: 0.6364\n",
      "[564/1762] D loss: 1.1110, G loss: 1.1297\n",
      "[644/1762] D loss: 1.3949, G loss: 0.7115\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6716\n",
      "[804/1762] D loss: 1.3888, G loss: 0.8004\n",
      "[884/1762] D loss: 1.4142, G loss: 0.7689\n",
      "[964/1762] D loss: 1.0977, G loss: 0.9085\n",
      "[1044/1762] D loss: 1.3939, G loss: 0.7345\n",
      "[1124/1762] D loss: 1.1008, G loss: 1.0032\n",
      "[1204/1762] D loss: 1.3949, G loss: 0.7040\n",
      "[1284/1762] D loss: 1.1567, G loss: 1.1418\n",
      "[1364/1762] D loss: 0.7947, G loss: 1.2879\n",
      "[1444/1762] D loss: 1.3974, G loss: 0.7969\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.7695\n",
      "[1604/1762] D loss: 1.3913, G loss: 0.5780\n",
      "[1684/1762] D loss: 1.3909, G loss: 0.6946\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.7151\n",
      "train error: \n",
      " D loss: 1.311593, G loss: 0.886278, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288057, G loss: 0.922604, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4011, G loss: 0.7127\n",
      "[84/1762] D loss: 1.4039, G loss: 0.5600\n",
      "[164/1762] D loss: 1.4234, G loss: 0.5502\n",
      "[244/1762] D loss: 1.3934, G loss: 0.7167\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6755\n",
      "[404/1762] D loss: 1.3993, G loss: 0.6421\n",
      "[484/1762] D loss: 1.3920, G loss: 0.6877\n",
      "[564/1762] D loss: 1.3909, G loss: 0.7042\n",
      "[644/1762] D loss: 1.3952, G loss: 0.6532\n",
      "[724/1762] D loss: 1.4055, G loss: 0.6578\n",
      "[804/1762] D loss: 1.3943, G loss: 0.6701\n",
      "[884/1762] D loss: 1.3231, G loss: 0.6068\n",
      "[964/1762] D loss: 1.4100, G loss: 0.5943\n",
      "[1044/1762] D loss: 1.3942, G loss: 0.6573\n",
      "[1124/1762] D loss: 1.4081, G loss: 0.7145\n",
      "[1204/1762] D loss: 1.4105, G loss: 0.6576\n",
      "[1284/1762] D loss: 1.1100, G loss: 0.9426\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6487\n",
      "[1444/1762] D loss: 1.0828, G loss: 0.9982\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.7074\n",
      "[1604/1762] D loss: 1.1260, G loss: 1.0294\n",
      "[1684/1762] D loss: 1.3959, G loss: 0.7404\n",
      "[1762/1762] D loss: 1.3998, G loss: 0.8198\n",
      "train error: \n",
      " D loss: 1.320194, G loss: 0.953097, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297620, G loss: 0.995383, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4067, G loss: 0.7491\n",
      "[84/1762] D loss: 1.4009, G loss: 0.7394\n",
      "[164/1762] D loss: 1.3961, G loss: 0.7035\n",
      "[244/1762] D loss: 1.3903, G loss: 0.7555\n",
      "[324/1762] D loss: 1.0575, G loss: 1.2875\n",
      "[404/1762] D loss: 1.4635, G loss: 0.7640\n",
      "[484/1762] D loss: 1.4068, G loss: 0.7045\n",
      "[564/1762] D loss: 1.3820, G loss: 0.6515\n",
      "[644/1762] D loss: 1.4048, G loss: 0.5688\n",
      "[724/1762] D loss: 1.4016, G loss: 0.7000\n",
      "[804/1762] D loss: 1.3886, G loss: 0.7118\n",
      "[884/1762] D loss: 1.1012, G loss: 0.9387\n",
      "[964/1762] D loss: 1.4025, G loss: 0.7883\n",
      "[1044/1762] D loss: 1.1543, G loss: 0.8592\n",
      "[1124/1762] D loss: 1.3839, G loss: 0.6484\n",
      "[1204/1762] D loss: 1.3765, G loss: 0.6223\n",
      "[1284/1762] D loss: 1.3742, G loss: 0.7365\n",
      "[1364/1762] D loss: 1.0874, G loss: 1.0110\n",
      "[1444/1762] D loss: 1.0773, G loss: 1.0273\n",
      "[1524/1762] D loss: 1.3562, G loss: 0.6525\n",
      "[1604/1762] D loss: 1.4269, G loss: 0.6103\n",
      "[1684/1762] D loss: 1.0949, G loss: 0.9430\n",
      "[1762/1762] D loss: 1.3851, G loss: 0.7736\n",
      "train error: \n",
      " D loss: 1.301871, G loss: 0.877329, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284749, G loss: 0.901734, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5208, G loss: 0.7312\n",
      "[84/1762] D loss: 1.0839, G loss: 1.2767\n",
      "[164/1762] D loss: 1.3887, G loss: 0.7147\n",
      "[244/1762] D loss: 1.3617, G loss: 0.7614\n",
      "[324/1762] D loss: 1.1121, G loss: 1.0329\n",
      "[404/1762] D loss: 1.4006, G loss: 0.7568\n",
      "[484/1762] D loss: 1.4348, G loss: 0.7247\n",
      "[564/1762] D loss: 1.2399, G loss: 0.8111\n",
      "[644/1762] D loss: 1.5275, G loss: 0.5370\n",
      "[724/1762] D loss: 1.1859, G loss: 0.9306\n",
      "[804/1762] D loss: 1.3036, G loss: 0.6289\n",
      "[884/1762] D loss: 1.2928, G loss: 0.7244\n",
      "[964/1762] D loss: 1.4217, G loss: 1.1041\n",
      "[1044/1762] D loss: 1.3527, G loss: 0.9401\n",
      "[1124/1762] D loss: 1.3736, G loss: 0.8055\n",
      "[1204/1762] D loss: 1.4487, G loss: 0.8011\n",
      "[1284/1762] D loss: 1.2668, G loss: 0.9354\n",
      "[1364/1762] D loss: 1.2893, G loss: 1.0107\n",
      "[1444/1762] D loss: 1.3663, G loss: 0.8807\n",
      "[1524/1762] D loss: 1.3992, G loss: 0.7381\n",
      "[1604/1762] D loss: 1.1450, G loss: 0.8295\n",
      "[1684/1762] D loss: 1.5841, G loss: 1.1245\n",
      "[1762/1762] D loss: 1.4935, G loss: 1.0994\n",
      "train error: \n",
      " D loss: 1.395516, G loss: 1.182491, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375062, G loss: 1.206644, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4529, G loss: 1.2543\n",
      "[84/1762] D loss: 1.3520, G loss: 0.9831\n",
      "[164/1762] D loss: 1.0734, G loss: 1.1216\n",
      "[244/1762] D loss: 1.2476, G loss: 0.8616\n",
      "[324/1762] D loss: 1.3972, G loss: 0.8384\n",
      "[404/1762] D loss: 1.4025, G loss: 0.5922\n",
      "[484/1762] D loss: 1.2044, G loss: 0.8326\n",
      "[564/1762] D loss: 1.4422, G loss: 0.5895\n",
      "[644/1762] D loss: 1.2913, G loss: 0.8294\n",
      "[724/1762] D loss: 1.1739, G loss: 0.7784\n",
      "[804/1762] D loss: 1.4206, G loss: 0.6009\n",
      "[884/1762] D loss: 1.4191, G loss: 0.6294\n",
      "[964/1762] D loss: 1.3996, G loss: 0.7462\n",
      "[1044/1762] D loss: 1.1255, G loss: 0.9694\n",
      "[1124/1762] D loss: 1.3209, G loss: 1.0718\n",
      "[1204/1762] D loss: 1.4183, G loss: 0.6169\n",
      "[1284/1762] D loss: 1.2364, G loss: 1.0660\n",
      "[1364/1762] D loss: 1.4200, G loss: 0.8265\n",
      "[1444/1762] D loss: 1.3922, G loss: 0.6834\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.6679\n",
      "[1604/1762] D loss: 1.4008, G loss: 0.6509\n",
      "[1684/1762] D loss: 1.4265, G loss: 0.7339\n",
      "[1762/1762] D loss: 1.1208, G loss: 1.2118\n",
      "train error: \n",
      " D loss: 1.288429, G loss: 0.765949, D accuracy: 57.9%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265887, G loss: 0.788477, D accuracy: 59.3%, cell accuracy: 99.6%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3359, G loss: 0.6537\n",
      "[84/1762] D loss: 1.3939, G loss: 0.6117\n",
      "[164/1762] D loss: 0.9854, G loss: 1.1701\n",
      "[244/1762] D loss: 1.2367, G loss: 1.1548\n",
      "[324/1762] D loss: 1.4265, G loss: 0.8067\n",
      "[404/1762] D loss: 1.3671, G loss: 0.7136\n",
      "[484/1762] D loss: 1.3929, G loss: 0.7409\n",
      "[564/1762] D loss: 1.1242, G loss: 0.8215\n",
      "[644/1762] D loss: 1.3921, G loss: 0.6316\n",
      "[724/1762] D loss: 1.1287, G loss: 0.7914\n",
      "[804/1762] D loss: 1.4376, G loss: 0.8534\n",
      "[884/1762] D loss: 1.3934, G loss: 0.5831\n",
      "[964/1762] D loss: 0.8861, G loss: 0.9821\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.6063\n",
      "[1124/1762] D loss: 1.0827, G loss: 1.0616\n",
      "[1204/1762] D loss: 1.4304, G loss: 0.7814\n",
      "[1284/1762] D loss: 1.0939, G loss: 1.0243\n",
      "[1364/1762] D loss: 1.4009, G loss: 0.6967\n",
      "[1444/1762] D loss: 1.3931, G loss: 0.6679\n",
      "[1524/1762] D loss: 1.2390, G loss: 0.8500\n",
      "[1604/1762] D loss: 1.3411, G loss: 0.7949\n",
      "[1684/1762] D loss: 1.4304, G loss: 0.8186\n",
      "[1762/1762] D loss: 1.1368, G loss: 1.0886\n",
      "train error: \n",
      " D loss: 1.273313, G loss: 0.765900, D accuracy: 58.2%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250963, G loss: 0.797630, D accuracy: 58.2%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4153, G loss: 0.5611\n",
      "[84/1762] D loss: 1.3941, G loss: 0.6946\n",
      "[164/1762] D loss: 1.4039, G loss: 0.7241\n",
      "[244/1762] D loss: 1.1442, G loss: 0.9961\n",
      "[324/1762] D loss: 1.3781, G loss: 0.6158\n",
      "[404/1762] D loss: 1.3586, G loss: 0.9723\n",
      "[484/1762] D loss: 1.0973, G loss: 0.8179\n",
      "[564/1762] D loss: 1.1053, G loss: 1.0004\n",
      "[644/1762] D loss: 1.3915, G loss: 0.7453\n",
      "[724/1762] D loss: 1.3193, G loss: 0.7181\n",
      "[804/1762] D loss: 1.1035, G loss: 0.9865\n",
      "[884/1762] D loss: 1.1369, G loss: 1.3200\n",
      "[964/1762] D loss: 1.4204, G loss: 0.8241\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.6039\n",
      "[1124/1762] D loss: 1.3828, G loss: 0.7371\n",
      "[1204/1762] D loss: 1.4447, G loss: 0.6139\n",
      "[1284/1762] D loss: 1.1604, G loss: 1.0602\n",
      "[1364/1762] D loss: 1.1093, G loss: 0.7342\n",
      "[1444/1762] D loss: 1.4155, G loss: 0.6222\n",
      "[1524/1762] D loss: 1.4186, G loss: 0.5872\n",
      "[1604/1762] D loss: 1.1522, G loss: 0.8285\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.6406\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.7128\n",
      "train error: \n",
      " D loss: 1.330306, G loss: 0.827251, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319310, G loss: 0.850678, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for cls in [TetrisDiscriminator, DiscWithExtraPaddedConvAfterPool, DiscWithExtraPaddedConvBeforePool, DiscWithStridedConv, DiscWith2x2Conv]:\n",
    "        train(run_name=cls.__name__, disc_cls=cls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these alternative discriminator architectures lead to an overall similar performance, and some architectures even degrade the performance, as measured by board accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We should keep the discriminator architecture the same for the time being, because reasonable-seeming changes to it don't improve the GAN performance and may degrade it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
