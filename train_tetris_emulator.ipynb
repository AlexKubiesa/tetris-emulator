{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Tetris emulator\n",
    "\n",
    "In this notebook, we train a model to emulate Tetris and provide a backend for our model-based game engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from models import TetrisModel, TetrisDiscriminator\n",
    "import metrics\n",
    "from recording import FileBasedDatabaseWithEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CELL_TYPES = 8\n",
    "NUM_EVENT_TYPES = 5\n",
    "\n",
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self._db = FileBasedDatabaseWithEvents(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._db)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        boards, events = self._db[idx]\n",
    "        b = self._transform_board(boards[-2]) # Ignore all boards except the last two\n",
    "        e = self._transform_event(events[-1])\n",
    "        x = (b, e)\n",
    "        y = self._transform_board(boards[-1])\n",
    "        return x, y\n",
    "    \n",
    "    def _transform_board(self, board):\n",
    "        board = torch.tensor(board, dtype=torch.long)\n",
    "        board = F.one_hot(board, NUM_CELL_TYPES) # One-hot encode the cell types\n",
    "        board = board.type(torch.float) # Convert to floating-point\n",
    "        board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "        return board\n",
    "    \n",
    "    def _transform_event(self, event):\n",
    "        event = torch.tensor(event, dtype=torch.long)\n",
    "        event = F.one_hot(event, NUM_EVENT_TYPES) # One-hot encode the event\n",
    "        event = event.type(torch.float) # Convert to floating-point\n",
    "        return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: shape torch.Size([4, 8, 22, 10]), dtype torch.float32\n",
      "e: shape torch.Size([4, 5]), dtype torch.float32\n",
      "y: shape torch.Size([4, 8, 22, 10]), dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "(b, e), y = next(iter(train_dataloader))\n",
    "print(f\"x: shape {b.shape}, dtype {b.dtype}\")\n",
    "print(f\"e: shape {e.shape}, dtype {e.dtype}\")\n",
    "print(f\"y: shape {y.shape}, dtype {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generator parameters: 19682\n",
      "Number of discriminator parameters: 9505\n",
      "Discriminator score for real data: 0.5570533275604248\n",
      "Discriminator score for fake data: 0.5637677907943726\n"
     ]
    }
   ],
   "source": [
    "gen = TetrisModel()\n",
    "disc = TetrisDiscriminator()\n",
    "\n",
    "with torch.no_grad():\n",
    "    (b, e), y = next(iter(train_dataloader))\n",
    "    y_gen = gen(b, e)\n",
    "    pred_on_real = F.sigmoid(disc(b, e, y)[0])\n",
    "    pred_on_fake = F.sigmoid(disc(b, e, y_gen)[0])\n",
    "    print(f\"Number of generator parameters: {count_parameters(gen)}\")\n",
    "    print(f\"Number of discriminator parameters: {count_parameters(disc)}\")\n",
    "    print(f\"Discriminator score for real data: {pred_on_real}\")\n",
    "    print(f\"Discriminator score for fake data: {pred_on_fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from engines import EventTypes\n",
    "\n",
    "def find_interesting_examples(dataset, num=3):\n",
    "    num_spawns = num\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "\n",
    "        for (b, e), y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (e.argmax(0).item() == EventTypes.DROP) & (b.argmax(0)[0] == 0).all() & (y.argmax(0)[0] > 0).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield (b, e), y\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tetris import CELL_COLORS\n",
    "\n",
    "def render_board(board):\n",
    "    height, width = board.shape\n",
    "    imgs = np.zeros((3, height, width))\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            imgs[:, row, col] = CELL_COLORS[board[row, col]] / 255.0\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prediction(b, e, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        b: Tensor of shape (height, width), the initial board state.\n",
    "        e: Tensor of shape (1,), the event type.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the next board state.\n",
    "    \"\"\"\n",
    "    assert len(b.shape) == 2, f\"Expected tensors of shape (width, height) but got {b.shape}\"\n",
    "    assert b.shape == pred.shape, f\"Shapes do not match: {b.shape} != {pred.shape}\"\n",
    "    assert b.shape == y.shape, f\"Shapes do not match: {b.shape} != {y.shape}\"\n",
    "    assert len(e.shape) == 0, f\"Expected e of shape () but got {e.shape}\"\n",
    "    height, width = b.shape\n",
    "    with torch.no_grad():\n",
    "        b = render_board(b)\n",
    "        pred = render_board(pred)\n",
    "        y = render_board(y)\n",
    "        separator = np.ones((3, height, 1))\n",
    "        return np.concatenate((b, separator, pred, separator, y), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, ((b, e), y) in enumerate(dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        batch_size = b.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(b, e, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(b, e)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(b, e, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(b, e, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 30 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = metrics.CellAccuracy()\n",
    "    board_accuracy = metrics.BoardAccuracy()\n",
    "    board_plausibility = metrics.BoardPlausibility()\n",
    "    spawn_recall = metrics.SpawnRecall()\n",
    "    spawn_precision = metrics.SpawnPrecision()\n",
    "    spawn_validity = metrics.SpawnValidity()\n",
    "    scores_real = np.zeros(len(dataloader.dataset))\n",
    "    scores_fake = np.zeros(len(dataloader.dataset))\n",
    "    spawn_diversity = metrics.SpawnDiversity()\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for batch, ((b, e), y) in enumerate(dataloader):\n",
    "            batch_size = b.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float)\n",
    "\n",
    "            output_real = disc(b, e, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            y_fake = gen(b, e)\n",
    "            output_fake = disc(b, e, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_b = torch.argmax(b, dim=1)\n",
    "            classes_e = torch.argmax(e, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy.update_state(classes_y_fake, classes_y)\n",
    "            board_accuracy.update_state(classes_y_fake, classes_y)\n",
    "            board_plausibility.update_state(classes_b, classes_y_fake, classes_y)\n",
    "\n",
    "            spawn_recall.update_state(classes_b, classes_y_fake, classes_y)\n",
    "            spawn_precision.update_state(classes_b, classes_y_fake, classes_y)\n",
    "            spawn_validity.update_state(classes_b, classes_y_fake)\n",
    "\n",
    "            start_index = dataloader.batch_size * batch\n",
    "            end_index = start_index + batch_size\n",
    "            scores_real[start_index:end_index] = torch.sigmoid(output_real).numpy()\n",
    "            scores_fake[start_index:end_index] = torch.sigmoid(output_fake).numpy()\n",
    "\n",
    "            spawn_diversity.update_state(classes_b, classes_y_fake)\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(cell_accuracy.result()):>0.1%}, board accuracy: {(board_accuracy.result()):>0.1%} \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Board plausibility/{split_name}\", board_plausibility.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn precision/{split_name}\", spawn_precision.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn validity/{split_name}\", spawn_validity.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn diversity/{split_name}\", spawn_diversity.result(), epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, ((b, e), y) in enumerate(examples):\n",
    "            b, e, y = b.unsqueeze(0), e.unsqueeze(0), y.unsqueeze(0)\n",
    "            y_fake = gen(b, e)\n",
    "            b, e, y, y_fake = b.squeeze(0), e.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            b, e, y, y_fake = b.argmax(0), e.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(b, e, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch)\n",
    "    \n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/real\", scores_real, epoch)\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/fake\", scores_fake, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3664, G loss: 0.7211\n",
      "[124/1600] D loss: 1.2802, G loss: 0.7686\n",
      "[244/1600] D loss: 1.1741, G loss: 0.8197\n",
      "[364/1600] D loss: 0.9778, G loss: 0.9621\n",
      "[484/1600] D loss: 0.8213, G loss: 1.1113\n",
      "[604/1600] D loss: 0.4770, G loss: 1.6681\n",
      "[724/1600] D loss: 0.2621, G loss: 2.3749\n",
      "[844/1600] D loss: 0.1249, G loss: 2.9399\n",
      "[964/1600] D loss: 0.1020, G loss: 3.8633\n",
      "[1084/1600] D loss: 0.1163, G loss: 4.0705\n",
      "[1204/1600] D loss: 0.1563, G loss: 3.4673\n",
      "[1324/1600] D loss: 0.1030, G loss: 4.9006\n",
      "[1444/1600] D loss: 0.0500, G loss: 5.8696\n",
      "[1564/1600] D loss: 0.1252, G loss: 5.9771\n",
      "train error: \n",
      " D loss: 0.191194, G loss: 5.838715, D accuracy: 96.9%, cell accuracy: 40.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.161720, G loss: 5.868677, D accuracy: 98.2%, cell accuracy: 40.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1091, G loss: 6.0402\n",
      "[124/1600] D loss: 0.1501, G loss: 5.4206\n",
      "[244/1600] D loss: 0.1031, G loss: 5.9282\n",
      "[364/1600] D loss: 0.0916, G loss: 6.4252\n",
      "[484/1600] D loss: 0.5493, G loss: 5.9694\n",
      "[604/1600] D loss: 0.1876, G loss: 6.2105\n",
      "[724/1600] D loss: 0.1586, G loss: 6.6171\n",
      "[844/1600] D loss: 0.3270, G loss: 5.2938\n",
      "[964/1600] D loss: 0.0795, G loss: 5.4654\n",
      "[1084/1600] D loss: 0.3485, G loss: 5.4722\n",
      "[1204/1600] D loss: 0.1362, G loss: 5.8442\n",
      "[1324/1600] D loss: 0.1489, G loss: 6.3669\n",
      "[1444/1600] D loss: 0.1469, G loss: 5.3525\n",
      "[1564/1600] D loss: 0.0654, G loss: 7.6421\n",
      "train error: \n",
      " D loss: 0.200560, G loss: 6.252357, D accuracy: 99.6%, cell accuracy: 56.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.193305, G loss: 6.244578, D accuracy: 99.9%, cell accuracy: 55.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1588, G loss: 6.8314\n",
      "[124/1600] D loss: 0.1440, G loss: 8.0332\n",
      "[244/1600] D loss: 0.5542, G loss: 7.2620\n",
      "[364/1600] D loss: 0.1188, G loss: 7.2896\n",
      "[484/1600] D loss: 0.0907, G loss: 4.8524\n",
      "[604/1600] D loss: 0.1135, G loss: 5.8245\n",
      "[724/1600] D loss: 0.3981, G loss: 6.3810\n",
      "[844/1600] D loss: 0.2796, G loss: 7.5039\n",
      "[964/1600] D loss: 0.3701, G loss: 6.2424\n",
      "[1084/1600] D loss: 0.3296, G loss: 5.4288\n",
      "[1204/1600] D loss: 0.1335, G loss: 7.1364\n",
      "[1324/1600] D loss: 0.1530, G loss: 4.6017\n",
      "[1444/1600] D loss: 0.1096, G loss: 5.4592\n",
      "[1564/1600] D loss: 0.5636, G loss: 5.9339\n",
      "train error: \n",
      " D loss: 0.188625, G loss: 6.148050, D accuracy: 99.4%, cell accuracy: 71.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.185803, G loss: 6.676411, D accuracy: 99.5%, cell accuracy: 70.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2617, G loss: 6.2427\n",
      "[124/1600] D loss: 0.1964, G loss: 3.9054\n",
      "[244/1600] D loss: 0.1885, G loss: 3.0241\n",
      "[364/1600] D loss: 0.1415, G loss: 5.5387\n",
      "[484/1600] D loss: 0.2722, G loss: 5.7956\n",
      "[604/1600] D loss: 0.2686, G loss: 2.7449\n",
      "[724/1600] D loss: 0.2248, G loss: 2.9684\n",
      "[844/1600] D loss: 0.2800, G loss: 2.4770\n",
      "[964/1600] D loss: 0.1309, G loss: 3.0193\n",
      "[1084/1600] D loss: 0.1691, G loss: 2.1804\n",
      "[1204/1600] D loss: 0.2273, G loss: 2.3044\n",
      "[1324/1600] D loss: 0.3366, G loss: 1.8976\n",
      "[1444/1600] D loss: 0.5018, G loss: 1.5521\n",
      "[1564/1600] D loss: 0.2382, G loss: 3.2900\n",
      "train error: \n",
      " D loss: 0.331588, G loss: 2.347929, D accuracy: 98.8%, cell accuracy: 77.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.334923, G loss: 2.381387, D accuracy: 98.1%, cell accuracy: 77.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1948, G loss: 2.4113\n",
      "[124/1600] D loss: 0.2988, G loss: 2.3131\n",
      "[244/1600] D loss: 0.2674, G loss: 1.9075\n",
      "[364/1600] D loss: 0.3420, G loss: 2.0244\n",
      "[484/1600] D loss: 0.3780, G loss: 1.6978\n",
      "[604/1600] D loss: 0.3189, G loss: 1.9356\n",
      "[724/1600] D loss: 0.4846, G loss: 2.0847\n",
      "[844/1600] D loss: 0.2376, G loss: 2.3077\n",
      "[964/1600] D loss: 0.3007, G loss: 1.7477\n",
      "[1084/1600] D loss: 0.3804, G loss: 1.9093\n",
      "[1204/1600] D loss: 0.2068, G loss: 3.0211\n",
      "[1324/1600] D loss: 0.2430, G loss: 2.4031\n",
      "[1444/1600] D loss: 0.4632, G loss: 1.9441\n",
      "[1564/1600] D loss: 0.0722, G loss: 3.3528\n",
      "train error: \n",
      " D loss: 0.305273, G loss: 2.257821, D accuracy: 97.8%, cell accuracy: 77.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.317116, G loss: 2.317587, D accuracy: 97.2%, cell accuracy: 76.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1625, G loss: 3.0659\n",
      "[124/1600] D loss: 0.2441, G loss: 2.5061\n",
      "[244/1600] D loss: 0.2813, G loss: 2.9253\n",
      "[364/1600] D loss: 0.7097, G loss: 2.9190\n",
      "[484/1600] D loss: 0.0824, G loss: 3.0770\n",
      "[604/1600] D loss: 0.1274, G loss: 2.3208\n",
      "[724/1600] D loss: 0.3171, G loss: 1.9553\n",
      "[844/1600] D loss: 0.0488, G loss: 3.6822\n",
      "[964/1600] D loss: 0.3153, G loss: 2.2104\n",
      "[1084/1600] D loss: 0.1606, G loss: 3.5176\n",
      "[1204/1600] D loss: 0.3203, G loss: 2.6746\n",
      "[1324/1600] D loss: 0.1183, G loss: 3.0014\n",
      "[1444/1600] D loss: 0.1474, G loss: 2.4728\n",
      "[1564/1600] D loss: 0.2189, G loss: 2.0877\n",
      "train error: \n",
      " D loss: 0.202605, G loss: 4.184395, D accuracy: 96.6%, cell accuracy: 78.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.231614, G loss: 4.244873, D accuracy: 95.8%, cell accuracy: 77.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1450, G loss: 3.1899\n",
      "[124/1600] D loss: 0.3051, G loss: 3.2618\n",
      "[244/1600] D loss: 0.0550, G loss: 3.6253\n",
      "[364/1600] D loss: 0.0767, G loss: 3.6426\n",
      "[484/1600] D loss: 0.0098, G loss: 5.8809\n",
      "[604/1600] D loss: 0.0525, G loss: 6.1015\n",
      "[724/1600] D loss: 0.3382, G loss: 3.5306\n",
      "[844/1600] D loss: 0.0658, G loss: 5.7261\n",
      "[964/1600] D loss: 0.0249, G loss: 4.8382\n",
      "[1084/1600] D loss: 0.0102, G loss: 5.0618\n",
      "[1204/1600] D loss: 0.1022, G loss: 3.5158\n",
      "[1324/1600] D loss: 0.0180, G loss: 4.6078\n",
      "[1444/1600] D loss: 0.0121, G loss: 6.7333\n",
      "[1564/1600] D loss: 0.1543, G loss: 3.6223\n",
      "train error: \n",
      " D loss: 0.095038, G loss: 4.360932, D accuracy: 99.3%, cell accuracy: 78.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.111593, G loss: 4.486610, D accuracy: 98.4%, cell accuracy: 78.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0722, G loss: 4.2310\n",
      "[124/1600] D loss: 0.0512, G loss: 4.2190\n",
      "[244/1600] D loss: 0.0075, G loss: 5.6139\n",
      "[364/1600] D loss: 0.0143, G loss: 7.1524\n",
      "[484/1600] D loss: 0.0577, G loss: 3.8288\n",
      "[604/1600] D loss: 0.0565, G loss: 5.7774\n",
      "[724/1600] D loss: 0.0389, G loss: 4.4035\n",
      "[844/1600] D loss: 0.1266, G loss: 3.7405\n",
      "[964/1600] D loss: 0.0196, G loss: 6.2960\n",
      "[1084/1600] D loss: 0.0896, G loss: 3.7651\n",
      "[1204/1600] D loss: 0.1550, G loss: 2.2556\n",
      "[1324/1600] D loss: 0.0276, G loss: 4.8545\n",
      "[1444/1600] D loss: 0.0421, G loss: 5.7368\n",
      "[1564/1600] D loss: 0.2573, G loss: 3.1881\n",
      "train error: \n",
      " D loss: 0.122247, G loss: 6.208199, D accuracy: 97.5%, cell accuracy: 79.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.154830, G loss: 6.304732, D accuracy: 96.8%, cell accuracy: 78.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0478, G loss: 4.4009\n",
      "[124/1600] D loss: 0.2630, G loss: 3.5783\n",
      "[244/1600] D loss: 0.0016, G loss: 8.1205\n",
      "[364/1600] D loss: 0.0884, G loss: 5.9001\n",
      "[484/1600] D loss: 0.0275, G loss: 6.0218\n",
      "[604/1600] D loss: 0.1648, G loss: 3.3865\n",
      "[724/1600] D loss: 0.1291, G loss: 4.6408\n",
      "[844/1600] D loss: 0.2218, G loss: 3.3909\n",
      "[964/1600] D loss: 0.0121, G loss: 6.8586\n",
      "[1084/1600] D loss: 0.0346, G loss: 3.5076\n",
      "[1204/1600] D loss: 0.0139, G loss: 6.2076\n",
      "[1324/1600] D loss: 0.0040, G loss: 6.7177\n",
      "[1444/1600] D loss: 0.1249, G loss: 3.6990\n",
      "[1564/1600] D loss: 0.0376, G loss: 5.6526\n",
      "train error: \n",
      " D loss: 0.073428, G loss: 4.590743, D accuracy: 99.7%, cell accuracy: 79.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.077727, G loss: 4.748871, D accuracy: 99.8%, cell accuracy: 78.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0294, G loss: 4.9966\n",
      "[124/1600] D loss: 0.0201, G loss: 6.3630\n",
      "[244/1600] D loss: 0.0116, G loss: 5.0392\n",
      "[364/1600] D loss: 0.1079, G loss: 5.2141\n",
      "[484/1600] D loss: 0.0104, G loss: 5.2016\n",
      "[604/1600] D loss: 0.0862, G loss: 4.7236\n",
      "[724/1600] D loss: 0.0242, G loss: 5.6479\n",
      "[844/1600] D loss: 0.0096, G loss: 7.7935\n",
      "[964/1600] D loss: 0.1002, G loss: 5.2663\n",
      "[1084/1600] D loss: 0.2136, G loss: 2.4323\n",
      "[1204/1600] D loss: 0.0118, G loss: 5.7194\n",
      "[1324/1600] D loss: 0.0790, G loss: 4.0596\n",
      "[1444/1600] D loss: 0.0998, G loss: 3.3957\n",
      "[1564/1600] D loss: 0.0875, G loss: 3.9048\n",
      "train error: \n",
      " D loss: 0.136176, G loss: 7.125595, D accuracy: 97.3%, cell accuracy: 78.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.170203, G loss: 7.219415, D accuracy: 96.5%, cell accuracy: 78.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1525, G loss: 7.5043\n",
      "[124/1600] D loss: 0.0656, G loss: 4.7127\n",
      "[244/1600] D loss: 0.0009, G loss: 9.1450\n",
      "[364/1600] D loss: 0.0270, G loss: 5.4838\n",
      "[484/1600] D loss: 0.0342, G loss: 6.5439\n",
      "[604/1600] D loss: 0.0197, G loss: 5.0689\n",
      "[724/1600] D loss: 0.0024, G loss: 6.8807\n",
      "[844/1600] D loss: 0.1611, G loss: 4.6534\n",
      "[964/1600] D loss: 0.0114, G loss: 6.4803\n",
      "[1084/1600] D loss: 0.2304, G loss: 7.7061\n",
      "[1204/1600] D loss: 0.3676, G loss: 4.6113\n",
      "[1324/1600] D loss: 0.0152, G loss: 5.2884\n",
      "[1444/1600] D loss: 0.0062, G loss: 6.5937\n",
      "[1564/1600] D loss: 0.0114, G loss: 6.1463\n",
      "train error: \n",
      " D loss: 0.078859, G loss: 6.642281, D accuracy: 99.0%, cell accuracy: 79.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.099270, G loss: 6.693571, D accuracy: 98.5%, cell accuracy: 79.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0626, G loss: 5.7446\n",
      "[124/1600] D loss: 1.7200, G loss: 6.0675\n",
      "[244/1600] D loss: 0.1625, G loss: 4.5694\n",
      "[364/1600] D loss: 0.0510, G loss: 6.2574\n",
      "[484/1600] D loss: 0.0003, G loss: 8.4875\n",
      "[604/1600] D loss: 0.0822, G loss: 4.4535\n",
      "[724/1600] D loss: 0.0183, G loss: 5.4655\n",
      "[844/1600] D loss: 0.0257, G loss: 6.6605\n",
      "[964/1600] D loss: 0.0006, G loss: 8.2869\n",
      "[1084/1600] D loss: 0.1271, G loss: 3.9490\n",
      "[1204/1600] D loss: 0.0549, G loss: 5.8410\n",
      "[1324/1600] D loss: 0.3234, G loss: 7.5924\n",
      "[1444/1600] D loss: 0.2123, G loss: 6.0349\n",
      "[1564/1600] D loss: 0.9857, G loss: 5.1093\n",
      "train error: \n",
      " D loss: 0.084365, G loss: 4.341126, D accuracy: 99.1%, cell accuracy: 80.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.094535, G loss: 4.430974, D accuracy: 98.8%, cell accuracy: 80.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0051, G loss: 6.2529\n",
      "[124/1600] D loss: 0.0292, G loss: 5.2910\n",
      "[244/1600] D loss: 0.1321, G loss: 3.2777\n",
      "[364/1600] D loss: 0.0672, G loss: 3.7928\n",
      "[484/1600] D loss: 0.0141, G loss: 7.2178\n",
      "[604/1600] D loss: 0.1218, G loss: 4.4558\n",
      "[724/1600] D loss: 0.0017, G loss: 7.0298\n",
      "[844/1600] D loss: 0.2233, G loss: 6.7370\n",
      "[964/1600] D loss: 0.1215, G loss: 3.5431\n",
      "[1084/1600] D loss: 0.2013, G loss: 5.3095\n",
      "[1204/1600] D loss: 0.0355, G loss: 4.0090\n",
      "[1324/1600] D loss: 0.1126, G loss: 3.4499\n",
      "[1444/1600] D loss: 0.0746, G loss: 3.1308\n",
      "[1564/1600] D loss: 0.0286, G loss: 4.6498\n",
      "train error: \n",
      " D loss: 0.058963, G loss: 5.536778, D accuracy: 99.4%, cell accuracy: 81.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.070041, G loss: 5.642759, D accuracy: 99.1%, cell accuracy: 81.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0131, G loss: 5.0172\n",
      "[124/1600] D loss: 0.6419, G loss: 4.5522\n",
      "[244/1600] D loss: 0.0071, G loss: 7.3305\n",
      "[364/1600] D loss: 0.0828, G loss: 4.2701\n",
      "[484/1600] D loss: 0.0383, G loss: 4.9522\n",
      "[604/1600] D loss: 0.0397, G loss: 5.0436\n",
      "[724/1600] D loss: 0.0030, G loss: 6.9579\n",
      "[844/1600] D loss: 0.0204, G loss: 4.7631\n",
      "[964/1600] D loss: 0.0078, G loss: 6.3092\n",
      "[1084/1600] D loss: 0.0594, G loss: 3.7145\n",
      "[1204/1600] D loss: 0.0087, G loss: 7.8911\n",
      "[1324/1600] D loss: 0.0204, G loss: 5.0335\n",
      "[1444/1600] D loss: 0.0374, G loss: 4.7132\n",
      "[1564/1600] D loss: 0.0215, G loss: 7.1402\n",
      "train error: \n",
      " D loss: 0.050466, G loss: 5.318691, D accuracy: 99.8%, cell accuracy: 81.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.057765, G loss: 5.405626, D accuracy: 99.6%, cell accuracy: 81.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0395, G loss: 6.0846\n",
      "[124/1600] D loss: 0.0008, G loss: 8.4481\n",
      "[244/1600] D loss: 0.0195, G loss: 4.9613\n",
      "[364/1600] D loss: 0.2966, G loss: 10.0113\n",
      "[484/1600] D loss: 0.0103, G loss: 5.3268\n",
      "[604/1600] D loss: 0.0821, G loss: 3.1372\n",
      "[724/1600] D loss: 0.0051, G loss: 6.5176\n",
      "[844/1600] D loss: 0.0362, G loss: 5.3118\n",
      "[964/1600] D loss: 0.0188, G loss: 5.8430\n",
      "[1084/1600] D loss: 0.0100, G loss: 9.7378\n",
      "[1204/1600] D loss: 0.0842, G loss: 5.5052\n",
      "[1324/1600] D loss: 0.0424, G loss: 5.1654\n",
      "[1444/1600] D loss: 0.0935, G loss: 4.1370\n",
      "[1564/1600] D loss: 0.2996, G loss: 8.1217\n",
      "train error: \n",
      " D loss: 0.169433, G loss: 5.233215, D accuracy: 96.6%, cell accuracy: 81.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.202034, G loss: 5.180718, D accuracy: 96.4%, cell accuracy: 81.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0019, G loss: 7.6778\n",
      "[124/1600] D loss: 0.0017, G loss: 7.0949\n",
      "[244/1600] D loss: 0.3105, G loss: 5.7087\n",
      "[364/1600] D loss: 0.5396, G loss: 4.6411\n",
      "[484/1600] D loss: 0.3401, G loss: 2.7294\n",
      "[604/1600] D loss: 0.0580, G loss: 3.8406\n",
      "[724/1600] D loss: 0.0213, G loss: 6.8574\n",
      "[844/1600] D loss: 0.0314, G loss: 7.0437\n",
      "[964/1600] D loss: 0.2231, G loss: 3.8193\n",
      "[1084/1600] D loss: 0.0956, G loss: 5.2551\n",
      "[1204/1600] D loss: 0.0080, G loss: 8.5628\n",
      "[1324/1600] D loss: 0.1516, G loss: 4.6044\n",
      "[1444/1600] D loss: 0.0176, G loss: 4.5165\n",
      "[1564/1600] D loss: 0.0415, G loss: 3.5543\n",
      "train error: \n",
      " D loss: 0.092494, G loss: 5.657385, D accuracy: 98.7%, cell accuracy: 82.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.115610, G loss: 5.605938, D accuracy: 98.0%, cell accuracy: 82.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0272, G loss: 5.1820\n",
      "[124/1600] D loss: 0.0112, G loss: 6.4601\n",
      "[244/1600] D loss: 0.0566, G loss: 3.4712\n",
      "[364/1600] D loss: 0.1368, G loss: 3.9241\n",
      "[484/1600] D loss: 0.1613, G loss: 3.0606\n",
      "[604/1600] D loss: 0.0080, G loss: 5.5406\n",
      "[724/1600] D loss: 0.3288, G loss: 4.3124\n",
      "[844/1600] D loss: 0.0017, G loss: 8.1722\n",
      "[964/1600] D loss: 0.0167, G loss: 6.2917\n",
      "[1084/1600] D loss: 0.0698, G loss: 3.4724\n",
      "[1204/1600] D loss: 0.3679, G loss: 7.2970\n",
      "[1324/1600] D loss: 0.2663, G loss: 6.5716\n",
      "[1444/1600] D loss: 0.1940, G loss: 3.2957\n",
      "[1564/1600] D loss: 0.1069, G loss: 3.5955\n",
      "train error: \n",
      " D loss: 0.086006, G loss: 5.203485, D accuracy: 98.9%, cell accuracy: 82.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.094513, G loss: 5.204443, D accuracy: 99.1%, cell accuracy: 82.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0674, G loss: 4.3476\n",
      "[124/1600] D loss: 0.0047, G loss: 8.3812\n",
      "[244/1600] D loss: 0.0282, G loss: 5.0474\n",
      "[364/1600] D loss: 0.1021, G loss: 4.1702\n",
      "[484/1600] D loss: 0.0400, G loss: 7.0983\n",
      "[604/1600] D loss: 0.1271, G loss: 6.3460\n",
      "[724/1600] D loss: 0.1886, G loss: 3.5122\n",
      "[844/1600] D loss: 0.0020, G loss: 8.1880\n",
      "[964/1600] D loss: 0.1258, G loss: 4.8795\n",
      "[1084/1600] D loss: 0.0230, G loss: 6.2163\n",
      "[1204/1600] D loss: 0.0729, G loss: 5.8165\n",
      "[1324/1600] D loss: 0.0093, G loss: 8.5138\n",
      "[1444/1600] D loss: 0.0073, G loss: 8.6357\n",
      "[1564/1600] D loss: 0.2270, G loss: 3.1548\n",
      "train error: \n",
      " D loss: 0.100155, G loss: 6.676581, D accuracy: 98.5%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.126587, G loss: 6.687191, D accuracy: 97.8%, cell accuracy: 82.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0847, G loss: 7.6085\n",
      "[124/1600] D loss: 0.1745, G loss: 6.6347\n",
      "[244/1600] D loss: 0.0216, G loss: 7.1814\n",
      "[364/1600] D loss: 0.3087, G loss: 4.3658\n",
      "[484/1600] D loss: 0.0313, G loss: 5.6083\n",
      "[604/1600] D loss: 0.0479, G loss: 5.7182\n",
      "[724/1600] D loss: 0.0090, G loss: 5.8254\n",
      "[844/1600] D loss: 0.0090, G loss: 7.9439\n",
      "[964/1600] D loss: 0.0080, G loss: 8.1981\n",
      "[1084/1600] D loss: 0.0436, G loss: 4.9525\n",
      "[1204/1600] D loss: 0.0045, G loss: 9.9202\n",
      "[1324/1600] D loss: 0.3084, G loss: 2.6127\n",
      "[1444/1600] D loss: 0.0137, G loss: 5.7306\n",
      "[1564/1600] D loss: 0.0010, G loss: 8.9615\n",
      "train error: \n",
      " D loss: 0.083588, G loss: 6.056780, D accuracy: 99.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.113487, G loss: 6.032145, D accuracy: 98.0%, cell accuracy: 82.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0071, G loss: 7.4180\n",
      "[124/1600] D loss: 0.0114, G loss: 7.3377\n",
      "[244/1600] D loss: 0.0019, G loss: 8.1030\n",
      "[364/1600] D loss: 0.0421, G loss: 5.7989\n",
      "[484/1600] D loss: 0.0139, G loss: 4.9434\n",
      "[604/1600] D loss: 0.0314, G loss: 4.2610\n",
      "[724/1600] D loss: 0.2593, G loss: 4.7598\n",
      "[844/1600] D loss: 0.1533, G loss: 6.0966\n",
      "[964/1600] D loss: 0.8547, G loss: 5.6521\n",
      "[1084/1600] D loss: 0.1110, G loss: 5.6097\n",
      "[1204/1600] D loss: 0.3344, G loss: 6.8404\n",
      "[1324/1600] D loss: 0.6511, G loss: 4.7466\n",
      "[1444/1600] D loss: 0.0468, G loss: 7.4381\n",
      "[1564/1600] D loss: 0.2945, G loss: 3.2784\n",
      "train error: \n",
      " D loss: 0.216471, G loss: 5.473980, D accuracy: 96.7%, cell accuracy: 82.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.240259, G loss: 5.544296, D accuracy: 96.1%, cell accuracy: 82.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0404, G loss: 5.7875\n",
      "[124/1600] D loss: 0.1473, G loss: 5.8825\n",
      "[244/1600] D loss: 0.1038, G loss: 5.7021\n",
      "[364/1600] D loss: 0.1069, G loss: 3.6976\n",
      "[484/1600] D loss: 0.0708, G loss: 3.9479\n",
      "[604/1600] D loss: 0.1477, G loss: 4.5371\n",
      "[724/1600] D loss: 0.3559, G loss: 3.5321\n",
      "[844/1600] D loss: 0.0407, G loss: 7.2115\n",
      "[964/1600] D loss: 0.0161, G loss: 5.5158\n",
      "[1084/1600] D loss: 0.5148, G loss: 4.7038\n",
      "[1204/1600] D loss: 0.1088, G loss: 5.7789\n",
      "[1324/1600] D loss: 0.0238, G loss: 6.9205\n",
      "[1444/1600] D loss: 0.0236, G loss: 7.8058\n",
      "[1564/1600] D loss: 0.1439, G loss: 4.7283\n",
      "train error: \n",
      " D loss: 0.130460, G loss: 5.081116, D accuracy: 98.0%, cell accuracy: 81.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.145946, G loss: 5.107365, D accuracy: 97.9%, cell accuracy: 81.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4260, G loss: 3.7645\n",
      "[124/1600] D loss: 0.0115, G loss: 7.0274\n",
      "[244/1600] D loss: 0.0984, G loss: 4.9354\n",
      "[364/1600] D loss: 0.0189, G loss: 5.6746\n",
      "[484/1600] D loss: 0.0576, G loss: 5.4260\n",
      "[604/1600] D loss: 0.0945, G loss: 6.5848\n",
      "[724/1600] D loss: 0.0056, G loss: 6.2310\n",
      "[844/1600] D loss: 0.2337, G loss: 3.2322\n",
      "[964/1600] D loss: 0.0493, G loss: 7.3673\n",
      "[1084/1600] D loss: 0.0140, G loss: 6.9190\n",
      "[1204/1600] D loss: 0.0158, G loss: 11.2676\n",
      "[1324/1600] D loss: 0.0552, G loss: 4.5518\n",
      "[1444/1600] D loss: 0.0783, G loss: 4.0555\n",
      "[1564/1600] D loss: 0.0123, G loss: 7.9871\n",
      "train error: \n",
      " D loss: 0.113420, G loss: 5.616497, D accuracy: 98.3%, cell accuracy: 82.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.132152, G loss: 5.723485, D accuracy: 97.2%, cell accuracy: 82.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0501, G loss: 5.2405\n",
      "[124/1600] D loss: 0.1775, G loss: 6.5419\n",
      "[244/1600] D loss: 0.1015, G loss: 4.9277\n",
      "[364/1600] D loss: 0.0379, G loss: 4.7424\n",
      "[484/1600] D loss: 0.0007, G loss: 9.2983\n",
      "[604/1600] D loss: 0.0754, G loss: 5.0000\n",
      "[724/1600] D loss: 0.0061, G loss: 8.3414\n",
      "[844/1600] D loss: 0.6890, G loss: 5.7260\n",
      "[964/1600] D loss: 0.0966, G loss: 9.1561\n",
      "[1084/1600] D loss: 0.0392, G loss: 6.4033\n",
      "[1204/1600] D loss: 0.0815, G loss: 5.5213\n",
      "[1324/1600] D loss: 0.0018, G loss: 8.4248\n",
      "[1444/1600] D loss: 0.0612, G loss: 6.7474\n",
      "[1564/1600] D loss: 0.1375, G loss: 7.9795\n",
      "train error: \n",
      " D loss: 0.114936, G loss: 6.461216, D accuracy: 98.5%, cell accuracy: 82.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.137998, G loss: 6.522337, D accuracy: 98.1%, cell accuracy: 82.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0201, G loss: 5.1588\n",
      "[124/1600] D loss: 0.0995, G loss: 5.5425\n",
      "[244/1600] D loss: 0.3276, G loss: 5.1252\n",
      "[364/1600] D loss: 0.0086, G loss: 8.3930\n",
      "[484/1600] D loss: 0.2497, G loss: 7.4009\n",
      "[604/1600] D loss: 0.0362, G loss: 6.1786\n",
      "[724/1600] D loss: 0.0226, G loss: 7.2471\n",
      "[844/1600] D loss: 0.1913, G loss: 5.7773\n",
      "[964/1600] D loss: 0.1453, G loss: 5.6661\n",
      "[1084/1600] D loss: 0.2255, G loss: 6.0520\n",
      "[1204/1600] D loss: 0.1849, G loss: 5.9761\n",
      "[1324/1600] D loss: 0.5452, G loss: 3.5880\n",
      "[1444/1600] D loss: 0.0011, G loss: 8.7729\n",
      "[1564/1600] D loss: 0.0017, G loss: 9.9269\n",
      "train error: \n",
      " D loss: 0.125773, G loss: 5.831837, D accuracy: 97.8%, cell accuracy: 84.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.139493, G loss: 5.938930, D accuracy: 97.8%, cell accuracy: 84.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0182, G loss: 5.1131\n",
      "[124/1600] D loss: 0.0020, G loss: 7.4302\n",
      "[244/1600] D loss: 0.1366, G loss: 3.7276\n",
      "[364/1600] D loss: 0.0232, G loss: 6.4739\n",
      "[484/1600] D loss: 0.1571, G loss: 3.6010\n",
      "[604/1600] D loss: 0.0597, G loss: 6.6938\n",
      "[724/1600] D loss: 0.0021, G loss: 8.8233\n",
      "[844/1600] D loss: 0.0304, G loss: 8.0840\n",
      "[964/1600] D loss: 0.0095, G loss: 6.7803\n",
      "[1084/1600] D loss: 0.0214, G loss: 6.9192\n",
      "[1204/1600] D loss: 0.0016, G loss: 8.0100\n",
      "[1324/1600] D loss: 0.0526, G loss: 4.3390\n",
      "[1444/1600] D loss: 0.0005, G loss: 9.5698\n",
      "[1564/1600] D loss: 0.0366, G loss: 9.6946\n",
      "train error: \n",
      " D loss: 0.125766, G loss: 5.269862, D accuracy: 97.8%, cell accuracy: 84.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.133645, G loss: 5.329634, D accuracy: 98.2%, cell accuracy: 84.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0098, G loss: 5.7681\n",
      "[124/1600] D loss: 0.0157, G loss: 5.3843\n",
      "[244/1600] D loss: 0.0166, G loss: 6.4473\n",
      "[364/1600] D loss: 0.0037, G loss: 6.6711\n",
      "[484/1600] D loss: 0.1994, G loss: 4.4687\n",
      "[604/1600] D loss: 0.0142, G loss: 7.4895\n",
      "[724/1600] D loss: 0.2309, G loss: 5.9071\n",
      "[844/1600] D loss: 0.0095, G loss: 7.3353\n",
      "[964/1600] D loss: 0.0390, G loss: 10.4155\n",
      "[1084/1600] D loss: 0.0001, G loss: 10.8864\n",
      "[1204/1600] D loss: 0.0207, G loss: 4.5989\n",
      "[1324/1600] D loss: 0.0377, G loss: 8.9231\n",
      "[1444/1600] D loss: 0.4162, G loss: 6.3582\n",
      "[1564/1600] D loss: 0.0390, G loss: 4.5979\n",
      "train error: \n",
      " D loss: 0.094907, G loss: 6.475570, D accuracy: 98.8%, cell accuracy: 84.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.118690, G loss: 6.532587, D accuracy: 98.2%, cell accuracy: 84.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0157, G loss: 6.7588\n",
      "[124/1600] D loss: 0.1893, G loss: 4.6367\n",
      "[244/1600] D loss: 0.0018, G loss: 7.1298\n",
      "[364/1600] D loss: 0.1038, G loss: 6.5356\n",
      "[484/1600] D loss: 0.0022, G loss: 7.2780\n",
      "[604/1600] D loss: 0.0034, G loss: 9.7305\n",
      "[724/1600] D loss: 0.0905, G loss: 4.8607\n",
      "[844/1600] D loss: 0.0053, G loss: 9.3198\n",
      "[964/1600] D loss: 0.0158, G loss: 7.2134\n",
      "[1084/1600] D loss: 0.0016, G loss: 7.2156\n",
      "[1204/1600] D loss: 0.0061, G loss: 7.6542\n",
      "[1324/1600] D loss: 0.0049, G loss: 8.3025\n",
      "[1444/1600] D loss: 0.3216, G loss: 5.5144\n",
      "[1564/1600] D loss: 0.0408, G loss: 5.0686\n",
      "train error: \n",
      " D loss: 0.108370, G loss: 7.143147, D accuracy: 98.3%, cell accuracy: 85.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.136723, G loss: 7.187266, D accuracy: 98.1%, cell accuracy: 84.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0075, G loss: 9.6779\n",
      "[124/1600] D loss: 0.0270, G loss: 5.2317\n",
      "[244/1600] D loss: 0.0171, G loss: 7.0986\n",
      "[364/1600] D loss: 0.0107, G loss: 9.1948\n",
      "[484/1600] D loss: 0.0635, G loss: 7.8897\n",
      "[604/1600] D loss: 0.0345, G loss: 7.1249\n",
      "[724/1600] D loss: 0.0259, G loss: 5.7324\n",
      "[844/1600] D loss: 0.1122, G loss: 3.7958\n",
      "[964/1600] D loss: 0.1120, G loss: 4.0417\n",
      "[1084/1600] D loss: 0.3107, G loss: 6.4645\n",
      "[1204/1600] D loss: 0.2831, G loss: 5.9431\n",
      "[1324/1600] D loss: 0.1156, G loss: 8.4382\n",
      "[1444/1600] D loss: 0.2673, G loss: 7.5703\n",
      "[1564/1600] D loss: 0.0638, G loss: 8.0536\n",
      "train error: \n",
      " D loss: 0.146667, G loss: 5.505235, D accuracy: 97.0%, cell accuracy: 85.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.185239, G loss: 5.649367, D accuracy: 95.9%, cell accuracy: 84.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0367, G loss: 7.0322\n",
      "[124/1600] D loss: 0.0226, G loss: 7.5474\n",
      "[244/1600] D loss: 0.0008, G loss: 9.1278\n",
      "[364/1600] D loss: 0.0108, G loss: 6.2970\n",
      "[484/1600] D loss: 0.0207, G loss: 5.8337\n",
      "[604/1600] D loss: 0.0082, G loss: 6.1829\n",
      "[724/1600] D loss: 1.8065, G loss: 9.1348\n",
      "[844/1600] D loss: 0.0619, G loss: 6.5634\n",
      "[964/1600] D loss: 0.2004, G loss: 7.2884\n",
      "[1084/1600] D loss: 0.0063, G loss: 7.1543\n",
      "[1204/1600] D loss: 0.0000, G loss: 11.9815\n",
      "[1324/1600] D loss: 0.0275, G loss: 7.8861\n",
      "[1444/1600] D loss: 0.4096, G loss: 2.3053\n",
      "[1564/1600] D loss: 0.0002, G loss: 10.4064\n",
      "train error: \n",
      " D loss: 0.099743, G loss: 7.007165, D accuracy: 98.7%, cell accuracy: 85.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.124584, G loss: 7.154133, D accuracy: 98.2%, cell accuracy: 84.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0027, G loss: 9.3450\n",
      "[124/1600] D loss: 0.0115, G loss: 5.3104\n",
      "[244/1600] D loss: 0.0948, G loss: 5.8258\n",
      "[364/1600] D loss: 1.1305, G loss: 3.3112\n",
      "[484/1600] D loss: 0.0045, G loss: 6.8408\n",
      "[604/1600] D loss: 0.0540, G loss: 6.6195\n",
      "[724/1600] D loss: 0.0053, G loss: 6.0004\n",
      "[844/1600] D loss: 0.0119, G loss: 8.2917\n",
      "[964/1600] D loss: 0.0014, G loss: 10.1472\n",
      "[1084/1600] D loss: 0.1818, G loss: 4.7126\n",
      "[1204/1600] D loss: 0.0042, G loss: 8.9332\n",
      "[1324/1600] D loss: 0.3462, G loss: 9.3687\n",
      "[1444/1600] D loss: 0.0471, G loss: 6.7695\n",
      "[1564/1600] D loss: 0.0170, G loss: 10.7005\n",
      "train error: \n",
      " D loss: 0.097230, G loss: 6.841554, D accuracy: 98.6%, cell accuracy: 85.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.129080, G loss: 6.984174, D accuracy: 97.9%, cell accuracy: 84.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0132, G loss: 6.4508\n",
      "[124/1600] D loss: 0.1573, G loss: 4.0668\n",
      "[244/1600] D loss: 0.0127, G loss: 8.1199\n",
      "[364/1600] D loss: 0.1253, G loss: 5.3149\n",
      "[484/1600] D loss: 0.0021, G loss: 8.7513\n",
      "[604/1600] D loss: 0.0496, G loss: 4.6330\n",
      "[724/1600] D loss: 0.0010, G loss: 12.3740\n",
      "[844/1600] D loss: 0.0989, G loss: 6.0818\n",
      "[964/1600] D loss: 0.1842, G loss: 6.4100\n",
      "[1084/1600] D loss: 0.0297, G loss: 6.4328\n",
      "[1204/1600] D loss: 0.0054, G loss: 7.6214\n",
      "[1324/1600] D loss: 0.0027, G loss: 9.2138\n",
      "[1444/1600] D loss: 0.3038, G loss: 6.2832\n",
      "[1564/1600] D loss: 0.0622, G loss: 7.1288\n",
      "train error: \n",
      " D loss: 0.118202, G loss: 7.618655, D accuracy: 98.2%, cell accuracy: 85.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.163792, G loss: 7.716718, D accuracy: 97.6%, cell accuracy: 85.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0153, G loss: 7.8361\n",
      "[124/1600] D loss: 0.0198, G loss: 10.1950\n",
      "[244/1600] D loss: 0.0974, G loss: 8.3174\n",
      "[364/1600] D loss: 0.0006, G loss: 8.4395\n",
      "[484/1600] D loss: 0.1855, G loss: 7.1706\n",
      "[604/1600] D loss: 1.3491, G loss: 8.3088\n",
      "[724/1600] D loss: 0.2788, G loss: 3.1378\n",
      "[844/1600] D loss: 0.1273, G loss: 4.5291\n",
      "[964/1600] D loss: 0.0739, G loss: 8.4407\n",
      "[1084/1600] D loss: 1.0256, G loss: 3.9752\n",
      "[1204/1600] D loss: 0.7402, G loss: 1.6850\n",
      "[1324/1600] D loss: 0.0008, G loss: 10.0641\n",
      "[1444/1600] D loss: 0.4706, G loss: 4.6988\n",
      "[1564/1600] D loss: 0.2066, G loss: 8.0996\n",
      "train error: \n",
      " D loss: 0.367085, G loss: 7.743118, D accuracy: 91.4%, cell accuracy: 85.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.402726, G loss: 7.861141, D accuracy: 90.4%, cell accuracy: 85.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2427, G loss: 8.4087\n",
      "[124/1600] D loss: 0.4931, G loss: 5.9350\n",
      "[244/1600] D loss: 0.0015, G loss: 8.9048\n",
      "[364/1600] D loss: 0.3988, G loss: 6.0786\n",
      "[484/1600] D loss: 0.2437, G loss: 9.8512\n",
      "[604/1600] D loss: 0.2173, G loss: 6.7027\n",
      "[724/1600] D loss: 0.0881, G loss: 8.6972\n",
      "[844/1600] D loss: 0.3106, G loss: 6.0951\n",
      "[964/1600] D loss: 0.0071, G loss: 10.1096\n",
      "[1084/1600] D loss: 0.0002, G loss: 10.9356\n",
      "[1204/1600] D loss: 0.2702, G loss: 8.2489\n",
      "[1324/1600] D loss: 0.3752, G loss: 4.0365\n",
      "[1444/1600] D loss: 0.1191, G loss: 4.9350\n",
      "[1564/1600] D loss: 0.0001, G loss: 10.1723\n",
      "train error: \n",
      " D loss: 0.308679, G loss: 6.970913, D accuracy: 93.3%, cell accuracy: 85.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.325303, G loss: 7.030194, D accuracy: 93.6%, cell accuracy: 85.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2490, G loss: 6.0668\n",
      "[124/1600] D loss: 0.0017, G loss: 8.2647\n",
      "[244/1600] D loss: 0.2471, G loss: 8.7243\n",
      "[364/1600] D loss: 0.3526, G loss: 8.0044\n",
      "[484/1600] D loss: 0.0025, G loss: 9.6332\n",
      "[604/1600] D loss: 0.2768, G loss: 8.5597\n",
      "[724/1600] D loss: 0.2453, G loss: 9.4186\n",
      "[844/1600] D loss: 0.1717, G loss: 4.8715\n",
      "[964/1600] D loss: 1.2556, G loss: 6.8007\n",
      "[1084/1600] D loss: 0.0022, G loss: 8.2429\n",
      "[1204/1600] D loss: 0.0246, G loss: 8.4040\n",
      "[1324/1600] D loss: 0.1026, G loss: 9.5774\n",
      "[1444/1600] D loss: 0.2653, G loss: 5.8959\n",
      "[1564/1600] D loss: 0.0899, G loss: 9.1633\n",
      "train error: \n",
      " D loss: 0.352958, G loss: 7.469687, D accuracy: 92.2%, cell accuracy: 86.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.377936, G loss: 7.563238, D accuracy: 90.6%, cell accuracy: 85.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9376, G loss: 4.6312\n",
      "[124/1600] D loss: 0.3553, G loss: 7.7983\n",
      "[244/1600] D loss: 0.3836, G loss: 6.2842\n",
      "[364/1600] D loss: 0.4344, G loss: 5.3438\n",
      "[484/1600] D loss: 0.2317, G loss: 7.8775\n",
      "[604/1600] D loss: 0.0002, G loss: 10.1662\n",
      "[724/1600] D loss: 0.2062, G loss: 6.9352\n",
      "[844/1600] D loss: 0.3500, G loss: 2.2184\n",
      "[964/1600] D loss: 0.5349, G loss: 5.2270\n",
      "[1084/1600] D loss: 0.2763, G loss: 7.8297\n",
      "[1204/1600] D loss: 0.0058, G loss: 10.2964\n",
      "[1324/1600] D loss: 0.0601, G loss: 6.7875\n",
      "[1444/1600] D loss: 0.5511, G loss: 4.2385\n",
      "[1564/1600] D loss: 0.5487, G loss: 5.1322\n",
      "train error: \n",
      " D loss: 0.317896, G loss: 6.690200, D accuracy: 93.3%, cell accuracy: 86.1%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.333075, G loss: 6.772405, D accuracy: 92.6%, cell accuracy: 85.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6560, G loss: 6.6829\n",
      "[124/1600] D loss: 0.0802, G loss: 8.8158\n",
      "[244/1600] D loss: 0.0362, G loss: 6.2946\n",
      "[364/1600] D loss: 0.0003, G loss: 9.6542\n",
      "[484/1600] D loss: 0.0001, G loss: 10.5312\n",
      "[604/1600] D loss: 0.0947, G loss: 7.7171\n",
      "[724/1600] D loss: 0.9733, G loss: 6.8720\n",
      "[844/1600] D loss: 0.0179, G loss: 9.2534\n",
      "[964/1600] D loss: 0.2108, G loss: 6.2291\n",
      "[1084/1600] D loss: 0.5618, G loss: 3.6017\n",
      "[1204/1600] D loss: 0.0000, G loss: 11.4389\n",
      "[1324/1600] D loss: 0.5335, G loss: 5.8821\n",
      "[1444/1600] D loss: 0.1264, G loss: 10.0561\n",
      "[1564/1600] D loss: 0.3633, G loss: 6.8162\n",
      "train error: \n",
      " D loss: 0.340115, G loss: 7.330465, D accuracy: 92.3%, cell accuracy: 86.4%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.371948, G loss: 7.432797, D accuracy: 91.5%, cell accuracy: 86.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0720, G loss: 8.3165\n",
      "[124/1600] D loss: 1.7852, G loss: 2.7343\n",
      "[244/1600] D loss: 0.0382, G loss: 8.1512\n",
      "[364/1600] D loss: 0.4709, G loss: 5.8361\n",
      "[484/1600] D loss: 0.3616, G loss: 5.8099\n",
      "[604/1600] D loss: 0.5509, G loss: 6.1618\n",
      "[724/1600] D loss: 0.2737, G loss: 5.6702\n",
      "[844/1600] D loss: 0.0445, G loss: 9.3274\n",
      "[964/1600] D loss: 0.5143, G loss: 8.7732\n",
      "[1084/1600] D loss: 0.5211, G loss: 4.9364\n",
      "[1204/1600] D loss: 0.2294, G loss: 7.2543\n",
      "[1324/1600] D loss: 0.3366, G loss: 3.7098\n",
      "[1444/1600] D loss: 2.9640, G loss: 7.8336\n",
      "[1564/1600] D loss: 0.3226, G loss: 4.4559\n",
      "train error: \n",
      " D loss: 0.403070, G loss: 5.669429, D accuracy: 89.0%, cell accuracy: 86.5%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.417641, G loss: 5.754597, D accuracy: 90.4%, cell accuracy: 86.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5075, G loss: 5.9594\n",
      "[124/1600] D loss: 0.2979, G loss: 5.2608\n",
      "[244/1600] D loss: 0.2622, G loss: 8.3680\n",
      "[364/1600] D loss: 0.0004, G loss: 8.8839\n",
      "[484/1600] D loss: 0.0003, G loss: 8.7790\n",
      "[604/1600] D loss: 0.6185, G loss: 4.2771\n",
      "[724/1600] D loss: 1.7921, G loss: 10.5952\n",
      "[844/1600] D loss: 0.2581, G loss: 7.4884\n",
      "[964/1600] D loss: 0.7643, G loss: 2.7613\n",
      "[1084/1600] D loss: 0.3366, G loss: 7.0321\n",
      "[1204/1600] D loss: 0.5590, G loss: 3.7271\n",
      "[1324/1600] D loss: 0.0102, G loss: 10.0151\n",
      "[1444/1600] D loss: 1.0921, G loss: 5.5619\n",
      "[1564/1600] D loss: 0.3731, G loss: 7.0859\n",
      "train error: \n",
      " D loss: 0.333305, G loss: 6.832962, D accuracy: 92.8%, cell accuracy: 86.5%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.360468, G loss: 6.906608, D accuracy: 91.8%, cell accuracy: 86.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5464, G loss: 5.7782\n",
      "[124/1600] D loss: 0.5203, G loss: 4.9814\n",
      "[244/1600] D loss: 0.0057, G loss: 7.4019\n",
      "[364/1600] D loss: 0.1108, G loss: 10.1765\n",
      "[484/1600] D loss: 0.7499, G loss: 6.3944\n",
      "[604/1600] D loss: 0.1889, G loss: 5.4635\n",
      "[724/1600] D loss: 0.3599, G loss: 5.2061\n",
      "[844/1600] D loss: 0.0599, G loss: 9.2354\n",
      "[964/1600] D loss: 0.0002, G loss: 10.4814\n",
      "[1084/1600] D loss: 0.6256, G loss: 3.9575\n",
      "[1204/1600] D loss: 0.2235, G loss: 5.0170\n",
      "[1324/1600] D loss: 0.0080, G loss: 5.5468\n",
      "[1444/1600] D loss: 0.0016, G loss: 8.5558\n",
      "[1564/1600] D loss: 0.3992, G loss: 4.4629\n",
      "train error: \n",
      " D loss: 0.356453, G loss: 6.881167, D accuracy: 91.3%, cell accuracy: 86.5%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.376458, G loss: 6.956370, D accuracy: 90.9%, cell accuracy: 86.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3703, G loss: 4.9113\n",
      "[124/1600] D loss: 0.8760, G loss: 2.3304\n",
      "[244/1600] D loss: 0.1244, G loss: 6.0219\n",
      "[364/1600] D loss: 0.2644, G loss: 7.8741\n",
      "[484/1600] D loss: 0.0016, G loss: 8.7444\n",
      "[604/1600] D loss: 0.6841, G loss: 6.0879\n",
      "[724/1600] D loss: 0.5034, G loss: 6.3480\n",
      "[844/1600] D loss: 0.1803, G loss: 8.7060\n",
      "[964/1600] D loss: 0.0372, G loss: 7.2813\n",
      "[1084/1600] D loss: 0.3292, G loss: 5.0793\n",
      "[1204/1600] D loss: 0.0312, G loss: 8.5401\n",
      "[1324/1600] D loss: 0.5125, G loss: 4.8645\n",
      "[1444/1600] D loss: 0.0005, G loss: 9.8084\n",
      "[1564/1600] D loss: 0.0006, G loss: 8.3297\n",
      "train error: \n",
      " D loss: 0.341823, G loss: 6.702889, D accuracy: 92.2%, cell accuracy: 86.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.384528, G loss: 6.770853, D accuracy: 90.8%, cell accuracy: 86.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4105, G loss: 5.9787\n",
      "[124/1600] D loss: 0.6311, G loss: 2.5845\n",
      "[244/1600] D loss: 0.2375, G loss: 6.3280\n",
      "[364/1600] D loss: 0.0342, G loss: 7.1434\n",
      "[484/1600] D loss: 0.0214, G loss: 8.0447\n",
      "[604/1600] D loss: 0.2445, G loss: 7.7927\n",
      "[724/1600] D loss: 0.8306, G loss: 2.8216\n",
      "[844/1600] D loss: 0.1742, G loss: 4.2950\n",
      "[964/1600] D loss: 0.0002, G loss: 9.1238\n",
      "[1084/1600] D loss: 0.0032, G loss: 6.6265\n",
      "[1204/1600] D loss: 0.6447, G loss: 4.7545\n",
      "[1324/1600] D loss: 0.4935, G loss: 8.2463\n",
      "[1444/1600] D loss: 0.4706, G loss: 5.3001\n",
      "[1564/1600] D loss: 0.0002, G loss: 9.2671\n",
      "train error: \n",
      " D loss: 0.376922, G loss: 6.029171, D accuracy: 90.5%, cell accuracy: 86.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.397174, G loss: 6.096159, D accuracy: 89.8%, cell accuracy: 86.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0002, G loss: 9.5856\n",
      "[124/1600] D loss: 0.1612, G loss: 4.2528\n",
      "[244/1600] D loss: 0.2698, G loss: 6.4548\n",
      "[364/1600] D loss: 0.0001, G loss: 11.2894\n",
      "[484/1600] D loss: 1.2772, G loss: 7.6660\n",
      "[604/1600] D loss: 0.0445, G loss: 6.7401\n",
      "[724/1600] D loss: 1.2254, G loss: 2.9251\n",
      "[844/1600] D loss: 1.3011, G loss: 3.4229\n",
      "[964/1600] D loss: 0.5383, G loss: 4.5461\n",
      "[1084/1600] D loss: 0.0831, G loss: 5.3164\n",
      "[1204/1600] D loss: 0.3006, G loss: 5.8241\n",
      "[1324/1600] D loss: 0.1474, G loss: 4.8598\n",
      "[1444/1600] D loss: 0.0091, G loss: 9.0450\n",
      "[1564/1600] D loss: 0.0007, G loss: 8.8158\n",
      "train error: \n",
      " D loss: 0.391401, G loss: 5.642066, D accuracy: 89.7%, cell accuracy: 86.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.428137, G loss: 5.755572, D accuracy: 88.8%, cell accuracy: 86.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1300, G loss: 7.4056\n",
      "[124/1600] D loss: 0.4439, G loss: 6.0332\n",
      "[244/1600] D loss: 0.6033, G loss: 4.8601\n",
      "[364/1600] D loss: 0.3357, G loss: 6.2173\n",
      "[484/1600] D loss: 0.4808, G loss: 5.3604\n",
      "[604/1600] D loss: 1.0650, G loss: 2.0759\n",
      "[724/1600] D loss: 1.0572, G loss: 7.2713\n",
      "[844/1600] D loss: 0.9695, G loss: 5.3481\n",
      "[964/1600] D loss: 0.2057, G loss: 5.0343\n",
      "[1084/1600] D loss: 0.2648, G loss: 3.1247\n",
      "[1204/1600] D loss: 0.3751, G loss: 4.7887\n",
      "[1324/1600] D loss: 0.3857, G loss: 3.2836\n",
      "[1444/1600] D loss: 0.3216, G loss: 5.2309\n",
      "[1564/1600] D loss: 0.7616, G loss: 5.0555\n",
      "train error: \n",
      " D loss: 0.373173, G loss: 5.992288, D accuracy: 90.8%, cell accuracy: 86.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.413733, G loss: 6.035158, D accuracy: 89.0%, cell accuracy: 86.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3387, G loss: 7.8232\n",
      "[124/1600] D loss: 0.3459, G loss: 5.2047\n",
      "[244/1600] D loss: 0.0004, G loss: 9.0556\n",
      "[364/1600] D loss: 0.4998, G loss: 7.3022\n",
      "[484/1600] D loss: 0.9017, G loss: 2.4267\n",
      "[604/1600] D loss: 0.9393, G loss: 3.8515\n",
      "[724/1600] D loss: 0.0003, G loss: 8.5108\n",
      "[844/1600] D loss: 0.0002, G loss: 10.1247\n",
      "[964/1600] D loss: 0.2407, G loss: 8.1291\n",
      "[1084/1600] D loss: 0.4859, G loss: 4.8158\n",
      "[1204/1600] D loss: 0.2047, G loss: 5.6655\n",
      "[1324/1600] D loss: 0.2564, G loss: 3.9641\n",
      "[1444/1600] D loss: 0.1050, G loss: 5.8316\n",
      "[1564/1600] D loss: 0.6871, G loss: 5.1310\n",
      "train error: \n",
      " D loss: 0.379376, G loss: 5.572026, D accuracy: 89.6%, cell accuracy: 86.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.412582, G loss: 5.671723, D accuracy: 88.9%, cell accuracy: 86.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0735, G loss: 8.2103\n",
      "[124/1600] D loss: 0.3865, G loss: 7.9135\n",
      "[244/1600] D loss: 0.8488, G loss: 4.7847\n",
      "[364/1600] D loss: 0.0017, G loss: 7.8202\n",
      "[484/1600] D loss: 0.0009, G loss: 7.3575\n",
      "[604/1600] D loss: 0.0135, G loss: 8.1050\n",
      "[724/1600] D loss: 0.1231, G loss: 7.6795\n",
      "[844/1600] D loss: 0.1125, G loss: 7.5864\n",
      "[964/1600] D loss: 0.7935, G loss: 5.5134\n",
      "[1084/1600] D loss: 0.7436, G loss: 4.7330\n",
      "[1204/1600] D loss: 0.5122, G loss: 5.8712\n",
      "[1324/1600] D loss: 0.3737, G loss: 4.8745\n",
      "[1444/1600] D loss: 0.1545, G loss: 4.1739\n",
      "[1564/1600] D loss: 0.4761, G loss: 6.2978\n",
      "train error: \n",
      " D loss: 0.380882, G loss: 5.960086, D accuracy: 90.0%, cell accuracy: 86.7%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.414367, G loss: 6.068620, D accuracy: 89.2%, cell accuracy: 86.4%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4769, G loss: 3.7342\n",
      "[124/1600] D loss: 0.5163, G loss: 4.9139\n",
      "[244/1600] D loss: 1.2726, G loss: 4.5992\n",
      "[364/1600] D loss: 0.7997, G loss: 1.9626\n",
      "[484/1600] D loss: 0.6120, G loss: 6.0951\n",
      "[604/1600] D loss: 0.5827, G loss: 5.0957\n",
      "[724/1600] D loss: 0.3587, G loss: 8.3152\n",
      "[844/1600] D loss: 0.0053, G loss: 7.2560\n",
      "[964/1600] D loss: 0.6981, G loss: 7.4464\n",
      "[1084/1600] D loss: 0.4201, G loss: 2.3417\n",
      "[1204/1600] D loss: 0.7643, G loss: 2.2685\n",
      "[1324/1600] D loss: 0.3528, G loss: 4.8007\n",
      "[1444/1600] D loss: 0.0003, G loss: 10.3520\n",
      "[1564/1600] D loss: 0.1455, G loss: 7.2909\n",
      "train error: \n",
      " D loss: 0.389431, G loss: 6.280484, D accuracy: 90.2%, cell accuracy: 86.7%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.422136, G loss: 6.342421, D accuracy: 88.9%, cell accuracy: 86.4%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3357, G loss: 6.0963\n",
      "[124/1600] D loss: 0.5713, G loss: 4.0452\n",
      "[244/1600] D loss: 0.1836, G loss: 7.1458\n",
      "[364/1600] D loss: 0.5484, G loss: 4.2866\n",
      "[484/1600] D loss: 0.4281, G loss: 7.4047\n",
      "[604/1600] D loss: 0.8985, G loss: 2.7447\n",
      "[724/1600] D loss: 1.0117, G loss: 3.9953\n",
      "[844/1600] D loss: 0.2208, G loss: 5.9836\n",
      "[964/1600] D loss: 0.3253, G loss: 4.8374\n",
      "[1084/1600] D loss: 0.0001, G loss: 9.9697\n",
      "[1204/1600] D loss: 0.2417, G loss: 5.1405\n",
      "[1324/1600] D loss: 0.0050, G loss: 8.4659\n",
      "[1444/1600] D loss: 0.0860, G loss: 3.9370\n",
      "[1564/1600] D loss: 0.1035, G loss: 5.8988\n",
      "train error: \n",
      " D loss: 0.375732, G loss: 5.836795, D accuracy: 90.1%, cell accuracy: 86.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.415060, G loss: 5.895113, D accuracy: 88.5%, cell accuracy: 86.4%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3299, G loss: 5.0323\n",
      "[124/1600] D loss: 0.0793, G loss: 6.5040\n",
      "[244/1600] D loss: 0.5794, G loss: 5.8106\n",
      "[364/1600] D loss: 0.4832, G loss: 5.8519\n",
      "[484/1600] D loss: 0.6892, G loss: 5.8876\n",
      "[604/1600] D loss: 0.5776, G loss: 5.0377\n",
      "[724/1600] D loss: 0.0026, G loss: 7.7635\n",
      "[844/1600] D loss: 0.8430, G loss: 5.7719\n",
      "[964/1600] D loss: 0.4050, G loss: 5.6572\n",
      "[1084/1600] D loss: 0.0036, G loss: 8.4612\n",
      "[1204/1600] D loss: 0.0008, G loss: 7.4883\n",
      "[1324/1600] D loss: 0.3655, G loss: 3.9500\n",
      "[1444/1600] D loss: 0.4580, G loss: 8.6381\n",
      "[1564/1600] D loss: 0.0005, G loss: 10.6166\n",
      "train error: \n",
      " D loss: 0.394434, G loss: 6.423614, D accuracy: 89.6%, cell accuracy: 86.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.431780, G loss: 6.486223, D accuracy: 88.4%, cell accuracy: 86.4%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2304, G loss: 6.3758\n",
      "[124/1600] D loss: 0.5145, G loss: 5.8095\n",
      "[244/1600] D loss: 0.0032, G loss: 6.4118\n",
      "[364/1600] D loss: 0.3588, G loss: 5.5317\n",
      "[484/1600] D loss: 0.0087, G loss: 7.7073\n",
      "[604/1600] D loss: 0.0002, G loss: 9.6289\n",
      "[724/1600] D loss: 0.4107, G loss: 5.3978\n",
      "[844/1600] D loss: 0.3886, G loss: 7.3809\n",
      "[964/1600] D loss: 0.1953, G loss: 7.2494\n",
      "[1084/1600] D loss: 0.3202, G loss: 8.0010\n",
      "[1204/1600] D loss: 0.4249, G loss: 4.0266\n",
      "[1324/1600] D loss: 0.0420, G loss: 7.7304\n",
      "[1444/1600] D loss: 0.4509, G loss: 3.6587\n",
      "[1564/1600] D loss: 0.2391, G loss: 7.7473\n",
      "train error: \n",
      " D loss: 0.407746, G loss: 6.206212, D accuracy: 88.8%, cell accuracy: 86.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.443795, G loss: 6.274692, D accuracy: 88.2%, cell accuracy: 86.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0017, G loss: 8.5288\n",
      "[124/1600] D loss: 0.5525, G loss: 5.2875\n",
      "[244/1600] D loss: 0.4626, G loss: 6.3021\n",
      "[364/1600] D loss: 0.0124, G loss: 7.5037\n",
      "[484/1600] D loss: 0.1445, G loss: 4.8008\n",
      "[604/1600] D loss: 0.8513, G loss: 3.8066\n",
      "[724/1600] D loss: 0.0014, G loss: 8.0096\n",
      "[844/1600] D loss: 0.6845, G loss: 4.7351\n",
      "[964/1600] D loss: 0.7060, G loss: 2.6166\n",
      "[1084/1600] D loss: 0.4563, G loss: 5.8612\n",
      "[1204/1600] D loss: 0.0001, G loss: 9.8489\n",
      "[1324/1600] D loss: 0.3848, G loss: 5.5523\n",
      "[1444/1600] D loss: 0.7720, G loss: 3.0800\n",
      "[1564/1600] D loss: 0.9745, G loss: 3.6774\n",
      "train error: \n",
      " D loss: 0.377998, G loss: 6.036630, D accuracy: 90.0%, cell accuracy: 86.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.413822, G loss: 6.087262, D accuracy: 89.0%, cell accuracy: 86.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7209, G loss: 2.5753\n",
      "[124/1600] D loss: 0.3076, G loss: 5.5079\n",
      "[244/1600] D loss: 0.3348, G loss: 7.0465\n",
      "[364/1600] D loss: 0.0784, G loss: 7.4191\n",
      "[484/1600] D loss: 0.4465, G loss: 5.4715\n",
      "[604/1600] D loss: 0.4664, G loss: 7.6599\n",
      "[724/1600] D loss: 0.3614, G loss: 4.7473\n",
      "[844/1600] D loss: 0.6420, G loss: 3.1355\n",
      "[964/1600] D loss: 0.2293, G loss: 7.6267\n",
      "[1084/1600] D loss: 0.0025, G loss: 8.3194\n",
      "[1204/1600] D loss: 0.0010, G loss: 7.4903\n",
      "[1324/1600] D loss: 0.7960, G loss: 4.1839\n",
      "[1444/1600] D loss: 1.5489, G loss: 1.3802\n",
      "[1564/1600] D loss: 0.5040, G loss: 4.9632\n",
      "train error: \n",
      " D loss: 0.372992, G loss: 5.623176, D accuracy: 90.6%, cell accuracy: 86.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.395103, G loss: 5.653398, D accuracy: 88.9%, cell accuracy: 86.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4176, G loss: 4.5270\n",
      "[124/1600] D loss: 0.0147, G loss: 7.6791\n",
      "[244/1600] D loss: 0.8062, G loss: 2.5160\n",
      "[364/1600] D loss: 0.0702, G loss: 6.4158\n",
      "[484/1600] D loss: 0.5639, G loss: 3.3112\n",
      "[604/1600] D loss: 0.0017, G loss: 9.1391\n",
      "[724/1600] D loss: 0.8162, G loss: 2.8311\n",
      "[844/1600] D loss: 0.2999, G loss: 6.4756\n",
      "[964/1600] D loss: 0.8467, G loss: 2.3163\n",
      "[1084/1600] D loss: 0.5803, G loss: 5.4409\n",
      "[1204/1600] D loss: 0.3957, G loss: 3.2799\n",
      "[1324/1600] D loss: 0.7595, G loss: 3.7677\n",
      "[1444/1600] D loss: 0.4093, G loss: 3.0592\n",
      "[1564/1600] D loss: 0.3627, G loss: 7.0825\n",
      "train error: \n",
      " D loss: 0.376855, G loss: 6.020941, D accuracy: 89.2%, cell accuracy: 86.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.401444, G loss: 6.053322, D accuracy: 88.5%, cell accuracy: 86.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6886, G loss: 4.4156\n",
      "[124/1600] D loss: 0.0001, G loss: 9.4486\n",
      "[244/1600] D loss: 1.1459, G loss: 4.9814\n",
      "[364/1600] D loss: 0.9001, G loss: 4.4172\n",
      "[484/1600] D loss: 0.8618, G loss: 4.0935\n",
      "[604/1600] D loss: 0.0832, G loss: 7.4070\n",
      "[724/1600] D loss: 0.7661, G loss: 4.0216\n",
      "[844/1600] D loss: 0.3479, G loss: 5.5918\n",
      "[964/1600] D loss: 0.1484, G loss: 8.0287\n",
      "[1084/1600] D loss: 0.5455, G loss: 5.8864\n",
      "[1204/1600] D loss: 0.3669, G loss: 5.4324\n",
      "[1324/1600] D loss: 1.0785, G loss: 2.7345\n",
      "[1444/1600] D loss: 0.3833, G loss: 6.4363\n",
      "[1564/1600] D loss: 0.2618, G loss: 7.9383\n",
      "train error: \n",
      " D loss: 0.374059, G loss: 6.257914, D accuracy: 89.5%, cell accuracy: 86.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.404078, G loss: 6.289774, D accuracy: 89.4%, cell accuracy: 86.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7485, G loss: 4.5078\n",
      "[124/1600] D loss: 0.1735, G loss: 6.6921\n",
      "[244/1600] D loss: 0.3838, G loss: 7.7253\n",
      "[364/1600] D loss: 0.1364, G loss: 5.0537\n",
      "[484/1600] D loss: 0.4544, G loss: 5.9194\n",
      "[604/1600] D loss: 0.9801, G loss: 1.6778\n",
      "[724/1600] D loss: 0.0048, G loss: 7.6021\n",
      "[844/1600] D loss: 0.6572, G loss: 4.6230\n",
      "[964/1600] D loss: 0.0029, G loss: 6.9352\n",
      "[1084/1600] D loss: 0.0031, G loss: 7.7695\n",
      "[1204/1600] D loss: 2.4670, G loss: 4.8834\n",
      "[1324/1600] D loss: 2.9634, G loss: 0.2580\n",
      "[1444/1600] D loss: 3.6517, G loss: 0.1583\n",
      "[1564/1600] D loss: 2.6951, G loss: 0.2803\n",
      "train error: \n",
      " D loss: 2.324990, G loss: 0.439406, D accuracy: 16.1%, cell accuracy: 84.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.332252, G loss: 0.446606, D accuracy: 15.2%, cell accuracy: 83.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1600] D loss: 2.4194, G loss: 0.3279\n",
      "[124/1600] D loss: 1.8693, G loss: 0.5419\n",
      "[244/1600] D loss: 1.5447, G loss: 0.5674\n",
      "[364/1600] D loss: 1.3886, G loss: 0.7096\n",
      "[484/1600] D loss: 1.2840, G loss: 0.8701\n",
      "[604/1600] D loss: 1.0908, G loss: 0.9120\n",
      "[724/1600] D loss: 1.4756, G loss: 0.7211\n",
      "[844/1600] D loss: 1.2594, G loss: 0.9455\n",
      "[964/1600] D loss: 0.9656, G loss: 1.0711\n",
      "[1084/1600] D loss: 1.0074, G loss: 1.0362\n",
      "[1204/1600] D loss: 1.1899, G loss: 1.1045\n",
      "[1324/1600] D loss: 1.1592, G loss: 0.9764\n",
      "[1444/1600] D loss: 1.0215, G loss: 0.9251\n",
      "[1564/1600] D loss: 0.9374, G loss: 0.9680\n",
      "train error: \n",
      " D loss: 1.119363, G loss: 0.953901, D accuracy: 75.3%, cell accuracy: 84.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.101792, G loss: 0.973138, D accuracy: 76.8%, cell accuracy: 84.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1512, G loss: 0.9868\n",
      "[124/1600] D loss: 1.1333, G loss: 0.9132\n",
      "[244/1600] D loss: 1.0431, G loss: 0.9401\n",
      "[364/1600] D loss: 1.3376, G loss: 0.8126\n",
      "[484/1600] D loss: 0.8226, G loss: 1.0741\n",
      "[604/1600] D loss: 0.5997, G loss: 1.5928\n",
      "[724/1600] D loss: 1.3119, G loss: 0.9886\n",
      "[844/1600] D loss: 0.7168, G loss: 1.8115\n",
      "[964/1600] D loss: 1.2930, G loss: 0.7454\n",
      "[1084/1600] D loss: 0.5923, G loss: 1.3152\n",
      "[1204/1600] D loss: 0.6216, G loss: 1.9878\n",
      "[1324/1600] D loss: 1.6149, G loss: 0.4664\n",
      "[1444/1600] D loss: 0.9734, G loss: 1.4559\n",
      "[1564/1600] D loss: 0.8602, G loss: 1.4883\n",
      "train error: \n",
      " D loss: 1.010075, G loss: 0.968621, D accuracy: 72.0%, cell accuracy: 84.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.995501, G loss: 1.018816, D accuracy: 73.6%, cell accuracy: 84.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3767, G loss: 0.5847\n",
      "[124/1600] D loss: 0.9049, G loss: 1.2776\n",
      "[244/1600] D loss: 0.7859, G loss: 1.5955\n",
      "[364/1600] D loss: 0.4099, G loss: 1.4901\n",
      "[484/1600] D loss: 1.0068, G loss: 1.5625\n",
      "[604/1600] D loss: 0.9222, G loss: 1.1480\n",
      "[724/1600] D loss: 0.8040, G loss: 1.2437\n",
      "[844/1600] D loss: 0.9238, G loss: 1.3240\n",
      "[964/1600] D loss: 0.8707, G loss: 1.3762\n",
      "[1084/1600] D loss: 0.9448, G loss: 1.1180\n",
      "[1204/1600] D loss: 1.1827, G loss: 1.8292\n",
      "[1324/1600] D loss: 0.5521, G loss: 2.2402\n",
      "[1444/1600] D loss: 0.7684, G loss: 1.5101\n",
      "[1564/1600] D loss: 0.6854, G loss: 1.2277\n",
      "train error: \n",
      " D loss: 0.925250, G loss: 1.012592, D accuracy: 75.8%, cell accuracy: 89.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.915583, G loss: 1.064290, D accuracy: 77.5%, cell accuracy: 89.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7180, G loss: 1.6115\n",
      "[124/1600] D loss: 0.8247, G loss: 1.3431\n",
      "[244/1600] D loss: 0.8253, G loss: 1.4390\n",
      "[364/1600] D loss: 1.1098, G loss: 0.9964\n",
      "[484/1600] D loss: 0.8773, G loss: 0.9608\n",
      "[604/1600] D loss: 1.0870, G loss: 0.9389\n",
      "[724/1600] D loss: 0.9028, G loss: 1.7313\n",
      "[844/1600] D loss: 1.0896, G loss: 2.3450\n",
      "[964/1600] D loss: 0.7418, G loss: 1.2780\n",
      "[1084/1600] D loss: 1.3523, G loss: 1.8197\n",
      "[1204/1600] D loss: 0.8288, G loss: 1.7990\n",
      "[1324/1600] D loss: 0.6016, G loss: 1.9339\n",
      "[1444/1600] D loss: 0.6061, G loss: 1.5773\n",
      "[1564/1600] D loss: 0.8674, G loss: 1.0042\n",
      "train error: \n",
      " D loss: 0.872616, G loss: 1.119552, D accuracy: 81.8%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.867519, G loss: 1.188951, D accuracy: 81.9%, cell accuracy: 91.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9675, G loss: 0.9295\n",
      "[124/1600] D loss: 0.9723, G loss: 1.2643\n",
      "[244/1600] D loss: 0.9728, G loss: 0.9804\n",
      "[364/1600] D loss: 0.7787, G loss: 1.2859\n",
      "[484/1600] D loss: 0.7487, G loss: 1.5564\n",
      "[604/1600] D loss: 0.4326, G loss: 1.4867\n",
      "[724/1600] D loss: 0.6015, G loss: 2.0400\n",
      "[844/1600] D loss: 0.7576, G loss: 1.5932\n",
      "[964/1600] D loss: 0.7100, G loss: 1.2656\n",
      "[1084/1600] D loss: 0.5272, G loss: 1.9750\n",
      "[1204/1600] D loss: 0.5066, G loss: 2.0817\n",
      "[1324/1600] D loss: 0.7085, G loss: 1.6491\n",
      "[1444/1600] D loss: 1.0071, G loss: 1.3321\n",
      "[1564/1600] D loss: 1.0532, G loss: 0.7842\n",
      "train error: \n",
      " D loss: 0.818669, G loss: 1.529181, D accuracy: 82.8%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.844568, G loss: 1.614507, D accuracy: 82.6%, cell accuracy: 92.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7270, G loss: 1.7164\n",
      "[124/1600] D loss: 0.2362, G loss: 2.3889\n",
      "[244/1600] D loss: 1.0891, G loss: 0.8736\n",
      "[364/1600] D loss: 1.0852, G loss: 1.3500\n",
      "[484/1600] D loss: 0.6779, G loss: 2.9121\n",
      "[604/1600] D loss: 0.5638, G loss: 1.7754\n",
      "[724/1600] D loss: 0.7125, G loss: 1.4894\n",
      "[844/1600] D loss: 0.5919, G loss: 1.4378\n",
      "[964/1600] D loss: 0.5972, G loss: 1.1297\n",
      "[1084/1600] D loss: 1.1930, G loss: 0.9604\n",
      "[1204/1600] D loss: 0.9051, G loss: 1.2231\n",
      "[1324/1600] D loss: 0.7463, G loss: 1.4699\n",
      "[1444/1600] D loss: 1.1725, G loss: 0.8612\n",
      "[1564/1600] D loss: 0.8869, G loss: 0.9041\n",
      "train error: \n",
      " D loss: 0.892073, G loss: 1.301449, D accuracy: 79.7%, cell accuracy: 93.7%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.911685, G loss: 1.382365, D accuracy: 79.6%, cell accuracy: 93.5%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7518, G loss: 1.3508\n",
      "[124/1600] D loss: 0.8548, G loss: 1.2124\n",
      "[244/1600] D loss: 0.4273, G loss: 2.2062\n",
      "[364/1600] D loss: 1.0286, G loss: 1.9105\n",
      "[484/1600] D loss: 0.9690, G loss: 1.3524\n",
      "[604/1600] D loss: 0.4861, G loss: 2.6215\n",
      "[724/1600] D loss: 0.7921, G loss: 1.1108\n",
      "[844/1600] D loss: 1.0460, G loss: 0.8757\n",
      "[964/1600] D loss: 0.5920, G loss: 1.5736\n",
      "[1084/1600] D loss: 1.4931, G loss: 1.0340\n",
      "[1204/1600] D loss: 0.7811, G loss: 1.5320\n",
      "[1324/1600] D loss: 0.9936, G loss: 0.8853\n",
      "[1444/1600] D loss: 0.7226, G loss: 1.5603\n",
      "[1564/1600] D loss: 0.6326, G loss: 1.7880\n",
      "train error: \n",
      " D loss: 0.911808, G loss: 1.289217, D accuracy: 79.4%, cell accuracy: 94.7%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.934717, G loss: 1.392515, D accuracy: 77.6%, cell accuracy: 94.5%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1210, G loss: 1.3236\n",
      "[124/1600] D loss: 1.0096, G loss: 0.9349\n",
      "[244/1600] D loss: 0.7974, G loss: 1.2239\n",
      "[364/1600] D loss: 0.8487, G loss: 1.2646\n",
      "[484/1600] D loss: 0.9639, G loss: 2.5540\n",
      "[604/1600] D loss: 1.5427, G loss: 1.4347\n",
      "[724/1600] D loss: 1.0941, G loss: 1.0660\n",
      "[844/1600] D loss: 0.4897, G loss: 3.7030\n",
      "[964/1600] D loss: 0.9439, G loss: 1.2636\n",
      "[1084/1600] D loss: 1.3124, G loss: 1.2949\n",
      "[1204/1600] D loss: 0.2589, G loss: 2.9328\n",
      "[1324/1600] D loss: 0.8337, G loss: 1.2157\n",
      "[1444/1600] D loss: 0.9515, G loss: 1.1842\n",
      "[1564/1600] D loss: 0.7002, G loss: 1.8297\n",
      "train error: \n",
      " D loss: 0.940755, G loss: 1.530108, D accuracy: 78.2%, cell accuracy: 95.3%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.973931, G loss: 1.630058, D accuracy: 79.0%, cell accuracy: 95.1%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1661, G loss: 2.2302\n",
      "[124/1600] D loss: 0.9508, G loss: 1.5938\n",
      "[244/1600] D loss: 1.1082, G loss: 1.8038\n",
      "[364/1600] D loss: 0.8656, G loss: 1.2951\n",
      "[484/1600] D loss: 1.1181, G loss: 1.2583\n",
      "[604/1600] D loss: 1.4828, G loss: 1.8460\n",
      "[724/1600] D loss: 0.2862, G loss: 2.2650\n",
      "[844/1600] D loss: 0.8649, G loss: 1.4144\n",
      "[964/1600] D loss: 0.9777, G loss: 1.1312\n",
      "[1084/1600] D loss: 0.9389, G loss: 1.4182\n",
      "[1204/1600] D loss: 1.2811, G loss: 1.6778\n",
      "[1324/1600] D loss: 1.1376, G loss: 1.3410\n",
      "[1444/1600] D loss: 0.3926, G loss: 2.1595\n",
      "[1564/1600] D loss: 0.6733, G loss: 1.6569\n",
      "train error: \n",
      " D loss: 0.949670, G loss: 1.242963, D accuracy: 77.6%, cell accuracy: 95.9%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.982640, G loss: 1.325559, D accuracy: 77.6%, cell accuracy: 95.8%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9959, G loss: 1.0364\n",
      "[124/1600] D loss: 0.7245, G loss: 1.3811\n",
      "[244/1600] D loss: 0.6809, G loss: 1.5303\n",
      "[364/1600] D loss: 1.0740, G loss: 1.1067\n",
      "[484/1600] D loss: 1.0095, G loss: 0.8254\n",
      "[604/1600] D loss: 0.8734, G loss: 1.2810\n",
      "[724/1600] D loss: 0.9892, G loss: 1.2355\n",
      "[844/1600] D loss: 1.2658, G loss: 1.3665\n",
      "[964/1600] D loss: 1.1593, G loss: 1.8089\n",
      "[1084/1600] D loss: 0.9276, G loss: 1.2062\n",
      "[1204/1600] D loss: 1.6931, G loss: 1.4609\n",
      "[1324/1600] D loss: 0.7177, G loss: 2.1058\n",
      "[1444/1600] D loss: 2.0288, G loss: 2.4911\n",
      "[1564/1600] D loss: 0.9685, G loss: 1.4554\n",
      "train error: \n",
      " D loss: 0.960730, G loss: 1.100841, D accuracy: 76.8%, cell accuracy: 96.2%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.991253, G loss: 1.162360, D accuracy: 77.4%, cell accuracy: 96.1%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9806, G loss: 1.1194\n",
      "[124/1600] D loss: 1.0910, G loss: 1.1598\n",
      "[244/1600] D loss: 1.0993, G loss: 1.0873\n",
      "[364/1600] D loss: 0.8959, G loss: 2.2453\n",
      "[484/1600] D loss: 0.8754, G loss: 1.4639\n",
      "[604/1600] D loss: 1.1010, G loss: 1.3403\n",
      "[724/1600] D loss: 0.5248, G loss: 2.5815\n",
      "[844/1600] D loss: 0.7130, G loss: 1.8560\n",
      "[964/1600] D loss: 0.5935, G loss: 2.3548\n",
      "[1084/1600] D loss: 1.1765, G loss: 0.8263\n",
      "[1204/1600] D loss: 0.7912, G loss: 1.4266\n",
      "[1324/1600] D loss: 1.2454, G loss: 1.1316\n",
      "[1444/1600] D loss: 0.9670, G loss: 1.2849\n",
      "[1564/1600] D loss: 1.1792, G loss: 0.7865\n",
      "train error: \n",
      " D loss: 0.955642, G loss: 1.574562, D accuracy: 78.6%, cell accuracy: 96.3%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.006470, G loss: 1.651858, D accuracy: 77.9%, cell accuracy: 96.2%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9837, G loss: 1.4950\n",
      "[124/1600] D loss: 0.6115, G loss: 1.8059\n",
      "[244/1600] D loss: 0.4384, G loss: 1.7614\n",
      "[364/1600] D loss: 0.3337, G loss: 1.9004\n",
      "[484/1600] D loss: 0.7277, G loss: 1.4957\n",
      "[604/1600] D loss: 1.3734, G loss: 1.3346\n",
      "[724/1600] D loss: 1.5947, G loss: 0.9923\n",
      "[844/1600] D loss: 0.9678, G loss: 0.8997\n",
      "[964/1600] D loss: 1.2133, G loss: 1.0034\n",
      "[1084/1600] D loss: 1.0015, G loss: 1.4916\n",
      "[1204/1600] D loss: 0.8327, G loss: 1.5021\n",
      "[1324/1600] D loss: 1.1282, G loss: 1.0675\n",
      "[1444/1600] D loss: 1.0654, G loss: 1.0238\n",
      "[1564/1600] D loss: 0.7445, G loss: 1.7835\n",
      "train error: \n",
      " D loss: 0.957643, G loss: 1.217056, D accuracy: 76.3%, cell accuracy: 96.2%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.989061, G loss: 1.285383, D accuracy: 76.6%, cell accuracy: 96.1%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3121, G loss: 1.0122\n",
      "[124/1600] D loss: 0.8575, G loss: 1.8992\n",
      "[244/1600] D loss: 0.6748, G loss: 1.3605\n",
      "[364/1600] D loss: 0.9854, G loss: 1.5260\n",
      "[484/1600] D loss: 0.3464, G loss: 2.2562\n",
      "[604/1600] D loss: 1.2245, G loss: 0.7447\n",
      "[724/1600] D loss: 0.9339, G loss: 0.9433\n",
      "[844/1600] D loss: 1.1142, G loss: 1.2363\n",
      "[964/1600] D loss: 1.3910, G loss: 0.5996\n",
      "[1084/1600] D loss: 0.7791, G loss: 1.8944\n",
      "[1204/1600] D loss: 0.8968, G loss: 1.3458\n",
      "[1324/1600] D loss: 0.7661, G loss: 1.5754\n",
      "[1444/1600] D loss: 1.1068, G loss: 1.1257\n",
      "[1564/1600] D loss: 0.7753, G loss: 1.3066\n",
      "train error: \n",
      " D loss: 0.980969, G loss: 1.334710, D accuracy: 75.4%, cell accuracy: 95.8%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.019161, G loss: 1.411928, D accuracy: 75.5%, cell accuracy: 95.7%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8097, G loss: 2.1777\n",
      "[124/1600] D loss: 0.8779, G loss: 1.1418\n",
      "[244/1600] D loss: 1.0187, G loss: 1.6904\n",
      "[364/1600] D loss: 0.7883, G loss: 2.2035\n",
      "[484/1600] D loss: 1.3574, G loss: 1.1427\n",
      "[604/1600] D loss: 0.7808, G loss: 1.9196\n",
      "[724/1600] D loss: 0.6517, G loss: 1.8012\n",
      "[844/1600] D loss: 1.3176, G loss: 0.8171\n",
      "[964/1600] D loss: 1.1297, G loss: 1.6414\n",
      "[1084/1600] D loss: 0.7484, G loss: 2.0943\n",
      "[1204/1600] D loss: 0.3317, G loss: 2.5248\n",
      "[1324/1600] D loss: 0.5190, G loss: 2.2006\n",
      "[1444/1600] D loss: 0.9108, G loss: 1.2588\n",
      "[1564/1600] D loss: 1.2583, G loss: 0.9757\n",
      "train error: \n",
      " D loss: 1.001530, G loss: 1.541525, D accuracy: 74.7%, cell accuracy: 96.4%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.058662, G loss: 1.594584, D accuracy: 74.5%, cell accuracy: 96.3%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9251, G loss: 1.6112\n",
      "[124/1600] D loss: 1.3394, G loss: 1.1790\n",
      "[244/1600] D loss: 1.2295, G loss: 1.4461\n",
      "[364/1600] D loss: 1.0718, G loss: 1.0973\n",
      "[484/1600] D loss: 1.2833, G loss: 0.4373\n",
      "[604/1600] D loss: 1.0241, G loss: 0.9445\n",
      "[724/1600] D loss: 1.0963, G loss: 1.0487\n",
      "[844/1600] D loss: 0.9685, G loss: 1.6380\n",
      "[964/1600] D loss: 0.8698, G loss: 0.9662\n",
      "[1084/1600] D loss: 1.2670, G loss: 1.1180\n",
      "[1204/1600] D loss: 0.6852, G loss: 1.4409\n",
      "[1324/1600] D loss: 1.2286, G loss: 0.4931\n",
      "[1444/1600] D loss: 1.5267, G loss: 0.6438\n",
      "[1564/1600] D loss: 1.3422, G loss: 0.5949\n",
      "train error: \n",
      " D loss: 1.228043, G loss: 1.191517, D accuracy: 68.0%, cell accuracy: 96.7%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300669, G loss: 1.251654, D accuracy: 65.9%, cell accuracy: 96.5%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9941, G loss: 1.1313\n",
      "[124/1600] D loss: 0.9294, G loss: 1.8946\n",
      "[244/1600] D loss: 1.1189, G loss: 1.2835\n",
      "[364/1600] D loss: 1.4123, G loss: 1.3656\n",
      "[484/1600] D loss: 1.2195, G loss: 1.7393\n",
      "[604/1600] D loss: 1.1890, G loss: 0.7716\n",
      "[724/1600] D loss: 1.0395, G loss: 0.8283\n",
      "[844/1600] D loss: 1.3232, G loss: 0.9229\n",
      "[964/1600] D loss: 1.0291, G loss: 1.5841\n",
      "[1084/1600] D loss: 0.8931, G loss: 1.7416\n",
      "[1204/1600] D loss: 1.1980, G loss: 0.6510\n",
      "[1324/1600] D loss: 1.3887, G loss: 0.9158\n",
      "[1444/1600] D loss: 1.2457, G loss: 0.9815\n",
      "[1564/1600] D loss: 1.0263, G loss: 1.2546\n",
      "train error: \n",
      " D loss: 1.154631, G loss: 0.849696, D accuracy: 70.1%, cell accuracy: 97.0%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.213929, G loss: 0.890617, D accuracy: 70.0%, cell accuracy: 96.9%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0907, G loss: 1.0648\n",
      "[124/1600] D loss: 1.1053, G loss: 1.4217\n",
      "[244/1600] D loss: 1.1428, G loss: 1.1475\n",
      "[364/1600] D loss: 0.9176, G loss: 1.3840\n",
      "[484/1600] D loss: 0.9051, G loss: 1.0910\n",
      "[604/1600] D loss: 1.1220, G loss: 1.3428\n",
      "[724/1600] D loss: 1.0743, G loss: 0.9656\n",
      "[844/1600] D loss: 0.8764, G loss: 1.2683\n",
      "[964/1600] D loss: 0.9130, G loss: 1.2579\n",
      "[1084/1600] D loss: 2.2494, G loss: 1.5512\n",
      "[1204/1600] D loss: 0.6349, G loss: 2.1367\n",
      "[1324/1600] D loss: 0.9994, G loss: 0.8324\n",
      "[1444/1600] D loss: 1.3405, G loss: 0.7450\n",
      "[1564/1600] D loss: 1.2610, G loss: 0.5532\n",
      "train error: \n",
      " D loss: 1.179634, G loss: 1.130520, D accuracy: 70.1%, cell accuracy: 96.8%, board accuracy: 1.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.239110, G loss: 1.183472, D accuracy: 66.6%, cell accuracy: 96.7%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9772, G loss: 1.0286\n",
      "[124/1600] D loss: 1.2755, G loss: 0.5952\n",
      "[244/1600] D loss: 0.8713, G loss: 1.2571\n",
      "[364/1600] D loss: 1.1148, G loss: 0.9902\n",
      "[484/1600] D loss: 0.9951, G loss: 0.9091\n",
      "[604/1600] D loss: 1.0320, G loss: 0.9445\n",
      "[724/1600] D loss: 0.7724, G loss: 1.7526\n",
      "[844/1600] D loss: 1.3014, G loss: 0.8823\n",
      "[964/1600] D loss: 1.3159, G loss: 0.8582\n",
      "[1084/1600] D loss: 1.2584, G loss: 0.8345\n",
      "[1204/1600] D loss: 1.2927, G loss: 1.1276\n",
      "[1324/1600] D loss: 1.4887, G loss: 1.0393\n",
      "[1444/1600] D loss: 1.7669, G loss: 0.8569\n",
      "[1564/1600] D loss: 1.2072, G loss: 0.7676\n",
      "train error: \n",
      " D loss: 1.186376, G loss: 0.785602, D accuracy: 66.5%, cell accuracy: 97.1%, board accuracy: 1.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.232075, G loss: 0.828350, D accuracy: 66.2%, cell accuracy: 96.9%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8859, G loss: 1.1299\n",
      "[124/1600] D loss: 0.9067, G loss: 1.0031\n",
      "[244/1600] D loss: 1.0802, G loss: 0.9456\n",
      "[364/1600] D loss: 1.1075, G loss: 0.7056\n",
      "[484/1600] D loss: 0.9720, G loss: 1.0417\n",
      "[604/1600] D loss: 1.0789, G loss: 1.0596\n",
      "[724/1600] D loss: 1.5829, G loss: 0.8154\n",
      "[844/1600] D loss: 1.0705, G loss: 1.3051\n",
      "[964/1600] D loss: 1.0872, G loss: 0.9116\n",
      "[1084/1600] D loss: 0.9887, G loss: 1.0630\n",
      "[1204/1600] D loss: 1.0652, G loss: 1.0410\n",
      "[1324/1600] D loss: 1.1795, G loss: 0.8559\n",
      "[1444/1600] D loss: 1.0670, G loss: 0.9391\n",
      "[1564/1600] D loss: 0.9699, G loss: 0.8460\n",
      "train error: \n",
      " D loss: 1.154021, G loss: 1.232279, D accuracy: 71.7%, cell accuracy: 97.0%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.218952, G loss: 1.274971, D accuracy: 70.1%, cell accuracy: 96.9%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1682, G loss: 0.8859\n",
      "[124/1600] D loss: 1.4444, G loss: 0.8709\n",
      "[244/1600] D loss: 1.2480, G loss: 0.7390\n",
      "[364/1600] D loss: 1.4637, G loss: 0.8144\n",
      "[484/1600] D loss: 0.9969, G loss: 0.9225\n",
      "[604/1600] D loss: 0.9098, G loss: 1.2250\n",
      "[724/1600] D loss: 0.8537, G loss: 1.0523\n",
      "[844/1600] D loss: 1.6202, G loss: 1.4325\n",
      "[964/1600] D loss: 1.1838, G loss: 0.9858\n",
      "[1084/1600] D loss: 0.9342, G loss: 1.1438\n",
      "[1204/1600] D loss: 1.5503, G loss: 1.7558\n",
      "[1324/1600] D loss: 1.6436, G loss: 1.3917\n",
      "[1444/1600] D loss: 1.2816, G loss: 1.4524\n",
      "[1564/1600] D loss: 0.8621, G loss: 1.5124\n",
      "train error: \n",
      " D loss: 1.167875, G loss: 1.318931, D accuracy: 70.1%, cell accuracy: 97.1%, board accuracy: 1.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.231732, G loss: 1.371421, D accuracy: 68.5%, cell accuracy: 97.0%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2367, G loss: 1.4866\n",
      "[124/1600] D loss: 0.9750, G loss: 0.9152\n",
      "[244/1600] D loss: 0.8495, G loss: 1.3238\n",
      "[364/1600] D loss: 1.0256, G loss: 0.6642\n",
      "[484/1600] D loss: 1.3213, G loss: 0.7068\n",
      "[604/1600] D loss: 1.1395, G loss: 0.6726\n",
      "[724/1600] D loss: 0.9407, G loss: 1.1600\n",
      "[844/1600] D loss: 1.4030, G loss: 0.6115\n",
      "[964/1600] D loss: 1.2031, G loss: 0.6222\n",
      "[1084/1600] D loss: 1.3728, G loss: 0.8164\n",
      "[1204/1600] D loss: 1.1810, G loss: 0.6334\n",
      "[1324/1600] D loss: 0.4665, G loss: 1.6325\n",
      "[1444/1600] D loss: 1.2365, G loss: 0.9930\n",
      "[1564/1600] D loss: 1.1289, G loss: 0.9017\n",
      "train error: \n",
      " D loss: 1.157354, G loss: 0.854890, D accuracy: 68.2%, cell accuracy: 97.3%, board accuracy: 1.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.208963, G loss: 0.906661, D accuracy: 67.4%, cell accuracy: 97.1%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1418, G loss: 0.7288\n",
      "[124/1600] D loss: 1.2279, G loss: 0.8057\n",
      "[244/1600] D loss: 1.0537, G loss: 0.9130\n",
      "[364/1600] D loss: 1.1829, G loss: 0.7997\n",
      "[484/1600] D loss: 1.1191, G loss: 1.5672\n",
      "[604/1600] D loss: 1.0452, G loss: 1.0470\n",
      "[724/1600] D loss: 1.2158, G loss: 0.8887\n",
      "[844/1600] D loss: 1.2910, G loss: 0.9315\n",
      "[964/1600] D loss: 1.3138, G loss: 1.0898\n",
      "[1084/1600] D loss: 1.3517, G loss: 1.0943\n",
      "[1204/1600] D loss: 1.0316, G loss: 0.8357\n",
      "[1324/1600] D loss: 1.2643, G loss: 0.6776\n",
      "[1444/1600] D loss: 0.8975, G loss: 1.7952\n",
      "[1564/1600] D loss: 1.2277, G loss: 0.6571\n",
      "train error: \n",
      " D loss: 1.156347, G loss: 1.187543, D accuracy: 68.2%, cell accuracy: 97.3%, board accuracy: 1.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.227170, G loss: 1.264083, D accuracy: 66.8%, cell accuracy: 97.2%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3124, G loss: 0.8476\n",
      "[124/1600] D loss: 0.7561, G loss: 1.2759\n",
      "[244/1600] D loss: 1.1635, G loss: 1.0868\n",
      "[364/1600] D loss: 1.0510, G loss: 0.8603\n",
      "[484/1600] D loss: 1.2007, G loss: 0.6180\n",
      "[604/1600] D loss: 1.2823, G loss: 0.8959\n",
      "[724/1600] D loss: 0.9025, G loss: 0.9353\n",
      "[844/1600] D loss: 1.1734, G loss: 0.7341\n",
      "[964/1600] D loss: 1.3452, G loss: 1.1099\n",
      "[1084/1600] D loss: 1.2962, G loss: 0.6412\n",
      "[1204/1600] D loss: 0.9095, G loss: 0.9666\n",
      "[1324/1600] D loss: 1.2852, G loss: 0.5885\n",
      "[1444/1600] D loss: 1.2303, G loss: 1.4204\n",
      "[1564/1600] D loss: 1.3149, G loss: 0.6639\n",
      "train error: \n",
      " D loss: 1.214258, G loss: 1.264683, D accuracy: 67.5%, cell accuracy: 97.1%, board accuracy: 1.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290740, G loss: 1.330868, D accuracy: 64.8%, cell accuracy: 97.0%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9945, G loss: 1.4705\n",
      "[124/1600] D loss: 1.2211, G loss: 0.8110\n",
      "[244/1600] D loss: 1.2679, G loss: 0.7051\n",
      "[364/1600] D loss: 0.9147, G loss: 0.8815\n",
      "[484/1600] D loss: 1.3499, G loss: 0.6395\n",
      "[604/1600] D loss: 1.4819, G loss: 1.5518\n",
      "[724/1600] D loss: 1.0082, G loss: 0.8982\n",
      "[844/1600] D loss: 1.4724, G loss: 1.2893\n",
      "[964/1600] D loss: 1.0180, G loss: 1.3031\n",
      "[1084/1600] D loss: 0.8719, G loss: 1.0336\n",
      "[1204/1600] D loss: 1.2504, G loss: 0.7561\n",
      "[1324/1600] D loss: 0.9014, G loss: 1.3528\n",
      "[1444/1600] D loss: 1.0258, G loss: 1.4581\n",
      "[1564/1600] D loss: 1.4262, G loss: 0.7452\n",
      "train error: \n",
      " D loss: 1.157062, G loss: 1.102562, D accuracy: 70.1%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.220792, G loss: 1.159462, D accuracy: 67.5%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0700, G loss: 1.0807\n",
      "[124/1600] D loss: 1.4495, G loss: 1.4154\n",
      "[244/1600] D loss: 0.9900, G loss: 0.7154\n",
      "[364/1600] D loss: 1.4174, G loss: 0.9623\n",
      "[484/1600] D loss: 0.5968, G loss: 1.9104\n",
      "[604/1600] D loss: 1.5780, G loss: 1.0556\n",
      "[724/1600] D loss: 0.9516, G loss: 0.8035\n",
      "[844/1600] D loss: 1.5906, G loss: 0.7531\n",
      "[964/1600] D loss: 1.3156, G loss: 0.8077\n",
      "[1084/1600] D loss: 1.2420, G loss: 0.7946\n",
      "[1204/1600] D loss: 0.9705, G loss: 0.9937\n",
      "[1324/1600] D loss: 1.0207, G loss: 1.6466\n",
      "[1444/1600] D loss: 0.5614, G loss: 1.4160\n",
      "[1564/1600] D loss: 1.3809, G loss: 1.3999\n",
      "train error: \n",
      " D loss: 1.124857, G loss: 1.248462, D accuracy: 71.4%, cell accuracy: 96.4%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.188411, G loss: 1.317437, D accuracy: 68.4%, cell accuracy: 96.3%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1749, G loss: 1.1824\n",
      "[124/1600] D loss: 0.8945, G loss: 1.0097\n",
      "[244/1600] D loss: 0.8630, G loss: 1.3258\n",
      "[364/1600] D loss: 1.0608, G loss: 1.3032\n",
      "[484/1600] D loss: 1.1341, G loss: 1.3205\n",
      "[604/1600] D loss: 1.6567, G loss: 0.7124\n",
      "[724/1600] D loss: 0.9942, G loss: 0.8188\n",
      "[844/1600] D loss: 1.0575, G loss: 1.3598\n",
      "[964/1600] D loss: 0.9590, G loss: 1.9517\n",
      "[1084/1600] D loss: 0.7671, G loss: 1.5328\n",
      "[1204/1600] D loss: 0.9136, G loss: 1.6243\n",
      "[1324/1600] D loss: 1.4047, G loss: 0.9427\n",
      "[1444/1600] D loss: 1.0358, G loss: 0.9020\n",
      "[1564/1600] D loss: 0.8641, G loss: 1.4023\n",
      "train error: \n",
      " D loss: 1.092087, G loss: 1.083145, D accuracy: 71.7%, cell accuracy: 97.3%, board accuracy: 1.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.159142, G loss: 1.135550, D accuracy: 69.4%, cell accuracy: 97.1%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7166, G loss: 1.5090\n",
      "[124/1600] D loss: 0.7421, G loss: 1.1683\n",
      "[244/1600] D loss: 1.4190, G loss: 1.0113\n",
      "[364/1600] D loss: 1.4190, G loss: 1.1342\n",
      "[484/1600] D loss: 1.2853, G loss: 0.8749\n",
      "[604/1600] D loss: 1.0607, G loss: 1.2502\n",
      "[724/1600] D loss: 0.9124, G loss: 1.1320\n",
      "[844/1600] D loss: 1.2860, G loss: 1.2793\n",
      "[964/1600] D loss: 1.0463, G loss: 1.1735\n",
      "[1084/1600] D loss: 0.8481, G loss: 1.3499\n",
      "[1204/1600] D loss: 1.1377, G loss: 1.5576\n",
      "[1324/1600] D loss: 1.2817, G loss: 0.8615\n",
      "[1444/1600] D loss: 1.4809, G loss: 0.7812\n",
      "[1564/1600] D loss: 0.8790, G loss: 1.2600\n",
      "train error: \n",
      " D loss: 1.094401, G loss: 1.041848, D accuracy: 71.0%, cell accuracy: 96.9%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.138570, G loss: 1.113659, D accuracy: 69.8%, cell accuracy: 96.7%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9856, G loss: 1.0002\n",
      "[124/1600] D loss: 1.0772, G loss: 0.8419\n",
      "[244/1600] D loss: 0.6954, G loss: 1.1603\n",
      "[364/1600] D loss: 1.5135, G loss: 0.7422\n",
      "[484/1600] D loss: 1.4700, G loss: 0.6638\n",
      "[604/1600] D loss: 0.7502, G loss: 1.3904\n",
      "[724/1600] D loss: 1.1097, G loss: 0.6976\n",
      "[844/1600] D loss: 1.1926, G loss: 0.6766\n",
      "[964/1600] D loss: 1.3595, G loss: 1.2705\n",
      "[1084/1600] D loss: 0.6573, G loss: 1.4955\n",
      "[1204/1600] D loss: 1.2966, G loss: 1.1525\n",
      "[1324/1600] D loss: 1.0684, G loss: 0.7754\n",
      "[1444/1600] D loss: 1.1758, G loss: 0.8910\n",
      "[1564/1600] D loss: 1.0121, G loss: 1.1060\n",
      "train error: \n",
      " D loss: 1.068941, G loss: 1.194920, D accuracy: 73.7%, cell accuracy: 97.0%, board accuracy: 1.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.130613, G loss: 1.251403, D accuracy: 70.9%, cell accuracy: 96.9%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1215, G loss: 1.0326\n",
      "[124/1600] D loss: 1.3918, G loss: 1.1945\n",
      "[244/1600] D loss: 1.2681, G loss: 1.2152\n",
      "[364/1600] D loss: 0.8330, G loss: 1.1077\n",
      "[484/1600] D loss: 1.1250, G loss: 1.4464\n",
      "[604/1600] D loss: 0.9680, G loss: 1.1338\n",
      "[724/1600] D loss: 1.0176, G loss: 1.3060\n",
      "[844/1600] D loss: 1.0007, G loss: 0.7040\n",
      "[964/1600] D loss: 0.9310, G loss: 2.0835\n",
      "[1084/1600] D loss: 1.0017, G loss: 1.4046\n",
      "[1204/1600] D loss: 0.9678, G loss: 1.3880\n",
      "[1324/1600] D loss: 1.1596, G loss: 0.9333\n",
      "[1444/1600] D loss: 1.1597, G loss: 1.6747\n",
      "[1564/1600] D loss: 1.0129, G loss: 0.9997\n",
      "train error: \n",
      " D loss: 1.102778, G loss: 0.962425, D accuracy: 70.8%, cell accuracy: 97.2%, board accuracy: 1.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.141376, G loss: 1.028816, D accuracy: 71.1%, cell accuracy: 97.2%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9806, G loss: 1.1491\n",
      "[124/1600] D loss: 1.0870, G loss: 0.6361\n",
      "[244/1600] D loss: 1.2466, G loss: 0.8511\n",
      "[364/1600] D loss: 0.9367, G loss: 0.9538\n",
      "[484/1600] D loss: 0.7884, G loss: 0.9125\n",
      "[604/1600] D loss: 0.8883, G loss: 1.0288\n",
      "[724/1600] D loss: 0.6767, G loss: 1.4805\n",
      "[844/1600] D loss: 1.7418, G loss: 0.5598\n",
      "[964/1600] D loss: 1.3532, G loss: 0.6504\n",
      "[1084/1600] D loss: 0.9125, G loss: 1.2132\n",
      "[1204/1600] D loss: 0.6858, G loss: 1.3827\n",
      "[1324/1600] D loss: 1.1719, G loss: 1.0175\n",
      "[1444/1600] D loss: 0.8864, G loss: 1.4553\n",
      "[1564/1600] D loss: 1.0980, G loss: 1.2853\n",
      "train error: \n",
      " D loss: 1.223262, G loss: 1.485789, D accuracy: 65.7%, cell accuracy: 97.3%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303145, G loss: 1.539546, D accuracy: 63.1%, cell accuracy: 97.2%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0328, G loss: 1.9918\n",
      "[124/1600] D loss: 1.5020, G loss: 0.5611\n",
      "[244/1600] D loss: 1.5842, G loss: 0.4670\n",
      "[364/1600] D loss: 0.7025, G loss: 2.1482\n",
      "[484/1600] D loss: 1.5604, G loss: 0.9664\n",
      "[604/1600] D loss: 1.0726, G loss: 1.4540\n",
      "[724/1600] D loss: 1.0983, G loss: 0.8676\n",
      "[844/1600] D loss: 1.0047, G loss: 1.6073\n",
      "[964/1600] D loss: 0.8870, G loss: 1.5847\n",
      "[1084/1600] D loss: 1.5028, G loss: 1.2394\n",
      "[1204/1600] D loss: 1.2722, G loss: 1.1521\n",
      "[1324/1600] D loss: 1.3728, G loss: 0.5523\n",
      "[1444/1600] D loss: 1.1352, G loss: 1.1460\n",
      "[1564/1600] D loss: 1.3363, G loss: 0.7047\n",
      "train error: \n",
      " D loss: 1.081559, G loss: 1.073284, D accuracy: 71.3%, cell accuracy: 97.2%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.141669, G loss: 1.134959, D accuracy: 68.5%, cell accuracy: 97.1%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3111, G loss: 1.0000\n",
      "[124/1600] D loss: 1.2753, G loss: 1.1234\n",
      "[244/1600] D loss: 1.3041, G loss: 0.5983\n",
      "[364/1600] D loss: 1.1689, G loss: 0.7976\n",
      "[484/1600] D loss: 1.5381, G loss: 1.4223\n",
      "[604/1600] D loss: 1.0922, G loss: 0.9366\n",
      "[724/1600] D loss: 1.4653, G loss: 1.0086\n",
      "[844/1600] D loss: 0.6517, G loss: 1.7798\n",
      "[964/1600] D loss: 0.7224, G loss: 1.6842\n",
      "[1084/1600] D loss: 1.1731, G loss: 0.7893\n",
      "[1204/1600] D loss: 0.8303, G loss: 0.9879\n",
      "[1324/1600] D loss: 1.2371, G loss: 0.9341\n",
      "[1444/1600] D loss: 0.9964, G loss: 0.9470\n",
      "[1564/1600] D loss: 1.0065, G loss: 1.8595\n",
      "train error: \n",
      " D loss: 1.053174, G loss: 1.235613, D accuracy: 74.2%, cell accuracy: 97.5%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.112642, G loss: 1.284485, D accuracy: 72.1%, cell accuracy: 97.4%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7748, G loss: 1.1307\n",
      "[124/1600] D loss: 1.3121, G loss: 0.5873\n",
      "[244/1600] D loss: 0.9406, G loss: 1.0028\n",
      "[364/1600] D loss: 1.0636, G loss: 1.1814\n",
      "[484/1600] D loss: 0.8800, G loss: 1.5011\n",
      "[604/1600] D loss: 1.8540, G loss: 1.6844\n",
      "[724/1600] D loss: 0.5232, G loss: 1.5853\n",
      "[844/1600] D loss: 1.2477, G loss: 1.1661\n",
      "[964/1600] D loss: 0.8692, G loss: 1.3637\n",
      "[1084/1600] D loss: 0.7818, G loss: 1.2238\n",
      "[1204/1600] D loss: 0.9308, G loss: 1.0777\n",
      "[1324/1600] D loss: 0.9421, G loss: 0.9884\n",
      "[1444/1600] D loss: 1.3045, G loss: 0.8119\n",
      "[1564/1600] D loss: 1.2373, G loss: 0.5887\n",
      "train error: \n",
      " D loss: 1.200060, G loss: 0.962420, D accuracy: 64.3%, cell accuracy: 95.9%, board accuracy: 1.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.244834, G loss: 1.026958, D accuracy: 62.4%, cell accuracy: 95.8%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1790, G loss: 0.9779\n",
      "[124/1600] D loss: 0.6193, G loss: 1.9962\n",
      "[244/1600] D loss: 1.4551, G loss: 1.0615\n",
      "[364/1600] D loss: 1.0847, G loss: 1.4879\n",
      "[484/1600] D loss: 0.9413, G loss: 1.3505\n",
      "[604/1600] D loss: 0.9548, G loss: 1.7412\n",
      "[724/1600] D loss: 0.7220, G loss: 2.3396\n",
      "[844/1600] D loss: 0.9677, G loss: 1.3943\n",
      "[964/1600] D loss: 1.4247, G loss: 0.5242\n",
      "[1084/1600] D loss: 0.6217, G loss: 1.8032\n",
      "[1204/1600] D loss: 0.9458, G loss: 1.1870\n",
      "[1324/1600] D loss: 0.8111, G loss: 1.3853\n",
      "[1444/1600] D loss: 1.3574, G loss: 0.7531\n",
      "[1564/1600] D loss: 1.1691, G loss: 0.9465\n",
      "train error: \n",
      " D loss: 1.117089, G loss: 1.094474, D accuracy: 70.0%, cell accuracy: 97.1%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.190196, G loss: 1.143996, D accuracy: 65.8%, cell accuracy: 97.0%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8796, G loss: 1.5635\n",
      "[124/1600] D loss: 0.8488, G loss: 0.9589\n",
      "[244/1600] D loss: 1.0471, G loss: 1.2181\n",
      "[364/1600] D loss: 1.3423, G loss: 1.0006\n",
      "[484/1600] D loss: 1.0256, G loss: 1.8659\n",
      "[604/1600] D loss: 0.7042, G loss: 2.1860\n",
      "[724/1600] D loss: 1.1005, G loss: 1.1176\n",
      "[844/1600] D loss: 0.9871, G loss: 1.0492\n",
      "[964/1600] D loss: 1.1098, G loss: 1.0489\n",
      "[1084/1600] D loss: 1.6359, G loss: 0.8093\n",
      "[1204/1600] D loss: 1.1522, G loss: 0.6591\n",
      "[1324/1600] D loss: 1.3281, G loss: 0.6522\n",
      "[1444/1600] D loss: 1.1240, G loss: 1.2922\n",
      "[1564/1600] D loss: 0.9937, G loss: 1.4387\n",
      "train error: \n",
      " D loss: 1.124920, G loss: 1.225974, D accuracy: 69.7%, cell accuracy: 97.4%, board accuracy: 1.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.198393, G loss: 1.283549, D accuracy: 67.0%, cell accuracy: 97.3%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7949, G loss: 1.5966\n",
      "[124/1600] D loss: 1.3563, G loss: 1.7210\n",
      "[244/1600] D loss: 1.1515, G loss: 0.8972\n",
      "[364/1600] D loss: 1.2257, G loss: 0.7361\n",
      "[484/1600] D loss: 0.9021, G loss: 1.6429\n",
      "[604/1600] D loss: 1.2131, G loss: 0.9642\n",
      "[724/1600] D loss: 1.0650, G loss: 1.1968\n",
      "[844/1600] D loss: 0.7845, G loss: 1.6474\n",
      "[964/1600] D loss: 1.3132, G loss: 0.6580\n",
      "[1084/1600] D loss: 0.8925, G loss: 0.9678\n",
      "[1204/1600] D loss: 1.0864, G loss: 1.0272\n",
      "[1324/1600] D loss: 1.0138, G loss: 0.9587\n",
      "[1444/1600] D loss: 1.0924, G loss: 1.5844\n",
      "[1564/1600] D loss: 1.0469, G loss: 0.9485\n",
      "train error: \n",
      " D loss: 1.265579, G loss: 0.949789, D accuracy: 64.6%, cell accuracy: 97.5%, board accuracy: 1.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341352, G loss: 0.998693, D accuracy: 60.9%, cell accuracy: 97.4%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1748, G loss: 1.2874\n",
      "[124/1600] D loss: 1.4353, G loss: 0.7947\n",
      "[244/1600] D loss: 1.4149, G loss: 0.6991\n",
      "[364/1600] D loss: 1.0756, G loss: 0.8082\n",
      "[484/1600] D loss: 0.9466, G loss: 0.9398\n",
      "[604/1600] D loss: 1.3334, G loss: 1.0548\n",
      "[724/1600] D loss: 1.0299, G loss: 0.7854\n",
      "[844/1600] D loss: 1.0062, G loss: 0.9454\n",
      "[964/1600] D loss: 1.5400, G loss: 0.8451\n",
      "[1084/1600] D loss: 1.4843, G loss: 0.9972\n",
      "[1204/1600] D loss: 1.4063, G loss: 0.7370\n",
      "[1324/1600] D loss: 1.0367, G loss: 0.8840\n",
      "[1444/1600] D loss: 1.0727, G loss: 0.8250\n",
      "[1564/1600] D loss: 1.1896, G loss: 1.2106\n",
      "train error: \n",
      " D loss: 1.313326, G loss: 1.291169, D accuracy: 62.6%, cell accuracy: 97.6%, board accuracy: 2.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.407683, G loss: 1.346526, D accuracy: 60.1%, cell accuracy: 97.4%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1757, G loss: 0.7876\n",
      "[124/1600] D loss: 1.2751, G loss: 1.1330\n",
      "[244/1600] D loss: 1.0609, G loss: 0.7823\n",
      "[364/1600] D loss: 0.8499, G loss: 1.5921\n",
      "[484/1600] D loss: 1.4500, G loss: 1.5810\n",
      "[604/1600] D loss: 1.4180, G loss: 1.3159\n",
      "[724/1600] D loss: 0.9086, G loss: 1.3002\n",
      "[844/1600] D loss: 1.0637, G loss: 0.9247\n",
      "[964/1600] D loss: 1.2551, G loss: 0.5741\n",
      "[1084/1600] D loss: 1.5189, G loss: 0.4077\n",
      "[1204/1600] D loss: 0.9084, G loss: 0.9194\n",
      "[1324/1600] D loss: 1.9064, G loss: 0.5084\n",
      "[1444/1600] D loss: 1.0115, G loss: 0.8638\n",
      "[1564/1600] D loss: 1.5900, G loss: 0.8764\n",
      "train error: \n",
      " D loss: 1.247838, G loss: 1.116838, D accuracy: 65.1%, cell accuracy: 97.6%, board accuracy: 1.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338550, G loss: 1.149956, D accuracy: 60.9%, cell accuracy: 97.5%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2802, G loss: 1.1914\n",
      "[124/1600] D loss: 1.2623, G loss: 0.9750\n",
      "[244/1600] D loss: 1.3415, G loss: 1.0554\n",
      "[364/1600] D loss: 1.1754, G loss: 1.0560\n",
      "[484/1600] D loss: 0.8089, G loss: 1.1014\n",
      "[604/1600] D loss: 1.3885, G loss: 0.5605\n",
      "[724/1600] D loss: 1.0545, G loss: 1.4476\n",
      "[844/1600] D loss: 1.4217, G loss: 1.1789\n",
      "[964/1600] D loss: 2.2536, G loss: 0.2698\n",
      "[1084/1600] D loss: 1.4841, G loss: 0.8593\n",
      "[1204/1600] D loss: 1.4142, G loss: 1.1201\n",
      "[1324/1600] D loss: 1.5528, G loss: 0.5914\n",
      "[1444/1600] D loss: 1.6058, G loss: 0.5832\n",
      "[1564/1600] D loss: 1.4287, G loss: 1.5716\n",
      "train error: \n",
      " D loss: 1.334402, G loss: 0.909036, D accuracy: 60.0%, cell accuracy: 96.1%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383412, G loss: 0.936809, D accuracy: 61.0%, cell accuracy: 96.0%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6447, G loss: 0.5248\n",
      "[124/1600] D loss: 1.1772, G loss: 1.2229\n",
      "[244/1600] D loss: 1.5351, G loss: 0.7363\n",
      "[364/1600] D loss: 1.0610, G loss: 1.0935\n",
      "[484/1600] D loss: 1.3282, G loss: 0.8613\n",
      "[604/1600] D loss: 1.6007, G loss: 0.7288\n",
      "[724/1600] D loss: 1.3430, G loss: 0.8456\n",
      "[844/1600] D loss: 1.2414, G loss: 0.7035\n",
      "[964/1600] D loss: 1.0995, G loss: 0.9939\n",
      "[1084/1600] D loss: 1.3583, G loss: 0.5998\n",
      "[1204/1600] D loss: 1.5271, G loss: 1.1791\n",
      "[1324/1600] D loss: 1.0927, G loss: 0.9048\n",
      "[1444/1600] D loss: 0.9596, G loss: 0.8210\n",
      "[1564/1600] D loss: 1.3849, G loss: 0.8238\n",
      "train error: \n",
      " D loss: 1.271925, G loss: 0.890166, D accuracy: 61.6%, cell accuracy: 97.6%, board accuracy: 2.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334669, G loss: 0.922891, D accuracy: 58.2%, cell accuracy: 97.5%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1573, G loss: 0.9275\n",
      "[124/1600] D loss: 1.1617, G loss: 0.8007\n",
      "[244/1600] D loss: 1.2014, G loss: 1.0419\n",
      "[364/1600] D loss: 1.0674, G loss: 0.9836\n",
      "[484/1600] D loss: 0.9701, G loss: 1.2062\n",
      "[604/1600] D loss: 1.2845, G loss: 1.0011\n",
      "[724/1600] D loss: 1.4307, G loss: 0.5132\n",
      "[844/1600] D loss: 1.7222, G loss: 0.6884\n",
      "[964/1600] D loss: 1.1696, G loss: 1.0289\n",
      "[1084/1600] D loss: 1.2757, G loss: 0.7410\n",
      "[1204/1600] D loss: 1.5586, G loss: 0.7280\n",
      "[1324/1600] D loss: 1.1019, G loss: 0.8891\n",
      "[1444/1600] D loss: 1.4179, G loss: 0.9762\n",
      "[1564/1600] D loss: 1.1201, G loss: 1.2436\n",
      "train error: \n",
      " D loss: 1.366149, G loss: 0.552684, D accuracy: 59.2%, cell accuracy: 97.7%, board accuracy: 2.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401224, G loss: 0.587450, D accuracy: 58.8%, cell accuracy: 97.5%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3007, G loss: 0.5625\n",
      "[124/1600] D loss: 1.5844, G loss: 0.5773\n",
      "[244/1600] D loss: 1.6054, G loss: 1.4266\n",
      "[364/1600] D loss: 1.1377, G loss: 1.3771\n",
      "[484/1600] D loss: 1.1325, G loss: 1.0400\n",
      "[604/1600] D loss: 1.2273, G loss: 0.9305\n",
      "[724/1600] D loss: 1.2163, G loss: 1.1442\n",
      "[844/1600] D loss: 1.2645, G loss: 0.9838\n",
      "[964/1600] D loss: 1.2306, G loss: 1.1653\n",
      "[1084/1600] D loss: 1.0919, G loss: 0.9329\n",
      "[1204/1600] D loss: 0.8797, G loss: 1.4784\n",
      "[1324/1600] D loss: 0.7732, G loss: 1.1589\n",
      "[1444/1600] D loss: 1.1487, G loss: 0.8309\n",
      "[1564/1600] D loss: 1.3066, G loss: 0.6513\n",
      "train error: \n",
      " D loss: 1.217265, G loss: 1.102110, D accuracy: 65.1%, cell accuracy: 97.7%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297294, G loss: 1.142577, D accuracy: 61.0%, cell accuracy: 97.5%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9152, G loss: 1.2998\n",
      "[124/1600] D loss: 1.5691, G loss: 0.9709\n",
      "[244/1600] D loss: 1.3160, G loss: 0.7120\n",
      "[364/1600] D loss: 1.4401, G loss: 0.7706\n",
      "[484/1600] D loss: 0.8904, G loss: 1.0561\n",
      "[604/1600] D loss: 1.0248, G loss: 0.7305\n",
      "[724/1600] D loss: 1.2605, G loss: 0.9003\n",
      "[844/1600] D loss: 1.0318, G loss: 0.8599\n",
      "[964/1600] D loss: 1.2876, G loss: 0.8826\n",
      "[1084/1600] D loss: 1.2527, G loss: 1.0364\n",
      "[1204/1600] D loss: 1.0279, G loss: 1.0046\n",
      "[1324/1600] D loss: 0.9294, G loss: 1.5981\n",
      "[1444/1600] D loss: 1.1841, G loss: 0.6773\n",
      "[1564/1600] D loss: 1.0644, G loss: 0.9707\n",
      "train error: \n",
      " D loss: 1.196381, G loss: 1.093805, D accuracy: 66.1%, cell accuracy: 97.6%, board accuracy: 2.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275668, G loss: 1.125007, D accuracy: 64.0%, cell accuracy: 97.4%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1175, G loss: 1.7577\n",
      "[124/1600] D loss: 1.1868, G loss: 0.6694\n",
      "[244/1600] D loss: 0.9400, G loss: 1.2160\n",
      "[364/1600] D loss: 1.3112, G loss: 0.7607\n",
      "[484/1600] D loss: 1.0449, G loss: 0.8741\n",
      "[604/1600] D loss: 1.0770, G loss: 1.0681\n",
      "[724/1600] D loss: 1.3709, G loss: 0.4449\n",
      "[844/1600] D loss: 1.4793, G loss: 1.2478\n",
      "[964/1600] D loss: 0.7601, G loss: 1.0784\n",
      "[1084/1600] D loss: 1.4537, G loss: 0.8679\n",
      "[1204/1600] D loss: 1.6237, G loss: 0.5107\n",
      "[1324/1600] D loss: 1.1286, G loss: 0.7640\n",
      "[1444/1600] D loss: 0.6961, G loss: 1.1235\n",
      "[1564/1600] D loss: 1.2976, G loss: 1.2917\n",
      "train error: \n",
      " D loss: 1.194986, G loss: 0.928558, D accuracy: 68.3%, cell accuracy: 97.9%, board accuracy: 4.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264092, G loss: 0.947424, D accuracy: 64.8%, cell accuracy: 97.7%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2684, G loss: 0.9272\n",
      "[124/1600] D loss: 0.8819, G loss: 1.4041\n",
      "[244/1600] D loss: 0.9674, G loss: 1.3493\n",
      "[364/1600] D loss: 1.1788, G loss: 1.1317\n",
      "[484/1600] D loss: 0.8260, G loss: 1.1302\n",
      "[604/1600] D loss: 1.2476, G loss: 0.7428\n",
      "[724/1600] D loss: 1.1462, G loss: 0.9360\n",
      "[844/1600] D loss: 1.2114, G loss: 0.9412\n",
      "[964/1600] D loss: 1.7539, G loss: 0.3591\n",
      "[1084/1600] D loss: 1.4871, G loss: 0.5167\n",
      "[1204/1600] D loss: 1.2248, G loss: 0.6791\n",
      "[1324/1600] D loss: 1.3321, G loss: 0.6957\n",
      "[1444/1600] D loss: 1.0983, G loss: 0.9978\n",
      "[1564/1600] D loss: 0.7367, G loss: 0.9929\n",
      "train error: \n",
      " D loss: 1.204755, G loss: 0.961447, D accuracy: 66.3%, cell accuracy: 97.8%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274295, G loss: 1.002820, D accuracy: 63.4%, cell accuracy: 97.7%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0927, G loss: 1.1094\n",
      "[124/1600] D loss: 0.9224, G loss: 1.5575\n",
      "[244/1600] D loss: 1.4925, G loss: 0.8964\n",
      "[364/1600] D loss: 1.1089, G loss: 1.1704\n",
      "[484/1600] D loss: 1.3281, G loss: 0.7628\n",
      "[604/1600] D loss: 1.0281, G loss: 1.3353\n",
      "[724/1600] D loss: 1.5041, G loss: 0.8907\n",
      "[844/1600] D loss: 1.3065, G loss: 1.2669\n",
      "[964/1600] D loss: 1.2582, G loss: 1.2779\n",
      "[1084/1600] D loss: 1.0125, G loss: 1.2593\n",
      "[1204/1600] D loss: 0.9304, G loss: 1.0601\n",
      "[1324/1600] D loss: 1.0637, G loss: 0.7993\n",
      "[1444/1600] D loss: 1.0634, G loss: 1.1184\n",
      "[1564/1600] D loss: 1.3980, G loss: 0.5807\n",
      "train error: \n",
      " D loss: 1.216241, G loss: 0.825294, D accuracy: 66.3%, cell accuracy: 97.6%, board accuracy: 3.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278136, G loss: 0.849454, D accuracy: 62.1%, cell accuracy: 97.5%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9670, G loss: 0.8022\n",
      "[124/1600] D loss: 1.1439, G loss: 1.0252\n",
      "[244/1600] D loss: 1.0100, G loss: 0.8093\n",
      "[364/1600] D loss: 1.0348, G loss: 0.9760\n",
      "[484/1600] D loss: 1.3945, G loss: 0.8568\n",
      "[604/1600] D loss: 1.4326, G loss: 0.6526\n",
      "[724/1600] D loss: 0.8989, G loss: 1.6953\n",
      "[844/1600] D loss: 1.3558, G loss: 1.0729\n",
      "[964/1600] D loss: 1.4907, G loss: 1.3561\n",
      "[1084/1600] D loss: 1.1971, G loss: 0.9050\n",
      "[1204/1600] D loss: 1.0558, G loss: 1.0580\n",
      "[1324/1600] D loss: 1.4164, G loss: 0.6276\n",
      "[1444/1600] D loss: 1.4032, G loss: 1.1873\n",
      "[1564/1600] D loss: 1.4254, G loss: 0.9060\n",
      "train error: \n",
      " D loss: 1.180384, G loss: 0.876452, D accuracy: 69.2%, cell accuracy: 97.5%, board accuracy: 2.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.245695, G loss: 0.886653, D accuracy: 64.9%, cell accuracy: 97.4%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2385, G loss: 1.4338\n",
      "[124/1600] D loss: 1.1585, G loss: 1.5424\n",
      "[244/1600] D loss: 1.2048, G loss: 1.6987\n",
      "[364/1600] D loss: 1.2498, G loss: 1.1649\n",
      "[484/1600] D loss: 1.2323, G loss: 1.2872\n",
      "[604/1600] D loss: 1.5074, G loss: 0.4811\n",
      "[724/1600] D loss: 0.9358, G loss: 1.4688\n",
      "[844/1600] D loss: 1.0270, G loss: 0.8409\n",
      "[964/1600] D loss: 1.2480, G loss: 0.6847\n",
      "[1084/1600] D loss: 1.1419, G loss: 0.7448\n",
      "[1204/1600] D loss: 0.8981, G loss: 1.1434\n",
      "[1324/1600] D loss: 1.6808, G loss: 0.4964\n",
      "[1444/1600] D loss: 0.3362, G loss: 1.9020\n",
      "[1564/1600] D loss: 1.2230, G loss: 1.3892\n",
      "train error: \n",
      " D loss: 1.175279, G loss: 1.138335, D accuracy: 68.8%, cell accuracy: 98.0%, board accuracy: 4.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256131, G loss: 1.151665, D accuracy: 64.4%, cell accuracy: 97.8%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4031, G loss: 1.4051\n",
      "[124/1600] D loss: 1.1816, G loss: 0.7578\n",
      "[244/1600] D loss: 0.9866, G loss: 2.0236\n",
      "[364/1600] D loss: 0.9288, G loss: 1.4675\n",
      "[484/1600] D loss: 0.7831, G loss: 1.5338\n",
      "[604/1600] D loss: 1.3884, G loss: 0.9852\n",
      "[724/1600] D loss: 1.0438, G loss: 1.2453\n",
      "[844/1600] D loss: 0.7777, G loss: 1.3967\n",
      "[964/1600] D loss: 1.2195, G loss: 0.7781\n",
      "[1084/1600] D loss: 1.0736, G loss: 1.1915\n",
      "[1204/1600] D loss: 1.6032, G loss: 0.7966\n",
      "[1324/1600] D loss: 1.6488, G loss: 1.2021\n",
      "[1444/1600] D loss: 1.0445, G loss: 0.8069\n",
      "[1564/1600] D loss: 1.1741, G loss: 0.9854\n",
      "train error: \n",
      " D loss: 1.189316, G loss: 1.108951, D accuracy: 67.2%, cell accuracy: 97.9%, board accuracy: 4.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273624, G loss: 1.116650, D accuracy: 62.9%, cell accuracy: 97.8%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1361, G loss: 0.9278\n",
      "[124/1600] D loss: 1.2153, G loss: 1.1160\n",
      "[244/1600] D loss: 1.1943, G loss: 1.6109\n",
      "[364/1600] D loss: 0.7215, G loss: 1.5870\n",
      "[484/1600] D loss: 1.1879, G loss: 1.8534\n",
      "[604/1600] D loss: 1.6914, G loss: 1.5331\n",
      "[724/1600] D loss: 1.2191, G loss: 0.6451\n",
      "[844/1600] D loss: 1.0977, G loss: 0.9279\n",
      "[964/1600] D loss: 1.4279, G loss: 0.7503\n",
      "[1084/1600] D loss: 1.1163, G loss: 0.9877\n",
      "[1204/1600] D loss: 0.6626, G loss: 1.2095\n",
      "[1324/1600] D loss: 1.2913, G loss: 1.3327\n",
      "[1444/1600] D loss: 0.9119, G loss: 1.1674\n",
      "[1564/1600] D loss: 1.3171, G loss: 1.2978\n",
      "train error: \n",
      " D loss: 1.147429, G loss: 1.143771, D accuracy: 68.6%, cell accuracy: 97.9%, board accuracy: 5.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.223788, G loss: 1.155607, D accuracy: 65.9%, cell accuracy: 97.8%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4163, G loss: 1.1560\n",
      "[124/1600] D loss: 0.9447, G loss: 1.0748\n",
      "[244/1600] D loss: 1.7517, G loss: 0.8004\n",
      "[364/1600] D loss: 1.4100, G loss: 1.2557\n",
      "[484/1600] D loss: 0.8587, G loss: 0.8346\n",
      "[604/1600] D loss: 1.2387, G loss: 0.9053\n",
      "[724/1600] D loss: 1.2412, G loss: 0.7018\n",
      "[844/1600] D loss: 1.1742, G loss: 0.8377\n",
      "[964/1600] D loss: 1.1247, G loss: 0.9890\n",
      "[1084/1600] D loss: 1.1932, G loss: 1.5739\n",
      "[1204/1600] D loss: 0.5300, G loss: 1.4420\n",
      "[1324/1600] D loss: 1.1368, G loss: 0.7735\n",
      "[1444/1600] D loss: 1.2219, G loss: 1.0316\n",
      "[1564/1600] D loss: 1.2762, G loss: 1.4845\n",
      "train error: \n",
      " D loss: 1.184838, G loss: 0.719655, D accuracy: 67.0%, cell accuracy: 97.1%, board accuracy: 2.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257333, G loss: 0.718967, D accuracy: 63.1%, cell accuracy: 97.0%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0009, G loss: 0.8960\n",
      "[124/1600] D loss: 0.7688, G loss: 1.2320\n",
      "[244/1600] D loss: 0.9659, G loss: 0.9859\n",
      "[364/1600] D loss: 1.3187, G loss: 0.8515\n",
      "[484/1600] D loss: 0.7944, G loss: 1.0741\n",
      "[604/1600] D loss: 0.9341, G loss: 1.0688\n",
      "[724/1600] D loss: 1.3122, G loss: 1.0570\n",
      "[844/1600] D loss: 1.0626, G loss: 1.1152\n",
      "[964/1600] D loss: 0.8790, G loss: 1.1388\n",
      "[1084/1600] D loss: 1.4050, G loss: 1.1936\n",
      "[1204/1600] D loss: 1.1717, G loss: 1.0866\n",
      "[1324/1600] D loss: 0.8023, G loss: 1.1761\n",
      "[1444/1600] D loss: 1.1786, G loss: 0.7320\n",
      "[1564/1600] D loss: 1.6317, G loss: 1.1383\n",
      "train error: \n",
      " D loss: 1.272235, G loss: 0.608080, D accuracy: 64.1%, cell accuracy: 98.0%, board accuracy: 5.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312391, G loss: 0.627318, D accuracy: 63.5%, cell accuracy: 97.9%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3394, G loss: 0.5569\n",
      "[124/1600] D loss: 1.1839, G loss: 0.9693\n",
      "[244/1600] D loss: 1.3292, G loss: 1.0353\n",
      "[364/1600] D loss: 0.8041, G loss: 1.2191\n",
      "[484/1600] D loss: 1.3418, G loss: 1.3655\n",
      "[604/1600] D loss: 1.0458, G loss: 2.1426\n",
      "[724/1600] D loss: 1.1742, G loss: 1.3328\n",
      "[844/1600] D loss: 1.0139, G loss: 0.7542\n",
      "[964/1600] D loss: 1.0635, G loss: 0.9789\n",
      "[1084/1600] D loss: 0.9269, G loss: 1.3054\n",
      "[1204/1600] D loss: 1.0639, G loss: 0.7401\n",
      "[1324/1600] D loss: 1.3312, G loss: 1.0894\n",
      "[1444/1600] D loss: 1.1017, G loss: 0.9714\n",
      "[1564/1600] D loss: 0.7290, G loss: 1.0110\n",
      "train error: \n",
      " D loss: 1.139428, G loss: 1.269739, D accuracy: 70.0%, cell accuracy: 98.0%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.226194, G loss: 1.293902, D accuracy: 67.0%, cell accuracy: 97.8%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4255, G loss: 1.0805\n",
      "[124/1600] D loss: 0.8946, G loss: 1.3219\n",
      "[244/1600] D loss: 1.0521, G loss: 1.1950\n",
      "[364/1600] D loss: 1.0330, G loss: 1.2405\n",
      "[484/1600] D loss: 1.3893, G loss: 1.1335\n",
      "[604/1600] D loss: 1.3026, G loss: 0.7245\n",
      "[724/1600] D loss: 1.0199, G loss: 1.2062\n",
      "[844/1600] D loss: 1.2661, G loss: 1.1859\n",
      "[964/1600] D loss: 1.0530, G loss: 0.8706\n",
      "[1084/1600] D loss: 1.3547, G loss: 1.3472\n",
      "[1204/1600] D loss: 1.4143, G loss: 1.0658\n",
      "[1324/1600] D loss: 1.3180, G loss: 1.0279\n",
      "[1444/1600] D loss: 1.4956, G loss: 1.1829\n",
      "[1564/1600] D loss: 0.7026, G loss: 1.1477\n",
      "train error: \n",
      " D loss: 1.114569, G loss: 0.881720, D accuracy: 71.1%, cell accuracy: 97.9%, board accuracy: 5.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.181689, G loss: 0.903167, D accuracy: 68.9%, cell accuracy: 97.8%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3063, G loss: 0.5280\n",
      "[124/1600] D loss: 0.9042, G loss: 0.9775\n",
      "[244/1600] D loss: 1.1594, G loss: 0.5840\n",
      "[364/1600] D loss: 1.0720, G loss: 0.6716\n",
      "[484/1600] D loss: 0.9945, G loss: 0.9842\n",
      "[604/1600] D loss: 1.2437, G loss: 0.6885\n",
      "[724/1600] D loss: 1.2768, G loss: 1.6865\n",
      "[844/1600] D loss: 1.4898, G loss: 0.8790\n",
      "[964/1600] D loss: 0.9196, G loss: 0.9265\n",
      "[1084/1600] D loss: 0.8288, G loss: 1.1417\n",
      "[1204/1600] D loss: 0.9824, G loss: 1.0830\n",
      "[1324/1600] D loss: 0.7778, G loss: 1.3656\n",
      "[1444/1600] D loss: 0.8576, G loss: 1.5603\n",
      "[1564/1600] D loss: 0.9200, G loss: 1.0123\n",
      "train error: \n",
      " D loss: 1.070847, G loss: 1.079331, D accuracy: 72.5%, cell accuracy: 98.0%, board accuracy: 4.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.150617, G loss: 1.104114, D accuracy: 68.9%, cell accuracy: 97.8%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1528, G loss: 1.5070\n",
      "[124/1600] D loss: 0.8643, G loss: 0.9052\n",
      "[244/1600] D loss: 1.5569, G loss: 0.5921\n",
      "[364/1600] D loss: 1.1123, G loss: 1.3665\n",
      "[484/1600] D loss: 1.1049, G loss: 0.8471\n",
      "[604/1600] D loss: 0.8456, G loss: 1.1130\n",
      "[724/1600] D loss: 1.3231, G loss: 0.8353\n",
      "[844/1600] D loss: 1.0325, G loss: 0.7448\n",
      "[964/1600] D loss: 0.8382, G loss: 1.2638\n",
      "[1084/1600] D loss: 0.7401, G loss: 1.5349\n",
      "[1204/1600] D loss: 1.5563, G loss: 0.5147\n",
      "[1324/1600] D loss: 1.1415, G loss: 0.7967\n",
      "[1444/1600] D loss: 1.6807, G loss: 0.4774\n",
      "[1564/1600] D loss: 0.9457, G loss: 1.0691\n",
      "train error: \n",
      " D loss: 1.056153, G loss: 1.124363, D accuracy: 73.1%, cell accuracy: 98.0%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.132537, G loss: 1.150550, D accuracy: 70.8%, cell accuracy: 97.9%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8962, G loss: 1.1652\n",
      "[124/1600] D loss: 1.0554, G loss: 1.0362\n",
      "[244/1600] D loss: 0.8039, G loss: 1.0590\n",
      "[364/1600] D loss: 1.1034, G loss: 1.0040\n",
      "[484/1600] D loss: 1.3577, G loss: 0.8708\n",
      "[604/1600] D loss: 0.9182, G loss: 0.9588\n",
      "[724/1600] D loss: 0.9608, G loss: 1.5885\n",
      "[844/1600] D loss: 1.2140, G loss: 0.7326\n",
      "[964/1600] D loss: 1.0039, G loss: 1.1896\n",
      "[1084/1600] D loss: 1.1328, G loss: 1.5247\n",
      "[1204/1600] D loss: 1.7257, G loss: 1.6017\n",
      "[1324/1600] D loss: 0.9688, G loss: 1.4221\n",
      "[1444/1600] D loss: 1.1671, G loss: 1.4429\n",
      "[1564/1600] D loss: 1.2969, G loss: 0.8642\n",
      "train error: \n",
      " D loss: 1.067946, G loss: 1.102484, D accuracy: 73.0%, cell accuracy: 97.9%, board accuracy: 5.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.140852, G loss: 1.122291, D accuracy: 70.8%, cell accuracy: 97.8%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9424, G loss: 1.5748\n",
      "[124/1600] D loss: 0.9895, G loss: 1.8657\n",
      "[244/1600] D loss: 0.8134, G loss: 0.8959\n",
      "[364/1600] D loss: 1.0627, G loss: 1.1588\n",
      "[484/1600] D loss: 1.2537, G loss: 0.8311\n",
      "[604/1600] D loss: 1.0751, G loss: 0.7981\n",
      "[724/1600] D loss: 0.9859, G loss: 1.2709\n",
      "[844/1600] D loss: 1.1208, G loss: 1.3862\n",
      "[964/1600] D loss: 1.0569, G loss: 1.3470\n",
      "[1084/1600] D loss: 1.9738, G loss: 0.7830\n",
      "[1204/1600] D loss: 0.8792, G loss: 1.3789\n",
      "[1324/1600] D loss: 1.5814, G loss: 2.1609\n",
      "[1444/1600] D loss: 0.9416, G loss: 1.1110\n",
      "[1564/1600] D loss: 0.8435, G loss: 1.1934\n",
      "train error: \n",
      " D loss: 1.066293, G loss: 1.348656, D accuracy: 72.9%, cell accuracy: 97.9%, board accuracy: 5.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.151186, G loss: 1.383392, D accuracy: 69.2%, cell accuracy: 97.8%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2630, G loss: 1.1449\n",
      "[124/1600] D loss: 1.0404, G loss: 1.1968\n",
      "[244/1600] D loss: 0.7955, G loss: 1.4011\n",
      "[364/1600] D loss: 0.8172, G loss: 1.2458\n",
      "[484/1600] D loss: 0.8309, G loss: 1.2701\n",
      "[604/1600] D loss: 1.0800, G loss: 1.5352\n",
      "[724/1600] D loss: 0.7636, G loss: 1.4156\n",
      "[844/1600] D loss: 1.0855, G loss: 1.1440\n",
      "[964/1600] D loss: 0.8975, G loss: 1.5903\n",
      "[1084/1600] D loss: 0.8964, G loss: 1.9189\n",
      "[1204/1600] D loss: 0.9204, G loss: 1.4977\n",
      "[1324/1600] D loss: 0.8019, G loss: 0.9608\n",
      "[1444/1600] D loss: 1.3145, G loss: 1.2000\n",
      "[1564/1600] D loss: 1.1216, G loss: 1.2260\n",
      "train error: \n",
      " D loss: 1.174184, G loss: 1.503316, D accuracy: 68.1%, cell accuracy: 97.2%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259714, G loss: 1.520525, D accuracy: 66.5%, cell accuracy: 97.1%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0332, G loss: 1.6702\n",
      "[124/1600] D loss: 0.9946, G loss: 1.2835\n",
      "[244/1600] D loss: 0.7568, G loss: 1.2919\n",
      "[364/1600] D loss: 1.1641, G loss: 1.3982\n",
      "[484/1600] D loss: 0.9818, G loss: 1.7508\n",
      "[604/1600] D loss: 1.2322, G loss: 1.2150\n",
      "[724/1600] D loss: 1.0702, G loss: 1.2150\n",
      "[844/1600] D loss: 1.3224, G loss: 1.0183\n",
      "[964/1600] D loss: 0.9094, G loss: 1.5562\n",
      "[1084/1600] D loss: 0.5955, G loss: 1.5299\n",
      "[1204/1600] D loss: 0.8333, G loss: 1.4017\n",
      "[1324/1600] D loss: 0.9660, G loss: 1.0356\n",
      "[1444/1600] D loss: 0.7221, G loss: 1.3098\n",
      "[1564/1600] D loss: 1.2143, G loss: 0.6179\n",
      "train error: \n",
      " D loss: 1.001975, G loss: 1.340279, D accuracy: 74.7%, cell accuracy: 97.9%, board accuracy: 6.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.071223, G loss: 1.365517, D accuracy: 71.5%, cell accuracy: 97.8%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0383, G loss: 1.2598\n",
      "[124/1600] D loss: 0.8179, G loss: 1.2449\n",
      "[244/1600] D loss: 1.2029, G loss: 0.5839\n",
      "[364/1600] D loss: 0.9739, G loss: 1.0274\n",
      "[484/1600] D loss: 1.0327, G loss: 1.2119\n",
      "[604/1600] D loss: 1.1134, G loss: 0.8687\n",
      "[724/1600] D loss: 0.9196, G loss: 1.4795\n",
      "[844/1600] D loss: 0.2541, G loss: 2.4285\n",
      "[964/1600] D loss: 0.9638, G loss: 1.0569\n",
      "[1084/1600] D loss: 1.1039, G loss: 0.9404\n",
      "[1204/1600] D loss: 0.7980, G loss: 1.0213\n",
      "[1324/1600] D loss: 0.8923, G loss: 0.9351\n",
      "[1444/1600] D loss: 0.6818, G loss: 1.5202\n",
      "[1564/1600] D loss: 1.0944, G loss: 0.8635\n",
      "train error: \n",
      " D loss: 0.996198, G loss: 1.066723, D accuracy: 74.8%, cell accuracy: 98.0%, board accuracy: 7.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.056303, G loss: 1.094419, D accuracy: 71.5%, cell accuracy: 97.9%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7806, G loss: 1.5892\n",
      "[124/1600] D loss: 0.9401, G loss: 1.0459\n",
      "[244/1600] D loss: 0.8214, G loss: 1.2203\n",
      "[364/1600] D loss: 0.4385, G loss: 1.4213\n",
      "[484/1600] D loss: 0.6224, G loss: 1.6781\n",
      "[604/1600] D loss: 0.6948, G loss: 2.3063\n",
      "[724/1600] D loss: 1.1892, G loss: 0.7302\n",
      "[844/1600] D loss: 1.2620, G loss: 0.7136\n",
      "[964/1600] D loss: 1.5604, G loss: 0.5257\n",
      "[1084/1600] D loss: 0.8896, G loss: 1.3564\n",
      "[1204/1600] D loss: 0.8088, G loss: 1.1612\n",
      "[1324/1600] D loss: 1.1846, G loss: 1.1565\n",
      "[1444/1600] D loss: 0.8364, G loss: 1.2338\n",
      "[1564/1600] D loss: 0.8780, G loss: 1.0212\n",
      "train error: \n",
      " D loss: 1.019560, G loss: 1.505398, D accuracy: 73.9%, cell accuracy: 98.0%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.119716, G loss: 1.522811, D accuracy: 69.9%, cell accuracy: 97.9%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9868, G loss: 1.1247\n",
      "[124/1600] D loss: 0.9889, G loss: 0.8727\n",
      "[244/1600] D loss: 0.9019, G loss: 1.1225\n",
      "[364/1600] D loss: 1.0289, G loss: 1.1409\n",
      "[484/1600] D loss: 0.9758, G loss: 1.2444\n",
      "[604/1600] D loss: 0.9599, G loss: 1.3625\n",
      "[724/1600] D loss: 0.8199, G loss: 1.3769\n",
      "[844/1600] D loss: 1.4341, G loss: 0.3985\n",
      "[964/1600] D loss: 0.7007, G loss: 1.2856\n",
      "[1084/1600] D loss: 0.9741, G loss: 0.9183\n",
      "[1204/1600] D loss: 0.5705, G loss: 1.0748\n",
      "[1324/1600] D loss: 0.5482, G loss: 2.0569\n",
      "[1444/1600] D loss: 1.0532, G loss: 2.0234\n",
      "[1564/1600] D loss: 1.0668, G loss: 1.2628\n",
      "train error: \n",
      " D loss: 1.047416, G loss: 0.928393, D accuracy: 72.3%, cell accuracy: 97.9%, board accuracy: 6.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.107134, G loss: 0.966810, D accuracy: 69.6%, cell accuracy: 97.8%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0991, G loss: 0.7665\n",
      "[124/1600] D loss: 1.2319, G loss: 1.2315\n",
      "[244/1600] D loss: 1.0152, G loss: 0.7845\n",
      "[364/1600] D loss: 0.9573, G loss: 1.2905\n",
      "[484/1600] D loss: 0.8719, G loss: 1.0809\n",
      "[604/1600] D loss: 1.2873, G loss: 0.7470\n",
      "[724/1600] D loss: 0.6168, G loss: 1.4199\n",
      "[844/1600] D loss: 1.3603, G loss: 0.9629\n",
      "[964/1600] D loss: 0.9465, G loss: 0.9522\n",
      "[1084/1600] D loss: 0.9490, G loss: 1.1558\n",
      "[1204/1600] D loss: 1.5376, G loss: 1.0096\n",
      "[1324/1600] D loss: 1.4168, G loss: 0.9262\n",
      "[1444/1600] D loss: 0.9536, G loss: 1.3645\n",
      "[1564/1600] D loss: 0.5947, G loss: 1.9814\n",
      "train error: \n",
      " D loss: 1.030978, G loss: 0.954008, D accuracy: 72.8%, cell accuracy: 98.0%, board accuracy: 7.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.078329, G loss: 1.002891, D accuracy: 71.4%, cell accuracy: 97.8%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6425, G loss: 0.5801\n",
      "[124/1600] D loss: 1.0998, G loss: 0.7045\n",
      "[244/1600] D loss: 0.9451, G loss: 1.6941\n",
      "[364/1600] D loss: 0.2707, G loss: 2.7287\n",
      "[484/1600] D loss: 1.0285, G loss: 1.7198\n",
      "[604/1600] D loss: 1.0905, G loss: 0.9659\n",
      "[724/1600] D loss: 0.8842, G loss: 1.0603\n",
      "[844/1600] D loss: 1.0363, G loss: 1.0018\n",
      "[964/1600] D loss: 0.3835, G loss: 2.7988\n",
      "[1084/1600] D loss: 1.1317, G loss: 1.8217\n",
      "[1204/1600] D loss: 0.9076, G loss: 0.9191\n",
      "[1324/1600] D loss: 1.0962, G loss: 1.0216\n",
      "[1444/1600] D loss: 0.4983, G loss: 2.0527\n",
      "[1564/1600] D loss: 0.8464, G loss: 1.2106\n",
      "train error: \n",
      " D loss: 0.981786, G loss: 1.438383, D accuracy: 75.6%, cell accuracy: 97.9%, board accuracy: 6.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.070216, G loss: 1.491430, D accuracy: 72.8%, cell accuracy: 97.8%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4027, G loss: 2.4472\n",
      "[124/1600] D loss: 0.8436, G loss: 1.3367\n",
      "[244/1600] D loss: 1.0804, G loss: 0.8896\n",
      "[364/1600] D loss: 0.9032, G loss: 1.6981\n",
      "[484/1600] D loss: 0.3120, G loss: 2.2733\n",
      "[604/1600] D loss: 0.6756, G loss: 1.5810\n",
      "[724/1600] D loss: 0.7659, G loss: 1.7827\n",
      "[844/1600] D loss: 1.0267, G loss: 0.9642\n",
      "[964/1600] D loss: 1.1569, G loss: 0.7384\n",
      "[1084/1600] D loss: 0.8832, G loss: 1.2572\n",
      "[1204/1600] D loss: 0.8117, G loss: 1.4087\n",
      "[1324/1600] D loss: 0.4940, G loss: 1.4266\n",
      "[1444/1600] D loss: 1.1041, G loss: 1.2884\n",
      "[1564/1600] D loss: 0.9405, G loss: 1.8021\n",
      "train error: \n",
      " D loss: 1.042234, G loss: 1.080168, D accuracy: 72.8%, cell accuracy: 97.9%, board accuracy: 8.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.091636, G loss: 1.129545, D accuracy: 70.8%, cell accuracy: 97.8%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7037, G loss: 1.7108\n",
      "[124/1600] D loss: 1.0324, G loss: 1.5134\n",
      "[244/1600] D loss: 2.1660, G loss: 1.3451\n",
      "[364/1600] D loss: 0.8008, G loss: 1.3330\n",
      "[484/1600] D loss: 0.9528, G loss: 1.4850\n",
      "[604/1600] D loss: 0.9105, G loss: 1.0832\n",
      "[724/1600] D loss: 1.3209, G loss: 0.7716\n",
      "[844/1600] D loss: 1.1005, G loss: 1.1072\n",
      "[964/1600] D loss: 1.1925, G loss: 1.0735\n",
      "[1084/1600] D loss: 1.1695, G loss: 1.4765\n",
      "[1204/1600] D loss: 0.7875, G loss: 1.6478\n",
      "[1324/1600] D loss: 1.0634, G loss: 0.8549\n",
      "[1444/1600] D loss: 0.9209, G loss: 1.1327\n",
      "[1564/1600] D loss: 0.3979, G loss: 1.7583\n",
      "train error: \n",
      " D loss: 1.011784, G loss: 1.282855, D accuracy: 75.3%, cell accuracy: 97.8%, board accuracy: 6.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.076991, G loss: 1.332706, D accuracy: 71.5%, cell accuracy: 97.7%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6314, G loss: 0.9589\n",
      "[124/1600] D loss: 0.8594, G loss: 1.0007\n",
      "[244/1600] D loss: 0.2786, G loss: 2.5556\n",
      "[364/1600] D loss: 0.7937, G loss: 1.5567\n",
      "[484/1600] D loss: 0.8027, G loss: 1.2569\n",
      "[604/1600] D loss: 1.0526, G loss: 1.1296\n",
      "[724/1600] D loss: 0.8033, G loss: 1.0892\n",
      "[844/1600] D loss: 0.8048, G loss: 1.1523\n",
      "[964/1600] D loss: 0.9376, G loss: 2.2165\n",
      "[1084/1600] D loss: 1.1632, G loss: 1.4982\n",
      "[1204/1600] D loss: 1.6672, G loss: 0.6988\n",
      "[1324/1600] D loss: 1.1477, G loss: 1.3648\n",
      "[1444/1600] D loss: 1.0311, G loss: 0.7496\n",
      "[1564/1600] D loss: 1.4884, G loss: 1.1906\n",
      "train error: \n",
      " D loss: 1.026118, G loss: 1.345217, D accuracy: 75.6%, cell accuracy: 97.8%, board accuracy: 5.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.096398, G loss: 1.369926, D accuracy: 71.6%, cell accuracy: 97.7%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9352, G loss: 1.2060\n",
      "[124/1600] D loss: 1.3615, G loss: 0.8069\n",
      "[244/1600] D loss: 1.2875, G loss: 1.0082\n",
      "[364/1600] D loss: 0.5935, G loss: 1.3441\n",
      "[484/1600] D loss: 0.7616, G loss: 2.0194\n",
      "[604/1600] D loss: 0.5419, G loss: 1.6294\n",
      "[724/1600] D loss: 0.6973, G loss: 2.3390\n",
      "[844/1600] D loss: 0.9764, G loss: 1.3161\n",
      "[964/1600] D loss: 0.8641, G loss: 1.6866\n",
      "[1084/1600] D loss: 1.1315, G loss: 1.2321\n",
      "[1204/1600] D loss: 0.6370, G loss: 1.9654\n",
      "[1324/1600] D loss: 1.0831, G loss: 1.3351\n",
      "[1444/1600] D loss: 0.8089, G loss: 2.2564\n",
      "[1564/1600] D loss: 1.4684, G loss: 0.7005\n",
      "train error: \n",
      " D loss: 0.992621, G loss: 1.207126, D accuracy: 75.6%, cell accuracy: 97.8%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.051131, G loss: 1.241942, D accuracy: 72.8%, cell accuracy: 97.7%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0993, G loss: 1.2514\n",
      "[124/1600] D loss: 0.4359, G loss: 1.7959\n",
      "[244/1600] D loss: 0.8350, G loss: 2.0948\n",
      "[364/1600] D loss: 0.7285, G loss: 1.3926\n",
      "[484/1600] D loss: 0.9777, G loss: 1.0293\n",
      "[604/1600] D loss: 1.1091, G loss: 1.4849\n",
      "[724/1600] D loss: 0.6895, G loss: 1.2393\n",
      "[844/1600] D loss: 0.5521, G loss: 1.9642\n",
      "[964/1600] D loss: 1.5168, G loss: 1.2446\n",
      "[1084/1600] D loss: 0.8644, G loss: 1.4868\n",
      "[1204/1600] D loss: 1.0444, G loss: 1.4349\n",
      "[1324/1600] D loss: 0.7828, G loss: 1.2113\n",
      "[1444/1600] D loss: 1.3210, G loss: 1.0016\n",
      "[1564/1600] D loss: 1.2776, G loss: 0.9451\n",
      "train error: \n",
      " D loss: 0.989811, G loss: 1.339390, D accuracy: 75.8%, cell accuracy: 97.9%, board accuracy: 4.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.048346, G loss: 1.420284, D accuracy: 72.8%, cell accuracy: 97.7%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9549, G loss: 0.8956\n",
      "[124/1600] D loss: 0.7655, G loss: 2.0478\n",
      "[244/1600] D loss: 1.0569, G loss: 1.2664\n",
      "[364/1600] D loss: 1.0825, G loss: 1.0405\n",
      "[484/1600] D loss: 1.3208, G loss: 0.7952\n",
      "[604/1600] D loss: 0.5873, G loss: 2.3449\n",
      "[724/1600] D loss: 0.6312, G loss: 2.2948\n",
      "[844/1600] D loss: 0.6066, G loss: 1.4292\n",
      "[964/1600] D loss: 0.8438, G loss: 0.8830\n",
      "[1084/1600] D loss: 0.8112, G loss: 1.1087\n",
      "[1204/1600] D loss: 1.0868, G loss: 0.9483\n",
      "[1324/1600] D loss: 0.7164, G loss: 2.1063\n",
      "[1444/1600] D loss: 0.9509, G loss: 1.3539\n",
      "[1564/1600] D loss: 0.7671, G loss: 1.2402\n",
      "train error: \n",
      " D loss: 1.118492, G loss: 0.993620, D accuracy: 72.9%, cell accuracy: 97.9%, board accuracy: 5.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.144313, G loss: 1.052217, D accuracy: 72.1%, cell accuracy: 97.7%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0618, G loss: 0.9028\n",
      "[124/1600] D loss: 0.7878, G loss: 1.2646\n",
      "[244/1600] D loss: 1.0226, G loss: 1.4022\n",
      "[364/1600] D loss: 1.0957, G loss: 0.7374\n",
      "[484/1600] D loss: 0.6330, G loss: 1.9357\n",
      "[604/1600] D loss: 0.5939, G loss: 2.0430\n",
      "[724/1600] D loss: 1.3366, G loss: 0.5993\n",
      "[844/1600] D loss: 0.7443, G loss: 1.2835\n",
      "[964/1600] D loss: 1.1309, G loss: 0.9493\n",
      "[1084/1600] D loss: 0.7629, G loss: 1.6261\n",
      "[1204/1600] D loss: 0.7099, G loss: 1.4279\n",
      "[1324/1600] D loss: 1.6730, G loss: 0.9134\n",
      "[1444/1600] D loss: 0.8546, G loss: 1.0687\n",
      "[1564/1600] D loss: 1.0692, G loss: 0.9588\n",
      "train error: \n",
      " D loss: 1.066112, G loss: 1.750596, D accuracy: 72.2%, cell accuracy: 97.8%, board accuracy: 4.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.151321, G loss: 1.851469, D accuracy: 70.6%, cell accuracy: 97.7%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0767, G loss: 1.4388\n",
      "[124/1600] D loss: 0.7960, G loss: 1.3620\n",
      "[244/1600] D loss: 0.8260, G loss: 1.5913\n",
      "[364/1600] D loss: 1.4310, G loss: 0.5654\n",
      "[484/1600] D loss: 1.1333, G loss: 1.1378\n",
      "[604/1600] D loss: 0.8578, G loss: 2.2887\n",
      "[724/1600] D loss: 1.5917, G loss: 0.4708\n",
      "[844/1600] D loss: 0.8927, G loss: 1.2959\n",
      "[964/1600] D loss: 0.9852, G loss: 1.4915\n",
      "[1084/1600] D loss: 1.1283, G loss: 1.4007\n",
      "[1204/1600] D loss: 1.0870, G loss: 1.4006\n",
      "[1324/1600] D loss: 0.8737, G loss: 1.2582\n",
      "[1444/1600] D loss: 0.8798, G loss: 2.0603\n",
      "[1564/1600] D loss: 0.2481, G loss: 2.2868\n",
      "train error: \n",
      " D loss: 0.969868, G loss: 1.275256, D accuracy: 76.2%, cell accuracy: 97.9%, board accuracy: 6.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.057867, G loss: 1.310143, D accuracy: 73.1%, cell accuracy: 97.8%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5385, G loss: 1.7280\n",
      "[124/1600] D loss: 1.4040, G loss: 0.7905\n",
      "[244/1600] D loss: 0.7293, G loss: 1.4198\n",
      "[364/1600] D loss: 0.9485, G loss: 1.5324\n",
      "[484/1600] D loss: 0.7234, G loss: 1.1881\n",
      "[604/1600] D loss: 1.1336, G loss: 0.9802\n",
      "[724/1600] D loss: 1.3623, G loss: 1.1649\n",
      "[844/1600] D loss: 1.0583, G loss: 1.2258\n",
      "[964/1600] D loss: 0.8882, G loss: 1.0320\n",
      "[1084/1600] D loss: 1.6497, G loss: 0.9247\n",
      "[1204/1600] D loss: 1.0520, G loss: 1.0692\n",
      "[1324/1600] D loss: 1.3633, G loss: 1.3082\n",
      "[1444/1600] D loss: 0.5728, G loss: 1.1471\n",
      "[1564/1600] D loss: 0.3120, G loss: 1.8370\n",
      "train error: \n",
      " D loss: 0.957565, G loss: 1.424632, D accuracy: 76.3%, cell accuracy: 97.8%, board accuracy: 5.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.047838, G loss: 1.521440, D accuracy: 72.8%, cell accuracy: 97.6%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4465, G loss: 2.4556\n",
      "[124/1600] D loss: 0.6447, G loss: 2.0088\n",
      "[244/1600] D loss: 1.0411, G loss: 1.6444\n",
      "[364/1600] D loss: 0.9836, G loss: 1.3728\n",
      "[484/1600] D loss: 0.7082, G loss: 1.2866\n",
      "[604/1600] D loss: 0.6350, G loss: 1.3657\n",
      "[724/1600] D loss: 1.3573, G loss: 0.8823\n",
      "[844/1600] D loss: 0.7890, G loss: 1.4324\n",
      "[964/1600] D loss: 1.0686, G loss: 1.3880\n",
      "[1084/1600] D loss: 0.3756, G loss: 2.7916\n",
      "[1204/1600] D loss: 0.9589, G loss: 1.1033\n",
      "[1324/1600] D loss: 1.0655, G loss: 0.6605\n",
      "[1444/1600] D loss: 1.1510, G loss: 1.2883\n",
      "[1564/1600] D loss: 0.7707, G loss: 2.2656\n",
      "train error: \n",
      " D loss: 0.938958, G loss: 1.451248, D accuracy: 77.2%, cell accuracy: 97.8%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.015729, G loss: 1.557539, D accuracy: 75.2%, cell accuracy: 97.6%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3161, G loss: 1.2425\n",
      "[124/1600] D loss: 0.5866, G loss: 1.5724\n",
      "[244/1600] D loss: 0.9206, G loss: 1.4452\n",
      "[364/1600] D loss: 0.7303, G loss: 1.0848\n",
      "[484/1600] D loss: 1.2572, G loss: 1.2700\n",
      "[604/1600] D loss: 1.4253, G loss: 1.0335\n",
      "[724/1600] D loss: 0.9566, G loss: 1.0430\n",
      "[844/1600] D loss: 0.8690, G loss: 1.7802\n",
      "[964/1600] D loss: 0.5595, G loss: 2.3090\n",
      "[1084/1600] D loss: 0.8107, G loss: 1.8841\n",
      "[1204/1600] D loss: 0.7891, G loss: 1.4390\n",
      "[1324/1600] D loss: 1.3569, G loss: 1.1967\n",
      "[1444/1600] D loss: 0.7767, G loss: 1.5509\n",
      "[1564/1600] D loss: 1.1895, G loss: 0.7617\n",
      "train error: \n",
      " D loss: 0.931299, G loss: 1.295684, D accuracy: 76.8%, cell accuracy: 97.9%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.000476, G loss: 1.388095, D accuracy: 74.2%, cell accuracy: 97.7%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4226, G loss: 2.1153\n",
      "[124/1600] D loss: 0.8581, G loss: 1.5720\n",
      "[244/1600] D loss: 0.7417, G loss: 1.3801\n",
      "[364/1600] D loss: 0.9999, G loss: 1.8943\n",
      "[484/1600] D loss: 0.6660, G loss: 1.5990\n",
      "[604/1600] D loss: 1.3803, G loss: 0.9109\n",
      "[724/1600] D loss: 0.5076, G loss: 2.6129\n",
      "[844/1600] D loss: 1.3924, G loss: 0.7496\n",
      "[964/1600] D loss: 1.0893, G loss: 0.9675\n",
      "[1084/1600] D loss: 1.0432, G loss: 1.7070\n",
      "[1204/1600] D loss: 0.8732, G loss: 2.2310\n",
      "[1324/1600] D loss: 0.7005, G loss: 2.0007\n",
      "[1444/1600] D loss: 0.7420, G loss: 0.8015\n",
      "[1564/1600] D loss: 0.7904, G loss: 1.1781\n",
      "train error: \n",
      " D loss: 0.993504, G loss: 1.795792, D accuracy: 74.9%, cell accuracy: 97.9%, board accuracy: 9.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.106675, G loss: 1.854993, D accuracy: 72.2%, cell accuracy: 97.7%, board accuracy: 8.8% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4540, G loss: 1.5779\n",
      "[124/1600] D loss: 1.1734, G loss: 1.6724\n",
      "[244/1600] D loss: 1.3220, G loss: 0.8226\n",
      "[364/1600] D loss: 1.3444, G loss: 0.5188\n",
      "[484/1600] D loss: 0.8830, G loss: 1.3391\n",
      "[604/1600] D loss: 0.6937, G loss: 2.1375\n",
      "[724/1600] D loss: 0.2921, G loss: 2.3333\n",
      "[844/1600] D loss: 1.5430, G loss: 0.6279\n",
      "[964/1600] D loss: 0.8708, G loss: 1.7865\n",
      "[1084/1600] D loss: 0.5357, G loss: 2.2473\n",
      "[1204/1600] D loss: 0.7498, G loss: 1.6713\n",
      "[1324/1600] D loss: 0.7037, G loss: 1.8701\n",
      "[1444/1600] D loss: 1.1092, G loss: 1.0665\n",
      "[1564/1600] D loss: 0.6550, G loss: 1.4143\n",
      "train error: \n",
      " D loss: 1.024611, G loss: 1.047145, D accuracy: 72.6%, cell accuracy: 97.8%, board accuracy: 8.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.079734, G loss: 1.142187, D accuracy: 70.4%, cell accuracy: 97.6%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8096, G loss: 1.5493\n",
      "[124/1600] D loss: 0.4331, G loss: 2.2538\n",
      "[244/1600] D loss: 1.0918, G loss: 0.9831\n",
      "[364/1600] D loss: 0.3188, G loss: 2.9065\n",
      "[484/1600] D loss: 0.8381, G loss: 1.1898\n",
      "[604/1600] D loss: 0.8986, G loss: 2.3155\n",
      "[724/1600] D loss: 0.8219, G loss: 1.4123\n",
      "[844/1600] D loss: 0.3168, G loss: 2.5559\n",
      "[964/1600] D loss: 1.1091, G loss: 1.1822\n",
      "[1084/1600] D loss: 1.2980, G loss: 1.1504\n",
      "[1204/1600] D loss: 1.1702, G loss: 0.7362\n",
      "[1324/1600] D loss: 1.0526, G loss: 1.0195\n",
      "[1444/1600] D loss: 0.7577, G loss: 1.3665\n",
      "[1564/1600] D loss: 0.7549, G loss: 1.2799\n",
      "train error: \n",
      " D loss: 0.935035, G loss: 1.311321, D accuracy: 76.7%, cell accuracy: 97.9%, board accuracy: 8.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.014351, G loss: 1.406563, D accuracy: 74.4%, cell accuracy: 97.8%, board accuracy: 8.5% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5137, G loss: 2.2310\n",
      "[124/1600] D loss: 1.0897, G loss: 0.9401\n",
      "[244/1600] D loss: 0.9635, G loss: 1.5358\n",
      "[364/1600] D loss: 1.2011, G loss: 1.1638\n",
      "[484/1600] D loss: 1.2975, G loss: 1.8795\n",
      "[604/1600] D loss: 1.4030, G loss: 2.1106\n",
      "[724/1600] D loss: 1.4702, G loss: 0.6171\n",
      "[844/1600] D loss: 1.0310, G loss: 1.4613\n",
      "[964/1600] D loss: 0.6493, G loss: 1.5138\n",
      "[1084/1600] D loss: 1.0604, G loss: 0.8920\n",
      "[1204/1600] D loss: 1.1088, G loss: 2.0041\n",
      "[1324/1600] D loss: 0.5465, G loss: 1.9454\n",
      "[1444/1600] D loss: 0.9890, G loss: 0.9506\n",
      "[1564/1600] D loss: 1.2901, G loss: 1.0894\n",
      "train error: \n",
      " D loss: 0.929506, G loss: 1.587288, D accuracy: 76.1%, cell accuracy: 97.9%, board accuracy: 9.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999011, G loss: 1.730115, D accuracy: 75.1%, cell accuracy: 97.8%, board accuracy: 9.0% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6220, G loss: 2.4722\n",
      "[124/1600] D loss: 0.7495, G loss: 1.0411\n",
      "[244/1600] D loss: 0.2563, G loss: 2.2371\n",
      "[364/1600] D loss: 0.7290, G loss: 1.8463\n",
      "[484/1600] D loss: 0.7491, G loss: 1.6781\n",
      "[604/1600] D loss: 0.6260, G loss: 1.7749\n",
      "[724/1600] D loss: 1.5415, G loss: 1.2370\n",
      "[844/1600] D loss: 0.9380, G loss: 1.1097\n",
      "[964/1600] D loss: 1.2436, G loss: 0.9924\n",
      "[1084/1600] D loss: 0.9994, G loss: 2.0389\n",
      "[1204/1600] D loss: 0.9371, G loss: 1.6196\n",
      "[1324/1600] D loss: 0.7011, G loss: 2.5846\n",
      "[1444/1600] D loss: 0.7617, G loss: 1.2499\n",
      "[1564/1600] D loss: 0.8351, G loss: 1.0318\n",
      "train error: \n",
      " D loss: 0.955995, G loss: 1.548714, D accuracy: 75.4%, cell accuracy: 97.9%, board accuracy: 9.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.056346, G loss: 1.668189, D accuracy: 72.5%, cell accuracy: 97.7%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9135, G loss: 1.3328\n",
      "[124/1600] D loss: 0.6874, G loss: 1.2859\n",
      "[244/1600] D loss: 1.0639, G loss: 1.9073\n",
      "[364/1600] D loss: 0.9118, G loss: 0.9686\n",
      "[484/1600] D loss: 0.7634, G loss: 1.2982\n",
      "[604/1600] D loss: 0.9102, G loss: 0.8200\n",
      "[724/1600] D loss: 1.0640, G loss: 1.4628\n",
      "[844/1600] D loss: 0.7012, G loss: 1.3755\n",
      "[964/1600] D loss: 1.1727, G loss: 0.7140\n",
      "[1084/1600] D loss: 2.2401, G loss: 0.5965\n",
      "[1204/1600] D loss: 0.7460, G loss: 2.4639\n",
      "[1324/1600] D loss: 0.5669, G loss: 2.1172\n",
      "[1444/1600] D loss: 1.3072, G loss: 2.0761\n",
      "[1564/1600] D loss: 0.6218, G loss: 2.8719\n",
      "train error: \n",
      " D loss: 0.958207, G loss: 1.213090, D accuracy: 75.2%, cell accuracy: 97.9%, board accuracy: 10.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.031541, G loss: 1.323039, D accuracy: 73.8%, cell accuracy: 97.8%, board accuracy: 10.2% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1956, G loss: 0.8080\n",
      "[124/1600] D loss: 1.0336, G loss: 1.0310\n",
      "[244/1600] D loss: 1.0389, G loss: 1.4870\n",
      "[364/1600] D loss: 0.8432, G loss: 1.3971\n",
      "[484/1600] D loss: 1.2562, G loss: 0.9738\n",
      "[604/1600] D loss: 1.8340, G loss: 0.9492\n",
      "[724/1600] D loss: 0.7221, G loss: 1.1612\n",
      "[844/1600] D loss: 0.7140, G loss: 1.8463\n",
      "[964/1600] D loss: 1.1716, G loss: 1.1104\n",
      "[1084/1600] D loss: 1.1488, G loss: 1.2094\n",
      "[1204/1600] D loss: 0.9490, G loss: 1.7295\n",
      "[1324/1600] D loss: 1.2442, G loss: 0.6851\n",
      "[1444/1600] D loss: 1.0928, G loss: 0.8096\n",
      "[1564/1600] D loss: 0.9815, G loss: 1.9726\n",
      "train error: \n",
      " D loss: 1.047668, G loss: 0.955040, D accuracy: 71.3%, cell accuracy: 97.8%, board accuracy: 9.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.084177, G loss: 1.085975, D accuracy: 71.8%, cell accuracy: 97.6%, board accuracy: 9.8% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9140, G loss: 1.0374\n",
      "[124/1600] D loss: 1.7132, G loss: 0.6280\n",
      "[244/1600] D loss: 0.6843, G loss: 1.1057\n",
      "[364/1600] D loss: 1.1177, G loss: 1.5645\n",
      "[484/1600] D loss: 0.8981, G loss: 1.7719\n",
      "[604/1600] D loss: 0.7306, G loss: 1.7035\n",
      "[724/1600] D loss: 1.0572, G loss: 1.2758\n",
      "[844/1600] D loss: 1.1749, G loss: 2.2260\n",
      "[964/1600] D loss: 1.3196, G loss: 0.6028\n",
      "[1084/1600] D loss: 0.5731, G loss: 2.3536\n",
      "[1204/1600] D loss: 1.2062, G loss: 1.8990\n",
      "[1324/1600] D loss: 1.0381, G loss: 1.0544\n",
      "[1444/1600] D loss: 0.2166, G loss: 2.8304\n",
      "[1564/1600] D loss: 0.8889, G loss: 1.1067\n",
      "train error: \n",
      " D loss: 0.945265, G loss: 1.308241, D accuracy: 75.3%, cell accuracy: 97.9%, board accuracy: 9.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.019999, G loss: 1.464661, D accuracy: 74.0%, cell accuracy: 97.7%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7936, G loss: 1.2308\n",
      "[124/1600] D loss: 0.9229, G loss: 1.5767\n",
      "[244/1600] D loss: 0.7345, G loss: 1.7681\n",
      "[364/1600] D loss: 0.6930, G loss: 1.2227\n",
      "[484/1600] D loss: 1.1852, G loss: 0.9650\n",
      "[604/1600] D loss: 0.9425, G loss: 1.3970\n",
      "[724/1600] D loss: 1.4495, G loss: 2.1092\n",
      "[844/1600] D loss: 1.3624, G loss: 0.7979\n",
      "[964/1600] D loss: 0.4566, G loss: 1.4854\n",
      "[1084/1600] D loss: 0.3215, G loss: 1.9144\n",
      "[1204/1600] D loss: 1.2139, G loss: 1.2047\n",
      "[1324/1600] D loss: 0.3860, G loss: 1.6820\n",
      "[1444/1600] D loss: 0.7650, G loss: 2.3748\n",
      "[1564/1600] D loss: 0.6858, G loss: 1.2042\n",
      "train error: \n",
      " D loss: 0.939694, G loss: 1.650399, D accuracy: 75.4%, cell accuracy: 97.9%, board accuracy: 11.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.002336, G loss: 1.825109, D accuracy: 74.8%, cell accuracy: 97.8%, board accuracy: 11.2% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6349, G loss: 2.9383\n",
      "[124/1600] D loss: 0.7093, G loss: 1.5525\n",
      "[244/1600] D loss: 0.9938, G loss: 0.8153\n",
      "[364/1600] D loss: 0.6371, G loss: 1.9410\n",
      "[484/1600] D loss: 0.4312, G loss: 2.1634\n",
      "[604/1600] D loss: 0.8481, G loss: 1.8552\n",
      "[724/1600] D loss: 1.0003, G loss: 1.1143\n",
      "[844/1600] D loss: 0.4858, G loss: 2.1795\n",
      "[964/1600] D loss: 0.7389, G loss: 1.4662\n",
      "[1084/1600] D loss: 1.1406, G loss: 0.6564\n",
      "[1204/1600] D loss: 1.0215, G loss: 1.5259\n",
      "[1324/1600] D loss: 0.6191, G loss: 2.0033\n",
      "[1444/1600] D loss: 0.6099, G loss: 1.8565\n",
      "[1564/1600] D loss: 1.0923, G loss: 1.3709\n",
      "train error: \n",
      " D loss: 0.936889, G loss: 1.733472, D accuracy: 76.2%, cell accuracy: 97.9%, board accuracy: 10.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.028951, G loss: 1.905492, D accuracy: 73.4%, cell accuracy: 97.8%, board accuracy: 11.8% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2871, G loss: 2.5304\n",
      "[124/1600] D loss: 0.5863, G loss: 1.2186\n",
      "[244/1600] D loss: 0.8375, G loss: 1.3448\n",
      "[364/1600] D loss: 0.7378, G loss: 1.5203\n",
      "[484/1600] D loss: 0.9959, G loss: 1.3151\n",
      "[604/1600] D loss: 1.1163, G loss: 1.2233\n",
      "[724/1600] D loss: 1.5100, G loss: 0.6215\n",
      "[844/1600] D loss: 1.1004, G loss: 2.1798\n",
      "[964/1600] D loss: 0.8093, G loss: 2.0342\n",
      "[1084/1600] D loss: 0.7587, G loss: 2.5381\n",
      "[1204/1600] D loss: 1.0807, G loss: 1.3827\n",
      "[1324/1600] D loss: 0.9580, G loss: 1.0102\n",
      "[1444/1600] D loss: 0.5004, G loss: 1.3828\n",
      "[1564/1600] D loss: 1.1343, G loss: 1.4670\n",
      "train error: \n",
      " D loss: 1.014593, G loss: 0.983847, D accuracy: 72.3%, cell accuracy: 97.9%, board accuracy: 10.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.038569, G loss: 1.099203, D accuracy: 71.1%, cell accuracy: 97.8%, board accuracy: 12.0% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2165, G loss: 2.2396\n",
      "[124/1600] D loss: 0.6771, G loss: 1.8352\n",
      "[244/1600] D loss: 0.7674, G loss: 2.1268\n",
      "[364/1600] D loss: 0.7152, G loss: 1.6717\n",
      "[484/1600] D loss: 0.7441, G loss: 1.1340\n",
      "[604/1600] D loss: 0.7392, G loss: 1.6291\n",
      "[724/1600] D loss: 1.5258, G loss: 0.7961\n",
      "[844/1600] D loss: 1.1988, G loss: 1.3164\n",
      "[964/1600] D loss: 0.9927, G loss: 1.4136\n",
      "[1084/1600] D loss: 0.7927, G loss: 1.2530\n",
      "[1204/1600] D loss: 0.7580, G loss: 1.0904\n",
      "[1324/1600] D loss: 0.7890, G loss: 1.6067\n",
      "[1444/1600] D loss: 0.7273, G loss: 2.0533\n",
      "[1564/1600] D loss: 0.9365, G loss: 0.7315\n",
      "train error: \n",
      " D loss: 0.954117, G loss: 1.894070, D accuracy: 74.9%, cell accuracy: 97.9%, board accuracy: 9.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.030825, G loss: 2.070653, D accuracy: 73.6%, cell accuracy: 97.8%, board accuracy: 10.2% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8609, G loss: 1.1042\n",
      "[124/1600] D loss: 0.6246, G loss: 1.2415\n",
      "[244/1600] D loss: 1.0180, G loss: 0.7801\n",
      "[364/1600] D loss: 0.5194, G loss: 1.3942\n",
      "[484/1600] D loss: 1.1794, G loss: 1.3386\n",
      "[604/1600] D loss: 1.2131, G loss: 1.3042\n",
      "[724/1600] D loss: 1.1509, G loss: 1.0757\n",
      "[844/1600] D loss: 0.6815, G loss: 2.1316\n",
      "[964/1600] D loss: 1.0764, G loss: 1.0576\n",
      "[1084/1600] D loss: 0.6752, G loss: 1.7848\n",
      "[1204/1600] D loss: 1.0479, G loss: 1.8441\n",
      "[1324/1600] D loss: 1.1486, G loss: 1.9632\n",
      "[1444/1600] D loss: 1.2853, G loss: 1.3320\n",
      "[1564/1600] D loss: 0.9965, G loss: 3.7079\n",
      "train error: \n",
      " D loss: 0.923194, G loss: 1.290253, D accuracy: 76.7%, cell accuracy: 97.9%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.974735, G loss: 1.420961, D accuracy: 75.9%, cell accuracy: 97.9%, board accuracy: 12.5% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0468, G loss: 0.9351\n",
      "[124/1600] D loss: 0.9524, G loss: 1.3965\n",
      "[244/1600] D loss: 0.6818, G loss: 0.9994\n",
      "[364/1600] D loss: 1.1818, G loss: 0.8993\n",
      "[484/1600] D loss: 1.5627, G loss: 1.4977\n",
      "[604/1600] D loss: 0.7304, G loss: 1.4597\n",
      "[724/1600] D loss: 1.2325, G loss: 1.6327\n",
      "[844/1600] D loss: 0.9002, G loss: 1.6029\n",
      "[964/1600] D loss: 1.1144, G loss: 0.7076\n",
      "[1084/1600] D loss: 0.7321, G loss: 1.7266\n",
      "[1204/1600] D loss: 0.7150, G loss: 1.6414\n",
      "[1324/1600] D loss: 1.1010, G loss: 1.6300\n",
      "[1444/1600] D loss: 0.5828, G loss: 1.8390\n",
      "[1564/1600] D loss: 0.6340, G loss: 1.8532\n",
      "train error: \n",
      " D loss: 0.889980, G loss: 1.341139, D accuracy: 76.5%, cell accuracy: 97.9%, board accuracy: 12.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.969903, G loss: 1.457546, D accuracy: 74.2%, cell accuracy: 97.8%, board accuracy: 13.8% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4156, G loss: 1.2974\n",
      "[124/1600] D loss: 0.7846, G loss: 1.8526\n",
      "[244/1600] D loss: 0.6474, G loss: 1.0056\n",
      "[364/1600] D loss: 0.9376, G loss: 1.9087\n",
      "[484/1600] D loss: 0.8675, G loss: 1.2749\n",
      "[604/1600] D loss: 1.4314, G loss: 0.7630\n",
      "[724/1600] D loss: 0.7433, G loss: 1.2318\n",
      "[844/1600] D loss: 0.6871, G loss: 1.5921\n",
      "[964/1600] D loss: 1.1108, G loss: 1.0448\n",
      "[1084/1600] D loss: 1.5027, G loss: 0.4823\n",
      "[1204/1600] D loss: 0.7395, G loss: 1.4484\n",
      "[1324/1600] D loss: 0.5579, G loss: 1.8073\n",
      "[1444/1600] D loss: 0.7845, G loss: 1.5237\n",
      "[1564/1600] D loss: 0.9828, G loss: 1.0988\n",
      "train error: \n",
      " D loss: 0.882869, G loss: 1.414872, D accuracy: 77.0%, cell accuracy: 98.0%, board accuracy: 11.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.974694, G loss: 1.516280, D accuracy: 74.6%, cell accuracy: 97.9%, board accuracy: 13.2% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0862, G loss: 1.0689\n",
      "[124/1600] D loss: 1.0167, G loss: 0.8563\n",
      "[244/1600] D loss: 1.1712, G loss: 0.6241\n",
      "[364/1600] D loss: 0.5829, G loss: 1.8310\n",
      "[484/1600] D loss: 1.1153, G loss: 1.8374\n",
      "[604/1600] D loss: 1.4809, G loss: 1.7386\n",
      "[724/1600] D loss: 1.0765, G loss: 1.0381\n",
      "[844/1600] D loss: 0.5638, G loss: 1.6204\n",
      "[964/1600] D loss: 1.3076, G loss: 0.7021\n",
      "[1084/1600] D loss: 1.1333, G loss: 1.0273\n",
      "[1204/1600] D loss: 0.8954, G loss: 2.8789\n",
      "[1324/1600] D loss: 1.0467, G loss: 1.2968\n",
      "[1444/1600] D loss: 0.9694, G loss: 1.6114\n",
      "[1564/1600] D loss: 1.2182, G loss: 1.2301\n",
      "train error: \n",
      " D loss: 0.892603, G loss: 1.600729, D accuracy: 76.9%, cell accuracy: 98.0%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.991555, G loss: 1.729445, D accuracy: 73.8%, cell accuracy: 97.9%, board accuracy: 13.0% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9162, G loss: 1.5131\n",
      "[124/1600] D loss: 0.8752, G loss: 1.5418\n",
      "[244/1600] D loss: 0.5715, G loss: 2.2619\n",
      "[364/1600] D loss: 0.4904, G loss: 2.1900\n",
      "[484/1600] D loss: 0.9924, G loss: 1.0893\n",
      "[604/1600] D loss: 1.4008, G loss: 1.9776\n",
      "[724/1600] D loss: 0.4465, G loss: 2.3543\n",
      "[844/1600] D loss: 0.8337, G loss: 1.4222\n",
      "[964/1600] D loss: 0.6896, G loss: 1.8059\n",
      "[1084/1600] D loss: 0.4588, G loss: 1.9921\n",
      "[1204/1600] D loss: 0.5489, G loss: 2.0379\n",
      "[1324/1600] D loss: 1.6042, G loss: 0.7126\n",
      "[1444/1600] D loss: 1.0357, G loss: 2.3887\n",
      "[1564/1600] D loss: 1.0598, G loss: 1.1663\n",
      "train error: \n",
      " D loss: 0.902095, G loss: 1.744205, D accuracy: 77.4%, cell accuracy: 98.0%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.019725, G loss: 1.861065, D accuracy: 74.1%, cell accuracy: 97.9%, board accuracy: 15.8% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7494, G loss: 2.2671\n",
      "[124/1600] D loss: 0.5663, G loss: 1.8793\n",
      "[244/1600] D loss: 1.4620, G loss: 2.1257\n",
      "[364/1600] D loss: 1.0894, G loss: 1.0778\n",
      "[484/1600] D loss: 0.4855, G loss: 1.3924\n",
      "[604/1600] D loss: 0.9280, G loss: 2.2617\n",
      "[724/1600] D loss: 1.0675, G loss: 1.6258\n",
      "[844/1600] D loss: 1.2621, G loss: 0.8166\n",
      "[964/1600] D loss: 1.3069, G loss: 1.2965\n",
      "[1084/1600] D loss: 1.5278, G loss: 1.1291\n",
      "[1204/1600] D loss: 0.4772, G loss: 2.1015\n",
      "[1324/1600] D loss: 0.7082, G loss: 1.6035\n",
      "[1444/1600] D loss: 1.3367, G loss: 0.5215\n",
      "[1564/1600] D loss: 0.3943, G loss: 2.1376\n",
      "train error: \n",
      " D loss: 0.904519, G loss: 1.286530, D accuracy: 76.7%, cell accuracy: 97.9%, board accuracy: 12.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.006836, G loss: 1.420566, D accuracy: 74.2%, cell accuracy: 97.8%, board accuracy: 14.8% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7330, G loss: 1.9729\n",
      "[124/1600] D loss: 1.2553, G loss: 1.5282\n",
      "[244/1600] D loss: 0.5321, G loss: 2.3657\n",
      "[364/1600] D loss: 0.4343, G loss: 2.2547\n",
      "[484/1600] D loss: 1.1586, G loss: 1.0503\n",
      "[604/1600] D loss: 0.4189, G loss: 1.7342\n",
      "[724/1600] D loss: 1.0080, G loss: 0.9316\n",
      "[844/1600] D loss: 0.5497, G loss: 2.0709\n",
      "[964/1600] D loss: 0.4551, G loss: 2.4431\n",
      "[1084/1600] D loss: 0.2966, G loss: 2.0920\n",
      "[1204/1600] D loss: 0.2310, G loss: 2.1207\n",
      "[1324/1600] D loss: 0.6814, G loss: 1.4324\n",
      "[1444/1600] D loss: 1.1477, G loss: 0.6317\n",
      "[1564/1600] D loss: 0.6528, G loss: 1.9442\n",
      "train error: \n",
      " D loss: 0.856689, G loss: 1.484749, D accuracy: 78.7%, cell accuracy: 98.0%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.964071, G loss: 1.604644, D accuracy: 74.4%, cell accuracy: 97.9%, board accuracy: 14.2% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9156, G loss: 1.8866\n",
      "[124/1600] D loss: 0.4412, G loss: 2.1341\n",
      "[244/1600] D loss: 0.9410, G loss: 2.6635\n",
      "[364/1600] D loss: 1.4024, G loss: 0.9986\n",
      "[484/1600] D loss: 0.8929, G loss: 1.7138\n",
      "[604/1600] D loss: 0.7940, G loss: 1.5608\n",
      "[724/1600] D loss: 0.5982, G loss: 2.3046\n",
      "[844/1600] D loss: 0.5955, G loss: 2.1786\n",
      "[964/1600] D loss: 0.8916, G loss: 1.0988\n",
      "[1084/1600] D loss: 0.8639, G loss: 1.1284\n",
      "[1204/1600] D loss: 1.3682, G loss: 0.8010\n",
      "[1324/1600] D loss: 0.7283, G loss: 1.4236\n",
      "[1444/1600] D loss: 0.8623, G loss: 2.2051\n",
      "[1564/1600] D loss: 0.8150, G loss: 0.9216\n",
      "train error: \n",
      " D loss: 0.946194, G loss: 2.189091, D accuracy: 75.3%, cell accuracy: 98.0%, board accuracy: 12.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.097675, G loss: 2.349008, D accuracy: 71.6%, cell accuracy: 97.8%, board accuracy: 12.8% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5255, G loss: 1.8948\n",
      "[124/1600] D loss: 0.6163, G loss: 1.4207\n",
      "[244/1600] D loss: 0.6847, G loss: 2.0643\n",
      "[364/1600] D loss: 1.0658, G loss: 1.0047\n",
      "[484/1600] D loss: 0.9187, G loss: 2.2283\n",
      "[604/1600] D loss: 1.0496, G loss: 0.8632\n",
      "[724/1600] D loss: 0.4329, G loss: 2.1075\n",
      "[844/1600] D loss: 0.8389, G loss: 1.5601\n",
      "[964/1600] D loss: 0.6912, G loss: 1.8066\n",
      "[1084/1600] D loss: 0.5884, G loss: 1.8204\n",
      "[1204/1600] D loss: 0.8105, G loss: 1.8708\n",
      "[1324/1600] D loss: 0.8044, G loss: 2.3560\n",
      "[1444/1600] D loss: 0.8318, G loss: 2.2311\n",
      "[1564/1600] D loss: 0.5680, G loss: 2.6420\n",
      "train error: \n",
      " D loss: 0.890061, G loss: 1.281088, D accuracy: 76.0%, cell accuracy: 98.0%, board accuracy: 13.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.961282, G loss: 1.395572, D accuracy: 72.4%, cell accuracy: 97.9%, board accuracy: 13.8% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9250, G loss: 1.1567\n",
      "[124/1600] D loss: 0.7641, G loss: 1.5900\n",
      "[244/1600] D loss: 0.2936, G loss: 2.3190\n",
      "[364/1600] D loss: 1.3609, G loss: 0.7148\n",
      "[484/1600] D loss: 1.2469, G loss: 0.9177\n",
      "[604/1600] D loss: 0.2844, G loss: 2.3999\n",
      "[724/1600] D loss: 0.9617, G loss: 1.3684\n",
      "[844/1600] D loss: 1.2655, G loss: 0.7943\n",
      "[964/1600] D loss: 0.3449, G loss: 2.8732\n",
      "[1084/1600] D loss: 0.7783, G loss: 1.6724\n",
      "[1204/1600] D loss: 0.5848, G loss: 2.8206\n",
      "[1324/1600] D loss: 0.7583, G loss: 1.0175\n",
      "[1444/1600] D loss: 0.7634, G loss: 1.8860\n",
      "[1564/1600] D loss: 0.8241, G loss: 1.8221\n",
      "train error: \n",
      " D loss: 0.878264, G loss: 1.437994, D accuracy: 77.2%, cell accuracy: 98.0%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.970109, G loss: 1.586188, D accuracy: 73.8%, cell accuracy: 97.9%, board accuracy: 17.0% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8211, G loss: 1.8021\n",
      "[124/1600] D loss: 0.7430, G loss: 1.5438\n",
      "[244/1600] D loss: 0.8090, G loss: 1.3925\n",
      "[364/1600] D loss: 0.8091, G loss: 1.2046\n",
      "[484/1600] D loss: 1.0267, G loss: 1.3378\n",
      "[604/1600] D loss: 0.7897, G loss: 1.4556\n",
      "[724/1600] D loss: 1.3234, G loss: 1.6526\n",
      "[844/1600] D loss: 1.1313, G loss: 1.0959\n",
      "[964/1600] D loss: 0.7204, G loss: 1.4656\n",
      "[1084/1600] D loss: 0.6923, G loss: 1.4526\n",
      "[1204/1600] D loss: 1.5752, G loss: 1.9064\n",
      "[1324/1600] D loss: 1.0634, G loss: 1.2771\n",
      "[1444/1600] D loss: 0.9379, G loss: 1.9369\n",
      "[1564/1600] D loss: 0.9749, G loss: 1.5586\n",
      "train error: \n",
      " D loss: 0.895357, G loss: 1.636089, D accuracy: 76.3%, cell accuracy: 98.0%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.988550, G loss: 1.832018, D accuracy: 74.8%, cell accuracy: 97.9%, board accuracy: 14.5% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0512, G loss: 0.8991\n",
      "[124/1600] D loss: 0.5877, G loss: 2.5944\n",
      "[244/1600] D loss: 1.5284, G loss: 1.9052\n",
      "[364/1600] D loss: 0.7327, G loss: 2.2319\n",
      "[484/1600] D loss: 1.5905, G loss: 0.3257\n",
      "[604/1600] D loss: 0.7961, G loss: 1.9949\n",
      "[724/1600] D loss: 0.7378, G loss: 2.0234\n",
      "[844/1600] D loss: 0.8083, G loss: 1.0672\n",
      "[964/1600] D loss: 1.6239, G loss: 0.8507\n",
      "[1084/1600] D loss: 0.7861, G loss: 2.2001\n",
      "[1204/1600] D loss: 1.1787, G loss: 2.6652\n",
      "[1324/1600] D loss: 0.7132, G loss: 1.6705\n",
      "[1444/1600] D loss: 1.1552, G loss: 1.0527\n",
      "[1564/1600] D loss: 1.1949, G loss: 1.9955\n",
      "train error: \n",
      " D loss: 0.846394, G loss: 1.723347, D accuracy: 77.9%, cell accuracy: 98.0%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.963323, G loss: 1.879824, D accuracy: 73.5%, cell accuracy: 97.9%, board accuracy: 16.5% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8165, G loss: 1.5272\n",
      "[124/1600] D loss: 1.2350, G loss: 1.1990\n",
      "[244/1600] D loss: 0.5721, G loss: 3.1884\n",
      "[364/1600] D loss: 0.7460, G loss: 1.5122\n",
      "[484/1600] D loss: 0.7977, G loss: 1.0539\n",
      "[604/1600] D loss: 1.4637, G loss: 2.5165\n",
      "[724/1600] D loss: 0.4799, G loss: 1.6384\n",
      "[844/1600] D loss: 1.4473, G loss: 1.0086\n",
      "[964/1600] D loss: 1.0725, G loss: 1.1649\n",
      "[1084/1600] D loss: 0.8471, G loss: 1.7156\n",
      "[1204/1600] D loss: 0.8046, G loss: 0.8822\n",
      "[1324/1600] D loss: 0.4971, G loss: 2.1892\n",
      "[1444/1600] D loss: 0.6872, G loss: 2.1056\n",
      "[1564/1600] D loss: 1.0080, G loss: 1.6125\n",
      "train error: \n",
      " D loss: 0.846810, G loss: 1.665541, D accuracy: 78.8%, cell accuracy: 98.1%, board accuracy: 17.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.953792, G loss: 1.816235, D accuracy: 74.1%, cell accuracy: 98.0%, board accuracy: 16.5% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1597, G loss: 1.1538\n",
      "[124/1600] D loss: 0.8674, G loss: 0.9309\n",
      "[244/1600] D loss: 0.8214, G loss: 2.5069\n",
      "[364/1600] D loss: 1.0083, G loss: 2.5152\n",
      "[484/1600] D loss: 0.7015, G loss: 1.9129\n",
      "[604/1600] D loss: 0.4692, G loss: 2.9159\n",
      "[724/1600] D loss: 1.1629, G loss: 1.2048\n",
      "[844/1600] D loss: 0.4932, G loss: 2.0050\n",
      "[964/1600] D loss: 1.1279, G loss: 1.0505\n",
      "[1084/1600] D loss: 0.4925, G loss: 2.1251\n",
      "[1204/1600] D loss: 0.3568, G loss: 2.6687\n",
      "[1324/1600] D loss: 0.8353, G loss: 3.2643\n",
      "[1444/1600] D loss: 0.6781, G loss: 2.2265\n",
      "[1564/1600] D loss: 1.2682, G loss: 1.2000\n",
      "train error: \n",
      " D loss: 0.864722, G loss: 1.929144, D accuracy: 77.9%, cell accuracy: 98.1%, board accuracy: 15.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.989089, G loss: 2.089768, D accuracy: 75.4%, cell accuracy: 97.9%, board accuracy: 16.0% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4289, G loss: 1.4483\n",
      "[124/1600] D loss: 1.5211, G loss: 0.5228\n",
      "[244/1600] D loss: 0.5743, G loss: 1.4033\n",
      "[364/1600] D loss: 0.5663, G loss: 2.0934\n",
      "[484/1600] D loss: 0.8463, G loss: 2.5040\n",
      "[604/1600] D loss: 1.2969, G loss: 1.1953\n",
      "[724/1600] D loss: 0.4977, G loss: 2.0409\n",
      "[844/1600] D loss: 0.8958, G loss: 0.9106\n",
      "[964/1600] D loss: 1.2681, G loss: 1.4227\n",
      "[1084/1600] D loss: 0.8854, G loss: 0.9054\n",
      "[1204/1600] D loss: 0.6205, G loss: 1.9113\n",
      "[1324/1600] D loss: 1.7758, G loss: 0.7564\n",
      "[1444/1600] D loss: 0.5672, G loss: 1.4788\n",
      "[1564/1600] D loss: 0.9090, G loss: 1.6259\n",
      "train error: \n",
      " D loss: 0.840263, G loss: 1.837088, D accuracy: 78.0%, cell accuracy: 98.1%, board accuracy: 16.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.949588, G loss: 2.031462, D accuracy: 74.4%, cell accuracy: 97.9%, board accuracy: 17.2% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1341, G loss: 1.5014\n",
      "[124/1600] D loss: 0.5295, G loss: 2.2585\n",
      "[244/1600] D loss: 1.1142, G loss: 0.8992\n",
      "[364/1600] D loss: 0.2650, G loss: 2.2752\n",
      "[484/1600] D loss: 0.6214, G loss: 2.0062\n",
      "[604/1600] D loss: 0.9266, G loss: 1.3585\n",
      "[724/1600] D loss: 0.8660, G loss: 1.1931\n",
      "[844/1600] D loss: 1.0455, G loss: 2.3138\n",
      "[964/1600] D loss: 1.1372, G loss: 0.8337\n",
      "[1084/1600] D loss: 0.9080, G loss: 1.2802\n",
      "[1204/1600] D loss: 1.4300, G loss: 0.7046\n",
      "[1324/1600] D loss: 0.4786, G loss: 1.3379\n",
      "[1444/1600] D loss: 1.2698, G loss: 0.8510\n",
      "[1564/1600] D loss: 1.0951, G loss: 0.8501\n",
      "train error: \n",
      " D loss: 0.840315, G loss: 1.713322, D accuracy: 78.3%, cell accuracy: 98.1%, board accuracy: 17.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.912436, G loss: 1.887272, D accuracy: 75.2%, cell accuracy: 98.0%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6557, G loss: 1.5414\n",
      "[124/1600] D loss: 1.4813, G loss: 0.4212\n",
      "[244/1600] D loss: 0.1628, G loss: 2.8850\n",
      "[364/1600] D loss: 0.9747, G loss: 1.9976\n",
      "[484/1600] D loss: 0.8539, G loss: 2.1768\n",
      "[604/1600] D loss: 0.6761, G loss: 2.0591\n",
      "[724/1600] D loss: 0.7496, G loss: 2.1664\n",
      "[844/1600] D loss: 1.2486, G loss: 1.4481\n",
      "[964/1600] D loss: 0.7559, G loss: 2.7831\n",
      "[1084/1600] D loss: 1.6914, G loss: 1.2613\n",
      "[1204/1600] D loss: 0.7488, G loss: 1.7491\n",
      "[1324/1600] D loss: 0.7693, G loss: 1.5615\n",
      "[1444/1600] D loss: 1.0262, G loss: 1.5121\n",
      "[1564/1600] D loss: 0.2852, G loss: 1.6733\n",
      "train error: \n",
      " D loss: 0.889409, G loss: 2.170655, D accuracy: 76.0%, cell accuracy: 98.1%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.019188, G loss: 2.386892, D accuracy: 72.9%, cell accuracy: 97.9%, board accuracy: 16.2% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2031, G loss: 3.1602\n",
      "[124/1600] D loss: 0.5007, G loss: 4.1990\n",
      "[244/1600] D loss: 0.4299, G loss: 2.9303\n",
      "[364/1600] D loss: 0.5917, G loss: 1.9299\n",
      "[484/1600] D loss: 0.6006, G loss: 1.4363\n",
      "[604/1600] D loss: 0.4264, G loss: 1.6948\n",
      "[724/1600] D loss: 0.7135, G loss: 2.8229\n",
      "[844/1600] D loss: 0.8940, G loss: 1.3551\n",
      "[964/1600] D loss: 0.9672, G loss: 1.0303\n",
      "[1084/1600] D loss: 0.8228, G loss: 1.9289\n",
      "[1204/1600] D loss: 0.8360, G loss: 1.9257\n",
      "[1324/1600] D loss: 0.7155, G loss: 2.3561\n",
      "[1444/1600] D loss: 1.4050, G loss: 0.7927\n",
      "[1564/1600] D loss: 0.9817, G loss: 0.8734\n",
      "train error: \n",
      " D loss: 0.878736, G loss: 1.392177, D accuracy: 77.0%, cell accuracy: 98.1%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.921377, G loss: 1.583996, D accuracy: 74.9%, cell accuracy: 98.0%, board accuracy: 16.2% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3194, G loss: 0.6459\n",
      "[124/1600] D loss: 1.1912, G loss: 1.4202\n",
      "[244/1600] D loss: 1.1958, G loss: 0.6352\n",
      "[364/1600] D loss: 0.5736, G loss: 2.8817\n",
      "[484/1600] D loss: 0.9617, G loss: 1.4984\n",
      "[604/1600] D loss: 0.3115, G loss: 2.1536\n",
      "[724/1600] D loss: 1.0636, G loss: 0.9715\n",
      "[844/1600] D loss: 0.6229, G loss: 1.5706\n",
      "[964/1600] D loss: 0.7050, G loss: 1.2061\n",
      "[1084/1600] D loss: 0.9806, G loss: 0.7443\n",
      "[1204/1600] D loss: 0.5620, G loss: 2.4698\n",
      "[1324/1600] D loss: 0.4784, G loss: 1.4701\n",
      "[1444/1600] D loss: 0.9287, G loss: 1.3594\n",
      "[1564/1600] D loss: 1.0311, G loss: 1.0855\n",
      "train error: \n",
      " D loss: 0.856317, G loss: 1.703524, D accuracy: 77.6%, cell accuracy: 98.1%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.934116, G loss: 1.883318, D accuracy: 76.2%, cell accuracy: 98.0%, board accuracy: 15.2% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3731, G loss: 2.8938\n",
      "[124/1600] D loss: 1.1149, G loss: 1.0715\n",
      "[244/1600] D loss: 1.3127, G loss: 0.8620\n",
      "[364/1600] D loss: 1.1326, G loss: 0.9560\n",
      "[484/1600] D loss: 0.4537, G loss: 1.9442\n",
      "[604/1600] D loss: 0.7816, G loss: 2.4347\n",
      "[724/1600] D loss: 1.1364, G loss: 1.5357\n",
      "[844/1600] D loss: 0.8508, G loss: 0.9704\n",
      "[964/1600] D loss: 0.6658, G loss: 1.0864\n",
      "[1084/1600] D loss: 0.1747, G loss: 3.0551\n",
      "[1204/1600] D loss: 1.3978, G loss: 1.5310\n",
      "[1324/1600] D loss: 0.9469, G loss: 1.6929\n",
      "[1444/1600] D loss: 0.6412, G loss: 1.6171\n",
      "[1564/1600] D loss: 1.1126, G loss: 1.8447\n",
      "train error: \n",
      " D loss: 0.840424, G loss: 1.500902, D accuracy: 78.2%, cell accuracy: 98.0%, board accuracy: 12.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.921357, G loss: 1.714999, D accuracy: 75.2%, cell accuracy: 97.9%, board accuracy: 13.2% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9479, G loss: 1.1972\n",
      "[124/1600] D loss: 1.1200, G loss: 1.0805\n",
      "[244/1600] D loss: 1.1075, G loss: 1.3398\n",
      "[364/1600] D loss: 1.0777, G loss: 0.5678\n",
      "[484/1600] D loss: 1.5966, G loss: 0.4108\n",
      "[604/1600] D loss: 0.8885, G loss: 1.2313\n",
      "[724/1600] D loss: 0.4464, G loss: 2.3224\n",
      "[844/1600] D loss: 1.0711, G loss: 0.5795\n",
      "[964/1600] D loss: 0.8648, G loss: 1.4387\n",
      "[1084/1600] D loss: 1.1817, G loss: 0.8906\n",
      "[1204/1600] D loss: 0.3698, G loss: 1.7919\n",
      "[1324/1600] D loss: 1.1555, G loss: 1.8890\n",
      "[1444/1600] D loss: 0.9002, G loss: 2.0896\n",
      "[1564/1600] D loss: 0.6788, G loss: 1.3946\n",
      "train error: \n",
      " D loss: 0.816990, G loss: 1.697079, D accuracy: 79.2%, cell accuracy: 98.1%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.895414, G loss: 1.867169, D accuracy: 77.1%, cell accuracy: 98.0%, board accuracy: 15.8% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5543, G loss: 2.4771\n",
      "[124/1600] D loss: 0.7317, G loss: 1.2576\n",
      "[244/1600] D loss: 1.4913, G loss: 0.6986\n",
      "[364/1600] D loss: 0.3175, G loss: 3.3773\n",
      "[484/1600] D loss: 0.5614, G loss: 1.4207\n",
      "[604/1600] D loss: 0.4556, G loss: 2.4235\n",
      "[724/1600] D loss: 1.2099, G loss: 1.1723\n",
      "[844/1600] D loss: 1.0907, G loss: 1.1688\n",
      "[964/1600] D loss: 0.9297, G loss: 1.5248\n",
      "[1084/1600] D loss: 0.2795, G loss: 2.6917\n",
      "[1204/1600] D loss: 0.3150, G loss: 3.1488\n",
      "[1324/1600] D loss: 1.3193, G loss: 0.9900\n",
      "[1444/1600] D loss: 1.1485, G loss: 0.9904\n",
      "[1564/1600] D loss: 0.4295, G loss: 1.7676\n",
      "train error: \n",
      " D loss: 0.892132, G loss: 1.294007, D accuracy: 76.0%, cell accuracy: 98.0%, board accuracy: 12.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.958751, G loss: 1.438959, D accuracy: 73.5%, cell accuracy: 98.0%, board accuracy: 13.2% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4618, G loss: 2.0215\n",
      "[124/1600] D loss: 1.0954, G loss: 1.7543\n",
      "[244/1600] D loss: 1.0454, G loss: 1.1789\n",
      "[364/1600] D loss: 1.1304, G loss: 2.0249\n",
      "[484/1600] D loss: 0.7590, G loss: 1.4488\n",
      "[604/1600] D loss: 0.6861, G loss: 2.0121\n",
      "[724/1600] D loss: 0.5317, G loss: 2.8269\n",
      "[844/1600] D loss: 0.9156, G loss: 1.4010\n",
      "[964/1600] D loss: 0.4595, G loss: 1.9423\n",
      "[1084/1600] D loss: 0.7745, G loss: 1.2595\n",
      "[1204/1600] D loss: 0.9200, G loss: 2.1354\n",
      "[1324/1600] D loss: 0.6929, G loss: 1.4885\n",
      "[1444/1600] D loss: 0.6590, G loss: 4.1254\n",
      "[1564/1600] D loss: 0.8459, G loss: 1.7552\n",
      "train error: \n",
      " D loss: 0.890207, G loss: 1.619004, D accuracy: 75.7%, cell accuracy: 98.1%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.968511, G loss: 1.771833, D accuracy: 72.0%, cell accuracy: 98.0%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3457, G loss: 1.1419\n",
      "[124/1600] D loss: 1.0640, G loss: 1.4348\n",
      "[244/1600] D loss: 0.4157, G loss: 1.8503\n",
      "[364/1600] D loss: 0.8257, G loss: 1.1411\n",
      "[484/1600] D loss: 0.8508, G loss: 2.0645\n",
      "[604/1600] D loss: 0.5011, G loss: 2.3452\n",
      "[724/1600] D loss: 0.6153, G loss: 2.6562\n",
      "[844/1600] D loss: 0.5932, G loss: 1.9606\n",
      "[964/1600] D loss: 0.4263, G loss: 1.7647\n",
      "[1084/1600] D loss: 0.7324, G loss: 1.7593\n",
      "[1204/1600] D loss: 0.8995, G loss: 2.3329\n",
      "[1324/1600] D loss: 0.7350, G loss: 1.4886\n",
      "[1444/1600] D loss: 1.4693, G loss: 1.2086\n",
      "[1564/1600] D loss: 0.6176, G loss: 1.9057\n",
      "train error: \n",
      " D loss: 0.819414, G loss: 1.647555, D accuracy: 78.8%, cell accuracy: 98.0%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.926305, G loss: 1.784053, D accuracy: 76.0%, cell accuracy: 97.9%, board accuracy: 15.5% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1420, G loss: 1.0667\n",
      "[124/1600] D loss: 0.6873, G loss: 2.0049\n",
      "[244/1600] D loss: 1.0559, G loss: 1.6395\n",
      "[364/1600] D loss: 0.7845, G loss: 1.6788\n",
      "[484/1600] D loss: 0.6010, G loss: 1.6639\n",
      "[604/1600] D loss: 0.3570, G loss: 1.7292\n",
      "[724/1600] D loss: 0.8533, G loss: 1.0776\n",
      "[844/1600] D loss: 0.4445, G loss: 2.6295\n",
      "[964/1600] D loss: 0.7666, G loss: 3.0183\n",
      "[1084/1600] D loss: 1.5488, G loss: 1.0384\n",
      "[1204/1600] D loss: 0.6349, G loss: 1.9260\n",
      "[1324/1600] D loss: 0.9933, G loss: 1.9612\n",
      "[1444/1600] D loss: 0.9097, G loss: 1.8412\n",
      "[1564/1600] D loss: 1.1465, G loss: 1.0280\n",
      "train error: \n",
      " D loss: 0.831053, G loss: 1.921022, D accuracy: 78.0%, cell accuracy: 98.1%, board accuracy: 16.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.953759, G loss: 2.097290, D accuracy: 74.1%, cell accuracy: 98.0%, board accuracy: 14.5% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9871, G loss: 1.9892\n",
      "[124/1600] D loss: 0.7639, G loss: 1.8147\n",
      "[244/1600] D loss: 1.2346, G loss: 0.9935\n",
      "[364/1600] D loss: 0.7555, G loss: 1.5713\n",
      "[484/1600] D loss: 1.0637, G loss: 0.9125\n",
      "[604/1600] D loss: 0.6487, G loss: 2.2204\n",
      "[724/1600] D loss: 0.4674, G loss: 3.6370\n",
      "[844/1600] D loss: 0.5487, G loss: 1.8957\n",
      "[964/1600] D loss: 1.3671, G loss: 0.5431\n",
      "[1084/1600] D loss: 1.4454, G loss: 1.1966\n",
      "[1204/1600] D loss: 1.0217, G loss: 1.1012\n",
      "[1324/1600] D loss: 1.1677, G loss: 1.7578\n",
      "[1444/1600] D loss: 0.8043, G loss: 2.5361\n",
      "[1564/1600] D loss: 1.3745, G loss: 1.6756\n",
      "train error: \n",
      " D loss: 0.917805, G loss: 1.326584, D accuracy: 76.1%, cell accuracy: 98.0%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.982292, G loss: 1.438834, D accuracy: 72.8%, cell accuracy: 97.9%, board accuracy: 15.8% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6561, G loss: 1.6338\n",
      "[124/1600] D loss: 0.5526, G loss: 2.4569\n",
      "[244/1600] D loss: 0.8354, G loss: 1.5724\n",
      "[364/1600] D loss: 0.9819, G loss: 1.8367\n",
      "[484/1600] D loss: 0.8009, G loss: 1.1625\n",
      "[604/1600] D loss: 0.8158, G loss: 1.8372\n",
      "[724/1600] D loss: 1.0137, G loss: 1.6407\n",
      "[844/1600] D loss: 0.7048, G loss: 1.2300\n",
      "[964/1600] D loss: 0.9094, G loss: 1.1248\n",
      "[1084/1600] D loss: 1.1980, G loss: 1.3473\n",
      "[1204/1600] D loss: 0.7787, G loss: 2.7824\n",
      "[1324/1600] D loss: 0.7993, G loss: 1.7386\n",
      "[1444/1600] D loss: 0.5425, G loss: 2.0027\n",
      "[1564/1600] D loss: 1.3398, G loss: 0.6701\n",
      "train error: \n",
      " D loss: 0.881109, G loss: 1.886468, D accuracy: 76.2%, cell accuracy: 98.2%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.008970, G loss: 2.020648, D accuracy: 71.8%, cell accuracy: 98.0%, board accuracy: 13.5% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8495, G loss: 1.7663\n",
      "[124/1600] D loss: 0.6196, G loss: 2.0573\n",
      "[244/1600] D loss: 1.2831, G loss: 1.0605\n",
      "[364/1600] D loss: 0.8633, G loss: 1.2287\n",
      "[484/1600] D loss: 0.7536, G loss: 2.4199\n",
      "[604/1600] D loss: 0.9277, G loss: 0.9736\n",
      "[724/1600] D loss: 0.9525, G loss: 1.1935\n",
      "[844/1600] D loss: 0.3476, G loss: 1.7764\n",
      "[964/1600] D loss: 1.3532, G loss: 0.8909\n",
      "[1084/1600] D loss: 0.7110, G loss: 2.8301\n",
      "[1204/1600] D loss: 0.4494, G loss: 2.9213\n",
      "[1324/1600] D loss: 0.9321, G loss: 1.5655\n",
      "[1444/1600] D loss: 1.1128, G loss: 0.9392\n",
      "[1564/1600] D loss: 1.3398, G loss: 1.8209\n",
      "train error: \n",
      " D loss: 0.843937, G loss: 1.720424, D accuracy: 78.6%, cell accuracy: 98.2%, board accuracy: 18.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.978326, G loss: 1.882956, D accuracy: 73.1%, cell accuracy: 98.1%, board accuracy: 16.0% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7201, G loss: 2.3559\n",
      "[124/1600] D loss: 0.8130, G loss: 1.5099\n",
      "[244/1600] D loss: 0.9591, G loss: 1.0654\n",
      "[364/1600] D loss: 1.4363, G loss: 0.4738\n",
      "[484/1600] D loss: 0.6532, G loss: 2.1564\n",
      "[604/1600] D loss: 0.8844, G loss: 2.2889\n",
      "[724/1600] D loss: 0.6999, G loss: 1.6367\n",
      "[844/1600] D loss: 0.2218, G loss: 2.6316\n",
      "[964/1600] D loss: 0.8189, G loss: 1.3331\n",
      "[1084/1600] D loss: 0.6704, G loss: 1.5018\n",
      "[1204/1600] D loss: 0.7953, G loss: 2.2269\n",
      "[1324/1600] D loss: 1.0912, G loss: 1.1290\n",
      "[1444/1600] D loss: 1.6734, G loss: 0.8478\n",
      "[1564/1600] D loss: 0.3782, G loss: 1.7108\n",
      "train error: \n",
      " D loss: 0.848050, G loss: 1.641921, D accuracy: 76.9%, cell accuracy: 98.1%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.984586, G loss: 1.808726, D accuracy: 73.1%, cell accuracy: 98.0%, board accuracy: 18.2% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0250, G loss: 1.0766\n",
      "[124/1600] D loss: 0.4732, G loss: 1.9599\n",
      "[244/1600] D loss: 0.5908, G loss: 2.4705\n",
      "[364/1600] D loss: 0.3362, G loss: 2.3677\n",
      "[484/1600] D loss: 0.6604, G loss: 1.7113\n",
      "[604/1600] D loss: 0.7392, G loss: 1.8063\n",
      "[724/1600] D loss: 0.5936, G loss: 2.6917\n",
      "[844/1600] D loss: 1.3199, G loss: 1.9723\n",
      "[964/1600] D loss: 0.8969, G loss: 2.2805\n",
      "[1084/1600] D loss: 0.8024, G loss: 3.7784\n",
      "[1204/1600] D loss: 0.8168, G loss: 1.7814\n",
      "[1324/1600] D loss: 0.7071, G loss: 2.1224\n",
      "[1444/1600] D loss: 0.4686, G loss: 3.2996\n",
      "[1564/1600] D loss: 1.4154, G loss: 1.1789\n",
      "train error: \n",
      " D loss: 0.881822, G loss: 1.608357, D accuracy: 76.2%, cell accuracy: 98.1%, board accuracy: 16.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999103, G loss: 1.739288, D accuracy: 72.0%, cell accuracy: 98.0%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8541, G loss: 1.8270\n",
      "[124/1600] D loss: 1.0576, G loss: 1.0361\n",
      "[244/1600] D loss: 0.3023, G loss: 1.8442\n",
      "[364/1600] D loss: 0.9857, G loss: 2.1862\n",
      "[484/1600] D loss: 0.8047, G loss: 1.2547\n",
      "[604/1600] D loss: 0.9306, G loss: 0.9250\n",
      "[724/1600] D loss: 0.5277, G loss: 1.4547\n",
      "[844/1600] D loss: 0.7097, G loss: 2.0157\n",
      "[964/1600] D loss: 0.8517, G loss: 0.9364\n",
      "[1084/1600] D loss: 1.2028, G loss: 0.7964\n",
      "[1204/1600] D loss: 0.3592, G loss: 2.4596\n",
      "[1324/1600] D loss: 1.1782, G loss: 1.1744\n",
      "[1444/1600] D loss: 1.6445, G loss: 1.1810\n",
      "[1564/1600] D loss: 1.0674, G loss: 1.4491\n",
      "train error: \n",
      " D loss: 0.870233, G loss: 1.490758, D accuracy: 77.8%, cell accuracy: 98.1%, board accuracy: 15.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.994269, G loss: 1.664180, D accuracy: 74.5%, cell accuracy: 98.0%, board accuracy: 16.5% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1169, G loss: 1.5397\n",
      "[124/1600] D loss: 0.6306, G loss: 1.7155\n",
      "[244/1600] D loss: 1.4352, G loss: 0.7334\n",
      "[364/1600] D loss: 0.8979, G loss: 1.3440\n",
      "[484/1600] D loss: 1.4257, G loss: 1.9295\n",
      "[604/1600] D loss: 0.6015, G loss: 2.0223\n",
      "[724/1600] D loss: 0.5171, G loss: 1.9602\n",
      "[844/1600] D loss: 1.4954, G loss: 0.6368\n",
      "[964/1600] D loss: 1.0975, G loss: 1.5994\n",
      "[1084/1600] D loss: 0.9479, G loss: 2.0766\n",
      "[1204/1600] D loss: 0.4194, G loss: 2.8239\n",
      "[1324/1600] D loss: 0.8268, G loss: 1.1746\n",
      "[1444/1600] D loss: 1.1195, G loss: 1.1301\n",
      "[1564/1600] D loss: 0.7405, G loss: 1.6600\n",
      "train error: \n",
      " D loss: 0.916764, G loss: 2.163970, D accuracy: 74.6%, cell accuracy: 98.1%, board accuracy: 17.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.075663, G loss: 2.345706, D accuracy: 72.6%, cell accuracy: 98.0%, board accuracy: 19.2% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3943, G loss: 1.3017\n",
      "[124/1600] D loss: 0.9610, G loss: 1.6962\n",
      "[244/1600] D loss: 0.4710, G loss: 2.9097\n",
      "[364/1600] D loss: 0.5461, G loss: 1.9077\n",
      "[484/1600] D loss: 1.1802, G loss: 2.6457\n",
      "[604/1600] D loss: 1.2314, G loss: 2.9728\n",
      "[724/1600] D loss: 1.3546, G loss: 1.4680\n",
      "[844/1600] D loss: 0.6125, G loss: 1.5664\n",
      "[964/1600] D loss: 0.9715, G loss: 1.7218\n",
      "[1084/1600] D loss: 0.5569, G loss: 2.2189\n",
      "[1204/1600] D loss: 1.8720, G loss: 0.3702\n",
      "[1324/1600] D loss: 0.4545, G loss: 2.4034\n",
      "[1444/1600] D loss: 0.8804, G loss: 1.9462\n",
      "[1564/1600] D loss: 1.2090, G loss: 2.2167\n",
      "train error: \n",
      " D loss: 0.997802, G loss: 2.466226, D accuracy: 72.2%, cell accuracy: 98.1%, board accuracy: 18.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.191211, G loss: 2.595296, D accuracy: 69.5%, cell accuracy: 98.1%, board accuracy: 18.2% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6436, G loss: 1.4696\n",
      "[124/1600] D loss: 0.5993, G loss: 4.3457\n",
      "[244/1600] D loss: 1.1696, G loss: 1.9929\n",
      "[364/1600] D loss: 0.7808, G loss: 1.3404\n",
      "[484/1600] D loss: 0.6873, G loss: 1.8916\n",
      "[604/1600] D loss: 0.7718, G loss: 1.3688\n",
      "[724/1600] D loss: 0.9448, G loss: 2.3548\n",
      "[844/1600] D loss: 1.4774, G loss: 0.9959\n",
      "[964/1600] D loss: 0.4225, G loss: 1.6747\n",
      "[1084/1600] D loss: 0.7973, G loss: 1.7721\n",
      "[1204/1600] D loss: 1.0523, G loss: 2.4586\n",
      "[1324/1600] D loss: 1.2664, G loss: 1.0939\n",
      "[1444/1600] D loss: 0.8429, G loss: 1.3993\n",
      "[1564/1600] D loss: 1.1148, G loss: 1.0658\n",
      "train error: \n",
      " D loss: 0.851668, G loss: 1.628160, D accuracy: 77.0%, cell accuracy: 98.2%, board accuracy: 18.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.991006, G loss: 1.787245, D accuracy: 72.9%, cell accuracy: 98.1%, board accuracy: 19.8% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7476, G loss: 2.2535\n",
      "[124/1600] D loss: 0.3125, G loss: 2.3342\n",
      "[244/1600] D loss: 0.6586, G loss: 2.3128\n",
      "[364/1600] D loss: 0.9475, G loss: 1.5832\n",
      "[484/1600] D loss: 1.2670, G loss: 2.3173\n",
      "[604/1600] D loss: 0.7871, G loss: 1.4898\n",
      "[724/1600] D loss: 1.3165, G loss: 1.0300\n",
      "[844/1600] D loss: 1.1342, G loss: 1.7772\n",
      "[964/1600] D loss: 1.2149, G loss: 1.3366\n",
      "[1084/1600] D loss: 0.5165, G loss: 1.7496\n",
      "[1204/1600] D loss: 0.2048, G loss: 3.0949\n",
      "[1324/1600] D loss: 0.9446, G loss: 1.3944\n",
      "[1444/1600] D loss: 0.8903, G loss: 1.8525\n",
      "[1564/1600] D loss: 1.0300, G loss: 1.5879\n",
      "train error: \n",
      " D loss: 0.835966, G loss: 1.708780, D accuracy: 77.6%, cell accuracy: 98.2%, board accuracy: 17.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.983305, G loss: 1.851501, D accuracy: 71.2%, cell accuracy: 98.1%, board accuracy: 18.2% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6431, G loss: 2.2409\n",
      "[124/1600] D loss: 1.1281, G loss: 1.6882\n",
      "[244/1600] D loss: 0.7539, G loss: 2.2767\n",
      "[364/1600] D loss: 0.7369, G loss: 1.9634\n",
      "[484/1600] D loss: 0.3345, G loss: 2.5489\n",
      "[604/1600] D loss: 1.3496, G loss: 2.2832\n",
      "[724/1600] D loss: 0.8305, G loss: 2.0626\n",
      "[844/1600] D loss: 1.3795, G loss: 0.9369\n",
      "[964/1600] D loss: 0.4106, G loss: 2.0941\n",
      "[1084/1600] D loss: 0.2745, G loss: 3.4565\n",
      "[1204/1600] D loss: 1.3784, G loss: 0.9839\n",
      "[1324/1600] D loss: 0.7466, G loss: 2.2533\n",
      "[1444/1600] D loss: 1.0191, G loss: 1.1246\n",
      "[1564/1600] D loss: 0.9615, G loss: 1.8035\n",
      "train error: \n",
      " D loss: 0.893063, G loss: 2.094207, D accuracy: 76.2%, cell accuracy: 98.1%, board accuracy: 19.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.050850, G loss: 2.213367, D accuracy: 72.1%, cell accuracy: 98.1%, board accuracy: 20.5% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7123, G loss: 2.3192\n",
      "[124/1600] D loss: 0.7246, G loss: 1.4523\n",
      "[244/1600] D loss: 1.0594, G loss: 1.8719\n",
      "[364/1600] D loss: 1.3720, G loss: 1.0462\n",
      "[484/1600] D loss: 0.7466, G loss: 3.2554\n",
      "[604/1600] D loss: 0.7310, G loss: 3.1199\n",
      "[724/1600] D loss: 0.7095, G loss: 3.0214\n",
      "[844/1600] D loss: 1.4315, G loss: 2.5858\n",
      "[964/1600] D loss: 0.8348, G loss: 1.4407\n",
      "[1084/1600] D loss: 0.6163, G loss: 1.2695\n",
      "[1204/1600] D loss: 0.6622, G loss: 1.2401\n",
      "[1324/1600] D loss: 1.2442, G loss: 0.9933\n",
      "[1444/1600] D loss: 1.7566, G loss: 0.7191\n",
      "[1564/1600] D loss: 0.4085, G loss: 2.6358\n",
      "train error: \n",
      " D loss: 0.894056, G loss: 2.058775, D accuracy: 75.3%, cell accuracy: 98.2%, board accuracy: 20.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.075781, G loss: 2.213956, D accuracy: 71.2%, cell accuracy: 98.1%, board accuracy: 21.0% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5588, G loss: 2.6659\n",
      "[124/1600] D loss: 0.4649, G loss: 2.7248\n",
      "[244/1600] D loss: 0.9946, G loss: 1.9583\n",
      "[364/1600] D loss: 0.9255, G loss: 1.8367\n",
      "[484/1600] D loss: 1.0892, G loss: 1.3312\n",
      "[604/1600] D loss: 0.6776, G loss: 1.8229\n",
      "[724/1600] D loss: 0.8022, G loss: 1.5665\n",
      "[844/1600] D loss: 0.5533, G loss: 2.7044\n",
      "[964/1600] D loss: 1.1880, G loss: 0.8380\n",
      "[1084/1600] D loss: 0.8381, G loss: 1.6953\n",
      "[1204/1600] D loss: 1.1722, G loss: 1.7342\n",
      "[1324/1600] D loss: 1.2723, G loss: 1.0690\n",
      "[1444/1600] D loss: 1.1902, G loss: 0.8237\n",
      "[1564/1600] D loss: 1.5222, G loss: 1.2756\n",
      "train error: \n",
      " D loss: 0.866889, G loss: 1.511938, D accuracy: 76.7%, cell accuracy: 98.2%, board accuracy: 19.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.988662, G loss: 1.667393, D accuracy: 72.4%, cell accuracy: 98.1%, board accuracy: 20.0% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5419, G loss: 2.2048\n",
      "[124/1600] D loss: 0.8000, G loss: 2.2831\n",
      "[244/1600] D loss: 2.0802, G loss: 0.7155\n",
      "[364/1600] D loss: 0.5442, G loss: 2.1001\n",
      "[484/1600] D loss: 0.8964, G loss: 1.1389\n",
      "[604/1600] D loss: 0.7807, G loss: 1.5456\n",
      "[724/1600] D loss: 1.1877, G loss: 2.0383\n",
      "[844/1600] D loss: 1.1709, G loss: 0.9684\n",
      "[964/1600] D loss: 1.3633, G loss: 0.7204\n",
      "[1084/1600] D loss: 0.8834, G loss: 2.2455\n",
      "[1204/1600] D loss: 1.2651, G loss: 0.8573\n",
      "[1324/1600] D loss: 1.0985, G loss: 1.2305\n",
      "[1444/1600] D loss: 0.6455, G loss: 1.8998\n",
      "[1564/1600] D loss: 1.1487, G loss: 0.8986\n",
      "train error: \n",
      " D loss: 0.845752, G loss: 1.633358, D accuracy: 76.9%, cell accuracy: 98.2%, board accuracy: 20.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.990160, G loss: 1.770433, D accuracy: 73.4%, cell accuracy: 98.1%, board accuracy: 21.8% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9102, G loss: 1.0589\n",
      "[124/1600] D loss: 0.7379, G loss: 1.8904\n",
      "[244/1600] D loss: 0.1999, G loss: 2.4852\n",
      "[364/1600] D loss: 0.3025, G loss: 3.4600\n",
      "[484/1600] D loss: 0.7059, G loss: 1.3564\n",
      "[604/1600] D loss: 1.2183, G loss: 0.8219\n",
      "[724/1600] D loss: 1.4153, G loss: 0.8561\n",
      "[844/1600] D loss: 0.4930, G loss: 1.6831\n",
      "[964/1600] D loss: 1.3091, G loss: 0.9305\n",
      "[1084/1600] D loss: 1.1992, G loss: 2.1402\n",
      "[1204/1600] D loss: 1.1748, G loss: 1.8276\n",
      "[1324/1600] D loss: 0.7833, G loss: 2.2720\n",
      "[1444/1600] D loss: 1.3069, G loss: 1.0854\n",
      "[1564/1600] D loss: 0.4391, G loss: 1.8515\n",
      "train error: \n",
      " D loss: 0.848950, G loss: 2.087573, D accuracy: 76.8%, cell accuracy: 98.1%, board accuracy: 18.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.024538, G loss: 2.196931, D accuracy: 72.4%, cell accuracy: 98.0%, board accuracy: 19.5% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4905, G loss: 2.2135\n",
      "[124/1600] D loss: 0.8057, G loss: 1.4771\n",
      "[244/1600] D loss: 1.1277, G loss: 1.0595\n",
      "[364/1600] D loss: 1.0840, G loss: 1.4377\n",
      "[484/1600] D loss: 0.5094, G loss: 3.0534\n",
      "[604/1600] D loss: 1.1828, G loss: 0.8758\n",
      "[724/1600] D loss: 0.3923, G loss: 3.8416\n",
      "[844/1600] D loss: 1.1528, G loss: 1.3572\n",
      "[964/1600] D loss: 0.4289, G loss: 2.5412\n",
      "[1084/1600] D loss: 1.0073, G loss: 2.0860\n",
      "[1204/1600] D loss: 0.6105, G loss: 2.5988\n",
      "[1324/1600] D loss: 1.3812, G loss: 1.2652\n",
      "[1444/1600] D loss: 0.9873, G loss: 1.5757\n",
      "[1564/1600] D loss: 1.2686, G loss: 2.7443\n",
      "train error: \n",
      " D loss: 0.842912, G loss: 1.739483, D accuracy: 76.6%, cell accuracy: 98.2%, board accuracy: 19.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.995931, G loss: 1.872089, D accuracy: 72.9%, cell accuracy: 98.1%, board accuracy: 19.8% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2079, G loss: 1.3880\n",
      "[124/1600] D loss: 0.6421, G loss: 1.7821\n",
      "[244/1600] D loss: 1.2090, G loss: 2.1721\n",
      "[364/1600] D loss: 0.4520, G loss: 2.5405\n",
      "[484/1600] D loss: 0.6785, G loss: 1.4048\n",
      "[604/1600] D loss: 1.3958, G loss: 0.8428\n",
      "[724/1600] D loss: 0.8765, G loss: 1.4659\n",
      "[844/1600] D loss: 0.8083, G loss: 1.2074\n",
      "[964/1600] D loss: 0.5680, G loss: 2.7591\n",
      "[1084/1600] D loss: 0.9163, G loss: 1.3813\n",
      "[1204/1600] D loss: 0.5760, G loss: 1.9611\n",
      "[1324/1600] D loss: 1.2069, G loss: 1.3133\n",
      "[1444/1600] D loss: 1.0373, G loss: 0.8718\n",
      "[1564/1600] D loss: 1.5005, G loss: 0.5175\n",
      "train error: \n",
      " D loss: 0.932533, G loss: 1.469523, D accuracy: 76.3%, cell accuracy: 98.2%, board accuracy: 21.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.059891, G loss: 1.649849, D accuracy: 72.5%, cell accuracy: 98.2%, board accuracy: 21.0% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7139, G loss: 1.8868\n",
      "[124/1600] D loss: 1.4742, G loss: 1.0194\n",
      "[244/1600] D loss: 1.5918, G loss: 0.8335\n",
      "[364/1600] D loss: 1.1396, G loss: 1.0496\n",
      "[484/1600] D loss: 0.8940, G loss: 1.3786\n",
      "[604/1600] D loss: 1.1744, G loss: 1.0872\n",
      "[724/1600] D loss: 0.5817, G loss: 1.7621\n",
      "[844/1600] D loss: 1.2441, G loss: 1.4919\n",
      "[964/1600] D loss: 0.4381, G loss: 2.8202\n",
      "[1084/1600] D loss: 0.8360, G loss: 1.7952\n",
      "[1204/1600] D loss: 0.4365, G loss: 2.4933\n",
      "[1324/1600] D loss: 0.8323, G loss: 1.1989\n",
      "[1444/1600] D loss: 0.7452, G loss: 1.4253\n",
      "[1564/1600] D loss: 0.7755, G loss: 1.8874\n",
      "train error: \n",
      " D loss: 1.096730, G loss: 2.670118, D accuracy: 71.9%, cell accuracy: 98.1%, board accuracy: 18.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304727, G loss: 2.861995, D accuracy: 69.8%, cell accuracy: 98.1%, board accuracy: 20.5% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2389, G loss: 2.2946\n",
      "[124/1600] D loss: 0.7923, G loss: 2.0078\n",
      "[244/1600] D loss: 0.2604, G loss: 2.1328\n",
      "[364/1600] D loss: 1.3078, G loss: 1.2908\n",
      "[484/1600] D loss: 0.8873, G loss: 1.9003\n",
      "[604/1600] D loss: 0.7876, G loss: 1.4977\n",
      "[724/1600] D loss: 0.6260, G loss: 1.2841\n",
      "[844/1600] D loss: 1.1276, G loss: 1.4050\n",
      "[964/1600] D loss: 0.5968, G loss: 2.6875\n",
      "[1084/1600] D loss: 0.9019, G loss: 1.3531\n",
      "[1204/1600] D loss: 0.0992, G loss: 4.2398\n",
      "[1324/1600] D loss: 0.4893, G loss: 2.5293\n",
      "[1444/1600] D loss: 1.3437, G loss: 0.5941\n",
      "[1564/1600] D loss: 0.8934, G loss: 1.2121\n",
      "train error: \n",
      " D loss: 0.809759, G loss: 1.719785, D accuracy: 78.0%, cell accuracy: 98.1%, board accuracy: 18.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.963861, G loss: 1.884885, D accuracy: 72.8%, cell accuracy: 98.1%, board accuracy: 21.0% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1252, G loss: 0.9371\n",
      "[124/1600] D loss: 1.0891, G loss: 0.7804\n",
      "[244/1600] D loss: 0.7779, G loss: 1.6483\n",
      "[364/1600] D loss: 0.9174, G loss: 2.9185\n",
      "[484/1600] D loss: 0.7320, G loss: 3.1569\n",
      "[604/1600] D loss: 0.3243, G loss: 2.6979\n",
      "[724/1600] D loss: 0.7317, G loss: 1.9986\n",
      "[844/1600] D loss: 0.5881, G loss: 3.2628\n",
      "[964/1600] D loss: 1.0816, G loss: 1.8655\n",
      "[1084/1600] D loss: 0.5495, G loss: 2.2279\n",
      "[1204/1600] D loss: 0.6873, G loss: 1.5937\n",
      "[1324/1600] D loss: 1.1170, G loss: 1.0140\n",
      "[1444/1600] D loss: 0.3453, G loss: 2.2160\n",
      "[1564/1600] D loss: 0.9541, G loss: 1.3116\n",
      "train error: \n",
      " D loss: 0.819304, G loss: 1.905034, D accuracy: 77.2%, cell accuracy: 98.2%, board accuracy: 20.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.008551, G loss: 2.079004, D accuracy: 73.8%, cell accuracy: 98.1%, board accuracy: 21.8% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6325, G loss: 2.8017\n",
      "[124/1600] D loss: 0.3434, G loss: 2.0888\n",
      "[244/1600] D loss: 0.6034, G loss: 2.2640\n",
      "[364/1600] D loss: 1.2582, G loss: 0.7907\n",
      "[484/1600] D loss: 0.5890, G loss: 3.1001\n",
      "[604/1600] D loss: 0.8230, G loss: 1.7471\n",
      "[724/1600] D loss: 0.7160, G loss: 1.9332\n",
      "[844/1600] D loss: 0.6785, G loss: 2.4937\n",
      "[964/1600] D loss: 0.2431, G loss: 2.9017\n",
      "[1084/1600] D loss: 0.9223, G loss: 1.6228\n",
      "[1204/1600] D loss: 1.5957, G loss: 0.5360\n",
      "[1324/1600] D loss: 0.6124, G loss: 1.4660\n",
      "[1444/1600] D loss: 0.6575, G loss: 1.9733\n",
      "[1564/1600] D loss: 0.2921, G loss: 2.8168\n",
      "train error: \n",
      " D loss: 1.006227, G loss: 1.146695, D accuracy: 73.8%, cell accuracy: 98.2%, board accuracy: 19.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.079911, G loss: 1.320929, D accuracy: 71.4%, cell accuracy: 98.1%, board accuracy: 20.8% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9875, G loss: 0.7867\n",
      "[124/1600] D loss: 0.6328, G loss: 1.6128\n",
      "[244/1600] D loss: 1.2820, G loss: 0.9840\n",
      "[364/1600] D loss: 0.1750, G loss: 3.2395\n",
      "[484/1600] D loss: 1.1595, G loss: 1.8442\n",
      "[604/1600] D loss: 0.5528, G loss: 3.2547\n",
      "[724/1600] D loss: 0.8672, G loss: 1.5262\n",
      "[844/1600] D loss: 1.2807, G loss: 1.0199\n",
      "[964/1600] D loss: 0.8896, G loss: 1.1064\n",
      "[1084/1600] D loss: 0.7209, G loss: 2.3016\n",
      "[1204/1600] D loss: 1.2196, G loss: 2.0064\n",
      "[1324/1600] D loss: 1.2223, G loss: 1.3290\n",
      "[1444/1600] D loss: 1.3519, G loss: 2.6585\n",
      "[1564/1600] D loss: 0.3611, G loss: 2.5818\n",
      "train error: \n",
      " D loss: 0.823066, G loss: 1.966346, D accuracy: 77.5%, cell accuracy: 98.2%, board accuracy: 20.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.001831, G loss: 2.163672, D accuracy: 73.1%, cell accuracy: 98.2%, board accuracy: 22.5% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5441, G loss: 1.7582\n",
      "[124/1600] D loss: 0.5587, G loss: 2.6160\n",
      "[244/1600] D loss: 0.7247, G loss: 1.7066\n",
      "[364/1600] D loss: 1.0702, G loss: 2.5996\n",
      "[484/1600] D loss: 0.3595, G loss: 2.4301\n",
      "[604/1600] D loss: 0.5204, G loss: 1.5876\n",
      "[724/1600] D loss: 0.8941, G loss: 1.0783\n",
      "[844/1600] D loss: 0.3148, G loss: 3.7397\n",
      "[964/1600] D loss: 0.4563, G loss: 2.3851\n",
      "[1084/1600] D loss: 1.5330, G loss: 0.5087\n",
      "[1204/1600] D loss: 1.3137, G loss: 1.0194\n",
      "[1324/1600] D loss: 1.0599, G loss: 1.5698\n",
      "[1444/1600] D loss: 0.8367, G loss: 2.0307\n",
      "[1564/1600] D loss: 0.9112, G loss: 1.7444\n",
      "train error: \n",
      " D loss: 0.842182, G loss: 2.177172, D accuracy: 76.1%, cell accuracy: 98.2%, board accuracy: 21.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.025796, G loss: 2.390509, D accuracy: 72.8%, cell accuracy: 98.2%, board accuracy: 22.2% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2915, G loss: 4.1271\n",
      "[124/1600] D loss: 0.8530, G loss: 1.8655\n",
      "[244/1600] D loss: 1.0720, G loss: 1.1147\n",
      "[364/1600] D loss: 0.3663, G loss: 3.0757\n",
      "[484/1600] D loss: 1.5291, G loss: 0.7034\n",
      "[604/1600] D loss: 0.5233, G loss: 1.8173\n",
      "[724/1600] D loss: 0.5891, G loss: 1.9671\n",
      "[844/1600] D loss: 0.4161, G loss: 2.1160\n",
      "[964/1600] D loss: 0.7955, G loss: 1.5960\n",
      "[1084/1600] D loss: 0.7602, G loss: 1.9133\n",
      "[1204/1600] D loss: 0.9652, G loss: 2.1689\n",
      "[1324/1600] D loss: 1.2484, G loss: 1.5632\n",
      "[1444/1600] D loss: 1.0612, G loss: 0.7274\n",
      "[1564/1600] D loss: 0.6786, G loss: 2.6390\n",
      "train error: \n",
      " D loss: 0.853475, G loss: 1.992641, D accuracy: 77.2%, cell accuracy: 98.1%, board accuracy: 20.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.030854, G loss: 2.222712, D accuracy: 72.9%, cell accuracy: 98.1%, board accuracy: 21.5% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5828, G loss: 2.6958\n",
      "[124/1600] D loss: 0.6198, G loss: 2.5607\n",
      "[244/1600] D loss: 1.2602, G loss: 0.5519\n",
      "[364/1600] D loss: 1.2055, G loss: 1.0588\n",
      "[484/1600] D loss: 0.9517, G loss: 2.2932\n",
      "[604/1600] D loss: 0.9410, G loss: 1.2379\n",
      "[724/1600] D loss: 1.2640, G loss: 2.0332\n",
      "[844/1600] D loss: 0.5825, G loss: 2.1446\n",
      "[964/1600] D loss: 1.3985, G loss: 0.6052\n",
      "[1084/1600] D loss: 0.5968, G loss: 2.1697\n",
      "[1204/1600] D loss: 0.7290, G loss: 2.4403\n",
      "[1324/1600] D loss: 1.0506, G loss: 1.4782\n",
      "[1444/1600] D loss: 0.4087, G loss: 3.5871\n",
      "[1564/1600] D loss: 0.8323, G loss: 1.3875\n",
      "train error: \n",
      " D loss: 0.932921, G loss: 1.320243, D accuracy: 74.4%, cell accuracy: 98.3%, board accuracy: 21.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.037243, G loss: 1.483560, D accuracy: 71.1%, cell accuracy: 98.2%, board accuracy: 21.0% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4012, G loss: 1.8260\n",
      "[124/1600] D loss: 1.0524, G loss: 1.1346\n",
      "[244/1600] D loss: 1.3944, G loss: 1.0955\n",
      "[364/1600] D loss: 1.0584, G loss: 2.2794\n",
      "[484/1600] D loss: 0.4857, G loss: 1.9674\n",
      "[604/1600] D loss: 0.8297, G loss: 2.1914\n",
      "[724/1600] D loss: 0.5847, G loss: 2.6791\n",
      "[844/1600] D loss: 0.7548, G loss: 2.3731\n",
      "[964/1600] D loss: 1.4375, G loss: 1.9735\n",
      "[1084/1600] D loss: 0.9854, G loss: 1.1610\n",
      "[1204/1600] D loss: 0.6480, G loss: 3.0050\n",
      "[1324/1600] D loss: 0.7609, G loss: 1.7972\n",
      "[1444/1600] D loss: 0.4959, G loss: 2.2712\n",
      "[1564/1600] D loss: 0.1847, G loss: 3.0647\n",
      "train error: \n",
      " D loss: 0.943211, G loss: 1.598784, D accuracy: 74.8%, cell accuracy: 98.2%, board accuracy: 22.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.053310, G loss: 1.738596, D accuracy: 72.1%, cell accuracy: 98.2%, board accuracy: 24.0% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2898, G loss: 1.0310\n",
      "[124/1600] D loss: 0.7585, G loss: 1.7766\n",
      "[244/1600] D loss: 1.5069, G loss: 0.4601\n",
      "[364/1600] D loss: 0.3293, G loss: 3.3275\n",
      "[484/1600] D loss: 0.6871, G loss: 3.6073\n",
      "[604/1600] D loss: 0.9649, G loss: 1.6396\n",
      "[724/1600] D loss: 1.7391, G loss: 1.3323\n",
      "[844/1600] D loss: 0.3572, G loss: 1.7541\n",
      "[964/1600] D loss: 1.5659, G loss: 0.9892\n",
      "[1084/1600] D loss: 0.6185, G loss: 1.7762\n",
      "[1204/1600] D loss: 1.1221, G loss: 1.4320\n",
      "[1324/1600] D loss: 0.8180, G loss: 1.6884\n",
      "[1444/1600] D loss: 1.3103, G loss: 1.7136\n",
      "[1564/1600] D loss: 0.8841, G loss: 2.1188\n",
      "train error: \n",
      " D loss: 0.883327, G loss: 2.286945, D accuracy: 75.2%, cell accuracy: 98.2%, board accuracy: 21.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.124345, G loss: 2.405852, D accuracy: 70.0%, cell accuracy: 98.1%, board accuracy: 23.5% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5847, G loss: 1.3692\n",
      "[124/1600] D loss: 0.7231, G loss: 2.4321\n",
      "[244/1600] D loss: 1.1278, G loss: 1.2652\n",
      "[364/1600] D loss: 0.7901, G loss: 1.2075\n",
      "[484/1600] D loss: 0.7927, G loss: 2.7269\n",
      "[604/1600] D loss: 0.7200, G loss: 1.3812\n",
      "[724/1600] D loss: 0.9189, G loss: 1.8214\n",
      "[844/1600] D loss: 0.4732, G loss: 2.4786\n",
      "[964/1600] D loss: 0.1420, G loss: 2.9873\n",
      "[1084/1600] D loss: 0.4639, G loss: 2.8236\n",
      "[1204/1600] D loss: 0.8704, G loss: 0.7868\n",
      "[1324/1600] D loss: 0.0748, G loss: 3.8164\n",
      "[1444/1600] D loss: 1.6221, G loss: 1.0564\n",
      "[1564/1600] D loss: 1.1924, G loss: 0.9120\n",
      "train error: \n",
      " D loss: 0.850019, G loss: 1.697679, D accuracy: 77.2%, cell accuracy: 98.3%, board accuracy: 23.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.027706, G loss: 1.832469, D accuracy: 71.9%, cell accuracy: 98.2%, board accuracy: 24.8% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8659, G loss: 1.5191\n",
      "[124/1600] D loss: 0.6689, G loss: 1.9950\n",
      "[244/1600] D loss: 0.1705, G loss: 3.7898\n",
      "[364/1600] D loss: 1.1868, G loss: 0.7190\n",
      "[484/1600] D loss: 0.6898, G loss: 1.5434\n",
      "[604/1600] D loss: 0.5909, G loss: 2.2702\n",
      "[724/1600] D loss: 1.0857, G loss: 1.8304\n",
      "[844/1600] D loss: 0.5525, G loss: 2.2026\n",
      "[964/1600] D loss: 0.9476, G loss: 2.3629\n",
      "[1084/1600] D loss: 1.0697, G loss: 1.1937\n",
      "[1204/1600] D loss: 1.0459, G loss: 2.2630\n",
      "[1324/1600] D loss: 1.0097, G loss: 1.4037\n",
      "[1444/1600] D loss: 0.7989, G loss: 3.0024\n",
      "[1564/1600] D loss: 0.8755, G loss: 2.2541\n",
      "train error: \n",
      " D loss: 0.821656, G loss: 2.071478, D accuracy: 76.6%, cell accuracy: 98.2%, board accuracy: 25.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.026440, G loss: 2.140752, D accuracy: 71.4%, cell accuracy: 98.2%, board accuracy: 24.0% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6890, G loss: 2.4336\n",
      "[124/1600] D loss: 1.1395, G loss: 1.0836\n",
      "[244/1600] D loss: 1.1099, G loss: 2.6995\n",
      "[364/1600] D loss: 0.1410, G loss: 2.7210\n",
      "[484/1600] D loss: 0.7218, G loss: 2.5444\n",
      "[604/1600] D loss: 0.6562, G loss: 2.1941\n",
      "[724/1600] D loss: 1.0453, G loss: 1.5714\n",
      "[844/1600] D loss: 0.7450, G loss: 1.5896\n",
      "[964/1600] D loss: 0.5797, G loss: 2.2349\n",
      "[1084/1600] D loss: 0.9726, G loss: 1.1596\n",
      "[1204/1600] D loss: 0.8677, G loss: 1.6593\n",
      "[1324/1600] D loss: 0.7500, G loss: 1.3846\n",
      "[1444/1600] D loss: 0.7107, G loss: 1.5134\n",
      "[1564/1600] D loss: 0.7836, G loss: 2.4153\n",
      "train error: \n",
      " D loss: 0.829574, G loss: 1.690821, D accuracy: 77.4%, cell accuracy: 98.3%, board accuracy: 24.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.998268, G loss: 1.836615, D accuracy: 72.6%, cell accuracy: 98.2%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8477, G loss: 1.5884\n",
      "[124/1600] D loss: 1.2610, G loss: 0.8247\n",
      "[244/1600] D loss: 1.2176, G loss: 1.0385\n",
      "[364/1600] D loss: 1.1481, G loss: 1.5406\n",
      "[484/1600] D loss: 0.7828, G loss: 1.5708\n",
      "[604/1600] D loss: 0.5734, G loss: 4.0768\n",
      "[724/1600] D loss: 1.3141, G loss: 1.4018\n",
      "[844/1600] D loss: 0.6296, G loss: 1.7720\n",
      "[964/1600] D loss: 0.6209, G loss: 2.4507\n",
      "[1084/1600] D loss: 0.6689, G loss: 1.3386\n",
      "[1204/1600] D loss: 0.6299, G loss: 2.3082\n",
      "[1324/1600] D loss: 0.6628, G loss: 2.4589\n",
      "[1444/1600] D loss: 1.2026, G loss: 0.9104\n",
      "[1564/1600] D loss: 0.7450, G loss: 1.6904\n",
      "train error: \n",
      " D loss: 0.831745, G loss: 2.171949, D accuracy: 76.7%, cell accuracy: 98.3%, board accuracy: 24.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.048843, G loss: 2.297036, D accuracy: 71.4%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9111, G loss: 2.3582\n",
      "[124/1600] D loss: 0.8732, G loss: 2.1387\n",
      "[244/1600] D loss: 0.9109, G loss: 1.3467\n",
      "[364/1600] D loss: 0.9491, G loss: 1.9254\n",
      "[484/1600] D loss: 0.4633, G loss: 3.1561\n",
      "[604/1600] D loss: 0.4762, G loss: 1.9079\n",
      "[724/1600] D loss: 1.0065, G loss: 1.7863\n",
      "[844/1600] D loss: 0.6321, G loss: 1.3426\n",
      "[964/1600] D loss: 0.8534, G loss: 2.6962\n",
      "[1084/1600] D loss: 1.0621, G loss: 2.0345\n",
      "[1204/1600] D loss: 1.0638, G loss: 1.3630\n",
      "[1324/1600] D loss: 0.7478, G loss: 2.0364\n",
      "[1444/1600] D loss: 0.4360, G loss: 2.4164\n",
      "[1564/1600] D loss: 0.6378, G loss: 3.1584\n",
      "train error: \n",
      " D loss: 0.825261, G loss: 1.978697, D accuracy: 77.6%, cell accuracy: 98.2%, board accuracy: 25.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.992659, G loss: 2.173651, D accuracy: 73.4%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8350, G loss: 1.3412\n",
      "[124/1600] D loss: 0.3999, G loss: 2.5129\n",
      "[244/1600] D loss: 0.8809, G loss: 2.5743\n",
      "[364/1600] D loss: 0.7453, G loss: 2.1494\n",
      "[484/1600] D loss: 0.7697, G loss: 2.6047\n",
      "[604/1600] D loss: 0.7966, G loss: 1.8814\n",
      "[724/1600] D loss: 1.0295, G loss: 1.0123\n",
      "[844/1600] D loss: 0.7527, G loss: 3.2048\n",
      "[964/1600] D loss: 1.4474, G loss: 0.8391\n",
      "[1084/1600] D loss: 0.3809, G loss: 2.0040\n",
      "[1204/1600] D loss: 0.9884, G loss: 1.8192\n",
      "[1324/1600] D loss: 0.6507, G loss: 1.5944\n",
      "[1444/1600] D loss: 0.7584, G loss: 2.0879\n",
      "[1564/1600] D loss: 0.7171, G loss: 2.5761\n",
      "train error: \n",
      " D loss: 0.864544, G loss: 1.618788, D accuracy: 77.2%, cell accuracy: 98.3%, board accuracy: 23.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.023727, G loss: 1.716717, D accuracy: 72.4%, cell accuracy: 98.2%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0959, G loss: 3.2187\n",
      "[124/1600] D loss: 0.6912, G loss: 3.0335\n",
      "[244/1600] D loss: 1.5618, G loss: 1.3308\n",
      "[364/1600] D loss: 0.8085, G loss: 1.6220\n",
      "[484/1600] D loss: 0.7747, G loss: 2.4248\n",
      "[604/1600] D loss: 0.5263, G loss: 3.5162\n",
      "[724/1600] D loss: 1.0306, G loss: 3.1273\n",
      "[844/1600] D loss: 0.9208, G loss: 1.5476\n",
      "[964/1600] D loss: 0.6448, G loss: 2.3779\n",
      "[1084/1600] D loss: 0.2119, G loss: 2.4626\n",
      "[1204/1600] D loss: 1.3865, G loss: 0.8681\n",
      "[1324/1600] D loss: 0.7644, G loss: 1.6878\n",
      "[1444/1600] D loss: 1.0327, G loss: 0.9691\n",
      "[1564/1600] D loss: 0.8808, G loss: 1.7124\n",
      "train error: \n",
      " D loss: 0.849590, G loss: 1.608163, D accuracy: 77.2%, cell accuracy: 98.3%, board accuracy: 26.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.041019, G loss: 1.719079, D accuracy: 70.9%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0524, G loss: 1.0317\n",
      "[124/1600] D loss: 0.7868, G loss: 1.7740\n",
      "[244/1600] D loss: 0.4193, G loss: 2.2606\n",
      "[364/1600] D loss: 0.5774, G loss: 2.1200\n",
      "[484/1600] D loss: 0.3419, G loss: 2.1420\n",
      "[604/1600] D loss: 0.9189, G loss: 1.6776\n",
      "[724/1600] D loss: 0.3575, G loss: 4.4568\n",
      "[844/1600] D loss: 0.8145, G loss: 1.5012\n",
      "[964/1600] D loss: 0.5728, G loss: 2.5661\n",
      "[1084/1600] D loss: 0.5468, G loss: 2.4941\n",
      "[1204/1600] D loss: 0.4241, G loss: 2.2993\n",
      "[1324/1600] D loss: 0.6704, G loss: 2.5982\n",
      "[1444/1600] D loss: 0.8660, G loss: 1.5981\n",
      "[1564/1600] D loss: 1.2708, G loss: 1.5127\n",
      "train error: \n",
      " D loss: 0.832351, G loss: 2.258016, D accuracy: 77.1%, cell accuracy: 98.3%, board accuracy: 23.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.060010, G loss: 2.419437, D accuracy: 71.4%, cell accuracy: 98.3%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7715, G loss: 1.6718\n",
      "[124/1600] D loss: 0.7193, G loss: 0.9206\n",
      "[244/1600] D loss: 0.6033, G loss: 1.2183\n",
      "[364/1600] D loss: 0.8389, G loss: 1.6770\n",
      "[484/1600] D loss: 0.3443, G loss: 3.6115\n",
      "[604/1600] D loss: 0.4459, G loss: 2.1966\n",
      "[724/1600] D loss: 0.8444, G loss: 1.9561\n",
      "[844/1600] D loss: 1.0828, G loss: 2.7781\n",
      "[964/1600] D loss: 0.3241, G loss: 1.7108\n",
      "[1084/1600] D loss: 0.7285, G loss: 1.8991\n",
      "[1204/1600] D loss: 1.0379, G loss: 1.4285\n",
      "[1324/1600] D loss: 1.1299, G loss: 1.4978\n",
      "[1444/1600] D loss: 1.1236, G loss: 0.9744\n",
      "[1564/1600] D loss: 0.5783, G loss: 1.9110\n",
      "train error: \n",
      " D loss: 0.821929, G loss: 1.655922, D accuracy: 78.3%, cell accuracy: 98.3%, board accuracy: 24.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.014232, G loss: 1.816294, D accuracy: 72.2%, cell accuracy: 98.3%, board accuracy: 23.8% \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1853, G loss: 1.5444\n",
      "[124/1600] D loss: 0.9023, G loss: 1.3520\n",
      "[244/1600] D loss: 1.1897, G loss: 2.8579\n",
      "[364/1600] D loss: 1.3993, G loss: 0.8814\n",
      "[484/1600] D loss: 1.6553, G loss: 0.6828\n",
      "[604/1600] D loss: 0.3806, G loss: 3.6573\n",
      "[724/1600] D loss: 0.5069, G loss: 2.9769\n",
      "[844/1600] D loss: 0.7922, G loss: 2.5991\n",
      "[964/1600] D loss: 0.3804, G loss: 2.0199\n",
      "[1084/1600] D loss: 0.5180, G loss: 2.0701\n",
      "[1204/1600] D loss: 0.4251, G loss: 2.8931\n",
      "[1324/1600] D loss: 1.0100, G loss: 0.8260\n",
      "[1444/1600] D loss: 1.0427, G loss: 1.7455\n",
      "[1564/1600] D loss: 0.9968, G loss: 1.9304\n",
      "train error: \n",
      " D loss: 0.837132, G loss: 1.974843, D accuracy: 76.4%, cell accuracy: 98.3%, board accuracy: 25.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.055467, G loss: 2.165702, D accuracy: 70.6%, cell accuracy: 98.3%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6520, G loss: 1.8145\n",
      "[124/1600] D loss: 0.7840, G loss: 2.4703\n",
      "[244/1600] D loss: 1.1502, G loss: 0.9924\n",
      "[364/1600] D loss: 1.3889, G loss: 2.0532\n",
      "[484/1600] D loss: 1.3449, G loss: 0.9224\n",
      "[604/1600] D loss: 1.1621, G loss: 1.4856\n",
      "[724/1600] D loss: 0.6881, G loss: 2.3378\n",
      "[844/1600] D loss: 1.1119, G loss: 0.9579\n",
      "[964/1600] D loss: 0.9214, G loss: 2.9984\n",
      "[1084/1600] D loss: 1.6408, G loss: 0.3932\n",
      "[1204/1600] D loss: 0.2810, G loss: 2.9162\n",
      "[1324/1600] D loss: 1.0050, G loss: 1.8124\n",
      "[1444/1600] D loss: 0.6505, G loss: 1.7597\n",
      "[1564/1600] D loss: 0.9282, G loss: 2.1204\n",
      "train error: \n",
      " D loss: 0.804866, G loss: 2.012214, D accuracy: 78.8%, cell accuracy: 98.3%, board accuracy: 25.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.010030, G loss: 2.175957, D accuracy: 73.9%, cell accuracy: 98.2%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2374, G loss: 2.2187\n",
      "[124/1600] D loss: 0.8147, G loss: 1.9018\n",
      "[244/1600] D loss: 1.3051, G loss: 1.0773\n",
      "[364/1600] D loss: 0.7671, G loss: 1.3399\n",
      "[484/1600] D loss: 0.4567, G loss: 1.9494\n",
      "[604/1600] D loss: 0.1314, G loss: 2.8179\n",
      "[724/1600] D loss: 1.0581, G loss: 1.8870\n",
      "[844/1600] D loss: 0.5983, G loss: 2.7503\n",
      "[964/1600] D loss: 0.8254, G loss: 1.2415\n",
      "[1084/1600] D loss: 0.4648, G loss: 2.0674\n",
      "[1204/1600] D loss: 0.3694, G loss: 3.9774\n",
      "[1324/1600] D loss: 0.9021, G loss: 1.1977\n",
      "[1444/1600] D loss: 0.6991, G loss: 2.1729\n",
      "[1564/1600] D loss: 1.4613, G loss: 0.4689\n",
      "train error: \n",
      " D loss: 0.825434, G loss: 1.755655, D accuracy: 77.5%, cell accuracy: 98.3%, board accuracy: 26.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.020587, G loss: 1.919615, D accuracy: 71.4%, cell accuracy: 98.2%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8537, G loss: 1.5769\n",
      "[124/1600] D loss: 0.5523, G loss: 2.1767\n",
      "[244/1600] D loss: 1.2087, G loss: 1.5896\n",
      "[364/1600] D loss: 1.1390, G loss: 2.4408\n",
      "[484/1600] D loss: 1.1833, G loss: 1.0192\n",
      "[604/1600] D loss: 0.6701, G loss: 1.9212\n",
      "[724/1600] D loss: 1.0317, G loss: 1.4357\n",
      "[844/1600] D loss: 0.6136, G loss: 1.7445\n",
      "[964/1600] D loss: 1.5663, G loss: 0.5711\n",
      "[1084/1600] D loss: 0.9550, G loss: 1.4621\n",
      "[1204/1600] D loss: 0.2573, G loss: 3.2083\n",
      "[1324/1600] D loss: 0.5750, G loss: 2.9139\n",
      "[1444/1600] D loss: 0.7777, G loss: 2.3350\n",
      "[1564/1600] D loss: 0.7653, G loss: 1.8306\n",
      "train error: \n",
      " D loss: 0.818435, G loss: 1.919434, D accuracy: 76.6%, cell accuracy: 98.3%, board accuracy: 25.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.012972, G loss: 2.144529, D accuracy: 70.6%, cell accuracy: 98.3%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6076, G loss: 1.9519\n",
      "[124/1600] D loss: 0.6639, G loss: 1.6664\n",
      "[244/1600] D loss: 0.6352, G loss: 1.4422\n",
      "[364/1600] D loss: 0.6031, G loss: 1.3972\n",
      "[484/1600] D loss: 0.8330, G loss: 1.4999\n",
      "[604/1600] D loss: 1.0273, G loss: 2.0517\n",
      "[724/1600] D loss: 0.6334, G loss: 2.6903\n",
      "[844/1600] D loss: 0.4032, G loss: 1.8868\n",
      "[964/1600] D loss: 0.9544, G loss: 2.1022\n",
      "[1084/1600] D loss: 1.2176, G loss: 1.6078\n",
      "[1204/1600] D loss: 0.7102, G loss: 1.1909\n",
      "[1324/1600] D loss: 0.4961, G loss: 1.6792\n",
      "[1444/1600] D loss: 0.5172, G loss: 2.8387\n",
      "[1564/1600] D loss: 0.1000, G loss: 3.7177\n",
      "train error: \n",
      " D loss: 0.948261, G loss: 1.336316, D accuracy: 73.9%, cell accuracy: 98.3%, board accuracy: 23.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.053679, G loss: 1.457096, D accuracy: 71.9%, cell accuracy: 98.2%, board accuracy: 23.0% \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1011, G loss: 1.3804\n",
      "[124/1600] D loss: 0.7066, G loss: 2.2943\n",
      "[244/1600] D loss: 0.4708, G loss: 2.9525\n",
      "[364/1600] D loss: 1.0029, G loss: 2.9954\n",
      "[484/1600] D loss: 0.6511, G loss: 1.7234\n",
      "[604/1600] D loss: 1.1488, G loss: 0.7531\n",
      "[724/1600] D loss: 0.7458, G loss: 1.7624\n",
      "[844/1600] D loss: 0.9515, G loss: 3.5550\n",
      "[964/1600] D loss: 1.0893, G loss: 1.1792\n",
      "[1084/1600] D loss: 0.7179, G loss: 2.0971\n",
      "[1204/1600] D loss: 0.9499, G loss: 1.5531\n",
      "[1324/1600] D loss: 1.2400, G loss: 2.3769\n",
      "[1444/1600] D loss: 0.8905, G loss: 1.2828\n",
      "[1564/1600] D loss: 0.7159, G loss: 2.8523\n",
      "train error: \n",
      " D loss: 0.807940, G loss: 1.809646, D accuracy: 77.9%, cell accuracy: 98.3%, board accuracy: 26.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.995680, G loss: 1.940457, D accuracy: 70.9%, cell accuracy: 98.2%, board accuracy: 24.2% \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8876, G loss: 0.9712\n",
      "[124/1600] D loss: 0.8982, G loss: 2.4292\n",
      "[244/1600] D loss: 0.7238, G loss: 2.6730\n",
      "[364/1600] D loss: 0.3924, G loss: 4.4890\n",
      "[484/1600] D loss: 0.4067, G loss: 3.6101\n",
      "[604/1600] D loss: 0.5430, G loss: 2.2013\n",
      "[724/1600] D loss: 0.6335, G loss: 2.0181\n",
      "[844/1600] D loss: 0.6589, G loss: 1.2686\n",
      "[964/1600] D loss: 1.5296, G loss: 0.5732\n",
      "[1084/1600] D loss: 0.0580, G loss: 4.3553\n",
      "[1204/1600] D loss: 0.5487, G loss: 2.8476\n",
      "[1324/1600] D loss: 0.8482, G loss: 1.8634\n",
      "[1444/1600] D loss: 0.7358, G loss: 2.4816\n",
      "[1564/1600] D loss: 1.2378, G loss: 3.4517\n",
      "train error: \n",
      " D loss: 0.865582, G loss: 2.097887, D accuracy: 75.7%, cell accuracy: 98.3%, board accuracy: 27.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.077538, G loss: 2.232624, D accuracy: 71.1%, cell accuracy: 98.2%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1998, G loss: 1.8217\n",
      "[124/1600] D loss: 0.8043, G loss: 1.4244\n",
      "[244/1600] D loss: 1.2943, G loss: 1.6868\n",
      "[364/1600] D loss: 0.4360, G loss: 4.2552\n",
      "[484/1600] D loss: 0.7107, G loss: 1.8521\n",
      "[604/1600] D loss: 0.4722, G loss: 2.3413\n",
      "[724/1600] D loss: 1.3416, G loss: 1.2299\n",
      "[844/1600] D loss: 0.7586, G loss: 1.7371\n",
      "[964/1600] D loss: 1.1315, G loss: 1.5764\n",
      "[1084/1600] D loss: 0.4217, G loss: 3.5232\n",
      "[1204/1600] D loss: 0.8610, G loss: 1.5845\n",
      "[1324/1600] D loss: 0.9277, G loss: 1.6376\n",
      "[1444/1600] D loss: 0.8893, G loss: 1.4668\n",
      "[1564/1600] D loss: 0.4652, G loss: 3.9318\n",
      "train error: \n",
      " D loss: 0.819314, G loss: 1.808119, D accuracy: 77.5%, cell accuracy: 98.3%, board accuracy: 26.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.999984, G loss: 1.980754, D accuracy: 72.4%, cell accuracy: 98.3%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2457, G loss: 0.6462\n",
      "[124/1600] D loss: 1.1387, G loss: 1.2941\n",
      "[244/1600] D loss: 0.9701, G loss: 1.7766\n",
      "[364/1600] D loss: 0.7895, G loss: 1.8271\n",
      "[484/1600] D loss: 0.7720, G loss: 2.1223\n",
      "[604/1600] D loss: 1.0144, G loss: 1.9036\n",
      "[724/1600] D loss: 0.5719, G loss: 2.0581\n",
      "[844/1600] D loss: 1.4218, G loss: 0.5197\n",
      "[964/1600] D loss: 0.5313, G loss: 1.9574\n",
      "[1084/1600] D loss: 1.0227, G loss: 1.8004\n",
      "[1204/1600] D loss: 0.8873, G loss: 1.5544\n",
      "[1324/1600] D loss: 0.4849, G loss: 2.2847\n",
      "[1444/1600] D loss: 0.7536, G loss: 1.8405\n",
      "[1564/1600] D loss: 0.8928, G loss: 1.3084\n",
      "train error: \n",
      " D loss: 0.854880, G loss: 2.223090, D accuracy: 75.8%, cell accuracy: 98.4%, board accuracy: 27.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.087032, G loss: 2.390270, D accuracy: 70.8%, cell accuracy: 98.3%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7433, G loss: 1.6275\n",
      "[124/1600] D loss: 1.4928, G loss: 2.5525\n",
      "[244/1600] D loss: 0.5346, G loss: 4.2677\n",
      "[364/1600] D loss: 0.8889, G loss: 2.4164\n",
      "[484/1600] D loss: 0.7346, G loss: 3.3525\n",
      "[604/1600] D loss: 0.9089, G loss: 1.3914\n",
      "[724/1600] D loss: 0.7999, G loss: 1.2731\n",
      "[844/1600] D loss: 1.0184, G loss: 1.0672\n",
      "[964/1600] D loss: 0.8857, G loss: 1.2509\n",
      "[1084/1600] D loss: 1.0589, G loss: 1.4550\n",
      "[1204/1600] D loss: 0.4881, G loss: 3.3926\n",
      "[1324/1600] D loss: 0.9165, G loss: 2.5214\n",
      "[1444/1600] D loss: 0.6175, G loss: 2.0915\n",
      "[1564/1600] D loss: 0.6115, G loss: 2.9196\n",
      "train error: \n",
      " D loss: 0.928257, G loss: 2.618173, D accuracy: 73.6%, cell accuracy: 98.4%, board accuracy: 27.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.185223, G loss: 2.847813, D accuracy: 69.6%, cell accuracy: 98.3%, board accuracy: 26.0% \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0658, G loss: 2.0158\n",
      "[124/1600] D loss: 1.0055, G loss: 1.2177\n",
      "[244/1600] D loss: 0.8457, G loss: 1.4703\n",
      "[364/1600] D loss: 0.5561, G loss: 1.9856\n",
      "[484/1600] D loss: 0.9651, G loss: 0.6227\n",
      "[604/1600] D loss: 0.4003, G loss: 2.0139\n",
      "[724/1600] D loss: 1.3031, G loss: 0.9398\n",
      "[844/1600] D loss: 0.5863, G loss: 1.4348\n",
      "[964/1600] D loss: 1.0852, G loss: 1.3807\n",
      "[1084/1600] D loss: 1.1460, G loss: 1.2132\n",
      "[1204/1600] D loss: 1.2048, G loss: 1.8015\n",
      "[1324/1600] D loss: 0.5313, G loss: 2.7278\n",
      "[1444/1600] D loss: 0.5741, G loss: 1.8255\n",
      "[1564/1600] D loss: 0.8029, G loss: 1.6541\n",
      "train error: \n",
      " D loss: 0.827421, G loss: 1.809253, D accuracy: 76.8%, cell accuracy: 98.4%, board accuracy: 29.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.011973, G loss: 1.977265, D accuracy: 71.9%, cell accuracy: 98.3%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6532, G loss: 1.5853\n",
      "[124/1600] D loss: 1.0392, G loss: 2.4072\n",
      "[244/1600] D loss: 1.2265, G loss: 1.4472\n",
      "[364/1600] D loss: 0.8704, G loss: 3.3648\n",
      "[484/1600] D loss: 0.3464, G loss: 3.3642\n",
      "[604/1600] D loss: 1.1841, G loss: 1.0404\n",
      "[724/1600] D loss: 0.8619, G loss: 1.4234\n",
      "[844/1600] D loss: 0.5645, G loss: 2.0070\n",
      "[964/1600] D loss: 1.4941, G loss: 0.7416\n",
      "[1084/1600] D loss: 0.4905, G loss: 3.1467\n",
      "[1204/1600] D loss: 1.1344, G loss: 0.8783\n",
      "[1324/1600] D loss: 1.0907, G loss: 1.7288\n",
      "[1444/1600] D loss: 0.8800, G loss: 2.1752\n",
      "[1564/1600] D loss: 0.7747, G loss: 1.5995\n",
      "train error: \n",
      " D loss: 0.842573, G loss: 2.151001, D accuracy: 76.6%, cell accuracy: 98.4%, board accuracy: 26.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.053109, G loss: 2.347136, D accuracy: 72.2%, cell accuracy: 98.3%, board accuracy: 23.5% \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9339, G loss: 3.4281\n",
      "[124/1600] D loss: 1.1980, G loss: 0.7321\n",
      "[244/1600] D loss: 1.1845, G loss: 1.3581\n",
      "[364/1600] D loss: 1.2315, G loss: 0.8172\n",
      "[484/1600] D loss: 1.0246, G loss: 1.2525\n",
      "[604/1600] D loss: 1.2274, G loss: 0.7255\n",
      "[724/1600] D loss: 0.5860, G loss: 2.0782\n",
      "[844/1600] D loss: 0.8549, G loss: 1.8715\n",
      "[964/1600] D loss: 0.9631, G loss: 3.4390\n",
      "[1084/1600] D loss: 0.6040, G loss: 1.1658\n",
      "[1204/1600] D loss: 1.8557, G loss: 0.4465\n",
      "[1324/1600] D loss: 0.2730, G loss: 1.9187\n",
      "[1444/1600] D loss: 0.6842, G loss: 1.0576\n",
      "[1564/1600] D loss: 0.3400, G loss: 3.1217\n",
      "train error: \n",
      " D loss: 0.852345, G loss: 1.655186, D accuracy: 75.2%, cell accuracy: 98.5%, board accuracy: 31.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.017549, G loss: 1.854941, D accuracy: 70.6%, cell accuracy: 98.4%, board accuracy: 31.0% \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7213, G loss: 2.7104\n",
      "[124/1600] D loss: 0.5106, G loss: 3.0855\n",
      "[244/1600] D loss: 0.3327, G loss: 3.2577\n",
      "[364/1600] D loss: 0.3711, G loss: 3.8602\n",
      "[484/1600] D loss: 0.2622, G loss: 3.8894\n",
      "[604/1600] D loss: 1.1574, G loss: 0.9499\n",
      "[724/1600] D loss: 0.5128, G loss: 3.3000\n",
      "[844/1600] D loss: 0.7683, G loss: 2.3085\n",
      "[964/1600] D loss: 0.8658, G loss: 1.6200\n",
      "[1084/1600] D loss: 0.6307, G loss: 2.4552\n",
      "[1204/1600] D loss: 0.5158, G loss: 3.3398\n",
      "[1324/1600] D loss: 0.5304, G loss: 1.6213\n",
      "[1444/1600] D loss: 0.6977, G loss: 1.8471\n",
      "[1564/1600] D loss: 0.6396, G loss: 2.6020\n",
      "train error: \n",
      " D loss: 0.889764, G loss: 2.284507, D accuracy: 74.2%, cell accuracy: 98.4%, board accuracy: 28.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.128979, G loss: 2.420586, D accuracy: 70.6%, cell accuracy: 98.3%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4591, G loss: 2.5640\n",
      "[124/1600] D loss: 0.8469, G loss: 1.9322\n",
      "[244/1600] D loss: 0.6254, G loss: 2.3029\n",
      "[364/1600] D loss: 0.9177, G loss: 1.1699\n",
      "[484/1600] D loss: 0.5384, G loss: 2.2125\n",
      "[604/1600] D loss: 0.5140, G loss: 3.2677\n",
      "[724/1600] D loss: 0.7411, G loss: 2.4314\n",
      "[844/1600] D loss: 0.6774, G loss: 2.4558\n",
      "[964/1600] D loss: 0.9558, G loss: 0.9739\n",
      "[1084/1600] D loss: 0.9532, G loss: 1.8157\n",
      "[1204/1600] D loss: 1.7636, G loss: 1.3901\n",
      "[1324/1600] D loss: 1.0638, G loss: 0.8651\n",
      "[1444/1600] D loss: 0.7173, G loss: 2.8306\n",
      "[1564/1600] D loss: 1.6874, G loss: 0.5809\n",
      "train error: \n",
      " D loss: 0.884284, G loss: 1.672657, D accuracy: 75.2%, cell accuracy: 98.4%, board accuracy: 28.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.026801, G loss: 1.850823, D accuracy: 71.0%, cell accuracy: 98.3%, board accuracy: 29.0% \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0815, G loss: 1.4727\n",
      "[124/1600] D loss: 1.0577, G loss: 1.4673\n",
      "[244/1600] D loss: 0.6805, G loss: 2.6076\n",
      "[364/1600] D loss: 0.3929, G loss: 3.4082\n",
      "[484/1600] D loss: 0.4728, G loss: 2.4499\n",
      "[604/1600] D loss: 0.4123, G loss: 3.4181\n",
      "[724/1600] D loss: 0.4347, G loss: 2.3650\n",
      "[844/1600] D loss: 0.7491, G loss: 1.9190\n",
      "[964/1600] D loss: 1.0360, G loss: 2.5597\n",
      "[1084/1600] D loss: 1.1322, G loss: 1.7536\n",
      "[1204/1600] D loss: 0.5167, G loss: 2.4234\n",
      "[1324/1600] D loss: 0.9664, G loss: 0.9857\n",
      "[1444/1600] D loss: 1.3156, G loss: 0.7248\n",
      "[1564/1600] D loss: 1.1833, G loss: 1.4298\n",
      "train error: \n",
      " D loss: 0.882495, G loss: 1.621013, D accuracy: 74.6%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.049482, G loss: 1.788876, D accuracy: 69.9%, cell accuracy: 98.3%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9637, G loss: 2.2016\n",
      "[124/1600] D loss: 0.4490, G loss: 2.7563\n",
      "[244/1600] D loss: 0.7858, G loss: 1.5217\n",
      "[364/1600] D loss: 0.3721, G loss: 2.9883\n",
      "[484/1600] D loss: 0.4014, G loss: 1.9832\n",
      "[604/1600] D loss: 0.1288, G loss: 2.4573\n",
      "[724/1600] D loss: 0.5689, G loss: 2.7722\n",
      "[844/1600] D loss: 1.3553, G loss: 1.7134\n",
      "[964/1600] D loss: 0.2153, G loss: 2.4254\n",
      "[1084/1600] D loss: 1.2237, G loss: 1.3146\n",
      "[1204/1600] D loss: 0.7348, G loss: 1.7621\n",
      "[1324/1600] D loss: 1.2047, G loss: 1.5539\n",
      "[1444/1600] D loss: 1.3368, G loss: 1.2990\n",
      "[1564/1600] D loss: 0.5448, G loss: 2.9315\n",
      "train error: \n",
      " D loss: 0.939310, G loss: 2.431714, D accuracy: 72.3%, cell accuracy: 98.5%, board accuracy: 30.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.192686, G loss: 2.562081, D accuracy: 68.4%, cell accuracy: 98.3%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.7612, G loss: 1.1644\n",
      "[124/1600] D loss: 1.1346, G loss: 1.3581\n",
      "[244/1600] D loss: 0.5478, G loss: 2.9777\n",
      "[364/1600] D loss: 0.3261, G loss: 3.1104\n",
      "[484/1600] D loss: 0.3067, G loss: 3.0187\n",
      "[604/1600] D loss: 0.8668, G loss: 1.0471\n",
      "[724/1600] D loss: 0.9884, G loss: 0.9952\n",
      "[844/1600] D loss: 0.5749, G loss: 2.4343\n",
      "[964/1600] D loss: 1.0990, G loss: 1.2335\n",
      "[1084/1600] D loss: 1.0091, G loss: 1.4644\n",
      "[1204/1600] D loss: 0.7104, G loss: 2.4914\n",
      "[1324/1600] D loss: 0.9738, G loss: 1.9572\n",
      "[1444/1600] D loss: 1.1332, G loss: 0.7630\n",
      "[1564/1600] D loss: 0.8130, G loss: 1.1908\n",
      "train error: \n",
      " D loss: 0.894594, G loss: 1.865252, D accuracy: 74.8%, cell accuracy: 98.5%, board accuracy: 32.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.074013, G loss: 2.039583, D accuracy: 70.6%, cell accuracy: 98.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6290, G loss: 3.7256\n",
      "[124/1600] D loss: 0.5169, G loss: 2.4619\n",
      "[244/1600] D loss: 0.7364, G loss: 1.4881\n",
      "[364/1600] D loss: 0.9024, G loss: 2.1995\n",
      "[484/1600] D loss: 0.6284, G loss: 3.6568\n",
      "[604/1600] D loss: 1.1379, G loss: 1.2617\n",
      "[724/1600] D loss: 1.1346, G loss: 2.0609\n",
      "[844/1600] D loss: 0.9970, G loss: 1.8249\n",
      "[964/1600] D loss: 0.9636, G loss: 1.1917\n",
      "[1084/1600] D loss: 0.8669, G loss: 1.8231\n",
      "[1204/1600] D loss: 0.1421, G loss: 2.5435\n",
      "[1324/1600] D loss: 0.8723, G loss: 3.7835\n",
      "[1444/1600] D loss: 0.8791, G loss: 2.4187\n",
      "[1564/1600] D loss: 0.3227, G loss: 3.2744\n",
      "train error: \n",
      " D loss: 0.920811, G loss: 1.668105, D accuracy: 74.9%, cell accuracy: 98.5%, board accuracy: 32.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.083760, G loss: 1.802090, D accuracy: 70.1%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8192, G loss: 1.8668\n",
      "[124/1600] D loss: 1.2713, G loss: 2.5908\n",
      "[244/1600] D loss: 0.8313, G loss: 2.9112\n",
      "[364/1600] D loss: 1.1250, G loss: 0.7773\n",
      "[484/1600] D loss: 2.3435, G loss: 0.4500\n",
      "[604/1600] D loss: 1.4011, G loss: 1.0449\n",
      "[724/1600] D loss: 0.4637, G loss: 3.0402\n",
      "[844/1600] D loss: 1.3127, G loss: 1.1047\n",
      "[964/1600] D loss: 0.9759, G loss: 1.4135\n",
      "[1084/1600] D loss: 1.1010, G loss: 2.7455\n",
      "[1204/1600] D loss: 0.5060, G loss: 2.8825\n",
      "[1324/1600] D loss: 0.9163, G loss: 1.6148\n",
      "[1444/1600] D loss: 0.9145, G loss: 1.7025\n",
      "[1564/1600] D loss: 0.8959, G loss: 3.0030\n",
      "train error: \n",
      " D loss: 0.900639, G loss: 2.109696, D accuracy: 74.2%, cell accuracy: 98.5%, board accuracy: 32.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.098409, G loss: 2.288954, D accuracy: 69.8%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7441, G loss: 3.5314\n",
      "[124/1600] D loss: 0.9206, G loss: 2.3533\n",
      "[244/1600] D loss: 1.0989, G loss: 1.2741\n",
      "[364/1600] D loss: 0.9316, G loss: 1.8614\n",
      "[484/1600] D loss: 0.1191, G loss: 2.5043\n",
      "[604/1600] D loss: 1.0450, G loss: 1.1646\n",
      "[724/1600] D loss: 1.1676, G loss: 1.9543\n",
      "[844/1600] D loss: 0.6843, G loss: 2.8860\n",
      "[964/1600] D loss: 0.6045, G loss: 2.7286\n",
      "[1084/1600] D loss: 0.4615, G loss: 3.1664\n",
      "[1204/1600] D loss: 1.0894, G loss: 0.8572\n",
      "[1324/1600] D loss: 1.2104, G loss: 1.6416\n",
      "[1444/1600] D loss: 0.8463, G loss: 1.7700\n",
      "[1564/1600] D loss: 1.1338, G loss: 1.6180\n",
      "train error: \n",
      " D loss: 0.917941, G loss: 1.686747, D accuracy: 74.5%, cell accuracy: 98.5%, board accuracy: 32.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.073814, G loss: 1.842254, D accuracy: 70.1%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0760, G loss: 0.9392\n",
      "[124/1600] D loss: 0.8529, G loss: 0.9203\n",
      "[244/1600] D loss: 1.4874, G loss: 0.6572\n",
      "[364/1600] D loss: 1.0093, G loss: 1.5928\n",
      "[484/1600] D loss: 1.4425, G loss: 0.9885\n",
      "[604/1600] D loss: 1.3311, G loss: 1.5714\n",
      "[724/1600] D loss: 1.0678, G loss: 1.1179\n",
      "[844/1600] D loss: 0.6382, G loss: 2.8658\n",
      "[964/1600] D loss: 1.1545, G loss: 0.9841\n",
      "[1084/1600] D loss: 1.2258, G loss: 3.8282\n",
      "[1204/1600] D loss: 0.7156, G loss: 2.7060\n",
      "[1324/1600] D loss: 1.2204, G loss: 1.0655\n",
      "[1444/1600] D loss: 0.4822, G loss: 2.6538\n",
      "[1564/1600] D loss: 1.1671, G loss: 1.1038\n",
      "train error: \n",
      " D loss: 1.053513, G loss: 1.260429, D accuracy: 72.3%, cell accuracy: 98.5%, board accuracy: 31.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.168593, G loss: 1.398783, D accuracy: 70.6%, cell accuracy: 98.4%, board accuracy: 31.0% \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0457, G loss: 2.0027\n",
      "[124/1600] D loss: 0.8762, G loss: 1.9428\n",
      "[244/1600] D loss: 0.1747, G loss: 3.8124\n",
      "[364/1600] D loss: 1.0559, G loss: 1.7930\n",
      "[484/1600] D loss: 0.5871, G loss: 3.8733\n",
      "[604/1600] D loss: 0.9016, G loss: 1.2416\n",
      "[724/1600] D loss: 0.4020, G loss: 3.6918\n",
      "[844/1600] D loss: 0.0723, G loss: 2.8958\n",
      "[964/1600] D loss: 1.4525, G loss: 1.6409\n",
      "[1084/1600] D loss: 0.9602, G loss: 2.8426\n",
      "[1204/1600] D loss: 1.1253, G loss: 1.0531\n",
      "[1324/1600] D loss: 0.7228, G loss: 1.8186\n",
      "[1444/1600] D loss: 1.3820, G loss: 0.7285\n",
      "[1564/1600] D loss: 0.7318, G loss: 1.7925\n",
      "train error: \n",
      " D loss: 0.878407, G loss: 1.780106, D accuracy: 75.3%, cell accuracy: 98.5%, board accuracy: 32.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.049427, G loss: 1.999493, D accuracy: 71.0%, cell accuracy: 98.4%, board accuracy: 31.0% \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1201, G loss: 1.1263\n",
      "[124/1600] D loss: 0.8766, G loss: 2.1961\n",
      "[244/1600] D loss: 1.4812, G loss: 0.6883\n",
      "[364/1600] D loss: 1.1320, G loss: 1.1784\n",
      "[484/1600] D loss: 0.9232, G loss: 1.6583\n",
      "[604/1600] D loss: 1.5924, G loss: 0.5742\n",
      "[724/1600] D loss: 1.2012, G loss: 0.7991\n",
      "[844/1600] D loss: 1.0473, G loss: 1.0188\n",
      "[964/1600] D loss: 1.2998, G loss: 2.4442\n",
      "[1084/1600] D loss: 1.0421, G loss: 1.0584\n",
      "[1204/1600] D loss: 1.4545, G loss: 0.6113\n",
      "[1324/1600] D loss: 0.5691, G loss: 2.5056\n",
      "[1444/1600] D loss: 0.3469, G loss: 1.8888\n",
      "[1564/1600] D loss: 0.8783, G loss: 1.3985\n",
      "train error: \n",
      " D loss: 0.887939, G loss: 1.755514, D accuracy: 74.7%, cell accuracy: 98.5%, board accuracy: 32.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.039482, G loss: 1.965675, D accuracy: 71.4%, cell accuracy: 98.4%, board accuracy: 32.8% \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2125, G loss: 1.6272\n",
      "[124/1600] D loss: 0.8916, G loss: 1.8942\n",
      "[244/1600] D loss: 0.8745, G loss: 1.7209\n",
      "[364/1600] D loss: 1.4126, G loss: 0.8864\n",
      "[484/1600] D loss: 0.4504, G loss: 1.9545\n",
      "[604/1600] D loss: 0.2296, G loss: 4.1725\n",
      "[724/1600] D loss: 1.0878, G loss: 1.6659\n",
      "[844/1600] D loss: 0.8995, G loss: 4.1395\n",
      "[964/1600] D loss: 1.1602, G loss: 1.5993\n",
      "[1084/1600] D loss: 0.6196, G loss: 3.0221\n",
      "[1204/1600] D loss: 0.4082, G loss: 2.7491\n",
      "[1324/1600] D loss: 1.0837, G loss: 1.3044\n",
      "[1444/1600] D loss: 0.5022, G loss: 2.9789\n",
      "[1564/1600] D loss: 0.4456, G loss: 2.3157\n",
      "train error: \n",
      " D loss: 0.871983, G loss: 1.698589, D accuracy: 75.0%, cell accuracy: 98.5%, board accuracy: 31.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.028441, G loss: 1.877670, D accuracy: 71.5%, cell accuracy: 98.4%, board accuracy: 30.5% \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8915, G loss: 1.6665\n",
      "[124/1600] D loss: 0.7745, G loss: 3.4663\n",
      "[244/1600] D loss: 1.0391, G loss: 1.4255\n",
      "[364/1600] D loss: 0.2353, G loss: 2.5956\n",
      "[484/1600] D loss: 0.7225, G loss: 1.8844\n",
      "[604/1600] D loss: 0.4014, G loss: 3.2771\n",
      "[724/1600] D loss: 1.0164, G loss: 1.3262\n",
      "[844/1600] D loss: 0.7782, G loss: 1.7379\n",
      "[964/1600] D loss: 1.4381, G loss: 1.1289\n",
      "[1084/1600] D loss: 0.8825, G loss: 3.3696\n",
      "[1204/1600] D loss: 0.6512, G loss: 2.0126\n",
      "[1324/1600] D loss: 0.5128, G loss: 2.5661\n",
      "[1444/1600] D loss: 0.5266, G loss: 1.9143\n",
      "[1564/1600] D loss: 1.2953, G loss: 1.2128\n",
      "train error: \n",
      " D loss: 0.872059, G loss: 1.887653, D accuracy: 75.5%, cell accuracy: 98.5%, board accuracy: 32.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.072676, G loss: 2.090951, D accuracy: 70.1%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7300, G loss: 2.0294\n",
      "[124/1600] D loss: 0.7937, G loss: 3.1241\n",
      "[244/1600] D loss: 0.2587, G loss: 2.6623\n",
      "[364/1600] D loss: 1.0905, G loss: 0.7694\n",
      "[484/1600] D loss: 0.8222, G loss: 1.5906\n",
      "[604/1600] D loss: 0.4526, G loss: 1.4356\n",
      "[724/1600] D loss: 0.5802, G loss: 1.8932\n",
      "[844/1600] D loss: 0.5087, G loss: 2.1047\n",
      "[964/1600] D loss: 1.2976, G loss: 1.4873\n",
      "[1084/1600] D loss: 0.5160, G loss: 2.3132\n",
      "[1204/1600] D loss: 0.7111, G loss: 2.7827\n",
      "[1324/1600] D loss: 1.3192, G loss: 1.2879\n",
      "[1444/1600] D loss: 0.6497, G loss: 2.7972\n",
      "[1564/1600] D loss: 1.0963, G loss: 0.8186\n",
      "train error: \n",
      " D loss: 0.903516, G loss: 2.047422, D accuracy: 73.9%, cell accuracy: 98.5%, board accuracy: 31.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.101577, G loss: 2.278394, D accuracy: 69.0%, cell accuracy: 98.4%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7681, G loss: 4.3685\n",
      "[124/1600] D loss: 0.1809, G loss: 2.5103\n",
      "[244/1600] D loss: 0.5773, G loss: 2.1612\n",
      "[364/1600] D loss: 0.5186, G loss: 2.5770\n",
      "[484/1600] D loss: 1.0789, G loss: 1.6015\n",
      "[604/1600] D loss: 1.4259, G loss: 0.4970\n",
      "[724/1600] D loss: 0.3816, G loss: 3.7251\n",
      "[844/1600] D loss: 1.3413, G loss: 0.7440\n",
      "[964/1600] D loss: 0.4379, G loss: 3.5808\n",
      "[1084/1600] D loss: 0.4955, G loss: 3.6619\n",
      "[1204/1600] D loss: 1.4866, G loss: 1.1129\n",
      "[1324/1600] D loss: 1.3026, G loss: 0.8318\n",
      "[1444/1600] D loss: 0.8696, G loss: 1.9197\n",
      "[1564/1600] D loss: 1.1481, G loss: 1.7555\n",
      "train error: \n",
      " D loss: 0.918060, G loss: 1.481642, D accuracy: 74.2%, cell accuracy: 98.5%, board accuracy: 30.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.029864, G loss: 1.676957, D accuracy: 71.5%, cell accuracy: 98.4%, board accuracy: 30.2% \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4409, G loss: 2.7255\n",
      "[124/1600] D loss: 0.8098, G loss: 2.1817\n",
      "[244/1600] D loss: 0.6969, G loss: 2.5473\n",
      "[364/1600] D loss: 0.5280, G loss: 1.6774\n",
      "[484/1600] D loss: 0.9612, G loss: 1.0435\n",
      "[604/1600] D loss: 1.3845, G loss: 1.0163\n",
      "[724/1600] D loss: 1.1746, G loss: 1.4934\n",
      "[844/1600] D loss: 1.0394, G loss: 1.1039\n",
      "[964/1600] D loss: 0.5058, G loss: 3.2713\n",
      "[1084/1600] D loss: 0.9563, G loss: 1.1312\n",
      "[1204/1600] D loss: 1.2069, G loss: 1.0488\n",
      "[1324/1600] D loss: 1.4039, G loss: 0.9193\n",
      "[1444/1600] D loss: 1.0822, G loss: 1.7411\n",
      "[1564/1600] D loss: 0.8606, G loss: 3.0656\n",
      "train error: \n",
      " D loss: 1.185065, G loss: 1.092086, D accuracy: 71.2%, cell accuracy: 98.5%, board accuracy: 34.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266347, G loss: 1.218067, D accuracy: 68.5%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4096, G loss: 1.4250\n",
      "[124/1600] D loss: 1.0906, G loss: 1.0471\n",
      "[244/1600] D loss: 0.8072, G loss: 1.6169\n",
      "[364/1600] D loss: 1.1253, G loss: 1.0938\n",
      "[484/1600] D loss: 0.5907, G loss: 2.7255\n",
      "[604/1600] D loss: 0.9320, G loss: 2.4946\n",
      "[724/1600] D loss: 0.7229, G loss: 2.2257\n",
      "[844/1600] D loss: 0.3759, G loss: 4.1978\n",
      "[964/1600] D loss: 0.7460, G loss: 2.2886\n",
      "[1084/1600] D loss: 0.7544, G loss: 1.9856\n",
      "[1204/1600] D loss: 0.4149, G loss: 3.1976\n",
      "[1324/1600] D loss: 0.7780, G loss: 1.5723\n",
      "[1444/1600] D loss: 0.7847, G loss: 2.4583\n",
      "[1564/1600] D loss: 1.3528, G loss: 1.8143\n",
      "train error: \n",
      " D loss: 0.894806, G loss: 1.680282, D accuracy: 74.8%, cell accuracy: 98.5%, board accuracy: 33.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.073449, G loss: 1.870820, D accuracy: 70.0%, cell accuracy: 98.4%, board accuracy: 29.5% \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7676, G loss: 2.2383\n",
      "[124/1600] D loss: 0.7356, G loss: 2.1971\n",
      "[244/1600] D loss: 0.1245, G loss: 3.0566\n",
      "[364/1600] D loss: 0.6369, G loss: 3.3975\n",
      "[484/1600] D loss: 0.5054, G loss: 1.5806\n",
      "[604/1600] D loss: 1.3302, G loss: 1.0251\n",
      "[724/1600] D loss: 0.6921, G loss: 3.3037\n",
      "[844/1600] D loss: 1.0422, G loss: 0.9438\n",
      "[964/1600] D loss: 0.6934, G loss: 1.8810\n",
      "[1084/1600] D loss: 1.0872, G loss: 0.9327\n",
      "[1204/1600] D loss: 1.2443, G loss: 1.0118\n",
      "[1324/1600] D loss: 1.2076, G loss: 0.9715\n",
      "[1444/1600] D loss: 0.8393, G loss: 1.3602\n",
      "[1564/1600] D loss: 1.0966, G loss: 1.5206\n",
      "train error: \n",
      " D loss: 0.899336, G loss: 2.210267, D accuracy: 73.8%, cell accuracy: 98.5%, board accuracy: 31.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.136324, G loss: 2.418773, D accuracy: 69.2%, cell accuracy: 98.4%, board accuracy: 31.0% \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0319, G loss: 2.1528\n",
      "[124/1600] D loss: 0.8110, G loss: 1.8705\n",
      "[244/1600] D loss: 0.8950, G loss: 0.9598\n",
      "[364/1600] D loss: 0.5361, G loss: 1.8537\n",
      "[484/1600] D loss: 0.5441, G loss: 1.9811\n",
      "[604/1600] D loss: 0.7644, G loss: 2.2414\n",
      "[724/1600] D loss: 0.9606, G loss: 1.1981\n",
      "[844/1600] D loss: 1.2094, G loss: 1.2491\n",
      "[964/1600] D loss: 0.3083, G loss: 3.4919\n",
      "[1084/1600] D loss: 0.4867, G loss: 3.7840\n",
      "[1204/1600] D loss: 1.0225, G loss: 1.2129\n",
      "[1324/1600] D loss: 1.4145, G loss: 0.6946\n",
      "[1444/1600] D loss: 1.1771, G loss: 0.6126\n",
      "[1564/1600] D loss: 1.0541, G loss: 1.2824\n",
      "train error: \n",
      " D loss: 0.889750, G loss: 1.555084, D accuracy: 75.1%, cell accuracy: 98.5%, board accuracy: 32.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.047607, G loss: 1.803577, D accuracy: 71.9%, cell accuracy: 98.4%, board accuracy: 31.8% \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4122, G loss: 2.9006\n",
      "[124/1600] D loss: 1.3006, G loss: 1.4661\n",
      "[244/1600] D loss: 0.8839, G loss: 1.5931\n",
      "[364/1600] D loss: 0.5073, G loss: 2.7130\n",
      "[484/1600] D loss: 0.6838, G loss: 1.9544\n",
      "[604/1600] D loss: 1.3596, G loss: 0.8240\n",
      "[724/1600] D loss: 0.6524, G loss: 3.3459\n",
      "[844/1600] D loss: 0.8354, G loss: 2.1403\n",
      "[964/1600] D loss: 0.2973, G loss: 4.2391\n",
      "[1084/1600] D loss: 0.5945, G loss: 1.6453\n",
      "[1204/1600] D loss: 1.0064, G loss: 1.1257\n",
      "[1324/1600] D loss: 1.2417, G loss: 1.5718\n",
      "[1444/1600] D loss: 1.3656, G loss: 0.6581\n",
      "[1564/1600] D loss: 0.7852, G loss: 1.9737\n",
      "train error: \n",
      " D loss: 0.900202, G loss: 1.669696, D accuracy: 74.7%, cell accuracy: 98.5%, board accuracy: 32.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.096074, G loss: 1.898979, D accuracy: 69.4%, cell accuracy: 98.4%, board accuracy: 31.5% \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7451, G loss: 1.8158\n",
      "[124/1600] D loss: 1.1678, G loss: 0.7757\n",
      "[244/1600] D loss: 0.6822, G loss: 1.8089\n",
      "[364/1600] D loss: 0.9122, G loss: 1.7670\n",
      "[484/1600] D loss: 1.1261, G loss: 1.1493\n",
      "[604/1600] D loss: 0.5620, G loss: 2.4554\n",
      "[724/1600] D loss: 0.5521, G loss: 2.8582\n",
      "[844/1600] D loss: 0.3678, G loss: 3.0671\n",
      "[964/1600] D loss: 1.0100, G loss: 1.0908\n",
      "[1084/1600] D loss: 0.9331, G loss: 1.0442\n",
      "[1204/1600] D loss: 0.6317, G loss: 2.2648\n",
      "[1324/1600] D loss: 0.9228, G loss: 1.3448\n",
      "[1444/1600] D loss: 0.8061, G loss: 1.6903\n",
      "[1564/1600] D loss: 0.7640, G loss: 1.7811\n",
      "train error: \n",
      " D loss: 0.878529, G loss: 1.668276, D accuracy: 75.1%, cell accuracy: 98.4%, board accuracy: 30.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.055133, G loss: 1.910099, D accuracy: 71.0%, cell accuracy: 98.3%, board accuracy: 29.5% \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4315, G loss: 3.5951\n",
      "[124/1600] D loss: 1.0090, G loss: 1.8994\n",
      "[244/1600] D loss: 0.3770, G loss: 4.3591\n",
      "[364/1600] D loss: 0.0660, G loss: 3.7223\n",
      "[484/1600] D loss: 0.9259, G loss: 1.3069\n",
      "[604/1600] D loss: 0.5178, G loss: 2.6636\n",
      "[724/1600] D loss: 0.4734, G loss: 2.2327\n",
      "[844/1600] D loss: 1.0824, G loss: 1.6655\n",
      "[964/1600] D loss: 0.7460, G loss: 1.5917\n",
      "[1084/1600] D loss: 0.7548, G loss: 1.9344\n",
      "[1204/1600] D loss: 1.0550, G loss: 1.6533\n",
      "[1324/1600] D loss: 1.1616, G loss: 1.0474\n",
      "[1444/1600] D loss: 0.9667, G loss: 1.3951\n",
      "[1564/1600] D loss: 1.0377, G loss: 1.7565\n",
      "train error: \n",
      " D loss: 0.879059, G loss: 1.883243, D accuracy: 74.5%, cell accuracy: 98.4%, board accuracy: 33.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.092768, G loss: 2.144551, D accuracy: 69.4%, cell accuracy: 98.3%, board accuracy: 31.8% \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4987, G loss: 1.9290\n",
      "[124/1600] D loss: 0.8756, G loss: 1.6750\n",
      "[244/1600] D loss: 0.6108, G loss: 1.6752\n",
      "[364/1600] D loss: 0.6087, G loss: 2.0880\n",
      "[484/1600] D loss: 0.9534, G loss: 1.4680\n",
      "[604/1600] D loss: 1.1310, G loss: 1.5271\n",
      "[724/1600] D loss: 0.7865, G loss: 2.5426\n",
      "[844/1600] D loss: 1.2434, G loss: 0.8306\n",
      "[964/1600] D loss: 0.4925, G loss: 2.2517\n",
      "[1084/1600] D loss: 0.9719, G loss: 2.4949\n",
      "[1204/1600] D loss: 0.8846, G loss: 2.2602\n",
      "[1324/1600] D loss: 1.0695, G loss: 1.3755\n",
      "[1444/1600] D loss: 0.5701, G loss: 3.0811\n",
      "[1564/1600] D loss: 0.7922, G loss: 2.7555\n",
      "train error: \n",
      " D loss: 0.873184, G loss: 2.008803, D accuracy: 75.3%, cell accuracy: 98.5%, board accuracy: 33.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.107070, G loss: 2.223913, D accuracy: 70.8%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2615, G loss: 1.8489\n",
      "[124/1600] D loss: 1.5993, G loss: 0.9893\n",
      "[244/1600] D loss: 1.1641, G loss: 1.5005\n",
      "[364/1600] D loss: 1.3706, G loss: 0.7035\n",
      "[484/1600] D loss: 0.8636, G loss: 1.7887\n",
      "[604/1600] D loss: 0.7320, G loss: 1.6040\n",
      "[724/1600] D loss: 0.9687, G loss: 2.7772\n",
      "[844/1600] D loss: 0.6844, G loss: 2.7987\n",
      "[964/1600] D loss: 0.5187, G loss: 2.9778\n",
      "[1084/1600] D loss: 1.0154, G loss: 1.9330\n",
      "[1204/1600] D loss: 1.4484, G loss: 2.0516\n",
      "[1324/1600] D loss: 0.2625, G loss: 3.4975\n",
      "[1444/1600] D loss: 0.9868, G loss: 1.6737\n",
      "[1564/1600] D loss: 0.4445, G loss: 2.2027\n",
      "train error: \n",
      " D loss: 0.936729, G loss: 1.450414, D accuracy: 73.6%, cell accuracy: 98.5%, board accuracy: 31.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.108635, G loss: 1.698550, D accuracy: 70.5%, cell accuracy: 98.4%, board accuracy: 32.2% \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7667, G loss: 0.8762\n",
      "[124/1600] D loss: 0.9007, G loss: 1.9639\n",
      "[244/1600] D loss: 1.1312, G loss: 1.4074\n",
      "[364/1600] D loss: 0.7518, G loss: 1.0054\n",
      "[484/1600] D loss: 0.8162, G loss: 1.8994\n",
      "[604/1600] D loss: 1.0403, G loss: 0.9464\n",
      "[724/1600] D loss: 0.5352, G loss: 3.0465\n",
      "[844/1600] D loss: 0.5283, G loss: 2.1718\n",
      "[964/1600] D loss: 0.5787, G loss: 1.5859\n",
      "[1084/1600] D loss: 0.6828, G loss: 1.5747\n",
      "[1204/1600] D loss: 0.6299, G loss: 2.7601\n",
      "[1324/1600] D loss: 0.7175, G loss: 2.2110\n",
      "[1444/1600] D loss: 0.4673, G loss: 1.8162\n",
      "[1564/1600] D loss: 1.0169, G loss: 2.1004\n",
      "train error: \n",
      " D loss: 0.917786, G loss: 1.911128, D accuracy: 72.8%, cell accuracy: 98.4%, board accuracy: 33.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.145526, G loss: 2.180127, D accuracy: 67.8%, cell accuracy: 98.3%, board accuracy: 33.5% \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1388, G loss: 1.0726\n",
      "[124/1600] D loss: 1.0503, G loss: 1.6699\n",
      "[244/1600] D loss: 1.2428, G loss: 0.8136\n",
      "[364/1600] D loss: 0.2003, G loss: 2.5895\n",
      "[484/1600] D loss: 0.4840, G loss: 2.5222\n",
      "[604/1600] D loss: 0.9737, G loss: 1.5965\n",
      "[724/1600] D loss: 0.7572, G loss: 2.2009\n",
      "[844/1600] D loss: 0.9777, G loss: 0.8125\n",
      "[964/1600] D loss: 0.1775, G loss: 3.0601\n",
      "[1084/1600] D loss: 1.3193, G loss: 0.6523\n",
      "[1204/1600] D loss: 0.7256, G loss: 2.2028\n",
      "[1324/1600] D loss: 1.0882, G loss: 1.3255\n",
      "[1444/1600] D loss: 0.6065, G loss: 1.2346\n",
      "[1564/1600] D loss: 0.8281, G loss: 2.0728\n",
      "train error: \n",
      " D loss: 0.916459, G loss: 2.020247, D accuracy: 72.7%, cell accuracy: 98.5%, board accuracy: 34.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.130436, G loss: 2.309407, D accuracy: 69.2%, cell accuracy: 98.4%, board accuracy: 35.0% \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9906, G loss: 1.9384\n",
      "[124/1600] D loss: 1.0083, G loss: 1.8291\n",
      "[244/1600] D loss: 1.0681, G loss: 2.0412\n",
      "[364/1600] D loss: 0.4947, G loss: 2.2429\n",
      "[484/1600] D loss: 0.6839, G loss: 1.9471\n",
      "[604/1600] D loss: 0.9245, G loss: 1.3138\n",
      "[724/1600] D loss: 1.1365, G loss: 1.1111\n",
      "[844/1600] D loss: 0.2634, G loss: 4.3723\n",
      "[964/1600] D loss: 0.6496, G loss: 2.3229\n",
      "[1084/1600] D loss: 0.7307, G loss: 1.4449\n",
      "[1204/1600] D loss: 0.4320, G loss: 2.7265\n",
      "[1324/1600] D loss: 1.4509, G loss: 0.8048\n",
      "[1444/1600] D loss: 1.3578, G loss: 0.9851\n",
      "[1564/1600] D loss: 1.0425, G loss: 1.0411\n",
      "train error: \n",
      " D loss: 0.948875, G loss: 2.090270, D accuracy: 71.4%, cell accuracy: 98.5%, board accuracy: 35.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.201205, G loss: 2.371896, D accuracy: 67.5%, cell accuracy: 98.4%, board accuracy: 36.2% \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1524, G loss: 1.6441\n",
      "[124/1600] D loss: 1.1613, G loss: 0.6737\n",
      "[244/1600] D loss: 1.5887, G loss: 0.5852\n",
      "[364/1600] D loss: 1.7700, G loss: 0.9800\n",
      "[484/1600] D loss: 1.1968, G loss: 1.1126\n",
      "[604/1600] D loss: 1.0715, G loss: 1.1962\n",
      "[724/1600] D loss: 1.2643, G loss: 0.7989\n",
      "[844/1600] D loss: 0.4211, G loss: 3.0854\n",
      "[964/1600] D loss: 0.8390, G loss: 2.2744\n",
      "[1084/1600] D loss: 1.1630, G loss: 1.0566\n",
      "[1204/1600] D loss: 0.8593, G loss: 1.5789\n",
      "[1324/1600] D loss: 1.1696, G loss: 1.5131\n",
      "[1444/1600] D loss: 1.0806, G loss: 0.9419\n",
      "[1564/1600] D loss: 0.5114, G loss: 2.2503\n",
      "train error: \n",
      " D loss: 0.878912, G loss: 1.851095, D accuracy: 74.0%, cell accuracy: 98.6%, board accuracy: 35.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.110156, G loss: 2.125972, D accuracy: 68.9%, cell accuracy: 98.4%, board accuracy: 35.8% \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8722, G loss: 1.2721\n",
      "[124/1600] D loss: 0.2420, G loss: 3.4197\n",
      "[244/1600] D loss: 0.9229, G loss: 1.6497\n",
      "[364/1600] D loss: 1.1721, G loss: 1.5329\n",
      "[484/1600] D loss: 0.5854, G loss: 1.5286\n",
      "[604/1600] D loss: 1.0686, G loss: 1.0850\n",
      "[724/1600] D loss: 1.1120, G loss: 1.5280\n",
      "[844/1600] D loss: 0.0971, G loss: 2.6857\n",
      "[964/1600] D loss: 1.2358, G loss: 1.1418\n",
      "[1084/1600] D loss: 1.0573, G loss: 1.4537\n",
      "[1204/1600] D loss: 0.3927, G loss: 2.1613\n",
      "[1324/1600] D loss: 0.2283, G loss: 3.1613\n",
      "[1444/1600] D loss: 1.0682, G loss: 1.0178\n",
      "[1564/1600] D loss: 1.2731, G loss: 1.7564\n",
      "train error: \n",
      " D loss: 0.899662, G loss: 2.154749, D accuracy: 72.6%, cell accuracy: 98.6%, board accuracy: 36.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.165069, G loss: 2.359309, D accuracy: 68.5%, cell accuracy: 98.5%, board accuracy: 38.2% \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7733, G loss: 1.5579\n",
      "[124/1600] D loss: 0.7019, G loss: 1.9386\n",
      "[244/1600] D loss: 0.7167, G loss: 2.5921\n",
      "[364/1600] D loss: 0.6658, G loss: 1.2496\n",
      "[484/1600] D loss: 0.9781, G loss: 0.9823\n",
      "[604/1600] D loss: 1.1329, G loss: 0.9778\n",
      "[724/1600] D loss: 0.8133, G loss: 1.5067\n",
      "[844/1600] D loss: 0.9798, G loss: 1.7791\n",
      "[964/1600] D loss: 0.7436, G loss: 2.6815\n",
      "[1084/1600] D loss: 1.0778, G loss: 1.9319\n",
      "[1204/1600] D loss: 0.9939, G loss: 1.4660\n",
      "[1324/1600] D loss: 1.0395, G loss: 1.3231\n",
      "[1444/1600] D loss: 0.8668, G loss: 2.0425\n",
      "[1564/1600] D loss: 0.4658, G loss: 2.2136\n",
      "train error: \n",
      " D loss: 0.901977, G loss: 1.986012, D accuracy: 73.7%, cell accuracy: 98.5%, board accuracy: 35.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.140173, G loss: 2.220176, D accuracy: 69.5%, cell accuracy: 98.4%, board accuracy: 35.5% \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4589, G loss: 2.2459\n",
      "[124/1600] D loss: 0.6388, G loss: 3.6410\n",
      "[244/1600] D loss: 1.1696, G loss: 2.8814\n",
      "[364/1600] D loss: 0.7658, G loss: 2.9315\n",
      "[484/1600] D loss: 0.5927, G loss: 3.3818\n",
      "[604/1600] D loss: 0.6907, G loss: 2.9606\n",
      "[724/1600] D loss: 0.7826, G loss: 1.4311\n",
      "[844/1600] D loss: 0.5584, G loss: 2.5782\n",
      "[964/1600] D loss: 0.7539, G loss: 2.1562\n",
      "[1084/1600] D loss: 1.1527, G loss: 2.7157\n",
      "[1204/1600] D loss: 0.6912, G loss: 3.2677\n",
      "[1324/1600] D loss: 1.4022, G loss: 0.6660\n",
      "[1444/1600] D loss: 0.7493, G loss: 2.2494\n",
      "[1564/1600] D loss: 0.5492, G loss: 2.3698\n",
      "train error: \n",
      " D loss: 0.903357, G loss: 1.662703, D accuracy: 73.2%, cell accuracy: 98.5%, board accuracy: 36.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.097792, G loss: 1.896768, D accuracy: 68.8%, cell accuracy: 98.4%, board accuracy: 36.5% \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5544, G loss: 2.4778\n",
      "[124/1600] D loss: 0.6572, G loss: 2.9319\n",
      "[244/1600] D loss: 0.8116, G loss: 1.3322\n",
      "[364/1600] D loss: 1.0131, G loss: 2.3356\n",
      "[484/1600] D loss: 0.6410, G loss: 1.8072\n",
      "[604/1600] D loss: 1.0586, G loss: 1.4165\n",
      "[724/1600] D loss: 0.6678, G loss: 1.7519\n",
      "[844/1600] D loss: 0.5877, G loss: 2.1081\n",
      "[964/1600] D loss: 1.3951, G loss: 0.7564\n",
      "[1084/1600] D loss: 1.3164, G loss: 2.5422\n",
      "[1204/1600] D loss: 1.0765, G loss: 2.0086\n",
      "[1324/1600] D loss: 0.6754, G loss: 2.4998\n",
      "[1444/1600] D loss: 0.3755, G loss: 2.2561\n",
      "[1564/1600] D loss: 1.0707, G loss: 1.9227\n",
      "train error: \n",
      " D loss: 0.904728, G loss: 1.691184, D accuracy: 73.6%, cell accuracy: 98.5%, board accuracy: 36.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.106904, G loss: 1.951952, D accuracy: 70.5%, cell accuracy: 98.4%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7388, G loss: 1.8342\n",
      "[124/1600] D loss: 0.4279, G loss: 4.6475\n",
      "[244/1600] D loss: 1.0562, G loss: 1.4699\n",
      "[364/1600] D loss: 1.3929, G loss: 0.7795\n",
      "[484/1600] D loss: 0.4902, G loss: 2.3251\n",
      "[604/1600] D loss: 1.0699, G loss: 1.3724\n",
      "[724/1600] D loss: 0.4303, G loss: 4.4899\n",
      "[844/1600] D loss: 1.2028, G loss: 1.5609\n",
      "[964/1600] D loss: 1.2864, G loss: 2.0227\n",
      "[1084/1600] D loss: 0.8768, G loss: 2.0451\n",
      "[1204/1600] D loss: 0.6882, G loss: 2.0131\n",
      "[1324/1600] D loss: 0.9219, G loss: 1.1688\n",
      "[1444/1600] D loss: 0.7334, G loss: 3.2363\n",
      "[1564/1600] D loss: 1.1474, G loss: 2.2376\n",
      "train error: \n",
      " D loss: 0.888549, G loss: 1.956821, D accuracy: 73.5%, cell accuracy: 98.6%, board accuracy: 37.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.115554, G loss: 2.179593, D accuracy: 69.0%, cell accuracy: 98.4%, board accuracy: 35.5% \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2718, G loss: 1.6494\n",
      "[124/1600] D loss: 0.5326, G loss: 3.4638\n",
      "[244/1600] D loss: 1.0600, G loss: 1.4212\n",
      "[364/1600] D loss: 0.5572, G loss: 2.6175\n",
      "[484/1600] D loss: 0.6540, G loss: 4.1066\n",
      "[604/1600] D loss: 0.7282, G loss: 2.3131\n",
      "[724/1600] D loss: 1.0044, G loss: 1.2760\n",
      "[844/1600] D loss: 1.8739, G loss: 0.5596\n",
      "[964/1600] D loss: 0.9188, G loss: 1.4638\n",
      "[1084/1600] D loss: 0.7167, G loss: 1.8320\n",
      "[1204/1600] D loss: 0.4482, G loss: 3.5998\n",
      "[1324/1600] D loss: 0.0687, G loss: 3.0936\n",
      "[1444/1600] D loss: 1.3701, G loss: 0.9989\n",
      "[1564/1600] D loss: 0.8543, G loss: 1.4262\n",
      "train error: \n",
      " D loss: 0.910575, G loss: 1.825493, D accuracy: 73.6%, cell accuracy: 98.6%, board accuracy: 35.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.132536, G loss: 2.103648, D accuracy: 69.0%, cell accuracy: 98.4%, board accuracy: 35.5% \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7502, G loss: 2.4156\n",
      "[124/1600] D loss: 0.5069, G loss: 2.6941\n",
      "[244/1600] D loss: 0.3723, G loss: 3.4143\n",
      "[364/1600] D loss: 1.2433, G loss: 0.9392\n",
      "[484/1600] D loss: 1.6449, G loss: 1.1721\n",
      "[604/1600] D loss: 1.1902, G loss: 1.0217\n",
      "[724/1600] D loss: 0.4249, G loss: 2.6622\n",
      "[844/1600] D loss: 0.7006, G loss: 1.9926\n",
      "[964/1600] D loss: 1.2038, G loss: 2.2548\n",
      "[1084/1600] D loss: 0.9144, G loss: 3.1732\n",
      "[1204/1600] D loss: 0.8570, G loss: 1.4804\n",
      "[1324/1600] D loss: 1.0154, G loss: 1.7466\n",
      "[1444/1600] D loss: 0.4690, G loss: 2.6779\n",
      "[1564/1600] D loss: 0.6316, G loss: 2.0072\n",
      "train error: \n",
      " D loss: 0.913580, G loss: 2.087448, D accuracy: 73.7%, cell accuracy: 98.6%, board accuracy: 36.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.158102, G loss: 2.396180, D accuracy: 69.6%, cell accuracy: 98.4%, board accuracy: 35.0% \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3096, G loss: 1.0008\n",
      "[124/1600] D loss: 0.1727, G loss: 3.9670\n",
      "[244/1600] D loss: 0.7250, G loss: 2.2217\n",
      "[364/1600] D loss: 0.8679, G loss: 1.5667\n",
      "[484/1600] D loss: 0.7516, G loss: 2.8600\n",
      "[604/1600] D loss: 0.5024, G loss: 2.4232\n",
      "[724/1600] D loss: 0.8520, G loss: 1.2008\n",
      "[844/1600] D loss: 0.8349, G loss: 1.7169\n",
      "[964/1600] D loss: 1.2395, G loss: 0.9502\n",
      "[1084/1600] D loss: 0.7834, G loss: 3.4628\n",
      "[1204/1600] D loss: 0.4265, G loss: 2.2080\n",
      "[1324/1600] D loss: 2.4810, G loss: 1.5327\n",
      "[1444/1600] D loss: 0.7399, G loss: 1.3013\n",
      "[1564/1600] D loss: 0.5895, G loss: 2.5149\n",
      "train error: \n",
      " D loss: 0.911519, G loss: 1.714932, D accuracy: 73.8%, cell accuracy: 98.6%, board accuracy: 36.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.104418, G loss: 1.937481, D accuracy: 69.4%, cell accuracy: 98.4%, board accuracy: 34.0% \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6242, G loss: 1.8089\n",
      "[124/1600] D loss: 1.2192, G loss: 1.6415\n",
      "[244/1600] D loss: 0.3434, G loss: 3.3056\n",
      "[364/1600] D loss: 1.1002, G loss: 1.1842\n",
      "[484/1600] D loss: 0.5890, G loss: 2.3539\n",
      "[604/1600] D loss: 0.4387, G loss: 3.0290\n",
      "[724/1600] D loss: 0.7626, G loss: 3.4538\n",
      "[844/1600] D loss: 0.1239, G loss: 4.8447\n",
      "[964/1600] D loss: 1.1603, G loss: 0.7161\n",
      "[1084/1600] D loss: 1.4736, G loss: 0.5152\n",
      "[1204/1600] D loss: 0.7803, G loss: 2.5200\n",
      "[1324/1600] D loss: 1.2649, G loss: 1.1505\n",
      "[1444/1600] D loss: 0.7597, G loss: 3.2160\n",
      "[1564/1600] D loss: 1.0506, G loss: 1.8467\n",
      "train error: \n",
      " D loss: 0.937210, G loss: 2.298140, D accuracy: 72.5%, cell accuracy: 98.5%, board accuracy: 35.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.186731, G loss: 2.632200, D accuracy: 68.1%, cell accuracy: 98.4%, board accuracy: 34.0% \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5999, G loss: 3.7162\n",
      "[124/1600] D loss: 0.7224, G loss: 3.1365\n",
      "[244/1600] D loss: 0.4774, G loss: 5.1260\n",
      "[364/1600] D loss: 0.5276, G loss: 2.2012\n",
      "[484/1600] D loss: 0.6538, G loss: 2.2800\n",
      "[604/1600] D loss: 0.7136, G loss: 1.3874\n",
      "[724/1600] D loss: 1.1378, G loss: 1.0241\n",
      "[844/1600] D loss: 0.7994, G loss: 1.5054\n",
      "[964/1600] D loss: 1.1178, G loss: 1.3529\n",
      "[1084/1600] D loss: 1.0877, G loss: 1.3081\n",
      "[1204/1600] D loss: 0.6898, G loss: 1.4688\n",
      "[1324/1600] D loss: 0.8459, G loss: 2.6580\n",
      "[1444/1600] D loss: 1.1462, G loss: 1.1347\n",
      "[1564/1600] D loss: 1.3330, G loss: 1.3046\n",
      "train error: \n",
      " D loss: 0.901664, G loss: 2.116940, D accuracy: 72.6%, cell accuracy: 98.5%, board accuracy: 33.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.134894, G loss: 2.301989, D accuracy: 69.0%, cell accuracy: 98.4%, board accuracy: 33.8% \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4399, G loss: 4.2781\n",
      "[124/1600] D loss: 1.4784, G loss: 0.8622\n",
      "[244/1600] D loss: 0.4281, G loss: 3.2875\n",
      "[364/1600] D loss: 0.3571, G loss: 3.1210\n",
      "[484/1600] D loss: 0.8349, G loss: 1.3120\n",
      "[604/1600] D loss: 0.6425, G loss: 2.2005\n",
      "[724/1600] D loss: 1.2035, G loss: 0.8453\n",
      "[844/1600] D loss: 0.9027, G loss: 1.0525\n",
      "[964/1600] D loss: 1.4687, G loss: 0.5971\n",
      "[1084/1600] D loss: 1.1883, G loss: 1.3801\n",
      "[1204/1600] D loss: 1.1026, G loss: 0.8884\n",
      "[1324/1600] D loss: 0.6403, G loss: 1.8518\n",
      "[1444/1600] D loss: 1.2613, G loss: 1.4506\n",
      "[1564/1600] D loss: 0.4708, G loss: 2.1155\n",
      "train error: \n",
      " D loss: 0.880446, G loss: 1.971526, D accuracy: 73.5%, cell accuracy: 98.5%, board accuracy: 37.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.128107, G loss: 2.235205, D accuracy: 68.9%, cell accuracy: 98.4%, board accuracy: 37.8% \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2189, G loss: 2.6543\n",
      "[124/1600] D loss: 1.0981, G loss: 1.2792\n",
      "[244/1600] D loss: 0.5719, G loss: 2.2948\n",
      "[364/1600] D loss: 0.7547, G loss: 1.4445\n",
      "[484/1600] D loss: 0.2242, G loss: 3.3355\n",
      "[604/1600] D loss: 1.4340, G loss: 1.2003\n",
      "[724/1600] D loss: 0.9585, G loss: 1.3585\n",
      "[844/1600] D loss: 0.5809, G loss: 2.4483\n",
      "[964/1600] D loss: 0.5267, G loss: 4.5846\n",
      "[1084/1600] D loss: 0.7002, G loss: 2.9537\n",
      "[1204/1600] D loss: 0.6176, G loss: 2.3296\n",
      "[1324/1600] D loss: 0.8962, G loss: 1.6382\n",
      "[1444/1600] D loss: 1.1637, G loss: 1.7701\n",
      "[1564/1600] D loss: 0.5800, G loss: 2.1145\n",
      "train error: \n",
      " D loss: 0.863821, G loss: 1.790165, D accuracy: 74.8%, cell accuracy: 98.5%, board accuracy: 36.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.063825, G loss: 2.069777, D accuracy: 70.2%, cell accuracy: 98.4%, board accuracy: 36.8% \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2685, G loss: 0.7583\n",
      "[124/1600] D loss: 1.0339, G loss: 2.0715\n",
      "[244/1600] D loss: 1.0822, G loss: 2.4636\n",
      "[364/1600] D loss: 0.8613, G loss: 1.5667\n",
      "[484/1600] D loss: 1.0588, G loss: 2.6765\n",
      "[604/1600] D loss: 1.3412, G loss: 0.8515\n",
      "[724/1600] D loss: 1.2863, G loss: 0.9099\n",
      "[844/1600] D loss: 0.5464, G loss: 2.3294\n",
      "[964/1600] D loss: 0.7954, G loss: 3.4997\n",
      "[1084/1600] D loss: 1.1807, G loss: 0.8735\n",
      "[1204/1600] D loss: 1.3942, G loss: 1.3939\n",
      "[1324/1600] D loss: 1.2622, G loss: 1.2275\n",
      "[1444/1600] D loss: 1.6521, G loss: 2.8315\n",
      "[1564/1600] D loss: 1.1215, G loss: 1.1285\n",
      "train error: \n",
      " D loss: 0.878766, G loss: 2.049420, D accuracy: 74.0%, cell accuracy: 98.6%, board accuracy: 36.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.094663, G loss: 2.305000, D accuracy: 69.5%, cell accuracy: 98.4%, board accuracy: 36.8% \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5703, G loss: 2.1714\n",
      "[124/1600] D loss: 1.1407, G loss: 1.0513\n",
      "[244/1600] D loss: 0.9054, G loss: 1.9115\n",
      "[364/1600] D loss: 0.9829, G loss: 1.8319\n",
      "[484/1600] D loss: 0.8582, G loss: 2.2544\n",
      "[604/1600] D loss: 0.8932, G loss: 1.7594\n",
      "[724/1600] D loss: 0.7681, G loss: 1.5020\n",
      "[844/1600] D loss: 1.1102, G loss: 1.5549\n",
      "[964/1600] D loss: 0.5372, G loss: 2.4705\n",
      "[1084/1600] D loss: 1.1497, G loss: 1.8706\n",
      "[1204/1600] D loss: 0.8440, G loss: 1.3726\n",
      "[1324/1600] D loss: 1.1573, G loss: 1.2675\n",
      "[1444/1600] D loss: 0.3837, G loss: 4.4962\n",
      "[1564/1600] D loss: 0.9293, G loss: 2.6365\n",
      "train error: \n",
      " D loss: 0.860134, G loss: 1.861711, D accuracy: 74.9%, cell accuracy: 98.6%, board accuracy: 36.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.063958, G loss: 2.117242, D accuracy: 69.6%, cell accuracy: 98.4%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7951, G loss: 2.4611\n",
      "[124/1600] D loss: 1.0801, G loss: 2.3487\n",
      "[244/1600] D loss: 1.4281, G loss: 0.7118\n",
      "[364/1600] D loss: 0.6909, G loss: 1.8987\n",
      "[484/1600] D loss: 0.9169, G loss: 1.2817\n",
      "[604/1600] D loss: 1.0264, G loss: 1.7331\n",
      "[724/1600] D loss: 0.8471, G loss: 2.0956\n",
      "[844/1600] D loss: 0.8622, G loss: 3.3374\n",
      "[964/1600] D loss: 0.9346, G loss: 0.9884\n",
      "[1084/1600] D loss: 0.8213, G loss: 1.6777\n",
      "[1204/1600] D loss: 0.9834, G loss: 0.8756\n",
      "[1324/1600] D loss: 0.4579, G loss: 2.4028\n",
      "[1444/1600] D loss: 1.0221, G loss: 2.4241\n",
      "[1564/1600] D loss: 0.6141, G loss: 2.2785\n",
      "train error: \n",
      " D loss: 0.864957, G loss: 1.711419, D accuracy: 75.0%, cell accuracy: 98.6%, board accuracy: 36.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.108221, G loss: 1.895353, D accuracy: 69.5%, cell accuracy: 98.4%, board accuracy: 36.5% \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6239, G loss: 1.6777\n",
      "[124/1600] D loss: 0.7534, G loss: 3.4662\n",
      "[244/1600] D loss: 1.4326, G loss: 0.8515\n",
      "[364/1600] D loss: 1.1133, G loss: 1.4115\n",
      "[484/1600] D loss: 0.6177, G loss: 2.5557\n",
      "[604/1600] D loss: 1.1108, G loss: 1.3475\n",
      "[724/1600] D loss: 0.7559, G loss: 2.1951\n",
      "[844/1600] D loss: 0.9311, G loss: 1.4772\n",
      "[964/1600] D loss: 0.9325, G loss: 1.1241\n",
      "[1084/1600] D loss: 1.0449, G loss: 1.9013\n",
      "[1204/1600] D loss: 1.2718, G loss: 2.1423\n",
      "[1324/1600] D loss: 0.7176, G loss: 1.4024\n",
      "[1444/1600] D loss: 0.9583, G loss: 1.9516\n",
      "[1564/1600] D loss: 0.2433, G loss: 2.7207\n",
      "train error: \n",
      " D loss: 0.937203, G loss: 2.178120, D accuracy: 72.5%, cell accuracy: 98.5%, board accuracy: 37.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.158525, G loss: 2.477365, D accuracy: 68.0%, cell accuracy: 98.4%, board accuracy: 36.5% \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2724, G loss: 1.0615\n",
      "[124/1600] D loss: 0.7478, G loss: 2.6867\n",
      "[244/1600] D loss: 0.9810, G loss: 1.8044\n",
      "[364/1600] D loss: 1.0178, G loss: 1.8679\n",
      "[484/1600] D loss: 0.7717, G loss: 2.6557\n",
      "[604/1600] D loss: 1.1637, G loss: 1.1469\n",
      "[724/1600] D loss: 0.4058, G loss: 2.6762\n",
      "[844/1600] D loss: 1.4267, G loss: 0.6791\n",
      "[964/1600] D loss: 0.7233, G loss: 2.9151\n",
      "[1084/1600] D loss: 1.3803, G loss: 0.6808\n",
      "[1204/1600] D loss: 0.8882, G loss: 1.0827\n",
      "[1324/1600] D loss: 1.0590, G loss: 1.3583\n",
      "[1444/1600] D loss: 0.9988, G loss: 2.3088\n",
      "[1564/1600] D loss: 0.7779, G loss: 3.0016\n",
      "train error: \n",
      " D loss: 0.899927, G loss: 1.719291, D accuracy: 74.5%, cell accuracy: 98.5%, board accuracy: 32.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.078923, G loss: 1.933802, D accuracy: 70.1%, cell accuracy: 98.4%, board accuracy: 32.8% \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7299, G loss: 3.0173\n",
      "[124/1600] D loss: 1.2585, G loss: 0.6563\n",
      "[244/1600] D loss: 0.8554, G loss: 2.2744\n",
      "[364/1600] D loss: 0.4288, G loss: 3.7375\n",
      "[484/1600] D loss: 1.2359, G loss: 1.4776\n",
      "[604/1600] D loss: 0.8314, G loss: 1.9415\n",
      "[724/1600] D loss: 0.8088, G loss: 1.3857\n",
      "[844/1600] D loss: 0.5659, G loss: 2.3086\n",
      "[964/1600] D loss: 1.2211, G loss: 0.5512\n",
      "[1084/1600] D loss: 0.8544, G loss: 2.1762\n",
      "[1204/1600] D loss: 0.3500, G loss: 4.2056\n",
      "[1324/1600] D loss: 1.0964, G loss: 1.2245\n",
      "[1444/1600] D loss: 1.0361, G loss: 1.4436\n",
      "[1564/1600] D loss: 0.4528, G loss: 2.8020\n",
      "train error: \n",
      " D loss: 0.858322, G loss: 2.090724, D accuracy: 73.8%, cell accuracy: 98.5%, board accuracy: 35.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.109247, G loss: 2.354599, D accuracy: 69.0%, cell accuracy: 98.3%, board accuracy: 35.0% \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2673, G loss: 1.2094\n",
      "[124/1600] D loss: 0.0406, G loss: 5.9021\n",
      "[244/1600] D loss: 0.8841, G loss: 2.3760\n",
      "[364/1600] D loss: 1.0724, G loss: 1.6113\n",
      "[484/1600] D loss: 0.4325, G loss: 5.1294\n",
      "[604/1600] D loss: 1.1859, G loss: 1.8210\n",
      "[724/1600] D loss: 0.7016, G loss: 1.9286\n",
      "[844/1600] D loss: 0.6511, G loss: 1.7495\n",
      "[964/1600] D loss: 1.2906, G loss: 1.4682\n",
      "[1084/1600] D loss: 1.3527, G loss: 0.8553\n",
      "[1204/1600] D loss: 0.8516, G loss: 2.8160\n",
      "[1324/1600] D loss: 0.3562, G loss: 4.0769\n",
      "[1444/1600] D loss: 1.4911, G loss: 0.6029\n",
      "[1564/1600] D loss: 0.6277, G loss: 2.8301\n",
      "train error: \n",
      " D loss: 0.938334, G loss: 1.544565, D accuracy: 73.4%, cell accuracy: 98.5%, board accuracy: 33.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.100424, G loss: 1.794397, D accuracy: 69.5%, cell accuracy: 98.4%, board accuracy: 32.2% \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1740, G loss: 0.9693\n",
      "[124/1600] D loss: 0.7578, G loss: 1.8344\n",
      "[244/1600] D loss: 0.8089, G loss: 1.9038\n",
      "[364/1600] D loss: 0.8018, G loss: 1.5432\n",
      "[484/1600] D loss: 0.5642, G loss: 2.2389\n",
      "[604/1600] D loss: 1.1513, G loss: 1.3467\n",
      "[724/1600] D loss: 0.8672, G loss: 1.4974\n",
      "[844/1600] D loss: 0.8269, G loss: 1.1081\n",
      "[964/1600] D loss: 0.8669, G loss: 1.1988\n",
      "[1084/1600] D loss: 1.1075, G loss: 0.9786\n",
      "[1204/1600] D loss: 0.8286, G loss: 1.7274\n",
      "[1324/1600] D loss: 1.2633, G loss: 1.6305\n",
      "[1444/1600] D loss: 1.0351, G loss: 2.5924\n",
      "[1564/1600] D loss: 1.0179, G loss: 1.3478\n",
      "train error: \n",
      " D loss: 0.889757, G loss: 2.004637, D accuracy: 74.8%, cell accuracy: 98.5%, board accuracy: 35.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.110821, G loss: 2.261877, D accuracy: 69.6%, cell accuracy: 98.4%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9376, G loss: 2.8093\n",
      "[124/1600] D loss: 0.8220, G loss: 1.9101\n",
      "[244/1600] D loss: 0.5454, G loss: 1.9525\n",
      "[364/1600] D loss: 0.0642, G loss: 5.2004\n",
      "[484/1600] D loss: 0.6052, G loss: 2.3556\n",
      "[604/1600] D loss: 0.9146, G loss: 1.7241\n",
      "[724/1600] D loss: 1.0415, G loss: 1.3063\n",
      "[844/1600] D loss: 0.9205, G loss: 1.6931\n",
      "[964/1600] D loss: 0.8477, G loss: 1.6104\n",
      "[1084/1600] D loss: 0.5249, G loss: 1.8451\n",
      "[1204/1600] D loss: 1.4979, G loss: 0.5196\n",
      "[1324/1600] D loss: 0.7951, G loss: 1.5257\n",
      "[1444/1600] D loss: 0.9574, G loss: 1.0032\n",
      "[1564/1600] D loss: 0.9924, G loss: 1.4938\n",
      "train error: \n",
      " D loss: 0.865210, G loss: 1.861290, D accuracy: 74.9%, cell accuracy: 98.5%, board accuracy: 31.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.082983, G loss: 2.144321, D accuracy: 69.8%, cell accuracy: 98.4%, board accuracy: 31.5% \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7000, G loss: 2.6376\n",
      "[124/1600] D loss: 0.7818, G loss: 2.1579\n",
      "[244/1600] D loss: 0.7661, G loss: 1.3125\n",
      "[364/1600] D loss: 0.3377, G loss: 4.0341\n",
      "[484/1600] D loss: 0.7829, G loss: 3.3105\n",
      "[604/1600] D loss: 0.5895, G loss: 2.6902\n",
      "[724/1600] D loss: 0.7490, G loss: 2.1152\n",
      "[844/1600] D loss: 1.1129, G loss: 1.1835\n",
      "[964/1600] D loss: 1.1752, G loss: 1.6184\n",
      "[1084/1600] D loss: 1.3309, G loss: 0.6479\n",
      "[1204/1600] D loss: 0.4689, G loss: 3.5158\n",
      "[1324/1600] D loss: 0.5421, G loss: 2.6718\n",
      "[1444/1600] D loss: 0.7146, G loss: 2.6165\n",
      "[1564/1600] D loss: 0.9575, G loss: 2.0459\n",
      "train error: \n",
      " D loss: 1.032985, G loss: 1.254026, D accuracy: 72.4%, cell accuracy: 98.5%, board accuracy: 34.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.186606, G loss: 1.492144, D accuracy: 68.9%, cell accuracy: 98.4%, board accuracy: 32.0% \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7538, G loss: 2.0654\n",
      "[124/1600] D loss: 1.0556, G loss: 2.0145\n",
      "[244/1600] D loss: 0.6919, G loss: 1.7228\n",
      "[364/1600] D loss: 0.2702, G loss: 1.8137\n",
      "[484/1600] D loss: 1.0375, G loss: 1.2157\n",
      "[604/1600] D loss: 0.7773, G loss: 1.0386\n",
      "[724/1600] D loss: 0.6500, G loss: 1.5719\n",
      "[844/1600] D loss: 0.4308, G loss: 3.1853\n",
      "[964/1600] D loss: 0.6860, G loss: 2.6944\n",
      "[1084/1600] D loss: 0.5612, G loss: 1.6374\n",
      "[1204/1600] D loss: 0.5465, G loss: 2.1873\n",
      "[1324/1600] D loss: 0.7960, G loss: 1.7246\n",
      "[1444/1600] D loss: 1.3178, G loss: 1.2491\n",
      "[1564/1600] D loss: 0.9773, G loss: 1.0667\n",
      "train error: \n",
      " D loss: 0.883170, G loss: 1.942236, D accuracy: 74.7%, cell accuracy: 98.5%, board accuracy: 33.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.100182, G loss: 2.182222, D accuracy: 70.2%, cell accuracy: 98.4%, board accuracy: 32.0% \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5383, G loss: 0.9014\n",
      "[124/1600] D loss: 0.6605, G loss: 2.1368\n",
      "[244/1600] D loss: 1.1768, G loss: 0.9034\n",
      "[364/1600] D loss: 0.8999, G loss: 1.1207\n",
      "[484/1600] D loss: 0.5079, G loss: 2.3349\n",
      "[604/1600] D loss: 1.0432, G loss: 0.8354\n",
      "[724/1600] D loss: 0.4263, G loss: 3.9849\n",
      "[844/1600] D loss: 0.8246, G loss: 1.7678\n",
      "[964/1600] D loss: 0.9535, G loss: 3.0732\n",
      "[1084/1600] D loss: 0.9936, G loss: 2.0350\n",
      "[1204/1600] D loss: 0.8037, G loss: 1.5155\n",
      "[1324/1600] D loss: 0.5613, G loss: 3.5298\n",
      "[1444/1600] D loss: 0.6962, G loss: 3.0109\n",
      "[1564/1600] D loss: 1.4200, G loss: 1.6275\n",
      "train error: \n",
      " D loss: 0.877353, G loss: 1.642543, D accuracy: 75.6%, cell accuracy: 98.5%, board accuracy: 34.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.047407, G loss: 1.955149, D accuracy: 71.8%, cell accuracy: 98.4%, board accuracy: 30.8% \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9673, G loss: 2.4889\n",
      "[124/1600] D loss: 0.7528, G loss: 2.9941\n",
      "[244/1600] D loss: 1.1075, G loss: 2.1195\n",
      "[364/1600] D loss: 0.7803, G loss: 2.6060\n",
      "[484/1600] D loss: 0.6573, G loss: 1.6441\n",
      "[604/1600] D loss: 0.6693, G loss: 2.7418\n",
      "[724/1600] D loss: 0.5232, G loss: 3.0343\n",
      "[844/1600] D loss: 1.1945, G loss: 1.0073\n",
      "[964/1600] D loss: 0.9747, G loss: 1.6135\n",
      "[1084/1600] D loss: 1.0288, G loss: 1.0436\n",
      "[1204/1600] D loss: 0.9562, G loss: 1.6293\n",
      "[1324/1600] D loss: 0.7393, G loss: 2.1164\n",
      "[1444/1600] D loss: 0.9222, G loss: 0.9888\n",
      "[1564/1600] D loss: 0.3418, G loss: 2.5233\n",
      "train error: \n",
      " D loss: 0.871069, G loss: 2.067353, D accuracy: 73.7%, cell accuracy: 98.5%, board accuracy: 35.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.118777, G loss: 2.337914, D accuracy: 68.8%, cell accuracy: 98.4%, board accuracy: 36.0% \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1620, G loss: 2.7598\n",
      "[124/1600] D loss: 1.0458, G loss: 1.4131\n",
      "[244/1600] D loss: 0.3548, G loss: 2.7745\n",
      "[364/1600] D loss: 0.6693, G loss: 1.9648\n",
      "[484/1600] D loss: 0.5577, G loss: 3.6916\n",
      "[604/1600] D loss: 1.1472, G loss: 0.9692\n",
      "[724/1600] D loss: 0.7396, G loss: 2.0980\n",
      "[844/1600] D loss: 1.2857, G loss: 0.8636\n",
      "[964/1600] D loss: 1.1723, G loss: 0.7798\n",
      "[1084/1600] D loss: 0.9677, G loss: 3.2261\n",
      "[1204/1600] D loss: 0.3202, G loss: 2.1412\n",
      "[1324/1600] D loss: 0.4426, G loss: 2.6079\n",
      "[1444/1600] D loss: 1.5221, G loss: 0.8968\n",
      "[1564/1600] D loss: 0.7476, G loss: 2.1234\n",
      "train error: \n",
      " D loss: 0.860072, G loss: 1.983574, D accuracy: 74.2%, cell accuracy: 98.5%, board accuracy: 34.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.085997, G loss: 2.259348, D accuracy: 69.4%, cell accuracy: 98.4%, board accuracy: 34.5% \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7878, G loss: 1.9809\n",
      "[124/1600] D loss: 1.3778, G loss: 1.2481\n",
      "[244/1600] D loss: 1.5446, G loss: 0.7111\n",
      "[364/1600] D loss: 0.4227, G loss: 2.5584\n",
      "[484/1600] D loss: 0.4959, G loss: 2.8064\n",
      "[604/1600] D loss: 1.6922, G loss: 0.7876\n",
      "[724/1600] D loss: 1.0405, G loss: 1.5697\n",
      "[844/1600] D loss: 0.8822, G loss: 2.6508\n",
      "[964/1600] D loss: 1.4415, G loss: 0.8570\n",
      "[1084/1600] D loss: 0.9395, G loss: 2.6610\n",
      "[1204/1600] D loss: 1.1314, G loss: 1.2698\n",
      "[1324/1600] D loss: 0.9646, G loss: 2.4216\n",
      "[1444/1600] D loss: 0.9152, G loss: 1.7142\n",
      "[1564/1600] D loss: 1.2621, G loss: 1.1697\n",
      "train error: \n",
      " D loss: 0.862039, G loss: 1.939700, D accuracy: 74.2%, cell accuracy: 98.5%, board accuracy: 36.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.058717, G loss: 2.236176, D accuracy: 70.5%, cell accuracy: 98.4%, board accuracy: 34.8% \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7195, G loss: 1.3530\n",
      "[124/1600] D loss: 0.7743, G loss: 1.7237\n",
      "[244/1600] D loss: 0.1632, G loss: 3.4032\n",
      "[364/1600] D loss: 0.9683, G loss: 1.1306\n",
      "[484/1600] D loss: 1.1162, G loss: 1.0327\n",
      "[604/1600] D loss: 0.4751, G loss: 2.9502\n",
      "[724/1600] D loss: 1.3220, G loss: 3.0432\n",
      "[844/1600] D loss: 1.1161, G loss: 0.9403\n",
      "[964/1600] D loss: 0.9808, G loss: 1.8663\n",
      "[1084/1600] D loss: 1.4401, G loss: 0.5979\n",
      "[1204/1600] D loss: 1.0025, G loss: 1.1570\n",
      "[1324/1600] D loss: 0.4146, G loss: 1.8885\n",
      "[1444/1600] D loss: 1.2219, G loss: 1.9607\n",
      "[1564/1600] D loss: 0.9578, G loss: 1.1476\n",
      "train error: \n",
      " D loss: 0.870819, G loss: 1.820816, D accuracy: 73.8%, cell accuracy: 98.6%, board accuracy: 34.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.073925, G loss: 2.036922, D accuracy: 70.2%, cell accuracy: 98.4%, board accuracy: 34.2% \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5507, G loss: 1.7632\n",
      "[124/1600] D loss: 1.3516, G loss: 1.9984\n",
      "[244/1600] D loss: 0.7502, G loss: 1.6378\n",
      "[364/1600] D loss: 0.9028, G loss: 1.6589\n",
      "[484/1600] D loss: 0.7312, G loss: 2.5587\n",
      "[604/1600] D loss: 1.2808, G loss: 0.8557\n",
      "[724/1600] D loss: 0.6208, G loss: 2.2251\n",
      "[844/1600] D loss: 0.5159, G loss: 3.2282\n",
      "[964/1600] D loss: 1.4716, G loss: 0.6561\n",
      "[1084/1600] D loss: 1.1002, G loss: 0.9320\n",
      "[1204/1600] D loss: 1.0889, G loss: 1.1967\n",
      "[1324/1600] D loss: 1.4860, G loss: 0.8996\n",
      "[1444/1600] D loss: 0.9017, G loss: 3.1175\n",
      "[1564/1600] D loss: 0.5883, G loss: 1.6958\n",
      "train error: \n",
      " D loss: 0.894440, G loss: 1.739987, D accuracy: 73.1%, cell accuracy: 98.6%, board accuracy: 35.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.126810, G loss: 1.977483, D accuracy: 68.4%, cell accuracy: 98.5%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0360, G loss: 1.7185\n",
      "[124/1600] D loss: 0.9747, G loss: 1.4245\n",
      "[244/1600] D loss: 0.8835, G loss: 1.5352\n",
      "[364/1600] D loss: 1.7954, G loss: 1.1473\n",
      "[484/1600] D loss: 1.2359, G loss: 1.0520\n",
      "[604/1600] D loss: 1.0176, G loss: 1.4686\n",
      "[724/1600] D loss: 0.6455, G loss: 2.8002\n",
      "[844/1600] D loss: 0.8757, G loss: 1.2545\n",
      "[964/1600] D loss: 0.7577, G loss: 1.5149\n",
      "[1084/1600] D loss: 0.3934, G loss: 4.4702\n",
      "[1204/1600] D loss: 0.4407, G loss: 2.3324\n",
      "[1324/1600] D loss: 0.6239, G loss: 1.5499\n",
      "[1444/1600] D loss: 1.2575, G loss: 1.5218\n",
      "[1564/1600] D loss: 0.9913, G loss: 1.6990\n",
      "train error: \n",
      " D loss: 1.085457, G loss: 2.602340, D accuracy: 71.3%, cell accuracy: 98.5%, board accuracy: 34.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325156, G loss: 2.893291, D accuracy: 68.1%, cell accuracy: 98.4%, board accuracy: 33.0% \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8858, G loss: 2.8853\n",
      "[124/1600] D loss: 0.8400, G loss: 1.3429\n",
      "[244/1600] D loss: 1.0687, G loss: 1.4064\n",
      "[364/1600] D loss: 0.6919, G loss: 2.4062\n",
      "[484/1600] D loss: 0.8717, G loss: 1.6870\n",
      "[604/1600] D loss: 0.8820, G loss: 1.9882\n",
      "[724/1600] D loss: 1.1262, G loss: 0.8614\n",
      "[844/1600] D loss: 0.7472, G loss: 2.2657\n",
      "[964/1600] D loss: 1.1659, G loss: 1.0473\n",
      "[1084/1600] D loss: 1.6195, G loss: 1.4051\n",
      "[1204/1600] D loss: 0.5976, G loss: 1.6450\n",
      "[1324/1600] D loss: 0.5528, G loss: 3.3823\n",
      "[1444/1600] D loss: 1.0913, G loss: 1.0325\n",
      "[1564/1600] D loss: 0.6527, G loss: 1.7533\n",
      "train error: \n",
      " D loss: 0.881240, G loss: 1.788366, D accuracy: 74.3%, cell accuracy: 98.5%, board accuracy: 34.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.122664, G loss: 2.056202, D accuracy: 68.4%, cell accuracy: 98.4%, board accuracy: 34.5% \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1505, G loss: 3.6218\n",
      "[124/1600] D loss: 1.1879, G loss: 2.8483\n",
      "[244/1600] D loss: 0.8014, G loss: 1.7699\n",
      "[364/1600] D loss: 0.7611, G loss: 3.5357\n",
      "[484/1600] D loss: 1.0733, G loss: 1.2788\n",
      "[604/1600] D loss: 0.8802, G loss: 0.8617\n",
      "[724/1600] D loss: 1.3299, G loss: 0.9628\n",
      "[844/1600] D loss: 0.9386, G loss: 2.5735\n",
      "[964/1600] D loss: 0.9525, G loss: 2.4738\n",
      "[1084/1600] D loss: 1.0556, G loss: 1.5510\n",
      "[1204/1600] D loss: 0.7850, G loss: 2.7121\n",
      "[1324/1600] D loss: 0.4937, G loss: 2.9820\n",
      "[1444/1600] D loss: 0.8589, G loss: 3.4947\n",
      "[1564/1600] D loss: 1.3784, G loss: 0.5965\n",
      "train error: \n",
      " D loss: 0.898441, G loss: 1.566053, D accuracy: 73.8%, cell accuracy: 98.5%, board accuracy: 34.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.065088, G loss: 1.886472, D accuracy: 70.1%, cell accuracy: 98.4%, board accuracy: 33.2% \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4518, G loss: 2.0968\n",
      "[124/1600] D loss: 1.2045, G loss: 1.1431\n",
      "[244/1600] D loss: 0.7511, G loss: 1.7470\n",
      "[364/1600] D loss: 1.4196, G loss: 1.2877\n",
      "[484/1600] D loss: 1.6714, G loss: 1.1953\n",
      "[604/1600] D loss: 1.2389, G loss: 0.9503\n",
      "[724/1600] D loss: 0.4769, G loss: 1.4697\n",
      "[844/1600] D loss: 0.8037, G loss: 1.4168\n",
      "[964/1600] D loss: 1.1935, G loss: 0.9380\n",
      "[1084/1600] D loss: 0.8223, G loss: 1.3497\n",
      "[1204/1600] D loss: 0.9241, G loss: 1.9059\n",
      "[1324/1600] D loss: 0.8910, G loss: 2.1682\n",
      "[1444/1600] D loss: 0.6909, G loss: 2.4852\n",
      "[1564/1600] D loss: 1.6090, G loss: 1.4469\n",
      "train error: \n",
      " D loss: 1.111808, G loss: 1.138248, D accuracy: 70.1%, cell accuracy: 98.5%, board accuracy: 32.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.194116, G loss: 1.405471, D accuracy: 69.2%, cell accuracy: 98.4%, board accuracy: 31.0% \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0592, G loss: 0.9642\n",
      "[124/1600] D loss: 1.3189, G loss: 1.8743\n",
      "[244/1600] D loss: 0.8351, G loss: 2.7173\n",
      "[364/1600] D loss: 1.2496, G loss: 1.2367\n",
      "[484/1600] D loss: 0.8604, G loss: 1.3503\n",
      "[604/1600] D loss: 1.2396, G loss: 1.0345\n",
      "[724/1600] D loss: 0.8182, G loss: 2.2599\n",
      "[844/1600] D loss: 0.8240, G loss: 1.7496\n",
      "[964/1600] D loss: 0.7540, G loss: 1.9913\n",
      "[1084/1600] D loss: 1.0762, G loss: 1.1837\n",
      "[1204/1600] D loss: 1.0027, G loss: 1.3317\n",
      "[1324/1600] D loss: 0.9516, G loss: 1.3517\n",
      "[1444/1600] D loss: 0.8288, G loss: 2.2047\n",
      "[1564/1600] D loss: 0.6053, G loss: 1.6787\n",
      "train error: \n",
      " D loss: 0.859966, G loss: 1.903533, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 34.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.089639, G loss: 2.228086, D accuracy: 70.0%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0080, G loss: 1.4637\n",
      "[124/1600] D loss: 0.8496, G loss: 1.3768\n",
      "[244/1600] D loss: 0.5302, G loss: 2.9560\n",
      "[364/1600] D loss: 0.9216, G loss: 1.7466\n",
      "[484/1600] D loss: 0.2466, G loss: 2.3705\n",
      "[604/1600] D loss: 0.7385, G loss: 2.2169\n",
      "[724/1600] D loss: 1.6156, G loss: 1.3502\n",
      "[844/1600] D loss: 0.4389, G loss: 2.8108\n",
      "[964/1600] D loss: 0.4536, G loss: 2.2052\n",
      "[1084/1600] D loss: 0.7549, G loss: 3.8894\n",
      "[1204/1600] D loss: 0.3123, G loss: 2.2802\n",
      "[1324/1600] D loss: 1.2773, G loss: 2.2752\n",
      "[1444/1600] D loss: 0.8269, G loss: 1.8048\n",
      "[1564/1600] D loss: 0.8375, G loss: 1.2969\n",
      "train error: \n",
      " D loss: 0.891850, G loss: 1.567294, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 33.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.086019, G loss: 1.902127, D accuracy: 70.1%, cell accuracy: 98.4%, board accuracy: 31.5% \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2084, G loss: 0.8067\n",
      "[124/1600] D loss: 0.4428, G loss: 3.5203\n",
      "[244/1600] D loss: 0.7641, G loss: 1.8273\n",
      "[364/1600] D loss: 0.6656, G loss: 2.1695\n",
      "[484/1600] D loss: 1.1930, G loss: 2.7775\n",
      "[604/1600] D loss: 1.0385, G loss: 2.0688\n",
      "[724/1600] D loss: 1.1045, G loss: 1.3037\n",
      "[844/1600] D loss: 1.9316, G loss: 0.4747\n",
      "[964/1600] D loss: 1.0155, G loss: 2.4780\n",
      "[1084/1600] D loss: 0.3969, G loss: 3.8816\n",
      "[1204/1600] D loss: 1.2317, G loss: 1.1305\n",
      "[1324/1600] D loss: 0.4084, G loss: 2.1014\n",
      "[1444/1600] D loss: 0.9579, G loss: 1.6568\n",
      "[1564/1600] D loss: 1.1247, G loss: 1.1426\n",
      "train error: \n",
      " D loss: 0.873596, G loss: 2.330699, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 31.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.131887, G loss: 2.633681, D accuracy: 70.2%, cell accuracy: 98.4%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2933, G loss: 4.3950\n",
      "[124/1600] D loss: 0.5561, G loss: 2.1278\n",
      "[244/1600] D loss: 0.9275, G loss: 1.6152\n",
      "[364/1600] D loss: 0.9366, G loss: 2.1695\n",
      "[484/1600] D loss: 0.7933, G loss: 1.5432\n",
      "[604/1600] D loss: 0.3570, G loss: 3.2616\n",
      "[724/1600] D loss: 0.8550, G loss: 1.8123\n",
      "[844/1600] D loss: 0.8079, G loss: 2.8371\n",
      "[964/1600] D loss: 1.8867, G loss: 1.5494\n",
      "[1084/1600] D loss: 0.6133, G loss: 2.7017\n",
      "[1204/1600] D loss: 0.5991, G loss: 2.0095\n",
      "[1324/1600] D loss: 0.7602, G loss: 1.6821\n",
      "[1444/1600] D loss: 0.3625, G loss: 3.7276\n",
      "[1564/1600] D loss: 0.7776, G loss: 1.8807\n",
      "train error: \n",
      " D loss: 0.989288, G loss: 2.676328, D accuracy: 71.1%, cell accuracy: 98.5%, board accuracy: 33.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309030, G loss: 2.951305, D accuracy: 67.5%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8061, G loss: 2.3626\n",
      "[124/1600] D loss: 0.7115, G loss: 2.2432\n",
      "[244/1600] D loss: 0.7544, G loss: 1.9836\n",
      "[364/1600] D loss: 1.0421, G loss: 0.9660\n",
      "[484/1600] D loss: 0.9240, G loss: 1.1193\n",
      "[604/1600] D loss: 1.3966, G loss: 0.8463\n",
      "[724/1600] D loss: 0.5996, G loss: 1.7966\n",
      "[844/1600] D loss: 0.3758, G loss: 3.6034\n",
      "[964/1600] D loss: 0.4109, G loss: 2.4963\n",
      "[1084/1600] D loss: 0.0792, G loss: 4.4022\n",
      "[1204/1600] D loss: 1.2495, G loss: 0.7880\n",
      "[1324/1600] D loss: 1.0009, G loss: 1.8126\n",
      "[1444/1600] D loss: 0.8417, G loss: 3.0917\n",
      "[1564/1600] D loss: 1.2410, G loss: 1.0782\n",
      "train error: \n",
      " D loss: 0.905802, G loss: 1.936171, D accuracy: 73.8%, cell accuracy: 98.5%, board accuracy: 34.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.135239, G loss: 2.221217, D accuracy: 68.8%, cell accuracy: 98.4%, board accuracy: 32.5% \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8614, G loss: 1.2845\n",
      "[124/1600] D loss: 0.7887, G loss: 1.3524\n",
      "[244/1600] D loss: 0.4896, G loss: 3.6803\n",
      "[364/1600] D loss: 1.3906, G loss: 0.9447\n",
      "[484/1600] D loss: 1.0191, G loss: 1.2483\n",
      "[604/1600] D loss: 0.3386, G loss: 2.9443\n",
      "[724/1600] D loss: 0.6179, G loss: 1.4815\n",
      "[844/1600] D loss: 0.5041, G loss: 3.6511\n",
      "[964/1600] D loss: 0.6109, G loss: 2.0382\n",
      "[1084/1600] D loss: 1.1106, G loss: 1.2331\n",
      "[1204/1600] D loss: 1.0346, G loss: 1.1620\n",
      "[1324/1600] D loss: 1.4760, G loss: 0.5557\n",
      "[1444/1600] D loss: 0.7317, G loss: 2.3205\n",
      "[1564/1600] D loss: 0.7238, G loss: 3.2572\n",
      "train error: \n",
      " D loss: 0.876416, G loss: 2.116305, D accuracy: 73.9%, cell accuracy: 98.6%, board accuracy: 34.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.129496, G loss: 2.450085, D accuracy: 69.9%, cell accuracy: 98.4%, board accuracy: 34.0% \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9118, G loss: 1.7658\n",
      "[124/1600] D loss: 0.8493, G loss: 2.8516\n",
      "[244/1600] D loss: 0.7313, G loss: 2.9673\n",
      "[364/1600] D loss: 1.3659, G loss: 0.5790\n",
      "[484/1600] D loss: 0.4392, G loss: 3.7068\n",
      "[604/1600] D loss: 0.9186, G loss: 2.3394\n",
      "[724/1600] D loss: 1.0918, G loss: 2.2016\n",
      "[844/1600] D loss: 0.7220, G loss: 3.9063\n",
      "[964/1600] D loss: 1.0138, G loss: 1.7124\n",
      "[1084/1600] D loss: 1.2428, G loss: 1.1124\n",
      "[1204/1600] D loss: 0.9013, G loss: 1.7936\n",
      "[1324/1600] D loss: 0.7504, G loss: 1.3927\n",
      "[1444/1600] D loss: 1.1871, G loss: 0.9312\n",
      "[1564/1600] D loss: 1.3728, G loss: 0.4992\n",
      "train error: \n",
      " D loss: 0.881978, G loss: 2.309465, D accuracy: 74.1%, cell accuracy: 98.6%, board accuracy: 36.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.165522, G loss: 2.542070, D accuracy: 68.6%, cell accuracy: 98.5%, board accuracy: 34.2% \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5786, G loss: 2.8132\n",
      "[124/1600] D loss: 0.3764, G loss: 3.3035\n",
      "[244/1600] D loss: 0.3956, G loss: 3.4900\n",
      "[364/1600] D loss: 0.4659, G loss: 4.7009\n",
      "[484/1600] D loss: 1.0205, G loss: 1.1208\n",
      "[604/1600] D loss: 1.4601, G loss: 0.7169\n",
      "[724/1600] D loss: 1.0044, G loss: 1.0136\n",
      "[844/1600] D loss: 0.5451, G loss: 2.0512\n",
      "[964/1600] D loss: 0.8255, G loss: 2.2862\n",
      "[1084/1600] D loss: 0.8482, G loss: 1.5721\n",
      "[1204/1600] D loss: 0.8242, G loss: 1.7082\n",
      "[1324/1600] D loss: 0.8223, G loss: 1.2793\n",
      "[1444/1600] D loss: 1.0652, G loss: 1.1720\n",
      "[1564/1600] D loss: 1.4417, G loss: 0.8964\n",
      "train error: \n",
      " D loss: 0.923832, G loss: 1.576012, D accuracy: 73.3%, cell accuracy: 98.6%, board accuracy: 35.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.128053, G loss: 1.881126, D accuracy: 68.2%, cell accuracy: 98.5%, board accuracy: 35.5% \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5295, G loss: 0.5998\n",
      "[124/1600] D loss: 0.6877, G loss: 1.6566\n",
      "[244/1600] D loss: 0.7178, G loss: 2.7381\n",
      "[364/1600] D loss: 1.5016, G loss: 1.1497\n",
      "[484/1600] D loss: 0.3548, G loss: 2.9229\n",
      "[604/1600] D loss: 1.0979, G loss: 1.0956\n",
      "[724/1600] D loss: 0.1823, G loss: 4.4326\n",
      "[844/1600] D loss: 1.1987, G loss: 2.8739\n",
      "[964/1600] D loss: 0.7363, G loss: 2.5357\n",
      "[1084/1600] D loss: 0.7401, G loss: 1.9525\n",
      "[1204/1600] D loss: 1.5794, G loss: 0.6629\n",
      "[1324/1600] D loss: 0.8589, G loss: 2.3777\n",
      "[1444/1600] D loss: 0.3387, G loss: 2.0467\n",
      "[1564/1600] D loss: 0.7768, G loss: 3.0974\n",
      "train error: \n",
      " D loss: 0.864845, G loss: 1.861965, D accuracy: 74.4%, cell accuracy: 98.5%, board accuracy: 33.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.076560, G loss: 2.154012, D accuracy: 69.9%, cell accuracy: 98.4%, board accuracy: 32.2% \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0784, G loss: 4.7020\n",
      "[124/1600] D loss: 1.1168, G loss: 1.1461\n",
      "[244/1600] D loss: 0.8662, G loss: 2.1051\n",
      "[364/1600] D loss: 0.6168, G loss: 1.6840\n",
      "[484/1600] D loss: 0.8378, G loss: 1.6725\n",
      "[604/1600] D loss: 0.7755, G loss: 2.5787\n",
      "[724/1600] D loss: 0.6187, G loss: 1.7830\n",
      "[844/1600] D loss: 0.8520, G loss: 1.4686\n",
      "[964/1600] D loss: 1.1304, G loss: 1.2556\n",
      "[1084/1600] D loss: 0.6693, G loss: 2.4971\n",
      "[1204/1600] D loss: 0.9470, G loss: 1.7245\n",
      "[1324/1600] D loss: 1.4344, G loss: 1.9309\n",
      "[1444/1600] D loss: 1.4607, G loss: 0.5913\n",
      "[1564/1600] D loss: 1.0717, G loss: 0.8249\n",
      "train error: \n",
      " D loss: 0.859356, G loss: 1.947912, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 36.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.123427, G loss: 2.198426, D accuracy: 67.9%, cell accuracy: 98.4%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3714, G loss: 4.1096\n",
      "[124/1600] D loss: 0.3553, G loss: 3.8447\n",
      "[244/1600] D loss: 1.0362, G loss: 2.6568\n",
      "[364/1600] D loss: 0.5857, G loss: 2.3218\n",
      "[484/1600] D loss: 0.8843, G loss: 1.1327\n",
      "[604/1600] D loss: 0.1939, G loss: 2.4790\n",
      "[724/1600] D loss: 0.4247, G loss: 3.4075\n",
      "[844/1600] D loss: 1.4542, G loss: 1.0694\n",
      "[964/1600] D loss: 1.3082, G loss: 0.7918\n",
      "[1084/1600] D loss: 0.5575, G loss: 1.5926\n",
      "[1204/1600] D loss: 0.9305, G loss: 1.0915\n",
      "[1324/1600] D loss: 0.7212, G loss: 2.7616\n",
      "[1444/1600] D loss: 0.5788, G loss: 2.7951\n",
      "[1564/1600] D loss: 0.7328, G loss: 2.4840\n",
      "train error: \n",
      " D loss: 0.839985, G loss: 2.173031, D accuracy: 75.4%, cell accuracy: 98.6%, board accuracy: 35.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.128195, G loss: 2.475971, D accuracy: 69.4%, cell accuracy: 98.5%, board accuracy: 33.0% \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1134, G loss: 2.4394\n",
      "[124/1600] D loss: 0.7177, G loss: 1.8407\n",
      "[244/1600] D loss: 0.7393, G loss: 2.0703\n",
      "[364/1600] D loss: 0.7844, G loss: 1.7061\n",
      "[484/1600] D loss: 1.4387, G loss: 0.6827\n",
      "[604/1600] D loss: 0.9892, G loss: 1.7044\n",
      "[724/1600] D loss: 0.8465, G loss: 1.8024\n",
      "[844/1600] D loss: 0.5315, G loss: 2.5163\n",
      "[964/1600] D loss: 0.6862, G loss: 2.3833\n",
      "[1084/1600] D loss: 0.6539, G loss: 2.6716\n",
      "[1204/1600] D loss: 0.7700, G loss: 2.6630\n",
      "[1324/1600] D loss: 0.2890, G loss: 6.6336\n",
      "[1444/1600] D loss: 0.7890, G loss: 2.7631\n",
      "[1564/1600] D loss: 0.8069, G loss: 1.5477\n",
      "train error: \n",
      " D loss: 0.862502, G loss: 1.979039, D accuracy: 74.4%, cell accuracy: 98.6%, board accuracy: 34.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.042586, G loss: 2.350008, D accuracy: 71.0%, cell accuracy: 98.5%, board accuracy: 33.2% \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3358, G loss: 2.5057\n",
      "[124/1600] D loss: 0.7749, G loss: 3.0590\n",
      "[244/1600] D loss: 0.8437, G loss: 1.6531\n",
      "[364/1600] D loss: 0.7208, G loss: 3.0380\n",
      "[484/1600] D loss: 0.7836, G loss: 1.3148\n",
      "[604/1600] D loss: 0.7427, G loss: 3.4534\n",
      "[724/1600] D loss: 1.0603, G loss: 1.6151\n",
      "[844/1600] D loss: 0.5638, G loss: 2.4256\n",
      "[964/1600] D loss: 0.8310, G loss: 1.3940\n",
      "[1084/1600] D loss: 0.7451, G loss: 2.5389\n",
      "[1204/1600] D loss: 1.1501, G loss: 1.4954\n",
      "[1324/1600] D loss: 1.0050, G loss: 2.4754\n",
      "[1444/1600] D loss: 0.4924, G loss: 2.5329\n",
      "[1564/1600] D loss: 0.8508, G loss: 1.5822\n",
      "train error: \n",
      " D loss: 0.880320, G loss: 1.612494, D accuracy: 74.5%, cell accuracy: 98.6%, board accuracy: 35.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.066523, G loss: 1.968580, D accuracy: 70.5%, cell accuracy: 98.4%, board accuracy: 34.0% \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7554, G loss: 1.3355\n",
      "[124/1600] D loss: 1.1219, G loss: 0.9309\n",
      "[244/1600] D loss: 0.7157, G loss: 1.8717\n",
      "[364/1600] D loss: 1.1096, G loss: 1.9510\n",
      "[484/1600] D loss: 0.5371, G loss: 3.1500\n",
      "[604/1600] D loss: 0.8017, G loss: 1.5543\n",
      "[724/1600] D loss: 0.6021, G loss: 2.1603\n",
      "[844/1600] D loss: 0.7852, G loss: 1.7852\n",
      "[964/1600] D loss: 0.6960, G loss: 1.5038\n",
      "[1084/1600] D loss: 0.8167, G loss: 1.6609\n",
      "[1204/1600] D loss: 0.8535, G loss: 2.2113\n",
      "[1324/1600] D loss: 0.4290, G loss: 3.1953\n",
      "[1444/1600] D loss: 0.6788, G loss: 2.5824\n",
      "[1564/1600] D loss: 0.8805, G loss: 1.6225\n",
      "train error: \n",
      " D loss: 0.960017, G loss: 1.415056, D accuracy: 72.9%, cell accuracy: 98.6%, board accuracy: 36.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.121891, G loss: 1.709832, D accuracy: 68.8%, cell accuracy: 98.4%, board accuracy: 32.8% \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2319, G loss: 1.3537\n",
      "[124/1600] D loss: 0.6021, G loss: 1.8034\n",
      "[244/1600] D loss: 0.5335, G loss: 3.4100\n",
      "[364/1600] D loss: 1.0116, G loss: 1.2776\n",
      "[484/1600] D loss: 0.7014, G loss: 1.7598\n",
      "[604/1600] D loss: 0.5684, G loss: 2.2400\n",
      "[724/1600] D loss: 0.7887, G loss: 1.7325\n",
      "[844/1600] D loss: 0.7521, G loss: 1.7230\n",
      "[964/1600] D loss: 0.6667, G loss: 3.4407\n",
      "[1084/1600] D loss: 0.4754, G loss: 2.1182\n",
      "[1204/1600] D loss: 0.9816, G loss: 3.1661\n",
      "[1324/1600] D loss: 0.9979, G loss: 0.8094\n",
      "[1444/1600] D loss: 0.6923, G loss: 3.6623\n",
      "[1564/1600] D loss: 0.8360, G loss: 3.9385\n",
      "train error: \n",
      " D loss: 0.861552, G loss: 1.821293, D accuracy: 74.2%, cell accuracy: 98.6%, board accuracy: 37.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.068074, G loss: 2.226918, D accuracy: 68.8%, cell accuracy: 98.4%, board accuracy: 35.5% \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3027, G loss: 0.8488\n",
      "[124/1600] D loss: 0.8574, G loss: 1.2200\n",
      "[244/1600] D loss: 0.8629, G loss: 1.9899\n",
      "[364/1600] D loss: 0.9752, G loss: 1.3392\n",
      "[484/1600] D loss: 1.0934, G loss: 1.5380\n",
      "[604/1600] D loss: 1.4975, G loss: 0.5334\n",
      "[724/1600] D loss: 1.0724, G loss: 1.3750\n",
      "[844/1600] D loss: 1.1565, G loss: 1.2021\n",
      "[964/1600] D loss: 0.7382, G loss: 2.3746\n",
      "[1084/1600] D loss: 0.7205, G loss: 2.9884\n",
      "[1204/1600] D loss: 0.5250, G loss: 2.4845\n",
      "[1324/1600] D loss: 1.0257, G loss: 1.5163\n",
      "[1444/1600] D loss: 1.2536, G loss: 1.4368\n",
      "[1564/1600] D loss: 0.3945, G loss: 3.1141\n",
      "train error: \n",
      " D loss: 0.868184, G loss: 1.956601, D accuracy: 73.8%, cell accuracy: 98.6%, board accuracy: 37.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.104938, G loss: 2.334637, D accuracy: 69.9%, cell accuracy: 98.5%, board accuracy: 36.5% \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4267, G loss: 0.8902\n",
      "[124/1600] D loss: 1.0669, G loss: 1.4244\n",
      "[244/1600] D loss: 0.5957, G loss: 2.8339\n",
      "[364/1600] D loss: 0.9142, G loss: 3.3873\n",
      "[484/1600] D loss: 0.7317, G loss: 2.6684\n",
      "[604/1600] D loss: 1.2970, G loss: 1.5510\n",
      "[724/1600] D loss: 0.6991, G loss: 1.7208\n",
      "[844/1600] D loss: 0.6743, G loss: 3.1557\n",
      "[964/1600] D loss: 0.8868, G loss: 1.6672\n",
      "[1084/1600] D loss: 0.4698, G loss: 4.0921\n",
      "[1204/1600] D loss: 0.4031, G loss: 3.4093\n",
      "[1324/1600] D loss: 0.5566, G loss: 1.9263\n",
      "[1444/1600] D loss: 0.7157, G loss: 3.8043\n",
      "[1564/1600] D loss: 1.1089, G loss: 1.0607\n",
      "train error: \n",
      " D loss: 0.877712, G loss: 1.736685, D accuracy: 74.1%, cell accuracy: 98.6%, board accuracy: 36.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.074971, G loss: 2.056794, D accuracy: 69.9%, cell accuracy: 98.4%, board accuracy: 33.8% \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5864, G loss: 1.7197\n",
      "[124/1600] D loss: 1.3648, G loss: 0.5506\n",
      "[244/1600] D loss: 0.9529, G loss: 2.7692\n",
      "[364/1600] D loss: 0.7408, G loss: 2.4400\n",
      "[484/1600] D loss: 1.4994, G loss: 0.6202\n",
      "[604/1600] D loss: 1.0639, G loss: 2.0118\n",
      "[724/1600] D loss: 0.7317, G loss: 1.7294\n",
      "[844/1600] D loss: 1.0793, G loss: 0.7972\n",
      "[964/1600] D loss: 0.7760, G loss: 2.6451\n",
      "[1084/1600] D loss: 1.2914, G loss: 1.5895\n",
      "[1204/1600] D loss: 1.2338, G loss: 1.0907\n",
      "[1324/1600] D loss: 0.3540, G loss: 2.8307\n",
      "[1444/1600] D loss: 0.7654, G loss: 2.0322\n",
      "[1564/1600] D loss: 0.9664, G loss: 1.1613\n",
      "train error: \n",
      " D loss: 0.928125, G loss: 2.041113, D accuracy: 72.5%, cell accuracy: 98.6%, board accuracy: 35.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.130651, G loss: 2.368864, D accuracy: 69.5%, cell accuracy: 98.4%, board accuracy: 32.2% \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4217, G loss: 3.0099\n",
      "[124/1600] D loss: 1.1777, G loss: 1.4039\n",
      "[244/1600] D loss: 0.9908, G loss: 1.6863\n",
      "[364/1600] D loss: 0.5119, G loss: 2.8053\n",
      "[484/1600] D loss: 0.5963, G loss: 2.5248\n",
      "[604/1600] D loss: 1.5567, G loss: 1.2584\n",
      "[724/1600] D loss: 0.8908, G loss: 1.7597\n",
      "[844/1600] D loss: 0.8166, G loss: 2.0391\n",
      "[964/1600] D loss: 1.0631, G loss: 0.8873\n",
      "[1084/1600] D loss: 0.2095, G loss: 2.4641\n",
      "[1204/1600] D loss: 0.7149, G loss: 3.5318\n",
      "[1324/1600] D loss: 0.7552, G loss: 1.2082\n",
      "[1444/1600] D loss: 0.5097, G loss: 1.5098\n",
      "[1564/1600] D loss: 0.7230, G loss: 3.0030\n",
      "train error: \n",
      " D loss: 0.926410, G loss: 2.430008, D accuracy: 72.6%, cell accuracy: 98.6%, board accuracy: 36.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.194682, G loss: 2.849163, D accuracy: 69.2%, cell accuracy: 98.4%, board accuracy: 33.0% \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1987, G loss: 1.0772\n",
      "[124/1600] D loss: 0.6229, G loss: 1.9954\n",
      "[244/1600] D loss: 0.6218, G loss: 2.3346\n",
      "[364/1600] D loss: 0.8565, G loss: 1.3046\n",
      "[484/1600] D loss: 1.4758, G loss: 0.7178\n",
      "[604/1600] D loss: 0.7530, G loss: 1.7926\n",
      "[724/1600] D loss: 0.6747, G loss: 4.2140\n",
      "[844/1600] D loss: 0.4397, G loss: 1.8292\n",
      "[964/1600] D loss: 0.8657, G loss: 3.3864\n",
      "[1084/1600] D loss: 0.4461, G loss: 2.0893\n",
      "[1204/1600] D loss: 0.4750, G loss: 2.1241\n",
      "[1324/1600] D loss: 1.2849, G loss: 0.6368\n",
      "[1444/1600] D loss: 1.4775, G loss: 0.8316\n",
      "[1564/1600] D loss: 1.2664, G loss: 0.9265\n",
      "train error: \n",
      " D loss: 0.835173, G loss: 2.028624, D accuracy: 75.7%, cell accuracy: 98.6%, board accuracy: 37.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.094976, G loss: 2.328587, D accuracy: 69.6%, cell accuracy: 98.5%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4444, G loss: 3.0701\n",
      "[124/1600] D loss: 0.5925, G loss: 2.2491\n",
      "[244/1600] D loss: 1.1549, G loss: 1.1776\n",
      "[364/1600] D loss: 0.9024, G loss: 1.7231\n",
      "[484/1600] D loss: 0.9217, G loss: 1.7480\n",
      "[604/1600] D loss: 1.1958, G loss: 1.3266\n",
      "[724/1600] D loss: 1.4138, G loss: 0.6665\n",
      "[844/1600] D loss: 1.0468, G loss: 2.8475\n",
      "[964/1600] D loss: 1.0171, G loss: 1.6861\n",
      "[1084/1600] D loss: 0.7893, G loss: 1.4472\n",
      "[1204/1600] D loss: 0.8123, G loss: 1.7387\n",
      "[1324/1600] D loss: 1.0826, G loss: 1.7326\n",
      "[1444/1600] D loss: 0.9224, G loss: 0.9480\n",
      "[1564/1600] D loss: 0.7044, G loss: 2.5770\n",
      "train error: \n",
      " D loss: 0.874995, G loss: 2.097255, D accuracy: 74.0%, cell accuracy: 98.6%, board accuracy: 38.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.135464, G loss: 2.474018, D accuracy: 68.8%, cell accuracy: 98.5%, board accuracy: 37.5% \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9054, G loss: 2.7876\n",
      "[124/1600] D loss: 1.4211, G loss: 0.8750\n",
      "[244/1600] D loss: 1.1640, G loss: 1.4920\n",
      "[364/1600] D loss: 0.9136, G loss: 1.8253\n",
      "[484/1600] D loss: 0.6331, G loss: 2.4391\n",
      "[604/1600] D loss: 0.8391, G loss: 1.9782\n",
      "[724/1600] D loss: 0.6517, G loss: 3.4543\n",
      "[844/1600] D loss: 1.0406, G loss: 2.1460\n",
      "[964/1600] D loss: 0.8362, G loss: 4.4325\n",
      "[1084/1600] D loss: 0.8721, G loss: 2.0910\n",
      "[1204/1600] D loss: 0.7154, G loss: 2.7669\n",
      "[1324/1600] D loss: 0.7638, G loss: 2.3370\n",
      "[1444/1600] D loss: 1.1662, G loss: 0.6423\n",
      "[1564/1600] D loss: 0.9078, G loss: 1.4638\n",
      "train error: \n",
      " D loss: 0.845485, G loss: 2.166616, D accuracy: 74.8%, cell accuracy: 98.6%, board accuracy: 36.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.114180, G loss: 2.565421, D accuracy: 69.2%, cell accuracy: 98.5%, board accuracy: 35.0% \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7314, G loss: 2.5291\n",
      "[124/1600] D loss: 0.9821, G loss: 2.6111\n",
      "[244/1600] D loss: 0.8987, G loss: 1.6715\n",
      "[364/1600] D loss: 0.7804, G loss: 3.0044\n",
      "[484/1600] D loss: 1.3646, G loss: 0.7881\n",
      "[604/1600] D loss: 0.3773, G loss: 3.5327\n",
      "[724/1600] D loss: 0.6183, G loss: 2.2558\n",
      "[844/1600] D loss: 0.4125, G loss: 2.3884\n",
      "[964/1600] D loss: 0.7149, G loss: 1.9895\n",
      "[1084/1600] D loss: 0.9078, G loss: 1.8867\n",
      "[1204/1600] D loss: 0.3810, G loss: 3.7064\n",
      "[1324/1600] D loss: 1.5177, G loss: 0.5732\n",
      "[1444/1600] D loss: 0.8324, G loss: 1.9909\n",
      "[1564/1600] D loss: 1.4496, G loss: 2.2172\n",
      "train error: \n",
      " D loss: 0.911101, G loss: 2.014804, D accuracy: 73.4%, cell accuracy: 98.6%, board accuracy: 37.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.167335, G loss: 2.337950, D accuracy: 69.1%, cell accuracy: 98.4%, board accuracy: 36.5% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "epochs = 300\n",
    "\n",
    "gen = TetrisModel()\n",
    "disc = TetrisDiscriminator()\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "log_dir = os.path.join(\"runs\", \"tetris_emulator\")\n",
    "log_subdir = os.path.join(log_dir, datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "train_examples = find_interesting_examples(train_dataset)\n",
    "test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "    test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "    test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "    gen_zero_grads = 0\n",
    "    for name, weight in gen.named_parameters():\n",
    "        tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "        if weight.grad is not None:\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "            gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "    tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "    disc_zero_grads = 0\n",
    "    for name, weight in disc.named_parameters():\n",
    "        tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "        if weight.grad is not None:\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "            disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "    tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "\n",
    "tb_writer.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this as many times as needed to \"top-up\" the training\n",
    "\n",
    "extra_epochs = 10\n",
    "\n",
    "tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "for epoch in range(epochs, epochs + extra_epochs):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "    test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "    test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "    gen_zero_grads = 0\n",
    "    for name, weight in gen.named_parameters():\n",
    "        tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "        if weight.grad is not None:\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "            gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "    tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "    disc_zero_grads = 0\n",
    "    for name, weight in disc.named_parameters():\n",
    "        tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "        if weight.grad is not None:\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "            disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "    tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "\n",
    "tb_writer.close()\n",
    "\n",
    "epochs += extra_epochs\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engines import EVENT_NAMES\n",
    "\n",
    "\n",
    "def show_prediction(example):\n",
    "    (b, e), y = example\n",
    "    pred = gen(b.unsqueeze(0), e.unsqueeze(0)).squeeze(0)\n",
    "    b, e, y, pred = b.argmax(0), e.argmax(0), y.argmax(0), pred.argmax(0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    fig.suptitle(f\"Prediction vs reality\\nEvent = {EVENT_NAMES[e]}\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].set_title(\"Predicted\")\n",
    "    axs[2].set_title(\"Reality\")\n",
    "\n",
    "    axs[0].imshow(render_board(b).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[1].imshow(render_board(pred).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[2].imshow(render_board(y).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 683\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random training prediction vs reality\n",
    "import random\n",
    "\n",
    "idx = random.randrange(len(train_dataset))\n",
    "print(f\"Showing prediction for training example {idx}\")\n",
    "show_prediction(train_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for test example 287\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random test prediction vs reality\n",
    "idx = random.randrange(len(test_dataset))\n",
    "print(f\"Showing prediction for test example {idx}\")\n",
    "show_prediction(test_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), \"tetris_emulator.pth\")\n",
    "torch.save(disc.state_dict(), \"tetris_discriminator.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
