{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Tetris emulator\n",
    "\n",
    "In this notebook, we train a model to emulate Tetris and provide a backend for our model-based game engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from models import TetrisModel, TetrisDiscriminator\n",
    "import metrics\n",
    "from recording import FileBasedDatabaseWithEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CELL_TYPES = 8\n",
    "NUM_EVENT_TYPES = 5\n",
    "\n",
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self._db = FileBasedDatabaseWithEvents(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._db)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        boards, events = self._db[idx]\n",
    "        b = self._transform_board(boards[-2]) # Ignore all boards except the last two\n",
    "        e = self._transform_event(events[-1])\n",
    "        x = (b, e)\n",
    "        y = self._transform_board(boards[-1])\n",
    "        return x, y\n",
    "    \n",
    "    def _transform_board(self, board):\n",
    "        board = torch.tensor(board, dtype=torch.long)\n",
    "        board = F.one_hot(board, NUM_CELL_TYPES) # One-hot encode the cell types\n",
    "        board = board.type(torch.float) # Convert to floating-point\n",
    "        board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "        return board\n",
    "    \n",
    "    def _transform_event(self, event):\n",
    "        event = torch.tensor(event, dtype=torch.long)\n",
    "        event = F.one_hot(event, NUM_EVENT_TYPES) # One-hot encode the event\n",
    "        event = event.type(torch.float) # Convert to floating-point\n",
    "        return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: shape torch.Size([4, 8, 22, 10]), dtype torch.float32\n",
      "e: shape torch.Size([4, 5]), dtype torch.float32\n",
      "y: shape torch.Size([4, 8, 22, 10]), dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "(b, e), y = next(iter(train_dataloader))\n",
    "print(f\"x: shape {b.shape}, dtype {b.dtype}\")\n",
    "print(f\"e: shape {e.shape}, dtype {e.dtype}\")\n",
    "print(f\"y: shape {y.shape}, dtype {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generator parameters: 19682\n",
      "Number of discriminator parameters: 9505\n",
      "Discriminator score for real data: 0.5872651934623718\n",
      "Discriminator score for fake data: 0.6052905917167664\n"
     ]
    }
   ],
   "source": [
    "gen = TetrisModel()\n",
    "disc = TetrisDiscriminator()\n",
    "\n",
    "with torch.no_grad():\n",
    "    (b, e), y = next(iter(train_dataloader))\n",
    "    y_gen = gen(b, e)\n",
    "    pred_on_real = F.sigmoid(disc(b, e, y)[0])\n",
    "    pred_on_fake = F.sigmoid(disc(b, e, y_gen)[0])\n",
    "    print(f\"Number of generator parameters: {count_parameters(gen)}\")\n",
    "    print(f\"Number of discriminator parameters: {count_parameters(disc)}\")\n",
    "    print(f\"Discriminator score for real data: {pred_on_real}\")\n",
    "    print(f\"Discriminator score for fake data: {pred_on_fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from engines import EventTypes\n",
    "\n",
    "def find_interesting_examples(dataset, num=3):\n",
    "    num_spawns = num\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "\n",
    "        for (b, e), y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (e.argmax(0).item() == EventTypes.DROP) & (b.argmax(0)[0] == 0).all() & (y.argmax(0)[0] > 0).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield (b, e), y\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tetris import CELL_COLORS\n",
    "\n",
    "def render_board(board):\n",
    "    height, width = board.shape\n",
    "    img = np.zeros((3, height, width))\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            img[:, row, col] = CELL_COLORS[board[row, col]]\n",
    "    img /= 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prediction(b, e, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        b: Tensor of shape (height, width), the initial board state.\n",
    "        e: Tensor of shape (1,), the event type.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the next board state.\n",
    "    \"\"\"\n",
    "    assert len(b.shape) == 2, f\"Expected tensors of shape (width, height) but got {b.shape}\"\n",
    "    assert b.shape == pred.shape, f\"Shapes do not match: {b.shape} != {pred.shape}\"\n",
    "    assert b.shape == y.shape, f\"Shapes do not match: {b.shape} != {y.shape}\"\n",
    "    assert len(e.shape) == 0, f\"Expected e of shape () but got {e.shape}\"\n",
    "    height, width = b.shape\n",
    "    with torch.no_grad():\n",
    "        b = render_board(b)\n",
    "        pred = render_board(pred)\n",
    "        y = render_board(y)\n",
    "        separator = np.ones((3, height, 1))\n",
    "        return np.concatenate((b, separator, pred, separator, y), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, ((b, e), y) in enumerate(dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        batch_size = b.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(b, e, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(b, e)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(b, e, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(b, e, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 30 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = metrics.CellAccuracy()\n",
    "    board_accuracy = metrics.BoardAccuracy()\n",
    "    board_plausibility = metrics.BoardPlausibility()\n",
    "    spawn_recall = metrics.SpawnRecall()\n",
    "    spawn_precision = metrics.SpawnPrecision()\n",
    "    spawn_validity = metrics.SpawnValidity()\n",
    "    scores_real = np.zeros(len(dataloader.dataset))\n",
    "    scores_fake = np.zeros(len(dataloader.dataset))\n",
    "    spawn_diversity = metrics.SpawnDiversity()\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for batch, ((b, e), y) in enumerate(dataloader):\n",
    "            batch_size = b.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float)\n",
    "\n",
    "            output_real = disc(b, e, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            y_fake = gen(b, e)\n",
    "            output_fake = disc(b, e, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_b = torch.argmax(b, dim=1)\n",
    "            classes_e = torch.argmax(e, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy.update_state(classes_y_fake, classes_y)\n",
    "            board_accuracy.update_state(classes_y_fake, classes_y)\n",
    "            board_plausibility.update_state(classes_b, classes_y_fake, classes_y)\n",
    "\n",
    "            spawn_recall.update_state(classes_b, classes_y_fake, classes_y)\n",
    "            spawn_precision.update_state(classes_b, classes_y_fake, classes_y)\n",
    "            spawn_validity.update_state(classes_b, classes_y_fake)\n",
    "\n",
    "            start_index = dataloader.batch_size * batch\n",
    "            end_index = start_index + batch_size\n",
    "            scores_real[start_index:end_index] = torch.sigmoid(output_real).numpy()\n",
    "            scores_fake[start_index:end_index] = torch.sigmoid(output_fake).numpy()\n",
    "\n",
    "            spawn_diversity.update_state(classes_b, classes_y_fake)\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(cell_accuracy.result()):>0.1%}, board accuracy: {(board_accuracy.result()):>0.1%} \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Board plausibility/{split_name}\", board_plausibility.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn precision/{split_name}\", spawn_precision.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn validity/{split_name}\", spawn_validity.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn diversity/{split_name}\", spawn_diversity.result(), epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, ((b, e), y) in enumerate(examples):\n",
    "            b, e, y = b.unsqueeze(0), e.unsqueeze(0), y.unsqueeze(0)\n",
    "            y_fake = gen(b, e)\n",
    "            b, e, y, y_fake = b.squeeze(0), e.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            b, e, y, y_fake = b.argmax(0), e.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(b, e, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch)\n",
    "    \n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/real\", scores_real, epoch)\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/fake\", scores_fake, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3456, G loss: 0.6193\n",
      "[124/1600] D loss: 1.2664, G loss: 0.6356\n",
      "[244/1600] D loss: 1.1182, G loss: 0.6585\n",
      "[364/1600] D loss: 1.0119, G loss: 0.6560\n",
      "[484/1600] D loss: 0.8031, G loss: 0.7269\n",
      "[604/1600] D loss: 0.7320, G loss: 0.7364\n",
      "[724/1600] D loss: 0.7036, G loss: 0.7673\n",
      "[844/1600] D loss: 0.6509, G loss: 0.8369\n",
      "[964/1600] D loss: 0.8988, G loss: 0.7631\n",
      "[1084/1600] D loss: 0.6283, G loss: 0.9918\n",
      "[1204/1600] D loss: 0.4863, G loss: 1.1581\n",
      "[1324/1600] D loss: 0.6584, G loss: 1.4735\n",
      "[1444/1600] D loss: 0.3856, G loss: 1.6085\n",
      "[1564/1600] D loss: 0.3305, G loss: 1.9264\n",
      "train error: \n",
      " D loss: 0.490880, G loss: 2.067127, D accuracy: 90.1%, cell accuracy: 34.4%, board accuracy: 0.0% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\tetris-emulator\\metrics.py:210: RuntimeWarning: invalid value encountered in divide\n",
      "  probs = self.predicted_spawn_type_counts / num_predicted_spawns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error: \n",
      " D loss: 0.475875, G loss: 2.104115, D accuracy: 90.9%, cell accuracy: 31.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4875, G loss: 2.1892\n",
      "[124/1600] D loss: 0.3174, G loss: 2.2965\n",
      "[244/1600] D loss: 0.4333, G loss: 2.7262\n",
      "[364/1600] D loss: 0.3509, G loss: 2.8353\n",
      "[484/1600] D loss: 0.3617, G loss: 2.9413\n",
      "[604/1600] D loss: 0.3620, G loss: 2.8984\n",
      "[724/1600] D loss: 0.4375, G loss: 3.4306\n",
      "[844/1600] D loss: 0.4585, G loss: 2.7666\n",
      "[964/1600] D loss: 0.4767, G loss: 2.7872\n",
      "[1084/1600] D loss: 0.7375, G loss: 2.8199\n",
      "[1204/1600] D loss: 0.5386, G loss: 3.1543\n",
      "[1324/1600] D loss: 0.4959, G loss: 3.3974\n",
      "[1444/1600] D loss: 0.2155, G loss: 2.9875\n",
      "[1564/1600] D loss: 0.5203, G loss: 3.0502\n",
      "train error: \n",
      " D loss: 0.332673, G loss: 3.338755, D accuracy: 97.5%, cell accuracy: 54.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.333827, G loss: 3.273748, D accuracy: 97.4%, cell accuracy: 56.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5855, G loss: 3.4239\n",
      "[124/1600] D loss: 0.3772, G loss: 3.0987\n",
      "[244/1600] D loss: 0.5181, G loss: 3.2122\n",
      "[364/1600] D loss: 0.4710, G loss: 2.4527\n",
      "[484/1600] D loss: 0.3867, G loss: 2.8327\n",
      "[604/1600] D loss: 0.3165, G loss: 2.8203\n",
      "[724/1600] D loss: 0.3210, G loss: 3.1357\n",
      "[844/1600] D loss: 0.4309, G loss: 3.2963\n",
      "[964/1600] D loss: 0.4869, G loss: 2.4135\n",
      "[1084/1600] D loss: 0.3983, G loss: 2.5231\n",
      "[1204/1600] D loss: 0.3831, G loss: 3.8041\n",
      "[1324/1600] D loss: 0.2845, G loss: 2.6511\n",
      "[1444/1600] D loss: 0.4075, G loss: 3.2531\n",
      "[1564/1600] D loss: 0.5112, G loss: 2.2593\n",
      "train error: \n",
      " D loss: 0.441503, G loss: 3.085625, D accuracy: 95.9%, cell accuracy: 60.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.455729, G loss: 2.893620, D accuracy: 94.9%, cell accuracy: 62.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5866, G loss: 4.1553\n",
      "[124/1600] D loss: 0.2626, G loss: 3.1730\n",
      "[244/1600] D loss: 0.6765, G loss: 3.3792\n",
      "[364/1600] D loss: 0.5632, G loss: 3.8597\n",
      "[484/1600] D loss: 0.4256, G loss: 3.7653\n",
      "[604/1600] D loss: 0.2661, G loss: 3.7388\n",
      "[724/1600] D loss: 0.3552, G loss: 3.1164\n",
      "[844/1600] D loss: 0.3900, G loss: 3.4800\n",
      "[964/1600] D loss: 0.4710, G loss: 3.3860\n",
      "[1084/1600] D loss: 0.3702, G loss: 3.2605\n",
      "[1204/1600] D loss: 0.7852, G loss: 3.4276\n",
      "[1324/1600] D loss: 0.5452, G loss: 2.9064\n",
      "[1444/1600] D loss: 0.3797, G loss: 2.8782\n",
      "[1564/1600] D loss: 0.6417, G loss: 3.0846\n",
      "train error: \n",
      " D loss: 0.417019, G loss: 3.242298, D accuracy: 96.0%, cell accuracy: 68.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.430011, G loss: 3.219236, D accuracy: 94.9%, cell accuracy: 66.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1745, G loss: 3.5911\n",
      "[124/1600] D loss: 0.3551, G loss: 2.9521\n",
      "[244/1600] D loss: 0.4895, G loss: 2.7114\n",
      "[364/1600] D loss: 0.5240, G loss: 2.6850\n",
      "[484/1600] D loss: 0.4213, G loss: 3.9518\n",
      "[604/1600] D loss: 0.2709, G loss: 3.7217\n",
      "[724/1600] D loss: 0.3369, G loss: 2.5549\n",
      "[844/1600] D loss: 0.5634, G loss: 2.5165\n",
      "[964/1600] D loss: 0.9368, G loss: 1.8485\n",
      "[1084/1600] D loss: 0.3462, G loss: 3.4546\n",
      "[1204/1600] D loss: 0.2208, G loss: 3.1310\n",
      "[1324/1600] D loss: 0.2797, G loss: 2.3183\n",
      "[1444/1600] D loss: 0.1734, G loss: 2.3222\n",
      "[1564/1600] D loss: 0.3312, G loss: 2.4694\n",
      "train error: \n",
      " D loss: 0.309442, G loss: 2.690435, D accuracy: 97.7%, cell accuracy: 78.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.312793, G loss: 2.725042, D accuracy: 97.5%, cell accuracy: 78.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2404, G loss: 2.2513\n",
      "[124/1600] D loss: 0.1826, G loss: 3.2336\n",
      "[244/1600] D loss: 0.2251, G loss: 2.8337\n",
      "[364/1600] D loss: 0.7146, G loss: 1.8105\n",
      "[484/1600] D loss: 0.1727, G loss: 2.7448\n",
      "[604/1600] D loss: 0.7015, G loss: 1.6605\n",
      "[724/1600] D loss: 0.4904, G loss: 1.8677\n",
      "[844/1600] D loss: 0.3681, G loss: 1.7666\n",
      "[964/1600] D loss: 0.2923, G loss: 2.4224\n",
      "[1084/1600] D loss: 0.2267, G loss: 3.2416\n",
      "[1204/1600] D loss: 0.5638, G loss: 2.1617\n",
      "[1324/1600] D loss: 0.4583, G loss: 3.5715\n",
      "[1444/1600] D loss: 0.3492, G loss: 2.3258\n",
      "[1564/1600] D loss: 0.2486, G loss: 2.7960\n",
      "train error: \n",
      " D loss: 0.513797, G loss: 1.779875, D accuracy: 85.8%, cell accuracy: 79.4%, board accuracy: 0.0% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\tetris-emulator\\metrics.py:237: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return self.num_true_positives / self.num_spawns_pred\n",
      "c:\\Projects\\tetris-emulator\\metrics.py:288: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return self.num_valid_spawns_pred / self.num_spawns_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error: \n",
      " D loss: 0.503772, G loss: 1.826886, D accuracy: 86.8%, cell accuracy: 78.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4169, G loss: 2.0441\n",
      "[124/1600] D loss: 0.5944, G loss: 1.3006\n",
      "[244/1600] D loss: 0.2702, G loss: 2.7413\n",
      "[364/1600] D loss: 0.2295, G loss: 3.3201\n",
      "[484/1600] D loss: 0.4416, G loss: 3.4798\n",
      "[604/1600] D loss: 0.0875, G loss: 3.7927\n",
      "[724/1600] D loss: 0.1723, G loss: 3.0431\n",
      "[844/1600] D loss: 0.3896, G loss: 3.4993\n",
      "[964/1600] D loss: 0.6520, G loss: 4.7088\n",
      "[1084/1600] D loss: 0.6890, G loss: 2.0021\n",
      "[1204/1600] D loss: 0.2331, G loss: 4.0583\n",
      "[1324/1600] D loss: 0.3864, G loss: 3.0265\n",
      "[1444/1600] D loss: 0.8070, G loss: 2.3006\n",
      "[1564/1600] D loss: 0.9709, G loss: 2.5059\n",
      "train error: \n",
      " D loss: 0.232015, G loss: 3.523158, D accuracy: 96.8%, cell accuracy: 79.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.258691, G loss: 3.570450, D accuracy: 95.6%, cell accuracy: 79.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2113, G loss: 2.6741\n",
      "[124/1600] D loss: 0.2560, G loss: 4.0880\n",
      "[244/1600] D loss: 0.1521, G loss: 3.2653\n",
      "[364/1600] D loss: 0.1849, G loss: 2.7928\n",
      "[484/1600] D loss: 0.0656, G loss: 6.6014\n",
      "[604/1600] D loss: 0.3128, G loss: 2.1677\n",
      "[724/1600] D loss: 0.0448, G loss: 5.4593\n",
      "[844/1600] D loss: 0.2003, G loss: 2.9704\n",
      "[964/1600] D loss: 0.3039, G loss: 3.4884\n",
      "[1084/1600] D loss: 0.4290, G loss: 2.6597\n",
      "[1204/1600] D loss: 0.0397, G loss: 6.6078\n",
      "[1324/1600] D loss: 0.4778, G loss: 5.6294\n",
      "[1444/1600] D loss: 0.4691, G loss: 2.4369\n",
      "[1564/1600] D loss: 0.1480, G loss: 3.6431\n",
      "train error: \n",
      " D loss: 0.202745, G loss: 3.330040, D accuracy: 97.8%, cell accuracy: 81.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.225726, G loss: 3.388050, D accuracy: 96.9%, cell accuracy: 81.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2743, G loss: 2.6389\n",
      "[124/1600] D loss: 0.0897, G loss: 3.0722\n",
      "[244/1600] D loss: 0.1436, G loss: 3.7777\n",
      "[364/1600] D loss: 0.2649, G loss: 4.7823\n",
      "[484/1600] D loss: 0.1730, G loss: 3.5850\n",
      "[604/1600] D loss: 0.1364, G loss: 3.2771\n",
      "[724/1600] D loss: 0.1854, G loss: 2.9750\n",
      "[844/1600] D loss: 0.3223, G loss: 2.3253\n",
      "[964/1600] D loss: 0.0726, G loss: 5.8078\n",
      "[1084/1600] D loss: 0.0242, G loss: 5.4117\n",
      "[1204/1600] D loss: 0.0214, G loss: 4.9357\n",
      "[1324/1600] D loss: 0.7386, G loss: 3.1846\n",
      "[1444/1600] D loss: 0.0007, G loss: 8.4197\n",
      "[1564/1600] D loss: 0.2688, G loss: 3.2354\n",
      "train error: \n",
      " D loss: 0.185132, G loss: 4.215623, D accuracy: 97.5%, cell accuracy: 82.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.213006, G loss: 4.274523, D accuracy: 97.1%, cell accuracy: 82.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4945, G loss: 4.2058\n",
      "[124/1600] D loss: 0.3502, G loss: 3.0831\n",
      "[244/1600] D loss: 0.0197, G loss: 6.5981\n",
      "[364/1600] D loss: 0.0033, G loss: 7.9506\n",
      "[484/1600] D loss: 0.3112, G loss: 2.0841\n",
      "[604/1600] D loss: 0.1426, G loss: 4.6743\n",
      "[724/1600] D loss: 0.0883, G loss: 4.1872\n",
      "[844/1600] D loss: 0.1142, G loss: 6.0423\n",
      "[964/1600] D loss: 0.2362, G loss: 2.0904\n",
      "[1084/1600] D loss: 0.0991, G loss: 4.1865\n",
      "[1204/1600] D loss: 0.4505, G loss: 4.1763\n",
      "[1324/1600] D loss: 0.1866, G loss: 3.3716\n",
      "[1444/1600] D loss: 1.6892, G loss: 4.5619\n",
      "[1564/1600] D loss: 0.0364, G loss: 5.4617\n",
      "train error: \n",
      " D loss: 0.176632, G loss: 4.616698, D accuracy: 97.8%, cell accuracy: 82.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.205145, G loss: 4.723529, D accuracy: 96.9%, cell accuracy: 82.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1122, G loss: 4.4286\n",
      "[124/1600] D loss: 0.4251, G loss: 3.0295\n",
      "[244/1600] D loss: 0.0647, G loss: 5.7109\n",
      "[364/1600] D loss: 0.1495, G loss: 3.2860\n",
      "[484/1600] D loss: 0.0173, G loss: 5.7275\n",
      "[604/1600] D loss: 0.0360, G loss: 5.2646\n",
      "[724/1600] D loss: 0.5125, G loss: 2.0591\n",
      "[844/1600] D loss: 0.1049, G loss: 2.8664\n",
      "[964/1600] D loss: 0.0019, G loss: 7.3053\n",
      "[1084/1600] D loss: 0.5988, G loss: 4.0445\n",
      "[1204/1600] D loss: 0.0191, G loss: 6.9866\n",
      "[1324/1600] D loss: 0.1767, G loss: 2.8872\n",
      "[1444/1600] D loss: 0.0736, G loss: 6.0807\n",
      "[1564/1600] D loss: 0.0962, G loss: 3.7732\n",
      "train error: \n",
      " D loss: 0.361266, G loss: 4.343340, D accuracy: 93.8%, cell accuracy: 80.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.412757, G loss: 4.478267, D accuracy: 93.1%, cell accuracy: 79.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6629, G loss: 6.6044\n",
      "[124/1600] D loss: 0.7718, G loss: 1.1883\n",
      "[244/1600] D loss: 0.0635, G loss: 6.8057\n",
      "[364/1600] D loss: 0.0236, G loss: 4.8935\n",
      "[484/1600] D loss: 0.5690, G loss: 5.8066\n",
      "[604/1600] D loss: 0.4216, G loss: 2.3679\n",
      "[724/1600] D loss: 0.0566, G loss: 4.9529\n",
      "[844/1600] D loss: 0.0245, G loss: 6.4810\n",
      "[964/1600] D loss: 0.4134, G loss: 3.0188\n",
      "[1084/1600] D loss: 0.9581, G loss: 2.6206\n",
      "[1204/1600] D loss: 0.0015, G loss: 7.1497\n",
      "[1324/1600] D loss: 0.0005, G loss: 8.3641\n",
      "[1444/1600] D loss: 0.0712, G loss: 5.6846\n",
      "[1564/1600] D loss: 0.4607, G loss: 3.8169\n",
      "train error: \n",
      " D loss: 0.133146, G loss: 4.851839, D accuracy: 98.1%, cell accuracy: 81.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.174034, G loss: 4.948860, D accuracy: 97.5%, cell accuracy: 81.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1659, G loss: 3.3186\n",
      "[124/1600] D loss: 0.0392, G loss: 4.7540\n",
      "[244/1600] D loss: 0.0353, G loss: 6.2863\n",
      "[364/1600] D loss: 0.3799, G loss: 3.1510\n",
      "[484/1600] D loss: 0.0228, G loss: 6.0140\n",
      "[604/1600] D loss: 0.1293, G loss: 3.4691\n",
      "[724/1600] D loss: 0.0280, G loss: 4.9312\n",
      "[844/1600] D loss: 0.1075, G loss: 3.8094\n",
      "[964/1600] D loss: 0.0539, G loss: 3.8024\n",
      "[1084/1600] D loss: 0.0224, G loss: 4.3894\n",
      "[1204/1600] D loss: 0.1346, G loss: 4.0922\n",
      "[1324/1600] D loss: 0.1110, G loss: 4.0744\n",
      "[1444/1600] D loss: 0.1654, G loss: 4.9387\n",
      "[1564/1600] D loss: 0.1127, G loss: 4.8223\n",
      "train error: \n",
      " D loss: 0.168917, G loss: 4.433658, D accuracy: 97.7%, cell accuracy: 83.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.208898, G loss: 4.483903, D accuracy: 96.6%, cell accuracy: 83.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0847, G loss: 4.5209\n",
      "[124/1600] D loss: 0.2770, G loss: 3.9701\n",
      "[244/1600] D loss: 0.2094, G loss: 3.5003\n",
      "[364/1600] D loss: 0.1413, G loss: 4.2294\n",
      "[484/1600] D loss: 0.0417, G loss: 5.4793\n",
      "[604/1600] D loss: 0.0054, G loss: 5.8687\n",
      "[724/1600] D loss: 0.0817, G loss: 3.0607\n",
      "[844/1600] D loss: 0.2737, G loss: 4.8907\n",
      "[964/1600] D loss: 0.0637, G loss: 4.4379\n",
      "[1084/1600] D loss: 0.1028, G loss: 4.0535\n",
      "[1204/1600] D loss: 0.0643, G loss: 4.6295\n",
      "[1324/1600] D loss: 0.3156, G loss: 2.4178\n",
      "[1444/1600] D loss: 0.3396, G loss: 2.7569\n",
      "[1564/1600] D loss: 1.0263, G loss: 1.0474\n",
      "train error: \n",
      " D loss: 0.252062, G loss: 2.971677, D accuracy: 96.8%, cell accuracy: 84.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.310418, G loss: 3.070193, D accuracy: 95.6%, cell accuracy: 83.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0233, G loss: 4.0472\n",
      "[124/1600] D loss: 0.0359, G loss: 4.6451\n",
      "[244/1600] D loss: 0.0578, G loss: 4.5100\n",
      "[364/1600] D loss: 0.0931, G loss: 5.9742\n",
      "[484/1600] D loss: 0.2508, G loss: 3.9134\n",
      "[604/1600] D loss: 0.0398, G loss: 4.0153\n",
      "[724/1600] D loss: 0.0288, G loss: 5.3229\n",
      "[844/1600] D loss: 0.2867, G loss: 2.7368\n",
      "[964/1600] D loss: 0.1205, G loss: 3.0494\n",
      "[1084/1600] D loss: 0.2387, G loss: 2.3502\n",
      "[1204/1600] D loss: 0.0084, G loss: 6.0837\n",
      "[1324/1600] D loss: 0.4029, G loss: 3.4798\n",
      "[1444/1600] D loss: 0.3405, G loss: 1.9448\n",
      "[1564/1600] D loss: 0.7007, G loss: 3.6778\n",
      "train error: \n",
      " D loss: 0.215728, G loss: 3.035692, D accuracy: 96.8%, cell accuracy: 85.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.283351, G loss: 3.162616, D accuracy: 95.8%, cell accuracy: 84.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1617, G loss: 2.3304\n",
      "[124/1600] D loss: 0.2025, G loss: 3.3568\n",
      "[244/1600] D loss: 0.0416, G loss: 4.1112\n",
      "[364/1600] D loss: 0.1492, G loss: 2.8515\n",
      "[484/1600] D loss: 0.6350, G loss: 4.4991\n",
      "[604/1600] D loss: 0.0058, G loss: 5.9406\n",
      "[724/1600] D loss: 0.1642, G loss: 3.7375\n",
      "[844/1600] D loss: 0.1266, G loss: 2.7098\n",
      "[964/1600] D loss: 0.1956, G loss: 3.6143\n",
      "[1084/1600] D loss: 0.0946, G loss: 3.8484\n",
      "[1204/1600] D loss: 0.1050, G loss: 5.4456\n",
      "[1324/1600] D loss: 0.0592, G loss: 6.7213\n",
      "[1444/1600] D loss: 0.0963, G loss: 2.8953\n",
      "[1564/1600] D loss: 0.3061, G loss: 4.7992\n",
      "train error: \n",
      " D loss: 0.252605, G loss: 3.025528, D accuracy: 95.4%, cell accuracy: 85.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.311824, G loss: 3.126509, D accuracy: 95.2%, cell accuracy: 85.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2159, G loss: 2.9819\n",
      "[124/1600] D loss: 0.1322, G loss: 5.4137\n",
      "[244/1600] D loss: 0.3593, G loss: 3.3663\n",
      "[364/1600] D loss: 0.6017, G loss: 2.7587\n",
      "[484/1600] D loss: 0.0247, G loss: 5.3974\n",
      "[604/1600] D loss: 0.0363, G loss: 5.7067\n",
      "[724/1600] D loss: 0.0671, G loss: 3.1131\n",
      "[844/1600] D loss: 0.0830, G loss: 3.7149\n",
      "[964/1600] D loss: 0.2552, G loss: 3.1000\n",
      "[1084/1600] D loss: 0.6506, G loss: 3.6470\n",
      "[1204/1600] D loss: 0.1047, G loss: 4.3949\n",
      "[1324/1600] D loss: 0.2080, G loss: 5.0692\n",
      "[1444/1600] D loss: 0.0385, G loss: 4.3229\n",
      "[1564/1600] D loss: 0.0351, G loss: 4.6489\n",
      "train error: \n",
      " D loss: 0.188940, G loss: 4.005217, D accuracy: 97.4%, cell accuracy: 86.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.255786, G loss: 4.164169, D accuracy: 96.5%, cell accuracy: 85.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1384, G loss: 4.5251\n",
      "[124/1600] D loss: 0.7704, G loss: 1.4230\n",
      "[244/1600] D loss: 0.0548, G loss: 4.1763\n",
      "[364/1600] D loss: 0.1252, G loss: 4.6532\n",
      "[484/1600] D loss: 0.0392, G loss: 5.4509\n",
      "[604/1600] D loss: 0.0517, G loss: 4.8065\n",
      "[724/1600] D loss: 0.0345, G loss: 4.6717\n",
      "[844/1600] D loss: 0.1189, G loss: 2.5748\n",
      "[964/1600] D loss: 0.1381, G loss: 4.5259\n",
      "[1084/1600] D loss: 0.0939, G loss: 3.3207\n",
      "[1204/1600] D loss: 0.0416, G loss: 5.1327\n",
      "[1324/1600] D loss: 0.0998, G loss: 5.0519\n",
      "[1444/1600] D loss: 0.1188, G loss: 3.4838\n",
      "[1564/1600] D loss: 0.0397, G loss: 4.9105\n",
      "train error: \n",
      " D loss: 0.195015, G loss: 4.329489, D accuracy: 97.2%, cell accuracy: 86.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.264246, G loss: 4.476557, D accuracy: 96.8%, cell accuracy: 85.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3726, G loss: 3.4421\n",
      "[124/1600] D loss: 0.8703, G loss: 2.3585\n",
      "[244/1600] D loss: 0.3177, G loss: 3.2203\n",
      "[364/1600] D loss: 0.5440, G loss: 3.2294\n",
      "[484/1600] D loss: 0.0191, G loss: 5.9107\n",
      "[604/1600] D loss: 0.6418, G loss: 4.6319\n",
      "[724/1600] D loss: 0.2237, G loss: 4.3310\n",
      "[844/1600] D loss: 0.1358, G loss: 4.7245\n",
      "[964/1600] D loss: 0.2712, G loss: 3.0146\n",
      "[1084/1600] D loss: 0.3200, G loss: 4.4058\n",
      "[1204/1600] D loss: 0.0582, G loss: 5.6176\n",
      "[1324/1600] D loss: 0.4634, G loss: 3.9248\n",
      "[1444/1600] D loss: 0.4248, G loss: 3.1374\n",
      "[1564/1600] D loss: 0.2382, G loss: 4.7037\n",
      "train error: \n",
      " D loss: 0.389269, G loss: 3.138429, D accuracy: 91.5%, cell accuracy: 86.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.501968, G loss: 3.254299, D accuracy: 90.5%, cell accuracy: 86.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3743, G loss: 2.1972\n",
      "[124/1600] D loss: 1.4186, G loss: 5.3524\n",
      "[244/1600] D loss: 0.6968, G loss: 2.1517\n",
      "[364/1600] D loss: 0.4376, G loss: 1.4941\n",
      "[484/1600] D loss: 1.3606, G loss: 1.3967\n",
      "[604/1600] D loss: 0.2642, G loss: 2.7756\n",
      "[724/1600] D loss: 0.5459, G loss: 3.4211\n",
      "[844/1600] D loss: 0.1120, G loss: 3.0252\n",
      "[964/1600] D loss: 1.0315, G loss: 4.4742\n",
      "[1084/1600] D loss: 0.2440, G loss: 4.4987\n",
      "[1204/1600] D loss: 0.2656, G loss: 4.3945\n",
      "[1324/1600] D loss: 0.8070, G loss: 2.7621\n",
      "[1444/1600] D loss: 0.5003, G loss: 2.5430\n",
      "[1564/1600] D loss: 1.2419, G loss: 3.2475\n",
      "train error: \n",
      " D loss: 0.434399, G loss: 3.741157, D accuracy: 91.6%, cell accuracy: 85.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.510275, G loss: 3.935249, D accuracy: 90.9%, cell accuracy: 85.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1987, G loss: 5.5415\n",
      "[124/1600] D loss: 0.6468, G loss: 3.1210\n",
      "[244/1600] D loss: 0.0801, G loss: 4.4935\n",
      "[364/1600] D loss: 0.0310, G loss: 4.4843\n",
      "[484/1600] D loss: 0.1019, G loss: 3.4334\n",
      "[604/1600] D loss: 0.4089, G loss: 2.9625\n",
      "[724/1600] D loss: 0.4066, G loss: 2.3564\n",
      "[844/1600] D loss: 1.4997, G loss: 4.9224\n",
      "[964/1600] D loss: 0.2362, G loss: 4.7391\n",
      "[1084/1600] D loss: 0.7825, G loss: 5.0139\n",
      "[1204/1600] D loss: 0.0622, G loss: 4.1021\n",
      "[1324/1600] D loss: 1.2477, G loss: 5.2827\n",
      "[1444/1600] D loss: 0.1646, G loss: 4.0188\n",
      "[1564/1600] D loss: 0.8143, G loss: 2.1632\n",
      "train error: \n",
      " D loss: 0.311722, G loss: 3.064169, D accuracy: 94.3%, cell accuracy: 87.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.356766, G loss: 3.175332, D accuracy: 94.4%, cell accuracy: 86.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3164, G loss: 2.7824\n",
      "[124/1600] D loss: 0.1006, G loss: 3.3326\n",
      "[244/1600] D loss: 0.4360, G loss: 1.9786\n",
      "[364/1600] D loss: 0.1281, G loss: 4.6627\n",
      "[484/1600] D loss: 0.3936, G loss: 2.3036\n",
      "[604/1600] D loss: 0.1393, G loss: 4.7361\n",
      "[724/1600] D loss: 0.4138, G loss: 4.4404\n",
      "[844/1600] D loss: 0.2756, G loss: 3.7736\n",
      "[964/1600] D loss: 0.2220, G loss: 2.5619\n",
      "[1084/1600] D loss: 0.9083, G loss: 0.9006\n",
      "[1204/1600] D loss: 0.2240, G loss: 3.5470\n",
      "[1324/1600] D loss: 0.1316, G loss: 3.7802\n",
      "[1444/1600] D loss: 1.0053, G loss: 3.7692\n",
      "[1564/1600] D loss: 0.4732, G loss: 4.5022\n",
      "train error: \n",
      " D loss: 0.438356, G loss: 2.386381, D accuracy: 90.1%, cell accuracy: 88.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.478907, G loss: 2.527029, D accuracy: 90.8%, cell accuracy: 88.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5121, G loss: 2.6690\n",
      "[124/1600] D loss: 0.0377, G loss: 4.8606\n",
      "[244/1600] D loss: 0.0557, G loss: 4.2383\n",
      "[364/1600] D loss: 1.1504, G loss: 3.7290\n",
      "[484/1600] D loss: 0.0342, G loss: 4.0569\n",
      "[604/1600] D loss: 0.7460, G loss: 2.0153\n",
      "[724/1600] D loss: 0.0610, G loss: 3.6286\n",
      "[844/1600] D loss: 2.0553, G loss: 4.6042\n",
      "[964/1600] D loss: 0.1404, G loss: 2.9765\n",
      "[1084/1600] D loss: 0.3873, G loss: 2.7211\n",
      "[1204/1600] D loss: 0.1777, G loss: 2.5822\n",
      "[1324/1600] D loss: 0.8660, G loss: 2.6242\n",
      "[1444/1600] D loss: 0.8649, G loss: 2.7437\n",
      "[1564/1600] D loss: 0.3473, G loss: 2.2019\n",
      "train error: \n",
      " D loss: 0.395827, G loss: 2.829366, D accuracy: 94.8%, cell accuracy: 90.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.457863, G loss: 2.918855, D accuracy: 92.9%, cell accuracy: 90.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1971, G loss: 3.0429\n",
      "[124/1600] D loss: 0.2126, G loss: 2.8759\n",
      "[244/1600] D loss: 0.6497, G loss: 1.5295\n",
      "[364/1600] D loss: 0.4496, G loss: 3.4207\n",
      "[484/1600] D loss: 0.1541, G loss: 3.3145\n",
      "[604/1600] D loss: 0.1913, G loss: 3.3404\n",
      "[724/1600] D loss: 0.3461, G loss: 3.2532\n",
      "[844/1600] D loss: 0.3887, G loss: 2.1583\n",
      "[964/1600] D loss: 0.2818, G loss: 2.7188\n",
      "[1084/1600] D loss: 0.1367, G loss: 3.8161\n",
      "[1204/1600] D loss: 0.1264, G loss: 3.8901\n",
      "[1324/1600] D loss: 0.3426, G loss: 2.2543\n",
      "[1444/1600] D loss: 0.0548, G loss: 5.0376\n",
      "[1564/1600] D loss: 0.2579, G loss: 2.2989\n",
      "train error: \n",
      " D loss: 0.522004, G loss: 2.335299, D accuracy: 90.6%, cell accuracy: 91.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.579439, G loss: 2.409118, D accuracy: 89.9%, cell accuracy: 90.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4341, G loss: 2.3606\n",
      "[124/1600] D loss: 0.4292, G loss: 2.0997\n",
      "[244/1600] D loss: 0.1167, G loss: 4.1075\n",
      "[364/1600] D loss: 0.1979, G loss: 3.0446\n",
      "[484/1600] D loss: 0.6445, G loss: 1.6504\n",
      "[604/1600] D loss: 0.4087, G loss: 2.4969\n",
      "[724/1600] D loss: 0.4320, G loss: 1.9414\n",
      "[844/1600] D loss: 1.6508, G loss: 2.6152\n",
      "[964/1600] D loss: 1.1457, G loss: 1.6854\n",
      "[1084/1600] D loss: 0.6417, G loss: 2.1534\n",
      "[1204/1600] D loss: 0.1131, G loss: 2.8639\n",
      "[1324/1600] D loss: 0.3486, G loss: 2.3484\n",
      "[1444/1600] D loss: 0.1604, G loss: 3.4503\n",
      "[1564/1600] D loss: 0.7250, G loss: 2.9085\n",
      "train error: \n",
      " D loss: 0.576154, G loss: 2.337957, D accuracy: 89.5%, cell accuracy: 91.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.617481, G loss: 2.397174, D accuracy: 89.6%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6041, G loss: 2.0041\n",
      "[124/1600] D loss: 0.2312, G loss: 3.3605\n",
      "[244/1600] D loss: 0.8638, G loss: 2.2995\n",
      "[364/1600] D loss: 0.9403, G loss: 1.5469\n",
      "[484/1600] D loss: 0.2222, G loss: 2.7229\n",
      "[604/1600] D loss: 1.1166, G loss: 2.3706\n",
      "[724/1600] D loss: 0.7692, G loss: 3.0566\n",
      "[844/1600] D loss: 0.2155, G loss: 3.3255\n",
      "[964/1600] D loss: 0.3067, G loss: 2.1928\n",
      "[1084/1600] D loss: 0.2745, G loss: 3.0260\n",
      "[1204/1600] D loss: 1.3876, G loss: 0.7093\n",
      "[1324/1600] D loss: 0.4805, G loss: 1.6726\n",
      "[1444/1600] D loss: 0.5787, G loss: 2.1198\n",
      "[1564/1600] D loss: 0.4276, G loss: 2.0333\n",
      "train error: \n",
      " D loss: 0.623705, G loss: 2.165958, D accuracy: 88.6%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.670973, G loss: 2.223964, D accuracy: 88.9%, cell accuracy: 92.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5048, G loss: 2.0745\n",
      "[124/1600] D loss: 1.4093, G loss: 0.8874\n",
      "[244/1600] D loss: 0.4408, G loss: 2.7750\n",
      "[364/1600] D loss: 0.3988, G loss: 2.1940\n",
      "[484/1600] D loss: 0.6408, G loss: 1.3559\n",
      "[604/1600] D loss: 0.6704, G loss: 1.8013\n",
      "[724/1600] D loss: 0.0478, G loss: 3.7565\n",
      "[844/1600] D loss: 0.2014, G loss: 2.5003\n",
      "[964/1600] D loss: 0.5600, G loss: 1.5750\n",
      "[1084/1600] D loss: 0.9172, G loss: 1.8077\n",
      "[1204/1600] D loss: 1.1991, G loss: 2.5114\n",
      "[1324/1600] D loss: 0.6261, G loss: 1.1569\n",
      "[1444/1600] D loss: 1.7132, G loss: 1.0159\n",
      "[1564/1600] D loss: 0.4327, G loss: 2.7330\n",
      "train error: \n",
      " D loss: 0.799154, G loss: 1.664918, D accuracy: 81.8%, cell accuracy: 93.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.833286, G loss: 1.744537, D accuracy: 83.1%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1753, G loss: 3.7206\n",
      "[124/1600] D loss: 0.2854, G loss: 2.1127\n",
      "[244/1600] D loss: 0.9049, G loss: 1.5313\n",
      "[364/1600] D loss: 0.3997, G loss: 1.8434\n",
      "[484/1600] D loss: 0.5531, G loss: 2.2592\n",
      "[604/1600] D loss: 0.4344, G loss: 2.3038\n",
      "[724/1600] D loss: 0.4443, G loss: 2.0257\n",
      "[844/1600] D loss: 1.3962, G loss: 1.1693\n",
      "[964/1600] D loss: 0.5098, G loss: 2.2374\n",
      "[1084/1600] D loss: 0.3635, G loss: 2.0753\n",
      "[1204/1600] D loss: 1.6802, G loss: 3.3287\n",
      "[1324/1600] D loss: 0.5502, G loss: 1.5320\n",
      "[1444/1600] D loss: 0.5374, G loss: 2.0184\n",
      "[1564/1600] D loss: 1.1270, G loss: 1.0588\n",
      "train error: \n",
      " D loss: 0.849905, G loss: 2.129950, D accuracy: 80.9%, cell accuracy: 93.6%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.887050, G loss: 2.198355, D accuracy: 80.5%, cell accuracy: 93.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0229, G loss: 1.5060\n",
      "[124/1600] D loss: 0.5866, G loss: 2.4174\n",
      "[244/1600] D loss: 1.0140, G loss: 1.2853\n",
      "[364/1600] D loss: 0.5867, G loss: 2.5203\n",
      "[484/1600] D loss: 0.7087, G loss: 2.2625\n",
      "[604/1600] D loss: 0.1362, G loss: 3.8027\n",
      "[724/1600] D loss: 0.6142, G loss: 1.5673\n",
      "[844/1600] D loss: 1.0867, G loss: 1.4240\n",
      "[964/1600] D loss: 0.4076, G loss: 2.3852\n",
      "[1084/1600] D loss: 0.7664, G loss: 1.9078\n",
      "[1204/1600] D loss: 2.0125, G loss: 0.8882\n",
      "[1324/1600] D loss: 0.6148, G loss: 1.5320\n",
      "[1444/1600] D loss: 1.2676, G loss: 1.6025\n",
      "[1564/1600] D loss: 0.5189, G loss: 1.4431\n",
      "train error: \n",
      " D loss: 0.910012, G loss: 1.663428, D accuracy: 79.3%, cell accuracy: 94.0%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.935763, G loss: 1.735182, D accuracy: 78.2%, cell accuracy: 93.6%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4031, G loss: 2.8533\n",
      "[124/1600] D loss: 0.8030, G loss: 1.5362\n",
      "[244/1600] D loss: 0.7616, G loss: 1.4867\n",
      "[364/1600] D loss: 0.7729, G loss: 1.6191\n",
      "[484/1600] D loss: 0.8093, G loss: 1.8278\n",
      "[604/1600] D loss: 0.6105, G loss: 1.8535\n",
      "[724/1600] D loss: 0.7510, G loss: 1.2734\n",
      "[844/1600] D loss: 0.8658, G loss: 0.8839\n",
      "[964/1600] D loss: 0.7780, G loss: 2.0824\n",
      "[1084/1600] D loss: 1.2907, G loss: 1.5027\n",
      "[1204/1600] D loss: 0.8686, G loss: 1.5454\n",
      "[1324/1600] D loss: 0.7110, G loss: 1.6057\n",
      "[1444/1600] D loss: 1.2853, G loss: 0.7973\n",
      "[1564/1600] D loss: 0.5841, G loss: 1.9190\n",
      "train error: \n",
      " D loss: 1.081207, G loss: 1.638454, D accuracy: 71.8%, cell accuracy: 93.7%, board accuracy: 1.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.089691, G loss: 1.703807, D accuracy: 72.1%, cell accuracy: 93.4%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9638, G loss: 2.1885\n",
      "[124/1600] D loss: 0.6593, G loss: 1.7728\n",
      "[244/1600] D loss: 1.2307, G loss: 0.6541\n",
      "[364/1600] D loss: 0.9192, G loss: 1.1238\n",
      "[484/1600] D loss: 0.9157, G loss: 1.9082\n",
      "[604/1600] D loss: 0.3060, G loss: 2.0850\n",
      "[724/1600] D loss: 1.1064, G loss: 1.6611\n",
      "[844/1600] D loss: 1.9931, G loss: 0.8701\n",
      "[964/1600] D loss: 0.6995, G loss: 1.6102\n",
      "[1084/1600] D loss: 0.9765, G loss: 2.4761\n",
      "[1204/1600] D loss: 1.1720, G loss: 0.9643\n",
      "[1324/1600] D loss: 0.8697, G loss: 1.1214\n",
      "[1444/1600] D loss: 0.4312, G loss: 1.7578\n",
      "[1564/1600] D loss: 1.5923, G loss: 0.9925\n",
      "train error: \n",
      " D loss: 0.986993, G loss: 1.348359, D accuracy: 74.0%, cell accuracy: 94.1%, board accuracy: 1.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.010832, G loss: 1.415392, D accuracy: 75.4%, cell accuracy: 93.8%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2536, G loss: 0.5897\n",
      "[124/1600] D loss: 0.9833, G loss: 0.7854\n",
      "[244/1600] D loss: 0.8248, G loss: 1.3703\n",
      "[364/1600] D loss: 0.4311, G loss: 2.8229\n",
      "[484/1600] D loss: 0.5680, G loss: 1.3541\n",
      "[604/1600] D loss: 0.7443, G loss: 1.4140\n",
      "[724/1600] D loss: 1.3280, G loss: 0.5561\n",
      "[844/1600] D loss: 2.1839, G loss: 1.0349\n",
      "[964/1600] D loss: 1.0789, G loss: 1.1052\n",
      "[1084/1600] D loss: 1.1109, G loss: 0.9679\n",
      "[1204/1600] D loss: 0.6896, G loss: 1.6708\n",
      "[1324/1600] D loss: 0.7887, G loss: 1.3385\n",
      "[1444/1600] D loss: 1.5690, G loss: 0.7494\n",
      "[1564/1600] D loss: 1.0046, G loss: 1.3432\n",
      "train error: \n",
      " D loss: 1.077560, G loss: 1.390262, D accuracy: 73.8%, cell accuracy: 95.1%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.123979, G loss: 1.439314, D accuracy: 71.5%, cell accuracy: 94.8%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9462, G loss: 1.7023\n",
      "[124/1600] D loss: 1.5193, G loss: 1.3535\n",
      "[244/1600] D loss: 0.3920, G loss: 1.6541\n",
      "[364/1600] D loss: 0.8587, G loss: 1.5579\n",
      "[484/1600] D loss: 1.6030, G loss: 1.2583\n",
      "[604/1600] D loss: 0.8996, G loss: 1.3550\n",
      "[724/1600] D loss: 1.0510, G loss: 1.3298\n",
      "[844/1600] D loss: 0.7522, G loss: 1.5818\n",
      "[964/1600] D loss: 1.0417, G loss: 0.7278\n",
      "[1084/1600] D loss: 0.8594, G loss: 0.9583\n",
      "[1204/1600] D loss: 1.1155, G loss: 1.4107\n",
      "[1324/1600] D loss: 0.4441, G loss: 1.3320\n",
      "[1444/1600] D loss: 0.8540, G loss: 1.3806\n",
      "[1564/1600] D loss: 0.6419, G loss: 1.0864\n",
      "train error: \n",
      " D loss: 1.110826, G loss: 1.003833, D accuracy: 70.8%, cell accuracy: 95.5%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.156167, G loss: 1.030129, D accuracy: 69.6%, cell accuracy: 95.2%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5761, G loss: 1.6553\n",
      "[124/1600] D loss: 1.1032, G loss: 0.5895\n",
      "[244/1600] D loss: 1.1895, G loss: 0.8069\n",
      "[364/1600] D loss: 0.6625, G loss: 1.0038\n",
      "[484/1600] D loss: 1.1710, G loss: 1.0926\n",
      "[604/1600] D loss: 1.1656, G loss: 0.8217\n",
      "[724/1600] D loss: 1.2483, G loss: 1.0892\n",
      "[844/1600] D loss: 0.9022, G loss: 1.1175\n",
      "[964/1600] D loss: 0.9180, G loss: 0.9959\n",
      "[1084/1600] D loss: 1.2834, G loss: 1.1763\n",
      "[1204/1600] D loss: 2.0265, G loss: 1.1637\n",
      "[1324/1600] D loss: 0.9231, G loss: 1.7980\n",
      "[1444/1600] D loss: 1.0658, G loss: 1.0168\n",
      "[1564/1600] D loss: 0.7758, G loss: 1.4122\n",
      "train error: \n",
      " D loss: 1.206531, G loss: 0.825427, D accuracy: 66.5%, cell accuracy: 95.7%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258010, G loss: 0.831790, D accuracy: 65.4%, cell accuracy: 95.5%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6951, G loss: 0.4377\n",
      "[124/1600] D loss: 1.6604, G loss: 1.3733\n",
      "[244/1600] D loss: 2.0015, G loss: 1.3616\n",
      "[364/1600] D loss: 0.7616, G loss: 1.3362\n",
      "[484/1600] D loss: 1.1283, G loss: 0.5897\n",
      "[604/1600] D loss: 1.3009, G loss: 0.9871\n",
      "[724/1600] D loss: 1.3795, G loss: 1.0815\n",
      "[844/1600] D loss: 1.9630, G loss: 1.3344\n",
      "[964/1600] D loss: 1.3453, G loss: 1.2637\n",
      "[1084/1600] D loss: 0.9911, G loss: 1.0446\n",
      "[1204/1600] D loss: 1.2313, G loss: 0.7278\n",
      "[1324/1600] D loss: 0.8615, G loss: 1.1702\n",
      "[1444/1600] D loss: 1.3463, G loss: 1.0463\n",
      "[1564/1600] D loss: 1.9537, G loss: 0.9264\n",
      "train error: \n",
      " D loss: 1.179026, G loss: 1.349102, D accuracy: 70.0%, cell accuracy: 95.9%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.220163, G loss: 1.360102, D accuracy: 68.8%, cell accuracy: 95.6%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8225, G loss: 1.1982\n",
      "[124/1600] D loss: 1.2147, G loss: 1.4143\n",
      "[244/1600] D loss: 1.2971, G loss: 0.9449\n",
      "[364/1600] D loss: 1.2309, G loss: 0.9756\n",
      "[484/1600] D loss: 1.1780, G loss: 0.6907\n",
      "[604/1600] D loss: 1.2363, G loss: 0.9253\n",
      "[724/1600] D loss: 1.0857, G loss: 0.8668\n",
      "[844/1600] D loss: 0.7895, G loss: 1.3980\n",
      "[964/1600] D loss: 1.3445, G loss: 0.8512\n",
      "[1084/1600] D loss: 0.9562, G loss: 1.2314\n",
      "[1204/1600] D loss: 1.0163, G loss: 1.5919\n",
      "[1324/1600] D loss: 0.9396, G loss: 1.4865\n",
      "[1444/1600] D loss: 1.0111, G loss: 1.0983\n",
      "[1564/1600] D loss: 1.0377, G loss: 1.1378\n",
      "train error: \n",
      " D loss: 1.246926, G loss: 0.701779, D accuracy: 63.3%, cell accuracy: 95.9%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316843, G loss: 0.683134, D accuracy: 62.3%, cell accuracy: 95.7%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6100, G loss: 0.9906\n",
      "[124/1600] D loss: 1.3763, G loss: 0.6169\n",
      "[244/1600] D loss: 1.7184, G loss: 0.7800\n",
      "[364/1600] D loss: 1.2990, G loss: 0.6545\n",
      "[484/1600] D loss: 1.2022, G loss: 1.3368\n",
      "[604/1600] D loss: 2.0080, G loss: 0.7772\n",
      "[724/1600] D loss: 1.3567, G loss: 1.2933\n",
      "[844/1600] D loss: 1.2875, G loss: 0.7967\n",
      "[964/1600] D loss: 1.1662, G loss: 1.1164\n",
      "[1084/1600] D loss: 0.6680, G loss: 1.2431\n",
      "[1204/1600] D loss: 1.0794, G loss: 0.6579\n",
      "[1324/1600] D loss: 1.3170, G loss: 0.9859\n",
      "[1444/1600] D loss: 1.4531, G loss: 1.0941\n",
      "[1564/1600] D loss: 0.8234, G loss: 1.2468\n",
      "train error: \n",
      " D loss: 1.166352, G loss: 0.966875, D accuracy: 70.2%, cell accuracy: 95.7%, board accuracy: 2.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.224583, G loss: 0.946095, D accuracy: 67.2%, cell accuracy: 95.5%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1204, G loss: 0.7744\n",
      "[124/1600] D loss: 0.9800, G loss: 2.2556\n",
      "[244/1600] D loss: 0.9409, G loss: 0.9439\n",
      "[364/1600] D loss: 0.9805, G loss: 1.2085\n",
      "[484/1600] D loss: 1.2144, G loss: 0.6377\n",
      "[604/1600] D loss: 1.1530, G loss: 0.6646\n",
      "[724/1600] D loss: 0.8979, G loss: 1.4841\n",
      "[844/1600] D loss: 1.0728, G loss: 1.0074\n",
      "[964/1600] D loss: 1.2420, G loss: 1.1163\n",
      "[1084/1600] D loss: 1.6390, G loss: 0.6700\n",
      "[1204/1600] D loss: 1.3492, G loss: 0.5621\n",
      "[1324/1600] D loss: 1.1795, G loss: 0.7535\n",
      "[1444/1600] D loss: 1.3260, G loss: 1.5866\n",
      "[1564/1600] D loss: 1.1986, G loss: 0.9610\n",
      "train error: \n",
      " D loss: 1.207232, G loss: 1.168134, D accuracy: 68.0%, cell accuracy: 96.1%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.243294, G loss: 1.186462, D accuracy: 67.0%, cell accuracy: 95.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1649, G loss: 1.1828\n",
      "[124/1600] D loss: 1.5484, G loss: 0.7552\n",
      "[244/1600] D loss: 1.1055, G loss: 0.6840\n",
      "[364/1600] D loss: 0.7954, G loss: 1.0902\n",
      "[484/1600] D loss: 1.1064, G loss: 0.9608\n",
      "[604/1600] D loss: 1.2138, G loss: 0.7882\n",
      "[724/1600] D loss: 1.5462, G loss: 1.6484\n",
      "[844/1600] D loss: 1.2813, G loss: 1.5684\n",
      "[964/1600] D loss: 1.0222, G loss: 1.0128\n",
      "[1084/1600] D loss: 0.7361, G loss: 1.3444\n",
      "[1204/1600] D loss: 0.9880, G loss: 1.1222\n",
      "[1324/1600] D loss: 1.1293, G loss: 1.2451\n",
      "[1444/1600] D loss: 1.2629, G loss: 1.1894\n",
      "[1564/1600] D loss: 1.2285, G loss: 0.6867\n",
      "train error: \n",
      " D loss: 1.228027, G loss: 0.840810, D accuracy: 65.5%, cell accuracy: 96.1%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276930, G loss: 0.845512, D accuracy: 62.4%, cell accuracy: 95.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1694, G loss: 0.8081\n",
      "[124/1600] D loss: 1.4718, G loss: 0.9008\n",
      "[244/1600] D loss: 0.9540, G loss: 1.0503\n",
      "[364/1600] D loss: 1.3553, G loss: 0.8246\n",
      "[484/1600] D loss: 1.2735, G loss: 0.9058\n",
      "[604/1600] D loss: 1.2529, G loss: 0.7943\n",
      "[724/1600] D loss: 2.0133, G loss: 0.6748\n",
      "[844/1600] D loss: 1.2974, G loss: 0.8067\n",
      "[964/1600] D loss: 1.5705, G loss: 0.7660\n",
      "[1084/1600] D loss: 1.1292, G loss: 0.9663\n",
      "[1204/1600] D loss: 1.2733, G loss: 1.3742\n",
      "[1324/1600] D loss: 1.4078, G loss: 1.1786\n",
      "[1444/1600] D loss: 1.4316, G loss: 0.9818\n",
      "[1564/1600] D loss: 1.3100, G loss: 0.6984\n",
      "train error: \n",
      " D loss: 1.389996, G loss: 0.693131, D accuracy: 54.9%, cell accuracy: 96.6%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.424559, G loss: 0.705270, D accuracy: 52.9%, cell accuracy: 96.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3943, G loss: 0.7639\n",
      "[124/1600] D loss: 1.2937, G loss: 0.7688\n",
      "[244/1600] D loss: 1.2400, G loss: 0.7193\n",
      "[364/1600] D loss: 1.4752, G loss: 0.7028\n",
      "[484/1600] D loss: 1.5570, G loss: 0.8094\n",
      "[604/1600] D loss: 1.4996, G loss: 0.6080\n",
      "[724/1600] D loss: 1.2455, G loss: 0.7056\n",
      "[844/1600] D loss: 1.1940, G loss: 0.8108\n",
      "[964/1600] D loss: 1.1019, G loss: 0.7351\n",
      "[1084/1600] D loss: 1.7064, G loss: 0.9903\n",
      "[1204/1600] D loss: 1.2608, G loss: 0.8871\n",
      "[1324/1600] D loss: 1.4519, G loss: 0.6668\n",
      "[1444/1600] D loss: 1.4640, G loss: 0.7770\n",
      "[1564/1600] D loss: 1.1820, G loss: 0.7791\n",
      "train error: \n",
      " D loss: 1.386955, G loss: 0.782940, D accuracy: 56.3%, cell accuracy: 96.9%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.419165, G loss: 0.789943, D accuracy: 57.4%, cell accuracy: 96.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9687, G loss: 0.9768\n",
      "[124/1600] D loss: 1.2410, G loss: 0.6464\n",
      "[244/1600] D loss: 1.3274, G loss: 0.9030\n",
      "[364/1600] D loss: 1.3157, G loss: 0.9162\n",
      "[484/1600] D loss: 1.2911, G loss: 0.6215\n",
      "[604/1600] D loss: 1.2723, G loss: 0.7614\n",
      "[724/1600] D loss: 1.6103, G loss: 0.6140\n",
      "[844/1600] D loss: 1.4331, G loss: 0.7997\n",
      "[964/1600] D loss: 1.3539, G loss: 0.8008\n",
      "[1084/1600] D loss: 1.3384, G loss: 0.6145\n",
      "[1204/1600] D loss: 1.3702, G loss: 0.8270\n",
      "[1324/1600] D loss: 1.6647, G loss: 0.6431\n",
      "[1444/1600] D loss: 1.4651, G loss: 0.5916\n",
      "[1564/1600] D loss: 1.4945, G loss: 0.6723\n",
      "train error: \n",
      " D loss: 1.416867, G loss: 0.660814, D accuracy: 53.4%, cell accuracy: 96.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.445681, G loss: 0.659489, D accuracy: 53.8%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3443, G loss: 0.6323\n",
      "[124/1600] D loss: 1.4359, G loss: 0.8660\n",
      "[244/1600] D loss: 1.3285, G loss: 0.8871\n",
      "[364/1600] D loss: 1.4064, G loss: 0.6757\n",
      "[484/1600] D loss: 1.3273, G loss: 0.8390\n",
      "[604/1600] D loss: 1.1741, G loss: 0.7297\n",
      "[724/1600] D loss: 1.4386, G loss: 0.6573\n",
      "[844/1600] D loss: 1.0983, G loss: 1.0823\n",
      "[964/1600] D loss: 1.4244, G loss: 0.6649\n",
      "[1084/1600] D loss: 1.3435, G loss: 0.8241\n",
      "[1204/1600] D loss: 1.2700, G loss: 0.7605\n",
      "[1324/1600] D loss: 1.1053, G loss: 0.7426\n",
      "[1444/1600] D loss: 1.3860, G loss: 0.8558\n",
      "[1564/1600] D loss: 1.3381, G loss: 0.6680\n",
      "train error: \n",
      " D loss: 1.391375, G loss: 0.736795, D accuracy: 55.7%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410913, G loss: 0.733295, D accuracy: 55.2%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4388, G loss: 0.7948\n",
      "[124/1600] D loss: 1.2703, G loss: 0.8458\n",
      "[244/1600] D loss: 1.3862, G loss: 1.1722\n",
      "[364/1600] D loss: 1.3258, G loss: 0.7519\n",
      "[484/1600] D loss: 1.8229, G loss: 0.6931\n",
      "[604/1600] D loss: 1.3559, G loss: 0.5843\n",
      "[724/1600] D loss: 1.2097, G loss: 0.7462\n",
      "[844/1600] D loss: 1.4363, G loss: 0.6997\n",
      "[964/1600] D loss: 1.2668, G loss: 0.7294\n",
      "[1084/1600] D loss: 1.2733, G loss: 0.7577\n",
      "[1204/1600] D loss: 1.4284, G loss: 0.6353\n",
      "[1324/1600] D loss: 1.3304, G loss: 0.8395\n",
      "[1444/1600] D loss: 1.3908, G loss: 0.6570\n",
      "[1564/1600] D loss: 1.3879, G loss: 0.7441\n",
      "train error: \n",
      " D loss: 1.358839, G loss: 0.774192, D accuracy: 60.3%, cell accuracy: 97.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379012, G loss: 0.774665, D accuracy: 58.8%, cell accuracy: 96.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4350, G loss: 0.6287\n",
      "[124/1600] D loss: 1.4023, G loss: 0.8510\n",
      "[244/1600] D loss: 1.3101, G loss: 0.9242\n",
      "[364/1600] D loss: 1.3875, G loss: 0.7138\n",
      "[484/1600] D loss: 1.2469, G loss: 0.8771\n",
      "[604/1600] D loss: 1.3148, G loss: 0.7748\n",
      "[724/1600] D loss: 1.4715, G loss: 0.7036\n",
      "[844/1600] D loss: 1.3840, G loss: 0.9597\n",
      "[964/1600] D loss: 1.1277, G loss: 0.9878\n",
      "[1084/1600] D loss: 1.4409, G loss: 0.7694\n",
      "[1204/1600] D loss: 1.3663, G loss: 0.6276\n",
      "[1324/1600] D loss: 1.3814, G loss: 0.6870\n",
      "[1444/1600] D loss: 1.2265, G loss: 0.9121\n",
      "[1564/1600] D loss: 1.7408, G loss: 0.7626\n",
      "train error: \n",
      " D loss: 1.336422, G loss: 0.740231, D accuracy: 59.7%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359220, G loss: 0.739948, D accuracy: 60.2%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3338, G loss: 0.6892\n",
      "[124/1600] D loss: 1.2510, G loss: 0.7356\n",
      "[244/1600] D loss: 1.1971, G loss: 0.7270\n",
      "[364/1600] D loss: 1.3807, G loss: 0.6720\n",
      "[484/1600] D loss: 1.4750, G loss: 0.6120\n",
      "[604/1600] D loss: 1.3695, G loss: 0.6899\n",
      "[724/1600] D loss: 1.4234, G loss: 0.7905\n",
      "[844/1600] D loss: 1.4214, G loss: 0.7889\n",
      "[964/1600] D loss: 1.3864, G loss: 0.7028\n",
      "[1084/1600] D loss: 1.2604, G loss: 0.8669\n",
      "[1204/1600] D loss: 1.5462, G loss: 0.8225\n",
      "[1324/1600] D loss: 1.3530, G loss: 0.5279\n",
      "[1444/1600] D loss: 1.3069, G loss: 0.9185\n",
      "[1564/1600] D loss: 1.4378, G loss: 0.6887\n",
      "train error: \n",
      " D loss: 1.364172, G loss: 0.797356, D accuracy: 57.6%, cell accuracy: 97.3%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376080, G loss: 0.803327, D accuracy: 58.9%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5006, G loss: 0.7473\n",
      "[124/1600] D loss: 1.3436, G loss: 0.7782\n",
      "[244/1600] D loss: 1.3690, G loss: 0.8237\n",
      "[364/1600] D loss: 1.4089, G loss: 0.6946\n",
      "[484/1600] D loss: 1.3019, G loss: 0.7014\n",
      "[604/1600] D loss: 1.2790, G loss: 0.6897\n",
      "[724/1600] D loss: 1.3274, G loss: 0.8759\n",
      "[844/1600] D loss: 1.3071, G loss: 0.7010\n",
      "[964/1600] D loss: 1.3130, G loss: 0.8345\n",
      "[1084/1600] D loss: 1.2888, G loss: 0.8177\n",
      "[1204/1600] D loss: 1.4467, G loss: 0.6878\n",
      "[1324/1600] D loss: 1.4600, G loss: 0.9663\n",
      "[1444/1600] D loss: 1.3299, G loss: 0.6984\n",
      "[1564/1600] D loss: 1.3207, G loss: 0.7333\n",
      "train error: \n",
      " D loss: 1.324771, G loss: 0.691601, D accuracy: 59.7%, cell accuracy: 97.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339692, G loss: 0.688104, D accuracy: 60.2%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6652, G loss: 0.7614\n",
      "[124/1600] D loss: 1.1995, G loss: 0.7593\n",
      "[244/1600] D loss: 1.4479, G loss: 0.6856\n",
      "[364/1600] D loss: 1.2788, G loss: 0.6183\n",
      "[484/1600] D loss: 1.2414, G loss: 0.8455\n",
      "[604/1600] D loss: 1.2487, G loss: 1.0435\n",
      "[724/1600] D loss: 1.4122, G loss: 0.8537\n",
      "[844/1600] D loss: 1.2119, G loss: 0.8639\n",
      "[964/1600] D loss: 1.0963, G loss: 1.0403\n",
      "[1084/1600] D loss: 1.2540, G loss: 0.7738\n",
      "[1204/1600] D loss: 1.3308, G loss: 0.9320\n",
      "[1324/1600] D loss: 1.2582, G loss: 0.7409\n",
      "[1444/1600] D loss: 1.4826, G loss: 0.5693\n",
      "[1564/1600] D loss: 1.3829, G loss: 0.8753\n",
      "train error: \n",
      " D loss: 1.330395, G loss: 0.848799, D accuracy: 61.3%, cell accuracy: 97.2%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347229, G loss: 0.844373, D accuracy: 61.3%, cell accuracy: 97.0%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2851, G loss: 0.9030\n",
      "[124/1600] D loss: 1.4227, G loss: 1.1027\n",
      "[244/1600] D loss: 1.4122, G loss: 0.7639\n",
      "[364/1600] D loss: 1.4881, G loss: 0.8933\n",
      "[484/1600] D loss: 1.2677, G loss: 0.7438\n",
      "[604/1600] D loss: 1.3796, G loss: 0.6350\n",
      "[724/1600] D loss: 1.4675, G loss: 0.7335\n",
      "[844/1600] D loss: 1.3254, G loss: 0.6495\n",
      "[964/1600] D loss: 1.1678, G loss: 0.6552\n",
      "[1084/1600] D loss: 1.2593, G loss: 0.7852\n",
      "[1204/1600] D loss: 1.3288, G loss: 0.7794\n",
      "[1324/1600] D loss: 1.2849, G loss: 0.7549\n",
      "[1444/1600] D loss: 1.2264, G loss: 0.7672\n",
      "[1564/1600] D loss: 1.2269, G loss: 0.7808\n",
      "train error: \n",
      " D loss: 1.341545, G loss: 0.746919, D accuracy: 59.7%, cell accuracy: 97.2%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356229, G loss: 0.748014, D accuracy: 57.9%, cell accuracy: 97.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3791, G loss: 0.6731\n",
      "[124/1600] D loss: 1.3230, G loss: 0.7094\n",
      "[244/1600] D loss: 1.3413, G loss: 0.9338\n",
      "[364/1600] D loss: 1.3324, G loss: 0.7684\n",
      "[484/1600] D loss: 1.2947, G loss: 0.8023\n",
      "[604/1600] D loss: 1.4278, G loss: 0.5583\n",
      "[724/1600] D loss: 1.1704, G loss: 0.7411\n",
      "[844/1600] D loss: 1.2485, G loss: 0.8140\n",
      "[964/1600] D loss: 1.3042, G loss: 0.7301\n",
      "[1084/1600] D loss: 1.2876, G loss: 0.7699\n",
      "[1204/1600] D loss: 1.2778, G loss: 0.8895\n",
      "[1324/1600] D loss: 1.3364, G loss: 1.0267\n",
      "[1444/1600] D loss: 1.4791, G loss: 0.6393\n",
      "[1564/1600] D loss: 1.2674, G loss: 0.8215\n",
      "train error: \n",
      " D loss: 1.333165, G loss: 0.827256, D accuracy: 59.9%, cell accuracy: 97.1%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355622, G loss: 0.833117, D accuracy: 58.5%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2639, G loss: 0.9597\n",
      "[124/1600] D loss: 1.1247, G loss: 0.9366\n",
      "[244/1600] D loss: 1.2901, G loss: 0.6411\n",
      "[364/1600] D loss: 1.2995, G loss: 0.5949\n",
      "[484/1600] D loss: 1.3828, G loss: 0.7274\n",
      "[604/1600] D loss: 1.1064, G loss: 0.7259\n",
      "[724/1600] D loss: 1.3706, G loss: 0.9217\n",
      "[844/1600] D loss: 1.1806, G loss: 0.8456\n",
      "[964/1600] D loss: 1.4038, G loss: 0.6868\n",
      "[1084/1600] D loss: 1.2506, G loss: 0.7543\n",
      "[1204/1600] D loss: 1.3543, G loss: 0.6965\n",
      "[1324/1600] D loss: 1.4690, G loss: 0.9227\n",
      "[1444/1600] D loss: 1.2400, G loss: 0.8494\n",
      "[1564/1600] D loss: 1.4206, G loss: 1.0273\n",
      "train error: \n",
      " D loss: 1.335047, G loss: 0.644236, D accuracy: 58.5%, cell accuracy: 96.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349256, G loss: 0.646606, D accuracy: 58.0%, cell accuracy: 96.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3739, G loss: 0.5084\n",
      "[124/1600] D loss: 1.4513, G loss: 0.6985\n",
      "[244/1600] D loss: 1.4036, G loss: 0.9454\n",
      "[364/1600] D loss: 1.1730, G loss: 0.6779\n",
      "[484/1600] D loss: 1.2924, G loss: 0.7226\n",
      "[604/1600] D loss: 1.3424, G loss: 0.8812\n",
      "[724/1600] D loss: 1.1971, G loss: 0.7106\n",
      "[844/1600] D loss: 1.2959, G loss: 0.6683\n",
      "[964/1600] D loss: 1.2228, G loss: 0.7525\n",
      "[1084/1600] D loss: 1.3952, G loss: 0.8883\n",
      "[1204/1600] D loss: 1.3842, G loss: 0.7439\n",
      "[1324/1600] D loss: 1.3776, G loss: 0.5015\n",
      "[1444/1600] D loss: 1.2302, G loss: 0.6163\n",
      "[1564/1600] D loss: 1.3330, G loss: 0.7146\n",
      "train error: \n",
      " D loss: 1.314137, G loss: 0.767146, D accuracy: 59.8%, cell accuracy: 97.4%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328395, G loss: 0.771594, D accuracy: 59.1%, cell accuracy: 97.2%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3825, G loss: 0.8901\n",
      "[124/1600] D loss: 1.2649, G loss: 0.7218\n",
      "[244/1600] D loss: 1.1826, G loss: 0.6759\n",
      "[364/1600] D loss: 1.2342, G loss: 0.8599\n",
      "[484/1600] D loss: 1.2143, G loss: 0.7008\n",
      "[604/1600] D loss: 1.4556, G loss: 0.9300\n",
      "[724/1600] D loss: 1.3320, G loss: 0.6733\n",
      "[844/1600] D loss: 1.2233, G loss: 0.8695\n",
      "[964/1600] D loss: 1.3494, G loss: 0.8517\n",
      "[1084/1600] D loss: 1.3439, G loss: 0.9836\n",
      "[1204/1600] D loss: 1.3519, G loss: 0.6631\n",
      "[1324/1600] D loss: 1.2912, G loss: 0.9733\n",
      "[1444/1600] D loss: 1.2741, G loss: 0.7388\n",
      "[1564/1600] D loss: 1.3869, G loss: 0.5365\n",
      "train error: \n",
      " D loss: 1.363799, G loss: 0.932448, D accuracy: 56.8%, cell accuracy: 97.6%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384899, G loss: 0.938998, D accuracy: 55.0%, cell accuracy: 97.4%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3765, G loss: 0.9730\n",
      "[124/1600] D loss: 1.2604, G loss: 0.8633\n",
      "[244/1600] D loss: 1.3323, G loss: 0.7011\n",
      "[364/1600] D loss: 1.5624, G loss: 0.6568\n",
      "[484/1600] D loss: 1.4100, G loss: 0.6420\n",
      "[604/1600] D loss: 1.4584, G loss: 0.5115\n",
      "[724/1600] D loss: 1.3398, G loss: 0.7773\n",
      "[844/1600] D loss: 1.3070, G loss: 0.7760\n",
      "[964/1600] D loss: 1.2539, G loss: 0.6078\n",
      "[1084/1600] D loss: 1.4606, G loss: 0.8989\n",
      "[1204/1600] D loss: 1.2546, G loss: 0.6384\n",
      "[1324/1600] D loss: 1.2872, G loss: 0.7515\n",
      "[1444/1600] D loss: 1.4432, G loss: 1.0593\n",
      "[1564/1600] D loss: 1.2310, G loss: 0.8866\n",
      "train error: \n",
      " D loss: 1.337334, G loss: 0.691821, D accuracy: 58.2%, cell accuracy: 97.6%, board accuracy: 1.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355596, G loss: 0.693332, D accuracy: 57.4%, cell accuracy: 97.4%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2403, G loss: 0.7584\n",
      "[124/1600] D loss: 1.2543, G loss: 0.6796\n",
      "[244/1600] D loss: 1.5326, G loss: 0.6966\n",
      "[364/1600] D loss: 1.3952, G loss: 0.6958\n",
      "[484/1600] D loss: 1.2727, G loss: 0.8085\n",
      "[604/1600] D loss: 1.1827, G loss: 0.7930\n",
      "[724/1600] D loss: 1.4075, G loss: 0.8531\n",
      "[844/1600] D loss: 1.2290, G loss: 0.7538\n",
      "[964/1600] D loss: 1.2743, G loss: 0.9637\n",
      "[1084/1600] D loss: 1.4193, G loss: 0.7621\n",
      "[1204/1600] D loss: 1.1186, G loss: 0.8922\n",
      "[1324/1600] D loss: 1.3000, G loss: 0.7289\n",
      "[1444/1600] D loss: 1.4063, G loss: 0.7043\n",
      "[1564/1600] D loss: 1.2403, G loss: 0.8057\n",
      "train error: \n",
      " D loss: 1.317299, G loss: 0.727356, D accuracy: 59.9%, cell accuracy: 97.6%, board accuracy: 1.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334280, G loss: 0.725694, D accuracy: 58.4%, cell accuracy: 97.5%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1038, G loss: 0.9124\n",
      "[124/1600] D loss: 1.4115, G loss: 0.5830\n",
      "[244/1600] D loss: 1.3164, G loss: 0.7031\n",
      "[364/1600] D loss: 1.2450, G loss: 0.7429\n",
      "[484/1600] D loss: 1.3268, G loss: 0.9846\n",
      "[604/1600] D loss: 1.2204, G loss: 0.7121\n",
      "[724/1600] D loss: 1.3792, G loss: 0.9974\n",
      "[844/1600] D loss: 1.3158, G loss: 0.6317\n",
      "[964/1600] D loss: 1.1268, G loss: 0.6384\n",
      "[1084/1600] D loss: 1.0842, G loss: 0.8235\n",
      "[1204/1600] D loss: 1.5010, G loss: 0.6303\n",
      "[1324/1600] D loss: 1.2535, G loss: 0.6863\n",
      "[1444/1600] D loss: 1.4169, G loss: 0.8539\n",
      "[1564/1600] D loss: 1.1554, G loss: 0.7999\n",
      "train error: \n",
      " D loss: 1.312163, G loss: 0.788813, D accuracy: 60.8%, cell accuracy: 97.6%, board accuracy: 1.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331098, G loss: 0.791404, D accuracy: 59.4%, cell accuracy: 97.5%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2390, G loss: 0.7369\n",
      "[124/1600] D loss: 1.4712, G loss: 0.7034\n",
      "[244/1600] D loss: 1.4154, G loss: 0.6307\n",
      "[364/1600] D loss: 1.1408, G loss: 0.8043\n",
      "[484/1600] D loss: 1.2500, G loss: 0.7122\n",
      "[604/1600] D loss: 1.4093, G loss: 0.7858\n",
      "[724/1600] D loss: 1.3865, G loss: 0.6940\n",
      "[844/1600] D loss: 1.3002, G loss: 0.5886\n",
      "[964/1600] D loss: 1.4670, G loss: 0.6452\n",
      "[1084/1600] D loss: 1.5187, G loss: 0.6235\n",
      "[1204/1600] D loss: 1.2836, G loss: 0.6458\n",
      "[1324/1600] D loss: 1.3529, G loss: 0.6714\n",
      "[1444/1600] D loss: 1.4099, G loss: 1.2649\n",
      "[1564/1600] D loss: 1.2784, G loss: 0.6233\n",
      "train error: \n",
      " D loss: 1.308011, G loss: 0.829122, D accuracy: 61.3%, cell accuracy: 97.1%, board accuracy: 1.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323073, G loss: 0.831632, D accuracy: 59.5%, cell accuracy: 97.0%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1691, G loss: 0.8463\n",
      "[124/1600] D loss: 1.3134, G loss: 0.7647\n",
      "[244/1600] D loss: 1.3199, G loss: 0.7420\n",
      "[364/1600] D loss: 1.3165, G loss: 0.8381\n",
      "[484/1600] D loss: 1.2322, G loss: 0.8644\n",
      "[604/1600] D loss: 1.2615, G loss: 0.9449\n",
      "[724/1600] D loss: 1.2768, G loss: 0.9382\n",
      "[844/1600] D loss: 1.5497, G loss: 0.6431\n",
      "[964/1600] D loss: 1.2862, G loss: 0.8177\n",
      "[1084/1600] D loss: 1.1905, G loss: 0.8472\n",
      "[1204/1600] D loss: 1.2717, G loss: 0.8462\n",
      "[1324/1600] D loss: 1.2822, G loss: 0.9524\n",
      "[1444/1600] D loss: 1.4461, G loss: 0.8625\n",
      "[1564/1600] D loss: 1.2486, G loss: 0.9122\n",
      "train error: \n",
      " D loss: 1.289310, G loss: 0.811421, D accuracy: 60.8%, cell accuracy: 97.4%, board accuracy: 1.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304001, G loss: 0.811838, D accuracy: 58.6%, cell accuracy: 97.3%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4162, G loss: 0.9568\n",
      "[124/1600] D loss: 1.2098, G loss: 1.0274\n",
      "[244/1600] D loss: 1.2897, G loss: 0.9956\n",
      "[364/1600] D loss: 1.2298, G loss: 0.6916\n",
      "[484/1600] D loss: 1.2534, G loss: 0.9057\n",
      "[604/1600] D loss: 1.2351, G loss: 0.8516\n",
      "[724/1600] D loss: 1.3782, G loss: 0.7474\n",
      "[844/1600] D loss: 1.1048, G loss: 1.0287\n",
      "[964/1600] D loss: 1.2233, G loss: 0.9080\n",
      "[1084/1600] D loss: 1.3357, G loss: 0.6632\n",
      "[1204/1600] D loss: 1.3222, G loss: 0.9479\n",
      "[1324/1600] D loss: 1.2695, G loss: 0.8118\n",
      "[1444/1600] D loss: 1.2403, G loss: 1.0798\n",
      "[1564/1600] D loss: 0.9797, G loss: 0.9813\n",
      "train error: \n",
      " D loss: 1.291047, G loss: 0.738716, D accuracy: 61.0%, cell accuracy: 97.6%, board accuracy: 3.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301183, G loss: 0.740116, D accuracy: 59.1%, cell accuracy: 97.5%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1954, G loss: 0.7495\n",
      "[124/1600] D loss: 1.2036, G loss: 0.8788\n",
      "[244/1600] D loss: 1.2495, G loss: 0.7915\n",
      "[364/1600] D loss: 1.2896, G loss: 0.8903\n",
      "[484/1600] D loss: 1.1720, G loss: 0.9702\n",
      "[604/1600] D loss: 1.2716, G loss: 0.9884\n",
      "[724/1600] D loss: 1.1321, G loss: 0.9915\n",
      "[844/1600] D loss: 1.1343, G loss: 1.1655\n",
      "[964/1600] D loss: 1.0527, G loss: 0.7502\n",
      "[1084/1600] D loss: 1.2887, G loss: 0.7264\n",
      "[1204/1600] D loss: 0.8706, G loss: 0.8954\n",
      "[1324/1600] D loss: 1.4320, G loss: 0.8140\n",
      "[1444/1600] D loss: 1.1910, G loss: 0.9125\n",
      "[1564/1600] D loss: 1.4495, G loss: 0.6670\n",
      "train error: \n",
      " D loss: 1.289688, G loss: 0.805080, D accuracy: 62.1%, cell accuracy: 97.2%, board accuracy: 1.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308379, G loss: 0.804869, D accuracy: 60.2%, cell accuracy: 97.1%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4114, G loss: 0.8032\n",
      "[124/1600] D loss: 1.3552, G loss: 0.6836\n",
      "[244/1600] D loss: 1.4235, G loss: 0.7340\n",
      "[364/1600] D loss: 1.2725, G loss: 0.8051\n",
      "[484/1600] D loss: 1.2941, G loss: 0.9534\n",
      "[604/1600] D loss: 1.1111, G loss: 0.8169\n",
      "[724/1600] D loss: 1.3155, G loss: 0.7052\n",
      "[844/1600] D loss: 1.1546, G loss: 0.8739\n",
      "[964/1600] D loss: 1.3202, G loss: 0.7573\n",
      "[1084/1600] D loss: 1.1686, G loss: 0.7305\n",
      "[1204/1600] D loss: 1.3400, G loss: 0.7813\n",
      "[1324/1600] D loss: 1.2582, G loss: 0.9062\n",
      "[1444/1600] D loss: 1.0126, G loss: 1.1302\n",
      "[1564/1600] D loss: 1.1225, G loss: 0.8349\n",
      "train error: \n",
      " D loss: 1.270056, G loss: 0.792442, D accuracy: 62.2%, cell accuracy: 97.3%, board accuracy: 1.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284467, G loss: 0.790572, D accuracy: 59.8%, cell accuracy: 97.2%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3457, G loss: 0.5230\n",
      "[124/1600] D loss: 1.2620, G loss: 0.8966\n",
      "[244/1600] D loss: 1.3942, G loss: 0.6870\n",
      "[364/1600] D loss: 1.1344, G loss: 0.9123\n",
      "[484/1600] D loss: 1.2727, G loss: 0.8969\n",
      "[604/1600] D loss: 1.5349, G loss: 1.2557\n",
      "[724/1600] D loss: 1.4248, G loss: 0.8848\n",
      "[844/1600] D loss: 1.1614, G loss: 1.0249\n",
      "[964/1600] D loss: 1.5146, G loss: 0.6581\n",
      "[1084/1600] D loss: 1.1171, G loss: 0.9020\n",
      "[1204/1600] D loss: 1.0908, G loss: 1.0433\n",
      "[1324/1600] D loss: 1.2321, G loss: 0.9185\n",
      "[1444/1600] D loss: 1.2787, G loss: 0.7371\n",
      "[1564/1600] D loss: 1.3075, G loss: 0.8685\n",
      "train error: \n",
      " D loss: 1.309750, G loss: 0.613002, D accuracy: 58.7%, cell accuracy: 97.6%, board accuracy: 2.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331189, G loss: 0.611138, D accuracy: 58.2%, cell accuracy: 97.4%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4063, G loss: 0.5603\n",
      "[124/1600] D loss: 1.3147, G loss: 0.6723\n",
      "[244/1600] D loss: 1.2843, G loss: 0.6955\n",
      "[364/1600] D loss: 1.5552, G loss: 0.5453\n",
      "[484/1600] D loss: 1.2308, G loss: 0.7668\n",
      "[604/1600] D loss: 1.3575, G loss: 0.7501\n",
      "[724/1600] D loss: 1.0430, G loss: 0.9897\n",
      "[844/1600] D loss: 1.2362, G loss: 0.5732\n",
      "[964/1600] D loss: 1.3671, G loss: 0.6427\n",
      "[1084/1600] D loss: 1.1058, G loss: 0.8442\n",
      "[1204/1600] D loss: 1.2437, G loss: 0.7381\n",
      "[1324/1600] D loss: 1.3177, G loss: 0.8294\n",
      "[1444/1600] D loss: 1.3745, G loss: 0.6914\n",
      "[1564/1600] D loss: 1.4342, G loss: 0.9565\n",
      "train error: \n",
      " D loss: 1.300981, G loss: 0.634027, D accuracy: 60.2%, cell accuracy: 97.7%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335458, G loss: 0.617276, D accuracy: 58.2%, cell accuracy: 97.5%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4186, G loss: 0.5100\n",
      "[124/1600] D loss: 1.3863, G loss: 0.9342\n",
      "[244/1600] D loss: 1.2323, G loss: 1.1262\n",
      "[364/1600] D loss: 1.1906, G loss: 0.7268\n",
      "[484/1600] D loss: 1.2801, G loss: 0.7195\n",
      "[604/1600] D loss: 1.2911, G loss: 0.6187\n",
      "[724/1600] D loss: 1.2663, G loss: 0.9238\n",
      "[844/1600] D loss: 1.2582, G loss: 0.6905\n",
      "[964/1600] D loss: 1.1960, G loss: 0.7748\n",
      "[1084/1600] D loss: 1.2041, G loss: 1.0144\n",
      "[1204/1600] D loss: 0.9845, G loss: 1.0827\n",
      "[1324/1600] D loss: 1.0691, G loss: 1.0674\n",
      "[1444/1600] D loss: 1.2244, G loss: 0.8167\n",
      "[1564/1600] D loss: 1.2495, G loss: 0.6538\n",
      "train error: \n",
      " D loss: 1.272198, G loss: 0.928924, D accuracy: 62.6%, cell accuracy: 97.5%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298630, G loss: 0.921393, D accuracy: 60.4%, cell accuracy: 97.4%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2848, G loss: 0.9808\n",
      "[124/1600] D loss: 0.9567, G loss: 1.0172\n",
      "[244/1600] D loss: 1.1233, G loss: 0.9300\n",
      "[364/1600] D loss: 1.3983, G loss: 0.6831\n",
      "[484/1600] D loss: 0.9106, G loss: 0.9751\n",
      "[604/1600] D loss: 1.3443, G loss: 0.9197\n",
      "[724/1600] D loss: 1.2972, G loss: 0.8167\n",
      "[844/1600] D loss: 1.0645, G loss: 0.9200\n",
      "[964/1600] D loss: 1.3081, G loss: 0.9467\n",
      "[1084/1600] D loss: 1.4844, G loss: 0.5141\n",
      "[1204/1600] D loss: 1.3091, G loss: 0.7664\n",
      "[1324/1600] D loss: 1.4248, G loss: 0.9347\n",
      "[1444/1600] D loss: 1.2100, G loss: 0.7925\n",
      "[1564/1600] D loss: 1.4561, G loss: 0.6940\n",
      "train error: \n",
      " D loss: 1.269572, G loss: 0.705362, D accuracy: 63.2%, cell accuracy: 97.6%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290322, G loss: 0.695613, D accuracy: 60.8%, cell accuracy: 97.4%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3572, G loss: 0.5802\n",
      "[124/1600] D loss: 1.3616, G loss: 0.7662\n",
      "[244/1600] D loss: 1.1828, G loss: 0.8937\n",
      "[364/1600] D loss: 1.1073, G loss: 1.0917\n",
      "[484/1600] D loss: 1.2945, G loss: 0.8255\n",
      "[604/1600] D loss: 1.3784, G loss: 1.1812\n",
      "[724/1600] D loss: 1.1413, G loss: 0.8954\n",
      "[844/1600] D loss: 1.4429, G loss: 0.7245\n",
      "[964/1600] D loss: 1.2155, G loss: 0.7128\n",
      "[1084/1600] D loss: 1.3296, G loss: 0.7466\n",
      "[1204/1600] D loss: 1.2217, G loss: 0.7838\n",
      "[1324/1600] D loss: 1.4467, G loss: 0.9186\n",
      "[1444/1600] D loss: 1.4006, G loss: 0.7089\n",
      "[1564/1600] D loss: 1.2690, G loss: 0.8850\n",
      "train error: \n",
      " D loss: 1.424917, G loss: 0.648688, D accuracy: 53.4%, cell accuracy: 96.8%, board accuracy: 1.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.433359, G loss: 0.656337, D accuracy: 52.1%, cell accuracy: 96.7%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4607, G loss: 0.6072\n",
      "[124/1600] D loss: 1.4157, G loss: 0.7984\n",
      "[244/1600] D loss: 1.4363, G loss: 0.6794\n",
      "[364/1600] D loss: 1.4482, G loss: 0.7829\n",
      "[484/1600] D loss: 1.3802, G loss: 0.7948\n",
      "[604/1600] D loss: 1.4293, G loss: 0.6681\n",
      "[724/1600] D loss: 1.3197, G loss: 0.6010\n",
      "[844/1600] D loss: 1.2320, G loss: 1.0264\n",
      "[964/1600] D loss: 1.2842, G loss: 0.9701\n",
      "[1084/1600] D loss: 1.2960, G loss: 0.9312\n",
      "[1204/1600] D loss: 1.2541, G loss: 0.6247\n",
      "[1324/1600] D loss: 1.0299, G loss: 0.9596\n",
      "[1444/1600] D loss: 1.2190, G loss: 1.2326\n",
      "[1564/1600] D loss: 1.2243, G loss: 0.7855\n",
      "train error: \n",
      " D loss: 1.394395, G loss: 0.638229, D accuracy: 62.5%, cell accuracy: 96.6%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.431683, G loss: 0.626225, D accuracy: 60.6%, cell accuracy: 96.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3703, G loss: 0.5930\n",
      "[124/1600] D loss: 1.3776, G loss: 0.5273\n",
      "[244/1600] D loss: 1.2456, G loss: 0.6676\n",
      "[364/1600] D loss: 1.2624, G loss: 0.6396\n",
      "[484/1600] D loss: 1.2694, G loss: 0.5852\n",
      "[604/1600] D loss: 1.3163, G loss: 0.6383\n",
      "[724/1600] D loss: 1.4023, G loss: 0.8309\n",
      "[844/1600] D loss: 1.3330, G loss: 0.6240\n",
      "[964/1600] D loss: 1.3630, G loss: 0.6746\n",
      "[1084/1600] D loss: 1.3432, G loss: 0.8610\n",
      "[1204/1600] D loss: 1.3435, G loss: 0.9823\n",
      "[1324/1600] D loss: 1.2980, G loss: 0.7013\n",
      "[1444/1600] D loss: 1.3673, G loss: 0.7430\n",
      "[1564/1600] D loss: 1.2558, G loss: 0.7602\n",
      "train error: \n",
      " D loss: 1.348688, G loss: 0.621086, D accuracy: 55.5%, cell accuracy: 97.8%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370073, G loss: 0.616705, D accuracy: 53.8%, cell accuracy: 97.6%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2743, G loss: 0.7121\n",
      "[124/1600] D loss: 1.2831, G loss: 0.6327\n",
      "[244/1600] D loss: 1.1780, G loss: 0.9025\n",
      "[364/1600] D loss: 1.5025, G loss: 0.5995\n",
      "[484/1600] D loss: 1.3967, G loss: 0.7867\n",
      "[604/1600] D loss: 1.4105, G loss: 0.6912\n",
      "[724/1600] D loss: 1.2702, G loss: 0.6951\n",
      "[844/1600] D loss: 1.2955, G loss: 0.7705\n",
      "[964/1600] D loss: 1.2398, G loss: 0.8541\n",
      "[1084/1600] D loss: 1.1843, G loss: 0.9174\n",
      "[1204/1600] D loss: 1.2869, G loss: 0.8660\n",
      "[1324/1600] D loss: 1.2858, G loss: 0.8180\n",
      "[1444/1600] D loss: 1.3196, G loss: 0.6885\n",
      "[1564/1600] D loss: 1.3587, G loss: 0.7043\n",
      "train error: \n",
      " D loss: 1.313667, G loss: 0.914244, D accuracy: 60.6%, cell accuracy: 97.8%, board accuracy: 2.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339979, G loss: 0.908603, D accuracy: 58.6%, cell accuracy: 97.6%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2980, G loss: 0.8753\n",
      "[124/1600] D loss: 1.3474, G loss: 0.6302\n",
      "[244/1600] D loss: 1.3046, G loss: 0.8749\n",
      "[364/1600] D loss: 1.2005, G loss: 0.7707\n",
      "[484/1600] D loss: 1.3708, G loss: 0.9082\n",
      "[604/1600] D loss: 1.4233, G loss: 0.8049\n",
      "[724/1600] D loss: 1.1186, G loss: 0.8606\n",
      "[844/1600] D loss: 1.2421, G loss: 0.9699\n",
      "[964/1600] D loss: 1.2844, G loss: 0.7146\n",
      "[1084/1600] D loss: 1.1332, G loss: 1.0359\n",
      "[1204/1600] D loss: 1.4327, G loss: 0.5656\n",
      "[1324/1600] D loss: 1.1397, G loss: 1.1760\n",
      "[1444/1600] D loss: 1.3828, G loss: 0.7268\n",
      "[1564/1600] D loss: 1.3758, G loss: 0.7487\n",
      "train error: \n",
      " D loss: 1.283498, G loss: 0.814269, D accuracy: 63.9%, cell accuracy: 97.7%, board accuracy: 3.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304416, G loss: 0.804123, D accuracy: 62.3%, cell accuracy: 97.5%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3816, G loss: 0.9530\n",
      "[124/1600] D loss: 1.1788, G loss: 0.7411\n",
      "[244/1600] D loss: 1.1944, G loss: 0.6334\n",
      "[364/1600] D loss: 1.3770, G loss: 0.9889\n",
      "[484/1600] D loss: 1.5162, G loss: 0.6732\n",
      "[604/1600] D loss: 1.4358, G loss: 0.7471\n",
      "[724/1600] D loss: 1.3017, G loss: 0.6580\n",
      "[844/1600] D loss: 1.3246, G loss: 0.6404\n",
      "[964/1600] D loss: 1.3178, G loss: 0.9033\n",
      "[1084/1600] D loss: 1.1909, G loss: 0.7329\n",
      "[1204/1600] D loss: 1.3226, G loss: 0.6778\n",
      "[1324/1600] D loss: 1.2210, G loss: 0.9538\n",
      "[1444/1600] D loss: 1.3282, G loss: 0.5480\n",
      "[1564/1600] D loss: 1.3046, G loss: 0.7263\n",
      "train error: \n",
      " D loss: 1.242519, G loss: 0.786829, D accuracy: 64.9%, cell accuracy: 97.9%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259846, G loss: 0.776213, D accuracy: 63.4%, cell accuracy: 97.7%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2065, G loss: 0.7093\n",
      "[124/1600] D loss: 1.1676, G loss: 1.2631\n",
      "[244/1600] D loss: 1.5305, G loss: 0.8149\n",
      "[364/1600] D loss: 1.2855, G loss: 0.7386\n",
      "[484/1600] D loss: 1.0240, G loss: 1.0341\n",
      "[604/1600] D loss: 1.1918, G loss: 0.6448\n",
      "[724/1600] D loss: 1.2203, G loss: 0.8304\n",
      "[844/1600] D loss: 1.3274, G loss: 0.8059\n",
      "[964/1600] D loss: 1.1426, G loss: 0.9161\n",
      "[1084/1600] D loss: 1.0837, G loss: 0.9820\n",
      "[1204/1600] D loss: 1.2997, G loss: 0.6627\n",
      "[1324/1600] D loss: 1.1029, G loss: 0.8149\n",
      "[1444/1600] D loss: 1.3598, G loss: 0.6725\n",
      "[1564/1600] D loss: 1.1409, G loss: 1.0987\n",
      "train error: \n",
      " D loss: 1.288129, G loss: 0.673230, D accuracy: 59.6%, cell accuracy: 97.8%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312592, G loss: 0.665994, D accuracy: 57.6%, cell accuracy: 97.6%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2698, G loss: 0.6555\n",
      "[124/1600] D loss: 1.0317, G loss: 0.8983\n",
      "[244/1600] D loss: 1.1549, G loss: 1.0151\n",
      "[364/1600] D loss: 1.2771, G loss: 0.9076\n",
      "[484/1600] D loss: 1.1041, G loss: 0.9427\n",
      "[604/1600] D loss: 1.1616, G loss: 0.7093\n",
      "[724/1600] D loss: 1.2225, G loss: 1.2013\n",
      "[844/1600] D loss: 0.9340, G loss: 0.7899\n",
      "[964/1600] D loss: 1.3220, G loss: 0.7121\n",
      "[1084/1600] D loss: 1.2795, G loss: 0.7151\n",
      "[1204/1600] D loss: 1.5349, G loss: 0.5987\n",
      "[1324/1600] D loss: 1.1642, G loss: 0.7784\n",
      "[1444/1600] D loss: 1.1849, G loss: 0.7550\n",
      "[1564/1600] D loss: 1.4038, G loss: 1.1516\n",
      "train error: \n",
      " D loss: 1.249051, G loss: 0.682104, D accuracy: 62.4%, cell accuracy: 98.1%, board accuracy: 4.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270559, G loss: 0.658356, D accuracy: 59.8%, cell accuracy: 97.9%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1694, G loss: 0.7121\n",
      "[124/1600] D loss: 1.4023, G loss: 0.6428\n",
      "[244/1600] D loss: 1.3272, G loss: 0.5989\n",
      "[364/1600] D loss: 1.1902, G loss: 0.8934\n",
      "[484/1600] D loss: 0.8493, G loss: 1.3187\n",
      "[604/1600] D loss: 1.2457, G loss: 1.0279\n",
      "[724/1600] D loss: 1.4063, G loss: 1.1703\n",
      "[844/1600] D loss: 0.9941, G loss: 1.3759\n",
      "[964/1600] D loss: 1.2950, G loss: 0.8559\n",
      "[1084/1600] D loss: 1.0095, G loss: 1.1642\n",
      "[1204/1600] D loss: 0.9505, G loss: 0.9874\n",
      "[1324/1600] D loss: 1.2530, G loss: 0.8795\n",
      "[1444/1600] D loss: 1.1186, G loss: 1.0079\n",
      "[1564/1600] D loss: 0.7745, G loss: 1.4262\n",
      "train error: \n",
      " D loss: 1.228799, G loss: 0.701161, D accuracy: 64.9%, cell accuracy: 97.8%, board accuracy: 3.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.234804, G loss: 0.710473, D accuracy: 64.8%, cell accuracy: 97.7%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1671, G loss: 0.7851\n",
      "[124/1600] D loss: 1.1259, G loss: 1.0848\n",
      "[244/1600] D loss: 1.1728, G loss: 0.9651\n",
      "[364/1600] D loss: 1.2030, G loss: 1.0936\n",
      "[484/1600] D loss: 1.3996, G loss: 1.0881\n",
      "[604/1600] D loss: 1.2293, G loss: 0.6957\n",
      "[724/1600] D loss: 1.1976, G loss: 1.0182\n",
      "[844/1600] D loss: 1.4574, G loss: 0.8661\n",
      "[964/1600] D loss: 1.3854, G loss: 0.6830\n",
      "[1084/1600] D loss: 1.1247, G loss: 0.9563\n",
      "[1204/1600] D loss: 1.1044, G loss: 1.0953\n",
      "[1324/1600] D loss: 1.3324, G loss: 0.6547\n",
      "[1444/1600] D loss: 1.1668, G loss: 0.8144\n",
      "[1564/1600] D loss: 0.9979, G loss: 0.8912\n",
      "train error: \n",
      " D loss: 1.203677, G loss: 0.806564, D accuracy: 66.7%, cell accuracy: 97.7%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.226851, G loss: 0.816794, D accuracy: 62.3%, cell accuracy: 97.6%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2998, G loss: 0.6110\n",
      "[124/1600] D loss: 1.2147, G loss: 1.0249\n",
      "[244/1600] D loss: 1.3286, G loss: 1.2571\n",
      "[364/1600] D loss: 1.1339, G loss: 1.2815\n",
      "[484/1600] D loss: 0.9944, G loss: 1.0896\n",
      "[604/1600] D loss: 1.1199, G loss: 0.9143\n",
      "[724/1600] D loss: 1.1657, G loss: 0.9392\n",
      "[844/1600] D loss: 1.0235, G loss: 0.9626\n",
      "[964/1600] D loss: 0.9182, G loss: 1.4330\n",
      "[1084/1600] D loss: 1.2500, G loss: 0.8533\n",
      "[1204/1600] D loss: 1.2768, G loss: 0.8933\n",
      "[1324/1600] D loss: 1.0854, G loss: 0.7874\n",
      "[1444/1600] D loss: 1.3825, G loss: 0.8678\n",
      "[1564/1600] D loss: 1.0942, G loss: 0.9058\n",
      "train error: \n",
      " D loss: 1.176742, G loss: 0.965150, D accuracy: 69.3%, cell accuracy: 97.8%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.213225, G loss: 0.959401, D accuracy: 66.8%, cell accuracy: 97.6%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2986, G loss: 0.8149\n",
      "[124/1600] D loss: 0.8451, G loss: 1.4327\n",
      "[244/1600] D loss: 0.9418, G loss: 0.6990\n",
      "[364/1600] D loss: 1.1000, G loss: 0.8375\n",
      "[484/1600] D loss: 1.2066, G loss: 0.8169\n",
      "[604/1600] D loss: 1.0570, G loss: 1.1835\n",
      "[724/1600] D loss: 1.3330, G loss: 1.0016\n",
      "[844/1600] D loss: 1.1780, G loss: 1.0560\n",
      "[964/1600] D loss: 1.0599, G loss: 1.1962\n",
      "[1084/1600] D loss: 0.8986, G loss: 1.2940\n",
      "[1204/1600] D loss: 1.3898, G loss: 0.8021\n",
      "[1324/1600] D loss: 1.2777, G loss: 0.6943\n",
      "[1444/1600] D loss: 1.0034, G loss: 0.8168\n",
      "[1564/1600] D loss: 1.1292, G loss: 1.3663\n",
      "train error: \n",
      " D loss: 1.224424, G loss: 0.701225, D accuracy: 65.9%, cell accuracy: 97.9%, board accuracy: 5.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272831, G loss: 0.688170, D accuracy: 64.8%, cell accuracy: 97.7%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3695, G loss: 0.6390\n",
      "[124/1600] D loss: 1.3228, G loss: 0.8764\n",
      "[244/1600] D loss: 1.0898, G loss: 0.8003\n",
      "[364/1600] D loss: 1.3572, G loss: 0.9306\n",
      "[484/1600] D loss: 1.3474, G loss: 0.8197\n",
      "[604/1600] D loss: 0.9921, G loss: 0.9668\n",
      "[724/1600] D loss: 1.1421, G loss: 1.0451\n",
      "[844/1600] D loss: 1.2193, G loss: 0.8243\n",
      "[964/1600] D loss: 1.2622, G loss: 0.6146\n",
      "[1084/1600] D loss: 1.0155, G loss: 0.9549\n",
      "[1204/1600] D loss: 1.2057, G loss: 1.0680\n",
      "[1324/1600] D loss: 1.2996, G loss: 0.7593\n",
      "[1444/1600] D loss: 1.3124, G loss: 0.6255\n",
      "[1564/1600] D loss: 1.1804, G loss: 0.5955\n",
      "train error: \n",
      " D loss: 1.199809, G loss: 1.173945, D accuracy: 66.1%, cell accuracy: 98.0%, board accuracy: 4.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.245791, G loss: 1.174215, D accuracy: 63.5%, cell accuracy: 97.8%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1447, G loss: 1.2655\n",
      "[124/1600] D loss: 1.3574, G loss: 0.8072\n",
      "[244/1600] D loss: 1.0722, G loss: 1.1162\n",
      "[364/1600] D loss: 1.0245, G loss: 0.9860\n",
      "[484/1600] D loss: 0.9129, G loss: 1.0433\n",
      "[604/1600] D loss: 1.1606, G loss: 0.9247\n",
      "[724/1600] D loss: 1.1419, G loss: 1.0382\n",
      "[844/1600] D loss: 1.4868, G loss: 0.9501\n",
      "[964/1600] D loss: 1.2344, G loss: 0.8316\n",
      "[1084/1600] D loss: 1.5556, G loss: 0.4602\n",
      "[1204/1600] D loss: 1.5331, G loss: 0.5744\n",
      "[1324/1600] D loss: 1.4491, G loss: 0.8917\n",
      "[1444/1600] D loss: 1.2232, G loss: 0.6910\n",
      "[1564/1600] D loss: 0.9375, G loss: 1.0753\n",
      "train error: \n",
      " D loss: 1.146992, G loss: 1.022299, D accuracy: 68.7%, cell accuracy: 97.9%, board accuracy: 4.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.197209, G loss: 1.014957, D accuracy: 66.6%, cell accuracy: 97.7%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9135, G loss: 1.3325\n",
      "[124/1600] D loss: 1.2342, G loss: 1.1498\n",
      "[244/1600] D loss: 0.9301, G loss: 1.2649\n",
      "[364/1600] D loss: 1.3717, G loss: 1.4173\n",
      "[484/1600] D loss: 1.4357, G loss: 1.0530\n",
      "[604/1600] D loss: 1.2303, G loss: 0.6939\n",
      "[724/1600] D loss: 0.8942, G loss: 1.7118\n",
      "[844/1600] D loss: 1.1834, G loss: 0.7170\n",
      "[964/1600] D loss: 1.5807, G loss: 0.5059\n",
      "[1084/1600] D loss: 1.4544, G loss: 1.1186\n",
      "[1204/1600] D loss: 1.3456, G loss: 1.2389\n",
      "[1324/1600] D loss: 1.2397, G loss: 1.1176\n",
      "[1444/1600] D loss: 0.8306, G loss: 1.1031\n",
      "[1564/1600] D loss: 0.8281, G loss: 1.2382\n",
      "train error: \n",
      " D loss: 1.146187, G loss: 0.931554, D accuracy: 68.5%, cell accuracy: 97.9%, board accuracy: 6.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.178000, G loss: 0.926674, D accuracy: 66.6%, cell accuracy: 97.8%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1734, G loss: 0.7349\n",
      "[124/1600] D loss: 1.2299, G loss: 1.4121\n",
      "[244/1600] D loss: 1.2461, G loss: 0.7980\n",
      "[364/1600] D loss: 1.4845, G loss: 0.7897\n",
      "[484/1600] D loss: 0.7732, G loss: 1.5076\n",
      "[604/1600] D loss: 0.8145, G loss: 1.6235\n",
      "[724/1600] D loss: 1.2494, G loss: 1.5873\n",
      "[844/1600] D loss: 0.9156, G loss: 0.9948\n",
      "[964/1600] D loss: 1.0720, G loss: 1.0771\n",
      "[1084/1600] D loss: 0.7974, G loss: 1.2837\n",
      "[1204/1600] D loss: 0.7553, G loss: 1.1862\n",
      "[1324/1600] D loss: 1.0159, G loss: 0.8034\n",
      "[1444/1600] D loss: 1.3757, G loss: 0.6263\n",
      "[1564/1600] D loss: 1.1371, G loss: 1.3075\n",
      "train error: \n",
      " D loss: 1.171130, G loss: 0.784007, D accuracy: 67.2%, cell accuracy: 97.8%, board accuracy: 5.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.223518, G loss: 0.772123, D accuracy: 64.0%, cell accuracy: 97.5%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2840, G loss: 0.7968\n",
      "[124/1600] D loss: 0.8854, G loss: 0.9625\n",
      "[244/1600] D loss: 1.0721, G loss: 0.8856\n",
      "[364/1600] D loss: 1.2755, G loss: 1.1242\n",
      "[484/1600] D loss: 1.3064, G loss: 0.6681\n",
      "[604/1600] D loss: 1.5387, G loss: 0.7797\n",
      "[724/1600] D loss: 1.2674, G loss: 1.0270\n",
      "[844/1600] D loss: 1.2125, G loss: 0.7089\n",
      "[964/1600] D loss: 1.2958, G loss: 0.6708\n",
      "[1084/1600] D loss: 1.4005, G loss: 1.1634\n",
      "[1204/1600] D loss: 0.8702, G loss: 1.0069\n",
      "[1324/1600] D loss: 1.0787, G loss: 1.2205\n",
      "[1444/1600] D loss: 1.1305, G loss: 0.7488\n",
      "[1564/1600] D loss: 0.8375, G loss: 1.6081\n",
      "train error: \n",
      " D loss: 1.127828, G loss: 1.258672, D accuracy: 69.4%, cell accuracy: 97.9%, board accuracy: 7.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.169167, G loss: 1.272000, D accuracy: 68.1%, cell accuracy: 97.7%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1400, G loss: 1.6063\n",
      "[124/1600] D loss: 1.6863, G loss: 0.6314\n",
      "[244/1600] D loss: 0.9810, G loss: 0.8871\n",
      "[364/1600] D loss: 1.3472, G loss: 1.0256\n",
      "[484/1600] D loss: 1.4051, G loss: 0.7963\n",
      "[604/1600] D loss: 1.2908, G loss: 1.0280\n",
      "[724/1600] D loss: 1.3520, G loss: 0.7699\n",
      "[844/1600] D loss: 0.9991, G loss: 1.2881\n",
      "[964/1600] D loss: 1.4390, G loss: 0.9227\n",
      "[1084/1600] D loss: 1.1670, G loss: 0.8835\n",
      "[1204/1600] D loss: 0.8753, G loss: 1.0957\n",
      "[1324/1600] D loss: 0.9044, G loss: 1.2122\n",
      "[1444/1600] D loss: 1.0101, G loss: 0.9590\n",
      "[1564/1600] D loss: 1.2684, G loss: 0.9519\n",
      "train error: \n",
      " D loss: 1.103866, G loss: 1.079171, D accuracy: 70.8%, cell accuracy: 97.8%, board accuracy: 5.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.147111, G loss: 1.088923, D accuracy: 68.8%, cell accuracy: 97.6%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6587, G loss: 1.4328\n",
      "[124/1600] D loss: 1.3324, G loss: 1.0206\n",
      "[244/1600] D loss: 1.2637, G loss: 0.7729\n",
      "[364/1600] D loss: 1.0889, G loss: 1.1609\n",
      "[484/1600] D loss: 0.5794, G loss: 1.1638\n",
      "[604/1600] D loss: 0.9406, G loss: 1.3194\n",
      "[724/1600] D loss: 1.1080, G loss: 1.0793\n",
      "[844/1600] D loss: 1.3372, G loss: 0.8117\n",
      "[964/1600] D loss: 1.2278, G loss: 0.7317\n",
      "[1084/1600] D loss: 1.4283, G loss: 1.2185\n",
      "[1204/1600] D loss: 1.9594, G loss: 0.5787\n",
      "[1324/1600] D loss: 1.1970, G loss: 0.7358\n",
      "[1444/1600] D loss: 1.1132, G loss: 1.0571\n",
      "[1564/1600] D loss: 0.8042, G loss: 1.5470\n",
      "train error: \n",
      " D loss: 1.144354, G loss: 0.974007, D accuracy: 67.9%, cell accuracy: 97.8%, board accuracy: 6.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.183345, G loss: 0.983012, D accuracy: 66.0%, cell accuracy: 97.6%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9159, G loss: 0.9909\n",
      "[124/1600] D loss: 0.8873, G loss: 1.1786\n",
      "[244/1600] D loss: 1.1631, G loss: 1.3000\n",
      "[364/1600] D loss: 0.9002, G loss: 1.1482\n",
      "[484/1600] D loss: 1.0706, G loss: 0.7305\n",
      "[604/1600] D loss: 0.8411, G loss: 1.0943\n",
      "[724/1600] D loss: 1.0243, G loss: 0.8926\n",
      "[844/1600] D loss: 0.9631, G loss: 0.9250\n",
      "[964/1600] D loss: 1.2741, G loss: 0.6230\n",
      "[1084/1600] D loss: 1.2301, G loss: 1.1584\n",
      "[1204/1600] D loss: 0.9267, G loss: 0.8930\n",
      "[1324/1600] D loss: 0.9463, G loss: 1.2135\n",
      "[1444/1600] D loss: 1.2975, G loss: 0.7444\n",
      "[1564/1600] D loss: 1.3352, G loss: 0.9686\n",
      "train error: \n",
      " D loss: 1.084462, G loss: 1.265891, D accuracy: 70.7%, cell accuracy: 97.8%, board accuracy: 5.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.135762, G loss: 1.292893, D accuracy: 67.6%, cell accuracy: 97.6%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6937, G loss: 1.4776\n",
      "[124/1600] D loss: 0.8945, G loss: 0.8868\n",
      "[244/1600] D loss: 1.2850, G loss: 0.8855\n",
      "[364/1600] D loss: 1.4318, G loss: 0.8807\n",
      "[484/1600] D loss: 1.1766, G loss: 0.8455\n",
      "[604/1600] D loss: 1.1750, G loss: 0.8788\n",
      "[724/1600] D loss: 1.2425, G loss: 0.9876\n",
      "[844/1600] D loss: 0.9782, G loss: 1.2305\n",
      "[964/1600] D loss: 1.3351, G loss: 1.2454\n",
      "[1084/1600] D loss: 0.8049, G loss: 1.8267\n",
      "[1204/1600] D loss: 1.1171, G loss: 0.8541\n",
      "[1324/1600] D loss: 0.8498, G loss: 0.9081\n",
      "[1444/1600] D loss: 1.2172, G loss: 0.8617\n",
      "[1564/1600] D loss: 1.4936, G loss: 0.6844\n",
      "train error: \n",
      " D loss: 1.140279, G loss: 1.460590, D accuracy: 67.6%, cell accuracy: 97.9%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.200156, G loss: 1.471485, D accuracy: 64.8%, cell accuracy: 97.7%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0336, G loss: 1.4901\n",
      "[124/1600] D loss: 1.2483, G loss: 0.6473\n",
      "[244/1600] D loss: 0.9322, G loss: 1.0554\n",
      "[364/1600] D loss: 1.0239, G loss: 1.1815\n",
      "[484/1600] D loss: 0.4366, G loss: 2.0745\n",
      "[604/1600] D loss: 0.7636, G loss: 1.2736\n",
      "[724/1600] D loss: 1.2572, G loss: 1.1823\n",
      "[844/1600] D loss: 1.1652, G loss: 1.5729\n",
      "[964/1600] D loss: 0.5007, G loss: 1.7424\n",
      "[1084/1600] D loss: 1.1056, G loss: 1.1558\n",
      "[1204/1600] D loss: 1.1446, G loss: 1.0597\n",
      "[1324/1600] D loss: 1.0159, G loss: 1.2720\n",
      "[1444/1600] D loss: 0.8428, G loss: 1.0797\n",
      "[1564/1600] D loss: 1.2281, G loss: 0.8608\n",
      "train error: \n",
      " D loss: 1.066471, G loss: 1.203112, D accuracy: 72.1%, cell accuracy: 98.0%, board accuracy: 5.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.110954, G loss: 1.229919, D accuracy: 70.4%, cell accuracy: 97.8%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0081, G loss: 1.0051\n",
      "[124/1600] D loss: 1.0808, G loss: 1.4570\n",
      "[244/1600] D loss: 1.2811, G loss: 1.6476\n",
      "[364/1600] D loss: 1.0102, G loss: 1.3352\n",
      "[484/1600] D loss: 0.8426, G loss: 1.6758\n",
      "[604/1600] D loss: 1.0584, G loss: 1.4028\n",
      "[724/1600] D loss: 0.9828, G loss: 1.0238\n",
      "[844/1600] D loss: 0.7555, G loss: 1.7256\n",
      "[964/1600] D loss: 0.7697, G loss: 1.1022\n",
      "[1084/1600] D loss: 1.2292, G loss: 0.8038\n",
      "[1204/1600] D loss: 1.2110, G loss: 1.0423\n",
      "[1324/1600] D loss: 0.9392, G loss: 0.9324\n",
      "[1444/1600] D loss: 1.2177, G loss: 0.8290\n",
      "[1564/1600] D loss: 1.6436, G loss: 1.2172\n",
      "train error: \n",
      " D loss: 1.057147, G loss: 1.089815, D accuracy: 72.4%, cell accuracy: 97.9%, board accuracy: 5.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.100064, G loss: 1.097030, D accuracy: 69.0%, cell accuracy: 97.7%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0238, G loss: 1.3131\n",
      "[124/1600] D loss: 1.1851, G loss: 1.3078\n",
      "[244/1600] D loss: 1.0471, G loss: 1.1419\n",
      "[364/1600] D loss: 0.6287, G loss: 1.3898\n",
      "[484/1600] D loss: 1.0356, G loss: 1.2767\n",
      "[604/1600] D loss: 1.2437, G loss: 1.8519\n",
      "[724/1600] D loss: 0.7612, G loss: 1.3687\n",
      "[844/1600] D loss: 1.3451, G loss: 0.5547\n",
      "[964/1600] D loss: 0.8984, G loss: 1.4683\n",
      "[1084/1600] D loss: 0.7869, G loss: 1.2464\n",
      "[1204/1600] D loss: 1.0041, G loss: 1.1343\n",
      "[1324/1600] D loss: 1.5605, G loss: 1.0273\n",
      "[1444/1600] D loss: 1.0716, G loss: 1.0654\n",
      "[1564/1600] D loss: 0.7633, G loss: 1.2703\n",
      "train error: \n",
      " D loss: 1.044563, G loss: 1.219644, D accuracy: 74.0%, cell accuracy: 97.9%, board accuracy: 6.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.081022, G loss: 1.247785, D accuracy: 72.8%, cell accuracy: 97.8%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2800, G loss: 0.6850\n",
      "[124/1600] D loss: 0.9149, G loss: 1.1485\n",
      "[244/1600] D loss: 0.9323, G loss: 1.2675\n",
      "[364/1600] D loss: 1.0408, G loss: 1.0332\n",
      "[484/1600] D loss: 1.2797, G loss: 0.8579\n",
      "[604/1600] D loss: 1.1479, G loss: 0.8652\n",
      "[724/1600] D loss: 1.4946, G loss: 0.4729\n",
      "[844/1600] D loss: 1.2739, G loss: 0.8827\n",
      "[964/1600] D loss: 1.0631, G loss: 1.2637\n",
      "[1084/1600] D loss: 0.6610, G loss: 1.7625\n",
      "[1204/1600] D loss: 0.7818, G loss: 1.4212\n",
      "[1324/1600] D loss: 1.1899, G loss: 0.9350\n",
      "[1444/1600] D loss: 1.1470, G loss: 1.1554\n",
      "[1564/1600] D loss: 1.0569, G loss: 0.8615\n",
      "train error: \n",
      " D loss: 1.048067, G loss: 1.388016, D accuracy: 73.3%, cell accuracy: 97.9%, board accuracy: 5.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.104051, G loss: 1.415206, D accuracy: 69.2%, cell accuracy: 97.7%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9788, G loss: 1.8054\n",
      "[124/1600] D loss: 0.5256, G loss: 1.5279\n",
      "[244/1600] D loss: 1.3479, G loss: 1.4776\n",
      "[364/1600] D loss: 0.8681, G loss: 1.2785\n",
      "[484/1600] D loss: 1.0576, G loss: 1.0711\n",
      "[604/1600] D loss: 0.6903, G loss: 1.3989\n",
      "[724/1600] D loss: 1.0579, G loss: 1.1499\n",
      "[844/1600] D loss: 0.9822, G loss: 0.8812\n",
      "[964/1600] D loss: 1.2166, G loss: 1.5518\n",
      "[1084/1600] D loss: 0.5464, G loss: 1.8466\n",
      "[1204/1600] D loss: 0.8297, G loss: 1.6275\n",
      "[1324/1600] D loss: 1.4515, G loss: 1.8025\n",
      "[1444/1600] D loss: 0.6901, G loss: 1.4766\n",
      "[1564/1600] D loss: 0.6278, G loss: 1.3399\n",
      "train error: \n",
      " D loss: 1.054944, G loss: 1.492932, D accuracy: 73.2%, cell accuracy: 97.9%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.111224, G loss: 1.510988, D accuracy: 70.0%, cell accuracy: 97.7%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1199, G loss: 1.1084\n",
      "[124/1600] D loss: 1.2372, G loss: 2.0725\n",
      "[244/1600] D loss: 0.5560, G loss: 1.2498\n",
      "[364/1600] D loss: 1.0895, G loss: 1.1286\n",
      "[484/1600] D loss: 0.8481, G loss: 1.0308\n",
      "[604/1600] D loss: 0.9265, G loss: 0.9969\n",
      "[724/1600] D loss: 0.4985, G loss: 1.6146\n",
      "[844/1600] D loss: 1.1188, G loss: 1.7576\n",
      "[964/1600] D loss: 1.5307, G loss: 0.7372\n",
      "[1084/1600] D loss: 0.9683, G loss: 1.7807\n",
      "[1204/1600] D loss: 1.7210, G loss: 0.6745\n",
      "[1324/1600] D loss: 0.7445, G loss: 2.1971\n",
      "[1444/1600] D loss: 0.8284, G loss: 1.7783\n",
      "[1564/1600] D loss: 0.8721, G loss: 1.1024\n",
      "train error: \n",
      " D loss: 1.028672, G loss: 1.340352, D accuracy: 71.5%, cell accuracy: 97.0%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.078403, G loss: 1.386424, D accuracy: 68.6%, cell accuracy: 96.8%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9376, G loss: 1.0817\n",
      "[124/1600] D loss: 1.1108, G loss: 0.8123\n",
      "[244/1600] D loss: 1.0296, G loss: 1.0723\n",
      "[364/1600] D loss: 0.9697, G loss: 0.9257\n",
      "[484/1600] D loss: 1.0968, G loss: 0.8838\n",
      "[604/1600] D loss: 0.9803, G loss: 0.6620\n",
      "[724/1600] D loss: 0.6582, G loss: 1.5905\n",
      "[844/1600] D loss: 1.0504, G loss: 0.8988\n",
      "[964/1600] D loss: 1.0013, G loss: 1.2906\n",
      "[1084/1600] D loss: 1.1091, G loss: 1.1573\n",
      "[1204/1600] D loss: 1.3566, G loss: 1.0982\n",
      "[1324/1600] D loss: 0.8902, G loss: 1.0932\n",
      "[1444/1600] D loss: 1.1079, G loss: 1.4420\n",
      "[1564/1600] D loss: 1.0077, G loss: 1.3977\n",
      "train error: \n",
      " D loss: 1.068481, G loss: 0.983826, D accuracy: 72.0%, cell accuracy: 97.9%, board accuracy: 6.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.128446, G loss: 0.992999, D accuracy: 69.6%, cell accuracy: 97.8%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9064, G loss: 1.2009\n",
      "[124/1600] D loss: 1.6203, G loss: 0.5684\n",
      "[244/1600] D loss: 1.3017, G loss: 1.0333\n",
      "[364/1600] D loss: 0.9073, G loss: 1.3041\n",
      "[484/1600] D loss: 1.4198, G loss: 1.5528\n",
      "[604/1600] D loss: 0.9456, G loss: 1.3144\n",
      "[724/1600] D loss: 0.9642, G loss: 1.3927\n",
      "[844/1600] D loss: 0.8293, G loss: 1.7522\n",
      "[964/1600] D loss: 0.9698, G loss: 1.3527\n",
      "[1084/1600] D loss: 1.4741, G loss: 0.7289\n",
      "[1204/1600] D loss: 1.0902, G loss: 0.9128\n",
      "[1324/1600] D loss: 0.8495, G loss: 2.0644\n",
      "[1444/1600] D loss: 1.4195, G loss: 0.7953\n",
      "[1564/1600] D loss: 1.0894, G loss: 0.7304\n",
      "train error: \n",
      " D loss: 1.061544, G loss: 1.543131, D accuracy: 72.0%, cell accuracy: 97.9%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.116906, G loss: 1.583697, D accuracy: 70.8%, cell accuracy: 97.7%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1169, G loss: 1.1224\n",
      "[124/1600] D loss: 1.0842, G loss: 1.1608\n",
      "[244/1600] D loss: 0.6917, G loss: 1.7059\n",
      "[364/1600] D loss: 1.0247, G loss: 1.0395\n",
      "[484/1600] D loss: 1.1637, G loss: 1.0375\n",
      "[604/1600] D loss: 1.4000, G loss: 1.1630\n",
      "[724/1600] D loss: 0.4980, G loss: 2.2195\n",
      "[844/1600] D loss: 1.0774, G loss: 1.9116\n",
      "[964/1600] D loss: 0.5606, G loss: 1.9776\n",
      "[1084/1600] D loss: 0.6346, G loss: 1.3026\n",
      "[1204/1600] D loss: 0.9967, G loss: 0.6429\n",
      "[1324/1600] D loss: 0.6986, G loss: 2.1554\n",
      "[1444/1600] D loss: 0.9405, G loss: 1.0903\n",
      "[1564/1600] D loss: 1.1072, G loss: 0.9445\n",
      "train error: \n",
      " D loss: 0.994207, G loss: 1.216125, D accuracy: 74.6%, cell accuracy: 98.0%, board accuracy: 6.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.047504, G loss: 1.248428, D accuracy: 70.9%, cell accuracy: 97.9%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2364, G loss: 0.7398\n",
      "[124/1600] D loss: 0.8670, G loss: 1.0204\n",
      "[244/1600] D loss: 0.7024, G loss: 1.3468\n",
      "[364/1600] D loss: 0.4534, G loss: 2.0943\n",
      "[484/1600] D loss: 1.0218, G loss: 1.2634\n",
      "[604/1600] D loss: 1.0077, G loss: 0.6156\n",
      "[724/1600] D loss: 1.2213, G loss: 0.9167\n",
      "[844/1600] D loss: 1.0275, G loss: 0.8396\n",
      "[964/1600] D loss: 1.4049, G loss: 1.6182\n",
      "[1084/1600] D loss: 1.0751, G loss: 1.0991\n",
      "[1204/1600] D loss: 0.6073, G loss: 1.5933\n",
      "[1324/1600] D loss: 1.2979, G loss: 1.2263\n",
      "[1444/1600] D loss: 1.0852, G loss: 1.4168\n",
      "[1564/1600] D loss: 0.6189, G loss: 1.3953\n",
      "train error: \n",
      " D loss: 1.000475, G loss: 1.085872, D accuracy: 73.8%, cell accuracy: 97.9%, board accuracy: 5.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.039745, G loss: 1.133600, D accuracy: 71.4%, cell accuracy: 97.7%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5428, G loss: 2.6318\n",
      "[124/1600] D loss: 0.6613, G loss: 1.4190\n",
      "[244/1600] D loss: 0.9635, G loss: 0.8517\n",
      "[364/1600] D loss: 1.3127, G loss: 1.0055\n",
      "[484/1600] D loss: 1.3050, G loss: 1.5239\n",
      "[604/1600] D loss: 0.8650, G loss: 1.3288\n",
      "[724/1600] D loss: 0.6551, G loss: 1.4239\n",
      "[844/1600] D loss: 1.0380, G loss: 1.0618\n",
      "[964/1600] D loss: 0.7723, G loss: 1.4995\n",
      "[1084/1600] D loss: 1.3425, G loss: 1.1776\n",
      "[1204/1600] D loss: 1.1299, G loss: 0.8471\n",
      "[1324/1600] D loss: 0.6184, G loss: 1.1478\n",
      "[1444/1600] D loss: 1.5432, G loss: 0.5891\n",
      "[1564/1600] D loss: 1.1257, G loss: 1.3093\n",
      "train error: \n",
      " D loss: 0.974322, G loss: 1.323106, D accuracy: 74.7%, cell accuracy: 97.9%, board accuracy: 5.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.027778, G loss: 1.350834, D accuracy: 72.0%, cell accuracy: 97.7%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9062, G loss: 1.0524\n",
      "[124/1600] D loss: 1.5956, G loss: 1.0697\n",
      "[244/1600] D loss: 0.5968, G loss: 1.3641\n",
      "[364/1600] D loss: 0.9589, G loss: 1.2842\n",
      "[484/1600] D loss: 0.7784, G loss: 3.1550\n",
      "[604/1600] D loss: 0.7005, G loss: 1.5382\n",
      "[724/1600] D loss: 0.9155, G loss: 1.2100\n",
      "[844/1600] D loss: 0.7574, G loss: 1.2222\n",
      "[964/1600] D loss: 1.0405, G loss: 1.1321\n",
      "[1084/1600] D loss: 0.9681, G loss: 0.9573\n",
      "[1204/1600] D loss: 0.7848, G loss: 2.3829\n",
      "[1324/1600] D loss: 1.1348, G loss: 0.9087\n",
      "[1444/1600] D loss: 1.0069, G loss: 1.3130\n",
      "[1564/1600] D loss: 0.8960, G loss: 1.1292\n",
      "train error: \n",
      " D loss: 1.031279, G loss: 1.515700, D accuracy: 72.5%, cell accuracy: 98.1%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.071688, G loss: 1.569495, D accuracy: 72.5%, cell accuracy: 97.9%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7703, G loss: 1.9046\n",
      "[124/1600] D loss: 1.0234, G loss: 1.0857\n",
      "[244/1600] D loss: 0.8532, G loss: 1.4003\n",
      "[364/1600] D loss: 1.2120, G loss: 2.0140\n",
      "[484/1600] D loss: 1.0056, G loss: 0.7560\n",
      "[604/1600] D loss: 0.7547, G loss: 1.9230\n",
      "[724/1600] D loss: 0.8742, G loss: 1.4951\n",
      "[844/1600] D loss: 1.3839, G loss: 0.9823\n",
      "[964/1600] D loss: 1.0444, G loss: 1.1500\n",
      "[1084/1600] D loss: 0.8032, G loss: 1.0051\n",
      "[1204/1600] D loss: 0.7042, G loss: 1.2709\n",
      "[1324/1600] D loss: 0.8107, G loss: 1.2824\n",
      "[1444/1600] D loss: 0.9308, G loss: 1.5379\n",
      "[1564/1600] D loss: 0.8632, G loss: 1.1872\n",
      "train error: \n",
      " D loss: 0.973680, G loss: 1.433371, D accuracy: 74.9%, cell accuracy: 98.0%, board accuracy: 8.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.026666, G loss: 1.463248, D accuracy: 72.5%, cell accuracy: 97.8%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6541, G loss: 1.5328\n",
      "[124/1600] D loss: 1.2107, G loss: 0.8936\n",
      "[244/1600] D loss: 0.7793, G loss: 1.8103\n",
      "[364/1600] D loss: 0.8072, G loss: 1.1096\n",
      "[484/1600] D loss: 1.0346, G loss: 1.2892\n",
      "[604/1600] D loss: 0.5274, G loss: 1.6799\n",
      "[724/1600] D loss: 1.0781, G loss: 1.1123\n",
      "[844/1600] D loss: 0.6868, G loss: 2.1508\n",
      "[964/1600] D loss: 1.4143, G loss: 0.8012\n",
      "[1084/1600] D loss: 0.6547, G loss: 1.4462\n",
      "[1204/1600] D loss: 1.2090, G loss: 0.8475\n",
      "[1324/1600] D loss: 1.3771, G loss: 1.0517\n",
      "[1444/1600] D loss: 0.9407, G loss: 1.4753\n",
      "[1564/1600] D loss: 0.9011, G loss: 1.0875\n",
      "train error: \n",
      " D loss: 1.007343, G loss: 1.724551, D accuracy: 73.5%, cell accuracy: 97.9%, board accuracy: 7.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.076067, G loss: 1.752210, D accuracy: 71.1%, cell accuracy: 97.7%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0561, G loss: 1.5050\n",
      "[124/1600] D loss: 1.4897, G loss: 1.0016\n",
      "[244/1600] D loss: 0.7497, G loss: 2.2578\n",
      "[364/1600] D loss: 1.1686, G loss: 1.8815\n",
      "[484/1600] D loss: 0.9501, G loss: 1.0079\n",
      "[604/1600] D loss: 0.8102, G loss: 1.5092\n",
      "[724/1600] D loss: 0.8192, G loss: 1.7564\n",
      "[844/1600] D loss: 0.7217, G loss: 1.6097\n",
      "[964/1600] D loss: 0.4864, G loss: 2.5575\n",
      "[1084/1600] D loss: 1.2330, G loss: 1.5046\n",
      "[1204/1600] D loss: 0.5888, G loss: 1.7296\n",
      "[1324/1600] D loss: 0.8156, G loss: 1.5633\n",
      "[1444/1600] D loss: 0.7764, G loss: 1.1385\n",
      "[1564/1600] D loss: 0.5087, G loss: 1.3563\n",
      "train error: \n",
      " D loss: 0.975894, G loss: 1.219904, D accuracy: 73.7%, cell accuracy: 98.0%, board accuracy: 8.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.021108, G loss: 1.282458, D accuracy: 71.9%, cell accuracy: 97.9%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3197, G loss: 0.7994\n",
      "[124/1600] D loss: 1.0874, G loss: 0.7785\n",
      "[244/1600] D loss: 0.8379, G loss: 0.9160\n",
      "[364/1600] D loss: 1.3055, G loss: 0.8823\n",
      "[484/1600] D loss: 0.2331, G loss: 2.3054\n",
      "[604/1600] D loss: 1.0276, G loss: 0.8873\n",
      "[724/1600] D loss: 1.1574, G loss: 0.8899\n",
      "[844/1600] D loss: 0.5743, G loss: 2.8290\n",
      "[964/1600] D loss: 0.9335, G loss: 1.4350\n",
      "[1084/1600] D loss: 1.2487, G loss: 0.9452\n",
      "[1204/1600] D loss: 1.2197, G loss: 0.8794\n",
      "[1324/1600] D loss: 0.6538, G loss: 1.6080\n",
      "[1444/1600] D loss: 0.9674, G loss: 1.6182\n",
      "[1564/1600] D loss: 0.8276, G loss: 1.0715\n",
      "train error: \n",
      " D loss: 0.967855, G loss: 1.396167, D accuracy: 75.4%, cell accuracy: 98.0%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.018224, G loss: 1.481808, D accuracy: 72.6%, cell accuracy: 97.8%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7499, G loss: 1.5273\n",
      "[124/1600] D loss: 0.3521, G loss: 2.3155\n",
      "[244/1600] D loss: 0.8699, G loss: 2.2657\n",
      "[364/1600] D loss: 0.7272, G loss: 1.7757\n",
      "[484/1600] D loss: 0.6711, G loss: 1.8597\n",
      "[604/1600] D loss: 0.9546, G loss: 1.0129\n",
      "[724/1600] D loss: 1.5692, G loss: 0.4489\n",
      "[844/1600] D loss: 0.6913, G loss: 2.1165\n",
      "[964/1600] D loss: 0.7015, G loss: 1.5342\n",
      "[1084/1600] D loss: 0.6459, G loss: 1.4204\n",
      "[1204/1600] D loss: 0.8112, G loss: 1.4813\n",
      "[1324/1600] D loss: 1.2864, G loss: 1.1301\n",
      "[1444/1600] D loss: 0.7256, G loss: 1.4759\n",
      "[1564/1600] D loss: 1.7758, G loss: 0.9157\n",
      "train error: \n",
      " D loss: 0.979631, G loss: 1.530969, D accuracy: 74.8%, cell accuracy: 98.0%, board accuracy: 8.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.046548, G loss: 1.588725, D accuracy: 72.6%, cell accuracy: 97.8%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9479, G loss: 1.1651\n",
      "[124/1600] D loss: 0.7255, G loss: 1.5251\n",
      "[244/1600] D loss: 0.2965, G loss: 2.5170\n",
      "[364/1600] D loss: 0.4110, G loss: 2.5772\n",
      "[484/1600] D loss: 1.1308, G loss: 1.5503\n",
      "[604/1600] D loss: 1.1679, G loss: 1.3091\n",
      "[724/1600] D loss: 0.5542, G loss: 1.6427\n",
      "[844/1600] D loss: 0.8178, G loss: 1.8681\n",
      "[964/1600] D loss: 0.8804, G loss: 1.0473\n",
      "[1084/1600] D loss: 1.0459, G loss: 0.9519\n",
      "[1204/1600] D loss: 0.6260, G loss: 2.5038\n",
      "[1324/1600] D loss: 0.9415, G loss: 1.1950\n",
      "[1444/1600] D loss: 0.9145, G loss: 2.2145\n",
      "[1564/1600] D loss: 0.9008, G loss: 1.0678\n",
      "train error: \n",
      " D loss: 0.985742, G loss: 1.497928, D accuracy: 74.6%, cell accuracy: 98.1%, board accuracy: 9.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.041511, G loss: 1.564136, D accuracy: 70.6%, cell accuracy: 98.0%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2499, G loss: 1.0688\n",
      "[124/1600] D loss: 1.0026, G loss: 1.3209\n",
      "[244/1600] D loss: 1.4521, G loss: 1.3736\n",
      "[364/1600] D loss: 0.9367, G loss: 2.3124\n",
      "[484/1600] D loss: 0.7202, G loss: 1.4459\n",
      "[604/1600] D loss: 0.7266, G loss: 1.1239\n",
      "[724/1600] D loss: 1.0747, G loss: 1.0598\n",
      "[844/1600] D loss: 0.8626, G loss: 1.0766\n",
      "[964/1600] D loss: 1.2870, G loss: 0.6941\n",
      "[1084/1600] D loss: 1.2252, G loss: 1.0079\n",
      "[1204/1600] D loss: 1.1095, G loss: 0.8382\n",
      "[1324/1600] D loss: 0.8011, G loss: 1.6549\n",
      "[1444/1600] D loss: 0.8883, G loss: 1.1184\n",
      "[1564/1600] D loss: 1.1414, G loss: 1.2669\n",
      "train error: \n",
      " D loss: 1.026543, G loss: 1.034796, D accuracy: 71.7%, cell accuracy: 98.2%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.079587, G loss: 1.060644, D accuracy: 70.5%, cell accuracy: 98.0%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7536, G loss: 1.2999\n",
      "[124/1600] D loss: 0.8183, G loss: 1.4583\n",
      "[244/1600] D loss: 1.2568, G loss: 1.1672\n",
      "[364/1600] D loss: 1.1314, G loss: 1.5392\n",
      "[484/1600] D loss: 0.8729, G loss: 1.1845\n",
      "[604/1600] D loss: 1.0914, G loss: 1.1234\n",
      "[724/1600] D loss: 0.6190, G loss: 1.7323\n",
      "[844/1600] D loss: 0.7006, G loss: 1.5647\n",
      "[964/1600] D loss: 1.0386, G loss: 1.0551\n",
      "[1084/1600] D loss: 0.9733, G loss: 0.9005\n",
      "[1204/1600] D loss: 1.0891, G loss: 1.0716\n",
      "[1324/1600] D loss: 0.8761, G loss: 1.3645\n",
      "[1444/1600] D loss: 0.8153, G loss: 1.0148\n",
      "[1564/1600] D loss: 1.0811, G loss: 1.8819\n",
      "train error: \n",
      " D loss: 1.068802, G loss: 0.983120, D accuracy: 70.3%, cell accuracy: 98.2%, board accuracy: 9.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.097950, G loss: 1.041147, D accuracy: 70.4%, cell accuracy: 98.0%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6232, G loss: 1.9056\n",
      "[124/1600] D loss: 0.9001, G loss: 1.1437\n",
      "[244/1600] D loss: 1.0165, G loss: 1.9601\n",
      "[364/1600] D loss: 1.1689, G loss: 0.6383\n",
      "[484/1600] D loss: 1.1058, G loss: 1.2908\n",
      "[604/1600] D loss: 1.0604, G loss: 0.8618\n",
      "[724/1600] D loss: 1.3437, G loss: 1.2908\n",
      "[844/1600] D loss: 0.8412, G loss: 1.4519\n",
      "[964/1600] D loss: 0.9946, G loss: 0.8128\n",
      "[1084/1600] D loss: 1.0988, G loss: 0.9299\n",
      "[1204/1600] D loss: 0.8803, G loss: 1.3155\n",
      "[1324/1600] D loss: 0.9566, G loss: 1.2268\n",
      "[1444/1600] D loss: 1.5651, G loss: 0.6876\n",
      "[1564/1600] D loss: 1.5872, G loss: 0.7731\n",
      "train error: \n",
      " D loss: 0.985188, G loss: 1.224202, D accuracy: 74.3%, cell accuracy: 98.2%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.022095, G loss: 1.271445, D accuracy: 72.8%, cell accuracy: 98.0%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7623, G loss: 1.4322\n",
      "[124/1600] D loss: 1.2818, G loss: 0.9069\n",
      "[244/1600] D loss: 1.4019, G loss: 0.9669\n",
      "[364/1600] D loss: 0.6738, G loss: 1.5983\n",
      "[484/1600] D loss: 0.7469, G loss: 1.3880\n",
      "[604/1600] D loss: 0.7908, G loss: 1.0895\n",
      "[724/1600] D loss: 1.2731, G loss: 0.6965\n",
      "[844/1600] D loss: 0.8543, G loss: 1.4470\n",
      "[964/1600] D loss: 0.8058, G loss: 1.3605\n",
      "[1084/1600] D loss: 1.0631, G loss: 1.3836\n",
      "[1204/1600] D loss: 1.0899, G loss: 1.1793\n",
      "[1324/1600] D loss: 1.1546, G loss: 0.8779\n",
      "[1444/1600] D loss: 1.0814, G loss: 1.8976\n",
      "[1564/1600] D loss: 0.9017, G loss: 0.9947\n",
      "train error: \n",
      " D loss: 0.947691, G loss: 1.467349, D accuracy: 76.2%, cell accuracy: 98.3%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.016250, G loss: 1.533068, D accuracy: 74.9%, cell accuracy: 98.1%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0042, G loss: 2.3011\n",
      "[124/1600] D loss: 1.2331, G loss: 1.2021\n",
      "[244/1600] D loss: 0.9852, G loss: 1.1171\n",
      "[364/1600] D loss: 0.8905, G loss: 2.0995\n",
      "[484/1600] D loss: 0.8249, G loss: 1.3734\n",
      "[604/1600] D loss: 0.5345, G loss: 2.1946\n",
      "[724/1600] D loss: 0.6118, G loss: 1.6002\n",
      "[844/1600] D loss: 0.9819, G loss: 1.6790\n",
      "[964/1600] D loss: 0.7743, G loss: 1.3918\n",
      "[1084/1600] D loss: 1.6811, G loss: 1.2495\n",
      "[1204/1600] D loss: 1.1659, G loss: 0.9936\n",
      "[1324/1600] D loss: 0.6766, G loss: 1.3952\n",
      "[1444/1600] D loss: 1.2077, G loss: 0.8658\n",
      "[1564/1600] D loss: 0.6274, G loss: 2.2683\n",
      "train error: \n",
      " D loss: 0.991910, G loss: 1.204815, D accuracy: 75.0%, cell accuracy: 98.2%, board accuracy: 9.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.030829, G loss: 1.263692, D accuracy: 73.2%, cell accuracy: 98.1%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4935, G loss: 2.7907\n",
      "[124/1600] D loss: 0.5498, G loss: 2.1590\n",
      "[244/1600] D loss: 0.6023, G loss: 1.9734\n",
      "[364/1600] D loss: 0.8877, G loss: 1.5282\n",
      "[484/1600] D loss: 0.1635, G loss: 3.4019\n",
      "[604/1600] D loss: 1.3972, G loss: 0.9926\n",
      "[724/1600] D loss: 0.6561, G loss: 1.6395\n",
      "[844/1600] D loss: 1.4433, G loss: 0.8075\n",
      "[964/1600] D loss: 0.3454, G loss: 1.7690\n",
      "[1084/1600] D loss: 0.5727, G loss: 1.7356\n",
      "[1204/1600] D loss: 0.7118, G loss: 1.4037\n",
      "[1324/1600] D loss: 0.3669, G loss: 1.6834\n",
      "[1444/1600] D loss: 1.2461, G loss: 1.1867\n",
      "[1564/1600] D loss: 1.4750, G loss: 1.4409\n",
      "train error: \n",
      " D loss: 0.981374, G loss: 1.413160, D accuracy: 75.7%, cell accuracy: 98.3%, board accuracy: 11.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.031056, G loss: 1.459126, D accuracy: 74.6%, cell accuracy: 98.1%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7661, G loss: 1.8158\n",
      "[124/1600] D loss: 0.7265, G loss: 2.1613\n",
      "[244/1600] D loss: 0.5685, G loss: 2.8609\n",
      "[364/1600] D loss: 0.7786, G loss: 1.5351\n",
      "[484/1600] D loss: 0.5797, G loss: 1.9133\n",
      "[604/1600] D loss: 1.0119, G loss: 0.6995\n",
      "[724/1600] D loss: 0.8387, G loss: 1.3549\n",
      "[844/1600] D loss: 0.6914, G loss: 1.2641\n",
      "[964/1600] D loss: 1.2213, G loss: 1.4138\n",
      "[1084/1600] D loss: 0.6510, G loss: 2.3047\n",
      "[1204/1600] D loss: 0.3214, G loss: 2.5649\n",
      "[1324/1600] D loss: 0.6776, G loss: 1.5565\n",
      "[1444/1600] D loss: 1.1240, G loss: 0.6988\n",
      "[1564/1600] D loss: 1.2585, G loss: 2.0339\n",
      "train error: \n",
      " D loss: 1.064226, G loss: 1.039621, D accuracy: 72.1%, cell accuracy: 98.3%, board accuracy: 12.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.111760, G loss: 1.074845, D accuracy: 69.9%, cell accuracy: 98.1%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0252, G loss: 0.9489\n",
      "[124/1600] D loss: 1.2388, G loss: 1.1953\n",
      "[244/1600] D loss: 1.4333, G loss: 1.1595\n",
      "[364/1600] D loss: 1.1547, G loss: 2.2157\n",
      "[484/1600] D loss: 1.0214, G loss: 1.7713\n",
      "[604/1600] D loss: 1.4711, G loss: 0.5748\n",
      "[724/1600] D loss: 1.4371, G loss: 1.0336\n",
      "[844/1600] D loss: 1.2555, G loss: 0.5307\n",
      "[964/1600] D loss: 0.4941, G loss: 2.2501\n",
      "[1084/1600] D loss: 0.5646, G loss: 2.0596\n",
      "[1204/1600] D loss: 1.2588, G loss: 0.7357\n",
      "[1324/1600] D loss: 0.8699, G loss: 1.3076\n",
      "[1444/1600] D loss: 1.1178, G loss: 0.6550\n",
      "[1564/1600] D loss: 0.8746, G loss: 0.8673\n",
      "train error: \n",
      " D loss: 1.034928, G loss: 1.493536, D accuracy: 71.8%, cell accuracy: 98.3%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.100582, G loss: 1.564645, D accuracy: 71.0%, cell accuracy: 98.1%, board accuracy: 9.5% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7427, G loss: 1.9210\n",
      "[124/1600] D loss: 0.8143, G loss: 1.5048\n",
      "[244/1600] D loss: 1.0627, G loss: 1.8845\n",
      "[364/1600] D loss: 0.6511, G loss: 0.9694\n",
      "[484/1600] D loss: 0.9323, G loss: 1.2739\n",
      "[604/1600] D loss: 0.4595, G loss: 1.6882\n",
      "[724/1600] D loss: 0.9586, G loss: 1.0888\n",
      "[844/1600] D loss: 0.8508, G loss: 1.3449\n",
      "[964/1600] D loss: 1.2691, G loss: 1.8403\n",
      "[1084/1600] D loss: 1.2856, G loss: 1.0784\n",
      "[1204/1600] D loss: 1.0563, G loss: 1.7463\n",
      "[1324/1600] D loss: 0.9907, G loss: 1.2435\n",
      "[1444/1600] D loss: 0.9989, G loss: 1.5049\n",
      "[1564/1600] D loss: 0.7228, G loss: 1.5501\n",
      "train error: \n",
      " D loss: 1.029745, G loss: 1.314430, D accuracy: 72.5%, cell accuracy: 98.3%, board accuracy: 15.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.101430, G loss: 1.363482, D accuracy: 70.4%, cell accuracy: 98.1%, board accuracy: 12.0% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0332, G loss: 1.0702\n",
      "[124/1600] D loss: 0.8957, G loss: 0.9241\n",
      "[244/1600] D loss: 1.2683, G loss: 1.8861\n",
      "[364/1600] D loss: 0.6495, G loss: 1.6391\n",
      "[484/1600] D loss: 1.2077, G loss: 1.2741\n",
      "[604/1600] D loss: 0.5845, G loss: 2.6341\n",
      "[724/1600] D loss: 0.7041, G loss: 1.2819\n",
      "[844/1600] D loss: 0.8451, G loss: 1.3551\n",
      "[964/1600] D loss: 0.8444, G loss: 2.3864\n",
      "[1084/1600] D loss: 1.1282, G loss: 1.5539\n",
      "[1204/1600] D loss: 1.7147, G loss: 1.5719\n",
      "[1324/1600] D loss: 1.6111, G loss: 1.5482\n",
      "[1444/1600] D loss: 0.9259, G loss: 1.6319\n",
      "[1564/1600] D loss: 1.0172, G loss: 1.0800\n",
      "train error: \n",
      " D loss: 1.017709, G loss: 1.280780, D accuracy: 72.0%, cell accuracy: 98.2%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.113078, G loss: 1.303815, D accuracy: 70.2%, cell accuracy: 98.1%, board accuracy: 10.2% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8683, G loss: 1.3297\n",
      "[124/1600] D loss: 1.4976, G loss: 0.8867\n",
      "[244/1600] D loss: 1.4662, G loss: 0.6214\n",
      "[364/1600] D loss: 0.2772, G loss: 1.5060\n",
      "[484/1600] D loss: 0.9977, G loss: 1.1945\n",
      "[604/1600] D loss: 1.4348, G loss: 0.6320\n",
      "[724/1600] D loss: 0.7235, G loss: 2.2821\n",
      "[844/1600] D loss: 0.9328, G loss: 1.1249\n",
      "[964/1600] D loss: 0.8959, G loss: 1.0806\n",
      "[1084/1600] D loss: 1.2990, G loss: 1.3974\n",
      "[1204/1600] D loss: 0.8094, G loss: 2.0291\n",
      "[1324/1600] D loss: 1.1089, G loss: 1.0376\n",
      "[1444/1600] D loss: 1.0809, G loss: 0.8360\n",
      "[1564/1600] D loss: 1.3819, G loss: 0.7948\n",
      "train error: \n",
      " D loss: 1.007302, G loss: 1.227924, D accuracy: 73.2%, cell accuracy: 98.4%, board accuracy: 14.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.085899, G loss: 1.291090, D accuracy: 71.5%, cell accuracy: 98.2%, board accuracy: 11.0% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0070, G loss: 0.9113\n",
      "[124/1600] D loss: 0.9734, G loss: 1.8205\n",
      "[244/1600] D loss: 0.5931, G loss: 2.3025\n",
      "[364/1600] D loss: 1.4121, G loss: 0.6107\n",
      "[484/1600] D loss: 0.6133, G loss: 1.8865\n",
      "[604/1600] D loss: 0.7183, G loss: 1.8815\n",
      "[724/1600] D loss: 0.9629, G loss: 1.0343\n",
      "[844/1600] D loss: 0.3833, G loss: 2.7452\n",
      "[964/1600] D loss: 0.5173, G loss: 1.5640\n",
      "[1084/1600] D loss: 1.1802, G loss: 0.7770\n",
      "[1204/1600] D loss: 1.0162, G loss: 1.3842\n",
      "[1324/1600] D loss: 0.5389, G loss: 1.9476\n",
      "[1444/1600] D loss: 1.5452, G loss: 0.9749\n",
      "[1564/1600] D loss: 1.0760, G loss: 2.3492\n",
      "train error: \n",
      " D loss: 1.035267, G loss: 1.138002, D accuracy: 72.8%, cell accuracy: 98.4%, board accuracy: 16.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.101163, G loss: 1.157910, D accuracy: 69.8%, cell accuracy: 98.3%, board accuracy: 12.5% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8364, G loss: 1.2063\n",
      "[124/1600] D loss: 1.1062, G loss: 1.3837\n",
      "[244/1600] D loss: 0.5323, G loss: 2.6934\n",
      "[364/1600] D loss: 1.0003, G loss: 1.2927\n",
      "[484/1600] D loss: 0.9840, G loss: 1.2636\n",
      "[604/1600] D loss: 1.0553, G loss: 2.0685\n",
      "[724/1600] D loss: 1.0921, G loss: 1.8500\n",
      "[844/1600] D loss: 0.5195, G loss: 2.0320\n",
      "[964/1600] D loss: 1.2921, G loss: 1.1116\n",
      "[1084/1600] D loss: 0.7777, G loss: 1.6058\n",
      "[1204/1600] D loss: 1.2199, G loss: 1.3732\n",
      "[1324/1600] D loss: 0.5617, G loss: 1.6095\n",
      "[1444/1600] D loss: 0.6774, G loss: 1.4227\n",
      "[1564/1600] D loss: 0.3579, G loss: 1.9951\n",
      "train error: \n",
      " D loss: 0.987435, G loss: 1.149568, D accuracy: 73.4%, cell accuracy: 98.4%, board accuracy: 16.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.052913, G loss: 1.207193, D accuracy: 70.8%, cell accuracy: 98.2%, board accuracy: 13.0% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2624, G loss: 0.8054\n",
      "[124/1600] D loss: 1.0712, G loss: 1.1753\n",
      "[244/1600] D loss: 1.0745, G loss: 1.1630\n",
      "[364/1600] D loss: 1.0140, G loss: 1.0668\n",
      "[484/1600] D loss: 1.0676, G loss: 1.2537\n",
      "[604/1600] D loss: 0.7474, G loss: 1.2907\n",
      "[724/1600] D loss: 0.9444, G loss: 1.3916\n",
      "[844/1600] D loss: 0.8724, G loss: 1.1332\n",
      "[964/1600] D loss: 0.9518, G loss: 1.5871\n",
      "[1084/1600] D loss: 1.2008, G loss: 1.3370\n",
      "[1204/1600] D loss: 1.3566, G loss: 0.8966\n",
      "[1324/1600] D loss: 0.9310, G loss: 1.4516\n",
      "[1444/1600] D loss: 0.4746, G loss: 1.4490\n",
      "[1564/1600] D loss: 0.6546, G loss: 2.1328\n",
      "train error: \n",
      " D loss: 0.978589, G loss: 1.187598, D accuracy: 73.4%, cell accuracy: 98.4%, board accuracy: 14.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.044539, G loss: 1.236375, D accuracy: 72.0%, cell accuracy: 98.2%, board accuracy: 12.8% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5935, G loss: 1.6015\n",
      "[124/1600] D loss: 0.7446, G loss: 1.4944\n",
      "[244/1600] D loss: 0.8109, G loss: 1.8455\n",
      "[364/1600] D loss: 0.6677, G loss: 2.1967\n",
      "[484/1600] D loss: 0.6583, G loss: 1.5030\n",
      "[604/1600] D loss: 0.8346, G loss: 1.2998\n",
      "[724/1600] D loss: 1.0354, G loss: 1.4205\n",
      "[844/1600] D loss: 1.1176, G loss: 0.8050\n",
      "[964/1600] D loss: 0.4527, G loss: 2.0715\n",
      "[1084/1600] D loss: 0.7198, G loss: 1.9486\n",
      "[1204/1600] D loss: 1.1386, G loss: 0.9178\n",
      "[1324/1600] D loss: 0.8154, G loss: 1.1321\n",
      "[1444/1600] D loss: 1.1225, G loss: 1.3143\n",
      "[1564/1600] D loss: 1.0052, G loss: 0.9972\n",
      "train error: \n",
      " D loss: 1.127219, G loss: 0.898741, D accuracy: 68.2%, cell accuracy: 98.5%, board accuracy: 18.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.152241, G loss: 0.973911, D accuracy: 68.5%, cell accuracy: 98.3%, board accuracy: 15.2% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0424, G loss: 1.5295\n",
      "[124/1600] D loss: 0.8550, G loss: 1.5020\n",
      "[244/1600] D loss: 0.6930, G loss: 1.3133\n",
      "[364/1600] D loss: 1.1124, G loss: 0.8741\n",
      "[484/1600] D loss: 1.3960, G loss: 1.2290\n",
      "[604/1600] D loss: 0.7130, G loss: 2.3536\n",
      "[724/1600] D loss: 1.0031, G loss: 1.0232\n",
      "[844/1600] D loss: 1.4852, G loss: 0.6556\n",
      "[964/1600] D loss: 1.1466, G loss: 0.8510\n",
      "[1084/1600] D loss: 0.9146, G loss: 1.0890\n",
      "[1204/1600] D loss: 1.0388, G loss: 2.4404\n",
      "[1324/1600] D loss: 1.0657, G loss: 0.8506\n",
      "[1444/1600] D loss: 1.1258, G loss: 1.6959\n",
      "[1564/1600] D loss: 1.2583, G loss: 0.9353\n",
      "train error: \n",
      " D loss: 0.994205, G loss: 1.595289, D accuracy: 72.5%, cell accuracy: 98.5%, board accuracy: 22.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.085958, G loss: 1.654039, D accuracy: 71.2%, cell accuracy: 98.3%, board accuracy: 19.0% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1774, G loss: 1.1860\n",
      "[124/1600] D loss: 0.9357, G loss: 0.8717\n",
      "[244/1600] D loss: 0.9694, G loss: 1.1552\n",
      "[364/1600] D loss: 0.5066, G loss: 1.9730\n",
      "[484/1600] D loss: 0.4066, G loss: 2.2257\n",
      "[604/1600] D loss: 0.9160, G loss: 1.1250\n",
      "[724/1600] D loss: 1.0064, G loss: 1.2218\n",
      "[844/1600] D loss: 1.0893, G loss: 1.5614\n",
      "[964/1600] D loss: 0.9476, G loss: 1.1918\n",
      "[1084/1600] D loss: 1.3231, G loss: 1.0592\n",
      "[1204/1600] D loss: 0.8084, G loss: 1.3882\n",
      "[1324/1600] D loss: 1.0672, G loss: 1.0777\n",
      "[1444/1600] D loss: 1.1982, G loss: 0.9593\n",
      "[1564/1600] D loss: 0.5673, G loss: 1.4373\n",
      "train error: \n",
      " D loss: 0.988339, G loss: 1.556474, D accuracy: 73.8%, cell accuracy: 98.5%, board accuracy: 19.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.089499, G loss: 1.602938, D accuracy: 70.4%, cell accuracy: 98.3%, board accuracy: 16.5% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8262, G loss: 1.6917\n",
      "[124/1600] D loss: 1.0000, G loss: 1.2485\n",
      "[244/1600] D loss: 0.8950, G loss: 1.4361\n",
      "[364/1600] D loss: 1.2865, G loss: 0.6440\n",
      "[484/1600] D loss: 0.5332, G loss: 2.7684\n",
      "[604/1600] D loss: 1.0160, G loss: 1.6496\n",
      "[724/1600] D loss: 1.2023, G loss: 0.7767\n",
      "[844/1600] D loss: 1.1952, G loss: 0.9603\n",
      "[964/1600] D loss: 1.1377, G loss: 0.9223\n",
      "[1084/1600] D loss: 1.1362, G loss: 1.0967\n",
      "[1204/1600] D loss: 0.7854, G loss: 1.4003\n",
      "[1324/1600] D loss: 0.2648, G loss: 2.8647\n",
      "[1444/1600] D loss: 0.7645, G loss: 1.1499\n",
      "[1564/1600] D loss: 1.3179, G loss: 0.7850\n",
      "train error: \n",
      " D loss: 0.975564, G loss: 1.389479, D accuracy: 72.8%, cell accuracy: 98.5%, board accuracy: 22.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.065471, G loss: 1.441513, D accuracy: 71.2%, cell accuracy: 98.3%, board accuracy: 20.0% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2446, G loss: 1.3945\n",
      "[124/1600] D loss: 0.5144, G loss: 1.8473\n",
      "[244/1600] D loss: 1.0239, G loss: 1.0294\n",
      "[364/1600] D loss: 0.9187, G loss: 1.4400\n",
      "[484/1600] D loss: 0.9236, G loss: 1.6217\n",
      "[604/1600] D loss: 0.6890, G loss: 1.8064\n",
      "[724/1600] D loss: 1.0346, G loss: 2.3019\n",
      "[844/1600] D loss: 1.3197, G loss: 1.0754\n",
      "[964/1600] D loss: 1.3958, G loss: 1.8815\n",
      "[1084/1600] D loss: 0.5728, G loss: 1.6653\n",
      "[1204/1600] D loss: 0.7100, G loss: 1.3528\n",
      "[1324/1600] D loss: 0.7781, G loss: 1.2412\n",
      "[1444/1600] D loss: 1.2916, G loss: 1.2578\n",
      "[1564/1600] D loss: 1.2359, G loss: 1.1921\n",
      "train error: \n",
      " D loss: 0.980149, G loss: 1.350801, D accuracy: 72.3%, cell accuracy: 98.5%, board accuracy: 20.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.054617, G loss: 1.414100, D accuracy: 69.9%, cell accuracy: 98.3%, board accuracy: 17.0% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5268, G loss: 1.7080\n",
      "[124/1600] D loss: 0.9584, G loss: 0.9745\n",
      "[244/1600] D loss: 1.1167, G loss: 1.9787\n",
      "[364/1600] D loss: 0.9912, G loss: 1.8152\n",
      "[484/1600] D loss: 0.9803, G loss: 1.0406\n",
      "[604/1600] D loss: 1.0645, G loss: 0.7725\n",
      "[724/1600] D loss: 0.5503, G loss: 1.5000\n",
      "[844/1600] D loss: 0.3440, G loss: 1.7511\n",
      "[964/1600] D loss: 0.9824, G loss: 1.7127\n",
      "[1084/1600] D loss: 1.1512, G loss: 1.0378\n",
      "[1204/1600] D loss: 0.9699, G loss: 1.2197\n",
      "[1324/1600] D loss: 1.1147, G loss: 2.4641\n",
      "[1444/1600] D loss: 1.0939, G loss: 1.4299\n",
      "[1564/1600] D loss: 1.0195, G loss: 1.2721\n",
      "train error: \n",
      " D loss: 0.987265, G loss: 1.312081, D accuracy: 72.7%, cell accuracy: 98.4%, board accuracy: 15.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.067000, G loss: 1.362704, D accuracy: 69.8%, cell accuracy: 98.3%, board accuracy: 18.5% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1410, G loss: 1.1604\n",
      "[124/1600] D loss: 0.8199, G loss: 1.6642\n",
      "[244/1600] D loss: 1.1075, G loss: 1.3259\n",
      "[364/1600] D loss: 1.1233, G loss: 1.1921\n",
      "[484/1600] D loss: 0.5145, G loss: 2.1954\n",
      "[604/1600] D loss: 1.5397, G loss: 0.9463\n",
      "[724/1600] D loss: 0.4137, G loss: 2.5467\n",
      "[844/1600] D loss: 1.4139, G loss: 1.0229\n",
      "[964/1600] D loss: 1.1114, G loss: 1.2898\n",
      "[1084/1600] D loss: 0.9020, G loss: 0.9507\n",
      "[1204/1600] D loss: 0.6262, G loss: 2.6007\n",
      "[1324/1600] D loss: 1.1111, G loss: 1.0159\n",
      "[1444/1600] D loss: 0.7167, G loss: 1.4940\n",
      "[1564/1600] D loss: 1.2945, G loss: 0.7497\n",
      "train error: \n",
      " D loss: 1.011521, G loss: 1.176431, D accuracy: 71.3%, cell accuracy: 98.5%, board accuracy: 18.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.058128, G loss: 1.233160, D accuracy: 69.9%, cell accuracy: 98.3%, board accuracy: 19.2% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7764, G loss: 1.1668\n",
      "[124/1600] D loss: 0.8159, G loss: 1.5301\n",
      "[244/1600] D loss: 0.7394, G loss: 1.6409\n",
      "[364/1600] D loss: 1.0478, G loss: 1.2756\n",
      "[484/1600] D loss: 1.0028, G loss: 1.5298\n",
      "[604/1600] D loss: 1.1987, G loss: 1.5793\n",
      "[724/1600] D loss: 0.6206, G loss: 1.8877\n",
      "[844/1600] D loss: 0.9258, G loss: 1.3118\n",
      "[964/1600] D loss: 1.0799, G loss: 1.7186\n",
      "[1084/1600] D loss: 0.8376, G loss: 1.8267\n",
      "[1204/1600] D loss: 1.1569, G loss: 0.5796\n",
      "[1324/1600] D loss: 0.9699, G loss: 2.1063\n",
      "[1444/1600] D loss: 1.1117, G loss: 1.0979\n",
      "[1564/1600] D loss: 1.0937, G loss: 1.3402\n",
      "train error: \n",
      " D loss: 1.009493, G loss: 1.323797, D accuracy: 71.5%, cell accuracy: 98.4%, board accuracy: 17.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.075256, G loss: 1.351894, D accuracy: 70.2%, cell accuracy: 98.3%, board accuracy: 18.0% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0422, G loss: 1.2035\n",
      "[124/1600] D loss: 0.7898, G loss: 1.1541\n",
      "[244/1600] D loss: 0.5179, G loss: 1.9764\n",
      "[364/1600] D loss: 1.3514, G loss: 0.7706\n",
      "[484/1600] D loss: 1.1506, G loss: 0.7874\n",
      "[604/1600] D loss: 1.1921, G loss: 1.4600\n",
      "[724/1600] D loss: 1.1679, G loss: 1.0408\n",
      "[844/1600] D loss: 1.2078, G loss: 1.2012\n",
      "[964/1600] D loss: 1.2921, G loss: 0.6278\n",
      "[1084/1600] D loss: 0.7154, G loss: 1.5863\n",
      "[1204/1600] D loss: 1.1296, G loss: 1.0395\n",
      "[1324/1600] D loss: 0.3754, G loss: 3.6281\n",
      "[1444/1600] D loss: 1.1185, G loss: 1.4602\n",
      "[1564/1600] D loss: 0.7726, G loss: 2.2607\n",
      "train error: \n",
      " D loss: 1.053037, G loss: 1.071896, D accuracy: 71.0%, cell accuracy: 98.4%, board accuracy: 17.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.103400, G loss: 1.120148, D accuracy: 69.1%, cell accuracy: 98.3%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8016, G loss: 1.3098\n",
      "[124/1600] D loss: 0.9218, G loss: 1.2227\n",
      "[244/1600] D loss: 0.8517, G loss: 1.5875\n",
      "[364/1600] D loss: 0.8260, G loss: 1.5056\n",
      "[484/1600] D loss: 1.3550, G loss: 0.8519\n",
      "[604/1600] D loss: 1.3759, G loss: 0.9085\n",
      "[724/1600] D loss: 0.5269, G loss: 1.3874\n",
      "[844/1600] D loss: 0.9394, G loss: 0.7570\n",
      "[964/1600] D loss: 1.1175, G loss: 1.0968\n",
      "[1084/1600] D loss: 0.7803, G loss: 1.3233\n",
      "[1204/1600] D loss: 0.7770, G loss: 1.4717\n",
      "[1324/1600] D loss: 0.9345, G loss: 1.9765\n",
      "[1444/1600] D loss: 0.9462, G loss: 1.2155\n",
      "[1564/1600] D loss: 0.7773, G loss: 1.2386\n",
      "train error: \n",
      " D loss: 0.982079, G loss: 1.324518, D accuracy: 73.2%, cell accuracy: 98.4%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.065765, G loss: 1.366461, D accuracy: 70.1%, cell accuracy: 98.3%, board accuracy: 17.0% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2172, G loss: 1.6442\n",
      "[124/1600] D loss: 0.4059, G loss: 1.4081\n",
      "[244/1600] D loss: 1.1086, G loss: 1.5156\n",
      "[364/1600] D loss: 0.8927, G loss: 1.3559\n",
      "[484/1600] D loss: 0.6828, G loss: 2.1301\n",
      "[604/1600] D loss: 1.4214, G loss: 0.9966\n",
      "[724/1600] D loss: 0.4736, G loss: 2.8918\n",
      "[844/1600] D loss: 1.9953, G loss: 0.7355\n",
      "[964/1600] D loss: 1.6132, G loss: 0.4721\n",
      "[1084/1600] D loss: 0.4390, G loss: 2.1946\n",
      "[1204/1600] D loss: 0.9859, G loss: 1.6497\n",
      "[1324/1600] D loss: 1.1316, G loss: 1.7121\n",
      "[1444/1600] D loss: 0.8336, G loss: 1.6415\n",
      "[1564/1600] D loss: 1.3736, G loss: 1.3309\n",
      "train error: \n",
      " D loss: 0.973646, G loss: 1.501096, D accuracy: 72.9%, cell accuracy: 98.5%, board accuracy: 18.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.067662, G loss: 1.551272, D accuracy: 70.0%, cell accuracy: 98.3%, board accuracy: 20.0% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0946, G loss: 1.6886\n",
      "[124/1600] D loss: 0.9012, G loss: 1.7882\n",
      "[244/1600] D loss: 0.9888, G loss: 1.1645\n",
      "[364/1600] D loss: 1.2920, G loss: 0.9076\n",
      "[484/1600] D loss: 1.0010, G loss: 1.0876\n",
      "[604/1600] D loss: 0.6738, G loss: 1.3084\n",
      "[724/1600] D loss: 0.8500, G loss: 1.6972\n",
      "[844/1600] D loss: 1.1139, G loss: 2.7407\n",
      "[964/1600] D loss: 1.5608, G loss: 1.2264\n",
      "[1084/1600] D loss: 1.1208, G loss: 0.8978\n",
      "[1204/1600] D loss: 0.7824, G loss: 1.3176\n",
      "[1324/1600] D loss: 1.1564, G loss: 1.4431\n",
      "[1444/1600] D loss: 0.8458, G loss: 1.9311\n",
      "[1564/1600] D loss: 0.9324, G loss: 1.1368\n",
      "train error: \n",
      " D loss: 1.006364, G loss: 1.127951, D accuracy: 72.6%, cell accuracy: 98.5%, board accuracy: 19.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.060539, G loss: 1.179617, D accuracy: 70.2%, cell accuracy: 98.3%, board accuracy: 20.8% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8584, G loss: 1.1084\n",
      "[124/1600] D loss: 0.9779, G loss: 1.2089\n",
      "[244/1600] D loss: 0.6266, G loss: 2.1825\n",
      "[364/1600] D loss: 1.0619, G loss: 2.2720\n",
      "[484/1600] D loss: 0.6918, G loss: 1.6404\n",
      "[604/1600] D loss: 0.8849, G loss: 1.1868\n",
      "[724/1600] D loss: 0.4496, G loss: 2.3078\n",
      "[844/1600] D loss: 0.1478, G loss: 2.2153\n",
      "[964/1600] D loss: 1.2053, G loss: 1.0177\n",
      "[1084/1600] D loss: 1.0775, G loss: 1.0984\n",
      "[1204/1600] D loss: 1.3660, G loss: 0.6116\n",
      "[1324/1600] D loss: 0.5252, G loss: 1.5489\n",
      "[1444/1600] D loss: 0.4777, G loss: 1.7070\n",
      "[1564/1600] D loss: 0.4346, G loss: 2.1375\n",
      "train error: \n",
      " D loss: 0.992979, G loss: 1.173224, D accuracy: 72.3%, cell accuracy: 98.5%, board accuracy: 20.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.039157, G loss: 1.220106, D accuracy: 70.4%, cell accuracy: 98.3%, board accuracy: 22.5% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9603, G loss: 1.4751\n",
      "[124/1600] D loss: 1.0787, G loss: 1.2673\n",
      "[244/1600] D loss: 1.2013, G loss: 0.9404\n",
      "[364/1600] D loss: 0.7591, G loss: 1.7268\n",
      "[484/1600] D loss: 0.6123, G loss: 2.6472\n",
      "[604/1600] D loss: 0.8766, G loss: 1.4014\n",
      "[724/1600] D loss: 1.3415, G loss: 1.0968\n",
      "[844/1600] D loss: 0.5614, G loss: 1.5690\n",
      "[964/1600] D loss: 0.6582, G loss: 2.6483\n",
      "[1084/1600] D loss: 1.1010, G loss: 1.2729\n",
      "[1204/1600] D loss: 0.4815, G loss: 2.0216\n",
      "[1324/1600] D loss: 1.1738, G loss: 1.1411\n",
      "[1444/1600] D loss: 0.6040, G loss: 1.5086\n",
      "[1564/1600] D loss: 0.8146, G loss: 1.4473\n",
      "train error: \n",
      " D loss: 0.948127, G loss: 1.420754, D accuracy: 74.0%, cell accuracy: 98.5%, board accuracy: 19.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.011490, G loss: 1.498678, D accuracy: 72.6%, cell accuracy: 98.3%, board accuracy: 19.5% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9752, G loss: 1.2159\n",
      "[124/1600] D loss: 0.8478, G loss: 1.2974\n",
      "[244/1600] D loss: 0.7022, G loss: 1.9444\n",
      "[364/1600] D loss: 0.9256, G loss: 1.0397\n",
      "[484/1600] D loss: 0.9016, G loss: 1.5348\n",
      "[604/1600] D loss: 1.0360, G loss: 1.1387\n",
      "[724/1600] D loss: 0.9596, G loss: 2.1643\n",
      "[844/1600] D loss: 1.1322, G loss: 0.9494\n",
      "[964/1600] D loss: 1.0086, G loss: 1.1809\n",
      "[1084/1600] D loss: 0.8426, G loss: 1.6053\n",
      "[1204/1600] D loss: 0.5330, G loss: 1.2181\n",
      "[1324/1600] D loss: 1.1564, G loss: 1.2105\n",
      "[1444/1600] D loss: 0.6978, G loss: 1.1821\n",
      "[1564/1600] D loss: 0.8339, G loss: 1.7463\n",
      "train error: \n",
      " D loss: 0.948433, G loss: 1.361736, D accuracy: 73.6%, cell accuracy: 98.5%, board accuracy: 22.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.037398, G loss: 1.406284, D accuracy: 71.2%, cell accuracy: 98.3%, board accuracy: 22.2% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8825, G loss: 1.7169\n",
      "[124/1600] D loss: 0.6623, G loss: 1.6565\n",
      "[244/1600] D loss: 0.8340, G loss: 1.4620\n",
      "[364/1600] D loss: 0.7793, G loss: 1.3659\n",
      "[484/1600] D loss: 0.2548, G loss: 2.8168\n",
      "[604/1600] D loss: 1.4306, G loss: 0.6510\n",
      "[724/1600] D loss: 1.5062, G loss: 1.1467\n",
      "[844/1600] D loss: 1.1034, G loss: 1.2816\n",
      "[964/1600] D loss: 0.7161, G loss: 2.4790\n",
      "[1084/1600] D loss: 0.8457, G loss: 1.0768\n",
      "[1204/1600] D loss: 0.9052, G loss: 1.7869\n",
      "[1324/1600] D loss: 0.5939, G loss: 1.5442\n",
      "[1444/1600] D loss: 1.2555, G loss: 1.4715\n",
      "[1564/1600] D loss: 1.3595, G loss: 0.7073\n",
      "train error: \n",
      " D loss: 0.973253, G loss: 1.420855, D accuracy: 72.5%, cell accuracy: 98.5%, board accuracy: 23.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.052551, G loss: 1.473470, D accuracy: 69.9%, cell accuracy: 98.3%, board accuracy: 24.2% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9690, G loss: 1.8284\n",
      "[124/1600] D loss: 1.2805, G loss: 0.5841\n",
      "[244/1600] D loss: 0.4681, G loss: 2.5320\n",
      "[364/1600] D loss: 0.7907, G loss: 1.3746\n",
      "[484/1600] D loss: 1.4534, G loss: 0.9455\n",
      "[604/1600] D loss: 0.9053, G loss: 0.8439\n",
      "[724/1600] D loss: 1.3147, G loss: 1.7218\n",
      "[844/1600] D loss: 0.7769, G loss: 1.2906\n",
      "[964/1600] D loss: 0.5370, G loss: 2.5846\n",
      "[1084/1600] D loss: 0.7699, G loss: 1.3700\n",
      "[1204/1600] D loss: 1.1773, G loss: 0.9882\n",
      "[1324/1600] D loss: 0.9388, G loss: 1.7328\n",
      "[1444/1600] D loss: 1.1903, G loss: 0.7259\n",
      "[1564/1600] D loss: 1.3918, G loss: 1.0586\n",
      "train error: \n",
      " D loss: 0.956682, G loss: 1.253420, D accuracy: 73.8%, cell accuracy: 98.5%, board accuracy: 25.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.043486, G loss: 1.299451, D accuracy: 70.6%, cell accuracy: 98.4%, board accuracy: 25.8% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8124, G loss: 2.0049\n",
      "[124/1600] D loss: 0.6272, G loss: 1.4007\n",
      "[244/1600] D loss: 0.7430, G loss: 1.3520\n",
      "[364/1600] D loss: 0.7230, G loss: 1.5339\n",
      "[484/1600] D loss: 1.3236, G loss: 0.8905\n",
      "[604/1600] D loss: 1.3918, G loss: 0.7277\n",
      "[724/1600] D loss: 1.4536, G loss: 0.7394\n",
      "[844/1600] D loss: 0.7109, G loss: 1.8690\n",
      "[964/1600] D loss: 0.3379, G loss: 2.7356\n",
      "[1084/1600] D loss: 1.1467, G loss: 1.2424\n",
      "[1204/1600] D loss: 1.2867, G loss: 0.8206\n",
      "[1324/1600] D loss: 1.0311, G loss: 0.8111\n",
      "[1444/1600] D loss: 1.2816, G loss: 1.1183\n",
      "[1564/1600] D loss: 1.1917, G loss: 0.9553\n",
      "train error: \n",
      " D loss: 0.977399, G loss: 1.264719, D accuracy: 73.1%, cell accuracy: 98.5%, board accuracy: 24.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.081569, G loss: 1.293661, D accuracy: 69.8%, cell accuracy: 98.4%, board accuracy: 24.0% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1210, G loss: 1.1814\n",
      "[124/1600] D loss: 0.7655, G loss: 2.0257\n",
      "[244/1600] D loss: 0.7930, G loss: 1.3203\n",
      "[364/1600] D loss: 1.2124, G loss: 0.7516\n",
      "[484/1600] D loss: 1.0383, G loss: 1.5429\n",
      "[604/1600] D loss: 1.1063, G loss: 1.0363\n",
      "[724/1600] D loss: 0.9364, G loss: 1.7366\n",
      "[844/1600] D loss: 1.2957, G loss: 2.0122\n",
      "[964/1600] D loss: 0.6951, G loss: 1.4746\n",
      "[1084/1600] D loss: 1.3576, G loss: 0.7913\n",
      "[1204/1600] D loss: 0.7032, G loss: 1.4081\n",
      "[1324/1600] D loss: 1.3833, G loss: 1.6573\n",
      "[1444/1600] D loss: 1.1089, G loss: 1.4246\n",
      "[1564/1600] D loss: 0.3965, G loss: 1.8655\n",
      "train error: \n",
      " D loss: 0.999092, G loss: 1.277662, D accuracy: 72.3%, cell accuracy: 98.5%, board accuracy: 25.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.099404, G loss: 1.328274, D accuracy: 69.8%, cell accuracy: 98.4%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8389, G loss: 1.6472\n",
      "[124/1600] D loss: 0.9977, G loss: 1.6862\n",
      "[244/1600] D loss: 0.7633, G loss: 1.7867\n",
      "[364/1600] D loss: 0.8773, G loss: 1.5105\n",
      "[484/1600] D loss: 0.5762, G loss: 1.7047\n",
      "[604/1600] D loss: 1.0171, G loss: 1.7563\n",
      "[724/1600] D loss: 0.8158, G loss: 2.5751\n",
      "[844/1600] D loss: 1.1532, G loss: 0.7987\n",
      "[964/1600] D loss: 0.6438, G loss: 1.6260\n",
      "[1084/1600] D loss: 1.1988, G loss: 1.3354\n",
      "[1204/1600] D loss: 0.8390, G loss: 1.3305\n",
      "[1324/1600] D loss: 0.9938, G loss: 1.2284\n",
      "[1444/1600] D loss: 1.4521, G loss: 0.8043\n",
      "[1564/1600] D loss: 0.7963, G loss: 2.3985\n",
      "train error: \n",
      " D loss: 1.000306, G loss: 1.188501, D accuracy: 71.6%, cell accuracy: 98.6%, board accuracy: 26.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.085446, G loss: 1.223535, D accuracy: 70.1%, cell accuracy: 98.4%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4174, G loss: 0.7412\n",
      "[124/1600] D loss: 1.2339, G loss: 1.9255\n",
      "[244/1600] D loss: 1.1936, G loss: 0.9100\n",
      "[364/1600] D loss: 0.6452, G loss: 1.2353\n",
      "[484/1600] D loss: 0.8353, G loss: 1.3282\n",
      "[604/1600] D loss: 0.6275, G loss: 1.3744\n",
      "[724/1600] D loss: 0.9106, G loss: 1.3902\n",
      "[844/1600] D loss: 1.0689, G loss: 1.2914\n",
      "[964/1600] D loss: 0.7321, G loss: 1.6307\n",
      "[1084/1600] D loss: 1.0243, G loss: 1.4684\n",
      "[1204/1600] D loss: 1.0687, G loss: 1.2497\n",
      "[1324/1600] D loss: 0.8107, G loss: 1.4933\n",
      "[1444/1600] D loss: 2.5399, G loss: 0.1928\n",
      "[1564/1600] D loss: 0.5146, G loss: 2.2484\n",
      "train error: \n",
      " D loss: 1.039174, G loss: 1.073047, D accuracy: 69.8%, cell accuracy: 98.5%, board accuracy: 26.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.120278, G loss: 1.110219, D accuracy: 69.1%, cell accuracy: 98.3%, board accuracy: 25.5% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3659, G loss: 1.7388\n",
      "[124/1600] D loss: 0.7439, G loss: 1.2089\n",
      "[244/1600] D loss: 1.2484, G loss: 0.9801\n",
      "[364/1600] D loss: 0.7307, G loss: 1.0050\n",
      "[484/1600] D loss: 0.8008, G loss: 2.4105\n",
      "[604/1600] D loss: 1.0982, G loss: 1.1446\n",
      "[724/1600] D loss: 0.8728, G loss: 1.5998\n",
      "[844/1600] D loss: 1.3304, G loss: 1.0047\n",
      "[964/1600] D loss: 0.7352, G loss: 1.6782\n",
      "[1084/1600] D loss: 1.3137, G loss: 1.6027\n",
      "[1204/1600] D loss: 0.5183, G loss: 2.2360\n",
      "[1324/1600] D loss: 1.0529, G loss: 0.8630\n",
      "[1444/1600] D loss: 1.1219, G loss: 2.2488\n",
      "[1564/1600] D loss: 1.0851, G loss: 1.5527\n",
      "train error: \n",
      " D loss: 0.960387, G loss: 1.603446, D accuracy: 72.3%, cell accuracy: 98.5%, board accuracy: 27.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.064379, G loss: 1.678984, D accuracy: 70.5%, cell accuracy: 98.4%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9479, G loss: 1.8721\n",
      "[124/1600] D loss: 0.7789, G loss: 1.7533\n",
      "[244/1600] D loss: 0.9488, G loss: 0.9616\n",
      "[364/1600] D loss: 0.7962, G loss: 1.3814\n",
      "[484/1600] D loss: 1.0873, G loss: 1.5567\n",
      "[604/1600] D loss: 0.8656, G loss: 0.9500\n",
      "[724/1600] D loss: 0.9582, G loss: 1.3180\n",
      "[844/1600] D loss: 1.0618, G loss: 1.5888\n",
      "[964/1600] D loss: 0.7332, G loss: 2.2081\n",
      "[1084/1600] D loss: 1.0581, G loss: 1.6719\n",
      "[1204/1600] D loss: 0.3511, G loss: 1.6640\n",
      "[1324/1600] D loss: 0.9427, G loss: 1.4713\n",
      "[1444/1600] D loss: 0.8968, G loss: 1.2678\n",
      "[1564/1600] D loss: 0.7090, G loss: 1.6433\n",
      "train error: \n",
      " D loss: 0.966497, G loss: 1.557659, D accuracy: 71.2%, cell accuracy: 98.6%, board accuracy: 29.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.068435, G loss: 1.639015, D accuracy: 69.2%, cell accuracy: 98.4%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2682, G loss: 0.9247\n",
      "[124/1600] D loss: 1.4036, G loss: 1.1506\n",
      "[244/1600] D loss: 0.7949, G loss: 1.1438\n",
      "[364/1600] D loss: 0.7767, G loss: 1.8377\n",
      "[484/1600] D loss: 0.6627, G loss: 1.2746\n",
      "[604/1600] D loss: 1.5166, G loss: 0.9227\n",
      "[724/1600] D loss: 0.7135, G loss: 1.2328\n",
      "[844/1600] D loss: 0.8198, G loss: 1.5102\n",
      "[964/1600] D loss: 0.8090, G loss: 1.2249\n",
      "[1084/1600] D loss: 0.4714, G loss: 1.6534\n",
      "[1204/1600] D loss: 1.0466, G loss: 1.0782\n",
      "[1324/1600] D loss: 1.4694, G loss: 0.8463\n",
      "[1444/1600] D loss: 0.7151, G loss: 1.3177\n",
      "[1564/1600] D loss: 0.6375, G loss: 1.3472\n",
      "train error: \n",
      " D loss: 0.988014, G loss: 1.614848, D accuracy: 71.9%, cell accuracy: 98.6%, board accuracy: 27.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.090439, G loss: 1.664072, D accuracy: 70.2%, cell accuracy: 98.4%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0331, G loss: 1.4368\n",
      "[124/1600] D loss: 0.6032, G loss: 1.7303\n",
      "[244/1600] D loss: 0.7077, G loss: 1.5817\n",
      "[364/1600] D loss: 0.9497, G loss: 1.3213\n",
      "[484/1600] D loss: 1.0200, G loss: 1.0855\n",
      "[604/1600] D loss: 0.5835, G loss: 1.4361\n",
      "[724/1600] D loss: 0.9933, G loss: 1.3802\n",
      "[844/1600] D loss: 0.3280, G loss: 2.1137\n",
      "[964/1600] D loss: 0.7684, G loss: 1.4823\n",
      "[1084/1600] D loss: 0.8212, G loss: 1.5581\n",
      "[1204/1600] D loss: 1.2907, G loss: 0.7392\n",
      "[1324/1600] D loss: 0.8300, G loss: 1.6120\n",
      "[1444/1600] D loss: 0.7870, G loss: 1.8979\n",
      "[1564/1600] D loss: 1.1852, G loss: 0.8740\n",
      "train error: \n",
      " D loss: 1.002981, G loss: 1.167125, D accuracy: 71.8%, cell accuracy: 98.6%, board accuracy: 27.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.093889, G loss: 1.219368, D accuracy: 68.4%, cell accuracy: 98.4%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1430, G loss: 0.9265\n",
      "[124/1600] D loss: 1.3435, G loss: 0.5458\n",
      "[244/1600] D loss: 0.9919, G loss: 1.8592\n",
      "[364/1600] D loss: 1.1002, G loss: 0.9763\n",
      "[484/1600] D loss: 1.0354, G loss: 1.4611\n",
      "[604/1600] D loss: 0.9334, G loss: 1.5083\n",
      "[724/1600] D loss: 0.9260, G loss: 1.5842\n",
      "[844/1600] D loss: 0.6817, G loss: 1.7703\n",
      "[964/1600] D loss: 1.3603, G loss: 1.3746\n",
      "[1084/1600] D loss: 0.6050, G loss: 1.5409\n",
      "[1204/1600] D loss: 1.1199, G loss: 1.0556\n",
      "[1324/1600] D loss: 0.9652, G loss: 0.9395\n",
      "[1444/1600] D loss: 0.9392, G loss: 1.0784\n",
      "[1564/1600] D loss: 0.7488, G loss: 1.3064\n",
      "train error: \n",
      " D loss: 0.949366, G loss: 1.496183, D accuracy: 73.2%, cell accuracy: 98.6%, board accuracy: 27.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.071237, G loss: 1.534676, D accuracy: 69.2%, cell accuracy: 98.4%, board accuracy: 27.8% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9236, G loss: 2.2363\n",
      "[124/1600] D loss: 1.0555, G loss: 1.5441\n",
      "[244/1600] D loss: 0.5316, G loss: 1.6340\n",
      "[364/1600] D loss: 0.8566, G loss: 2.1540\n",
      "[484/1600] D loss: 0.5798, G loss: 2.0842\n",
      "[604/1600] D loss: 1.0003, G loss: 1.5163\n",
      "[724/1600] D loss: 0.9775, G loss: 1.0411\n",
      "[844/1600] D loss: 0.2838, G loss: 2.3536\n",
      "[964/1600] D loss: 1.3734, G loss: 0.8084\n",
      "[1084/1600] D loss: 1.3326, G loss: 1.1822\n",
      "[1204/1600] D loss: 1.1974, G loss: 1.1939\n",
      "[1324/1600] D loss: 0.6578, G loss: 1.2568\n",
      "[1444/1600] D loss: 0.4311, G loss: 1.8461\n",
      "[1564/1600] D loss: 1.3264, G loss: 1.4427\n",
      "train error: \n",
      " D loss: 0.953775, G loss: 1.425327, D accuracy: 73.5%, cell accuracy: 98.6%, board accuracy: 28.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.049095, G loss: 1.499203, D accuracy: 70.2%, cell accuracy: 98.4%, board accuracy: 30.2% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6180, G loss: 1.5970\n",
      "[124/1600] D loss: 1.0689, G loss: 2.0188\n",
      "[244/1600] D loss: 1.1750, G loss: 1.2872\n",
      "[364/1600] D loss: 1.0574, G loss: 1.8038\n",
      "[484/1600] D loss: 0.8298, G loss: 1.5730\n",
      "[604/1600] D loss: 1.1481, G loss: 0.6620\n",
      "[724/1600] D loss: 0.7902, G loss: 1.3935\n",
      "[844/1600] D loss: 0.9922, G loss: 0.9949\n",
      "[964/1600] D loss: 1.4992, G loss: 0.6369\n",
      "[1084/1600] D loss: 0.9825, G loss: 1.5065\n",
      "[1204/1600] D loss: 0.8727, G loss: 1.4068\n",
      "[1324/1600] D loss: 0.7955, G loss: 2.0646\n",
      "[1444/1600] D loss: 1.0811, G loss: 0.9081\n",
      "[1564/1600] D loss: 0.9633, G loss: 1.2205\n",
      "train error: \n",
      " D loss: 0.966006, G loss: 1.387899, D accuracy: 73.2%, cell accuracy: 98.6%, board accuracy: 29.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.060678, G loss: 1.491124, D accuracy: 70.4%, cell accuracy: 98.4%, board accuracy: 29.2% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5135, G loss: 0.8590\n",
      "[124/1600] D loss: 0.8785, G loss: 1.3266\n",
      "[244/1600] D loss: 1.2451, G loss: 1.1001\n",
      "[364/1600] D loss: 1.0022, G loss: 1.3231\n",
      "[484/1600] D loss: 0.6501, G loss: 1.7739\n",
      "[604/1600] D loss: 0.3075, G loss: 1.9792\n",
      "[724/1600] D loss: 1.0024, G loss: 0.7608\n",
      "[844/1600] D loss: 0.7018, G loss: 1.4540\n",
      "[964/1600] D loss: 1.1760, G loss: 0.8855\n",
      "[1084/1600] D loss: 0.4692, G loss: 2.4850\n",
      "[1204/1600] D loss: 1.3472, G loss: 0.8630\n",
      "[1324/1600] D loss: 1.1386, G loss: 0.8547\n",
      "[1444/1600] D loss: 1.2941, G loss: 0.8594\n",
      "[1564/1600] D loss: 0.8552, G loss: 1.2829\n",
      "train error: \n",
      " D loss: 0.940801, G loss: 1.436214, D accuracy: 73.5%, cell accuracy: 98.5%, board accuracy: 25.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.048530, G loss: 1.521714, D accuracy: 70.6%, cell accuracy: 98.3%, board accuracy: 24.2% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2704, G loss: 1.0003\n",
      "[124/1600] D loss: 0.5302, G loss: 2.2636\n",
      "[244/1600] D loss: 0.7732, G loss: 2.3394\n",
      "[364/1600] D loss: 0.6928, G loss: 1.2996\n",
      "[484/1600] D loss: 1.0438, G loss: 0.8117\n",
      "[604/1600] D loss: 1.3647, G loss: 0.7469\n",
      "[724/1600] D loss: 0.9241, G loss: 1.2482\n",
      "[844/1600] D loss: 0.4949, G loss: 1.9607\n",
      "[964/1600] D loss: 0.5398, G loss: 1.8726\n",
      "[1084/1600] D loss: 1.3316, G loss: 1.0574\n",
      "[1204/1600] D loss: 1.0287, G loss: 1.5179\n",
      "[1324/1600] D loss: 0.7457, G loss: 1.2807\n",
      "[1444/1600] D loss: 0.5239, G loss: 1.5520\n",
      "[1564/1600] D loss: 0.8031, G loss: 1.3693\n",
      "train error: \n",
      " D loss: 0.961645, G loss: 1.331047, D accuracy: 71.8%, cell accuracy: 98.6%, board accuracy: 29.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.051534, G loss: 1.408552, D accuracy: 70.5%, cell accuracy: 98.4%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9936, G loss: 1.1535\n",
      "[124/1600] D loss: 0.7317, G loss: 1.7874\n",
      "[244/1600] D loss: 0.7412, G loss: 1.9015\n",
      "[364/1600] D loss: 1.0942, G loss: 1.1930\n",
      "[484/1600] D loss: 0.9547, G loss: 1.2770\n",
      "[604/1600] D loss: 0.6851, G loss: 1.4975\n",
      "[724/1600] D loss: 0.6573, G loss: 1.6061\n",
      "[844/1600] D loss: 0.7112, G loss: 1.0174\n",
      "[964/1600] D loss: 0.7334, G loss: 2.0853\n",
      "[1084/1600] D loss: 0.7445, G loss: 2.6292\n",
      "[1204/1600] D loss: 0.9033, G loss: 1.1203\n",
      "[1324/1600] D loss: 0.8654, G loss: 1.0302\n",
      "[1444/1600] D loss: 1.0445, G loss: 1.0650\n",
      "[1564/1600] D loss: 1.7691, G loss: 1.2405\n",
      "train error: \n",
      " D loss: 0.963335, G loss: 1.207217, D accuracy: 72.9%, cell accuracy: 98.5%, board accuracy: 25.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.038606, G loss: 1.312742, D accuracy: 71.0%, cell accuracy: 98.2%, board accuracy: 23.2% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7128, G loss: 1.3572\n",
      "[124/1600] D loss: 1.0669, G loss: 0.8558\n",
      "[244/1600] D loss: 0.7576, G loss: 1.6440\n",
      "[364/1600] D loss: 1.0300, G loss: 0.8558\n",
      "[484/1600] D loss: 1.7047, G loss: 0.8218\n",
      "[604/1600] D loss: 0.9354, G loss: 1.3651\n",
      "[724/1600] D loss: 1.0047, G loss: 1.3591\n",
      "[844/1600] D loss: 0.7277, G loss: 2.1387\n",
      "[964/1600] D loss: 1.2300, G loss: 0.7319\n",
      "[1084/1600] D loss: 1.4225, G loss: 1.1711\n",
      "[1204/1600] D loss: 0.9206, G loss: 1.7729\n",
      "[1324/1600] D loss: 1.1726, G loss: 0.8967\n",
      "[1444/1600] D loss: 1.3765, G loss: 1.7783\n",
      "[1564/1600] D loss: 0.8924, G loss: 0.7576\n",
      "train error: \n",
      " D loss: 0.949619, G loss: 1.600034, D accuracy: 72.9%, cell accuracy: 98.5%, board accuracy: 26.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.065656, G loss: 1.717660, D accuracy: 70.2%, cell accuracy: 98.3%, board accuracy: 26.5% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1359, G loss: 1.4134\n",
      "[124/1600] D loss: 0.8018, G loss: 1.4061\n",
      "[244/1600] D loss: 0.6689, G loss: 1.4890\n",
      "[364/1600] D loss: 1.7054, G loss: 0.5785\n",
      "[484/1600] D loss: 1.1927, G loss: 0.9136\n",
      "[604/1600] D loss: 0.5298, G loss: 1.5847\n",
      "[724/1600] D loss: 1.2339, G loss: 0.7391\n",
      "[844/1600] D loss: 1.5290, G loss: 0.5288\n",
      "[964/1600] D loss: 0.6330, G loss: 1.5586\n",
      "[1084/1600] D loss: 1.2491, G loss: 0.9675\n",
      "[1204/1600] D loss: 1.1324, G loss: 0.9590\n",
      "[1324/1600] D loss: 0.2274, G loss: 2.8376\n",
      "[1444/1600] D loss: 1.3211, G loss: 0.6849\n",
      "[1564/1600] D loss: 0.6984, G loss: 1.7072\n",
      "train error: \n",
      " D loss: 0.936189, G loss: 1.408799, D accuracy: 73.8%, cell accuracy: 98.5%, board accuracy: 26.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.010526, G loss: 1.530307, D accuracy: 71.4%, cell accuracy: 98.3%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1687, G loss: 0.9400\n",
      "[124/1600] D loss: 0.7755, G loss: 1.5390\n",
      "[244/1600] D loss: 0.5658, G loss: 2.5691\n",
      "[364/1600] D loss: 0.4733, G loss: 2.9007\n",
      "[484/1600] D loss: 1.2563, G loss: 0.8936\n",
      "[604/1600] D loss: 1.3582, G loss: 0.9985\n",
      "[724/1600] D loss: 0.9194, G loss: 2.0187\n",
      "[844/1600] D loss: 0.4677, G loss: 1.8481\n",
      "[964/1600] D loss: 1.0469, G loss: 1.1858\n",
      "[1084/1600] D loss: 0.8136, G loss: 1.1730\n",
      "[1204/1600] D loss: 1.1272, G loss: 0.7477\n",
      "[1324/1600] D loss: 0.4794, G loss: 2.7653\n",
      "[1444/1600] D loss: 0.8924, G loss: 1.6964\n",
      "[1564/1600] D loss: 1.3361, G loss: 1.2397\n",
      "train error: \n",
      " D loss: 0.981443, G loss: 1.398983, D accuracy: 72.5%, cell accuracy: 98.3%, board accuracy: 26.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.077058, G loss: 1.530022, D accuracy: 70.0%, cell accuracy: 98.0%, board accuracy: 26.0% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8819, G loss: 1.5135\n",
      "[124/1600] D loss: 0.8165, G loss: 1.1869\n",
      "[244/1600] D loss: 0.7071, G loss: 1.1708\n",
      "[364/1600] D loss: 1.6525, G loss: 1.8188\n",
      "[484/1600] D loss: 1.2178, G loss: 1.5982\n",
      "[604/1600] D loss: 1.4698, G loss: 0.6851\n",
      "[724/1600] D loss: 0.9422, G loss: 1.9950\n",
      "[844/1600] D loss: 0.6725, G loss: 2.0488\n",
      "[964/1600] D loss: 0.4642, G loss: 1.6532\n",
      "[1084/1600] D loss: 0.6770, G loss: 1.2492\n",
      "[1204/1600] D loss: 1.4490, G loss: 0.5534\n",
      "[1324/1600] D loss: 1.3514, G loss: 0.7194\n",
      "[1444/1600] D loss: 1.3823, G loss: 0.9704\n",
      "[1564/1600] D loss: 1.5550, G loss: 1.0661\n",
      "train error: \n",
      " D loss: 0.998202, G loss: 1.646087, D accuracy: 70.7%, cell accuracy: 98.3%, board accuracy: 28.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.098592, G loss: 1.782733, D accuracy: 69.9%, cell accuracy: 98.0%, board accuracy: 25.5% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0063, G loss: 1.5937\n",
      "[124/1600] D loss: 0.9476, G loss: 1.4071\n",
      "[244/1600] D loss: 1.1485, G loss: 1.0828\n",
      "[364/1600] D loss: 1.7825, G loss: 0.8775\n",
      "[484/1600] D loss: 1.3671, G loss: 0.7988\n",
      "[604/1600] D loss: 0.8543, G loss: 1.4888\n",
      "[724/1600] D loss: 0.9793, G loss: 0.9796\n",
      "[844/1600] D loss: 0.8318, G loss: 2.5708\n",
      "[964/1600] D loss: 0.8883, G loss: 1.4020\n",
      "[1084/1600] D loss: 0.8925, G loss: 1.5780\n",
      "[1204/1600] D loss: 1.3818, G loss: 0.6646\n",
      "[1324/1600] D loss: 0.7058, G loss: 1.2075\n",
      "[1444/1600] D loss: 1.1090, G loss: 2.8731\n",
      "[1564/1600] D loss: 0.6127, G loss: 2.3802\n",
      "train error: \n",
      " D loss: 0.995803, G loss: 1.604021, D accuracy: 71.2%, cell accuracy: 98.4%, board accuracy: 27.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.109568, G loss: 1.702659, D accuracy: 69.5%, cell accuracy: 98.2%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7436, G loss: 1.5572\n",
      "[124/1600] D loss: 0.5688, G loss: 2.1109\n",
      "[244/1600] D loss: 0.9554, G loss: 1.5081\n",
      "[364/1600] D loss: 0.7876, G loss: 2.1060\n",
      "[484/1600] D loss: 1.2035, G loss: 1.1675\n",
      "[604/1600] D loss: 0.6635, G loss: 2.0517\n",
      "[724/1600] D loss: 0.7961, G loss: 1.2224\n",
      "[844/1600] D loss: 1.2952, G loss: 0.8073\n",
      "[964/1600] D loss: 0.3414, G loss: 2.5376\n",
      "[1084/1600] D loss: 1.1411, G loss: 1.4584\n",
      "[1204/1600] D loss: 0.5815, G loss: 2.2042\n",
      "[1324/1600] D loss: 1.5045, G loss: 0.8464\n",
      "[1444/1600] D loss: 0.9366, G loss: 1.1479\n",
      "[1564/1600] D loss: 1.2934, G loss: 0.9654\n",
      "train error: \n",
      " D loss: 0.983633, G loss: 1.600233, D accuracy: 70.6%, cell accuracy: 98.3%, board accuracy: 29.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.082894, G loss: 1.717271, D accuracy: 69.0%, cell accuracy: 98.1%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9004, G loss: 1.4022\n",
      "[124/1600] D loss: 0.8928, G loss: 1.4227\n",
      "[244/1600] D loss: 0.6758, G loss: 1.4163\n",
      "[364/1600] D loss: 0.8967, G loss: 1.9426\n",
      "[484/1600] D loss: 1.4823, G loss: 0.4290\n",
      "[604/1600] D loss: 0.7291, G loss: 1.4483\n",
      "[724/1600] D loss: 0.7878, G loss: 1.7714\n",
      "[844/1600] D loss: 1.3418, G loss: 0.9045\n",
      "[964/1600] D loss: 0.6720, G loss: 1.9046\n",
      "[1084/1600] D loss: 1.1376, G loss: 1.3091\n",
      "[1204/1600] D loss: 1.0712, G loss: 1.3001\n",
      "[1324/1600] D loss: 0.9091, G loss: 1.1224\n",
      "[1444/1600] D loss: 1.0734, G loss: 1.2440\n",
      "[1564/1600] D loss: 0.5468, G loss: 1.7284\n",
      "train error: \n",
      " D loss: 0.958114, G loss: 1.510096, D accuracy: 72.0%, cell accuracy: 98.3%, board accuracy: 28.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.041020, G loss: 1.628569, D accuracy: 70.8%, cell accuracy: 98.0%, board accuracy: 25.2% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7363, G loss: 1.6168\n",
      "[124/1600] D loss: 0.4717, G loss: 1.9904\n",
      "[244/1600] D loss: 1.2448, G loss: 2.6615\n",
      "[364/1600] D loss: 1.3893, G loss: 0.7080\n",
      "[484/1600] D loss: 0.6892, G loss: 1.4812\n",
      "[604/1600] D loss: 0.9636, G loss: 1.5475\n",
      "[724/1600] D loss: 0.4010, G loss: 2.4963\n",
      "[844/1600] D loss: 0.6402, G loss: 1.3911\n",
      "[964/1600] D loss: 1.2495, G loss: 1.1786\n",
      "[1084/1600] D loss: 1.0343, G loss: 1.6832\n",
      "[1204/1600] D loss: 0.7562, G loss: 2.1353\n",
      "[1324/1600] D loss: 1.1194, G loss: 1.3144\n",
      "[1444/1600] D loss: 1.0505, G loss: 1.3121\n",
      "[1564/1600] D loss: 0.7023, G loss: 2.8888\n",
      "train error: \n",
      " D loss: 1.025823, G loss: 1.165425, D accuracy: 70.5%, cell accuracy: 98.4%, board accuracy: 29.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.102970, G loss: 1.265461, D accuracy: 68.4%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7679, G loss: 1.3296\n",
      "[124/1600] D loss: 0.6347, G loss: 2.2465\n",
      "[244/1600] D loss: 1.2352, G loss: 0.6531\n",
      "[364/1600] D loss: 0.6001, G loss: 2.1744\n",
      "[484/1600] D loss: 0.5880, G loss: 1.5048\n",
      "[604/1600] D loss: 0.6267, G loss: 2.2847\n",
      "[724/1600] D loss: 1.1858, G loss: 1.6443\n",
      "[844/1600] D loss: 0.9049, G loss: 1.5479\n",
      "[964/1600] D loss: 1.1887, G loss: 0.8067\n",
      "[1084/1600] D loss: 0.7802, G loss: 1.6459\n",
      "[1204/1600] D loss: 1.1159, G loss: 1.0686\n",
      "[1324/1600] D loss: 1.0898, G loss: 1.0041\n",
      "[1444/1600] D loss: 0.9552, G loss: 0.9463\n",
      "[1564/1600] D loss: 1.1135, G loss: 0.9567\n",
      "train error: \n",
      " D loss: 0.961528, G loss: 1.354411, D accuracy: 72.2%, cell accuracy: 98.5%, board accuracy: 28.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.038285, G loss: 1.456911, D accuracy: 71.0%, cell accuracy: 98.3%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1570, G loss: 0.9276\n",
      "[124/1600] D loss: 0.7725, G loss: 1.7655\n",
      "[244/1600] D loss: 0.7455, G loss: 1.5029\n",
      "[364/1600] D loss: 1.0042, G loss: 1.2811\n",
      "[484/1600] D loss: 0.6641, G loss: 1.8132\n",
      "[604/1600] D loss: 0.9704, G loss: 0.9990\n",
      "[724/1600] D loss: 1.2846, G loss: 1.1120\n",
      "[844/1600] D loss: 0.7666, G loss: 2.4139\n",
      "[964/1600] D loss: 1.0047, G loss: 1.1037\n",
      "[1084/1600] D loss: 1.1566, G loss: 1.0305\n",
      "[1204/1600] D loss: 0.4655, G loss: 2.3733\n",
      "[1324/1600] D loss: 1.5828, G loss: 0.9344\n",
      "[1444/1600] D loss: 0.8107, G loss: 1.8087\n",
      "[1564/1600] D loss: 1.0571, G loss: 1.1099\n",
      "train error: \n",
      " D loss: 0.963033, G loss: 1.397425, D accuracy: 72.1%, cell accuracy: 98.4%, board accuracy: 29.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.051373, G loss: 1.534547, D accuracy: 69.9%, cell accuracy: 98.2%, board accuracy: 26.2% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8241, G loss: 1.6182\n",
      "[124/1600] D loss: 1.2089, G loss: 2.0552\n",
      "[244/1600] D loss: 1.2660, G loss: 0.9914\n",
      "[364/1600] D loss: 0.8413, G loss: 1.3983\n",
      "[484/1600] D loss: 1.1053, G loss: 2.0955\n",
      "[604/1600] D loss: 0.9040, G loss: 2.0987\n",
      "[724/1600] D loss: 1.1454, G loss: 0.9314\n",
      "[844/1600] D loss: 0.5579, G loss: 2.2924\n",
      "[964/1600] D loss: 0.2920, G loss: 1.6404\n",
      "[1084/1600] D loss: 1.0013, G loss: 1.7925\n",
      "[1204/1600] D loss: 1.2734, G loss: 0.6970\n",
      "[1324/1600] D loss: 1.2761, G loss: 0.8256\n",
      "[1444/1600] D loss: 1.2744, G loss: 0.8095\n",
      "[1564/1600] D loss: 0.2466, G loss: 2.4370\n",
      "train error: \n",
      " D loss: 0.982225, G loss: 1.565475, D accuracy: 71.6%, cell accuracy: 98.3%, board accuracy: 30.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.080915, G loss: 1.674357, D accuracy: 70.4%, cell accuracy: 98.1%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1345, G loss: 1.4037\n",
      "[124/1600] D loss: 1.0553, G loss: 0.9177\n",
      "[244/1600] D loss: 1.1284, G loss: 1.7628\n",
      "[364/1600] D loss: 0.9139, G loss: 1.2546\n",
      "[484/1600] D loss: 1.0206, G loss: 1.8107\n",
      "[604/1600] D loss: 1.2644, G loss: 1.0394\n",
      "[724/1600] D loss: 0.4320, G loss: 2.0886\n",
      "[844/1600] D loss: 0.6776, G loss: 2.0079\n",
      "[964/1600] D loss: 1.0895, G loss: 2.0056\n",
      "[1084/1600] D loss: 1.1834, G loss: 1.4457\n",
      "[1204/1600] D loss: 0.6785, G loss: 1.4307\n",
      "[1324/1600] D loss: 0.5004, G loss: 1.7727\n",
      "[1444/1600] D loss: 1.2089, G loss: 1.4441\n",
      "[1564/1600] D loss: 0.6177, G loss: 1.4177\n",
      "train error: \n",
      " D loss: 1.011922, G loss: 1.231141, D accuracy: 70.1%, cell accuracy: 98.5%, board accuracy: 31.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.089811, G loss: 1.322627, D accuracy: 67.8%, cell accuracy: 98.3%, board accuracy: 31.5% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4402, G loss: 2.0504\n",
      "[124/1600] D loss: 0.7410, G loss: 2.0151\n",
      "[244/1600] D loss: 0.8440, G loss: 1.4697\n",
      "[364/1600] D loss: 0.9032, G loss: 2.8282\n",
      "[484/1600] D loss: 0.7546, G loss: 2.4849\n",
      "[604/1600] D loss: 0.8073, G loss: 1.5816\n",
      "[724/1600] D loss: 1.1563, G loss: 1.6568\n",
      "[844/1600] D loss: 0.3941, G loss: 2.9758\n",
      "[964/1600] D loss: 0.8017, G loss: 1.4233\n",
      "[1084/1600] D loss: 1.0290, G loss: 1.1456\n",
      "[1204/1600] D loss: 1.3852, G loss: 0.9752\n",
      "[1324/1600] D loss: 1.0902, G loss: 1.1063\n",
      "[1444/1600] D loss: 1.0767, G loss: 1.0399\n",
      "[1564/1600] D loss: 1.0551, G loss: 1.5280\n",
      "train error: \n",
      " D loss: 1.003256, G loss: 1.768083, D accuracy: 69.8%, cell accuracy: 98.5%, board accuracy: 33.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.145484, G loss: 1.873907, D accuracy: 68.0%, cell accuracy: 98.3%, board accuracy: 33.0% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5982, G loss: 2.2320\n",
      "[124/1600] D loss: 0.8252, G loss: 2.5141\n",
      "[244/1600] D loss: 0.9914, G loss: 2.0315\n",
      "[364/1600] D loss: 1.2187, G loss: 0.8242\n",
      "[484/1600] D loss: 0.7792, G loss: 1.8825\n",
      "[604/1600] D loss: 1.0221, G loss: 1.9663\n",
      "[724/1600] D loss: 0.8448, G loss: 2.1889\n",
      "[844/1600] D loss: 0.9035, G loss: 1.2026\n",
      "[964/1600] D loss: 1.0281, G loss: 0.9403\n",
      "[1084/1600] D loss: 0.9926, G loss: 1.1247\n",
      "[1204/1600] D loss: 1.0579, G loss: 1.7289\n",
      "[1324/1600] D loss: 0.4173, G loss: 1.8747\n",
      "[1444/1600] D loss: 0.6696, G loss: 1.6356\n",
      "[1564/1600] D loss: 1.4254, G loss: 1.5163\n",
      "train error: \n",
      " D loss: 1.001373, G loss: 1.563268, D accuracy: 70.9%, cell accuracy: 98.6%, board accuracy: 31.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.121720, G loss: 1.694821, D accuracy: 68.8%, cell accuracy: 98.4%, board accuracy: 30.8% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3033, G loss: 1.6275\n",
      "[124/1600] D loss: 0.7584, G loss: 1.4151\n",
      "[244/1600] D loss: 0.9005, G loss: 1.3384\n",
      "[364/1600] D loss: 1.3502, G loss: 0.7006\n",
      "[484/1600] D loss: 1.0595, G loss: 1.4342\n",
      "[604/1600] D loss: 0.9138, G loss: 1.0859\n",
      "[724/1600] D loss: 0.8361, G loss: 2.5621\n",
      "[844/1600] D loss: 0.8439, G loss: 1.4837\n",
      "[964/1600] D loss: 1.2766, G loss: 1.0243\n",
      "[1084/1600] D loss: 1.1704, G loss: 0.8849\n",
      "[1204/1600] D loss: 1.0748, G loss: 1.1626\n",
      "[1324/1600] D loss: 1.0141, G loss: 1.4210\n",
      "[1444/1600] D loss: 1.1241, G loss: 1.0989\n",
      "[1564/1600] D loss: 0.5703, G loss: 1.7498\n",
      "train error: \n",
      " D loss: 0.972558, G loss: 1.470301, D accuracy: 71.6%, cell accuracy: 98.7%, board accuracy: 35.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.090373, G loss: 1.574250, D accuracy: 69.9%, cell accuracy: 98.5%, board accuracy: 32.0% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7169, G loss: 1.2470\n",
      "[124/1600] D loss: 0.5938, G loss: 2.2254\n",
      "[244/1600] D loss: 1.1591, G loss: 0.8106\n",
      "[364/1600] D loss: 1.3681, G loss: 0.9739\n",
      "[484/1600] D loss: 0.7571, G loss: 1.4387\n",
      "[604/1600] D loss: 0.5303, G loss: 2.3888\n",
      "[724/1600] D loss: 0.2527, G loss: 2.3713\n",
      "[844/1600] D loss: 1.3032, G loss: 0.8792\n",
      "[964/1600] D loss: 0.1578, G loss: 3.4326\n",
      "[1084/1600] D loss: 0.8431, G loss: 1.3502\n",
      "[1204/1600] D loss: 0.8763, G loss: 1.8404\n",
      "[1324/1600] D loss: 0.7880, G loss: 1.5366\n",
      "[1444/1600] D loss: 0.8167, G loss: 1.6629\n",
      "[1564/1600] D loss: 0.5979, G loss: 1.8959\n",
      "train error: \n",
      " D loss: 1.002050, G loss: 1.575304, D accuracy: 70.8%, cell accuracy: 98.5%, board accuracy: 21.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.112416, G loss: 1.664038, D accuracy: 68.4%, cell accuracy: 98.3%, board accuracy: 20.0% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5420, G loss: 2.7210\n",
      "[124/1600] D loss: 1.1793, G loss: 1.0672\n",
      "[244/1600] D loss: 0.8304, G loss: 1.6913\n",
      "[364/1600] D loss: 0.9021, G loss: 2.6256\n",
      "[484/1600] D loss: 1.7651, G loss: 0.6762\n",
      "[604/1600] D loss: 1.2265, G loss: 1.2835\n",
      "[724/1600] D loss: 0.7859, G loss: 1.4411\n",
      "[844/1600] D loss: 1.2012, G loss: 0.9101\n",
      "[964/1600] D loss: 0.7113, G loss: 1.5561\n",
      "[1084/1600] D loss: 1.2908, G loss: 0.7379\n",
      "[1204/1600] D loss: 0.8712, G loss: 1.6718\n",
      "[1324/1600] D loss: 0.2612, G loss: 2.5161\n",
      "[1444/1600] D loss: 1.1251, G loss: 1.0994\n",
      "[1564/1600] D loss: 1.1169, G loss: 1.4834\n",
      "train error: \n",
      " D loss: 1.022083, G loss: 1.093018, D accuracy: 70.2%, cell accuracy: 98.7%, board accuracy: 35.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.134547, G loss: 1.150567, D accuracy: 66.0%, cell accuracy: 98.5%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9299, G loss: 0.9577\n",
      "[124/1600] D loss: 1.2549, G loss: 1.1352\n",
      "[244/1600] D loss: 0.5880, G loss: 2.3829\n",
      "[364/1600] D loss: 1.1254, G loss: 0.7785\n",
      "[484/1600] D loss: 0.8236, G loss: 1.9491\n",
      "[604/1600] D loss: 1.4192, G loss: 1.0003\n",
      "[724/1600] D loss: 0.5280, G loss: 2.5973\n",
      "[844/1600] D loss: 1.1174, G loss: 1.3590\n",
      "[964/1600] D loss: 1.1066, G loss: 1.3791\n",
      "[1084/1600] D loss: 0.6633, G loss: 2.2067\n",
      "[1204/1600] D loss: 1.0256, G loss: 1.0492\n",
      "[1324/1600] D loss: 0.4631, G loss: 2.5537\n",
      "[1444/1600] D loss: 0.6127, G loss: 1.7466\n",
      "[1564/1600] D loss: 1.0870, G loss: 1.1502\n",
      "train error: \n",
      " D loss: 0.993263, G loss: 1.506255, D accuracy: 70.3%, cell accuracy: 98.7%, board accuracy: 36.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.127779, G loss: 1.558670, D accuracy: 66.6%, cell accuracy: 98.5%, board accuracy: 36.5% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9214, G loss: 1.9672\n",
      "[124/1600] D loss: 0.9985, G loss: 1.1585\n",
      "[244/1600] D loss: 0.9338, G loss: 0.9875\n",
      "[364/1600] D loss: 1.0837, G loss: 1.5045\n",
      "[484/1600] D loss: 0.4692, G loss: 2.5534\n",
      "[604/1600] D loss: 1.3231, G loss: 1.1190\n",
      "[724/1600] D loss: 1.1848, G loss: 0.8219\n",
      "[844/1600] D loss: 1.2451, G loss: 0.8056\n",
      "[964/1600] D loss: 0.4904, G loss: 2.4851\n",
      "[1084/1600] D loss: 0.4349, G loss: 1.5538\n",
      "[1204/1600] D loss: 1.1896, G loss: 1.4650\n",
      "[1324/1600] D loss: 1.4879, G loss: 0.8307\n",
      "[1444/1600] D loss: 1.2429, G loss: 1.1025\n",
      "[1564/1600] D loss: 1.1711, G loss: 2.1775\n",
      "train error: \n",
      " D loss: 0.996506, G loss: 1.438042, D accuracy: 70.6%, cell accuracy: 98.6%, board accuracy: 35.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.108435, G loss: 1.530030, D accuracy: 68.6%, cell accuracy: 98.5%, board accuracy: 34.0% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0112, G loss: 0.8912\n",
      "[124/1600] D loss: 1.0568, G loss: 0.9602\n",
      "[244/1600] D loss: 0.8773, G loss: 2.0298\n",
      "[364/1600] D loss: 1.4075, G loss: 0.7029\n",
      "[484/1600] D loss: 1.1006, G loss: 0.8617\n",
      "[604/1600] D loss: 0.4382, G loss: 2.6564\n",
      "[724/1600] D loss: 0.6149, G loss: 2.0848\n",
      "[844/1600] D loss: 1.4182, G loss: 0.6528\n",
      "[964/1600] D loss: 0.8523, G loss: 1.5189\n",
      "[1084/1600] D loss: 0.4078, G loss: 2.8857\n",
      "[1204/1600] D loss: 0.7401, G loss: 1.4589\n",
      "[1324/1600] D loss: 1.2719, G loss: 1.0913\n",
      "[1444/1600] D loss: 0.4414, G loss: 2.3939\n",
      "[1564/1600] D loss: 1.2616, G loss: 2.0281\n",
      "train error: \n",
      " D loss: 1.048264, G loss: 1.087930, D accuracy: 69.8%, cell accuracy: 98.7%, board accuracy: 34.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.127636, G loss: 1.174497, D accuracy: 67.2%, cell accuracy: 98.5%, board accuracy: 32.8% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8854, G loss: 1.1535\n",
      "[124/1600] D loss: 0.7826, G loss: 1.8024\n",
      "[244/1600] D loss: 0.8599, G loss: 1.7872\n",
      "[364/1600] D loss: 0.6461, G loss: 1.7213\n",
      "[484/1600] D loss: 1.1876, G loss: 0.9408\n",
      "[604/1600] D loss: 0.9131, G loss: 2.0029\n",
      "[724/1600] D loss: 1.4478, G loss: 0.6071\n",
      "[844/1600] D loss: 1.0495, G loss: 1.2562\n",
      "[964/1600] D loss: 0.8180, G loss: 1.8389\n",
      "[1084/1600] D loss: 0.6016, G loss: 2.0496\n",
      "[1204/1600] D loss: 1.5167, G loss: 0.9919\n",
      "[1324/1600] D loss: 0.7321, G loss: 2.5376\n",
      "[1444/1600] D loss: 0.8058, G loss: 1.4117\n",
      "[1564/1600] D loss: 0.7957, G loss: 1.5790\n",
      "train error: \n",
      " D loss: 0.968389, G loss: 1.443547, D accuracy: 73.1%, cell accuracy: 98.6%, board accuracy: 31.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.091704, G loss: 1.490249, D accuracy: 68.9%, cell accuracy: 98.5%, board accuracy: 28.7% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5014, G loss: 2.2202\n",
      "[124/1600] D loss: 0.9829, G loss: 1.0360\n",
      "[244/1600] D loss: 0.8062, G loss: 1.9455\n",
      "[364/1600] D loss: 1.0785, G loss: 1.1955\n",
      "[484/1600] D loss: 1.0009, G loss: 1.3573\n",
      "[604/1600] D loss: 1.3435, G loss: 0.6895\n",
      "[724/1600] D loss: 0.6813, G loss: 1.4411\n",
      "[844/1600] D loss: 1.3432, G loss: 0.8628\n",
      "[964/1600] D loss: 1.4151, G loss: 0.8246\n",
      "[1084/1600] D loss: 0.9724, G loss: 0.9583\n",
      "[1204/1600] D loss: 1.2555, G loss: 0.9549\n",
      "[1324/1600] D loss: 0.4341, G loss: 2.9889\n",
      "[1444/1600] D loss: 1.2816, G loss: 1.8937\n",
      "[1564/1600] D loss: 0.7889, G loss: 2.1404\n",
      "train error: \n",
      " D loss: 0.994661, G loss: 1.379845, D accuracy: 70.8%, cell accuracy: 98.6%, board accuracy: 32.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.106094, G loss: 1.487349, D accuracy: 67.9%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7766, G loss: 1.4766\n",
      "[124/1600] D loss: 0.4023, G loss: 2.5562\n",
      "[244/1600] D loss: 1.2091, G loss: 1.1541\n",
      "[364/1600] D loss: 1.2528, G loss: 1.2841\n",
      "[484/1600] D loss: 0.7863, G loss: 2.1888\n",
      "[604/1600] D loss: 0.7004, G loss: 1.9118\n",
      "[724/1600] D loss: 1.3476, G loss: 1.2533\n",
      "[844/1600] D loss: 0.1424, G loss: 2.3009\n",
      "[964/1600] D loss: 1.2626, G loss: 0.7465\n",
      "[1084/1600] D loss: 0.8328, G loss: 1.4467\n",
      "[1204/1600] D loss: 0.8239, G loss: 1.0154\n",
      "[1324/1600] D loss: 1.0292, G loss: 1.8270\n",
      "[1444/1600] D loss: 1.3976, G loss: 1.1706\n",
      "[1564/1600] D loss: 1.1461, G loss: 1.0512\n",
      "train error: \n",
      " D loss: 1.008584, G loss: 1.335203, D accuracy: 69.8%, cell accuracy: 98.6%, board accuracy: 35.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.107632, G loss: 1.437203, D accuracy: 67.4%, cell accuracy: 98.4%, board accuracy: 33.2% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1408, G loss: 1.0270\n",
      "[124/1600] D loss: 0.8813, G loss: 1.3972\n",
      "[244/1600] D loss: 1.5673, G loss: 0.9979\n",
      "[364/1600] D loss: 1.0001, G loss: 1.0695\n",
      "[484/1600] D loss: 0.9227, G loss: 1.2187\n",
      "[604/1600] D loss: 1.1010, G loss: 1.5271\n",
      "[724/1600] D loss: 0.5339, G loss: 2.3538\n",
      "[844/1600] D loss: 1.2991, G loss: 0.9639\n",
      "[964/1600] D loss: 1.4282, G loss: 0.8275\n",
      "[1084/1600] D loss: 1.1146, G loss: 1.7332\n",
      "[1204/1600] D loss: 1.2513, G loss: 1.1451\n",
      "[1324/1600] D loss: 0.9843, G loss: 1.3136\n",
      "[1444/1600] D loss: 0.9271, G loss: 1.1279\n",
      "[1564/1600] D loss: 0.8712, G loss: 1.7971\n",
      "train error: \n",
      " D loss: 1.046894, G loss: 1.225322, D accuracy: 69.4%, cell accuracy: 98.5%, board accuracy: 33.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.113809, G loss: 1.289457, D accuracy: 66.5%, cell accuracy: 98.3%, board accuracy: 31.5% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4224, G loss: 0.5292\n",
      "[124/1600] D loss: 0.9694, G loss: 1.5627\n",
      "[244/1600] D loss: 1.0032, G loss: 1.5688\n",
      "[364/1600] D loss: 0.9646, G loss: 1.1364\n",
      "[484/1600] D loss: 1.0724, G loss: 0.8459\n",
      "[604/1600] D loss: 0.6393, G loss: 2.9876\n",
      "[724/1600] D loss: 1.1945, G loss: 1.1376\n",
      "[844/1600] D loss: 0.4678, G loss: 1.5345\n",
      "[964/1600] D loss: 0.5151, G loss: 2.4823\n",
      "[1084/1600] D loss: 0.9121, G loss: 1.6664\n",
      "[1204/1600] D loss: 0.7950, G loss: 1.9705\n",
      "[1324/1600] D loss: 0.7035, G loss: 1.6771\n",
      "[1444/1600] D loss: 0.5173, G loss: 3.2871\n",
      "[1564/1600] D loss: 1.0892, G loss: 1.0764\n",
      "train error: \n",
      " D loss: 1.100675, G loss: 1.027204, D accuracy: 69.2%, cell accuracy: 98.5%, board accuracy: 32.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.168485, G loss: 1.084372, D accuracy: 66.2%, cell accuracy: 98.3%, board accuracy: 30.5% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6367, G loss: 2.0324\n",
      "[124/1600] D loss: 1.0862, G loss: 0.9746\n",
      "[244/1600] D loss: 0.8541, G loss: 1.6972\n",
      "[364/1600] D loss: 1.0785, G loss: 1.0159\n",
      "[484/1600] D loss: 0.3218, G loss: 2.7968\n",
      "[604/1600] D loss: 0.6442, G loss: 2.1620\n",
      "[724/1600] D loss: 0.9230, G loss: 1.0637\n",
      "[844/1600] D loss: 1.0732, G loss: 0.9293\n",
      "[964/1600] D loss: 1.1150, G loss: 1.1213\n",
      "[1084/1600] D loss: 0.6453, G loss: 3.1844\n",
      "[1204/1600] D loss: 1.1255, G loss: 1.1106\n",
      "[1324/1600] D loss: 1.3227, G loss: 0.6773\n",
      "[1444/1600] D loss: 1.1717, G loss: 1.0359\n",
      "[1564/1600] D loss: 1.3726, G loss: 0.7264\n",
      "train error: \n",
      " D loss: 1.021602, G loss: 1.284821, D accuracy: 70.5%, cell accuracy: 98.5%, board accuracy: 34.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.107622, G loss: 1.363215, D accuracy: 67.4%, cell accuracy: 98.3%, board accuracy: 33.8% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6358, G loss: 1.4269\n",
      "[124/1600] D loss: 1.3645, G loss: 1.0879\n",
      "[244/1600] D loss: 1.0961, G loss: 1.1993\n",
      "[364/1600] D loss: 1.4824, G loss: 0.4996\n",
      "[484/1600] D loss: 0.8883, G loss: 1.6274\n",
      "[604/1600] D loss: 1.0359, G loss: 0.9426\n",
      "[724/1600] D loss: 0.4745, G loss: 2.4828\n",
      "[844/1600] D loss: 1.0071, G loss: 1.0914\n",
      "[964/1600] D loss: 0.8264, G loss: 0.9792\n",
      "[1084/1600] D loss: 1.4100, G loss: 1.1715\n",
      "[1204/1600] D loss: 1.4600, G loss: 1.1073\n",
      "[1324/1600] D loss: 1.2814, G loss: 0.8727\n",
      "[1444/1600] D loss: 1.0269, G loss: 1.2057\n",
      "[1564/1600] D loss: 1.1251, G loss: 1.1974\n",
      "train error: \n",
      " D loss: 1.049235, G loss: 1.188706, D accuracy: 70.1%, cell accuracy: 98.5%, board accuracy: 32.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.122794, G loss: 1.259383, D accuracy: 66.4%, cell accuracy: 98.3%, board accuracy: 31.8% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0593, G loss: 1.3572\n",
      "[124/1600] D loss: 0.9570, G loss: 1.2476\n",
      "[244/1600] D loss: 0.6472, G loss: 1.2680\n",
      "[364/1600] D loss: 0.5882, G loss: 1.5282\n",
      "[484/1600] D loss: 0.7506, G loss: 1.2785\n",
      "[604/1600] D loss: 1.2034, G loss: 1.2668\n",
      "[724/1600] D loss: 0.7140, G loss: 2.0893\n",
      "[844/1600] D loss: 0.4663, G loss: 2.1778\n",
      "[964/1600] D loss: 0.9019, G loss: 1.8179\n",
      "[1084/1600] D loss: 1.2995, G loss: 0.5061\n",
      "[1204/1600] D loss: 0.7503, G loss: 2.3812\n",
      "[1324/1600] D loss: 1.2725, G loss: 1.2039\n",
      "[1444/1600] D loss: 1.4553, G loss: 0.8421\n",
      "[1564/1600] D loss: 1.1034, G loss: 1.2738\n",
      "train error: \n",
      " D loss: 1.050821, G loss: 1.361113, D accuracy: 69.6%, cell accuracy: 98.6%, board accuracy: 33.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.147867, G loss: 1.460080, D accuracy: 67.6%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3071, G loss: 1.0906\n",
      "[124/1600] D loss: 1.2844, G loss: 0.7002\n",
      "[244/1600] D loss: 0.8808, G loss: 1.6103\n",
      "[364/1600] D loss: 0.4362, G loss: 2.3371\n",
      "[484/1600] D loss: 0.9138, G loss: 1.4430\n",
      "[604/1600] D loss: 1.1425, G loss: 1.5297\n",
      "[724/1600] D loss: 0.7711, G loss: 1.8058\n",
      "[844/1600] D loss: 1.1581, G loss: 1.2755\n",
      "[964/1600] D loss: 1.4039, G loss: 0.7046\n",
      "[1084/1600] D loss: 1.2027, G loss: 0.8002\n",
      "[1204/1600] D loss: 0.8866, G loss: 1.3868\n",
      "[1324/1600] D loss: 0.5819, G loss: 2.1065\n",
      "[1444/1600] D loss: 1.4908, G loss: 1.3329\n",
      "[1564/1600] D loss: 1.1216, G loss: 1.0600\n",
      "train error: \n",
      " D loss: 1.043962, G loss: 1.329413, D accuracy: 69.0%, cell accuracy: 98.5%, board accuracy: 34.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.146014, G loss: 1.379135, D accuracy: 66.6%, cell accuracy: 98.4%, board accuracy: 32.2% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2231, G loss: 0.8647\n",
      "[124/1600] D loss: 1.2719, G loss: 1.3776\n",
      "[244/1600] D loss: 1.0295, G loss: 1.3450\n",
      "[364/1600] D loss: 0.3975, G loss: 1.9910\n",
      "[484/1600] D loss: 1.2011, G loss: 1.3508\n",
      "[604/1600] D loss: 1.3986, G loss: 1.3501\n",
      "[724/1600] D loss: 1.0221, G loss: 1.7460\n",
      "[844/1600] D loss: 1.0663, G loss: 1.6170\n",
      "[964/1600] D loss: 1.1947, G loss: 1.4173\n",
      "[1084/1600] D loss: 1.1622, G loss: 1.1279\n",
      "[1204/1600] D loss: 0.9333, G loss: 1.1524\n",
      "[1324/1600] D loss: 0.7593, G loss: 1.8557\n",
      "[1444/1600] D loss: 0.7480, G loss: 1.6790\n",
      "[1564/1600] D loss: 1.1296, G loss: 1.9918\n",
      "train error: \n",
      " D loss: 1.013475, G loss: 1.350596, D accuracy: 70.1%, cell accuracy: 98.6%, board accuracy: 31.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.127162, G loss: 1.438902, D accuracy: 67.2%, cell accuracy: 98.4%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9687, G loss: 1.3723\n",
      "[124/1600] D loss: 1.0417, G loss: 1.1993\n",
      "[244/1600] D loss: 0.8516, G loss: 2.3848\n",
      "[364/1600] D loss: 1.2558, G loss: 0.7053\n",
      "[484/1600] D loss: 0.8752, G loss: 1.7219\n",
      "[604/1600] D loss: 0.8816, G loss: 1.3006\n",
      "[724/1600] D loss: 1.4521, G loss: 0.7879\n",
      "[844/1600] D loss: 0.5857, G loss: 2.3205\n",
      "[964/1600] D loss: 1.3522, G loss: 1.2418\n",
      "[1084/1600] D loss: 0.7408, G loss: 1.8027\n",
      "[1204/1600] D loss: 1.3263, G loss: 0.8273\n",
      "[1324/1600] D loss: 1.2917, G loss: 0.6810\n",
      "[1444/1600] D loss: 1.1474, G loss: 0.8419\n",
      "[1564/1600] D loss: 0.8943, G loss: 1.7634\n",
      "train error: \n",
      " D loss: 1.006094, G loss: 1.390519, D accuracy: 69.4%, cell accuracy: 98.7%, board accuracy: 32.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.122714, G loss: 1.488451, D accuracy: 66.1%, cell accuracy: 98.5%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1626, G loss: 1.4150\n",
      "[124/1600] D loss: 0.9129, G loss: 1.3626\n",
      "[244/1600] D loss: 1.2613, G loss: 0.8244\n",
      "[364/1600] D loss: 1.0062, G loss: 1.3227\n",
      "[484/1600] D loss: 0.7236, G loss: 1.6172\n",
      "[604/1600] D loss: 1.2428, G loss: 0.6920\n",
      "[724/1600] D loss: 1.9383, G loss: 1.1616\n",
      "[844/1600] D loss: 1.4313, G loss: 0.6487\n",
      "[964/1600] D loss: 0.7930, G loss: 1.5529\n",
      "[1084/1600] D loss: 1.3902, G loss: 0.6707\n",
      "[1204/1600] D loss: 0.8746, G loss: 1.7622\n",
      "[1324/1600] D loss: 0.6156, G loss: 2.3627\n",
      "[1444/1600] D loss: 0.8082, G loss: 2.6317\n",
      "[1564/1600] D loss: 0.7165, G loss: 1.4349\n",
      "train error: \n",
      " D loss: 1.049119, G loss: 1.546022, D accuracy: 68.6%, cell accuracy: 98.6%, board accuracy: 32.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.174966, G loss: 1.637378, D accuracy: 66.5%, cell accuracy: 98.4%, board accuracy: 27.0% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0494, G loss: 2.1383\n",
      "[124/1600] D loss: 1.4058, G loss: 0.6586\n",
      "[244/1600] D loss: 0.5719, G loss: 1.7888\n",
      "[364/1600] D loss: 0.6140, G loss: 2.0769\n",
      "[484/1600] D loss: 1.5235, G loss: 0.6205\n",
      "[604/1600] D loss: 1.0771, G loss: 0.7351\n",
      "[724/1600] D loss: 1.4328, G loss: 2.1146\n",
      "[844/1600] D loss: 0.6890, G loss: 2.0058\n",
      "[964/1600] D loss: 0.9582, G loss: 1.1630\n",
      "[1084/1600] D loss: 1.2448, G loss: 0.9404\n",
      "[1204/1600] D loss: 1.4146, G loss: 1.0124\n",
      "[1324/1600] D loss: 0.7693, G loss: 1.4754\n",
      "[1444/1600] D loss: 1.2355, G loss: 1.1012\n",
      "[1564/1600] D loss: 1.1215, G loss: 0.9901\n",
      "train error: \n",
      " D loss: 1.032432, G loss: 1.342850, D accuracy: 69.1%, cell accuracy: 98.6%, board accuracy: 32.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.152559, G loss: 1.407625, D accuracy: 66.0%, cell accuracy: 98.4%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1119, G loss: 0.8119\n",
      "[124/1600] D loss: 1.2797, G loss: 0.8166\n",
      "[244/1600] D loss: 0.7106, G loss: 1.7862\n",
      "[364/1600] D loss: 0.9578, G loss: 1.0489\n",
      "[484/1600] D loss: 0.7565, G loss: 1.2361\n",
      "[604/1600] D loss: 1.0653, G loss: 1.2458\n",
      "[724/1600] D loss: 1.1806, G loss: 0.9500\n",
      "[844/1600] D loss: 1.0665, G loss: 1.3824\n",
      "[964/1600] D loss: 0.7497, G loss: 1.5698\n",
      "[1084/1600] D loss: 0.9166, G loss: 1.2304\n",
      "[1204/1600] D loss: 0.7900, G loss: 2.1532\n",
      "[1324/1600] D loss: 0.7146, G loss: 2.5365\n",
      "[1444/1600] D loss: 1.3680, G loss: 0.6429\n",
      "[1564/1600] D loss: 0.8224, G loss: 1.9350\n",
      "train error: \n",
      " D loss: 1.027028, G loss: 1.387448, D accuracy: 69.1%, cell accuracy: 98.6%, board accuracy: 34.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.137073, G loss: 1.510140, D accuracy: 67.4%, cell accuracy: 98.5%, board accuracy: 32.2% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7612, G loss: 1.3872\n",
      "[124/1600] D loss: 0.5895, G loss: 1.8482\n",
      "[244/1600] D loss: 0.3903, G loss: 1.9160\n",
      "[364/1600] D loss: 1.1202, G loss: 0.9167\n",
      "[484/1600] D loss: 0.7090, G loss: 1.4088\n",
      "[604/1600] D loss: 1.3064, G loss: 1.3025\n",
      "[724/1600] D loss: 1.0558, G loss: 1.1204\n",
      "[844/1600] D loss: 0.9072, G loss: 1.7593\n",
      "[964/1600] D loss: 0.8609, G loss: 1.1058\n",
      "[1084/1600] D loss: 0.5821, G loss: 2.1606\n",
      "[1204/1600] D loss: 0.9452, G loss: 0.9832\n",
      "[1324/1600] D loss: 0.8834, G loss: 1.4254\n",
      "[1444/1600] D loss: 1.1997, G loss: 0.9491\n",
      "[1564/1600] D loss: 1.0915, G loss: 2.1101\n",
      "train error: \n",
      " D loss: 1.043286, G loss: 1.309301, D accuracy: 70.1%, cell accuracy: 98.6%, board accuracy: 34.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.152996, G loss: 1.374656, D accuracy: 67.5%, cell accuracy: 98.5%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2904, G loss: 0.9848\n",
      "[124/1600] D loss: 0.7230, G loss: 1.8694\n",
      "[244/1600] D loss: 0.6907, G loss: 2.3012\n",
      "[364/1600] D loss: 0.7749, G loss: 1.9264\n",
      "[484/1600] D loss: 1.1433, G loss: 2.2619\n",
      "[604/1600] D loss: 0.7293, G loss: 1.7508\n",
      "[724/1600] D loss: 1.2514, G loss: 0.8690\n",
      "[844/1600] D loss: 1.3413, G loss: 0.8451\n",
      "[964/1600] D loss: 0.7322, G loss: 2.2961\n",
      "[1084/1600] D loss: 1.1985, G loss: 0.9815\n",
      "[1204/1600] D loss: 0.6038, G loss: 2.3072\n",
      "[1324/1600] D loss: 0.7679, G loss: 2.3521\n",
      "[1444/1600] D loss: 1.4579, G loss: 0.7376\n",
      "[1564/1600] D loss: 1.0297, G loss: 1.3885\n",
      "train error: \n",
      " D loss: 1.028473, G loss: 1.274527, D accuracy: 68.6%, cell accuracy: 98.7%, board accuracy: 36.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.135234, G loss: 1.354303, D accuracy: 66.1%, cell accuracy: 98.5%, board accuracy: 31.8% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7932, G loss: 1.6949\n",
      "[124/1600] D loss: 0.9506, G loss: 1.0774\n",
      "[244/1600] D loss: 0.9039, G loss: 1.3138\n",
      "[364/1600] D loss: 0.4058, G loss: 2.7819\n",
      "[484/1600] D loss: 1.0145, G loss: 0.8804\n",
      "[604/1600] D loss: 1.1885, G loss: 0.8333\n",
      "[724/1600] D loss: 1.3741, G loss: 0.8609\n",
      "[844/1600] D loss: 1.0557, G loss: 1.1129\n",
      "[964/1600] D loss: 0.7103, G loss: 1.6087\n",
      "[1084/1600] D loss: 1.2558, G loss: 0.9689\n",
      "[1204/1600] D loss: 0.6829, G loss: 1.4372\n",
      "[1324/1600] D loss: 0.7259, G loss: 1.9551\n",
      "[1444/1600] D loss: 1.1660, G loss: 0.9412\n",
      "[1564/1600] D loss: 0.1927, G loss: 2.1525\n",
      "train error: \n",
      " D loss: 1.008787, G loss: 1.354949, D accuracy: 69.7%, cell accuracy: 98.6%, board accuracy: 33.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.098902, G loss: 1.444935, D accuracy: 67.1%, cell accuracy: 98.4%, board accuracy: 30.5% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6286, G loss: 2.3223\n",
      "[124/1600] D loss: 1.1670, G loss: 1.0250\n",
      "[244/1600] D loss: 1.0969, G loss: 1.0275\n",
      "[364/1600] D loss: 0.8119, G loss: 1.5907\n",
      "[484/1600] D loss: 1.3202, G loss: 1.5304\n",
      "[604/1600] D loss: 0.6662, G loss: 1.4548\n",
      "[724/1600] D loss: 0.6188, G loss: 1.8142\n",
      "[844/1600] D loss: 1.2563, G loss: 0.7906\n",
      "[964/1600] D loss: 1.6650, G loss: 1.7333\n",
      "[1084/1600] D loss: 1.5531, G loss: 0.7697\n",
      "[1204/1600] D loss: 1.1255, G loss: 1.5115\n",
      "[1324/1600] D loss: 1.4759, G loss: 1.2173\n",
      "[1444/1600] D loss: 0.7693, G loss: 1.1694\n",
      "[1564/1600] D loss: 0.7148, G loss: 1.8713\n",
      "train error: \n",
      " D loss: 1.110253, G loss: 1.237478, D accuracy: 68.5%, cell accuracy: 98.7%, board accuracy: 34.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.184027, G loss: 1.360846, D accuracy: 66.8%, cell accuracy: 98.5%, board accuracy: 30.8% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2785, G loss: 0.9654\n",
      "[124/1600] D loss: 1.3547, G loss: 0.8333\n",
      "[244/1600] D loss: 1.2926, G loss: 0.9703\n",
      "[364/1600] D loss: 0.1627, G loss: 2.4072\n",
      "[484/1600] D loss: 0.8084, G loss: 2.0724\n",
      "[604/1600] D loss: 0.5339, G loss: 1.8147\n",
      "[724/1600] D loss: 1.3002, G loss: 0.8124\n",
      "[844/1600] D loss: 1.0667, G loss: 1.0192\n",
      "[964/1600] D loss: 0.1884, G loss: 2.0179\n",
      "[1084/1600] D loss: 1.0168, G loss: 1.3430\n",
      "[1204/1600] D loss: 0.9053, G loss: 1.0424\n",
      "[1324/1600] D loss: 1.0188, G loss: 1.1979\n",
      "[1444/1600] D loss: 0.6085, G loss: 1.9268\n",
      "[1564/1600] D loss: 1.0129, G loss: 1.6782\n",
      "train error: \n",
      " D loss: 1.032527, G loss: 1.563002, D accuracy: 68.7%, cell accuracy: 98.7%, board accuracy: 35.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.159684, G loss: 1.658481, D accuracy: 66.5%, cell accuracy: 98.6%, board accuracy: 30.5% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1608, G loss: 1.4218\n",
      "[124/1600] D loss: 1.2981, G loss: 0.9805\n",
      "[244/1600] D loss: 0.9344, G loss: 1.1318\n",
      "[364/1600] D loss: 1.1226, G loss: 1.0164\n",
      "[484/1600] D loss: 0.7118, G loss: 1.5310\n",
      "[604/1600] D loss: 1.1347, G loss: 1.5626\n",
      "[724/1600] D loss: 0.4453, G loss: 3.1098\n",
      "[844/1600] D loss: 0.9941, G loss: 1.1349\n",
      "[964/1600] D loss: 1.2397, G loss: 1.7029\n",
      "[1084/1600] D loss: 1.1488, G loss: 1.1398\n",
      "[1204/1600] D loss: 1.2011, G loss: 0.9105\n",
      "[1324/1600] D loss: 0.7306, G loss: 1.4746\n",
      "[1444/1600] D loss: 1.2140, G loss: 1.6841\n",
      "[1564/1600] D loss: 1.2347, G loss: 1.1056\n",
      "train error: \n",
      " D loss: 1.013228, G loss: 1.255147, D accuracy: 69.7%, cell accuracy: 98.7%, board accuracy: 39.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.126357, G loss: 1.366852, D accuracy: 66.8%, cell accuracy: 98.5%, board accuracy: 33.2% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9769, G loss: 1.4289\n",
      "[124/1600] D loss: 0.4051, G loss: 2.8037\n",
      "[244/1600] D loss: 1.1466, G loss: 1.0466\n",
      "[364/1600] D loss: 1.4574, G loss: 0.7117\n",
      "[484/1600] D loss: 1.2558, G loss: 1.1527\n",
      "[604/1600] D loss: 1.3580, G loss: 0.8446\n",
      "[724/1600] D loss: 0.9136, G loss: 2.1523\n",
      "[844/1600] D loss: 0.7852, G loss: 2.3256\n",
      "[964/1600] D loss: 0.3347, G loss: 2.7575\n",
      "[1084/1600] D loss: 1.2782, G loss: 1.1870\n",
      "[1204/1600] D loss: 0.9746, G loss: 1.5212\n",
      "[1324/1600] D loss: 1.2662, G loss: 1.7260\n",
      "[1444/1600] D loss: 0.7683, G loss: 1.8177\n",
      "[1564/1600] D loss: 1.1404, G loss: 1.7755\n",
      "train error: \n",
      " D loss: 1.054342, G loss: 1.357212, D accuracy: 68.7%, cell accuracy: 98.7%, board accuracy: 39.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.152361, G loss: 1.522427, D accuracy: 66.5%, cell accuracy: 98.5%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0245, G loss: 1.2193\n",
      "[124/1600] D loss: 0.7546, G loss: 1.8637\n",
      "[244/1600] D loss: 0.4545, G loss: 2.9903\n",
      "[364/1600] D loss: 1.6579, G loss: 1.4800\n",
      "[484/1600] D loss: 0.8835, G loss: 2.2454\n",
      "[604/1600] D loss: 1.1990, G loss: 0.6926\n",
      "[724/1600] D loss: 1.1717, G loss: 1.2399\n",
      "[844/1600] D loss: 0.6319, G loss: 1.9326\n",
      "[964/1600] D loss: 0.8448, G loss: 1.2813\n",
      "[1084/1600] D loss: 1.3114, G loss: 0.7575\n",
      "[1204/1600] D loss: 0.9717, G loss: 1.7824\n",
      "[1324/1600] D loss: 0.8712, G loss: 1.0466\n",
      "[1444/1600] D loss: 0.9598, G loss: 1.4758\n",
      "[1564/1600] D loss: 0.7899, G loss: 0.9381\n",
      "train error: \n",
      " D loss: 1.036347, G loss: 1.650372, D accuracy: 68.4%, cell accuracy: 98.7%, board accuracy: 37.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.163966, G loss: 1.780166, D accuracy: 66.5%, cell accuracy: 98.5%, board accuracy: 31.2% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3908, G loss: 2.3793\n",
      "[124/1600] D loss: 0.6735, G loss: 1.7888\n",
      "[244/1600] D loss: 1.0131, G loss: 1.1097\n",
      "[364/1600] D loss: 1.3362, G loss: 1.5188\n",
      "[484/1600] D loss: 1.1958, G loss: 0.8400\n",
      "[604/1600] D loss: 0.7317, G loss: 1.6589\n",
      "[724/1600] D loss: 1.1503, G loss: 1.3266\n",
      "[844/1600] D loss: 0.7993, G loss: 1.7751\n",
      "[964/1600] D loss: 1.4374, G loss: 1.0168\n",
      "[1084/1600] D loss: 0.7523, G loss: 3.1624\n",
      "[1204/1600] D loss: 1.1080, G loss: 1.2050\n",
      "[1324/1600] D loss: 0.5316, G loss: 2.2511\n",
      "[1444/1600] D loss: 0.8001, G loss: 2.1777\n",
      "[1564/1600] D loss: 0.7212, G loss: 2.2970\n",
      "train error: \n",
      " D loss: 1.018561, G loss: 1.486502, D accuracy: 69.4%, cell accuracy: 98.7%, board accuracy: 37.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.145346, G loss: 1.590131, D accuracy: 67.2%, cell accuracy: 98.5%, board accuracy: 34.0% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8065, G loss: 1.6814\n",
      "[124/1600] D loss: 1.2853, G loss: 1.0488\n",
      "[244/1600] D loss: 0.7177, G loss: 2.3536\n",
      "[364/1600] D loss: 1.3430, G loss: 1.2217\n",
      "[484/1600] D loss: 1.0021, G loss: 1.4493\n",
      "[604/1600] D loss: 0.6191, G loss: 1.8586\n",
      "[724/1600] D loss: 1.0439, G loss: 1.4510\n",
      "[844/1600] D loss: 1.3553, G loss: 0.7533\n",
      "[964/1600] D loss: 1.2558, G loss: 1.3000\n",
      "[1084/1600] D loss: 0.8278, G loss: 1.5981\n",
      "[1204/1600] D loss: 0.8616, G loss: 1.3145\n",
      "[1324/1600] D loss: 0.1889, G loss: 3.1511\n",
      "[1444/1600] D loss: 0.8454, G loss: 1.2382\n",
      "[1564/1600] D loss: 0.9313, G loss: 2.2527\n",
      "train error: \n",
      " D loss: 1.058023, G loss: 1.093775, D accuracy: 69.3%, cell accuracy: 98.8%, board accuracy: 38.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.138874, G loss: 1.189687, D accuracy: 67.5%, cell accuracy: 98.6%, board accuracy: 36.0% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4369, G loss: 2.3013\n",
      "[124/1600] D loss: 0.7407, G loss: 2.0680\n",
      "[244/1600] D loss: 0.7260, G loss: 1.6507\n",
      "[364/1600] D loss: 1.0808, G loss: 1.4599\n",
      "[484/1600] D loss: 0.3862, G loss: 2.4826\n",
      "[604/1600] D loss: 0.7703, G loss: 2.8035\n",
      "[724/1600] D loss: 1.0968, G loss: 1.0677\n",
      "[844/1600] D loss: 1.4025, G loss: 0.6962\n",
      "[964/1600] D loss: 1.4155, G loss: 0.7683\n",
      "[1084/1600] D loss: 0.8509, G loss: 1.0554\n",
      "[1204/1600] D loss: 1.2631, G loss: 1.4494\n",
      "[1324/1600] D loss: 0.7106, G loss: 1.8361\n",
      "[1444/1600] D loss: 1.1497, G loss: 0.9383\n",
      "[1564/1600] D loss: 0.6583, G loss: 1.6642\n",
      "train error: \n",
      " D loss: 1.002241, G loss: 1.627548, D accuracy: 69.4%, cell accuracy: 98.7%, board accuracy: 36.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.133930, G loss: 1.758200, D accuracy: 67.8%, cell accuracy: 98.5%, board accuracy: 32.2% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4785, G loss: 2.3097\n",
      "[124/1600] D loss: 1.3507, G loss: 0.6028\n",
      "[244/1600] D loss: 0.7733, G loss: 2.2262\n",
      "[364/1600] D loss: 1.1960, G loss: 0.8269\n",
      "[484/1600] D loss: 1.0618, G loss: 1.2808\n",
      "[604/1600] D loss: 1.0244, G loss: 1.5164\n",
      "[724/1600] D loss: 0.1351, G loss: 2.7329\n",
      "[844/1600] D loss: 1.3958, G loss: 0.8010\n",
      "[964/1600] D loss: 1.5567, G loss: 1.7051\n",
      "[1084/1600] D loss: 0.7872, G loss: 2.0488\n",
      "[1204/1600] D loss: 0.9264, G loss: 1.4571\n",
      "[1324/1600] D loss: 0.2140, G loss: 2.6042\n",
      "[1444/1600] D loss: 0.1259, G loss: 2.7741\n",
      "[1564/1600] D loss: 1.3299, G loss: 0.9276\n",
      "train error: \n",
      " D loss: 1.018361, G loss: 1.209237, D accuracy: 69.7%, cell accuracy: 98.7%, board accuracy: 38.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.151220, G loss: 1.275158, D accuracy: 65.6%, cell accuracy: 98.6%, board accuracy: 33.5% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4879, G loss: 1.7126\n",
      "[124/1600] D loss: 1.0891, G loss: 1.4279\n",
      "[244/1600] D loss: 0.9753, G loss: 1.8643\n",
      "[364/1600] D loss: 1.2435, G loss: 0.8173\n",
      "[484/1600] D loss: 0.6954, G loss: 1.6706\n",
      "[604/1600] D loss: 1.0678, G loss: 1.0396\n",
      "[724/1600] D loss: 1.1391, G loss: 1.1884\n",
      "[844/1600] D loss: 1.4742, G loss: 0.8196\n",
      "[964/1600] D loss: 1.3994, G loss: 0.8294\n",
      "[1084/1600] D loss: 0.7401, G loss: 1.5248\n",
      "[1204/1600] D loss: 1.4213, G loss: 1.4425\n",
      "[1324/1600] D loss: 1.0086, G loss: 1.5095\n",
      "[1444/1600] D loss: 1.0674, G loss: 1.2111\n",
      "[1564/1600] D loss: 0.9704, G loss: 1.4036\n",
      "train error: \n",
      " D loss: 0.999205, G loss: 1.334641, D accuracy: 69.9%, cell accuracy: 98.7%, board accuracy: 39.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.121771, G loss: 1.425670, D accuracy: 68.1%, cell accuracy: 98.6%, board accuracy: 35.8% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4510, G loss: 2.1276\n",
      "[124/1600] D loss: 1.5069, G loss: 0.8483\n",
      "[244/1600] D loss: 1.3095, G loss: 0.8637\n",
      "[364/1600] D loss: 1.0577, G loss: 1.4269\n",
      "[484/1600] D loss: 0.9704, G loss: 1.2521\n",
      "[604/1600] D loss: 0.7634, G loss: 2.3565\n",
      "[724/1600] D loss: 0.8037, G loss: 1.5030\n",
      "[844/1600] D loss: 0.9561, G loss: 1.6537\n",
      "[964/1600] D loss: 1.1048, G loss: 0.7583\n",
      "[1084/1600] D loss: 0.9935, G loss: 1.2256\n",
      "[1204/1600] D loss: 1.2446, G loss: 1.4387\n",
      "[1324/1600] D loss: 0.7769, G loss: 2.7619\n",
      "[1444/1600] D loss: 0.7175, G loss: 2.3260\n",
      "[1564/1600] D loss: 0.7799, G loss: 1.0787\n",
      "train error: \n",
      " D loss: 1.004995, G loss: 1.315974, D accuracy: 69.6%, cell accuracy: 98.7%, board accuracy: 40.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.139017, G loss: 1.401984, D accuracy: 67.1%, cell accuracy: 98.5%, board accuracy: 39.2% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7913, G loss: 1.3414\n",
      "[124/1600] D loss: 0.6046, G loss: 1.6194\n",
      "[244/1600] D loss: 1.3839, G loss: 0.6603\n",
      "[364/1600] D loss: 1.0906, G loss: 1.2241\n",
      "[484/1600] D loss: 0.9642, G loss: 1.2992\n",
      "[604/1600] D loss: 0.3563, G loss: 1.9197\n",
      "[724/1600] D loss: 1.0154, G loss: 1.6558\n",
      "[844/1600] D loss: 1.0557, G loss: 0.7493\n",
      "[964/1600] D loss: 0.9739, G loss: 1.3382\n",
      "[1084/1600] D loss: 1.4332, G loss: 0.7789\n",
      "[1204/1600] D loss: 1.1031, G loss: 1.3614\n",
      "[1324/1600] D loss: 1.0974, G loss: 1.2112\n",
      "[1444/1600] D loss: 1.3854, G loss: 0.7719\n",
      "[1564/1600] D loss: 1.0977, G loss: 1.9294\n",
      "train error: \n",
      " D loss: 1.023464, G loss: 1.401687, D accuracy: 69.1%, cell accuracy: 98.7%, board accuracy: 41.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.149171, G loss: 1.502069, D accuracy: 66.9%, cell accuracy: 98.5%, board accuracy: 39.2% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1241, G loss: 1.5873\n",
      "[124/1600] D loss: 1.2455, G loss: 1.3430\n",
      "[244/1600] D loss: 0.7112, G loss: 1.5549\n",
      "[364/1600] D loss: 0.7188, G loss: 2.2629\n",
      "[484/1600] D loss: 1.0460, G loss: 1.9990\n",
      "[604/1600] D loss: 1.1025, G loss: 0.9854\n",
      "[724/1600] D loss: 1.3342, G loss: 0.6207\n",
      "[844/1600] D loss: 1.3317, G loss: 0.6985\n",
      "[964/1600] D loss: 0.6258, G loss: 2.2957\n",
      "[1084/1600] D loss: 1.0938, G loss: 1.1591\n",
      "[1204/1600] D loss: 1.2974, G loss: 1.2944\n",
      "[1324/1600] D loss: 0.7650, G loss: 1.6939\n",
      "[1444/1600] D loss: 0.9807, G loss: 0.9025\n",
      "[1564/1600] D loss: 0.9069, G loss: 1.5466\n",
      "train error: \n",
      " D loss: 1.007870, G loss: 1.310742, D accuracy: 69.4%, cell accuracy: 98.7%, board accuracy: 40.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.114235, G loss: 1.436262, D accuracy: 68.0%, cell accuracy: 98.5%, board accuracy: 38.8% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1784, G loss: 0.8919\n",
      "[124/1600] D loss: 1.2917, G loss: 0.7059\n",
      "[244/1600] D loss: 1.1446, G loss: 1.0915\n",
      "[364/1600] D loss: 0.6755, G loss: 1.6541\n",
      "[484/1600] D loss: 1.3106, G loss: 0.8415\n",
      "[604/1600] D loss: 0.8569, G loss: 1.0794\n",
      "[724/1600] D loss: 1.2520, G loss: 1.8285\n",
      "[844/1600] D loss: 1.4089, G loss: 0.5034\n",
      "[964/1600] D loss: 1.1025, G loss: 1.1484\n",
      "[1084/1600] D loss: 0.7863, G loss: 1.9686\n",
      "[1204/1600] D loss: 0.7994, G loss: 1.7749\n",
      "[1324/1600] D loss: 1.0077, G loss: 1.0589\n",
      "[1444/1600] D loss: 1.0563, G loss: 1.3706\n",
      "[1564/1600] D loss: 0.8884, G loss: 1.8199\n",
      "train error: \n",
      " D loss: 1.063773, G loss: 1.585599, D accuracy: 68.6%, cell accuracy: 98.7%, board accuracy: 41.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.176426, G loss: 1.662657, D accuracy: 65.8%, cell accuracy: 98.5%, board accuracy: 35.0% \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5818, G loss: 2.3551\n",
      "[124/1600] D loss: 1.0598, G loss: 1.1000\n",
      "[244/1600] D loss: 1.0591, G loss: 1.4772\n",
      "[364/1600] D loss: 1.0902, G loss: 1.2138\n",
      "[484/1600] D loss: 1.0146, G loss: 1.3309\n",
      "[604/1600] D loss: 0.8266, G loss: 2.6286\n",
      "[724/1600] D loss: 0.6670, G loss: 1.7837\n",
      "[844/1600] D loss: 1.1587, G loss: 0.7706\n",
      "[964/1600] D loss: 0.9571, G loss: 1.1359\n",
      "[1084/1600] D loss: 1.0480, G loss: 1.4222\n",
      "[1204/1600] D loss: 1.4254, G loss: 0.8063\n",
      "[1324/1600] D loss: 1.0595, G loss: 1.2724\n",
      "[1444/1600] D loss: 1.3996, G loss: 0.9974\n",
      "[1564/1600] D loss: 1.1312, G loss: 1.3250\n",
      "train error: \n",
      " D loss: 1.030362, G loss: 1.580385, D accuracy: 67.1%, cell accuracy: 98.8%, board accuracy: 43.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.167767, G loss: 1.680791, D accuracy: 64.1%, cell accuracy: 98.6%, board accuracy: 41.8% \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2419, G loss: 0.9741\n",
      "[124/1600] D loss: 1.3524, G loss: 1.1053\n",
      "[244/1600] D loss: 1.2150, G loss: 0.7648\n",
      "[364/1600] D loss: 0.9842, G loss: 1.6327\n",
      "[484/1600] D loss: 0.7052, G loss: 1.6343\n",
      "[604/1600] D loss: 1.0283, G loss: 1.4248\n",
      "[724/1600] D loss: 1.3836, G loss: 0.9381\n",
      "[844/1600] D loss: 1.1419, G loss: 1.0838\n",
      "[964/1600] D loss: 0.8432, G loss: 1.2439\n",
      "[1084/1600] D loss: 0.7949, G loss: 2.0435\n",
      "[1204/1600] D loss: 0.6444, G loss: 2.0542\n",
      "[1324/1600] D loss: 1.5220, G loss: 0.5859\n",
      "[1444/1600] D loss: 1.2883, G loss: 1.7191\n",
      "[1564/1600] D loss: 1.0873, G loss: 1.2318\n",
      "train error: \n",
      " D loss: 1.067265, G loss: 1.197014, D accuracy: 68.3%, cell accuracy: 98.8%, board accuracy: 43.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.158023, G loss: 1.284346, D accuracy: 65.5%, cell accuracy: 98.6%, board accuracy: 38.5% \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5248, G loss: 0.5616\n",
      "[124/1600] D loss: 0.9598, G loss: 1.9128\n",
      "[244/1600] D loss: 1.0478, G loss: 1.8975\n",
      "[364/1600] D loss: 0.6707, G loss: 1.3973\n",
      "[484/1600] D loss: 1.4498, G loss: 0.7224\n",
      "[604/1600] D loss: 0.6925, G loss: 1.8674\n",
      "[724/1600] D loss: 0.7564, G loss: 1.4522\n",
      "[844/1600] D loss: 0.3932, G loss: 2.8737\n",
      "[964/1600] D loss: 0.4927, G loss: 2.7444\n",
      "[1084/1600] D loss: 0.9286, G loss: 2.9833\n",
      "[1204/1600] D loss: 1.0787, G loss: 1.3781\n",
      "[1324/1600] D loss: 0.9303, G loss: 1.5982\n",
      "[1444/1600] D loss: 0.8578, G loss: 1.2731\n",
      "[1564/1600] D loss: 0.9685, G loss: 2.0258\n",
      "train error: \n",
      " D loss: 1.002249, G loss: 1.406537, D accuracy: 68.6%, cell accuracy: 98.7%, board accuracy: 43.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.124715, G loss: 1.510638, D accuracy: 65.9%, cell accuracy: 98.5%, board accuracy: 41.8% \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1415, G loss: 0.8756\n",
      "[124/1600] D loss: 0.8605, G loss: 1.3492\n",
      "[244/1600] D loss: 0.7012, G loss: 1.5126\n",
      "[364/1600] D loss: 1.3792, G loss: 0.9478\n",
      "[484/1600] D loss: 1.1521, G loss: 1.3085\n",
      "[604/1600] D loss: 1.3229, G loss: 0.8237\n",
      "[724/1600] D loss: 0.4321, G loss: 2.2837\n",
      "[844/1600] D loss: 1.3840, G loss: 0.8261\n",
      "[964/1600] D loss: 0.8694, G loss: 1.6180\n",
      "[1084/1600] D loss: 1.2946, G loss: 0.7744\n",
      "[1204/1600] D loss: 0.8380, G loss: 1.3384\n",
      "[1324/1600] D loss: 1.4455, G loss: 0.6237\n",
      "[1444/1600] D loss: 0.9844, G loss: 1.2221\n",
      "[1564/1600] D loss: 1.5023, G loss: 0.7040\n",
      "train error: \n",
      " D loss: 1.024277, G loss: 1.232485, D accuracy: 69.4%, cell accuracy: 98.8%, board accuracy: 45.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.152230, G loss: 1.296143, D accuracy: 66.4%, cell accuracy: 98.6%, board accuracy: 42.8% \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1404, G loss: 0.8575\n",
      "[124/1600] D loss: 0.6397, G loss: 1.5299\n",
      "[244/1600] D loss: 0.6968, G loss: 2.1646\n",
      "[364/1600] D loss: 1.1387, G loss: 0.9811\n",
      "[484/1600] D loss: 1.0566, G loss: 1.0130\n",
      "[604/1600] D loss: 0.4998, G loss: 2.0517\n",
      "[724/1600] D loss: 0.7509, G loss: 1.9457\n",
      "[844/1600] D loss: 1.1865, G loss: 0.8910\n",
      "[964/1600] D loss: 1.1316, G loss: 1.1554\n",
      "[1084/1600] D loss: 1.1821, G loss: 1.5335\n",
      "[1204/1600] D loss: 1.2693, G loss: 0.9011\n",
      "[1324/1600] D loss: 1.2197, G loss: 0.9642\n",
      "[1444/1600] D loss: 1.3927, G loss: 0.5600\n",
      "[1564/1600] D loss: 0.9306, G loss: 1.4863\n",
      "train error: \n",
      " D loss: 1.021326, G loss: 1.304306, D accuracy: 69.5%, cell accuracy: 98.7%, board accuracy: 42.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.126461, G loss: 1.386815, D accuracy: 67.5%, cell accuracy: 98.5%, board accuracy: 40.2% \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0283, G loss: 1.3297\n",
      "[124/1600] D loss: 1.5422, G loss: 1.2943\n",
      "[244/1600] D loss: 1.4282, G loss: 0.8895\n",
      "[364/1600] D loss: 0.8544, G loss: 1.1737\n",
      "[484/1600] D loss: 1.0667, G loss: 0.8572\n",
      "[604/1600] D loss: 0.6055, G loss: 3.7334\n",
      "[724/1600] D loss: 0.7610, G loss: 1.2965\n",
      "[844/1600] D loss: 0.6537, G loss: 1.7383\n",
      "[964/1600] D loss: 0.6539, G loss: 1.9130\n",
      "[1084/1600] D loss: 1.1198, G loss: 1.5727\n",
      "[1204/1600] D loss: 1.3989, G loss: 1.6404\n",
      "[1324/1600] D loss: 0.8317, G loss: 1.4730\n",
      "[1444/1600] D loss: 1.4382, G loss: 0.6661\n",
      "[1564/1600] D loss: 0.7279, G loss: 1.7405\n",
      "train error: \n",
      " D loss: 1.012231, G loss: 1.406218, D accuracy: 69.0%, cell accuracy: 98.8%, board accuracy: 43.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.133796, G loss: 1.485056, D accuracy: 66.2%, cell accuracy: 98.6%, board accuracy: 42.8% \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9431, G loss: 1.1927\n",
      "[124/1600] D loss: 0.9123, G loss: 1.1260\n",
      "[244/1600] D loss: 1.0188, G loss: 1.3323\n",
      "[364/1600] D loss: 1.1017, G loss: 0.7658\n",
      "[484/1600] D loss: 1.2961, G loss: 1.3808\n",
      "[604/1600] D loss: 1.0524, G loss: 0.9111\n",
      "[724/1600] D loss: 1.0507, G loss: 1.1452\n",
      "[844/1600] D loss: 1.0627, G loss: 1.1825\n",
      "[964/1600] D loss: 1.1395, G loss: 1.0496\n",
      "[1084/1600] D loss: 1.0852, G loss: 1.3577\n",
      "[1204/1600] D loss: 1.2190, G loss: 1.0237\n",
      "[1324/1600] D loss: 0.4911, G loss: 2.6435\n",
      "[1444/1600] D loss: 1.5248, G loss: 0.5873\n",
      "[1564/1600] D loss: 1.3118, G loss: 0.8828\n",
      "train error: \n",
      " D loss: 1.005489, G loss: 1.459301, D accuracy: 69.2%, cell accuracy: 98.7%, board accuracy: 42.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.129803, G loss: 1.562971, D accuracy: 67.0%, cell accuracy: 98.5%, board accuracy: 39.0% \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0405, G loss: 1.2793\n",
      "[124/1600] D loss: 1.2733, G loss: 0.8444\n",
      "[244/1600] D loss: 0.8412, G loss: 1.7434\n",
      "[364/1600] D loss: 0.9610, G loss: 1.3098\n",
      "[484/1600] D loss: 1.3413, G loss: 0.6801\n",
      "[604/1600] D loss: 1.0773, G loss: 1.0649\n",
      "[724/1600] D loss: 1.0920, G loss: 1.7822\n",
      "[844/1600] D loss: 0.6212, G loss: 1.4851\n",
      "[964/1600] D loss: 1.3513, G loss: 0.9593\n",
      "[1084/1600] D loss: 0.8915, G loss: 1.3619\n",
      "[1204/1600] D loss: 0.1766, G loss: 3.0596\n",
      "[1324/1600] D loss: 1.2388, G loss: 1.7101\n",
      "[1444/1600] D loss: 0.8086, G loss: 1.5186\n",
      "[1564/1600] D loss: 1.1684, G loss: 0.7860\n",
      "train error: \n",
      " D loss: 1.029626, G loss: 1.654968, D accuracy: 67.4%, cell accuracy: 98.7%, board accuracy: 44.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.170606, G loss: 1.744771, D accuracy: 64.4%, cell accuracy: 98.6%, board accuracy: 43.8% \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5212, G loss: 1.1272\n",
      "[124/1600] D loss: 1.0657, G loss: 1.1340\n",
      "[244/1600] D loss: 0.8600, G loss: 1.8032\n",
      "[364/1600] D loss: 0.9066, G loss: 2.2909\n",
      "[484/1600] D loss: 0.6292, G loss: 2.1441\n",
      "[604/1600] D loss: 1.3087, G loss: 1.7813\n",
      "[724/1600] D loss: 1.0349, G loss: 1.5617\n",
      "[844/1600] D loss: 1.0784, G loss: 1.6332\n",
      "[964/1600] D loss: 0.7702, G loss: 1.5118\n",
      "[1084/1600] D loss: 0.9294, G loss: 1.0591\n",
      "[1204/1600] D loss: 0.4981, G loss: 2.1086\n",
      "[1324/1600] D loss: 1.2920, G loss: 0.7753\n",
      "[1444/1600] D loss: 0.0858, G loss: 2.9330\n",
      "[1564/1600] D loss: 1.3145, G loss: 0.8703\n",
      "train error: \n",
      " D loss: 1.005912, G loss: 1.362058, D accuracy: 69.5%, cell accuracy: 98.7%, board accuracy: 42.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.131567, G loss: 1.459038, D accuracy: 67.2%, cell accuracy: 98.6%, board accuracy: 39.5% \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0128, G loss: 1.8756\n",
      "[124/1600] D loss: 0.9198, G loss: 1.8133\n",
      "[244/1600] D loss: 0.9471, G loss: 1.7714\n",
      "[364/1600] D loss: 1.0649, G loss: 1.4460\n",
      "[484/1600] D loss: 0.9948, G loss: 1.6241\n",
      "[604/1600] D loss: 0.3884, G loss: 2.4119\n",
      "[724/1600] D loss: 1.2107, G loss: 0.7314\n",
      "[844/1600] D loss: 1.0898, G loss: 1.4333\n",
      "[964/1600] D loss: 1.0661, G loss: 1.3448\n",
      "[1084/1600] D loss: 0.4824, G loss: 2.7530\n",
      "[1204/1600] D loss: 0.5247, G loss: 2.1523\n",
      "[1324/1600] D loss: 0.6994, G loss: 1.7685\n",
      "[1444/1600] D loss: 1.7084, G loss: 0.8305\n",
      "[1564/1600] D loss: 1.1755, G loss: 0.7700\n",
      "train error: \n",
      " D loss: 0.992111, G loss: 1.451141, D accuracy: 69.0%, cell accuracy: 98.7%, board accuracy: 42.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.110730, G loss: 1.552729, D accuracy: 67.6%, cell accuracy: 98.6%, board accuracy: 41.2% \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7598, G loss: 1.6497\n",
      "[124/1600] D loss: 1.1747, G loss: 1.0189\n",
      "[244/1600] D loss: 0.6331, G loss: 2.4736\n",
      "[364/1600] D loss: 1.0649, G loss: 1.6864\n",
      "[484/1600] D loss: 1.5345, G loss: 0.5823\n",
      "[604/1600] D loss: 1.1029, G loss: 1.3325\n",
      "[724/1600] D loss: 1.5383, G loss: 0.7449\n",
      "[844/1600] D loss: 0.4446, G loss: 3.2335\n",
      "[964/1600] D loss: 0.5353, G loss: 2.1542\n",
      "[1084/1600] D loss: 1.6551, G loss: 2.2087\n",
      "[1204/1600] D loss: 1.2992, G loss: 0.7262\n",
      "[1324/1600] D loss: 1.6283, G loss: 0.5603\n",
      "[1444/1600] D loss: 0.7440, G loss: 1.3517\n",
      "[1564/1600] D loss: 0.8735, G loss: 1.1527\n",
      "train error: \n",
      " D loss: 1.015072, G loss: 1.414956, D accuracy: 68.0%, cell accuracy: 98.8%, board accuracy: 44.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.140936, G loss: 1.503539, D accuracy: 65.5%, cell accuracy: 98.7%, board accuracy: 43.5% \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6536, G loss: 2.1857\n",
      "[124/1600] D loss: 0.8705, G loss: 1.5804\n",
      "[244/1600] D loss: 1.0332, G loss: 1.2826\n",
      "[364/1600] D loss: 0.6087, G loss: 1.8431\n",
      "[484/1600] D loss: 0.3577, G loss: 2.5160\n",
      "[604/1600] D loss: 1.3116, G loss: 1.0622\n",
      "[724/1600] D loss: 1.2164, G loss: 1.0683\n",
      "[844/1600] D loss: 0.9466, G loss: 1.2133\n",
      "[964/1600] D loss: 0.7554, G loss: 2.1346\n",
      "[1084/1600] D loss: 0.8216, G loss: 1.7304\n",
      "[1204/1600] D loss: 1.3113, G loss: 1.1599\n",
      "[1324/1600] D loss: 1.0864, G loss: 1.4983\n",
      "[1444/1600] D loss: 0.8531, G loss: 1.9728\n",
      "[1564/1600] D loss: 1.0965, G loss: 0.9142\n",
      "train error: \n",
      " D loss: 1.051066, G loss: 1.685861, D accuracy: 67.4%, cell accuracy: 98.8%, board accuracy: 43.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.190307, G loss: 1.788612, D accuracy: 66.1%, cell accuracy: 98.6%, board accuracy: 42.5% \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0040, G loss: 1.4326\n",
      "[124/1600] D loss: 1.0109, G loss: 1.7319\n",
      "[244/1600] D loss: 0.7375, G loss: 1.5078\n",
      "[364/1600] D loss: 1.5359, G loss: 0.9514\n",
      "[484/1600] D loss: 1.1596, G loss: 0.8897\n",
      "[604/1600] D loss: 1.4869, G loss: 0.9086\n",
      "[724/1600] D loss: 0.7028, G loss: 2.1178\n",
      "[844/1600] D loss: 0.6596, G loss: 2.4096\n",
      "[964/1600] D loss: 0.6251, G loss: 1.8922\n",
      "[1084/1600] D loss: 0.3939, G loss: 1.9649\n",
      "[1204/1600] D loss: 0.9711, G loss: 2.1216\n",
      "[1324/1600] D loss: 0.9145, G loss: 1.0870\n",
      "[1444/1600] D loss: 1.1553, G loss: 0.9761\n",
      "[1564/1600] D loss: 1.3791, G loss: 0.9284\n",
      "train error: \n",
      " D loss: 1.006655, G loss: 1.465335, D accuracy: 68.3%, cell accuracy: 98.8%, board accuracy: 44.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.146231, G loss: 1.556652, D accuracy: 65.5%, cell accuracy: 98.6%, board accuracy: 43.2% \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7062, G loss: 2.5610\n",
      "[124/1600] D loss: 1.4566, G loss: 0.6311\n",
      "[244/1600] D loss: 0.7927, G loss: 1.3401\n",
      "[364/1600] D loss: 0.8129, G loss: 1.8803\n",
      "[484/1600] D loss: 1.2434, G loss: 0.7589\n",
      "[604/1600] D loss: 1.4479, G loss: 0.6585\n",
      "[724/1600] D loss: 1.0815, G loss: 0.9782\n",
      "[844/1600] D loss: 1.0283, G loss: 1.0920\n",
      "[964/1600] D loss: 0.8565, G loss: 1.3488\n",
      "[1084/1600] D loss: 1.0916, G loss: 0.9810\n",
      "[1204/1600] D loss: 0.4297, G loss: 2.7817\n",
      "[1324/1600] D loss: 0.8612, G loss: 1.4283\n",
      "[1444/1600] D loss: 0.9153, G loss: 1.2349\n",
      "[1564/1600] D loss: 1.0118, G loss: 1.3301\n",
      "train error: \n",
      " D loss: 0.995904, G loss: 1.442124, D accuracy: 68.7%, cell accuracy: 98.8%, board accuracy: 45.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.122969, G loss: 1.562037, D accuracy: 66.2%, cell accuracy: 98.6%, board accuracy: 45.8% \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0541, G loss: 1.6136\n",
      "[124/1600] D loss: 0.6881, G loss: 2.1440\n",
      "[244/1600] D loss: 1.0905, G loss: 1.3176\n",
      "[364/1600] D loss: 1.0153, G loss: 1.2601\n",
      "[484/1600] D loss: 0.8192, G loss: 1.2857\n",
      "[604/1600] D loss: 0.7279, G loss: 1.8265\n",
      "[724/1600] D loss: 0.7323, G loss: 1.3393\n",
      "[844/1600] D loss: 0.4995, G loss: 2.0560\n",
      "[964/1600] D loss: 1.3618, G loss: 0.5984\n",
      "[1084/1600] D loss: 0.6619, G loss: 2.9016\n",
      "[1204/1600] D loss: 1.2042, G loss: 0.9605\n",
      "[1324/1600] D loss: 0.8085, G loss: 1.4615\n",
      "[1444/1600] D loss: 0.9153, G loss: 2.4800\n",
      "[1564/1600] D loss: 1.4022, G loss: 0.7794\n",
      "train error: \n",
      " D loss: 1.026827, G loss: 1.256856, D accuracy: 68.7%, cell accuracy: 98.7%, board accuracy: 40.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.141615, G loss: 1.334281, D accuracy: 66.0%, cell accuracy: 98.5%, board accuracy: 39.2% \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2769, G loss: 0.8564\n",
      "[124/1600] D loss: 1.1109, G loss: 1.1055\n",
      "[244/1600] D loss: 0.7047, G loss: 2.9772\n",
      "[364/1600] D loss: 0.7329, G loss: 2.3982\n",
      "[484/1600] D loss: 0.9521, G loss: 1.3240\n",
      "[604/1600] D loss: 0.7803, G loss: 1.8061\n",
      "[724/1600] D loss: 0.7707, G loss: 2.1585\n",
      "[844/1600] D loss: 1.0934, G loss: 1.1959\n",
      "[964/1600] D loss: 1.1549, G loss: 1.7779\n",
      "[1084/1600] D loss: 0.5704, G loss: 1.7924\n",
      "[1204/1600] D loss: 1.0992, G loss: 0.9743\n",
      "[1324/1600] D loss: 1.1444, G loss: 0.8631\n",
      "[1444/1600] D loss: 1.4027, G loss: 0.6419\n",
      "[1564/1600] D loss: 0.9435, G loss: 1.5719\n",
      "train error: \n",
      " D loss: 1.023900, G loss: 1.324210, D accuracy: 68.8%, cell accuracy: 98.8%, board accuracy: 43.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.135028, G loss: 1.402097, D accuracy: 66.2%, cell accuracy: 98.6%, board accuracy: 41.5% \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6663, G loss: 2.3417\n",
      "[124/1600] D loss: 1.0273, G loss: 1.1305\n",
      "[244/1600] D loss: 1.0434, G loss: 2.0496\n",
      "[364/1600] D loss: 0.4506, G loss: 2.2205\n",
      "[484/1600] D loss: 0.9451, G loss: 1.5788\n",
      "[604/1600] D loss: 0.9178, G loss: 1.2727\n",
      "[724/1600] D loss: 1.0498, G loss: 1.0362\n",
      "[844/1600] D loss: 0.4422, G loss: 2.0752\n",
      "[964/1600] D loss: 0.4287, G loss: 2.4360\n",
      "[1084/1600] D loss: 0.9878, G loss: 0.9184\n",
      "[1204/1600] D loss: 0.6671, G loss: 1.4680\n",
      "[1324/1600] D loss: 1.4743, G loss: 0.6276\n",
      "[1444/1600] D loss: 0.6268, G loss: 1.9272\n",
      "[1564/1600] D loss: 1.2270, G loss: 1.1228\n",
      "train error: \n",
      " D loss: 1.003009, G loss: 1.485305, D accuracy: 69.3%, cell accuracy: 98.8%, board accuracy: 43.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.134502, G loss: 1.580040, D accuracy: 67.0%, cell accuracy: 98.6%, board accuracy: 42.8% \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0950, G loss: 0.9560\n",
      "[124/1600] D loss: 1.0217, G loss: 1.0756\n",
      "[244/1600] D loss: 1.2182, G loss: 1.6474\n",
      "[364/1600] D loss: 1.1396, G loss: 1.1078\n",
      "[484/1600] D loss: 0.5032, G loss: 2.8014\n",
      "[604/1600] D loss: 1.1900, G loss: 1.7022\n",
      "[724/1600] D loss: 0.5113, G loss: 2.3640\n",
      "[844/1600] D loss: 0.6354, G loss: 2.1278\n",
      "[964/1600] D loss: 1.0889, G loss: 1.2825\n",
      "[1084/1600] D loss: 1.4060, G loss: 0.9134\n",
      "[1204/1600] D loss: 1.0397, G loss: 1.2954\n",
      "[1324/1600] D loss: 1.0889, G loss: 0.8360\n",
      "[1444/1600] D loss: 0.9421, G loss: 1.3369\n",
      "[1564/1600] D loss: 0.9140, G loss: 1.3032\n",
      "train error: \n",
      " D loss: 1.006178, G loss: 1.419716, D accuracy: 69.1%, cell accuracy: 98.7%, board accuracy: 41.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.140437, G loss: 1.514223, D accuracy: 65.6%, cell accuracy: 98.6%, board accuracy: 41.2% \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3993, G loss: 0.7240\n",
      "[124/1600] D loss: 0.4391, G loss: 3.0157\n",
      "[244/1600] D loss: 0.8342, G loss: 1.8656\n",
      "[364/1600] D loss: 0.5453, G loss: 2.1715\n",
      "[484/1600] D loss: 1.1654, G loss: 0.6819\n",
      "[604/1600] D loss: 0.6894, G loss: 1.6720\n",
      "[724/1600] D loss: 1.9568, G loss: 0.7959\n",
      "[844/1600] D loss: 1.0602, G loss: 1.2041\n",
      "[964/1600] D loss: 1.2629, G loss: 1.2911\n",
      "[1084/1600] D loss: 1.1020, G loss: 1.0740\n",
      "[1204/1600] D loss: 1.1544, G loss: 1.4936\n",
      "[1324/1600] D loss: 0.7077, G loss: 2.6114\n",
      "[1444/1600] D loss: 0.8999, G loss: 1.6825\n",
      "[1564/1600] D loss: 1.0816, G loss: 1.2574\n",
      "train error: \n",
      " D loss: 1.034165, G loss: 1.479419, D accuracy: 68.0%, cell accuracy: 98.8%, board accuracy: 43.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.202081, G loss: 1.579847, D accuracy: 64.6%, cell accuracy: 98.6%, board accuracy: 44.2% \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3421, G loss: 0.6059\n",
      "[124/1600] D loss: 1.1494, G loss: 1.1905\n",
      "[244/1600] D loss: 1.2078, G loss: 0.9902\n",
      "[364/1600] D loss: 1.4527, G loss: 0.6709\n",
      "[484/1600] D loss: 1.4164, G loss: 0.6324\n",
      "[604/1600] D loss: 1.1893, G loss: 1.5721\n",
      "[724/1600] D loss: 0.7996, G loss: 2.3009\n",
      "[844/1600] D loss: 0.6233, G loss: 2.4554\n",
      "[964/1600] D loss: 0.6413, G loss: 1.9050\n",
      "[1084/1600] D loss: 0.8941, G loss: 1.9575\n",
      "[1204/1600] D loss: 0.8084, G loss: 1.3109\n",
      "[1324/1600] D loss: 0.7161, G loss: 1.9597\n",
      "[1444/1600] D loss: 0.3973, G loss: 2.1434\n",
      "[1564/1600] D loss: 1.1269, G loss: 0.9231\n",
      "train error: \n",
      " D loss: 1.042036, G loss: 1.565161, D accuracy: 67.4%, cell accuracy: 98.8%, board accuracy: 44.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.191091, G loss: 1.678547, D accuracy: 64.5%, cell accuracy: 98.6%, board accuracy: 43.2% \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8604, G loss: 1.5748\n",
      "[124/1600] D loss: 1.0644, G loss: 1.0919\n",
      "[244/1600] D loss: 1.4420, G loss: 0.6167\n",
      "[364/1600] D loss: 0.7283, G loss: 1.7028\n",
      "[484/1600] D loss: 0.3969, G loss: 2.4592\n",
      "[604/1600] D loss: 0.5608, G loss: 1.6786\n",
      "[724/1600] D loss: 0.2679, G loss: 2.3203\n",
      "[844/1600] D loss: 1.0919, G loss: 1.2130\n",
      "[964/1600] D loss: 0.8991, G loss: 1.5171\n",
      "[1084/1600] D loss: 0.9470, G loss: 1.0440\n",
      "[1204/1600] D loss: 0.4417, G loss: 2.3101\n",
      "[1324/1600] D loss: 1.0476, G loss: 1.1386\n",
      "[1444/1600] D loss: 0.8774, G loss: 1.0681\n",
      "[1564/1600] D loss: 1.2381, G loss: 1.4679\n",
      "train error: \n",
      " D loss: 1.088072, G loss: 1.180587, D accuracy: 68.7%, cell accuracy: 98.8%, board accuracy: 39.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.170499, G loss: 1.282414, D accuracy: 65.8%, cell accuracy: 98.6%, board accuracy: 36.8% \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8161, G loss: 1.5739\n",
      "[124/1600] D loss: 1.1796, G loss: 1.2995\n",
      "[244/1600] D loss: 1.4853, G loss: 0.6495\n",
      "[364/1600] D loss: 1.4266, G loss: 1.2252\n",
      "[484/1600] D loss: 1.1870, G loss: 1.9037\n",
      "[604/1600] D loss: 0.7339, G loss: 1.2882\n",
      "[724/1600] D loss: 0.9599, G loss: 1.2241\n",
      "[844/1600] D loss: 0.9393, G loss: 1.1442\n",
      "[964/1600] D loss: 1.1512, G loss: 0.8610\n",
      "[1084/1600] D loss: 0.6661, G loss: 2.1426\n",
      "[1204/1600] D loss: 0.8504, G loss: 2.0366\n",
      "[1324/1600] D loss: 0.9210, G loss: 1.2087\n",
      "[1444/1600] D loss: 1.3684, G loss: 0.7876\n",
      "[1564/1600] D loss: 0.5938, G loss: 1.7176\n",
      "train error: \n",
      " D loss: 1.017335, G loss: 1.386595, D accuracy: 68.7%, cell accuracy: 98.8%, board accuracy: 43.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.155379, G loss: 1.501278, D accuracy: 66.0%, cell accuracy: 98.6%, board accuracy: 41.5% \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9353, G loss: 1.3908\n",
      "[124/1600] D loss: 1.3341, G loss: 0.6712\n",
      "[244/1600] D loss: 1.0995, G loss: 0.8990\n",
      "[364/1600] D loss: 1.4906, G loss: 0.9817\n",
      "[484/1600] D loss: 1.3700, G loss: 0.6267\n",
      "[604/1600] D loss: 0.3794, G loss: 2.8710\n",
      "[724/1600] D loss: 0.7291, G loss: 2.1770\n",
      "[844/1600] D loss: 0.9919, G loss: 1.2963\n",
      "[964/1600] D loss: 0.9625, G loss: 1.2643\n",
      "[1084/1600] D loss: 1.0897, G loss: 1.3218\n",
      "[1204/1600] D loss: 0.7265, G loss: 2.4054\n",
      "[1324/1600] D loss: 1.2731, G loss: 0.8247\n",
      "[1444/1600] D loss: 0.7354, G loss: 1.8271\n",
      "[1564/1600] D loss: 1.2076, G loss: 1.2154\n",
      "train error: \n",
      " D loss: 1.042539, G loss: 1.338323, D accuracy: 67.6%, cell accuracy: 98.8%, board accuracy: 43.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.176111, G loss: 1.443261, D accuracy: 66.4%, cell accuracy: 98.7%, board accuracy: 41.0% \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3278, G loss: 0.8103\n",
      "[124/1600] D loss: 1.1381, G loss: 0.7808\n",
      "[244/1600] D loss: 0.9446, G loss: 1.8773\n",
      "[364/1600] D loss: 0.9546, G loss: 1.4200\n",
      "[484/1600] D loss: 0.7090, G loss: 1.7558\n",
      "[604/1600] D loss: 0.4641, G loss: 2.2733\n",
      "[724/1600] D loss: 1.6071, G loss: 1.1252\n",
      "[844/1600] D loss: 1.1134, G loss: 1.2472\n",
      "[964/1600] D loss: 1.2836, G loss: 0.8309\n",
      "[1084/1600] D loss: 0.6672, G loss: 1.7481\n",
      "[1204/1600] D loss: 0.9977, G loss: 1.0548\n",
      "[1324/1600] D loss: 1.1368, G loss: 0.9223\n",
      "[1444/1600] D loss: 1.4087, G loss: 0.8624\n",
      "[1564/1600] D loss: 0.7759, G loss: 1.4233\n",
      "train error: \n",
      " D loss: 1.051898, G loss: 1.284738, D accuracy: 67.9%, cell accuracy: 98.8%, board accuracy: 44.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.177383, G loss: 1.417864, D accuracy: 65.4%, cell accuracy: 98.6%, board accuracy: 42.5% \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6228, G loss: 2.6751\n",
      "[124/1600] D loss: 1.0923, G loss: 1.8423\n",
      "[244/1600] D loss: 0.8521, G loss: 1.6511\n",
      "[364/1600] D loss: 0.8601, G loss: 1.4711\n",
      "[484/1600] D loss: 1.4117, G loss: 0.5110\n",
      "[604/1600] D loss: 0.9302, G loss: 1.3232\n",
      "[724/1600] D loss: 0.9558, G loss: 1.0546\n",
      "[844/1600] D loss: 1.1859, G loss: 0.8636\n",
      "[964/1600] D loss: 1.0582, G loss: 1.7844\n",
      "[1084/1600] D loss: 1.0797, G loss: 1.2766\n",
      "[1204/1600] D loss: 1.2336, G loss: 0.9309\n",
      "[1324/1600] D loss: 0.7633, G loss: 2.0856\n",
      "[1444/1600] D loss: 0.8227, G loss: 1.8016\n",
      "[1564/1600] D loss: 1.3852, G loss: 1.0718\n",
      "train error: \n",
      " D loss: 1.036827, G loss: 1.334729, D accuracy: 67.7%, cell accuracy: 98.8%, board accuracy: 44.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.171861, G loss: 1.441769, D accuracy: 64.2%, cell accuracy: 98.7%, board accuracy: 42.8% \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6854, G loss: 2.5986\n",
      "[124/1600] D loss: 1.3740, G loss: 0.7924\n",
      "[244/1600] D loss: 0.4348, G loss: 2.3065\n",
      "[364/1600] D loss: 0.0657, G loss: 2.8872\n",
      "[484/1600] D loss: 1.1762, G loss: 1.2769\n",
      "[604/1600] D loss: 0.7502, G loss: 1.6319\n",
      "[724/1600] D loss: 1.1579, G loss: 0.8749\n",
      "[844/1600] D loss: 0.8314, G loss: 1.1139\n",
      "[964/1600] D loss: 0.6160, G loss: 2.2453\n",
      "[1084/1600] D loss: 1.3534, G loss: 0.7805\n",
      "[1204/1600] D loss: 1.3263, G loss: 0.6698\n",
      "[1324/1600] D loss: 1.2713, G loss: 1.2192\n",
      "[1444/1600] D loss: 0.7417, G loss: 1.7666\n",
      "[1564/1600] D loss: 1.3062, G loss: 0.8985\n",
      "train error: \n",
      " D loss: 1.033866, G loss: 1.491215, D accuracy: 67.4%, cell accuracy: 98.8%, board accuracy: 45.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.172717, G loss: 1.595481, D accuracy: 65.2%, cell accuracy: 98.6%, board accuracy: 42.0% \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0380, G loss: 1.9516\n",
      "[124/1600] D loss: 1.6027, G loss: 0.4635\n",
      "[244/1600] D loss: 0.7128, G loss: 2.6747\n",
      "[364/1600] D loss: 1.3155, G loss: 0.8098\n",
      "[484/1600] D loss: 1.2181, G loss: 0.8511\n",
      "[604/1600] D loss: 0.7430, G loss: 1.7590\n",
      "[724/1600] D loss: 1.3107, G loss: 0.8940\n",
      "[844/1600] D loss: 1.3553, G loss: 0.9947\n",
      "[964/1600] D loss: 0.8221, G loss: 1.3064\n",
      "[1084/1600] D loss: 1.1816, G loss: 0.9003\n",
      "[1204/1600] D loss: 1.2487, G loss: 0.9009\n",
      "[1324/1600] D loss: 1.1063, G loss: 0.9001\n",
      "[1444/1600] D loss: 1.1027, G loss: 1.4561\n",
      "[1564/1600] D loss: 0.5817, G loss: 1.9002\n",
      "train error: \n",
      " D loss: 1.166135, G loss: 1.830117, D accuracy: 64.9%, cell accuracy: 98.8%, board accuracy: 45.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312146, G loss: 1.974605, D accuracy: 63.6%, cell accuracy: 98.6%, board accuracy: 42.0% \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1446, G loss: 1.5500\n",
      "[124/1600] D loss: 1.4211, G loss: 0.7845\n",
      "[244/1600] D loss: 0.9267, G loss: 1.1811\n",
      "[364/1600] D loss: 1.0156, G loss: 1.0881\n",
      "[484/1600] D loss: 0.4507, G loss: 2.0016\n",
      "[604/1600] D loss: 0.8866, G loss: 2.1701\n",
      "[724/1600] D loss: 1.4089, G loss: 0.7893\n",
      "[844/1600] D loss: 1.1837, G loss: 0.8282\n",
      "[964/1600] D loss: 1.2232, G loss: 1.1772\n",
      "[1084/1600] D loss: 0.7159, G loss: 1.5693\n",
      "[1204/1600] D loss: 0.6975, G loss: 1.5700\n",
      "[1324/1600] D loss: 0.9770, G loss: 1.3108\n",
      "[1444/1600] D loss: 1.4302, G loss: 0.7797\n",
      "[1564/1600] D loss: 1.2432, G loss: 1.6195\n",
      "train error: \n",
      " D loss: 1.193328, G loss: 0.986432, D accuracy: 65.0%, cell accuracy: 98.8%, board accuracy: 45.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267930, G loss: 1.083618, D accuracy: 64.4%, cell accuracy: 98.6%, board accuracy: 43.2% \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1151, G loss: 1.1510\n",
      "[124/1600] D loss: 1.1672, G loss: 1.5979\n",
      "[244/1600] D loss: 1.0949, G loss: 1.3758\n",
      "[364/1600] D loss: 1.3783, G loss: 0.5447\n",
      "[484/1600] D loss: 1.0714, G loss: 0.8322\n",
      "[604/1600] D loss: 0.7815, G loss: 1.7103\n",
      "[724/1600] D loss: 1.0232, G loss: 1.3819\n",
      "[844/1600] D loss: 1.1959, G loss: 0.6816\n",
      "[964/1600] D loss: 1.1549, G loss: 1.2179\n",
      "[1084/1600] D loss: 0.7911, G loss: 1.4802\n",
      "[1204/1600] D loss: 0.5544, G loss: 3.0057\n",
      "[1324/1600] D loss: 0.6129, G loss: 1.7823\n",
      "[1444/1600] D loss: 0.8840, G loss: 1.5144\n",
      "[1564/1600] D loss: 1.4629, G loss: 0.5818\n",
      "train error: \n",
      " D loss: 1.039600, G loss: 1.238476, D accuracy: 68.0%, cell accuracy: 98.7%, board accuracy: 46.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.161243, G loss: 1.342618, D accuracy: 65.4%, cell accuracy: 98.5%, board accuracy: 44.2% \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5677, G loss: 1.6546\n",
      "[124/1600] D loss: 1.5007, G loss: 0.9171\n",
      "[244/1600] D loss: 0.7444, G loss: 1.3657\n",
      "[364/1600] D loss: 1.4010, G loss: 0.9965\n",
      "[484/1600] D loss: 1.1164, G loss: 1.8488\n",
      "[604/1600] D loss: 1.1908, G loss: 1.1998\n",
      "[724/1600] D loss: 1.2491, G loss: 0.8488\n",
      "[844/1600] D loss: 1.2365, G loss: 1.3749\n",
      "[964/1600] D loss: 0.9689, G loss: 1.1963\n",
      "[1084/1600] D loss: 0.9380, G loss: 1.4536\n",
      "[1204/1600] D loss: 1.0368, G loss: 1.1639\n",
      "[1324/1600] D loss: 0.7526, G loss: 2.0903\n",
      "[1444/1600] D loss: 0.5147, G loss: 2.9510\n",
      "[1564/1600] D loss: 0.7123, G loss: 1.9068\n",
      "train error: \n",
      " D loss: 1.050548, G loss: 1.312610, D accuracy: 67.7%, cell accuracy: 98.8%, board accuracy: 47.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.183709, G loss: 1.404164, D accuracy: 64.5%, cell accuracy: 98.7%, board accuracy: 43.5% \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2530, G loss: 0.8483\n",
      "[124/1600] D loss: 1.2220, G loss: 1.6251\n",
      "[244/1600] D loss: 1.0617, G loss: 1.3705\n",
      "[364/1600] D loss: 1.4423, G loss: 0.6445\n",
      "[484/1600] D loss: 0.4361, G loss: 2.8628\n",
      "[604/1600] D loss: 0.9448, G loss: 1.2140\n",
      "[724/1600] D loss: 1.1580, G loss: 0.8308\n",
      "[844/1600] D loss: 0.8964, G loss: 1.4709\n",
      "[964/1600] D loss: 1.0957, G loss: 0.9907\n",
      "[1084/1600] D loss: 0.7357, G loss: 1.7203\n",
      "[1204/1600] D loss: 0.6617, G loss: 1.7936\n",
      "[1324/1600] D loss: 0.7467, G loss: 1.4411\n",
      "[1444/1600] D loss: 1.1471, G loss: 0.8441\n",
      "[1564/1600] D loss: 1.0614, G loss: 1.3936\n",
      "train error: \n",
      " D loss: 1.046932, G loss: 1.252707, D accuracy: 67.6%, cell accuracy: 98.8%, board accuracy: 46.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.162238, G loss: 1.382035, D accuracy: 65.1%, cell accuracy: 98.6%, board accuracy: 43.0% \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8526, G loss: 1.5764\n",
      "[124/1600] D loss: 1.1377, G loss: 0.8656\n",
      "[244/1600] D loss: 0.7732, G loss: 2.6486\n",
      "[364/1600] D loss: 0.5411, G loss: 2.6746\n",
      "[484/1600] D loss: 0.6272, G loss: 2.9742\n",
      "[604/1600] D loss: 0.3129, G loss: 2.6753\n",
      "[724/1600] D loss: 0.8004, G loss: 1.5343\n",
      "[844/1600] D loss: 0.6333, G loss: 2.2790\n",
      "[964/1600] D loss: 1.1892, G loss: 1.2511\n",
      "[1084/1600] D loss: 1.2039, G loss: 0.9734\n",
      "[1204/1600] D loss: 1.1965, G loss: 1.0101\n",
      "[1324/1600] D loss: 1.4910, G loss: 0.5586\n",
      "[1444/1600] D loss: 0.8039, G loss: 1.9599\n",
      "[1564/1600] D loss: 0.4903, G loss: 2.2502\n",
      "train error: \n",
      " D loss: 1.025621, G loss: 1.399453, D accuracy: 67.5%, cell accuracy: 98.9%, board accuracy: 49.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.166411, G loss: 1.497635, D accuracy: 64.8%, cell accuracy: 98.8%, board accuracy: 45.8% \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7451, G loss: 1.8234\n",
      "[124/1600] D loss: 1.0989, G loss: 1.5129\n",
      "[244/1600] D loss: 0.7484, G loss: 1.7413\n",
      "[364/1600] D loss: 1.4291, G loss: 0.4947\n",
      "[484/1600] D loss: 0.8888, G loss: 1.2891\n",
      "[604/1600] D loss: 0.8509, G loss: 3.6300\n",
      "[724/1600] D loss: 1.1454, G loss: 1.3830\n",
      "[844/1600] D loss: 1.2163, G loss: 0.8718\n",
      "[964/1600] D loss: 1.5766, G loss: 0.9012\n",
      "[1084/1600] D loss: 1.0703, G loss: 1.3921\n",
      "[1204/1600] D loss: 1.0327, G loss: 1.4141\n",
      "[1324/1600] D loss: 1.0784, G loss: 1.3287\n",
      "[1444/1600] D loss: 1.3438, G loss: 1.1523\n",
      "[1564/1600] D loss: 1.2857, G loss: 0.9298\n",
      "train error: \n",
      " D loss: 1.035220, G loss: 1.567802, D accuracy: 67.2%, cell accuracy: 98.9%, board accuracy: 47.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.195827, G loss: 1.658826, D accuracy: 64.8%, cell accuracy: 98.7%, board accuracy: 45.2% \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9450, G loss: 1.2910\n",
      "[124/1600] D loss: 0.7512, G loss: 1.8457\n",
      "[244/1600] D loss: 1.2128, G loss: 0.9413\n",
      "[364/1600] D loss: 1.2007, G loss: 0.7621\n",
      "[484/1600] D loss: 0.8204, G loss: 1.3851\n",
      "[604/1600] D loss: 0.9987, G loss: 1.5485\n",
      "[724/1600] D loss: 1.5520, G loss: 1.8587\n",
      "[844/1600] D loss: 1.1255, G loss: 1.0408\n",
      "[964/1600] D loss: 1.3425, G loss: 0.9666\n",
      "[1084/1600] D loss: 0.4025, G loss: 2.0944\n",
      "[1204/1600] D loss: 1.2578, G loss: 1.0016\n",
      "[1324/1600] D loss: 0.9287, G loss: 1.5787\n",
      "[1444/1600] D loss: 1.5308, G loss: 0.5674\n",
      "[1564/1600] D loss: 1.0801, G loss: 0.8175\n",
      "train error: \n",
      " D loss: 1.037113, G loss: 1.309219, D accuracy: 67.8%, cell accuracy: 98.9%, board accuracy: 48.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.182989, G loss: 1.388367, D accuracy: 64.0%, cell accuracy: 98.7%, board accuracy: 44.2% \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6729, G loss: 1.5766\n",
      "[124/1600] D loss: 0.7579, G loss: 2.0761\n",
      "[244/1600] D loss: 0.8170, G loss: 1.3088\n",
      "[364/1600] D loss: 1.0216, G loss: 1.6581\n",
      "[484/1600] D loss: 0.3366, G loss: 3.0597\n",
      "[604/1600] D loss: 1.1360, G loss: 1.3652\n",
      "[724/1600] D loss: 0.9153, G loss: 2.0276\n",
      "[844/1600] D loss: 0.5410, G loss: 2.6569\n",
      "[964/1600] D loss: 1.1281, G loss: 1.5370\n",
      "[1084/1600] D loss: 1.1140, G loss: 1.7145\n",
      "[1204/1600] D loss: 0.7527, G loss: 1.7549\n",
      "[1324/1600] D loss: 1.1272, G loss: 1.8843\n",
      "[1444/1600] D loss: 1.4893, G loss: 0.8803\n",
      "[1564/1600] D loss: 1.0879, G loss: 1.0875\n",
      "train error: \n",
      " D loss: 1.039164, G loss: 1.524176, D accuracy: 66.7%, cell accuracy: 98.8%, board accuracy: 48.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.190659, G loss: 1.635694, D accuracy: 63.1%, cell accuracy: 98.6%, board accuracy: 45.0% \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1172, G loss: 1.1688\n",
      "[124/1600] D loss: 0.9303, G loss: 1.0008\n",
      "[244/1600] D loss: 1.0772, G loss: 1.3811\n",
      "[364/1600] D loss: 0.4461, G loss: 2.2803\n",
      "[484/1600] D loss: 1.3555, G loss: 1.1062\n",
      "[604/1600] D loss: 1.2513, G loss: 1.2340\n",
      "[724/1600] D loss: 1.3915, G loss: 0.7449\n",
      "[844/1600] D loss: 1.3265, G loss: 0.9381\n",
      "[964/1600] D loss: 1.3652, G loss: 0.6007\n",
      "[1084/1600] D loss: 0.7417, G loss: 1.3901\n",
      "[1204/1600] D loss: 0.9976, G loss: 1.1392\n",
      "[1324/1600] D loss: 1.0731, G loss: 1.1694\n",
      "[1444/1600] D loss: 0.3956, G loss: 2.2115\n",
      "[1564/1600] D loss: 0.8026, G loss: 1.8116\n",
      "train error: \n",
      " D loss: 1.029129, G loss: 1.467083, D accuracy: 67.3%, cell accuracy: 98.8%, board accuracy: 48.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.169835, G loss: 1.560793, D accuracy: 63.9%, cell accuracy: 98.7%, board accuracy: 46.8% \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4405, G loss: 2.3239\n",
      "[124/1600] D loss: 1.5118, G loss: 0.6616\n",
      "[244/1600] D loss: 0.4927, G loss: 1.7948\n",
      "[364/1600] D loss: 0.8131, G loss: 2.0938\n",
      "[484/1600] D loss: 1.2670, G loss: 0.7749\n",
      "[604/1600] D loss: 1.1628, G loss: 2.9871\n",
      "[724/1600] D loss: 0.9753, G loss: 1.6281\n",
      "[844/1600] D loss: 0.8049, G loss: 1.5015\n",
      "[964/1600] D loss: 1.0487, G loss: 1.4265\n",
      "[1084/1600] D loss: 1.0174, G loss: 1.6703\n",
      "[1204/1600] D loss: 1.0582, G loss: 1.3071\n",
      "[1324/1600] D loss: 1.3750, G loss: 1.0283\n",
      "[1444/1600] D loss: 1.0896, G loss: 1.5424\n",
      "[1564/1600] D loss: 1.4527, G loss: 0.5100\n",
      "train error: \n",
      " D loss: 1.055133, G loss: 1.479320, D accuracy: 66.0%, cell accuracy: 98.8%, board accuracy: 48.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.193282, G loss: 1.600949, D accuracy: 64.9%, cell accuracy: 98.7%, board accuracy: 45.0% \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4138, G loss: 0.7536\n",
      "[124/1600] D loss: 0.8192, G loss: 2.0685\n",
      "[244/1600] D loss: 1.0345, G loss: 0.9976\n",
      "[364/1600] D loss: 1.2316, G loss: 0.8457\n",
      "[484/1600] D loss: 0.9931, G loss: 1.0913\n",
      "[604/1600] D loss: 1.3284, G loss: 0.7178\n",
      "[724/1600] D loss: 1.2998, G loss: 0.7349\n",
      "[844/1600] D loss: 0.6908, G loss: 2.5283\n",
      "[964/1600] D loss: 1.2502, G loss: 1.2129\n",
      "[1084/1600] D loss: 0.9468, G loss: 2.0561\n",
      "[1204/1600] D loss: 1.2433, G loss: 0.5750\n",
      "[1324/1600] D loss: 1.1744, G loss: 1.9654\n",
      "[1444/1600] D loss: 1.2627, G loss: 1.0200\n",
      "[1564/1600] D loss: 1.0071, G loss: 1.8169\n",
      "train error: \n",
      " D loss: 1.170320, G loss: 1.000853, D accuracy: 66.1%, cell accuracy: 98.8%, board accuracy: 49.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.240970, G loss: 1.089662, D accuracy: 65.0%, cell accuracy: 98.6%, board accuracy: 46.5% \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3262, G loss: 1.0000\n",
      "[124/1600] D loss: 0.4429, G loss: 2.3450\n",
      "[244/1600] D loss: 1.0493, G loss: 1.4248\n",
      "[364/1600] D loss: 1.0602, G loss: 1.1423\n",
      "[484/1600] D loss: 0.6554, G loss: 2.1387\n",
      "[604/1600] D loss: 0.7959, G loss: 1.7676\n",
      "[724/1600] D loss: 0.7299, G loss: 1.9080\n",
      "[844/1600] D loss: 1.3354, G loss: 0.8375\n",
      "[964/1600] D loss: 1.2309, G loss: 0.7956\n",
      "[1084/1600] D loss: 1.0977, G loss: 1.5445\n",
      "[1204/1600] D loss: 1.8312, G loss: 1.4466\n",
      "[1324/1600] D loss: 1.2417, G loss: 0.8510\n",
      "[1444/1600] D loss: 1.3190, G loss: 0.7662\n",
      "[1564/1600] D loss: 1.3890, G loss: 0.6696\n",
      "train error: \n",
      " D loss: 1.034114, G loss: 1.343455, D accuracy: 67.5%, cell accuracy: 98.8%, board accuracy: 48.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.155519, G loss: 1.458672, D accuracy: 65.1%, cell accuracy: 98.6%, board accuracy: 45.8% \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1126, G loss: 0.9760\n",
      "[124/1600] D loss: 0.8133, G loss: 1.9190\n",
      "[244/1600] D loss: 1.0998, G loss: 1.2515\n",
      "[364/1600] D loss: 0.9703, G loss: 2.1071\n",
      "[484/1600] D loss: 1.0967, G loss: 1.5420\n",
      "[604/1600] D loss: 1.4108, G loss: 0.9438\n",
      "[724/1600] D loss: 1.0282, G loss: 1.2676\n",
      "[844/1600] D loss: 1.2841, G loss: 1.1586\n",
      "[964/1600] D loss: 1.2248, G loss: 0.7693\n",
      "[1084/1600] D loss: 0.0898, G loss: 3.3200\n",
      "[1204/1600] D loss: 0.7113, G loss: 2.2421\n",
      "[1324/1600] D loss: 0.7608, G loss: 2.8239\n",
      "[1444/1600] D loss: 1.0807, G loss: 1.1114\n",
      "[1564/1600] D loss: 1.3178, G loss: 1.0235\n",
      "train error: \n",
      " D loss: 1.052221, G loss: 1.633311, D accuracy: 66.3%, cell accuracy: 98.6%, board accuracy: 46.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.200001, G loss: 1.750124, D accuracy: 64.1%, cell accuracy: 98.4%, board accuracy: 45.5% \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4370, G loss: 0.9309\n",
      "[124/1600] D loss: 1.1199, G loss: 1.0620\n",
      "[244/1600] D loss: 1.4036, G loss: 0.5404\n",
      "[364/1600] D loss: 0.6378, G loss: 1.7538\n",
      "[484/1600] D loss: 1.5212, G loss: 0.7498\n",
      "[604/1600] D loss: 1.1302, G loss: 1.3355\n",
      "[724/1600] D loss: 1.2721, G loss: 1.0954\n",
      "[844/1600] D loss: 0.8248, G loss: 1.8699\n",
      "[964/1600] D loss: 0.3767, G loss: 1.7411\n",
      "[1084/1600] D loss: 0.9584, G loss: 1.5870\n",
      "[1204/1600] D loss: 1.0659, G loss: 1.1395\n",
      "[1324/1600] D loss: 0.9720, G loss: 1.5908\n",
      "[1444/1600] D loss: 0.3597, G loss: 1.9848\n",
      "[1564/1600] D loss: 0.7450, G loss: 2.6194\n",
      "train error: \n",
      " D loss: 1.042756, G loss: 1.491499, D accuracy: 67.0%, cell accuracy: 98.8%, board accuracy: 49.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.181660, G loss: 1.593080, D accuracy: 65.2%, cell accuracy: 98.7%, board accuracy: 47.2% \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8940, G loss: 1.5559\n",
      "[124/1600] D loss: 0.6793, G loss: 1.8726\n",
      "[244/1600] D loss: 0.6801, G loss: 1.8628\n",
      "[364/1600] D loss: 1.4018, G loss: 0.9779\n",
      "[484/1600] D loss: 0.4413, G loss: 3.3254\n",
      "[604/1600] D loss: 0.7598, G loss: 1.7337\n",
      "[724/1600] D loss: 0.4592, G loss: 2.4450\n",
      "[844/1600] D loss: 1.1784, G loss: 0.7585\n",
      "[964/1600] D loss: 1.0458, G loss: 1.2605\n",
      "[1084/1600] D loss: 0.4308, G loss: 2.2349\n",
      "[1204/1600] D loss: 0.7574, G loss: 2.3097\n",
      "[1324/1600] D loss: 0.7337, G loss: 1.8948\n",
      "[1444/1600] D loss: 0.5812, G loss: 2.0005\n",
      "[1564/1600] D loss: 0.9712, G loss: 1.9655\n",
      "train error: \n",
      " D loss: 1.029643, G loss: 1.437004, D accuracy: 67.7%, cell accuracy: 98.9%, board accuracy: 51.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.170983, G loss: 1.537781, D accuracy: 64.1%, cell accuracy: 98.7%, board accuracy: 46.8% \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4159, G loss: 0.8403\n",
      "[124/1600] D loss: 0.7338, G loss: 2.4940\n",
      "[244/1600] D loss: 0.8903, G loss: 1.5388\n",
      "[364/1600] D loss: 1.3992, G loss: 0.7668\n",
      "[484/1600] D loss: 1.0765, G loss: 1.1441\n",
      "[604/1600] D loss: 1.3496, G loss: 1.5019\n",
      "[724/1600] D loss: 1.1126, G loss: 0.7440\n",
      "[844/1600] D loss: 0.6313, G loss: 2.2425\n",
      "[964/1600] D loss: 0.7316, G loss: 1.6140\n",
      "[1084/1600] D loss: 1.5827, G loss: 1.0519\n",
      "[1204/1600] D loss: 1.1133, G loss: 1.3062\n",
      "[1324/1600] D loss: 1.2438, G loss: 1.0589\n",
      "[1444/1600] D loss: 1.3661, G loss: 0.9350\n",
      "[1564/1600] D loss: 1.1138, G loss: 0.7935\n",
      "train error: \n",
      " D loss: 1.037719, G loss: 1.221595, D accuracy: 67.4%, cell accuracy: 98.9%, board accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.144721, G loss: 1.318719, D accuracy: 64.9%, cell accuracy: 98.7%, board accuracy: 47.2% \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9391, G loss: 2.0983\n",
      "[124/1600] D loss: 1.3590, G loss: 0.8411\n",
      "[244/1600] D loss: 1.1356, G loss: 1.7817\n",
      "[364/1600] D loss: 0.7435, G loss: 1.1954\n",
      "[484/1600] D loss: 1.0751, G loss: 1.0890\n",
      "[604/1600] D loss: 0.7748, G loss: 2.9864\n",
      "[724/1600] D loss: 0.5156, G loss: 1.6138\n",
      "[844/1600] D loss: 0.4836, G loss: 1.9465\n",
      "[964/1600] D loss: 1.4678, G loss: 0.5383\n",
      "[1084/1600] D loss: 1.0796, G loss: 1.2182\n",
      "[1204/1600] D loss: 1.0841, G loss: 1.3279\n",
      "[1324/1600] D loss: 1.0042, G loss: 1.7294\n",
      "[1444/1600] D loss: 1.5258, G loss: 0.7058\n",
      "[1564/1600] D loss: 1.3827, G loss: 0.8402\n",
      "train error: \n",
      " D loss: 1.064601, G loss: 1.237338, D accuracy: 67.2%, cell accuracy: 98.9%, board accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.172530, G loss: 1.343127, D accuracy: 65.6%, cell accuracy: 98.7%, board accuracy: 47.0% \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9116, G loss: 1.4973\n",
      "[124/1600] D loss: 0.9481, G loss: 1.1852\n",
      "[244/1600] D loss: 1.0546, G loss: 1.4970\n",
      "[364/1600] D loss: 0.9740, G loss: 1.8199\n",
      "[484/1600] D loss: 0.9144, G loss: 1.4391\n",
      "[604/1600] D loss: 0.9792, G loss: 1.0378\n",
      "[724/1600] D loss: 0.9659, G loss: 1.1100\n",
      "[844/1600] D loss: 1.1400, G loss: 1.3774\n",
      "[964/1600] D loss: 0.9406, G loss: 1.1337\n",
      "[1084/1600] D loss: 1.3543, G loss: 0.8494\n",
      "[1204/1600] D loss: 1.3430, G loss: 0.8585\n",
      "[1324/1600] D loss: 1.5948, G loss: 0.9591\n",
      "[1444/1600] D loss: 1.1373, G loss: 1.2988\n",
      "[1564/1600] D loss: 0.7351, G loss: 1.6023\n",
      "train error: \n",
      " D loss: 1.047166, G loss: 1.256131, D accuracy: 66.9%, cell accuracy: 98.9%, board accuracy: 49.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.177647, G loss: 1.357544, D accuracy: 63.9%, cell accuracy: 98.7%, board accuracy: 44.8% \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9456, G loss: 1.0003\n",
      "[124/1600] D loss: 1.0641, G loss: 1.8163\n",
      "[244/1600] D loss: 1.1044, G loss: 1.1590\n",
      "[364/1600] D loss: 0.7411, G loss: 1.5493\n",
      "[484/1600] D loss: 0.9217, G loss: 1.9461\n",
      "[604/1600] D loss: 0.7277, G loss: 1.3226\n",
      "[724/1600] D loss: 1.3964, G loss: 0.8023\n",
      "[844/1600] D loss: 1.2259, G loss: 0.8634\n",
      "[964/1600] D loss: 0.8320, G loss: 1.5037\n",
      "[1084/1600] D loss: 0.4037, G loss: 2.2722\n",
      "[1204/1600] D loss: 1.1346, G loss: 1.2106\n",
      "[1324/1600] D loss: 0.7913, G loss: 1.9977\n",
      "[1444/1600] D loss: 1.0406, G loss: 0.7298\n",
      "[1564/1600] D loss: 1.0081, G loss: 1.4313\n",
      "train error: \n",
      " D loss: 1.080768, G loss: 1.164933, D accuracy: 66.8%, cell accuracy: 98.9%, board accuracy: 50.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.187887, G loss: 1.273951, D accuracy: 64.9%, cell accuracy: 98.7%, board accuracy: 46.2% \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3298, G loss: 0.8147\n",
      "[124/1600] D loss: 0.7005, G loss: 1.7325\n",
      "[244/1600] D loss: 1.3240, G loss: 1.1334\n",
      "[364/1600] D loss: 0.9880, G loss: 1.5448\n",
      "[484/1600] D loss: 0.7198, G loss: 2.4111\n",
      "[604/1600] D loss: 1.3126, G loss: 0.5829\n",
      "[724/1600] D loss: 1.2574, G loss: 0.5502\n",
      "[844/1600] D loss: 1.3803, G loss: 0.6365\n",
      "[964/1600] D loss: 1.0048, G loss: 0.9434\n",
      "[1084/1600] D loss: 1.3770, G loss: 0.7222\n",
      "[1204/1600] D loss: 0.7626, G loss: 1.4000\n",
      "[1324/1600] D loss: 0.7407, G loss: 1.8231\n",
      "[1444/1600] D loss: 1.1129, G loss: 1.3643\n",
      "[1564/1600] D loss: 1.2429, G loss: 1.6877\n",
      "train error: \n",
      " D loss: 1.055417, G loss: 1.274883, D accuracy: 67.2%, cell accuracy: 98.9%, board accuracy: 50.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.195282, G loss: 1.358892, D accuracy: 64.5%, cell accuracy: 98.8%, board accuracy: 44.8% \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9729, G loss: 1.3978\n",
      "[124/1600] D loss: 1.4589, G loss: 0.7407\n",
      "[244/1600] D loss: 1.2397, G loss: 0.6538\n",
      "[364/1600] D loss: 0.9897, G loss: 2.2290\n",
      "[484/1600] D loss: 0.9089, G loss: 1.6892\n",
      "[604/1600] D loss: 1.4311, G loss: 0.7663\n",
      "[724/1600] D loss: 1.2683, G loss: 0.6110\n",
      "[844/1600] D loss: 0.2981, G loss: 2.0040\n",
      "[964/1600] D loss: 0.7688, G loss: 1.4422\n",
      "[1084/1600] D loss: 1.0224, G loss: 1.5291\n",
      "[1204/1600] D loss: 0.4385, G loss: 2.2404\n",
      "[1324/1600] D loss: 1.3612, G loss: 0.7504\n",
      "[1444/1600] D loss: 1.1639, G loss: 1.2907\n",
      "[1564/1600] D loss: 0.7998, G loss: 2.3102\n",
      "train error: \n",
      " D loss: 1.109159, G loss: 1.210551, D accuracy: 66.7%, cell accuracy: 98.9%, board accuracy: 49.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.232477, G loss: 1.297582, D accuracy: 63.6%, cell accuracy: 98.7%, board accuracy: 43.5% \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1040, G loss: 1.5819\n",
      "[124/1600] D loss: 0.7288, G loss: 1.7396\n",
      "[244/1600] D loss: 1.6005, G loss: 0.7375\n",
      "[364/1600] D loss: 1.0949, G loss: 0.9916\n",
      "[484/1600] D loss: 1.1555, G loss: 0.7007\n",
      "[604/1600] D loss: 1.3924, G loss: 0.6271\n",
      "[724/1600] D loss: 1.3300, G loss: 0.7832\n",
      "[844/1600] D loss: 1.0516, G loss: 1.8931\n",
      "[964/1600] D loss: 1.2099, G loss: 1.4678\n",
      "[1084/1600] D loss: 1.0191, G loss: 0.9945\n",
      "[1204/1600] D loss: 1.0855, G loss: 0.9982\n",
      "[1324/1600] D loss: 1.1493, G loss: 1.2334\n",
      "[1444/1600] D loss: 1.0805, G loss: 1.0660\n",
      "[1564/1600] D loss: 0.9636, G loss: 1.2480\n",
      "train error: \n",
      " D loss: 1.047405, G loss: 1.536696, D accuracy: 66.6%, cell accuracy: 98.9%, board accuracy: 50.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.211042, G loss: 1.646009, D accuracy: 63.6%, cell accuracy: 98.7%, board accuracy: 45.8% \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4324, G loss: 0.8527\n",
      "[124/1600] D loss: 1.0786, G loss: 1.0549\n",
      "[244/1600] D loss: 1.0004, G loss: 1.4305\n",
      "[364/1600] D loss: 0.3793, G loss: 2.7992\n",
      "[484/1600] D loss: 1.3694, G loss: 0.7445\n",
      "[604/1600] D loss: 1.0604, G loss: 1.0701\n",
      "[724/1600] D loss: 0.7153, G loss: 3.2093\n",
      "[844/1600] D loss: 0.8839, G loss: 1.6589\n",
      "[964/1600] D loss: 1.1663, G loss: 1.1166\n",
      "[1084/1600] D loss: 0.7465, G loss: 1.1841\n",
      "[1204/1600] D loss: 1.2205, G loss: 0.9437\n",
      "[1324/1600] D loss: 1.1425, G loss: 1.4144\n",
      "[1444/1600] D loss: 0.8796, G loss: 1.1401\n",
      "[1564/1600] D loss: 1.0228, G loss: 1.4372\n",
      "train error: \n",
      " D loss: 1.047401, G loss: 1.488123, D accuracy: 66.7%, cell accuracy: 98.9%, board accuracy: 50.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.212173, G loss: 1.600321, D accuracy: 63.9%, cell accuracy: 98.7%, board accuracy: 46.2% \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3140, G loss: 0.7260\n",
      "[124/1600] D loss: 0.9021, G loss: 1.6494\n",
      "[244/1600] D loss: 1.1789, G loss: 0.8260\n",
      "[364/1600] D loss: 1.0982, G loss: 0.8891\n",
      "[484/1600] D loss: 1.3158, G loss: 0.9123\n",
      "[604/1600] D loss: 1.0866, G loss: 1.5064\n",
      "[724/1600] D loss: 0.8805, G loss: 1.7460\n",
      "[844/1600] D loss: 1.1682, G loss: 1.7113\n",
      "[964/1600] D loss: 0.8585, G loss: 1.4489\n",
      "[1084/1600] D loss: 1.1944, G loss: 1.4662\n",
      "[1204/1600] D loss: 0.7347, G loss: 1.8566\n",
      "[1324/1600] D loss: 1.1577, G loss: 1.0823\n",
      "[1444/1600] D loss: 1.2284, G loss: 0.9887\n",
      "[1564/1600] D loss: 1.2618, G loss: 0.8547\n",
      "train error: \n",
      " D loss: 1.067519, G loss: 1.214376, D accuracy: 66.9%, cell accuracy: 98.8%, board accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.212386, G loss: 1.281611, D accuracy: 64.2%, cell accuracy: 98.7%, board accuracy: 47.8% \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1112, G loss: 1.0640\n",
      "[124/1600] D loss: 0.9297, G loss: 1.5051\n",
      "[244/1600] D loss: 1.0439, G loss: 1.0263\n",
      "[364/1600] D loss: 1.5281, G loss: 1.1047\n",
      "[484/1600] D loss: 0.9388, G loss: 1.3776\n",
      "[604/1600] D loss: 0.9436, G loss: 1.0701\n",
      "[724/1600] D loss: 1.1715, G loss: 1.7978\n",
      "[844/1600] D loss: 0.4555, G loss: 2.8667\n",
      "[964/1600] D loss: 0.4371, G loss: 1.9123\n",
      "[1084/1600] D loss: 1.3895, G loss: 0.9014\n",
      "[1204/1600] D loss: 1.2578, G loss: 0.7762\n",
      "[1324/1600] D loss: 1.2765, G loss: 1.2636\n",
      "[1444/1600] D loss: 1.6188, G loss: 0.7056\n",
      "[1564/1600] D loss: 0.7183, G loss: 2.3064\n",
      "train error: \n",
      " D loss: 1.080679, G loss: 1.501085, D accuracy: 65.9%, cell accuracy: 98.9%, board accuracy: 51.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.225069, G loss: 1.596655, D accuracy: 64.0%, cell accuracy: 98.7%, board accuracy: 48.2% \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3695, G loss: 0.7577\n",
      "[124/1600] D loss: 1.4154, G loss: 0.7016\n",
      "[244/1600] D loss: 1.1378, G loss: 1.6905\n",
      "[364/1600] D loss: 1.3451, G loss: 0.8415\n",
      "[484/1600] D loss: 0.7426, G loss: 1.8677\n",
      "[604/1600] D loss: 1.1321, G loss: 1.2650\n",
      "[724/1600] D loss: 0.2669, G loss: 2.4630\n",
      "[844/1600] D loss: 1.2091, G loss: 1.3294\n",
      "[964/1600] D loss: 1.0739, G loss: 1.3448\n",
      "[1084/1600] D loss: 1.1104, G loss: 1.4913\n",
      "[1204/1600] D loss: 1.2283, G loss: 0.9328\n",
      "[1324/1600] D loss: 0.7100, G loss: 1.8918\n",
      "[1444/1600] D loss: 1.0869, G loss: 1.1355\n",
      "[1564/1600] D loss: 0.6550, G loss: 1.6462\n",
      "train error: \n",
      " D loss: 1.030756, G loss: 1.409632, D accuracy: 67.5%, cell accuracy: 98.9%, board accuracy: 47.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.188055, G loss: 1.484265, D accuracy: 63.5%, cell accuracy: 98.7%, board accuracy: 42.5% \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2581, G loss: 1.2914\n",
      "[124/1600] D loss: 0.7160, G loss: 1.4452\n",
      "[244/1600] D loss: 1.4199, G loss: 0.5292\n",
      "[364/1600] D loss: 1.2266, G loss: 0.6341\n",
      "[484/1600] D loss: 0.7044, G loss: 2.8073\n",
      "[604/1600] D loss: 0.4870, G loss: 2.1422\n",
      "[724/1600] D loss: 1.0549, G loss: 1.2998\n",
      "[844/1600] D loss: 0.7971, G loss: 1.5886\n",
      "[964/1600] D loss: 0.4241, G loss: 2.0217\n",
      "[1084/1600] D loss: 1.1819, G loss: 1.2296\n",
      "[1204/1600] D loss: 0.9069, G loss: 1.1072\n",
      "[1324/1600] D loss: 0.9163, G loss: 1.4278\n",
      "[1444/1600] D loss: 1.1757, G loss: 0.9644\n",
      "[1564/1600] D loss: 1.0368, G loss: 0.9614\n",
      "train error: \n",
      " D loss: 1.075287, G loss: 1.293768, D accuracy: 66.6%, cell accuracy: 98.8%, board accuracy: 51.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.226295, G loss: 1.377859, D accuracy: 62.6%, cell accuracy: 98.6%, board accuracy: 45.2% \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1328, G loss: 1.0548\n",
      "[124/1600] D loss: 0.4899, G loss: 2.0015\n",
      "[244/1600] D loss: 1.0823, G loss: 1.2207\n",
      "[364/1600] D loss: 0.6312, G loss: 2.1916\n",
      "[484/1600] D loss: 1.3851, G loss: 0.6092\n",
      "[604/1600] D loss: 1.0989, G loss: 1.6468\n",
      "[724/1600] D loss: 0.9699, G loss: 1.2981\n",
      "[844/1600] D loss: 0.7311, G loss: 1.5158\n",
      "[964/1600] D loss: 0.7398, G loss: 1.5903\n",
      "[1084/1600] D loss: 0.9325, G loss: 1.6804\n",
      "[1204/1600] D loss: 1.3921, G loss: 0.4992\n",
      "[1324/1600] D loss: 1.2678, G loss: 1.1362\n",
      "[1444/1600] D loss: 0.9702, G loss: 1.7348\n",
      "[1564/1600] D loss: 0.8409, G loss: 1.6548\n",
      "train error: \n",
      " D loss: 1.113205, G loss: 1.146121, D accuracy: 65.9%, cell accuracy: 98.9%, board accuracy: 51.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.218776, G loss: 1.225036, D accuracy: 64.0%, cell accuracy: 98.7%, board accuracy: 47.0% \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9473, G loss: 1.0262\n",
      "[124/1600] D loss: 0.8387, G loss: 1.8249\n",
      "[244/1600] D loss: 0.7985, G loss: 1.6824\n",
      "[364/1600] D loss: 1.0613, G loss: 1.3558\n",
      "[484/1600] D loss: 1.2347, G loss: 1.0063\n",
      "[604/1600] D loss: 1.1085, G loss: 0.8325\n",
      "[724/1600] D loss: 1.3701, G loss: 0.6243\n",
      "[844/1600] D loss: 0.8925, G loss: 1.0924\n",
      "[964/1600] D loss: 0.5753, G loss: 1.7389\n",
      "[1084/1600] D loss: 1.0771, G loss: 1.4646\n",
      "[1204/1600] D loss: 0.6630, G loss: 2.1208\n",
      "[1324/1600] D loss: 1.0454, G loss: 0.9170\n",
      "[1444/1600] D loss: 0.7350, G loss: 2.4001\n",
      "[1564/1600] D loss: 0.7983, G loss: 1.5736\n",
      "train error: \n",
      " D loss: 1.084227, G loss: 1.572265, D accuracy: 65.4%, cell accuracy: 98.9%, board accuracy: 51.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250419, G loss: 1.670523, D accuracy: 63.4%, cell accuracy: 98.7%, board accuracy: 46.2% \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4639, G loss: 1.1193\n",
      "[124/1600] D loss: 0.7829, G loss: 2.1143\n",
      "[244/1600] D loss: 0.7013, G loss: 2.6817\n",
      "[364/1600] D loss: 0.4491, G loss: 2.0263\n",
      "[484/1600] D loss: 1.2589, G loss: 0.6589\n",
      "[604/1600] D loss: 1.0193, G loss: 0.9243\n",
      "[724/1600] D loss: 1.1944, G loss: 0.9421\n",
      "[844/1600] D loss: 0.9997, G loss: 0.9255\n",
      "[964/1600] D loss: 1.1244, G loss: 1.1627\n",
      "[1084/1600] D loss: 1.1294, G loss: 1.6848\n",
      "[1204/1600] D loss: 1.3084, G loss: 0.7394\n",
      "[1324/1600] D loss: 1.0833, G loss: 1.2654\n",
      "[1444/1600] D loss: 1.2678, G loss: 0.6943\n",
      "[1564/1600] D loss: 0.7439, G loss: 1.7005\n",
      "train error: \n",
      " D loss: 1.102552, G loss: 1.519870, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 52.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281362, G loss: 1.592944, D accuracy: 63.5%, cell accuracy: 98.8%, board accuracy: 49.2% \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0512, G loss: 1.5634\n",
      "[124/1600] D loss: 1.0307, G loss: 1.2028\n",
      "[244/1600] D loss: 0.5154, G loss: 2.4179\n",
      "[364/1600] D loss: 1.3030, G loss: 0.9474\n",
      "[484/1600] D loss: 0.6842, G loss: 1.9260\n",
      "[604/1600] D loss: 1.1037, G loss: 1.2806\n",
      "[724/1600] D loss: 1.4924, G loss: 0.9880\n",
      "[844/1600] D loss: 1.0616, G loss: 1.1449\n",
      "[964/1600] D loss: 1.4652, G loss: 1.2078\n",
      "[1084/1600] D loss: 0.7790, G loss: 2.4533\n",
      "[1204/1600] D loss: 1.3323, G loss: 0.9522\n",
      "[1324/1600] D loss: 1.3142, G loss: 0.8265\n",
      "[1444/1600] D loss: 1.4220, G loss: 0.8091\n",
      "[1564/1600] D loss: 0.8655, G loss: 1.8781\n",
      "train error: \n",
      " D loss: 1.073500, G loss: 1.572653, D accuracy: 65.8%, cell accuracy: 98.9%, board accuracy: 52.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.219934, G loss: 1.691012, D accuracy: 63.9%, cell accuracy: 98.7%, board accuracy: 48.2% \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2451, G loss: 1.2965\n",
      "[124/1600] D loss: 0.7427, G loss: 2.1454\n",
      "[244/1600] D loss: 0.6419, G loss: 2.0622\n",
      "[364/1600] D loss: 0.3862, G loss: 2.6129\n",
      "[484/1600] D loss: 0.7775, G loss: 1.7003\n",
      "[604/1600] D loss: 1.3838, G loss: 0.9425\n",
      "[724/1600] D loss: 0.7667, G loss: 1.6546\n",
      "[844/1600] D loss: 0.8356, G loss: 1.5225\n",
      "[964/1600] D loss: 1.6912, G loss: 0.6468\n",
      "[1084/1600] D loss: 1.0539, G loss: 1.1503\n",
      "[1204/1600] D loss: 0.8724, G loss: 1.1922\n",
      "[1324/1600] D loss: 0.5895, G loss: 1.5788\n",
      "[1444/1600] D loss: 1.2576, G loss: 0.5937\n",
      "[1564/1600] D loss: 0.7810, G loss: 1.4856\n",
      "train error: \n",
      " D loss: 1.043895, G loss: 1.404702, D accuracy: 66.2%, cell accuracy: 98.9%, board accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.190375, G loss: 1.494344, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 50.2% \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3176, G loss: 0.9258\n",
      "[124/1600] D loss: 1.0592, G loss: 1.2501\n",
      "[244/1600] D loss: 1.3298, G loss: 0.6335\n",
      "[364/1600] D loss: 1.1048, G loss: 1.3586\n",
      "[484/1600] D loss: 1.0384, G loss: 1.4752\n",
      "[604/1600] D loss: 0.7037, G loss: 2.6702\n",
      "[724/1600] D loss: 1.4201, G loss: 0.7981\n",
      "[844/1600] D loss: 0.7522, G loss: 1.6517\n",
      "[964/1600] D loss: 1.5663, G loss: 0.5543\n",
      "[1084/1600] D loss: 0.8140, G loss: 1.4426\n",
      "[1204/1600] D loss: 0.8069, G loss: 2.6164\n",
      "[1324/1600] D loss: 1.2719, G loss: 0.6532\n",
      "[1444/1600] D loss: 1.1638, G loss: 1.1522\n",
      "[1564/1600] D loss: 0.4121, G loss: 3.1065\n",
      "train error: \n",
      " D loss: 1.058655, G loss: 1.503367, D accuracy: 66.7%, cell accuracy: 98.9%, board accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.219828, G loss: 1.597122, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 48.8% \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7044, G loss: 1.6466\n",
      "[124/1600] D loss: 0.9590, G loss: 1.5039\n",
      "[244/1600] D loss: 0.5009, G loss: 1.8800\n",
      "[364/1600] D loss: 1.0416, G loss: 1.1325\n",
      "[484/1600] D loss: 0.9966, G loss: 1.4181\n",
      "[604/1600] D loss: 0.7938, G loss: 1.6263\n",
      "[724/1600] D loss: 1.4016, G loss: 0.6804\n",
      "[844/1600] D loss: 1.4163, G loss: 0.8827\n",
      "[964/1600] D loss: 0.9634, G loss: 1.0280\n",
      "[1084/1600] D loss: 1.1089, G loss: 0.8544\n",
      "[1204/1600] D loss: 0.7270, G loss: 2.3095\n",
      "[1324/1600] D loss: 0.9219, G loss: 1.2911\n",
      "[1444/1600] D loss: 1.0633, G loss: 1.2666\n",
      "[1564/1600] D loss: 1.0496, G loss: 1.3886\n",
      "train error: \n",
      " D loss: 1.049508, G loss: 1.453006, D accuracy: 66.4%, cell accuracy: 98.9%, board accuracy: 51.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.207419, G loss: 1.551553, D accuracy: 63.5%, cell accuracy: 98.8%, board accuracy: 47.2% \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5350, G loss: 2.0863\n",
      "[124/1600] D loss: 1.0637, G loss: 1.3341\n",
      "[244/1600] D loss: 0.5278, G loss: 1.9900\n",
      "[364/1600] D loss: 0.5801, G loss: 2.3859\n",
      "[484/1600] D loss: 0.5961, G loss: 2.3810\n",
      "[604/1600] D loss: 1.3128, G loss: 0.7012\n",
      "[724/1600] D loss: 1.2298, G loss: 0.7948\n",
      "[844/1600] D loss: 1.0941, G loss: 1.1898\n",
      "[964/1600] D loss: 0.4078, G loss: 2.5972\n",
      "[1084/1600] D loss: 1.4647, G loss: 0.7203\n",
      "[1204/1600] D loss: 1.0131, G loss: 0.9827\n",
      "[1324/1600] D loss: 1.4523, G loss: 1.2837\n",
      "[1444/1600] D loss: 1.2285, G loss: 1.8982\n",
      "[1564/1600] D loss: 0.7141, G loss: 2.0265\n",
      "train error: \n",
      " D loss: 1.052716, G loss: 1.398605, D accuracy: 66.4%, cell accuracy: 98.9%, board accuracy: 51.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.212296, G loss: 1.487504, D accuracy: 62.6%, cell accuracy: 98.7%, board accuracy: 46.2% \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3952, G loss: 1.1881\n",
      "[124/1600] D loss: 0.7609, G loss: 1.9598\n",
      "[244/1600] D loss: 0.6967, G loss: 1.6582\n",
      "[364/1600] D loss: 0.9663, G loss: 2.0061\n",
      "[484/1600] D loss: 1.1500, G loss: 1.5573\n",
      "[604/1600] D loss: 0.5250, G loss: 1.8211\n",
      "[724/1600] D loss: 1.0479, G loss: 1.3689\n",
      "[844/1600] D loss: 1.1131, G loss: 0.9987\n",
      "[964/1600] D loss: 0.7593, G loss: 1.8289\n",
      "[1084/1600] D loss: 1.1573, G loss: 0.8757\n",
      "[1204/1600] D loss: 0.7225, G loss: 1.8898\n",
      "[1324/1600] D loss: 1.2469, G loss: 0.9895\n",
      "[1444/1600] D loss: 0.7294, G loss: 1.8623\n",
      "[1564/1600] D loss: 0.8678, G loss: 1.5394\n",
      "train error: \n",
      " D loss: 1.037027, G loss: 1.423779, D accuracy: 67.4%, cell accuracy: 98.9%, board accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.211495, G loss: 1.511295, D accuracy: 62.7%, cell accuracy: 98.7%, board accuracy: 46.0% \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0506, G loss: 0.9674\n",
      "[124/1600] D loss: 1.1642, G loss: 0.8728\n",
      "[244/1600] D loss: 1.0099, G loss: 2.4555\n",
      "[364/1600] D loss: 1.5849, G loss: 1.1209\n",
      "[484/1600] D loss: 0.8125, G loss: 1.7959\n",
      "[604/1600] D loss: 1.3911, G loss: 0.7002\n",
      "[724/1600] D loss: 0.3449, G loss: 2.2749\n",
      "[844/1600] D loss: 0.9407, G loss: 1.2549\n",
      "[964/1600] D loss: 0.7285, G loss: 1.8366\n",
      "[1084/1600] D loss: 0.8838, G loss: 1.3973\n",
      "[1204/1600] D loss: 1.5189, G loss: 0.5774\n",
      "[1324/1600] D loss: 0.7577, G loss: 1.6433\n",
      "[1444/1600] D loss: 1.1850, G loss: 1.2012\n",
      "[1564/1600] D loss: 0.9893, G loss: 1.5989\n",
      "train error: \n",
      " D loss: 1.050903, G loss: 1.398302, D accuracy: 66.9%, cell accuracy: 98.9%, board accuracy: 48.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.230363, G loss: 1.469550, D accuracy: 62.9%, cell accuracy: 98.7%, board accuracy: 46.8% \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0348, G loss: 1.0858\n",
      "[124/1600] D loss: 1.1248, G loss: 0.9853\n",
      "[244/1600] D loss: 1.0709, G loss: 1.7014\n",
      "[364/1600] D loss: 0.7284, G loss: 1.9250\n",
      "[484/1600] D loss: 1.1326, G loss: 1.5664\n",
      "[604/1600] D loss: 1.1252, G loss: 1.1592\n",
      "[724/1600] D loss: 0.7856, G loss: 1.7757\n",
      "[844/1600] D loss: 1.3700, G loss: 0.6729\n",
      "[964/1600] D loss: 1.2510, G loss: 0.8496\n",
      "[1084/1600] D loss: 1.1860, G loss: 1.1656\n",
      "[1204/1600] D loss: 0.8938, G loss: 1.1816\n",
      "[1324/1600] D loss: 1.1033, G loss: 1.4641\n",
      "[1444/1600] D loss: 0.8920, G loss: 1.5946\n",
      "[1564/1600] D loss: 0.5509, G loss: 2.8550\n",
      "train error: \n",
      " D loss: 1.057596, G loss: 1.370624, D accuracy: 65.9%, cell accuracy: 98.9%, board accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.223998, G loss: 1.494394, D accuracy: 62.4%, cell accuracy: 98.7%, board accuracy: 47.0% \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7897, G loss: 1.6468\n",
      "[124/1600] D loss: 1.0391, G loss: 1.3748\n",
      "[244/1600] D loss: 1.2693, G loss: 0.6819\n",
      "[364/1600] D loss: 1.3148, G loss: 0.9251\n",
      "[484/1600] D loss: 1.3499, G loss: 0.7366\n",
      "[604/1600] D loss: 0.6275, G loss: 1.7189\n",
      "[724/1600] D loss: 1.0198, G loss: 1.7165\n",
      "[844/1600] D loss: 1.0903, G loss: 1.8813\n",
      "[964/1600] D loss: 1.4884, G loss: 0.5310\n",
      "[1084/1600] D loss: 1.4642, G loss: 0.6193\n",
      "[1204/1600] D loss: 0.5617, G loss: 2.8703\n",
      "[1324/1600] D loss: 0.9000, G loss: 1.1366\n",
      "[1444/1600] D loss: 1.4029, G loss: 0.6931\n",
      "[1564/1600] D loss: 1.4269, G loss: 0.9491\n",
      "train error: \n",
      " D loss: 1.022994, G loss: 1.434919, D accuracy: 67.9%, cell accuracy: 98.9%, board accuracy: 47.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.196403, G loss: 1.539682, D accuracy: 64.2%, cell accuracy: 98.7%, board accuracy: 42.5% \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0428, G loss: 1.4791\n",
      "[124/1600] D loss: 0.9805, G loss: 1.7036\n",
      "[244/1600] D loss: 1.3266, G loss: 0.8093\n",
      "[364/1600] D loss: 1.0749, G loss: 1.3220\n",
      "[484/1600] D loss: 1.0518, G loss: 1.2952\n",
      "[604/1600] D loss: 1.3044, G loss: 0.6589\n",
      "[724/1600] D loss: 1.0121, G loss: 1.2960\n",
      "[844/1600] D loss: 1.3525, G loss: 0.5793\n",
      "[964/1600] D loss: 1.5733, G loss: 0.7098\n",
      "[1084/1600] D loss: 0.8524, G loss: 1.8153\n",
      "[1204/1600] D loss: 0.8321, G loss: 1.6920\n",
      "[1324/1600] D loss: 0.7486, G loss: 1.8882\n",
      "[1444/1600] D loss: 1.4107, G loss: 1.3395\n",
      "[1564/1600] D loss: 0.6522, G loss: 1.6824\n",
      "train error: \n",
      " D loss: 1.050923, G loss: 1.290751, D accuracy: 67.6%, cell accuracy: 98.9%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.231482, G loss: 1.379617, D accuracy: 63.6%, cell accuracy: 98.8%, board accuracy: 48.2% \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8138, G loss: 1.5683\n",
      "[124/1600] D loss: 1.2354, G loss: 1.5239\n",
      "[244/1600] D loss: 1.3592, G loss: 0.7880\n",
      "[364/1600] D loss: 0.8759, G loss: 2.3777\n",
      "[484/1600] D loss: 0.7198, G loss: 1.9177\n",
      "[604/1600] D loss: 0.9259, G loss: 1.4721\n",
      "[724/1600] D loss: 1.3126, G loss: 1.5149\n",
      "[844/1600] D loss: 0.8883, G loss: 1.1603\n",
      "[964/1600] D loss: 0.4455, G loss: 2.1855\n",
      "[1084/1600] D loss: 0.9260, G loss: 1.4230\n",
      "[1204/1600] D loss: 1.2219, G loss: 1.9075\n",
      "[1324/1600] D loss: 1.2877, G loss: 0.5447\n",
      "[1444/1600] D loss: 1.2327, G loss: 0.7081\n",
      "[1564/1600] D loss: 0.5662, G loss: 2.5560\n",
      "train error: \n",
      " D loss: 1.050230, G loss: 1.399100, D accuracy: 67.0%, cell accuracy: 98.8%, board accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.217822, G loss: 1.524984, D accuracy: 63.2%, cell accuracy: 98.6%, board accuracy: 48.0% \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0864, G loss: 1.0103\n",
      "[124/1600] D loss: 1.0829, G loss: 1.8688\n",
      "[244/1600] D loss: 1.5482, G loss: 0.4942\n",
      "[364/1600] D loss: 1.0552, G loss: 1.5679\n",
      "[484/1600] D loss: 0.8069, G loss: 1.5909\n",
      "[604/1600] D loss: 0.8402, G loss: 1.8314\n",
      "[724/1600] D loss: 1.0595, G loss: 1.6665\n",
      "[844/1600] D loss: 1.3333, G loss: 0.8080\n",
      "[964/1600] D loss: 1.0773, G loss: 1.9296\n",
      "[1084/1600] D loss: 0.7505, G loss: 1.7707\n",
      "[1204/1600] D loss: 1.1960, G loss: 1.4070\n",
      "[1324/1600] D loss: 1.0190, G loss: 1.3963\n",
      "[1444/1600] D loss: 0.8440, G loss: 2.0282\n",
      "[1564/1600] D loss: 0.8899, G loss: 1.7629\n",
      "train error: \n",
      " D loss: 1.055313, G loss: 1.274656, D accuracy: 66.5%, cell accuracy: 98.9%, board accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.216532, G loss: 1.388119, D accuracy: 64.2%, cell accuracy: 98.7%, board accuracy: 48.8% \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6212, G loss: 2.6851\n",
      "[124/1600] D loss: 1.4228, G loss: 0.8845\n",
      "[244/1600] D loss: 1.0636, G loss: 1.2969\n",
      "[364/1600] D loss: 0.9788, G loss: 1.2954\n",
      "[484/1600] D loss: 1.3410, G loss: 0.8897\n",
      "[604/1600] D loss: 1.1674, G loss: 1.5138\n",
      "[724/1600] D loss: 0.6448, G loss: 1.6535\n",
      "[844/1600] D loss: 1.5008, G loss: 0.6111\n",
      "[964/1600] D loss: 0.9178, G loss: 0.9862\n",
      "[1084/1600] D loss: 0.7442, G loss: 1.7086\n",
      "[1204/1600] D loss: 1.0197, G loss: 1.3074\n",
      "[1324/1600] D loss: 1.3247, G loss: 0.5719\n",
      "[1444/1600] D loss: 1.0296, G loss: 1.1836\n",
      "[1564/1600] D loss: 0.9004, G loss: 1.5378\n",
      "train error: \n",
      " D loss: 1.057335, G loss: 1.328397, D accuracy: 67.0%, cell accuracy: 98.9%, board accuracy: 52.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.223353, G loss: 1.425228, D accuracy: 63.5%, cell accuracy: 98.8%, board accuracy: 49.0% \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4059, G loss: 1.6493\n",
      "[124/1600] D loss: 1.0242, G loss: 1.9003\n",
      "[244/1600] D loss: 0.7281, G loss: 2.6697\n",
      "[364/1600] D loss: 1.0591, G loss: 1.0122\n",
      "[484/1600] D loss: 1.0351, G loss: 1.5254\n",
      "[604/1600] D loss: 0.8745, G loss: 1.7693\n",
      "[724/1600] D loss: 0.8278, G loss: 1.2847\n",
      "[844/1600] D loss: 1.2534, G loss: 0.9871\n",
      "[964/1600] D loss: 0.3425, G loss: 2.8250\n",
      "[1084/1600] D loss: 0.7181, G loss: 1.9584\n",
      "[1204/1600] D loss: 0.8239, G loss: 1.6026\n",
      "[1324/1600] D loss: 0.9739, G loss: 1.8709\n",
      "[1444/1600] D loss: 1.1558, G loss: 1.4587\n",
      "[1564/1600] D loss: 1.3542, G loss: 0.8039\n",
      "train error: \n",
      " D loss: 1.138703, G loss: 1.064791, D accuracy: 65.8%, cell accuracy: 98.9%, board accuracy: 49.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.246222, G loss: 1.177887, D accuracy: 63.4%, cell accuracy: 98.7%, board accuracy: 48.2% \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5033, G loss: 1.5681\n",
      "[124/1600] D loss: 1.0042, G loss: 1.9621\n",
      "[244/1600] D loss: 0.8980, G loss: 1.5126\n",
      "[364/1600] D loss: 1.4727, G loss: 0.9369\n",
      "[484/1600] D loss: 0.7716, G loss: 1.4114\n",
      "[604/1600] D loss: 1.4196, G loss: 0.8128\n",
      "[724/1600] D loss: 1.2889, G loss: 0.8374\n",
      "[844/1600] D loss: 1.1289, G loss: 1.2627\n",
      "[964/1600] D loss: 0.6272, G loss: 2.8033\n",
      "[1084/1600] D loss: 1.1109, G loss: 1.4921\n",
      "[1204/1600] D loss: 1.0088, G loss: 1.1736\n",
      "[1324/1600] D loss: 0.9706, G loss: 1.3364\n",
      "[1444/1600] D loss: 1.1560, G loss: 1.1132\n",
      "[1564/1600] D loss: 0.5495, G loss: 1.8193\n",
      "train error: \n",
      " D loss: 1.093253, G loss: 1.675064, D accuracy: 65.4%, cell accuracy: 99.0%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264467, G loss: 1.817791, D accuracy: 63.6%, cell accuracy: 98.8%, board accuracy: 49.0% \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5762, G loss: 2.4679\n",
      "[124/1600] D loss: 0.7947, G loss: 2.0458\n",
      "[244/1600] D loss: 1.0579, G loss: 1.3159\n",
      "[364/1600] D loss: 1.0882, G loss: 1.1071\n",
      "[484/1600] D loss: 0.3393, G loss: 3.4893\n",
      "[604/1600] D loss: 0.6582, G loss: 1.8319\n",
      "[724/1600] D loss: 1.0163, G loss: 2.0173\n",
      "[844/1600] D loss: 1.1763, G loss: 1.0179\n",
      "[964/1600] D loss: 0.5317, G loss: 3.2928\n",
      "[1084/1600] D loss: 0.5540, G loss: 2.7334\n",
      "[1204/1600] D loss: 1.1376, G loss: 1.3094\n",
      "[1324/1600] D loss: 0.8820, G loss: 2.0253\n",
      "[1444/1600] D loss: 1.0795, G loss: 1.3871\n",
      "[1564/1600] D loss: 1.5233, G loss: 1.1128\n",
      "train error: \n",
      " D loss: 1.054599, G loss: 1.286167, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259098, G loss: 1.372255, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8054, G loss: 1.7345\n",
      "[124/1600] D loss: 1.4103, G loss: 0.8161\n",
      "[244/1600] D loss: 1.0384, G loss: 1.4591\n",
      "[364/1600] D loss: 1.3344, G loss: 0.7294\n",
      "[484/1600] D loss: 1.3430, G loss: 0.8751\n",
      "[604/1600] D loss: 1.1215, G loss: 1.1833\n",
      "[724/1600] D loss: 1.0965, G loss: 1.0057\n",
      "[844/1600] D loss: 0.9693, G loss: 1.5270\n",
      "[964/1600] D loss: 1.4600, G loss: 0.6746\n",
      "[1084/1600] D loss: 0.8007, G loss: 1.6657\n",
      "[1204/1600] D loss: 1.1292, G loss: 1.1569\n",
      "[1324/1600] D loss: 1.3677, G loss: 0.7792\n",
      "[1444/1600] D loss: 1.0410, G loss: 0.9493\n",
      "[1564/1600] D loss: 1.1246, G loss: 0.9618\n",
      "train error: \n",
      " D loss: 1.076328, G loss: 1.189276, D accuracy: 66.4%, cell accuracy: 98.9%, board accuracy: 53.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.236787, G loss: 1.288900, D accuracy: 63.7%, cell accuracy: 98.7%, board accuracy: 49.2% \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7692, G loss: 1.7646\n",
      "[124/1600] D loss: 1.3761, G loss: 0.7009\n",
      "[244/1600] D loss: 1.4156, G loss: 0.9698\n",
      "[364/1600] D loss: 0.9479, G loss: 1.9348\n",
      "[484/1600] D loss: 0.5610, G loss: 1.8762\n",
      "[604/1600] D loss: 1.3217, G loss: 0.7327\n",
      "[724/1600] D loss: 0.6849, G loss: 2.0430\n",
      "[844/1600] D loss: 1.1784, G loss: 0.8508\n",
      "[964/1600] D loss: 0.8277, G loss: 1.5621\n",
      "[1084/1600] D loss: 0.4752, G loss: 1.9946\n",
      "[1204/1600] D loss: 1.0313, G loss: 1.6086\n",
      "[1324/1600] D loss: 0.9270, G loss: 1.4812\n",
      "[1444/1600] D loss: 1.4515, G loss: 0.8327\n",
      "[1564/1600] D loss: 0.7278, G loss: 1.9282\n",
      "train error: \n",
      " D loss: 1.048903, G loss: 1.393942, D accuracy: 66.6%, cell accuracy: 98.9%, board accuracy: 55.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.207845, G loss: 1.490758, D accuracy: 63.6%, cell accuracy: 98.7%, board accuracy: 51.7% \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2542, G loss: 1.0571\n",
      "[124/1600] D loss: 0.7127, G loss: 2.2054\n",
      "[244/1600] D loss: 1.0187, G loss: 0.8713\n",
      "[364/1600] D loss: 1.2819, G loss: 0.9271\n",
      "[484/1600] D loss: 1.3543, G loss: 0.7933\n",
      "[604/1600] D loss: 0.9967, G loss: 1.5534\n",
      "[724/1600] D loss: 1.4329, G loss: 0.8150\n",
      "[844/1600] D loss: 0.8289, G loss: 2.1285\n",
      "[964/1600] D loss: 1.1919, G loss: 1.1700\n",
      "[1084/1600] D loss: 1.1476, G loss: 1.6337\n",
      "[1204/1600] D loss: 0.5029, G loss: 2.1230\n",
      "[1324/1600] D loss: 0.8210, G loss: 1.5322\n",
      "[1444/1600] D loss: 1.4097, G loss: 0.5626\n",
      "[1564/1600] D loss: 1.4261, G loss: 0.6262\n",
      "train error: \n",
      " D loss: 1.046819, G loss: 1.446153, D accuracy: 67.1%, cell accuracy: 99.0%, board accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.243477, G loss: 1.514005, D accuracy: 63.1%, cell accuracy: 98.8%, board accuracy: 49.8% \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6524, G loss: 2.0958\n",
      "[124/1600] D loss: 1.3699, G loss: 1.1474\n",
      "[244/1600] D loss: 1.2560, G loss: 0.7646\n",
      "[364/1600] D loss: 1.4285, G loss: 0.6190\n",
      "[484/1600] D loss: 0.3089, G loss: 2.4010\n",
      "[604/1600] D loss: 0.7982, G loss: 1.9194\n",
      "[724/1600] D loss: 0.4727, G loss: 2.8186\n",
      "[844/1600] D loss: 0.7103, G loss: 2.5467\n",
      "[964/1600] D loss: 1.0711, G loss: 1.1179\n",
      "[1084/1600] D loss: 0.7406, G loss: 1.8181\n",
      "[1204/1600] D loss: 0.8113, G loss: 1.1405\n",
      "[1324/1600] D loss: 1.0710, G loss: 1.7194\n",
      "[1444/1600] D loss: 0.7553, G loss: 1.8901\n",
      "[1564/1600] D loss: 0.7224, G loss: 3.3462\n",
      "train error: \n",
      " D loss: 1.056401, G loss: 1.451863, D accuracy: 65.9%, cell accuracy: 98.9%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251455, G loss: 1.564677, D accuracy: 62.7%, cell accuracy: 98.7%, board accuracy: 51.2% \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9850, G loss: 2.0749\n",
      "[124/1600] D loss: 1.0974, G loss: 1.2259\n",
      "[244/1600] D loss: 1.1038, G loss: 1.1825\n",
      "[364/1600] D loss: 1.1404, G loss: 1.1549\n",
      "[484/1600] D loss: 1.1249, G loss: 1.8514\n",
      "[604/1600] D loss: 1.2762, G loss: 1.3117\n",
      "[724/1600] D loss: 0.4241, G loss: 2.3830\n",
      "[844/1600] D loss: 1.0762, G loss: 1.4625\n",
      "[964/1600] D loss: 1.1348, G loss: 0.9726\n",
      "[1084/1600] D loss: 0.8663, G loss: 1.4441\n",
      "[1204/1600] D loss: 1.0991, G loss: 1.3422\n",
      "[1324/1600] D loss: 1.2508, G loss: 0.8310\n",
      "[1444/1600] D loss: 1.2120, G loss: 1.3440\n",
      "[1564/1600] D loss: 1.3477, G loss: 0.5624\n",
      "train error: \n",
      " D loss: 1.053682, G loss: 1.414965, D accuracy: 66.2%, cell accuracy: 98.9%, board accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.220022, G loss: 1.543416, D accuracy: 63.1%, cell accuracy: 98.7%, board accuracy: 50.5% \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0644, G loss: 1.4646\n",
      "[124/1600] D loss: 1.2660, G loss: 1.0699\n",
      "[244/1600] D loss: 0.6768, G loss: 1.7166\n",
      "[364/1600] D loss: 1.2860, G loss: 1.2560\n",
      "[484/1600] D loss: 1.1949, G loss: 0.9338\n",
      "[604/1600] D loss: 0.7237, G loss: 1.9018\n",
      "[724/1600] D loss: 1.0696, G loss: 1.4477\n",
      "[844/1600] D loss: 1.0903, G loss: 1.2151\n",
      "[964/1600] D loss: 1.3469, G loss: 1.0473\n",
      "[1084/1600] D loss: 0.7175, G loss: 2.8796\n",
      "[1204/1600] D loss: 1.3976, G loss: 0.6681\n",
      "[1324/1600] D loss: 1.0821, G loss: 1.5462\n",
      "[1444/1600] D loss: 1.2024, G loss: 1.0743\n",
      "[1564/1600] D loss: 0.9623, G loss: 1.3044\n",
      "train error: \n",
      " D loss: 1.048391, G loss: 1.423974, D accuracy: 66.3%, cell accuracy: 98.9%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.226458, G loss: 1.533624, D accuracy: 62.4%, cell accuracy: 98.7%, board accuracy: 50.2% \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0666, G loss: 1.4442\n",
      "[124/1600] D loss: 1.0783, G loss: 1.2840\n",
      "[244/1600] D loss: 1.4734, G loss: 0.5916\n",
      "[364/1600] D loss: 0.9736, G loss: 1.8185\n",
      "[484/1600] D loss: 0.9743, G loss: 2.0842\n",
      "[604/1600] D loss: 0.6917, G loss: 2.0536\n",
      "[724/1600] D loss: 0.8132, G loss: 1.3321\n",
      "[844/1600] D loss: 1.2509, G loss: 0.7928\n",
      "[964/1600] D loss: 1.0708, G loss: 1.3430\n",
      "[1084/1600] D loss: 0.9986, G loss: 1.5999\n",
      "[1204/1600] D loss: 0.8513, G loss: 1.6058\n",
      "[1324/1600] D loss: 0.9191, G loss: 1.1638\n",
      "[1444/1600] D loss: 0.6030, G loss: 1.7386\n",
      "[1564/1600] D loss: 0.9280, G loss: 1.2754\n",
      "train error: \n",
      " D loss: 1.051346, G loss: 1.395219, D accuracy: 66.5%, cell accuracy: 98.9%, board accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.229043, G loss: 1.503175, D accuracy: 62.9%, cell accuracy: 98.7%, board accuracy: 50.5% \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0236, G loss: 1.5446\n",
      "[124/1600] D loss: 0.8656, G loss: 1.0128\n",
      "[244/1600] D loss: 1.1198, G loss: 1.0560\n",
      "[364/1600] D loss: 1.3241, G loss: 0.7091\n",
      "[484/1600] D loss: 1.3244, G loss: 0.6758\n",
      "[604/1600] D loss: 1.5415, G loss: 0.6875\n",
      "[724/1600] D loss: 0.3857, G loss: 3.4896\n",
      "[844/1600] D loss: 1.3971, G loss: 0.5983\n",
      "[964/1600] D loss: 1.0969, G loss: 0.9811\n",
      "[1084/1600] D loss: 1.4200, G loss: 1.7952\n",
      "[1204/1600] D loss: 0.7441, G loss: 2.1467\n",
      "[1324/1600] D loss: 1.1439, G loss: 0.8708\n",
      "[1444/1600] D loss: 1.0412, G loss: 1.3575\n",
      "[1564/1600] D loss: 1.3876, G loss: 0.6987\n",
      "train error: \n",
      " D loss: 1.074427, G loss: 1.260700, D accuracy: 67.4%, cell accuracy: 98.9%, board accuracy: 53.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.237582, G loss: 1.353472, D accuracy: 64.8%, cell accuracy: 98.7%, board accuracy: 48.8% \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9836, G loss: 1.2451\n",
      "[124/1600] D loss: 0.2713, G loss: 2.3543\n",
      "[244/1600] D loss: 0.7270, G loss: 1.8095\n",
      "[364/1600] D loss: 1.2925, G loss: 0.8827\n",
      "[484/1600] D loss: 0.7431, G loss: 1.6952\n",
      "[604/1600] D loss: 1.0572, G loss: 1.3167\n",
      "[724/1600] D loss: 0.7268, G loss: 2.5742\n",
      "[844/1600] D loss: 0.5754, G loss: 1.9770\n",
      "[964/1600] D loss: 1.0217, G loss: 1.3858\n",
      "[1084/1600] D loss: 0.6479, G loss: 3.2234\n",
      "[1204/1600] D loss: 1.0646, G loss: 1.2546\n",
      "[1324/1600] D loss: 1.1230, G loss: 0.9572\n",
      "[1444/1600] D loss: 0.9433, G loss: 1.8437\n",
      "[1564/1600] D loss: 1.1011, G loss: 0.9417\n",
      "train error: \n",
      " D loss: 1.045518, G loss: 1.536039, D accuracy: 66.1%, cell accuracy: 98.9%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.220532, G loss: 1.644664, D accuracy: 62.9%, cell accuracy: 98.7%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9680, G loss: 1.5608\n",
      "[124/1600] D loss: 1.1551, G loss: 1.2177\n",
      "[244/1600] D loss: 0.6021, G loss: 1.7505\n",
      "[364/1600] D loss: 1.3875, G loss: 1.0008\n",
      "[484/1600] D loss: 1.0450, G loss: 2.1780\n",
      "[604/1600] D loss: 0.8428, G loss: 1.5406\n",
      "[724/1600] D loss: 1.3118, G loss: 0.6867\n",
      "[844/1600] D loss: 0.9841, G loss: 1.3223\n",
      "[964/1600] D loss: 0.4144, G loss: 3.9097\n",
      "[1084/1600] D loss: 1.4027, G loss: 0.7395\n",
      "[1204/1600] D loss: 0.6165, G loss: 1.5837\n",
      "[1324/1600] D loss: 0.6803, G loss: 2.6148\n",
      "[1444/1600] D loss: 1.1269, G loss: 0.9256\n",
      "[1564/1600] D loss: 0.8842, G loss: 1.3510\n",
      "train error: \n",
      " D loss: 1.071145, G loss: 1.200525, D accuracy: 66.0%, cell accuracy: 98.9%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.218877, G loss: 1.332111, D accuracy: 63.7%, cell accuracy: 98.8%, board accuracy: 52.8% \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0791, G loss: 1.0829\n",
      "[124/1600] D loss: 0.7292, G loss: 2.2420\n",
      "[244/1600] D loss: 0.3760, G loss: 2.5635\n",
      "[364/1600] D loss: 0.7755, G loss: 1.6213\n",
      "[484/1600] D loss: 0.7525, G loss: 1.4083\n",
      "[604/1600] D loss: 0.9408, G loss: 1.5718\n",
      "[724/1600] D loss: 1.0184, G loss: 1.0576\n",
      "[844/1600] D loss: 0.9338, G loss: 1.9407\n",
      "[964/1600] D loss: 0.7364, G loss: 2.5524\n",
      "[1084/1600] D loss: 0.8362, G loss: 1.4811\n",
      "[1204/1600] D loss: 1.2053, G loss: 1.5852\n",
      "[1324/1600] D loss: 1.4305, G loss: 0.8085\n",
      "[1444/1600] D loss: 1.3682, G loss: 0.6667\n",
      "[1564/1600] D loss: 1.3002, G loss: 0.6720\n",
      "train error: \n",
      " D loss: 1.050217, G loss: 1.501934, D accuracy: 66.1%, cell accuracy: 98.9%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.231306, G loss: 1.596536, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 51.2% \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2967, G loss: 1.1177\n",
      "[124/1600] D loss: 0.8610, G loss: 2.5174\n",
      "[244/1600] D loss: 0.9460, G loss: 1.6270\n",
      "[364/1600] D loss: 1.0869, G loss: 1.2676\n",
      "[484/1600] D loss: 0.3275, G loss: 3.2583\n",
      "[604/1600] D loss: 1.3555, G loss: 0.8509\n",
      "[724/1600] D loss: 0.7376, G loss: 1.8768\n",
      "[844/1600] D loss: 0.7163, G loss: 1.8457\n",
      "[964/1600] D loss: 1.0567, G loss: 1.1068\n",
      "[1084/1600] D loss: 0.7070, G loss: 3.5943\n",
      "[1204/1600] D loss: 0.8316, G loss: 2.3790\n",
      "[1324/1600] D loss: 0.6176, G loss: 2.4176\n",
      "[1444/1600] D loss: 1.0175, G loss: 0.9538\n",
      "[1564/1600] D loss: 1.1376, G loss: 1.3016\n",
      "train error: \n",
      " D loss: 1.046360, G loss: 1.481889, D accuracy: 66.6%, cell accuracy: 98.9%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.242678, G loss: 1.547847, D accuracy: 62.9%, cell accuracy: 98.7%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4010, G loss: 0.7902\n",
      "[124/1600] D loss: 1.1723, G loss: 1.5864\n",
      "[244/1600] D loss: 1.5586, G loss: 0.4829\n",
      "[364/1600] D loss: 1.4539, G loss: 0.6596\n",
      "[484/1600] D loss: 1.4210, G loss: 0.7510\n",
      "[604/1600] D loss: 1.3121, G loss: 0.9306\n",
      "[724/1600] D loss: 1.4166, G loss: 0.8763\n",
      "[844/1600] D loss: 1.0001, G loss: 1.4239\n",
      "[964/1600] D loss: 1.1784, G loss: 1.1487\n",
      "[1084/1600] D loss: 0.8247, G loss: 1.8156\n",
      "[1204/1600] D loss: 1.2305, G loss: 0.7945\n",
      "[1324/1600] D loss: 0.9510, G loss: 1.3658\n",
      "[1444/1600] D loss: 1.0332, G loss: 1.3251\n",
      "[1564/1600] D loss: 1.3529, G loss: 0.8423\n",
      "train error: \n",
      " D loss: 1.066735, G loss: 1.210402, D accuracy: 66.7%, cell accuracy: 98.8%, board accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.221335, G loss: 1.323549, D accuracy: 64.4%, cell accuracy: 98.6%, board accuracy: 49.2% \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0276, G loss: 1.5445\n",
      "[124/1600] D loss: 0.6773, G loss: 2.0485\n",
      "[244/1600] D loss: 1.3160, G loss: 0.7247\n",
      "[364/1600] D loss: 1.4149, G loss: 0.6729\n",
      "[484/1600] D loss: 1.0361, G loss: 1.6664\n",
      "[604/1600] D loss: 0.7744, G loss: 2.4472\n",
      "[724/1600] D loss: 1.1399, G loss: 1.2113\n",
      "[844/1600] D loss: 1.4147, G loss: 1.0590\n",
      "[964/1600] D loss: 1.2620, G loss: 0.8532\n",
      "[1084/1600] D loss: 1.0545, G loss: 2.0210\n",
      "[1204/1600] D loss: 0.7634, G loss: 2.1095\n",
      "[1324/1600] D loss: 0.7051, G loss: 2.0154\n",
      "[1444/1600] D loss: 1.4617, G loss: 0.8777\n",
      "[1564/1600] D loss: 1.1035, G loss: 1.2890\n",
      "train error: \n",
      " D loss: 1.047066, G loss: 1.274803, D accuracy: 66.0%, cell accuracy: 98.9%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.192958, G loss: 1.395204, D accuracy: 63.6%, cell accuracy: 98.7%, board accuracy: 48.2% \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3136, G loss: 0.6522\n",
      "[124/1600] D loss: 1.0262, G loss: 1.3889\n",
      "[244/1600] D loss: 1.1019, G loss: 1.6307\n",
      "[364/1600] D loss: 1.4054, G loss: 0.8024\n",
      "[484/1600] D loss: 0.7380, G loss: 2.3541\n",
      "[604/1600] D loss: 1.3164, G loss: 0.9602\n",
      "[724/1600] D loss: 1.0296, G loss: 1.5578\n",
      "[844/1600] D loss: 1.3878, G loss: 0.7461\n",
      "[964/1600] D loss: 1.0642, G loss: 1.2968\n",
      "[1084/1600] D loss: 0.7262, G loss: 2.7301\n",
      "[1204/1600] D loss: 0.7732, G loss: 1.8685\n",
      "[1324/1600] D loss: 1.3718, G loss: 0.8800\n",
      "[1444/1600] D loss: 1.2988, G loss: 0.9675\n",
      "[1564/1600] D loss: 1.0594, G loss: 1.2716\n",
      "train error: \n",
      " D loss: 1.059567, G loss: 1.498798, D accuracy: 66.6%, cell accuracy: 98.9%, board accuracy: 55.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.241533, G loss: 1.581483, D accuracy: 62.6%, cell accuracy: 98.7%, board accuracy: 51.5% \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7139, G loss: 1.4684\n",
      "[124/1600] D loss: 1.1484, G loss: 1.2940\n",
      "[244/1600] D loss: 0.9660, G loss: 1.7538\n",
      "[364/1600] D loss: 1.1280, G loss: 1.0495\n",
      "[484/1600] D loss: 0.9925, G loss: 1.0708\n",
      "[604/1600] D loss: 1.0370, G loss: 1.5580\n",
      "[724/1600] D loss: 1.1835, G loss: 0.9942\n",
      "[844/1600] D loss: 0.6826, G loss: 2.7806\n",
      "[964/1600] D loss: 1.3659, G loss: 0.8459\n",
      "[1084/1600] D loss: 1.0845, G loss: 1.3522\n",
      "[1204/1600] D loss: 1.2314, G loss: 0.9115\n",
      "[1324/1600] D loss: 1.3630, G loss: 0.9425\n",
      "[1444/1600] D loss: 1.1736, G loss: 1.2932\n",
      "[1564/1600] D loss: 1.1486, G loss: 1.1824\n",
      "train error: \n",
      " D loss: 1.041185, G loss: 1.454162, D accuracy: 67.0%, cell accuracy: 98.9%, board accuracy: 53.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.223215, G loss: 1.578486, D accuracy: 63.2%, cell accuracy: 98.7%, board accuracy: 48.8% \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7421, G loss: 1.6840\n",
      "[124/1600] D loss: 0.5933, G loss: 2.0532\n",
      "[244/1600] D loss: 0.5820, G loss: 1.7823\n",
      "[364/1600] D loss: 0.7115, G loss: 1.7652\n",
      "[484/1600] D loss: 0.3969, G loss: 2.7723\n",
      "[604/1600] D loss: 1.1739, G loss: 1.4729\n",
      "[724/1600] D loss: 1.1204, G loss: 1.6431\n",
      "[844/1600] D loss: 0.5428, G loss: 2.0874\n",
      "[964/1600] D loss: 1.0054, G loss: 1.5759\n",
      "[1084/1600] D loss: 0.7415, G loss: 2.9748\n",
      "[1204/1600] D loss: 1.6155, G loss: 0.7836\n",
      "[1324/1600] D loss: 1.0579, G loss: 1.4004\n",
      "[1444/1600] D loss: 0.7026, G loss: 1.8259\n",
      "[1564/1600] D loss: 1.8992, G loss: 1.3957\n",
      "train error: \n",
      " D loss: 1.074323, G loss: 1.323463, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260891, G loss: 1.418486, D accuracy: 61.4%, cell accuracy: 98.8%, board accuracy: 52.8% \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3411, G loss: 0.7254\n",
      "[124/1600] D loss: 1.0517, G loss: 1.2035\n",
      "[244/1600] D loss: 1.3118, G loss: 1.2033\n",
      "[364/1600] D loss: 1.1023, G loss: 1.1538\n",
      "[484/1600] D loss: 1.3817, G loss: 0.7042\n",
      "[604/1600] D loss: 1.4660, G loss: 1.0260\n",
      "[724/1600] D loss: 0.3996, G loss: 2.5042\n",
      "[844/1600] D loss: 0.5512, G loss: 2.0083\n",
      "[964/1600] D loss: 1.0779, G loss: 2.1649\n",
      "[1084/1600] D loss: 1.0462, G loss: 1.6496\n",
      "[1204/1600] D loss: 1.1734, G loss: 0.9080\n",
      "[1324/1600] D loss: 1.3284, G loss: 0.7530\n",
      "[1444/1600] D loss: 1.3976, G loss: 0.7342\n",
      "[1564/1600] D loss: 1.0722, G loss: 1.2047\n",
      "train error: \n",
      " D loss: 1.043362, G loss: 1.402063, D accuracy: 66.9%, cell accuracy: 98.9%, board accuracy: 54.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.222882, G loss: 1.478839, D accuracy: 62.3%, cell accuracy: 98.7%, board accuracy: 49.2% \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3297, G loss: 0.7101\n",
      "[124/1600] D loss: 1.0700, G loss: 0.7529\n",
      "[244/1600] D loss: 0.4820, G loss: 1.8899\n",
      "[364/1600] D loss: 0.8834, G loss: 2.0462\n",
      "[484/1600] D loss: 1.0725, G loss: 1.3493\n",
      "[604/1600] D loss: 0.7281, G loss: 1.9464\n",
      "[724/1600] D loss: 1.3950, G loss: 0.7916\n",
      "[844/1600] D loss: 0.7483, G loss: 2.0768\n",
      "[964/1600] D loss: 1.0790, G loss: 1.0185\n",
      "[1084/1600] D loss: 1.4442, G loss: 0.6385\n",
      "[1204/1600] D loss: 1.0597, G loss: 1.2749\n",
      "[1324/1600] D loss: 1.0833, G loss: 1.7052\n",
      "[1444/1600] D loss: 1.3806, G loss: 0.6647\n",
      "[1564/1600] D loss: 0.4421, G loss: 2.6097\n",
      "train error: \n",
      " D loss: 1.052964, G loss: 1.340058, D accuracy: 66.2%, cell accuracy: 98.9%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.232874, G loss: 1.428244, D accuracy: 62.6%, cell accuracy: 98.7%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4369, G loss: 0.6987\n",
      "[124/1600] D loss: 1.2126, G loss: 1.4150\n",
      "[244/1600] D loss: 1.1768, G loss: 0.7165\n",
      "[364/1600] D loss: 1.4383, G loss: 0.5360\n",
      "[484/1600] D loss: 0.5292, G loss: 2.0143\n",
      "[604/1600] D loss: 0.6743, G loss: 1.5065\n",
      "[724/1600] D loss: 0.8904, G loss: 1.7052\n",
      "[844/1600] D loss: 1.0236, G loss: 1.8829\n",
      "[964/1600] D loss: 1.2968, G loss: 0.8937\n",
      "[1084/1600] D loss: 1.0876, G loss: 1.4392\n",
      "[1204/1600] D loss: 0.9889, G loss: 1.8094\n",
      "[1324/1600] D loss: 1.1069, G loss: 1.1400\n",
      "[1444/1600] D loss: 1.0488, G loss: 1.5356\n",
      "[1564/1600] D loss: 1.0510, G loss: 1.6532\n",
      "train error: \n",
      " D loss: 1.050737, G loss: 1.372497, D accuracy: 66.2%, cell accuracy: 98.8%, board accuracy: 52.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.232847, G loss: 1.462956, D accuracy: 61.5%, cell accuracy: 98.6%, board accuracy: 45.0% \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7780, G loss: 1.9623\n",
      "[124/1600] D loss: 0.7498, G loss: 1.7657\n",
      "[244/1600] D loss: 1.2311, G loss: 0.7257\n",
      "[364/1600] D loss: 1.2230, G loss: 1.0025\n",
      "[484/1600] D loss: 0.7968, G loss: 1.6927\n",
      "[604/1600] D loss: 1.2596, G loss: 0.7632\n",
      "[724/1600] D loss: 1.2376, G loss: 0.7489\n",
      "[844/1600] D loss: 1.0401, G loss: 1.3363\n",
      "[964/1600] D loss: 0.6231, G loss: 2.3121\n",
      "[1084/1600] D loss: 1.0510, G loss: 2.0150\n",
      "[1204/1600] D loss: 0.9134, G loss: 2.0805\n",
      "[1324/1600] D loss: 0.8661, G loss: 1.7228\n",
      "[1444/1600] D loss: 0.7642, G loss: 2.0661\n",
      "[1564/1600] D loss: 1.3196, G loss: 1.1023\n",
      "train error: \n",
      " D loss: 1.062379, G loss: 1.397482, D accuracy: 65.5%, cell accuracy: 98.9%, board accuracy: 55.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.224101, G loss: 1.503995, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7593, G loss: 1.5786\n",
      "[124/1600] D loss: 0.9335, G loss: 1.4794\n",
      "[244/1600] D loss: 1.5378, G loss: 1.0061\n",
      "[364/1600] D loss: 1.1266, G loss: 1.8108\n",
      "[484/1600] D loss: 1.5627, G loss: 1.1557\n",
      "[604/1600] D loss: 1.2880, G loss: 0.7289\n",
      "[724/1600] D loss: 1.4656, G loss: 0.4982\n",
      "[844/1600] D loss: 1.2172, G loss: 0.8800\n",
      "[964/1600] D loss: 1.3169, G loss: 0.7806\n",
      "[1084/1600] D loss: 1.4619, G loss: 0.5959\n",
      "[1204/1600] D loss: 0.5620, G loss: 2.1160\n",
      "[1324/1600] D loss: 0.6750, G loss: 2.2992\n",
      "[1444/1600] D loss: 1.3593, G loss: 0.7587\n",
      "[1564/1600] D loss: 1.3698, G loss: 0.8542\n",
      "train error: \n",
      " D loss: 1.069093, G loss: 1.476528, D accuracy: 65.2%, cell accuracy: 98.9%, board accuracy: 54.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.240864, G loss: 1.580664, D accuracy: 62.0%, cell accuracy: 98.7%, board accuracy: 49.2% \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7392, G loss: 2.1229\n",
      "[124/1600] D loss: 1.2083, G loss: 0.8347\n",
      "[244/1600] D loss: 1.3665, G loss: 0.7201\n",
      "[364/1600] D loss: 0.9556, G loss: 1.3577\n",
      "[484/1600] D loss: 1.0427, G loss: 1.2303\n",
      "[604/1600] D loss: 1.1679, G loss: 0.9139\n",
      "[724/1600] D loss: 1.0068, G loss: 1.3940\n",
      "[844/1600] D loss: 1.0574, G loss: 1.1056\n",
      "[964/1600] D loss: 0.9076, G loss: 1.9152\n",
      "[1084/1600] D loss: 1.2505, G loss: 1.1246\n",
      "[1204/1600] D loss: 0.9311, G loss: 1.1713\n",
      "[1324/1600] D loss: 1.1316, G loss: 2.5163\n",
      "[1444/1600] D loss: 1.3601, G loss: 0.9032\n",
      "[1564/1600] D loss: 1.4019, G loss: 0.6509\n",
      "train error: \n",
      " D loss: 1.048385, G loss: 1.401228, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 56.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.218403, G loss: 1.517742, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2501, G loss: 0.9246\n",
      "[124/1600] D loss: 1.0480, G loss: 1.4862\n",
      "[244/1600] D loss: 1.3840, G loss: 0.5956\n",
      "[364/1600] D loss: 1.4452, G loss: 0.8751\n",
      "[484/1600] D loss: 0.9706, G loss: 2.1182\n",
      "[604/1600] D loss: 1.4361, G loss: 0.8656\n",
      "[724/1600] D loss: 0.9570, G loss: 1.7285\n",
      "[844/1600] D loss: 1.3759, G loss: 0.6942\n",
      "[964/1600] D loss: 1.3416, G loss: 0.8058\n",
      "[1084/1600] D loss: 0.9647, G loss: 1.7723\n",
      "[1204/1600] D loss: 0.7041, G loss: 2.7145\n",
      "[1324/1600] D loss: 0.7797, G loss: 2.0286\n",
      "[1444/1600] D loss: 1.6324, G loss: 1.0701\n",
      "[1564/1600] D loss: 0.8936, G loss: 1.2641\n",
      "train error: \n",
      " D loss: 1.055350, G loss: 1.365348, D accuracy: 66.3%, cell accuracy: 98.9%, board accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.227320, G loss: 1.469584, D accuracy: 62.5%, cell accuracy: 98.7%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7165, G loss: 2.0730\n",
      "[124/1600] D loss: 0.6815, G loss: 2.9611\n",
      "[244/1600] D loss: 1.3761, G loss: 0.6115\n",
      "[364/1600] D loss: 1.4267, G loss: 0.7592\n",
      "[484/1600] D loss: 1.0734, G loss: 1.0685\n",
      "[604/1600] D loss: 0.8368, G loss: 1.6829\n",
      "[724/1600] D loss: 1.0824, G loss: 1.2093\n",
      "[844/1600] D loss: 0.3627, G loss: 3.0719\n",
      "[964/1600] D loss: 1.1590, G loss: 1.5862\n",
      "[1084/1600] D loss: 0.7535, G loss: 1.8765\n",
      "[1204/1600] D loss: 1.2377, G loss: 0.8040\n",
      "[1324/1600] D loss: 1.1051, G loss: 0.9962\n",
      "[1444/1600] D loss: 0.8764, G loss: 1.2458\n",
      "[1564/1600] D loss: 0.5815, G loss: 2.5292\n",
      "train error: \n",
      " D loss: 1.056634, G loss: 1.431246, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.224658, G loss: 1.533449, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7277, G loss: 2.2375\n",
      "[124/1600] D loss: 0.7493, G loss: 2.2171\n",
      "[244/1600] D loss: 1.4268, G loss: 0.9128\n",
      "[364/1600] D loss: 1.5035, G loss: 0.6623\n",
      "[484/1600] D loss: 1.1736, G loss: 0.9422\n",
      "[604/1600] D loss: 1.3912, G loss: 0.7357\n",
      "[724/1600] D loss: 1.3687, G loss: 0.6998\n",
      "[844/1600] D loss: 1.6324, G loss: 0.8918\n",
      "[964/1600] D loss: 0.8287, G loss: 1.6031\n",
      "[1084/1600] D loss: 0.6749, G loss: 2.6944\n",
      "[1204/1600] D loss: 1.1190, G loss: 0.9099\n",
      "[1324/1600] D loss: 0.7669, G loss: 1.4289\n",
      "[1444/1600] D loss: 1.2678, G loss: 0.9448\n",
      "[1564/1600] D loss: 1.2718, G loss: 1.2613\n",
      "train error: \n",
      " D loss: 1.056146, G loss: 1.469320, D accuracy: 65.9%, cell accuracy: 98.9%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.230554, G loss: 1.579273, D accuracy: 62.3%, cell accuracy: 98.7%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2448, G loss: 0.6698\n",
      "[124/1600] D loss: 0.9451, G loss: 1.6688\n",
      "[244/1600] D loss: 0.7704, G loss: 2.0024\n",
      "[364/1600] D loss: 1.4387, G loss: 0.5290\n",
      "[484/1600] D loss: 0.3290, G loss: 3.1362\n",
      "[604/1600] D loss: 0.7370, G loss: 1.8585\n",
      "[724/1600] D loss: 0.7389, G loss: 1.6655\n",
      "[844/1600] D loss: 0.9954, G loss: 1.4172\n",
      "[964/1600] D loss: 0.9038, G loss: 1.6722\n",
      "[1084/1600] D loss: 1.0501, G loss: 2.0774\n",
      "[1204/1600] D loss: 1.3990, G loss: 0.7993\n",
      "[1324/1600] D loss: 1.1998, G loss: 1.0185\n",
      "[1444/1600] D loss: 0.7256, G loss: 1.6717\n",
      "[1564/1600] D loss: 0.9942, G loss: 1.2258\n",
      "train error: \n",
      " D loss: 1.073370, G loss: 1.240214, D accuracy: 66.0%, cell accuracy: 99.0%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.213332, G loss: 1.342700, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 52.5% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "epochs = 300\n",
    "\n",
    "gen = TetrisModel()\n",
    "disc = TetrisDiscriminator()\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "log_dir = os.path.join(\"runs\", \"tetris_emulator\")\n",
    "log_subdir = os.path.join(log_dir, datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "train_examples = find_interesting_examples(train_dataset)\n",
    "test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "    test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "    test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "    gen_zero_grads = 0\n",
    "    for name, weight in gen.named_parameters():\n",
    "        tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "        if weight.grad is not None:\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "            gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "    tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "    disc_zero_grads = 0\n",
    "    for name, weight in disc.named_parameters():\n",
    "        tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "        if weight.grad is not None:\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "            disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "    tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "\n",
    "tb_writer.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0731, G loss: 1.2577\n",
      "[124/1600] D loss: 0.9596, G loss: 2.1260\n",
      "[244/1600] D loss: 0.7556, G loss: 1.6564\n",
      "[364/1600] D loss: 1.0809, G loss: 1.4954\n",
      "[484/1600] D loss: 0.6574, G loss: 2.4862\n",
      "[604/1600] D loss: 1.4975, G loss: 0.7639\n",
      "[724/1600] D loss: 0.7760, G loss: 2.1910\n",
      "[844/1600] D loss: 1.2182, G loss: 0.8299\n",
      "[964/1600] D loss: 1.1152, G loss: 1.2972\n",
      "[1084/1600] D loss: 1.3750, G loss: 0.7030\n",
      "[1204/1600] D loss: 1.2902, G loss: 1.6389\n",
      "[1324/1600] D loss: 0.7756, G loss: 1.3143\n",
      "[1444/1600] D loss: 1.1462, G loss: 1.2608\n",
      "[1564/1600] D loss: 1.4608, G loss: 0.5491\n",
      "train error: \n",
      " D loss: 1.050239, G loss: 1.399197, D accuracy: 66.3%, cell accuracy: 98.9%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.224440, G loss: 1.496554, D accuracy: 63.2%, cell accuracy: 98.7%, board accuracy: 47.2% \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1801, G loss: 1.1322\n",
      "[124/1600] D loss: 1.0948, G loss: 1.0288\n",
      "[244/1600] D loss: 0.9153, G loss: 1.4658\n",
      "[364/1600] D loss: 1.4117, G loss: 0.7262\n",
      "[484/1600] D loss: 1.2461, G loss: 0.8243\n",
      "[604/1600] D loss: 1.0323, G loss: 1.7800\n",
      "[724/1600] D loss: 1.4925, G loss: 1.0304\n",
      "[844/1600] D loss: 0.7599, G loss: 1.8765\n",
      "[964/1600] D loss: 1.0805, G loss: 1.2771\n",
      "[1084/1600] D loss: 1.0420, G loss: 1.6900\n",
      "[1204/1600] D loss: 1.0597, G loss: 1.1864\n",
      "[1324/1600] D loss: 1.2517, G loss: 0.8245\n",
      "[1444/1600] D loss: 1.4278, G loss: 0.6521\n",
      "[1564/1600] D loss: 1.3424, G loss: 0.7251\n",
      "train error: \n",
      " D loss: 1.061813, G loss: 1.473879, D accuracy: 65.3%, cell accuracy: 98.7%, board accuracy: 52.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254313, G loss: 1.589575, D accuracy: 62.4%, cell accuracy: 98.5%, board accuracy: 44.2% \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7153, G loss: 2.5270\n",
      "[124/1600] D loss: 0.7175, G loss: 2.7214\n",
      "[244/1600] D loss: 1.4473, G loss: 0.5357\n",
      "[364/1600] D loss: 1.0805, G loss: 1.6195\n",
      "[484/1600] D loss: 0.7184, G loss: 1.9670\n",
      "[604/1600] D loss: 1.4643, G loss: 0.5509\n",
      "[724/1600] D loss: 0.7997, G loss: 1.5284\n",
      "[844/1600] D loss: 1.3208, G loss: 0.9171\n",
      "[964/1600] D loss: 1.3412, G loss: 0.6904\n",
      "[1084/1600] D loss: 1.0818, G loss: 1.0944\n",
      "[1204/1600] D loss: 0.7642, G loss: 1.0945\n",
      "[1324/1600] D loss: 1.0698, G loss: 1.1586\n",
      "[1444/1600] D loss: 0.7821, G loss: 1.5701\n",
      "[1564/1600] D loss: 1.2306, G loss: 1.3368\n",
      "train error: \n",
      " D loss: 1.093753, G loss: 1.220881, D accuracy: 65.9%, cell accuracy: 98.9%, board accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.239194, G loss: 1.329379, D accuracy: 62.5%, cell accuracy: 98.7%, board accuracy: 48.0% \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7523, G loss: 1.7106\n",
      "[124/1600] D loss: 0.6246, G loss: 2.4779\n",
      "[244/1600] D loss: 1.2132, G loss: 1.3775\n",
      "[364/1600] D loss: 0.9229, G loss: 1.3487\n",
      "[484/1600] D loss: 1.0817, G loss: 1.1777\n",
      "[604/1600] D loss: 0.6935, G loss: 2.0230\n",
      "[724/1600] D loss: 1.0494, G loss: 0.7245\n",
      "[844/1600] D loss: 1.2615, G loss: 1.2687\n",
      "[964/1600] D loss: 1.3164, G loss: 0.6952\n",
      "[1084/1600] D loss: 0.6429, G loss: 1.8608\n",
      "[1204/1600] D loss: 1.2299, G loss: 0.8819\n",
      "[1324/1600] D loss: 1.2753, G loss: 1.0437\n",
      "[1444/1600] D loss: 1.2472, G loss: 0.9616\n",
      "[1564/1600] D loss: 1.0635, G loss: 1.3563\n",
      "train error: \n",
      " D loss: 1.043641, G loss: 1.358518, D accuracy: 66.9%, cell accuracy: 99.0%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.235593, G loss: 1.450885, D accuracy: 63.5%, cell accuracy: 98.8%, board accuracy: 49.2% \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3009, G loss: 1.0423\n",
      "[124/1600] D loss: 0.7707, G loss: 1.8581\n",
      "[244/1600] D loss: 1.4638, G loss: 0.8822\n",
      "[364/1600] D loss: 1.4110, G loss: 0.8791\n",
      "[484/1600] D loss: 0.3827, G loss: 2.8371\n",
      "[604/1600] D loss: 1.2312, G loss: 0.9601\n",
      "[724/1600] D loss: 1.1876, G loss: 1.4869\n",
      "[844/1600] D loss: 1.1255, G loss: 1.0789\n",
      "[964/1600] D loss: 0.8892, G loss: 1.4891\n",
      "[1084/1600] D loss: 1.1491, G loss: 1.0432\n",
      "[1204/1600] D loss: 1.0497, G loss: 1.4917\n",
      "[1324/1600] D loss: 1.3344, G loss: 1.0361\n",
      "[1444/1600] D loss: 0.8788, G loss: 1.8585\n",
      "[1564/1600] D loss: 0.8668, G loss: 1.6263\n",
      "train error: \n",
      " D loss: 1.063667, G loss: 1.586157, D accuracy: 66.1%, cell accuracy: 98.9%, board accuracy: 51.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255353, G loss: 1.698437, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 44.5% \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4573, G loss: 0.8338\n",
      "[124/1600] D loss: 0.8004, G loss: 1.5822\n",
      "[244/1600] D loss: 1.2895, G loss: 0.6204\n",
      "[364/1600] D loss: 0.7129, G loss: 2.6641\n",
      "[484/1600] D loss: 1.1777, G loss: 1.1475\n",
      "[604/1600] D loss: 1.0735, G loss: 0.9749\n",
      "[724/1600] D loss: 1.4713, G loss: 0.9110\n",
      "[844/1600] D loss: 1.4174, G loss: 0.8572\n",
      "[964/1600] D loss: 1.3912, G loss: 0.8875\n",
      "[1084/1600] D loss: 1.5600, G loss: 0.6989\n",
      "[1204/1600] D loss: 1.1438, G loss: 1.0929\n",
      "[1324/1600] D loss: 1.4653, G loss: 0.7470\n",
      "[1444/1600] D loss: 1.0492, G loss: 0.8249\n",
      "[1564/1600] D loss: 0.8467, G loss: 1.5244\n",
      "train error: \n",
      " D loss: 1.035181, G loss: 1.458751, D accuracy: 67.1%, cell accuracy: 98.9%, board accuracy: 50.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.228841, G loss: 1.595154, D accuracy: 63.6%, cell accuracy: 98.7%, board accuracy: 43.8% \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8013, G loss: 2.3182\n",
      "[124/1600] D loss: 1.0281, G loss: 1.4751\n",
      "[244/1600] D loss: 0.3809, G loss: 2.7156\n",
      "[364/1600] D loss: 1.1377, G loss: 1.1231\n",
      "[484/1600] D loss: 1.3667, G loss: 0.6210\n",
      "[604/1600] D loss: 1.0184, G loss: 2.0135\n",
      "[724/1600] D loss: 1.4178, G loss: 0.7683\n",
      "[844/1600] D loss: 1.0112, G loss: 1.6864\n",
      "[964/1600] D loss: 0.8277, G loss: 1.9578\n",
      "[1084/1600] D loss: 1.2902, G loss: 0.8609\n",
      "[1204/1600] D loss: 0.4061, G loss: 2.5734\n",
      "[1324/1600] D loss: 1.0952, G loss: 1.4653\n",
      "[1444/1600] D loss: 0.9180, G loss: 1.2003\n",
      "[1564/1600] D loss: 1.3893, G loss: 0.9605\n",
      "train error: \n",
      " D loss: 1.113544, G loss: 1.047845, D accuracy: 64.6%, cell accuracy: 99.0%, board accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263311, G loss: 1.143694, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6742, G loss: 0.5355\n",
      "[124/1600] D loss: 0.9951, G loss: 1.3128\n",
      "[244/1600] D loss: 1.2550, G loss: 1.0936\n",
      "[364/1600] D loss: 0.7789, G loss: 3.0402\n",
      "[484/1600] D loss: 1.4389, G loss: 0.8183\n",
      "[604/1600] D loss: 1.1653, G loss: 1.3368\n",
      "[724/1600] D loss: 1.0084, G loss: 2.0724\n",
      "[844/1600] D loss: 1.1328, G loss: 1.2344\n",
      "[964/1600] D loss: 0.9098, G loss: 1.5674\n",
      "[1084/1600] D loss: 1.1150, G loss: 1.0185\n",
      "[1204/1600] D loss: 0.4563, G loss: 2.1762\n",
      "[1324/1600] D loss: 0.9250, G loss: 1.1647\n",
      "[1444/1600] D loss: 0.9586, G loss: 1.6162\n",
      "[1564/1600] D loss: 1.4255, G loss: 0.7278\n",
      "train error: \n",
      " D loss: 1.027135, G loss: 1.344826, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.218126, G loss: 1.434365, D accuracy: 63.1%, cell accuracy: 98.8%, board accuracy: 51.5% \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1155, G loss: 1.0837\n",
      "[124/1600] D loss: 1.0661, G loss: 1.3699\n",
      "[244/1600] D loss: 0.7287, G loss: 1.9948\n",
      "[364/1600] D loss: 0.9547, G loss: 1.3372\n",
      "[484/1600] D loss: 1.4860, G loss: 0.5479\n",
      "[604/1600] D loss: 1.1485, G loss: 1.2201\n",
      "[724/1600] D loss: 0.7243, G loss: 1.9385\n",
      "[844/1600] D loss: 1.3482, G loss: 0.6831\n",
      "[964/1600] D loss: 1.0619, G loss: 2.0253\n",
      "[1084/1600] D loss: 0.8949, G loss: 0.9852\n",
      "[1204/1600] D loss: 0.7820, G loss: 2.0910\n",
      "[1324/1600] D loss: 0.5091, G loss: 3.0929\n",
      "[1444/1600] D loss: 1.4222, G loss: 0.7791\n",
      "[1564/1600] D loss: 0.5437, G loss: 1.9605\n",
      "train error: \n",
      " D loss: 1.036996, G loss: 1.326653, D accuracy: 67.6%, cell accuracy: 99.0%, board accuracy: 54.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.240109, G loss: 1.441955, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 51.7% \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9355, G loss: 1.4266\n",
      "[124/1600] D loss: 0.8665, G loss: 1.4319\n",
      "[244/1600] D loss: 0.7815, G loss: 1.7502\n",
      "[364/1600] D loss: 1.2230, G loss: 0.7525\n",
      "[484/1600] D loss: 0.3879, G loss: 2.6669\n",
      "[604/1600] D loss: 0.7610, G loss: 1.4747\n",
      "[724/1600] D loss: 1.4983, G loss: 0.9759\n",
      "[844/1600] D loss: 1.3584, G loss: 1.0695\n",
      "[964/1600] D loss: 0.7513, G loss: 1.8647\n",
      "[1084/1600] D loss: 0.5127, G loss: 2.4502\n",
      "[1204/1600] D loss: 0.8932, G loss: 1.4573\n",
      "[1324/1600] D loss: 1.0081, G loss: 1.6143\n",
      "[1444/1600] D loss: 1.2182, G loss: 0.8323\n",
      "[1564/1600] D loss: 0.7132, G loss: 1.6335\n",
      "train error: \n",
      " D loss: 1.016986, G loss: 1.453629, D accuracy: 67.2%, cell accuracy: 98.9%, board accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.248586, G loss: 1.538301, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 50.5% \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0806, G loss: 1.6941\n",
      "[124/1600] D loss: 0.8486, G loss: 1.2731\n",
      "[244/1600] D loss: 1.1226, G loss: 1.0273\n",
      "[364/1600] D loss: 0.2758, G loss: 2.8109\n",
      "[484/1600] D loss: 1.2216, G loss: 0.8772\n",
      "[604/1600] D loss: 1.0814, G loss: 1.7650\n",
      "[724/1600] D loss: 1.0660, G loss: 1.3003\n",
      "[844/1600] D loss: 1.3763, G loss: 0.6637\n",
      "[964/1600] D loss: 1.2280, G loss: 0.7208\n",
      "[1084/1600] D loss: 1.3757, G loss: 0.7774\n",
      "[1204/1600] D loss: 0.0316, G loss: 4.1477\n",
      "[1324/1600] D loss: 0.9991, G loss: 1.4942\n",
      "[1444/1600] D loss: 0.9480, G loss: 1.4577\n",
      "[1564/1600] D loss: 0.7135, G loss: 2.0369\n",
      "train error: \n",
      " D loss: 1.078254, G loss: 1.318856, D accuracy: 66.6%, cell accuracy: 98.7%, board accuracy: 53.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299142, G loss: 1.401819, D accuracy: 60.6%, cell accuracy: 98.5%, board accuracy: 48.8% \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7377, G loss: 2.0267\n",
      "[124/1600] D loss: 1.3380, G loss: 0.8610\n",
      "[244/1600] D loss: 0.6389, G loss: 2.1610\n",
      "[364/1600] D loss: 1.1830, G loss: 0.9696\n",
      "[484/1600] D loss: 0.9877, G loss: 1.1625\n",
      "[604/1600] D loss: 0.9314, G loss: 1.9074\n",
      "[724/1600] D loss: 1.1254, G loss: 1.8689\n",
      "[844/1600] D loss: 0.7525, G loss: 1.7431\n",
      "[964/1600] D loss: 0.8308, G loss: 1.7358\n",
      "[1084/1600] D loss: 1.0467, G loss: 1.6849\n",
      "[1204/1600] D loss: 1.2807, G loss: 1.4439\n",
      "[1324/1600] D loss: 1.4142, G loss: 0.7541\n",
      "[1444/1600] D loss: 1.3503, G loss: 1.1818\n",
      "[1564/1600] D loss: 1.3856, G loss: 0.5050\n",
      "train error: \n",
      " D loss: 1.072452, G loss: 1.610476, D accuracy: 65.9%, cell accuracy: 98.8%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316609, G loss: 1.692106, D accuracy: 61.5%, cell accuracy: 98.5%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7841, G loss: 1.8189\n",
      "[124/1600] D loss: 0.6781, G loss: 1.8968\n",
      "[244/1600] D loss: 1.2659, G loss: 1.3417\n",
      "[364/1600] D loss: 0.7550, G loss: 1.6771\n",
      "[484/1600] D loss: 1.0141, G loss: 0.9047\n",
      "[604/1600] D loss: 1.4033, G loss: 0.9604\n",
      "[724/1600] D loss: 0.9211, G loss: 1.7810\n",
      "[844/1600] D loss: 0.5701, G loss: 3.4142\n",
      "[964/1600] D loss: 1.4714, G loss: 1.0070\n",
      "[1084/1600] D loss: 1.5191, G loss: 0.6277\n",
      "[1204/1600] D loss: 1.3154, G loss: 0.9408\n",
      "[1324/1600] D loss: 1.0162, G loss: 1.5834\n",
      "[1444/1600] D loss: 0.8796, G loss: 1.5827\n",
      "[1564/1600] D loss: 0.7786, G loss: 2.3251\n",
      "train error: \n",
      " D loss: 1.056302, G loss: 1.364017, D accuracy: 67.0%, cell accuracy: 98.8%, board accuracy: 54.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257294, G loss: 1.502220, D accuracy: 62.4%, cell accuracy: 98.6%, board accuracy: 50.2% \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0659, G loss: 1.8933\n",
      "[124/1600] D loss: 1.2929, G loss: 0.6380\n",
      "[244/1600] D loss: 1.4476, G loss: 0.5980\n",
      "[364/1600] D loss: 0.8129, G loss: 2.0999\n",
      "[484/1600] D loss: 1.0730, G loss: 1.4940\n",
      "[604/1600] D loss: 1.2847, G loss: 0.8613\n",
      "[724/1600] D loss: 1.2604, G loss: 0.7911\n",
      "[844/1600] D loss: 0.9131, G loss: 1.4726\n",
      "[964/1600] D loss: 1.0517, G loss: 1.7571\n",
      "[1084/1600] D loss: 1.0921, G loss: 1.0575\n",
      "[1204/1600] D loss: 1.2013, G loss: 0.8018\n",
      "[1324/1600] D loss: 1.0612, G loss: 1.4060\n",
      "[1444/1600] D loss: 0.5348, G loss: 1.9909\n",
      "[1564/1600] D loss: 1.0222, G loss: 1.4979\n",
      "train error: \n",
      " D loss: 1.045681, G loss: 1.387501, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 56.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.226834, G loss: 1.554218, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 52.8% \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4000, G loss: 0.5899\n",
      "[124/1600] D loss: 1.0538, G loss: 0.9654\n",
      "[244/1600] D loss: 0.8673, G loss: 2.1032\n",
      "[364/1600] D loss: 0.8815, G loss: 1.1717\n",
      "[484/1600] D loss: 1.1118, G loss: 1.5569\n",
      "[604/1600] D loss: 0.9923, G loss: 1.3009\n",
      "[724/1600] D loss: 0.8648, G loss: 1.5600\n",
      "[844/1600] D loss: 0.5994, G loss: 1.9554\n",
      "[964/1600] D loss: 0.9842, G loss: 1.0546\n",
      "[1084/1600] D loss: 0.6506, G loss: 1.8270\n",
      "[1204/1600] D loss: 0.2912, G loss: 2.7623\n",
      "[1324/1600] D loss: 0.9283, G loss: 1.4536\n",
      "[1444/1600] D loss: 1.1030, G loss: 1.7940\n",
      "[1564/1600] D loss: 0.7164, G loss: 1.9284\n",
      "train error: \n",
      " D loss: 1.022127, G loss: 1.463959, D accuracy: 67.5%, cell accuracy: 98.9%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.221284, G loss: 1.597824, D accuracy: 63.1%, cell accuracy: 98.7%, board accuracy: 50.5% \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7544, G loss: 2.6550\n",
      "[124/1600] D loss: 0.7321, G loss: 2.2038\n",
      "[244/1600] D loss: 0.7477, G loss: 1.9157\n",
      "[364/1600] D loss: 0.3753, G loss: 2.6236\n",
      "[484/1600] D loss: 0.5688, G loss: 2.1534\n",
      "[604/1600] D loss: 1.1487, G loss: 0.7069\n",
      "[724/1600] D loss: 0.9831, G loss: 1.6509\n",
      "[844/1600] D loss: 1.0062, G loss: 2.2145\n",
      "[964/1600] D loss: 0.9119, G loss: 2.0116\n",
      "[1084/1600] D loss: 1.4182, G loss: 0.7558\n",
      "[1204/1600] D loss: 0.7921, G loss: 1.5261\n",
      "[1324/1600] D loss: 0.6494, G loss: 2.2544\n",
      "[1444/1600] D loss: 1.2297, G loss: 1.1962\n",
      "[1564/1600] D loss: 1.3202, G loss: 0.9410\n",
      "train error: \n",
      " D loss: 1.036344, G loss: 1.453573, D accuracy: 67.1%, cell accuracy: 99.0%, board accuracy: 57.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.246385, G loss: 1.584588, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 54.5% \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4925, G loss: 1.0724\n",
      "[124/1600] D loss: 1.3889, G loss: 0.5937\n",
      "[244/1600] D loss: 0.7705, G loss: 2.0565\n",
      "[364/1600] D loss: 0.2006, G loss: 3.0021\n",
      "[484/1600] D loss: 1.4738, G loss: 0.4618\n",
      "[604/1600] D loss: 0.8779, G loss: 1.3222\n",
      "[724/1600] D loss: 1.1751, G loss: 1.0443\n",
      "[844/1600] D loss: 0.7355, G loss: 1.6367\n",
      "[964/1600] D loss: 1.0588, G loss: 1.2945\n",
      "[1084/1600] D loss: 1.0495, G loss: 1.8580\n",
      "[1204/1600] D loss: 1.0275, G loss: 1.1700\n",
      "[1324/1600] D loss: 1.4738, G loss: 0.6297\n",
      "[1444/1600] D loss: 1.0551, G loss: 1.3607\n",
      "[1564/1600] D loss: 1.3942, G loss: 0.6347\n",
      "train error: \n",
      " D loss: 1.036401, G loss: 1.423599, D accuracy: 66.2%, cell accuracy: 98.9%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.220726, G loss: 1.537524, D accuracy: 63.7%, cell accuracy: 98.7%, board accuracy: 52.8% \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3751, G loss: 0.7860\n",
      "[124/1600] D loss: 1.2950, G loss: 1.1859\n",
      "[244/1600] D loss: 1.3165, G loss: 0.9557\n",
      "[364/1600] D loss: 1.3538, G loss: 1.0336\n",
      "[484/1600] D loss: 0.8003, G loss: 1.7986\n",
      "[604/1600] D loss: 1.2062, G loss: 0.9255\n",
      "[724/1600] D loss: 0.7130, G loss: 2.1363\n",
      "[844/1600] D loss: 0.9489, G loss: 1.6696\n",
      "[964/1600] D loss: 1.3616, G loss: 1.0186\n",
      "[1084/1600] D loss: 0.7491, G loss: 2.1003\n",
      "[1204/1600] D loss: 1.5117, G loss: 1.0440\n",
      "[1324/1600] D loss: 0.5067, G loss: 2.9450\n",
      "[1444/1600] D loss: 0.8819, G loss: 1.6390\n",
      "[1564/1600] D loss: 0.8020, G loss: 1.3226\n",
      "train error: \n",
      " D loss: 1.035294, G loss: 1.505335, D accuracy: 66.9%, cell accuracy: 98.9%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.236368, G loss: 1.645979, D accuracy: 63.1%, cell accuracy: 98.7%, board accuracy: 51.5% \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3121, G loss: 0.7462\n",
      "[124/1600] D loss: 1.1379, G loss: 1.2606\n",
      "[244/1600] D loss: 1.0220, G loss: 1.9092\n",
      "[364/1600] D loss: 0.8985, G loss: 0.9725\n",
      "[484/1600] D loss: 1.0601, G loss: 1.8387\n",
      "[604/1600] D loss: 1.1068, G loss: 1.2144\n",
      "[724/1600] D loss: 1.1906, G loss: 0.8361\n",
      "[844/1600] D loss: 0.8088, G loss: 1.8362\n",
      "[964/1600] D loss: 0.3966, G loss: 2.3535\n",
      "[1084/1600] D loss: 1.3512, G loss: 2.3712\n",
      "[1204/1600] D loss: 1.1221, G loss: 1.1925\n",
      "[1324/1600] D loss: 0.8915, G loss: 1.3098\n",
      "[1444/1600] D loss: 1.3631, G loss: 0.5656\n",
      "[1564/1600] D loss: 1.1283, G loss: 1.1927\n",
      "train error: \n",
      " D loss: 1.035609, G loss: 1.515285, D accuracy: 66.7%, cell accuracy: 98.9%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263348, G loss: 1.644131, D accuracy: 62.6%, cell accuracy: 98.7%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0020, G loss: 1.5170\n",
      "[124/1600] D loss: 1.2084, G loss: 0.9132\n",
      "[244/1600] D loss: 0.7039, G loss: 2.3048\n",
      "[364/1600] D loss: 0.7564, G loss: 2.5566\n",
      "[484/1600] D loss: 1.4393, G loss: 0.7424\n",
      "[604/1600] D loss: 1.5397, G loss: 0.4445\n",
      "[724/1600] D loss: 1.3536, G loss: 0.7732\n",
      "[844/1600] D loss: 0.8511, G loss: 1.3734\n",
      "[964/1600] D loss: 1.1836, G loss: 1.1478\n",
      "[1084/1600] D loss: 0.6899, G loss: 2.6931\n",
      "[1204/1600] D loss: 0.9232, G loss: 1.6788\n",
      "[1324/1600] D loss: 1.4694, G loss: 0.7509\n",
      "[1444/1600] D loss: 1.1643, G loss: 1.3865\n",
      "[1564/1600] D loss: 1.3952, G loss: 0.6706\n",
      "train error: \n",
      " D loss: 1.051163, G loss: 1.282334, D accuracy: 66.1%, cell accuracy: 98.9%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249810, G loss: 1.394593, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3353, G loss: 0.6900\n",
      "[124/1600] D loss: 1.4094, G loss: 0.6131\n",
      "[244/1600] D loss: 1.3201, G loss: 0.8527\n",
      "[364/1600] D loss: 0.6601, G loss: 1.7274\n",
      "[484/1600] D loss: 1.5476, G loss: 0.9286\n",
      "[604/1600] D loss: 0.4105, G loss: 3.0482\n",
      "[724/1600] D loss: 1.0832, G loss: 1.0755\n",
      "[844/1600] D loss: 0.9078, G loss: 1.2038\n",
      "[964/1600] D loss: 1.0808, G loss: 1.4750\n",
      "[1084/1600] D loss: 1.4794, G loss: 0.7093\n",
      "[1204/1600] D loss: 1.4276, G loss: 0.5206\n",
      "[1324/1600] D loss: 1.1399, G loss: 1.0893\n",
      "[1444/1600] D loss: 0.3768, G loss: 2.1111\n",
      "[1564/1600] D loss: 1.1585, G loss: 1.7448\n",
      "train error: \n",
      " D loss: 1.059214, G loss: 1.217729, D accuracy: 66.0%, cell accuracy: 99.0%, board accuracy: 57.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251225, G loss: 1.303355, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 53.8% \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9837, G loss: 1.1730\n",
      "[124/1600] D loss: 1.1623, G loss: 0.9799\n",
      "[244/1600] D loss: 0.7254, G loss: 2.2401\n",
      "[364/1600] D loss: 1.1954, G loss: 0.9175\n",
      "[484/1600] D loss: 1.3696, G loss: 0.6769\n",
      "[604/1600] D loss: 0.4162, G loss: 2.7107\n",
      "[724/1600] D loss: 0.7491, G loss: 2.1402\n",
      "[844/1600] D loss: 0.9977, G loss: 1.2950\n",
      "[964/1600] D loss: 0.5521, G loss: 1.7218\n",
      "[1084/1600] D loss: 1.3068, G loss: 0.6652\n",
      "[1204/1600] D loss: 0.4403, G loss: 2.2209\n",
      "[1324/1600] D loss: 0.9811, G loss: 0.7266\n",
      "[1444/1600] D loss: 0.7197, G loss: 1.3646\n",
      "[1564/1600] D loss: 0.6193, G loss: 2.1760\n",
      "train error: \n",
      " D loss: 1.042531, G loss: 1.325015, D accuracy: 67.2%, cell accuracy: 98.9%, board accuracy: 56.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.233201, G loss: 1.500926, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 53.5% \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1070, G loss: 1.6654\n",
      "[124/1600] D loss: 0.7572, G loss: 2.1141\n",
      "[244/1600] D loss: 1.1539, G loss: 0.9400\n",
      "[364/1600] D loss: 0.9636, G loss: 1.9511\n",
      "[484/1600] D loss: 1.4454, G loss: 0.6371\n",
      "[604/1600] D loss: 0.5687, G loss: 1.6518\n",
      "[724/1600] D loss: 0.7758, G loss: 1.5513\n",
      "[844/1600] D loss: 0.9177, G loss: 1.7802\n",
      "[964/1600] D loss: 0.7259, G loss: 2.0198\n",
      "[1084/1600] D loss: 1.3812, G loss: 0.6571\n",
      "[1204/1600] D loss: 1.1663, G loss: 0.7362\n",
      "[1324/1600] D loss: 0.9415, G loss: 1.3479\n",
      "[1444/1600] D loss: 0.9982, G loss: 1.2948\n",
      "[1564/1600] D loss: 0.7299, G loss: 2.2161\n",
      "train error: \n",
      " D loss: 1.089562, G loss: 1.677308, D accuracy: 65.8%, cell accuracy: 98.9%, board accuracy: 58.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320764, G loss: 1.802791, D accuracy: 61.9%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4292, G loss: 0.6841\n",
      "[124/1600] D loss: 1.3046, G loss: 1.1377\n",
      "[244/1600] D loss: 1.0781, G loss: 0.8649\n",
      "[364/1600] D loss: 1.1526, G loss: 0.9948\n",
      "[484/1600] D loss: 1.4887, G loss: 0.6267\n",
      "[604/1600] D loss: 1.0431, G loss: 1.3391\n",
      "[724/1600] D loss: 0.7790, G loss: 2.2110\n",
      "[844/1600] D loss: 1.0852, G loss: 1.9730\n",
      "[964/1600] D loss: 1.0830, G loss: 2.3275\n",
      "[1084/1600] D loss: 1.1841, G loss: 1.1605\n",
      "[1204/1600] D loss: 1.2037, G loss: 0.8437\n",
      "[1324/1600] D loss: 1.0796, G loss: 0.8986\n",
      "[1444/1600] D loss: 0.6775, G loss: 2.3386\n",
      "[1564/1600] D loss: 1.1802, G loss: 1.4704\n",
      "train error: \n",
      " D loss: 1.062144, G loss: 1.275495, D accuracy: 66.4%, cell accuracy: 98.9%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.242435, G loss: 1.447613, D accuracy: 63.6%, cell accuracy: 98.7%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7627, G loss: 2.1568\n",
      "[124/1600] D loss: 1.1763, G loss: 0.9586\n",
      "[244/1600] D loss: 1.0361, G loss: 2.0142\n",
      "[364/1600] D loss: 1.0691, G loss: 2.0973\n",
      "[484/1600] D loss: 0.9908, G loss: 1.4072\n",
      "[604/1600] D loss: 1.0874, G loss: 1.1318\n",
      "[724/1600] D loss: 0.5278, G loss: 2.4485\n",
      "[844/1600] D loss: 1.0121, G loss: 1.3762\n",
      "[964/1600] D loss: 1.2479, G loss: 0.9880\n",
      "[1084/1600] D loss: 1.3476, G loss: 0.7577\n",
      "[1204/1600] D loss: 1.5288, G loss: 1.0364\n",
      "[1324/1600] D loss: 0.9333, G loss: 1.2294\n",
      "[1444/1600] D loss: 1.0166, G loss: 1.4483\n",
      "[1564/1600] D loss: 1.4427, G loss: 0.4987\n",
      "train error: \n",
      " D loss: 1.075115, G loss: 1.543517, D accuracy: 65.3%, cell accuracy: 98.8%, board accuracy: 60.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327749, G loss: 1.691596, D accuracy: 61.3%, cell accuracy: 98.6%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4733, G loss: 0.6681\n",
      "[124/1600] D loss: 1.4085, G loss: 1.0454\n",
      "[244/1600] D loss: 1.0783, G loss: 1.5591\n",
      "[364/1600] D loss: 1.3749, G loss: 0.6197\n",
      "[484/1600] D loss: 0.7236, G loss: 1.7955\n",
      "[604/1600] D loss: 1.4314, G loss: 0.7802\n",
      "[724/1600] D loss: 1.1636, G loss: 1.1653\n",
      "[844/1600] D loss: 1.3168, G loss: 1.0859\n",
      "[964/1600] D loss: 0.7790, G loss: 1.8552\n",
      "[1084/1600] D loss: 0.6358, G loss: 2.2396\n",
      "[1204/1600] D loss: 0.5701, G loss: 1.6082\n",
      "[1324/1600] D loss: 1.4244, G loss: 0.8516\n",
      "[1444/1600] D loss: 1.4349, G loss: 0.8406\n",
      "[1564/1600] D loss: 0.4110, G loss: 2.4469\n",
      "train error: \n",
      " D loss: 1.046498, G loss: 1.428057, D accuracy: 66.2%, cell accuracy: 98.9%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284391, G loss: 1.586339, D accuracy: 62.4%, cell accuracy: 98.7%, board accuracy: 54.2% \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7095, G loss: 2.8910\n",
      "[124/1600] D loss: 1.0943, G loss: 1.0628\n",
      "[244/1600] D loss: 0.8967, G loss: 1.5342\n",
      "[364/1600] D loss: 1.0649, G loss: 1.3336\n",
      "[484/1600] D loss: 0.8966, G loss: 1.4831\n",
      "[604/1600] D loss: 1.1981, G loss: 1.1962\n",
      "[724/1600] D loss: 1.0351, G loss: 1.4107\n",
      "[844/1600] D loss: 0.6225, G loss: 1.6386\n",
      "[964/1600] D loss: 1.3335, G loss: 0.7269\n",
      "[1084/1600] D loss: 0.7914, G loss: 2.6987\n",
      "[1204/1600] D loss: 1.0347, G loss: 1.4045\n",
      "[1324/1600] D loss: 0.7952, G loss: 2.2830\n",
      "[1444/1600] D loss: 1.0529, G loss: 1.3438\n",
      "[1564/1600] D loss: 1.2425, G loss: 1.0712\n",
      "train error: \n",
      " D loss: 1.038222, G loss: 1.480035, D accuracy: 66.0%, cell accuracy: 98.9%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266610, G loss: 1.627903, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4111, G loss: 0.7693\n",
      "[124/1600] D loss: 0.9157, G loss: 1.9169\n",
      "[244/1600] D loss: 0.7849, G loss: 2.1041\n",
      "[364/1600] D loss: 1.1359, G loss: 1.1267\n",
      "[484/1600] D loss: 1.3870, G loss: 0.6709\n",
      "[604/1600] D loss: 1.1108, G loss: 1.6056\n",
      "[724/1600] D loss: 0.7783, G loss: 2.5288\n",
      "[844/1600] D loss: 1.0205, G loss: 1.5075\n",
      "[964/1600] D loss: 1.0134, G loss: 1.3072\n",
      "[1084/1600] D loss: 1.0768, G loss: 1.1891\n",
      "[1204/1600] D loss: 1.1544, G loss: 1.3839\n",
      "[1324/1600] D loss: 1.2449, G loss: 0.8306\n",
      "[1444/1600] D loss: 1.6798, G loss: 0.9417\n",
      "[1564/1600] D loss: 1.0666, G loss: 1.5023\n",
      "train error: \n",
      " D loss: 1.054750, G loss: 1.493896, D accuracy: 66.5%, cell accuracy: 98.9%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304291, G loss: 1.631418, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9121, G loss: 1.6375\n",
      "[124/1600] D loss: 0.8058, G loss: 1.1227\n",
      "[244/1600] D loss: 1.0384, G loss: 1.8113\n",
      "[364/1600] D loss: 0.8935, G loss: 1.6266\n",
      "[484/1600] D loss: 1.4128, G loss: 0.8425\n",
      "[604/1600] D loss: 0.6874, G loss: 1.8342\n",
      "[724/1600] D loss: 0.8984, G loss: 1.3442\n",
      "[844/1600] D loss: 1.4489, G loss: 0.7818\n",
      "[964/1600] D loss: 1.3330, G loss: 0.9029\n",
      "[1084/1600] D loss: 0.8382, G loss: 1.7678\n",
      "[1204/1600] D loss: 1.1207, G loss: 1.4802\n",
      "[1324/1600] D loss: 1.4297, G loss: 0.6288\n",
      "[1444/1600] D loss: 1.0043, G loss: 1.8103\n",
      "[1564/1600] D loss: 0.5568, G loss: 2.3123\n",
      "train error: \n",
      " D loss: 1.053499, G loss: 1.344552, D accuracy: 66.1%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.232569, G loss: 1.509395, D accuracy: 62.9%, cell accuracy: 98.5%, board accuracy: 51.7% \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3809, G loss: 0.7182\n",
      "[124/1600] D loss: 0.8887, G loss: 2.0747\n",
      "[244/1600] D loss: 1.3797, G loss: 0.5565\n",
      "[364/1600] D loss: 1.0809, G loss: 1.9675\n",
      "[484/1600] D loss: 1.3840, G loss: 0.8725\n",
      "[604/1600] D loss: 0.6128, G loss: 2.0514\n",
      "[724/1600] D loss: 1.4212, G loss: 0.8840\n",
      "[844/1600] D loss: 1.3796, G loss: 1.7438\n",
      "[964/1600] D loss: 0.6140, G loss: 1.7158\n",
      "[1084/1600] D loss: 0.9545, G loss: 1.4578\n",
      "[1204/1600] D loss: 0.8488, G loss: 1.9556\n",
      "[1324/1600] D loss: 1.1169, G loss: 1.2172\n",
      "[1444/1600] D loss: 1.6801, G loss: 0.5796\n",
      "[1564/1600] D loss: 1.2344, G loss: 0.9426\n",
      "train error: \n",
      " D loss: 1.194245, G loss: 1.828947, D accuracy: 65.8%, cell accuracy: 98.9%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.428057, G loss: 1.929392, D accuracy: 61.0%, cell accuracy: 98.7%, board accuracy: 53.5% \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9814, G loss: 3.0257\n",
      "[124/1600] D loss: 1.2747, G loss: 0.6696\n",
      "[244/1600] D loss: 0.7099, G loss: 2.3367\n",
      "[364/1600] D loss: 1.3742, G loss: 0.6646\n",
      "[484/1600] D loss: 0.9409, G loss: 1.5926\n",
      "[604/1600] D loss: 0.4283, G loss: 2.1119\n",
      "[724/1600] D loss: 1.3557, G loss: 0.7729\n",
      "[844/1600] D loss: 1.0163, G loss: 1.4090\n",
      "[964/1600] D loss: 1.0550, G loss: 1.6221\n",
      "[1084/1600] D loss: 1.4927, G loss: 1.0280\n",
      "[1204/1600] D loss: 1.3150, G loss: 0.8855\n",
      "[1324/1600] D loss: 0.8262, G loss: 1.7803\n",
      "[1444/1600] D loss: 0.5819, G loss: 2.7697\n",
      "[1564/1600] D loss: 1.3272, G loss: 0.8218\n",
      "train error: \n",
      " D loss: 1.034548, G loss: 1.528007, D accuracy: 66.5%, cell accuracy: 98.9%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260438, G loss: 1.654826, D accuracy: 62.4%, cell accuracy: 98.7%, board accuracy: 53.5% \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2669, G loss: 0.9861\n",
      "[124/1600] D loss: 0.9144, G loss: 1.4502\n",
      "[244/1600] D loss: 0.8075, G loss: 1.5911\n",
      "[364/1600] D loss: 0.6097, G loss: 1.9031\n",
      "[484/1600] D loss: 1.7000, G loss: 1.5887\n",
      "[604/1600] D loss: 0.6817, G loss: 1.1252\n",
      "[724/1600] D loss: 1.4028, G loss: 0.5917\n",
      "[844/1600] D loss: 1.0686, G loss: 1.2180\n",
      "[964/1600] D loss: 0.8006, G loss: 1.8696\n",
      "[1084/1600] D loss: 1.2069, G loss: 0.7193\n",
      "[1204/1600] D loss: 1.0181, G loss: 1.4133\n",
      "[1324/1600] D loss: 1.0417, G loss: 1.1935\n",
      "[1444/1600] D loss: 0.7335, G loss: 2.0944\n",
      "[1564/1600] D loss: 0.7841, G loss: 1.8026\n",
      "train error: \n",
      " D loss: 1.025798, G loss: 1.469818, D accuracy: 67.4%, cell accuracy: 99.0%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273706, G loss: 1.606049, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3134, G loss: 0.8695\n",
      "[124/1600] D loss: 1.0533, G loss: 1.3204\n",
      "[244/1600] D loss: 1.4802, G loss: 1.3960\n",
      "[364/1600] D loss: 0.3275, G loss: 2.2962\n",
      "[484/1600] D loss: 0.8598, G loss: 1.8705\n",
      "[604/1600] D loss: 0.7419, G loss: 1.9236\n",
      "[724/1600] D loss: 0.7384, G loss: 2.3236\n",
      "[844/1600] D loss: 0.9873, G loss: 1.1736\n",
      "[964/1600] D loss: 1.0942, G loss: 2.1961\n",
      "[1084/1600] D loss: 0.8406, G loss: 1.6955\n",
      "[1204/1600] D loss: 1.0631, G loss: 1.3143\n",
      "[1324/1600] D loss: 0.9022, G loss: 1.4499\n",
      "[1444/1600] D loss: 1.4226, G loss: 0.5266\n",
      "[1564/1600] D loss: 0.9223, G loss: 1.7511\n",
      "train error: \n",
      " D loss: 1.049904, G loss: 1.386495, D accuracy: 66.3%, cell accuracy: 98.9%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255550, G loss: 1.542666, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0705, G loss: 1.2251\n",
      "[124/1600] D loss: 1.1154, G loss: 1.2925\n",
      "[244/1600] D loss: 0.8958, G loss: 1.3024\n",
      "[364/1600] D loss: 0.3957, G loss: 2.4181\n",
      "[484/1600] D loss: 1.1014, G loss: 1.2292\n",
      "[604/1600] D loss: 0.7228, G loss: 2.2904\n",
      "[724/1600] D loss: 1.2675, G loss: 0.7560\n",
      "[844/1600] D loss: 1.1137, G loss: 1.2112\n",
      "[964/1600] D loss: 1.1429, G loss: 0.9681\n",
      "[1084/1600] D loss: 0.9020, G loss: 1.4240\n",
      "[1204/1600] D loss: 1.0825, G loss: 1.3729\n",
      "[1324/1600] D loss: 0.7065, G loss: 2.2051\n",
      "[1444/1600] D loss: 0.9892, G loss: 1.3115\n",
      "[1564/1600] D loss: 1.0211, G loss: 1.1088\n",
      "train error: \n",
      " D loss: 1.031488, G loss: 1.497282, D accuracy: 66.7%, cell accuracy: 98.9%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264069, G loss: 1.671125, D accuracy: 62.4%, cell accuracy: 98.7%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7432, G loss: 2.0240\n",
      "[124/1600] D loss: 1.0970, G loss: 1.1932\n",
      "[244/1600] D loss: 0.9319, G loss: 1.2176\n",
      "[364/1600] D loss: 0.6687, G loss: 2.9693\n",
      "[484/1600] D loss: 0.7572, G loss: 2.3185\n",
      "[604/1600] D loss: 1.1279, G loss: 0.7644\n",
      "[724/1600] D loss: 1.6025, G loss: 0.4568\n",
      "[844/1600] D loss: 1.4955, G loss: 0.9746\n",
      "[964/1600] D loss: 0.9025, G loss: 1.6253\n",
      "[1084/1600] D loss: 1.3002, G loss: 0.8110\n",
      "[1204/1600] D loss: 1.4695, G loss: 0.7411\n",
      "[1324/1600] D loss: 1.0681, G loss: 1.2401\n",
      "[1444/1600] D loss: 0.7213, G loss: 2.1622\n",
      "[1564/1600] D loss: 0.1157, G loss: 2.8276\n",
      "train error: \n",
      " D loss: 1.079589, G loss: 1.667121, D accuracy: 65.7%, cell accuracy: 98.9%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314844, G loss: 1.818236, D accuracy: 61.4%, cell accuracy: 98.7%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0594, G loss: 1.6272\n",
      "[124/1600] D loss: 1.0521, G loss: 1.6005\n",
      "[244/1600] D loss: 0.9416, G loss: 1.8360\n",
      "[364/1600] D loss: 1.3995, G loss: 0.7531\n",
      "[484/1600] D loss: 0.9745, G loss: 2.2094\n",
      "[604/1600] D loss: 0.9364, G loss: 2.2863\n",
      "[724/1600] D loss: 1.1521, G loss: 1.1987\n",
      "[844/1600] D loss: 1.5811, G loss: 0.9795\n",
      "[964/1600] D loss: 1.0984, G loss: 1.3171\n",
      "[1084/1600] D loss: 1.3962, G loss: 0.6167\n",
      "[1204/1600] D loss: 0.6960, G loss: 3.2819\n",
      "[1324/1600] D loss: 1.0454, G loss: 1.6604\n",
      "[1444/1600] D loss: 1.0462, G loss: 1.2658\n",
      "[1564/1600] D loss: 1.6284, G loss: 0.8724\n",
      "train error: \n",
      " D loss: 1.081584, G loss: 1.382140, D accuracy: 65.3%, cell accuracy: 98.8%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297386, G loss: 1.575869, D accuracy: 62.4%, cell accuracy: 98.6%, board accuracy: 53.8% \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8139, G loss: 2.5174\n",
      "[124/1600] D loss: 1.0346, G loss: 0.9375\n",
      "[244/1600] D loss: 0.7031, G loss: 1.8337\n",
      "[364/1600] D loss: 0.8138, G loss: 1.4862\n",
      "[484/1600] D loss: 0.4906, G loss: 2.4992\n",
      "[604/1600] D loss: 0.7218, G loss: 1.9039\n",
      "[724/1600] D loss: 1.0983, G loss: 1.7869\n",
      "[844/1600] D loss: 0.8002, G loss: 1.3748\n",
      "[964/1600] D loss: 0.8051, G loss: 1.4582\n",
      "[1084/1600] D loss: 0.2222, G loss: 3.5375\n",
      "[1204/1600] D loss: 1.3092, G loss: 1.0445\n",
      "[1324/1600] D loss: 1.1194, G loss: 0.8746\n",
      "[1444/1600] D loss: 1.2266, G loss: 1.2183\n",
      "[1564/1600] D loss: 1.0882, G loss: 1.1785\n",
      "train error: \n",
      " D loss: 1.036168, G loss: 1.474858, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276588, G loss: 1.616448, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0521, G loss: 1.8702\n",
      "[124/1600] D loss: 1.0960, G loss: 2.1124\n",
      "[244/1600] D loss: 1.1771, G loss: 1.0880\n",
      "[364/1600] D loss: 1.0467, G loss: 1.6714\n",
      "[484/1600] D loss: 0.8634, G loss: 1.5783\n",
      "[604/1600] D loss: 0.9224, G loss: 1.7625\n",
      "[724/1600] D loss: 0.6939, G loss: 1.8732\n",
      "[844/1600] D loss: 1.0630, G loss: 1.1819\n",
      "[964/1600] D loss: 0.7254, G loss: 1.9520\n",
      "[1084/1600] D loss: 1.1820, G loss: 0.9837\n",
      "[1204/1600] D loss: 1.3989, G loss: 0.6493\n",
      "[1324/1600] D loss: 0.8993, G loss: 1.9617\n",
      "[1444/1600] D loss: 1.4034, G loss: 0.7482\n",
      "[1564/1600] D loss: 1.1901, G loss: 0.9237\n",
      "train error: \n",
      " D loss: 1.028899, G loss: 1.472403, D accuracy: 66.5%, cell accuracy: 98.9%, board accuracy: 60.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251726, G loss: 1.674042, D accuracy: 62.6%, cell accuracy: 98.7%, board accuracy: 54.2% \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4365, G loss: 2.9626\n",
      "[124/1600] D loss: 0.9477, G loss: 1.8596\n",
      "[244/1600] D loss: 1.1426, G loss: 1.3039\n",
      "[364/1600] D loss: 1.0434, G loss: 1.1166\n",
      "[484/1600] D loss: 0.8420, G loss: 1.6355\n",
      "[604/1600] D loss: 1.1166, G loss: 1.6991\n",
      "[724/1600] D loss: 0.9908, G loss: 1.9117\n",
      "[844/1600] D loss: 0.5941, G loss: 2.3966\n",
      "[964/1600] D loss: 0.7540, G loss: 3.0238\n",
      "[1084/1600] D loss: 0.3805, G loss: 3.1134\n",
      "[1204/1600] D loss: 1.4190, G loss: 0.5496\n",
      "[1324/1600] D loss: 0.6869, G loss: 1.8493\n",
      "[1444/1600] D loss: 1.2142, G loss: 1.0921\n",
      "[1564/1600] D loss: 1.0568, G loss: 1.8738\n",
      "train error: \n",
      " D loss: 1.033073, G loss: 1.426570, D accuracy: 66.8%, cell accuracy: 98.9%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262209, G loss: 1.619529, D accuracy: 62.6%, cell accuracy: 98.7%, board accuracy: 54.5% \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0779, G loss: 1.2383\n",
      "[124/1600] D loss: 0.8330, G loss: 1.5687\n",
      "[244/1600] D loss: 0.9454, G loss: 1.1574\n",
      "[364/1600] D loss: 0.7267, G loss: 2.3221\n",
      "[484/1600] D loss: 1.1176, G loss: 1.5224\n",
      "[604/1600] D loss: 1.1002, G loss: 1.8485\n",
      "[724/1600] D loss: 1.3955, G loss: 0.7467\n",
      "[844/1600] D loss: 0.7035, G loss: 3.1727\n",
      "[964/1600] D loss: 1.4352, G loss: 0.6859\n",
      "[1084/1600] D loss: 1.0773, G loss: 1.1935\n",
      "[1204/1600] D loss: 1.4863, G loss: 0.4768\n",
      "[1324/1600] D loss: 0.9968, G loss: 2.5064\n",
      "[1444/1600] D loss: 1.0729, G loss: 1.4661\n",
      "[1564/1600] D loss: 0.9458, G loss: 1.4362\n",
      "train error: \n",
      " D loss: 1.024030, G loss: 1.428928, D accuracy: 67.1%, cell accuracy: 98.9%, board accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260326, G loss: 1.603698, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2250, G loss: 1.4507\n",
      "[124/1600] D loss: 1.2557, G loss: 1.1727\n",
      "[244/1600] D loss: 1.4377, G loss: 0.8008\n",
      "[364/1600] D loss: 1.3951, G loss: 0.6773\n",
      "[484/1600] D loss: 1.3557, G loss: 0.7235\n",
      "[604/1600] D loss: 0.8071, G loss: 1.3644\n",
      "[724/1600] D loss: 0.6413, G loss: 2.4604\n",
      "[844/1600] D loss: 1.1274, G loss: 1.2283\n",
      "[964/1600] D loss: 1.1291, G loss: 0.7142\n",
      "[1084/1600] D loss: 1.1276, G loss: 1.1655\n",
      "[1204/1600] D loss: 0.7128, G loss: 2.6310\n",
      "[1324/1600] D loss: 0.6335, G loss: 2.9431\n",
      "[1444/1600] D loss: 0.7062, G loss: 2.4766\n",
      "[1564/1600] D loss: 1.1039, G loss: 1.9144\n",
      "train error: \n",
      " D loss: 1.085641, G loss: 1.452964, D accuracy: 65.7%, cell accuracy: 99.0%, board accuracy: 60.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271958, G loss: 1.608623, D accuracy: 63.2%, cell accuracy: 98.8%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7058, G loss: 2.7438\n",
      "[124/1600] D loss: 1.1200, G loss: 1.7812\n",
      "[244/1600] D loss: 1.0651, G loss: 1.4794\n",
      "[364/1600] D loss: 1.3869, G loss: 1.1826\n",
      "[484/1600] D loss: 1.4202, G loss: 0.9150\n",
      "[604/1600] D loss: 1.5914, G loss: 1.1759\n",
      "[724/1600] D loss: 0.9772, G loss: 1.5337\n",
      "[844/1600] D loss: 1.3352, G loss: 0.7560\n",
      "[964/1600] D loss: 1.0868, G loss: 2.2708\n",
      "[1084/1600] D loss: 0.5811, G loss: 2.1332\n",
      "[1204/1600] D loss: 1.0897, G loss: 1.2908\n",
      "[1324/1600] D loss: 1.2534, G loss: 2.0265\n",
      "[1444/1600] D loss: 0.9941, G loss: 1.1105\n",
      "[1564/1600] D loss: 0.9784, G loss: 1.4206\n",
      "train error: \n",
      " D loss: 1.028805, G loss: 1.434128, D accuracy: 67.5%, cell accuracy: 98.9%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257275, G loss: 1.587571, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2598, G loss: 2.8349\n",
      "[124/1600] D loss: 0.6158, G loss: 2.3487\n",
      "[244/1600] D loss: 1.2944, G loss: 1.2050\n",
      "[364/1600] D loss: 1.3841, G loss: 0.6896\n",
      "[484/1600] D loss: 1.3289, G loss: 0.8593\n",
      "[604/1600] D loss: 1.0615, G loss: 1.1372\n",
      "[724/1600] D loss: 0.7210, G loss: 2.1956\n",
      "[844/1600] D loss: 0.8021, G loss: 2.1101\n",
      "[964/1600] D loss: 1.3680, G loss: 0.5445\n",
      "[1084/1600] D loss: 1.4358, G loss: 0.6183\n",
      "[1204/1600] D loss: 1.0037, G loss: 1.5097\n",
      "[1324/1600] D loss: 0.7532, G loss: 2.3786\n",
      "[1444/1600] D loss: 1.1103, G loss: 1.2174\n",
      "[1564/1600] D loss: 1.0582, G loss: 1.2279\n",
      "train error: \n",
      " D loss: 1.027730, G loss: 1.387644, D accuracy: 67.3%, cell accuracy: 99.0%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.220300, G loss: 1.532507, D accuracy: 63.4%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8540, G loss: 1.3995\n",
      "[124/1600] D loss: 1.4739, G loss: 0.9562\n",
      "[244/1600] D loss: 1.4594, G loss: 0.8845\n",
      "[364/1600] D loss: 1.4565, G loss: 0.6917\n",
      "[484/1600] D loss: 0.7395, G loss: 1.7577\n",
      "[604/1600] D loss: 1.0083, G loss: 2.5517\n",
      "[724/1600] D loss: 1.1084, G loss: 1.0046\n",
      "[844/1600] D loss: 1.0798, G loss: 1.5474\n",
      "[964/1600] D loss: 0.8020, G loss: 2.1239\n",
      "[1084/1600] D loss: 0.8613, G loss: 1.8300\n",
      "[1204/1600] D loss: 1.4254, G loss: 0.5346\n",
      "[1324/1600] D loss: 0.9507, G loss: 1.2896\n",
      "[1444/1600] D loss: 1.3866, G loss: 0.7978\n",
      "[1564/1600] D loss: 1.1099, G loss: 1.4971\n",
      "train error: \n",
      " D loss: 1.038108, G loss: 1.641742, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322707, G loss: 1.822742, D accuracy: 61.8%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7732, G loss: 2.2493\n",
      "[124/1600] D loss: 1.0565, G loss: 1.5280\n",
      "[244/1600] D loss: 0.8293, G loss: 2.0689\n",
      "[364/1600] D loss: 1.2433, G loss: 1.3783\n",
      "[484/1600] D loss: 1.3198, G loss: 0.7326\n",
      "[604/1600] D loss: 0.7562, G loss: 2.6689\n",
      "[724/1600] D loss: 0.7783, G loss: 2.2991\n",
      "[844/1600] D loss: 0.9349, G loss: 1.4603\n",
      "[964/1600] D loss: 0.7518, G loss: 2.7367\n",
      "[1084/1600] D loss: 0.9067, G loss: 1.9074\n",
      "[1204/1600] D loss: 0.9526, G loss: 1.0518\n",
      "[1324/1600] D loss: 1.4223, G loss: 0.6045\n",
      "[1444/1600] D loss: 1.1802, G loss: 1.2475\n",
      "[1564/1600] D loss: 1.0809, G loss: 1.5923\n",
      "train error: \n",
      " D loss: 1.057775, G loss: 1.316362, D accuracy: 65.8%, cell accuracy: 99.0%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.245435, G loss: 1.460445, D accuracy: 63.1%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8003, G loss: 1.5838\n",
      "[124/1600] D loss: 1.3762, G loss: 0.7060\n",
      "[244/1600] D loss: 0.5039, G loss: 2.5870\n",
      "[364/1600] D loss: 1.2041, G loss: 1.2791\n",
      "[484/1600] D loss: 0.9183, G loss: 1.9906\n",
      "[604/1600] D loss: 0.8303, G loss: 1.4337\n",
      "[724/1600] D loss: 1.0930, G loss: 1.2800\n",
      "[844/1600] D loss: 1.3324, G loss: 0.8365\n",
      "[964/1600] D loss: 1.1073, G loss: 2.0851\n",
      "[1084/1600] D loss: 0.8334, G loss: 1.9225\n",
      "[1204/1600] D loss: 0.8488, G loss: 1.6085\n",
      "[1324/1600] D loss: 0.6273, G loss: 2.8091\n",
      "[1444/1600] D loss: 1.0642, G loss: 1.6942\n",
      "[1564/1600] D loss: 1.0563, G loss: 1.5259\n",
      "train error: \n",
      " D loss: 1.022817, G loss: 1.444995, D accuracy: 67.6%, cell accuracy: 98.9%, board accuracy: 55.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252199, G loss: 1.653499, D accuracy: 63.1%, cell accuracy: 98.7%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4293, G loss: 0.6138\n",
      "[124/1600] D loss: 0.8208, G loss: 1.5375\n",
      "[244/1600] D loss: 1.7686, G loss: 0.8188\n",
      "[364/1600] D loss: 1.1784, G loss: 0.9764\n",
      "[484/1600] D loss: 0.7266, G loss: 2.2682\n",
      "[604/1600] D loss: 1.1552, G loss: 2.2807\n",
      "[724/1600] D loss: 1.4230, G loss: 0.8697\n",
      "[844/1600] D loss: 1.1493, G loss: 1.6155\n",
      "[964/1600] D loss: 0.6987, G loss: 2.5429\n",
      "[1084/1600] D loss: 1.4350, G loss: 0.8795\n",
      "[1204/1600] D loss: 1.4098, G loss: 0.6889\n",
      "[1324/1600] D loss: 0.8745, G loss: 1.4562\n",
      "[1444/1600] D loss: 0.4275, G loss: 2.4047\n",
      "[1564/1600] D loss: 1.0500, G loss: 1.3844\n",
      "train error: \n",
      " D loss: 1.048793, G loss: 1.293356, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266185, G loss: 1.446260, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0812, G loss: 1.1661\n",
      "[124/1600] D loss: 0.8864, G loss: 2.0189\n",
      "[244/1600] D loss: 0.9251, G loss: 2.0691\n",
      "[364/1600] D loss: 1.3960, G loss: 0.6831\n",
      "[484/1600] D loss: 1.0584, G loss: 1.2534\n",
      "[604/1600] D loss: 0.7374, G loss: 2.5084\n",
      "[724/1600] D loss: 1.3955, G loss: 0.8269\n",
      "[844/1600] D loss: 0.9905, G loss: 1.3827\n",
      "[964/1600] D loss: 0.7464, G loss: 2.2820\n",
      "[1084/1600] D loss: 1.6513, G loss: 0.4498\n",
      "[1204/1600] D loss: 1.0677, G loss: 1.3997\n",
      "[1324/1600] D loss: 1.0870, G loss: 1.5631\n",
      "[1444/1600] D loss: 1.3096, G loss: 0.6295\n",
      "[1564/1600] D loss: 0.9878, G loss: 1.4209\n",
      "train error: \n",
      " D loss: 1.053338, G loss: 1.285906, D accuracy: 66.5%, cell accuracy: 98.9%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283715, G loss: 1.504869, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7931, G loss: 1.8447\n",
      "[124/1600] D loss: 1.0687, G loss: 1.0716\n",
      "[244/1600] D loss: 1.0021, G loss: 1.1410\n",
      "[364/1600] D loss: 1.4109, G loss: 0.8056\n",
      "[484/1600] D loss: 1.0696, G loss: 1.2940\n",
      "[604/1600] D loss: 0.3468, G loss: 3.5871\n",
      "[724/1600] D loss: 1.4579, G loss: 0.7803\n",
      "[844/1600] D loss: 1.0952, G loss: 2.4413\n",
      "[964/1600] D loss: 1.2899, G loss: 0.7150\n",
      "[1084/1600] D loss: 1.2857, G loss: 1.0714\n",
      "[1204/1600] D loss: 1.0439, G loss: 1.3574\n",
      "[1324/1600] D loss: 1.7376, G loss: 0.8617\n",
      "[1444/1600] D loss: 1.0490, G loss: 1.7463\n",
      "[1564/1600] D loss: 0.9168, G loss: 1.8561\n",
      "train error: \n",
      " D loss: 1.056536, G loss: 1.307727, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260209, G loss: 1.475582, D accuracy: 62.9%, cell accuracy: 98.8%, board accuracy: 54.5% \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9737, G loss: 1.2085\n",
      "[124/1600] D loss: 0.3702, G loss: 3.1047\n",
      "[244/1600] D loss: 0.8875, G loss: 1.8024\n",
      "[364/1600] D loss: 1.0472, G loss: 1.4811\n",
      "[484/1600] D loss: 0.5128, G loss: 2.0657\n",
      "[604/1600] D loss: 1.1599, G loss: 1.4361\n",
      "[724/1600] D loss: 1.0461, G loss: 1.1635\n",
      "[844/1600] D loss: 1.1140, G loss: 0.8967\n",
      "[964/1600] D loss: 1.1208, G loss: 2.0337\n",
      "[1084/1600] D loss: 1.0774, G loss: 1.5783\n",
      "[1204/1600] D loss: 0.8841, G loss: 1.7724\n",
      "[1324/1600] D loss: 1.1058, G loss: 1.2671\n",
      "[1444/1600] D loss: 0.7280, G loss: 2.4597\n",
      "[1564/1600] D loss: 0.4536, G loss: 2.4366\n",
      "train error: \n",
      " D loss: 1.048552, G loss: 1.603554, D accuracy: 66.1%, cell accuracy: 98.9%, board accuracy: 57.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286952, G loss: 1.796182, D accuracy: 62.4%, cell accuracy: 98.7%, board accuracy: 52.0% \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1848, G loss: 0.9302\n",
      "[124/1600] D loss: 1.3087, G loss: 1.2215\n",
      "[244/1600] D loss: 0.7763, G loss: 1.8860\n",
      "[364/1600] D loss: 0.7701, G loss: 1.6584\n",
      "[484/1600] D loss: 0.8178, G loss: 1.1355\n",
      "[604/1600] D loss: 0.7139, G loss: 2.3243\n",
      "[724/1600] D loss: 0.9496, G loss: 1.3542\n",
      "[844/1600] D loss: 0.3474, G loss: 3.0797\n",
      "[964/1600] D loss: 0.7300, G loss: 2.3329\n",
      "[1084/1600] D loss: 0.6828, G loss: 1.8890\n",
      "[1204/1600] D loss: 0.8623, G loss: 2.2551\n",
      "[1324/1600] D loss: 0.7911, G loss: 1.7270\n",
      "[1444/1600] D loss: 0.7195, G loss: 2.5075\n",
      "[1564/1600] D loss: 0.6741, G loss: 1.8874\n",
      "train error: \n",
      " D loss: 1.072138, G loss: 1.701095, D accuracy: 65.7%, cell accuracy: 98.9%, board accuracy: 55.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338269, G loss: 1.872957, D accuracy: 61.6%, cell accuracy: 98.7%, board accuracy: 52.0% \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7070, G loss: 2.8734\n",
      "[124/1600] D loss: 0.8846, G loss: 1.1675\n",
      "[244/1600] D loss: 1.4896, G loss: 0.5850\n",
      "[364/1600] D loss: 0.7148, G loss: 2.1722\n",
      "[484/1600] D loss: 1.4615, G loss: 0.7941\n",
      "[604/1600] D loss: 1.4014, G loss: 0.6002\n",
      "[724/1600] D loss: 1.4810, G loss: 0.6737\n",
      "[844/1600] D loss: 0.9286, G loss: 1.8540\n",
      "[964/1600] D loss: 0.8348, G loss: 1.4882\n",
      "[1084/1600] D loss: 1.0016, G loss: 2.1887\n",
      "[1204/1600] D loss: 0.7262, G loss: 2.5236\n",
      "[1324/1600] D loss: 0.8123, G loss: 2.1431\n",
      "[1444/1600] D loss: 0.6569, G loss: 2.5750\n",
      "[1564/1600] D loss: 0.7648, G loss: 2.1029\n",
      "train error: \n",
      " D loss: 1.060820, G loss: 1.707063, D accuracy: 66.0%, cell accuracy: 98.9%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321610, G loss: 1.883636, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9272, G loss: 2.2207\n",
      "[124/1600] D loss: 0.8389, G loss: 2.0135\n",
      "[244/1600] D loss: 0.7953, G loss: 2.0869\n",
      "[364/1600] D loss: 1.1117, G loss: 0.9383\n",
      "[484/1600] D loss: 1.4082, G loss: 0.8664\n",
      "[604/1600] D loss: 1.1304, G loss: 1.3932\n",
      "[724/1600] D loss: 1.2443, G loss: 0.7186\n",
      "[844/1600] D loss: 1.0686, G loss: 1.2310\n",
      "[964/1600] D loss: 1.0428, G loss: 1.4824\n",
      "[1084/1600] D loss: 0.8976, G loss: 1.6800\n",
      "[1204/1600] D loss: 1.1143, G loss: 0.8502\n",
      "[1324/1600] D loss: 0.8091, G loss: 2.9052\n",
      "[1444/1600] D loss: 0.7022, G loss: 2.1519\n",
      "[1564/1600] D loss: 1.2186, G loss: 0.9772\n",
      "train error: \n",
      " D loss: 1.038805, G loss: 1.540814, D accuracy: 67.1%, cell accuracy: 98.9%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320491, G loss: 1.738952, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 51.5% \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9557, G loss: 1.5836\n",
      "[124/1600] D loss: 1.0503, G loss: 1.6558\n",
      "[244/1600] D loss: 0.5689, G loss: 2.7223\n",
      "[364/1600] D loss: 0.7270, G loss: 2.0838\n",
      "[484/1600] D loss: 0.5293, G loss: 2.4095\n",
      "[604/1600] D loss: 0.7730, G loss: 1.9172\n",
      "[724/1600] D loss: 1.0585, G loss: 1.1687\n",
      "[844/1600] D loss: 1.4463, G loss: 0.6256\n",
      "[964/1600] D loss: 0.5298, G loss: 2.8436\n",
      "[1084/1600] D loss: 0.7336, G loss: 1.3467\n",
      "[1204/1600] D loss: 0.5997, G loss: 1.9400\n",
      "[1324/1600] D loss: 1.4132, G loss: 0.7626\n",
      "[1444/1600] D loss: 0.6531, G loss: 2.0411\n",
      "[1564/1600] D loss: 1.3097, G loss: 0.9108\n",
      "train error: \n",
      " D loss: 1.034504, G loss: 1.470691, D accuracy: 66.2%, cell accuracy: 98.8%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270159, G loss: 1.665235, D accuracy: 62.3%, cell accuracy: 98.6%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8089, G loss: 1.3121\n",
      "[124/1600] D loss: 1.1647, G loss: 2.0314\n",
      "[244/1600] D loss: 1.3274, G loss: 0.6628\n",
      "[364/1600] D loss: 1.0858, G loss: 1.4176\n",
      "[484/1600] D loss: 1.0550, G loss: 2.2597\n",
      "[604/1600] D loss: 1.4548, G loss: 0.7018\n",
      "[724/1600] D loss: 1.1486, G loss: 1.4861\n",
      "[844/1600] D loss: 1.3845, G loss: 0.6764\n",
      "[964/1600] D loss: 1.4322, G loss: 0.7165\n",
      "[1084/1600] D loss: 0.7151, G loss: 2.1269\n",
      "[1204/1600] D loss: 0.8968, G loss: 1.4135\n",
      "[1324/1600] D loss: 1.0752, G loss: 1.2620\n",
      "[1444/1600] D loss: 0.7139, G loss: 1.9728\n",
      "[1564/1600] D loss: 0.7427, G loss: 2.2376\n",
      "train error: \n",
      " D loss: 1.035926, G loss: 1.532259, D accuracy: 66.6%, cell accuracy: 98.9%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268770, G loss: 1.717340, D accuracy: 62.4%, cell accuracy: 98.7%, board accuracy: 52.5% \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4017, G loss: 0.8988\n",
      "[124/1600] D loss: 0.9336, G loss: 1.3337\n",
      "[244/1600] D loss: 1.2542, G loss: 0.7105\n",
      "[364/1600] D loss: 1.0807, G loss: 1.2532\n",
      "[484/1600] D loss: 1.3868, G loss: 0.7995\n",
      "[604/1600] D loss: 0.9986, G loss: 1.2988\n",
      "[724/1600] D loss: 0.7374, G loss: 2.2580\n",
      "[844/1600] D loss: 1.4744, G loss: 1.2425\n",
      "[964/1600] D loss: 1.2150, G loss: 1.1734\n",
      "[1084/1600] D loss: 0.9739, G loss: 1.1604\n",
      "[1204/1600] D loss: 1.2921, G loss: 1.1857\n",
      "[1324/1600] D loss: 1.0766, G loss: 1.0989\n",
      "[1444/1600] D loss: 1.1127, G loss: 1.0293\n",
      "[1564/1600] D loss: 0.9401, G loss: 1.1841\n",
      "train error: \n",
      " D loss: 1.030252, G loss: 1.406198, D accuracy: 67.1%, cell accuracy: 98.9%, board accuracy: 57.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280689, G loss: 1.548198, D accuracy: 62.9%, cell accuracy: 98.7%, board accuracy: 50.2% \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0905, G loss: 1.2688\n",
      "[124/1600] D loss: 1.1567, G loss: 0.8688\n",
      "[244/1600] D loss: 1.0928, G loss: 1.0628\n",
      "[364/1600] D loss: 1.4355, G loss: 0.6912\n",
      "[484/1600] D loss: 0.7631, G loss: 2.8998\n",
      "[604/1600] D loss: 0.7165, G loss: 2.5451\n",
      "[724/1600] D loss: 0.7425, G loss: 1.5600\n",
      "[844/1600] D loss: 0.7217, G loss: 1.8411\n",
      "[964/1600] D loss: 0.9817, G loss: 1.5577\n",
      "[1084/1600] D loss: 0.7985, G loss: 1.4598\n",
      "[1204/1600] D loss: 1.1326, G loss: 1.5174\n",
      "[1324/1600] D loss: 1.4415, G loss: 0.6605\n",
      "[1444/1600] D loss: 0.7025, G loss: 2.3458\n",
      "[1564/1600] D loss: 0.8954, G loss: 1.9759\n",
      "train error: \n",
      " D loss: 1.036299, G loss: 1.528694, D accuracy: 66.6%, cell accuracy: 98.9%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292822, G loss: 1.717119, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 53.8% \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7753, G loss: 1.9951\n",
      "[124/1600] D loss: 1.0999, G loss: 0.9433\n",
      "[244/1600] D loss: 1.2983, G loss: 1.0193\n",
      "[364/1600] D loss: 1.0832, G loss: 1.2367\n",
      "[484/1600] D loss: 0.7051, G loss: 2.4798\n",
      "[604/1600] D loss: 0.3881, G loss: 3.1901\n",
      "[724/1600] D loss: 1.0812, G loss: 1.6619\n",
      "[844/1600] D loss: 0.9187, G loss: 2.0097\n",
      "[964/1600] D loss: 0.9783, G loss: 1.9491\n",
      "[1084/1600] D loss: 0.8861, G loss: 1.6258\n",
      "[1204/1600] D loss: 1.0464, G loss: 1.5137\n",
      "[1324/1600] D loss: 0.4842, G loss: 2.8325\n",
      "[1444/1600] D loss: 1.4411, G loss: 0.7871\n",
      "[1564/1600] D loss: 1.1293, G loss: 1.5010\n",
      "train error: \n",
      " D loss: 1.061899, G loss: 1.271488, D accuracy: 66.3%, cell accuracy: 98.9%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317565, G loss: 1.432389, D accuracy: 61.9%, cell accuracy: 98.7%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0766, G loss: 1.0666\n",
      "[124/1600] D loss: 1.3916, G loss: 0.7661\n",
      "[244/1600] D loss: 0.9698, G loss: 3.0398\n",
      "[364/1600] D loss: 1.0262, G loss: 1.0229\n",
      "[484/1600] D loss: 1.0394, G loss: 1.2532\n",
      "[604/1600] D loss: 0.9753, G loss: 1.7812\n",
      "[724/1600] D loss: 1.2027, G loss: 1.1148\n",
      "[844/1600] D loss: 1.1667, G loss: 1.2125\n",
      "[964/1600] D loss: 0.6874, G loss: 2.2162\n",
      "[1084/1600] D loss: 0.6080, G loss: 2.0796\n",
      "[1204/1600] D loss: 1.3752, G loss: 0.8375\n",
      "[1324/1600] D loss: 1.0588, G loss: 1.8054\n",
      "[1444/1600] D loss: 1.0846, G loss: 1.0851\n",
      "[1564/1600] D loss: 1.3337, G loss: 0.8362\n",
      "train error: \n",
      " D loss: 1.045882, G loss: 1.437294, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289200, G loss: 1.584144, D accuracy: 61.8%, cell accuracy: 98.8%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4490, G loss: 0.8091\n",
      "[124/1600] D loss: 1.1035, G loss: 1.3153\n",
      "[244/1600] D loss: 0.4165, G loss: 2.8619\n",
      "[364/1600] D loss: 1.3240, G loss: 1.2702\n",
      "[484/1600] D loss: 1.1748, G loss: 1.0873\n",
      "[604/1600] D loss: 1.1953, G loss: 0.7023\n",
      "[724/1600] D loss: 0.7313, G loss: 2.8447\n",
      "[844/1600] D loss: 1.2043, G loss: 1.0865\n",
      "[964/1600] D loss: 0.5620, G loss: 2.1602\n",
      "[1084/1600] D loss: 1.2445, G loss: 2.0293\n",
      "[1204/1600] D loss: 1.4279, G loss: 0.7260\n",
      "[1324/1600] D loss: 0.5412, G loss: 2.9037\n",
      "[1444/1600] D loss: 1.0669, G loss: 1.3427\n",
      "[1564/1600] D loss: 1.4767, G loss: 0.4493\n",
      "train error: \n",
      " D loss: 1.023265, G loss: 1.372040, D accuracy: 67.6%, cell accuracy: 98.9%, board accuracy: 57.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301119, G loss: 1.524623, D accuracy: 61.8%, cell accuracy: 98.8%, board accuracy: 53.8% \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6890, G loss: 2.1457\n",
      "[124/1600] D loss: 0.9472, G loss: 1.7528\n",
      "[244/1600] D loss: 1.4443, G loss: 0.6641\n",
      "[364/1600] D loss: 0.8433, G loss: 2.1778\n",
      "[484/1600] D loss: 1.1368, G loss: 1.1406\n",
      "[604/1600] D loss: 0.7068, G loss: 1.8656\n",
      "[724/1600] D loss: 1.4208, G loss: 0.7749\n",
      "[844/1600] D loss: 0.1882, G loss: 2.7665\n",
      "[964/1600] D loss: 0.7330, G loss: 2.2721\n",
      "[1084/1600] D loss: 1.0711, G loss: 1.2323\n",
      "[1204/1600] D loss: 1.1080, G loss: 1.2512\n",
      "[1324/1600] D loss: 0.7175, G loss: 1.9498\n",
      "[1444/1600] D loss: 0.7153, G loss: 2.2080\n",
      "[1564/1600] D loss: 1.0590, G loss: 1.3024\n",
      "train error: \n",
      " D loss: 1.044517, G loss: 1.629000, D accuracy: 66.5%, cell accuracy: 98.9%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321784, G loss: 1.806535, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 52.8% \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5503, G loss: 0.9254\n",
      "[124/1600] D loss: 0.6625, G loss: 2.2687\n",
      "[244/1600] D loss: 1.1302, G loss: 1.3092\n",
      "[364/1600] D loss: 0.7671, G loss: 1.7805\n",
      "[484/1600] D loss: 0.3082, G loss: 2.6253\n",
      "[604/1600] D loss: 1.2555, G loss: 1.1302\n",
      "[724/1600] D loss: 0.6404, G loss: 2.5206\n",
      "[844/1600] D loss: 0.9427, G loss: 1.7285\n",
      "[964/1600] D loss: 1.2131, G loss: 1.2554\n",
      "[1084/1600] D loss: 1.3190, G loss: 0.9617\n",
      "[1204/1600] D loss: 0.7077, G loss: 2.1216\n",
      "[1324/1600] D loss: 1.1363, G loss: 1.9719\n",
      "[1444/1600] D loss: 1.1109, G loss: 1.6174\n",
      "[1564/1600] D loss: 0.6803, G loss: 1.6157\n",
      "train error: \n",
      " D loss: 1.023485, G loss: 1.522251, D accuracy: 67.3%, cell accuracy: 98.9%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273720, G loss: 1.712421, D accuracy: 63.2%, cell accuracy: 98.7%, board accuracy: 51.7% \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3754, G loss: 0.7008\n",
      "[124/1600] D loss: 0.9266, G loss: 1.3308\n",
      "[244/1600] D loss: 1.3762, G loss: 0.8606\n",
      "[364/1600] D loss: 1.2232, G loss: 0.9462\n",
      "[484/1600] D loss: 1.1473, G loss: 0.8762\n",
      "[604/1600] D loss: 0.7308, G loss: 2.0035\n",
      "[724/1600] D loss: 0.7502, G loss: 2.4848\n",
      "[844/1600] D loss: 1.1203, G loss: 1.4594\n",
      "[964/1600] D loss: 1.2727, G loss: 0.7996\n",
      "[1084/1600] D loss: 1.0030, G loss: 1.1307\n",
      "[1204/1600] D loss: 0.9464, G loss: 1.2429\n",
      "[1324/1600] D loss: 1.3725, G loss: 1.1941\n",
      "[1444/1600] D loss: 1.0721, G loss: 0.9289\n",
      "[1564/1600] D loss: 1.1597, G loss: 1.2872\n",
      "train error: \n",
      " D loss: 1.034340, G loss: 1.502081, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305683, G loss: 1.663688, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3708, G loss: 0.8616\n",
      "[124/1600] D loss: 1.0232, G loss: 1.5469\n",
      "[244/1600] D loss: 0.4364, G loss: 2.4009\n",
      "[364/1600] D loss: 1.2267, G loss: 0.7081\n",
      "[484/1600] D loss: 0.7894, G loss: 2.1928\n",
      "[604/1600] D loss: 0.7130, G loss: 2.3630\n",
      "[724/1600] D loss: 0.7700, G loss: 1.9934\n",
      "[844/1600] D loss: 1.0776, G loss: 2.1921\n",
      "[964/1600] D loss: 1.0709, G loss: 1.7753\n",
      "[1084/1600] D loss: 1.3631, G loss: 0.7743\n",
      "[1204/1600] D loss: 1.0621, G loss: 1.1673\n",
      "[1324/1600] D loss: 1.4001, G loss: 0.7866\n",
      "[1444/1600] D loss: 1.0306, G loss: 1.3755\n",
      "[1564/1600] D loss: 0.2410, G loss: 2.3296\n",
      "train error: \n",
      " D loss: 1.067365, G loss: 1.785195, D accuracy: 66.0%, cell accuracy: 98.9%, board accuracy: 56.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367507, G loss: 1.998981, D accuracy: 62.1%, cell accuracy: 98.7%, board accuracy: 50.5% \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7930, G loss: 3.1239\n",
      "[124/1600] D loss: 1.4193, G loss: 0.8118\n",
      "[244/1600] D loss: 1.0716, G loss: 1.4262\n",
      "[364/1600] D loss: 1.2205, G loss: 0.7246\n",
      "[484/1600] D loss: 1.3150, G loss: 1.5770\n",
      "[604/1600] D loss: 1.0223, G loss: 1.5153\n",
      "[724/1600] D loss: 0.7341, G loss: 2.0926\n",
      "[844/1600] D loss: 1.3714, G loss: 0.9421\n",
      "[964/1600] D loss: 0.7959, G loss: 1.7062\n",
      "[1084/1600] D loss: 0.8322, G loss: 2.3881\n",
      "[1204/1600] D loss: 1.0244, G loss: 1.8002\n",
      "[1324/1600] D loss: 0.4911, G loss: 2.6539\n",
      "[1444/1600] D loss: 1.0436, G loss: 1.1013\n",
      "[1564/1600] D loss: 1.6286, G loss: 1.3010\n",
      "train error: \n",
      " D loss: 1.092286, G loss: 1.259880, D accuracy: 65.5%, cell accuracy: 99.0%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294476, G loss: 1.472446, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 52.5% \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3548, G loss: 0.7448\n",
      "[124/1600] D loss: 1.1917, G loss: 1.2215\n",
      "[244/1600] D loss: 0.8670, G loss: 1.9754\n",
      "[364/1600] D loss: 0.7837, G loss: 1.8583\n",
      "[484/1600] D loss: 1.0361, G loss: 1.6972\n",
      "[604/1600] D loss: 0.8436, G loss: 1.7031\n",
      "[724/1600] D loss: 0.8901, G loss: 1.7564\n",
      "[844/1600] D loss: 0.7236, G loss: 1.7766\n",
      "[964/1600] D loss: 1.1894, G loss: 0.7305\n",
      "[1084/1600] D loss: 1.4116, G loss: 0.5968\n",
      "[1204/1600] D loss: 1.0536, G loss: 1.4546\n",
      "[1324/1600] D loss: 1.3865, G loss: 0.8392\n",
      "[1444/1600] D loss: 1.2351, G loss: 0.9673\n",
      "[1564/1600] D loss: 1.0976, G loss: 0.7603\n",
      "train error: \n",
      " D loss: 1.032254, G loss: 1.551997, D accuracy: 66.2%, cell accuracy: 98.9%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309565, G loss: 1.725535, D accuracy: 61.1%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7303, G loss: 1.6924\n",
      "[124/1600] D loss: 1.1971, G loss: 0.8643\n",
      "[244/1600] D loss: 1.4363, G loss: 0.8937\n",
      "[364/1600] D loss: 0.7736, G loss: 2.0422\n",
      "[484/1600] D loss: 0.8701, G loss: 1.3184\n",
      "[604/1600] D loss: 1.4161, G loss: 0.4919\n",
      "[724/1600] D loss: 0.7463, G loss: 2.2432\n",
      "[844/1600] D loss: 1.2650, G loss: 0.7711\n",
      "[964/1600] D loss: 1.0981, G loss: 0.9705\n",
      "[1084/1600] D loss: 1.0564, G loss: 1.7164\n",
      "[1204/1600] D loss: 1.0908, G loss: 1.3037\n",
      "[1324/1600] D loss: 0.3858, G loss: 2.9047\n",
      "[1444/1600] D loss: 1.4166, G loss: 0.5319\n",
      "[1564/1600] D loss: 1.4852, G loss: 0.8305\n",
      "train error: \n",
      " D loss: 1.035017, G loss: 1.342482, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253765, G loss: 1.561500, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0550, G loss: 1.2460\n",
      "[124/1600] D loss: 1.1236, G loss: 1.0496\n",
      "[244/1600] D loss: 0.3915, G loss: 3.4355\n",
      "[364/1600] D loss: 1.1263, G loss: 1.3215\n",
      "[484/1600] D loss: 1.1551, G loss: 1.0040\n",
      "[604/1600] D loss: 1.3245, G loss: 0.7830\n",
      "[724/1600] D loss: 1.1061, G loss: 1.5145\n",
      "[844/1600] D loss: 1.3700, G loss: 0.7430\n",
      "[964/1600] D loss: 0.8126, G loss: 1.5839\n",
      "[1084/1600] D loss: 0.6005, G loss: 2.2609\n",
      "[1204/1600] D loss: 0.8956, G loss: 1.5460\n",
      "[1324/1600] D loss: 1.1276, G loss: 0.9086\n",
      "[1444/1600] D loss: 0.6645, G loss: 2.1110\n",
      "[1564/1600] D loss: 1.2973, G loss: 0.6063\n",
      "train error: \n",
      " D loss: 1.035994, G loss: 1.563188, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290945, G loss: 1.778860, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0596, G loss: 1.3528\n",
      "[124/1600] D loss: 0.9961, G loss: 1.2772\n",
      "[244/1600] D loss: 0.9361, G loss: 2.2852\n",
      "[364/1600] D loss: 1.2223, G loss: 1.1391\n",
      "[484/1600] D loss: 1.1317, G loss: 1.4075\n",
      "[604/1600] D loss: 1.0943, G loss: 2.1005\n",
      "[724/1600] D loss: 0.7125, G loss: 2.4215\n",
      "[844/1600] D loss: 0.7740, G loss: 1.5950\n",
      "[964/1600] D loss: 1.2872, G loss: 0.8299\n",
      "[1084/1600] D loss: 0.8231, G loss: 1.4544\n",
      "[1204/1600] D loss: 0.8135, G loss: 2.4037\n",
      "[1324/1600] D loss: 1.4465, G loss: 0.6049\n",
      "[1444/1600] D loss: 1.0582, G loss: 1.2530\n",
      "[1564/1600] D loss: 1.4644, G loss: 0.6169\n",
      "train error: \n",
      " D loss: 1.028147, G loss: 1.455316, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271892, G loss: 1.661569, D accuracy: 62.9%, cell accuracy: 98.8%, board accuracy: 52.5% \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2218, G loss: 3.0319\n",
      "[124/1600] D loss: 1.3514, G loss: 1.1733\n",
      "[244/1600] D loss: 0.7264, G loss: 2.0507\n",
      "[364/1600] D loss: 0.7140, G loss: 2.0827\n",
      "[484/1600] D loss: 0.5531, G loss: 1.8541\n",
      "[604/1600] D loss: 0.7635, G loss: 2.0447\n",
      "[724/1600] D loss: 1.0718, G loss: 1.3253\n",
      "[844/1600] D loss: 1.1433, G loss: 1.5559\n",
      "[964/1600] D loss: 1.2672, G loss: 0.8258\n",
      "[1084/1600] D loss: 0.8186, G loss: 2.0005\n",
      "[1204/1600] D loss: 0.9484, G loss: 1.7701\n",
      "[1324/1600] D loss: 1.1751, G loss: 1.5152\n",
      "[1444/1600] D loss: 0.8249, G loss: 1.9059\n",
      "[1564/1600] D loss: 0.7974, G loss: 1.3143\n",
      "train error: \n",
      " D loss: 1.068817, G loss: 1.728414, D accuracy: 64.9%, cell accuracy: 98.9%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363939, G loss: 1.964384, D accuracy: 62.0%, cell accuracy: 98.7%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3673, G loss: 0.6730\n",
      "[124/1600] D loss: 0.8444, G loss: 1.5902\n",
      "[244/1600] D loss: 1.2337, G loss: 0.7907\n",
      "[364/1600] D loss: 0.6466, G loss: 1.8911\n",
      "[484/1600] D loss: 1.1891, G loss: 0.7720\n",
      "[604/1600] D loss: 0.8100, G loss: 1.6103\n",
      "[724/1600] D loss: 0.7417, G loss: 2.5679\n",
      "[844/1600] D loss: 0.8610, G loss: 2.1853\n",
      "[964/1600] D loss: 0.7162, G loss: 3.0320\n",
      "[1084/1600] D loss: 1.0094, G loss: 1.3905\n",
      "[1204/1600] D loss: 0.8875, G loss: 1.4537\n",
      "[1324/1600] D loss: 1.1668, G loss: 2.0922\n",
      "[1444/1600] D loss: 0.9544, G loss: 1.9635\n",
      "[1564/1600] D loss: 1.0813, G loss: 1.3908\n",
      "train error: \n",
      " D loss: 1.036935, G loss: 1.405328, D accuracy: 65.8%, cell accuracy: 98.9%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284525, G loss: 1.632813, D accuracy: 61.6%, cell accuracy: 98.6%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9692, G loss: 1.2931\n",
      "[124/1600] D loss: 1.7753, G loss: 0.5320\n",
      "[244/1600] D loss: 1.2938, G loss: 1.4881\n",
      "[364/1600] D loss: 1.0228, G loss: 1.3105\n",
      "[484/1600] D loss: 1.3374, G loss: 1.8108\n",
      "[604/1600] D loss: 0.9034, G loss: 1.5256\n",
      "[724/1600] D loss: 0.8315, G loss: 1.5774\n",
      "[844/1600] D loss: 0.9205, G loss: 1.6266\n",
      "[964/1600] D loss: 0.8253, G loss: 1.4568\n",
      "[1084/1600] D loss: 1.5293, G loss: 0.6467\n",
      "[1204/1600] D loss: 1.2653, G loss: 1.0970\n",
      "[1324/1600] D loss: 1.1494, G loss: 1.2421\n",
      "[1444/1600] D loss: 0.3903, G loss: 3.1712\n",
      "[1564/1600] D loss: 0.7685, G loss: 1.9628\n",
      "train error: \n",
      " D loss: 1.050979, G loss: 1.381678, D accuracy: 66.4%, cell accuracy: 98.9%, board accuracy: 56.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297068, G loss: 1.579381, D accuracy: 62.3%, cell accuracy: 98.6%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7820, G loss: 2.1021\n",
      "[124/1600] D loss: 1.3737, G loss: 0.6771\n",
      "[244/1600] D loss: 1.2646, G loss: 0.7679\n",
      "[364/1600] D loss: 0.6927, G loss: 1.8208\n",
      "[484/1600] D loss: 1.2701, G loss: 0.8219\n",
      "[604/1600] D loss: 1.0129, G loss: 1.1685\n",
      "[724/1600] D loss: 0.7532, G loss: 2.4117\n",
      "[844/1600] D loss: 1.1942, G loss: 0.9259\n",
      "[964/1600] D loss: 0.8736, G loss: 2.2690\n",
      "[1084/1600] D loss: 0.9754, G loss: 2.0662\n",
      "[1204/1600] D loss: 0.7329, G loss: 2.4030\n",
      "[1324/1600] D loss: 1.0060, G loss: 1.1412\n",
      "[1444/1600] D loss: 1.2656, G loss: 0.7391\n",
      "[1564/1600] D loss: 0.5029, G loss: 2.6362\n",
      "train error: \n",
      " D loss: 1.077637, G loss: 1.269062, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292268, G loss: 1.491674, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8723, G loss: 1.6210\n",
      "[124/1600] D loss: 1.0594, G loss: 1.3921\n",
      "[244/1600] D loss: 0.7861, G loss: 1.5676\n",
      "[364/1600] D loss: 1.0565, G loss: 1.5814\n",
      "[484/1600] D loss: 1.2967, G loss: 0.7637\n",
      "[604/1600] D loss: 1.3878, G loss: 0.7178\n",
      "[724/1600] D loss: 1.3985, G loss: 0.5754\n",
      "[844/1600] D loss: 1.3989, G loss: 0.6703\n",
      "[964/1600] D loss: 1.2887, G loss: 0.7933\n",
      "[1084/1600] D loss: 0.9368, G loss: 1.2935\n",
      "[1204/1600] D loss: 1.1646, G loss: 0.7741\n",
      "[1324/1600] D loss: 0.8608, G loss: 1.5037\n",
      "[1444/1600] D loss: 0.5346, G loss: 2.3669\n",
      "[1564/1600] D loss: 1.3085, G loss: 1.4381\n",
      "train error: \n",
      " D loss: 1.022200, G loss: 1.436840, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280082, G loss: 1.670210, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 53.8% \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3906, G loss: 0.6129\n",
      "[124/1600] D loss: 1.1087, G loss: 0.9255\n",
      "[244/1600] D loss: 1.5785, G loss: 1.4177\n",
      "[364/1600] D loss: 1.0877, G loss: 1.3126\n",
      "[484/1600] D loss: 1.0859, G loss: 1.6000\n",
      "[604/1600] D loss: 0.7646, G loss: 2.4343\n",
      "[724/1600] D loss: 1.0932, G loss: 0.9234\n",
      "[844/1600] D loss: 0.6964, G loss: 2.2176\n",
      "[964/1600] D loss: 0.7443, G loss: 2.3106\n",
      "[1084/1600] D loss: 1.4390, G loss: 0.7941\n",
      "[1204/1600] D loss: 0.7653, G loss: 1.7205\n",
      "[1324/1600] D loss: 1.2946, G loss: 1.0974\n",
      "[1444/1600] D loss: 0.5956, G loss: 1.9071\n",
      "[1564/1600] D loss: 1.0694, G loss: 1.2988\n",
      "train error: \n",
      " D loss: 1.044819, G loss: 1.532881, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309680, G loss: 1.801601, D accuracy: 61.4%, cell accuracy: 98.7%, board accuracy: 53.8% \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1358, G loss: 0.8800\n",
      "[124/1600] D loss: 0.8726, G loss: 1.3276\n",
      "[244/1600] D loss: 1.4920, G loss: 1.2061\n",
      "[364/1600] D loss: 1.2982, G loss: 0.7898\n",
      "[484/1600] D loss: 1.3074, G loss: 0.6402\n",
      "[604/1600] D loss: 0.6993, G loss: 3.7810\n",
      "[724/1600] D loss: 1.0553, G loss: 1.4446\n",
      "[844/1600] D loss: 0.7577, G loss: 1.4851\n",
      "[964/1600] D loss: 0.7076, G loss: 1.6214\n",
      "[1084/1600] D loss: 1.4474, G loss: 0.7175\n",
      "[1204/1600] D loss: 1.0052, G loss: 1.2818\n",
      "[1324/1600] D loss: 0.7288, G loss: 2.8115\n",
      "[1444/1600] D loss: 1.3396, G loss: 0.9831\n",
      "[1564/1600] D loss: 1.2478, G loss: 1.1565\n",
      "train error: \n",
      " D loss: 1.042463, G loss: 1.397012, D accuracy: 66.5%, cell accuracy: 98.9%, board accuracy: 60.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268732, G loss: 1.624486, D accuracy: 62.5%, cell accuracy: 98.7%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7891, G loss: 1.3424\n",
      "[124/1600] D loss: 0.7520, G loss: 1.7910\n",
      "[244/1600] D loss: 0.5158, G loss: 2.7843\n",
      "[364/1600] D loss: 0.8030, G loss: 2.1394\n",
      "[484/1600] D loss: 0.8418, G loss: 1.3793\n",
      "[604/1600] D loss: 1.1780, G loss: 1.3234\n",
      "[724/1600] D loss: 0.4177, G loss: 2.5954\n",
      "[844/1600] D loss: 1.3994, G loss: 0.9376\n",
      "[964/1600] D loss: 0.8142, G loss: 1.8962\n",
      "[1084/1600] D loss: 0.7136, G loss: 2.4231\n",
      "[1204/1600] D loss: 1.0333, G loss: 1.5714\n",
      "[1324/1600] D loss: 0.9276, G loss: 1.7280\n",
      "[1444/1600] D loss: 0.8535, G loss: 1.7163\n",
      "[1564/1600] D loss: 1.0972, G loss: 1.2782\n",
      "train error: \n",
      " D loss: 1.096321, G loss: 1.263994, D accuracy: 65.8%, cell accuracy: 99.0%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316791, G loss: 1.488948, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2835, G loss: 1.5992\n",
      "[124/1600] D loss: 0.8363, G loss: 2.4360\n",
      "[244/1600] D loss: 0.9885, G loss: 1.7939\n",
      "[364/1600] D loss: 0.4831, G loss: 2.7274\n",
      "[484/1600] D loss: 1.4062, G loss: 0.4629\n",
      "[604/1600] D loss: 1.5153, G loss: 0.6701\n",
      "[724/1600] D loss: 1.4443, G loss: 0.6199\n",
      "[844/1600] D loss: 1.3956, G loss: 0.6338\n",
      "[964/1600] D loss: 0.7214, G loss: 1.9113\n",
      "[1084/1600] D loss: 0.3773, G loss: 2.7471\n",
      "[1204/1600] D loss: 0.8077, G loss: 1.2755\n",
      "[1324/1600] D loss: 0.8107, G loss: 1.8929\n",
      "[1444/1600] D loss: 0.8217, G loss: 2.0597\n",
      "[1564/1600] D loss: 0.9570, G loss: 1.5439\n",
      "train error: \n",
      " D loss: 1.049606, G loss: 1.474517, D accuracy: 66.5%, cell accuracy: 98.9%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277579, G loss: 1.677083, D accuracy: 62.4%, cell accuracy: 98.7%, board accuracy: 51.5% \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7341, G loss: 1.6710\n",
      "[124/1600] D loss: 0.7473, G loss: 2.9800\n",
      "[244/1600] D loss: 0.5583, G loss: 2.0735\n",
      "[364/1600] D loss: 1.1804, G loss: 1.0565\n",
      "[484/1600] D loss: 1.0670, G loss: 1.2567\n",
      "[604/1600] D loss: 1.1892, G loss: 0.8137\n",
      "[724/1600] D loss: 0.8746, G loss: 2.1223\n",
      "[844/1600] D loss: 0.6283, G loss: 2.7613\n",
      "[964/1600] D loss: 0.5831, G loss: 1.8524\n",
      "[1084/1600] D loss: 1.3088, G loss: 0.6986\n",
      "[1204/1600] D loss: 0.7645, G loss: 2.8401\n",
      "[1324/1600] D loss: 1.3797, G loss: 0.6601\n",
      "[1444/1600] D loss: 0.7042, G loss: 2.6446\n",
      "[1564/1600] D loss: 1.1105, G loss: 1.3671\n",
      "train error: \n",
      " D loss: 1.036037, G loss: 1.425184, D accuracy: 66.9%, cell accuracy: 98.9%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291697, G loss: 1.665326, D accuracy: 62.3%, cell accuracy: 98.7%, board accuracy: 51.7% \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6769, G loss: 2.5494\n",
      "[124/1600] D loss: 1.1223, G loss: 1.3738\n",
      "[244/1600] D loss: 1.3797, G loss: 0.6691\n",
      "[364/1600] D loss: 0.6188, G loss: 2.4705\n",
      "[484/1600] D loss: 1.0156, G loss: 1.4825\n",
      "[604/1600] D loss: 1.4103, G loss: 0.9530\n",
      "[724/1600] D loss: 0.8784, G loss: 1.6105\n",
      "[844/1600] D loss: 1.0823, G loss: 1.3046\n",
      "[964/1600] D loss: 1.0516, G loss: 0.8278\n",
      "[1084/1600] D loss: 1.4024, G loss: 0.7111\n",
      "[1204/1600] D loss: 0.9948, G loss: 2.0772\n",
      "[1324/1600] D loss: 1.2320, G loss: 0.8860\n",
      "[1444/1600] D loss: 0.4465, G loss: 2.1682\n",
      "[1564/1600] D loss: 1.0954, G loss: 1.2043\n",
      "train error: \n",
      " D loss: 1.085772, G loss: 1.261076, D accuracy: 65.8%, cell accuracy: 98.9%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282857, G loss: 1.490918, D accuracy: 62.9%, cell accuracy: 98.7%, board accuracy: 54.2% \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2070, G loss: 0.7895\n",
      "[124/1600] D loss: 1.1944, G loss: 0.7639\n",
      "[244/1600] D loss: 1.4379, G loss: 0.7491\n",
      "[364/1600] D loss: 1.4884, G loss: 0.6287\n",
      "[484/1600] D loss: 1.2192, G loss: 0.9908\n",
      "[604/1600] D loss: 1.0764, G loss: 0.9483\n",
      "[724/1600] D loss: 0.7294, G loss: 1.6241\n",
      "[844/1600] D loss: 0.8661, G loss: 1.2037\n",
      "[964/1600] D loss: 0.8932, G loss: 2.9509\n",
      "[1084/1600] D loss: 1.4353, G loss: 0.7641\n",
      "[1204/1600] D loss: 0.6313, G loss: 1.9063\n",
      "[1324/1600] D loss: 1.2301, G loss: 1.2050\n",
      "[1444/1600] D loss: 1.1511, G loss: 0.7706\n",
      "[1564/1600] D loss: 0.7528, G loss: 1.8913\n",
      "train error: \n",
      " D loss: 1.030761, G loss: 1.517754, D accuracy: 66.2%, cell accuracy: 98.9%, board accuracy: 60.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310361, G loss: 1.753085, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3905, G loss: 0.6129\n",
      "[124/1600] D loss: 1.2923, G loss: 1.0515\n",
      "[244/1600] D loss: 1.1277, G loss: 0.8874\n",
      "[364/1600] D loss: 0.9415, G loss: 1.5625\n",
      "[484/1600] D loss: 1.0682, G loss: 1.4167\n",
      "[604/1600] D loss: 1.2987, G loss: 0.5729\n",
      "[724/1600] D loss: 1.1280, G loss: 1.7556\n",
      "[844/1600] D loss: 0.0306, G loss: 3.7067\n",
      "[964/1600] D loss: 1.4448, G loss: 0.8539\n",
      "[1084/1600] D loss: 1.4117, G loss: 0.7576\n",
      "[1204/1600] D loss: 1.0645, G loss: 1.3593\n",
      "[1324/1600] D loss: 0.8253, G loss: 1.9141\n",
      "[1444/1600] D loss: 1.0508, G loss: 1.3828\n",
      "[1564/1600] D loss: 1.0472, G loss: 1.4782\n",
      "train error: \n",
      " D loss: 1.035228, G loss: 1.485144, D accuracy: 66.1%, cell accuracy: 98.9%, board accuracy: 60.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291535, G loss: 1.715949, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7684, G loss: 2.1758\n",
      "[124/1600] D loss: 1.3800, G loss: 0.5889\n",
      "[244/1600] D loss: 1.1156, G loss: 0.9077\n",
      "[364/1600] D loss: 1.4209, G loss: 0.6253\n",
      "[484/1600] D loss: 1.1932, G loss: 0.9865\n",
      "[604/1600] D loss: 0.8082, G loss: 1.4148\n",
      "[724/1600] D loss: 1.4953, G loss: 0.4829\n",
      "[844/1600] D loss: 1.0258, G loss: 1.2803\n",
      "[964/1600] D loss: 1.0588, G loss: 1.3085\n",
      "[1084/1600] D loss: 0.7620, G loss: 2.5061\n",
      "[1204/1600] D loss: 0.6717, G loss: 2.4244\n",
      "[1324/1600] D loss: 1.1486, G loss: 0.9786\n",
      "[1444/1600] D loss: 1.2944, G loss: 1.0496\n",
      "[1564/1600] D loss: 0.7518, G loss: 2.1107\n",
      "train error: \n",
      " D loss: 1.035374, G loss: 1.361689, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267658, G loss: 1.552004, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9402, G loss: 1.4223\n",
      "[124/1600] D loss: 0.8582, G loss: 2.4689\n",
      "[244/1600] D loss: 1.3877, G loss: 0.6580\n",
      "[364/1600] D loss: 1.0458, G loss: 1.7398\n",
      "[484/1600] D loss: 0.4161, G loss: 2.1164\n",
      "[604/1600] D loss: 0.6256, G loss: 2.8204\n",
      "[724/1600] D loss: 1.2539, G loss: 0.8414\n",
      "[844/1600] D loss: 0.9060, G loss: 1.2585\n",
      "[964/1600] D loss: 1.0708, G loss: 1.1273\n",
      "[1084/1600] D loss: 0.7266, G loss: 2.1577\n",
      "[1204/1600] D loss: 1.3177, G loss: 0.8737\n",
      "[1324/1600] D loss: 1.3099, G loss: 0.6841\n",
      "[1444/1600] D loss: 1.3166, G loss: 0.7408\n",
      "[1564/1600] D loss: 0.4682, G loss: 2.2092\n",
      "train error: \n",
      " D loss: 1.068387, G loss: 1.555574, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329455, G loss: 1.738093, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4753, G loss: 0.6993\n",
      "[124/1600] D loss: 0.6267, G loss: 1.5315\n",
      "[244/1600] D loss: 1.3497, G loss: 0.5975\n",
      "[364/1600] D loss: 1.6240, G loss: 0.7496\n",
      "[484/1600] D loss: 1.2688, G loss: 0.6534\n",
      "[604/1600] D loss: 1.2832, G loss: 0.8417\n",
      "[724/1600] D loss: 0.4260, G loss: 2.9068\n",
      "[844/1600] D loss: 1.0986, G loss: 1.9629\n",
      "[964/1600] D loss: 0.5392, G loss: 2.5098\n",
      "[1084/1600] D loss: 1.2486, G loss: 1.1322\n",
      "[1204/1600] D loss: 0.8479, G loss: 1.4521\n",
      "[1324/1600] D loss: 0.6077, G loss: 3.3185\n",
      "[1444/1600] D loss: 1.3905, G loss: 0.7336\n",
      "[1564/1600] D loss: 0.6886, G loss: 2.2852\n",
      "train error: \n",
      " D loss: 1.047740, G loss: 1.298574, D accuracy: 65.9%, cell accuracy: 99.0%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285088, G loss: 1.466842, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 54.2% \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4784, G loss: 2.4846\n",
      "[124/1600] D loss: 1.1332, G loss: 0.7205\n",
      "[244/1600] D loss: 0.8512, G loss: 1.8261\n",
      "[364/1600] D loss: 0.9224, G loss: 1.9314\n",
      "[484/1600] D loss: 0.7445, G loss: 1.9861\n",
      "[604/1600] D loss: 1.3574, G loss: 0.8679\n",
      "[724/1600] D loss: 0.6598, G loss: 2.6086\n",
      "[844/1600] D loss: 0.9057, G loss: 1.9559\n",
      "[964/1600] D loss: 0.7587, G loss: 2.3636\n",
      "[1084/1600] D loss: 0.7109, G loss: 2.3769\n",
      "[1204/1600] D loss: 0.2425, G loss: 2.5575\n",
      "[1324/1600] D loss: 0.7292, G loss: 2.0146\n",
      "[1444/1600] D loss: 0.7492, G loss: 1.8982\n",
      "[1564/1600] D loss: 1.4381, G loss: 0.8487\n",
      "train error: \n",
      " D loss: 1.047223, G loss: 1.286718, D accuracy: 65.8%, cell accuracy: 99.0%, board accuracy: 60.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264457, G loss: 1.501130, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4071, G loss: 0.5673\n",
      "[124/1600] D loss: 0.7286, G loss: 2.0230\n",
      "[244/1600] D loss: 1.3040, G loss: 0.6247\n",
      "[364/1600] D loss: 0.7110, G loss: 2.3699\n",
      "[484/1600] D loss: 0.3572, G loss: 3.6349\n",
      "[604/1600] D loss: 1.4158, G loss: 0.8326\n",
      "[724/1600] D loss: 1.3937, G loss: 0.6564\n",
      "[844/1600] D loss: 1.1715, G loss: 0.8900\n",
      "[964/1600] D loss: 1.0469, G loss: 1.3939\n",
      "[1084/1600] D loss: 1.0483, G loss: 1.3827\n",
      "[1204/1600] D loss: 1.4676, G loss: 0.6101\n",
      "[1324/1600] D loss: 1.5694, G loss: 1.1503\n",
      "[1444/1600] D loss: 1.3993, G loss: 0.6500\n",
      "[1564/1600] D loss: 0.7922, G loss: 2.0425\n",
      "train error: \n",
      " D loss: 1.018516, G loss: 1.463202, D accuracy: 67.4%, cell accuracy: 99.0%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289588, G loss: 1.669690, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 53.5% \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0773, G loss: 1.3147\n",
      "[124/1600] D loss: 0.2006, G loss: 3.2612\n",
      "[244/1600] D loss: 0.9035, G loss: 1.4662\n",
      "[364/1600] D loss: 1.1142, G loss: 0.9724\n",
      "[484/1600] D loss: 1.0908, G loss: 1.5422\n",
      "[604/1600] D loss: 0.9568, G loss: 1.4248\n",
      "[724/1600] D loss: 0.7248, G loss: 2.1932\n",
      "[844/1600] D loss: 0.4605, G loss: 2.4097\n",
      "[964/1600] D loss: 0.8518, G loss: 2.4258\n",
      "[1084/1600] D loss: 1.1165, G loss: 0.8520\n",
      "[1204/1600] D loss: 1.1266, G loss: 1.3834\n",
      "[1324/1600] D loss: 0.8469, G loss: 1.7879\n",
      "[1444/1600] D loss: 1.3080, G loss: 0.7491\n",
      "[1564/1600] D loss: 1.3997, G loss: 0.6911\n",
      "train error: \n",
      " D loss: 1.042809, G loss: 1.529465, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 60.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308655, G loss: 1.709990, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7631, G loss: 1.8348\n",
      "[124/1600] D loss: 0.5051, G loss: 2.6182\n",
      "[244/1600] D loss: 1.0402, G loss: 1.5059\n",
      "[364/1600] D loss: 1.1676, G loss: 0.9020\n",
      "[484/1600] D loss: 0.3945, G loss: 3.1842\n",
      "[604/1600] D loss: 0.3564, G loss: 2.3906\n",
      "[724/1600] D loss: 0.8870, G loss: 1.7234\n",
      "[844/1600] D loss: 0.7982, G loss: 2.2735\n",
      "[964/1600] D loss: 1.2136, G loss: 0.7914\n",
      "[1084/1600] D loss: 0.3550, G loss: 2.5138\n",
      "[1204/1600] D loss: 1.2967, G loss: 1.4439\n",
      "[1324/1600] D loss: 0.8532, G loss: 1.6520\n",
      "[1444/1600] D loss: 0.7289, G loss: 2.0633\n",
      "[1564/1600] D loss: 1.0325, G loss: 1.1518\n",
      "train error: \n",
      " D loss: 1.049897, G loss: 1.269477, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288772, G loss: 1.472515, D accuracy: 61.6%, cell accuracy: 98.8%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3208, G loss: 0.5937\n",
      "[124/1600] D loss: 0.8210, G loss: 1.8333\n",
      "[244/1600] D loss: 1.0764, G loss: 1.3048\n",
      "[364/1600] D loss: 0.7819, G loss: 2.0840\n",
      "[484/1600] D loss: 0.6297, G loss: 2.0566\n",
      "[604/1600] D loss: 1.4936, G loss: 0.6567\n",
      "[724/1600] D loss: 0.9085, G loss: 1.0252\n",
      "[844/1600] D loss: 1.3803, G loss: 0.6910\n",
      "[964/1600] D loss: 1.3657, G loss: 0.7372\n",
      "[1084/1600] D loss: 1.0471, G loss: 1.5115\n",
      "[1204/1600] D loss: 1.4575, G loss: 0.7929\n",
      "[1324/1600] D loss: 1.4327, G loss: 0.6533\n",
      "[1444/1600] D loss: 0.5257, G loss: 2.5640\n",
      "[1564/1600] D loss: 1.0919, G loss: 1.5459\n",
      "train error: \n",
      " D loss: 1.073103, G loss: 1.236010, D accuracy: 66.3%, cell accuracy: 98.9%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282246, G loss: 1.443477, D accuracy: 62.0%, cell accuracy: 98.7%, board accuracy: 53.5% \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1483, G loss: 0.6423\n",
      "[124/1600] D loss: 1.0800, G loss: 0.9915\n",
      "[244/1600] D loss: 0.9688, G loss: 1.2770\n",
      "[364/1600] D loss: 1.1424, G loss: 0.9093\n",
      "[484/1600] D loss: 1.5374, G loss: 1.0129\n",
      "[604/1600] D loss: 0.8044, G loss: 2.6729\n",
      "[724/1600] D loss: 0.9984, G loss: 1.8783\n",
      "[844/1600] D loss: 1.4032, G loss: 0.6503\n",
      "[964/1600] D loss: 1.2924, G loss: 0.8965\n",
      "[1084/1600] D loss: 0.6875, G loss: 2.4417\n",
      "[1204/1600] D loss: 0.9478, G loss: 1.7224\n",
      "[1324/1600] D loss: 0.3861, G loss: 2.4989\n",
      "[1444/1600] D loss: 1.0227, G loss: 2.3368\n",
      "[1564/1600] D loss: 1.4598, G loss: 0.8243\n",
      "train error: \n",
      " D loss: 1.055893, G loss: 1.295928, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272707, G loss: 1.505034, D accuracy: 61.9%, cell accuracy: 98.8%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4465, G loss: 0.7829\n",
      "[124/1600] D loss: 1.3655, G loss: 0.6605\n",
      "[244/1600] D loss: 0.7048, G loss: 2.4969\n",
      "[364/1600] D loss: 1.0609, G loss: 1.0002\n",
      "[484/1600] D loss: 0.7165, G loss: 2.5300\n",
      "[604/1600] D loss: 1.1738, G loss: 1.7250\n",
      "[724/1600] D loss: 0.9093, G loss: 1.9658\n",
      "[844/1600] D loss: 1.7592, G loss: 0.8538\n",
      "[964/1600] D loss: 0.5343, G loss: 2.0614\n",
      "[1084/1600] D loss: 0.9559, G loss: 1.8381\n",
      "[1204/1600] D loss: 0.9810, G loss: 1.3321\n",
      "[1324/1600] D loss: 1.5484, G loss: 0.5541\n",
      "[1444/1600] D loss: 1.0406, G loss: 2.2443\n",
      "[1564/1600] D loss: 1.0443, G loss: 1.3451\n",
      "train error: \n",
      " D loss: 1.093911, G loss: 1.150873, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 57.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301659, G loss: 1.315349, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4442, G loss: 0.5225\n",
      "[124/1600] D loss: 1.0359, G loss: 2.2049\n",
      "[244/1600] D loss: 0.9812, G loss: 1.9403\n",
      "[364/1600] D loss: 1.2149, G loss: 0.9223\n",
      "[484/1600] D loss: 0.5793, G loss: 2.7945\n",
      "[604/1600] D loss: 1.3810, G loss: 0.6655\n",
      "[724/1600] D loss: 1.2853, G loss: 0.7170\n",
      "[844/1600] D loss: 0.8596, G loss: 2.1476\n",
      "[964/1600] D loss: 1.1148, G loss: 1.2655\n",
      "[1084/1600] D loss: 1.1927, G loss: 1.0196\n",
      "[1204/1600] D loss: 1.0462, G loss: 1.0924\n",
      "[1324/1600] D loss: 1.3638, G loss: 0.6462\n",
      "[1444/1600] D loss: 1.0989, G loss: 2.1428\n",
      "[1564/1600] D loss: 1.4672, G loss: 0.6653\n",
      "train error: \n",
      " D loss: 1.045089, G loss: 1.633921, D accuracy: 66.1%, cell accuracy: 98.9%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322163, G loss: 1.839119, D accuracy: 61.3%, cell accuracy: 98.7%, board accuracy: 53.5% \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0375, G loss: 1.4469\n",
      "[124/1600] D loss: 1.5644, G loss: 1.1042\n",
      "[244/1600] D loss: 1.3996, G loss: 0.7547\n",
      "[364/1600] D loss: 1.1674, G loss: 1.3746\n",
      "[484/1600] D loss: 1.4218, G loss: 0.6084\n",
      "[604/1600] D loss: 1.5384, G loss: 0.8494\n",
      "[724/1600] D loss: 1.3476, G loss: 0.8698\n",
      "[844/1600] D loss: 1.4889, G loss: 0.4447\n",
      "[964/1600] D loss: 0.7501, G loss: 1.9863\n",
      "[1084/1600] D loss: 0.9349, G loss: 2.7271\n",
      "[1204/1600] D loss: 1.3947, G loss: 0.7552\n",
      "[1324/1600] D loss: 1.3727, G loss: 0.7184\n",
      "[1444/1600] D loss: 0.7883, G loss: 1.5429\n",
      "[1564/1600] D loss: 1.4675, G loss: 0.8953\n",
      "train error: \n",
      " D loss: 1.035755, G loss: 1.377415, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277770, G loss: 1.570971, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7176, G loss: 2.7255\n",
      "[124/1600] D loss: 1.2507, G loss: 0.9404\n",
      "[244/1600] D loss: 1.0407, G loss: 1.7112\n",
      "[364/1600] D loss: 0.3825, G loss: 2.7617\n",
      "[484/1600] D loss: 1.1144, G loss: 2.0194\n",
      "[604/1600] D loss: 1.2480, G loss: 0.7418\n",
      "[724/1600] D loss: 0.4092, G loss: 2.8402\n",
      "[844/1600] D loss: 0.2701, G loss: 3.0993\n",
      "[964/1600] D loss: 0.7176, G loss: 1.8601\n",
      "[1084/1600] D loss: 0.7235, G loss: 2.2783\n",
      "[1204/1600] D loss: 1.3701, G loss: 0.7481\n",
      "[1324/1600] D loss: 0.7514, G loss: 1.9141\n",
      "[1444/1600] D loss: 1.0511, G loss: 1.9588\n",
      "[1564/1600] D loss: 1.0551, G loss: 1.3381\n",
      "train error: \n",
      " D loss: 1.042994, G loss: 1.390493, D accuracy: 66.7%, cell accuracy: 98.9%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287096, G loss: 1.624400, D accuracy: 62.4%, cell accuracy: 98.7%, board accuracy: 53.8% \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4513, G loss: 0.5751\n",
      "[124/1600] D loss: 0.8014, G loss: 1.6471\n",
      "[244/1600] D loss: 1.4307, G loss: 0.5945\n",
      "[364/1600] D loss: 0.9113, G loss: 1.5740\n",
      "[484/1600] D loss: 0.7701, G loss: 1.5043\n",
      "[604/1600] D loss: 1.4084, G loss: 0.7052\n",
      "[724/1600] D loss: 1.4089, G loss: 0.8295\n",
      "[844/1600] D loss: 1.1803, G loss: 1.5536\n",
      "[964/1600] D loss: 2.3791, G loss: 0.5196\n",
      "[1084/1600] D loss: 0.9458, G loss: 2.0284\n",
      "[1204/1600] D loss: 1.1083, G loss: 1.7568\n",
      "[1324/1600] D loss: 1.2533, G loss: 1.0282\n",
      "[1444/1600] D loss: 0.4921, G loss: 2.4078\n",
      "[1564/1600] D loss: 0.8057, G loss: 1.1575\n",
      "train error: \n",
      " D loss: 1.036223, G loss: 1.407120, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277148, G loss: 1.642235, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 52.2% \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4090, G loss: 0.6652\n",
      "[124/1600] D loss: 1.1344, G loss: 1.3997\n",
      "[244/1600] D loss: 1.4301, G loss: 1.0182\n",
      "[364/1600] D loss: 0.9867, G loss: 1.1958\n",
      "[484/1600] D loss: 1.0843, G loss: 1.3900\n",
      "[604/1600] D loss: 1.1114, G loss: 1.3376\n",
      "[724/1600] D loss: 0.7621, G loss: 1.7944\n",
      "[844/1600] D loss: 1.1021, G loss: 1.1198\n",
      "[964/1600] D loss: 0.4108, G loss: 2.4697\n",
      "[1084/1600] D loss: 0.9144, G loss: 1.4600\n",
      "[1204/1600] D loss: 0.7391, G loss: 2.3773\n",
      "[1324/1600] D loss: 0.8989, G loss: 1.8661\n",
      "[1444/1600] D loss: 0.7795, G loss: 1.4436\n",
      "[1564/1600] D loss: 0.9570, G loss: 1.5736\n",
      "train error: \n",
      " D loss: 1.038654, G loss: 1.504327, D accuracy: 66.7%, cell accuracy: 98.9%, board accuracy: 57.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282586, G loss: 1.739796, D accuracy: 62.3%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3761, G loss: 2.8514\n",
      "[124/1600] D loss: 0.8624, G loss: 1.7423\n",
      "[244/1600] D loss: 0.4294, G loss: 2.9157\n",
      "[364/1600] D loss: 1.3159, G loss: 0.7585\n",
      "[484/1600] D loss: 0.3559, G loss: 3.8973\n",
      "[604/1600] D loss: 0.9250, G loss: 1.5338\n",
      "[724/1600] D loss: 1.4094, G loss: 0.7903\n",
      "[844/1600] D loss: 1.5282, G loss: 0.4731\n",
      "[964/1600] D loss: 1.0408, G loss: 1.7543\n",
      "[1084/1600] D loss: 0.4130, G loss: 2.2523\n",
      "[1204/1600] D loss: 0.5090, G loss: 2.9063\n",
      "[1324/1600] D loss: 1.3811, G loss: 0.7734\n",
      "[1444/1600] D loss: 0.0368, G loss: 3.4700\n",
      "[1564/1600] D loss: 0.4440, G loss: 2.7259\n",
      "train error: \n",
      " D loss: 1.047110, G loss: 1.259515, D accuracy: 66.6%, cell accuracy: 98.9%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269733, G loss: 1.463135, D accuracy: 62.1%, cell accuracy: 98.7%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0980, G loss: 1.6471\n",
      "[124/1600] D loss: 1.5751, G loss: 1.2090\n",
      "[244/1600] D loss: 0.8802, G loss: 2.1671\n",
      "[364/1600] D loss: 1.1788, G loss: 1.4309\n",
      "[484/1600] D loss: 0.4629, G loss: 2.1898\n",
      "[604/1600] D loss: 1.9364, G loss: 1.4629\n",
      "[724/1600] D loss: 0.7065, G loss: 2.1170\n",
      "[844/1600] D loss: 1.4225, G loss: 0.6872\n",
      "[964/1600] D loss: 1.1071, G loss: 1.0239\n",
      "[1084/1600] D loss: 0.3787, G loss: 3.1259\n",
      "[1204/1600] D loss: 1.0576, G loss: 1.5184\n",
      "[1324/1600] D loss: 0.7538, G loss: 1.8252\n",
      "[1444/1600] D loss: 0.8564, G loss: 1.6228\n",
      "[1564/1600] D loss: 0.9195, G loss: 1.9119\n",
      "train error: \n",
      " D loss: 1.031946, G loss: 1.438075, D accuracy: 66.8%, cell accuracy: 98.9%, board accuracy: 60.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304048, G loss: 1.644450, D accuracy: 62.0%, cell accuracy: 98.7%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7380, G loss: 1.9902\n",
      "[124/1600] D loss: 1.5615, G loss: 0.5321\n",
      "[244/1600] D loss: 0.9567, G loss: 1.1466\n",
      "[364/1600] D loss: 1.2193, G loss: 1.6701\n",
      "[484/1600] D loss: 1.3563, G loss: 0.9586\n",
      "[604/1600] D loss: 1.1398, G loss: 1.8940\n",
      "[724/1600] D loss: 1.1217, G loss: 1.6632\n",
      "[844/1600] D loss: 0.7478, G loss: 3.2697\n",
      "[964/1600] D loss: 1.0206, G loss: 1.1432\n",
      "[1084/1600] D loss: 0.7881, G loss: 1.3935\n",
      "[1204/1600] D loss: 1.1324, G loss: 1.8241\n",
      "[1324/1600] D loss: 1.2320, G loss: 0.8700\n",
      "[1444/1600] D loss: 0.7414, G loss: 2.2329\n",
      "[1564/1600] D loss: 1.4139, G loss: 0.7202\n",
      "train error: \n",
      " D loss: 1.029887, G loss: 1.455500, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282005, G loss: 1.687054, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2329, G loss: 0.8112\n",
      "[124/1600] D loss: 1.0498, G loss: 1.3450\n",
      "[244/1600] D loss: 1.4563, G loss: 0.7498\n",
      "[364/1600] D loss: 1.0822, G loss: 1.2984\n",
      "[484/1600] D loss: 0.8337, G loss: 3.0787\n",
      "[604/1600] D loss: 1.0723, G loss: 0.9514\n",
      "[724/1600] D loss: 1.0947, G loss: 1.4347\n",
      "[844/1600] D loss: 1.1025, G loss: 1.3596\n",
      "[964/1600] D loss: 0.7736, G loss: 1.3565\n",
      "[1084/1600] D loss: 1.5023, G loss: 0.4198\n",
      "[1204/1600] D loss: 1.1200, G loss: 1.0374\n",
      "[1324/1600] D loss: 1.0933, G loss: 1.3677\n",
      "[1444/1600] D loss: 1.1351, G loss: 0.9934\n",
      "[1564/1600] D loss: 0.6826, G loss: 2.6666\n",
      "train error: \n",
      " D loss: 1.064874, G loss: 1.350711, D accuracy: 66.0%, cell accuracy: 98.9%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289097, G loss: 1.561894, D accuracy: 63.0%, cell accuracy: 98.7%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7762, G loss: 1.9296\n",
      "[124/1600] D loss: 1.0670, G loss: 1.6128\n",
      "[244/1600] D loss: 1.4552, G loss: 0.5997\n",
      "[364/1600] D loss: 1.0461, G loss: 2.1662\n",
      "[484/1600] D loss: 0.7473, G loss: 1.4314\n",
      "[604/1600] D loss: 1.3912, G loss: 1.0332\n",
      "[724/1600] D loss: 1.3367, G loss: 0.7303\n",
      "[844/1600] D loss: 1.1017, G loss: 1.3454\n",
      "[964/1600] D loss: 0.8191, G loss: 1.9111\n",
      "[1084/1600] D loss: 1.0362, G loss: 1.3681\n",
      "[1204/1600] D loss: 0.7869, G loss: 2.4867\n",
      "[1324/1600] D loss: 0.8859, G loss: 1.7678\n",
      "[1444/1600] D loss: 0.9202, G loss: 1.5031\n",
      "[1564/1600] D loss: 1.0614, G loss: 1.3558\n",
      "train error: \n",
      " D loss: 1.036852, G loss: 1.581191, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296244, G loss: 1.792475, D accuracy: 61.1%, cell accuracy: 98.8%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7527, G loss: 1.9901\n",
      "[124/1600] D loss: 1.0512, G loss: 1.4678\n",
      "[244/1600] D loss: 1.3634, G loss: 0.8066\n",
      "[364/1600] D loss: 0.5296, G loss: 2.3352\n",
      "[484/1600] D loss: 1.0500, G loss: 1.7630\n",
      "[604/1600] D loss: 1.0673, G loss: 1.3852\n",
      "[724/1600] D loss: 1.4404, G loss: 1.0437\n",
      "[844/1600] D loss: 0.5441, G loss: 2.9893\n",
      "[964/1600] D loss: 0.7246, G loss: 1.8287\n",
      "[1084/1600] D loss: 1.2223, G loss: 1.1313\n",
      "[1204/1600] D loss: 1.1992, G loss: 1.1851\n",
      "[1324/1600] D loss: 1.0720, G loss: 1.1897\n",
      "[1444/1600] D loss: 1.0185, G loss: 1.7486\n",
      "[1564/1600] D loss: 0.8729, G loss: 1.5792\n",
      "train error: \n",
      " D loss: 1.036675, G loss: 1.410709, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322580, G loss: 1.618571, D accuracy: 61.6%, cell accuracy: 98.8%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3081, G loss: 0.7708\n",
      "[124/1600] D loss: 1.1400, G loss: 1.1786\n",
      "[244/1600] D loss: 1.0467, G loss: 1.8552\n",
      "[364/1600] D loss: 0.9458, G loss: 1.3085\n",
      "[484/1600] D loss: 1.1358, G loss: 1.4620\n",
      "[604/1600] D loss: 0.7960, G loss: 2.0812\n",
      "[724/1600] D loss: 1.0343, G loss: 1.7511\n",
      "[844/1600] D loss: 1.0624, G loss: 1.1175\n",
      "[964/1600] D loss: 1.2164, G loss: 1.1450\n",
      "[1084/1600] D loss: 1.0546, G loss: 1.8935\n",
      "[1204/1600] D loss: 0.9928, G loss: 1.3021\n",
      "[1324/1600] D loss: 0.8205, G loss: 1.5475\n",
      "[1444/1600] D loss: 1.4530, G loss: 0.5460\n",
      "[1564/1600] D loss: 1.3694, G loss: 0.8479\n",
      "train error: \n",
      " D loss: 1.038217, G loss: 1.395166, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 58.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280773, G loss: 1.628033, D accuracy: 62.7%, cell accuracy: 98.8%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0472, G loss: 0.9831\n",
      "[124/1600] D loss: 1.5116, G loss: 0.5441\n",
      "[244/1600] D loss: 1.4283, G loss: 0.5720\n",
      "[364/1600] D loss: 1.2492, G loss: 0.9672\n",
      "[484/1600] D loss: 1.1469, G loss: 0.8196\n",
      "[604/1600] D loss: 1.2254, G loss: 1.0201\n",
      "[724/1600] D loss: 0.7308, G loss: 2.3358\n",
      "[844/1600] D loss: 1.3363, G loss: 0.7662\n",
      "[964/1600] D loss: 0.7150, G loss: 2.9021\n",
      "[1084/1600] D loss: 0.7688, G loss: 2.4352\n",
      "[1204/1600] D loss: 1.0773, G loss: 1.3372\n",
      "[1324/1600] D loss: 1.4610, G loss: 0.5252\n",
      "[1444/1600] D loss: 0.9964, G loss: 1.8236\n",
      "[1564/1600] D loss: 1.1133, G loss: 1.2907\n",
      "train error: \n",
      " D loss: 1.039412, G loss: 1.405769, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 60.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304632, G loss: 1.615035, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3280, G loss: 0.5921\n",
      "[124/1600] D loss: 1.0316, G loss: 1.9709\n",
      "[244/1600] D loss: 0.9673, G loss: 0.8623\n",
      "[364/1600] D loss: 0.9098, G loss: 1.3813\n",
      "[484/1600] D loss: 1.1396, G loss: 0.9393\n",
      "[604/1600] D loss: 1.0810, G loss: 3.3552\n",
      "[724/1600] D loss: 1.1057, G loss: 0.9559\n",
      "[844/1600] D loss: 1.2030, G loss: 0.9583\n",
      "[964/1600] D loss: 0.4365, G loss: 2.3937\n",
      "[1084/1600] D loss: 1.2159, G loss: 1.2452\n",
      "[1204/1600] D loss: 1.2690, G loss: 0.7923\n",
      "[1324/1600] D loss: 0.9727, G loss: 1.7424\n",
      "[1444/1600] D loss: 1.2415, G loss: 0.8660\n",
      "[1564/1600] D loss: 0.7514, G loss: 2.0384\n",
      "train error: \n",
      " D loss: 1.042279, G loss: 1.402314, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 58.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283427, G loss: 1.611041, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3193, G loss: 0.6995\n",
      "[124/1600] D loss: 0.3127, G loss: 2.8698\n",
      "[244/1600] D loss: 1.4917, G loss: 0.7502\n",
      "[364/1600] D loss: 1.0490, G loss: 1.4138\n",
      "[484/1600] D loss: 1.3994, G loss: 0.7942\n",
      "[604/1600] D loss: 0.7523, G loss: 1.7719\n",
      "[724/1600] D loss: 0.5716, G loss: 1.7775\n",
      "[844/1600] D loss: 1.3941, G loss: 0.6501\n",
      "[964/1600] D loss: 1.0914, G loss: 1.4580\n",
      "[1084/1600] D loss: 1.1638, G loss: 1.7190\n",
      "[1204/1600] D loss: 0.8261, G loss: 1.5483\n",
      "[1324/1600] D loss: 1.1348, G loss: 0.8953\n",
      "[1444/1600] D loss: 1.1843, G loss: 2.0222\n",
      "[1564/1600] D loss: 0.7218, G loss: 2.9632\n",
      "train error: \n",
      " D loss: 1.062238, G loss: 1.291351, D accuracy: 65.6%, cell accuracy: 99.0%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266216, G loss: 1.515984, D accuracy: 63.1%, cell accuracy: 98.8%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7073, G loss: 2.4215\n",
      "[124/1600] D loss: 0.6983, G loss: 2.6149\n",
      "[244/1600] D loss: 1.4192, G loss: 0.6487\n",
      "[364/1600] D loss: 1.0414, G loss: 1.4827\n",
      "[484/1600] D loss: 0.7473, G loss: 2.7056\n",
      "[604/1600] D loss: 0.8299, G loss: 1.7282\n",
      "[724/1600] D loss: 0.6854, G loss: 2.0417\n",
      "[844/1600] D loss: 1.4601, G loss: 0.8599\n",
      "[964/1600] D loss: 1.0704, G loss: 1.5409\n",
      "[1084/1600] D loss: 1.4209, G loss: 0.5682\n",
      "[1204/1600] D loss: 0.8394, G loss: 3.9512\n",
      "[1324/1600] D loss: 0.4745, G loss: 2.6829\n",
      "[1444/1600] D loss: 1.4403, G loss: 0.6648\n",
      "[1564/1600] D loss: 0.9063, G loss: 1.2053\n",
      "train error: \n",
      " D loss: 1.033606, G loss: 1.740912, D accuracy: 67.0%, cell accuracy: 98.9%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337391, G loss: 1.960597, D accuracy: 61.8%, cell accuracy: 98.7%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7011, G loss: 1.9904\n",
      "[124/1600] D loss: 1.0064, G loss: 1.2455\n",
      "[244/1600] D loss: 0.2103, G loss: 2.5628\n",
      "[364/1600] D loss: 0.0228, G loss: 4.0233\n",
      "[484/1600] D loss: 1.1767, G loss: 1.0842\n",
      "[604/1600] D loss: 0.7738, G loss: 2.1109\n",
      "[724/1600] D loss: 1.3874, G loss: 0.7029\n",
      "[844/1600] D loss: 0.5822, G loss: 1.5499\n",
      "[964/1600] D loss: 1.1452, G loss: 1.0784\n",
      "[1084/1600] D loss: 1.1704, G loss: 1.8714\n",
      "[1204/1600] D loss: 1.1000, G loss: 1.3849\n",
      "[1324/1600] D loss: 1.1998, G loss: 0.9316\n",
      "[1444/1600] D loss: 1.0544, G loss: 1.4862\n",
      "[1564/1600] D loss: 1.0098, G loss: 1.5528\n",
      "train error: \n",
      " D loss: 1.038260, G loss: 1.565090, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314271, G loss: 1.821846, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9646, G loss: 1.6017\n",
      "[124/1600] D loss: 1.0890, G loss: 0.8639\n",
      "[244/1600] D loss: 0.7789, G loss: 1.8183\n",
      "[364/1600] D loss: 0.9630, G loss: 1.5055\n",
      "[484/1600] D loss: 0.7043, G loss: 2.2594\n",
      "[604/1600] D loss: 1.0955, G loss: 1.2024\n",
      "[724/1600] D loss: 1.0992, G loss: 1.1941\n",
      "[844/1600] D loss: 0.4639, G loss: 2.3613\n",
      "[964/1600] D loss: 1.4146, G loss: 0.9949\n",
      "[1084/1600] D loss: 1.1131, G loss: 1.7217\n",
      "[1204/1600] D loss: 1.5682, G loss: 1.1917\n",
      "[1324/1600] D loss: 1.4758, G loss: 1.2084\n",
      "[1444/1600] D loss: 1.0735, G loss: 1.0393\n",
      "[1564/1600] D loss: 1.3640, G loss: 0.6704\n",
      "train error: \n",
      " D loss: 1.025304, G loss: 1.561367, D accuracy: 65.8%, cell accuracy: 98.9%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315696, G loss: 1.766575, D accuracy: 63.0%, cell accuracy: 98.7%, board accuracy: 54.5% \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1270, G loss: 0.9397\n",
      "[124/1600] D loss: 0.9129, G loss: 1.4236\n",
      "[244/1600] D loss: 0.3936, G loss: 2.3884\n",
      "[364/1600] D loss: 1.1073, G loss: 1.0907\n",
      "[484/1600] D loss: 1.2096, G loss: 0.8768\n",
      "[604/1600] D loss: 0.7889, G loss: 1.8333\n",
      "[724/1600] D loss: 1.0308, G loss: 1.6218\n",
      "[844/1600] D loss: 1.0550, G loss: 1.3487\n",
      "[964/1600] D loss: 0.7946, G loss: 2.0944\n",
      "[1084/1600] D loss: 0.9365, G loss: 1.1208\n",
      "[1204/1600] D loss: 0.7085, G loss: 2.9940\n",
      "[1324/1600] D loss: 0.7195, G loss: 2.5724\n",
      "[1444/1600] D loss: 1.4839, G loss: 0.5344\n",
      "[1564/1600] D loss: 1.0406, G loss: 1.0919\n",
      "train error: \n",
      " D loss: 1.017556, G loss: 1.583044, D accuracy: 67.2%, cell accuracy: 98.9%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317022, G loss: 1.777369, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 54.2% \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1430, G loss: 1.5364\n",
      "[124/1600] D loss: 1.0464, G loss: 2.2300\n",
      "[244/1600] D loss: 1.0674, G loss: 1.3990\n",
      "[364/1600] D loss: 0.8371, G loss: 1.8372\n",
      "[484/1600] D loss: 1.2062, G loss: 0.8570\n",
      "[604/1600] D loss: 0.8317, G loss: 1.9892\n",
      "[724/1600] D loss: 0.8522, G loss: 1.8353\n",
      "[844/1600] D loss: 1.2806, G loss: 0.6778\n",
      "[964/1600] D loss: 0.7697, G loss: 2.1643\n",
      "[1084/1600] D loss: 0.8306, G loss: 2.3827\n",
      "[1204/1600] D loss: 1.4571, G loss: 0.9154\n",
      "[1324/1600] D loss: 1.0599, G loss: 2.3270\n",
      "[1444/1600] D loss: 1.3328, G loss: 0.6031\n",
      "[1564/1600] D loss: 1.2193, G loss: 1.8636\n",
      "train error: \n",
      " D loss: 1.015907, G loss: 1.464541, D accuracy: 67.2%, cell accuracy: 98.9%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268624, G loss: 1.688127, D accuracy: 63.2%, cell accuracy: 98.7%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5304, G loss: 0.6912\n",
      "[124/1600] D loss: 1.4146, G loss: 0.7758\n",
      "[244/1600] D loss: 0.4102, G loss: 2.7528\n",
      "[364/1600] D loss: 1.0716, G loss: 1.4913\n",
      "[484/1600] D loss: 1.4273, G loss: 0.8687\n",
      "[604/1600] D loss: 1.1108, G loss: 0.8153\n",
      "[724/1600] D loss: 0.8153, G loss: 1.4558\n",
      "[844/1600] D loss: 1.3250, G loss: 0.8990\n",
      "[964/1600] D loss: 1.0680, G loss: 1.3267\n",
      "[1084/1600] D loss: 0.7737, G loss: 1.9350\n",
      "[1204/1600] D loss: 1.1026, G loss: 1.3890\n",
      "[1324/1600] D loss: 0.8092, G loss: 1.7938\n",
      "[1444/1600] D loss: 1.3804, G loss: 0.7450\n",
      "[1564/1600] D loss: 1.3908, G loss: 0.7025\n",
      "train error: \n",
      " D loss: 1.071426, G loss: 1.268177, D accuracy: 65.8%, cell accuracy: 99.0%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283604, G loss: 1.512969, D accuracy: 63.1%, cell accuracy: 98.8%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0912, G loss: 4.8628\n",
      "[124/1600] D loss: 0.7645, G loss: 1.8381\n",
      "[244/1600] D loss: 0.9600, G loss: 1.5603\n",
      "[364/1600] D loss: 1.0863, G loss: 1.3115\n",
      "[484/1600] D loss: 1.0862, G loss: 1.5438\n",
      "[604/1600] D loss: 1.0638, G loss: 1.4820\n",
      "[724/1600] D loss: 1.0543, G loss: 1.4264\n",
      "[844/1600] D loss: 1.0930, G loss: 2.0447\n",
      "[964/1600] D loss: 1.0395, G loss: 2.0787\n",
      "[1084/1600] D loss: 0.9065, G loss: 1.2688\n",
      "[1204/1600] D loss: 0.8270, G loss: 2.4541\n",
      "[1324/1600] D loss: 1.1486, G loss: 0.8861\n",
      "[1444/1600] D loss: 1.0503, G loss: 1.9430\n",
      "[1564/1600] D loss: 1.0945, G loss: 1.8256\n",
      "train error: \n",
      " D loss: 1.136485, G loss: 1.173242, D accuracy: 64.7%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302258, G loss: 1.387921, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5292, G loss: 0.9107\n",
      "[124/1600] D loss: 0.7446, G loss: 2.3751\n",
      "[244/1600] D loss: 0.9921, G loss: 1.0908\n",
      "[364/1600] D loss: 0.3837, G loss: 2.6112\n",
      "[484/1600] D loss: 1.2994, G loss: 1.8068\n",
      "[604/1600] D loss: 1.0818, G loss: 1.0255\n",
      "[724/1600] D loss: 1.1296, G loss: 1.3873\n",
      "[844/1600] D loss: 1.2866, G loss: 0.9274\n",
      "[964/1600] D loss: 1.1929, G loss: 2.1437\n",
      "[1084/1600] D loss: 1.3857, G loss: 0.7301\n",
      "[1204/1600] D loss: 1.0894, G loss: 0.9502\n",
      "[1324/1600] D loss: 0.9394, G loss: 1.0425\n",
      "[1444/1600] D loss: 0.9402, G loss: 1.1036\n",
      "[1564/1600] D loss: 0.7067, G loss: 2.2663\n",
      "train error: \n",
      " D loss: 1.022297, G loss: 1.361484, D accuracy: 67.3%, cell accuracy: 99.0%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287606, G loss: 1.543145, D accuracy: 61.6%, cell accuracy: 98.8%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9138, G loss: 1.7498\n",
      "[124/1600] D loss: 1.3316, G loss: 0.9696\n",
      "[244/1600] D loss: 1.1926, G loss: 0.7923\n",
      "[364/1600] D loss: 1.3568, G loss: 0.8509\n",
      "[484/1600] D loss: 1.1211, G loss: 1.0943\n",
      "[604/1600] D loss: 0.7579, G loss: 3.1044\n",
      "[724/1600] D loss: 0.9962, G loss: 1.8641\n",
      "[844/1600] D loss: 0.7312, G loss: 2.5007\n",
      "[964/1600] D loss: 1.4551, G loss: 0.8222\n",
      "[1084/1600] D loss: 0.7146, G loss: 2.2677\n",
      "[1204/1600] D loss: 0.4209, G loss: 2.5026\n",
      "[1324/1600] D loss: 1.3760, G loss: 0.6895\n",
      "[1444/1600] D loss: 1.2222, G loss: 0.9620\n",
      "[1564/1600] D loss: 0.7549, G loss: 1.8410\n",
      "train error: \n",
      " D loss: 1.039859, G loss: 1.673843, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 61.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317385, G loss: 1.896783, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4422, G loss: 3.0178\n",
      "[124/1600] D loss: 0.6916, G loss: 2.0055\n",
      "[244/1600] D loss: 0.4915, G loss: 2.1259\n",
      "[364/1600] D loss: 1.3945, G loss: 0.5992\n",
      "[484/1600] D loss: 1.3298, G loss: 1.3918\n",
      "[604/1600] D loss: 1.1313, G loss: 2.2234\n",
      "[724/1600] D loss: 1.3667, G loss: 0.9108\n",
      "[844/1600] D loss: 0.6140, G loss: 2.3345\n",
      "[964/1600] D loss: 1.0644, G loss: 2.0778\n",
      "[1084/1600] D loss: 1.0222, G loss: 2.3427\n",
      "[1204/1600] D loss: 0.9790, G loss: 1.9486\n",
      "[1324/1600] D loss: 0.7858, G loss: 1.8389\n",
      "[1444/1600] D loss: 1.3038, G loss: 0.7434\n",
      "[1564/1600] D loss: 1.0673, G loss: 1.2576\n",
      "train error: \n",
      " D loss: 1.034200, G loss: 1.588095, D accuracy: 66.2%, cell accuracy: 98.9%, board accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335256, G loss: 1.814925, D accuracy: 61.5%, cell accuracy: 98.7%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0293, G loss: 1.8739\n",
      "[124/1600] D loss: 1.1914, G loss: 1.0514\n",
      "[244/1600] D loss: 1.4431, G loss: 0.8046\n",
      "[364/1600] D loss: 1.4185, G loss: 1.1066\n",
      "[484/1600] D loss: 1.0542, G loss: 1.1055\n",
      "[604/1600] D loss: 1.0244, G loss: 2.0967\n",
      "[724/1600] D loss: 1.1147, G loss: 0.9706\n",
      "[844/1600] D loss: 0.7969, G loss: 1.6794\n",
      "[964/1600] D loss: 1.0517, G loss: 1.6158\n",
      "[1084/1600] D loss: 0.4303, G loss: 2.6759\n",
      "[1204/1600] D loss: 0.3602, G loss: 3.8480\n",
      "[1324/1600] D loss: 0.8330, G loss: 1.1621\n",
      "[1444/1600] D loss: 1.2051, G loss: 0.9594\n",
      "[1564/1600] D loss: 1.1346, G loss: 1.2975\n",
      "train error: \n",
      " D loss: 1.029753, G loss: 1.363904, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 60.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264297, G loss: 1.568549, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3955, G loss: 0.6348\n",
      "[124/1600] D loss: 1.1482, G loss: 1.1782\n",
      "[244/1600] D loss: 1.0176, G loss: 1.1919\n",
      "[364/1600] D loss: 0.3831, G loss: 3.2347\n",
      "[484/1600] D loss: 1.0677, G loss: 1.4878\n",
      "[604/1600] D loss: 1.3366, G loss: 0.8266\n",
      "[724/1600] D loss: 1.1484, G loss: 1.8649\n",
      "[844/1600] D loss: 1.3607, G loss: 0.8258\n",
      "[964/1600] D loss: 0.8448, G loss: 1.6476\n",
      "[1084/1600] D loss: 0.8371, G loss: 1.5453\n",
      "[1204/1600] D loss: 0.5725, G loss: 2.4527\n",
      "[1324/1600] D loss: 1.0596, G loss: 1.8286\n",
      "[1444/1600] D loss: 0.8186, G loss: 2.0187\n",
      "[1564/1600] D loss: 1.0117, G loss: 1.7045\n",
      "train error: \n",
      " D loss: 1.014508, G loss: 1.557617, D accuracy: 67.1%, cell accuracy: 99.0%, board accuracy: 60.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299351, G loss: 1.768455, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8872, G loss: 1.8654\n",
      "[124/1600] D loss: 0.7001, G loss: 2.6052\n",
      "[244/1600] D loss: 1.2768, G loss: 0.6123\n",
      "[364/1600] D loss: 0.9605, G loss: 1.9132\n",
      "[484/1600] D loss: 1.2975, G loss: 0.6989\n",
      "[604/1600] D loss: 0.8187, G loss: 2.1674\n",
      "[724/1600] D loss: 0.0274, G loss: 3.9809\n",
      "[844/1600] D loss: 0.7129, G loss: 2.5070\n",
      "[964/1600] D loss: 1.4100, G loss: 0.6018\n",
      "[1084/1600] D loss: 1.1325, G loss: 1.9594\n",
      "[1204/1600] D loss: 1.3967, G loss: 0.8188\n",
      "[1324/1600] D loss: 1.0195, G loss: 1.9107\n",
      "[1444/1600] D loss: 1.0675, G loss: 1.4057\n",
      "[1564/1600] D loss: 1.4424, G loss: 0.5865\n",
      "train error: \n",
      " D loss: 1.019151, G loss: 1.539133, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 62.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297605, G loss: 1.726825, D accuracy: 61.8%, cell accuracy: 98.8%, board accuracy: 57.8% \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7688, G loss: 2.0429\n",
      "[124/1600] D loss: 1.3854, G loss: 0.7079\n",
      "[244/1600] D loss: 0.8093, G loss: 1.3478\n",
      "[364/1600] D loss: 1.0560, G loss: 1.5626\n",
      "[484/1600] D loss: 1.0325, G loss: 1.6710\n",
      "[604/1600] D loss: 1.0398, G loss: 1.3489\n",
      "[724/1600] D loss: 1.3567, G loss: 0.6443\n",
      "[844/1600] D loss: 1.0401, G loss: 1.4374\n",
      "[964/1600] D loss: 1.5340, G loss: 0.6468\n",
      "[1084/1600] D loss: 0.3531, G loss: 4.2153\n",
      "[1204/1600] D loss: 0.5012, G loss: 2.3361\n",
      "[1324/1600] D loss: 1.4077, G loss: 0.6576\n",
      "[1444/1600] D loss: 1.0472, G loss: 1.1904\n",
      "[1564/1600] D loss: 1.5478, G loss: 0.6090\n",
      "train error: \n",
      " D loss: 1.030714, G loss: 1.383176, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 61.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302623, G loss: 1.588607, D accuracy: 61.5%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5368, G loss: 2.1594\n",
      "[124/1600] D loss: 1.3829, G loss: 0.7774\n",
      "[244/1600] D loss: 0.9306, G loss: 1.2918\n",
      "[364/1600] D loss: 0.8703, G loss: 2.0196\n",
      "[484/1600] D loss: 0.9029, G loss: 1.8828\n",
      "[604/1600] D loss: 1.1762, G loss: 1.2581\n",
      "[724/1600] D loss: 0.8654, G loss: 1.7391\n",
      "[844/1600] D loss: 0.8169, G loss: 1.8118\n",
      "[964/1600] D loss: 1.1360, G loss: 0.9076\n",
      "[1084/1600] D loss: 1.1427, G loss: 0.8455\n",
      "[1204/1600] D loss: 1.2870, G loss: 0.5765\n",
      "[1324/1600] D loss: 1.0857, G loss: 1.4051\n",
      "[1444/1600] D loss: 0.9805, G loss: 1.8488\n",
      "[1564/1600] D loss: 1.0750, G loss: 1.4684\n",
      "train error: \n",
      " D loss: 1.008487, G loss: 1.588168, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291478, G loss: 1.748386, D accuracy: 62.4%, cell accuracy: 98.9%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0602, G loss: 1.7269\n",
      "[124/1600] D loss: 0.4675, G loss: 2.1528\n",
      "[244/1600] D loss: 1.1792, G loss: 0.9866\n",
      "[364/1600] D loss: 1.0577, G loss: 1.1944\n",
      "[484/1600] D loss: 1.4119, G loss: 0.6315\n",
      "[604/1600] D loss: 1.1005, G loss: 1.2567\n",
      "[724/1600] D loss: 0.6242, G loss: 2.7606\n",
      "[844/1600] D loss: 1.0977, G loss: 1.8247\n",
      "[964/1600] D loss: 1.3662, G loss: 0.7401\n",
      "[1084/1600] D loss: 1.4674, G loss: 0.8200\n",
      "[1204/1600] D loss: 1.4621, G loss: 0.8616\n",
      "[1324/1600] D loss: 1.5097, G loss: 0.5560\n",
      "[1444/1600] D loss: 1.5277, G loss: 0.4342\n",
      "[1564/1600] D loss: 0.4189, G loss: 2.7634\n",
      "train error: \n",
      " D loss: 1.015715, G loss: 1.496635, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296794, G loss: 1.671559, D accuracy: 62.4%, cell accuracy: 98.9%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7545, G loss: 1.5610\n",
      "[124/1600] D loss: 1.0563, G loss: 1.9019\n",
      "[244/1600] D loss: 1.3570, G loss: 0.6241\n",
      "[364/1600] D loss: 1.0754, G loss: 1.1497\n",
      "[484/1600] D loss: 0.6665, G loss: 1.2735\n",
      "[604/1600] D loss: 1.0865, G loss: 2.0810\n",
      "[724/1600] D loss: 0.9746, G loss: 1.3393\n",
      "[844/1600] D loss: 0.9905, G loss: 1.8968\n",
      "[964/1600] D loss: 1.1813, G loss: 0.8823\n",
      "[1084/1600] D loss: 1.0489, G loss: 1.2703\n",
      "[1204/1600] D loss: 1.4311, G loss: 0.8932\n",
      "[1324/1600] D loss: 0.7113, G loss: 2.3877\n",
      "[1444/1600] D loss: 1.0597, G loss: 2.0522\n",
      "[1564/1600] D loss: 0.6129, G loss: 2.3930\n",
      "train error: \n",
      " D loss: 1.017531, G loss: 1.529172, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324037, G loss: 1.713724, D accuracy: 61.4%, cell accuracy: 98.8%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9203, G loss: 1.5380\n",
      "[124/1600] D loss: 0.8413, G loss: 2.0612\n",
      "[244/1600] D loss: 1.3890, G loss: 0.6699\n",
      "[364/1600] D loss: 1.0888, G loss: 2.2625\n",
      "[484/1600] D loss: 1.0480, G loss: 1.2512\n",
      "[604/1600] D loss: 1.1198, G loss: 1.1914\n",
      "[724/1600] D loss: 1.0478, G loss: 1.3936\n",
      "[844/1600] D loss: 0.3859, G loss: 2.4861\n",
      "[964/1600] D loss: 1.2233, G loss: 0.6692\n",
      "[1084/1600] D loss: 0.7522, G loss: 1.7835\n",
      "[1204/1600] D loss: 0.8948, G loss: 1.4808\n",
      "[1324/1600] D loss: 1.0237, G loss: 1.7630\n",
      "[1444/1600] D loss: 1.0472, G loss: 1.1928\n",
      "[1564/1600] D loss: 1.3943, G loss: 0.6378\n",
      "train error: \n",
      " D loss: 1.038002, G loss: 1.717160, D accuracy: 65.7%, cell accuracy: 99.0%, board accuracy: 62.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368385, G loss: 1.905828, D accuracy: 61.1%, cell accuracy: 98.9%, board accuracy: 58.8% \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0626, G loss: 1.8174\n",
      "[124/1600] D loss: 1.1546, G loss: 1.4842\n",
      "[244/1600] D loss: 1.1247, G loss: 1.3332\n",
      "[364/1600] D loss: 0.9060, G loss: 1.1955\n",
      "[484/1600] D loss: 1.3989, G loss: 0.7637\n",
      "[604/1600] D loss: 0.7181, G loss: 2.4388\n",
      "[724/1600] D loss: 0.9282, G loss: 1.2893\n",
      "[844/1600] D loss: 0.7427, G loss: 2.2762\n",
      "[964/1600] D loss: 0.8002, G loss: 1.7194\n",
      "[1084/1600] D loss: 1.3407, G loss: 0.6661\n",
      "[1204/1600] D loss: 1.4234, G loss: 0.6917\n",
      "[1324/1600] D loss: 1.3948, G loss: 0.6769\n",
      "[1444/1600] D loss: 1.4348, G loss: 0.6237\n",
      "[1564/1600] D loss: 1.4044, G loss: 0.7470\n",
      "train error: \n",
      " D loss: 1.020684, G loss: 1.560929, D accuracy: 67.1%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333334, G loss: 1.728671, D accuracy: 61.0%, cell accuracy: 98.8%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4051, G loss: 0.7491\n",
      "[124/1600] D loss: 1.0644, G loss: 1.4872\n",
      "[244/1600] D loss: 0.8953, G loss: 1.7517\n",
      "[364/1600] D loss: 0.8081, G loss: 1.7532\n",
      "[484/1600] D loss: 0.7665, G loss: 2.9545\n",
      "[604/1600] D loss: 0.7407, G loss: 2.3447\n",
      "[724/1600] D loss: 0.8028, G loss: 2.9093\n",
      "[844/1600] D loss: 1.0621, G loss: 1.6238\n",
      "[964/1600] D loss: 0.9444, G loss: 1.5693\n",
      "[1084/1600] D loss: 1.3989, G loss: 0.7081\n",
      "[1204/1600] D loss: 0.7085, G loss: 2.7802\n",
      "[1324/1600] D loss: 0.7425, G loss: 2.7068\n",
      "[1444/1600] D loss: 0.9988, G loss: 1.8323\n",
      "[1564/1600] D loss: 1.4468, G loss: 0.7668\n",
      "train error: \n",
      " D loss: 1.022041, G loss: 1.383041, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 61.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294039, G loss: 1.597554, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1863, G loss: 3.3260\n",
      "[124/1600] D loss: 1.4843, G loss: 0.4904\n",
      "[244/1600] D loss: 1.1554, G loss: 0.8385\n",
      "[364/1600] D loss: 0.4824, G loss: 2.3460\n",
      "[484/1600] D loss: 1.2208, G loss: 0.8984\n",
      "[604/1600] D loss: 1.1254, G loss: 1.1073\n",
      "[724/1600] D loss: 1.2552, G loss: 0.8295\n",
      "[844/1600] D loss: 1.0367, G loss: 1.6204\n",
      "[964/1600] D loss: 1.1956, G loss: 1.2772\n",
      "[1084/1600] D loss: 1.0667, G loss: 1.4581\n",
      "[1204/1600] D loss: 1.4849, G loss: 0.8517\n",
      "[1324/1600] D loss: 1.0553, G loss: 1.2482\n",
      "[1444/1600] D loss: 0.7051, G loss: 3.2764\n",
      "[1564/1600] D loss: 1.0333, G loss: 1.2445\n",
      "train error: \n",
      " D loss: 1.008532, G loss: 1.549871, D accuracy: 67.2%, cell accuracy: 99.0%, board accuracy: 61.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323862, G loss: 1.732561, D accuracy: 61.1%, cell accuracy: 98.9%, board accuracy: 58.5% \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0121, G loss: 1.5580\n",
      "[124/1600] D loss: 0.4792, G loss: 2.7659\n",
      "[244/1600] D loss: 1.1165, G loss: 1.3784\n",
      "[364/1600] D loss: 0.8822, G loss: 1.6523\n",
      "[484/1600] D loss: 0.6020, G loss: 2.2812\n",
      "[604/1600] D loss: 1.4740, G loss: 0.8579\n",
      "[724/1600] D loss: 1.0598, G loss: 2.1154\n",
      "[844/1600] D loss: 1.4525, G loss: 0.7343\n",
      "[964/1600] D loss: 1.0158, G loss: 2.4717\n",
      "[1084/1600] D loss: 0.9116, G loss: 1.1128\n",
      "[1204/1600] D loss: 0.7600, G loss: 1.5729\n",
      "[1324/1600] D loss: 0.3937, G loss: 3.4592\n",
      "[1444/1600] D loss: 1.2020, G loss: 0.9856\n",
      "[1564/1600] D loss: 1.2814, G loss: 0.8861\n",
      "train error: \n",
      " D loss: 1.038064, G loss: 1.410913, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306742, G loss: 1.649236, D accuracy: 60.9%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0032, G loss: 1.0122\n",
      "[124/1600] D loss: 0.7777, G loss: 1.5662\n",
      "[244/1600] D loss: 0.8890, G loss: 1.3333\n",
      "[364/1600] D loss: 0.7987, G loss: 1.5860\n",
      "[484/1600] D loss: 0.4090, G loss: 4.4366\n",
      "[604/1600] D loss: 0.6430, G loss: 3.2699\n",
      "[724/1600] D loss: 0.7797, G loss: 1.4425\n",
      "[844/1600] D loss: 0.6502, G loss: 2.7012\n",
      "[964/1600] D loss: 0.9376, G loss: 2.0535\n",
      "[1084/1600] D loss: 0.9923, G loss: 1.4692\n",
      "[1204/1600] D loss: 1.1109, G loss: 1.3884\n",
      "[1324/1600] D loss: 0.7339, G loss: 2.1760\n",
      "[1444/1600] D loss: 1.2644, G loss: 1.1277\n",
      "[1564/1600] D loss: 0.5249, G loss: 2.0805\n",
      "train error: \n",
      " D loss: 1.044377, G loss: 1.356829, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 62.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269494, G loss: 1.627160, D accuracy: 62.7%, cell accuracy: 98.8%, board accuracy: 58.8% \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4302, G loss: 0.5790\n",
      "[124/1600] D loss: 1.0446, G loss: 1.8981\n",
      "[244/1600] D loss: 1.0933, G loss: 1.6602\n",
      "[364/1600] D loss: 1.0597, G loss: 1.4506\n",
      "[484/1600] D loss: 1.6188, G loss: 1.0845\n",
      "[604/1600] D loss: 0.8296, G loss: 1.4694\n",
      "[724/1600] D loss: 0.0560, G loss: 3.0904\n",
      "[844/1600] D loss: 0.3940, G loss: 2.5027\n",
      "[964/1600] D loss: 0.3475, G loss: 3.2358\n",
      "[1084/1600] D loss: 1.0805, G loss: 1.7042\n",
      "[1204/1600] D loss: 0.6891, G loss: 1.9197\n",
      "[1324/1600] D loss: 1.0810, G loss: 1.3514\n",
      "[1444/1600] D loss: 1.4983, G loss: 0.6176\n",
      "[1564/1600] D loss: 0.9692, G loss: 1.3525\n",
      "train error: \n",
      " D loss: 1.022843, G loss: 1.451190, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 62.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319311, G loss: 1.663710, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4860, G loss: 2.1498\n",
      "[124/1600] D loss: 0.6639, G loss: 1.7086\n",
      "[244/1600] D loss: 0.8977, G loss: 1.2968\n",
      "[364/1600] D loss: 1.0742, G loss: 1.3688\n",
      "[484/1600] D loss: 0.4370, G loss: 2.8314\n",
      "[604/1600] D loss: 0.8628, G loss: 1.3750\n",
      "[724/1600] D loss: 1.3669, G loss: 0.7625\n",
      "[844/1600] D loss: 1.0617, G loss: 1.7535\n",
      "[964/1600] D loss: 0.7438, G loss: 1.9643\n",
      "[1084/1600] D loss: 1.2202, G loss: 1.3458\n",
      "[1204/1600] D loss: 1.2442, G loss: 1.2431\n",
      "[1324/1600] D loss: 0.5196, G loss: 2.0736\n",
      "[1444/1600] D loss: 1.4082, G loss: 0.6147\n",
      "[1564/1600] D loss: 1.4728, G loss: 0.5356\n",
      "train error: \n",
      " D loss: 1.013648, G loss: 1.487008, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 62.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304926, G loss: 1.740328, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4144, G loss: 0.7183\n",
      "[124/1600] D loss: 1.3558, G loss: 0.6255\n",
      "[244/1600] D loss: 1.4175, G loss: 0.8613\n",
      "[364/1600] D loss: 1.1022, G loss: 0.9089\n",
      "[484/1600] D loss: 0.7506, G loss: 3.1045\n",
      "[604/1600] D loss: 1.0991, G loss: 1.6358\n",
      "[724/1600] D loss: 1.3879, G loss: 0.6860\n",
      "[844/1600] D loss: 1.0571, G loss: 1.6146\n",
      "[964/1600] D loss: 0.8755, G loss: 1.4271\n",
      "[1084/1600] D loss: 1.5798, G loss: 0.5310\n",
      "[1204/1600] D loss: 1.4120, G loss: 0.6043\n",
      "[1324/1600] D loss: 1.2679, G loss: 0.8328\n",
      "[1444/1600] D loss: 1.1661, G loss: 1.1628\n",
      "[1564/1600] D loss: 0.8798, G loss: 1.5426\n",
      "train error: \n",
      " D loss: 1.041240, G loss: 1.656156, D accuracy: 65.9%, cell accuracy: 99.0%, board accuracy: 62.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347375, G loss: 1.890357, D accuracy: 61.1%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3651, G loss: 0.8876\n",
      "[124/1600] D loss: 0.7903, G loss: 1.6589\n",
      "[244/1600] D loss: 1.3772, G loss: 0.7089\n",
      "[364/1600] D loss: 1.0420, G loss: 1.7208\n",
      "[484/1600] D loss: 0.7168, G loss: 2.1590\n",
      "[604/1600] D loss: 1.0843, G loss: 1.6678\n",
      "[724/1600] D loss: 1.0505, G loss: 1.3321\n",
      "[844/1600] D loss: 1.2852, G loss: 0.7399\n",
      "[964/1600] D loss: 1.1946, G loss: 0.9968\n",
      "[1084/1600] D loss: 0.8512, G loss: 1.1180\n",
      "[1204/1600] D loss: 0.7924, G loss: 1.9141\n",
      "[1324/1600] D loss: 1.0290, G loss: 1.6938\n",
      "[1444/1600] D loss: 1.4893, G loss: 0.5782\n",
      "[1564/1600] D loss: 1.4891, G loss: 0.5165\n",
      "train error: \n",
      " D loss: 1.021717, G loss: 1.654668, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 60.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325118, G loss: 1.905645, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4021, G loss: 0.7453\n",
      "[124/1600] D loss: 0.3751, G loss: 3.1193\n",
      "[244/1600] D loss: 1.5061, G loss: 0.6284\n",
      "[364/1600] D loss: 1.2044, G loss: 0.7096\n",
      "[484/1600] D loss: 1.0680, G loss: 1.1729\n",
      "[604/1600] D loss: 1.0842, G loss: 1.5848\n",
      "[724/1600] D loss: 1.0307, G loss: 1.3224\n",
      "[844/1600] D loss: 0.7477, G loss: 2.1330\n",
      "[964/1600] D loss: 0.5232, G loss: 2.7220\n",
      "[1084/1600] D loss: 1.0524, G loss: 1.9538\n",
      "[1204/1600] D loss: 1.4054, G loss: 0.7421\n",
      "[1324/1600] D loss: 0.8583, G loss: 1.5424\n",
      "[1444/1600] D loss: 1.0795, G loss: 0.9718\n",
      "[1564/1600] D loss: 0.7434, G loss: 2.0665\n",
      "train error: \n",
      " D loss: 1.022832, G loss: 1.397462, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 62.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298482, G loss: 1.609010, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7962, G loss: 2.0037\n",
      "[124/1600] D loss: 1.0794, G loss: 0.9549\n",
      "[244/1600] D loss: 1.4178, G loss: 0.7677\n",
      "[364/1600] D loss: 1.0445, G loss: 2.0861\n",
      "[484/1600] D loss: 1.0578, G loss: 1.5081\n",
      "[604/1600] D loss: 1.4111, G loss: 0.8303\n",
      "[724/1600] D loss: 1.1287, G loss: 0.7831\n",
      "[844/1600] D loss: 1.1927, G loss: 0.9248\n",
      "[964/1600] D loss: 1.1441, G loss: 1.1623\n",
      "[1084/1600] D loss: 0.7201, G loss: 2.2744\n",
      "[1204/1600] D loss: 0.8374, G loss: 1.9989\n",
      "[1324/1600] D loss: 1.0482, G loss: 2.0788\n",
      "[1444/1600] D loss: 0.8361, G loss: 1.5999\n",
      "[1564/1600] D loss: 0.8420, G loss: 2.1475\n",
      "train error: \n",
      " D loss: 1.005144, G loss: 1.524831, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 60.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314972, G loss: 1.745281, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1697, G loss: 0.7342\n",
      "[124/1600] D loss: 0.7590, G loss: 2.4777\n",
      "[244/1600] D loss: 0.9827, G loss: 1.6408\n",
      "[364/1600] D loss: 1.0682, G loss: 1.3567\n",
      "[484/1600] D loss: 0.8834, G loss: 1.6250\n",
      "[604/1600] D loss: 1.1412, G loss: 1.1256\n",
      "[724/1600] D loss: 1.0711, G loss: 1.3486\n",
      "[844/1600] D loss: 0.4190, G loss: 2.9639\n",
      "[964/1600] D loss: 0.6041, G loss: 1.4568\n",
      "[1084/1600] D loss: 1.1689, G loss: 0.8619\n",
      "[1204/1600] D loss: 0.9439, G loss: 1.6906\n",
      "[1324/1600] D loss: 0.9892, G loss: 2.0303\n",
      "[1444/1600] D loss: 1.0850, G loss: 1.6392\n",
      "[1564/1600] D loss: 0.7398, G loss: 1.1642\n",
      "train error: \n",
      " D loss: 1.052080, G loss: 1.723619, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 61.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362992, G loss: 1.965363, D accuracy: 61.9%, cell accuracy: 98.8%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4360, G loss: 0.8411\n",
      "[124/1600] D loss: 0.8810, G loss: 1.3449\n",
      "[244/1600] D loss: 0.8224, G loss: 1.6090\n",
      "[364/1600] D loss: 0.7218, G loss: 2.2795\n",
      "[484/1600] D loss: 1.0800, G loss: 1.7260\n",
      "[604/1600] D loss: 0.7299, G loss: 2.4910\n",
      "[724/1600] D loss: 0.9351, G loss: 2.2909\n",
      "[844/1600] D loss: 0.7210, G loss: 2.8109\n",
      "[964/1600] D loss: 0.7005, G loss: 2.5460\n",
      "[1084/1600] D loss: 1.0744, G loss: 1.4900\n",
      "[1204/1600] D loss: 1.2115, G loss: 0.8984\n",
      "[1324/1600] D loss: 1.0076, G loss: 1.4591\n",
      "[1444/1600] D loss: 1.4181, G loss: 0.6572\n",
      "[1564/1600] D loss: 0.7136, G loss: 2.5514\n",
      "train error: \n",
      " D loss: 1.019080, G loss: 1.407581, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 62.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291550, G loss: 1.684720, D accuracy: 62.7%, cell accuracy: 98.8%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0739, G loss: 1.1472\n",
      "[124/1600] D loss: 0.6105, G loss: 2.2031\n",
      "[244/1600] D loss: 1.0797, G loss: 1.4459\n",
      "[364/1600] D loss: 1.0349, G loss: 1.5720\n",
      "[484/1600] D loss: 1.3978, G loss: 0.6093\n",
      "[604/1600] D loss: 0.6748, G loss: 2.6909\n",
      "[724/1600] D loss: 1.2744, G loss: 0.8300\n",
      "[844/1600] D loss: 1.3993, G loss: 0.7422\n",
      "[964/1600] D loss: 0.6695, G loss: 1.5658\n",
      "[1084/1600] D loss: 0.8835, G loss: 2.3057\n",
      "[1204/1600] D loss: 0.9440, G loss: 1.2084\n",
      "[1324/1600] D loss: 1.0925, G loss: 1.3955\n",
      "[1444/1600] D loss: 0.4847, G loss: 2.4873\n",
      "[1564/1600] D loss: 1.1212, G loss: 0.9198\n",
      "train error: \n",
      " D loss: 1.024553, G loss: 1.497882, D accuracy: 67.3%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281244, G loss: 1.749999, D accuracy: 63.4%, cell accuracy: 98.8%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0869, G loss: 1.0645\n",
      "[124/1600] D loss: 1.0093, G loss: 1.8034\n",
      "[244/1600] D loss: 0.3623, G loss: 3.2117\n",
      "[364/1600] D loss: 0.9589, G loss: 2.0238\n",
      "[484/1600] D loss: 0.3976, G loss: 3.0441\n",
      "[604/1600] D loss: 1.0533, G loss: 1.9805\n",
      "[724/1600] D loss: 1.0670, G loss: 1.3653\n",
      "[844/1600] D loss: 1.0820, G loss: 1.0153\n",
      "[964/1600] D loss: 1.0886, G loss: 1.1324\n",
      "[1084/1600] D loss: 1.0404, G loss: 1.4785\n",
      "[1204/1600] D loss: 0.8254, G loss: 1.8490\n",
      "[1324/1600] D loss: 0.7608, G loss: 2.0563\n",
      "[1444/1600] D loss: 0.6107, G loss: 2.5571\n",
      "[1564/1600] D loss: 0.7825, G loss: 1.7682\n",
      "train error: \n",
      " D loss: 1.042967, G loss: 1.563850, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 61.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327688, G loss: 1.743931, D accuracy: 62.6%, cell accuracy: 98.9%, board accuracy: 57.8% \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4593, G loss: 3.1064\n",
      "[124/1600] D loss: 0.8382, G loss: 1.6255\n",
      "[244/1600] D loss: 0.5079, G loss: 2.3892\n",
      "[364/1600] D loss: 0.3655, G loss: 4.3087\n",
      "[484/1600] D loss: 1.0549, G loss: 1.2858\n",
      "[604/1600] D loss: 0.5767, G loss: 2.2008\n",
      "[724/1600] D loss: 1.3436, G loss: 0.6510\n",
      "[844/1600] D loss: 1.0574, G loss: 1.4315\n",
      "[964/1600] D loss: 1.0533, G loss: 1.5804\n",
      "[1084/1600] D loss: 0.2282, G loss: 3.3665\n",
      "[1204/1600] D loss: 0.7057, G loss: 2.8583\n",
      "[1324/1600] D loss: 1.0190, G loss: 1.5521\n",
      "[1444/1600] D loss: 1.0566, G loss: 1.6503\n",
      "[1564/1600] D loss: 1.0654, G loss: 1.2434\n",
      "train error: \n",
      " D loss: 1.023598, G loss: 1.467636, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 61.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300815, G loss: 1.702029, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7115, G loss: 2.6543\n",
      "[124/1600] D loss: 0.6954, G loss: 2.9583\n",
      "[244/1600] D loss: 1.1728, G loss: 1.0646\n",
      "[364/1600] D loss: 1.1818, G loss: 0.8709\n",
      "[484/1600] D loss: 0.4207, G loss: 2.1624\n",
      "[604/1600] D loss: 0.9736, G loss: 1.3612\n",
      "[724/1600] D loss: 0.7252, G loss: 2.2408\n",
      "[844/1600] D loss: 1.4392, G loss: 0.6174\n",
      "[964/1600] D loss: 1.0770, G loss: 1.6549\n",
      "[1084/1600] D loss: 1.3665, G loss: 0.6802\n",
      "[1204/1600] D loss: 0.8573, G loss: 2.1979\n",
      "[1324/1600] D loss: 1.0463, G loss: 1.5440\n",
      "[1444/1600] D loss: 0.4972, G loss: 2.3922\n",
      "[1564/1600] D loss: 1.3971, G loss: 0.7429\n",
      "train error: \n",
      " D loss: 1.024591, G loss: 1.382302, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290202, G loss: 1.584717, D accuracy: 62.0%, cell accuracy: 98.9%, board accuracy: 60.0% \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3734, G loss: 0.7516\n",
      "[124/1600] D loss: 0.7365, G loss: 1.5971\n",
      "[244/1600] D loss: 0.9723, G loss: 2.2764\n",
      "[364/1600] D loss: 0.7040, G loss: 2.0807\n",
      "[484/1600] D loss: 1.1241, G loss: 1.6242\n",
      "[604/1600] D loss: 1.0581, G loss: 1.8062\n",
      "[724/1600] D loss: 1.0920, G loss: 1.1560\n",
      "[844/1600] D loss: 1.0696, G loss: 1.0948\n",
      "[964/1600] D loss: 1.0965, G loss: 1.3926\n",
      "[1084/1600] D loss: 0.9684, G loss: 1.6078\n",
      "[1204/1600] D loss: 0.7577, G loss: 1.9883\n",
      "[1324/1600] D loss: 0.9733, G loss: 1.8317\n",
      "[1444/1600] D loss: 1.4646, G loss: 0.8329\n",
      "[1564/1600] D loss: 1.0516, G loss: 2.3403\n",
      "train error: \n",
      " D loss: 1.008691, G loss: 1.551193, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 61.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326039, G loss: 1.742230, D accuracy: 62.5%, cell accuracy: 98.9%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8500, G loss: 1.4151\n",
      "[124/1600] D loss: 0.7378, G loss: 2.5426\n",
      "[244/1600] D loss: 0.8357, G loss: 1.6565\n",
      "[364/1600] D loss: 0.7734, G loss: 1.0953\n",
      "[484/1600] D loss: 0.1818, G loss: 2.9446\n",
      "[604/1600] D loss: 1.3992, G loss: 0.6847\n",
      "[724/1600] D loss: 1.2031, G loss: 0.7416\n",
      "[844/1600] D loss: 0.7400, G loss: 2.0358\n",
      "[964/1600] D loss: 0.7566, G loss: 2.4889\n",
      "[1084/1600] D loss: 1.3950, G loss: 0.6236\n",
      "[1204/1600] D loss: 1.3695, G loss: 0.7933\n",
      "[1324/1600] D loss: 1.3677, G loss: 0.6623\n",
      "[1444/1600] D loss: 1.3571, G loss: 0.8318\n",
      "[1564/1600] D loss: 1.4373, G loss: 0.9133\n",
      "train error: \n",
      " D loss: 1.014344, G loss: 1.536217, D accuracy: 67.1%, cell accuracy: 99.0%, board accuracy: 61.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326122, G loss: 1.731869, D accuracy: 62.0%, cell accuracy: 98.9%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7980, G loss: 1.6224\n",
      "[124/1600] D loss: 1.2245, G loss: 0.7271\n",
      "[244/1600] D loss: 0.7422, G loss: 2.0939\n",
      "[364/1600] D loss: 0.7891, G loss: 2.9490\n",
      "[484/1600] D loss: 1.0495, G loss: 1.1198\n",
      "[604/1600] D loss: 1.4223, G loss: 0.7479\n",
      "[724/1600] D loss: 0.9908, G loss: 0.9736\n",
      "[844/1600] D loss: 1.0494, G loss: 1.4625\n",
      "[964/1600] D loss: 1.0681, G loss: 1.6546\n",
      "[1084/1600] D loss: 0.7201, G loss: 2.0169\n",
      "[1204/1600] D loss: 1.3361, G loss: 0.8907\n",
      "[1324/1600] D loss: 1.0471, G loss: 1.4120\n",
      "[1444/1600] D loss: 0.6817, G loss: 2.3753\n",
      "[1564/1600] D loss: 1.0548, G loss: 1.3857\n",
      "train error: \n",
      " D loss: 1.097506, G loss: 1.179435, D accuracy: 65.4%, cell accuracy: 99.0%, board accuracy: 62.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312834, G loss: 1.389691, D accuracy: 62.9%, cell accuracy: 98.9%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4289, G loss: 0.5783\n",
      "[124/1600] D loss: 1.0272, G loss: 1.6181\n",
      "[244/1600] D loss: 0.5863, G loss: 1.6525\n",
      "[364/1600] D loss: 0.7341, G loss: 1.9200\n",
      "[484/1600] D loss: 0.4483, G loss: 3.1759\n",
      "[604/1600] D loss: 1.0397, G loss: 1.5185\n",
      "[724/1600] D loss: 1.2583, G loss: 0.9720\n",
      "[844/1600] D loss: 0.7142, G loss: 2.1502\n",
      "[964/1600] D loss: 1.0692, G loss: 1.6540\n",
      "[1084/1600] D loss: 1.4032, G loss: 0.6663\n",
      "[1204/1600] D loss: 1.2296, G loss: 0.8286\n",
      "[1324/1600] D loss: 0.7941, G loss: 1.9586\n",
      "[1444/1600] D loss: 1.0714, G loss: 1.5578\n",
      "[1564/1600] D loss: 0.7662, G loss: 2.1243\n",
      "train error: \n",
      " D loss: 1.032052, G loss: 1.450443, D accuracy: 66.9%, cell accuracy: 99.0%, board accuracy: 61.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329841, G loss: 1.639622, D accuracy: 62.7%, cell accuracy: 98.9%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0366, G loss: 1.2861\n",
      "[124/1600] D loss: 1.4608, G loss: 0.5181\n",
      "[244/1600] D loss: 1.3684, G loss: 0.6908\n",
      "[364/1600] D loss: 0.3978, G loss: 2.4990\n",
      "[484/1600] D loss: 1.0625, G loss: 1.8415\n",
      "[604/1600] D loss: 0.6928, G loss: 2.7852\n",
      "[724/1600] D loss: 1.4108, G loss: 0.7322\n",
      "[844/1600] D loss: 1.0812, G loss: 1.6152\n",
      "[964/1600] D loss: 1.2671, G loss: 0.8692\n",
      "[1084/1600] D loss: 1.3426, G loss: 0.7387\n",
      "[1204/1600] D loss: 0.8226, G loss: 1.7707\n",
      "[1324/1600] D loss: 0.8594, G loss: 1.5186\n",
      "[1444/1600] D loss: 0.9720, G loss: 1.3787\n",
      "[1564/1600] D loss: 1.0998, G loss: 1.0768\n",
      "train error: \n",
      " D loss: 1.008416, G loss: 1.454906, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 61.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307610, G loss: 1.665485, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2349, G loss: 0.8057\n",
      "[124/1600] D loss: 1.0639, G loss: 1.7752\n",
      "[244/1600] D loss: 1.4046, G loss: 0.6357\n",
      "[364/1600] D loss: 1.3988, G loss: 0.7275\n",
      "[484/1600] D loss: 0.8764, G loss: 1.4847\n",
      "[604/1600] D loss: 1.3659, G loss: 0.6638\n",
      "[724/1600] D loss: 1.0408, G loss: 1.8384\n",
      "[844/1600] D loss: 1.2253, G loss: 1.2533\n",
      "[964/1600] D loss: 1.1527, G loss: 1.2322\n",
      "[1084/1600] D loss: 1.8868, G loss: 0.5148\n",
      "[1204/1600] D loss: 1.3857, G loss: 0.7402\n",
      "[1324/1600] D loss: 1.4392, G loss: 0.7828\n",
      "[1444/1600] D loss: 0.9759, G loss: 1.2913\n",
      "[1564/1600] D loss: 0.9289, G loss: 1.6855\n",
      "train error: \n",
      " D loss: 1.010842, G loss: 1.580253, D accuracy: 67.3%, cell accuracy: 99.0%, board accuracy: 61.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325117, G loss: 1.772501, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2031, G loss: 0.9267\n",
      "[124/1600] D loss: 1.2592, G loss: 0.7661\n",
      "[244/1600] D loss: 0.8035, G loss: 1.7667\n",
      "[364/1600] D loss: 1.4203, G loss: 0.6908\n",
      "[484/1600] D loss: 0.8110, G loss: 1.9807\n",
      "[604/1600] D loss: 1.5926, G loss: 1.1845\n",
      "[724/1600] D loss: 0.6866, G loss: 2.6318\n",
      "[844/1600] D loss: 1.2053, G loss: 0.8054\n",
      "[964/1600] D loss: 0.7077, G loss: 2.4698\n",
      "[1084/1600] D loss: 0.5087, G loss: 2.3781\n",
      "[1204/1600] D loss: 1.2299, G loss: 0.8217\n",
      "[1324/1600] D loss: 1.0512, G loss: 1.4264\n",
      "[1444/1600] D loss: 1.0426, G loss: 1.1093\n",
      "[1564/1600] D loss: 1.3830, G loss: 0.7205\n",
      "train error: \n",
      " D loss: 1.017421, G loss: 1.480993, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299365, G loss: 1.683842, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2633, G loss: 0.7276\n",
      "[124/1600] D loss: 1.0523, G loss: 0.9976\n",
      "[244/1600] D loss: 1.2306, G loss: 0.7826\n",
      "[364/1600] D loss: 0.7912, G loss: 1.3048\n",
      "[484/1600] D loss: 1.0187, G loss: 0.9115\n",
      "[604/1600] D loss: 1.4578, G loss: 0.8056\n",
      "[724/1600] D loss: 0.6714, G loss: 2.2343\n",
      "[844/1600] D loss: 0.9732, G loss: 1.6878\n",
      "[964/1600] D loss: 0.8059, G loss: 2.5537\n",
      "[1084/1600] D loss: 0.8977, G loss: 1.8100\n",
      "[1204/1600] D loss: 1.1100, G loss: 1.4276\n",
      "[1324/1600] D loss: 0.7774, G loss: 1.4707\n",
      "[1444/1600] D loss: 0.8991, G loss: 2.1003\n",
      "[1564/1600] D loss: 1.0337, G loss: 1.2261\n",
      "train error: \n",
      " D loss: 1.019277, G loss: 1.599428, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 61.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344476, G loss: 1.784120, D accuracy: 61.6%, cell accuracy: 98.9%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9376, G loss: 2.2120\n",
      "[124/1600] D loss: 1.4353, G loss: 0.5506\n",
      "[244/1600] D loss: 0.2166, G loss: 3.4672\n",
      "[364/1600] D loss: 0.9794, G loss: 1.1847\n",
      "[484/1600] D loss: 0.7691, G loss: 2.1096\n",
      "[604/1600] D loss: 1.0877, G loss: 1.5851\n",
      "[724/1600] D loss: 1.0513, G loss: 1.9485\n",
      "[844/1600] D loss: 1.3359, G loss: 0.7679\n",
      "[964/1600] D loss: 0.7339, G loss: 2.2938\n",
      "[1084/1600] D loss: 1.3734, G loss: 0.6574\n",
      "[1204/1600] D loss: 1.0805, G loss: 1.6924\n",
      "[1324/1600] D loss: 1.4099, G loss: 0.7635\n",
      "[1444/1600] D loss: 1.2325, G loss: 0.6427\n",
      "[1564/1600] D loss: 1.3948, G loss: 0.6963\n",
      "train error: \n",
      " D loss: 1.012994, G loss: 1.617014, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 63.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344519, G loss: 1.807875, D accuracy: 62.1%, cell accuracy: 98.9%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2081, G loss: 0.8982\n",
      "[124/1600] D loss: 1.3887, G loss: 0.7546\n",
      "[244/1600] D loss: 1.1367, G loss: 1.7426\n",
      "[364/1600] D loss: 1.2321, G loss: 0.7963\n",
      "[484/1600] D loss: 1.4205, G loss: 0.6070\n",
      "[604/1600] D loss: 1.4411, G loss: 0.5110\n",
      "[724/1600] D loss: 1.1497, G loss: 1.9487\n",
      "[844/1600] D loss: 0.8682, G loss: 2.7105\n",
      "[964/1600] D loss: 1.3737, G loss: 0.6986\n",
      "[1084/1600] D loss: 0.9878, G loss: 2.1017\n",
      "[1204/1600] D loss: 1.2100, G loss: 1.2707\n",
      "[1324/1600] D loss: 1.3279, G loss: 0.6855\n",
      "[1444/1600] D loss: 1.0066, G loss: 2.1767\n",
      "[1564/1600] D loss: 0.7493, G loss: 2.1130\n",
      "train error: \n",
      " D loss: 1.030178, G loss: 1.749038, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389573, G loss: 1.954031, D accuracy: 61.6%, cell accuracy: 98.8%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1982, G loss: 2.1116\n",
      "[124/1600] D loss: 1.2725, G loss: 0.8127\n",
      "[244/1600] D loss: 1.0272, G loss: 1.8008\n",
      "[364/1600] D loss: 0.8074, G loss: 1.5025\n",
      "[484/1600] D loss: 0.9877, G loss: 1.8912\n",
      "[604/1600] D loss: 0.9466, G loss: 1.9468\n",
      "[724/1600] D loss: 1.4199, G loss: 0.8362\n",
      "[844/1600] D loss: 1.4516, G loss: 0.5741\n",
      "[964/1600] D loss: 1.0939, G loss: 1.6530\n",
      "[1084/1600] D loss: 0.6504, G loss: 2.1583\n",
      "[1204/1600] D loss: 0.7624, G loss: 2.1220\n",
      "[1324/1600] D loss: 0.5048, G loss: 2.0147\n",
      "[1444/1600] D loss: 0.7618, G loss: 1.8471\n",
      "[1564/1600] D loss: 0.8537, G loss: 1.6449\n",
      "train error: \n",
      " D loss: 1.037368, G loss: 1.720782, D accuracy: 65.6%, cell accuracy: 99.0%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381447, G loss: 1.948270, D accuracy: 61.6%, cell accuracy: 98.9%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1473, G loss: 1.8080\n",
      "[124/1600] D loss: 1.6297, G loss: 0.5113\n",
      "[244/1600] D loss: 0.8431, G loss: 2.5588\n",
      "[364/1600] D loss: 0.9275, G loss: 1.1534\n",
      "[484/1600] D loss: 1.4740, G loss: 0.7266\n",
      "[604/1600] D loss: 0.7597, G loss: 2.3837\n",
      "[724/1600] D loss: 0.9205, G loss: 1.3399\n",
      "[844/1600] D loss: 1.1914, G loss: 0.7474\n",
      "[964/1600] D loss: 1.0398, G loss: 2.3690\n",
      "[1084/1600] D loss: 1.0644, G loss: 1.3814\n",
      "[1204/1600] D loss: 1.0004, G loss: 1.3719\n",
      "[1324/1600] D loss: 0.7705, G loss: 2.7803\n",
      "[1444/1600] D loss: 1.0407, G loss: 1.9109\n",
      "[1564/1600] D loss: 0.7402, G loss: 1.6930\n",
      "train error: \n",
      " D loss: 1.014174, G loss: 1.671507, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348709, G loss: 1.886871, D accuracy: 61.6%, cell accuracy: 98.8%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0920, G loss: 1.7008\n",
      "[124/1600] D loss: 1.1995, G loss: 0.7402\n",
      "[244/1600] D loss: 1.0072, G loss: 1.3208\n",
      "[364/1600] D loss: 1.0640, G loss: 2.1793\n",
      "[484/1600] D loss: 0.4186, G loss: 2.8767\n",
      "[604/1600] D loss: 0.7395, G loss: 1.6658\n",
      "[724/1600] D loss: 1.0893, G loss: 1.5885\n",
      "[844/1600] D loss: 0.8002, G loss: 1.7004\n",
      "[964/1600] D loss: 0.6968, G loss: 2.6211\n",
      "[1084/1600] D loss: 1.1217, G loss: 1.1214\n",
      "[1204/1600] D loss: 0.4449, G loss: 3.5303\n",
      "[1324/1600] D loss: 1.4183, G loss: 0.7576\n",
      "[1444/1600] D loss: 1.4200, G loss: 0.7395\n",
      "[1564/1600] D loss: 0.7425, G loss: 2.3723\n",
      "train error: \n",
      " D loss: 1.013972, G loss: 1.662459, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356423, G loss: 1.847171, D accuracy: 62.4%, cell accuracy: 98.9%, board accuracy: 54.5% \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3822, G loss: 3.3998\n",
      "[124/1600] D loss: 0.4153, G loss: 3.1538\n",
      "[244/1600] D loss: 1.1460, G loss: 0.9600\n",
      "[364/1600] D loss: 1.4309, G loss: 0.8103\n",
      "[484/1600] D loss: 0.7227, G loss: 2.1883\n",
      "[604/1600] D loss: 0.8296, G loss: 1.0071\n",
      "[724/1600] D loss: 1.3880, G loss: 0.6641\n",
      "[844/1600] D loss: 1.0162, G loss: 1.4232\n",
      "[964/1600] D loss: 1.3856, G loss: 0.7814\n",
      "[1084/1600] D loss: 1.3851, G loss: 0.6532\n",
      "[1204/1600] D loss: 1.2355, G loss: 1.2981\n",
      "[1324/1600] D loss: 1.3964, G loss: 0.7210\n",
      "[1444/1600] D loss: 1.0853, G loss: 1.3578\n",
      "[1564/1600] D loss: 1.0592, G loss: 1.6835\n",
      "train error: \n",
      " D loss: 1.021201, G loss: 1.405515, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299796, G loss: 1.643432, D accuracy: 63.2%, cell accuracy: 98.8%, board accuracy: 54.2% \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4662, G loss: 1.9712\n",
      "[124/1600] D loss: 1.5188, G loss: 0.7858\n",
      "[244/1600] D loss: 1.0490, G loss: 1.8011\n",
      "[364/1600] D loss: 1.4782, G loss: 0.6473\n",
      "[484/1600] D loss: 1.0554, G loss: 1.8025\n",
      "[604/1600] D loss: 1.0685, G loss: 1.3457\n",
      "[724/1600] D loss: 0.7152, G loss: 2.3247\n",
      "[844/1600] D loss: 1.2627, G loss: 0.9980\n",
      "[964/1600] D loss: 1.4319, G loss: 0.6072\n",
      "[1084/1600] D loss: 0.9012, G loss: 1.5670\n",
      "[1204/1600] D loss: 1.3379, G loss: 0.7714\n",
      "[1324/1600] D loss: 0.9595, G loss: 1.4361\n",
      "[1444/1600] D loss: 1.0963, G loss: 0.9554\n",
      "[1564/1600] D loss: 1.3110, G loss: 0.6785\n",
      "train error: \n",
      " D loss: 1.038135, G loss: 1.409375, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 61.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302527, G loss: 1.600175, D accuracy: 62.4%, cell accuracy: 98.9%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1769, G loss: 0.7348\n",
      "[124/1600] D loss: 0.7485, G loss: 2.0965\n",
      "[244/1600] D loss: 0.4516, G loss: 2.3759\n",
      "[364/1600] D loss: 0.3960, G loss: 3.8179\n",
      "[484/1600] D loss: 1.3971, G loss: 0.5729\n",
      "[604/1600] D loss: 1.2579, G loss: 0.6920\n",
      "[724/1600] D loss: 0.7151, G loss: 2.9577\n",
      "[844/1600] D loss: 1.0619, G loss: 2.2377\n",
      "[964/1600] D loss: 0.6942, G loss: 2.3019\n",
      "[1084/1600] D loss: 1.4010, G loss: 0.6548\n",
      "[1204/1600] D loss: 0.6561, G loss: 2.2916\n",
      "[1324/1600] D loss: 1.0809, G loss: 1.4920\n",
      "[1444/1600] D loss: 1.2639, G loss: 0.8414\n",
      "[1564/1600] D loss: 0.5969, G loss: 1.7745\n",
      "train error: \n",
      " D loss: 1.007138, G loss: 1.548946, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 61.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335891, G loss: 1.747652, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6256, G loss: 0.6719\n",
      "[124/1600] D loss: 0.4283, G loss: 2.9674\n",
      "[244/1600] D loss: 0.7998, G loss: 2.5917\n",
      "[364/1600] D loss: 1.0612, G loss: 1.4473\n",
      "[484/1600] D loss: 0.7186, G loss: 2.5713\n",
      "[604/1600] D loss: 0.7467, G loss: 2.0364\n",
      "[724/1600] D loss: 0.9427, G loss: 1.3217\n",
      "[844/1600] D loss: 1.4076, G loss: 0.8823\n",
      "[964/1600] D loss: 1.0648, G loss: 1.6427\n",
      "[1084/1600] D loss: 1.1294, G loss: 0.9715\n",
      "[1204/1600] D loss: 1.0532, G loss: 1.3599\n",
      "[1324/1600] D loss: 1.0675, G loss: 1.5524\n",
      "[1444/1600] D loss: 1.4065, G loss: 0.7407\n",
      "[1564/1600] D loss: 1.0910, G loss: 0.9714\n",
      "train error: \n",
      " D loss: 1.025453, G loss: 1.690060, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 62.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364450, G loss: 1.911391, D accuracy: 61.4%, cell accuracy: 98.8%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0244, G loss: 1.3425\n",
      "[124/1600] D loss: 1.1439, G loss: 1.1575\n",
      "[244/1600] D loss: 1.3934, G loss: 0.6423\n",
      "[364/1600] D loss: 0.5160, G loss: 2.8033\n",
      "[484/1600] D loss: 0.8693, G loss: 2.1127\n",
      "[604/1600] D loss: 1.0436, G loss: 2.0917\n",
      "[724/1600] D loss: 1.3888, G loss: 0.7567\n",
      "[844/1600] D loss: 1.4002, G loss: 0.7718\n",
      "[964/1600] D loss: 0.5800, G loss: 2.4833\n",
      "[1084/1600] D loss: 0.9394, G loss: 0.9992\n",
      "[1204/1600] D loss: 0.9000, G loss: 2.5498\n",
      "[1324/1600] D loss: 1.0504, G loss: 1.8447\n",
      "[1444/1600] D loss: 0.7573, G loss: 2.4378\n",
      "[1564/1600] D loss: 0.6370, G loss: 2.1793\n",
      "train error: \n",
      " D loss: 1.092890, G loss: 1.939769, D accuracy: 66.0%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.457199, G loss: 2.144542, D accuracy: 61.4%, cell accuracy: 98.8%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1646, G loss: 1.3834\n",
      "[124/1600] D loss: 1.0705, G loss: 1.1781\n",
      "[244/1600] D loss: 1.4401, G loss: 0.7873\n",
      "[364/1600] D loss: 0.7368, G loss: 2.5560\n",
      "[484/1600] D loss: 1.1833, G loss: 0.8470\n",
      "[604/1600] D loss: 0.4536, G loss: 3.7747\n",
      "[724/1600] D loss: 1.1627, G loss: 0.9554\n",
      "[844/1600] D loss: 0.6884, G loss: 3.1224\n",
      "[964/1600] D loss: 1.1673, G loss: 0.7776\n",
      "[1084/1600] D loss: 0.4086, G loss: 3.0093\n",
      "[1204/1600] D loss: 1.1435, G loss: 2.0574\n",
      "[1324/1600] D loss: 0.4908, G loss: 2.6763\n",
      "[1444/1600] D loss: 0.8403, G loss: 1.0683\n",
      "[1564/1600] D loss: 1.1590, G loss: 1.4407\n",
      "train error: \n",
      " D loss: 1.012024, G loss: 1.637723, D accuracy: 67.1%, cell accuracy: 99.0%, board accuracy: 60.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345022, G loss: 1.867429, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2916, G loss: 0.9242\n",
      "[124/1600] D loss: 0.8221, G loss: 1.8534\n",
      "[244/1600] D loss: 1.0792, G loss: 1.6789\n",
      "[364/1600] D loss: 0.7163, G loss: 2.4691\n",
      "[484/1600] D loss: 1.0748, G loss: 1.2698\n",
      "[604/1600] D loss: 0.9226, G loss: 2.6073\n",
      "[724/1600] D loss: 1.0693, G loss: 2.4318\n",
      "[844/1600] D loss: 0.7672, G loss: 1.6036\n",
      "[964/1600] D loss: 1.1646, G loss: 1.4770\n",
      "[1084/1600] D loss: 1.1008, G loss: 1.6048\n",
      "[1204/1600] D loss: 1.7152, G loss: 0.6022\n",
      "[1324/1600] D loss: 1.1395, G loss: 1.2448\n",
      "[1444/1600] D loss: 0.6045, G loss: 2.9171\n",
      "[1564/1600] D loss: 1.2084, G loss: 0.9160\n",
      "train error: \n",
      " D loss: 1.019767, G loss: 1.767831, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 60.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361402, G loss: 2.024083, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9084, G loss: 1.8785\n",
      "[124/1600] D loss: 0.6827, G loss: 1.2545\n",
      "[244/1600] D loss: 0.3597, G loss: 4.0510\n",
      "[364/1600] D loss: 1.1445, G loss: 0.9242\n",
      "[484/1600] D loss: 0.7462, G loss: 2.5617\n",
      "[604/1600] D loss: 1.1202, G loss: 1.7466\n",
      "[724/1600] D loss: 1.2917, G loss: 0.8101\n",
      "[844/1600] D loss: 1.1247, G loss: 1.0381\n",
      "[964/1600] D loss: 1.0180, G loss: 1.5404\n",
      "[1084/1600] D loss: 0.7907, G loss: 1.6654\n",
      "[1204/1600] D loss: 1.3983, G loss: 0.6202\n",
      "[1324/1600] D loss: 1.0479, G loss: 1.5362\n",
      "[1444/1600] D loss: 1.1733, G loss: 1.5201\n",
      "[1564/1600] D loss: 1.2718, G loss: 1.6379\n",
      "train error: \n",
      " D loss: 1.019372, G loss: 1.517162, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 61.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345986, G loss: 1.765303, D accuracy: 61.9%, cell accuracy: 98.8%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0898, G loss: 1.4983\n",
      "[124/1600] D loss: 1.1998, G loss: 0.9121\n",
      "[244/1600] D loss: 0.7080, G loss: 3.1644\n",
      "[364/1600] D loss: 0.5839, G loss: 2.1091\n",
      "[484/1600] D loss: 1.4376, G loss: 0.6352\n",
      "[604/1600] D loss: 1.2822, G loss: 0.7422\n",
      "[724/1600] D loss: 1.2489, G loss: 1.0593\n",
      "[844/1600] D loss: 0.8256, G loss: 2.1465\n",
      "[964/1600] D loss: 0.8566, G loss: 1.8469\n",
      "[1084/1600] D loss: 1.3955, G loss: 0.8328\n",
      "[1204/1600] D loss: 0.6213, G loss: 2.5121\n",
      "[1324/1600] D loss: 1.1487, G loss: 0.9899\n",
      "[1444/1600] D loss: 1.3648, G loss: 0.9752\n",
      "[1564/1600] D loss: 0.7959, G loss: 2.8964\n",
      "train error: \n",
      " D loss: 1.097995, G loss: 1.219925, D accuracy: 65.5%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340442, G loss: 1.452168, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3809, G loss: 0.7128\n",
      "[124/1600] D loss: 0.3712, G loss: 3.7035\n",
      "[244/1600] D loss: 1.0926, G loss: 1.5186\n",
      "[364/1600] D loss: 0.4824, G loss: 2.3417\n",
      "[484/1600] D loss: 1.1700, G loss: 1.8182\n",
      "[604/1600] D loss: 1.0409, G loss: 2.1436\n",
      "[724/1600] D loss: 0.8757, G loss: 2.1696\n",
      "[844/1600] D loss: 0.3890, G loss: 3.2682\n",
      "[964/1600] D loss: 0.7258, G loss: 2.3734\n",
      "[1084/1600] D loss: 1.1487, G loss: 1.2592\n",
      "[1204/1600] D loss: 1.1269, G loss: 1.3881\n",
      "[1324/1600] D loss: 1.4666, G loss: 0.8471\n",
      "[1444/1600] D loss: 1.4023, G loss: 0.8002\n",
      "[1564/1600] D loss: 1.0349, G loss: 1.5150\n",
      "train error: \n",
      " D loss: 1.017683, G loss: 1.560867, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305224, G loss: 1.780551, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0509, G loss: 1.5722\n",
      "[124/1600] D loss: 1.0534, G loss: 1.4621\n",
      "[244/1600] D loss: 0.5359, G loss: 2.5256\n",
      "[364/1600] D loss: 1.0781, G loss: 1.6328\n",
      "[484/1600] D loss: 1.2140, G loss: 0.7327\n",
      "[604/1600] D loss: 1.0504, G loss: 1.5287\n",
      "[724/1600] D loss: 1.4047, G loss: 0.7512\n",
      "[844/1600] D loss: 1.0776, G loss: 1.4645\n",
      "[964/1600] D loss: 0.7138, G loss: 2.2208\n",
      "[1084/1600] D loss: 1.3471, G loss: 0.5908\n",
      "[1204/1600] D loss: 1.3209, G loss: 0.8712\n",
      "[1324/1600] D loss: 0.8149, G loss: 1.8059\n",
      "[1444/1600] D loss: 1.4738, G loss: 0.5785\n",
      "[1564/1600] D loss: 0.9373, G loss: 2.0663\n",
      "train error: \n",
      " D loss: 1.009266, G loss: 1.663059, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349344, G loss: 1.883464, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3697, G loss: 0.7264\n",
      "[124/1600] D loss: 0.5007, G loss: 2.1646\n",
      "[244/1600] D loss: 1.0823, G loss: 1.2952\n",
      "[364/1600] D loss: 1.4289, G loss: 0.9837\n",
      "[484/1600] D loss: 1.1457, G loss: 0.8263\n",
      "[604/1600] D loss: 1.0363, G loss: 1.8460\n",
      "[724/1600] D loss: 0.7672, G loss: 2.4321\n",
      "[844/1600] D loss: 0.7060, G loss: 1.7261\n",
      "[964/1600] D loss: 1.4487, G loss: 0.8750\n",
      "[1084/1600] D loss: 0.6793, G loss: 3.1637\n",
      "[1204/1600] D loss: 0.7762, G loss: 1.6176\n",
      "[1324/1600] D loss: 1.1601, G loss: 1.7534\n",
      "[1444/1600] D loss: 1.4738, G loss: 0.7144\n",
      "[1564/1600] D loss: 0.8920, G loss: 1.9869\n",
      "train error: \n",
      " D loss: 1.027070, G loss: 1.487520, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299884, G loss: 1.699049, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0598, G loss: 1.8788\n",
      "[124/1600] D loss: 1.4034, G loss: 0.7345\n",
      "[244/1600] D loss: 0.7778, G loss: 2.4062\n",
      "[364/1600] D loss: 0.4698, G loss: 2.6518\n",
      "[484/1600] D loss: 1.2310, G loss: 0.9606\n",
      "[604/1600] D loss: 1.0173, G loss: 1.7235\n",
      "[724/1600] D loss: 1.1056, G loss: 1.2811\n",
      "[844/1600] D loss: 1.0865, G loss: 1.1758\n",
      "[964/1600] D loss: 1.4127, G loss: 0.7992\n",
      "[1084/1600] D loss: 1.0579, G loss: 1.7031\n",
      "[1204/1600] D loss: 0.2352, G loss: 2.5482\n",
      "[1324/1600] D loss: 1.0550, G loss: 1.8938\n",
      "[1444/1600] D loss: 1.2982, G loss: 0.8464\n",
      "[1564/1600] D loss: 1.0720, G loss: 1.1176\n",
      "train error: \n",
      " D loss: 1.024044, G loss: 1.467286, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311106, G loss: 1.691057, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9687, G loss: 1.4246\n",
      "[124/1600] D loss: 1.0555, G loss: 1.4254\n",
      "[244/1600] D loss: 0.6845, G loss: 2.1135\n",
      "[364/1600] D loss: 1.5075, G loss: 0.6944\n",
      "[484/1600] D loss: 0.8516, G loss: 1.6479\n",
      "[604/1600] D loss: 0.3658, G loss: 3.2021\n",
      "[724/1600] D loss: 0.7134, G loss: 3.0613\n",
      "[844/1600] D loss: 0.3772, G loss: 3.2952\n",
      "[964/1600] D loss: 0.7455, G loss: 1.5939\n",
      "[1084/1600] D loss: 0.9095, G loss: 1.2412\n",
      "[1204/1600] D loss: 0.6840, G loss: 2.5510\n",
      "[1324/1600] D loss: 1.2519, G loss: 1.0679\n",
      "[1444/1600] D loss: 1.1029, G loss: 1.1236\n",
      "[1564/1600] D loss: 0.7134, G loss: 2.6829\n",
      "train error: \n",
      " D loss: 1.036381, G loss: 1.477498, D accuracy: 67.1%, cell accuracy: 99.0%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357572, G loss: 1.693538, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 54.5% \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3822, G loss: 0.7480\n",
      "[124/1600] D loss: 1.3957, G loss: 0.5774\n",
      "[244/1600] D loss: 1.0418, G loss: 1.2272\n",
      "[364/1600] D loss: 1.4398, G loss: 0.6466\n",
      "[484/1600] D loss: 1.0600, G loss: 1.5381\n",
      "[604/1600] D loss: 0.8039, G loss: 2.0107\n",
      "[724/1600] D loss: 1.4861, G loss: 0.7588\n",
      "[844/1600] D loss: 0.5766, G loss: 3.0102\n",
      "[964/1600] D loss: 1.0648, G loss: 1.2535\n",
      "[1084/1600] D loss: 1.3607, G loss: 0.5452\n",
      "[1204/1600] D loss: 1.1020, G loss: 1.8129\n",
      "[1324/1600] D loss: 1.2006, G loss: 0.7840\n",
      "[1444/1600] D loss: 1.1855, G loss: 1.1097\n",
      "[1564/1600] D loss: 1.2087, G loss: 0.8093\n",
      "train error: \n",
      " D loss: 1.025543, G loss: 1.389169, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 58.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318171, G loss: 1.600885, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2466, G loss: 0.7594\n",
      "[124/1600] D loss: 0.7556, G loss: 1.8750\n",
      "[244/1600] D loss: 1.0529, G loss: 1.7203\n",
      "[364/1600] D loss: 0.3034, G loss: 3.2590\n",
      "[484/1600] D loss: 2.0274, G loss: 0.5562\n",
      "[604/1600] D loss: 0.7048, G loss: 2.5411\n",
      "[724/1600] D loss: 1.3853, G loss: 0.9337\n",
      "[844/1600] D loss: 0.7587, G loss: 2.1017\n",
      "[964/1600] D loss: 0.5812, G loss: 2.9582\n",
      "[1084/1600] D loss: 1.4371, G loss: 0.7461\n",
      "[1204/1600] D loss: 0.6834, G loss: 2.5322\n",
      "[1324/1600] D loss: 0.7706, G loss: 1.5547\n",
      "[1444/1600] D loss: 1.1614, G loss: 1.0114\n",
      "[1564/1600] D loss: 0.0385, G loss: 3.9486\n",
      "train error: \n",
      " D loss: 1.024641, G loss: 1.437358, D accuracy: 66.9%, cell accuracy: 98.9%, board accuracy: 52.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333839, G loss: 1.619661, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4490, G loss: 0.7191\n",
      "[124/1600] D loss: 1.0289, G loss: 1.5630\n",
      "[244/1600] D loss: 0.9190, G loss: 1.2734\n",
      "[364/1600] D loss: 1.0249, G loss: 1.9410\n",
      "[484/1600] D loss: 0.6019, G loss: 3.3112\n",
      "[604/1600] D loss: 1.1990, G loss: 0.6869\n",
      "[724/1600] D loss: 0.7737, G loss: 2.1564\n",
      "[844/1600] D loss: 1.5257, G loss: 0.8120\n",
      "[964/1600] D loss: 0.5553, G loss: 3.2690\n",
      "[1084/1600] D loss: 1.1879, G loss: 1.0470\n",
      "[1204/1600] D loss: 0.7588, G loss: 2.2488\n",
      "[1324/1600] D loss: 0.7931, G loss: 2.0082\n",
      "[1444/1600] D loss: 1.0424, G loss: 1.8257\n",
      "[1564/1600] D loss: 0.7435, G loss: 2.1960\n",
      "train error: \n",
      " D loss: 1.016659, G loss: 1.623094, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 58.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371873, G loss: 1.862385, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 54.2% \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1075, G loss: 1.5157\n",
      "[124/1600] D loss: 0.6774, G loss: 2.2423\n",
      "[244/1600] D loss: 1.3861, G loss: 0.8058\n",
      "[364/1600] D loss: 0.6578, G loss: 2.6492\n",
      "[484/1600] D loss: 1.1144, G loss: 0.7612\n",
      "[604/1600] D loss: 1.4598, G loss: 0.9218\n",
      "[724/1600] D loss: 1.2066, G loss: 1.3184\n",
      "[844/1600] D loss: 0.8591, G loss: 1.7695\n",
      "[964/1600] D loss: 0.5310, G loss: 2.7171\n",
      "[1084/1600] D loss: 1.1003, G loss: 1.0120\n",
      "[1204/1600] D loss: 1.0506, G loss: 1.5581\n",
      "[1324/1600] D loss: 1.2570, G loss: 0.6662\n",
      "[1444/1600] D loss: 1.4041, G loss: 0.6828\n",
      "[1564/1600] D loss: 0.3659, G loss: 3.7150\n",
      "train error: \n",
      " D loss: 1.004325, G loss: 1.535878, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347928, G loss: 1.727075, D accuracy: 62.1%, cell accuracy: 98.9%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8834, G loss: 1.2917\n",
      "[124/1600] D loss: 0.7956, G loss: 1.8797\n",
      "[244/1600] D loss: 1.0828, G loss: 2.4405\n",
      "[364/1600] D loss: 1.3584, G loss: 1.1340\n",
      "[484/1600] D loss: 1.0928, G loss: 2.3448\n",
      "[604/1600] D loss: 1.2863, G loss: 1.1235\n",
      "[724/1600] D loss: 1.0608, G loss: 1.3662\n",
      "[844/1600] D loss: 1.3918, G loss: 0.7567\n",
      "[964/1600] D loss: 0.7464, G loss: 2.3925\n",
      "[1084/1600] D loss: 1.1267, G loss: 1.0098\n",
      "[1204/1600] D loss: 0.7588, G loss: 1.9130\n",
      "[1324/1600] D loss: 0.9972, G loss: 1.5857\n",
      "[1444/1600] D loss: 1.3950, G loss: 0.8017\n",
      "[1564/1600] D loss: 1.0991, G loss: 1.0559\n",
      "train error: \n",
      " D loss: 1.043925, G loss: 1.708818, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 61.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374058, G loss: 1.922610, D accuracy: 62.9%, cell accuracy: 98.8%, board accuracy: 57.8% \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4134, G loss: 0.8343\n",
      "[124/1600] D loss: 0.7405, G loss: 1.7028\n",
      "[244/1600] D loss: 0.4173, G loss: 3.5479\n",
      "[364/1600] D loss: 0.3669, G loss: 3.0869\n",
      "[484/1600] D loss: 1.3878, G loss: 0.6552\n",
      "[604/1600] D loss: 1.0621, G loss: 1.3824\n",
      "[724/1600] D loss: 0.7137, G loss: 2.5849\n",
      "[844/1600] D loss: 0.8643, G loss: 1.4073\n",
      "[964/1600] D loss: 0.8998, G loss: 1.4269\n",
      "[1084/1600] D loss: 0.4421, G loss: 2.4591\n",
      "[1204/1600] D loss: 0.9876, G loss: 1.6688\n",
      "[1324/1600] D loss: 0.7368, G loss: 2.6510\n",
      "[1444/1600] D loss: 0.9303, G loss: 1.3252\n",
      "[1564/1600] D loss: 1.0169, G loss: 0.7972\n",
      "train error: \n",
      " D loss: 1.027923, G loss: 1.648227, D accuracy: 66.0%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342948, G loss: 1.872789, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 54.5% \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6843, G loss: 1.9370\n",
      "[124/1600] D loss: 1.4841, G loss: 0.8419\n",
      "[244/1600] D loss: 1.0917, G loss: 1.2619\n",
      "[364/1600] D loss: 1.3837, G loss: 0.5564\n",
      "[484/1600] D loss: 0.9510, G loss: 1.5230\n",
      "[604/1600] D loss: 1.4891, G loss: 0.7367\n",
      "[724/1600] D loss: 0.7926, G loss: 1.2637\n",
      "[844/1600] D loss: 1.1629, G loss: 1.2807\n",
      "[964/1600] D loss: 1.1370, G loss: 2.0661\n",
      "[1084/1600] D loss: 1.0364, G loss: 1.9879\n",
      "[1204/1600] D loss: 1.2251, G loss: 1.1316\n",
      "[1324/1600] D loss: 1.0608, G loss: 1.4978\n",
      "[1444/1600] D loss: 1.3989, G loss: 0.6884\n",
      "[1564/1600] D loss: 1.0638, G loss: 1.3511\n",
      "train error: \n",
      " D loss: 1.052903, G loss: 1.527169, D accuracy: 65.2%, cell accuracy: 99.0%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329544, G loss: 1.733980, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 53.8% \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5936, G loss: 1.8055\n",
      "[124/1600] D loss: 0.9846, G loss: 1.4391\n",
      "[244/1600] D loss: 1.0959, G loss: 1.7726\n",
      "[364/1600] D loss: 1.3929, G loss: 0.6404\n",
      "[484/1600] D loss: 1.2996, G loss: 1.1767\n",
      "[604/1600] D loss: 1.1043, G loss: 1.0144\n",
      "[724/1600] D loss: 1.0405, G loss: 1.6366\n",
      "[844/1600] D loss: 0.7425, G loss: 2.4776\n",
      "[964/1600] D loss: 0.7150, G loss: 2.3061\n",
      "[1084/1600] D loss: 1.4201, G loss: 0.6889\n",
      "[1204/1600] D loss: 0.7187, G loss: 2.7848\n",
      "[1324/1600] D loss: 1.0834, G loss: 2.1399\n",
      "[1444/1600] D loss: 1.0349, G loss: 1.5249\n",
      "[1564/1600] D loss: 0.9960, G loss: 1.4467\n",
      "train error: \n",
      " D loss: 1.007501, G loss: 1.651717, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320251, G loss: 1.887688, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3815, G loss: 0.8576\n",
      "[124/1600] D loss: 0.7939, G loss: 2.1087\n",
      "[244/1600] D loss: 0.7267, G loss: 3.0856\n",
      "[364/1600] D loss: 1.1048, G loss: 1.3610\n",
      "[484/1600] D loss: 1.1502, G loss: 0.9282\n",
      "[604/1600] D loss: 0.9149, G loss: 1.6904\n",
      "[724/1600] D loss: 1.4048, G loss: 0.6364\n",
      "[844/1600] D loss: 1.4550, G loss: 0.6379\n",
      "[964/1600] D loss: 1.0447, G loss: 1.7021\n",
      "[1084/1600] D loss: 1.2073, G loss: 1.1293\n",
      "[1204/1600] D loss: 0.6534, G loss: 3.2301\n",
      "[1324/1600] D loss: 1.4158, G loss: 0.9726\n",
      "[1444/1600] D loss: 1.0892, G loss: 1.1491\n",
      "[1564/1600] D loss: 0.7459, G loss: 2.0825\n",
      "train error: \n",
      " D loss: 1.040090, G loss: 1.314279, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 61.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324693, G loss: 1.561854, D accuracy: 63.9%, cell accuracy: 98.8%, board accuracy: 52.2% \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7676, G loss: 1.5754\n",
      "[124/1600] D loss: 1.3909, G loss: 0.7603\n",
      "[244/1600] D loss: 1.3777, G loss: 0.5945\n",
      "[364/1600] D loss: 1.3992, G loss: 0.6150\n",
      "[484/1600] D loss: 1.0509, G loss: 1.2796\n",
      "[604/1600] D loss: 0.7821, G loss: 1.5149\n",
      "[724/1600] D loss: 0.4112, G loss: 2.8389\n",
      "[844/1600] D loss: 0.7410, G loss: 1.5557\n",
      "[964/1600] D loss: 2.2240, G loss: 1.0132\n",
      "[1084/1600] D loss: 1.2240, G loss: 1.1038\n",
      "[1204/1600] D loss: 1.4396, G loss: 0.6370\n",
      "[1324/1600] D loss: 0.7220, G loss: 2.1382\n",
      "[1444/1600] D loss: 1.2855, G loss: 0.9241\n",
      "[1564/1600] D loss: 0.5050, G loss: 2.2548\n",
      "train error: \n",
      " D loss: 1.038711, G loss: 1.310453, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 59.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314813, G loss: 1.569243, D accuracy: 63.4%, cell accuracy: 98.8%, board accuracy: 51.2% \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4331, G loss: 0.5759\n",
      "[124/1600] D loss: 1.3928, G loss: 0.7415\n",
      "[244/1600] D loss: 1.1609, G loss: 0.8635\n",
      "[364/1600] D loss: 0.9909, G loss: 1.1695\n",
      "[484/1600] D loss: 1.5307, G loss: 2.7117\n",
      "[604/1600] D loss: 1.4308, G loss: 0.5794\n",
      "[724/1600] D loss: 1.0774, G loss: 1.3792\n",
      "[844/1600] D loss: 1.1897, G loss: 1.1421\n",
      "[964/1600] D loss: 1.3135, G loss: 1.3555\n",
      "[1084/1600] D loss: 1.2829, G loss: 0.8415\n",
      "[1204/1600] D loss: 1.3985, G loss: 0.8875\n",
      "[1324/1600] D loss: 0.3908, G loss: 2.2663\n",
      "[1444/1600] D loss: 1.4479, G loss: 0.5588\n",
      "[1564/1600] D loss: 0.3745, G loss: 2.8266\n",
      "train error: \n",
      " D loss: 1.013506, G loss: 1.689050, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341235, G loss: 1.954779, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0240, G loss: 1.4061\n",
      "[124/1600] D loss: 1.1145, G loss: 1.4724\n",
      "[244/1600] D loss: 0.8278, G loss: 1.5202\n",
      "[364/1600] D loss: 0.7132, G loss: 2.0763\n",
      "[484/1600] D loss: 0.9544, G loss: 2.0477\n",
      "[604/1600] D loss: 0.9346, G loss: 1.7026\n",
      "[724/1600] D loss: 1.3546, G loss: 0.6539\n",
      "[844/1600] D loss: 1.1014, G loss: 1.5487\n",
      "[964/1600] D loss: 0.8049, G loss: 1.2616\n",
      "[1084/1600] D loss: 0.9877, G loss: 1.1148\n",
      "[1204/1600] D loss: 0.7028, G loss: 2.0120\n",
      "[1324/1600] D loss: 1.0859, G loss: 1.2050\n",
      "[1444/1600] D loss: 0.5050, G loss: 2.4351\n",
      "[1564/1600] D loss: 1.4353, G loss: 0.6417\n",
      "train error: \n",
      " D loss: 1.010456, G loss: 1.679641, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 59.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359814, G loss: 1.905013, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3598, G loss: 1.0476\n",
      "[124/1600] D loss: 0.6970, G loss: 2.5309\n",
      "[244/1600] D loss: 1.3875, G loss: 0.6462\n",
      "[364/1600] D loss: 0.7549, G loss: 1.8022\n",
      "[484/1600] D loss: 0.9111, G loss: 2.3148\n",
      "[604/1600] D loss: 1.4159, G loss: 0.5249\n",
      "[724/1600] D loss: 1.0727, G loss: 2.4110\n",
      "[844/1600] D loss: 1.1281, G loss: 1.0910\n",
      "[964/1600] D loss: 1.4155, G loss: 0.6516\n",
      "[1084/1600] D loss: 1.0280, G loss: 1.4326\n",
      "[1204/1600] D loss: 1.5128, G loss: 0.6421\n",
      "[1324/1600] D loss: 1.1766, G loss: 1.8151\n",
      "[1444/1600] D loss: 1.0942, G loss: 1.3390\n",
      "[1564/1600] D loss: 0.6532, G loss: 2.7339\n",
      "train error: \n",
      " D loss: 1.025349, G loss: 1.463939, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 59.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303136, G loss: 1.728171, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0621, G loss: 1.5904\n",
      "[124/1600] D loss: 1.0637, G loss: 1.3282\n",
      "[244/1600] D loss: 1.2351, G loss: 1.0340\n",
      "[364/1600] D loss: 1.0773, G loss: 1.3509\n",
      "[484/1600] D loss: 1.5033, G loss: 0.6360\n",
      "[604/1600] D loss: 0.9374, G loss: 1.8585\n",
      "[724/1600] D loss: 0.8018, G loss: 1.5849\n",
      "[844/1600] D loss: 0.3937, G loss: 2.8387\n",
      "[964/1600] D loss: 0.6829, G loss: 2.6024\n",
      "[1084/1600] D loss: 1.1648, G loss: 0.9995\n",
      "[1204/1600] D loss: 0.7297, G loss: 2.7065\n",
      "[1324/1600] D loss: 0.9596, G loss: 1.6553\n",
      "[1444/1600] D loss: 1.4061, G loss: 0.7761\n",
      "[1564/1600] D loss: 1.2306, G loss: 0.7323\n",
      "train error: \n",
      " D loss: 1.024762, G loss: 1.459891, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 61.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346018, G loss: 1.707983, D accuracy: 62.9%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7583, G loss: 1.7515\n",
      "[124/1600] D loss: 0.8058, G loss: 1.7966\n",
      "[244/1600] D loss: 0.7109, G loss: 2.1688\n",
      "[364/1600] D loss: 1.0298, G loss: 2.1718\n",
      "[484/1600] D loss: 1.1297, G loss: 1.5664\n",
      "[604/1600] D loss: 0.7787, G loss: 2.2736\n",
      "[724/1600] D loss: 1.1085, G loss: 0.9981\n",
      "[844/1600] D loss: 1.0870, G loss: 1.9157\n",
      "[964/1600] D loss: 1.1420, G loss: 1.2660\n",
      "[1084/1600] D loss: 1.1802, G loss: 0.9218\n",
      "[1204/1600] D loss: 1.1146, G loss: 1.6926\n",
      "[1324/1600] D loss: 1.0746, G loss: 1.0907\n",
      "[1444/1600] D loss: 1.1041, G loss: 1.8870\n",
      "[1564/1600] D loss: 0.5327, G loss: 3.2343\n",
      "train error: \n",
      " D loss: 1.002942, G loss: 1.538224, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 62.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351114, G loss: 1.750146, D accuracy: 62.9%, cell accuracy: 98.9%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3671, G loss: 0.6815\n",
      "[124/1600] D loss: 0.7674, G loss: 1.6712\n",
      "[244/1600] D loss: 0.7204, G loss: 2.2920\n",
      "[364/1600] D loss: 1.0827, G loss: 1.7815\n",
      "[484/1600] D loss: 0.5232, G loss: 2.6146\n",
      "[604/1600] D loss: 1.0588, G loss: 1.4794\n",
      "[724/1600] D loss: 1.1773, G loss: 0.8673\n",
      "[844/1600] D loss: 1.2042, G loss: 1.2914\n",
      "[964/1600] D loss: 0.9847, G loss: 1.4955\n",
      "[1084/1600] D loss: 1.0084, G loss: 1.3936\n",
      "[1204/1600] D loss: 0.9125, G loss: 1.0590\n",
      "[1324/1600] D loss: 0.1568, G loss: 3.8272\n",
      "[1444/1600] D loss: 1.2689, G loss: 0.8715\n",
      "[1564/1600] D loss: 0.5780, G loss: 2.6094\n",
      "train error: \n",
      " D loss: 1.010911, G loss: 1.639201, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338520, G loss: 1.949509, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4386, G loss: 0.7502\n",
      "[124/1600] D loss: 1.0515, G loss: 1.3716\n",
      "[244/1600] D loss: 1.0474, G loss: 1.6114\n",
      "[364/1600] D loss: 1.2517, G loss: 0.6942\n",
      "[484/1600] D loss: 1.0718, G loss: 1.2347\n",
      "[604/1600] D loss: 1.0909, G loss: 1.3414\n",
      "[724/1600] D loss: 1.0713, G loss: 1.1608\n",
      "[844/1600] D loss: 0.8413, G loss: 1.4227\n",
      "[964/1600] D loss: 1.0500, G loss: 1.5942\n",
      "[1084/1600] D loss: 1.0386, G loss: 1.4700\n",
      "[1204/1600] D loss: 1.1517, G loss: 2.1485\n",
      "[1324/1600] D loss: 0.7446, G loss: 1.7431\n",
      "[1444/1600] D loss: 1.1185, G loss: 0.9435\n",
      "[1564/1600] D loss: 0.7030, G loss: 2.8054\n",
      "train error: \n",
      " D loss: 1.017490, G loss: 1.501538, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355646, G loss: 1.724195, D accuracy: 61.5%, cell accuracy: 98.9%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7091, G loss: 2.3724\n",
      "[124/1600] D loss: 1.0479, G loss: 1.6692\n",
      "[244/1600] D loss: 1.1189, G loss: 0.8489\n",
      "[364/1600] D loss: 1.4300, G loss: 0.7067\n",
      "[484/1600] D loss: 0.7445, G loss: 2.6797\n",
      "[604/1600] D loss: 0.5947, G loss: 2.2467\n",
      "[724/1600] D loss: 1.4343, G loss: 0.6453\n",
      "[844/1600] D loss: 1.4257, G loss: 0.8238\n",
      "[964/1600] D loss: 0.6903, G loss: 2.6476\n",
      "[1084/1600] D loss: 0.7842, G loss: 1.8263\n",
      "[1204/1600] D loss: 1.1812, G loss: 1.0132\n",
      "[1324/1600] D loss: 1.2082, G loss: 0.8343\n",
      "[1444/1600] D loss: 1.2359, G loss: 1.1737\n",
      "[1564/1600] D loss: 0.7666, G loss: 2.8463\n",
      "train error: \n",
      " D loss: 1.019247, G loss: 1.555524, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341843, G loss: 1.778076, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2930, G loss: 0.7567\n",
      "[124/1600] D loss: 1.1941, G loss: 1.0432\n",
      "[244/1600] D loss: 1.0574, G loss: 1.4077\n",
      "[364/1600] D loss: 1.3297, G loss: 0.9052\n",
      "[484/1600] D loss: 1.1641, G loss: 0.9744\n",
      "[604/1600] D loss: 1.0934, G loss: 1.5332\n",
      "[724/1600] D loss: 0.8720, G loss: 1.7507\n",
      "[844/1600] D loss: 1.0819, G loss: 1.0982\n",
      "[964/1600] D loss: 0.6706, G loss: 1.7164\n",
      "[1084/1600] D loss: 1.1441, G loss: 1.1485\n",
      "[1204/1600] D loss: 0.7767, G loss: 1.5562\n",
      "[1324/1600] D loss: 0.9386, G loss: 1.3910\n",
      "[1444/1600] D loss: 1.0446, G loss: 2.0015\n",
      "[1564/1600] D loss: 0.8275, G loss: 1.7592\n",
      "train error: \n",
      " D loss: 1.029380, G loss: 1.369376, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 60.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321394, G loss: 1.636286, D accuracy: 63.1%, cell accuracy: 98.8%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0114, G loss: 1.5759\n",
      "[124/1600] D loss: 0.0358, G loss: 4.1169\n",
      "[244/1600] D loss: 0.4034, G loss: 2.9953\n",
      "[364/1600] D loss: 1.3316, G loss: 0.7142\n",
      "[484/1600] D loss: 1.0652, G loss: 1.5555\n",
      "[604/1600] D loss: 1.4171, G loss: 0.5889\n",
      "[724/1600] D loss: 1.4305, G loss: 0.6929\n",
      "[844/1600] D loss: 1.3513, G loss: 0.6121\n",
      "[964/1600] D loss: 0.6974, G loss: 2.4100\n",
      "[1084/1600] D loss: 0.8125, G loss: 2.2000\n",
      "[1204/1600] D loss: 0.8526, G loss: 1.9009\n",
      "[1324/1600] D loss: 1.0792, G loss: 1.6787\n",
      "[1444/1600] D loss: 1.1375, G loss: 0.8954\n",
      "[1564/1600] D loss: 1.6818, G loss: 0.4123\n",
      "train error: \n",
      " D loss: 1.029043, G loss: 1.449390, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 60.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316246, G loss: 1.693482, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 54.5% \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0435, G loss: 1.9222\n",
      "[124/1600] D loss: 1.3686, G loss: 0.7440\n",
      "[244/1600] D loss: 1.3183, G loss: 0.7261\n",
      "[364/1600] D loss: 0.7167, G loss: 2.7791\n",
      "[484/1600] D loss: 0.9834, G loss: 0.8791\n",
      "[604/1600] D loss: 1.0932, G loss: 1.2095\n",
      "[724/1600] D loss: 1.1242, G loss: 1.1844\n",
      "[844/1600] D loss: 0.8184, G loss: 2.2157\n",
      "[964/1600] D loss: 0.7100, G loss: 2.2111\n",
      "[1084/1600] D loss: 1.4820, G loss: 0.8472\n",
      "[1204/1600] D loss: 0.7895, G loss: 2.4187\n",
      "[1324/1600] D loss: 0.3698, G loss: 3.4217\n",
      "[1444/1600] D loss: 1.0335, G loss: 1.9692\n",
      "[1564/1600] D loss: 0.6852, G loss: 2.4179\n",
      "train error: \n",
      " D loss: 1.051523, G loss: 1.502156, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 59.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396882, G loss: 1.701616, D accuracy: 61.5%, cell accuracy: 98.8%, board accuracy: 52.8% \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3507, G loss: 0.7501\n",
      "[124/1600] D loss: 1.4039, G loss: 0.6258\n",
      "[244/1600] D loss: 1.1641, G loss: 1.0217\n",
      "[364/1600] D loss: 1.0262, G loss: 1.3285\n",
      "[484/1600] D loss: 0.8459, G loss: 1.6676\n",
      "[604/1600] D loss: 0.8822, G loss: 1.3536\n",
      "[724/1600] D loss: 1.4215, G loss: 0.6794\n",
      "[844/1600] D loss: 1.2123, G loss: 1.4220\n",
      "[964/1600] D loss: 1.0883, G loss: 1.0373\n",
      "[1084/1600] D loss: 0.8663, G loss: 1.5512\n",
      "[1204/1600] D loss: 0.5409, G loss: 2.0158\n",
      "[1324/1600] D loss: 0.8349, G loss: 2.6008\n",
      "[1444/1600] D loss: 0.9474, G loss: 1.8910\n",
      "[1564/1600] D loss: 0.7290, G loss: 2.7468\n",
      "train error: \n",
      " D loss: 0.999311, G loss: 1.519627, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312541, G loss: 1.767255, D accuracy: 63.2%, cell accuracy: 98.8%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2369, G loss: 0.7979\n",
      "[124/1600] D loss: 1.0736, G loss: 1.3597\n",
      "[244/1600] D loss: 1.0375, G loss: 2.2167\n",
      "[364/1600] D loss: 0.8886, G loss: 1.9822\n",
      "[484/1600] D loss: 1.4074, G loss: 0.5489\n",
      "[604/1600] D loss: 0.7796, G loss: 1.4342\n",
      "[724/1600] D loss: 1.5316, G loss: 0.4556\n",
      "[844/1600] D loss: 1.4131, G loss: 0.6472\n",
      "[964/1600] D loss: 1.2495, G loss: 1.1385\n",
      "[1084/1600] D loss: 1.4065, G loss: 0.7384\n",
      "[1204/1600] D loss: 0.6831, G loss: 2.6560\n",
      "[1324/1600] D loss: 1.0748, G loss: 1.6870\n",
      "[1444/1600] D loss: 1.3231, G loss: 1.6282\n",
      "[1564/1600] D loss: 0.5207, G loss: 2.5860\n",
      "train error: \n",
      " D loss: 1.022749, G loss: 1.743905, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 62.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390359, G loss: 1.946427, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7073, G loss: 2.4415\n",
      "[124/1600] D loss: 1.1042, G loss: 0.9401\n",
      "[244/1600] D loss: 0.8235, G loss: 1.6553\n",
      "[364/1600] D loss: 1.0686, G loss: 1.3316\n",
      "[484/1600] D loss: 1.3952, G loss: 0.7470\n",
      "[604/1600] D loss: 1.1439, G loss: 0.8628\n",
      "[724/1600] D loss: 1.1502, G loss: 1.2230\n",
      "[844/1600] D loss: 0.7511, G loss: 2.2345\n",
      "[964/1600] D loss: 0.5317, G loss: 2.5452\n",
      "[1084/1600] D loss: 0.8310, G loss: 1.5877\n",
      "[1204/1600] D loss: 0.5831, G loss: 3.2155\n",
      "[1324/1600] D loss: 1.4050, G loss: 0.6399\n",
      "[1444/1600] D loss: 1.4805, G loss: 0.6470\n",
      "[1564/1600] D loss: 1.4623, G loss: 0.4937\n",
      "train error: \n",
      " D loss: 1.041928, G loss: 1.838709, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 60.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409626, G loss: 2.099154, D accuracy: 61.4%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0743, G loss: 1.4846\n",
      "[124/1600] D loss: 1.2574, G loss: 0.6987\n",
      "[244/1600] D loss: 1.0844, G loss: 1.3186\n",
      "[364/1600] D loss: 1.0331, G loss: 1.6528\n",
      "[484/1600] D loss: 0.7454, G loss: 2.2516\n",
      "[604/1600] D loss: 1.0696, G loss: 1.5856\n",
      "[724/1600] D loss: 1.0868, G loss: 1.5095\n",
      "[844/1600] D loss: 0.7038, G loss: 2.3160\n",
      "[964/1600] D loss: 1.1165, G loss: 1.2240\n",
      "[1084/1600] D loss: 0.9621, G loss: 1.5439\n",
      "[1204/1600] D loss: 0.7155, G loss: 2.0311\n",
      "[1324/1600] D loss: 0.4179, G loss: 4.0430\n",
      "[1444/1600] D loss: 1.1565, G loss: 1.1300\n",
      "[1564/1600] D loss: 1.0452, G loss: 1.7999\n",
      "train error: \n",
      " D loss: 1.004595, G loss: 1.587740, D accuracy: 67.2%, cell accuracy: 99.0%, board accuracy: 61.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340207, G loss: 1.830371, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0396, G loss: 1.4280\n",
      "[124/1600] D loss: 1.4446, G loss: 0.5898\n",
      "[244/1600] D loss: 0.8833, G loss: 1.2013\n",
      "[364/1600] D loss: 1.0821, G loss: 1.3552\n",
      "[484/1600] D loss: 1.0175, G loss: 1.2739\n",
      "[604/1600] D loss: 1.0912, G loss: 1.9213\n",
      "[724/1600] D loss: 1.3140, G loss: 0.7734\n",
      "[844/1600] D loss: 1.4837, G loss: 0.5959\n",
      "[964/1600] D loss: 1.0494, G loss: 1.8028\n",
      "[1084/1600] D loss: 1.0799, G loss: 1.7262\n",
      "[1204/1600] D loss: 0.9406, G loss: 1.6657\n",
      "[1324/1600] D loss: 1.0636, G loss: 1.6429\n",
      "[1444/1600] D loss: 1.3483, G loss: 0.9436\n",
      "[1564/1600] D loss: 1.0749, G loss: 1.1338\n",
      "train error: \n",
      " D loss: 1.018548, G loss: 1.448278, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331890, G loss: 1.705341, D accuracy: 63.0%, cell accuracy: 98.9%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7233, G loss: 1.9186\n",
      "[124/1600] D loss: 0.8168, G loss: 2.0195\n",
      "[244/1600] D loss: 0.6978, G loss: 3.2621\n",
      "[364/1600] D loss: 1.3482, G loss: 0.6959\n",
      "[484/1600] D loss: 0.7110, G loss: 2.6108\n",
      "[604/1600] D loss: 1.1693, G loss: 1.1968\n",
      "[724/1600] D loss: 1.0711, G loss: 2.1943\n",
      "[844/1600] D loss: 1.1848, G loss: 0.9190\n",
      "[964/1600] D loss: 1.4111, G loss: 0.7200\n",
      "[1084/1600] D loss: 1.1126, G loss: 0.8650\n",
      "[1204/1600] D loss: 0.6896, G loss: 1.9863\n",
      "[1324/1600] D loss: 0.7580, G loss: 1.7376\n",
      "[1444/1600] D loss: 0.8031, G loss: 1.5434\n",
      "[1564/1600] D loss: 0.9267, G loss: 1.6107\n",
      "train error: \n",
      " D loss: 1.009324, G loss: 1.459160, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337120, G loss: 1.719680, D accuracy: 62.9%, cell accuracy: 98.8%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1124, G loss: 1.2839\n",
      "[124/1600] D loss: 1.0656, G loss: 1.4166\n",
      "[244/1600] D loss: 1.4241, G loss: 0.8328\n",
      "[364/1600] D loss: 0.7523, G loss: 1.8738\n",
      "[484/1600] D loss: 1.1565, G loss: 1.2484\n",
      "[604/1600] D loss: 1.4140, G loss: 0.6650\n",
      "[724/1600] D loss: 0.7010, G loss: 2.7389\n",
      "[844/1600] D loss: 1.0295, G loss: 1.5941\n",
      "[964/1600] D loss: 0.6605, G loss: 2.4636\n",
      "[1084/1600] D loss: 0.3696, G loss: 3.0785\n",
      "[1204/1600] D loss: 1.0333, G loss: 1.7700\n",
      "[1324/1600] D loss: 1.1311, G loss: 2.0242\n",
      "[1444/1600] D loss: 1.0976, G loss: 1.1767\n",
      "[1564/1600] D loss: 1.0644, G loss: 1.1172\n",
      "train error: \n",
      " D loss: 1.046906, G loss: 1.746627, D accuracy: 65.6%, cell accuracy: 99.0%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410085, G loss: 1.984227, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2082, G loss: 1.3443\n",
      "[124/1600] D loss: 0.0918, G loss: 3.2651\n",
      "[244/1600] D loss: 0.7200, G loss: 1.9470\n",
      "[364/1600] D loss: 0.6997, G loss: 2.6128\n",
      "[484/1600] D loss: 1.0921, G loss: 1.3303\n",
      "[604/1600] D loss: 1.1331, G loss: 1.2259\n",
      "[724/1600] D loss: 1.0895, G loss: 1.3894\n",
      "[844/1600] D loss: 0.9383, G loss: 1.3657\n",
      "[964/1600] D loss: 1.1170, G loss: 0.8553\n",
      "[1084/1600] D loss: 0.9890, G loss: 1.4092\n",
      "[1204/1600] D loss: 1.0467, G loss: 1.1289\n",
      "[1324/1600] D loss: 0.7643, G loss: 2.9078\n",
      "[1444/1600] D loss: 1.2786, G loss: 0.8416\n",
      "[1564/1600] D loss: 1.1366, G loss: 1.4551\n",
      "train error: \n",
      " D loss: 1.004250, G loss: 1.658112, D accuracy: 67.1%, cell accuracy: 99.0%, board accuracy: 58.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360389, G loss: 1.932878, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 51.2% \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0663, G loss: 1.5551\n",
      "[124/1600] D loss: 0.2948, G loss: 2.7309\n",
      "[244/1600] D loss: 1.1200, G loss: 1.5105\n",
      "[364/1600] D loss: 1.3788, G loss: 0.6697\n",
      "[484/1600] D loss: 0.8083, G loss: 1.7577\n",
      "[604/1600] D loss: 1.0120, G loss: 1.7819\n",
      "[724/1600] D loss: 0.7406, G loss: 1.7860\n",
      "[844/1600] D loss: 1.5603, G loss: 0.9391\n",
      "[964/1600] D loss: 0.7761, G loss: 1.8206\n",
      "[1084/1600] D loss: 1.0699, G loss: 1.0072\n",
      "[1204/1600] D loss: 1.4052, G loss: 0.6753\n",
      "[1324/1600] D loss: 0.2269, G loss: 3.3816\n",
      "[1444/1600] D loss: 1.2385, G loss: 0.8680\n",
      "[1564/1600] D loss: 0.7476, G loss: 3.2165\n",
      "train error: \n",
      " D loss: 1.001320, G loss: 1.693846, D accuracy: 66.9%, cell accuracy: 99.0%, board accuracy: 61.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363972, G loss: 1.944568, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4138, G loss: 0.9437\n",
      "[124/1600] D loss: 0.7151, G loss: 3.0361\n",
      "[244/1600] D loss: 1.4143, G loss: 0.7596\n",
      "[364/1600] D loss: 0.4004, G loss: 3.2964\n",
      "[484/1600] D loss: 0.9068, G loss: 1.6586\n",
      "[604/1600] D loss: 0.9431, G loss: 1.7980\n",
      "[724/1600] D loss: 1.1580, G loss: 0.7574\n",
      "[844/1600] D loss: 1.3943, G loss: 0.6364\n",
      "[964/1600] D loss: 1.0316, G loss: 1.1113\n",
      "[1084/1600] D loss: 1.0044, G loss: 1.6443\n",
      "[1204/1600] D loss: 0.6999, G loss: 3.3874\n",
      "[1324/1600] D loss: 1.0488, G loss: 2.2301\n",
      "[1444/1600] D loss: 1.0513, G loss: 1.3507\n",
      "[1564/1600] D loss: 1.0591, G loss: 1.3637\n",
      "train error: \n",
      " D loss: 0.995732, G loss: 1.528821, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 61.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328105, G loss: 1.806631, D accuracy: 62.5%, cell accuracy: 98.9%, board accuracy: 54.0% \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8149, G loss: 2.0528\n",
      "[124/1600] D loss: 1.4781, G loss: 0.5063\n",
      "[244/1600] D loss: 1.2549, G loss: 1.1016\n",
      "[364/1600] D loss: 0.8355, G loss: 1.8258\n",
      "[484/1600] D loss: 1.3577, G loss: 0.6160\n",
      "[604/1600] D loss: 1.4401, G loss: 0.9104\n",
      "[724/1600] D loss: 1.1817, G loss: 1.0299\n",
      "[844/1600] D loss: 1.0958, G loss: 1.3752\n",
      "[964/1600] D loss: 0.8231, G loss: 1.7305\n",
      "[1084/1600] D loss: 1.0538, G loss: 1.4800\n",
      "[1204/1600] D loss: 0.7413, G loss: 1.4960\n",
      "[1324/1600] D loss: 1.3649, G loss: 0.6747\n",
      "[1444/1600] D loss: 0.7643, G loss: 2.0787\n",
      "[1564/1600] D loss: 1.6567, G loss: 0.5591\n",
      "train error: \n",
      " D loss: 1.056074, G loss: 1.632603, D accuracy: 66.0%, cell accuracy: 99.0%, board accuracy: 61.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361432, G loss: 1.899690, D accuracy: 63.0%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7234, G loss: 2.4158\n",
      "[124/1600] D loss: 0.7195, G loss: 2.7612\n",
      "[244/1600] D loss: 1.0747, G loss: 1.6830\n",
      "[364/1600] D loss: 0.9062, G loss: 1.6959\n",
      "[484/1600] D loss: 1.4031, G loss: 0.6834\n",
      "[604/1600] D loss: 0.8432, G loss: 1.6304\n",
      "[724/1600] D loss: 1.0847, G loss: 1.6754\n",
      "[844/1600] D loss: 0.7380, G loss: 1.6618\n",
      "[964/1600] D loss: 0.6994, G loss: 3.2290\n",
      "[1084/1600] D loss: 1.0858, G loss: 1.2768\n",
      "[1204/1600] D loss: 0.4986, G loss: 2.4952\n",
      "[1324/1600] D loss: 1.3335, G loss: 0.8622\n",
      "[1444/1600] D loss: 0.7004, G loss: 2.1783\n",
      "[1564/1600] D loss: 0.6814, G loss: 2.6547\n",
      "train error: \n",
      " D loss: 1.004864, G loss: 1.534831, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317713, G loss: 1.827442, D accuracy: 63.9%, cell accuracy: 98.8%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7718, G loss: 2.3196\n",
      "[124/1600] D loss: 1.3976, G loss: 0.6087\n",
      "[244/1600] D loss: 1.3764, G loss: 1.0285\n",
      "[364/1600] D loss: 1.1140, G loss: 1.5305\n",
      "[484/1600] D loss: 1.0411, G loss: 1.4354\n",
      "[604/1600] D loss: 1.1122, G loss: 1.8140\n",
      "[724/1600] D loss: 1.0728, G loss: 1.6730\n",
      "[844/1600] D loss: 0.8723, G loss: 1.7733\n",
      "[964/1600] D loss: 0.7215, G loss: 2.4216\n",
      "[1084/1600] D loss: 1.3946, G loss: 0.6390\n",
      "[1204/1600] D loss: 1.4959, G loss: 0.6154\n",
      "[1324/1600] D loss: 0.4322, G loss: 2.0056\n",
      "[1444/1600] D loss: 0.5456, G loss: 2.2979\n",
      "[1564/1600] D loss: 0.2842, G loss: 4.8210\n",
      "train error: \n",
      " D loss: 1.007042, G loss: 1.458840, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341138, G loss: 1.724592, D accuracy: 62.9%, cell accuracy: 98.8%, board accuracy: 51.5% \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1026, G loss: 1.4337\n",
      "[124/1600] D loss: 1.0671, G loss: 1.4538\n",
      "[244/1600] D loss: 1.0684, G loss: 1.4715\n",
      "[364/1600] D loss: 1.4744, G loss: 0.8147\n",
      "[484/1600] D loss: 1.4086, G loss: 0.8440\n",
      "[604/1600] D loss: 0.7645, G loss: 3.1376\n",
      "[724/1600] D loss: 1.1691, G loss: 1.2512\n",
      "[844/1600] D loss: 1.0959, G loss: 1.6506\n",
      "[964/1600] D loss: 1.4589, G loss: 0.6150\n",
      "[1084/1600] D loss: 1.4669, G loss: 0.5755\n",
      "[1204/1600] D loss: 0.9216, G loss: 2.0851\n",
      "[1324/1600] D loss: 0.5673, G loss: 2.6904\n",
      "[1444/1600] D loss: 0.6149, G loss: 2.0592\n",
      "[1564/1600] D loss: 1.4484, G loss: 0.7798\n",
      "train error: \n",
      " D loss: 0.992896, G loss: 1.537105, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 60.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341839, G loss: 1.758300, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7556, G loss: 2.0047\n",
      "[124/1600] D loss: 1.0244, G loss: 1.7139\n",
      "[244/1600] D loss: 1.1041, G loss: 1.4929\n",
      "[364/1600] D loss: 0.7367, G loss: 2.1140\n",
      "[484/1600] D loss: 1.5659, G loss: 1.0680\n",
      "[604/1600] D loss: 1.0897, G loss: 1.4221\n",
      "[724/1600] D loss: 1.1484, G loss: 0.9101\n",
      "[844/1600] D loss: 1.1502, G loss: 2.3445\n",
      "[964/1600] D loss: 1.3902, G loss: 0.6362\n",
      "[1084/1600] D loss: 1.3954, G loss: 0.6937\n",
      "[1204/1600] D loss: 1.2597, G loss: 0.7735\n",
      "[1324/1600] D loss: 1.4794, G loss: 0.9394\n",
      "[1444/1600] D loss: 1.2319, G loss: 0.8467\n",
      "[1564/1600] D loss: 0.4473, G loss: 2.4733\n",
      "train error: \n",
      " D loss: 1.006811, G loss: 1.541563, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 60.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344563, G loss: 1.816015, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3371, G loss: 0.7249\n",
      "[124/1600] D loss: 0.6737, G loss: 3.4849\n",
      "[244/1600] D loss: 0.7360, G loss: 2.8544\n",
      "[364/1600] D loss: 1.3941, G loss: 0.6219\n",
      "[484/1600] D loss: 1.0963, G loss: 1.1782\n",
      "[604/1600] D loss: 1.1009, G loss: 0.9764\n",
      "[724/1600] D loss: 1.1203, G loss: 1.5182\n",
      "[844/1600] D loss: 1.2381, G loss: 1.1327\n",
      "[964/1600] D loss: 1.1481, G loss: 1.0815\n",
      "[1084/1600] D loss: 1.1541, G loss: 0.8738\n",
      "[1204/1600] D loss: 0.3974, G loss: 2.7757\n",
      "[1324/1600] D loss: 1.0775, G loss: 1.1867\n",
      "[1444/1600] D loss: 0.7098, G loss: 2.9938\n",
      "[1564/1600] D loss: 1.0689, G loss: 1.5969\n",
      "train error: \n",
      " D loss: 1.025219, G loss: 1.466478, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363860, G loss: 1.706762, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 57.8% \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4160, G loss: 0.5605\n",
      "[124/1600] D loss: 1.0522, G loss: 1.4951\n",
      "[244/1600] D loss: 1.1021, G loss: 1.5810\n",
      "[364/1600] D loss: 1.0841, G loss: 0.7687\n",
      "[484/1600] D loss: 1.4902, G loss: 1.1328\n",
      "[604/1600] D loss: 0.8396, G loss: 1.2887\n",
      "[724/1600] D loss: 0.4480, G loss: 2.2775\n",
      "[844/1600] D loss: 1.1815, G loss: 0.8426\n",
      "[964/1600] D loss: 1.0554, G loss: 2.0606\n",
      "[1084/1600] D loss: 1.3938, G loss: 0.6957\n",
      "[1204/1600] D loss: 1.1066, G loss: 0.8973\n",
      "[1324/1600] D loss: 1.3522, G loss: 0.7020\n",
      "[1444/1600] D loss: 1.4318, G loss: 0.6627\n",
      "[1564/1600] D loss: 0.7226, G loss: 2.5475\n",
      "train error: \n",
      " D loss: 0.999984, G loss: 1.543579, D accuracy: 67.4%, cell accuracy: 99.0%, board accuracy: 61.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345927, G loss: 1.761243, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7312, G loss: 2.4824\n",
      "[124/1600] D loss: 1.1716, G loss: 1.3876\n",
      "[244/1600] D loss: 1.4137, G loss: 0.6404\n",
      "[364/1600] D loss: 0.5113, G loss: 2.2981\n",
      "[484/1600] D loss: 0.4571, G loss: 2.8635\n",
      "[604/1600] D loss: 0.9753, G loss: 1.4221\n",
      "[724/1600] D loss: 0.9007, G loss: 1.4440\n",
      "[844/1600] D loss: 1.0691, G loss: 1.7860\n",
      "[964/1600] D loss: 0.7700, G loss: 2.1524\n",
      "[1084/1600] D loss: 0.1769, G loss: 2.5891\n",
      "[1204/1600] D loss: 1.4249, G loss: 0.9447\n",
      "[1324/1600] D loss: 1.2074, G loss: 1.4665\n",
      "[1444/1600] D loss: 1.0601, G loss: 1.6910\n",
      "[1564/1600] D loss: 1.1822, G loss: 1.4055\n",
      "train error: \n",
      " D loss: 1.029386, G loss: 1.779646, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 59.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417131, G loss: 1.989110, D accuracy: 61.5%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7960, G loss: 2.9753\n",
      "[124/1600] D loss: 1.0949, G loss: 1.1234\n",
      "[244/1600] D loss: 1.1156, G loss: 1.2344\n",
      "[364/1600] D loss: 1.0662, G loss: 0.9809\n",
      "[484/1600] D loss: 1.0506, G loss: 1.5710\n",
      "[604/1600] D loss: 1.4299, G loss: 0.7378\n",
      "[724/1600] D loss: 1.0605, G loss: 1.6471\n",
      "[844/1600] D loss: 1.0649, G loss: 1.5155\n",
      "[964/1600] D loss: 1.4199, G loss: 0.9076\n",
      "[1084/1600] D loss: 1.4204, G loss: 0.6531\n",
      "[1204/1600] D loss: 1.0457, G loss: 1.3475\n",
      "[1324/1600] D loss: 1.0812, G loss: 1.0267\n",
      "[1444/1600] D loss: 1.3266, G loss: 1.0402\n",
      "[1564/1600] D loss: 0.7197, G loss: 2.2399\n",
      "train error: \n",
      " D loss: 1.016771, G loss: 1.659549, D accuracy: 65.8%, cell accuracy: 99.0%, board accuracy: 61.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408699, G loss: 1.876710, D accuracy: 61.6%, cell accuracy: 98.9%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0919, G loss: 2.0567\n",
      "[124/1600] D loss: 1.0553, G loss: 1.6708\n",
      "[244/1600] D loss: 0.7082, G loss: 2.7304\n",
      "[364/1600] D loss: 1.0929, G loss: 1.3433\n",
      "[484/1600] D loss: 0.7221, G loss: 2.1364\n",
      "[604/1600] D loss: 0.7034, G loss: 2.5005\n",
      "[724/1600] D loss: 1.1240, G loss: 1.4808\n",
      "[844/1600] D loss: 0.4555, G loss: 2.1429\n",
      "[964/1600] D loss: 0.5960, G loss: 2.1355\n",
      "[1084/1600] D loss: 1.1002, G loss: 1.4214\n",
      "[1204/1600] D loss: 0.7627, G loss: 2.5087\n",
      "[1324/1600] D loss: 0.9327, G loss: 1.4115\n",
      "[1444/1600] D loss: 0.1723, G loss: 3.4558\n",
      "[1564/1600] D loss: 1.4177, G loss: 0.7699\n",
      "train error: \n",
      " D loss: 1.012539, G loss: 1.556200, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366560, G loss: 1.791616, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7340, G loss: 2.5118\n",
      "[124/1600] D loss: 1.0575, G loss: 1.4530\n",
      "[244/1600] D loss: 1.1099, G loss: 1.7174\n",
      "[364/1600] D loss: 1.1332, G loss: 1.3159\n",
      "[484/1600] D loss: 0.9420, G loss: 1.5800\n",
      "[604/1600] D loss: 0.0324, G loss: 3.9363\n",
      "[724/1600] D loss: 1.4178, G loss: 0.5996\n",
      "[844/1600] D loss: 1.1114, G loss: 1.6326\n",
      "[964/1600] D loss: 1.2396, G loss: 0.8230\n",
      "[1084/1600] D loss: 0.7623, G loss: 1.8794\n",
      "[1204/1600] D loss: 1.4329, G loss: 0.5659\n",
      "[1324/1600] D loss: 0.7769, G loss: 2.4921\n",
      "[1444/1600] D loss: 1.3557, G loss: 0.9454\n",
      "[1564/1600] D loss: 0.7784, G loss: 2.0672\n",
      "train error: \n",
      " D loss: 1.030315, G loss: 1.554699, D accuracy: 65.9%, cell accuracy: 99.0%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368385, G loss: 1.783386, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 53.8% \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7133, G loss: 2.2198\n",
      "[124/1600] D loss: 0.9582, G loss: 1.5084\n",
      "[244/1600] D loss: 1.0656, G loss: 1.3696\n",
      "[364/1600] D loss: 1.1102, G loss: 0.9972\n",
      "[484/1600] D loss: 1.1085, G loss: 1.0055\n",
      "[604/1600] D loss: 1.1288, G loss: 1.2890\n",
      "[724/1600] D loss: 1.1906, G loss: 0.7933\n",
      "[844/1600] D loss: 1.1054, G loss: 1.3341\n",
      "[964/1600] D loss: 1.1319, G loss: 0.9634\n",
      "[1084/1600] D loss: 0.7492, G loss: 1.7844\n",
      "[1204/1600] D loss: 1.4486, G loss: 0.9415\n",
      "[1324/1600] D loss: 0.7075, G loss: 3.1316\n",
      "[1444/1600] D loss: 1.3432, G loss: 0.7597\n",
      "[1564/1600] D loss: 1.0172, G loss: 1.9000\n",
      "train error: \n",
      " D loss: 1.010085, G loss: 1.559574, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 59.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365610, G loss: 1.800414, D accuracy: 61.9%, cell accuracy: 98.9%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0506, G loss: 1.3788\n",
      "[124/1600] D loss: 1.2317, G loss: 0.9469\n",
      "[244/1600] D loss: 0.4722, G loss: 2.4701\n",
      "[364/1600] D loss: 0.8404, G loss: 2.9379\n",
      "[484/1600] D loss: 0.7344, G loss: 2.5318\n",
      "[604/1600] D loss: 0.8918, G loss: 1.9335\n",
      "[724/1600] D loss: 1.6340, G loss: 0.9709\n",
      "[844/1600] D loss: 0.8009, G loss: 1.4356\n",
      "[964/1600] D loss: 0.1276, G loss: 3.0897\n",
      "[1084/1600] D loss: 0.5309, G loss: 3.2788\n",
      "[1204/1600] D loss: 1.4838, G loss: 0.6104\n",
      "[1324/1600] D loss: 0.7037, G loss: 2.6976\n",
      "[1444/1600] D loss: 1.0484, G loss: 1.5298\n",
      "[1564/1600] D loss: 0.9499, G loss: 1.3561\n",
      "train error: \n",
      " D loss: 1.038627, G loss: 1.411228, D accuracy: 65.5%, cell accuracy: 99.0%, board accuracy: 60.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327552, G loss: 1.698314, D accuracy: 62.7%, cell accuracy: 98.8%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3695, G loss: 3.5432\n",
      "[124/1600] D loss: 0.7774, G loss: 1.7652\n",
      "[244/1600] D loss: 1.2239, G loss: 1.2170\n",
      "[364/1600] D loss: 1.3819, G loss: 0.7913\n",
      "[484/1600] D loss: 0.7823, G loss: 2.2490\n",
      "[604/1600] D loss: 1.0400, G loss: 1.5501\n",
      "[724/1600] D loss: 0.7490, G loss: 2.9054\n",
      "[844/1600] D loss: 1.0786, G loss: 1.2460\n",
      "[964/1600] D loss: 0.9421, G loss: 2.0344\n",
      "[1084/1600] D loss: 1.1011, G loss: 1.4439\n",
      "[1204/1600] D loss: 1.2665, G loss: 0.6873\n",
      "[1324/1600] D loss: 1.3507, G loss: 0.8855\n",
      "[1444/1600] D loss: 0.6527, G loss: 2.7435\n",
      "[1564/1600] D loss: 0.7836, G loss: 1.6864\n",
      "train error: \n",
      " D loss: 1.029472, G loss: 1.507061, D accuracy: 66.3%, cell accuracy: 98.9%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380325, G loss: 1.746964, D accuracy: 61.3%, cell accuracy: 98.7%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7336, G loss: 2.6195\n",
      "[124/1600] D loss: 1.1090, G loss: 1.5546\n",
      "[244/1600] D loss: 1.3035, G loss: 0.6845\n",
      "[364/1600] D loss: 1.0124, G loss: 1.8662\n",
      "[484/1600] D loss: 0.4246, G loss: 2.5964\n",
      "[604/1600] D loss: 0.9880, G loss: 2.0695\n",
      "[724/1600] D loss: 1.0126, G loss: 1.9412\n",
      "[844/1600] D loss: 1.3317, G loss: 0.9047\n",
      "[964/1600] D loss: 0.5941, G loss: 1.7606\n",
      "[1084/1600] D loss: 1.1164, G loss: 0.9840\n",
      "[1204/1600] D loss: 1.9364, G loss: 0.5549\n",
      "[1324/1600] D loss: 0.4973, G loss: 2.4253\n",
      "[1444/1600] D loss: 1.5128, G loss: 1.0771\n",
      "[1564/1600] D loss: 1.1855, G loss: 1.3585\n",
      "train error: \n",
      " D loss: 1.033355, G loss: 1.648214, D accuracy: 66.0%, cell accuracy: 99.0%, board accuracy: 60.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364752, G loss: 1.798703, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 55.2% \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9905, G loss: 1.8365\n",
      "[124/1600] D loss: 0.6211, G loss: 2.4649\n",
      "[244/1600] D loss: 0.9714, G loss: 1.9961\n",
      "[364/1600] D loss: 0.7539, G loss: 2.3339\n",
      "[484/1600] D loss: 1.3661, G loss: 0.6993\n",
      "[604/1600] D loss: 1.6966, G loss: 0.7955\n",
      "[724/1600] D loss: 1.0804, G loss: 0.9511\n",
      "[844/1600] D loss: 1.3591, G loss: 0.7564\n",
      "[964/1600] D loss: 1.0827, G loss: 1.9356\n",
      "[1084/1600] D loss: 0.7293, G loss: 2.0494\n",
      "[1204/1600] D loss: 0.9919, G loss: 1.4285\n",
      "[1324/1600] D loss: 1.0353, G loss: 1.1118\n",
      "[1444/1600] D loss: 0.7121, G loss: 2.5003\n",
      "[1564/1600] D loss: 0.5213, G loss: 3.5366\n",
      "train error: \n",
      " D loss: 1.038716, G loss: 1.947373, D accuracy: 65.9%, cell accuracy: 98.5%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337287, G loss: 2.103617, D accuracy: 62.7%, cell accuracy: 98.3%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3091, G loss: 2.0299\n",
      "[124/1600] D loss: 0.5616, G loss: 4.0333\n",
      "[244/1600] D loss: 0.7446, G loss: 2.8992\n",
      "[364/1600] D loss: 1.4781, G loss: 0.7829\n",
      "[484/1600] D loss: 1.0578, G loss: 1.8316\n",
      "[604/1600] D loss: 0.8989, G loss: 1.4499\n",
      "[724/1600] D loss: 0.7134, G loss: 2.2730\n",
      "[844/1600] D loss: 0.7950, G loss: 2.3537\n",
      "[964/1600] D loss: 1.1379, G loss: 0.7411\n",
      "[1084/1600] D loss: 0.4384, G loss: 2.9596\n",
      "[1204/1600] D loss: 0.7050, G loss: 2.6065\n",
      "[1324/1600] D loss: 0.7653, G loss: 1.9868\n",
      "[1444/1600] D loss: 0.7303, G loss: 2.3654\n",
      "[1564/1600] D loss: 0.5999, G loss: 2.3457\n",
      "train error: \n",
      " D loss: 1.033293, G loss: 1.793447, D accuracy: 65.9%, cell accuracy: 99.0%, board accuracy: 62.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393417, G loss: 1.950056, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4214, G loss: 0.8447\n",
      "[124/1600] D loss: 1.2203, G loss: 1.0126\n",
      "[244/1600] D loss: 0.8402, G loss: 1.2304\n",
      "[364/1600] D loss: 0.6337, G loss: 3.0819\n",
      "[484/1600] D loss: 1.4579, G loss: 0.6973\n",
      "[604/1600] D loss: 0.9381, G loss: 1.8681\n",
      "[724/1600] D loss: 1.0405, G loss: 2.3026\n",
      "[844/1600] D loss: 1.5557, G loss: 1.3448\n",
      "[964/1600] D loss: 0.7895, G loss: 2.4304\n",
      "[1084/1600] D loss: 1.4058, G loss: 0.6362\n",
      "[1204/1600] D loss: 1.0911, G loss: 0.9230\n",
      "[1324/1600] D loss: 1.3789, G loss: 0.9011\n",
      "[1444/1600] D loss: 1.0695, G loss: 1.9275\n",
      "[1564/1600] D loss: 1.0566, G loss: 1.3279\n",
      "train error: \n",
      " D loss: 1.017902, G loss: 1.413598, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 62.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315690, G loss: 1.616152, D accuracy: 62.4%, cell accuracy: 98.9%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9991, G loss: 1.4927\n",
      "[124/1600] D loss: 1.3769, G loss: 0.7473\n",
      "[244/1600] D loss: 0.3630, G loss: 3.1988\n",
      "[364/1600] D loss: 0.8258, G loss: 1.7427\n",
      "[484/1600] D loss: 1.0154, G loss: 1.4183\n",
      "[604/1600] D loss: 1.1022, G loss: 1.4391\n",
      "[724/1600] D loss: 0.4146, G loss: 3.2055\n",
      "[844/1600] D loss: 1.0999, G loss: 1.3333\n",
      "[964/1600] D loss: 1.0641, G loss: 1.1629\n",
      "[1084/1600] D loss: 1.3800, G loss: 0.6434\n",
      "[1204/1600] D loss: 0.3961, G loss: 3.2089\n",
      "[1324/1600] D loss: 0.9970, G loss: 1.8184\n",
      "[1444/1600] D loss: 0.9195, G loss: 1.7977\n",
      "[1564/1600] D loss: 1.0540, G loss: 1.6576\n",
      "train error: \n",
      " D loss: 1.013213, G loss: 1.680919, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 61.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376191, G loss: 1.907864, D accuracy: 61.8%, cell accuracy: 98.9%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7192, G loss: 2.5083\n",
      "[124/1600] D loss: 0.8897, G loss: 2.1851\n",
      "[244/1600] D loss: 1.1545, G loss: 1.0265\n",
      "[364/1600] D loss: 1.0876, G loss: 1.3848\n",
      "[484/1600] D loss: 0.6940, G loss: 1.5655\n",
      "[604/1600] D loss: 1.0159, G loss: 2.0565\n",
      "[724/1600] D loss: 1.1459, G loss: 1.0714\n",
      "[844/1600] D loss: 1.4512, G loss: 0.8793\n",
      "[964/1600] D loss: 1.0858, G loss: 1.7751\n",
      "[1084/1600] D loss: 0.9132, G loss: 1.2049\n",
      "[1204/1600] D loss: 0.8918, G loss: 2.4263\n",
      "[1324/1600] D loss: 0.9023, G loss: 2.0357\n",
      "[1444/1600] D loss: 0.7866, G loss: 2.0550\n",
      "[1564/1600] D loss: 1.0373, G loss: 1.2894\n",
      "train error: \n",
      " D loss: 1.005060, G loss: 1.488120, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 62.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329479, G loss: 1.726566, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6851, G loss: 1.7232\n",
      "[124/1600] D loss: 1.0204, G loss: 1.9950\n",
      "[244/1600] D loss: 1.3928, G loss: 0.7219\n",
      "[364/1600] D loss: 0.9615, G loss: 1.4749\n",
      "[484/1600] D loss: 0.8183, G loss: 1.7831\n",
      "[604/1600] D loss: 0.8580, G loss: 1.4633\n",
      "[724/1600] D loss: 0.7254, G loss: 2.4269\n",
      "[844/1600] D loss: 0.8242, G loss: 1.1169\n",
      "[964/1600] D loss: 0.7849, G loss: 1.3706\n",
      "[1084/1600] D loss: 1.0466, G loss: 1.5516\n",
      "[1204/1600] D loss: 0.8585, G loss: 1.6540\n",
      "[1324/1600] D loss: 0.7168, G loss: 2.6838\n",
      "[1444/1600] D loss: 1.4189, G loss: 0.6743\n",
      "[1564/1600] D loss: 1.0324, G loss: 2.7145\n",
      "train error: \n",
      " D loss: 1.026823, G loss: 1.337873, D accuracy: 66.3%, cell accuracy: 99.1%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352265, G loss: 1.526909, D accuracy: 61.8%, cell accuracy: 98.9%, board accuracy: 59.5% \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3859, G loss: 0.5827\n",
      "[124/1600] D loss: 1.0481, G loss: 1.6826\n",
      "[244/1600] D loss: 0.4365, G loss: 2.6149\n",
      "[364/1600] D loss: 1.1149, G loss: 1.0907\n",
      "[484/1600] D loss: 1.1002, G loss: 1.4313\n",
      "[604/1600] D loss: 0.7092, G loss: 2.4405\n",
      "[724/1600] D loss: 0.7647, G loss: 1.9241\n",
      "[844/1600] D loss: 1.4181, G loss: 0.5351\n",
      "[964/1600] D loss: 1.0456, G loss: 1.7158\n",
      "[1084/1600] D loss: 0.7062, G loss: 2.8028\n",
      "[1204/1600] D loss: 0.3892, G loss: 3.4897\n",
      "[1324/1600] D loss: 1.4113, G loss: 0.6260\n",
      "[1444/1600] D loss: 0.7661, G loss: 2.8702\n",
      "[1564/1600] D loss: 0.1614, G loss: 2.8199\n",
      "train error: \n",
      " D loss: 1.005075, G loss: 1.546980, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 62.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378219, G loss: 1.751007, D accuracy: 62.0%, cell accuracy: 98.9%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4340, G loss: 2.6401\n",
      "[124/1600] D loss: 0.7125, G loss: 2.5584\n",
      "[244/1600] D loss: 1.3971, G loss: 1.1539\n",
      "[364/1600] D loss: 0.4168, G loss: 3.7001\n",
      "[484/1600] D loss: 0.7588, G loss: 1.8375\n",
      "[604/1600] D loss: 1.4348, G loss: 0.6369\n",
      "[724/1600] D loss: 0.6269, G loss: 3.3742\n",
      "[844/1600] D loss: 1.4365, G loss: 0.9231\n",
      "[964/1600] D loss: 0.7286, G loss: 2.8730\n",
      "[1084/1600] D loss: 1.4294, G loss: 0.5646\n",
      "[1204/1600] D loss: 0.2053, G loss: 3.0108\n",
      "[1324/1600] D loss: 0.7067, G loss: 1.8459\n",
      "[1444/1600] D loss: 1.2378, G loss: 0.9577\n",
      "[1564/1600] D loss: 1.0555, G loss: 1.2845\n",
      "train error: \n",
      " D loss: 0.997816, G loss: 1.623894, D accuracy: 66.7%, cell accuracy: 99.1%, board accuracy: 63.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375090, G loss: 1.844106, D accuracy: 62.1%, cell accuracy: 98.9%, board accuracy: 57.8% \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0618, G loss: 1.6144\n",
      "[124/1600] D loss: 0.7422, G loss: 2.6162\n",
      "[244/1600] D loss: 0.6705, G loss: 1.9352\n",
      "[364/1600] D loss: 1.0550, G loss: 2.0320\n",
      "[484/1600] D loss: 0.7514, G loss: 2.7734\n",
      "[604/1600] D loss: 1.0542, G loss: 1.4959\n",
      "[724/1600] D loss: 1.0479, G loss: 1.6323\n",
      "[844/1600] D loss: 1.1390, G loss: 1.5620\n",
      "[964/1600] D loss: 1.4172, G loss: 0.7308\n",
      "[1084/1600] D loss: 0.9042, G loss: 1.5331\n",
      "[1204/1600] D loss: 1.4240, G loss: 0.8477\n",
      "[1324/1600] D loss: 1.3449, G loss: 0.7666\n",
      "[1444/1600] D loss: 1.1717, G loss: 0.9223\n",
      "[1564/1600] D loss: 1.0634, G loss: 1.9024\n",
      "train error: \n",
      " D loss: 0.998197, G loss: 1.697973, D accuracy: 66.8%, cell accuracy: 99.1%, board accuracy: 63.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390018, G loss: 1.892548, D accuracy: 61.5%, cell accuracy: 98.9%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0660, G loss: 1.0956\n",
      "[124/1600] D loss: 0.4589, G loss: 3.0004\n",
      "[244/1600] D loss: 0.7440, G loss: 2.2109\n",
      "[364/1600] D loss: 1.3045, G loss: 0.9037\n",
      "[484/1600] D loss: 0.8395, G loss: 1.4138\n",
      "[604/1600] D loss: 1.4138, G loss: 0.7479\n",
      "[724/1600] D loss: 0.6746, G loss: 1.6906\n",
      "[844/1600] D loss: 1.4752, G loss: 0.6631\n",
      "[964/1600] D loss: 1.0878, G loss: 1.1438\n",
      "[1084/1600] D loss: 0.7128, G loss: 2.1150\n",
      "[1204/1600] D loss: 0.4442, G loss: 2.7625\n",
      "[1324/1600] D loss: 0.6453, G loss: 1.8760\n",
      "[1444/1600] D loss: 1.1162, G loss: 1.8044\n",
      "[1564/1600] D loss: 1.0568, G loss: 1.5412\n",
      "train error: \n",
      " D loss: 1.042898, G loss: 1.737113, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 63.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.425212, G loss: 1.959266, D accuracy: 61.4%, cell accuracy: 98.9%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4814, G loss: 0.8820\n",
      "[124/1600] D loss: 1.3231, G loss: 0.8950\n",
      "[244/1600] D loss: 1.0780, G loss: 1.7167\n",
      "[364/1600] D loss: 1.1510, G loss: 2.1137\n",
      "[484/1600] D loss: 1.0253, G loss: 1.6565\n",
      "[604/1600] D loss: 0.3973, G loss: 3.5625\n",
      "[724/1600] D loss: 1.0828, G loss: 1.1353\n",
      "[844/1600] D loss: 0.4842, G loss: 2.2946\n",
      "[964/1600] D loss: 1.0521, G loss: 1.9030\n",
      "[1084/1600] D loss: 0.7928, G loss: 2.4980\n",
      "[1204/1600] D loss: 1.2052, G loss: 1.1860\n",
      "[1324/1600] D loss: 1.0722, G loss: 1.2096\n",
      "[1444/1600] D loss: 1.0364, G loss: 1.5616\n",
      "[1564/1600] D loss: 1.1012, G loss: 1.2410\n",
      "train error: \n",
      " D loss: 1.019910, G loss: 1.523858, D accuracy: 66.6%, cell accuracy: 99.1%, board accuracy: 63.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394934, G loss: 1.705657, D accuracy: 61.5%, cell accuracy: 98.9%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7476, G loss: 1.9318\n",
      "[124/1600] D loss: 1.0900, G loss: 1.2629\n",
      "[244/1600] D loss: 0.7334, G loss: 2.1595\n",
      "[364/1600] D loss: 0.9123, G loss: 1.3521\n",
      "[484/1600] D loss: 0.3917, G loss: 3.4916\n",
      "[604/1600] D loss: 0.7534, G loss: 1.9256\n",
      "[724/1600] D loss: 1.1109, G loss: 2.0434\n",
      "[844/1600] D loss: 0.4556, G loss: 3.5450\n",
      "[964/1600] D loss: 1.0516, G loss: 1.6885\n",
      "[1084/1600] D loss: 1.2918, G loss: 1.5147\n",
      "[1204/1600] D loss: 1.3725, G loss: 0.7955\n",
      "[1324/1600] D loss: 0.9403, G loss: 1.7133\n",
      "[1444/1600] D loss: 0.6072, G loss: 2.4051\n",
      "[1564/1600] D loss: 0.4375, G loss: 2.9415\n",
      "train error: \n",
      " D loss: 0.993391, G loss: 1.554366, D accuracy: 67.1%, cell accuracy: 99.0%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372938, G loss: 1.748588, D accuracy: 62.3%, cell accuracy: 98.9%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0444, G loss: 1.6604\n",
      "[124/1600] D loss: 1.3866, G loss: 0.7112\n",
      "[244/1600] D loss: 0.3666, G loss: 3.9286\n",
      "[364/1600] D loss: 0.8091, G loss: 1.8297\n",
      "[484/1600] D loss: 0.0785, G loss: 3.4737\n",
      "[604/1600] D loss: 0.7075, G loss: 2.1752\n",
      "[724/1600] D loss: 0.7484, G loss: 2.9131\n",
      "[844/1600] D loss: 1.3550, G loss: 0.7116\n",
      "[964/1600] D loss: 0.7876, G loss: 2.0999\n",
      "[1084/1600] D loss: 1.1277, G loss: 1.1805\n",
      "[1204/1600] D loss: 0.8276, G loss: 1.6146\n",
      "[1324/1600] D loss: 1.4690, G loss: 1.0073\n",
      "[1444/1600] D loss: 0.7873, G loss: 2.0158\n",
      "[1564/1600] D loss: 0.8179, G loss: 2.4989\n",
      "train error: \n",
      " D loss: 1.014812, G loss: 1.581858, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.406013, G loss: 1.804225, D accuracy: 61.8%, cell accuracy: 98.8%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0809, G loss: 1.8576\n",
      "[124/1600] D loss: 1.0771, G loss: 1.2077\n",
      "[244/1600] D loss: 1.0167, G loss: 1.2820\n",
      "[364/1600] D loss: 0.7891, G loss: 1.6198\n",
      "[484/1600] D loss: 1.0832, G loss: 1.2677\n",
      "[604/1600] D loss: 0.4510, G loss: 4.1994\n",
      "[724/1600] D loss: 0.7040, G loss: 2.7825\n",
      "[844/1600] D loss: 1.0348, G loss: 1.8612\n",
      "[964/1600] D loss: 0.7887, G loss: 2.6236\n",
      "[1084/1600] D loss: 1.0695, G loss: 1.5472\n",
      "[1204/1600] D loss: 0.9797, G loss: 1.3827\n",
      "[1324/1600] D loss: 1.1133, G loss: 1.9876\n",
      "[1444/1600] D loss: 1.0754, G loss: 1.5144\n",
      "[1564/1600] D loss: 0.7816, G loss: 1.8700\n",
      "train error: \n",
      " D loss: 0.999710, G loss: 1.489021, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 63.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355095, G loss: 1.728658, D accuracy: 62.7%, cell accuracy: 98.9%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9260, G loss: 1.9440\n",
      "[124/1600] D loss: 1.2534, G loss: 1.9846\n",
      "[244/1600] D loss: 0.7098, G loss: 3.2995\n",
      "[364/1600] D loss: 0.7209, G loss: 2.2785\n",
      "[484/1600] D loss: 0.3717, G loss: 2.7537\n",
      "[604/1600] D loss: 1.2066, G loss: 0.9347\n",
      "[724/1600] D loss: 1.4324, G loss: 0.7454\n",
      "[844/1600] D loss: 1.3985, G loss: 0.6470\n",
      "[964/1600] D loss: 0.7235, G loss: 2.7140\n",
      "[1084/1600] D loss: 0.7157, G loss: 2.7322\n",
      "[1204/1600] D loss: 1.4337, G loss: 1.8349\n",
      "[1324/1600] D loss: 1.1121, G loss: 1.7187\n",
      "[1444/1600] D loss: 0.7454, G loss: 2.4533\n",
      "[1564/1600] D loss: 1.3074, G loss: 0.8289\n",
      "train error: \n",
      " D loss: 1.003761, G loss: 1.649495, D accuracy: 66.9%, cell accuracy: 99.0%, board accuracy: 61.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358105, G loss: 1.838062, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7915, G loss: 2.1963\n",
      "[124/1600] D loss: 1.1034, G loss: 1.1745\n",
      "[244/1600] D loss: 0.8463, G loss: 2.2166\n",
      "[364/1600] D loss: 1.1142, G loss: 1.4045\n",
      "[484/1600] D loss: 0.6352, G loss: 2.7411\n",
      "[604/1600] D loss: 1.0904, G loss: 2.1031\n",
      "[724/1600] D loss: 1.1129, G loss: 1.0255\n",
      "[844/1600] D loss: 0.7756, G loss: 2.4168\n",
      "[964/1600] D loss: 1.0547, G loss: 1.4292\n",
      "[1084/1600] D loss: 1.1162, G loss: 1.2626\n",
      "[1204/1600] D loss: 1.0582, G loss: 1.5384\n",
      "[1324/1600] D loss: 1.0283, G loss: 1.5385\n",
      "[1444/1600] D loss: 0.3659, G loss: 3.5593\n",
      "[1564/1600] D loss: 1.4176, G loss: 1.0628\n",
      "train error: \n",
      " D loss: 1.025151, G loss: 1.387735, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402370, G loss: 1.583141, D accuracy: 61.5%, cell accuracy: 98.9%, board accuracy: 59.0% \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9748, G loss: 1.8320\n",
      "[124/1600] D loss: 0.8190, G loss: 1.2674\n",
      "[244/1600] D loss: 1.1823, G loss: 0.8911\n",
      "[364/1600] D loss: 1.0504, G loss: 1.0184\n",
      "[484/1600] D loss: 1.2838, G loss: 0.6853\n",
      "[604/1600] D loss: 0.7568, G loss: 1.8743\n",
      "[724/1600] D loss: 0.3819, G loss: 2.7184\n",
      "[844/1600] D loss: 1.3277, G loss: 0.7138\n",
      "[964/1600] D loss: 0.7619, G loss: 2.0605\n",
      "[1084/1600] D loss: 0.7759, G loss: 2.6094\n",
      "[1204/1600] D loss: 1.0175, G loss: 2.4047\n",
      "[1324/1600] D loss: 1.4496, G loss: 0.7003\n",
      "[1444/1600] D loss: 1.2535, G loss: 1.8103\n",
      "[1564/1600] D loss: 1.2108, G loss: 1.2409\n",
      "train error: \n",
      " D loss: 0.995337, G loss: 1.617732, D accuracy: 67.2%, cell accuracy: 99.0%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385060, G loss: 1.810182, D accuracy: 61.0%, cell accuracy: 98.8%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4771, G loss: 0.5981\n",
      "[124/1600] D loss: 1.0811, G loss: 1.1256\n",
      "[244/1600] D loss: 0.7478, G loss: 2.5833\n",
      "[364/1600] D loss: 1.0870, G loss: 1.5276\n",
      "[484/1600] D loss: 0.6039, G loss: 2.5081\n",
      "[604/1600] D loss: 1.0898, G loss: 1.2464\n",
      "[724/1600] D loss: 1.5008, G loss: 0.8809\n",
      "[844/1600] D loss: 0.7949, G loss: 1.8472\n",
      "[964/1600] D loss: 1.0617, G loss: 1.6072\n",
      "[1084/1600] D loss: 1.0467, G loss: 1.5704\n",
      "[1204/1600] D loss: 1.4070, G loss: 0.7497\n",
      "[1324/1600] D loss: 1.4386, G loss: 0.8540\n",
      "[1444/1600] D loss: 1.2217, G loss: 0.9156\n",
      "[1564/1600] D loss: 0.6815, G loss: 2.1752\n",
      "train error: \n",
      " D loss: 1.007329, G loss: 1.707858, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 62.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.423103, G loss: 1.914326, D accuracy: 61.4%, cell accuracy: 98.8%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4450, G loss: 0.7789\n",
      "[124/1600] D loss: 0.7233, G loss: 1.8986\n",
      "[244/1600] D loss: 1.1478, G loss: 0.9335\n",
      "[364/1600] D loss: 0.7388, G loss: 2.1765\n",
      "[484/1600] D loss: 1.0293, G loss: 1.1508\n",
      "[604/1600] D loss: 1.4195, G loss: 0.8014\n",
      "[724/1600] D loss: 0.9119, G loss: 1.1017\n",
      "[844/1600] D loss: 0.7242, G loss: 2.2451\n",
      "[964/1600] D loss: 0.9797, G loss: 1.7059\n",
      "[1084/1600] D loss: 0.9302, G loss: 1.6855\n",
      "[1204/1600] D loss: 0.7161, G loss: 2.6281\n",
      "[1324/1600] D loss: 0.7053, G loss: 2.3773\n",
      "[1444/1600] D loss: 1.3499, G loss: 0.7313\n",
      "[1564/1600] D loss: 0.8700, G loss: 2.6768\n",
      "train error: \n",
      " D loss: 1.077400, G loss: 1.567895, D accuracy: 65.3%, cell accuracy: 99.0%, board accuracy: 62.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369011, G loss: 1.844798, D accuracy: 62.9%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7820, G loss: 2.9866\n",
      "[124/1600] D loss: 1.2204, G loss: 1.4353\n",
      "[244/1600] D loss: 0.9541, G loss: 1.4392\n",
      "[364/1600] D loss: 0.4599, G loss: 3.6302\n",
      "[484/1600] D loss: 1.1729, G loss: 1.0434\n",
      "[604/1600] D loss: 1.0467, G loss: 1.4487\n",
      "[724/1600] D loss: 1.3969, G loss: 0.9673\n",
      "[844/1600] D loss: 1.3751, G loss: 0.6691\n",
      "[964/1600] D loss: 1.1246, G loss: 1.0033\n",
      "[1084/1600] D loss: 1.4534, G loss: 0.7192\n",
      "[1204/1600] D loss: 0.5676, G loss: 2.9671\n",
      "[1324/1600] D loss: 0.7116, G loss: 3.1383\n",
      "[1444/1600] D loss: 1.1551, G loss: 1.3052\n",
      "[1564/1600] D loss: 0.7453, G loss: 2.1313\n",
      "train error: \n",
      " D loss: 1.054030, G loss: 1.645107, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394962, G loss: 1.888363, D accuracy: 61.8%, cell accuracy: 98.8%, board accuracy: 57.8% \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4935, G loss: 2.2003\n",
      "[124/1600] D loss: 1.3987, G loss: 0.7667\n",
      "[244/1600] D loss: 0.7341, G loss: 2.3536\n",
      "[364/1600] D loss: 1.1863, G loss: 1.4362\n",
      "[484/1600] D loss: 0.3973, G loss: 2.5722\n",
      "[604/1600] D loss: 1.0556, G loss: 1.4696\n",
      "[724/1600] D loss: 1.3937, G loss: 0.6276\n",
      "[844/1600] D loss: 0.4338, G loss: 2.9070\n",
      "[964/1600] D loss: 1.4953, G loss: 0.6689\n",
      "[1084/1600] D loss: 1.0811, G loss: 1.8146\n",
      "[1204/1600] D loss: 1.0459, G loss: 1.8207\n",
      "[1324/1600] D loss: 1.1100, G loss: 1.2133\n",
      "[1444/1600] D loss: 0.7483, G loss: 2.8213\n",
      "[1564/1600] D loss: 1.0613, G loss: 1.8217\n",
      "train error: \n",
      " D loss: 1.000928, G loss: 1.481090, D accuracy: 67.3%, cell accuracy: 99.0%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344020, G loss: 1.744143, D accuracy: 62.7%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4299, G loss: 3.4635\n",
      "[124/1600] D loss: 0.6670, G loss: 2.2666\n",
      "[244/1600] D loss: 1.4030, G loss: 0.5920\n",
      "[364/1600] D loss: 1.2200, G loss: 0.9482\n",
      "[484/1600] D loss: 1.0588, G loss: 1.7373\n",
      "[604/1600] D loss: 0.3680, G loss: 3.4543\n",
      "[724/1600] D loss: 1.5341, G loss: 0.5270\n",
      "[844/1600] D loss: 1.0998, G loss: 0.9947\n",
      "[964/1600] D loss: 1.4132, G loss: 0.6272\n",
      "[1084/1600] D loss: 1.0282, G loss: 2.4698\n",
      "[1204/1600] D loss: 0.8059, G loss: 1.8309\n",
      "[1324/1600] D loss: 0.3659, G loss: 4.0256\n",
      "[1444/1600] D loss: 1.0799, G loss: 1.4291\n",
      "[1564/1600] D loss: 1.2143, G loss: 0.8524\n",
      "train error: \n",
      " D loss: 1.001163, G loss: 1.515887, D accuracy: 66.9%, cell accuracy: 99.0%, board accuracy: 62.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351261, G loss: 1.795048, D accuracy: 62.9%, cell accuracy: 98.8%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4906, G loss: 0.6446\n",
      "[124/1600] D loss: 1.0123, G loss: 2.2959\n",
      "[244/1600] D loss: 0.7351, G loss: 2.2496\n",
      "[364/1600] D loss: 1.0255, G loss: 1.5058\n",
      "[484/1600] D loss: 1.4167, G loss: 0.6043\n",
      "[604/1600] D loss: 0.7515, G loss: 2.5303\n",
      "[724/1600] D loss: 1.4111, G loss: 0.9215\n",
      "[844/1600] D loss: 0.6428, G loss: 2.0222\n",
      "[964/1600] D loss: 0.7712, G loss: 2.6849\n",
      "[1084/1600] D loss: 1.0785, G loss: 1.2610\n",
      "[1204/1600] D loss: 0.7236, G loss: 2.0121\n",
      "[1324/1600] D loss: 1.1188, G loss: 1.3494\n",
      "[1444/1600] D loss: 1.1374, G loss: 1.2514\n",
      "[1564/1600] D loss: 1.2078, G loss: 1.1147\n",
      "train error: \n",
      " D loss: 1.006129, G loss: 1.625424, D accuracy: 67.0%, cell accuracy: 99.0%, board accuracy: 62.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395183, G loss: 1.943643, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0986, G loss: 1.5996\n",
      "[124/1600] D loss: 1.0792, G loss: 1.2539\n",
      "[244/1600] D loss: 0.6898, G loss: 2.3166\n",
      "[364/1600] D loss: 1.0857, G loss: 1.0892\n",
      "[484/1600] D loss: 1.4003, G loss: 0.7070\n",
      "[604/1600] D loss: 1.1106, G loss: 1.4204\n",
      "[724/1600] D loss: 1.3992, G loss: 0.8266\n",
      "[844/1600] D loss: 0.4518, G loss: 2.9768\n",
      "[964/1600] D loss: 1.0535, G loss: 1.6300\n",
      "[1084/1600] D loss: 0.8221, G loss: 1.4655\n",
      "[1204/1600] D loss: 1.0225, G loss: 1.2954\n",
      "[1324/1600] D loss: 0.6020, G loss: 2.7458\n",
      "[1444/1600] D loss: 0.9252, G loss: 1.5461\n",
      "[1564/1600] D loss: 0.7117, G loss: 3.9664\n",
      "train error: \n",
      " D loss: 1.020423, G loss: 1.467864, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 63.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378381, G loss: 1.718959, D accuracy: 62.9%, cell accuracy: 98.8%, board accuracy: 57.8% \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4449, G loss: 2.0351\n",
      "[124/1600] D loss: 0.8238, G loss: 1.6014\n",
      "[244/1600] D loss: 0.7268, G loss: 2.5819\n",
      "[364/1600] D loss: 0.9746, G loss: 1.5812\n",
      "[484/1600] D loss: 1.3579, G loss: 0.9166\n",
      "[604/1600] D loss: 1.3521, G loss: 0.8199\n",
      "[724/1600] D loss: 1.4514, G loss: 0.8213\n",
      "[844/1600] D loss: 0.8575, G loss: 1.9399\n",
      "[964/1600] D loss: 1.0549, G loss: 1.9371\n",
      "[1084/1600] D loss: 1.0556, G loss: 1.1310\n",
      "[1204/1600] D loss: 0.9348, G loss: 1.1671\n",
      "[1324/1600] D loss: 0.8664, G loss: 2.3848\n",
      "[1444/1600] D loss: 1.3698, G loss: 0.6907\n",
      "[1564/1600] D loss: 0.8412, G loss: 1.6582\n",
      "train error: \n",
      " D loss: 1.018918, G loss: 1.492316, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 62.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404483, G loss: 1.708969, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7008, G loss: 2.3205\n",
      "[124/1600] D loss: 1.5426, G loss: 1.3457\n",
      "[244/1600] D loss: 0.7858, G loss: 2.8176\n",
      "[364/1600] D loss: 1.3340, G loss: 0.8839\n",
      "[484/1600] D loss: 1.1111, G loss: 1.0234\n",
      "[604/1600] D loss: 1.4343, G loss: 0.5844\n",
      "[724/1600] D loss: 1.0388, G loss: 1.8411\n",
      "[844/1600] D loss: 1.0796, G loss: 1.0817\n",
      "[964/1600] D loss: 1.3831, G loss: 0.6622\n",
      "[1084/1600] D loss: 1.4406, G loss: 0.5605\n",
      "[1204/1600] D loss: 0.5981, G loss: 2.2529\n",
      "[1324/1600] D loss: 0.7187, G loss: 2.1494\n",
      "[1444/1600] D loss: 1.3512, G loss: 0.8454\n",
      "[1564/1600] D loss: 1.0453, G loss: 1.1686\n",
      "train error: \n",
      " D loss: 1.015693, G loss: 1.466099, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368667, G loss: 1.706072, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8986, G loss: 1.2372\n",
      "[124/1600] D loss: 0.6248, G loss: 2.3281\n",
      "[244/1600] D loss: 1.2702, G loss: 0.7808\n",
      "[364/1600] D loss: 0.8735, G loss: 1.4689\n",
      "[484/1600] D loss: 1.4654, G loss: 0.9608\n",
      "[604/1600] D loss: 0.9640, G loss: 2.0350\n",
      "[724/1600] D loss: 1.0444, G loss: 1.5429\n",
      "[844/1600] D loss: 1.4221, G loss: 0.6538\n",
      "[964/1600] D loss: 1.4524, G loss: 0.7131\n",
      "[1084/1600] D loss: 0.7040, G loss: 2.5098\n",
      "[1204/1600] D loss: 0.0639, G loss: 4.6398\n",
      "[1324/1600] D loss: 0.1963, G loss: 4.2068\n",
      "[1444/1600] D loss: 0.7617, G loss: 1.8411\n",
      "[1564/1600] D loss: 0.3423, G loss: 3.4145\n",
      "train error: \n",
      " D loss: 1.001892, G loss: 1.734796, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 63.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398523, G loss: 1.936921, D accuracy: 61.9%, cell accuracy: 98.9%, board accuracy: 59.5% \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5230, G loss: 2.0137\n",
      "[124/1600] D loss: 1.4118, G loss: 0.7152\n",
      "[244/1600] D loss: 0.7108, G loss: 2.1851\n",
      "[364/1600] D loss: 1.3752, G loss: 0.7696\n",
      "[484/1600] D loss: 1.3669, G loss: 0.6535\n",
      "[604/1600] D loss: 0.5494, G loss: 3.1951\n",
      "[724/1600] D loss: 1.0999, G loss: 1.5404\n",
      "[844/1600] D loss: 0.8036, G loss: 1.3926\n",
      "[964/1600] D loss: 0.3636, G loss: 3.8954\n",
      "[1084/1600] D loss: 1.1272, G loss: 0.8500\n",
      "[1204/1600] D loss: 1.0447, G loss: 1.5274\n",
      "[1324/1600] D loss: 1.1343, G loss: 1.0249\n",
      "[1444/1600] D loss: 0.7178, G loss: 2.8634\n",
      "[1564/1600] D loss: 1.2322, G loss: 0.8464\n",
      "train error: \n",
      " D loss: 1.036253, G loss: 1.402604, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351261, G loss: 1.606672, D accuracy: 62.4%, cell accuracy: 98.9%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0494, G loss: 1.5321\n",
      "[124/1600] D loss: 1.0456, G loss: 1.6251\n",
      "[244/1600] D loss: 1.4863, G loss: 0.5548\n",
      "[364/1600] D loss: 0.9910, G loss: 1.0369\n",
      "[484/1600] D loss: 0.8280, G loss: 1.3778\n",
      "[604/1600] D loss: 1.2957, G loss: 0.7700\n",
      "[724/1600] D loss: 0.8383, G loss: 1.2541\n",
      "[844/1600] D loss: 0.9485, G loss: 1.1186\n",
      "[964/1600] D loss: 1.1397, G loss: 1.4383\n",
      "[1084/1600] D loss: 1.3063, G loss: 0.6549\n",
      "[1204/1600] D loss: 1.0517, G loss: 2.0167\n",
      "[1324/1600] D loss: 1.0651, G loss: 1.4476\n",
      "[1444/1600] D loss: 1.3175, G loss: 0.8390\n",
      "[1564/1600] D loss: 0.7858, G loss: 2.9061\n",
      "train error: \n",
      " D loss: 0.995744, G loss: 1.621736, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 62.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391737, G loss: 1.844511, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2940, G loss: 0.9625\n",
      "[124/1600] D loss: 1.0070, G loss: 2.1051\n",
      "[244/1600] D loss: 1.0877, G loss: 1.7628\n",
      "[364/1600] D loss: 1.0182, G loss: 1.7010\n",
      "[484/1600] D loss: 0.6949, G loss: 3.0512\n",
      "[604/1600] D loss: 1.0721, G loss: 1.0451\n",
      "[724/1600] D loss: 0.7248, G loss: 2.0980\n",
      "[844/1600] D loss: 1.4306, G loss: 0.5523\n",
      "[964/1600] D loss: 1.2697, G loss: 2.1311\n",
      "[1084/1600] D loss: 1.1219, G loss: 1.2702\n",
      "[1204/1600] D loss: 1.0592, G loss: 1.0305\n",
      "[1324/1600] D loss: 1.0327, G loss: 1.4748\n",
      "[1444/1600] D loss: 0.7988, G loss: 1.6090\n",
      "[1564/1600] D loss: 1.1369, G loss: 2.3038\n",
      "train error: \n",
      " D loss: 1.029207, G loss: 1.755684, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 61.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.423256, G loss: 1.967398, D accuracy: 62.7%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3894, G loss: 3.6030\n",
      "[124/1600] D loss: 0.7968, G loss: 2.4018\n",
      "[244/1600] D loss: 1.1611, G loss: 2.2633\n",
      "[364/1600] D loss: 1.3881, G loss: 0.6644\n",
      "[484/1600] D loss: 1.1231, G loss: 0.6891\n",
      "[604/1600] D loss: 1.0554, G loss: 1.6094\n",
      "[724/1600] D loss: 0.6226, G loss: 3.7641\n",
      "[844/1600] D loss: 1.1278, G loss: 1.4188\n",
      "[964/1600] D loss: 0.7178, G loss: 2.3354\n",
      "[1084/1600] D loss: 1.3475, G loss: 0.7607\n",
      "[1204/1600] D loss: 0.7440, G loss: 2.4964\n",
      "[1324/1600] D loss: 0.7790, G loss: 1.5877\n",
      "[1444/1600] D loss: 0.2984, G loss: 3.6748\n",
      "[1564/1600] D loss: 1.3939, G loss: 0.6513\n",
      "train error: \n",
      " D loss: 0.997365, G loss: 1.722382, D accuracy: 67.2%, cell accuracy: 98.9%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393863, G loss: 1.902021, D accuracy: 62.5%, cell accuracy: 98.7%, board accuracy: 55.0% \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2921, G loss: 0.8184\n",
      "[124/1600] D loss: 1.4263, G loss: 0.7736\n",
      "[244/1600] D loss: 1.2072, G loss: 1.1109\n",
      "[364/1600] D loss: 0.9504, G loss: 1.4422\n",
      "[484/1600] D loss: 1.4493, G loss: 1.7086\n",
      "[604/1600] D loss: 1.3917, G loss: 0.7103\n",
      "[724/1600] D loss: 1.0664, G loss: 1.6940\n",
      "[844/1600] D loss: 1.3758, G loss: 0.7797\n",
      "[964/1600] D loss: 0.6998, G loss: 1.5540\n",
      "[1084/1600] D loss: 0.9925, G loss: 4.0339\n",
      "[1204/1600] D loss: 1.0650, G loss: 1.9330\n",
      "[1324/1600] D loss: 1.4368, G loss: 0.5416\n",
      "[1444/1600] D loss: 1.3904, G loss: 0.6890\n",
      "[1564/1600] D loss: 0.7039, G loss: 3.3925\n",
      "train error: \n",
      " D loss: 1.003969, G loss: 1.692964, D accuracy: 66.2%, cell accuracy: 98.9%, board accuracy: 61.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412051, G loss: 1.915160, D accuracy: 62.1%, cell accuracy: 98.7%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0551, G loss: 1.4509\n",
      "[124/1600] D loss: 0.7408, G loss: 2.0996\n",
      "[244/1600] D loss: 1.0747, G loss: 1.7038\n",
      "[364/1600] D loss: 1.0588, G loss: 1.5855\n",
      "[484/1600] D loss: 0.5918, G loss: 2.7366\n",
      "[604/1600] D loss: 1.5255, G loss: 0.8249\n",
      "[724/1600] D loss: 1.4291, G loss: 0.6735\n",
      "[844/1600] D loss: 0.6978, G loss: 3.0743\n",
      "[964/1600] D loss: 1.4022, G loss: 0.6975\n",
      "[1084/1600] D loss: 1.1454, G loss: 1.6100\n",
      "[1204/1600] D loss: 1.3574, G loss: 0.7649\n",
      "[1324/1600] D loss: 1.3940, G loss: 0.7455\n",
      "[1444/1600] D loss: 0.7469, G loss: 1.6871\n",
      "[1564/1600] D loss: 1.4090, G loss: 0.7105\n",
      "train error: \n",
      " D loss: 1.007009, G loss: 1.544359, D accuracy: 66.5%, cell accuracy: 99.0%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360928, G loss: 1.801298, D accuracy: 62.0%, cell accuracy: 98.9%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4429, G loss: 2.8189\n",
      "[124/1600] D loss: 1.2261, G loss: 0.8174\n",
      "[244/1600] D loss: 1.4362, G loss: 0.9055\n",
      "[364/1600] D loss: 1.0548, G loss: 1.5002\n",
      "[484/1600] D loss: 1.0476, G loss: 1.5359\n",
      "[604/1600] D loss: 1.0945, G loss: 1.5007\n",
      "[724/1600] D loss: 1.0184, G loss: 1.3160\n",
      "[844/1600] D loss: 1.0197, G loss: 1.2769\n",
      "[964/1600] D loss: 1.0444, G loss: 2.0747\n",
      "[1084/1600] D loss: 1.5770, G loss: 0.6552\n",
      "[1204/1600] D loss: 0.7192, G loss: 2.4754\n",
      "[1324/1600] D loss: 0.3902, G loss: 2.9289\n",
      "[1444/1600] D loss: 0.3711, G loss: 3.6088\n",
      "[1564/1600] D loss: 1.0506, G loss: 1.5249\n",
      "train error: \n",
      " D loss: 1.041380, G loss: 1.428518, D accuracy: 65.5%, cell accuracy: 99.0%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377341, G loss: 1.673051, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 53.0% \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.8688, G loss: 0.4470\n",
      "[124/1600] D loss: 0.7632, G loss: 1.9697\n",
      "[244/1600] D loss: 0.7605, G loss: 2.4120\n",
      "[364/1600] D loss: 0.7212, G loss: 2.2231\n",
      "[484/1600] D loss: 0.7712, G loss: 2.2791\n",
      "[604/1600] D loss: 0.8527, G loss: 1.5700\n",
      "[724/1600] D loss: 0.4023, G loss: 1.7907\n",
      "[844/1600] D loss: 1.3736, G loss: 0.7656\n",
      "[964/1600] D loss: 1.3374, G loss: 0.7190\n",
      "[1084/1600] D loss: 0.7997, G loss: 2.7342\n",
      "[1204/1600] D loss: 0.8829, G loss: 2.2968\n",
      "[1324/1600] D loss: 0.7252, G loss: 2.1536\n",
      "[1444/1600] D loss: 0.4404, G loss: 3.3417\n",
      "[1564/1600] D loss: 0.3915, G loss: 3.5936\n",
      "train error: \n",
      " D loss: 1.019121, G loss: 1.637988, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.405636, G loss: 1.930889, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 52.8% \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0660, G loss: 1.0726\n",
      "[124/1600] D loss: 1.3858, G loss: 1.0969\n",
      "[244/1600] D loss: 1.1496, G loss: 1.0884\n",
      "[364/1600] D loss: 1.0855, G loss: 1.7427\n",
      "[484/1600] D loss: 1.0612, G loss: 1.2078\n",
      "[604/1600] D loss: 1.0714, G loss: 1.3741\n",
      "[724/1600] D loss: 0.9844, G loss: 1.2112\n",
      "[844/1600] D loss: 0.7351, G loss: 2.3287\n",
      "[964/1600] D loss: 1.1046, G loss: 2.4331\n",
      "[1084/1600] D loss: 1.0669, G loss: 1.0878\n",
      "[1204/1600] D loss: 1.0905, G loss: 1.3549\n",
      "[1324/1600] D loss: 0.7873, G loss: 1.6604\n",
      "[1444/1600] D loss: 1.0744, G loss: 2.1471\n",
      "[1564/1600] D loss: 1.4619, G loss: 0.6466\n",
      "train error: \n",
      " D loss: 1.020200, G loss: 1.572090, D accuracy: 65.8%, cell accuracy: 99.0%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364972, G loss: 1.890882, D accuracy: 63.2%, cell accuracy: 98.8%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9834, G loss: 1.8200\n",
      "[124/1600] D loss: 1.3896, G loss: 0.7853\n",
      "[244/1600] D loss: 1.0879, G loss: 1.3693\n",
      "[364/1600] D loss: 1.0405, G loss: 1.7608\n",
      "[484/1600] D loss: 1.1396, G loss: 1.0143\n",
      "[604/1600] D loss: 1.0250, G loss: 2.1023\n",
      "[724/1600] D loss: 0.4554, G loss: 2.1829\n",
      "[844/1600] D loss: 0.9670, G loss: 1.4673\n",
      "[964/1600] D loss: 1.3337, G loss: 1.0608\n",
      "[1084/1600] D loss: 1.2116, G loss: 1.4687\n",
      "[1204/1600] D loss: 0.7912, G loss: 1.7072\n",
      "[1324/1600] D loss: 0.7196, G loss: 2.0042\n",
      "[1444/1600] D loss: 0.5722, G loss: 1.8523\n",
      "[1564/1600] D loss: 1.2612, G loss: 0.8943\n",
      "train error: \n",
      " D loss: 1.007673, G loss: 1.539170, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394647, G loss: 1.789736, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0467, G loss: 1.6100\n",
      "[124/1600] D loss: 1.1383, G loss: 1.2612\n",
      "[244/1600] D loss: 1.0469, G loss: 1.2887\n",
      "[364/1600] D loss: 1.1133, G loss: 1.2218\n",
      "[484/1600] D loss: 0.9184, G loss: 1.8023\n",
      "[604/1600] D loss: 1.0664, G loss: 1.4957\n",
      "[724/1600] D loss: 1.4664, G loss: 0.9411\n",
      "[844/1600] D loss: 1.4114, G loss: 0.5834\n",
      "[964/1600] D loss: 1.0381, G loss: 1.4929\n",
      "[1084/1600] D loss: 0.8988, G loss: 1.4689\n",
      "[1204/1600] D loss: 1.3964, G loss: 0.6996\n",
      "[1324/1600] D loss: 1.0191, G loss: 1.5954\n",
      "[1444/1600] D loss: 0.7067, G loss: 3.0618\n",
      "[1564/1600] D loss: 1.4019, G loss: 0.6346\n",
      "train error: \n",
      " D loss: 1.011982, G loss: 1.584219, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.425632, G loss: 1.849476, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0771, G loss: 2.1597\n",
      "[124/1600] D loss: 1.3209, G loss: 0.6887\n",
      "[244/1600] D loss: 0.7064, G loss: 2.1815\n",
      "[364/1600] D loss: 1.4410, G loss: 0.6174\n",
      "[484/1600] D loss: 0.7645, G loss: 1.7044\n",
      "[604/1600] D loss: 0.8915, G loss: 1.2823\n",
      "[724/1600] D loss: 0.9992, G loss: 1.4001\n",
      "[844/1600] D loss: 1.0513, G loss: 1.6894\n",
      "[964/1600] D loss: 0.8273, G loss: 2.0238\n",
      "[1084/1600] D loss: 1.3910, G loss: 0.6695\n",
      "[1204/1600] D loss: 1.0743, G loss: 1.5290\n",
      "[1324/1600] D loss: 0.6241, G loss: 2.0117\n",
      "[1444/1600] D loss: 1.0541, G loss: 1.6120\n",
      "[1564/1600] D loss: 0.5743, G loss: 1.8625\n",
      "train error: \n",
      " D loss: 1.017559, G loss: 1.682799, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 61.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.450863, G loss: 1.996007, D accuracy: 61.9%, cell accuracy: 98.8%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4131, G loss: 2.3408\n",
      "[124/1600] D loss: 0.7993, G loss: 2.6499\n",
      "[244/1600] D loss: 0.7539, G loss: 1.9007\n",
      "[364/1600] D loss: 1.5428, G loss: 0.3945\n",
      "[484/1600] D loss: 0.8310, G loss: 1.8032\n",
      "[604/1600] D loss: 0.5977, G loss: 1.7007\n",
      "[724/1600] D loss: 1.0901, G loss: 0.9595\n",
      "[844/1600] D loss: 0.6495, G loss: 2.5334\n",
      "[964/1600] D loss: 0.9222, G loss: 1.2219\n",
      "[1084/1600] D loss: 1.3707, G loss: 0.7624\n",
      "[1204/1600] D loss: 1.0405, G loss: 1.6391\n",
      "[1324/1600] D loss: 1.4005, G loss: 0.6663\n",
      "[1444/1600] D loss: 1.1501, G loss: 0.8740\n",
      "[1564/1600] D loss: 0.9751, G loss: 1.5570\n",
      "train error: \n",
      " D loss: 0.995751, G loss: 1.669381, D accuracy: 67.3%, cell accuracy: 99.0%, board accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.427207, G loss: 1.893525, D accuracy: 61.8%, cell accuracy: 98.8%, board accuracy: 53.5% \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9354, G loss: 1.9458\n",
      "[124/1600] D loss: 1.0819, G loss: 1.4877\n",
      "[244/1600] D loss: 0.9363, G loss: 1.1953\n",
      "[364/1600] D loss: 0.8217, G loss: 1.4113\n",
      "[484/1600] D loss: 1.4061, G loss: 0.6905\n",
      "[604/1600] D loss: 1.1069, G loss: 1.6684\n",
      "[724/1600] D loss: 1.3986, G loss: 0.9829\n",
      "[844/1600] D loss: 0.8017, G loss: 1.5631\n",
      "[964/1600] D loss: 0.4553, G loss: 2.7065\n",
      "[1084/1600] D loss: 0.8481, G loss: 1.7847\n",
      "[1204/1600] D loss: 1.1011, G loss: 1.6788\n",
      "[1324/1600] D loss: 1.1013, G loss: 1.3252\n",
      "[1444/1600] D loss: 1.1937, G loss: 0.7877\n",
      "[1564/1600] D loss: 1.4130, G loss: 0.6004\n",
      "train error: \n",
      " D loss: 1.005843, G loss: 1.709534, D accuracy: 66.9%, cell accuracy: 99.0%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.424339, G loss: 1.956681, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 52.5% \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2502, G loss: 0.9054\n",
      "[124/1600] D loss: 0.8770, G loss: 1.2944\n",
      "[244/1600] D loss: 0.8579, G loss: 2.4524\n",
      "[364/1600] D loss: 0.7312, G loss: 2.7716\n",
      "[484/1600] D loss: 1.4246, G loss: 0.8764\n",
      "[604/1600] D loss: 0.8720, G loss: 1.2203\n",
      "[724/1600] D loss: 1.3885, G loss: 0.6704\n",
      "[844/1600] D loss: 0.9924, G loss: 1.3633\n",
      "[964/1600] D loss: 0.9930, G loss: 1.5683\n",
      "[1084/1600] D loss: 0.4624, G loss: 3.0709\n",
      "[1204/1600] D loss: 1.0213, G loss: 1.4210\n",
      "[1324/1600] D loss: 1.0454, G loss: 2.1110\n",
      "[1444/1600] D loss: 1.4346, G loss: 0.8738\n",
      "[1564/1600] D loss: 1.0589, G loss: 1.3745\n",
      "train error: \n",
      " D loss: 1.020292, G loss: 1.862521, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 62.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.496374, G loss: 2.037640, D accuracy: 61.5%, cell accuracy: 98.9%, board accuracy: 55.8% \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0914, G loss: 1.2057\n",
      "[124/1600] D loss: 0.7864, G loss: 2.1270\n",
      "[244/1600] D loss: 1.3663, G loss: 0.6793\n",
      "[364/1600] D loss: 0.5966, G loss: 2.2399\n",
      "[484/1600] D loss: 1.1803, G loss: 1.2736\n",
      "[604/1600] D loss: 1.4171, G loss: 0.8083\n",
      "[724/1600] D loss: 1.1217, G loss: 1.0838\n",
      "[844/1600] D loss: 0.8080, G loss: 2.1829\n",
      "[964/1600] D loss: 1.4019, G loss: 0.6027\n",
      "[1084/1600] D loss: 1.4003, G loss: 1.4928\n",
      "[1204/1600] D loss: 1.3234, G loss: 0.7935\n",
      "[1324/1600] D loss: 1.1354, G loss: 0.8989\n",
      "[1444/1600] D loss: 1.1018, G loss: 0.9200\n",
      "[1564/1600] D loss: 1.2361, G loss: 1.1608\n",
      "train error: \n",
      " D loss: 1.030194, G loss: 1.389859, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 62.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408997, G loss: 1.609627, D accuracy: 61.4%, cell accuracy: 98.9%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1248, G loss: 0.9081\n",
      "[124/1600] D loss: 1.0611, G loss: 1.6651\n",
      "[244/1600] D loss: 0.8631, G loss: 1.7237\n",
      "[364/1600] D loss: 0.7977, G loss: 2.6906\n",
      "[484/1600] D loss: 1.1168, G loss: 1.1039\n",
      "[604/1600] D loss: 1.4297, G loss: 0.6080\n",
      "[724/1600] D loss: 0.7840, G loss: 2.8484\n",
      "[844/1600] D loss: 1.0359, G loss: 1.1632\n",
      "[964/1600] D loss: 0.7067, G loss: 2.7085\n",
      "[1084/1600] D loss: 0.7986, G loss: 2.2380\n",
      "[1204/1600] D loss: 0.9396, G loss: 1.0744\n",
      "[1324/1600] D loss: 0.9318, G loss: 1.4470\n",
      "[1444/1600] D loss: 1.4884, G loss: 0.5721\n",
      "[1564/1600] D loss: 1.4074, G loss: 0.7456\n",
      "train error: \n",
      " D loss: 1.014810, G loss: 1.440639, D accuracy: 66.9%, cell accuracy: 99.0%, board accuracy: 63.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416678, G loss: 1.685906, D accuracy: 62.1%, cell accuracy: 98.9%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1017, G loss: 1.0779\n",
      "[124/1600] D loss: 0.7473, G loss: 2.3096\n",
      "[244/1600] D loss: 1.1797, G loss: 1.2201\n",
      "[364/1600] D loss: 1.1990, G loss: 0.9282\n",
      "[484/1600] D loss: 0.7668, G loss: 2.4052\n",
      "[604/1600] D loss: 0.7163, G loss: 2.3635\n",
      "[724/1600] D loss: 0.7821, G loss: 1.5014\n",
      "[844/1600] D loss: 1.2905, G loss: 0.7654\n",
      "[964/1600] D loss: 0.6979, G loss: 3.4647\n",
      "[1084/1600] D loss: 1.4053, G loss: 0.6117\n",
      "[1204/1600] D loss: 1.0098, G loss: 1.6826\n",
      "[1324/1600] D loss: 1.0691, G loss: 1.4042\n",
      "[1444/1600] D loss: 0.8696, G loss: 2.3476\n",
      "[1564/1600] D loss: 0.3701, G loss: 3.0023\n",
      "train error: \n",
      " D loss: 0.995229, G loss: 1.659278, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.445188, G loss: 1.916074, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 56.5% \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8111, G loss: 1.5197\n",
      "[124/1600] D loss: 0.6892, G loss: 2.1996\n",
      "[244/1600] D loss: 1.0256, G loss: 1.7434\n",
      "[364/1600] D loss: 1.3935, G loss: 0.6273\n",
      "[484/1600] D loss: 1.0519, G loss: 2.0282\n",
      "[604/1600] D loss: 1.4133, G loss: 0.6684\n",
      "[724/1600] D loss: 0.9862, G loss: 1.9782\n",
      "[844/1600] D loss: 0.8842, G loss: 1.3284\n",
      "[964/1600] D loss: 0.9443, G loss: 1.2309\n",
      "[1084/1600] D loss: 0.8016, G loss: 2.3395\n",
      "[1204/1600] D loss: 0.4752, G loss: 2.7187\n",
      "[1324/1600] D loss: 1.1186, G loss: 1.3460\n",
      "[1444/1600] D loss: 1.4555, G loss: 1.0077\n",
      "[1564/1600] D loss: 0.3663, G loss: 4.1873\n",
      "train error: \n",
      " D loss: 1.037160, G loss: 1.389658, D accuracy: 66.1%, cell accuracy: 99.0%, board accuracy: 62.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359821, G loss: 1.666433, D accuracy: 62.6%, cell accuracy: 98.9%, board accuracy: 56.0% \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2202, G loss: 1.1517\n",
      "[124/1600] D loss: 1.5642, G loss: 0.9218\n",
      "[244/1600] D loss: 0.5826, G loss: 2.0270\n",
      "[364/1600] D loss: 1.4811, G loss: 0.7010\n",
      "[484/1600] D loss: 1.4161, G loss: 0.8596\n",
      "[604/1600] D loss: 1.3892, G loss: 0.7122\n",
      "[724/1600] D loss: 0.5463, G loss: 2.7886\n",
      "[844/1600] D loss: 0.7365, G loss: 2.6174\n",
      "[964/1600] D loss: 1.0453, G loss: 1.4629\n",
      "[1084/1600] D loss: 1.0945, G loss: 1.3060\n",
      "[1204/1600] D loss: 1.4795, G loss: 0.5787\n",
      "[1324/1600] D loss: 1.4078, G loss: 0.8332\n",
      "[1444/1600] D loss: 1.1020, G loss: 1.3675\n",
      "[1564/1600] D loss: 0.6248, G loss: 1.7363\n",
      "train error: \n",
      " D loss: 1.005704, G loss: 1.483187, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386781, G loss: 1.761350, D accuracy: 62.3%, cell accuracy: 98.9%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0727, G loss: 1.3559\n",
      "[124/1600] D loss: 1.0686, G loss: 1.3125\n",
      "[244/1600] D loss: 1.0754, G loss: 1.4488\n",
      "[364/1600] D loss: 0.6988, G loss: 2.3492\n",
      "[484/1600] D loss: 1.0324, G loss: 1.4912\n",
      "[604/1600] D loss: 1.1768, G loss: 0.8589\n",
      "[724/1600] D loss: 1.0571, G loss: 1.2669\n",
      "[844/1600] D loss: 0.5947, G loss: 2.2813\n",
      "[964/1600] D loss: 1.2043, G loss: 2.3310\n",
      "[1084/1600] D loss: 1.0977, G loss: 2.0113\n",
      "[1204/1600] D loss: 1.4000, G loss: 0.7210\n",
      "[1324/1600] D loss: 1.0938, G loss: 1.4802\n",
      "[1444/1600] D loss: 1.1046, G loss: 1.2637\n",
      "[1564/1600] D loss: 1.6138, G loss: 1.0758\n",
      "train error: \n",
      " D loss: 1.054747, G loss: 1.580209, D accuracy: 65.4%, cell accuracy: 99.0%, board accuracy: 62.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.489316, G loss: 1.831825, D accuracy: 61.8%, cell accuracy: 98.8%, board accuracy: 55.5% \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0897, G loss: 1.1766\n",
      "[124/1600] D loss: 1.1809, G loss: 0.7005\n",
      "[244/1600] D loss: 1.4056, G loss: 0.7345\n",
      "[364/1600] D loss: 1.3907, G loss: 0.6890\n",
      "[484/1600] D loss: 1.0492, G loss: 1.7369\n",
      "[604/1600] D loss: 0.7417, G loss: 2.7246\n",
      "[724/1600] D loss: 0.8655, G loss: 1.4528\n",
      "[844/1600] D loss: 1.0740, G loss: 1.2295\n",
      "[964/1600] D loss: 1.4187, G loss: 0.6470\n",
      "[1084/1600] D loss: 0.7044, G loss: 2.7148\n",
      "[1204/1600] D loss: 0.2323, G loss: 2.8048\n",
      "[1324/1600] D loss: 1.1426, G loss: 0.9298\n",
      "[1444/1600] D loss: 1.0501, G loss: 2.2143\n",
      "[1564/1600] D loss: 1.3089, G loss: 0.6545\n",
      "train error: \n",
      " D loss: 0.979433, G loss: 1.702591, D accuracy: 68.2%, cell accuracy: 99.0%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411896, G loss: 1.986922, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 51.5% \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1050, G loss: 0.8863\n",
      "[124/1600] D loss: 0.3625, G loss: 3.7783\n",
      "[244/1600] D loss: 1.4192, G loss: 0.6514\n",
      "[364/1600] D loss: 0.7685, G loss: 2.0770\n",
      "[484/1600] D loss: 0.8267, G loss: 1.6325\n",
      "[604/1600] D loss: 1.0747, G loss: 1.8769\n",
      "[724/1600] D loss: 1.0753, G loss: 1.6107\n",
      "[844/1600] D loss: 1.0534, G loss: 1.5635\n",
      "[964/1600] D loss: 1.0908, G loss: 1.5955\n",
      "[1084/1600] D loss: 1.1710, G loss: 1.1645\n",
      "[1204/1600] D loss: 0.7885, G loss: 2.6316\n",
      "[1324/1600] D loss: 0.7355, G loss: 2.3580\n",
      "[1444/1600] D loss: 1.2272, G loss: 0.8126\n",
      "[1564/1600] D loss: 0.8548, G loss: 1.8562\n",
      "train error: \n",
      " D loss: 1.006656, G loss: 1.778099, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.449877, G loss: 2.088835, D accuracy: 61.5%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3963, G loss: 0.7759\n",
      "[124/1600] D loss: 1.4389, G loss: 0.8572\n",
      "[244/1600] D loss: 0.7040, G loss: 2.7771\n",
      "[364/1600] D loss: 1.0527, G loss: 1.7698\n",
      "[484/1600] D loss: 0.7010, G loss: 2.7622\n",
      "[604/1600] D loss: 0.9032, G loss: 1.4301\n",
      "[724/1600] D loss: 0.5923, G loss: 2.4812\n",
      "[844/1600] D loss: 1.0619, G loss: 2.0889\n",
      "[964/1600] D loss: 0.7527, G loss: 1.9098\n",
      "[1084/1600] D loss: 0.6427, G loss: 2.3001\n",
      "[1204/1600] D loss: 1.4103, G loss: 0.8245\n",
      "[1324/1600] D loss: 0.4420, G loss: 3.1508\n",
      "[1444/1600] D loss: 1.0657, G loss: 1.2061\n",
      "[1564/1600] D loss: 0.7292, G loss: 2.0034\n",
      "train error: \n",
      " D loss: 0.995530, G loss: 1.706922, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.445483, G loss: 1.970073, D accuracy: 61.0%, cell accuracy: 98.8%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4233, G loss: 0.8403\n",
      "[124/1600] D loss: 1.3861, G loss: 0.6529\n",
      "[244/1600] D loss: 0.7145, G loss: 2.4356\n",
      "[364/1600] D loss: 1.0844, G loss: 1.8785\n",
      "[484/1600] D loss: 0.7746, G loss: 1.8748\n",
      "[604/1600] D loss: 1.0427, G loss: 1.6129\n",
      "[724/1600] D loss: 0.3192, G loss: 3.5551\n",
      "[844/1600] D loss: 1.1004, G loss: 1.2931\n",
      "[964/1600] D loss: 0.5952, G loss: 2.8957\n",
      "[1084/1600] D loss: 0.4900, G loss: 1.9050\n",
      "[1204/1600] D loss: 0.9985, G loss: 1.6042\n",
      "[1324/1600] D loss: 0.4485, G loss: 2.1196\n",
      "[1444/1600] D loss: 0.3484, G loss: 4.1793\n",
      "[1564/1600] D loss: 0.7228, G loss: 2.2122\n",
      "train error: \n",
      " D loss: 1.009836, G loss: 1.814419, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 63.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.480779, G loss: 2.126332, D accuracy: 61.9%, cell accuracy: 98.8%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1736, G loss: 1.0735\n",
      "[124/1600] D loss: 1.0993, G loss: 1.1897\n",
      "[244/1600] D loss: 1.4206, G loss: 0.7505\n",
      "[364/1600] D loss: 0.7464, G loss: 2.3265\n",
      "[484/1600] D loss: 0.8371, G loss: 2.2422\n",
      "[604/1600] D loss: 1.4042, G loss: 0.7512\n",
      "[724/1600] D loss: 1.0438, G loss: 2.0261\n",
      "[844/1600] D loss: 1.0603, G loss: 1.4843\n",
      "[964/1600] D loss: 0.7815, G loss: 1.6023\n",
      "[1084/1600] D loss: 0.3807, G loss: 3.3989\n",
      "[1204/1600] D loss: 0.7419, G loss: 2.3889\n",
      "[1324/1600] D loss: 1.0677, G loss: 1.5684\n",
      "[1444/1600] D loss: 0.9413, G loss: 2.3737\n",
      "[1564/1600] D loss: 0.8656, G loss: 1.5518\n",
      "train error: \n",
      " D loss: 1.004621, G loss: 1.797352, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 63.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.470988, G loss: 2.065167, D accuracy: 61.0%, cell accuracy: 98.8%, board accuracy: 58.5% \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0445, G loss: 1.4946\n",
      "[124/1600] D loss: 0.9932, G loss: 1.6216\n",
      "[244/1600] D loss: 1.3235, G loss: 0.7685\n",
      "[364/1600] D loss: 0.7567, G loss: 2.6674\n",
      "[484/1600] D loss: 1.0033, G loss: 1.6817\n",
      "[604/1600] D loss: 1.4602, G loss: 0.5293\n",
      "[724/1600] D loss: 1.1661, G loss: 0.8753\n",
      "[844/1600] D loss: 1.4268, G loss: 0.5576\n",
      "[964/1600] D loss: 0.7169, G loss: 1.9427\n",
      "[1084/1600] D loss: 1.3947, G loss: 0.7128\n",
      "[1204/1600] D loss: 1.4201, G loss: 0.8492\n",
      "[1324/1600] D loss: 1.4006, G loss: 0.6625\n",
      "[1444/1600] D loss: 1.4007, G loss: 0.7369\n",
      "[1564/1600] D loss: 0.7414, G loss: 2.4977\n",
      "train error: \n",
      " D loss: 1.002317, G loss: 1.591629, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 63.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410727, G loss: 1.866284, D accuracy: 61.6%, cell accuracy: 98.8%, board accuracy: 57.8% \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7153, G loss: 2.2307\n",
      "[124/1600] D loss: 1.2242, G loss: 0.7832\n",
      "[244/1600] D loss: 0.7523, G loss: 2.3501\n",
      "[364/1600] D loss: 1.3796, G loss: 0.7688\n",
      "[484/1600] D loss: 1.0812, G loss: 1.8425\n",
      "[604/1600] D loss: 0.7461, G loss: 2.4943\n",
      "[724/1600] D loss: 0.9049, G loss: 1.9942\n",
      "[844/1600] D loss: 1.4181, G loss: 0.5753\n",
      "[964/1600] D loss: 0.7321, G loss: 3.1920\n",
      "[1084/1600] D loss: 1.4769, G loss: 0.7395\n",
      "[1204/1600] D loss: 0.5778, G loss: 2.0523\n",
      "[1324/1600] D loss: 0.9364, G loss: 1.5963\n",
      "[1444/1600] D loss: 1.2511, G loss: 0.7928\n",
      "[1564/1600] D loss: 1.4149, G loss: 0.6262\n",
      "train error: \n",
      " D loss: 1.031740, G loss: 1.918439, D accuracy: 65.6%, cell accuracy: 99.0%, board accuracy: 63.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.529673, G loss: 2.190578, D accuracy: 61.0%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5986, G loss: 2.7436\n",
      "[124/1600] D loss: 1.0358, G loss: 1.7240\n",
      "[244/1600] D loss: 1.1305, G loss: 1.4608\n",
      "[364/1600] D loss: 0.6001, G loss: 3.1569\n",
      "[484/1600] D loss: 1.3747, G loss: 0.7414\n",
      "[604/1600] D loss: 0.7558, G loss: 2.1064\n",
      "[724/1600] D loss: 0.9468, G loss: 1.7566\n",
      "[844/1600] D loss: 1.4279, G loss: 0.6163\n",
      "[964/1600] D loss: 0.7221, G loss: 1.5595\n",
      "[1084/1600] D loss: 1.0915, G loss: 1.5966\n",
      "[1204/1600] D loss: 1.4527, G loss: 0.7450\n",
      "[1324/1600] D loss: 0.7113, G loss: 2.1676\n",
      "[1444/1600] D loss: 0.8623, G loss: 2.5390\n",
      "[1564/1600] D loss: 1.4652, G loss: 0.7228\n",
      "train error: \n",
      " D loss: 1.020700, G loss: 1.561142, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 63.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.439796, G loss: 1.848214, D accuracy: 61.4%, cell accuracy: 98.8%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0487, G loss: 1.6118\n",
      "[124/1600] D loss: 1.0842, G loss: 1.3728\n",
      "[244/1600] D loss: 0.7165, G loss: 2.3049\n",
      "[364/1600] D loss: 0.6958, G loss: 3.1122\n",
      "[484/1600] D loss: 1.4464, G loss: 0.6972\n",
      "[604/1600] D loss: 1.1387, G loss: 0.9838\n",
      "[724/1600] D loss: 1.0524, G loss: 1.2202\n",
      "[844/1600] D loss: 1.3818, G loss: 0.6893\n",
      "[964/1600] D loss: 0.8127, G loss: 2.1792\n",
      "[1084/1600] D loss: 1.0525, G loss: 2.0429\n",
      "[1204/1600] D loss: 1.2601, G loss: 0.7552\n",
      "[1324/1600] D loss: 0.9328, G loss: 1.1830\n",
      "[1444/1600] D loss: 0.8544, G loss: 2.0072\n",
      "[1564/1600] D loss: 1.3863, G loss: 0.6452\n",
      "train error: \n",
      " D loss: 0.998643, G loss: 1.734936, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 63.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.435048, G loss: 2.074586, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1806, G loss: 2.0544\n",
      "[124/1600] D loss: 0.5785, G loss: 1.7486\n",
      "[244/1600] D loss: 1.4208, G loss: 0.8438\n",
      "[364/1600] D loss: 0.8443, G loss: 1.9177\n",
      "[484/1600] D loss: 0.6642, G loss: 2.0343\n",
      "[604/1600] D loss: 0.7315, G loss: 2.8776\n",
      "[724/1600] D loss: 1.0666, G loss: 1.6411\n",
      "[844/1600] D loss: 1.0363, G loss: 1.7339\n",
      "[964/1600] D loss: 0.9854, G loss: 1.8691\n",
      "[1084/1600] D loss: 0.0841, G loss: 3.9851\n",
      "[1204/1600] D loss: 0.9570, G loss: 1.6055\n",
      "[1324/1600] D loss: 1.0843, G loss: 1.1643\n",
      "[1444/1600] D loss: 0.7106, G loss: 2.1445\n",
      "[1564/1600] D loss: 1.0951, G loss: 1.9258\n",
      "train error: \n",
      " D loss: 1.021538, G loss: 1.505495, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 63.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.445010, G loss: 1.794055, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8241, G loss: 1.8701\n",
      "[124/1600] D loss: 1.3110, G loss: 0.8692\n",
      "[244/1600] D loss: 1.0930, G loss: 1.4472\n",
      "[364/1600] D loss: 1.1619, G loss: 0.9195\n",
      "[484/1600] D loss: 1.3860, G loss: 0.7199\n",
      "[604/1600] D loss: 1.3864, G loss: 0.8066\n",
      "[724/1600] D loss: 0.7117, G loss: 2.4894\n",
      "[844/1600] D loss: 1.4097, G loss: 0.6612\n",
      "[964/1600] D loss: 0.9030, G loss: 1.6659\n",
      "[1084/1600] D loss: 0.7590, G loss: 1.8334\n",
      "[1204/1600] D loss: 0.9507, G loss: 1.0534\n",
      "[1324/1600] D loss: 1.1081, G loss: 1.3284\n",
      "[1444/1600] D loss: 1.0359, G loss: 1.6435\n",
      "[1564/1600] D loss: 1.0858, G loss: 1.7375\n",
      "train error: \n",
      " D loss: 1.001157, G loss: 1.734066, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 63.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.459984, G loss: 2.005043, D accuracy: 61.4%, cell accuracy: 98.9%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0827, G loss: 1.1229\n",
      "[124/1600] D loss: 1.3806, G loss: 0.8109\n",
      "[244/1600] D loss: 1.4331, G loss: 0.7488\n",
      "[364/1600] D loss: 0.8768, G loss: 2.0372\n",
      "[484/1600] D loss: 0.8187, G loss: 1.7901\n",
      "[604/1600] D loss: 1.3950, G loss: 0.6116\n",
      "[724/1600] D loss: 0.5258, G loss: 3.2521\n",
      "[844/1600] D loss: 0.7891, G loss: 1.6674\n",
      "[964/1600] D loss: 1.0557, G loss: 1.4012\n",
      "[1084/1600] D loss: 0.3796, G loss: 2.9595\n",
      "[1204/1600] D loss: 1.0367, G loss: 2.0110\n",
      "[1324/1600] D loss: 0.9913, G loss: 1.4567\n",
      "[1444/1600] D loss: 0.8045, G loss: 2.6151\n",
      "[1564/1600] D loss: 0.8389, G loss: 2.3849\n",
      "train error: \n",
      " D loss: 1.018658, G loss: 1.656766, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 64.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.434445, G loss: 1.932019, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 57.2% \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7024, G loss: 2.9755\n",
      "[124/1600] D loss: 0.8673, G loss: 2.0132\n",
      "[244/1600] D loss: 0.6538, G loss: 2.9571\n",
      "[364/1600] D loss: 1.2589, G loss: 0.7689\n",
      "[484/1600] D loss: 1.1481, G loss: 0.8175\n",
      "[604/1600] D loss: 0.9874, G loss: 1.5280\n",
      "[724/1600] D loss: 0.4164, G loss: 3.2985\n",
      "[844/1600] D loss: 1.4778, G loss: 0.7720\n",
      "[964/1600] D loss: 1.4968, G loss: 0.8836\n",
      "[1084/1600] D loss: 1.1544, G loss: 1.3029\n",
      "[1204/1600] D loss: 1.0947, G loss: 1.0899\n",
      "[1324/1600] D loss: 0.0416, G loss: 3.8654\n",
      "[1444/1600] D loss: 1.1466, G loss: 2.2709\n",
      "[1564/1600] D loss: 1.0687, G loss: 1.5715\n",
      "train error: \n",
      " D loss: 1.027639, G loss: 1.395811, D accuracy: 65.9%, cell accuracy: 99.0%, board accuracy: 63.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417649, G loss: 1.720927, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0348, G loss: 1.0939\n",
      "[124/1600] D loss: 1.0319, G loss: 1.5736\n",
      "[244/1600] D loss: 0.9490, G loss: 1.3210\n",
      "[364/1600] D loss: 0.7181, G loss: 2.4039\n",
      "[484/1600] D loss: 1.4006, G loss: 0.6153\n",
      "[604/1600] D loss: 1.1878, G loss: 0.7379\n",
      "[724/1600] D loss: 1.1978, G loss: 0.7880\n",
      "[844/1600] D loss: 1.4469, G loss: 0.6996\n",
      "[964/1600] D loss: 0.7702, G loss: 2.2042\n",
      "[1084/1600] D loss: 1.0495, G loss: 1.6605\n",
      "[1204/1600] D loss: 1.0570, G loss: 1.9451\n",
      "[1324/1600] D loss: 1.1792, G loss: 1.1981\n",
      "[1444/1600] D loss: 1.4142, G loss: 0.5744\n",
      "[1564/1600] D loss: 1.3805, G loss: 0.6512\n",
      "train error: \n",
      " D loss: 1.021395, G loss: 1.869796, D accuracy: 65.9%, cell accuracy: 99.0%, board accuracy: 63.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.513797, G loss: 2.176603, D accuracy: 61.4%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8794, G loss: 2.3148\n",
      "[124/1600] D loss: 1.0958, G loss: 1.2298\n",
      "[244/1600] D loss: 1.3763, G loss: 0.6969\n",
      "[364/1600] D loss: 1.4159, G loss: 0.6595\n",
      "[484/1600] D loss: 0.4270, G loss: 3.0137\n",
      "[604/1600] D loss: 0.7179, G loss: 2.4927\n",
      "[724/1600] D loss: 1.2204, G loss: 0.9294\n",
      "[844/1600] D loss: 1.0484, G loss: 1.4942\n",
      "[964/1600] D loss: 1.0681, G loss: 1.2941\n",
      "[1084/1600] D loss: 1.4139, G loss: 0.5878\n",
      "[1204/1600] D loss: 1.0933, G loss: 2.4963\n",
      "[1324/1600] D loss: 0.8626, G loss: 1.7644\n",
      "[1444/1600] D loss: 0.7517, G loss: 2.0993\n",
      "[1564/1600] D loss: 0.7686, G loss: 2.0263\n",
      "train error: \n",
      " D loss: 1.022124, G loss: 1.415410, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 64.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397888, G loss: 1.752353, D accuracy: 61.9%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0759, G loss: 1.3795\n",
      "[124/1600] D loss: 0.7283, G loss: 2.6921\n",
      "[244/1600] D loss: 0.7866, G loss: 1.8331\n",
      "[364/1600] D loss: 0.9277, G loss: 2.4224\n",
      "[484/1600] D loss: 0.7193, G loss: 2.2281\n",
      "[604/1600] D loss: 1.0536, G loss: 1.9524\n",
      "[724/1600] D loss: 1.4248, G loss: 0.6783\n",
      "[844/1600] D loss: 0.4340, G loss: 3.2313\n",
      "[964/1600] D loss: 1.5003, G loss: 0.5031\n",
      "[1084/1600] D loss: 1.0447, G loss: 2.2702\n",
      "[1204/1600] D loss: 0.7111, G loss: 2.4451\n",
      "[1324/1600] D loss: 1.0384, G loss: 2.1153\n",
      "[1444/1600] D loss: 0.3994, G loss: 2.8491\n",
      "[1564/1600] D loss: 0.8098, G loss: 1.4382\n",
      "train error: \n",
      " D loss: 1.006591, G loss: 1.518708, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 64.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.405500, G loss: 1.856176, D accuracy: 62.4%, cell accuracy: 98.8%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4378, G loss: 0.6986\n",
      "[124/1600] D loss: 0.6809, G loss: 2.1269\n",
      "[244/1600] D loss: 0.6030, G loss: 3.0681\n",
      "[364/1600] D loss: 1.0914, G loss: 1.9033\n",
      "[484/1600] D loss: 0.8113, G loss: 2.0062\n",
      "[604/1600] D loss: 1.0566, G loss: 1.8554\n",
      "[724/1600] D loss: 1.1915, G loss: 0.8199\n",
      "[844/1600] D loss: 1.4023, G loss: 0.7285\n",
      "[964/1600] D loss: 1.4125, G loss: 0.6210\n",
      "[1084/1600] D loss: 0.0653, G loss: 3.5930\n",
      "[1204/1600] D loss: 1.3844, G loss: 0.9298\n",
      "[1324/1600] D loss: 1.0556, G loss: 1.3632\n",
      "[1444/1600] D loss: 0.7948, G loss: 2.4273\n",
      "[1564/1600] D loss: 0.7995, G loss: 3.6926\n",
      "train error: \n",
      " D loss: 1.011380, G loss: 1.518028, D accuracy: 66.4%, cell accuracy: 99.0%, board accuracy: 64.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.434350, G loss: 1.797925, D accuracy: 61.6%, cell accuracy: 98.9%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0542, G loss: 1.7864\n",
      "[124/1600] D loss: 1.1251, G loss: 1.1208\n",
      "[244/1600] D loss: 0.7037, G loss: 2.3306\n",
      "[364/1600] D loss: 1.3943, G loss: 0.7710\n",
      "[484/1600] D loss: 1.0894, G loss: 1.3343\n",
      "[604/1600] D loss: 1.0232, G loss: 1.2156\n",
      "[724/1600] D loss: 1.2433, G loss: 0.8589\n",
      "[844/1600] D loss: 0.9824, G loss: 1.0442\n",
      "[964/1600] D loss: 0.7656, G loss: 2.2306\n",
      "[1084/1600] D loss: 1.0651, G loss: 1.6732\n",
      "[1204/1600] D loss: 1.2866, G loss: 1.4460\n",
      "[1324/1600] D loss: 1.1286, G loss: 1.9322\n",
      "[1444/1600] D loss: 1.1588, G loss: 0.8710\n",
      "[1564/1600] D loss: 0.7002, G loss: 2.1954\n",
      "train error: \n",
      " D loss: 1.033339, G loss: 1.940639, D accuracy: 66.2%, cell accuracy: 99.0%, board accuracy: 62.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.494691, G loss: 2.217262, D accuracy: 61.5%, cell accuracy: 98.8%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4933, G loss: 0.9953\n",
      "[124/1600] D loss: 0.7205, G loss: 2.4431\n",
      "[244/1600] D loss: 0.8133, G loss: 1.7426\n",
      "[364/1600] D loss: 1.0542, G loss: 1.6652\n",
      "[484/1600] D loss: 0.9920, G loss: 1.2916\n",
      "[604/1600] D loss: 0.3557, G loss: 4.2938\n",
      "[724/1600] D loss: 1.0484, G loss: 1.6292\n",
      "[844/1600] D loss: 1.0590, G loss: 1.4540\n",
      "[964/1600] D loss: 0.7167, G loss: 2.0849\n",
      "[1084/1600] D loss: 0.7699, G loss: 2.4510\n",
      "[1204/1600] D loss: 1.0707, G loss: 1.6011\n",
      "[1324/1600] D loss: 0.4177, G loss: 3.1380\n",
      "[1444/1600] D loss: 1.1870, G loss: 1.1488\n",
      "[1564/1600] D loss: 1.0455, G loss: 1.7047\n",
      "train error: \n",
      " D loss: 1.019940, G loss: 1.568211, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 61.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.471256, G loss: 1.876866, D accuracy: 61.8%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9373, G loss: 1.3373\n",
      "[124/1600] D loss: 1.4297, G loss: 0.7519\n",
      "[244/1600] D loss: 0.9177, G loss: 1.6600\n",
      "[364/1600] D loss: 0.3581, G loss: 4.0379\n",
      "[484/1600] D loss: 1.1164, G loss: 1.7291\n",
      "[604/1600] D loss: 1.4202, G loss: 0.8326\n",
      "[724/1600] D loss: 0.6124, G loss: 2.3041\n",
      "[844/1600] D loss: 1.1788, G loss: 1.8390\n",
      "[964/1600] D loss: 0.6940, G loss: 2.8686\n",
      "[1084/1600] D loss: 0.9411, G loss: 1.3264\n",
      "[1204/1600] D loss: 1.0495, G loss: 2.0963\n",
      "[1324/1600] D loss: 1.0691, G loss: 1.3496\n",
      "[1444/1600] D loss: 1.4438, G loss: 0.8819\n",
      "[1564/1600] D loss: 0.7971, G loss: 1.9500\n",
      "train error: \n",
      " D loss: 0.989024, G loss: 1.839964, D accuracy: 67.3%, cell accuracy: 98.8%, board accuracy: 60.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.407027, G loss: 2.098448, D accuracy: 62.5%, cell accuracy: 98.6%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0753, G loss: 1.5731\n",
      "[124/1600] D loss: 0.8049, G loss: 3.2654\n",
      "[244/1600] D loss: 0.8085, G loss: 2.3876\n",
      "[364/1600] D loss: 0.4695, G loss: 3.5064\n",
      "[484/1600] D loss: 0.7558, G loss: 1.7954\n",
      "[604/1600] D loss: 1.0175, G loss: 2.0102\n",
      "[724/1600] D loss: 1.3828, G loss: 0.6811\n",
      "[844/1600] D loss: 1.4072, G loss: 0.7948\n",
      "[964/1600] D loss: 1.0567, G loss: 1.3254\n",
      "[1084/1600] D loss: 0.5465, G loss: 2.1787\n",
      "[1204/1600] D loss: 1.0090, G loss: 1.6404\n",
      "[1324/1600] D loss: 1.4046, G loss: 0.6782\n",
      "[1444/1600] D loss: 1.3900, G loss: 0.7868\n",
      "[1564/1600] D loss: 1.3841, G loss: 0.8526\n",
      "train error: \n",
      " D loss: 1.040862, G loss: 1.426284, D accuracy: 66.0%, cell accuracy: 99.0%, board accuracy: 63.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416978, G loss: 1.749992, D accuracy: 62.6%, cell accuracy: 98.8%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7180, G loss: 1.2346\n",
      "[124/1600] D loss: 1.2269, G loss: 0.8424\n",
      "[244/1600] D loss: 1.3434, G loss: 0.7633\n",
      "[364/1600] D loss: 1.2925, G loss: 0.7818\n",
      "[484/1600] D loss: 1.3652, G loss: 0.8095\n",
      "[604/1600] D loss: 0.9680, G loss: 1.3429\n",
      "[724/1600] D loss: 1.3942, G loss: 0.7283\n",
      "[844/1600] D loss: 1.4200, G loss: 0.8004\n",
      "[964/1600] D loss: 1.3928, G loss: 0.7910\n",
      "[1084/1600] D loss: 0.7247, G loss: 2.0155\n",
      "[1204/1600] D loss: 0.5541, G loss: 2.9508\n",
      "[1324/1600] D loss: 1.1681, G loss: 1.2007\n",
      "[1444/1600] D loss: 0.8332, G loss: 1.5562\n",
      "[1564/1600] D loss: 0.7602, G loss: 2.1276\n",
      "train error: \n",
      " D loss: 1.002718, G loss: 1.568467, D accuracy: 66.8%, cell accuracy: 99.0%, board accuracy: 63.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.450619, G loss: 1.824222, D accuracy: 61.4%, cell accuracy: 98.9%, board accuracy: 58.5% \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7209, G loss: 2.1687\n",
      "[124/1600] D loss: 0.6791, G loss: 2.8440\n",
      "[244/1600] D loss: 1.0472, G loss: 1.8877\n",
      "[364/1600] D loss: 1.4521, G loss: 0.8466\n",
      "[484/1600] D loss: 1.1000, G loss: 1.0848\n",
      "[604/1600] D loss: 1.4277, G loss: 0.7444\n",
      "[724/1600] D loss: 1.1282, G loss: 0.9764\n",
      "[844/1600] D loss: 0.6850, G loss: 3.3150\n",
      "[964/1600] D loss: 1.0096, G loss: 2.1237\n",
      "[1084/1600] D loss: 1.2913, G loss: 0.6688\n",
      "[1204/1600] D loss: 1.2989, G loss: 0.7533\n",
      "[1324/1600] D loss: 1.1456, G loss: 1.1647\n",
      "[1444/1600] D loss: 1.0468, G loss: 1.8097\n",
      "[1564/1600] D loss: 1.0493, G loss: 1.7679\n",
      "train error: \n",
      " D loss: 0.998355, G loss: 1.624253, D accuracy: 66.6%, cell accuracy: 99.0%, board accuracy: 64.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.434373, G loss: 1.974439, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 59.2% \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7037, G loss: 2.6825\n",
      "[124/1600] D loss: 0.4060, G loss: 2.7818\n",
      "[244/1600] D loss: 1.0302, G loss: 1.7858\n",
      "[364/1600] D loss: 1.2268, G loss: 0.7197\n",
      "[484/1600] D loss: 1.1742, G loss: 1.7334\n",
      "[604/1600] D loss: 1.0531, G loss: 2.2060\n",
      "[724/1600] D loss: 1.1944, G loss: 0.9700\n",
      "[844/1600] D loss: 1.3272, G loss: 0.9209\n",
      "[964/1600] D loss: 0.7822, G loss: 1.9878\n",
      "[1084/1600] D loss: 1.4420, G loss: 0.5881\n",
      "[1204/1600] D loss: 1.5392, G loss: 0.9976\n",
      "[1324/1600] D loss: 1.0889, G loss: 1.1520\n",
      "[1444/1600] D loss: 0.7329, G loss: 2.0956\n",
      "[1564/1600] D loss: 0.6547, G loss: 2.3617\n",
      "train error: \n",
      " D loss: 0.990133, G loss: 1.722019, D accuracy: 66.7%, cell accuracy: 99.0%, board accuracy: 62.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.455873, G loss: 1.993675, D accuracy: 61.3%, cell accuracy: 98.8%, board accuracy: 56.2% \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0046, G loss: 1.5930\n",
      "[124/1600] D loss: 0.6807, G loss: 1.8507\n",
      "[244/1600] D loss: 0.8433, G loss: 1.9493\n",
      "[364/1600] D loss: 1.0663, G loss: 1.6940\n",
      "[484/1600] D loss: 0.7354, G loss: 2.7113\n",
      "[604/1600] D loss: 0.7252, G loss: 2.5192\n",
      "[724/1600] D loss: 1.0011, G loss: 0.9448\n",
      "[844/1600] D loss: 1.0548, G loss: 1.5320\n",
      "[964/1600] D loss: 1.3216, G loss: 1.0612\n",
      "[1084/1600] D loss: 1.1790, G loss: 1.0746\n",
      "[1204/1600] D loss: 1.0913, G loss: 1.5811\n",
      "[1324/1600] D loss: 1.0999, G loss: 1.4988\n",
      "[1444/1600] D loss: 1.2588, G loss: 0.8604\n",
      "[1564/1600] D loss: 1.1866, G loss: 1.6942\n",
      "train error: \n",
      " D loss: 0.998516, G loss: 1.731373, D accuracy: 66.3%, cell accuracy: 99.0%, board accuracy: 64.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.435709, G loss: 2.086054, D accuracy: 62.1%, cell accuracy: 98.8%, board accuracy: 59.2% \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0311, G loss: 1.8226\n",
      "[124/1600] D loss: 0.6441, G loss: 2.0754\n",
      "[244/1600] D loss: 1.4425, G loss: 0.8868\n",
      "[364/1600] D loss: 1.1908, G loss: 2.2995\n",
      "[484/1600] D loss: 1.1283, G loss: 1.9936\n",
      "[604/1600] D loss: 1.0790, G loss: 1.7578\n",
      "[724/1600] D loss: 0.7821, G loss: 2.1542\n",
      "[844/1600] D loss: 0.3820, G loss: 3.3162\n",
      "[964/1600] D loss: 0.7237, G loss: 2.1514\n",
      "[1084/1600] D loss: 1.2285, G loss: 0.8184\n",
      "[1204/1600] D loss: 0.7128, G loss: 2.2921\n",
      "[1324/1600] D loss: 1.1536, G loss: 0.6902\n",
      "[1444/1600] D loss: 0.4039, G loss: 2.8002\n",
      "[1564/1600] D loss: 1.1784, G loss: 0.8843\n",
      "train error: \n",
      " D loss: 0.996618, G loss: 1.592914, D accuracy: 66.6%, cell accuracy: 99.1%, board accuracy: 63.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.415052, G loss: 1.848821, D accuracy: 61.5%, cell accuracy: 98.9%, board accuracy: 57.8% \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4100, G loss: 2.5861\n",
      "[124/1600] D loss: 0.7192, G loss: 2.6716\n",
      "[244/1600] D loss: 0.7587, G loss: 3.2102\n",
      "[364/1600] D loss: 0.8547, G loss: 1.4539\n",
      "[484/1600] D loss: 0.5533, G loss: 3.5159\n",
      "[604/1600] D loss: 0.7210, G loss: 2.1866\n",
      "[724/1600] D loss: 0.4022, G loss: 3.0611\n",
      "[844/1600] D loss: 1.0835, G loss: 2.2927\n",
      "[964/1600] D loss: 1.1430, G loss: 1.5710\n",
      "[1084/1600] D loss: 1.0550, G loss: 1.9127\n",
      "[1204/1600] D loss: 1.0558, G loss: 1.3404\n",
      "[1324/1600] D loss: 1.4303, G loss: 0.5353\n",
      "[1444/1600] D loss: 1.4161, G loss: 0.6254\n",
      "[1564/1600] D loss: 0.7020, G loss: 3.1963\n",
      "train error: \n",
      " D loss: 1.038954, G loss: 1.498779, D accuracy: 66.0%, cell accuracy: 99.0%, board accuracy: 64.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.461232, G loss: 1.778809, D accuracy: 62.0%, cell accuracy: 98.8%, board accuracy: 59.8% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Run this as many times as needed to \"top-up\" the training\n",
    "\n",
    "extra_epochs = 290\n",
    "\n",
    "tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "for epoch in range(epochs, epochs + extra_epochs):\n",
    "    print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "    test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "    test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "    gen_zero_grads = 0\n",
    "    for name, weight in gen.named_parameters():\n",
    "        tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "        if weight.grad is not None:\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "            gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "    tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "    disc_zero_grads = 0\n",
    "    for name, weight in disc.named_parameters():\n",
    "        tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "        if weight.grad is not None:\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "            disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "    tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "\n",
    "tb_writer.close()\n",
    "\n",
    "epochs += extra_epochs\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engines import EVENT_NAMES\n",
    "\n",
    "\n",
    "def show_prediction(example):\n",
    "    (b, e), y = example\n",
    "    pred = gen(b.unsqueeze(0), e.unsqueeze(0)).squeeze(0)\n",
    "    b, e, y, pred = b.argmax(0), e.argmax(0), y.argmax(0), pred.argmax(0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    fig.suptitle(f\"Prediction vs reality\\nEvent = {EVENT_NAMES[e]}\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].set_title(\"Predicted\")\n",
    "    axs[2].set_title(\"Reality\")\n",
    "\n",
    "    axs[0].imshow(render_board(b).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[1].imshow(render_board(pred).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[2].imshow(render_board(y).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 371\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random training prediction vs reality\n",
    "import random\n",
    "\n",
    "idx = random.randrange(len(train_dataset))\n",
    "print(f\"Showing prediction for training example {idx}\")\n",
    "show_prediction(train_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for test example 287\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random test prediction vs reality\n",
    "idx = random.randrange(len(test_dataset))\n",
    "print(f\"Showing prediction for test example {idx}\")\n",
    "show_prediction(test_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), \"tetris_emulator.pth\")\n",
    "torch.save(disc.state_dict(), \"tetris_discriminator.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
